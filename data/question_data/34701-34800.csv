,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Solution explanation Durrett probability 5th edition exercise 2.3.12,Solution explanation Durrett probability 5th edition exercise 2.3.12,,"Let $X_1,X_2,...$ be a sequence of random variables on $(\Omega,\mathcal{F},P)$ where $\Omega$ is a countable set and $\mathcal{F}$ consists of all subsets of $\Omega$ . Show $X_n \rightarrow X$ in probability implies $X_n \rightarrow X$ a.s. Here is the solution from the book: We can pick $\delta_n \rightarrow 0$ so that $P(|X_n-X|>\delta_n) \rightarrow 0$ . Let $\omega \in \Omega$ with $P(\omega)=p>0$ . For large $n$ we have $P(|X_n-X|>\delta_n)  \leq p/2$ so $|X_n(\omega)-X(\omega)| \leq \delta_n \rightarrow 0$ . If $\Omega_0=\{\omega:P(\{w\})>0\}$ then $P(\Omega_0)=1$ and done. I don't follow the argument, starting ""For large $n$ we have $P(|X_n-X|>\delta_n)  \leq p/2$ so $|X_n(\omega)-X(\omega)| \leq \delta_n \rightarrow 0$ ."". Can someone walk me through? Thanks.","Let be a sequence of random variables on where is a countable set and consists of all subsets of . Show in probability implies a.s. Here is the solution from the book: We can pick so that . Let with . For large we have so . If then and done. I don't follow the argument, starting ""For large we have so ."". Can someone walk me through? Thanks.","X_1,X_2,... (\Omega,\mathcal{F},P) \Omega \mathcal{F} \Omega X_n \rightarrow X X_n \rightarrow X \delta_n \rightarrow 0 P(|X_n-X|>\delta_n) \rightarrow 0 \omega \in \Omega P(\omega)=p>0 n P(|X_n-X|>\delta_n)  \leq p/2 |X_n(\omega)-X(\omega)| \leq \delta_n \rightarrow 0 \Omega_0=\{\omega:P(\{w\})>0\} P(\Omega_0)=1 n P(|X_n-X|>\delta_n)  \leq p/2 |X_n(\omega)-X(\omega)| \leq \delta_n \rightarrow 0","['probability', 'proof-explanation']"
1,Probability you end dice rolling sequence with 1-2-3 and odd total number of rolls,Probability you end dice rolling sequence with 1-2-3 and odd total number of rolls,,"Here's a question from the AIME competition: Misha rolls a standard, fair six-sided die until she rolls 1-2-3 in that order on three consecutive rolls. The probability that she will roll the die an odd number of times is ${m\over{n}}$ where $m$ and $n$ are relatively prime positive integers. Find $m + n$ . This is what I did. Let's add up the following cases with an odd number of rolls, where in each sequence of XXX... there is no subsequence of 123: Probability of 123: $({1/6})^3$ Probability of XX123: $({1/6})^3$ Probability of XXXX123: $(1/6)^3(1 - 2(1/6)^3)$ Probability of XXXXXX123: $(1/6)^3(1 - 4(1/6)^3 + (1/6)^6)$ Probability of XXXXXXXX123: $(1/6)^3 (1 - 6(1/6)^3 + \binom{4}{2} (1/6)^6) = (1/6)^3 (1 - 6(1/6)^3 + 6(1/6)^6)$ Probability of XXXXXXXXXX123: $(1/6)^3 (1 - 8(1/6)^3 + \binom{6}{2} (1/6)^6 - 4(1/6)^9) = (1/6)^3 (1 - 8(1/6)^3 + 15(1/6)^6 - 4(1/6)^9)$ Probability of XXXXXXXXXXXX123: $(1/6)^3 (1 - 10(1/6)^3 + \binom{8}{2} (1/6)^6 - \binom{6}{3}(1/6)^9 + (1/6)^{12}) = (1/6)^3 (1 - 10(1/6)^3 + 28 (1/6)^6 - 20(1/6)^9 + (1/6)^{12})$ $\ldots$ and so forth. I notice some obvious patterns, but nonetheless I'm stuck with proceeding further. Any hints towards finding a way to add this all up would be well-appreciated. Please, no complete solutions. Edit: For the record, the correct probability after you add this all up should be ${{216}\over{431}}$ . Edit 2: There are a number of solutions to this problem here: https://artofproblemsolving.com/wiki/index.php/2018_AIME_II_Problems/Problem_13 However, all the solutions at the link are extremely clever, whereas my approach is a naive brute force. I would like some hints/suggestions on how to make my brute force approach work.","Here's a question from the AIME competition: Misha rolls a standard, fair six-sided die until she rolls 1-2-3 in that order on three consecutive rolls. The probability that she will roll the die an odd number of times is where and are relatively prime positive integers. Find . This is what I did. Let's add up the following cases with an odd number of rolls, where in each sequence of XXX... there is no subsequence of 123: Probability of 123: Probability of XX123: Probability of XXXX123: Probability of XXXXXX123: Probability of XXXXXXXX123: Probability of XXXXXXXXXX123: Probability of XXXXXXXXXXXX123: and so forth. I notice some obvious patterns, but nonetheless I'm stuck with proceeding further. Any hints towards finding a way to add this all up would be well-appreciated. Please, no complete solutions. Edit: For the record, the correct probability after you add this all up should be . Edit 2: There are a number of solutions to this problem here: https://artofproblemsolving.com/wiki/index.php/2018_AIME_II_Problems/Problem_13 However, all the solutions at the link are extremely clever, whereas my approach is a naive brute force. I would like some hints/suggestions on how to make my brute force approach work.",{m\over{n}} m n m + n ({1/6})^3 ({1/6})^3 (1/6)^3(1 - 2(1/6)^3) (1/6)^3(1 - 4(1/6)^3 + (1/6)^6) (1/6)^3 (1 - 6(1/6)^3 + \binom{4}{2} (1/6)^6) = (1/6)^3 (1 - 6(1/6)^3 + 6(1/6)^6) (1/6)^3 (1 - 8(1/6)^3 + \binom{6}{2} (1/6)^6 - 4(1/6)^9) = (1/6)^3 (1 - 8(1/6)^3 + 15(1/6)^6 - 4(1/6)^9) (1/6)^3 (1 - 10(1/6)^3 + \binom{8}{2} (1/6)^6 - \binom{6}{3}(1/6)^9 + (1/6)^{12}) = (1/6)^3 (1 - 10(1/6)^3 + 28 (1/6)^6 - 20(1/6)^9 + (1/6)^{12}) \ldots {{216}\over{431}},"['probability', 'combinatorics', 'algebra-precalculus', 'summation', 'markov-chains']"
2,Intuition behind a hypergeometric distribution with standard deviation greater than the mean,Intuition behind a hypergeometric distribution with standard deviation greater than the mean,,"Say I've bought 100 tickets in a raffle of 10,000 tickets total. Assuming three tickets are randomly drawn without replacement from this raffle, we can represent the probability of different outcomes as a hypergeometric distribution with parameters $n = 3$ , $s = 100$ and $N = 10,000$ . In this case, the number of my tickets that I can expect to be drawn are: $$E(X) = n\left(\frac{s}{N}\right) = 0.03$$ With standard deviation of: $$\sigma(X) = \sqrt{n \left(\frac{s}{N}\right) \left(1 - \frac{s}{N}\right) \left(\frac{N - n}{N - 1}\right)} = 0.17$$ I'm trying to intuitively understand how this makes sense - our expected number of successes in this instance is $0.03 \pm 0.17$ . This means that negative successes lie in the range of probable outcomes, but by definition we can't have negative successes. Hence, are the expected outcomes positively skewed in some way? E.g. say each prize was worth €20, we'd have an expected return of $ € 0.60 \pm €3.40$ . But, since we can't have negative prizes, this actually lies in the range €0 - €4.00. This doesn't seem right but I'm trying to figure out where I'm going wrong with my assumptions and interpretations above. Many thanks.","Say I've bought 100 tickets in a raffle of 10,000 tickets total. Assuming three tickets are randomly drawn without replacement from this raffle, we can represent the probability of different outcomes as a hypergeometric distribution with parameters , and . In this case, the number of my tickets that I can expect to be drawn are: With standard deviation of: I'm trying to intuitively understand how this makes sense - our expected number of successes in this instance is . This means that negative successes lie in the range of probable outcomes, but by definition we can't have negative successes. Hence, are the expected outcomes positively skewed in some way? E.g. say each prize was worth €20, we'd have an expected return of . But, since we can't have negative prizes, this actually lies in the range €0 - €4.00. This doesn't seem right but I'm trying to figure out where I'm going wrong with my assumptions and interpretations above. Many thanks.","n = 3 s = 100 N = 10,000 E(X) = n\left(\frac{s}{N}\right) = 0.03 \sigma(X) = \sqrt{n \left(\frac{s}{N}\right) \left(1 - \frac{s}{N}\right) \left(\frac{N - n}{N - 1}\right)} = 0.17 0.03 \pm 0.17  € 0.60 \pm €3.40","['probability', 'statistics', 'probability-distributions']"
3,"Car, gas, crow problem - looking for analytic solution","Car, gas, crow problem - looking for analytic solution",,"I made up this problem recently. possible configuration Imagine you are lost in a car on a long circular road in a hot desert. You have enough gas to go halfway around the circle. There is a gas station that is your only hope for survival, but you don’t even know where you are, let alone which direction will get you to the gas. With this much information, your best option is to pick a direction and go that way until you reach the gas or run out. Your chances of survival are 50%. Now imagine there is also a dead crow on the side of the road. All three objects are randomly distributed around the circle with all locations equally likely. Also, you are told which direction will get you to the crow before the gas station. Does this help? What should you do? What are your chances? I have the sketch of a solution, but it leans on a simulation. Is there a purely analytic solution? The gas station and the car divide the road into two segments, and you  need the smaller segment to survive. The randomly placed crow is more  likely to be in the larger segment, simply because it’s larger. You  should go in the other direction. coordinate system To avoid considering cases  separately, we define a coordinate system going from the car opposite  the crow-first direction with circle circumference 1, so g < c. We  know that 0 ≤ g < 1 but the probability of g → 1 is vanishingly small  since it would also require that c → 1. It is reasonable to assume  (and simulation confirms) that the probability density function for g  is linear so it must be probability density function The probability of survival is the sum of  the areas shown, p(g<1/2) = 3/4.","I made up this problem recently. possible configuration Imagine you are lost in a car on a long circular road in a hot desert. You have enough gas to go halfway around the circle. There is a gas station that is your only hope for survival, but you don’t even know where you are, let alone which direction will get you to the gas. With this much information, your best option is to pick a direction and go that way until you reach the gas or run out. Your chances of survival are 50%. Now imagine there is also a dead crow on the side of the road. All three objects are randomly distributed around the circle with all locations equally likely. Also, you are told which direction will get you to the crow before the gas station. Does this help? What should you do? What are your chances? I have the sketch of a solution, but it leans on a simulation. Is there a purely analytic solution? The gas station and the car divide the road into two segments, and you  need the smaller segment to survive. The randomly placed crow is more  likely to be in the larger segment, simply because it’s larger. You  should go in the other direction. coordinate system To avoid considering cases  separately, we define a coordinate system going from the car opposite  the crow-first direction with circle circumference 1, so g < c. We  know that 0 ≤ g < 1 but the probability of g → 1 is vanishingly small  since it would also require that c → 1. It is reasonable to assume  (and simulation confirms) that the probability density function for g  is linear so it must be probability density function The probability of survival is the sum of  the areas shown, p(g<1/2) = 3/4.",,"['probability', 'puzzle']"
4,Can we treat these events as independent?,Can we treat these events as independent?,,"Problem: The chances of someone having a genetic stigma is $1$ %. Assume a couple with $2$ children. If both parent have a stigma, the chances of each child having it is $50$ %. If just one parent has a genetic stigma, the chances of each child having it is $2$ %. a) What is the probability of both children having the stigma, assuming that only one parent has it? b) What is the probability of both children having the stigma, if we know nothing about the parents? My assumption: I think that in both a) and b) we deal with independent events (since the birth of a child doesnt influence the chances of the next one having the stigma). So i think that for a) its $0.02 * 0.02$ and for b) its $0.01 * 0.01$ Is this assumption correct?","Problem: The chances of someone having a genetic stigma is %. Assume a couple with children. If both parent have a stigma, the chances of each child having it is %. If just one parent has a genetic stigma, the chances of each child having it is %. a) What is the probability of both children having the stigma, assuming that only one parent has it? b) What is the probability of both children having the stigma, if we know nothing about the parents? My assumption: I think that in both a) and b) we deal with independent events (since the birth of a child doesnt influence the chances of the next one having the stigma). So i think that for a) its and for b) its Is this assumption correct?",1 2 50 2 0.02 * 0.02 0.01 * 0.01,['probability']
5,Expected number of cards drawn to get 4 consecutive spades,Expected number of cards drawn to get 4 consecutive spades,,"Here's a question from my probability textbook: A person draws cards one by one from a pack and replaces them till he has drawn four consecutive spades. How many cards may he expect to draw? I ended up solving the equation $$e = {3\over4}(e + 1) + {3\over{4^2}}(e + 2) + {3\over{4^3}}(e + 3) + {1\over{4^4}}4,$$ getting $e = 82$ . However, the answer in the back of my book is $340$ . And the answer following the equations given here: The expected number of draws until four successive cards of the same suit appear $\mu_{3}=1+\frac{3}{4}\mu_{1}$ $\mu_{2}=1+\frac{3}{4}\mu_{1}+\frac{1}{4}\mu_{3}$ $\mu_{1}=1+\frac{3}{4}\mu_{1}+\frac{1}{4}\mu_{2}$ $\mu_{0}=1+\mu_{1}$ Gets us the answer $\mu_0 = 85$ according to Wolfram Alpha: https://www.wolframalpha.com/input/?i=d+%3D+1+%2B+%283%2F4%29b%2C+c+%3D+1+%2B+%283%2F4%29b+%2B+%281%2F4%29d%2C+b+%3D+1+%2B+%283%2F4%29b+%2B+%281%2F4%29c%2C+a+%3D+1+%2B+b So there's three possible answers of $82$ , $340$ , $85$ . Which one is correct? EDIT: I see the error of my ways, my equation is missing a term. It should be $$e = {3\over4}(e + 1) + {3\over{4^2}}(e + 2) + {3\over{4^3}}(e + 3) + {3\over{4^4}}(e + 4) + {1\over{4^4}}4,$$ getting $e = 340$ as desired.","Here's a question from my probability textbook: A person draws cards one by one from a pack and replaces them till he has drawn four consecutive spades. How many cards may he expect to draw? I ended up solving the equation getting . However, the answer in the back of my book is . And the answer following the equations given here: The expected number of draws until four successive cards of the same suit appear Gets us the answer according to Wolfram Alpha: https://www.wolframalpha.com/input/?i=d+%3D+1+%2B+%283%2F4%29b%2C+c+%3D+1+%2B+%283%2F4%29b+%2B+%281%2F4%29d%2C+b+%3D+1+%2B+%283%2F4%29b+%2B+%281%2F4%29c%2C+a+%3D+1+%2B+b So there's three possible answers of , , . Which one is correct? EDIT: I see the error of my ways, my equation is missing a term. It should be getting as desired.","e = {3\over4}(e + 1) + {3\over{4^2}}(e + 2) + {3\over{4^3}}(e + 3) + {1\over{4^4}}4, e = 82 340 \mu_{3}=1+\frac{3}{4}\mu_{1} \mu_{2}=1+\frac{3}{4}\mu_{1}+\frac{1}{4}\mu_{3} \mu_{1}=1+\frac{3}{4}\mu_{1}+\frac{1}{4}\mu_{2} \mu_{0}=1+\mu_{1} \mu_0 = 85 82 340 85 e = {3\over4}(e + 1) + {3\over{4^2}}(e + 2) + {3\over{4^3}}(e + 3) + {3\over{4^4}}(e + 4) + {1\over{4^4}}4, e = 340","['probability', 'combinatorics', 'expected-value']"
6,A characterization of almost sure convergence,A characterization of almost sure convergence,,"Suppose we have a sequence of positive random variables $X_1,X_2,...,X$ . I am trying to prove a characterization of almost sure convergence. It states that $X_n \rightarrow X$ almost surely iff for every $\epsilon >0$ , $\lim_{n \rightarrow \infty} P[\sup_{k \ge n} \frac{X_k}{X} > 1+ \epsilon]=0$ and $\lim_{n \rightarrow \infty} P[\sup_{k \ge n} \frac{X}{X_k} > 1+ \epsilon]=0$ . If I assume almost sure convergence, then the implication is easy but I am not being able to prove the other way round.","Suppose we have a sequence of positive random variables . I am trying to prove a characterization of almost sure convergence. It states that almost surely iff for every , and . If I assume almost sure convergence, then the implication is easy but I am not being able to prove the other way round.","X_1,X_2,...,X X_n \rightarrow X \epsilon >0 \lim_{n \rightarrow \infty} P[\sup_{k \ge n} \frac{X_k}{X} > 1+ \epsilon]=0 \lim_{n \rightarrow \infty} P[\sup_{k \ge n} \frac{X}{X_k} > 1+ \epsilon]=0","['probability', 'sequences-and-series', 'probability-theory', 'measure-theory', 'convergence-divergence']"
7,Probability of a flush given that the first two cards are of the same suit.,Probability of a flush given that the first two cards are of the same suit.,,"there. I'm looking to write probability of a flush (suppose it contains royal flush, straight flush, etc.) given that the first two cards are of the same suit. Here is the solution, let $F$ be the event that a flush appears, $T$ be the event that the first two are of the same suit. $$ \begin{aligned} \mathbb{P}(F|T) &=\frac{\mathbb{P}(T|F)\mathbb{P}(F)}{\mathbb{P}(T)} \\ &= \frac{\mathbb{P}(F)}{\mathbb{P}(T)} \\ &= \frac{{4\choose 1} {13\choose 5}/{52 \choose 5}}{{4 \choose1} {13 \choose 2}{50 \choose 3}/{52 \choose 5}} \end{aligned} $$ I agree with all the above calculation except the last probability $\mathbb{P} (T)$ . I think the correct $\mathbb{P}(T)$ should be $$\frac{{4 \choose 1}{13\choose 2}}{{52 \choose 2}}$$ because the probability that there are two cards of the same suit in a hand is not equal to the probability that the first two cards are of the same suit. Am I right or wrong? Any help is greatly appreciated.","there. I'm looking to write probability of a flush (suppose it contains royal flush, straight flush, etc.) given that the first two cards are of the same suit. Here is the solution, let be the event that a flush appears, be the event that the first two are of the same suit. I agree with all the above calculation except the last probability . I think the correct should be because the probability that there are two cards of the same suit in a hand is not equal to the probability that the first two cards are of the same suit. Am I right or wrong? Any help is greatly appreciated.","F T 
\begin{aligned}
\mathbb{P}(F|T) &=\frac{\mathbb{P}(T|F)\mathbb{P}(F)}{\mathbb{P}(T)} \\
&= \frac{\mathbb{P}(F)}{\mathbb{P}(T)} \\
&= \frac{{4\choose 1} {13\choose 5}/{52 \choose 5}}{{4 \choose1} {13 \choose 2}{50 \choose 3}/{52 \choose 5}}
\end{aligned}
 \mathbb{P} (T) \mathbb{P}(T) \frac{{4 \choose 1}{13\choose 2}}{{52 \choose 2}}","['probability', 'combinatorics', 'probability-theory', 'poker']"
8,Moment Generating Function (MGF) of Hypergeometric Distribution is No Greater Than MGF of Binomial Distribution with the Same Mean,Moment Generating Function (MGF) of Hypergeometric Distribution is No Greater Than MGF of Binomial Distribution with the Same Mean,,"The Setup Consider a hypergeometric distribution $X$ with parameters $N, n, m,$ i.e. $$\mathbb{P}[X = k] = \frac{{m \choose k} {N-m \choose n-k}}{{N \choose n}},$$ for $k$ running from $0$ to $\min\{n,m\}.$ The mean $\mathbb{E}[X]$ is $\frac{mn}{N}.$ Let $Y$ be a $\mathsf{Bi}(m,n/N)$ distribution, i.e. $$\mathbb{P}[Y = k] = {m \choose k}\left(\frac{n}{N}\right)^k \left(1-\frac{n}{N} \right)^{m-k}.$$ $Y$ also has mean $\frac{mn}{N}.$ (In $X,$ the roles of $m$ and $n$ are interchangeable, so the following should hold for $\mathsf{Bi}(n,m/N)$ also.) In Janson, Łuczak, and Ruciński's Random Graphs (JLR), the proof of Theorem 2.10 (page 29 in my edition) is largely left as an exercise. It depends on the following fact: The Question $$(1) \ \ \forall u \in \mathbb{R}, \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}].$$ That is, the MGF of $X$ is less than or equal to the MGF of $Y.$ Intuitively, this makes sense, since $Y$ seems more likely than $X$ to be far from its mean. How can we prove this? What I've Tried JLR references Hoeffding 1963 for this result. I went through the parts of that paper that seemed most relevant to this problem--""Sampling from a Finite Population"" and some of ""Sums of Dependent Random Variables"", but I was unable to find anything that proves $$\forall u \in \mathbb{R}, \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}].$$ (I skimmed the rest of the paper as well.) One more remark about Hoeffding: when this paper talks about $\mathbb{E}[e^{cZ}]$ it seems to usually require $c>0$ , whereas our desired result holds for all $u \in \mathbb{R}.$ I have tried writing out explicit expressions for these MGFs: $$\mathbb{E}[e^{uX}] = \sum_{k} \frac{{m \choose k} {N-m \choose n-k}}{{N \choose n}} e^{uk}$$ and $$\mathbb{E}[e^{uY}] = \sum_{k} {m \choose k} \left(\frac{n}{N} \right)^k \left(1-\frac{n}{N}\right)^{m-k} e^{uk}.$$ These summands share factors of ${m \choose k}$ , and $e^{uk} > 0,$ so one might hope to prove $$(2) \ \ \forall k \leq m,n \leq N, \ \ \frac{{N - m \choose n-k}}{{N \choose n}}  \leq \left(\frac{n}{N} \right)^k \left(1 - \frac{n}{N} \right)^{m-k}.$$ $(2)$ , if true, would prove $(1), \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}].$ I currently do not believe this inequality is true, based on some numbers I put into Maple (but I may have made an error there). In any case, although this inequality would be sufficient, it is not necessary for proving (1). I also tried expanding $e^{uX} = 1 + uX + \frac{u^2 X^2}{2} + \cdots,$ and similarly for $e^{uY}.$ For $u \geq 0,$ (probably using Fubini-Tonelli somewhere), it would suffice to prove $$(3) \ \ \forall K \in \mathbb{N}, \ \ \mathbb{E}[X^K] \leq \mathbb{E}[Y^K].$$ I do not know how to do this (although it seems true), and in any case it wouldn't directly prove (1) when $u < 0.$","The Setup Consider a hypergeometric distribution with parameters i.e. for running from to The mean is Let be a distribution, i.e. also has mean (In the roles of and are interchangeable, so the following should hold for also.) In Janson, Łuczak, and Ruciński's Random Graphs (JLR), the proof of Theorem 2.10 (page 29 in my edition) is largely left as an exercise. It depends on the following fact: The Question That is, the MGF of is less than or equal to the MGF of Intuitively, this makes sense, since seems more likely than to be far from its mean. How can we prove this? What I've Tried JLR references Hoeffding 1963 for this result. I went through the parts of that paper that seemed most relevant to this problem--""Sampling from a Finite Population"" and some of ""Sums of Dependent Random Variables"", but I was unable to find anything that proves (I skimmed the rest of the paper as well.) One more remark about Hoeffding: when this paper talks about it seems to usually require , whereas our desired result holds for all I have tried writing out explicit expressions for these MGFs: and These summands share factors of , and so one might hope to prove , if true, would prove I currently do not believe this inequality is true, based on some numbers I put into Maple (but I may have made an error there). In any case, although this inequality would be sufficient, it is not necessary for proving (1). I also tried expanding and similarly for For (probably using Fubini-Tonelli somewhere), it would suffice to prove I do not know how to do this (although it seems true), and in any case it wouldn't directly prove (1) when","X N, n, m, \mathbb{P}[X = k] = \frac{{m \choose k} {N-m \choose n-k}}{{N \choose n}}, k 0 \min\{n,m\}. \mathbb{E}[X] \frac{mn}{N}. Y \mathsf{Bi}(m,n/N) \mathbb{P}[Y = k] = {m \choose k}\left(\frac{n}{N}\right)^k \left(1-\frac{n}{N} \right)^{m-k}. Y \frac{mn}{N}. X, m n \mathsf{Bi}(n,m/N) (1) \ \ \forall u \in \mathbb{R}, \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}]. X Y. Y X \forall u \in \mathbb{R}, \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}]. \mathbb{E}[e^{cZ}] c>0 u \in \mathbb{R}. \mathbb{E}[e^{uX}] = \sum_{k} \frac{{m \choose k} {N-m \choose n-k}}{{N \choose n}} e^{uk} \mathbb{E}[e^{uY}] = \sum_{k} {m \choose k} \left(\frac{n}{N} \right)^k \left(1-\frac{n}{N}\right)^{m-k} e^{uk}. {m \choose k} e^{uk} > 0, (2) \ \ \forall k \leq m,n \leq N, \ \ \frac{{N - m \choose n-k}}{{N \choose n}}  \leq \left(\frac{n}{N} \right)^k \left(1 - \frac{n}{N} \right)^{m-k}. (2) (1), \mathbb{E}[e^{uX}] \leq \mathbb{E}[e^{uY}]. e^{uX} = 1 + uX + \frac{u^2 X^2}{2} + \cdots, e^{uY}. u \geq 0, (3) \ \ \forall K \in \mathbb{N}, \ \ \mathbb{E}[X^K] \leq \mathbb{E}[Y^K]. u < 0.","['probability', 'combinatorics', 'probability-distributions', 'hypergeometric-function', 'probabilistic-method']"
9,Expected number of rolls in a game of snakes and ladders,Expected number of rolls in a game of snakes and ladders,,"You are playing a game of snakes and ladders. You start at square $1$ , and each turn you roll a $6$ sided dice and move the corresponding number of squares. When you reach at least square $25$ , you stop. There is also a snake which connects squares $5$ and $20$ (i.e. if you land on $20$ , you immediately move down to $5$ ), and there is a ladder from $10$ to $15$ (so if you land on 10, you immediately move up to $15$ ). What is the expected number of rolls until you finish the game? [ Source ] If we think about the game without any snakes or ladders, you need to move at least $24$ squares. The expected number you roll on each throw is $3.5$ . However, how can you calculate your expected stopping value, when it is likely to be past $25$ ? I cannot see how to factor in the probability of hitting the snake or ladder.","You are playing a game of snakes and ladders. You start at square , and each turn you roll a sided dice and move the corresponding number of squares. When you reach at least square , you stop. There is also a snake which connects squares and (i.e. if you land on , you immediately move down to ), and there is a ladder from to (so if you land on 10, you immediately move up to ). What is the expected number of rolls until you finish the game? [ Source ] If we think about the game without any snakes or ladders, you need to move at least squares. The expected number you roll on each throw is . However, how can you calculate your expected stopping value, when it is likely to be past ? I cannot see how to factor in the probability of hitting the snake or ladder.",1 6 25 5 20 20 5 10 15 15 24 3.5 25,"['probability', 'probability-theory', 'expected-value', 'dice']"
10,Almost sure convergence of random variables with continuous densities implies $L^1$ convergence of densities?,Almost sure convergence of random variables with continuous densities implies  convergence of densities?,L^1,Suppose we have a sequence of random variables $f_n:\Omega\rightarrow\mathbb{R}$ converging almost surely to some random variable $f:\Omega\rightarrow\mathbb{R}$ . Suppose we know that the law of each $f_n$ has a continuous density function $\phi_n:\mathbb{R}\rightarrow\mathbb{R}$ and $f$ has a continuous density $\phi:\mathbb{R}\rightarrow\mathbb{R}$ . I know that almost sure convergence of the random variables implies weak convergence of the laws. Can we use the extra assumptions here to conclude that we have a stronger form of convergence? For example it seems like we should have $\|\phi_n-\phi\|_{L^1}\rightarrow 0$ .,Suppose we have a sequence of random variables converging almost surely to some random variable . Suppose we know that the law of each has a continuous density function and has a continuous density . I know that almost sure convergence of the random variables implies weak convergence of the laws. Can we use the extra assumptions here to conclude that we have a stronger form of convergence? For example it seems like we should have .,f_n:\Omega\rightarrow\mathbb{R} f:\Omega\rightarrow\mathbb{R} f_n \phi_n:\mathbb{R}\rightarrow\mathbb{R} f \phi:\mathbb{R}\rightarrow\mathbb{R} \|\phi_n-\phi\|_{L^1}\rightarrow 0,"['probability', 'functional-analysis', 'probability-theory', 'measure-theory']"
11,Finding the correlation between the maximum and minimum of two uniform random variables,Finding the correlation between the maximum and minimum of two uniform random variables,,"Suppose $X_1, X_2 \stackrel{\mathrm{iid}}{\sim}$ Uniform $(-1, 2)$ . I am interested in finding Corr $(Y, Z)$ , where $Y = \min\{X_1, X_2\}$ and $Z = \max\{X_1, X_2\}$ . Now, I can solve the problem following the traditional methods i.e. by first finding the respective probability density functions and so on. However, this process is very long and tedious. After a bit of searching online, I came across this post , where the question is very similar to mine but I am more interested in the answer, which gives the following three ""short-cuts"" for $X_1, X_2 \stackrel{\mathrm{iid}}{\sim}$ Uniform $(0, 1)$ and $Y$ and $Z$ defined as above: $\mathbb{E}[Y] + \mathbb{E}[Z] = 1$ Var $(Y)$ = Var $(Z)$ $\mathbb{E}[YZ] = \frac 1 4$ I am unable to see how these relationships are true. Moreover, do such relationships hold in general (possibly just simply requiring to change the values on the RHS of 1 and 3 accordingly) or are they only true for standard iid uniform random variables? Any intuitive explanations will be greatly appreciated! :)","Suppose Uniform . I am interested in finding Corr , where and . Now, I can solve the problem following the traditional methods i.e. by first finding the respective probability density functions and so on. However, this process is very long and tedious. After a bit of searching online, I came across this post , where the question is very similar to mine but I am more interested in the answer, which gives the following three ""short-cuts"" for Uniform and and defined as above: Var = Var I am unable to see how these relationships are true. Moreover, do such relationships hold in general (possibly just simply requiring to change the values on the RHS of 1 and 3 accordingly) or are they only true for standard iid uniform random variables? Any intuitive explanations will be greatly appreciated! :)","X_1, X_2 \stackrel{\mathrm{iid}}{\sim} (-1, 2) (Y, Z) Y = \min\{X_1, X_2\} Z = \max\{X_1, X_2\} X_1, X_2 \stackrel{\mathrm{iid}}{\sim} (0, 1) Y Z \mathbb{E}[Y] + \mathbb{E}[Z] = 1 (Y) (Z) \mathbb{E}[YZ] = \frac 1 4","['probability', 'probability-distributions', 'uniform-distribution', 'correlation']"
12,Chain Rule for Conditional Probability?,Chain Rule for Conditional Probability?,,"So while the most basic form of the product rule for probability is $P(A \cap B) = P(A) P(B|A)$ , I heard that for any events $A, B, C,$ the following also holds: $$P(A \cap B | C) = P(A|C) P(B| A \cap C). $$ I've been trying to derive this formula and/or find the general form of this for $n$ events, but so far haven't had any success. Could someone help me see why $$P(A \cap B | C) = P(A|C) P(B| A \cap C)$$ is true (how we get from $P(A \cap B) = P(A) P(B|A)$ to this) and if there's a more general formula for this?","So while the most basic form of the product rule for probability is , I heard that for any events the following also holds: I've been trying to derive this formula and/or find the general form of this for events, but so far haven't had any success. Could someone help me see why is true (how we get from to this) and if there's a more general formula for this?","P(A \cap B) = P(A) P(B|A) A, B, C, P(A \cap B | C) = P(A|C) P(B| A \cap C).  n P(A \cap B | C) = P(A|C) P(B| A \cap C) P(A \cap B) = P(A) P(B|A)","['probability', 'probability-theory', 'conditional-probability']"
13,Which Deck wins the most?,Which Deck wins the most?,,"I have two decks of cards, both shuffled randomly and placed face-down. Deck A has 40 cards. 10 are red, while the remaining 30 are black. Deck B has 80 cards. 20 are red, while the remaining 60 are black. I am asked to pick one deck and draw 20 cards from the top of it, scoring 1 point for each red card I draw. Which deck should I choose? Edit: The question is: ""Which Deck, A or B, would win in a game where you're drawing 20 cards randomly?"" Said another way, which deck, A or B would win in a head to head game? When I worked it out, it seems that both Decks have an expected value of 5 points. So, if I did the work right, then on average, there should not be any advantage to picking either deck. To confirm this, I ran a monte carlo simulation and it seems that my long running average has A with a slight advantage over deck B. I wrote this up in R to check it out. BDeckWins <- 0 ADeckWins <- 0 ties <- 0 trials <- 100000 deckApts <- vector(mode = 'numeric', length = trials) deckBpts <- vector(mode = 'numeric', length = trials) for(i in 1:trials) {   deckA <- rep(0, 40) # make all blacks   deckA[sample(1:40,10)] <- 1 #randomly pick 10 reds   handA <- sample(deckA, 20)   pntsA <- sum(handA)   deckApts[i] <- pntsA   #print(stringr::str_c(""Deck A points:"", pntsA))      deckB <- rep(0, 80) # make all blacks   deckB[sample(1:80,20)] <- 1 #randomly pick 20 reds   handB <- sample(deckB, 20)   pntsB <- sum(handB)   deckBpts[i] <- pntsB   #print(stringr::str_c(""Deck B points:"", pntsB))      if(pntsB != pntsA)   {     if(pntsB > pntsA)     {       #print(""Deck B wins"")       BDeckWins <- BDeckWins + 1     }     else     {       #print(""Deck A wins"")       ADeckWins <- ADeckWins + 1     }   }   else   {     #print(""Tie, no winner"")     ties <- ties + 1   } }  mean(deckApts) mean(deckBpts)  print(ADeckWins) print(BDeckWins) print(ties)  print(ADeckWins + BDeckWins + ties) The code to calculate the expected values is as follows: ev_a <- vector(mode = 'numeric', length = 10) for(i in 0:10) {     ev_a[i+1] <- i*(choose(10, i)*choose(30, 20 - i) / choose(40,20)) } sum(ev_a)  ev_b <- vector(mode = 'numeric', length = 20) for(i in 0:20) {   ev_b[i+1] <- i*(choose(20, i)*choose(60, 20 - i) / choose(80,20)) } sum(ev_b) So...I checked that the simulation agrees that 5 is the long run expected value. I don't know what I am not seeing.","I have two decks of cards, both shuffled randomly and placed face-down. Deck A has 40 cards. 10 are red, while the remaining 30 are black. Deck B has 80 cards. 20 are red, while the remaining 60 are black. I am asked to pick one deck and draw 20 cards from the top of it, scoring 1 point for each red card I draw. Which deck should I choose? Edit: The question is: ""Which Deck, A or B, would win in a game where you're drawing 20 cards randomly?"" Said another way, which deck, A or B would win in a head to head game? When I worked it out, it seems that both Decks have an expected value of 5 points. So, if I did the work right, then on average, there should not be any advantage to picking either deck. To confirm this, I ran a monte carlo simulation and it seems that my long running average has A with a slight advantage over deck B. I wrote this up in R to check it out. BDeckWins <- 0 ADeckWins <- 0 ties <- 0 trials <- 100000 deckApts <- vector(mode = 'numeric', length = trials) deckBpts <- vector(mode = 'numeric', length = trials) for(i in 1:trials) {   deckA <- rep(0, 40) # make all blacks   deckA[sample(1:40,10)] <- 1 #randomly pick 10 reds   handA <- sample(deckA, 20)   pntsA <- sum(handA)   deckApts[i] <- pntsA   #print(stringr::str_c(""Deck A points:"", pntsA))      deckB <- rep(0, 80) # make all blacks   deckB[sample(1:80,20)] <- 1 #randomly pick 20 reds   handB <- sample(deckB, 20)   pntsB <- sum(handB)   deckBpts[i] <- pntsB   #print(stringr::str_c(""Deck B points:"", pntsB))      if(pntsB != pntsA)   {     if(pntsB > pntsA)     {       #print(""Deck B wins"")       BDeckWins <- BDeckWins + 1     }     else     {       #print(""Deck A wins"")       ADeckWins <- ADeckWins + 1     }   }   else   {     #print(""Tie, no winner"")     ties <- ties + 1   } }  mean(deckApts) mean(deckBpts)  print(ADeckWins) print(BDeckWins) print(ties)  print(ADeckWins + BDeckWins + ties) The code to calculate the expected values is as follows: ev_a <- vector(mode = 'numeric', length = 10) for(i in 0:10) {     ev_a[i+1] <- i*(choose(10, i)*choose(30, 20 - i) / choose(40,20)) } sum(ev_a)  ev_b <- vector(mode = 'numeric', length = 20) for(i in 0:20) {   ev_b[i+1] <- i*(choose(20, i)*choose(60, 20 - i) / choose(80,20)) } sum(ev_b) So...I checked that the simulation agrees that 5 is the long run expected value. I don't know what I am not seeing.",,"['probability', 'expected-value', 'card-games']"
14,"What is the variance of the product of a Bernoulli (0,1) and a normal random variable?","What is the variance of the product of a Bernoulli (0,1) and a normal random variable?",,"I want to find the variance of the product of a Bernoulli random variable and a normal random variable. I only have an introductory probability background...and here is what I would do normally. If I were dealing with the product of a discrete random variable, I would just list all the cases and find their probabilities and get $E[X], E[X^2],$ and $Var(X)$ from that. If I were dealing with a continuous random variable, I would find the CDF, differentiate to get the pdf, and find $E[X], E[X^2],$ and $Var(X)$ from that. But I'm not sure where to start with this case, where I have a piecewise continuous pdf. The answer to this question seems very relevant, except how would I work with a piecewise cdf like this? I appreciate any insight!","I want to find the variance of the product of a Bernoulli random variable and a normal random variable. I only have an introductory probability background...and here is what I would do normally. If I were dealing with the product of a discrete random variable, I would just list all the cases and find their probabilities and get and from that. If I were dealing with a continuous random variable, I would find the CDF, differentiate to get the pdf, and find and from that. But I'm not sure where to start with this case, where I have a piecewise continuous pdf. The answer to this question seems very relevant, except how would I work with a piecewise cdf like this? I appreciate any insight!","E[X], E[X^2], Var(X) E[X], E[X^2], Var(X)","['probability', 'normal-distribution', 'expected-value', 'variance']"
15,We can convert one apple to mango or vice versa in one move with equal probability. Expected moves by which only one kind of fruit will be left?,We can convert one apple to mango or vice versa in one move with equal probability. Expected moves by which only one kind of fruit will be left?,,"Given $a$ apples and $b$ mangoes, where $a$ and $b$ can be non negative numbers, we can convert one apple to mango or vice versa in one move. What is the expected number of moves after which only one kind of fruit will be left, i.e, one of the following condition satisfies: #apples = $a$ + $b$ and #mangoes = 0 #apples = 0 and #mangoes = $a$ + $b$ My attempt: I thought of recurrence relation $E(a,b) = 1 + \tfrac12 E(a-1,b+1) + \tfrac12 E(a+1,b-1)$ (thanks @henry for correcting it) but could not moved further from this. Also, I thought that expected number of moves will only depend on max( $a$ , $b$ ). I am not sure but I have strong intuition that this is correct. Question Link: https://my.newtonschool.co/playground/code/crm33y2jcf/","Given apples and mangoes, where and can be non negative numbers, we can convert one apple to mango or vice versa in one move. What is the expected number of moves after which only one kind of fruit will be left, i.e, one of the following condition satisfies: #apples = + and #mangoes = 0 #apples = 0 and #mangoes = + My attempt: I thought of recurrence relation (thanks @henry for correcting it) but could not moved further from this. Also, I thought that expected number of moves will only depend on max( , ). I am not sure but I have strong intuition that this is correct. Question Link: https://my.newtonschool.co/playground/code/crm33y2jcf/","a b a b a b a b E(a,b) = 1 + \tfrac12 E(a-1,b+1) + \tfrac12 E(a+1,b-1) a b","['probability', 'expected-value']"
16,Coin tossing - what's more probable?,Coin tossing - what's more probable?,,"I am solving the following probability exercise. The solution I have found is very counter intuitive and I feel It is wrong, but I can't seem to understand why. A fair coin is tossed twice, you have to decide wheter it is more likely that two heads showed up given that: 1) at least one toss is head, 2) the second toss was head. Solution Let $A$ be the event ""the first toss is head"" and let $B$ be the event ""the second toss is head"". For case 1,: $$ P(A \cap B \vert A \cup B) = \frac{P(A \cap B \cap (A \cup B))}{P(A \cup B)} = \frac{P(A\cap B)}{P(A) + P(B) - P(A \cap B)} = \frac{1/4}{3/4} = 1/3$$ For case 2: $$ P(A \cap B \vert B) = \frac{P(A\cap B)}{P(B)} = \frac{1/4}{1/2} = \frac{1}{2}$$ Is this right? I feel like case $1$ should be more probable, given that at least may mean there are already two heads? Can someone shed some light?","I am solving the following probability exercise. The solution I have found is very counter intuitive and I feel It is wrong, but I can't seem to understand why. A fair coin is tossed twice, you have to decide wheter it is more likely that two heads showed up given that: 1) at least one toss is head, 2) the second toss was head. Solution Let be the event ""the first toss is head"" and let be the event ""the second toss is head"". For case 1,: For case 2: Is this right? I feel like case should be more probable, given that at least may mean there are already two heads? Can someone shed some light?",A B  P(A \cap B \vert A \cup B) = \frac{P(A \cap B \cap (A \cup B))}{P(A \cup B)} = \frac{P(A\cap B)}{P(A) + P(B) - P(A \cap B)} = \frac{1/4}{3/4} = 1/3  P(A \cap B \vert B) = \frac{P(A\cap B)}{P(B)} = \frac{1/4}{1/2} = \frac{1}{2} 1,['probability']
17,"Given $2^k$ random binary sequences of length $k$, how many are expected to be distinct?","Given  random binary sequences of length , how many are expected to be distinct?",2^k k,"For example, say you get a uniformly random batch of $256$ sequences of $8$ bits each, and count the number of distinct sequences (i.e. discard duplicates then count), and repeat this experiment indefinitely. In the limit, what's the ratio of distinct sequences to total sequences? Empirically, irrespective of choice of $k$ , this seems to be converging to something around $0.63214$ , so as a pure guess, I'm thinking maybe $1-\frac{1}{e}$ , but I'm sure someone on here will immediately know the answer to this one.","For example, say you get a uniformly random batch of sequences of bits each, and count the number of distinct sequences (i.e. discard duplicates then count), and repeat this experiment indefinitely. In the limit, what's the ratio of distinct sequences to total sequences? Empirically, irrespective of choice of , this seems to be converging to something around , so as a pure guess, I'm thinking maybe , but I'm sure someone on here will immediately know the answer to this one.",256 8 k 0.63214 1-\frac{1}{e},"['probability', 'probability-distributions', 'random']"
18,Discrepancy of answers between differing computations of $E[e^{W_s}e^{W_t}]$ ($W_t$ being the Wiener process),Discrepancy of answers between differing computations of  ( being the Wiener process),E[e^{W_s}e^{W_t}] W_t,"I was looking at another thread , and the following two distinct solutions to $E[e^{W_s}e^{W_t}]$ (assume that $W_0 = 0$ and $t>s$ ) were given, with both giving identical answers (I have slightly re-written the notation in the second solution for the reader's sake): 1. by direct computation I find: $$ \begin{array} \mathbb{E}[e^{W_t}e^{W_s}] &= \mathbb{E}[e^{W_t - W_s} e^{2W_s}] \\  &= \mathbb{E}[e^{W_t - W_s}]\mathbb{E}[e^{2W_s}] \\  &= e^{\frac12(t-s)} e^{2s} \\  &= e^{\frac12 t + \frac32 s}. \end{array} $$ Given the facts that for $X_t = e^{W_t}$ , $(a)$ $e^{-\frac t2}X_t$ is a martingale and $(b)$ For any constant $\lambda \in\mathbb R$ , the process $Y_t= e^{\lambda W_t - \frac12 \lambda^2t}$ is a martingale, we have \begin{align} E[e^{W_s}e^{W_t}] &= e^{\frac{t}{2}}E[e^{W_s}e^{W_t - \frac{t}{2}}] \\ &= e^{\frac{t}{2}}E[e^{W_s}E[e^{W_t - \frac{t}{2}}|\mathcal{F}_s]] \quad \text{$W_s$ is $\mathcal{F}_s$-mesurable and thanks to a)}\\  &= e^{\frac{t}{2}}E[e^{2W_s - \frac{s}{2}}] \\ &= e^{\frac{t+3s}{2}}E[e^{2W_s - 2s}] \quad \text{thanks to b) with $\lambda=2$}\\ &= e^{\frac{t+3s}{2}}\\ \end{align} On the other hand, I took quite a different approach, getting a different answer (note that I write $\exp(x)$ instead of $e^x$ ): Let $Z \sim N(0,1)$ . Then its moment generating function is, \begin{align*} E[\exp{(\lambda Z)}] &= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} \exp\left({\lambda z})\exp({-z^2/2}\right)dz \\ &= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty}\exp\left({(-z^2 + 2\lambda z)/{2}}\right)dz \\ &= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty}\exp\left({{-(z + \lambda)^2}/{2} + {\lambda^2}/{2}}\right)dz \\ &= \exp\left({\frac{\lambda^2}{2}}\right)\int_{-\infty}^{\infty}\frac{\exp\left({{-(z + \lambda)^2}/2}\right)}{\sqrt{2 \pi}}dz . \end{align*} Since the function inside the last integral is precisely the pdf of $N(\lambda , 1)$ , its integral equals 1. Therefore we have, $$E[\exp{(\lambda Z)}] = \exp\left({\frac{\lambda^2}{2}}\right).$$ Now, \begin{align*} E[\exp\left({W_s}\right)\exp\left({W_t}\right)] &= E[\exp\left({W_s + W_t}\right)] \\ &= E[\exp\left({(\sqrt{s} + \sqrt{t})Z}\right)] \text{ since $W_t \sim N(0,t)$}\\ &= \exp\left({\frac{(\sqrt{s} + \sqrt{t})^2}{2}}\right) \\ &= \exp\left( \frac{s + t + 2\sqrt{st}}{2} \right). \\ \end{align*} Since $t > s$ , we can write $t = a s$ for some $a > 1$ . Hence, \begin{align*} E[\exp\left({W_s}\right)\exp\left({W_t}\right)] &= \exp\left( \frac{s + t + 2\sqrt{s(as)}}{2} \right) = \exp\left( \frac{s + t + 2s\sqrt{a}}{2} \right) \\ &> \exp\left( \frac{s + t + 2s \cdot \sqrt{1}}{2} \right) = \exp\left( \frac{t + 3s}{2} \right), \end{align*} and hence the discrepancy is clear (with the two answers being equal only if $s = t$ ). Naturally, my question is where my mistake is. Thanks!","I was looking at another thread , and the following two distinct solutions to (assume that and ) were given, with both giving identical answers (I have slightly re-written the notation in the second solution for the reader's sake): 1. by direct computation I find: Given the facts that for , is a martingale and For any constant , the process is a martingale, we have On the other hand, I took quite a different approach, getting a different answer (note that I write instead of ): Let . Then its moment generating function is, Since the function inside the last integral is precisely the pdf of , its integral equals 1. Therefore we have, Now, Since , we can write for some . Hence, and hence the discrepancy is clear (with the two answers being equal only if ). Naturally, my question is where my mistake is. Thanks!","E[e^{W_s}e^{W_t}] W_0 = 0 t>s 
\begin{array}
\mathbb{E}[e^{W_t}e^{W_s}] &= \mathbb{E}[e^{W_t - W_s} e^{2W_s}] \\
 &= \mathbb{E}[e^{W_t - W_s}]\mathbb{E}[e^{2W_s}] \\
 &= e^{\frac12(t-s)} e^{2s} \\
 &= e^{\frac12 t + \frac32 s}.
\end{array}
 X_t = e^{W_t} (a) e^{-\frac t2}X_t (b) \lambda \in\mathbb R Y_t= e^{\lambda W_t - \frac12 \lambda^2t} \begin{align}
E[e^{W_s}e^{W_t}] &= e^{\frac{t}{2}}E[e^{W_s}e^{W_t - \frac{t}{2}}] \\
&= e^{\frac{t}{2}}E[e^{W_s}E[e^{W_t - \frac{t}{2}}|\mathcal{F}_s]]
\quad \text{W_s is \mathcal{F}_s-mesurable and thanks to a)}\\ 
&= e^{\frac{t}{2}}E[e^{2W_s - \frac{s}{2}}] \\
&= e^{\frac{t+3s}{2}}E[e^{2W_s - 2s}] \quad \text{thanks to b) with \lambda=2}\\
&= e^{\frac{t+3s}{2}}\\
\end{align} \exp(x) e^x Z \sim N(0,1) \begin{align*}
E[\exp{(\lambda Z)}] &= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} \exp\left({\lambda z})\exp({-z^2/2}\right)dz \\
&= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty}\exp\left({(-z^2 + 2\lambda z)/{2}}\right)dz \\
&= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty}\exp\left({{-(z + \lambda)^2}/{2} + {\lambda^2}/{2}}\right)dz \\
&= \exp\left({\frac{\lambda^2}{2}}\right)\int_{-\infty}^{\infty}\frac{\exp\left({{-(z + \lambda)^2}/2}\right)}{\sqrt{2 \pi}}dz .
\end{align*} N(\lambda , 1) E[\exp{(\lambda Z)}] = \exp\left({\frac{\lambda^2}{2}}\right). \begin{align*}
E[\exp\left({W_s}\right)\exp\left({W_t}\right)] &= E[\exp\left({W_s + W_t}\right)] \\
&= E[\exp\left({(\sqrt{s} + \sqrt{t})Z}\right)] \text{ since W_t \sim N(0,t)}\\
&= \exp\left({\frac{(\sqrt{s} + \sqrt{t})^2}{2}}\right) \\
&= \exp\left( \frac{s + t + 2\sqrt{st}}{2} \right). \\
\end{align*} t > s t = a s a > 1 \begin{align*}
E[\exp\left({W_s}\right)\exp\left({W_t}\right)] &= \exp\left( \frac{s + t + 2\sqrt{s(as)}}{2} \right) = \exp\left( \frac{s + t + 2s\sqrt{a}}{2} \right) \\
&> \exp\left( \frac{s + t + 2s \cdot \sqrt{1}}{2} \right) = \exp\left( \frac{t + 3s}{2} \right),
\end{align*} s = t","['probability', 'probability-theory', 'stochastic-calculus', 'brownian-motion']"
19,What is the probability that the store is supplied by factory II?,What is the probability that the store is supplied by factory II?,,"Two factories I and II produce phones for brand ABC. Factory I produces 60% of all ABC phones, and factory II produces 40%. 10% of phones produced by factory I are defective, and 20% of those produced by factory II are defective. You know that the store where you buy your phones is supplied by one of the factories, but you do not know which one. You buy two phones, and both are defective. What is the probability that the store is supplied by factory II? My Attempt We are trying to find $\mathbb{P}(\text{factory II}|\text{defect})$ From the problem, we know: $$\mathbb{P}(\text{defect}|\text{factory I})=0.1$$ $$\mathbb{P}(\text{defect}|\text{factory II})=0.2$$ $$\mathbb{P}(\text{factory I})=0.6$$ $$\mathbb{P}(\text{factory II})=0.4$$ Using Bayes rule, we have $$\mathbb{P}(\text{factory II}|\text{defect})=\frac{(0.2)(0.4)}{(0.2)(0.4)+(0.1)(0.6)}=0.5714$$ I was told that this is wrong, but I don't know where I went wrong. Can someone point me in the right direction? Thank you.","Two factories I and II produce phones for brand ABC. Factory I produces 60% of all ABC phones, and factory II produces 40%. 10% of phones produced by factory I are defective, and 20% of those produced by factory II are defective. You know that the store where you buy your phones is supplied by one of the factories, but you do not know which one. You buy two phones, and both are defective. What is the probability that the store is supplied by factory II? My Attempt We are trying to find From the problem, we know: Using Bayes rule, we have I was told that this is wrong, but I don't know where I went wrong. Can someone point me in the right direction? Thank you.",\mathbb{P}(\text{factory II}|\text{defect}) \mathbb{P}(\text{defect}|\text{factory I})=0.1 \mathbb{P}(\text{defect}|\text{factory II})=0.2 \mathbb{P}(\text{factory I})=0.6 \mathbb{P}(\text{factory II})=0.4 \mathbb{P}(\text{factory II}|\text{defect})=\frac{(0.2)(0.4)}{(0.2)(0.4)+(0.1)(0.6)}=0.5714,"['probability', 'conditional-probability', 'bayes-theorem']"
20,Transposition Distance between two permutations.,Transposition Distance between two permutations.,,"I'm working on the following problem. Suppose that $A \subseteq S_n$ is a subset of at least $n!/2$ permutations, and let $A(t)$ be the set of permutations that can be obtained from starting at some element of $A$ , and then applying at most $t$ transpositions. Prove that there is some absolute constant $c > 0$ so that $$A(t) \geq (1-e^{-ct^2/n})n!$$ My first thoughts are that I want to use the Talagrand concentration theorem, but for that I need to write $S_n$ as a product space. Since I can write any permutation $\sigma$ as a product of transpositions, I thought maybe I could think of $S_n$ as the product of $m = \binom{n}{2}$ independent identically distributed random variables taking values either $0$ or $1$ , and a vector of $0$ 's and $1$ 's would correspond to whether or not the indicated transposition was in a minimal representation of $\sigma$ as a product of transpositions. This has some problems however. First of all, I doubt this is well defined since there are several ways we can write $\sigma$ as a product of transpositions. The second problem is that order matters, since $(12)(23)$ and $(23)(12)$ give different permutations. Is there any way I can use Talagrand concentration to approach this problem, probably with a different setup? Does anyone have any thoughts on a different approach?","I'm working on the following problem. Suppose that is a subset of at least permutations, and let be the set of permutations that can be obtained from starting at some element of , and then applying at most transpositions. Prove that there is some absolute constant so that My first thoughts are that I want to use the Talagrand concentration theorem, but for that I need to write as a product space. Since I can write any permutation as a product of transpositions, I thought maybe I could think of as the product of independent identically distributed random variables taking values either or , and a vector of 's and 's would correspond to whether or not the indicated transposition was in a minimal representation of as a product of transpositions. This has some problems however. First of all, I doubt this is well defined since there are several ways we can write as a product of transpositions. The second problem is that order matters, since and give different permutations. Is there any way I can use Talagrand concentration to approach this problem, probably with a different setup? Does anyone have any thoughts on a different approach?",A \subseteq S_n n!/2 A(t) A t c > 0 A(t) \geq (1-e^{-ct^2/n})n! S_n \sigma S_n m = \binom{n}{2} 0 1 0 1 \sigma \sigma (12)(23) (23)(12),"['probability', 'combinatorics', 'probabilistic-method']"
21,Probability of extinction in generation 3 [closed],Probability of extinction in generation 3 [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The branching process has offspring distribution $μ(0) = a, μ(1) = b, μ(2) = c$ and $μ(n) = 0$ , what is the probability that the population is extinct in the 3rd generation, given that it is not extinct in the 2nd generation? How would i solve this? How is it different from finding the probability of extinction in exactly generation 3?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question The branching process has offspring distribution and , what is the probability that the population is extinct in the 3rd generation, given that it is not extinct in the 2nd generation? How would i solve this? How is it different from finding the probability of extinction in exactly generation 3?","μ(0) = a, μ(1) = b, μ(2) = c μ(n) = 0","['probability', 'markov-chains', 'conditional-probability']"
22,Is $X_t=X_{t-1}^{\alpha} + \varepsilon_t$ stationary for $\alpha<1$?,Is  stationary for ?,X_t=X_{t-1}^{\alpha} + \varepsilon_t \alpha<1,"Let { $\varepsilon_t$ } be iid. Then, we have time series defined by $$X_t=cX_{t-1}^{\alpha} + \varepsilon_t,$$ with $0<\alpha<1$ and $c\in\mathbb{R}$ and let $\varepsilon_t$ be non-negative. Is it strictly stationary? If we have $\alpha=1$ we obtain classic AR(1) process, where we need $c<1$ for stationarity. For lower $\alpha$ it seems that $X_t$ is ""smaller"" and should be also stationary, but I have a hard time proving that. Also, do we need then some restriction for $c$ in such case?","Let { } be iid. Then, we have time series defined by with and and let be non-negative. Is it strictly stationary? If we have we obtain classic AR(1) process, where we need for stationarity. For lower it seems that is ""smaller"" and should be also stationary, but I have a hard time proving that. Also, do we need then some restriction for in such case?","\varepsilon_t X_t=cX_{t-1}^{\alpha} + \varepsilon_t, 0<\alpha<1 c\in\mathbb{R} \varepsilon_t \alpha=1 c<1 \alpha X_t c","['probability', 'probability-distributions', 'time-series', 'stationary-processes']"
23,Constructing a Multivariate Probability Distribution Formula,Constructing a Multivariate Probability Distribution Formula,,"Suppose there are three individuals playing a simple game, Player $1$ , Player $2$ , and Player $3$ . In each round of the game, one of the players is uniformly randomly selected to receive the point for that round.  The game ends when any player achieves a score of $10$ points. How can a multivariate probability distribution formula be constructed that would express the probability of each possible combination of the total number of rounds a game will contain, and an arbitrarily chosen player's (i.e., Player $1$ 's) score at the end of the game?  How does this formula change if we introduce the assumption that the arbitrarily chosen player did not win the game? I started by noting that the chosen player has a $\frac{1}{3}$ probability of winning each round.  I think that for a fixed number of rounds $n$ , the formula would be the binomial distribution ${n \choose a} (\frac{1}{3})^a (\frac{2}{3})^{1 - a}$ , where by plugging a possible point score into $a$ one obtains the probability of the chosen player attaining that exact point score, but I'm not sure if this is right or where to go from here.","Suppose there are three individuals playing a simple game, Player , Player , and Player . In each round of the game, one of the players is uniformly randomly selected to receive the point for that round.  The game ends when any player achieves a score of points. How can a multivariate probability distribution formula be constructed that would express the probability of each possible combination of the total number of rounds a game will contain, and an arbitrarily chosen player's (i.e., Player 's) score at the end of the game?  How does this formula change if we introduce the assumption that the arbitrarily chosen player did not win the game? I started by noting that the chosen player has a probability of winning each round.  I think that for a fixed number of rounds , the formula would be the binomial distribution , where by plugging a possible point score into one obtains the probability of the chosen player attaining that exact point score, but I'm not sure if this is right or where to go from here.",1 2 3 10 1 \frac{1}{3} n {n \choose a} (\frac{1}{3})^a (\frac{2}{3})^{1 - a} a,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions', 'random-variables']"
24,"$P(E_i) = 0, \forall i\in I \Leftrightarrow P(\bigcup_{i\in I} E_i) =0$ and $P(E_i) = 1, \forall i\in I \Leftrightarrow P(\bigcap_{i\in I} E_i) =1$",and,"P(E_i) = 0, \forall i\in I \Leftrightarrow P(\bigcup_{i\in I} E_i) =0 P(E_i) = 1, \forall i\in I \Leftrightarrow P(\bigcap_{i\in I} E_i) =1","Prove that $P(E_i) = 0, \forall i\in I \Leftrightarrow P(\bigcup_{i\in I} E_i) =0$ and $P(E_i) = 1, \forall i\in I \Leftrightarrow P(\bigcap_{i\in I} E_i) =1$ , where $I$ is a countable index set. $P$ is a probability measure, and we have generalized Boole's inequality, to begin with: $$0\le P\left(\bigcup_{i=1}^\infty E_i \right) \le \sum_{i=1}^\infty P(E_i)$$ Is the following proof okay? $P(E_i) = 0$ for all $i\in I$ then $P(\cup_{i\in I}E_i)=0$ by Boole's inequality above. If $P(\cup_{i\in I}E_i)=0$ holds, then Boole's inequality is probably of no use. I tried a proof by contradiction. Let's suppose there exists $j\in I$ such that $P(E_j) \neq 0$ . Then $P(\cup_{i\in I}E_i)=0$ is definitely absurd - but how do I put this in mathematical terms? $(\star \star \star)$ In the other case, we have $P(E_i^c) = 0$ for all $i\in I$ , which tells us (with the help of the first part) that $$P\left(\bigcup_{i\in I}E_i^c\right)=0 \implies P\left(\bigcap_{i\in I}E_i\right)^c=0 \implies P\left(\bigcap_{i\in I}E_i\right) = 1$$ and the proof is complete. If everything above sounds fine, I only need help with the line marked $(\star \star \star)$ . Thanks!","Prove that and , where is a countable index set. is a probability measure, and we have generalized Boole's inequality, to begin with: Is the following proof okay? for all then by Boole's inequality above. If holds, then Boole's inequality is probably of no use. I tried a proof by contradiction. Let's suppose there exists such that . Then is definitely absurd - but how do I put this in mathematical terms? In the other case, we have for all , which tells us (with the help of the first part) that and the proof is complete. If everything above sounds fine, I only need help with the line marked . Thanks!","P(E_i) = 0, \forall i\in I \Leftrightarrow P(\bigcup_{i\in I} E_i) =0 P(E_i) = 1, \forall i\in I \Leftrightarrow P(\bigcap_{i\in I} E_i) =1 I P 0\le P\left(\bigcup_{i=1}^\infty E_i \right) \le \sum_{i=1}^\infty P(E_i) P(E_i) = 0 i\in I P(\cup_{i\in I}E_i)=0 P(\cup_{i\in I}E_i)=0 j\in I P(E_j) \neq 0 P(\cup_{i\in I}E_i)=0 (\star \star \star) P(E_i^c) = 0 i\in I P\left(\bigcup_{i\in I}E_i^c\right)=0 \implies P\left(\bigcap_{i\in I}E_i\right)^c=0 \implies P\left(\bigcap_{i\in I}E_i\right) = 1 (\star \star \star)","['probability', 'probability-theory']"
25,Couples are equally likely to have 1 or 2 children. How likely does a randomly chosen person have a sibling?,Couples are equally likely to have 1 or 2 children. How likely does a randomly chosen person have a sibling?,,"Assume that every couple can only have exactly 1 child or two children, with those outcomes being equally likely. Ignore any silly extra factors (e.g. 1 child dying, another being alive). If I choose a human on the face of the earth randomly, what is the probability that they had a sibling? As a follow-up, what would be the general answer if couples had $i$ children with probability $\pi_i$ ? My thought for the simple case is either 1/2 or 2/3, and I can think of compelling reasons for both. Siblings get counted twice, and only-children get counted once, leading to 2/3. A given person's parents were equally likely to give him a sibling or not, leading to 1/2. This kind of problem occurred to me one day. A similar problem occurs to me when I think about divorce rates. (e.g. if the divorce rate is 50%, is the probability a person is divorced 50% or 66.6%?) Any help is appreciated!","Assume that every couple can only have exactly 1 child or two children, with those outcomes being equally likely. Ignore any silly extra factors (e.g. 1 child dying, another being alive). If I choose a human on the face of the earth randomly, what is the probability that they had a sibling? As a follow-up, what would be the general answer if couples had children with probability ? My thought for the simple case is either 1/2 or 2/3, and I can think of compelling reasons for both. Siblings get counted twice, and only-children get counted once, leading to 2/3. A given person's parents were equally likely to give him a sibling or not, leading to 1/2. This kind of problem occurred to me one day. A similar problem occurs to me when I think about divorce rates. (e.g. if the divorce rate is 50%, is the probability a person is divorced 50% or 66.6%?) Any help is appreciated!",i \pi_i,"['probability', 'conditional-probability', 'paradoxes']"
26,Need help understanding formula for probability that something good happens before something bad happens.,Need help understanding formula for probability that something good happens before something bad happens.,,"My book says this. Consider a sequence of independent trials, each of which can be classified as good, bad, or neutral, which happen (on any given trial) with probabilities $p, q,$ and $1 − p − q$ , respectively. (We do not necessarily have $q = 1 − p$ here, although that case is allowed.) Then the probability that something good happens before something bad happens is $p/(p + q)$ . My question is, how did they derive this formula $p/(p+q)$ for probability that something good happens before something bad happens? can someone show me a derivation/explain to me this?","My book says this. Consider a sequence of independent trials, each of which can be classified as good, bad, or neutral, which happen (on any given trial) with probabilities and , respectively. (We do not necessarily have here, although that case is allowed.) Then the probability that something good happens before something bad happens is . My question is, how did they derive this formula for probability that something good happens before something bad happens? can someone show me a derivation/explain to me this?","p, q, 1 − p − q q = 1 − p p/(p + q) p/(p+q)",[]
27,formula for relating number of successes to number of tries,formula for relating number of successes to number of tries,,"Imagine we have a jar of marbles, where there are 10 different colors of marbles in the jar. Let N be the number of marbles drawn in a sample and K be the number of distinct colors in the sample. Let C be the total number of colors in the jar (which is 10 in this example). We know that: K = F(C,N) + chance. Intuitively, the more marbles we draw at a time, the more colors we are likely to obtain, up to the maximum. This strikes me as a binomial. I am looking for a formula to express in more detail how K = F(C,N). An obvious feature is that C is the maximum value. So I figure this is a model where K is an increasing proportion of C as N increases. I already know how to simulate the data, but wish to provide an expression of K depending on C and N. Any suggestions will be appreciated. Simulated data for the situation I intend will be as follows. I assume sampling with replacement. For this example, we have 10 colors in the jar (C=10). Note that we start by drawing one marble from the jar, which gives us a sample where N=1 and K=1. The number of colors found in a sample depends on the size of the sample. In this case it is seq(1:20). In this particular simulation, we have an equal representation for each color. The snip of R code I use to simulate the data is: ###snip of modified code for stack exchange exchange T <- c(1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10) for (i in 1:N){ for (s in 1:n.sims) { plot.sample <- sample(T, size=N[i]) K[s,i] <- length(unique(plot.sample)) } } Note that the line is just a loess plot at this point and the proper function would level off at C, the maximum number of colors. If I use the suggested formula K=N*C/(N+C-1) I get the figure on the right, which has the right shape, but finds colors very slowly. If I estimate the function with a scaling coefficient, I get the following graph. Excellent fit: explained variance = 97%, though the visual suggests there could be a better function?","Imagine we have a jar of marbles, where there are 10 different colors of marbles in the jar. Let N be the number of marbles drawn in a sample and K be the number of distinct colors in the sample. Let C be the total number of colors in the jar (which is 10 in this example). We know that: K = F(C,N) + chance. Intuitively, the more marbles we draw at a time, the more colors we are likely to obtain, up to the maximum. This strikes me as a binomial. I am looking for a formula to express in more detail how K = F(C,N). An obvious feature is that C is the maximum value. So I figure this is a model where K is an increasing proportion of C as N increases. I already know how to simulate the data, but wish to provide an expression of K depending on C and N. Any suggestions will be appreciated. Simulated data for the situation I intend will be as follows. I assume sampling with replacement. For this example, we have 10 colors in the jar (C=10). Note that we start by drawing one marble from the jar, which gives us a sample where N=1 and K=1. The number of colors found in a sample depends on the size of the sample. In this case it is seq(1:20). In this particular simulation, we have an equal representation for each color. The snip of R code I use to simulate the data is: ###snip of modified code for stack exchange exchange T <- c(1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10) for (i in 1:N){ for (s in 1:n.sims) { plot.sample <- sample(T, size=N[i]) K[s,i] <- length(unique(plot.sample)) } } Note that the line is just a loess plot at this point and the proper function would level off at C, the maximum number of colors. If I use the suggested formula K=N*C/(N+C-1) I get the figure on the right, which has the right shape, but finds colors very slowly. If I estimate the function with a scaling coefficient, I get the following graph. Excellent fit: explained variance = 97%, though the visual suggests there could be a better function?",,['probability']
28,Need help understanding proof for probability of union for two events.,Need help understanding proof for probability of union for two events.,,My book says that for any two events A and B $P(A \cup B) = P(A)+P(B)-P(A\cap B)$ The proof it provides is this: $$\def\P{\mathop{\rm P}}\begin{align}\P(A \cup B) &= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) \\[1ex]&= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) + \P(A\cap B) - \P(A\cap B) \\[1ex]&= \P(A)\hspace{16.5ex}+\P(B)\hspace{16.5ex}-\P(A\cap B)  \end{align}$$ My question is what happened to the $P(A\setminus B)$ and $P(B\setminus A)$ in the second line?,My book says that for any two events A and B The proof it provides is this: My question is what happened to the and in the second line?,P(A \cup B) = P(A)+P(B)-P(A\cap B) \def\P{\mathop{\rm P}}\begin{align}\P(A \cup B) &= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) \\[1ex]&= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) + \P(A\cap B) - \P(A\cap B) \\[1ex]&= \P(A)\hspace{16.5ex}+\P(B)\hspace{16.5ex}-\P(A\cap B)  \end{align} P(A\setminus B) P(B\setminus A),[]
29,Find the Expectation and Variance of 4 Independent Dice,Find the Expectation and Variance of 4 Independent Dice,,"We were given this seatwork: With four independent dice: a) the expected value of the sum of the rolls, b) the expected value of the product of the rolls, and c) the variance of the sum of the rolls . I was able to answer a and b, but I don't know how to get the variance. Here's my attempt: \begin{align*} S = \dfrac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5 \end{align*} This is the expectation of one die. For the expectation of four dice, we could assume the expectation of the sum four dice is equal to the sum of the expectations of a die: \begin{align*} &= S + S + S + S\\ &= 4S\\ &= 4(3.5)\\ &= 14 \end{align*} Similarly, we could also do this for the products. The expected product of four dice rolls is: \begin{align*} &= S \cdot S \cdot S \cdot S\\ &= S^4\\ &= 3.5^4\\ &= 150.06 \end{align*} Are these assumptions correct?","We were given this seatwork: With four independent dice: a) the expected value of the sum of the rolls, b) the expected value of the product of the rolls, and c) the variance of the sum of the rolls . I was able to answer a and b, but I don't know how to get the variance. Here's my attempt: This is the expectation of one die. For the expectation of four dice, we could assume the expectation of the sum four dice is equal to the sum of the expectations of a die: Similarly, we could also do this for the products. The expected product of four dice rolls is: Are these assumptions correct?","\begin{align*}
S = \dfrac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
\end{align*} \begin{align*}
&= S + S + S + S\\
&= 4S\\
&= 4(3.5)\\
&= 14
\end{align*} \begin{align*}
&= S \cdot S \cdot S \cdot S\\
&= S^4\\
&= 3.5^4\\
&= 150.06
\end{align*}","['probability', 'discrete-mathematics', 'solution-verification']"
30,Test and probability / Bayes,Test and probability / Bayes,,"There is a virus test with has 95% reliability. We randomly choose one person from a country with 10,000,000 people, in which it is estimated that the number of cases of this virus is 20,000. The selected person is tested positive. What is the probability that this person is actually positive? This is clearly an example of Bayes theorem use, but I am getting an odd result: $\mathrm{P}(A \mid Β) = \frac {\mathrm{P}(B \mid A).\mathrm{P}(A)}{\mathrm{P}(B)}$ $\mathrm{P}(A) = \frac {20,000}{10,000,000} = 0.002$ Since the test has 95% reliability, in the entire country (with population 10,000,000), if all were tested, there would be 95,000 people who are sick test positive and 95,000 of the healthy people test negative, therefore a total of 190,000. So: $\mathrm{P}(B) = \frac {190,000}{10,000,000} = 0.019$ (unconditional probability). Finally, since the sensitivity of the test is 95%, $\mathrm{P}(B \mid A) = 0.95$ . So from Bayes theorem we get $\mathrm{P}(A \mid Β) = \frac {0.95*0.002}{0.019} = 0.1$ , that is, 10%. But this is a bit counter-intuitive. Is it correct? Thank you","There is a virus test with has 95% reliability. We randomly choose one person from a country with 10,000,000 people, in which it is estimated that the number of cases of this virus is 20,000. The selected person is tested positive. What is the probability that this person is actually positive? This is clearly an example of Bayes theorem use, but I am getting an odd result: Since the test has 95% reliability, in the entire country (with population 10,000,000), if all were tested, there would be 95,000 people who are sick test positive and 95,000 of the healthy people test negative, therefore a total of 190,000. So: (unconditional probability). Finally, since the sensitivity of the test is 95%, . So from Bayes theorem we get , that is, 10%. But this is a bit counter-intuitive. Is it correct? Thank you","\mathrm{P}(A \mid Β) = \frac {\mathrm{P}(B \mid A).\mathrm{P}(A)}{\mathrm{P}(B)} \mathrm{P}(A) = \frac {20,000}{10,000,000} = 0.002 \mathrm{P}(B) = \frac {190,000}{10,000,000} = 0.019 \mathrm{P}(B \mid A) = 0.95 \mathrm{P}(A \mid Β) = \frac {0.95*0.002}{0.019} = 0.1","['probability', 'bayes-theorem']"
31,Calculation on the Power of Means (Probability),Calculation on the Power of Means (Probability),,"The problem is: Suppose $X\ge 0$ is a random variable, $p(x)$ is its probability density function. If $\operatorname EX$ exists, $r>0$ , prove: $$\operatorname EX^r = \int_0^\infty rx^{r-1}P(X>x) \, dx.$$ I see $\operatorname E X^r$ as $\int_{-\infty}^\infty x^r p(x) \, dx$ , while $$\text{RHS}=\int_0^\infty \left(\int_x^\infty p(t)\,dt \right) dx^r = \left.\left(x^r\int_x^\infty p(t) \, dt\right)\right|_0^\infty-\int_0^\infty x^r p(x) \, dx.$$ However, when calculating $x^r \int_x^\infty p(t) \, dt$ as $x\to \infty$ , it comes to a $0 \times \infty$ problem. How can I solve it? Thanks.","The problem is: Suppose is a random variable, is its probability density function. If exists, , prove: I see as , while However, when calculating as , it comes to a problem. How can I solve it? Thanks.","X\ge 0 p(x) \operatorname EX r>0 \operatorname EX^r = \int_0^\infty rx^{r-1}P(X>x) \, dx. \operatorname E X^r \int_{-\infty}^\infty x^r p(x) \, dx \text{RHS}=\int_0^\infty \left(\int_x^\infty p(t)\,dt \right) dx^r = \left.\left(x^r\int_x^\infty p(t) \, dt\right)\right|_0^\infty-\int_0^\infty x^r p(x) \, dx. x^r \int_x^\infty p(t) \, dt x\to \infty 0 \times \infty","['probability', 'integration', 'probability-theory', 'expected-value']"
32,infinite sum of inverse binomial coefficient encountered in Bayesian treatment of the German tank problem,infinite sum of inverse binomial coefficient encountered in Bayesian treatment of the German tank problem,,"in the Bayesian treatment of the German tank problem in Wikipedia here , they use: $\displaystyle \sum_{n=m}^\infty \dfrac{1}{\binom{n}{k}}=\dfrac{k}{k-1}\dfrac{1}{\binom{m-1}{k-1}}$ how can I prove this in a clever combinatorics fashion? I found this paper, see eqn. (9), which uses Gauss' hypergeometric function-- a bit beyond me. there must be some way via a recursion relation, like I found in this old paper . theorem 1 in that reference has a similar infinite sum of an inverse binomial coefficient.","in the Bayesian treatment of the German tank problem in Wikipedia here , they use: how can I prove this in a clever combinatorics fashion? I found this paper, see eqn. (9), which uses Gauss' hypergeometric function-- a bit beyond me. there must be some way via a recursion relation, like I found in this old paper . theorem 1 in that reference has a similar infinite sum of an inverse binomial coefficient.",\displaystyle \sum_{n=m}^\infty \dfrac{1}{\binom{n}{k}}=\dfrac{k}{k-1}\dfrac{1}{\binom{m-1}{k-1}},"['probability', 'sequences-and-series', 'combinatorics', 'combinatorial-proofs']"
33,Average density of a continuous random variable,Average density of a continuous random variable,,"Suppose, $X$ is a continuous random variable on $[0; 1]$ , and $p_X$ is its PDF. Suppose $E[X] = \lambda$ . What is the smallest possible value of $E[p_X(X)]$ ? I managed to prove the following bound: $$E[p_X(X)] \geq 3 \lambda^2$$ Indeed, $$\lambda = E[X] = \int_0^1 t p_X(t) dt \leq \sqrt{(\int_0^1 p_X(t)^2 dt)(\int_0^1 t^2 dt)} = \sqrt{\frac{E[p_X(X)]}{3}}$$ by Hoelder inequality. However, I do not know, whether this bound is tight…","Suppose, is a continuous random variable on , and is its PDF. Suppose . What is the smallest possible value of ? I managed to prove the following bound: Indeed, by Hoelder inequality. However, I do not know, whether this bound is tight…",X [0; 1] p_X E[X] = \lambda E[p_X(X)] E[p_X(X)] \geq 3 \lambda^2 \lambda = E[X] = \int_0^1 t p_X(t) dt \leq \sqrt{(\int_0^1 p_X(t)^2 dt)(\int_0^1 t^2 dt)} = \sqrt{\frac{E[p_X(X)]}{3}},"['probability', 'probability-theory', 'expected-value']"
34,Approximation to the monkey typewriter probability,Approximation to the monkey typewriter probability,,"Say that we are interested in the problem of a monkey randomly typing out a specific string of length m on a keyboard with k keys, in n trials, at least once: $$ 1 - \left(1 - \frac{1}{k^{m}}\right)^n $$ I would like to get some intuition about how this expression varies for m and n (with k around 26). Is there an approximation we can use in this instance? I would like to understand how this probability varies as we add one more character - by how much must we increase $n$ to keep the probability the same $?$ . Related to $1.$ : How do I compute the probability for the case where $k = 26, m = 50, n = 1,000,000\ ?$ . I couldn't do it in Python. Thank you","Say that we are interested in the problem of a monkey randomly typing out a specific string of length m on a keyboard with k keys, in n trials, at least once: I would like to get some intuition about how this expression varies for m and n (with k around 26). Is there an approximation we can use in this instance? I would like to understand how this probability varies as we add one more character - by how much must we increase to keep the probability the same . Related to : How do I compute the probability for the case where . I couldn't do it in Python. Thank you","
1 - \left(1 - \frac{1}{k^{m}}\right)^n
 n ? 1. k = 26, m = 50, n = 1,000,000\ ?",['probability']
35,Probability after rolling 4 dice,Probability after rolling 4 dice,,"Q. (the probability that the total after rolling 4 fair dice is 21) > (the probability that the total after rolling 4 fair dice is 22) A. Explanation: All ordered outcomes are equally likely here. So for example with two dice, obtaining a total of 9 is more likely than obtaining a total of 10 since there are two ways to get a 5 and a 4, and only one way to get two 5’s. To get a 21, the outcome must be a permutation of (6, 6, 6, 3) (4 possibilities), (6, 5, 5, 5) (4 possibilities), or (6, 6, 5, 4) (4!/2 = 12 possibilities). To get a 22, the outcome must be a permutation of (6, 6, 6, 4) (4 possibilities), or (6, 6, 5, 5) (4!/22 = 6 possibilities). So getting a 21 is more likely; in fact, it is exactly twice as likely as getting a 22. What I have understood so far is that after rolling 4 fair dice you can get 22 in the following ways - 6,6,6,4 - $4C_1$ - 4 6,6,5,5 - $4C_2$ - 6 So the total ways in which you can get 22 is 10, where you can get 21 in the following ways - 6,6,6,3 - $4C_1$ - 4 6,6,5,4 - $4C_2$ - 6 6,5,5,5 - $4C_1$ - 4 and hence the total ways in which you can choose is 14. Am I doing something wrong here? Can someone please help me understand the answer (A.) a bit better? Thanks in advance.","Q. (the probability that the total after rolling 4 fair dice is 21) > (the probability that the total after rolling 4 fair dice is 22) A. Explanation: All ordered outcomes are equally likely here. So for example with two dice, obtaining a total of 9 is more likely than obtaining a total of 10 since there are two ways to get a 5 and a 4, and only one way to get two 5’s. To get a 21, the outcome must be a permutation of (6, 6, 6, 3) (4 possibilities), (6, 5, 5, 5) (4 possibilities), or (6, 6, 5, 4) (4!/2 = 12 possibilities). To get a 22, the outcome must be a permutation of (6, 6, 6, 4) (4 possibilities), or (6, 6, 5, 5) (4!/22 = 6 possibilities). So getting a 21 is more likely; in fact, it is exactly twice as likely as getting a 22. What I have understood so far is that after rolling 4 fair dice you can get 22 in the following ways - 6,6,6,4 - - 4 6,6,5,5 - - 6 So the total ways in which you can get 22 is 10, where you can get 21 in the following ways - 6,6,6,3 - - 4 6,6,5,4 - - 6 6,5,5,5 - - 4 and hence the total ways in which you can choose is 14. Am I doing something wrong here? Can someone please help me understand the answer (A.) a bit better? Thanks in advance.",4C_1 4C_2 4C_1 4C_2 4C_1,"['probability', 'combinatorics', 'dice']"
36,Does the Poisson distribution arise from something deeper?,Does the Poisson distribution arise from something deeper?,,Is the Poisson distribution a mere approximation to the binomial distribution or a result of something more fundamental?,Is the Poisson distribution a mere approximation to the binomial distribution or a result of something more fundamental?,,"['probability', 'probability-distributions', 'poisson-distribution', 'foundations']"
37,What is the probability that the total score after throwing darts is divisible by $3$.,What is the probability that the total score after throwing darts is divisible by .,3,"To play a game of darts Michael throws three darts at the dart board shown. The number of points $(1,$ $5$ or $10)$ for each of the three regions is indicated. His score is the sum of the points for the three darts. If the radii of the three concentric circles are $1,$ $2$ and $3$ units, and each dart Michael throws hits this dart board at random, what is the probability that his score is evenly divisible by $3?$ Express your answer as a common fraction. After taking the values modulo $3$ , we have $1, 2, 1$ . I am pretty sure that the only way we can get divisible by $3$ in this problem is if we have modulos $1, 1, 1$ or $2, 2, 2$ for the darts. This means that the probability is ${\left(\dfrac23\right)}^3+{\left(\dfrac13\right)}^3=\dfrac13$ . I feel as if I am missing something, or am I correct? Thanks! EDIT: ""At random"" means that the likelihood of a dart landing in a region is the total area of that region divided by the total area of the dart-board.","To play a game of darts Michael throws three darts at the dart board shown. The number of points or for each of the three regions is indicated. His score is the sum of the points for the three darts. If the radii of the three concentric circles are and units, and each dart Michael throws hits this dart board at random, what is the probability that his score is evenly divisible by Express your answer as a common fraction. After taking the values modulo , we have . I am pretty sure that the only way we can get divisible by in this problem is if we have modulos or for the darts. This means that the probability is . I feel as if I am missing something, or am I correct? Thanks! EDIT: ""At random"" means that the likelihood of a dart landing in a region is the total area of that region divided by the total area of the dart-board.","(1, 5 10) 1, 2 3 3? 3 1, 2, 1 3 1, 1, 1 2, 2, 2 {\left(\dfrac23\right)}^3+{\left(\dfrac13\right)}^3=\dfrac13","['probability', 'elementary-number-theory']"
38,couple of questions in probability,couple of questions in probability,,"I'm trying to solve some questions and I'm not sure if I'm solving it correctly. Question 1: "" A boy participating in a game and throwing normal dice, if the dice shows the number 6 the game is over. Else, the boy need to wait the number of minutes the dice shows. For example: if the dice shows 4 the boy need to wait 4 minutes and then continue playing. What is the Expected value the boy will wait? My answer: $x$ is a random variable that gets the values ( $1, \ldots, 6$ ) with the same probability, so the expected value should be $$2.5 = \frac{1}{6}(1+2+3+4+5) + \frac{1}{6} \cdot 0$$ Question 2: The number of earthquakes in a year at  a country is  a Poisson variable with $2 = \lambda$ .  Given that in certain year the the number of earthquakes was $2$ , what is the probability that the $2$ earthquakes accord at the first $3$ months of the year? My answer: I am not sure that my way is correct it thought that I divide $\lambda$ by $4$ ,then $\lambda$ is the number of earthquakes in a $1/4$ of a year and then I get that the answer is $0.0758$ , but I am not sure this is the right way. Thanks for the help!","I'm trying to solve some questions and I'm not sure if I'm solving it correctly. Question 1: "" A boy participating in a game and throwing normal dice, if the dice shows the number 6 the game is over. Else, the boy need to wait the number of minutes the dice shows. For example: if the dice shows 4 the boy need to wait 4 minutes and then continue playing. What is the Expected value the boy will wait? My answer: is a random variable that gets the values ( ) with the same probability, so the expected value should be Question 2: The number of earthquakes in a year at  a country is  a Poisson variable with .  Given that in certain year the the number of earthquakes was , what is the probability that the earthquakes accord at the first months of the year? My answer: I am not sure that my way is correct it thought that I divide by ,then is the number of earthquakes in a of a year and then I get that the answer is , but I am not sure this is the right way. Thanks for the help!","x 1, \ldots, 6 2.5 = \frac{1}{6}(1+2+3+4+5) + \frac{1}{6} \cdot 0 2 = \lambda 2 2 3 \lambda 4 \lambda 1/4 0.0758","['probability', 'expected-value']"
39,about prisoners and selection of numbers,about prisoners and selection of numbers,,"Each of the three prisoners had a natural number written on their foreheads: 1, 2 or 3. Numbers can be repeated.  The prisoners see all numbers except their own.  After that, everyone tries to guess their number.  If someone succeeds, the prisoners will be released, otherwise they will be executed.  Before the trial, the prisoners can agree.  How can they get out? (prisoners cannot hear each other during the trial) I thought that 1st prisoner can do this. if he sees two identical numbers in front of him, then he will say the same number and thus one of the prisoners will definitely be right if all the numbers are the same, and if the first prisoner sees different numbers, then he will say the third number which was not there and thus the prisoners will be  right in the case of three different digits.  but after that I don't know how the other 2 prisoners should act, they already know that in the case with three different numbers and the case with three identical numbers, the first one has already taken over, so it is necessary to choose one number from the two that they see.  But how can they choose to be right in all cases?","Each of the three prisoners had a natural number written on their foreheads: 1, 2 or 3. Numbers can be repeated.  The prisoners see all numbers except their own.  After that, everyone tries to guess their number.  If someone succeeds, the prisoners will be released, otherwise they will be executed.  Before the trial, the prisoners can agree.  How can they get out? (prisoners cannot hear each other during the trial) I thought that 1st prisoner can do this. if he sees two identical numbers in front of him, then he will say the same number and thus one of the prisoners will definitely be right if all the numbers are the same, and if the first prisoner sees different numbers, then he will say the third number which was not there and thus the prisoners will be  right in the case of three different digits.  but after that I don't know how the other 2 prisoners should act, they already know that in the case with three different numbers and the case with three identical numbers, the first one has already taken over, so it is necessary to choose one number from the two that they see.  But how can they choose to be right in all cases?",,"['probability', 'logic']"
40,Finite Markov Chain: $ X_n = X_{n-1}+B_{n} $ with two recurrent states.,Finite Markov Chain:  with two recurrent states., X_n = X_{n-1}+B_{n} ,"I have a simple and rather basic question regarding Markov Chains: let $B_{n}$ be an i.i.d process that gets the values $\{-1,1\}$ with probability of $\frac{1}{2}$ . We define the following Markov Chain above $\{0,1,...,K-1,K\}$ states: $X_{n}=\begin{cases} X_{n-1}+B_{n}, & 0<X_{n-1}<K\\ X_{n-1}, & X_{n-1}=\{0,K\} \end{cases}$ The State Diagram for ( $ p=\frac{1}{2} $ ): I'm interested in finding the transition probability: $\rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\}$ for $i,j\in\{1,2,...,K-1\}$ which is the probability that the process $X_{n}$ reaches state $i$ at some time $n$ , given that the initial state was $j$ . first, I was able to calculate: $\pi_{k}=\rho_{k0}=P\{\exists n>0:X_{n}=0|X_{0}=k\}=\begin{cases} 1-\frac{k}{K}, & 0<k<K\end{cases}$ which is the probability to reach state $0$ given that the initial state was at state $0<k<K$ . this was done by assuming a general solution $\pi_{k}=a\lambda^{k}+b$ , and solving an equation that has a relation between $\pi_{k,}\pi_{k-1,}\pi_{k+1}$ , which gives $\pi_{k}=1-\frac{1-\lambda^{k}}{1-\lambda^{K}}$ where $\lambda={{\frac{p}{1-p}} }$ . taking the limit $\lambda\rightarrow1$ , which suits our case, (in which $p=\frac{1}{2}$ ), gives the result for $\pi_{k}$ that I wrote above. I want to use $\pi_{k}$ to find an expression for $\rho_{ji}$ for $i,j\in\{1,2,...,K-1\}$ . I argue that, in case $j>i$ : $\rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\}=P\{\exists n>0:X_{n}=0|X_{0}=|j-i|\}=\pi_{|j-i|0}$ from symmetry. which means moving (to the left) from state $j$ to $i$ (where $i,j\in\{1,2,...,K-1\}$ ), is equivalent to moving from state $|j-i|$ to state $0$ . thus, by using the previous solution for $\pi_{k}$ , one can find $\rho_{ji}$ for $j>i$ case: $\rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\}=P\{\exists n>0:X_{n}=0|X_{0}=|j-i|\}=\begin{cases} 1 & |j-i|=k=0\\ 1-\frac{k}{K} & |j-i|=k\in\{1,..,K-1\}\\ 0 & |j-i|=k=K \end{cases}$ I somehow concluded also that $\rho_{ji}$ for $j<i$ should be equal to to the expression I got fior $j>i$ case, since intuitively, it sounds right to me. but turns out, according to an official solution (which wasn't really detailed), that the final answer for case $j<i$ (moving to the right) should be: $\rho_{ji}={ {\frac{j}{i}} }$ I can't figure out why, and I would be glad for some enlightenment. Note: it's possible that there is a mistake in the official solution, and I hope you can help me verify that. Modification: Thanks to Misha's Answer, I figured out that the reason behind replacing $K$ with $K-i$ is the following: for example for $i<j:$ we are interested in defining a ""new"" Markov Chain depending on the distance we want to move from $j$ to $i$ . (from right to left) for example if $K=6$ and we want to move from $state$ $j=5$ to $state$ $i=2$ , its equivalent to moving from $state$ $j=$$3$ to $state$ $i=0$ in a ""smaller"" Markov Chain that has the state $K-i$ at it's far right instead of $K.$ (which is the state we are never interested to visit, since our goal is to meet the wanted state which happens to be on the left). in other words, the Markov chain $\{0,...,K-i\}$ includes all the possible traveling distances to state $0$ starting from the state $\{K-i-1\}$ , and the largest distance is moving $\{K-i-1\}$ $states$ down to state $zero$ , which is equivalent to the largest traveling distance from $state$ $j=5$ down to $state$ $i=2$ , which is $\{j-i\}$ .","I have a simple and rather basic question regarding Markov Chains: let be an i.i.d process that gets the values with probability of . We define the following Markov Chain above states: The State Diagram for ( ): I'm interested in finding the transition probability: for which is the probability that the process reaches state at some time , given that the initial state was . first, I was able to calculate: which is the probability to reach state given that the initial state was at state . this was done by assuming a general solution , and solving an equation that has a relation between , which gives where . taking the limit , which suits our case, (in which ), gives the result for that I wrote above. I want to use to find an expression for for . I argue that, in case : from symmetry. which means moving (to the left) from state to (where ), is equivalent to moving from state to state . thus, by using the previous solution for , one can find for case: I somehow concluded also that for should be equal to to the expression I got fior case, since intuitively, it sounds right to me. but turns out, according to an official solution (which wasn't really detailed), that the final answer for case (moving to the right) should be: I can't figure out why, and I would be glad for some enlightenment. Note: it's possible that there is a mistake in the official solution, and I hope you can help me verify that. Modification: Thanks to Misha's Answer, I figured out that the reason behind replacing with is the following: for example for we are interested in defining a ""new"" Markov Chain depending on the distance we want to move from to . (from right to left) for example if and we want to move from to , its equivalent to moving from to in a ""smaller"" Markov Chain that has the state at it's far right instead of (which is the state we are never interested to visit, since our goal is to meet the wanted state which happens to be on the left). in other words, the Markov chain includes all the possible traveling distances to state starting from the state , and the largest distance is moving down to state , which is equivalent to the largest traveling distance from down to , which is .","B_{n} \{-1,1\} \frac{1}{2} \{0,1,...,K-1,K\} X_{n}=\begin{cases}
X_{n-1}+B_{n}, & 0<X_{n-1}<K\\
X_{n-1}, & X_{n-1}=\{0,K\}
\end{cases}  p=\frac{1}{2}  \rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\} i,j\in\{1,2,...,K-1\} X_{n} i n j \pi_{k}=\rho_{k0}=P\{\exists n>0:X_{n}=0|X_{0}=k\}=\begin{cases}
1-\frac{k}{K}, & 0<k<K\end{cases} 0 0<k<K \pi_{k}=a\lambda^{k}+b \pi_{k,}\pi_{k-1,}\pi_{k+1} \pi_{k}=1-\frac{1-\lambda^{k}}{1-\lambda^{K}} \lambda={{\frac{p}{1-p}} } \lambda\rightarrow1 p=\frac{1}{2} \pi_{k} \pi_{k} \rho_{ji} i,j\in\{1,2,...,K-1\} j>i \rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\}=P\{\exists n>0:X_{n}=0|X_{0}=|j-i|\}=\pi_{|j-i|0} j i i,j\in\{1,2,...,K-1\} |j-i| 0 \pi_{k} \rho_{ji} j>i \rho_{ji}=P\{\exists n>0:X_{n}=i|X_{0}=j\}=P\{\exists n>0:X_{n}=0|X_{0}=|j-i|\}=\begin{cases}
1 & |j-i|=k=0\\
1-\frac{k}{K} & |j-i|=k\in\{1,..,K-1\}\\
0 & |j-i|=k=K
\end{cases} \rho_{ji} j<i j>i j<i \rho_{ji}={ {\frac{j}{i}} } K K-i i<j: j i K=6 state j=5 state i=2 state j=3 state i=0 K-i K. \{0,...,K-i\} 0 \{K-i-1\} \{K-i-1\} states zero state j=5 state i=2 \{j-i\}","['probability', 'stochastic-processes', 'markov-chains', 'markov-process', 'random-walk']"
41,Where is the mistake with this conditional expectation calculation?,Where is the mistake with this conditional expectation calculation?,,"Let $X$ and $Y$ be independent uniform random variables in $[0,1]$ and let $\alpha\geq 1$ . I am interested in computing $E(\alpha)=\mathbb{E}(X\mid X\geq \alpha Y)$ . Intuitively, I expect to have $E'(\alpha)>0$ as when $\alpha$ increases, conditional on $\{X\geq \alpha Y\}$ , I know $X$ can only take higher values. I am stuck with the computations, however. This is what I've done: We know that $$\mathbb{E}(X\mid X\geq \alpha Y)=\frac{\mathbb{E}(X\mathbb{I}_{X\geq \alpha Y})}{\mathbb{P}(X\geq \alpha Y)}.$$ As $X\in[0,1]$ , $$\mathbb{P}(X\geq \alpha Y)=\int_{0}^{1/\alpha}\mathbb{P}(X\geq \alpha y)\,dy+\underbrace{\int_{1/\alpha}^{1}\mathbb{P}(X\geq \alpha y)\,dy}_{=0}=\int_{0}^{1/\alpha}[1-F_X(\alpha y)]\,dy=\frac{1}{2\alpha}.$$ This expression seems about right, as I know that $\mathbb{P}(X>Y)=\frac{1}{2}$ , and it is decreasing in $\alpha$ as it should intuitively be. Likewise, I can compute $$\mathbb{E}(X\mathbb{I}_{X\geq \alpha Y})=\mathbb{E}\left(X\mathbb{I}_{X\geq \alpha Y}\mathbb{I}_{Y\leq \frac{1}{\alpha}}\right)+\underbrace{\mathbb{E}\left(X\mathbb{I}_{X\geq \alpha Y}\mathbb{I}_{Y> \frac{1}{\alpha}}\right)}_{=0}=\int_0^{1/\alpha}\int_{\alpha y}^1x\,dx\,dy=\int_{0}^{1/\alpha}\left(\frac{1}{2}-\frac{\alpha^2 y^2}{2}\right)dy= \frac{1}{3\alpha}$$ Then, $\mathbb{E}(X\mid X\geq \alpha Y)=\frac{2}{3}$ , which I know that it is true if $\alpha=1$ , but doesn't make sense for other $\alpha>1$ . Can someone point me where is the mistake in my computations? EDIT: As someone already pointed out, the calculations are correct. Can someone come up with a nice intuitive explanation for it?","Let and be independent uniform random variables in and let . I am interested in computing . Intuitively, I expect to have as when increases, conditional on , I know can only take higher values. I am stuck with the computations, however. This is what I've done: We know that As , This expression seems about right, as I know that , and it is decreasing in as it should intuitively be. Likewise, I can compute Then, , which I know that it is true if , but doesn't make sense for other . Can someone point me where is the mistake in my computations? EDIT: As someone already pointed out, the calculations are correct. Can someone come up with a nice intuitive explanation for it?","X Y [0,1] \alpha\geq 1 E(\alpha)=\mathbb{E}(X\mid X\geq \alpha Y) E'(\alpha)>0 \alpha \{X\geq \alpha Y\} X \mathbb{E}(X\mid X\geq \alpha Y)=\frac{\mathbb{E}(X\mathbb{I}_{X\geq \alpha Y})}{\mathbb{P}(X\geq \alpha Y)}. X\in[0,1] \mathbb{P}(X\geq \alpha Y)=\int_{0}^{1/\alpha}\mathbb{P}(X\geq \alpha y)\,dy+\underbrace{\int_{1/\alpha}^{1}\mathbb{P}(X\geq \alpha y)\,dy}_{=0}=\int_{0}^{1/\alpha}[1-F_X(\alpha y)]\,dy=\frac{1}{2\alpha}. \mathbb{P}(X>Y)=\frac{1}{2} \alpha \mathbb{E}(X\mathbb{I}_{X\geq \alpha Y})=\mathbb{E}\left(X\mathbb{I}_{X\geq \alpha Y}\mathbb{I}_{Y\leq \frac{1}{\alpha}}\right)+\underbrace{\mathbb{E}\left(X\mathbb{I}_{X\geq \alpha Y}\mathbb{I}_{Y> \frac{1}{\alpha}}\right)}_{=0}=\int_0^{1/\alpha}\int_{\alpha y}^1x\,dx\,dy=\int_{0}^{1/\alpha}\left(\frac{1}{2}-\frac{\alpha^2 y^2}{2}\right)dy= \frac{1}{3\alpha} \mathbb{E}(X\mid X\geq \alpha Y)=\frac{2}{3} \alpha=1 \alpha>1","['probability', 'conditional-expectation', 'expected-value']"
42,Combinatorial identity: $\sum_{i=0}^{k}\binom{n}{i}p^{i}q^{n-i}+ \sum_{i=k}^{n-1}\binom{i}{k}p^{k+1}q^{i-k}=1$.,Combinatorial identity: .,\sum_{i=0}^{k}\binom{n}{i}p^{i}q^{n-i}+ \sum_{i=k}^{n-1}\binom{i}{k}p^{k+1}q^{i-k}=1,While answering a recent question I came across an unexpected identity: $$ \sum_{i=0}^{k}\binom{n}{i}p^{i}q^{n-i}+ \sum_{i=k}^{n-1}\binom{i}{k}p^{k+1}q^{i-k}=1.\tag1 $$ valid provided that $p+q=1$ . The identity (1) can be also written as: $$ \sum_{i=k}^{n}\binom{n}{i}p^{i}q^{n-i-1}=\sum_{i=k}^{n}\binom{i-1}{k-1} p^{k}q^{i-k}.\tag2 $$ Is there a simple combinatorial (probabilistic) explanation of the result for $k<n$ ?,While answering a recent question I came across an unexpected identity: valid provided that . The identity (1) can be also written as: Is there a simple combinatorial (probabilistic) explanation of the result for ?,"
\sum_{i=0}^{k}\binom{n}{i}p^{i}q^{n-i}+
\sum_{i=k}^{n-1}\binom{i}{k}p^{k+1}q^{i-k}=1.\tag1
 p+q=1 
\sum_{i=k}^{n}\binom{n}{i}p^{i}q^{n-i-1}=\sum_{i=k}^{n}\binom{i-1}{k-1} p^{k}q^{i-k}.\tag2
 k<n","['probability', 'combinatorics', 'binomial-coefficients']"
43,Coupon collector with arbitrary duplicates,Coupon collector with arbitrary duplicates,,"What is the expected number of tickets in the coupon collector's problem where duplicates are allowed, but some tickets have a different, arbitrary number of duplicates required until the collector's job is finished? Example: Pool of five different tickets where each ticket has their own number of duplicates: $1, 2, 4, 6, 7$ tickets each. So having only one of each ticket is not enough, but specific tickets need multiple. Of course, each ticket still has the same probability to draw throughout.","What is the expected number of tickets in the coupon collector's problem where duplicates are allowed, but some tickets have a different, arbitrary number of duplicates required until the collector's job is finished? Example: Pool of five different tickets where each ticket has their own number of duplicates: tickets each. So having only one of each ticket is not enough, but specific tickets need multiple. Of course, each ticket still has the same probability to draw throughout.","1, 2, 4, 6, 7","['probability', 'coupon-collector']"
44,Calculate the probability that the event A occurred based on weighted premises,Calculate the probability that the event A occurred based on weighted premises,,"I am implementing some code, and want to implement the following: Calculate the probability that event A occurred based on weighted premises. So I want to be able to define some premises (other events that occurred in the system - these either occurred or not - I know whether they occurred for sure or not). These premises have different weights in terms of how much do they commit to the occurrence of event A and are independent of each other. So for instance, a dummy example (weight of the event is in the parenthesis): a) clouds are visible on the sky (4) b) it was raining yesterday (1) c) rain detectors detected water (7) d) relative humidity in the air is high (6) Before calculating I know that these events happened or not. And I want to calculate probability whether it is raining at the moment (event A) based on a), b), c), d) premises (events) that have different weights. Could you point me in the right direction? Thank you","I am implementing some code, and want to implement the following: Calculate the probability that event A occurred based on weighted premises. So I want to be able to define some premises (other events that occurred in the system - these either occurred or not - I know whether they occurred for sure or not). These premises have different weights in terms of how much do they commit to the occurrence of event A and are independent of each other. So for instance, a dummy example (weight of the event is in the parenthesis): a) clouds are visible on the sky (4) b) it was raining yesterday (1) c) rain detectors detected water (7) d) relative humidity in the air is high (6) Before calculating I know that these events happened or not. And I want to calculate probability whether it is raining at the moment (event A) based on a), b), c), d) premises (events) that have different weights. Could you point me in the right direction? Thank you",,"['probability', 'conditional-probability']"
45,Expected number of turns for getting six 1's in six dice.,Expected number of turns for getting six 1's in six dice.,,"You have 6 unbiased dice. What is the expected numbers of turns required to get 1 in all the faces such that whenever you get 1 in any of the dice, you do not roll it for next three turns. For example, the die faces could be as follows: Turn 1 $\rightarrow$ 1, 2, 3, 4, 5, 6 (since the first die came up with 1 on top, you do not roll the first die for next 3 turns) Turn 2 $\rightarrow$ $\mathbf{1} $ , 3, 3, 1, 4, 1 Turn 3 $\rightarrow$ $\mathbf{1}$ , 5, 6, $\mathbf{1}$ , 3, $\mathbf{1}$ Turn 4 $\rightarrow$ $\mathbf{1}$ , 4, 4, $\mathbf{1}$ , 2, $\mathbf{1}$ Turn 5 $\rightarrow$ 6, 1, 3, $\mathbf{1}$ , 5, $\mathbf{1}$ Turn 6 $\rightarrow$ 2, $\mathbf{1}$ , 1, 3, 2, 6 and so on. (Numbers in bold indicate that they were not rolled during that turn.)","You have 6 unbiased dice. What is the expected numbers of turns required to get 1 in all the faces such that whenever you get 1 in any of the dice, you do not roll it for next three turns. For example, the die faces could be as follows: Turn 1 1, 2, 3, 4, 5, 6 (since the first die came up with 1 on top, you do not roll the first die for next 3 turns) Turn 2 , 3, 3, 1, 4, 1 Turn 3 , 5, 6, , 3, Turn 4 , 4, 4, , 2, Turn 5 6, 1, 3, , 5, Turn 6 2, , 1, 3, 2, 6 and so on. (Numbers in bold indicate that they were not rolled during that turn.)",\rightarrow \rightarrow \mathbf{1}  \rightarrow \mathbf{1} \mathbf{1} \mathbf{1} \rightarrow \mathbf{1} \mathbf{1} \mathbf{1} \rightarrow \mathbf{1} \mathbf{1} \rightarrow \mathbf{1},"['probability', 'combinatorics', 'conditional-expectation', 'expected-value', 'dice']"
46,"Probability of getting 3 specific characters from a pool of 400, with 200 attempts, with repetitions","Probability of getting 3 specific characters from a pool of 400, with 200 attempts, with repetitions",,"I'm playing a game where you can get characters from a pool of 400, if you get one character and dismiss it you can get that character again in another attempt, but if you take the character with you, you can't get it again. Also, you can only get one character per attempt. So, what is the probability of getting 3 specific characters after 200 attempts? Consider I would only get those 3 and dismiss all the rest. I came to a result, but I'm not sure if I'm right: Assuming they're all equally probable, and I already have 7 characters, the chances of getting the first one is $1 - (1 - 1/393)^{200} = 0.3992$ . The chances for the second are $1 - (1 - 1/392)^{199} = 0.3985$ , since I would take the first one, and I'd have to find it in the other 199 attempts. The chances for the third would be $1 - (1 - 1/391)^{198} = 0.3977$ . So, the chances of getting those 3 events in the same 200 attempts would be the multiplication of the probabilities of those 3 events alone: $0.3992 * 0.3985 * 0.3977 = 0.0632$ Is this correct? It's been some years since I last did something like this in university, so it's likely that I'm missing something.","I'm playing a game where you can get characters from a pool of 400, if you get one character and dismiss it you can get that character again in another attempt, but if you take the character with you, you can't get it again. Also, you can only get one character per attempt. So, what is the probability of getting 3 specific characters after 200 attempts? Consider I would only get those 3 and dismiss all the rest. I came to a result, but I'm not sure if I'm right: Assuming they're all equally probable, and I already have 7 characters, the chances of getting the first one is . The chances for the second are , since I would take the first one, and I'd have to find it in the other 199 attempts. The chances for the third would be . So, the chances of getting those 3 events in the same 200 attempts would be the multiplication of the probabilities of those 3 events alone: Is this correct? It's been some years since I last did something like this in university, so it's likely that I'm missing something.",1 - (1 - 1/393)^{200} = 0.3992 1 - (1 - 1/392)^{199} = 0.3985 1 - (1 - 1/391)^{198} = 0.3977 0.3992 * 0.3985 * 0.3977 = 0.0632,"['probability', 'conditional-probability']"
47,Probability that all red cards are assigned a number less than or equal to 15,Probability that all red cards are assigned a number less than or equal to 15,,"I have 10 red and 10 blue cards. I shuffle the cards and then label the cards based on their orders: I write the number one on the first card, the number two on the second card, and so on. What is the probability that a) All red cards are assigned numbers less than or equal to 15? b) Exactly 8 red cards are assigned numbers less than or equal to 15? I know that the total number of ways to arrange 20 cards is $20!$ . How do I proceed further?","I have 10 red and 10 blue cards. I shuffle the cards and then label the cards based on their orders: I write the number one on the first card, the number two on the second card, and so on. What is the probability that a) All red cards are assigned numbers less than or equal to 15? b) Exactly 8 red cards are assigned numbers less than or equal to 15? I know that the total number of ways to arrange 20 cards is . How do I proceed further?",20!,"['probability', 'combinatorics', 'self-learning']"
48,MLE of Geometric distribution - consistency and variance of inverse arithmetic sum,MLE of Geometric distribution - consistency and variance of inverse arithmetic sum,,"I want to calculate the MLE and its consistency of Geometric distribution: $$\mathbb{P}(X=x)=p(1-p)^{x-1}$$ $$ l(p) = p(1-p)^{x_1-1}\cdot p(1-p)^{x_2-1} \cdot \cdots \cdot p(1-p)^{x_n-1} \\ L(p)=n\ln p + (x_1 + \cdots +x_n -n)\ln(1-p) \\ (L(p))'= \frac{n}{p} - \frac{x_1 + \cdots + x_n - n}{1-p} \\ \hat{p} = \frac{n}{x_1 + \cdots + x_n} = \frac{1}{\overline{X}} $$ Now, to check the consistency I would use Markov's Inequality: $$ \mathbb{P}(|\hat{p_n} - \mathbb{E}(\hat{p_n})| \geq \epsilon) \leq \frac{\operatorname{Var}(\hat{p_n})}{\epsilon^2} $$ I am stuck on calculating Variance though. Variance of arithmetic sum would be a breeze - here though it is an inverse of it. How can i proceed? Is it just the inverse of $\operatorname{Var}(\overline{X})$ = $\frac{\operatorname{Var}(X)}{n}$ which would equal $\frac{n}{\operatorname{Var}(X)}$ ? What is the $\mathbb{E}(\hat{p_n})$ ?","I want to calculate the MLE and its consistency of Geometric distribution: Now, to check the consistency I would use Markov's Inequality: I am stuck on calculating Variance though. Variance of arithmetic sum would be a breeze - here though it is an inverse of it. How can i proceed? Is it just the inverse of = which would equal ? What is the ?","\mathbb{P}(X=x)=p(1-p)^{x-1} 
l(p) = p(1-p)^{x_1-1}\cdot p(1-p)^{x_2-1} \cdot \cdots \cdot p(1-p)^{x_n-1} \\
L(p)=n\ln p + (x_1 + \cdots +x_n -n)\ln(1-p) \\
(L(p))'= \frac{n}{p} - \frac{x_1 + \cdots + x_n - n}{1-p} \\
\hat{p} = \frac{n}{x_1 + \cdots + x_n} = \frac{1}{\overline{X}}
 
\mathbb{P}(|\hat{p_n} - \mathbb{E}(\hat{p_n})| \geq \epsilon) \leq \frac{\operatorname{Var}(\hat{p_n})}{\epsilon^2}
 \operatorname{Var}(\overline{X}) \frac{\operatorname{Var}(X)}{n} \frac{n}{\operatorname{Var}(X)} \mathbb{E}(\hat{p_n})","['probability', 'probability-theory', 'statistics', 'statistical-inference', 'maximum-likelihood']"
49,Rolling at Least 2 2's on 3 fair dice,Rolling at Least 2 2's on 3 fair dice,,Say we roll three 6-sided dice. What is the probability that at least two of the faces are a 2? The sample space here is 216. Rolling a 2 on one dice is 1/6. Rolling two 2s is 1/6 * 1/6 = 1/36 The third dice is at least two 2s so the probability it isn't a 2 is 5/6 and the probability it is a 2 is 1/6. So do we multiply 1/36 * 1/6 * 5/6 to get the answer? 5/1296 is the probability of rolling at least two 2s on 3 fair dice?,Say we roll three 6-sided dice. What is the probability that at least two of the faces are a 2? The sample space here is 216. Rolling a 2 on one dice is 1/6. Rolling two 2s is 1/6 * 1/6 = 1/36 The third dice is at least two 2s so the probability it isn't a 2 is 5/6 and the probability it is a 2 is 1/6. So do we multiply 1/36 * 1/6 * 5/6 to get the answer? 5/1296 is the probability of rolling at least two 2s on 3 fair dice?,,"['probability', 'statistics']"
50,Number of ‘acceptable’ pairs in card drawing game,Number of ‘acceptable’ pairs in card drawing game,,"A deck contains six cards, one pair labelled '1', another pair labelled '2' and the last labelled '3'. The deck is shuffled and you a pair of cards at a time until there are no cards left. A pair of cards $(i,j)$ is called acceptable if $|i-j|\leq1$ . What is the probability you have drawn only acceptable pairs? How does your answer change if there are $n$ pairs and the condition becomes $|i-j|\leq k$ ? I'm quite stuck on the last bit of the problem. Here's my approach to the first part: My solution so far:  My idea is that as long as a pair $(1,3)$ or $(3,1)$ is drawn, then set contains an unacceptable pair. The probability $(1,3)$ or $(3,1)$ is drawn first is $$2\left(\frac26\times\frac25\right)=\frac4{15},$$ the probability $(1,3)$ or $(3,1)$ is drawn second is $$\left(1-\frac4{15}\right)\frac4{15}=\frac{44}{225},$$ and the probability $(1,3)$ or $(3,1)$ is drawn last is $$\left(1-\frac4{15}-\frac{44}{225}\right)\frac4{15}=\frac{484}{3375},$$ so the probability of having only acceptable pairs is $$1-\frac4{15}-\frac{44}{225}-\frac{484}{3375}=1-\frac{900}{3375}-\frac{660}{3375}-\frac{484}{3375}=\frac{1331}{3375}.$$ (Correct me if this is wrong please!) However, I am unsure of how to extend this to a more general number of cards and relaxed constraint. Taking the complement seems to be less efficient compared to finding the actual probability, but I'm not sure if there's a closed form. Qualitatively, all I can see is the probability dropping to zero as the number of cards increases. Could someone provide better insight? Cheers!","A deck contains six cards, one pair labelled '1', another pair labelled '2' and the last labelled '3'. The deck is shuffled and you a pair of cards at a time until there are no cards left. A pair of cards is called acceptable if . What is the probability you have drawn only acceptable pairs? How does your answer change if there are pairs and the condition becomes ? I'm quite stuck on the last bit of the problem. Here's my approach to the first part: My solution so far:  My idea is that as long as a pair or is drawn, then set contains an unacceptable pair. The probability or is drawn first is the probability or is drawn second is and the probability or is drawn last is so the probability of having only acceptable pairs is (Correct me if this is wrong please!) However, I am unsure of how to extend this to a more general number of cards and relaxed constraint. Taking the complement seems to be less efficient compared to finding the actual probability, but I'm not sure if there's a closed form. Qualitatively, all I can see is the probability dropping to zero as the number of cards increases. Could someone provide better insight? Cheers!","(i,j) |i-j|\leq1 n |i-j|\leq k (1,3) (3,1) (1,3) (3,1) 2\left(\frac26\times\frac25\right)=\frac4{15}, (1,3) (3,1) \left(1-\frac4{15}\right)\frac4{15}=\frac{44}{225}, (1,3) (3,1) \left(1-\frac4{15}-\frac{44}{225}\right)\frac4{15}=\frac{484}{3375}, 1-\frac4{15}-\frac{44}{225}-\frac{484}{3375}=1-\frac{900}{3375}-\frac{660}{3375}-\frac{484}{3375}=\frac{1331}{3375}.","['probability', 'card-games']"
51,"Getting a cat, fish, dog, and your lunch across a river","Getting a cat, fish, dog, and your lunch across a river",,"You're trying to get a cat, a fish, a dog, and your lunch across a river, but there's a troll in the way. The troll says, ""I'll allow you to cross the river, but only if you play this game with me. I have a die here showing a cat, a fish, a dog, and your lunch. I'll roll that die, and then you must bring that item across the river, no matter which side it's on. Once you do that, I'll roll the die again. If you can get everything to the other side, I'll let you go."" You quickly realize this is a bad idea: If you leave the cat and fish alone on one side, the cat will eat the fish, and if you leave the dog and lunch alone on one side, the dog will eat your lunch. (If the cat, the fish, and something else are alone on one side, nothing will be eaten. Likewise, if the dog, your lunch, and something else are alone on one side, nothing will be eaten.) You tell this to the troll, who says, ""Fine. When I absolutely need to, I'll re-roll the die to make sure none of your precious cargo is harmed."" Suppose that you make a move when you bring something from one side of the river to the other. (If the troll re-rolls their die, this does not count as a move.) Find the expected number of moves you'll need to make before everything is on the other side of the river. I honestly don't know where to start with this problem and a solution would be greatly appreciated.","You're trying to get a cat, a fish, a dog, and your lunch across a river, but there's a troll in the way. The troll says, ""I'll allow you to cross the river, but only if you play this game with me. I have a die here showing a cat, a fish, a dog, and your lunch. I'll roll that die, and then you must bring that item across the river, no matter which side it's on. Once you do that, I'll roll the die again. If you can get everything to the other side, I'll let you go."" You quickly realize this is a bad idea: If you leave the cat and fish alone on one side, the cat will eat the fish, and if you leave the dog and lunch alone on one side, the dog will eat your lunch. (If the cat, the fish, and something else are alone on one side, nothing will be eaten. Likewise, if the dog, your lunch, and something else are alone on one side, nothing will be eaten.) You tell this to the troll, who says, ""Fine. When I absolutely need to, I'll re-roll the die to make sure none of your precious cargo is harmed."" Suppose that you make a move when you bring something from one side of the river to the other. (If the troll re-rolls their die, this does not count as a move.) Find the expected number of moves you'll need to make before everything is on the other side of the river. I honestly don't know where to start with this problem and a solution would be greatly appreciated.",,"['probability', 'combinatorics', 'expected-value']"
52,Prove $\lim_{\varepsilon\to 0^+}\frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}=0$,Prove,\lim_{\varepsilon\to 0^+}\frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}=0,"Let $X$ be a random variable taking values in $[0,+\infty]$ . Prove that: $$\lim_{\varepsilon\to 0^+}\frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}=0 ~~~~\mathrm{and~~~}  \lim_{x \to +\infty}\frac{1}{x}\int\limits_{X\leqslant x}X\mathrm{d}\mathbb{P}=0.$$ Attempt. Of course we have $\displaystyle \frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}\leqslant \frac{1}{\varepsilon} \varepsilon =1,$ but we don't get anything interesting by that (the same arguments holds for the other integral also). Thank you in advance.",Let be a random variable taking values in . Prove that: Attempt. Of course we have but we don't get anything interesting by that (the same arguments holds for the other integral also). Thank you in advance.,"X [0,+\infty] \lim_{\varepsilon\to 0^+}\frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}=0 ~~~~\mathrm{and~~~} 
\lim_{x \to +\infty}\frac{1}{x}\int\limits_{X\leqslant x}X\mathrm{d}\mathbb{P}=0. \displaystyle \frac{1}{\varepsilon}\int\limits_{X\leqslant \varepsilon}X\mathrm{d}\mathbb{P}\leqslant \frac{1}{\varepsilon} \varepsilon =1,","['probability', 'probability-theory', 'random-variables', 'means']"
53,Asymptotic Distribution of Order Statistic for a uniform random variable,Asymptotic Distribution of Order Statistic for a uniform random variable,,"I am trying to find the asymptotic distribution of an order statistic $X_{(n)}$ for  iid RVs $X_1, ..., X_n \sim \mathrm{Unif}(0,a)$ , where $a>0$ . The distribution for $X_{(n)}$ $$f(X_{(n)}=x) = \frac{nx^{n-1}}{a^n}I(0<x<a)$$ My gut reaction was to find the limit as $n\rightarrow \infty$ of the CDF, and see if this resembled another distribution.  This gave me $$\frac{x^n}{a^n}$$ My guess is there is a trick or a property I am forgetting.  Note: the actual problem was more involved, I simplified it to just include the component I unsure about.","I am trying to find the asymptotic distribution of an order statistic for  iid RVs , where . The distribution for My gut reaction was to find the limit as of the CDF, and see if this resembled another distribution.  This gave me My guess is there is a trick or a property I am forgetting.  Note: the actual problem was more involved, I simplified it to just include the component I unsure about.","X_{(n)} X_1, ..., X_n \sim \mathrm{Unif}(0,a) a>0 X_{(n)} f(X_{(n)}=x) = \frac{nx^{n-1}}{a^n}I(0<x<a) n\rightarrow \infty \frac{x^n}{a^n}","['probability', 'probability-theory', 'uniform-distribution', 'probability-limit-theorems', 'order-statistics']"
54,Ratings on a 1-5 star scale when total number of ratings not known.,Ratings on a 1-5 star scale when total number of ratings not known.,,"I work for a driving company who likes to hide what I consider important feedback. Right now I have an average rating of 4.61 on a 1-5 star rating scale. Once I figured out they were not going to tell me the data,I have been keeping track  of the up and downs. I have at least 11 ratings but I do not know the total number of ratings.I could have 20,30 or 50 ratings. Started data collection with: 4.81 4.68 4.7 4.71 4.72 4.73 4.62 4.6 4.58 4.59 4.61 Is there a way to figure out what my total rating number is with this data provided so I can predict future data?","I work for a driving company who likes to hide what I consider important feedback. Right now I have an average rating of 4.61 on a 1-5 star rating scale. Once I figured out they were not going to tell me the data,I have been keeping track  of the up and downs. I have at least 11 ratings but I do not know the total number of ratings.I could have 20,30 or 50 ratings. Started data collection with: 4.81 4.68 4.7 4.71 4.72 4.73 4.62 4.6 4.58 4.59 4.61 Is there a way to figure out what my total rating number is with this data provided so I can predict future data?",,"['probability', 'average']"
55,How many random variables greater than a threshold?,How many random variables greater than a threshold?,,"Given $T$ iid random variables $X_1,X_2,\cdots,X_T$ (for $T\to+\infty$ ). How many random variables exceed the threshold $a$ (for some given $a$ )? (Assuming that the random variables are positive.) My work: let $Z_i$ be a binary variable that is $1$ if $X_i\geq a$ . Thus, $\mathbb{E}[Z_i]=\Pr[X_i\geq a]$ and $$\sum_i\Pr[X_i\geq a]=T\Pr[X_1\geq a]$$ is the answer. So, unless $\Pr[X_1\geq a]=0$ , there are infinitely many random variables in the sequence that exceed the threshold $a$ . Is this intuitive? I mean $a$ could be anything and still we have infinitely many. If so, then, for $T$ iid exponentially distributed random variables, how could I choose $a$ to have $n$ random variables that are greater than $a$ ?","Given iid random variables (for ). How many random variables exceed the threshold (for some given )? (Assuming that the random variables are positive.) My work: let be a binary variable that is if . Thus, and is the answer. So, unless , there are infinitely many random variables in the sequence that exceed the threshold . Is this intuitive? I mean could be anything and still we have infinitely many. If so, then, for iid exponentially distributed random variables, how could I choose to have random variables that are greater than ?","T X_1,X_2,\cdots,X_T T\to+\infty a a Z_i 1 X_i\geq a \mathbb{E}[Z_i]=\Pr[X_i\geq a] \sum_i\Pr[X_i\geq a]=T\Pr[X_1\geq a] \Pr[X_1\geq a]=0 a a T a n a","['probability', 'probability-theory']"
56,Number of empty subway cars,Number of empty subway cars,,"I have task: There are $9$ passengers and they get into empty $5$ -car subway train. What is the probability of the fact, that exactly two cars will be empty? I know that the power of all possibilities is $5^9$ . Then I thought to pick two empty cars that is ${5\choose 2}$ possibilities, then pick three people that get to the rest of the cars, that is $9\cdot 8\cdot 7$ and the rest of the people have $3^6$ possibilities. I checked it on my calculator and it seems that the power of this event is bigger than the power of $\Omega$ . What is wrong?","I have task: There are passengers and they get into empty -car subway train. What is the probability of the fact, that exactly two cars will be empty? I know that the power of all possibilities is . Then I thought to pick two empty cars that is possibilities, then pick three people that get to the rest of the cars, that is and the rest of the people have possibilities. I checked it on my calculator and it seems that the power of this event is bigger than the power of . What is wrong?",9 5 5^9 {5\choose 2} 9\cdot 8\cdot 7 3^6 \Omega,"['probability', 'combinatorics']"
57,Minesweeper revisited,Minesweeper revisited,,"This is a followup query to the following: Minesweeper odds for this scenario, 2 different calculations I answered that query and now believe that my answer is wrong (explanation below).  I ask professional mathematicians to respond. In my answer, I assumed that each case was equally likely, and in my addendum-1 , which endorsed the OP's identification of 104 cases, I assumed that each of the 104 cases was equally likely.  I now question that assumption. In Minesweeper, there are always a greater number of unmined cells than mined cells.  Therefore, it seems to me that in the OP's query, a case that involved only 4 mines in the region is more likely than a case that involved 5 mines . Specifically, suppose that the underlying diagram which this minesweeper region came from  has $m$ mined cells and $t$ total cells with $\;p = m/t\;$ and $\;p < 1/2\;$ and $\;q = 1-p.\;$ In the OP's diagram there are 17 unknown cells, each of which may or may not contain a mine (i.e. cell Q could contain a mine).  Consider the following two  specific cases, each of which satisfy the original problem's constraints. $\underline{\text{Case 1}}$ Mines only in cells A, B, F, H, and N.  The chance of this case occuring is $p^5 \times q^{12}.$ $\underline{\text{Case 2}}$ Mines only in cells A, B, and G.  The chance of this case occuring is $p^3 \times q^{14}.$ Therefore, case 2 above is $\;(q/p)^2\;$ times more likely than case 1. Is my analysis correct?","This is a followup query to the following: Minesweeper odds for this scenario, 2 different calculations I answered that query and now believe that my answer is wrong (explanation below).  I ask professional mathematicians to respond. In my answer, I assumed that each case was equally likely, and in my addendum-1 , which endorsed the OP's identification of 104 cases, I assumed that each of the 104 cases was equally likely.  I now question that assumption. In Minesweeper, there are always a greater number of unmined cells than mined cells.  Therefore, it seems to me that in the OP's query, a case that involved only 4 mines in the region is more likely than a case that involved 5 mines . Specifically, suppose that the underlying diagram which this minesweeper region came from  has mined cells and total cells with and and In the OP's diagram there are 17 unknown cells, each of which may or may not contain a mine (i.e. cell Q could contain a mine).  Consider the following two  specific cases, each of which satisfy the original problem's constraints. Mines only in cells A, B, F, H, and N.  The chance of this case occuring is Mines only in cells A, B, and G.  The chance of this case occuring is Therefore, case 2 above is times more likely than case 1. Is my analysis correct?",m t \;p = m/t\; \;p < 1/2\; \;q = 1-p.\; \underline{\text{Case 1}} p^5 \times q^{12}. \underline{\text{Case 2}} p^3 \times q^{14}. \;(q/p)^2\;,['probability']
58,Is there an explicit solution of $y_{n}$ in this binomial coefficient relation?,Is there an explicit solution of  in this binomial coefficient relation?,y_{n},"In following, $x_{n}$ is a set of given numbers, n = 0, 1, 2, ..., $y_{n}$ is defined by the following relation: For example: ${\displaystyle {x_{1}=x_{0}y_{1} }}.$ ${\displaystyle {x_{2}={\binom {1}{0}}x_{0}y_{2} + {\binom {1}{1}}x_{1}y_{1}  }}.$ ${\displaystyle {x_{3}={\binom {2}{0}}x_{0}y_{3} + {\binom {2}{1}}x_{1}y_{2}  + {\binom {2}{2}}x_{2}y_{1}  }}.$ For simplicity, we can assume $x_{0} = 1$ . Q: Is there an explicit solution of $y_{n}$ in term of $x_{n}$ ? Thank you.","In following, is a set of given numbers, n = 0, 1, 2, ..., is defined by the following relation: For example: For simplicity, we can assume . Q: Is there an explicit solution of in term of ? Thank you.",x_{n} y_{n} {\displaystyle {x_{1}=x_{0}y_{1} }}. {\displaystyle {x_{2}={\binom {1}{0}}x_{0}y_{2} + {\binom {1}{1}}x_{1}y_{1}  }}. {\displaystyle {x_{3}={\binom {2}{0}}x_{0}y_{3} + {\binom {2}{1}}x_{1}y_{2}  + {\binom {2}{2}}x_{2}y_{1}  }}. x_{0} = 1 y_{n} x_{n},"['probability', 'stochastic-processes', 'random-variables', 'binomial-coefficients']"
59,Optimal strategy for this d6 game,Optimal strategy for this d6 game,,"In my attempts to learn the foundations, I was given the following game in a mock interview: Two players each roll a d6, and are not able to see each other's   rolls. The player with the higher value wins \$1. After the players   roll their dice, each player may either pay \$0.25 to increase their   individual roll by 2 or keep their roll. What is the optimal strategy   and payout? Consider the cases for which i) nothing happens when both   players roll the same number, and ii) the players keep rerolling (for free) until   different numbers appear. What is the best strategy here? Is it important for both players to have the same strategy for Nash/symmetric equilibrium (not sure what the terminology I should be using is)? What should my considerations be in calculating the expected value? Please help prod me to attempt deriving the strategy, thanks!","In my attempts to learn the foundations, I was given the following game in a mock interview: Two players each roll a d6, and are not able to see each other's   rolls. The player with the higher value wins \$1. After the players   roll their dice, each player may either pay \$0.25 to increase their   individual roll by 2 or keep their roll. What is the optimal strategy   and payout? Consider the cases for which i) nothing happens when both   players roll the same number, and ii) the players keep rerolling (for free) until   different numbers appear. What is the best strategy here? Is it important for both players to have the same strategy for Nash/symmetric equilibrium (not sure what the terminology I should be using is)? What should my considerations be in calculating the expected value? Please help prod me to attempt deriving the strategy, thanks!",,"['probability', 'game-theory', 'expected-value', 'dice']"
60,Poisson mixture process independence used to devastating effect on the Coupon collectors problem,Poisson mixture process independence used to devastating effect on the Coupon collectors problem,,"Proposition 5.2 of the book, Introduction to probability models by Sheldon Ross says that if we have a Poisson process and each event in the process is of type-1 with probability $p$ and type-2 with probability $1-p$ , then the number of type-1 and type-2 events are independent Poisson processes with rates $\lambda p$ and $\lambda (1-p)$ respectively. The independence is key here. It is then used as a powerful tool in example 5.17, where Ross addresses the coupon collectors problem. Quoting: There are $m$ different types of coupons. Each time a person collects a coupon it is, independently of ones previously obtained, a type $j$ coupon with probability $p_j$ , $\sum\limits_{j} p_j = 1$ . Let $N$ denote the number of coupons one needs to collect in order to have a complete collection of at least one of each type. Find $E[N]$ . In the solution, he starts with the straightforward approach, denoting by $N_j$ the number of coupons that must be collected to obtain a type $j$ coupon. We can then express $N$ as: $$N = \max_{1\leq j \leq m} N_j \tag{1}$$ He notes that the $N_j$ are geometric, but this method runs into a wall when we realize that the $N_j$ 's aren't independent. And this makes sense. If there were only two types of coupons, they would be competing each time we collected a coupon. So, if we need very few coupons to collect one for the first kind, it tells us it's a common coupon and so, we now know that we'll have to wait a long time to see the second coupon (meaning $N_1$ and $N_2$ are negatively correlated). Now, Ross considers the coupons arriving according to a Poisson process with rate $1$ . By proposition 5.2, the counting processes defining the arrivals of each of the coupon types (say $j$ ) are independent Poisson process with rates $1 . p_j$ . Now, define $X$ the time at which all coupons are collected and $X_j$ the time at which the first type $j$ coupon is collected. We get an equation very similar to (1): $$X = \max_{1\leq j \leq m} X_j \tag{2}$$ Now, we don't run into the wall since by proposition 5.2, the $X_j$ 's are independent. However, I haven't been convinced by the arguments presented for this. Why does the reasoning we used to conclude that the $N_j$ 's are negatively correlated not apply to the $X_j$ 's as well?","Proposition 5.2 of the book, Introduction to probability models by Sheldon Ross says that if we have a Poisson process and each event in the process is of type-1 with probability and type-2 with probability , then the number of type-1 and type-2 events are independent Poisson processes with rates and respectively. The independence is key here. It is then used as a powerful tool in example 5.17, where Ross addresses the coupon collectors problem. Quoting: There are different types of coupons. Each time a person collects a coupon it is, independently of ones previously obtained, a type coupon with probability , . Let denote the number of coupons one needs to collect in order to have a complete collection of at least one of each type. Find . In the solution, he starts with the straightforward approach, denoting by the number of coupons that must be collected to obtain a type coupon. We can then express as: He notes that the are geometric, but this method runs into a wall when we realize that the 's aren't independent. And this makes sense. If there were only two types of coupons, they would be competing each time we collected a coupon. So, if we need very few coupons to collect one for the first kind, it tells us it's a common coupon and so, we now know that we'll have to wait a long time to see the second coupon (meaning and are negatively correlated). Now, Ross considers the coupons arriving according to a Poisson process with rate . By proposition 5.2, the counting processes defining the arrivals of each of the coupon types (say ) are independent Poisson process with rates . Now, define the time at which all coupons are collected and the time at which the first type coupon is collected. We get an equation very similar to (1): Now, we don't run into the wall since by proposition 5.2, the 's are independent. However, I haven't been convinced by the arguments presented for this. Why does the reasoning we used to conclude that the 's are negatively correlated not apply to the 's as well?",p 1-p \lambda p \lambda (1-p) m j p_j \sum\limits_{j} p_j = 1 N E[N] N_j j N N = \max_{1\leq j \leq m} N_j \tag{1} N_j N_j N_1 N_2 1 j 1 . p_j X X_j j X = \max_{1\leq j \leq m} X_j \tag{2} X_j N_j X_j,"['probability', 'poisson-distribution', 'poisson-process', 'coupon-collector']"
61,Probability and marbles,Probability and marbles,,"My brother brings a certain number of his marbles to play with in my room. Each marble is distinct. He has 8 total marbles that are either red or blue. One day, I spotted two red marbles in my room. The probability that any two of his marbles (of those that he plays in my room), randomly chosen, both being red is 1/2. How many marbles does he bring into my room? I tried doing this: let x = number of red marbles So $(x/8)$ = probability of picking red marble and then $(x-1)/(8 - 1)$ = probability of picking second red marble. $(x/8)(x-1)/(7) = 1/2$ , but I got x to be a decimal which is not possible. EDIT:  I kept guessing and checking $\frac{x}{b}\cdot\frac{x-1}{b-1}=\frac{1}{2}$ , where $x =$ number of red balls, and $b=$ number of balls he brings into my room to get that $b=4$ and $x=3$ , but unsure how to get this solution formally.","My brother brings a certain number of his marbles to play with in my room. Each marble is distinct. He has 8 total marbles that are either red or blue. One day, I spotted two red marbles in my room. The probability that any two of his marbles (of those that he plays in my room), randomly chosen, both being red is 1/2. How many marbles does he bring into my room? I tried doing this: let x = number of red marbles So = probability of picking red marble and then = probability of picking second red marble. , but I got x to be a decimal which is not possible. EDIT:  I kept guessing and checking , where number of red balls, and number of balls he brings into my room to get that and , but unsure how to get this solution formally.",(x/8) (x-1)/(8 - 1) (x/8)(x-1)/(7) = 1/2 \frac{x}{b}\cdot\frac{x-1}{b-1}=\frac{1}{2} x = b= b=4 x=3,['probability']
62,"Are there two dependent, but uncorrelated random variables $X,Y\sim \mathcal {N}(0,1)$ such that their sum $X+Y$ is normal, i.e. $\mathcal {N}(0,2)$?","Are there two dependent, but uncorrelated random variables  such that their sum  is normal, i.e. ?","X,Y\sim \mathcal {N}(0,1) X+Y \mathcal {N}(0,2)","Context : The question comes from another question I saw regarding the characterization of Brownian motion : does it hold that for all $t>s\ge 0$ $$\operatorname{Cov}(B_s, B_t-B_s) = 0\ \ \ \ \Longrightarrow\ \  B_s \perp \!\!\! \perp B_t-B_s \text{ (independent})$$ provided that $B_0 = 0$ and $B_t-B_s \sim \mathcal N(0,t-s)$ ? The asker did not assume that $(B_t)_{t\ge 0}$ is a Gaussian process. So I thought the answer is ""no"" because in general mere $\operatorname{Cov}(B_s,B_t-B_s) = 0$ does not imply $B_s \perp \!\!\!\perp B_t-B_s$ unless $(B_s,B_t-B_s)$ is jointly normal. (Some counterexamples can be found here in Wikipedia.) In the linked page, we can find various pairs of dependent normal random variables $X,Y \sim \mathcal{N}(0,1)$ with $\operatorname{Cov}(X,Y) = 0$ . Also we can generate many other examples using similar ideas and techniques. However, I have failed to find an example where $X+Y$ is also normally distributed, which must hold in the setting of the original question, i.e. $$ \underbrace{B_1}_{ =X \sim \mathcal N(0,1)} + \underbrace{B_2-B_1}_{ =Y\sim \mathcal N(0,1)} = \underbrace{B_2}_{=X+Y\sim \mathcal N(0,2)}. $$ So my question is: are there uncorrelated dependent r.v.'s $X,Y \sim \mathcal {N}(0,1)$ such that their sum $X+Y$ is also distributed normally, i.e. $\mathcal N(0,2)$ ? If there are, can we construct an example explicitly? My thought : Essentially the given condition is providing information about the moments of all orders $$ E[X^n],\ \, E[Y^n],\ \  E[(X+Y)^n]\qquad \forall n\ge 1. $$ However, we cannot pin down, for instance, the values of $E[X^2Y]$ or $E[XY^2]$ using this information only. This suggests that the given condition does not determine the distribution of $(X,Y)$ uniquely. So my guess is that the answer is affirmative. I've also tried an abstract approach to find a characteristic function (Fourier transform or a positive-definite function equivalently) $\hat \mu(s,t) = \int_{\mathbb R^2} e^{i(sx+ty)}d\mu(x,y)$ satisfying $d\mu(x,y) \neq (2\pi)^{-1}e^{-(x^2+y^2)/2}dxdy$ $$ \hat\mu (t,0) = \hat\mu(0,t) = e^{-t^2/2},\quad \hat\mu(t,t) = e^{-t^2}\qquad\forall t\in\mathbb R, $$ but was in vain.","Context : The question comes from another question I saw regarding the characterization of Brownian motion : does it hold that for all provided that and ? The asker did not assume that is a Gaussian process. So I thought the answer is ""no"" because in general mere does not imply unless is jointly normal. (Some counterexamples can be found here in Wikipedia.) In the linked page, we can find various pairs of dependent normal random variables with . Also we can generate many other examples using similar ideas and techniques. However, I have failed to find an example where is also normally distributed, which must hold in the setting of the original question, i.e. So my question is: are there uncorrelated dependent r.v.'s such that their sum is also distributed normally, i.e. ? If there are, can we construct an example explicitly? My thought : Essentially the given condition is providing information about the moments of all orders However, we cannot pin down, for instance, the values of or using this information only. This suggests that the given condition does not determine the distribution of uniquely. So my guess is that the answer is affirmative. I've also tried an abstract approach to find a characteristic function (Fourier transform or a positive-definite function equivalently) satisfying but was in vain.","t>s\ge 0 \operatorname{Cov}(B_s, B_t-B_s) = 0\ \ \ \ \Longrightarrow\ \  B_s \perp \!\!\! \perp B_t-B_s \text{ (independent}) B_0 = 0 B_t-B_s \sim \mathcal N(0,t-s) (B_t)_{t\ge 0} \operatorname{Cov}(B_s,B_t-B_s) = 0 B_s \perp \!\!\!\perp B_t-B_s (B_s,B_t-B_s) X,Y \sim \mathcal{N}(0,1) \operatorname{Cov}(X,Y) = 0 X+Y 
\underbrace{B_1}_{ =X \sim \mathcal N(0,1)} + \underbrace{B_2-B_1}_{ =Y\sim \mathcal N(0,1)} = \underbrace{B_2}_{=X+Y\sim \mathcal N(0,2)}.
 X,Y \sim \mathcal {N}(0,1) X+Y \mathcal N(0,2) 
E[X^n],\ \, E[Y^n],\ \  E[(X+Y)^n]\qquad \forall n\ge 1.
 E[X^2Y] E[XY^2] (X,Y) \hat \mu(s,t) = \int_{\mathbb R^2} e^{i(sx+ty)}d\mu(x,y) d\mu(x,y) \neq (2\pi)^{-1}e^{-(x^2+y^2)/2}dxdy 
\hat\mu (t,0) = \hat\mu(0,t) = e^{-t^2/2},\quad \hat\mu(t,t) = e^{-t^2}\qquad\forall t\in\mathbb R,
","['probability', 'probability-theory', 'measure-theory', 'probability-distributions']"
63,Classify the states of a random walk with reflection at state zero,Classify the states of a random walk with reflection at state zero,,"Consider the following Markov chain, which is as a random walk with reflection at state zero. Classify the states of the chain (positive/null recurrent or transient). Solution: if $p<\frac{1}{2}$ , all the states are positive recurrent; if $p=\frac{1}{2}$ , all states are null recurrent, and in the case $p>\frac{1}{2}$ we have that every state is transient. As the chain is irreducible all the states will be of the same type. Studying the state $0$ seems to be the best option. I tried proving if $\sum_{n\geq1}p_{00}(n)=\infty$ to see if $0$ is recurrent. $\sum_{n\geq1}p_{00}(2n)=\sum_{n\geq1}{2n\choose n}p^nq^n$$\sim \sum_{n\geq1}\frac{(4pq)^n}{\sqrt{\pi n}}$ (by Stirling), which diverges iff $p=\frac{1}{2}$ , but for $p<\frac{1}{2}$ the states are also recurrent... To prove positive/null recurrence we know that a recurrent state is null-recurrent iff $p_{ii}(n)\to0$ as $n\to\infty$ , but $\lim_{n\to\infty}\frac{(4pq)^n}{\sqrt{\pi n}}=0$ , and we already now that for $p<\frac{1}{2}$ this should not happen. EDIT 1 While proving $\sum_{n\geq1}p_{00}(n)=\infty$ I was assuming that $p_{00}(2n+1)=0$ , which is clearly wrong as we can go from $0$ to $0$ in an odd number of steps thanks to $p_{00}(1)=q$ . Now I'm trying to calculate these $p_{00}(n)$ but I don't succeed. EDIT 2 - New attempt Let $T_i$ be the return time of a certain state (i.e. first time we hit $i$ since we leave it). Then the state $i$ is transient if $Pr(T_i<\infty)=1$ and recurrent if $Pr(T_i<\infty)<1$ . In this case we have that $Pr(T_i=2n+1)=0$ for $n\geq1$ , $Pr(T_i=1)=q,\ Pr(T_i=2n+2)=pq\cdot C_{2n}\cdot(pq)^n\sim$$\sim\frac{pq}{\sqrt\pi}\frac{(4pq)^n}{(n+1)\sqrt n}$ (by Stirling), as we first must go from $0$ to $1$ (and the last step from $1$ to $0$ ) and then in $1$ we can go right a number of steps always $\geq$ than the ones we go left. Then, $Pr(T_i<\infty)=Pr(T_i=1)+\sum_{n\geq0}Pr(T_i=2n+2)=q+pq+\frac{pq}{\sqrt\pi}\sum_{n\geq1}\frac{(4pq)^n}{(n+1)\sqrt n}$ , but I don't know how to compute this sum.","Consider the following Markov chain, which is as a random walk with reflection at state zero. Classify the states of the chain (positive/null recurrent or transient). Solution: if , all the states are positive recurrent; if , all states are null recurrent, and in the case we have that every state is transient. As the chain is irreducible all the states will be of the same type. Studying the state seems to be the best option. I tried proving if to see if is recurrent. (by Stirling), which diverges iff , but for the states are also recurrent... To prove positive/null recurrence we know that a recurrent state is null-recurrent iff as , but , and we already now that for this should not happen. EDIT 1 While proving I was assuming that , which is clearly wrong as we can go from to in an odd number of steps thanks to . Now I'm trying to calculate these but I don't succeed. EDIT 2 - New attempt Let be the return time of a certain state (i.e. first time we hit since we leave it). Then the state is transient if and recurrent if . In this case we have that for , (by Stirling), as we first must go from to (and the last step from to ) and then in we can go right a number of steps always than the ones we go left. Then, , but I don't know how to compute this sum.","p<\frac{1}{2} p=\frac{1}{2} p>\frac{1}{2} 0 \sum_{n\geq1}p_{00}(n)=\infty 0 \sum_{n\geq1}p_{00}(2n)=\sum_{n\geq1}{2n\choose n}p^nq^n\sim \sum_{n\geq1}\frac{(4pq)^n}{\sqrt{\pi n}} p=\frac{1}{2} p<\frac{1}{2} p_{ii}(n)\to0 n\to\infty \lim_{n\to\infty}\frac{(4pq)^n}{\sqrt{\pi n}}=0 p<\frac{1}{2} \sum_{n\geq1}p_{00}(n)=\infty p_{00}(2n+1)=0 0 0 p_{00}(1)=q p_{00}(n) T_i i i Pr(T_i<\infty)=1 Pr(T_i<\infty)<1 Pr(T_i=2n+1)=0 n\geq1 Pr(T_i=1)=q,\ Pr(T_i=2n+2)=pq\cdot C_{2n}\cdot(pq)^n\sim\sim\frac{pq}{\sqrt\pi}\frac{(4pq)^n}{(n+1)\sqrt n} 0 1 1 0 1 \geq Pr(T_i<\infty)=Pr(T_i=1)+\sum_{n\geq0}Pr(T_i=2n+2)=q+pq+\frac{pq}{\sqrt\pi}\sum_{n\geq1}\frac{(4pq)^n}{(n+1)\sqrt n}","['probability', 'probability-theory', 'stochastic-processes', 'markov-chains', 'random-walk']"
64,Variance of taking balls from a bag question,Variance of taking balls from a bag question,,"A bag contains $2$ white balls and $2$ black balls. Each instance a ball is taken from the bag, if it's white it's returned to the bag and if it's black it's replaced by a white ball. The game ends when no black balls remain in the bag. Let $Y$ be the number of instances of the game; calculate $\operatorname{var}(Y).$ Answer in the book: $14.$ I am not sure how to write the probability function of $Y;$ please help and thanks in advance!","A bag contains white balls and black balls. Each instance a ball is taken from the bag, if it's white it's returned to the bag and if it's black it's replaced by a white ball. The game ends when no black balls remain in the bag. Let be the number of instances of the game; calculate Answer in the book: I am not sure how to write the probability function of please help and thanks in advance!",2 2 Y \operatorname{var}(Y). 14. Y;,"['probability', 'random-variables', 'variance']"
65,Probability Proof. $P(A | B) = P(A | B^c)$,Probability Proof.,P(A | B) = P(A | B^c),"Be A,B are independent envents, if and only if $P(A|B) = P(A|B^c)$ I know that $P(A) = P(A∩B) + P(A∩B^c)$ and $P(B)= 1- P(B^c)$ So... $\frac {P(A∩B)}{P(B)} = \frac {P(A∩B^c)}{P(B^c)}$ hence $(1-P(B)) P(A∩B) = P(B)P(A∩B^c)$ $P(A∩B)=P(B)P(A|B^c)$ (this change is not very clear to me) But i can't see how continue... Thanks for the time :)","Be A,B are independent envents, if and only if I know that and So... hence (this change is not very clear to me) But i can't see how continue... Thanks for the time :)",P(A|B) = P(A|B^c) P(A) = P(A∩B) + P(A∩B^c) P(B)= 1- P(B^c) \frac {P(A∩B)}{P(B)} = \frac {P(A∩B^c)}{P(B^c)} (1-P(B)) P(A∩B) = P(B)P(A∩B^c) P(A∩B)=P(B)P(A|B^c),"['probability', 'elementary-set-theory', 'independence']"
66,Property of distributions over R x R with identical marginal distributions,Property of distributions over R x R with identical marginal distributions,,"Let $D_1$ and $D_2$ be probability distributions on $\mathbb{R} \times \mathbb{R}$ with identical marginal distributions (i.e. the distribution of the first component of $D_1$ is the same as the distribution of the first component of $D_2$ , and similarly for the second components). Let $e_1 = \mathbb{E}_{ D_1} [x - y]$ and $e_2 = \mathbb{E}_{ D_2} [x -y]$ . (Assume that these quantities are defined -- they could be finite or infinite.) Does $e_1$ necessarily equal $e_2$ ? (Note that this does not immediately follow from linearity of expectation, because $\mathbb{E}[x - y]$ could be defined even if $\mathbb{E}[x]$ and $\mathbb{E}[y]$ are not.)","Let and be probability distributions on with identical marginal distributions (i.e. the distribution of the first component of is the same as the distribution of the first component of , and similarly for the second components). Let and . (Assume that these quantities are defined -- they could be finite or infinite.) Does necessarily equal ? (Note that this does not immediately follow from linearity of expectation, because could be defined even if and are not.)",D_1 D_2 \mathbb{R} \times \mathbb{R} D_1 D_2 e_1 = \mathbb{E}_{ D_1} [x - y] e_2 = \mathbb{E}_{ D_2} [x -y] e_1 e_2 \mathbb{E}[x - y] \mathbb{E}[x] \mathbb{E}[y],"['real-analysis', 'probability', 'probability-theory', 'statistics', 'marginal-distribution']"
67,"If $Y = 1 - X$ then is the cdf of $Y$, 1 for y ≥ 1?","If  then is the cdf of , 1 for y ≥ 1?",Y = 1 - X Y,"$$F_{X}(x)=\begin{cases} 0, & x<0 \\ x, & 0 \le x < 1 \\ 1, & x ≥ 1. \end{cases}$$ The question is contained in a text book: This is how I have proceeded: $P(y≥1) = P[(1-x)≥1] = P(x\leq 0) = 0$ . I don't know how to get $1$ .",The question is contained in a text book: This is how I have proceeded: . I don't know how to get .,"F_{X}(x)=\begin{cases} 0, & x<0 \\ x, & 0 \le x < 1 \\ 1, & x ≥ 1. \end{cases} P(y≥1) = P[(1-x)≥1] = P(x\leq 0) = 0 1",['probability']
68,Expected overlap of n circles of equal area randomly placed inside a circle of larger area,Expected overlap of n circles of equal area randomly placed inside a circle of larger area,,"Say I have an outer circle of area $\Omega$ . If I randomly position n circles of area $\omega$ ( $0 \le \omega \le \Omega$ ) completely inside the outer circle, then what is the expected overlap area of the inner circles? Assume uniform random positioning. As in, in order to select an inner circle center point, uniformly sample from the points in the outer circle, re-sampling if the point doesn't place the inner circle entirely inside the outer circle. I've calculated the answer fairly easily through simulation, but I'm looking for an analytic solution $E(overlap)=f(n,\frac{\omega}{\Omega})$ . from simulations I'm pretty sure that $\frac{\partial{f(n,\frac{\omega}{\Omega})}}{\partial{\frac{\omega}{\Omega}}}=g(n)$ , and from common sense I know that $f(n,1)=\Omega$ and $f(n,0)=0$ , but beyond that I'm stuck. EDIT: I'm also pretty sure that $f(\inf,\frac{\omega}{\Omega}) = (2\sqrt{\frac{\omega}{\Omega}}-1)^2$ EDIT EDIT: Here are a few examples for $N=3$ , $\frac{\omega}{\Omega}=.4$ . I randomly placed three circles and highlighted the overlap. ex1 ex2","Say I have an outer circle of area . If I randomly position n circles of area ( ) completely inside the outer circle, then what is the expected overlap area of the inner circles? Assume uniform random positioning. As in, in order to select an inner circle center point, uniformly sample from the points in the outer circle, re-sampling if the point doesn't place the inner circle entirely inside the outer circle. I've calculated the answer fairly easily through simulation, but I'm looking for an analytic solution . from simulations I'm pretty sure that , and from common sense I know that and , but beyond that I'm stuck. EDIT: I'm also pretty sure that EDIT EDIT: Here are a few examples for , . I randomly placed three circles and highlighted the overlap. ex1 ex2","\Omega \omega 0 \le \omega \le \Omega E(overlap)=f(n,\frac{\omega}{\Omega}) \frac{\partial{f(n,\frac{\omega}{\Omega})}}{\partial{\frac{\omega}{\Omega}}}=g(n) f(n,1)=\Omega f(n,0)=0 f(\inf,\frac{\omega}{\Omega}) = (2\sqrt{\frac{\omega}{\Omega}}-1)^2 N=3 \frac{\omega}{\Omega}=.4","['probability', 'geometry', 'circles']"
69,Continuity of mean and quantile functionals,Continuity of mean and quantile functionals,,"We say the functional $\gamma$ is continuous if for all $\varepsilon>0$ and two cdfs $F$ and $G$ , there exists a $\delta>0$ such that $\|G-F\|_\infty=\sup_{t\in\mathbb{R}}|G(t)-F(t)|\leq\delta$ implies $|\gamma(G)-\gamma(F)|\leq\varepsilon$ . Now try to prove or disprove the continuity of mean and quatile functional, which are mean: $F\to\int xdF(x)$ ; quantile: $Q_{\alpha}(F)=\inf \{t\in\mathbb{R}|F(t)\geq \alpha\}$ . Intuitively, I think mean functional is continuous however I don't know how to bound the integral as it contains the derivative and then control it via the sup-norm $\|\cdot\|_\infty$ between $F$ and $G$ . While quantile seems to be more complicated and I wonder if there exist some tricks to transfer the definition to a more direct form with respect the the sup-norm. Thanks for the reading.:)","We say the functional is continuous if for all and two cdfs and , there exists a such that implies . Now try to prove or disprove the continuity of mean and quatile functional, which are mean: ; quantile: . Intuitively, I think mean functional is continuous however I don't know how to bound the integral as it contains the derivative and then control it via the sup-norm between and . While quantile seems to be more complicated and I wonder if there exist some tricks to transfer the definition to a more direct form with respect the the sup-norm. Thanks for the reading.:)",\gamma \varepsilon>0 F G \delta>0 \|G-F\|_\infty=\sup_{t\in\mathbb{R}}|G(t)-F(t)|\leq\delta |\gamma(G)-\gamma(F)|\leq\varepsilon F\to\int xdF(x) Q_{\alpha}(F)=\inf \{t\in\mathbb{R}|F(t)\geq \alpha\} \|\cdot\|_\infty F G,"['probability', 'functional-analysis', 'statistics', 'probability-distributions']"
70,Does setting records in a sport become less likely (under certain assumptions)?,Does setting records in a sport become less likely (under certain assumptions)?,,"Problem Let $X_{j}$ be the number of seconds $j$ -th swimmer takes from one end of the pool to the other, where $X_{1}, X_{2}, ...$ are i.i.d. with a continuous distribution. We will say that the $j$ -th swimmer sets a records if $X_{j}$ is greater than all of $X_{j-1}, ..., X_{1}.$ Is the event that ""the 110th swimmer sets a record"" independent of the event that ""the 111th swimmer sets a record""? Approach : Prove $P(I_{111}=1, I_{110}=1) = P(I_{111}=1)P(I_{110}=1)$ where $I_{j}$ is an indicator random variable for the $j$ -th person setting a record. $P(I_{j} = 1) = \frac{1}{j}$ , since by i.i.d. properties, all of the first $j$ swimmers are equally likely to set the record. $P(I_{111}=1, I_{110}=1) = \frac{109!}{111!}$ , since we fix the 111-th and 110-th swimmers in record setting positions. Then, $$P(I_{111}=1, I_{110}=1) = \frac{109!}{111!} = \frac{1}{111 * 110} = P(I_{111} = 1) * P(I_{110} = 1).$$ Thus, the events in question are independent . Intuition Suppose a million swimmers participate in the competition. If the $999999$ -th swimmer sets a record, the swimmer probably completed the task in an incredible short period of time, since $999998$ swimmers before him had chances to set records. This means that for the $1000000$ -th swimmer to set a new record, they will probably need to complete the task in an extremely unlikely amount of time. So, the events in question are dependent . Question I am having trouble reconciling my intuition with the result obtained after doing the computation. I have a suspicion the key is in the fact that $X_{j}$ are i.i.d., Any pointers? Note The question comes from strategic practice and homework 4 of Stat110 .","Problem Let be the number of seconds -th swimmer takes from one end of the pool to the other, where are i.i.d. with a continuous distribution. We will say that the -th swimmer sets a records if is greater than all of Is the event that ""the 110th swimmer sets a record"" independent of the event that ""the 111th swimmer sets a record""? Approach : Prove where is an indicator random variable for the -th person setting a record. , since by i.i.d. properties, all of the first swimmers are equally likely to set the record. , since we fix the 111-th and 110-th swimmers in record setting positions. Then, Thus, the events in question are independent . Intuition Suppose a million swimmers participate in the competition. If the -th swimmer sets a record, the swimmer probably completed the task in an incredible short period of time, since swimmers before him had chances to set records. This means that for the -th swimmer to set a new record, they will probably need to complete the task in an extremely unlikely amount of time. So, the events in question are dependent . Question I am having trouble reconciling my intuition with the result obtained after doing the computation. I have a suspicion the key is in the fact that are i.i.d., Any pointers? Note The question comes from strategic practice and homework 4 of Stat110 .","X_{j} j X_{1}, X_{2}, ... j X_{j} X_{j-1}, ..., X_{1}. P(I_{111}=1, I_{110}=1) = P(I_{111}=1)P(I_{110}=1) I_{j} j P(I_{j} = 1) = \frac{1}{j} j P(I_{111}=1, I_{110}=1) = \frac{109!}{111!} P(I_{111}=1, I_{110}=1) = \frac{109!}{111!} = \frac{1}{111 * 110} = P(I_{111} = 1) * P(I_{110} = 1). 999999 999998 1000000 X_{j}","['probability', 'probability-theory', 'statistics']"
71,"Probability that $AX^2+BX+C=0$ has only real roots for $A,B,C \sim Unif(0,1)$ [duplicate]",Probability that  has only real roots for  [duplicate],"AX^2+BX+C=0 A,B,C \sim Unif(0,1)","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . From chapter 6, practice exercise 26 (b) from ""A First Course in Probability"" by Sheldon Ross (working it for my own recreation): Given R.V.s $A,B,C\sim_{iid}Unif(0,1)$ and asked to find the probability that $AX^2+BX+C=0$ has real roots (ie $B^2>4AC$ ). Can someone help me understand how to set up the integral to compute the desired probability: $$ Pr(B^2>4AC)=Pr(B>2\sqrt{AC}) $$ * $\{B<-2\sqrt{AC}\}$ has probability zero since $B\sim Unif(0,1)$ and, therefore, cannot be negative. I understand that, in order for $B$ to be between 0 and 1, we need $0<\sqrt{AC}<\frac{1}{2} \rightarrow 0<AC <\frac{1}{4}$ , but I am having trouble coming up with an integral that makes sense. Thanks!","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . From chapter 6, practice exercise 26 (b) from ""A First Course in Probability"" by Sheldon Ross (working it for my own recreation): Given R.V.s and asked to find the probability that has real roots (ie ). Can someone help me understand how to set up the integral to compute the desired probability: * has probability zero since and, therefore, cannot be negative. I understand that, in order for to be between 0 and 1, we need , but I am having trouble coming up with an integral that makes sense. Thanks!","A,B,C\sim_{iid}Unif(0,1) AX^2+BX+C=0 B^2>4AC 
Pr(B^2>4AC)=Pr(B>2\sqrt{AC})
 \{B<-2\sqrt{AC}\} B\sim Unif(0,1) B 0<\sqrt{AC}<\frac{1}{2} \rightarrow 0<AC <\frac{1}{4}","['probability', 'probability-distributions']"
72,Determine the probability,Determine the probability,,"Joe, who owns a grocery store, has ordered tins of chickpeas and lentils. When unpacking the tins, he finds that one box contains 10 tins that have lost their labels. The tins are identical but after looking through his invoices, he has determined that 7 of the tins contain chickpeas and 3 contain lentils. Joe decides to take them home since he is unable to sell them without a label. He will open one tin each day and use whatever it contains. Determine the probability that he opens at least one tin of each over the next 3 nights.","Joe, who owns a grocery store, has ordered tins of chickpeas and lentils. When unpacking the tins, he finds that one box contains 10 tins that have lost their labels. The tins are identical but after looking through his invoices, he has determined that 7 of the tins contain chickpeas and 3 contain lentils. Joe decides to take them home since he is unable to sell them without a label. He will open one tin each day and use whatever it contains. Determine the probability that he opens at least one tin of each over the next 3 nights.",,['probability']
73,Removed Archer example from wikipedia.,Removed Archer example from wikipedia.,,"I have question about example illustration Convergence of random variables in probability but not almost surely. Suppose a person takes a bow and starts shooting arrows at a target. Let $X_n$ be his score in $n$ -th shot. Initially he will be very likely to score zeros, but as the time goes and his archery skill increases, he will become more and more likely to hit the bullseye and score $10$ points. After years of practice the probability that he hit anything but $10$ will be getting increasingly smaller and smaller and will converge to $0$ . Thus, the sequence $X_n$ converges in probability to $X = 10$ . Note that $X_n$ does not converge almost surely however. No matter how professional the archer becomes, there will always be a small probability of making an error. Thus the sequence $(X_n)$ will never turn stationary: there will always be non-perfect scores in it, even if they are becoming increasingly less frequent. https://en.wikipedia.org/w/index.php?title=Convergence_of_random_variables&diff=879355996&oldid=879219919 For me this example is true. But not for 69.181.249.190. Why? You have any idea? 69.181.249.190 talk‎ 36,722 bytes -957‎ →‎Convergence in probability: removed false archer example","I have question about example illustration Convergence of random variables in probability but not almost surely. Suppose a person takes a bow and starts shooting arrows at a target. Let be his score in -th shot. Initially he will be very likely to score zeros, but as the time goes and his archery skill increases, he will become more and more likely to hit the bullseye and score points. After years of practice the probability that he hit anything but will be getting increasingly smaller and smaller and will converge to . Thus, the sequence converges in probability to . Note that does not converge almost surely however. No matter how professional the archer becomes, there will always be a small probability of making an error. Thus the sequence will never turn stationary: there will always be non-perfect scores in it, even if they are becoming increasingly less frequent. https://en.wikipedia.org/w/index.php?title=Convergence_of_random_variables&diff=879355996&oldid=879219919 For me this example is true. But not for 69.181.249.190. Why? You have any idea? 69.181.249.190 talk‎ 36,722 bytes -957‎ →‎Convergence in probability: removed false archer example",X_n n 10 10 0 X_n X = 10 X_n (X_n),"['probability', 'convergence-divergence', 'random-variables']"
74,Marginalizing by sampling from the joint distribution,Marginalizing by sampling from the joint distribution,,"For two random variables $x$ and $y$ , if I can sample from the joint distribution $p(x, y)$ , I can obtain samples from the marginal $p(x)$ by sampling from the joint distribution and ignoring the values of $y$ . I want to make a formal argument for this. Something like: $$ \begin{align} \mathbb{E}_{x \sim p(x)} [f(x)] &= \int_{x \in \mathcal{X}} f(x)\,p(x)\,dx \\ &= \int_{x \in \mathcal{X}} f(x)\,\int_{y \in \mathcal{Y}} p(x, y)\,dy\,dx \\ &= \int_{x \in \mathcal{X}} \int_{y \in \mathcal{Y}}  f(x)\,p(x, y)\,dy\,dx \\ &= \mathbb{E}_{x, y \sim p(x, y)} [f(x)] \end{align} $$ Is this a reasonable argument?","For two random variables and , if I can sample from the joint distribution , I can obtain samples from the marginal by sampling from the joint distribution and ignoring the values of . I want to make a formal argument for this. Something like: Is this a reasonable argument?","x y p(x, y) p(x) y 
\begin{align}
\mathbb{E}_{x \sim p(x)} [f(x)]
&= \int_{x \in \mathcal{X}} f(x)\,p(x)\,dx \\
&= \int_{x \in \mathcal{X}} f(x)\,\int_{y \in \mathcal{Y}} p(x, y)\,dy\,dx \\
&= \int_{x \in \mathcal{X}} \int_{y \in \mathcal{Y}}  f(x)\,p(x, y)\,dy\,dx \\
&= \mathbb{E}_{x, y \sim p(x, y)} [f(x)]
\end{align}
","['probability', 'probability-distributions', 'marginal-distribution']"
75,justification of $\operatorname {E} \left[2X\operatorname {E} [X]\right] = 2\operatorname {E} [X]\operatorname {E} [X]$,justification of,\operatorname {E} \left[2X\operatorname {E} [X]\right] = 2\operatorname {E} [X]\operatorname {E} [X],"I am learning Variance . $${\displaystyle {\begin{aligned}\operatorname {Var} (X)&=\operatorname {E} \left[(X-\operatorname {E} [X])^{2}\right]\\[4pt]&=\operatorname {E} \left[X^{2}-2X\operatorname {E} [X]+\operatorname {E} [X]^{2}\right]\\[4pt]&=\operatorname {E} \left[X^{2}\right]-2\operatorname {E} [X]\operatorname {E} [X]+\operatorname {E} [X]^{2}\\[4pt]&=\operatorname {E} \left[X^{2}\right]-\operatorname {E} [X]^{2}\end{aligned}}} $$ where, the part $$\operatorname {E} \left[2X\operatorname {E} [X]\right] = 2\operatorname {E} [X]\operatorname {E} [X] $$ is a little bit difficult to justify, can anyone give a hint? which rule can apply this.","I am learning Variance . where, the part is a little bit difficult to justify, can anyone give a hint? which rule can apply this.","{\displaystyle {\begin{aligned}\operatorname {Var} (X)&=\operatorname {E} \left[(X-\operatorname {E} [X])^{2}\right]\\[4pt]&=\operatorname {E} \left[X^{2}-2X\operatorname {E} [X]+\operatorname {E} [X]^{2}\right]\\[4pt]&=\operatorname {E} \left[X^{2}\right]-2\operatorname {E} [X]\operatorname {E} [X]+\operatorname {E} [X]^{2}\\[4pt]&=\operatorname {E} \left[X^{2}\right]-\operatorname {E} [X]^{2}\end{aligned}}}
 \operatorname {E} \left[2X\operatorname {E} [X]\right] = 2\operatorname {E} [X]\operatorname {E} [X]
",['probability']
76,Two wins in a lottery. Good chance or just luck? [duplicate],Two wins in a lottery. Good chance or just luck? [duplicate],,"This question already has answers here : If I double my lottery tickets, do I double my chances of winning? [duplicate] (2 answers) Closed last year . I've a probability question. ""I bought a lottery ticket where just wins and blanks are possible. I don't know about the chance to win.  With the first lottery ticket i won. Know it could be just luck or the chance to win is ""good"". I took a second ticket and won again. Was this now just luck again or can i say with a specific guarantee, the chance to win is ""good"" (whatever ""good"" means.) Any approaches welcome. Thanks for your help and interest Max","This question already has answers here : If I double my lottery tickets, do I double my chances of winning? [duplicate] (2 answers) Closed last year . I've a probability question. ""I bought a lottery ticket where just wins and blanks are possible. I don't know about the chance to win.  With the first lottery ticket i won. Know it could be just luck or the chance to win is ""good"". I took a second ticket and won again. Was this now just luck again or can i say with a specific guarantee, the chance to win is ""good"" (whatever ""good"" means.) Any approaches welcome. Thanks for your help and interest Max",,"['probability', 'random', 'lotteries']"
77,Probability of ⁿC₇ being divisible by 12,Probability of ⁿC₇ being divisible by 12,,"Let n be a natural number, then, 1.) Probability that ⁿC₇ is divisible by 7. This one I could solve by observing a pattern in by writing 7 consecutive digits, I observed that for every 7 consecutive natural numbers starting from 7, there was only 1 value of n which made ⁿC₇ divisible by 7. Hence, the required probability was 1/7. Edit 1: I realised that I did a mistake while calculating and got the answer by mistake, but the answer given in the book  is 1/7 . Edit 2: as pointed out in the comments, that for the condition doesn't hold true for any n<49, I did some rigorous calculation and found that all natural numbers from  49≤n<98 , only 7 satisfy the given condition . I found the same for the next 49 numbers. Can this be generalised to all natural numbers? This gives the probability 7/49 , = 1/7. 2.) Probability that ⁿC₇ is divisible by 12. I tried this the same way I did the above question but couldn't see any simple pattern for 12. Is there a general, more elegant way to solve these kind of problems?","Let n be a natural number, then, 1.) Probability that ⁿC₇ is divisible by 7. This one I could solve by observing a pattern in by writing 7 consecutive digits, I observed that for every 7 consecutive natural numbers starting from 7, there was only 1 value of n which made ⁿC₇ divisible by 7. Hence, the required probability was 1/7. Edit 1: I realised that I did a mistake while calculating and got the answer by mistake, but the answer given in the book  is 1/7 . Edit 2: as pointed out in the comments, that for the condition doesn't hold true for any n<49, I did some rigorous calculation and found that all natural numbers from  49≤n<98 , only 7 satisfy the given condition . I found the same for the next 49 numbers. Can this be generalised to all natural numbers? This gives the probability 7/49 , = 1/7. 2.) Probability that ⁿC₇ is divisible by 12. I tried this the same way I did the above question but couldn't see any simple pattern for 12. Is there a general, more elegant way to solve these kind of problems?",,"['probability', 'elementary-number-theory', 'divisibility']"
78,Actuarial practice exam: Find number of exponential data values above threshold given MLE.,Actuarial practice exam: Find number of exponential data values above threshold given MLE.,,"I was going thorough an actuarial exam and came across a problem that I can't figure out. Here is the problem as stated on the practice exam: You are given: $\bullet$ An insurance product with a per loss limit of 200 covers losses from an exponential distribution with parameter $\theta$ . $\bullet$ Based on the following table, the maximum likelihood estimate of $\theta$ is 168. $$\begin{array}{|c | c | c |}\hline \text{Size of loss} & \text{Number of claims} & \text{Sum of losses} \\ \hline \text{Less than  } 200 & 1,114 & 142,752\\ \hline \text{At least  } 200 & N & 200N \\ \hline \end{array}$$ Calculate $N$ for the table above. The answer is: $N$ is less than 250. My question: How can we know for sure that $N$ is less than 250? It can be thought of as a random variable, couldn't it? It could be that there is a single loss above 200 but very large so that the overall average is still 168, yes? It seems that we are supposed to assume that the losses above 200 are exponential with mean 168 above 200 by the memoryless property and thus $$\frac{142752+368N}{1114+N}=168$$ gives $N=222$ , which aligns well with the official answer. But with the given information, it could be that the first 1,114 data points are all 128.14 and then we have a single data point of 44568. Of course this is an event of negligible probability, but nonetheless it is theoretically positive. What am I missing?","I was going thorough an actuarial exam and came across a problem that I can't figure out. Here is the problem as stated on the practice exam: You are given: An insurance product with a per loss limit of 200 covers losses from an exponential distribution with parameter . Based on the following table, the maximum likelihood estimate of is 168. Calculate for the table above. The answer is: is less than 250. My question: How can we know for sure that is less than 250? It can be thought of as a random variable, couldn't it? It could be that there is a single loss above 200 but very large so that the overall average is still 168, yes? It seems that we are supposed to assume that the losses above 200 are exponential with mean 168 above 200 by the memoryless property and thus gives , which aligns well with the official answer. But with the given information, it could be that the first 1,114 data points are all 128.14 and then we have a single data point of 44568. Of course this is an event of negligible probability, but nonetheless it is theoretically positive. What am I missing?","\bullet \theta \bullet \theta \begin{array}{|c | c | c |}\hline
\text{Size of loss} & \text{Number of claims} & \text{Sum of losses} \\ \hline
\text{Less than  } 200 & 1,114 & 142,752\\ \hline
\text{At least  } 200 & N & 200N \\ \hline
\end{array} N N N \frac{142752+368N}{1114+N}=168 N=222","['probability', 'statistics', 'actuarial-science']"
79,Probability no one needs to wait for changes when buying tickets .,Probability no one needs to wait for changes when buying tickets .,,"There are $2 \cdot n$ people in the queue to the theater office; n people on only banknotes worth $20$ zlotys, and the remaining n people only have banknotes worth $10$ zlotys . At the beginning of the sale at the box office there is no money. Each person buys one ticket worth 10 zlotys. If one with only $20$ -zlotys banknotes is in the first of the queue, then he/she needs to wait for another guy with only 10-zlotys banknote to complete his/her transaction, because the ticket office does not have any change to offer at that time. What is the probability that no one will wait for the change? $A$ = no one will wait for the rest. $P (A) = 1-P (A ')$ , that is, it subtracts the waiting persons from the whole and will leave me without waiting, but I do not know how to calculate it.","There are people in the queue to the theater office; n people on only banknotes worth zlotys, and the remaining n people only have banknotes worth zlotys . At the beginning of the sale at the box office there is no money. Each person buys one ticket worth 10 zlotys. If one with only -zlotys banknotes is in the first of the queue, then he/she needs to wait for another guy with only 10-zlotys banknote to complete his/her transaction, because the ticket office does not have any change to offer at that time. What is the probability that no one will wait for the change? = no one will wait for the rest. , that is, it subtracts the waiting persons from the whole and will leave me without waiting, but I do not know how to calculate it.",2 \cdot n 20 10 20 A P (A) = 1-P (A '),['probability']
80,A 'Kinda' Normal Distribution Over the Unit Interval? (the ladybug won't die),A 'Kinda' Normal Distribution Over the Unit Interval? (the ladybug won't die),,"Update: I added the stochastic-processes tag. For my non-theoretical computer model/application, I'm trying to approximate a Bernoulli random variable. So we are 'watching the ladybug' to get a real-time estimate of the probability as each observation is processed. The application uses an $\alpha$ of $\text{1%}$ . This is a filtering parameter - we allow for the fact that the Bernoulli distribution itself can change over time. If things (strategic adaptions) changed quickly, an $\alpha = \text{10%}$ might work better - we 'open up the filter' to place more value in the current reading. Let $\alpha = 0.01$ . A ladybug is walking on the open unit interval $(0,1)$ . She starts at the midpoint $\frac{1}{2}$ . Every minute she makes a move to either the right (a larger number) or to the left (a smaller number). The ladybug makes the move by flipping a coin. If the coin comes up heads and she is at position $x$ , she move to the right to the number $\tag 1 x  + \alpha \, (1 - x) = (1 - \alpha)\,x + \alpha$ If the coin comes up tails and she is at position $x$ , she move to the left to the number $\tag 2 (1  - \alpha) \, x$ If the ladybug does this for many weeks, is there a continuous random   variable that statisticians use to estimate probabilities that the   ladybug is in some sub-interval? Note: I am just curious about this and would expect any answer to be a bit esoteric from my perspective. For example, it might involve Beta distributions , something that I've never studied.","Update: I added the stochastic-processes tag. For my non-theoretical computer model/application, I'm trying to approximate a Bernoulli random variable. So we are 'watching the ladybug' to get a real-time estimate of the probability as each observation is processed. The application uses an of . This is a filtering parameter - we allow for the fact that the Bernoulli distribution itself can change over time. If things (strategic adaptions) changed quickly, an might work better - we 'open up the filter' to place more value in the current reading. Let . A ladybug is walking on the open unit interval . She starts at the midpoint . Every minute she makes a move to either the right (a larger number) or to the left (a smaller number). The ladybug makes the move by flipping a coin. If the coin comes up heads and she is at position , she move to the right to the number If the coin comes up tails and she is at position , she move to the left to the number If the ladybug does this for many weeks, is there a continuous random   variable that statisticians use to estimate probabilities that the   ladybug is in some sub-interval? Note: I am just curious about this and would expect any answer to be a bit esoteric from my perspective. For example, it might involve Beta distributions , something that I've never studied.","\alpha \text{1%} \alpha = \text{10%} \alpha = 0.01 (0,1) \frac{1}{2} x \tag 1 x  + \alpha \, (1 - x) = (1 - \alpha)\,x + \alpha x \tag 2 (1  - \alpha) \, x","['probability', 'statistics', 'stochastic-processes', 'maximum-likelihood']"
81,Promise of formal definition of conditional expectation: what is $E[X|Y=y]$ exactly?,Promise of formal definition of conditional expectation: what is  exactly?,E[X|Y=y],"There are many questions here related to this but I'm yet to see one that directly address this issue. The promise of a formal definition of conditional expectation is that with it we may have a well-defined $E[X|Y=y]$ even when $Y$ is continuous. So, after lots of work, here we have $E[X|\sigma(Y)]$ or expectation with respect to a sub-field in general and we have proved it exists and unique up to measure zero. And I understand that $E[X|\sigma(Y)]$ is a random variable that takes exactly the same expectation as $X$ on each measurable set in $\sigma(Y)$ . So what is the definition of $E[X|Y=y]$ exactly now? My intuition is that $E[X|Y=y]=E[X|\sigma(Y)](\omega), \forall \omega \in \{\omega \in \Omega: Y=y\}$ . But I'm not sure and haven't seen a proof that $E[X|Y=y]=E[X|\sigma(Y)](\omega)$ is indeed a constant for all $\omega \in \{\omega \in \Omega: Y=y\}.$ Any clarification is appreciated, especially a definitive statement of what $E[X|Y=y]$ is exactly.","There are many questions here related to this but I'm yet to see one that directly address this issue. The promise of a formal definition of conditional expectation is that with it we may have a well-defined even when is continuous. So, after lots of work, here we have or expectation with respect to a sub-field in general and we have proved it exists and unique up to measure zero. And I understand that is a random variable that takes exactly the same expectation as on each measurable set in . So what is the definition of exactly now? My intuition is that . But I'm not sure and haven't seen a proof that is indeed a constant for all Any clarification is appreciated, especially a definitive statement of what is exactly.","E[X|Y=y] Y E[X|\sigma(Y)] E[X|\sigma(Y)] X \sigma(Y) E[X|Y=y] E[X|Y=y]=E[X|\sigma(Y)](\omega), \forall \omega \in \{\omega \in \Omega: Y=y\} E[X|Y=y]=E[X|\sigma(Y)](\omega) \omega \in \{\omega \in \Omega: Y=y\}. E[X|Y=y]","['real-analysis', 'probability']"
82,Fix $0\leq\delta\leq1.$ Bob rolls a die repeatedly in the hopes of rolling a six.,Fix  Bob rolls a die repeatedly in the hopes of rolling a six.,0\leq\delta\leq1.,"Fix a parameter $0\leq\delta\leq1.$ Bob rolls a die repeatedly in the hopes of rolling a six. However, after each failure to roll a six he gives up with probability $1-\delta$ and decides to try again with probability $\delta$ . What is the probability that Bob will never roll a six? Let $A$ denote the event that Bob does not roll a six, and let $B$ be the event that he gives up after a failure. Then $P(A\cap B)=1-\delta$ and $P(A\cap B^{C})=\delta.$ Now after the first roll, the probability that Bob did not roll a six is $5/6$ . I am having difficulty with understanding how the parameter $\delta$ comes into the calculation of the probability that Bob does not get a six given that he failed and tried again. Could you please provide a hint, no solutions please, just a hint on how to start thinking about this kind of problem. Thank you for time, I appreciate any feedback.","Fix a parameter Bob rolls a die repeatedly in the hopes of rolling a six. However, after each failure to roll a six he gives up with probability and decides to try again with probability . What is the probability that Bob will never roll a six? Let denote the event that Bob does not roll a six, and let be the event that he gives up after a failure. Then and Now after the first roll, the probability that Bob did not roll a six is . I am having difficulty with understanding how the parameter comes into the calculation of the probability that Bob does not get a six given that he failed and tried again. Could you please provide a hint, no solutions please, just a hint on how to start thinking about this kind of problem. Thank you for time, I appreciate any feedback.",0\leq\delta\leq1. 1-\delta \delta A B P(A\cap B)=1-\delta P(A\cap B^{C})=\delta. 5/6 \delta,"['probability', 'dice']"
83,Evaluating integrals in the paper Auto-Encoding Variational Bayes,Evaluating integrals in the paper Auto-Encoding Variational Bayes,,"This is the first time that I'm asking on this site so apologies in advance if it's not quite the usual standard. I'm going thorough the paper Auto-Encoding Variational Bayes https://arxiv.org/abs/1312.6114 and in page 10 appendix B there is a simple enough looking equation that I don't fully understand how they got the results they have. $$\int q_{\phi}(\mathbf{z})log\,p(\mathbf{z})d\mathbf{z} = ... $$ when I expand $log\,p(\mathbf{z})$ I get $$log\,p(\mathbf{z}) = log\, \mathcal{N}(\mathbf{z}; \mathbf{0}, \mathbf{I}) =   log\, det(2\pi I)^{-1/2}\,e^{-1/2 \,\mathbf{z}'I\mathbf{z}} = \frac{-J}{2}\, log \,2\pi \, -\frac{1}{2}\left\lVert \mathbf{z} \right\rVert ^{2}$$ where $J$ is the dimension of $\mathbf{z}$ . From there it is easy to see that the term $\int q_{\phi}(\mathbf{z})\frac{-J}{2}\, log \,2\pi\, d\mathbf{z}$ evaluates to $\frac{-J}{2}\, log \,2\pi$ given that the integral over a density function evaluates to 1 which is in agreement with the paper. However I'm not sure how to proceed with the second part $\int q_{\phi}(\mathbf{z})\frac{-J}{2}\, \left\lVert \mathbf{z} \right\rVert ^{2} d\mathbf{z}$ . I'll really appreciate if anyone that knows could please explain what is it that I'm misunderstanding. Thanks.",This is the first time that I'm asking on this site so apologies in advance if it's not quite the usual standard. I'm going thorough the paper Auto-Encoding Variational Bayes https://arxiv.org/abs/1312.6114 and in page 10 appendix B there is a simple enough looking equation that I don't fully understand how they got the results they have. when I expand I get where is the dimension of . From there it is easy to see that the term evaluates to given that the integral over a density function evaluates to 1 which is in agreement with the paper. However I'm not sure how to proceed with the second part . I'll really appreciate if anyone that knows could please explain what is it that I'm misunderstanding. Thanks.,"\int q_{\phi}(\mathbf{z})log\,p(\mathbf{z})d\mathbf{z} = ...  log\,p(\mathbf{z}) log\,p(\mathbf{z}) = log\, \mathcal{N}(\mathbf{z}; \mathbf{0}, \mathbf{I}) = 
 log\, det(2\pi I)^{-1/2}\,e^{-1/2 \,\mathbf{z}'I\mathbf{z}} = \frac{-J}{2}\, log \,2\pi \, -\frac{1}{2}\left\lVert \mathbf{z} \right\rVert ^{2} J \mathbf{z} \int q_{\phi}(\mathbf{z})\frac{-J}{2}\, log \,2\pi\, d\mathbf{z} \frac{-J}{2}\, log \,2\pi \int q_{\phi}(\mathbf{z})\frac{-J}{2}\, \left\lVert \mathbf{z} \right\rVert ^{2} d\mathbf{z}","['probability', 'integration']"
84,What is the distribution of $(1+X^2)e^{-X^2/2}$ when $X$ is Cauchy?,What is the distribution of  when  is Cauchy?,(1+X^2)e^{-X^2/2} X,"If $X$ is a Cauchy random variable with $f(x)=\frac{1}{\pi}\frac{1}{1+x^{2}}$ , what is the distribution of $Y= (1+X^2)e^{-X^2/2}$ ? What I tried: I was thinking I may be able to use Jacobian, but I am unable to invert the function $Y=f(X)$ to find solutions. Any Idea how to go about this problem?","If is a Cauchy random variable with , what is the distribution of ? What I tried: I was thinking I may be able to use Jacobian, but I am unable to invert the function to find solutions. Any Idea how to go about this problem?",X f(x)=\frac{1}{\pi}\frac{1}{1+x^{2}} Y= (1+X^2)e^{-X^2/2} Y=f(X),"['probability', 'statistics', 'probability-distributions']"
85,"Another marble and urn problem, this time to $\infty$","Another marble and urn problem, this time to",\infty,"We have an urn with two marbles numbered $1$ and $2.$ We pick a marble randomly, write down its number and return it to the urn. Then we add a marble with the number 3 to the urn, choose one of the three marbles randomly, record its number and return it to the urn. We repeat this over and over: before the $(k+ 1)$ st pick we add a marble with with the number $k + 2$ in the urn (so that it contains the numbers $1, \dots , k + 2)$ , choose a marble randomly, record its number (that's the $(k + 1)$ st pick) and return it to the urn. At the end of the experiment we have an infinite sequence of integers. Show that with probability one the marble with the number $1$ will be picked at some point. It was recommended to break up the event into disjoint pieces. But I have no idea how to do this. Also, does this mean that all drawings must give a different number, with say $1$ in the $n$ th draw? Any hints are much appreciated.","We have an urn with two marbles numbered and We pick a marble randomly, write down its number and return it to the urn. Then we add a marble with the number 3 to the urn, choose one of the three marbles randomly, record its number and return it to the urn. We repeat this over and over: before the st pick we add a marble with with the number in the urn (so that it contains the numbers , choose a marble randomly, record its number (that's the st pick) and return it to the urn. At the end of the experiment we have an infinite sequence of integers. Show that with probability one the marble with the number will be picked at some point. It was recommended to break up the event into disjoint pieces. But I have no idea how to do this. Also, does this mean that all drawings must give a different number, with say in the th draw? Any hints are much appreciated.","1 2. (k+ 1) k + 2 1, \dots , k + 2) (k + 1) 1 1 n","['probability', 'probability-theory']"
86,Probabilistic models problem,Probabilistic models problem,,"Problem: The probability of a player making a free throw is 0.6. Find the probability that the player makes the first at least 7 consecutive free throws. The problem is that I have a dilemma: the requirement sounds for me that I need to use the formula from Poisson Model, but in that case, number of successes will be 8 (because ""at least 7""), and I don't know how to find the number of trials, it will be also 8? Is it correct what I suppose?","Problem: The probability of a player making a free throw is 0.6. Find the probability that the player makes the first at least 7 consecutive free throws. The problem is that I have a dilemma: the requirement sounds for me that I need to use the formula from Poisson Model, but in that case, number of successes will be 8 (because ""at least 7""), and I don't know how to find the number of trials, it will be also 8? Is it correct what I suppose?",,"['probability', 'probability-theory']"
87,What does the value of a PDF mean? [duplicate],What does the value of a PDF mean? [duplicate],,"This question already has answers here : What does the value of a probability density function (PDF) at some x indicate? (6 answers) Closed 5 years ago . I understand that the integral of a PDF provides tangible value --i.e., the integral of a PDF allows one to see the probability of a value or less than that value, under a particular distribution, occurring. But, what does the value of just the output of the PDF provide? In other words, what does the PDF of the standard normal distribution at x=0.5 mean?","This question already has answers here : What does the value of a probability density function (PDF) at some x indicate? (6 answers) Closed 5 years ago . I understand that the integral of a PDF provides tangible value --i.e., the integral of a PDF allows one to see the probability of a value or less than that value, under a particular distribution, occurring. But, what does the value of just the output of the PDF provide? In other words, what does the PDF of the standard normal distribution at x=0.5 mean?",,['probability']
88,Sum of two multinomial random variables,Sum of two multinomial random variables,,"I have two independent multinomial random variables $Y_1$ and $Y_2$ . I have to find the distribution of $$X=Y_1+Y_2$$ $$Y_1 \sim \text{Multinomial}(n_1,(p_1,p_2...p_k))$$ $$Y_2 \sim \text{Multinomial}(n_2,(p_1,p_2...p_k))$$ I tried using the convolution to calculate the distribution but got stuck after a while $$P(x_1,x_2..x_k) = \sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k}p_1^{y_1}p_2^{y_2}..p_k^{y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)..(x_k-y_k)}p_1^{x_1-y_1}p_2^{x_2-y_2}..p_k^{x_k-y_k}$$ such that $y_1+y_2+...+y_n = n_1$ and by similar reasoning we see that $x_1+x_2+...+x_n=n_1+n_2$ $$P(x_1,x_2..x_k) = p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)...(x_k-y_k)}$$ $$P(x_1,x_2..x_k) = (n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \frac{1}{y_1! y_2!..y_k!} \cdot\frac{1}{(x_1-y_1)! (x_2-y_2)!...(x_k-y_k)!}$$ $$P(x_1,x_2..x_k) = \frac{(n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}}{x_1! x_2!..x_k!}\sum_{y_1,y_2..y_n} \binom{x_1}{y_1}\binom{x_2}{y_2}...\binom{x_k}{y_k}$$ But after this I couldn't solve it. Please help",I have two independent multinomial random variables and . I have to find the distribution of I tried using the convolution to calculate the distribution but got stuck after a while such that and by similar reasoning we see that But after this I couldn't solve it. Please help,"Y_1 Y_2 X=Y_1+Y_2 Y_1 \sim \text{Multinomial}(n_1,(p_1,p_2...p_k)) Y_2 \sim \text{Multinomial}(n_2,(p_1,p_2...p_k)) P(x_1,x_2..x_k) = \sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k}p_1^{y_1}p_2^{y_2}..p_k^{y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)..(x_k-y_k)}p_1^{x_1-y_1}p_2^{x_2-y_2}..p_k^{x_k-y_k} y_1+y_2+...+y_n = n_1 x_1+x_2+...+x_n=n_1+n_2 P(x_1,x_2..x_k) = p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \binom{n_1}{y_1 y_2..y_k} \binom{n_2}{(x_1-y_1) (x_2-y_2)...(x_k-y_k)} P(x_1,x_2..x_k) = (n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}\sum_{y_1,y_2..y_n} \frac{1}{y_1! y_2!..y_k!} \cdot\frac{1}{(x_1-y_1)! (x_2-y_2)!...(x_k-y_k)!} P(x_1,x_2..x_k) = \frac{(n_1!)(n_2!) p_1^{x_1}p_2^{x_2}...p_k^{x_k}}{x_1! x_2!..x_k!}\sum_{y_1,y_2..y_n} \binom{x_1}{y_1}\binom{x_2}{y_2}...\binom{x_k}{y_k}","['probability', 'statistics', 'probability-distributions']"
89,Expectation of the function of multiple random variables,Expectation of the function of multiple random variables,,"I am working through some basic probability stuff and have a question regarding functions of multiple variables. If I have two random variables $X,Y$ which have some joint probability distribution $P_{XY}(x,y)$ I can obtain expected value of some function $f(x,y)$ by integrating across both variables: $$ E[f(x,y)] = \int \int f(x,y) P_{XY}(x,y) \ dx \ dy $$ we can also obtain the expected value of a function of a single variable by following the workings here $$ E[g(x)] = \int g(x) P_{X}(x) \ dx $$ If the integration across a function of a single value has meaning I am wondering how we would interpret the integration of a function of multiple variables across a single value $$ \int f(x,y) P_X(x)dx $$ and wether this expression has any meaning?",I am working through some basic probability stuff and have a question regarding functions of multiple variables. If I have two random variables which have some joint probability distribution I can obtain expected value of some function by integrating across both variables: we can also obtain the expected value of a function of a single variable by following the workings here If the integration across a function of a single value has meaning I am wondering how we would interpret the integration of a function of multiple variables across a single value and wether this expression has any meaning?,"X,Y P_{XY}(x,y) f(x,y) 
E[f(x,y)] = \int \int f(x,y) P_{XY}(x,y) \ dx \ dy
 
E[g(x)] = \int g(x) P_{X}(x) \ dx
 
\int f(x,y) P_X(x)dx
","['probability', 'probability-theory', 'random-variables']"
90,"Probability Question - A large number, $N$ , people go to a convention at a hotel. Each person is assigned one of $N $ hotel rooms....","Probability Question - A large number,  , people go to a convention at a hotel. Each person is assigned one of  hotel rooms....",N N ,"A large number of people, $N$ , go to a convention at a hotel.  Each person is assigned one of the $N$ hotel rooms.  Before going to the convention, everyone gives their room key to the doorman.  On the way out, the doorman hands the keys back at random. What is the probability that at least one person is given his/her original key? The general equation I have worked out should be, $$P(X \geq 1) = 1 - P(X=0)$$ $$P(X=0) = (1-(1/N))^N$$ Adding up all the probabilities that one person gets the right key.  I have checked with the answer key and this is a solution.  However, it does not work for the case where $N = 2$ . The probability that at least one person gets the right key should be $50% $ ,but this equation returns $75%$ .  Can anyone explain what logical error I am making?","A large number of people, , go to a convention at a hotel.  Each person is assigned one of the hotel rooms.  Before going to the convention, everyone gives their room key to the doorman.  On the way out, the doorman hands the keys back at random. What is the probability that at least one person is given his/her original key? The general equation I have worked out should be, Adding up all the probabilities that one person gets the right key.  I have checked with the answer key and this is a solution.  However, it does not work for the case where . The probability that at least one person gets the right key should be ,but this equation returns .  Can anyone explain what logical error I am making?",N N P(X \geq 1) = 1 - P(X=0) P(X=0) = (1-(1/N))^N N = 2 50%  75%,"['probability', 'discrete-mathematics', 'contest-math', 'derangements']"
91,Exterior Covering Number of $\epsilon /2$ is greater of equal than Covering Number of $\epsilon$,Exterior Covering Number of  is greater of equal than Covering Number of,\epsilon /2 \epsilon,"Definition $(\epsilon -Net)$ :let $(T,d)$ be a metric space .Consider a subset $ K \subset T$ and let $\epsilon >0$ , A subset $N \subset K $ is called $\epsilon -Net$ of $K$ if every point in $K$ is within a distance $\epsilon$ if every point in K is within a distance $\epsilon$ of some point of $N$ ,i.e. $$\forall x \in K  \ \ \  \exists x_0 \in N \ : d (x,x_0) \leq \ \epsilon$$ Definition(Covering  Number): For  metric space $(T,d)$ The covering number of $K \subset T$ respect to a given $\epsilon \geq 0$ ,denotes as $N(K,d,\epsilon )$ , is the smallest possible cardinarity an $\epsilon -Net$ of K , or equivalently ,is the smallest number of closed balls with centers  in $K$ and radii $\epsilon$ whose union covers $K$ Definition(Exterior Covering  Number): For  metric space $(T,d)$ The exterior covering number of $K \subset T$ respect to a given $\epsilon \geq 0$ ,denotes as $N^{ext}(K,d,\epsilon )$ ,  is the smallest number of closed balls with centers not necessary in $K$ and radii $\epsilon$ whose union covers $K$ then  I was  asked to prove that: $$N(K,d,\epsilon) \leq N^{ext} (K,d,\epsilon /2) $$ how to see that ? here is my attempt: since each $\epsilon -ball$ in $N(K,d, \epsilon) $ should intersect at least one $\epsilon /2 -ball$ in $N^{ext}(N,d,\epsilon/2)$ ,thus I am trying to show that by contradiction: for each two  distinct $\epsilon -ball$ in $N(K,d, \epsilon)$ ,the $\epsilon /2 -balls$ they intersect must contain a distinct one.","Definition :let be a metric space .Consider a subset and let , A subset is called of if every point in is within a distance if every point in K is within a distance of some point of ,i.e. Definition(Covering  Number): For  metric space The covering number of respect to a given ,denotes as , is the smallest possible cardinarity an of K , or equivalently ,is the smallest number of closed balls with centers  in and radii whose union covers Definition(Exterior Covering  Number): For  metric space The exterior covering number of respect to a given ,denotes as ,  is the smallest number of closed balls with centers not necessary in and radii whose union covers then  I was  asked to prove that: how to see that ? here is my attempt: since each in should intersect at least one in ,thus I am trying to show that by contradiction: for each two  distinct in ,the they intersect must contain a distinct one.","(\epsilon -Net) (T,d)  K \subset T \epsilon >0 N \subset K  \epsilon -Net K K \epsilon \epsilon N \forall x \in K  \ \ \  \exists x_0 \in N \ : d (x,x_0) \leq \ \epsilon (T,d) K \subset T \epsilon \geq 0 N(K,d,\epsilon ) \epsilon -Net K \epsilon K (T,d) K \subset T \epsilon \geq 0 N^{ext}(K,d,\epsilon ) K \epsilon K N(K,d,\epsilon) \leq N^{ext} (K,d,\epsilon /2)  \epsilon -ball N(K,d, \epsilon)  \epsilon /2 -ball N^{ext}(N,d,\epsilon/2) \epsilon -ball N(K,d, \epsilon) \epsilon /2 -balls","['real-analysis', 'probability', 'general-topology', 'functional-analysis']"
92,A.S. convergence of sum of square-integrable independent random variables with summable variation,A.S. convergence of sum of square-integrable independent random variables with summable variation,,"I'm working on the following exercise from Achim Klenke's ""Probability Theory: A Comprehensive Course"" (exercise 6.1.4): Let $X_1, X_2, \ldots$ be independent, square integrable, centered random variables with $\sum_{i=1}^\infty \mathbf{Var}[X_i] < \infty$ . Show that there exists a square integrable $X$ with $X = \lim_{n \to \infty} \sum_{i=1}^n X_i$ almost surely. Chebyshev's inequality gives us $$ \mathbf P\left[|S_m - S_n| > \epsilon\right] \leq \epsilon^{-2} \mathbf{Var}\left[ \sum_{i=m+1}^n X_i\right] = \epsilon^{-2} \sum_{i=m+1}^n \mathbf{Var}\left[X_i\right] \xrightarrow{m,n \to \infty} 0. $$ whence $(S_n)_{n \in \mathbb N}$ is a Cauchy sequence in probability. Thus $S_n \xrightarrow{\mathbf P} X$ . Using a similar strategy, we can in fact show that $S_n \to X$ in $L^2$ . Now, to prove almost sure convergence, I'd like to use the following result (Corollary 6.13 in Klenke): Let $(E,d)$ be a separable metric space. Let $f, f_1, f_2, \ldots$ be measurable maps $\Omega \to E$ . Then the following statements are equivalent. (i) $\quad f_n \to f$ in measure as $n \to \infty$ . (ii) $\quad$ For any subsequence of $(f_n)_{n \in \mathbb N}$ , there exists a sub-subsequence that converges to $f$ almost everywhere. and somehow use the fact that we're working with a sum of centered random variables to show that in fact every subsequence converges a.s. But I'm not sure how to do this since our $X_i$ are not nonnegative. I tried reconstructing the proof of this theorem, but I've only been able to show once again that there are a.e. convergent subsequences. My other thought was to apply the Borel-Cantelli lemma to the events $B_n(\epsilon) := \left\{ |X - S_n| > \epsilon\right\}$ and prove that $\limsup_{n \to \infty} B_n(\epsilon) =: B(\epsilon)$ has probability $0$ , but in the latter case I don't know how to approximate the probability of $B_n(\epsilon)$ . Chebyshev doesn't seem available to us since strictly speaking we don't know what $X$ looks like, only that $S_n$ converges in $L^2$ to it. Even if we could say $X - S_n = \sum_{i=n+1}^\infty X_i$ , the above approximation using Chebyshev with $|X - S_n|$ instead of $|S_m - S_n|$ would work out to $$ \mathbf P\left[|X - S_n| > \epsilon\right] \leq \epsilon^{-2} \sum_{i=n+1}^\infty \mathbf{Var}[X_i] $$ which would sum to $\epsilon^{-2} \sum_{n=1}^\infty n\mathbf{Var}[X_n]$ , but I don't see why this series converges. Any thoughts on how to prove $S_n \to X$ almost surely?","I'm working on the following exercise from Achim Klenke's ""Probability Theory: A Comprehensive Course"" (exercise 6.1.4): Let be independent, square integrable, centered random variables with . Show that there exists a square integrable with almost surely. Chebyshev's inequality gives us whence is a Cauchy sequence in probability. Thus . Using a similar strategy, we can in fact show that in . Now, to prove almost sure convergence, I'd like to use the following result (Corollary 6.13 in Klenke): Let be a separable metric space. Let be measurable maps . Then the following statements are equivalent. (i) in measure as . (ii) For any subsequence of , there exists a sub-subsequence that converges to almost everywhere. and somehow use the fact that we're working with a sum of centered random variables to show that in fact every subsequence converges a.s. But I'm not sure how to do this since our are not nonnegative. I tried reconstructing the proof of this theorem, but I've only been able to show once again that there are a.e. convergent subsequences. My other thought was to apply the Borel-Cantelli lemma to the events and prove that has probability , but in the latter case I don't know how to approximate the probability of . Chebyshev doesn't seem available to us since strictly speaking we don't know what looks like, only that converges in to it. Even if we could say , the above approximation using Chebyshev with instead of would work out to which would sum to , but I don't see why this series converges. Any thoughts on how to prove almost surely?","X_1, X_2, \ldots \sum_{i=1}^\infty \mathbf{Var}[X_i] < \infty X X = \lim_{n \to \infty} \sum_{i=1}^n X_i 
\mathbf P\left[|S_m - S_n| > \epsilon\right] \leq \epsilon^{-2} \mathbf{Var}\left[ \sum_{i=m+1}^n X_i\right] = \epsilon^{-2} \sum_{i=m+1}^n \mathbf{Var}\left[X_i\right] \xrightarrow{m,n \to \infty} 0.
 (S_n)_{n \in \mathbb N} S_n \xrightarrow{\mathbf P} X S_n \to X L^2 (E,d) f, f_1, f_2, \ldots \Omega \to E \quad f_n \to f n \to \infty \quad (f_n)_{n \in \mathbb N} f X_i B_n(\epsilon) := \left\{ |X - S_n| > \epsilon\right\} \limsup_{n \to \infty} B_n(\epsilon) =: B(\epsilon) 0 B_n(\epsilon) X S_n L^2 X - S_n = \sum_{i=n+1}^\infty X_i |X - S_n| |S_m - S_n| 
\mathbf P\left[|X - S_n| > \epsilon\right] \leq \epsilon^{-2} \sum_{i=n+1}^\infty \mathbf{Var}[X_i]
 \epsilon^{-2} \sum_{n=1}^\infty n\mathbf{Var}[X_n] S_n \to X","['real-analysis', 'probability', 'probability-theory', 'convergence-divergence', 'borel-cantelli-lemmas']"
93,Number of urns with more than K balls inside,Number of urns with more than K balls inside,,"I have a probability problem that I have simplified down to the following: Given M balls that are thrown randomly (uniformly) into N urns, what is the expected number of urns that have more than K balls inside?","I have a probability problem that I have simplified down to the following: Given M balls that are thrown randomly (uniformly) into N urns, what is the expected number of urns that have more than K balls inside?",,"['probability', 'balls-in-bins']"
94,Find a probability mass function of a random variable [duplicate],Find a probability mass function of a random variable [duplicate],,"This question already has answers here : What's the probability that a given permutation has exactly $k$ fixed points. [duplicate] (3 answers) Closed 5 years ago . $\color{red}{Attempt} $ We start with $k=1$ , $P(X=1)$ is the probability that one letter have been put in the correct envelope. Our sample space size is $n$ and since there is only one way that one letter must have been put into the correct envelope and the rest $n-1$ incorrectly and so we see that $P(X=1)= \dfrac{(n-1)!}{n}$ , now for $P(X=2)$ it becomes more complicated, so far I know that ${n \choose 2}$ is the size of the sample space and now we want to count the number of ways in which 2 letters must have been put in the correct envelope. First, of all, the $n-2$ letters that have been put incorrectly we have to count them and we have $(n-2)!$ and then the 2 letters that are put correctly this is done in one way thus $$ P(X=2) = \frac{(n-2)!}{{n \choose 2} }$$ so, in general, we have $$ P(X=k) = \frac{(n-k)!}{n \choose k } $$ is this correct?","This question already has answers here : What's the probability that a given permutation has exactly $k$ fixed points. [duplicate] (3 answers) Closed 5 years ago . We start with , is the probability that one letter have been put in the correct envelope. Our sample space size is and since there is only one way that one letter must have been put into the correct envelope and the rest incorrectly and so we see that , now for it becomes more complicated, so far I know that is the size of the sample space and now we want to count the number of ways in which 2 letters must have been put in the correct envelope. First, of all, the letters that have been put incorrectly we have to count them and we have and then the 2 letters that are put correctly this is done in one way thus so, in general, we have is this correct?",\color{red}{Attempt}  k=1 P(X=1) n n-1 P(X=1)= \dfrac{(n-1)!}{n} P(X=2) {n \choose 2} n-2 (n-2)!  P(X=2) = \frac{(n-2)!}{{n \choose 2} }  P(X=k) = \frac{(n-k)!}{n \choose k } ,['probability']
95,Finding correlation between CDF of two normal distributions,Finding correlation between CDF of two normal distributions,,"Suppose that $X\sim N(0,1)$ , $Y\sim N(0,1)$ with correlation $(X, Y) =ρ$ where $ρ ∈ (−1, 1)$ . Show the following, Correlation $(Φ(X),Φ(Y))=\dfrac6π \arcsin\dfrac ρ2 $ . Here $Φ(X)$ , and $Φ(Y)$ denote the CDF of Random variables $X$ and $Y$ respectively. What I know so far: $$\text{Cov}( Φ(X),Φ(Y)) =E(Φ(X)Φ(Y)) - E(Φ(X)) ×E(Φ(Y)) $$ We also know since $X \sim N(0,1)$ and $Y\sim N(0,1)$ ; $Φ(X)\sim\text{unif}(0,1)$ , $Φ(Y)\sim\text{unif}(0,1)$ . Hence $$E(Φ(X)) =E(Φ(Y)) =\frac12.$$ I am stuck in finding $E(Φ(X)Φ(Y))$ [I tried to find it using double expectation]. What I have written may be the wrong way of attempting the question. So I am thankful for any help.","Suppose that , with correlation where . Show the following, Correlation . Here , and denote the CDF of Random variables and respectively. What I know so far: We also know since and ; , . Hence I am stuck in finding [I tried to find it using double expectation]. What I have written may be the wrong way of attempting the question. So I am thankful for any help.","X\sim N(0,1) Y\sim N(0,1) (X, Y) =ρ ρ ∈ (−1, 1) (Φ(X),Φ(Y))=\dfrac6π \arcsin\dfrac ρ2  Φ(X) Φ(Y) X Y \text{Cov}( Φ(X),Φ(Y)) =E(Φ(X)Φ(Y)) - E(Φ(X)) ×E(Φ(Y))  X \sim N(0,1) Y\sim N(0,1) Φ(X)\sim\text{unif}(0,1) Φ(Y)\sim\text{unif}(0,1) E(Φ(X)) =E(Φ(Y)) =\frac12. E(Φ(X)Φ(Y))","['probability', 'normal-distribution', 'correlation', 'expected-value']"
96,The pdf of $\tan X$ when $X$ is Uniform,The pdf of  when  is Uniform,\tan X X,"Let $X$ be a random variable with pdf $$ f(x) = \begin{cases} \frac{1}{\pi}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases} $$ Find the pdf of $Y = \tan(x)$ . My attempt: $$F_Y(y) = P(Y\le y) = P(\tan(x)\le y) = P(x\le \tan^{-1}(y))=F_X(\tan^{-1}y) = \begin{cases} 0,&\text{if } x<-\frac{\pi}{2} \\  \frac{1}{\pi}{\tan^{-1}y}, & \text{if } -\frac{\pi}{2} \leq x <\frac{\pi}{2} \\ 1, & \text{if } x\geq \frac{\pi}{2} \end{cases}$$ $$ f_Y(y) = \begin{cases} \frac{1}{\pi} \frac{1}{1+x^2}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases} $$ Am I on the right path?",Let be a random variable with pdf Find the pdf of . My attempt: Am I on the right path?,"X  f(x) = \begin{cases} \frac{1}{\pi}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases}  Y = \tan(x) F_Y(y) = P(Y\le y) = P(\tan(x)\le y) = P(x\le \tan^{-1}(y))=F_X(\tan^{-1}y) = \begin{cases} 0,&\text{if } x<-\frac{\pi}{2} \\  \frac{1}{\pi}{\tan^{-1}y}, & \text{if } -\frac{\pi}{2} \leq x <\frac{\pi}{2} \\ 1, & \text{if } x\geq \frac{\pi}{2} \end{cases}  f_Y(y) = \begin{cases} \frac{1}{\pi} \frac{1}{1+x^2}, & \text{if } -\frac{\pi}{2} < x <\frac{\pi}{2} \\ 0, & \text{elsewhere} \end{cases} ","['probability', 'statistics', 'probability-distributions']"
97,On the definition of ergodicity and how it relates to random processes.,On the definition of ergodicity and how it relates to random processes.,,"Let $\mathcal{M} : = \{ \mu | \mu \text{ is a probability measure} \}$ , and let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a measurable function. $\mu \in \mathcal{M}$ is ergodic if for all $A \in \mathcal{B} $ (the Borel set on $\mathbb{R}$ ) such that $f^{-1}(A) = A$ either $\mu(A) = 0$ or $\mu(A) = 1$ . Let $f$ have a periodic orbit of period $n \in \mathbb{N} $ with points $\{p_1, \dots, p_n  \}$ then $$\mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} )$$ is easily seen to be ergodic according to the definition given. Even a weighted average of the $ \delta_{p_1} + \dots + \delta_{p_n}$ would be. Under the article on Ergodicity on wikipedia I find that ""A random process is ergodic if its time average is the same as its average over the probability space"", if I Imagine the orbit of $f$ as a random process this statement does not seem to agree with the definition since the time average would be $$\frac{1}{n} (  p_1 + \dots + p_n )$$ and the average over the probability space is $$\mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} )$$ (?). Also the statement ""a Markov chain is ergodic if there is a positive probability to pass from any state to any other state in one step"" seems in contrast with the example give with $f$ having a periodic orbit of period $n$ . In short my question is, how does the given definition of ergodicity reconcile itself with the statements quoted on the Wikipedia page? Simple examples are welcome (or utilizing mine would be great).","Let , and let be a measurable function. is ergodic if for all (the Borel set on ) such that either or . Let have a periodic orbit of period with points then is easily seen to be ergodic according to the definition given. Even a weighted average of the would be. Under the article on Ergodicity on wikipedia I find that ""A random process is ergodic if its time average is the same as its average over the probability space"", if I Imagine the orbit of as a random process this statement does not seem to agree with the definition since the time average would be and the average over the probability space is (?). Also the statement ""a Markov chain is ergodic if there is a positive probability to pass from any state to any other state in one step"" seems in contrast with the example give with having a periodic orbit of period . In short my question is, how does the given definition of ergodicity reconcile itself with the statements quoted on the Wikipedia page? Simple examples are welcome (or utilizing mine would be great).","\mathcal{M} : = \{ \mu | \mu \text{ is a probability measure} \} f:\mathbb{R} \rightarrow \mathbb{R} \mu \in \mathcal{M} A \in \mathcal{B}  \mathbb{R} f^{-1}(A) = A \mu(A) = 0 \mu(A) = 1 f n \in \mathbb{N}  \{p_1, \dots, p_n  \} \mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} )  \delta_{p_1} + \dots + \delta_{p_n} f \frac{1}{n} (  p_1 + \dots + p_n ) \mu = \frac{1}{n} (  \delta_{p_1} + \dots + \delta_{p_n} ) f n","['probability', 'probability-theory', 'dynamical-systems', 'ergodic-theory']"
98,Expected number of parallel tosses of $N$ unfair coins until all coins landed head at least once,Expected number of parallel tosses of  unfair coins until all coins landed head at least once,N,"I am trying to understand this answer , but it doesn't work when I plug in the numbers. Given the recurrence relation \begin{align*}   E_n &= \dfrac{\displaystyle 1+\sum_{k=1}^{n-1}q^kp^{n-k}E_{k}}{1-q^n} \\   E_1 &= \frac{1}{p} \end{align*} and assuming $p = q = 1/2$, we can compute $E_5$ as: \begin{align} E_1 &= 2\\ E_2 &= \frac{1 + (1/2)(1/2)2}{1-(1/4)} = \frac{6}{3} = 2\\ E_3 &= \frac{1 + (1/2)(1/4)2 + (1/4)(1/2)2}{1-(1/8)} = \frac{12}{7} \approx 1.714\\ E_4 &= \frac{1 + (1/2)(1/8)2 + (1/4)(1/4)2 + (1/8)(1/2)(12/7)}{1-(1/16)} = \frac{152}{105} \approx 1.448\\ E_5 &= \frac{1 + (1/2)(1/16)2 + (1/4)(1/8)2 + (1/8)(1/4)(12/7) + (1/16)(1/2)(152/105)}{1-(1/32)} = \frac{4112}{3255} \approx 1.263, \end{align} which does not match the author's answer of $E_5 = 2470/651 \approx 3.79416282642$. I have no experience with absorbing Markov chains so I have no idea where the mistake is.  Am I doing something wrong or is the answer wrong? (Apologies if this is not the right place.  I would have posted this as a comment to the answer, but my reputation is not high enough to do that...)","I am trying to understand this answer , but it doesn't work when I plug in the numbers. Given the recurrence relation \begin{align*}   E_n &= \dfrac{\displaystyle 1+\sum_{k=1}^{n-1}q^kp^{n-k}E_{k}}{1-q^n} \\   E_1 &= \frac{1}{p} \end{align*} and assuming $p = q = 1/2$, we can compute $E_5$ as: \begin{align} E_1 &= 2\\ E_2 &= \frac{1 + (1/2)(1/2)2}{1-(1/4)} = \frac{6}{3} = 2\\ E_3 &= \frac{1 + (1/2)(1/4)2 + (1/4)(1/2)2}{1-(1/8)} = \frac{12}{7} \approx 1.714\\ E_4 &= \frac{1 + (1/2)(1/8)2 + (1/4)(1/4)2 + (1/8)(1/2)(12/7)}{1-(1/16)} = \frac{152}{105} \approx 1.448\\ E_5 &= \frac{1 + (1/2)(1/16)2 + (1/4)(1/8)2 + (1/8)(1/4)(12/7) + (1/16)(1/2)(152/105)}{1-(1/32)} = \frac{4112}{3255} \approx 1.263, \end{align} which does not match the author's answer of $E_5 = 2470/651 \approx 3.79416282642$. I have no experience with absorbing Markov chains so I have no idea where the mistake is.  Am I doing something wrong or is the answer wrong? (Apologies if this is not the right place.  I would have posted this as a comment to the answer, but my reputation is not high enough to do that...)",,"['probability', 'expectation', 'markov-chains']"
99,Random walk probability,Random walk probability,,"I encounter a problem:Consider a two dimensional map, with an x-axis (horizontal direction) and a y-axis (vertical direction). Coordinates on the map can therefore be represented as a two-dimensional vector (x, y). A tourist is standing at coordinates (0, 0), and is looking for the the tourist information centre, located at coordinates (−10, 30). However, the tourist is completely lost and instead of asking for directions, begins a random walk to search for the tourist information centre. The tourist moves one step at a time, either horizonally or vertically (but can not move diagonally). Steps can also be forwards (in a positive direction) or backwards (in a negative direction). Therefore, at every point, there are 4 possible moves the tourist can make. For instance, when standing at the origin (0,0), the tourist can move either to (0, 1), (0, −1), (1, 0) or (−1, 0), and has an equal probability of moving in each direction, thus a probability of 0.25 for each option. What is the probability that this tourist locates the tourist office in 1000 steps or less? Aaron Montgomery gave the hint that the simulation is a good way to estimate the probability. Could any expert give a full code, like the C++ or R code, to help us better understand this kind of question? Thanks in advance.","I encounter a problem:Consider a two dimensional map, with an x-axis (horizontal direction) and a y-axis (vertical direction). Coordinates on the map can therefore be represented as a two-dimensional vector (x, y). A tourist is standing at coordinates (0, 0), and is looking for the the tourist information centre, located at coordinates (−10, 30). However, the tourist is completely lost and instead of asking for directions, begins a random walk to search for the tourist information centre. The tourist moves one step at a time, either horizonally or vertically (but can not move diagonally). Steps can also be forwards (in a positive direction) or backwards (in a negative direction). Therefore, at every point, there are 4 possible moves the tourist can make. For instance, when standing at the origin (0,0), the tourist can move either to (0, 1), (0, −1), (1, 0) or (−1, 0), and has an equal probability of moving in each direction, thus a probability of 0.25 for each option. What is the probability that this tourist locates the tourist office in 1000 steps or less? Aaron Montgomery gave the hint that the simulation is a good way to estimate the probability. Could any expert give a full code, like the C++ or R code, to help us better understand this kind of question? Thanks in advance.",,"['probability', 'random-walk']"
