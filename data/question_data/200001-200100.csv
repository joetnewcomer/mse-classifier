,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Lie algebra of a Lie group literature,Lie algebra of a Lie group literature,,I'm currently writing my thesis and want to use the concept of Lie-algebras. I explained everything with the definitions of a lie-algebra that I had of an old lecture. There the lie-algebra of a lie-group is defined as the tangent space at the identity element. I understand that there is an isomorphism between this tangent-space and the set of left-invariant vector-fields but I do not want to make things more complicated and just state it like this. The script does not have literature advice and in the standard differential geometry literature that I know the definition is different. Can anyone advice me a citable document?,I'm currently writing my thesis and want to use the concept of Lie-algebras. I explained everything with the definitions of a lie-algebra that I had of an old lecture. There the lie-algebra of a lie-group is defined as the tangent space at the identity element. I understand that there is an isomorphism between this tangent-space and the set of left-invariant vector-fields but I do not want to make things more complicated and just state it like this. The script does not have literature advice and in the standard differential geometry literature that I know the definition is different. Can anyone advice me a citable document?,,"['differential-geometry', 'lie-groups', 'lie-algebras']"
1,Motivation for the standard symplectic space,Motivation for the standard symplectic space,,"I'm aware that for the vector space $V\oplus V^*$ that the product between $(v,\phi)$ and $(w,\psi)$ is given by $\psi(v)-\phi(v)$ . What I'm struggling to see is why a person might want to define a product this way, other than to give an example of a symplectic product. Is there a particularly nice geometric or physics interpretation?","I'm aware that for the vector space that the product between and is given by . What I'm struggling to see is why a person might want to define a product this way, other than to give an example of a symplectic product. Is there a particularly nice geometric or physics interpretation?","V\oplus V^* (v,\phi) (w,\psi) \psi(v)-\phi(v)","['differential-geometry', 'symplectic-geometry', 'symplectic-linear-algebra']"
2,Do covariant derivatives commute?,Do covariant derivatives commute?,,"Let $M$ be a differentiable manifold, let $f:M\rightarrow\mathbb{R}$ be smooth and let $v,w$ be vector fields in $M$ . Must it be true that $\nabla_w(\nabla_vf) = \nabla_v(\nabla_wf)$ where $\nabla$ denotes the covariant derivative? If so I would like a proof and if not a counter example. Also, to motivate this question, it seems to me that one can ask this independently of picking a riemannian metric. Because of this, if one had a counter example, then one should be able to put any metric on the space (in particular a flat metric) which would give rise to non commuting derivatives for a smooth function in $\mathbb{R}^n$ which never happens. Because of this I suspect this equality must hold, however I am still unsure. To clarify, the reason I think one can ask this equality without picking a metric is that to my understanding $\nabla_vf$ is defined independently of the metric and results in a function from $M\rightarrow\mathbb{R}$ . That is to say, the covariant derivative of a function from the manifold to the reals with respect to a vector field is itself a function from the manifold to the reals and this is defined independently of the metric. Here is why I think the covariant derivative is defined independently of the metric. Say you have a vector field $v$ and real valued function $f$ on the manifold. To get the covariant derivative at a point $p$ we take the vector of the vector field $v$ at $p$ (call this vector $v_p$ ) and we consider some function from $\phi:\mathbb{R}\rightarrow M$ such that $\frac{d}{dt}\phi(t) = v_p$ . Then the covariant derivative is defined as $\frac{d}{dt} f(\phi(t))$ which is a real because $f\circ\phi$ is a map from $\mathbb{R}$ to $\mathbb{R}$ . At no point is the metric required in this definition. Also, I don't think use of the metric is hiding in the definition of the derivative of a map from the reals to the manifold because a tangent vector can be defined as an equivalence class of functions from the reals to the manifold that all have the same derivative when passed through some chart of the smooth manifold. It is quite likely my confusion stems from some miss understanding which is present in my above explanation in which case please point this out to me. Thanks for taking the time to read this post.","Let be a differentiable manifold, let be smooth and let be vector fields in . Must it be true that where denotes the covariant derivative? If so I would like a proof and if not a counter example. Also, to motivate this question, it seems to me that one can ask this independently of picking a riemannian metric. Because of this, if one had a counter example, then one should be able to put any metric on the space (in particular a flat metric) which would give rise to non commuting derivatives for a smooth function in which never happens. Because of this I suspect this equality must hold, however I am still unsure. To clarify, the reason I think one can ask this equality without picking a metric is that to my understanding is defined independently of the metric and results in a function from . That is to say, the covariant derivative of a function from the manifold to the reals with respect to a vector field is itself a function from the manifold to the reals and this is defined independently of the metric. Here is why I think the covariant derivative is defined independently of the metric. Say you have a vector field and real valued function on the manifold. To get the covariant derivative at a point we take the vector of the vector field at (call this vector ) and we consider some function from such that . Then the covariant derivative is defined as which is a real because is a map from to . At no point is the metric required in this definition. Also, I don't think use of the metric is hiding in the definition of the derivative of a map from the reals to the manifold because a tangent vector can be defined as an equivalence class of functions from the reals to the manifold that all have the same derivative when passed through some chart of the smooth manifold. It is quite likely my confusion stems from some miss understanding which is present in my above explanation in which case please point this out to me. Thanks for taking the time to read this post.","M f:M\rightarrow\mathbb{R} v,w M \nabla_w(\nabla_vf) = \nabla_v(\nabla_wf) \nabla \mathbb{R}^n \nabla_vf M\rightarrow\mathbb{R} v f p v p v_p \phi:\mathbb{R}\rightarrow M \frac{d}{dt}\phi(t) = v_p \frac{d}{dt} f(\phi(t)) f\circ\phi \mathbb{R} \mathbb{R}",['differential-geometry']
3,How to show $f^{-1}(0) \subset \mathbb{R}^m \times \mathbb{R}^n$ is smooth,How to show  is smooth,f^{-1}(0) \subset \mathbb{R}^m \times \mathbb{R}^n,"Let $f : \mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}^m$ be a smooth map. I'm wondering about smoothness of the set $f^{-1}(0)$ under the following conditions: (1) For all $x \in \mathbb{R}^m$ , $f^{-1}(0) \cap (\{x\} \times \mathbb{R}^n)$ is smooth of dimension $r$ (if non-empty). The dimension stays the same for all $x$ . (2) For all $(x, y) \in f^{-1}(0)$ the restriction of the projection $\mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}^m$ to the kernel of $df_{(x,y)}$ is surjective. In other words, for all $u \in \mathbb{R}^m$ there exists $v \in \mathbb{R}^n$ such that $df_{(x,y)}(u, v) = 0$ . Why is $f^{-1}(0)$ a smooth submanifold of $\mathbb{R}^m \times \mathbb{R}^n$ ? (Maybe it isn't, but I've seen that claim somewhere, that's why I'm asking.) I'm trying to apply the transversality theorem, but it's not obvious how since $df_{(x,y)}$ may not be surjective. Intuitively, by (1), non-smoothness can only arise in the transverse directions $\mathbb{R}^m \times \{y\}$ but because $\ker df_{(x,y)} \to \mathbb{R}^m$ is surjective that cannot happen.","Let be a smooth map. I'm wondering about smoothness of the set under the following conditions: (1) For all , is smooth of dimension (if non-empty). The dimension stays the same for all . (2) For all the restriction of the projection to the kernel of is surjective. In other words, for all there exists such that . Why is a smooth submanifold of ? (Maybe it isn't, but I've seen that claim somewhere, that's why I'm asking.) I'm trying to apply the transversality theorem, but it's not obvious how since may not be surjective. Intuitively, by (1), non-smoothness can only arise in the transverse directions but because is surjective that cannot happen.","f : \mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}^m f^{-1}(0) x \in \mathbb{R}^m f^{-1}(0) \cap (\{x\} \times \mathbb{R}^n) r x (x, y) \in f^{-1}(0) \mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}^m df_{(x,y)} u \in \mathbb{R}^m v \in \mathbb{R}^n df_{(x,y)}(u, v) = 0 f^{-1}(0) \mathbb{R}^m \times \mathbb{R}^n df_{(x,y)} \mathbb{R}^m \times \{y\} \ker df_{(x,y)} \to \mathbb{R}^m","['differential-geometry', 'smooth-manifolds']"
4,Defining the natural almost complex structure on a complex manifold.,Defining the natural almost complex structure on a complex manifold.,,"The definition of an almost complex structure is as follows. If $X$ is a differentiable manifold and $TX$ is its tangent bundle, then the endomorphism $I: TX \to TX$ defines an almost complex structure if $I \circ I = -1$ on all the fibers. If $X$ is a complex manifold, it would be easy to define $I$ locally (on the holomorphic tangent bundle) on a chart $U_i$ with the trivialization $\Phi_i : U_i \times \mathbb{C}^n \to \pi^{-1}(U_i)$ by letting $I_i(p, v) = (p, iv)$ . Then clearly, $I_i^2 = -1$ so every chart has an almost complex structure. This would then give a natural map $I_i': \pi^{-1}(U_i) \to \pi^{-1}(U_i)$ by $I_i' = \Phi_i I_i \Phi^{-1}_i$ which satisfies the conditions of an almost complex structure on $TU_i$ . However, I'm having trouble seeing how this extends to a global endomorphism $I$ . To do so, we would need $I_i \equiv I_j$ on $\pi^{-1}(U_i \cap U_j).$ If $U_j$ has a local trivialization $\Phi_j$ , then the transition map $\Phi_j^{-1} \circ \Phi_i: (U_i \cap U_j )\times \mathbb{C}^n \to (U_i \cap U_j )\times \mathbb{C}^n$ is given by $(p, v) \mapsto (p, \tau_p(v))$ for some differentiable map $\tau: U_i \cap U_j \to GL(n, \mathbb{C})$ . Then, in order for $I_i' = I_j'$ , we would need $\Phi_i I_i \Phi_i^{-1} = \Phi_j I_j \Phi_j^{-1}$ which is true iff $\Phi_j ^{-1} \Phi_i I_i = I_j \Phi_j^{-1} \Phi_i$ which is true iff $(p, \tau_p(iv)) = (p, i \tau_p(v))$ which is obviously true by the fact that $\tau_p \in GL(n, \mathbb{C})$ . Does this prove that X has an almost complex structure? Also, is there a more clear way to construct it? The book I'm reading from dismisses this fact as obvious which makes me concerned. Thank you!","The definition of an almost complex structure is as follows. If is a differentiable manifold and is its tangent bundle, then the endomorphism defines an almost complex structure if on all the fibers. If is a complex manifold, it would be easy to define locally (on the holomorphic tangent bundle) on a chart with the trivialization by letting . Then clearly, so every chart has an almost complex structure. This would then give a natural map by which satisfies the conditions of an almost complex structure on . However, I'm having trouble seeing how this extends to a global endomorphism . To do so, we would need on If has a local trivialization , then the transition map is given by for some differentiable map . Then, in order for , we would need which is true iff which is true iff which is obviously true by the fact that . Does this prove that X has an almost complex structure? Also, is there a more clear way to construct it? The book I'm reading from dismisses this fact as obvious which makes me concerned. Thank you!","X TX I: TX \to TX I \circ I = -1 X I U_i \Phi_i : U_i \times \mathbb{C}^n \to \pi^{-1}(U_i) I_i(p, v) = (p, iv) I_i^2 = -1 I_i': \pi^{-1}(U_i) \to \pi^{-1}(U_i) I_i' = \Phi_i I_i \Phi^{-1}_i TU_i I I_i \equiv I_j \pi^{-1}(U_i \cap U_j). U_j \Phi_j \Phi_j^{-1} \circ \Phi_i: (U_i \cap U_j )\times \mathbb{C}^n \to (U_i \cap U_j )\times \mathbb{C}^n (p, v) \mapsto (p, \tau_p(v)) \tau: U_i \cap U_j \to GL(n, \mathbb{C}) I_i' = I_j' \Phi_i I_i \Phi_i^{-1} = \Phi_j I_j \Phi_j^{-1} \Phi_j ^{-1} \Phi_i I_i = I_j \Phi_j^{-1} \Phi_i (p, \tau_p(iv)) = (p, i \tau_p(v)) \tau_p \in GL(n, \mathbb{C})","['differential-geometry', 'complex-geometry', 'vector-bundles', 'almost-complex']"
5,Degree of a map when restricting it to a submanifold,Degree of a map when restricting it to a submanifold,,"Let $X, Y$ be closed oriented smooth manifolds of dimension $(n+1)$ , where $Y$ is also connected, and let $F: X → Y$ be a smooth map. As usual, the degree $\deg{F}$ is defined as $$     \deg{F} = ∑_{x ∈ F^{-1}(y)} ±1 \; , $$ where $y ∈ Y$ is any regular value of $F$ and the sign is chosen depending on whether $F$ preserves or reverses orientation at the given point $x$ . Let $N^n ⊂ Y$ be an oriented, embedded and connected submanifold such that $N$ is closed as a subset of $Y$ . Suppose $M ≔ F^{-1}(N) ⊂ X$ is also an oriented embedded submanifold of dimension $n$ . By construction, $M$ and $N$ are both compact and $N$ is connected, so the degree of the restriction $\tilde{F} ≔ F|_M: M → N$ is well-defined. Is there anything that can be said about the degree of $\tilde{F}$ ? Do we have $\deg{\tilde{F}} = ± \deg{F}$ ? Notice that if $y \in Y$ is a regular value of $F$ (and thus of $\tilde{F}$ ) and happens to lie in $N$ , then $F^{-1}(y) = \tilde{F}^{-1}(y)$ and the claim that $\deg{\tilde{F}} = \pm \deg{F}$ follows if it can be shown that: Let $x \in F^{-1}(y) = \tilde{F}^{-1}(y)$ . Then $F$ is orientation-preserving at $x$ if and only if $\tilde{F}$ is orientation-preserving (or orientation-reversing – in the case of the minus sign). If it helps, I'm particularly interested in the special case where $X, Y$ are Riemannian manifolds and $M$ and $N$ are constructed as follows: Let $p: Y → ℝ$ be a smooth map and suppose $t ∈ ℝ$ is a regular value of both $p$ and $p ∘ F$ . Then define $N ≔ p^{-1}(t)$ and $M ≔ F^{-1}(t) = (p ∘ F)^{-1}(t)$ and assume that $N$ is connected. Note that $N$ and $M$ are automatically two-sided (and thus oriented) because the gradients of $p$ and $p ∘ F$ give rise to a trivialization of their normal bundles. My issue in proving the claim even in this special case is that I'm having trouble relating the normal vectors on $M$ and $N$ to each other as I don't know what $F$ and the two Riemannian metrics are doing.","Let be closed oriented smooth manifolds of dimension , where is also connected, and let be a smooth map. As usual, the degree is defined as where is any regular value of and the sign is chosen depending on whether preserves or reverses orientation at the given point . Let be an oriented, embedded and connected submanifold such that is closed as a subset of . Suppose is also an oriented embedded submanifold of dimension . By construction, and are both compact and is connected, so the degree of the restriction is well-defined. Is there anything that can be said about the degree of ? Do we have ? Notice that if is a regular value of (and thus of ) and happens to lie in , then and the claim that follows if it can be shown that: Let . Then is orientation-preserving at if and only if is orientation-preserving (or orientation-reversing – in the case of the minus sign). If it helps, I'm particularly interested in the special case where are Riemannian manifolds and and are constructed as follows: Let be a smooth map and suppose is a regular value of both and . Then define and and assume that is connected. Note that and are automatically two-sided (and thus oriented) because the gradients of and give rise to a trivialization of their normal bundles. My issue in proving the claim even in this special case is that I'm having trouble relating the normal vectors on and to each other as I don't know what and the two Riemannian metrics are doing.","X, Y (n+1) Y F: X → Y \deg{F} 
    \deg{F} = ∑_{x ∈ F^{-1}(y)} ±1 \; ,
 y ∈ Y F F x N^n ⊂ Y N Y M ≔ F^{-1}(N) ⊂ X n M N N \tilde{F} ≔ F|_M: M → N \tilde{F} \deg{\tilde{F}} = ± \deg{F} y \in Y F \tilde{F} N F^{-1}(y) = \tilde{F}^{-1}(y) \deg{\tilde{F}} = \pm \deg{F} x \in F^{-1}(y) = \tilde{F}^{-1}(y) F x \tilde{F} X, Y M N p: Y → ℝ t ∈ ℝ p p ∘ F N ≔ p^{-1}(t) M ≔ F^{-1}(t) = (p ∘ F)^{-1}(t) N N M p p ∘ F M N F","['differential-geometry', 'differential-topology', 'differential-forms']"
6,"For the 3D rotation operation $R^{-1}(R(\omega_0)*R(\omega))$, how can we compute the derivative wrt $\omega$?","For the 3D rotation operation , how can we compute the derivative wrt ?",R^{-1}(R(\omega_0)*R(\omega)) \omega,"How can we compute the Jacobian derivative of the function: $$f(\omega) = R^{-1}(R(\omega_0) R(w))$$ with respect to $\omega$ , where $\omega_0 \in \mathbb{R}^3$ is some fixed/constant vector, the function: $$R(\omega) \triangleq \exp \big( [\omega]_{\times} \big) \triangleq \exp  \left(  \begin{bmatrix}  0    & -w_z  &  w_y \\  w_z  &  0    & -w_x \\ -w_y  &  w_x  &  0 \\ \end{bmatrix} \right), $$ is the Rodrigues-vector-to-rotation mapping , and $R^{-1}(\cdot)$ is the corresponding inverse function? For the sake of this question, we are primarily interested in taking the derivative about the point $\omega=0$ , since other values of $\omega$ can be absorbed into the constant $\omega_0$ with a little extra effort. So everything should be expressible in terms of $\omega_0$ . Edit: Using some dirty empirical methods, I was able to get the first few coefficients of the Taylor expansion as: $$ \frac{d f}{d \omega} = Z^0 + \frac{1}{2!} Z^1+ \frac{1}{2 (3!)}Z^2 - \frac{1}{6 (5!)}Z^4 + \frac{1}{6 (7!)} Z^6 - (...) $$ where $Z=[\omega_0]_{\times}$ . (Evidently, there no higher order odd terms beyond the first.) So this appears to have a similar form to Rodrigues, as: $$\frac{d f}{d \omega} = I + \frac{1}{2} Z + \beta(\omega_0) Z^2$$ but getting a functional form for $\beta$ seems nontrivial. (I'd venture a guess than $\beta$ is purely a function of $\|\omega_0\|$ .)","How can we compute the Jacobian derivative of the function: with respect to , where is some fixed/constant vector, the function: is the Rodrigues-vector-to-rotation mapping , and is the corresponding inverse function? For the sake of this question, we are primarily interested in taking the derivative about the point , since other values of can be absorbed into the constant with a little extra effort. So everything should be expressible in terms of . Edit: Using some dirty empirical methods, I was able to get the first few coefficients of the Taylor expansion as: where . (Evidently, there no higher order odd terms beyond the first.) So this appears to have a similar form to Rodrigues, as: but getting a functional form for seems nontrivial. (I'd venture a guess than is purely a function of .)","f(\omega) = R^{-1}(R(\omega_0) R(w)) \omega \omega_0 \in \mathbb{R}^3 R(\omega) \triangleq \exp \big( [\omega]_{\times} \big) \triangleq \exp 
\left( 
\begin{bmatrix}
 0    & -w_z  &  w_y \\
 w_z  &  0    & -w_x \\
-w_y  &  w_x  &  0 \\
\end{bmatrix}
\right),
 R^{-1}(\cdot) \omega=0 \omega \omega_0 \omega_0 
\frac{d f}{d \omega} = Z^0 + \frac{1}{2!} Z^1+ \frac{1}{2 (3!)}Z^2 - \frac{1}{6 (5!)}Z^4 + \frac{1}{6 (7!)} Z^6 - (...)
 Z=[\omega_0]_{\times} \frac{d f}{d \omega} = I + \frac{1}{2} Z + \beta(\omega_0) Z^2 \beta \beta \|\omega_0\|","['differential-geometry', 'matrix-calculus', 'rotations', 'matrix-exponential']"
7,What does $\nabla^j$ mean in Riemannian geometry?,What does  mean in Riemannian geometry?,\nabla^j,"I was learning about Holder space from this paper page 8 , and it uses the notation $\nabla^j u$ for a function $u$ on a Riemannian manifold $M$ . I am confused about the meaning of it. I think it might mean $\nabla_{\frac{\partial}{\partial x_j}}u = \frac{\partial}{\partial x_j }u$ locally, since this description would match the definition of the Holder space on the Euclidean space. But it is not well defined in my opinion, since it is not invariant under coordinate change. After recalling the definition of a Holder space on on an Euclidean space, I am now convinced the author should mean something like $\nabla^j u = \nabla_{\frac{\partial}{\partial x_{l_1}}}\ldots \nabla_{\frac{\partial}{\partial x_{l_j}}}u$ . However as I said before, this seems to not be independent of the coordinate choice.","I was learning about Holder space from this paper page 8 , and it uses the notation for a function on a Riemannian manifold . I am confused about the meaning of it. I think it might mean locally, since this description would match the definition of the Holder space on the Euclidean space. But it is not well defined in my opinion, since it is not invariant under coordinate change. After recalling the definition of a Holder space on on an Euclidean space, I am now convinced the author should mean something like . However as I said before, this seems to not be independent of the coordinate choice.",\nabla^j u u M \nabla_{\frac{\partial}{\partial x_j}}u = \frac{\partial}{\partial x_j }u \nabla^j u = \nabla_{\frac{\partial}{\partial x_{l_1}}}\ldots \nabla_{\frac{\partial}{\partial x_{l_j}}}u,"['real-analysis', 'differential-geometry', 'differential-topology', 'riemannian-geometry']"
8,Trouble with the definition of the cross product,Trouble with the definition of the cross product,,"Throughout the question, please keep in mind that I know very little differential geometry. I.e., just the intrinsic definitions of differentiable/Riemannian manifolds and the metric tensor, etc. I am trying to understand the definition of the cross product given by Wikipedia here: https://en.wikipedia.org/wiki/Cross_product#Index_notation_for_tensors The article says that we can define the cross product $c$ of two vectors $u$ , $v$ given a suitable ""dot product"" $\eta^{mi}$ as follows $c^m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\eta^{mi}\epsilon_{ijk}u^jv^k$ To demonstrate my current understanding of this definition, I will introduce some notation and terminology. Then I will show where my confusion arises with an example. I do apologize in advance for the length of this post. Let $M$ be a smooth Riemannian manifold on $\mathbb{R}^3$ with the metric tensor $g$ . Pick a coordinate chart $(U,\phi)$ with $\phi$ a diffeomorphism. We define a collection $\beta = \{b_i:U \to TM | i\in\{1,2,3\}\}$ of vector fields, called coordinate vectors, as follows $b_i(x) := \Big(x,\big(\delta_x \circ \frac{\partial{\phi^{-1}}}{\partial{q_i}} \circ \phi\big)(x)\Big)$ where $\delta_x:\mathbb{R}^3 \to T_xM$ denotes the canonical bijection. The coordinate vectors induce a natural basis $\gamma_x$ at each point $x \in U$ for the tangent space $T_xM$ . Let $[g_x]_S$ denote the matrix representation of the metric tensor at the point $x$ in the standard basis for $T_xM$ and let $[g_x]_{\gamma_x}$ denote the matrix representation in the basis $\gamma_x$ . My understanding of the above definition of the cross product now follows. Let $u,v \in T_xM$ be tangent vectors and let $[u]_{\gamma_x}=\begin{bmatrix} u_1\\ u_2\\ u_3 \end{bmatrix}$ $\space \space \space \space \space \space [v]_{\gamma_x}=\begin{bmatrix} v_1\\ v_2\\ v_3 \end{bmatrix}$ denote the coordinates of $u,v$ in the basis $\gamma_x$ . Then we define the $m$ th coordinate of the cross product $u \times v \in T_xM$ in the basis $\gamma_x$ as $\big([u \times v]_{\gamma_x}\big)_m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\big([g_x]_{\gamma_x}\big)_{mi}\epsilon_{ijk}u_jv_k$ Now I will demonstrate my apparent misunderstanding with an example. Let the manifold $M$ be the usual Riemannian manifold on $\mathbb{R}^3$ and let $\phi$ be given by $\phi(x_1,x_2,x_3) = (x_1,x_2,x_3-x_1^2-x_2^2)$ $\phi^{-1}(q_1,q_2,q_3)=(q_1,q_2,q_3+q_1^2+q_2^2)$ The Jacobian matrix $J$ of $\phi^{-1}$ is $J=\begin{bmatrix} 1 & 0 & 0 \\\ 0 & 1 & 0 \\\ 2q_1 & 2q_2 & 1 \end{bmatrix}$ $\space \space \space \space \space \space J^{-1}=\begin{bmatrix} 1 & 0 & 0 \\\ 0 & 1 & 0 \\\ -2q_1 & -2q_2 & 1 \end{bmatrix}$ And the matrix representation of the metric tensor in the basis $\gamma_x$ is $[g_x]_{\gamma_x} = J^T[g_x]_SJ = \begin{bmatrix} 1+4q_1^2 & 4q_1q_2 & 2q_1 \\\ 4q_1q_2 & 1+4q_2^2 & 2q_2 \\\ 2q_1 & 2q_2 & 1 \end{bmatrix}$ Now choose $x=(1,1,-1)$ . The coordinates of $x$ are evidently $\phi(x) = (1,1,1)$ and the three matrices above become $J=\begin{bmatrix} 1 & 0 & 0 \\\ 0 & 1 & 0 \\\ 2 & 2 & 1 \end{bmatrix}$ $\space \space \space \space \space \space J^{-1}=\begin{bmatrix} 1 & 0 & 0 \\\ 0 & 1 & 0 \\\ -2 & -2 & 1 \end{bmatrix}$ $\space \space \space \space \space \space [g_x]_{\gamma_x} = \begin{bmatrix} 5 & 4 & 2 \\\ 4 & 5 & 2 \\\ 2 & 2 & 1 \end{bmatrix}$ Now we compute the cross product in the basis $\gamma_x$ . Using my understanding of the definition as outlined above, I get $[u \times v]_{\gamma_x} = \begin{bmatrix} 36 \\\ 35 \\\ 16 \end{bmatrix}$ If we instead compute the cross product in the standard basis, then using my understanding of the definition, I get $[u \times v]_S = \begin{bmatrix} 0 \\\ -1 \\\ 2 \end{bmatrix}$ Naturally, these results ought to agree if we perform a change of basis on $[u \times v]_{\gamma_x}$ . Doing just that, I get $[u \times v]_S = J[u \times v]_{\gamma_x} = \begin{bmatrix} 1 & 0 & 0 \\\ 0 & 1 & 0 \\\ 2 & 2 & 1 \end{bmatrix} \begin{bmatrix} 36 \\\ 35 \\\ 16 \end{bmatrix} = \begin{bmatrix} 36 \\\ 35 \\\ 158 \end{bmatrix}$ Clearly, these do not agree. I can think of several reasons for this. Perhaps the definition given on Wikipedia is erroneous or only works for orthogonal coordinates. Perhaps I am misinterpreting the definition given on Wikipedia. Or maybe I have made an error somewhere in my calculation. My question is then as follows. How should I interpret the definition given on Wikipedia, and how should one express that definition using the notation provided here?","Throughout the question, please keep in mind that I know very little differential geometry. I.e., just the intrinsic definitions of differentiable/Riemannian manifolds and the metric tensor, etc. I am trying to understand the definition of the cross product given by Wikipedia here: https://en.wikipedia.org/wiki/Cross_product#Index_notation_for_tensors The article says that we can define the cross product of two vectors , given a suitable ""dot product"" as follows To demonstrate my current understanding of this definition, I will introduce some notation and terminology. Then I will show where my confusion arises with an example. I do apologize in advance for the length of this post. Let be a smooth Riemannian manifold on with the metric tensor . Pick a coordinate chart with a diffeomorphism. We define a collection of vector fields, called coordinate vectors, as follows where denotes the canonical bijection. The coordinate vectors induce a natural basis at each point for the tangent space . Let denote the matrix representation of the metric tensor at the point in the standard basis for and let denote the matrix representation in the basis . My understanding of the above definition of the cross product now follows. Let be tangent vectors and let denote the coordinates of in the basis . Then we define the th coordinate of the cross product in the basis as Now I will demonstrate my apparent misunderstanding with an example. Let the manifold be the usual Riemannian manifold on and let be given by The Jacobian matrix of is And the matrix representation of the metric tensor in the basis is Now choose . The coordinates of are evidently and the three matrices above become Now we compute the cross product in the basis . Using my understanding of the definition as outlined above, I get If we instead compute the cross product in the standard basis, then using my understanding of the definition, I get Naturally, these results ought to agree if we perform a change of basis on . Doing just that, I get Clearly, these do not agree. I can think of several reasons for this. Perhaps the definition given on Wikipedia is erroneous or only works for orthogonal coordinates. Perhaps I am misinterpreting the definition given on Wikipedia. Or maybe I have made an error somewhere in my calculation. My question is then as follows. How should I interpret the definition given on Wikipedia, and how should one express that definition using the notation provided here?","c u v \eta^{mi} c^m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\eta^{mi}\epsilon_{ijk}u^jv^k M \mathbb{R}^3 g (U,\phi) \phi \beta = \{b_i:U \to TM | i\in\{1,2,3\}\} b_i(x) := \Big(x,\big(\delta_x \circ \frac{\partial{\phi^{-1}}}{\partial{q_i}} \circ \phi\big)(x)\Big) \delta_x:\mathbb{R}^3 \to T_xM \gamma_x x \in U T_xM [g_x]_S x T_xM [g_x]_{\gamma_x} \gamma_x u,v \in T_xM [u]_{\gamma_x}=\begin{bmatrix}
u_1\\
u_2\\
u_3
\end{bmatrix} \space \space \space \space \space \space [v]_{\gamma_x}=\begin{bmatrix}
v_1\\
v_2\\
v_3
\end{bmatrix} u,v \gamma_x m u \times v \in T_xM \gamma_x \big([u \times v]_{\gamma_x}\big)_m := \sum_{i=1}^3\sum_{j=1}^3\sum_{k=1}^3\big([g_x]_{\gamma_x}\big)_{mi}\epsilon_{ijk}u_jv_k M \mathbb{R}^3 \phi \phi(x_1,x_2,x_3) = (x_1,x_2,x_3-x_1^2-x_2^2) \phi^{-1}(q_1,q_2,q_3)=(q_1,q_2,q_3+q_1^2+q_2^2) J \phi^{-1} J=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2q_1 & 2q_2 & 1
\end{bmatrix} \space \space \space \space \space \space J^{-1}=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
-2q_1 & -2q_2 & 1
\end{bmatrix} \gamma_x [g_x]_{\gamma_x} = J^T[g_x]_SJ = \begin{bmatrix}
1+4q_1^2 & 4q_1q_2 & 2q_1 \\\
4q_1q_2 & 1+4q_2^2 & 2q_2 \\\
2q_1 & 2q_2 & 1
\end{bmatrix} x=(1,1,-1) x \phi(x) = (1,1,1) J=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2 & 2 & 1
\end{bmatrix} \space \space \space \space \space \space J^{-1}=\begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
-2 & -2 & 1
\end{bmatrix} \space \space \space \space \space \space [g_x]_{\gamma_x} = \begin{bmatrix}
5 & 4 & 2 \\\
4 & 5 & 2 \\\
2 & 2 & 1
\end{bmatrix} \gamma_x [u \times v]_{\gamma_x} = \begin{bmatrix}
36 \\\
35 \\\
16
\end{bmatrix} [u \times v]_S = \begin{bmatrix}
0 \\\
-1 \\\
2
\end{bmatrix} [u \times v]_{\gamma_x} [u \times v]_S = J[u \times v]_{\gamma_x} = \begin{bmatrix}
1 & 0 & 0 \\\
0 & 1 & 0 \\\
2 & 2 & 1
\end{bmatrix} \begin{bmatrix}
36 \\\
35 \\\
16
\end{bmatrix} = \begin{bmatrix}
36 \\\
35 \\\
158
\end{bmatrix}","['differential-geometry', 'riemannian-geometry', 'coordinate-systems', 'cross-product']"
9,Deriving Bachet's duplication formula,Deriving Bachet's duplication formula,,"Let $y^2-x^3 = c$ be Bachet's equation and pretend $(x,y)$ is a solution. The tangent at $(x,y)$ of Bachet's curve is going to intersect it in a unique new point whose coordinates are supposed to yield the so-called ""duplication formula"": $(\frac{x^4-8cx}{4y^2},\frac{-x^6-20cx^3+8c^2}{8y^3})$ I have not been able to re-derive this formula no matter how hard I try. It just won't work. Attempt: Let $f(x,y)=y^2-x^3-c$ , then the curve is implicitly parametrized by $f(x,y)=0$ . The gradient of $f$ at $(x,y)$ , which is $(-3x^2,2y)$ , is orthogonal to the curve at $(x,y)$ . Therefore, the equation of the tangent is $-3x^2(X-x)+2y(Y-y) = 0$ (I'm looking at the only line orthogonal to the gradient at $(x,y)$ going through $(x,y)$ ) So, if $(X,Y)$ is the coordinates of the point of intersection I'm looking for, it should be the unique solution (different from $(x,y)$ ), of the following conditions: $-3x^2(X-x)+2y(Y-y) = 0$ and $Y^2 - X^3 - c = 0$ with the assumption that, of course, by hypothesis, $y^2 - x^3 = c$ Is my reasoning sound until now? Mathematica does not seem to agree with me, but it could be that the full-simplify function isn't sophisticated enough (it does not reduce to Bachet's formula) FullSimplify[Solve[{2*y*(Y - y) - 3*x^2*(X - x) == 0,     Y^2 - X^3 - c == 0}, {X, Y}], y^2 - x^3 == c] I'm not expecting anybody to actually carry out the tedious calculations, though if somebody can manage to make Mathematica or some other software spit out the formula on its own I would be happy as I am trying to program an algorithm which automatically takes a curve in and finds the formula","Let be Bachet's equation and pretend is a solution. The tangent at of Bachet's curve is going to intersect it in a unique new point whose coordinates are supposed to yield the so-called ""duplication formula"": I have not been able to re-derive this formula no matter how hard I try. It just won't work. Attempt: Let , then the curve is implicitly parametrized by . The gradient of at , which is , is orthogonal to the curve at . Therefore, the equation of the tangent is (I'm looking at the only line orthogonal to the gradient at going through ) So, if is the coordinates of the point of intersection I'm looking for, it should be the unique solution (different from ), of the following conditions: and with the assumption that, of course, by hypothesis, Is my reasoning sound until now? Mathematica does not seem to agree with me, but it could be that the full-simplify function isn't sophisticated enough (it does not reduce to Bachet's formula) FullSimplify[Solve[{2*y*(Y - y) - 3*x^2*(X - x) == 0,     Y^2 - X^3 - c == 0}, {X, Y}], y^2 - x^3 == c] I'm not expecting anybody to actually carry out the tedious calculations, though if somebody can manage to make Mathematica or some other software spit out the formula on its own I would be happy as I am trying to program an algorithm which automatically takes a curve in and finds the formula","y^2-x^3 = c (x,y) (x,y) (\frac{x^4-8cx}{4y^2},\frac{-x^6-20cx^3+8c^2}{8y^3}) f(x,y)=y^2-x^3-c f(x,y)=0 f (x,y) (-3x^2,2y) (x,y) -3x^2(X-x)+2y(Y-y) = 0 (x,y) (x,y) (X,Y) (x,y) -3x^2(X-x)+2y(Y-y) = 0 Y^2 - X^3 - c = 0 y^2 - x^3 = c","['proof-verification', 'differential-geometry', 'elliptic-curves']"
10,Tangent space and Jacobian,Tangent space and Jacobian,,"I'm reading John Willards Topology with a differential view point and an confused about tangent spaces. To define the notion of derivative $df_x$ for a smooth map between smooth manifolds we introduce a tanget space at each point $x$ in the manifold $M$ . The tangent space is denoted $TM_x$ . If $M$ is an $m$ -dimensional manifold then $TM_x$ is the $m$ -dimensional hyperplane through the origin parallel to the hyperplane that that best approximates $M$ at $x$ . Similarly one things of the nonhomegeneous linear mapping from the tangent hyperplane at $x$ to the tangent hyperplane at $y$ which best approximates $f$ . My confusion lies the following sentence: Translating both hyperplanes to the origin, one obtains $df_x$ . Is this saying $df_x$ is a map between these two hyperplanes? If so, how should I think about this map what is getting mapped to what? Edit: All manifolds are in $R^n$ for some $n$ , but the two manifolds may not be of the same dimension.","I'm reading John Willards Topology with a differential view point and an confused about tangent spaces. To define the notion of derivative for a smooth map between smooth manifolds we introduce a tanget space at each point in the manifold . The tangent space is denoted . If is an -dimensional manifold then is the -dimensional hyperplane through the origin parallel to the hyperplane that that best approximates at . Similarly one things of the nonhomegeneous linear mapping from the tangent hyperplane at to the tangent hyperplane at which best approximates . My confusion lies the following sentence: Translating both hyperplanes to the origin, one obtains . Is this saying is a map between these two hyperplanes? If so, how should I think about this map what is getting mapped to what? Edit: All manifolds are in for some , but the two manifolds may not be of the same dimension.",df_x x M TM_x M m TM_x m M x x y f df_x df_x R^n n,"['differential-geometry', 'differential-topology']"
11,"How to prove $\frac{\partial}{\partial x^r} (x^r) = 1$ where $(U, (x^1, ..., x^n))$ is a local chart of a smooth manifold.",How to prove  where  is a local chart of a smooth manifold.,"\frac{\partial}{\partial x^r} (x^r) = 1 (U, (x^1, ..., x^n))","Let $M$ be a  smooth manifold. I am getting lost in the notations. Could someone please explain me how to prove $\frac{\partial}{\partial x^r} (x^r) = 1$ where $(U, \phi = (x^1, ..., x^n))$ is a local chart of $M$ ? Also I would appreciate if someone one can tell me what I should think of $\frac{\partial}{\partial x^r}$ as intuitively?",Let be a  smooth manifold. I am getting lost in the notations. Could someone please explain me how to prove where is a local chart of ? Also I would appreciate if someone one can tell me what I should think of as intuitively?,"M \frac{\partial}{\partial x^r} (x^r) = 1 (U, \phi = (x^1, ..., x^n)) M \frac{\partial}{\partial x^r}","['differential-geometry', 'smooth-manifolds', 'intuition']"
12,$\Delta \mathbf n = -2 \mathbf n$ on the Euclidean sphere,on the Euclidean sphere,\Delta \mathbf n = -2 \mathbf n,"Let us consider the Euclidean two-sphere, defined by the embedding in the three dimensional Euclidean space as $$ \mathbf n \cdot \mathbf n = 1\,, $$ where $\cdot$ denotes the standard scalar product. The metric on the sphere, in some coordinates $x^i$ , is expressed as $$ \gamma_{ij}=\mathbf e_i \cdot \mathbf e_j\,, $$ where $\mathbf e_i=\partial_i\mathbf n$ . For instance, in the standard spherical coordinates $$ \mathbf n=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta) $$ and $$ \gamma_{\theta\theta}=1\,,\qquad \gamma_{\phi\phi}=\sin^2\theta\,,\qquad \gamma_{\theta\phi}=0\,. $$ We define the Laplace-Beltrami operator on the sphere by $ \Delta = \gamma^{ij} D_iD_i $ , where $\gamma^{ij}$ is its inverse and $D_i$ is the associated Levi-Civita connection. I would like to prove that $$\Delta \mathbf n = -2 \mathbf n$$ and that in higher dimensions the same holds with $2$ replaced by the dimension of the sphere. I came to believe that this is true by an explicit check in spherical coordinates in dimensions $3$ , $4$ and $6$ . Considering that parallel transport of a given tangent vector $\mathbf v$ defined at the point $x+dx$ to the point $x$ is defined by keeping constant its embedding components and then projecting it on the sphere at the point $x$ , we have $$ \mathbf v_{\parallel}(x+dx,x)=\mathbf v(x+dx)-\mathbf v(x+dx)\cdot \mathbf n (x)\, \mathbf n(x) $$ hence $$ D_i\mathbf v\, dx^i = \mathbf v_{\parallel}(x+dx,x)- \mathbf v (x)= (\partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v\, \mathbf n)dx^i $$ where we have used $\mathbf n \cdot \partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v=0$ and $$ D_i\mathbf v = \partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v\, \mathbf n\,. $$ Applying this to the basis vectors $\mathbf e_j =\partial_j\mathbf n$ affords $$ D_i\mathbf e_j = \partial_i \mathbf e_j+\gamma_{ij}\mathbf n\,. $$ But unfortunataly I am not able to go further.","Let us consider the Euclidean two-sphere, defined by the embedding in the three dimensional Euclidean space as where denotes the standard scalar product. The metric on the sphere, in some coordinates , is expressed as where . For instance, in the standard spherical coordinates and We define the Laplace-Beltrami operator on the sphere by , where is its inverse and is the associated Levi-Civita connection. I would like to prove that and that in higher dimensions the same holds with replaced by the dimension of the sphere. I came to believe that this is true by an explicit check in spherical coordinates in dimensions , and . Considering that parallel transport of a given tangent vector defined at the point to the point is defined by keeping constant its embedding components and then projecting it on the sphere at the point , we have hence where we have used and Applying this to the basis vectors affords But unfortunataly I am not able to go further.","
\mathbf n \cdot \mathbf n = 1\,,
 \cdot x^i 
\gamma_{ij}=\mathbf e_i \cdot \mathbf e_j\,,
 \mathbf e_i=\partial_i\mathbf n 
\mathbf n=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)
 
\gamma_{\theta\theta}=1\,,\qquad \gamma_{\phi\phi}=\sin^2\theta\,,\qquad
\gamma_{\theta\phi}=0\,.
 
\Delta = \gamma^{ij} D_iD_i
 \gamma^{ij} D_i \Delta \mathbf n = -2 \mathbf n 2 3 4 6 \mathbf v x+dx x x 
\mathbf v_{\parallel}(x+dx,x)=\mathbf v(x+dx)-\mathbf v(x+dx)\cdot \mathbf n (x)\, \mathbf n(x)
 
D_i\mathbf v\, dx^i = \mathbf v_{\parallel}(x+dx,x)- \mathbf v (x)= (\partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v\, \mathbf n)dx^i
 \mathbf n \cdot \partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v=0 
D_i\mathbf v = \partial_i\mathbf v+\partial_i\mathbf n \cdot \mathbf v\, \mathbf n\,.
 \mathbf e_j =\partial_j\mathbf n 
D_i\mathbf e_j = \partial_i \mathbf e_j+\gamma_{ij}\mathbf n\,.
","['differential-geometry', 'riemannian-geometry', 'surfaces', 'laplacian']"
13,Prove that the covariant derivative commutes with musical isomorphisms,Prove that the covariant derivative commutes with musical isomorphisms,,"Suppose I have a covector field $\omega$ and a covariant derivative $\nabla_{X}$ for some vector field $X$ on a Riemannian manifold $(M, g)$ . Define $X^{\flat} \in \mathfrak{X}^{*}(M)$ as $X^{\flat}(Y) = g(X, Y)$ , and $\omega^{\sharp}$ as the unique vector for which $\omega(X) = g(\omega^{\sharp}, X)$ ; it's easily checked that these musical maps are mutually inverse, so they're isomorphisms between $\mathfrak{X}(M)$ and $\mathfrak{X}^{*}(M)$ . Anyway, I want to prove that, for the Levi-Civita connection $\nabla$ on $(M, g)$ , we have $\nabla_{X}(\omega^{\sharp}) = (\nabla_{X}\omega)^{\sharp}.$ In several books I've been reading, it says that this follows immediately from $\nabla g = 0$ . However, I keep getting that this is wrong, for example if $(E_{1},...,E_{n})$ is a local orthonormal frame on $M$ , I get that $\nabla_{E_{i}}(E_{j}^{*}{^{\sharp}})$ does not equal $(\nabla_{E_{i}}E_{j}^{*})^{\sharp}$ . Here's what I've been trying: 1. Finding $\nabla_{E_{i}}(E_{j}^{*}{^{\sharp}})$ : I start by finding the components of $E_{j}^{*}{^{\sharp}}$ $$(E_{j}^{*}{^{\sharp}})^{k} = \sum_{l} g^{kl} (E_{j}^{*})_{l} = \delta_{kj}.$$ Therefore, $E_{j}^{*}{^{\sharp}} = E_{j}$ . Now, I want to find $\nabla_{E_{i}} E_{j}^{*}{^{\sharp}} = \nabla_{E_{i}} E_{j}$ . $$\nabla_{E_{i}} E_{j} = \sum_{k} \Gamma_{ij}^{k}E_{k},$$ where $\Gamma_{ij}^{k}$ are the Christoffel symbols with respect to this frame. 2. Finding $(\nabla_{E_{i}}E_{j}^{*})^{\sharp}$ : again, I begin by finding the components, this time of $(\nabla_{E_{i}}E_{j}^{*})^{\sharp}$ : $$ ((\nabla_{E_{i}}E_{j}^{*})^{\sharp})^{k} = \sum_{l} g^{kl} (\nabla_{E_{i}}E_{j}^{*})_{l},$$ so I want to find $\nabla_{E_{i}}E_{j}^{*}(E_{l})$ . Since $\nabla_{E_{i}}$ is a tensor derivative, we have: $$ 0 = \nabla_{E_{i}}(E_{j}^{*}(E_{l})) = \nabla_{E_{i}}E_{j}^{*}(E_{l}) + E_{j}^{*}(\nabla_{E_{i}}E_{l}),$$ so $\nabla_{E_{i}}E_{j}^{*}(E_{l}) = - E_{j}^{*}(\sum_{k}\Gamma_{il}^{k}E_{k}) = - \Gamma_{il}^{j}$ . Finally, $$ ((\nabla_{E_{i}}E_{j}^{*})^{\sharp})^{k} = \sum_{l} g^{kl} (\nabla_{E_{i}}E_{j}^{*})_{l} = -\Gamma_{ik}^{j},$$ so $(\nabla_{E_{i}}E_{j}^{*})^{\sharp} = \sum_{k} (-\Gamma_{ik}^{j}E_{k}) = -\sum_{k}\Gamma_{ik}^{j}E_{k}$ . Since I don't know that $\Gamma_{ik}^{j} + \Gamma_{ij}^{k} = 0$ , I don't see why these two are equal. Did I make a mistake somewhere; is there an easier proof of this fact?","Suppose I have a covector field and a covariant derivative for some vector field on a Riemannian manifold . Define as , and as the unique vector for which ; it's easily checked that these musical maps are mutually inverse, so they're isomorphisms between and . Anyway, I want to prove that, for the Levi-Civita connection on , we have In several books I've been reading, it says that this follows immediately from . However, I keep getting that this is wrong, for example if is a local orthonormal frame on , I get that does not equal . Here's what I've been trying: 1. Finding : I start by finding the components of Therefore, . Now, I want to find . where are the Christoffel symbols with respect to this frame. 2. Finding : again, I begin by finding the components, this time of : so I want to find . Since is a tensor derivative, we have: so . Finally, so . Since I don't know that , I don't see why these two are equal. Did I make a mistake somewhere; is there an easier proof of this fact?","\omega \nabla_{X} X (M, g) X^{\flat} \in \mathfrak{X}^{*}(M) X^{\flat}(Y) = g(X, Y) \omega^{\sharp} \omega(X) = g(\omega^{\sharp}, X) \mathfrak{X}(M) \mathfrak{X}^{*}(M) \nabla (M, g) \nabla_{X}(\omega^{\sharp}) = (\nabla_{X}\omega)^{\sharp}. \nabla g = 0 (E_{1},...,E_{n}) M \nabla_{E_{i}}(E_{j}^{*}{^{\sharp}}) (\nabla_{E_{i}}E_{j}^{*})^{\sharp} \nabla_{E_{i}}(E_{j}^{*}{^{\sharp}}) E_{j}^{*}{^{\sharp}} (E_{j}^{*}{^{\sharp}})^{k} = \sum_{l} g^{kl} (E_{j}^{*})_{l} = \delta_{kj}. E_{j}^{*}{^{\sharp}} = E_{j} \nabla_{E_{i}} E_{j}^{*}{^{\sharp}} = \nabla_{E_{i}} E_{j} \nabla_{E_{i}} E_{j} = \sum_{k} \Gamma_{ij}^{k}E_{k}, \Gamma_{ij}^{k} (\nabla_{E_{i}}E_{j}^{*})^{\sharp} (\nabla_{E_{i}}E_{j}^{*})^{\sharp}  ((\nabla_{E_{i}}E_{j}^{*})^{\sharp})^{k} = \sum_{l} g^{kl} (\nabla_{E_{i}}E_{j}^{*})_{l}, \nabla_{E_{i}}E_{j}^{*}(E_{l}) \nabla_{E_{i}}  0 = \nabla_{E_{i}}(E_{j}^{*}(E_{l})) = \nabla_{E_{i}}E_{j}^{*}(E_{l}) + E_{j}^{*}(\nabla_{E_{i}}E_{l}), \nabla_{E_{i}}E_{j}^{*}(E_{l}) = - E_{j}^{*}(\sum_{k}\Gamma_{il}^{k}E_{k}) = - \Gamma_{il}^{j}  ((\nabla_{E_{i}}E_{j}^{*})^{\sharp})^{k} = \sum_{l} g^{kl} (\nabla_{E_{i}}E_{j}^{*})_{l} = -\Gamma_{ik}^{j}, (\nabla_{E_{i}}E_{j}^{*})^{\sharp} = \sum_{k} (-\Gamma_{ik}^{j}E_{k}) = -\sum_{k}\Gamma_{ik}^{j}E_{k} \Gamma_{ik}^{j} + \Gamma_{ij}^{k} = 0","['differential-geometry', 'tensors', 'vector-fields', 'connections']"
14,are geodesic shortest path or quickest path?,are geodesic shortest path or quickest path?,,"I'm a bit confused with geodesics : are they the shortest path (in distance) or the quickest path (in time). For example, Let take a triangle ABC. I'm using a car. I'm in $A$ and I have to go in $B$ . The path $AB$ is 2km long, but I can go at 10 km/h only, where as the path that path through C has 4 km length, but it's a free way and I can go at 100 km/h. Clearly, the path through C is quicker, but the path AB is shorter. What is going to be the Geodesic ? The path through $C$ or the path $AB$ ?","I'm a bit confused with geodesics : are they the shortest path (in distance) or the quickest path (in time). For example, Let take a triangle ABC. I'm using a car. I'm in and I have to go in . The path is 2km long, but I can go at 10 km/h only, where as the path that path through C has 4 km length, but it's a free way and I can go at 100 km/h. Clearly, the path through C is quicker, but the path AB is shorter. What is going to be the Geodesic ? The path through or the path ?",A B AB C AB,['differential-geometry']
15,Whether the induced map in de Rham cohomology is injective,Whether the induced map in de Rham cohomology is injective,,"Let $M, N$ be smooth manifolds, and let $f: M \rightarrow N$ be a surjective submersion, i.e. a surjective smooth map such that the differential $f_{*}$ is also surjective. I have shown that for all $k \geq 0$ , the pullback map of $k$ -forms $$ f^{*} : \Omega^{k}(N) \rightarrow \Omega^{k} (M)$$ is injective. However, the problem now asks me whether the induced map on de Rham cohomology $$  H_{dR}^k (N) \rightarrow H_{dR}^k (M) : [\omega] \mapsto [f^{*} \omega] $$ is also injective ? I was trying to prove this. I took $[\omega] \in H_{dR}^{k} (N)$ and assumed $[f^{*} \omega] = [0]$ . This means $f^{*} \omega \sim 0$ or $$ f^{*} \omega = d \tau $$ for some $(k-1)$ form $\tau$ on $M$ . I want to conclude from this somehow that $[\omega ] = [0]$ or $\omega = d \sigma$ for some $(k-1)$ form $\sigma$ on $N$ . But I'm not sure if the statement is even true. I tried to find a counter example, but couldn't. Any help is appreciated!","Let be smooth manifolds, and let be a surjective submersion, i.e. a surjective smooth map such that the differential is also surjective. I have shown that for all , the pullback map of -forms is injective. However, the problem now asks me whether the induced map on de Rham cohomology is also injective ? I was trying to prove this. I took and assumed . This means or for some form on . I want to conclude from this somehow that or for some form on . But I'm not sure if the statement is even true. I tried to find a counter example, but couldn't. Any help is appreciated!","M, N f: M \rightarrow N f_{*} k \geq 0 k  f^{*} : \Omega^{k}(N) \rightarrow \Omega^{k} (M)   H_{dR}^k (N) \rightarrow H_{dR}^k (M) : [\omega] \mapsto [f^{*} \omega]  [\omega] \in H_{dR}^{k} (N) [f^{*} \omega] = [0] f^{*} \omega \sim 0  f^{*} \omega = d \tau  (k-1) \tau M [\omega ] = [0] \omega = d \sigma (k-1) \sigma N","['differential-geometry', 'homology-cohomology', 'differential-forms']"
16,Connected components of nonempty level sets form a foliation of $M$.,Connected components of nonempty level sets form a foliation of .,M,"Let $M,N$ smooth manifolds and $F:M \to N$ a smooth submersion. Show that the connected components of nonempty level sets form a foliation of $M$. My idea is to use the Global Fröbenius theorem for the distribution $D$, where $D_{p}=ker (dF)_{p}$, I proved that $D$ is involutive distribution and for each $p \in M$, $F^{-1}(F(p))$ is an integral manifold for $M$ passing by $p$. My question is: If I prove that the connected components of $F^{-1}(F(p))$ are integral manifolds for $M$, then is each one a maximal integral manifold passing by $p$ and the global Frobenius theorem assures that connected components are a foliation for $M$?","Let $M,N$ smooth manifolds and $F:M \to N$ a smooth submersion. Show that the connected components of nonempty level sets form a foliation of $M$. My idea is to use the Global Fröbenius theorem for the distribution $D$, where $D_{p}=ker (dF)_{p}$, I proved that $D$ is involutive distribution and for each $p \in M$, $F^{-1}(F(p))$ is an integral manifold for $M$ passing by $p$. My question is: If I prove that the connected components of $F^{-1}(F(p))$ are integral manifolds for $M$, then is each one a maximal integral manifold passing by $p$ and the global Frobenius theorem assures that connected components are a foliation for $M$?",,"['differential-geometry', 'smooth-manifolds', 'foliations']"
17,Immersion of non-orientable manifold in a small orientable one,Immersion of non-orientable manifold in a small orientable one,,"I was trying to prove the following fact: given a non orientable manifold $M$ of dimension $m$, $M$ is always contained in an orientable manifold of dimension $m+1$. I have gotten nothing out of it, so I am asking you. I warn you that my background involves no charachteristic classes, but only basic differential geometry. Thanks in advance","I was trying to prove the following fact: given a non orientable manifold $M$ of dimension $m$, $M$ is always contained in an orientable manifold of dimension $m+1$. I have gotten nothing out of it, so I am asking you. I warn you that my background involves no charachteristic classes, but only basic differential geometry. Thanks in advance",,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'orientation', 'non-orientable-surfaces']"
18,Does every connection admit a parallel volume form?,Does every connection admit a parallel volume form?,,Let $E$ be a smooth orientable vector bundle of rank $k$ over a manifold $M$. Let $\nabla$ be a connection on $E$. Does there always exist a non-zero parallel section of $\Lambda_k(E)$? What about $E=TM$? (when $M$ is orientable),Let $E$ be a smooth orientable vector bundle of rank $k$ over a manifold $M$. Let $\nabla$ be a connection on $E$. Does there always exist a non-zero parallel section of $\Lambda_k(E)$? What about $E=TM$? (when $M$ is orientable),,"['differential-geometry', 'vector-bundles', 'exterior-algebra', 'connections']"
19,Proving that two curves in $\mathbb{R^3}$ with the same binormal vector are congruent,Proving that two curves in  with the same binormal vector are congruent,\mathbb{R^3},"Let $\alpha, \bar{\alpha}: I \mapsto \mathbb{R^3}$ be two regular unit speed curves with non vanishing curvature and torsion. Prove that if the binormal vectors of the curves coincide, i.e $B(s) = \bar{B}(s)$, they are congruent. I know there is a unique isometry that takes the orthonormal frenet frame of $\alpha$ to that of $\bar{\alpha}$, but I don't know how to prove what the exercise is asking me. I  tried a proof by contradiction but that led nowhere. I'd be grateful for any help.","Let $\alpha, \bar{\alpha}: I \mapsto \mathbb{R^3}$ be two regular unit speed curves with non vanishing curvature and torsion. Prove that if the binormal vectors of the curves coincide, i.e $B(s) = \bar{B}(s)$, they are congruent. I know there is a unique isometry that takes the orthonormal frenet frame of $\alpha$ to that of $\bar{\alpha}$, but I don't know how to prove what the exercise is asking me. I  tried a proof by contradiction but that led nowhere. I'd be grateful for any help.",,"['differential-geometry', 'curves', 'isometry', 'frenet-frame']"
20,Flow invariance of submanifold implies that tangent subspace is unvariant under the action of differential map,Flow invariance of submanifold implies that tangent subspace is unvariant under the action of differential map,,"Suppose that you have a system of ODEs $$\dot{x} = F(x), \, x \in \mathbb{R}^n,$$ and $x_0$ is a an equilibrium point of this system, i.e. $F(x_0) = 0$. Suppose you have a locally invariant smooth submanifold $\mathcal{M}$ that passes through $x_0$. By locally invariant I mean that for any point $p \in \mathcal{M}$ there exists an $\varepsilon > 0$ such that $\varphi^{t}(p) \in \mathcal{M}$ for $\lvert t \rvert < \varepsilon$, where $\varphi^t$ is the flow defined by a system of ODEs. I believe that if these conditions are met, then $DF(x_0) (T_{x_0}\mathcal{M}) \subset T_{x_0}\mathcal{M}$; $DF(x_0)$ is a Jacobi matrix for $F(x)$ at point $x_0$. It feels like I had encountered similar statement somewhere before, but I can't remember the exact reference. I can't find a counter-example or a proof for this statement from the get-go, though I definitely want to crack that puzzle if there is no reference to it.  If this statement was true, it would much simplify one of my proofs, so that's the reason why I'm so interested in it. So, mostly I'm interested in the reference where this (or very similar) statement had been proved. If the statement is false and you know a counter-example, that would be very useful (although a bit heartbreaking). ADDED LATER I have a sketch of the proof for this statement (kind of). If we pick any vector $v \in T_{x_0}\mathcal{M}$ there exists a curve $\gamma_v(s)$ such that $\gamma_v'(0) = v, \gamma_v(0) = x_0,$ and which lies in $\mathcal{M}$. If we choose some $\tau$ and apply $\varphi^{\tau}$ to $\gamma_v(s)$ we will obtain some curve $\tilde{\gamma}_v(s)$ that still lies on $\mathcal{M}$ and $\tilde{\gamma}_v(0) = x_0$. Thus tangent vector to this curve has to lie in $T_{x_0}\mathcal{M}$. But this tangent vector is nothing but $DF(x_0)(v)$ and this implies that $\forall v \in T_{x_0}\mathcal{M}$ follows $DF(x_0)(v) \in T_{x_0}\mathcal{M}$.","Suppose that you have a system of ODEs $$\dot{x} = F(x), \, x \in \mathbb{R}^n,$$ and $x_0$ is a an equilibrium point of this system, i.e. $F(x_0) = 0$. Suppose you have a locally invariant smooth submanifold $\mathcal{M}$ that passes through $x_0$. By locally invariant I mean that for any point $p \in \mathcal{M}$ there exists an $\varepsilon > 0$ such that $\varphi^{t}(p) \in \mathcal{M}$ for $\lvert t \rvert < \varepsilon$, where $\varphi^t$ is the flow defined by a system of ODEs. I believe that if these conditions are met, then $DF(x_0) (T_{x_0}\mathcal{M}) \subset T_{x_0}\mathcal{M}$; $DF(x_0)$ is a Jacobi matrix for $F(x)$ at point $x_0$. It feels like I had encountered similar statement somewhere before, but I can't remember the exact reference. I can't find a counter-example or a proof for this statement from the get-go, though I definitely want to crack that puzzle if there is no reference to it.  If this statement was true, it would much simplify one of my proofs, so that's the reason why I'm so interested in it. So, mostly I'm interested in the reference where this (or very similar) statement had been proved. If the statement is false and you know a counter-example, that would be very useful (although a bit heartbreaking). ADDED LATER I have a sketch of the proof for this statement (kind of). If we pick any vector $v \in T_{x_0}\mathcal{M}$ there exists a curve $\gamma_v(s)$ such that $\gamma_v'(0) = v, \gamma_v(0) = x_0,$ and which lies in $\mathcal{M}$. If we choose some $\tau$ and apply $\varphi^{\tau}$ to $\gamma_v(s)$ we will obtain some curve $\tilde{\gamma}_v(s)$ that still lies on $\mathcal{M}$ and $\tilde{\gamma}_v(0) = x_0$. Thus tangent vector to this curve has to lie in $T_{x_0}\mathcal{M}$. But this tangent vector is nothing but $DF(x_0)(v)$ and this implies that $\forall v \in T_{x_0}\mathcal{M}$ follows $DF(x_0)(v) \in T_{x_0}\mathcal{M}$.",,"['differential-geometry', 'reference-request', 'dynamical-systems']"
21,"""Shrinking"" open sets technique.","""Shrinking"" open sets technique.",,"So I was reading a lot of proofs in geometry and analysis and sometimes the follow phrase gets used ""if necessary, shrink open sets $U$ and $V$ so that property $X$ is satisfied"" or something along the lines of that. What exactly does this mean? Here is an example. I was reading something in differential geometry and this is one of those ""is this chart dependant"" questions. I think this is differential geometry's way of asking ""is this thing well-defined"". Anyways, when defining the Tangent Space, one will be asked ""what if we use another chart?"". So let $X$ be a manifold in $\mathbb{R}^n$ with chart $\phi: U \subset \mathbb{R}^k \to X$ and $\phi(0) = x \in X$.  Now suppose we have another chart $\psi: V \to  X$ with $\psi(0) = x$, then by shrinking $U$ and $V$, we may assume $\phi(U) = \psi(V)$ . I believe this is so that we can define the map $h = \psi^{-1}\circ \phi$, because if the image sets are not equal, then $\psi^{-1}$ may not be defined on $\phi(U)$. Or is ""shrink"" here imply that the image sets are ""equal up to diffeomorphism""?","So I was reading a lot of proofs in geometry and analysis and sometimes the follow phrase gets used ""if necessary, shrink open sets $U$ and $V$ so that property $X$ is satisfied"" or something along the lines of that. What exactly does this mean? Here is an example. I was reading something in differential geometry and this is one of those ""is this chart dependant"" questions. I think this is differential geometry's way of asking ""is this thing well-defined"". Anyways, when defining the Tangent Space, one will be asked ""what if we use another chart?"". So let $X$ be a manifold in $\mathbb{R}^n$ with chart $\phi: U \subset \mathbb{R}^k \to X$ and $\phi(0) = x \in X$.  Now suppose we have another chart $\psi: V \to  X$ with $\psi(0) = x$, then by shrinking $U$ and $V$, we may assume $\phi(U) = \psi(V)$ . I believe this is so that we can define the map $h = \psi^{-1}\circ \phi$, because if the image sets are not equal, then $\psi^{-1}$ may not be defined on $\phi(U)$. Or is ""shrink"" here imply that the image sets are ""equal up to diffeomorphism""?",,"['real-analysis', 'differential-geometry', 'proof-writing', 'proof-explanation']"
22,Is $x^2 = y ^2$ an immersed submanifold of $\mathbb{R}^2$?,Is  an immersed submanifold of ?,x^2 = y ^2 \mathbb{R}^2,"So, I know that this isn't an embedded submanifold, since with the subspace topology inherited from $\mathbb{R}^2$, it is not locally Euclidean at $0$. Further, I also know that if I can parametrize it nicely, I will be able to say that it is the image of an injective smooth immersion and thus an immersed submanifold, but I can't seem to do that and don't know how to prove that it is not one.","So, I know that this isn't an embedded submanifold, since with the subspace topology inherited from $\mathbb{R}^2$, it is not locally Euclidean at $0$. Further, I also know that if I can parametrize it nicely, I will be able to say that it is the image of an injective smooth immersion and thus an immersed submanifold, but I can't seem to do that and don't know how to prove that it is not one.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
23,Is $\frac{\partial}{\partial x_1}=\frac{\partial}{\partial y_1}$ if $x_1=y_1$?,Is  if ?,\frac{\partial}{\partial x_1}=\frac{\partial}{\partial y_1} x_1=y_1,"Let $M$ be a manifold, $p\in M$ and $(U,\varphi=(x_1,\dots,x_n))$, $(V,\psi=(y_1,\dots,y_n))$ two local charts such that $p\in U\cap V$ and $x_1=y_1$. Is it true that $(\frac{\partial}{\partial x_1})_p=(\frac{\partial}{\partial y_1})_p$? My professor says that the answer is yes, and so I build a proof. But then I found the following counterexample: Let $M=\mathbb{R}^2$, $p=(0,0)$, $U=V=\mathbb{R}^2$, $\varphi(u,v)=(u,v)$ and $\psi(u,v)=(u,u+v)$. Then $x_1(y_1,y_2)=y_1$ and $x_2(y_1,y_2)=y_2-y_1$. Using the formula for the change of basis I've got $$(\frac{\partial}{\partial y_1})_p=\sum_{i=1}^2(\frac{\partial x_i}{\partial y_1})_p(\frac{\partial}{\partial x_i})_p=(\frac{\partial}{\partial x_2})_p-(\frac{\partial}{\partial x_1})_p\neq (\frac{\partial}{\partial x_1})_p$$ What's wrong with this counterexample?","Let $M$ be a manifold, $p\in M$ and $(U,\varphi=(x_1,\dots,x_n))$, $(V,\psi=(y_1,\dots,y_n))$ two local charts such that $p\in U\cap V$ and $x_1=y_1$. Is it true that $(\frac{\partial}{\partial x_1})_p=(\frac{\partial}{\partial y_1})_p$? My professor says that the answer is yes, and so I build a proof. But then I found the following counterexample: Let $M=\mathbb{R}^2$, $p=(0,0)$, $U=V=\mathbb{R}^2$, $\varphi(u,v)=(u,v)$ and $\psi(u,v)=(u,u+v)$. Then $x_1(y_1,y_2)=y_1$ and $x_2(y_1,y_2)=y_2-y_1$. Using the formula for the change of basis I've got $$(\frac{\partial}{\partial y_1})_p=\sum_{i=1}^2(\frac{\partial x_i}{\partial y_1})_p(\frac{\partial}{\partial x_i})_p=(\frac{\partial}{\partial x_2})_p-(\frac{\partial}{\partial x_1})_p\neq (\frac{\partial}{\partial x_1})_p$$ What's wrong with this counterexample?",,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-fields']"
24,What is the relation between universal covering space and curvature of base manifolds?,What is the relation between universal covering space and curvature of base manifolds?,,"Does anyone know what is the relation between universal covering space and curvature of base manifolds? Edit: For example   If universal covering of a complete $3$-manifold $(M,g)$   isometric to a Riemann product $N^2\times \Bbb R$ where $N^2$ is a complete $2$-manifold with non-negative sectional curvature then what we can say about $(M,g)$? Thanks","Does anyone know what is the relation between universal covering space and curvature of base manifolds? Edit: For example   If universal covering of a complete $3$-manifold $(M,g)$   isometric to a Riemann product $N^2\times \Bbb R$ where $N^2$ is a complete $2$-manifold with non-negative sectional curvature then what we can say about $(M,g)$? Thanks",,"['differential-geometry', 'riemannian-geometry']"
25,Hessian Matrix And Gauss Curvature Example,Hessian Matrix And Gauss Curvature Example,,"The connection between is written in wikipedia : ""We represent the surface by the implicit function theorem as the graph of a function, $f$, of two variables, in such a way that the point $p$ is a critical point, i.e. , the gradient of $f$ vanishes (this can always be attained by a suitable rigid motion). Then the Gaussian curvature of the surface at $p$ is the determinant of the Hessian matrix of $f$ (being the product of the eigenvalues of the Hessian)."" I am searching for an example to better understand it.","The connection between is written in wikipedia : ""We represent the surface by the implicit function theorem as the graph of a function, $f$, of two variables, in such a way that the point $p$ is a critical point, i.e. , the gradient of $f$ vanishes (this can always be attained by a suitable rigid motion). Then the Gaussian curvature of the surface at $p$ is the determinant of the Hessian matrix of $f$ (being the product of the eigenvalues of the Hessian)."" I am searching for an example to better understand it.",,['differential-geometry']
26,Relation between left and right invariant vector fields.,Relation between left and right invariant vector fields.,,"What I'm trying to show: Let $Y$ be a vector field on a Lie group $G$. If $G$ is connected and $[X,Y]=0$ for all left invariant vector field $X$, then $Y$ is right invariant. I thought I could prove it using only the relations between left and right invariant vector fields, but I failed. I realized I wasn't using the connectedness of $G$. I'm having difficulty in understanding what role plays the connectedness of $G$.","What I'm trying to show: Let $Y$ be a vector field on a Lie group $G$. If $G$ is connected and $[X,Y]=0$ for all left invariant vector field $X$, then $Y$ is right invariant. I thought I could prove it using only the relations between left and right invariant vector fields, but I failed. I realized I wasn't using the connectedness of $G$. I'm having difficulty in understanding what role plays the connectedness of $G$.",,"['differential-geometry', 'lie-groups']"
27,Problem underestanding holomorphic quadratic diferentials,Problem underestanding holomorphic quadratic diferentials,,"I am trying to understand what a holomorphic quadratic differential is, i have read a local definition on two books: Jürgen-Jost-""Compact Riemman Surfaces"" and Kurt Strebel-""Quadratic-Differentials"". The definition that they use is  local: Definition: Let ( M , g) be a Riemann surface with a conformal metric and $z$ a local conformal coordinate, we say that $\varphi dz^2$ is a holomorphic quadratic differential if $\varphi$ is holomorphic. That is the definition in Jürgen-Jost book, in Kurt Strebel ""Quadratic-Differentials"" They only add that a transformation rule for other coordinates is needed. I would like to understand a global definition in terms of sections, in wikipedia i found this: ""a quadratic differential on a Riemann surface is a section of the symmetric square of the holomorphic cotangent bundle"" I guess holomorphic cotangent bundle means the bundle of holomorphic 1-forms. I don't understand the ""symmetric square part"". I would like to have a global definition and a local coordinate representation. Of course I don't trust at all about a wikipedia link. So I would like to ask, is this definition  right? Is there a good reference  i should  read ?","I am trying to understand what a holomorphic quadratic differential is, i have read a local definition on two books: Jürgen-Jost-""Compact Riemman Surfaces"" and Kurt Strebel-""Quadratic-Differentials"". The definition that they use is  local: Definition: Let ( M , g) be a Riemann surface with a conformal metric and $z$ a local conformal coordinate, we say that $\varphi dz^2$ is a holomorphic quadratic differential if $\varphi$ is holomorphic. That is the definition in Jürgen-Jost book, in Kurt Strebel ""Quadratic-Differentials"" They only add that a transformation rule for other coordinates is needed. I would like to understand a global definition in terms of sections, in wikipedia i found this: ""a quadratic differential on a Riemann surface is a section of the symmetric square of the holomorphic cotangent bundle"" I guess holomorphic cotangent bundle means the bundle of holomorphic 1-forms. I don't understand the ""symmetric square part"". I would like to have a global definition and a local coordinate representation. Of course I don't trust at all about a wikipedia link. So I would like to ask, is this definition  right? Is there a good reference  i should  read ?",,"['differential-geometry', 'riemann-surfaces']"
28,Is it ever possible to fully avoid Cartesian coordinates?,Is it ever possible to fully avoid Cartesian coordinates?,,"I think this question is more philosophical than mathematical, though I may be wrong, probably it is just a stupid lack of understanding. Anyway, if you don't mind, please read the question carefully to get the sense of what I am asking. It is a bit difficult to express. Tensors and differential geometry consider oblique (non-orthogonal) and even curvilinear ""axes"" or basis vectors.  But, the basis vectors themselves must be expressed somehow.  Does this require going back to some underlying ""master"" orthogonal (Cartesian) coordinate system? Here are two examples of my puzzle. Example 1. A vector $\mathbf{v}$ can be written in terms of Cartesian coordinates as $$    \mathbf{v} = v^k \mathbf{e}_k $$ where $e_k$ are the regular basis vectors (in the 3D case, (1,0,0), (0,1,0), (0,0,1)). A vector can also be written in terms of an arbitrary non-orthogonal system as for example $$    \mathbf{v} = w^k \mathbf{u}_k $$ Suppose that $w^k$ are given. To know the vector, we have to know what the vectors $\mathbf{u}_k$ are, and these would either have to be specified in terms of an underlying Cartesian coordinate system, for example $$    \mathbf{u}_2 = (0.3, 0.799, -0.1) $$ or in terms of some other coordinate system, which in turn(!) (possibility of infinite regress here) would need to be specified eventually in terms of the Cartesian coordinate system ? I suppose if the other coordinate system is a physical given thing (lines drawn by aliens in the desert) then one can avoid the issue. Example 2. In Susskind's Einstein's General Theory of Relativity | Lecture 5 https://www.youtube.com/watch?v=WtPtxz3ef8U at around 18:30 he describes why the derivative of the components of a tensor are not themselves a tensor, giving the example of a field of constant-direction-and-constant-magnitude vectors. The derivatives of components of these vectors w.r.t. cartesian axes are zero, but the derivatives w.r.t spatially varying axes are non-zero. Here we have some vectors, which appear to be pointing in the same direction, and measure them using some underlying axes, which certainly appear to be curving.  But how do we know that the vectors are pointing in the same direction and the axes are curving and not the other way?  In everyday live, of course I can see that what was drawn on the white board was straight/curving, but that is not a scientific answer. Don't we need to measure with respect to some other coordinate system,  and wouldn't that one be...(eventually)...Cartesian? Note, it sounds that someone in the class was possibly asking this question around 18:30, but the professor closed the question. EDIT: Seeing the first 3 answers, it is clear that I failed to explain the question... or else the question is just nonsense. I fear that I am missing something very fundamental! Surprising however. The idea of a basis is something I have successfully used in various exercises and is second nature at this point.","I think this question is more philosophical than mathematical, though I may be wrong, probably it is just a stupid lack of understanding. Anyway, if you don't mind, please read the question carefully to get the sense of what I am asking. It is a bit difficult to express. Tensors and differential geometry consider oblique (non-orthogonal) and even curvilinear ""axes"" or basis vectors.  But, the basis vectors themselves must be expressed somehow.  Does this require going back to some underlying ""master"" orthogonal (Cartesian) coordinate system? Here are two examples of my puzzle. Example 1. A vector $\mathbf{v}$ can be written in terms of Cartesian coordinates as $$    \mathbf{v} = v^k \mathbf{e}_k $$ where $e_k$ are the regular basis vectors (in the 3D case, (1,0,0), (0,1,0), (0,0,1)). A vector can also be written in terms of an arbitrary non-orthogonal system as for example $$    \mathbf{v} = w^k \mathbf{u}_k $$ Suppose that $w^k$ are given. To know the vector, we have to know what the vectors $\mathbf{u}_k$ are, and these would either have to be specified in terms of an underlying Cartesian coordinate system, for example $$    \mathbf{u}_2 = (0.3, 0.799, -0.1) $$ or in terms of some other coordinate system, which in turn(!) (possibility of infinite regress here) would need to be specified eventually in terms of the Cartesian coordinate system ? I suppose if the other coordinate system is a physical given thing (lines drawn by aliens in the desert) then one can avoid the issue. Example 2. In Susskind's Einstein's General Theory of Relativity | Lecture 5 https://www.youtube.com/watch?v=WtPtxz3ef8U at around 18:30 he describes why the derivative of the components of a tensor are not themselves a tensor, giving the example of a field of constant-direction-and-constant-magnitude vectors. The derivatives of components of these vectors w.r.t. cartesian axes are zero, but the derivatives w.r.t spatially varying axes are non-zero. Here we have some vectors, which appear to be pointing in the same direction, and measure them using some underlying axes, which certainly appear to be curving.  But how do we know that the vectors are pointing in the same direction and the axes are curving and not the other way?  In everyday live, of course I can see that what was drawn on the white board was straight/curving, but that is not a scientific answer. Don't we need to measure with respect to some other coordinate system,  and wouldn't that one be...(eventually)...Cartesian? Note, it sounds that someone in the class was possibly asking this question around 18:30, but the professor closed the question. EDIT: Seeing the first 3 answers, it is clear that I failed to explain the question... or else the question is just nonsense. I fear that I am missing something very fundamental! Surprising however. The idea of a basis is something I have successfully used in various exercises and is second nature at this point.",,"['differential-geometry', 'tensors']"
29,Local trivialization and local frame,Local trivialization and local frame,,"The textbook told me if $(\pi,E,M)$ is a vector bundle, if we have a local frame $s_i$ of $E$ over $U$ then forall vector $v_p$ at $p$ we have $$v_p=c_1s_1+\cdots+c_ks_k$$ Then we define k maps $c_i$ from $\pi^{-1}(U)$ to $\mathrm{R}$ , so we can define a local trivialization of $E$ over $U$ by setting： $$\Omega_U(p,v_p)=(p,c_1,…c_k)$$ But how can I prove that each $c_i$ is smooth?","The textbook told me if $(\pi,E,M)$ is a vector bundle, if we have a local frame $s_i$ of $E$ over $U$ then forall vector $v_p$ at $p$ we have $$v_p=c_1s_1+\cdots+c_ks_k$$ Then we define k maps $c_i$ from $\pi^{-1}(U)$ to $\mathrm{R}$ , so we can define a local trivialization of $E$ over $U$ by setting： $$\Omega_U(p,v_p)=(p,c_1,…c_k)$$ But how can I prove that each $c_i$ is smooth?",,"['differential-geometry', 'differential-topology', 'vector-bundles']"
30,Curvature tensor for a manifold with torsion,Curvature tensor for a manifold with torsion,,"Wikipedia defines the Riemann curvature tensor as a (1,3) tensor, meaning it takes 3 vectors and maps it into one other vector, with the rule: $$ R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z$$ If I use the Levi-Civita connection, this seems to agree with the definition by coordinates: $$ [\nabla_\mu,\nabla_\nu]V^\rho= R^\rho_{\ \ \sigma\mu\nu} V^\sigma$$ If by the $(,)$ in the first formula we mean contraction by the last two indices. I was wondering what happens if we have a generic connection, instead of the Levi-Civita connection. The last equation then becomes: $$ [\nabla_\mu,\nabla_\nu]V^\rho= R^\rho_{\ \ \sigma\mu\nu} V^\sigma - T_{\mu\nu}^{\ \ \ \lambda}\nabla_\lambda V^\rho$$ And I get: $$ R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z -\nabla_{T(X,Y)}Z$$ This seems to be in contradiction with formula (3.71) in Sean Caroll's lecture notes on General Relativity https://arxiv.org/abs/gr-qc/9712019 where the last term given by the torsion is missing. So my question is, is that formula in the notes wrong, or am I making a mistake?","Wikipedia defines the Riemann curvature tensor as a (1,3) tensor, meaning it takes 3 vectors and maps it into one other vector, with the rule: $$ R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z$$ If I use the Levi-Civita connection, this seems to agree with the definition by coordinates: $$ [\nabla_\mu,\nabla_\nu]V^\rho= R^\rho_{\ \ \sigma\mu\nu} V^\sigma$$ If by the $(,)$ in the first formula we mean contraction by the last two indices. I was wondering what happens if we have a generic connection, instead of the Levi-Civita connection. The last equation then becomes: $$ [\nabla_\mu,\nabla_\nu]V^\rho= R^\rho_{\ \ \sigma\mu\nu} V^\sigma - T_{\mu\nu}^{\ \ \ \lambda}\nabla_\lambda V^\rho$$ And I get: $$ R(X,Y)Z = \nabla_X \nabla_Y Z - \nabla_Y \nabla_X Z - \nabla_{[X,Y]}Z -\nabla_{T(X,Y)}Z$$ This seems to be in contradiction with formula (3.71) in Sean Caroll's lecture notes on General Relativity https://arxiv.org/abs/gr-qc/9712019 where the last term given by the torsion is missing. So my question is, is that formula in the notes wrong, or am I making a mistake?",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
31,Geodesic curvature with arbitrary parametrization,Geodesic curvature with arbitrary parametrization,,"If a curve $\alpha(s)$ on a surface $S$ is parametrized by arc length the geodesic curvature can easily be found $$k_g(s)=\alpha''(s)\cdot (N(\alpha(s))\times \alpha'(s))$$ where $N$ is the unit normal. The problem is that there are sometimes when it is extremely hard to reparametrize a curve by arclenght. Sometimes it involves eliptic integrals and so on. In that case, how could one find the geodesic curvature? How can I find one expression for the geodesic curvature without needing to reparametrize by arc length?","If a curve $\alpha(s)$ on a surface $S$ is parametrized by arc length the geodesic curvature can easily be found $$k_g(s)=\alpha''(s)\cdot (N(\alpha(s))\times \alpha'(s))$$ where $N$ is the unit normal. The problem is that there are sometimes when it is extremely hard to reparametrize a curve by arclenght. Sometimes it involves eliptic integrals and so on. In that case, how could one find the geodesic curvature? How can I find one expression for the geodesic curvature without needing to reparametrize by arc length?",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'geodesic']"
32,computing Laplacian of hyperbolic spaces,computing Laplacian of hyperbolic spaces,,"Ok, as a beginner to Riemannian manifolds, let me ask the following embarrassing question. Consider the hyperbolic  manifold $(\mathbb H^n,g)$ with hyperbolic metric $g_{ij}=\delta_{ij}\frac{1}{x^2_n}$. Why is that the Laplace-Beltrami operator equal to $$\Delta_g=-x_n^2\sum_{i=1}^n\frac{\partial^2}{\partial x_i^2}?$$ Even for  $\mathbb H^2$ my computations does not confirm the above expression (which should be $\Delta_g=-y^2(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})$ ). Or am I missing something in here?","Ok, as a beginner to Riemannian manifolds, let me ask the following embarrassing question. Consider the hyperbolic  manifold $(\mathbb H^n,g)$ with hyperbolic metric $g_{ij}=\delta_{ij}\frac{1}{x^2_n}$. Why is that the Laplace-Beltrami operator equal to $$\Delta_g=-x_n^2\sum_{i=1}^n\frac{\partial^2}{\partial x_i^2}?$$ Even for  $\mathbb H^2$ my computations does not confirm the above expression (which should be $\Delta_g=-y^2(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})$ ). Or am I missing something in here?",,"['differential-geometry', 'riemannian-geometry']"
33,Differential of a function between manifolds,Differential of a function between manifolds,,"The book we are using in class is Frank Warner Foundation of Differential Manifold and Lie Group. Let $M,N$ be two smooth $d$-dim manifold, the differential of a $C^\infty$ function $\phi:M\rightarrow N$ is defined by  $$d\phi: M_m \rightarrow N_{\phi(m)}$$ For $v\in M_n$, and $g:N \rightarrow \mathbb{R}$ a smooth function, we define $$d\phi(v)(g) = v(g\circ \phi).$$ Now for a smooth function $f:M \rightarrow \mathbb{R}$, I don't quite see why the book states $$df(v)(g) = v(f) \frac{\partial}{\partial r}\bigg|_{r_0} g$$ from the definition above. Edit: Reading the answer here seems that if we plug $g(r) = r$, we will get the identity $df(v) =  v(f)$, but how do we know it will hold for all $g$?","The book we are using in class is Frank Warner Foundation of Differential Manifold and Lie Group. Let $M,N$ be two smooth $d$-dim manifold, the differential of a $C^\infty$ function $\phi:M\rightarrow N$ is defined by  $$d\phi: M_m \rightarrow N_{\phi(m)}$$ For $v\in M_n$, and $g:N \rightarrow \mathbb{R}$ a smooth function, we define $$d\phi(v)(g) = v(g\circ \phi).$$ Now for a smooth function $f:M \rightarrow \mathbb{R}$, I don't quite see why the book states $$df(v)(g) = v(f) \frac{\partial}{\partial r}\bigg|_{r_0} g$$ from the definition above. Edit: Reading the answer here seems that if we plug $g(r) = r$, we will get the identity $df(v) =  v(f)$, but how do we know it will hold for all $g$?",,"['real-analysis', 'differential-geometry', 'differential-topology', 'differential-forms']"
34,Need more help with differential forms,Need more help with differential forms,,"The standard contact form on the sphere $S^{2n +1}$ in $\mathbb R^{2n + 2}$ is given by $$ \omega = \sum_{k=1}^{n+1} x_k dy_k - y_k dx_k$$ (see e.g. here ) Now what I'm confused about is that this form uses all $2n + 2$ coordinates of $\mathbb R^{2n + 2}$ but the sphere is only $2n + 1$-dimensional. Question 1 : Doesn't one have to restrict this to the sphere? By that I mean compose with the differential of the inclusion map $i:S^{2n +1}\hookrightarrow \mathbb R^{2n +2}$. It's not clear to me though what $i$ should be: a point $x$ in $S^{2n +1}$ only has $2n+1$ coordinates. Question 2: So do we map an arbitrary coordinte to $0$? But if so, wouldn't then   $i$ be not defined on all of the sphere (but only chartwise)? When restricted I expect $\omega$ to become an expression of only $2n+1$ coordinates. Am I on the right track of understanding or is my current understanding all complete nonsense? I also believe that $\omega$ is globally defined on $S^{2n+1}$. But I don't understand how it's possible since the sphere does not admit a global coordinate system. Question 3: How is it possible that $\omega$ is nonetheless a globally defined   differential form?","The standard contact form on the sphere $S^{2n +1}$ in $\mathbb R^{2n + 2}$ is given by $$ \omega = \sum_{k=1}^{n+1} x_k dy_k - y_k dx_k$$ (see e.g. here ) Now what I'm confused about is that this form uses all $2n + 2$ coordinates of $\mathbb R^{2n + 2}$ but the sphere is only $2n + 1$-dimensional. Question 1 : Doesn't one have to restrict this to the sphere? By that I mean compose with the differential of the inclusion map $i:S^{2n +1}\hookrightarrow \mathbb R^{2n +2}$. It's not clear to me though what $i$ should be: a point $x$ in $S^{2n +1}$ only has $2n+1$ coordinates. Question 2: So do we map an arbitrary coordinte to $0$? But if so, wouldn't then   $i$ be not defined on all of the sphere (but only chartwise)? When restricted I expect $\omega$ to become an expression of only $2n+1$ coordinates. Am I on the right track of understanding or is my current understanding all complete nonsense? I also believe that $\omega$ is globally defined on $S^{2n+1}$. But I don't understand how it's possible since the sphere does not admit a global coordinate system. Question 3: How is it possible that $\omega$ is nonetheless a globally defined   differential form?",,['differential-geometry']
35,existence of closed surface having only negative Gaussian curvature.,existence of closed surface having only negative Gaussian curvature.,,"I heard a theorem in differential geometry course. State of the theorem is ""There is no closed (regular) surface having only negative Gaussian curvature."" I tried to prove the theorem using Gauss-Bonnet theorem, but coudn't have any progress. How can I get proof? +) I guess that above theorem is also true when the word 'negative Gaussian curvature' is replaced with 'nonpositive Gaussian curvature'. Is this right?","I heard a theorem in differential geometry course. State of the theorem is ""There is no closed (regular) surface having only negative Gaussian curvature."" I tried to prove the theorem using Gauss-Bonnet theorem, but coudn't have any progress. How can I get proof? +) I guess that above theorem is also true when the word 'negative Gaussian curvature' is replaced with 'nonpositive Gaussian curvature'. Is this right?",,['differential-geometry']
36,Can every Riemmanian Manifold be completed?,Can every Riemmanian Manifold be completed?,,"I had two trails of though.. is either of them fruitful? I know every metric space can be completed, my question is: can a Riemmanian manifold $M$ be embedded smoothly and isometrically into it's metric completion $\hat{M}$? If so I could conclude using the Hopf–Rinow theorem that $M$ can be embedded into a geodesically complete manifold $\hat{M}$... Can we adjoin the boundary to M and then it becomes compact since Riemmanian manifolds satisfy the HB property?","I had two trails of though.. is either of them fruitful? I know every metric space can be completed, my question is: can a Riemmanian manifold $M$ be embedded smoothly and isometrically into it's metric completion $\hat{M}$? If so I could conclude using the Hopf–Rinow theorem that $M$ can be embedded into a geodesically complete manifold $\hat{M}$... Can we adjoin the boundary to M and then it becomes compact since Riemmanian manifolds satisfy the HB property?",,"['differential-geometry', 'manifolds', 'differential-topology', 'riemannian-geometry', 'manifolds-with-boundary']"
37,"""Flow lines"" of ""dust"" are geodesics?","""Flow lines"" of ""dust"" are geodesics?",,"The stress-energy tensor representing ""dust"" takes the form$$T_{ab} = \rho u_au_b$$where $u^a$ is a unit timelike vector field, i.e., $u^au_a = -1$. Does it necessarily follow that in any solution to Einstein's equation with dust matter (with $\rho > 0$ everywhere), that the ""flow lines"" of the dust, i.e., the integral curves of $u^a$, are geodesics?","The stress-energy tensor representing ""dust"" takes the form$$T_{ab} = \rho u_au_b$$where $u^a$ is a unit timelike vector field, i.e., $u^au_a = -1$. Does it necessarily follow that in any solution to Einstein's equation with dust matter (with $\rho > 0$ everywhere), that the ""flow lines"" of the dust, i.e., the integral curves of $u^a$, are geodesics?",,"['differential-geometry', 'riemannian-geometry', 'physics', 'mathematical-physics', 'general-relativity']"
38,Confused by two different perspectives on $G$-vector bundles,Confused by two different perspectives on -vector bundles,G,"I'm trying to understand how these two perspectives on vector bundle with a $G$-action come together. Perspective 1: Let $P \to X$ be a principal $G$-bundle. The associated bundle construction gives an exact tensor functor from finite linear representation of $G$ to vector bundle with $G$-action: $P \times_G(-): Rep(G) \to Vect^G(X)$. How does the essential image of this functor looks like? Is it faithful? full? Perspective 2: Let $V \to X$ be a vector bundle with $G$-action. Under some suitable conditions on $G$ (finite will obviously do but I'm pretty sure weaker assumptions will do - perhaps semisimple is enough) we have the following characterization of $E$. Let $\{V_j\}$ be the trivial vector bundles with $G$ action over $X$ corresponding to the irreducible reprepsentations of $G$. $$V \cong \bigoplus_j V_j \otimes Hom_{G}(V_j,V)$$ Where $G$ acts on $Hom_G(V_j,V)$ trivially. The fact that $Hom_G(V_j,V)$ is a vector bundle follows from the averaging projection operator on sections of any vector bundle with $G$-action. This is a fulll description of the objects in $Vect^G(X)$ (for when $G$ is nice enough so that it holds). One way to spell out my confusion is this: Is a vector bundle with $G$-action the same as a reduction of structure group from $GL(V)$ to $G$? I'm pretty convinced that being a $G$-vector bundle is weaker than having structure group $G$. For example if $G$ is finite then a principal $G$ bundle will always be flat and so will any associated bundle while it looks like $G$-vector bundles mat be non-flat. I don't understand really how these POV's come together. In particular: When is a $G$-vector bundle an associated bundle of some principal bundle? Let $\rho : G \to GL(V)$ be a representation. How does the associated bundle $P\times_{\rho}V$ decompose via perspective 2? For $G$ finite: Is every $G$-vector bundle flat (locally constant)?","I'm trying to understand how these two perspectives on vector bundle with a $G$-action come together. Perspective 1: Let $P \to X$ be a principal $G$-bundle. The associated bundle construction gives an exact tensor functor from finite linear representation of $G$ to vector bundle with $G$-action: $P \times_G(-): Rep(G) \to Vect^G(X)$. How does the essential image of this functor looks like? Is it faithful? full? Perspective 2: Let $V \to X$ be a vector bundle with $G$-action. Under some suitable conditions on $G$ (finite will obviously do but I'm pretty sure weaker assumptions will do - perhaps semisimple is enough) we have the following characterization of $E$. Let $\{V_j\}$ be the trivial vector bundles with $G$ action over $X$ corresponding to the irreducible reprepsentations of $G$. $$V \cong \bigoplus_j V_j \otimes Hom_{G}(V_j,V)$$ Where $G$ acts on $Hom_G(V_j,V)$ trivially. The fact that $Hom_G(V_j,V)$ is a vector bundle follows from the averaging projection operator on sections of any vector bundle with $G$-action. This is a fulll description of the objects in $Vect^G(X)$ (for when $G$ is nice enough so that it holds). One way to spell out my confusion is this: Is a vector bundle with $G$-action the same as a reduction of structure group from $GL(V)$ to $G$? I'm pretty convinced that being a $G$-vector bundle is weaker than having structure group $G$. For example if $G$ is finite then a principal $G$ bundle will always be flat and so will any associated bundle while it looks like $G$-vector bundles mat be non-flat. I don't understand really how these POV's come together. In particular: When is a $G$-vector bundle an associated bundle of some principal bundle? Let $\rho : G \to GL(V)$ be a representation. How does the associated bundle $P\times_{\rho}V$ decompose via perspective 2? For $G$ finite: Is every $G$-vector bundle flat (locally constant)?",,"['algebraic-geometry', 'differential-geometry', 'representation-theory', 'vector-bundles', 'principal-bundles']"
39,Frenet-Serret formulas in arbitrary dimensions,Frenet-Serret formulas in arbitrary dimensions,,Can anyone point me to a proof of the Frenet-Serret formulas for arbitrary (i.e. $N>3$) dimensions?,Can anyone point me to a proof of the Frenet-Serret formulas for arbitrary (i.e. $N>3$) dimensions?,,"['differential-geometry', 'reference-request', 'frenet-frame']"
40,Implicit formula for the Levi-Civita connection,Implicit formula for the Levi-Civita connection,,"Let  $(M, g)$ be a Riemannian manifold and $X, Y, Z$ smooth vector fields on $M$. Let $\theta_X$ be the $1$-form defined as $\theta_X(Y) = g(X,Y)$ and let $d\theta_X$ be its exterior derivative. Let $L_X$ denote the Lie derivative. Let $\nabla$ be the Levi-Civita connection, i.e. the unique torsion free connection on $(M,g)$ which is also compatible with the metric. I want to prove that:  $$ 2 g(\nabla_Y X, Z) = (L_Xg)(Y,Z) + (d \theta_X)(Y,Z). $$ Is there a quick way to see that? EDIT: I'm stuck with the $2$-form $d\theta_X$. I don't know how to deal with it. Can I express it just using the metric and the Lie derivative (without working in local coordinates)?","Let  $(M, g)$ be a Riemannian manifold and $X, Y, Z$ smooth vector fields on $M$. Let $\theta_X$ be the $1$-form defined as $\theta_X(Y) = g(X,Y)$ and let $d\theta_X$ be its exterior derivative. Let $L_X$ denote the Lie derivative. Let $\nabla$ be the Levi-Civita connection, i.e. the unique torsion free connection on $(M,g)$ which is also compatible with the metric. I want to prove that:  $$ 2 g(\nabla_Y X, Z) = (L_Xg)(Y,Z) + (d \theta_X)(Y,Z). $$ Is there a quick way to see that? EDIT: I'm stuck with the $2$-form $d\theta_X$. I don't know how to deal with it. Can I express it just using the metric and the Lie derivative (without working in local coordinates)?",,"['differential-geometry', 'riemannian-geometry', 'differential-forms', 'connections', 'lie-derivative']"
41,"If $d(f\omega)=0$, then $\omega \wedge d(\omega)=0$","If , then",d(f\omega)=0 \omega \wedge d(\omega)=0,"Here's the question: Suppose that $\omega$ is a $k$-form on an open set $U$ of $\mathbb{R}^n$ and $f:U \to \mathbb{R}$ is a $C^\infty$ function such that $f(x) \neq 0$, for all $x \in U$, and $d(f\omega)=0$. Prove that $\omega \wedge d(\omega)=0$ My attempts so far: Differentiate the product $f\omega$, and take the wedge product with $\omega$: $$d(f\omega)=df\wedge\omega + f d\omega=0$$ $$\Rightarrow \omega \wedge df\wedge\omega + f \omega \wedge d\omega=0$$ I see 2 cases: If $k$ is odd: then the product $\omega \wedge \omega$ must be zero, since if the commutation formula is used: $$\omega \wedge \omega = (-1)^{k^2} \omega \wedge \omega = - \omega \wedge \omega$$ Then, commutating $df$ above with $\omega$ (with a sign that comes out, no problem) and dividing by $f$, which is valid since $f$ is never zero, yields the result. If $k$ is even: I don't really see how to extend the above argument. I'm worried I might have to toss it away and try with another tool. Or maybe I'm missing something very fundamental in here. Any suggestion or solution is welcome. Thanks!","Here's the question: Suppose that $\omega$ is a $k$-form on an open set $U$ of $\mathbb{R}^n$ and $f:U \to \mathbb{R}$ is a $C^\infty$ function such that $f(x) \neq 0$, for all $x \in U$, and $d(f\omega)=0$. Prove that $\omega \wedge d(\omega)=0$ My attempts so far: Differentiate the product $f\omega$, and take the wedge product with $\omega$: $$d(f\omega)=df\wedge\omega + f d\omega=0$$ $$\Rightarrow \omega \wedge df\wedge\omega + f \omega \wedge d\omega=0$$ I see 2 cases: If $k$ is odd: then the product $\omega \wedge \omega$ must be zero, since if the commutation formula is used: $$\omega \wedge \omega = (-1)^{k^2} \omega \wedge \omega = - \omega \wedge \omega$$ Then, commutating $df$ above with $\omega$ (with a sign that comes out, no problem) and dividing by $f$, which is valid since $f$ is never zero, yields the result. If $k$ is even: I don't really see how to extend the above argument. I'm worried I might have to toss it away and try with another tool. Or maybe I'm missing something very fundamental in here. Any suggestion or solution is welcome. Thanks!",,"['differential-geometry', 'differential-forms']"
42,Why are the fibers of principal G-bundles homeomorphic to G?,Why are the fibers of principal G-bundles homeomorphic to G?,,"I'm trying to get a grip on the modern geometric formulation of gauge theory, in particular connections on principal G-bundles. However, I am stuck right after the definition already: Virtually all introductory texts I found mention (without proof) the fact that the fiber of such a bundle is homeomorphic to the structural group. To avoid ambiguity, let's use the Wikipedia definition: Definition: Let $G$ be a topological group. A principal $G$-bundle is a fiber bundle $F \hookrightarrow P \xrightarrow{\pi} X$ together with a continuous right action   $$P \times G \to P$$   $$(p,g) \mapsto p.g$$    of $G$ on $P$ which preserves fibers, i.e.   $$\pi(p.g) = \pi(p) $$   $\forall p \in P$, $g \in G$   and is free and transitive on all  $F_x = \pi^{-1}(\{x\})$. It appears to be a standard fact that $F \cong G$; I haven't a clue how to prove this, though. My best guess is to fix an element $p\in P$ and consider the restricted group action $$G\cong\{p\}\times G \to F_{\pi(p)} \cong F$$ By transitivity, freeness and continuity of the group action, this map is a continuous bijection which is not necessarily a homeomorphism unless e.g. $G$ is compact and $F$ is Hausdorff. I can buy that $F$ is Hausdorff if we restrict ourselves to manifolds, but even then $G$ certainly does not have to be compact. What am I missing? Any help is greatly appreciated.","I'm trying to get a grip on the modern geometric formulation of gauge theory, in particular connections on principal G-bundles. However, I am stuck right after the definition already: Virtually all introductory texts I found mention (without proof) the fact that the fiber of such a bundle is homeomorphic to the structural group. To avoid ambiguity, let's use the Wikipedia definition: Definition: Let $G$ be a topological group. A principal $G$-bundle is a fiber bundle $F \hookrightarrow P \xrightarrow{\pi} X$ together with a continuous right action   $$P \times G \to P$$   $$(p,g) \mapsto p.g$$    of $G$ on $P$ which preserves fibers, i.e.   $$\pi(p.g) = \pi(p) $$   $\forall p \in P$, $g \in G$   and is free and transitive on all  $F_x = \pi^{-1}(\{x\})$. It appears to be a standard fact that $F \cong G$; I haven't a clue how to prove this, though. My best guess is to fix an element $p\in P$ and consider the restricted group action $$G\cong\{p\}\times G \to F_{\pi(p)} \cong F$$ By transitivity, freeness and continuity of the group action, this map is a continuous bijection which is not necessarily a homeomorphism unless e.g. $G$ is compact and $F$ is Hausdorff. I can buy that $F$ is Hausdorff if we restrict ourselves to manifolds, but even then $G$ certainly does not have to be compact. What am I missing? Any help is greatly appreciated.",,"['differential-geometry', 'topological-groups', 'fiber-bundles', 'principal-bundles']"
43,When do parallel sections exist?,When do parallel sections exist?,,"I suspect that this is a ""trivial"" question, but I don't have enough background to know the answer immediately: Suppose $\pi : E \to M$ is a trivial real line bundle on a smooth manifold $M$, and suppose we have a flat connection $\nabla$ on $E$. Does there always exist a nowhere vanishing parallel section of $E$? If not, when does one exist?","I suspect that this is a ""trivial"" question, but I don't have enough background to know the answer immediately: Suppose $\pi : E \to M$ is a trivial real line bundle on a smooth manifold $M$, and suppose we have a flat connection $\nabla$ on $E$. Does there always exist a nowhere vanishing parallel section of $E$? If not, when does one exist?",,"['differential-geometry', 'vector-bundles', 'connections']"
44,"Lie bracket of two vectors $X,Y$ perpendicular to $Z$ is perpendicular to $Z$",Lie bracket of two vectors  perpendicular to  is perpendicular to,"X,Y Z Z","Where $Z$ is a Killing vector field (is this even necessary?) In case more assumptions are necessary, I have: $[Z,X] = [Z,Y] = g(Z,X) = g(Z,Y) = 0$ I want to prove $g([X,Y],Z) = 0$ I am trying to prove this without using coordinates. I kind of have a rough argument using the definition of the Lie derivative (I'm moving a vector that's always perpendicular to $Z$ through a curve in the orthogonal space to $Z$ so necessarily the difference must be in the orthogonal space) but I am not sure how to formalize it and whether I can simply put the definition inside the dot product. Are the assumptions that $Z$ is a Killing vector field necessary, and what about $[Z,X] = [Z,Y] = 0$? edit: I forgot to mention, the metric is of the form $ds^2 = \Theta dz^2 + \hat{g}_{ab}dx^adx^b$ where nothing depends on $z$. I think that the precise name for this is polarized axial symmetry, or equivalently Ernst potential is $0$.","Where $Z$ is a Killing vector field (is this even necessary?) In case more assumptions are necessary, I have: $[Z,X] = [Z,Y] = g(Z,X) = g(Z,Y) = 0$ I want to prove $g([X,Y],Z) = 0$ I am trying to prove this without using coordinates. I kind of have a rough argument using the definition of the Lie derivative (I'm moving a vector that's always perpendicular to $Z$ through a curve in the orthogonal space to $Z$ so necessarily the difference must be in the orthogonal space) but I am not sure how to formalize it and whether I can simply put the definition inside the dot product. Are the assumptions that $Z$ is a Killing vector field necessary, and what about $[Z,X] = [Z,Y] = 0$? edit: I forgot to mention, the metric is of the form $ds^2 = \Theta dz^2 + \hat{g}_{ab}dx^adx^b$ where nothing depends on $z$. I think that the precise name for this is polarized axial symmetry, or equivalently Ernst potential is $0$.",,"['differential-geometry', 'lie-derivative']"
45,Does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point?,Does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point?,,"As the question suggests, does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point? Many thanks in advance. To be clear, I'm using the statement of Brouwer's Fixed-Point Theorem from $\S$2.2 of Guillemin-Pollack, which is stated as follows. Any smooth map $f$ of the closed unit ball $B^n \subset \mathbb{R}^n$ into itself must have a fixed point; that is, $f(x) = x$ for some $x \in B^n$.","As the question suggests, does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point? Many thanks in advance. To be clear, I'm using the statement of Brouwer's Fixed-Point Theorem from $\S$2.2 of Guillemin-Pollack, which is stated as follows. Any smooth map $f$ of the closed unit ball $B^n \subset \mathbb{R}^n$ into itself must have a fixed point; that is, $f(x) = x$ for some $x \in B^n$.",,"['differential-geometry', 'manifolds']"
46,Push-forward of vector fields by local isometries,Push-forward of vector fields by local isometries,,"I am studying Riemannian Manifolds by John Lee, and there is this lemma: Lemma 7.2. The Riemann curvature endomorphism and curvature tensor are local isometry invariants. More precisely, if $\varphi:(M,g)\to(\widetilde{M},\tilde{g})$ is a local isometry, then $$\varphi^\ast\widetilde{Rm}=Rm;$$   $$\widetilde{R}(\varphi_\ast X,\varphi_\ast Y)\varphi_\ast Z=\varphi_\ast(R(X,Y)Z)\tag{1}.$$ But a general local isometry need not be a diffeomorphism, so how to make sense of the push-forward of vector fields (e.g. $\varphi_\ast X$) in this case? How to interpret equation $(1)$? As far as I know, the push-forward is defined for a vector field $X$ on $M$ by $$\varphi_\ast X:\widetilde{M}\to T\widetilde{M},\quad (\varphi_\ast X)_q=d\varphi_{\varphi^{-1}(q)}(X_{\varphi^{-1}(q)}),$$ so $\varphi^{-1}$ must exist and be smooth. The proof of Lemma 7.2 is left as an exercise to the reader, so I don't have much clue to understand what the author meant.","I am studying Riemannian Manifolds by John Lee, and there is this lemma: Lemma 7.2. The Riemann curvature endomorphism and curvature tensor are local isometry invariants. More precisely, if $\varphi:(M,g)\to(\widetilde{M},\tilde{g})$ is a local isometry, then $$\varphi^\ast\widetilde{Rm}=Rm;$$   $$\widetilde{R}(\varphi_\ast X,\varphi_\ast Y)\varphi_\ast Z=\varphi_\ast(R(X,Y)Z)\tag{1}.$$ But a general local isometry need not be a diffeomorphism, so how to make sense of the push-forward of vector fields (e.g. $\varphi_\ast X$) in this case? How to interpret equation $(1)$? As far as I know, the push-forward is defined for a vector field $X$ on $M$ by $$\varphi_\ast X:\widetilde{M}\to T\widetilde{M},\quad (\varphi_\ast X)_q=d\varphi_{\varphi^{-1}(q)}(X_{\varphi^{-1}(q)}),$$ so $\varphi^{-1}$ must exist and be smooth. The proof of Lemma 7.2 is left as an exercise to the reader, so I don't have much clue to understand what the author meant.",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds', 'curvature']"
47,About the definition of regular surface in do Carmo,About the definition of regular surface in do Carmo,,"According to do Carmo, the definition of regular surface requires us to check $X^{-1}$ to be continuous (where $X$ is a local parametrization). But doesn't it infer from other conditions (as shown in his Prop. 4 of Sec 2-2, see photo attached here !!! )? Although he stated regular surface has to be known in advance (prop. 4), actually it seems that he doesn't use it in the proof. He simply uses $X$ to be differentiable and regular and inverse function theorem to conclude $X^{-1}$ is continuous.","According to do Carmo, the definition of regular surface requires us to check $X^{-1}$ to be continuous (where $X$ is a local parametrization). But doesn't it infer from other conditions (as shown in his Prop. 4 of Sec 2-2, see photo attached here !!! )? Although he stated regular surface has to be known in advance (prop. 4), actually it seems that he doesn't use it in the proof. He simply uses $X$ to be differentiable and regular and inverse function theorem to conclude $X^{-1}$ is continuous.",,['differential-geometry']
48,Applications of Principal Bundle Construction: Vague Question,Applications of Principal Bundle Construction: Vague Question,,"I recently read the principal $G$-bundle construction on a smooth manifold $M$, where $G$ is a Lie group. To understand them better, I am looking for some applications. Can the principal $G$-bundle help us get some usual bundle constructions, for example tensor product of two vector bundles, the pullback bundle etc? Right now, the constructions I have seen are specific to each type of construction. If I want the tensor product of two vector bundles $E$ and $F$ over a smooth manifold $M$, I start from scratch and consider the disjoint union $\bigsqcup_{p\in M} E_p\otimes F_p$ and put trivializations ""naturally"". Similarly for the dual bundle. Is there a unified way to think of these constructions so that all the constructions are dealt with in one shot?","I recently read the principal $G$-bundle construction on a smooth manifold $M$, where $G$ is a Lie group. To understand them better, I am looking for some applications. Can the principal $G$-bundle help us get some usual bundle constructions, for example tensor product of two vector bundles, the pullback bundle etc? Right now, the constructions I have seen are specific to each type of construction. If I want the tensor product of two vector bundles $E$ and $F$ over a smooth manifold $M$, I start from scratch and consider the disjoint union $\bigsqcup_{p\in M} E_p\otimes F_p$ and put trivializations ""naturally"". Similarly for the dual bundle. Is there a unified way to think of these constructions so that all the constructions are dealt with in one shot?",,"['differential-geometry', 'smooth-manifolds', 'principal-bundles']"
49,CAT(K) Finsler manifolds.,CAT(K) Finsler manifolds.,,"I was wondering if the following is true (and common knowledge): Let $(M,F)$ be a Finsler manifold. Let d be the induced distance by the norm in the usual sense. That is, $d(x,y)=\inf${lenghts of all piece-wise smooth curves...}. We consider then $(M,d)$ as a metric space. My questions, which are probably quite easy, are these: 1) Suppose that $d$ is a righteous metric, in the sense that is also symmetric. Does that imply that $(M,F)$ was actually a Riemannian manifold for starters? If not could you please show me a counter example? 2) If the answer to 1) is negative then suppose $(M,d)$ happens to also be a $CAT(\kappa)$ space. does it follow that M is necessarily a Riemannian manifold? If not, what about $\kappa =0$? Thanks a lot in advance for any help clearing this out. Of curse, any reference is gratefully welcomed.","I was wondering if the following is true (and common knowledge): Let $(M,F)$ be a Finsler manifold. Let d be the induced distance by the norm in the usual sense. That is, $d(x,y)=\inf${lenghts of all piece-wise smooth curves...}. We consider then $(M,d)$ as a metric space. My questions, which are probably quite easy, are these: 1) Suppose that $d$ is a righteous metric, in the sense that is also symmetric. Does that imply that $(M,F)$ was actually a Riemannian manifold for starters? If not could you please show me a counter example? 2) If the answer to 1) is negative then suppose $(M,d)$ happens to also be a $CAT(\kappa)$ space. does it follow that M is necessarily a Riemannian manifold? If not, what about $\kappa =0$? Thanks a lot in advance for any help clearing this out. Of curse, any reference is gratefully welcomed.",,"['differential-geometry', 'riemannian-geometry', 'metric-geometry']"
50,Chern class of complex vector bundles,Chern class of complex vector bundles,,"Let $\xi$ be an $n$-dimensional complex vector bundle. It is claimed that the Chern class of $\xi$ is $$ c(\xi)=(1+x_1)\cdots (1+x_n), $$ $|x_k|=2$, $c_j(\xi)$ is the $j$-th symmetric polynomial of $x_1,\cdots,x_n$. Is this claim true? In the case $\xi=L_1\oplus\cdots\oplus L_n$, Whitney sum of complex line bundles, I have obtained the claim. How about general case?","Let $\xi$ be an $n$-dimensional complex vector bundle. It is claimed that the Chern class of $\xi$ is $$ c(\xi)=(1+x_1)\cdots (1+x_n), $$ $|x_k|=2$, $c_j(\xi)$ is the $j$-th symmetric polynomial of $x_1,\cdots,x_n$. Is this claim true? In the case $\xi=L_1\oplus\cdots\oplus L_n$, Whitney sum of complex line bundles, I have obtained the claim. How about general case?",,"['algebraic-geometry', 'differential-geometry', 'algebraic-topology', 'vector-bundles', 'characteristic-classes']"
51,"In the definition of critical point, how can $df_p$ be surjective?","In the definition of critical point, how can  be surjective?",df_p,"Let $f:M→N$ be a smooth function between two smooth manifolds. Then $p\in M$ is a critical point if $df_p$ is not surjective. I feel very confused about this definition, even in the case where $M=N=\mathbb{R}$ . I can understand at a critical point $p$ , $df_p$ sends all tangent vectors at $p$ (all on the x-axis) to a zero tangent vector w.r.t. the y-axis. But on a regular point, I feel $df_p$ is not surjective either, ""since"" the tangent direction is fixed at each point $f(p)$ . Where does my intuition go wrong?","Let be a smooth function between two smooth manifolds. Then is a critical point if is not surjective. I feel very confused about this definition, even in the case where . I can understand at a critical point , sends all tangent vectors at (all on the x-axis) to a zero tangent vector w.r.t. the y-axis. But on a regular point, I feel is not surjective either, ""since"" the tangent direction is fixed at each point . Where does my intuition go wrong?",f:M→N p\in M df_p M=N=\mathbb{R} p df_p p df_p f(p),"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds', 'smooth-functions']"
52,Almost hermitian manifolds with closed symplectic form,Almost hermitian manifolds with closed symplectic form,,"An hermitian manifold $M$ is a manifold equipped with a Riemannian metric $g$, a non-degenerate two-form $\omega$, and an almost complex structure $J$ such that $\omega(\cdot,\cdot) = g(J\cdot,\cdot)$ $(M,g,J,\omega)$ is a Kahler manifold if and only if $J$ is integrable, namely it is a complex structure on $M$, and $\omega$ is closed, namely it is a symplectic form on $M$. What happens if we relax the condition of $J$ being integrable but we still demand $\omega$ to be closed? Does this kind of manifolds have a name? Do they enjoy interesting geometric properties as the more constained Kahler manifolds do? Thanks.","An hermitian manifold $M$ is a manifold equipped with a Riemannian metric $g$, a non-degenerate two-form $\omega$, and an almost complex structure $J$ such that $\omega(\cdot,\cdot) = g(J\cdot,\cdot)$ $(M,g,J,\omega)$ is a Kahler manifold if and only if $J$ is integrable, namely it is a complex structure on $M$, and $\omega$ is closed, namely it is a symplectic form on $M$. What happens if we relax the condition of $J$ being integrable but we still demand $\omega$ to be closed? Does this kind of manifolds have a name? Do they enjoy interesting geometric properties as the more constained Kahler manifolds do? Thanks.",,"['differential-geometry', 'almost-complex']"
53,Umbilical points of Ellipsoid alternate method,Umbilical points of Ellipsoid alternate method,,"I'm having serious trouble finding the umbilical points of the ellipsoid represented by $$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1,    \;\;\;a,b,c\neq 0.$$ My first thought was to use the parametrization $$\mathbf{x}(u,v)=(a\sin(u)\cos(v),b\sin(u)\sin(v),c\cos(u)),$$ for $0<u<\pi$ and $0<v<2\pi$, compute the first and second fundamental forms, etc., but this is a nightmare. After doing some researching (and on the back solutions of Do Carmo) I came across I suppose what would be an alternate method which doesn't dig directly into a parametrization. It is explained slightly at the end of the pdf: http://www.math.umn.edu/~voronov/5378/sample1.pdf which essentially states to notice that $N_1=(\frac{x^2}{a^2},\frac{y^2}{b^2},\frac{z^2}{b^2})$ (the gradient) is such that $N_1=fN$, for some $f$ such that $|f|=|N_1|$, where $N$ is the unit normal vector to surface, as well as notice a point on a curve $\alpha(t)=(x(t),y(t),z(t))$ lying on the ellipsoid is an umbilical point iff the vector triple product \begin{equation} \left(\frac{dN_1}{dt}\wedge \alpha '\right)\cdot N_1=0\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(1) \end{equation} which I mostly understand. Then it says use some trickery by multiplying a $\frac{z}{c^2}$ to the equation and put it in terms of $x,x',y',$ and $y$ like this... The way I understand it you should start with equation (1) in this form $$ \left(\left(\frac{x'}{a^2},\frac{y'}{b^2},\frac{z'}{c^2}\right)\wedge\left(x',y',z'\right)\right)\cdot\left(\frac{x}{a^2},\frac{y}{b^2},\frac{z}{c^2}\right)=0. $$ Then, making things more complicated, (plugging everything in and doing the computation) we have $$ \frac{xy'z}{a^2b^2}-\frac{xy'z'}{a^2c^2}+\frac{x'yz'}{b^2c^2}-\frac{x'yz'}{a^2b^2}+\frac{x'y'z}{a^2c^2}-\frac{x'y'z}{b^2c^2}=0. $$ Multiplying $\frac{z}{c^2}$ to both sides gives $$ \frac{xy'z'z}{a^2b^2c^2}-\frac{xy'z'z}{a^2c^4}+\frac{x'yz'z}{b^2c^4}-\frac{x'yz'z}{a^2b^2c^2}+\frac{x'y'z^2}{a^2c^4}-\frac{x'y'z^2}{b^2c^4}=0 $$ From here I suppose one would use the original equation for the ellipsoid as well as implicit derivative, $\frac{2zz'}{c^2}=-\frac{2yy'}{b^2}-\frac{2xx'}{a^2}$ to get rid of $z$ and $z'$. However, when I do that it starts getting pretty messy and I'm starting to believe I'm not quite understanding the method correctly. I also believe $y=0$ should satisfy this equation, but that's not quite working out, which also leads me to believe that I'm wrong in my thought. Any opinions/suggestions would be greatly appreciated. Thank you","I'm having serious trouble finding the umbilical points of the ellipsoid represented by $$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1,    \;\;\;a,b,c\neq 0.$$ My first thought was to use the parametrization $$\mathbf{x}(u,v)=(a\sin(u)\cos(v),b\sin(u)\sin(v),c\cos(u)),$$ for $0<u<\pi$ and $0<v<2\pi$, compute the first and second fundamental forms, etc., but this is a nightmare. After doing some researching (and on the back solutions of Do Carmo) I came across I suppose what would be an alternate method which doesn't dig directly into a parametrization. It is explained slightly at the end of the pdf: http://www.math.umn.edu/~voronov/5378/sample1.pdf which essentially states to notice that $N_1=(\frac{x^2}{a^2},\frac{y^2}{b^2},\frac{z^2}{b^2})$ (the gradient) is such that $N_1=fN$, for some $f$ such that $|f|=|N_1|$, where $N$ is the unit normal vector to surface, as well as notice a point on a curve $\alpha(t)=(x(t),y(t),z(t))$ lying on the ellipsoid is an umbilical point iff the vector triple product \begin{equation} \left(\frac{dN_1}{dt}\wedge \alpha '\right)\cdot N_1=0\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(1) \end{equation} which I mostly understand. Then it says use some trickery by multiplying a $\frac{z}{c^2}$ to the equation and put it in terms of $x,x',y',$ and $y$ like this... The way I understand it you should start with equation (1) in this form $$ \left(\left(\frac{x'}{a^2},\frac{y'}{b^2},\frac{z'}{c^2}\right)\wedge\left(x',y',z'\right)\right)\cdot\left(\frac{x}{a^2},\frac{y}{b^2},\frac{z}{c^2}\right)=0. $$ Then, making things more complicated, (plugging everything in and doing the computation) we have $$ \frac{xy'z}{a^2b^2}-\frac{xy'z'}{a^2c^2}+\frac{x'yz'}{b^2c^2}-\frac{x'yz'}{a^2b^2}+\frac{x'y'z}{a^2c^2}-\frac{x'y'z}{b^2c^2}=0. $$ Multiplying $\frac{z}{c^2}$ to both sides gives $$ \frac{xy'z'z}{a^2b^2c^2}-\frac{xy'z'z}{a^2c^4}+\frac{x'yz'z}{b^2c^4}-\frac{x'yz'z}{a^2b^2c^2}+\frac{x'y'z^2}{a^2c^4}-\frac{x'y'z^2}{b^2c^4}=0 $$ From here I suppose one would use the original equation for the ellipsoid as well as implicit derivative, $\frac{2zz'}{c^2}=-\frac{2yy'}{b^2}-\frac{2xx'}{a^2}$ to get rid of $z$ and $z'$. However, when I do that it starts getting pretty messy and I'm starting to believe I'm not quite understanding the method correctly. I also believe $y=0$ should satisfy this equation, but that's not quite working out, which also leads me to believe that I'm wrong in my thought. Any opinions/suggestions would be greatly appreciated. Thank you",,['differential-geometry']
54,how do I calculate the Euler characteristic of a Klein bottle?,how do I calculate the Euler characteristic of a Klein bottle?,,"I guess I have to use that it is a closed surface (manifold) and therefore its boundary is empty, so then I gotta use Gauss-Bonnet easily (but I just cannot think of how to use it.) i.e. $$\chi(\textit{Klein Bottle})=\frac{1}{2\pi}\int\int_{\textit{Klein Bottle}}K\,d\sigma$$ I was thinking on using that a Klein bottle is homeomorphic to 2 ""glued"" Möbius strips, but how from then...? P.S. this is from my first course on Differential Geometry, so talkings on higher-level courses wouldn't help me at all","I guess I have to use that it is a closed surface (manifold) and therefore its boundary is empty, so then I gotta use Gauss-Bonnet easily (but I just cannot think of how to use it.) i.e. $$\chi(\textit{Klein Bottle})=\frac{1}{2\pi}\int\int_{\textit{Klein Bottle}}K\,d\sigma$$ I was thinking on using that a Klein bottle is homeomorphic to 2 ""glued"" Möbius strips, but how from then...? P.S. this is from my first course on Differential Geometry, so talkings on higher-level courses wouldn't help me at all",,"['differential-geometry', 'algebraic-topology', 'klein-bottle', 'mobius-band']"
55,The differential $\text d F_p$ is injective iff the pullback $F_p^*$ is surjective.,The differential  is injective iff the pullback  is surjective.,\text d F_p F_p^*,"I'm trying to prove the following claim: Let $F\colon M \to N$ be a differentiable application beetween $C^\infty$ manifolds. Then the differential $\text dF_p\colon T_p M \to T_{F(p)}N$ is injective if and only if the pullback $F_p^*\colon C^\infty _N (F(p))\to C^\infty _M (p)$ is surjective. Where $C^\infty _S (q)$ are the germs in $q$, $F_p^*(\mathbf g)=\mathbf g \circ F$ and $\text dF_p (X)=X\circ F_p ^*$. I'll use Einstein's convention on summations. Let $(\varphi = (x^1,x^2,\dots,x^n),U)$ be a local chart in $p$. Sufficiency: Proof by contrapositive: suppose that $\text d F_p(X^i \partial _i |_p)=O$ and $X^k\neq 0$. Then for all $\mathbf g \in C^\infty _N (F(p))$ $$0=\text d F_p(X^i \partial _i |_p)(\mathbf g)=X^i \partial _i |_p(F_p ^*(\mathbf g)).$$ This shows that $\mathbf x ^k$ is not in the image of $F_p ^*$, hence if $F_p^*$ is surjective then $\text d F _p$ is injective. [] Now for the converse, I was reasoning on these lines: if $F_p ^* (\mathbf h)\neq \mathbf g$ for all $\mathbf h \in C^\infty _N (F(p))$ and for some $\mathbf g \in C^\infty _M (p)$, then we can consider the ideal $$I=\{ \mathbf g \cdot \mathbf f_0 | \mathbf f _0 \in C^\infty _M (p)\}.$$ It is easily seen that $$\text {Im}F_p ^*\cap I= \{\mathbf 0 \}.$$ Now, if I could find a derivation such that $X(\mathbf g)=1$ and $X(C^\infty _M (p) - I)=\{0\}$ this would be done. My problem is to find such $X$. Since it is not restrictive to assume $\mathbf g(p)=0$, more generally a derivation would act on $I$ in this way: $$X(\mathbf f)=X(\mathbf g \mathbf f _0)=X(\mathbf g)\mathbf f(p),$$ however I'm not sure if I can use this fact in any way. Any help is appreciated; I'd prefer to complete my proof, but also a different one would be OK.","I'm trying to prove the following claim: Let $F\colon M \to N$ be a differentiable application beetween $C^\infty$ manifolds. Then the differential $\text dF_p\colon T_p M \to T_{F(p)}N$ is injective if and only if the pullback $F_p^*\colon C^\infty _N (F(p))\to C^\infty _M (p)$ is surjective. Where $C^\infty _S (q)$ are the germs in $q$, $F_p^*(\mathbf g)=\mathbf g \circ F$ and $\text dF_p (X)=X\circ F_p ^*$. I'll use Einstein's convention on summations. Let $(\varphi = (x^1,x^2,\dots,x^n),U)$ be a local chart in $p$. Sufficiency: Proof by contrapositive: suppose that $\text d F_p(X^i \partial _i |_p)=O$ and $X^k\neq 0$. Then for all $\mathbf g \in C^\infty _N (F(p))$ $$0=\text d F_p(X^i \partial _i |_p)(\mathbf g)=X^i \partial _i |_p(F_p ^*(\mathbf g)).$$ This shows that $\mathbf x ^k$ is not in the image of $F_p ^*$, hence if $F_p^*$ is surjective then $\text d F _p$ is injective. [] Now for the converse, I was reasoning on these lines: if $F_p ^* (\mathbf h)\neq \mathbf g$ for all $\mathbf h \in C^\infty _N (F(p))$ and for some $\mathbf g \in C^\infty _M (p)$, then we can consider the ideal $$I=\{ \mathbf g \cdot \mathbf f_0 | \mathbf f _0 \in C^\infty _M (p)\}.$$ It is easily seen that $$\text {Im}F_p ^*\cap I= \{\mathbf 0 \}.$$ Now, if I could find a derivation such that $X(\mathbf g)=1$ and $X(C^\infty _M (p) - I)=\{0\}$ this would be done. My problem is to find such $X$. Since it is not restrictive to assume $\mathbf g(p)=0$, more generally a derivation would act on $I$ in this way: $$X(\mathbf f)=X(\mathbf g \mathbf f _0)=X(\mathbf g)\mathbf f(p),$$ however I'm not sure if I can use this fact in any way. Any help is appreciated; I'd prefer to complete my proof, but also a different one would be OK.",,['differential-geometry']
56,Connection vs Curvature,Connection vs Curvature,,"Why is twice a connection usually referred to the curvature: $\overline{\nabla}\circ\nabla=F^\nabla$ Is there an axiomatic definition of curvature, e.g. it is module-linear operator etc?","Why is twice a connection usually referred to the curvature: $\overline{\nabla}\circ\nabla=F^\nabla$ Is there an axiomatic definition of curvature, e.g. it is module-linear operator etc?",,"['differential-geometry', 'manifolds', 'vector-bundles']"
57,diffeomorphism of the bundle chart of a Tangent bundle,diffeomorphism of the bundle chart of a Tangent bundle,,"I am studying about tangent bundle from the book ""J. M lee"", on page 66 of the book a map $\tilde{\phi} : \pi^{-1}(U) \to \mathbb{R}^{2n}$ is defined by $$v^i \frac{\partial}{\partial x^i}|_p \mapsto (x^1(p),\cdots, x^n(p),v^1,\cdots,v^n)$$ where $(x^1,\cdots,x^n)$ is the coordinate functions of $\phi$ and $(U,\phi)$ is a local coordinate chart of a smooth manifold $M$. It is written on page 252 that $\tilde{\phi}$ is a diffeomorphism but i am not able to prove it. Can someone explain it! Thanks!","I am studying about tangent bundle from the book ""J. M lee"", on page 66 of the book a map $\tilde{\phi} : \pi^{-1}(U) \to \mathbb{R}^{2n}$ is defined by $$v^i \frac{\partial}{\partial x^i}|_p \mapsto (x^1(p),\cdots, x^n(p),v^1,\cdots,v^n)$$ where $(x^1,\cdots,x^n)$ is the coordinate functions of $\phi$ and $(U,\phi)$ is a local coordinate chart of a smooth manifold $M$. It is written on page 252 that $\tilde{\phi}$ is a diffeomorphism but i am not able to prove it. Can someone explain it! Thanks!",,['differential-geometry']
58,Flatness of a manifold (or a connection),Flatness of a manifold (or a connection),,"Suppose we have an $n$-dimensional manifold $S$ (with a global coordinate system) with a metric $g$ and a connection $\nabla$ with connection coefficients (Christoffel symbols) $\Gamma_{i,j}^k$ given. Suppose that the $\nabla$-geodesic connecting any two points of the manifold completely lies in $S$. Can we then say that $S$ must be flat with respect to the given connection? I am not able to straightaway show that $(\Gamma_{i,j}^k)_p = 0$ at all points $p$ of $S$.","Suppose we have an $n$-dimensional manifold $S$ (with a global coordinate system) with a metric $g$ and a connection $\nabla$ with connection coefficients (Christoffel symbols) $\Gamma_{i,j}^k$ given. Suppose that the $\nabla$-geodesic connecting any two points of the manifold completely lies in $S$. Can we then say that $S$ must be flat with respect to the given connection? I am not able to straightaway show that $(\Gamma_{i,j}^k)_p = 0$ at all points $p$ of $S$.",,"['differential-geometry', 'riemannian-geometry']"
59,Recommendation on studying differential geometry,Recommendation on studying differential geometry,,"Below are what i studied so far: Rudin - Principles of Anlysis (only except one chapter, namely differential forms) Munkres - Topology (only point-set topology) Rudin - RCA (Only first 4 chapters) Frank Jones - Real analysis (Till a chapter about the Lebesgue measure of a 2-norm ball) The problem is, i have never studied multivariable calculus rigorously . The only thing i know about this subject is that smooth manifold is a generalization of differential geometry in $\mathbb{R}^n$ . Well, i want to directly study that, but i'm taking introductory differential geometry this semester, so i have to study this introductory level to get a credit :) What i'm curious to know about this subject are followings: Could line integral, area integral and etc which appear in this subject be generalized throughout Lebesgue integration? What's the point of differential forms ? I find it very unnatural and guess this is merely an argument about Lebesgue integral in Riemann integral setting . Which chapters should i focus on when i study this subject? That is, one may find a motivation to expand the theory to a general setting, namely smooth manifolds. What point of view should i have in my mind? One more, the text using in the class is ""Differential geometry - Barrett O neil"". This text restricts every context in $\mathbb{R}^3$ . I don't quite understand what the author inteded by such reatriction. Why not $\mathbb{R}^n$ ? Is it to avoid introducing tensor product?","Below are what i studied so far: Rudin - Principles of Anlysis (only except one chapter, namely differential forms) Munkres - Topology (only point-set topology) Rudin - RCA (Only first 4 chapters) Frank Jones - Real analysis (Till a chapter about the Lebesgue measure of a 2-norm ball) The problem is, i have never studied multivariable calculus rigorously . The only thing i know about this subject is that smooth manifold is a generalization of differential geometry in . Well, i want to directly study that, but i'm taking introductory differential geometry this semester, so i have to study this introductory level to get a credit :) What i'm curious to know about this subject are followings: Could line integral, area integral and etc which appear in this subject be generalized throughout Lebesgue integration? What's the point of differential forms ? I find it very unnatural and guess this is merely an argument about Lebesgue integral in Riemann integral setting . Which chapters should i focus on when i study this subject? That is, one may find a motivation to expand the theory to a general setting, namely smooth manifolds. What point of view should i have in my mind? One more, the text using in the class is ""Differential geometry - Barrett O neil"". This text restricts every context in . I don't quite understand what the author inteded by such reatriction. Why not ? Is it to avoid introducing tensor product?",\mathbb{R}^n \mathbb{R}^3 \mathbb{R}^n,"['real-analysis', 'differential-geometry', 'soft-question', 'manifolds']"
60,"If a smooth map between manifolds is injective, is the induced map on the tangent spaces injective too?","If a smooth map between manifolds is injective, is the induced map on the tangent spaces injective too?",,"If $\phi:M\longrightarrow N$ is an injective smooth map between two manifolds, then is $d\phi_m:M_m\longrightarrow N_{\phi(m)}$, the induced map between the tangent spaces injective too? I tried the following : If $v\in M_m$ is such that $d\phi_m(v)=0$, then for all $g$, $C^{\infty}$ function in a neighbourhood of $\phi(m)$, $d\phi_m(v)(g)=0$, that is $v(g\circ\phi)=0$ for all such $g$. From this can we conclude that $v$ is the $0$ tangent vector. I got this doubt when I was trying to understand the definition of an immersion. I was wondering if $\phi$ being injective will automatically make it an immersion.","If $\phi:M\longrightarrow N$ is an injective smooth map between two manifolds, then is $d\phi_m:M_m\longrightarrow N_{\phi(m)}$, the induced map between the tangent spaces injective too? I tried the following : If $v\in M_m$ is such that $d\phi_m(v)=0$, then for all $g$, $C^{\infty}$ function in a neighbourhood of $\phi(m)$, $d\phi_m(v)(g)=0$, that is $v(g\circ\phi)=0$ for all such $g$. From this can we conclude that $v$ is the $0$ tangent vector. I got this doubt when I was trying to understand the definition of an immersion. I was wondering if $\phi$ being injective will automatically make it an immersion.",,"['differential-geometry', 'manifolds']"
61,How to verify that this is a submanifold,How to verify that this is a submanifold,,"Let $ g: \mathbb{R}^2 \to \mathbb{R}^2 $ , $ g (x, y) = (x^2-y^2, y) $ be a differentiable map. Let $ r $ the line passing through $(1, 0) $ parallel to the $ y-$axis. Prove that $ g^{-1}(r) $ is a submanifold of $ \mathbb{R}^2 $ I don't have many instruments to prove this fact, and the only theorem which involves the inverse of a differential function is this one: Theorem: Suppose $ X, Y $ are manifolds and $ f:X \to Y $ a differentiable map. Let $ y \in Y $. If $ f $ is a submersion at each point of $ f^{-1}(y) $, then $ f^{-1}(y) $ is a submanifold. I think this is the result to use, but $ r $ is not a point of $\mathbb{R}^2 $, so I don't know whether i can use the theorem. Maybe there is something else to use, but these are my first exercises involving manifolds so I don't have much practice.","Let $ g: \mathbb{R}^2 \to \mathbb{R}^2 $ , $ g (x, y) = (x^2-y^2, y) $ be a differentiable map. Let $ r $ the line passing through $(1, 0) $ parallel to the $ y-$axis. Prove that $ g^{-1}(r) $ is a submanifold of $ \mathbb{R}^2 $ I don't have many instruments to prove this fact, and the only theorem which involves the inverse of a differential function is this one: Theorem: Suppose $ X, Y $ are manifolds and $ f:X \to Y $ a differentiable map. Let $ y \in Y $. If $ f $ is a submersion at each point of $ f^{-1}(y) $, then $ f^{-1}(y) $ is a submanifold. I think this is the result to use, but $ r $ is not a point of $\mathbb{R}^2 $, so I don't know whether i can use the theorem. Maybe there is something else to use, but these are my first exercises involving manifolds so I don't have much practice.",,"['differential-geometry', 'manifolds']"
62,Length of a Coastline,Length of a Coastline,,"When B. Mandelbrot's typical example of measuring the length of a coastline is referenced, they mention how at every scale the length increases. In pure mathematics, I can imagine this quite well-- the iterating function goes on forever (infinitely) and there are no restrictions to how small it can get. Do they mean it increases asymptotically? Would the ""true"" length then be the limit? In practice, would this scaling factor not be so well defined? Can it be true that a coastline is always getting longer depending on how small of a measuring stick you use? I understand that these topics are frequently explained to non-mathematicians and a lot of the available literature is geared toward them, but that makes it more difficult to grasp. Please use however advanced language you need in order to make the discussion precise.","When B. Mandelbrot's typical example of measuring the length of a coastline is referenced, they mention how at every scale the length increases. In pure mathematics, I can imagine this quite well-- the iterating function goes on forever (infinitely) and there are no restrictions to how small it can get. Do they mean it increases asymptotically? Would the ""true"" length then be the limit? In practice, would this scaling factor not be so well defined? Can it be true that a coastline is always getting longer depending on how small of a measuring stick you use? I understand that these topics are frequently explained to non-mathematicians and a lot of the available literature is geared toward them, but that makes it more difficult to grasp. Please use however advanced language you need in order to make the discussion precise.",,"['differential-geometry', 'fractals', 'low-dimensional-topology']"
63,Surface from metric,Surface from metric,,"I have a metric $g_{i,j}$, in two dimensions for example. How do I find the surface that it represents, in paramatrized form, as a function $z=f(x,y)$, etc. ?","I have a metric $g_{i,j}$, in two dimensions for example. How do I find the surface that it represents, in paramatrized form, as a function $z=f(x,y)$, etc. ?",,['differential-geometry']
64,Surface area element of an ellipsoid,Surface area element of an ellipsoid,,"I would like to evaluate an integral numerically over the surface of an ellipsoid. Take an $N \times N$ grid over the parameter space $(u, v) \in [0, 2\pi) \times [0, \pi) $. A simple approximation of the integral is $$ \int_0^{2\pi}\int_0^\pi \mathbf{f}(u,v)\,dA \simeq \sum_{i,j=1}^N \mathbf{f}(u_i,v_j)\, \Delta A(u_i,v_j) $$ where $\Delta A(u_i, v_j)$ is the surface area of the portion of the ellipsoid spanned by the parameter region $(u_i, u_{i+1}) \times (v_j, v_{j+1})$. I had hoped to compute $\Delta A(u_i, v_j)$ analytically: \begin{equation} \Delta A(u_i, v_j) = \int_{u_i}^{u_{i+1}}\int_{v_j}^{v_{j+1}}dA. \end{equation} To derive $dA$ I used the first fundamental form , $dA = \sqrt{EG-F^2}du\,dv$. An example of its application to an ellipsoid can be found in this answer, though note that (1) $dA$ is merged with the integrand and (2) $u$ and $v$ are switched from here. Here is what I obtain: $$ dA = \sqrt{a^2b^2 \cos^2 v \sin^2 v + c^2 \sin^4v\ (b^2 \cos^2 u + a^2 \sin^2 u)}\ \ du\,dv, $$ where $a,b,c$ are the semi-major axes associated with $x,y,z$ respectively. I am almost certain that with this expression for $dA$, the integral for $\Delta A(u_i, v_j)$ above cannot be evaluated analytically. Do I need to resort to a numerical approximation of $\Delta A(u_i, v_j)$? If so, in light of the simplistic approximation of the original integral, will it be sufficient to use the area of the trapezoid formed by connecting the image of the four points $(u_i, v_j), (u_{i+1}, v_j), (u_{i}, v_{j+1}), (u_{i+1}, v_{j+1})$ in $\mathbb{R}^3$?","I would like to evaluate an integral numerically over the surface of an ellipsoid. Take an $N \times N$ grid over the parameter space $(u, v) \in [0, 2\pi) \times [0, \pi) $. A simple approximation of the integral is $$ \int_0^{2\pi}\int_0^\pi \mathbf{f}(u,v)\,dA \simeq \sum_{i,j=1}^N \mathbf{f}(u_i,v_j)\, \Delta A(u_i,v_j) $$ where $\Delta A(u_i, v_j)$ is the surface area of the portion of the ellipsoid spanned by the parameter region $(u_i, u_{i+1}) \times (v_j, v_{j+1})$. I had hoped to compute $\Delta A(u_i, v_j)$ analytically: \begin{equation} \Delta A(u_i, v_j) = \int_{u_i}^{u_{i+1}}\int_{v_j}^{v_{j+1}}dA. \end{equation} To derive $dA$ I used the first fundamental form , $dA = \sqrt{EG-F^2}du\,dv$. An example of its application to an ellipsoid can be found in this answer, though note that (1) $dA$ is merged with the integrand and (2) $u$ and $v$ are switched from here. Here is what I obtain: $$ dA = \sqrt{a^2b^2 \cos^2 v \sin^2 v + c^2 \sin^4v\ (b^2 \cos^2 u + a^2 \sin^2 u)}\ \ du\,dv, $$ where $a,b,c$ are the semi-major axes associated with $x,y,z$ respectively. I am almost certain that with this expression for $dA$, the integral for $\Delta A(u_i, v_j)$ above cannot be evaluated analytically. Do I need to resort to a numerical approximation of $\Delta A(u_i, v_j)$? If so, in light of the simplistic approximation of the original integral, will it be sufficient to use the area of the trapezoid formed by connecting the image of the four points $(u_i, v_j), (u_{i+1}, v_j), (u_{i}, v_{j+1}), (u_{i+1}, v_{j+1})$ in $\mathbb{R}^3$?",,"['differential-geometry', 'numerical-methods', 'surfaces']"
65,Bounded vector field has globally defined flow,Bounded vector field has globally defined flow,,"Let $X$ be a vector field on $\mathbb R^n$, and suppose that $\|X\|$ is bounded, where the norm is taken with respect to the Euclidean inner product. I am trying to show that $X$ has globally defined flow. To prove this, it will suffice to find some $\epsilon > 0$, independent of $x \in \mathbb R^n$, such that the flow of $X$ can be defined on $(-\epsilon , \epsilon)$ for each $x\in \mathbb R^n$. But, I can't seem to get such an $\epsilon$ just from the boundedness hypothesis. Is there a simple proof of this fact?","Let $X$ be a vector field on $\mathbb R^n$, and suppose that $\|X\|$ is bounded, where the norm is taken with respect to the Euclidean inner product. I am trying to show that $X$ has globally defined flow. To prove this, it will suffice to find some $\epsilon > 0$, independent of $x \in \mathbb R^n$, such that the flow of $X$ can be defined on $(-\epsilon , \epsilon)$ for each $x\in \mathbb R^n$. But, I can't seem to get such an $\epsilon$ just from the boundedness hypothesis. Is there a simple proof of this fact?",,"['differential-geometry', 'partial-differential-equations', 'differential-topology']"
66,Is Whitney sum of vector bundle a categorical colimit?,Is Whitney sum of vector bundle a categorical colimit?,,"We known that the direct sum of two vector spaces is the categorical colimit of vector spaces. My question is whether Whitney sum of vector bundle is a categorical colimit (in the category of vector bundles over a fixed $B$ and bundle maps fix $B$ too)? This may be too easy, just give me quick answer or reference.","We known that the direct sum of two vector spaces is the categorical colimit of vector spaces. My question is whether Whitney sum of vector bundle is a categorical colimit (in the category of vector bundles over a fixed $B$ and bundle maps fix $B$ too)? This may be too easy, just give me quick answer or reference.",,"['differential-geometry', 'vector-bundles']"
67,Generally covariant Klein-Gordon equation,Generally covariant Klein-Gordon equation,,"Consider a 4-dimensional smooth manifold $M$ on which there is a Lorentzian metric $g_{ab}$ and a function $\phi$ satisfying the following two equations (in abstract index notation): \begin{equation} g^{ab}\nabla_{a}\nabla_{b}\phi - m^{2}\phi = 0, \qquad R_{abcd} = 0. \end{equation} I've been told that the covariance group of these equations is $\mathrm{Diff}(M)$, but I am having a hard time seeing it for myself.  From what I understand, this means that for any $\psi \in \mathrm{Diff}(M)$, $\psi^{*}\phi$ (and $\psi^{*}g_{ab}$?) is a solution of these equations just if $\phi$ (and $g_{ab}$?) is.  It's straightforward that $\psi^{*}R_{abcd} = 0$, but I am having a hard time showing that $\psi^{*}(g^{ab}\nabla_{a}\nabla_{b}\phi) = g^{ab}\nabla_{a}\nabla_{b}(\psi^{*}\phi)$.  Is this true?  If so, how would I go about showing that?","Consider a 4-dimensional smooth manifold $M$ on which there is a Lorentzian metric $g_{ab}$ and a function $\phi$ satisfying the following two equations (in abstract index notation): \begin{equation} g^{ab}\nabla_{a}\nabla_{b}\phi - m^{2}\phi = 0, \qquad R_{abcd} = 0. \end{equation} I've been told that the covariance group of these equations is $\mathrm{Diff}(M)$, but I am having a hard time seeing it for myself.  From what I understand, this means that for any $\psi \in \mathrm{Diff}(M)$, $\psi^{*}\phi$ (and $\psi^{*}g_{ab}$?) is a solution of these equations just if $\phi$ (and $g_{ab}$?) is.  It's straightforward that $\psi^{*}R_{abcd} = 0$, but I am having a hard time showing that $\psi^{*}(g^{ab}\nabla_{a}\nabla_{b}\phi) = g^{ab}\nabla_{a}\nabla_{b}(\psi^{*}\phi)$.  Is this true?  If so, how would I go about showing that?",,"['differential-geometry', 'physics']"
68,Quotient theorem for tensors,Quotient theorem for tensors,,"Can somebody please explain to me how the following statement is true? The Riemann curvature tensor $R^c_{dab}$ is given by the Ricci identity $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V^c\equiv R^c_{dab}V^d$$ where $\nabla_a$ denotes the covariant derivative. It is linear in $V^c$, hence may be shown by the Quotient theorem to be a tensor. Now, I can see that the $R^c_{dab}$ is a tensor by construction -- based on the LHS of the Ricci identity. However, I don't understand how the linearity in $V^d$ comes to play. Also, it is  given that for covectors, the Ricci identity takes the form $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c\equiv -R^d_{cab}V_d$$ How does this follow from the Ricci identity for (contravariant) vectors? If I write $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c=(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)$$ and in GR, the Levi-Civita connection has that the metric is covariantly constant, we have  $$(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)=g_{cd}(\nabla_a\nabla_b-\nabla_b\nabla_a)V^d\\=g_{cd}R^d_{eab}V^e=R_{ceab}V^e=R^d_{cab}V_d$$   Where has my minus sign gone? I have read that you can  the Ricci identity for covectors by arguing using the fact that the Levi-Civita connection is symmetric, but I don't know how they mean. Thanks in advance for any help!","Can somebody please explain to me how the following statement is true? The Riemann curvature tensor $R^c_{dab}$ is given by the Ricci identity $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V^c\equiv R^c_{dab}V^d$$ where $\nabla_a$ denotes the covariant derivative. It is linear in $V^c$, hence may be shown by the Quotient theorem to be a tensor. Now, I can see that the $R^c_{dab}$ is a tensor by construction -- based on the LHS of the Ricci identity. However, I don't understand how the linearity in $V^d$ comes to play. Also, it is  given that for covectors, the Ricci identity takes the form $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c\equiv -R^d_{cab}V_d$$ How does this follow from the Ricci identity for (contravariant) vectors? If I write $$(\nabla_a\nabla_b-\nabla_b\nabla_a)V_c=(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)$$ and in GR, the Levi-Civita connection has that the metric is covariantly constant, we have  $$(\nabla_a\nabla_b-\nabla_b\nabla_a)(g_{cd}V^d)=g_{cd}(\nabla_a\nabla_b-\nabla_b\nabla_a)V^d\\=g_{cd}R^d_{eab}V^e=R_{ceab}V^e=R^d_{cab}V_d$$   Where has my minus sign gone? I have read that you can  the Ricci identity for covectors by arguing using the fact that the Levi-Civita connection is symmetric, but I don't know how they mean. Thanks in advance for any help!",,"['differential-geometry', 'riemannian-geometry', 'tensors']"
69,Diffeomorphisms to $S^n$,Diffeomorphisms to,S^n,Is $S^4$ diffeomorfhic to $S^2\times S^2$? Moreover. Is $S^n$ diffeomorphic to some cross product of manifolds $X\times Y$ for $n\geq2$? Is there a elemental topological invariant to let me see this? Any suggestions are welcome! thanks,Is $S^4$ diffeomorfhic to $S^2\times S^2$? Moreover. Is $S^n$ diffeomorphic to some cross product of manifolds $X\times Y$ for $n\geq2$? Is there a elemental topological invariant to let me see this? Any suggestions are welcome! thanks,,['differential-geometry']
70,What is a tangent bundle? (Aubin),What is a tangent bundle? (Aubin),,"Here's what I read in A Course in Differential Geometry by Thierry Aubin. 2.5. Definition. The tangent bundle $T(M)$ is $\bigcup_{P\in M} T_P(M).$ And then 2.6. Definition. Let $\Phi$ be a differentiable map of $M_n$ into $W_p$ (two differentiable manifolds). Let $P\in M_n,$ and set $Q=\Phi(P).$ The map $\Phi$ induces a linear map $(\Phi_*)_P$ of the tangent bundle $T_P(M)$ into $T_Q(W)$ defined by $$[(\Phi_*)_PX](f)=X(f\circ\Phi);$$ here $X\in T_P(M),\;(\Phi_*)_PX\in T_Q(W)$ and $f$ is a differentiable function in a neighbourhood $\theta$ of $Q.$ We call $(\Phi_*)_P$ the linear tangent mapping of $\Phi$ at $P.$ I don't understand why the author calls $T_P(M)$ a tangent bundle in the second definition. Is it a mistake? From the first definition, a tangent bundle is the union of all tangent spaces over all points of the manifold. And $T_P(M)$ is just one tangent space, at a particular point $P$ . And an additional question: Should I be worried whether the union in the first definition is disjoint or not? After a moment's thought, I believe it might turn out not to be according to the previous definitions.","Here's what I read in A Course in Differential Geometry by Thierry Aubin. 2.5. Definition. The tangent bundle is And then 2.6. Definition. Let be a differentiable map of into (two differentiable manifolds). Let and set The map induces a linear map of the tangent bundle into defined by here and is a differentiable function in a neighbourhood of We call the linear tangent mapping of at I don't understand why the author calls a tangent bundle in the second definition. Is it a mistake? From the first definition, a tangent bundle is the union of all tangent spaces over all points of the manifold. And is just one tangent space, at a particular point . And an additional question: Should I be worried whether the union in the first definition is disjoint or not? After a moment's thought, I believe it might turn out not to be according to the previous definitions.","T(M) \bigcup_{P\in M} T_P(M). \Phi M_n W_p P\in M_n, Q=\Phi(P). \Phi (\Phi_*)_P T_P(M) T_Q(W) [(\Phi_*)_PX](f)=X(f\circ\Phi); X\in T_P(M),\;(\Phi_*)_PX\in T_Q(W) f \theta Q. (\Phi_*)_P \Phi P. T_P(M) T_P(M) P","['differential-geometry', 'definition', 'vector-bundles']"
71,"What is ment by: ""parallel transport preserves orientation""?","What is ment by: ""parallel transport preserves orientation""?",,In my text its written that parallel transport on a Riemannian manifold preserves orientation. Can someone clarify what does that mean? I am confused about this notion.,In my text its written that parallel transport on a Riemannian manifold preserves orientation. Can someone clarify what does that mean? I am confused about this notion.,,"['differential-geometry', 'riemannian-geometry']"
72,condition for compatible connection on a Riemannian manifold,condition for compatible connection on a Riemannian manifold,,"Prove that connection $\nabla $ on a Riemannian manifold $M$ is compatible with metric iff $$Xg(Y,Z)=g(\nabla_XY,Z)+g(Y,\nabla_XZ),$$ for every smooth vector fields $X,Y,Z$. I am confused about how to prove compatibility from this equation. Any help is appreciated it. By my text it should be obvious (Do Carmo).","Prove that connection $\nabla $ on a Riemannian manifold $M$ is compatible with metric iff $$Xg(Y,Z)=g(\nabla_XY,Z)+g(Y,\nabla_XZ),$$ for every smooth vector fields $X,Y,Z$. I am confused about how to prove compatibility from this equation. Any help is appreciated it. By my text it should be obvious (Do Carmo).",,"['differential-geometry', 'riemannian-geometry']"
73,The cone is not immersed in $\mathbb{R}^3$,The cone is not immersed in,\mathbb{R}^3,The problem is to show that the cone $ z^2= x^2+y^2$  is not an immersed smooth manifold in $\mathbb{R}^3$.,The problem is to show that the cone $ z^2= x^2+y^2$  is not an immersed smooth manifold in $\mathbb{R}^3$.,,"['differential-geometry', 'differential-topology']"
74,The differentiability of distance function,The differentiability of distance function,,"Let $M$ be a submanifold of $\mathbb R^n$, then is there an open set $\Omega$ in $\mathbb R^n$ such that function $d(x,M)$ (distance function) is smooth on $\Omega$?","Let $M$ be a submanifold of $\mathbb R^n$, then is there an open set $\Omega$ in $\mathbb R^n$ such that function $d(x,M)$ (distance function) is smooth on $\Omega$?",,['differential-geometry']
75,Principal directions,Principal directions,,"Consider a catenoid $C$ parametrized by $$r(u,v)= (u, \cosh u \cos v, \cosh u \sin v), u\in \mathbb{R}, v\in(-\pi, \pi)$$ I am required to show that the principal directions are the same as the coordiante curves, u= constant, v=constant. The formula I want to use is $$dN_p (v)=\lambda v$$ for $v$ in the tangent space to $C$ at $p$. I have found the the differential of the Gauss map($N$) by using  $$N= \frac{r_u\times r_v}{|r_u\times r_v|}$$ But once I start calculating the differential of $N$, things get messy. Am I on the right track? Is there a better way to find the principal directions? Thanks in advance.","Consider a catenoid $C$ parametrized by $$r(u,v)= (u, \cosh u \cos v, \cosh u \sin v), u\in \mathbb{R}, v\in(-\pi, \pi)$$ I am required to show that the principal directions are the same as the coordiante curves, u= constant, v=constant. The formula I want to use is $$dN_p (v)=\lambda v$$ for $v$ in the tangent space to $C$ at $p$. I have found the the differential of the Gauss map($N$) by using  $$N= \frac{r_u\times r_v}{|r_u\times r_v|}$$ But once I start calculating the differential of $N$, things get messy. Am I on the right track? Is there a better way to find the principal directions? Thanks in advance.",,['differential-geometry']
76,"Computing $d\omega$ and $g^\ast \omega$ when $(x,y)=g(s,t)=(st,e^t)$ and $\omega= xdy$",Computing  and  when  and,"d\omega g^\ast \omega (x,y)=g(s,t)=(st,e^t) \omega= xdy","Define $g:\mathbb{R^2} \rightarrow \mathbb{R^2}$ by $(x,y)=g(s,t)=(st,e^t)$ and let $\omega= xdy$. How can I compute $d\omega$ and $g^\ast \omega$? Actually, I computed $d\omega =tds \wedge e^tdt$. (Is this true?) However I am confused about the pullback map.","Define $g:\mathbb{R^2} \rightarrow \mathbb{R^2}$ by $(x,y)=g(s,t)=(st,e^t)$ and let $\omega= xdy$. How can I compute $d\omega$ and $g^\ast \omega$? Actually, I computed $d\omega =tds \wedge e^tdt$. (Is this true?) However I am confused about the pullback map.",,"['differential-geometry', 'differential-forms']"
77,Parametric Equations for a Hypercone,Parametric Equations for a Hypercone,,"The n-dimensional cone, with vertex at the origin, central angle, $\alpha$ and central axis in the direction of the unit vector $\xi$ is defined to be all those points, $x\in {R^n}$ whose dot product with $\xi$ is |$x$|$cos(\alpha)$.  How would I find parametric equations for this surface?","The n-dimensional cone, with vertex at the origin, central angle, $\alpha$ and central axis in the direction of the unit vector $\xi$ is defined to be all those points, $x\in {R^n}$ whose dot product with $\xi$ is |$x$|$cos(\alpha)$.  How would I find parametric equations for this surface?",,"['differential-geometry', 'parametric']"
78,Differential and Riemannian structure on the cone,Differential and Riemannian structure on the cone,,"I think the cone (or what is also called the ""half cone"") is a differential manifold but not a smooth manifold. Can anyone help me understand this the nuts and bolts way? How explicitly can I write down the differential structure on the cone? Also what is the natural metric on it? (Is that what is called the ""Sasakian Metric""? If yes then can one kindly explain that or give an expository reference on this?)","I think the cone (or what is also called the ""half cone"") is a differential manifold but not a smooth manifold. Can anyone help me understand this the nuts and bolts way? How explicitly can I write down the differential structure on the cone? Also what is the natural metric on it? (Is that what is called the ""Sasakian Metric""? If yes then can one kindly explain that or give an expository reference on this?)",,['differential-geometry']
79,Orientation on a Manifold,Orientation on a Manifold,,Let M  be an (n-1)-manifold in R^n . Let M(e)  be the set of end-points of normal vectors (in both directions) of length e  and suppose e  is small enough so that M(e) is also an (n-1)-manifold. Show that M(e)  is orientable (even if M  is not),Let M  be an (n-1)-manifold in R^n . Let M(e)  be the set of end-points of normal vectors (in both directions) of length e  and suppose e  is small enough so that M(e) is also an (n-1)-manifold. Show that M(e)  is orientable (even if M  is not),,['differential-geometry']
80,Differential Geometry of Curves and Surfaces from Riemannian Geometry,Differential Geometry of Curves and Surfaces from Riemannian Geometry,,"I'm a relativist. Hence, I have a working knowledge of Riemannian geometry, but I never really studied differential geometry of curves and surfaces. I know the traditional path is to start with curves and surfaces and then go to smooth manifolds, Riemannian geometry and etc, but I would like to know if there are any references that work backwards. Namely, I'd like a reference that defines concepts such as Gaussian and geodesic curvature using the tools from Riemannian geometry and use this language to discuss, for example, Gauss' Theorema egregium and the Gauss–Bonnet theorem (especially if they have generalizations to higher dimensions). Are there any such references?","I'm a relativist. Hence, I have a working knowledge of Riemannian geometry, but I never really studied differential geometry of curves and surfaces. I know the traditional path is to start with curves and surfaces and then go to smooth manifolds, Riemannian geometry and etc, but I would like to know if there are any references that work backwards. Namely, I'd like a reference that defines concepts such as Gaussian and geodesic curvature using the tools from Riemannian geometry and use this language to discuss, for example, Gauss' Theorema egregium and the Gauss–Bonnet theorem (especially if they have generalizations to higher dimensions). Are there any such references?",,"['differential-geometry', 'riemannian-geometry', 'curves', 'surfaces']"
81,Smoothness of horizontal bundle defined by connection one-form,Smoothness of horizontal bundle defined by connection one-form,,"Let $G$ denote a Lie group and $\mathfrak{g}$ its Lie algebra. $P$ is a smooth principal bundle. Given a smooth $\mathfrak{g}$ -valued one-form $\omega_p: TP_p \to \mathfrak{g}$ , which fulfils the properties listed below, is there an easy way to see that $p \mapsto ker(\omega_p) =: H_p$ is smooth? For all $p \in P$ and $X \in \mathfrak{g}$ , $\omega_p(\underline{X}_p) = X$ , where $\underline{X}_p$ denotes the fundamental vector field to $X$ . For all $p \in P$ and $g \in G$ , $$\omega_{p \cdot g} \circ (dR_g)_p = Ad_{g^{-1}} \circ \omega_{p}.$$ Here, $R_g$ denotes the right action of $g$ on P and $Ad_g$ the adjoint representation.","Let denote a Lie group and its Lie algebra. is a smooth principal bundle. Given a smooth -valued one-form , which fulfils the properties listed below, is there an easy way to see that is smooth? For all and , , where denotes the fundamental vector field to . For all and , Here, denotes the right action of on P and the adjoint representation.",G \mathfrak{g} P \mathfrak{g} \omega_p: TP_p \to \mathfrak{g} p \mapsto ker(\omega_p) =: H_p p \in P X \in \mathfrak{g} \omega_p(\underline{X}_p) = X \underline{X}_p X p \in P g \in G \omega_{p \cdot g} \circ (dR_g)_p = Ad_{g^{-1}} \circ \omega_{p}. R_g g Ad_g,"['differential-geometry', 'lie-groups', 'connections', 'principal-bundles']"
82,Which is the correct definition of covectors?,Which is the correct definition of covectors?,,"Some says covectors are linear map that maps $ V \mapsto R $ (which means it's just a row vector considering vectors are $ n $ x $ 1 $ matrix and mapping is matrix multiplication), while some say it's a certain value whose components follow $ v'_i = \frac{\partial x^j}{\partial x'^i} v_j $ under coordinate transformation from $ x $ coordinate to $ x' $ coordinate. Let's see gradient for example. $ \nabla $ itself is not a map $ \nabla : V \mapsto R $ , but divergence, $ \nabla \cdot $ is. So $ \nabla $ is not a covector of first definition. However, considering $ \nabla $ 's components are $ \frac{\partial}{\partial x^i} $ , they actually follow the transformation rule by $ \frac{\partial x^i}{\partial x'^j} \frac{\partial}{\partial x^i} = \frac{\partial}{\partial x'^j} $ . So it's a covector of the second example. Which one's right? Are they actually the same definition and I'm misunderstanding something or are they just different things I'm talking about?","Some says covectors are linear map that maps (which means it's just a row vector considering vectors are x matrix and mapping is matrix multiplication), while some say it's a certain value whose components follow under coordinate transformation from coordinate to coordinate. Let's see gradient for example. itself is not a map , but divergence, is. So is not a covector of first definition. However, considering 's components are , they actually follow the transformation rule by . So it's a covector of the second example. Which one's right? Are they actually the same definition and I'm misunderstanding something or are they just different things I'm talking about?", V \mapsto R   n   1   v'_i = \frac{\partial x^j}{\partial x'^i} v_j   x   x'   \nabla   \nabla : V \mapsto R   \nabla \cdot   \nabla   \nabla   \frac{\partial}{\partial x^i}   \frac{\partial x^i}{\partial x'^j} \frac{\partial}{\partial x^i} = \frac{\partial}{\partial x'^j} ,"['differential-geometry', 'vectors', 'definition', 'tensors', 'covariance']"
83,Compute the Lie derivative for $X=y \frac{\partial}{\partial x}$ and $Y=x \frac{\partial}{\partial y}$,Compute the Lie derivative for  and,X=y \frac{\partial}{\partial x} Y=x \frac{\partial}{\partial y},"Question : On $\mathbf{R}^2$ , let $X=y \frac{\partial}{\partial x}$ and let $Y=x \frac{\partial}{\partial y}$ , with corresponding flows given by $\phi_t(x, y)=(x+t y, y)$ and $\psi_t(x, y)=(x, y+t x)$ . Then show that the Lie derivative, $\mathcal L_XY=-x\frac{\partial}{\partial x}+y\frac{\partial}{\partial y}$ The definition given in the book, Definition 4.7.1. Let $T$ be a tensor field of type $(r, s)$ on $\mathbf{R}^n$ and let $X$ be a vector field with flow $\phi_t: \mathbf{R}^n \rightarrow \mathbf{R}^n$ . The Lie derivative of $T$ with respect to $X$ , denoted by $\mathcal{L}_X T$ , is the $(r, s)$ -tensor defined as $$ \mathcal{L}_X T=\left.\frac{d}{d t}\right|_{t=0}\left(\phi_t^* T\right) . $$ But when we have a ambient space like for this example then do we need the flow to define the Lie derivative? Inspired from this M.SE answer , I give a try below: $$ \begin{align} \mathcal L_XY&=\mathcal L_X\left(x\frac{\partial}{\partial y}\right)\\ &=[\mathcal L_X(x)]\frac{\partial}{\partial y}+x[\mathcal L_X\left(\frac{\partial}{\partial y}\right)]\\ &=[y\frac{\partial}{\partial x}(x)]\frac{\partial}{\partial y}+x[y\frac{\partial}{\partial x}\left(\frac{\partial}{\partial y}\right)]\\ &=y\frac{\partial}{\partial y}+? \end{align} $$ but here I guess $\mathcal L_X(\frac{\partial}{\partial y})$ doesn't make sense! Or I am not expert enough to guess the meaning.","Question : On , let and let , with corresponding flows given by and . Then show that the Lie derivative, The definition given in the book, Definition 4.7.1. Let be a tensor field of type on and let be a vector field with flow . The Lie derivative of with respect to , denoted by , is the -tensor defined as But when we have a ambient space like for this example then do we need the flow to define the Lie derivative? Inspired from this M.SE answer , I give a try below: but here I guess doesn't make sense! Or I am not expert enough to guess the meaning.","\mathbf{R}^2 X=y \frac{\partial}{\partial x} Y=x \frac{\partial}{\partial y} \phi_t(x, y)=(x+t y, y) \psi_t(x, y)=(x, y+t x) \mathcal L_XY=-x\frac{\partial}{\partial x}+y\frac{\partial}{\partial y} T (r, s) \mathbf{R}^n X \phi_t: \mathbf{R}^n \rightarrow \mathbf{R}^n T X \mathcal{L}_X T (r, s) 
\mathcal{L}_X T=\left.\frac{d}{d t}\right|_{t=0}\left(\phi_t^* T\right) .
 
\begin{align}
\mathcal L_XY&=\mathcal L_X\left(x\frac{\partial}{\partial y}\right)\\
&=[\mathcal L_X(x)]\frac{\partial}{\partial y}+x[\mathcal L_X\left(\frac{\partial}{\partial y}\right)]\\
&=[y\frac{\partial}{\partial x}(x)]\frac{\partial}{\partial y}+x[y\frac{\partial}{\partial x}\left(\frac{\partial}{\partial y}\right)]\\
&=y\frac{\partial}{\partial y}+?
\end{align}
 \mathcal L_X(\frac{\partial}{\partial y})","['differential-geometry', 'lie-derivative']"
84,Is there any relation between an Ehresmann connection/connection 1-form and an affine connection?,Is there any relation between an Ehresmann connection/connection 1-form and an affine connection?,,"We can define a connection 1-form which picks out the vertical part of any vector in the tangent bundle of some principal bundle. This allows us to define parallel transport so that we have a way to connect nearby fibers. As a map, it maps vectors in the tangent bundle to the Lie algebra associated with the Lie group of the principal bundle In contrast, an affine connection is defined for any manifold and maps the cartesian product of two vector fields to another vector field. I am confused on the relationship between these two kinds of connections. On one hand they both capture a similar idea of connecting nearby fibers to each other, but as maps they seem completely different with one have values in the space of vector fields and the other having values in a Lie algebra. Furthermore affine connections seem to have nothing to do with horizontal or vertical tangent spaces, which seem to be at the heart of connection 1-forms/Ehresmann connections. Is there any relationship between these two objects? I took a look at some older posts, such as the one below, but I am still confused. Levi-Civita connection as an Ehresmann connection","We can define a connection 1-form which picks out the vertical part of any vector in the tangent bundle of some principal bundle. This allows us to define parallel transport so that we have a way to connect nearby fibers. As a map, it maps vectors in the tangent bundle to the Lie algebra associated with the Lie group of the principal bundle In contrast, an affine connection is defined for any manifold and maps the cartesian product of two vector fields to another vector field. I am confused on the relationship between these two kinds of connections. On one hand they both capture a similar idea of connecting nearby fibers to each other, but as maps they seem completely different with one have values in the space of vector fields and the other having values in a Lie algebra. Furthermore affine connections seem to have nothing to do with horizontal or vertical tangent spaces, which seem to be at the heart of connection 1-forms/Ehresmann connections. Is there any relationship between these two objects? I took a look at some older posts, such as the one below, but I am still confused. Levi-Civita connection as an Ehresmann connection",,"['differential-geometry', 'fiber-bundles', 'connections', 'principal-bundles']"
85,Interpretation of Ricci and Scalar curvature.,Interpretation of Ricci and Scalar curvature.,,"Let $(M,g)$ be a SR-manifold and for $p \in M$ , let $\{e_1,\ldots,e_n\}$ be a pseudo-orthonormal basis for $T_pM$ . Now, in my notes, it says that, if $v \in T_pM$ is such that $g(v,v) \neq 0$ and $$\{e_2,\ldots,e_n\}$$ is an orthonormal basis of $v^{\perp}$ then $$\operatorname{Ric}(v,v) = g(v,v) \sum_{i = 2}^{n} K(v,e_i)$$ where $K(-,-)$ is the sectional curvature of non-degenerate two-planes at $p \in M$ . Then it says that from this, we can interpret $\operatorname{Ric}(v,v)$ as the ”mean” of all sectional curvatures of two-planes containing $v$ . Now, for the scalar curvature $\operatorname{scal} = \operatorname{tr}_g(\operatorname{Ric}) \in C^{\infty}(M)$ we have $$\operatorname{scal}(p) = \sum_{i,j = 1}^{n} \epsilon_i \epsilon_j R(e_j,e_i,e_i,e_j) = \sum_{\substack{i,j = 1, \\ i \neq j}}^{n} \epsilon_i \epsilon_j K(e_i,e_j)(\underbrace{g(e_i,e_i)}_{=\epsilon_i}\underbrace{g(e_j,e_j)}_{=\epsilon_j}-\underbrace{g(e_i,e_j)}_{= 0}) = \sum_{i \neq j} K(e_i,e_j)$$ so that $\operatorname{scal}(p)$ is the ”mean” over all $i \neq j$ sectional curvatures of non-degenerate two-planes. My question is this: In what sense are these two descriptions ”means”? My mind is naturally drawn to the arithmetic mean, but there are of course other means, and I am not sure there is a mathematical definition of mean independent of the specific mean one is referring to, but since we don’t divide by something, it can’t be the arithmetic mean, I presume. Any thoughts on in which sense these are means? And for the scalar curvature, I presume they must mean all non-degenerate two-planes spanned by the basis vectors? Because could there not potentially be other two-planes?","Let be a SR-manifold and for , let be a pseudo-orthonormal basis for . Now, in my notes, it says that, if is such that and is an orthonormal basis of then where is the sectional curvature of non-degenerate two-planes at . Then it says that from this, we can interpret as the ”mean” of all sectional curvatures of two-planes containing . Now, for the scalar curvature we have so that is the ”mean” over all sectional curvatures of non-degenerate two-planes. My question is this: In what sense are these two descriptions ”means”? My mind is naturally drawn to the arithmetic mean, but there are of course other means, and I am not sure there is a mathematical definition of mean independent of the specific mean one is referring to, but since we don’t divide by something, it can’t be the arithmetic mean, I presume. Any thoughts on in which sense these are means? And for the scalar curvature, I presume they must mean all non-degenerate two-planes spanned by the basis vectors? Because could there not potentially be other two-planes?","(M,g) p \in M \{e_1,\ldots,e_n\} T_pM v \in T_pM g(v,v) \neq 0 \{e_2,\ldots,e_n\} v^{\perp} \operatorname{Ric}(v,v) = g(v,v) \sum_{i = 2}^{n} K(v,e_i) K(-,-) p \in M \operatorname{Ric}(v,v) v \operatorname{scal} = \operatorname{tr}_g(\operatorname{Ric}) \in C^{\infty}(M) \operatorname{scal}(p) = \sum_{i,j = 1}^{n} \epsilon_i \epsilon_j R(e_j,e_i,e_i,e_j) = \sum_{\substack{i,j = 1, \\ i \neq j}}^{n} \epsilon_i \epsilon_j K(e_i,e_j)(\underbrace{g(e_i,e_i)}_{=\epsilon_i}\underbrace{g(e_j,e_j)}_{=\epsilon_j}-\underbrace{g(e_i,e_j)}_{= 0}) = \sum_{i \neq j} K(e_i,e_j) \operatorname{scal}(p) i \neq j","['differential-geometry', 'riemannian-geometry']"
86,Is a stationary point for length functional automatically a local minimum?,Is a stationary point for length functional automatically a local minimum?,,"Given a Lagrangian $L:TM \rightarrow \mathbb{R}$ defined on a tangent bundle, Hamilton's principle states that a curve $\gamma:[a,b] \rightarrow M$ is a stationary point of the action functional $S[\gamma]:=\int_a^b L(\gamma(t),\gamma'(t)) dt$ among variations with fixed endpoints iff the Euler-Lagrange equations $\frac{d}{dt}\left(\frac{\partial L}{\partial q'} \right) - \frac{\partial L}{\partial q} = 0$ are satisfied. Now we consider the Lagrangian given by $L(q,q')= \sqrt{g(q',q')}$ , that is the length of a tangent vector. Then the action functional becomes arc length. The Euler-Lagrange equations then become the geodesic equations. My question is the following: Is a stationary point of the length functional $S_l[\gamma]:=\int_a^b\sqrt{(g(\gamma'(t), \gamma'(t)))} dt$ automatically a local minimum for this length functional $S_l$ among all variations with fixed endpoints? In other words, if $\gamma$ is a stationary point of $S_l$ (equivalently, if it satisfies the Euler-Lagrange equation, that is in this case the geodesic equations) is it then true that for any variation $f:(-\epsilon, \epsilon) \times [a,b] \rightarrow M$ of $\gamma$ with fixed endpoints (that is $f(0,t)=\gamma(t)$ for all $t \in [a,b]$ and $f(s,a)=\gamma(a)$ and $f(s,b) = \gamma(b)$ for all $s \in ( -\epsilon, \epsilon)$ ) we have that for all small enough $s$ $$S_l(f(s, \cdot))= \int_a^b \sqrt{g \left(\frac{\partial f}{\partial t}(s,t)),\frac{\partial f}{\partial t}(s,t) \right)} dt \geq S_l(f(0, \cdot))=S_l[\gamma] \ \ \ ?$$ (This is different from the fact that a geodesic is not necessarily a global minimum of the length functional among all admissible path connecting two given points. And it is different from the property of geodesics to be length-minimizing within a geodesic ball.)","Given a Lagrangian defined on a tangent bundle, Hamilton's principle states that a curve is a stationary point of the action functional among variations with fixed endpoints iff the Euler-Lagrange equations are satisfied. Now we consider the Lagrangian given by , that is the length of a tangent vector. Then the action functional becomes arc length. The Euler-Lagrange equations then become the geodesic equations. My question is the following: Is a stationary point of the length functional automatically a local minimum for this length functional among all variations with fixed endpoints? In other words, if is a stationary point of (equivalently, if it satisfies the Euler-Lagrange equation, that is in this case the geodesic equations) is it then true that for any variation of with fixed endpoints (that is for all and and for all ) we have that for all small enough (This is different from the fact that a geodesic is not necessarily a global minimum of the length functional among all admissible path connecting two given points. And it is different from the property of geodesics to be length-minimizing within a geodesic ball.)","L:TM \rightarrow \mathbb{R} \gamma:[a,b] \rightarrow M S[\gamma]:=\int_a^b L(\gamma(t),\gamma'(t)) dt \frac{d}{dt}\left(\frac{\partial L}{\partial q'} \right) - \frac{\partial L}{\partial q} = 0 L(q,q')= \sqrt{g(q',q')} S_l[\gamma]:=\int_a^b\sqrt{(g(\gamma'(t), \gamma'(t)))} dt S_l \gamma S_l f:(-\epsilon, \epsilon) \times [a,b] \rightarrow M \gamma f(0,t)=\gamma(t) t \in [a,b] f(s,a)=\gamma(a) f(s,b) = \gamma(b) s \in ( -\epsilon, \epsilon) s S_l(f(s, \cdot))= \int_a^b \sqrt{g \left(\frac{\partial f}{\partial t}(s,t)),\frac{\partial f}{\partial t}(s,t) \right)} dt \geq S_l(f(0, \cdot))=S_l[\gamma] \ \ \ ?","['differential-geometry', 'riemannian-geometry', 'calculus-of-variations', 'geodesic']"
87,Trivial principal bundles and curvature.,Trivial principal bundles and curvature.,,"Let $\mathcal{M}$ be a smooth manifold, $G$ a Lie group with Lie algebra $\mathfrak{g}$ and $\mathcal{P}\xrightarrow{\pi}\mathcal{M}$ a principal bundle. If $A\in\Omega^{1}(\mathcal{P},\mathfrak{g})$ is a connection form, we can define its curvature $F^{A}\in\Omega^{2}(\mathcal{P},\mathfrak{g})$ . Now, it is a general fact that, since $F^{A}$ is ""horizontal and of type Ad'', it can be identified with an element $F^{A}_{\mathcal{M}}\in\Omega^{2}(\mathcal{M},\mathrm{Ad}(\mathcal{P}))$ , where $\mathrm{Ad}(\mathcal{P}):=\mathcal{P}\times_{\mathrm{Ad}}\mathfrak{g}$ denotes the adjoint bundle. Now, let us assume that $\mathcal{P}$ is the trivial $G$ -bundle, i.e. $\mathcal{P}\cong\mathcal{M}\times G$ . As a consequence, also the adjoint bundle is the trivial vector bundle, i.e. $\mathrm{Ad}(\mathcal{P})\cong\mathcal{M}\times\mathfrak{g}$ (correct me if I am wrong). In particular, this implies that $F_{\mathcal{M}}^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g})$ . Now, since $\mathcal{P}$ is trivial, there is a global section $s\in\Gamma^{\infty}(\mathcal{P})$ and we can define $F_{s}:=s^{\ast}F^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g})$ . Is there any relation between $F_{\mathcal{M}}^{A}$ and $F_{s}$ , both of which are elements of $\Omega^{2}(\mathcal{M},\mathfrak{g})$ ? If $G$ is abelian, then the answer is clearly yes, since in this case, one can easily show that $F_{s}$ is independent of the choice of $s$ , by the transformation law of $F^{A}$ under gauge transformations. However, in the non-abelian case, it is not clear.","Let be a smooth manifold, a Lie group with Lie algebra and a principal bundle. If is a connection form, we can define its curvature . Now, it is a general fact that, since is ""horizontal and of type Ad'', it can be identified with an element , where denotes the adjoint bundle. Now, let us assume that is the trivial -bundle, i.e. . As a consequence, also the adjoint bundle is the trivial vector bundle, i.e. (correct me if I am wrong). In particular, this implies that . Now, since is trivial, there is a global section and we can define . Is there any relation between and , both of which are elements of ? If is abelian, then the answer is clearly yes, since in this case, one can easily show that is independent of the choice of , by the transformation law of under gauge transformations. However, in the non-abelian case, it is not clear.","\mathcal{M} G \mathfrak{g} \mathcal{P}\xrightarrow{\pi}\mathcal{M} A\in\Omega^{1}(\mathcal{P},\mathfrak{g}) F^{A}\in\Omega^{2}(\mathcal{P},\mathfrak{g}) F^{A} F^{A}_{\mathcal{M}}\in\Omega^{2}(\mathcal{M},\mathrm{Ad}(\mathcal{P})) \mathrm{Ad}(\mathcal{P}):=\mathcal{P}\times_{\mathrm{Ad}}\mathfrak{g} \mathcal{P} G \mathcal{P}\cong\mathcal{M}\times G \mathrm{Ad}(\mathcal{P})\cong\mathcal{M}\times\mathfrak{g} F_{\mathcal{M}}^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g}) \mathcal{P} s\in\Gamma^{\infty}(\mathcal{P}) F_{s}:=s^{\ast}F^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g}) F_{\mathcal{M}}^{A} F_{s} \Omega^{2}(\mathcal{M},\mathfrak{g}) G F_{s} s F^{A}","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'principal-bundles', 'gauge-theory']"
88,Vector bundle on surface topologically characterized by rank and degree,Vector bundle on surface topologically characterized by rank and degree,,"I have read in some texts (e.g. in https://www.math.uni-duesseldorf.de/~grk2240/pdf/ModuliVectorBundles.pdf ) that complex vector bundles over a compact surface $S$ (usually a Riemann surface) are topologically characterized by their degree and rank. For rank one, i.e. line bundles, this is something I am familiar with. Does anybody have a reference for a proof for rank >1? Another question: what about the smooth structure? Is it uniquely determined by the topology?","I have read in some texts (e.g. in https://www.math.uni-duesseldorf.de/~grk2240/pdf/ModuliVectorBundles.pdf ) that complex vector bundles over a compact surface (usually a Riemann surface) are topologically characterized by their degree and rank. For rank one, i.e. line bundles, this is something I am familiar with. Does anybody have a reference for a proof for rank >1? Another question: what about the smooth structure? Is it uniquely determined by the topology?",S,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'riemann-surfaces']"
89,"Diffeomorphisms of $(-1,1)^n$ sending fixed point to origin",Diffeomorphisms of  sending fixed point to origin,"(-1,1)^n","Consider $I^n\equiv(-1,1)^n:=\{(x_1,\dots,x_n)\in \mathbb{R}^n: |x_i|<1 \ \text{for each} \ 1\leq i\leq n\}.$ Let's fix a point $a=(a_1,\dots,a_n)\in I^n$ . Question: How to construct a $C^1$ -diffeomorphism $\Phi:I^n\to I^n$ such that $\Phi(a)=\vec{0}$ ? I believe it suffices to construct a diffeomorphism $f:I\to I$ such that $f(a)=0$ , where $a$ is some fixed point in $I$ . I tried to come up with some constructions but they did not work out. I know usually one needs to show some efforts but in this case I don't have anything to show.","Consider Let's fix a point . Question: How to construct a -diffeomorphism such that ? I believe it suffices to construct a diffeomorphism such that , where is some fixed point in . I tried to come up with some constructions but they did not work out. I know usually one needs to show some efforts but in this case I don't have anything to show.","I^n\equiv(-1,1)^n:=\{(x_1,\dots,x_n)\in \mathbb{R}^n: |x_i|<1 \ \text{for each} \ 1\leq i\leq n\}. a=(a_1,\dots,a_n)\in I^n C^1 \Phi:I^n\to I^n \Phi(a)=\vec{0} f:I\to I f(a)=0 a I","['real-analysis', 'differential-geometry', 'smooth-manifolds', 'smooth-functions', 'diffeomorphism']"
90,Coclosed form is sum of coexact and harmonic form.,Coclosed form is sum of coexact and harmonic form.,,"Let $(\mathcal{M},g)$ be a compact and connected Riemannian manifold, $\mathrm{d}$ and $\delta$ differential and codifferential, respectively, and $\Delta:=\delta\mathrm{d}+\mathrm{d}\delta$ the corresponding de Rham-Hodge Laplacian. Is it true that $$\mathrm{ker}(\delta)=\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta)$$ Direction "" $\supset$ "" is clear, since $\delta^{2}=0$ and every harmonic form is both closed and coclosed. However, I am struggeling with the other direction. Let $\omega\in\mathrm{ker}(\delta)$ . My idea was to use condradiction: Assume $\omega\notin\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta)$ . Is it possible to argue by Hodge decomposition that then $\omega\in\mathrm{ran}(\mathrm{d})$ ? Because then the claim follows, since $\omega$ would be both closed and coclosed and hence in particular harmonic. EDIT: At least for $1$ -forms, it should be true: Take $A\in\Omega^{1}(\mathcal{M})$ such that $\delta A=0$ . By Hodge decomposition, $A=\mathrm{d}f+\delta F+h$ for $h$ harmonic. Then $\delta A=\Delta f=0$ and hence $f=\mathrm{const}$ , since any harmonic $1$ -form on a compact manifold is necessarily constant. It follows that $A=\delta F+h\in\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta)$ .","Let be a compact and connected Riemannian manifold, and differential and codifferential, respectively, and the corresponding de Rham-Hodge Laplacian. Is it true that Direction "" "" is clear, since and every harmonic form is both closed and coclosed. However, I am struggeling with the other direction. Let . My idea was to use condradiction: Assume . Is it possible to argue by Hodge decomposition that then ? Because then the claim follows, since would be both closed and coclosed and hence in particular harmonic. EDIT: At least for -forms, it should be true: Take such that . By Hodge decomposition, for harmonic. Then and hence , since any harmonic -form on a compact manifold is necessarily constant. It follows that .","(\mathcal{M},g) \mathrm{d} \delta \Delta:=\delta\mathrm{d}+\mathrm{d}\delta \mathrm{ker}(\delta)=\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta) \supset \delta^{2}=0 \omega\in\mathrm{ker}(\delta) \omega\notin\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta) \omega\in\mathrm{ran}(\mathrm{d}) \omega 1 A\in\Omega^{1}(\mathcal{M}) \delta A=0 A=\mathrm{d}f+\delta F+h h \delta A=\Delta f=0 f=\mathrm{const} 1 A=\delta F+h\in\mathrm{ran}(\delta)\oplus\mathrm{ker}(\Delta)","['differential-geometry', 'riemannian-geometry', 'differential-topology', 'hodge-theory']"
91,An analog of Jordan curve theorem for various type of smooth manifolds,An analog of Jordan curve theorem for various type of smooth manifolds,,"I would like to know whether the following tentative generalization of the Jordan curve theorem in higher dimensions and for smooth manifolds are true, and in case I ask for references proving them. Let $M$ be an orientable connected smooth n-manifold ( $n>1$ ) without boundary. Suppose $\iota: X_{n-1}\rightarrow M$ is a compact connected orientable $n-1$ dimensional submanifold. I expect the following to be true: If the map induced in homology $\iota _* : H_{n-1}(X_{n-1})\rightarrow H_{n-1}(M)$ is trivial, then $M-X_{n-1}$ is the disjoint union of two connected n-manifolds $A$ , $B$ such that $\partial A=\partial B= X_{n-1}$ . For this statement I essentially have a proof: since $X_{n-1}$ is trivial in homology $X_{n-1}=\partial A$ , and then I can define $B=M-\overline{\partial A}$ . Is this obvious that $B$ is connected or there might be some subtlety? Furthermore let us assume $M$ to be also compact. Then I expect the converse to be also true: If $M$ is compact, then $M-X_{n-1}$ is the disjoint union of n-manifolds $A$ , $B$ such that $\partial A=\partial B= X_{n-1}$ if and only if $\iota _* : H_{n-1}(X_{n-1})\rightarrow H_{n-1}(M)$ is trivial. Is this statement true? An obvious counterexample to the second statement if we drop compactness is $\mathbb{R}^2-\left\{0\right\}$ .","I would like to know whether the following tentative generalization of the Jordan curve theorem in higher dimensions and for smooth manifolds are true, and in case I ask for references proving them. Let be an orientable connected smooth n-manifold ( ) without boundary. Suppose is a compact connected orientable dimensional submanifold. I expect the following to be true: If the map induced in homology is trivial, then is the disjoint union of two connected n-manifolds , such that . For this statement I essentially have a proof: since is trivial in homology , and then I can define . Is this obvious that is connected or there might be some subtlety? Furthermore let us assume to be also compact. Then I expect the converse to be also true: If is compact, then is the disjoint union of n-manifolds , such that if and only if is trivial. Is this statement true? An obvious counterexample to the second statement if we drop compactness is .",M n>1 \iota: X_{n-1}\rightarrow M n-1 \iota _* : H_{n-1}(X_{n-1})\rightarrow H_{n-1}(M) M-X_{n-1} A B \partial A=\partial B= X_{n-1} X_{n-1} X_{n-1}=\partial A B=M-\overline{\partial A} B M M M-X_{n-1} A B \partial A=\partial B= X_{n-1} \iota _* : H_{n-1}(X_{n-1})\rightarrow H_{n-1}(M) \mathbb{R}^2-\left\{0\right\},"['differential-geometry', 'algebraic-topology', 'differential-topology']"
92,When is a principal bundle with group $G \times H$ the product of a principal bundle with group $G$ and one with group $H$?,When is a principal bundle with group  the product of a principal bundle with group  and one with group ?,G \times H G H,"In general, it is not true that a fiber bundle with a product fiber is the product of two fiber bundles with the factors as fibers (think of vector bundles). However, I read somewhere that every 2-torus bundle is the product of two circle bundles, and I do not know why. So, my question is both why is this true in the torus case and what can we say in the more general case of the product of two Lie groups?","In general, it is not true that a fiber bundle with a product fiber is the product of two fiber bundles with the factors as fibers (think of vector bundles). However, I read somewhere that every 2-torus bundle is the product of two circle bundles, and I do not know why. So, my question is both why is this true in the torus case and what can we say in the more general case of the product of two Lie groups?",,"['differential-geometry', 'lie-groups', 'fiber-bundles', 'principal-bundles', 'gauge-theory']"
93,Dimension of the space of derivations for finitely differentiable manifolds,Dimension of the space of derivations for finitely differentiable manifolds,,"The $C^\infty$ -case: If $M$ is a (paracompact Hausdorff) real $C^\infty$ -manifold and $p \in M$ then the tangent space $T_pM$ can be defined in several different but equivalent ways. One possibility is to define a tangent vector via its action on smooth functions $M \to \mathbb{R}$ and set $T_pM := \mathrm{Der}_p(C_p^\infty(M))$ . Here $C_p^\infty(M)$ is the algebra of germs at $p$ of smooth real valued functions, and $\mathrm{Der}_p(C^\infty(M))$ is the space of derivations of $C_p^\infty(M)$ relative to evaluation at $p$ , i.e. the space linear maps $\varphi: C_p^\infty(M) \to \mathbb{R}$ satisfying $\varphi(fg) = \varphi(f)g(p) + f(p)\varphi(g)$ for $f,g \in C_p^\infty(M)$ . Equivalently one can also use $\mathrm{Der}_p(C^\infty(U))$ for an arbitrary open neighbourhood $U$ of $p$ . To proof the finite-dimensionality of $T_pM$ we can assume without loss of generality that $M=\mathbb{R}^n$ , $p=0$ and that $U$ is a convex set containing $0$ . One can then write down a basis for $T_pM$ , namely the derivations $\frac{\partial}{\partial x^i}|_0$ where $i \in \{1,\ldots,n\}$ . To see that this is a spanning set one first writes any smooth function $g$ on $U$ as $g = g(0) + \sum_i g_ix^i$ , where $g_i(x) = \int_{0}^1\frac{\partial g}{\partial x^i}(tx)dt$ (using the fundamantal theorem of calculus) and then applies a derivation $\varphi$ to obtain $\varphi(g) = \sum_i \varphi(x^i)\frac{\partial}{\partial x^i}|_0(g)$ . For linear independence one evaluates at the coordinate functions $x^i$ . The $C^r$ -case: In contrast, for a $C^r$ -manifold where $r$ is a positive integer the situations looks different. Namely here $\mathrm{Der}_p(C^r(U))$ is infinite dimensional. A proof outline of this can for example be found in J.M.Lee's book ""Manifolds and differential geometry"", Chapter 2, Problem (18) on page 124. First it is established that as vector spaces $\mathrm{Der}_p(C^r(U)) \cong (\mathfrak{m}_r/\mathfrak{m}_r²)^*$ , where $\mathfrak{m}_r$ is the maximal ideal of $\mathrm{Der}_p(C^r(U))$ given by functions $f$ that vanish at $p$ , $f(p)=0$ . In the case $M=\mathbb{R}$ and $p=0$ one then defines functions $g^r_\varepsilon(x) := \begin{cases}x^{r+\varepsilon} & x \geq 0 \\ 0 & x \leq 0\end{cases}$ for $\varepsilon \in (0,1)$ and shows that their equivalence classes are all linearly independent in $\mathfrak{m}_r/\mathfrak{m}_r²$ . The general case follows from this as well. Question: Going through the proof of finite-dimensionality in the $C^\infty$ -case I can't see where we need the assumption of smoothness, it all seems to work verbatim for the $C^r$ -case. That we can choose an arbitrary open neighbourhood $U$ for the proof follows from the existence of cutoff functions. These are smooth and in particular $C^r$ , so this also works in the latter case. In the argument that the $\frac{\partial}{\partial x^i}|_0$ form a basis we only seem to assume $C^1$ really. This of course stands in contradiction to the fact that $\mathrm{Der}_p(C^r(U))$ is infinite-dimensional. So where does the proof go wrong?","The -case: If is a (paracompact Hausdorff) real -manifold and then the tangent space can be defined in several different but equivalent ways. One possibility is to define a tangent vector via its action on smooth functions and set . Here is the algebra of germs at of smooth real valued functions, and is the space of derivations of relative to evaluation at , i.e. the space linear maps satisfying for . Equivalently one can also use for an arbitrary open neighbourhood of . To proof the finite-dimensionality of we can assume without loss of generality that , and that is a convex set containing . One can then write down a basis for , namely the derivations where . To see that this is a spanning set one first writes any smooth function on as , where (using the fundamantal theorem of calculus) and then applies a derivation to obtain . For linear independence one evaluates at the coordinate functions . The -case: In contrast, for a -manifold where is a positive integer the situations looks different. Namely here is infinite dimensional. A proof outline of this can for example be found in J.M.Lee's book ""Manifolds and differential geometry"", Chapter 2, Problem (18) on page 124. First it is established that as vector spaces , where is the maximal ideal of given by functions that vanish at , . In the case and one then defines functions for and shows that their equivalence classes are all linearly independent in . The general case follows from this as well. Question: Going through the proof of finite-dimensionality in the -case I can't see where we need the assumption of smoothness, it all seems to work verbatim for the -case. That we can choose an arbitrary open neighbourhood for the proof follows from the existence of cutoff functions. These are smooth and in particular , so this also works in the latter case. In the argument that the form a basis we only seem to assume really. This of course stands in contradiction to the fact that is infinite-dimensional. So where does the proof go wrong?","C^\infty M C^\infty p \in M T_pM M \to \mathbb{R} T_pM := \mathrm{Der}_p(C_p^\infty(M)) C_p^\infty(M) p \mathrm{Der}_p(C^\infty(M)) C_p^\infty(M) p \varphi: C_p^\infty(M) \to \mathbb{R} \varphi(fg) = \varphi(f)g(p) + f(p)\varphi(g) f,g \in C_p^\infty(M) \mathrm{Der}_p(C^\infty(U)) U p T_pM M=\mathbb{R}^n p=0 U 0 T_pM \frac{\partial}{\partial x^i}|_0 i \in \{1,\ldots,n\} g U g = g(0) + \sum_i g_ix^i g_i(x) = \int_{0}^1\frac{\partial g}{\partial x^i}(tx)dt \varphi \varphi(g) = \sum_i \varphi(x^i)\frac{\partial}{\partial x^i}|_0(g) x^i C^r C^r r \mathrm{Der}_p(C^r(U)) \mathrm{Der}_p(C^r(U)) \cong (\mathfrak{m}_r/\mathfrak{m}_r²)^* \mathfrak{m}_r \mathrm{Der}_p(C^r(U)) f p f(p)=0 M=\mathbb{R} p=0 g^r_\varepsilon(x) := \begin{cases}x^{r+\varepsilon} & x \geq 0 \\ 0 & x \leq 0\end{cases} \varepsilon \in (0,1) \mathfrak{m}_r/\mathfrak{m}_r² C^\infty C^r U C^r \frac{\partial}{\partial x^i}|_0 C^1 \mathrm{Der}_p(C^r(U))","['real-analysis', 'differential-geometry', 'differential-topology']"
94,"Convexity in ""usual Partition of Unity arguments""","Convexity in ""usual Partition of Unity arguments""",,"I stumbled upon Problem 13-2 on p.344 in John Lee's Introduction to Smooth Manifolds (2nd Edition) where Lee explains that the proof for the existence of a Riemannian Metric on a manifold is done by a ""Partition of Unity""-Argument and he emphasizes that a crucial part in the proof was that the set of inner products on a given tangent space is a convex subset of the vector space of all symmetric $2$ -tensors. Now it seems that the convexity property can not be omitted in ""usual partition of unity"" arguments but unfortunately, I don't understand why it's so important. Where exactly does the convexity of the (respective) subset comes into play if we want to do such partition of unity argument (in a much more general sense)? So, to make my question a bit more precise: My question: Say we want to patch together local objects to a global one (e.g. local sections of a vector bundle to a global section) by a usual partition of unity argument. Why and where do we need to use convexity of the subset containing the images of the objects we want to patch together? (in the case of local sections we require that there is an open set $V\subset E$ (total space) so that $V\cap E_p$ is a convex subset of the fiber $E_p$ . Why do we need convexity of $V\cap E_p$ for example? Thanks in advance for any help!","I stumbled upon Problem 13-2 on p.344 in John Lee's Introduction to Smooth Manifolds (2nd Edition) where Lee explains that the proof for the existence of a Riemannian Metric on a manifold is done by a ""Partition of Unity""-Argument and he emphasizes that a crucial part in the proof was that the set of inner products on a given tangent space is a convex subset of the vector space of all symmetric -tensors. Now it seems that the convexity property can not be omitted in ""usual partition of unity"" arguments but unfortunately, I don't understand why it's so important. Where exactly does the convexity of the (respective) subset comes into play if we want to do such partition of unity argument (in a much more general sense)? So, to make my question a bit more precise: My question: Say we want to patch together local objects to a global one (e.g. local sections of a vector bundle to a global section) by a usual partition of unity argument. Why and where do we need to use convexity of the subset containing the images of the objects we want to patch together? (in the case of local sections we require that there is an open set (total space) so that is a convex subset of the fiber . Why do we need convexity of for example? Thanks in advance for any help!",2 V\subset E V\cap E_p E_p V\cap E_p,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'fiber-bundles']"
95,Is a map which sends a $3\times 3$ symmetric tensor to an element of $SO(3)$ which diagonalizes it necessarily discontinuous?,Is a map which sends a  symmetric tensor to an element of  which diagonalizes it necessarily discontinuous?,3\times 3 SO(3),"For a $3\times 3$ symmetric matrix $Q$ , one can construct a map to $SO(3)$ which sends $Q$ to a matrix which diagonalizes it. If $Q$ has distinct eigenvalues, there are three choices for rotation matrix: given one (guaranteed by the spectral theorem) you can always cyclically permute the columns to get two more. Choosing one arbitrarily defines a locally smooth map. That is, perturbing the entries of $Q$ slightly will only slightly perturb the eigenvalues and eigenvectors. However, if $Q$ has repeated eigenvalues then given $R \in SO(3)$ which diagonalizes $Q$ , we also have that $R'(\theta) R$ is a valid choice, where $R'(\theta)$ is a rotation by any angle $\theta$ in the plane spanned by the eigenvectors corresponding to repeated eigenvalues. It seems reasonable to me that if we arbitrarily choose some $R$ , then slightly perturbing $Q$ could give another element of $SO(3)$ which is far away from $R$ but perhaps close to $R'(\theta') R$ for some $\theta'$ . The question is then, is it possible to construct a mapping so that no such discontinuities occur, or will such a mapping always be discontinuous at elements with repeated eigenvalues?","For a symmetric matrix , one can construct a map to which sends to a matrix which diagonalizes it. If has distinct eigenvalues, there are three choices for rotation matrix: given one (guaranteed by the spectral theorem) you can always cyclically permute the columns to get two more. Choosing one arbitrarily defines a locally smooth map. That is, perturbing the entries of slightly will only slightly perturb the eigenvalues and eigenvectors. However, if has repeated eigenvalues then given which diagonalizes , we also have that is a valid choice, where is a rotation by any angle in the plane spanned by the eigenvectors corresponding to repeated eigenvalues. It seems reasonable to me that if we arbitrarily choose some , then slightly perturbing could give another element of which is far away from but perhaps close to for some . The question is then, is it possible to construct a mapping so that no such discontinuities occur, or will such a mapping always be discontinuous at elements with repeated eigenvalues?",3\times 3 Q SO(3) Q Q Q Q R \in SO(3) Q R'(\theta) R R'(\theta) \theta R Q SO(3) R R'(\theta') R \theta',"['linear-algebra', 'differential-geometry', 'rotations', 'symmetric-matrices', 'smooth-functions']"
96,Are all manifolds locally flat?,Are all manifolds locally flat?,,"The definition of manifold I usually see is “A topological space $(X,T)$ in which for every member of the topological space $x \in (X,T)$ there exists a neighborhood $M_x$ such that is homeomorphic to an open set of $\mathbb{R}^n$ The problem with this definition is that it doesn’t seem to imply the intuitive notion that manifolds are locally flat (look flat when you zoom in). All it implies is that there are neighborhoods around points where the topology looks the same, but we know of objects that have the same topology but do not geometrically look the same (.ex a coffee cup and a donut). It looks like a better definition of a manifold would be a set where for each member of the set there exists a neighborhood where the Riemann curvature tensor is approximately 0. Does this definition work? Is it implied from the 1st definition of a manifold? If so, how? Thanks","The definition of manifold I usually see is “A topological space in which for every member of the topological space there exists a neighborhood such that is homeomorphic to an open set of The problem with this definition is that it doesn’t seem to imply the intuitive notion that manifolds are locally flat (look flat when you zoom in). All it implies is that there are neighborhoods around points where the topology looks the same, but we know of objects that have the same topology but do not geometrically look the same (.ex a coffee cup and a donut). It looks like a better definition of a manifold would be a set where for each member of the set there exists a neighborhood where the Riemann curvature tensor is approximately 0. Does this definition work? Is it implied from the 1st definition of a manifold? If so, how? Thanks","(X,T) x \in (X,T) M_x \mathbb{R}^n","['differential-geometry', 'manifolds', 'differential-topology']"
97,Terminology confusion in complex geometry (hermitian geometry),Terminology confusion in complex geometry (hermitian geometry),,"I was reading the book by Huybrechts and he writes the definition of an Hermitian structure as follows: Let $X$ be a complex manifold and $I$ be the induced almost complex structure. A Riemannian metric $g$ on $X$ is said to hermitian structure on $X$ if for any point $x \in X$ , the scalar product $g_x$ on $T_x X$ is compatible with the almost complex structure $I$ (i.e $g_x(v,w) = g_x(I(v),I(w)$ for all $v,w \in T_xM$ ). And I found the definition of Hermitian metric in Griffiths and Harris's Principles of Algebraic geometry as follows: Let $X$ be a complex manifold of dimension $n$ . A hermitian metric on $X$ is given by a positive definite hermitian inner product $$ (\cdot, \cdot)_z : T^{'}_{z}(X) \otimes \overline{T^{'}_{z}(X)} \longrightarrow \mathbb{C} $$ on the holomorphic tangent space at $z$ for each $z \in X$ , depending smoothly on $z$ . My question: I am facing difficulty in understanding the following terminologies: Hermitian metric Hermitian structure Hermitian form Hermitian inner product Giving really stupid input, I think 1) and 2) must be the same things (if it is, still I don't get how). Can anyone please clarify these terminologies? I am really confused looking at different other sources (in fact, I am getting more confused after referring to other references). Thanks!","I was reading the book by Huybrechts and he writes the definition of an Hermitian structure as follows: Let be a complex manifold and be the induced almost complex structure. A Riemannian metric on is said to hermitian structure on if for any point , the scalar product on is compatible with the almost complex structure (i.e for all ). And I found the definition of Hermitian metric in Griffiths and Harris's Principles of Algebraic geometry as follows: Let be a complex manifold of dimension . A hermitian metric on is given by a positive definite hermitian inner product on the holomorphic tangent space at for each , depending smoothly on . My question: I am facing difficulty in understanding the following terminologies: Hermitian metric Hermitian structure Hermitian form Hermitian inner product Giving really stupid input, I think 1) and 2) must be the same things (if it is, still I don't get how). Can anyone please clarify these terminologies? I am really confused looking at different other sources (in fact, I am getting more confused after referring to other references). Thanks!","X I g X X x \in X g_x T_x X I g_x(v,w) = g_x(I(v),I(w) v,w \in T_xM X n X  (\cdot, \cdot)_z : T^{'}_{z}(X) \otimes \overline{T^{'}_{z}(X)} \longrightarrow \mathbb{C}  z z \in X z","['differential-geometry', 'complex-geometry']"
98,Notion of maximal atlases in differential geometry,Notion of maximal atlases in differential geometry,,"I'm following a course on differential geometry and from some background I've gotten used to the fact that a topological manifold $M$ is called a smooth/differentiable manifold if we can equip $M$ with some smooth atlas $\mathcal{A}$ , then the pair $(M, \mathcal{A})$ is called a differentiable manifold. Now reading Lee's book I've found out that we actually require $\mathcal{A}$ to be something called maximal. He first states that Our plan is to define a “smooth structure” on $M$ by giving a smooth atlas, and to define a function $f : M \to \Bbb R$ to be smooth if and only if $f \circ \varphi^{-1}$ is smooth in the sense of ordinary calculus for each coordinate chart $(U, \varphi)$ in the atlas. There is one minor technical problem with this approach: in general, there will be many possible atlases that give the “same” smooth structure, in that they all determine the same collection of smooth functions on $M$ . Then he goes on to state that However, it is more straightforward to make the following definition: a smooth atlas $\mathcal{A}$ on $M$ is maximal if it is not properly contained in any larger smooth atlas. This just means that any chart that is smoothly compatible with every chart in $\mathcal{A}$ is already in $\mathcal{A}$ . The lecturer in the course I'm taking says that in practice we only need to consider some atlas $\mathcal{A}$ for $M$ instead of the maximal one which is causing my confusion. Why is this true? Lee also  gives the proposition $1.17$ which states that Let $M$ be a topological manifold, then every smooth atlas $\mathcal{A}$ for $M$ is contained in a unique maximal smooth atlas, called the smooth structure determined by $\mathcal{A}.$ and presumably this is the reason why we can consider some arbitary atlas $\mathcal{A}$ instead of the maximal one? Why does this imply that we don't need to consider the maximal one? I don't think it's obvious.","I'm following a course on differential geometry and from some background I've gotten used to the fact that a topological manifold is called a smooth/differentiable manifold if we can equip with some smooth atlas , then the pair is called a differentiable manifold. Now reading Lee's book I've found out that we actually require to be something called maximal. He first states that Our plan is to define a “smooth structure” on by giving a smooth atlas, and to define a function to be smooth if and only if is smooth in the sense of ordinary calculus for each coordinate chart in the atlas. There is one minor technical problem with this approach: in general, there will be many possible atlases that give the “same” smooth structure, in that they all determine the same collection of smooth functions on . Then he goes on to state that However, it is more straightforward to make the following definition: a smooth atlas on is maximal if it is not properly contained in any larger smooth atlas. This just means that any chart that is smoothly compatible with every chart in is already in . The lecturer in the course I'm taking says that in practice we only need to consider some atlas for instead of the maximal one which is causing my confusion. Why is this true? Lee also  gives the proposition which states that Let be a topological manifold, then every smooth atlas for is contained in a unique maximal smooth atlas, called the smooth structure determined by and presumably this is the reason why we can consider some arbitary atlas instead of the maximal one? Why does this imply that we don't need to consider the maximal one? I don't think it's obvious.","M M \mathcal{A} (M, \mathcal{A}) \mathcal{A} M f : M \to \Bbb R f \circ \varphi^{-1} (U, \varphi) M \mathcal{A} M \mathcal{A} \mathcal{A} \mathcal{A} M 1.17 M \mathcal{A} M \mathcal{A}. \mathcal{A}","['differential-geometry', 'manifolds', 'smooth-manifolds']"
99,Question about differential forms spherical,Question about differential forms spherical,,"Consider the $2$ -form on $\mathbb{R}^3$ given by $$\omega = x\,dy\wedge dz+y\,dz\wedge dx+z\,dx\wedge dy.$$ We can restrict this to the sphere. If I use spherical coordinates with $\phi$ the polar angle from the $z$ -axis and $\theta$ the azimuthal angle from the $x$ -axis, the resulting form I get from computing pullbacks is $\sin\phi\,d\phi\wedge d\theta$ . This can only be computed where spherical coordinates work, which turns out to be everywhere on $S^2$ except for the north and south pole. I know for a fact that the form is nonzero everywhere on $S^2$ . But it seems like $\sin\phi\,d\phi\wedge d\theta$ gets very ""small"" near the north pole: the scaling by $\sin\phi$ approaches zero. So it seems for the form to be continuous, we would need it to be zero at the north pole, but I know this is not the case. How am I to reconcile these facts, geometrically? It seems like $d\phi$ and $d\theta$ don't ""shrink"" near the poles either--I am looking for some geometric intuition. Thanks!","Consider the -form on given by We can restrict this to the sphere. If I use spherical coordinates with the polar angle from the -axis and the azimuthal angle from the -axis, the resulting form I get from computing pullbacks is . This can only be computed where spherical coordinates work, which turns out to be everywhere on except for the north and south pole. I know for a fact that the form is nonzero everywhere on . But it seems like gets very ""small"" near the north pole: the scaling by approaches zero. So it seems for the form to be continuous, we would need it to be zero at the north pole, but I know this is not the case. How am I to reconcile these facts, geometrically? It seems like and don't ""shrink"" near the poles either--I am looking for some geometric intuition. Thanks!","2 \mathbb{R}^3 \omega = x\,dy\wedge dz+y\,dz\wedge dx+z\,dx\wedge dy. \phi z \theta x \sin\phi\,d\phi\wedge d\theta S^2 S^2 \sin\phi\,d\phi\wedge d\theta \sin\phi d\phi d\theta","['differential-geometry', 'differential-forms']"
