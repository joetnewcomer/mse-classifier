,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Doubt about Taylor series: do successive derivatives on a point determine the whole function?,Doubt about Taylor series: do successive derivatives on a point determine the whole function?,,"I'm currently relearning Taylor series and yersterday I thought about something that left me puzzled. As far as I understand, whenever you take the Taylor series of any function $f(x)$ around a point $x = a$ , the function is exactly equal to its Taylor series, that is: $$ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n $$ For example, if we take $f(x) = e^x$ and $x = 0$ , we obtain: $ e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} $ My doubt is: the only variables in the Tayor series formula are $f(a), f'(a), f''(a),$ etc., that is, the successive derivatives of the function $f$ evaluated in one point $x = a$ . But the Taylor series of $f(x)$ determine the whole function! How is it possible that the successive derivatives of the function evaluated in a single point determine the whole function? Does this mean that if we know the values of $f^{(n)}(a)$ , then $f$ is uniquely determined? Is there an intuition as to why the succesive derivatives of $f$ on a single point encode the necessary information to determine $f$ uniquely? Maybe I'm missing a key insight and all my reasoning is wrong, if so please tell where is my mistake. Thanks!","I'm currently relearning Taylor series and yersterday I thought about something that left me puzzled. As far as I understand, whenever you take the Taylor series of any function around a point , the function is exactly equal to its Taylor series, that is: For example, if we take and , we obtain: My doubt is: the only variables in the Tayor series formula are etc., that is, the successive derivatives of the function evaluated in one point . But the Taylor series of determine the whole function! How is it possible that the successive derivatives of the function evaluated in a single point determine the whole function? Does this mean that if we know the values of , then is uniquely determined? Is there an intuition as to why the succesive derivatives of on a single point encode the necessary information to determine uniquely? Maybe I'm missing a key insight and all my reasoning is wrong, if so please tell where is my mistake. Thanks!","f(x) x = a  f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n  f(x) = e^x x = 0  e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}  f(a), f'(a), f''(a), f x = a f(x) f^{(n)}(a) f f f","['calculus', 'functions', 'taylor-expansion']"
1,When is the derivative of an inverse function equal to the reciprocal of the derivative?,When is the derivative of an inverse function equal to the reciprocal of the derivative?,,When is this statement true? $$\dfrac {\mathrm dx}{\mathrm dy} = \frac 1 {\frac {\mathrm dy}{\mathrm dx}}$$ where $y=y(x)$. I think that $y(x)$ has to be bijective in order to have an inverse and let the expression $\dfrac {\mathrm dx}{\mathrm dy}$ make sense. But is there any other condition?,When is this statement true? $$\dfrac {\mathrm dx}{\mathrm dy} = \frac 1 {\frac {\mathrm dy}{\mathrm dx}}$$ where $y=y(x)$. I think that $y(x)$ has to be bijective in order to have an inverse and let the expression $\dfrac {\mathrm dx}{\mathrm dy}$ make sense. But is there any other condition?,,"['calculus', 'derivatives', 'inverse']"
2,"Integral involving Clausen function ${\large\int}_0^{2\pi}\operatorname{Cl}_2(x)^2\,x^p\,dx$",Integral involving Clausen function,"{\large\int}_0^{2\pi}\operatorname{Cl}_2(x)^2\,x^p\,dx","Consider the Clausen function $\operatorname{Cl}_2(x)$ that can be defined for $0<x<2\pi$ in several equivalent ways: $$\begin{align}\operatorname{Cl}_2(x)&=-\int_0^x\ln\left(2\sin\left(\tfrac t2\right)\right)dt\\&=\sum_{n=1}^\infty\frac{\sin\,(n x)}{n^2}\\&=\Im\operatorname{Li}_2\left(e^{i x}\right)\\&=i\left(\frac{\pi^2}6+\frac{x^2}4-\frac{\pi x}2-\operatorname{Li}_2\left(e^{i x}\right)\right).\end{align}\tag1$$ I'm interested in integrals of the form $$I(p)=\int_0^{2\pi}\operatorname{Cl}_2(x)^2\,x^p\,dx.\tag2$$ I found that $$I(0)=\frac{\pi^5}{90}\tag3$$ and conjectured next several values based on numeric evidence: $$I(1)\stackrel?=\frac{\pi^6}{90},\ \ I(2)\stackrel?=\frac{44\,\pi^7}{2835},\ \ I(3)\stackrel?=\frac{23\,\pi^8}{945}.\tag4$$ One might expect that $I(4)$ is a rational multiple of $\pi^9$, but apparently it is not (unless the denominator is huge). I'm asking for your help in proving conjectured values $(4)$, finding a closed form of $I(4)$, and, if possible, a general formula for $I(p)$. Update: Values $I(-1)$ and $I(-2)$ are also interesting.","Consider the Clausen function $\operatorname{Cl}_2(x)$ that can be defined for $0<x<2\pi$ in several equivalent ways: $$\begin{align}\operatorname{Cl}_2(x)&=-\int_0^x\ln\left(2\sin\left(\tfrac t2\right)\right)dt\\&=\sum_{n=1}^\infty\frac{\sin\,(n x)}{n^2}\\&=\Im\operatorname{Li}_2\left(e^{i x}\right)\\&=i\left(\frac{\pi^2}6+\frac{x^2}4-\frac{\pi x}2-\operatorname{Li}_2\left(e^{i x}\right)\right).\end{align}\tag1$$ I'm interested in integrals of the form $$I(p)=\int_0^{2\pi}\operatorname{Cl}_2(x)^2\,x^p\,dx.\tag2$$ I found that $$I(0)=\frac{\pi^5}{90}\tag3$$ and conjectured next several values based on numeric evidence: $$I(1)\stackrel?=\frac{\pi^6}{90},\ \ I(2)\stackrel?=\frac{44\,\pi^7}{2835},\ \ I(3)\stackrel?=\frac{23\,\pi^8}{945}.\tag4$$ One might expect that $I(4)$ is a rational multiple of $\pi^9$, but apparently it is not (unless the denominator is huge). I'm asking for your help in proving conjectured values $(4)$, finding a closed form of $I(4)$, and, if possible, a general formula for $I(p)$. Update: Values $I(-1)$ and $I(-2)$ are also interesting.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'polylogarithm']"
3,From the series $\sum_{n=1}^{+\infty}\left(H_n-\ln n-\gamma-\frac1{2n}\right)$ to $\zeta(\frac12+it)$.,From the series  to .,\sum_{n=1}^{+\infty}\left(H_n-\ln n-\gamma-\frac1{2n}\right) \zeta(\frac12+it),Here is a pretty series $$ \displaystyle \sum_{n=1}^{+ \infty} \left(H_{n}-\ln n-\gamma -\frac{1}{2n}\right)=\frac{1}{2} \left(1-\ln (2\pi)+\gamma\right) \tag{*} $$ where $H_{n}:=\sum_{1}^{n} \frac{1}{k}$ are the harmonic numbers and $\gamma := \lim\limits_{n \to \infty} (H_n- \ln n)$ is the Euler constant. $$ $$ Now just introduce a parameter in the general term of the series and you get a link with... the Riemann $\zeta$ function on the critical line! Q 1. What proof would you give for (*)? Q 2. What elements would you give to get the link with $\zeta\left(\frac{1}{2}+it\right)$?,Here is a pretty series $$ \displaystyle \sum_{n=1}^{+ \infty} \left(H_{n}-\ln n-\gamma -\frac{1}{2n}\right)=\frac{1}{2} \left(1-\ln (2\pi)+\gamma\right) \tag{*} $$ where $H_{n}:=\sum_{1}^{n} \frac{1}{k}$ are the harmonic numbers and $\gamma := \lim\limits_{n \to \infty} (H_n- \ln n)$ is the Euler constant. $$ $$ Now just introduce a parameter in the general term of the series and you get a link with... the Riemann $\zeta$ function on the critical line! Q 1. What proof would you give for (*)? Q 2. What elements would you give to get the link with $\zeta\left(\frac{1}{2}+it\right)$?,,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'riemann-zeta']"
4,How to determine whether this function is differentiable at a point?,How to determine whether this function is differentiable at a point?,,"We are given the following function: $$f(x) =     \left\{ \begin{array}{ll}       \dfrac{x}{1+x} & x \geq 0 \\       x^2 & x < 0 \\ \end{array}  \right.$$ We wanted to determine whether or not $f(x)$ is differentiable at $0$. I already know that $f(x)$ is continuous at $0$ using the definition of continuity. If I am correct, to show differentiability we have to show that the following limit exists: $f'(x)=\lim_{~h \to 0} \dfrac{f(x+h)-f(x)}{h}$. Since $f(x) = \dfrac{x}{1+x}$ at $x=0$, would it then be enough to say that the derivative of $[\dfrac{x}{1+x}]' = \dfrac{1}{(x+1)^2}$ is defined at $x=0$, and since we know that $f(x)$ is also continuous at $0$, we can say $f(x)$ is differentiable at $0$?","We are given the following function: $$f(x) =     \left\{ \begin{array}{ll}       \dfrac{x}{1+x} & x \geq 0 \\       x^2 & x < 0 \\ \end{array}  \right.$$ We wanted to determine whether or not $f(x)$ is differentiable at $0$. I already know that $f(x)$ is continuous at $0$ using the definition of continuity. If I am correct, to show differentiability we have to show that the following limit exists: $f'(x)=\lim_{~h \to 0} \dfrac{f(x+h)-f(x)}{h}$. Since $f(x) = \dfrac{x}{1+x}$ at $x=0$, would it then be enough to say that the derivative of $[\dfrac{x}{1+x}]' = \dfrac{1}{(x+1)^2}$ is defined at $x=0$, and since we know that $f(x)$ is also continuous at $0$, we can say $f(x)$ is differentiable at $0$?",,"['calculus', 'limits']"
5,Other challenging logarithmic integral $\int_0^1 \frac{\log^2(x)\log(1-x)\log(1+x)}{x}dx$,Other challenging logarithmic integral,\int_0^1 \frac{\log^2(x)\log(1-x)\log(1+x)}{x}dx,How can we prove that: $$\int_0^1\frac{\log^2(x)\log(1-x)\log(1+x)}{x}dx=\frac{\pi^2}{8}\zeta(3)-\frac{27}{16}\zeta(5)  $$,How can we prove that: $$\int_0^1\frac{\log^2(x)\log(1-x)\log(1+x)}{x}dx=\frac{\pi^2}{8}\zeta(3)-\frac{27}{16}\zeta(5)  $$,,"['calculus', 'integration', 'improper-integrals', 'special-functions', 'harmonic-numbers']"
6,"What does a ""half derivative"" mean?","What does a ""half derivative"" mean?",,"I was looking at fractional calculus on Wikipedia, specifically this section and came across the half derivative of the function $y=x$ which is $\frac{d^{1/2}y}{dx^{1/2}}=\frac{2\sqrt{x}}{\sqrt{\pi}}$ . The derivative tells the slope at any point on the curve, but what does the ""half derivative"" mean - it's obviously not $\frac{1}{2}$ the derivative of $y=x$ which would be just $\frac{1}{2}$ . I do not have a very deep understanding of calculus - I have just taken Calc 1 & 2 out of a 4 series, but anything helps! Also, I have checked similar questions, but they did not seem to answer my question that I have bolded .","I was looking at fractional calculus on Wikipedia, specifically this section and came across the half derivative of the function which is . The derivative tells the slope at any point on the curve, but what does the ""half derivative"" mean - it's obviously not the derivative of which would be just . I do not have a very deep understanding of calculus - I have just taken Calc 1 & 2 out of a 4 series, but anything helps! Also, I have checked similar questions, but they did not seem to answer my question that I have bolded .",y=x \frac{d^{1/2}y}{dx^{1/2}}=\frac{2\sqrt{x}}{\sqrt{\pi}} \frac{1}{2} y=x \frac{1}{2},"['calculus', 'fractional-calculus']"
7,A closed form for $\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx$,A closed form for,\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx,"Let $\operatorname{li}x$ denote the logarithmic integral $^{[1]}$ $^{[2]}$ $^{[3]}$ : $$\operatorname{li}x=\int_0^x\frac{dt}{\ln t}$$ and $$I=\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx\approx-4.311872263...$$ Is it possible to express the integral $I$ in a closed form (using algebraic numbers, known mathematical constants, elementary and known special functions)?","Let $\operatorname{li}x$ denote the logarithmic integral $^{[1]}$ $^{[2]}$ $^{[3]}$ : $$\operatorname{li}x=\int_0^x\frac{dt}{\ln t}$$ and $$I=\int_0^1\frac{\ln(-\ln x)\ \operatorname{li}^2x}{x}dx\approx-4.311872263...$$ Is it possible to express the integral $I$ in a closed form (using algebraic numbers, known mathematical constants, elementary and known special functions)?",,"['calculus', 'integration', 'special-functions', 'logarithms', 'closed-form']"
8,How can we think and/or write rigorously about integration by substitution?,How can we think and/or write rigorously about integration by substitution?,,"Define a function $I:\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ as follows. $$I(a,b)=\int_a^b \sin t \cos t \,d t$$ Then we can find a more explicit description of $I$ using integration by substitution. So let $u = \sin t$. Then $d u = \cos t \,dt$. Therefore: $$I(a,b) = \int_a^b \sin t \cos t \,d t = \int_{t=a}^{t=b}udu = \left[\frac{1}{2}u^2\right]_{t=a}^{t=b} = \left[\frac{1}{2} \sin^2 t\right]_{t=a}^{t=b}  = \frac{1}{2}\left(\sin^2b-\sin^2 a\right)$$ I'm not confident in our final answer, though; there's just too many dodgy things going on. These include both general issues with integration by substitution, and issues that are somewhat more specific to this problem. General Issues. I've always been a bit uncomfortable with this ""let $u=\sin t$"" stuff, since we never said anything like ""let $t$ denote a fixed but arbitrary real number,"" so the meaning of $t$ is ambiguous. This isn't easily fixed though; we don't want to say ""let $t$ denote a fixed but arbitrary real number"" because moments later, we're going to quantify over $t$ by integrating, so clearly it wasn't fixed. Another general issue is that I don't really know what expressions like $du = \cos t dt$ mean. Under the usual semantics for equations, we would think of this as being true for some pairs $(u,t)$ and false for others. Here, that semantics doesn't work, so its not at all clear to me what is being asserted. Particular Issues. In this particular case, since the function $t \in [a,b] \mapsto \sin t \in \mathbb{R}$ isn't injective for a sufficiently large gap between $a$ and $b$, I'm not even sure we're allowed to perform integration by substitution here. (Are we?) The notation $\int_{t=a}^{t=b}udu$ and $\left[\frac{1}{2}u^2\right]_{t=a}^{t=b}$ just kind of seems kind of ambiguous to me. Does this really make sense? If so, how does one formalize the meanings of these expressions? Question. Suppose we want to conceptualize integration by substitution rigorously, and to apply it rigorously (using unambiguous notation) to find $I(a,b)$ explicitly. How can we do this? Please don't post answers that cleverly avoid using integration by substitution. I want to understand it, not avoid it.","Define a function $I:\mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ as follows. $$I(a,b)=\int_a^b \sin t \cos t \,d t$$ Then we can find a more explicit description of $I$ using integration by substitution. So let $u = \sin t$. Then $d u = \cos t \,dt$. Therefore: $$I(a,b) = \int_a^b \sin t \cos t \,d t = \int_{t=a}^{t=b}udu = \left[\frac{1}{2}u^2\right]_{t=a}^{t=b} = \left[\frac{1}{2} \sin^2 t\right]_{t=a}^{t=b}  = \frac{1}{2}\left(\sin^2b-\sin^2 a\right)$$ I'm not confident in our final answer, though; there's just too many dodgy things going on. These include both general issues with integration by substitution, and issues that are somewhat more specific to this problem. General Issues. I've always been a bit uncomfortable with this ""let $u=\sin t$"" stuff, since we never said anything like ""let $t$ denote a fixed but arbitrary real number,"" so the meaning of $t$ is ambiguous. This isn't easily fixed though; we don't want to say ""let $t$ denote a fixed but arbitrary real number"" because moments later, we're going to quantify over $t$ by integrating, so clearly it wasn't fixed. Another general issue is that I don't really know what expressions like $du = \cos t dt$ mean. Under the usual semantics for equations, we would think of this as being true for some pairs $(u,t)$ and false for others. Here, that semantics doesn't work, so its not at all clear to me what is being asserted. Particular Issues. In this particular case, since the function $t \in [a,b] \mapsto \sin t \in \mathbb{R}$ isn't injective for a sufficiently large gap between $a$ and $b$, I'm not even sure we're allowed to perform integration by substitution here. (Are we?) The notation $\int_{t=a}^{t=b}udu$ and $\left[\frac{1}{2}u^2\right]_{t=a}^{t=b}$ just kind of seems kind of ambiguous to me. Does this really make sense? If so, how does one formalize the meanings of these expressions? Question. Suppose we want to conceptualize integration by substitution rigorously, and to apply it rigorously (using unambiguous notation) to find $I(a,b)$ explicitly. How can we do this? Please don't post answers that cleverly avoid using integration by substitution. I want to understand it, not avoid it.",,"['calculus', 'integration', 'proof-writing', 'definition']"
9,Math contest: Find number of roots of $F(x)=\frac{n}{2}$ involving a strange integral.,Math contest: Find number of roots of  involving a strange integral.,F(x)=\frac{n}{2},"Edit summary : A good answer appeared. CW full answer added, based on given answers. Removing my ugly-looking attempts, as they still remain in the rev. history. Here's a final-round calculus contest problem in our district in 2009. Test paper isn't available online. I originally proved $F(n/2)<n/2$ but failed to prove $F(n)>n/2$ and the monotonicity of $F(n)$. Define       $$F(x)=\int\limits_0^x \mathrm e^{-t} \left(1+t+\frac{t^2}{2!}+\cdots+\frac{t^n}{n!}\right) \mathrm d t$$     where $n>1, n \in \mathbb N^+$; and an equation: $\displaystyle F(x)=\frac{n}{2}$. Find the number of roots of this equation within the interval $\displaystyle I=\left(\frac{n}{2},n\right)$. Tedious Previous Attempts Removed.","Edit summary : A good answer appeared. CW full answer added, based on given answers. Removing my ugly-looking attempts, as they still remain in the rev. history. Here's a final-round calculus contest problem in our district in 2009. Test paper isn't available online. I originally proved $F(n/2)<n/2$ but failed to prove $F(n)>n/2$ and the monotonicity of $F(n)$. Define       $$F(x)=\int\limits_0^x \mathrm e^{-t} \left(1+t+\frac{t^2}{2!}+\cdots+\frac{t^n}{n!}\right) \mathrm d t$$     where $n>1, n \in \mathbb N^+$; and an equation: $\displaystyle F(x)=\frac{n}{2}$. Find the number of roots of this equation within the interval $\displaystyle I=\left(\frac{n}{2},n\right)$. Tedious Previous Attempts Removed.",,"['calculus', 'integration', 'power-series', 'contest-math']"
10,What is $\lim\limits_{n\to\infty}\frac1n \left(\text{maximum value of }\sum\limits_{k=1}^n\sin (kx)\right)$?,What is ?,\lim\limits_{n\to\infty}\frac1n \left(\text{maximum value of }\sum\limits_{k=1}^n\sin (kx)\right),"Consider $f(x)=\sum\limits_{k=1}^n\sin (kx), 0\le x \le \pi$ . Here is the graph of $y=f(x)$ for $n=8$ . I noticed that, as $n\to\infty$ , the maximum value of $\frac1n f(x)$ seems to approach a limit of approximately $0.7246$ . What is $\lim\limits_{n\to\infty}\frac1n \left(\text{maximum value of }\sum\limits_{k=1}^n\sin (kx)\right)$ ? My thoughts: I tried to find the first turning point to the right of the $y$ -axis, without success. I don't know if this helps, but I have found the roots of $f(x)$ , and shown that there is exactly one turning point between neighboring roots. Finding the roots of $f(x)$ $f(x)=\text{Im}\sum\limits_{k=1}^n e^{kxi}=\dots=\dfrac{\sin x+\sin ((nx+x)-x)-\sin (nx+x)}{2-2\cos x}=0$ If $\sin (nx)=0$ then $(\sin x)(1-\cos (nx))=0\implies x=0, \pi, \frac{2k\pi}{n}$ If $\sin (nx+x)=0$ then $(\sin x)(1-\cos ((n+1)x)=0\implies x=0, \pi, \frac{2k\pi}{n+1}$ We have found $n+1$ distinct roots. Now we will show that these are the only roots. $\sin (kx)=\text{Im}(\cos x+i\sin x)^k=(\sin x)(k-1 \text{ -degree polynomial in $\cos x$})$ $\implies f(x)=(\sin x)(n-1 \text{ -degree polynomial in }\cos x)$ The $n-1 \text{ degree polynomial in }\cos x$ has at most $n-1$ distinct roots in $\cos x$ , so it has at most $n-1$ distinct roots in $x$ . The roots of $\sin x$ are $0$ and $\pi$ . So $f(x)$ has at most $n+1$ distinct roots in $x$ . So the $n+1$ roots that I found above, are the only roots. Showing that $f(x)$ has exactly one turning point between neighboring roots $\cos (kx)=\text{Re}(\cos x+i\sin x)^k=k \text{ -degree polynomial in $\cos x$}$ $\implies f'(x)=\sum\limits_{k=1}^n k\cos (kx)$ is an $n$ -degree polynomial in $\cos x$ So $f'(x)$ has at most $n$ distinct roots in $\cos x$ , so it has at most $n$ distinct roots in $x$ . So $f(x)$ has at most $n$ turning points. Earlier we found that $f(x)$ has at exactly $n+1$ distinct roots. So $f(x)$ has exactly one turning point between neighboring roots.","Consider . Here is the graph of for . I noticed that, as , the maximum value of seems to approach a limit of approximately . What is ? My thoughts: I tried to find the first turning point to the right of the -axis, without success. I don't know if this helps, but I have found the roots of , and shown that there is exactly one turning point between neighboring roots. Finding the roots of If then If then We have found distinct roots. Now we will show that these are the only roots. The has at most distinct roots in , so it has at most distinct roots in . The roots of are and . So has at most distinct roots in . So the roots that I found above, are the only roots. Showing that has exactly one turning point between neighboring roots is an -degree polynomial in So has at most distinct roots in , so it has at most distinct roots in . So has at most turning points. Earlier we found that has at exactly distinct roots. So has exactly one turning point between neighboring roots.","f(x)=\sum\limits_{k=1}^n\sin (kx), 0\le x \le \pi y=f(x) n=8 n\to\infty \frac1n f(x) 0.7246 \lim\limits_{n\to\infty}\frac1n \left(\text{maximum value of }\sum\limits_{k=1}^n\sin (kx)\right) y f(x) f(x) f(x)=\text{Im}\sum\limits_{k=1}^n e^{kxi}=\dots=\dfrac{\sin x+\sin ((nx+x)-x)-\sin (nx+x)}{2-2\cos x}=0 \sin (nx)=0 (\sin x)(1-\cos (nx))=0\implies x=0, \pi, \frac{2k\pi}{n} \sin (nx+x)=0 (\sin x)(1-\cos ((n+1)x)=0\implies x=0, \pi, \frac{2k\pi}{n+1} n+1 \sin (kx)=\text{Im}(\cos x+i\sin x)^k=(\sin x)(k-1 \text{ -degree polynomial in \cos x}) \implies f(x)=(\sin x)(n-1 \text{ -degree polynomial in }\cos x) n-1 \text{ degree polynomial in }\cos x n-1 \cos x n-1 x \sin x 0 \pi f(x) n+1 x n+1 f(x) \cos (kx)=\text{Re}(\cos x+i\sin x)^k=k \text{ -degree polynomial in \cos x} \implies f'(x)=\sum\limits_{k=1}^n k\cos (kx) n \cos x f'(x) n \cos x n x f(x) n f(x) n+1 f(x)","['calculus', 'sequences-and-series', 'limits', 'trigonometry', 'maxima-minima']"
11,Is $ \frac{\mathrm{d}{x}}{\mathrm{d}{y}} = \frac{1}{\left( \frac{\mathrm{d}{y}}{\mathrm{d}{x}} \right)} $?,Is ?, \frac{\mathrm{d}{x}}{\mathrm{d}{y}} = \frac{1}{\left( \frac{\mathrm{d}{y}}{\mathrm{d}{x}} \right)} ,"In calculus, is $ \dfrac{\mathrm{d}{x}}{\mathrm{d}{y}} = \dfrac{1}{\left( \dfrac{\mathrm{d}{y}}{\mathrm{d}{x}} \right)} $? I’m so confused about this matter. What would be a proof of it? Edit: By the Chain Rule, $ \dfrac{\mathrm{d}{y}}{\mathrm{d}{x}} \cdot \dfrac{\mathrm{d}{x}}{\mathrm{d}{y}} = \dfrac{\mathrm{d}{y}}{\mathrm{d}{y}} = 1 $, so this confuses me.","In calculus, is $ \dfrac{\mathrm{d}{x}}{\mathrm{d}{y}} = \dfrac{1}{\left( \dfrac{\mathrm{d}{y}}{\mathrm{d}{x}} \right)} $? I’m so confused about this matter. What would be a proof of it? Edit: By the Chain Rule, $ \dfrac{\mathrm{d}{y}}{\mathrm{d}{x}} \cdot \dfrac{\mathrm{d}{x}}{\mathrm{d}{y}} = \dfrac{\mathrm{d}{y}}{\mathrm{d}{y}} = 1 $, so this confuses me.",,"['calculus', 'derivatives']"
12,Why is differentiation called differentiation?,Why is differentiation called differentiation?,,What is the etymological link between the word 'differentiation' and the procedure it describes?,What is the etymological link between the word 'differentiation' and the procedure it describes?,,"['calculus', 'terminology', 'math-history']"
13,Integrate $\int\frac{1}{\sin x+\cos x+\tan x+\cot x+\csc x+\sec x}dx$,Integrate,\int\frac{1}{\sin x+\cos x+\tan x+\cot x+\csc x+\sec x}dx,Solve the indefinite integral $$ I=\int\frac{1}{\sin x+\cos x+\tan x+\cot x+\csc x+\sec x}\;dx $$ My Attempt: $$ \begin{align} I&=\int\frac{1}{\sin x+\cos x+\frac{1}{\sin x \cos x}+\frac{\sin x +\cos x}{\sin x\cos x}}\;dx\\ \\ &=\int\frac{\sin x\cos x}{\left(\sin x+\cos x\right)\left(\sin x\cos x \right)+1+\left(\sin x+\cos x\right)}\;dx \end{align} $$ How can I complete the solution from here?,Solve the indefinite integral $$ I=\int\frac{1}{\sin x+\cos x+\tan x+\cot x+\csc x+\sec x}\;dx $$ My Attempt: $$ \begin{align} I&=\int\frac{1}{\sin x+\cos x+\frac{1}{\sin x \cos x}+\frac{\sin x +\cos x}{\sin x\cos x}}\;dx\\ \\ &=\int\frac{\sin x\cos x}{\left(\sin x+\cos x\right)\left(\sin x\cos x \right)+1+\left(\sin x+\cos x\right)}\;dx \end{align} $$ How can I complete the solution from here?,,"['calculus', 'integration']"
14,What's the connection between derivatives and boundaries?,What's the connection between derivatives and boundaries?,,"The (second) fundamental theorem of calculus says that $$\int_a^b f'(x) dx = f(b) - f(a)$$ which can also be stated, if one knows enough about what's coming next, as: The integral of the derivative of a function over an interval is the same as the function evaluated at the (signed) boundary of the interval. where I had to insert the word 'signed' to make it clear that there's an implicit multiplication by $-1$ when you evaluate the function at the 'bottom' end of the integral. If we wrote the right-hand side of the expression as $$f(b) + (-1) f(a)$$ then even a high-school student could probably be persuaded that this is the same as 'integrating' $f$ over the two points $b$ and $a$, with a multiplication by $-1$ attached to the evaluation at $a$. The generalization of this is the generalized Stokes theorem: $$\int_C dw = \int_{\partial C} w$$ where $w$ is a differential form , $d$ is the exterior derivative , $C$ is a manifold on which $dw$ is defined, and $\partial$ is the boundary operator, which maps a manifold $C$ to its boundary. This can be made to look pretty suggestive by writing integration of a form over a manifold using inner product notation: $$\langle C, w \rangle \equiv \int_Cw$$ in which case Stokes' theorem becomes $$\langle C, dw \rangle = \langle \partial C, w \rangle$$ which looks suspiciously like $\partial$ is the Hermitian adjoint of $d$. But is that really the case? Differential forms and manifolds seem pretty different to me. If they are, in fact, related in this way, is there a theory which expounds upon this relation, generalizes it, or puts it in context with other areas of mathematics?","The (second) fundamental theorem of calculus says that $$\int_a^b f'(x) dx = f(b) - f(a)$$ which can also be stated, if one knows enough about what's coming next, as: The integral of the derivative of a function over an interval is the same as the function evaluated at the (signed) boundary of the interval. where I had to insert the word 'signed' to make it clear that there's an implicit multiplication by $-1$ when you evaluate the function at the 'bottom' end of the integral. If we wrote the right-hand side of the expression as $$f(b) + (-1) f(a)$$ then even a high-school student could probably be persuaded that this is the same as 'integrating' $f$ over the two points $b$ and $a$, with a multiplication by $-1$ attached to the evaluation at $a$. The generalization of this is the generalized Stokes theorem: $$\int_C dw = \int_{\partial C} w$$ where $w$ is a differential form , $d$ is the exterior derivative , $C$ is a manifold on which $dw$ is defined, and $\partial$ is the boundary operator, which maps a manifold $C$ to its boundary. This can be made to look pretty suggestive by writing integration of a form over a manifold using inner product notation: $$\langle C, w \rangle \equiv \int_Cw$$ in which case Stokes' theorem becomes $$\langle C, dw \rangle = \langle \partial C, w \rangle$$ which looks suspiciously like $\partial$ is the Hermitian adjoint of $d$. But is that really the case? Differential forms and manifolds seem pretty different to me. If they are, in fact, related in this way, is there a theory which expounds upon this relation, generalizes it, or puts it in context with other areas of mathematics?",,"['calculus', 'differential-geometry', 'intuition', 'manifolds', 'exterior-algebra']"
15,Why is the gradient always perpendicular to level curves?,Why is the gradient always perpendicular to level curves?,,"Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a function. A level set is a set of points: $$L(c) = \{x \in \mathbb{R}^n | f(x) = c\}$$ Two vectors $a, b \in \mathbb{R}^n$ are perpendicular, when their dot product is 0: $$a \perp b :\Leftrightarrow a \cdot b = \sum_{i=1}^n a_i b_i = 0$$ The gradient of $f$ is $$\nabla f = \begin{pmatrix}\frac{\partial f}{\partial x_1}\\ \frac{\partial f}{\partial x_2}\\ \dots\\ \frac{\partial f}{\partial x_n}\\\end{pmatrix}$$ Question Why is $\nabla f(p)$ at any given point $p \in \mathbb{R}^n$ perpendicular to the level set $L(f(p))$? What does it mean anyway to be perpendicular to the level set? Does it mean the tangent of the level set in this point is perpendicular to the gradient in this point? How do I get the tangent? Are there any important implications of this? Context I found the question ""why is the level curve perpendicular to the gradient"" in an exam protocol for probabilistic planning.","Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a function. A level set is a set of points: $$L(c) = \{x \in \mathbb{R}^n | f(x) = c\}$$ Two vectors $a, b \in \mathbb{R}^n$ are perpendicular, when their dot product is 0: $$a \perp b :\Leftrightarrow a \cdot b = \sum_{i=1}^n a_i b_i = 0$$ The gradient of $f$ is $$\nabla f = \begin{pmatrix}\frac{\partial f}{\partial x_1}\\ \frac{\partial f}{\partial x_2}\\ \dots\\ \frac{\partial f}{\partial x_n}\\\end{pmatrix}$$ Question Why is $\nabla f(p)$ at any given point $p \in \mathbb{R}^n$ perpendicular to the level set $L(f(p))$? What does it mean anyway to be perpendicular to the level set? Does it mean the tangent of the level set in this point is perpendicular to the gradient in this point? How do I get the tangent? Are there any important implications of this? Context I found the question ""why is the level curve perpendicular to the gradient"" in an exam protocol for probabilistic planning.",,"['calculus', 'multivariable-calculus', 'vector-analysis']"
16,Proving that $~\sum\limits_{k=2}^{\infty}\frac{(-1)^k}{k^2}~H_k~H_{k-1}=\frac{3}{16}~\zeta(4)$,Proving that,~\sum\limits_{k=2}^{\infty}\frac{(-1)^k}{k^2}~H_k~H_{k-1}=\frac{3}{16}~\zeta(4),"To show that  $$\sum\limits_{k=2}^{\infty} \frac{(-1)^{k}}{k^{2}} \, \left(1+\frac{1}{2}+...+\frac{1}{k}\right) \cdot \left(1+\frac{1}{2}+...+\frac{1}{k-1}\right) = \frac{3}{16}\zeta(4).$$ I came across this when trying to solve a problem from the current edition of the American Mathematical Monthly. Is there some easy way to show this? I checked numerically that this series does converge to the value of $\frac{3}{16}\zeta(4)$. Note : An alternate form, with $H_{n}$ being the harmonic numbers, is: $$ \sum\limits_{k=2}^{\infty} \frac{(-1)^{k}}{k^{2}} \, H_{k} \, H_{k-1} = \frac{3}{16}\zeta(4). $$","To show that  $$\sum\limits_{k=2}^{\infty} \frac{(-1)^{k}}{k^{2}} \, \left(1+\frac{1}{2}+...+\frac{1}{k}\right) \cdot \left(1+\frac{1}{2}+...+\frac{1}{k-1}\right) = \frac{3}{16}\zeta(4).$$ I came across this when trying to solve a problem from the current edition of the American Mathematical Monthly. Is there some easy way to show this? I checked numerically that this series does converge to the value of $\frac{3}{16}\zeta(4)$. Note : An alternate form, with $H_{n}$ being the harmonic numbers, is: $$ \sum\limits_{k=2}^{\infty} \frac{(-1)^{k}}{k^{2}} \, H_{k} \, H_{k-1} = \frac{3}{16}\zeta(4). $$",,"['calculus', 'sequences-and-series', 'definite-integrals', 'contest-math', 'harmonic-numbers']"
17,Proof of a Ramanujan Integral,Proof of a Ramanujan Integral,,"While studying Ramanujan's Collected Papers I came across a paper titled ""Some Definite Integrals"" which appeared in Messenger of Mathematics , ${\tt XLIV}, 1915, \mbox{10-18}$ . It contains lot of weird integrals for which Ramanujan has given proofs. However in one instance he discusses about the integral \begin{align} &\int_{0}^{\infty}\frac{dx}{\left(1 + x^{2}\right)\left(1 + r^{2}x^{2}\right)\left(1 + r^{4}x^{2}\right)\cdots} \\[5mm] = &\ \frac{\pi}{2\left(1 + r + r^{3} + r^{6} + r^{10} + \cdots\right)}\label{1}\tag{1} \end{align} where $0 < r < 1$ . Ramanujan derives this formula from \begin{align} &\int_{0}^{\infty}\frac{\left(1 + arx\right)\left(1 + ar^{2}x\right)\cdots}{\left(1 + x\right)\left(1 + rx\right)\left(1 + r^{2}x\right)\cdots}x^{n - 1}\,\mathrm{d}x \\[5mm] = &\ \frac{\pi}{\sin\left(n\pi\right)} \prod_{m = 1}^{\infty}\frac{\left(1 - r^{m - n}\,\,\right)\left(1 - ar^{m}\,\right)}{\left(1 - r^{m}\,\right)\left(1 - ar^{m - n}\,\,\right)}\label{2}\tag{2} \end{align} where $0 < r < 1, n > 0, 0 < a < r^{n - 1}$ and $n$ is not an integer and $a$ is not of the form $a = r^{p}$ where $p$ is a positive integer. Unfortunately, Ramanujan does not prove the formula (\ref{2}). Is there any direct approach to establish (\ref{1}) without using (\ref{2}) or some way to establish (\ref{2}) $?$ .","While studying Ramanujan's Collected Papers I came across a paper titled ""Some Definite Integrals"" which appeared in Messenger of Mathematics , . It contains lot of weird integrals for which Ramanujan has given proofs. However in one instance he discusses about the integral where . Ramanujan derives this formula from where and is not an integer and is not of the form where is a positive integer. Unfortunately, Ramanujan does not prove the formula (\ref{2}). Is there any direct approach to establish (\ref{1}) without using (\ref{2}) or some way to establish (\ref{2}) .","{\tt XLIV}, 1915, \mbox{10-18} \begin{align}
&\int_{0}^{\infty}\frac{dx}{\left(1 + x^{2}\right)\left(1 + r^{2}x^{2}\right)\left(1 + r^{4}x^{2}\right)\cdots}
\\[5mm] = &\ \frac{\pi}{2\left(1 + r + r^{3} + r^{6} + r^{10} + \cdots\right)}\label{1}\tag{1}
\end{align} 0 < r < 1 \begin{align}
&\int_{0}^{\infty}\frac{\left(1 + arx\right)\left(1 + ar^{2}x\right)\cdots}{\left(1 + x\right)\left(1 + rx\right)\left(1 + r^{2}x\right)\cdots}x^{n - 1}\,\mathrm{d}x
\\[5mm] = &\
\frac{\pi}{\sin\left(n\pi\right)}
\prod_{m = 1}^{\infty}\frac{\left(1 - r^{m - n}\,\,\right)\left(1 - ar^{m}\,\right)}{\left(1 - r^{m}\,\right)\left(1 - ar^{m - n}\,\,\right)}\label{2}\tag{2}
\end{align} 0 < r < 1, n > 0, 0 < a < r^{n - 1} n a a = r^{p} p ?","['calculus', 'definite-integrals', 'improper-integrals']"
18,"How to prove $\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x=G^2$?",How to prove ?,"\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x=G^2","A while back I made a post asking for examples of integrals which evaluated to famous irrational constants (or constants that were very likely irrational but yet unproven to be). The top answer in said post was by Quanto, who posted this equation: $$\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x=G^2 $$ where $G$ is Catalan's constant . I decided to try and prove said equation. These were my attempts: Attempt 1: The integral can be split into a linear combination of the $2$ integrals $I_1 = \int_0^1 \frac{\arctan^2(x)\ln\left(x\right)}x \, \mathrm{d}x$ and $I_2 = \int_0^1 \frac{\arctan^2(x)\ln\left(1-x\right)}x \, \mathrm{d}x$ such that the original integral $I = I_1 - 2I_2$ . The first integral was evaluated in this answer to be $$ \int_0^1 \frac{\arctan^2(x)\ln\left(x\right)}x \, \mathrm{d}x = \operatorname{Li}_4 \left (\frac{1}{2} \right ) - \frac{151 \pi^4}{11520} + \frac{7}{8} \zeta (3) \ln(2) - \frac{\pi^2}{24} \ln^2(2) + \frac{1}{24} \ln^4(2) $$ Following the same steps used to evaluate $I_1$ for $I_2$ we get \begin{align*} \int_{0}^{1}\frac{\arctan^2(x)\ln\left(1-x\right)}x \, \mathrm{d}x & =-\frac{\pi^4}{96} + 2\int_{0}^{1}\frac{\arctan(x)\, \mathrm{Li}_2(x)}{x^2+1} \, \mathrm{d}x\\ & = -\frac{\pi^4}{96} - 2\int_0^1 \int_0^1\frac{\arctan(x) \ln(1-xy)}{(x^2+1)y}\, \mathrm{d}y \, \mathrm{d}x \end{align*} which I couldn't find a way to continue evaluating even exploiting the change of the order of integration. Attempt 2: Trying the substitution $u = \frac{1-x}{1+x}$ gives \begin{align*} \int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x  \, \mathrm{d}x & = \int_{0}^{1} \left( \frac{\pi}{4} - \arctan(u) \right)^2 \ln\left(\frac{1-u^2}{4u^2} \right)\frac{2}{1-u^2} \, \mathrm{d}u \end{align*} This allows us to split the integral into several other integrals, however, several of the resulting integrals seemed to me equally hard to evaluate compared to the original. So I felt this approach was more akin to cutting off one hydra head, just to have two more take its place. Attempt 3: I noticed that given real numbers $a, l$ then $\Re\{l^3 - (l + ia)^3\} = 3a^2l$ . This meant that taking $a = \arctan(x)$ and $l = \ln\left(\frac{x}{(1-x)^2} \right)$ we could get: $$ \int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x  = \frac{1}{3}\Re \left\{ \int_{0}^{1}\left[ \ln^3\left(\frac{x}{(1-x)^2} \right)- \frac{1}{2^3} \ln^3\left( \frac{(i-x)x^2}{(i+x)(1-x)^4}\right)\right] \frac{\mathrm{d}x}{x}\right\} $$ which I had the hopes of being able to split up, but unfortunately the integrals don't converge separately. Since the final result is so concise, I have hopes that there's a clever way to evaluate the integral which avoids going into all the polylogarithm-territory where similar integral evaluations end up going to. I suspect (with no evidence, though) that the integral can be cleverly split up into a separable double integral, where each of the individual integrals would evaluate to $G$ by themselves (and hence their product resulting in $G^2$ ). This would kind of be like doing the evaluation of the Gaussian integral in reverse, starting at the single integral $I = 2\pi \int_{0}^{\infty}e^{-x^2} x \, \mathrm{d}x$ and then splitting it into $\left(\int_{\mathbb{R}}e^{-x^2} \, \mathrm{d}x\right)\left(\int_{\mathbb{R}}e^{-y^2} \, \mathrm{d}y\right)$ , except that in this case the resulting product of integrals would be a product of known integral representations of Catalan's constant. But this is only conjecture as I haven't been able to spot a clever way to do this. Does anyone have any ideas on how to evaluate this integral? Either by continuing/improving on my attempts or trying something else entirely, everything is welcome. Thank you very much!","A while back I made a post asking for examples of integrals which evaluated to famous irrational constants (or constants that were very likely irrational but yet unproven to be). The top answer in said post was by Quanto, who posted this equation: where is Catalan's constant . I decided to try and prove said equation. These were my attempts: Attempt 1: The integral can be split into a linear combination of the integrals and such that the original integral . The first integral was evaluated in this answer to be Following the same steps used to evaluate for we get which I couldn't find a way to continue evaluating even exploiting the change of the order of integration. Attempt 2: Trying the substitution gives This allows us to split the integral into several other integrals, however, several of the resulting integrals seemed to me equally hard to evaluate compared to the original. So I felt this approach was more akin to cutting off one hydra head, just to have two more take its place. Attempt 3: I noticed that given real numbers then . This meant that taking and we could get: which I had the hopes of being able to split up, but unfortunately the integrals don't converge separately. Since the final result is so concise, I have hopes that there's a clever way to evaluate the integral which avoids going into all the polylogarithm-territory where similar integral evaluations end up going to. I suspect (with no evidence, though) that the integral can be cleverly split up into a separable double integral, where each of the individual integrals would evaluate to by themselves (and hence their product resulting in ). This would kind of be like doing the evaluation of the Gaussian integral in reverse, starting at the single integral and then splitting it into , except that in this case the resulting product of integrals would be a product of known integral representations of Catalan's constant. But this is only conjecture as I haven't been able to spot a clever way to do this. Does anyone have any ideas on how to evaluate this integral? Either by continuing/improving on my attempts or trying something else entirely, everything is welcome. Thank you very much!","\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x=G^2  G 2 I_1 = \int_0^1 \frac{\arctan^2(x)\ln\left(x\right)}x \, \mathrm{d}x I_2 = \int_0^1 \frac{\arctan^2(x)\ln\left(1-x\right)}x \, \mathrm{d}x I = I_1 - 2I_2 
\int_0^1 \frac{\arctan^2(x)\ln\left(x\right)}x \, \mathrm{d}x = \operatorname{Li}_4 \left (\frac{1}{2} \right ) - \frac{151 \pi^4}{11520} + \frac{7}{8} \zeta (3) \ln(2) - \frac{\pi^2}{24} \ln^2(2) + \frac{1}{24} \ln^4(2)
 I_1 I_2 \begin{align*}
\int_{0}^{1}\frac{\arctan^2(x)\ln\left(1-x\right)}x \, \mathrm{d}x & =-\frac{\pi^4}{96} + 2\int_{0}^{1}\frac{\arctan(x)\, \mathrm{Li}_2(x)}{x^2+1} \, \mathrm{d}x\\
& = -\frac{\pi^4}{96} - 2\int_0^1 \int_0^1\frac{\arctan(x) \ln(1-xy)}{(x^2+1)y}\, \mathrm{d}y \, \mathrm{d}x
\end{align*} u = \frac{1-x}{1+x} \begin{align*}
\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x  \, \mathrm{d}x & = \int_{0}^{1} \left( \frac{\pi}{4} - \arctan(u) \right)^2 \ln\left(\frac{1-u^2}{4u^2} \right)\frac{2}{1-u^2} \, \mathrm{d}u
\end{align*} a, l \Re\{l^3 - (l + ia)^3\} = 3a^2l a = \arctan(x) l = \ln\left(\frac{x}{(1-x)^2} \right) 
\int_0^1 \frac{\arctan^2(x)\ln\left(\frac{x}{(1-x)^2}\right)}x \, \mathrm{d}x  = \frac{1}{3}\Re \left\{ \int_{0}^{1}\left[ \ln^3\left(\frac{x}{(1-x)^2} \right)- \frac{1}{2^3} \ln^3\left( \frac{(i-x)x^2}{(i+x)(1-x)^4}\right)\right] \frac{\mathrm{d}x}{x}\right\}
 G G^2 I = 2\pi \int_{0}^{\infty}e^{-x^2} x \, \mathrm{d}x \left(\int_{\mathbb{R}}e^{-x^2} \, \mathrm{d}x\right)\left(\int_{\mathbb{R}}e^{-y^2} \, \mathrm{d}y\right)","['calculus', 'integration', 'definite-integrals', 'closed-form', 'catalans-constant']"
19,Limit of $\lim_{x\rightarrow 1}\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\sqrt[5]{x-.....}}}}$,Limit of,\lim_{x\rightarrow 1}\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\sqrt[5]{x-.....}}}},"I known how to find the limit of my last question which was Finding $\lim_{x\rightarrow 1}\sqrt{x-\sqrt{x-\sqrt{x-\sqrt{x....}}}}$ , but I couldn't how to start to find the limit of $$\lim_{x\rightarrow 1}\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\sqrt[5]{x-.....}}}}$$     so I used  a program written in visual basic 6 to calculate it.I found the limit about equal to $29/30$ but I am not sure if this value is right because the accuracy of this language not enough to give me a trust value. Anyhow,I want to know how to find the limit analytically.","I known how to find the limit of my last question which was Finding $\lim_{x\rightarrow 1}\sqrt{x-\sqrt{x-\sqrt{x-\sqrt{x....}}}}$ , but I couldn't how to start to find the limit of $$\lim_{x\rightarrow 1}\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\sqrt[5]{x-.....}}}}$$     so I used  a program written in visual basic 6 to calculate it.I found the limit about equal to $29/30$ but I am not sure if this value is right because the accuracy of this language not enough to give me a trust value. Anyhow,I want to know how to find the limit analytically.",,"['calculus', 'limits']"
20,Strange closed forms for hypergeometric functions,Strange closed forms for hypergeometric functions,,"So in the process of trying to find a derivation for this answer, the following interesting equalities arose (one can check with Wolfram Alpha/Mathematica): $$\frac{8\sqrt{2}G^4}{5\pi^2} \left(\left(7 \sqrt{2}-10\right) \beta +5 \left(\sqrt{2}-2\right)\right) = -\pi/2,\tag1$$ $$-\frac{4}{3} \left(\alpha\left(\sqrt{2}-1\right)^2 +6 \ln \left(\sqrt{2}-1\right)\right) = 7\ln 2 - \ln(17-12\sqrt{2})-\pi/2,\tag2$$ where $G = \Gamma\left(\frac{3}{4}\right)$, $\alpha = {}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right)$ and $\beta = {}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right)$. Doing some simplification and solving will tell you: $${}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right) = \frac{3}{4}\cdot\frac{\pi/2-7\ln{2}-4\ln(\sqrt{2}-1)}{(\sqrt{2}-1)^2},\tag4$$ $${}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right) = \frac{5}{4}\cdot\frac{(\pi/2)^3-4(\sqrt{2}-1)G^4}{G^4(\sqrt{2}-1)^3}.\tag5$$ It's very bizarre that aside from the Gamma function valued at 3/4, these come out to (relatively) nice closed forms. My guess is that they are a result of integrals, but I have no idea what those integrals could be. Mathematica doesn't get anywhere with the hypergeometric functions, so I'm a bit stuck. Note: $(\sqrt{2}-1)^2 = 3 - 2\sqrt{2}$. That last number seems to come out, sort of, in the result of the hypergeometric functions' closed form, but I can't place why. EDIT: Here are some ways of describing both functions simultaneously, which may help in some way: ${}_3F_2\left(a,b,c;c+\frac{1}{2},b+1;z\right)$, ${}_3F_2\left(a,b,c;c+\frac{1}{2},a+b;z\right)$, ${}_3F_2\left(a,b,b+\frac{1}{4};a+b-\frac{1}{4},a+b;z\right)$, ${}_3F_2\left(1,a,a+\frac{1}{4};a+\frac{3}{4},a+1;z\right)$","So in the process of trying to find a derivation for this answer, the following interesting equalities arose (one can check with Wolfram Alpha/Mathematica): $$\frac{8\sqrt{2}G^4}{5\pi^2} \left(\left(7 \sqrt{2}-10\right) \beta +5 \left(\sqrt{2}-2\right)\right) = -\pi/2,\tag1$$ $$-\frac{4}{3} \left(\alpha\left(\sqrt{2}-1\right)^2 +6 \ln \left(\sqrt{2}-1\right)\right) = 7\ln 2 - \ln(17-12\sqrt{2})-\pi/2,\tag2$$ where $G = \Gamma\left(\frac{3}{4}\right)$, $\alpha = {}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right)$ and $\beta = {}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right)$. Doing some simplification and solving will tell you: $${}_3F_2\left(1,1,\frac{5}{4};\frac{7}{4},2;3-2\sqrt{2}\right) = \frac{3}{4}\cdot\frac{\pi/2-7\ln{2}-4\ln(\sqrt{2}-1)}{(\sqrt{2}-1)^2},\tag4$$ $${}_3F_2\left(1,\frac{3}{2},\frac{7}{4};\frac{9}{4},\frac{5}{2};3-2\sqrt{2}\right) = \frac{5}{4}\cdot\frac{(\pi/2)^3-4(\sqrt{2}-1)G^4}{G^4(\sqrt{2}-1)^3}.\tag5$$ It's very bizarre that aside from the Gamma function valued at 3/4, these come out to (relatively) nice closed forms. My guess is that they are a result of integrals, but I have no idea what those integrals could be. Mathematica doesn't get anywhere with the hypergeometric functions, so I'm a bit stuck. Note: $(\sqrt{2}-1)^2 = 3 - 2\sqrt{2}$. That last number seems to come out, sort of, in the result of the hypergeometric functions' closed form, but I can't place why. EDIT: Here are some ways of describing both functions simultaneously, which may help in some way: ${}_3F_2\left(a,b,c;c+\frac{1}{2},b+1;z\right)$, ${}_3F_2\left(a,b,c;c+\frac{1}{2},a+b;z\right)$, ${}_3F_2\left(a,b,b+\frac{1}{4};a+b-\frac{1}{4},a+b;z\right)$, ${}_3F_2\left(1,a,a+\frac{1}{4};a+\frac{3}{4},a+1;z\right)$",,"['calculus', 'special-functions', 'gamma-function', 'closed-form', 'hypergeometric-function']"
21,Evaluate $\int_{0}^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\mathrm{d}\theta $,Evaluate,\int_{0}^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\mathrm{d}\theta ,"Evaluate $$\int_{0}^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\,\mathrm{d}\theta $$ Several days ago,I found this interesting integral from a paper about generalized log-sine integrals,but I can't remember the title of it. The answer of the integral is \begin{align*} -\mathrm{Ls}_{7}^{\left ( 3 \right )}\left ( \pi  \right)&=\frac{9}{35}\log^72+\frac{4}{5}\pi ^{2} \log^52+9\zeta \left ( 3 \right )\log^42-\frac{31}{30}\pi ^{4}\log^32\\ &-\left [ 72\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{9}{8}\zeta \left ( 5 \right )-\frac{51}{4}\pi ^{2}\zeta \left ( 3 \right ) \right ]\log^22\\ &+\left [ 72\mathrm{Li}_{5,1}\left ( \frac{1}{2} \right )-216\mathrm{Li}_6\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_4\left ( \frac{1}{2} \right ) \right ]\log2+72\mathrm{Li}_{6,1}\left ( \frac{1}{2} \right )\\ &-216\mathrm{Li}_7\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{1161}{32}\zeta \left ( 7 \right )-\frac{375}{32}\pi ^{2}\zeta \left ( 5 \right )+\frac{1}{10}\pi ^{4}\zeta \left ( 3 \right ) \end{align*} where $$\mathrm{Ls}_n^{\left ( k \right )}\left ( \alpha  \right ):=-\int_{0}^{\alpha }\theta ^{k}\log^{n-1-k}\left | 2\sin\frac{\theta }{2} \right |\mathrm{d}\theta $$ is the generalized log-sine integral and $$\mathrm{Li}_{\lambda ,1}\left ( z \right )=\sum_{k=1}^{\infty }\frac{z^{k}}{k^{\lambda }}\sum_{j=1}^{k-1}\frac{1}{j}$$ is the multiple polylogarithm. I found a beautiful way to solve the integrals below $$\int_{0}^{\frac{\pi }{2}}t^{2n}\log^{m}\left ( 2\cos t  \right )\mathrm{d}t $$ Let's consider $$\mathcal{I}\left ( x,y \right )=\int_{0}^{\frac{\pi }{2}}\cos\left ( xt \right )\left ( 2\cos t \right )^{y}\mathrm{d}t$$ By using Gamma function,the integral become $$\mathcal{I}\left ( x,y \right )=\frac{\pi \, \Gamma \left ( y+1 \right )}{2\Gamma \left ( \dfrac{x+y+2}{2} \right )\Gamma \left ( \dfrac{y-x+2}{2} \right )}$$ Then we can get $$\mathcal{I}\left ( x,y \right )=\frac{\pi }{2}\exp\left ( \sum_{k=2}^{\infty }\frac{\left ( -1 \right )^{k}}{k\cdot 2^{k}}\zeta \left ( k \right )\left [ \left ( 2y \right )^{k}-\left ( y-x \right )^{k}-\left ( x+y \right )^{k} \right ] \right )$$ On the other hand,using taylor series $$\mathcal{I}\left ( x,y \right )=\sum_{n=0}^{\infty }\frac{\left ( -1 \right )^{n}}{\left ( 2n \right )!}x^{2n}\sum_{m=0}^{\infty }\frac{y^{m}}{m!}\int_{0}^{\frac{\pi }{2}}t^{2n}\log^m\left ( 2\cos t \right )\mathrm{d}t$$ So,the comparison of coefficient shows the answer.For example $$\int_{0}^{\frac{\pi }{2}}t^{2}\log^2\left ( 2\cos t \right )\mathrm{d}t=4\cdot \frac{\pi }{2}\left [ \frac{12}{4\cdot 16} \zeta \left ( 4 \right )+\frac{1}{2}\frac{8}{2^{2}\cdot 4^{2}}\zeta \left ( 2 \right )^{2}\right ]=\frac{11}{1440}\pi ^{5}$$ I wonder can we use the same way to prove the integral in the beginning,if not,is there another way to handle it?","Evaluate Several days ago,I found this interesting integral from a paper about generalized log-sine integrals,but I can't remember the title of it. The answer of the integral is where is the generalized log-sine integral and is the multiple polylogarithm. I found a beautiful way to solve the integrals below Let's consider By using Gamma function,the integral become Then we can get On the other hand,using taylor series So,the comparison of coefficient shows the answer.For example I wonder can we use the same way to prove the integral in the beginning,if not,is there another way to handle it?","\int_{0}^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\,\mathrm{d}\theta  \begin{align*}
-\mathrm{Ls}_{7}^{\left ( 3 \right )}\left ( \pi  \right)&=\frac{9}{35}\log^72+\frac{4}{5}\pi ^{2} \log^52+9\zeta \left ( 3 \right )\log^42-\frac{31}{30}\pi ^{4}\log^32\\
&-\left [ 72\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{9}{8}\zeta \left ( 5 \right )-\frac{51}{4}\pi ^{2}\zeta \left ( 3 \right ) \right ]\log^22\\
&+\left [ 72\mathrm{Li}_{5,1}\left ( \frac{1}{2} \right )-216\mathrm{Li}_6\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_4\left ( \frac{1}{2} \right ) \right ]\log2+72\mathrm{Li}_{6,1}\left ( \frac{1}{2} \right )\\
&-216\mathrm{Li}_7\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{1161}{32}\zeta \left ( 7 \right )-\frac{375}{32}\pi ^{2}\zeta \left ( 5 \right )+\frac{1}{10}\pi ^{4}\zeta \left ( 3 \right )
\end{align*} \mathrm{Ls}_n^{\left ( k \right )}\left ( \alpha  \right ):=-\int_{0}^{\alpha }\theta ^{k}\log^{n-1-k}\left | 2\sin\frac{\theta }{2} \right |\mathrm{d}\theta  \mathrm{Li}_{\lambda ,1}\left ( z \right )=\sum_{k=1}^{\infty }\frac{z^{k}}{k^{\lambda }}\sum_{j=1}^{k-1}\frac{1}{j} \int_{0}^{\frac{\pi }{2}}t^{2n}\log^{m}\left ( 2\cos t  \right )\mathrm{d}t  \mathcal{I}\left ( x,y \right )=\int_{0}^{\frac{\pi }{2}}\cos\left ( xt \right )\left ( 2\cos t \right )^{y}\mathrm{d}t \mathcal{I}\left ( x,y \right )=\frac{\pi \, \Gamma \left ( y+1 \right )}{2\Gamma \left ( \dfrac{x+y+2}{2} \right )\Gamma \left ( \dfrac{y-x+2}{2} \right )} \mathcal{I}\left ( x,y \right )=\frac{\pi }{2}\exp\left ( \sum_{k=2}^{\infty }\frac{\left ( -1 \right )^{k}}{k\cdot 2^{k}}\zeta \left ( k \right )\left [ \left ( 2y \right )^{k}-\left ( y-x \right )^{k}-\left ( x+y \right )^{k} \right ] \right ) \mathcal{I}\left ( x,y \right )=\sum_{n=0}^{\infty }\frac{\left ( -1 \right )^{n}}{\left ( 2n \right )!}x^{2n}\sum_{m=0}^{\infty }\frac{y^{m}}{m!}\int_{0}^{\frac{\pi }{2}}t^{2n}\log^m\left ( 2\cos t \right )\mathrm{d}t \int_{0}^{\frac{\pi }{2}}t^{2}\log^2\left ( 2\cos t \right )\mathrm{d}t=4\cdot \frac{\pi }{2}\left [ \frac{12}{4\cdot 16} \zeta \left ( 4 \right )+\frac{1}{2}\frac{8}{2^{2}\cdot 4^{2}}\zeta \left ( 2 \right )^{2}\right ]=\frac{11}{1440}\pi ^{5}","['calculus', 'integration', 'analysis', 'polylogarithm']"
22,When is $\sin x$ an algebraic number and when is it non-algebraic?,When is  an algebraic number and when is it non-algebraic?,\sin x,"Show that if $x$ is rational, then $\sin x$ is algebraic number when $x$ is in degrees and $\sin x$ is non algebraic when $x$ is in radians. Details: so we have $\sin(p/q)$ is algebraic when $p/q$ is in degrees, that is what my book says. of course $\sin (30^{\circ})$, $\sin 45^{\circ}$, $\sin 90^{\circ}$, and halves of them is algebraic. but I'm not so sure about $\sin(1^{\circ})$. Also is this is an existence proof or is there actually a way to show the full radical solution. One way to get this started is change degrees to radians. x deg = pi/180 * x radian.  So if x = p/q, then sin (p/q deg) = sin ( pi/180 * p/q rad). Therefore without loss of generality the question is show sin (pi*m/n rad) is algebraic. and then show sin (m/n rad) is non-algebraic.","Show that if $x$ is rational, then $\sin x$ is algebraic number when $x$ is in degrees and $\sin x$ is non algebraic when $x$ is in radians. Details: so we have $\sin(p/q)$ is algebraic when $p/q$ is in degrees, that is what my book says. of course $\sin (30^{\circ})$, $\sin 45^{\circ}$, $\sin 90^{\circ}$, and halves of them is algebraic. but I'm not so sure about $\sin(1^{\circ})$. Also is this is an existence proof or is there actually a way to show the full radical solution. One way to get this started is change degrees to radians. x deg = pi/180 * x radian.  So if x = p/q, then sin (p/q deg) = sin ( pi/180 * p/q rad). Therefore without loss of generality the question is show sin (pi*m/n rad) is algebraic. and then show sin (m/n rad) is non-algebraic.",,"['calculus', 'number-theory', 'trigonometry']"
23,A curious connection : What's the function $f(x)$?,A curious connection : What's the function ?,f(x),"Hello I was wondering what was the function $f$ defines like this : Let $f(x)$ a continuous and differentiable function such that :   $$f(x)=\sum_{k=0}^{\infty}\frac{f'(k)}{k!}(-x)^k$$ In fact can't solve it but it makes a connection between Ramanujan's Master theorem and Frullani's integral via the Fundamental theorem of calculus I explain  : We have : $$\int_{0}^{\infty}x^{-s-1}f(x)dx=\Gamma{(-s)}f'(s)$$ Or : $$\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dx=f'(s)$$ Now we use the Fundamental theorem of calculus to get : $$\int_{0}^{s}\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dxds=f(s)-f(0)$$ Now we take the limit to get : $$\lim_{s\to\infty}\int_{0}^{s}\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dxds=f(\infty)-f(0)$$ Wich is equal to : $$\int_{0}^{\infty}\frac{f(ax)-f(bx)}{ln(\frac{a}{b})x}$$ So my question is what is the function $f(x)$ , there exists a closed form to this ,is it trivial or not ? Thanks Ps:I know it's not very rigorous but I think it's interesting","Hello I was wondering what was the function $f$ defines like this : Let $f(x)$ a continuous and differentiable function such that :   $$f(x)=\sum_{k=0}^{\infty}\frac{f'(k)}{k!}(-x)^k$$ In fact can't solve it but it makes a connection between Ramanujan's Master theorem and Frullani's integral via the Fundamental theorem of calculus I explain  : We have : $$\int_{0}^{\infty}x^{-s-1}f(x)dx=\Gamma{(-s)}f'(s)$$ Or : $$\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dx=f'(s)$$ Now we use the Fundamental theorem of calculus to get : $$\int_{0}^{s}\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dxds=f(s)-f(0)$$ Now we take the limit to get : $$\lim_{s\to\infty}\int_{0}^{s}\int_{0}^{\infty}\frac{x^{-s-1}f(x)}{\Gamma{(-s)}}dxds=f(\infty)-f(0)$$ Wich is equal to : $$\int_{0}^{\infty}\frac{f(ax)-f(bx)}{ln(\frac{a}{b})x}$$ So my question is what is the function $f(x)$ , there exists a closed form to this ,is it trivial or not ? Thanks Ps:I know it's not very rigorous but I think it's interesting",,['calculus']
24,"Does integration by parts with ""deja vu"" have a name?","Does integration by parts with ""deja vu"" have a name?",,"In some integration by parts problems, such as evaluating the integral of $e^x \cos x$ or $\sec^ 3 x$, one performs integration by parts (possibly more than once, and possibly together with algebraic manipulations) and eventually the original integral appears again. To beginning students, this may superficially appear to be ""circular reasoning"" that doesn't solve the problem.  But it does, because if we have $\int f(x) dx = g(x) + K \int f(x) dx$ where $K \ne 1$, then rearranging gives $\int f(x) dx = \frac{1}{1-K} g(x)$. My question: Does this technique have a commonly used name? I once saw it called ""integration by parts with deja vu"" in some supplemental study materials for a calculus course.  I don't know who thought of that name but I've taken to using it with my students.","In some integration by parts problems, such as evaluating the integral of $e^x \cos x$ or $\sec^ 3 x$, one performs integration by parts (possibly more than once, and possibly together with algebraic manipulations) and eventually the original integral appears again. To beginning students, this may superficially appear to be ""circular reasoning"" that doesn't solve the problem.  But it does, because if we have $\int f(x) dx = g(x) + K \int f(x) dx$ where $K \ne 1$, then rearranging gives $\int f(x) dx = \frac{1}{1-K} g(x)$. My question: Does this technique have a commonly used name? I once saw it called ""integration by parts with deja vu"" in some supplemental study materials for a calculus course.  I don't know who thought of that name but I've taken to using it with my students.",,"['calculus', 'integration', 'ring-theory', 'terminology']"
25,"A closed form for $\int_0^\infty\left(\frac{2^{-x}-3^{-x}}x\right)^adx,\ a\notin\mathbb{Z}^+$",A closed form for,"\int_0^\infty\left(\frac{2^{-x}-3^{-x}}x\right)^adx,\ a\notin\mathbb{Z}^+","Let $$I(a)=\int_0^\infty\left(\frac{2^{-x}-3^{-x}}x\right)^adx.$$ $I(a)$ has closed form representations for all $a\in\mathbb{Z}^+$. Is there any algebraic (or at least period ) $a\notin\mathbb{Z}^+$ such that $I(a)$ has a closed form representation? In particular, does $\displaystyle I\left(\frac12\right)=\int_0^\infty\sqrt{\frac{2^{-x}-3^{-x}\vphantom|}{x}}\ dx\ $ have a closed form representation?","Let $$I(a)=\int_0^\infty\left(\frac{2^{-x}-3^{-x}}x\right)^adx.$$ $I(a)$ has closed form representations for all $a\in\mathbb{Z}^+$. Is there any algebraic (or at least period ) $a\notin\mathbb{Z}^+$ such that $I(a)$ has a closed form representation? In particular, does $\displaystyle I\left(\frac12\right)=\int_0^\infty\sqrt{\frac{2^{-x}-3^{-x}\vphantom|}{x}}\ dx\ $ have a closed form representation?",,"['calculus', 'integration', 'definite-integrals', 'exponential-function', 'closed-form']"
26,How do I generalize the derivatives / integrals from multivariable calc?,How do I generalize the derivatives / integrals from multivariable calc?,,"$\newcommand{\RR}{\mathbb{R}}$ This is a long post, so I'll put the big question right at the top: There's a whole lot of derivative-like and integral-like operations. Are they special cases of some larger derivative/integral? Lots of Derivatives and Integrals , or This Isn't Even My Final Form When I was first introduced to calculus, we learned three kinds of derivatives/integrals of a single-variable function: $$ \begin{array}{|c|c|c|c|} \hline \textbf{Name} & \textbf{Symbolic} & \textbf{Type of } f \textrm{ ( or } F \textrm{ )} & \textbf{Output Type} \\ \hline \textrm{Derivative} & \frac{df}{dx} & \RR \to \RR & \RR \to \RR \\ \hline \textrm{Indefinite Integral} & \int f~dx & \RR \to \RR & \RR \to (\RR \to \RR) \\ \hline \textrm{Definite Integral} & \int_a^b f~dx & \RR \to \RR & \RR \\ \hline \end{array} $$ But in multivariable, we learned several new types for multivariate functions. $$ \begin{array}{|c|c|c|c|} \hline \textrm{Partial Derivative} & \frac{\partial f}{\partial x} & \RR^n \to \RR & \RR^n \to \RR \\ \hline \textrm{Gradient} & \nabla f & \RR^n \to \RR & \RR^n \to \RR^n \\ \hline \textrm{Area/Volume Integral}^\ast & \int_A f~dA & \RR^n \to \RR & \RR \\ \hline \textrm{Line/Surface Integral}^{\ast\ast} & \int_\gamma f~ds & \RR^n \to \RR & \RR \\ \hline \textrm{Laplacian} & \nabla^2 f & \RR^n \to \RR & \RR^n \to \RR \\ \hline \end{array} $$ When we consider vector-valued functions, we get still more. (little $f$ changed to big $F$ for convention's sake) $$ \begin{array}{|c|c|c|c|} \hline \textrm{Partial Derivative} & \frac{\partial F}{\partial x} & \RR^n \to \RR^m & \RR^n \to \RR^m \\ \hline \textrm{Area/Volume Integral}^\ast & \int_A F~dA & \RR^n \to \RR^m & \RR^m \\ \hline \textrm{Line/Surface Integral}^{\ast\ast} & \int_\gamma F~ds & \RR^n \to \RR^m & \RR^m \\ \hline \end{array} $$ As for the special case of $n = m$, a vector field, we have additional derivatives/integrals: $$ \begin{array}{|c|c|c|c|} \hline \textrm{Divergence} & \nabla \cdot F & \RR^n \to \RR^n & \RR^n \to \RR \\ \hline \textrm{Curl} & \nabla \times F & \RR^n \to \RR^n & \RR^n \to \RR^{???} \\ \hline \textrm{Flux Integral}^\dagger & \int_S F \cdot \hat{n}dS & \RR^n \to \RR^n & \RR \\ \hline \textrm{Work Integral}^{\dagger\dagger} & \int_\gamma F \cdot d\vec{r} & \RR^n \to \RR^n & \RR \\ \hline \end{array} $$ And then there's the Jacobian, which seems like a kind of derivative, but it's between coordinate systems. $^\ast~~$ $A$ must have dimension exactly $n$ $^{\ast\ast}~$ $\gamma$ can take any dimension less than $n$ $^\dagger~~$ $S$ must have dimension $n - 1$ $^{\dagger\dagger}~$ $\gamma$ must have dimension $1$ Observations Derivatives are all functions. Integrals are just scalars/vectors. Except the indefinite integral, but perhaps that doesn't actually belong? Or I guess you could treat them as functions that accept a line/surface/etc. Things That Are Special Cases Of Other Things , aka, Motivation For This Question ""Normal"" derivatives are just partials with $n = 1$. Similarly, definite integrals are area/volume integrals where $n = 1$. Area/volume integrals seems to be a special case of line/surface integrals: when I do a surface integral with $S$ a subset of the $xy$-plane, I get just the equivalent area integral, but I can't verify for higher dimensions. We can 'extend' most operators componentwise for $f : \RR^n \to \RR$ to operators on $f : \RR^n \to \RR^m$. Examples: partial derivative and area/volume/line/surface integrals. Minor Questions (i.e., not the big one at the top, but probably answered by it): What's with the codomain of the curl? For $n = 2$, it's $1$, but for $n = 3$, it's $3$. I assume it doesn't become $5$ at $n = 4$, that seems somehow wrong. It seems to be $\binom{n}{2}$, because rotations occur in a plane, and there are $\binom{n}{2}$ ways to pick $2$ basis vectors to get ""basis planes"". The surfaces for work and flux integrals are fixed at dimensions $1$ and $n - 1$. Are there analogous ones for dimensions in between? If I 'extend' the gradient to a vector-valued function where $m = n$, then I get the Jacobian. But what if $m \ne n$? I can still compute it, but it's not a coordinate transform, nor does it have a determinant. Does this Jacobian-like derivative have any meaning? According to Wikipedia, the Jacobian of $F$ at a point $p$ is ""the best linear approximation of the function $F$ near the point $p$"". EDIT: two of them make sense now! Thanks for reading all this way! I'm sorry about the length; this is something that's bugged me since I learned multivariable, and I can't seem to get it any smaller. If it's too broad, could you just point me in the direction of a helpful textbook?","$\newcommand{\RR}{\mathbb{R}}$ This is a long post, so I'll put the big question right at the top: There's a whole lot of derivative-like and integral-like operations. Are they special cases of some larger derivative/integral? Lots of Derivatives and Integrals , or This Isn't Even My Final Form When I was first introduced to calculus, we learned three kinds of derivatives/integrals of a single-variable function: $$ \begin{array}{|c|c|c|c|} \hline \textbf{Name} & \textbf{Symbolic} & \textbf{Type of } f \textrm{ ( or } F \textrm{ )} & \textbf{Output Type} \\ \hline \textrm{Derivative} & \frac{df}{dx} & \RR \to \RR & \RR \to \RR \\ \hline \textrm{Indefinite Integral} & \int f~dx & \RR \to \RR & \RR \to (\RR \to \RR) \\ \hline \textrm{Definite Integral} & \int_a^b f~dx & \RR \to \RR & \RR \\ \hline \end{array} $$ But in multivariable, we learned several new types for multivariate functions. $$ \begin{array}{|c|c|c|c|} \hline \textrm{Partial Derivative} & \frac{\partial f}{\partial x} & \RR^n \to \RR & \RR^n \to \RR \\ \hline \textrm{Gradient} & \nabla f & \RR^n \to \RR & \RR^n \to \RR^n \\ \hline \textrm{Area/Volume Integral}^\ast & \int_A f~dA & \RR^n \to \RR & \RR \\ \hline \textrm{Line/Surface Integral}^{\ast\ast} & \int_\gamma f~ds & \RR^n \to \RR & \RR \\ \hline \textrm{Laplacian} & \nabla^2 f & \RR^n \to \RR & \RR^n \to \RR \\ \hline \end{array} $$ When we consider vector-valued functions, we get still more. (little $f$ changed to big $F$ for convention's sake) $$ \begin{array}{|c|c|c|c|} \hline \textrm{Partial Derivative} & \frac{\partial F}{\partial x} & \RR^n \to \RR^m & \RR^n \to \RR^m \\ \hline \textrm{Area/Volume Integral}^\ast & \int_A F~dA & \RR^n \to \RR^m & \RR^m \\ \hline \textrm{Line/Surface Integral}^{\ast\ast} & \int_\gamma F~ds & \RR^n \to \RR^m & \RR^m \\ \hline \end{array} $$ As for the special case of $n = m$, a vector field, we have additional derivatives/integrals: $$ \begin{array}{|c|c|c|c|} \hline \textrm{Divergence} & \nabla \cdot F & \RR^n \to \RR^n & \RR^n \to \RR \\ \hline \textrm{Curl} & \nabla \times F & \RR^n \to \RR^n & \RR^n \to \RR^{???} \\ \hline \textrm{Flux Integral}^\dagger & \int_S F \cdot \hat{n}dS & \RR^n \to \RR^n & \RR \\ \hline \textrm{Work Integral}^{\dagger\dagger} & \int_\gamma F \cdot d\vec{r} & \RR^n \to \RR^n & \RR \\ \hline \end{array} $$ And then there's the Jacobian, which seems like a kind of derivative, but it's between coordinate systems. $^\ast~~$ $A$ must have dimension exactly $n$ $^{\ast\ast}~$ $\gamma$ can take any dimension less than $n$ $^\dagger~~$ $S$ must have dimension $n - 1$ $^{\dagger\dagger}~$ $\gamma$ must have dimension $1$ Observations Derivatives are all functions. Integrals are just scalars/vectors. Except the indefinite integral, but perhaps that doesn't actually belong? Or I guess you could treat them as functions that accept a line/surface/etc. Things That Are Special Cases Of Other Things , aka, Motivation For This Question ""Normal"" derivatives are just partials with $n = 1$. Similarly, definite integrals are area/volume integrals where $n = 1$. Area/volume integrals seems to be a special case of line/surface integrals: when I do a surface integral with $S$ a subset of the $xy$-plane, I get just the equivalent area integral, but I can't verify for higher dimensions. We can 'extend' most operators componentwise for $f : \RR^n \to \RR$ to operators on $f : \RR^n \to \RR^m$. Examples: partial derivative and area/volume/line/surface integrals. Minor Questions (i.e., not the big one at the top, but probably answered by it): What's with the codomain of the curl? For $n = 2$, it's $1$, but for $n = 3$, it's $3$. I assume it doesn't become $5$ at $n = 4$, that seems somehow wrong. It seems to be $\binom{n}{2}$, because rotations occur in a plane, and there are $\binom{n}{2}$ ways to pick $2$ basis vectors to get ""basis planes"". The surfaces for work and flux integrals are fixed at dimensions $1$ and $n - 1$. Are there analogous ones for dimensions in between? If I 'extend' the gradient to a vector-valued function where $m = n$, then I get the Jacobian. But what if $m \ne n$? I can still compute it, but it's not a coordinate transform, nor does it have a determinant. Does this Jacobian-like derivative have any meaning? According to Wikipedia, the Jacobian of $F$ at a point $p$ is ""the best linear approximation of the function $F$ near the point $p$"". EDIT: two of them make sense now! Thanks for reading all this way! I'm sorry about the length; this is something that's bugged me since I learned multivariable, and I can't seem to get it any smaller. If it's too broad, could you just point me in the direction of a helpful textbook?",,"['calculus', 'multivariable-calculus']"
27,Closed form for $\int_0^\infty\frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x\phantom{|}}\sqrt{x^2+1}}e^{-x}dx$,Closed form for,\int_0^\infty\frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x\phantom{|}}\sqrt{x^2+1}}e^{-x}dx,Is it possible to evaluate this integral in a closed form? $$\int_0^\infty\frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x\phantom{|}}\sqrt{x^2+1}}e^{-x}dx$$,Is it possible to evaluate this integral in a closed form? $$\int_0^\infty\frac{\sqrt{x+\sqrt{x^2+1}}}{\sqrt{x\phantom{|}}\sqrt{x^2+1}}e^{-x}dx$$,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
28,"What is a good way to explain why the graph of polynomials do not exhibit ripples, even in an arbitrarily small interval?","What is a good way to explain why the graph of polynomials do not exhibit ripples, even in an arbitrarily small interval?",,"I was showing someone the graph of $0.1x^9+0.6x^5+0.5x^2 + x$ on Wolframalpha (for this question, any real valued polynomial will do) Someone asked me why the graphs of polynomials are smooth no matter what interval on $\mathbb{R}$ we look. More precisely, the person asked me why there isn't random ripples like or as we travel along the graph of the polynomial. Or using another example, imagine $x^2$, why isn't there a sinusoid like perturbation for this function in the range $(10000000018.3, 10000000019.1)$? A tinie tiny sinusoid? My answer was basically that we can check the derivative and see that it is always going up or down. However, I am not totally satisfied with this answer. So, what would be a good way to explain to someone why there isn't random oscillation (or ripples) in the interval (using another example, say) $(-398, -386)$ for the polynomial $x^{340} + 0.5x^{238} + 0.4x^{77} + 4$?","I was showing someone the graph of $0.1x^9+0.6x^5+0.5x^2 + x$ on Wolframalpha (for this question, any real valued polynomial will do) Someone asked me why the graphs of polynomials are smooth no matter what interval on $\mathbb{R}$ we look. More precisely, the person asked me why there isn't random ripples like or as we travel along the graph of the polynomial. Or using another example, imagine $x^2$, why isn't there a sinusoid like perturbation for this function in the range $(10000000018.3, 10000000019.1)$? A tinie tiny sinusoid? My answer was basically that we can check the derivative and see that it is always going up or down. However, I am not totally satisfied with this answer. So, what would be a good way to explain to someone why there isn't random oscillation (or ripples) in the interval (using another example, say) $(-398, -386)$ for the polynomial $x^{340} + 0.5x^{238} + 0.4x^{77} + 4$?",,"['calculus', 'algebra-precalculus', 'polynomials', 'intuition', 'elementary-functions']"
29,"For $f$ continuous, show $\lim_{n\to\infty} n\int_0^1 f(x)x^n\,dx = f(1).$","For  continuous, show","f \lim_{n\to\infty} n\int_0^1 f(x)x^n\,dx = f(1).","Suppose $f:[0,1]\to \mathbb{R}$ is continuous. Show that $$\lim_{n\to\infty} n\int_0^1 f(x)x^n\,dx = f(1).$$ My answer so far: First I want to assume that $f\in C^1$. Then $$n\int_0^1f(x)x^n\,dx = \left[\frac{n}{n+1}x^{n+1}f(x)\right]_0^1 - \frac{n}{n+1}\int_0^1 x^{n+1}f'(x)\, dx\\ \frac{n}{n+1}f(1) - \frac{n}{n+1}\int_0^1 x^{n+1}f'(x)\, dx,$$ which goes to $f(1)$ because the last integral goes to zero. But approximating $f$ by $\phi\in C^1$ won't necessarily work, because $\phi(1)$ may not equal $f(1)$... how can we finish the argument?","Suppose $f:[0,1]\to \mathbb{R}$ is continuous. Show that $$\lim_{n\to\infty} n\int_0^1 f(x)x^n\,dx = f(1).$$ My answer so far: First I want to assume that $f\in C^1$. Then $$n\int_0^1f(x)x^n\,dx = \left[\frac{n}{n+1}x^{n+1}f(x)\right]_0^1 - \frac{n}{n+1}\int_0^1 x^{n+1}f'(x)\, dx\\ \frac{n}{n+1}f(1) - \frac{n}{n+1}\int_0^1 x^{n+1}f'(x)\, dx,$$ which goes to $f(1)$ because the last integral goes to zero. But approximating $f$ by $\phi\in C^1$ won't necessarily work, because $\phi(1)$ may not equal $f(1)$... how can we finish the argument?",,"['calculus', 'integration', 'functional-analysis']"
30,Calculator similar to Desmos but for $3$D,Calculator similar to Desmos but for D,3,Is there a calculator with functionality similar to Desmos but in $3$ dimensions?  I am looking to learn about families of quadric surfaces so I am looking for a $3$ D calculator with sliders.,Is there a calculator with functionality similar to Desmos but in dimensions?  I am looking to learn about families of quadric surfaces so I am looking for a D calculator with sliders.,3 3,"['calculus', 'multivariable-calculus', 'soft-question', 'math-software', 'calculator']"
31,Exact Sum of Series,Exact Sum of Series,,"I am a tutor at university, and one of my students brought me this question, which I was unable to work out. It is from a past final exam in calculus II, so any response should be very basic in what machinery it uses, although it may be complicated. The series is: $$\sum \limits_{n=1}^{\infty} \frac{(-1)^n}{(2n+3)(3^n)}.$$ Normally I'm pretty good with infinite series. It is clear enough to me that this sum converges. None of the kind of obvious rearrangements yielded anything, and I couldn't come up with any smart tricks in the time we had. I put it into Wolfram and got a very striking answer indeed. Wolfram reports the value to be $\frac{1}{6}(16-3\sqrt{3} \pi)$. It does this using something it calls the ""Lerch Transcendent"" ( link here about Lerch) . After looking around, I think maybe I can understand how the summing is done, if you knew about this guy and special values it takes. But how could I do it as a calculus II student, never having seen anything like this monstrosity before?","I am a tutor at university, and one of my students brought me this question, which I was unable to work out. It is from a past final exam in calculus II, so any response should be very basic in what machinery it uses, although it may be complicated. The series is: $$\sum \limits_{n=1}^{\infty} \frac{(-1)^n}{(2n+3)(3^n)}.$$ Normally I'm pretty good with infinite series. It is clear enough to me that this sum converges. None of the kind of obvious rearrangements yielded anything, and I couldn't come up with any smart tricks in the time we had. I put it into Wolfram and got a very striking answer indeed. Wolfram reports the value to be $\frac{1}{6}(16-3\sqrt{3} \pi)$. It does this using something it calls the ""Lerch Transcendent"" ( link here about Lerch) . After looking around, I think maybe I can understand how the summing is done, if you knew about this guy and special values it takes. But how could I do it as a calculus II student, never having seen anything like this monstrosity before?",,"['calculus', 'sequences-and-series']"
32,How to evaluate the integral $\int e^{x^3}dx $,How to evaluate the integral,\int e^{x^3}dx ,"How to evaluate the integral $$\int e^{x^3}dx \quad ?$$ I've tried to set $t=x^3$, but it seems to be a blind alley; I don't know what to do with $\int\frac{e^t}{3\sqrt[3]{t^2}}dt$.","How to evaluate the integral $$\int e^{x^3}dx \quad ?$$ I've tried to set $t=x^3$, but it seems to be a blind alley; I don't know what to do with $\int\frac{e^t}{3\sqrt[3]{t^2}}dt$.",,"['calculus', 'integration', 'indefinite-integrals']"
33,"""Why do I always get 1 when I keep hitting the square root button on my calculator?""","""Why do I always get 1 when I keep hitting the square root button on my calculator?""",,"I asked myself this question when I was a young boy playing around with the calculator. Today, I think I know the answer, but I'm not sure whether I'd be able to explain it to a child or layman playing around with a calculator. Hence I'm interested in answers suitable for a person that, say, knows what the square root of a square number is, but doesn't know about sequences, functions, convergence and the like.","I asked myself this question when I was a young boy playing around with the calculator. Today, I think I know the answer, but I'm not sure whether I'd be able to explain it to a child or layman playing around with a calculator. Hence I'm interested in answers suitable for a person that, say, knows what the square root of a square number is, but doesn't know about sequences, functions, convergence and the like.",,"['calculus', 'convergence-divergence', 'fixed-point-theorems', 'calculator']"
34,Sum of the supremum and supremum of a sum,Sum of the supremum and supremum of a sum,,"Consider two real-valued functions of $\theta$, $f(\cdot): \Theta \subset\mathbb{R}\rightarrow \mathbb{R}$ and $g(\cdot):\Theta \subset \mathbb{R}\rightarrow \mathbb{R}$. Is there any relation between (1) $\sup_{\theta \in \Theta} (f(\theta)+g(\theta))$ and (2) $\sup_{\theta \in \Theta} f(\theta)+\sup_{\theta \in \Theta} g(\theta)$ ? Could you provide some informal proof or intuition behind your answer?","Consider two real-valued functions of $\theta$, $f(\cdot): \Theta \subset\mathbb{R}\rightarrow \mathbb{R}$ and $g(\cdot):\Theta \subset \mathbb{R}\rightarrow \mathbb{R}$. Is there any relation between (1) $\sup_{\theta \in \Theta} (f(\theta)+g(\theta))$ and (2) $\sup_{\theta \in \Theta} f(\theta)+\sup_{\theta \in \Theta} g(\theta)$ ? Could you provide some informal proof or intuition behind your answer?",,"['calculus', 'supremum-and-infimum']"
35,"Is the derivative function typically ""worse"" than the original function?","Is the derivative function typically ""worse"" than the original function?",,"For instance, the absolute value function is defined and continuous on the whole real line, but its derivative behaves like a step function with a jump-discontinuity. For some nice functions, though, such as $e^x$ or $\sin(x)$, the derivatives of course are no ""worse"" than the original function. Can I say something that is typical of the derivative?  Is it typically not as nice as the original function?","For instance, the absolute value function is defined and continuous on the whole real line, but its derivative behaves like a step function with a jump-discontinuity. For some nice functions, though, such as $e^x$ or $\sin(x)$, the derivatives of course are no ""worse"" than the original function. Can I say something that is typical of the derivative?  Is it typically not as nice as the original function?",,"['calculus', 'derivatives']"
36,"Generalised Integral $I_n=\int_0^{\pi/2} \frac{x^n}{\sin ^n x} \ \mathrm{d}x, \quad n\in \mathbb{Z}^+.$",Generalised Integral,"I_n=\int_0^{\pi/2} \frac{x^n}{\sin ^n x} \ \mathrm{d}x, \quad n\in \mathbb{Z}^+.","I have this integral,  $$I_n=\displaystyle \int_0^{\pi/2} \frac{x^n}{\sin ^n x} \ \mathrm{d}x, \qquad n\in \mathbb{Z}^+.$$ We have the results $$ \begin{align} I_1 & = 2C, \\ I_2 &= \pi\log 2, \\ I_4 & = -\frac{\pi^3}{12} + 2\pi\log 2 + \frac{\pi^3}{3}\log 2-\frac{3\pi}{2}\zeta(3), \end{align}  $$ where $C$ is Catalan's constant. Can we prove any of these results, or make any progress on $I_3$, or the general case?","I have this integral,  $$I_n=\displaystyle \int_0^{\pi/2} \frac{x^n}{\sin ^n x} \ \mathrm{d}x, \qquad n\in \mathbb{Z}^+.$$ We have the results $$ \begin{align} I_1 & = 2C, \\ I_2 &= \pi\log 2, \\ I_4 & = -\frac{\pi^3}{12} + 2\pi\log 2 + \frac{\pi^3}{3}\log 2-\frac{3\pi}{2}\zeta(3), \end{align}  $$ where $C$ is Catalan's constant. Can we prove any of these results, or make any progress on $I_3$, or the general case?",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
37,"Wrong Wolfram|Alpha limit? $ f(x,y) = \frac {xy}{|x|+|y|} $ for $(x,y)\to(0,0)$",Wrong Wolfram|Alpha limit?  for," f(x,y) = \frac {xy}{|x|+|y|}  (x,y)\to(0,0)","I have this function: $$ f(x,y) = \frac {xy}{|x|+|y|} $$ And I want to evaluate it's limit when $$ (x,y) \to (0,0)$$ My guess is that it tends to zero. So, by definition, if: $$ \forall \varepsilon \gt 0, \exists \delta \gt 0 \diagup \\ 0\lt||(x,y)||\lt \delta , \left|\frac{xy}{|x|+|y|}\right| \lt \varepsilon $$ Then $$ \lim_{(x,y)\to(0,0)}\frac {xy}{|x|+|y|} = 0 $$ So: $$ \left|\frac{xy}{|x|+|y|}\right| = \frac{|xy|}{|x|+|y|} = \frac{|x||y|}{|x|+|y|} \le 1 |y| \lt \delta $$ So for any $$\delta \lt \varepsilon$$ the inequality is true. Hence, the limit exists and is equal to zero. Wolfram|Alpha says that the limit does not exist . Am I wrong or is Wolfram|Alpha wrong?","I have this function: $$ f(x,y) = \frac {xy}{|x|+|y|} $$ And I want to evaluate it's limit when $$ (x,y) \to (0,0)$$ My guess is that it tends to zero. So, by definition, if: $$ \forall \varepsilon \gt 0, \exists \delta \gt 0 \diagup \\ 0\lt||(x,y)||\lt \delta , \left|\frac{xy}{|x|+|y|}\right| \lt \varepsilon $$ Then $$ \lim_{(x,y)\to(0,0)}\frac {xy}{|x|+|y|} = 0 $$ So: $$ \left|\frac{xy}{|x|+|y|}\right| = \frac{|xy|}{|x|+|y|} = \frac{|x||y|}{|x|+|y|} \le 1 |y| \lt \delta $$ So for any $$\delta \lt \varepsilon$$ the inequality is true. Hence, the limit exists and is equal to zero. Wolfram|Alpha says that the limit does not exist . Am I wrong or is Wolfram|Alpha wrong?",,"['calculus', 'limits', 'multivariable-calculus', 'wolfram-alpha']"
38,"Proving that $\gamma = \int_{0}^{1} \!\!\int_{0}^{1} \!\frac{x - 1}{(1 - x y) \log(x y)} \, \mathrm{d}{x} \, \mathrm{d}{y} $.",Proving that .,"\gamma = \int_{0}^{1} \!\!\int_{0}^{1} \!\frac{x - 1}{(1 - x y) \log(x y)} \, \mathrm{d}{x} \, \mathrm{d}{y} ","In 2005, J. Sondow found a surprising formula for the Euler-Mascheroni constant $ \gamma $. The formula is $$   \gamma = \int_{0}^{1} \int_{0}^{1} \frac{x - 1}{(1 - x y) \log(x y)}   ~ \mathrm{d}{x} ~ \mathrm{d}{y}. $$ Now, the definition of $ \gamma $ is $$ \gamma \stackrel{\text{def}}{=} \lim_{n \to \infty} \left[ \sum_{k = 1}^{n} \frac{1}{k} - \log(n) \right]. $$ I have tried using the geometric series $$ \frac{1}{1 - x y} = \sum_{n = 0}^{\infty} x^{n} y^{n} $$ to obtain a proof, but it would not work. Thanks for any help.","In 2005, J. Sondow found a surprising formula for the Euler-Mascheroni constant $ \gamma $. The formula is $$   \gamma = \int_{0}^{1} \int_{0}^{1} \frac{x - 1}{(1 - x y) \log(x y)}   ~ \mathrm{d}{x} ~ \mathrm{d}{y}. $$ Now, the definition of $ \gamma $ is $$ \gamma \stackrel{\text{def}}{=} \lim_{n \to \infty} \left[ \sum_{k = 1}^{n} \frac{1}{k} - \log(n) \right]. $$ I have tried using the geometric series $$ \frac{1}{1 - x y} = \sum_{n = 0}^{\infty} x^{n} y^{n} $$ to obtain a proof, but it would not work. Thanks for any help.",,"['calculus', 'integration', 'summation', 'improper-integrals']"
39,Is it simply a coincidence that if you differentiate the formula for the volume of sphere you get the formula for the surface area of sphere? [duplicate],Is it simply a coincidence that if you differentiate the formula for the volume of sphere you get the formula for the surface area of sphere? [duplicate],,"This question already has answers here : Why is the derivative of a circle's area its perimeter (and similarly for spheres)? (8 answers) Closed 5 years ago . So my question is this: $$V=\frac{4}{3}\pi r^3$$ And, $$\frac{dV}{dr}=4\pi r^2=SA$$ Is this a coincidence or are there some mathematical hoodoos that I'm unaware of? P.S. are there any more tags that I should use?","This question already has answers here : Why is the derivative of a circle's area its perimeter (and similarly for spheres)? (8 answers) Closed 5 years ago . So my question is this: And, Is this a coincidence or are there some mathematical hoodoos that I'm unaware of? P.S. are there any more tags that I should use?",V=\frac{4}{3}\pi r^3 \frac{dV}{dr}=4\pi r^2=SA,"['calculus', 'geometry', 'volume']"
40,Is there a simpler closed form for $\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2}$,Is there a simpler closed form for,\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2},"I have the following infinite sum that can be expressed in terms of the generalized hypergeometric function : $$\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2}=\frac{31}8-4\times{_4F_3}\left(-\frac12,\frac12,1,1;\ 2,2,2;\ 1\right)\\\ \\\approx0.008749644047541935203478962326551903908774780849356243615274...$$ I wonder if it can be expressed in terms of simpler functions and well-known mathematical constants.","I have the following infinite sum that can be expressed in terms of the generalized hypergeometric function : $$\sum_{n=1}^\infty\frac{(2n-1)!!\ (2n+1)!!}{4^n\ (n+2)\ (n+2)!^2}=\frac{31}8-4\times{_4F_3}\left(-\frac12,\frac12,1,1;\ 2,2,2;\ 1\right)\\\ \\\approx0.008749644047541935203478962326551903908774780849356243615274...$$ I wonder if it can be expressed in terms of simpler functions and well-known mathematical constants.",,"['calculus', 'sequences-and-series', 'closed-form', 'hypergeometric-function']"
41,Computing $\lim\limits_{n\to+\infty}n\int_{0}^{\pi/2}xf(x)\cos ^n xdx$,Computing,\lim\limits_{n\to+\infty}n\int_{0}^{\pi/2}xf(x)\cos ^n xdx,"I got stuck at the following problem. Let $f\in C([0,\pi/2])$, then compute   $$ \lim_{n\to+\infty}n\int\limits_{0}^{\pi/2}xf(x)\cos ^n xdx $$ Could you suggest a helpful idea?","I got stuck at the following problem. Let $f\in C([0,\pi/2])$, then compute   $$ \lim_{n\to+\infty}n\int\limits_{0}^{\pi/2}xf(x)\cos ^n xdx $$ Could you suggest a helpful idea?",,"['calculus', 'integration', 'limits']"
42,Finding the limit $\lim \limits_{n \to \infty}\ (\cos \frac x 2 \cdot\cos \frac x 4\cdot \cos \frac x 8\cdots \cos \frac x {2^n}) $,Finding the limit,\lim \limits_{n \to \infty}\ (\cos \frac x 2 \cdot\cos \frac x 4\cdot \cos \frac x 8\cdots \cos \frac x {2^n}) ,This limit seemed quite unusual to me as there aren't any intermediate forms or series expansions which are generally used in limits. Stuck on this for a while now .Here's how it goes : $$ \lim \limits_{n \to \infty} \left[\cos\left(x \over 2\right)\cos\left(x \over 4\right)       \cos\left(x \over 8\right)\ \cdots\ \cos\left(x \over 2^{n}\right)\right] $$,This limit seemed quite unusual to me as there aren't any intermediate forms or series expansions which are generally used in limits. Stuck on this for a while now .Here's how it goes :,"
\lim \limits_{n \to \infty}
\left[\cos\left(x \over 2\right)\cos\left(x \over 4\right)
      \cos\left(x \over 8\right)\ \cdots\ \cos\left(x \over 2^{n}\right)\right]
","['calculus', 'limits', 'trigonometry', 'infinite-product']"
43,Minimum of the Gamma Function $\Gamma (x)$ for $x>0$. How to find $x_{\min}$?,Minimum of the Gamma Function  for . How to find ?,\Gamma (x) x>0 x_{\min},"The $\Gamma (x)$ function has just one minimum for $x>0$ . This result uses some properties of the gamma function: $\Gamma ^{\prime \prime }(x)>0$ and $\Gamma (x)>0$ for all $x>0$ $\Gamma (1)=\Gamma (2)=1$. Observing the following graph (created in SWP) of $y=\Gamma (x)$ this minimum is near $x=3/2$, but likely $\min \Gamma (x)\neq \Gamma \left( 3/2\right) =\dfrac{1}{2}\Gamma \left( 1/2\right) =\dfrac{1}{2}\sqrt{\pi }$. I think that it is not possible to find analytically the exact value of $x_{\min }$, even by converting to an adequate problem in the interval $]0,1]$ and using the functional equation $\Gamma (x+1)=x\Gamma (x)$ and the reflection formula $\Gamma (p)\Gamma (p-1)=\dfrac{\pi }{\sin px}\qquad $( $0\lt p\lt 1$) Question: a) Which is the best way to find $\min_{[1,2]}\Gamma (x)$ and does $x_{\min }$ lay in $[1,3/2]$ or in $[3/2,2]$? b) Is there some useful series expansion of $\Gamma (x)$? c) Which numeric method do you suggest? Edit: Due to the shape of $\Gamma (x)$ I thought on the one-dimensional Davies-Swann-Campey method of direct search for unconstrained optimization, which approximates a function near a minimum by successive approximating quadratic polynomials.","The $\Gamma (x)$ function has just one minimum for $x>0$ . This result uses some properties of the gamma function: $\Gamma ^{\prime \prime }(x)>0$ and $\Gamma (x)>0$ for all $x>0$ $\Gamma (1)=\Gamma (2)=1$. Observing the following graph (created in SWP) of $y=\Gamma (x)$ this minimum is near $x=3/2$, but likely $\min \Gamma (x)\neq \Gamma \left( 3/2\right) =\dfrac{1}{2}\Gamma \left( 1/2\right) =\dfrac{1}{2}\sqrt{\pi }$. I think that it is not possible to find analytically the exact value of $x_{\min }$, even by converting to an adequate problem in the interval $]0,1]$ and using the functional equation $\Gamma (x+1)=x\Gamma (x)$ and the reflection formula $\Gamma (p)\Gamma (p-1)=\dfrac{\pi }{\sin px}\qquad $( $0\lt p\lt 1$) Question: a) Which is the best way to find $\min_{[1,2]}\Gamma (x)$ and does $x_{\min }$ lay in $[1,3/2]$ or in $[3/2,2]$? b) Is there some useful series expansion of $\Gamma (x)$? c) Which numeric method do you suggest? Edit: Due to the shape of $\Gamma (x)$ I thought on the one-dimensional Davies-Swann-Campey method of direct search for unconstrained optimization, which approximates a function near a minimum by successive approximating quadratic polynomials.",,"['calculus', 'approximation', 'gamma-function', 'numerical-methods', 'special-functions']"
44,How to integrate $\int\frac{1}{\sqrt{1+x^3}}\mathrm dx$?,How to integrate ?,\int\frac{1}{\sqrt{1+x^3}}\mathrm dx,"In a course, my teacher told us that the following integral is convergent and used the comparison test to prove it; my question is how to find the antiderivative in closed form? It seems to exist; if, however, it doesn't exist, can someone prove it? $$\int\sqrt{\dfrac1{1+x^3}}\mathrm dx$$","In a course, my teacher told us that the following integral is convergent and used the comparison test to prove it; my question is how to find the antiderivative in closed form? It seems to exist; if, however, it doesn't exist, can someone prove it? $$\int\sqrt{\dfrac1{1+x^3}}\mathrm dx$$",,"['calculus', 'integration']"
45,"When integrating how do I choose wisely between Green's, Stokes' and Divergence?","When integrating how do I choose wisely between Green's, Stokes' and Divergence?",,"I've been taught Green's Theorem, Stokes' Theorem and the Divergence Theorem, but I don't understand them very well. In particular I don't understand in what circumstances I would choose to use any one of these over any one of the others. What criteria should I be looking for to help me decide? I specifically want to use the theorems to make integration as easy or trivial as possible.","I've been taught Green's Theorem, Stokes' Theorem and the Divergence Theorem, but I don't understand them very well. In particular I don't understand in what circumstances I would choose to use any one of these over any one of the others. What criteria should I be looking for to help me decide? I specifically want to use the theorems to make integration as easy or trivial as possible.",,"['calculus', 'multivariable-calculus', 'integration']"
46,How does trigonometric substitution work?,How does trigonometric substitution work?,,"I have read my book, watched the MIT lecture and read Paul's Online Notes (which was pretty much worthless, no explanations just examples) and I have no idea what is going on with this at all. I understand that if I need to find something like $$\int \frac { \sqrt{9-x^2}}{x^2}dx$$ I can't use any other method except this one. What I do not get is pretty much everything else. It is hard to visualize the bounds of the substitution that will keep it positive but I think that is something I can just memorize from a table. So this is similar to u substitution except that I am not using a single variable but expressing x in the form of a trig function. How does this not change the value of the problem? To me it seems like it would, algebraically how is something like $$\int \frac { \sqrt{9-x^2}}{x^2}dx$$ the same as $$\int \frac {3\cos x}{9\sin^2 x}3\cos x \, dx$$ It feels like if I were to put in numbers for $x$ that it would be a different answer. Anyways just assuming that works I really do not understand at all what happens next. ""Returning"" to the original variable to me should just mean plugging back in what you had from before the substitution but for whatever unknown and unexplained reason this is not true. Even though on problems before I could just plug back in my substitution of $u = 2x$, $\sin2u = \sin4x$ that would work fine but for whatever reason no longer works. I am not expected to do some pretty complex trigonometric manipulation with the use of a triangle which I do not follow at all, luckily though this process is not explained at all in my book so I think I am just suppose to memorize it. Then when it gets time for the answer there is no explanation at all but out of nowhere inverse sin comes in for some reason. $$\frac {- \sqrt{9-x^2}}{x} - \sin^{-1} (x/3) +c$$ I have no idea happened but neither does the author apparently since there is no explanation.","I have read my book, watched the MIT lecture and read Paul's Online Notes (which was pretty much worthless, no explanations just examples) and I have no idea what is going on with this at all. I understand that if I need to find something like $$\int \frac { \sqrt{9-x^2}}{x^2}dx$$ I can't use any other method except this one. What I do not get is pretty much everything else. It is hard to visualize the bounds of the substitution that will keep it positive but I think that is something I can just memorize from a table. So this is similar to u substitution except that I am not using a single variable but expressing x in the form of a trig function. How does this not change the value of the problem? To me it seems like it would, algebraically how is something like $$\int \frac { \sqrt{9-x^2}}{x^2}dx$$ the same as $$\int \frac {3\cos x}{9\sin^2 x}3\cos x \, dx$$ It feels like if I were to put in numbers for $x$ that it would be a different answer. Anyways just assuming that works I really do not understand at all what happens next. ""Returning"" to the original variable to me should just mean plugging back in what you had from before the substitution but for whatever unknown and unexplained reason this is not true. Even though on problems before I could just plug back in my substitution of $u = 2x$, $\sin2u = \sin4x$ that would work fine but for whatever reason no longer works. I am not expected to do some pretty complex trigonometric manipulation with the use of a triangle which I do not follow at all, luckily though this process is not explained at all in my book so I think I am just suppose to memorize it. Then when it gets time for the answer there is no explanation at all but out of nowhere inverse sin comes in for some reason. $$\frac {- \sqrt{9-x^2}}{x} - \sin^{-1} (x/3) +c$$ I have no idea happened but neither does the author apparently since there is no explanation.",,['calculus']
47,Does absolute convergence of a sum imply uniform convergence?,Does absolute convergence of a sum imply uniform convergence?,,"Suppose I have a series $\sum_{n = 0}^{\infty} f_{n}(x)$ which converges absolutely to a function $f(x)$. Does the series converge uniformly to $f(x)$? I want to say this follows from Dini's Theorem , but I can't seem to see how.","Suppose I have a series $\sum_{n = 0}^{\infty} f_{n}(x)$ which converges absolutely to a function $f(x)$. Does the series converge uniformly to $f(x)$? I want to say this follows from Dini's Theorem , but I can't seem to see how.",,"['calculus', 'analysis', 'uniform-convergence', 'absolute-convergence']"
48,Definite Integral of square root of polynomial,Definite Integral of square root of polynomial,,"I need to learn how to find the definite integral of  the square root of a polynomial such as:      $$\sqrt{36x + 1}$$ or $$\sqrt{2x^2 + 3x + 7} $$ EDIT: It's not guaranteed to be of the same form. It could be any polynomial that can't be easily factored into squares. This isn't homework, I'm studying for a final. And for context, I'm finding the arc length of a function.","I need to learn how to find the definite integral of  the square root of a polynomial such as:      $$\sqrt{36x + 1}$$ or $$\sqrt{2x^2 + 3x + 7} $$ EDIT: It's not guaranteed to be of the same form. It could be any polynomial that can't be easily factored into squares. This isn't homework, I'm studying for a final. And for context, I'm finding the arc length of a function.",,"['calculus', 'integration']"
49,StarCraft II: Ladder math,StarCraft II: Ladder math,,"At the Blizzcon 2010, StarCraft II multiplayer panel, this stuff was supposed to explain the ladder matchmaking system. I look at this and go eh? what!? Is any of this real? or are they just messing with me, because I can't make heads or tails of this humongous equation. Can anyone break it down for me? or at least explain the principle behind this, I don't get how these integrals, derivatives, Euler-functions and multiplication sums yield anything meaningful...","At the Blizzcon 2010, StarCraft II multiplayer panel, this stuff was supposed to explain the ladder matchmaking system. I look at this and go eh? what!? Is any of this real? or are they just messing with me, because I can't make heads or tails of this humongous equation. Can anyone break it down for me? or at least explain the principle behind this, I don't get how these integrals, derivatives, Euler-functions and multiplication sums yield anything meaningful...",,"['calculus', 'statistics', 'applications']"
50,Why does trying to compute $\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}}$ result in the negative of the answer given?,Why does trying to compute  result in the negative of the answer given?,\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}},"My textbook asks me to evaluate the limit $$\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}}$$ which evaluates to $-2\over\sqrt{3}$ . The method in the book is to factor out $x^2$ from the root in the denominator: $$\begin{align} \lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}} & = \lim_{x\to-\infty} {2x-1\over \sqrt{x^2\left(3+\frac{1}{x}+\frac{1}{x^2}\right)}} \\  & = \lim_{x\to-\infty} {2x-1\over -x\sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\  & = \lim_{x\to-\infty} {-2+\frac{1}{x}\over \sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\  & = {-2\over\sqrt{3}} \end{align}$$ the second step is justified because $x\to-\infty$ implies $x\lt0$ , so $\sqrt{x^2}=-x$ . For my attempt I ended up with the negative of the correct answer: $$\begin{align} \lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}} & = \lim_{x\to-\infty} \left({2x-1\over \sqrt{3x^2+x+1}}\cdot\frac{\frac{1}{x}}{\frac{1}{x}}\right) \\  & = \lim_{x\to-\infty} {2-\frac{1}{x}\over \sqrt{\frac{1}{x^2}\left(3x^2+x+1\right)}} \\  & = \lim_{x\to-\infty} {2-\frac{1}{x}\over \sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\  & = {2\over\sqrt{3}} \end{align}$$ Where have I gone wrong? I suspect the mistake lies in my second step, but I'm unable to identify what went wrong exactly.","My textbook asks me to evaluate the limit which evaluates to . The method in the book is to factor out from the root in the denominator: the second step is justified because implies , so . For my attempt I ended up with the negative of the correct answer: Where have I gone wrong? I suspect the mistake lies in my second step, but I'm unable to identify what went wrong exactly.","\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}} -2\over\sqrt{3} x^2 \begin{align}
\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}} & = \lim_{x\to-\infty} {2x-1\over \sqrt{x^2\left(3+\frac{1}{x}+\frac{1}{x^2}\right)}} \\
 & = \lim_{x\to-\infty} {2x-1\over -x\sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\
 & = \lim_{x\to-\infty} {-2+\frac{1}{x}\over \sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\
 & = {-2\over\sqrt{3}}
\end{align} x\to-\infty x\lt0 \sqrt{x^2}=-x \begin{align}
\lim_{x\to-\infty} {2x-1\over \sqrt{3x^2+x+1}} & = \lim_{x\to-\infty} \left({2x-1\over \sqrt{3x^2+x+1}}\cdot\frac{\frac{1}{x}}{\frac{1}{x}}\right) \\
 & = \lim_{x\to-\infty} {2-\frac{1}{x}\over \sqrt{\frac{1}{x^2}\left(3x^2+x+1\right)}} \\
 & = \lim_{x\to-\infty} {2-\frac{1}{x}\over \sqrt{3+\frac{1}{x}+\frac{1}{x^2}}} \\
 & = {2\over\sqrt{3}}
\end{align}","['calculus', 'algebra-precalculus', 'limits']"
51,"Integral: $\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx$",Integral:,"\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx","I am trying to solve the following by elementary methods: $$\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx$$ I wrote the integral as: $$\Re\int_0^{\pi} \frac{dx}{x-i\ln(2\sin x)}$$ But I don't find this easier than the original integral. I have seen solutions which make use of complex analysis but I am interested in elementary approaches. Any help is appreciated. Thanks!","I am trying to solve the following by elementary methods: $$\int_0^{\pi} \frac{x}{x^2+\ln^2(2\sin x)}\,dx$$ I wrote the integral as: $$\Re\int_0^{\pi} \frac{dx}{x-i\ln(2\sin x)}$$ But I don't find this easier than the original integral. I have seen solutions which make use of complex analysis but I am interested in elementary approaches. Any help is appreciated. Thanks!",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
52,Derivative of the Meijer G-function with respect to one of its parameters,Derivative of the Meijer G-function with respect to one of its parameters,,"Are there any approaches that allow to find a derivative of the Meijer G-function with respect to one of its parameters in a closed form (or at least numerically with a high precision and in reasonable time, with all found digits provably correct)? I am particularly interested in this case: $$\mathcal{D}=\left.\partial_\alpha G_{2,3}^{2,1}\left(1\middle|\begin{array}c1,\alpha\\1,1,0\end{array}\right)\right|_{\alpha=1}$$","Are there any approaches that allow to find a derivative of the Meijer G-function with respect to one of its parameters in a closed form (or at least numerically with a high precision and in reasonable time, with all found digits provably correct)? I am particularly interested in this case: $$\mathcal{D}=\left.\partial_\alpha G_{2,3}^{2,1}\left(1\middle|\begin{array}c1,\alpha\\1,1,0\end{array}\right)\right|_{\alpha=1}$$",,"['calculus', 'complex-analysis', 'derivatives', 'special-functions', 'closed-form']"
53,Imaginary part of $\int_{0}^{\pi/2} \frac{x^2}{x^2+\log ^2(-2\cos x)} \:\mathrm{d}x$ and $\int_{0}^{\pi/2} \frac{\log \cos x}{x^2}\:\mathrm{d}x$,Imaginary part of  and,\int_{0}^{\pi/2} \frac{x^2}{x^2+\log ^2(-2\cos x)} \:\mathrm{d}x \int_{0}^{\pi/2} \frac{\log \cos x}{x^2}\:\mathrm{d}x,"I have found the following new result connecting two rational log-cosine integrals. Proposition. \begin{align}  	\displaystyle & {\Im} \int_{0}^{\pi/2} \frac{x^2}{x^2+\log ^2(-2\cos x)} \:\mathrm{d}x  =    \frac{\pi^2}{16} - \frac{\ln 2}{4}  + \frac{\pi}{8} \int_{0}^{\pi/2} \frac{\log \cos x}{x^2}\:\mathrm{d}x \end{align} where $\displaystyle  \log (z)$ denotes the principal value of the logarithm defined for $z \neq 0$ by     \begin{align}    \displaystyle \log (z)  = \ln |z| + i \: \mathrm{arg}z, \quad -\pi <\mathrm{arg} z \leq \pi. \nonumber \end{align} How would you prove it?","I have found the following new result connecting two rational log-cosine integrals. Proposition. \begin{align}  	\displaystyle & {\Im} \int_{0}^{\pi/2} \frac{x^2}{x^2+\log ^2(-2\cos x)} \:\mathrm{d}x  =    \frac{\pi^2}{16} - \frac{\ln 2}{4}  + \frac{\pi}{8} \int_{0}^{\pi/2} \frac{\log \cos x}{x^2}\:\mathrm{d}x \end{align} where $\displaystyle  \log (z)$ denotes the principal value of the logarithm defined for $z \neq 0$ by     \begin{align}    \displaystyle \log (z)  = \ln |z| + i \: \mathrm{arg}z, \quad -\pi <\mathrm{arg} z \leq \pi. \nonumber \end{align} How would you prove it?",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals', 'logarithms']"
54,Prove local minimum of a convex function is a global minumum (using only convexity),Prove local minimum of a convex function is a global minumum (using only convexity),,"Let $C\subseteq \mathbb{R}^d$ a convex set, and let $f:C\rightarrow \mathbb{R}$ be a convex function. Let $x^*$ be a local minimizer of $f$, that is there exists a value $p>0$ such that for every $x\in C$ : $||x-x^*||\leq p \Rightarrow f(x) \geq f(x^*)$. How do I show that that $x^*$ is a global minimum without using limits, but only using the convexity property ? I know how to prove this using limits. I tried to prove it by contradiction (i.e assume by contradiction that there exists another $x$ that is a local minimum), but have gotten nowhere.","Let $C\subseteq \mathbb{R}^d$ a convex set, and let $f:C\rightarrow \mathbb{R}$ be a convex function. Let $x^*$ be a local minimizer of $f$, that is there exists a value $p>0$ such that for every $x\in C$ : $||x-x^*||\leq p \Rightarrow f(x) \geq f(x^*)$. How do I show that that $x^*$ is a global minimum without using limits, but only using the convexity property ? I know how to prove this using limits. I tried to prove it by contradiction (i.e assume by contradiction that there exists another $x$ that is a local minimum), but have gotten nowhere.",,"['calculus', 'convex-analysis']"
55,"Integral $\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx$",Integral,"\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx","I have to evaluate this definite integral: $$Z=\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx$$ My CAS was only able to find its approximate numeric value: $$Z\approx0.796300956669079523165601562454031588576893734085453548868394...$$ Is there an approach that would allow to evaluate it in a closed form? I looked up this integral in Gradshteyn-Ryzhyk, but the closest one I found was formula 4.511: $$\int_0^\infty\operatorname{arccot}(px)\,\operatorname{arccot}(qx)\,dx=\frac\pi2\left[\frac1p\,\ln\left(1+\frac p q\right)+\frac1q\,\ln\left(1+\frac q p\right)\right]$$ Is there a way to generalize it to a product of 3 arccotangents? Any help is appreciated.","I have to evaluate this definite integral: $$Z=\int_0^\infty\operatorname{arccot}(x)\,\operatorname{arccot}(2x)\,\operatorname{arccot}(5x)\,dx$$ My CAS was only able to find its approximate numeric value: $$Z\approx0.796300956669079523165601562454031588576893734085453548868394...$$ Is there an approach that would allow to evaluate it in a closed form? I looked up this integral in Gradshteyn-Ryzhyk, but the closest one I found was formula 4.511: $$\int_0^\infty\operatorname{arccot}(px)\,\operatorname{arccot}(qx)\,dx=\frac\pi2\left[\frac1p\,\ln\left(1+\frac p q\right)+\frac1q\,\ln\left(1+\frac q p\right)\right]$$ Is there a way to generalize it to a product of 3 arccotangents? Any help is appreciated.",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'trigonometry']"
56,"Lagrange multipliers with inequality constraints: minimize $f$ on the region $0 \leq x,y \leq 1$",Lagrange multipliers with inequality constraints: minimize  on the region,"f 0 \leq x,y \leq 1","I do not have much experience with constrained optimization, but I am hoping that you can help. My current problem involves a more complex function, but the constraints are similar to the ones below. Just so that I can see how to apply Lagrange multipliers to my problem, I want to look at a simpler function. Suppose that I would like to minimize the function $$ f(x,y) = a + bx + cy $$ subject to the constraints $$ 0 \le x, y \le 1. $$ If I understand the Lagrange multipliers technique correctly, I should create 4 constraint functions: $x = 0$ , $x = 1$ , $y = 0$ , and $y = 1$ . This would lead to minimizing the function $$ a + bx + cy - \lambda_1 x + \lambda_2 (x-1) - \lambda_3y + \lambda_4(y-1) $$ with respect to $x,y,\lambda_1, \lambda_2,\lambda_3$ , and $\lambda_4$ . Does this look correct? If not, where did I go wrong? Your help is greatly appreciated.","I do not have much experience with constrained optimization, but I am hoping that you can help. My current problem involves a more complex function, but the constraints are similar to the ones below. Just so that I can see how to apply Lagrange multipliers to my problem, I want to look at a simpler function. Suppose that I would like to minimize the function subject to the constraints If I understand the Lagrange multipliers technique correctly, I should create 4 constraint functions: , , , and . This would lead to minimizing the function with respect to , and . Does this look correct? If not, where did I go wrong? Your help is greatly appreciated.","
f(x,y) = a + bx + cy
 
0 \le x, y \le 1.
 x = 0 x = 1 y = 0 y = 1 
a + bx + cy - \lambda_1 x + \lambda_2 (x-1) - \lambda_3y + \lambda_4(y-1)
 x,y,\lambda_1, \lambda_2,\lambda_3 \lambda_4","['calculus', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
57,Is there a general formula for the derivative of $\exp(A(x))$ when $A(x)$ is a matrix?,Is there a general formula for the derivative of  when  is a matrix?,\exp(A(x)) A(x),"It's easy for scalars, $(\exp(a(x)))' = a' e^a$. But can anything be said about matrices? Do $A(x)$ and $A'(x)$ commute such that $(\exp(A(x)))' = A' e^A = e^A A'$ or is this only a special case?","It's easy for scalars, $(\exp(a(x)))' = a' e^a$. But can anything be said about matrices? Do $A(x)$ and $A'(x)$ commute such that $(\exp(A(x)))' = A' e^A = e^A A'$ or is this only a special case?",,"['calculus', 'matrices', 'derivatives', 'matrix-exponential']"
58,How to evaluate $\sum\limits_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k}$?,How to evaluate ?,\sum\limits_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k},"There is post here asking for $$\sum_{n=1}^{+\infty}\frac{1}{1^2+2^2+\cdots+n^2}.$$ And the answer is $18-24\ln 2$. It is easy to elvaluate that $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1+2+\cdots+n}=2$ and it is not difficult to justify the convergence of $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k}$ for all $k>1$. Here comes my question: How to evaluate $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^3+2^3+\cdots+n^3}$ or in general, what is $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k}$ if $k$ is a positive integer.","There is post here asking for $$\sum_{n=1}^{+\infty}\frac{1}{1^2+2^2+\cdots+n^2}.$$ And the answer is $18-24\ln 2$. It is easy to elvaluate that $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1+2+\cdots+n}=2$ and it is not difficult to justify the convergence of $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k}$ for all $k>1$. Here comes my question: How to evaluate $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^3+2^3+\cdots+n^3}$ or in general, what is $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{1^k+2^k+\cdots+n^k}$ if $k$ is a positive integer.",,"['calculus', 'sequences-and-series', 'limits']"
59,Averaging 2 roots of a cubic polynomial,Averaging 2 roots of a cubic polynomial,,"Consider a cubic polynomial, $p(x)=k(x-a)(x-b)(x-c)$ where $k$ is some constant and $a,b,c$ its $3$ roots (not necessarily distinct, not necessarily real). It is very simple to show that if you average two roots of a cubic polynomial and compute the tangent line at their average that it will intersect the cubic polynomial at the remaining root. I tried to generalize this result to other odd degree polynomials and it did not seem to work well. What is so special about cubic polynomials that allows this to work that isn't true about higher degree odd polynomials?","Consider a cubic polynomial, $p(x)=k(x-a)(x-b)(x-c)$ where $k$ is some constant and $a,b,c$ its $3$ roots (not necessarily distinct, not necessarily real). It is very simple to show that if you average two roots of a cubic polynomial and compute the tangent line at their average that it will intersect the cubic polynomial at the remaining root. I tried to generalize this result to other odd degree polynomials and it did not seem to work well. What is so special about cubic polynomials that allows this to work that isn't true about higher degree odd polynomials?",,"['calculus', 'algebra-precalculus', 'polynomials', 'roots']"
60,"Closed-form of $\int_0^1 \operatorname{Li}_3^3(x)\,dx$ and $\int_0^1 \operatorname{Li}_3^4(x)\,dx$",Closed-form of  and,"\int_0^1 \operatorname{Li}_3^3(x)\,dx \int_0^1 \operatorname{Li}_3^4(x)\,dx","We know a closed-form of the first two powers of the integral of trilogarithm function between $0$ and $1$ . From the result here we know that $$I_1=\int_0^1 \operatorname{Li}_3(x)\,dx = \zeta(3)-\frac{\pi^2}{6}+1.$$ From here we also know that $$I_2=\int_0^1 \operatorname{Li}_3^2(x)\,dx = 20-8\zeta(2)-10\zeta(3)+\frac{15}{2}\zeta(4)-2\zeta(2)\zeta(3)+\zeta^2(3).$$ Is there a closed-form of $$I_3=\int_0^1 \operatorname{Li}_3^3(x)\,dx$$ and $$I_4=\int_0^1 \operatorname{Li}_3^4(x)\,dx\,?$$ Update (by editor after 6 years): By generalizing @Kirill's algorithm one may prove that: $$\int_0^1 \text{Li}_3(x){}^4 \, dx=-51 \pi ^2 \zeta(6,2)+6480 \zeta(6,2)+\frac{4743}{8} \zeta(8,2)+\zeta (3)^4-\frac{2 \pi ^2 \zeta (3)^3}{3}-68 \zeta (3)^3-248 \pi ^2 \zeta (3)^2+16680 \zeta (3)^2+\frac{106 \pi ^6 \zeta (3)}{105}+126 \pi ^4 \zeta (3)+3920 \pi ^2 \zeta (3)+102 \pi ^2 \zeta (5) \zeta (3)-11160 \zeta (5) \zeta (3)-\frac{4743 \zeta (7) \zeta (3)}{4}-114240 \zeta (3)+42 \pi ^4 \zeta (5)+1260 \pi ^2 \zeta (5)-73080 \zeta (5)+\frac{819 \pi ^2 \zeta (7)}{2}-33030 \zeta (7)-9660 \zeta (9)-\frac{4023 \zeta (5)^2}{4}+\frac{563 \pi ^{10}}{39600}+\frac{83 \pi ^8}{42}-1064 \pi ^4-11200 \pi ^2-\frac{184 \pi ^6}{21}+369600$$ Here $\zeta(6,2), \zeta(8,2)$ are irreducible. One may verify its correctness numerically.",We know a closed-form of the first two powers of the integral of trilogarithm function between and . From the result here we know that From here we also know that Is there a closed-form of and Update (by editor after 6 years): By generalizing @Kirill's algorithm one may prove that: Here are irreducible. One may verify its correctness numerically.,"0 1 I_1=\int_0^1 \operatorname{Li}_3(x)\,dx = \zeta(3)-\frac{\pi^2}{6}+1. I_2=\int_0^1 \operatorname{Li}_3^2(x)\,dx = 20-8\zeta(2)-10\zeta(3)+\frac{15}{2}\zeta(4)-2\zeta(2)\zeta(3)+\zeta^2(3). I_3=\int_0^1 \operatorname{Li}_3^3(x)\,dx I_4=\int_0^1 \operatorname{Li}_3^4(x)\,dx\,? \int_0^1 \text{Li}_3(x){}^4 \, dx=-51 \pi ^2 \zeta(6,2)+6480 \zeta(6,2)+\frac{4743}{8} \zeta(8,2)+\zeta (3)^4-\frac{2 \pi ^2 \zeta (3)^3}{3}-68 \zeta (3)^3-248 \pi ^2 \zeta (3)^2+16680 \zeta (3)^2+\frac{106 \pi ^6 \zeta (3)}{105}+126 \pi ^4 \zeta (3)+3920 \pi ^2 \zeta (3)+102 \pi ^2 \zeta (5) \zeta (3)-11160 \zeta (5) \zeta (3)-\frac{4743 \zeta (7) \zeta (3)}{4}-114240 \zeta (3)+42 \pi ^4 \zeta (5)+1260 \pi ^2 \zeta (5)-73080 \zeta (5)+\frac{819 \pi ^2 \zeta (7)}{2}-33030 \zeta (7)-9660 \zeta (9)-\frac{4023 \zeta (5)^2}{4}+\frac{563 \pi ^{10}}{39600}+\frac{83 \pi ^8}{42}-1064 \pi ^4-11200 \pi ^2-\frac{184 \pi ^6}{21}+369600 \zeta(6,2), \zeta(8,2)","['calculus', 'integration', 'definite-integrals', 'special-functions', 'polylogarithm']"
61,product= $\exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\left(\frac{11^{11}3^3}{13^{13}}\right)^{1/20}\sqrt{\frac{3}{7^{7/6}\pi}\sqrt{\frac2\pi}}$,product=,\exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\left(\frac{11^{11}3^3}{13^{13}}\right)^{1/20}\sqrt{\frac{3}{7^{7/6}\pi}\sqrt{\frac2\pi}},"$\mathrm G$ is Catalan's constant. I recently found the product $$ \alpha=\prod_{n=1}^{\infty}\frac{E_n(\frac12)E_n(\frac7{12})E_n(\frac1{20})E_n(\frac{13}{20})}{E_n(\frac14)E_n(\frac1{12})E_n(\frac3{20})E_n(\frac{11}{20})}=\\ \exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\sqrt{\frac{33}{91\pi}\sqrt{\frac2\pi\frac{\sqrt[5]{11}}{\sqrt[3]{7}}\sqrt[5]{\frac{3^3}{13^{3}}}}}$$ (an alternate form of the product in the title) Where $$E_n(x)=\frac{j(n+x)}{(en)^{2x}j(n-x)}\qquad x\in(0,1)$$ and $j(x)=x^x$ . Could I have some numerical evidence, or better yet an alternate proof? My tools are limited to desmos, which cannot really handle infinite products. Thanks. My Proof. We define $$\mathrm L(x)=\frac1\pi\int_0^{\pi x}\log(\sin t)dt$$ And we use $$\sin t=t\prod_{n\geq1}\left(1-\frac{t^2}{\pi^2 n^2}\right)$$ To see that $$\log(\sin t)=\log(t)+\sum_{n\geq1}\log\frac{\pi^2n^2-t^2}{\pi^2n^2}$$ Then integrate both sides over $[0,x]$ to get $$\pi\mathrm L(x/\pi)=x(\log x-1)+\sum_{n\geq1}x\log\bigg(1-\frac{x^2}{\pi^2n^2}\bigg)-2x+\pi n\log\frac{\pi n+x}{\pi n-x}$$ $$\pi\mathrm L(x/\pi)=\log\left[\frac{j(x)}{e^x}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+x)}{(e\pi n)^{2x}j(\pi n-x)}\right]$$ $x\mapsto \pi x$ : $$\pi\mathrm L(x)=\log\left[\frac{j(\pi x)}{e^{\pi x}}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+\pi x)}{(e\pi n)^{2\pi x}j(\pi n-\pi x)}\right]$$ $$\mathrm L(x)=\log\left[\left(\frac\pi{e}\right)^xj(x)\right]+\sum_{n\geq1}\log E_n(x)$$ Then we define $$U(x)=\prod_{n\geq1}E_n(x)$$ To see that $$U(x)=\left(\frac{e}{\pi x}\right)^x\exp\mathrm L(x)$$ Where we used $$\sum_{n}\log(a_n)=\log\left[\prod_{n}a_n\right]$$ and the neat rules $$\log(a^b)=\log(e^{b\log a})=b\log a$$ $$\log(a)\pm b=\log\left(e^{\pm b}a\right)$$ to simplify the expressions. Next, we define $$P_{\mu,\nu}(a_1,a_2,\dots,a_\mu;b_1,b_2,\dots,b_\nu)=\frac{\prod_{i=1}^\mu U(a_i)}{\prod_{i=1}^\nu U(b_i)}$$ And we see that $$P_{\mu,\nu}(a_1,\dots,a_\mu;b_1,\dots,b_\nu)=\prod_{n\geq1}\frac{\prod_{i=1}^\mu E_n(a_i)}{\prod_{i=1}^\nu E_n(b_i)}$$ This gives $$P_{1,1}(x_1;x_2)=\left(\frac{e}{\pi}\right)^{x_1-x_2}\frac{j(x_2)}{j(x_1)}\exp\left[\mathrm L(x_1)-\mathrm L(x_2)\right]$$ Then we define $$\mathrm{T}(x)=\frac{1}{\pi}\int_0^{\pi x}\log(\tan t)dt=\mathrm L(x)-\mathrm L(x+1/2)-\frac12\log2$$ To get that $$P_{1,1}\left(x;x+\frac12\right)=\sqrt{\frac{2\pi}e}\,\frac{j(x+1/2)}{j(x)}\exp\mathrm T(x)$$ So we have $$P_{2,2}\left(x_1,x_2+\frac12 ;x_2,x_1+\frac12\right)=\frac{j(x_1+1/2)j(x_2)}{j(x_2+1/2)j(x_1)}\exp\left[\mathrm T(x_1)-\mathrm T(x_2)\right]$$ Then using the identities $$\mathrm L(1/2)=-\frac12\log2$$ $$\mathrm L(1/4)=-\frac{\mathrm G}{2\pi}-\frac14\log2$$ We get $$P_{1,1}\left(\frac12;\frac14\right)=\frac1{(2\pi)^{1/4}}\exp\left[\frac{\mathrm G}{2\pi}+\frac14\right]\tag{1}$$ From here , the identity $$-\mathrm T(1/12)=\frac{2\mathrm G}{3\pi}$$ which gives $$P_{1,1}\left(\frac7{12};\frac1{12}\right)=\sqrt{\frac6{7\pi\sqrt[6]{7}}}\exp\left[\frac{2\mathrm G}{3\pi}+\frac12\right]\tag{2}$$ Then from here , the identity $$\mathrm T(1/20)-\mathrm T(3/20)=\frac{2\mathrm G}{5\pi}$$ gives $$P_{2,2}\left(\frac1{20},\frac{13}{20};\frac3{20},\frac{11}{20}\right)=\left(\frac{j(11)j(3)}{j(13)}\right)^{1/20}\exp\frac{2\mathrm G}{5\pi}\tag{3}$$ Then multiplying $(1),(2),$ and $(3)$ , we have the desired result, namely $$P_{4,4}\left(\frac12,\frac7{12},\frac1{20},\frac{13}{20};\frac14,\frac1{12},\frac3{20},\frac{11}{20}\right)=\alpha$$","is Catalan's constant. I recently found the product (an alternate form of the product in the title) Where and . Could I have some numerical evidence, or better yet an alternate proof? My tools are limited to desmos, which cannot really handle infinite products. Thanks. My Proof. We define And we use To see that Then integrate both sides over to get : Then we define To see that Where we used and the neat rules to simplify the expressions. Next, we define And we see that This gives Then we define To get that So we have Then using the identities We get From here , the identity which gives Then from here , the identity gives Then multiplying and , we have the desired result, namely","\mathrm G 
\alpha=\prod_{n=1}^{\infty}\frac{E_n(\frac12)E_n(\frac7{12})E_n(\frac1{20})E_n(\frac{13}{20})}{E_n(\frac14)E_n(\frac1{12})E_n(\frac3{20})E_n(\frac{11}{20})}=\\
\exp\left[\frac{47\mathrm G}{30\pi}+\frac34\right]\sqrt{\frac{33}{91\pi}\sqrt{\frac2\pi\frac{\sqrt[5]{11}}{\sqrt[3]{7}}\sqrt[5]{\frac{3^3}{13^{3}}}}} E_n(x)=\frac{j(n+x)}{(en)^{2x}j(n-x)}\qquad x\in(0,1) j(x)=x^x \mathrm L(x)=\frac1\pi\int_0^{\pi x}\log(\sin t)dt \sin t=t\prod_{n\geq1}\left(1-\frac{t^2}{\pi^2 n^2}\right) \log(\sin t)=\log(t)+\sum_{n\geq1}\log\frac{\pi^2n^2-t^2}{\pi^2n^2} [0,x] \pi\mathrm L(x/\pi)=x(\log x-1)+\sum_{n\geq1}x\log\bigg(1-\frac{x^2}{\pi^2n^2}\bigg)-2x+\pi n\log\frac{\pi n+x}{\pi n-x} \pi\mathrm L(x/\pi)=\log\left[\frac{j(x)}{e^x}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+x)}{(e\pi n)^{2x}j(\pi n-x)}\right] x\mapsto \pi x \pi\mathrm L(x)=\log\left[\frac{j(\pi x)}{e^{\pi x}}\right]+\sum_{n\geq1}\log\left[\frac{j(\pi n+\pi x)}{(e\pi n)^{2\pi x}j(\pi n-\pi x)}\right] \mathrm L(x)=\log\left[\left(\frac\pi{e}\right)^xj(x)\right]+\sum_{n\geq1}\log E_n(x) U(x)=\prod_{n\geq1}E_n(x) U(x)=\left(\frac{e}{\pi x}\right)^x\exp\mathrm L(x) \sum_{n}\log(a_n)=\log\left[\prod_{n}a_n\right] \log(a^b)=\log(e^{b\log a})=b\log a \log(a)\pm b=\log\left(e^{\pm b}a\right) P_{\mu,\nu}(a_1,a_2,\dots,a_\mu;b_1,b_2,\dots,b_\nu)=\frac{\prod_{i=1}^\mu U(a_i)}{\prod_{i=1}^\nu U(b_i)} P_{\mu,\nu}(a_1,\dots,a_\mu;b_1,\dots,b_\nu)=\prod_{n\geq1}\frac{\prod_{i=1}^\mu E_n(a_i)}{\prod_{i=1}^\nu E_n(b_i)} P_{1,1}(x_1;x_2)=\left(\frac{e}{\pi}\right)^{x_1-x_2}\frac{j(x_2)}{j(x_1)}\exp\left[\mathrm L(x_1)-\mathrm L(x_2)\right] \mathrm{T}(x)=\frac{1}{\pi}\int_0^{\pi x}\log(\tan t)dt=\mathrm L(x)-\mathrm L(x+1/2)-\frac12\log2 P_{1,1}\left(x;x+\frac12\right)=\sqrt{\frac{2\pi}e}\,\frac{j(x+1/2)}{j(x)}\exp\mathrm T(x) P_{2,2}\left(x_1,x_2+\frac12 ;x_2,x_1+\frac12\right)=\frac{j(x_1+1/2)j(x_2)}{j(x_2+1/2)j(x_1)}\exp\left[\mathrm T(x_1)-\mathrm T(x_2)\right] \mathrm L(1/2)=-\frac12\log2 \mathrm L(1/4)=-\frac{\mathrm G}{2\pi}-\frac14\log2 P_{1,1}\left(\frac12;\frac14\right)=\frac1{(2\pi)^{1/4}}\exp\left[\frac{\mathrm G}{2\pi}+\frac14\right]\tag{1} -\mathrm T(1/12)=\frac{2\mathrm G}{3\pi} P_{1,1}\left(\frac7{12};\frac1{12}\right)=\sqrt{\frac6{7\pi\sqrt[6]{7}}}\exp\left[\frac{2\mathrm G}{3\pi}+\frac12\right]\tag{2} \mathrm T(1/20)-\mathrm T(3/20)=\frac{2\mathrm G}{5\pi} P_{2,2}\left(\frac1{20},\frac{13}{20};\frac3{20},\frac{11}{20}\right)=\left(\frac{j(11)j(3)}{j(13)}\right)^{1/20}\exp\frac{2\mathrm G}{5\pi}\tag{3} (1),(2), (3) P_{4,4}\left(\frac12,\frac7{12},\frac1{20},\frac{13}{20};\frac14,\frac1{12},\frac3{20},\frac{11}{20}\right)=\alpha","['calculus', 'integration', 'alternative-proof', 'infinite-product', 'constants']"
62,Improving one's calculation skills,Improving one's calculation skills,,"I am a first-year graduate student in mathematics. My undergraduate mathematics curriculum did not emphasize ""calculating""; it was a theoretical curriculum in which even a traditional course in multivariable calculus was not ""required"" (a course in differential geometry sufficed). I am training to be a ""hands-on analyst"", if that term makes any sense. For example, I know how to existence and uniqueness of solutions to PDE, but I haven't yet the ""nose"" to compute, to perform certain critical integration by parts, etc. I am starting to realize that theories are built on calculations and certain very interesting techniques in PDE--such as viscosity methods for example--arose from refining one's intuition while performing calculations. This is very inspiring for me and I want to learn to calculate! Calculating has been an acquired taste for me, and as a ""hands-on analyst"", I would like to work in PDE and variational problems where one is interested in producing sharp bounds, etc. (this is vague, I know). I am wondering if anyone can suggest any references/ workbooks where I can refine my ""computation"" skills. For example, I heard that the physicist Lev Landau gave his prospective students a preliminary test in integration. I suspect I will not pass such a test at this moment, but I would like to try to get myself to a stage where I can. Is there perhaps (a Russian?) text that emphasizes computation and serves as a good workbook for refining one's computation/calculation abilities. Much thanks in advance!","I am a first-year graduate student in mathematics. My undergraduate mathematics curriculum did not emphasize ""calculating""; it was a theoretical curriculum in which even a traditional course in multivariable calculus was not ""required"" (a course in differential geometry sufficed). I am training to be a ""hands-on analyst"", if that term makes any sense. For example, I know how to existence and uniqueness of solutions to PDE, but I haven't yet the ""nose"" to compute, to perform certain critical integration by parts, etc. I am starting to realize that theories are built on calculations and certain very interesting techniques in PDE--such as viscosity methods for example--arose from refining one's intuition while performing calculations. This is very inspiring for me and I want to learn to calculate! Calculating has been an acquired taste for me, and as a ""hands-on analyst"", I would like to work in PDE and variational problems where one is interested in producing sharp bounds, etc. (this is vague, I know). I am wondering if anyone can suggest any references/ workbooks where I can refine my ""computation"" skills. For example, I heard that the physicist Lev Landau gave his prospective students a preliminary test in integration. I suspect I will not pass such a test at this moment, but I would like to try to get myself to a stage where I can. Is there perhaps (a Russian?) text that emphasizes computation and serves as a good workbook for refining one's computation/calculation abilities. Much thanks in advance!",,"['calculus', 'reference-request']"
63,Proof of $\zeta(2)=\frac{\pi^2}{6}$,Proof of,\zeta(2)=\frac{\pi^2}{6},"While messing around with some integrals, I have found the following proof for $\zeta(2)=\frac{\pi^2}{6}$, but I'm not sure if it is valid: We take a look at the integral $I=\int_0^{\frac{\pi}{2}} \ln(\cos(x))\space dx$. Clearly, we have $\Im(I)=0$; to show that the integral converges isn't difficult and consequently, it is real. Now some calculations using $\cos(x)=\frac{e^{ix}+e^{-ix}}{2}$: $$ I=\int_0^{\frac{\pi}{2}} \ln\left(\frac{e^{ix}+e^{-ix}}{2}\right)\space dx=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)-ix-\ln(2)\space dx=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)\space dx-i\frac{\pi^2}{8}-\frac{\pi}{2}\ln(2) $$ Now: $$ J=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)\space dx=\int_0^{\frac{\pi}{2}} \sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot e^{2ixk}}{k}\space dx=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot \left[\frac{e^{2ixk}}{2ik}\right]_0^{\frac{\pi}{2}}}{k}=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot \left(\frac{(-1)^k-1}{2ik}\right)}{k} $$ When $k$ is even, then $(-1)^k-1=0$ so those terms cancel out, leaving: $$ J=\sum_{k=1}^{\infty}\frac{\left(\frac{-2}{2i(2k-1)}\right)}{2k-1}=i\sum_{k=1}^{\infty}\frac{1}{(2k-1)^2}=i\left(\sum_{k=1}^{\infty}\frac{1}{k^2}-\sum_{k=1}^{\infty}\frac{1}{(2k)^2}\right)=i\cdot\frac{3}{4}\zeta(2) $$ Clearly, we have $\Re(J)=0$ and therefore $0=\Im(I)=\frac{3}{4}\zeta(2)-\frac{\pi^2}{8}$ and thus $\zeta(2)=\frac{\pi^2}{6}$. I'm not sure with all those complex terms which are involved so it would be highly appreciated if someone could tell me wether the steps are valid or not. Edit: The main aspects I'm concerned about are $\ln\left(e^{ix}+e^{-ix}\right)=\ln\left(e^{2ix}+1\right)-ix$ or $e^{i\pi k}=(-1)^{k}$ and in general manipulations involving the natural log of complex arguments, because I'm familar with the fact, that it can take infinitly potential values, but until now I havent had a proper introduction to the subject and learned the major things autodidactically, so I'm not sure about the validity.","While messing around with some integrals, I have found the following proof for $\zeta(2)=\frac{\pi^2}{6}$, but I'm not sure if it is valid: We take a look at the integral $I=\int_0^{\frac{\pi}{2}} \ln(\cos(x))\space dx$. Clearly, we have $\Im(I)=0$; to show that the integral converges isn't difficult and consequently, it is real. Now some calculations using $\cos(x)=\frac{e^{ix}+e^{-ix}}{2}$: $$ I=\int_0^{\frac{\pi}{2}} \ln\left(\frac{e^{ix}+e^{-ix}}{2}\right)\space dx=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)-ix-\ln(2)\space dx=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)\space dx-i\frac{\pi^2}{8}-\frac{\pi}{2}\ln(2) $$ Now: $$ J=\int_0^{\frac{\pi}{2}} \ln\left(e^{2ix}+1\right)\space dx=\int_0^{\frac{\pi}{2}} \sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot e^{2ixk}}{k}\space dx=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot \left[\frac{e^{2ixk}}{2ik}\right]_0^{\frac{\pi}{2}}}{k}=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}\cdot \left(\frac{(-1)^k-1}{2ik}\right)}{k} $$ When $k$ is even, then $(-1)^k-1=0$ so those terms cancel out, leaving: $$ J=\sum_{k=1}^{\infty}\frac{\left(\frac{-2}{2i(2k-1)}\right)}{2k-1}=i\sum_{k=1}^{\infty}\frac{1}{(2k-1)^2}=i\left(\sum_{k=1}^{\infty}\frac{1}{k^2}-\sum_{k=1}^{\infty}\frac{1}{(2k)^2}\right)=i\cdot\frac{3}{4}\zeta(2) $$ Clearly, we have $\Re(J)=0$ and therefore $0=\Im(I)=\frac{3}{4}\zeta(2)-\frac{\pi^2}{8}$ and thus $\zeta(2)=\frac{\pi^2}{6}$. I'm not sure with all those complex terms which are involved so it would be highly appreciated if someone could tell me wether the steps are valid or not. Edit: The main aspects I'm concerned about are $\ln\left(e^{ix}+e^{-ix}\right)=\ln\left(e^{2ix}+1\right)-ix$ or $e^{i\pi k}=(-1)^{k}$ and in general manipulations involving the natural log of complex arguments, because I'm familar with the fact, that it can take infinitly potential values, but until now I havent had a proper introduction to the subject and learned the major things autodidactically, so I'm not sure about the validity.",,"['calculus', 'sequences-and-series', 'definite-integrals', 'proof-verification', 'riemann-zeta']"
64,"Is there a symbol for ""taking a derivative of something""?","Is there a symbol for ""taking a derivative of something""?",,"When presented with an equation, say, $y=5x^3+7x^2+4x+9$, you can write on the second line, $\frac{dy}{dx}=15x^2+14x+4$. Similarly, $f(x)=5x^3+7x^2+4x+9$ and $f'(x)=15x^2+14x+4$. But is there a way to write ""the derivative of $5x^3+7x^2+4x+9$ is $15x^2+14x+4$"" in just one line? What should l write, $\frac{dy}{d5x^3+7x^2+4x+9}=\cdots$? That fraction just gives me a headache trying to understand it. What about $f'(5x^3+7x^2+4x+9)=\cdots$? For all the reader knows, $f(x)$ could be anything, and the writer wanted them to plug in $5x^3+7x^2+4x+9$ into the original $f(x)$ and then take the derivative. So has anyone come up with a better way to write this that does not involve defining anything and then using the newly defined function/operator?","When presented with an equation, say, $y=5x^3+7x^2+4x+9$, you can write on the second line, $\frac{dy}{dx}=15x^2+14x+4$. Similarly, $f(x)=5x^3+7x^2+4x+9$ and $f'(x)=15x^2+14x+4$. But is there a way to write ""the derivative of $5x^3+7x^2+4x+9$ is $15x^2+14x+4$"" in just one line? What should l write, $\frac{dy}{d5x^3+7x^2+4x+9}=\cdots$? That fraction just gives me a headache trying to understand it. What about $f'(5x^3+7x^2+4x+9)=\cdots$? For all the reader knows, $f(x)$ could be anything, and the writer wanted them to plug in $5x^3+7x^2+4x+9$ into the original $f(x)$ and then take the derivative. So has anyone come up with a better way to write this that does not involve defining anything and then using the newly defined function/operator?",,"['calculus', 'derivatives', 'notation']"
65,Calculate $\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots$,Calculate,\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots,I'm an eight-grader and I need help to answer this math problem. Problem: Calculate $$\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots$$ This one is very hard for me. It seems unsolvable. How to calculate the series without using Wolfram Alpha? Please help me. Grazie!,I'm an eight-grader and I need help to answer this math problem. Problem: Calculate $$\frac{1}{5^1}+\frac{3}{5^3}+\frac{5}{5^5}+\frac{7}{5^7}+\frac{9}{5^9}+\cdots$$ This one is very hard for me. It seems unsolvable. How to calculate the series without using Wolfram Alpha? Please help me. Grazie!,,"['calculus', 'sequences-and-series', 'algebra-precalculus', 'summation', 'problem-solving']"
66,Maclaurin expansion of $\arcsin x$,Maclaurin expansion of,\arcsin x,"I'm trying to find the first five terms of the Maclaurin expansion of $\arcsin x$, possibly using the fact that $$\arcsin x = \int_0^x \frac{dt}{(1-t^2)^{1/2}}.$$ I can only see that I can interchange differentiation and integration but not sure how to go about this. Thanks!","I'm trying to find the first five terms of the Maclaurin expansion of $\arcsin x$, possibly using the fact that $$\arcsin x = \int_0^x \frac{dt}{(1-t^2)^{1/2}}.$$ I can only see that I can interchange differentiation and integration but not sure how to go about this. Thanks!",,['calculus']
67,"Calculus, water poured into a cone: Why is the derivative non-linear?","Calculus, water poured into a cone: Why is the derivative non-linear?",,"If water is poured into a cone at a constant rate and if $\frac {dh}{dt}$ is the rate of change of the depth of the water, I understand that $\frac {dh}{dt}$ is decreasing. However, I don't understand why $\frac {dh}{dt}$ is non-linear. Why can't it be linear? I am NOT asking whether or not the height function is linear. Many are telling me that the derivative of height is not a constant so thus the height function is not linear, but this is not what I am asking. This is my mistake, because I had used $h(t)$ originally to denote the derivative of height which is what my book used. Rather I am asking if $\frac {dh}{dt}$ is linear or not and why. It would be nice if someone could better explain what my book is telling me: At every instant the portion of the cone containing water is similar to the entire cone; the volume is proportional to the cube of the depth of the water. The rate of change of depth (the derivative) is therefore not linear.","If water is poured into a cone at a constant rate and if is the rate of change of the depth of the water, I understand that is decreasing. However, I don't understand why is non-linear. Why can't it be linear? I am NOT asking whether or not the height function is linear. Many are telling me that the derivative of height is not a constant so thus the height function is not linear, but this is not what I am asking. This is my mistake, because I had used originally to denote the derivative of height which is what my book used. Rather I am asking if is linear or not and why. It would be nice if someone could better explain what my book is telling me: At every instant the portion of the cone containing water is similar to the entire cone; the volume is proportional to the cube of the depth of the water. The rate of change of depth (the derivative) is therefore not linear.",\frac {dh}{dt} \frac {dh}{dt} \frac {dh}{dt} h(t) \frac {dh}{dt},['calculus']
68,What is the limit of $\frac{1}{\sqrt{n}}\sum_{k=1}^n\frac{1}{\sqrt{2k-1}+\sqrt{2k+1}}$? [duplicate],What is the limit of ? [duplicate],\frac{1}{\sqrt{n}}\sum_{k=1}^n\frac{1}{\sqrt{2k-1}+\sqrt{2k+1}},"This question already has answers here : Find $\lim\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$ [closed] (2 answers) Closed 3 years ago . $$\lim_{n\to \infty} \frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\cdots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)=? $$ I tried with the squeeze theorem, though I got the upper bound, but I couldn't find the lower bound. I also tried to solve it with the order limit theorem, but without any success. I guessed the result should be $\frac{1}{\sqrt{2}}$. How can I do this?","This question already has answers here : Find $\lim\frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\ldots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)$ [closed] (2 answers) Closed 3 years ago . $$\lim_{n\to \infty} \frac{1}{\sqrt{n}}\left(\frac{1}{\sqrt{1}+\sqrt{3}}+\frac{1}{\sqrt{3}+\sqrt{5}}+\cdots+\frac{1}{\sqrt{2n-1}+\sqrt{2n+1}}\right)=? $$ I tried with the squeeze theorem, though I got the upper bound, but I couldn't find the lower bound. I also tried to solve it with the order limit theorem, but without any success. I guessed the result should be $\frac{1}{\sqrt{2}}$. How can I do this?",,"['calculus', 'sequences-and-series', 'limits']"
69,Limit of $\sqrt x$ as $x$ approaches $0$,Limit of  as  approaches,\sqrt x x 0,"What is the limit of $\sqrt x$ as $x$ approaches $0$? I asked a few people and they all gave me two different answers. Some said that the limit is $0$, and other say that the limit is not defined because the right-hand limit is $0$ while the left-hand limit is undefined. I'm confused. please help!!","What is the limit of $\sqrt x$ as $x$ approaches $0$? I asked a few people and they all gave me two different answers. Some said that the limit is $0$, and other say that the limit is not defined because the right-hand limit is $0$ while the left-hand limit is undefined. I'm confused. please help!!",,"['calculus', 'algebra-precalculus', 'limits', 'radicals']"
70,Why is the number $e$ so important in mathematics?,Why is the number  so important in mathematics?,e,I've heard a lot about this number $e$. Why is it so important? How does it fit into the 'bigger picture' of mathematics? How is it calculated and used?,I've heard a lot about this number $e$. Why is it so important? How does it fit into the 'bigger picture' of mathematics? How is it calculated and used?,,['calculus']
71,Why is it not possible to generate an explicit formula for Newton's method?,Why is it not possible to generate an explicit formula for Newton's method?,,"Going through the recursive formula for approximating roots every time is extraordinarily tedious, so I was wondering why there was no formula that computed the $n$th iteration of Newton's method.","Going through the recursive formula for approximating roots every time is extraordinarily tedious, so I was wondering why there was no formula that computed the $n$th iteration of Newton's method.",,"['calculus', 'numerical-methods', 'newton-raphson']"
72,Finding $\lim\limits_{n \to \infty}{\frac{1^1+2^2+3^3+\cdots+n^n}{n^n}}$,Finding,\lim\limits_{n \to \infty}{\frac{1^1+2^2+3^3+\cdots+n^n}{n^n}},$$\lim_{n \to \infty}{\frac{1^1+2^2+3^3+\cdots+n^n}{n^n}}.$$ With a first look this must give $1$ as a result but have a problem to explain it. How can I do it? Edit I noticed that it is $\frac{\infty}{\infty}$. $$\lim_{n \to \infty}{n^{n}\frac{(\frac{1^1}{n^{n}}+\frac{2^2}{n^{n}}+\frac{3^3}{n^{n}}+\cdots+1)}{n^n}}= \lim_{n \to \infty}{\frac{1^1}{n^{n}}+\frac{2^2}{n^{n}}+\frac{3^3}{n^{n}}+\cdots+1}=1$$ Is this correct?,$$\lim_{n \to \infty}{\frac{1^1+2^2+3^3+\cdots+n^n}{n^n}}.$$ With a first look this must give $1$ as a result but have a problem to explain it. How can I do it? Edit I noticed that it is $\frac{\infty}{\infty}$. $$\lim_{n \to \infty}{n^{n}\frac{(\frac{1^1}{n^{n}}+\frac{2^2}{n^{n}}+\frac{3^3}{n^{n}}+\cdots+1)}{n^n}}= \lim_{n \to \infty}{\frac{1^1}{n^{n}}+\frac{2^2}{n^{n}}+\frac{3^3}{n^{n}}+\cdots+1}=1$$ Is this correct?,,"['calculus', 'limits']"
73,Interesting calculus problems of medium difficulty?,Interesting calculus problems of medium difficulty?,,"I would like to know sources, and examples of good ""challenge"" problems for students who have studied pre-calculus and some calculus. (differentiation and the very basics of integration.) Topics could be related to things such as: Taylor Series. Product Rule, Quotient Rule, Chain Rule. Simple limits. Delta Epsilon Proofs. Induction proofs for the sum of the first n, integer, squares, etc. Integration by substitution. Other topics... What I have found so far are too many problems that are just a bit too difficult. The problem can have a ""trick"" but it needs to be something a freshman could do. Here is one problem that I thought was just at the right level: If $f(x) = \frac{x}{x+\frac{x}{x+ \frac{x}{x+ \vdots}}}$, find $f'(x)$* *To be honest this problem makes me a little nervous. Still, I like it.","I would like to know sources, and examples of good ""challenge"" problems for students who have studied pre-calculus and some calculus. (differentiation and the very basics of integration.) Topics could be related to things such as: Taylor Series. Product Rule, Quotient Rule, Chain Rule. Simple limits. Delta Epsilon Proofs. Induction proofs for the sum of the first n, integer, squares, etc. Integration by substitution. Other topics... What I have found so far are too many problems that are just a bit too difficult. The problem can have a ""trick"" but it needs to be something a freshman could do. Here is one problem that I thought was just at the right level: If $f(x) = \frac{x}{x+\frac{x}{x+ \frac{x}{x+ \vdots}}}$, find $f'(x)$* *To be honest this problem makes me a little nervous. Still, I like it.",,"['calculus', 'algebra-precalculus', 'big-list']"
74,Derivative of a Delta function,Derivative of a Delta function,,"I know questions similar to this one have been asked, but there is a particular aspect that I'm confused about that wasn't addressed in the answers to the other ones. I'm dealing with an expression which I have simplified into something like \begin{equation}f(D)\int_{-\infty}^{\infty} dk\, e^{-ikx}\end{equation} Where $D=\frac{d}{dx}$ The integral is simply a Dirac delta $\delta(x)$, and from what little I know about distributions I know that derivatives of delta functions only make sense when they appear inside an integral. This isn't the case here though, so I'm not sure how to proceed. I've seen some identities here and there such as $\frac{d}{dx}\delta (x)=-\frac{\delta(x)}{x}$ and other similar ones and I'm not sure how to interpret them.  Any help on this would be greatly appreciated.","I know questions similar to this one have been asked, but there is a particular aspect that I'm confused about that wasn't addressed in the answers to the other ones. I'm dealing with an expression which I have simplified into something like \begin{equation}f(D)\int_{-\infty}^{\infty} dk\, e^{-ikx}\end{equation} Where $D=\frac{d}{dx}$ The integral is simply a Dirac delta $\delta(x)$, and from what little I know about distributions I know that derivatives of delta functions only make sense when they appear inside an integral. This isn't the case here though, so I'm not sure how to proceed. I've seen some identities here and there such as $\frac{d}{dx}\delta (x)=-\frac{\delta(x)}{x}$ and other similar ones and I'm not sure how to interpret them.  Any help on this would be greatly appreciated.",,"['calculus', 'analysis', 'distribution-theory']"
75,Proof of $\int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}$,Proof of,\int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}},Numerically it seems to be true that $$ \int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}. $$ Any ideas how to prove this?,Numerically it seems to be true that $$ \int_0^\infty \frac{\sin x}{\sqrt{x}}dx=\sqrt{\frac{\pi}{2}}. $$ Any ideas how to prove this?,,"['calculus', 'integration', 'definite-integrals']"
76,Does it make sense to learn mathematical concepts as you encounter them rather than in a fixed progression? [closed],Does it make sense to learn mathematical concepts as you encounter them rather than in a fixed progression? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question I understand the fundamentals of algrebra, but have very limited knowledge of geometry and trigonometry. I wish to learn calculus at this point. Is it reasonable to begin learning calculus, and learn these other concepts as I encounter them rather than learning the prerequisites in the standard fixed progression (i.e. Algebra I -> Algebra 2 -> Geometry -> Trigonometry, etc)? How difficult will it be to learn these concepts without the prescribed linear progression?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question I understand the fundamentals of algrebra, but have very limited knowledge of geometry and trigonometry. I wish to learn calculus at this point. Is it reasonable to begin learning calculus, and learn these other concepts as I encounter them rather than learning the prerequisites in the standard fixed progression (i.e. Algebra I -> Algebra 2 -> Geometry -> Trigonometry, etc)? How difficult will it be to learn these concepts without the prescribed linear progression?",,"['calculus', 'algebra-precalculus', 'ordinary-differential-equations', 'soft-question']"
77,What is the difference between square of sum and sum of square?,What is the difference between square of sum and sum of square?,,What is difference between square of sum $(\sum_{i=1}^{n}x_i)^2$ and sum of square $\sum_{i=1}^{n}x_i^2$? I think square of sum is bigger than sum of square but i can not find a relation between them. I mean: $$\left(\sum_{i=1}^{n}x_i\right)^2=\sum_{i=1}^{n}x_i^2+?$$,What is difference between square of sum $(\sum_{i=1}^{n}x_i)^2$ and sum of square $\sum_{i=1}^{n}x_i^2$? I think square of sum is bigger than sum of square but i can not find a relation between them. I mean: $$\left(\sum_{i=1}^{n}x_i\right)^2=\sum_{i=1}^{n}x_i^2+?$$,,['calculus']
78,Intuition for volume of a simplex being $\frac 1{n!}$,Intuition for volume of a simplex being,\frac 1{n!},"Consider the simplex determined by the origin, and $n$ unit basis vectors. The volume of this simplex is $\frac{1}{n!}$, but I am intuitively struggling to see why. I have seen proofs for this and am convinced, but I can't help but think there must be a slicker or more intuitive argument for why this is so than what I have already seen. Any help would be appreciated!","Consider the simplex determined by the origin, and $n$ unit basis vectors. The volume of this simplex is $\frac{1}{n!}$, but I am intuitively struggling to see why. I have seen proofs for this and am convinced, but I can't help but think there must be a slicker or more intuitive argument for why this is so than what I have already seen. Any help would be appreciated!",,"['calculus', 'volume', 'simplex']"
79,"Which $f$ satisfy the equation $\,\,f(x)\,f(y)-f(x+y)=\sin x\,\sin y\,$?",Which  satisfy the equation ?,"f \,\,f(x)\,f(y)-f(x+y)=\sin x\,\sin y\,","Find all continuous functions $f$ which satisfy the functional equation  $$ f(x)\,f(y)-f(x+y)=\sin x\,\sin y, $$  for all $x,y\in\mathbb R$. I can prove that $f(n\pi)=\cos\left(n\pi\right)$ for all $n\in\mathbb Z$. First attempt. I have tried to prove that:  $$ f\left(\frac{\pi}n\right)=\cos\left(\frac{\pi}n\right),\quad \text{for all}\,\,\, n\in\mathbb Z\smallsetminus\{0\} \tag{1}, $$  but I have failed. If I prove $(1)$, then the functional equation will be solved completely using the  continuity of $f$. So how do we solve this functional equation?","Find all continuous functions $f$ which satisfy the functional equation  $$ f(x)\,f(y)-f(x+y)=\sin x\,\sin y, $$  for all $x,y\in\mathbb R$. I can prove that $f(n\pi)=\cos\left(n\pi\right)$ for all $n\in\mathbb Z$. First attempt. I have tried to prove that:  $$ f\left(\frac{\pi}n\right)=\cos\left(\frac{\pi}n\right),\quad \text{for all}\,\,\, n\in\mathbb Z\smallsetminus\{0\} \tag{1}, $$  but I have failed. If I prove $(1)$, then the functional equation will be solved completely using the  continuity of $f$. So how do we solve this functional equation?",,"['calculus', 'trigonometry', 'continuity', 'contest-math', 'functional-equations']"
80,What is infinity divided by infinity?,What is infinity divided by infinity?,,"This should be a simple question but I just want to make sure. I know $\infty/\infty$ is undefined. However, if we have 2 equal infinities divided by each other, would it be 1? And if we have an infinity divided by another half-as-big infinity, would we get 2? For example $\frac{1+1+1+\ldots}{2+2+2+\ldots}=\frac12$?","This should be a simple question but I just want to make sure. I know $\infty/\infty$ is undefined. However, if we have 2 equal infinities divided by each other, would it be 1? And if we have an infinity divided by another half-as-big infinity, would we get 2? For example $\frac{1+1+1+\ldots}{2+2+2+\ldots}=\frac12$?",,"['calculus', 'sequences-and-series', 'infinity', 'nonstandard-analysis']"
81,$\int_{0}^{\infty}\frac{\sin^{2n+1}(x)}{x} \mathrm {d}x$ Evaluate Integral,Evaluate Integral,\int_{0}^{\infty}\frac{\sin^{2n+1}(x)}{x} \mathrm {d}x,"Here is a fun integral I am trying to evaluate: $$\int_{0}^{\infty}\frac{\sin^{2n+1}(x)}{x} \ dx=\frac{\pi \binom{2n}{n}}{2^{2n+1}}.$$ I thought about integrating by parts $2n$ times and then using the binomial theorem for $\sin(x)$, that is, using $\dfrac{e^{ix}-e^{-ix}}{2i}$ form in the binomial series. But, I am having a rough time getting it set up correctly. Then, again, there is probably a better approach. $$\frac{1}{(2n)!}\int_{0}^{\infty}\frac{1}{(2i)^{2n}}\sum_{k=0}^{n}(-1)^{2n+1-k}\binom{2n}{k}\frac{d^{2n}}{dx^{2n}}(e^{i(2k-2n-1)x})\frac{dx}{x^{1-2n}}$$ or something like that. I doubt if that is anywhere close, but is my initial idea of using the binomial series for sin valid or is there a better way?. Thanks everyone.","Here is a fun integral I am trying to evaluate: $$\int_{0}^{\infty}\frac{\sin^{2n+1}(x)}{x} \ dx=\frac{\pi \binom{2n}{n}}{2^{2n+1}}.$$ I thought about integrating by parts $2n$ times and then using the binomial theorem for $\sin(x)$, that is, using $\dfrac{e^{ix}-e^{-ix}}{2i}$ form in the binomial series. But, I am having a rough time getting it set up correctly. Then, again, there is probably a better approach. $$\frac{1}{(2n)!}\int_{0}^{\infty}\frac{1}{(2i)^{2n}}\sum_{k=0}^{n}(-1)^{2n+1-k}\binom{2n}{k}\frac{d^{2n}}{dx^{2n}}(e^{i(2k-2n-1)x})\frac{dx}{x^{1-2n}}$$ or something like that. I doubt if that is anywhere close, but is my initial idea of using the binomial series for sin valid or is there a better way?. Thanks everyone.",,"['calculus', 'integration', 'trigonometry', 'improper-integrals']"
82,Prove: $\int_0^2 \frac{dx}{\sqrt{1+x^3}}=\frac{\Gamma\left(\frac{1}{6}\right)\Gamma\left(\frac{1}{3}\right)}{6\Gamma\left(\frac{1}{2}\right)}$,Prove:,\int_0^2 \frac{dx}{\sqrt{1+x^3}}=\frac{\Gamma\left(\frac{1}{6}\right)\Gamma\left(\frac{1}{3}\right)}{6\Gamma\left(\frac{1}{2}\right)},"Prove: $$ \int_{0}^{2}\frac{\mathrm{d}x}{\,\sqrt{\,{1 + x^{3}}\,}\,} = \frac{\Gamma\left(\,{1/6}\,\right) \Gamma\left(\,{1/3}\,\right)}{6\,\Gamma\left(\,{1/2}\,\right)} $$ First obvious sub is $t = 1 + x^{3}$ : $$ \frac{1}{3}\int_{1}^{9}{\left(\,{t - 1}\,\right)}^{-2/3}\, t^{-1/2}\, \mathrm{d}t $$ From here I tried many things like $\frac{1}{t}$ , $t-1$ , and more.  The trickiest part is the bounds! Reversing it from the answer the integral should be like $$ \frac{1}{6}\int_{0}^{1} x^{-2/3}\left(\,{1 - x}\,\right)^{-5/6}\,\mathrm{d}t $$ I'm not sure where the $1/2$ comes from and the $0$ to $1$ bounds.  Any idea or tip please ?.","Prove: First obvious sub is : From here I tried many things like , , and more.  The trickiest part is the bounds! Reversing it from the answer the integral should be like I'm not sure where the comes from and the to bounds.  Any idea or tip please ?.","
\int_{0}^{2}\frac{\mathrm{d}x}{\,\sqrt{\,{1 + x^{3}}\,}\,} =
\frac{\Gamma\left(\,{1/6}\,\right)
\Gamma\left(\,{1/3}\,\right)}{6\,\Gamma\left(\,{1/2}\,\right)}
 t = 1 + x^{3} 
\frac{1}{3}\int_{1}^{9}{\left(\,{t - 1}\,\right)}^{-2/3}\, t^{-1/2}\, \mathrm{d}t
 \frac{1}{t} t-1 
\frac{1}{6}\int_{0}^{1}
x^{-2/3}\left(\,{1 - x}\,\right)^{-5/6}\,\mathrm{d}t
 1/2 0 1","['calculus', 'integration']"
83,1 to the power of infinity formula,1 to the power of infinity formula,,"There is a general formula for indeterminate form $1 ^ {\infty}$ which I'm looking for a proof which is also used here . ( picture ) Given $$\lim_{x\to a} f(x) = 1$$ and $$\lim_{x\to a} g(x) = \infty$$ , what is $$\lim_{x\to a} f^{g} = e^{\lim_{x\to a}{(f-1)g}}\quad ? $$ I would appreciate it if somone could give me a proof of this formula.","There is a general formula for indeterminate form which I'm looking for a proof which is also used here . ( picture ) Given and , what is I would appreciate it if somone could give me a proof of this formula.",1 ^ {\infty} \lim_{x\to a} f(x) = 1 \lim_{x\to a} g(x) = \infty \lim_{x\to a} f^{g} = e^{\lim_{x\to a}{(f-1)g}}\quad ? ,"['calculus', 'limits']"
84,Proof of L'Hospitals Rule,Proof of L'Hospitals Rule,,"No matter where I would look it would seem that L'Hospital's Rule has a strange proof-given that they teach it in high school, it seems troublesome that I can't find a solid proof at that level of knowledge. Does anyone have a proof that is fairly basic? Or does proving it simply require higher math?","No matter where I would look it would seem that L'Hospital's Rule has a strange proof-given that they teach it in high school, it seems troublesome that I can't find a solid proof at that level of knowledge. Does anyone have a proof that is fairly basic? Or does proving it simply require higher math?",,[]
85,How to calculate the derivative of this integral?,How to calculate the derivative of this integral?,,"Here it is : $$ \frac{\mathrm d}{\mathrm dx}\left( \int_{\cos x}^{\sin x}{\sin \left( t^3 \right)\mathrm dt} \right) $$ I've got the answer but I don't know how to start , what to do ? Here is the answer :  $ \sin \left( \sin^3 x \right)\cos x + \sin \left( \cos ^{3}x \right)\sin x $ So first I calculate the primitive and then I derivate it. But I don't know how to integrate. Should I use 'substitution' method ? I tried but then i was blocked...","Here it is : $$ \frac{\mathrm d}{\mathrm dx}\left( \int_{\cos x}^{\sin x}{\sin \left( t^3 \right)\mathrm dt} \right) $$ I've got the answer but I don't know how to start , what to do ? Here is the answer :  $ \sin \left( \sin^3 x \right)\cos x + \sin \left( \cos ^{3}x \right)\sin x $ So first I calculate the primitive and then I derivate it. But I don't know how to integrate. Should I use 'substitution' method ? I tried but then i was blocked...",,"['calculus', 'integration']"
86,Evaluating a sum involving binomial coefficient in denominator,Evaluating a sum involving binomial coefficient in denominator,,"I came across the following sum: $$\sum_{k=0}^{\infty} \frac{(-1)^k}{(2k+1)^2}\frac{4^k}{{2k \choose k}}$$ I thought that this can be evaluated using the expansion of $\dfrac{\sin^{-1}x}{\sqrt{1-x^2}}$ but I couldn't make any use of it. Then I tried to use the following: $$\frac{1}{(2k+1)}\frac{1}{{2k \choose k}}=\frac{\Gamma(k+1)\Gamma(k+1)}{\Gamma(2k+2)}=\int_0^1 x^k(1-x)^k\,dx$$ but this didn't help either and now I am stuck. Any help is greatly appreciated. Thanks! EDIT: The sum originated from the following definite integral: $$\int_0^{\pi/2}\tan^{-1}(\sin x)\,dx$$","I came across the following sum: $$\sum_{k=0}^{\infty} \frac{(-1)^k}{(2k+1)^2}\frac{4^k}{{2k \choose k}}$$ I thought that this can be evaluated using the expansion of $\dfrac{\sin^{-1}x}{\sqrt{1-x^2}}$ but I couldn't make any use of it. Then I tried to use the following: $$\frac{1}{(2k+1)}\frac{1}{{2k \choose k}}=\frac{\Gamma(k+1)\Gamma(k+1)}{\Gamma(2k+2)}=\int_0^1 x^k(1-x)^k\,dx$$ but this didn't help either and now I am stuck. Any help is greatly appreciated. Thanks! EDIT: The sum originated from the following definite integral: $$\int_0^{\pi/2}\tan^{-1}(\sin x)\,dx$$",,"['calculus', 'integration', 'sequences-and-series', 'binomial-coefficients']"
87,"$\epsilon, \delta$...So what?",...So what?,"\epsilon, \delta","Over the course of my studies I often encounter phrases in reference material of the type ""and this avoids the need for using $\epsilon$, $\delta$ definitions"" or ""by this we can omit those complicated $\epsilon, \delta$ arguments"" , etc. In other words performing stunts in order to get around $\epsilon, \delta$. I've seen enough of this to think that it should be categorized as epsilondeltophobia , if you all will permit. Personally, I was thrilled to learn definitions in these terms because it was one of the first rigorous definitions given to me, all in terms of quantifier logic, and it was used for very fundamental things whose real meaning I always wondered about. In the beginning of course I didn't have a clue how to use the language, but I loved it anyways because it was like, ""wooow, deep maan"". Not to mention that later on, I began to see that all of the higher-order constructions that were built upon $\epsilon, \delta$-objects worked out perfectly, giving me more satisfaction that whoever came up with $\epsilon, \delta$ language knew what they were doing. So I'm not saying that it's not ok to develop an epsilondeltophobia , as we all do naturally in the beginning...but textbooks (some) seem to promote this fear, even some teachers, and this is what I'm not happy about. I think $\epsilon, \delta$ is great. Question: who thinks likewise? oppositely? Edit: I don't want this to come off as a pedantic ""rigor or death"" statement, or as a suggestion that first courses on calculus should always include $\epsilon, \delta$ (although maybe yes in mathematics). I'm just against the predisposal to it in a negative way.","Over the course of my studies I often encounter phrases in reference material of the type ""and this avoids the need for using $\epsilon$, $\delta$ definitions"" or ""by this we can omit those complicated $\epsilon, \delta$ arguments"" , etc. In other words performing stunts in order to get around $\epsilon, \delta$. I've seen enough of this to think that it should be categorized as epsilondeltophobia , if you all will permit. Personally, I was thrilled to learn definitions in these terms because it was one of the first rigorous definitions given to me, all in terms of quantifier logic, and it was used for very fundamental things whose real meaning I always wondered about. In the beginning of course I didn't have a clue how to use the language, but I loved it anyways because it was like, ""wooow, deep maan"". Not to mention that later on, I began to see that all of the higher-order constructions that were built upon $\epsilon, \delta$-objects worked out perfectly, giving me more satisfaction that whoever came up with $\epsilon, \delta$ language knew what they were doing. So I'm not saying that it's not ok to develop an epsilondeltophobia , as we all do naturally in the beginning...but textbooks (some) seem to promote this fear, even some teachers, and this is what I'm not happy about. I think $\epsilon, \delta$ is great. Question: who thinks likewise? oppositely? Edit: I don't want this to come off as a pedantic ""rigor or death"" statement, or as a suggestion that first courses on calculus should always include $\epsilon, \delta$ (although maybe yes in mathematics). I'm just against the predisposal to it in a negative way.",,"['calculus', 'soft-question', 'definition', 'education']"
88,smooth functions or continuous,smooth functions or continuous,,"When wesay a function is smooth? Is there any difference between smooth function and continuous function? If they are the same, why sometimes we say f is smooth and sometimes f is continuous?","When wesay a function is smooth? Is there any difference between smooth function and continuous function? If they are the same, why sometimes we say f is smooth and sometimes f is continuous?",,"['calculus', 'analysis', 'numerical-methods']"
89,Two Dirac delta functions in an integral?,Two Dirac delta functions in an integral?,,"For context, this is from a quantum mechanics lecture in which we were considering continuous eigenvalues of the position operator. Starting with the position eigenvalue equation, $$\hat{x}\,\phi(x_m, x)=x_m\phi(x_m,x)$$ where $x_m$ is the eigenvalue and $\phi(x_m, x)$ are the continuous eigenfunctions of the position operator $\hat x$.  The professor wrote that $\phi(x_m, x)=\delta(x-x_m)$ and stated that this is because the eigenbasis is continuous. But then he wrote the following $$\begin{align}\int_{-\infty}^{\infty}\phi^*(x_m,x)\phi({x_m}',x)\,dx &=\int_{-\infty}^{\infty}\delta(x_m-x)\delta({x_m}'-x)\,dx \tag{1}\\ &=\color{red}{\delta(x_m-{x_m}')}\end{align}$$ I don't understand how the expression in $(1)$ can be equal to the expression in red. I do understand that $$\begin{align}\int_{-\infty}^{\infty}\delta(x_m-x)\phi({x_m}',x)\,dx &=\phi({x_m}',x_m)\tag{2}\\&=\color{#080}{\delta(x_m-{x_m}')}\end{align}$$ since the integral 'sifts' out the only value of $x$ where the argument of the Dirac delta function is zero (at $x_m$). I have applied this sifting property for one Dirac delta function (as in $(2)$). But I don't understand how this works when there are two Dirac deltas in the integrand, $(1)$. By my logic, I think it should sift out each value, one at a time, so I think that $(1)$ should be  $$\int_{-\infty}^{\infty}\delta(x_m-x)\delta({x_m}'-x)\,dx =\delta(x_m)+\delta({x_m}')$$ where the results of the integration are added, since the values $x_m$ and ${x_m}'$ are sifted out one after the other , depending on which of $x_m$ and ${x_m}'$ are larger (here I assumed ${x_m}'\gt x_m$). Could someone please derive or explain why equation $(1)$ is true, or give me any hints to help me understand it.","For context, this is from a quantum mechanics lecture in which we were considering continuous eigenvalues of the position operator. Starting with the position eigenvalue equation, $$\hat{x}\,\phi(x_m, x)=x_m\phi(x_m,x)$$ where $x_m$ is the eigenvalue and $\phi(x_m, x)$ are the continuous eigenfunctions of the position operator $\hat x$.  The professor wrote that $\phi(x_m, x)=\delta(x-x_m)$ and stated that this is because the eigenbasis is continuous. But then he wrote the following $$\begin{align}\int_{-\infty}^{\infty}\phi^*(x_m,x)\phi({x_m}',x)\,dx &=\int_{-\infty}^{\infty}\delta(x_m-x)\delta({x_m}'-x)\,dx \tag{1}\\ &=\color{red}{\delta(x_m-{x_m}')}\end{align}$$ I don't understand how the expression in $(1)$ can be equal to the expression in red. I do understand that $$\begin{align}\int_{-\infty}^{\infty}\delta(x_m-x)\phi({x_m}',x)\,dx &=\phi({x_m}',x_m)\tag{2}\\&=\color{#080}{\delta(x_m-{x_m}')}\end{align}$$ since the integral 'sifts' out the only value of $x$ where the argument of the Dirac delta function is zero (at $x_m$). I have applied this sifting property for one Dirac delta function (as in $(2)$). But I don't understand how this works when there are two Dirac deltas in the integrand, $(1)$. By my logic, I think it should sift out each value, one at a time, so I think that $(1)$ should be  $$\int_{-\infty}^{\infty}\delta(x_m-x)\delta({x_m}'-x)\,dx =\delta(x_m)+\delta({x_m}')$$ where the results of the integration are added, since the values $x_m$ and ${x_m}'$ are sifted out one after the other , depending on which of $x_m$ and ${x_m}'$ are larger (here I assumed ${x_m}'\gt x_m$). Could someone please derive or explain why equation $(1)$ is true, or give me any hints to help me understand it.",,"['calculus', 'dirac-delta', 'quantum-mechanics']"
90,Asymptotic formula for ratio of double factorials,Asymptotic formula for ratio of double factorials,,"I am interested in getting an asymptotic formula for $$ \frac{(2n-1)!!} {(2n)!!}. $$ After some trial and error, I think the asymptotic can be of the form $\frac{1}{\sqrt{\alpha n + \beta}}.$ Use Stirling's formula, I got $\alpha = \pi$ Using software, I was able to get $\beta = \frac{\pi}{4}$ , but I have no idea how to prove this. So my question is: how do I show that $$ \lim_{n \to \infty} \left(\left(\frac{(2n)!!}{(2n-1)!!}\right)^{2} - \pi n\right) = \frac{\pi}{4} $$ ?","I am interested in getting an asymptotic formula for After some trial and error, I think the asymptotic can be of the form Use Stirling's formula, I got Using software, I was able to get , but I have no idea how to prove this. So my question is: how do I show that ?","
\frac{(2n-1)!!} {(2n)!!}.
 \frac{1}{\sqrt{\alpha n + \beta}}. \alpha = \pi \beta = \frac{\pi}{4} 
\lim_{n \to \infty} \left(\left(\frac{(2n)!!}{(2n-1)!!}\right)^{2} - \pi n\right) = \frac{\pi}{4}
","['calculus', 'limits', 'factorial']"
91,Difference between Increasing and Monotone increasing function,Difference between Increasing and Monotone increasing function,,"I have some confusion in difference between monotone increasing function and Increasing function. For example $$f(x)=x^3$$ is Monotone increasing i.e, if $$x_2 \gt x_1$$ then $$f(x_2) \gt f(x_1)$$ and some books give such functions as Strictly Increasing functions. But if $$f(x)= \begin{cases}        x & x\leq 1 \\       1 & 1\leq x\leq 2\\       x-1 & 2\leq x     \end{cases} $$ Is this function Monotone increasing?","I have some confusion in difference between monotone increasing function and Increasing function. For example $$f(x)=x^3$$ is Monotone increasing i.e, if $$x_2 \gt x_1$$ then $$f(x_2) \gt f(x_1)$$ and some books give such functions as Strictly Increasing functions. But if $$f(x)= \begin{cases}        x & x\leq 1 \\       1 & 1\leq x\leq 2\\       x-1 & 2\leq x     \end{cases} $$ Is this function Monotone increasing?",,"['calculus', 'derivatives']"
92,Determine if this series converges or diverges,Determine if this series converges or diverges,,"$$\sum_{n=1}^\infty \sin^{[n]}(1)$$ Where by $\sin^{[n]}(1)$ we mean $ \sin\left(\sin\left(\dots\sin(1)\right)\right)$ composed $n$ times. Have tried the divergence test, which fails.  Have tried Ratio test, also fails, as the limit is 1.  Integral test, or root test do not seem promising. Help is appreciated","$$\sum_{n=1}^\infty \sin^{[n]}(1)$$ Where by $\sin^{[n]}(1)$ we mean $ \sin\left(\sin\left(\dots\sin(1)\right)\right)$ composed $n$ times. Have tried the divergence test, which fails.  Have tried Ratio test, also fails, as the limit is 1.  Integral test, or root test do not seem promising. Help is appreciated",,"['calculus', 'sequences-and-series', 'power-series']"
93,"Integral $\int_{-\infty}^\infty\frac{\Gamma(x)\,\sin(\pi x)}{\Gamma\left(x+a\right)}\,dx$",Integral,"\int_{-\infty}^\infty\frac{\Gamma(x)\,\sin(\pi x)}{\Gamma\left(x+a\right)}\,dx","I would like to evaluate this integral: $$\mathcal F(a)=\int_{-\infty}^\infty\frac{\Gamma(x)\,\sin(\pi x)}{\Gamma\left(x+a\right)}\,dx,\quad a>0.\tag1$$ For all $a>0$ the integrand is a smooth oscillating function decaying for $x\to\pm\infty$. The poles of the gamma function in the numerator are cancelled by the sine factor. For $a\in\mathbb N$, the ratio of the gamma functions simplifies to a polynomial in the denominator, and in each case the integral can be pretty easily evaluated in a closed form, e.g. $$\mathcal F(3)=\int_{-\infty}^\infty\frac{\sin(\pi x)}{x\,(x+1)\,(x+2)}\,dx=2\pi.\tag2$$ Can we find a general formula for $\mathcal F(a)$ valid both for integer and non-integers positive values of $a$?","I would like to evaluate this integral: $$\mathcal F(a)=\int_{-\infty}^\infty\frac{\Gamma(x)\,\sin(\pi x)}{\Gamma\left(x+a\right)}\,dx,\quad a>0.\tag1$$ For all $a>0$ the integrand is a smooth oscillating function decaying for $x\to\pm\infty$. The poles of the gamma function in the numerator are cancelled by the sine factor. For $a\in\mathbb N$, the ratio of the gamma functions simplifies to a polynomial in the denominator, and in each case the integral can be pretty easily evaluated in a closed form, e.g. $$\mathcal F(3)=\int_{-\infty}^\infty\frac{\sin(\pi x)}{x\,(x+1)\,(x+2)}\,dx=2\pi.\tag2$$ Can we find a general formula for $\mathcal F(a)$ valid both for integer and non-integers positive values of $a$?",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'gamma-function']"
94,Does Tom catch Jerry?,Does Tom catch Jerry?,,"Tom has Jerry backed against a wall. Tom is distance 1 away (perpendicularly). At time t=0, Jerry runs along the wall. Tom runs directly towards Jerry. Tom always runs directly towards Jerry. Tom and Jerry both run at the same speed. Does Tom catch Jerry? How close does he get (in the limit t tends to infinity)? What shaped curve does Tom run? Edit: I made this problem up last week. Friends enjoyed it, I thought this site might too. Hint: Take the x-axis as the wall, and assume Jerry runs to the right, without loss of generality at speed 1. Let $x(t)$ and $y(t)$ be Tom's position at time $t$. So $x(0) = 0$, and $y(0) = 1$. Consider Tom's direction of travel at time $t$ towards Jerry at $(t, 0)$. Write $\theta$ for the (positive) angle below the horizon. Then $$ \tan \theta =  \frac{dy}{dx} =  \frac {y}{t-x} $$ Tom runs at unit speed, so also $$ \frac{dy}{dt} = - \sin \theta $$ $$ \frac{dx}{dt} = \cos \theta $$ That's as far as I got, I don't know how to solve such a complex differential equation.","Tom has Jerry backed against a wall. Tom is distance 1 away (perpendicularly). At time t=0, Jerry runs along the wall. Tom runs directly towards Jerry. Tom always runs directly towards Jerry. Tom and Jerry both run at the same speed. Does Tom catch Jerry? How close does he get (in the limit t tends to infinity)? What shaped curve does Tom run? Edit: I made this problem up last week. Friends enjoyed it, I thought this site might too. Hint: Take the x-axis as the wall, and assume Jerry runs to the right, without loss of generality at speed 1. Let $x(t)$ and $y(t)$ be Tom's position at time $t$. So $x(0) = 0$, and $y(0) = 1$. Consider Tom's direction of travel at time $t$ towards Jerry at $(t, 0)$. Write $\theta$ for the (positive) angle below the horizon. Then $$ \tan \theta =  \frac{dy}{dx} =  \frac {y}{t-x} $$ Tom runs at unit speed, so also $$ \frac{dy}{dt} = - \sin \theta $$ $$ \frac{dx}{dt} = \cos \theta $$ That's as far as I got, I don't know how to solve such a complex differential equation.",,"['calculus', 'ordinary-differential-equations', 'differential-games']"
95,"Is $\int_0^2 f(x) dx$ defined for $f(x)=x,x \ne 1$?",Is  defined for ?,"\int_0^2 f(x) dx f(x)=x,x \ne 1","Let $f(x)=x,x \ne 1$. Is $$\int_0^2 f(x) dx$$ defined? I'm currently a high school student, and we learn that the integral is the area under the graph. But in calculus textbooks and websites, I see some stuff about ""continuity"" and things being ""integrable"". So I was wondering if this simple case is considered ""integrable"" (because $\lim_{x\to1} f(x)$ is defined) or not (because it has a value ""missing"" altogether, rather than being discontinuous but still integrable like a step function). Thanks!","Let $f(x)=x,x \ne 1$. Is $$\int_0^2 f(x) dx$$ defined? I'm currently a high school student, and we learn that the integral is the area under the graph. But in calculus textbooks and websites, I see some stuff about ""continuity"" and things being ""integrable"". So I was wondering if this simple case is considered ""integrable"" (because $\lim_{x\to1} f(x)$ is defined) or not (because it has a value ""missing"" altogether, rather than being discontinuous but still integrable like a step function). Thanks!",,"['calculus', 'integration', 'analysis']"
96,Find the area enclosed by $\sqrt{(x-2)^2+(y-3)^2} + 2\sqrt{(x-3)^2+(y-1)^2} = 4$,Find the area enclosed by,\sqrt{(x-2)^2+(y-3)^2} + 2\sqrt{(x-3)^2+(y-1)^2} = 4,"Question: What is the area of the interior of the simple closed curve described by the equation $\sqrt{(x-2)^2+(y-3)^2} + 2\sqrt{(x-3)^2+(y-1)^2} = 4$? Comments: I came up with this specific problem myself in response to my earlier question , which I don't think was well posed, or at least it was not clear what I was after: to see how to find the area of the interior of a Jordan curve that is described by an implicit function. To see how this area looks like, I uploaded a picture from WolframAlpha: As you can see, it is quite egg-like. We can generalize; the object could be called a weighted ellipse [edit: usually called a Cartesian oval ] with an equation of the form $\sqrt{(x-x_1)^2+(y-y_1)^2} + a \cdot \sqrt{(x-x_2)^2+(y-y_2)^2} = k$ where $(x_1,y_1)$ and $(x_2,y_2)$ are the Cartesian coordinates of the focal points of this weighted ellipse and $a$ is a weight (it equals $1$ in the case of an ordinary ellipse). As a bonus question, I would like to see how to find the area of this object.","Question: What is the area of the interior of the simple closed curve described by the equation $\sqrt{(x-2)^2+(y-3)^2} + 2\sqrt{(x-3)^2+(y-1)^2} = 4$? Comments: I came up with this specific problem myself in response to my earlier question , which I don't think was well posed, or at least it was not clear what I was after: to see how to find the area of the interior of a Jordan curve that is described by an implicit function. To see how this area looks like, I uploaded a picture from WolframAlpha: As you can see, it is quite egg-like. We can generalize; the object could be called a weighted ellipse [edit: usually called a Cartesian oval ] with an equation of the form $\sqrt{(x-x_1)^2+(y-y_1)^2} + a \cdot \sqrt{(x-x_2)^2+(y-y_2)^2} = k$ where $(x_1,y_1)$ and $(x_2,y_2)$ are the Cartesian coordinates of the focal points of this weighted ellipse and $a$ is a weight (it equals $1$ in the case of an ordinary ellipse). As a bonus question, I would like to see how to find the area of this object.",,"['calculus', 'area']"
97,"Evaluating $\lim \limits_{n\to \infty}\,\,\, n\!\! \int\limits_{0}^{\pi/2}\!\! \left(1-\sqrt [n]{\sin x} \right)\,\mathrm dx$",Evaluating,"\lim \limits_{n\to \infty}\,\,\, n\!\! \int\limits_{0}^{\pi/2}\!\! \left(1-\sqrt [n]{\sin x} \right)\,\mathrm dx","Evaluate the following limit:   $$\lim \limits_{n\to \infty}\,\,\, n\!\! \int\limits_{0}^{\pi/2}\!\! \left(1-\sqrt [n]{\sin x} \right)\,\mathrm dx $$ I have done the problem . My method: First I applied L'Hôpital's rule as it can be made of the form $\frac0 0$. Then I used weighted mean value theorem and using sandwich theorem reduced the limit to an integral which could be evaluated using properties of define integration . I would like to see other different ways to solve for the limit.","Evaluate the following limit:   $$\lim \limits_{n\to \infty}\,\,\, n\!\! \int\limits_{0}^{\pi/2}\!\! \left(1-\sqrt [n]{\sin x} \right)\,\mathrm dx $$ I have done the problem . My method: First I applied L'Hôpital's rule as it can be made of the form $\frac0 0$. Then I used weighted mean value theorem and using sandwich theorem reduced the limit to an integral which could be evaluated using properties of define integration . I would like to see other different ways to solve for the limit.",,"['calculus', 'sequences-and-series', 'limits', 'integration', 'convergence-divergence']"
98,How did Ramanujan get this result?,How did Ramanujan get this result?,,"We know Ramanujan got this result $$\sqrt{1+2\sqrt{1+3\sqrt{1+\cdots }}}=3$$ and he used the formula $$x+n+a=\sqrt{ax+{{(n+a)}^{2}}+x\sqrt{a(x+n)+{{(n+a)}^{2}}+(x+n)\sqrt{\cdots }}}$$ where $x=2,n=1,a=0$ ,we get the first result, but I don't know how to prove it, can you help me?","We know Ramanujan got this result $$\sqrt{1+2\sqrt{1+3\sqrt{1+\cdots }}}=3$$ and he used the formula $$x+n+a=\sqrt{ax+{{(n+a)}^{2}}+x\sqrt{a(x+n)+{{(n+a)}^{2}}+(x+n)\sqrt{\cdots }}}$$ where $x=2,n=1,a=0$ ,we get the first result, but I don't know how to prove it, can you help me?",,['calculus']
99,Closed form for $\sum_{n=0}^\infty\frac{\operatorname{Li}_{1/2}\left(-2^{-2^{-n}}\right)}{\sqrt{2^n}}$,Closed form for,\sum_{n=0}^\infty\frac{\operatorname{Li}_{1/2}\left(-2^{-2^{-n}}\right)}{\sqrt{2^n}},"Let $$S=\sum_{n=0}^\infty\frac{\operatorname{Li}_{1/2}\left(-2^{-2^{-n}}\right)}{\sqrt{2^n}},\tag1$$ where $\operatorname{Li}_a(z)$ is the polylogarithm . For $a=1/2$ it can be represented as $$\begin{align}\operatorname{Li}_{1/2}(z)&=\sum_{k=1}^\infty\frac{z^k}{\sqrt k}\tag2\\&=\int_0^\infty\frac z{\sqrt{\pi\,x}\ \left(e^x-z\right)}\,dx.\tag3\end{align}$$ How to find a closed-form expression for $S$?","Let $$S=\sum_{n=0}^\infty\frac{\operatorname{Li}_{1/2}\left(-2^{-2^{-n}}\right)}{\sqrt{2^n}},\tag1$$ where $\operatorname{Li}_a(z)$ is the polylogarithm . For $a=1/2$ it can be represented as $$\begin{align}\operatorname{Li}_{1/2}(z)&=\sum_{k=1}^\infty\frac{z^k}{\sqrt k}\tag2\\&=\int_0^\infty\frac z{\sqrt{\pi\,x}\ \left(e^x-z\right)}\,dx.\tag3\end{align}$$ How to find a closed-form expression for $S$?",,"['calculus', 'sequences-and-series', 'contest-math', 'closed-form', 'polylogarithm']"
