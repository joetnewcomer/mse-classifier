,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Set of increasing/Decreasing functions,Set of increasing/Decreasing functions,,A function f : N → N is increasing if f(n + 1) ≥ f(n) for all n and decreasing if f(n + 1) ≤ f(n) for all n Is the set of increasing functions countable or uncountable? What about the set of decreasing functions? I have a feeling the increasing functions are uncountable but im not sure to show it. Some injection to the Power set?,A function f : N → N is increasing if f(n + 1) ≥ f(n) for all n and decreasing if f(n + 1) ≤ f(n) for all n Is the set of increasing functions countable or uncountable? What about the set of decreasing functions? I have a feeling the increasing functions are uncountable but im not sure to show it. Some injection to the Power set?,,['elementary-set-theory']
1,Is this complete partial order?,Is this complete partial order?,,"Is $(\mathbb{N} , \#)$ complete partial order, where $m\#n$ iff $(\exists k \in \mathbb{N})m=kn$. I proved it's partial order. For completeness I take directed subset and I know there is upper bond $1$ but does it mean there is supremum?","Is $(\mathbb{N} , \#)$ complete partial order, where $m\#n$ iff $(\exists k \in \mathbb{N})m=kn$. I proved it's partial order. For completeness I take directed subset and I know there is upper bond $1$ but does it mean there is supremum?",,"['elementary-set-theory', 'order-theory']"
2,"Prove that if $A$ and $B$ are finite, then $A \cup B$ is finite","Prove that if  and  are finite, then  is finite",A B A \cup B,"Statement: if $A$ and $B$ are finite, then $A \cup B$ is finite Proof: If $A$ and $B$ are finite, then there exists $m, n \in \mathbb{N}$ such that $A \approx \mathbb{N}_{m}$ and $B \approx \mathbb{N}_{n}$. Let $f: A \xrightarrow[onto]{1-1} \mathbb{N}_{m}$ and $h: B\xrightarrow[onto]{1-1} \mathbb{N}_{n}$. Then $f \cup h: A\cup B \xrightarrow[onto]{1-1} \mathbb{N}_{m+n}$, which shows that $A \cup B \approx \mathbb{N}_{m+n}$. Thus $A \cup B$ is finite. Is this proof valid?","Statement: if $A$ and $B$ are finite, then $A \cup B$ is finite Proof: If $A$ and $B$ are finite, then there exists $m, n \in \mathbb{N}$ such that $A \approx \mathbb{N}_{m}$ and $B \approx \mathbb{N}_{n}$. Let $f: A \xrightarrow[onto]{1-1} \mathbb{N}_{m}$ and $h: B\xrightarrow[onto]{1-1} \mathbb{N}_{n}$. Then $f \cup h: A\cup B \xrightarrow[onto]{1-1} \mathbb{N}_{m+n}$, which shows that $A \cup B \approx \mathbb{N}_{m+n}$. Thus $A \cup B$ is finite. Is this proof valid?",,"['elementary-set-theory', 'proof-writing', 'proof-verification', 'solution-verification']"
3,well ordering principle implies Zorn's Lemma,well ordering principle implies Zorn's Lemma,,"In here: Proving that well ordering principle implies Zorn's Lemma. I asked how to finish a proof of this statement. After a few helpful remarks, I think I have managed to finish it. What do you think? Given that on every set, a well ordering can be defined, we should prove that Given a partially ordered set $A$, if every increasing chain in $A$ has an upper bound in $A$, Then $A$ has a maximal element. Proof: Take $A$ partially ordered by $R$.  We know that there exists a well ordering $S$ on $A$. Let $k$ be the smallest ordinal s.t. $k=|A|$ and let, $k^+=k+1$. Define by transfinite induction, a function, $g:k^+ \rightarrow A$ as follows: $g(0)$ is the first element in $A$ by $S$. For any , $\alpha < k^+$: If $\alpha$ is a successor ordinal, s.t. $\alpha = \beta + 1$, then, define $g(\alpha)$, the first element (by $S$), $a \in A$ such that $g(\beta) <_{R} a$ if $\alpha$ is a limit ordinal, then, The set $\{g(\beta);\beta<\alpha\}$, is linearly ordered by $R$. Therefor it has an upper bound. From all the uppers bounds, we will take the first (By $S$) to be $g(a)$. $g(k^{+})$ is linearly ordered. So, by the lemma assumption, it has an upper bound in $M \in A$. We claim that $M$ is a maximal element of $A$. Because, if there would be $x >_{R} M$ in $A$, by the construction of $g$, $g(k^{+})$ would contain an element which ia greater or equall (by $R$) to $x$, contradicting the fact that $M$ is an upper bound of $g(k^{+})$. The step which I'm not sure of is step 5. I am not sure weather the fact that $|k|=|A|$ and that $g(k^{+})$ is isomorphic to $k$ are enough. What do you think? Thank you! Shir","In here: Proving that well ordering principle implies Zorn's Lemma. I asked how to finish a proof of this statement. After a few helpful remarks, I think I have managed to finish it. What do you think? Given that on every set, a well ordering can be defined, we should prove that Given a partially ordered set $A$, if every increasing chain in $A$ has an upper bound in $A$, Then $A$ has a maximal element. Proof: Take $A$ partially ordered by $R$.  We know that there exists a well ordering $S$ on $A$. Let $k$ be the smallest ordinal s.t. $k=|A|$ and let, $k^+=k+1$. Define by transfinite induction, a function, $g:k^+ \rightarrow A$ as follows: $g(0)$ is the first element in $A$ by $S$. For any , $\alpha < k^+$: If $\alpha$ is a successor ordinal, s.t. $\alpha = \beta + 1$, then, define $g(\alpha)$, the first element (by $S$), $a \in A$ such that $g(\beta) <_{R} a$ if $\alpha$ is a limit ordinal, then, The set $\{g(\beta);\beta<\alpha\}$, is linearly ordered by $R$. Therefor it has an upper bound. From all the uppers bounds, we will take the first (By $S$) to be $g(a)$. $g(k^{+})$ is linearly ordered. So, by the lemma assumption, it has an upper bound in $M \in A$. We claim that $M$ is a maximal element of $A$. Because, if there would be $x >_{R} M$ in $A$, by the construction of $g$, $g(k^{+})$ would contain an element which ia greater or equall (by $R$) to $x$, contradicting the fact that $M$ is an upper bound of $g(k^{+})$. The step which I'm not sure of is step 5. I am not sure weather the fact that $|k|=|A|$ and that $g(k^{+})$ is isomorphic to $k$ are enough. What do you think? Thank you! Shir",,"['elementary-set-theory', 'axiom-of-choice']"
4,What does $|A|$ denote in set notation?,What does  denote in set notation?,|A|,"What does $|A|$ of a set $A$ denote? Also, what does $A\leftrightarrow B$ of sets $A, B$ mean? I encountered this in one of my textbooks which said: Of two sets $A, B$ we know $|B|$ but $|A|$ is unknown. If we succeed   in constructing a bijection $A\leftrightarrow B$, then$|A|=|B|$. A proof which shows   $|A|=|B|$ by such an explicit construction is called a bijective proof   or combinatorial proof. I'm afraid I'm new to set notation. I would be grateful if someone could point me to a good resource on it.","What does $|A|$ of a set $A$ denote? Also, what does $A\leftrightarrow B$ of sets $A, B$ mean? I encountered this in one of my textbooks which said: Of two sets $A, B$ we know $|B|$ but $|A|$ is unknown. If we succeed   in constructing a bijection $A\leftrightarrow B$, then$|A|=|B|$. A proof which shows   $|A|=|B|$ by such an explicit construction is called a bijective proof   or combinatorial proof. I'm afraid I'm new to set notation. I would be grateful if someone could point me to a good resource on it.",,"['elementary-set-theory', 'notation']"
5,Sigma field generated by Borel sets is the same as sigma field generated by intervals,Sigma field generated by Borel sets is the same as sigma field generated by intervals,,"Let $\mathcal{R} = \{ B_1 \times B_2 : B_1,B_2 \in \mathcal{B} \} $ where $\mathcal{B}$ is the sigma field of Borel sets. Let $\mathcal{I} = \{ I_1 \times I_2 : I_1,I_2 \; \; \text{are intervals} \} $. We want to show that $\sigma(\mathcal{R}) = \sigma( \mathcal{I} )$. My try: We know that the Borel sets are generated by intervals, hence we must have $\mathcal{I} \subseteq \mathcal{R} $. Therefore, $\sigma( \mathcal{I} ) \subset \sigma( \mathcal{R} ) $. I am kind of stuck trying to prove the other direction. Can someone help me? It would be really appreciated. Thanks.","Let $\mathcal{R} = \{ B_1 \times B_2 : B_1,B_2 \in \mathcal{B} \} $ where $\mathcal{B}$ is the sigma field of Borel sets. Let $\mathcal{I} = \{ I_1 \times I_2 : I_1,I_2 \; \; \text{are intervals} \} $. We want to show that $\sigma(\mathcal{R}) = \sigma( \mathcal{I} )$. My try: We know that the Borel sets are generated by intervals, hence we must have $\mathcal{I} \subseteq \mathcal{R} $. Therefore, $\sigma( \mathcal{I} ) \subset \sigma( \mathcal{R} ) $. I am kind of stuck trying to prove the other direction. Can someone help me? It would be really appreciated. Thanks.",,"['real-analysis', 'measure-theory', 'elementary-set-theory']"
6,Is the intersection of a chain of covers also a cover?,Is the intersection of a chain of covers also a cover?,,"Let $\mathcal{F}$ be a family of sets covering some set $X$, so $\bigcup_{F \in \mathcal{F}} F=X$. Assume we take an infinite chain $\mathcal{X}$ of nested families $\mathcal{F}''\subset \mathcal{F}'\subset \mathcal{F}$ so for every $\mathcal{F}_1, \mathcal{F}_2 \in \mathcal{X}$ either $\mathcal{F}_1 \subset \mathcal{F}_2$ or the other way round, where inclusion is strict, such that we always have $\bigcup_{F \in \mathcal{F}'} F=X$ for all $\mathcal{F}' \in \mathcal{X}$. Does it necessarily follows that $\bigcup_{F \in \bigcap_{\mathcal{F}' \in \mathcal{X}}} F=X$ or there is a counter example?","Let $\mathcal{F}$ be a family of sets covering some set $X$, so $\bigcup_{F \in \mathcal{F}} F=X$. Assume we take an infinite chain $\mathcal{X}$ of nested families $\mathcal{F}''\subset \mathcal{F}'\subset \mathcal{F}$ so for every $\mathcal{F}_1, \mathcal{F}_2 \in \mathcal{X}$ either $\mathcal{F}_1 \subset \mathcal{F}_2$ or the other way round, where inclusion is strict, such that we always have $\bigcup_{F \in \mathcal{F}'} F=X$ for all $\mathcal{F}' \in \mathcal{X}$. Does it necessarily follows that $\bigcup_{F \in \bigcap_{\mathcal{F}' \in \mathcal{X}}} F=X$ or there is a counter example?",,['elementary-set-theory']
7,Inequality with the supremum,Inequality with the supremum,,"I am trying to prove the following statement for $A\subset \mathbb{R},~\epsilon>0$ with $A$ bounded above: $\sup(A)-\epsilon<a\leq\sup(A)$, for some $a \in A$ I have tried dividing it into two cases. Case 1: $\sup(A)\in A$. Then take $a=\sup(A)$ and we are done. Case 2: $\sup(A)\notin A$. I tried to formalise the idea that if we started writing down elements of $A$ in increasing order, then the maximum element of these lists must tend to $\sup(A)$. This is because if it didn't, then there would be some element at which we would have to stop before we got as close as we wanted to $\sup(A)$. This element would be the least upper bound, but $\sup(A)\notin A $ which is a contradiction. Hence there exists $\epsilon$ such that $|a_n-\sup(A)|<\epsilon$ for some $n$ and the result follows. Is this proof valid? Are there any better ones? Thanks.","I am trying to prove the following statement for $A\subset \mathbb{R},~\epsilon>0$ with $A$ bounded above: $\sup(A)-\epsilon<a\leq\sup(A)$, for some $a \in A$ I have tried dividing it into two cases. Case 1: $\sup(A)\in A$. Then take $a=\sup(A)$ and we are done. Case 2: $\sup(A)\notin A$. I tried to formalise the idea that if we started writing down elements of $A$ in increasing order, then the maximum element of these lists must tend to $\sup(A)$. This is because if it didn't, then there would be some element at which we would have to stop before we got as close as we wanted to $\sup(A)$. This element would be the least upper bound, but $\sup(A)\notin A $ which is a contradiction. Hence there exists $\epsilon$ such that $|a_n-\sup(A)|<\epsilon$ for some $n$ and the result follows. Is this proof valid? Are there any better ones? Thanks.",,"['real-analysis', 'elementary-set-theory']"
8,A question about convex set,A question about convex set,,"I need to prove the closed set $C\subseteq \mathbb{R}_{+}$ is a convex. And let $x$, $y$ be arbitrary given in $C$, I have proved that $1/2(x+y)\in C$. Then does this means $C$ is convex ?","I need to prove the closed set $C\subseteq \mathbb{R}_{+}$ is a convex. And let $x$, $y$ be arbitrary given in $C$, I have proved that $1/2(x+y)\in C$. Then does this means $C$ is convex ?",,"['general-topology', 'functional-analysis', 'elementary-set-theory', 'operator-algebras']"
9,Is the Cartesian product of an infinite number of $\mathbb{Z}^+$ countable?,Is the Cartesian product of an infinite number of  countable?,\mathbb{Z}^+,"We know the Cartesian product of a finite number of $\mathbb{Z}^+$ is countable, for example, $\mathbb{Z}^+ \times \mathbb{Z}^+ \times \mathbb{Z}^+$, because, let $m, n, p$ be from each of the $\mathbb{Z}^+$,  we can find a one-to-one function $2^m 3^n 5^p$ that maps them to a subset of $\mathbb{Z}^+$. But what if we increase the number of $\mathbb{Z}^+$ to (countable) infinity, i.e. $$ \mathbb{Z}^+ \times \mathbb{Z}^+ \times \mathbb{Z}^+ \times \cdots $$ ?","We know the Cartesian product of a finite number of $\mathbb{Z}^+$ is countable, for example, $\mathbb{Z}^+ \times \mathbb{Z}^+ \times \mathbb{Z}^+$, because, let $m, n, p$ be from each of the $\mathbb{Z}^+$,  we can find a one-to-one function $2^m 3^n 5^p$ that maps them to a subset of $\mathbb{Z}^+$. But what if we increase the number of $\mathbb{Z}^+$ to (countable) infinity, i.e. $$ \mathbb{Z}^+ \times \mathbb{Z}^+ \times \mathbb{Z}^+ \times \cdots $$ ?",,['elementary-set-theory']
10,Cardinality of product of two sets is the product of the cardinalities of both sets,Cardinality of product of two sets is the product of the cardinalities of both sets,,"Suppose $|X| = n$ and $|Y| = m$. We want to show $|X \times Y | = mn$. MY attempt: By hypothesis, we can find bijections $f: X \to \{ 1,...,n\}$ and $g : Y \to \{1,...,m\}$. We want to find a bijection from $X \times Y \to \{ 1,....,nm\}$. I was thinking maybe of $h(x) = 2^x    3^y$. But it doesnt seem to be bijective. How can we find a bijection? Thanks a lot.","Suppose $|X| = n$ and $|Y| = m$. We want to show $|X \times Y | = mn$. MY attempt: By hypothesis, we can find bijections $f: X \to \{ 1,...,n\}$ and $g : Y \to \{1,...,m\}$. We want to find a bijection from $X \times Y \to \{ 1,....,nm\}$. I was thinking maybe of $h(x) = 2^x    3^y$. But it doesnt seem to be bijective. How can we find a bijection? Thanks a lot.",,['elementary-set-theory']
11,"How to create a Reflexive-, symmetric-, and transitive closures?","How to create a Reflexive-, symmetric-, and transitive closures?",,"I'm working on a task where I need to find out the reflexive, symmetric and transitive closures of R. Statement is given below: Assume that U = {1, 2, 3, a, b} and let the relation R on U which is  given by R = {<2,3>, <3, 2>, <1, a>}  1. What is the reflexive closure of R? 2. What is the symmetric closure of R? 3. What is the transitive closure of R? Here is my answers: R $\cup$ {< 2, 2 >, <3, 3>, } - reflexive closure R $\cup$ {< a, 1 >} - symmetric closure R $\cup$ {<1, 2>, <1, 3>} - transitive closure I would appreciate if someone could see if i've done this correct or if i'm missing something. Thanks alot!","I'm working on a task where I need to find out the reflexive, symmetric and transitive closures of R. Statement is given below: Assume that U = {1, 2, 3, a, b} and let the relation R on U which is  given by R = {<2,3>, <3, 2>, <1, a>}  1. What is the reflexive closure of R? 2. What is the symmetric closure of R? 3. What is the transitive closure of R? Here is my answers: R $\cup$ {< 2, 2 >, <3, 3>, } - reflexive closure R $\cup$ {< a, 1 >} - symmetric closure R $\cup$ {<1, 2>, <1, 3>} - transitive closure I would appreciate if someone could see if i've done this correct or if i'm missing something. Thanks alot!",,"['elementary-set-theory', 'relations']"
12,Intersection of int(cl) of open sets,Intersection of int(cl) of open sets,,"$\newcommand{\cl}{\operatorname{cl}}$ $\newcommand{\i}{\operatorname{int}}$ Prove that if $A$ and $B$ are open, then $\i(\cl(A\cap B))=\i(\cl A) \cap \i(\cl B)$. One way implication is easy as we have $$\cl(A\cap B)\subseteq \cl A \cap \cl B \Rightarrow \i(\cl(A\cap B))\subseteq \i(\cl(A)\cap \cl(B))= \i \cl A \cap \i\cl B. $$ I had difficulties in proving the other way. Let $x \in \i\cl(A) \cap \i\cl(B).$ Then there are open neighborhoods $U$, $V$ of $x$ such that $x\in U\subseteq \cl A$ and $x\in V\subseteq \cl B.$ I want to show that$ U\cap V \subseteq \cl(A \cap B)$ hence implies that this way implication is true. let $y\in U\cap V$ and $R$ to be any open neighborhood of $y$. Then $R\cap A$ and$ R\cap B$ are non-empty. But I am stuck here when I try to prove that $R \cap A \cap B$ is non-empty. (Because if $R \cap A\cap B$ is non-empty were to be true, then I am done). Can anyone give me some hints to proceed in this proof?Or actually I am heading in the wrong direction?","$\newcommand{\cl}{\operatorname{cl}}$ $\newcommand{\i}{\operatorname{int}}$ Prove that if $A$ and $B$ are open, then $\i(\cl(A\cap B))=\i(\cl A) \cap \i(\cl B)$. One way implication is easy as we have $$\cl(A\cap B)\subseteq \cl A \cap \cl B \Rightarrow \i(\cl(A\cap B))\subseteq \i(\cl(A)\cap \cl(B))= \i \cl A \cap \i\cl B. $$ I had difficulties in proving the other way. Let $x \in \i\cl(A) \cap \i\cl(B).$ Then there are open neighborhoods $U$, $V$ of $x$ such that $x\in U\subseteq \cl A$ and $x\in V\subseteq \cl B.$ I want to show that$ U\cap V \subseteq \cl(A \cap B)$ hence implies that this way implication is true. let $y\in U\cap V$ and $R$ to be any open neighborhood of $y$. Then $R\cap A$ and$ R\cap B$ are non-empty. But I am stuck here when I try to prove that $R \cap A \cap B$ is non-empty. (Because if $R \cap A\cap B$ is non-empty were to be true, then I am done). Can anyone give me some hints to proceed in this proof?Or actually I am heading in the wrong direction?",,"['general-topology', 'elementary-set-theory']"
13,Describe explicitly the $M$-measurable functions in case $M$ is one of the following $\sigma$-algebras:,Describe explicitly the -measurable functions in case  is one of the following -algebras:,M M \sigma,"Describe explicitly the $M$-measurable functions in case $M$ is one of the following $\sigma$-algebras: (a) $M=\{\emptyset,X\}$ (b) $M=2^{X}$ (c) For certain disjoint sets $E_1,...,E_N$, $X=\cup_{k=1}^N E_k$, and $M$ is the algebra (in fact, $\sigma$-algebra) generated by the collection of sets $\{E_1,...,E_N\}$. Here's my book's definition of $M$-measurable: Suppose $f:X\to[-\infty,\infty]$. Then $f$ is $M$-measurable if for all $t\in[-\infty,\infty]$ the set $f^{-1}([-\infty,t])$ belongs to $M$. Inn other words, $\{x\in X|f(x)\le t\}\in M$. Of course, the form of the inequality $f(x)\le t$ is arbitrary. Thanks.","Describe explicitly the $M$-measurable functions in case $M$ is one of the following $\sigma$-algebras: (a) $M=\{\emptyset,X\}$ (b) $M=2^{X}$ (c) For certain disjoint sets $E_1,...,E_N$, $X=\cup_{k=1}^N E_k$, and $M$ is the algebra (in fact, $\sigma$-algebra) generated by the collection of sets $\{E_1,...,E_N\}$. Here's my book's definition of $M$-measurable: Suppose $f:X\to[-\infty,\infty]$. Then $f$ is $M$-measurable if for all $t\in[-\infty,\infty]$ the set $f^{-1}([-\infty,t])$ belongs to $M$. Inn other words, $\{x\in X|f(x)\le t\}\in M$. Of course, the form of the inequality $f(x)\le t$ is arbitrary. Thanks.",,"['real-analysis', 'analysis', 'measure-theory', 'elementary-set-theory']"
14,countability of a set,countability of a set,,"Is this set countable or uncountable? ""Set of binary strings of length greater than 30"" not sure if length can be infinite or has to be considered finite. For every binary string we can map it to the corresponding decimal value in the set of natural numbers. But if length becomes infinite then decimal value would not exist. It becomes confusing after this.","Is this set countable or uncountable? ""Set of binary strings of length greater than 30"" not sure if length can be infinite or has to be considered finite. For every binary string we can map it to the corresponding decimal value in the set of natural numbers. But if length becomes infinite then decimal value would not exist. It becomes confusing after this.",,['elementary-set-theory']
15,"Prove or disprove the statement: There exists a set T such that for all sets S, (S ⋂ T = ∅)","Prove or disprove the statement: There exists a set T such that for all sets S, (S ⋂ T = ∅)",,"I need help proving or disproving this statement. For the negation of the statement I got: For every set T, there exists a set S, where (S ⋂ T ≠ ∅). Is this negation correct? Can someone please help me prove or disprove this statement? I'm really confused.","I need help proving or disproving this statement. For the negation of the statement I got: For every set T, there exists a set S, where (S ⋂ T ≠ ∅). Is this negation correct? Can someone please help me prove or disprove this statement? I'm really confused.",,"['elementary-set-theory', 'logic']"
16,"Let $C$ be a set of sets defined as follows,","Let  be a set of sets defined as follows,",C,"I'm in Theory of Computation, I've already taken Set Theory so I'm familiar with the terminology but this question is not making sense to me. Let $C$ be a set of sets defined as follows: $\emptyset\in C$ If $S_1\in C$ and $S_2\in C$ then $\{S_1, S_2\}\in C$. If $S_1\in C$ and $S_2\in C$ then $S_1\times S_2\in C$. Nothing is in $C$ except that which follows from (1), (2), and (3). b) Give an example of a set $S$ of ordered pairs such that $S\in C$, and $|S|>1$ c) Does $C$ contain any infinite sets? d) Is $C$ countable or uncountable? I'm not looking for an answer, just a way of understanding what exactly is going on and a way to find the answer would be a lifesaver! Thank you!","I'm in Theory of Computation, I've already taken Set Theory so I'm familiar with the terminology but this question is not making sense to me. Let $C$ be a set of sets defined as follows: $\emptyset\in C$ If $S_1\in C$ and $S_2\in C$ then $\{S_1, S_2\}\in C$. If $S_1\in C$ and $S_2\in C$ then $S_1\times S_2\in C$. Nothing is in $C$ except that which follows from (1), (2), and (3). b) Give an example of a set $S$ of ordered pairs such that $S\in C$, and $|S|>1$ c) Does $C$ contain any infinite sets? d) Is $C$ countable or uncountable? I'm not looking for an answer, just a way of understanding what exactly is going on and a way to find the answer would be a lifesaver! Thank you!",,"['elementary-set-theory', 'computational-complexity']"
17,A particular measure in the Cantor space $2^\infty$ / How to prove it also defines a $\sigma$-algebra?,A particular measure in the Cantor space  / How to prove it also defines a -algebra?,2^\infty \sigma,"Consider the following measure $\mu$ for the Cantor set (seen as the space of infinite sequences of 0's and 1's):  $$ \mu\left(E\right) = \lambda \left(g\left(E\right) \right) \tag{1}$$ where $g:2^\infty \to \left[0,1\right]$ is the function with the rule $(x_i)_{i=1}^\infty \mapsto \sum_{i=1}^\infty x_i/2^i$ and $\lambda$ is the Lebesgue measure. This rule suggests that a set must be called measurable in $2^\infty$ iff its image under $g$ its Lebesgue-measurable in $[0,1]$. This function is continuous and surjective but not injective (e.g., $(01000...)$ and $(00111..)$ have the same image). This was taken from J. Oxtoby's ""Measure and Category"" [2nd ed. p. 84]. One thing that is not proven in the book is that this actually defines a $\sigma$-algebra in the space $2^\infty$. One condition is very easy to check, for instance, if the sets $(E_i)_{i=1}^\infty$ are such that $g(E_i)$ is measurable for every $i$ then $\bigcup_i E_i$ is measurable since $g(\bigcup_i E_i)= \bigcup_i g(E_i)$. I am having some trouble proving that if $E\subseteq 2^\infty$ is such that $g(E)$ is measurable, then $g(2^\infty\setminus E)$ is measurable. I think this condition is necessary for (1) to define a $\sigma$-algebra and a measure in $2^\infty$. Am I missing some elementary set-theoretic fact here that makes this evident?","Consider the following measure $\mu$ for the Cantor set (seen as the space of infinite sequences of 0's and 1's):  $$ \mu\left(E\right) = \lambda \left(g\left(E\right) \right) \tag{1}$$ where $g:2^\infty \to \left[0,1\right]$ is the function with the rule $(x_i)_{i=1}^\infty \mapsto \sum_{i=1}^\infty x_i/2^i$ and $\lambda$ is the Lebesgue measure. This rule suggests that a set must be called measurable in $2^\infty$ iff its image under $g$ its Lebesgue-measurable in $[0,1]$. This function is continuous and surjective but not injective (e.g., $(01000...)$ and $(00111..)$ have the same image). This was taken from J. Oxtoby's ""Measure and Category"" [2nd ed. p. 84]. One thing that is not proven in the book is that this actually defines a $\sigma$-algebra in the space $2^\infty$. One condition is very easy to check, for instance, if the sets $(E_i)_{i=1}^\infty$ are such that $g(E_i)$ is measurable for every $i$ then $\bigcup_i E_i$ is measurable since $g(\bigcup_i E_i)= \bigcup_i g(E_i)$. I am having some trouble proving that if $E\subseteq 2^\infty$ is such that $g(E)$ is measurable, then $g(2^\infty\setminus E)$ is measurable. I think this condition is necessary for (1) to define a $\sigma$-algebra and a measure in $2^\infty$. Am I missing some elementary set-theoretic fact here that makes this evident?",,"['measure-theory', 'elementary-set-theory', 'descriptive-set-theory']"
18,Countability and sequences,Countability and sequences,,"I am having some trouble understanding my textbook in this passage: ""In particular, we see that if a set is countably infinite, then it is the range of an infinite sequence (but not conversely) "". It then proceeds to prove the proposition: ""A non-empty set is countable if and only if it is the range of an infinite sequence"". This seems to me like a contradiction. Can anyone supply me with an example of a set that is the range of an infinite sequence, but is not countable? If so, how does this not contradict the proposition posed? My thought is that it depends on the index of your sequence. If the sequence is indexed by naturals numbers (and hence countable), then the proposition holds. If the sequence is indexed by an uncountable set, then it may not hold. Is this reasoning correct?","I am having some trouble understanding my textbook in this passage: ""In particular, we see that if a set is countably infinite, then it is the range of an infinite sequence (but not conversely) "". It then proceeds to prove the proposition: ""A non-empty set is countable if and only if it is the range of an infinite sequence"". This seems to me like a contradiction. Can anyone supply me with an example of a set that is the range of an infinite sequence, but is not countable? If so, how does this not contradict the proposition posed? My thought is that it depends on the index of your sequence. If the sequence is indexed by naturals numbers (and hence countable), then the proposition holds. If the sequence is indexed by an uncountable set, then it may not hold. Is this reasoning correct?",,['elementary-set-theory']
19,I am having problems understanding this mark:,I am having problems understanding this mark:,,"I have this set defined as follows: $$A_n=\{(i,j)\in Z^2: (i,j)=1, 0\le i,j \le n\} $$  What does  (i,j)=1 means? Thanks in advance Now that we know it means gcd(i,j)=1, How can I calculate the size of this set?","I have this set defined as follows: $$A_n=\{(i,j)\in Z^2: (i,j)=1, 0\le i,j \le n\} $$  What does  (i,j)=1 means? Thanks in advance Now that we know it means gcd(i,j)=1, How can I calculate the size of this set?",,['elementary-set-theory']
20,"Exam Proof Read: $\forall x,~\exists y\ni\forall z,~[(z>y)\implies (z>x+y)]$",Exam Proof Read:,"\forall x,~\exists y\ni\forall z,~[(z>y)\implies (z>x+y)]","I just got my exam back, and the question went like this: Determine the truth value of the following statement, assuming that $x$, $y$, and $z$ are real numbers. Justify your answer.   $$\forall x,~\exists y\ni\forall z,~[(z>y)\implies (z>x+y)]$$ So I said, ""True. Let $y=(z-x+1)$."" I meant ""False."" I got $\varnothing$ points. :-(","I just got my exam back, and the question went like this: Determine the truth value of the following statement, assuming that $x$, $y$, and $z$ are real numbers. Justify your answer.   $$\forall x,~\exists y\ni\forall z,~[(z>y)\implies (z>x+y)]$$ So I said, ""True. Let $y=(z-x+1)$."" I meant ""False."" I got $\varnothing$ points. :-(",,"['elementary-set-theory', 'inequality']"
21,Equational theories in commutative idempotent monoids,Equational theories in commutative idempotent monoids,,"It might well be that my question is trivial but I'm not a mathematician, I just need a formalization for algebraic semiotics. If I have a commutative idempotent monoid, I can define a partial ordering $\preccurlyeq$ as follows: $$a \preccurlyeq b \equiv_{df} a \cdot b = b$$ Now let $E$ be a set of equational axioms (identities) $\{a_1\approx b_1,\dots,a_n\approx b_n\}$ (over elements $a_i,b_i$ of the monoid). I define $\doteq_E$ as the least relation such that $a\approx b\in E$ implies $a\doteq_E b$, the relation $\doteq_E$ is reflexive, symmetric and transitive, $a\doteq_E b$ implies $a\cdot c \doteq_E b\cdot c$ for all $a,b,c$. Is this relation a congruence ?","It might well be that my question is trivial but I'm not a mathematician, I just need a formalization for algebraic semiotics. If I have a commutative idempotent monoid, I can define a partial ordering $\preccurlyeq$ as follows: $$a \preccurlyeq b \equiv_{df} a \cdot b = b$$ Now let $E$ be a set of equational axioms (identities) $\{a_1\approx b_1,\dots,a_n\approx b_n\}$ (over elements $a_i,b_i$ of the monoid). I define $\doteq_E$ as the least relation such that $a\approx b\in E$ implies $a\doteq_E b$, the relation $\doteq_E$ is reflexive, symmetric and transitive, $a\doteq_E b$ implies $a\cdot c \doteq_E b\cdot c$ for all $a,b,c$. Is this relation a congruence ?",,"['elementary-set-theory', 'semigroups', 'monoid']"
22,About unions of $\sigma$-algebra being sigma algebras,About unions of -algebra being sigma algebras,\sigma,"Let $\Omega$ be a set and $\mathcal{A}$ and $\mathcal{B}$ be two sigma-algebras on $\Omega$. Put $$\mathcal{F}=\{A\cap B:A\in\mathcal{A}\;\text{and}\;B\in\mathcal{B}\}.$$ I have two question which seem intuitively true, but I am unable to prove them, since I am not a mathematician, but an engineer with an interest in probability theory: Is it true that the sigma-algebra generated by $\mathcal{F}$ equals the sigma-algebra generated by $\mathcal{A\cup B}$, i.e. do we have $$\sigma(\mathcal{F})=\sigma(\mathcal{A}\cup\mathcal{B})?$$ Does $\mathcal{F}$ satisfy the property $$F,G\in\mathcal{F}\implies F\cap G\in\mathcal{F}?$$","Let $\Omega$ be a set and $\mathcal{A}$ and $\mathcal{B}$ be two sigma-algebras on $\Omega$. Put $$\mathcal{F}=\{A\cap B:A\in\mathcal{A}\;\text{and}\;B\in\mathcal{B}\}.$$ I have two question which seem intuitively true, but I am unable to prove them, since I am not a mathematician, but an engineer with an interest in probability theory: Is it true that the sigma-algebra generated by $\mathcal{F}$ equals the sigma-algebra generated by $\mathcal{A\cup B}$, i.e. do we have $$\sigma(\mathcal{F})=\sigma(\mathcal{A}\cup\mathcal{B})?$$ Does $\mathcal{F}$ satisfy the property $$F,G\in\mathcal{F}\implies F\cap G\in\mathcal{F}?$$",,"['probability-theory', 'measure-theory', 'elementary-set-theory']"
23,Some questions about the Jech's book (Generalized De Morgan's law and distributive law ),Some questions about the Jech's book (Generalized De Morgan's law and distributive law ),,"I finished the first chapter of the book Introduction to Set Theory by Jech (I started to love). And I have questions of some exercises where I'm not totally sure if my attempt  was complete or even correct. The two last are where I have more doubts. Here we go: (A) Generalized distributive law : Let $S \not= \emptyset$ and $A$ be a set.  Set, $\;T_{\,1}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A\cap x \,)\,   \right\}$ and prove that: $\, A\cap \bigcup S =\bigcup T_{\,1}.$ Proof: ($\,\Rightarrow\,$) If $\,z \in A\cap \bigcup S$, $z\in A$ and  $\,z\in \bigcup S$. For $\,z\in \bigcup S,\,$ that means $z \in x_{0}$ for some $\, x_{0}\in S.\, $ Then, $\,z\in A$ and $z \in x_{0}$, i.e.,  $\,z\in A\cap x_0\,$   (where $\,x_0 \in S\,$). On the other hand, for $z$ be in the union of $T_{\,1}$, $\,z\in \bigcup T_{\,1}$, it is a sufficient condition that $z\in y_{0}$ for some $\,y_0 \in T_{\,1}.\,$ We define $y_{0} = A \cap x_{0}$. It follows immediately that $y_{0} \in T_{\,1}$ $($as $\,y_{0} \in \wp(A)$ and $\,x_0 \in S\,)$. So as $\,z\in A\cap x_0\,$ and we defined $\,y_{0} = A \cap x_{0}$, then $\,z\in y_{0}$ for some $\,y_0 \in T_{\,1}$, as desired. That is, $\, A\cap \bigcup S \subseteq \, \bigcup T_{\,1}$. ($\,\Leftarrow\,$) If  $z\in \bigcup T_{\,1},\, z\in y_{0}$ for some $y_{0} \in T_{\,1}.\,$ Then, by the definition of $T_{\,1},\,\,y_{0} = A\cap x_{0}\, $ for some $x_{0} \in S.\;$ It follows that, if $z\in y_{0}$, then $z\in x_{0}$ ( this is because $\,y_{0} \subseteq x_{0}\,).\,$  And as there a $x_{0} \in S\,$ for which $\,z\in x_{0},$ by the union axiom we can conclude that $\,z\in \bigcup S$. Hence, $z \in A$ and $\,z\in \bigcup S$, $\,z \in A\cap \bigcup S.\,$ That is, $\bigcup T_{\,1} \subseteq\, A\cap \bigcup S. $  $\;\Box$ (B) Generalized De Morgan's laws : Set,  $\;T_{\,2}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A - x \,)\,   \right\}\,$ and prove  that: ($\,i\,$) $A - \bigcup S = \bigcap T_{2}\,$ and  ($\,ii\,$) $\,A - \bigcap S = \bigcup T_{2}.$ Proof: ($\,i\,$) ($\,\Rightarrow\,$) If $z \in A - \bigcup S,\, z\in A\, $ and $ z\notin \bigcup S$ ( which means that,  for each $x \in S,\, z \notin x$ ). For $z$ be a member of the right-hand side, $z \in \bigcap T_{2},\, $ it is necessary that: for every $y\in T_{2}\,$ ( which assume is nonempty ) $z \in y: = A-x.\,$ Then, $z \in A$ and $z \notin x$  as in our assumption has that properties, it follows that $z \in \bigcap T_{2},\, $ i.e., $  A - \bigcup S \subseteq \bigcap T_{2}. $ ($\,\Leftarrow\,$) If  $z \in \bigcap T_{2},\, $ where assume that $T_{2}$ is nonempty. So, for each $y\in T_{2},\,z \in y: = A-x\,$. Therefore, $z \in A$ and $z\notin x\,$ and by definition of the set $ T_{2},\, x\in S $; which  holds for each $y \in T_{2}. $ For all $y, \,$ we have that $x\in S\,$ and $ z \notin x,\, $  $ z\notin \bigcup S\,$* ?? * (* ** How do we know that $S$ cannot have some element out of the elements   that we use by the definition of the set $T_{2}$ which could be in? I   don't know maybe I misunderstood this part *) Hence, $z\in A$ and $ z\notin \bigcup S,\,$ $z \in A - \bigcup S\, $, i.e, $\bigcap T_{2} \subseteq  A- \bigcup S.$ $(\, ii \,)$ $(\, \Rightarrow \,)$ If $z\in A - \bigcap S,\, z\in A\,$ and $z \notin \bigcap S.\,$ For  $z \notin \bigcap S\,$, means that there exist some $x\in S$ for which $z\notin x.$  Then, $z\in A- x_{0}\,$ for some $x_{0} \in S.\,$ We set, $\,y_{0}:= A- x_{0}.\,$ So, $\,y_{0} \in T_{2}\,$ because $\,y_{0} \in \wp(A)$ and $\, x_{0}\in S.\,$ As $\, y_{0} \in T_{2}\,$ and $\, z\in y_0,\,$ it follows that $z \in \bigcup T_{2},\,$ i.e., $A-\bigcap S \subseteq \,\bigcup T_{2}.\, $ ($\,\Leftarrow\,$) if $\,z \in \bigcup T_{2}\,$, then there exist a $\,y_{0} \in T_{2}\,$ for which $\,z\in y_{0}: = A-x_{0}\,$ ( for some $\,x_{0} \in S\,).\,$ Then $z \in A\,$ and for some $\,x_{0} \in S,\, z\notin x_{0}.\,$ Therefore, $z \in A\,$ and $\,z\notin \bigcap S,\, $ $z\in A - \bigcap S,\, $ i.e., $\, \,\bigcup T_{2} \subseteq\, A-\bigcap S .\, $ Claim 1 : The set $T_{2}$ is non empty We'll show that the set $T_{2}$ is empty iff the set $S$ is empty. Proof: Suppose $S = \emptyset$, we need to show that $T_{2}$ is empty. Assume for the sake of the contradiction that $y$ is in $T_{2},$  $\,y\in T_{2} \leftrightarrow y = A-x$ for some $x\in S,\,$ but since $x\notin S:=\emptyset$ we have a contradiction, it follows that $y$ cannot be in $T_{2},\,$ i.e., $y \notin  T_{2}.\,$ Therefore $T_{2} = \emptyset,\,$ as desired. On the other hand, if we assume that $\,T_{2} = \emptyset,\,$ we need to seek if this assumption implies the emptiness of $S.\,$  By contradiction, suppose $S \not= \emptyset,\,$ then $x\in S,\,$ and the set $A-x \in T_{2},\,$ which is a contradiction, because is empty by hypothesis. Therefore, $S = \emptyset.\,$ Then, if we assume that $S \not= \emptyset$ it follows that $T_{2} \not= \emptyset,\,$ as desired.  $\;\Box$ ** I have problems to understand what's going on in that parts where I put the question mark in boldface.... I don't know maybe I'm tired. I need a coffee. As usual, thanks in advance :)","I finished the first chapter of the book Introduction to Set Theory by Jech (I started to love). And I have questions of some exercises where I'm not totally sure if my attempt  was complete or even correct. The two last are where I have more doubts. Here we go: (A) Generalized distributive law : Let $S \not= \emptyset$ and $A$ be a set.  Set, $\;T_{\,1}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A\cap x \,)\,   \right\}$ and prove that: $\, A\cap \bigcup S =\bigcup T_{\,1}.$ Proof: ($\,\Rightarrow\,$) If $\,z \in A\cap \bigcup S$, $z\in A$ and  $\,z\in \bigcup S$. For $\,z\in \bigcup S,\,$ that means $z \in x_{0}$ for some $\, x_{0}\in S.\, $ Then, $\,z\in A$ and $z \in x_{0}$, i.e.,  $\,z\in A\cap x_0\,$   (where $\,x_0 \in S\,$). On the other hand, for $z$ be in the union of $T_{\,1}$, $\,z\in \bigcup T_{\,1}$, it is a sufficient condition that $z\in y_{0}$ for some $\,y_0 \in T_{\,1}.\,$ We define $y_{0} = A \cap x_{0}$. It follows immediately that $y_{0} \in T_{\,1}$ $($as $\,y_{0} \in \wp(A)$ and $\,x_0 \in S\,)$. So as $\,z\in A\cap x_0\,$ and we defined $\,y_{0} = A \cap x_{0}$, then $\,z\in y_{0}$ for some $\,y_0 \in T_{\,1}$, as desired. That is, $\, A\cap \bigcup S \subseteq \, \bigcup T_{\,1}$. ($\,\Leftarrow\,$) If  $z\in \bigcup T_{\,1},\, z\in y_{0}$ for some $y_{0} \in T_{\,1}.\,$ Then, by the definition of $T_{\,1},\,\,y_{0} = A\cap x_{0}\, $ for some $x_{0} \in S.\;$ It follows that, if $z\in y_{0}$, then $z\in x_{0}$ ( this is because $\,y_{0} \subseteq x_{0}\,).\,$  And as there a $x_{0} \in S\,$ for which $\,z\in x_{0},$ by the union axiom we can conclude that $\,z\in \bigcup S$. Hence, $z \in A$ and $\,z\in \bigcup S$, $\,z \in A\cap \bigcup S.\,$ That is, $\bigcup T_{\,1} \subseteq\, A\cap \bigcup S. $  $\;\Box$ (B) Generalized De Morgan's laws : Set,  $\;T_{\,2}:= \left\{\,y\in \wp (A): \exists x\in S\, (\, y = A - x \,)\,   \right\}\,$ and prove  that: ($\,i\,$) $A - \bigcup S = \bigcap T_{2}\,$ and  ($\,ii\,$) $\,A - \bigcap S = \bigcup T_{2}.$ Proof: ($\,i\,$) ($\,\Rightarrow\,$) If $z \in A - \bigcup S,\, z\in A\, $ and $ z\notin \bigcup S$ ( which means that,  for each $x \in S,\, z \notin x$ ). For $z$ be a member of the right-hand side, $z \in \bigcap T_{2},\, $ it is necessary that: for every $y\in T_{2}\,$ ( which assume is nonempty ) $z \in y: = A-x.\,$ Then, $z \in A$ and $z \notin x$  as in our assumption has that properties, it follows that $z \in \bigcap T_{2},\, $ i.e., $  A - \bigcup S \subseteq \bigcap T_{2}. $ ($\,\Leftarrow\,$) If  $z \in \bigcap T_{2},\, $ where assume that $T_{2}$ is nonempty. So, for each $y\in T_{2},\,z \in y: = A-x\,$. Therefore, $z \in A$ and $z\notin x\,$ and by definition of the set $ T_{2},\, x\in S $; which  holds for each $y \in T_{2}. $ For all $y, \,$ we have that $x\in S\,$ and $ z \notin x,\, $  $ z\notin \bigcup S\,$* ?? * (* ** How do we know that $S$ cannot have some element out of the elements   that we use by the definition of the set $T_{2}$ which could be in? I   don't know maybe I misunderstood this part *) Hence, $z\in A$ and $ z\notin \bigcup S,\,$ $z \in A - \bigcup S\, $, i.e, $\bigcap T_{2} \subseteq  A- \bigcup S.$ $(\, ii \,)$ $(\, \Rightarrow \,)$ If $z\in A - \bigcap S,\, z\in A\,$ and $z \notin \bigcap S.\,$ For  $z \notin \bigcap S\,$, means that there exist some $x\in S$ for which $z\notin x.$  Then, $z\in A- x_{0}\,$ for some $x_{0} \in S.\,$ We set, $\,y_{0}:= A- x_{0}.\,$ So, $\,y_{0} \in T_{2}\,$ because $\,y_{0} \in \wp(A)$ and $\, x_{0}\in S.\,$ As $\, y_{0} \in T_{2}\,$ and $\, z\in y_0,\,$ it follows that $z \in \bigcup T_{2},\,$ i.e., $A-\bigcap S \subseteq \,\bigcup T_{2}.\, $ ($\,\Leftarrow\,$) if $\,z \in \bigcup T_{2}\,$, then there exist a $\,y_{0} \in T_{2}\,$ for which $\,z\in y_{0}: = A-x_{0}\,$ ( for some $\,x_{0} \in S\,).\,$ Then $z \in A\,$ and for some $\,x_{0} \in S,\, z\notin x_{0}.\,$ Therefore, $z \in A\,$ and $\,z\notin \bigcap S,\, $ $z\in A - \bigcap S,\, $ i.e., $\, \,\bigcup T_{2} \subseteq\, A-\bigcap S .\, $ Claim 1 : The set $T_{2}$ is non empty We'll show that the set $T_{2}$ is empty iff the set $S$ is empty. Proof: Suppose $S = \emptyset$, we need to show that $T_{2}$ is empty. Assume for the sake of the contradiction that $y$ is in $T_{2},$  $\,y\in T_{2} \leftrightarrow y = A-x$ for some $x\in S,\,$ but since $x\notin S:=\emptyset$ we have a contradiction, it follows that $y$ cannot be in $T_{2},\,$ i.e., $y \notin  T_{2}.\,$ Therefore $T_{2} = \emptyset,\,$ as desired. On the other hand, if we assume that $\,T_{2} = \emptyset,\,$ we need to seek if this assumption implies the emptiness of $S.\,$  By contradiction, suppose $S \not= \emptyset,\,$ then $x\in S,\,$ and the set $A-x \in T_{2},\,$ which is a contradiction, because is empty by hypothesis. Therefore, $S = \emptyset.\,$ Then, if we assume that $S \not= \emptyset$ it follows that $T_{2} \not= \emptyset,\,$ as desired.  $\;\Box$ ** I have problems to understand what's going on in that parts where I put the question mark in boldface.... I don't know maybe I'm tired. I need a coffee. As usual, thanks in advance :)",,['elementary-set-theory']
24,Sets and first order logic question,Sets and first order logic question,,"this question has me stumped. Any help would be greatly appreciated. It goes like this: For the domain of all sets, give a first-order logic formula saying -   There exists no set such that all other sets are its element. So far I have this: Let $x$ and $y$ be all sets. $\lnot\exists x\,\forall\,y\,(y\in x \impliedby x\ne y)$ Note, the reason I've put $x$ does not equal $y$ is because the question says ""all OTHER"" sets, so I interpreted that as, it does not include itself, so it's not a member of itself but again I'm not sure.","this question has me stumped. Any help would be greatly appreciated. It goes like this: For the domain of all sets, give a first-order logic formula saying -   There exists no set such that all other sets are its element. So far I have this: Let $x$ and $y$ be all sets. $\lnot\exists x\,\forall\,y\,(y\in x \impliedby x\ne y)$ Note, the reason I've put $x$ does not equal $y$ is because the question says ""all OTHER"" sets, so I interpreted that as, it does not include itself, so it's not a member of itself but again I'm not sure.",,"['elementary-set-theory', 'first-order-logic']"
25,Apparent equivalent notations for the axiom of infinity,Apparent equivalent notations for the axiom of infinity,,"I'm just begining to build the systems of numbers based on the axioms of set theory ($\mathsf{ZF}$). Accordingly the axiom of infinity is no more than assuming the existence of $\mathbb{N}$ (of course the axiom is formulated in terms of the existence of an inductive set). Now the original statement in terms of logic is $\exists I(\emptyset \in I\wedge(\forall x(x\in I \longrightarrow x^{+}\in I)))$, understanding $x^{+}:=x\cup\{x\}$. This is the way I learnt it first.  After some days I have learnt it I just worried about  understanding the concept. But now that I try to use it again I just came up (I don't know why, maybe it's because of the similarity to the notation of the other axioms in my attempt to remember the original notation) with this apparently equivalent statements: $1) \exists I\forall x(x\in I\longrightarrow (x=\emptyset \vee  x^{+}\in I))$ $2) \exists I\forall x(x\in I\longrightarrow (\emptyset \in I\wedge x^{+}\in I))$ If I put the original statement in the equivalent form $\exists I\forall x(\emptyset \in I\wedge(x\in I \longrightarrow x^{+}\in I))$ Then to prove the equivalence I probably should deal with the main part that is bound with the quantifiers. So I want to ask how to prove that my statements are equivalent or not, logically speaking. Note : Intuitively both statements are false because I could form I=$\emptyset$ and this is not and inductive set.","I'm just begining to build the systems of numbers based on the axioms of set theory ($\mathsf{ZF}$). Accordingly the axiom of infinity is no more than assuming the existence of $\mathbb{N}$ (of course the axiom is formulated in terms of the existence of an inductive set). Now the original statement in terms of logic is $\exists I(\emptyset \in I\wedge(\forall x(x\in I \longrightarrow x^{+}\in I)))$, understanding $x^{+}:=x\cup\{x\}$. This is the way I learnt it first.  After some days I have learnt it I just worried about  understanding the concept. But now that I try to use it again I just came up (I don't know why, maybe it's because of the similarity to the notation of the other axioms in my attempt to remember the original notation) with this apparently equivalent statements: $1) \exists I\forall x(x\in I\longrightarrow (x=\emptyset \vee  x^{+}\in I))$ $2) \exists I\forall x(x\in I\longrightarrow (\emptyset \in I\wedge x^{+}\in I))$ If I put the original statement in the equivalent form $\exists I\forall x(\emptyset \in I\wedge(x\in I \longrightarrow x^{+}\in I))$ Then to prove the equivalence I probably should deal with the main part that is bound with the quantifiers. So I want to ask how to prove that my statements are equivalent or not, logically speaking. Note : Intuitively both statements are false because I could form I=$\emptyset$ and this is not and inductive set.",,"['elementary-set-theory', 'logic', 'axioms']"
26,Number of days it took to climb the mountain (BdMO 2012 National Primary/Junior question),Number of days it took to climb the mountain (BdMO 2012 National Primary/Junior question),,"From the Bangladesh Mathematical Olympiad 2012 National Secondary (Question 7, or ৭). When Tanvir climbed the Tajingdong mountain, on his way to the top he saw it was raining $11$ times. At Tajindong, on a rainy day, it rains either in the morning or in the afternoon; but it never rains twice in the    same day. On his way, Tanvir spent $16$ mornings and $13$ afternoons without rain. How many days did it    take for Tanvir to climb the Tajindong mountain in total? I tried to solve it using sets but it has not worked out too well. I asked people who did it but most of them gave different answers ,often having a difference of $1$ or $2$. Any help will be appreciated.","From the Bangladesh Mathematical Olympiad 2012 National Secondary (Question 7, or ৭). When Tanvir climbed the Tajingdong mountain, on his way to the top he saw it was raining $11$ times. At Tajindong, on a rainy day, it rains either in the morning or in the afternoon; but it never rains twice in the    same day. On his way, Tanvir spent $16$ mornings and $13$ afternoons without rain. How many days did it    take for Tanvir to climb the Tajindong mountain in total? I tried to solve it using sets but it has not worked out too well. I asked people who did it but most of them gave different answers ,often having a difference of $1$ or $2$. Any help will be appreciated.",,"['elementary-set-theory', 'recreational-mathematics']"
27,Is there a preference between proving a total order (strict vs partial)?,Is there a preference between proving a total order (strict vs partial)?,,"I know that proving a relation $\mathcal{R}$ to be a strict total order (asymmetric, transitive,and  total ) implies that the relation $S$ defined as $X\mathcal{S} Y \longleftrightarrow (X\mathcal{R}Y\vee X=Y)$ is a total order (antisymmetric, transitive, reflexive, and complete). Conversely, if  a relation $\mathcal{R}$ is a total order then the relation $S$ defined as $X\mathcal{S} Y \longleftrightarrow (X\mathcal{R}Y\wedge  X\neq Y)$ is a strict total order. My perception is that people use to prove a relation to be a total order over proving that a relation is a strict total order. If proving a relation to be a total order automatically implies the other to hold why people don't do it by considering strict total orders? For example in the definition of $\mathbb{N}$ I think it should be the same (even easier) if we prove that it's a totally strict ordered set and then automatically it's a totally order set, but books prefer the other way around. They prove that it's a totally ordered set and then the other option follows automatically. What am I missing? is it just matter of custom, style, or something?","I know that proving a relation $\mathcal{R}$ to be a strict total order (asymmetric, transitive,and  total ) implies that the relation $S$ defined as $X\mathcal{S} Y \longleftrightarrow (X\mathcal{R}Y\vee X=Y)$ is a total order (antisymmetric, transitive, reflexive, and complete). Conversely, if  a relation $\mathcal{R}$ is a total order then the relation $S$ defined as $X\mathcal{S} Y \longleftrightarrow (X\mathcal{R}Y\wedge  X\neq Y)$ is a strict total order. My perception is that people use to prove a relation to be a total order over proving that a relation is a strict total order. If proving a relation to be a total order automatically implies the other to hold why people don't do it by considering strict total orders? For example in the definition of $\mathbb{N}$ I think it should be the same (even easier) if we prove that it's a totally strict ordered set and then automatically it's a totally order set, but books prefer the other way around. They prove that it's a totally ordered set and then the other option follows automatically. What am I missing? is it just matter of custom, style, or something?",,"['abstract-algebra', 'elementary-set-theory']"
28,standard definitions when talking about ordered sets,standard definitions when talking about ordered sets,,"What is the standardization if any when it comes to ordered sets?. Specifically I'm always confused in the following cases: 1) When someone say ""a partial ordered set"" :  to me it can mean a strict partial ordered set (The relation is asymmetric and transitive) or a non strict partial ordered set (the relation is antisymmetric, reflexive and transitive), but many books refer to partial ordered sets like they were non strict and excluding the other case, why?. 2) When someone say ""a total ordering"" : to me it can mean a strict total ordered set or it can mean a non strict total ordered set, but many books refer to total orders like they were non strict and excluding the other case. 3) When someone say ""an ordered set"" : to me it can mean any ordered set, partial, complete, strict, or non strict, but many books don't make this distintion and they refer to a ""non strict partial orderd"". Am I missing something? Is it just me the one making these distintions?, please help me clarify this.","What is the standardization if any when it comes to ordered sets?. Specifically I'm always confused in the following cases: 1) When someone say ""a partial ordered set"" :  to me it can mean a strict partial ordered set (The relation is asymmetric and transitive) or a non strict partial ordered set (the relation is antisymmetric, reflexive and transitive), but many books refer to partial ordered sets like they were non strict and excluding the other case, why?. 2) When someone say ""a total ordering"" : to me it can mean a strict total ordered set or it can mean a non strict total ordered set, but many books refer to total orders like they were non strict and excluding the other case. 3) When someone say ""an ordered set"" : to me it can mean any ordered set, partial, complete, strict, or non strict, but many books don't make this distintion and they refer to a ""non strict partial orderd"". Am I missing something? Is it just me the one making these distintions?, please help me clarify this.",,['elementary-set-theory']
29,A picky question on set theory,A picky question on set theory,,"I just came to this math statement: Let A,B,C be sets. Then: (AxB)xC = Ax(BxC) My question is, why is it so? I mean, (AxB)xC = { ((a1,b1),c1), ((a1,b2),c3), ... } and Ax(BxC) = { (a1,(b1,c1)), (a2,(b3,c2)), ... } Is there any ""hidden"" assumptions on this?","I just came to this math statement: Let A,B,C be sets. Then: (AxB)xC = Ax(BxC) My question is, why is it so? I mean, (AxB)xC = { ((a1,b1),c1), ((a1,b2),c3), ... } and Ax(BxC) = { (a1,(b1,c1)), (a2,(b3,c2)), ... } Is there any ""hidden"" assumptions on this?",,['elementary-set-theory']
30,Preordering on a set,Preordering on a set,,I am given a definition which states that a 'preodering on a set is a relation that is reflexive and transitive.' Show that a relation $\leq$ defined on $\mathbb{C}$ by $z_1 \leq z_2$ iff $|z_1| = |z_2|$ is a preodering on $\mathbb{C}$. I must be missing something here because clearly for any $z \in \mathbb{C}$ we have $|z| = |z|$ and if $z_1 \leq z_2$ and $z_2 \leq z_3$ then that implies that $|z_1| = |z_2| = |z_3|$ which means that $z_1 \leq z_3$.  I must be reading the question wrong surely.  What am I missing?,I am given a definition which states that a 'preodering on a set is a relation that is reflexive and transitive.' Show that a relation $\leq$ defined on $\mathbb{C}$ by $z_1 \leq z_2$ iff $|z_1| = |z_2|$ is a preodering on $\mathbb{C}$. I must be missing something here because clearly for any $z \in \mathbb{C}$ we have $|z| = |z|$ and if $z_1 \leq z_2$ and $z_2 \leq z_3$ then that implies that $|z_1| = |z_2| = |z_3|$ which means that $z_1 \leq z_3$.  I must be reading the question wrong surely.  What am I missing?,,"['elementary-set-theory', 'relations']"
31,Equivalence Relations and functions on partitions of Sets,Equivalence Relations and functions on partitions of Sets,,"let $f$ be a function on $A$ onto $B$.  Define an equivalence relation $E$ in $A$ by: $aEb$ if and only if $f(a)=f(b)$. Define a function $\phi$ on $A/E$ by $\phi([a]_{E})=f(a)$. Hint: Verify that $\phi([a]_{E})=\phi([a']_{E}) $ if $[a]_{E} = [a']_{E}$ I know that A/E is a partition of A. I know that a binary relation $F$ is called a function if $aFb$ and $aFc$ implies $b=c$ for any $a, b, \text {  and  } c$","let $f$ be a function on $A$ onto $B$.  Define an equivalence relation $E$ in $A$ by: $aEb$ if and only if $f(a)=f(b)$. Define a function $\phi$ on $A/E$ by $\phi([a]_{E})=f(a)$. Hint: Verify that $\phi([a]_{E})=\phi([a']_{E}) $ if $[a]_{E} = [a']_{E}$ I know that A/E is a partition of A. I know that a binary relation $F$ is called a function if $aFb$ and $aFc$ implies $b=c$ for any $a, b, \text {  and  } c$",,"['elementary-set-theory', 'equivalence-relations']"
32,cardinality of the union of 2 sets with at least two elements and cardinality of cartesian product,cardinality of the union of 2 sets with at least two elements and cardinality of cartesian product,,"Suppose X,Y are sets with at least 2 elements. Show that  $X\cup Y\le X\times Y$ So my first thought was that cardinality $|X|\ge 2$ and the same for $|Y|\ge 2$ but by the inclusion-exclusion principle we have $|X\cup Y|=|X|+|Y|-|X\cap Y|$ but the problem does not say if they are disjoint or not. If we assume that they are disjoint then $|X\cup Y|\ge 4$ right? But from the definition of the cardinality for the cartesian product we have similar $|X\times Y|\ge 4$. But I have to find an injective function (including the number of elements) s.t $f:X\cup Y\to X\times Y$ and thus conclude the result.  How should I do it?","Suppose X,Y are sets with at least 2 elements. Show that  $X\cup Y\le X\times Y$ So my first thought was that cardinality $|X|\ge 2$ and the same for $|Y|\ge 2$ but by the inclusion-exclusion principle we have $|X\cup Y|=|X|+|Y|-|X\cap Y|$ but the problem does not say if they are disjoint or not. If we assume that they are disjoint then $|X\cup Y|\ge 4$ right? But from the definition of the cardinality for the cartesian product we have similar $|X\times Y|\ge 4$. But I have to find an injective function (including the number of elements) s.t $f:X\cup Y\to X\times Y$ and thus conclude the result.  How should I do it?",,['elementary-set-theory']
33,show that $P$ is partially ordered set by $\subseteq$,show that  is partially ordered set by,P \subseteq,"Let $Y$ be a set and suppose$P \subseteq \mathcal{P}(Y)$. Show that $P$ is partially ordered set by $\subseteq$. So I start off with $\mathcal{P}(Y)=\{\emptyset\subseteq,......\subseteq P....\subseteq..\subseteq Y\}$ How should I use now the reflexivity, antisymmetry and transitivity? I don't think I understand the question. The inclusion is a partial ordering relation on the power set but how to show that one of it's members is partially ordered?","Let $Y$ be a set and suppose$P \subseteq \mathcal{P}(Y)$. Show that $P$ is partially ordered set by $\subseteq$. So I start off with $\mathcal{P}(Y)=\{\emptyset\subseteq,......\subseteq P....\subseteq..\subseteq Y\}$ How should I use now the reflexivity, antisymmetry and transitivity? I don't think I understand the question. The inclusion is a partial ordering relation on the power set but how to show that one of it's members is partially ordered?",,['elementary-set-theory']
34,Proving an equation in set theory: $L \setminus (M ∪ N) = (L \setminus M) ∩ (L \setminus N)$,Proving an equation in set theory:,L \setminus (M ∪ N) = (L \setminus M) ∩ (L \setminus N),"This may be simple, but it just won't work for me. Here's what I need to proof: L \ (M ∪ N) = (L \ M) ∩ (L \ N) And this is what I did: L \ (M ∪ N) = L \ ({x: x ∈ M ∨ x ∈ N}) = {x: x ∈ L ∧ (x ∉ M ∨ x ∉ N)} = {x: (x ∈ L ∧ x ∉ M) ∨ (x ∈ L ∧ x ∉ N )} = (L / M) ∪ (L / N) I'm pretty sure it should say (L \ M) ∩ (L \ N) but somehow I always end up with (L / M) ∪ (L / N) instead.","This may be simple, but it just won't work for me. Here's what I need to proof: L \ (M ∪ N) = (L \ M) ∩ (L \ N) And this is what I did: L \ (M ∪ N) = L \ ({x: x ∈ M ∨ x ∈ N}) = {x: x ∈ L ∧ (x ∉ M ∨ x ∉ N)} = {x: (x ∈ L ∧ x ∉ M) ∨ (x ∈ L ∧ x ∉ N )} = (L / M) ∪ (L / N) I'm pretty sure it should say (L \ M) ∩ (L \ N) but somehow I always end up with (L / M) ∪ (L / N) instead.",,['elementary-set-theory']
35,Relation and the complementary relation: reflexivity and irreflexivity,Relation and the complementary relation: reflexivity and irreflexivity,,"How do I show that the relation R on a set A is reflexive if and only if the complementary relation R is irreflexive. Because of iff: I start with let R be a relation from a set A to B. The complementary relation R is the set $\{(a,b):(a,b) \not\in R\}$ I think a relation R on the set A is irreflexive if for every a is an element of A, $(a,a)$ is in R. That is, R is irreflexive if no element in A is related to itself.","How do I show that the relation R on a set A is reflexive if and only if the complementary relation R is irreflexive. Because of iff: I start with let R be a relation from a set A to B. The complementary relation R is the set $\{(a,b):(a,b) \not\in R\}$ I think a relation R on the set A is irreflexive if for every a is an element of A, $(a,a)$ is in R. That is, R is irreflexive if no element in A is related to itself.",,"['elementary-set-theory', 'relations']"
36,find the number of equivalence classes of $\mathbb R$.,find the number of equivalence classes of .,\mathbb R,"Let $\mathscr X$ be the set of all nonempty sub sets of the set $\{1,2,3,...,10\}. $Define the relation $\mathscr R$ on $\mathscr X$ by: for all $A,B \in \mathscr X, A\mathscr RB$ if and only if the smallest element of $A$ is equal to the smallest element of $B$. (a) find the number of equivalence classes of $\mathbb R$. (b) find the number of elements in the equivalence class $[\{2,6,7\}]$. I am thinking this would be the number of subsets containing the element 2 of the set $\{1,3,4,...,10\}$ so it would be $2^9$? (c) find the number of four-element sets which are elements of the equivalence class $[\{2,6,7\}]$. Also this would be like choosing a 3-element subset from the set $\{1,3,4,...,10\}$ so ${9 \choose 3}$?","Let $\mathscr X$ be the set of all nonempty sub sets of the set $\{1,2,3,...,10\}. $Define the relation $\mathscr R$ on $\mathscr X$ by: for all $A,B \in \mathscr X, A\mathscr RB$ if and only if the smallest element of $A$ is equal to the smallest element of $B$. (a) find the number of equivalence classes of $\mathbb R$. (b) find the number of elements in the equivalence class $[\{2,6,7\}]$. I am thinking this would be the number of subsets containing the element 2 of the set $\{1,3,4,...,10\}$ so it would be $2^9$? (c) find the number of four-element sets which are elements of the equivalence class $[\{2,6,7\}]$. Also this would be like choosing a 3-element subset from the set $\{1,3,4,...,10\}$ so ${9 \choose 3}$?",,"['combinatorics', 'elementary-set-theory', 'equivalence-relations']"
37,Term for sets with a bijection between them,Term for sets with a bijection between them,,"If there exists an isomorphism between $G$ and $H$, we say that $G$ and $H$ are isomorphic. If there exists a bijection between $A$ and $B$, we say that $A$ and $B$ are _______. Is there a word that nicely fills in the blank?","If there exists an isomorphism between $G$ and $H$, we say that $G$ and $H$ are isomorphic. If there exists a bijection between $A$ and $B$, we say that $A$ and $B$ are _______. Is there a word that nicely fills in the blank?",,"['elementary-set-theory', 'terminology']"
38,A proof on infimum property,A proof on infimum property,,"Suppose that $A_1$ and $A_2$ are nonempty sets with $A_2 \subset A_1$ of real numbers that are bounded below. I want to show that $\inf A_1 \leq \inf A_2$ I managed to do the opposite, that is $\inf A_2 \leq \inf A_1$ and not sure what went wrong in my proof Let $x \in A_2$ , then because $A_2$ is bounded below there exists a number $y$ such that $y \leq x$ for all $x \in A_2$ $A_2$ is nonempty, so by the greatest lower bound property that there exists a number $y^*$ such that $y \leq y^* \leq x$ Now let $x \in A_2 \subset A_1$ , then since $A_1$ is bounded below we have $y \leq x$ for each $x \in A_1$ . By the greaest lower bound property, there exists a number $z^*$ such that $y \leq z^* \leq x$ , but recall $y^* \in A_1$ is an lower bound for some $x$ , so we must have $y^* \leq z^* \implies \inf A_2 \leq \inf A_1$ My motivation for proving this come from proving that if $P \subset Q$ , then $L(f,P) \leq L(f,Q)$","Suppose that and are nonempty sets with of real numbers that are bounded below. I want to show that I managed to do the opposite, that is and not sure what went wrong in my proof Let , then because is bounded below there exists a number such that for all is nonempty, so by the greatest lower bound property that there exists a number such that Now let , then since is bounded below we have for each . By the greaest lower bound property, there exists a number such that , but recall is an lower bound for some , so we must have My motivation for proving this come from proving that if , then","A_1 A_2 A_2 \subset A_1 \inf A_1 \leq \inf A_2 \inf A_2 \leq \inf A_1 x \in A_2 A_2 y y \leq x x \in A_2 A_2 y^* y \leq y^* \leq x x \in A_2 \subset A_1 A_1 y \leq x x \in A_1 z^* y \leq z^* \leq x y^* \in A_1 x y^* \leq z^* \implies \inf A_2 \leq \inf A_1 P \subset Q L(f,P) \leq L(f,Q)","['real-analysis', 'elementary-set-theory']"
39,Proving that the intersection of closed sets is closed,Proving that the intersection of closed sets is closed,,I am having major trouble on this homework and need help! Let $*$ be a binary operation on a set A.  Let B and C be subsets of A that are closed under $*$ . a) Prove that $B \cap C$ is closed under $*$ b) Give an example to show that $B \cup C$ need not in general be closed under $*$ Is this just some basic theorem of set intersections? I've been scanning my textbook and can't find a thing. Am I overthinking?,I am having major trouble on this homework and need help! Let be a binary operation on a set A.  Let B and C be subsets of A that are closed under . a) Prove that is closed under b) Give an example to show that need not in general be closed under Is this just some basic theorem of set intersections? I've been scanning my textbook and can't find a thing. Am I overthinking?,* * B \cap C * B \cup C *,"['elementary-set-theory', 'relations']"
40,Proof by contradiction: $ A \subseteq A $,Proof by contradiction:, A \subseteq A ,I have to proof by contradiction that $ A \subseteq A $; if  $ A \nsubseteq A $ then $ \exists x \in A ( x \notin A ) $ but $ \exists x \in A ( x \notin A ) $ is contradiction (in fact: $ \exists x  ( x \in A \wedge x \notin A ) $) therefore $ A \subseteq A $ is true... The process is correct? Thank you all in advance,I have to proof by contradiction that $ A \subseteq A $; if  $ A \nsubseteq A $ then $ \exists x \in A ( x \notin A ) $ but $ \exists x \in A ( x \notin A ) $ is contradiction (in fact: $ \exists x  ( x \in A \wedge x \notin A ) $) therefore $ A \subseteq A $ is true... The process is correct? Thank you all in advance,,['elementary-set-theory']
41,Is $\mathbb R^2$ equipotent to $\mathbb R$? [duplicate],Is  equipotent to ? [duplicate],\mathbb R^2 \mathbb R,This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Closed 11 years ago . I know that $\mathbb N^2$ is equipotent to $\mathbb N$ (By drawing zig-zag path to join all the points on xy-plane). Is this method available to prove $\mathbb R^2 $ equipotent to $\mathbb R$?,This question already has answers here : Examples of bijective map from $\mathbb{R}^3\rightarrow \mathbb{R}$ (2 answers) Closed 11 years ago . I know that $\mathbb N^2$ is equipotent to $\mathbb N$ (By drawing zig-zag path to join all the points on xy-plane). Is this method available to prove $\mathbb R^2 $ equipotent to $\mathbb R$?,,['elementary-set-theory']
42,Showing a model does not have a particular substructure and understanding satisfaction relations.,Showing a model does not have a particular substructure and understanding satisfaction relations.,,"Out of Winfried Just and Martin Weese's Set theory book: Show that the model $\mathfrak B=\langle \Bbb Z, +, \le, 0 \rangle$ does not have any substructure whose universe is $\{-1,0,1\}$. In a previous example he showed that there is such a substructure for $\mathfrak B$ with multiplication instead of addition. However, I do not see how changing the function breaks the identity embedding. My guess is that it has to do with {-1,0,1} not being closed under addition but I am unsure how to formalize this. Something like $i(1+1)\neq i(1)+i(1)$ since $1+1\notin \{-1,0,1\}$ where $i$ is the identity function is my attempt but this is clearly lacking. Also on a somewhat related note, I'm not quite sure I understand the following property of satisfaction relations under a valuation s $\mathfrak U \vDash_s \exists v_i\phi$ iff there exists a valuation $s^*$ such that $\mathfrak U \vDash_s^* \phi$ and $s(k)=s^*(k)$ for all $k\neq i$ How I understand this property is that a bounded variable's formula is true under the valuation $s$ as long as the formula can be satisfied under a valuation for all of the free variables of $\phi$ in $\mathfrak U$. Is this interpretation correct?","Out of Winfried Just and Martin Weese's Set theory book: Show that the model $\mathfrak B=\langle \Bbb Z, +, \le, 0 \rangle$ does not have any substructure whose universe is $\{-1,0,1\}$. In a previous example he showed that there is such a substructure for $\mathfrak B$ with multiplication instead of addition. However, I do not see how changing the function breaks the identity embedding. My guess is that it has to do with {-1,0,1} not being closed under addition but I am unsure how to formalize this. Something like $i(1+1)\neq i(1)+i(1)$ since $1+1\notin \{-1,0,1\}$ where $i$ is the identity function is my attempt but this is clearly lacking. Also on a somewhat related note, I'm not quite sure I understand the following property of satisfaction relations under a valuation s $\mathfrak U \vDash_s \exists v_i\phi$ iff there exists a valuation $s^*$ such that $\mathfrak U \vDash_s^* \phi$ and $s(k)=s^*(k)$ for all $k\neq i$ How I understand this property is that a bounded variable's formula is true under the valuation $s$ as long as the formula can be satisfied under a valuation for all of the free variables of $\phi$ in $\mathfrak U$. Is this interpretation correct?",,"['elementary-set-theory', 'model-theory']"
43,Cardinality of $\omega^2$ [duplicate],Cardinality of  [duplicate],\omega^2,"This question already has answers here : Cartesian Product of Two Countable Sets is Countable [closed] (3 answers) Closed 11 years ago . I know $ \omega ^ 2  $ is countable, but I'm unable to find a bijection from $ \omega * \omega  \rightarrow \omega $ This should be simple, but I'm very stuck.","This question already has answers here : Cartesian Product of Two Countable Sets is Countable [closed] (3 answers) Closed 11 years ago . I know $ \omega ^ 2  $ is countable, but I'm unable to find a bijection from $ \omega * \omega  \rightarrow \omega $ This should be simple, but I'm very stuck.",,['elementary-set-theory']
44,A question about isomorphism between orders,A question about isomorphism between orders,,"Is there an isomorphism between the naturals with the regular order $\le$ and the set $\mathbb{N}\times \mathbb{N}$ with the order $R$ defined to be $\langle k_1,r_1\rangle\mathrel R\langle k_2,r_2\rangle$ iff $2^{k_1} (2r_1+1)\le 2^{k_2} (2r_2+1)$? I may not be using the correct terms in English as I was unable to find out what they are. When I say isomorphism between relations I mean that there's a bijective function from say $A$ to $B$ such that if there's some relation order $L$ defined on $B$ and some relation order R defined on A, if $x\mathrel Ry$ then $f(x)\mathrel Lf(y)$. What are general guidelines to know if such a function exists? Thanks a million!","Is there an isomorphism between the naturals with the regular order $\le$ and the set $\mathbb{N}\times \mathbb{N}$ with the order $R$ defined to be $\langle k_1,r_1\rangle\mathrel R\langle k_2,r_2\rangle$ iff $2^{k_1} (2r_1+1)\le 2^{k_2} (2r_2+1)$? I may not be using the correct terms in English as I was unable to find out what they are. When I say isomorphism between relations I mean that there's a bijective function from say $A$ to $B$ such that if there's some relation order $L$ defined on $B$ and some relation order R defined on A, if $x\mathrel Ry$ then $f(x)\mathrel Lf(y)$. What are general guidelines to know if such a function exists? Thanks a million!",,['elementary-set-theory']
45,Question about relation on certain sets of integers,Question about relation on certain sets of integers,,"I'm new to discrete maths and I have a few questions. Let $C = \{x \in\mathbb{Z}: 0 < x < 10\}$ and let $D = \{ y \in\mathbb{Z}: 1 < y < 9\}$, and define a binary   relation $S$ from $C$ to $D$ as follows: For all $(x, y) \in C \times D$, $(x, y) \in S$ if and only if $y = 2x - 1$. How to list down the ordered pair of $S$ if it has a range? What about the domain and range of $S$? Is it a function? How do I check?","I'm new to discrete maths and I have a few questions. Let $C = \{x \in\mathbb{Z}: 0 < x < 10\}$ and let $D = \{ y \in\mathbb{Z}: 1 < y < 9\}$, and define a binary   relation $S$ from $C$ to $D$ as follows: For all $(x, y) \in C \times D$, $(x, y) \in S$ if and only if $y = 2x - 1$. How to list down the ordered pair of $S$ if it has a range? What about the domain and range of $S$? Is it a function? How do I check?",,"['elementary-set-theory', 'relations']"
46,Do there exist bijections between the following sets?,Do there exist bijections between the following sets?,,"Let $A$ be an infinite set. Do there exist bijections between the following sets? $A$ and $A\setminus B$ where $B$ is a finite subset $A$ and $A\times \{1, 2, \dots, n\}$ $A$ and $A\times A$","Let $A$ be an infinite set. Do there exist bijections between the following sets? $A$ and $A\setminus B$ where $B$ is a finite subset $A$ and $A\times \{1, 2, \dots, n\}$ $A$ and $A\times A$",,"['elementary-set-theory', 'cardinals']"
47,Set notation for infinite subsets.,Set notation for infinite subsets.,,"In set notation, how can one express an infinite set of subsets where each subset has exactly two elements $\{an-1, an+1\}$ where $a$ is a constant and $n\ge1$ and the $n$ value for each subset is one more than that of the previous subset. Example: $\{ \{a1-1, a1+1\},~\{a2-1, a2+1\},~\{a3-1, a3+1\},~. . . \}$","In set notation, how can one express an infinite set of subsets where each subset has exactly two elements $\{an-1, an+1\}$ where $a$ is a constant and $n\ge1$ and the $n$ value for each subset is one more than that of the previous subset. Example: $\{ \{a1-1, a1+1\},~\{a2-1, a2+1\},~\{a3-1, a3+1\},~. . . \}$",,"['elementary-set-theory', 'notation']"
48,A question on linear ordered space,A question on linear ordered space,,A space $X$ is called left-separated if it can be well-ordered in such a way that every initial segment is closed in $X$. And we know every space contains a dense left-separated subspace. My question is this: Is such left-separated space as a subspace linear ordered space? Thanks for any help and the references on the left-separated space are also welcome.,A space $X$ is called left-separated if it can be well-ordered in such a way that every initial segment is closed in $X$. And we know every space contains a dense left-separated subspace. My question is this: Is such left-separated space as a subspace linear ordered space? Thanks for any help and the references on the left-separated space are also welcome.,,"['general-topology', 'reference-request', 'elementary-set-theory', 'definition']"
49,Bijection between power set and power of the set.,Bijection between power set and power of the set.,,"This problem courtesy of Allen Clark's ""Elements of Abstract Algebra"". Let $N_k=\{1, 2, \ldots, k\}$. Construct a bijection, $\phi: 2^{N_k} \to N_{2^k}$, where $$2^{N_k}=\{S \mid S \subset N_k\}.$$ Can anyone come up with one?","This problem courtesy of Allen Clark's ""Elements of Abstract Algebra"". Let $N_k=\{1, 2, \ldots, k\}$. Construct a bijection, $\phi: 2^{N_k} \to N_{2^k}$, where $$2^{N_k}=\{S \mid S \subset N_k\}.$$ Can anyone come up with one?",,['elementary-set-theory']
50,"Proof of ""ordinal if and only if is Mostowski collapse""","Proof of ""ordinal if and only if is Mostowski collapse""",,"I tried to prove the following, can you tell me please if my proof is correct? Thank you. Claim: A set $\alpha$ is an ordinal iff $\alpha$ is the Mostowski collapse of a strict well-order $\langle X, \prec \rangle$. The Mostowski collapse of a strict well-order $\langle X, \prec \rangle$ is a unique transitive set $\alpha$ together with a collapsing function $F: X \to \alpha$ such that $F$ is a bijection and $\forall x,x' \in X ( x \prec x' \leftrightarrow F(x) \in F(x'))$, that is, $F$ is an order isomorphism. Proof: $\implies$ Let $\alpha$ be an ordinal. Then by definition, $\alpha$ is transitive and strictly well-ordered with respect to $\in$. Hence $\mathrm{id}: \alpha \to \alpha$ is a collapsing function and every ordinal is its own Mostowski collapse. $\Longleftarrow$: Let $\alpha$ be the Mostowski collapse of a strict well-order $\langle X, \prec \rangle$. Then $\alpha$ is transitive. It remains to be verified that $\alpha$ is strictly well-ordered with respect to $\in$. Since we have $\forall x,x' \in X ( x \prec x' \leftrightarrow F(x) \in F(x'))$, $F$ is a bijection and $X$ is a strict total order, it follows that $\alpha$ is a strict total order. Assume $\alpha$ was not well-founded and let $\beta \subset \alpha$ be a set containing an infinite descending chain. Then $F^{-1}\beta$ would be a subset of $X$ containing an infinite descending chain hence contradicting well-foundedness of $\prec$.","I tried to prove the following, can you tell me please if my proof is correct? Thank you. Claim: A set $\alpha$ is an ordinal iff $\alpha$ is the Mostowski collapse of a strict well-order $\langle X, \prec \rangle$. The Mostowski collapse of a strict well-order $\langle X, \prec \rangle$ is a unique transitive set $\alpha$ together with a collapsing function $F: X \to \alpha$ such that $F$ is a bijection and $\forall x,x' \in X ( x \prec x' \leftrightarrow F(x) \in F(x'))$, that is, $F$ is an order isomorphism. Proof: $\implies$ Let $\alpha$ be an ordinal. Then by definition, $\alpha$ is transitive and strictly well-ordered with respect to $\in$. Hence $\mathrm{id}: \alpha \to \alpha$ is a collapsing function and every ordinal is its own Mostowski collapse. $\Longleftarrow$: Let $\alpha$ be the Mostowski collapse of a strict well-order $\langle X, \prec \rangle$. Then $\alpha$ is transitive. It remains to be verified that $\alpha$ is strictly well-ordered with respect to $\in$. Since we have $\forall x,x' \in X ( x \prec x' \leftrightarrow F(x) \in F(x'))$, $F$ is a bijection and $X$ is a strict total order, it follows that $\alpha$ is a strict total order. Assume $\alpha$ was not well-founded and let $\beta \subset \alpha$ be a set containing an infinite descending chain. Then $F^{-1}\beta$ would be a subset of $X$ containing an infinite descending chain hence contradicting well-foundedness of $\prec$.",,"['elementary-set-theory', 'ordinals']"
51,Equivalent characterisations of Dedekind-finite proof,Equivalent characterisations of Dedekind-finite proof,,"The following is an exercise in Just/Weese: Show in ZF that the following are equivalent for every set $A$: (a) There is no injection $f: \omega \to A$ (b) Every injection $f: A \to A$ is a surjection Can you tell me if my proof is correct? Thank you! (b) $\rightarrow $ (a):  Assume $\lnot$ (a) and let $f: \omega \hookrightarrow A$ be an injection. Then $A$ is infinite hence (by corollary 13 on page 49) there exists a map $g: A \to A$ that is injective but not surjective. (a) $\rightarrow $ (b): Assume $\lnot$ (b) and let $f: A \to A$ be injective but not surjective. Let $a_0 \in f(A)^c$. Then the following map is an injection: define $g: \omega \to A$ as $g(\varnothing) = a_0$ and $g(n) = f(g(n-1))$. To see that $g$ is injective assume $g(n) = g(m)$ for $n > m$. Then $g(n-1) = g(m-1)$ and so on, until $g(n-m) = g(\varnothing) = a_0$. But the empty set is the only element mapping to $a_0$ hence $n-m = \varnothing$ and hence $n = m$. Edit","The following is an exercise in Just/Weese: Show in ZF that the following are equivalent for every set $A$: (a) There is no injection $f: \omega \to A$ (b) Every injection $f: A \to A$ is a surjection Can you tell me if my proof is correct? Thank you! (b) $\rightarrow $ (a):  Assume $\lnot$ (a) and let $f: \omega \hookrightarrow A$ be an injection. Then $A$ is infinite hence (by corollary 13 on page 49) there exists a map $g: A \to A$ that is injective but not surjective. (a) $\rightarrow $ (b): Assume $\lnot$ (b) and let $f: A \to A$ be injective but not surjective. Let $a_0 \in f(A)^c$. Then the following map is an injection: define $g: \omega \to A$ as $g(\varnothing) = a_0$ and $g(n) = f(g(n-1))$. To see that $g$ is injective assume $g(n) = g(m)$ for $n > m$. Then $g(n-1) = g(m-1)$ and so on, until $g(n-m) = g(\varnothing) = a_0$. But the empty set is the only element mapping to $a_0$ hence $n-m = \varnothing$ and hence $n = m$. Edit",,['elementary-set-theory']
52,How can you prove this set theory statement by contradiction [duplicate],How can you prove this set theory statement by contradiction [duplicate],,"This question already has answers here : Prove $f(S \cup T) = f(S) \cup f(T)$ (3 answers) Closed 10 years ago . $$f(A\cup B)=f(A)\cup f(B)$$ My attempt: Suppose that $f(A\cup B) \neq f(A) \cup f(B)$, then $f(A\cup B)$ has a variable $x$ that is neither in $A$ nor $B$; however, $A\cup B$ implies that $x$ must me in either $A$ or $B$, thus we have a contradiction. Yeah... it's terrible, but I have no intuition as to how to prove this in any other way. Also, the proofs I saw in the lectures were sometimes as unconvincing as this one I just came up with. It's like they're saying this is this because it is so. How do you develop the skills and intuition to solve these kind of problems? Also, you have to know it is true before proving it. How do you even know it is true just by looking at it?","This question already has answers here : Prove $f(S \cup T) = f(S) \cup f(T)$ (3 answers) Closed 10 years ago . $$f(A\cup B)=f(A)\cup f(B)$$ My attempt: Suppose that $f(A\cup B) \neq f(A) \cup f(B)$, then $f(A\cup B)$ has a variable $x$ that is neither in $A$ nor $B$; however, $A\cup B$ implies that $x$ must me in either $A$ or $B$, thus we have a contradiction. Yeah... it's terrible, but I have no intuition as to how to prove this in any other way. Also, the proofs I saw in the lectures were sometimes as unconvincing as this one I just came up with. It's like they're saying this is this because it is so. How do you develop the skills and intuition to solve these kind of problems? Also, you have to know it is true before proving it. How do you even know it is true just by looking at it?",,['elementary-set-theory']
53,The union of powersets is contained in the powerset of union,The union of powersets is contained in the powerset of union,,Prove or Disprove: For any family of sets $\{A_n\}_{n\in\mathbb N}$ $$\bigcup_{n=1}^\infty\mathcal P \left({A_n}\right)\subseteq \mathcal P \left({\bigcup_{n=1}^\infty A_n}\right)$$ How do I approach proving this? I know how to unpack the definition of powersets ($\mathcal P \left({A}\right) = \{x | x \subseteq A\}$) but I'm not sure what else I can do. I've done powerset proofs before but none involving indexed family of sets.,Prove or Disprove: For any family of sets $\{A_n\}_{n\in\mathbb N}$ $$\bigcup_{n=1}^\infty\mathcal P \left({A_n}\right)\subseteq \mathcal P \left({\bigcup_{n=1}^\infty A_n}\right)$$ How do I approach proving this? I know how to unpack the definition of powersets ($\mathcal P \left({A}\right) = \{x | x \subseteq A\}$) but I'm not sure what else I can do. I've done powerset proofs before but none involving indexed family of sets.,,['elementary-set-theory']
54,Directed Graphs on Relations - Set Theory,Directed Graphs on Relations - Set Theory,,"These questions were from an assignment I had some time ago but the solutions were not provided. A permutation $P$ on a finite set $A$ is a binary relation with the property that for each $a∈A$, there is precisely one element of $P$ of the form $(a, x)$, and precisely one element of $P$ of the form $(x, a)$. For example, $\{(1, 4), (2, 2), (3, 1), (4, 3)\}$ is a permutation of the set $\{1, 2, 3, 4\}$. Q: If $P$ is a permutation, describe the general form of its directed graph diagram. My solution: The general form of its directed graph being that it is one-to-one is that each element will have exactly one arrow going from it and one to it. (The marker of this assignment states, ""What does this mean for the structure of the diagram?""). Q: If $P$ and $Q$ are permutations on the set $\{1, 2, ... n\}$, how is the directed graph diagram of $P$ related to the directed graph $Q^{-1} \circ P \circ Q$? A: I claimed that they will have the exact same figure, meaning that the shape of the closed circuits will always be the same. Apparently this is correct according to the marker, but I am not sure how to prove this statement.","These questions were from an assignment I had some time ago but the solutions were not provided. A permutation $P$ on a finite set $A$ is a binary relation with the property that for each $a∈A$, there is precisely one element of $P$ of the form $(a, x)$, and precisely one element of $P$ of the form $(x, a)$. For example, $\{(1, 4), (2, 2), (3, 1), (4, 3)\}$ is a permutation of the set $\{1, 2, 3, 4\}$. Q: If $P$ is a permutation, describe the general form of its directed graph diagram. My solution: The general form of its directed graph being that it is one-to-one is that each element will have exactly one arrow going from it and one to it. (The marker of this assignment states, ""What does this mean for the structure of the diagram?""). Q: If $P$ and $Q$ are permutations on the set $\{1, 2, ... n\}$, how is the directed graph diagram of $P$ related to the directed graph $Q^{-1} \circ P \circ Q$? A: I claimed that they will have the exact same figure, meaning that the shape of the closed circuits will always be the same. Apparently this is correct according to the marker, but I am not sure how to prove this statement.",,"['elementary-set-theory', 'permutations']"
55,Proving $\bigcup A - \bigcup B \subset \bigcup(A-B)$,Proving,\bigcup A - \bigcup B \subset \bigcup(A-B),I need to prove: $\bigcup\limits_{i} A - \bigcup\limits_j B \subset \bigcup\limits_j (A-B)$ $\bigcap\limits_{i} A - \bigcap\limits_j B \subset \bigcup\limits_j (A-B)$ So when can the equality hold? Appreciate your help.,I need to prove: $\bigcup\limits_{i} A - \bigcup\limits_j B \subset \bigcup\limits_j (A-B)$ $\bigcap\limits_{i} A - \bigcap\limits_j B \subset \bigcup\limits_j (A-B)$ So when can the equality hold? Appreciate your help.,,['elementary-set-theory']
56,Set notation: subtracting elements with given cardinality from the powerset,Set notation: subtracting elements with given cardinality from the powerset,,"I have a set $S = \{1,2,\ldots,n\}$ of $n$ elements and I denote with $P(S)$ the powerset of $S$. Which is a correct and accepted notation to say that the set $Z$ is composed by all the elements in $P(S)$ with the exception of all the subsets of cardinality $h$? Example: if $S=\{1,2,3\}$ then $P(S) = \{\emptyset, \{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}$. If $h = 1$, then it should be $Z = \{\emptyset, \{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}=P(S)\setminus\{\{1\},\{2\},\{3\}\}$. How can it be expressed in a formal and concise way, for any value of $n$ and $h$? Thanks","I have a set $S = \{1,2,\ldots,n\}$ of $n$ elements and I denote with $P(S)$ the powerset of $S$. Which is a correct and accepted notation to say that the set $Z$ is composed by all the elements in $P(S)$ with the exception of all the subsets of cardinality $h$? Example: if $S=\{1,2,3\}$ then $P(S) = \{\emptyset, \{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}$. If $h = 1$, then it should be $Z = \{\emptyset, \{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\}=P(S)\setminus\{\{1\},\{2\},\{3\}\}$. How can it be expressed in a formal and concise way, for any value of $n$ and $h$? Thanks",,"['elementary-set-theory', 'notation']"
57,What does String mean in context of counting theory?,What does String mean in context of counting theory?,,"What does ""String"" mean in context of counting theory ? For example : There are 8 binary strings of length 3 . What does binary and length signify here ? Edit : I want to specifically why it is called a String ?","What does ""String"" mean in context of counting theory ? For example : There are 8 binary strings of length 3 . What does binary and length signify here ? Edit : I want to specifically why it is called a String ?",,"['probability', 'combinatorics', 'elementary-set-theory']"
58,Cantor's theorem,Cantor's theorem,,"The theorem cardinality of set of real numbers is strictly larger than cardinality of set of natural numbers uses diagonal method in its proof. Why can't we use the same argument for creating a natural number just like we do real number? i.e. take 1st digit of the first element, 2nd digit of the second element... and change the digits so that the new natural number differs from the rest in the set of natural numbers.","The theorem cardinality of set of real numbers is strictly larger than cardinality of set of natural numbers uses diagonal method in its proof. Why can't we use the same argument for creating a natural number just like we do real number? i.e. take 1st digit of the first element, 2nd digit of the second element... and change the digits so that the new natural number differs from the rest in the set of natural numbers.",,['elementary-set-theory']
59,Ordinal exponentiation of limit ordinal,Ordinal exponentiation of limit ordinal,,"Prove that If $a$ is a limit ordinal and $p$ and $q$ are finite ordinals, then $(ap)^q$ = $a^q$$p^q$. In my book, the right side of the equality is written as $a^qp$, but i think its typo since equality does not hold for the case $q=0$ and $p\ge1$.","Prove that If $a$ is a limit ordinal and $p$ and $q$ are finite ordinals, then $(ap)^q$ = $a^q$$p^q$. In my book, the right side of the equality is written as $a^qp$, but i think its typo since equality does not hold for the case $q=0$ and $p\ge1$.",,"['elementary-set-theory', 'ordinals']"
60,n-tuple Notation,n-tuple Notation,,"I am reading a paper (to be able to implement the Baum-Welch algorithm in it) and the following notation is defined: $$ [ a_k ]_{k=i}^j  ≡ (a_i, a_{i+1}, \ldots , a_j) $$ $$ [a(k)]_{k=i}^j ≡ (a(i), a(i+ 1), \ldots , a( j)) $$ I (think) the first is shorthand of a n-tuple. I guess the second is something like that, but I don't understand the difference between the first and the second. Is this common notation something odd, or what? I am pretty rusty on my math, so if I am missing something obvious please don't hesitate to point that out.","I am reading a paper (to be able to implement the Baum-Welch algorithm in it) and the following notation is defined: $$ [ a_k ]_{k=i}^j  ≡ (a_i, a_{i+1}, \ldots , a_j) $$ $$ [a(k)]_{k=i}^j ≡ (a(i), a(i+ 1), \ldots , a( j)) $$ I (think) the first is shorthand of a n-tuple. I guess the second is something like that, but I don't understand the difference between the first and the second. Is this common notation something odd, or what? I am pretty rusty on my math, so if I am missing something obvious please don't hesitate to point that out.",,"['elementary-set-theory', 'notation']"
61,Product space and product topology,Product space and product topology,,"I have been told that (in context of Tychonoff's theorem) that $\prod_{i\in I}X_i$ (take for example $I=\{1,2\}$) and $X_1 \times X_2$ are isomorphic. Generally when $I$ is countably infinite or finite then $\prod_{i\in I}X_i$ is isomorphic to $\prod_{i=1}^\infty X_i$. I am not able to understand how they are isomorphic. My main issue is not being able to understand the what ""product space"" means and how is it different from the product topology.  Waiting for a reply. Thanks","I have been told that (in context of Tychonoff's theorem) that $\prod_{i\in I}X_i$ (take for example $I=\{1,2\}$) and $X_1 \times X_2$ are isomorphic. Generally when $I$ is countably infinite or finite then $\prod_{i\in I}X_i$ is isomorphic to $\prod_{i=1}^\infty X_i$. I am not able to understand how they are isomorphic. My main issue is not being able to understand the what ""product space"" means and how is it different from the product topology.  Waiting for a reply. Thanks",,"['general-topology', 'elementary-set-theory']"
62,Cardinality of a product of countable many sets,Cardinality of a product of countable many sets,,"I'm working on this problem that involves the collections of sets. I'm not really sure how to approach this problem. I understand that to prove that something is numerically equivalent one must show that there is a bijection. Any help would be appreciated. Let $\{A_i\}_{i \in \mathbb{Z_+}}$ be a countable collection of sets. Let $B = \displaystyle \prod_{i\in \mathbb{Z_+}}A_i$ be the Cartesian product of the collection. Prove that if every set of the collection $\{A_i\}_{i\in \mathbb{Z_+}}$ contains two distinct elements, then $B$ is numerically equivalent to $\mathbb{R}$, that is, $|B|=|\mathbb{R}|$","I'm working on this problem that involves the collections of sets. I'm not really sure how to approach this problem. I understand that to prove that something is numerically equivalent one must show that there is a bijection. Any help would be appreciated. Let $\{A_i\}_{i \in \mathbb{Z_+}}$ be a countable collection of sets. Let $B = \displaystyle \prod_{i\in \mathbb{Z_+}}A_i$ be the Cartesian product of the collection. Prove that if every set of the collection $\{A_i\}_{i\in \mathbb{Z_+}}$ contains two distinct elements, then $B$ is numerically equivalent to $\mathbb{R}$, that is, $|B|=|\mathbb{R}|$",,"['elementary-set-theory', 'cardinals']"
63,Image countable when state space is not?,Image countable when state space is not?,,"From Jacod / Protter: ""Probability Essentials"" , Springer : Note that even if the state space (or range space) $T$ is not countable, the image $T'$ of $\Omega$ under $X$ (that is, all points $\{i\}$ in $T$ for which there exists an $\omega\in\Omega$ such that $X(\omega) = i$ ) is either finite or countably infinite. (where $X$ is a function (random variable) from $\Omega$ into a set $T$) I do not understand this. If $T$ is the uncountable set $\bf R$ (the real numbers), could the image also be uncountably infinite?","From Jacod / Protter: ""Probability Essentials"" , Springer : Note that even if the state space (or range space) $T$ is not countable, the image $T'$ of $\Omega$ under $X$ (that is, all points $\{i\}$ in $T$ for which there exists an $\omega\in\Omega$ such that $X(\omega) = i$ ) is either finite or countably infinite. (where $X$ is a function (random variable) from $\Omega$ into a set $T$) I do not understand this. If $T$ is the uncountable set $\bf R$ (the real numbers), could the image also be uncountably infinite?",,"['probability-theory', 'elementary-set-theory', 'random']"
64,Set of intervals on the real line,Set of intervals on the real line,,"I'm not sure how to approach this proof? any ideas Let $A$ be a set of intervals of the real line any two of which are disjoint - in other words, if $(a,b)$ and $(x,y)$ are distinct elements of $A$ then $(a,b)\cap(x,y)=\emptyset$. Prove that A is countable. *(Use the fact that $\mathbb Q$ is countable)","I'm not sure how to approach this proof? any ideas Let $A$ be a set of intervals of the real line any two of which are disjoint - in other words, if $(a,b)$ and $(x,y)$ are distinct elements of $A$ then $(a,b)\cap(x,y)=\emptyset$. Prove that A is countable. *(Use the fact that $\mathbb Q$ is countable)",,['elementary-set-theory']
65,Cardinality of the power set of natural numbers,Cardinality of the power set of natural numbers,,"I was reading an article on infinite sets and I came across a proof about how the power set of natural numbers has a greater cardinality than the set of natural numbers. I know that both given that proof and the proof of Cantor's theorem, that it must be true. So, my question is why does encoding the each set of natural numbers in the power set using Gödel numbering not work? Thanks.","I was reading an article on infinite sets and I came across a proof about how the power set of natural numbers has a greater cardinality than the set of natural numbers. I know that both given that proof and the proof of Cantor's theorem, that it must be true. So, my question is why does encoding the each set of natural numbers in the power set using Gödel numbering not work? Thanks.",,"['elementary-set-theory', 'natural-numbers']"
66,"Given the set $\textbf{S}$, find a subset such that the sum of all the elements equals to 1","Given the set , find a subset such that the sum of all the elements equals to 1",\textbf{S},"Given the set $\textbf{S}=\{\frac{1}{2},\frac{1}{4},\frac{1}{6},\frac{1}{8},\frac{1}{10},\frac{1}{12},\frac{1}{14}\}$, find a subset such that the sum of all the elements equals to 1 The answer to this question is relatively easy to obtain, however, I am not happy with my approach. Basically my question is, is there an analytical approach to solve this problem? My approach: $\frac{1}{2}$ must be an element of the subset since $\frac{1}{4}+\frac{1}{6}+\frac{1}{8}+\frac{1}{10}+\frac{1}{12}+\frac{1}{14}<1$. Using similar logic I also deduced that $\frac{1}{4}$ must be a member of the subset. However, after this, my approach was literally guesswork. I was lucky however and knew that $\frac{1}{6}+\frac{1}{12}=\frac{1}{4}$ which allowed me to solve the problem. However, the latter approach (the guesswork part) was only successful because the given set was small enough for a brute force approach and I was lucky to know $\frac{1}{6}+\frac{1}{12}=\frac{1}{4}$. If the set was bigger however, and lets say the sum of the elements of the subset had to be 99.5 instead of 1 it would take a lot longer to solve. Is there a more rigorous way to solve this question?","Given the set $\textbf{S}=\{\frac{1}{2},\frac{1}{4},\frac{1}{6},\frac{1}{8},\frac{1}{10},\frac{1}{12},\frac{1}{14}\}$, find a subset such that the sum of all the elements equals to 1 The answer to this question is relatively easy to obtain, however, I am not happy with my approach. Basically my question is, is there an analytical approach to solve this problem? My approach: $\frac{1}{2}$ must be an element of the subset since $\frac{1}{4}+\frac{1}{6}+\frac{1}{8}+\frac{1}{10}+\frac{1}{12}+\frac{1}{14}<1$. Using similar logic I also deduced that $\frac{1}{4}$ must be a member of the subset. However, after this, my approach was literally guesswork. I was lucky however and knew that $\frac{1}{6}+\frac{1}{12}=\frac{1}{4}$ which allowed me to solve the problem. However, the latter approach (the guesswork part) was only successful because the given set was small enough for a brute force approach and I was lucky to know $\frac{1}{6}+\frac{1}{12}=\frac{1}{4}$. If the set was bigger however, and lets say the sum of the elements of the subset had to be 99.5 instead of 1 it would take a lot longer to solve. Is there a more rigorous way to solve this question?",,['elementary-set-theory']
67,Proving all rational numbers including negatives are countable,Proving all rational numbers including negatives are countable,,In this proof can I show independently that positive rationals and negative rationals are countable by using Cantor's zigzag and then say that the union of two countable sets is countable so therefore positive and negative rationals are countable. Is this correct ?,In this proof can I show independently that positive rationals and negative rationals are countable by using Cantor's zigzag and then say that the union of two countable sets is countable so therefore positive and negative rationals are countable. Is this correct ?,,['elementary-set-theory']
68,Suppose $A \subseteq  C$ and $B$  and $C$ are disjoint. Prove that $x \in A \rightarrow x \notin B$,Suppose  and   and  are disjoint. Prove that,A \subseteq  C B C x \in A \rightarrow x \notin B,Suppose $A \subseteq  C$ and $B$  and $C$ are disjoint. Prove that $x \in A \rightarrow x \notin B$. Basically I need to prove this.,Suppose $A \subseteq  C$ and $B$  and $C$ are disjoint. Prove that $x \in A \rightarrow x \notin B$. Basically I need to prove this.,,"['algebra-precalculus', 'elementary-set-theory']"
69,Explicit description in set-builder notation of an arbitrary open set of the product topology,Explicit description in set-builder notation of an arbitrary open set of the product topology,,"Short version : Is it possible to explicitly describe the open sets of the product topology (of arbitrary topological spaces) via set-builder notation? (Or differently formulated: What do to if set set I want to describe contains arbitrary many disjunction symbols ?) Long  version : Given a set $I$ and for every $i\in I$ a topological space $(X_i,\tau _i)$, then one can endow $\prod X_i $ with a topology by specifying  a set $$\mathcal{S}=\{\prod Y_i \ |\  \exists j\in I \ \ \forall i \in I\setminus \{j\}: Y_i=X_i \textrm{ and } Y_j\in \tau _j\}.$$ Then there is only one topology, the product topology, for which this set is a subbase. To obtain the open sets in this topology, one has to go through the following process: One first has to intersect the elements from $S$ finitely many times - then one has obtained a base, $\mathcal{B}$, for the topology - and then one has to form arbitrary unions of the set in the base. $ \ $ Let's warm up - I can describe the an element to be in $\mathcal{S}$ either by its construction, meaning it satisfies: $S\in \mathcal{S} \Leftrightarrow \exists j\in I \ \ \exists O\in \tau_j \ \ \forall i \in I\setminus \{j\}: Y_i=X_i \textrm{ and } Y_j=O,$ or if it is of the form $S=\{f:I\rightarrow \cup_{i\in I} X_i \ | \ \exists i\in I \ \ \exists O\in \tau_i: f(i)\in O  \}.$ $ \ $ The same (only a bit more tedious to write out) goes for $\mathcal{B}$: $B\in \mathcal{B}  \Leftrightarrow  \exists J, \ J \textrm{ finite set, such that } B=\cap_{j\in J} S_j $ with $S_j\in S,$ or in set-builder notation: $B = \{  f:I\rightarrow \cup_{i\in I} X_i \ | \ \exists n\in \mathbb{N} \ \ \exists i_1,\ldots,i_n \in I \ \ \exists O_{i_1}\in T_{i_1},\ldots,O_{i_n}\in T_{i_n} $ such that $f(i_1)\in O_{i_1} \land ,\ldots, \land f(i_n)\in O_{i_n} \}. $ $ \ $ But if I want to describe an open set like above, I can only describe it via its contruction: $O\in \mathcal{O}  \Leftrightarrow  \exists F, F \textrm{ arbitrary set},\  \ \exists J, \ J \textrm{ finite set, such that } O=\cup_{f \in F} \, \cap_{j\in J} S_{fj} $ with $S_{fj}\in S$. If I wanted to describe it in set-builder notation I would have to have use infinitely many disjunction symbols.  To exemplify this, see the following: Since an union of, lets say two base sets, $B_1\cup B_2$, can be written in set-builder notation as - this gets nasty - $B_1\cup B_2= \{  f:I\rightarrow \cup_{i\in I} X_i \ | \ \  \exists n_1,n_2 \in \mathbb{N} \ \ \exists i_{1,n_1},\ldots ,i_{n_1,n_1}\in I, \ \  [\ldots ]$  $ [\ldots ]  i_{1,n_2},\ldots ,i_{2,n_2} \in I \ \ \ \exists O_{1,n_1} \in \tau_{i_{1,n_1}} ,\ldots ,O_{n_1,n_1} \in \tau_{i_{n_1,n_1}}, \ [\ldots ]  $ $[\ldots ]  O_{1,n_2} \in \tau_{i_{1,n_2}}  ,\ldots ,O_{n_2,n_2} \in \tau_{i_{n_2,n_2}}  \textrm{ such that }  [\ldots ]$ $  [\ldots ]  ( f(i_{1,n_1})\in O_{1,n_1} \land ,\ldots , \land f(i_{n_1,n_1})\in O_{n_1,n_1}) \ \ \lor ( f(i_{1,n_2})\in O_{1,n_2} \land ,\ldots , \land f(i_{n_2,n_2})\in O_{n_2,n_2})$} I would get for arbitrary unions  arbitrary many disjunctions - but I can't write that out!","Short version : Is it possible to explicitly describe the open sets of the product topology (of arbitrary topological spaces) via set-builder notation? (Or differently formulated: What do to if set set I want to describe contains arbitrary many disjunction symbols ?) Long  version : Given a set $I$ and for every $i\in I$ a topological space $(X_i,\tau _i)$, then one can endow $\prod X_i $ with a topology by specifying  a set $$\mathcal{S}=\{\prod Y_i \ |\  \exists j\in I \ \ \forall i \in I\setminus \{j\}: Y_i=X_i \textrm{ and } Y_j\in \tau _j\}.$$ Then there is only one topology, the product topology, for which this set is a subbase. To obtain the open sets in this topology, one has to go through the following process: One first has to intersect the elements from $S$ finitely many times - then one has obtained a base, $\mathcal{B}$, for the topology - and then one has to form arbitrary unions of the set in the base. $ \ $ Let's warm up - I can describe the an element to be in $\mathcal{S}$ either by its construction, meaning it satisfies: $S\in \mathcal{S} \Leftrightarrow \exists j\in I \ \ \exists O\in \tau_j \ \ \forall i \in I\setminus \{j\}: Y_i=X_i \textrm{ and } Y_j=O,$ or if it is of the form $S=\{f:I\rightarrow \cup_{i\in I} X_i \ | \ \exists i\in I \ \ \exists O\in \tau_i: f(i)\in O  \}.$ $ \ $ The same (only a bit more tedious to write out) goes for $\mathcal{B}$: $B\in \mathcal{B}  \Leftrightarrow  \exists J, \ J \textrm{ finite set, such that } B=\cap_{j\in J} S_j $ with $S_j\in S,$ or in set-builder notation: $B = \{  f:I\rightarrow \cup_{i\in I} X_i \ | \ \exists n\in \mathbb{N} \ \ \exists i_1,\ldots,i_n \in I \ \ \exists O_{i_1}\in T_{i_1},\ldots,O_{i_n}\in T_{i_n} $ such that $f(i_1)\in O_{i_1} \land ,\ldots, \land f(i_n)\in O_{i_n} \}. $ $ \ $ But if I want to describe an open set like above, I can only describe it via its contruction: $O\in \mathcal{O}  \Leftrightarrow  \exists F, F \textrm{ arbitrary set},\  \ \exists J, \ J \textrm{ finite set, such that } O=\cup_{f \in F} \, \cap_{j\in J} S_{fj} $ with $S_{fj}\in S$. If I wanted to describe it in set-builder notation I would have to have use infinitely many disjunction symbols.  To exemplify this, see the following: Since an union of, lets say two base sets, $B_1\cup B_2$, can be written in set-builder notation as - this gets nasty - $B_1\cup B_2= \{  f:I\rightarrow \cup_{i\in I} X_i \ | \ \  \exists n_1,n_2 \in \mathbb{N} \ \ \exists i_{1,n_1},\ldots ,i_{n_1,n_1}\in I, \ \  [\ldots ]$  $ [\ldots ]  i_{1,n_2},\ldots ,i_{2,n_2} \in I \ \ \ \exists O_{1,n_1} \in \tau_{i_{1,n_1}} ,\ldots ,O_{n_1,n_1} \in \tau_{i_{n_1,n_1}}, \ [\ldots ]  $ $[\ldots ]  O_{1,n_2} \in \tau_{i_{1,n_2}}  ,\ldots ,O_{n_2,n_2} \in \tau_{i_{n_2,n_2}}  \textrm{ such that }  [\ldots ]$ $  [\ldots ]  ( f(i_{1,n_1})\in O_{1,n_1} \land ,\ldots , \land f(i_{n_1,n_1})\in O_{n_1,n_1}) \ \ \lor ( f(i_{1,n_2})\in O_{1,n_2} \land ,\ldots , \land f(i_{n_2,n_2})\in O_{n_2,n_2})$} I would get for arbitrary unions  arbitrary many disjunctions - but I can't write that out!",,"['general-topology', 'logic', 'elementary-set-theory', 'notation']"
70,How to show the ascending chain condition,How to show the ascending chain condition,,"Let $(A,\le)$ be a poset.  Suppose that for any $a < b \in A$ and for any chain $Q$ of $A$ whose maximum and minimum are $a$ and $b$ respectively, $Q$ is finite. Let $C$ be the set of all chains of $A$, ordered under inclusion. I'd like to show that the poset $(C,\subset)$ satisfies the ascending chain condition (ACC). I tried to show it by contradiction.  Negating the ACC, we can say the existence of an infinite sequence $(Q_i)_{i\in\mathbb{N}}$ of elements of $C$ such that $Q_0 \subsetneq Q_1 \subsetneq Q_2 \subsetneq \cdots$.  I think this contradicts the fact that all elements of $C$ are finite, but I cannot show it vigorously. EDIT:  What I really wanted to prove was that $(C, \subset)$ satisfies the ACC, where C is the set of chains whose whose maximum and minimum are $a$ and $b$ respectively.  I'm sorry, but the answers seem to still hold.","Let $(A,\le)$ be a poset.  Suppose that for any $a < b \in A$ and for any chain $Q$ of $A$ whose maximum and minimum are $a$ and $b$ respectively, $Q$ is finite. Let $C$ be the set of all chains of $A$, ordered under inclusion. I'd like to show that the poset $(C,\subset)$ satisfies the ascending chain condition (ACC). I tried to show it by contradiction.  Negating the ACC, we can say the existence of an infinite sequence $(Q_i)_{i\in\mathbb{N}}$ of elements of $C$ such that $Q_0 \subsetneq Q_1 \subsetneq Q_2 \subsetneq \cdots$.  I think this contradicts the fact that all elements of $C$ are finite, but I cannot show it vigorously. EDIT:  What I really wanted to prove was that $(C, \subset)$ satisfies the ACC, where C is the set of chains whose whose maximum and minimum are $a$ and $b$ respectively.  I'm sorry, but the answers seem to still hold.",,"['elementary-set-theory', 'order-theory']"
71,Can you please explain this simple task with sets to me?,Can you please explain this simple task with sets to me?,,"I'm solving some problems for practice, and I've come across a something I don't quite understand... So here's the deal: $A = \{x \in \mathbb{N}: -1 \leq x < 2\}$ $B = \{x \in \mathbb{Z}: -10 < x \leq 0\}$ $C = \{n \in \mathbb{Z}: n = 2k + 1, k \in \mathbb{Z}\}$ a) $C \setminus(A\cap B)$ b) $(B\cup C)\setminus A$ How am I supposed to solve this when $C$ has infinite members?","I'm solving some problems for practice, and I've come across a something I don't quite understand... So here's the deal: $A = \{x \in \mathbb{N}: -1 \leq x < 2\}$ $B = \{x \in \mathbb{Z}: -10 < x \leq 0\}$ $C = \{n \in \mathbb{Z}: n = 2k + 1, k \in \mathbb{Z}\}$ a) $C \setminus(A\cap B)$ b) $(B\cup C)\setminus A$ How am I supposed to solve this when $C$ has infinite members?",,['elementary-set-theory']
72,Testing two sets for equivalence,Testing two sets for equivalence,,"I'm confused. Two finite sets (call them A = [a, b] and C = [c, d]) are equivalent if there exists a 1-1 bijection from A to C. But the bijection exists iff A has the same number of elements as C. So am I correct in saying that two finite sets can't be equivalent unless they have the same number of elements? I've been asked this: Let a < b and c < d. Show [a, b] is equivalent to [c, d].","I'm confused. Two finite sets (call them A = [a, b] and C = [c, d]) are equivalent if there exists a 1-1 bijection from A to C. But the bijection exists iff A has the same number of elements as C. So am I correct in saying that two finite sets can't be equivalent unless they have the same number of elements? I've been asked this: Let a < b and c < d. Show [a, b] is equivalent to [c, d].",,[]
73,What is the simplest way to represent this situation mathematically?,What is the simplest way to represent this situation mathematically?,,"Sitting in my room with two large jars full of green tea and black coffee, I suddenly realized that I would not be able to drink the coffee first. That is because I only regularly drink out of one of the jars. Yet I also realized that, without a third jar, I would not be able to move all of the contents of jar 1 into jar 2. As such, it seemed like there was something universal about the fact that, given two full jars, the contents of one cannot be poured into the other without the existence of a third jar. I suddenly found myself wanting a mathematical abstraction that could represent this situation. But I have no idea how a set could be called 'full.' I suppose there is some set-theoretic mathematical structure that can have this property though, right?","Sitting in my room with two large jars full of green tea and black coffee, I suddenly realized that I would not be able to drink the coffee first. That is because I only regularly drink out of one of the jars. Yet I also realized that, without a third jar, I would not be able to move all of the contents of jar 1 into jar 2. As such, it seemed like there was something universal about the fact that, given two full jars, the contents of one cannot be poured into the other without the existence of a third jar. I suddenly found myself wanting a mathematical abstraction that could represent this situation. But I have no idea how a set could be called 'full.' I suppose there is some set-theoretic mathematical structure that can have this property though, right?",,['elementary-set-theory']
74,Is this relation transitive if $n=m$?,Is this relation transitive if ?,n=m,"If $X$ is a set and $n \in \mathbb N$, then $[X]^n$ will denote the set of all subsets of $X$ with exactly $n$ elements. For a set $X$ and natural numbers $n$ and $m$ define a relation $R$ on $[X]^n$ and $[X]^m$ by $R(A,B)$ holds if and only $A \cap B = \emptyset$. Is $R$ transitive if $n = m$? Need an example or proof","If $X$ is a set and $n \in \mathbb N$, then $[X]^n$ will denote the set of all subsets of $X$ with exactly $n$ elements. For a set $X$ and natural numbers $n$ and $m$ define a relation $R$ on $[X]^n$ and $[X]^m$ by $R(A,B)$ holds if and only $A \cap B = \emptyset$. Is $R$ transitive if $n = m$? Need an example or proof",,"['elementary-set-theory', 'relations', 'problem-solving', 'proof-writing']"
75,"Finding a set of subsets such that for each such subset in the set, there exists another subset in the same set which is non-disjoint","Finding a set of subsets such that for each such subset in the set, there exists another subset in the same set which is non-disjoint",,"I'm sorry if the title is a bit convoluted. I'm a bit unsure how to formulate this condition in words, see below instead. Say we are given a set $Y$. I want to find the following set: $\mathcal{A}$ such that for any $x=\{G_1, ..., G_k\} \in \mathcal{A}, G_i \subset Y$, we have that: $\forall G_i \in x, \exists G_j \in x, i \neq j ,  \quad G_i \cap G_j \neq \emptyset $ I'm mostly interesting in finding an algorithm which generates this set. This problem arose when trying to figure out how to generate the set of subgraphs of a connected subgraphs, such that their union is still connected. So the sets above would then be vertex sets and I would form their induced graph. So, I want to find the subgraphs such that the union of all those subgraphs $\bigcup_{i=1}^{k}G_{i} \text{ is connected}$. Since each of the subgraphs themselves are connected (since the graph is), the above stated condition ought to ensure that their union is connected. Anyone have an idea how to tackle this? Any help is much appreciated!","I'm sorry if the title is a bit convoluted. I'm a bit unsure how to formulate this condition in words, see below instead. Say we are given a set $Y$. I want to find the following set: $\mathcal{A}$ such that for any $x=\{G_1, ..., G_k\} \in \mathcal{A}, G_i \subset Y$, we have that: $\forall G_i \in x, \exists G_j \in x, i \neq j ,  \quad G_i \cap G_j \neq \emptyset $ I'm mostly interesting in finding an algorithm which generates this set. This problem arose when trying to figure out how to generate the set of subgraphs of a connected subgraphs, such that their union is still connected. So the sets above would then be vertex sets and I would form their induced graph. So, I want to find the subgraphs such that the union of all those subgraphs $\bigcup_{i=1}^{k}G_{i} \text{ is connected}$. Since each of the subgraphs themselves are connected (since the graph is), the above stated condition ought to ensure that their union is connected. Anyone have an idea how to tackle this? Any help is much appreciated!",,"['combinatorics', 'graph-theory', 'elementary-set-theory']"
76,Help on a proof,Help on a proof,,"I'm studying a proof on this book http://www.math.ucsd.edu/~atparris/papers/book.pdf I can't copy here the proof I'm studying because it is a little bit long. I only need help on a little statement. I don't understand in the page 180 of the book why we can choose $\alpha,\alpha^\prime\in\{\alpha_1,\alpha_2,\alpha_3\}$ distinct such that $x_\alpha-x_{\alpha^\prime}\not\in\{x_\beta-x_{\beta^\prime},x_{\beta^\prime}-x_\beta\}$.","I'm studying a proof on this book http://www.math.ucsd.edu/~atparris/papers/book.pdf I can't copy here the proof I'm studying because it is a little bit long. I only need help on a little statement. I don't understand in the page 180 of the book why we can choose $\alpha,\alpha^\prime\in\{\alpha_1,\alpha_2,\alpha_3\}$ distinct such that $x_\alpha-x_{\alpha^\prime}\not\in\{x_\beta-x_{\beta^\prime},x_{\beta^\prime}-x_\beta\}$.",,"['elementary-set-theory', 'logic', 'proof-explanation']"
77,How to write that type can be one of?,How to write that type can be one of?,,"Having: $$ O \in \{{A,B,C}\} $$ How to stress that $O$ has to be one of types defined in collection? Does inclusion already does it?","Having: $$ O \in \{{A,B,C}\} $$ How to stress that $O$ has to be one of types defined in collection? Does inclusion already does it?",,['elementary-set-theory']
78,"If $m<n$, then $k^m<k^n$?","If , then ?",m<n k^m<k^n,"So I want to prove that for natural numbers $m,n,k$, if $k$ is no $0$ or $1$, and if $m<n$, then $k^m<k^n$. I jotted down the following proof, but I'm not sure how acceptable it is. I only have use of basic set theoretic properties of the naturals with addition, multiplication, and powers. I also have use of cancellation. Let $$ K=\{k\in\omega\ |\ k^m<k^n\}. $$ Since $m<n$ there exists a $p^+\in\omega$ such that $m+p^+=n$. Consider $2$. I claim $2^{p^+}>1$. Now $p^+\neq 0$, since $0$ is not in the range of the successor. If $p^+=1$, then from the work above, $2^1=2>1$. Suppose then that $2^{p^+}>1$. Then $2^{p^{++}}=2^{p^+}\cdot 2>1$. This follows by transitivity since $1<2^{p^+}$, and $1<2$ implies $2^{p^+}\cdot 1<2^{p^+}\cdot 2$, that is $2^{p^+}<2^{p^{++}}$. Then from $1<2^{p^+}$ we have $2^m=2^m\cdot 1<2^m\cdot 2^{p^+}=2^{m+p^+}=2^n$, so $2\in K$. By the same reasoning we can show that any $k\neq 0,1$ is in $K$. If $k\neq 0,1$, then $1<k$. Again, I claim $k^{p^+}>1$. If $p^+=1$, we are done. So suppose $k^{p^+}>1$. Then since $1<k$, we have $k^{p^+}=k^{p^+}\cdot 1<k^{p^+}\cdot k=k^{p^{++}}$, so $1<k^{p^{++}}$ by transitivity, and so $k^{p^+}>1$ for all $p$, since $p^+\neq 0$. Then from $1<k^{p^+}$ we have $k^m\cdot 1<k^m\cdot k^{p^+}=k^{m+p^+}=k^n$, so $k\in K$, and the result follows. All in all, this approach seems very ugly. Is there a way to clean it up? I wanted to use the time tested method of induction, but assuming $k^m<k^n$ seems to have little to do with showing $(k^+)^m<(k^+)^n$, since I don't know how to distribute powers. Thanks for any constructive criticism.","So I want to prove that for natural numbers $m,n,k$, if $k$ is no $0$ or $1$, and if $m<n$, then $k^m<k^n$. I jotted down the following proof, but I'm not sure how acceptable it is. I only have use of basic set theoretic properties of the naturals with addition, multiplication, and powers. I also have use of cancellation. Let $$ K=\{k\in\omega\ |\ k^m<k^n\}. $$ Since $m<n$ there exists a $p^+\in\omega$ such that $m+p^+=n$. Consider $2$. I claim $2^{p^+}>1$. Now $p^+\neq 0$, since $0$ is not in the range of the successor. If $p^+=1$, then from the work above, $2^1=2>1$. Suppose then that $2^{p^+}>1$. Then $2^{p^{++}}=2^{p^+}\cdot 2>1$. This follows by transitivity since $1<2^{p^+}$, and $1<2$ implies $2^{p^+}\cdot 1<2^{p^+}\cdot 2$, that is $2^{p^+}<2^{p^{++}}$. Then from $1<2^{p^+}$ we have $2^m=2^m\cdot 1<2^m\cdot 2^{p^+}=2^{m+p^+}=2^n$, so $2\in K$. By the same reasoning we can show that any $k\neq 0,1$ is in $K$. If $k\neq 0,1$, then $1<k$. Again, I claim $k^{p^+}>1$. If $p^+=1$, we are done. So suppose $k^{p^+}>1$. Then since $1<k$, we have $k^{p^+}=k^{p^+}\cdot 1<k^{p^+}\cdot k=k^{p^{++}}$, so $1<k^{p^{++}}$ by transitivity, and so $k^{p^+}>1$ for all $p$, since $p^+\neq 0$. Then from $1<k^{p^+}$ we have $k^m\cdot 1<k^m\cdot k^{p^+}=k^{m+p^+}=k^n$, so $k\in K$, and the result follows. All in all, this approach seems very ugly. Is there a way to clean it up? I wanted to use the time tested method of induction, but assuming $k^m<k^n$ seems to have little to do with showing $(k^+)^m<(k^+)^n$, since I don't know how to distribute powers. Thanks for any constructive criticism.",,[]
79,Is 2-multiset a valid term?,Is 2-multiset a valid term?,,"I am trying to describe the edges of an undirected graph that contains loops. On Wikipedia they are characterized as 2-multisets , meaning it has two elements which can be identical, and the order is not important. I never heard of that term, and find no reference to it anywhere else, so I am not sure whether it is OK to use it in my thesis. Can anyone clear that up for me?","I am trying to describe the edges of an undirected graph that contains loops. On Wikipedia they are characterized as 2-multisets , meaning it has two elements which can be identical, and the order is not important. I never heard of that term, and find no reference to it anywhere else, so I am not sure whether it is OK to use it in my thesis. Can anyone clear that up for me?",,"['elementary-set-theory', 'notation', 'multisets']"
80,"If $p\in\mathbb{Q}^+$, for any $x\in\mathbb{R}$, there is a rational $q\in x$ such that $p+q\not\in x$","If , for any , there is a rational  such that",p\in\mathbb{Q}^+ x\in\mathbb{R} q\in x p+q\not\in x,"I just read about the construction of the real numbers in Enderton's Elements of Set Theory, and am now trying to go through all the exercises. Enderton chooses to construct the reals with left sides of Dedekind cuts. His definition is $y$ is a Dedekind cut if $\emptyset\neq y\neq\mathbb{Q}$, $y$ has no largest member, and $y$ is downward closed, i.e., $q\in y\wedge r<q\implies r\in y$. The following, question 19 of chapter 5 has me a bit baffled. Assume that $p$ is a positive rational number. Show that for any real number $x$ there is some rational $q$ in $x$ such that $p+q\not\in x$. I have this intuitive argument in my head. I guess I want to take $q\in x$, preferably closer to the right in $x$ on the rational line than not, and add it to $p$. If $p+q\not\in x$, then I am done. Otherwise, since $x$ has no greatest element, I can find $q'\in x$ such that $q'>q$, and add it to $p$ until I finally get a $q$ that pushes $p+q$ out of $x$, supposing of course that this process eventually ends. But this is horribly informal, and I have very little experience with analysis, and can't see a way to formalize it (if this is even the correct approach.) Could someone please explain how to make this argument more rigorous, or perhaps point out a better way? Thanks.","I just read about the construction of the real numbers in Enderton's Elements of Set Theory, and am now trying to go through all the exercises. Enderton chooses to construct the reals with left sides of Dedekind cuts. His definition is $y$ is a Dedekind cut if $\emptyset\neq y\neq\mathbb{Q}$, $y$ has no largest member, and $y$ is downward closed, i.e., $q\in y\wedge r<q\implies r\in y$. The following, question 19 of chapter 5 has me a bit baffled. Assume that $p$ is a positive rational number. Show that for any real number $x$ there is some rational $q$ in $x$ such that $p+q\not\in x$. I have this intuitive argument in my head. I guess I want to take $q\in x$, preferably closer to the right in $x$ on the rational line than not, and add it to $p$. If $p+q\not\in x$, then I am done. Otherwise, since $x$ has no greatest element, I can find $q'\in x$ such that $q'>q$, and add it to $p$ until I finally get a $q$ that pushes $p+q$ out of $x$, supposing of course that this process eventually ends. But this is horribly informal, and I have very little experience with analysis, and can't see a way to formalize it (if this is even the correct approach.) Could someone please explain how to make this argument more rigorous, or perhaps point out a better way? Thanks.",,"['real-analysis', 'elementary-set-theory']"
81,Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area,Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area,,"Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area. Hexagonal intersection means that every side of two intersecting triangles intersects two sides of another triangle, and all vertices of both triangles are not intersection points, as it is shown in picture below. We need to prove that blue area is positive for any number of triangles.","Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area. Hexagonal intersection means that every side of two intersecting triangles intersects two sides of another triangle, and all vertices of both triangles are not intersection points, as it is shown in picture below. We need to prove that blue area is positive for any number of triangles.",,"['geometry', 'elementary-set-theory', 'triangles']"
82,A constructive proof of this innocent set theoretic proposition?,A constructive proof of this innocent set theoretic proposition?,,"I was reading Freiwald's An Introduction to Set Theory and Topology , and I came across the following exercise from Chapter 1: E8. Suppose $A$ , $B$ , $C$ , and $D$ are sets with $A\ne\emptyset$ and $B\ne\emptyset$ . Show that if $$(A\times B)\cup (B\times A) = (C\times D)\cup(D\times C)\tag{1},$$ then either ( $A = C$ and $B = D$ ) or ( $A = D$ and $B = C$ ). I prove this by contradiction , analyzing the following cases: $\underline{a_0\in A\setminus C \text{ and } a_1\in A\setminus D}$ : Then due to nonemptiness of $B$ and Eq. (1), we get $a_0\in D$ and $a_1\in C$ . Thus, $(a_0, a_1)\in D\times C$ and again by using (1), we get that one of $a_0$ or $a_1$ , say $a_i$ , is in $B$ . Since $a_i\in A$ already, we have that $(a_i, a_i)\in A\times B$ so that by (1) again, we must have that $a_i\in C\cap D$ , a contradiction. $\underline{a_0\in A\setminus C \text{ and } d_0\in D\setminus A}$ : Then due to similar reasons as above, $d_0\in B$ so that $(a_0, d_0)\in A\times B$ . Since $a_0\notin C$ , we have $(a_0, d_0)\in D\times C$ so that $d_0\in C$ . But then $(d_0, d_0)\in C\times D$ so that by (1), $d_0\in A$ – false. $\underline{a_0\in A\setminus C \text{ and } b_0\in B\setminus C}$ : Then $(a_0, b_0)\in A\times B$ so that by (1), one of $a_0$ or $b_0$ must be in $C$ , again false. The rest of the cases are similar. Question: Now, this above uses Double Negation Elimination (DNE) to prove what is a very innocent-looking proposition, which, it feels like, must be provable constructively. Any insights on this?","I was reading Freiwald's An Introduction to Set Theory and Topology , and I came across the following exercise from Chapter 1: E8. Suppose , , , and are sets with and . Show that if then either ( and ) or ( and ). I prove this by contradiction , analyzing the following cases: : Then due to nonemptiness of and Eq. (1), we get and . Thus, and again by using (1), we get that one of or , say , is in . Since already, we have that so that by (1) again, we must have that , a contradiction. : Then due to similar reasons as above, so that . Since , we have so that . But then so that by (1), – false. : Then so that by (1), one of or must be in , again false. The rest of the cases are similar. Question: Now, this above uses Double Negation Elimination (DNE) to prove what is a very innocent-looking proposition, which, it feels like, must be provable constructively. Any insights on this?","A B C D A\ne\emptyset B\ne\emptyset (A\times B)\cup (B\times A) = (C\times D)\cup(D\times C)\tag{1}, A = C B = D A = D B = C \underline{a_0\in A\setminus C \text{ and } a_1\in A\setminus D} B a_0\in D a_1\in C (a_0, a_1)\in D\times C a_0 a_1 a_i B a_i\in A (a_i, a_i)\in A\times B a_i\in C\cap D \underline{a_0\in A\setminus C \text{ and } d_0\in D\setminus A} d_0\in B (a_0, d_0)\in A\times B a_0\notin C (a_0, d_0)\in D\times C d_0\in C (d_0, d_0)\in C\times D d_0\in A \underline{a_0\in A\setminus C \text{ and } b_0\in B\setminus C} (a_0, b_0)\in A\times B a_0 b_0 C","['elementary-set-theory', 'proof-writing', 'intuition', 'alternative-proof', 'constructive-mathematics']"
83,"Does the statement $\forall x \in \mathbb{R}, \det(x) = 0$ have a truth value?",Does the statement  have a truth value?,"\forall x \in \mathbb{R}, \det(x) = 0","I couldn't think of anything specific for the question title so I just used an illustrative example. Context I often encounter the scenario where I have a set $X$ of objects for which a property $P$ is defined. But then I often have to prove (as some trivial case) that for some $Y \subset X$ , $P(y)$ is true for all $y \in Y$ . But it turns out that Y is empty and so I thought the result holds vacuously. But then I started thinking about properties and vacuous truths and had some questions. I haven't studied formal mathematical logic and would appreciate an answer for the 'working' mathematician. Questions From my understanding, any property $P$ has to be defined for a particular set of objects and evaluates to true or false for the objects for which it is defined. For example, let $P(x)$ be the property that $\det(x) = 0$ . Then $P(x)$ would be undefined if $x$ is a real number since the determinant of a real number is undefined. Hence, a statement like $\forall x \in \mathbb{R}, P(x)$ does not have a truth value. Is this correct? But then are statements like $\forall x \in \emptyset, P(x)$ (where $P$ is any property) true (vacuously)? Are all properties automatically defined for the (nonexistent) elements of the empty set? I believe I just have some severe misunderstandings and would appreciate it if anyone could help me resolve them.","I couldn't think of anything specific for the question title so I just used an illustrative example. Context I often encounter the scenario where I have a set of objects for which a property is defined. But then I often have to prove (as some trivial case) that for some , is true for all . But it turns out that Y is empty and so I thought the result holds vacuously. But then I started thinking about properties and vacuous truths and had some questions. I haven't studied formal mathematical logic and would appreciate an answer for the 'working' mathematician. Questions From my understanding, any property has to be defined for a particular set of objects and evaluates to true or false for the objects for which it is defined. For example, let be the property that . Then would be undefined if is a real number since the determinant of a real number is undefined. Hence, a statement like does not have a truth value. Is this correct? But then are statements like (where is any property) true (vacuously)? Are all properties automatically defined for the (nonexistent) elements of the empty set? I believe I just have some severe misunderstandings and would appreciate it if anyone could help me resolve them.","X P Y \subset X P(y) y \in Y P P(x) \det(x) = 0 P(x) x \forall x \in \mathbb{R}, P(x) \forall x \in \emptyset, P(x) P","['elementary-set-theory', 'logic']"
84,unsure about logic in elementary set theory exercise Tao Analysis I 3.5.9,unsure about logic in elementary set theory exercise Tao Analysis I 3.5.9,,"This question is about the validity of a proof argument. I am asking because I am new to proofs. This question is not specifically about solving the exercise. The exercise is Tao Analysis I 4thed ex 3.5.9 Suppose that $I$ and $J$ are two sets, and for all $\alpha \in I$ let $A_{\alpha}$ be a set, and for all $\beta \in J$ let $B_{\beta}$ be a set. Show that $$(\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) = \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta})$$ What happens if one interchanges all the union and intersection symbols here? Note: I wanted to show this using a series of $\iff$ statements and not the more verbose proving both inclusions $\implies$ and $\impliedby$ . Let's start with the LHS. $$x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) \iff x \in (\bigcup_{\alpha \in I} A_{\alpha}) \land x \in (\bigcup_{\beta \in J} B_{\beta})$$ Using the definition of the union of sets, this means both of the following are true: $x$ is an element of at least one $A_{\alpha}$ , let's call one of them $A_{\alpha'}$ $x$ is an element of at least one $B_{\beta}$ , let's call one of them $B_{\beta'}$ This gives us $$\begin{align}x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) &\iff x \in A_{\alpha'} \land x \in B_{\beta'} \\ \\ & \iff x \in A_{\alpha'} \cap B_{\beta'} \\ \\ & \iff x \in \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta})\end{align}$$ Thus, we have shown $$(\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) = \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta}) \; \square$$ My Doubt 1 My doubts are in using the specific $A_{\alpha'}$ and $B_{\beta'}$ which we know exist . For example, consider the following: $$x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) \iff x \in A_{\alpha'} \land x \in B_{\beta'}$$ If the LHS is true we know there must exist an $A_{\alpha'}$ such that $x \in A_{\alpha'}$ , and similarly there must exist a $B_{\beta'}$ such that $x \in B_{\beta'}$ . Now consider the RHS $x \in A_{\alpha'} \land x \in B_{\beta'}$ . If this is true, then I would argue that the LHS is true because the argument "" $x \in P \implies x \in P \cup Q$ for any set $Q$ "" is generalisable as "" $x \in A_{\alpha'} \implies x \in \bigcup A_\alpha$ "". Am I right? My Doubt 2 My next doubt arises from the following statement: $$x \in A_{\alpha'} \cap B_{\beta'} \iff x \in \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta})$$ The nature of my doubt is the same as Doubt 1.","This question is about the validity of a proof argument. I am asking because I am new to proofs. This question is not specifically about solving the exercise. The exercise is Tao Analysis I 4thed ex 3.5.9 Suppose that and are two sets, and for all let be a set, and for all let be a set. Show that What happens if one interchanges all the union and intersection symbols here? Note: I wanted to show this using a series of statements and not the more verbose proving both inclusions and . Let's start with the LHS. Using the definition of the union of sets, this means both of the following are true: is an element of at least one , let's call one of them is an element of at least one , let's call one of them This gives us Thus, we have shown My Doubt 1 My doubts are in using the specific and which we know exist . For example, consider the following: If the LHS is true we know there must exist an such that , and similarly there must exist a such that . Now consider the RHS . If this is true, then I would argue that the LHS is true because the argument "" for any set "" is generalisable as "" "". Am I right? My Doubt 2 My next doubt arises from the following statement: The nature of my doubt is the same as Doubt 1.","I J \alpha \in I A_{\alpha} \beta \in J B_{\beta} (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) = \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta}) \iff \implies \impliedby x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) \iff x \in (\bigcup_{\alpha \in I} A_{\alpha}) \land x \in (\bigcup_{\beta \in J} B_{\beta}) x A_{\alpha} A_{\alpha'} x B_{\beta} B_{\beta'} \begin{align}x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) &\iff x \in A_{\alpha'} \land x \in B_{\beta'} \\ \\ & \iff x \in A_{\alpha'} \cap B_{\beta'} \\ \\ & \iff x \in \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta})\end{align} (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) = \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta}) \; \square A_{\alpha'} B_{\beta'} x \in (\bigcup_{\alpha \in I} A_{\alpha}) \cap (\bigcup_{\beta \in J} B_{\beta}) \iff x \in A_{\alpha'} \land x \in B_{\beta'} A_{\alpha'} x \in A_{\alpha'} B_{\beta'} x \in B_{\beta'} x \in A_{\alpha'} \land x \in B_{\beta'} x \in P \implies x \in P \cup Q Q x \in A_{\alpha'} \implies x \in \bigcup A_\alpha x \in A_{\alpha'} \cap B_{\beta'} \iff x \in \bigcup_{(\alpha,\beta) \in I \times J} (A_{\alpha} \cap B_{\beta})","['elementary-set-theory', 'solution-verification']"
85,"Set theory: how do I ""distribute"" overlapping sets?","Set theory: how do I ""distribute"" overlapping sets?",,"Let me preface by saying that I'm a software engineer; I'm neither a mathematician nor a logician in the academic sense. So I apologize if terms / symbols are not accurate for representing sets. EDIT: I agree with commenters that the original text I had was worded way too confusingly. I've boiled it down to what I think is the simplest example I can think of. Say I have this sequence/set: abcd , with each letter representing a distinct item. In the domain language I'm using, any item or groups of items can be extended. So, say I extend b with e . That means that we need to represent 2 new sequences: abcd and aecd , but a proper way to structure this would be a(b|e)cd with the group of items that will be distributed across sequences. If I were to extend cd with f , then the list would be a(b|e)(cd|f) as the smallest possible representation of this list, which represents all list combinations. So, let's start again with abcd . Given abcd , here is a list of extensions to be made, with the bracketed search (the ""find"") and => listing what it is extended with: [abc]d => h abc[d] => e ab[c]d => g ab[cd] => f Meaning: [abc] will be [abc] OR [h] -- represented as (abc|h)d [d] will be [d] OR [e] -- taking prev. as input, represented as (abc|h)(d|e) [c] will be [c] OR [g] -- (ab(c|g)|h)(d|e) [cd] will be [cd] OR [f] -- ??? I'm stumped as to how to determine the simplest representation of combinations of items for the last one. If I were to substitute the last item first, it would be ab(cd|f) , but once lists are overlapping, I'm unsure how to mathematically / algorithmically determine the smallest possible set representation. ORIGINAL QUESTION: To try to boil this problem down, I'm working on a stylesheet language. Let's say I have this set: { .one, .two, .three.four } (For the purpose of simplification, consider these strings, or arrays of strings i.e. it's represented more like: { '.one', '.two', ['.three', '.four'] } I can ""extend"" this set and represent it as nested sets. So, for example: Given the above, I can extend .four with .five , this creates the nested set: { .one, .two, .three{ .four, .five } } (with the actual data structure in memory being like { '.one', '.two', ['.three', { '.four', '.five' }] } Continuing on, given the result of the #1, I extend .three.four with .six . This creates the set { .one, .two, { .three{ .four, .five }, .six } } Continuing, I extend .three with .seven , and I the resulting set should be: { .one, .two, { { .three, .seven }{ .four, .five }, .six } } Now, the following is where my brain breaks. I want to extend {.one, .two, .three} with .eight . In other words, had I started with { .one, .two, .three } and I extended with .eight , the end result would be: { { .one, .two, .three }, .eight }. With the result from #2, however, I need to redistribute such that I end up with a set like: { .one, .two, { { .three, .seven }{ .four, .five }, .six}, { .eight{ { .four, .five } } } or { { .one, .two, .three }, .eight }{ { .three, .four }, { .one, .two, { { .six{ .four, .five }, .six } } So, I know what the possible results should be for the smallest grouping of distributed sets. Another way to phrase the problem (maybe this is simpler to demonstrate): Say I have a set  { abxy }. I want to extend { ab } with { c }, which would result in { abxy, cxy }. However, I want to represent this as the simplest set: { (ab|c)xy } Now, I want to extend { bx } with { d }. Again, if this were distributed, it would be { abxy, cxy, dy }. However, how do I algorithmically calculate the simplest set, and duplicate items that need to be distributed? I can represent this as { ((ab|c)x|d)y } as the simplest possible form, but then how do I extend { cx } with { e } or { xy } with { f } from that simple form? I hope one or both of those explanations make sense. Any help figuring this out algorithmically would be appreciated!","Let me preface by saying that I'm a software engineer; I'm neither a mathematician nor a logician in the academic sense. So I apologize if terms / symbols are not accurate for representing sets. EDIT: I agree with commenters that the original text I had was worded way too confusingly. I've boiled it down to what I think is the simplest example I can think of. Say I have this sequence/set: abcd , with each letter representing a distinct item. In the domain language I'm using, any item or groups of items can be extended. So, say I extend b with e . That means that we need to represent 2 new sequences: abcd and aecd , but a proper way to structure this would be a(b|e)cd with the group of items that will be distributed across sequences. If I were to extend cd with f , then the list would be a(b|e)(cd|f) as the smallest possible representation of this list, which represents all list combinations. So, let's start again with abcd . Given abcd , here is a list of extensions to be made, with the bracketed search (the ""find"") and => listing what it is extended with: [abc]d => h abc[d] => e ab[c]d => g ab[cd] => f Meaning: [abc] will be [abc] OR [h] -- represented as (abc|h)d [d] will be [d] OR [e] -- taking prev. as input, represented as (abc|h)(d|e) [c] will be [c] OR [g] -- (ab(c|g)|h)(d|e) [cd] will be [cd] OR [f] -- ??? I'm stumped as to how to determine the simplest representation of combinations of items for the last one. If I were to substitute the last item first, it would be ab(cd|f) , but once lists are overlapping, I'm unsure how to mathematically / algorithmically determine the smallest possible set representation. ORIGINAL QUESTION: To try to boil this problem down, I'm working on a stylesheet language. Let's say I have this set: { .one, .two, .three.four } (For the purpose of simplification, consider these strings, or arrays of strings i.e. it's represented more like: { '.one', '.two', ['.three', '.four'] } I can ""extend"" this set and represent it as nested sets. So, for example: Given the above, I can extend .four with .five , this creates the nested set: { .one, .two, .three{ .four, .five } } (with the actual data structure in memory being like { '.one', '.two', ['.three', { '.four', '.five' }] } Continuing on, given the result of the #1, I extend .three.four with .six . This creates the set { .one, .two, { .three{ .four, .five }, .six } } Continuing, I extend .three with .seven , and I the resulting set should be: { .one, .two, { { .three, .seven }{ .four, .five }, .six } } Now, the following is where my brain breaks. I want to extend {.one, .two, .three} with .eight . In other words, had I started with { .one, .two, .three } and I extended with .eight , the end result would be: { { .one, .two, .three }, .eight }. With the result from #2, however, I need to redistribute such that I end up with a set like: { .one, .two, { { .three, .seven }{ .four, .five }, .six}, { .eight{ { .four, .five } } } or { { .one, .two, .three }, .eight }{ { .three, .four }, { .one, .two, { { .six{ .four, .five }, .six } } So, I know what the possible results should be for the smallest grouping of distributed sets. Another way to phrase the problem (maybe this is simpler to demonstrate): Say I have a set  { abxy }. I want to extend { ab } with { c }, which would result in { abxy, cxy }. However, I want to represent this as the simplest set: { (ab|c)xy } Now, I want to extend { bx } with { d }. Again, if this were distributed, it would be { abxy, cxy, dy }. However, how do I algorithmically calculate the simplest set, and duplicate items that need to be distributed? I can represent this as { ((ab|c)x|d)y } as the simplest possible form, but then how do I extend { cx } with { e } or { xy } with { f } from that simple form? I hope one or both of those explanations make sense. Any help figuring this out algorithmically would be appreciated!",,"['elementary-set-theory', 'set-theory']"
86,"Solving a Set Theory Problem Involving Intersections, Unions, and Complements","Solving a Set Theory Problem Involving Intersections, Unions, and Complements",,"I'm struggling with a particular set theory question and would greatly appreciate some guidance. The problem is as follows: Let $A=\{1,2,5,6,7\}$ , $B=\{0,4,6,7,9\}$ , and $C=\{0,1,2,6,7,9\}$ be subsets of $S=\{0,1,\ldots,9\}$ . I need to determine which subsets $X$ of $S$ satisfy the equation $$ (A \cap X) \cup (B \cap X^c) = C. $$ Here, $X^c$ denotes the complement of $X$ within the universal set $S$ . I understand that $A \cap X$ refers to elements common to both $A$ and $X$ , and $B \cap X^c$ includes elements in $B$ but not in $X$ , with their union needing to equal $C$ . However, I'm having trouble figuring out how to approach finding all possible subsets $X$ that meet this criterion. Could someone please explain a step-by-step method to solve this problem? If there are any specific theorems or concepts that could simplify the process, I'd love to learn about those as well. I'm familiar with basic set theory operations like unions, intersections, and complements but applying them in this context has been challenging for me.","I'm struggling with a particular set theory question and would greatly appreciate some guidance. The problem is as follows: Let , , and be subsets of . I need to determine which subsets of satisfy the equation Here, denotes the complement of within the universal set . I understand that refers to elements common to both and , and includes elements in but not in , with their union needing to equal . However, I'm having trouble figuring out how to approach finding all possible subsets that meet this criterion. Could someone please explain a step-by-step method to solve this problem? If there are any specific theorems or concepts that could simplify the process, I'd love to learn about those as well. I'm familiar with basic set theory operations like unions, intersections, and complements but applying them in this context has been challenging for me.","A=\{1,2,5,6,7\} B=\{0,4,6,7,9\} C=\{0,1,2,6,7,9\} S=\{0,1,\ldots,9\} X S  (A \cap X) \cup (B \cap X^c) = C.  X^c X S A \cap X A X B \cap X^c B X C X","['elementary-set-theory', 'problem-solving']"
87,"Is the statement ""A set is closed if and only if it contains all of its limit points"" vacuously true for a singleton?","Is the statement ""A set is closed if and only if it contains all of its limit points"" vacuously true for a singleton?",,"I have come across the statement: ""A set is closed if and only if it contains all of its limit points"". on MSE. The limit point (in my understanding) of a set $P\subset X$ is a point $p\in X$ whose every neighborhood contains a point in $P$ other than $p$ itself. With this definition the singleton, $\{p\}$ , has no limit points. Singletons are closed (in the usual topology in $\mathbb{R}$ . Why is this not a contradiction?","I have come across the statement: ""A set is closed if and only if it contains all of its limit points"". on MSE. The limit point (in my understanding) of a set is a point whose every neighborhood contains a point in other than itself. With this definition the singleton, , has no limit points. Singletons are closed (in the usual topology in . Why is this not a contradiction?",P\subset X p\in X P p \{p\} \mathbb{R},"['real-analysis', 'elementary-set-theory']"
88,Let $∼$ be a relation on $\mathbb{R}$ and $x ∼ y \iff x=y$ or $x+y=6$. [closed],Let  be a relation on  and  or . [closed],∼ \mathbb{R} x ∼ y \iff x=y x+y=6,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 months ago . Improve this question Let $∼$ be a relation on $\mathbb{R}$ and $x ∼ y \iff x=y$ or $x+y=6$ . I proved that $∼$ is an equivalence relation. Now I have to find a complete set of representatives. I know that $[a]_∼ := \{b \in \mathbb{R} \mid b ∼ a\}$ , but I don't know how to use this to find a CSR.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 months ago . Improve this question Let be a relation on and or . I proved that is an equivalence relation. Now I have to find a complete set of representatives. I know that , but I don't know how to use this to find a CSR.",∼ \mathbb{R} x ∼ y \iff x=y x+y=6 ∼ [a]_∼ := \{b \in \mathbb{R} \mid b ∼ a\},"['elementary-set-theory', 'equivalence-relations']"
89,Simplifying $(A^c\setminus B^c)^c\cap (A\cup B)$,Simplifying,(A^c\setminus B^c)^c\cap (A\cup B),"How can we simplify the following set-theoretical expression? $$(A^c\setminus B^c)^c\cap (A\cup B)$$ Where $A, B\neq \emptyset$ and $A, B\subset E$ . Let $x\in (A^c\setminus B^c)^c\cap (A\cup B)$ , so $x\in (A^c\setminus B^c)^c$ and $x\in (A\cup B)$ . $$(A^c\setminus B^c)^c = (A^c\cap B)^c$$ Therefore $x\notin A^c, B$ , and so $x\in A, B^c$ . Thus, $$(A^c\setminus B^c)^c\cap (A\cup B) = A\cap B^c$$","How can we simplify the following set-theoretical expression? Where and . Let , so and . Therefore , and so . Thus,","(A^c\setminus B^c)^c\cap (A\cup B) A, B\neq \emptyset A, B\subset E x\in (A^c\setminus B^c)^c\cap (A\cup B) x\in (A^c\setminus B^c)^c x\in (A\cup B) (A^c\setminus B^c)^c = (A^c\cap B)^c x\notin A^c, B x\in A, B^c (A^c\setminus B^c)^c\cap (A\cup B) = A\cap B^c",[]
90,Enemy of an enemy relation,Enemy of an enemy relation,,"I'm going through the book ""How to prove it"" by Velleman and I have come across the following question: ""Let E = {(p, q) ∈ P × P | the person p is an enemy of the person q}, and F = {(p, q) ∈ P × P | the person p is a friend of the person q}, where P is the set of all people. What does the saying ""an enemy of one’s enemy is one’s friend"" mean about the relations E and F?"" In attempting to solve this problem I let E be the set {(J, M), (B, M)}. Where J, M and B are people named John, Bill and Mark. I assume this would then mean that E -1 ∘ E = F. But the answer key gives a different solution: E ∘ E ⊆ F (answer key) While I agree that a subset of F is correct (one can have friends that are not enemies of enemies). I find the choice of E ∘ E peculiar, after some further reasoning this only seems to be true if both the pairs (J, M) and (M, J) are included. But it's certainly possible to be one's enemy without that being the opposite way around unless I am misunderstanding something here? Any input is appreciated.","I'm going through the book ""How to prove it"" by Velleman and I have come across the following question: ""Let E = {(p, q) ∈ P × P | the person p is an enemy of the person q}, and F = {(p, q) ∈ P × P | the person p is a friend of the person q}, where P is the set of all people. What does the saying ""an enemy of one’s enemy is one’s friend"" mean about the relations E and F?"" In attempting to solve this problem I let E be the set {(J, M), (B, M)}. Where J, M and B are people named John, Bill and Mark. I assume this would then mean that E -1 ∘ E = F. But the answer key gives a different solution: E ∘ E ⊆ F (answer key) While I agree that a subset of F is correct (one can have friends that are not enemies of enemies). I find the choice of E ∘ E peculiar, after some further reasoning this only seems to be true if both the pairs (J, M) and (M, J) are included. But it's certainly possible to be one's enemy without that being the opposite way around unless I am misunderstanding something here? Any input is appreciated.",,"['elementary-set-theory', 'relations', 'function-and-relation-composition']"
91,Non-natural dimension of sets,Non-natural dimension of sets,,"This question is not for an exercise or a task, but just mathematical curiosity: In Mathematics we are used to work with sets such as $\mathbb{Z}$ , $\mathbb{Q}$ , etc. However, we also use their ""powers"" provided by the cartesian product ( $\mathbb{R}^n$ for example). However, I wonder if somebody knows whether it is possible to define ""non-natural"" ""powers"" of this sets, or of any set apart from the usual ones, the same as with the set of real numbers, where exponentiation can be extended to any number like for example, $2^\pi$ or $3^{5.43}$ . Is it possible to define stuff like $\mathbb{R}^{\frac{2}{5}}$ , $\mathbb{Q}^\pi$ or $[0,1]^{\frac{\sqrt{2}}{3}}$ ? Does it makes sense? Has anybody thought about it before? Not only that, but if they exist, is it possible to equip these sets with an operation to create an algebraic structure? As a lover and still student of algebraic structures, it would be great for me that groups like $(\mathbb{R}^{\pi},+)$ could be created, or even more. Postdata: I don't know which tags use for this question, so please don't downvote just for this.","This question is not for an exercise or a task, but just mathematical curiosity: In Mathematics we are used to work with sets such as , , etc. However, we also use their ""powers"" provided by the cartesian product ( for example). However, I wonder if somebody knows whether it is possible to define ""non-natural"" ""powers"" of this sets, or of any set apart from the usual ones, the same as with the set of real numbers, where exponentiation can be extended to any number like for example, or . Is it possible to define stuff like , or ? Does it makes sense? Has anybody thought about it before? Not only that, but if they exist, is it possible to equip these sets with an operation to create an algebraic structure? As a lover and still student of algebraic structures, it would be great for me that groups like could be created, or even more. Postdata: I don't know which tags use for this question, so please don't downvote just for this.","\mathbb{Z} \mathbb{Q} \mathbb{R}^n 2^\pi 3^{5.43} \mathbb{R}^{\frac{2}{5}} \mathbb{Q}^\pi [0,1]^{\frac{\sqrt{2}}{3}} (\mathbb{R}^{\pi},+)","['group-theory', 'elementary-set-theory', 'exponentiation']"
92,"When $|A|<|B|$ and the function $f: A \to B$ is injective, how do we define the inverse function $g$, with or without the extra elements in $B$?","When  and the function  is injective, how do we define the inverse function , with or without the extra elements in ?",|A|<|B| f: A \to B g B,"I need help to understand this elementary part in the set theory. We all have seen the diagram of an injective mapping where few elements of the range set has no pre-image in the domain. My reasoning gets stuck when I think about how can I define the inverse function $g : B \to A$ , where $A, B$ are sets with $|A|=n, |B|=n+2$ and there exists an injective mapping $f: A \to B$ , such that each elements of $A$ gets mapped to exactly one element of the set $B$ . Clearly set $B$ has extra two elements. Since $f$ is injective, then $g$ has to be injective. But my doubts are:- $a$ • when we construct the inverse function $g: B \to A$ , then do we include those two un-mapped elements for mapping? $b$ • Is there any difference between these terms $\textrm{not mapping two elements of the domain to the range set}$ and $\textrm{two elements in the domain do not have images in the range set}$ ? $c$ • From the image it is clear that in case of injective mapping there can be elements in the range set who have no pre-image. But can we say that in case of inverse injective mapping some elements in domain (here set $B$ ) may have no image in the range set ( here set $A$ )? If yes, doesn't it contradict the definition of a function? Also my reasoning in case of constructing the inversion function $g$ in such cases is that the function should look like $g: B \setminus 2 \to A$ , to keep the one-one format, but that is not same as $g : B \to A$ . Therefore I request to help me to clear my doubts here. Any response, answer, hints and suggestions are valuable and appreciated. Thanks to everyone for suggesting links, notes and the answer.","I need help to understand this elementary part in the set theory. We all have seen the diagram of an injective mapping where few elements of the range set has no pre-image in the domain. My reasoning gets stuck when I think about how can I define the inverse function , where are sets with and there exists an injective mapping , such that each elements of gets mapped to exactly one element of the set . Clearly set has extra two elements. Since is injective, then has to be injective. But my doubts are:- • when we construct the inverse function , then do we include those two un-mapped elements for mapping? • Is there any difference between these terms and ? • From the image it is clear that in case of injective mapping there can be elements in the range set who have no pre-image. But can we say that in case of inverse injective mapping some elements in domain (here set ) may have no image in the range set ( here set )? If yes, doesn't it contradict the definition of a function? Also my reasoning in case of constructing the inversion function in such cases is that the function should look like , to keep the one-one format, but that is not same as . Therefore I request to help me to clear my doubts here. Any response, answer, hints and suggestions are valuable and appreciated. Thanks to everyone for suggesting links, notes and the answer.","g : B \to A A, B |A|=n, |B|=n+2 f: A \to B A B B f g a g: B \to A b \textrm{not mapping two elements of the domain to the range set} \textrm{two elements in the domain do not have images in the range set} c B A g g: B \setminus 2 \to A g : B \to A",['elementary-set-theory']
93,"Derived set of subset $A$ of metric space $(X,d)$ is a closed set",Derived set of subset  of metric space  is a closed set,"A (X,d)","I have to prove that derived set of subset $A$ of metric space $(X,d)$ is a closed set. And here is my attempt: it is sufficient to prove $\overline{A^{'}}=A^{'}$ , and it is equivalent to prove $(A^{'})^{'}\subset A^{'}$ .Suppose $A$ is infinite. (if $A$ is finite, $A^{'}$ is empty, it's closed. )So, $\forall x\in A^{'}, \exists  p_n\in A^{'}$ s.t. $p_n\rightarrow x$ . If $A^{'}$ is finite, it is closed. If $A^{'}$ is infinite, we have $\forall y\in (A^{'})^{'}, \exists  x_n\in A^{'}$ s.t. $x_n\rightarrow y$ .Now, I need to prove $\forall y\in (A^{'})^{'} \exists p_n\in A$ s.t. $p_n\rightarrow y$ , which means every point of $(A^{'})^{'}$ is a limit point of $A$ , i.e. $(A^{'})^{'}\subset A^{'}$ . Fix $y\in(A^{'})^{'}$ , then we have $x_n(\in A^{'})\rightarrow y$ , and for each $x_n$ , we have $p_n^m(\in A)\rightarrow x_n$ , for each n, there exists $p_n^k$ s.t. $d(p_n^k,x_n)<\frac{1}{n}$ , let $b_n=p_n^k$ , then we have $b_n\rightarrow y$ , and $y$ is arbitrary, thus $(A^{'})^{'}\subset A^{'}$ . I have 3 questions. 1.Is my proof correct? 2.If my proof is correct, can we use this method to prove the same property in Hausdorff space, we don't have something like ""distance"" in Hausdorff space, so I don't know how to select an element from $p_n^m$ . 3.In my attempt, I find a subsequence $p_1^{k(1)},p_2^{k(2)}...$ .And we can do the same thing in $\mathbb{R}$ . If we have countable subset of $\mathbb{R}$ , $A_{1}, A_{2},...,A_{n}...$ , and for each $n$ , $A_{n}$ is countable too, in other words, it is sequence, denoted as $A_{n}=\{a_{n1},a_{n2},a_{n3}...a_{nm}...\}$ , suppose for each n, the sequence $a_{nm}$ is converge to $b_n$ , now we have sequence $b_n$ , and suppose $b_n$ is converge to $y$ , like we did above, we can select $c_1\in A_1,c_2\in A_2...c_n\in A_n...$ , then sequence $c_n$ is converge to $y$ . We know the countable union of countable set is also countable, in this sense, $\bigcup\limits_{i=1}^{\infty}A_i$ is also a sequence $T_n$ , so we can say there is a subsequence of $T_n$ converge to $y$ . Is it true for sequence $T_n$ ? I guess it is related to the arrangement of $T_n$ , for the arrangement of the set of rational numbers, it's false, however, I just know one arrangement of the countable union of countable set, it is the same as set of rational numbers. Do we have any other arrangement of these two sets? Especially, do we have a special arrangement makes proposition always true? Thanks!","I have to prove that derived set of subset of metric space is a closed set. And here is my attempt: it is sufficient to prove , and it is equivalent to prove .Suppose is infinite. (if is finite, is empty, it's closed. )So, s.t. . If is finite, it is closed. If is infinite, we have s.t. .Now, I need to prove s.t. , which means every point of is a limit point of , i.e. . Fix , then we have , and for each , we have , for each n, there exists s.t. , let , then we have , and is arbitrary, thus . I have 3 questions. 1.Is my proof correct? 2.If my proof is correct, can we use this method to prove the same property in Hausdorff space, we don't have something like ""distance"" in Hausdorff space, so I don't know how to select an element from . 3.In my attempt, I find a subsequence .And we can do the same thing in . If we have countable subset of , , and for each , is countable too, in other words, it is sequence, denoted as , suppose for each n, the sequence is converge to , now we have sequence , and suppose is converge to , like we did above, we can select , then sequence is converge to . We know the countable union of countable set is also countable, in this sense, is also a sequence , so we can say there is a subsequence of converge to . Is it true for sequence ? I guess it is related to the arrangement of , for the arrangement of the set of rational numbers, it's false, however, I just know one arrangement of the countable union of countable set, it is the same as set of rational numbers. Do we have any other arrangement of these two sets? Especially, do we have a special arrangement makes proposition always true? Thanks!","A (X,d) \overline{A^{'}}=A^{'} (A^{'})^{'}\subset A^{'} A A A^{'} \forall x\in A^{'}, \exists  p_n\in A^{'} p_n\rightarrow x A^{'} A^{'} \forall y\in (A^{'})^{'}, \exists  x_n\in A^{'} x_n\rightarrow y \forall y\in (A^{'})^{'} \exists p_n\in A p_n\rightarrow y (A^{'})^{'} A (A^{'})^{'}\subset A^{'} y\in(A^{'})^{'} x_n(\in A^{'})\rightarrow y x_n p_n^m(\in A)\rightarrow x_n p_n^k d(p_n^k,x_n)<\frac{1}{n} b_n=p_n^k b_n\rightarrow y y (A^{'})^{'}\subset A^{'} p_n^m p_1^{k(1)},p_2^{k(2)}... \mathbb{R} \mathbb{R} A_{1}, A_{2},...,A_{n}... n A_{n} A_{n}=\{a_{n1},a_{n2},a_{n3}...a_{nm}...\} a_{nm} b_n b_n b_n y c_1\in A_1,c_2\in A_2...c_n\in A_n... c_n y \bigcup\limits_{i=1}^{\infty}A_i T_n T_n y T_n T_n","['general-topology', 'elementary-set-theory', 'solution-verification']"
94,Well-ordering of natural numbers from axioms of real numbers,Well-ordering of natural numbers from axioms of real numbers,,"Let $(\mathbb R,+,\times,<)$ be an ordered field that is Dedekind complete. Let $\mathbb N$ be the intersection of all additive submonoids $M \subseteq \mathbb R$ with $1 \in M$ . The question is, can we prove that every subset of $\mathbb N$ has a least element (i.e. well-ordering principle)? If not, can we ""construct"" a model of $\mathbb R$ such that $\mathbb N$ does not have the well-ordering principle (apologize for the language as I am not a model theorist)? This is inspired by the answer https://math.stackexchange.com/a/2214227/553409 , although I don't think Proposition 3 in the cited answer works. In particular, elements of $\mathbb N$ may get arbitrarily closed to each other. [1]: https://math.stackexchange.com/a/2214227/553409","Let be an ordered field that is Dedekind complete. Let be the intersection of all additive submonoids with . The question is, can we prove that every subset of has a least element (i.e. well-ordering principle)? If not, can we ""construct"" a model of such that does not have the well-ordering principle (apologize for the language as I am not a model theorist)? This is inspired by the answer https://math.stackexchange.com/a/2214227/553409 , although I don't think Proposition 3 in the cited answer works. In particular, elements of may get arbitrarily closed to each other. [1]: https://math.stackexchange.com/a/2214227/553409","(\mathbb R,+,\times,<) \mathbb N M \subseteq \mathbb R 1 \in M \mathbb N \mathbb R \mathbb N \mathbb N","['real-analysis', 'elementary-set-theory']"
95,Uncountable set of different sized infinities,Uncountable set of different sized infinities,,"Using Cantor's Theorem is is easy to see that $s=$ { $ \mathbb{N}, \mathcal{P}(\mathbb{N}), \mathcal{P}(\mathcal{P}(\mathbb{N})), \mathcal{P}(\mathcal{P}(\mathcal{P}(\mathbb{N}))), ...$ } is a countable set of ""different sized infinities."" However, I am interested in constructing an uncountable set of different sized infinities. More precisely, I want to find a set $S$ such that $$\text{card}(\mathbb{N})<\text{card}(S)$$ and for all $s_1, s_2 \in S$ such that $s_1 \neq s_2$ $$\text{card}(s_1)<\text{card}(s_2) \text{ or } \text{card}(s_2)<\text{card}(s_1).$$ Is this possible to construct $S$ with ZFC?","Using Cantor's Theorem is is easy to see that { } is a countable set of ""different sized infinities."" However, I am interested in constructing an uncountable set of different sized infinities. More precisely, I want to find a set such that and for all such that Is this possible to construct with ZFC?","s=  \mathbb{N}, \mathcal{P}(\mathbb{N}), \mathcal{P}(\mathcal{P}(\mathbb{N})), \mathcal{P}(\mathcal{P}(\mathcal{P}(\mathbb{N}))), ... S \text{card}(\mathbb{N})<\text{card}(S) s_1, s_2 \in S s_1 \neq s_2 \text{card}(s_1)<\text{card}(s_2) \text{ or } \text{card}(s_2)<\text{card}(s_1). S",['elementary-set-theory']
96,Is 2d space a subset of 3d?,Is 2d space a subset of 3d?,,"I’m working on some exercises on sets. One of the tasks asked if $R^2 \subseteq R^3$ So talking in terms of sets, it’s false (which is confirmed by the book), since $R^2$ is a set of pairs and $R^3$ is a set of triplets. When I’m thinking in a bit more natural way, I see $R^3$ as an infinite stack of $R^2$ . I’m not sure if I can write it like that, but to some extent I feel like I could define it as $R^3 = \{(R^2, z) : z \in R\}$ I can’t seem to see the logical error in the latter. Any help?","I’m working on some exercises on sets. One of the tasks asked if So talking in terms of sets, it’s false (which is confirmed by the book), since is a set of pairs and is a set of triplets. When I’m thinking in a bit more natural way, I see as an infinite stack of . I’m not sure if I can write it like that, but to some extent I feel like I could define it as I can’t seem to see the logical error in the latter. Any help?","R^2 \subseteq R^3 R^2 R^3 R^3 R^2 R^3 = \{(R^2, z) : z \in R\}",['elementary-set-theory']
97,"Number of subsets $\{1, 2, \dots, n\}$ without numbers with forbidden differences.",Number of subsets  without numbers with forbidden differences.,"\{1, 2, \dots, n\}","Let $S = \{1, 2, \dots, n\}$ . Let $R = \{r_1, r_2, \dots, r_m\}$ be a set of forbidden differences. How many subsets of $S$ don't have two numbers the difference of which belongs to $R$ ? I have found that recursive approach helps to solve some cases. For example let's start with $R = \{1, 2\}$ . Then let $a_n$ be a number of these subsets of $\{1, 2, \dots, n\}$ . Let $A$ be a subset with given conditions. We begin by looking at some cases: $n \in A$ , then $n-1 \not\in A$ and $n-2 \not \in A$ , so $a_n = a_{n-3}$ $n\not\in A$ , then $a_n = a_{n-1}$ So $a_n = a_{n-1} + a_{n-3}$ . Similarly if $R = \{1, \dots, m\}$ then $a_n = a_{n-1} + a_{n-m-1}$ . Let then $R = \{2\}$ . Again some cases: $n \in A, n-1 \in A$ . Then $n-2 \not\in A$ and $n-3 \not\in A$ , $a_n = a_{n-4}$ . $n \in A, n-1 \not\in A$ . Then $n-2 \not\in A$ so $a_n = a_{n-3}$ . Finally if $n \not\in A$ $a_n = a_{n-1}$ This way $a_n = a_{n-1} + a_{n-3} + a_{n-4}$ . However I struggle to find a recurrence for $R = \{m\}$ and generalize solution to any set of $R$ .","Let . Let be a set of forbidden differences. How many subsets of don't have two numbers the difference of which belongs to ? I have found that recursive approach helps to solve some cases. For example let's start with . Then let be a number of these subsets of . Let be a subset with given conditions. We begin by looking at some cases: , then and , so , then So . Similarly if then . Let then . Again some cases: . Then and , . . Then so . Finally if This way . However I struggle to find a recurrence for and generalize solution to any set of .","S = \{1, 2, \dots, n\} R = \{r_1, r_2, \dots, r_m\} S R R = \{1, 2\} a_n \{1, 2, \dots, n\} A n \in A n-1 \not\in A n-2 \not \in A a_n = a_{n-3} n\not\in A a_n = a_{n-1} a_n = a_{n-1} + a_{n-3} R = \{1, \dots, m\} a_n = a_{n-1} + a_{n-m-1} R = \{2\} n \in A, n-1 \in A n-2 \not\in A n-3 \not\in A a_n = a_{n-4} n \in A, n-1 \not\in A n-2 \not\in A a_n = a_{n-3} n \not\in A a_n = a_{n-1} a_n = a_{n-1} + a_{n-3} + a_{n-4} R = \{m\} R","['combinatorics', 'elementary-set-theory', 'recurrence-relations']"
98,"Given $p\in[0,1]$ form a set $\Omega$ and a function $f$ such that $\{f = 1\} = p$ and $\{f = 0\} = 1-p$",Given  form a set  and a function  such that  and,"p\in[0,1] \Omega f \{f = 1\} = p \{f = 0\} = 1-p","Given $p\in[0,1]$ is it always possible to form a set $\Omega$ and a function $f$ such that the expressions below are true? $$ \begin{align}     \frac{|\{\omega\in\Omega\,:\, f(\omega) = 1\}|}{|\Omega|} &= p \\     \frac{|\{\omega\in\Omega\,:\, f(\omega) = 0\}|}{|\Omega|} &= 1-p \end{align} $$ Ideally, I would like $\Omega$ to always be finite, but I recon this could be difficult when $p$ is irrational, althogh the fact that one can choose $f$ might actually make this possible. Context I am trying to write down a detailed definition of a Bernoulli random variable and of its distribution using measure theory. I am working ""backwards"" from the distribution, to figure out all the measurable spaces and functions involved. Bernoulli Distribution : Discrete Probability Measure : Here's the definition of a discrete measure. Let $(\mathsf{E}, \Sigma_\mathsf{E})$ be any measurable space, let $\mathsf{D}\subset\mathsf{E}$ be a countable subset of $\mathsf{E}$ . For any $x\in\mathsf{D}$ let $m(x)$ be a positive number, such that $\sum_{x\in\mathsf{D}} m(x) = 1$ . Then $$ \eta(\mathsf{A}) = \sum_{x\in\mathsf{D}} m(x) \delta_x(\mathsf{A}) \qquad \mathsf{A}\in\Sigma_\mathsf{E} $$ is a valid probability measure, and we call all distributions of this form discrete probability measures. Bernoulli Distribution : This makes me believe that the Bernoulli distribution, for $p\in[0, 1]$ is defined as $\text{Ber}_p:\Sigma_\mathsf{E}\to\{p, 1-p\}$ $$ \text{Ber}_p(\mathsf{A}) = \sum_{x\in\{0, 1\}} p^x (1 - p)^{1-x}\delta_x(\mathsf{A}) $$ for any measurable set $\mathsf{A}$ . The challenge is understanding what sigma algebra these sets come from, i.e. what is $(\mathsf{E}, \Sigma_\mathsf{E})$ in this case? By definition $\{0, 1\}\subset\mathsf{E}$ , but there are infinitely many such sets, so one has to choose a sensible one. Counting Measure : To try and figure out $(\mathsf{E}, \Sigma_\mathsf{E})$ I tried to think about a dominating measure on the same space. The classical dominating measure is the counting measure $$ d\text{count}(\mathsf{A}) = \begin{cases}     \text{number of elements in } \mathsf{A} & \text{ if } \mathsf{A} \text{ is finite.} \\     \infty & \text{ if } \mathsf{A} \text{ if infinite.}. \end{cases} $$ This doesn't tell us what $(\mathsf{E}, \Sigma_\mathsf{E})$ is though. Bernoulli Random Variable : To try and figure this out, I tried thinking about the Bernoulli random variable $X$ that has $\text{Ber}_p$ as its distribution. Of course, the random variable must take values in $\{0, 1\}$ , but the domain of this random variable is unclear to me. However, by definition, if $\text{Ber}_p$ is the distribution of a random variable, there must exist another probability space $(\Omega, \Sigma_\Omega, \lambda)$ such that $$ \text{Ber}_p = \lambda\circ X^{-1} $$ These two things combine tell me that $(\mathsf{E}, \Sigma_\mathsf{E}) = (\{0, 1\}, 2^{\{0, 1\}})$ , where $2^{\{0, 1\}}$ is the power set of $\{0, 1\}$ , since we know the values that $X$ takes. However, I now need to figure out $(\Omega, \Sigma_\Omega, \lambda)$ . My guess is that $\lambda$ is the counting measure on some countable measurable set. Then, I tried to guess that given $p\in[0, 1]$ one would construct $\Omega$ and $X$ so that the expressions in the original question hold.","Given is it always possible to form a set and a function such that the expressions below are true? Ideally, I would like to always be finite, but I recon this could be difficult when is irrational, althogh the fact that one can choose might actually make this possible. Context I am trying to write down a detailed definition of a Bernoulli random variable and of its distribution using measure theory. I am working ""backwards"" from the distribution, to figure out all the measurable spaces and functions involved. Bernoulli Distribution : Discrete Probability Measure : Here's the definition of a discrete measure. Let be any measurable space, let be a countable subset of . For any let be a positive number, such that . Then is a valid probability measure, and we call all distributions of this form discrete probability measures. Bernoulli Distribution : This makes me believe that the Bernoulli distribution, for is defined as for any measurable set . The challenge is understanding what sigma algebra these sets come from, i.e. what is in this case? By definition , but there are infinitely many such sets, so one has to choose a sensible one. Counting Measure : To try and figure out I tried to think about a dominating measure on the same space. The classical dominating measure is the counting measure This doesn't tell us what is though. Bernoulli Random Variable : To try and figure this out, I tried thinking about the Bernoulli random variable that has as its distribution. Of course, the random variable must take values in , but the domain of this random variable is unclear to me. However, by definition, if is the distribution of a random variable, there must exist another probability space such that These two things combine tell me that , where is the power set of , since we know the values that takes. However, I now need to figure out . My guess is that is the counting measure on some countable measurable set. Then, I tried to guess that given one would construct and so that the expressions in the original question hold.","p\in[0,1] \Omega f 
\begin{align}
    \frac{|\{\omega\in\Omega\,:\, f(\omega) = 1\}|}{|\Omega|} &= p \\
    \frac{|\{\omega\in\Omega\,:\, f(\omega) = 0\}|}{|\Omega|} &= 1-p
\end{align}
 \Omega p f (\mathsf{E}, \Sigma_\mathsf{E}) \mathsf{D}\subset\mathsf{E} \mathsf{E} x\in\mathsf{D} m(x) \sum_{x\in\mathsf{D}} m(x) = 1 
\eta(\mathsf{A}) = \sum_{x\in\mathsf{D}} m(x) \delta_x(\mathsf{A}) \qquad \mathsf{A}\in\Sigma_\mathsf{E}
 p\in[0, 1] \text{Ber}_p:\Sigma_\mathsf{E}\to\{p, 1-p\} 
\text{Ber}_p(\mathsf{A}) = \sum_{x\in\{0, 1\}} p^x (1 - p)^{1-x}\delta_x(\mathsf{A})
 \mathsf{A} (\mathsf{E}, \Sigma_\mathsf{E}) \{0, 1\}\subset\mathsf{E} (\mathsf{E}, \Sigma_\mathsf{E}) 
d\text{count}(\mathsf{A}) = \begin{cases}
    \text{number of elements in } \mathsf{A} & \text{ if } \mathsf{A} \text{ is finite.} \\
    \infty & \text{ if } \mathsf{A} \text{ if infinite.}.
\end{cases}
 (\mathsf{E}, \Sigma_\mathsf{E}) X \text{Ber}_p \{0, 1\} \text{Ber}_p (\Omega, \Sigma_\Omega, \lambda) 
\text{Ber}_p = \lambda\circ X^{-1}
 (\mathsf{E}, \Sigma_\mathsf{E}) = (\{0, 1\}, 2^{\{0, 1\}}) 2^{\{0, 1\}} \{0, 1\} X (\Omega, \Sigma_\Omega, \lambda) \lambda p\in[0, 1] \Omega X","['calculus', 'algebra-precalculus', 'elementary-set-theory', 'set-theory', 'descriptive-set-theory']"
99,Prove $\mathcal T∘\mathcal R=\mathcal T∘\mathcal S$ for any $\mathcal T$ iff $\mathcal R∘\mathcal T=\mathcal S∘\mathcal T$ for any $\mathcal T$.,Prove  for any  iff  for any .,\mathcal T∘\mathcal R=\mathcal T∘\mathcal S \mathcal T \mathcal R∘\mathcal T=\mathcal S∘\mathcal T \mathcal T,"I am trying to understand if for two binary relations $\mathcal R$ and $\mathcal S$ the following statements are equivalent. $\mathcal R=\mathcal S$ $\mathcal R\circ\mathcal T=\mathcal S\circ\mathcal T$ for any (possible) relation $\mathcal T$ $\mathcal R[X]=\mathcal S[X]$ for any (possible) $X$ $\mathcal R^{-1}=\mathcal S^{-1}$ $\mathcal T\circ\mathcal R=\mathcal T\circ\mathcal S$ for any (possible) relation $\mathcal T$ So if $1$ holds then trivially $2$ holds. Now if $2$ holds then for any $X$ we can consider the identity relation $\operatorname{id}_X$ so that the equality $$ \tag{2.1}\label{2.1}\mathcal R\circ\operatorname{id}_X=\mathcal S\circ\operatorname{id}_X $$ holds. So by \eqref{2.1} we argue that the equality $$ \mathcal R[X]=\mathcal R\big[\operatorname{id}_X[X]\big]=(\mathcal R\circ\operatorname{id}_X)[X]=(\mathcal S\circ\operatorname{id}_X)[X]=\mathcal S\big[\operatorname{id}_X[X]\big]=\mathcal S[X] $$ holds. Now if $(y,x)$ is in $\mathcal R^{-1}$ then $(x,y)$ is in $\mathcal R$ and so $y$ is in $\mathcal R[x]$ ; however, if by hypothesis the equality $$ \mathcal R[x]=\mathcal S[x] $$ holds then $y$ is in $\mathcal S[x]$ and thus $(x,y)$ is in $\mathcal S$ : we conclude that $(y,x)$ is in $\mathcal S^{-1}$ which is in particular not empty. Moreover by analogous arguments we can see that if $\mathcal S^{-1}$ is not empty then even $\mathcal R^{-1}$ is not empty and in particular it contains $\mathcal S^{-1}$ . So by extensionality we conclude that $\mathcal R^{-1}$ and $\mathcal S^{-1}$ are equals. Now if $\mathcal R^{-1}$ and $\mathcal S^{-1}$ are equals then the equality $$ \mathcal R^{-1}\circ\mathcal T^{-1}=\mathcal S^{-1}\circ\mathcal T^{-1} $$ holds so that even the equality $$ \mathcal T\circ\mathcal R=\big((\mathcal T\circ\mathcal R)^{-1}\big)^{-1}=(\mathcal R^{-1}\circ\mathcal T^{-1})^{-1}=(\mathcal S^{-1}\circ\mathcal T^{-1})^{-1}=\big((\mathcal T\circ\mathcal S)^{-1}\big)^{-1}=\mathcal T\circ\mathcal S $$ holds. Finally if 5. holds then the equality $$ \mathcal T^{-1}\circ\mathcal R=\mathcal T^{-1}\circ\mathcal S $$ holds so that as above it is not complicate to conclude that the equality $$ \mathcal S^{-1}\circ\mathcal T=\mathcal R^{-1}\circ\mathcal T $$ holds. So as in 2. we conclude that $$ \mathcal R^{-1}[X]=\mathcal S^{-1}[X] $$ for any set $X$ . Finally as in $3$ we conclude that $$ \mathcal R=\mathcal S $$ So first of all I ask if actually statements 1-5 are equivalent and so I ask if I well proved it. Specifically I ask to prove it more using a more clear argument since it seems to me it would be better to prove $1\to 5\to 2\to 3\to 4\to 1$ but unfortunately I am not able to prove $5\to 2$ . So couls someone help me, please?","I am trying to understand if for two binary relations and the following statements are equivalent. for any (possible) relation for any (possible) for any (possible) relation So if holds then trivially holds. Now if holds then for any we can consider the identity relation so that the equality holds. So by \eqref{2.1} we argue that the equality holds. Now if is in then is in and so is in ; however, if by hypothesis the equality holds then is in and thus is in : we conclude that is in which is in particular not empty. Moreover by analogous arguments we can see that if is not empty then even is not empty and in particular it contains . So by extensionality we conclude that and are equals. Now if and are equals then the equality holds so that even the equality holds. Finally if 5. holds then the equality holds so that as above it is not complicate to conclude that the equality holds. So as in 2. we conclude that for any set . Finally as in we conclude that So first of all I ask if actually statements 1-5 are equivalent and so I ask if I well proved it. Specifically I ask to prove it more using a more clear argument since it seems to me it would be better to prove but unfortunately I am not able to prove . So couls someone help me, please?","\mathcal R \mathcal S \mathcal R=\mathcal S \mathcal R\circ\mathcal T=\mathcal S\circ\mathcal T \mathcal T \mathcal R[X]=\mathcal S[X] X \mathcal R^{-1}=\mathcal S^{-1} \mathcal T\circ\mathcal R=\mathcal T\circ\mathcal S \mathcal T 1 2 2 X \operatorname{id}_X 
\tag{2.1}\label{2.1}\mathcal R\circ\operatorname{id}_X=\mathcal S\circ\operatorname{id}_X
 
\mathcal R[X]=\mathcal R\big[\operatorname{id}_X[X]\big]=(\mathcal R\circ\operatorname{id}_X)[X]=(\mathcal S\circ\operatorname{id}_X)[X]=\mathcal S\big[\operatorname{id}_X[X]\big]=\mathcal S[X]
 (y,x) \mathcal R^{-1} (x,y) \mathcal R y \mathcal R[x] 
\mathcal R[x]=\mathcal S[x]
 y \mathcal S[x] (x,y) \mathcal S (y,x) \mathcal S^{-1} \mathcal S^{-1} \mathcal R^{-1} \mathcal S^{-1} \mathcal R^{-1} \mathcal S^{-1} \mathcal R^{-1} \mathcal S^{-1} 
\mathcal R^{-1}\circ\mathcal T^{-1}=\mathcal S^{-1}\circ\mathcal T^{-1}
 
\mathcal T\circ\mathcal R=\big((\mathcal T\circ\mathcal R)^{-1}\big)^{-1}=(\mathcal R^{-1}\circ\mathcal T^{-1})^{-1}=(\mathcal S^{-1}\circ\mathcal T^{-1})^{-1}=\big((\mathcal T\circ\mathcal S)^{-1}\big)^{-1}=\mathcal T\circ\mathcal S
 
\mathcal T^{-1}\circ\mathcal R=\mathcal T^{-1}\circ\mathcal S
 
\mathcal S^{-1}\circ\mathcal T=\mathcal R^{-1}\circ\mathcal T
 
\mathcal R^{-1}[X]=\mathcal S^{-1}[X]
 X 3 
\mathcal R=\mathcal S
 1\to 5\to 2\to 3\to 4\to 1 5\to 2","['elementary-set-theory', 'solution-verification', 'examples-counterexamples', 'relations', 'alternative-proof']"
