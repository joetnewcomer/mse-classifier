,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How many sewings are there on a soccer ball?,How many sewings are there on a soccer ball?,,"A soccer ball is obtained by sewing $20$ hexagonal pieces of leather and $12$ pieces of leather of pentagonal shape. A sewing joins together the sides of two adjacent pieces. How many sewings are there ? My effort I was able to solve this problem by realizing that if I count the number of sewings adjacent to the hexagons and the ones adjacent to the pentagons I will be counting each sewing twice. So, the number of sewings is $$\cfrac{120 + 60}{2}=90.$$ Second Approach (this is the one I am asking about) If we count the sewings adjacent to the pentagons we have $12 \cdot 5 =60 $ sewings ,now to count the rest of the sewings I just observe that any other sewing starts at the edge of some pentagon,so I have $60$ other sewings,for a total of $120$ sewings . However this doesn't quite work, but if I look at the picture I have posted above it seems to be correct as I don't have any pentagon sharing a sewing with another pentagon. What am I missing?","A soccer ball is obtained by sewing $20$ hexagonal pieces of leather and $12$ pieces of leather of pentagonal shape. A sewing joins together the sides of two adjacent pieces. How many sewings are there ? My effort I was able to solve this problem by realizing that if I count the number of sewings adjacent to the hexagons and the ones adjacent to the pentagons I will be counting each sewing twice. So, the number of sewings is $$\cfrac{120 + 60}{2}=90.$$ Second Approach (this is the one I am asking about) If we count the sewings adjacent to the pentagons we have $12 \cdot 5 =60 $ sewings ,now to count the rest of the sewings I just observe that any other sewing starts at the edge of some pentagon,so I have $60$ other sewings,for a total of $120$ sewings . However this doesn't quite work, but if I look at the picture I have posted above it seems to be correct as I don't have any pentagon sharing a sewing with another pentagon. What am I missing?",,"['combinatorics', 'algebra-precalculus', 'contest-math', 'polyhedra']"
1,Number of ways two knights can be placed such that they don't attack.,Number of ways two knights can be placed such that they don't attack.,,"What are the number of ways two knights can be placed on a k×k chessboard so that they do not attack each other? For k from 1 to 8, the answer is given below. How do I find a general formula? 0 6 28 96 252 550 1056 1848 Edit: Here's my approach after @Peter 's help,  I came to a conclusion that number of ways such that they attack is equal to two times the number of possible ways I can put an ""L"" shape on the board. (2 times because knights can swap positions), am I right? I don't know how do I more forward from here. I tried finding number of ways to place L by this recursive formula: F[n][n]=4+F[i][i-3]+F[i-2][3]; But it's not working.","What are the number of ways two knights can be placed on a k×k chessboard so that they do not attack each other? For k from 1 to 8, the answer is given below. How do I find a general formula? 0 6 28 96 252 550 1056 1848 Edit: Here's my approach after @Peter 's help,  I came to a conclusion that number of ways such that they attack is equal to two times the number of possible ways I can put an ""L"" shape on the board. (2 times because knights can swap positions), am I right? I don't know how do I more forward from here. I tried finding number of ways to place L by this recursive formula: F[n][n]=4+F[i][i-3]+F[i-2][3]; But it's not working.",,['combinatorics']
2,"On an infinitely large chessboard, in how many paths of length $10$ can a knight take and end up in its original position?","On an infinitely large chessboard, in how many paths of length  can a knight take and end up in its original position?",10,The knight is moved exactly $10$ times. A knight has $8$ possible ways to move once. So I believe there are $8^{10}= 2^{30} \sim 1$ billion permutations. How many in which the knight ends up on the same square?,The knight is moved exactly times. A knight has possible ways to move once. So I believe there are billion permutations. How many in which the knight ends up on the same square?,10 8 8^{10}= 2^{30} \sim 1,"['combinatorics', 'chessboard']"
3,Prove that a $k$-regular bipartite graph has a perfect matching,Prove that a -regular bipartite graph has a perfect matching,k,Prove that a $k$-regular bipartite graph has a perfect matching by using Hall's theorem. Let $S$ be any subset of the left side of the graph. The only thing I know is the number of things leaving the subset is $|S|\times k$.,Prove that a $k$-regular bipartite graph has a perfect matching by using Hall's theorem. Let $S$ be any subset of the left side of the graph. The only thing I know is the number of things leaving the subset is $|S|\times k$.,,"['combinatorics', 'graph-theory', 'bipartite-graphs', 'matching-theory']"
4,How many non-increasing sequences are there over the natural numbers?,How many non-increasing sequences are there over the natural numbers?,,"How many non-increasing sequences are there over the natural numbers? By splitting it to categories, I sort of got it has to be $\aleph_0$. Nevertheless, I haven't seen such a question and therefore I don't know if I am even correct in my result. I would appreciate your help.","How many non-increasing sequences are there over the natural numbers? By splitting it to categories, I sort of got it has to be $\aleph_0$. Nevertheless, I haven't seen such a question and therefore I don't know if I am even correct in my result. I would appreciate your help.",,"['combinatorics', 'elementary-set-theory']"
5,Are there any Combinatoric proofs of Bertrand's postulate?,Are there any Combinatoric proofs of Bertrand's postulate?,,"I feel like there must exist a combinatoric proof of a theorem like: There is a prime between $n$ and $2n$, or $p$ and $p^2$ or anything similar to this stronger than there is a prime between $p$ and $(\prod_p p) + 1$ (Euclid's theorem). I was trying to prove one by the Sieve on this grid 1     2     3     4 ... p   p+1   p+2   p+3   p+4 ... 2p  2p+1  2p+2  2p+3  2p+4 ... 3p ........................... ........................... ........................... p^2 p^2+1 p^2+2 p^2+3 p^2+4 ... but it did not work. Do any good arguments like this exist? I don't expect anything as strong as Prime Number Theorem or even Bertrand, but surely a direct combination proof can prove that there are lots of primes?","I feel like there must exist a combinatoric proof of a theorem like: There is a prime between $n$ and $2n$, or $p$ and $p^2$ or anything similar to this stronger than there is a prime between $p$ and $(\prod_p p) + 1$ (Euclid's theorem). I was trying to prove one by the Sieve on this grid 1     2     3     4 ... p   p+1   p+2   p+3   p+4 ... 2p  2p+1  2p+2  2p+3  2p+4 ... 3p ........................... ........................... ........................... p^2 p^2+1 p^2+2 p^2+3 p^2+4 ... but it did not work. Do any good arguments like this exist? I don't expect anything as strong as Prime Number Theorem or even Bertrand, but surely a direct combination proof can prove that there are lots of primes?",,"['combinatorics', 'number-theory', 'prime-numbers', 'analytic-number-theory']"
6,Stirling numbers of second type [duplicate],Stirling numbers of second type [duplicate],,"This question already has answers here : Stirling numbers combinatorial proof: $S(m,n)=\frac 1{n!} \sum_{k=0}^{n} (-1)^k\binom nk (n-k)^m$ (3 answers) Closed 10 years ago . How can I do a combinatoric proof that for Stirling number of second type the equality if true: $${n\brace k} = \frac{1}{k!}\sum_{i=0}^{k}{k \choose i}i^n(-1)^{k-i}$$","This question already has answers here : Stirling numbers combinatorial proof: $S(m,n)=\frac 1{n!} \sum_{k=0}^{n} (-1)^k\binom nk (n-k)^m$ (3 answers) Closed 10 years ago . How can I do a combinatoric proof that for Stirling number of second type the equality if true: $${n\brace k} = \frac{1}{k!}\sum_{i=0}^{k}{k \choose i}i^n(-1)^{k-i}$$",,"['combinatorics', 'stirling-numbers']"
7,Why is $\sum_{p \in S_n} 2^{c(p)}$ equal to $(n+1)!$?,Why is  equal to ?,\sum_{p \in S_n} 2^{c(p)} (n+1)!,"It is obvious that $\sum_{p \in S_n} 1=n!$ because it is just counting how many permutations there are of $n$ symbols. But I have also observed that $\sum_{p \in S_n} 2^{c(p)}=(n+1)!$ , where $c(p)$ is the number of cycles of $p$ . What is the combinatorial interpretation of this identity? An example. In $S_3$ we have one permutation with 3 cycles, three permutations with 2 cycles and two with 1 cycle. Then $1\times 2^3+3\times 2^2+2\times 2^1=24=4!$","It is obvious that because it is just counting how many permutations there are of symbols. But I have also observed that , where is the number of cycles of . What is the combinatorial interpretation of this identity? An example. In we have one permutation with 3 cycles, three permutations with 2 cycles and two with 1 cycle. Then",\sum_{p \in S_n} 1=n! n \sum_{p \in S_n} 2^{c(p)}=(n+1)! c(p) p S_3 1\times 2^3+3\times 2^2+2\times 2^1=24=4!,"['combinatorics', 'permutations']"
8,Are the logarithms in number theory natural?,Are the logarithms in number theory natural?,,"I find the frequent emergence of logarithms and even nested logarithms in number theory, especially the prime number counting business , somewhat unsettling. What is the reason for them? Has it maybe to do with the series expansion of the logarithm? Or is there something inherently exponential in any of the relevant number distributions, like in complexity theory or combinatorical problems? I think maybe in how you can construct bigger integers out of smaller ones.","I find the frequent emergence of logarithms and even nested logarithms in number theory, especially the prime number counting business , somewhat unsettling. What is the reason for them? Has it maybe to do with the series expansion of the logarithm? Or is there something inherently exponential in any of the relevant number distributions, like in complexity theory or combinatorical problems? I think maybe in how you can construct bigger integers out of smaller ones.",,"['combinatorics', 'number-theory', 'prime-numbers', 'logarithms']"
9,Finding the minimal number of members,Finding the minimal number of members,,"I've been working on the following problem For every issue in the Blue's association, a commission with 10 members (belonging the Blue's) is formed in order to solve the problem. The only condition is There can't be two commissions having more than one member in common The Blue's association has formed this year 40 commissions. What's the minimal amount of members in the Blue's association? I've only found out the following For any commission you can form $\binom{10}{2}=45$ different pairs and none of them can appear in another commission. Since 40 different commissions are formed, the minimal number of pairs is $45\times 40=1800$ . Denote by $n$ the number of members. Thus $$\binom{n}{2}≥1800\Rightarrow n>60$$ $$$$ The minimal amount of members has to be 100 or less. You can observe a distribution for 100 members here My question: Is 100 the answer or is there an ever smaller possible amount of members? If so, how can I prove it?","I've been working on the following problem For every issue in the Blue's association, a commission with 10 members (belonging the Blue's) is formed in order to solve the problem. The only condition is There can't be two commissions having more than one member in common The Blue's association has formed this year 40 commissions. What's the minimal amount of members in the Blue's association? I've only found out the following For any commission you can form different pairs and none of them can appear in another commission. Since 40 different commissions are formed, the minimal number of pairs is . Denote by the number of members. Thus The minimal amount of members has to be 100 or less. You can observe a distribution for 100 members here My question: Is 100 the answer or is there an ever smaller possible amount of members? If so, how can I prove it?",\binom{10}{2}=45 45\times 40=1800 n \binom{n}{2}≥1800\Rightarrow n>60 ,['combinatorics']
10,Prove that $n! \equiv \sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(n-k+r)^{n} $,Prove that,n! \equiv \sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(n-k+r)^{n} ,"Basically I had some fun doing this: 0     1 1       6     7       6 8       12     19      6 27      18     37      6 64      24     61 125  etc. starting with $k^n$ ($n=3$) and then calculating the differences. It turns out that the result after n steps is always $n!$. Pretty neat, heh? :) Therefore: $$ n! \equiv \sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(n-k+r)^{n} $$ where $n \in \mathbb{N}$ and $r \in \mathbb{Z}$ But how do I prove that?","Basically I had some fun doing this: 0     1 1       6     7       6 8       12     19      6 27      18     37      6 64      24     61 125  etc. starting with $k^n$ ($n=3$) and then calculating the differences. It turns out that the result after n steps is always $n!$. Pretty neat, heh? :) Therefore: $$ n! \equiv \sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(n-k+r)^{n} $$ where $n \in \mathbb{N}$ and $r \in \mathbb{Z}$ But how do I prove that?",,"['combinatorics', 'binomial-coefficients']"
11,Notation for the set created from the combination or permutation of a set,Notation for the set created from the combination or permutation of a set,,"For a set $S$ with $n$ elements, the notation for a combination $\binom{n}{k}$, or $C(n, k)$, indicates the number of combinations of $k$ elements from $S$, but how does one indicate the actual set created from combinations of $k$ elements from $S$? That is, $\binom{n}{k}$ is the size of the set I'd like to represent. Likewise, how would one indicate the actual set of items created from the permutations of $k$ elements, rather than the size of that set?","For a set $S$ with $n$ elements, the notation for a combination $\binom{n}{k}$, or $C(n, k)$, indicates the number of combinations of $k$ elements from $S$, but how does one indicate the actual set created from combinations of $k$ elements from $S$? That is, $\binom{n}{k}$ is the size of the set I'd like to represent. Likewise, how would one indicate the actual set of items created from the permutations of $k$ elements, rather than the size of that set?",,"['combinatorics', 'notation']"
12,Stopping the Coronavirus puzzle [closed],Stopping the Coronavirus puzzle [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question A square region $2020 \times 2020 \text{ km}^2$ divided into $2020^2$ cells. Some cells are contaminated by covid-19 . Every week the virus spread to those cell which have at least $2$ side in common with contaminated cells. Find the maximum number of contaminated cells such that no matter where they are located the covid-19 pandemic will not spread to the entire region. My school friend gave me this problem( better to say a puzzle) may be during the lockdown period(July-August) but I forgot it and yesterday he asked me if I have been able to solve the problem or not? And then the answer was obviously not, although I put a sufficient effort behind the problem that time and after the meet yesterday and also today I gave a lots of time but unable to figure it out. Thanks for your attention!","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question A square region divided into cells. Some cells are contaminated by covid-19 . Every week the virus spread to those cell which have at least side in common with contaminated cells. Find the maximum number of contaminated cells such that no matter where they are located the covid-19 pandemic will not spread to the entire region. My school friend gave me this problem( better to say a puzzle) may be during the lockdown period(July-August) but I forgot it and yesterday he asked me if I have been able to solve the problem or not? And then the answer was obviously not, although I put a sufficient effort behind the problem that time and after the meet yesterday and also today I gave a lots of time but unable to figure it out. Thanks for your attention!",2020 \times 2020 \text{ km}^2 2020^2 2,"['combinatorics', 'recreational-mathematics', 'puzzle']"
13,Pigeonhole Principle Question: Jessica the Combinatorics Student,Pigeonhole Principle Question: Jessica the Combinatorics Student,,"Jessica is studying combinatorics during a $7$-week period. She will   study a positive integer number of hours every day during the $7$   weeks (so, for example, she won't study for $0$ or $1.5$ hours), but   she won't study more than $11$ hours in any $7$-day period. Prove that   there must exist some period of consecutive days during which Jessica   studies exactly $20$ hours. Here are my thoughts so far: Let $f(n)$ represent the total number of hours Jessica has studied after day $n$. Clearly, there are $49$ days in total, and the domain of $f$ is integers in the interval $[0,49]$. Proving that there must exist some period of consecutive days during which Jessica studies exactly $20$ hours is equivalent to proving that there must exist $i$ and $j$ such that $f(i)-f(j)=20$. This is a really interesting question, but I don't see a clear path forward. How do you solve this question? Please try not to use extremely advanced math or I won't understand :P","Jessica is studying combinatorics during a $7$-week period. She will   study a positive integer number of hours every day during the $7$   weeks (so, for example, she won't study for $0$ or $1.5$ hours), but   she won't study more than $11$ hours in any $7$-day period. Prove that   there must exist some period of consecutive days during which Jessica   studies exactly $20$ hours. Here are my thoughts so far: Let $f(n)$ represent the total number of hours Jessica has studied after day $n$. Clearly, there are $49$ days in total, and the domain of $f$ is integers in the interval $[0,49]$. Proving that there must exist some period of consecutive days during which Jessica studies exactly $20$ hours is equivalent to proving that there must exist $i$ and $j$ such that $f(i)-f(j)=20$. This is a really interesting question, but I don't see a clear path forward. How do you solve this question? Please try not to use extremely advanced math or I won't understand :P",,['combinatorics']
14,"Calculate the sum of inverse values of ${n\choose 0}, {n\choose 1}, ... {n\choose n}$",Calculate the sum of inverse values of,"{n\choose 0}, {n\choose 1}, ... {n\choose n}","Calculate $$A={1\over {n\choose 0}}+ {1\over {n\choose 1}}+ ...+{1\over  {n\choose n}}$$ and $$B={1\over {n\choose 0}}- {1\over {n\choose 1}}+ ...+{(-1)^n\over  {n\choose n}}$$ My idea for $A$ is some probabilistic reasoning. Color the sets $$\{\}, \{1\}, \{1,2\}, \{1,2,3\},...\{1,2,...,n\}$$ and ask our self what is the probability that I choose colored set among all sets. Clearly this is exactly ${n+1\over 2^n}$ and on the other side it is $A$: probability that I take empty set is ${1\over {n\choose 0}}$, probability that I take colored set with 1 element is ${1\over {n\choose 1}}$ probability that I take colored set with 2 elements is ${1\over {n\choose 2}}$ and so on ... So $A ={n+1\over 2^n}$. But I have no idea how to attack $B$.","Calculate $$A={1\over {n\choose 0}}+ {1\over {n\choose 1}}+ ...+{1\over  {n\choose n}}$$ and $$B={1\over {n\choose 0}}- {1\over {n\choose 1}}+ ...+{(-1)^n\over  {n\choose n}}$$ My idea for $A$ is some probabilistic reasoning. Color the sets $$\{\}, \{1\}, \{1,2\}, \{1,2,3\},...\{1,2,...,n\}$$ and ask our self what is the probability that I choose colored set among all sets. Clearly this is exactly ${n+1\over 2^n}$ and on the other side it is $A$: probability that I take empty set is ${1\over {n\choose 0}}$, probability that I take colored set with 1 element is ${1\over {n\choose 1}}$ probability that I take colored set with 2 elements is ${1\over {n\choose 2}}$ and so on ... So $A ={n+1\over 2^n}$. But I have no idea how to attack $B$.",,"['combinatorics', 'summation', 'combinations', 'binomial-coefficients']"
15,How do I calculate the number of different combinations of multiple sets' elements (different number of elements on each set)?,How do I calculate the number of different combinations of multiple sets' elements (different number of elements on each set)?,,"First of all, I have no experience with mathematics, so my terminology may be wrong, but let me illustrate my question: Let's say that I have 4 different sets of elements: [apples, oranges, lemons] [a, b, c, d, e] [black, white, red, blue] [1, 2] I want to find how many different combinations of the items there are. Notice: The combinations will always have 1 item from every list The 1st item in every combination will be chosen from the 1st list, the 2nd from the 2nd etc. So, basically the first 5 combinations would be: apples - a - black - 1 apples - a - black - 2 apples - a - white - 1 apples - a - white - 2 apples - a - red - 1 etc etc Sorry for not putting it in mathematical terms but I hope you understand what I'm trying to ask.","First of all, I have no experience with mathematics, so my terminology may be wrong, but let me illustrate my question: Let's say that I have 4 different sets of elements: [apples, oranges, lemons] [a, b, c, d, e] [black, white, red, blue] [1, 2] I want to find how many different combinations of the items there are. Notice: The combinations will always have 1 item from every list The 1st item in every combination will be chosen from the 1st list, the 2nd from the 2nd etc. So, basically the first 5 combinations would be: apples - a - black - 1 apples - a - black - 2 apples - a - white - 1 apples - a - white - 2 apples - a - red - 1 etc etc Sorry for not putting it in mathematical terms but I hope you understand what I'm trying to ask.",,['combinatorics']
16,Decreasing integers on the blackboard,Decreasing integers on the blackboard,,"There are $n\geq 2$ copies of an integer $k>0$ written on the blackboard. A move consists of choosing an integer $m>0$ on the blackboard, and replacing it as well as one other integer on the blackboard (you can choose which one) by the integer $m-1$. For example, if you have numbers $(3,0,1)$ on the blackboard, a move can change them to $(2,2,1)$ or $(2,0,2)$ or $(3,0,0)$ or $(0,0,0)$. What is the maximum possible number $f(n,k)$ of moves you can perform? An asymptotic answer would be good enough (I think it could be $O(kn^2)$).","There are $n\geq 2$ copies of an integer $k>0$ written on the blackboard. A move consists of choosing an integer $m>0$ on the blackboard, and replacing it as well as one other integer on the blackboard (you can choose which one) by the integer $m-1$. For example, if you have numbers $(3,0,1)$ on the blackboard, a move can change them to $(2,2,1)$ or $(2,0,2)$ or $(3,0,0)$ or $(0,0,0)$. What is the maximum possible number $f(n,k)$ of moves you can perform? An asymptotic answer would be good enough (I think it could be $O(kn^2)$).",,"['combinatorics', 'discrete-mathematics', 'asymptotics']"
17,"Is $\prod_{1\leq i< j\leq n} \frac{a_i - a_j}{i-j}$, with distinct integers $a_i$, an integer?","Is , with distinct integers , an integer?",\prod_{1\leq i< j\leq n} \frac{a_i - a_j}{i-j} a_i,"It is known that for every $n$ consecutive integers, their product is divisible by $n!$, since $${{m}\choose{n}} = \frac{m!}{n!(m-n)!}$$ is also an integer. So is it true that for every distinct integer $a_1, a_2, ..., a_n$, the number $$S = \prod_{1\leq i< j\leq n} \frac{a_i - a_j}{i-j}$$ is also an integer? (Sorry for my grammar mistakes, English is my second language)","It is known that for every $n$ consecutive integers, their product is divisible by $n!$, since $${{m}\choose{n}} = \frac{m!}{n!(m-n)!}$$ is also an integer. So is it true that for every distinct integer $a_1, a_2, ..., a_n$, the number $$S = \prod_{1\leq i< j\leq n} \frac{a_i - a_j}{i-j}$$ is also an integer? (Sorry for my grammar mistakes, English is my second language)",,"['combinatorics', 'algebra-precalculus', 'geometry', 'number-theory']"
18,"Recent Question in American Math Monthly, proposed by Donald Knuth","Recent Question in American Math Monthly, proposed by Donald Knuth",,"Problem 11985, by Donald Knuth, American Mathematical Monthly , June-July, 2017: For fixed $s,t \in \mathbb{N}$. with $s\leq t$. let $a_{n}=\sum\limits_{k=s}^{t}$ $ {n}\choose{k}$. Prove that this sequence is log-concave, namely that $a_{n}^{2}\geq a_{n-1}a_{n+1} \ \forall n\geq 1$. The submission deadline for this problem was over on 31st October. Does this statement follow from some well known results?","Problem 11985, by Donald Knuth, American Mathematical Monthly , June-July, 2017: For fixed $s,t \in \mathbb{N}$. with $s\leq t$. let $a_{n}=\sum\limits_{k=s}^{t}$ $ {n}\choose{k}$. Prove that this sequence is log-concave, namely that $a_{n}^{2}\geq a_{n-1}a_{n+1} \ \forall n\geq 1$. The submission deadline for this problem was over on 31st October. Does this statement follow from some well known results?",,"['combinatorics', 'inequality', 'summation', 'binomial-coefficients']"
19,Weekend birthdays,Weekend birthdays,,"My birthday this year (2011) is on a Friday. In most years, one's birthday the following year is on the subsequent day of the week, and in that pattern, my birthday next year (2012) it is on a Saturday. However, due to 2012 being a leap year, my birthday in 2013 will be on Monday - I miss out on having a Sunday birthday. I quite like having weekend birthdays, so that disappoints me a bit. However it leads me to a question: Over a reasonable-length life-time, does any given person's number of weekend birthdays even out to an average, or are some people significantly more blessed than others? If some people do have an advantage in this respect, is there any way mathematical way to work out whether being born on any given day of any given year will confer an advantage? And further, what are the probabilities of being 'lucky' in your number of weekend birthdays. My guess is that for any given year, on each side of Feb 29th, birthdays on any given day of the week throughout the year will have the same score. To make it a bit easier, lets say for a 'reasonable length life-time', we mean a fixed length of 80 years (though I for one intend to beat that!). That said, I would also be interested in how the maths change as we vary the life-span.","My birthday this year (2011) is on a Friday. In most years, one's birthday the following year is on the subsequent day of the week, and in that pattern, my birthday next year (2012) it is on a Saturday. However, due to 2012 being a leap year, my birthday in 2013 will be on Monday - I miss out on having a Sunday birthday. I quite like having weekend birthdays, so that disappoints me a bit. However it leads me to a question: Over a reasonable-length life-time, does any given person's number of weekend birthdays even out to an average, or are some people significantly more blessed than others? If some people do have an advantage in this respect, is there any way mathematical way to work out whether being born on any given day of any given year will confer an advantage? And further, what are the probabilities of being 'lucky' in your number of weekend birthdays. My guess is that for any given year, on each side of Feb 29th, birthdays on any given day of the week throughout the year will have the same score. To make it a bit easier, lets say for a 'reasonable length life-time', we mean a fixed length of 80 years (though I for one intend to beat that!). That said, I would also be interested in how the maths change as we vary the life-span.",,"['combinatorics', 'calendar-computations']"
20,Nice application of the Cauchy?-Frobenius?-Burnside?-Pólya? formula,Nice application of the Cauchy?-Frobenius?-Burnside?-Pólya? formula,,"Burnside's Lemma , whose list of names is longer than the proof, says that the number of orbits of a permutation group is the average number of fixed points of its elements. It's a very elegant result, but I'm a bit disappointed by the fact that the examples given in the textbooks always amount to counting some colorings of a symmetric object, up to symmetry (the less original example probably being the cube). My question is then: do you know some funnier (but still rather direct) applications of this result?","Burnside's Lemma , whose list of names is longer than the proof, says that the number of orbits of a permutation group is the average number of fixed points of its elements. It's a very elegant result, but I'm a bit disappointed by the fact that the examples given in the textbooks always amount to counting some colorings of a symmetric object, up to symmetry (the less original example probably being the cube). My question is then: do you know some funnier (but still rather direct) applications of this result?",,"['group-theory', 'soft-question', 'combinatorics']"
21,Proving $\sum_{k=0}^n{2k\choose k}{2n-2k\choose n-k}=4^n$ [duplicate],Proving  [duplicate],\sum_{k=0}^n{2k\choose k}{2n-2k\choose n-k}=4^n,"This question already has answers here : Identity for convolution of central binomial coefficients: $\sum\limits_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}=2^{2n}$ (4 answers) Closed 9 years ago . Some background. I was asked to find an arithmetic function $f$ such that $f*f=\mathbf 1$ where $\mathbf 1$ is the constant function 1 and $*$ denotes Dirichlet convolution. I was able to prove that there are two solutions $\pm f$ and that $f$ is multiplicative. Next, I would have to evaluate $f$ at prime powers. I constructed a few values and my conjecture is that $$f(p^n)=\frac{2n-1\choose n}{2^{2n-1}}$$ for $p$ prime and $n>0$. To prove this, I only need to show that $$\sum_{k=1}^n{2k-1\choose k}{2n-2k+1\choose n-k+1}=4^n-{2n+1\choose n+1}\qquad\text{for }\;n\geq0.$$ (This is simply expressing $(f*f)(p^{n+1})=1$ explicitly, plugging in the conjecture.) For readers who don't really understand what I'm talking about and who are merely interested in the proof of the identity, you can just start reading from here. Hoping for a combinatorial proof, I interpreted the summation as follows. Given a set of $n+1$ indistinguishable marbles and $n+1$ distinguishable bags (say $b_1,\ldots,b_{n+1}$), the term ${2k-1\choose k}{2n-2k+1\choose n-k+1}$ counts the number of ways to put the marbles in the bags such that there are exactly $k$ marbles in the first $k$ bags $b_1,\ldots,b_k$. Equivalently, if we identify a configuration of the marbles with a monotonic path in a $n+1\times n+1$ grid such that the path starts in the bottom left corner and ends in the upper right corner, the sum $${2n+1\choose n+1}+\sum_{k=1}^n{2k-1\choose k}{2n-2k+1\choose n-k+1}$$ counts the number of times a path 'crosses' or 'touches' the main diagonal in a point that is not the 'origin', if we summate over all possible paths. (There are ${2n+2\choose n+1}$ such paths in total.) For example, the following path touches the main diagonal $4$ times: At $(2,2)$, $(3,3)$, $(4,4)$ and $(7,7)$. (We do not count $(0,0)$ because the summation doesn't.) However, interpreting the summation like this I can't get any further. Any other ideas or suggestions on how to approach this problem? Edit: There are some errors in my reasoning above, let's try again. Using the identity ${2n-1\choose n}=\frac12{2n\choose n}$ it can be rewritten as $$\sum_{k=0}^n{2k\choose k}{2n-2k\choose n-k}=4^n$$ which looks much better and holds for all $n\geq0$, making it more naturally. This form may give some ideas for combinatorial proofs but I don't really see any. The term ${2k\choose k}{2n-2k\choose n-k}$ counts the number of $n\times n$ monotonic paths intersecting the diagonal at $(k,k)$. So the summation counts the number of intersection points with the diagonal (all of them this time, including the origin) summing over all paths. As in Arthur's comment, it would suffice to find a bijection between all $2n$-monotonic paths (no matter their width or height) and the pairs $(p,s)$ where $p$ is a $n\times n$ path and $s$ an intersection point with the diagonal. Perhaps there is a weird bijection which would then solve the question. For the sake of a proof with induction, I considered all paths that intersect the diagonal for the first time at $(k,k)$ and all possible continuations and their intersection points, summed for $k$ from $1$ to $n$ using the induction hypothesis and a trick with Catalan numbers . (Writing out the details would be tedious, I think the reasoning becomes clear when you see the sum.) It turns out to be sufficient to prove $$\sum_{k=1}^n2C_{k-1}\left(4^{n-k}+{2n-2k\choose n-k}\right)=4^n$$ where $C_n=\frac1{n+1}{2n\choose n}$ denotes the $n$th Catalan number. However this doesn't seem to be a simplification.","This question already has answers here : Identity for convolution of central binomial coefficients: $\sum\limits_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}=2^{2n}$ (4 answers) Closed 9 years ago . Some background. I was asked to find an arithmetic function $f$ such that $f*f=\mathbf 1$ where $\mathbf 1$ is the constant function 1 and $*$ denotes Dirichlet convolution. I was able to prove that there are two solutions $\pm f$ and that $f$ is multiplicative. Next, I would have to evaluate $f$ at prime powers. I constructed a few values and my conjecture is that $$f(p^n)=\frac{2n-1\choose n}{2^{2n-1}}$$ for $p$ prime and $n>0$. To prove this, I only need to show that $$\sum_{k=1}^n{2k-1\choose k}{2n-2k+1\choose n-k+1}=4^n-{2n+1\choose n+1}\qquad\text{for }\;n\geq0.$$ (This is simply expressing $(f*f)(p^{n+1})=1$ explicitly, plugging in the conjecture.) For readers who don't really understand what I'm talking about and who are merely interested in the proof of the identity, you can just start reading from here. Hoping for a combinatorial proof, I interpreted the summation as follows. Given a set of $n+1$ indistinguishable marbles and $n+1$ distinguishable bags (say $b_1,\ldots,b_{n+1}$), the term ${2k-1\choose k}{2n-2k+1\choose n-k+1}$ counts the number of ways to put the marbles in the bags such that there are exactly $k$ marbles in the first $k$ bags $b_1,\ldots,b_k$. Equivalently, if we identify a configuration of the marbles with a monotonic path in a $n+1\times n+1$ grid such that the path starts in the bottom left corner and ends in the upper right corner, the sum $${2n+1\choose n+1}+\sum_{k=1}^n{2k-1\choose k}{2n-2k+1\choose n-k+1}$$ counts the number of times a path 'crosses' or 'touches' the main diagonal in a point that is not the 'origin', if we summate over all possible paths. (There are ${2n+2\choose n+1}$ such paths in total.) For example, the following path touches the main diagonal $4$ times: At $(2,2)$, $(3,3)$, $(4,4)$ and $(7,7)$. (We do not count $(0,0)$ because the summation doesn't.) However, interpreting the summation like this I can't get any further. Any other ideas or suggestions on how to approach this problem? Edit: There are some errors in my reasoning above, let's try again. Using the identity ${2n-1\choose n}=\frac12{2n\choose n}$ it can be rewritten as $$\sum_{k=0}^n{2k\choose k}{2n-2k\choose n-k}=4^n$$ which looks much better and holds for all $n\geq0$, making it more naturally. This form may give some ideas for combinatorial proofs but I don't really see any. The term ${2k\choose k}{2n-2k\choose n-k}$ counts the number of $n\times n$ monotonic paths intersecting the diagonal at $(k,k)$. So the summation counts the number of intersection points with the diagonal (all of them this time, including the origin) summing over all paths. As in Arthur's comment, it would suffice to find a bijection between all $2n$-monotonic paths (no matter their width or height) and the pairs $(p,s)$ where $p$ is a $n\times n$ path and $s$ an intersection point with the diagonal. Perhaps there is a weird bijection which would then solve the question. For the sake of a proof with induction, I considered all paths that intersect the diagonal for the first time at $(k,k)$ and all possible continuations and their intersection points, summed for $k$ from $1$ to $n$ using the induction hypothesis and a trick with Catalan numbers . (Writing out the details would be tedious, I think the reasoning becomes clear when you see the sum.) It turns out to be sufficient to prove $$\sum_{k=1}^n2C_{k-1}\left(4^{n-k}+{2n-2k\choose n-k}\right)=4^n$$ where $C_n=\frac1{n+1}{2n\choose n}$ denotes the $n$th Catalan number. However this doesn't seem to be a simplification.",,"['combinatorics', 'elementary-number-theory', 'summation', 'binomial-coefficients']"
22,How many resulting regions if we partition $\mathbb{R}^m$ with $n$ hyperplanes?,How many resulting regions if we partition  with  hyperplanes?,\mathbb{R}^m n,"This is a generalization of this question . So in $\mathbb{R}^2$, the problem is illustrated like so: Here, $n = 3$ lines divides $\mathbb{R}^2$ into $N_2=7$ regions. For general $n$ in the case of $\mathbb{R}^2$, the number of regions $N_2$ is $\binom{n+1}{2}+1$. But what about if we consider the case of $\mathbb{R}^m$, partitioned using $n$ hyperplanes? Is the answer $N_m$ still $\binom{n+1}{2}+1$, or will it be a function of $m$?","This is a generalization of this question . So in $\mathbb{R}^2$, the problem is illustrated like so: Here, $n = 3$ lines divides $\mathbb{R}^2$ into $N_2=7$ regions. For general $n$ in the case of $\mathbb{R}^2$, the number of regions $N_2$ is $\binom{n+1}{2}+1$. But what about if we consider the case of $\mathbb{R}^m$, partitioned using $n$ hyperplanes? Is the answer $N_m$ still $\binom{n+1}{2}+1$, or will it be a function of $m$?",,['combinatorics']
23,The best $n$-digit password?,The best -digit password?,n,"I suddenly thought of a question today: What is the best $n$ -digit password? It is not specific so I'll write it in a better way: There is a password lock that has $n$ digits. There are $t$ choices for every digit. There is a thief that wants to  crack the password lock, so he blows some powder into the lock that  will show the fingerprints and will tell him the digits used (If there are repeated digit in the password, it only shows one fingerprint on the repeated digit). If the password consists of $m$ distinct digits, then find $m$ ( $m\le n$ ) that makes the number of the combination of the possible password $P\left(m\right)$ the most. Let me show a example: For $n=4,t=4$ , $P\left(1\right)=1,$ $P\left(2\right)=C^4_2+2C^4_1=14$ $P\left(3\right)=3\times2C^4_2=36$ $P\left(4\right)=4!=24$ $\therefore m=3$ is the answer for the case $n=4,t=4$ . However, when $n,t$ are bigger number, it will be hard to calculate. Hence, I want to ask you guys the general case or making a table. Thank you!","I suddenly thought of a question today: What is the best -digit password? It is not specific so I'll write it in a better way: There is a password lock that has digits. There are choices for every digit. There is a thief that wants to  crack the password lock, so he blows some powder into the lock that  will show the fingerprints and will tell him the digits used (If there are repeated digit in the password, it only shows one fingerprint on the repeated digit). If the password consists of distinct digits, then find ( ) that makes the number of the combination of the possible password the most. Let me show a example: For , is the answer for the case . However, when are bigger number, it will be hard to calculate. Hence, I want to ask you guys the general case or making a table. Thank you!","n n t m m m\le n P\left(m\right) n=4,t=4 P\left(1\right)=1, P\left(2\right)=C^4_2+2C^4_1=14 P\left(3\right)=3\times2C^4_2=36 P\left(4\right)=4!=24 \therefore m=3 n=4,t=4 n,t","['combinatorics', 'permutations', 'combinations']"
24,"Proof of the identity $\sum_{k=0}^{\min[p,q]}{p\choose k}{q\choose k}{n+k\choose p+q}={n\choose p}{n\choose q}$",Proof of the identity,"\sum_{k=0}^{\min[p,q]}{p\choose k}{q\choose k}{n+k\choose p+q}={n\choose p}{n\choose q}","Prove the identity: $$\sum_{k=0}^{\min[p,q]}{p\choose k}{q\choose k}{n+k\choose p+q}={n\choose p}{n\choose q}.$$","Prove the identity: $$\sum_{k=0}^{\min[p,q]}{p\choose k}{q\choose k}{n+k\choose p+q}={n\choose p}{n\choose q}.$$",,"['combinatorics', 'binomial-coefficients']"
25,Children's Fruit Division,Children's Fruit Division,,"How many ways can $11$ apples and $9$ pears be divided between 4 children so that each child receives five fruits? (Apples are identical. just like pears). Solution: $f\left(x,y\right)=\left(x^5+x^4y+x^3y^2+x^2y^3+xy^4+y^5\right)^4$ $f\left(x,y\right)=\left(\frac{x^6-y^6}{x-y}\right)^4$ $f\left(x,y\right)=\left(x^6-y^6\right)^4{\cdot\left(x-y\right)}^{-4}$ $f\left( x,y \right)={{\left( {{x}^{6}}-{{y}^{6}} \right)}^{4}}\cdot {{x}^{-4}}{{\left( 1-\frac{y}{x} \right)}^{-4}}$ $f\left(x,y\right)=\left(x^{24}-4x^{18}y^6+{6x}^{12}y^{12}-{4x}^6y^{18}+y^{24}\right)\cdot\sum_{k=0}^{\infty}\binom{3+k}{k}x^{-4-k}y^k$ The coefficient of $x^{11}y^9$ in $f\left(x,y\right)=\binom{3+9}{9}-4\binom{3+3}{3}=140.$ I'm right?",How many ways can apples and pears be divided between 4 children so that each child receives five fruits? (Apples are identical. just like pears). Solution: The coefficient of in I'm right?,"11 9 f\left(x,y\right)=\left(x^5+x^4y+x^3y^2+x^2y^3+xy^4+y^5\right)^4 f\left(x,y\right)=\left(\frac{x^6-y^6}{x-y}\right)^4 f\left(x,y\right)=\left(x^6-y^6\right)^4{\cdot\left(x-y\right)}^{-4} f\left( x,y \right)={{\left( {{x}^{6}}-{{y}^{6}} \right)}^{4}}\cdot {{x}^{-4}}{{\left( 1-\frac{y}{x} \right)}^{-4}} f\left(x,y\right)=\left(x^{24}-4x^{18}y^6+{6x}^{12}y^{12}-{4x}^6y^{18}+y^{24}\right)\cdot\sum_{k=0}^{\infty}\binom{3+k}{k}x^{-4-k}y^k x^{11}y^9 f\left(x,y\right)=\binom{3+9}{9}-4\binom{3+3}{3}=140.","['combinatorics', 'solution-verification']"
26,When adding zero really counts ...,When adding zero really counts ...,,"Note: Although adding zero has usually no effect, there is sometimes a situation where it is the essence of a calculation which drives the development into a surprisingly fruitful direction. Here is one example of what I mean. The Goulden-Jackson Cluster Method counts words built from a finite alphabet which are not allowed to contain so-called bad words . This method nicely presented (and something to chuckling about) by J. Noonan and D. Zeilberger is very efficient and the reason for it's efficiency is due to a clever addition of zeros. Let's denote the alphabet $V$, the language $\mathcal{L}$ and let $B$ be the set of bad words . Since we want to work with generating functions, we introduce weights on words $$weight(w):=s^{length(w)}$$ The generating function $f(s)$ is the weight enumerator of the set of valid words $\mathcal{L}(B)$ that avoids the members of $B$ as factors (i.e. substrings). We obtain   \begin{align*} f(s)=\sum_{w\in\mathcal{L}(B)}weight(w) \end{align*} It turns out according to the first section in the referred paper that counting these words is a cumbersome job. In fact we can do it much better and the trick is to add $0$ to both sides and rewrite this expression as   \begin{align*} f(s)=\sum_{w\in V^*}weight(w)0^{[\text{number of factors of }w\text{ that belong to }B]} \end{align*}   and then use the following deep facts (wording from the paper :-) )   \begin{align*} 0&=1+(-1)\\ 0^r&= \begin{cases} 1,&\text{if }r=0\\ 0,&\text{if }r>0 \end{cases} \end{align*}   and for any finite set $A$,   \begin{align*} \prod_{a\in A}0=\prod_{a\in A}(1+(-1))=\sum_{S\subset A}(-1)^{|S|} \end{align*}   where $|S|$ denotes the cardinality of $S$. We now have \begin{align*} f(s)&=\sum_{w\in V^*}weight(w)0^{[\text{number of factors of }w\text{ that belong to }B]}\\ &=\sum_{w\in V^*}weight(w)(1+(-1))^{[\text{number of factors of }w\text{ that belong to }B]}\\ &=\sum_{w\in V^*}\sum_{S\subset\text{Bad}(w)}(-1)^{|S|}s^{\text{length}(w)} \end{align*} where Bad$(w)$ is the set of factors of $w$ that belong to $B$. This clever usage of the Inclusion-exclusion principle is a much more superior approach to calculate the valid words not containing any bad factors and the essence was to add zero in order to introduce the IEP. So, my question is: Do you know from other situations where cleverly adding $0$ or multiplying with $1$ opens up a door to solve a problem.","Note: Although adding zero has usually no effect, there is sometimes a situation where it is the essence of a calculation which drives the development into a surprisingly fruitful direction. Here is one example of what I mean. The Goulden-Jackson Cluster Method counts words built from a finite alphabet which are not allowed to contain so-called bad words . This method nicely presented (and something to chuckling about) by J. Noonan and D. Zeilberger is very efficient and the reason for it's efficiency is due to a clever addition of zeros. Let's denote the alphabet $V$, the language $\mathcal{L}$ and let $B$ be the set of bad words . Since we want to work with generating functions, we introduce weights on words $$weight(w):=s^{length(w)}$$ The generating function $f(s)$ is the weight enumerator of the set of valid words $\mathcal{L}(B)$ that avoids the members of $B$ as factors (i.e. substrings). We obtain   \begin{align*} f(s)=\sum_{w\in\mathcal{L}(B)}weight(w) \end{align*} It turns out according to the first section in the referred paper that counting these words is a cumbersome job. In fact we can do it much better and the trick is to add $0$ to both sides and rewrite this expression as   \begin{align*} f(s)=\sum_{w\in V^*}weight(w)0^{[\text{number of factors of }w\text{ that belong to }B]} \end{align*}   and then use the following deep facts (wording from the paper :-) )   \begin{align*} 0&=1+(-1)\\ 0^r&= \begin{cases} 1,&\text{if }r=0\\ 0,&\text{if }r>0 \end{cases} \end{align*}   and for any finite set $A$,   \begin{align*} \prod_{a\in A}0=\prod_{a\in A}(1+(-1))=\sum_{S\subset A}(-1)^{|S|} \end{align*}   where $|S|$ denotes the cardinality of $S$. We now have \begin{align*} f(s)&=\sum_{w\in V^*}weight(w)0^{[\text{number of factors of }w\text{ that belong to }B]}\\ &=\sum_{w\in V^*}weight(w)(1+(-1))^{[\text{number of factors of }w\text{ that belong to }B]}\\ &=\sum_{w\in V^*}\sum_{S\subset\text{Bad}(w)}(-1)^{|S|}s^{\text{length}(w)} \end{align*} where Bad$(w)$ is the set of factors of $w$ that belong to $B$. This clever usage of the Inclusion-exclusion principle is a much more superior approach to calculate the valid words not containing any bad factors and the essence was to add zero in order to introduce the IEP. So, my question is: Do you know from other situations where cleverly adding $0$ or multiplying with $1$ opens up a door to solve a problem.",,"['combinatorics', 'analysis', 'big-list']"
27,Is the Young Symmetrizer defined as $c_T=a_T b_T$ or $c_T=b_T a_T$?,Is the Young Symmetrizer defined as  or ?,c_T=a_T b_T c_T=b_T a_T,"I have a question regarding the equivalence of two definitions of the young symmetrizer. First, some notation: let $\lambda$ be a partition of $n$. Given a $\lambda$-tableau $T$ (that is, a tableau of shape $\lambda$ filled with the entries $1,2,\ldots,n$), we define the row stabilizer of $T$ by $R(T)=S_{r_1} \times \dots \times S_{r_l}$ where $r_1, \dots, r_l$ are the rows of $T$, and analogously, we define the column stabilizer of $T$ as $C(T)=S_{c_1} \times \dots \times S_{c_k}$, where $c_1, \dots, c_k$ are the columns of $T$. (We regard both $R(T)$ and $C(T)$ as subgroups of the symmetric group $S_n$.) Let $a_T=\sum_{\sigma \in R(T)} \sigma $ and $b_T=\sum_{\tau \in C(T)} \mbox{sgn}(\tau) \tau $ be two elements of the group algebra $\mathbb C\left[S_n\right]$. Now, for my question: some references I've seen define $c_T = a_T b_T$ as the Young symmetrizer . The important thing for my purposes here is that this symmetrizer corresponds to an irreducible representation of $S_n$ indexed by $\lambda$.  However, I've seen other sources define the Young symmetrizer $b_T a_T$. The latter definition is more useful in something I'm working on, so I wanted to verify that this is correct. Does the second definition still correspond in the same way to the same irreducible representation of $S_n$? All of my intuition tells me it should, and I've tried out several examples with a computer algebra system, but I just want to be sure.","I have a question regarding the equivalence of two definitions of the young symmetrizer. First, some notation: let $\lambda$ be a partition of $n$. Given a $\lambda$-tableau $T$ (that is, a tableau of shape $\lambda$ filled with the entries $1,2,\ldots,n$), we define the row stabilizer of $T$ by $R(T)=S_{r_1} \times \dots \times S_{r_l}$ where $r_1, \dots, r_l$ are the rows of $T$, and analogously, we define the column stabilizer of $T$ as $C(T)=S_{c_1} \times \dots \times S_{c_k}$, where $c_1, \dots, c_k$ are the columns of $T$. (We regard both $R(T)$ and $C(T)$ as subgroups of the symmetric group $S_n$.) Let $a_T=\sum_{\sigma \in R(T)} \sigma $ and $b_T=\sum_{\tau \in C(T)} \mbox{sgn}(\tau) \tau $ be two elements of the group algebra $\mathbb C\left[S_n\right]$. Now, for my question: some references I've seen define $c_T = a_T b_T$ as the Young symmetrizer . The important thing for my purposes here is that this symmetrizer corresponds to an irreducible representation of $S_n$ indexed by $\lambda$.  However, I've seen other sources define the Young symmetrizer $b_T a_T$. The latter definition is more useful in something I'm working on, so I wanted to verify that this is correct. Does the second definition still correspond in the same way to the same irreducible representation of $S_n$? All of my intuition tells me it should, and I've tried out several examples with a computer algebra system, but I just want to be sure.",,"['combinatorics', 'finite-groups', 'representation-theory', 'definition', 'symmetric-groups']"
28,Combinatorial interpretation of this identity of Gauss?,Combinatorial interpretation of this identity of Gauss?,,"Gauss came up with some bizarre identities, namely $$ \sum_{n\in\mathbb{Z}}(-1)^nq^{n^2}=\prod_{k\geq 1}\frac{1-q^k}{1+q^k}. $$ How can this be interpreted combinatorially? It strikes me as being similar to many partition identities. Thanks.","Gauss came up with some bizarre identities, namely $$ \sum_{n\in\mathbb{Z}}(-1)^nq^{n^2}=\prod_{k\geq 1}\frac{1-q^k}{1+q^k}. $$ How can this be interpreted combinatorially? It strikes me as being similar to many partition identities. Thanks.",,"['combinatorics', 'theta-functions', 'q-series']"
29,Shuffling the digits of an integer so that the ratio between the resulting numbers is fixed.,Shuffling the digits of an integer so that the ratio between the resulting numbers is fixed.,,"Suppose we have a 3-digit integer with all digits distinct. If we create its two shift numbers (resulting by rotation of the original digits), the ratio between the two subsequent numbers (if we order them in ascending or descending order) must be fixed. Find this number. Suppose the number is xyz and the two resulting numbers, if we shift the digits to the right, are yzx and zxy. Assuming $xyz<yzx<zxy$ (there is no equal, since all digits are distinct), we want $\frac{zxy}{yzx} = \frac{yzx}{xyz} = k$ , where k: rational. Furthermore, it is easy to deduce that 0 is excluded, or one of the resulting numbers would be 2-digit. I have found 2 such sets of numbers, {243, 324, 432} and {486, 648, 864} and now I am trying to formulate an algebraic solution. If xyz is the original number, the first rotation is yzx and can be found as follows: $yzx = xyz*10+x-1000*x$ . Also $zxy= yzx*10+y-1000*y$ . Assuming wlg that $xyz<yzx<zxy$ , we must have $\frac{xyz*10+x-1000*x}{xyz} = \frac{yzx*10+y-1000*y}{xyz*10+x-1000*x} = k$ I also noticed that if the 3 numbers are in ascending order $xyz<yzx<zxy$ , then their differences $yzx-xyz$ and $zxy-yzx$ have the same 3 digits in rotation. but I don't think I can advance it any further...","Suppose we have a 3-digit integer with all digits distinct. If we create its two shift numbers (resulting by rotation of the original digits), the ratio between the two subsequent numbers (if we order them in ascending or descending order) must be fixed. Find this number. Suppose the number is xyz and the two resulting numbers, if we shift the digits to the right, are yzx and zxy. Assuming (there is no equal, since all digits are distinct), we want , where k: rational. Furthermore, it is easy to deduce that 0 is excluded, or one of the resulting numbers would be 2-digit. I have found 2 such sets of numbers, {243, 324, 432} and {486, 648, 864} and now I am trying to formulate an algebraic solution. If xyz is the original number, the first rotation is yzx and can be found as follows: . Also . Assuming wlg that , we must have I also noticed that if the 3 numbers are in ascending order , then their differences and have the same 3 digits in rotation. but I don't think I can advance it any further...",xyz<yzx<zxy \frac{zxy}{yzx} = \frac{yzx}{xyz} = k yzx = xyz*10+x-1000*x zxy= yzx*10+y-1000*y xyz<yzx<zxy \frac{xyz*10+x-1000*x}{xyz} = \frac{yzx*10+y-1000*y}{xyz*10+x-1000*x} = k xyz<yzx<zxy yzx-xyz zxy-yzx,"['combinatorics', 'number-theory']"
30,How many tickets should Paul buy?,How many tickets should Paul buy?,,"An old friend of mine who is now studying mathematics in Germany sent me an exercise from the German Mathematics Olympiads, which was thought for 16-years-old students. Since I used to participate in MO, my friend asked me to help him with this problem. Notwithstanding, I have the feeling that I am as lost as he is. Here the problem! In a lottery, you are given tickets with the numbers $1,2,...,49$ , of which exactly six must be ticked. In the lotto draw, seven of these 49 numbers are drawn. If at least three of the numbers marked on a lotto ticket belong to the seven numbers drawn, the lottery player has won a ""third"". Paul wants to play the lottery and win a third in any case. He fills in $n$ lottery tickets and marks exactly six numbers on each ticket. Determine the smallest $n$ , such that Paul can play in a way that he is guaranteed to have a third on at least one of his lotto tickets. At first, I evaluated the number $t$ of tripels among the $49$ numbers you can choose: $$t=\binom{49}{3}=18424$$ Out of these $18424$ tripels, $\binom{7}{3}=35$ lead Paul to win. Now, every set of $6$ numbers -the ones chosen by Paul- contains $s$ different tripels $$s=\binom{6}{3}=20$$ How should I continue? What's the solution? Thanks in advance and please don't hesitate to edit the question in order to improve language mistakes. Fun fact: The solution did not require to prove that the given $n$ was, in fact, minimal. It sufficed with showing that $n$ allowed Paul to win. Therefore, when it came to grading ( max. $7$ points), the jury did not only take the correctness of the proof into consideration, but also how small $n$ was in comparison to the answers given by other competitors.","An old friend of mine who is now studying mathematics in Germany sent me an exercise from the German Mathematics Olympiads, which was thought for 16-years-old students. Since I used to participate in MO, my friend asked me to help him with this problem. Notwithstanding, I have the feeling that I am as lost as he is. Here the problem! In a lottery, you are given tickets with the numbers , of which exactly six must be ticked. In the lotto draw, seven of these 49 numbers are drawn. If at least three of the numbers marked on a lotto ticket belong to the seven numbers drawn, the lottery player has won a ""third"". Paul wants to play the lottery and win a third in any case. He fills in lottery tickets and marks exactly six numbers on each ticket. Determine the smallest , such that Paul can play in a way that he is guaranteed to have a third on at least one of his lotto tickets. At first, I evaluated the number of tripels among the numbers you can choose: Out of these tripels, lead Paul to win. Now, every set of numbers -the ones chosen by Paul- contains different tripels How should I continue? What's the solution? Thanks in advance and please don't hesitate to edit the question in order to improve language mistakes. Fun fact: The solution did not require to prove that the given was, in fact, minimal. It sufficed with showing that allowed Paul to win. Therefore, when it came to grading ( max. points), the jury did not only take the correctness of the proof into consideration, but also how small was in comparison to the answers given by other competitors.","1,2,...,49 n n t 49 t=\binom{49}{3}=18424 18424 \binom{7}{3}=35 6 s s=\binom{6}{3}=20 n n 7 n","['combinatorics', 'contest-math', 'gambling', 'combinatorial-designs', 'lotteries']"
31,Finding equal partial sum given two $N$-tuples of natural numbers,Finding equal partial sum given two -tuples of natural numbers,N,"This is an interesting question which I haven't found anyone addressing it. Let $N$ be a fixed natural number, $(a_1, \cdots, a_N), (b_1, \cdots, b_N)$ two $N$-tuples of natural numbers with $a_i, b_j \in \{1, 2. \cdots, N\}$. Does there exist a subcollection $(a_{i_1}, \cdots, a_{i_k})$, $(b_{j_1}, \cdots, b_{j_l})$ so that    $$a_{i_1} + \cdots + a_{i_k} = b_{j_1} + \cdots + b_{j_l}?$$ Example : say $N=3$. Consider $(1,1,2)$ and $(1,3,3)$. Obviously there are equal partial sums.  Take $1, 2$ from the first triples and $3$ from the second, we got $1+2 =3$. Or , you can find another equal sum: Take $1 =1$ for example. For example for $N=4$. Similarly we can always find an equal sum. Let's check this with a few trials. Say we have $$(4, 4,4,4), (3,3,3,2).$$ We can find at least one equal sum as follows: $4+4 =3+3+2$. Another trial : $(1,1,1,1)$, $(2,3,2,3)$. We can find easily even more than one equal sum: $1+1=2$, $1+1+1 =3$ etc... I always found equal partial sums. I couldn't find a counter example. I am asking either for a counter example or a proof. Remark :  I know that the statement is true for two $2N$-tuples with numbers ranged from $1$ to $N$. In this case the proof is easy with the pigeonhole principle. You must get two subgroups which are equal. Moreover you would get sequences which are equal. But would that hold true for sets of length $N$? The simple proof that works for $2N$ wouldn't hold here. On the other hand I couldn't find any counter example for $N$. Is it true or not?  Is it possible to prove one way or the other?","This is an interesting question which I haven't found anyone addressing it. Let $N$ be a fixed natural number, $(a_1, \cdots, a_N), (b_1, \cdots, b_N)$ two $N$-tuples of natural numbers with $a_i, b_j \in \{1, 2. \cdots, N\}$. Does there exist a subcollection $(a_{i_1}, \cdots, a_{i_k})$, $(b_{j_1}, \cdots, b_{j_l})$ so that    $$a_{i_1} + \cdots + a_{i_k} = b_{j_1} + \cdots + b_{j_l}?$$ Example : say $N=3$. Consider $(1,1,2)$ and $(1,3,3)$. Obviously there are equal partial sums.  Take $1, 2$ from the first triples and $3$ from the second, we got $1+2 =3$. Or , you can find another equal sum: Take $1 =1$ for example. For example for $N=4$. Similarly we can always find an equal sum. Let's check this with a few trials. Say we have $$(4, 4,4,4), (3,3,3,2).$$ We can find at least one equal sum as follows: $4+4 =3+3+2$. Another trial : $(1,1,1,1)$, $(2,3,2,3)$. We can find easily even more than one equal sum: $1+1=2$, $1+1+1 =3$ etc... I always found equal partial sums. I couldn't find a counter example. I am asking either for a counter example or a proof. Remark :  I know that the statement is true for two $2N$-tuples with numbers ranged from $1$ to $N$. In this case the proof is easy with the pigeonhole principle. You must get two subgroups which are equal. Moreover you would get sequences which are equal. But would that hold true for sets of length $N$? The simple proof that works for $2N$ wouldn't hold here. On the other hand I couldn't find any counter example for $N$. Is it true or not?  Is it possible to prove one way or the other?",,"['combinatorics', 'contest-math', 'pigeonhole-principle']"
32,"Partitioning $\{1,2,\ldots,k\}$ into $p$ subsets with equal sums, where $p$ is prime","Partitioning  into  subsets with equal sums, where  is prime","\{1,2,\ldots,k\} p p","Let $p$ be a prime natural number. For which positive integer $k$ can the set $\{1,2,\ldots,k\}$ be partitioned into $p$ subsets with equal sums of elements ? Obviously, $p\mid k(k+1)$ . Hence, $p\mid k$ or $p\mid k+1$ . All we have to do now is to show a construction. But I can't find one. I have tried partitioning the set and choose one element from each set but that hasn't yielded anything. Any hint will be appreciated.","Let be a prime natural number. For which positive integer can the set be partitioned into subsets with equal sums of elements ? Obviously, . Hence, or . All we have to do now is to show a construction. But I can't find one. I have tried partitioning the set and choose one element from each set but that hasn't yielded anything. Any hint will be appreciated.","p k \{1,2,\ldots,k\} p p\mid k(k+1) p\mid k p\mid k+1","['combinatorics', 'elementary-number-theory', 'discrete-mathematics', 'contest-math', 'divisibility']"
33,Elementary Combinatorial Proofs using group action,Elementary Combinatorial Proofs using group action,,"In trying to prove that the number of spanning trees in $K_5$ is $125$ I adopted the following method: Let $S$ be the set of all such spanning trees and let $S_5$ act in a natural way on $S$. Now exactly three nonisomorphic spanning trees $T_1=K_{1,4},T_2=P_5,T_3=\text{chair}$ are possible with $\text{Stab}(T_i)=\text{Aut}(T_i)$. As $|\text{Orbit}(T_i)|=\frac{|S_5|}{|\text{Stab}(T_i)|}$ and as $S$ is a disjoint union of the three orbits so we have: $$|S|=\frac{5!}{4!}+\frac{5!}{2!}+\frac{5!}{2!}=125.$$ This result can be obtained purely by counting arguments as well, but I find the above proof more satisfying. What are some other elementary counting proofs in combinatorics which can be interpreted in terms of group action? Here is another example of the type of results that I am looking for: The number of ways of choosing $k$ distinct objects out of $n$ where   the order matters is $\frac{n!}{(n-k)!}$. Proof: Suppose $G=S_n$ and $X=\cup_{m=1}^n \{(x_1,\ldots,x_m):x_i\ne x_j\text{ for }i\ne j, x_i\in[n]\}$. The function from $G\times X$ to $X$ defined by $\sigma\cdot (x_1,\ldots,x_m)=(\sigma(x_1),\ldots,\sigma(x_m))$ is clearly a group action. Let $x=(x_1,\ldots,x_k)\in X$. Then $\mathcal{O}_x$ is precisely the collection of all $k$-tuples from $[n]$ where each coordinate is different. Our proof will be finished if we show that $|\mathcal{O}_x|=\frac{n!}{(n-k)!}$. Note that the permutations which fix $x$ and thereby each $x_i$ are exactly those which permute elements other then $x_1,\ldots,x_k$ and such permutations are precisely $(n-k)!$ in number. So $|G_x|=(n-k)!$. The result now follows by invoking the orbit stabilizer theorem. A similar result $\tbinom{n}{k}=\frac{n!}{k!(n-k)!}$ can be obtained by letting $X$ to be the set of all $k$-subsets of $[n]$.","In trying to prove that the number of spanning trees in $K_5$ is $125$ I adopted the following method: Let $S$ be the set of all such spanning trees and let $S_5$ act in a natural way on $S$. Now exactly three nonisomorphic spanning trees $T_1=K_{1,4},T_2=P_5,T_3=\text{chair}$ are possible with $\text{Stab}(T_i)=\text{Aut}(T_i)$. As $|\text{Orbit}(T_i)|=\frac{|S_5|}{|\text{Stab}(T_i)|}$ and as $S$ is a disjoint union of the three orbits so we have: $$|S|=\frac{5!}{4!}+\frac{5!}{2!}+\frac{5!}{2!}=125.$$ This result can be obtained purely by counting arguments as well, but I find the above proof more satisfying. What are some other elementary counting proofs in combinatorics which can be interpreted in terms of group action? Here is another example of the type of results that I am looking for: The number of ways of choosing $k$ distinct objects out of $n$ where   the order matters is $\frac{n!}{(n-k)!}$. Proof: Suppose $G=S_n$ and $X=\cup_{m=1}^n \{(x_1,\ldots,x_m):x_i\ne x_j\text{ for }i\ne j, x_i\in[n]\}$. The function from $G\times X$ to $X$ defined by $\sigma\cdot (x_1,\ldots,x_m)=(\sigma(x_1),\ldots,\sigma(x_m))$ is clearly a group action. Let $x=(x_1,\ldots,x_k)\in X$. Then $\mathcal{O}_x$ is precisely the collection of all $k$-tuples from $[n]$ where each coordinate is different. Our proof will be finished if we show that $|\mathcal{O}_x|=\frac{n!}{(n-k)!}$. Note that the permutations which fix $x$ and thereby each $x_i$ are exactly those which permute elements other then $x_1,\ldots,x_k$ and such permutations are precisely $(n-k)!$ in number. So $|G_x|=(n-k)!$. The result now follows by invoking the orbit stabilizer theorem. A similar result $\tbinom{n}{k}=\frac{n!}{k!(n-k)!}$ can be obtained by letting $X$ to be the set of all $k$-subsets of $[n]$.",,"['combinatorics', 'group-theory']"
34,Prove that $\exp(\log(\frac{1}{1-x})) = \frac{1}{1-x}$,Prove that,\exp(\log(\frac{1}{1-x})) = \frac{1}{1-x},"I am trying to prove this directly by comparing the coefficients in the two series rather than using formal calculus. Here is what I have so far, but I think I made a mistake: \begin{align*} e^{\log\frac{1}{1-x}} &= \sum_{n\geq0}\frac{1}{n!}\left(\log\frac{1}{1-x}\right)^n\\ &= 1+\sum_{n\ge1}\frac{1}{n!}\sum_{k\geq 1}\sum_{i_1+\dotsb+i_n=k}\frac{x^k}{i_1\dotsb i_n} \end{align*} Is this correct so far? If so, how do I proceed? EDIT: \begin{align*} \log\left(\frac{1}{1-x}\right) &= \sum_{k\geq1}\frac{x^k}{k}\\ e^x &= \sum_{n\geq 0} \frac{x^n}{n!} \end{align*} The composition is well defined since the constant term of $\log(\frac{1}{1-x})$ is 0.","I am trying to prove this directly by comparing the coefficients in the two series rather than using formal calculus. Here is what I have so far, but I think I made a mistake: \begin{align*} e^{\log\frac{1}{1-x}} &= \sum_{n\geq0}\frac{1}{n!}\left(\log\frac{1}{1-x}\right)^n\\ &= 1+\sum_{n\ge1}\frac{1}{n!}\sum_{k\geq 1}\sum_{i_1+\dotsb+i_n=k}\frac{x^k}{i_1\dotsb i_n} \end{align*} Is this correct so far? If so, how do I proceed? EDIT: \begin{align*} \log\left(\frac{1}{1-x}\right) &= \sum_{k\geq1}\frac{x^k}{k}\\ e^x &= \sum_{n\geq 0} \frac{x^n}{n!} \end{align*} The composition is well defined since the constant term of $\log(\frac{1}{1-x})$ is 0.",,"['combinatorics', 'binomial-coefficients', 'power-series', 'generating-functions']"
35,Minimum number of integer-sided squares needed to tile an $m$ by $n$ rectangle.,Minimum number of integer-sided squares needed to tile an  by  rectangle.,m n,"Let $T(m,n)$ for integers $m,n$ be the least number of integer-sided squares needed to tile an $m\times n$ rectangle. Clearly $T(kx,ky)\leq T(x,y)$. Are there integers $x,y,k\gt 1$, such that $T(kx,ky)<T(x,y)$?","Let $T(m,n)$ for integers $m,n$ be the least number of integer-sided squares needed to tile an $m\times n$ rectangle. Clearly $T(kx,ky)\leq T(x,y)$. Are there integers $x,y,k\gt 1$, such that $T(kx,ky)<T(x,y)$?",,"['combinatorics', 'number-theory', 'packing-problem', 'tiling', 'extremal-combinatorics']"
36,What does the minimal eigenvalue of a graph say about the graph's connectivity?,What does the minimal eigenvalue of a graph say about the graph's connectivity?,,"I'm reading Fan Chung's Spectral Graph Theory , and I'm now in chapter 2.  There, Chung proves Cheeger's inequality , which is that $2h_G \geq \lambda_1 > h_G^2/2$ for any graph $G$.  To me, this inequality raises the question of a physical interpretation of $\lambda_1$ and I'm wondering if such an interpretation exists.  Below, I'll explain this terminology and ask my question a little more precisely. Let $G$ be a graph with vertex set $V$, with $\#V =n$.  The Laplacian of $G$ is the $n\times n$ matrix $\mathcal{L}$ whose $(u,v)^{\text{th}}$ entry is $\text{deg}(v)$ if $u=v$, $-(\text{deg}(u)\text{deg}(v))^{-1/2}$ if $u$ and $v$ are adjacent vertices, and $0$ otherwise.  The eigenvalues of $\mathcal{L}$ are called the eigenvalues of $G$ and are denoted by $\lambda_0 \leq \lambda_1 \leq \dots \leq \lambda_{n-1}$.  It's not too hard to show that $\lambda_0$ is always $0$, so we normally refer to $\lambda_1$ as the minimal eigenvalue of $G$. If $S\subset V$ (with $S\neq V$) then we define $\overline{S} := V-S$ and $E(S,\overline{S})$ to be the set of edges of $G$ with one vertex in $S$ and the other in $\overline{S}$.  Also, let the volume of $S$ be defined as $\text{vol}(S) := \sum_{v \in S} \text{deg}(v)$. We then define $$ h_G(S) := \frac{\# E(S,\overline{S})}{\text{min}(\text{vol}(S),\text{vol}(\overline{S}))}.$$  The Cheeger constant of $G$ is defined to be $h_G := \min_{S \subset V} h_G(S)$. It's clear from the definition that the Cheeger constant measures how much the graph ""bottlenecks"" somewhere (to borrow Wikipedia's apt description).  Loosely speaking, if Cheeger's constant is small then there's a small set of edges that you can remove from the graph to disconnect it into two relatively large and relatively connected subgraphs. Now, it doesn't seem like $\lambda_1$ (which equals the minimal Rayleigh quotient over the space of harmonic eigenfunctions) would have much of a physical interpretation.  However,  Cheeger's inequality traps $\lambda_1$ fairly close to $h_G$, so it is some loose measure of bottlenecking.  Also, there are other little hints in the text I've read so far that $\lambda_1$ might be related to the graph's connectedness.  For instance, she proves $\lambda_1 = 0$ if and only if $G$ is disconnected and that $\lambda_1 \geq 1/D\text{vol}(G)$, where $D$ is the length of the maximal-length path in $G$. So I'm wondering if there is a meaningful physical interpretation of $\lambda_1$ that is more precise than ""it's bounded near something that is meaningful.""","I'm reading Fan Chung's Spectral Graph Theory , and I'm now in chapter 2.  There, Chung proves Cheeger's inequality , which is that $2h_G \geq \lambda_1 > h_G^2/2$ for any graph $G$.  To me, this inequality raises the question of a physical interpretation of $\lambda_1$ and I'm wondering if such an interpretation exists.  Below, I'll explain this terminology and ask my question a little more precisely. Let $G$ be a graph with vertex set $V$, with $\#V =n$.  The Laplacian of $G$ is the $n\times n$ matrix $\mathcal{L}$ whose $(u,v)^{\text{th}}$ entry is $\text{deg}(v)$ if $u=v$, $-(\text{deg}(u)\text{deg}(v))^{-1/2}$ if $u$ and $v$ are adjacent vertices, and $0$ otherwise.  The eigenvalues of $\mathcal{L}$ are called the eigenvalues of $G$ and are denoted by $\lambda_0 \leq \lambda_1 \leq \dots \leq \lambda_{n-1}$.  It's not too hard to show that $\lambda_0$ is always $0$, so we normally refer to $\lambda_1$ as the minimal eigenvalue of $G$. If $S\subset V$ (with $S\neq V$) then we define $\overline{S} := V-S$ and $E(S,\overline{S})$ to be the set of edges of $G$ with one vertex in $S$ and the other in $\overline{S}$.  Also, let the volume of $S$ be defined as $\text{vol}(S) := \sum_{v \in S} \text{deg}(v)$. We then define $$ h_G(S) := \frac{\# E(S,\overline{S})}{\text{min}(\text{vol}(S),\text{vol}(\overline{S}))}.$$  The Cheeger constant of $G$ is defined to be $h_G := \min_{S \subset V} h_G(S)$. It's clear from the definition that the Cheeger constant measures how much the graph ""bottlenecks"" somewhere (to borrow Wikipedia's apt description).  Loosely speaking, if Cheeger's constant is small then there's a small set of edges that you can remove from the graph to disconnect it into two relatively large and relatively connected subgraphs. Now, it doesn't seem like $\lambda_1$ (which equals the minimal Rayleigh quotient over the space of harmonic eigenfunctions) would have much of a physical interpretation.  However,  Cheeger's inequality traps $\lambda_1$ fairly close to $h_G$, so it is some loose measure of bottlenecking.  Also, there are other little hints in the text I've read so far that $\lambda_1$ might be related to the graph's connectedness.  For instance, she proves $\lambda_1 = 0$ if and only if $G$ is disconnected and that $\lambda_1 \geq 1/D\text{vol}(G)$, where $D$ is the length of the maximal-length path in $G$. So I'm wondering if there is a meaningful physical interpretation of $\lambda_1$ that is more precise than ""it's bounded near something that is meaningful.""",,"['combinatorics', 'graph-theory', 'eigenvalues-eigenvectors', 'spectral-graph-theory']"
37,"How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object?","How to find the number of -permutations of  objects with  types, and  = the number of each type of object?","k n x r_1, r_2, r_3, \cdots , r_x","How can I find the number of $k$ -permutations of $n$ objects, where there are $x$ types of objects, and $r_1, r_2, r_3, \cdots , r_x$ give the number of each type of object? I'm still looking for the solution to this more general problem out of interest. Here is an example with $n = 20, k = 15, x = 4,$ $ r_1 = 4 \quad r_2 = 5 \quad r_3 = 8 \quad r_4 = 3$ . I have 20 letters from the alphabet. There are some duplicates - 4 of them are a , 5 of them are b , 8 of them are c , and 3 are d . How many unique 15-letter permutations can I make? Edits: I've done some more work on this problem but haven't really come up with anything useful. Intuition tells me that as Douglas suggests below there will probably not be an easy solution. However, I haven't been able to prove that for sure - does anyone else have any ideas? I've now re-asked this question  on MO .","How can I find the number of -permutations of objects, where there are types of objects, and give the number of each type of object? I'm still looking for the solution to this more general problem out of interest. Here is an example with . I have 20 letters from the alphabet. There are some duplicates - 4 of them are a , 5 of them are b , 8 of them are c , and 3 are d . How many unique 15-letter permutations can I make? Edits: I've done some more work on this problem but haven't really come up with anything useful. Intuition tells me that as Douglas suggests below there will probably not be an easy solution. However, I haven't been able to prove that for sure - does anyone else have any ideas? I've now re-asked this question  on MO .","k n x r_1, r_2, r_3, \cdots , r_x n = 20, k = 15, x = 4,  r_1 = 4 \quad r_2 = 5 \quad r_3 = 8 \quad r_4 = 3","['combinatorics', 'multisets']"
38,A Vandermonde Identity for Stirling Numbers?,A Vandermonde Identity for Stirling Numbers?,,"I'm facing the problem of trying to express a quantity in the simplest possible way (it is, using the least possible number of sum symbols). $$ \sum_{j=0}^{n} \sum_{\ell=0}^m \frac{1}{j!}\binom{b+j}{j} {j+1 \brack {\ell+1}} {b+2 \brack {m-\ell+1}}$$ Of course, this can be easily written as a convolution between two polynomials (which happen to be more or less simple). I'm pretty sure that approach will not work (at most, one can write the above expression as ""the coefficient of $x^m$ in this product [...]"", but that is not useful to my purpose). However, if one explores this sum a little bit, it pretty soon come up the fact that it could be truly useful to, for example, be able to compute this: $$\sum_{\ell=0}^m {j+1\brack{\ell+1}}{b+2 \brack {m-\ell+1}}$$ (which resembles a lot Vandermonde's Identity, but with Stirling numbers instead of binomial coefficients). I looked up on a couple of books (Concrete Mathematics of Graham-Knuth-Patashnik, and others), and I couldn't find any references pointing to such an identity. Does anybody know something like that? (Perhaps involving other weird numbers as Eulerian or double Eulerian or that kind of stuff?) Nevertheless, any kind of help simplifying the first double sum would be really appreciated.","I'm facing the problem of trying to express a quantity in the simplest possible way (it is, using the least possible number of sum symbols). Of course, this can be easily written as a convolution between two polynomials (which happen to be more or less simple). I'm pretty sure that approach will not work (at most, one can write the above expression as ""the coefficient of in this product [...]"", but that is not useful to my purpose). However, if one explores this sum a little bit, it pretty soon come up the fact that it could be truly useful to, for example, be able to compute this: (which resembles a lot Vandermonde's Identity, but with Stirling numbers instead of binomial coefficients). I looked up on a couple of books (Concrete Mathematics of Graham-Knuth-Patashnik, and others), and I couldn't find any references pointing to such an identity. Does anybody know something like that? (Perhaps involving other weird numbers as Eulerian or double Eulerian or that kind of stuff?) Nevertheless, any kind of help simplifying the first double sum would be really appreciated.", \sum_{j=0}^{n} \sum_{\ell=0}^m \frac{1}{j!}\binom{b+j}{j} {j+1 \brack {\ell+1}} {b+2 \brack {m-\ell+1}} x^m \sum_{\ell=0}^m {j+1\brack{\ell+1}}{b+2 \brack {m-\ell+1}},"['combinatorics', 'summation', 'binomial-coefficients', 'stirling-numbers']"
39,Why are braid numbers of the form $Q_h^2$ or $2 \times Q_h^2$?,Why are braid numbers of the form  or ?,Q_h^2 2 \times Q_h^2,"Consider two piles of $h$ playing cards each, all distinct. Repeatedly take one of the cards on top of one of these two piles and move it on top of one of two new piles, until both of the new piles are of height $h$. How many different configurations can you end up with? I did some computing and found the values in the table below. I noticed that the number of possible configurations seems to be either a square or twice a square, depending on $h$ modulo $2$. I don't see why however, and I haven't been able to spot a pattern in the $Q_h$ values either. $$\begin{array}{lrr} h & {\frak B}((h,h)\rightarrow(h,h)) & 2^{h \pmod{2}} \times Q_h^2\\ 0 & 1 & 1^2\\ 1 & 2 & 2 \times 1^2\\ 2 & 16 & 4^2\\ 3 & 128 & 2 \times 8^2\\ 4 & 1,\!156 & 34^2\\ 5 & 10,\!952 & 2 \times 74^2\\ 6 & 107,\!584 & 328^2\\ 7 & 1,\!083,\!392 & 2 \times 736^2\\ 8 & 11,\!115,\!556 & 3,\!334^2\\ 9 & 115,\!702,\!472 & 2 \times 7,\!606^2\\ 10 & 1,\!218,\!289,\!216 & 34,\!904^2\\ 11 & 12,\!948,\!910,\!592 & 2 \times 80,\!464^2\\ 12 & 138,\!708,\!574,\!096 & 372,\!436^2\\ 13 & 1,\!495,\!661,\!223,\!968 & 2 \times 864,\!772^2\\ 14 & 16,\!218,\!468,\!710,\!656 & 4,\!027,\!216^2\\ 15 & 176,\!727,\!219,\!273,\!728 & 2 \times 9,\!400,\!192^2\\ 16 & 1,\!933,\!956,\!651,\!447,\!076 & 43,\!976,\!774^2\\ 17 & 21,\!243,\!204,\!576,\!601,\!928 & 2 \times 103,\!061,\!158^2\\ 18 & 234,\!121,\!111,\!199,\!439,\!424 & 483,\!860,\!632^2\\ 19 & 2,\!587,\!943,\!032,\!046,\!002,\!688 & 2 \times 1,\!137,\!528,\!688^2\\ \end{array}$$ Does anyone have an insight? Most people whom I've asked to give the problem some thought, have answered $\sum_{i=0}^h\binom{h}{i}^4$ in a reflex, but this is only an upper bound. (As a side note, when considering the case where you go from $k$ piles of height $2$ to $k$ new piles of height $2$, I found the formula $\frac{3k-2}{4k-2}(2k)!$. Cute, but seemingly entirely different.)","Consider two piles of $h$ playing cards each, all distinct. Repeatedly take one of the cards on top of one of these two piles and move it on top of one of two new piles, until both of the new piles are of height $h$. How many different configurations can you end up with? I did some computing and found the values in the table below. I noticed that the number of possible configurations seems to be either a square or twice a square, depending on $h$ modulo $2$. I don't see why however, and I haven't been able to spot a pattern in the $Q_h$ values either. $$\begin{array}{lrr} h & {\frak B}((h,h)\rightarrow(h,h)) & 2^{h \pmod{2}} \times Q_h^2\\ 0 & 1 & 1^2\\ 1 & 2 & 2 \times 1^2\\ 2 & 16 & 4^2\\ 3 & 128 & 2 \times 8^2\\ 4 & 1,\!156 & 34^2\\ 5 & 10,\!952 & 2 \times 74^2\\ 6 & 107,\!584 & 328^2\\ 7 & 1,\!083,\!392 & 2 \times 736^2\\ 8 & 11,\!115,\!556 & 3,\!334^2\\ 9 & 115,\!702,\!472 & 2 \times 7,\!606^2\\ 10 & 1,\!218,\!289,\!216 & 34,\!904^2\\ 11 & 12,\!948,\!910,\!592 & 2 \times 80,\!464^2\\ 12 & 138,\!708,\!574,\!096 & 372,\!436^2\\ 13 & 1,\!495,\!661,\!223,\!968 & 2 \times 864,\!772^2\\ 14 & 16,\!218,\!468,\!710,\!656 & 4,\!027,\!216^2\\ 15 & 176,\!727,\!219,\!273,\!728 & 2 \times 9,\!400,\!192^2\\ 16 & 1,\!933,\!956,\!651,\!447,\!076 & 43,\!976,\!774^2\\ 17 & 21,\!243,\!204,\!576,\!601,\!928 & 2 \times 103,\!061,\!158^2\\ 18 & 234,\!121,\!111,\!199,\!439,\!424 & 483,\!860,\!632^2\\ 19 & 2,\!587,\!943,\!032,\!046,\!002,\!688 & 2 \times 1,\!137,\!528,\!688^2\\ \end{array}$$ Does anyone have an insight? Most people whom I've asked to give the problem some thought, have answered $\sum_{i=0}^h\binom{h}{i}^4$ in a reflex, but this is only an upper bound. (As a side note, when considering the case where you go from $k$ piles of height $2$ to $k$ new piles of height $2$, I found the formula $\frac{3k-2}{4k-2}(2k)!$. Cute, but seemingly entirely different.)",,"['combinatorics', 'problem-solving']"
40,How many meetings would it take for 12 people to meet in 4 groups of 3 until they met everyone?,How many meetings would it take for 12 people to meet in 4 groups of 3 until they met everyone?,,I have a group of 12 people that I would like to meet in four groups of three each month.  How many minimum months would it take such that each person has been in at least one group with every other person? Below is the brute force method I used to get it to seven months:,I have a group of 12 people that I would like to meet in four groups of three each month.  How many minimum months would it take such that each person has been in at least one group with every other person? Below is the brute force method I used to get it to seven months:,,"['combinatorics', 'combinatorial-designs']"
41,How close are the closests cells of the same color in a periodically colored grid?,How close are the closests cells of the same color in a periodically colored grid?,,"In a square grid, if we have a coloring of the form $c(x, y) = (x + ny) \bmod m$ , what is the minimum (positive!) taxicab distance (i.e. sum of absolute value fo coordinates) between different cells of the same color? (In this example I colored all values except for 0 the same color. We are interested in the distance between yellow cells.) This is the same as minimizing the following function, $$d(m, n) = |mk + n\ell| + |\ell|$$ for fixed $0 \leq m < n$ , and $k, \ell$ are integers that can be chosen freely (not both 0). Ideally, I would like a formula for the minimum value of $d$ in terms of $m$ and $n$ . For the example shown above, $m = 7, n = 3$ , and we find the minimum of $d$ to be $3$ (with $k = -1$ and $\ell = 2$ ). It looks like this should be very easy but I find it tricky in the general case. Background: I came across this question: Minimum colors needed to color Z2 with connected subsets restriction , where a specific instance of this problem is used in the answer. This is also related to another question I asked: What is the minimum distance between vertices on an integer grid with the form $(m(m+2), 0)p + (m, 1)q$ ? (Although in that question the Euclidean distance rather than the taxicab distance is being minimized.) Update: I wrote a program to calculate the value of $d(m, n)$ . There are obviously patterns, although I have not worked out exactly what. Here is the same data arranged in a triangle; obviously factors play a role. One interesting observation: the maximum value in each row (for fixed $m$ ), is roughly $\sqrt{2m}$ , and in fact exactly $\sqrt{2m}$ for $m = 2, 8, 18, 32, ...$ (whenever $m$ is double a perfect square).","In a square grid, if we have a coloring of the form , what is the minimum (positive!) taxicab distance (i.e. sum of absolute value fo coordinates) between different cells of the same color? (In this example I colored all values except for 0 the same color. We are interested in the distance between yellow cells.) This is the same as minimizing the following function, for fixed , and are integers that can be chosen freely (not both 0). Ideally, I would like a formula for the minimum value of in terms of and . For the example shown above, , and we find the minimum of to be (with and ). It looks like this should be very easy but I find it tricky in the general case. Background: I came across this question: Minimum colors needed to color Z2 with connected subsets restriction , where a specific instance of this problem is used in the answer. This is also related to another question I asked: What is the minimum distance between vertices on an integer grid with the form ? (Although in that question the Euclidean distance rather than the taxicab distance is being minimized.) Update: I wrote a program to calculate the value of . There are obviously patterns, although I have not worked out exactly what. Here is the same data arranged in a triangle; obviously factors play a role. One interesting observation: the maximum value in each row (for fixed ), is roughly , and in fact exactly for (whenever is double a perfect square).","c(x, y) = (x + ny) \bmod m d(m, n) = |mk + n\ell| + |\ell| 0 \leq m < n k, \ell d m n m = 7, n = 3 d 3 k = -1 \ell = 2 (m(m+2), 0)p + (m, 1)q d(m, n) m \sqrt{2m} \sqrt{2m} m = 2, 8, 18, 32, ... m","['combinatorics', 'integer-programming', 'discrete-geometry']"
42,Conjecture about reversal operations on strings (with duplicates),Conjecture about reversal operations on strings (with duplicates),,"Note : If you can find a proof of this, please give me just a hint first, so I can try to solve it on my own. Let $\Sigma$ be a finite alphabet (set of symbols) and $s,t\in\Sigma^\ast$ two strings (sequences of symbols) of equal length $n$ over $\Sigma$ . We denote by $s_i\in \Sigma$ the $i$ -th symbol of $s$ , and by $as\in\Sigma^{n+1}$ the concatenation of the symbol $a\in\Sigma$ with $s\in\Sigma^n$ . First, define a reversal operation $\text{r}(i,j)$ on $s$ as the operation: $$s=s_1...s_n\quad\mapsto\quad s_1...s_{i-1}\ \ s_j s_{j-1}...s_{i+1}s_i\ \ s_{j+1}...s_n$$ that extracts the substring $s_i\dots s_j$ from $s$ , reverses it, and puts it back in the same place, where $1 \le i\le j \le n$ . Then, define the reversal distance $d_r(s,t)$ between $s$ and $t$ as the minimum number of reversal operations (on either $s$ or $t$ ) needed to transform $s$ into $t$ ( $d_r(s,t):=\infty$ if not possible). Conjecture : Let $a\in\Sigma$ and $s,t\in\Sigma^n$ . Prove (or find a counterexample) that: $$d_r(as,at)=d_r(s,t)$$ (In other terms, we can disregard the longest common prefix between two given strings when transforming one into the other.) Note that $a$ can occur in $s,t$ . Example : $a=1,\ s=23141,\ t=41123$ $$ \begin{array}{cl|cl} as\to^2 at           &                & s\to^2 t          &                \\ \hline \underline{1\ 23}141 & \text{r}(1,3)\ & \underline{2314}1 & \text{r}(1,4)\ \\  \underline{3\ 21141} & \text{r}(1,6)\ & 41\underline{321} & \text{r}(3,5)\ \\             1\ 41123  &                & 41123             &                \\ \hline \end{array} $$ A few remarks: That $d_r(as,at)\le d_r(s,t)$ is obvious, the converse less so. If $n\gt 0$ and $d_r(as,at)=1$ then $d_r(s,t)=1$ . If $n\gt 0$ and $a$ does not occur in $s,t$ , then it must return at the initial position at some point. Therefore, the same reversal operations that transform $as$ into $at$ can be easily adjusted to transform $s$ into $t$ , so that the relative positions between all the other symbols excluding $a$ remain the same. This implies the conjecture in this case. Induction alone doesn't seem to be powerful enough. Also, most results I've found in the literature either provide lower/upper bounds on the minimum $k$ , or concern the computational complexity of this kind of problems, collectively known as sorting by reversals . I tested it via computer on random instances up to a reasonably high $n$ and it seems to hold. I've edited this question numerous times, mainly to consider some variation of the conjecture. We write $s\to^k t$ if $s$ can be transformed into $t$ by application of exactly $k$ reversals: Assume $i\lt j$ (i.e. $\text{r}(i,i)$ are disallowed). Prove that if $as\to^k at$ then $s\to^k t$ . Counterexample: $$ \begin{array}{cl|cl} as\to^1 at               &                & s\to^1 t  &     \\ \hline \underline{1\ 1}23123... & \text{r}(1,2)\ & 123123... & ? \ \\             1\ 123123...  &                & 123123... &     \\ \hline \end{array} $$ Assume $i\lt j$ (i.e. $\text{r}(i,i)$ are disallowed). Prove that if $as\to^k at$ and $s\neq t$ then $s\to^k t$ . Counterexample: $$ \begin{array}{cl|cl} as\to^3 at         &                & s\to^3 t &     \\ \hline \underline{1\ 23}4 & \text{r}(1,3)\ & 234      & ? \ \\  3\ 2\underline{14} & \text{r}(3,4)\ &          & ? \ \\  \underline{3\ 241} & \text{r}(1,4)\ &          & ? \ \\             1\ 423  &                & 423      &     \\ \hline \end{array} $$ For sake of completeness, the original conjecture above can be practically re-written as: Prove that if $n\gt 0$ and $as\to^k at$ then $s\to^k t$ . Edit : Possible counterexample to the original conjecture: $$ \begin{array}{cl|cl} as\to^3 at              &                & s\to^3 t &     \\ \hline \underline{4\ 221}31441 & \text{r}(1,4)\ & 22131441 & ? \ \\  1\ 2\underline{2431441} & \text{r}(3,9)\ &          & ? \ \\  \underline{1\ 2144}1342 & \text{r}(1,5)\ &          & ? \ \\             4\ 41211342  &                & 41211342 &     \\ \hline \end{array} $$","Note : If you can find a proof of this, please give me just a hint first, so I can try to solve it on my own. Let be a finite alphabet (set of symbols) and two strings (sequences of symbols) of equal length over . We denote by the -th symbol of , and by the concatenation of the symbol with . First, define a reversal operation on as the operation: that extracts the substring from , reverses it, and puts it back in the same place, where . Then, define the reversal distance between and as the minimum number of reversal operations (on either or ) needed to transform into ( if not possible). Conjecture : Let and . Prove (or find a counterexample) that: (In other terms, we can disregard the longest common prefix between two given strings when transforming one into the other.) Note that can occur in . Example : A few remarks: That is obvious, the converse less so. If and then . If and does not occur in , then it must return at the initial position at some point. Therefore, the same reversal operations that transform into can be easily adjusted to transform into , so that the relative positions between all the other symbols excluding remain the same. This implies the conjecture in this case. Induction alone doesn't seem to be powerful enough. Also, most results I've found in the literature either provide lower/upper bounds on the minimum , or concern the computational complexity of this kind of problems, collectively known as sorting by reversals . I tested it via computer on random instances up to a reasonably high and it seems to hold. I've edited this question numerous times, mainly to consider some variation of the conjecture. We write if can be transformed into by application of exactly reversals: Assume (i.e. are disallowed). Prove that if then . Counterexample: Assume (i.e. are disallowed). Prove that if and then . Counterexample: For sake of completeness, the original conjecture above can be practically re-written as: Prove that if and then . Edit : Possible counterexample to the original conjecture:","\Sigma s,t\in\Sigma^\ast n \Sigma s_i\in \Sigma i s as\in\Sigma^{n+1} a\in\Sigma s\in\Sigma^n \text{r}(i,j) s s=s_1...s_n\quad\mapsto\quad s_1...s_{i-1}\ \ s_j s_{j-1}...s_{i+1}s_i\ \ s_{j+1}...s_n s_i\dots s_j s 1 \le i\le j \le n d_r(s,t) s t s t s t d_r(s,t):=\infty a\in\Sigma s,t\in\Sigma^n d_r(as,at)=d_r(s,t) a s,t a=1,\ s=23141,\ t=41123 
\begin{array}{cl|cl}
as\to^2 at           &                & s\to^2 t          &                \\ \hline
\underline{1\ 23}141 & \text{r}(1,3)\ & \underline{2314}1 & \text{r}(1,4)\ \\ 
\underline{3\ 21141} & \text{r}(1,6)\ & 41\underline{321} & \text{r}(3,5)\ \\ 
           1\ 41123  &                & 41123             &                \\ \hline
\end{array}
 d_r(as,at)\le d_r(s,t) n\gt 0 d_r(as,at)=1 d_r(s,t)=1 n\gt 0 a s,t as at s t a k n s\to^k t s t k i\lt j \text{r}(i,i) as\to^k at s\to^k t 
\begin{array}{cl|cl}
as\to^1 at               &                & s\to^1 t  &     \\ \hline
\underline{1\ 1}23123... & \text{r}(1,2)\ & 123123... & ? \ \\ 
           1\ 123123...  &                & 123123... &     \\ \hline
\end{array}
 i\lt j \text{r}(i,i) as\to^k at s\neq t s\to^k t 
\begin{array}{cl|cl}
as\to^3 at         &                & s\to^3 t &     \\ \hline
\underline{1\ 23}4 & \text{r}(1,3)\ & 234      & ? \ \\ 
3\ 2\underline{14} & \text{r}(3,4)\ &          & ? \ \\ 
\underline{3\ 241} & \text{r}(1,4)\ &          & ? \ \\ 
           1\ 423  &                & 423      &     \\ \hline
\end{array}
 n\gt 0 as\to^k at s\to^k t 
\begin{array}{cl|cl}
as\to^3 at              &                & s\to^3 t &     \\ \hline
\underline{4\ 221}31441 & \text{r}(1,4)\ & 22131441 & ? \ \\ 
1\ 2\underline{2431441} & \text{r}(3,9)\ &          & ? \ \\ 
\underline{1\ 2144}1342 & \text{r}(1,5)\ &          & ? \ \\ 
           4\ 41211342  &                & 41211342 &     \\ \hline
\end{array}
","['combinatorics', 'computer-science']"
43,Moving particles on graph,Moving particles on graph,,"Consider the complete graph $K_n$ , and suppose we put $k$ different particles in each vertex, so there are $kn$ particles in total. We say the $k$ particles in a vertex are paired with each other. Now we do the following game: At the step $1$ we must move every particle from its current vertex to another one, with the following rules in mind: No particle can stay in its position. No particle can stay paired with another one. There can not be more than $k$ particles in each vertex at the end of the step. So, after the step $1$ every two particles $p,q$ which were paired before (shared the same vertex before the step 1) must go to different vertices. Then, we end up with a different configuration of the $kn$ particles in the $n$ vertices. So, if we have just done the step $i$ , we proceed with the step $i+1$ as follows: We must move every particle from its current vertex to another one, with the following rules No particle can stay in its position nor to a vertex it's been before. No particle can be paired with any particle it's been paired before with. There can not be more than $k$ particles in each vertex at the end of the step. We continue until we cannot proceed at some step $s$ ; then the game ends. We win if we can make every particle reach every vertex, and we lose otherwise. So, my questions are: Is there any way to build some algorithm to know if some game with $k$ particles in each vertex is winnable? In particular, is there any way to find the value of $k$ such that a game with $k$ particles in each vertex is winnable, but a game with $k+1$ particles is not? Is there a more or less known (solved or not) problem or theorem which could help getting a solution for this one (In case a solution of this problem is not so elementary)? For example, with $1$ particle in each vertex the game is clearly winnable (Just go through a Hamiltonian cycle with all the particles), and with $n$ particles the game is not (There will be two vertices which must stay paired or one vertex which doesn't move at the step $1$ ). I'm particularly interested in the case where $n=6$ , but when I thought about it I wanted to generalize it. Of course, instead of being $K_n$ we can start with an arbitrary Hamiltonian graph $G$ , modifying the number of particles each vertex has initially having the particles only move from a vertex to some of its neighbors, but it can get more complex. The game came from a problem my father (who is a P.E. teacher at a school) asked me about. He has $36$ students and wanted to make 6 groups, place 6 students in each group to discuss some topic, and then each student must go to another group to discuss another topic. But he didn't want the students to stay in the same group or repeat partners. Of course, this is not possible, but I can try giving him an alternative where instead of being groups of 6 people, they are, for example groups of $3$ pairs of people.","Consider the complete graph , and suppose we put different particles in each vertex, so there are particles in total. We say the particles in a vertex are paired with each other. Now we do the following game: At the step we must move every particle from its current vertex to another one, with the following rules in mind: No particle can stay in its position. No particle can stay paired with another one. There can not be more than particles in each vertex at the end of the step. So, after the step every two particles which were paired before (shared the same vertex before the step 1) must go to different vertices. Then, we end up with a different configuration of the particles in the vertices. So, if we have just done the step , we proceed with the step as follows: We must move every particle from its current vertex to another one, with the following rules No particle can stay in its position nor to a vertex it's been before. No particle can be paired with any particle it's been paired before with. There can not be more than particles in each vertex at the end of the step. We continue until we cannot proceed at some step ; then the game ends. We win if we can make every particle reach every vertex, and we lose otherwise. So, my questions are: Is there any way to build some algorithm to know if some game with particles in each vertex is winnable? In particular, is there any way to find the value of such that a game with particles in each vertex is winnable, but a game with particles is not? Is there a more or less known (solved or not) problem or theorem which could help getting a solution for this one (In case a solution of this problem is not so elementary)? For example, with particle in each vertex the game is clearly winnable (Just go through a Hamiltonian cycle with all the particles), and with particles the game is not (There will be two vertices which must stay paired or one vertex which doesn't move at the step ). I'm particularly interested in the case where , but when I thought about it I wanted to generalize it. Of course, instead of being we can start with an arbitrary Hamiltonian graph , modifying the number of particles each vertex has initially having the particles only move from a vertex to some of its neighbors, but it can get more complex. The game came from a problem my father (who is a P.E. teacher at a school) asked me about. He has students and wanted to make 6 groups, place 6 students in each group to discuss some topic, and then each student must go to another group to discuss another topic. But he didn't want the students to stay in the same group or repeat partners. Of course, this is not possible, but I can try giving him an alternative where instead of being groups of 6 people, they are, for example groups of pairs of people.","K_n k kn k 1 k 1 p,q kn n i i+1 k s k k k k+1 1 n 1 n=6 K_n G 36 3","['combinatorics', 'graph-theory']"
44,Candy store with eggs,Candy store with eggs,,"The owner of a candy shop has 11 hollow chocolate eggs in his display, all of the same size but different weights of 1 lb, 2 lbs,… 11 lbs respectively. Each of them is marked with a different sticker, so that they are distinguishable. A customer, intending to buy one egg, claims that he knows all the individual weights. The owner, being rather suspicious, asks him to guess the egg that weighs 1 lb. For this reason, he gave him an empty plastic bag that can hold up to exactly 11 lbs, otherwise it will be torn and can’t be used. Please describe the strategy of the customer in order to demonstrate which one is the egg of 1 lb. What is the minimum number of uses of the plastic bag and which eggs will he put inside it in each use? With any 5 eggs the bag will be torn. With any 4 eggs, the bag will also be torn except from the cases 1,2,3,4 and 1,2,3,5. With any 3 eggs, the bag will be torn except from 16 out of 165 cases, of which only 4 do not contain the egg of 1 lb. With any 2 eggs, the bag will be torn except from 25 out of 55 cases (only 9 containing the egg of 1 lb) and obviously with only 1 egg it will not be torn. But how do we identify the egg of 1 lb in the least number of uses of the bag?","The owner of a candy shop has 11 hollow chocolate eggs in his display, all of the same size but different weights of 1 lb, 2 lbs,… 11 lbs respectively. Each of them is marked with a different sticker, so that they are distinguishable. A customer, intending to buy one egg, claims that he knows all the individual weights. The owner, being rather suspicious, asks him to guess the egg that weighs 1 lb. For this reason, he gave him an empty plastic bag that can hold up to exactly 11 lbs, otherwise it will be torn and can’t be used. Please describe the strategy of the customer in order to demonstrate which one is the egg of 1 lb. What is the minimum number of uses of the plastic bag and which eggs will he put inside it in each use? With any 5 eggs the bag will be torn. With any 4 eggs, the bag will also be torn except from the cases 1,2,3,4 and 1,2,3,5. With any 3 eggs, the bag will be torn except from 16 out of 165 cases, of which only 4 do not contain the egg of 1 lb. With any 2 eggs, the bag will be torn except from 25 out of 55 cases (only 9 containing the egg of 1 lb) and obviously with only 1 egg it will not be torn. But how do we identify the egg of 1 lb in the least number of uses of the bag?",,['combinatorics']
45,Congruent quadrilaterals in a tri-colored $72$-gon,Congruent quadrilaterals in a tri-colored -gon,72,"I recently watched a movie (A Brilliant Young Mind) in which this problem appeared: Let the vertices of a regular $72$-gon be colored red, blue, and green in equal parts. Show that there are $4$ vertices of each color such that the resulting monochromatic quadrilaterals formed are congruent to each other. I don't know the solution to this problem, nor do I even know if the problem is actually true (it is from a movie after all). But I would love to see a proof, if one exists, or otherwise a counter-example.","I recently watched a movie (A Brilliant Young Mind) in which this problem appeared: Let the vertices of a regular $72$-gon be colored red, blue, and green in equal parts. Show that there are $4$ vertices of each color such that the resulting monochromatic quadrilaterals formed are congruent to each other. I don't know the solution to this problem, nor do I even know if the problem is actually true (it is from a movie after all). But I would love to see a proof, if one exists, or otherwise a counter-example.",,"['combinatorics', 'geometry', 'ramsey-theory']"
46,Rubik's cube interesting questions?,Rubik's cube interesting questions?,,The upper bound for the number of moves required to solve a regular Rubik's cube has been shown to be 20 . Two questions come to mind: Does this result have more general significance? What are the most pressing issue with regards to Rubik's cube (or generalizations) or its group?,The upper bound for the number of moves required to solve a regular Rubik's cube has been shown to be 20 . Two questions come to mind: Does this result have more general significance? What are the most pressing issue with regards to Rubik's cube (or generalizations) or its group?,,"['combinatorics', 'group-theory', 'recreational-mathematics', 'rubiks-cube']"
47,Proving $\sum_{k=2}^n \frac{(k-2){n-k+2\choose k-1}+k{n-k+1\choose k-1}}{k{n\choose k}}=1$ for $n\geq 2$ [closed],Proving  for  [closed],\sum_{k=2}^n \frac{(k-2){n-k+2\choose k-1}+k{n-k+1\choose k-1}}{k{n\choose k}}=1 n\geq 2,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question My friend showed me a difficult combinatorial identity I cannot solve. Prove that: $$\sum_{k=2}^n \frac{(k-2){n-k+2\choose k-1}+k{n-k+1\choose k-1}}{k{n\choose k}}=1$$ for all $n\ge 2$ . How do I prove this? Edit: I would like to bump this again, due to lack of attention.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question My friend showed me a difficult combinatorial identity I cannot solve. Prove that: for all . How do I prove this? Edit: I would like to bump this again, due to lack of attention.",\sum_{k=2}^n \frac{(k-2){n-k+2\choose k-1}+k{n-k+1\choose k-1}}{k{n\choose k}}=1 n\ge 2,['combinatorics']
48,Intuition behind sums of sums of whole numbers,Intuition behind sums of sums of whole numbers,,"So I was playing around, and all this is just a curiosity and nothing serious. Anyway, most readers probably know: $$1+2+3+4+5+...+(n-1)+n=\frac{1}{2}n^{2}+\frac{1}{2}n=\binom{n+1}{n-1}$$ I started playing around, adding the individual sums of whole numbers instead of whole numbers alone. Words aren't very helpful to describe this process, instead consider the sum of sums for $n=4$ , which we shall call $N_2(4)$ for simplicity: $$\left ( 1+2+3+4 \right ) + \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) = 20$$ Remarkably, there is a simple formula (I did the math): $$N_{2}(n)=\binom{n+2}{n-1}$$ Where $N_2(n)$ is the sum of sums as above. Formally, $N_2(n)=\sum_{1\leq i}^{n}\sum_{1\leq j\leq i}j$ . Now imagine going further, with sums of sums of sums, for instance: $$N_3(4) = \left ( \left ( 1+2+3+4 \right ) + \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1 \right ) \right ) = 35$$ Again, this seems to follow the pattern (I haven't explicitly checked): $$N_3(n)=\binom{n+3}{n-1}$$ And we might conjecture: $$N_k(n)=\binom{n+k}{n-1}$$ One angle of attack is this: realizing that the previous series always adds up to that of the differences between successive elements of the next series, and so verifying that: $$\binom{n+k}{n-1} - \binom{(n-1)+k}{(n-1)-1}=\binom{n+(k-1)}{n-1}$$ I.e. that $N_{k}(n)-N_{k}(n-1)=N_{k-1}(n)$ for any suitable $n$ and $k$ . My question is if there's some intuition behind all this. Maybe an alternative way of looking at this, or proving it. Why are the sums so neatly expressible?","So I was playing around, and all this is just a curiosity and nothing serious. Anyway, most readers probably know: I started playing around, adding the individual sums of whole numbers instead of whole numbers alone. Words aren't very helpful to describe this process, instead consider the sum of sums for , which we shall call for simplicity: Remarkably, there is a simple formula (I did the math): Where is the sum of sums as above. Formally, . Now imagine going further, with sums of sums of sums, for instance: Again, this seems to follow the pattern (I haven't explicitly checked): And we might conjecture: One angle of attack is this: realizing that the previous series always adds up to that of the differences between successive elements of the next series, and so verifying that: I.e. that for any suitable and . My question is if there's some intuition behind all this. Maybe an alternative way of looking at this, or proving it. Why are the sums so neatly expressible?",1+2+3+4+5+...+(n-1)+n=\frac{1}{2}n^{2}+\frac{1}{2}n=\binom{n+1}{n-1} n=4 N_2(4) \left ( 1+2+3+4 \right ) + \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) = 20 N_{2}(n)=\binom{n+2}{n-1} N_2(n) N_2(n)=\sum_{1\leq i}^{n}\sum_{1\leq j\leq i}j N_3(4) = \left ( \left ( 1+2+3+4 \right ) + \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1+2+3 \right ) + \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1+2 \right ) + \left ( 1 \right ) \right ) + \left ( \left ( 1 \right ) \right ) = 35 N_3(n)=\binom{n+3}{n-1} N_k(n)=\binom{n+k}{n-1} \binom{n+k}{n-1} - \binom{(n-1)+k}{(n-1)-1}=\binom{n+(k-1)}{n-1} N_{k}(n)-N_{k}(n-1)=N_{k-1}(n) n k,"['combinatorics', 'summation', 'binomial-coefficients', 'recreational-mathematics', 'intuition']"
49,Sum of squares of products of subsets without neighboring elements equals $(N+1)! -1$,Sum of squares of products of subsets without neighboring elements equals,(N+1)! -1,"Question : Let $n$ be any natural number. Consider all nonempty subsets of the set $\{1,2,...,n\}$ , which do not contain any neighboring elements. Prove that the sum of the squares of the products of all numbers in these subsets is $$(n + 1)! - 1.$$ For example, if $n = 3$ , then such subsets of $\{1,2,3\}$ are $\{1\}$ , $\{2\}$ , $\{3\}$ , and $\{1,3\}$ , and $$1^2 + 2^2 + 3^2 + (1\cdot3)^2 = 23 = 4! -1.$$ This question can be proved by induction, as shown here: induction (sum of squares of products of elements of certain subsets of $\{1,\dots,n\}$) This seems to me like something that is really out of the blue. So my question is, is there another way to see why this is true ? Such as a combinatorial argument. In particular, does the quantity ""sum of squares of products of numbers in subsets without neighboring elements"" arise in some natural way?","Question : Let be any natural number. Consider all nonempty subsets of the set , which do not contain any neighboring elements. Prove that the sum of the squares of the products of all numbers in these subsets is For example, if , then such subsets of are , , , and , and This question can be proved by induction, as shown here: induction (sum of squares of products of elements of certain subsets of $\{1,\dots,n\}$) This seems to me like something that is really out of the blue. So my question is, is there another way to see why this is true ? Such as a combinatorial argument. In particular, does the quantity ""sum of squares of products of numbers in subsets without neighboring elements"" arise in some natural way?","n \{1,2,...,n\} (n + 1)! - 1. n = 3 \{1,2,3\} \{1\} \{2\} \{3\} \{1,3\} 1^2 + 2^2 + 3^2 + (1\cdot3)^2 = 23 = 4! -1.","['combinatorics', 'induction']"
50,Generating functions for context-free languages,Generating functions for context-free languages,,"I have a question about context free grammars and their relationship with generating functions . It is well-know how to associate a generating function $\mathsf{gf}{(R)}$ with a non-ambiguous regular expression $R$ over the alphabet $\Sigma$: $$ \begin{array}{rclcrcl}   \mathsf{gf}{(\emptyset)} &=& 0 &\qquad&   \mathsf{gf}{(\epsilon)} &=& 1\\   \mathsf{gf}{(a)} &=& x \quad (a \in \Sigma) &&   \mathsf{gf}{(R + R')} &=& \mathsf{gf}{(R)} + \mathsf{gf}{(R')} \\   \mathsf{gf}{(RR')} &=& \mathsf{gf}{(R)} \cdot \mathsf{gf}{(R')} &&   \mathsf{gf}{(R^*)} &=& \frac{1}{1 - \mathsf{gf}{(R)}} \end{array} $$ A regular expression, and more generally a grammar, is ambiguous if at least one string in its language can be parsed in more than one way. (Note that not all languages have non-ambiguous grammars, and that ambiguity of context-free grammars is not decidable.) The generating function of a regular expression can be used to count the number of words of length $n$ in the language of the regular expression: If $f$ is the generating function of a regular expression $R$ and $f$ has    the power series expansion $\Sigma_{i < \omega}a_ix^i$ then the language generated by $R$ has $a_i$ words of length $i$. This is explained for example in H. Wilf's book generatingfunctionology .  The general theory behind this is the theory of combinatorial species . Now my question: is there a way to do this same thing, explicitly getting a generating function in an inductive (or otherwise 'nice') way, for non-ambiguous context free grammars?","I have a question about context free grammars and their relationship with generating functions . It is well-know how to associate a generating function $\mathsf{gf}{(R)}$ with a non-ambiguous regular expression $R$ over the alphabet $\Sigma$: $$ \begin{array}{rclcrcl}   \mathsf{gf}{(\emptyset)} &=& 0 &\qquad&   \mathsf{gf}{(\epsilon)} &=& 1\\   \mathsf{gf}{(a)} &=& x \quad (a \in \Sigma) &&   \mathsf{gf}{(R + R')} &=& \mathsf{gf}{(R)} + \mathsf{gf}{(R')} \\   \mathsf{gf}{(RR')} &=& \mathsf{gf}{(R)} \cdot \mathsf{gf}{(R')} &&   \mathsf{gf}{(R^*)} &=& \frac{1}{1 - \mathsf{gf}{(R)}} \end{array} $$ A regular expression, and more generally a grammar, is ambiguous if at least one string in its language can be parsed in more than one way. (Note that not all languages have non-ambiguous grammars, and that ambiguity of context-free grammars is not decidable.) The generating function of a regular expression can be used to count the number of words of length $n$ in the language of the regular expression: If $f$ is the generating function of a regular expression $R$ and $f$ has    the power series expansion $\Sigma_{i < \omega}a_ix^i$ then the language generated by $R$ has $a_i$ words of length $i$. This is explained for example in H. Wilf's book generatingfunctionology .  The general theory behind this is the theory of combinatorial species . Now my question: is there a way to do this same thing, explicitly getting a generating function in an inductive (or otherwise 'nice') way, for non-ambiguous context free grammars?",,"['combinatorics', 'generating-functions', 'formal-languages', 'context-free-grammar']"
51,Finding when $(a-n)(b-n)|(ab-n)$,Finding when,(a-n)(b-n)|(ab-n),"Given $n$ and $k$, find the number of pairs of integers $(a, b)$ which satisfy the conditions $n < a < k, n < b < k$ and $(ab-n)$ is divisible by $(a-n)(b-n)$. Given: $0 ≤ n ≤ 100000, \ n < k ≤ 10^{18}$. Link to problem: http://www.codechef.com/SEPT11/problems/SHORT","Given $n$ and $k$, find the number of pairs of integers $(a, b)$ which satisfy the conditions $n < a < k, n < b < k$ and $(ab-n)$ is divisible by $(a-n)(b-n)$. Given: $0 ≤ n ≤ 100000, \ n < k ≤ 10^{18}$. Link to problem: http://www.codechef.com/SEPT11/problems/SHORT",,"['combinatorics', 'elementary-number-theory']"
52,Infection spread on a torus chessboard,Infection spread on a torus chessboard,,"In one of his books, Peter Winkler includes the following problem: A disease is spreading on a $n\times n$ chessboard as follows: if a healthy cell is neighboring at least 2 infected cells, it becomes infected. Using the property that the perimeter of the infected area never increases, it’s easy to prove that it’s impossible to infect the entire chessboard with fewer than $n$ infected cells. If the chessboard is a torus, the result no longer holds (verified on some instances of $n$ ). It seems that $n-1$ is the smallest number of infected cells required to infect the chessboard. The perimeter argument can’t be used here. Does anyone know any other ‘invariant’ that can be used? Note : two cells are neighbors if they share one side.","In one of his books, Peter Winkler includes the following problem: A disease is spreading on a chessboard as follows: if a healthy cell is neighboring at least 2 infected cells, it becomes infected. Using the property that the perimeter of the infected area never increases, it’s easy to prove that it’s impossible to infect the entire chessboard with fewer than infected cells. If the chessboard is a torus, the result no longer holds (verified on some instances of ). It seems that is the smallest number of infected cells required to infect the chessboard. The perimeter argument can’t be used here. Does anyone know any other ‘invariant’ that can be used? Note : two cells are neighbors if they share one side.",n\times n n n n-1,"['combinatorics', 'puzzle', 'upper-lower-bounds', 'combinatorial-game-theory', 'cellular-automata']"
53,Bases for symmetric polynomials,Bases for symmetric polynomials,,"I’ve been playing with symmetric polynomials, as one does, and I’ve run into something that must be familiar, but I can’t find anything about it. To present the idea, I’ll work with symmetric polynomials in $\Bbb Z[x,y]$, but the idea extends to any number of variables, with the details just getting a little more difficult to write down. We have the elementary symmetric polynomials in two variables: $\sigma_1=x+y$ and $\sigma_2=xy$. Now, we pick a degree, say $4$. If we want to express any degree $4$ symmetric polynomials in $x$ and $y$, there are two bases that seem natural to use: $\rho_1=\sigma_1^4\\ \rho_2=\sigma_1^2\sigma_2\\ \rho_3=\sigma_2^2$ and $\tau_1=x^4+y^4\\ \tau_2=x^3y+xy^3\\ \tau_3=x^2y^2$ These bases are related by the equation: $\left[\begin{matrix} 1&4&6\\0&1&2\\0&0&1\end{matrix}\right]\left[\begin{matrix} \tau_1\\ \tau_2\\ \tau_3\end{matrix}\right] = \left[\begin{matrix} \rho_1\\ \rho_2\\ \rho_3\end{matrix}\right]$ The entries in this matrix are binomial coefficients, if we were working in 3 variables, we’d be looking at trinomial coefficients instead, etc. My question is: what am I looking at? I assume this has been thoroughly studied. Are these bases, and the transformations between them, called something? Are the transformations special in some way? They all have characteristic polynomials of the form $(1-\lambda)^k$ for some $k$, being triangular with $1$s on the diagonal. Is there more that I’m not seeing? Is there a quicker way to write the transformations down than just expanding each $\rho_i$? Thanks in advance for any insight or information anyone can provide.","I’ve been playing with symmetric polynomials, as one does, and I’ve run into something that must be familiar, but I can’t find anything about it. To present the idea, I’ll work with symmetric polynomials in $\Bbb Z[x,y]$, but the idea extends to any number of variables, with the details just getting a little more difficult to write down. We have the elementary symmetric polynomials in two variables: $\sigma_1=x+y$ and $\sigma_2=xy$. Now, we pick a degree, say $4$. If we want to express any degree $4$ symmetric polynomials in $x$ and $y$, there are two bases that seem natural to use: $\rho_1=\sigma_1^4\\ \rho_2=\sigma_1^2\sigma_2\\ \rho_3=\sigma_2^2$ and $\tau_1=x^4+y^4\\ \tau_2=x^3y+xy^3\\ \tau_3=x^2y^2$ These bases are related by the equation: $\left[\begin{matrix} 1&4&6\\0&1&2\\0&0&1\end{matrix}\right]\left[\begin{matrix} \tau_1\\ \tau_2\\ \tau_3\end{matrix}\right] = \left[\begin{matrix} \rho_1\\ \rho_2\\ \rho_3\end{matrix}\right]$ The entries in this matrix are binomial coefficients, if we were working in 3 variables, we’d be looking at trinomial coefficients instead, etc. My question is: what am I looking at? I assume this has been thoroughly studied. Are these bases, and the transformations between them, called something? Are the transformations special in some way? They all have characteristic polynomials of the form $(1-\lambda)^k$ for some $k$, being triangular with $1$s on the diagonal. Is there more that I’m not seeing? Is there a quicker way to write the transformations down than just expanding each $\rho_i$? Thanks in advance for any insight or information anyone can provide.",,"['combinatorics', 'linear-transformations', 'symmetric-polynomials']"
54,Rolling $n$ $k$-sided dice and discarding the lowest $m$ of them.,Rolling  -sided dice and discarding the lowest  of them.,n k m,"In this question I will use the notation $\Bbb{E}(n,k,m)$ to refer to the expected average of rolling $n$ $k$-sided dice and discarding the lowest $m$ of them. The most trivial response happens when $m = 0$, in which case we discard no dice and we arrive at the result: $$\Bbb{E}(n,k,0) = \frac{k}{2} + \frac{1}{2}$$ When $m = 1$, I considered a sample case to give some intuition for this problem. Looking at the case of $\Bbb{E}(2, 6, 1)$, I found the following pattern. There are one $1$s, three $2$s, five $3$s, etc. The sum of these outcomes is: $$\sum_{i=1}^{6} i(2i-1)$$ In general, the expected outcome for $\Bbb{E}(2,k,1)$ is: $$\frac{\sum_{i=1}^{k} i(2i-1)}{k^2} = \frac{\sum_{i=1}^{k} 2i^2 - \sum_{i=1}^{k} i}{k^2} = \frac{\frac{2k(k+1)(2k+1)}{6} - \frac{k(k+1)}{2}}{k^2} = \frac{2}{3}k + \frac{1}{2} - \frac{1}{6k}$$ Now I want to consider $\Bbb{E}(3,k,2)$. In the previous case each value $i$ occurred $2i - 1$ number of times. Where did $2i - 1$ come from? It looks like the frequency of occurrence is the difference of consecutive squares. $$i^2 - (i-1)^2 = 2i - 1$$ This seems intuitive based on the image I provided. We can reason that in the case of $n = 3$, the frequency of occurrence will be the difference of consecutive cubes . $$i^3 - (i-1)^3 = 3i^2 - 3i + 1$$ The expected outcome of $\Bbb{E}(3,k,2)$ is messy, so I'll just write the initial expression and the simplified expression. $$\frac{\sum_{i=1}^{k} i(3i^2-3i+1)}{k^3} = \frac{3}{4}k + \frac{1}{2} - \frac{1}{4k}$$ Let's finally look at the case of $\Bbb{E}(n,k,n-1)$. Based on the previous results, I conjecture that it looks like: $$\frac{\sum_{i=1}^{k} i(i^n - (i-1)^n))}{k^n} = \frac{n}{n+1}k + \frac{1}{2} - \mathcal{O}(\frac{1}{k})$$ My two questions are this: Is my conjecture for $\Bbb{E}(n,k,n-1)$ correct, and if so, how can I prove this? What happens when $m \ne n-1$? How can I adjust my analysis to account for discarding dice such that I leave not just the maximum value?","In this question I will use the notation $\Bbb{E}(n,k,m)$ to refer to the expected average of rolling $n$ $k$-sided dice and discarding the lowest $m$ of them. The most trivial response happens when $m = 0$, in which case we discard no dice and we arrive at the result: $$\Bbb{E}(n,k,0) = \frac{k}{2} + \frac{1}{2}$$ When $m = 1$, I considered a sample case to give some intuition for this problem. Looking at the case of $\Bbb{E}(2, 6, 1)$, I found the following pattern. There are one $1$s, three $2$s, five $3$s, etc. The sum of these outcomes is: $$\sum_{i=1}^{6} i(2i-1)$$ In general, the expected outcome for $\Bbb{E}(2,k,1)$ is: $$\frac{\sum_{i=1}^{k} i(2i-1)}{k^2} = \frac{\sum_{i=1}^{k} 2i^2 - \sum_{i=1}^{k} i}{k^2} = \frac{\frac{2k(k+1)(2k+1)}{6} - \frac{k(k+1)}{2}}{k^2} = \frac{2}{3}k + \frac{1}{2} - \frac{1}{6k}$$ Now I want to consider $\Bbb{E}(3,k,2)$. In the previous case each value $i$ occurred $2i - 1$ number of times. Where did $2i - 1$ come from? It looks like the frequency of occurrence is the difference of consecutive squares. $$i^2 - (i-1)^2 = 2i - 1$$ This seems intuitive based on the image I provided. We can reason that in the case of $n = 3$, the frequency of occurrence will be the difference of consecutive cubes . $$i^3 - (i-1)^3 = 3i^2 - 3i + 1$$ The expected outcome of $\Bbb{E}(3,k,2)$ is messy, so I'll just write the initial expression and the simplified expression. $$\frac{\sum_{i=1}^{k} i(3i^2-3i+1)}{k^3} = \frac{3}{4}k + \frac{1}{2} - \frac{1}{4k}$$ Let's finally look at the case of $\Bbb{E}(n,k,n-1)$. Based on the previous results, I conjecture that it looks like: $$\frac{\sum_{i=1}^{k} i(i^n - (i-1)^n))}{k^n} = \frac{n}{n+1}k + \frac{1}{2} - \mathcal{O}(\frac{1}{k})$$ My two questions are this: Is my conjecture for $\Bbb{E}(n,k,n-1)$ correct, and if so, how can I prove this? What happens when $m \ne n-1$? How can I adjust my analysis to account for discarding dice such that I leave not just the maximum value?",,"['combinatorics', 'dice']"
55,"Does the ""prime ant"" ever backtrack?","Does the ""prime ant"" ever backtrack?",,"A few mathematical questions have come up from the question "" The prime ant 🐜 "" on the Programming Puzzles & Code Golf Stack Exchange. Here is how the prime ant is defined: Initially, we have an infinite array A containing all the integers >= 2 : [2,3,4,5,6,.. ] Let p be the position of the ant on the array. Initially, p = 0 (array is 0-indexed) Each turn, the ant will move as follows: if A[p] is prime, the ant moves to the next position : p ← p+1 else, if A[p] is a composite number, let q be its smaller divisor > 1. We divide A[p] by q , and we add q to A[p-1] . The ant moves to the previous position: p ← p-1 Here are the first moves for the ant: 2  3  4  5  6  7  8  9  ...   ^  2  3  4  5  6  7  8  9  ...      ^  2  3  4  5  6  7  8  9  ...         ^  2  5  2  5  6  7  8  9  ...      ^  2  5  2  5  6  7  8  9  ...         ^  2  5  2  5  6  7  8  9  ...            ^  2  5  2  5  6  7  8  9  ...               ^  2  5  2  7  3  7  8  9  ...            ^ Questions relate to proving the sequence is well-defined: I wonder whether the sequence is well-defined for arbitrarily large n (or whether the composite case could ever push the ant to the left of the initial 2). – Martin Ender♦ Oct 9 at 6:59 Whether all prime values appear: @MartinEnder Another open question is whether a prime > 7 can eventually be left behind for good. – Arnauld Oct 9 at 10:39 And what the asymptotic growth looks like: @Arnauld I'm curious how the ant's position grows with respect to the number of moves. My guess is logarithmic. – kamoroso94 Oct 9 at 12:58 I have added this sequence to the On-Line Encylopedia of Integer Sequences (OEIS) as sequence A293689 . Here's what the plot of the first 10000 terms looks like:","A few mathematical questions have come up from the question "" The prime ant 🐜 "" on the Programming Puzzles & Code Golf Stack Exchange. Here is how the prime ant is defined: Initially, we have an infinite array A containing all the integers >= 2 : [2,3,4,5,6,.. ] Let p be the position of the ant on the array. Initially, p = 0 (array is 0-indexed) Each turn, the ant will move as follows: if A[p] is prime, the ant moves to the next position : p ← p+1 else, if A[p] is a composite number, let q be its smaller divisor > 1. We divide A[p] by q , and we add q to A[p-1] . The ant moves to the previous position: p ← p-1 Here are the first moves for the ant: 2  3  4  5  6  7  8  9  ...   ^  2  3  4  5  6  7  8  9  ...      ^  2  3  4  5  6  7  8  9  ...         ^  2  5  2  5  6  7  8  9  ...      ^  2  5  2  5  6  7  8  9  ...         ^  2  5  2  5  6  7  8  9  ...            ^  2  5  2  5  6  7  8  9  ...               ^  2  5  2  7  3  7  8  9  ...            ^ Questions relate to proving the sequence is well-defined: I wonder whether the sequence is well-defined for arbitrarily large n (or whether the composite case could ever push the ant to the left of the initial 2). – Martin Ender♦ Oct 9 at 6:59 Whether all prime values appear: @MartinEnder Another open question is whether a prime > 7 can eventually be left behind for good. – Arnauld Oct 9 at 10:39 And what the asymptotic growth looks like: @Arnauld I'm curious how the ant's position grows with respect to the number of moves. My guess is logarithmic. – kamoroso94 Oct 9 at 12:58 I have added this sequence to the On-Line Encylopedia of Integer Sequences (OEIS) as sequence A293689 . Here's what the plot of the first 10000 terms looks like:",,"['combinatorics', 'asymptotics', 'random-walk', 'oeis']"
56,Attempting to restate the question of whether the collatz conjecture has a nontrivial cycle as a combinatorics problem,Attempting to restate the question of whether the collatz conjecture has a nontrivial cycle as a combinatorics problem,,"It occurs to me that the question about whether non-trivial cycles exist for the collatz conjecture can be restated as these two questions (details on how this relates to the collatz conjecture can be found here ): Is there a general method for determining how many distinct values of $t_1, t_2, \dots, t_k$ exist for a given $k$ such that: $t_k > t_{k-1} > \dots > t_2 > t_1 > 0$ $2\left(2^{t_k} - 3^k\right) < 3^{k-1} + \sum\limits_{i=1}^{k-1}3^{k-1-i}2^{t_i}$ $2^{t_k} - 3^k > 1$ Would it follow that as $k$ increases, the number of distinct values approaches infinity? It seems to me that the conjecture is false if any nontrivial cycle occurs. A non-trivial cycle occurs if $2^{t_k}−3^k$ divides $3^{k−1}+\sum\limits_{i=1}^{𝑘−1}3^{h−1−i}2^{t_i}$ which would seem to me be a high probability if there are an infinite number of distinct values. Infinity does not mean this is necessary the case. More information is needed on the variability of the distinct values Do my assumptions sound reasonable?  Are there any well known papers that investigate the collatz conjecture from this viewpoint? Update: By ""non-trivial"" cycles, I mean cycles that involve $2^{t_k} - 3^k > 1$ and include all cycles listed here as ""trivial"". I have added a third bullet point above to clarify this point.  Thanks to Rosie F for noticing that it was missing.","It occurs to me that the question about whether non-trivial cycles exist for the collatz conjecture can be restated as these two questions (details on how this relates to the collatz conjecture can be found here ): Is there a general method for determining how many distinct values of exist for a given such that: Would it follow that as increases, the number of distinct values approaches infinity? It seems to me that the conjecture is false if any nontrivial cycle occurs. A non-trivial cycle occurs if divides which would seem to me be a high probability if there are an infinite number of distinct values. Infinity does not mean this is necessary the case. More information is needed on the variability of the distinct values Do my assumptions sound reasonable?  Are there any well known papers that investigate the collatz conjecture from this viewpoint? Update: By ""non-trivial"" cycles, I mean cycles that involve and include all cycles listed here as ""trivial"". I have added a third bullet point above to clarify this point.  Thanks to Rosie F for noticing that it was missing.","t_1, t_2, \dots, t_k k t_k > t_{k-1} > \dots > t_2 > t_1 > 0 2\left(2^{t_k} - 3^k\right) < 3^{k-1} + \sum\limits_{i=1}^{k-1}3^{k-1-i}2^{t_i} 2^{t_k} - 3^k > 1 k 2^{t_k}−3^k 3^{k−1}+\sum\limits_{i=1}^{𝑘−1}3^{h−1−i}2^{t_i} 2^{t_k} - 3^k > 1","['combinatorics', 'number-theory', 'reference-request', 'collatz-conjecture']"
57,Minimum number of balanced partitions,Minimum number of balanced partitions,,"For any multiset $x_1,x_2,\ldots,x_{2n}$ of positive real numbers, a partition into two nonempty subsets $(A,B)$ is called ""balanced"" if $\text{sum}(A)\geq\text{sum}(B)-\max(B)$ and $\text{sum}(B)\geq\text{sum}(A)-\max(A)$. What is the minimum number of balanced partitions, in terms of $n$? For the case that all numbers are equal, a partition is balanced if and only if it puts $n$ numbers in each part. So there are $\binom{2n}{n}$ balanced partitions. I conjecture that this is also the minimum. The reason is that if the numbers are not equal, there is more ""advantage"" to be gained by subtracting the max, which should give more balanced partitions.","For any multiset $x_1,x_2,\ldots,x_{2n}$ of positive real numbers, a partition into two nonempty subsets $(A,B)$ is called ""balanced"" if $\text{sum}(A)\geq\text{sum}(B)-\max(B)$ and $\text{sum}(B)\geq\text{sum}(A)-\max(A)$. What is the minimum number of balanced partitions, in terms of $n$? For the case that all numbers are equal, a partition is balanced if and only if it puts $n$ numbers in each part. So there are $\binom{2n}{n}$ balanced partitions. I conjecture that this is also the minimum. The reason is that if the numbers are not equal, there is more ""advantage"" to be gained by subtracting the max, which should give more balanced partitions.",,"['combinatorics', 'binomial-coefficients', 'extremal-combinatorics']"
58,Covering pairs with permutations,Covering pairs with permutations,,"Consider an $n \times n$ matrix $M_n$ with the following properties: Each row is a permutation of $A_n \equiv \{1, 2, ..., n\}$. Every ordered pair $(i,j)$, $i,j \in A_n$, $i \neq j$, appears as a horizontally adjacent pair in $M_n$ exactly once (which works out since there are $n(n-1)$ such pairs). Together with user Sp3000 we've ran some automated search for these matrices. It seems that solutions are not possible for all $n$. Here are some working cases (of course, these are not unique): $$ M_1 = \left(\begin{array}{c} 1 \end{array}\right) \\ M_2 = \left(\begin{array}{cc} 1 & 2 \\ 2 & 1 \end{array}\right) \\ M_4 = \left(\begin{array}{cccc} 1&2&3&4\\2&4&1&3\\3&1&4&2\\4&3&2&1\end{array}\right)  \\ M_6 = \left(\begin{array}{cccc} 1&2&3&4&5&6\\2&1&3&6&5&4\\3&1&4&6&2&5\\4&2&6&1&5&3\\5&1&6&4&3&2\\6&3&5&2&4&1\end{array}\right)  $$ We also have solutions for all further $n$ up to and including $26$. However, we've verified that no solutions exist for $n = 3$ and $n = 5$. So the interesting question is: for which values $n$ does at least one $M_n$ exist? Are $3$ and $5$ the only exceptions? When solutions do exist, can one of them be constructed from some obvious pattern or do they always have to be searched for? A few additional observations on our part: This problem has an equivalent formulation in graph theory. For the complete digraph $K_n$ can you find a set of $n$ (edge disjoint) Hamiltonian paths whose union covers all edges? The first and last column of the matrix are necessarily permutations of $A_n$ as well. If we remove the constraint that the individual rows are permutations, then $n = 3$ has solutions, e.g. $(121, 232, 313)$, as does $n = 5$. Final note: I actually have an application for this problem. I came across this question while trying to devise test cases for a programming challenge where I wanted to cover all possible cases in as few lists as possible (with $n$ lists of length $n$ being the minimum).","Consider an $n \times n$ matrix $M_n$ with the following properties: Each row is a permutation of $A_n \equiv \{1, 2, ..., n\}$. Every ordered pair $(i,j)$, $i,j \in A_n$, $i \neq j$, appears as a horizontally adjacent pair in $M_n$ exactly once (which works out since there are $n(n-1)$ such pairs). Together with user Sp3000 we've ran some automated search for these matrices. It seems that solutions are not possible for all $n$. Here are some working cases (of course, these are not unique): $$ M_1 = \left(\begin{array}{c} 1 \end{array}\right) \\ M_2 = \left(\begin{array}{cc} 1 & 2 \\ 2 & 1 \end{array}\right) \\ M_4 = \left(\begin{array}{cccc} 1&2&3&4\\2&4&1&3\\3&1&4&2\\4&3&2&1\end{array}\right)  \\ M_6 = \left(\begin{array}{cccc} 1&2&3&4&5&6\\2&1&3&6&5&4\\3&1&4&6&2&5\\4&2&6&1&5&3\\5&1&6&4&3&2\\6&3&5&2&4&1\end{array}\right)  $$ We also have solutions for all further $n$ up to and including $26$. However, we've verified that no solutions exist for $n = 3$ and $n = 5$. So the interesting question is: for which values $n$ does at least one $M_n$ exist? Are $3$ and $5$ the only exceptions? When solutions do exist, can one of them be constructed from some obvious pattern or do they always have to be searched for? A few additional observations on our part: This problem has an equivalent formulation in graph theory. For the complete digraph $K_n$ can you find a set of $n$ (edge disjoint) Hamiltonian paths whose union covers all edges? The first and last column of the matrix are necessarily permutations of $A_n$ as well. If we remove the constraint that the individual rows are permutations, then $n = 3$ has solutions, e.g. $(121, 232, 313)$, as does $n = 5$. Final note: I actually have an application for this problem. I came across this question while trying to devise test cases for a programming challenge where I wanted to cover all possible cases in as few lists as possible (with $n$ lists of length $n$ being the minimum).",,"['combinatorics', 'graph-theory', 'permutations', 'hamiltonian-path', 'latin-square']"
59,Circular permutations with repetitions,Circular permutations with repetitions,,"$n$ distinct objects have $n!$ (linear) permutations and thus $(n-1)!$ circular permutations. Now consider $n$ objects, some identical, $r_1$ of the first kind, $r_2$ of the second kind, ..., $r_k$ of the $k$ th kind. These $n$ objects have $\frac{n!}{r_1!r_2!\dots r_k!}$ (linear) permutations. Can we likewise reason that these $m$ objects have $\frac{(n-1)!}{r_1!r_2!\dots r_k!}$ circular permutations? I think the answer is no, but can someone explain the intuition why the reasoning that worked earlier doesn't work here? Also, what is the correct number of circular permutations for these $m!$ objects? (I am hoping for an answer that's suitable for high school students. Thanks.)","distinct objects have (linear) permutations and thus circular permutations. Now consider objects, some identical, of the first kind, of the second kind, ..., of the th kind. These objects have (linear) permutations. Can we likewise reason that these objects have circular permutations? I think the answer is no, but can someone explain the intuition why the reasoning that worked earlier doesn't work here? Also, what is the correct number of circular permutations for these objects? (I am hoping for an answer that's suitable for high school students. Thanks.)",n n! (n-1)! n r_1 r_2 r_k k n \frac{n!}{r_1!r_2!\dots r_k!} m \frac{(n-1)!}{r_1!r_2!\dots r_k!} m!,[]
60,Optimal strategy for guessing a binary string,Optimal strategy for guessing a binary string,,"I would have thought this was well known, but I have not been able to track down a reference. Suppose you are trying to guess an $n-$ digit binary string.  At any point you may guess all or any portion of it (a single specified digit if you like, or any specified collection of digits).  Once you have made a guess, you will be told the number, though not the locations, of the correct entries in your guess. There is no penalty for wrong guesses, nor for unguessed positions. Let $a_n$ denote the maximal number of guesses it takes to determine the string under an optimal strategy (optimized, that is, to minimize the worst case). Stating the final result once it is determined does not count as a guess.  Thus $a_1=1$ since a single guess determines a single digit string.  It is not hard to see that $a_2=2$ . I'm after a description of the optimal strategy, along with the computation of $a_n$ .  Failing that, I'm interested in upper and lower bounds for $a_n$ . Discussion: Simple observations:  Since we can guess digit by digit, $a_n≤n$ .  It is also easy to see that $$a_n≤a_{n+1}≤a_n+1$$ Now, $a_3=2$ .  To see that, it suffices to exhibit a two step guessing strategy for $n=3$ :  First guess $111$ .  If the answer is $0$ or $3$ you are done. $1$ and $2$ are effectively the same, so let's say the answer was $1$ .  Then the string is one of $\{100, 010,001\}$ .  If you guess $10\_$ the answers will be $\{2,0,1\}$ respectively so the answer will determine the string. We can use this to improve the upper bound.   Working in blocks of length $3$ with a possible remainder we get $$a_{3n+i}≤2n+i\quad \text{for}\quad i\in \{0,1,2\}$$ I have not been able to improve on this bound, nor have I got a useful lower bound.  I have no particular reason to imagine that this upper bound is optimal, nor anything to suggest that it can be improved. The sequence of upper bounds $\{1,2,2,3,4,4,5,6,6\cdots\}$ is A004523 and that link associates the sequence with the optimal strategy for Static Mastermind which is a guessing game with some similarity to the desired game, but it is not obvious to me that the games are equivalent. here is an analysis of Static Mastermind which claims to yield that upper bound, though I have not yet studied it. Is this game equivalent to Static Mastermind?  is this ""blocks of length $3$ "" strategy optimal?  More broadly, is this game equivalent to some other,  well documented, game?","I would have thought this was well known, but I have not been able to track down a reference. Suppose you are trying to guess an digit binary string.  At any point you may guess all or any portion of it (a single specified digit if you like, or any specified collection of digits).  Once you have made a guess, you will be told the number, though not the locations, of the correct entries in your guess. There is no penalty for wrong guesses, nor for unguessed positions. Let denote the maximal number of guesses it takes to determine the string under an optimal strategy (optimized, that is, to minimize the worst case). Stating the final result once it is determined does not count as a guess.  Thus since a single guess determines a single digit string.  It is not hard to see that . I'm after a description of the optimal strategy, along with the computation of .  Failing that, I'm interested in upper and lower bounds for . Discussion: Simple observations:  Since we can guess digit by digit, .  It is also easy to see that Now, .  To see that, it suffices to exhibit a two step guessing strategy for :  First guess .  If the answer is or you are done. and are effectively the same, so let's say the answer was .  Then the string is one of .  If you guess the answers will be respectively so the answer will determine the string. We can use this to improve the upper bound.   Working in blocks of length with a possible remainder we get I have not been able to improve on this bound, nor have I got a useful lower bound.  I have no particular reason to imagine that this upper bound is optimal, nor anything to suggest that it can be improved. The sequence of upper bounds is A004523 and that link associates the sequence with the optimal strategy for Static Mastermind which is a guessing game with some similarity to the desired game, but it is not obvious to me that the games are equivalent. here is an analysis of Static Mastermind which claims to yield that upper bound, though I have not yet studied it. Is this game equivalent to Static Mastermind?  is this ""blocks of length "" strategy optimal?  More broadly, is this game equivalent to some other,  well documented, game?","n- a_n a_1=1 a_2=2 a_n a_n a_n≤n a_n≤a_{n+1}≤a_n+1 a_3=2 n=3 111 0 3 1 2 1 \{100, 010,001\} 10\_ \{2,0,1\} 3 a_{3n+i}≤2n+i\quad \text{for}\quad i\in \{0,1,2\} \{1,2,2,3,4,4,5,6,6\cdots\} 3","['combinatorics', 'puzzle', 'information-theory', 'combinatorial-game-theory']"
61,Books/Resources on generating functions,Books/Resources on generating functions,,"I'm currently doing a research on generating functions, but I have only found few books on this topic. Can anyone provide references (if possible, trying to assess the level of math competence required) on generating functions? Ideally, what is the context of the referenced book and further details to help to put the book itself in context would be much appreciated.","I'm currently doing a research on generating functions, but I have only found few books on this topic. Can anyone provide references (if possible, trying to assess the level of math competence required) on generating functions? Ideally, what is the context of the referenced book and further details to help to put the book itself in context would be much appreciated.",,"['combinatorics', 'reference-request', 'generating-functions']"
62,Exponential Generating Function For Derangements,Exponential Generating Function For Derangements,,"I have been introduced to the concept of exponential generating functions a few days ago. However, my understanding of them are still quite limited, and I would like to see some examples. Earlier this term, I derived a formula for the number of derangements of size $n$ using the inclusion/exclusion principle, namely that $D_n = n!\sum_{k=0}^{\infty}\frac{(-1)^k}{k!}$. How would I go about deriving this result using exponential generating functions, without using the inclusion/exclusion principle to derive $D_n$. The formula we are using for the these generating functions are $\Phi_D(x) = \sum_{n=0}^{\infty}|D_n|\frac{x^n}{n!}$. If anyone could walk me through this example, I would greatly appreciate it :) Thanks!","I have been introduced to the concept of exponential generating functions a few days ago. However, my understanding of them are still quite limited, and I would like to see some examples. Earlier this term, I derived a formula for the number of derangements of size $n$ using the inclusion/exclusion principle, namely that $D_n = n!\sum_{k=0}^{\infty}\frac{(-1)^k}{k!}$. How would I go about deriving this result using exponential generating functions, without using the inclusion/exclusion principle to derive $D_n$. The formula we are using for the these generating functions are $\Phi_D(x) = \sum_{n=0}^{\infty}|D_n|\frac{x^n}{n!}$. If anyone could walk me through this example, I would greatly appreciate it :) Thanks!",,"['combinatorics', 'permutations', 'generating-functions', 'derangements']"
63,Combinatorial proof of $\sum_{k=1}^n k k!=(n+1)!-1$,Combinatorial proof of,\sum_{k=1}^n k k!=(n+1)!-1,"Prove: $\displaystyle\sum_{k=1}^n k k!=(n+1)!-1$ (preferably combinatorially) It's pretty easy to think of a story for the RHS: arrange $n+1$ people in a row and remove the the option of everyone arranged to height from shortest to highest, but it doesn't hold up for the LHS. Alternatively, trying to visualize the LHS, I noticed that it's like a right angle tetrahedra: 1 2!+2! 3!+3!+3! ... But it doesn't help to see a connection to the RHS. Note: no integrals or gamma function nor use of other identities without proving them nor generating functions.","Prove: $\displaystyle\sum_{k=1}^n k k!=(n+1)!-1$ (preferably combinatorially) It's pretty easy to think of a story for the RHS: arrange $n+1$ people in a row and remove the the option of everyone arranged to height from shortest to highest, but it doesn't hold up for the LHS. Alternatively, trying to visualize the LHS, I noticed that it's like a right angle tetrahedra: 1 2!+2! 3!+3!+3! ... But it doesn't help to see a connection to the RHS. Note: no integrals or gamma function nor use of other identities without proving them nor generating functions.",,"['combinatorics', 'summation', 'induction', 'factorial']"
64,How do I prove that there infinitely many rows of Pascal's triangle with only odd numbers?,How do I prove that there infinitely many rows of Pascal's triangle with only odd numbers?,,"This is exercise number $59$ from Chapter $2$ of Hugh Gordon's Discrete Probability . Show that there are infinitely many rows of Pascal's Triangle that consist entirely of odd numbers. Intuitively, if you draw boxes around the numbers in Pascal's triangle and color the boxes black if the number is odd and white if the number is even, then the triangle will look like the Sierpinsky triangle as you zoom out. In particular, if we number the rows starting with the top as $1$, the rows will all odd numbers will be exactly the rows with number $2^n$ for some $n \in \mathbb{N}$ (or $n=0$ for the first). You can see this if you think about the Sierpinsky triangle coloring. Anyway, is there any direct way to show the following for all $k$ with $0 \leq k \leq 2^n-1$? $$\binom{2^n-1}{k} \equiv 1 \pmod{2}$$ This can probably be done by induction but a direct proof would be preferable.","This is exercise number $59$ from Chapter $2$ of Hugh Gordon's Discrete Probability . Show that there are infinitely many rows of Pascal's Triangle that consist entirely of odd numbers. Intuitively, if you draw boxes around the numbers in Pascal's triangle and color the boxes black if the number is odd and white if the number is even, then the triangle will look like the Sierpinsky triangle as you zoom out. In particular, if we number the rows starting with the top as $1$, the rows will all odd numbers will be exactly the rows with number $2^n$ for some $n \in \mathbb{N}$ (or $n=0$ for the first). You can see this if you think about the Sierpinsky triangle coloring. Anyway, is there any direct way to show the following for all $k$ with $0 \leq k \leq 2^n-1$? $$\binom{2^n-1}{k} \equiv 1 \pmod{2}$$ This can probably be done by induction but a direct proof would be preferable.",,"['combinatorics', 'modular-arithmetic', 'binomial-coefficients']"
65,Prove $\sum\limits_{i=0}^n\binom{i+k-1}{k-1}=\binom{n+k}{k}$ (a.k.a. Hockey-Stick Identity) [duplicate],Prove  (a.k.a. Hockey-Stick Identity) [duplicate],\sum\limits_{i=0}^n\binom{i+k-1}{k-1}=\binom{n+k}{k},"This question already has answers here : Proof of the hockey stick/Zhu Shijie identity $\sum\limits_{t=0}^n \binom tk = \binom{n+1}{k+1}$ (20 answers) Closed 8 years ago . Let $n$ be a nonnegative integer, and $k$ a positive integer. Could someone explain to me why the identity $$ \sum_{i=0}^n\binom{i+k-1}{k-1}=\binom{n+k}{k} $$ holds?","This question already has answers here : Proof of the hockey stick/Zhu Shijie identity $\sum\limits_{t=0}^n \binom tk = \binom{n+1}{k+1}$ (20 answers) Closed 8 years ago . Let $n$ be a nonnegative integer, and $k$ a positive integer. Could someone explain to me why the identity $$ \sum_{i=0}^n\binom{i+k-1}{k-1}=\binom{n+k}{k} $$ holds?",,"['combinatorics', 'summation', 'binomial-coefficients']"
66,How to find the number of anti-symmetric relations?,How to find the number of anti-symmetric relations?,,"I know that given a set $A = \{1, 2, 3, ... , n\}$, the total number of relations on $A$ is $$2^{n^2}$$ The number of reflexive relations is $$2^{n^2 - n}$$ The number of symmetric relations is $$2^{{n+1}\choose 2}$$ But how can I find the number of anti-symmetric relations? With a small set, say $n = 4$, it can be easy to just brute force it. Is there another way (perhaps using the inclusion-exclusion principle?)","I know that given a set $A = \{1, 2, 3, ... , n\}$, the total number of relations on $A$ is $$2^{n^2}$$ The number of reflexive relations is $$2^{n^2 - n}$$ The number of symmetric relations is $$2^{{n+1}\choose 2}$$ But how can I find the number of anti-symmetric relations? With a small set, say $n = 4$, it can be easy to just brute force it. Is there another way (perhaps using the inclusion-exclusion principle?)",,"['combinatorics', 'elementary-set-theory', 'relations']"
67,Number of equivalence classes of $w \times h$ matrices under switching rows and columns,Number of equivalence classes of  matrices under switching rows and columns,w \times h,"If I have a $w \times h$ matrix where each value is an integer $0 \lt n \lt 20$ , how can I count the number of distinct configurations, where $2$ configurations are ""distinct"" if there is no way to reshuffle the rows and columns that would produce the same matrix? Can this be counted with the stars and bars method? For example, these are equal (we swapped a row, then a column): 0 0 0    2 0 4 0 2 4    0 0 0 but these are distinct (no way to swap rows or columns to produce the other): 0 0 0    2 0 0 0 2 4    0 4 0 It seems like there ought to be a way to count the rows or columns as ""bins"" and the values as balls.  I realize that in this case there are $18$ different colored balls, but even if the only values possible were $1$ and $0$ , (ball or no ball) I can't see how to represent it as stars and bars.","If I have a matrix where each value is an integer , how can I count the number of distinct configurations, where configurations are ""distinct"" if there is no way to reshuffle the rows and columns that would produce the same matrix? Can this be counted with the stars and bars method? For example, these are equal (we swapped a row, then a column): 0 0 0    2 0 4 0 2 4    0 0 0 but these are distinct (no way to swap rows or columns to produce the other): 0 0 0    2 0 0 0 2 4    0 4 0 It seems like there ought to be a way to count the rows or columns as ""bins"" and the values as balls.  I realize that in this case there are different colored balls, but even if the only values possible were and , (ball or no ball) I can't see how to represent it as stars and bars.",w \times h 0 \lt n \lt 20 2 18 1 0,"['combinatorics', 'matrices']"
68,Demonstrate another way to implement the Inclusion–exclusion principle?,Demonstrate another way to implement the Inclusion–exclusion principle?,,"I'm attempting to implement the Inclusion–exclusion principle, which is generally described as follows... $$\begin{align}  \left| \bigcup\limits_{i=1}^n A_i \right| =   + \left( \sum\limits_{i=1}^n | A_i | \right)   - \left( \sum\limits_{i,j:1 \le i<j \le n} \right. &| A_i \cap A_j |   +\cdots \\ & \cdots + (-1)^{n-1} | A_1 \cap A_2  \cap \ldots  \cap A_{n-1}  \cap A_n |\huge)  \end{align}$$ However, I wish to demonstrate that by ""mapping"" values to a binary representation (forgive/correct my language, math is not my core competency) we can find the same thing by keeping the sign as the same cardinality of the sets. Lets assume we're working with three sets, A, B and C. I could quickly generate a table based on a binary representation that shows each place value to be a set, and thus generate all my combinations: A | B | C  | Represents -----------  0 | 0 | 1  | C  0 | 1 | 0  | B  0 | 1 | 1  | C intersection B  1 | 0 | 0  | A  1 | 0 | 1  | A intersection C  1 | 1 | 0  | A intersection B  1 | 1 | 1  | A intersection B intersection C Thus I now have my sets: $$ \{ | C_i |, | B_i |, | C_i \cap B_i |, | A_i |, | A_i \cap C_i |, | A_i \cap B_i |, | A_i \cap B_i \cap C_i | \}$$ I wish to describe that the cardinality of the sets determines addition or subtraction. This is obvious with the general equation from above (negative multiplier in front of each term after the sums are calculated). Thus, from the above set we know we can simply express this equation with addition/subtraction dependent on cardinality: $$ \left|\bigcup\limits_{i=1}^3 A_i\right| = + | C_i | + | B_i | - | C_i \cap B_i | + | A_i | - | A_i \cap C_i | - | A_i \cap B_i | + | A_i \cap B_i \cap C_i | $$ I wish to express this as a general an equation, but am unsure of which concepts to use or how to implement them.","I'm attempting to implement the Inclusion–exclusion principle, which is generally described as follows... However, I wish to demonstrate that by ""mapping"" values to a binary representation (forgive/correct my language, math is not my core competency) we can find the same thing by keeping the sign as the same cardinality of the sets. Lets assume we're working with three sets, A, B and C. I could quickly generate a table based on a binary representation that shows each place value to be a set, and thus generate all my combinations: A | B | C  | Represents -----------  0 | 0 | 1  | C  0 | 1 | 0  | B  0 | 1 | 1  | C intersection B  1 | 0 | 0  | A  1 | 0 | 1  | A intersection C  1 | 1 | 0  | A intersection B  1 | 1 | 1  | A intersection B intersection C Thus I now have my sets: I wish to describe that the cardinality of the sets determines addition or subtraction. This is obvious with the general equation from above (negative multiplier in front of each term after the sums are calculated). Thus, from the above set we know we can simply express this equation with addition/subtraction dependent on cardinality: I wish to express this as a general an equation, but am unsure of which concepts to use or how to implement them.","\begin{align}
 \left| \bigcup\limits_{i=1}^n A_i \right| = 
 + \left( \sum\limits_{i=1}^n | A_i | \right) 
 - \left( \sum\limits_{i,j:1 \le i<j \le n} \right. &| A_i \cap A_j | 
 +\cdots \\
& \cdots + (-1)^{n-1} | A_1 \cap A_2  \cap \ldots  \cap A_{n-1}  \cap A_n |\huge) 
\end{align}  \{ | C_i |, | B_i |, | C_i \cap B_i |, | A_i |, | A_i \cap C_i |, | A_i \cap B_i |, | A_i \cap B_i \cap C_i | \}  \left|\bigcup\limits_{i=1}^3 A_i\right| = + | C_i | + | B_i | - | C_i \cap B_i | + | A_i | - | A_i \cap C_i | - | A_i \cap B_i | + | A_i \cap B_i \cap C_i | ","['combinatorics', 'inclusion-exclusion']"
69,How to prove that $\frac{(12!)!}{12!^{11!}}$ is integer? [duplicate],How to prove that  is integer? [duplicate],\frac{(12!)!}{12!^{11!}},This question already has answers here : Proving that $\frac{(k!)!}{k!^{(k-1)!}}$ is an integer (3 answers) Closed 2 years ago . So far I have used that a combination is an integer so $\frac{n!}{m!(n-m)!}$ is integer. Now let $n=mb$ so $\frac{mb!}{m!(mb-m)!}$. What is left is to prove that $\frac{(mb)!}{m!^b}$ is integer so that i can apply $m=12$ and $b =11!$ How to do that?,This question already has answers here : Proving that $\frac{(k!)!}{k!^{(k-1)!}}$ is an integer (3 answers) Closed 2 years ago . So far I have used that a combination is an integer so $\frac{n!}{m!(n-m)!}$ is integer. Now let $n=mb$ so $\frac{mb!}{m!(mb-m)!}$. What is left is to prove that $\frac{(mb)!}{m!^b}$ is integer so that i can apply $m=12$ and $b =11!$ How to do that?,,"['combinatorics', 'discrete-mathematics', 'combinations']"
70,Counting functions between two sets,Counting functions between two sets,,"We got this question in homework (excuse my poor translation): This question deals with counting functions between two sets: A. How many functions exist between the set $[1,2,...,n]$ and the set $\{1,2\}$ ? How many of them are onto ? B. How many functions exist between the set $\{1,2\}$ and $[1,2,...,n]$ ? How many of them are injective ? I don't really know where to start. I tried summing the Binomial coefficient, but it repeats sets. Any ideas to get me going? Thanks!","We got this question in homework (excuse my poor translation): This question deals with counting functions between two sets: A. How many functions exist between the set and the set ? How many of them are onto ? B. How many functions exist between the set and ? How many of them are injective ? I don't really know where to start. I tried summing the Binomial coefficient, but it repeats sets. Any ideas to get me going? Thanks!","[1,2,...,n] \{1,2\} \{1,2\} [1,2,...,n]","['combinatorics', 'functions', 'discrete-mathematics']"
71,How to prove that $\sum_{i=0}^n 2^i\binom{2n-i}{n} = 4^n$.,How to prove that .,\sum_{i=0}^n 2^i\binom{2n-i}{n} = 4^n,"So I've been struggling with this sum for some time and I just can't figure it out. I tried proving by induction that if the sum above is a $S_n$ then $S_{n+1} = 4S_n$, but I didn't really succeed so here I am. Thanks in advance.","So I've been struggling with this sum for some time and I just can't figure it out. I tried proving by induction that if the sum above is a $S_n$ then $S_{n+1} = 4S_n$, but I didn't really succeed so here I am. Thanks in advance.",,"['combinatorics', 'summation', 'induction', 'binomial-coefficients']"
72,Maximum number of intersections between a quadrilateral and a pentagon,Maximum number of intersections between a quadrilateral and a pentagon,,"What is the maximum number of intersection points between a quadrilateral and a pentagon, both non-intersecting? I believe the maximum is 16 as shown below, but I have no idea how to prove this. Any help or pointers would be greatly appreciated. (Or a diagram with more than 16 intersection points.)","What is the maximum number of intersection points between a quadrilateral and a pentagon, both non-intersecting? I believe the maximum is 16 as shown below, but I have no idea how to prove this. Any help or pointers would be greatly appreciated. (Or a diagram with more than 16 intersection points.)",,['combinatorics']
73,"For any given set of 13 distinct real numbers, prove we can always find two numbers $x$ and $y$ that $0<\frac{x-y}{1+xy}\leq 2-\sqrt{3}$.","For any given set of 13 distinct real numbers, prove we can always find two numbers  and  that .",x y 0<\frac{x-y}{1+xy}\leq 2-\sqrt{3},"For any given set of 13 distinct real numbers, prove we can always find two numbers x and y that $0<\dfrac{x-y}{1+xy}\leq 2-\sqrt{3}$. I knew we can always make $0<\dfrac{x-y}{1+xy}$ happen. Since x and y are distinct, we can just switch the order of x and y to change the sign of $\dfrac{x-y}{1+xy}$, but what should I do for the right hand side?","For any given set of 13 distinct real numbers, prove we can always find two numbers x and y that $0<\dfrac{x-y}{1+xy}\leq 2-\sqrt{3}$. I knew we can always make $0<\dfrac{x-y}{1+xy}$ happen. Since x and y are distinct, we can just switch the order of x and y to change the sign of $\dfrac{x-y}{1+xy}$, but what should I do for the right hand side?",,['combinatorics']
74,How do I compute multinomials efficiently?,How do I compute multinomials efficiently?,,"I'm trying to reproduce Excel's MULTINOMIAL function in C# so $${MULTINOMIAL(a,b,..,n)} = \frac{(a+b +\cdots +n)!}{a!b! \cdots n!}$$ How can I do this without causing an overflow due to the factorials?","I'm trying to reproduce Excel's MULTINOMIAL function in C# so $${MULTINOMIAL(a,b,..,n)} = \frac{(a+b +\cdots +n)!}{a!b! \cdots n!}$$ How can I do this without causing an overflow due to the factorials?",,"['combinatorics', 'multinomial-coefficients']"
75,Polynomial in $\mathbb{Q}[x]$ sending integers to integers?,Polynomial in  sending integers to integers?,\mathbb{Q}[x],"We can view the binomial coefficient $\binom{x}{k}$ has a polynomial in $x$ with degree $k$. So taking some $f\in\mathbb{Q}[x]$, why is $f(n)\in\mathbb{Z}$ for all $n\in\mathbb{Z}$, precisely when the coefficients of $f$ are integers with respect to the basis $\{\binom{x}{k}\mid k\in\mathbb{N}\}$? The reverse direction seems clear, so I wonder why the opposite implication is also true. I did notice that all the roots of $\binom{x}{k}$ are just $0,\dots,k-1$. Can we factor the polynomial is some nice way to reveal the opposite conclusion? Thanks.","We can view the binomial coefficient $\binom{x}{k}$ has a polynomial in $x$ with degree $k$. So taking some $f\in\mathbb{Q}[x]$, why is $f(n)\in\mathbb{Z}$ for all $n\in\mathbb{Z}$, precisely when the coefficients of $f$ are integers with respect to the basis $\{\binom{x}{k}\mid k\in\mathbb{N}\}$? The reverse direction seems clear, so I wonder why the opposite implication is also true. I did notice that all the roots of $\binom{x}{k}$ are just $0,\dots,k-1$. Can we factor the polynomial is some nice way to reveal the opposite conclusion? Thanks.",,"['combinatorics', 'polynomials', 'binomial-coefficients']"
76,"Choose $3n$ points on a circle, show that there are two diametrically opposite point","Choose  points on a circle, show that there are two diametrically opposite point",3n,"On a circle of length $6n$ , we choose $3n$ points such that they split the circle into $n$ arcs of length $1$ , $n$ arcs of length $2$ , $n$ arcs of length $3$ . Show that there exists two chosen points which are diametrically opposite. Source: Russian MO $1982$ Swiss MO $2006$ - Final round IMAC $2012$ Romania MO $2018$ - $9$ . grade Edit: Partition of circumference into $3k$ arcs","On a circle of length , we choose points such that they split the circle into arcs of length , arcs of length , arcs of length . Show that there exists two chosen points which are diametrically opposite. Source: Russian MO Swiss MO - Final round IMAC Romania MO - . grade Edit: Partition of circumference into $3k$ arcs",6n 3n n 1 n 2 n 3 1982 2006 2012 2018 9,"['combinatorics', 'continuity', 'contest-math', 'combinatorial-geometry']"
77,Books for combinatorial thinking,Books for combinatorial thinking,,I have looked through many discrete mathematics books but they don't put much emphasis on combinatorial thinking.What books could you recommend that are more problem-oriented and emphasize combinatorial thinking?,I have looked through many discrete mathematics books but they don't put much emphasis on combinatorial thinking.What books could you recommend that are more problem-oriented and emphasize combinatorial thinking?,,"['combinatorics', 'reference-request']"
78,Combinatorics: Selecting objects arranged in a circle,Combinatorics: Selecting objects arranged in a circle,,"If $n$ distinct objects are arranged in a circle, I need to prove that the number of ways of selecting three of these $n$ things so that no two of them are next to each other is $\frac{1}{6}n(n-4)(n-5)$. Initially I can select $1$ object in $n$ ways. Then its neighbours cannot be selected. So I will have $n-3$ objects to choose $2$ objects from. Again, I can select the second object in $n-3$ ways. The neighbours of this object cannot be selected. However from here onwards, I am unable to extend this argument as the selection of the third object is dependent on the position of the first and the second object. Is there any simpler method to prove the result?","If $n$ distinct objects are arranged in a circle, I need to prove that the number of ways of selecting three of these $n$ things so that no two of them are next to each other is $\frac{1}{6}n(n-4)(n-5)$. Initially I can select $1$ object in $n$ ways. Then its neighbours cannot be selected. So I will have $n-3$ objects to choose $2$ objects from. Again, I can select the second object in $n-3$ ways. The neighbours of this object cannot be selected. However from here onwards, I am unable to extend this argument as the selection of the third object is dependent on the position of the first and the second object. Is there any simpler method to prove the result?",,['combinatorics']
79,We have $n$ charged and $n$ uncharged batteries and a radio which needs two charged batteries to work.,We have  charged and  uncharged batteries and a radio which needs two charged batteries to work.,n n,"We have $n$ charged and $n$ uncharged batteries and a radio which needs two charged batteries to work. Suppose we don't know which batteries are charged and which ones are uncharged. Find the least number of attempts sufficient to make sure the radio will work. An attempt consists in putting two batteries in the radio and check if the radio works or not. I can prove that it is $\leq n+3$ (or $\leq n+4$ , look at the comment): Say we have batteries $B_1,B_2,....B_{2n}$ , $n$ of them charged and other not. If in one of $n$ attempts $$\{B_1,B_2\}, \{B_3,B_4\}, ...\{B_{2n-1},B_{2n}\}$$ radio work we are done. If non of them work, then in each pair we must have charged and uncharged batteries. Thus in one of next 4 pairs: $$\{B_1,B_3\}, \{B_1,B_4\}, \{B_2,B_3\}, \{B_2,B_4\}$$ must be a pair of charged batteries and we are done (so if 3 times doesn't work we know the last pair is charged). But, can we reduce the number of attempts?","We have charged and uncharged batteries and a radio which needs two charged batteries to work. Suppose we don't know which batteries are charged and which ones are uncharged. Find the least number of attempts sufficient to make sure the radio will work. An attempt consists in putting two batteries in the radio and check if the radio works or not. I can prove that it is (or , look at the comment): Say we have batteries , of them charged and other not. If in one of attempts radio work we are done. If non of them work, then in each pair we must have charged and uncharged batteries. Thus in one of next 4 pairs: must be a pair of charged batteries and we are done (so if 3 times doesn't work we know the last pair is charged). But, can we reduce the number of attempts?","n n \leq n+3 \leq n+4 B_1,B_2,....B_{2n} n n \{B_1,B_2\}, \{B_3,B_4\}, ...\{B_{2n-1},B_{2n}\} \{B_1,B_3\}, \{B_1,B_4\}, \{B_2,B_3\}, \{B_2,B_4\}","['combinatorics', 'graph-theory', 'contest-math', 'discrete-optimization', 'extremal-combinatorics']"
80,Proving that $\frac{(k!)!}{k!^{(k-1)!}}$ is an integer,Proving that  is an integer,\frac{(k!)!}{k!^{(k-1)!}},"I have to prove that: $$\frac{(k!)!}{k!^{(k-1)!}} \in \Bbb Z$$ for any $k \geq 1, k \in \Bbb N$ Tried doing $t = k!$ which would give $$\frac{t!}{t^{t/k}}$$ But I think I just made it harder, and I have no other clue!","I have to prove that: $$\frac{(k!)!}{k!^{(k-1)!}} \in \Bbb Z$$ for any $k \geq 1, k \in \Bbb N$ Tried doing $t = k!$ which would give $$\frac{t!}{t^{t/k}}$$ But I think I just made it harder, and I have no other clue!",,"['combinatorics', 'factorial']"
81,Identity involving partitions of even and odd parts.,Identity involving partitions of even and odd parts.,,"First, denote by $p_E(n)$ be the number of partitions of $n$ with an even number of parts, and let $p_O(n)$ be those with an odd number of parts. Moreover, let $p_{DO}(x)$ be the number of partitions of $n$ whose parts are distinct and odd. Finally, let $c(n)$ be the number of partitions of $n$ which are conjugate to themselves. With this notation, why does $c(n)=p_{DO}(n)=(-1)^n(p_E(n)-p_O(n))$?","First, denote by $p_E(n)$ be the number of partitions of $n$ with an even number of parts, and let $p_O(n)$ be those with an odd number of parts. Moreover, let $p_{DO}(x)$ be the number of partitions of $n$ whose parts are distinct and odd. Finally, let $c(n)$ be the number of partitions of $n$ which are conjugate to themselves. With this notation, why does $c(n)=p_{DO}(n)=(-1)^n(p_E(n)-p_O(n))$?",,"['combinatorics', 'integer-partitions', 'algebraic-combinatorics']"
82,Greatest number of parts in which n planes can divide the space,Greatest number of parts in which n planes can divide the space,,"Find the greatest number of parts including unbounded in which n planes can divide the space. I am trying like this, since it is very hard to visualize( or draw in paper). Equation of plane in 3 space could be ax + by + cz +d = 0.  If I could get an equation for number of regions I could use derivative to maximize it. We will get a region when ax + by + cz + d < 0 or > 0 in all n planes. I am unable to find a equation for number of regions.","Find the greatest number of parts including unbounded in which n planes can divide the space. I am trying like this, since it is very hard to visualize( or draw in paper). Equation of plane in 3 space could be ax + by + cz +d = 0.  If I could get an equation for number of regions I could use derivative to maximize it. We will get a region when ax + by + cz + d < 0 or > 0 in all n planes. I am unable to find a equation for number of regions.",,"['combinatorics', 'geometry', 'discrete-mathematics', 'discrete-optimization', 'discrete-geometry']"
83,Deriving the formula for the Möbius function?,Deriving the formula for the Möbius function?,,"There is a rich and beautiful theory in combinatorics which deals with the Möbius functions of posets and arrives at the ""Classical"" formula of the Möbius function. Let's forget all about it, since I'm hoping to find an elementary solution. I wish to arrive at the formula for the classical Möbius function $\mu$ (which is defined as $1$ on $1$, $0$ on non square-free numbers, and as $(-1)^k$ for square-free numbers with exactly $k$ prime divisors) from the following formula: $$\sum_{d|n}\mu(d)=\cases{1, & n=1;\\ 0, & n>1.}$$ So let's assume I'm given this formula and nothing else (especially not a pre-hand knowledge of the definition of $\mu$) - is there a simple way to derive the standard definition, without using deeper theory or ""insight""?","There is a rich and beautiful theory in combinatorics which deals with the Möbius functions of posets and arrives at the ""Classical"" formula of the Möbius function. Let's forget all about it, since I'm hoping to find an elementary solution. I wish to arrive at the formula for the classical Möbius function $\mu$ (which is defined as $1$ on $1$, $0$ on non square-free numbers, and as $(-1)^k$ for square-free numbers with exactly $k$ prime divisors) from the following formula: $$\sum_{d|n}\mu(d)=\cases{1, & n=1;\\ 0, & n>1.}$$ So let's assume I'm given this formula and nothing else (especially not a pre-hand knowledge of the definition of $\mu$) - is there a simple way to derive the standard definition, without using deeper theory or ""insight""?",,"['combinatorics', 'elementary-number-theory']"
84,Squarefree polynomials over finite fields,Squarefree polynomials over finite fields,,"I'm trying to figure out how many squarefree polynomials there are of a fixed degree over $\mathbb{F}_2$ specifically (and in general, over any finite field). Looking at some low-degree examples seems to suggest that half of the polynomials of any given degree are squarefree, but I'm not sure how to prove this, or whether the pattern continues at all. I'm considering the possibility of using the formal derivative, and the fact that a polynomial is relatively prime to its formal derivative iff it is squarefree, but I don't see how to proceed with this. So is there a known formula?","I'm trying to figure out how many squarefree polynomials there are of a fixed degree over $\mathbb{F}_2$ specifically (and in general, over any finite field). Looking at some low-degree examples seems to suggest that half of the polynomials of any given degree are squarefree, but I'm not sure how to prove this, or whether the pattern continues at all. I'm considering the possibility of using the formal derivative, and the fact that a polynomial is relatively prime to its formal derivative iff it is squarefree, but I don't see how to proceed with this. So is there a known formula?",,"['combinatorics', 'finite-fields']"
85,A question on partitions of n,A question on partitions of n,,"Let $P$ be the set of partitions of $n$. Let $\lambda$ denote the shape of a particular partition. Let $f_\lambda(i)$ be the frequency of $i$ in $\lambda$ and let $a_\lambda(i) := \# \lbrace j : f_\lambda(j) \geq i \rbrace$. For example: $n=5,~ \lambda=(1,1,3),~ f_\lambda(1)=2,~ a_\lambda(1)=2$ (added: since $f_\lambda(1)$ and $f_\lambda(3)$ are both at least 1). It is easy to see that for a fixed $\lambda$, $\sum_k f_\lambda(k)=\sum_k a_\lambda(k)$. But, I am having trouble showing: For a fixed $k$, $$\sum_\lambda f_\lambda(k)=\sum_\lambda a_\lambda(k)$$ Thanks for the help!","Let $P$ be the set of partitions of $n$. Let $\lambda$ denote the shape of a particular partition. Let $f_\lambda(i)$ be the frequency of $i$ in $\lambda$ and let $a_\lambda(i) := \# \lbrace j : f_\lambda(j) \geq i \rbrace$. For example: $n=5,~ \lambda=(1,1,3),~ f_\lambda(1)=2,~ a_\lambda(1)=2$ (added: since $f_\lambda(1)$ and $f_\lambda(3)$ are both at least 1). It is easy to see that for a fixed $\lambda$, $\sum_k f_\lambda(k)=\sum_k a_\lambda(k)$. But, I am having trouble showing: For a fixed $k$, $$\sum_\lambda f_\lambda(k)=\sum_\lambda a_\lambda(k)$$ Thanks for the help!",,"['combinatorics', 'representation-theory', 'integer-partitions', 'symmetric-groups']"
86,The pigeonhole principle(?),The pigeonhole principle(?),,"I have this question that seems to be an application of the Pigeonhole Principle, but I can't see how. Let $n\geq3$. Consider the set $S=\{1,2,\ldots,n\}$ and $2n+1$ nonempty random subsets of $S$. Prove that there are at least three of those subsets $B_1,B_2,B_3$ such that $(\forall i\neq j)B_i\not\subset B_j$. How can I apply the pigeonhole principle for this?Is the straightforward approach any good? I am asking because the way the statement is, a proof by contradiction seems more appropriate... I tried constructing the three sets out of a given random choice of subsets: Say $A_1,A_2,...,A_{2n+1}$ are the 2n+1 subsets. Since the choice is random, we can consider that a subcollection exists, say A,B,...,C such that these sets have at least one element of S not in common. These would be the boxes in the principle...","I have this question that seems to be an application of the Pigeonhole Principle, but I can't see how. Let $n\geq3$. Consider the set $S=\{1,2,\ldots,n\}$ and $2n+1$ nonempty random subsets of $S$. Prove that there are at least three of those subsets $B_1,B_2,B_3$ such that $(\forall i\neq j)B_i\not\subset B_j$. How can I apply the pigeonhole principle for this?Is the straightforward approach any good? I am asking because the way the statement is, a proof by contradiction seems more appropriate... I tried constructing the three sets out of a given random choice of subsets: Say $A_1,A_2,...,A_{2n+1}$ are the 2n+1 subsets. Since the choice is random, we can consider that a subcollection exists, say A,B,...,C such that these sets have at least one element of S not in common. These would be the boxes in the principle...",,"['combinatorics', 'pigeonhole-principle']"
87,Algorithm for generating integer partitions up to a certain maximum length,Algorithm for generating integer partitions up to a certain maximum length,,"I'm looking for a fast algorithm for generating all the partitions of an integer up to a certain maximum length; ideally, I don't want to have to generate all of them and then discard the ones that are too long, as this will take around 5 times longer in my case. Specifically, given $L = N(N+1)$ , I need to generate all the partitions of $L$ that have at most $N$ parts. I can't seem to find any algorithms that'll do this directly; all I've found that seems relevant is this paper, which I unfortunately can't seem to access via my institution's subscription. It apparently 1 documents an algorithm that generates the partitions of each individual length, which could presumably be easily adapted to my needs. Does anyone know of any such algorithms? 1 Zoghbi, Antoine; Stojmenović, Ivan , Fast algorithms for generating integer partitions , Int. J. Comput. Math. 70, No. 2, 319-332 (1998). ZBL0918.68040 , MR1712501 . Wayback Machine","I'm looking for a fast algorithm for generating all the partitions of an integer up to a certain maximum length; ideally, I don't want to have to generate all of them and then discard the ones that are too long, as this will take around 5 times longer in my case. Specifically, given , I need to generate all the partitions of that have at most parts. I can't seem to find any algorithms that'll do this directly; all I've found that seems relevant is this paper, which I unfortunately can't seem to access via my institution's subscription. It apparently 1 documents an algorithm that generates the partitions of each individual length, which could presumably be easily adapted to my needs. Does anyone know of any such algorithms? 1 Zoghbi, Antoine; Stojmenović, Ivan , Fast algorithms for generating integer partitions , Int. J. Comput. Math. 70, No. 2, 319-332 (1998). ZBL0918.68040 , MR1712501 . Wayback Machine",L = N(N+1) L N,"['combinatorics', 'algorithms', 'integer-partitions']"
88,"""Math Lotto"" Tickets - finding the minimum winning set","""Math Lotto"" Tickets - finding the minimum winning set",,"""Math lotto"" is played as follows:  a player marks six squares on a 6x6 square. Then six  ""losing squares"" are drawn. A player wins if none of the losing squares are marked on his lottery ticket. 1)Prove that one can complete nine lottery tickets in such a way that at least one of them wins. 2)Prove that this is not possible with only eight tickets. My attempt is as follows; First I divided the square into 6 rectangles (figure 1). If one rectangle doesn't contain a cross then some ticket (ticket 1 to ticket 6) would win the game. Now we consider the case where each rectangle has one cross each. Now take the two rectangles on the top left of the square (figure 2). These have a total of two crosses. The first two columns together contains one cross and the third and fourth columns together contains one cross. There are four cases and we need at least four tickets (ticket 7 to ticket 10) to ensure win. I am only getting a minimum of ten tickets. How do I prove only nine tickets is required and for eight tickets it is not possible? Reference: Combinatorics by Stephan Wagner, Page 42, Problem 49 . https://math.sun.ac.za/swagner/Combinatorics.pdf","""Math lotto"" is played as follows:  a player marks six squares on a 6x6 square. Then six  ""losing squares"" are drawn. A player wins if none of the losing squares are marked on his lottery ticket. 1)Prove that one can complete nine lottery tickets in such a way that at least one of them wins. 2)Prove that this is not possible with only eight tickets. My attempt is as follows; First I divided the square into 6 rectangles (figure 1). If one rectangle doesn't contain a cross then some ticket (ticket 1 to ticket 6) would win the game. Now we consider the case where each rectangle has one cross each. Now take the two rectangles on the top left of the square (figure 2). These have a total of two crosses. The first two columns together contains one cross and the third and fourth columns together contains one cross. There are four cases and we need at least four tickets (ticket 7 to ticket 10) to ensure win. I am only getting a minimum of ten tickets. How do I prove only nine tickets is required and for eight tickets it is not possible? Reference: Combinatorics by Stephan Wagner, Page 42, Problem 49 . https://math.sun.ac.za/swagner/Combinatorics.pdf",,"['combinatorics', 'pigeonhole-principle', 'coloring', 'combinatorial-designs', 'lotteries']"
89,An interesting combinatorics problem,An interesting combinatorics problem,,"$A$ is a set containing $n$ elements. A subset $P_1$ of $A$ is chosen. The set is reconstructed by replacing the elements of $P_1$. Then a subset $P_2$ is chosen and again the set is reconstructed by replacing the elements of $P_2$. In this way $m$ subsets $P_1,......,P_m$ are chosen where $m>1$. Find the number of ways of choosing $P_1,.......,P_m$ such that no two of them  are pairwise disjoint. I don't have any clue how to start this problem I tried a lot of things but couldn't even get close to a conclusion. Edit: An equivalent (and hopefully simpler and neater) way of putting it. Given a set $A$ with $n$ elements, let $B=(P_1,P_2 \cdots, P_m)$ be a tuple of $m$ non-empty subsets of $A$, $P_i \subset A$ such that $P_i \cap P_j \ne \varnothing$. How many different $B$ there are?","$A$ is a set containing $n$ elements. A subset $P_1$ of $A$ is chosen. The set is reconstructed by replacing the elements of $P_1$. Then a subset $P_2$ is chosen and again the set is reconstructed by replacing the elements of $P_2$. In this way $m$ subsets $P_1,......,P_m$ are chosen where $m>1$. Find the number of ways of choosing $P_1,.......,P_m$ such that no two of them  are pairwise disjoint. I don't have any clue how to start this problem I tried a lot of things but couldn't even get close to a conclusion. Edit: An equivalent (and hopefully simpler and neater) way of putting it. Given a set $A$ with $n$ elements, let $B=(P_1,P_2 \cdots, P_m)$ be a tuple of $m$ non-empty subsets of $A$, $P_i \subset A$ such that $P_i \cap P_j \ne \varnothing$. How many different $B$ there are?",,['combinatorics']
90,How much would it cost to try every possible burger combination?,How much would it cost to try every possible burger combination?,,"I was at a restaurant that allows you to build your own custom burger. I got bored and started to work out how many possible combinations of burger there could be. After figuring that out and sharing the number with a friend he wondered how much it would cost you if you were to order every possible combination. This is where I got stuck. Ignoring all the options that don't affect the price here's the basic menu: Choose either one (\$7.99) or two (\$9.48) patties. Choose from 7 cheeses \$0.89 each Choose from 10 hot toppings \$0.99 each Choose from 3 premium toppings \$1.49 each Choose from 4 cold toppings \$0.39 each I've been mulling it over in my head for a few days and I can't really figure out a good way to go about it. The best thing I've come up with so far is to pick a category and find out the total to try all combinations in that category using $\sum _{i=1}^m \binom{m}{i} c i$ where $c$ is the cost per item and $m$ is the total number of items to choose from. Then taking that and multiplying it by all the other possibilities created by the other categories. Please forgive me if I'm missing something obvious or screwed something up, my formal schooling doesn't extend much beyond algebra and that was a decade ago.","I was at a restaurant that allows you to build your own custom burger. I got bored and started to work out how many possible combinations of burger there could be. After figuring that out and sharing the number with a friend he wondered how much it would cost you if you were to order every possible combination. This is where I got stuck. Ignoring all the options that don't affect the price here's the basic menu: Choose either one (\$7.99) or two (\$9.48) patties. Choose from 7 cheeses \$0.89 each Choose from 10 hot toppings \$0.99 each Choose from 3 premium toppings \$1.49 each Choose from 4 cold toppings \$0.39 each I've been mulling it over in my head for a few days and I can't really figure out a good way to go about it. The best thing I've come up with so far is to pick a category and find out the total to try all combinations in that category using $\sum _{i=1}^m \binom{m}{i} c i$ where $c$ is the cost per item and $m$ is the total number of items to choose from. Then taking that and multiplying it by all the other possibilities created by the other categories. Please forgive me if I'm missing something obvious or screwed something up, my formal schooling doesn't extend much beyond algebra and that was a decade ago.",,['combinatorics']
91,Is it possible to uniquely number faces of a hexagonal grid with consecutive numbers?,Is it possible to uniquely number faces of a hexagonal grid with consecutive numbers?,,"You have a grid of regular hexagons. The aim of the game is to have each hex contain the numbers 1-6 on its edges. Each edge must also be connected to another edge that has a value one higher and one lower than the value of itself, with 6's wrapping to 1's. The other two edges can be any number as long as the first rule isn't broken. Below, I have completed a small section by hand as an example: Can this pattern propagate to a hex grid of infinite size and does it repeat? In this example I started with a hex labeled 1-6 going anti-clockwise from the top however this is not a requirement.","You have a grid of regular hexagons. The aim of the game is to have each hex contain the numbers 1-6 on its edges. Each edge must also be connected to another edge that has a value one higher and one lower than the value of itself, with 6's wrapping to 1's. The other two edges can be any number as long as the first rule isn't broken. Below, I have completed a small section by hand as an example: Can this pattern propagate to a hex grid of infinite size and does it repeat? In this example I started with a hex labeled 1-6 going anti-clockwise from the top however this is not a requirement.",,"['combinatorics', 'graph-theory', 'puzzle', 'coloring', 'tessellations']"
92,The 'Unlock All Digits' Game,The 'Unlock All Digits' Game,,"I challenged myself and thought of a new problem I tried to solve. Here are the rules : The goal is to 'unlock' all the numbers $0,1,2,3,4,5,6,7,8$ and $9$ When you start the game, the only number to be unlocked is $0$ To unlock a number, you must express it as the result of an operation between two numbers you already unlocked The set of allowed operation between two unlocked number $a$ and $b$ is : $a+b$, $a-b$, $a*b$, $a/b$, $a^b$, $log_{(a)}b$, $\sqrt[a]{b}$, $S(a) = a+1$ and $P(a) = a-1$ You can use each operation only once. Here's an example : $0$ is unlocked $S(0) = 1$  is unlocked $1+1 = 2$ is unlocked $2*2 = 4$ is unlocked $4-1 = 3$ is unlocked $3^2 = 9$ is unlocked $P(9) = 8$ is unlocked In this example the digits unlocked are : $0,1,2,3,4,8,9$. My question is : Is it possible to unlock all digits with these rules ? If you have interesting and solvable variants in mind, I would be pleased to hear about it. EDIT : There is no solutions. But if you replace the initially unlocked $0$ by another digit, you will be able to find solutions for digits $4,5,6,7,8,9$.","I challenged myself and thought of a new problem I tried to solve. Here are the rules : The goal is to 'unlock' all the numbers $0,1,2,3,4,5,6,7,8$ and $9$ When you start the game, the only number to be unlocked is $0$ To unlock a number, you must express it as the result of an operation between two numbers you already unlocked The set of allowed operation between two unlocked number $a$ and $b$ is : $a+b$, $a-b$, $a*b$, $a/b$, $a^b$, $log_{(a)}b$, $\sqrt[a]{b}$, $S(a) = a+1$ and $P(a) = a-1$ You can use each operation only once. Here's an example : $0$ is unlocked $S(0) = 1$  is unlocked $1+1 = 2$ is unlocked $2*2 = 4$ is unlocked $4-1 = 3$ is unlocked $3^2 = 9$ is unlocked $P(9) = 8$ is unlocked In this example the digits unlocked are : $0,1,2,3,4,8,9$. My question is : Is it possible to unlock all digits with these rules ? If you have interesting and solvable variants in mind, I would be pleased to hear about it. EDIT : There is no solutions. But if you replace the initially unlocked $0$ by another digit, you will be able to find solutions for digits $4,5,6,7,8,9$.",,"['combinatorics', 'recreational-mathematics']"
93,"Find the number of pairs $(m, n)$ of positive integers such that $\frac{ m}{n+1} < \sqrt{2} < \frac{m+1}{n}$",Find the number of pairs  of positive integers such that,"(m, n) \frac{ m}{n+1} < \sqrt{2} < \frac{m+1}{n}","Find the number of pairs $(m, n)$ of positive integers such that $\frac{ m}{n+1} < \sqrt{2} < \frac{m+1}{n}$ Constraint: $m$ and $n$ are both less than or equal to 1000 I toiled over this problem for a bit. I tested the first few positive integers of m and found the corresponding values of $n$, but no real pattern seemed to emerge. Clearly $m \ge n$ . I believe that for each value of $m$, there were either two or one value(s) for $n$ in no clear order, which is the part that is messing me up. This is meant to be done by hand so I have not used any software on it.","Find the number of pairs $(m, n)$ of positive integers such that $\frac{ m}{n+1} < \sqrt{2} < \frac{m+1}{n}$ Constraint: $m$ and $n$ are both less than or equal to 1000 I toiled over this problem for a bit. I tested the first few positive integers of m and found the corresponding values of $n$, but no real pattern seemed to emerge. Clearly $m \ge n$ . I believe that for each value of $m$, there were either two or one value(s) for $n$ in no clear order, which is the part that is messing me up. This is meant to be done by hand so I have not used any software on it.",,"['combinatorics', 'number-theory', 'inequality']"
94,Name for the fact that a mattress can't be evenly rotated by repeatedly applying the same transformation?,Name for the fact that a mattress can't be evenly rotated by repeatedly applying the same transformation?,,"Please excuse any errors in terminology or notation, I am neither a mathematician nor do I play one on TV. I'm pretty sure this is a known problem, probably named, but I lack the background knowledge to even know where to start. All the searching I've done has gotten me advice on how to rotate my mattress, and information on different cycles -- carnot, nitrogen, biogeochemical, etc. You're supposed to rotate and flip a mattress so that your head rests on one end 1/4 of the time. Let's label the mattress so that it has a top and a bottom, and a north side and a south side: +---T---+ |       | +---B---+  +---N---+ |       | |       | |       | |       | +---S---+ There are four states the mattress can be in: {TN, TS, BN, BS}. To flip a mattress exchanges (T,B), to rotate it exchanges (N,S). There is no combination of flipping and rotation that when continuously repeated will visit all the states -- if you flip the (N,S) state remains the same; if you rotate the (T,B) state remains the same; if you flip and rotate you still flip-flop between two states. If I'm not mistaken the number of states you can achieve by cycling through substates with degrees $m, n, ...$ is $LCM(m, n, ...)$. What is the name of this property, and the fact that this will enumerate all states iff $m, n, ...$ are all co-prime?","Please excuse any errors in terminology or notation, I am neither a mathematician nor do I play one on TV. I'm pretty sure this is a known problem, probably named, but I lack the background knowledge to even know where to start. All the searching I've done has gotten me advice on how to rotate my mattress, and information on different cycles -- carnot, nitrogen, biogeochemical, etc. You're supposed to rotate and flip a mattress so that your head rests on one end 1/4 of the time. Let's label the mattress so that it has a top and a bottom, and a north side and a south side: +---T---+ |       | +---B---+  +---N---+ |       | |       | |       | |       | +---S---+ There are four states the mattress can be in: {TN, TS, BN, BS}. To flip a mattress exchanges (T,B), to rotate it exchanges (N,S). There is no combination of flipping and rotation that when continuously repeated will visit all the states -- if you flip the (N,S) state remains the same; if you rotate the (T,B) state remains the same; if you flip and rotate you still flip-flop between two states. If I'm not mistaken the number of states you can achieve by cycling through substates with degrees $m, n, ...$ is $LCM(m, n, ...)$. What is the name of this property, and the fact that this will enumerate all states iff $m, n, ...$ are all co-prime?",,"['combinatorics', 'group-theory', 'finite-groups']"
95,minimum number of steps for knight in chess,minimum number of steps for knight in chess,,"Given two squares on an 8×8 chess board, how can we determine the minimum number of moves required by a knight to reach one square starting from the other?","Given two squares on an 8×8 chess board, how can we determine the minimum number of moves required by a knight to reach one square starting from the other?",,['combinatorics']
96,Game to maintain distinct number of balls in glasses,Game to maintain distinct number of balls in glasses,,"There are $n$ glasses, containing $n+1,n+2,\ldots,2n$ balls, respectively. Two players $A$ and $B$ play a game, alternately taking turns with $A$ going first. In each move, the player must choose some balls (perhaps all, but not empty) from one glass, so that the number of balls remain pairwise distinct. The player who cannot move loses. Who can win? The position where the game ends must be $0,1,\ldots,n-1$, since otherwise there is a move left. To reach this position, the game must be in the position where $n-1$ of the $n$ glasses coincide with the end position. For $n=1$, $A$ wins after the first move. For $n=2$, $A$ takes off two balls from $4$ to get to $3,2$. Then whatever $B$ does, some glass contains $0$ or $1$ balls, so $A$ wins in the next turn.","There are $n$ glasses, containing $n+1,n+2,\ldots,2n$ balls, respectively. Two players $A$ and $B$ play a game, alternately taking turns with $A$ going first. In each move, the player must choose some balls (perhaps all, but not empty) from one glass, so that the number of balls remain pairwise distinct. The player who cannot move loses. Who can win? The position where the game ends must be $0,1,\ldots,n-1$, since otherwise there is a move left. To reach this position, the game must be in the position where $n-1$ of the $n$ glasses coincide with the end position. For $n=1$, $A$ wins after the first move. For $n=2$, $A$ takes off two balls from $4$ to get to $3,2$. Then whatever $B$ does, some glass contains $0$ or $1$ balls, so $A$ wins in the next turn.",,"['combinatorics', 'game-theory', 'combinatorial-game-theory']"
97,How to find the smallest number with just $0$ and $1$ which is divided by a given number?,How to find the smallest number with just  and  which is divided by a given number?,0 1,Every positive integer divide some number whose representation (base $10$) contains only zeroes and ones. One can easily prove that using pigeonhole principle. Some examples: 2 -> 10 3 -> 111 4 -> 100 ... But how to find the smallest answer? Is there any way to find it efficiently?,Every positive integer divide some number whose representation (base $10$) contains only zeroes and ones. One can easily prove that using pigeonhole principle. Some examples: 2 -> 10 3 -> 111 4 -> 100 ... But how to find the smallest answer? Is there any way to find it efficiently?,,"['combinatorics', 'number-theory', 'project-euler']"
98,Count the number of integer solutions to $x_1+x_2+\cdots+x_5=36$ [duplicate],Count the number of integer solutions to  [duplicate],x_1+x_2+\cdots+x_5=36,"This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . How to count the number of integer solutions to  $x_1+x_2+\cdots+x_5=36$ such that $x_1\ge 4,x_3 = 11,x_4\ge 7$ And how about $x_1\ge 4, x_3=11,x_4\ge 7,x_5\le 5$ In both cases, $x_1,x_2,x_3,x_4,x_5$ must be nonnegative integers. Is there a general formula to calculate things like this?","This question already has answers here : Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$ (5 answers) Closed 1 year ago . How to count the number of integer solutions to  $x_1+x_2+\cdots+x_5=36$ such that $x_1\ge 4,x_3 = 11,x_4\ge 7$ And how about $x_1\ge 4, x_3=11,x_4\ge 7,x_5\le 5$ In both cases, $x_1,x_2,x_3,x_4,x_5$ must be nonnegative integers. Is there a general formula to calculate things like this?",,"['combinatorics', 'diophantine-equations', 'integer-partitions']"
99,When is the number of areas obtained by cutting a circle with $n$ chords a power of $2$?,When is the number of areas obtained by cutting a circle with  chords a power of ?,n 2,"Also asked on MathOverflow: When is the number of areas obtained by cutting a circle with $n$ chords a power of $2$ ? Introduction Recently, a friend told me about the following interesting fact: Place $n$ points on a circle and draw a line between every pair of points. Suppose that no three lines intersect at one point. Then the number of regions which are separated by the lines is equal to the sum of the first five numbers in the $n-1$ st row of Pascal's triangle! See this image image (from Wikipedia ). Here, $n$ is the number of points, $c$ is the number of lines and $r_G$ is the number of regions: Here is a great video by 3Blue1Brown on this subject: Circle Division Solution . The series is A000127 in the OEIS. Preliminary results The following is known (see again Wikipedia for instance): For $n$ points, the number of resulting regions is $$1+\binom n2+\binom n4 = \sum_{i=0}^4 \binom{n-1}i=\text{sum of first } 5 \text{ numbers in $n$th row of Pascal's triang.}=\frac{1}{24}n(n^3-6n^2+23n-18)+1.$$ In particular, for $n\in\{1,2,3,4,5,10\}$ , the number of areas is a power of $2$ . My question Is it true that, for any other $n$ , the number of areas is not a power of two? Some attempts First off, we can simply check that for $n\in\{6,7,8,9\}$ , the number of areas is not a power of two. So the question is equivalent to: Is it true that, for any $n\geq 11$ , the number of areas is not a power of $2$ ? The following Proposition is easy to prove: Proposition. For $n> 5$ , we have that $f(n)< 2^{n-1}$ , where $f(n)$ denotes the number of regions. Proof. For $n>5$ we have $$f(n)=\sum_{i=0}^{n-1} \binom{n-1}i-\sum_{i=5}^{n-1}\binom{n-1}i = 2^{n-1}-\sum_{i=5}^{n-1}\binom{n-1}i<2^{n-1}.\square$$ However, this only proves that $f(n)\neq 2^{n-1}$ for any $n>6$ . There could still be some $m\in\mathbb N$ with $m<n$ such that $f(n)=2^m$ .","Also asked on MathOverflow: When is the number of areas obtained by cutting a circle with chords a power of ? Introduction Recently, a friend told me about the following interesting fact: Place points on a circle and draw a line between every pair of points. Suppose that no three lines intersect at one point. Then the number of regions which are separated by the lines is equal to the sum of the first five numbers in the st row of Pascal's triangle! See this image image (from Wikipedia ). Here, is the number of points, is the number of lines and is the number of regions: Here is a great video by 3Blue1Brown on this subject: Circle Division Solution . The series is A000127 in the OEIS. Preliminary results The following is known (see again Wikipedia for instance): For points, the number of resulting regions is In particular, for , the number of areas is a power of . My question Is it true that, for any other , the number of areas is not a power of two? Some attempts First off, we can simply check that for , the number of areas is not a power of two. So the question is equivalent to: Is it true that, for any , the number of areas is not a power of ? The following Proposition is easy to prove: Proposition. For , we have that , where denotes the number of regions. Proof. For we have However, this only proves that for any . There could still be some with such that .","n 2 n n-1 n c r_G n 1+\binom n2+\binom n4 = \sum_{i=0}^4 \binom{n-1}i=\text{sum of first } 5 \text{ numbers in nth row of Pascal's triang.}=\frac{1}{24}n(n^3-6n^2+23n-18)+1. n\in\{1,2,3,4,5,10\} 2 n n\in\{6,7,8,9\} n\geq 11 2 n> 5 f(n)< 2^{n-1} f(n) n>5 f(n)=\sum_{i=0}^{n-1} \binom{n-1}i-\sum_{i=5}^{n-1}\binom{n-1}i = 2^{n-1}-\sum_{i=5}^{n-1}\binom{n-1}i<2^{n-1}.\square f(n)\neq 2^{n-1} n>6 m\in\mathbb N m<n f(n)=2^m","['combinatorics', 'number-theory', 'circles', 'diophantine-equations']"
