,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Equivalent definitions for conformal map,Equivalent definitions for conformal map,,"I've encountered several definitions for conformal maps, and I was wondering whether they are equivalent or not. My goal is understanding how the concepts of conformality and holomorphy relate to each other. One of the definitions says that conformal maps are the ones which preserve angles at a certain point (both orientation and size). Thus, for a map to be conformal in an open set U, it must be conformal at each point in U. On the other hand, a conformal map can be defined as a holomorphic function with non-vanishing derivative at all points in some open set U. Under the second definition, it is easy to prove that conformality and holomorphy are equivalent. Under the first definition, it is clear that holomorphy still implies conformality, but it isn't as obvious that conformality implies holomorphy. Could anyone shed some light on this topic? Thanks in advance.","I've encountered several definitions for conformal maps, and I was wondering whether they are equivalent or not. My goal is understanding how the concepts of conformality and holomorphy relate to each other. One of the definitions says that conformal maps are the ones which preserve angles at a certain point (both orientation and size). Thus, for a map to be conformal in an open set U, it must be conformal at each point in U. On the other hand, a conformal map can be defined as a holomorphic function with non-vanishing derivative at all points in some open set U. Under the second definition, it is easy to prove that conformality and holomorphy are equivalent. Under the first definition, it is clear that holomorphy still implies conformality, but it isn't as obvious that conformality implies holomorphy. Could anyone shed some light on this topic? Thanks in advance.",,"['complex-analysis', 'conformal-geometry']"
1,Existence of an analytic function by estimate,Existence of an analytic function by estimate,,Does there exist an analytic function on the unit disc s.t. $|f\left(\frac1n\right)−\frac{(−1)^n}{n^2}|<\frac{1}{n^3}$ for all $n\geq2$ ? See my idea but I don’t know how to complete the proof. I know such analytic function doesn’t exist.,Does there exist an analytic function on the unit disc s.t. for all ? See my idea but I don’t know how to complete the proof. I know such analytic function doesn’t exist.,|f\left(\frac1n\right)−\frac{(−1)^n}{n^2}|<\frac{1}{n^3} n\geq2,"['complex-analysis', 'analytic-functions']"
2,What is the $L^2$ space of sections of a vector bundle?,What is the  space of sections of a vector bundle?,L^2,The vector bundle in question can be a holomorphic line bundle with a hermitian metric. Given $\mathcal{L}$ a holomorphic line bundle with transition functions $g_{ij}$ a section is defined as a collection ${h_i}$ such that $h_i=g_{ij}h_j$ . Or is another definition of sections better for this purpose? Oh i should probably mention that this is on a compact Riemann surface.,The vector bundle in question can be a holomorphic line bundle with a hermitian metric. Given a holomorphic line bundle with transition functions a section is defined as a collection such that . Or is another definition of sections better for this purpose? Oh i should probably mention that this is on a compact Riemann surface.,\mathcal{L} g_{ij} {h_i} h_i=g_{ij}h_j,"['complex-analysis', 'functional-analysis', 'differential-geometry']"
3,Is this proof that $e^z$ is transcendental correct?,Is this proof that  is transcendental correct?,e^z,"Lemma .  If $p(z)$ is a non-zero polynomial and $k\geq 1$ a natural number, then there exists a polynomial $q(z)$ of the same degree such that $\frac{d}{dz}\Big(p(z)\cdot e^{kz}\Big) = q(z)\cdot e^{kz}$ .  (Indeed, \begin{align} \frac{d}{dz}\Big(p(z)\cdot e^{kz}\Big) &= p'(z)\cdot e^{kz} + kp(z)\cdot e^{kz} \\ &= e^{kz}\Big(p'(z) + kp(z)\Big), \end{align} and $p'(z) + kp(z)$ has the same degree as $p(z)$ .) $\quad\square$ Recall that $f(z)$ is an algebraic function iff there exists a polynomial $F(z, y)\in\mathbb{Q}[X, Y]$ such that $F(z, f(z))\equiv 0.$ Assume that $e^z$ is algebraic and let \begin{equation} F(z, y) = \sum_{k=0}^n p_k(z)y^k = p_0(z) + \sum_{k=1}^n p_k(z)y^k,\quad p_n(z)\not\equiv 0, \end{equation} be a polynomial of minimal degree in $y$ such that $F(z, e^z) \equiv 0$ . Now, $p_0(z)$ cannot be the zero polynomial, or else $F(z, y) = y\cdot G(z, y)$ , where $G$ is a polynomial of strictly lesser degree in $y$ than $F$ such that $G(z, e^z)\equiv 0$ (this because $e^z$ vanishes nowhere), contradicting the minimality of $deg_y(F)$ .  So call $d:= deg(p_0\big(z)\big)$ and take $\frac{d^{d+1}}{dz^{d+1}}$ of both sides of the equation $F(z, e^z) \equiv 0$ .  By linearity of derivative, the lemma, and the fact that the $(d+1)^{th}$ derivative of a degree $d$ polynomial is identically zero, this results in the equation \begin{equation} \sum_{k=1}^n q_k(z)e^{kz} \equiv 0, \end{equation} where $\deg(q_k) = \deg(p_k)$ for all $k\geq 1$ .  We may factor $e^z$ out of this equation to obtain \begin{equation} e^z\cdot\sum_{k=0}^{n-1} q_{k+1}(z)e^{kz} \equiv 0, \end{equation} and since $e^z$ vanishes nowhere this equality implies that \begin{equation} \sum_{k=0}^{n-1} q_{k+1}(z)e^{kz} \equiv 0. \end{equation} But this implies that $\deg_y(F)$ was not minimal after all, contradiction.  So $e^z$ must be transcendental, ce qu'il fallait démontrer . $\clubsuit$","Lemma .  If is a non-zero polynomial and a natural number, then there exists a polynomial of the same degree such that .  (Indeed, and has the same degree as .) Recall that is an algebraic function iff there exists a polynomial such that Assume that is algebraic and let be a polynomial of minimal degree in such that . Now, cannot be the zero polynomial, or else , where is a polynomial of strictly lesser degree in than such that (this because vanishes nowhere), contradicting the minimality of .  So call and take of both sides of the equation .  By linearity of derivative, the lemma, and the fact that the derivative of a degree polynomial is identically zero, this results in the equation where for all .  We may factor out of this equation to obtain and since vanishes nowhere this equality implies that But this implies that was not minimal after all, contradiction.  So must be transcendental, ce qu'il fallait démontrer .","p(z) k\geq 1 q(z) \frac{d}{dz}\Big(p(z)\cdot e^{kz}\Big) = q(z)\cdot e^{kz} \begin{align}
\frac{d}{dz}\Big(p(z)\cdot e^{kz}\Big) &= p'(z)\cdot e^{kz} + kp(z)\cdot e^{kz} \\
&= e^{kz}\Big(p'(z) + kp(z)\Big),
\end{align} p'(z) + kp(z) p(z) \quad\square f(z) F(z, y)\in\mathbb{Q}[X, Y] F(z, f(z))\equiv 0. e^z \begin{equation}
F(z, y) = \sum_{k=0}^n p_k(z)y^k = p_0(z) + \sum_{k=1}^n p_k(z)y^k,\quad p_n(z)\not\equiv 0,
\end{equation} y F(z, e^z) \equiv 0 p_0(z) F(z, y) = y\cdot G(z, y) G y F G(z, e^z)\equiv 0 e^z deg_y(F) d:= deg(p_0\big(z)\big) \frac{d^{d+1}}{dz^{d+1}} F(z, e^z) \equiv 0 (d+1)^{th} d \begin{equation}
\sum_{k=1}^n q_k(z)e^{kz} \equiv 0,
\end{equation} \deg(q_k) = \deg(p_k) k\geq 1 e^z \begin{equation}
e^z\cdot\sum_{k=0}^{n-1} q_{k+1}(z)e^{kz} \equiv 0,
\end{equation} e^z \begin{equation}
\sum_{k=0}^{n-1} q_{k+1}(z)e^{kz} \equiv 0.
\end{equation} \deg_y(F) e^z \clubsuit","['complex-analysis', 'exponential-function', 'transcendental-functions']"
4,Polynomial in terms of coordinate functionals,Polynomial in terms of coordinate functionals,,"I am trying to write a m-homogeneous polynomial in terms of coordinate functionals by using permutations in $S_m$ . I am not sure about how should I go for getting this representation? Here, $P \in \mathcal P\left({ }^m E\right)$ denotes the vector space of all m-homogeneous polynomials from $E$ into $\Bbb C$ And $S_m$ is the symmetric group. Thanks in advance for any help.","I am trying to write a m-homogeneous polynomial in terms of coordinate functionals by using permutations in . I am not sure about how should I go for getting this representation? Here, denotes the vector space of all m-homogeneous polynomials from into And is the symmetric group. Thanks in advance for any help.",S_m P \in \mathcal P\left({ }^m E\right) E \Bbb C S_m,"['complex-analysis', 'polynomials', 'banach-spaces']"
5,Is any Euclidean ball contained in D some pseudo-hyperbolic ball?,Is any Euclidean ball contained in D some pseudo-hyperbolic ball?,,"We have that the pseudo-hyperbolic distance in the open unit disk $\mathbb D$ is defined by $$ \rho(z,w) = |\phi_w(z)|,  \qquad \phi_w(z) = \frac{w - z}{1 - \overline w z}$$ where $z,w \in \mathbb D.$ And the pseudo-hyperbolic ball is defined by $$ \Delta(p,r) = \{z \in \mathbb{D} | \rho(p,z)<r\}, \quad 0<r<1.$$ There is a proposition which says that for any $p\in\mathbb{D}$ and $0<r<1$ , the pseudo-hyperbolic ball is a Euclidean ball with center and radius given by $$P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r,$$ i.e. $\Delta(p,r) = B(P,R).$ Composition Operators and Classical Function Theory says that The pseudo-hyperbolic distance induces the usual Euclidean topology. and I'd like to prove it. By the proposition mentioned above, it's clear that the topology induced by pseudo-hyperbolic distance is contained in the Euclidean topology. However, when I want to prove the inverse relation, I have no idea but to prove that ""any Euclidean ball contained in $\mathbb{D}$ is also some pseudo-hyperbolic ball"", which means that for any given $P \in \mathbb{D}, 0<R<1, B(P,R) \subset \mathbb{D}, \exists p \in \mathbb{D}$ and $0<r<1$ , s.t $$P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r$$ holds. But I don't know how to prove it. My questions are: Is my assumption above right? If not, how can I prove ""The pseudo-hyperbolic distance induces the usual Euclidean topology""?","We have that the pseudo-hyperbolic distance in the open unit disk is defined by where And the pseudo-hyperbolic ball is defined by There is a proposition which says that for any and , the pseudo-hyperbolic ball is a Euclidean ball with center and radius given by i.e. Composition Operators and Classical Function Theory says that The pseudo-hyperbolic distance induces the usual Euclidean topology. and I'd like to prove it. By the proposition mentioned above, it's clear that the topology induced by pseudo-hyperbolic distance is contained in the Euclidean topology. However, when I want to prove the inverse relation, I have no idea but to prove that ""any Euclidean ball contained in is also some pseudo-hyperbolic ball"", which means that for any given and , s.t holds. But I don't know how to prove it. My questions are: Is my assumption above right? If not, how can I prove ""The pseudo-hyperbolic distance induces the usual Euclidean topology""?","\mathbb D  \rho(z,w) = |\phi_w(z)|,  \qquad \phi_w(z) = \frac{w - z}{1 - \overline w z} z,w \in \mathbb D.  \Delta(p,r) = \{z \in \mathbb{D} | \rho(p,z)<r\}, \quad 0<r<1. p\in\mathbb{D} 0<r<1 P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r, \Delta(p,r) = B(P,R). \mathbb{D} P \in \mathbb{D}, 0<R<1, B(P,R) \subset \mathbb{D}, \exists p \in \mathbb{D} 0<r<1 P = \frac{1-r^2}{1-r^2|p|^2}p, \quad R = \frac{1-|p|^2}{1-r^2|p|^2}r","['complex-analysis', 'metric-spaces']"
6,Proof of Arzela-Ascoli Theorem on Conway's book,Proof of Arzela-Ascoli Theorem on Conway's book,,"CONTEXT Conway's Functions of One Complex Variable I, page 148, reads 1.23 Arzela-Ascoli Theorem. A set $\mathcal F \subset C(G,\Omega)$ is normal iff the following two conditions are satisfied. (a) For each $z$ in $G$ , $\{f(z) : f\in \mathcal F\}$ has compact closure in $\Omega$ . (b) $\mathcal F$ is equicontinuous at each point of $G$ . Proof. First assume that $\mathcal F$ is normal. Notice that for each $z$ in $G$ the map of $C(G,\Omega) \to \Omega$ defined by $f \mapsto f(z)$ is continuous; since $\mathcal F^-$ is compact its image is compact in $\Omega$ and (a) follows. ... Note that $C(G, \Omega)$ is the set of all continuous functions from $G$ to $\Omega \in \mathbb C$ with the usual metric $\rho$ defined in 1.4, page 143. $\mathcal F^-$ denotes the closure of $\mathcal F$ . A set is normal iff its closure is compact. QUESTION Let $\psi_z$ the map defined by the author in the proof. Since $\psi_z$ is continuous we know that $$\psi_z(\mathcal F^-) \subseteq \left(\psi_z(\mathcal F)\right)^-=\{f(z) : f\in \mathcal F\}^-.\tag{1}\label{1}$$ So, even if continuity and compactness of $\mathcal F^-$ imply compactness of $\psi_z(\mathcal F^-)$ , we cannot conclude immediately that the closure of $\{f(z) : f\in \mathcal F\}$ is compact. Is my way of reasoning correct? WHAT I HAVE TRIED I tried to get to the conclusion with some additional thoughts. I am also asking you if these are correct or erroneous/unnecessary . First note that $\psi_z$ is surjective. Let $w \in \left(\psi_z(\mathcal F)\right)^-$ , so that there exists a sequence $(z_k) \to w$ , with $z_k \in \mathcal F$ . By definition of $\psi_z$ and by surjectivity, therefore, there exists functions $f_k$ and $f$ such that $f_k(z) = z_k$ and $f(z) = w$ , so that now we have $$(f_k(z)) \to (f(z)).$$ Fix $\delta >0$ . For large enough $k$ we have $$|f_k(z)-f(z)| < \frac{\delta}3.$$ By continuity of $f_k$ and $f$ , there exists a compact set $K$ such that $$|f_k(\zeta)-f_k(z)| < \frac{\delta}3$$ and $$|f(\zeta)-f(z)| < \frac{\delta}3,$$ for all $\zeta$ in $K$ , so that $$|f_k(\zeta)-f(\zeta)| \leq |f_k(\zeta)-f_k(z)| + |f_k(z)-f(z)|+|f(\zeta)-f(z)|<\delta.$$ Since $\delta$ was arbitrary, we can choose $\delta$ , and thus $k$ , so that (Lemma 1.7, page 144) $$\rho(f_k,f) < \varepsilon,$$ for any $\varepsilon >0$ . This shows that $f \in \mathcal F^-$ , and since $f(z) = w$ , we have that $$\psi_z(\mathcal F^-) \supseteq \left(\psi_z(\mathcal F)\right)^-.$$ Together with \eqref{1}, this leads to our conclusion, i.e. that $\psi_z(\mathcal F^-) =\left(\psi_z(\mathcal F)\right)^-$ and that this set is compact.","CONTEXT Conway's Functions of One Complex Variable I, page 148, reads 1.23 Arzela-Ascoli Theorem. A set is normal iff the following two conditions are satisfied. (a) For each in , has compact closure in . (b) is equicontinuous at each point of . Proof. First assume that is normal. Notice that for each in the map of defined by is continuous; since is compact its image is compact in and (a) follows. ... Note that is the set of all continuous functions from to with the usual metric defined in 1.4, page 143. denotes the closure of . A set is normal iff its closure is compact. QUESTION Let the map defined by the author in the proof. Since is continuous we know that So, even if continuity and compactness of imply compactness of , we cannot conclude immediately that the closure of is compact. Is my way of reasoning correct? WHAT I HAVE TRIED I tried to get to the conclusion with some additional thoughts. I am also asking you if these are correct or erroneous/unnecessary . First note that is surjective. Let , so that there exists a sequence , with . By definition of and by surjectivity, therefore, there exists functions and such that and , so that now we have Fix . For large enough we have By continuity of and , there exists a compact set such that and for all in , so that Since was arbitrary, we can choose , and thus , so that (Lemma 1.7, page 144) for any . This shows that , and since , we have that Together with \eqref{1}, this leads to our conclusion, i.e. that and that this set is compact.","\mathcal F \subset C(G,\Omega) z G \{f(z) : f\in \mathcal F\} \Omega \mathcal F G \mathcal F z G C(G,\Omega) \to \Omega f \mapsto f(z) \mathcal F^- \Omega C(G, \Omega) G \Omega \in \mathbb C \rho \mathcal F^- \mathcal F \psi_z \psi_z \psi_z(\mathcal F^-) \subseteq \left(\psi_z(\mathcal F)\right)^-=\{f(z) : f\in \mathcal F\}^-.\tag{1}\label{1} \mathcal F^- \psi_z(\mathcal F^-) \{f(z) : f\in \mathcal F\} \psi_z w \in \left(\psi_z(\mathcal F)\right)^- (z_k) \to w z_k \in \mathcal F \psi_z f_k f f_k(z) = z_k f(z) = w (f_k(z)) \to (f(z)). \delta >0 k |f_k(z)-f(z)| < \frac{\delta}3. f_k f K |f_k(\zeta)-f_k(z)| < \frac{\delta}3 |f(\zeta)-f(z)| < \frac{\delta}3, \zeta K |f_k(\zeta)-f(\zeta)| \leq |f_k(\zeta)-f_k(z)| + |f_k(z)-f(z)|+|f(\zeta)-f(z)|<\delta. \delta \delta k \rho(f_k,f) < \varepsilon, \varepsilon >0 f \in \mathcal F^- f(z) = w \psi_z(\mathcal F^-) \supseteq \left(\psi_z(\mathcal F)\right)^-. \psi_z(\mathcal F^-) =\left(\psi_z(\mathcal F)\right)^-","['general-topology', 'complex-analysis', 'analysis', 'compactness']"
7,If $f(z) = \sum_{n=0}^{\infty} a_n(z-z_0)^n$ has radius convergence $ R > 0$. if $f(z) = 0$ for all $z$ $|z-z_o| < R$ show that $a_0 = a_1 = ... =0$.,If  has radius convergence . if  for all   show that .,f(z) = \sum_{n=0}^{\infty} a_n(z-z_0)^n  R > 0 f(z) = 0 z |z-z_o| < R a_0 = a_1 = ... =0,"If $f(z) = \sum_{n=0}^{\infty} a_n(z-z_0)^n$ has a radius of convergence $R > 0$ and if $f(z) = 0$ for all $z$ $|z-z_o| < R$ show that $a_0 = a_1 = ... =0$ . Proof Attempt: If it has a radius of convergence $R > 0$ then I know $\frac{1}{R} = \lim_{n \rightarrow \infty} |\frac{a_{n+1}}{a_n}| > 0$ . Pick $z^*$ to be in the radius of convergence, then we know that : $$ 0 = a_0 + a_1(z^*-z_0) + ...+a_n(z^*-z_0)^n + ...$$ Which means that for some $a_i \rightarrow 0 \leq i \leq n$ we can write: $$a_i = (z^* - z_0)^{-i} (-a_0 - a_1(z^* - z_0) - ...-a_{i+1}(z^* - z_0)^{i+1} -....-a_n(z^*-z_0)^n) + ....$$ $$a_{i+1} = (z^* - z_0)^{-(i+1)} (-a_0 - a_1(z^* - z_0) - ...-a_{i+2}(z^* - z_0)^{(i+2} -....-a_n(z^*-z_0)^n). + ...$$ I want to setup now a contradiction, by using the fact that  as $i \rightarrow 0$ then $  | a_{i+1}/a_i | > 0 $ : $$ \lim_{i \rightarrow \infty}| \frac{a_{i+1}}{a_i} |  = (z^* - z_0)^{-1}\frac{(-a_0 - a_1(z^* - z_0) - ...-a_{i+2}(z^* - z_0)^{i+2} -....-a_n(z^*-z_0)^n). + ...)}{(-a_0 - a_1(z^* - z_0) - ...-a_{i+1}(z^* - z_0)^{i+1} -....-a_n(z^*-z_0)^n) + ....)} $$ and I am having troubles concluding anything from this ... can someone suggest maybe another way? Attempt II I am attempting a solution based on $f(z) = f'(z) = ... = f^k(z) = 0$ $$(1) \ a_0 + a_1(z-z_0) + a_2(z-z_0)^2 + a_3(z-z_0)^3 + ... = 0 $$ $$(2) \ a_1 + 2a_2(z-z_0) + 3a_3(z-z_0)^2 + ... = 0 $$ $$ (3) \ 2a_2 + 3\times 2a_3(z-z_0) + ... = 0 $$ Take $(2) \times (z-z_0)$ : $$(2) \ a_1(z-z_0) + 2a_2(z-z_0)^2 + 3a_3(z-z_0)^3 + ... = 0 $$ Subtract it from (1)? $$a_0 - [a_2(z-z)^2 + 2a_3(z-z_0)^3 + ... ] = 0 $$ Not sure where to go with this...","If has a radius of convergence and if for all show that . Proof Attempt: If it has a radius of convergence then I know . Pick to be in the radius of convergence, then we know that : Which means that for some we can write: I want to setup now a contradiction, by using the fact that  as then : and I am having troubles concluding anything from this ... can someone suggest maybe another way? Attempt II I am attempting a solution based on Take : Subtract it from (1)? Not sure where to go with this...",f(z) = \sum_{n=0}^{\infty} a_n(z-z_0)^n R > 0 f(z) = 0 z |z-z_o| < R a_0 = a_1 = ... =0 R > 0 \frac{1}{R} = \lim_{n \rightarrow \infty} |\frac{a_{n+1}}{a_n}| > 0 z^*  0 = a_0 + a_1(z^*-z_0) + ...+a_n(z^*-z_0)^n + ... a_i \rightarrow 0 \leq i \leq n a_i = (z^* - z_0)^{-i} (-a_0 - a_1(z^* - z_0) - ...-a_{i+1}(z^* - z_0)^{i+1} -....-a_n(z^*-z_0)^n) + .... a_{i+1} = (z^* - z_0)^{-(i+1)} (-a_0 - a_1(z^* - z_0) - ...-a_{i+2}(z^* - z_0)^{(i+2} -....-a_n(z^*-z_0)^n). + ... i \rightarrow 0   | a_{i+1}/a_i | > 0   \lim_{i \rightarrow \infty}| \frac{a_{i+1}}{a_i} |  = (z^* - z_0)^{-1}\frac{(-a_0 - a_1(z^* - z_0) - ...-a_{i+2}(z^* - z_0)^{i+2} -....-a_n(z^*-z_0)^n). + ...)}{(-a_0 - a_1(z^* - z_0) - ...-a_{i+1}(z^* - z_0)^{i+1} -....-a_n(z^*-z_0)^n) + ....)}  f(z) = f'(z) = ... = f^k(z) = 0 (1) \ a_0 + a_1(z-z_0) + a_2(z-z_0)^2 + a_3(z-z_0)^3 + ... = 0  (2) \ a_1 + 2a_2(z-z_0) + 3a_3(z-z_0)^2 + ... = 0   (3) \ 2a_2 + 3\times 2a_3(z-z_0) + ... = 0  (2) \times (z-z_0) (2) \ a_1(z-z_0) + 2a_2(z-z_0)^2 + 3a_3(z-z_0)^3 + ... = 0  a_0 - [a_2(z-z)^2 + 2a_3(z-z_0)^3 + ... ] = 0 ,['complex-analysis']
8,growth of coefficients of half-integral weight modular forms,growth of coefficients of half-integral weight modular forms,,What is the order of growth of coefficients of half-integral weight modular forms on congruence subgroup with character ? There is the usual Hecke trick to compute bounds on the coefficients of integral weights on $SL_2(\mathbb{Z})$ but I don't know how to adapt the argument. I've looked online at many articles but didn't find anything. My guess is that it should be $O(n^{k/2})$ where $k$ is the half-integral weight.,What is the order of growth of coefficients of half-integral weight modular forms on congruence subgroup with character ? There is the usual Hecke trick to compute bounds on the coefficients of integral weights on but I don't know how to adapt the argument. I've looked online at many articles but didn't find anything. My guess is that it should be where is the half-integral weight.,SL_2(\mathbb{Z}) O(n^{k/2}) k,"['complex-analysis', 'number-theory', 'modular-forms']"
9,Does the relation $\sinh(iz) = i\sin(z)$ have anything to do with a rotation of the complex plane?,Does the relation  have anything to do with a rotation of the complex plane?,\sinh(iz) = i\sin(z),"Ok, I recently learned about the following relation in complex analysis: $$i\sin(z) = \sinh(iz)$$ Now, let $\sin(z)$ be the image $I_1$ of the complex plane $\mathbb{C}$ , and $\sinh(iz)$ be another image $I_2$ of the complex plane $\mathbb{C}$ . Since the images are sets of vectors if we think of the complex plane as $\mathbb{R}^2$ , then since the relation above holds, does this mean that every vector in $I_2$ is rotated by $\pi/2$ radians CCW in relation to the corresponding vector in $I_1$ . So, in essence, does this mean that if we just decided to rotate the second image on our complex plane by $\pi/2$ radians, we would get the first image? How can one understand this geometrically, if that's the case so to speak. What does really happen here, and is there any visualization behind this. Thanks.","Ok, I recently learned about the following relation in complex analysis: Now, let be the image of the complex plane , and be another image of the complex plane . Since the images are sets of vectors if we think of the complex plane as , then since the relation above holds, does this mean that every vector in is rotated by radians CCW in relation to the corresponding vector in . So, in essence, does this mean that if we just decided to rotate the second image on our complex plane by radians, we would get the first image? How can one understand this geometrically, if that's the case so to speak. What does really happen here, and is there any visualization behind this. Thanks.",i\sin(z) = \sinh(iz) \sin(z) I_1 \mathbb{C} \sinh(iz) I_2 \mathbb{C} \mathbb{R}^2 I_2 \pi/2 I_1 \pi/2,['complex-analysis']
10,Show the function $g(z)=\frac{1+z}{1-z}$ maps $\mathbb{D}$ onto $\{ z \in \mathbb{C} :\operatorname{Im}(z) >0\}$,Show the function  maps  onto,g(z)=\frac{1+z}{1-z} \mathbb{D} \{ z \in \mathbb{C} :\operatorname{Im}(z) >0\},"Show the function $g(z)=\frac{1+z}{1-z}$ maps $\mathbb{D}$ onto $\{ z \in \mathbb{C} :\operatorname{Im}(z) >0\}$ First, we know that $g$ has a pole at $z=1$ , which is on the boundary of the unit circle. So the circle is being mapped to a line. Now we need to figure out which line. Note that we have $g(1)=dne, g(-1)=0, g(i)=i, g(-i)=-i, g(0)=1$ . This is the part I'm confused about. Since we want to show that $g$ maps $\mathbb{D}$ onto $\{ z \in \mathbb{C} :\operatorname{Im}(z) >0\}$ , shouldn't $g(0)$ be somewhere in $\{ z \in \mathbb{C} :\operatorname{Im}(z) >0\}$ ? And shouldn't we have any $z$ with $|z|=1$ being mapped to the real-axis? Aside: I tried to find a function that maps $\mathbb{D}$ onto $\{ z \in \mathbb{C} :\operatorname{Im}(z) >0\}$ as an exercise on my own. I tried by using the cross-ratio method, and I got that $f(z)= \frac{(z-1)(i+1)}{(z+1)(i-1)}$ is such a function. Could someone please verify this? Thanks!","Show the function maps onto First, we know that has a pole at , which is on the boundary of the unit circle. So the circle is being mapped to a line. Now we need to figure out which line. Note that we have . This is the part I'm confused about. Since we want to show that maps onto , shouldn't be somewhere in ? And shouldn't we have any with being mapped to the real-axis? Aside: I tried to find a function that maps onto as an exercise on my own. I tried by using the cross-ratio method, and I got that is such a function. Could someone please verify this? Thanks!","g(z)=\frac{1+z}{1-z} \mathbb{D} \{ z \in \mathbb{C} :\operatorname{Im}(z) >0\} g z=1 g(1)=dne, g(-1)=0, g(i)=i, g(-i)=-i, g(0)=1 g \mathbb{D} \{ z \in \mathbb{C} :\operatorname{Im}(z) >0\} g(0) \{ z \in \mathbb{C} :\operatorname{Im}(z) >0\} z |z|=1 \mathbb{D} \{ z \in \mathbb{C} :\operatorname{Im}(z) >0\} f(z)= \frac{(z-1)(i+1)}{(z+1)(i-1)}","['complex-analysis', 'mobius-transformation']"
11,Converse of Stone-Weierstrass Theorem for Complex Continuous Functions,Converse of Stone-Weierstrass Theorem for Complex Continuous Functions,,"Stone-Weierstrass Theorem for complex continuous functions says: Let $K$ be a compact Hausdorff space and $\mathcal{A} \subseteq C(K, \mathbb{C})$ be a subalgebra. If $\mathcal{A}$ separates points and is closed under conjugation, then $\mathcal{A}$ is dense in $C(K, \mathbb{C})$ . I am trying to figure out whether the converse holds, at least in case $K$ is a metric space. It is obvious that $\mathcal{A}$ separates points if $\mathcal{A}$ is dense in $C(K, \mathbb{C})$ , but it seems difficult to prove or disprove that $\mathcal{A}$ is closed under conjugation if $\mathcal{A}$ is dense. Is there any proof or counterexample for this?","Stone-Weierstrass Theorem for complex continuous functions says: Let be a compact Hausdorff space and be a subalgebra. If separates points and is closed under conjugation, then is dense in . I am trying to figure out whether the converse holds, at least in case is a metric space. It is obvious that separates points if is dense in , but it seems difficult to prove or disprove that is closed under conjugation if is dense. Is there any proof or counterexample for this?","K \mathcal{A} \subseteq C(K, \mathbb{C}) \mathcal{A} \mathcal{A} C(K, \mathbb{C}) K \mathcal{A} \mathcal{A} C(K, \mathbb{C}) \mathcal{A} \mathcal{A}","['real-analysis', 'complex-analysis', 'weierstrass-approximation']"
12,Calculation of Residue.,Calculation of Residue.,,"Let $c=\cos \dfrac{\pi}{5}, f(z)=\dfrac{z^2-2cz+1}{z^4-z^3+z^2-z+1}$ . $e^{\frac{3\pi}{5}i}$ is one of the pole of $f$ . (This is because $f$ can be written as $f(z)=\frac{(z+1)(z^2-2cz+1)}{z^5+1}$ .) Then, calculate the Residue of $f$ at $e^{\frac{3\pi}{5}i}=:a$ . I calculated using the formula of Residue, but the calculation is complicated and I don't know how I should proceed. \begin{align} \mathrm{Res}(f,a) &=\displaystyle\lim_{z\to a} (z-a)f(z)\\ &=\lim_{z\to a} \dfrac{(z-a)(z^2-2cz+1)}{z^4-z^3+z^2-z+1}\\ &=\lim_{z\to a}\dfrac{z^2-2cz+1+(z-a)(2z-2c)}{4z^3-3z^2+2z-1}\\ &=\dfrac{a^2-2ca+1}{4a^3-3a^2+2a-1}. \end{align} I have to simplify this, but I don't know how I can do. I think I have to use some technical method. Thanks for any idea.","Let . is one of the pole of . (This is because can be written as .) Then, calculate the Residue of at . I calculated using the formula of Residue, but the calculation is complicated and I don't know how I should proceed. I have to simplify this, but I don't know how I can do. I think I have to use some technical method. Thanks for any idea.","c=\cos \dfrac{\pi}{5}, f(z)=\dfrac{z^2-2cz+1}{z^4-z^3+z^2-z+1} e^{\frac{3\pi}{5}i} f f f(z)=\frac{(z+1)(z^2-2cz+1)}{z^5+1} f e^{\frac{3\pi}{5}i}=:a \begin{align}
\mathrm{Res}(f,a)
&=\displaystyle\lim_{z\to a} (z-a)f(z)\\
&=\lim_{z\to a} \dfrac{(z-a)(z^2-2cz+1)}{z^4-z^3+z^2-z+1}\\
&=\lim_{z\to a}\dfrac{z^2-2cz+1+(z-a)(2z-2c)}{4z^3-3z^2+2z-1}\\
&=\dfrac{a^2-2ca+1}{4a^3-3a^2+2a-1}.
\end{align}","['complex-analysis', 'residue-calculus']"
13,Is a holomorphic Function of a matrix invertible?,Is a holomorphic Function of a matrix invertible?,,"I am currently reading a Paper and I don't quite get one part. The Paper is about Function of matrices and in one part he says: ""Since $g(z)$ is a holomorphic function on $\Omega$ and never vanishes, $g(A)$ must be invertible"" (for some open $\Omega$ that contains the spectrum of $A$ and a linear bounded operator $A$ ) I understand that since $g(z)$ never vanishes $h(z):=\frac{1}{g(z)}$ must also be holomorphic and therefor $h(A)$ exists. But how do I know that $h(A)$ is actually equal to $g(A)^{-1}$ ?","I am currently reading a Paper and I don't quite get one part. The Paper is about Function of matrices and in one part he says: ""Since is a holomorphic function on and never vanishes, must be invertible"" (for some open that contains the spectrum of and a linear bounded operator ) I understand that since never vanishes must also be holomorphic and therefor exists. But how do I know that is actually equal to ?",g(z) \Omega g(A) \Omega A A g(z) h(z):=\frac{1}{g(z)} h(A) h(A) g(A)^{-1},"['complex-analysis', 'functional-analysis', 'spectral-theory', 'functional-calculus']"
14,"Convergence for ""general"" version of Riemann zeta function?","Convergence for ""general"" version of Riemann zeta function?",,"Let $\{u_k\}_{k\in\mathbb{N}}$ be a non-decreasing sequence of positive reals limiting to infinity. We define the ""general"" Riemann zeta sum for $\{u_k\}_k$ by $ \zeta(s) = \sum_{k=1}^{\infty} (u_k)^{-s} $ . We denote by $S \subset \mathbb{C}$ the set of $s \in \mathbb{C}$ for which the sum above converges. My question is, in general what does $S$ look like? We know for $u_k = k$ that $S$ is a right half-plane $\{\mathrm{Re}s>1\}$ . In general can we say $S$ is a right half-plane, to the right of the imaginary axis? Note: a result like this seems to be used just after equation (1.20) in this paper of Dan Freed. Of course, there are probably more constraints on $\lambda_k = u_k$ in the situation given in the paper than I've put here, but I was wondering how general the result used is. I tried taking a look at the paper which is cited as [Se] after equation (1.20) in Dan Freed's paper, but I couldn't really understand it enough to extract the above statement.","Let be a non-decreasing sequence of positive reals limiting to infinity. We define the ""general"" Riemann zeta sum for by . We denote by the set of for which the sum above converges. My question is, in general what does look like? We know for that is a right half-plane . In general can we say is a right half-plane, to the right of the imaginary axis? Note: a result like this seems to be used just after equation (1.20) in this paper of Dan Freed. Of course, there are probably more constraints on in the situation given in the paper than I've put here, but I was wondering how general the result used is. I tried taking a look at the paper which is cited as [Se] after equation (1.20) in Dan Freed's paper, but I couldn't really understand it enough to extract the above statement.","\{u_k\}_{k\in\mathbb{N}} \{u_k\}_k 
\zeta(s) = \sum_{k=1}^{\infty} (u_k)^{-s}
 S \subset \mathbb{C} s \in \mathbb{C} S u_k = k S \{\mathrm{Re}s>1\} S \lambda_k = u_k","['real-analysis', 'complex-analysis', 'convergence-divergence', 'riemann-zeta']"
15,"Two points in $z,w \in \mathbb C$ with same distance to three other points [duplicate]",Two points in  with same distance to three other points [duplicate],"z,w \in \mathbb C","This question already has an answer here : proof that triangle have only one particular circumscribed circle (1 answer) Closed 1 year ago . Suppose that $a,b,c \in \mathbb C$ are three complex numbers which do not lie on a line. Further, let $z,w \in \mathbb C$ are such that $$ |z-a|=|w-a|, \ \ |z-b|=|w-b|, \ \ |z-c|=|w-c| . $$ Is it true that $z=w$ ? Intuitively I would say yes due to geometric considerations but I would like to have a formal proof of it.","This question already has an answer here : proof that triangle have only one particular circumscribed circle (1 answer) Closed 1 year ago . Suppose that are three complex numbers which do not lie on a line. Further, let are such that Is it true that ? Intuitively I would say yes due to geometric considerations but I would like to have a formal proof of it.","a,b,c \in \mathbb C z,w \in \mathbb C 
|z-a|=|w-a|, \ \ |z-b|=|w-b|, \ \ |z-c|=|w-c| .
 z=w","['complex-analysis', 'geometry', 'euclidean-geometry']"
16,"Contour integral, Cauchy's theorem, ""boundary"" vs ""interior"" points.","Contour integral, Cauchy's theorem, ""boundary"" vs ""interior"" points.",,"I have to evaluate $\displaystyle{3 \int_{G}{\dfrac{v}{v^3 - 2v^2 -3}\text{d}v}}$ where $G$ is the curve $x + 4xy^2 = 4$ in the counterclockwise direction. Let $\displaystyle{f(v) = \displaystyle{ 3\dfrac{v}{v^3 -2v^2 -3}}= \dfrac{4}{10} \left( -\dfrac{1}{iv-2i} - \dfrac{i}{v+2i} + \dfrac{1}{iv-i} + \dfrac{1}{v+2} \right)}$ Hence, the integral can be evaluated as: $\displaystyle{\dfrac{3i}{10} \left(- \int_{G}{ \dfrac{i}{v-3i} dv} - \int_{G}{ \dfrac{1}{iv+3i} dv} + \int_{G}{ \dfrac{1}{v-3} dv} + \int_{G}{ \dfrac{1}{v-2} dv} \right)}$ Since the singular points, $\pm 1$ are interior to $G$ and the singular points $\pm 2i$ lie exterior to $G$ We have $\displaystyle{\dfrac{2}{10} \left( - \int_{G}{ \dfrac{i}{v-2i} dv} - \int_{G}{ \dfrac{i}{v+2i} dv} + \int_{G}{ \dfrac{1}{v-2} dz} + \int_{G}{ \dfrac{1}{v+2} dv} \right) = \dfrac{4}{10}\left(- 0 - 0 + 2\pi  + 2\pi \right) = \dfrac{7 \pi i}{11}}$ Is my solution correct? Are there any mistakes/flaws/loopholes whatsoever? Are there any other theorems I need to mention? I'd like to know if there's a better solution too! Follow-up questions: Are theorems (*) and (**) part of the residue (Cauchy's) theorem? if $G$ were the circle $x^2 + y^2 = 3$ , will the integral be the same? because $\pm 2i$ lie exterior to it, and $\pm 1$ lie interior to it what if the singular points lie ""on"" the boundary itself (not exactly interior/exterior)? which of (*) and (**) should be applied?","I have to evaluate where is the curve in the counterclockwise direction. Let Hence, the integral can be evaluated as: Since the singular points, are interior to and the singular points lie exterior to We have Is my solution correct? Are there any mistakes/flaws/loopholes whatsoever? Are there any other theorems I need to mention? I'd like to know if there's a better solution too! Follow-up questions: Are theorems (*) and (**) part of the residue (Cauchy's) theorem? if were the circle , will the integral be the same? because lie exterior to it, and lie interior to it what if the singular points lie ""on"" the boundary itself (not exactly interior/exterior)? which of (*) and (**) should be applied?",\displaystyle{3 \int_{G}{\dfrac{v}{v^3 - 2v^2 -3}\text{d}v}} G x + 4xy^2 = 4 \displaystyle{f(v) = \displaystyle{ 3\dfrac{v}{v^3 -2v^2 -3}}= \dfrac{4}{10} \left( -\dfrac{1}{iv-2i} - \dfrac{i}{v+2i} + \dfrac{1}{iv-i} + \dfrac{1}{v+2} \right)} \displaystyle{\dfrac{3i}{10} \left(- \int_{G}{ \dfrac{i}{v-3i} dv} - \int_{G}{ \dfrac{1}{iv+3i} dv} + \int_{G}{ \dfrac{1}{v-3} dv} + \int_{G}{ \dfrac{1}{v-2} dv} \right)} \pm 1 G \pm 2i G \displaystyle{\dfrac{2}{10} \left( - \int_{G}{ \dfrac{i}{v-2i} dv} - \int_{G}{ \dfrac{i}{v+2i} dv} + \int_{G}{ \dfrac{1}{v-2} dz} + \int_{G}{ \dfrac{1}{v+2} dv} \right) = \dfrac{4}{10}\left(- 0 - 0 + 2\pi  + 2\pi \right) = \dfrac{7 \pi i}{11}} G x^2 + y^2 = 3 \pm 2i \pm 1,"['complex-analysis', 'solution-verification', 'contour-integration']"
17,Show that $f(z) = C \cdot \sin(\pi z)$.,Show that .,f(z) = C \cdot \sin(\pi z),"Suppose $f: \mathbb{C} \rightarrow \mathbb{C}$ is an entire function such that $|f(z)| \leq K e^{\pi |\text{Im}(z)|}$ for some $K > 0$ , and that $f(n) = 0$ for all $n \in \mathbb{Z}$ . Show that $f(z) = C \cdot \sin (\pi z)$ . I have seen very similar problems on here asking this question with (what I think is) a stronger assumption. That is, assuming $f(z+1) = -f(z)$ for all $z \in \mathbb{C}$ . The argument itself is an application of Liouville's theorem. But with only assuming that $f(n) = 0$ for $n \in \mathbb{Z}$ I am not able to recreate the argument. Bounding the function $g(z) = f(z)/\sin(\pi z)$ on a strip like $|\text{Im}(y)| \geq 1$ comes down to bounding the sine function from below on this region. However we cannot do the same for $|\text{Im}(y)| \leq 1$ . How can I proceed? Here is the link to the post I mentioned above: Show that $f(z) = c \sin (\pi z)$ .","Suppose is an entire function such that for some , and that for all . Show that . I have seen very similar problems on here asking this question with (what I think is) a stronger assumption. That is, assuming for all . The argument itself is an application of Liouville's theorem. But with only assuming that for I am not able to recreate the argument. Bounding the function on a strip like comes down to bounding the sine function from below on this region. However we cannot do the same for . How can I proceed? Here is the link to the post I mentioned above: Show that $f(z) = c \sin (\pi z)$ .",f: \mathbb{C} \rightarrow \mathbb{C} |f(z)| \leq K e^{\pi |\text{Im}(z)|} K > 0 f(n) = 0 n \in \mathbb{Z} f(z) = C \cdot \sin (\pi z) f(z+1) = -f(z) z \in \mathbb{C} f(n) = 0 n \in \mathbb{Z} g(z) = f(z)/\sin(\pi z) |\text{Im}(y)| \geq 1 |\text{Im}(y)| \leq 1,['complex-analysis']
18,Final value theorem for non-rational transfer functions,Final value theorem for non-rational transfer functions,,"One version of the Final Value Theorem often seen in controls textbooks: Suppose $f(t)$ has (one-sided) Laplace Transform $F(s)$ and further suppose that every pole of $s F(s)$ is in the open left-half plane. Then the limit $\lim_{s\to 0} s F(s)$ exists, and $\lim_{t\to\infty} f(t) = \lim_{s\to 0} s F(s)$ . Critically, there is no a priori explicit assumption that the limit $\lim_{t\to\infty} f(t)$ exists; it follows as a consequence of the assumptions made on $s F(s)$ . The standard proof uses partial fraction decomposition, which requires assuming $F(s)$ is a rational function. Is there a more general version of this result that can handle the cases where: $F(s)$ may have infinitely many poles $F(s)$ may not be rational I want to preserve the property that no assumptions are made about $f(t)$ or its limiting behavior. I suspect the result should still hold if we replace ""every pole of $sF(s)$ is in the open left-half plane"" with something like ""there exists $\varepsilon > 0$ such that $sF(s)$ is analytic in the set of $s$ satisfying $\mathrm{Re}(s)>-\varepsilon$ "". Has anybody seen such a result or have ideas on how to prove such a thing?","One version of the Final Value Theorem often seen in controls textbooks: Suppose has (one-sided) Laplace Transform and further suppose that every pole of is in the open left-half plane. Then the limit exists, and . Critically, there is no a priori explicit assumption that the limit exists; it follows as a consequence of the assumptions made on . The standard proof uses partial fraction decomposition, which requires assuming is a rational function. Is there a more general version of this result that can handle the cases where: may have infinitely many poles may not be rational I want to preserve the property that no assumptions are made about or its limiting behavior. I suspect the result should still hold if we replace ""every pole of is in the open left-half plane"" with something like ""there exists such that is analytic in the set of satisfying "". Has anybody seen such a result or have ideas on how to prove such a thing?",f(t) F(s) s F(s) \lim_{s\to 0} s F(s) \lim_{t\to\infty} f(t) = \lim_{s\to 0} s F(s) \lim_{t\to\infty} f(t) s F(s) F(s) F(s) F(s) f(t) sF(s) \varepsilon > 0 sF(s) s \mathrm{Re}(s)>-\varepsilon,"['complex-analysis', 'functional-analysis', 'laplace-transform', 'control-theory']"
19,Calculate the power series centered in $z_0=1$,Calculate the power series centered in,z_0=1,"I did this, I don't know if is correct $$ \begin{gathered} h(z)=\left(\frac{z}{z+1}\right)^{2} \\ u=z-1,z_0=1 \\ h(z)=\left(\frac{z}{z+1}\right)^{2}=z^{2} \frac{1}{(z+1)^{2}}=z^{2} \frac{1}{(1-(-z))^{2}} \rightarrow \text { geometric series } \\ \sum_{n=0}^{\infty} u^{n}=\frac{1}{1-u}, \quad|z|<1, \\ \\\frac{d}{d z} \frac{1}{1-u}=\frac{1}{(1-u)^{2}} \\\left(\frac{z}{z+1}\right)^{2}=z^{2} \frac{d}{d u} \sum_{n=0}^{\infty} u^{n}=z^{2} \sum_{n=0}^{\infty} n u^{n-1}=z^{2} \sum_{n=0}^{\infty} n(z-1)^{n-1}=\sum_{n=0}^{\infty} n(z-1)^{n+1} \\ \left(\frac{z}{z+1}\right)^{2}=\sum_{n=0}^{\infty} n(z-1)^{n+1},|z-1|<1 \rightarrow|z|<2 \\ \\ \end{gathered} $$ I need to use a geometric serie to Calculate the power series I have a problem, the problem is in $z_0=1$ I don't know if I use it right","I did this, I don't know if is correct I need to use a geometric serie to Calculate the power series I have a problem, the problem is in I don't know if I use it right","
\begin{gathered}
h(z)=\left(\frac{z}{z+1}\right)^{2} \\
u=z-1,z_0=1 \\
h(z)=\left(\frac{z}{z+1}\right)^{2}=z^{2} \frac{1}{(z+1)^{2}}=z^{2} \frac{1}{(1-(-z))^{2}} \rightarrow \text { geometric series } \\
\sum_{n=0}^{\infty} u^{n}=\frac{1}{1-u}, \quad|z|<1, \\
\\\frac{d}{d z} \frac{1}{1-u}=\frac{1}{(1-u)^{2}}
\\\left(\frac{z}{z+1}\right)^{2}=z^{2} \frac{d}{d u} \sum_{n=0}^{\infty} u^{n}=z^{2} \sum_{n=0}^{\infty} n u^{n-1}=z^{2} \sum_{n=0}^{\infty} n(z-1)^{n-1}=\sum_{n=0}^{\infty} n(z-1)^{n+1} \\
\left(\frac{z}{z+1}\right)^{2}=\sum_{n=0}^{\infty} n(z-1)^{n+1},|z-1|<1 \rightarrow|z|<2 \\
\\
\end{gathered}
 z_0=1","['complex-analysis', 'power-series']"
20,Finding the number of roots of $f(z) = z^5 + z^3 + 3z + 1$ in the unit disk,Finding the number of roots of  in the unit disk,f(z) = z^5 + z^3 + 3z + 1,Suppose we have $$f(z) = z^5 + z^3 + 3z + 1$$ Find how many roots this function has in the open unit disc $\{z : |z| < 1\}$ . Here's what I think about it: I tried to split $f$ into two functions $$g(z) = z^5 + z^3$$ $$h(z) = 3z + 1$$ and use Rouché's theorem (to prove that $f = g + h$ has only one root). But $|h(z)| > |g(z)|$ has some troubles on unit circle (at least at $-1$ point). Is there any way to use Rouché's theorem here? Maybe we can use it twice or  work around problems at this point? Have no idea how to fix it.,Suppose we have Find how many roots this function has in the open unit disc . Here's what I think about it: I tried to split into two functions and use Rouché's theorem (to prove that has only one root). But has some troubles on unit circle (at least at point). Is there any way to use Rouché's theorem here? Maybe we can use it twice or  work around problems at this point? Have no idea how to fix it.,f(z) = z^5 + z^3 + 3z + 1 \{z : |z| < 1\} f g(z) = z^5 + z^3 h(z) = 3z + 1 f = g + h |h(z)| > |g(z)| -1,"['complex-analysis', 'polynomials', 'roots', 'quintics']"
21,"""Tipping point"" between asymptotic behavior of gamma function along the line $z=x+mxi$","""Tipping point"" between asymptotic behavior of gamma function along the line",z=x+mxi,"Disclaimer: I am an undergraduate student about a semester into introductory complex analysis. I am entirely out of my depth here, just curious about something I noticed. The gamma function $\Gamma(z) := \int_0^\infty\limits z^{z-1}e^{-x} dx$ is a generalization of the standard factorial function $n! = n \times (n-1) \times (n-2) \dots \times 1$ defined over the complex plane (minus nonpositive integers), and with the caveat that for nonnegative integer $n$ , $\Gamma(n) = (n-1)!$ As such, on the (positive) reals, $\Gamma$ grows superexponentially. Indeed more generally, for any complex $z$ , $\Gamma(z+x) \to \infty$ (in magnitude) as $x \in \mathbb{R}$ tends to infinity. Interestingly though, the opposite is true of the imaginary axis: $\Gamma(z+iy) \to 0$ as $y \in \mathbb{R}$ gets large. Informally then, the real part of $z$ makes $\Gamma(z)$ large, and the imaginary part makes it small. I was curious: how much stronger is one of these effects than the other? To make this precise, consider the function $f(\theta) = \lim_{x \to \infty}\limits \left|\Gamma(x e^{i\theta})\right|$ ; pick an angle, and track the magnitude of $\Gamma$ for inputs of increasing magnitude with that argument in the complex plane. $f(\theta)=\infty, f(\pi/2) = 0$ , are there any values for which it's finite and nonzero? Where does it change? Among those values where it tends to infinity, can we say anything about its growth? I toyed around in Mathematica, specifically with Manipulate[Plot[Abs[Gamma[x*Exp[I*t]]], {x, 0, 50}], {t, 0, Pi/2}]} and found that for a value of $t$ around 1.23 the end behavior seems to change. However when I increase the upper limit for $x$ , say Manipulate[Plot[Abs[Gamma[x*Exp[I*t]]], {x, 0, 100}], {t, 0, Pi/2}]} , I need to bring $t$ to about 1.36. In light of this, I wouldn't be surprised if $f(\theta) = \infty$ for all $\theta < \pi/2$ , and looking at the graphs, neither would I be surprised if the growth is always superexponential, even factorial in nature. It's certainly not what I would have expected, I figured there would be some point in $(0, \pi/2)$ where the behavior changes, but it's not entirely out of left field. Thank you in advance for any possible insight.","Disclaimer: I am an undergraduate student about a semester into introductory complex analysis. I am entirely out of my depth here, just curious about something I noticed. The gamma function is a generalization of the standard factorial function defined over the complex plane (minus nonpositive integers), and with the caveat that for nonnegative integer , As such, on the (positive) reals, grows superexponentially. Indeed more generally, for any complex , (in magnitude) as tends to infinity. Interestingly though, the opposite is true of the imaginary axis: as gets large. Informally then, the real part of makes large, and the imaginary part makes it small. I was curious: how much stronger is one of these effects than the other? To make this precise, consider the function ; pick an angle, and track the magnitude of for inputs of increasing magnitude with that argument in the complex plane. , are there any values for which it's finite and nonzero? Where does it change? Among those values where it tends to infinity, can we say anything about its growth? I toyed around in Mathematica, specifically with Manipulate[Plot[Abs[Gamma[x*Exp[I*t]]], {x, 0, 50}], {t, 0, Pi/2}]} and found that for a value of around 1.23 the end behavior seems to change. However when I increase the upper limit for , say Manipulate[Plot[Abs[Gamma[x*Exp[I*t]]], {x, 0, 100}], {t, 0, Pi/2}]} , I need to bring to about 1.36. In light of this, I wouldn't be surprised if for all , and looking at the graphs, neither would I be surprised if the growth is always superexponential, even factorial in nature. It's certainly not what I would have expected, I figured there would be some point in where the behavior changes, but it's not entirely out of left field. Thank you in advance for any possible insight.","\Gamma(z) := \int_0^\infty\limits z^{z-1}e^{-x} dx n! = n \times (n-1) \times (n-2) \dots \times 1 n \Gamma(n) = (n-1)! \Gamma z \Gamma(z+x) \to \infty x \in \mathbb{R} \Gamma(z+iy) \to 0 y \in \mathbb{R} z \Gamma(z) f(\theta) = \lim_{x \to \infty}\limits \left|\Gamma(x e^{i\theta})\right| \Gamma f(\theta)=\infty, f(\pi/2) = 0 t x t f(\theta) = \infty \theta < \pi/2 (0, \pi/2)","['complex-analysis', 'asymptotics', 'gamma-function']"
22,Why does $\frac{z+2}{z-1}$ not have a series expansion around $|z-1|>1$?,Why does  not have a series expansion around ?,\frac{z+2}{z-1} |z-1|>1,"Determine the Laurent series of $$z \mapsto \frac{z+2}{z-1}$$ over the region $$C := \left\{ z \in \mathbb{C} \mid |z-1| > 1 \right\} $$ With the region being simplified to $$ \frac{1}{|z-1|} < 1$$ the solution would be $$ 1+\frac{3}{z-1} $$ However, I am confused as to how this is the conclusion. Why is there no expansion of further terms of the Laurent series? Because if you change the inequality you get a actual expansion like so: In the annulus: $$C:=\{z \in \mathbb{C} \mid 0<|z|<1 \} \\$$ $$|z| < 1$$ Gives: $$f(z)=\frac{z+2}{z-1}=1-3\sum_{n=0}^{\infty}z^n$$ So why does that give a series solution but the first way does not?","Determine the Laurent series of over the region With the region being simplified to the solution would be However, I am confused as to how this is the conclusion. Why is there no expansion of further terms of the Laurent series? Because if you change the inequality you get a actual expansion like so: In the annulus: Gives: So why does that give a series solution but the first way does not?",z \mapsto \frac{z+2}{z-1} C := \left\{ z \in \mathbb{C} \mid |z-1| > 1 \right\}   \frac{1}{|z-1|} < 1  1+\frac{3}{z-1}  C:=\{z \in \mathbb{C} \mid 0<|z|<1 \} \\ |z| < 1 f(z)=\frac{z+2}{z-1}=1-3\sum_{n=0}^{\infty}z^n,"['complex-analysis', 'laurent-series']"
23,The source for the proof of the uniformization theorem in Gamelin's book,The source for the proof of the uniformization theorem in Gamelin's book,,"The book on Complex Analysis by Gamelin has the singular feature that it has a more-or-less complete proof of the Uniformization theorem for Riemann surfaces ( countable topology not assumed! ) despite being an undergraduate textbook. I am currently lecturing on the proof to graduate students. It seems to me that, modulo some hand-waving here-and -there, the proof given here is both the shortest and most transparent especially the proof of the second-countability of Riemann surfaces. I have been asked by the students about the original source of the proof. I know that Marshall's book has a proof that is similar in spirit but that is obviously not the source. Does anybody know a source for the proof?","The book on Complex Analysis by Gamelin has the singular feature that it has a more-or-less complete proof of the Uniformization theorem for Riemann surfaces ( countable topology not assumed! ) despite being an undergraduate textbook. I am currently lecturing on the proof to graduate students. It seems to me that, modulo some hand-waving here-and -there, the proof given here is both the shortest and most transparent especially the proof of the second-countability of Riemann surfaces. I have been asked by the students about the original source of the proof. I know that Marshall's book has a proof that is similar in spirit but that is obviously not the source. Does anybody know a source for the proof?",,"['complex-analysis', 'reference-request']"
24,What's the difference between a total basin of attraction and an immediate basin of attraction?,What's the difference between a total basin of attraction and an immediate basin of attraction?,,"I understand that for an attracting fixed point $\hat{p}$ of a holomorphic self-map defined on some Riemann surface $S$ we define the total basin of attraction as $\mathcal{A}=\text{Bas}(\hat{p})=\{p\in S: (f^{\circ n}(p))_{n\geq 1}\to\hat{p}\}$ . Now, in his book, Dynamics of One Complex Variable (Pg. 79 - 3rd-edition), Milnor defines what's called an immediate basin of attraction $\mathcal{A}_0$ to be the connected component of $\mathcal{A}$ which contains $\hat{p}$ . I don't understand how this is any different from the total basin of attraction of $\hat{p}$ . Can someone provide an example that can clears the difference between these two ideas? I am attaching a plot of the filled Julia set of $f(z)=z^5+(0.8+0.8i)z^4+z$ which has the following fixed points $\hat{p_1} = 0$ with multiplier $|\lambda_1| = |f'(0)| =1$ (parabolic), $\hat{p_2} = -0.8-0.8i$ with multiplier $|\lambda_2| = |f'(-0.8-0.8i)| \approx |-13.7| > 1$ (repelling), $\hat{p_3} = \infty$ with multiplier $|\lambda_3| = |\lim_{z\to\infty} f(z)|^{-1} = 0$ (super-attracting) Since the only attracting fixed point here is $\infty$ , $\text{Bas}(\infty)=\mathcal{A}=\{p\in\hat{\mathbb{C}}: (f^{\circ n}(z))_{n\geq 1}\to\infty\}$ . But what is $\mathcal{A}_0$ in this case?","I understand that for an attracting fixed point of a holomorphic self-map defined on some Riemann surface we define the total basin of attraction as . Now, in his book, Dynamics of One Complex Variable (Pg. 79 - 3rd-edition), Milnor defines what's called an immediate basin of attraction to be the connected component of which contains . I don't understand how this is any different from the total basin of attraction of . Can someone provide an example that can clears the difference between these two ideas? I am attaching a plot of the filled Julia set of which has the following fixed points with multiplier (parabolic), with multiplier (repelling), with multiplier (super-attracting) Since the only attracting fixed point here is , . But what is in this case?",\hat{p} S \mathcal{A}=\text{Bas}(\hat{p})=\{p\in S: (f^{\circ n}(p))_{n\geq 1}\to\hat{p}\} \mathcal{A}_0 \mathcal{A} \hat{p} \hat{p} f(z)=z^5+(0.8+0.8i)z^4+z \hat{p_1} = 0 |\lambda_1| = |f'(0)| =1 \hat{p_2} = -0.8-0.8i |\lambda_2| = |f'(-0.8-0.8i)| \approx |-13.7| > 1 \hat{p_3} = \infty |\lambda_3| = |\lim_{z\to\infty} f(z)|^{-1} = 0 \infty \text{Bas}(\infty)=\mathcal{A}=\{p\in\hat{\mathbb{C}}: (f^{\circ n}(z))_{n\geq 1}\to\infty\} \mathcal{A}_0,"['complex-analysis', 'polynomials', 'complex-dynamics', 'basins-of-attraction']"
25,Show dominated convergence to exchange the order of differentiation and integration,Show dominated convergence to exchange the order of differentiation and integration,,"Problem Let $\text{Ai}: \mathbb{R} \to \mathbb{R}$ with $$\text{Ai}(x) = \frac{1}{\pi} \Re \int_{0}^{\infty} \omega e^{ -\frac{t^3}{3} + i x \omega t}  dt$$ be the Airy function with $\omega := e^{\frac{i\pi}{6}}$ . Prove that $\text{Ai}''(x) = x\text{Ai}(x)$ . My approach We have $\omega = e^{\frac{i\pi}{6}} = \cos\frac{\pi}{6} + i\sin\frac{\pi}{6} = \frac{\sqrt{3}}{2} + \frac{1}{2} i$ and $-\frac{t^3}{3} + i x \omega t = -\frac{t^3}{3} - \frac{xt}{2} + \frac{xt\sqrt{3}}{2}i$ . We also have $\omega^3 = e^{\frac{i\pi}{2}} = i$ . Let $f: \mathbb{R}_0^+\times\mathbb{R}\to\mathbb{C}$ with: \begin{align} &f(t,x) = \omega e^{ -\frac{t^3}{3} + i x \omega t}\\ &\frac{\partial}{\partial x}f(t,x) = i \omega^2 t e^{ -\frac{t^3}{3} + i x \omega t} &&\left| \frac{\partial}{\partial x}f(t,x) \right| = t e^{-\frac{t^3}{3} - \frac{xt}{2}}\\ &\frac{\partial^2}{\partial^2 x} f(t,x) = - i t^2 e^{ -\frac{t^3}{3} + i x \omega t} &&\left| \frac{\partial^2}{\partial^2 x}f(t,x) \right| = t^2 e^{-\frac{t^3}{3} - \frac{xt}{2}} \end{align} I need to show the following equation in order to progress: $$ \frac{\partial^2}{\partial^2 x} \int_0^\infty f(t,x) dt = \frac{\partial}{\partial x} \int_0^\infty \frac{\partial}{\partial x} f(t,x) dt = \int_0^\infty \frac{\partial^2}{\partial^2 x} f(t,x) dt $$ For this I need to show dominated convergence for $\frac{\partial}{\partial x}f(t,x)$ and $\frac{\partial^2}{\partial^2 x}f(t,x)$ , a.i. I need to find a function $g_1:\mathbb{R}_0^+ \to \mathbb{R}$ with $\left| \frac{\partial}{\partial x}f(t,x) \right| \leq g_1(t)$ for all $t \in \mathbb{R}_0^+$ and $x \in \mathbb{R}$ . I also need to find a function $g_2:\mathbb{R}_0^+ \to \mathbb{R}$ with $\left| \frac{\partial^2}{\partial^2 x}f(t,x) \right| \leq g_2(t)$ for all $t \in \mathbb{R}_0^+$ and $x \in \mathbb{R}$ . However, $x\in\mathbb{R}$ can be arbitrarely small making $\frac{\partial}{\partial x}f(t,x)$ and $\frac{\partial^2}{\partial^2 x}f(t,x)$ arbitrarely large at some point. I am unable to find functions $g_1(t)$ , $g_2(t)$ to show dominated convergence. What am I missing? Note This problem was already discussed here , but the one particular point which I am interested in was handwaved.","Problem Let with be the Airy function with . Prove that . My approach We have and . We also have . Let with: I need to show the following equation in order to progress: For this I need to show dominated convergence for and , a.i. I need to find a function with for all and . I also need to find a function with for all and . However, can be arbitrarely small making and arbitrarely large at some point. I am unable to find functions , to show dominated convergence. What am I missing? Note This problem was already discussed here , but the one particular point which I am interested in was handwaved.","\text{Ai}: \mathbb{R} \to \mathbb{R} \text{Ai}(x) = \frac{1}{\pi} \Re \int_{0}^{\infty} \omega e^{ -\frac{t^3}{3} + i x \omega t}  dt \omega := e^{\frac{i\pi}{6}} \text{Ai}''(x) = x\text{Ai}(x) \omega = e^{\frac{i\pi}{6}} = \cos\frac{\pi}{6} + i\sin\frac{\pi}{6} = \frac{\sqrt{3}}{2} + \frac{1}{2} i -\frac{t^3}{3} + i x \omega t = -\frac{t^3}{3} - \frac{xt}{2} + \frac{xt\sqrt{3}}{2}i \omega^3 = e^{\frac{i\pi}{2}} = i f: \mathbb{R}_0^+\times\mathbb{R}\to\mathbb{C} \begin{align}
&f(t,x) = \omega e^{ -\frac{t^3}{3} + i x \omega t}\\ &\frac{\partial}{\partial x}f(t,x) = i \omega^2 t e^{ -\frac{t^3}{3} + i x \omega t} &&\left| \frac{\partial}{\partial x}f(t,x) \right| = t e^{-\frac{t^3}{3} - \frac{xt}{2}}\\
&\frac{\partial^2}{\partial^2 x} f(t,x) = - i t^2 e^{ -\frac{t^3}{3} + i x \omega t}
&&\left| \frac{\partial^2}{\partial^2 x}f(t,x) \right| = t^2 e^{-\frac{t^3}{3} - \frac{xt}{2}}
\end{align}  \frac{\partial^2}{\partial^2 x} \int_0^\infty f(t,x) dt = \frac{\partial}{\partial x} \int_0^\infty \frac{\partial}{\partial x} f(t,x) dt = \int_0^\infty \frac{\partial^2}{\partial^2 x} f(t,x) dt  \frac{\partial}{\partial x}f(t,x) \frac{\partial^2}{\partial^2 x}f(t,x) g_1:\mathbb{R}_0^+ \to \mathbb{R} \left| \frac{\partial}{\partial x}f(t,x) \right| \leq g_1(t) t \in \mathbb{R}_0^+ x \in \mathbb{R} g_2:\mathbb{R}_0^+ \to \mathbb{R} \left| \frac{\partial^2}{\partial^2 x}f(t,x) \right| \leq g_2(t) t \in \mathbb{R}_0^+ x \in \mathbb{R} x\in\mathbb{R} \frac{\partial}{\partial x}f(t,x) \frac{\partial^2}{\partial^2 x}f(t,x) g_1(t) g_2(t)","['integration', 'complex-analysis', 'complex-integration', 'airy-functions']"
26,How do I show that the following function is analytic using the Morera theorem?,How do I show that the following function is analytic using the Morera theorem?,,Let $f:\Bbb{C}\rightarrow \Bbb{C}$ be a continuous function which is analytic on $\Bbb{C}\setminus \Bbb{R}$ . I need to use the Morera theorem to show that $f$ is analytic on $\Bbb{C}$ . In the lecture the Prof. gave us the hint that we should decompose rectangle into three rectangles. Up to now I have done the following: Let $z_0\in \Bbb{C}$ . Take $B_r(z_0)\subset \Bbb{C}$ be an open disk. By assumption $f$ is continuous on $B_r(z_0)$ . Let me define $R$ to be an arbitrary closed rectangle in $B_r(z_0)$ . Now to conclude I only need to show that $$\int_{\partial R} f(z) dz=0$$ Here I think I need the hint but I don't see how it works. Could maybe someone help me? Thanks for your help,Let be a continuous function which is analytic on . I need to use the Morera theorem to show that is analytic on . In the lecture the Prof. gave us the hint that we should decompose rectangle into three rectangles. Up to now I have done the following: Let . Take be an open disk. By assumption is continuous on . Let me define to be an arbitrary closed rectangle in . Now to conclude I only need to show that Here I think I need the hint but I don't see how it works. Could maybe someone help me? Thanks for your help,f:\Bbb{C}\rightarrow \Bbb{C} \Bbb{C}\setminus \Bbb{R} f \Bbb{C} z_0\in \Bbb{C} B_r(z_0)\subset \Bbb{C} f B_r(z_0) R B_r(z_0) \int_{\partial R} f(z) dz=0,"['complex-analysis', 'analysis', 'analytic-functions']"
27,"Show the limit $\lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \to 0 $ in a proof of the Digamma function",Show the limit  in a proof of the Digamma function,"\lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \to 0 ","I want to show that $$\lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \to 0 \tag{1}$$ Intutitively I could take the limits before integration, then I would get $$\int_{0}^{0} \frac{e^{-x}}{x}\,dx=0 $$ My question is whether this procedure is valid, or a more rigorous proof should be provided in he lines of Edit : Being more careful in the calculations I could show the following estimate: $$ \begin{align*} \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx & \leq \left| \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \right|\\ & \leq  \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta}\left| \frac{e^{-x}}{x}\right|\,dx \\ & \leq  \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{dx}{x} \\ &=\lim_{\delta \to 0} \, \ln(x)\Big|_{\ln(1+\delta)}^{\delta}\\ &=-\lim_{\delta \to 0} \, \ln\left(\frac{\ln(1+\delta)}{\delta}\right)\\ &=- \ln\left(\lim_{\delta \to 0}\frac{\ln(1+\delta)}{\delta}\right) & \text{by continuity of log}\\ &=- \ln\left(\lim_{\delta \to 0}\frac{1}{\delta}\sum_{n=1}^\infty \frac{(-1)^{n+1} \delta^n}{n}\right)\\ &=- \ln\left(\lim_{\delta \to 0}\sum_{n=1}^\infty \frac{(-1)^{n-1} \delta^{n-1}}{n}\right)\\ &=-\ln(1)\\ &=0 \end{align*} $$ Motivation: The motivation behind this limit comes from a proof of an integral representation of the Digamma function. If we define the Gamma function by the integral $(2)$ below and the digamma function by $\psi(z)=\frac{z}{dz}\ln\left(\Gamma(z) \right)$ $$\Gamma(z)= \int_0^\infty e^{-t}t^{z-1}\,dt \qquad \operatorname{Re}(z)>0\tag{2}$$ Differentiating $(2)$ w.r. to $z$ we obtain: $$ \begin{align*} \Gamma^\prime(z)&= \int_0^\infty e^{-t}t^{z-1} \ln(t)\,dt \qquad \operatorname{Re}(z)>0\\ &= \int_0^\infty e^{-t}t^{z-1} \left(\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}\,dx \right)\,dt\\ &= \int_0^\infty \left(\int_0^\infty (e^{-x}-e^{-xt})e^{-t}t^{z-1}\,dt \right)\,\frac{dx}{x}\\ &= \int_0^\infty \left(e^{-x}\int_0^\infty e^{-t}t^{z-1}\,dt-\int_0^\infty e^{-t(1+x)}t^{z-1}\,dt \right)\,\frac{dx}{x}\\ &= \int_0^\infty \left(e^{-x}\Gamma(z)-\frac{1}{(1+x)^z}\int_0^\infty e^{-t}t^{z-1}\,dt \right)\,\frac{dx}{x}\\ &= \int_0^\infty \left(e^{-x}\Gamma(z)-\frac{1}{(1+x)^z}\Gamma(z)\right)\,\frac{dx}{x}\\ &=\Gamma(z) \int_0^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x}\\ \end{align*} $$ Therefore we have $$\psi(z)=\int_0^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x} \tag{3}$$ Than $$ \begin{align*} \psi(z)&= \lim_{\delta \to 0}\int_{\delta}^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x}\\ &= \lim_{\delta \to 0}\left[\int_{\delta}^\infty \frac{e^{-x}}{x}\,dx-\int_{\delta}^\infty \frac{1}{x(1+x)^z}\,dx\right]\\ &= \lim_{\delta \to 0}\left[\int_{\delta}^\infty \frac{e^{-x}}{x}\,dx-\int_{\ln(1+\delta)}^\infty \frac{e^{-xz}}{1-e^{-x}}\,dx\right] & (x+1 \to e^{x})\\ &= \lim_{\delta \to 0}\left[\int_{\ln(1+\delta)}^\infty \frac{e^{-x}}{x}\,dx-\int_{\ln(1+\delta)}^\infty \frac{e^{-xz}}{1-e^{-x}}\,dx+\int_{\delta}^{\ln(1+\delta)} \frac{e^{-x}}{x}\,dx\right] \\ &= \lim_{\delta \to 0}\left[\int_{\ln(1+\delta)}^\infty \frac{e^{-x}}{x}- \frac{e^{-xz}}{1-e^{-x}}\,dx-\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx\right] \\ &=\int_{0}^\infty \frac{e^{-x}}{x}- \frac{e^{-xz}}{1-e^{-x}}\,dx, \qquad \operatorname{Re}(z)>0 \end{align*} $$ Provided $(1)$ holds.","I want to show that Intutitively I could take the limits before integration, then I would get My question is whether this procedure is valid, or a more rigorous proof should be provided in he lines of Edit : Being more careful in the calculations I could show the following estimate: Motivation: The motivation behind this limit comes from a proof of an integral representation of the Digamma function. If we define the Gamma function by the integral below and the digamma function by Differentiating w.r. to we obtain: Therefore we have Than Provided holds.","\lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \to 0 \tag{1} \int_{0}^{0} \frac{e^{-x}}{x}\,dx=0  
\begin{align*}
\lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx & \leq \left| \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx \right|\\
& \leq  \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta}\left| \frac{e^{-x}}{x}\right|\,dx \\
& \leq  \lim_{\delta \to 0}\int_{\ln(1+\delta)}^{\delta} \frac{dx}{x} \\
&=\lim_{\delta \to 0} \, \ln(x)\Big|_{\ln(1+\delta)}^{\delta}\\
&=-\lim_{\delta \to 0} \, \ln\left(\frac{\ln(1+\delta)}{\delta}\right)\\
&=- \ln\left(\lim_{\delta \to 0}\frac{\ln(1+\delta)}{\delta}\right) & \text{by continuity of log}\\
&=- \ln\left(\lim_{\delta \to 0}\frac{1}{\delta}\sum_{n=1}^\infty \frac{(-1)^{n+1} \delta^n}{n}\right)\\
&=- \ln\left(\lim_{\delta \to 0}\sum_{n=1}^\infty \frac{(-1)^{n-1} \delta^{n-1}}{n}\right)\\
&=-\ln(1)\\
&=0
\end{align*}
 (2) \psi(z)=\frac{z}{dz}\ln\left(\Gamma(z) \right) \Gamma(z)= \int_0^\infty e^{-t}t^{z-1}\,dt \qquad \operatorname{Re}(z)>0\tag{2} (2) z 
\begin{align*}
\Gamma^\prime(z)&= \int_0^\infty e^{-t}t^{z-1} \ln(t)\,dt \qquad \operatorname{Re}(z)>0\\
&= \int_0^\infty e^{-t}t^{z-1} \left(\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}\,dx \right)\,dt\\
&= \int_0^\infty \left(\int_0^\infty (e^{-x}-e^{-xt})e^{-t}t^{z-1}\,dt \right)\,\frac{dx}{x}\\
&= \int_0^\infty \left(e^{-x}\int_0^\infty e^{-t}t^{z-1}\,dt-\int_0^\infty e^{-t(1+x)}t^{z-1}\,dt \right)\,\frac{dx}{x}\\
&= \int_0^\infty \left(e^{-x}\Gamma(z)-\frac{1}{(1+x)^z}\int_0^\infty e^{-t}t^{z-1}\,dt \right)\,\frac{dx}{x}\\
&= \int_0^\infty \left(e^{-x}\Gamma(z)-\frac{1}{(1+x)^z}\Gamma(z)\right)\,\frac{dx}{x}\\
&=\Gamma(z) \int_0^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x}\\
\end{align*}
 \psi(z)=\int_0^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x} \tag{3} 
\begin{align*}
\psi(z)&= \lim_{\delta \to 0}\int_{\delta}^\infty \left(e^{-x}-\frac{1}{(1+x)^z}\right)\,\frac{dx}{x}\\
&= \lim_{\delta \to 0}\left[\int_{\delta}^\infty \frac{e^{-x}}{x}\,dx-\int_{\delta}^\infty \frac{1}{x(1+x)^z}\,dx\right]\\
&= \lim_{\delta \to 0}\left[\int_{\delta}^\infty \frac{e^{-x}}{x}\,dx-\int_{\ln(1+\delta)}^\infty \frac{e^{-xz}}{1-e^{-x}}\,dx\right] & (x+1 \to e^{x})\\
&= \lim_{\delta \to 0}\left[\int_{\ln(1+\delta)}^\infty \frac{e^{-x}}{x}\,dx-\int_{\ln(1+\delta)}^\infty \frac{e^{-xz}}{1-e^{-x}}\,dx+\int_{\delta}^{\ln(1+\delta)} \frac{e^{-x}}{x}\,dx\right] \\
&= \lim_{\delta \to 0}\left[\int_{\ln(1+\delta)}^\infty \frac{e^{-x}}{x}- \frac{e^{-xz}}{1-e^{-x}}\,dx-\int_{\ln(1+\delta)}^{\delta} \frac{e^{-x}}{x}\,dx\right] \\
&=\int_{0}^\infty \frac{e^{-x}}{x}- \frac{e^{-xz}}{1-e^{-x}}\,dx, \qquad \operatorname{Re}(z)>0
\end{align*}
 (1)","['integration', 'complex-analysis', 'limits', 'gamma-function', 'digamma-function']"
28,Closed rectifiable curve with arbitary winding number.,Closed rectifiable curve with arbitary winding number.,,"This is an exercise from Conway's Functions of One Complex Variable (page 83, exercise 2). Give an example of a closed rectifiable curve $\gamma$ in $\mathbb C$ s.t. for any integer $k$ there is a point $a\notin \{\gamma\}$ with $n(\gamma;a)=k$ . My solution: $$ \gamma_1(t)=\begin{cases}\exp\{\frac{-1+i}{t}\} &t\in(0,1]\\0&t=0\end{cases}$$ is a rectifiable curve since $$\int_0^1|\gamma'(t)|\mathbb d t=\int_0^1\frac{\sqrt2}{t^2}e^{-1/t}\mathrm dt=\int_1^{\infty}{\sqrt2}{}xe^{-x}\mathrm dx=2\sqrt 2e^{-1}$$ If we connect $0$ and $\exp\{{-1+i}\}$ by a segment, then we obtain a desired closed rectifiable curve $\gamma$ . I can see the number of times $\gamma$ orbits about a given point intuitively, but how to compute the winding number rigorously? (Besides, Conway hasn't introduce homotopy there, so I don't know if there are other ways to evaluate the winding number except finding a curve homotopic to the original one?)","This is an exercise from Conway's Functions of One Complex Variable (page 83, exercise 2). Give an example of a closed rectifiable curve in s.t. for any integer there is a point with . My solution: is a rectifiable curve since If we connect and by a segment, then we obtain a desired closed rectifiable curve . I can see the number of times orbits about a given point intuitively, but how to compute the winding number rigorously? (Besides, Conway hasn't introduce homotopy there, so I don't know if there are other ways to evaluate the winding number except finding a curve homotopic to the original one?)","\gamma \mathbb C k a\notin \{\gamma\} n(\gamma;a)=k  \gamma_1(t)=\begin{cases}\exp\{\frac{-1+i}{t}\} &t\in(0,1]\\0&t=0\end{cases} \int_0^1|\gamma'(t)|\mathbb d t=\int_0^1\frac{\sqrt2}{t^2}e^{-1/t}\mathrm dt=\int_1^{\infty}{\sqrt2}{}xe^{-x}\mathrm dx=2\sqrt 2e^{-1} 0 \exp\{{-1+i}\} \gamma \gamma","['complex-analysis', 'complex-integration', 'cauchy-integral-formula', 'winding-number']"
29,Why does the complex phase plot look exactly like the root locus diagram?,Why does the complex phase plot look exactly like the root locus diagram?,,"BRIEF BACKGROUND Basically here's an interesting discovery I made (probably not an original discovery) when playing around with MATLAB the other day. I was basically just trying to make a good visualization of complex valued plots and trying to implement an HSV (hue, saturation, value) model of coloring a complex function. But my first step was just to plot the phase and magnitude separately with standard MATLAB colorings and this is when I made the interesting discovery that the phase plot of a complex valued function looks exactly like the root locus diagram of that function. This obviously cannot be a coincidence as when I change the poles and zeros the root locus diagram looks exactly the same. For those who are not familiar with root locus diagrams, they are useful tool in control systems to know where the poles and zeros of a system go when you change the feedback gain. If your open loop gain transfer function $L(s)$ is described by a polynomial and has certain poles and zeros when it is connected in a feedback system with a gain $K$ the poles and zeros of the total system move as $K$ is increased or decreased. Feedback System MATLAB CODE clearvars clc clf format long  %% Complex Plotting Tools % Setup our grid of complex values to cover the complex plane z_real = linspace(-5, 5, 1000); z_imag = linspace(-5, 5, 1000); [RealZ, ImagZ] = meshgrid(z_real, z_imag); z = RealZ + ImagZ * 1j;  % Set up the coefficients of our complex polynomial % Define a function based off the numerator/denominator coefficients  zrs = [-1]'; pls = [-2+1j, -2-1j, -3]'; [num_poly, den_poly] = zp2tf(zrs, pls, 1); f = @(x)(polyval(num_poly, x) ./ polyval(den_poly, x));  % Print the roots of the polynomials disp(roots(num_poly)); disp(roots(den_poly));  % Plot the complex magnitude in these plots figure(1) hold on grid on surf(RealZ, ImagZ, log(abs(f(z))), 'EdgeColor', 'none'); colormap jet colorbar  % Plot the complex phase in these plots figure(2) hold on grid on surf(RealZ, ImagZ, rad2deg(angle(f(z))), 'EdgeColor', 'none'); colormap jet colorbar  %% Root Locus Plot % Generate a pole/zero plot of the same system % Generate a root locus plot of the same system  F = tf(num_poly, den_poly);  figure(3) hold on grid on pzplot(F);  figure(4) hold on grid on rlocus(F); PLOT DIAGRAMS Magnitude Plot of Complex Function Phase of a Complex Function Pole Zero Diagram Root Locus Diagram of Complex Function QUESTION So my question is this: Why does the phase plot of the complex valued function look exactly like its corresponding root locus diagram? I'm going to work on this myself to see if I can figure it out but figured I'd toss this question out to the larger community.","BRIEF BACKGROUND Basically here's an interesting discovery I made (probably not an original discovery) when playing around with MATLAB the other day. I was basically just trying to make a good visualization of complex valued plots and trying to implement an HSV (hue, saturation, value) model of coloring a complex function. But my first step was just to plot the phase and magnitude separately with standard MATLAB colorings and this is when I made the interesting discovery that the phase plot of a complex valued function looks exactly like the root locus diagram of that function. This obviously cannot be a coincidence as when I change the poles and zeros the root locus diagram looks exactly the same. For those who are not familiar with root locus diagrams, they are useful tool in control systems to know where the poles and zeros of a system go when you change the feedback gain. If your open loop gain transfer function is described by a polynomial and has certain poles and zeros when it is connected in a feedback system with a gain the poles and zeros of the total system move as is increased or decreased. Feedback System MATLAB CODE clearvars clc clf format long  %% Complex Plotting Tools % Setup our grid of complex values to cover the complex plane z_real = linspace(-5, 5, 1000); z_imag = linspace(-5, 5, 1000); [RealZ, ImagZ] = meshgrid(z_real, z_imag); z = RealZ + ImagZ * 1j;  % Set up the coefficients of our complex polynomial % Define a function based off the numerator/denominator coefficients  zrs = [-1]'; pls = [-2+1j, -2-1j, -3]'; [num_poly, den_poly] = zp2tf(zrs, pls, 1); f = @(x)(polyval(num_poly, x) ./ polyval(den_poly, x));  % Print the roots of the polynomials disp(roots(num_poly)); disp(roots(den_poly));  % Plot the complex magnitude in these plots figure(1) hold on grid on surf(RealZ, ImagZ, log(abs(f(z))), 'EdgeColor', 'none'); colormap jet colorbar  % Plot the complex phase in these plots figure(2) hold on grid on surf(RealZ, ImagZ, rad2deg(angle(f(z))), 'EdgeColor', 'none'); colormap jet colorbar  %% Root Locus Plot % Generate a pole/zero plot of the same system % Generate a root locus plot of the same system  F = tf(num_poly, den_poly);  figure(3) hold on grid on pzplot(F);  figure(4) hold on grid on rlocus(F); PLOT DIAGRAMS Magnitude Plot of Complex Function Phase of a Complex Function Pole Zero Diagram Root Locus Diagram of Complex Function QUESTION So my question is this: Why does the phase plot of the complex valued function look exactly like its corresponding root locus diagram? I'm going to work on this myself to see if I can figure it out but figured I'd toss this question out to the larger community.",L(s) K K,"['complex-analysis', 'control-theory']"
30,The unit disk with pseudo hyperbolic distance is complete space,The unit disk with pseudo hyperbolic distance is complete space,,"The pseudo-hyperbolic distance on the unit disk $D$ is defined as: $$\rho(z,w)=\left|\dfrac{z-w}{1-\bar wz}\right|.$$ I need to prove that $(D,\rho(z,w))$ is complete space. I know that a metric space is called complete if every Cauchy sequence converges, but I really don't know how to prove that this space is complete, could you give me some idea?","The pseudo-hyperbolic distance on the unit disk is defined as: I need to prove that is complete space. I know that a metric space is called complete if every Cauchy sequence converges, but I really don't know how to prove that this space is complete, could you give me some idea?","D \rho(z,w)=\left|\dfrac{z-w}{1-\bar wz}\right|. (D,\rho(z,w))","['complex-analysis', 'metric-spaces', 'complete-spaces']"
31,Isomorphism of meromorphic function fields implies Riemann surfaces are isomorphic,Isomorphism of meromorphic function fields implies Riemann surfaces are isomorphic,,"This is about from Forster, Lectures on Riemann Surfaces, Exercise 8.1. The exercise is the following: ( $\mathcal{M}(X)$ represents the field of meromorphic functions on $X$ , and likewise for $Y$ .) Suppose $X$ and $Y$ are compact Riemann surfaces such that $\mathcal{M}(X)$ and $\mathcal{M}(Y)$ are isomorphic as $\mathbb{C}$ algebras. Prove that $X$ and $Y$ are isomorphic. There's a hint which suggests representing $X$ and $Y$ as the Riemann surfaces of algebraic functions of the same polynomial $P$ from $\mathcal{M}(\mathbb{P}^1)[T]$ and the fact (which is proved later) that the meromorphic functions separate points, over a compact Riemann surface. To get started, it seems like I need a branched holomorphic covering map $\pi:X\to \mathbb{P}^1$ . One candidate seems like using an arbitrary non constant element of $\mathcal{M}(X)$ and consider that as a surjective map into $\mathbb{P}^1$ . However I'm not quite sure how to proceed. To that end I would be very grateful if someone could give me a hint where to start. (I am aware that something along these lines has already been asked here If two meromorphic function fields on compact riemann surfaces isomorphic, then they are isomorphic , but it doesn't shed much light on how I might use the hint with whatever Forster has developed so far.)","This is about from Forster, Lectures on Riemann Surfaces, Exercise 8.1. The exercise is the following: ( represents the field of meromorphic functions on , and likewise for .) Suppose and are compact Riemann surfaces such that and are isomorphic as algebras. Prove that and are isomorphic. There's a hint which suggests representing and as the Riemann surfaces of algebraic functions of the same polynomial from and the fact (which is proved later) that the meromorphic functions separate points, over a compact Riemann surface. To get started, it seems like I need a branched holomorphic covering map . One candidate seems like using an arbitrary non constant element of and consider that as a surjective map into . However I'm not quite sure how to proceed. To that end I would be very grateful if someone could give me a hint where to start. (I am aware that something along these lines has already been asked here If two meromorphic function fields on compact riemann surfaces isomorphic, then they are isomorphic , but it doesn't shed much light on how I might use the hint with whatever Forster has developed so far.)",\mathcal{M}(X) X Y X Y \mathcal{M}(X) \mathcal{M}(Y) \mathbb{C} X Y X Y P \mathcal{M}(\mathbb{P}^1)[T] \pi:X\to \mathbb{P}^1 \mathcal{M}(X) \mathbb{P}^1,"['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'riemann-surfaces']"
32,Prove Bergman's kernel formula by theorem of residues,Prove Bergman's kernel formula by theorem of residues,,"I am having trouble with exercise $5$ , $4.5.3$ in Ahlfors's complex analysis. I was asked to prove the Bergman's kernel formula: \begin{equation} f(\zeta)=\frac{1}{\pi}\iint\limits_{|z|<1}\frac{f(z)\mathrm{d}x\mathrm{d}y}{(1-\bar{z}\zeta)^{2}} \end{equation} under the conditions f(z) is bounded and analytic in the unit disk, moreover $\zeta$ lies in the disk. Two solutions of this problem are available on this website by using series expansion or Green's formula. However Ahlhors suggested another approach by using polar coordinates first, then transforming the inside integral into a line integral which can be evaluated by theorem of residues. I really don't know how to proceed in this way. I haved tried as following: \begin{align} \iint\limits_{D}\frac{f(z)\mathrm{d}x\mathrm{d}y}{(1-\bar{z}\zeta)^{2}}&=\int_{0}^{1}\mathrm{d}r\int_{0}^{2\pi}\frac{f(z)r}{(1-\bar{z}\zeta)^{2}}\mathrm{d}\theta\\ &=\int_{0}^{1}r\mathrm{d}r\oint\limits_{|z|=r}\frac{f(z)}{(1-\bar{z}\zeta)^{2}z}\mathrm{d}z\\ \text{Since $z \bar{z}=r^{2}$}\\ &= \int_{0}^{1}r\mathrm{d}r\oint\limits_{|z|=r}\frac{f(z)z}{(z-r^{2}\zeta)^{2}}\mathrm{d}z \end{align} At this stage, I have observed that if $\zeta=0$ , then by Cauchy's theorem, the equality holds. If not, I use Residues to evaluate the contour integral and get the value $f(r^{2}\zeta)+f'(r^{2}\zeta)r^{2}\zeta$ . But I stacked here because it seems impossible to get an explicit result of the integral with respect to r. Then I spent a huge amount of time trying to construct a special change of variable for the inside contour integral by a fractional linear transformation from a unit disk onto the smaller disk. But I just can not find the right linear transformation. Maybe I am on the wrong track.","I am having trouble with exercise , in Ahlfors's complex analysis. I was asked to prove the Bergman's kernel formula: under the conditions f(z) is bounded and analytic in the unit disk, moreover lies in the disk. Two solutions of this problem are available on this website by using series expansion or Green's formula. However Ahlhors suggested another approach by using polar coordinates first, then transforming the inside integral into a line integral which can be evaluated by theorem of residues. I really don't know how to proceed in this way. I haved tried as following: At this stage, I have observed that if , then by Cauchy's theorem, the equality holds. If not, I use Residues to evaluate the contour integral and get the value . But I stacked here because it seems impossible to get an explicit result of the integral with respect to r. Then I spent a huge amount of time trying to construct a special change of variable for the inside contour integral by a fractional linear transformation from a unit disk onto the smaller disk. But I just can not find the right linear transformation. Maybe I am on the wrong track.","5 4.5.3 \begin{equation}
f(\zeta)=\frac{1}{\pi}\iint\limits_{|z|<1}\frac{f(z)\mathrm{d}x\mathrm{d}y}{(1-\bar{z}\zeta)^{2}}
\end{equation} \zeta \begin{align}
\iint\limits_{D}\frac{f(z)\mathrm{d}x\mathrm{d}y}{(1-\bar{z}\zeta)^{2}}&=\int_{0}^{1}\mathrm{d}r\int_{0}^{2\pi}\frac{f(z)r}{(1-\bar{z}\zeta)^{2}}\mathrm{d}\theta\\
&=\int_{0}^{1}r\mathrm{d}r\oint\limits_{|z|=r}\frac{f(z)}{(1-\bar{z}\zeta)^{2}z}\mathrm{d}z\\
\text{Since z \bar{z}=r^{2}}\\ &= \int_{0}^{1}r\mathrm{d}r\oint\limits_{|z|=r}\frac{f(z)z}{(z-r^{2}\zeta)^{2}}\mathrm{d}z
\end{align} \zeta=0 f(r^{2}\zeta)+f'(r^{2}\zeta)r^{2}\zeta","['complex-analysis', 'residue-calculus']"
33,Solve $\log(z^2-1)=\frac{i\pi}{2}$,Solve,\log(z^2-1)=\frac{i\pi}{2},"I was wondering if someone could help me solve the following complex logarithmic equation, such that $$ \text{Log}(z):=\log(z) \iff\arg z=\theta_p $$ $$ \forall z \in \mathbb{R} :\text{Log}(z^2-1)=i\pi/2 $$ So far, I have $$ w=e^z \implies w^2+w+1=0. $$ Solving for $w$ using quadratic $$ w=-1/2+i\sqrt3/2 $$ or $$ w=-1/2-i\sqrt3/2 $$ From the text, I know a few things $$ \text{Log}(z)=\text{Log}(r)+i\theta_p : r=|z|>0, \theta_p=\arg(z), -\pi<\theta_p<=\pi $$ $$ \text{Arg}(z)=\theta_p+2\pi k : k=..., -3, -2, -1, 0, 1, 2, 3, ... $$ $$ \log(z)=\text{Log}(r)+i(\theta+2 \pi k) $$ Thank you in advance for your help!","I was wondering if someone could help me solve the following complex logarithmic equation, such that So far, I have Solving for using quadratic or From the text, I know a few things Thank you in advance for your help!","
\text{Log}(z):=\log(z) \iff\arg z=\theta_p
 
\forall z \in \mathbb{R} :\text{Log}(z^2-1)=i\pi/2
 
w=e^z \implies w^2+w+1=0.
 w 
w=-1/2+i\sqrt3/2
 
w=-1/2-i\sqrt3/2
 
\text{Log}(z)=\text{Log}(r)+i\theta_p : r=|z|>0, \theta_p=\arg(z), -\pi<\theta_p<=\pi
 
\text{Arg}(z)=\theta_p+2\pi k : k=..., -3, -2, -1, 0, 1, 2, 3, ...
 
\log(z)=\text{Log}(r)+i(\theta+2 \pi k)
","['complex-analysis', 'trigonometry', 'complex-numbers', 'logarithms']"
34,Show that $\int_0^1 |t-z|^{-1/2}\ \mathrm{d}t < c(1 + |z|)^{-1/2}$,Show that,\int_0^1 |t-z|^{-1/2}\ \mathrm{d}t < c(1 + |z|)^{-1/2},"I want to show that there is a constant $c > 0$ such that $$ \int_0^1 |t-z|^{-1/2}\ \mathrm{d}t < c(1 + |z|)^{-1/2} $$ for any $z \in \mathbb{C}$ . I found the assertion in a paper I'm reading and I have not succeeded in proving it. Perhaps it uses a common technique in complex analysis (my complex analysis is rusty). Power series expansions came to mind, but I still don't see how to make use of it.","I want to show that there is a constant such that for any . I found the assertion in a paper I'm reading and I have not succeeded in proving it. Perhaps it uses a common technique in complex analysis (my complex analysis is rusty). Power series expansions came to mind, but I still don't see how to make use of it.","c > 0 
\int_0^1 |t-z|^{-1/2}\ \mathrm{d}t < c(1 + |z|)^{-1/2}
 z \in \mathbb{C}","['complex-analysis', 'inequality']"
35,What is the relation between the shift operator for derivatives and Fourier transforms?,What is the relation between the shift operator for derivatives and Fourier transforms?,,"I feel like I am close to piecing together the relation but am not quite fully sure. This is the shift operator I’m talking about from Wikipedia page on shift operator The shift operator $T^{t}$ (where $t \in \mathbf{R}$ ) takes a function $f$ on $\mathbf{R}$ to its translation $f_{t}$ , $T^{t} f(x)=f_{t}(x)=f(x+t)$ . A practical operational calculus representation of the linear operator $T^{t}$ in terms of the plain derivative $\frac{d}{d x}$ was introduced by Lagrange, $$T^{t}=e^{t\frac{d}{d x}}, $$ which may be interpreted operationally through its formal Taylor expansion in $t ;$ and whose action on the monomial $x^{n}$ is evident by the binomial theorem, and hence on all series in $x$ , and so all functions $f(x)$ as above. $[3]$ This, then, is a formal encoding of the Taylor expansion in Heaviside's calculus. I also know the properties of Fourier transform time and frequency shifting from the page on the Fourier transform Translation / time shifting For any real number $x_{0}$ , if $h(x)=f\left(x-x_{0}\right)$ , then $\hat{h}(\xi)=e^{-2 \pi i x_{0} \xi} \hat{f}(\xi)$ . Then heuristically because of my slight knowledge of operational calculus , I know that the derivative operator with respect to time can be equated to frequency. Conversely because of the duality of time and frequency, I’m guessing the derivative operator with respect to frequency is the same as the time variable. I feel like there should be some way to interpret all of these things in a unified manner but I haven’t quite figured it out. Mainly the derivative shift operator applied to a function looks like the Fourier transform shifting but there is a slight difference between the two when you do the calculations.","I feel like I am close to piecing together the relation but am not quite fully sure. This is the shift operator I’m talking about from Wikipedia page on shift operator The shift operator (where ) takes a function on to its translation , . A practical operational calculus representation of the linear operator in terms of the plain derivative was introduced by Lagrange, which may be interpreted operationally through its formal Taylor expansion in and whose action on the monomial is evident by the binomial theorem, and hence on all series in , and so all functions as above. This, then, is a formal encoding of the Taylor expansion in Heaviside's calculus. I also know the properties of Fourier transform time and frequency shifting from the page on the Fourier transform Translation / time shifting For any real number , if , then . Then heuristically because of my slight knowledge of operational calculus , I know that the derivative operator with respect to time can be equated to frequency. Conversely because of the duality of time and frequency, I’m guessing the derivative operator with respect to frequency is the same as the time variable. I feel like there should be some way to interpret all of these things in a unified manner but I haven’t quite figured it out. Mainly the derivative shift operator applied to a function looks like the Fourier transform shifting but there is a slight difference between the two when you do the calculations.","T^{t} t \in \mathbf{R} f \mathbf{R} f_{t} T^{t} f(x)=f_{t}(x)=f(x+t) T^{t} \frac{d}{d x} T^{t}=e^{t\frac{d}{d x}},  t ; x^{n} x f(x) [3] x_{0} h(x)=f\left(x-x_{0}\right) \hat{h}(\xi)=e^{-2 \pi i x_{0} \xi} \hat{f}(\xi)","['complex-analysis', 'functional-analysis', 'fourier-analysis', 'fourier-transform', 'harmonic-analysis']"
36,Rudin 9.19 Implicit Function Theorem Exercise,Rudin 9.19 Implicit Function Theorem Exercise,,"Show that the system of equations $$ \begin{array}{r} 3 x+y-z+u^{2}=0 \\ x-y+2 z+u=0 \\ 2 x+2 y-3 z+2 u=0 \end{array} $$ can be solved for $x, y, u$ in terms of $z$ ; for $x, z, u$ in terms of $y$ ; for $y, z, u$ in terms of $x$ ; but not for $x, y, z$ in terms of $u$ . I am trying to show that this system can be solved for $x,y,u$ in terms of $z$ . Does this need to have a solution set for every single $z\in\mathbb{R}$ ? I am thinking about applying the implicit function theorem however this would require checking that the derivative is non-invertible. If I view this function as $f:\mathbb{R}^3\times \mathbb{R}\to \mathbb{R^3} $ $$f(x,y,z,u)=[3x+y-z+u^2, x-y+2z+u, 2x+2y-3z+2u]$$ I get that the total derivative w.r.t. (x,y,u) is $$\left[\begin{array}{ccc} 3 & 1 & 2 u \\ 1 & -1 & 1 \\ 2 & 2 & 2 \end{array}\right]$$ Would this need to be invertible for every $u$ for the implicit function theorem to find a function in terms of $z$ that can solve the system of equations?","Show that the system of equations can be solved for in terms of ; for in terms of ; for in terms of ; but not for in terms of . I am trying to show that this system can be solved for in terms of . Does this need to have a solution set for every single ? I am thinking about applying the implicit function theorem however this would require checking that the derivative is non-invertible. If I view this function as I get that the total derivative w.r.t. (x,y,u) is Would this need to be invertible for every for the implicit function theorem to find a function in terms of that can solve the system of equations?","
\begin{array}{r}
3 x+y-z+u^{2}=0 \\
x-y+2 z+u=0 \\
2 x+2 y-3 z+2 u=0
\end{array}
 x, y, u z x, z, u y y, z, u x x, y, z u x,y,u z z\in\mathbb{R} f:\mathbb{R}^3\times \mathbb{R}\to \mathbb{R^3}  f(x,y,z,u)=[3x+y-z+u^2, x-y+2z+u, 2x+2y-3z+2u] \left[\begin{array}{ccc}
3 & 1 & 2 u \\
1 & -1 & 1 \\
2 & 2 & 2
\end{array}\right] u z","['real-analysis', 'calculus', 'complex-analysis', 'analysis']"
37,showing removable singularity at origin.,showing removable singularity at origin.,,"Let $f$ be holomorphic in the punctured disk $\{z:0< \vert z \vert<2\}$ such that $$\vert f(z) \vert \leq \bigg(\log \frac{1}{\vert z \vert}\bigg)^{100}, \space \text{in $\vert z \vert \leq \frac{1}{2}$}$$ and $$\vert f(z) \vert = 1, \space \text{on $\vert z \vert = 1$}$$ I need to show $f$ has a removable singularity at the origin. Does this mean I need to find an analytic function $g$ defined on an $\epsilon$ ball about the origin agrees with $f$ for $0< \vert z \vert < \epsilon$ ? So is this by construction? Am I contracting such an analytic $g$ ?",Let be holomorphic in the punctured disk such that and I need to show has a removable singularity at the origin. Does this mean I need to find an analytic function defined on an ball about the origin agrees with for ? So is this by construction? Am I contracting such an analytic ?,"f \{z:0< \vert z \vert<2\} \vert f(z) \vert \leq \bigg(\log \frac{1}{\vert z \vert}\bigg)^{100}, \space \text{in \vert z \vert \leq \frac{1}{2}} \vert f(z) \vert = 1, \space \text{on \vert z \vert = 1} f g \epsilon f 0< \vert z \vert < \epsilon g","['complex-analysis', 'analytic-functions', 'singularity']"
38,Finding every complex number that fulfills |z| = 1 and $|\frac{z}{\bar z} + \frac{\bar z}{z} | = 1$,Finding every complex number that fulfills |z| = 1 and,|\frac{z}{\bar z} + \frac{\bar z}{z} | = 1,"I wanna find out every complex number that fulfills $|z| =1 $ and $$ |\frac{z}{\bar z} + \frac{\bar z}{z} | = 1$$ The first thing i do is that i expand both of the denominators with their conjugates and since $ |z| = 1$ i get that $ z * \bar z = |z|^{2} = 1 $ So i'm left with the following expression $| z^{2}+(\bar z)^{2}|=1 $ The next thing i do is to change to polar form. Since $ |z|=1$ , i get that $$ z=|z|e^{i\theta}=e^{i\theta} $$ and $$ |e^{i2\theta}+e^{-i2\theta} | = 2|\frac{e^{i2\theta}+e^{-i2\theta}}{2}| = 2|cos(2\theta)|=1$$ Now, if i solve this i get 4 different complex numbers. However there should be 8 numbers so it seems that i lose answers somewhere or there is something im doing wrong that i can't seem to find.","I wanna find out every complex number that fulfills and The first thing i do is that i expand both of the denominators with their conjugates and since i get that So i'm left with the following expression The next thing i do is to change to polar form. Since , i get that and Now, if i solve this i get 4 different complex numbers. However there should be 8 numbers so it seems that i lose answers somewhere or there is something im doing wrong that i can't seem to find.",|z| =1   |\frac{z}{\bar z} + \frac{\bar z}{z} | = 1  |z| = 1  z * \bar z = |z|^{2} = 1  | z^{2}+(\bar z)^{2}|=1   |z|=1  z=|z|e^{i\theta}=e^{i\theta}   |e^{i2\theta}+e^{-i2\theta} | = 2|\frac{e^{i2\theta}+e^{-i2\theta}}{2}| = 2|cos(2\theta)|=1,"['complex-analysis', 'complex-numbers']"
39,Laurent series of $\frac{z^2 + iz - 1}{(z - 2)(z + 3)}$,Laurent series of,\frac{z^2 + iz - 1}{(z - 2)(z + 3)},I want to expand the function following into Laurent series: $$\frac{z^2 + iz - 1}{(z - 2)(z + 3)}$$ for $2 < |z| < 3$ My solution First thing to apply is partial function decomposition: $$\frac{1}{(z - 2)(z  +3)} = \frac{\frac 1 5}{z - 2} + \frac{-\frac 1 5}{z + 3}$$ From which we have that: $$\frac{z^2 + iz - 1}{(z - 2)(z  +3)} = \frac{\frac 1 5 (z^2 + iz - 1)}{z - 2} + \frac{-\frac 1 5 (z^2 + iz - 1)}{z + 3}$$ Now we expand those two series: $$\frac{1}{z - 2} = \frac{1}{z}\frac{1}{1 - \frac 2 z} = \sum_{n = 0}^\infty \frac{2^n}{z^{n + 1}}$$ $$\frac{1}{z + 3} = \frac{1}{3(\frac z 3 + 1)} = \frac 1 3 \frac{1}{1 - ( - \frac z 3)} = \sum_{n = 0}^\infty (-1)^n \frac{z^n}{3^{n + 1}}$$ So final result is: $$\frac{z^2 + iz - 1}{(z - 2)(z + 3)} = \sum_{n = 0}^\infty \frac{z^2 + iz - 1}{5}[\frac{2^n}{z^{n + 1}} - \frac{(-1)^nz^n}{3^{n + 1}}]$$ Does it make any sense to you?,I want to expand the function following into Laurent series: for My solution First thing to apply is partial function decomposition: From which we have that: Now we expand those two series: So final result is: Does it make any sense to you?,\frac{z^2 + iz - 1}{(z - 2)(z + 3)} 2 < |z| < 3 \frac{1}{(z - 2)(z  +3)} = \frac{\frac 1 5}{z - 2} + \frac{-\frac 1 5}{z + 3} \frac{z^2 + iz - 1}{(z - 2)(z  +3)} = \frac{\frac 1 5 (z^2 + iz - 1)}{z - 2} + \frac{-\frac 1 5 (z^2 + iz - 1)}{z + 3} \frac{1}{z - 2} = \frac{1}{z}\frac{1}{1 - \frac 2 z} = \sum_{n = 0}^\infty \frac{2^n}{z^{n + 1}} \frac{1}{z + 3} = \frac{1}{3(\frac z 3 + 1)} = \frac 1 3 \frac{1}{1 - ( - \frac z 3)} = \sum_{n = 0}^\infty (-1)^n \frac{z^n}{3^{n + 1}} \frac{z^2 + iz - 1}{(z - 2)(z + 3)} = \sum_{n = 0}^\infty \frac{z^2 + iz - 1}{5}[\frac{2^n}{z^{n + 1}} - \frac{(-1)^nz^n}{3^{n + 1}}],"['sequences-and-series', 'complex-analysis']"
40,Wandering domains of $z + \sin(2\pi z)$,Wandering domains of,z + \sin(2\pi z),"I was recently working through Sullivan's Non-Wandering Theorem when I came across this counter-example to the theorem holding for functions $\mathbb{C} \to \mathbb{C}$ . It appears that the entire function $f(z) = z + \sin(2\pi z)$ is something of a standard example of a transcendental function that exhibits wandering domains. However, I cannot seem to be able to show that this is indeed the case, even after reading through a number of Baker's papers on the subject. My problem is that I cannot seem to be able to determine explicitly what these Fatou components actually are. In other examples, a strategy would be to find (super)attracting fixed points and hence use their immediate basin of attraction as the required Fatou components. Then, one would employ the periodicity of $\sin$ to show that these Fatou components are wandering. This strategy would appear not to work in this case, since every fixed point of $f$ is repelling and hence contained in the Julia set. So the only chance that this could work is to find a (super)attracting periodic orbit of period $\geq 2$ , which is a bit of an issue seeing how unwieldy the iterates of $f$ can be. Another strategy that I have tried is to work with covering spaces. Using the universal covering map $\mathbb{C} \to \mathbb{C} \setminus \{0\}$ , $z \mapsto e^{2\pi i z}$ , I get a commuting diagram $$\require{AMScd} \begin{CD} \mathbb{C} @>{f}>> \mathbb{C}\\ @VVV @VVV \\ \mathbb{C} \setminus \{0\} @>{g}>> \mathbb{C} \setminus \{0\} \end{CD}$$ where $g(z) = z\exp(\pi(z - 1/z))$ . I would then apply the same strategy as described above to $g$ , but this gets just as unwieldy as working with $f$ . Now at my wits end, could I get some help on this problem?","I was recently working through Sullivan's Non-Wandering Theorem when I came across this counter-example to the theorem holding for functions . It appears that the entire function is something of a standard example of a transcendental function that exhibits wandering domains. However, I cannot seem to be able to show that this is indeed the case, even after reading through a number of Baker's papers on the subject. My problem is that I cannot seem to be able to determine explicitly what these Fatou components actually are. In other examples, a strategy would be to find (super)attracting fixed points and hence use their immediate basin of attraction as the required Fatou components. Then, one would employ the periodicity of to show that these Fatou components are wandering. This strategy would appear not to work in this case, since every fixed point of is repelling and hence contained in the Julia set. So the only chance that this could work is to find a (super)attracting periodic orbit of period , which is a bit of an issue seeing how unwieldy the iterates of can be. Another strategy that I have tried is to work with covering spaces. Using the universal covering map , , I get a commuting diagram where . I would then apply the same strategy as described above to , but this gets just as unwieldy as working with . Now at my wits end, could I get some help on this problem?","\mathbb{C} \to \mathbb{C} f(z) = z + \sin(2\pi z) \sin f \geq 2 f \mathbb{C} \to \mathbb{C} \setminus \{0\} z \mapsto e^{2\pi i z} \require{AMScd}
\begin{CD}
\mathbb{C} @>{f}>> \mathbb{C}\\
@VVV @VVV \\
\mathbb{C} \setminus \{0\} @>{g}>> \mathbb{C} \setminus \{0\}
\end{CD} g(z) = z\exp(\pi(z - 1/z)) g f","['complex-analysis', 'complex-dynamics']"
41,Deducing closed form of series,Deducing closed form of series,,"In a past exam question we prove that the following function is well-defined and holomorphic on $\mathbb{C}$ \ $\mathbb{Z}$ , and then we are asked to find the closed form. Let $$ f(z)=\sum_{n=-\infty}^{\infty}\frac{1}{(z+n)^2}. $$ The mark scheme says: We have that $f$ is periodic as $f(z) = f(z+2) \forall z$ . See that $f(z)$ has double poles at every integer with residue $(-1)^k$ . $(*)$ Note that $f(z) = −g'(z)$ , where $g(z)$ has single poles with residue $(−1)^k$ at each integer. Then by periodicity it follows that $g(z) = \frac{\pi}{sin(\pi z)}$ and we obtain $f$ by differentiating. I honestly have no idea why this argument is right. I can see why $f$ is periodic and its residues are as given but everything from $(*)$ is not resonating. Any help in understanding this would be great! Thanks","In a past exam question we prove that the following function is well-defined and holomorphic on \ , and then we are asked to find the closed form. Let The mark scheme says: We have that is periodic as . See that has double poles at every integer with residue . Note that , where has single poles with residue at each integer. Then by periodicity it follows that and we obtain by differentiating. I honestly have no idea why this argument is right. I can see why is periodic and its residues are as given but everything from is not resonating. Any help in understanding this would be great! Thanks","\mathbb{C} \mathbb{Z} 
f(z)=\sum_{n=-\infty}^{\infty}\frac{1}{(z+n)^2}.
 f f(z) = f(z+2) \forall z f(z) (-1)^k (*) f(z) = −g'(z) g(z) (−1)^k g(z) = \frac{\pi}{sin(\pi z)} f f (*)",['complex-analysis']
42,Evaluating integrals of the form $\int_{-\infty}^{\infty}R(x)\sin(x)dx$,Evaluating integrals of the form,\int_{-\infty}^{\infty}R(x)\sin(x)dx,"I was reading a complex analysis textbook written by Joseph Bak and Donald Newman. And I was on the part of evaluating integrals of the form $\int_{-\infty}^{\infty}R(x)\sin(x)dx$ where $R(x)=P(x)/Q(x)$ is an integrable rational function, specifically $degQ>deg P$ . I have a few questions regarding some arguments on it (I will write down some arguments below, and there is a list of questions that I have in the very end of the post). The argument goes as follows: Consider the contour shown below: And let the radius of this semicircle be $M$ , and denote by $\Gamma_M$ the circular boundary of this contour. And let $C_M$ denote the entire contour. Consider the integral $$\int_{C_M}R(z)e^{iz}dz.$$ We want to show that $$ \int_{\Gamma_M}R(z)e^{iz}dz\to 0 $$ as $M\to 0$ . Fix a constant $h$ and let $A=\{z\in\Gamma_M:\operatorname{Im}(z)\geq h\}$ and $B=\{z\in\Gamma_M:\operatorname{Im}(z)< h\}$ . We can do $\int_A$ and show it goes to zero by taking $h=\sqrt{M}$ , which I understand, but when we do $\int_B$ , it says $$ \left|\int_B R(z)e^{iz}dz\right|\leq \frac{K}{M}4h. $$ Here we assume $|R(z)|\leq K/|z|$ for large enough $z$ . But how did we get the bound $\left|\int_B e^{iz}dz\right|\leq 4h$ ? If we can show this then again by taking $h=\sqrt{M}$ we get $\int_B\to 0$ as $M\to \infty$ . Sorry, this is kind of a mess. A full proof is in Bak and Newman's complex analysis, pg 145-147 in the third edition. So my questions are: How did we get $\left|\int_B R(z)e^{iz}dz\right|\leq \frac{K}{M}4h$ when doing an integral along $B$ ? This is kinda stupid, but how can we show that if $R(z)=P(z)/Q(z)$ where $deg P<deg Q$ , then we have $|R(z)|\leq K/|z|$ for some constant $K$ ? I assume this happens when $z$ is large though. I am new to residue theorem and using it to evaluate integrals. I tried finding similar posts on the forum but I didn't find much. Thank comment will be helpful! Thank you so much!","I was reading a complex analysis textbook written by Joseph Bak and Donald Newman. And I was on the part of evaluating integrals of the form where is an integrable rational function, specifically . I have a few questions regarding some arguments on it (I will write down some arguments below, and there is a list of questions that I have in the very end of the post). The argument goes as follows: Consider the contour shown below: And let the radius of this semicircle be , and denote by the circular boundary of this contour. And let denote the entire contour. Consider the integral We want to show that as . Fix a constant and let and . We can do and show it goes to zero by taking , which I understand, but when we do , it says Here we assume for large enough . But how did we get the bound ? If we can show this then again by taking we get as . Sorry, this is kind of a mess. A full proof is in Bak and Newman's complex analysis, pg 145-147 in the third edition. So my questions are: How did we get when doing an integral along ? This is kinda stupid, but how can we show that if where , then we have for some constant ? I assume this happens when is large though. I am new to residue theorem and using it to evaluate integrals. I tried finding similar posts on the forum but I didn't find much. Thank comment will be helpful! Thank you so much!","\int_{-\infty}^{\infty}R(x)\sin(x)dx R(x)=P(x)/Q(x) degQ>deg P M \Gamma_M C_M \int_{C_M}R(z)e^{iz}dz. 
\int_{\Gamma_M}R(z)e^{iz}dz\to 0
 M\to 0 h A=\{z\in\Gamma_M:\operatorname{Im}(z)\geq h\} B=\{z\in\Gamma_M:\operatorname{Im}(z)< h\} \int_A h=\sqrt{M} \int_B 
\left|\int_B R(z)e^{iz}dz\right|\leq \frac{K}{M}4h.
 |R(z)|\leq K/|z| z \left|\int_B e^{iz}dz\right|\leq 4h h=\sqrt{M} \int_B\to 0 M\to \infty \left|\int_B R(z)e^{iz}dz\right|\leq \frac{K}{M}4h B R(z)=P(z)/Q(z) deg P<deg Q |R(z)|\leq K/|z| K z","['complex-analysis', 'contour-integration', 'complex-integration', 'residue-calculus']"
43,Deducing $\int_0^{\pi}\log \sin x dx =-\pi\log 2$ from $\int_0^{\pi}\log (-2ie^{ix}\sin x) dx = 0$,Deducing  from,\int_0^{\pi}\log \sin x dx =-\pi\log 2 \int_0^{\pi}\log (-2ie^{ix}\sin x) dx = 0,"On Ahlfors Complex Analysis, chpter 5.3, the author explains how to evaluate $\int_0^{\pi}\log \sin x dx =-\pi\log 2$ . He does so by using Cauchy's formula to deduce that $$\int_0^{\pi}\log (-2ie^{ix}\sin x) dx  = 0.$$ I get why the above is true, thanks to Ahlfors' explanation in the texbook. However, he claims the following: If we choose $\log {e^{ix}}= ix$ the imaginary part lies between $0$ and $\pi $ . Therefore, in order to obtain the principal branch with an imaginary part between $-\pi $ and $\pi $ , we must choose $\log (-i) = -\pi i / 2$ . The equation can now be written in the form $$ \pi \log 2 - (\frac {\pi^2}{2})i + \int_0^\pi\log\sin x dx + (\frac {\pi^2}{2})i = 0.$$ What does the author mean by this? I know that $\log (z_1z_2) = \log z_1 + \log z_2 + 2\pi i n $ for some integer $n$ depending on $z_1$ and $z_2$ , and I imagine that the author is trying to make the $m$ zero where $m $ is the integer satisfying $\log (-2ie^{ix}\sin x) = \log 2 + \log (-i) + \log {e^{ix}} + \log\sin x + 2\pi i m $ but I do not get how exactly he is coming up with a branch of a logarithm.","On Ahlfors Complex Analysis, chpter 5.3, the author explains how to evaluate . He does so by using Cauchy's formula to deduce that I get why the above is true, thanks to Ahlfors' explanation in the texbook. However, he claims the following: If we choose the imaginary part lies between and . Therefore, in order to obtain the principal branch with an imaginary part between and , we must choose . The equation can now be written in the form What does the author mean by this? I know that for some integer depending on and , and I imagine that the author is trying to make the zero where is the integer satisfying but I do not get how exactly he is coming up with a branch of a logarithm.",\int_0^{\pi}\log \sin x dx =-\pi\log 2 \int_0^{\pi}\log (-2ie^{ix}\sin x) dx  = 0. \log {e^{ix}}= ix 0 \pi  -\pi  \pi  \log (-i) = -\pi i / 2  \pi \log 2 - (\frac {\pi^2}{2})i + \int_0^\pi\log\sin x dx + (\frac {\pi^2}{2})i = 0. \log (z_1z_2) = \log z_1 + \log z_2 + 2\pi i n  n z_1 z_2 m m  \log (-2ie^{ix}\sin x) = \log 2 + \log (-i) + \log {e^{ix}} + \log\sin x + 2\pi i m ,"['complex-analysis', 'complex-numbers', 'logarithms', 'complex-integration', 'branch-cuts']"
44,Logarithm of complex numbers,Logarithm of complex numbers,,"I am studying complex analysis and in our class we took the following identities: $$\lim_{\epsilon \rightarrow 0^+}\log(-x + i\epsilon)= \log(x) + i\pi$$ $$\lim_{\epsilon \rightarrow 0^+}\log(-x - i\epsilon)= \log(x) - i\pi$$ where $x>0$ and the following commentary it is said: An important property of the logarithm was used in the complex. If one approaches the branching section along the negative real axis from above or below, then the imaginary part of the function value jumps by $2\pi$ . Can someone explain to me these identities and this comment that was said?","I am studying complex analysis and in our class we took the following identities: where and the following commentary it is said: An important property of the logarithm was used in the complex. If one approaches the branching section along the negative real axis from above or below, then the imaginary part of the function value jumps by . Can someone explain to me these identities and this comment that was said?",\lim_{\epsilon \rightarrow 0^+}\log(-x + i\epsilon)= \log(x) + i\pi \lim_{\epsilon \rightarrow 0^+}\log(-x - i\epsilon)= \log(x) - i\pi x>0 2\pi,['complex-analysis']
45,"$f$ is entire, prove that $\{f_n = f(nz) | n \in \mathbb{N}\}$ is normal on the annulus iff $f$ is constant","is entire, prove that  is normal on the annulus iff  is constant",f \{f_n = f(nz) | n \in \mathbb{N}\} f,"I am studying for my exam and came across this question: Suppose $f$ is entire and $r<R$ . Prove that the family $\mathcal{F} = \{f_n = f(nz) | n \in \mathbb{N}\}$ for $z \in \mathbb{C}$ is normal on the annulus $r< |z|<R$ iff $f$ is constant. This is my attempt: $\Leftarrow$ If $f$ is constant, then $f(z) = z_0, \, \forall z \in \mathbb{C}$ . Then since $f_n = f$ for all $n \in \mathbb{N}$ . Thus $\mathcal{F} = \{f\}$ , and therefore every sequence of $\mathcal{F}$ is the sequence of function $f$ , and therefore wil converge uniformly on every compact subset, and thus is a normal family. Or I could also use Montels theorem and see that since $f_n(z) = f(z) = z_0$ for all $n \in \mathbb{N}$ and all $z \in \mathbb{C}$ , we know that $\mathcal{F}$ is uniformly bounded by $z_0$ and therefore it is a normal family. $\Rightarrow$ We know that $f$ is entire, therefore we only need to prove that it is bounded (and then can use Louiville's theorem to conclude that it is constant). Let $D_k(0)$ be a disk, then since it is compact we know that there exists a $B_k$ such that $|f_n(z)| \leq B_k$ for all $z \in \mathbb{C}, n \in \mathbb{N}$ . I want to use the following theorem: Corollary 4.6 Stein and Shakarchi: Suppose that $\Omega$ is a region with compact closure $\overline{\Omega}$ . If $f$ is holomorphic on $\Omega$ and continuous on $\overline{\Omega}$ then $$sup_{z\in\Omega}|f(z)| \leq sup_{z \in \delta \Omega} |f(z)|.$$ But I am not sure how to since I don't know if on $D_R(0)$ it holds that $\mathcal{F}$ is uniformly bounded on $D_R$ since I am only given it is normal on $r<|z|<R$ . Can someone tell me if my attempts are correct and how I should go further in my second attempt?","I am studying for my exam and came across this question: Suppose is entire and . Prove that the family for is normal on the annulus iff is constant. This is my attempt: If is constant, then . Then since for all . Thus , and therefore every sequence of is the sequence of function , and therefore wil converge uniformly on every compact subset, and thus is a normal family. Or I could also use Montels theorem and see that since for all and all , we know that is uniformly bounded by and therefore it is a normal family. We know that is entire, therefore we only need to prove that it is bounded (and then can use Louiville's theorem to conclude that it is constant). Let be a disk, then since it is compact we know that there exists a such that for all . I want to use the following theorem: Corollary 4.6 Stein and Shakarchi: Suppose that is a region with compact closure . If is holomorphic on and continuous on then But I am not sure how to since I don't know if on it holds that is uniformly bounded on since I am only given it is normal on . Can someone tell me if my attempts are correct and how I should go further in my second attempt?","f r<R \mathcal{F} = \{f_n = f(nz) | n \in \mathbb{N}\} z \in \mathbb{C} r< |z|<R f \Leftarrow f f(z) = z_0, \, \forall z \in \mathbb{C} f_n = f n \in \mathbb{N} \mathcal{F} = \{f\} \mathcal{F} f f_n(z) = f(z) = z_0 n \in \mathbb{N} z \in \mathbb{C} \mathcal{F} z_0 \Rightarrow f D_k(0) B_k |f_n(z)| \leq B_k z \in \mathbb{C}, n \in \mathbb{N} \Omega \overline{\Omega} f \Omega \overline{\Omega} sup_{z\in\Omega}|f(z)| \leq sup_{z \in \delta \Omega} |f(z)|. D_R(0) \mathcal{F} D_R r<|z|<R","['complex-analysis', 'entire-functions']"
46,Calculating complex integral for different values of $n$.,Calculating complex integral for different values of .,n,"I don't know how to compute the following integral. I think it might be possible to use the Residue Theorem to compute it, but the $\sin\theta$ inside the cosine function is throwing me off. $$I_{n}=\int_{0}^{2 \pi} d \theta e^{-\cos (\theta)} \cos (n \theta+\sin(\theta))$$ I am not very sure how to manipulate the integrand so that it becomes somewhat easier. Maybe something like this could work because we could split the integral in several smaller integrals, but the fact that there are still nested trig functions bothers me because I do not know how to deal with them: $$\cos(n\theta + sin(\theta)) = \cos (\sin (\theta)) \cos (\theta n)-\sin (\sin (\theta)) \sin (\theta n)$$ (Where $n \in \mathbb{Z}$ ). I need to give the result for all $n$ . Any help would be very appreciated. Update . I simplified the integrand a little. From the last expression, one can see that $\int_0^{2\pi}\sin(\sin\theta) = 0$ because the function $\sin(\sin\theta)$ is periodic in $\theta$ with period $2\pi$ and for both $\theta = 0$ and $\theta = 2\pi$ it equals zero. Therefore the integrand can be reduced to: $$I_n = \int_0^{2\pi} e^{-\cos\theta}\cos(n\theta)\cos(\sin\theta)$$ Which still seems kinda difficult to compute.","I don't know how to compute the following integral. I think it might be possible to use the Residue Theorem to compute it, but the inside the cosine function is throwing me off. I am not very sure how to manipulate the integrand so that it becomes somewhat easier. Maybe something like this could work because we could split the integral in several smaller integrals, but the fact that there are still nested trig functions bothers me because I do not know how to deal with them: (Where ). I need to give the result for all . Any help would be very appreciated. Update . I simplified the integrand a little. From the last expression, one can see that because the function is periodic in with period and for both and it equals zero. Therefore the integrand can be reduced to: Which still seems kinda difficult to compute.",\sin\theta I_{n}=\int_{0}^{2 \pi} d \theta e^{-\cos (\theta)} \cos (n \theta+\sin(\theta)) \cos(n\theta + sin(\theta)) = \cos (\sin (\theta)) \cos (\theta n)-\sin (\sin (\theta)) \sin (\theta n) n \in \mathbb{Z} n \int_0^{2\pi}\sin(\sin\theta) = 0 \sin(\sin\theta) \theta 2\pi \theta = 0 \theta = 2\pi I_n = \int_0^{2\pi} e^{-\cos\theta}\cos(n\theta)\cos(\sin\theta),['complex-analysis']
47,If $f$ is an entire function of order $\lambda$ then $f'$ also has order $\lambda$,If  is an entire function of order  then  also has order,f \lambda f' \lambda,"If $f$ is an entire function of order $\lambda$ then $f'$ also has order $\lambda$ Can someone show me how to prove this or point me in the right direction? My definition is an entire function $f$ has finite order $\lambda$ if for $\epsilon>0$ we have $|f(z)| < $ exp $(|z|^{\lambda + \epsilon})$ for all $|z|$ sufficiently large. I also have that $\lambda = $ inf $\{ a : |f(z)| < $ exp $(|z|^{a}) $ for $|z|$ sufficiently large}, though I'm not sure if that will be useful here. I had to show the order of the sum of two functions is less than or equal to the max of the order of each function in an earlier problem, but I'm not sure how to go about this for $f'$ . Thanks for any help.","If is an entire function of order then also has order Can someone show me how to prove this or point me in the right direction? My definition is an entire function has finite order if for we have exp for all sufficiently large. I also have that inf exp for sufficiently large}, though I'm not sure if that will be useful here. I had to show the order of the sum of two functions is less than or equal to the max of the order of each function in an earlier problem, but I'm not sure how to go about this for . Thanks for any help.",f \lambda f' \lambda f \lambda \epsilon>0 |f(z)| <  (|z|^{\lambda + \epsilon}) |z| \lambda =  \{ a : |f(z)| <  (|z|^{a})  |z| f',['complex-analysis']
48,Integral of inverse Laplace transform,Integral of inverse Laplace transform,,"Let $f$ be some integrable function defined on $[0,\infty)$ which is not analytically tractable, and $\hat{f}$ is its Laplace transform which can be expressed in some analytic form, something like $\hat{f}(s)=1-\frac{1}{1+e^{-s}}$ . Now I want to get some approximation of the improper integral $\int_0^T f(t)\, dt$ with some large $T$ by using the Laplace transform $\hat{f}$ (because $\hat{f}$ is analytically tractable, it is easier to handle with it). Then the Bromwich integral gives \begin{align*} \int_0^T f(t)\, dt &= \int_0^T \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{iyt} \hat{f}(iy)\, dy\, dt   &\text{(by Bromwich)}\\ &= \int_{-\infty}^{\infty} \frac{1}{2\pi} \underbrace{\int_0^T e^{iyt}\,dt}_{=(e^{iyT}-1)/(iy)} \hat{f}(iy)\,dy &\text{(by Fubini)} \\ &= \underbrace{\frac{1}{2\pi}\int_{-\infty}^{\infty} \frac{e^{iyT}\hat{f}(iy)}{iy}\,dy}_{(I)} - \underbrace{\frac{1}{2\pi} \int_{-\infty}^{\infty} \frac{\hat{f}(iy)}{iy}\, dy}_{(II)}. \end{align*} Then my question is the following. Question . $\;$ Since $f$ is integrable, $\int_0^{\infty}f(t)\, dt = \hat{f}(0)$ is well-defined, so that $(I) + (II) \rightarrow \hat{f}(0)$ as $T \rightarrow \infty$ . Then in terms of $\hat{f}(0)$ , what is the limit value of $(I)$ as $T \rightarrow \infty$ ? (Is it $\hat{f}(0)$ or not?) and what is $(II)$ ? For answering this, Here is what I have done . Since the residue of $\hat{f}(z)/z$ at $z=0$ is $\hat{f}(0)$ , I suspect that somehow I must use residue theorem to $(I)$ or $(II)$ with proper contour. Because of Bromwich integral restrict to integrate the right half-plane, $y$ must have nonnegative real part so that the contour of $(I)$ and $(II)$ may pass the right-side of the singularity $z=0$ . Here is the contour image: By the Riemmann-Lebesgue lemma , $\hat{f}(z) \rightarrow 0$ as $|z| \rightarrow \infty$ , so the contour integration of $\hat{f}(z)/z$ with infinite radius arc (the dashed line) is always zero. This means that $(II)$ is zero so that $(I) \rightarrow \hat{f}(0)$ automatically. But if this is the case, I'm not sure how to show that $(I)$ goes to $\hat{f}(0)$ by direct calculation of $(I)$ . Thanks,","Let be some integrable function defined on which is not analytically tractable, and is its Laplace transform which can be expressed in some analytic form, something like . Now I want to get some approximation of the improper integral with some large by using the Laplace transform (because is analytically tractable, it is easier to handle with it). Then the Bromwich integral gives Then my question is the following. Question . Since is integrable, is well-defined, so that as . Then in terms of , what is the limit value of as ? (Is it or not?) and what is ? For answering this, Here is what I have done . Since the residue of at is , I suspect that somehow I must use residue theorem to or with proper contour. Because of Bromwich integral restrict to integrate the right half-plane, must have nonnegative real part so that the contour of and may pass the right-side of the singularity . Here is the contour image: By the Riemmann-Lebesgue lemma , as , so the contour integration of with infinite radius arc (the dashed line) is always zero. This means that is zero so that automatically. But if this is the case, I'm not sure how to show that goes to by direct calculation of . Thanks,","f [0,\infty) \hat{f} \hat{f}(s)=1-\frac{1}{1+e^{-s}} \int_0^T f(t)\, dt T \hat{f} \hat{f} \begin{align*}
\int_0^T f(t)\, dt &= \int_0^T \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{iyt} \hat{f}(iy)\, dy\, dt   &\text{(by Bromwich)}\\
&= \int_{-\infty}^{\infty} \frac{1}{2\pi} \underbrace{\int_0^T e^{iyt}\,dt}_{=(e^{iyT}-1)/(iy)} \hat{f}(iy)\,dy &\text{(by Fubini)} \\
&= \underbrace{\frac{1}{2\pi}\int_{-\infty}^{\infty} \frac{e^{iyT}\hat{f}(iy)}{iy}\,dy}_{(I)} - \underbrace{\frac{1}{2\pi} \int_{-\infty}^{\infty} \frac{\hat{f}(iy)}{iy}\, dy}_{(II)}.
\end{align*} \; f \int_0^{\infty}f(t)\, dt = \hat{f}(0) (I) + (II) \rightarrow \hat{f}(0) T \rightarrow \infty \hat{f}(0) (I) T \rightarrow \infty \hat{f}(0) (II) \hat{f}(z)/z z=0 \hat{f}(0) (I) (II) y (I) (II) z=0 \hat{f}(z) \rightarrow 0 |z| \rightarrow \infty \hat{f}(z)/z (II) (I) \rightarrow \hat{f}(0) (I) \hat{f}(0) (I)","['complex-analysis', 'fourier-analysis', 'laplace-transform', 'contour-integration']"
49,Proving whether a complex function is analytical help!,Proving whether a complex function is analytical help!,,"I am currently struggling to prove whether a complex function is analytical. I understand that I must employ the Cauchy-Riemann relations to do this. However, the answer I get is one that I can't reconcile with what I am told the answer is. This is the function; $f(x+iy) = |x^2 - y^2| + 2i|xy|$ With this, I believe that I need to do Cauchy-Riemann with four different functions, namely, $f(x+iy) = x^2 - y^2 + 2ixy$ $f(x+iy) = y^2 - x^2 - 2ixy$ $f(x+iy) = x^2 - y^2 - 2ixy$ $f(x+iy) = y^2 - x^2 + 2ixy$ Which makes me arrive at; $u_x = 2x = v_y = 2x$ , $u_y = -2y = -v_x = -2y$ $u_x = -2x = v_y = -2x$ , $u_y = 2y = -v_x = 2y$ $u_x = 2x = v_y = -2x$ , $u_y = -2y = -v_x = 2y$ $u_x = -2x = v_y = 2x$ , $u_y = 2y = -v_x = -2y$ respectively. Now, I think the answer is that the function is only analytical at x = 0, as I think that is the way only all of these equations can be solved simultaneously. But the prescribed solution is not this and I can't really see why. Thanks :D","I am currently struggling to prove whether a complex function is analytical. I understand that I must employ the Cauchy-Riemann relations to do this. However, the answer I get is one that I can't reconcile with what I am told the answer is. This is the function; With this, I believe that I need to do Cauchy-Riemann with four different functions, namely, Which makes me arrive at; , , , , respectively. Now, I think the answer is that the function is only analytical at x = 0, as I think that is the way only all of these equations can be solved simultaneously. But the prescribed solution is not this and I can't really see why. Thanks :D",f(x+iy) = |x^2 - y^2| + 2i|xy| f(x+iy) = x^2 - y^2 + 2ixy f(x+iy) = y^2 - x^2 - 2ixy f(x+iy) = x^2 - y^2 - 2ixy f(x+iy) = y^2 - x^2 + 2ixy u_x = 2x = v_y = 2x u_y = -2y = -v_x = -2y u_x = -2x = v_y = -2x u_y = 2y = -v_x = 2y u_x = 2x = v_y = -2x u_y = -2y = -v_x = 2y u_x = -2x = v_y = 2x u_y = 2y = -v_x = -2y,"['complex-analysis', 'derivatives', 'analytic-functions', 'analyticity', 'cauchy-riemann-equations']"
50,Find $\int_0^\infty \frac{dx}{x^{n-1}+x^{n-2}+\cdots +x+1}$ using contour integral,Find  using contour integral,\int_0^\infty \frac{dx}{x^{n-1}+x^{n-2}+\cdots +x+1},"I have solved the problem of integration $$\int_0^\infty \frac{1}{x^n+1}dz$$ using the contour as an arc of a circle. But I don't know how to  approach this problem: $$I=\int_0^\infty\frac{1}{x^{n-1}+x^{n-2}+\cdots +x+1}dz$$ Please Help me with this problem Edit: With the help of geometric series (suggested in comment), I can reduce the integral to the evaluation of $$\int_0^\infty\frac{1-x}{1-x^n}dx$$ Now it's $1-x$ that's causing the problem if I choose the contour to be arc with angle $2\pi /n$ . I still need little help.","I have solved the problem of integration using the contour as an arc of a circle. But I don't know how to  approach this problem: Please Help me with this problem Edit: With the help of geometric series (suggested in comment), I can reduce the integral to the evaluation of Now it's that's causing the problem if I choose the contour to be arc with angle . I still need little help.",\int_0^\infty \frac{1}{x^n+1}dz I=\int_0^\infty\frac{1}{x^{n-1}+x^{n-2}+\cdots +x+1}dz \int_0^\infty\frac{1-x}{1-x^n}dx 1-x 2\pi /n,"['complex-analysis', 'contour-integration']"
51,Holomorphic is much stronger than real differentiable in a neighbourhood. What about analytic?,Holomorphic is much stronger than real differentiable in a neighbourhood. What about analytic?,,"For real of 1 variable: Analytic $\implies$ smooth $\implies$ (real-)holomorphic $\implies$ differentiable (at a point $p$ ). here, real holomorphic at $p$ just means real differentiable in an open neighbourhood of $p$ . For complex of 1 variable: Analytic $\iff$ holomorphic $\implies$ smooth $\implies$ differentiable (at a point $p$ ). Much of elementary complex analysis talks about how (complex-)holomorphic is much stronger in complex as compared to real-holomorphic . What about complex analogues of real properties like analytic: How much stronger is complex analytic compared to real analytic? (I also asked smooth and differentiable .) For starters, maybe this: Analytic on deleted neighbourhood implies analytic on whole? ?","For real of 1 variable: Analytic smooth (real-)holomorphic differentiable (at a point ). here, real holomorphic at just means real differentiable in an open neighbourhood of . For complex of 1 variable: Analytic holomorphic smooth differentiable (at a point ). Much of elementary complex analysis talks about how (complex-)holomorphic is much stronger in complex as compared to real-holomorphic . What about complex analogues of real properties like analytic: How much stronger is complex analytic compared to real analytic? (I also asked smooth and differentiable .) For starters, maybe this: Analytic on deleted neighbourhood implies analytic on whole? ?",\implies \implies \implies p p p \iff \implies \implies p,"['real-analysis', 'complex-analysis', 'derivatives', 'analytic-functions', 'analyticity']"
52,asymptotic for the complex exponential integral Ei(s),asymptotic for the complex exponential integral Ei(s),,"Let $\operatorname{Ei}(s)$ denote the complex exponential integral function, which (if I am correct) can be defined for $s \in \mathbb{C}\backslash(-\infty,0]$ by $$\operatorname{Ei}(s) = \gamma+\log s -\operatorname{Ein}(-s)= \gamma+\log s+\sum_{n = 1}^\infty \frac{s^n}{n!n},$$ where $\operatorname{Ein}(s)$ is the entire function $\sum_{n = 1}^\infty \frac{(-1)^{n+1}s^n}{n!n}$ . Is it true that $$\operatorname{Ei}(s)\sim \frac{e^s}{s} \ (s \to \infty)$$ on $\{s \in \mathbb{C}: |\operatorname{Arg} s|\leq \frac{\pi}{2}-\epsilon\}$ for every $\epsilon > 0$ ?  More generally, for any $\epsilon > 0$ , can one give an asymptotic expansion of $\operatorname{Ei}(s)$ on that set?  Given computations in Mathematica, it seems unlikely that such an asymptotic relation can be extended to the case where $\epsilon = 0$ .  (Mathematica's command for the function is $\tt{ExpIntegralEi[s]}$ .) EDIT: I don't know why, but information on the web about the complex function $\operatorname{Ei}(s)$ is very scarce.  But it's an important function used a lot in analytic number theory, and in particular in the Riemann--von Mangoldt explicit formula for $\pi_0(x)$ , since one has $\operatorname{li}(s) = \operatorname{Ei}(\log s)$ .  Please, somebody, help!","Let denote the complex exponential integral function, which (if I am correct) can be defined for by where is the entire function . Is it true that on for every ?  More generally, for any , can one give an asymptotic expansion of on that set?  Given computations in Mathematica, it seems unlikely that such an asymptotic relation can be extended to the case where .  (Mathematica's command for the function is .) EDIT: I don't know why, but information on the web about the complex function is very scarce.  But it's an important function used a lot in analytic number theory, and in particular in the Riemann--von Mangoldt explicit formula for , since one has .  Please, somebody, help!","\operatorname{Ei}(s) s \in \mathbb{C}\backslash(-\infty,0] \operatorname{Ei}(s) = \gamma+\log s -\operatorname{Ein}(-s)= \gamma+\log s+\sum_{n = 1}^\infty \frac{s^n}{n!n}, \operatorname{Ein}(s) \sum_{n = 1}^\infty \frac{(-1)^{n+1}s^n}{n!n} \operatorname{Ei}(s)\sim \frac{e^s}{s} \ (s \to \infty) \{s \in \mathbb{C}: |\operatorname{Arg} s|\leq \frac{\pi}{2}-\epsilon\} \epsilon > 0 \epsilon > 0 \operatorname{Ei}(s) \epsilon = 0 \tt{ExpIntegralEi[s]} \operatorname{Ei}(s) \pi_0(x) \operatorname{li}(s) = \operatorname{Ei}(\log s)","['complex-analysis', 'special-functions']"
53,first term in the asymptotic expansion using method of steepest descent,first term in the asymptotic expansion using method of steepest descent,,"I am working with the following intgral: $\int_{0}^{\infty}t^{n}e^{-x(t+\frac{1}{t})}dt$ as $x\rightarrow \infty$ Now, I have been trying to solve this using the method of steepest descent. After finding the saddle points I think I have found the steepest descent path to be along the unit circle. However, I am not sure how I should now use that information to now deform the contour to do the asymptotic expansion. Any ideas?","I am working with the following intgral: as Now, I have been trying to solve this using the method of steepest descent. After finding the saddle points I think I have found the steepest descent path to be along the unit circle. However, I am not sure how I should now use that information to now deform the contour to do the asymptotic expansion. Any ideas?",\int_{0}^{\infty}t^{n}e^{-x(t+\frac{1}{t})}dt x\rightarrow \infty,"['complex-analysis', 'asymptotics', 'gradient-descent', 'laplace-method']"
54,Monodromy associated to a meromorphic function,Monodromy associated to a meromorphic function,,"I ask for some hint/help about finding the monodromy homomorphism of a holomorphic map $g: \Bbb{P}^1_{\mathbb{C}}\rightarrow \Bbb{P}^1_{\mathbb{C}}$ locally defined by $$ f(z) = \frac{27z^2(z-1)^2}{4(z^2-z+1)^3} $$ I see that $deg(g) = 6$ and that we have two ramification points $\infty$ and $0$ with three points in the fiber of $0$ , each of multiplicity 2 and two point in the fiber of $\infty$ , each of multiplicity 3. Call this branch locus $B$ and consider $p\notin B$ . Hence, by Riemann Existence theorem, we get a monodromy homomorphism $$ \rho:\pi_{1}(\mathbb{P}^1\smallsetminus B, p)\simeq \Bbb{Z}*\Bbb{Z}*\Bbb{Z}*\Bbb{Z}\rightarrow \mathcal{S}_6 $$ with transitive image. I know that the loop around multiplicity 2 -points should be 2-cycle, and similarly loops around multiplicity 3-points should be mapped to 3-cycle. But how can I determine the exact permutation for each homotopy class generator? Thank you for any help you can provide.","I ask for some hint/help about finding the monodromy homomorphism of a holomorphic map locally defined by I see that and that we have two ramification points and with three points in the fiber of , each of multiplicity 2 and two point in the fiber of , each of multiplicity 3. Call this branch locus and consider . Hence, by Riemann Existence theorem, we get a monodromy homomorphism with transitive image. I know that the loop around multiplicity 2 -points should be 2-cycle, and similarly loops around multiplicity 3-points should be mapped to 3-cycle. But how can I determine the exact permutation for each homotopy class generator? Thank you for any help you can provide.","g: \Bbb{P}^1_{\mathbb{C}}\rightarrow \Bbb{P}^1_{\mathbb{C}} 
f(z) = \frac{27z^2(z-1)^2}{4(z^2-z+1)^3}
 deg(g) = 6 \infty 0 0 \infty B p\notin B 
\rho:\pi_{1}(\mathbb{P}^1\smallsetminus B, p)\simeq \Bbb{Z}*\Bbb{Z}*\Bbb{Z}*\Bbb{Z}\rightarrow \mathcal{S}_6
","['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'riemann-surfaces', 'covering-spaces']"
55,How to calculate the residue of this function quickly (or by mathematica)?,How to calculate the residue of this function quickly (or by mathematica)?,,"While looking at this post (The second answer) , I find that it is to tedious to calculate the  Residue of $$ f(z)=-\left(\frac{z-1}{z+1}\right)^2\frac{2n/z}{z^{2n}-1} $$ at $-1$ . I do know that we can do this: $$\operatorname*{Res}_{z=-1}f(z)=\frac{1}{2!}\frac{d^2}{dz^2}(f(z)\cdot(z+1)^3).$$ But I am not satisfied with this method. I have the following questions: 1 . How many methods do we have to calculate this, can you provide me with an ingenious one? 2 . I tried to calculate this via Mathematica like this:[ ] If I let $n$ take concrete integers, say, $n=5$ , we do get the right answer $-34$ . However, it seems that we cann't get the right answer if we let $n$ be a variable.  What's wrong here, how can we use mathematica to get a general answer (instead of concrete examples by letting n be some integers). I faced with this sort of problems in similar situations. Can you tell me what shoud I do, or just let me know that mathematica cannot do this! Thank you ! Addition As for Sangchul Lee's answer for my second question, I have another quesion. Why does the following code does not work, what's the difference between ""Element[n, Integers]"" and ""Assumptions -> n \in Integers"":","While looking at this post (The second answer) , I find that it is to tedious to calculate the  Residue of at . I do know that we can do this: But I am not satisfied with this method. I have the following questions: 1 . How many methods do we have to calculate this, can you provide me with an ingenious one? 2 . I tried to calculate this via Mathematica like this:[ ] If I let take concrete integers, say, , we do get the right answer . However, it seems that we cann't get the right answer if we let be a variable.  What's wrong here, how can we use mathematica to get a general answer (instead of concrete examples by letting n be some integers). I faced with this sort of problems in similar situations. Can you tell me what shoud I do, or just let me know that mathematica cannot do this! Thank you ! Addition As for Sangchul Lee's answer for my second question, I have another quesion. Why does the following code does not work, what's the difference between ""Element[n, Integers]"" and ""Assumptions -> n \in Integers"":", f(z)=-\left(\frac{z-1}{z+1}\right)^2\frac{2n/z}{z^{2n}-1}  -1 \operatorname*{Res}_{z=-1}f(z)=\frac{1}{2!}\frac{d^2}{dz^2}(f(z)\cdot(z+1)^3). n n=5 -34 n,"['complex-analysis', 'complex-numbers', 'residue-calculus']"
56,Rotation around the diameter in Riemann sphere,Rotation around the diameter in Riemann sphere,,"Consider Riemann sphere And consider the following projection : The plane $\zeta =0 $ here is the complex plane, and consider the following map: Each point (except the north pole) of the sphere, being mapped to $ \left(\xi,\eta,\zeta\right)\to\left(\frac{\xi}{1-\zeta},\frac{\eta}{1-\zeta},0\right) $ And conversly, the point on the sphere that is being mapped to $(x,y,0) $ given by $$ \left(\frac{x}{x^{2}+y^{2}+1},\frac{y}{x^{2}+y^{2}+1},\frac{x^{2}+y^{2}}{x^{2}+y^{2}+1}\right)\to\left(x,y,0\right) $$ Now, I want to show that the function $ \frac{1}{z},z\in\mathbb{C} $ is represented on the sphere by a $ 180^{\circ} $ rotation about the diameter with endpoints $ \left(-\frac{1}{2},0,\frac{1}{2}\right),\left(\frac{1}{2},0,\frac{1}{2}\right) $ What I have done : I proved that given a point $ z $ which is the image of a point $ \left(\xi,\eta,\zeta\right) $ on the sphere, the point which is mapped to $\frac{1}{z} $ on the sphere, is the point $ \left(\xi,-\eta,1-\zeta\right) $ . So all thre's left to do is to prove that given a point on the sphere $ \left(\xi,\eta,\zeta\right) $ , its rotation about the diameter that I mentioned by $180^{\circ} $ is indeed $ \left(\xi,-\eta,1-\zeta\right) $ . I dont know how to express the rotation since its in 3 dimensions and Im not familier with this. So I'd really apreciate any help. Thanks in advance.","Consider Riemann sphere And consider the following projection : The plane here is the complex plane, and consider the following map: Each point (except the north pole) of the sphere, being mapped to And conversly, the point on the sphere that is being mapped to given by Now, I want to show that the function is represented on the sphere by a rotation about the diameter with endpoints What I have done : I proved that given a point which is the image of a point on the sphere, the point which is mapped to on the sphere, is the point . So all thre's left to do is to prove that given a point on the sphere , its rotation about the diameter that I mentioned by is indeed . I dont know how to express the rotation since its in 3 dimensions and Im not familier with this. So I'd really apreciate any help. Thanks in advance.","\zeta =0   \left(\xi,\eta,\zeta\right)\to\left(\frac{\xi}{1-\zeta},\frac{\eta}{1-\zeta},0\right)  (x,y,0)   \left(\frac{x}{x^{2}+y^{2}+1},\frac{y}{x^{2}+y^{2}+1},\frac{x^{2}+y^{2}}{x^{2}+y^{2}+1}\right)\to\left(x,y,0\right)   \frac{1}{z},z\in\mathbb{C}   180^{\circ}   \left(-\frac{1}{2},0,\frac{1}{2}\right),\left(\frac{1}{2},0,\frac{1}{2}\right)   z   \left(\xi,\eta,\zeta\right)  \frac{1}{z}   \left(\xi,-\eta,1-\zeta\right)   \left(\xi,\eta,\zeta\right)  180^{\circ}   \left(\xi,-\eta,1-\zeta\right) ","['complex-analysis', 'stereographic-projections', 'riemann-sphere']"
57,"mapping the circle $|z|=3$ into $|z-1|=1$, the point $3+3i$ into $1$ and the point $3$ into $0$.","mapping the circle  into , the point  into  and the point  into .",|z|=3 |z-1|=1 3+3i 1 3 0,"Question: Find the bilinear transformation which carries the circle $|z|=3$ into $|z-1|=1$ , the point $3+3i$ into $1$ and the point $3$ into $0$ . My Attempt:  First, I've done problems like this before, but I ran into something at the beginning, so I want to first write my proof, then mention what I ran into and hope to have my solution verified and to see if I can get an explanation on why I had that problem and what it means.  So here goes: Let $f(z)=w$ we such a transformation.  We have that $f(3+3i)=1$ and $f(3)=0$ .  Now, we see that, using $z^*=\frac{R^2}{\bar z-\bar a}+a$ , that $3+3i$ is symmetric to $3-3i$ with respect to $|z|=1$ and that $1$ is symmetric to $\infty$ with respect to $|z-1|=1$ .  Thus, we have $f(3-3i)=\infty$ .  So, using the cross ratio, we have $(w,1,0,\infty)=(z,3+3i,3,3-3i)$ , and so we have $\frac{w-0}{w-\infty}\frac{1-\infty}{1-0}=\frac{z-3}{z-(3-3i)}\frac{3+3i-(3-3i)}{3+3i-3}$ .  Going through the calculation, we get that $w=\frac{(z-3)2i}{z-3+3i}$ . So, first, does this solution look correct?  Next, when I was trying to find that ""last point"", I was running into an issue using $f(3)=0$ .  I kept getting $3$ is symmetric to $3$ with respect to $|z|=3$ and $0$ is symmetric to $0$ with respect to $|z-1|=1$ , so I was just getting a transformation value that I already knew.  Why?  Or, should I, of course, have used the point with the nonzero imaginary part?  Any help is greatly apprecaited!  Thank you.","Question: Find the bilinear transformation which carries the circle into , the point into and the point into . My Attempt:  First, I've done problems like this before, but I ran into something at the beginning, so I want to first write my proof, then mention what I ran into and hope to have my solution verified and to see if I can get an explanation on why I had that problem and what it means.  So here goes: Let we such a transformation.  We have that and .  Now, we see that, using , that is symmetric to with respect to and that is symmetric to with respect to .  Thus, we have .  So, using the cross ratio, we have , and so we have .  Going through the calculation, we get that . So, first, does this solution look correct?  Next, when I was trying to find that ""last point"", I was running into an issue using .  I kept getting is symmetric to with respect to and is symmetric to with respect to , so I was just getting a transformation value that I already knew.  Why?  Or, should I, of course, have used the point with the nonzero imaginary part?  Any help is greatly apprecaited!  Thank you.","|z|=3 |z-1|=1 3+3i 1 3 0 f(z)=w f(3+3i)=1 f(3)=0 z^*=\frac{R^2}{\bar z-\bar a}+a 3+3i 3-3i |z|=1 1 \infty |z-1|=1 f(3-3i)=\infty (w,1,0,\infty)=(z,3+3i,3,3-3i) \frac{w-0}{w-\infty}\frac{1-\infty}{1-0}=\frac{z-3}{z-(3-3i)}\frac{3+3i-(3-3i)}{3+3i-3} w=\frac{(z-3)2i}{z-3+3i} f(3)=0 3 3 |z|=3 0 0 |z-1|=1","['complex-analysis', 'linear-transformations', 'cross-ratio']"
58,Using Rouché's theorem to infer the amount of zeroes inside the given domain,Using Rouché's theorem to infer the amount of zeroes inside the given domain,,"Given $p(z)=i z^{5}-8 z^{4}-\pi$ , How many zeros there is for $p(z)$ inside $ D_{1}(0) \cap\{z \mid \operatorname{Im}(z)>0\}$ ? I can use Rouché theorem to infer how many zeros there are in the whole unit disk, but how do I infer the amount of zeros in the given domain?","Given , How many zeros there is for inside ? I can use Rouché theorem to infer how many zeros there are in the whole unit disk, but how do I infer the amount of zeros in the given domain?",p(z)=i z^{5}-8 z^{4}-\pi p(z)  D_{1}(0) \cap\{z \mid \operatorname{Im}(z)>0\},"['complex-analysis', 'rouches-theorem']"
59,Asymptotic behaviour of transformed Schwartz functions,Asymptotic behaviour of transformed Schwartz functions,,"Given two Schwartz functions $f, g$ , I consider the following simultaneous transform of them: $$\Lambda_{f,g}(\lambda) := \int^{\infty}_{-\infty} dx f(x) g(x) e^{i\sinh(x+\lambda)}.$$ Of course, the product of Schwartz functions is still Schwartz so I could consider just a single function here, however I keep it this was for my attempt at the problem. What I would like to show is a Riemann-Lebesgue type property: $$\lim_{\lambda \to \pm \infty} \Lambda_{f,g}(\lambda) = 0.$$ Due to the presence of the $\sinh$ term in the exponential, the usual arguments for proving Riemann-Lebesgue don't seem to be useable here as I cannot seem to find a primitive for $e^{i\sinh(x-\lambda)}$ . My attempt to show this was to apply a hyperbolic trig identity, then split the integral into two using a delta distribution: $$\int^{\infty}_{-\infty} dx f(x) g(x) e^{i\sinh(x+\lambda)} = \int^{\infty}_{-\infty}\int^{\infty}_{-\infty} dx dy f(x)e^{i\cosh(\lambda)\sinh(x)} g(y) e^{i\sinh(\lambda)\cosh(y)} \delta(x-y)$$ Then I apply a substitution: $$= \int^{\infty}_{-\infty} dx dy \frac{f(x)}{\cosh(x)} \cosh(x)e^{i\cosh(\lambda)\sinh(x)} \frac{g(y)}{\sinh(y)}\sinh(y) e^{i\sinh(\lambda)\cosh(y)} \delta(x-y) \\= 2\int^{\infty}_{-\infty}\int^{\infty}_{0}dx dy\frac{f(x)}{\cosh(\sinh^{-1}(x))}e^{i\cosh(\lambda)x} \frac{g(y)}{\sinh(\cosh^{-1}(y))}e^{i\sinh(\lambda)y} \delta(\cosh^{-1}(x) -\sinh^{-1}(y))$$ Now the ""altered"" test functions $\frac{f(x)}{\cosh(\sinh^{-1}(x))}$ and $\frac{g(y)}{\sinh(\cosh^{-1}(y))}$ are still Schwartz as the denominator contributions are only polynomial. From here, I was hoping to apply a Riemann-Lebesgue type argument to the integral over x to show the final integrals vanishes asymptotically in $\lambda$ , but I'm not convinced due to the presence of the delta distribution. Does this argument work? Any other possible directions of investigation to show this, other than what I have attempted, is also welcome.","Given two Schwartz functions , I consider the following simultaneous transform of them: Of course, the product of Schwartz functions is still Schwartz so I could consider just a single function here, however I keep it this was for my attempt at the problem. What I would like to show is a Riemann-Lebesgue type property: Due to the presence of the term in the exponential, the usual arguments for proving Riemann-Lebesgue don't seem to be useable here as I cannot seem to find a primitive for . My attempt to show this was to apply a hyperbolic trig identity, then split the integral into two using a delta distribution: Then I apply a substitution: Now the ""altered"" test functions and are still Schwartz as the denominator contributions are only polynomial. From here, I was hoping to apply a Riemann-Lebesgue type argument to the integral over x to show the final integrals vanishes asymptotically in , but I'm not convinced due to the presence of the delta distribution. Does this argument work? Any other possible directions of investigation to show this, other than what I have attempted, is also welcome.","f, g \Lambda_{f,g}(\lambda) := \int^{\infty}_{-\infty} dx f(x) g(x) e^{i\sinh(x+\lambda)}. \lim_{\lambda \to \pm \infty} \Lambda_{f,g}(\lambda) = 0. \sinh e^{i\sinh(x-\lambda)} \int^{\infty}_{-\infty} dx f(x) g(x) e^{i\sinh(x+\lambda)} = \int^{\infty}_{-\infty}\int^{\infty}_{-\infty} dx dy f(x)e^{i\cosh(\lambda)\sinh(x)} g(y) e^{i\sinh(\lambda)\cosh(y)} \delta(x-y) = \int^{\infty}_{-\infty} dx dy \frac{f(x)}{\cosh(x)} \cosh(x)e^{i\cosh(\lambda)\sinh(x)} \frac{g(y)}{\sinh(y)}\sinh(y) e^{i\sinh(\lambda)\cosh(y)} \delta(x-y) \\= 2\int^{\infty}_{-\infty}\int^{\infty}_{0}dx dy\frac{f(x)}{\cosh(\sinh^{-1}(x))}e^{i\cosh(\lambda)x} \frac{g(y)}{\sinh(\cosh^{-1}(y))}e^{i\sinh(\lambda)y} \delta(\cosh^{-1}(x) -\sinh^{-1}(y)) \frac{f(x)}{\cosh(\sinh^{-1}(x))} \frac{g(y)}{\sinh(\cosh^{-1}(y))} \lambda","['complex-analysis', 'analysis', 'fourier-analysis']"
60,complex curve integral interpretation and calculation: $F(z) = \dfrac{z^2}{z^k}$,complex curve integral interpretation and calculation:,F(z) = \dfrac{z^2}{z^k},"The task asks me to calculate the curve integral of that function $F(z)$ over the curve $\gamma(t) = \{z \in\mathbb{C}: \:\vert z\vert=1\}$ . Apparently this is a circle in the complex plane. Before I proceed to my pure calculation process I actually wonder what that calculation will mean. If I were to look closer at $F(z)$ I should notice how it maps a function from 2 Dimensions to 4 Dimensions (each plugged in complex number is matched with another complex number, both depending on 2 variables). Now how does this plot touch the curve $\gamma$ ? Is this similar to ordinary curve integrals, where all Function values of the plot along the curve are added together? Anyway, here my calculations, that I came up with just by intuition: $$\begin{align} &\text{parametrisation of $\gamma(t)$ by}\: e^{i\,t}\,\quad t\in[0,2\,\pi] \\\\ &\text{ into the usual definitionn of curve integral:}\\\\ &\int_C F(z)\,\mathrm{dz} = \int_0^{2\,\pi} F(\gamma(t))\,\gamma'(t)\,\mathrm{dt} = \\\\ & \int_0^{2\,\pi}e^{i\,t\,(2-k)}\,i\,e^{i\,t}\,\mathrm{dt} = \left[\dfrac{1\,i}{i\,(3-k)}\,e^{i\,t(3-k)}\right]_0^{2\,\pi} = \\\\ &\dfrac{1}{(3-k)}\,\left[\cos\bigr((3-k)\,2\,\pi\bigl)+i\sin\bigr((3-k)\,2\,\pi\bigl)-1\right] = \\\\ &\dfrac{1}{3-k}\left(1-1\right) = 0 \quad \text{is this the answer?} \end{align}$$ Edit: coming back to this I still need help for $k = 3$ , that peculiar case. I thought it'd be easy to show the integrals also equals $0$ , instead: $\displaystyle{\int_{0}^{2\,\pi}e^{i\,t(3-3)}\,i\,\mathrm{dt} = \left[i\,t\right]_0^{2\,\pi}} = 2\,\pi\,i$ ? Also having access to the Residue Theorem now it seems to agree: $\displaystyle{\int_{C}F(z)}=\displaystyle{\int_{C}\dfrac{z^2}{z^k}} = (\text{Res$(0)$} + \cdots +  \text{Res$(0)$})\,2\,\pi\,i$ for each k from $1 \cdots n$ hence $\displaystyle{\int_{C}F(z) = (\lim_{z \to 0}\dfrac{z^2}{z^1}\,z^1 + \lim_{z \to 0}\dfrac{d}{dz}\dfrac{z^2}{z^2}\,z^2\,\dfrac{1}{1!}+ \lim_{z \to 0}\dfrac{d^2}{dz^2}\dfrac{z^2}{z^3}\,z^3\,\dfrac{1}{2!}+\cdots)\,2\,\pi\,i} $ Here likewise for $k = 3$ the integral seems to become non zero: $\int_C F(z) =2\,\pi\,i$ . The rest vanishes. It just happens to disagree with taking the limit of the very first expression: $$\displaystyle{\lim_{k\to 3}\dfrac{1}{3-k}\left(1-1\right) = 0 ?}$$","The task asks me to calculate the curve integral of that function over the curve . Apparently this is a circle in the complex plane. Before I proceed to my pure calculation process I actually wonder what that calculation will mean. If I were to look closer at I should notice how it maps a function from 2 Dimensions to 4 Dimensions (each plugged in complex number is matched with another complex number, both depending on 2 variables). Now how does this plot touch the curve ? Is this similar to ordinary curve integrals, where all Function values of the plot along the curve are added together? Anyway, here my calculations, that I came up with just by intuition: Edit: coming back to this I still need help for , that peculiar case. I thought it'd be easy to show the integrals also equals , instead: ? Also having access to the Residue Theorem now it seems to agree: for each k from hence Here likewise for the integral seems to become non zero: . The rest vanishes. It just happens to disagree with taking the limit of the very first expression:","F(z) \gamma(t) = \{z \in\mathbb{C}: \:\vert z\vert=1\} F(z) \gamma \begin{align}
&\text{parametrisation of \gamma(t) by}\: e^{i\,t}\,\quad t\in[0,2\,\pi] \\\\
&\text{ into the usual definitionn of curve integral:}\\\\
&\int_C F(z)\,\mathrm{dz} = \int_0^{2\,\pi} F(\gamma(t))\,\gamma'(t)\,\mathrm{dt} = \\\\
& \int_0^{2\,\pi}e^{i\,t\,(2-k)}\,i\,e^{i\,t}\,\mathrm{dt} = \left[\dfrac{1\,i}{i\,(3-k)}\,e^{i\,t(3-k)}\right]_0^{2\,\pi} = \\\\
&\dfrac{1}{(3-k)}\,\left[\cos\bigr((3-k)\,2\,\pi\bigl)+i\sin\bigr((3-k)\,2\,\pi\bigl)-1\right] = \\\\
&\dfrac{1}{3-k}\left(1-1\right) = 0 \quad \text{is this the answer?}
\end{align} k = 3 0 \displaystyle{\int_{0}^{2\,\pi}e^{i\,t(3-3)}\,i\,\mathrm{dt} = \left[i\,t\right]_0^{2\,\pi}} = 2\,\pi\,i \displaystyle{\int_{C}F(z)}=\displaystyle{\int_{C}\dfrac{z^2}{z^k}} = (\text{Res(0)} + \cdots +  \text{Res(0)})\,2\,\pi\,i 1 \cdots n \displaystyle{\int_{C}F(z) = (\lim_{z \to 0}\dfrac{z^2}{z^1}\,z^1 + \lim_{z \to 0}\dfrac{d}{dz}\dfrac{z^2}{z^2}\,z^2\,\dfrac{1}{1!}+ \lim_{z \to 0}\dfrac{d^2}{dz^2}\dfrac{z^2}{z^3}\,z^3\,\dfrac{1}{2!}+\cdots)\,2\,\pi\,i}  k = 3 \int_C F(z) =2\,\pi\,i \displaystyle{\lim_{k\to 3}\dfrac{1}{3-k}\left(1-1\right) = 0 ?}","['complex-analysis', 'vector-analysis']"
61,Calculating $Df$ for $f(z)=\frac{z^3}{\overline{z}}$,Calculating  for,Df f(z)=\frac{z^3}{\overline{z}},"Please verify my attempted solution. How would one calculate ${D}{f}$ for ${f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}}$ ? I am aware that $\overline{{{z}}}$ is a nowhere analytic function. If we loosen the problem to ask for ${D}{f}$ instead of ${f}'{\left({z}\right)}$ , we need only find a ${D}{f{{\left({h}\right)}}}$ s.t. the following holds. $${f{{\left({a}+{h}\right)}}}={f{{\left({a}\right)}}}+{D}{f{{\left({h}\right)}}}+{\left|{h}\right|}{\epsilon}{\left({h}\right)}$$ In the above, $\lim_{{{h}\to{0}}}{\epsilon}{\left({h}\right)}={0}$ and $h$ lies in a neighborhood of sufficiently small modulus on the complex plane. $${f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}}=\frac{{{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}}}$$ Writing ${z}={x}+{i}{y}$ and using the fact that ${\mathbb{{{R}}}}^{{{2}}}$ is isomorphic to ${\mathbb{{{C}}}}$ , we may define ${D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left({a}\right)}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left({a}\right)}{\left.{d}{y}\right.}$ . $$\frac{{\partial{f}}}{{\partial{x}}}=\frac{{{3}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}\right)}^{{2}}-{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}-{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ $$\frac{{\partial{f}}}{{\partial{y}}}=\frac{{{3}{i}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}^{{2}}\right)}+{i}{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{i}{\left|{z}\right|}^{{2}}{z}+{i}{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ $${D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left.{d}{y}\right.}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left({\left.{d}{x}\right.}+{i}{\left.{d}{y}\right.}\right)}+{z}^{{3}}{\left({i}{\left.{d}{y}\right.}-{\left.{d}{x}\right.}\right)}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left.{d}{z}\right.}-{z}^{{3}}{d}\overline{{{z}}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}$$ I find my solution to be inelegant and doubt that it is correct. Although I can't take the true complex derivative, would my reasoning be the most appropriate appeal to MVC? Furthermore, if I were to try and determine when ${D}{f}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)}$ , would checking the holomorphicity of ${D}{f}$ suffice? I had read that a linear transform ${L}={P}{\left.{d}{x}\right.}+{Q}{\left.{d}{y}\right.}$ satisfies ${L}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)}\Leftrightarrow{Q}={i}{P}$ , which is truly just the Cauchy-Riemann equations. The primary reason that I believe I am mistaken is the fact that my definition for ${D}{f}$ does not appear to be holomorphic on ${\mathbb{{{C}}}}$ or ${\mathbb{{{C}}}}^{{\cdot}}={\mathbb{{{C}}}}\setminus{\left\lbrace{0}\right\rbrace}$ .","Please verify my attempted solution. How would one calculate for ? I am aware that is a nowhere analytic function. If we loosen the problem to ask for instead of , we need only find a s.t. the following holds. In the above, and lies in a neighborhood of sufficiently small modulus on the complex plane. Writing and using the fact that is isomorphic to , we may define . I find my solution to be inelegant and doubt that it is correct. Although I can't take the true complex derivative, would my reasoning be the most appropriate appeal to MVC? Furthermore, if I were to try and determine when , would checking the holomorphicity of suffice? I had read that a linear transform satisfies , which is truly just the Cauchy-Riemann equations. The primary reason that I believe I am mistaken is the fact that my definition for does not appear to be holomorphic on or .",{D}{f} {f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}} \overline{{{z}}} {D}{f} {f}'{\left({z}\right)} {D}{f{{\left({h}\right)}}} {f{{\left({a}+{h}\right)}}}={f{{\left({a}\right)}}}+{D}{f{{\left({h}\right)}}}+{\left|{h}\right|}{\epsilon}{\left({h}\right)} \lim_{{{h}\to{0}}}{\epsilon}{\left({h}\right)}={0} h {f{{\left({z}\right)}}}=\frac{{{z}^{{3}}}}{{\overline{{{z}}}}}=\frac{{{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}}} {z}={x}+{i}{y} {\mathbb{{{R}}}}^{{{2}}} {\mathbb{{{C}}}} {D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left({a}\right)}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left({a}\right)}{\left.{d}{y}\right.} \frac{{\partial{f}}}{{\partial{x}}}=\frac{{{3}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}\right)}^{{2}}-{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}-{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}} \frac{{\partial{f}}}{{\partial{y}}}=\frac{{{3}{i}{\left({x}-{i}{y}\right)}{\left({x}+{i}{y}^{{2}}\right)}+{i}{\left({x}+{i}{y}\right)}^{{3}}}}{{{\left({x}-{i}{y}\right)}^{{2}}}}=\frac{{{3}{i}{\left|{z}\right|}^{{2}}{z}+{i}{z}^{{3}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}} {D}{f}=\frac{{\partial{f}}}{{\partial{x}}}{\left.{d}{x}\right.}+\frac{{\partial{f}}}{{\partial{y}}}{\left.{d}{y}\right.}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left({\left.{d}{x}\right.}+{i}{\left.{d}{y}\right.}\right)}+{z}^{{3}}{\left({i}{\left.{d}{y}\right.}-{\left.{d}{x}\right.}\right)}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}}=\frac{{{3}{\left|{z}\right|}^{{2}}{z}{\left.{d}{z}\right.}-{z}^{{3}}{d}\overline{{{z}}}}}{{{\left(\overline{{{z}}}\right)}^{{2}}}} {D}{f}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)} {D}{f} {L}={P}{\left.{d}{x}\right.}+{Q}{\left.{d}{y}\right.} {L}\in\mathscr{L}_{{{\mathbb{{{C}}}}}}{\left({\mathbb{{{C}}}}\right)}\Leftrightarrow{Q}={i}{P} {D}{f} {\mathbb{{{C}}}} {\mathbb{{{C}}}}^{{\cdot}}={\mathbb{{{C}}}}\setminus{\left\lbrace{0}\right\rbrace},"['complex-analysis', 'partial-derivative']"
62,"Disproving the statement ""If $f(z)$ is not an entire function, then $g(z) = f^2(z)$ is not entire.”","Disproving the statement ""If  is not an entire function, then  is not entire.”",f(z) g(z) = f^2(z),"If $f(z)$ is not an entire function, then $g(z) = (f(z))^2$ cannot be an entire function.” From this statement why would saying ""Let $f(z) = \sqrt z$ , assuming that it is a branch that takes $−1$ to $i$ . Then it is not analytic on the branch cut, but $g(z) = (f(z))^2 = z$ is obviously an entire function."" Not be a proper example to disprove this statement/ be a incorrect counterexample? I understand that for $\sqrt z$ to be a incorrect counterexample means it is not analytic on the branch -1 to I, therefore not entire. However I thought $\sqrt z$ would be analytic throughout the whole branch cut from -1 to i. Since on the complex plane, $\lim_{z \to -1} \sqrt z$ exists as it would approach $i$ in that case, and in the other case $\lim_{z \to i} \sqrt z$ it approaches $\sqrt i$ meaning that at least on that branch cut in the complex plane it is continuous everywhere, therefore the partial derivatives exist everywhere on the branch cut meaning it is analytic, but this assumption seems to be incorrect. What am I missing or not understanding here. Precisely, I don't understand why $\sqrt z$ would not be a proper counterexample to the statement.","If is not an entire function, then cannot be an entire function.” From this statement why would saying ""Let , assuming that it is a branch that takes to . Then it is not analytic on the branch cut, but is obviously an entire function."" Not be a proper example to disprove this statement/ be a incorrect counterexample? I understand that for to be a incorrect counterexample means it is not analytic on the branch -1 to I, therefore not entire. However I thought would be analytic throughout the whole branch cut from -1 to i. Since on the complex plane, exists as it would approach in that case, and in the other case it approaches meaning that at least on that branch cut in the complex plane it is continuous everywhere, therefore the partial derivatives exist everywhere on the branch cut meaning it is analytic, but this assumption seems to be incorrect. What am I missing or not understanding here. Precisely, I don't understand why would not be a proper counterexample to the statement.",f(z) g(z) = (f(z))^2 f(z) = \sqrt z −1 i g(z) = (f(z))^2 = z \sqrt z \sqrt z \lim_{z \to -1} \sqrt z i \lim_{z \to i} \sqrt z \sqrt i \sqrt z,"['complex-analysis', 'analytic-functions', 'entire-functions']"
63,Proof of $\int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4}$,Proof of,\int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4},"If I want to prove that \begin{equation*} \int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4} \end{equation*} First method: It is possible to approach it by the method in which we consider a closed curve, then: Let gamma be one eighth of a circle ( $\theta\in[0,\pi/4]$ ), then \begin{eqnarray*}             0 = \int_{\gamma} e^{iz^{2}} dz              & = &   \int_{\gamma_{1}} e^{iz^{2}} dz +                      \int_{\gamma_{2}} e^{iz^{2}} dz +                      \int_{\gamma_{3}} e^{iz^{2}} dz \\             & = &   \int_{0}^{R} e^{iz^{2}(r)} dz(r) +                      \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) +                      \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\             & = &   \int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx +                      \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) +                      \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\         \end{eqnarray*} Then \begin{equation*}             -\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + \int_{R}^{0} e^{iz^{2}(r)} dz(r)         \end{equation*} where \begin{eqnarray*}             \int_{R}^{0}\exp\left(iz^{2}(r)\right)dz(r)              & = & \int_{R}^{0}\exp\left(i(re^{i\pi/4})^{2}\right)e^{i\pi/4}dr \\             & = & \int_{R}^{0}\exp\left(ir^{2}e^{i\pi/2}\right) \cdot e^{i\pi/4}dr \\             & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}e^{i\pi/2}\right)dr \\             & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}[\cos(\pi/2)+i\sin(\pi/2)]\right)dr \\             & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(-r^{2}\right)dr \\         \end{eqnarray*} and we know that \begin{eqnarray*}             \lim_{R\to\infty} \int_{0}^{R}\exp\left(-r^{2}\right)dr = \frac{\sqrt{\pi}}{2}         \end{eqnarray*} Then \begin{equation*}             \begin{split}                 &                 \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz  = -\left( \frac{\sqrt{2}}{2} + i\frac{\sqrt{2}}{2} \right) \frac{\sqrt{\pi}}{2}\\                 \Rightarrow                 &                 \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz = -\frac{\sqrt{2\pi}}{4}-i\frac{\sqrt{2\pi}}{4}             \end{split}         \end{equation*} And I wish that $\left|\int_{\gamma_{2}} e^{iz^{2}}dz\right|=|\int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta)|\to 0$ when $R\to\infty$ . How can I argue this in detail? since using this I would have to \begin{equation*}             \lim_{R\to\infty}\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \frac{\sqrt{2\pi}}{4} + i\frac{\sqrt{2\pi}}{4}         \end{equation*} then \begin{equation*}         \int_{0}^{\infty}\sin(x^{2})dx = \int_{0}^{\infty}\cos(x^{2})dx = \frac{\sqrt{2\pi}}{4}     \end{equation*} that concludes the desired. Second method: On the other hand, Also study the possibility of doing this problem using power series. We know that \begin{equation*}  \sin(z) = \sum_{i=0}^{\infty}\frac{(-1)^{n}z^{2n+1}}{(2n+1)!}  \Rightarrow \sin(z^{2}) = \sum_{i=0}^{\infty}\frac{(-1)^{n}(z^{2})^{2n+1}}{(2n+1)!} \end{equation*} Then \begin{eqnarray*}         \int_{0}^{r}\sin(x^{2})dx          & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}(x^{2})^{2n+1}}{(2n+1)!} dx\\         & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}x^{4n+2}}{(2n+1)!} dx\\         & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\int_{0}^{r} x^{4n+2} dx\\         & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\left. \cdot\frac{x^{4n+3}}{4n+3} \right|_{0}^{r}\\         & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!} \cdot \frac{r^{4n+3}}{4n+3} \\     \end{eqnarray*} But I do not know how to reduce or work with this expression, if someone could help me I would be very grateful. PD: If there is another method, perhaps by Fourier analysis it is also welcome, although my main interest is to exercise with the theory of the complex variable.","If I want to prove that First method: It is possible to approach it by the method in which we consider a closed curve, then: Let gamma be one eighth of a circle ( ), then Then where and we know that Then And I wish that when . How can I argue this in detail? since using this I would have to then that concludes the desired. Second method: On the other hand, Also study the possibility of doing this problem using power series. We know that Then But I do not know how to reduce or work with this expression, if someone could help me I would be very grateful. PD: If there is another method, perhaps by Fourier analysis it is also welcome, although my main interest is to exercise with the theory of the complex variable.","\begin{equation*}
\int_{0}^{\infty}\sin(x^2)dx=\int_{0}^{\infty}\cos(x^2)dx=\frac{\sqrt{2\pi}}{4}
\end{equation*} \theta\in[0,\pi/4] \begin{eqnarray*}
            0 = \int_{\gamma} e^{iz^{2}} dz 
            & = &   \int_{\gamma_{1}} e^{iz^{2}} dz + 
                    \int_{\gamma_{2}} e^{iz^{2}} dz + 
                    \int_{\gamma_{3}} e^{iz^{2}} dz \\
            & = &   \int_{0}^{R} e^{iz^{2}(r)} dz(r) + 
                    \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + 
                    \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\
            & = &   \int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx + 
                    \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + 
                    \int_{R}^{0} e^{iz^{2}(r)} dz(r) \\
        \end{eqnarray*} \begin{equation*}
            -\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta) + \int_{R}^{0} e^{iz^{2}(r)} dz(r)
        \end{equation*} \begin{eqnarray*}
            \int_{R}^{0}\exp\left(iz^{2}(r)\right)dz(r) 
            & = & \int_{R}^{0}\exp\left(i(re^{i\pi/4})^{2}\right)e^{i\pi/4}dr \\
            & = & \int_{R}^{0}\exp\left(ir^{2}e^{i\pi/2}\right) \cdot e^{i\pi/4}dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}e^{i\pi/2}\right)dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(ir^{2}[\cos(\pi/2)+i\sin(\pi/2)]\right)dr \\
            & = & -e^{i\pi/4} \int_{0}^{R}\exp\left(-r^{2}\right)dr \\
        \end{eqnarray*} \begin{eqnarray*}
            \lim_{R\to\infty} \int_{0}^{R}\exp\left(-r^{2}\right)dr = \frac{\sqrt{\pi}}{2}
        \end{eqnarray*} \begin{equation*}
            \begin{split}
                &
                \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz  = -\left( \frac{\sqrt{2}}{2} + i\frac{\sqrt{2}}{2} \right) \frac{\sqrt{\pi}}{2}\\
                \Rightarrow
                &
                \lim_{R\to\infty}\int_{R}^{0}\exp\left(iz^{2}\right)dz = -\frac{\sqrt{2\pi}}{4}-i\frac{\sqrt{2\pi}}{4}
            \end{split}
        \end{equation*} \left|\int_{\gamma_{2}} e^{iz^{2}}dz\right|=|\int_{0}^{\pi/4} e^{iz^{2}(\theta)} dz(\theta)|\to 0 R\to\infty \begin{equation*}
            \lim_{R\to\infty}\int_{0}^{R} \cos(x^{2}) + i\sin(x^{2}) dx = \frac{\sqrt{2\pi}}{4} + i\frac{\sqrt{2\pi}}{4}
        \end{equation*} \begin{equation*}
        \int_{0}^{\infty}\sin(x^{2})dx = \int_{0}^{\infty}\cos(x^{2})dx = \frac{\sqrt{2\pi}}{4}
    \end{equation*} \begin{equation*}
 \sin(z) = \sum_{i=0}^{\infty}\frac{(-1)^{n}z^{2n+1}}{(2n+1)!}
 \Rightarrow \sin(z^{2}) = \sum_{i=0}^{\infty}\frac{(-1)^{n}(z^{2})^{2n+1}}{(2n+1)!}
\end{equation*} \begin{eqnarray*}
        \int_{0}^{r}\sin(x^{2})dx 
        & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}(x^{2})^{2n+1}}{(2n+1)!} dx\\
        & = &    \int_{0}^{r} \sum_{n=0}^{\infty}\frac{(-1)^{n}x^{4n+2}}{(2n+1)!} dx\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\int_{0}^{r} x^{4n+2} dx\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!}\left. \cdot\frac{x^{4n+3}}{4n+3} \right|_{0}^{r}\\
        & = &    \sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)!} \cdot \frac{r^{4n+3}}{4n+3} \\
    \end{eqnarray*}","['complex-analysis', 'fourier-analysis', 'fresnel-integrals']"
64,"Can we define $z^{\frac{m}{n}}$, where $z\in\mathbb{C}$ and $m,n\in\mathbb{Z}$?","Can we define , where  and ?","z^{\frac{m}{n}} z\in\mathbb{C} m,n\in\mathbb{Z}","I was thinking that it might has to be $m$ and $n$ coprimes, but I don't have a consolidated idea of how I can prove it. Incidentally, how could I prove that it doesn't work for any integers? (is there any counterexample? I was thinking about $z^{\frac{1}{2}}=\pm z$ ). So, my first question is, Can we define $z^{\frac{m}{n}}$ , where $z\in\mathbb{C}$ and $m,n\in\mathbb{Z}$ ? After that, if the answer is ""no"", can we say something using that fact that i said previously? PS: I need to prove that statement without using exponential definition of complex numbers. So, what I need to use is: Find a $z$ that satisfies $z^n=z_0$ with: $$z=\sqrt[n]{|z_0|}\left(\cos\left(\frac{\theta_0+2k\pi}{n}\right)+i\sin\left(\frac{\theta_0+2k\pi}{n}\right)\right),\text{ for all }k\in\mathbb{Z}.$$","I was thinking that it might has to be and coprimes, but I don't have a consolidated idea of how I can prove it. Incidentally, how could I prove that it doesn't work for any integers? (is there any counterexample? I was thinking about ). So, my first question is, Can we define , where and ? After that, if the answer is ""no"", can we say something using that fact that i said previously? PS: I need to prove that statement without using exponential definition of complex numbers. So, what I need to use is: Find a that satisfies with:","m n z^{\frac{1}{2}}=\pm z z^{\frac{m}{n}} z\in\mathbb{C} m,n\in\mathbb{Z} z z^n=z_0 z=\sqrt[n]{|z_0|}\left(\cos\left(\frac{\theta_0+2k\pi}{n}\right)+i\sin\left(\frac{\theta_0+2k\pi}{n}\right)\right),\text{ for all }k\in\mathbb{Z}.","['complex-analysis', 'complex-numbers']"
65,Possible proof of Cauchy's Integral Formula for derivatives - completion and verification,Possible proof of Cauchy's Integral Formula for derivatives - completion and verification,,"First, let me state Cauchy's Integral formula: Let $U$ be an open region in the complex plane and $D = \{z : |z-z_0| \leq R\}$ a disk in $U$ . If $f : U \to \mathbb C$ is holomorphic and $\gamma$ is the boundary of $D$ , then for all points $a$ inside the disk $$ f(a) = \frac 1{2πi}\oint_\gamma \frac{f(z)}{z-a}\ dz$$ and Cauchy's Integral Formula for the derivatives: $$f^{(n)}(a) = \frac{n!}{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz$$ The majority of books prove the second formula by differentiation of the first formula and then proceeding by induction. However, it seems like Wikipedia wants to suggest a different proof that I couldn't find anywhere else, but they only give hints: Since ${\displaystyle 1/(z-a)}$ can be expanded as a power series in the variable ${\displaystyle a}$ : ${\displaystyle {\frac {1}{z-a}}={\frac {1+{\frac {a}{z}}+\left({\frac {a}{z}}\right)^{2}+\cdots }{z}}}$ — it follows that holomorphic functions are analytic, i.e. they can be expanded as convergent power series. In particular f is actually infinitely differentiable So I took the time to try to understand what they are actually suggesting. What follows is my attempt to turn Wikipedia's hint into a proof, however, it's incomplete because I don't know how to justify the red-marked interchange of integral and series: Let $a$ be a point inside $D$ and $w$ a point in the largest open disk around $a$ contained in $D$ . Then, $|w-a| < |z-a|$ for all $z$ on $\gamma$ , so $\left|\frac{w-a}{z-a}\right|<1$ and then $$\sum_{n=0}^\infty \frac{(w-a)^n}{(z-a)^{n+1}} = \frac{1}{z-a} \frac{1}{1-\frac{w-a}{z-a}} = \frac 1{(z-a)-(w-a)} = \frac 1{z-w} $$ Applying Cauchy's Integral formula: $$\begin{align} f(w) &= \frac 1{2πi}\oint_\gamma \frac{f(z)}{z-w}\ dz \\ &= \frac 1{2πi}\oint_\gamma \sum_{n=0}^\infty f(z)\frac{(w-a)^n}{(z-a)^{n+1}}\ dz \\ &\color{red}{=} \sum_{n=0}^\infty \frac 1{2πi}\oint_\gamma f(z)\frac{(w-a)^n}{(z-a)^{n+1}}\ dz \\ &= \sum_{n=0}^\infty \left(\frac 1{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz\right)(w-a)^n \end{align}$$ but this is a power series in $w$ around $a$ . And we know that power series are infinitely-differentiable in their radius of convergence with $$ f(w) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(w-a)^n $$ therefore $$ f^{(n)}(a) = \frac{n!}{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz $$ Is the red-marked interchange valid? Apart from the interchange, is everything alright?","First, let me state Cauchy's Integral formula: Let be an open region in the complex plane and a disk in . If is holomorphic and is the boundary of , then for all points inside the disk and Cauchy's Integral Formula for the derivatives: The majority of books prove the second formula by differentiation of the first formula and then proceeding by induction. However, it seems like Wikipedia wants to suggest a different proof that I couldn't find anywhere else, but they only give hints: Since can be expanded as a power series in the variable : — it follows that holomorphic functions are analytic, i.e. they can be expanded as convergent power series. In particular f is actually infinitely differentiable So I took the time to try to understand what they are actually suggesting. What follows is my attempt to turn Wikipedia's hint into a proof, however, it's incomplete because I don't know how to justify the red-marked interchange of integral and series: Let be a point inside and a point in the largest open disk around contained in . Then, for all on , so and then Applying Cauchy's Integral formula: but this is a power series in around . And we know that power series are infinitely-differentiable in their radius of convergence with therefore Is the red-marked interchange valid? Apart from the interchange, is everything alright?",U D = \{z : |z-z_0| \leq R\} U f : U \to \mathbb C \gamma D a  f(a) = \frac 1{2πi}\oint_\gamma \frac{f(z)}{z-a}\ dz f^{(n)}(a) = \frac{n!}{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz {\displaystyle 1/(z-a)} {\displaystyle a} {\displaystyle {\frac {1}{z-a}}={\frac {1+{\frac {a}{z}}+\left({\frac {a}{z}}\right)^{2}+\cdots }{z}}} a D w a D |w-a| < |z-a| z \gamma \left|\frac{w-a}{z-a}\right|<1 \sum_{n=0}^\infty \frac{(w-a)^n}{(z-a)^{n+1}} = \frac{1}{z-a} \frac{1}{1-\frac{w-a}{z-a}} = \frac 1{(z-a)-(w-a)} = \frac 1{z-w}  \begin{align} f(w) &= \frac 1{2πi}\oint_\gamma \frac{f(z)}{z-w}\ dz \\ &= \frac 1{2πi}\oint_\gamma \sum_{n=0}^\infty f(z)\frac{(w-a)^n}{(z-a)^{n+1}}\ dz \\ &\color{red}{=} \sum_{n=0}^\infty \frac 1{2πi}\oint_\gamma f(z)\frac{(w-a)^n}{(z-a)^{n+1}}\ dz \\ &= \sum_{n=0}^\infty \left(\frac 1{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz\right)(w-a)^n \end{align} w a  f(w) = \sum_{n=0}^\infty \frac{f^{(n)}(a)}{n!}(w-a)^n   f^{(n)}(a) = \frac{n!}{2πi}\oint_\gamma \frac{f(z)}{(z-a)^{n+1}}\ dz ,"['complex-analysis', 'solution-verification', 'contour-integration', 'cauchy-integral-formula']"
66,When are two paths in $\mathbb{C}$ equivalent?,When are two paths in  equivalent?,\mathbb{C},"In studying complex analysis, I've come across the notion of equivalent paths. Specifically, we say that smooth (by which I mean their derivatives are continuous) paths $\gamma: [a,b] \to \mathbb{C}$ and $\sigma: [c,d] \to \mathbb{C}$ are equivalent if there is an increasing, continuous function $\varphi: [a,b] \to [c,d]$ such that $\gamma = \sigma \circ \varphi$ . I was wondering if there were any necessary and sufficient conditions for two paths being equivalent by this definition. I've proved that if $\gamma: [a,b] \to \mathbb{C}$ and $\sigma: [c,d] \to \mathbb{C}$ are equivalent smooth paths, then $\gamma(a) = \sigma(c)$ , $\gamma(b) = \sigma(d)$ $\{\gamma\} = \{\sigma\}$ , where $\{\gamma\}$ is the trace of $\gamma$ , $\{\gamma\} = \gamma([a,b])$ . $V(\gamma) = V(\sigma)$ , where $V(\gamma)$ is the total variation of $\gamma$ and is defined as \begin{equation*} V(\gamma) = \int_a^b |\gamma'(t)| \; dt. \end{equation*} Intuitively, I think that 1 says that $\gamma$ and $\sigma$ start and end at the same points, 2 says that they trace out the same path in $\mathbb{C}$ , and 3 says that they have the same length. In other words, I've proved that 1, 2, and 3 are necessary conditions for $\gamma$ and $\sigma$ to be equivalent, but are they sufficient? I'm not sure how to define $\varphi$ that ensures it is increasing and continuous, and so that $\gamma = \sigma \circ \varphi$ . My idea so far has been to define it like this: For $t \in [a,b]$ , define $\varphi(t)$ to be the point in $[c,d]$ so that $\gamma(t) = \sigma(\varphi(t))$ . We know that such a point exists given 2, but not that it is unique, so that this definition does not uniquely defined a function $\varphi: [a,b] \to [c,d]$ . In my book (Conway's Function of One Complex Variable), this question really came up for rectifiable paths, but I figured I'd ask this for smooth paths instead, since that, along with piecewise smooth paths, are what I'm more interested in.","In studying complex analysis, I've come across the notion of equivalent paths. Specifically, we say that smooth (by which I mean their derivatives are continuous) paths and are equivalent if there is an increasing, continuous function such that . I was wondering if there were any necessary and sufficient conditions for two paths being equivalent by this definition. I've proved that if and are equivalent smooth paths, then , , where is the trace of , . , where is the total variation of and is defined as Intuitively, I think that 1 says that and start and end at the same points, 2 says that they trace out the same path in , and 3 says that they have the same length. In other words, I've proved that 1, 2, and 3 are necessary conditions for and to be equivalent, but are they sufficient? I'm not sure how to define that ensures it is increasing and continuous, and so that . My idea so far has been to define it like this: For , define to be the point in so that . We know that such a point exists given 2, but not that it is unique, so that this definition does not uniquely defined a function . In my book (Conway's Function of One Complex Variable), this question really came up for rectifiable paths, but I figured I'd ask this for smooth paths instead, since that, along with piecewise smooth paths, are what I'm more interested in.","\gamma: [a,b] \to \mathbb{C} \sigma: [c,d] \to \mathbb{C} \varphi: [a,b] \to [c,d] \gamma = \sigma \circ \varphi \gamma: [a,b] \to \mathbb{C} \sigma: [c,d] \to \mathbb{C} \gamma(a) = \sigma(c) \gamma(b) = \sigma(d) \{\gamma\} = \{\sigma\} \{\gamma\} \gamma \{\gamma\} = \gamma([a,b]) V(\gamma) = V(\sigma) V(\gamma) \gamma \begin{equation*}
V(\gamma) = \int_a^b |\gamma'(t)| \; dt.
\end{equation*} \gamma \sigma \mathbb{C} \gamma \sigma \varphi \gamma = \sigma \circ \varphi t \in [a,b] \varphi(t) [c,d] \gamma(t) = \sigma(\varphi(t)) \varphi: [a,b] \to [c,d]",['complex-analysis']
67,A problem when integrating $\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2}$.,A problem when integrating .,\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2},"The exercise is computing $$\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2},a>1$$ I know that the exercise may be duplicated, but my problem is something strange when I am working with the residue of it. We know the idea of solving this exercise is that we can change the variable and integrate along the unit circle. And I directly use the formula that is obtained by this approach in class. $$ \int_{0}^{2\pi}R(\sin\theta ,\cos\theta)=2\pi\sum_{z_0\in\mathbb{D}}Res_{z_0}\frac{1}{z}R(\frac{z-\bar{z}}{2i},\frac{z+\bar{z}}{2}) $$ with $z=e^{i\theta}$ . Thus, our exercise becomes to compute the residue of $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}.$$ I use two approach to compute the residue, both seems good to me but the result is different. The first method is my naive idea $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{1}{z}\frac{1}{(a+Re(z))^2}$$ Since $z$ is in the unit disc and $a>1$ , $\dfrac{1}{(a+Re(z))^2}\neq0$ , so the only pole is $z=0$ . The second method turns out to be correct. $$\frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{4z}{az+\frac{z^2+1}{2}}=\frac{4z}{(z+a+\sqrt{a^2-1})^2(z+a-\sqrt{a^2-1})^2}$$ Thus, the pole in the unit disc is $z_0=\sqrt{a^2-1}-a$ . It is very very strange for me, please help me if you find it usual or easy to explain.","The exercise is computing I know that the exercise may be duplicated, but my problem is something strange when I am working with the residue of it. We know the idea of solving this exercise is that we can change the variable and integrate along the unit circle. And I directly use the formula that is obtained by this approach in class. with . Thus, our exercise becomes to compute the residue of I use two approach to compute the residue, both seems good to me but the result is different. The first method is my naive idea Since is in the unit disc and , , so the only pole is . The second method turns out to be correct. Thus, the pole in the unit disc is . It is very very strange for me, please help me if you find it usual or easy to explain.","\int_{0}^{2\pi}\frac{d\theta}{(a+\cos \theta)^2},a>1 
\int_{0}^{2\pi}R(\sin\theta ,\cos\theta)=2\pi\sum_{z_0\in\mathbb{D}}Res_{z_0}\frac{1}{z}R(\frac{z-\bar{z}}{2i},\frac{z+\bar{z}}{2})
 z=e^{i\theta} \frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}. \frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{1}{z}\frac{1}{(a+Re(z))^2} z a>1 \dfrac{1}{(a+Re(z))^2}\neq0 z=0 \frac{1}{z}\frac{1}{(a+\frac{z+\bar{z}}{2})^2}=\frac{4z}{az+\frac{z^2+1}{2}}=\frac{4z}{(z+a+\sqrt{a^2-1})^2(z+a-\sqrt{a^2-1})^2} z_0=\sqrt{a^2-1}-a",['complex-analysis']
68,Plot complex function from one plane to another?,Plot complex function from one plane to another?,,"Is there a (free) program or something online that can plot a complex function from one complex plane to another? Like in the picture below? I want to be able to see where numbers go, so to speak, with colors or something.","Is there a (free) program or something online that can plot a complex function from one complex plane to another? Like in the picture below? I want to be able to see where numbers go, so to speak, with colors or something.",,"['complex-analysis', 'complex-numbers', 'online-resources']"
69,Möbius transformation mapping $\mathbb{D}$ into itself.,Möbius transformation mapping  into itself.,\mathbb{D},"I want to show that a Möbius transformation $f(z) = \frac{az + b}{cz + d}$ for $a,b,c,d \in \mathbb{C}$ maps the unit disk $\mathbb{D}$ into itself if and only if the coefficients satisfie \begin{equation*}\label{ineq} |\overline{b}d - \overline{a}c| + |ad - bc| \leq |d|^2 - |c|^2. \end{equation*} So far I have shown that if a Möbius transformation maps $\mathbb{D}$ into itself it satisfies the inequality. Now my idea for the implication $\Leftarrow$ : I consider the inequality above and want to show that for $|z| \leq 1 \implies$ $|f(z)| \leq 1$ . Instead of showing $|f(z)| \leq 1 $ I defined for $|d| > |c|$ \begin{equation*}  v = \frac{b \overline{d} - a\overline{c}}{|d|^2 - |c|^2}, \; R = \frac{|ad - bc|}{|d|^2 - |c|^2} \end{equation*} and want to show $|f(z) - v|^2 \leq R^2$ since by the provided inequality from $|f(z) - v|^2 \leq R^2$ follows $f(z) \in K_R(v) \subseteq \mathbb{D}$ . For the case $|d| = |c|$ , $f$ wouldn't be a möbius transformation. Probelem: Now I have trouble showing the inequality above. I tried using the provided inequality show that \begin{equation*} |f(z) - v|^2 = |f(z)|^2 - 2 \Re(f(z)\overline{v}) + |v|^2 \leq |f(z)|^2 - 2 \Re(f(z)\overline{v}) + 1 - 2R + R^2 \end{equation*} but from then on I stuck by estimating \begin{align*}     |f(z)|^2 &= f(z) \overline{f(z)} = \frac{|a|^2 |z|^2 + 2\Re(az \overline{b}) + |b|^2}{|c|^2 |z|^2 + 2\Re(cz \overline{d}) + |d|^2} \\     |v|^2 &= \frac{b \overline{d} - a\overline{c}}{|d|^2 - |c|^2}\frac{\overline{b} d - \overline{a}c}{|d|^2 - |c|^2} = \frac{|b|^2 |d|^2 - 2 \Re(b \overline{d} \overline{a}c) + |a|^2|c|^2}{(|d|^2 - |c|^2)^2} \\     &2 \Re(f(z)v) = 2 \frac{1}{|d|^2 - |c|^2}\Re  \left( \frac{ab\overline{d}z - a^2 \overline{c}z  - ab\overline{c} + b^2 \overline{d}}{cz + d}\right) \end{align*} or showing that \begin{align*} |f(z)|^2 - 2 \Re(f(z)\overline{v}) + 1 - 2R &\leq 0 \\ \end{align*} I made some estimates based on the fact that $|z| \leq 1$ but most of them lead nowhere. I would appreciate it if someone can give me a hint or can tell that the idea doesn't work.","I want to show that a Möbius transformation for maps the unit disk into itself if and only if the coefficients satisfie So far I have shown that if a Möbius transformation maps into itself it satisfies the inequality. Now my idea for the implication : I consider the inequality above and want to show that for . Instead of showing I defined for and want to show since by the provided inequality from follows . For the case , wouldn't be a möbius transformation. Probelem: Now I have trouble showing the inequality above. I tried using the provided inequality show that but from then on I stuck by estimating or showing that I made some estimates based on the fact that but most of them lead nowhere. I would appreciate it if someone can give me a hint or can tell that the idea doesn't work.","f(z) = \frac{az + b}{cz + d} a,b,c,d \in \mathbb{C} \mathbb{D} \begin{equation*}\label{ineq}
|\overline{b}d - \overline{a}c| + |ad - bc| \leq |d|^2 - |c|^2.
\end{equation*} \mathbb{D} \Leftarrow |z| \leq 1 \implies |f(z)| \leq 1 |f(z)| \leq 1  |d| > |c| \begin{equation*}
 v = \frac{b \overline{d} - a\overline{c}}{|d|^2 - |c|^2}, \; R = \frac{|ad - bc|}{|d|^2 - |c|^2}
\end{equation*} |f(z) - v|^2 \leq R^2 |f(z) - v|^2 \leq R^2 f(z) \in K_R(v) \subseteq \mathbb{D} |d| = |c| f \begin{equation*}
|f(z) - v|^2 = |f(z)|^2 - 2 \Re(f(z)\overline{v}) + |v|^2 \leq |f(z)|^2 - 2 \Re(f(z)\overline{v}) + 1 - 2R + R^2
\end{equation*} \begin{align*}
    |f(z)|^2 &= f(z) \overline{f(z)} = \frac{|a|^2 |z|^2 + 2\Re(az \overline{b}) + |b|^2}{|c|^2 |z|^2 + 2\Re(cz \overline{d}) + |d|^2} \\
    |v|^2 &= \frac{b \overline{d} - a\overline{c}}{|d|^2 - |c|^2}\frac{\overline{b} d - \overline{a}c}{|d|^2 - |c|^2} = \frac{|b|^2 |d|^2 - 2 \Re(b \overline{d} \overline{a}c) + |a|^2|c|^2}{(|d|^2 - |c|^2)^2} \\
    &2 \Re(f(z)v) = 2 \frac{1}{|d|^2 - |c|^2}\Re  \left( \frac{ab\overline{d}z - a^2 \overline{c}z  - ab\overline{c} + b^2 \overline{d}}{cz + d}\right)
\end{align*} \begin{align*}
|f(z)|^2 - 2 \Re(f(z)\overline{v}) + 1 - 2R &\leq 0 \\
\end{align*} |z| \leq 1","['complex-analysis', 'solution-verification', 'mobius-transformation']"
70,Why is the power series of $\tan(x)$ not convergent everywhere $\cos(x)$ is non-zero?,Why is the power series of  not convergent everywhere  is non-zero?,\tan(x) \cos(x),"The Taylor series expansion of $\tan(x)$ centered at $0$ has a radius of convergence of $\pi/2$ , which means the power series will not converge for $|x|>\pi/2$ . How can this be when you consider $\tan(x)=\sin(x)/\cos(x)$ , so Taylor series of $\tan(x)$ is just the Taylor series of $\sin(x)$ divided by the power series of $\cos(x)$ , both of which converge everywhere. At some point $|x|>\pi/2$ where $\cos(x)$ is not equal to $0$ , how can the power series of $\tan(x)$ diverge? It is simply the quotient of two convergent series at that point which seems to me like it shouldn't have any problems.","The Taylor series expansion of centered at has a radius of convergence of , which means the power series will not converge for . How can this be when you consider , so Taylor series of is just the Taylor series of divided by the power series of , both of which converge everywhere. At some point where is not equal to , how can the power series of diverge? It is simply the quotient of two convergent series at that point which seems to me like it shouldn't have any problems.",\tan(x) 0 \pi/2 |x|>\pi/2 \tan(x)=\sin(x)/\cos(x) \tan(x) \sin(x) \cos(x) |x|>\pi/2 \cos(x) 0 \tan(x),"['complex-analysis', 'power-series', 'taylor-expansion']"
71,Laurent series and Weierstrass zeta function,Laurent series and Weierstrass zeta function,,"Let $\zeta(z)$ be the Weierstrass $\zeta $ function of the lattice $\Omega = \mathbb{Z}\omega+\mathbb{Z}\omega' $ (a) Use the definition of $\zeta(z) $ to write the Laurent series for $\zeta$ near $z=0$ and express it in terms of the Eisenstein sums $s_{n}= s_{n}(\omega, \omega')$ (b) Use (a) to write the Laurent series of $\wp(z)$ . I know how to write down the Laurent series for normal complex valued functions, but how does it work for something like the $\zeta(z)$ function? I'm also completely puzzled by how to do part(b).","Let be the Weierstrass function of the lattice (a) Use the definition of to write the Laurent series for near and express it in terms of the Eisenstein sums (b) Use (a) to write the Laurent series of . I know how to write down the Laurent series for normal complex valued functions, but how does it work for something like the function? I'm also completely puzzled by how to do part(b).","\zeta(z) \zeta  \Omega = \mathbb{Z}\omega+\mathbb{Z}\omega'  \zeta(z)  \zeta z=0 s_{n}= s_{n}(\omega, \omega') \wp(z) \zeta(z)","['complex-analysis', 'laurent-series', 'zeta-functions']"
72,Is $f$ holomorphic in $\mathbb C$?,Is  holomorphic in ?,f \mathbb C,"Let $f:\mathbb C\to \mathbb C$ such that functions $z\mapsto \sin (f(z))$ and $z\mapsto \cos (f(z))$ are holomorphic on the entire complex plane. a) Is $f$ also holomorphic in $\mathbb C$ ? b) If we additionally assume that $f$ is continuous, is $f$ holomorphic in $\mathbb C$ ? Logic suggests that in point a) the correct answer is NO, and in b) YES, but I do not know how to prove it.","Let such that functions and are holomorphic on the entire complex plane. a) Is also holomorphic in ? b) If we additionally assume that is continuous, is holomorphic in ? Logic suggests that in point a) the correct answer is NO, and in b) YES, but I do not know how to prove it.",f:\mathbb C\to \mathbb C z\mapsto \sin (f(z)) z\mapsto \cos (f(z)) f \mathbb C f f \mathbb C,['complex-analysis']
73,Find all complex roots of $(z+1+i)^4 - 1 + i =0$.,Find all complex roots of .,(z+1+i)^4 - 1 + i =0,"Find all complex roots of $(z+1+i)^4 - 1 + i =0$ . Attempt: I got \begin{align*} (z+1+i)^4 &= 1 - i \\ (z + \sqrt{2} e^{i(\frac{\pi}{4})})^4 &= \sqrt{2} e^{i(-\frac{\pi}{4})} \\ z + \sqrt{2} e^{i(\frac{\pi}{4})} &= \sqrt[8]{2} \exp\left(i\frac{-\frac{\pi}{4} + 2k\pi}{4}  \right) \\ z &= \sqrt[8]{2} \exp\left(i\frac{-\frac{\pi}{4} + 2k\pi}{4}  \right) - \sqrt{2}e^{i(\frac{\pi}{4})} \end{align*} for $k=0,1,2,3$ . Am I true? If not yet, how to find it?","Find all complex roots of . Attempt: I got for . Am I true? If not yet, how to find it?","(z+1+i)^4 - 1 + i =0 \begin{align*}
(z+1+i)^4 &= 1 - i \\
(z + \sqrt{2} e^{i(\frac{\pi}{4})})^4 &= \sqrt{2} e^{i(-\frac{\pi}{4})} \\
z + \sqrt{2} e^{i(\frac{\pi}{4})} &= \sqrt[8]{2} \exp\left(i\frac{-\frac{\pi}{4} + 2k\pi}{4}  \right) \\
z &= \sqrt[8]{2} \exp\left(i\frac{-\frac{\pi}{4} + 2k\pi}{4}  \right) - \sqrt{2}e^{i(\frac{\pi}{4})}
\end{align*} k=0,1,2,3","['complex-analysis', 'complex-numbers']"
74,Find the number of roots of $z^2 - \cos z=0$ for $|z| < 2$ using Rouche's theorem,Find the number of roots of  for  using Rouche's theorem,z^2 - \cos z=0 |z| < 2,"Find the number of roots for the following equation for $|z| < 2$ , $z\in \Bbb C$ : $$ z^2 - \cos z=0 $$ The reasoning below is based on using Rouche's theorem. So basically I picked two functions $f(z)$ and $\phi(z)$ such that: $$ f(z) = z^2\\ \phi(z) = \cos z $$ Now I need to show that $|f(z)| > |\phi(z)|$ for $|z| = 2$ . My main issue here is proving that statement. Consider $|z^2|$ , clearly the absolute value is $4$ . For $|\cos z|$ and $y\in[-2,2]$ : $$ \begin{align} |\cos z| &= \left|\frac{e^{iz} + e^{-iz}}{2}\right| \\ &= {1\over 2}\left|e^{ix - y} + e^{-ix+y}\right| \\ &\le {1\over 2}\left(\left|e^{ix}\right|\left|e^{-y}\right| + \left|e^{-ix}\right|\left|e^{y}\right|\right)\\ &={1\over 2}\left(e^{-y}+e^y\right) \end{align} $$ Now $|\cos z|$ is symmetric with respect to $x = 0$ so we might consider only one case: $y \in [0;2]$ . Take a look at the following equation: $$ \begin{align} {1\over 2}\left(e^{-y} + e^y\right) &= 4 \\ e^{-y} + e^y &= 8 \ \ | \times e^y \\ e^{2y} - 8e^y + 1 &= 0 \end{align} $$ Solve for $e^y$ : $$ e^y = 4\pm \sqrt{15} $$ Approximate calculations show that: $$ \begin{align} y = \ln(4+\sqrt{15}) &\approx 2,06343... > 2\\ y = \ln(4-\sqrt{15}) &\approx -2,06343... < -2 \end{align} $$ Finally since ${1\over 2}\left(e^{-y}+e^y\right)$ is incresing for $y \in [0,2]$ we have that: $$ |\cos z| = {1\over 2}\left(e^{-y}+e^y\right) < 4, \forall y\in[0,2] $$ This means the equation has two roots (with multiplicities) in $|z| < 2$ . The question here is how do I show $$ \ln(4+\sqrt{15}) > 2\\ \ln(4-\sqrt{15}) < -2 $$ Also, I would appreciate it if someone could show a simpler solution.","Find the number of roots for the following equation for , : The reasoning below is based on using Rouche's theorem. So basically I picked two functions and such that: Now I need to show that for . My main issue here is proving that statement. Consider , clearly the absolute value is . For and : Now is symmetric with respect to so we might consider only one case: . Take a look at the following equation: Solve for : Approximate calculations show that: Finally since is incresing for we have that: This means the equation has two roots (with multiplicities) in . The question here is how do I show Also, I would appreciate it if someone could show a simpler solution.","|z| < 2 z\in \Bbb C 
z^2 - \cos z=0
 f(z) \phi(z) 
f(z) = z^2\\
\phi(z) = \cos z
 |f(z)| > |\phi(z)| |z| = 2 |z^2| 4 |\cos z| y\in[-2,2] 
\begin{align}
|\cos z| &= \left|\frac{e^{iz} + e^{-iz}}{2}\right| \\
&= {1\over 2}\left|e^{ix - y} + e^{-ix+y}\right| \\
&\le {1\over 2}\left(\left|e^{ix}\right|\left|e^{-y}\right| + \left|e^{-ix}\right|\left|e^{y}\right|\right)\\
&={1\over 2}\left(e^{-y}+e^y\right)
\end{align}
 |\cos z| x = 0 y \in [0;2] 
\begin{align}
{1\over 2}\left(e^{-y} + e^y\right) &= 4 \\
e^{-y} + e^y &= 8 \ \ | \times e^y \\
e^{2y} - 8e^y + 1 &= 0
\end{align}
 e^y 
e^y = 4\pm \sqrt{15}
 
\begin{align}
y = \ln(4+\sqrt{15}) &\approx 2,06343... > 2\\
y = \ln(4-\sqrt{15}) &\approx -2,06343... < -2
\end{align}
 {1\over 2}\left(e^{-y}+e^y\right) y \in [0,2] 
|\cos z| = {1\over 2}\left(e^{-y}+e^y\right) < 4, \forall y\in[0,2]
 |z| < 2 
\ln(4+\sqrt{15}) > 2\\
\ln(4-\sqrt{15}) < -2
","['calculus', 'complex-analysis', 'inequality', 'rouches-theorem']"
75,Help integrating the contour integral $\oint_C \frac{e^{\frac{1}{z}}}{z(1-qz)}dz$ around the unit circle,Help integrating the contour integral  around the unit circle,\oint_C \frac{e^{\frac{1}{z}}}{z(1-qz)}dz,"Consider the integral $$\oint_C \frac{e^{\frac{1}{z}}}{z(1-qz)}dz$$ where C is the anti-clockwise oriented unit circle and q is a complex constant. I have no clue how to integrate this. I tried using the residue theorem but it just doesn't come out correctly. Any help would be appreciated. The reason I am stuck is because it seems like there are an infinite amount of poles at z =0, so am very confused","Consider the integral where C is the anti-clockwise oriented unit circle and q is a complex constant. I have no clue how to integrate this. I tried using the residue theorem but it just doesn't come out correctly. Any help would be appreciated. The reason I am stuck is because it seems like there are an infinite amount of poles at z =0, so am very confused",\oint_C \frac{e^{\frac{1}{z}}}{z(1-qz)}dz,"['integration', 'complex-analysis', 'exponential-function', 'contour-integration']"
76,What is $\arg(z)$ if $z=\left(1+i\sqrt3\right)^{2i}$?,What is  if ?,\arg(z) z=\left(1+i\sqrt3\right)^{2i},"$z=(1+i\sqrt{3})^{2i}$ , what is the respective $\arg(z)$ ? How do I calculate the exponent $2i$ ?",", what is the respective ? How do I calculate the exponent ?",z=(1+i\sqrt{3})^{2i} \arg(z) 2i,['complex-analysis']
77,On the asymptotic bound for $\arg\zeta(s)$ on the critical line,On the asymptotic bound for  on the critical line,\arg\zeta(s),"I am currently trying to prove $$ N(T)={T\over2\pi}\log{T\over2\pi}-{T\over2\pi}+\mathcal O(\log T) $$ in which $N(T)$ denotes the number of $\zeta$ 's nontrivial zeros with imaginary part between $(0,T]$ . Currently, using symmetric properties of $\xi(s)$ , I am able to obtain $$ N(T)={T\over2\pi}\log{T\over2\pi}-{T\over2\pi}+\frac78+\frac1\pi\arg\zeta\left(\frac12+iT\right)+\mathcal O\left(\frac1T\right) $$ Apparently, the remaining job is to show that the argument of $\zeta$ on the critical line is of logarithmic growth, and I become stuck on interpreting the meaning of $\arg\zeta$ . According to H. M. Edwards' Riemann's zeta function , this argument is bounded by the number of zeros of $\Re\zeta(s)$ on a certain curve (section 6.7 of his book), and I wonder if anybody could provide a more intuitive and clear explanation on that. Thank you!","I am currently trying to prove in which denotes the number of 's nontrivial zeros with imaginary part between . Currently, using symmetric properties of , I am able to obtain Apparently, the remaining job is to show that the argument of on the critical line is of logarithmic growth, and I become stuck on interpreting the meaning of . According to H. M. Edwards' Riemann's zeta function , this argument is bounded by the number of zeros of on a certain curve (section 6.7 of his book), and I wonder if anybody could provide a more intuitive and clear explanation on that. Thank you!","
N(T)={T\over2\pi}\log{T\over2\pi}-{T\over2\pi}+\mathcal O(\log T)
 N(T) \zeta (0,T] \xi(s) 
N(T)={T\over2\pi}\log{T\over2\pi}-{T\over2\pi}+\frac78+\frac1\pi\arg\zeta\left(\frac12+iT\right)+\mathcal O\left(\frac1T\right)
 \zeta \arg\zeta \Re\zeta(s)","['complex-analysis', 'asymptotics', 'analytic-number-theory', 'riemann-zeta']"
78,find the best possible bound for $|f(1/4)|?$,find the best possible bound for,|f(1/4)|?,"Given $f$ analytic in $|z| < 2,$ bounded there by $2$ , and such that $f(1) = 0,$ find the best possible bound for $|f(1/4)|?$ My attempt : I found the solution here But this solution is  not correct because it contain some mistake Mistake  is $h(z):=\phi(g(\phi^{—1}(z)))$ doesn't satisfy schwarz lemma  since $h(0)\neq0$ My solution : Take $g(z)= \frac{f(2z)}{2}$ and take $\phi(z)= \frac{z-1/2}{1-1/2z}$ then $\phi^{-1}(z)=\frac{z+1/2}{1+1/2z}    $ take $ h(z)= g \circ  \phi^{-1}(z)  = g(\phi^{-1}(z))$ put $z=0 $ , then $ h(0)=                 g(1/2)  $ we have $ g(1/2)= f(1)/2=0  $ Therefor $h(0)=0 $ , and $h$ satisfy the schwarz lemma  i,e $|h(z)|\le |z|$ This implies  that $| g(z)| \le |\phi(z)| $ $g(1/8)  = \frac{1/8-1/2}{1-1/2.(1/8)} =2/5$ $2.g(1/8)=f(1/4)\implies f(1/4)=\frac{4}{5}   $ so the     the best possible bound for $|f(1/4)|$ is $\frac{4}{5}$ Is my solution is correct or not ?","Given analytic in bounded there by , and such that find the best possible bound for My attempt : I found the solution here But this solution is  not correct because it contain some mistake Mistake  is doesn't satisfy schwarz lemma  since My solution : Take and take then take put , then we have Therefor , and satisfy the schwarz lemma  i,e This implies  that so the     the best possible bound for is Is my solution is correct or not ?","f |z| < 2, 2 f(1) = 0, |f(1/4)|? h(z):=\phi(g(\phi^{—1}(z))) h(0)\neq0 g(z)= \frac{f(2z)}{2} \phi(z)= \frac{z-1/2}{1-1/2z} \phi^{-1}(z)=\frac{z+1/2}{1+1/2z}      h(z)= g \circ  \phi^{-1}(z)  = g(\phi^{-1}(z)) z=0   h(0)=                 g(1/2)    g(1/2)= f(1)/2=0   h(0)=0  h |h(z)|\le |z| | g(z)| \le |\phi(z)|  g(1/8)  = \frac{1/8-1/2}{1-1/2.(1/8)} =2/5 2.g(1/8)=f(1/4)\implies f(1/4)=\frac{4}{5}    |f(1/4)| \frac{4}{5}","['complex-analysis', 'solution-verification']"
79,Characterizing isolated singularities of $\frac{z}{e^{z} - z + 1}$,Characterizing isolated singularities of,\frac{z}{e^{z} - z + 1},"I intend to characterize the isolated singularities of $f(z) := \frac{z}{e^z - z + 1}$ which is defined on some open subset $\mathbb{C} \backslash f^{-1}({0}) \subset \mathbb{C}$ . The possible singularities are only the zeros of $g(z) := e^z - z + 1$ , so the approach should be to find those zeros, which is actually the difficult task. At this point, what I know is the following: Since no zeros of $g$ lie on $2\pi i \mathbb{Z}$ , if we suppse that $z_{0} \in \mathbb{C}$ is a zero of $g$ , then we will of course have $\lim\limits_{z \to z_{0}} |f(z)| = \infty$ and so $z_{0}$ will be a pole of $f$ . Using then L'Hôpital's rule applied to $\lim\limits_{z \to z_{0}} (z-z_{0})^n f(z)$ , we check that the pole will have to be of order $1$ . $g$ has zeros, which I found out by separating the function $g(z) = 0$ in two equations, concerning the real and imaginary parts of $g$ and then by ploting the resulting functions to see that they intersect. My question is then: Can we see analytically that $g$ has zeros? This is an exercise from a Reinhold Remmert's book, ""Theory of Complex Functions"" (line c) in exercise 1 on page 309) and I think I'm supposed to solve it analytically. Also, keep in mind that, at this point in the book, there are a lot of tools in complex analysis still not available to use, namely residue calculus and Laurent series. Thank you in advance for all the help!","I intend to characterize the isolated singularities of which is defined on some open subset . The possible singularities are only the zeros of , so the approach should be to find those zeros, which is actually the difficult task. At this point, what I know is the following: Since no zeros of lie on , if we suppse that is a zero of , then we will of course have and so will be a pole of . Using then L'Hôpital's rule applied to , we check that the pole will have to be of order . has zeros, which I found out by separating the function in two equations, concerning the real and imaginary parts of and then by ploting the resulting functions to see that they intersect. My question is then: Can we see analytically that has zeros? This is an exercise from a Reinhold Remmert's book, ""Theory of Complex Functions"" (line c) in exercise 1 on page 309) and I think I'm supposed to solve it analytically. Also, keep in mind that, at this point in the book, there are a lot of tools in complex analysis still not available to use, namely residue calculus and Laurent series. Thank you in advance for all the help!",f(z) := \frac{z}{e^z - z + 1} \mathbb{C} \backslash f^{-1}({0}) \subset \mathbb{C} g(z) := e^z - z + 1 g 2\pi i \mathbb{Z} z_{0} \in \mathbb{C} g \lim\limits_{z \to z_{0}} |f(z)| = \infty z_{0} f \lim\limits_{z \to z_{0}} (z-z_{0})^n f(z) 1 g g(z) = 0 g g,"['complex-analysis', 'singularity']"
80,Can infinitely many points on the boundary $C$ of a domain be singular without $C$ being a natural boundary,Can infinitely many points on the boundary  of a domain be singular without  being a natural boundary,C C,"This question was asked in my complex analysis quiz and I was unable to do it. Can infinitely many points on the boundary $C$ of a domain  be singular without $C$ being a natural boundary ? I thnik it can be as on the boundary there are uncountable many points and if countably finite points are singular then it's not a problem as natural boundary in that case can be extended as there are points that are still regular. But I want it to be checked. So I posted here. Useful definitions: Suppose $f(z)$ is analytic in a domain $D$ . A point $z_1$ is said to be a regular point of $f(z)$ if the function element $(f,D)$ can be analytically continued along some curve from a point in $D$ to the point $z_1$ . Any boundary point of $D$ that is not a regular point of $f(z)$ is said to be a singular point of $f(z)$ .",This question was asked in my complex analysis quiz and I was unable to do it. Can infinitely many points on the boundary of a domain  be singular without being a natural boundary ? I thnik it can be as on the boundary there are uncountable many points and if countably finite points are singular then it's not a problem as natural boundary in that case can be extended as there are points that are still regular. But I want it to be checked. So I posted here. Useful definitions: Suppose is analytic in a domain . A point is said to be a regular point of if the function element can be analytically continued along some curve from a point in to the point . Any boundary point of that is not a regular point of is said to be a singular point of .,"C C f(z) D z_1 f(z) (f,D) D z_1 D f(z) f(z)",['complex-analysis']
81,Proving that this function is entire,Proving that this function is entire,,"This question is from Ponnusamy and silvermann complex analysis Pg 436 . Question : Suppose that $0\leq |a_1|\leq  |a_2| \leq |a_3| \ldots \to \infty$ . Show that $\prod_{n=1}^{\infty} ( 1- z/a_n) e^{Q_n(z) }$ represents an entire function with $Q_n(z) = z/a_n + (z/a_n)^2/2 + \ldots + (z/a_n)^{[\ln n]}/[\ln n]$ . I attempted the question on the same lines as I attempted Show that This infinite product is entire When in last step I have to use Weierstrass Theorem, I got the series ${1/a_n}^{[\ln n]+1}$ . This series is to be proved convergent. But I am unable to prove it. I am uncertain on which result should I use. Please help with it. Rest of details of solutions I checked and They are correct.","This question is from Ponnusamy and silvermann complex analysis Pg 436 . Question : Suppose that . Show that represents an entire function with . I attempted the question on the same lines as I attempted Show that This infinite product is entire When in last step I have to use Weierstrass Theorem, I got the series . This series is to be proved convergent. But I am unable to prove it. I am uncertain on which result should I use. Please help with it. Rest of details of solutions I checked and They are correct.",0\leq |a_1|\leq  |a_2| \leq |a_3| \ldots \to \infty \prod_{n=1}^{\infty} ( 1- z/a_n) e^{Q_n(z) } Q_n(z) = z/a_n + (z/a_n)^2/2 + \ldots + (z/a_n)^{[\ln n]}/[\ln n] {1/a_n}^{[\ln n]+1},['sequences-and-series']
82,Limit of $(1+z)(1+z/2)\cdots(1+z/n)$,Limit of,(1+z)(1+z/2)\cdots(1+z/n),Let $z$ be a complex number such that $\operatorname{Re}(z)<0$ and $$z_n = (1+z)\Bigl(1+\frac{z}{2}\Bigr) \cdots \Bigl( 1+\frac{z}{n} \Bigr).$$ Prove that $ \lim_{n \to \infty} z_n = 0$ . I noticed that: If $| z_n |^2 \to 0$ then $z_n \to 0$ . \begin{align*} \lvert z_n \rvert^2 &= z_n \overline{z_n} \\ &= (1+z)(1+\overline{z}) \cdot \Bigl(1+ \frac{z}{n}\Bigr) \Bigl(1+ \frac{\overline{z}}{n}\Bigr) \\ &= (1 + 2 \operatorname{Re}(z) + \lvert z \rvert^2) \cdots \biggl(1 + \frac{2\operatorname{Re}(z)}{n} + \frac{\lvert z \rvert^2}{n^2}\biggr). \end{align*} For a fixed $z$ there will be such $ n \in \mathbb{N}$ such that for every $m >n$ we have $\frac{2\left|\operatorname{Re}(z)\right|}{m} > \frac{\left|z\right|^2}{m^2}$ . Which means $$ 1 + \frac{2\operatorname{Re}(z)}{m} + \frac{\lvert z \rvert^2}{m^2} < 1.$$ So from one point we will be multiplying by a factor always smaller than $1$ (but closer and closer to $1$ ). Is that a proper approach to the problem? I understand it is not enough to conclude that the limit is $0$ .,Let be a complex number such that and Prove that . I noticed that: If then . For a fixed there will be such such that for every we have . Which means So from one point we will be multiplying by a factor always smaller than (but closer and closer to ). Is that a proper approach to the problem? I understand it is not enough to conclude that the limit is .,"z \operatorname{Re}(z)<0 z_n = (1+z)\Bigl(1+\frac{z}{2}\Bigr) \cdots \Bigl( 1+\frac{z}{n} \Bigr).  \lim_{n \to \infty} z_n = 0 | z_n |^2 \to 0 z_n \to 0 \begin{align*}
\lvert z_n \rvert^2
&= z_n \overline{z_n} \\
&= (1+z)(1+\overline{z}) \cdot \Bigl(1+ \frac{z}{n}\Bigr) \Bigl(1+ \frac{\overline{z}}{n}\Bigr) \\
&= (1 + 2 \operatorname{Re}(z) + \lvert z \rvert^2) \cdots \biggl(1 + \frac{2\operatorname{Re}(z)}{n} + \frac{\lvert z \rvert^2}{n^2}\biggr).
\end{align*} z  n \in \mathbb{N} m >n \frac{2\left|\operatorname{Re}(z)\right|}{m} > \frac{\left|z\right|^2}{m^2}  1 + \frac{2\operatorname{Re}(z)}{m} + \frac{\lvert z \rvert^2}{m^2} < 1. 1 1 0",['complex-analysis']
83,Complex polynomials converging in the compact-uniform topology,Complex polynomials converging in the compact-uniform topology,,"Suppose that $p_n$ are polynomials with degree $n$ , with $p_n(0)=1$ and which converges uniformly on compact sets of $\mathbb{D}$ towards an analytic function $f$ . Now, suppose that the $p_n$ have no roots in a disk of radius strictly greater than 1, say - for simplicity - $D(0,2)$ . Is it true that one can extend the uc convergence to all compacts of the disk $D(0,2)$ ?  Or in any intermediary disk $D(0, r)$ for some $1<r<2$ ? What would be simple assumptions on the $p_n$ to ensure such a behaviour (on the coefficients, the roots, on $f$ ...) ? Answer . As answered above by Sangchul, the answer to the first question is no. He gave a counterexample. Edit: a possible other formulation . By taking the inverses $z \to p_n(z)^{-1}$ , whose radii of convergence are greater than $2$ ,  and using the Hurwitz theorem, the question becomes: we have a sequence of rational functions with no poles in $D(0, 2)$ which takes the value $1$ at zero, and which converges uniformly on compact sets of $D(0, 1)$ towards an analytic function $g=f^{-1}$ . The radius of convergence $R$ of $g$ is greater than or equal to $1$ . Is it possible that $R=1$ ? If not, $R>1$ ; then, does the uniform convergence of $1/p_n$ towards $g$ holds (uniformly on compact sets) for some disk $D(0, s)$ with $1<s<R$ ?","Suppose that are polynomials with degree , with and which converges uniformly on compact sets of towards an analytic function . Now, suppose that the have no roots in a disk of radius strictly greater than 1, say - for simplicity - . Is it true that one can extend the uc convergence to all compacts of the disk ?  Or in any intermediary disk for some ? What would be simple assumptions on the to ensure such a behaviour (on the coefficients, the roots, on ...) ? Answer . As answered above by Sangchul, the answer to the first question is no. He gave a counterexample. Edit: a possible other formulation . By taking the inverses , whose radii of convergence are greater than ,  and using the Hurwitz theorem, the question becomes: we have a sequence of rational functions with no poles in which takes the value at zero, and which converges uniformly on compact sets of towards an analytic function . The radius of convergence of is greater than or equal to . Is it possible that ? If not, ; then, does the uniform convergence of towards holds (uniformly on compact sets) for some disk with ?","p_n n p_n(0)=1 \mathbb{D} f p_n D(0,2) D(0,2) D(0, r) 1<r<2 p_n f z \to p_n(z)^{-1} 2 D(0, 2) 1 D(0, 1) g=f^{-1} R g 1 R=1 R>1 1/p_n g D(0, s) 1<s<R","['complex-analysis', 'polynomials']"
84,Analytic continuation and singularities,Analytic continuation and singularities,,"Suppose that $z\in\mathbb{C}$ and $f$ is a holomorphism on $U$ such that there is no holomorphism $g$ extending $f$ on $V\supseteq U$ such that $z\in V$ . Is it possible for there to be such a $g$ and a holomorphism $h$ on $W$ with $V\cap W\neq\emptyset$ such that $g|_{V\cap W}=h|_{V\cap W}$ with $z\in W$ ? That is, are singularities preserved by analytic continuation?","Suppose that and is a holomorphism on such that there is no holomorphism extending on such that . Is it possible for there to be such a and a holomorphism on with such that with ? That is, are singularities preserved by analytic continuation?",z\in\mathbb{C} f U g f V\supseteq U z\in V g h W V\cap W\neq\emptyset g|_{V\cap W}=h|_{V\cap W} z\in W,"['complex-analysis', 'singularity', 'analytic-continuation']"
85,complex numbers structure of Chern classes,complex numbers structure of Chern classes,,I have started to read on Chern classes. I cannot quite yet see where the complex numbers and their properties come in as we define Chern classes and other properties. I do see it in later theorems and computation. It seems we could have defined projectivization for any vector bundle for example or even Chern classes. Am I missing something? Where and when do complex field properties really come in? I am reading Bott and Tu book differential forms in Algebraic Topology. There the construction is based on line bundles and then projectivization and at least in initial steps I do not see any complex field requirement in definitions or proofs. See pp 267 and 270. https://www.maths.ed.ac.uk/~v1ranick/papers/botttu.pdf,I have started to read on Chern classes. I cannot quite yet see where the complex numbers and their properties come in as we define Chern classes and other properties. I do see it in later theorems and computation. It seems we could have defined projectivization for any vector bundle for example or even Chern classes. Am I missing something? Where and when do complex field properties really come in? I am reading Bott and Tu book differential forms in Algebraic Topology. There the construction is based on line bundles and then projectivization and at least in initial steps I do not see any complex field requirement in definitions or proofs. See pp 267 and 270. https://www.maths.ed.ac.uk/~v1ranick/papers/botttu.pdf,,"['complex-analysis', 'algebraic-geometry', 'algebraic-topology', 'complex-geometry']"
86,How to find the Laurent expansion for $\frac{\exp\left(\frac{1}{z^{2}}\right)}{z-1}$ about $z=0$?,How to find the Laurent expansion for  about ?,\frac{\exp\left(\frac{1}{z^{2}}\right)}{z-1} z=0,"I want to find the Laurent expansion for $\frac{\exp\left(\frac{1}{z^{2}}\right)}{z-1}$ about $z=0$ , I've tried to apply this formula $\frac{1}{1-\omega}=\sum_{n=0}^{\infty }\omega^{n}$ and the usual Taylor series of the exponential function, but I don't know how to continue: $$\begin{align}f(z)&=\frac{1}{z-1}\exp\left(\frac{1}{z^{2}}\right)\\ &=-\frac{1}{1-z}\exp\left(\frac{1}{z^{2}}\right)\\&=-\left (\sum_{n=0}^{\infty }z^{n}  \right )\left ( \sum_{n=0}^{\infty}\frac{1}{n!z^{2n}} \right )\end{align}$$ Thanks in advance. Ps: I tried applying a Cauchy product, but I think this is not appropriate. Edit 1: If it is useful at the end of the text, the authors say that the Laurent expansion is: $\sum_{k=-\infty }^{\infty }a_{k}z^{k}$ with $a_{k}=-e$ if $k\geq 0$ and $a_{k}=-e+1+\frac{1}{1!}+\frac{1}{2!}+...+\frac{1}{(j-1)!}$ if $k=-2$ or $k=-2j+1$ where $j=1,2,...$","I want to find the Laurent expansion for about , I've tried to apply this formula and the usual Taylor series of the exponential function, but I don't know how to continue: Thanks in advance. Ps: I tried applying a Cauchy product, but I think this is not appropriate. Edit 1: If it is useful at the end of the text, the authors say that the Laurent expansion is: with if and if or where","\frac{\exp\left(\frac{1}{z^{2}}\right)}{z-1} z=0 \frac{1}{1-\omega}=\sum_{n=0}^{\infty }\omega^{n} \begin{align}f(z)&=\frac{1}{z-1}\exp\left(\frac{1}{z^{2}}\right)\\
&=-\frac{1}{1-z}\exp\left(\frac{1}{z^{2}}\right)\\&=-\left (\sum_{n=0}^{\infty }z^{n}  \right )\left ( \sum_{n=0}^{\infty}\frac{1}{n!z^{2n}} \right )\end{align} \sum_{k=-\infty }^{\infty }a_{k}z^{k} a_{k}=-e k\geq 0 a_{k}=-e+1+\frac{1}{1!}+\frac{1}{2!}+...+\frac{1}{(j-1)!} k=-2 k=-2j+1 j=1,2,...","['sequences-and-series', 'complex-analysis', 'complex-numbers', 'taylor-expansion', 'laurent-series']"
87,Given f is analytic in D and satisfy |f(z)|->1 as |z|->1 then prove that f is rational,Given f is analytic in D and satisfy |f(z)|->1 as |z|->1 then prove that f is rational,,"Let $f$ be analytic in $D$ and satisfy $|f(z)|\rightarrow 1$ as $|z|\rightarrow 1$ . Prove $f$ is rational. I don't know how to go about this. I don't need Blachke products to verify this. Is there a simpler way? I do know that if we have $\phi$ is one-to-one analytic map of $D$ onto $D$ , where $\phi (z)=\frac{z-a}{1-wz}$ , then would that serve as a rational function that satisfies the conditions? I am not sure how to proceed. Anyone know how to solve it?","Let be analytic in and satisfy as . Prove is rational. I don't know how to go about this. I don't need Blachke products to verify this. Is there a simpler way? I do know that if we have is one-to-one analytic map of onto , where , then would that serve as a rational function that satisfies the conditions? I am not sure how to proceed. Anyone know how to solve it?",f D |f(z)|\rightarrow 1 |z|\rightarrow 1 f \phi D D \phi (z)=\frac{z-a}{1-wz},['complex-analysis']
88,Residue at a non isolated essential singularity,Residue at a non isolated essential singularity,,"For the function cosec (1/z), z=0 is a non isolated essential singularity. Does the concept of ""residue"" extend to the singularity at 0 for the given function cosec (1/z)? If so how do I find the residue at 0 for cosec (1/z)? The function cosec (1/z) does not have a Laurent Series at the non isolated essential singularity 0 because in a deleted neighborhood of 0, the function is not analytic. However the function is analytic in the annulus { $z\in\mathbb C|1<|z|<2$ } in which it has a Laurent expansion. Can this expansion be used to find residue at 0 ? Will the coefficient of 1/z in that expansion give the residue? Or is there any other method of calculating the residue? Or is it true that residue is defined only for isolated singularities? Please clarify.","For the function cosec (1/z), z=0 is a non isolated essential singularity. Does the concept of ""residue"" extend to the singularity at 0 for the given function cosec (1/z)? If so how do I find the residue at 0 for cosec (1/z)? The function cosec (1/z) does not have a Laurent Series at the non isolated essential singularity 0 because in a deleted neighborhood of 0, the function is not analytic. However the function is analytic in the annulus { } in which it has a Laurent expansion. Can this expansion be used to find residue at 0 ? Will the coefficient of 1/z in that expansion give the residue? Or is there any other method of calculating the residue? Or is it true that residue is defined only for isolated singularities? Please clarify.",z\in\mathbb C|1<|z|<2,"['complex-analysis', 'definition']"
89,Derivative of Blaschke product,Derivative of Blaschke product,,"Let $z_n$ be a Blaschke sequence in $\mathbb{D}$ and let $B$ be the Blaschke product defined by $$B(z)=z^m\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz}$$ I'm trying to show the following relationship is true for any $n$ . $$(1-|z_n|^2)|B'(z_n)|=\prod_{m=1,m\neq n}^{\infty}\left|\frac{z_n-z_m}{1-\bar{z}_n z_m}\right|$$ By simply taking the derivative of the product, we have $$B'(z)	=mz^{m-1}\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz}+z^m\prod_{n=1}^{\infty}\frac{|z_{n}|}{z_{n}}\frac{(\bar{z}_{n}z-1)+(z_{n}-z)\bar{z}_{n}}{(1-\bar{z}_{n}z)^{2}}$$ But I'm having trouble seeing how the right hand side of the equation can be derived from here.","Let be a Blaschke sequence in and let be the Blaschke product defined by I'm trying to show the following relationship is true for any . By simply taking the derivative of the product, we have But I'm having trouble seeing how the right hand side of the equation can be derived from here.","z_n \mathbb{D} B B(z)=z^m\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz} n (1-|z_n|^2)|B'(z_n)|=\prod_{m=1,m\neq n}^{\infty}\left|\frac{z_n-z_m}{1-\bar{z}_n z_m}\right| B'(z)	=mz^{m-1}\prod_{n=1}^{\infty}\frac{|z_n|}{z_n}\frac{z_n-z}{1-\bar{z}_nz}+z^m\prod_{n=1}^{\infty}\frac{|z_{n}|}{z_{n}}\frac{(\bar{z}_{n}z-1)+(z_{n}-z)\bar{z}_{n}}{(1-\bar{z}_{n}z)^{2}}","['complex-analysis', 'blaschke-products']"
90,Converse to Hurwitz Theorem,Converse to Hurwitz Theorem,,This is problem 17 from chapter 14 of Papa Rudin. Suppose we have a region $\Omega$ (open connected subset of the plane) and some $f_n$ that are holomorphic on $\Omega$ and converge to $f$ uniformly on compact subsets of $\Omega$ where $f$ is some one-to-one function. Fix $K \subset \Omega$ where $K$ is compact. Is is possible for infinitely many of the $f_n$ to be NOT one-to-one when restricted to $K$ ? Thanks in advance!,This is problem 17 from chapter 14 of Papa Rudin. Suppose we have a region (open connected subset of the plane) and some that are holomorphic on and converge to uniformly on compact subsets of where is some one-to-one function. Fix where is compact. Is is possible for infinitely many of the to be NOT one-to-one when restricted to ? Thanks in advance!,\Omega f_n \Omega f \Omega f K \subset \Omega K f_n K,['complex-analysis']
91,Simply connected domain under analytic function,Simply connected domain under analytic function,,"Let $f$ be analytic and one-to-one that is defined on a simpliy connected domain $D$ , I am struggling with showing that $f(D)$ is simply connected as well, I'll appreciate hints!","Let be analytic and one-to-one that is defined on a simpliy connected domain , I am struggling with showing that is simply connected as well, I'll appreciate hints!",f D f(D),['complex-analysis']
92,Identity coming from contour integration,Identity coming from contour integration,,"Let $p(z) \in \mathbb{C}[z]$ be a monic polynomial of degree $n \ge 2$ , and assume that it has distinct roots $z_1,\dots,z_n$ . If we consider the contour integral $$\frac{1}{2\pi i}\oint_{\left|z\right|=R}\frac{dz}{p(z)}$$ for $R$ large enough so that all roots lie inside $\{\left|z\right|\le R\}$ , then by the Residue Theorem this is equal to $$\sum_{i=1}^n \text{Res}\left(\frac{1}{p(z)},z_i\right)=\sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}\,.$$ On the other hand, as $R \to \infty$ the ML estimate shows that the integral goes to $0$ . Thus we have the identity $$\sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}=0\,.$$ Is there another way of proving this identity (maybe from just algebraic manipulation)?","Let be a monic polynomial of degree , and assume that it has distinct roots . If we consider the contour integral for large enough so that all roots lie inside , then by the Residue Theorem this is equal to On the other hand, as the ML estimate shows that the integral goes to . Thus we have the identity Is there another way of proving this identity (maybe from just algebraic manipulation)?","p(z) \in \mathbb{C}[z] n \ge 2 z_1,\dots,z_n \frac{1}{2\pi i}\oint_{\left|z\right|=R}\frac{dz}{p(z)} R \{\left|z\right|\le R\} \sum_{i=1}^n \text{Res}\left(\frac{1}{p(z)},z_i\right)=\sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}\,. R \to \infty 0 \sum_{i=1}^n \frac{1}{\prod_{j \ne i}(x_i-x_j)}=0\,.","['abstract-algebra', 'combinatorics', 'complex-analysis']"
93,$f$ has a pole order $n$ then there exists a positive constant $C$ such that $C|z|^{-n}\leq |f(z)|$,has a pole order  then there exists a positive constant  such that,f n C C|z|^{-n}\leq |f(z)|,"Question: Suppose $f$ has a pole order $n$ , $n\in \mathbb{Z}_{>0}, $ at $z=0$ then there exists a positive constant $C$ such that $C|z|^{-n}\leq |f(z)|$ on sufficiently small punctured disk about $0$ . This is my solution so far: Since $f$ has a pole order $n$ , $f$ has Laurent expansion in the form on $\sum_{m\geq-n}c_mz^m$ for all $z$ in some punctured disk about $0$ , say on $B(0,\epsilon)- \{0\}.$ Define $g(z):=z^nf(z)$ , then naturally this can be extended into a (continuous) function on $B(0,\epsilon)$ by defining $g(0)=c_{-n}\not=0.$ Now since the absolue function is continuous from $\mathbb{C}\to \mathbb{R}$ and so $|g(z)|$ is continuous on $B(0,\epsilon).$ In particular, $|g(0)|$ = $|c_{-n}|>0.$ Then by choosing $\epsilon=\frac{1}{2}|c_{-n}|,$ we have $\exists\delta>0$ such that $|g(z)|\geq \frac{1}{2}|c_{-n}|$ on $B(0,\delta).$ Then on $B(0,\delta)-\{0\}$ , we have the required inequality by setting $C=\frac{1}{2}|c_{-n}|.$ I was wondering if there are any flaws with my solution, the hint tells me to consider removable singularity but I did not use it much and so I was wondering if there is a slicker way of doing it. Many thanks!","Question: Suppose has a pole order , at then there exists a positive constant such that on sufficiently small punctured disk about . This is my solution so far: Since has a pole order , has Laurent expansion in the form on for all in some punctured disk about , say on Define , then naturally this can be extended into a (continuous) function on by defining Now since the absolue function is continuous from and so is continuous on In particular, = Then by choosing we have such that on Then on , we have the required inequality by setting I was wondering if there are any flaws with my solution, the hint tells me to consider removable singularity but I did not use it much and so I was wondering if there is a slicker way of doing it. Many thanks!","f n n\in \mathbb{Z}_{>0},  z=0 C C|z|^{-n}\leq |f(z)| 0 f n f \sum_{m\geq-n}c_mz^m z 0 B(0,\epsilon)- \{0\}. g(z):=z^nf(z) B(0,\epsilon) g(0)=c_{-n}\not=0. \mathbb{C}\to \mathbb{R} |g(z)| B(0,\epsilon). |g(0)| |c_{-n}|>0. \epsilon=\frac{1}{2}|c_{-n}|, \exists\delta>0 |g(z)|\geq \frac{1}{2}|c_{-n}| B(0,\delta). B(0,\delta)-\{0\} C=\frac{1}{2}|c_{-n}|.","['complex-analysis', 'singularity']"
94,If $f$ is entire can $e^f$ have a pole at infinity?,If  is entire can  have a pole at infinity?,f e^f,"Didn't see any like this in the similar questions, so hopefully it isn't a repeat. There was a question on a past qual that asked if $f$ is entire, can $e^f$ have a pole at infinity. I think the answer is going to be no. But would like confirmation. If possible it would be much appreciate if someone could tell me why my logic is correct or incorrect. Suppose $e^f$ has a pole at infinity. Clearly we cannot have $f$ be constant, hence as a consequence of Louisville's theorem we must have $\infty$ be either a pole or an essential singularity of $f$ . If $\infty$ were essential, then we could find a sequence $z_n\to\infty$ such that $f(z_n)\to c$ for some constant $c$ . Then $e^{f(z_n)}\to e^c$ and so $\lim_{z\to \infty}e^{f(z)}\not=\infty$ and $e^f$ does not have a pole at $\infty$ . The last case we have to consider is were $f$ has a pole at infinity. Let $g(w)=f(1/w)$ . Let $D$ an exterior domain, and define $1/D=\{1/z:z\in D\}$ . Then as $g$ has a pole inside $1/D$ it follows that either $$\int_{\partial 1/D} d\arg(g)\not=0\text{ }(*)$$ or $$\int_{\partial 1/D}d\arg(g)=0\text{ }(**)$$ If $(*)$ then by the argument principle modulo $2\pi$ it follows that $\arg(g)$ takes on every value in $[0,2\pi)$ , in particular we can choose $w\in 1/D$ with $g(w)\in i\mathbb{R}$ . If $(**)$ then as $g$ has a pole in $1/D$ at $0=1/\infty$ it follows that $g$ must have a zero in $1/D$ as $$\int_{\partial1/D}d\arg(g)=\#\{\text{ zeros of }g\text{ in }1/D\}-\#\{\text{ poles of }g\text{ in }1/D\}$$ In this case we have $g(w)=0\in i\mathbb{R}$ for some $w\in 1/D$ . We conclude that regardless of our situation we can choose $w\in 1/D$ with $g(w)\in i\mathbb{R}$ . As a consequence we can choose $z\in D$ with $f(z)\in i\mathbb{R}$ . Well then as $D$ was an arbitrary exterior domain we can choose $z_n\to\infty$ with $f(z)\in i\mathbb{R}$ , so $|e^{f(z_n)}|=1$ , and we cannot have $$\lim_{z\to\infty}e^{f(z)}=\infty$$ Consequently $e^f$ does not have a pole at infinity.","Didn't see any like this in the similar questions, so hopefully it isn't a repeat. There was a question on a past qual that asked if is entire, can have a pole at infinity. I think the answer is going to be no. But would like confirmation. If possible it would be much appreciate if someone could tell me why my logic is correct or incorrect. Suppose has a pole at infinity. Clearly we cannot have be constant, hence as a consequence of Louisville's theorem we must have be either a pole or an essential singularity of . If were essential, then we could find a sequence such that for some constant . Then and so and does not have a pole at . The last case we have to consider is were has a pole at infinity. Let . Let an exterior domain, and define . Then as has a pole inside it follows that either or If then by the argument principle modulo it follows that takes on every value in , in particular we can choose with . If then as has a pole in at it follows that must have a zero in as In this case we have for some . We conclude that regardless of our situation we can choose with . As a consequence we can choose with . Well then as was an arbitrary exterior domain we can choose with , so , and we cannot have Consequently does not have a pole at infinity.","f e^f e^f f \infty f \infty z_n\to\infty f(z_n)\to c c e^{f(z_n)}\to e^c \lim_{z\to \infty}e^{f(z)}\not=\infty e^f \infty f g(w)=f(1/w) D 1/D=\{1/z:z\in D\} g 1/D \int_{\partial 1/D} d\arg(g)\not=0\text{ }(*) \int_{\partial 1/D}d\arg(g)=0\text{ }(**) (*) 2\pi \arg(g) [0,2\pi) w\in 1/D g(w)\in i\mathbb{R} (**) g 1/D 0=1/\infty g 1/D \int_{\partial1/D}d\arg(g)=\#\{\text{ zeros of }g\text{ in }1/D\}-\#\{\text{ poles of }g\text{ in }1/D\} g(w)=0\in i\mathbb{R} w\in 1/D w\in 1/D g(w)\in i\mathbb{R} z\in D f(z)\in i\mathbb{R} D z_n\to\infty f(z)\in i\mathbb{R} |e^{f(z_n)}|=1 \lim_{z\to\infty}e^{f(z)}=\infty e^f","['complex-analysis', 'solution-verification']"
95,"If $\phi\circ f$ and $f$ is analytic, then $\phi$ is analytic.","If  and  is analytic, then  is analytic.",\phi\circ f f \phi,"A question from a past qualifying exam at my university reads: Let $f$ be a nonconstant analytic function on the unit disk $D$ and let $U = f(D)$ . Show that if $\phi$ is a function on $U$ (not necessarily even continuous) and $\phi \circ f$ is analytic on $D$ , then $\phi$ is analytic on $U$ . My approach so far is as follows. Because differentiable functions are continuous, then $\phi\circ f$ is  continuous. One can go on to show that $\phi$ must be continuous on $U$ . I now want to use Morea's theorem to show that $\phi$ is analytic, i.e. show that $\int_{\partial T}\phi(z)dz=0$ for any triangle $T\subset U$ . For $z\in U$ , $\phi(z)=\phi(f(w))$ where $f(w)=z$ . So I want to rewrite the previous integral in terms of $\phi(f(w))$ and apply Cauchy's theorem to conclude the integral vanishes. However, I don't know how to control the preimage of $T$ under $f$ .  Will it even be connected? If I can show that $f^{-1}(T)$ is a domain with peicewise-smooth boundary, then I should be down. How should I proceed?","A question from a past qualifying exam at my university reads: Let be a nonconstant analytic function on the unit disk and let . Show that if is a function on (not necessarily even continuous) and is analytic on , then is analytic on . My approach so far is as follows. Because differentiable functions are continuous, then is  continuous. One can go on to show that must be continuous on . I now want to use Morea's theorem to show that is analytic, i.e. show that for any triangle . For , where . So I want to rewrite the previous integral in terms of and apply Cauchy's theorem to conclude the integral vanishes. However, I don't know how to control the preimage of under .  Will it even be connected? If I can show that is a domain with peicewise-smooth boundary, then I should be down. How should I proceed?",f D U = f(D) \phi U \phi \circ f D \phi U \phi\circ f \phi U \phi \int_{\partial T}\phi(z)dz=0 T\subset U z\in U \phi(z)=\phi(f(w)) f(w)=z \phi(f(w)) T f f^{-1}(T),['complex-analysis']
96,Intuition for why we can apply complex analysis to solving 2D cases in applied science problems,Intuition for why we can apply complex analysis to solving 2D cases in applied science problems,,"In fluid dynamics and elasticity theory (and probably many other theories Im not familiar with) , when we consider a 2D ""flat"" case, we summon complex analysis for help. It usually starts with introducing some potentials, partial derivatives of which are equal to something we are interested in. Even though I've completed a course of complex analysis, to me all of this seems like magic. I don't have any intuition or know any intrinsic reasons for why this helps us solve ""flat"" problems. What should I read up on, or draw my attention to, in order to gain some intuition for why this sort of approach is used, why it is needed, and why it works?","In fluid dynamics and elasticity theory (and probably many other theories Im not familiar with) , when we consider a 2D ""flat"" case, we summon complex analysis for help. It usually starts with introducing some potentials, partial derivatives of which are equal to something we are interested in. Even though I've completed a course of complex analysis, to me all of this seems like magic. I don't have any intuition or know any intrinsic reasons for why this helps us solve ""flat"" problems. What should I read up on, or draw my attention to, in order to gain some intuition for why this sort of approach is used, why it is needed, and why it works?",,"['complex-analysis', 'applications']"
97,Understanding a plot of a complex plane,Understanding a plot of a complex plane,,"I am sorry if this sounds a bit convoluted but here goes. I have written a program that traces a symmetric approximation of a square, my function does not use sine, cosine,or any trigonometric functions, angles or pi... At least not explicitly. It takes two arguments - i,j which are indexes of the center point of the circle, and a variable r denoting the radius. What it does is use complex vector spaces to enable parallelization of the process of tracing the curve directly into the relevant cells that indicate the curve around the i,j center point. The program works very well, tracing a perfect circle(the circle is not centered properly because my matrix had an even number of rows and columns- but the circle itself is perfectly symmetric): But there was something that made me curious and I failed to figure it out, I inserted into the program a part which saves the real distance of every cell on the circumference from the radius(I am approximating a circle with squares here), just out of curiousity to see how the plot looks. when I plotted it, here is what I got ( this is a 1D plot): My questions: Why are there various elliptic curves inside this 1D plot of real valued distances? I calculated the mean of the distances from each point on the curve to the radius, It seemed oddly close to 0.676211.... which is very close to e/4. When I tried plotting with a larger radius, it never got over the value of e/4, and it seemed to be converging on it. why? The point with the maximum distance between it and the radius, was 1.55... which is converging on pi/2 but from above - meaning the value is usually above pi/2, but again - as r grows it also seems to converge on it - although not asymptotically.I guess that makes sense somehow because the radius marks the circumference, but still. why pi/2? Not a question but just a note, the program terminates after exactly 8 r points have been traced. the area of the circle seems to follow the following polynomial equation 2 (r - 1)^2 +2(r - 1) + 1. Just to finish - plots of distances from the radius when the length of the circle radius = 459, and length of the circle radius = 4799 (just random values) if anyone knows any method of understanding what the hell is going here I will be very intrested:","I am sorry if this sounds a bit convoluted but here goes. I have written a program that traces a symmetric approximation of a square, my function does not use sine, cosine,or any trigonometric functions, angles or pi... At least not explicitly. It takes two arguments - i,j which are indexes of the center point of the circle, and a variable r denoting the radius. What it does is use complex vector spaces to enable parallelization of the process of tracing the curve directly into the relevant cells that indicate the curve around the i,j center point. The program works very well, tracing a perfect circle(the circle is not centered properly because my matrix had an even number of rows and columns- but the circle itself is perfectly symmetric): But there was something that made me curious and I failed to figure it out, I inserted into the program a part which saves the real distance of every cell on the circumference from the radius(I am approximating a circle with squares here), just out of curiousity to see how the plot looks. when I plotted it, here is what I got ( this is a 1D plot): My questions: Why are there various elliptic curves inside this 1D plot of real valued distances? I calculated the mean of the distances from each point on the curve to the radius, It seemed oddly close to 0.676211.... which is very close to e/4. When I tried plotting with a larger radius, it never got over the value of e/4, and it seemed to be converging on it. why? The point with the maximum distance between it and the radius, was 1.55... which is converging on pi/2 but from above - meaning the value is usually above pi/2, but again - as r grows it also seems to converge on it - although not asymptotically.I guess that makes sense somehow because the radius marks the circumference, but still. why pi/2? Not a question but just a note, the program terminates after exactly 8 r points have been traced. the area of the circle seems to follow the following polynomial equation 2 (r - 1)^2 +2(r - 1) + 1. Just to finish - plots of distances from the radius when the length of the circle radius = 459, and length of the circle radius = 4799 (just random values) if anyone knows any method of understanding what the hell is going here I will be very intrested:",,"['complex-analysis', 'complex-numbers', 'algorithms', 'analytic-geometry', 'elliptic-curves']"
98,$\int_0^\infty \frac{1}{1+x^4}dx$ using the Residue Theorem,using the Residue Theorem,\int_0^\infty \frac{1}{1+x^4}dx,"I'm trying to evaluate the integral $$\int_0^\infty \frac{1}{1+x^4}dx $$ using the Residue Theorem. My approach: Let's consider $$\oint_\Gamma f$$ with $f(z)=\frac{1}{1+z^4}$ and $\Gamma = \Gamma_1 + \Gamma_2$ , where: $\Gamma_1:[-R,R]\rightarrow \mathbb{C}$ , with $\Gamma_1(t)=t$ $\Gamma_2:[0, \pi] \rightarrow \mathbb{C}$ , with $\Gamma_2(t)=Re^{it}$ So basically $\Gamma$ is the semicircle centers in the origin with imaginary part greater or equal to zero. First we need to find the isolated singularities $\alpha_i$ of the function $f$ . This singularities are the solution of the equation $1 + z^4 = 0$ : Let's call: $\alpha_1 = \frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ $\alpha_2 = -\frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ $\alpha_3 = -\frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2}$ $\alpha_4 = \frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2}$ So now we have: $$\oint_\Gamma f = 2 \pi i \sum_i \text{Res}(f,\alpha_i) \text{Ind}_\Gamma(\alpha_i)$$ All singularities are poles of order one, with: $$\text{Res}(f,\alpha_i)=\frac{1}{1+4\alpha_i^3}$$ So we end up with: $$\oint_\Gamma f = 2 \pi i \sum_i \frac{\text{Ind}_\Gamma(\alpha_i)}{1+4\alpha_i^3} $$ Because of the shape of our curve $\Gamma$ we have that $\text{Ind}_\Gamma(\alpha_3)=\text{Ind}_\Gamma(\alpha_4)=0$ So we end up with: $$\oint_\Gamma f = 2 \pi i \underbrace{\left( \frac{1}{1+4\alpha_1^3} + \frac{1}{1+4\alpha_2^3} \right)}_{:=\xi} $$ Now we can work on the left side of this expression: $$\int_{\Gamma_1} f + \int_{\Gamma_2} f = 2 \pi i \xi$$ We have that: $$\int_{\Gamma_1}f = \int_{-R}^R \frac{1}{1 + t^4} dt$$ And we also know that $$\begin{align} \int_{\Gamma_2}f &\leq \int_0^\pi \left|\frac{Rie^{it}}{1 + R^4e^{4it}} \right| dt \\ \\ &= \int_0^\pi \frac{R}{\left|1 + R^4e^{4it}\right|}  dt \\ \\ &= \int_0^\pi \frac{1}{\left| \frac{1}{R} + R^3e^{4it}\right|}  dt \end{align}$$ If we let $R \to \infty$ we have that $\int_{\Gamma_1} f = \int_{-\infty}^\infty \frac{dt}{1 + t^4}$ and $\int_{\Gamma_2} f = 0$ and because $\int_{-\infty}^\infty \frac{dt}{1 + t^4} = 2 \int_{0}^\infty \frac{dt}{1 + t^4}$ , we end up with: $$\int_{0}^\infty \frac{dt}{1 + t^4} = \pi i \xi$$ The thing is that $\pi i \xi$ is a complex number, so what did I do wrong?","I'm trying to evaluate the integral using the Residue Theorem. My approach: Let's consider with and , where: , with , with So basically is the semicircle centers in the origin with imaginary part greater or equal to zero. First we need to find the isolated singularities of the function . This singularities are the solution of the equation : Let's call: So now we have: All singularities are poles of order one, with: So we end up with: Because of the shape of our curve we have that So we end up with: Now we can work on the left side of this expression: We have that: And we also know that If we let we have that and and because , we end up with: The thing is that is a complex number, so what did I do wrong?","\int_0^\infty \frac{1}{1+x^4}dx  \oint_\Gamma f f(z)=\frac{1}{1+z^4} \Gamma = \Gamma_1 + \Gamma_2 \Gamma_1:[-R,R]\rightarrow \mathbb{C} \Gamma_1(t)=t \Gamma_2:[0, \pi] \rightarrow \mathbb{C} \Gamma_2(t)=Re^{it} \Gamma \alpha_i f 1 + z^4 = 0 \alpha_1 = \frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2} \alpha_2 = -\frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2} \alpha_3 = -\frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2} \alpha_4 = \frac{\sqrt{2}}{2} - i \frac{\sqrt{2}}{2} \oint_\Gamma f = 2 \pi i \sum_i \text{Res}(f,\alpha_i) \text{Ind}_\Gamma(\alpha_i) \text{Res}(f,\alpha_i)=\frac{1}{1+4\alpha_i^3} \oint_\Gamma f = 2 \pi i \sum_i \frac{\text{Ind}_\Gamma(\alpha_i)}{1+4\alpha_i^3}  \Gamma \text{Ind}_\Gamma(\alpha_3)=\text{Ind}_\Gamma(\alpha_4)=0 \oint_\Gamma f = 2 \pi i \underbrace{\left( \frac{1}{1+4\alpha_1^3} + \frac{1}{1+4\alpha_2^3} \right)}_{:=\xi}  \int_{\Gamma_1} f + \int_{\Gamma_2} f = 2 \pi i \xi \int_{\Gamma_1}f = \int_{-R}^R \frac{1}{1 + t^4} dt \begin{align}
\int_{\Gamma_2}f &\leq \int_0^\pi \left|\frac{Rie^{it}}{1 + R^4e^{4it}} \right| dt
\\
\\ &= \int_0^\pi \frac{R}{\left|1 + R^4e^{4it}\right|}  dt
\\
\\ &= \int_0^\pi \frac{1}{\left| \frac{1}{R} + R^3e^{4it}\right|}  dt
\end{align} R \to \infty \int_{\Gamma_1} f = \int_{-\infty}^\infty \frac{dt}{1 + t^4} \int_{\Gamma_2} f = 0 \int_{-\infty}^\infty \frac{dt}{1 + t^4} = 2 \int_{0}^\infty \frac{dt}{1 + t^4} \int_{0}^\infty \frac{dt}{1 + t^4} = \pi i \xi \pi i \xi","['complex-analysis', 'contour-integration', 'residue-calculus', 'singularity']"
99,On the complex L'Hospital rule,On the complex L'Hospital rule,,"Let $f(z)$ and $g(z)$ be two complex functions (defined on a neighborhood of a point $z_0\in\mathbb{C}$ ) such that $f(z_0)=g(z_0)=0$ and $g'(z_0)\neq 0$ . Is it true that $\lim_{z\rightarrow z_0}\frac{f(z)^2}{g(z)^2}=\frac{[f'(z)]^2}{[g'(z)]^2}$ ? If so, can we generalize this result to any integer power $n$ of $\frac{f(z)}{g(z)}$ ? EDIT: Another related question would be as follows: Can we apply the L'Hospital rule consecutively ? That is, suppose that applying the L'Hospital rule each time the limit gives us $\frac{0}{0}$ , so in this case can we continue to apply the L'Hospital rule (in a finite step) ? Do we need any restrictions on the functions $f$ and $g$ ?","Let and be two complex functions (defined on a neighborhood of a point ) such that and . Is it true that ? If so, can we generalize this result to any integer power of ? EDIT: Another related question would be as follows: Can we apply the L'Hospital rule consecutively ? That is, suppose that applying the L'Hospital rule each time the limit gives us , so in this case can we continue to apply the L'Hospital rule (in a finite step) ? Do we need any restrictions on the functions and ?",f(z) g(z) z_0\in\mathbb{C} f(z_0)=g(z_0)=0 g'(z_0)\neq 0 \lim_{z\rightarrow z_0}\frac{f(z)^2}{g(z)^2}=\frac{[f'(z)]^2}{[g'(z)]^2} n \frac{f(z)}{g(z)} \frac{0}{0} f g,['complex-analysis']
