,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Integral of sine multiplied by Bessel function with complicated argument,Integral of sine multiplied by Bessel function with complicated argument,,"I need a help with integral below, $$ \int_0^\infty \sin(ax)\ J_0\left(b\sqrt{1+x^2}\right)\ \mathrm{d}x, $$ where $a,b > 0 $ and real, $J_0(x)$ is the zeroth-order of Bessel function of the first kind. I found some integrals similar to the integral above, but I don't have any idea on how to apply it. Here are some integrals that might help. $$ \int_0^\infty \cos(ax)\ J_0\left(b\sqrt{1+x^2}\right)\ \mathrm{d}x = \frac{\cos\sqrt{b^2-a^2}}{\sqrt{b^2-a^2}}; \mathrm{~~for~0 < a < b} $$ $$ \int_0^\infty \sin(ax)\ J_0(bx)\ \mathrm{d}x = \frac{1}{\sqrt{a^2-b^2}}; \mathrm{~~for~0 < b < a} $$ The proof of the first integral can be seen here .","I need a help with integral below, $$ \int_0^\infty \sin(ax)\ J_0\left(b\sqrt{1+x^2}\right)\ \mathrm{d}x, $$ where $a,b > 0 $ and real, $J_0(x)$ is the zeroth-order of Bessel function of the first kind. I found some integrals similar to the integral above, but I don't have any idea on how to apply it. Here are some integrals that might help. $$ \int_0^\infty \cos(ax)\ J_0\left(b\sqrt{1+x^2}\right)\ \mathrm{d}x = \frac{\cos\sqrt{b^2-a^2}}{\sqrt{b^2-a^2}}; \mathrm{~~for~0 < a < b} $$ $$ \int_0^\infty \sin(ax)\ J_0(bx)\ \mathrm{d}x = \frac{1}{\sqrt{a^2-b^2}}; \mathrm{~~for~0 < b < a} $$ The proof of the first integral can be seen here .",,"['integration', 'trigonometry', 'definite-integrals', 'bessel-functions']"
1,Is area under an integral limit exact or an approximation?,Is area under an integral limit exact or an approximation?,,"Suppose we need to calculate the area of the the curve $y=sin x$. Then we calculate the area  enclosed by the curve from $x=x_1$ to $x=x_2$ as $\int_{x_1}^{x_2}sin x\, dx$. Is the area calculated so exact or approximate?. In case of a linear curve such $y=ax+b$, we do get an exact value (as justified by geometry) This confusion stems from the question whether limits are exact or not (and hence all operations related to limits). Note: I did see other posts to see an answer, but none of them were complete or the questions were something else entirely. So this is not a duplicate.","Suppose we need to calculate the area of the the curve $y=sin x$. Then we calculate the area  enclosed by the curve from $x=x_1$ to $x=x_2$ as $\int_{x_1}^{x_2}sin x\, dx$. Is the area calculated so exact or approximate?. In case of a linear curve such $y=ax+b$, we do get an exact value (as justified by geometry) This confusion stems from the question whether limits are exact or not (and hence all operations related to limits). Note: I did see other posts to see an answer, but none of them were complete or the questions were something else entirely. So this is not a duplicate.",,"['integration', 'definite-integrals']"
2,How do you integrate Gaussian integral with contour integration method?,How do you integrate Gaussian integral with contour integration method?,,How do you integrate $$\int^{\infty}_{-\infty} e^{-x^2} dx$$ with contour integration method? I do not even know how to setup the problem.,How do you integrate $$\int^{\infty}_{-\infty} e^{-x^2} dx$$ with contour integration method? I do not even know how to setup the problem.,,"['integration', 'complex-analysis', 'improper-integrals', 'contour-integration', 'complex-integration']"
3,Proving that a function is analytic,Proving that a function is analytic,,"I'm struggling with the following problem: Problem : Suppose that $h$ is a continuous function on a simple closed curve $\gamma$. Define $$ H(w) = \oint_{\gamma} \frac{h(z)}{z - w} \, dz. $$ Show that $H$ is analytic on $\mathbb{C} \setminus \gamma$. I feel like the solution should fall very easy from the Cauchy integral formula, but I'm having trouble seeing how to connect the two. Could anyone lend a helping hand?","I'm struggling with the following problem: Problem : Suppose that $h$ is a continuous function on a simple closed curve $\gamma$. Define $$ H(w) = \oint_{\gamma} \frac{h(z)}{z - w} \, dz. $$ Show that $H$ is analytic on $\mathbb{C} \setminus \gamma$. I feel like the solution should fall very easy from the Cauchy integral formula, but I'm having trouble seeing how to connect the two. Could anyone lend a helping hand?",,"['integration', 'complex-analysis', 'contour-integration', 'analyticity']"
4,How find this $\int_{0}^{\pi}\frac{\cos{(nx)}}{\cos{x}+a}dx$,How find this,\int_{0}^{\pi}\frac{\cos{(nx)}}{\cos{x}+a}dx,"Fin the integral  $$I_{n}=\int_{0}^{\pi}\dfrac{\cos{(nx)}}{\cos{x}+a}dx$$ where $n\in {\mathbb N}\,,\ a>1$ My try: let $$I_{n}-I_{n-1}=\int_{0}^{\pi}\dfrac{\cos{(nx)}-\cos{(n-1)x}}{\cos{x}+a}dx$$ and note $$\cos{x}-\cos{y}=-2\sin{\dfrac{x+y}{2}}\sin{\dfrac{x-y}{2}}$$ so $$I_{n}-I_{n-1}=-2\int_{0}^{\pi}\dfrac{\sin{(nx-\dfrac{x}{2})}\sin{\dfrac{x}{2}}}{\cos{x}+a}dx$$ Then I can't ,Thank you for your help.","Fin the integral  $$I_{n}=\int_{0}^{\pi}\dfrac{\cos{(nx)}}{\cos{x}+a}dx$$ where $n\in {\mathbb N}\,,\ a>1$ My try: let $$I_{n}-I_{n-1}=\int_{0}^{\pi}\dfrac{\cos{(nx)}-\cos{(n-1)x}}{\cos{x}+a}dx$$ and note $$\cos{x}-\cos{y}=-2\sin{\dfrac{x+y}{2}}\sin{\dfrac{x-y}{2}}$$ so $$I_{n}-I_{n-1}=-2\int_{0}^{\pi}\dfrac{\sin{(nx-\dfrac{x}{2})}\sin{\dfrac{x}{2}}}{\cos{x}+a}dx$$ Then I can't ,Thank you for your help.",,[]
5,"how to do integration $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x$?",how to do integration ?,"\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x","how to do integration $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x$, assuming $n>1$ ? From wiki page Gaussian Integral : $\int_{-\infty}^{+\infty}\exp(-x^2)\,\mathrm{d}x = \sqrt{\pi}$ So, one can define a random variable $X$ has $\text{pdf}(x) = \frac{1}{\sqrt{\pi}} \text{exp}(-x^2)$ , since $\int_{-\infty}^{+\infty}\text{pdf}(x)\,\mathrm{d}x = 1$. Actually, this is normal distribution. Now, I'd like to define  $\text{pdf}(x) = \frac{1}{c} \text{exp}(-x^n)$, but how much is $c$? Or, $\int_{-\infty}^{\infty}\exp(-x^n)\,\mathrm{d}x = ?$ There is a hint on wiki page Error Function : Error function is $\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x}\exp(-t^2)\,\mathrm{d}t$, with $\text{erf}(0)=0$ and $\text{erf}(+\infty) = 1$. So this means a pdf can be defined as $\text{pdf}(x) = \frac{1}{2}\text{erf}(x)$. Then, Generalized Error Function is defined as $$E_n(x) = \frac{n!}{\sqrt{\pi}} \int_{0}^{x} \text{exp}(-t^n)dt$$ does this mean $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x =  \frac{2\sqrt{\pi}}{n!} $ ? Even so, there's still a problem: if $n$ is not integer, how to calculate $n!$? Does it becomes Gamma function $\Gamma(n)$? like this: $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x =  \frac{2\sqrt{\pi}}{\Gamma(n)} $","how to do integration $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x$, assuming $n>1$ ? From wiki page Gaussian Integral : $\int_{-\infty}^{+\infty}\exp(-x^2)\,\mathrm{d}x = \sqrt{\pi}$ So, one can define a random variable $X$ has $\text{pdf}(x) = \frac{1}{\sqrt{\pi}} \text{exp}(-x^2)$ , since $\int_{-\infty}^{+\infty}\text{pdf}(x)\,\mathrm{d}x = 1$. Actually, this is normal distribution. Now, I'd like to define  $\text{pdf}(x) = \frac{1}{c} \text{exp}(-x^n)$, but how much is $c$? Or, $\int_{-\infty}^{\infty}\exp(-x^n)\,\mathrm{d}x = ?$ There is a hint on wiki page Error Function : Error function is $\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x}\exp(-t^2)\,\mathrm{d}t$, with $\text{erf}(0)=0$ and $\text{erf}(+\infty) = 1$. So this means a pdf can be defined as $\text{pdf}(x) = \frac{1}{2}\text{erf}(x)$. Then, Generalized Error Function is defined as $$E_n(x) = \frac{n!}{\sqrt{\pi}} \int_{0}^{x} \text{exp}(-t^n)dt$$ does this mean $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x =  \frac{2\sqrt{\pi}}{n!} $ ? Even so, there's still a problem: if $n$ is not integer, how to calculate $n!$? Does it becomes Gamma function $\Gamma(n)$? like this: $\int_{-\infty}^{+\infty}\exp(-x^n)\,\mathrm{d}x =  \frac{2\sqrt{\pi}}{\Gamma(n)} $",,['integration']
6,"An integral related to the beta function: $\int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx $",An integral related to the beta function:,"\int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx ","I came across an exercise in a textbook that says to show that $$ \int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx = 2^{m+n-2} B(m,n), \ (m,n >0),$$ and then deduce that $$ \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \Big( \frac{\cos x + \sin x}{\cos x - \sin x} \Big)^{\cos \alpha} \, dx = \frac{\pi}{2 \sin \left( \pi \cos^{2} \frac{\alpha}{2}\right)}, $$ where $\alpha$ is not a multiple of $\pi$. (Considering that $m$ and $n$ aren't necessarily integers here, using them for the parameters is perhaps a bit unconventional.) I managed to figure out the second part of the exercise (which I'll show below), but not the first part. I assume that with the right substitution, one can show that $$\int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx = 2^{m+n-2} \int_{0}^{1} u^{m-1} (1-u)^{n-1} \, du.  $$ $$ \begin{align} \int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx  &= \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{(1 + \tan u)^{2m-1}(1-\tan u)^{2n-1}}{\sec^{2(m+n)} (u)} \, \sec^{2} (u) \, du \\ &= \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} (\cos u  + \sin u)^{2m-1}(\cos u - \sin  u)^{2n-1} \ du \end{align}$$ If we then let $\displaystyle m = \frac{1 + \cos \alpha}{2}$ and $\displaystyle n= \frac{1- \cos \alpha}{2}$, we get $$ \begin{align} \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \Big( \frac{\cos x + \sin x}{\cos x - \sin x} \Big)^{\cos \alpha} \, dx &= \frac{1}{2} \frac{\Gamma \left(\frac{1 + \cos \alpha}{2} \right) \Gamma \left(\frac{1 - \cos \alpha}{2} \right)}{\Gamma (1)} \\ &= \frac{1}{2} \, \Gamma \left(\frac{1 + \cos \alpha}{2} \right) \Gamma \left( 1- \frac{ 1 + \cos \alpha}{2} \right) \\ &= \frac{1}{2} \, \frac{\pi}{\sin \, \left( \pi \frac{1+\cos \alpha}{2} \right)} \\ &= \frac{\pi}{2 \sin \left( \pi \cos^{2} \frac{\alpha}{2}\right)} . \end{align}$$","I came across an exercise in a textbook that says to show that $$ \int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx = 2^{m+n-2} B(m,n), \ (m,n >0),$$ and then deduce that $$ \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \Big( \frac{\cos x + \sin x}{\cos x - \sin x} \Big)^{\cos \alpha} \, dx = \frac{\pi}{2 \sin \left( \pi \cos^{2} \frac{\alpha}{2}\right)}, $$ where $\alpha$ is not a multiple of $\pi$. (Considering that $m$ and $n$ aren't necessarily integers here, using them for the parameters is perhaps a bit unconventional.) I managed to figure out the second part of the exercise (which I'll show below), but not the first part. I assume that with the right substitution, one can show that $$\int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx = 2^{m+n-2} \int_{0}^{1} u^{m-1} (1-u)^{n-1} \, du.  $$ $$ \begin{align} \int_{-1}^{1} \frac{(1+x)^{2m-1}(1-x)^{2n-1}}{(1+x^{2})^{m+n}} \, dx  &= \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{(1 + \tan u)^{2m-1}(1-\tan u)^{2n-1}}{\sec^{2(m+n)} (u)} \, \sec^{2} (u) \, du \\ &= \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} (\cos u  + \sin u)^{2m-1}(\cos u - \sin  u)^{2n-1} \ du \end{align}$$ If we then let $\displaystyle m = \frac{1 + \cos \alpha}{2}$ and $\displaystyle n= \frac{1- \cos \alpha}{2}$, we get $$ \begin{align} \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \Big( \frac{\cos x + \sin x}{\cos x - \sin x} \Big)^{\cos \alpha} \, dx &= \frac{1}{2} \frac{\Gamma \left(\frac{1 + \cos \alpha}{2} \right) \Gamma \left(\frac{1 - \cos \alpha}{2} \right)}{\Gamma (1)} \\ &= \frac{1}{2} \, \Gamma \left(\frac{1 + \cos \alpha}{2} \right) \Gamma \left( 1- \frac{ 1 + \cos \alpha}{2} \right) \\ &= \frac{1}{2} \, \frac{\pi}{\sin \, \left( \pi \frac{1+\cos \alpha}{2} \right)} \\ &= \frac{\pi}{2 \sin \left( \pi \cos^{2} \frac{\alpha}{2}\right)} . \end{align}$$",,"['integration', 'definite-integrals', 'special-functions', 'gamma-function', 'beta-function']"
7,Summing over General Functions of Primes and an Application to Prime $\zeta$ Function,Summing over General Functions of Primes and an Application to Prime  Function,\zeta,"Along the lines of thought given here , is it in general possible to substitute a summation over a function $f$ of primes like the following: $$ \sum_{p\le x}f(p)=\int_2^x f(t) d(\pi(t))\tag{1} $$ and further $$ \int_2^x f(t) d(\pi(t))=f(t)\pi(t)\biggr|_2^{x}-\int_2^{x}f'(t)\pi(t)dt\tag{2}. $$ If it's possible only for some cases, how can one specify them? answered in the comments Let's continue from $(2)$ with an representation of the prime counting function: $$ \pi(t) = \operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho}) \tag{3} $$ with $    \operatorname{R}(u) = \sum_{n=1}^{\infty} \frac{ \mu (n)}{n} \operatorname{li}(u^{1/n})$ (the so-called Riemann's ${\rm R}$ Function, see e.g. $(11)$ here ) and $\rho$ running over all the zeros (trivial and non-trivial) of $\zeta$ function. $\operatorname{li}(\cdot)$ is the logarithmic integral . So we have  $$ \begin{eqnarray} &=&f(t)\pi(t)\biggr|_2^{x}-\int_2^{x}f'(t)\pi(t)dt\\ &=&f(t)\left(\operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho})\right)\biggr|_2^{x} -\int_2^{x}f'(t)\left(\operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho})\right)dt \phantom{somemorerspace}\\ &\phantom{AA}&\\ &=&\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\Big\{\left[f(t)\left( \sum_{z\in\{1,\rho\}} (-1)^{1-\delta_{1z}} \operatorname{li}(t^{z/n})\right)\right]_2^{x}\\ &&- \int_2^{x}f'(t)\left( \sum_{z\in\{1,\rho\}} (-1)^{1-\delta_{1z}} \operatorname{li}(t^{z/n})\right)dt\Big\}\\ &\phantom{AA}&\\ &=&\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\left[f(t)\left(   \operatorname{li}(t^{z/n})\right)\right]_2^{x} - \int_2^{x}f'(t)\left(  \operatorname{li}(t^{z/n})\right)dt\right\}\hskip0.9in(4) \end{eqnarray} $$ where I tried to combine the sum a little without introducing to much confusion by using  $$ (-1)^{1-\delta_{1z}}= \cases{ +1&$ \text{if } z=1$\\ -1&$ \text{if } z=\rho$\\ } $$ Now, what if we just take an approximation $\tilde{\pi}(t)$, where the sums over $n$ and $\rho$ are truncated. Is this approach still valid? I'm worried because $\tilde{\pi}(t)$ might not be monotone, which is a prerequisite of the Lebesgue-Stieltjes integration .  Let's work out the last integral, by parts: We use $$ \int_2^{x}f'(t) \operatorname{li}(t^{w})dt =\left[ f(t)\operatorname{li}(t^{w}) \right]_2^x - \int_2^x \frac{f(t)wt^{w-1}}{\ln(t^w)}dt \tag{5} $$ which gives a nice result when $f(t)=t^{-s}$, see here : $$ \int_2^{x}(-st^{-s-1}) \operatorname{li}(t^{w})dt =\left[ t^{-s}\operatorname{li}(t^{w}) \right]_2^x - \int_2^x \frac{t^{-s}t^{w-1}}{\ln(t)}dt =\left[ t^{-s}\operatorname{li}(t^{w}) \right]_2^x - \left[{\rm li}(t^{w-s})\right]^x_2. $$ So overall we get $$ \sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\left[f(t)  \operatorname{li}(t^{z/n})\right]_2^{x}- \left[ f(t)\operatorname{li}(t^{z/n}) \right]_2^x +\int_2^x \frac{zf(t)t^{z/n-1}}{n\ln(t^{z/n})}dt \right\}\\ =\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\int_2^x \frac{f(t)t^{z/n-1}}{\ln(t)}dt \right\}\tag{6}\\ $$ and in the special case $f(t)=t^{-s}$ this simplifies to $$ P_\color{red}x(\color{blue}s)=\sum_{p<\color{red}x} \frac{1}{p^s} =\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}} \left[ {\rm li}(t^{\frac zn-\color{blue}s}) \right]^{\color{red}x}_2 \tag{7} $$ (for the interested reader: the story continues here... ) If anybody could confirm this, it would be ever so cool. Thanks for your help and your time for reading all this,","Along the lines of thought given here , is it in general possible to substitute a summation over a function $f$ of primes like the following: $$ \sum_{p\le x}f(p)=\int_2^x f(t) d(\pi(t))\tag{1} $$ and further $$ \int_2^x f(t) d(\pi(t))=f(t)\pi(t)\biggr|_2^{x}-\int_2^{x}f'(t)\pi(t)dt\tag{2}. $$ If it's possible only for some cases, how can one specify them? answered in the comments Let's continue from $(2)$ with an representation of the prime counting function: $$ \pi(t) = \operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho}) \tag{3} $$ with $    \operatorname{R}(u) = \sum_{n=1}^{\infty} \frac{ \mu (n)}{n} \operatorname{li}(u^{1/n})$ (the so-called Riemann's ${\rm R}$ Function, see e.g. $(11)$ here ) and $\rho$ running over all the zeros (trivial and non-trivial) of $\zeta$ function. $\operatorname{li}(\cdot)$ is the logarithmic integral . So we have  $$ \begin{eqnarray} &=&f(t)\pi(t)\biggr|_2^{x}-\int_2^{x}f'(t)\pi(t)dt\\ &=&f(t)\left(\operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho})\right)\biggr|_2^{x} -\int_2^{x}f'(t)\left(\operatorname{R}(t^1) - \sum_{\rho}\operatorname{R}(t^{\rho})\right)dt \phantom{somemorerspace}\\ &\phantom{AA}&\\ &=&\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\Big\{\left[f(t)\left( \sum_{z\in\{1,\rho\}} (-1)^{1-\delta_{1z}} \operatorname{li}(t^{z/n})\right)\right]_2^{x}\\ &&- \int_2^{x}f'(t)\left( \sum_{z\in\{1,\rho\}} (-1)^{1-\delta_{1z}} \operatorname{li}(t^{z/n})\right)dt\Big\}\\ &\phantom{AA}&\\ &=&\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\left[f(t)\left(   \operatorname{li}(t^{z/n})\right)\right]_2^{x} - \int_2^{x}f'(t)\left(  \operatorname{li}(t^{z/n})\right)dt\right\}\hskip0.9in(4) \end{eqnarray} $$ where I tried to combine the sum a little without introducing to much confusion by using  $$ (-1)^{1-\delta_{1z}}= \cases{ +1&$ \text{if } z=1$\\ -1&$ \text{if } z=\rho$\\ } $$ Now, what if we just take an approximation $\tilde{\pi}(t)$, where the sums over $n$ and $\rho$ are truncated. Is this approach still valid? I'm worried because $\tilde{\pi}(t)$ might not be monotone, which is a prerequisite of the Lebesgue-Stieltjes integration .  Let's work out the last integral, by parts: We use $$ \int_2^{x}f'(t) \operatorname{li}(t^{w})dt =\left[ f(t)\operatorname{li}(t^{w}) \right]_2^x - \int_2^x \frac{f(t)wt^{w-1}}{\ln(t^w)}dt \tag{5} $$ which gives a nice result when $f(t)=t^{-s}$, see here : $$ \int_2^{x}(-st^{-s-1}) \operatorname{li}(t^{w})dt =\left[ t^{-s}\operatorname{li}(t^{w}) \right]_2^x - \int_2^x \frac{t^{-s}t^{w-1}}{\ln(t)}dt =\left[ t^{-s}\operatorname{li}(t^{w}) \right]_2^x - \left[{\rm li}(t^{w-s})\right]^x_2. $$ So overall we get $$ \sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\left[f(t)  \operatorname{li}(t^{z/n})\right]_2^{x}- \left[ f(t)\operatorname{li}(t^{z/n}) \right]_2^x +\int_2^x \frac{zf(t)t^{z/n-1}}{n\ln(t^{z/n})}dt \right\}\\ =\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}}\left\{\int_2^x \frac{f(t)t^{z/n-1}}{\ln(t)}dt \right\}\tag{6}\\ $$ and in the special case $f(t)=t^{-s}$ this simplifies to $$ P_\color{red}x(\color{blue}s)=\sum_{p<\color{red}x} \frac{1}{p^s} =\sum_{n=1}^{\infty}\frac{ \mu (n)}{n}\sum_{z\in\{1,\rho\}}(-1)^{1-\delta_{1z}} \left[ {\rm li}(t^{\frac zn-\color{blue}s}) \right]^{\color{red}x}_2 \tag{7} $$ (for the interested reader: the story continues here... ) If anybody could confirm this, it would be ever so cool. Thanks for your help and your time for reading all this,",,"['integration', 'measure-theory', 'prime-numbers']"
8,What is $\int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx$?,What is ?,\int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx,"Let $I_n=\int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx$ Wolfram Alpha gives an exact value for $n=-4,-3,-2,-1,0,1,2,3,4,6,8$ and interestingly enough, it seems $I_n=I_{-n}$ . $$I_0=\frac{\pi}{2}\sin(1)$$ $$I_1=I_{-1}=\frac{\operatorname{Ei}(1)-e^2\operatorname{Ei}(-1)}{2e}$$ $$I_2=I_{-2}=\frac{\pi}{2}\left(\sin(1)\left(\operatorname{C}\left(\sqrt{\frac{2}{\pi}}\right)+\operatorname{S}\left(\sqrt{\frac{2}{\pi}}\right)\right)+\cos(1)\left(\operatorname{C}\left(\sqrt{\frac{2}{\pi}}\right)-\operatorname{S}\left(\sqrt{\frac{2}{\pi}}\right)\right)\right)$$ And so on... $$I_{\frac{1}{2}}=\frac{\pi}{e^\frac{1}{\sqrt{2}}}\sin\left(\frac{1}{\sqrt{2}}\right)$$ So my question is: For any $n$ , what is $\int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx$ ?","Let Wolfram Alpha gives an exact value for and interestingly enough, it seems . And so on... So my question is: For any , what is ?","I_n=\int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx n=-4,-3,-2,-1,0,1,2,3,4,6,8 I_n=I_{-n} I_0=\frac{\pi}{2}\sin(1) I_1=I_{-1}=\frac{\operatorname{Ei}(1)-e^2\operatorname{Ei}(-1)}{2e} I_2=I_{-2}=\frac{\pi}{2}\left(\sin(1)\left(\operatorname{C}\left(\sqrt{\frac{2}{\pi}}\right)+\operatorname{S}\left(\sqrt{\frac{2}{\pi}}\right)\right)+\cos(1)\left(\operatorname{C}\left(\sqrt{\frac{2}{\pi}}\right)-\operatorname{S}\left(\sqrt{\frac{2}{\pi}}\right)\right)\right) I_{\frac{1}{2}}=\frac{\pi}{e^\frac{1}{\sqrt{2}}}\sin\left(\frac{1}{\sqrt{2}}\right) n \int\limits_{0}^{\infty}\frac{\sin(x^n)}{x^2+1}dx","['integration', 'definite-integrals', 'improper-integrals']"
9,Estimating the value of this Integral,Estimating the value of this Integral,,"If I= $\int_0^1x^{sinx+cosx}dx$ then find the value of $[10I]$ where $[.]$ represent greatest integer function. A)3 $\boxed{B)4}$ C)5 D)6 Mathongo, JEE sample questions Method 1 : I took a few points on the given curve and estimated out the area to be slightly less than 0.5 in the given interval, thus yielding the correct answer: 4. Legend: Black line $y=x$ Curve bordering red area $x^{\sin x + \cos x}$ Bounds as given. Here is the attached Desmos link to depict the same Method 2 (prompted): $\hspace{42px} 1\leq sinx+cosx \leq \sqrt{2}$ $\implies x \geq x^{sinx+cosx} \geq x^{\sqrt{2}}$ $\implies \int_0^1 xdx \geq \int_0^1x^{sinx+cosx}dx \geq \int_0^1x^{\sqrt{2}}dx$ $\implies 0.5 \geq I \geq 0.414$ Thus, $\boxed{[10I]=4}$ . Would be glad if the community could come up with more alternative approaches.","If I= then find the value of where represent greatest integer function. A)3 C)5 D)6 Mathongo, JEE sample questions Method 1 : I took a few points on the given curve and estimated out the area to be slightly less than 0.5 in the given interval, thus yielding the correct answer: 4. Legend: Black line Curve bordering red area Bounds as given. Here is the attached Desmos link to depict the same Method 2 (prompted): Thus, . Would be glad if the community could come up with more alternative approaches.",\int_0^1x^{sinx+cosx}dx [10I] [.] \boxed{B)4} y=x x^{\sin x + \cos x} \hspace{42px} 1\leq sinx+cosx \leq \sqrt{2} \implies x \geq x^{sinx+cosx} \geq x^{\sqrt{2}} \implies \int_0^1 xdx \geq \int_0^1x^{sinx+cosx}dx \geq \int_0^1x^{\sqrt{2}}dx \implies 0.5 \geq I \geq 0.414 \boxed{[10I]=4},"['integration', 'area', 'estimation']"
10,Evaluate $\int \:\frac{3x^5+13x^4+32x^3+8x^2-40x-75}{x^2\left(x^2+3x+5\right)^2}\:dx$,Evaluate,\int \:\frac{3x^5+13x^4+32x^3+8x^2-40x-75}{x^2\left(x^2+3x+5\right)^2}\:dx,I am supposed to evaluate $$\int \:\frac{3x^5+13x^4+32x^3+8x^2-40x-75}{x^2\left(x^2+3x+5\right)^2}\:dx$$ I started using partial fractions $$3x^5+13x^4+32x^3+8x^2-40x-75=x\left(x^2+3x+5^2\right)^2A+\left(x^2+3x+5^2\right)^2B+x\left(x^2+3x+5^2\right)\left(Cx+D\right)+x^2\left(Ex+F\right)$$ I managed to get to $$\:\int \:\left(\frac{2}{x}-\frac{3}{x^2}+\frac{x+1}{x^2+3x+5}+\frac{4x}{\left(x^2+3x+5\right)^2}\right)\:dx$$ Am i on the right track? is there an easier way to simplify the original integral?,I am supposed to evaluate I started using partial fractions I managed to get to Am i on the right track? is there an easier way to simplify the original integral?,\int \:\frac{3x^5+13x^4+32x^3+8x^2-40x-75}{x^2\left(x^2+3x+5\right)^2}\:dx 3x^5+13x^4+32x^3+8x^2-40x-75=x\left(x^2+3x+5^2\right)^2A+\left(x^2+3x+5^2\right)^2B+x\left(x^2+3x+5^2\right)\left(Cx+D\right)+x^2\left(Ex+F\right) \:\int \:\left(\frac{2}{x}-\frac{3}{x^2}+\frac{x+1}{x^2+3x+5}+\frac{4x}{\left(x^2+3x+5\right)^2}\right)\:dx,['integration']
11,Fourier series of a polynomial.,Fourier series of a polynomial.,,"I am looking for the Fourier series of a monomial restricted to the inteval $(0,2\pi)$ . Let $n\in\mathbb{N}$ and $$\forall x\in (0, 2\pi), \ f(x)=x^n.$$ By definition, the Fourier coefficients are $$c_k = \frac{1}{2\pi}\int_0^{2\pi} x^n e^{-ikx} dx,$$ and we know that $$f(x) =_{\text{a.e.}} \sum_{k\in\mathbb{Z}} c_k e^{ikx}.$$ This can be written in terms of gamma incomplete function, but there might be a closed form for this particular definite integral. What is the exact value of $c_k$ , the Fourier coefficient of the monomial $x^n$ ?","I am looking for the Fourier series of a monomial restricted to the inteval . Let and By definition, the Fourier coefficients are and we know that This can be written in terms of gamma incomplete function, but there might be a closed form for this particular definite integral. What is the exact value of , the Fourier coefficient of the monomial ?","(0,2\pi) n\in\mathbb{N} \forall x\in (0, 2\pi), \ f(x)=x^n. c_k = \frac{1}{2\pi}\int_0^{2\pi} x^n e^{-ikx} dx, f(x) =_{\text{a.e.}} \sum_{k\in\mathbb{Z}} c_k e^{ikx}. c_k x^n","['integration', 'fourier-series', 'gamma-function']"
12,Very advanced sums: Compute $\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2}$ and $\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2}$,Very advanced sums: Compute  and,\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2} \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2},"How to prove: $$S_1=\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2} =\frac{23 }{32}\zeta (2) \zeta (3)-\frac{581}{128} \zeta (5)-\frac{2}{3}\ln ^32 \zeta (2)+\frac{7}{4} \ln^22\zeta (3)\\ +\frac{2}{15} \ln ^52 +4\ln2 \operatorname{Li}_4\left(\frac{1}{2}\right) +4 \operatorname{Li}_5\left(\frac{1}{2}\right)$$ $$S_2=\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2} =\frac{23 }{32}\zeta (2) \zeta (3)+\frac{917 }{128}\zeta (5)+\frac{2}{3}  \ln ^32\zeta (2)-\frac{7}{4}  \ln ^22\zeta (3)\\-\frac{2}{15} \ln ^52 -4 \ln2\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right)$$ where $H_n^{(m)}=1+\frac{1}{2^m}+\cdots+\frac{1}{n^m}, \ m\ge1,$ represents the $n$ th generalized harmonic number of order $m$ , $\zeta$ is the Riemann zeta function and $\operatorname{Li}_n$ is the polylogarithm function. These two sums were proposed by Cornel here where he asked if these results and others ( in the link) exist in the literature. I managed to find a relation between $S_1$ and $S_2$ so we need to find another relation or evaluate of them separately. Here is how I got the relation: From here we have $$\int_0^1 x^{2n-1}\ln^2(1-x)\ dx=\frac{H_{2n}^2+H_{2n}^{(2)}}{2n}$$ multiply both sides by $\frac{H_n}{2n}$ then sum them from $n=1$ to $\infty$ to get $$\sum_{n=1}^\infty\frac{H_n}{(2n)^2}(H_{2n}^2+H_{2n}^{(2)})=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\sum_{n=1}^\infty(x^2)^n\frac{H_n}{n}\ dx\\=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\left(\operatorname{Li}_2(x^2)+\frac12\ln^2(1-x^2)\right)\ dx\\=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\left(2\operatorname{Li}_2(x)+2\operatorname{Li}_2(-x)+\frac12\ln^2(1-x^2)\right)\ dx\\=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(x)}{x}+\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(-x)}{x}+\frac14\int_0^1\frac{\ln^2(1-x)\ln^2(1-x^2)}{x}\ dx\\=A+B+\frac14C$$ \begin{align} A&=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(x)}{x}\ dx=\int_0^1\frac{\ln^2x\operatorname{Li}_2(1-x)}{1-x}\ dx\\ &=\zeta(2)\int_0^1\frac{\ln^2x}{1-x}-\int_0^1\frac{\ln^3x\ln(1-x)}{1-x}-\int_0^1\frac{\ln^2x\operatorname{Li}_2(x)}{1-x}\ dx\\ &=2\zeta(2)\zeta(3)+\sum_{n=1}^\infty H_n\int_0^1 x^n\ln^3x-\sum_{n=1}^\infty H_n^{(2)}\int_0^1x^n\ln^2x\ dx\\ &=2\zeta(2)\zeta(3)-6\sum_{n=1}^\infty\frac{H_n}{(n+1)^4}-2\sum_{n=1}^\infty\frac{H_n^{(2)}}{(n+1)^3}\\ &=2\zeta(2)\zeta(3)-6\sum_{n=1}^\infty\frac{H_n}{n^4}+6\zeta(5)-2\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^3}+2\zeta(5)\\ &=\boxed{2\zeta(2)\zeta(3)-\zeta(5)} \end{align} where we used $\sum_{n=1}^\infty\frac{H_n}{n^4}=3\zeta(5)-\zeta(2)\zeta(3)$ and $\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^3}=3\zeta(2)\zeta(3)-\frac92\zeta(5)$ \begin{align} B&=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(-x)}{x}\ dx\\ &=\sum_{n=1}^\infty\frac{(-1)^n}{n^2}\int_0^1x^{n-1} \ln^2(1-x)\ dx\\ &=\sum_{n=1}^\infty(-1)^n\frac{H_n^2+H_n^{(2)}}{n^3}\\ &=\boxed{\small{\frac23\ln^32\zeta(2)-\frac74\ln^22\zeta(3)+\frac{3}4\zeta(2)\zeta(3)+\frac{15}{16}\zeta(5)-\frac2{15}\ln^52-4\ln2\operatorname{Li}_4\left(\frac12\right)-4\operatorname{Li}_5\left(\frac12\right)}} \end{align} where the results $$\small{\sum_{n=1}^\infty\frac{(-1)^nH_n^2}{n^3}=\frac23\ln^32\zeta(2)-\frac74\ln^22\zeta(3)+\frac{3}4\zeta(2)\zeta(3)+\frac{15}{16}\zeta(5)-\frac2{15}\ln^52-4\ln2\operatorname{Li}_4\left(\frac12\right)-4\operatorname{Li}_5\left(\frac12\right)}$$ and $$\sum_{n=1}^\infty\frac{(-1)^nH_n^{(2)}}{n^3}=\frac{11}{32}\zeta(5)-\frac58\zeta(2)\zeta(3)$$ were used. Both series can be found here . To find $C$ , we are going to use the algebraic identity: $$a^2(a+b)^2=\frac43a^4-\frac23b^4+\frac5{24}(a+b)^4+\frac{13}{24}(a-b)^4-(a-b)^3b$$ with $a=\ln(1-x)$ and $b=\ln(1+x)$ we can write $$C=\frac43\int_0^1\frac{\ln^4(1-x)}{x}\ dx-\frac23\int_0^1\frac{\ln^4(1+x)}{x}\ dx+\frac5{24}\underbrace{\int_0^1\frac{\ln^4(1-x^2)}{x}\ dx}_{x^2\mapsto x}-\frac{13}{24}\underbrace{\int_0^1\frac{\ln^4\left(\frac{1-x}{1+x}\right)}{x}\ dx}_{\frac{1-x}{1+x}\mapsto x}-\underbrace{\int_0^1\frac{\ln^3\left(\frac{1-x}{1+x}\right)\ln(1+x)}{x}\ dx}_{\frac{1-x}{1+x}\mapsto x}\\C=\small{\frac{23}{16}\underbrace{\int_0^1\frac{\ln^4(1-x)}{x}\ dx}_{24\zeta(5)}-\frac23\int_0^1\frac{\ln^4(1+x)}{x}\ dx-\frac{13}{12}\underbrace{\int_0^1\frac{\ln^4x}{1-x^2}\ dx}_{\frac{93}4\zeta(5)}}-2\int_0^1\frac{\ln^2x\ln\left(\frac{1+x}{2}\right)}{1-x^2}\ dx\\C=\frac{149}{16}\zeta(5)-\frac23\underbrace{\int_0^1\frac{\ln^4(1+x)}{x}\ dx}_{K}+\underbrace{2\int_0^1\frac{\ln^3x\ln\left(\frac{1+x}{2}\right)}{1-x^2}\ dx}_{J}$$ The integrals $K$ and $J$ are calculated here $$K=4\ln^32\zeta(2)-\frac{21}2\ln^22\zeta(3)+24\zeta(5)-\frac45\ln^52-24\ln2\operatorname{Li}_4\left(\frac12\right)-24\operatorname{Li}_5\left(\frac12\right)$$ $$J=\frac{279}{16}\zeta(5)-\frac{21}{4}\zeta(2)\zeta(3)$$ Combining $K$ and $J$ gives $$\boxed{\small{C=\frac{43}{4}\zeta(5)-\frac{21}4\zeta(2)\zeta(3)-\frac83\ln^32\zeta(2)+7\ln^22\zeta(3)+\frac8{15}\ln^52+16\ln2\operatorname{Li}_4\left(\frac12\right)+16\operatorname{Li}_5\left(\frac12\right)}}$$ now combine the boxed results of the integrals $A$ , $B$ and $C$ we get $$\sum_{n=1}^\infty\frac{H_n}{(2n)^2}(H_{2n}^2+H_{2n}^{(2)})=\frac{23}{16}\zeta (2) \zeta (3)+\frac{21}{8} \zeta (5)$$","How to prove: where represents the th generalized harmonic number of order , is the Riemann zeta function and is the polylogarithm function. These two sums were proposed by Cornel here where he asked if these results and others ( in the link) exist in the literature. I managed to find a relation between and so we need to find another relation or evaluate of them separately. Here is how I got the relation: From here we have multiply both sides by then sum them from to to get where we used and where the results and were used. Both series can be found here . To find , we are going to use the algebraic identity: with and we can write The integrals and are calculated here Combining and gives now combine the boxed results of the integrals , and we get","S_1=\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2}
=\frac{23 }{32}\zeta (2) \zeta (3)-\frac{581}{128} \zeta (5)-\frac{2}{3}\ln ^32 \zeta (2)+\frac{7}{4} \ln^22\zeta (3)\\ +\frac{2}{15} \ln ^52
+4\ln2 \operatorname{Li}_4\left(\frac{1}{2}\right) +4 \operatorname{Li}_5\left(\frac{1}{2}\right) S_2=\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2}
=\frac{23 }{32}\zeta (2) \zeta (3)+\frac{917 }{128}\zeta (5)+\frac{2}{3}  \ln ^32\zeta (2)-\frac{7}{4}  \ln ^22\zeta (3)\\-\frac{2}{15} \ln ^52
-4 \ln2\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right) H_n^{(m)}=1+\frac{1}{2^m}+\cdots+\frac{1}{n^m}, \ m\ge1, n m \zeta \operatorname{Li}_n S_1 S_2 \int_0^1 x^{2n-1}\ln^2(1-x)\ dx=\frac{H_{2n}^2+H_{2n}^{(2)}}{2n} \frac{H_n}{2n} n=1 \infty \sum_{n=1}^\infty\frac{H_n}{(2n)^2}(H_{2n}^2+H_{2n}^{(2)})=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\sum_{n=1}^\infty(x^2)^n\frac{H_n}{n}\ dx\\=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\left(\operatorname{Li}_2(x^2)+\frac12\ln^2(1-x^2)\right)\ dx\\=\frac12\int_0^1\frac{\ln^2(1-x)}{x}\left(2\operatorname{Li}_2(x)+2\operatorname{Li}_2(-x)+\frac12\ln^2(1-x^2)\right)\ dx\\=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(x)}{x}+\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(-x)}{x}+\frac14\int_0^1\frac{\ln^2(1-x)\ln^2(1-x^2)}{x}\ dx\\=A+B+\frac14C \begin{align}
A&=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(x)}{x}\ dx=\int_0^1\frac{\ln^2x\operatorname{Li}_2(1-x)}{1-x}\ dx\\
&=\zeta(2)\int_0^1\frac{\ln^2x}{1-x}-\int_0^1\frac{\ln^3x\ln(1-x)}{1-x}-\int_0^1\frac{\ln^2x\operatorname{Li}_2(x)}{1-x}\ dx\\
&=2\zeta(2)\zeta(3)+\sum_{n=1}^\infty H_n\int_0^1 x^n\ln^3x-\sum_{n=1}^\infty H_n^{(2)}\int_0^1x^n\ln^2x\ dx\\
&=2\zeta(2)\zeta(3)-6\sum_{n=1}^\infty\frac{H_n}{(n+1)^4}-2\sum_{n=1}^\infty\frac{H_n^{(2)}}{(n+1)^3}\\
&=2\zeta(2)\zeta(3)-6\sum_{n=1}^\infty\frac{H_n}{n^4}+6\zeta(5)-2\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^3}+2\zeta(5)\\
&=\boxed{2\zeta(2)\zeta(3)-\zeta(5)}
\end{align} \sum_{n=1}^\infty\frac{H_n}{n^4}=3\zeta(5)-\zeta(2)\zeta(3) \sum_{n=1}^\infty\frac{H_n^{(2)}}{n^3}=3\zeta(2)\zeta(3)-\frac92\zeta(5) \begin{align}
B&=\int_0^1\frac{\ln^2(1-x)\operatorname{Li}_2(-x)}{x}\ dx\\
&=\sum_{n=1}^\infty\frac{(-1)^n}{n^2}\int_0^1x^{n-1} \ln^2(1-x)\ dx\\
&=\sum_{n=1}^\infty(-1)^n\frac{H_n^2+H_n^{(2)}}{n^3}\\
&=\boxed{\small{\frac23\ln^32\zeta(2)-\frac74\ln^22\zeta(3)+\frac{3}4\zeta(2)\zeta(3)+\frac{15}{16}\zeta(5)-\frac2{15}\ln^52-4\ln2\operatorname{Li}_4\left(\frac12\right)-4\operatorname{Li}_5\left(\frac12\right)}}
\end{align} \small{\sum_{n=1}^\infty\frac{(-1)^nH_n^2}{n^3}=\frac23\ln^32\zeta(2)-\frac74\ln^22\zeta(3)+\frac{3}4\zeta(2)\zeta(3)+\frac{15}{16}\zeta(5)-\frac2{15}\ln^52-4\ln2\operatorname{Li}_4\left(\frac12\right)-4\operatorname{Li}_5\left(\frac12\right)} \sum_{n=1}^\infty\frac{(-1)^nH_n^{(2)}}{n^3}=\frac{11}{32}\zeta(5)-\frac58\zeta(2)\zeta(3) C a^2(a+b)^2=\frac43a^4-\frac23b^4+\frac5{24}(a+b)^4+\frac{13}{24}(a-b)^4-(a-b)^3b a=\ln(1-x) b=\ln(1+x) C=\frac43\int_0^1\frac{\ln^4(1-x)}{x}\ dx-\frac23\int_0^1\frac{\ln^4(1+x)}{x}\ dx+\frac5{24}\underbrace{\int_0^1\frac{\ln^4(1-x^2)}{x}\ dx}_{x^2\mapsto x}-\frac{13}{24}\underbrace{\int_0^1\frac{\ln^4\left(\frac{1-x}{1+x}\right)}{x}\ dx}_{\frac{1-x}{1+x}\mapsto x}-\underbrace{\int_0^1\frac{\ln^3\left(\frac{1-x}{1+x}\right)\ln(1+x)}{x}\ dx}_{\frac{1-x}{1+x}\mapsto x}\\C=\small{\frac{23}{16}\underbrace{\int_0^1\frac{\ln^4(1-x)}{x}\ dx}_{24\zeta(5)}-\frac23\int_0^1\frac{\ln^4(1+x)}{x}\ dx-\frac{13}{12}\underbrace{\int_0^1\frac{\ln^4x}{1-x^2}\ dx}_{\frac{93}4\zeta(5)}}-2\int_0^1\frac{\ln^2x\ln\left(\frac{1+x}{2}\right)}{1-x^2}\ dx\\C=\frac{149}{16}\zeta(5)-\frac23\underbrace{\int_0^1\frac{\ln^4(1+x)}{x}\ dx}_{K}+\underbrace{2\int_0^1\frac{\ln^3x\ln\left(\frac{1+x}{2}\right)}{1-x^2}\ dx}_{J} K J K=4\ln^32\zeta(2)-\frac{21}2\ln^22\zeta(3)+24\zeta(5)-\frac45\ln^52-24\ln2\operatorname{Li}_4\left(\frac12\right)-24\operatorname{Li}_5\left(\frac12\right) J=\frac{279}{16}\zeta(5)-\frac{21}{4}\zeta(2)\zeta(3) K J \boxed{\small{C=\frac{43}{4}\zeta(5)-\frac{21}4\zeta(2)\zeta(3)-\frac83\ln^32\zeta(2)+7\ln^22\zeta(3)+\frac8{15}\ln^52+16\ln2\operatorname{Li}_4\left(\frac12\right)+16\operatorname{Li}_5\left(\frac12\right)}} A B C \sum_{n=1}^\infty\frac{H_n}{(2n)^2}(H_{2n}^2+H_{2n}^{(2)})=\frac{23}{16}\zeta (2) \zeta (3)+\frac{21}{8} \zeta (5)","['integration', 'sequences-and-series', 'definite-integrals', 'harmonic-numbers', 'polylogarithm']"
13,Does multiplication by a test function stay in a Sobolev space?,Does multiplication by a test function stay in a Sobolev space?,,"Let $u \in D^{1,\vec{p}}(\Omega)$ and $\phi \in C_c^{\infty}(\Omega)$ .   Then do we necessarily have $u\phi \in D^{1,\vec{p}}(\Omega)$ ? My attempt What we need to show is that $\partial_i (u \phi) \in L^{p_i}(\Omega)$ for each $i$ . We can try to break up the integral as: \begin{align*} \int_{\Omega} |\partial_i (u \phi)|^{p_i} &= \int_{\Omega} |\partial_i u \cdot \phi + \partial_i \phi \cdot u|^{p_i} \leq \int_{\Omega} |\partial_i u \cdot \phi|^{p_i} + \int_{\Omega} |\partial_i \phi \cdot u|^{p_i} \\ &= \int_{\Omega} |\partial_i u|^{p_i} |\phi|^{p_i} + \int_{\Omega} |\partial_i \phi|^{p_i} |u|^{p_i} \end{align*} The first term is easily bounded given the nature of $\phi$ and $u$ . But, the second term is more troublesome. We can bound the size of $|\partial_i \phi|$ and restrict the integral to a compact set. Then if $p_i \leq p^*$ , we can easily bound our integral by $|\operatorname{supp} \partial_i \phi| + \|u\|_{p^*}$ , which is finite since $D^{1,\vec{p}}(\Omega)$ is embedded in $L^{p^*}(\Omega)$ . But we don't necessarily always have $p_i \leq p^*$ ; in this case, I don't know what to do. Background For $\vec{p} = (p_1, ..., p_N)$ and $\Omega \subseteq \mathbb{R}^N$ , the Sobolev space $D^{1,\vec{p}}(\Omega)$ is defined as the completion of $C_c^{\infty}(\Omega)$ with respect to the norm: \begin{align*} \|u\|_{\vec{p}} = \sum \limits_{i=1}^N \|\partial_i u \|_{p_i} \end{align*} We think of this space as being continuously embedded into $L^{p^*}(\Omega)$ via the Sobolev inequality given here , where $p^* = Np/(N-p)$ and $1/p = \sum 1/p_i$ .","Let and .   Then do we necessarily have ? My attempt What we need to show is that for each . We can try to break up the integral as: The first term is easily bounded given the nature of and . But, the second term is more troublesome. We can bound the size of and restrict the integral to a compact set. Then if , we can easily bound our integral by , which is finite since is embedded in . But we don't necessarily always have ; in this case, I don't know what to do. Background For and , the Sobolev space is defined as the completion of with respect to the norm: We think of this space as being continuously embedded into via the Sobolev inequality given here , where and .","u \in D^{1,\vec{p}}(\Omega) \phi \in C_c^{\infty}(\Omega) u\phi \in D^{1,\vec{p}}(\Omega) \partial_i (u \phi) \in L^{p_i}(\Omega) i \begin{align*}
\int_{\Omega} |\partial_i (u \phi)|^{p_i}
&=
\int_{\Omega} |\partial_i u \cdot \phi + \partial_i \phi \cdot u|^{p_i}
\leq
\int_{\Omega} |\partial_i u \cdot \phi|^{p_i} + \int_{\Omega} |\partial_i \phi \cdot u|^{p_i}
\\
&=
\int_{\Omega} |\partial_i u|^{p_i} |\phi|^{p_i} + \int_{\Omega} |\partial_i \phi|^{p_i} |u|^{p_i}
\end{align*} \phi u |\partial_i \phi| p_i \leq p^* |\operatorname{supp} \partial_i \phi| + \|u\|_{p^*} D^{1,\vec{p}}(\Omega) L^{p^*}(\Omega) p_i \leq p^* \vec{p} = (p_1, ..., p_N) \Omega \subseteq \mathbb{R}^N D^{1,\vec{p}}(\Omega) C_c^{\infty}(\Omega) \begin{align*}
\|u\|_{\vec{p}} = \sum \limits_{i=1}^N \|\partial_i u \|_{p_i}
\end{align*} L^{p^*}(\Omega) p^* = Np/(N-p) 1/p = \sum 1/p_i","['integration', 'functional-analysis', 'sobolev-spaces', 'lp-spaces', 'smooth-functions']"
14,Alternative version of the Final Value theorem for Laplace Transform,Alternative version of the Final Value theorem for Laplace Transform,,"Let $f:[0,\infty) \to \mathbb{C}$ be a continuous and bounded function such that the limit $$\lim_{T\to\infty} \frac{1}{T} \int_{0}^{T}f(t)dt = d \quad\text{exists}.$$ Let $\hat{f}$ be the Laplace transform of f, i.e., $$\hat{f} = \int_{0}^{\infty}e^{-st}f(t)dt.$$ Prove that $$\lim_{s\to0,\:s>0} s\hat{f} = d.$$ I have tried different ways, but for now I still did not get the whole proof. I started with the following idea (non rigorous). Define $T=\frac{1}{s}$ , then $$\lim_{s\to0,\:s>0} s\hat{f} = \lim_{T\to\infty} \frac{1}{T}\hat{f}=\lim_{T\to\infty} \frac{1}{T} \int_{0}^{T}e^{-t/T}f(t)dt$$ where the integrand converges to $f(t)$ and therefore the dominant convergence theorem I guess could be used. However, there are two problems: (a) $T \in \mathbb{C}$ and therefore I am not sure I can do that, (b) I don't want to use the dominant convergence theorem since it was not introduced in class. A different approach is to use the fundamental theorem of calculus since f continuous and define: $$F(T) = F(0) + \int_{0}^{T}f(t)dt \quad \forall \; T \in [0,\infty).$$ Then from here use the formula for the Laplace transform of the derivative, but I did not manage to move on.","Let be a continuous and bounded function such that the limit Let be the Laplace transform of f, i.e., Prove that I have tried different ways, but for now I still did not get the whole proof. I started with the following idea (non rigorous). Define , then where the integrand converges to and therefore the dominant convergence theorem I guess could be used. However, there are two problems: (a) and therefore I am not sure I can do that, (b) I don't want to use the dominant convergence theorem since it was not introduced in class. A different approach is to use the fundamental theorem of calculus since f continuous and define: Then from here use the formula for the Laplace transform of the derivative, but I did not manage to move on.","f:[0,\infty) \to \mathbb{C} \lim_{T\to\infty} \frac{1}{T} \int_{0}^{T}f(t)dt = d \quad\text{exists}. \hat{f} \hat{f} = \int_{0}^{\infty}e^{-st}f(t)dt. \lim_{s\to0,\:s>0} s\hat{f} = d. T=\frac{1}{s} \lim_{s\to0,\:s>0} s\hat{f} = \lim_{T\to\infty} \frac{1}{T}\hat{f}=\lim_{T\to\infty} \frac{1}{T} \int_{0}^{T}e^{-t/T}f(t)dt f(t) T \in \mathbb{C} F(T) = F(0) + \int_{0}^{T}f(t)dt \quad \forall \; T \in [0,\infty).","['integration', 'functional-analysis', 'laplace-transform']"
15,Examples of integration by parts that work both ways,Examples of integration by parts that work both ways,,"Usually, integration by parts only works one way. For example, evaluating $\int xe^x\,dx$ can only be done by differentiating $x$ and integrating $e^x$ , but not the other way round, since $\int x^2e^x\,dx$ makes it more difficult than the original integral. However, the integral $$\int x\ln x\,dx$$ can be evaluated using integration by parts both ways: $$\int x\ln x\,dx=x\int \ln x\,dx - \int\left(x'\int\ln x\,dx\right)\,dx=x^2(\ln x-1)-\int x(\ln x-1)\,dx$$ and (directly), $$\int x\ln x\,dx=\ln x\int x\,dx-\int\left(\ln'x\int x\,dx\right)\,dx=\frac{x^2}2\ln x-\int\frac x2\,dx.$$ There are also trigonometric integrals that can do this. For instance, an integral consisting of $\sin$ and $\cos$ , as $\int \sin = -\cos$ and $\int \cos = \sin$ : $$\int \sin2x\cos3x\,dx.$$ @JamesArathoon has provided this one as well: $$\int x\arctan x\,dx$$ What are some other examples of integrals that have this property as well? I believe that such integrals are rather rare, so I don't want 'similar' integrals like multiplying by a constant or adding $1$ to the integrand. Of course, integrands of forms other than $xf(x)$ would be even better (and more challenging :)","Usually, integration by parts only works one way. For example, evaluating can only be done by differentiating and integrating , but not the other way round, since makes it more difficult than the original integral. However, the integral can be evaluated using integration by parts both ways: and (directly), There are also trigonometric integrals that can do this. For instance, an integral consisting of and , as and : @JamesArathoon has provided this one as well: What are some other examples of integrals that have this property as well? I believe that such integrals are rather rare, so I don't want 'similar' integrals like multiplying by a constant or adding to the integrand. Of course, integrands of forms other than would be even better (and more challenging :)","\int xe^x\,dx x e^x \int x^2e^x\,dx \int x\ln x\,dx \int x\ln x\,dx=x\int \ln x\,dx - \int\left(x'\int\ln x\,dx\right)\,dx=x^2(\ln x-1)-\int x(\ln x-1)\,dx \int x\ln x\,dx=\ln x\int x\,dx-\int\left(\ln'x\int x\,dx\right)\,dx=\frac{x^2}2\ln x-\int\frac x2\,dx. \sin \cos \int \sin = -\cos \int \cos = \sin \int \sin2x\cos3x\,dx. \int x\arctan x\,dx 1 xf(x)","['integration', 'indefinite-integrals']"
16,How to evaluate the integral $\int_0^{\infty}\mathrm{d}x\frac{\sin(x)\sin(ax)}{\pi^2-x^2}e^{-ibx^2}$?,How to evaluate the integral ?,\int_0^{\infty}\mathrm{d}x\frac{\sin(x)\sin(ax)}{\pi^2-x^2}e^{-ibx^2},Note that $a$ and $b$ are positive constants. Can this integral be evaluated in closed form ? $$\int_0^{\infty}\mathrm{d}x\frac{\sin(x)\sin(ax)}{\pi^2-x^2}e^{-ibx^2}$$,Note that $a$ and $b$ are positive constants. Can this integral be evaluated in closed form ? $$\int_0^{\infty}\mathrm{d}x\frac{\sin(x)\sin(ax)}{\pi^2-x^2}e^{-ibx^2}$$,,"['integration', 'complex-analysis', 'definite-integrals', 'special-functions', 'contour-integration']"
17,Evaluate $\int_{0}^{\infty}\frac{\log^2 x}{e^{x^2}}\mathrm{d}x$.,Evaluate .,\int_{0}^{\infty}\frac{\log^2 x}{e^{x^2}}\mathrm{d}x,"Evaluate $$\int_{0}^{\infty}\frac{\log^2 x}{e^{x^2}}\mathrm{d}x$$. EDIT Thank you for putting the question on hold and leaving me without any idea. Now that I have solved it I think it's a quite nice integral and so I'm glad I managed to do it on my own. Here is my solution. Exponent with negative argument in integral from $0$ to $\infty$ reminds us of the gamma function. Recall the definition: $\Gamma(s)=\int_{0}^{\infty}e^{-x}x^{s-1}\mathrm{d}x$. In this way the logarithm comes quite naturally as we take derivative of $\Gamma$ using diferentiation under the integral sign. Second power of the $\log$ comes from second derivative of $\Gamma$. The situation is a bit more complicated here, since we have $e$ to the power $x^2$. However this is not a great obstacle - just make the change $x\to\sqrt{x}$. Thus $\int_{0}^{\infty}e^{-x^2}x^{s-1}\mathrm{d}x=\int_{0}^{\infty}e^{-x}x^{\frac{s-1}{2}}\frac{1}{2\sqrt{x}}\mathrm{d}x=\frac{1}{2}\Gamma(\frac{s}{2})$. Hence $$\int_{0}^{\infty}e^{-x^2}\log^2 x =\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=1}\int_{0}^{\infty}e^{-x^2}x^{s-1}\mathrm{d}x=\frac{1}{8}\Gamma''\left(\frac{1}{2}\right).$$ The problem now reduces to finding second derivative of gamma at $\frac{1}{2}$. To find derivatives of $\Gamma$ it is helpful to find derivatives of $\log\Gamma$ - the so-called polygamma function. Representing $\Gamma$ as its Weierstrass factorization and taking $\log$ leads to series which are simple to differentiate and calculate. Recall that $$\Gamma(s)=\frac{e^{-\gamma s}}{s}\prod_{n\ge 1}^{\infty}\left(\left(1+\frac{s}{n}\right)^{-1} e^{s/n}\right).$$ Thus $$\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\left(-\gamma s-\log s+\sum_{n\ge 1}^{\infty}\left(-\log\left(1+\frac{s}{n}\right)+\frac{s}{n}\right)\right)=-\gamma-\frac{1}{s}+\sum_{n\ge 1}^{\infty}\left(-\frac{1}{n+s}+\frac{1}{n}\right)\Big|_{s=\frac{1}{2}}=-\gamma-2+2\sum_{n=1}^{\infty}\frac{1}{2n(2n+1)}=-\gamma+\log 4.$$ Now rewrite $\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{\Gamma'\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right) }$. So we have $$\Gamma'\left(\frac{1}{2}\right)=\Gamma\left(\frac{1}{2}\right)(-\gamma+\log 4)\ (1).$$ In the same manner we find second derivative of $\log\Gamma$ $$\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{1}{s^2}+\sum_{n\ge 1}^{\infty}\frac{1}{(n+s)^2}\Big|_{s=\frac{1}{2}}=4+4\sum_{n=1}^{\infty}\frac{1}{(2n+1)^2}=\frac{\pi^2}{2}.$$ Again we rewrite the derivative as differentiation of composite function - $\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=-\frac{\Gamma'\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right)^2}+\frac{\Gamma''\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right)}$. Now, taking into consideration what we previously obtained about the second derivative, the result about the first derivative and the fact $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$ we come to equation for the second derivative at $\frac{1}{2}$ which gives us $$\Gamma''\left(\frac{1}{2}\right)=\frac{\sqrt{\pi}}{2}\left(2\gamma^2+\pi^2+4\gamma \log 4+2\log^2 4\right).$$ Now mupltiply by $8$ and get the final result.","Evaluate $$\int_{0}^{\infty}\frac{\log^2 x}{e^{x^2}}\mathrm{d}x$$. EDIT Thank you for putting the question on hold and leaving me without any idea. Now that I have solved it I think it's a quite nice integral and so I'm glad I managed to do it on my own. Here is my solution. Exponent with negative argument in integral from $0$ to $\infty$ reminds us of the gamma function. Recall the definition: $\Gamma(s)=\int_{0}^{\infty}e^{-x}x^{s-1}\mathrm{d}x$. In this way the logarithm comes quite naturally as we take derivative of $\Gamma$ using diferentiation under the integral sign. Second power of the $\log$ comes from second derivative of $\Gamma$. The situation is a bit more complicated here, since we have $e$ to the power $x^2$. However this is not a great obstacle - just make the change $x\to\sqrt{x}$. Thus $\int_{0}^{\infty}e^{-x^2}x^{s-1}\mathrm{d}x=\int_{0}^{\infty}e^{-x}x^{\frac{s-1}{2}}\frac{1}{2\sqrt{x}}\mathrm{d}x=\frac{1}{2}\Gamma(\frac{s}{2})$. Hence $$\int_{0}^{\infty}e^{-x^2}\log^2 x =\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=1}\int_{0}^{\infty}e^{-x^2}x^{s-1}\mathrm{d}x=\frac{1}{8}\Gamma''\left(\frac{1}{2}\right).$$ The problem now reduces to finding second derivative of gamma at $\frac{1}{2}$. To find derivatives of $\Gamma$ it is helpful to find derivatives of $\log\Gamma$ - the so-called polygamma function. Representing $\Gamma$ as its Weierstrass factorization and taking $\log$ leads to series which are simple to differentiate and calculate. Recall that $$\Gamma(s)=\frac{e^{-\gamma s}}{s}\prod_{n\ge 1}^{\infty}\left(\left(1+\frac{s}{n}\right)^{-1} e^{s/n}\right).$$ Thus $$\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\left(-\gamma s-\log s+\sum_{n\ge 1}^{\infty}\left(-\log\left(1+\frac{s}{n}\right)+\frac{s}{n}\right)\right)=-\gamma-\frac{1}{s}+\sum_{n\ge 1}^{\infty}\left(-\frac{1}{n+s}+\frac{1}{n}\right)\Big|_{s=\frac{1}{2}}=-\gamma-2+2\sum_{n=1}^{\infty}\frac{1}{2n(2n+1)}=-\gamma+\log 4.$$ Now rewrite $\frac{\mathrm{d}}{\mathrm{d}s}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{\Gamma'\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right) }$. So we have $$\Gamma'\left(\frac{1}{2}\right)=\Gamma\left(\frac{1}{2}\right)(-\gamma+\log 4)\ (1).$$ In the same manner we find second derivative of $\log\Gamma$ $$\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=\frac{1}{s^2}+\sum_{n\ge 1}^{\infty}\frac{1}{(n+s)^2}\Big|_{s=\frac{1}{2}}=4+4\sum_{n=1}^{\infty}\frac{1}{(2n+1)^2}=\frac{\pi^2}{2}.$$ Again we rewrite the derivative as differentiation of composite function - $\frac{\mathrm{d}^2}{\mathrm{d}s^2}\Big|_{s=\frac{1}{2}}\log\Gamma(s)=-\frac{\Gamma'\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right)^2}+\frac{\Gamma''\left(\frac{1}{2}\right)}{\Gamma\left(\frac{1}{2}\right)}$. Now, taking into consideration what we previously obtained about the second derivative, the result about the first derivative and the fact $\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}$ we come to equation for the second derivative at $\frac{1}{2}$ which gives us $$\Gamma''\left(\frac{1}{2}\right)=\frac{\sqrt{\pi}}{2}\left(2\gamma^2+\pi^2+4\gamma \log 4+2\log^2 4\right).$$ Now mupltiply by $8$ and get the final result.",,"['integration', 'definite-integrals']"
18,Does this integral $\int_0^\infty \frac{dx}{(1+e^x)(a+x)}$ have a closed form?,Does this integral  have a closed form?,\int_0^\infty \frac{dx}{(1+e^x)(a+x)},"Note that $a>0$, thus I'm not sure if we can apply residues here. (For $a=0$ the integral doesn't converge). $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}$$ Despite the simple expression under the integral, I didn't find it in G-R book. I attempted the most straightforward way - geometric series - since $e^x \geq 1$. $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty (-1)^{k+1} \int_0^\infty \frac{e^{-kx}dx}{a+x}$$ The integrals on the right can be expressed using incomplete gamma function: $$\int_0^\infty \frac{e^{-kx}dx}{a+x}=\frac{e^{ka}}{k} \Gamma(0,ka)$$ We obtain: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty (-1)^{k+1} \frac{e^{ka}}{k} \Gamma(0,ka)$$ This is correct, but not very useful, since each incomplete gamma just disguises an integral. It can be computed independently by: $$\Gamma (0,t)=\cfrac{\exp(-t)}{t+1-\cfrac{1}{t+3-\cfrac{4}{t+5-\cfrac{9}{t+7-\cdots}}}}$$ Thus I suppose we can express the integral as: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty \frac{(-1)^{k+1}}{k}  \cfrac{1}{ka+1-\cfrac{1}{ka+3-\cfrac{4}{ka+5-\cfrac{9}{ka+7-\cdots}}}}$$ Amusing, but again, not very useful. Does this integral have a closed form? If so, what is it and how do we find it? Edit Another interesting expression for incomplete gamma from DLMF : $$\Gamma (0,t)=e^{-t} \sum_{n=0}^\infty \frac{L_n (t)}{n+1}$$ Here $L_n (t)$ are Laguerre polynomials. This series converges extremely slowly (and oscillates), so it seem quite useless for computation, however gives a pretty expression for the integral: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty \frac{(-1)^{k+1}}{k}  \sum_{n=0}^\infty \frac{L_n (ka)}{n+1} $$ Note, that the continued fraction above converges much faster than the series.","Note that $a>0$, thus I'm not sure if we can apply residues here. (For $a=0$ the integral doesn't converge). $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}$$ Despite the simple expression under the integral, I didn't find it in G-R book. I attempted the most straightforward way - geometric series - since $e^x \geq 1$. $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty (-1)^{k+1} \int_0^\infty \frac{e^{-kx}dx}{a+x}$$ The integrals on the right can be expressed using incomplete gamma function: $$\int_0^\infty \frac{e^{-kx}dx}{a+x}=\frac{e^{ka}}{k} \Gamma(0,ka)$$ We obtain: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty (-1)^{k+1} \frac{e^{ka}}{k} \Gamma(0,ka)$$ This is correct, but not very useful, since each incomplete gamma just disguises an integral. It can be computed independently by: $$\Gamma (0,t)=\cfrac{\exp(-t)}{t+1-\cfrac{1}{t+3-\cfrac{4}{t+5-\cfrac{9}{t+7-\cdots}}}}$$ Thus I suppose we can express the integral as: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty \frac{(-1)^{k+1}}{k}  \cfrac{1}{ka+1-\cfrac{1}{ka+3-\cfrac{4}{ka+5-\cfrac{9}{ka+7-\cdots}}}}$$ Amusing, but again, not very useful. Does this integral have a closed form? If so, what is it and how do we find it? Edit Another interesting expression for incomplete gamma from DLMF : $$\Gamma (0,t)=e^{-t} \sum_{n=0}^\infty \frac{L_n (t)}{n+1}$$ Here $L_n (t)$ are Laguerre polynomials. This series converges extremely slowly (and oscillates), so it seem quite useless for computation, however gives a pretty expression for the integral: $$\int_0^\infty \frac{dx}{(1+e^x)(a+x)}=\sum_{k=1}^\infty \frac{(-1)^{k+1}}{k}  \sum_{n=0}^\infty \frac{L_n (ka)}{n+1} $$ Note, that the continued fraction above converges much faster than the series.",,"['integration', 'definite-integrals', 'closed-form', 'continued-fractions']"
19,Simpler proof of an integral representation of Bessel function of the first kind $J_n(x)$,Simpler proof of an integral representation of Bessel function of the first kind,J_n(x),"While doing research in electrical engineering, I derived the following integral representation of the Bessel function of the first kind: $$J_n(x)=\frac{e^{in\pi/2}}{2\pi}\int_0^{2\pi}e^{i(n\tau-x\cos\tau)}\mathrm{d}\tau\tag{1}$$ My derivation, which I include below, is long and ugly.  I am wondering if there is a more elegant proof of (1) using basic facts about other integral representations of the Bessel function, trig identities, and, perhaps, clever integration techniques.  The integral representation for Bessel function (found on wikipedia page ) that looks similar to mine is: $$J_n(x)=\frac{1}{2\pi}\int_{-\pi}^{\pi}e^{i(n\tau-x\sin\tau)}\mathrm{d}\tau. \tag{2}$$ Gradshteyn and Ryzhik (G&R) give the same expression in a slightly different form as formula 8.411.1 in the 7th edition.  However, I failed to convert (2) into (1) using simple substitution.  Does anyone have any other ideas? My LONG proof of (1) First, I use Euler's formula to break the integrand in (1) into in-phase and quadrature components, and apply the angle sum identities : $$\begin{align}e^{i(n\tau-x\cos\tau)}&=\cos(n\tau-x\cos\tau)+i\sin(n\tau-x\cos\tau)\\ &=\cos(n\tau)\cos(x\cos\tau)\tag{a}\\ &\phantom{=}+\sin(n\tau)\sin(x\cos\tau)\tag{b}\\ &\phantom{=}+i\sin(n\tau)\cos(x\cos\tau)\tag{c}\\ &\phantom{=}-i\cos(n\tau)\sin(x\cos\tau)\tag{d} \end{align}$$ Now let's integrate (a)-(d) in turn.  First, for (a), note that: $$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\cos(x\cos(\tau+\pi))\mathrm{d}\tau\\ &=(-1)^n\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\tag{a1}, \end{align}$$ where (a1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$. By formula 3.715.18 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=\pi\cos\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^n)\pi\cos\left(\frac{n\pi}{2}\right)J_n(x)\\ &=2\pi\cos\left(\frac{n\pi}{2}\right)J_n(x),\tag{a2} \end{align}$$ where (a2) is because when $n$ is odd, $\cos\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Now let's integrate (b). First consider odd $n$: $$\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau,$$ because $\sin(n(\tau+\pi))\sin(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to the negation of the sine (and cosine) from the shift by odd multiples of $\pi$, or, formally, $\sin(\theta+n\pi)=(-1)^n\sin\theta$ and the fact that $\sin(-\theta)=-\sin\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\sin(x\cos(\pi-\tau))\mathrm{d}\tau\tag{b1}\\ &=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b2}, \end{align}$$ where (b1) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (b2) is since $\sin(n\pi-\theta)=\sin(\theta)$ for odd $n$ and $\cos(\pi-\theta)=-\cos(\theta)$. Now let's integrate (b) with even $n$: $$\begin{align}\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\sin(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{b3}\\ &=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b4}, \end{align}$$ where (b3) is due to the substitution of $\tau=2\pi-\tau'$ (again, the prime is dropped after substitution is made) and (b4) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for an integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now let's integrate (c). Consider odd $n$ (let's omit the imaginary unit): $$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\cos(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{c1}\\ &=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0,\tag{c2}\\ \end{align}$$ where (c1) is due to the substitution of $\tau=2\pi-\tau'$ (the prime is dropped after substitution is made) and (c2) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now integrate (c) with even $n$ (again, let's omit the imaginary unit): $$\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau,$$ because $\sin(n(\tau+\pi))\cos(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to $\sin(\theta+n\pi)=\sin\theta$ for even $n$, and $\cos(-\theta)=\cos\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\cos(x\cos(\pi-\tau))\mathrm{d}\tau\tag{c3}\\ &=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0\tag{c4}, \end{align}$$ where (c3) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (c4) is since $\sin(n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for even $n$ and $\cos(-\theta)=\cos(\theta)$. Finally, we integrate (d), omitting the negative imaginary unit for now. First, note that  $$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\sin(x\cos(\tau+\pi))\mathrm{d}\tau\\ &=(-1)^{n+1}\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\tag{d1}, \end{align}$$ where (d1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$ and by the fact that $\sin(-\theta)=-\sin\theta$. By formula 3.715.13 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=\pi\sin\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^{n+1})\pi\sin\left(\frac{n\pi}{2}\right)J_n(x)\\ &=2\pi\sin\left(\frac{n\pi}{2}\right)J_n(x),\tag{d2} \end{align}$$ where (d2) is because when $n$ is even, $\sin\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Combining all the terms, using Euler's formula, and solving for $J_n(x)$, we arrive at (1).  Surely there is a better way...","While doing research in electrical engineering, I derived the following integral representation of the Bessel function of the first kind: $$J_n(x)=\frac{e^{in\pi/2}}{2\pi}\int_0^{2\pi}e^{i(n\tau-x\cos\tau)}\mathrm{d}\tau\tag{1}$$ My derivation, which I include below, is long and ugly.  I am wondering if there is a more elegant proof of (1) using basic facts about other integral representations of the Bessel function, trig identities, and, perhaps, clever integration techniques.  The integral representation for Bessel function (found on wikipedia page ) that looks similar to mine is: $$J_n(x)=\frac{1}{2\pi}\int_{-\pi}^{\pi}e^{i(n\tau-x\sin\tau)}\mathrm{d}\tau. \tag{2}$$ Gradshteyn and Ryzhik (G&R) give the same expression in a slightly different form as formula 8.411.1 in the 7th edition.  However, I failed to convert (2) into (1) using simple substitution.  Does anyone have any other ideas? My LONG proof of (1) First, I use Euler's formula to break the integrand in (1) into in-phase and quadrature components, and apply the angle sum identities : $$\begin{align}e^{i(n\tau-x\cos\tau)}&=\cos(n\tau-x\cos\tau)+i\sin(n\tau-x\cos\tau)\\ &=\cos(n\tau)\cos(x\cos\tau)\tag{a}\\ &\phantom{=}+\sin(n\tau)\sin(x\cos\tau)\tag{b}\\ &\phantom{=}+i\sin(n\tau)\cos(x\cos\tau)\tag{c}\\ &\phantom{=}-i\cos(n\tau)\sin(x\cos\tau)\tag{d} \end{align}$$ Now let's integrate (a)-(d) in turn.  First, for (a), note that: $$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\cos(x\cos(\tau+\pi))\mathrm{d}\tau\\ &=(-1)^n\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\tag{a1}, \end{align}$$ where (a1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$. By formula 3.715.18 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=\pi\cos\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^n)\pi\cos\left(\frac{n\pi}{2}\right)J_n(x)\\ &=2\pi\cos\left(\frac{n\pi}{2}\right)J_n(x),\tag{a2} \end{align}$$ where (a2) is because when $n$ is odd, $\cos\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Now let's integrate (b). First consider odd $n$: $$\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau,$$ because $\sin(n(\tau+\pi))\sin(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to the negation of the sine (and cosine) from the shift by odd multiples of $\pi$, or, formally, $\sin(\theta+n\pi)=(-1)^n\sin\theta$ and the fact that $\sin(-\theta)=-\sin\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\sin(x\cos(\pi-\tau))\mathrm{d}\tau\tag{b1}\\ &=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b2}, \end{align}$$ where (b1) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (b2) is since $\sin(n\pi-\theta)=\sin(\theta)$ for odd $n$ and $\cos(\pi-\theta)=-\cos(\theta)$. Now let's integrate (b) with even $n$: $$\begin{align}\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\sin(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{b3}\\ &=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b4}, \end{align}$$ where (b3) is due to the substitution of $\tau=2\pi-\tau'$ (again, the prime is dropped after substitution is made) and (b4) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for an integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now let's integrate (c). Consider odd $n$ (let's omit the imaginary unit): $$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\cos(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{c1}\\ &=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0,\tag{c2}\\ \end{align}$$ where (c1) is due to the substitution of $\tau=2\pi-\tau'$ (the prime is dropped after substitution is made) and (c2) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now integrate (c) with even $n$ (again, let's omit the imaginary unit): $$\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau,$$ because $\sin(n(\tau+\pi))\cos(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to $\sin(\theta+n\pi)=\sin\theta$ for even $n$, and $\cos(-\theta)=\cos\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\ &\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\cos(x\cos(\pi-\tau))\mathrm{d}\tau\tag{c3}\\ &=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0\tag{c4}, \end{align}$$ where (c3) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (c4) is since $\sin(n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for even $n$ and $\cos(-\theta)=\cos(\theta)$. Finally, we integrate (d), omitting the negative imaginary unit for now. First, note that  $$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\sin(x\cos(\tau+\pi))\mathrm{d}\tau\\ &=(-1)^{n+1}\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\tag{d1}, \end{align}$$ where (d1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$ and by the fact that $\sin(-\theta)=-\sin\theta$. By formula 3.715.13 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=\pi\sin\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^{n+1})\pi\sin\left(\frac{n\pi}{2}\right)J_n(x)\\ &=2\pi\sin\left(\frac{n\pi}{2}\right)J_n(x),\tag{d2} \end{align}$$ where (d2) is because when $n$ is even, $\sin\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Combining all the terms, using Euler's formula, and solving for $J_n(x)$, we arrive at (1).  Surely there is a better way...",,"['integration', 'definite-integrals', 'special-functions', 'bessel-functions']"
20,Composition of a Dirac delta and a function in higher dimensions [duplicate],Composition of a Dirac delta and a function in higher dimensions [duplicate],,"This question already has answers here : Property of Dirac delta function in $\mathbb{R}^n$ (3 answers) Closed 2 years ago . Coming from a physics background, I was taught the formula for the composition of a Dirac delta and a function. Indeed, if we consider a nice function $ f : \mathbb{R} \to \mathbb{R} $, one can write $$ \delta_{\rm D} (f(x)) = \sum_{x_{0} \in \mathcal{Z}_{f}} \frac{\delta_{\rm D} (x \!-\! x_{0})}{|f'(x_{0})|} \, , $$ where ${ \mathcal{Z}_{f} = \{ x_{0} \,|\, f(x_{0}) = 0 \} }$ is the set of all the zeroes of $f$, and where we assumed that all the zeroes of $f$ are simple, so that ${f'(x_{0}) \neq 0}$. My question is now related to what would happen in higher dimensions. (Such formulas are often encountered in kinetic theory). Let's assume I want to compute the double integral $$ I = \iint dx \, dy \, \delta_{\rm D} (f (x,y)) \, g(x,y) \, ,  $$ My questions are then the following ones : Let's assume that $f(x,y) = f(x)$, so that $y$ is absent from the Dirac delta. Provided that the zeroes of $f$ are simple, do we have ? $$ I = \sum_{x_{0} \in \mathcal{Z}{f}} \frac{1}{|f'(x_{0})|} \int dy \, g(x_{0} , y) $$ Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ is made of isolated points . Can we compute $I$ ? If yes, how can it be done ? Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ can be parametrized under the form ${ \mathcal{Z}_{f} = \{ (x(\lambda),y(\lambda)) \,|\, \lambda \in \mathbb{R} \} }$, i.e. the zeroes of ${ f(x,y) }$ are along a given nice curve in $\mathbb{R}^{2}$. Is it possible to compute $I$ ? Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ is even more filled than a line, so that the zeroes of $f$ constitute a closed region of $\mathbb{R}^{2}$ of non-zero volume . (I am not sure of the best way to phrase it...) For example, ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, x_{0}^{2} \!+\! y_{0}^{2} \leq 1 \} }$. Does the double integral $I$ have a meaning ? Finally, are there any other sorts of others $\mathcal{Z}_{f}$ for which the integral $I$ could have a meaning and be computed ?","This question already has answers here : Property of Dirac delta function in $\mathbb{R}^n$ (3 answers) Closed 2 years ago . Coming from a physics background, I was taught the formula for the composition of a Dirac delta and a function. Indeed, if we consider a nice function $ f : \mathbb{R} \to \mathbb{R} $, one can write $$ \delta_{\rm D} (f(x)) = \sum_{x_{0} \in \mathcal{Z}_{f}} \frac{\delta_{\rm D} (x \!-\! x_{0})}{|f'(x_{0})|} \, , $$ where ${ \mathcal{Z}_{f} = \{ x_{0} \,|\, f(x_{0}) = 0 \} }$ is the set of all the zeroes of $f$, and where we assumed that all the zeroes of $f$ are simple, so that ${f'(x_{0}) \neq 0}$. My question is now related to what would happen in higher dimensions. (Such formulas are often encountered in kinetic theory). Let's assume I want to compute the double integral $$ I = \iint dx \, dy \, \delta_{\rm D} (f (x,y)) \, g(x,y) \, ,  $$ My questions are then the following ones : Let's assume that $f(x,y) = f(x)$, so that $y$ is absent from the Dirac delta. Provided that the zeroes of $f$ are simple, do we have ? $$ I = \sum_{x_{0} \in \mathcal{Z}{f}} \frac{1}{|f'(x_{0})|} \int dy \, g(x_{0} , y) $$ Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ is made of isolated points . Can we compute $I$ ? If yes, how can it be done ? Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ can be parametrized under the form ${ \mathcal{Z}_{f} = \{ (x(\lambda),y(\lambda)) \,|\, \lambda \in \mathbb{R} \} }$, i.e. the zeroes of ${ f(x,y) }$ are along a given nice curve in $\mathbb{R}^{2}$. Is it possible to compute $I$ ? Let's assume that the set ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, f(x_{0},y_{0}) \} }$ is even more filled than a line, so that the zeroes of $f$ constitute a closed region of $\mathbb{R}^{2}$ of non-zero volume . (I am not sure of the best way to phrase it...) For example, ${ \mathcal{Z}_{f} = \{ (x_{0},y_{0}) \,|\, x_{0}^{2} \!+\! y_{0}^{2} \leq 1 \} }$. Does the double integral $I$ have a meaning ? Finally, are there any other sorts of others $\mathcal{Z}_{f}$ for which the integral $I$ could have a meaning and be computed ?",,"['integration', 'analysis', 'dirac-delta']"
21,Discrete analogue of Green's theorem,Discrete analogue of Green's theorem,,"Following formula concerning finite differences is in a way a discrete analogue of the fundamental theorem of calculus: $$\sum_{n=a}^b \Delta f(n) = f(b+1) - f(a) $$ We can think about the Green's theorem as a two-dimensional generalization of fundamental theorem of calculus, so I'm interested is there a discrete analogue of Green's theorem?","Following formula concerning finite differences is in a way a discrete analogue of the fundamental theorem of calculus: $$\sum_{n=a}^b \Delta f(n) = f(b+1) - f(a) $$ We can think about the Green's theorem as a two-dimensional generalization of fundamental theorem of calculus, so I'm interested is there a discrete analogue of Green's theorem?",,"['integration', 'discrete-mathematics', 'soft-question']"
22,power series for $\int_0^x e^{-t^2}dt$,power series for,\int_0^x e^{-t^2}dt,"Use a known power series expansion to find the power series   representation of the integral function $g(x) =\int_0^x e^{-t^2}dt$   centered at $a=0$ My approach Note that $g'(x) = e^{-x^2}$. We also know the Maclaurin Series for   $e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}$. Then, $$g'(x)=e^{-x^2} = \sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}$$    $$g(x) = \int  \bigg[\sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}\bigg]  dx$$ $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{n!} \int x^{2n}dx $$    $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)} +K,  \text{  where $K$ is unknown}$$ Consider $x=0$, we figured out that $g(0) = 0 +K = 0$, hence $K=0$. Hence   $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)}$$ Is this right? I cannot differentiate between power series and Maclaurin series or stuffs like that. Can anybody clarify on this too?","Use a known power series expansion to find the power series   representation of the integral function $g(x) =\int_0^x e^{-t^2}dt$   centered at $a=0$ My approach Note that $g'(x) = e^{-x^2}$. We also know the Maclaurin Series for   $e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}$. Then, $$g'(x)=e^{-x^2} = \sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}$$    $$g(x) = \int  \bigg[\sum_{n=0}^{\infty} \frac{(-x^2)^n}{n!}\bigg]  dx$$ $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{n!} \int x^{2n}dx $$    $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)} +K,  \text{  where $K$ is unknown}$$ Consider $x=0$, we figured out that $g(0) = 0 +K = 0$, hence $K=0$. Hence   $$g(x) = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{n!(2n+1)}$$ Is this right? I cannot differentiate between power series and Maclaurin series or stuffs like that. Can anybody clarify on this too?",,"['integration', 'sequences-and-series', 'power-series']"
23,Integrals 3.384 from Gradshteyn and Ryzhik,Integrals 3.384 from Gradshteyn and Ryzhik,,"I'm interested in understanding the computation of $$\int_{-\infty}^\infty\frac{e^{-ip x}}{(1 + ix)^{2u}(1-ix)^{2v}}\mathrm{d}x,$$ which is evaluated in 3.384.9 of Gradshteyn and Rhysik for sufficiently large $u, v$ as $$(2\pi) 2^{-u-v} \frac{p^{u+v-1}}{\Gamma(2v)}W_{v-u, \frac 12 - v - u}(2p).$$ (I'm pretty sure I didn't mess up my transcription of that). The reference given in Gradshteyn and Rhysik is Erdelyi's Table of Integrals, volume I, pg 119 equation 12 (actually, my copy of Gradshteyn and Rhysik has a typo and says pg 19 equation 12 - so it goes). But in Erdelyi's Table, there are no proofs nor references. By $W$, I mean Whittaker's $W$ function. Since I don't quite know the most convenient characterization to give as I don't know how to do this integral (yet), I might be misleading you. But I think the convenient characterization will be $$ W_{\lambda, \mu}(z) = \frac{z^{\mu + \frac 12} e^{-z/2}}{\Gamma(\mu - \lambda + \frac 12)} \int_0^\infty t^{\mu - \lambda - \frac 12}e^{-t}\left(1 + \frac{t}{z}\right)^{\mu + \lambda - \frac 12} \mathrm{d}t,$$ for real part of $\mu - \lambda > -\frac 12$ and $|\arg z| < \pi$. Do you know how to compute this integral, or alternatively have a reference for it?","I'm interested in understanding the computation of $$\int_{-\infty}^\infty\frac{e^{-ip x}}{(1 + ix)^{2u}(1-ix)^{2v}}\mathrm{d}x,$$ which is evaluated in 3.384.9 of Gradshteyn and Rhysik for sufficiently large $u, v$ as $$(2\pi) 2^{-u-v} \frac{p^{u+v-1}}{\Gamma(2v)}W_{v-u, \frac 12 - v - u}(2p).$$ (I'm pretty sure I didn't mess up my transcription of that). The reference given in Gradshteyn and Rhysik is Erdelyi's Table of Integrals, volume I, pg 119 equation 12 (actually, my copy of Gradshteyn and Rhysik has a typo and says pg 19 equation 12 - so it goes). But in Erdelyi's Table, there are no proofs nor references. By $W$, I mean Whittaker's $W$ function. Since I don't quite know the most convenient characterization to give as I don't know how to do this integral (yet), I might be misleading you. But I think the convenient characterization will be $$ W_{\lambda, \mu}(z) = \frac{z^{\mu + \frac 12} e^{-z/2}}{\Gamma(\mu - \lambda + \frac 12)} \int_0^\infty t^{\mu - \lambda - \frac 12}e^{-t}\left(1 + \frac{t}{z}\right)^{\mu + \lambda - \frac 12} \mathrm{d}t,$$ for real part of $\mu - \lambda > -\frac 12$ and $|\arg z| < \pi$. Do you know how to compute this integral, or alternatively have a reference for it?",,"['reference-request', 'definite-integrals', 'integration']"
24,Complex integral $1/(z^2+1)$ along circle $|z|=2$,Complex integral  along circle,1/(z^2+1) |z|=2,"I want to compute the complex integral $$\int_{|z|=2}\frac{1}{z^2+1}dz$$ I write it as a partial fraction $\dfrac12i\int_{|z|=2}\dfrac{1}{z+i}dz-\dfrac12i\int_{|z|=2}\dfrac{1}{z-i}dz.$ Let $f(z)=1$. Then by Cauchy's formula, the first integral is $2\pi if(-i)=2\pi i$. Similarly, the second integral is $2\pi i$, so the whole thing is $0$. Is this correct, and what would be other (quicker) ways to do it?","I want to compute the complex integral $$\int_{|z|=2}\frac{1}{z^2+1}dz$$ I write it as a partial fraction $\dfrac12i\int_{|z|=2}\dfrac{1}{z+i}dz-\dfrac12i\int_{|z|=2}\dfrac{1}{z-i}dz.$ Let $f(z)=1$. Then by Cauchy's formula, the first integral is $2\pi if(-i)=2\pi i$. Similarly, the second integral is $2\pi i$, so the whole thing is $0$. Is this correct, and what would be other (quicker) ways to do it?",,"['integration', 'complex-analysis']"
25,Matrix-product-integrals?,Matrix-product-integrals?,,"Whereas the conventional ""sum integral"" is $$ \lim_{\Delta x\to 0} \sum_i f(x_i)\,\Delta x, $$ a ""product integral"" is $$ \lim_{\Delta x\to 0} \prod_i f(x_i)^{\Delta x}. $$ Now you're thinking: just take logarithms and it's a ""sum integral"", so why bother having this additional concept? Somewhere I heard this answer proposed: Because one does this with matrix multiplication rather than multiplication of numbers. So: Is this actually done?  What's been published on it? What are the most interesting results about it? What's it's used for?","Whereas the conventional ""sum integral"" is $$ \lim_{\Delta x\to 0} \sum_i f(x_i)\,\Delta x, $$ a ""product integral"" is $$ \lim_{\Delta x\to 0} \prod_i f(x_i)^{\Delta x}. $$ Now you're thinking: just take logarithms and it's a ""sum integral"", so why bother having this additional concept? Somewhere I heard this answer proposed: Because one does this with matrix multiplication rather than multiplication of numbers. So: Is this actually done?  What's been published on it? What are the most interesting results about it? What's it's used for?",,"['matrices', 'reference-request', 'integration']"
26,"Let $f:[a,b]\to\mathbb R$ be Riemann integrable and $f>0$. Prove that $\int_a^bf>0$. (No Measure theory) [closed]",Let  be Riemann integrable and . Prove that . (No Measure theory) [closed],"f:[a,b]\to\mathbb R f>0 \int_a^bf>0","Closed. This question is off-topic . It is not currently accepting answers. Want to improve this question? Update the question so it's on-topic for Mathematics Stack Exchange. Closed 11 years ago . Improve this question Is the Riemann integral of a strictly positive function positive? This is not a duplicate. I'm specifically interested in a proof not involving Measure Theory. The thread above uses the fact that $f$ has to be continuous at some point and as such that its intergral is bounded below by a positive value. The question I posted and that was marked as a duplicate is as follows: Here's a link to it: Let $f:[a,b]\to\mathbb R$ be Riemann integrable and $f>0$. Prove that $\int_a^bf>0$. (Without Measure theory) ""I've been struggling with this for a while, and I have a couple of leads that kind of got me nowhere: At first I thought that if $f$ is continuous somewhere then the integral will be $>0$. So, if the integral was $0$ then that would mean it would need to be nowhere continuous. That seemed unlikely to me, but I couldn't prove the existence of a point at which it is continuous. For the integral to be $0$ it would necessitate that for any sub interval of $[a,b]$ the function's infimum would have to be $0$. Also seems weird for $f>0$. Again, got me nowhere. Thank you!"" If you feel this proof that I'm looking for is impossible to produce, please state why you think so. I have reasons to believe this is feasible (One being as it appeared as a a starred question in my homework assignment when we have only just started learning about integration a few weeks ago). Edits: Wasn't aware that I could file a claim to re-open a post. I'll keep that in mind. Also, I feel that the contradiction should come from assuming that $f$ is nowhere continuous, and then somehow show that there exists $x\in[a,b]$ such that $f(x)=0$, contradicting the definition of $f$.","Closed. This question is off-topic . It is not currently accepting answers. Want to improve this question? Update the question so it's on-topic for Mathematics Stack Exchange. Closed 11 years ago . Improve this question Is the Riemann integral of a strictly positive function positive? This is not a duplicate. I'm specifically interested in a proof not involving Measure Theory. The thread above uses the fact that $f$ has to be continuous at some point and as such that its intergral is bounded below by a positive value. The question I posted and that was marked as a duplicate is as follows: Here's a link to it: Let $f:[a,b]\to\mathbb R$ be Riemann integrable and $f>0$. Prove that $\int_a^bf>0$. (Without Measure theory) ""I've been struggling with this for a while, and I have a couple of leads that kind of got me nowhere: At first I thought that if $f$ is continuous somewhere then the integral will be $>0$. So, if the integral was $0$ then that would mean it would need to be nowhere continuous. That seemed unlikely to me, but I couldn't prove the existence of a point at which it is continuous. For the integral to be $0$ it would necessitate that for any sub interval of $[a,b]$ the function's infimum would have to be $0$. Also seems weird for $f>0$. Again, got me nowhere. Thank you!"" If you feel this proof that I'm looking for is impossible to produce, please state why you think so. I have reasons to believe this is feasible (One being as it appeared as a a starred question in my homework assignment when we have only just started learning about integration a few weeks ago). Edits: Wasn't aware that I could file a claim to re-open a post. I'll keep that in mind. Also, I feel that the contradiction should come from assuming that $f$ is nowhere continuous, and then somehow show that there exists $x\in[a,b]$ such that $f(x)=0$, contradicting the definition of $f$.",,"['integration', 'definite-integrals']"
27,"Evaluating $\int_0^{\infty } \frac{x^{\alpha}}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx \quad \alpha = \frac{9}{2},3,\cdots $",Evaluating,"\int_0^{\infty } \frac{x^{\alpha}}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx \quad \alpha = \frac{9}{2},3,\cdots ","I'm looking for an analytical solution of the following two integrals $$\int_0^{\infty } \frac{x^{9/2}}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx$$ and $$\int_0^{\infty } \frac{x^3}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx$$ with $$A,B\in\mathbb{R} \land A,B\geq0$$ Wolfram Alpha gives up unfortunately. For $B=0$ solutions exist. These integrals have a physics background. They result from the Cronwell-Weisskopf approximation of calculating the energy averaged doping scattering times to get the dielectric function of a doped semiconductor. The usual theory is based on non-degenerate statistics, whereas I'm working on an implementation using degenerate statistics (needed for high doping concentrations). Within this framework the above integrals occur.","I'm looking for an analytical solution of the following two integrals $$\int_0^{\infty } \frac{x^{9/2}}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx$$ and $$\int_0^{\infty } \frac{x^3}{\left(A+x^3\right) \left(B+e^x\right)} \, \mathrm dx$$ with $$A,B\in\mathbb{R} \land A,B\geq0$$ Wolfram Alpha gives up unfortunately. For $B=0$ solutions exist. These integrals have a physics background. They result from the Cronwell-Weisskopf approximation of calculating the energy averaged doping scattering times to get the dielectric function of a doped semiconductor. The usual theory is based on non-degenerate statistics, whereas I'm working on an implementation using degenerate statistics (needed for high doping concentrations). Within this framework the above integrals occur.",,['integration']
28,the solution for an integral including exponential integral function,the solution for an integral including exponential integral function,,I have the following integral $$\int_c^\infty{x^{a-1} e^{\ p \ x} \ \mathrm{Ei}(-p\ x) \ \mathrm{d}x}.$$ I'd like you to help me to evaluate it or giving me a hint to proceed.,I have the following integral $$\int_c^\infty{x^{a-1} e^{\ p \ x} \ \mathrm{Ei}(-p\ x) \ \mathrm{d}x}.$$ I'd like you to help me to evaluate it or giving me a hint to proceed.,,"['integration', 'definite-integrals', 'improper-integrals', 'special-functions']"
29,Integrating $\frac{x dx}{\sin x+\cos x}$,Integrating,\frac{x dx}{\sin x+\cos x},I am trying to carry out this integration but I seem to be going wrong: $$I=\int_{0}^{\frac{\pi}{2}}\frac{x dx}{\sin x+\cos x}=\int_{0}^{\frac{\pi}{2}}\frac{(\frac{\pi}{2}-x) dx}{\sin(\frac{\pi}{2}-x)+\cos (\frac{\pi}{2}-x)} \implies 2I=\frac{\pi}{2}\int_{0}^{\frac{\pi}{2}}\frac{ dx}{\sin x+\cos x}$$ I am not able to proceed from here.,I am trying to carry out this integration but I seem to be going wrong: $$I=\int_{0}^{\frac{\pi}{2}}\frac{x dx}{\sin x+\cos x}=\int_{0}^{\frac{\pi}{2}}\frac{(\frac{\pi}{2}-x) dx}{\sin(\frac{\pi}{2}-x)+\cos (\frac{\pi}{2}-x)} \implies 2I=\frac{\pi}{2}\int_{0}^{\frac{\pi}{2}}\frac{ dx}{\sin x+\cos x}$$ I am not able to proceed from here.,,['integration']
30,Contour Integral of Gamma Functions from Knuth Paper,Contour Integral of Gamma Functions from Knuth Paper,,"I was attempting to go through the addendum of Chapter 21 of Donald Knuth's Selected Papers on Analysis of Algorithms . In a lengthy derivation, Knuth asymptotically expands the following integral: $$ \frac{1}{2 \pi i} \int_{c-i \infty}^{c + i \infty } \frac{\Gamma(s-5/2)\Gamma(4-s) m^s \zeta(s)}{\Gamma(3/2)} ds \sim \frac{\Gamma(-3/2)\Gamma(3)}{\Gamma(3/2)} m + \sum_{n=0}^\infty \frac{(-1)^n}{n!} \frac{\Gamma(3/2+n)}{\Gamma(3/2)} m^{5/2-n} \zeta(5/2-n) $$ where $\frac{5}{2} < c < 4$ . Knuth only states that the asymptotic series is obtained ""by decreasing c as far as we like and adding up the residues of the poles of the integrand"" - however I am having difficulty tracing the logic in how he did so. Considering the more general integral $$ \frac{1}{2 \pi i} \int_{c-i \infty }^{c + i \infty } \frac{\Gamma(s-\alpha) \Gamma(\alpha+\beta-s)m^s\zeta(s)}{\Gamma(\beta)} $$ where $\alpha = A+\frac{1}{2}, \beta = B-\frac{1}{2}$ and both $A,B \in \mathbb{N}$ . The domain of integration is taken as the limit of the line integral from $c-iR$ to $c+iR$ as $R \to \infty$ . Note first that the integrand has poles whenever $s = k, k + \frac{1}{2}, k \in \mathbb{Z}$ . This function stems from an inverse Mellin transform with a fundamental strip of $\{ z \in \mathbb{C} : \alpha < \Re(z) < \alpha + \beta \}$ , so the integrand is only defined on this strip but can be analytically continued to the whole complex plane. Consider the contour $C = L \cup S$ where $L$ is the line segment going from $s=c-iR$ to $s=c+iR$ and $S$ be the semicircular contour going from $s=c+iR$ to $s=c-iR$ extending to the negative real axis (i.e. parametrized by $S(t) = c + Re^{i \theta}$ for $\theta \in (\frac{\pi}{2}, \frac{3\pi}{2})$ ). By the Residue Theorem, we have that $$\int_C f(z) dz = 2 \pi i \sum_{z \in [c, c-R] \cap \left( \mathbb{Z} \cup \mathbb{Z} + \frac{1}{2} \right)} \text{Res}\left(f; z\right)$$ where the sum is taken over the residues inside the contour (i.e. all integers and half integers in the interval $[c, c-R]$ ). We also have: $$ 2 \pi i \sum \text{Res} f(z) = \int_C f(z) dz = \int_{c-iR}^{c+iR} f(z) dz + \int_S f(z) dz $$ If we have that $\int_S f(z) dz \to 0$ as $R \to \infty$ , then Knuth's claim follows - however this is where I am stuck. I have tried to manipulate the inner gamma function terms with Stirling's approximation and have gotten nowhere, so some assistance here would be appreciated. Note: I am aware that there are some theorems involving Mellin transforms that I think are mentioned in the original paper that Knuth cites - however, I am trying to avoid them as it is made to seem as though this is a straightforward computation. Any assistance would be appreciated!","I was attempting to go through the addendum of Chapter 21 of Donald Knuth's Selected Papers on Analysis of Algorithms . In a lengthy derivation, Knuth asymptotically expands the following integral: where . Knuth only states that the asymptotic series is obtained ""by decreasing c as far as we like and adding up the residues of the poles of the integrand"" - however I am having difficulty tracing the logic in how he did so. Considering the more general integral where and both . The domain of integration is taken as the limit of the line integral from to as . Note first that the integrand has poles whenever . This function stems from an inverse Mellin transform with a fundamental strip of , so the integrand is only defined on this strip but can be analytically continued to the whole complex plane. Consider the contour where is the line segment going from to and be the semicircular contour going from to extending to the negative real axis (i.e. parametrized by for ). By the Residue Theorem, we have that where the sum is taken over the residues inside the contour (i.e. all integers and half integers in the interval ). We also have: If we have that as , then Knuth's claim follows - however this is where I am stuck. I have tried to manipulate the inner gamma function terms with Stirling's approximation and have gotten nowhere, so some assistance here would be appreciated. Note: I am aware that there are some theorems involving Mellin transforms that I think are mentioned in the original paper that Knuth cites - however, I am trying to avoid them as it is made to seem as though this is a straightforward computation. Any assistance would be appreciated!"," \frac{1}{2 \pi i} \int_{c-i \infty}^{c + i \infty } \frac{\Gamma(s-5/2)\Gamma(4-s) m^s \zeta(s)}{\Gamma(3/2)} ds \sim \frac{\Gamma(-3/2)\Gamma(3)}{\Gamma(3/2)} m + \sum_{n=0}^\infty \frac{(-1)^n}{n!} \frac{\Gamma(3/2+n)}{\Gamma(3/2)} m^{5/2-n} \zeta(5/2-n)  \frac{5}{2} < c < 4  \frac{1}{2 \pi i} \int_{c-i \infty }^{c + i \infty } \frac{\Gamma(s-\alpha) \Gamma(\alpha+\beta-s)m^s\zeta(s)}{\Gamma(\beta)}  \alpha = A+\frac{1}{2}, \beta = B-\frac{1}{2} A,B \in \mathbb{N} c-iR c+iR R \to \infty s = k, k + \frac{1}{2}, k \in \mathbb{Z} \{ z \in \mathbb{C} : \alpha < \Re(z) < \alpha + \beta \} C = L \cup S L s=c-iR s=c+iR S s=c+iR s=c-iR S(t) = c + Re^{i \theta} \theta \in (\frac{\pi}{2}, \frac{3\pi}{2}) \int_C f(z) dz = 2 \pi i \sum_{z \in [c, c-R] \cap \left( \mathbb{Z} \cup \mathbb{Z} + \frac{1}{2} \right)} \text{Res}\left(f; z\right) [c, c-R]  2 \pi i \sum \text{Res} f(z) = \int_C f(z) dz = \int_{c-iR}^{c+iR} f(z) dz + \int_S f(z) dz  \int_S f(z) dz \to 0 R \to \infty","['integration', 'gamma-function', 'complex-integration', 'mellin-transform']"
31,Integral inequality involving $e^{i\theta}$,Integral inequality involving,e^{i\theta},"I believe the below inequality is true; $$\int_0^{2\pi}|a+e^{i\theta}\alpha b|^pd\theta\leq (1+\alpha)^p \int_0^{2\pi}|a+e^{i\theta} b|^pd\theta,$$ for any nonnegative reals $a, b, \alpha$ and $p>0.$ When $a=0$ or $b=0$ or $\alpha=1,$ the inequality is true.  May I know how to  verify if my claim is true or not. When $\alpha=1,$ the bound $(1+\alpha)^p$ appears relatively large, and therefore, is there any scope for sharpening this bound in my claim if the inequality is true in its current form?","I believe the below inequality is true; for any nonnegative reals and When or or the inequality is true.  May I know how to  verify if my claim is true or not. When the bound appears relatively large, and therefore, is there any scope for sharpening this bound in my claim if the inequality is true in its current form?","\int_0^{2\pi}|a+e^{i\theta}\alpha b|^pd\theta\leq (1+\alpha)^p \int_0^{2\pi}|a+e^{i\theta} b|^pd\theta, a, b, \alpha p>0. a=0 b=0 \alpha=1, \alpha=1, (1+\alpha)^p","['integration', 'complex-analysis', 'inequality', 'definite-integrals']"
32,help evaluating tricky contour integral,help evaluating tricky contour integral,,"I am a 16 year old in Sweden learning complex analysis and I'm trying to evaluate the integral (I've checked that it converges) $$ I = \int_{0}^{\infty}\frac{e^{ix}}{x^3+x^2+x+1}\ dx $$ ( $e^{ix}$ to give the answer to both the integrals with $\cos(x)$ and $\sin(x)$ ) Taking $f(z) = \frac{e^{iz}}{z^3+z^2+z+1} = \frac{e^{iz}}{(z+1)(z+i)(z-i)}$ with poles at $z=-i,\ z=i,\ z=-1\ $ as the integrand I constructed a counter-clockwise oriented contour C not enclosing any singularity as a quarter circle with radius R centered on the origin, C being made up of the a circular arc $\Gamma $ , the real number line from $0$ to R named $\Lambda$ , the semicircular arc with radius $\epsilon$ around the right side of the singularity at $z=i$ named $\gamma $ , and the imaginary number line from $0$ to $i$ R, broken up by $\gamma $ called $\psi_1$ and $\psi_2$ , $\psi_1$ being the one from $i-i\epsilon$ to $0$ and $\psi_2$ being from $i$ R to $i+i\epsilon$ . Summarized: $$\oint_{C}^{}f(z)\ dz = \int_{\Gamma }^{}f(z)\ dz + \int_{\gamma }^{}f(z)\ dz + \int_{\Lambda }^{}f(z)\ dz + \int_{\psi_1}^{}f(z)\ dz + \int_{\psi_2}^{}f(z)\ dz$$ By Cauchy's residue theorem the integral over C equals $0$ as it doesn't enclose any poles. Using Jordan's Lemma i found the intgral over $\Gamma$ to be $0$ as R approaches infnity, likewise the integral over $\Lambda$ yields the answer $I$ I'm looking for as R approaches infinity. Since $\gamma$ is a right-facing semicircle with radius $\epsilon$ centered at the point $z=i$ I parametarized it in the following way: $$z=\epsilon e^{i(\frac{\pi}{2}-t)}+i,\ t \in [0, \pi]$$ $$dz=-i\epsilon e^{i(\frac{\pi}{2}-t)}\ dt$$ The integrand after factorizing the denominator and is therefore $$\frac{e^{i(\epsilon e^{i(\frac{\pi}{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+i+i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i-i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)}(-i\epsilon e^{i(\frac{\pi }{2}-t)})\ dt$$ silplifying: $$(-i)\frac{e^{i(\epsilon e^{i(\frac{\pi }{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+2i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)}\ dt$$ making the integral over $\gamma$ equal to $$-i\int_{0}^{\pi }\frac{e^{i(\epsilon e^{i(\frac{\pi }{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+2i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)} \ dt$$ in the limit as $\epsilon$ goes to $0$ , the integral approaches $$-i\int_{0}^{\pi } \frac{e^{-1}}{1+3i}\ dt = \frac{-\pi}{e}\left (\frac{3+i}{10}  \right )$$ However I am unsure how to evaluate the integrals over $\psi_1$ and $\psi_2$ , if you can combine them into one integral when $\epsilon$ approaches zero since it would integrate over all numbers from $i$ R to $0$ except for $z=i$ or if there's some obscure theorem or something I don't know about, otherwise I don't know if there's anything I can do except integrate it non-elementary which defeats the entire purpouse of contour integrating in the first place.","I am a 16 year old in Sweden learning complex analysis and I'm trying to evaluate the integral (I've checked that it converges) ( to give the answer to both the integrals with and ) Taking with poles at as the integrand I constructed a counter-clockwise oriented contour C not enclosing any singularity as a quarter circle with radius R centered on the origin, C being made up of the a circular arc , the real number line from to R named , the semicircular arc with radius around the right side of the singularity at named , and the imaginary number line from to R, broken up by called and , being the one from to and being from R to . Summarized: By Cauchy's residue theorem the integral over C equals as it doesn't enclose any poles. Using Jordan's Lemma i found the intgral over to be as R approaches infnity, likewise the integral over yields the answer I'm looking for as R approaches infinity. Since is a right-facing semicircle with radius centered at the point I parametarized it in the following way: The integrand after factorizing the denominator and is therefore silplifying: making the integral over equal to in the limit as goes to , the integral approaches However I am unsure how to evaluate the integrals over and , if you can combine them into one integral when approaches zero since it would integrate over all numbers from R to except for or if there's some obscure theorem or something I don't know about, otherwise I don't know if there's anything I can do except integrate it non-elementary which defeats the entire purpouse of contour integrating in the first place."," I = \int_{0}^{\infty}\frac{e^{ix}}{x^3+x^2+x+1}\ dx  e^{ix} \cos(x) \sin(x) f(z) = \frac{e^{iz}}{z^3+z^2+z+1} = \frac{e^{iz}}{(z+1)(z+i)(z-i)} z=-i,\ z=i,\ z=-1\  \Gamma  0 \Lambda \epsilon z=i \gamma  0 i \gamma  \psi_1 \psi_2 \psi_1 i-i\epsilon 0 \psi_2 i i+i\epsilon \oint_{C}^{}f(z)\ dz = \int_{\Gamma }^{}f(z)\ dz + \int_{\gamma }^{}f(z)\ dz + \int_{\Lambda }^{}f(z)\ dz + \int_{\psi_1}^{}f(z)\ dz + \int_{\psi_2}^{}f(z)\ dz 0 \Gamma 0 \Lambda I \gamma \epsilon z=i z=\epsilon e^{i(\frac{\pi}{2}-t)}+i,\ t \in [0, \pi] dz=-i\epsilon e^{i(\frac{\pi}{2}-t)}\ dt \frac{e^{i(\epsilon e^{i(\frac{\pi}{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+i+i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i-i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)}(-i\epsilon e^{i(\frac{\pi }{2}-t)})\ dt (-i)\frac{e^{i(\epsilon e^{i(\frac{\pi }{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+2i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)}\ dt \gamma -i\int_{0}^{\pi }\frac{e^{i(\epsilon e^{i(\frac{\pi }{2}-t)}+i)}}{(\epsilon e^{i(\frac{\pi }{2}-t)}+2i)(\epsilon e^{i(\frac{\pi }{2}-t)}+i+1)} \ dt \epsilon 0 -i\int_{0}^{\pi } \frac{e^{-1}}{1+3i}\ dt = \frac{-\pi}{e}\left (\frac{3+i}{10}  \right ) \psi_1 \psi_2 \epsilon i 0 z=i","['integration', 'complex-analysis', 'improper-integrals', 'contour-integration', 'complex-integration']"
33,"Evaluating $\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt$, $k\in\Bbb N_0$","Evaluating ,","\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt k\in\Bbb N_0","Let $$ I_k=\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt, $$ with $k\in\Bbb N_0$ and $a>0$ . Since $k$ is an integer we can expand the binomial to obtain $$ I_k=\sum_{\ell=0}^k\binom{k}{\ell}a^{k-\ell}\int_0^\infty t^\ell e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt. $$ Expanding the quadratic in the Gaussian and combining all the exponential terms subsequently allows us to write a closed-form for $I_k$ that is a finite sum of parabolic cylinder function $D_\nu(z)$ with $$ D_\nu(z)=\frac{e^{-z^2/4}}{\Gamma(-\nu)}\int_0^\infty t^{-\nu-1} e^{-t^2/2-zt}\,\mathrm dt. $$ Can we write a closed-form for $I_k$ that does not involve a sum like this? Is there a special function, related to $D_\nu$ , that admits an integral expression in the form of $I_k$ ? I would think that Meijer-G functions would be a potential candidate. Edit: I was asked for additional details/context. The origins of this problem are rooted in studying how photon noise passes through electro-optical image sensors.  Without getting into too much detail, the model of the problem being studied leads to a random variable of the form $$ Y=\mathcal P(W)+R, $$ where $R\sim\mathcal N(0,\sigma_R^2)$ and $\mathcal P(W)$ is a compound Poisson random variable with random mean $W$ , i.e. $\mathcal P(W)|W=w\sim\operatorname{Poisson}(w)$ . In this problem, $W$ is truncated normal with lower bound $(a)$ and infinite upper bound.  The density of $Y$ has the form $$ f_Y(y)=\sum_{k=0}^\infty \mathsf P(\mathcal P(W)=k)\phi(y-k,0,\sigma_R) $$ and the integral in question is needed to deduce $\mathsf P(\mathcal P(W)=k)$ .","Let with and . Since is an integer we can expand the binomial to obtain Expanding the quadratic in the Gaussian and combining all the exponential terms subsequently allows us to write a closed-form for that is a finite sum of parabolic cylinder function with Can we write a closed-form for that does not involve a sum like this? Is there a special function, related to , that admits an integral expression in the form of ? I would think that Meijer-G functions would be a potential candidate. Edit: I was asked for additional details/context. The origins of this problem are rooted in studying how photon noise passes through electro-optical image sensors.  Without getting into too much detail, the model of the problem being studied leads to a random variable of the form where and is a compound Poisson random variable with random mean , i.e. . In this problem, is truncated normal with lower bound and infinite upper bound.  The density of has the form and the integral in question is needed to deduce .","
I_k=\int_0^\infty (t+a)^k e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt,
 k\in\Bbb N_0 a>0 k 
I_k=\sum_{\ell=0}^k\binom{k}{\ell}a^{k-\ell}\int_0^\infty t^\ell e^{-t}\exp\left(-\frac{(t-\mu)^2}{2\sigma^2}\right)\,\mathrm dt.
 I_k D_\nu(z) 
D_\nu(z)=\frac{e^{-z^2/4}}{\Gamma(-\nu)}\int_0^\infty t^{-\nu-1} e^{-t^2/2-zt}\,\mathrm dt.
 I_k D_\nu I_k 
Y=\mathcal P(W)+R,
 R\sim\mathcal N(0,\sigma_R^2) \mathcal P(W) W \mathcal P(W)|W=w\sim\operatorname{Poisson}(w) W (a) Y 
f_Y(y)=\sum_{k=0}^\infty \mathsf P(\mathcal P(W)=k)\phi(y-k,0,\sigma_R)
 \mathsf P(\mathcal P(W)=k)","['integration', 'normal-distribution', 'special-functions', 'hermite-polynomials']"
34,Evaluate $\lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n$,Evaluate,\lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n,"Evaluate $\lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n$ . I've tried this: from Taylor's expansion at $t_0=0$ of the function $e^t$ , I get that for any $t \in \mathbb{R}$ it is $e^t \ge 1+t$ . Moreover, for the Lagrange's remainder of the Taylor's expansion there exists $c(t)$ on the segment of endpoints $0$ and $t$ such that $$e^t=1+t+\frac{t^2}{2}+\frac{t^3}{6}e^{c(t)}$$ When $t \le 0$ , it is $\frac{t^3}{6}e^{c(t)}\le0$ ; hence for $t \le 0$ it is $e^t\le1+t+\frac{t^2}{2}$ . Since $-\frac{x^2}{n} \le 0$ for any $x\in[0,1]$ and for any $n\in\mathbb{N}$ , it is $$1-\frac{x^2}{n}\le e^{-x^2/n} \le 1-\frac{x^2}{n}+\frac{x^4}{2n^2}$$ For monotonicity of integral, integrating in the inequality in the interval $[0,1]$ it is $$1-\frac{1}{3n} \le \int_0^1 e^{-x^2/n} dx\le1-\frac{1}{3n}+\frac{1}{10n^2}$$ Since $1-\frac{1}{3n} \ge 0$ for any $n\in\mathbb{N}$ , for the monotonicity of the $n$ -th power it is $$\left(1-\frac{1}{3n}\right)^n \le \left(\int_0^1 e^{-x^2/n} dx\right)^n \le \left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n$$ Since the limit preserves non strict inequalities, it is $$\lim_{n\to\infty} \left(1-\frac{1}{3n}\right)^n\le \lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n \le \lim_{n\to\infty} \left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n$$ So, since for $n\to\infty$ it is $\left(1-\frac{1}{3n}\right)^n \to e^{-1/3}$ and $\left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n \to e^{-1/3}$ , for the squeeze theorem it follows that $$\lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n=e^{-1/3}$$ Could this work? I am unsure about the use of the Taylor formula for $t \le 0$ and the various monotonicity arguments I made.","Evaluate . I've tried this: from Taylor's expansion at of the function , I get that for any it is . Moreover, for the Lagrange's remainder of the Taylor's expansion there exists on the segment of endpoints and such that When , it is ; hence for it is . Since for any and for any , it is For monotonicity of integral, integrating in the inequality in the interval it is Since for any , for the monotonicity of the -th power it is Since the limit preserves non strict inequalities, it is So, since for it is and , for the squeeze theorem it follows that Could this work? I am unsure about the use of the Taylor formula for and the various monotonicity arguments I made.","\lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n t_0=0 e^t t \in \mathbb{R} e^t \ge 1+t c(t) 0 t e^t=1+t+\frac{t^2}{2}+\frac{t^3}{6}e^{c(t)} t \le 0 \frac{t^3}{6}e^{c(t)}\le0 t \le 0 e^t\le1+t+\frac{t^2}{2} -\frac{x^2}{n} \le 0 x\in[0,1] n\in\mathbb{N} 1-\frac{x^2}{n}\le e^{-x^2/n} \le 1-\frac{x^2}{n}+\frac{x^4}{2n^2} [0,1] 1-\frac{1}{3n} \le \int_0^1 e^{-x^2/n} dx\le1-\frac{1}{3n}+\frac{1}{10n^2} 1-\frac{1}{3n} \ge 0 n\in\mathbb{N} n \left(1-\frac{1}{3n}\right)^n \le \left(\int_0^1 e^{-x^2/n} dx\right)^n \le \left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n \lim_{n\to\infty} \left(1-\frac{1}{3n}\right)^n\le \lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n \le \lim_{n\to\infty} \left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n n\to\infty \left(1-\frac{1}{3n}\right)^n \to e^{-1/3} \left(1-\frac{1}{3n}+\frac{1}{10n^2}\right)^n \to e^{-1/3} \lim_{n \to \infty} \left(\int_0^1 e^{-x^2/n} dx\right)^n=e^{-1/3} t \le 0","['integration', 'limits', 'analysis', 'solution-verification']"
35,Should I ignore ± sign when integrating square roots?,Should I ignore ± sign when integrating square roots?,,"I was solving the following integral: $$ \int \:\frac{x^2}{\sqrt{x^2+4}}dx $$ $$ u=\sqrt{x^2+4} $$ $$ \:du=\frac{2x}{2\sqrt{x^2+4}}dx=\frac{x}{u}dx $$ $$ \int \:\frac{x^2}{\sqrt{x^2+4}}dx=\int \:\frac{x^2}{u}dx=\int \:xdu $$ Now I only need to find what x means in terms of u: $$ u^2=x^2+4,\:u^2-4=x^2 $$ $$ x=\pm \sqrt{u^2-4} $$ But now I have a problem, which is the plus minus sign, so my integral would be: $$ \int \pm \sqrt{u^2-4}du $$ To avoid this problem, I decided to use integration by parts instead: $$ \int xdu\:=\:xu-\int \:udx\:= $$ $$ x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx $$ But it looks like both equations yielded the same result and the plus minus sign was unnecessary. $$\int \pm \sqrt{u^2-4}du$$ $$x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx$$ $$u=2sect,\:t=arcsec\left(\frac{u}{2}\right),\:du=2sec\left(t\right)tan\left(t\right)dt$$ $$x=2tan\left(t\right),\:t=arctan\left(\frac{x}{2}\right),\:dx=2sec^2tdt$$ $$\int \:\sqrt{u^2-4}du=\int \:2tan\left(t\right)\cdot 2sec\left(t\right)tan\left(t\right)dt=$$ $$x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx=\:x\sqrt{x^2+4}-\int \:2sec\left(t\right)\cdot 2sec^2tdt=$$ $$4\int \:sec\left(t\right)tan^2\left(t\right)dt=4\int \:\:sec\left(t\right)\left(sec^2\left(t\right)-1\right)dt=$$ $$\:x\sqrt{x^2+4}-4\int \:sec^3tdt$$ $$4\int \:\:sec^3tdt-4\int \:sec\left(t\right)dt$$ $$\int \:sec^3tdt=\frac{1}{2}\sec \:\left(t\right)\tan \:\left(t\right)+\frac{1}{2}\ln \:\left|\tan \:\left(t\right)+\sec \:\left(t\right)\right|+C$$ $$=4\left(\frac{1}{2}\sec \:\:\left(t\right)\tan \:\:\left(t\right)+\frac{1}{2}\ln \:\:\left|\tan \:\:\left(t\right)+\sec \:\:\left(t\right)\right|-ln\left|\tan \:\:\:\left(t\right)+\sec \:\:\:\left(t\right)\right|\right)$$ $$=x\sqrt{x^2+4}-4\left[\frac{1}{2}\sec \left(t\right)\tan \left(t\right)+\frac{1}{2}\ln \left|\tan \left(t\right)+\sec \left(t\right)\right|\right]$$ $$=2\sec \left(t\right)\tan \left(t\right)-2\ln \left|\tan \:\:\left(t\right)+\sec \:\:\left(t\right)\right|$$ $$=x\sqrt{x^2+4}-2\sec \left(t\right)\tan \left(t\right)-2\ln \left|\tan \left(t\right)+\sec \left(t\right)\right|$$ $$=2\sec \left(sec^{-1}\left(\frac{u}{2}\right)\right)\tan \left(sec^{-1}\left(\frac{u}{2}\right)\right)-2\ln \left|\tan \:\:\left(sec^{-1}\left(\frac{u}{2}\right)\right)+\sec \:\:\left(sec^{-1}\left(\frac{u}{2}\right)\right)\right|$$ $$=x\sqrt{x^2+4}-2\sec \left(tan^{-1}\left(\frac{x}{2}\right)\right)\tan \left(tan^{-1}\left(\frac{x}{2}\right)\right)-2\ln \left|\tan \left(tan^{-1}\left(\frac{x}{2}\right)\right)+\sec \left(tan^{-1}\left(\frac{x}{2}\right)\right)\right|$$ $$sec=\frac{h}{a}=\frac{u}{2},\:o=\sqrt{u^2-2^2},\:tan=\frac{o}{a}=\frac{\sqrt{u^2-4}}{2}$$ $$tan=\frac{o}{a}=\frac{x}{2},\:h=\sqrt{x^2+2^2},\:sec=\frac{h}{a}=\frac{\sqrt{x^2+4}}{2}$$ $$=2\left(\frac{u}{2}\right)\frac{\sqrt{u^2-4}}{2}-2\ln \left(\left|\frac{\sqrt{u^2-4}}{2}+\frac{u}{2}\right|\right)$$ $$=x\sqrt{x^2+4}-2\frac{\sqrt{x^2+4}}{2}\left(\frac{x}{2}\right)-2\ln \:\left|\frac{x}{2}+\frac{\sqrt{x^2+4}}{2}\right|$$ $$=\frac{\sqrt{x^{2}+4}\sqrt{\left(\sqrt{x^{2}+4}\right)^{2}-4}}{2}-2\ln\left(\left|\frac{\sqrt{\left(\sqrt{x^{2}+4}\right)^{2}-4}}{2}+\frac{\sqrt{x^{2}+4}}{2}\right|\right)$$ $$=\frac{2x\sqrt{x^2+4}}{2}-\frac{x\sqrt{x^2+4}}{2}-2\ln \:\left|\frac{x}{2}+\frac{\sqrt{x^2+4}}{2}\right|$$ $$=\frac{x\sqrt{x^{2}+4}}{2}-2\ln\left|\frac{x+\sqrt{x^{2}+4}}{2}\right|$$ $$=\frac{x\sqrt{x^2+4}}{2}-2\ln \:\left|\frac{x+\sqrt{x^2+4}}{2}\right|$$ So, since both of them yield the exact same answer after simplification, I wonder if we can always assume that square roots are positive and omit the plus minus sign, or was my logic actually right that I should always try to avoid substitutions with plus minus square roots? As you can see by the graph it seems to work for both positive and negative x . My only suspicion is that in cases where it is not possible to simplify the formations such as fractional angles. Then maybe we could be getting it wrong... for example when answer is like this... $$sin\left(\frac{1}{8}cos^{-1}x\right)$$","I was solving the following integral: Now I only need to find what x means in terms of u: But now I have a problem, which is the plus minus sign, so my integral would be: To avoid this problem, I decided to use integration by parts instead: But it looks like both equations yielded the same result and the plus minus sign was unnecessary. So, since both of them yield the exact same answer after simplification, I wonder if we can always assume that square roots are positive and omit the plus minus sign, or was my logic actually right that I should always try to avoid substitutions with plus minus square roots? As you can see by the graph it seems to work for both positive and negative x . My only suspicion is that in cases where it is not possible to simplify the formations such as fractional angles. Then maybe we could be getting it wrong... for example when answer is like this...","
\int \:\frac{x^2}{\sqrt{x^2+4}}dx
 
u=\sqrt{x^2+4}
 
\:du=\frac{2x}{2\sqrt{x^2+4}}dx=\frac{x}{u}dx
 
\int \:\frac{x^2}{\sqrt{x^2+4}}dx=\int \:\frac{x^2}{u}dx=\int \:xdu
 
u^2=x^2+4,\:u^2-4=x^2
 
x=\pm \sqrt{u^2-4}
 
\int \pm \sqrt{u^2-4}du
 
\int xdu\:=\:xu-\int \:udx\:=
 
x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx
 \int \pm \sqrt{u^2-4}du x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx u=2sect,\:t=arcsec\left(\frac{u}{2}\right),\:du=2sec\left(t\right)tan\left(t\right)dt x=2tan\left(t\right),\:t=arctan\left(\frac{x}{2}\right),\:dx=2sec^2tdt \int \:\sqrt{u^2-4}du=\int \:2tan\left(t\right)\cdot 2sec\left(t\right)tan\left(t\right)dt= x\sqrt{x^2+4}-\int \:\sqrt{x^2+4}dx=\:x\sqrt{x^2+4}-\int \:2sec\left(t\right)\cdot 2sec^2tdt= 4\int \:sec\left(t\right)tan^2\left(t\right)dt=4\int \:\:sec\left(t\right)\left(sec^2\left(t\right)-1\right)dt= \:x\sqrt{x^2+4}-4\int \:sec^3tdt 4\int \:\:sec^3tdt-4\int \:sec\left(t\right)dt \int \:sec^3tdt=\frac{1}{2}\sec \:\left(t\right)\tan \:\left(t\right)+\frac{1}{2}\ln \:\left|\tan \:\left(t\right)+\sec \:\left(t\right)\right|+C =4\left(\frac{1}{2}\sec \:\:\left(t\right)\tan \:\:\left(t\right)+\frac{1}{2}\ln \:\:\left|\tan \:\:\left(t\right)+\sec \:\:\left(t\right)\right|-ln\left|\tan \:\:\:\left(t\right)+\sec \:\:\:\left(t\right)\right|\right) =x\sqrt{x^2+4}-4\left[\frac{1}{2}\sec \left(t\right)\tan \left(t\right)+\frac{1}{2}\ln \left|\tan \left(t\right)+\sec \left(t\right)\right|\right] =2\sec \left(t\right)\tan \left(t\right)-2\ln \left|\tan \:\:\left(t\right)+\sec \:\:\left(t\right)\right| =x\sqrt{x^2+4}-2\sec \left(t\right)\tan \left(t\right)-2\ln \left|\tan \left(t\right)+\sec \left(t\right)\right| =2\sec \left(sec^{-1}\left(\frac{u}{2}\right)\right)\tan \left(sec^{-1}\left(\frac{u}{2}\right)\right)-2\ln \left|\tan \:\:\left(sec^{-1}\left(\frac{u}{2}\right)\right)+\sec \:\:\left(sec^{-1}\left(\frac{u}{2}\right)\right)\right| =x\sqrt{x^2+4}-2\sec \left(tan^{-1}\left(\frac{x}{2}\right)\right)\tan \left(tan^{-1}\left(\frac{x}{2}\right)\right)-2\ln \left|\tan \left(tan^{-1}\left(\frac{x}{2}\right)\right)+\sec \left(tan^{-1}\left(\frac{x}{2}\right)\right)\right| sec=\frac{h}{a}=\frac{u}{2},\:o=\sqrt{u^2-2^2},\:tan=\frac{o}{a}=\frac{\sqrt{u^2-4}}{2} tan=\frac{o}{a}=\frac{x}{2},\:h=\sqrt{x^2+2^2},\:sec=\frac{h}{a}=\frac{\sqrt{x^2+4}}{2} =2\left(\frac{u}{2}\right)\frac{\sqrt{u^2-4}}{2}-2\ln \left(\left|\frac{\sqrt{u^2-4}}{2}+\frac{u}{2}\right|\right) =x\sqrt{x^2+4}-2\frac{\sqrt{x^2+4}}{2}\left(\frac{x}{2}\right)-2\ln \:\left|\frac{x}{2}+\frac{\sqrt{x^2+4}}{2}\right| =\frac{\sqrt{x^{2}+4}\sqrt{\left(\sqrt{x^{2}+4}\right)^{2}-4}}{2}-2\ln\left(\left|\frac{\sqrt{\left(\sqrt{x^{2}+4}\right)^{2}-4}}{2}+\frac{\sqrt{x^{2}+4}}{2}\right|\right) =\frac{2x\sqrt{x^2+4}}{2}-\frac{x\sqrt{x^2+4}}{2}-2\ln \:\left|\frac{x}{2}+\frac{\sqrt{x^2+4}}{2}\right| =\frac{x\sqrt{x^{2}+4}}{2}-2\ln\left|\frac{x+\sqrt{x^{2}+4}}{2}\right| =\frac{x\sqrt{x^2+4}}{2}-2\ln \:\left|\frac{x+\sqrt{x^2+4}}{2}\right| sin\left(\frac{1}{8}cos^{-1}x\right)","['integration', 'trigonometric-integrals']"
36,An example of high dimension (financial) integrals?,An example of high dimension (financial) integrals?,,"Introduction This question mainly arises out of the context of [Quasi Monte Carlo integration][1]. Which uses ""quasi-random"" numbers, (i.e. deterministic) with low discrepancy to reduce the variance in Monte Carlo integration. This reduction in variance is more prevalent in higher dimensions. And has thus found use in financial mathematics where they require numerical solutions to very high dimension integrals (>10^2). Question I have been unable to find any explicit examples of these very high dimension integrals anywhere online. Many articles reference these to arise from financial mathematics but are quite vague about its precise origins. I would like to know how I could construct a integral of this manner and what its implications would be? Unfortunately I am very clueless on what goes on in financial mathematics. Even better would be if anyone knows of an explicitly stated example of such a higher dimensional integral, but that seems unlikely. My main purpose is really more of a showcase of Quasi Monte Carlo, but at the same time I want to avoid simply constructing an elementary integral like: $$\int_{\Omega^d} \cos(x)^d\,dx$$ Thanks for any and all help!","Introduction This question mainly arises out of the context of [Quasi Monte Carlo integration][1]. Which uses ""quasi-random"" numbers, (i.e. deterministic) with low discrepancy to reduce the variance in Monte Carlo integration. This reduction in variance is more prevalent in higher dimensions. And has thus found use in financial mathematics where they require numerical solutions to very high dimension integrals (>10^2). Question I have been unable to find any explicit examples of these very high dimension integrals anywhere online. Many articles reference these to arise from financial mathematics but are quite vague about its precise origins. I would like to know how I could construct a integral of this manner and what its implications would be? Unfortunately I am very clueless on what goes on in financial mathematics. Even better would be if anyone knows of an explicitly stated example of such a higher dimensional integral, but that seems unlikely. My main purpose is really more of a showcase of Quasi Monte Carlo, but at the same time I want to avoid simply constructing an elementary integral like: Thanks for any and all help!","\int_{\Omega^d} \cos(x)^d\,dx","['integration', 'numerical-methods', 'finance', 'monte-carlo']"
37,"Integral form(s) of a general tetration/power tower integral solution: $\sum\limits_{n=0}^\infty \frac{(pn+q)^{rn+s}Γ(An+B,Cn+D)}{Γ(an+b,cn+d)}$",Integral form(s) of a general tetration/power tower integral solution:,"\sum\limits_{n=0}^\infty \frac{(pn+q)^{rn+s}Γ(An+B,Cn+D)}{Γ(an+b,cn+d)}","In many tetration/power tower integrals, one sees a general form of the following. Let this new function be notation used to show the connection between the general result and special cases using types of Incomplete Gamma functions . The goal is to find an integral representation of the general case or a special case. If this is not possible, then maybe a special case of it has an integral representation. Note there are ways to put the summand into other functions, but this way is simple. Please note that I will use a made up general “T” function to show how each integral below it is a special case of the following: $$T_{p,q}^{r,s}\left(_{\ \ a,b,c,d}^{A,B,C,D}\right)=\sum_{n=0}^\infty \frac{(pn+q)^{rn+s}Γ(An+B,Cn+D)}{Γ(an+b,cn+d)}$$ Here is motivation that integral representations are possible. Note that I will use the primitive for simplicity: $$\int (cx)^{ax^b}dx=\sum_{n=0}^\infty\frac{(-a)^n Q(n+1,-(bn+1)\ln(cx))}{c^{bn+1}(bn+1)^{n+1}}= \frac{1}{-ac^{b-1}}\sum_{n=0}^\infty\frac{ (-ac^bbn-ac^b)^{n+1}Γ(n+1,-bn\ln(cx)-\ln(cx))}{Γ(n+1,0)} =  -\frac{1}{ac^{b-1}}  T_{-abc^b,-ac^b}^{1,1}\left(_{\ \ 1,1,0,0}^{1,1,-b\ln(cx),-\ln(cx)}\right) $$ $$\int a^{ta^t}dt=t+\frac{1}{\ln(a)}\sum_{n=0}^\infty \frac {(-1)^n Q(n+1,-nt\,\ln(a))}{n^{n+1}}= t-\frac{1}{\ln(a)}\sum_{n=0}^\infty \frac {(-n)^{-n-1} Γ(n+1,-nt\,\ln(a))}{Γ(n+1,0)} =t-\frac{1}{\ln(a)} T_{-1,0}^{-1,-1}\left(_{\ \ 1,1,0,0}^{1,1,-t\,\ln(a),0}\right) $$ $$\int \frac{dx}{xe^x-1}=\sum_{n=0}^\infty \frac{Γ(n+1,-nx)}{n^{n+1}}= \sum_{n=0}^\infty n^{-n-1} Γ(n+1,-nx)= T_{1,0}^{-1,-1}\left(_{0,1,0,0}^{1,1,-x,0}\right) $$ $$\int \text W(\ln(x))dx=\text W(\ln(x))(x-1)+\sum_{n=1}^\infty\frac{(-1)^n Q(n+1,-n\,\text W(\ln(x))}{n^{n+1}}= \text W(\ln(x))(x-1) -\sum_{n=1}^\infty\frac{(-n)^{-n-1}Γ(n+1,-n\,\text W(\ln(x))}{Γ(n+1)} = T_{-1,0}^{-1,-1}\left(_{1,1,0,0}^{1,1, -\,\text W(\ln(x)),0}\right) $$ Miscellaneous sums of interest. Subfactorial : $$\sum_{n=2}^\infty \frac{1}{!n}=e\sum_{n=0}^\infty \frac{1}{Γ(n+2,-1)}=e\,T_{p,q}^{0,0}\left(_{1,2,0,-1}^{0,1,0,0}\right)$$ $$\sum_{n=-\infty}^{-1} Γ(n,n)=\sum_{n=0}^\infty Γ(-n-1,-n-1)= T_{p,q}^{0,0}\left(_{-1,-1,-1,-1}^{\quad 0,1,0,0}\right) $$ I already know about the Abel-Plana formula , but it offers no new insights. There are other theorems that could possibly be used. How can the integral representations for the goal sum be found? If the integral representation is indeed impossible, then what is an integral  representation for a special case? This will help us solve similar problems. Please correct me and give me feedback!","In many tetration/power tower integrals, one sees a general form of the following. Let this new function be notation used to show the connection between the general result and special cases using types of Incomplete Gamma functions . The goal is to find an integral representation of the general case or a special case. If this is not possible, then maybe a special case of it has an integral representation. Note there are ways to put the summand into other functions, but this way is simple. Please note that I will use a made up general “T” function to show how each integral below it is a special case of the following: Here is motivation that integral representations are possible. Note that I will use the primitive for simplicity: Miscellaneous sums of interest. Subfactorial : I already know about the Abel-Plana formula , but it offers no new insights. There are other theorems that could possibly be used. How can the integral representations for the goal sum be found? If the integral representation is indeed impossible, then what is an integral  representation for a special case? This will help us solve similar problems. Please correct me and give me feedback!","T_{p,q}^{r,s}\left(_{\ \ a,b,c,d}^{A,B,C,D}\right)=\sum_{n=0}^\infty \frac{(pn+q)^{rn+s}Γ(An+B,Cn+D)}{Γ(an+b,cn+d)} \int (cx)^{ax^b}dx=\sum_{n=0}^\infty\frac{(-a)^n Q(n+1,-(bn+1)\ln(cx))}{c^{bn+1}(bn+1)^{n+1}}= \frac{1}{-ac^{b-1}}\sum_{n=0}^\infty\frac{ (-ac^bbn-ac^b)^{n+1}Γ(n+1,-bn\ln(cx)-\ln(cx))}{Γ(n+1,0)} =  -\frac{1}{ac^{b-1}}  T_{-abc^b,-ac^b}^{1,1}\left(_{\ \ 1,1,0,0}^{1,1,-b\ln(cx),-\ln(cx)}\right)  \int a^{ta^t}dt=t+\frac{1}{\ln(a)}\sum_{n=0}^\infty \frac {(-1)^n Q(n+1,-nt\,\ln(a))}{n^{n+1}}= t-\frac{1}{\ln(a)}\sum_{n=0}^\infty \frac {(-n)^{-n-1} Γ(n+1,-nt\,\ln(a))}{Γ(n+1,0)} =t-\frac{1}{\ln(a)} T_{-1,0}^{-1,-1}\left(_{\ \ 1,1,0,0}^{1,1,-t\,\ln(a),0}\right)  \int \frac{dx}{xe^x-1}=\sum_{n=0}^\infty \frac{Γ(n+1,-nx)}{n^{n+1}}= \sum_{n=0}^\infty n^{-n-1} Γ(n+1,-nx)= T_{1,0}^{-1,-1}\left(_{0,1,0,0}^{1,1,-x,0}\right)  \int \text W(\ln(x))dx=\text W(\ln(x))(x-1)+\sum_{n=1}^\infty\frac{(-1)^n Q(n+1,-n\,\text W(\ln(x))}{n^{n+1}}= \text W(\ln(x))(x-1) -\sum_{n=1}^\infty\frac{(-n)^{-n-1}Γ(n+1,-n\,\text W(\ln(x))}{Γ(n+1)} = T_{-1,0}^{-1,-1}\left(_{1,1,0,0}^{1,1, -\,\text W(\ln(x)),0}\right)  \sum_{n=2}^\infty \frac{1}{!n}=e\sum_{n=0}^\infty \frac{1}{Γ(n+2,-1)}=e\,T_{p,q}^{0,0}\left(_{1,2,0,-1}^{0,1,0,0}\right) \sum_{n=-\infty}^{-1} Γ(n,n)=\sum_{n=0}^\infty Γ(-n-1,-n-1)= T_{p,q}^{0,0}\left(_{-1,-1,-1,-1}^{\quad 0,1,0,0}\right) ","['integration', 'gamma-function', 'tetration', 'summation-method', 'power-towers']"
38,The product of the derivative and anti derivative is the function?,The product of the derivative and anti derivative is the function?,,When is $$f(x) = f'(x)\int{f(x)}dx$$? I just though of the problem but couldn't solve it myself.,When is $$f(x) = f'(x)\int{f(x)}dx$$? I just though of the problem but couldn't solve it myself.,,"['integration', 'ordinary-differential-equations', 'derivatives']"
39,On the integral $\int\sqrt{1+\cos x}\text{d} x$,On the integral,\int\sqrt{1+\cos x}\text{d} x,"I've been wondering about the following integral recently: $$ I = \int\sqrt{1+\cos x}\,\text{d}x $$ The way I integrated it is I used the identity $\sqrt{1+\cos x} = \sqrt2\cos\frac x2$, and so $$ I = 2\sqrt2\sin\frac x2 + C $$ the problem is that $\sqrt{1+\cos x}$ is actually integrable over the entire real line, but the derivative of $2\sqrt2\sin\frac x2$ is only equal to $\sqrt{1+\cos x}$ in certain intervals. This is because the actual identity is $\sqrt{1+\cos x} = \sqrt2\left|\cos\frac x2\right|$. Now, I wasn't exactly sure how to integrate the absolute value, so I thought I would ""fix"" the function after integration. The first fix we can do is making sure that the sign of the result of integration is correct: $$ I = 2\sqrt2\sin\frac x2\text{sgn}\cos\frac x2 + C $$ The problem with just $\sin\frac x2$ was that sometimes it was ""flipped"", on certain intervals it was actually the antiderivative of the $-\sqrt{1+\cos x}$ (this is because we dropped the absolute value signs). There is one further problem with this, however. The above function is not continuous, meaning it's not continuously differentiable with derivative equal to $\sqrt{1+\cos x}$ everywhere. Namely, it is discontinuous at $x=(4n\pm1)\pi$ where $n\in\mathbb{Z}$. I noticed, however, that the limit of the derivative on either side of $x=(4n\pm1)\pi$ existed and was equal to each other. Hence, I figured that I could somehow ""stitch"" these continuous sections end to end and get a continuous result whose derivative was $\sqrt{1+\cos x}$ everywhere. The resulting function I got was $$ I = 2\sqrt2\sin\frac x2\text{sgn}\cos\frac x2 + 4\sqrt2\left\lfloor\frac1{2\pi}x+\frac12\right\rfloor + C $$ Now, I was wondering, is there any way to arrive at this result just by integrating $\sqrt{1+\cos x}$ using the usual techniques? The method I used can be boiled down to ""integrating"" then ""fixing"", but I'm just wondering if you can arrive at a result that is continuous and differentiable on the entire real line by doing just the ""integrating"" part. Any help would be appreciated. Thanks! Edit: To be clear, I'm not looking for exactly the function above, but rather simply any function that is ""nice"", continuous and differentiable on $\mathbb{R}$, and has derivative equal to $\sqrt{1+\cos x}$ everywhere, and which is attainable through ""simple"" integration methods.","I've been wondering about the following integral recently: $$ I = \int\sqrt{1+\cos x}\,\text{d}x $$ The way I integrated it is I used the identity $\sqrt{1+\cos x} = \sqrt2\cos\frac x2$, and so $$ I = 2\sqrt2\sin\frac x2 + C $$ the problem is that $\sqrt{1+\cos x}$ is actually integrable over the entire real line, but the derivative of $2\sqrt2\sin\frac x2$ is only equal to $\sqrt{1+\cos x}$ in certain intervals. This is because the actual identity is $\sqrt{1+\cos x} = \sqrt2\left|\cos\frac x2\right|$. Now, I wasn't exactly sure how to integrate the absolute value, so I thought I would ""fix"" the function after integration. The first fix we can do is making sure that the sign of the result of integration is correct: $$ I = 2\sqrt2\sin\frac x2\text{sgn}\cos\frac x2 + C $$ The problem with just $\sin\frac x2$ was that sometimes it was ""flipped"", on certain intervals it was actually the antiderivative of the $-\sqrt{1+\cos x}$ (this is because we dropped the absolute value signs). There is one further problem with this, however. The above function is not continuous, meaning it's not continuously differentiable with derivative equal to $\sqrt{1+\cos x}$ everywhere. Namely, it is discontinuous at $x=(4n\pm1)\pi$ where $n\in\mathbb{Z}$. I noticed, however, that the limit of the derivative on either side of $x=(4n\pm1)\pi$ existed and was equal to each other. Hence, I figured that I could somehow ""stitch"" these continuous sections end to end and get a continuous result whose derivative was $\sqrt{1+\cos x}$ everywhere. The resulting function I got was $$ I = 2\sqrt2\sin\frac x2\text{sgn}\cos\frac x2 + 4\sqrt2\left\lfloor\frac1{2\pi}x+\frac12\right\rfloor + C $$ Now, I was wondering, is there any way to arrive at this result just by integrating $\sqrt{1+\cos x}$ using the usual techniques? The method I used can be boiled down to ""integrating"" then ""fixing"", but I'm just wondering if you can arrive at a result that is continuous and differentiable on the entire real line by doing just the ""integrating"" part. Any help would be appreciated. Thanks! Edit: To be clear, I'm not looking for exactly the function above, but rather simply any function that is ""nice"", continuous and differentiable on $\mathbb{R}$, and has derivative equal to $\sqrt{1+\cos x}$ everywhere, and which is attainable through ""simple"" integration methods.",,"['integration', 'indefinite-integrals']"
40,Is it possible to find the Taylor series of an integral where the upper limit depends on the variable? [closed],Is it possible to find the Taylor series of an integral where the upper limit depends on the variable? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How to find the first three terms of the Taylor series around $b=c$ of $$ \int^{\frac{1}{b}}_{a}f(b,x) dx $$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How to find the first three terms of the Taylor series around $b=c$ of $$ \int^{\frac{1}{b}}_{a}f(b,x) dx $$",,"['integration', 'ordinary-differential-equations', 'taylor-expansion']"
41,Differences between Quaternion integration methods,Differences between Quaternion integration methods,,"I've implemented a Quaternion Kalman filter and i have the choice between multiple way to integrate angular velocities. The goal is to predict futur orientation $q^{n+1}$ from current orientation $q^{n}$ and angular velocity $\vec{r}$. During the time step $\Delta_t$ separating $q^{n+1}$ from $q^{n}$, the angular velocity is said to be constant. The first method transform angular velocity $\vec{r}=[r_x \ r_y \ r_z]$ into a quaternion $q_r$ and multiply the result with the current orientation quaternion $q^n$ : $$ q_r =(a,\vec{v})\\ a = \cos{(\frac{|\vec{r}|\Delta_t}{2})} \\ \vec{v}=\sin{(\frac{|\vec{r}|\Delta_t}{2})}\frac{\vec{r}}{|\vec{r}|}\\ q^{n+1}=q^{n}q_r $$ The second method is based on the quaternion derivative formula :  $$ q_r =(0,\vec{r})\\ q^{n+1}=q^n+ \Delta_t(\frac{1}{2}q^nq_r) $$ What are the fundamental differences between the two approach? What are their properties ? I understand the second one is a simple Euler integration, a crude first order approximation assuming a fixed $q$ and $\vec{r}$ during integration. At the end, we can possibly have $|q^{n+1}|$ different from unity so a normalization can be necessary. This kind of approach, based on the derivative, can easily be generalized to higher orders. On the other hand, i don't know what the first approach really is. It doesn't require any normalization. In which aspect is it an approximation ? If this integration method a numeric approximation, what's its order ?  Could a RK4 approximation be better ? Here is a similar question asked on a programming thread. No clear answer was given. Here is a patent relative to the first method : http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20080004113.pdf Best,","I've implemented a Quaternion Kalman filter and i have the choice between multiple way to integrate angular velocities. The goal is to predict futur orientation $q^{n+1}$ from current orientation $q^{n}$ and angular velocity $\vec{r}$. During the time step $\Delta_t$ separating $q^{n+1}$ from $q^{n}$, the angular velocity is said to be constant. The first method transform angular velocity $\vec{r}=[r_x \ r_y \ r_z]$ into a quaternion $q_r$ and multiply the result with the current orientation quaternion $q^n$ : $$ q_r =(a,\vec{v})\\ a = \cos{(\frac{|\vec{r}|\Delta_t}{2})} \\ \vec{v}=\sin{(\frac{|\vec{r}|\Delta_t}{2})}\frac{\vec{r}}{|\vec{r}|}\\ q^{n+1}=q^{n}q_r $$ The second method is based on the quaternion derivative formula :  $$ q_r =(0,\vec{r})\\ q^{n+1}=q^n+ \Delta_t(\frac{1}{2}q^nq_r) $$ What are the fundamental differences between the two approach? What are their properties ? I understand the second one is a simple Euler integration, a crude first order approximation assuming a fixed $q$ and $\vec{r}$ during integration. At the end, we can possibly have $|q^{n+1}|$ different from unity so a normalization can be necessary. This kind of approach, based on the derivative, can easily be generalized to higher orders. On the other hand, i don't know what the first approach really is. It doesn't require any normalization. In which aspect is it an approximation ? If this integration method a numeric approximation, what's its order ?  Could a RK4 approximation be better ? Here is a similar question asked on a programming thread. No clear answer was given. Here is a patent relative to the first method : http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20080004113.pdf Best,",,"['integration', 'quaternions', 'bayesian-network', 'kalman-filter', 'runge-kutta-methods']"
42,"Is there an easier way to find the ""natural"" integration constant?","Is there an easier way to find the ""natural"" integration constant?",,"Suppose we take consequtive derivatives of a function at a point and then interpolate them with Newton series (Newton interpolation formula) so to obtain a smooth curve. $$f^{(s)}(x)=\sum_{m=0}^{\infty} \binom {s}m \sum_{k=0}^m\binom mk(-1)^{m-k}f^{(k)}(x)$$ If the series converges at $s=-1$ we take this value to be the ""natural"" value of antiderivative of $f$ at the point $x$ (assuming that integral is the -1-th derivative). For instance, for function $f(x)=a^x$ the expansion converges (if converges, which is not the case for all $a$) to $a^x (\ln a)^s$, or $(\ln a)^s$ at $x=0$. Thus antiderivative of $a^x$ should naturally have value of $\frac{1}{\ln a}$ at $x=0$. Is there an easier way to obtain this value, and possibly, more universal (working where the series diverges)?","Suppose we take consequtive derivatives of a function at a point and then interpolate them with Newton series (Newton interpolation formula) so to obtain a smooth curve. $$f^{(s)}(x)=\sum_{m=0}^{\infty} \binom {s}m \sum_{k=0}^m\binom mk(-1)^{m-k}f^{(k)}(x)$$ If the series converges at $s=-1$ we take this value to be the ""natural"" value of antiderivative of $f$ at the point $x$ (assuming that integral is the -1-th derivative). For instance, for function $f(x)=a^x$ the expansion converges (if converges, which is not the case for all $a$) to $a^x (\ln a)^s$, or $(\ln a)^s$ at $x=0$. Thus antiderivative of $a^x$ should naturally have value of $\frac{1}{\ln a}$ at $x=0$. Is there an easier way to obtain this value, and possibly, more universal (working where the series diverges)?",,"['integration', 'sequences-and-series', 'derivatives', 'partial-derivative']"
43,Why does the definition of an integral specify a closed interval?,Why does the definition of an integral specify a closed interval?,,"Here's the definition of an integral from Wikipedia: Given a function $f$ of a real variable $x$ and an interval $[a, b]$ of the   real line, the definite integral $$\int_a^b f(x) \, dx$$ is defined informally to be the area of the region in the $xy$-plane   bounded by the graph of $f$, the $x$-axis, and the vertical lines $x = a$   and $x = b$, such that area above the $x$-axis adds to the total, and that   below the $x$-axis subtracts from the total. Why do they specify a closed interval? Wouldn't using $(a,b)$ make no difference as the contribution to the integral from the endpoints $a$ and $b$ is zero as points have no width?","Here's the definition of an integral from Wikipedia: Given a function $f$ of a real variable $x$ and an interval $[a, b]$ of the   real line, the definite integral $$\int_a^b f(x) \, dx$$ is defined informally to be the area of the region in the $xy$-plane   bounded by the graph of $f$, the $x$-axis, and the vertical lines $x = a$   and $x = b$, such that area above the $x$-axis adds to the total, and that   below the $x$-axis subtracts from the total. Why do they specify a closed interval? Wouldn't using $(a,b)$ make no difference as the contribution to the integral from the endpoints $a$ and $b$ is zero as points have no width?",,['integration']
44,Integral with Bessel function,Integral with Bessel function,,"Let $n$ be half an odd integer, say $n=k+1/2, k \in \mathbb{N}$. Let $q\geq 1$. I would like to calculate (or approximate) the following integral: $$ \int_0^{\infty}\left(\sqrt{\frac{\pi}{2}}\cdot 1\cdot 3\cdot 5\cdots (2k+1) \frac{J_{k+\frac 12}(t)}{t^{k+ \frac 12}}\right)^q t\ dt. $$ Any ideas or references will be very helpful. Thank you.","Let $n$ be half an odd integer, say $n=k+1/2, k \in \mathbb{N}$. Let $q\geq 1$. I would like to calculate (or approximate) the following integral: $$ \int_0^{\infty}\left(\sqrt{\frac{\pi}{2}}\cdot 1\cdot 3\cdot 5\cdots (2k+1) \frac{J_{k+\frac 12}(t)}{t^{k+ \frac 12}}\right)^q t\ dt. $$ Any ideas or references will be very helpful. Thank you.",,"['integration', 'special-functions', 'approximation', 'approximation-theory', 'bessel-functions']"
45,Evaluate $\int_0^\infty\frac{dx}{1+x^2}\prod_i\arctan a_ix$ (product of arctangents and Lorentzian),Evaluate  (product of arctangents and Lorentzian),\int_0^\infty\frac{dx}{1+x^2}\prod_i\arctan a_ix,"Define $$I(a_1,\dots,a_n)=\int_0^\infty\frac{dx}{1+x^2}\prod_{i=1}^n\arctan a_ix$$ with $a_i>0$ . By this answer $\newcommand{Li}{\operatorname{Li}_2}$ $$I(a,b)= \frac\pi4\left(\frac{\pi^2}6 -\Li\left(\frac{1-a}{1+a}\right) -\Li\left(\frac{1-b}{1+b}\right) +\Li\left(\frac{1-a}{1+a}\frac{1-b}{1+b}\right)\right)$$ By taking the limit as $b\to\infty$ or by here we get $$I(a)= \frac12\left(\frac{\pi^2}4 -\Li\left(\frac{1-a}{1+a}\right) +\Li\left(-\frac{1-a}{1+a}\right)\right)$$ But I have not been able to reduce $I(a,b,c)$ to polylogarithms like the previous two equations. Can $I(a_1,\dots,a_n)$ be reduced to elementary functions, polylogarithms and possibly other special functions appearing in the literature for general $a_i$ and $n$ ? Contour integration might help for even $n$ . If not, then what about the special case where $a_i\in\{1,a\}$ for a given $a$ ? Such integrals occur in the probability discussed here . Here is my attempt at calculating $I(a,b,c)$ . Define the self-inverse transformation $f:v\mapsto\frac{1-v}{1+v}$ , $x=f(a),y=f(b),z=f(c)$ and $J(a,b,c)=I(f(a),f(b),f(c))$ . Then $I(a,b,c)=J(x,y,z)$ with $-1<x,y,z<1$ and we can get the Maclaurin series expansion of $J$ in $x,y,z$ by differentiating under the integral sign. Numerical results strongly suggest that the $x^iy^jz^k$ coefficient of this series is the sum of $\frac{2^{p-2}}{(i+j+k)(i-j-k)(j-k-i)(k-i-j)}$ if $i+j+k$ is odd, where $p$ of the exponents $i,j,k$ are positive $\frac{\pi^2}{16i^2}$ if $p=2$ and (without loss of generality) $i=j>0,k=0$ $-\frac{\pi^2}{8i^2}$ if $p=1$ and (without loss of generality) $i>0,j=k=0$ $\frac{\pi^4}{64}$ if $p=0$ (i.e. $i=j=k=0$ ) This would mean $\newcommand{Li}{\operatorname{Li}_2}$ $$I(a,b,c)=\frac{\pi^4}{64}-\frac{\pi^2}8(\Li(x)+\Li(y)+\Li(z))+\frac{\pi^2}{16}(\Li(xy)+\Li(zx)+\Li(yz))$$ $$+\sum_{i,j,k=0,2\nmid i+j+k}^\infty\frac{2^{p-2}}{(i+j+k)(i-j-k)(j-k-i)(k-i-j)}x^iy^jz^k$$ But an observed pattern is not a proof. How can this last equation be proved and can the last sum be reduced to special functions in the literature?","Define with . By this answer By taking the limit as or by here we get But I have not been able to reduce to polylogarithms like the previous two equations. Can be reduced to elementary functions, polylogarithms and possibly other special functions appearing in the literature for general and ? Contour integration might help for even . If not, then what about the special case where for a given ? Such integrals occur in the probability discussed here . Here is my attempt at calculating . Define the self-inverse transformation , and . Then with and we can get the Maclaurin series expansion of in by differentiating under the integral sign. Numerical results strongly suggest that the coefficient of this series is the sum of if is odd, where of the exponents are positive if and (without loss of generality) if and (without loss of generality) if (i.e. ) This would mean But an observed pattern is not a proof. How can this last equation be proved and can the last sum be reduced to special functions in the literature?","I(a_1,\dots,a_n)=\int_0^\infty\frac{dx}{1+x^2}\prod_{i=1}^n\arctan a_ix a_i>0 \newcommand{Li}{\operatorname{Li}_2} I(a,b)=
\frac\pi4\left(\frac{\pi^2}6
-\Li\left(\frac{1-a}{1+a}\right)
-\Li\left(\frac{1-b}{1+b}\right)
+\Li\left(\frac{1-a}{1+a}\frac{1-b}{1+b}\right)\right) b\to\infty I(a)=
\frac12\left(\frac{\pi^2}4
-\Li\left(\frac{1-a}{1+a}\right)
+\Li\left(-\frac{1-a}{1+a}\right)\right) I(a,b,c) I(a_1,\dots,a_n) a_i n n a_i\in\{1,a\} a I(a,b,c) f:v\mapsto\frac{1-v}{1+v} x=f(a),y=f(b),z=f(c) J(a,b,c)=I(f(a),f(b),f(c)) I(a,b,c)=J(x,y,z) -1<x,y,z<1 J x,y,z x^iy^jz^k \frac{2^{p-2}}{(i+j+k)(i-j-k)(j-k-i)(k-i-j)} i+j+k p i,j,k \frac{\pi^2}{16i^2} p=2 i=j>0,k=0 -\frac{\pi^2}{8i^2} p=1 i>0,j=k=0 \frac{\pi^4}{64} p=0 i=j=k=0 \newcommand{Li}{\operatorname{Li}_2} I(a,b,c)=\frac{\pi^4}{64}-\frac{\pi^2}8(\Li(x)+\Li(y)+\Li(z))+\frac{\pi^2}{16}(\Li(xy)+\Li(zx)+\Li(yz)) +\sum_{i,j,k=0,2\nmid i+j+k}^\infty\frac{2^{p-2}}{(i+j+k)(i-j-k)(j-k-i)(k-i-j)}x^iy^jz^k","['integration', 'definite-integrals', 'closed-form', 'polylogarithm']"
46,Domain over which $f(\alpha) = \int_0^\infty \frac{x^\alpha}{1 + x^2} \ \mathrm{d}x$ is convergent [duplicate],Domain over which  is convergent [duplicate],f(\alpha) = \int_0^\infty \frac{x^\alpha}{1 + x^2} \ \mathrm{d}x,"This question already has answers here : Does the integral converge $\int_{-\infty}^{+\infty}\frac{\exp(ibx)}{1+e^x}\,dx$ for $b>0$? (4 answers) Closed 9 months ago . For $-1 < \alpha < 1$ real, the below integral is well-known and an elementary exercise in complex analysis: \begin{align*} f(\alpha) \overset{\text{def}}{=} \displaystyle \int_0^\infty \frac{x^\alpha}{1 + x^2} \ \mathrm{d}x = \frac{\pi}{2} \sec \left(\frac{\pi}{2} \alpha\right ) \end{align*} However, $f$ can be extended as a complex function. In particular, over the region $D = \{\alpha \in \mathbb{C} : -1 < \operatorname{Re}(\alpha) < 1\}$ the above still holds, and I am reasonably sure $f$ blows up outside $\overline{D}$ . I was interested in the behaviour of $f$ over $\overline{D} \setminus D$ (i.e. when $\operatorname{Re}(\alpha) = \pm 1$ ). It is easily seen that if $\alpha = \pm 1$ then $f$ blows up, but e.g. Mathematica claims the above formula holds if $\alpha = 1 + i$ . However, Mathematica also won't give an output if I substitute $x = \tan\theta$ into the integral for $\alpha = 1 + i$ , and claims it is not convergent in a slightly older version, so I am hesitant in accepting its answer. I would like a solution that carefully analyses and determines the convergence of the integral over $\overline{D}\setminus D$ .","This question already has answers here : Does the integral converge $\int_{-\infty}^{+\infty}\frac{\exp(ibx)}{1+e^x}\,dx$ for $b>0$? (4 answers) Closed 9 months ago . For real, the below integral is well-known and an elementary exercise in complex analysis: However, can be extended as a complex function. In particular, over the region the above still holds, and I am reasonably sure blows up outside . I was interested in the behaviour of over (i.e. when ). It is easily seen that if then blows up, but e.g. Mathematica claims the above formula holds if . However, Mathematica also won't give an output if I substitute into the integral for , and claims it is not convergent in a slightly older version, so I am hesitant in accepting its answer. I would like a solution that carefully analyses and determines the convergence of the integral over .","-1 < \alpha < 1 \begin{align*}
f(\alpha) \overset{\text{def}}{=} \displaystyle \int_0^\infty \frac{x^\alpha}{1 + x^2} \ \mathrm{d}x = \frac{\pi}{2} \sec \left(\frac{\pi}{2} \alpha\right )
\end{align*} f D = \{\alpha \in \mathbb{C} : -1 < \operatorname{Re}(\alpha) < 1\} f \overline{D} f \overline{D} \setminus D \operatorname{Re}(\alpha) = \pm 1 \alpha = \pm 1 f \alpha = 1 + i x = \tan\theta \alpha = 1 + i \overline{D}\setminus D","['integration', 'complex-analysis', 'definite-integrals', 'contour-integration']"
47,"Closed form of $\int_0^1\frac{W_0(-t/e)}{W_{-1}(-t/e)} \,dt$",Closed form of,"\int_0^1\frac{W_0(-t/e)}{W_{-1}(-t/e)} \,dt","$\require{begingroup} \begingroup$ $\def\e{\mathrm{e}}\def\W{\operatorname{W}}\def\Wp{\operatorname{W_0}}\def\Wm{\operatorname{W_{-1}}}\def\Ei{\operatorname{Ei}}$ Is there a known closed form for the integral \begin{align}	 I&=\int_0^1 \frac{\Wp(-\tfrac t\e)}{\Wm(-\tfrac t\e)}  \,dt \approx 0.151216902884937 \tag{1}\label{1} , \end{align} where $\Wp,\Wm$ are two real branches of the Lambert $\W$ function? An alternative form of \eqref{1} is \begin{align}	 I&=\e\cdot\!\!\int_0^1 \frac{\sqrt[1-t]{t}(1-t+t\,\ln t)(t-1-\ln t)}{(1-t)^3} \, dt \tag{2}\label{2} . \end{align} Using series expansion of $\Wp$ it can be expressed in terms of the infinite sum: \begin{align} I&=\e-2- \e\cdot\sum_{n=1}^\infty \frac{\Gamma(n+2,n+1)}{\Gamma(n+2)\,n^3\,(1+\tfrac1n)^{n+1}} \tag{3}\label{3} . \end{align} Also, the closed form of \eqref{1}  can be found, using closed form of either \begin{align} I_2&=\int_0^1 \left(-\Wp(-\tfrac t\e)-\frac1{\Wm(-\tfrac t\e)}\right)^2\, dt \approx 0.62200121658 \\ \text{or }\quad  I_3&=\int_0^1 \left(-\Wp(-\tfrac t\e)+\frac1{\Wm(-\tfrac t\e)}\right)^2\, dt \approx 0.01713360504 , \end{align} or both, since \begin{align} I_2+I_3&= 20+4\,\e\,(\Ei(1,1)-2) \approx 0.639134821620414414482 , \end{align} where \begin{align} \Ei(1,1)&=\int_1^\infty \frac{\exp(-t)}t \, dt \approx 0.21938393439552 . \end{align} Any ideas? $\endgroup$","Is there a known closed form for the integral where are two real branches of the Lambert function? An alternative form of \eqref{1} is Using series expansion of it can be expressed in terms of the infinite sum: Also, the closed form of \eqref{1}  can be found, using closed form of either or both, since where Any ideas?","\require{begingroup} \begingroup \def\e{\mathrm{e}}\def\W{\operatorname{W}}\def\Wp{\operatorname{W_0}}\def\Wm{\operatorname{W_{-1}}}\def\Ei{\operatorname{Ei}} \begin{align}	
I&=\int_0^1
\frac{\Wp(-\tfrac t\e)}{\Wm(-\tfrac t\e)} 
\,dt
\approx 0.151216902884937
\tag{1}\label{1}
,
\end{align} \Wp,\Wm \W \begin{align}	
I&=\e\cdot\!\!\int_0^1
\frac{\sqrt[1-t]{t}(1-t+t\,\ln t)(t-1-\ln t)}{(1-t)^3}
\, dt
\tag{2}\label{2}
.
\end{align} \Wp \begin{align}
I&=\e-2-
\e\cdot\sum_{n=1}^\infty
\frac{\Gamma(n+2,n+1)}{\Gamma(n+2)\,n^3\,(1+\tfrac1n)^{n+1}}
\tag{3}\label{3}
.
\end{align} \begin{align}
I_2&=\int_0^1 \left(-\Wp(-\tfrac t\e)-\frac1{\Wm(-\tfrac t\e)}\right)^2\, dt
\approx 0.62200121658
\\
\text{or }\quad 
I_3&=\int_0^1 \left(-\Wp(-\tfrac t\e)+\frac1{\Wm(-\tfrac t\e)}\right)^2\, dt
\approx 0.01713360504
,
\end{align} \begin{align}
I_2+I_3&=
20+4\,\e\,(\Ei(1,1)-2)
\approx 0.639134821620414414482
,
\end{align} \begin{align}
\Ei(1,1)&=\int_1^\infty \frac{\exp(-t)}t \, dt
\approx 0.21938393439552
.
\end{align} \endgroup","['integration', 'definite-integrals', 'closed-form', 'lambert-w']"
48,( Proof Explanation ) Show that a certain system preserves the weighted area $ (dx \wedge dy)/xy$,( Proof Explanation ) Show that a certain system preserves the weighted area, (dx \wedge dy)/xy,"I already told few questions ago that I'm currently reading an abstract about the Lotka Volterra differential equations. But now I have a proof, where I need explanations. Consider: $$ \dot{x} = -xy\frac{\delta H}{ \delta y} , x(0) = \hat{x} $$ $$  \dot{y} = xy\frac{\delta H}{ \delta x} , y(0) = \hat{y} $$ where $H(x,y) = x + y - ln(x) -ln(y)$ . I have to show that this System preserve the weighted area $(dx \wedge dy)/xy$ . I marked my Questions in the proof below. Proof : Let $\Omega_0$ be a subset of $\mathbb{R}^2$ at time $t_0$ and $ \Omega_1$ the set into which $\Omega_0$ is mapped by the system above at time $t_1$ . Preservation of $(dx \wedge dy)xy$ is equivalent to $$ \int_{\Omega_0} \frac{1}{xy}dxdy = \int_{\Omega_1} \frac{1}{xy} dxdy $$ first Question: why is this equivalent? We now look at the Domain $D$ in x,y,t space with bondary $\delta D$ given by $\Omega_0$ at $t_0$ , $\Omega_1$ at $t_1$ and the set of trajectories emerging from the boundary of $\Omega_0$ and ending on the boudnary of $\Omega_1$ . Consider the vector field $$ v := \frac{1}{xy}(\dot{x},\dot{y},1)^T $$ in $x,y,t$ space. Integrating this vector field over the boundary $\delta D$ of $D$ , we obtain $$ \int_{\delta D} v \cdot n = \int_{\Omega_0} v \cdot n_0 + \int_{\Omega_1} v \cdot n_1 = \int_{\Omega_0} \frac{1}{xy} dxdy - \int_{\Omega_1} \frac{1}{xy}dxdy $$ where $n_0 =(0,0,-1)^T$ denote the unit outward normal of $\Omega_0$ and $\Omega_1$ . Second question & Third question: Can you explain why we integrate $v \cdot n$ ? I thought we integrate $v$ and can you explain the first equation above? There is no other contribution to the surface integral, because the vector field $v$ is by contruction parallel to the trajectories, which form the rest of the bondary $\delta D$ . Forth question: Can you explain why vector field is parallel to the trajectories? Applying the divergence theorem to the left hand side of the same equation, we get $$ \int_{\delta D} v \cdot n = \int_D \nabla v = \int_D - \frac{\delta H^2}{\delta x \delta y} + \frac{ \delta H^2}{\delta x \delta y} + 0 = 0 $$ which concludes the proof. I hope that my questions are not to easy, but I'm a beginner.","I already told few questions ago that I'm currently reading an abstract about the Lotka Volterra differential equations. But now I have a proof, where I need explanations. Consider: where . I have to show that this System preserve the weighted area . I marked my Questions in the proof below. Proof : Let be a subset of at time and the set into which is mapped by the system above at time . Preservation of is equivalent to first Question: why is this equivalent? We now look at the Domain in x,y,t space with bondary given by at , at and the set of trajectories emerging from the boundary of and ending on the boudnary of . Consider the vector field in space. Integrating this vector field over the boundary of , we obtain where denote the unit outward normal of and . Second question & Third question: Can you explain why we integrate ? I thought we integrate and can you explain the first equation above? There is no other contribution to the surface integral, because the vector field is by contruction parallel to the trajectories, which form the rest of the bondary . Forth question: Can you explain why vector field is parallel to the trajectories? Applying the divergence theorem to the left hand side of the same equation, we get which concludes the proof. I hope that my questions are not to easy, but I'm a beginner."," \dot{x} = -xy\frac{\delta H}{ \delta y} , x(0) = \hat{x}    \dot{y} = xy\frac{\delta H}{ \delta x} , y(0) = \hat{y}  H(x,y) = x + y - ln(x) -ln(y) (dx \wedge dy)/xy \Omega_0 \mathbb{R}^2 t_0  \Omega_1 \Omega_0 t_1 (dx \wedge dy)xy  \int_{\Omega_0} \frac{1}{xy}dxdy = \int_{\Omega_1} \frac{1}{xy} dxdy  D \delta D \Omega_0 t_0 \Omega_1 t_1 \Omega_0 \Omega_1  v := \frac{1}{xy}(\dot{x},\dot{y},1)^T  x,y,t \delta D D  \int_{\delta D} v \cdot n = \int_{\Omega_0} v \cdot n_0 + \int_{\Omega_1} v \cdot n_1 = \int_{\Omega_0} \frac{1}{xy} dxdy - \int_{\Omega_1} \frac{1}{xy}dxdy  n_0 =(0,0,-1)^T \Omega_0 \Omega_1 v \cdot n v v \delta D  \int_{\delta D} v \cdot n = \int_D \nabla v = \int_D - \frac{\delta H^2}{\delta x \delta y} + \frac{ \delta H^2}{\delta x \delta y} + 0 = 0 ","['integration', 'proof-explanation', 'vector-fields', 'surface-integrals']"
49,Show that $\int_{0}^{\pi\over 2}\arctan(\tan^8{(\pi^2{x}}))\mathrm dx={5\over 4}$,Show that,\int_{0}^{\pi\over 2}\arctan(\tan^8{(\pi^2{x}}))\mathrm dx={5\over 4},Can anyone help to provide a proof for $(1)$? Pleases! Thank you. $$\int_{0}^{\pi\over 2}\arctan(\tan^8{(\pi^2{x}}))\mathrm dx={5\over 4}\tag1$$ Enforcing $u=\tan^8{(\pi^2{x})}$ then $du={8\over \pi^2}\tan^7{(\pi^2{x})}\sec^2{(\pi^2{x})}dx$ Recall: $1+\tan^2{x}=\sec^2{x}$ $du={8\over \pi^2}\tan^7{(\pi^2{x})}+{8\over \pi^2}\tan^8{(\pi^2{x})}dx$ $${\pi^2\over 8}\int_{0}^{k}\arctan{u}\cdot{\mathrm du\over u+u^{7/8}}$$ $k=\arctan{\left(\tan^8{\left(\pi^3\over 2\right)}\right)}$ This is where I got so far. Can't go any further. Extra note I think this is the correct version $$\lim_{n\to \infty}\int_{0}^{\pi\over 2}\arctan(\tan^{2n}{(\pi^2{x}}))\mathrm dx={5\over 4}\tag2$$,Can anyone help to provide a proof for $(1)$? Pleases! Thank you. $$\int_{0}^{\pi\over 2}\arctan(\tan^8{(\pi^2{x}}))\mathrm dx={5\over 4}\tag1$$ Enforcing $u=\tan^8{(\pi^2{x})}$ then $du={8\over \pi^2}\tan^7{(\pi^2{x})}\sec^2{(\pi^2{x})}dx$ Recall: $1+\tan^2{x}=\sec^2{x}$ $du={8\over \pi^2}\tan^7{(\pi^2{x})}+{8\over \pi^2}\tan^8{(\pi^2{x})}dx$ $${\pi^2\over 8}\int_{0}^{k}\arctan{u}\cdot{\mathrm du\over u+u^{7/8}}$$ $k=\arctan{\left(\tan^8{\left(\pi^3\over 2\right)}\right)}$ This is where I got so far. Can't go any further. Extra note I think this is the correct version $$\lim_{n\to \infty}\int_{0}^{\pi\over 2}\arctan(\tan^{2n}{(\pi^2{x}}))\mathrm dx={5\over 4}\tag2$$,,['integration']
50,What happens when I convert a Taylor series into an integral?,What happens when I convert a Taylor series into an integral?,,"Suppose we have the Taylor series of an analytic function as follows: $$f(x) = \sum_{k=0}^\infty \frac{1}{k!} a_k x^k$$ Then I decide to (kind of) turn it into an integral: $$g(x) = \int_0^\infty \frac{1}{\Gamma(k+1)} a(k) x^k \, dk$$ Clearly, $f(x) \neq g(x)$.  But the values the two functions produce are somewhat close to each other.  What's the relation between the two?","Suppose we have the Taylor series of an analytic function as follows: $$f(x) = \sum_{k=0}^\infty \frac{1}{k!} a_k x^k$$ Then I decide to (kind of) turn it into an integral: $$g(x) = \int_0^\infty \frac{1}{\Gamma(k+1)} a(k) x^k \, dk$$ Clearly, $f(x) \neq g(x)$.  But the values the two functions produce are somewhat close to each other.  What's the relation between the two?",,"['integration', 'taylor-expansion', 'analyticity']"
51,Trigonometric Substitution,Trigonometric Substitution,,"I am having trouble with this problem even though everything I did seemed right to me since we went over a similar one in my class. I used the method of setting up a triangle, my hypotenuse is $\sqrt{54+9x^2}$ and my sides are $\sqrt{54}$ and $3x$. I got $\tan(t)=3x/\sqrt{54}$ so $$x=\sqrt{54} \tan(t) \frac{1}{3}$$ which left $$\sec(t) = \frac{\sqrt{54+9x^2}}{\frac{\sqrt{54}}{3}}$$ and then $$\frac{\sqrt{54}}{3} \sec(t) = \sqrt{54+9x^2}.$$ This left me with a simplified $6 \int \sec^3(t) \, dt$. After using the reduction formula my answer was $$3 \tan(t) \sec(t) +3 \ln |\sec(t) + \tan(t)| +C$$ and then I plugged back in with my $x$ values. If anyone can help it would be greatly appreciated!","I am having trouble with this problem even though everything I did seemed right to me since we went over a similar one in my class. I used the method of setting up a triangle, my hypotenuse is $\sqrt{54+9x^2}$ and my sides are $\sqrt{54}$ and $3x$. I got $\tan(t)=3x/\sqrt{54}$ so $$x=\sqrt{54} \tan(t) \frac{1}{3}$$ which left $$\sec(t) = \frac{\sqrt{54+9x^2}}{\frac{\sqrt{54}}{3}}$$ and then $$\frac{\sqrt{54}}{3} \sec(t) = \sqrt{54+9x^2}.$$ This left me with a simplified $6 \int \sec^3(t) \, dt$. After using the reduction formula my answer was $$3 \tan(t) \sec(t) +3 \ln |\sec(t) + \tan(t)| +C$$ and then I plugged back in with my $x$ values. If anyone can help it would be greatly appreciated!",,"['integration', 'trigonometry', 'triangles']"
52,Find this limit $\lim_{n\to\infty}\frac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n})$,Find this limit,\lim_{n\to\infty}\frac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n}),"let sequence $\{a_{n}\}$ such $$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ Useing Riemann integral of suitably chosen  functions,Find  the following limit $$I=\lim_{n\to\infty}\dfrac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n})$$ If  this problem can use Stloz lemma: we have $$I=\lim_{n\to\infty}\dfrac{a_{1}+a_{2}+\cdots+a_{n}}{n^{1+\alpha}}=\lim_{n\to\infty}\dfrac{a_{n}}{n^{1+\alpha}-(n-1)^{1+\alpha}}=\dfrac{1}{\alpha+1}$$ becasuse $$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ But use Riemann integral of suitably chosen  functions: I have $$I=\lim_{n\to\infty}\dfrac{1}{n}\sum_{i=1}^{n}\dfrac{a_{i}}{n^a}$$ I guess we will prove $$I=\int_{0}^{1}x^{\alpha}dx=\dfrac{1}{1+\alpha}$$ But I can't prove this equation. Thank you","let sequence $\{a_{n}\}$ such $$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ Useing Riemann integral of suitably chosen  functions,Find  the following limit $$I=\lim_{n\to\infty}\dfrac{1}{n^{1+\alpha}}(a_{1}+a_{2}+\cdots+a_{n})$$ If  this problem can use Stloz lemma: we have $$I=\lim_{n\to\infty}\dfrac{a_{1}+a_{2}+\cdots+a_{n}}{n^{1+\alpha}}=\lim_{n\to\infty}\dfrac{a_{n}}{n^{1+\alpha}-(n-1)^{1+\alpha}}=\dfrac{1}{\alpha+1}$$ becasuse $$\lim_{n\to\infty}\dfrac{a_{n}}{n^{\alpha}}=1(\alpha>0)$$ But use Riemann integral of suitably chosen  functions: I have $$I=\lim_{n\to\infty}\dfrac{1}{n}\sum_{i=1}^{n}\dfrac{a_{i}}{n^a}$$ I guess we will prove $$I=\int_{0}^{1}x^{\alpha}dx=\dfrac{1}{1+\alpha}$$ But I can't prove this equation. Thank you",,"['integration', 'limits']"
53,Surface integral of $2x+y+2z=16$,Surface integral of,2x+y+2z=16,"Here's the question: Find the surface area of the part of the plane $2x+y+2z=16$ bounded by the surfaces $x=0$, $y=0$ and $x^2+y^2=64$. So, I know I have to parameterize the surface $S:\mathbf{x}=\mathbf{x}(u,v)$ and I currently have it parameterized as $\mathbf{x}(u,v)=(\sqrt{32}\cos{u},\sqrt{32}\sin{u},v)$ because we're dealing with a circle of radius $8$ in the first quadrant (octants 1 and 5). If my parameterization is correct, then  $$\left\lVert\frac{\partial\mathbf{x}}{\partial u}\times \frac{\partial\mathbf{x}}{\partial u}\right\rVert=64.$$ I'm still confused about the bounds though. Obviously, $0\le u\le\pi/2$ but what about $v$? Help! Thank you :)","Here's the question: Find the surface area of the part of the plane $2x+y+2z=16$ bounded by the surfaces $x=0$, $y=0$ and $x^2+y^2=64$. So, I know I have to parameterize the surface $S:\mathbf{x}=\mathbf{x}(u,v)$ and I currently have it parameterized as $\mathbf{x}(u,v)=(\sqrt{32}\cos{u},\sqrt{32}\sin{u},v)$ because we're dealing with a circle of radius $8$ in the first quadrant (octants 1 and 5). If my parameterization is correct, then  $$\left\lVert\frac{\partial\mathbf{x}}{\partial u}\times \frac{\partial\mathbf{x}}{\partial u}\right\rVert=64.$$ I'm still confused about the bounds though. Obviously, $0\le u\le\pi/2$ but what about $v$? Help! Thank you :)",,"['integration', 'multivariable-calculus', 'definite-integrals', 'surfaces']"
54,proof of stokes theorem,proof of stokes theorem,,"I don't understand the ""idea"" of the following proof, as well as some of the steps. As I'm not sure about its ""ways"", I'm not editing it much and as such it might be in the wrong order. My sincere apologies. If you got any idea where to find that proof in the literature, I'd be very thankful! The proof works only on certain sets, equipped with the following properties: Definition ""Set of integration"" Let $G\subset \mathbb R^n$ be an open, bounded set and his boundary $\partial G:= \partial_r G \cup G_0$ so that the following holds true: $\partial G$ is a $(n-1)$-dimensional submanifold of  $\mathbb R^n$ dim$ G_0 < n-1$, (hausdoff-dimension or lower dimensional manifold) vol$(\partial_r G < \infty)$ For every $x \in \partial_r G$ exists an open subset $U \subset \mathbb R^n$, so that $x \in U$ and a diffeomorphism $\phi:U\to B^n\subset \mathbb R^n$, so that $\phi(U\cap G)=\{x \in B^n|x_1 > 0\}$. Stokes Theorem Let $G\subset \mathbb R^n$ be a set of integration. Let $U \supset \overline{G}$ be an open subset and $w \in \Lambda^{n-1} (U)$ a differential form. Then the following holds  true: $\int_G d\omega = \int _{\partial_r G} \omega $ Proof $\underline{n=1}$: $G$ is a union of finitely many intervalls. Question one :Do i get the finitely many intervalls because of the following argument? As $\partial_r G$ is of dimension zero according to 2., it's charts carry the discrete topology and therefore the charts domains are only single points. And with 3. and the counting measure the finity follows. Without the loss of substance we can limit ourself to one open intervall. Question two :With the exactness of the cohomolgy group on the intervall and and the fundamental theorem of integration follows: $\int_a^b f'(x) dx = f(b)-f(a)$ $\underline{1\to n}$: Let $H:=\{x \in R^n | x_1 = 0\}$, $pr_H : R^N \to H$ the orthgonal projection and $p:= pr_H|_\overline{G}$. Then $p(\overline{G})=p(\partial G)$: Question three :About: $p(\overline{G})=p(\partial G)$ $p(x)$ is closed, $p$ is continuous and $G$ is bounded therefore $p^{-1} (x)$ is compact.   With compactness we get the existence of a finite cover of $p^{-1}(x)$, so we get finitely many intervals.But how does that help me, if it's true? So that now we can write:(Fubini) $\int_G d\omega = \int _{p(G)} \int_{p^{-1}(x)} d\omega $ Here i will omit the proof and only name his next two claims. The author proves that: $p(G) \backslash p(\partial_r G)$ and $p(\partial_r G) \backslash p(G)$ are both null sets. And concludes with following lemma the proof of stokes theorem: Lemma Let $X,Y$ be oriented manifolds, dimension of $X$ and $Y$ should be $n$. And $\varphi:Y\to X$ a $C^1$ function, $\Omega \in \Lambda^n(X)$ and $f: Y \to \mathbb R$ be $\varphi ^* \Omega $ integratable. Then the following holds true: $\int_Y f\varphi^* \Omega = \int_X (\sum_y\in \varphi^{-1} f(y))\Omega$ where $\epsilon(y)$:= sign of the determinant of $d\varphi_y$ We can simplify the differential form $\omega$ to $\omega = f dx_2 \wedge ... \wedge dx_n$ and  $d\omega = \frac{\partial f}{\partial x_1} dx_1^...dx_n:=\omega_1 \wedge \Omega, \omega_1 \in \Lambda^1(U) $. For $\Omega = dx_2 \wedge ... \wedge dx_n$ there is $p^* \Omega = dx_2 \wedge...\wedge dx_n$ and we can write: $\int_{\partial_r G} \omega$ $= \int_{\partial_r G}p^*\Omega $ = $\int_{\partial_r G} f\Omega $= $\int_{p(\partial_r G)} (\sum_{y \in (p|_{\partial _r G})^{-1} (x) } \epsilon(y) f(y))\Omega$ And we have already shown that: $(p|_{\partial_r G})^{-1}= \{a_1,b1\} \cup ...\cup \{a_m,b_m\}$ And $\epsilon(a_j)=-1$,$\epsilon(b_j)=1$, so that:  $\sum_{y \in p^{-1}(x)}\epsilon(y)f(y)=\sum_{j=1,..,n} f(b_j)-f(a_j)=\int_p^{-1}(x) \frac{\partial f}{\partial x_1}dx_1$. Now we conclude that: $ \int_G d\omega $= $ \int_{p(\partial_r G)}(\int_{p|_G)^{-1}(x)} \frac{\partial f}{\partial x_1}\omega $ =$ \int_{p(\partial_r G)} (\sum_{y \in (p|_{\partial _r G})^{-1} (x) } \epsilon(y) f(y))\Omega = \int_{\partial_r G} \omega$ Question four: We now know that $p(G) \backslash p(\partial_r G)$ and $p(\partial_r G) \backslash p(G)$ are both null sets. I suppose we're using the Lebesgue measure to quantify a nullset. When doing the actual integration in the stokes theorem, we use the integral of a differential form, not the Lebesgue measure. Or am i wrong, in that we use the Lebesgue measure to define the integral of a differential form? And we do need to know that $G_0$ is a nullset for both sides $\omega$ and $d\omega$ because we use a Lebesgue measure of degree $n$ and one of degree $n-1$ ? I hope $p(G) \backslash p(\partial_r G)$ is a nullset for the measure of degree $n$ and $p(\partial_r G) \backslash p(G)$  for $n-1$. Question five: One more thing about the sort of interval $p^{-1}(x)$. He's basically using the fact that $p^{-1}(x) \in \mathbb R x \mathbb R^{n-1} \cong \mathbb R$, that means for orthogonal projections the intervall in $\mathbb R^n$ is canonically isomorph to $\mathbb R$.  So if we integrate now, we measure $p^{-1}(x)$ with the Lebesgue measure in $\mathbb R$? I guess that's some sort of fubini? Thanks again!","I don't understand the ""idea"" of the following proof, as well as some of the steps. As I'm not sure about its ""ways"", I'm not editing it much and as such it might be in the wrong order. My sincere apologies. If you got any idea where to find that proof in the literature, I'd be very thankful! The proof works only on certain sets, equipped with the following properties: Definition ""Set of integration"" Let $G\subset \mathbb R^n$ be an open, bounded set and his boundary $\partial G:= \partial_r G \cup G_0$ so that the following holds true: $\partial G$ is a $(n-1)$-dimensional submanifold of  $\mathbb R^n$ dim$ G_0 < n-1$, (hausdoff-dimension or lower dimensional manifold) vol$(\partial_r G < \infty)$ For every $x \in \partial_r G$ exists an open subset $U \subset \mathbb R^n$, so that $x \in U$ and a diffeomorphism $\phi:U\to B^n\subset \mathbb R^n$, so that $\phi(U\cap G)=\{x \in B^n|x_1 > 0\}$. Stokes Theorem Let $G\subset \mathbb R^n$ be a set of integration. Let $U \supset \overline{G}$ be an open subset and $w \in \Lambda^{n-1} (U)$ a differential form. Then the following holds  true: $\int_G d\omega = \int _{\partial_r G} \omega $ Proof $\underline{n=1}$: $G$ is a union of finitely many intervalls. Question one :Do i get the finitely many intervalls because of the following argument? As $\partial_r G$ is of dimension zero according to 2., it's charts carry the discrete topology and therefore the charts domains are only single points. And with 3. and the counting measure the finity follows. Without the loss of substance we can limit ourself to one open intervall. Question two :With the exactness of the cohomolgy group on the intervall and and the fundamental theorem of integration follows: $\int_a^b f'(x) dx = f(b)-f(a)$ $\underline{1\to n}$: Let $H:=\{x \in R^n | x_1 = 0\}$, $pr_H : R^N \to H$ the orthgonal projection and $p:= pr_H|_\overline{G}$. Then $p(\overline{G})=p(\partial G)$: Question three :About: $p(\overline{G})=p(\partial G)$ $p(x)$ is closed, $p$ is continuous and $G$ is bounded therefore $p^{-1} (x)$ is compact.   With compactness we get the existence of a finite cover of $p^{-1}(x)$, so we get finitely many intervals.But how does that help me, if it's true? So that now we can write:(Fubini) $\int_G d\omega = \int _{p(G)} \int_{p^{-1}(x)} d\omega $ Here i will omit the proof and only name his next two claims. The author proves that: $p(G) \backslash p(\partial_r G)$ and $p(\partial_r G) \backslash p(G)$ are both null sets. And concludes with following lemma the proof of stokes theorem: Lemma Let $X,Y$ be oriented manifolds, dimension of $X$ and $Y$ should be $n$. And $\varphi:Y\to X$ a $C^1$ function, $\Omega \in \Lambda^n(X)$ and $f: Y \to \mathbb R$ be $\varphi ^* \Omega $ integratable. Then the following holds true: $\int_Y f\varphi^* \Omega = \int_X (\sum_y\in \varphi^{-1} f(y))\Omega$ where $\epsilon(y)$:= sign of the determinant of $d\varphi_y$ We can simplify the differential form $\omega$ to $\omega = f dx_2 \wedge ... \wedge dx_n$ and  $d\omega = \frac{\partial f}{\partial x_1} dx_1^...dx_n:=\omega_1 \wedge \Omega, \omega_1 \in \Lambda^1(U) $. For $\Omega = dx_2 \wedge ... \wedge dx_n$ there is $p^* \Omega = dx_2 \wedge...\wedge dx_n$ and we can write: $\int_{\partial_r G} \omega$ $= \int_{\partial_r G}p^*\Omega $ = $\int_{\partial_r G} f\Omega $= $\int_{p(\partial_r G)} (\sum_{y \in (p|_{\partial _r G})^{-1} (x) } \epsilon(y) f(y))\Omega$ And we have already shown that: $(p|_{\partial_r G})^{-1}= \{a_1,b1\} \cup ...\cup \{a_m,b_m\}$ And $\epsilon(a_j)=-1$,$\epsilon(b_j)=1$, so that:  $\sum_{y \in p^{-1}(x)}\epsilon(y)f(y)=\sum_{j=1,..,n} f(b_j)-f(a_j)=\int_p^{-1}(x) \frac{\partial f}{\partial x_1}dx_1$. Now we conclude that: $ \int_G d\omega $= $ \int_{p(\partial_r G)}(\int_{p|_G)^{-1}(x)} \frac{\partial f}{\partial x_1}\omega $ =$ \int_{p(\partial_r G)} (\sum_{y \in (p|_{\partial _r G})^{-1} (x) } \epsilon(y) f(y))\Omega = \int_{\partial_r G} \omega$ Question four: We now know that $p(G) \backslash p(\partial_r G)$ and $p(\partial_r G) \backslash p(G)$ are both null sets. I suppose we're using the Lebesgue measure to quantify a nullset. When doing the actual integration in the stokes theorem, we use the integral of a differential form, not the Lebesgue measure. Or am i wrong, in that we use the Lebesgue measure to define the integral of a differential form? And we do need to know that $G_0$ is a nullset for both sides $\omega$ and $d\omega$ because we use a Lebesgue measure of degree $n$ and one of degree $n-1$ ? I hope $p(G) \backslash p(\partial_r G)$ is a nullset for the measure of degree $n$ and $p(\partial_r G) \backslash p(G)$  for $n-1$. Question five: One more thing about the sort of interval $p^{-1}(x)$. He's basically using the fact that $p^{-1}(x) \in \mathbb R x \mathbb R^{n-1} \cong \mathbb R$, that means for orthogonal projections the intervall in $\mathbb R^n$ is canonically isomorph to $\mathbb R$.  So if we integrate now, we measure $p^{-1}(x)$ with the Lebesgue measure in $\mathbb R$? I guess that's some sort of fubini? Thanks again!",,"['integration', 'manifolds']"
55,Is there an error in my work book? (Double integral),Is there an error in my work book? (Double integral),,"Hello it is my first post here! I have integral $$ \iint\frac{x^2}{x^2+y^2}\,\mathrm dx\mathrm dy $$ over the area bounded by $y=x$ , $2y=x^2$ . I tried to draw the area and it seemed like a pretty straightforward integral. Integrating by $\mathrm dx$ , I have that $x\in[0,2]$ , $y \in [\frac{x^2}{2}, x]$ . The integral then is: $$\int_0^2 \int_{\frac{x^2}{2}}^x \frac{x^2}{x^2+y^2} \,\mathrm dy\mathrm dx$$ (swapped the integrals because I can't integrate by dx first since it's in a boundary) which evaluates to $2 - \frac{\pi}{2}$ . However my workbook says that the solution is $\ln{2}$ . Is there an error?","Hello it is my first post here! I have integral over the area bounded by , . I tried to draw the area and it seemed like a pretty straightforward integral. Integrating by , I have that , . The integral then is: (swapped the integrals because I can't integrate by dx first since it's in a boundary) which evaluates to . However my workbook says that the solution is . Is there an error?","
\iint\frac{x^2}{x^2+y^2}\,\mathrm dx\mathrm dy
 y=x 2y=x^2 \mathrm dx x\in[0,2] y \in [\frac{x^2}{2}, x] \int_0^2 \int_{\frac{x^2}{2}}^x \frac{x^2}{x^2+y^2} \,\mathrm dy\mathrm dx 2 - \frac{\pi}{2} \ln{2}","['integration', 'multivariable-calculus', 'multiple-integral']"
56,Is there a closed-form for $\sum _{k=1}^{\infty }\frac{\operatorname{Si}\left(k\right)}{k^2}$?,Is there a closed-form for ?,\sum _{k=1}^{\infty }\frac{\operatorname{Si}\left(k\right)}{k^2},"So far I've got this: $$\sum _{k=1}^{\infty }\frac{\operatorname{Si}\left(k\right)}{k^2}=\int _0^1\left(\sum _{k=1}^{\infty }\frac{\sin \left(kx\right)}{k^2}\right)\frac{1}{x}\:dx$$ $$=\int _0^1\frac{\operatorname{Cl}_2\left(x\right)}{x}\:dx=\operatorname{\mathfrak{R}} \left\{\int _0^1\ln \left(1-e^{ix}\right)\ln \left(x\right)\:dx\right\}$$ $$=\frac{1}{2}\ln \left(2\right)\int _0^1\ln \left(x\right)\:dx+\frac{1}{2}\int _0^1\ln \left(1-\cos \left(x\right)\right)\ln \left(x\right)\:dx$$ $$=-\ln \left(2\right)+2\ln \left(2\right)\int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\:dx+2\int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\ln \left(x\right)\:dx$$ Where $\operatorname{Si}\left(k\right)=\int _0^k\frac{\sin \left(x\right)}{x}\:dx$ is the sine integral and $\operatorname{Cl}_2\left(x\right)=\sum _{k=1}^{\infty }\frac{\sin \left(kx\right)}{k^2}$ is the Clausen function. Note that: $$\int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\:dx=\frac{i}{8}-\frac{i}{2}\zeta \left(2\right)-\frac{1}{2}\ln \left(1-e^i\right)+\frac{i}{2}\operatorname{Li}_2\left(e^i\right)+\frac{1}{2}\ln \left(\sin \left(\frac{1}{2}\right)\right)$$ But I've no idea how to even start with that other integral, how to proceed with it or the sum?","So far I've got this: Where is the sine integral and is the Clausen function. Note that: But I've no idea how to even start with that other integral, how to proceed with it or the sum?",\sum _{k=1}^{\infty }\frac{\operatorname{Si}\left(k\right)}{k^2}=\int _0^1\left(\sum _{k=1}^{\infty }\frac{\sin \left(kx\right)}{k^2}\right)\frac{1}{x}\:dx =\int _0^1\frac{\operatorname{Cl}_2\left(x\right)}{x}\:dx=\operatorname{\mathfrak{R}} \left\{\int _0^1\ln \left(1-e^{ix}\right)\ln \left(x\right)\:dx\right\} =\frac{1}{2}\ln \left(2\right)\int _0^1\ln \left(x\right)\:dx+\frac{1}{2}\int _0^1\ln \left(1-\cos \left(x\right)\right)\ln \left(x\right)\:dx =-\ln \left(2\right)+2\ln \left(2\right)\int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\:dx+2\int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\ln \left(x\right)\:dx \operatorname{Si}\left(k\right)=\int _0^k\frac{\sin \left(x\right)}{x}\:dx \operatorname{Cl}_2\left(x\right)=\sum _{k=1}^{\infty }\frac{\sin \left(kx\right)}{k^2} \int _0^{\frac{1}{2}}\ln \left(\sin \left(x\right)\right)\:dx=\frac{i}{8}-\frac{i}{2}\zeta \left(2\right)-\frac{1}{2}\ln \left(1-e^i\right)+\frac{i}{2}\operatorname{Li}_2\left(e^i\right)+\frac{1}{2}\ln \left(\sin \left(\frac{1}{2}\right)\right),"['integration', 'sequences-and-series', 'definite-integrals', 'polylogarithm']"
57,How can two seemingly identical conditional expectations have different values?,How can two seemingly identical conditional expectations have different values?,,"Background Suppose that we are using a simplified spherical model of the Earth's surface with latitude $u \in (-\frac {\pi} 2, \frac {\pi} 2)$ and longitude $v \in (-\pi, \pi)$ . Restricting attention to the hemisphere, $H$ , where $u, v \in (-\frac {\pi} 2, \frac {\pi} 2)$ , a simple map projection from $H$ can be obtained by just taking the $x$ and $y$ coordinates via $x = \cos u \sin v$ and $y = \sin u$ , which is a smooth one-to-one transformation on $H$ . Now, picking a point with coordinates $(U, V)$ on $H$ uniformly according to surface area, the joint density of $U$ and $V$ is $$f_{U, V}(u, v) = \frac 1 {2\pi} \cos u, \quad \lvert u \rvert, \lvert v \rvert < \frac {\pi} 2.$$ Question $(a)\quad$ Find $\mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ . $(b)\quad$ Find $\mathbb{E}[\lvert Y \rvert \mid X = 0]$ . $(c)\quad$ Observe that $\lvert Y \rvert = \lvert \sin U \rvert$ and the event $\{X = 0\}$ is exactly the same as the event $\{V = 0\}$ . How is it possible that $\mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ ? My working I have omitted intermediate steps and only shown the essential parts to minimise the length of this post. $(a)$ $$\begin{aligned} \because f_{U \mid V = v}(u) & = \frac 1 2 \cos u,\quad \lvert u \rvert, \lvert v \rvert < \frac \pi 2 \\[5 mm] \therefore \mathbb{E}[\lvert \sin U \rvert \mid V = 0] & = \int^{\infty}_{-\infty} \lvert \sin u \rvert \left(\frac 1 2 \cos u\right)\ \mathrm{d}u \\[5 mm] & = \int^{\frac \pi 2}_0 \sin u \cos u\ \mathrm{d}u \\[5 mm] & = \frac 1 2 \end{aligned}$$ $(b)$ $$\begin{aligned} \\[5 mm] \because f_{X, Y}(x, y) & = \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1 \\[5 mm] \therefore f_{Y \mid X = x}(y) & = \frac {\frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}} {\int^{\sqrt{1 - x^2}}_{-\sqrt{1 - x^2}} \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}\ \mathrm{d}y} \\[5 mm] & = \frac 1 {\pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1 \\[5 mm] \implies \mathbb{E}[\lvert Y \rvert \mid X = 0] & = \int^{\infty}_{-\infty} \frac {\lvert y \rvert} {\pi \sqrt{1 - y^2}}\ \mathrm{d}y \\[5 mm] & = \frac 2 \pi \int^1_0 \frac y {\sqrt{1 - y^2}}\ \mathrm{d}y \\[5 mm] & = \frac 2 \pi \end{aligned}$$ $(c)\quad$ Although $\lvert Y \rvert = \lvert \sin U \rvert$ and the event $\{X = 0\}$ is indeed identical to the event $\{V = 0\}$ , we must be mindful of the coordinate systems in play here. In particular, there are two - the $(x, y)$ plane and the $(u, v)$ plane, which are not identical but related by a transformation. Thus, since $\lvert Y \rvert$ and the event $\{X = 0\}$ concern the $(x, y)$ plane, while $\lvert \sin U \rvert$ and the event $\{V = 0\}$ concern the $(u, v)$ plane, it follows that $\mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0]$ . I think my answers to $(a)$ and $(b)$ are correct, but I am not sure about my answer to $(c)$ , so any intuitive explanations will be greatly appreciated!","Background Suppose that we are using a simplified spherical model of the Earth's surface with latitude and longitude . Restricting attention to the hemisphere, , where , a simple map projection from can be obtained by just taking the and coordinates via and , which is a smooth one-to-one transformation on . Now, picking a point with coordinates on uniformly according to surface area, the joint density of and is Question Find . Find . Observe that and the event is exactly the same as the event . How is it possible that ? My working I have omitted intermediate steps and only shown the essential parts to minimise the length of this post. Although and the event is indeed identical to the event , we must be mindful of the coordinate systems in play here. In particular, there are two - the plane and the plane, which are not identical but related by a transformation. Thus, since and the event concern the plane, while and the event concern the plane, it follows that . I think my answers to and are correct, but I am not sure about my answer to , so any intuitive explanations will be greatly appreciated!","u \in (-\frac {\pi} 2, \frac {\pi} 2) v \in (-\pi, \pi) H u, v \in (-\frac {\pi} 2, \frac {\pi} 2) H x y x = \cos u \sin v y = \sin u H (U, V) H U V f_{U, V}(u, v) = \frac 1 {2\pi} \cos u, \quad \lvert u \rvert, \lvert v \rvert < \frac {\pi} 2. (a)\quad \mathbb{E}[\lvert \sin U \rvert \mid V = 0] (b)\quad \mathbb{E}[\lvert Y \rvert \mid X = 0] (c)\quad \lvert Y \rvert = \lvert \sin U \rvert \{X = 0\} \{V = 0\} \mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0] (a) \begin{aligned}
\because f_{U \mid V = v}(u) & = \frac 1 2 \cos u,\quad \lvert u \rvert, \lvert v \rvert < \frac \pi 2
\\[5 mm] \therefore \mathbb{E}[\lvert \sin U \rvert \mid V = 0] & = \int^{\infty}_{-\infty} \lvert \sin u \rvert \left(\frac 1 2 \cos u\right)\ \mathrm{d}u
\\[5 mm] & = \int^{\frac \pi 2}_0 \sin u \cos u\ \mathrm{d}u
\\[5 mm] & = \frac 1 2
\end{aligned} (b) \begin{aligned}
\\[5 mm] \because f_{X, Y}(x, y) & = \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1
\\[5 mm] \therefore f_{Y \mid X = x}(y) & = \frac {\frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}} {\int^{\sqrt{1 - x^2}}_{-\sqrt{1 - x^2}} \frac 1 {2 \pi \sqrt{1 - y^2 - x^2}}\ \mathrm{d}y}
\\[5 mm] & = \frac 1 {\pi \sqrt{1 - y^2 - x^2}}, \quad x^2 + y^2 < 1
\\[5 mm] \implies \mathbb{E}[\lvert Y \rvert \mid X = 0] & = \int^{\infty}_{-\infty} \frac {\lvert y \rvert} {\pi \sqrt{1 - y^2}}\ \mathrm{d}y
\\[5 mm] & = \frac 2 \pi \int^1_0 \frac y {\sqrt{1 - y^2}}\ \mathrm{d}y
\\[5 mm] & = \frac 2 \pi
\end{aligned} (c)\quad \lvert Y \rvert = \lvert \sin U \rvert \{X = 0\} \{V = 0\} (x, y) (u, v) \lvert Y \rvert \{X = 0\} (x, y) \lvert \sin U \rvert \{V = 0\} (u, v) \mathbb{E}[\lvert Y \rvert \mid X = 0] \neq \mathbb{E}[\lvert \sin U \rvert \mid V = 0] (a) (b) (c)","['integration', 'probability-theory', 'statistics', 'solution-verification', 'conditional-expectation']"
58,Evaluating $\int_0^1 \frac{\mathrm dx}{(x^2+ax+1)^{n+1}}$ with real methods,Evaluating  with real methods,\int_0^1 \frac{\mathrm dx}{(x^2+ax+1)^{n+1}},"I would like to know if there are any (preferably easier) methods of evaluating $$Q_n(a)=\int_0^1 \frac{\mathrm dx}{(x^2+ax+1)^{n+1}}$$ With real methods. Here's the way I did it. Complete the square: $$Q_n(a)=4^{n+1}\int_0^1\frac{\mathrm dx}{((2x+a)^2+4-a^2)^{n+1}}$$ Then $u=2x+a$ gives $$Q_n(a)=2^{2n+1}\int_a^{a+2}\frac{\mathrm du}{(u^2+4-a^2)^{n+1}}$$ Then consider the indefinite integral $$F_n^{w}(x)=\int\frac{\mathrm dx}{(x^2+w)^{n+1}}$$ Integration by parts yields the recurrence relation (for $n\in\Bbb Z\geq 1$ ) $$F_n^{w}(x)=\frac{x}{2wn(x^2+w)^n}+\frac{2n-1}{2wn}F_{n-1}^{w}(x)$$ With the base case $$F_0^{w}(x)=\frac1{\sqrt{w}}\arctan\frac{x}{\sqrt{w}}$$ And since this recurrence is in the form $$f_n=\alpha_n+\beta_nf_{n-1}$$ the solution to which is $$f_n=f_0\prod_{k=1}^{n}\beta_k+\sum_{k=0}^{n-1}\alpha_{n-k}\prod_{j=1}^{k}\beta_{n-j+1}$$ We have (I omit the simplification steps) $$F_n^{w}(x)=\frac{{2n\choose n}}{2^{2n}w^{n+1/2}}\arctan\frac{x}{\sqrt{w}}+S_n^w(x)$$ With $$S_n^w(x)=\frac{x}{2w}\sum_{r=0}^{n-1}\frac{(x^2+w)^{r-n}}{(2w)^r}R_r^{(n)}$$ and $$R_r^{(n)}=\frac1{n-r}\prod_{j=1}^{r}\frac{2n-2j+1}{n-j+1}$$ So we have that $$Q_n(a)=2^{2n+1}\left[F_n^{4-a^2}(a+2)-F_n^{4-a^2}(a)\right]$$ Which is, after some simplification, $$\begin{align} Q_n(a)=&\frac{2{2n\choose n}}{(4-a^2)^{n+1/2}}\left[\arctan\sqrt{\frac{2+a}{2-a}}-\arctan\frac{a}{\sqrt{4-a^2}}\right]\\ &+\frac1{4-a^2}\sum_{r=0}^{n-1}\frac{2^rR_r^{(n)}}{(4-a^2)^r}\left[(2+a)^{r-n+1}-a\right] \end{align}$$","I would like to know if there are any (preferably easier) methods of evaluating With real methods. Here's the way I did it. Complete the square: Then gives Then consider the indefinite integral Integration by parts yields the recurrence relation (for ) With the base case And since this recurrence is in the form the solution to which is We have (I omit the simplification steps) With and So we have that Which is, after some simplification,","Q_n(a)=\int_0^1 \frac{\mathrm dx}{(x^2+ax+1)^{n+1}} Q_n(a)=4^{n+1}\int_0^1\frac{\mathrm dx}{((2x+a)^2+4-a^2)^{n+1}} u=2x+a Q_n(a)=2^{2n+1}\int_a^{a+2}\frac{\mathrm du}{(u^2+4-a^2)^{n+1}} F_n^{w}(x)=\int\frac{\mathrm dx}{(x^2+w)^{n+1}} n\in\Bbb Z\geq 1 F_n^{w}(x)=\frac{x}{2wn(x^2+w)^n}+\frac{2n-1}{2wn}F_{n-1}^{w}(x) F_0^{w}(x)=\frac1{\sqrt{w}}\arctan\frac{x}{\sqrt{w}} f_n=\alpha_n+\beta_nf_{n-1} f_n=f_0\prod_{k=1}^{n}\beta_k+\sum_{k=0}^{n-1}\alpha_{n-k}\prod_{j=1}^{k}\beta_{n-j+1} F_n^{w}(x)=\frac{{2n\choose n}}{2^{2n}w^{n+1/2}}\arctan\frac{x}{\sqrt{w}}+S_n^w(x) S_n^w(x)=\frac{x}{2w}\sum_{r=0}^{n-1}\frac{(x^2+w)^{r-n}}{(2w)^r}R_r^{(n)} R_r^{(n)}=\frac1{n-r}\prod_{j=1}^{r}\frac{2n-2j+1}{n-j+1} Q_n(a)=2^{2n+1}\left[F_n^{4-a^2}(a+2)-F_n^{4-a^2}(a)\right] \begin{align}
Q_n(a)=&\frac{2{2n\choose n}}{(4-a^2)^{n+1/2}}\left[\arctan\sqrt{\frac{2+a}{2-a}}-\arctan\frac{a}{\sqrt{4-a^2}}\right]\\
&+\frac1{4-a^2}\sum_{r=0}^{n-1}\frac{2^rR_r^{(n)}}{(4-a^2)^r}\left[(2+a)^{r-n+1}-a\right]
\end{align}","['integration', 'definite-integrals']"
59,"Evaluate integral $\int_{0}^{\frac\pi2}\frac{x}{\sin(x)+6x} \, dx$",Evaluate integral,"\int_{0}^{\frac\pi2}\frac{x}{\sin(x)+6x} \, dx","Show that $$\int_0^{\pi/2}\frac x {\sin(x)+6x} \, dx =\frac{\pi}{2\sqrt2}\ln \left( \cot \frac \pi 8 \right)$$ I tried to apply a related theory for the integral using substitution for $x,$ since there is 0 as the lower interval,  $x=\frac\pi2-x $ $$\int_0^{\pi/2}\frac{\frac\pi2-x}{\sin(\frac\pi2-x)+6(\frac\pi2-x)} \, dx$$ But what to do next? Is there a specific substitution when there is a denominator with trigonometric and algebraic function together?","Show that $$\int_0^{\pi/2}\frac x {\sin(x)+6x} \, dx =\frac{\pi}{2\sqrt2}\ln \left( \cot \frac \pi 8 \right)$$ I tried to apply a related theory for the integral using substitution for $x,$ since there is 0 as the lower interval,  $x=\frac\pi2-x $ $$\int_0^{\pi/2}\frac{\frac\pi2-x}{\sin(\frac\pi2-x)+6(\frac\pi2-x)} \, dx$$ But what to do next? Is there a specific substitution when there is a denominator with trigonometric and algebraic function together?",,"['integration', 'trigonometric-integrals']"
60,Is the integral form of the polarisation identity useful for anything?,Is the integral form of the polarisation identity useful for anything?,,"It is well-known that the polarisation identity for real vector spaces is $$ \langle a,b \rangle =\frac{1}{4}\sum_{k=0}^1 (-1)^k\lVert a+(-1)^k b \rVert^2, $$ and the complex generalisation is $$ \langle a,b \rangle =\frac{1}{4}\sum_{k=0}^3 i^{-k} \lVert a+i^k b \rVert^2. $$ There are two generalisations of this: take $\omega$ a complex primitive $n$ th root of unity. Then $$ \langle a,b \rangle =\frac{1}{n}\sum_{k=0}^n \omega^{-k}\lVert a+\omega^k b \rVert^2, $$ because $ \frac{1}{n}\sum_{k=0}^n \omega^{mk} = 0 $ unless $m=0$ , when it's $1$ . (Note we need to be careful with $n=2$ , which is not enough to extract the imaginary part of a complex inner product: we instead have $$ \frac{1}{2}\sum_{k=0}^1 (-1)^{k} \lVert a+(-1)^k b \rVert^2 = \langle a,b \rangle - \langle b,a \rangle = 2\Re\langle a,b \rangle.) $$ But there's another generalisation: using Fourier series, we have $$ \langle a,b \rangle = \frac{1}{2\pi}\int_0^{2\pi} e^{-i\theta}\lVert a+e^{i\theta} b \rVert^2 \, d\theta \left( = \frac{1}{2\pi i}\int_{|z|=1} \frac{\lVert a+zb \rVert^2}{z^2} \, dz \right) $$ My question is: is this just a pretty identity, or are there situations where this is the ""right""/nicest form to use in proofs requiring a polarisation identity? Obviously it adds no new mathematical content, since the $n=4$ (indeed, $n=3$ ) case is sufficient to determine the inner product.","It is well-known that the polarisation identity for real vector spaces is and the complex generalisation is There are two generalisations of this: take a complex primitive th root of unity. Then because unless , when it's . (Note we need to be careful with , which is not enough to extract the imaginary part of a complex inner product: we instead have But there's another generalisation: using Fourier series, we have My question is: is this just a pretty identity, or are there situations where this is the ""right""/nicest form to use in proofs requiring a polarisation identity? Obviously it adds no new mathematical content, since the (indeed, ) case is sufficient to determine the inner product."," \langle a,b \rangle =\frac{1}{4}\sum_{k=0}^1 (-1)^k\lVert a+(-1)^k b \rVert^2,   \langle a,b \rangle =\frac{1}{4}\sum_{k=0}^3 i^{-k} \lVert a+i^k b \rVert^2.  \omega n  \langle a,b \rangle =\frac{1}{n}\sum_{k=0}^n \omega^{-k}\lVert a+\omega^k b \rVert^2,   \frac{1}{n}\sum_{k=0}^n \omega^{mk} = 0  m=0 1 n=2  \frac{1}{2}\sum_{k=0}^1 (-1)^{k} \lVert a+(-1)^k b \rVert^2 = \langle a,b \rangle - \langle b,a \rangle = 2\Re\langle a,b \rangle.)   \langle a,b \rangle = \frac{1}{2\pi}\int_0^{2\pi} e^{-i\theta}\lVert a+e^{i\theta} b \rVert^2 \, d\theta \left( = \frac{1}{2\pi i}\int_{|z|=1} \frac{\lVert a+zb \rVert^2}{z^2} \, dz \right)  n=4 n=3","['integration', 'hilbert-spaces', 'normed-spaces']"
61,"Contradiction from evaluating $\int _0^2 (x^2+1) \; d \lfloor x\rfloor$ by splitting into two parts, where is the error?","Contradiction from evaluating  by splitting into two parts, where is the error?",\int _0^2 (x^2+1) \; d \lfloor x\rfloor,"Evaluate: $$\int _0^2 (x^2+1)  \; d \lfloor x\rfloor$$ Here $[x]$ denotes the greatest integer function of $x$. I know this has to be done by parts as: $$\int _0^2 (x^2+1) \, d [x]= {|(1+x^2)[x]|}_0^2- \int_0^2 [x] \, d(1+x^2)$$ Note:- This integral can be quite easily evaluated.I don't need the method for this. But if we split the given integral into the sum of $2$ integrals as:- $$\int _0^2 (x^2+1) \, d [x]=\int _0^1 (x^2+1)  d [x]+\int _1^2 (x^2+1) \, d [x]$$ My question is as $[x]$ is constant in each of the intervals $[0,1)$  and $[1,2)$ in each of these $2$ integrals $d[x] = 0$ So, the value of the given integral should be $0$. This seems contradictory !! Kindly correct my reasoning for the part $d[x]=0$.","Evaluate: $$\int _0^2 (x^2+1)  \; d \lfloor x\rfloor$$ Here $[x]$ denotes the greatest integer function of $x$. I know this has to be done by parts as: $$\int _0^2 (x^2+1) \, d [x]= {|(1+x^2)[x]|}_0^2- \int_0^2 [x] \, d(1+x^2)$$ Note:- This integral can be quite easily evaluated.I don't need the method for this. But if we split the given integral into the sum of $2$ integrals as:- $$\int _0^2 (x^2+1) \, d [x]=\int _0^1 (x^2+1)  d [x]+\int _1^2 (x^2+1) \, d [x]$$ My question is as $[x]$ is constant in each of the intervals $[0,1)$  and $[1,2)$ in each of these $2$ integrals $d[x] = 0$ So, the value of the given integral should be $0$. This seems contradictory !! Kindly correct my reasoning for the part $d[x]=0$.",,"['integration', 'definite-integrals']"
62,Geometric intuition of improper integrals,Geometric intuition of improper integrals,,"I am aware that the area under the curve of $\frac{1}{x}$ is infinite yet the area under the curve of $\frac{1}{x^2}$ is finite. Calculus and series wise, I understand what is going on, but I can't seem to get a good geometric intuition of the problem. Both curves can be shown to converge to $0$ (the curves themselves, not the area), and on the interval from $1$ to infinity, the two curves have nothing intrinsically different. Can someone please provide me with an good geometric intuition of what's going on? I can't find anything on the web, people seem to not want to explain it geometrically.","I am aware that the area under the curve of $\frac{1}{x}$ is infinite yet the area under the curve of $\frac{1}{x^2}$ is finite. Calculus and series wise, I understand what is going on, but I can't seem to get a good geometric intuition of the problem. Both curves can be shown to converge to $0$ (the curves themselves, not the area), and on the interval from $1$ to infinity, the two curves have nothing intrinsically different. Can someone please provide me with an good geometric intuition of what's going on? I can't find anything on the web, people seem to not want to explain it geometrically.",,['integration']
63,The inverse Laplace transform of $ s^{3/2}-a-bs \over s^{3/2}+a+bs$,The inverse Laplace transform of, s^{3/2}-a-bs \over s^{3/2}+a+bs,"How can I solve the inverse Laplace transform as below: $$\mathscr{L}^{-1}\left( s^{3/2}-a-bs \over s^{3/2}+a+bs \right) $$ where a and b are constants. Hint: we can consider $${ s^{3/2}-a-bs \over s^{3/2}+a+bs} = {1 \over {1+as^{-3/2}+bs^{-1/2}}}-{a \over {s^{3/2}+bs+a}}-{b \over {s^{1/2}+as^{-1}+b}}$$ I applied residue theorem to each, and at the end I got 3 integrals which I could not solve, they are given by: $${1\over \pi} \int_{0}^{\infty}\left({{ax^{-3/2}-bx^{-1/2}}\over {1+(ax^{-3/2}-bx^{-1/2})^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ $${a\over \pi} \int_{0}^{\infty}\left({{x^{3/2}}\over {x^3+(a-bx)^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ and $${-b\over \pi} \int_{0}^{\infty}\left({{x^{1/2}}\over {x+(b-ax^{-1})^2}}\right) \exp(-xt)\,\mathrm{d} x. $$ Thanks!","How can I solve the inverse Laplace transform as below: $$\mathscr{L}^{-1}\left( s^{3/2}-a-bs \over s^{3/2}+a+bs \right) $$ where a and b are constants. Hint: we can consider $${ s^{3/2}-a-bs \over s^{3/2}+a+bs} = {1 \over {1+as^{-3/2}+bs^{-1/2}}}-{a \over {s^{3/2}+bs+a}}-{b \over {s^{1/2}+as^{-1}+b}}$$ I applied residue theorem to each, and at the end I got 3 integrals which I could not solve, they are given by: $${1\over \pi} \int_{0}^{\infty}\left({{ax^{-3/2}-bx^{-1/2}}\over {1+(ax^{-3/2}-bx^{-1/2})^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ $${a\over \pi} \int_{0}^{\infty}\left({{x^{3/2}}\over {x^3+(a-bx)^2}}\right) \exp(-xt)\,\mathrm{d} x, $$ and $${-b\over \pi} \int_{0}^{\infty}\left({{x^{1/2}}\over {x+(b-ax^{-1})^2}}\right) \exp(-xt)\,\mathrm{d} x. $$ Thanks!",,"['integration', 'inverse', 'laplace-transform', 'contour-integration', 'integral-transforms']"
64,show that $\int_0^{\infty}\sin(u\cosh x)\sin(u\sinh x)\frac{dx}{\sinh x}=\frac{\pi }{2}\sin u$,show that,\int_0^{\infty}\sin(u\cosh x)\sin(u\sinh x)\frac{dx}{\sinh x}=\frac{\pi }{2}\sin u,$$I(a)=\int_0^{\infty}\sin(u\cosh x)\sin(u\sinh x)\frac{dx}{\sinh x}:a>0$$ I started with $$\sin(a)\sin(b)=\frac{1}{2}(\cos(a-b)-\cos(a+b))$$ so $$I(a)=\frac{1}{2}\int_0^{\infty}\left ( \cos(ue^{-x})-\cos(ue^x) \right )\frac{dx}{\sinh x}$$ $t=e^x$ $$I(a)=\int_1^{\infty}\left ( \cos(ut^{-1})-\cos(ut) \right )\frac{dt}{t^2-1}$$ $t \to1/v$ $$I(a)=\int_0^{1}\left ( \cos(uv)-\cos(uv^{-1}) \right )\frac{dv}{1-v^2}$$ $$I(a)=\sum_{n=0}^{\infty}\int_0^{1}\left ( v^{2n}\cos(uv)-v^{2n}\cos(uv^{-1}) \right )dv$$ and I can't solve the last integral --- so what is your suggestions to solve the last integral or if there is better way to start using real analysis.,$$I(a)=\int_0^{\infty}\sin(u\cosh x)\sin(u\sinh x)\frac{dx}{\sinh x}:a>0$$ I started with $$\sin(a)\sin(b)=\frac{1}{2}(\cos(a-b)-\cos(a+b))$$ so $$I(a)=\frac{1}{2}\int_0^{\infty}\left ( \cos(ue^{-x})-\cos(ue^x) \right )\frac{dx}{\sinh x}$$ $t=e^x$ $$I(a)=\int_1^{\infty}\left ( \cos(ut^{-1})-\cos(ut) \right )\frac{dt}{t^2-1}$$ $t \to1/v$ $$I(a)=\int_0^{1}\left ( \cos(uv)-\cos(uv^{-1}) \right )\frac{dv}{1-v^2}$$ $$I(a)=\sum_{n=0}^{\infty}\int_0^{1}\left ( v^{2n}\cos(uv)-v^{2n}\cos(uv^{-1}) \right )dv$$ and I can't solve the last integral --- so what is your suggestions to solve the last integral or if there is better way to start using real analysis.,,"['integration', 'closed-form']"
65,How to solve this complicated double integral problem?,How to solve this complicated double integral problem?,,"I have written this in way to make it as much as possible non-confusing. I will start describing my problem and I will walk you through my question, I have a double integration which I am trying to solve of the following form, $$F=\int\limits_{0<\gamma_1<\gamma_2<+\infty} \mathcal{L}\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)\ g(\gamma_1,\gamma_2)\ d\gamma_1 d\gamma_2$$ where  $$\mathcal{L}(t) = \text{exp}\left(- \int_{\gamma_2}^\infty (1- \frac{1}{1+t \ x^{-1}})\ h(x)\ dx\right) $$ Now assume that $h(x)$ is a very complex expression,  I tell you that $\mathcal{L(t)}$ can not be integrated in closed form analytically and should be solved numerically. So to solve my problem I have to take numerical values of $t$ in order to integrate numerically. But notice that to solve my main integration $F$ defined above, I need to set $$t=\sum_{i=1}^2\gamma_i^{-1} $$ and then integrate numerically to obtain $L\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)$ by taking numerical values of $\gamma_1$ and $\gamma_2$. Now that I took numerical values of $\gamma_1$ and $\gamma_2$ to solve my $\mathcal {L}(t)$. My inner integral is then numerical values for certain values of $\gamma_1$ and $\gamma_2$ that I picked. My question is, since I was obliged to take certain values of $\gamma_1$ and $\gamma_2$ to solve for my non-integrable function $\mathcal{L}(t)$ - since it happened to be that by $t$ is a function of $\gamma_1$ and $\gamma_2$. How would I proceed to solve my function $F$? Am I now obliged to integrate numerically over the same values of $\gamma_1$ and $\gamma_2$ I picked to solve for  $\mathcal{L}(t)$ ? In general do you think this way of analyzing such a problem is correct. Any better ideas on tackling such a problem? for example approximations/ Thanks","I have written this in way to make it as much as possible non-confusing. I will start describing my problem and I will walk you through my question, I have a double integration which I am trying to solve of the following form, $$F=\int\limits_{0<\gamma_1<\gamma_2<+\infty} \mathcal{L}\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)\ g(\gamma_1,\gamma_2)\ d\gamma_1 d\gamma_2$$ where  $$\mathcal{L}(t) = \text{exp}\left(- \int_{\gamma_2}^\infty (1- \frac{1}{1+t \ x^{-1}})\ h(x)\ dx\right) $$ Now assume that $h(x)$ is a very complex expression,  I tell you that $\mathcal{L(t)}$ can not be integrated in closed form analytically and should be solved numerically. So to solve my problem I have to take numerical values of $t$ in order to integrate numerically. But notice that to solve my main integration $F$ defined above, I need to set $$t=\sum_{i=1}^2\gamma_i^{-1} $$ and then integrate numerically to obtain $L\bigl(\sum_{i=1}^2\gamma_i^{-1} \bigl)$ by taking numerical values of $\gamma_1$ and $\gamma_2$. Now that I took numerical values of $\gamma_1$ and $\gamma_2$ to solve my $\mathcal {L}(t)$. My inner integral is then numerical values for certain values of $\gamma_1$ and $\gamma_2$ that I picked. My question is, since I was obliged to take certain values of $\gamma_1$ and $\gamma_2$ to solve for my non-integrable function $\mathcal{L}(t)$ - since it happened to be that by $t$ is a function of $\gamma_1$ and $\gamma_2$. How would I proceed to solve my function $F$? Am I now obliged to integrate numerically over the same values of $\gamma_1$ and $\gamma_2$ I picked to solve for  $\mathcal{L}(t)$ ? In general do you think this way of analyzing such a problem is correct. Any better ideas on tackling such a problem? for example approximations/ Thanks",,"['integration', 'definite-integrals', 'improper-integrals', 'indefinite-integrals']"
66,Looking for a reference of integral involving product of four spherical harmonics,Looking for a reference of integral involving product of four spherical harmonics,,"We know $$\int d \Omega Y_{l_1m_1}(\theta,\phi) Y_{l_2 m_2}(\theta,\phi)  Y_{l_3 m_3 } (\theta,\phi) = \sqrt{ \frac{ (2l_1 + 1)(2 l_2+1)(2l_3+1)}{4\pi} } \pmatrix{ l_1 l_2 l_3 \\ m_1 m_2 m_3 } \pmatrix{ l_1 l_2 l_3 \\ 0 0 0 } $$ Is there any reference for integral involving four spherical harmonics? I could try to work it out myself, but a cross check with literature maybe useful","We know $$\int d \Omega Y_{l_1m_1}(\theta,\phi) Y_{l_2 m_2}(\theta,\phi)  Y_{l_3 m_3 } (\theta,\phi) = \sqrt{ \frac{ (2l_1 + 1)(2 l_2+1)(2l_3+1)}{4\pi} } \pmatrix{ l_1 l_2 l_3 \\ m_1 m_2 m_3 } \pmatrix{ l_1 l_2 l_3 \\ 0 0 0 } $$ Is there any reference for integral involving four spherical harmonics? I could try to work it out myself, but a cross check with literature maybe useful",,"['integration', 'spherical-harmonics']"
67,"How to find this integral $\int_{0}^{1}\frac{x}{1-x^4}\arctan{\frac{x-x^5}{1+x^6}}\,dx$",How to find this integral,"\int_{0}^{1}\frac{x}{1-x^4}\arctan{\frac{x-x^5}{1+x^6}}\,dx","Find the integral value $$ I=\int_{0}^{1} {x \over 1 - x^{4}}\,\arctan\left(x - x^{5} \over 1 + x^{6}\right)\,{\rm d}x $$ My good friends gave me this problem, and I can't solve it. Using computer I found closed form  $$ I=\int_{0}^{1}\left[{x \over 1 - x^{4}}\, \arctan\left(x - x^{5} \over 1 + x^{6}\right)\right]\,{\rm d}x ={\pi \over 8}\, \left[\left(1 + \,\sqrt{\,5\,}\, \over 2\right)^{3} - {\ln\left(5\right) \over 2}\right] $$","Find the integral value $$ I=\int_{0}^{1} {x \over 1 - x^{4}}\,\arctan\left(x - x^{5} \over 1 + x^{6}\right)\,{\rm d}x $$ My good friends gave me this problem, and I can't solve it. Using computer I found closed form  $$ I=\int_{0}^{1}\left[{x \over 1 - x^{4}}\, \arctan\left(x - x^{5} \over 1 + x^{6}\right)\right]\,{\rm d}x ={\pi \over 8}\, \left[\left(1 + \,\sqrt{\,5\,}\, \over 2\right)^{3} - {\ln\left(5\right) \over 2}\right] $$",,['integration']
68,"Does this inner product on $L^1([0,1])$ have a name?",Does this inner product on  have a name?,"L^1([0,1])","Math people: For $f, g \in L^1([0,1])$, define $$\langle f,g \rangle = \int_0^1 \int_0^1 f(t)g(t')\exp(-|t-t'|)dt'\,dt.$$ Although we don't normally think of $L^1([0,1])$ as an inner product space, this is an inner product on $L^1([0,1])$.  The only requirement that is not trivial to verify is positive-definiteness: $\langle f, f \rangle > 0$ for $f \neq 0$. This requires a straightforward argument that leads to integration by parts. My question is, has this been done before?  Does this have a name?  You can use an interval other than $[0,1]$ and use a sum of several positively weighted exponential functions if you want, but I wanted to give the simplest possible example.","Math people: For $f, g \in L^1([0,1])$, define $$\langle f,g \rangle = \int_0^1 \int_0^1 f(t)g(t')\exp(-|t-t'|)dt'\,dt.$$ Although we don't normally think of $L^1([0,1])$ as an inner product space, this is an inner product on $L^1([0,1])$.  The only requirement that is not trivial to verify is positive-definiteness: $\langle f, f \rangle > 0$ for $f \neq 0$. This requires a straightforward argument that leads to integration by parts. My question is, has this been done before?  Does this have a name?  You can use an interval other than $[0,1]$ and use a sum of several positively weighted exponential functions if you want, but I wanted to give the simplest possible example.",,"['functional-analysis', 'integration', 'reference-request', 'inner-products']"
69,How did you prove this integral?,How did you prove this integral?,,"This  is my problem, true or false? prove that: $$\int_{0}^{\infty}\frac{\displaystyle{\sum_{k=1}^{\infty}}k\sin(kx)\,e^{-tk^2}}{\displaystyle{\sum_{k=1}^{\infty}}\cos(kx)\,e^{-tk^2}}dt=\frac{\pi^2({\pi-x})}{8}$$ and $0<x<\dfrac{\pi}{2}$ Thank you.","This  is my problem, true or false? prove that: $$\int_{0}^{\infty}\frac{\displaystyle{\sum_{k=1}^{\infty}}k\sin(kx)\,e^{-tk^2}}{\displaystyle{\sum_{k=1}^{\infty}}\cos(kx)\,e^{-tk^2}}dt=\frac{\pi^2({\pi-x})}{8}$$ and $0<x<\dfrac{\pi}{2}$ Thank you.",,['integration']
70,Understanding intuition behind integral involving mixed product,Understanding intuition behind integral involving mixed product,,"The topological charge i.e. skyrmion number (also called wrapping number) is defined as the number of times the spin vectors in a 2D configuration (i.e. lying on a 2D plane, as shown in the image above, bottom 2) wrap around a unit sphere (as shown in the image above, top 2).  The integration is performed over this 2D configuration/plane (far away, the spins are zero). For a magnetic skyrmion, this is an integer number of times. The topological charge is defined as follows: $$ Q = \frac{1}{4\pi} \int \vec{n} \cdot \left( \frac{\partial \vec{n}}{\partial x} \times \frac{\partial \vec{n}}{\partial y} \right) dxdy, $$ where $\vec{n}$ is the (normalized) spin vector. You can write the spin vector as follows: $$ \vec{n} = \begin{pmatrix} \sin\theta \cos\phi \\ \sin\theta \sin\phi \\ \cos\theta \end{pmatrix} $$ If I understand correctly, this can be seen as a mapping from a two-dimensional space to the surface of a sphere $S^2$ , but not sure how to precisely define this. Any way, I am curious behind the intuition of this integral. Why exactly does this integral calculate the number of times the spins in a 2D configuration wrap a unit sphere? I recognize the fact that there is a mixed product which essentially measures the volume of the parallelepiped by the three vectors, and the fact that this could be related to solid angle, but it is not clear to me exactly how this follows (both mathematically and visually).","The topological charge i.e. skyrmion number (also called wrapping number) is defined as the number of times the spin vectors in a 2D configuration (i.e. lying on a 2D plane, as shown in the image above, bottom 2) wrap around a unit sphere (as shown in the image above, top 2).  The integration is performed over this 2D configuration/plane (far away, the spins are zero). For a magnetic skyrmion, this is an integer number of times. The topological charge is defined as follows: where is the (normalized) spin vector. You can write the spin vector as follows: If I understand correctly, this can be seen as a mapping from a two-dimensional space to the surface of a sphere , but not sure how to precisely define this. Any way, I am curious behind the intuition of this integral. Why exactly does this integral calculate the number of times the spins in a 2D configuration wrap a unit sphere? I recognize the fact that there is a mixed product which essentially measures the volume of the parallelepiped by the three vectors, and the fact that this could be related to solid angle, but it is not clear to me exactly how this follows (both mathematically and visually).","
Q = \frac{1}{4\pi} \int \vec{n} \cdot \left( \frac{\partial \vec{n}}{\partial x} \times \frac{\partial \vec{n}}{\partial y} \right) dxdy,
 \vec{n} 
\vec{n} = \begin{pmatrix}
\sin\theta \cos\phi \\
\sin\theta \sin\phi \\
\cos\theta
\end{pmatrix}
 S^2","['integration', 'multivariable-calculus', 'vectors']"
71,"Is there a generalized solution to the ""Freshman's dream"" of derivatives equation?","Is there a generalized solution to the ""Freshman's dream"" of derivatives equation?",,Michael Penn shows that $(f(x)g(x))^{\prime} = f^{\prime}(x) g^{\prime}(x)$ has solutions of the form $$f(x) = C \exp{\int \frac{g^{\prime}(x)}{g^{\prime}(x)-g(x)}dx}$$ for a given function $g(x)$ . Taking a generalization of this freshman's dream to be $$\left( \prod_{j=1}^n f_j (x)\right)^{\prime} = \left( \prod_{j=1}^n f_j^{\prime} (x)\right)$$ is there analogously a collection of formulae for constructing a solution? Blackpenredpen also considered the case of two functions.,Michael Penn shows that has solutions of the form for a given function . Taking a generalization of this freshman's dream to be is there analogously a collection of formulae for constructing a solution? Blackpenredpen also considered the case of two functions.,(f(x)g(x))^{\prime} = f^{\prime}(x) g^{\prime}(x) f(x) = C \exp{\int \frac{g^{\prime}(x)}{g^{\prime}(x)-g(x)}dx} g(x) \left( \prod_{j=1}^n f_j (x)\right)^{\prime} = \left( \prod_{j=1}^n f_j^{\prime} (x)\right),"['integration', 'derivatives']"
72,Integral from Ramanujan to Hardy,Integral from Ramanujan to Hardy,,"I came across the interesting family of integrals that was studied by Ramanujan and was one of subjects of his first letter to Hardy. $$ \phi(n):=\int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x $$ He offers a functional equation $$ \int_{0}^{\infty} \frac{\sin n x}{e^{2 \pi \sqrt{x}}-1} d x=\phi(n)-\frac{1}{2 n}+\phi\left(\frac{\pi^{2}}{n}\right) \sqrt{\frac{2 \pi^{3}}{n^{3}}} $$ And give some special cases, $$ \phi(0)=\frac{1}{12} ; \quad \phi\left(\frac{\pi}{2}\right)=\frac{1}{4 \pi} ; \quad \phi(\pi)=\frac{2-\sqrt{2}}{8} ; \quad \phi(2 \pi)=\frac{1}{16} $$ $$ \begin{gathered} \phi\left(\frac{2 \pi}{5}\right)=\frac{8-3 \sqrt{5}}{16} ; \quad \phi\left(\frac{\pi}{5}\right)=\frac{6+\sqrt{5}}{4}-\frac{5 \sqrt{10}}{8}  \\ \phi\left(\frac{2 \pi}{3}\right)=\frac{1}{3}-\sqrt{3}\left(\frac{3}{16}-\frac{1}{8 \pi}\right) \end{gathered} $$ The particular case $\phi(0)=\frac{1}{12}$ is easy to proof: $$ \begin{aligned} \phi(0)&=\int_{0}^{\infty} \frac{1}{e^{2 \pi \sqrt{x}}-1} d x \qquad (x \mapsto x^2)\\ &=2 \int_{0}^{\infty} \frac{x}{e^{2 \pi x}-1} d x \qquad (2\pi x \mapsto x)\\ &=\frac{1}{2 \pi^2} \int_{0}^{\infty} \frac{x}{e^{ x}-1} d x\\ &=\frac{1}{2 \pi^2} \zeta(2)\\ &=\frac{1}{12} \qquad \blacksquare \end{aligned} $$ I am interesting in computing $\phi(\pi)=\frac{2-\sqrt{2}}{8}$ $$ \phi(n)=\int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x $$ Letting $x \mapsto x^2$ we obtain $$ \begin{aligned} \phi(n)&=2\int_{0}^{\infty} \frac{x\cos n x^2}{e^{2 \pi x}-1} d x \qquad (2 \pi x \mapsto x)\\ &=\frac{1}{2 \pi^2}\int_{0}^{\infty} \frac{x\cos \frac{n x^2}{4 \pi^2} }{e^{ x}-1} d x \end{aligned} $$ Recall the Bernoulli polynomials generating function $$\sum_{k=0}^{\infty} \frac{B_{k} \, x^k}{k!} = \frac{x}{e^{x} - 1}$$ Then, letting $ n \rightarrow \pi$ we get $$ \begin{aligned} \phi(\pi)&=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}\int_{0}^{\infty} x^k\cos \frac{ x^2}{4 \pi}  d x \qquad (\frac{x^2}{4 \pi}=w)\\ &=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}(2 \sqrt{\pi})^{k+1}\int_{0}^{\infty} w^{\frac{k-1}{2}}\cos w  d w\\ &=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}(2 \sqrt{\pi})^{k+1}\Gamma \left(\frac{k+1}{2} \right)\cos\left(\frac{(k+1) \pi}{4} \right) \end{aligned} $$ Which does not seem very promising! Any idea how to proceed?","I came across the interesting family of integrals that was studied by Ramanujan and was one of subjects of his first letter to Hardy. He offers a functional equation And give some special cases, The particular case is easy to proof: I am interesting in computing Letting we obtain Recall the Bernoulli polynomials generating function Then, letting we get Which does not seem very promising! Any idea how to proceed?","
\phi(n):=\int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x
 
\int_{0}^{\infty} \frac{\sin n x}{e^{2 \pi \sqrt{x}}-1} d x=\phi(n)-\frac{1}{2 n}+\phi\left(\frac{\pi^{2}}{n}\right) \sqrt{\frac{2 \pi^{3}}{n^{3}}}
 
\phi(0)=\frac{1}{12} ; \quad \phi\left(\frac{\pi}{2}\right)=\frac{1}{4 \pi} ; \quad \phi(\pi)=\frac{2-\sqrt{2}}{8} ; \quad \phi(2 \pi)=\frac{1}{16}
 
\begin{gathered}
\phi\left(\frac{2 \pi}{5}\right)=\frac{8-3 \sqrt{5}}{16} ; \quad \phi\left(\frac{\pi}{5}\right)=\frac{6+\sqrt{5}}{4}-\frac{5 \sqrt{10}}{8}  \\
\phi\left(\frac{2 \pi}{3}\right)=\frac{1}{3}-\sqrt{3}\left(\frac{3}{16}-\frac{1}{8 \pi}\right)
\end{gathered}
 \phi(0)=\frac{1}{12} 
\begin{aligned}
\phi(0)&=\int_{0}^{\infty} \frac{1}{e^{2 \pi \sqrt{x}}-1} d x \qquad (x \mapsto x^2)\\
&=2 \int_{0}^{\infty} \frac{x}{e^{2 \pi x}-1} d x \qquad (2\pi x \mapsto x)\\
&=\frac{1}{2 \pi^2} \int_{0}^{\infty} \frac{x}{e^{ x}-1} d x\\
&=\frac{1}{2 \pi^2} \zeta(2)\\
&=\frac{1}{12} \qquad \blacksquare
\end{aligned}
 \phi(\pi)=\frac{2-\sqrt{2}}{8} 
\phi(n)=\int_{0}^{\infty} \frac{\cos n x}{e^{2 \pi \sqrt{x}}-1} d x
 x \mapsto x^2 
\begin{aligned}
\phi(n)&=2\int_{0}^{\infty} \frac{x\cos n x^2}{e^{2 \pi x}-1} d x \qquad (2 \pi x \mapsto x)\\
&=\frac{1}{2 \pi^2}\int_{0}^{\infty} \frac{x\cos \frac{n x^2}{4 \pi^2} }{e^{ x}-1} d x
\end{aligned}
 \sum_{k=0}^{\infty} \frac{B_{k} \, x^k}{k!} = \frac{x}{e^{x} - 1}  n \rightarrow \pi 
\begin{aligned}
\phi(\pi)&=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}\int_{0}^{\infty} x^k\cos \frac{ x^2}{4 \pi}  d x \qquad (\frac{x^2}{4 \pi}=w)\\
&=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}(2 \sqrt{\pi})^{k+1}\int_{0}^{\infty} w^{\frac{k-1}{2}}\cos w  d w\\
&=\frac{1}{2 \pi^2}\sum_{k=0}^{\infty} \frac{B_{k} }{k!}(2 \sqrt{\pi})^{k+1}\Gamma \left(\frac{k+1}{2} \right)\cos\left(\frac{(k+1) \pi}{4} \right)
\end{aligned}
",['integration']
73,Validating solution to PDE using integral transforms,Validating solution to PDE using integral transforms,,"I'm trying to obtain the analytical solution of a Fokker-Planck PDE, which the solution is a probability density function, and then use this to find the mean of some quantity in the paper. The paper has a solution which they say can be found via Mehler-Fock transform. Their solution which I am trying to obtain reads $$P_{\varepsilon}(L,u) = \frac{e^{-\varepsilon^2sL/4}}{2\sqrt{2\pi}(\varepsilon^2sL)^{\frac32}}\int_{u}^{\infty}\frac{xe^{-x^2/(\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dx.$$ I obtain a different solution to this one. $\textbf{My attempt:}$ The equation in the paper reads \begin{align} \frac{\partial P_\varepsilon}{\partial L} = \varepsilon^2s\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial P_\varepsilon}{\partial u}\bigg], \quad P_\varepsilon(L=0,u) = \delta(u-1). \end{align} This is a $1d$ Fokker-Planck equation, where $P_\varepsilon(L,u)$ is a probability density for some diffusion Markov process. To solve this equation, note that the right hand side is simply a Legendre differential equation. Denote the legendre function of the first kind via \begin{align} 	\frac{d}{du}(u^2-1)\frac{d}{du}P_{-\frac12+i\mu}(u) = -\bigg(\mu^2+\frac14\bigg)P_{-\frac12+i\mu}(u), \end{align} which has an integral representation \begin{align} 	P_{-\frac12+i\mu}(u) = \frac{\sqrt{2}}{\pi}\cosh{(\pi\mu)}\int_{0}^{\infty}\frac{\cos{(\mu\tau)}}{\sqrt{\cosh{(\tau)}+u}}d\tau. \end{align} Now use the Mehler-Fock transform. The Mehler-Fock transform of an integrble function $f$ defined on $[1,\infty)$ is the function $\check f$ defined on $[0,\infty)$ where \begin{align} \hat{f}(\mu) = \int_{1}^{\infty}f(u) P_{-\frac12+i\mu}(u)\,du, \end{align} with inverse transform \begin{align} 	f(u) = \int_{0}^{\infty}\check{f}(\mu)\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u)\,d\mu. \end{align} Applying the Mehler-Fock transform to the PDF $P_\varepsilon(L,u)$ gives \begin{align} 	\check p(L,\mu) = \int_{1}^{\infty}p(L,u)P_{-\frac12+i\mu}(u)du. \end{align} Taking a partial derivative in $L$ gives \begin{align} 	\frac{\partial\check p}{\partial L}(L,\mu) = \varepsilon^2s\int_{1}^{\infty}\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial p}{\partial u}(L,u)\bigg]P_{-\frac12+i\mu}(u)du. \end{align} Integrating twice more by parts gives \begin{align} 	\frac{\partial\check p}{\partial L}(L,\mu) = \varepsilon^2s\int_{1}^{\infty}p(L,u)\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial P_{-\frac12+i\mu}}{\partial u}(u)\bigg]du. \end{align} Using the ODE $(2)$ which satisfies the Legendre function, the Mehler-Fock transform satisfies the ODE \begin{align} 	\frac{\partial \check p}{\partial L}(L,\mu) = -\varepsilon^2s\bigg(\mu^2+\frac14\bigg)\check p(L,\mu), \quad \check p(L=0,\mu) = 1. \end{align} Then \begin{align} 	\check p(L,\mu) = \exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}. \end{align} Hence, the solution to $(1)$ is \begin{align}\nonumber 	P_\varepsilon(L,u) &= \int_{0}^{\infty}\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u)\exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}d\mu \\ 	&= \int_{0}^{\infty}\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u) = \frac{\sqrt{2}}{\pi}\cosh{(\pi\mu)}\int_{0}^{\infty}\frac{\cos{(\mu\tau)}}{\sqrt{\cosh{(\tau)}+u}} \\ &\times\exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}d\tau d\mu. \end{align} This paper claims to have a solution $$P_{\varepsilon}(L,u) = \frac{e^{-\varepsilon^2sL/4}}{2\sqrt{2\pi}(\varepsilon^2sL)^{\frac32}}\int_{u}^{\infty}\frac{xe^{-x^2/(\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dx.$$ Here I have computed my solution vs theirs, for varying parameter $L\in[1,10]$ and fixed $\varepsilon^2s$ Clearly they do not agree. $\textbf{My second question}$ is how they use this solution to find a mean value via \begin{align}\mathbb{E(R)} &= \int_{1}^{\infty}\bigg(\frac{u-1}{u+1}\bigg)P_{\varepsilon}(L,u)du \\ &= \frac{e^{(-\varepsilon^2sL/4)}}{2\sqrt{2\pi}(\varepsilon^2Ls)^{\frac32}}\int_{1}^{\infty}\bigg(\frac{u-1}{u+1}\bigg)\int_{u}^{\infty}\frac{xe^{-x^2/(4\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dxdu \end{align} $\textbf{AND then reduce this expression to read}$ $$\mathbb{E(R)}=1-\frac{4}{\sqrt{\pi}}e^{-\varepsilon^2sL}\int_{0}^{\infty}\frac{x^2e^{-x^2}}{\cosh{(\sqrt{\varepsilon^2sL}x)}}dx,$$ since it's easy to see asymptotically that they behave differently. I'm looking for help in either of these questions. Thanks for the help in advance.","I'm trying to obtain the analytical solution of a Fokker-Planck PDE, which the solution is a probability density function, and then use this to find the mean of some quantity in the paper. The paper has a solution which they say can be found via Mehler-Fock transform. Their solution which I am trying to obtain reads I obtain a different solution to this one. The equation in the paper reads This is a Fokker-Planck equation, where is a probability density for some diffusion Markov process. To solve this equation, note that the right hand side is simply a Legendre differential equation. Denote the legendre function of the first kind via which has an integral representation Now use the Mehler-Fock transform. The Mehler-Fock transform of an integrble function defined on is the function defined on where with inverse transform Applying the Mehler-Fock transform to the PDF gives Taking a partial derivative in gives Integrating twice more by parts gives Using the ODE which satisfies the Legendre function, the Mehler-Fock transform satisfies the ODE Then Hence, the solution to is This paper claims to have a solution Here I have computed my solution vs theirs, for varying parameter and fixed Clearly they do not agree. is how they use this solution to find a mean value via since it's easy to see asymptotically that they behave differently. I'm looking for help in either of these questions. Thanks for the help in advance.","P_{\varepsilon}(L,u) = \frac{e^{-\varepsilon^2sL/4}}{2\sqrt{2\pi}(\varepsilon^2sL)^{\frac32}}\int_{u}^{\infty}\frac{xe^{-x^2/(\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dx. \textbf{My attempt:} \begin{align}
\frac{\partial P_\varepsilon}{\partial L} = \varepsilon^2s\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial P_\varepsilon}{\partial u}\bigg], \quad P_\varepsilon(L=0,u) = \delta(u-1).
\end{align} 1d P_\varepsilon(L,u) \begin{align}
	\frac{d}{du}(u^2-1)\frac{d}{du}P_{-\frac12+i\mu}(u) = -\bigg(\mu^2+\frac14\bigg)P_{-\frac12+i\mu}(u),
\end{align} \begin{align}
	P_{-\frac12+i\mu}(u) = \frac{\sqrt{2}}{\pi}\cosh{(\pi\mu)}\int_{0}^{\infty}\frac{\cos{(\mu\tau)}}{\sqrt{\cosh{(\tau)}+u}}d\tau.
\end{align} f [1,\infty) \check f [0,\infty) \begin{align}
\hat{f}(\mu) = \int_{1}^{\infty}f(u) P_{-\frac12+i\mu}(u)\,du,
\end{align} \begin{align}
	f(u) = \int_{0}^{\infty}\check{f}(\mu)\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u)\,d\mu.
\end{align} P_\varepsilon(L,u) \begin{align}
	\check p(L,\mu) = \int_{1}^{\infty}p(L,u)P_{-\frac12+i\mu}(u)du.
\end{align} L \begin{align}
	\frac{\partial\check p}{\partial L}(L,\mu) = \varepsilon^2s\int_{1}^{\infty}\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial p}{\partial u}(L,u)\bigg]P_{-\frac12+i\mu}(u)du.
\end{align} \begin{align}
	\frac{\partial\check p}{\partial L}(L,\mu) = \varepsilon^2s\int_{1}^{\infty}p(L,u)\frac{\partial}{\partial u}\bigg[(u^2-1)\frac{\partial P_{-\frac12+i\mu}}{\partial u}(u)\bigg]du.
\end{align} (2) \begin{align}
	\frac{\partial \check p}{\partial L}(L,\mu) = -\varepsilon^2s\bigg(\mu^2+\frac14\bigg)\check p(L,\mu), \quad \check p(L=0,\mu) = 1.
\end{align} \begin{align}
	\check p(L,\mu) = \exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}.
\end{align} (1) \begin{align}\nonumber
	P_\varepsilon(L,u) &= \int_{0}^{\infty}\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u)\exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}d\mu \\
	&= \int_{0}^{\infty}\mu\tanh{(\mu\pi)}P_{-\frac12+i\mu}(u) = \frac{\sqrt{2}}{\pi}\cosh{(\pi\mu)}\int_{0}^{\infty}\frac{\cos{(\mu\tau)}}{\sqrt{\cosh{(\tau)}+u}} \\
&\times\exp{\bigg(-\bigg(\mu^2+\frac14\bigg)L\varepsilon^2s\bigg)}d\tau d\mu.
\end{align} P_{\varepsilon}(L,u) = \frac{e^{-\varepsilon^2sL/4}}{2\sqrt{2\pi}(\varepsilon^2sL)^{\frac32}}\int_{u}^{\infty}\frac{xe^{-x^2/(\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dx. L\in[1,10] \varepsilon^2s \textbf{My second question} \begin{align}\mathbb{E(R)} &= \int_{1}^{\infty}\bigg(\frac{u-1}{u+1}\bigg)P_{\varepsilon}(L,u)du \\
&= \frac{e^{(-\varepsilon^2sL/4)}}{2\sqrt{2\pi}(\varepsilon^2Ls)^{\frac32}}\int_{1}^{\infty}\bigg(\frac{u-1}{u+1}\bigg)\int_{u}^{\infty}\frac{xe^{-x^2/(4\varepsilon^2sL)}}{\sqrt{\cosh{(x)}-\cosh{(u)}}}dxdu
\end{align} \textbf{AND then reduce this expression to read} \mathbb{E(R)}=1-\frac{4}{\sqrt{\pi}}e^{-\varepsilon^2sL}\int_{0}^{\infty}\frac{x^2e^{-x^2}}{\cosh{(\sqrt{\varepsilon^2sL}x)}}dx,","['integration', 'partial-differential-equations', 'improper-integrals', 'contour-integration', 'integral-transforms']"
74,"Evaluate $\iiint_{[0,1]^3}\frac{dx\,dy\,dz}{(1+x^2+y^2+z^2)^2}$",Evaluate,"\iiint_{[0,1]^3}\frac{dx\,dy\,dz}{(1+x^2+y^2+z^2)^2}","As in the title I have to evaluate this triple integral: $$\iiint_{[0,1]^3}\frac{dx\,dy\,dz}{(1+x^2+y^2+z^2)^2}$$ I've been trying to solve this since a week ago. The first thing I've done was understand the meaning of the integral. I think this integral represents the mass (as an example) of a unitary cube which contains materials of different density. The values of the materials density are, point for point, the inverse of the square of spheres centered in the origin plus one. The max value of the density is $1$ in the origin of the cube and the min value is $\frac{1}{16}$ on the opposite vertex. I suppose that the value of the integral is $\frac{\pi^2}{32}$ I've tried to use simple substitutions without any results, so I tried to change the coordinates with spherical and cylindrical systems. The spherical coordinates give me an incredibly long sum of integrals and I doubt that they're all integrable as elementary functions. The cylindrical gives me the following result $$\frac{\pi^2}{16}-\int_0^\frac{\sqrt2}{2}{\frac{\arctan{\sqrt{\frac{u^2-1}{u^2-2}}}}{\sqrt{2-u^2}}du},$$ which I'm not able to solve. My instinct tells me that there is a trick in some steps where I can observe that a difficult integral actually is exactly half of another one simpler but I can't figure out where. I'll appreciate any kind of suggestions.","As in the title I have to evaluate this triple integral: I've been trying to solve this since a week ago. The first thing I've done was understand the meaning of the integral. I think this integral represents the mass (as an example) of a unitary cube which contains materials of different density. The values of the materials density are, point for point, the inverse of the square of spheres centered in the origin plus one. The max value of the density is in the origin of the cube and the min value is on the opposite vertex. I suppose that the value of the integral is I've tried to use simple substitutions without any results, so I tried to change the coordinates with spherical and cylindrical systems. The spherical coordinates give me an incredibly long sum of integrals and I doubt that they're all integrable as elementary functions. The cylindrical gives me the following result which I'm not able to solve. My instinct tells me that there is a trick in some steps where I can observe that a difficult integral actually is exactly half of another one simpler but I can't figure out where. I'll appreciate any kind of suggestions.","\iiint_{[0,1]^3}\frac{dx\,dy\,dz}{(1+x^2+y^2+z^2)^2} 1 \frac{1}{16} \frac{\pi^2}{32} \frac{\pi^2}{16}-\int_0^\frac{\sqrt2}{2}{\frac{\arctan{\sqrt{\frac{u^2-1}{u^2-2}}}}{\sqrt{2-u^2}}du},","['integration', 'multivariable-calculus', 'definite-integrals', 'multiple-integral']"
75,"integrate $F(x)$: NO complex analysis, NO multivariable calculus","integrate : NO complex analysis, NO multivariable calculus",F(x),"Suppose I have an elementary function $F(x)$ for which $\int_{-\infty}^\infty F(x) \, \text{d}x $ has an elementary value. Here 'elementary value' means anything generated by $0,1,+,-,\div,\times,\exp,\sin$ . Suppose, indeed, I can compute this value by means of complex contours or multivariable calculus — the latter being involved, say, in Feynman's trick or in the Fourier transform. Can it be proved that I could have given a proof that the integral has that exact value, by 'single-variable methods' alone? That is to say, without differentiating or integrating anything with two real variables $x,y$ ? Will it suffice to work in the language of single-variable calculus? I don't profess to know any model theory, so do help me to formulate the question more precisely. I'm astounded to learn that for $F(x)=\frac{\sin(x)}{x}$ , there are such methods: Evaluating the integral $\int_0^\infty \frac{\sin x} x \ dx = \frac \pi 2$ ? But a general result would be all the more fascinating.","Suppose I have an elementary function for which has an elementary value. Here 'elementary value' means anything generated by . Suppose, indeed, I can compute this value by means of complex contours or multivariable calculus — the latter being involved, say, in Feynman's trick or in the Fourier transform. Can it be proved that I could have given a proof that the integral has that exact value, by 'single-variable methods' alone? That is to say, without differentiating or integrating anything with two real variables ? Will it suffice to work in the language of single-variable calculus? I don't profess to know any model theory, so do help me to formulate the question more precisely. I'm astounded to learn that for , there are such methods: Evaluating the integral ? But a general result would be all the more fascinating.","F(x) \int_{-\infty}^\infty F(x) \, \text{d}x  0,1,+,-,\div,\times,\exp,\sin x,y F(x)=\frac{\sin(x)}{x} \int_0^\infty \frac{\sin x} x \ dx = \frac \pi 2","['integration', 'improper-integrals', 'elementary-functions']"
76,Using the Saddle point method (or Laplace method) for a multiple integral over a large number of variables,Using the Saddle point method (or Laplace method) for a multiple integral over a large number of variables,,"I am trying to understand the saddle point method used in the large N limit of matrix models. First, for the case of the integral of a single variable I found this notes There they say that you can approximate the integral $$I(A)=\int_{-\infty}^\infty e^{Ag(x)} dx$$ by expanding $A g(x)$ in powers of $y=(x-x_0)\sqrt{A}$ $$Ag(x)=Ag(x_0)+\frac{1}{2}g''(x_0)y^2+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\dots$$ where $x_0$ is a maximum of $g(x)$. Then we expand the exponential $e^{Ag(x)}$ $$e^{Ag(x)}=e^{Ag(x_0)}e^{\frac{1}{2}g''(x_0)y^2}(1+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\frac{g''''(x_0)}{72A}y^4+\dots)$$ so now $$I(A)=e^{Ag(x_0)}\int_{-\infty}^\infty \frac{dy}{\sqrt{A}}e^{\frac{1}{2}g''(x_0)y^2}(1+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\frac{g''''(x_0)}{72A}y^4+\dots) $$ The first integral is a gaussian, the others are known, so this gives an asymptotic series $$I(A)=e^{Ag(x_0)}\sqrt{\frac{2\pi}{-Ag''(x_0)}}(1+\frac{C_2}{A}+\frac{C_4}{A^2}+\dots) $$ Now, I want to do the same for the large N limit of partition function of a matrix model. The partition function is a multiple integral over a large number of variables $$Z=\int_{-\infty}^\infty [dm] e^{-N^2 S(m)}$$ $$[dm]=\prod_{j=1}^{N}dm_j$$ Here, the action is a function of $N$ variables. For the gaussian model for example $$S(m)=\frac{2}{\lambda N}\sum_{j'=1}^N m_{j'}^2-\frac{2}{N^2}\sum_{j'=2}^N\sum_{i=1}^{j'-1}\ln|m_i-m_{j'} |$$ Let's say $m_{(0)}$ is the minimun of $S(m)$. Using Taylor expansion of several variables we have $$e^{-N^2S(m)}=e^{-N^2S(m_{(0)})} \ e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \ e^{-\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots}$$ where the vector $u$ is $$u=N(m-m_{(0)})$$ $$e^{-N^2S(m)}=e^{-N^2S(m_{(0)})} \ e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \left(1 -\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots\right)$$ so now $$Z=N^{-N}e^{-N^2S(m_{(0)})}\times\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \left(1 -\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots\right)$$ Now, the first integral is a gaussian. The second integral $$\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})=0$$ The problem is in the third integral $$C=\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})$$ Since $$(u\cdot\nabla)^4S(m_{(0)})=\sum u_{i_1}u_{i_2}u_{i_3}u_{i_4}\partial_{i_1}\partial_{i_2}\partial_{i_3}\partial_{i_4}S(m_{(0)})$$ we have $$C=\frac{1}{4!N^2}\sum \partial_{i_1}\partial_{i_2}\partial_{i_3}\partial_{i_4}S(m_{(0)})\int [du]u_{i_1}u_{i_2}u_{i_3}u_{i_4}e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}$$ The sum over indices will give an order $N^4$ so it seems that $C$ is bigger than the gaussian integral, the opposite of what you expect. What is the problem here? Have I done the power counting properly? I want to get an asymptotic series where the terms get smaller and smaller.","I am trying to understand the saddle point method used in the large N limit of matrix models. First, for the case of the integral of a single variable I found this notes There they say that you can approximate the integral $$I(A)=\int_{-\infty}^\infty e^{Ag(x)} dx$$ by expanding $A g(x)$ in powers of $y=(x-x_0)\sqrt{A}$ $$Ag(x)=Ag(x_0)+\frac{1}{2}g''(x_0)y^2+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\dots$$ where $x_0$ is a maximum of $g(x)$. Then we expand the exponential $e^{Ag(x)}$ $$e^{Ag(x)}=e^{Ag(x_0)}e^{\frac{1}{2}g''(x_0)y^2}(1+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\frac{g''''(x_0)}{72A}y^4+\dots)$$ so now $$I(A)=e^{Ag(x_0)}\int_{-\infty}^\infty \frac{dy}{\sqrt{A}}e^{\frac{1}{2}g''(x_0)y^2}(1+\frac{g'''(x_0)}{6\sqrt{A}}y^3+\frac{g''''(x_0)}{72A}y^4+\dots) $$ The first integral is a gaussian, the others are known, so this gives an asymptotic series $$I(A)=e^{Ag(x_0)}\sqrt{\frac{2\pi}{-Ag''(x_0)}}(1+\frac{C_2}{A}+\frac{C_4}{A^2}+\dots) $$ Now, I want to do the same for the large N limit of partition function of a matrix model. The partition function is a multiple integral over a large number of variables $$Z=\int_{-\infty}^\infty [dm] e^{-N^2 S(m)}$$ $$[dm]=\prod_{j=1}^{N}dm_j$$ Here, the action is a function of $N$ variables. For the gaussian model for example $$S(m)=\frac{2}{\lambda N}\sum_{j'=1}^N m_{j'}^2-\frac{2}{N^2}\sum_{j'=2}^N\sum_{i=1}^{j'-1}\ln|m_i-m_{j'} |$$ Let's say $m_{(0)}$ is the minimun of $S(m)$. Using Taylor expansion of several variables we have $$e^{-N^2S(m)}=e^{-N^2S(m_{(0)})} \ e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \ e^{-\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots}$$ where the vector $u$ is $$u=N(m-m_{(0)})$$ $$e^{-N^2S(m)}=e^{-N^2S(m_{(0)})} \ e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \left(1 -\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots\right)$$ so now $$Z=N^{-N}e^{-N^2S(m_{(0)})}\times\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})} \left(1 -\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})-\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})+\dots\right)$$ Now, the first integral is a gaussian. The second integral $$\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}\frac{1}{3!N}(u\cdot\nabla)^3S(m_{(0)})=0$$ The problem is in the third integral $$C=\int [du]e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}\frac{1}{4!N^2}(u\cdot\nabla)^4S(m_{(0)})$$ Since $$(u\cdot\nabla)^4S(m_{(0)})=\sum u_{i_1}u_{i_2}u_{i_3}u_{i_4}\partial_{i_1}\partial_{i_2}\partial_{i_3}\partial_{i_4}S(m_{(0)})$$ we have $$C=\frac{1}{4!N^2}\sum \partial_{i_1}\partial_{i_2}\partial_{i_3}\partial_{i_4}S(m_{(0)})\int [du]u_{i_1}u_{i_2}u_{i_3}u_{i_4}e^{-\frac{1}{2}(u\cdot\nabla)^2S(m_{(0)})}$$ The sum over indices will give an order $N^4$ so it seems that $C$ is bigger than the gaussian integral, the opposite of what you expect. What is the problem here? Have I done the power counting properly? I want to get an asymptotic series where the terms get smaller and smaller.",,"['integration', 'asymptotics', 'approximation-theory', 'laplace-method']"
77,Definition of closed Poincaré dual,Definition of closed Poincaré dual,,"I'm studying De Rham Theory on some lecture notes. I have searched in many other references, but I have not found a clear answer. The question is simple, but involves a fundamental definition. I recall a fact. Let $M$ be an orientable $n$ -dimensional manifold without boundary. For all $q\in\mathbb{Z}$ , Poincaré Duality provides an isomorphism $H^q_{DR}(M)\simeq(H^{n-q}_c(M))^*$ given by the map $$ \delta: H^q_{DR}(M) \longmapsto (H^{n-q}_c(M))^*,$$ $$[\eta]\longmapsto ([\omega]\mapsto\int_M\eta\wedge\omega). $$ Let $S$ be a $k$ -dimensional closed submanifold without boundary embedded in $M$ and let $\int_S\colon H^{k}_c(M)\to\mathbb{R}$ be defined by $\int_S\omega=\int_S \omega_{|S}$ . The closed Poincaré dual of $S$ is the unique cohomology class $[\eta_S]\in H^{n-k}_{DR}(M)$ such that, for all $[\omega]\in H^{k}_c(M)$ , it holds that $$\int_S\omega=\int_M\omega\wedge \eta_S \tag{1}$$ My question : for which reason we require the closed Poincaré dual of $S$ to satisfy $(1)$ instead of $$\int_S\omega=\int_M\eta_S \wedge \omega,$$ as $\delta$ , the Poincaré Duality isomorphism above, would suggest? It should be true that $\int_M\omega\wedge \eta_S=(-1)^{k(n-k)}\int_M\eta_S \wedge \omega$ , so why do we forget the sign? Is it not important, since it depends on the orientation of $M$ ? Is the isomorphism $\delta$ not completely correct?","I'm studying De Rham Theory on some lecture notes. I have searched in many other references, but I have not found a clear answer. The question is simple, but involves a fundamental definition. I recall a fact. Let be an orientable -dimensional manifold without boundary. For all , Poincaré Duality provides an isomorphism given by the map Let be a -dimensional closed submanifold without boundary embedded in and let be defined by . The closed Poincaré dual of is the unique cohomology class such that, for all , it holds that My question : for which reason we require the closed Poincaré dual of to satisfy instead of as , the Poincaré Duality isomorphism above, would suggest? It should be true that , so why do we forget the sign? Is it not important, since it depends on the orientation of ? Is the isomorphism not completely correct?","M n q\in\mathbb{Z} H^q_{DR}(M)\simeq(H^{n-q}_c(M))^*  \delta: H^q_{DR}(M) \longmapsto (H^{n-q}_c(M))^*, [\eta]\longmapsto ([\omega]\mapsto\int_M\eta\wedge\omega).  S k M \int_S\colon H^{k}_c(M)\to\mathbb{R} \int_S\omega=\int_S \omega_{|S} S [\eta_S]\in H^{n-k}_{DR}(M) [\omega]\in H^{k}_c(M) \int_S\omega=\int_M\omega\wedge \eta_S \tag{1} S (1) \int_S\omega=\int_M\eta_S \wedge \omega, \delta \int_M\omega\wedge \eta_S=(-1)^{k(n-k)}\int_M\eta_S \wedge \omega M \delta","['integration', 'differential-geometry', 'algebraic-topology', 'duality-theorems']"
78,Canceling out integral,Canceling out integral,,"Bear with my naivety, I wanted to ask if it is possible to cancel out $\int$ with a $\frac{\mathrm d}{\mathrm dx}$. I had $\frac{\partial}{\partial v}$ in a question and I took $\partial v$ to the other side and took integration on both sides. So now on left hand side only $\partial$ remains so will it cancel out with the integral?","Bear with my naivety, I wanted to ask if it is possible to cancel out $\int$ with a $\frac{\mathrm d}{\mathrm dx}$. I had $\frac{\partial}{\partial v}$ in a question and I took $\partial v$ to the other side and took integration on both sides. So now on left hand side only $\partial$ remains so will it cancel out with the integral?",,"['integration', 'differential']"
79,Intuition of a tangent vector being a line segment in the context of integration,Intuition of a tangent vector being a line segment in the context of integration,,"Following my previous question on the meaning of dx , and my read on A geometric approach of differential forms , I was trying to work out the intuition on paper. tldr of the post : $\frac{\partial f}{\partial x}$ the tangent vector can be thought as a line segment. $dx$ can be though as evaluating the length of a vector (i.e line segment) and takes the value 1 on the basis vector. So let's say we want to generalize integration on manifolds, in the nice case of a Riemannian manifold with euclidean structure, we chop the coordinates axis, evaluate the volume of the little pieces and multiply that by the value of the function. So for the 1D case : \begin{align} \sum f(x_i)\Delta_i  \end{align} with $\Delta_i = x_{i+1} - x_i$. The integral is taken by taking the limit when $\Delta_i \rightarrow 0$ This is pretty intuitive and geometric. So on a manifold (let's say we are working on a local patch and do not worry of partition of unity etc...) we have no way to chop up the manifold into little pieces to compute the volume. So we decide to approximate the manifold by a linear space known as the Tangent space $T_pM$. Elements of $T_pM$ are vectors which are directional derivative operators. I know that when you take the directional derivative of a function you find the linear approximation of the function. So I do not understand why $\frac{\partial}{\partial x}$ would be this object since no function are involve. I understand the object $\frac{\partial}{\partial x}$ as a basis vector of the Tangent space, but not as a representative of the linear approximation of the manifold. This is my number (1) issue. Let's say now that elements of the tangent space are indeed locally (using an euclidean structure which is always possible on a manifold locally ) represent line segments. Then we have no notion of length in $T_pM$ so we introduce differential forms that eat a Vector and spit out a number. We call this number the ""length"" of the vector. This work out good because everything is linear as we expect. Just the value is completely arbitrary (but at least is consistent with addition and scaling). So looking at the littles $\Delta_i$ from the beginning we can replace them by $\omega(X_i)$ where $\omega$ is a volume form and $X_i$ a Tangent vector at the point $i$. This way we form the sum : \begin{align} \sum f(x_i)\omega(X_i) \end{align} We can incorporate the function f with the volume form to form a differential 1 form (using $dx$ as basis) and we have : \begin{align} \sum f(x_i)dx_i(X_i) \end{align} Now comes my number (2) issue. I know that $dx_i(X_i) = 1$ by definition, but the goal of the Rieamann sum is to make something goes to 0 to have a better and better approximation of the sum. So My guess is that $dx_i(X_i)$ has to go to $0$. So here is my way to do it. We can multiply $X_i$ by $\frac{1}{n}$ and make $n\rightarrow \infty$. So : \begin{align} \sum f(x_i)dx_i(\frac{1}{n}X_i) = \sum \frac{1}{n}f(x_i)dx_i(X_i) \end{align} Now this last expression os attractive but I do not know how to proceed. We can always cancel $dx_i(X_i) = 1$ but then we are left with what seems to be ill-defined under change of coordinates. So to sum up : Why $X_p \in T_p M$ can be seen as a line element ? It is an operator and when we plug in a function, it is the best linear approximation of the function at $p$. How come we can interpret it as being the best linear approximation of the manifold ( also supported by the drawing of an arrow attached to $p$ pointing in the Tangent direction of the manifold ) How to derive a well defined Riemann sum for arbitrary manifold (since we can't integrate function on manifold) and how all of this fits together (intuition of volume, differential forms, and integration using Sums) I appreciate any suggestions / references !","Following my previous question on the meaning of dx , and my read on A geometric approach of differential forms , I was trying to work out the intuition on paper. tldr of the post : $\frac{\partial f}{\partial x}$ the tangent vector can be thought as a line segment. $dx$ can be though as evaluating the length of a vector (i.e line segment) and takes the value 1 on the basis vector. So let's say we want to generalize integration on manifolds, in the nice case of a Riemannian manifold with euclidean structure, we chop the coordinates axis, evaluate the volume of the little pieces and multiply that by the value of the function. So for the 1D case : \begin{align} \sum f(x_i)\Delta_i  \end{align} with $\Delta_i = x_{i+1} - x_i$. The integral is taken by taking the limit when $\Delta_i \rightarrow 0$ This is pretty intuitive and geometric. So on a manifold (let's say we are working on a local patch and do not worry of partition of unity etc...) we have no way to chop up the manifold into little pieces to compute the volume. So we decide to approximate the manifold by a linear space known as the Tangent space $T_pM$. Elements of $T_pM$ are vectors which are directional derivative operators. I know that when you take the directional derivative of a function you find the linear approximation of the function. So I do not understand why $\frac{\partial}{\partial x}$ would be this object since no function are involve. I understand the object $\frac{\partial}{\partial x}$ as a basis vector of the Tangent space, but not as a representative of the linear approximation of the manifold. This is my number (1) issue. Let's say now that elements of the tangent space are indeed locally (using an euclidean structure which is always possible on a manifold locally ) represent line segments. Then we have no notion of length in $T_pM$ so we introduce differential forms that eat a Vector and spit out a number. We call this number the ""length"" of the vector. This work out good because everything is linear as we expect. Just the value is completely arbitrary (but at least is consistent with addition and scaling). So looking at the littles $\Delta_i$ from the beginning we can replace them by $\omega(X_i)$ where $\omega$ is a volume form and $X_i$ a Tangent vector at the point $i$. This way we form the sum : \begin{align} \sum f(x_i)\omega(X_i) \end{align} We can incorporate the function f with the volume form to form a differential 1 form (using $dx$ as basis) and we have : \begin{align} \sum f(x_i)dx_i(X_i) \end{align} Now comes my number (2) issue. I know that $dx_i(X_i) = 1$ by definition, but the goal of the Rieamann sum is to make something goes to 0 to have a better and better approximation of the sum. So My guess is that $dx_i(X_i)$ has to go to $0$. So here is my way to do it. We can multiply $X_i$ by $\frac{1}{n}$ and make $n\rightarrow \infty$. So : \begin{align} \sum f(x_i)dx_i(\frac{1}{n}X_i) = \sum \frac{1}{n}f(x_i)dx_i(X_i) \end{align} Now this last expression os attractive but I do not know how to proceed. We can always cancel $dx_i(X_i) = 1$ but then we are left with what seems to be ill-defined under change of coordinates. So to sum up : Why $X_p \in T_p M$ can be seen as a line element ? It is an operator and when we plug in a function, it is the best linear approximation of the function at $p$. How come we can interpret it as being the best linear approximation of the manifold ( also supported by the drawing of an arrow attached to $p$ pointing in the Tangent direction of the manifold ) How to derive a well defined Riemann sum for arbitrary manifold (since we can't integrate function on manifold) and how all of this fits together (intuition of volume, differential forms, and integration using Sums) I appreciate any suggestions / references !",,"['integration', 'differential-geometry', 'reference-request', 'riemann-sum']"
80,"On Bourbaki's ""Integration"" - Why/What/How to read it","On Bourbaki's ""Integration"" - Why/What/How to read it",,"I have a question concerning the Bourbaki 's book on integration . Whenever I find them referenced (in answers on this site as well), it looks like they aged more than volumes of the same series on other topics. Also, it looks like they were criticised from the outset (e.g. see Halmos' comment from page 11 of this chapter ). Thus, the questions: why? Is there a problem in the entire approach to the topic? What was problematic in it? How sensible is to read them right now, beyond historical purposes? What should somebody have in mind when reading them? How shoud somebody read them? Given the answer to question (1), what should be taken, and what should be dismissed? Thank you as always for any feedback. PS: Moreover, right now, are there serious problems with the terminology? Is it outdated?","I have a question concerning the Bourbaki 's book on integration . Whenever I find them referenced (in answers on this site as well), it looks like they aged more than volumes of the same series on other topics. Also, it looks like they were criticised from the outset (e.g. see Halmos' comment from page 11 of this chapter ). Thus, the questions: why? Is there a problem in the entire approach to the topic? What was problematic in it? How sensible is to read them right now, beyond historical purposes? What should somebody have in mind when reading them? How shoud somebody read them? Given the answer to question (1), what should be taken, and what should be dismissed? Thank you as always for any feedback. PS: Moreover, right now, are there serious problems with the terminology? Is it outdated?",,"['integration', 'measure-theory', 'math-history']"
81,"Seem to be encountering many interesting results from integrals in the form: $\int_0^\infty \frac{f(a,x)}{e^{2\pi x}-1}\text{d}x$",Seem to be encountering many interesting results from integrals in the form:,"\int_0^\infty \frac{f(a,x)}{e^{2\pi x}-1}\text{d}x","I have found interesting results from integrals in the form: $$I=\int_0^\infty \frac{f(a,x)}{e^{2\pi x}-1}\text{d}x$$ A few examples of interesting functions here are: $$f(a,x)=\sin(ax)\implies I=\frac{1}{4}\coth \frac{a}{2}-\frac{1}{2a}$$ and... $$f(a,x)=2\arctan (x/a)\implies I=\log\Gamma(a)-a\log a+a-\frac{1}{2}\log \frac{2\pi}{a}$$ to even... $$f(a,x)=\frac{2\sin(a \arctan x)}{(x^2+1)^{a/2}}\implies I= \zeta(a)-\frac{1}{2}-\frac{1}{a-1}$$ Does there exist a non-trivial function $f$ such that $I=\operatorname{Bi} (a)+\text{some extra stuff}$? Non-trivial means that you can't have a factor of the numerator being $(e^{2\pi x} -1)$","I have found interesting results from integrals in the form: $$I=\int_0^\infty \frac{f(a,x)}{e^{2\pi x}-1}\text{d}x$$ A few examples of interesting functions here are: $$f(a,x)=\sin(ax)\implies I=\frac{1}{4}\coth \frac{a}{2}-\frac{1}{2a}$$ and... $$f(a,x)=2\arctan (x/a)\implies I=\log\Gamma(a)-a\log a+a-\frac{1}{2}\log \frac{2\pi}{a}$$ to even... $$f(a,x)=\frac{2\sin(a \arctan x)}{(x^2+1)^{a/2}}\implies I= \zeta(a)-\frac{1}{2}-\frac{1}{a-1}$$ Does there exist a non-trivial function $f$ such that $I=\operatorname{Bi} (a)+\text{some extra stuff}$? Non-trivial means that you can't have a factor of the numerator being $(e^{2\pi x} -1)$",,['integration']
82,Stokes' Theorem and Vector Fields with Jump Discontinuities,Stokes' Theorem and Vector Fields with Jump Discontinuities,,"What are the continuity requirements on a vector field $\boldsymbol{A}$ such that Stokes' theorem, $$ \iint_S\nabla\times\left[(\boldsymbol{\hat{x}}\cdot\nabla\phi)\boldsymbol{A}\right]\cdot d\boldsymbol{s} = \oint_C \left(\boldsymbol{\hat{x}}\cdot\nabla\phi\right)\boldsymbol{A}\cdot d\boldsymbol{l}, $$ holds? Here $\boldsymbol{\hat{x}}$ is a constant vector, $\phi$ is a smooth function (1) over all of $\mathbb{R}^3$, $S\subset\mathbb{R}^3$ is a bounded, connected and open set with boundary $C$. More specifically, can it suffer a jump discontinuity on $C$? To put this into context (2), there is an article that supposes that the vector field must be continuous on $S$ and across $C$. Since $\boldsymbol{A}$ suffers a jump discontinuity on $C$, Stokes' theorem fails. This is used to argue that some integral representation of electromagnetic fields fail. On the other hand, I have this article saying that even if $\boldsymbol{A}$ is discontinuous across $C$, Stokes' theorem still holds, citing the work of Whitney (3, p.100). (1): It can be singular at isolated points on $S$, but for our purposes it can be considered smooth. (2): I can provide PDFs via email, see my bio. (3): H. Whitney, Geometric Integration Theory, Princeton University Press: Princeton, 1957. Update : This first article seems to say that the divergence theorem (not Stokes' theorem, but I suppose the arguments would be the same as for the divergence theorem) holds if the vector field is discontinuous in a set $Z$, contained in $S+C$, that is of logarithmic capacity zero. The way I understand it, this seems to preclude a jump discontinuity on $C$. This second article , however, includes an additional term due to the discontinuity at $C$. Is that second article right? Would that carry over to Stokes' theorem?","What are the continuity requirements on a vector field $\boldsymbol{A}$ such that Stokes' theorem, $$ \iint_S\nabla\times\left[(\boldsymbol{\hat{x}}\cdot\nabla\phi)\boldsymbol{A}\right]\cdot d\boldsymbol{s} = \oint_C \left(\boldsymbol{\hat{x}}\cdot\nabla\phi\right)\boldsymbol{A}\cdot d\boldsymbol{l}, $$ holds? Here $\boldsymbol{\hat{x}}$ is a constant vector, $\phi$ is a smooth function (1) over all of $\mathbb{R}^3$, $S\subset\mathbb{R}^3$ is a bounded, connected and open set with boundary $C$. More specifically, can it suffer a jump discontinuity on $C$? To put this into context (2), there is an article that supposes that the vector field must be continuous on $S$ and across $C$. Since $\boldsymbol{A}$ suffers a jump discontinuity on $C$, Stokes' theorem fails. This is used to argue that some integral representation of electromagnetic fields fail. On the other hand, I have this article saying that even if $\boldsymbol{A}$ is discontinuous across $C$, Stokes' theorem still holds, citing the work of Whitney (3, p.100). (1): It can be singular at isolated points on $S$, but for our purposes it can be considered smooth. (2): I can provide PDFs via email, see my bio. (3): H. Whitney, Geometric Integration Theory, Princeton University Press: Princeton, 1957. Update : This first article seems to say that the divergence theorem (not Stokes' theorem, but I suppose the arguments would be the same as for the divergence theorem) holds if the vector field is discontinuous in a set $Z$, contained in $S+C$, that is of logarithmic capacity zero. The way I understand it, this seems to preclude a jump discontinuity on $C$. This second article , however, includes an additional term due to the discontinuity at $C$. Is that second article right? Would that carry over to Stokes' theorem?",,"['integration', 'physics', 'vector-analysis', 'stokes-theorem']"
83,Can you add new functions to the set of elementary functions such that every function has an anti-derivative?,Can you add new functions to the set of elementary functions such that every function has an anti-derivative?,,"Its fairly well known that not every elementary function has an elementary anti-derivative.  The common examples of this are $\exp(-x^2)$ and $\sin(x)/x$.  The general workaround to this problem is to create new functions like $\mathrm{Erf}(X)$ and $\mathrm{Si}(x)$ to go alongside the more elementary functions.  I was wondering if there is a way to add ""enough"" non-elementary functions so that every function has an anti-derivative that can be expressed via other functions.  The typical solution to this question is to introduce Riemann integration as an operator on functions, and then declare that the set of functions is closed under this operator.  That definitely works, but I'm looking for something that is more enumerable.  Like a simple countable set of functions that I can build everything else out of.  Has anyone come up with a set of functions like this, or proved that making one is impossible?","Its fairly well known that not every elementary function has an elementary anti-derivative.  The common examples of this are $\exp(-x^2)$ and $\sin(x)/x$.  The general workaround to this problem is to create new functions like $\mathrm{Erf}(X)$ and $\mathrm{Si}(x)$ to go alongside the more elementary functions.  I was wondering if there is a way to add ""enough"" non-elementary functions so that every function has an anti-derivative that can be expressed via other functions.  The typical solution to this question is to introduce Riemann integration as an operator on functions, and then declare that the set of functions is closed under this operator.  That definitely works, but I'm looking for something that is more enumerable.  Like a simple countable set of functions that I can build everything else out of.  Has anyone come up with a set of functions like this, or proved that making one is impossible?",,"['integration', 'functions']"
84,Help with the integral $\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx$,Help with the integral,\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx,"Referring to a previous question , i want help with the integral : $$\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx$$ Where $n,m$ are positive integers, and $t$ is a real variable. I have tried repeated integration by parts, but it becomes very confusing after a couple of steps. Hints: $$\int\frac{\log(1+ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}dx=\frac{4\pi in}{t}\left(e^{-2\pi n/t}\text{Ei}\left(\log(1+ix)+\frac{2\pi n}{t}\right)-e^{2\pi n/t}\text{Ei}\left(\log(1+ix)-\frac{2\pi n}{t}\right) \right )+\frac{4x-4i}{t^{2}}$$ $$\int \text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)dx=(x-i)\text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)+ie^{\mp 2\pi n/t}\text{Ei}\left(2\log(1+ix)\pm\frac{4\pi n}{t}\right)$$ EDIT We notice that: $$\frac{\log(1+ ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}=\frac{4\log(1+ix)}{t^{2}}\int_{0}^{\infty}\sinh\left(\frac{2\pi ny}{t} \right )(1+ix)^{-y}dy$$ So we need to evaluate : $$f(y,m)=\int_{0}^{\infty}\log(1+ix)(1+ix)^{-y}e^{-2\pi m x}dx$$ And : $$\frac{4}{t^{2}}\int_{0}^{\infty}f(y,m)\sinh\left(\frac{2\pi ny}{t} \right )dy$$ But : $$f(y,m)=-\frac{d}{dy}\left[\int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi m x}dx\right]$$ And the problem reduces to this last integral ! EDIT 2 $$(1+ix)^{-y}=\sum_{k=0}^{\infty}i^{k}x^{k}\frac{\Gamma(1-y)}{k!\Gamma(1-k-y)}$$ Thus : $$\int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi mx}dx=\sum_{k=0}^{\infty}i^{k}\frac{\Gamma(1-y)}{\Gamma(1-k-y)}\frac{1}{(2\pi m)^{k+1}}$$ $$=i(-2\pi i m)^{y-1}\Gamma(1-y,-2\pi i m )$$","Referring to a previous question , i want help with the integral : Where are positive integers, and is a real variable. I have tried repeated integration by parts, but it becomes very confusing after a couple of steps. Hints: EDIT We notice that: So we need to evaluate : And : But : And the problem reduces to this last integral ! EDIT 2 Thus :","\int_{0}^{\infty}\frac{\log(1\pm ix)^{2}}{\left(\frac{t}{2}\log(1 \pm ix) \right )^{2}-\pi ^{2}n^{2}}e^{-2\pi mx}dx n,m t \int\frac{\log(1+ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}dx=\frac{4\pi in}{t}\left(e^{-2\pi n/t}\text{Ei}\left(\log(1+ix)+\frac{2\pi n}{t}\right)-e^{2\pi n/t}\text{Ei}\left(\log(1+ix)-\frac{2\pi n}{t}\right) \right )+\frac{4x-4i}{t^{2}} \int \text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)dx=(x-i)\text{Ei}\left(\log(1+ix)\pm\frac{2\pi n}{t}\right)+ie^{\mp 2\pi n/t}\text{Ei}\left(2\log(1+ix)\pm\frac{4\pi n}{t}\right) \frac{\log(1+ ix)^{2}}{\left(\frac{t}{2}\log(1 + ix) \right )^{2}-\pi ^{2}n^{2}}=\frac{4\log(1+ix)}{t^{2}}\int_{0}^{\infty}\sinh\left(\frac{2\pi ny}{t} \right )(1+ix)^{-y}dy f(y,m)=\int_{0}^{\infty}\log(1+ix)(1+ix)^{-y}e^{-2\pi m x}dx \frac{4}{t^{2}}\int_{0}^{\infty}f(y,m)\sinh\left(\frac{2\pi ny}{t} \right )dy f(y,m)=-\frac{d}{dy}\left[\int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi m x}dx\right] (1+ix)^{-y}=\sum_{k=0}^{\infty}i^{k}x^{k}\frac{\Gamma(1-y)}{k!\Gamma(1-k-y)} \int_{0}^{\infty}(1+ix)^{-y}e^{-2\pi mx}dx=\sum_{k=0}^{\infty}i^{k}\frac{\Gamma(1-y)}{\Gamma(1-k-y)}\frac{1}{(2\pi m)^{k+1}} =i(-2\pi i m)^{y-1}\Gamma(1-y,-2\pi i m )","['integration', 'complex-analysis', 'special-functions']"
85,Help to understand changing order of integration,Help to understand changing order of integration,,"I have a problem I have been working on, with the solution but the thing is I don't really understand how it is done. The question, is to compute, $$\int_0^1 \int_{9x^2}^9 x^3\sin(8y^3) \,dy\,dx $$ Now, I did notice that we are going to have to reverse the order of integration so first I took note of, as of now I have $$0 \le x \le 1$$ and $$9x^2 \le y \le 9$$ and I tried to consider the graph. This is where I am getting confused, I don't know if I am supposed to consider the area basically above the line $$0\le x\le\sqrt{\frac{y}{9}}$$  and put $0 \le y \le 9$ and compute. I know that is what I should do, but I am having a lot of trouble seeing this from the graph. My apologizes as I am not aware of how to put graphs on the site. I mean I am having trouble visualizing what it is meant to say $x$ is less than that value of $y$, when are we not considering the region bounded above? I appreciate all answers and comments, ideally though I would like an answer that includes graphics if possible! Could anyone shed some light on this? Ps, this is not homework and I already have the final solution if anyone wants to check, it is $$=\frac{1-\cos(5832)}{7776}$$ Thank you all","I have a problem I have been working on, with the solution but the thing is I don't really understand how it is done. The question, is to compute, $$\int_0^1 \int_{9x^2}^9 x^3\sin(8y^3) \,dy\,dx $$ Now, I did notice that we are going to have to reverse the order of integration so first I took note of, as of now I have $$0 \le x \le 1$$ and $$9x^2 \le y \le 9$$ and I tried to consider the graph. This is where I am getting confused, I don't know if I am supposed to consider the area basically above the line $$0\le x\le\sqrt{\frac{y}{9}}$$  and put $0 \le y \le 9$ and compute. I know that is what I should do, but I am having a lot of trouble seeing this from the graph. My apologizes as I am not aware of how to put graphs on the site. I mean I am having trouble visualizing what it is meant to say $x$ is less than that value of $y$, when are we not considering the region bounded above? I appreciate all answers and comments, ideally though I would like an answer that includes graphics if possible! Could anyone shed some light on this? Ps, this is not homework and I already have the final solution if anyone wants to check, it is $$=\frac{1-\cos(5832)}{7776}$$ Thank you all",,"['integration', 'multivariable-calculus']"
86,Largest rectangle bounded under a function,Largest rectangle bounded under a function,,"Let $f$ be a positive monotonically increasing real function in $[0,1]$. Let $F$ be the area under the curve of $f$ ($F=\int_0^1{f(x)dx}$) For every $x\in[0,1]$, let $G(x)=f(x)\cdot (1-x)$ = the area of a rectangle bounded below the curve of $f$ and the $x$ axis: Let $L=\left\lceil\log_2{\frac{f(1)}{f(0)}}\right\rceil$. Prove that there exists an $x$ such that: $$G(x)\geq F/(2L)$$ Here is a possible proof: Partition the interval $[0,1]$ to bins such that, in each bins $[a,b]$, $f(b)\leq 2f(a)$ (i.e. the value of $f$ grows by at most a factor of 2). The number of such bins is at most $L$. Hence, by the pigeonhole principle, there is a bin $[a,b]$ in which the area under the curve ($= \int_a^b{f(x)dx}$) is at least $F/L$. Now, this area is bounded below the rectangle $(b-a)f(b)$. By definition of a bin, $f(a)\geq f(b)/2$. Hence:\begin{align}G(a) &= (1-a)f(a) \\&\geq (b-a)f(a) \\&\geq (b-a)f(b)/2 \\&\geq F/2L\end{align} MY QUESTIONS ARE: Is there a simpler proof? Is there a better bound for the area of the maximal rectangle?","Let $f$ be a positive monotonically increasing real function in $[0,1]$. Let $F$ be the area under the curve of $f$ ($F=\int_0^1{f(x)dx}$) For every $x\in[0,1]$, let $G(x)=f(x)\cdot (1-x)$ = the area of a rectangle bounded below the curve of $f$ and the $x$ axis: Let $L=\left\lceil\log_2{\frac{f(1)}{f(0)}}\right\rceil$. Prove that there exists an $x$ such that: $$G(x)\geq F/(2L)$$ Here is a possible proof: Partition the interval $[0,1]$ to bins such that, in each bins $[a,b]$, $f(b)\leq 2f(a)$ (i.e. the value of $f$ grows by at most a factor of 2). The number of such bins is at most $L$. Hence, by the pigeonhole principle, there is a bin $[a,b]$ in which the area under the curve ($= \int_a^b{f(x)dx}$) is at least $F/L$. Now, this area is bounded below the rectangle $(b-a)f(b)$. By definition of a bin, $f(a)\geq f(b)/2$. Hence:\begin{align}G(a) &= (1-a)f(a) \\&\geq (b-a)f(a) \\&\geq (b-a)f(b)/2 \\&\geq F/2L\end{align} MY QUESTIONS ARE: Is there a simpler proof? Is there a better bound for the area of the maximal rectangle?",,"['integration', 'geometry', 'alternative-proof', 'area', 'rectangles']"
87,Surface integral for a scalar function defined on a discrete surface,Surface integral for a scalar function defined on a discrete surface,,"Imagine a polyhedral, discrete surface embedded in $\mathbb{R}^3$. Its faces are all triangles. For each vertex, one can compute the discrete mean and Gaussian curvatures and evaluate the sum of square principal curvatures, $k_1^2 + k_2^2$. The goal is to evaluate the bending energy at a vertex $v_0$ by computing this integral over all incident triangles at the $v_0$ vertex: $$ \int_{S}{k_1^2+k_2^2 dS} $$ The problem is that there's no analytical expression for the $k_i$ curvatures, they're just scalars associated to each $v_k$ vertex of the mesh. Is there a way to evaluate this particular surface integral? Or, more clearly, given a random triangle in 3D with scalars attached to its vertices, can a notion of surface integral for a function that just interpolates the scalar values over this triangle be established in a consistent way? (then I can just sum the integrals over all triangles and get a numerical estimate). NOTE The purpose of computing that surface integral is to assess the importance of a vertex as a salient feature in a local context for a polyhedral surface. The entire concept should be implementable using a computer programming language (hence the more abstract mathematical quirks and impediments may be overlooked up to an acceptable limit). For a ""quick"" reference, a good survey of how some continuous differential geometry concepts are adapted in the discrete context, you can consult CalTech's Graphics Group tech report on the issue: http://multires.caltech.edu/pubs/diffGeoOps.pdf Solution proposition Let $f(v) = (k_1^2 + k_2^2)(v)$ be a positive scalar function defined on the polyhedral surface. Evaluating $\int_S{f dS}$ can be done by summing all $\int_{\Delta{ijk}}{f dS}$ over all $(v_i,v_j,v_k)$ triangular faces of the surface. Then the problem is reduced to evaluating: $$ \int_{\Delta{ijk}}{f dS} = \int_s \int_t { f(v(s,t)) \left| \frac{\partial v}{\partial s} \times \frac{\partial v}{\partial t}\right| ds dt },$$ where $v(s,t)$ is a parameterization for the $\Delta_{ijk}$ triangle. For example, $v(s,t) = (1-t)((1-s)v_1 + sv_2) + tv_3$, where $(s,t) \in [0,1]^2$. Now, we require that $f(v(0,0))=f(v_1)=K_1$, $f(v(1,0))=f(v_2)=K_2$ and $f(v(0,1))=f(v_3)=K_3$, i.e. $f(v_i)=K_i$. Hence $f$ can also be a convex combination of $K_1$, $K_2$ and $K_3$, but this time over a triangular domain that is isometric to $\Delta_{v_1v_2v_3}$. There should exist a parameterization $v^*(s,t)$ of the $\Delta_{v_1v_2v_3}$ triangle such that $\left| \frac{\partial v}{\partial s} \times \frac{\partial v}{\partial t}\right| = 1$ ( is this affirmation valid? ). Since the image of $f(\Delta_{v_1v_2v_3})$ is also a triangle (it is a convex combination of $K_i$s), and since there must be a ""canonical"" parameterization $v^*(s,t)$ of $\Delta$, then we can compute the resulting double integral as the volume under the $K_1K_2K_3$ triangle over the triangular domain that is isometric to $\Delta_{v_1v_2v_3}$. This solid object is a generalized triangular prism (its base planes are not necessarily parallel anymore). Is there any obvious flaw in the above solution?","Imagine a polyhedral, discrete surface embedded in $\mathbb{R}^3$. Its faces are all triangles. For each vertex, one can compute the discrete mean and Gaussian curvatures and evaluate the sum of square principal curvatures, $k_1^2 + k_2^2$. The goal is to evaluate the bending energy at a vertex $v_0$ by computing this integral over all incident triangles at the $v_0$ vertex: $$ \int_{S}{k_1^2+k_2^2 dS} $$ The problem is that there's no analytical expression for the $k_i$ curvatures, they're just scalars associated to each $v_k$ vertex of the mesh. Is there a way to evaluate this particular surface integral? Or, more clearly, given a random triangle in 3D with scalars attached to its vertices, can a notion of surface integral for a function that just interpolates the scalar values over this triangle be established in a consistent way? (then I can just sum the integrals over all triangles and get a numerical estimate). NOTE The purpose of computing that surface integral is to assess the importance of a vertex as a salient feature in a local context for a polyhedral surface. The entire concept should be implementable using a computer programming language (hence the more abstract mathematical quirks and impediments may be overlooked up to an acceptable limit). For a ""quick"" reference, a good survey of how some continuous differential geometry concepts are adapted in the discrete context, you can consult CalTech's Graphics Group tech report on the issue: http://multires.caltech.edu/pubs/diffGeoOps.pdf Solution proposition Let $f(v) = (k_1^2 + k_2^2)(v)$ be a positive scalar function defined on the polyhedral surface. Evaluating $\int_S{f dS}$ can be done by summing all $\int_{\Delta{ijk}}{f dS}$ over all $(v_i,v_j,v_k)$ triangular faces of the surface. Then the problem is reduced to evaluating: $$ \int_{\Delta{ijk}}{f dS} = \int_s \int_t { f(v(s,t)) \left| \frac{\partial v}{\partial s} \times \frac{\partial v}{\partial t}\right| ds dt },$$ where $v(s,t)$ is a parameterization for the $\Delta_{ijk}$ triangle. For example, $v(s,t) = (1-t)((1-s)v_1 + sv_2) + tv_3$, where $(s,t) \in [0,1]^2$. Now, we require that $f(v(0,0))=f(v_1)=K_1$, $f(v(1,0))=f(v_2)=K_2$ and $f(v(0,1))=f(v_3)=K_3$, i.e. $f(v_i)=K_i$. Hence $f$ can also be a convex combination of $K_1$, $K_2$ and $K_3$, but this time over a triangular domain that is isometric to $\Delta_{v_1v_2v_3}$. There should exist a parameterization $v^*(s,t)$ of the $\Delta_{v_1v_2v_3}$ triangle such that $\left| \frac{\partial v}{\partial s} \times \frac{\partial v}{\partial t}\right| = 1$ ( is this affirmation valid? ). Since the image of $f(\Delta_{v_1v_2v_3})$ is also a triangle (it is a convex combination of $K_i$s), and since there must be a ""canonical"" parameterization $v^*(s,t)$ of $\Delta$, then we can compute the resulting double integral as the volume under the $K_1K_2K_3$ triangle over the triangular domain that is isometric to $\Delta_{v_1v_2v_3}$. This solid object is a generalized triangular prism (its base planes are not necessarily parallel anymore). Is there any obvious flaw in the above solution?",,"['multivariable-calculus', 'differential-geometry', 'integration', 'curvature', 'discrete-geometry']"
88,Different ways to prove $\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$ (the Basel problem),Different ways to prove  (the Basel problem),\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6},"As I have heard people did not trust Euler when he first discovered the formula (solution of the Basel problem ) $$\zeta(2)=\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}$$ However, Euler was Euler and he gave other proofs. I believe many of you know some nice proofs of this, can you please share it with us?","As I have heard people did not trust Euler when he first discovered the formula (solution of the Basel problem ) However, Euler was Euler and he gave other proofs. I believe many of you know some nice proofs of this, can you please share it with us?",\zeta(2)=\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6},"['sequences-and-series', 'fourier-analysis', 'big-list', 'transcendental-numbers', 'faq']"
89,Show that the function is constant,Show that the function is constant,,"Let $S^n$ be an $n$-dimentional unit sphere. Consider $f: S^n \longrightarrow R_+$ even continuous function. Denote $$ F(f):=\int_0^{\infty}\int_{S^n}f(y)g\left(\frac{|xy|}{t}\right)dy\frac{dt}{t^{n+1}}, $$ where $x \in S^n, \, t>0$ and function $g$ is such that $$ \int_{0}^{\infty}s^jg(s)ds=0, \quad j=0,2,4,\ldots, 2\left[(n-1)/2\right] $$ $$ \int_1^{\infty}s^{\alpha}|g(s)|ds< \infty, \quad \alpha>n-1. $$ Show that if Fourier transform $\hat{F}=f$, then $f$ is constant. Thank you.","Let $S^n$ be an $n$-dimentional unit sphere. Consider $f: S^n \longrightarrow R_+$ even continuous function. Denote $$ F(f):=\int_0^{\infty}\int_{S^n}f(y)g\left(\frac{|xy|}{t}\right)dy\frac{dt}{t^{n+1}}, $$ where $x \in S^n, \, t>0$ and function $g$ is such that $$ \int_{0}^{\infty}s^jg(s)ds=0, \quad j=0,2,4,\ldots, 2\left[(n-1)/2\right] $$ $$ \int_1^{\infty}s^{\alpha}|g(s)|ds< \infty, \quad \alpha>n-1. $$ Show that if Fourier transform $\hat{F}=f$, then $f$ is constant. Thank you.",,"['functional-analysis', 'integration', 'fourier-analysis', 'approximation', 'fourier-series']"
90,Is this method of indefinite integration correct? $\int{ dx\over12+5\tan(x)}$,Is this method of indefinite integration correct?,\int{ dx\over12+5\tan(x)},"I am integrating: $$ \int{ dx\over12+5\tan(x)} $$ I proposed $x = \arctan(u)$, replacing $dx$ by $du \over 1+u^2$, so  the integral becomes: $$ \int{du \over (1+u^2)(12+5u)} $$ Which can be integrated using partial fractions and then I eventually get that the anti-derivative is: $$ {5 \over 169} \ln |12+5u| - {5 \over 338}\ln|1+u^2| + {12 \over 169}\arctan (u) + C $$ And finally going back to the original variable substituting $u = \tan(x)$ So my question is if this method is correct?","I am integrating: $$ \int{ dx\over12+5\tan(x)} $$ I proposed $x = \arctan(u)$, replacing $dx$ by $du \over 1+u^2$, so  the integral becomes: $$ \int{du \over (1+u^2)(12+5u)} $$ Which can be integrated using partial fractions and then I eventually get that the anti-derivative is: $$ {5 \over 169} \ln |12+5u| - {5 \over 338}\ln|1+u^2| + {12 \over 169}\arctan (u) + C $$ And finally going back to the original variable substituting $u = \tan(x)$ So my question is if this method is correct?",,"['integration', 'trigonometric-integrals']"
91,How to integrate $\frac{x^{2}\log {\sin x}}{1+x^{6}}$,How to integrate,\frac{x^{2}\log {\sin x}}{1+x^{6}},"I recently stumbled upon a question $$\int_0^{\infty}\frac{x^{m-1}\log^{a}x}{1+x^n}dx$$ I was able to evaluate it,but I am curious if there exists a closed form for, $$\int_0^{\pi/2}\frac{x^{2}\log{\sin x}}{1+x^6}dx$$ It numerically evaluates to -0.1392432458. My attempt- $$\int \frac {x^2}{1+x^6}dx=\frac13 \int \frac {d(x^3)}{1+x^6}=\frac13 \arctan {x^3}$$ Then,by applying integration by parts, $$\int_0^{\pi/2}\frac{x^2\log\sin x}{1+x^6}dx=-\int_0^{\pi/2}\frac13\arctan {x^3} \cot x dx$$.But now I'm stuck.","I recently stumbled upon a question $$\int_0^{\infty}\frac{x^{m-1}\log^{a}x}{1+x^n}dx$$ I was able to evaluate it,but I am curious if there exists a closed form for, $$\int_0^{\pi/2}\frac{x^{2}\log{\sin x}}{1+x^6}dx$$ It numerically evaluates to -0.1392432458. My attempt- $$\int \frac {x^2}{1+x^6}dx=\frac13 \int \frac {d(x^3)}{1+x^6}=\frac13 \arctan {x^3}$$ Then,by applying integration by parts, $$\int_0^{\pi/2}\frac{x^2\log\sin x}{1+x^6}dx=-\int_0^{\pi/2}\frac13\arctan {x^3} \cot x dx$$.But now I'm stuck.",,"['integration', 'definite-integrals', 'closed-form']"
92,What is the integral of $x(1-x)^8$?,What is the integral of ?,x(1-x)^8,"I want to find the integral of $x (1-x)^8$. How do I go about this? For example, which rule do I use from http://integral-table.com ? Thanks!","I want to find the integral of $x (1-x)^8$. How do I go about this? For example, which rule do I use from http://integral-table.com ? Thanks!",,['integration']
93,What is the integral of $e^{-x^2/2}$ over $\mathbb{R}$ [closed],What is the integral of  over  [closed],e^{-x^2/2} \mathbb{R},"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question What is the integral of $$\int_{-\infty}^{\infty}e^{-x^2/2}dx\,?$$ My working is here: = $-e^(-1/2x^2)/x$ from negative infinity to infinity. What is the value of this? Not sure how to carry on from here.  Thank you.",Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question What is the integral of My working is here: = from negative infinity to infinity. What is the value of this? Not sure how to carry on from here.  Thank you.,"\int_{-\infty}^{\infty}e^{-x^2/2}dx\,? -e^(-1/2x^2)/x",['integration']
94,How do I evaluate this : $\int_{0}^{\infty} \ln \left( 1 + \frac{a^{2}}{x^{2}}\right)\ dx $ for $a > 0$?,How do I evaluate this :  for ?,\int_{0}^{\infty} \ln \left( 1 + \frac{a^{2}}{x^{2}}\right)\ dx  a > 0,How do I evaluate this integral if I suppose that $a > 0$ $$\int_{0}^{\infty} \ln \left( 1 + \frac{a^{2}}{x^{2}}\right)\ \mathrm{d}x .$$ For $a=2$ I got $2\pi$ I think the result will be $a\pi$.,How do I evaluate this integral if I suppose that $a > 0$ $$\int_{0}^{\infty} \ln \left( 1 + \frac{a^{2}}{x^{2}}\right)\ \mathrm{d}x .$$ For $a=2$ I got $2\pi$ I think the result will be $a\pi$.,,"['integration', 'definite-integrals', 'improper-integrals']"
95,Integration substitution: How does Wolfram Alpha come up with this step?,Integration substitution: How does Wolfram Alpha come up with this step?,,"I have to integrate  $$ \int \frac{1}{(\sin  x) (\cos  x)} \, dx $$ I looked at the Wolfram Alpha step by step solution to figure out how to do it. First, it rewrites the integral as: $$ \int (\csc x) (\sec x) \, dx $$ This step I understand, but then it substitutes: For the integrand $\csc x\cdot\sec x$, substitute $u=\tan(x)$ and $\mathrm{d}u=\sec^2(x)\mathrm{d}x$: $$ \int \frac{1}{u} \, du $$ My question is, how does it know to substitute $\tan x$ for $u$, and $\sec^2x$ for $\mathrm{d}x$? And how does that simplifies to $1/u~\mathrm{d}u$?","I have to integrate  $$ \int \frac{1}{(\sin  x) (\cos  x)} \, dx $$ I looked at the Wolfram Alpha step by step solution to figure out how to do it. First, it rewrites the integral as: $$ \int (\csc x) (\sec x) \, dx $$ This step I understand, but then it substitutes: For the integrand $\csc x\cdot\sec x$, substitute $u=\tan(x)$ and $\mathrm{d}u=\sec^2(x)\mathrm{d}x$: $$ \int \frac{1}{u} \, du $$ My question is, how does it know to substitute $\tan x$ for $u$, and $\sec^2x$ for $\mathrm{d}x$? And how does that simplifies to $1/u~\mathrm{d}u$?",,"['integration', 'analysis', 'trigonometry', 'wolfram-alpha']"
96,"How to evaluate $\int_0^\pi \cos(x) \cos(2x) \cos(3x) \cos(4x)\, dx$",How to evaluate,"\int_0^\pi \cos(x) \cos(2x) \cos(3x) \cos(4x)\, dx","Is there an easy way to evaluate the integral $\int_0^\pi \cos(x) \cos(2x) \cos(3x) \cos(4x)\, dx$? I know that I can plugin the $e$-function and use the linearity of the integral. However this would lead to 16 summands which I really dont want to calculate separately.","Is there an easy way to evaluate the integral $\int_0^\pi \cos(x) \cos(2x) \cos(3x) \cos(4x)\, dx$? I know that I can plugin the $e$-function and use the linearity of the integral. However this would lead to 16 summands which I really dont want to calculate separately.",,['integration']
97,A Sum that came up while solving a integral,A Sum that came up while solving a integral,,"While evaluating $I$, I did the following- $$\begin{align}I= \int_{0}^{1} \log \left(\dfrac{1+x}{1-x}\right) \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x &= 2 \int_{0}^{1}\sum_{n=0}^{\infty} \dfrac{x^{2n+1}}{2n+1} \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x\\ &=2\sum_{n=0}^{\infty} \int_{0}^{1} \dfrac{x^{2n}}{(2n+1)\sqrt{1-x^2}}  \ \mathrm{d}x \end{align}$$ Then I used the substitution $x \mapsto \sin \theta $. $$\begin{align} \therefore I &=2\sum_{n=0}^{\infty} \int_{0}^{\pi/2} \dfrac{\sin^{2n} {\theta}}{2n+1} \ \mathrm{d}\theta\\ &=\pi \sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)} \end{align}$$ The last step is due to Wallis' formula. However, I couldn't solve the last series. My question is that how do we prove that $$\displaystyle\sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)}=\dfrac{\pi}{2} \ ?$$","While evaluating $I$, I did the following- $$\begin{align}I= \int_{0}^{1} \log \left(\dfrac{1+x}{1-x}\right) \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x &= 2 \int_{0}^{1}\sum_{n=0}^{\infty} \dfrac{x^{2n+1}}{2n+1} \dfrac{1}{x\sqrt{1-x^2}} \ \mathrm{d}x\\ &=2\sum_{n=0}^{\infty} \int_{0}^{1} \dfrac{x^{2n}}{(2n+1)\sqrt{1-x^2}}  \ \mathrm{d}x \end{align}$$ Then I used the substitution $x \mapsto \sin \theta $. $$\begin{align} \therefore I &=2\sum_{n=0}^{\infty} \int_{0}^{\pi/2} \dfrac{\sin^{2n} {\theta}}{2n+1} \ \mathrm{d}\theta\\ &=\pi \sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)} \end{align}$$ The last step is due to Wallis' formula. However, I couldn't solve the last series. My question is that how do we prove that $$\displaystyle\sum_{n=0}^{\infty} \dfrac{(2n)!}{2^{2n}(n!)^2(2n+1)}=\dfrac{\pi}{2} \ ?$$",,"['integration', 'summation']"
98,Integrate Gumbel times Normal,Integrate Gumbel times Normal,,"I try to solve an integral of the following form: $$ \int_{-\infty}^\infty e^{-x^2} \, e^{-e^{-x^2}} dx $$ Intuitively, the first term, $e^{-x^2}$ , is related to the pdf of a standard-normal distribution, while the second term, $e^{-e^{-x^2}}$ , is related to the pdf of a Gumbel-distribution (except for the square). From plotting the function, it seems that the integral should be well defined, but I cannot find a solution yet. Any hint on how to solve this is highly appreciated.","I try to solve an integral of the following form: Intuitively, the first term, , is related to the pdf of a standard-normal distribution, while the second term, , is related to the pdf of a Gumbel-distribution (except for the square). From plotting the function, it seems that the integral should be well defined, but I cannot find a solution yet. Any hint on how to solve this is highly appreciated."," \int_{-\infty}^\infty e^{-x^2} \, e^{-e^{-x^2}} dx  e^{-x^2} e^{-e^{-x^2}}","['density-function', 'integration']"
99,Evaluate the following integral :$\int\limits_0^{\infty}\frac{\log (1+x^{4})}{\sqrt{x}(1+x)}dx$,Evaluate the following integral :,\int\limits_0^{\infty}\frac{\log (1+x^{4})}{\sqrt{x}(1+x)}dx,"Evaluate the following integral : $$I=\int\limits_0^{\infty}\frac{\log (1+x^{4})}{\sqrt{x}(1+x)}dx$$ I was tried use change variable , If I use $x=y^2$ integral becomes : $$I=2\int\limits_0^{\infty}\frac{\log (1+x^{8})}{1+x^{2}}dx$$ From here I have one idea  the derivative under sing integral but I got I difficult integration : $$I=2\int\limits_0^{\infty}\frac{x^{8}}{(1+ax^{8})(1+x)}dx$$ I already to see you hints or solution!","Evaluate the following integral : I was tried use change variable , If I use integral becomes : From here I have one idea  the derivative under sing integral but I got I difficult integration : I already to see you hints or solution!",I=\int\limits_0^{\infty}\frac{\log (1+x^{4})}{\sqrt{x}(1+x)}dx x=y^2 I=2\int\limits_0^{\infty}\frac{\log (1+x^{8})}{1+x^{2}}dx I=2\int\limits_0^{\infty}\frac{x^{8}}{(1+ax^{8})(1+x)}dx,"['integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
