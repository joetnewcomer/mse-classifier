,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Curvature of Lie group endowed with bi-invariant Riemmanian metric.,Curvature of Lie group endowed with bi-invariant Riemmanian metric.,,"Let $G$ be a Lie group endowed by a biinvariant Riemmanian metric $\langle\cdot,\cdot\rangle$ and $\mathfrak{g}$ its Lie algebra. It is known that the metric is fully determined by its behaviour at the identity element, i.e. the scalar product $\langle\cdot,\cdot\rangle_e$ on $T_eG\cong\mathfrak{g}$ . Now, the following properties hold for the curvature $R$ , Ricci tensor $Ric$ the Killing form $B$ , at the identity element, i. $\forall x,y,z\in\mathfrak{g}$ : $R(x,y)z=\frac{1}{4}[[x,y],z]$ $R(x,y,x,y)=\frac{1}{4}||[x,y]||^2$ , $\operatorname{Ric}(x,y)=-\frac{1}{4}B(x,y)$ Now, I agree that the same relations will hold when evaluating the corresponding tensors on the unique left invariant vector fields $X,Y,Z$ determined, respectively by $x,y,z$ . But the sources presenting these results then use them to say that, for instance the sectional curvature is nonnegative or, if $G$ is compact and semisimple $(G,-B)$ is Einstein. I mean this would certainly be true if we could extend this relations to hold for any vector field, and not only for left invariants one. And I don't see why this should be true. What am I missing?","Let be a Lie group endowed by a biinvariant Riemmanian metric and its Lie algebra. It is known that the metric is fully determined by its behaviour at the identity element, i.e. the scalar product on . Now, the following properties hold for the curvature , Ricci tensor the Killing form , at the identity element, i. : , Now, I agree that the same relations will hold when evaluating the corresponding tensors on the unique left invariant vector fields determined, respectively by . But the sources presenting these results then use them to say that, for instance the sectional curvature is nonnegative or, if is compact and semisimple is Einstein. I mean this would certainly be true if we could extend this relations to hold for any vector field, and not only for left invariants one. And I don't see why this should be true. What am I missing?","G \langle\cdot,\cdot\rangle \mathfrak{g} \langle\cdot,\cdot\rangle_e T_eG\cong\mathfrak{g} R Ric B \forall x,y,z\in\mathfrak{g} R(x,y)z=\frac{1}{4}[[x,y],z] R(x,y,x,y)=\frac{1}{4}||[x,y]||^2 \operatorname{Ric}(x,y)=-\frac{1}{4}B(x,y) X,Y,Z x,y,z G (G,-B)","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'lie-algebras', 'curvature']"
1,Differential of a canonical map,Differential of a canonical map,,"While studying about curvatures I came up with the following but was unable to work it out fully. Let $M \subset \mathbb{R^n}$ be an embedded submanifold of dimension $k$ . Then there is a natural (smooth?) map $$\alpha: M \rightarrow \text{Gr}(k,\mathbb{R}^n),$$ given by $p \mapsto T_p M$ . I know the grassmanian admits a natural description of its tangent spaces, namely: $$T_V\text{Gr}(k,\mathbb{R}^n) \cong \text{Hom}(V , V^+)$$ where by $V^+$ I mean the orthogonal complement. Is there a nice description of its differential at an arbitrary point $p$ ? I couldn’t work it out. Also, a closesly related question: suppose we look instead of at $p \mapsto T_pM$ at $p \mapsto (T_p M)^+$ , in the codimension 1 case, I think the differential + a choice of normal vector field gives you a bilinear form on $T_pM$ automatically. Intuitively I would expect this is something like the second fundamental form of the manifold , but again, when trying to work it out it becomes a mess. Any ideas? Thanks! P.S. If someone knows a universal property the grassmanians satisfy, I’m also very interested!","While studying about curvatures I came up with the following but was unable to work it out fully. Let be an embedded submanifold of dimension . Then there is a natural (smooth?) map given by . I know the grassmanian admits a natural description of its tangent spaces, namely: where by I mean the orthogonal complement. Is there a nice description of its differential at an arbitrary point ? I couldn’t work it out. Also, a closesly related question: suppose we look instead of at at , in the codimension 1 case, I think the differential + a choice of normal vector field gives you a bilinear form on automatically. Intuitively I would expect this is something like the second fundamental form of the manifold , but again, when trying to work it out it becomes a mess. Any ideas? Thanks! P.S. If someone knows a universal property the grassmanians satisfy, I’m also very interested!","M \subset \mathbb{R^n} k \alpha: M \rightarrow \text{Gr}(k,\mathbb{R}^n), p \mapsto T_p M T_V\text{Gr}(k,\mathbb{R}^n) \cong \text{Hom}(V , V^+) V^+ p p \mapsto T_pM p \mapsto (T_p M)^+ T_pM","['differential-geometry', 'riemannian-geometry', 'curvature', 'grassmannian', 'tangent-bundle']"
2,Proving a closed form is exact using Stokes Theorem,Proving a closed form is exact using Stokes Theorem,,"Let $\eta = \sum_{i=1}^n a_i(\mathbf x)dx_i$ be a closed, $C^2$ $1$ -form defined in a convex open set $E$ of $\mathbb{R}^n$ . Prove that it is exact by following the outline: For $\mathbf p \in E$ , define $$f(\mathbf x) := \int_{[\mathbf p,\mathbf x]}\eta \qquad (\mathbf x \in E)$$ and apply Stokes' theorem to the oriented affine $2$ -simplex $[\mathbf p, \mathbf x, \mathbf y]^1$ . Deduce that $$f(\mathbf y) - f(\mathbf x) = \sum_{i=1}^n({y_i-x_i})\int_{0}^{1}{a_i((1-t)\mathbf x + t\mathbf y)dt}$$ for $\mathbf x, \mathbf y \in E$ . Hence $(D_if)(\mathbf x) = a_i(\mathbf x)$ . Assume that $\eta$ is a $1$ -form such that $$\int_\gamma \eta = 0$$ for every $C^1$ closed curve $\gamma$ . Prove that $\eta$ is exact by imitating steps in the last point. Assume $\eta$ is a closed 1-form in $\mathbb{R}^3\setminus \{(0,0,0)\}$ . Prove that it is exact. The last question looks like I should use Poincare's lemma, except that it is punctured at the origin. I want to try the first question, but I cannot understand the notation being used here, even after carefully reading Baby Rudin's chapter 10 (Background: I have taken Analysis with Rudin's book, chapters 1~10). Any help would be much appreciated. $^1$ An oriented affine $k$ -simplex is defined in Baby Rudin ch. 10, page 266, as follows: $\sigma = [\mathbf p_0, \mathbf p_1, \dots, \mathbf p_k]$ is the affine mapping $\sigma : \mathbb R^k \to \mathbb R^k$ such that $\sigma( \mathbf 0) = \mathbf p_0$ and $\sigma( \mathbf e_i) = \mathbf p_i$ for $i=1,\dots,k$ .","Let be a closed, -form defined in a convex open set of . Prove that it is exact by following the outline: For , define and apply Stokes' theorem to the oriented affine -simplex . Deduce that for . Hence . Assume that is a -form such that for every closed curve . Prove that is exact by imitating steps in the last point. Assume is a closed 1-form in . Prove that it is exact. The last question looks like I should use Poincare's lemma, except that it is punctured at the origin. I want to try the first question, but I cannot understand the notation being used here, even after carefully reading Baby Rudin's chapter 10 (Background: I have taken Analysis with Rudin's book, chapters 1~10). Any help would be much appreciated. An oriented affine -simplex is defined in Baby Rudin ch. 10, page 266, as follows: is the affine mapping such that and for .","\eta = \sum_{i=1}^n a_i(\mathbf x)dx_i C^2 1 E \mathbb{R}^n \mathbf p \in E f(\mathbf x) := \int_{[\mathbf p,\mathbf x]}\eta \qquad (\mathbf x \in E) 2 [\mathbf p, \mathbf x, \mathbf y]^1 f(\mathbf y) - f(\mathbf x) = \sum_{i=1}^n({y_i-x_i})\int_{0}^{1}{a_i((1-t)\mathbf x + t\mathbf y)dt} \mathbf x, \mathbf y \in E (D_if)(\mathbf x) = a_i(\mathbf x) \eta 1 \int_\gamma \eta = 0 C^1 \gamma \eta \eta \mathbb{R}^3\setminus \{(0,0,0)\} ^1 k \sigma = [\mathbf p_0, \mathbf p_1, \dots, \mathbf p_k] \sigma : \mathbb R^k \to \mathbb R^k \sigma( \mathbf 0) = \mathbf p_0 \sigma( \mathbf e_i) = \mathbf p_i i=1,\dots,k","['differential-geometry', 'stokes-theorem']"
3,Is Geometric Algebra/Geometric Calculus all that it's hyped up to be? [closed],Is Geometric Algebra/Geometric Calculus all that it's hyped up to be? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question There appears to be a cult following of geometric algebra/geometric calculus (GA/GC) as developed by David Hestenes. Many questions on stack exchange regarding this. I wanted to make this question different than others, this question hopes to bring together many mathematicians whom can contribute to the discussion of the validity of the claims and soundness of GA/GC. I want to ask the mathematicians here on stack exchange what they know and what they think about GA/GC. The claims are always as follows, GA/GC provides a unified formalism for physics and mathematics. It provides a framework which unifies many of the concepts in fields of mathematics such as differential geometry, algebra and many more.... Why are theoretical physicists/mathematicians not rushing into this field? If it was so universal and apparently simpler to learn (also as claimed), then why is it not as widespread? Now most textbooks and articles on this subject give the answer that Clifford developed this formalism concurrently with Gibbs standard formalism for vector calculus. Gibbs was a famous physicists/mathematician and worked at Princeton and so it is the reason his approach was so widespread and Cliffords approach was swept under the rug. Not until David Hestenes revived it, and now there are many descendants/followers of his whom repeat what I just said in the introduction or preface to their book or article. A prolific follower and firm believer of GA/GC is Alan MacDonald a professor of mathematics at Luther College in Decorah, IA. He wrote the following article (there are MANY more by other authors). https://www.astro.umd.edu/~jph/GAandGC.pdf Just read the introduction paragraph and this is generally the type of introduction which comes from most articles and books on GA/GC. It is basically a rephrasing of what Hestenes said in his pioneering work and books on GA/GC, such as his book Space-Time Algebra. I need honest opinions from reputable mathematicians all over. It is important for us to get feedback from mathematicians outside the field of GA/GC because it seems the only people HIGHLY RECOMMENDING using GA/GC are only those who are using it exclusively. It would be good to get many opinions from mathematicians in fields related to GA/GC, such as Differential Geometry, Mathematical Physicists who make extensive use of Differential Geometry, Modern Algebraic Geometers, algebraists.... I know it is difficult for someone to comment on other mathematicians work, but when something makes such big claims as Unifying much of mathematics and physics, it is important for the community to discuss this, so that opinions and ideas are shared and cult following is either justified or unjustly spreading. I am not against GA/GC, I am curious and want to know what other professional mathematicians think of this field and their claims. Please spread this article around so that others can make their comments and we can either begin to embrace GA/GC or refute its claims. Thank you.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 years ago . Improve this question There appears to be a cult following of geometric algebra/geometric calculus (GA/GC) as developed by David Hestenes. Many questions on stack exchange regarding this. I wanted to make this question different than others, this question hopes to bring together many mathematicians whom can contribute to the discussion of the validity of the claims and soundness of GA/GC. I want to ask the mathematicians here on stack exchange what they know and what they think about GA/GC. The claims are always as follows, GA/GC provides a unified formalism for physics and mathematics. It provides a framework which unifies many of the concepts in fields of mathematics such as differential geometry, algebra and many more.... Why are theoretical physicists/mathematicians not rushing into this field? If it was so universal and apparently simpler to learn (also as claimed), then why is it not as widespread? Now most textbooks and articles on this subject give the answer that Clifford developed this formalism concurrently with Gibbs standard formalism for vector calculus. Gibbs was a famous physicists/mathematician and worked at Princeton and so it is the reason his approach was so widespread and Cliffords approach was swept under the rug. Not until David Hestenes revived it, and now there are many descendants/followers of his whom repeat what I just said in the introduction or preface to their book or article. A prolific follower and firm believer of GA/GC is Alan MacDonald a professor of mathematics at Luther College in Decorah, IA. He wrote the following article (there are MANY more by other authors). https://www.astro.umd.edu/~jph/GAandGC.pdf Just read the introduction paragraph and this is generally the type of introduction which comes from most articles and books on GA/GC. It is basically a rephrasing of what Hestenes said in his pioneering work and books on GA/GC, such as his book Space-Time Algebra. I need honest opinions from reputable mathematicians all over. It is important for us to get feedback from mathematicians outside the field of GA/GC because it seems the only people HIGHLY RECOMMENDING using GA/GC are only those who are using it exclusively. It would be good to get many opinions from mathematicians in fields related to GA/GC, such as Differential Geometry, Mathematical Physicists who make extensive use of Differential Geometry, Modern Algebraic Geometers, algebraists.... I know it is difficult for someone to comment on other mathematicians work, but when something makes such big claims as Unifying much of mathematics and physics, it is important for the community to discuss this, so that opinions and ideas are shared and cult following is either justified or unjustly spreading. I am not against GA/GC, I am curious and want to know what other professional mathematicians think of this field and their claims. Please spread this article around so that others can make their comments and we can either begin to embrace GA/GC or refute its claims. Thank you.",,"['abstract-algebra', 'differential-geometry', 'mathematical-physics', 'multilinear-algebra', 'geometric-algebras']"
4,Dynkin index of quotient map for a simple Lie group,Dynkin index of quotient map for a simple Lie group,,"Let $G_1, G_2$ be simple compact Lie groups. Then $h_i := H_3(G_i, \mathbb Z)/ \mathrm{torsion} \cong \mathbb Z$ . If $\phi : G_1 \to G_2$ is a homomorphism, then the pushforward $\phi_* : h_1 \to h_2$ carries a generator of $h_1$ to a generator of $h_2$ multiplied by some natural number $\mathrm{ind}(\phi)$ , called the Dynkin index of $\phi$ . I would like to ask if the value of the Dynkin index is known in the case that $\phi : G_1 \to G_2$ is a universal cover of $G_2$ . It is easy to see that for $G_2 = \mathrm{SO}(3)$ we have $\mathrm{ind}(\phi)=2$ . I would like to know what happens for other groups.","Let be simple compact Lie groups. Then . If is a homomorphism, then the pushforward carries a generator of to a generator of multiplied by some natural number , called the Dynkin index of . I would like to ask if the value of the Dynkin index is known in the case that is a universal cover of . It is easy to see that for we have . I would like to know what happens for other groups.","G_1, G_2 h_i := H_3(G_i, \mathbb Z)/ \mathrm{torsion} \cong \mathbb Z \phi : G_1 \to G_2 \phi_* : h_1 \to h_2 h_1 h_2 \mathrm{ind}(\phi) \phi \phi : G_1 \to G_2 G_2 G_2 = \mathrm{SO}(3) \mathrm{ind}(\phi)=2","['differential-geometry', 'algebraic-topology', 'lie-groups', 'homology-cohomology']"
5,Riemann-Hilbert correspondence versus Simpson correspondence,Riemann-Hilbert correspondence versus Simpson correspondence,,"Let us assume that $X$ is a connected, smooth complex algebraic variety. Then the Riemann-Hilbert correspondence tells us that the functor which sends a flat connection with regular singularities on a vector bundle of $X$ to its asocciated monodromy representation is an equivalence of categories. Furthermore, the Simpson correspondence tells us that there is an equivalence of categories between the category of complex representations of the fundamental group of curves and the category of semi-stable Higgs bundles with trivial Chern class. Its seems to me that the Simpson correspondence should be a consequence of the Riemann-Hilbert correspondence, especially since the category of Higgs bundles is roughly the tangent category of the category of vector bundles. However, based on the number of papers written on this, and the fact that Simpson wrote a ICM note on this, this is clearly not the case. So I guess I must miss what the additional content of the Simpson correspondence is. Could someone help me?","Let us assume that is a connected, smooth complex algebraic variety. Then the Riemann-Hilbert correspondence tells us that the functor which sends a flat connection with regular singularities on a vector bundle of to its asocciated monodromy representation is an equivalence of categories. Furthermore, the Simpson correspondence tells us that there is an equivalence of categories between the category of complex representations of the fundamental group of curves and the category of semi-stable Higgs bundles with trivial Chern class. Its seems to me that the Simpson correspondence should be a consequence of the Riemann-Hilbert correspondence, especially since the category of Higgs bundles is roughly the tangent category of the category of vector bundles. However, based on the number of papers written on this, and the fact that Simpson wrote a ICM note on this, this is clearly not the case. So I guess I must miss what the additional content of the Simpson correspondence is. Could someone help me?",X X,"['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'fundamental-groups']"
6,Lower Dimensional Scalar Densities on a Manifold,Lower Dimensional Scalar Densities on a Manifold,,"On a smooth $n$ dimensional manifold $M$ , it is possible to define a smooth scalar density as a pointwise-defined function $s$ which takes $n$ vector fields $X_1, \dots, X_n \in \Gamma(TM)$ , and return a $C^\infty(M)$ function $s(X_1, \dots, X_n)$ , such that for any section $A$ of $\text{End}(TM)$ (i.e. a map which associates with each point $p$ a endomorphism $A_p$ of $T_pM$ in a smooth manner), $$ s(AX_1, \dots, AX_n) = |\det(A)| \cdot s(X_1, \dots, X_n). $$ Intuitively $s$ can be viewed as assigning a volume to each $n$ dimensional paralleliped in space. Naturally, they are the core objects which can be integrated on a manifold (differential forms allow integration on an oriented manifold). One can form a one dimensional vector bundle $\xi$ whose sections are precisely the scalar densities. My question is whether there exists a similar construction which enables one to integrate on lower dimensional submanifolds. In particular, given a pointwise defined function $s$ which takes $k$ vector fields $X_1, \dots, X_k \in \Gamma(TM)$ , and spits out a $C^\infty(M)$ function, what properties should $s$ have in order for us to consider it as a natural way of measuring the area of $k$ dimensional paralleliped's on the tangent space to $M$ . One such property that should be true is that for any constants $$ \{ a_{ij} : i,j \in \{ 1, \dots, k \} \} $$ and any vector fields $X_1, \dots X_k \in \Gamma(TM)$ , we should have $$ s \left( \sum_i a_{1i} X_i, \dots, \sum_i a_{ki} X_i \right) = |\det(a_{ij})| \cdot s(X_1, \dots, X_k). $$ Certainly, if $N$ is a $k$ dimensional submanifold, then a function $s$ with this property restricts to a scalar density for vector fields $\Gamma(TN)$ , and can therefore be integrated on $N$ . But this doesn't seem like the only property that is necessary, since the family of functions at each point with this property is infinite dimensional (consider the case $k = 1$ where $s$ is simply a seminorm chosen smoothly on each tangent space, and there are infinitely many seminorms). Thus it seems unlikely we can make a vector bundle whose sections are precisely the ' $k$ dimensional' scalar densities. What further properties are needed?","On a smooth dimensional manifold , it is possible to define a smooth scalar density as a pointwise-defined function which takes vector fields , and return a function , such that for any section of (i.e. a map which associates with each point a endomorphism of in a smooth manner), Intuitively can be viewed as assigning a volume to each dimensional paralleliped in space. Naturally, they are the core objects which can be integrated on a manifold (differential forms allow integration on an oriented manifold). One can form a one dimensional vector bundle whose sections are precisely the scalar densities. My question is whether there exists a similar construction which enables one to integrate on lower dimensional submanifolds. In particular, given a pointwise defined function which takes vector fields , and spits out a function, what properties should have in order for us to consider it as a natural way of measuring the area of dimensional paralleliped's on the tangent space to . One such property that should be true is that for any constants and any vector fields , we should have Certainly, if is a dimensional submanifold, then a function with this property restricts to a scalar density for vector fields , and can therefore be integrated on . But this doesn't seem like the only property that is necessary, since the family of functions at each point with this property is infinite dimensional (consider the case where is simply a seminorm chosen smoothly on each tangent space, and there are infinitely many seminorms). Thus it seems unlikely we can make a vector bundle whose sections are precisely the ' dimensional' scalar densities. What further properties are needed?","n M s n X_1, \dots, X_n \in \Gamma(TM) C^\infty(M) s(X_1, \dots, X_n) A \text{End}(TM) p A_p T_pM  s(AX_1, \dots, AX_n) = |\det(A)| \cdot s(X_1, \dots, X_n).  s n \xi s k X_1, \dots, X_k \in \Gamma(TM) C^\infty(M) s k M  \{ a_{ij} : i,j \in \{ 1, \dots, k \} \}  X_1, \dots X_k \in \Gamma(TM)  s \left( \sum_i a_{1i} X_i, \dots, \sum_i a_{ki} X_i \right) = |\det(a_{ij})| \cdot s(X_1, \dots, X_k).  N k s \Gamma(TN) N k = 1 s k","['differential-geometry', 'general-relativity']"
7,Projected Euclidean vs. Geodesic distances of embedded manifolds,Projected Euclidean vs. Geodesic distances of embedded manifolds,,"Let $(M,g)$ be a Riemannian manifold embedded into $R^n$ with $g$ induced by the Euclidean distance of $R^n$ (i.e., this is an isometric embedding). Suppose $x, y \in M$ , and consider the Euclidean line segment $c(t) = (1-t)x + t y$ where $t$ is a scalar: $t \in [0..1]$ . Now, define a curve $p(t) \in M$ by projecting $c(t)$ onto $M$ . Thus: $p(t) = Proj_{M} (c(t)) = \arg\min_{p \in M} \|p - c(t)\|_2$ . I'm wondering if there is a relation between the geodesic on $M$ between $x$ and $y$ and the length of the curve $p(t)$ (which must lie on $M$ by definition). Any simplifying assumptions such as $M$ being compact, without boundary and with a positive reach are OK in my context. For example, if $M$ is a sphere, then it seems that $p(t)$ will trace the geodesic between $x$ and $y$ , unless they are on the poles. Is there a characterization of this situation? Is this true locally (e.g., for $y$ in the neighborhood of $x$ )? To me, it seems that $p(t)$ must provide a better estimate of the geodesic, but I cannot find relevant results. Thank you.","Let be a Riemannian manifold embedded into with induced by the Euclidean distance of (i.e., this is an isometric embedding). Suppose , and consider the Euclidean line segment where is a scalar: . Now, define a curve by projecting onto . Thus: . I'm wondering if there is a relation between the geodesic on between and and the length of the curve (which must lie on by definition). Any simplifying assumptions such as being compact, without boundary and with a positive reach are OK in my context. For example, if is a sphere, then it seems that will trace the geodesic between and , unless they are on the poles. Is there a characterization of this situation? Is this true locally (e.g., for in the neighborhood of )? To me, it seems that must provide a better estimate of the geodesic, but I cannot find relevant results. Thank you.","(M,g) R^n g R^n x, y \in M c(t) = (1-t)x + t y t t \in [0..1] p(t) \in M c(t) M p(t) = Proj_{M} (c(t)) = \arg\min_{p \in M} \|p - c(t)\|_2 M x y p(t) M M M p(t) x y y x p(t)","['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds']"
8,Does any pseudo-Riemannian metric admit a metric-compatible linear connection with vanishing curvature?,Does any pseudo-Riemannian metric admit a metric-compatible linear connection with vanishing curvature?,,"It is well-known that a pseudo-Riemannian manifold $(M,g)$ admits a (unique) torsion-free linear connection $\stackrel{\circ}{\nabla}$ that is compatible with the given metric, i.e. $\stackrel{\circ}{\nabla} g = 0$ . Is it true that there also exists a curvature-free metric-compatible connection $\nabla$ ? Or under what circumstances? Edit: About my conjecture below: In the refined case of a parallelizable pseudo-Riemannian manifold, does there always exist a curvature-free metric-compatible linear connection? Take as an counterexample the maximally-extended Schwarzschild spacetime $(M,g)$ . It is parallelizable as the underlying manifold is homeomorphic to $S^2 \times \mathbb R^2$ . Suppose there exists a metric-compatible curvature-free connection $\nabla$ . Since $M$ is simply-connected, the holonomy group $\operatorname{Hol}^{\nabla}(p)$ vanishes for any point $p \in M$ . We thus can construct a global orthonormal frame using the parallel transport of $\nabla$ . However, no such global orthonormal frame exists. A contradiction.","It is well-known that a pseudo-Riemannian manifold admits a (unique) torsion-free linear connection that is compatible with the given metric, i.e. . Is it true that there also exists a curvature-free metric-compatible connection ? Or under what circumstances? Edit: About my conjecture below: In the refined case of a parallelizable pseudo-Riemannian manifold, does there always exist a curvature-free metric-compatible linear connection? Take as an counterexample the maximally-extended Schwarzschild spacetime . It is parallelizable as the underlying manifold is homeomorphic to . Suppose there exists a metric-compatible curvature-free connection . Since is simply-connected, the holonomy group vanishes for any point . We thus can construct a global orthonormal frame using the parallel transport of . However, no such global orthonormal frame exists. A contradiction.","(M,g) \stackrel{\circ}{\nabla} \stackrel{\circ}{\nabla} g = 0 \nabla (M,g) S^2 \times \mathbb R^2 \nabla M \operatorname{Hol}^{\nabla}(p) p \in M \nabla","['differential-geometry', 'riemannian-geometry']"
9,Inner product of Killing vector field and unit normal satisfies Jacobi equation,Inner product of Killing vector field and unit normal satisfies Jacobi equation,,"Let $(M^{n+1},\bar{g})$ be a space form (i.e. a Riemannian manifold with constant sectional curvature, says $K\in\mathbb{R}$ ). Let $\Sigma$ be an orientable hypersurface in $M$ , with induced metric $g$ and unit normal vector field $\nu$ . Let $X$ be a Killing vector field on $M$ (i.e. $\mathcal{L}_X\bar{g}=0$ ). It is known that if $\Sigma$ has constant mean curvature, then the function \begin{align} f:=\langle X,\nu\rangle \end{align} (I will often use $\langle,\rangle$ to denote $\bar{g}$ ) satisfies the Jacobi equation : \begin{align} \Delta_{\Sigma}f+\big(|A|^2+\overline{Ric}(\nu,\nu)\big)f=0 \end{align} where $\Delta_{\Sigma}$ is the Laplacian on $\Sigma$ in the induced metric, $A=(h_{ij})$ is the second fundamental form of $\Sigma$ , and $\overline{Ric}$ is the Ricci curvature of $(M,\bar{g})$ . This result seems to be quite standard. However I fail to find any reference that gives a proof on it, so I try to prove it by myself as an exercise. Fix a point $p\in\Sigma$ and choose a local orthonormal frame $\{e_i\}_{i=1}^n$ around $p$ such that \begin{align} \nabla_{e_i}e_j\big|_p=0 & & (1) \end{align} where $\nabla$ is the Levi-Civita connection of $(\Sigma,g)$ and I will denote $D$ the Levi-Civita connection of $(M,\bar{g})$ . Then we will have, at point $p$ , \begin{align} \Delta_{\Sigma}f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle +2\sum_{i=1}^n\langle D_{e_i}X,D_{e_i}\nu\rangle +\sum_{i=1}^n\langle X,D_{e_i}(D_{e_i}\nu)\rangle \end{align} I can show that the 2nd term on R.H.S. vanishes and the 3rd term gives $\langle X,\nabla H\rangle-|A|^2\langle X,\nu\rangle$ , so that with $H\equiv const$ and rearrange the equation, we get that at $p$ , \begin{align} \Delta_{\Sigma}f+|A|^2f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle & & (2) \end{align} Now I would like to know how to obtain $-\overline{Ric}(\nu,\nu)\langle X,\nu\rangle$ from the 1st term (the R.H.S. of (2)). Of course, since $(M,\bar{g})$ is a space form, this term is also equal to $-\overline{Ric}(X,\nu)$ . It would perhaps be too long to include my full computation here (surely, I am ready to provide them per request). In short, first using the Killing property of $X$ and (1), I am able to compute that at $p$ , \begin{align} \sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle=-\sum_{i=1}^n\langle D^2_{e_i,\nu}X,e_i\rangle \end{align} then we can use the definition of Riemann curvature tensor to yield an $\overline{Rm}$ -term, which then yields $\overline{Ric}(X,\nu)$ after taking trace. However, the other terms seems to give an extra term, so that in summary, I get \begin{align} -\overline{Ric}(X,\nu) +\sum_{i=1}^n\langle D_{[\nu,e_i]}X,e_i\rangle \end{align} where $[,]$ is the Lie bracket on $(M,\bar{g})$ . I wonder how do we get rid of this extra last term. Any hint, comment and answer are welcomed and greatly appreciated. Any reference which contain a proof of it will also be great.","Let be a space form (i.e. a Riemannian manifold with constant sectional curvature, says ). Let be an orientable hypersurface in , with induced metric and unit normal vector field . Let be a Killing vector field on (i.e. ). It is known that if has constant mean curvature, then the function (I will often use to denote ) satisfies the Jacobi equation : where is the Laplacian on in the induced metric, is the second fundamental form of , and is the Ricci curvature of . This result seems to be quite standard. However I fail to find any reference that gives a proof on it, so I try to prove it by myself as an exercise. Fix a point and choose a local orthonormal frame around such that where is the Levi-Civita connection of and I will denote the Levi-Civita connection of . Then we will have, at point , I can show that the 2nd term on R.H.S. vanishes and the 3rd term gives , so that with and rearrange the equation, we get that at , Now I would like to know how to obtain from the 1st term (the R.H.S. of (2)). Of course, since is a space form, this term is also equal to . It would perhaps be too long to include my full computation here (surely, I am ready to provide them per request). In short, first using the Killing property of and (1), I am able to compute that at , then we can use the definition of Riemann curvature tensor to yield an -term, which then yields after taking trace. However, the other terms seems to give an extra term, so that in summary, I get where is the Lie bracket on . I wonder how do we get rid of this extra last term. Any hint, comment and answer are welcomed and greatly appreciated. Any reference which contain a proof of it will also be great.","(M^{n+1},\bar{g}) K\in\mathbb{R} \Sigma M g \nu X M \mathcal{L}_X\bar{g}=0 \Sigma \begin{align}
f:=\langle X,\nu\rangle
\end{align} \langle,\rangle \bar{g} \begin{align}
\Delta_{\Sigma}f+\big(|A|^2+\overline{Ric}(\nu,\nu)\big)f=0
\end{align} \Delta_{\Sigma} \Sigma A=(h_{ij}) \Sigma \overline{Ric} (M,\bar{g}) p\in\Sigma \{e_i\}_{i=1}^n p \begin{align}
\nabla_{e_i}e_j\big|_p=0 & & (1)
\end{align} \nabla (\Sigma,g) D (M,\bar{g}) p \begin{align}
\Delta_{\Sigma}f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle
+2\sum_{i=1}^n\langle D_{e_i}X,D_{e_i}\nu\rangle
+\sum_{i=1}^n\langle X,D_{e_i}(D_{e_i}\nu)\rangle
\end{align} \langle X,\nabla H\rangle-|A|^2\langle X,\nu\rangle H\equiv const p \begin{align}
\Delta_{\Sigma}f+|A|^2f=\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle & & (2)
\end{align} -\overline{Ric}(\nu,\nu)\langle X,\nu\rangle (M,\bar{g}) -\overline{Ric}(X,\nu) X p \begin{align}
\sum_{i=1}^n\langle D_{e_i}(D_{e_i}X),\nu\rangle=-\sum_{i=1}^n\langle D^2_{e_i,\nu}X,e_i\rangle
\end{align} \overline{Rm} \overline{Ric}(X,\nu) \begin{align}
-\overline{Ric}(X,\nu)
+\sum_{i=1}^n\langle D_{[\nu,e_i]}X,e_i\rangle
\end{align} [,] (M,\bar{g})","['differential-geometry', 'riemannian-geometry', 'curvature']"
10,Differentiable manifolds as locally ringed spaces,Differentiable manifolds as locally ringed spaces,,"Let $X$ be a differentiable manifold. Let $\mathcal{O}_X$ be the sheaf of $\mathcal{C}^\infty$ functions on $X$. Since every stalk of $\mathcal{O}_X$ is a local ring, $(X, \mathcal{O}_X)$ is a locally ringed space. Let $Y$ be another differentiable manifold. Let $f\colon X \rightarrow Y$ be a differentiable map. Let $U$ be an open subset of $Y$. For $h \in \Gamma(\mathcal{O}_Y, U)$, $h\circ f \in \Gamma(\mathcal{O}_X, f^{-1}(U))$. Hence we get an $\mathbb{R}$-morphism $\Gamma(\mathcal{O}_Y, U) \rightarrow \Gamma(\mathcal{O}_X, f^{-1}(U))$ of $\mathbb{R}$-algebras. Hence we get a morphism $f^{\#} \colon \mathcal{O}_Y \rightarrow f_*(\mathcal{O}_X)$ of sheaves of $\mathbb{R}$-algebras. It is easy to see that $(f, f^{\#})$ is a morphism of locally ringed spaces. Conversely suppose $(f, \psi)\colon X \rightarrow Y$ is a morphism of locally ringed spaces, where $X$ and $Y$ are differentiable manifolds and $\psi\colon \mathcal{O}_Y \rightarrow f_*(\mathcal{O}_X)$is a morphism of sheaves of $\mathbb{R}$-algebras. Is $f$ a differentiable map and $\psi = f^{\#}$?","Let $X$ be a differentiable manifold. Let $\mathcal{O}_X$ be the sheaf of $\mathcal{C}^\infty$ functions on $X$. Since every stalk of $\mathcal{O}_X$ is a local ring, $(X, \mathcal{O}_X)$ is a locally ringed space. Let $Y$ be another differentiable manifold. Let $f\colon X \rightarrow Y$ be a differentiable map. Let $U$ be an open subset of $Y$. For $h \in \Gamma(\mathcal{O}_Y, U)$, $h\circ f \in \Gamma(\mathcal{O}_X, f^{-1}(U))$. Hence we get an $\mathbb{R}$-morphism $\Gamma(\mathcal{O}_Y, U) \rightarrow \Gamma(\mathcal{O}_X, f^{-1}(U))$ of $\mathbb{R}$-algebras. Hence we get a morphism $f^{\#} \colon \mathcal{O}_Y \rightarrow f_*(\mathcal{O}_X)$ of sheaves of $\mathbb{R}$-algebras. It is easy to see that $(f, f^{\#})$ is a morphism of locally ringed spaces. Conversely suppose $(f, \psi)\colon X \rightarrow Y$ is a morphism of locally ringed spaces, where $X$ and $Y$ are differentiable manifolds and $\psi\colon \mathcal{O}_Y \rightarrow f_*(\mathcal{O}_X)$is a morphism of sheaves of $\mathbb{R}$-algebras. Is $f$ a differentiable map and $\psi = f^{\#}$?",,"['differential-geometry', 'sheaf-theory']"
11,Show that submanifolds are in fact manifolds.,Show that submanifolds are in fact manifolds.,,"Quoting Tu's ""An introduction to manifolds"": Definition 9.1 . A subset $S$ of a manifold $N$ of dimension $n$ is a regular submanifold of dimension $k$ if for every $p \in S$ there is a coordinate neighborhood $(U,f) = (U,x_1,\dots,x_n)$ of $p$ in the maximal atlas of $N$ such that $U \cap S$ is defined by the vanishing of $n−k$ of the coordinate functions. By renumbering the coordinates, we may assume that these $n−k$ coordinate functions are $x_{k+1},\dots,x_n$ . We call such a chart $(U,f)$ in $N$ an adapted chart relative to $S$ . On $U \cap S$ , $f = (x_1, . . . ,x_k,0, . . . ,0)$ . More concretely, $$f(U\cap S) = f(U) \cap (\mathbb{R}^k \times \{0_{n-k}\})$$ Let $f_S : U\cap S→\mathbb{R}^k$ be the restriction of the first $k$ components of $f$ to $U \cap S$ , that is, $f_S = (x_1, . . . ,x_k)$ . Note that $(U\cap S,f_S)$ is a chart for $S$ in the subspace topology. My notes then say that if we put the subspace topology on $S$ and the atlas $\{(U\cap S, f_S)\}$ , then $S$ becomes a smooth manifold with as maximal atlas the unique atlas containing $\{(U\cap S, f_S)\}$ . I'm trying to prove this (Tu's book contains a proof, but this seems easier). Here is my idea: Clearly $U \cap S$ is open in $S$ , because $U$ is open in $M$ . Define $\operatorname{pr}: f(U \cap S) \to pr(f(U \cap S)): (x_1, \dots, x_n) \mapsto (x_1, \dots, x_k)$ , thus the projection that forgets the last $n-k$ coordinates. Note that on the given domain and codomain, $pr$ is bijective with $$\operatorname{pr}^{-1}(x_1, \dots, x_k) = (x_1, \dots, x_k, 0, \dots, 0)$$ Then, observe that $f_S = \operatorname{pr} \circ f$ . Clearly, $pr$ is a $C^\infty$ diffeomorphism on the given domain and codomain, and thus $f_S$ is a homeomorphism as composition of homeomorphisms. I also have a proof that $f_S(U \cap S)$ is an open subset of $\mathbb{R}^k$ , but to save space I won't include it here. Thus, it remains to prove that any two charts $f_S: U \cap S\to \mathbb{R}^k, g_S: U \cap S \to \mathbb{R}^k$ are compatible. This is clear, because on $f_S(U \cap V \cap S)$ we have $$g_S \circ f_S^{-1} = (\operatorname{pr}^g \circ g) \circ (\operatorname{pr}^f \circ f)^{-1} = \operatorname{pr}^f \circ (g \circ f^{-1}) \circ \operatorname{pr}^f$$ which is $C^\infty$ , as composition of $C^\infty$ maps. Is the above correct? Thanks in advance for any help.","Quoting Tu's ""An introduction to manifolds"": Definition 9.1 . A subset of a manifold of dimension is a regular submanifold of dimension if for every there is a coordinate neighborhood of in the maximal atlas of such that is defined by the vanishing of of the coordinate functions. By renumbering the coordinates, we may assume that these coordinate functions are . We call such a chart in an adapted chart relative to . On , . More concretely, Let be the restriction of the first components of to , that is, . Note that is a chart for in the subspace topology. My notes then say that if we put the subspace topology on and the atlas , then becomes a smooth manifold with as maximal atlas the unique atlas containing . I'm trying to prove this (Tu's book contains a proof, but this seems easier). Here is my idea: Clearly is open in , because is open in . Define , thus the projection that forgets the last coordinates. Note that on the given domain and codomain, is bijective with Then, observe that . Clearly, is a diffeomorphism on the given domain and codomain, and thus is a homeomorphism as composition of homeomorphisms. I also have a proof that is an open subset of , but to save space I won't include it here. Thus, it remains to prove that any two charts are compatible. This is clear, because on we have which is , as composition of maps. Is the above correct? Thanks in advance for any help.","S N n k p \in S (U,f) = (U,x_1,\dots,x_n) p N U \cap S n−k n−k x_{k+1},\dots,x_n (U,f) N S U \cap S f =
(x_1, . . . ,x_k,0, . . . ,0) f(U\cap S) = f(U) \cap (\mathbb{R}^k \times \{0_{n-k}\}) f_S : U\cap S→\mathbb{R}^k k f U \cap S f_S = (x_1, . . . ,x_k) (U\cap S,f_S) S S \{(U\cap S, f_S)\} S \{(U\cap S, f_S)\} U \cap S S U M \operatorname{pr}: f(U \cap S) \to pr(f(U \cap S)): (x_1, \dots, x_n) \mapsto (x_1, \dots, x_k) n-k pr \operatorname{pr}^{-1}(x_1, \dots, x_k) = (x_1, \dots, x_k, 0, \dots, 0) f_S = \operatorname{pr} \circ f pr C^\infty f_S f_S(U \cap S) \mathbb{R}^k f_S: U \cap S\to \mathbb{R}^k, g_S: U \cap S \to \mathbb{R}^k f_S(U \cap V \cap S) g_S \circ f_S^{-1} = (\operatorname{pr}^g \circ g) \circ (\operatorname{pr}^f \circ f)^{-1} = \operatorname{pr}^f \circ (g \circ f^{-1}) \circ \operatorname{pr}^f C^\infty C^\infty","['proof-verification', 'differential-geometry']"
12,$f:\mathbb{R}^n\to\mathbb{R}^n$ is diffeomorphism iff $f$ is local diffeomorphism and proper map,is diffeomorphism iff  is local diffeomorphism and proper map,f:\mathbb{R}^n\to\mathbb{R}^n f,I have to prove that a proper local diffeomorphism in $\mathbb{R}^n$ is a diffeomorphism. I'm trying to show that it is injective but I just have that the preimage of every $y\in\mathbb{R}^n$ is a finite set. Could anybody help me? Thanks.,I have to prove that a proper local diffeomorphism in is a diffeomorphism. I'm trying to show that it is injective but I just have that the preimage of every is a finite set. Could anybody help me? Thanks.,\mathbb{R}^n y\in\mathbb{R}^n,"['real-analysis', 'differential-geometry', 'differential-topology', 'diffeomorphism']"
13,Show that a vector field is complete,Show that a vector field is complete,,"Show that if $f:M\to \mathbb{R}$ is a positive and proper function and $X$ is a vector field such that $\langle df,X\rangle $ is bounded, then $X$ is complete. I know that if $X$ is a vector field with compact support, then it is complete, but i do not know how to use the fact that $\langle df,X\rangle $ is bounded. Thank you!","Show that if is a positive and proper function and is a vector field such that is bounded, then is complete. I know that if is a vector field with compact support, then it is complete, but i do not know how to use the fact that is bounded. Thank you!","f:M\to \mathbb{R} X \langle df,X\rangle  X X \langle df,X\rangle ","['differential-geometry', 'smooth-manifolds', 'vector-fields']"
14,"Alternate proof of the isomorphism $T_{(p,q)}(X \times Y) \cong T_p X \times T_q Y$",Alternate proof of the isomorphism,"T_{(p,q)}(X \times Y) \cong T_p X \times T_q Y","As in the title, with $X$ and $Y$ smooth manifolds. I am filling in the details of a proof here , and I have a question about identifications of tangent vectors/spaces. Fix $(p,q)\in X\times Y$ . Let $i:x\mapsto (x,q)$ and $\pi:(x,y)\mapsto x$ . Then, $L=d(i\circ \pi)$ is a projection, so $\text{ker}(L)\oplus \text{im}(L)=T_{(p,q)}(X\times Y).$ Assume first that $X$ and $Y$ are Euclidean spaces, and take a curve $\gamma:(-\epsilon,\epsilon)\to X\times Y$ with $\gamma (0)=(p,q)$ . Now, $\gamma (t)=(\gamma_1(t),\gamma_2(t))$ with $\gamma_1(0)=p$ . Then, $d(\iota_X\circ \pi_X)_{(p,q)}\gamma'(0) = \frac{d}{dt}|_{t=0}(\gamma_1(t),q) = (\gamma_1'(0),0)$ so the image of $L$ is isomorphic to $T_pX.$ Simlilarly, since $di$ is injective, $\text{ker}L=\text{ker}\pi$ so for $\gamma$ as above we have $(d\pi)_{(p,q)}\gamma'(0)=\frac{d}{dt}|_{t=0}\pi\circ\gamma(t)=\gamma_1'(0).$ If this is to be equal to $0$ then $T_pX=0$ and so $\text{ker}L\cong T_qY.$ Now, suppose that $X$ and $Y$ are arbitrary manifolds, so that now the tangent vector is defined by $d(\iota_X\circ \pi_X)_{(p,q)}\gamma'(0)(f) = \frac{d}{dt}|_{t=0}f(\gamma_1(t),q)$ for smooth $f:X\times Y\to \mathbb R.$ In the above link to the sketch of a proof, the author uses the first blockquote equation for the arbitrary manifolds $X$ and $Y$ , (the second is mine) but isn't there a problem with this? He/she seems to be using the same symbol for different objects and/or making some identification. Namely, the equation that should be used is that in the third blockquote, because if not, then the $\gamma'(0)$ on the LHS is a tangent vector in $T_{(p,q)}(X\times Y$ ), whereas the RHS is not a tangent vector. The derivative does not even make sense unless we are working in some coordinate chart, but even in this case, it is not clear to me what identification(s) we are using. I am not claiming that the result is false, only that there is some explanation that I am missing here. In fact, I have a general problem with this type of machinery one uses in differential geometry (I am self-studying Lee). I understand how the various definitions of the tangent space are equivalent, but I have trouble understanding equations in which there are implicit identifications made.","As in the title, with and smooth manifolds. I am filling in the details of a proof here , and I have a question about identifications of tangent vectors/spaces. Fix . Let and . Then, is a projection, so Assume first that and are Euclidean spaces, and take a curve with . Now, with . Then, so the image of is isomorphic to Simlilarly, since is injective, so for as above we have If this is to be equal to then and so Now, suppose that and are arbitrary manifolds, so that now the tangent vector is defined by for smooth In the above link to the sketch of a proof, the author uses the first blockquote equation for the arbitrary manifolds and , (the second is mine) but isn't there a problem with this? He/she seems to be using the same symbol for different objects and/or making some identification. Namely, the equation that should be used is that in the third blockquote, because if not, then the on the LHS is a tangent vector in ), whereas the RHS is not a tangent vector. The derivative does not even make sense unless we are working in some coordinate chart, but even in this case, it is not clear to me what identification(s) we are using. I am not claiming that the result is false, only that there is some explanation that I am missing here. In fact, I have a general problem with this type of machinery one uses in differential geometry (I am self-studying Lee). I understand how the various definitions of the tangent space are equivalent, but I have trouble understanding equations in which there are implicit identifications made.","X Y (p,q)\in X\times Y i:x\mapsto (x,q) \pi:(x,y)\mapsto x L=d(i\circ \pi) \text{ker}(L)\oplus \text{im}(L)=T_{(p,q)}(X\times Y). X Y \gamma:(-\epsilon,\epsilon)\to X\times Y \gamma (0)=(p,q) \gamma (t)=(\gamma_1(t),\gamma_2(t)) \gamma_1(0)=p d(\iota_X\circ \pi_X)_{(p,q)}\gamma'(0) = \frac{d}{dt}|_{t=0}(\gamma_1(t),q) = (\gamma_1'(0),0) L T_pX. di \text{ker}L=\text{ker}\pi \gamma (d\pi)_{(p,q)}\gamma'(0)=\frac{d}{dt}|_{t=0}\pi\circ\gamma(t)=\gamma_1'(0). 0 T_pX=0 \text{ker}L\cong T_qY. X Y d(\iota_X\circ \pi_X)_{(p,q)}\gamma'(0)(f) = \frac{d}{dt}|_{t=0}f(\gamma_1(t),q) f:X\times Y\to \mathbb R. X Y \gamma'(0) T_{(p,q)}(X\times Y","['proof-verification', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'alternative-proof']"
15,Elementary Differential Geometry before Manifolds?,Elementary Differential Geometry before Manifolds?,,"Many courses called Differential Geometry (at least in Germany; at least as far as I know!) solely deal with manifolds and not classical/elementary Differential Geometry (curves, curvature, fundamental forms, ...). So my simple question is: Should you study Elementary Differential Geometry before having a serious go at manifolds?","Many courses called Differential Geometry (at least in Germany; at least as far as I know!) solely deal with manifolds and not classical/elementary Differential Geometry (curves, curvature, fundamental forms, ...). So my simple question is: Should you study Elementary Differential Geometry before having a serious go at manifolds?",,"['differential-geometry', 'soft-question', 'self-learning', 'advice']"
16,Hamiltonian flow vs Gradient flow,Hamiltonian flow vs Gradient flow,,"A Hamiltonian vector field in a symplectic manifold is the analog of a gradient vector field in Riemannian manifold. A simple computation using Cartan's magic formula shows that a Hamiltonian vector field preserves the symplectic structure, equivalently its flow acts by symplectomorphisms. However it is not the case that a gradient flow preserves the Riemannian metric, even for a Euclidean metric. Why does it work in one case and not the other? I mean, I understand the computations, but is there any insight that can be given?","A Hamiltonian vector field in a symplectic manifold is the analog of a gradient vector field in Riemannian manifold. A simple computation using Cartan's magic formula shows that a Hamiltonian vector field preserves the symplectic structure, equivalently its flow acts by symplectomorphisms. However it is not the case that a gradient flow preserves the Riemannian metric, even for a Euclidean metric. Why does it work in one case and not the other? I mean, I understand the computations, but is there any insight that can be given?",,"['differential-geometry', 'riemannian-geometry', 'symplectic-geometry']"
17,Which applications parallel transport have?,Which applications parallel transport have?,,"I am looking for some applications of parallel transport. I have seen that, for example, one can find connection by using parallel transport. Which other application the parallel transport might have that make it interesting to study or in other words Why we do parallel transport of a vector along a curve?","I am looking for some applications of parallel transport. I have seen that, for example, one can find connection by using parallel transport. Which other application the parallel transport might have that make it interesting to study or in other words Why we do parallel transport of a vector along a curve?",,"['differential-geometry', 'riemannian-geometry']"
18,Line bundle defined by exceptional divisor; $\mathcal O(E) = \pi^*\mathcal O(-1)$,Line bundle defined by exceptional divisor;,\mathcal O(E) = \pi^*\mathcal O(-1),"In Huybrechts book (Cor 2.5.6), it is shown: Let $X=\mathbb C^{n}$ and $\hat X$ its blow-up at $0$ . Then locally $\mathcal O(E) = \pi^*\mathcal O(-1)$ , where $\pi: \hat X \to \mathbb P^{n-1}$ . I have trouble understanding the proof: Its clear, that $\bigcup_{(\ell,z)\in \hat X} \ell$ is a line bundle. But why is it isomorphic to $\mathcal O(E)$ ? Why does the section $t(\ell,z)=((\ell,z),z)$ vanish with multiplicity $1$ ? Why does 2. imply $\mathcal O(E) = \pi^*\mathcal O(-1)$ ? I think 2. is simply because the function $z$ vanishes with multiplicity $1$ at $0$ , but for the rest I have no clue.","In Huybrechts book (Cor 2.5.6), it is shown: Let and its blow-up at . Then locally , where . I have trouble understanding the proof: Its clear, that is a line bundle. But why is it isomorphic to ? Why does the section vanish with multiplicity ? Why does 2. imply ? I think 2. is simply because the function vanishes with multiplicity at , but for the rest I have no clue.","X=\mathbb C^{n} \hat X 0 \mathcal O(E) = \pi^*\mathcal O(-1) \pi: \hat X \to \mathbb P^{n-1} \bigcup_{(\ell,z)\in \hat X} \ell \mathcal O(E) t(\ell,z)=((\ell,z),z) 1 \mathcal O(E) = \pi^*\mathcal O(-1) z 1 0","['differential-geometry', 'complex-geometry', 'blowup']"
19,The diffeomorphism between two sub-level sets,The diffeomorphism between two sub-level sets,,"Let $f:M \rightarrow \mathbb{R}$ be a smooth map ( $f \in C^{\infty}(M)$ ), where $M$ is a compact manifold . Prove that $f^{-1}((-\infty,a])$ is diffeomorphic to $f^{-1}((-\infty,b])$ if the interval $[a,b]$ doesn't contain critical values of $f$ . I have no idea how to deal with this now and really need some hints. Any help would be appreciated.","Let be a smooth map ( ), where is a compact manifold . Prove that is diffeomorphic to if the interval doesn't contain critical values of . I have no idea how to deal with this now and really need some hints. Any help would be appreciated.","f:M \rightarrow \mathbb{R} f \in C^{\infty}(M) M f^{-1}((-\infty,a]) f^{-1}((-\infty,b]) [a,b] f","['differential-geometry', 'differential-topology']"
20,Structure Group of a Principal G Bundle is G,Structure Group of a Principal G Bundle is G,,"Definition 1: A principal $G$ -bundle is a fiber bundle $F \to P \xrightarrow{\pi} X$ together with a right action of $G$ on $P$ such that: (i) $G$ acts freely and transitively on fibers. (ii) $G$ preserves fibers. I am trying to show that the structure group of a principal $G$ -Bundle is $G$ , following wikipedia's definition of a structure group of a fiber bundle .  What I have come up with is the following: Suppose $(U_i,φ_i)$ , $(U_j,φ_j)$ are local trivilizations, then since $φ_i \vert_{π^{-1}(q)} : π^{-1}(q) \to \{q\}\times F  $ (similarly for $j$ ) we should have for $x \in U_i \cap U_j $ , $ξ \in F$ $$φ_i φ^{-1}_j (x,ξ)=(x,ξ') $$ Now $(x,ξ')$ corresponds to an element $p \in π^{-1} (x)$ by $φ^{-1}_j$ and $(x,ξ)$ to an element $p' \in  π^{-1} (x)$ . But we have a transitive right action of G on P, so that we can find a $g \in G$ s.t. $p'=pg$ . Thus, for each $x \in U_i \cap U_j $ we can define a left action on $F$ that takes $ξ$ το $ξ'$ : $$φ_i φ^{-1}_j (x,ξ)=(x,ξ')=(x', t_{ij}(x)ξ) $$ and now $t_{ij}(x)=g \in G$ (the $g$ which acting on $p$ gives $p'$ ) acts on $F$ , so that $G$ is the structure group of our principal $G$ bundle. Is this reasoning correct/complete? Have I missed something? I haven't managed to find anything in the literature proving that  given Definition 1 we can show that the structure group is $G$ and I was wondering if what I came up with is the way it's supposed to be done. EDIT Seeing this question Equivalence of Definitions of Principal G -bundle it seems to me from Defition 3, since existence of G-equivariant cover is equivalent to having a structure group G, that the structure group being G is part of the definition and thus does not follow from it? I have to say I am generally confused by the definition(s), does it contain both actions on P and on the fiber, or do we define one action and the other follows?","Definition 1: A principal -bundle is a fiber bundle together with a right action of on such that: (i) acts freely and transitively on fibers. (ii) preserves fibers. I am trying to show that the structure group of a principal -Bundle is , following wikipedia's definition of a structure group of a fiber bundle .  What I have come up with is the following: Suppose , are local trivilizations, then since (similarly for ) we should have for , Now corresponds to an element by and to an element . But we have a transitive right action of G on P, so that we can find a s.t. . Thus, for each we can define a left action on that takes το : and now (the which acting on gives ) acts on , so that is the structure group of our principal bundle. Is this reasoning correct/complete? Have I missed something? I haven't managed to find anything in the literature proving that  given Definition 1 we can show that the structure group is and I was wondering if what I came up with is the way it's supposed to be done. EDIT Seeing this question Equivalence of Definitions of Principal G -bundle it seems to me from Defition 3, since existence of G-equivariant cover is equivalent to having a structure group G, that the structure group being G is part of the definition and thus does not follow from it? I have to say I am generally confused by the definition(s), does it contain both actions on P and on the fiber, or do we define one action and the other follows?","G F \to P \xrightarrow{\pi} X G P G G G G (U_i,φ_i) (U_j,φ_j) φ_i \vert_{π^{-1}(q)} : π^{-1}(q) \to \{q\}\times F   j x \in U_i \cap U_j  ξ \in F φ_i φ^{-1}_j (x,ξ)=(x,ξ')  (x,ξ') p \in π^{-1} (x) φ^{-1}_j (x,ξ) p' \in  π^{-1} (x) g \in G p'=pg x \in U_i \cap U_j  F ξ ξ' φ_i φ^{-1}_j (x,ξ)=(x,ξ')=(x', t_{ij}(x)ξ)  t_{ij}(x)=g \in G g p p' F G G G","['differential-geometry', 'differential-topology', 'fiber-bundles', 'principal-bundles']"
21,Reference request on Riemann-Hilbert correspondence,Reference request on Riemann-Hilbert correspondence,,"I'm looking for any books, lecture notes, e.t.c for the Riemann-Hilbert correspondence in the form of the following equivalence between flat $G$ -connections, $G$ -local systems and Homomorphisms from a fundamental group to $G$ .","I'm looking for any books, lecture notes, e.t.c for the Riemann-Hilbert correspondence in the form of the following equivalence between flat -connections, -local systems and Homomorphisms from a fundamental group to .",G G G,"['differential-geometry', 'algebraic-geometry', 'reference-request', 'complex-geometry']"
22,Problem with equivalent definition of a integrable $G$-structure,Problem with equivalent definition of a integrable -structure,G,"I'm reading Kobayashi's book Transformation Groups in Differential Geometry and I don't understand a thing at page 2. It this proposition: My problem is that I don't understand the converse of this proposition. Is not clear how he is doing that linear change of coordinate, nothing is clear or formal and I'm also new to the subject. Can some one fill in some details for me please? Or maybe I should check another book on $G$ - structures. Can some one point me to a good book on this subject? EDIT: this is the definition of the integrability that is used here.","I'm reading Kobayashi's book Transformation Groups in Differential Geometry and I don't understand a thing at page 2. It this proposition: My problem is that I don't understand the converse of this proposition. Is not clear how he is doing that linear change of coordinate, nothing is clear or formal and I'm also new to the subject. Can some one fill in some details for me please? Or maybe I should check another book on - structures. Can some one point me to a good book on this subject? EDIT: this is the definition of the integrability that is used here.",G,"['differential-geometry', 'tensor-products', 'fiber-bundles', 'principal-bundles']"
23,Can one hear the shape of a DeRham ring ? Is any ring a DeRham ring?,Can one hear the shape of a DeRham ring ? Is any ring a DeRham ring?,,"Sorry for the Clicbait title, but take $A$ a graded $\mathbb R$ commutative (in the graded sense) algebra of finite dimension. Does there exist a smooth manifold $M$ having $A$ as a DeRham cohomology ring : $H^*(M) \simeq A$ ? In the negative case, what would be a natural restriction that I missed on the structure of the DeRham ring ? I was thinking of taking generators for the algebra and taking product of spheres. But i have problems when those generators verfies relations among them.","Sorry for the Clicbait title, but take a graded commutative (in the graded sense) algebra of finite dimension. Does there exist a smooth manifold having as a DeRham cohomology ring : ? In the negative case, what would be a natural restriction that I missed on the structure of the DeRham ring ? I was thinking of taking generators for the algebra and taking product of spheres. But i have problems when those generators verfies relations among them.",A \mathbb R M A H^*(M) \simeq A,"['differential-geometry', 'ring-theory']"
24,"Geometric significance of the differential of the Gauss map, $dN_p: T_p(S) \rightarrow T_p(S)$, being a self adjoint linear map.","Geometric significance of the differential of the Gauss map, , being a self adjoint linear map.",dN_p: T_p(S) \rightarrow T_p(S),"i'm studying differential geometry for the first time and I just started reading about the gauss map and I've gotta say this stuff is pretty cool. The claim made in the title of this post is from page 142 of Do Carmo's Differential geometry book, where it is stated as ""proposition 1"". I have never taken a proper geometry class before and the text is starting to get to the point where the density of the calculus/linear algebra is making the geometric significance of the statements rather opaque. That being said, I feel that there is an 'aha' moment just around the corner with this one, and people here are usually pretty good at breaking things down for me so I thought i'd ask y'll this rather soft question. Anyway, just to refresh your memory, I'm looking to understand the geometric significance of the differential of the Gauss map, $dN_p: T_p(S) \rightarrow T_p(S)$ , being a self adjoint linear map. (in particular, what is the geometric significance of this linear map being 'self adjoint'.) Where $N: S \rightarrow S^2$ is a map from the set of normal unit vectors of a regualer surface $S$ to the unit sphere $S^2$ and $T_p(S)$ is that tangent plane of an arbitrary $p \in S$ . Also, note that $T_p(S)$ and $T_{N(p)}(S^2)$ are the same as vector spaces, which is why we can view $dN_p$ as a linear map from $T_p(S) \rightarrow T_p(S)$","i'm studying differential geometry for the first time and I just started reading about the gauss map and I've gotta say this stuff is pretty cool. The claim made in the title of this post is from page 142 of Do Carmo's Differential geometry book, where it is stated as ""proposition 1"". I have never taken a proper geometry class before and the text is starting to get to the point where the density of the calculus/linear algebra is making the geometric significance of the statements rather opaque. That being said, I feel that there is an 'aha' moment just around the corner with this one, and people here are usually pretty good at breaking things down for me so I thought i'd ask y'll this rather soft question. Anyway, just to refresh your memory, I'm looking to understand the geometric significance of the differential of the Gauss map, , being a self adjoint linear map. (in particular, what is the geometric significance of this linear map being 'self adjoint'.) Where is a map from the set of normal unit vectors of a regualer surface to the unit sphere and is that tangent plane of an arbitrary . Also, note that and are the same as vector spaces, which is why we can view as a linear map from",dN_p: T_p(S) \rightarrow T_p(S) N: S \rightarrow S^2 S S^2 T_p(S) p \in S T_p(S) T_{N(p)}(S^2) dN_p T_p(S) \rightarrow T_p(S),['differential-geometry']
25,Understanding the homotopy operator for de Rham Cohomology,Understanding the homotopy operator for de Rham Cohomology,,"This is in John Lee's Smooth Manifold 2nd Edition, pg 444 For any smooth manifold $M$ , there exists a linear map $$ h:\Omega^p(M \times I ) \rightarrow \Omega^{p-1}(M)$$ such that $$ h(dw)+d(hw) = i_1^*w - i^*_0w$$ The proof begins goes as follows. This is the same one here . Let $s$ be the standard coordinate on $\Bbb R$ and let $S$ be the vector field on $M \times \Bbb R$ given by $S_{(q,s)} = (0, \partial/\partial s|_s)$ . Let $w$ be a smooth $p$ -form on $M \times I$ . Define $hw \in \Omega^{p-1}(M)$ by $$ hw = \int_0^1 i^*_t (S \lrcorner w) \, dt. $$ Specifically, given $q \in M$ , this means, $$ (hw)_q = \int_0^1 i^*_t\Big( (S \lrcorner w )_{(q,t)} \Big) \, dt $$ The notation $S \lrcorner w$ is interior multiplication. Otherwise denoted by $\iota_Sw$ . My question is, what does this integral even mean ? At each point $q \in M$ , the integrand is a function of $t$ with values in the vector space $\wedge^{p-1} (T^*q M)$ . How do we integrate over this? My thoughts on the way to see this: We work locally, in nhood $U_q$ . For $r \in U_q$ our integrand is given by $$ \sum a_I(r,t) dx^I$$ summing over indices $I$ increasing $p-1$ length subset of $0$ to $n$ . Our new $p-1$ form is given by $$ \sum \int a_I(r,t) \, dt \, d x^I $$ There is a problem however, that we have to show this is independent of the choice of coordinate.","This is in John Lee's Smooth Manifold 2nd Edition, pg 444 For any smooth manifold , there exists a linear map such that The proof begins goes as follows. This is the same one here . Let be the standard coordinate on and let be the vector field on given by . Let be a smooth -form on . Define by Specifically, given , this means, The notation is interior multiplication. Otherwise denoted by . My question is, what does this integral even mean ? At each point , the integrand is a function of with values in the vector space . How do we integrate over this? My thoughts on the way to see this: We work locally, in nhood . For our integrand is given by summing over indices increasing length subset of to . Our new form is given by There is a problem however, that we have to show this is independent of the choice of coordinate.","M  h:\Omega^p(M \times I ) \rightarrow \Omega^{p-1}(M)  h(dw)+d(hw) = i_1^*w - i^*_0w s \Bbb R S M \times \Bbb R S_{(q,s)} = (0, \partial/\partial s|_s) w p M \times I hw \in \Omega^{p-1}(M)  hw = \int_0^1 i^*_t (S \lrcorner w) \, dt.  q \in M  (hw)_q = \int_0^1 i^*_t\Big( (S \lrcorner w )_{(q,t)} \Big) \, dt  S \lrcorner w \iota_Sw q \in M t \wedge^{p-1} (T^*q M) U_q r \in U_q  \sum a_I(r,t) dx^I I p-1 0 n p-1  \sum \int a_I(r,t) \, dt \, d x^I ","['differential-geometry', 'algebraic-topology', 'homotopy-theory', 'de-rham-cohomology']"
26,Osculating circle at curvature minimum point of simple closed curve encloses the curve,Osculating circle at curvature minimum point of simple closed curve encloses the curve,,"The story begins with seemingly unrelating situation. I was trying to find out an elementary solution of the following problem. A circle is called a separator for a set of five points in a plane if it passes through three of these points, it contains a fourth point inside and the fifth point is outside the circle. Prove that every set of five points such that no three are collinear and no four are concyclic has exactly four separators. (IMO Shortlist 1999 G2) This problem can be solved by means of inversion or Möbius transformations. But I was stuck making elementary solution which does not makes use of those tools. I reached at the point that the following may be useful For each three distinct points $P$ , $Q$ , $R$ , let $\Gamma(P,Q,R)$ be the outer circle of $PQR$ . Let $A_1A_2A_3 \cdots A_n$ be a convex polygon where no three of the consecutive vertices are colinear and $n \ge 3$ . Prove that among the $n$ circles, the one with the maximum radius encloses the polygon; $$ \Gamma(A_1A_2A_3), \Gamma(A_2A_3A_4), \ldots \Gamma(A_nA_1A_2) $$ At the moment when I got this observation, I guess this can be proved easily. But after trying some quick treat, I realized that this is essentially the problem of curvature.(Anyway, I cannot prove this either) So my question is the following Let $\gamma$ be a smooth closed simple curve whose curvature never vanishes. Prove that the osculating circle at the point where the curvature is minimum encloses the curve. I know that the question is so elementary that it is almost surely duplicate. However, I have searched several keywords without encountering similar question. So it would be great if someone gives links or the same questions or references in which the proof could be found. Thanks for your attention.","The story begins with seemingly unrelating situation. I was trying to find out an elementary solution of the following problem. A circle is called a separator for a set of five points in a plane if it passes through three of these points, it contains a fourth point inside and the fifth point is outside the circle. Prove that every set of five points such that no three are collinear and no four are concyclic has exactly four separators. (IMO Shortlist 1999 G2) This problem can be solved by means of inversion or Möbius transformations. But I was stuck making elementary solution which does not makes use of those tools. I reached at the point that the following may be useful For each three distinct points , , , let be the outer circle of . Let be a convex polygon where no three of the consecutive vertices are colinear and . Prove that among the circles, the one with the maximum radius encloses the polygon; At the moment when I got this observation, I guess this can be proved easily. But after trying some quick treat, I realized that this is essentially the problem of curvature.(Anyway, I cannot prove this either) So my question is the following Let be a smooth closed simple curve whose curvature never vanishes. Prove that the osculating circle at the point where the curvature is minimum encloses the curve. I know that the question is so elementary that it is almost surely duplicate. However, I have searched several keywords without encountering similar question. So it would be great if someone gives links or the same questions or references in which the proof could be found. Thanks for your attention.","P Q R \Gamma(P,Q,R) PQR A_1A_2A_3 \cdots A_n n \ge 3 n  \Gamma(A_1A_2A_3), \Gamma(A_2A_3A_4), \ldots \Gamma(A_nA_1A_2)  \gamma","['differential-geometry', 'curves', 'curvature']"
27,Detail in Perelman's proof of the Soul Conjecture: why $O(\delta^2)$ and not $O(\delta)$?,Detail in Perelman's proof of the Soul Conjecture: why  and not ?,O(\delta^2) O(\delta),"Referring to G. Perelman, Proof of the soul conjecture by Cheeger and Gromoll . Given a distance-nonincreasing retraction $P$ from an open complete manifold of nonnegative curvature onto its soul $S$ , one wants to prove that $P(\exp_xt\nu)=x$ for every $x\in S$ and $t\geq 0$ . Suppose this is true up to $t=l$ , and consider the function $$f(r)=\max\{|xP(\exp_x(l+r)\nu)|\mid x\in S, \nu\in SN_x(S)\}$$ where $SN(S)$ is the unitary normal bundle to $S$ . It seems to me that the only way to interpret the notation $|xP(\exp_x(l+r)\nu)|$ is ""the Riemannian distance between the two points"". But later in the proof, Perelman does the following: he has a geodesic $\gamma(u)\in S$ , a parallel normal field $\nu$ along $\gamma$ , and two ""vertical"" geodesics related to a variation around $\gamma$ , namely $\sigma_{u_0}(t)=\exp_{\gamma(u_0)}t\nu$ and $\sigma_{u_1}(t)=\exp_{\gamma(u_0)}t\nu$ , $t$ varying. He then proves that the two-dimensional strip between these two $\sigma_{u_0}$ and $\sigma_{u_1}$ is flat and totally geodesic, and that all the   ""horizontal"" geodesics $\gamma_t(u)=\exp_{\gamma(u)}t\nu, > u\in[u_0,u_1]$ are minimizing of constant length $l(\gamma|_{[u_0,u_1]})$ . Then he claims that, for small $\delta$ , $$f(r-\delta)\geq |\gamma(u_1)P(\sigma_{u_1}(l+r-\delta))|\geq|P(\sigma_{u_0}(l+r)\gamma(u_1)|-|P(\sigma_{u_0}(l+r))P(\sigma_{u_1}(l+r-\delta))|\geq|P(\sigma_{u_0}(l+r))\gamma(u_1)|-|\sigma_{u_1}(l+r-\delta)\sigma_{u_0}(l+r)|\geq|P(\sigma_{u_0}(l+r)\gamma(x_1)|-|\sigma_{u_0}(l+r)\sigma_{u_1}(l+r)|-O(\delta^2).$$ Recall that $\gamma(u)=\sigma_u(0)$ and think that you can just put $l=0$ for simplicity. The first inequalities are easy applications of the triangle inequality and the fact that $P$ does not increase distances. Now consider the last inequality of the chain just written. It seems to me that he is applying the triangle inequality to the term with sign ""-"" and then says that one can estimate the distance $\rho(\sigma_{u_0}(l+r-\delta),\sigma_{u_0}(l+r))$ as $O(\delta^2)$ . I wonder why. Shouldn't it be $O(\delta)$ ? Moreover, he says that he uses in that last in equality the fact that I put under citation. Where does he use it? Does it allow to gain the $O(\delta)$ ? I don't think so, since in the case of $\mathbb R^2$ that distance is precisely $\delta$ . Another hypothesis was the following: he is not using the distances, but their squares. This would provide the $\delta^2$ , but what about the triangle inequality? That should not be true anymore... So I am surely missing something important. Can someone help me? Thank you in advance. EDIT: Question solved. One can use flatness to use Pitagoras's theorem and then that $\sqrt{1+a^2}= 1+a^2/2+O(a^2)$ .","Referring to G. Perelman, Proof of the soul conjecture by Cheeger and Gromoll . Given a distance-nonincreasing retraction from an open complete manifold of nonnegative curvature onto its soul , one wants to prove that for every and . Suppose this is true up to , and consider the function where is the unitary normal bundle to . It seems to me that the only way to interpret the notation is ""the Riemannian distance between the two points"". But later in the proof, Perelman does the following: he has a geodesic , a parallel normal field along , and two ""vertical"" geodesics related to a variation around , namely and , varying. He then proves that the two-dimensional strip between these two and is flat and totally geodesic, and that all the   ""horizontal"" geodesics are minimizing of constant length . Then he claims that, for small , Recall that and think that you can just put for simplicity. The first inequalities are easy applications of the triangle inequality and the fact that does not increase distances. Now consider the last inequality of the chain just written. It seems to me that he is applying the triangle inequality to the term with sign ""-"" and then says that one can estimate the distance as . I wonder why. Shouldn't it be ? Moreover, he says that he uses in that last in equality the fact that I put under citation. Where does he use it? Does it allow to gain the ? I don't think so, since in the case of that distance is precisely . Another hypothesis was the following: he is not using the distances, but their squares. This would provide the , but what about the triangle inequality? That should not be true anymore... So I am surely missing something important. Can someone help me? Thank you in advance. EDIT: Question solved. One can use flatness to use Pitagoras's theorem and then that .","P S P(\exp_xt\nu)=x x\in S t\geq 0 t=l f(r)=\max\{|xP(\exp_x(l+r)\nu)|\mid x\in S, \nu\in SN_x(S)\} SN(S) S |xP(\exp_x(l+r)\nu)| \gamma(u)\in S \nu \gamma \gamma \sigma_{u_0}(t)=\exp_{\gamma(u_0)}t\nu \sigma_{u_1}(t)=\exp_{\gamma(u_0)}t\nu t \sigma_{u_0} \sigma_{u_1} \gamma_t(u)=\exp_{\gamma(u)}t\nu,
> u\in[u_0,u_1] l(\gamma|_{[u_0,u_1]}) \delta f(r-\delta)\geq |\gamma(u_1)P(\sigma_{u_1}(l+r-\delta))|\geq|P(\sigma_{u_0}(l+r)\gamma(u_1)|-|P(\sigma_{u_0}(l+r))P(\sigma_{u_1}(l+r-\delta))|\geq|P(\sigma_{u_0}(l+r))\gamma(u_1)|-|\sigma_{u_1}(l+r-\delta)\sigma_{u_0}(l+r)|\geq|P(\sigma_{u_0}(l+r)\gamma(x_1)|-|\sigma_{u_0}(l+r)\sigma_{u_1}(l+r)|-O(\delta^2). \gamma(u)=\sigma_u(0) l=0 P \rho(\sigma_{u_0}(l+r-\delta),\sigma_{u_0}(l+r)) O(\delta^2) O(\delta) O(\delta) \mathbb R^2 \delta \delta^2 \sqrt{1+a^2}= 1+a^2/2+O(a^2)","['differential-geometry', 'metric-spaces', 'riemannian-geometry', 'curvature']"
28,Why do metrics act on tangent vectors?,Why do metrics act on tangent vectors?,,"Consider a manifold $M$ and a curve $\gamma : \mathbb{R} \supseteq I \rightarrow M$. The length of this curve is defined as $$ L = \int \sqrt{g(X,X)}_{\gamma(t)} dt $$ where $g$ is the metric tensor, $X$ is the tangent vector to the curve and $t$ is the parameter of the curve. I do not understand why we require a tangent space in order to calculate lengths of curves. I understand a metric tensor takes in two tangent vectors and spits out a number which allows us to calculate lengths and angles on manifolds, but why exactly do we require a metric defined in this way? Why is there no notion of length that is independent of tangent spaces and is in terms of the manifold alone?","Consider a manifold $M$ and a curve $\gamma : \mathbb{R} \supseteq I \rightarrow M$. The length of this curve is defined as $$ L = \int \sqrt{g(X,X)}_{\gamma(t)} dt $$ where $g$ is the metric tensor, $X$ is the tangent vector to the curve and $t$ is the parameter of the curve. I do not understand why we require a tangent space in order to calculate lengths of curves. I understand a metric tensor takes in two tangent vectors and spits out a number which allows us to calculate lengths and angles on manifolds, but why exactly do we require a metric defined in this way? Why is there no notion of length that is independent of tangent spaces and is in terms of the manifold alone?",,['differential-geometry']
29,"$\mathbb{HP}^2$, exotic 7-spheres, and Bott manifolds",", exotic 7-spheres, and Bott manifolds",\mathbb{HP}^2,"I am looking for some explanation how $\mathbb{HP}^2$ , exotic 7-spheres, and Bott manifolds are related? And how the construction of a Bott manifold is related to $\mathbb{HP}^2$ and exotic 7-spheres? p.s. The description I found is Kervaire-Milnors work on homotopy spheres and the description by Johannes Ebert . But this description is too dense and too quick to me, could you provide more details in a slow manner? Johannes Ebert said : ""A textbook reference is Kosinski: ''Differential manifolds''. In section IX.8 (Theorem 8.7), you find the statement that there exists an 8-dimensional manifold which is almost parallelizable (i.e. parallelizable away from a point) whose signature is $8 \cdot 28$ . Because this $M$ is almost parallelizable, $p_1 (TM)=0$ , and from the formulae for the $\hat A$ -class and the $L$ -class, you get that $\hat{A} =1$ . Typically, one wants that the signature is zero, and this you can achieve by connected sum with $8 \cdot 28$ copies of $\overline{HP^2}$ . How is $M$ constructed? You take the $E_8$ -plumbing manifold $V$ . It is a $3$ -connected $8$ -manifold which is parallelizable, which has signature $8$ and whose boundary is a homotopy sphere. In fact, $\partial V$ generates the group $\Theta_7 \cong Z/28$ of exotic $7$ -spheres. Now you form the boundary connected sum of $28$ copies of $V$ ; the boundary of the resulting manifold is the standard $S^7$ , and you glue in a copy of $D^8$ to obtain $M$ .""","I am looking for some explanation how , exotic 7-spheres, and Bott manifolds are related? And how the construction of a Bott manifold is related to and exotic 7-spheres? p.s. The description I found is Kervaire-Milnors work on homotopy spheres and the description by Johannes Ebert . But this description is too dense and too quick to me, could you provide more details in a slow manner? Johannes Ebert said : ""A textbook reference is Kosinski: ''Differential manifolds''. In section IX.8 (Theorem 8.7), you find the statement that there exists an 8-dimensional manifold which is almost parallelizable (i.e. parallelizable away from a point) whose signature is . Because this is almost parallelizable, , and from the formulae for the -class and the -class, you get that . Typically, one wants that the signature is zero, and this you can achieve by connected sum with copies of . How is constructed? You take the -plumbing manifold . It is a -connected -manifold which is parallelizable, which has signature and whose boundary is a homotopy sphere. In fact, generates the group of exotic -spheres. Now you form the boundary connected sum of copies of ; the boundary of the resulting manifold is the standard , and you glue in a copy of to obtain .""",\mathbb{HP}^2 \mathbb{HP}^2 8 \cdot 28 M p_1 (TM)=0 \hat A L \hat{A} =1 8 \cdot 28 \overline{HP^2} M E_8 V 3 8 8 \partial V \Theta_7 \cong Z/28 7 28 V S^7 D^8 M,"['differential-geometry', 'manifolds', 'differential-topology', 'geometric-topology', 'surgery-theory']"
30,In what $precise$ sense is Minkowski space asymptotically flat?,In what  sense is Minkowski space asymptotically flat?,precise,"I've brought this question over from the physics stack exchange, where it didn't generate interest. We say a manifold $(M,g)$ is conformally compact if it is the interior of some $(\overline M, \overline g)$, such that $$g = r^{-2}\overline g|_M,\quad \mathcal Z(r) = \partial M,\quad \text{and}\quad \mathrm{d}r_p \neq 0\ \text{for any}\ p\in \partial M.$$ Moreover, we say a conformally compact manifold is asymptotically flat if $|\mathrm{d} r|^2_{\overline g}\equiv 0$ on the boundary. (i.e. the first derivative of the defining function is null on the boundary.) It is ""well known"" that Minkowski space is an asymptotically flat manifold - Penrose's famous compactification supposedly shows this. However, in his compactification, there are two points on the boundary for which $\mathrm{d}r_p = 0$: namely spacelike and timelike infinity. I've made my own coordinate free compactifications of Minkowski space, but they also have some singularities at conformal infinity. How is this formalised? When people say ""conformally compact"" in literature, do they just mean ""there is a dense subset of the boundary satisfying the above conditions""?","I've brought this question over from the physics stack exchange, where it didn't generate interest. We say a manifold $(M,g)$ is conformally compact if it is the interior of some $(\overline M, \overline g)$, such that $$g = r^{-2}\overline g|_M,\quad \mathcal Z(r) = \partial M,\quad \text{and}\quad \mathrm{d}r_p \neq 0\ \text{for any}\ p\in \partial M.$$ Moreover, we say a conformally compact manifold is asymptotically flat if $|\mathrm{d} r|^2_{\overline g}\equiv 0$ on the boundary. (i.e. the first derivative of the defining function is null on the boundary.) It is ""well known"" that Minkowski space is an asymptotically flat manifold - Penrose's famous compactification supposedly shows this. However, in his compactification, there are two points on the boundary for which $\mathrm{d}r_p = 0$: namely spacelike and timelike infinity. I've made my own coordinate free compactifications of Minkowski space, but they also have some singularities at conformal infinity. How is this formalised? When people say ""conformally compact"" in literature, do they just mean ""there is a dense subset of the boundary satisfying the above conditions""?",,"['differential-geometry', 'riemannian-geometry', 'mathematical-physics', 'conformal-geometry', 'general-relativity']"
31,Does this manifold have a name?,Does this manifold have a name?,,"EDIT: In an attempt to not let the bounty go to waste, I will consider responses that give reasonable guesses of what the involved surfaces are, WITHOUT requiring parametrizations. While using Mathematica to alter manifolds and numerically verify the Gauss-Bonnet Theorem, I generated the figure whose pictures I've attached in this post (multiple perspectives of the same shape are provided). Does anyone know whether it is a known manifold with a name? I generated this surface by using $h_{x}, h_{y}, h_{z}$ below, setting $t_{2}=t=1, M=0, \phi=\pi/2$ on the interval $0 \leq k_{x} \leq 2\pi$ and $0 \leq k_{x} \leq 2\pi$ : After much reading, my biggest guess is that this is a pseudosphere glued to a duplin cyclide - however, I am having trouble knowing this for sure. I do not even know how I would go about proving this. Note that I plotted some of the normal vectors on its surface and it appears that normal vectors in the pseudosphere-like region point INTO the surface, whereas other normal vectors point out. Perhaps this could be useful information. Since this is a question with a bounty on it now, I should know what this 2D surface is with certainty. For your convenience, I have a link to MATLAB and Mathematica files that have manipulable figures here: https://1drv.ms/f/s!Ak6chxAgMs9Pg_tYixvFy6MfO9531A Here are some animations that show sections of the surface (I change parameters in a fixed frame so that you get certain perspectives inside the surface as it leaves the fixed frame). Here are some static images (essentially screenshots from the models in the link above):","EDIT: In an attempt to not let the bounty go to waste, I will consider responses that give reasonable guesses of what the involved surfaces are, WITHOUT requiring parametrizations. While using Mathematica to alter manifolds and numerically verify the Gauss-Bonnet Theorem, I generated the figure whose pictures I've attached in this post (multiple perspectives of the same shape are provided). Does anyone know whether it is a known manifold with a name? I generated this surface by using below, setting on the interval and : After much reading, my biggest guess is that this is a pseudosphere glued to a duplin cyclide - however, I am having trouble knowing this for sure. I do not even know how I would go about proving this. Note that I plotted some of the normal vectors on its surface and it appears that normal vectors in the pseudosphere-like region point INTO the surface, whereas other normal vectors point out. Perhaps this could be useful information. Since this is a question with a bounty on it now, I should know what this 2D surface is with certainty. For your convenience, I have a link to MATLAB and Mathematica files that have manipulable figures here: https://1drv.ms/f/s!Ak6chxAgMs9Pg_tYixvFy6MfO9531A Here are some animations that show sections of the surface (I change parameters in a fixed frame so that you get certain perspectives inside the surface as it leaves the fixed frame). Here are some static images (essentially screenshots from the models in the link above):","h_{x}, h_{y}, h_{z} t_{2}=t=1, M=0, \phi=\pi/2 0 \leq k_{x} \leq 2\pi 0 \leq k_{x} \leq 2\pi","['differential-geometry', 'terminology', 'manifolds', 'surfaces', 'non-orientable-surfaces']"
32,Differentiating the Riemannian exponential map with respect to the base point,Differentiating the Riemannian exponential map with respect to the base point,,"If $(M,g)$ is a Riemannian manifold, $\alpha \in \Omega^1 M$ a smooth $1$-form, $x \in M$ and $y$ in a normal coordinates neighbourhood $U$ of $x$, how should I proceed in differentiating $y \mapsto \alpha_y (\exp_y ^{-1} (x))$ with respect to $y$? (I am interested in the gradient and the Laplacian of this function.) If differentiating were with respect to $x$, I would know what to do (perform the computation in normal coordinates around $x$), but how to deal with the argument being the base point of $\exp$, so that for each $y$ there exists a different set of normal coordinates?","If $(M,g)$ is a Riemannian manifold, $\alpha \in \Omega^1 M$ a smooth $1$-form, $x \in M$ and $y$ in a normal coordinates neighbourhood $U$ of $x$, how should I proceed in differentiating $y \mapsto \alpha_y (\exp_y ^{-1} (x))$ with respect to $y$? (I am interested in the gradient and the Laplacian of this function.) If differentiating were with respect to $x$, I would know what to do (perform the computation in normal coordinates around $x$), but how to deal with the argument being the base point of $\exp$, so that for each $y$ there exists a different set of normal coordinates?",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'coordinate-systems', 'geodesic']"
33,Where does the symplectic structure on coadjoint orbits of Lie groups on their Lie algebras come from?,Where does the symplectic structure on coadjoint orbits of Lie groups on their Lie algebras come from?,,"I have read in several places that if $\Omega$ is the coadjoint orbit of $\zeta \in \mathfrak{g}^*$, the map from $G \to \Omega$ that sends $g \mapsto Ad^*(g)(\zeta)$ gives a surjection, and taking the differential of this map at the identity gives a surjection from $T_eG = \mathfrak{g} \to T_{\zeta}\Omega$, and then the $2$-form is defined by identifying elements of the tangent space with elements of $\mathfrak{g}$ and taking the Lie bracket. But a priori this only seems to define the $2$-form at $\zeta$, ie: $\omega(\zeta) (\hat{X}, \hat{Y})  = \zeta([X,Y])$ where $\hat{X},\hat{Y} \in T_\zeta \Omega$. But what about $\omega(\eta)$ for $\eta \in \Omega$ but $\omega \neq \zeta$? The surjection is from $\mathfrak{g} \to T_\zeta \Omega$, but not from $\mathfrak{g} \to T_{\eta}\Omega$.","I have read in several places that if $\Omega$ is the coadjoint orbit of $\zeta \in \mathfrak{g}^*$, the map from $G \to \Omega$ that sends $g \mapsto Ad^*(g)(\zeta)$ gives a surjection, and taking the differential of this map at the identity gives a surjection from $T_eG = \mathfrak{g} \to T_{\zeta}\Omega$, and then the $2$-form is defined by identifying elements of the tangent space with elements of $\mathfrak{g}$ and taking the Lie bracket. But a priori this only seems to define the $2$-form at $\zeta$, ie: $\omega(\zeta) (\hat{X}, \hat{Y})  = \zeta([X,Y])$ where $\hat{X},\hat{Y} \in T_\zeta \Omega$. But what about $\omega(\eta)$ for $\eta \in \Omega$ but $\omega \neq \zeta$? The surjection is from $\mathfrak{g} \to T_\zeta \Omega$, but not from $\mathfrak{g} \to T_{\eta}\Omega$.",,"['differential-geometry', 'lie-groups']"
34,Correspondence between flat connections and fundamental group representations,Correspondence between flat connections and fundamental group representations,,"Let $M$ be a manifold. Two stackexchange posts state that there is a correspondence $$ \{ (P,A): P \text{ a $G$-bundle}, A \text{ flat connection} \} \leftrightarrow \{ \text{morphisms } f:\pi_1(M) \rightarrow G \}, $$ namely Recovering a principal connection from its monodromy and Are vector bundles given by their monodromy? . I believe that the correspondence is given by $$ (P,A) \mapsto f, $$ where $f([\gamma])=g$, where $g$ denotes the element such that $\gamma^*(0)g=\gamma^*(1)$. Here $\gamma^*$ denotes a horizontal lift of $\gamma$. This is well defined by flatness of $A$. If $\pi_1(M)$ is a free group, I understand why the correspondence is 1-to-1. That is because to define a $G$-bundle on $M$ I need to specify precisely an element in $G$ for each loop in $\pi_1(M)$, that is the idea mentioned in the accepted answer of the question https://mathoverflow.net/questions/4138/why-are-local-systems-on-a-complex-analytic-space-equivalent-to-vector-bundles-w?noredirect=1&lq=1 . Why is this correspondence 1-to-1 in general?   Can you point me to a reference which contains the proof?","Let $M$ be a manifold. Two stackexchange posts state that there is a correspondence $$ \{ (P,A): P \text{ a $G$-bundle}, A \text{ flat connection} \} \leftrightarrow \{ \text{morphisms } f:\pi_1(M) \rightarrow G \}, $$ namely Recovering a principal connection from its monodromy and Are vector bundles given by their monodromy? . I believe that the correspondence is given by $$ (P,A) \mapsto f, $$ where $f([\gamma])=g$, where $g$ denotes the element such that $\gamma^*(0)g=\gamma^*(1)$. Here $\gamma^*$ denotes a horizontal lift of $\gamma$. This is well defined by flatness of $A$. If $\pi_1(M)$ is a free group, I understand why the correspondence is 1-to-1. That is because to define a $G$-bundle on $M$ I need to specify precisely an element in $G$ for each loop in $\pi_1(M)$, that is the idea mentioned in the accepted answer of the question https://mathoverflow.net/questions/4138/why-are-local-systems-on-a-complex-analytic-space-equivalent-to-vector-bundles-w?noredirect=1&lq=1 . Why is this correspondence 1-to-1 in general?   Can you point me to a reference which contains the proof?",,"['differential-geometry', 'fundamental-groups', 'principal-bundles', 'holonomy']"
35,When is a surjective polynomial map proper?,When is a surjective polynomial map proper?,,"Suppose $F: \mathbb{C}^n \to \mathbb{C}^n$ is a surjective function such that $F$ is defined by a polynomial in each coordinate, i.e.  $$ F = (f_1,\ldots,f_n) \quad f_i \in \mathbb{C}[x_1,\ldots,x_n] \: \forall i \leq n $$ I know that for $n = 1$, $F$ is simply a polynomial function in one variable, and therefore the fact that $F$ is surjective implies $F$ is proper. Furthermore I know that for $n > 1$, each $f_i$ is not proper as a map $f_i: \mathbb{C}^n \to \mathbb C$. My question is, under what circumstances is the map $F$ a proper map in general? Is this dependent or independent of whether $F$ is a submersion?","Suppose $F: \mathbb{C}^n \to \mathbb{C}^n$ is a surjective function such that $F$ is defined by a polynomial in each coordinate, i.e.  $$ F = (f_1,\ldots,f_n) \quad f_i \in \mathbb{C}[x_1,\ldots,x_n] \: \forall i \leq n $$ I know that for $n = 1$, $F$ is simply a polynomial function in one variable, and therefore the fact that $F$ is surjective implies $F$ is proper. Furthermore I know that for $n > 1$, each $f_i$ is not proper as a map $f_i: \mathbb{C}^n \to \mathbb C$. My question is, under what circumstances is the map $F$ a proper map in general? Is this dependent or independent of whether $F$ is a submersion?",,"['differential-geometry', 'polynomials']"
36,Find the Ricci tensor from given product metric quickly,Find the Ricci tensor from given product metric quickly,,"I am having trouble calculating the Ricci tensor. Suppose the product $I\times S^n$ has metric $$g=dt^2+f^2(t)g_{S^{n}}$$ where $g_{S^{n}}$ is the standard metric on $S^{n}$, what is the Ricci tensor of this metric? I have tried to do it for $n=2$ by writing the metric as $$g=\begin{pmatrix}1&0&0\\0&f^2&0\\0&0&f^2\sin^2\theta\end{pmatrix}$$ In a standard way, I calculated the Christoffel symbols and using the definition of Riemann tensor, of course, It is not wise to do similar thing in higher dimension. I am thinking that since the hypershpere is a manifold of constant sectional curvature 1 and the Ricci tensor is $$Ric=(n-1)g_{S^{n}}$$ Can we write the Ric on $I\times S^n$ from the Ric on $S^n$ and the product factor $f(t)$ quickly? But I don't know how to proceed. Any hint will be appreciated.","I am having trouble calculating the Ricci tensor. Suppose the product $I\times S^n$ has metric $$g=dt^2+f^2(t)g_{S^{n}}$$ where $g_{S^{n}}$ is the standard metric on $S^{n}$, what is the Ricci tensor of this metric? I have tried to do it for $n=2$ by writing the metric as $$g=\begin{pmatrix}1&0&0\\0&f^2&0\\0&0&f^2\sin^2\theta\end{pmatrix}$$ In a standard way, I calculated the Christoffel symbols and using the definition of Riemann tensor, of course, It is not wise to do similar thing in higher dimension. I am thinking that since the hypershpere is a manifold of constant sectional curvature 1 and the Ricci tensor is $$Ric=(n-1)g_{S^{n}}$$ Can we write the Ric on $I\times S^n$ from the Ric on $S^n$ and the product factor $f(t)$ quickly? But I don't know how to proceed. Any hint will be appreciated.",,"['differential-geometry', 'riemannian-geometry']"
37,Composition of vector bundles is only a fibre bundle,Composition of vector bundles is only a fibre bundle,,"On page 101 of Lang's ""Differential and Riemannian Manifolds"", he introduces fibre-bundles because composing vector bundles does not give vector bundles. To be more precise, given a vector bundle $p : E \rightarrow X$ and the tangent bundle $p: TE \rightarrow E$, he states that the composite $f =  p \circ \pi$ is ""only a fibre bundle over $X$, a fact which is obvious by picking trivializations in charts"". Looking at the relevant trivializations, this is not clear to me at all. Why is $f$ not a vector bundle in general?","On page 101 of Lang's ""Differential and Riemannian Manifolds"", he introduces fibre-bundles because composing vector bundles does not give vector bundles. To be more precise, given a vector bundle $p : E \rightarrow X$ and the tangent bundle $p: TE \rightarrow E$, he states that the composite $f =  p \circ \pi$ is ""only a fibre bundle over $X$, a fact which is obvious by picking trivializations in charts"". Looking at the relevant trivializations, this is not clear to me at all. Why is $f$ not a vector bundle in general?",,"['differential-geometry', 'vector-bundles']"
38,Geometric intuition behind the proof of Frobenius' Theorem,Geometric intuition behind the proof of Frobenius' Theorem,,"II am studying Frobenius' Theorem in Agricola & Friedrich's Global Analysis or, to be more precise, an auxiliary theorem that, roughly speaking, states that if $m-k$ $1$ -forms exist on a $m$ -dimensional manifold, and their derivatives can be written as: $$dw_i=\sum_{j=1}^{m-k}\theta_{ij}\wedge w_j$$ then the forms themselves can be expressed (locally) as: $$w_i=\sum_{j=1}^{m-k}h_{ij}\; df_j$$ for some functions $h_{ij},f_j$ . The proof proceeds in several steps that can be summarized by: Consider some coordinate system $(y,z)\in\mathbb{R}^k\times\mathbb{R}^{m-k}$ such that the forms take the special structure: $$w_i=dz^i-\sum_{j=1}^k A_{ij}(y,z)\,dy^j$$ For each fixed $(u,v)\in\mathbb{R}^k\times\mathbb{R}^{m-k}$ , build the system of ODEs: $$\left(\gamma^i\right)'=\sum_{j=1}^k A_{ij}(t\,u,\gamma)\,u^j\quad ;\qquad\qquad \gamma^i(0)=v^i$$ If $F^i(t,u,v)=\gamma^i(t)$ is the solution of such system with parameters $u$ and initial values $v$ , consider the change of coordinates: $$\begin{aligned} u^i&=y^i\\ F^j(1,u,v)&=z^j \end{aligned}$$ Prove that when $w_i$ is expressed in the dual basis $\{du^1,\dots,du^k,dv^1,\dots,dv^{m-k}\}$ , the coefficients of the $du^i$ terms vanish, so that the functions $v^j$ are those required by the statement. Now, all the steps are more or less involved but, in the end, mechanical. But I am intrigued by the geometric intuition of the system of ODEs that appears at step 2. Does it mean that solution trajectories of the ODE remain on the integral manifold? It is not easy to see because, strictly speaking, the ODE is time-varying thus the solutions lie on a $m+1$ -dimensional space that includes time as an additional variable. So the title of the question could be rephrased as: how could Frobenius (and the other people in the history of the theorem) even think that the statement was true or figure out the proof procedure? NOTE: I have tried to keep the post both brief and self-contained, but please ask for more detail if needed.","II am studying Frobenius' Theorem in Agricola & Friedrich's Global Analysis or, to be more precise, an auxiliary theorem that, roughly speaking, states that if -forms exist on a -dimensional manifold, and their derivatives can be written as: then the forms themselves can be expressed (locally) as: for some functions . The proof proceeds in several steps that can be summarized by: Consider some coordinate system such that the forms take the special structure: For each fixed , build the system of ODEs: If is the solution of such system with parameters and initial values , consider the change of coordinates: Prove that when is expressed in the dual basis , the coefficients of the terms vanish, so that the functions are those required by the statement. Now, all the steps are more or less involved but, in the end, mechanical. But I am intrigued by the geometric intuition of the system of ODEs that appears at step 2. Does it mean that solution trajectories of the ODE remain on the integral manifold? It is not easy to see because, strictly speaking, the ODE is time-varying thus the solutions lie on a -dimensional space that includes time as an additional variable. So the title of the question could be rephrased as: how could Frobenius (and the other people in the history of the theorem) even think that the statement was true or figure out the proof procedure? NOTE: I have tried to keep the post both brief and self-contained, but please ask for more detail if needed.","m-k 1 m dw_i=\sum_{j=1}^{m-k}\theta_{ij}\wedge w_j w_i=\sum_{j=1}^{m-k}h_{ij}\; df_j h_{ij},f_j (y,z)\in\mathbb{R}^k\times\mathbb{R}^{m-k} w_i=dz^i-\sum_{j=1}^k A_{ij}(y,z)\,dy^j (u,v)\in\mathbb{R}^k\times\mathbb{R}^{m-k} \left(\gamma^i\right)'=\sum_{j=1}^k A_{ij}(t\,u,\gamma)\,u^j\quad ;\qquad\qquad \gamma^i(0)=v^i F^i(t,u,v)=\gamma^i(t) u v \begin{aligned}
u^i&=y^i\\
F^j(1,u,v)&=z^j
\end{aligned} w_i \{du^1,\dots,du^k,dv^1,\dots,dv^{m-k}\} du^i v^j m+1","['differential-geometry', 'differential-forms']"
39,Basic spectral geometry question for surfaces in $\mathbb{R}^3$,Basic spectral geometry question for surfaces in,\mathbb{R}^3,"Assume that $S \subset \mathbb{R}^3$ is a smooth, compact, properly embedded surface with boundary $\partial S = \gamma_1 \cup \gamma_2$, where $\gamma_i$ are smooth closed curves. Moreover assume that $S$ is diffeomorphic to an annulus. If I know the value of the first Dirichlet eigenvalue of $S$, what kind of geometric information do I get? Can I have an estimate on the area, for example? Any help would be very much appreciated!","Assume that $S \subset \mathbb{R}^3$ is a smooth, compact, properly embedded surface with boundary $\partial S = \gamma_1 \cup \gamma_2$, where $\gamma_i$ are smooth closed curves. Moreover assume that $S$ is diffeomorphic to an annulus. If I know the value of the first Dirichlet eigenvalue of $S$, what kind of geometric information do I get? Can I have an estimate on the area, for example? Any help would be very much appreciated!",,"['differential-geometry', 'surfaces', 'spectral-theory']"
40,Direct proof that the wedge product preserves integral cohomology classes?,Direct proof that the wedge product preserves integral cohomology classes?,,"Let $H^k(M,\mathbb R)$ be the De Rham cohomology of a manifold $M$. There is a canonical map $H^k(M;\mathbb Z) \to H^k(M;\mathbb R)$ from the integral cohomology to the cohomology with coefficients in $\mathbb R$, which is isomorphic to the De Rham cohomology. As a previous question already revealed, the images of this map are precisely the classes of differential $k$-forms $[\omega]$ that yield integers when integrated over a $k$-cycle $\sigma$, $$ \int_{\sigma} \omega \in \mathbb{Z}  \quad\text{ whenever } d\sigma = 0$$ Let us call them ""integral forms"". Motivated by the cup product on cohomology, my question/request is the following: Give a direct proof that the wedge product $[\omega\wedge\eta]\in H^{k+l}(M,\mathbb R)$ of two integral forms $\omega\in \Omega^k(M)$ and $\eta\in \Omega^l(M)$ is again an integral form. This should be true because the cup product is mapped to the wedge product, but the point of the exercise is to prove this statement directly, without constructing the singular cohomology $H^k(M,\mathbb Z)$ or homology first. Maybe I also have to make sure that the condition of being an integral form is something that can be ""checked effectively"" without singular homology; this might be subject to a new question.","Let $H^k(M,\mathbb R)$ be the De Rham cohomology of a manifold $M$. There is a canonical map $H^k(M;\mathbb Z) \to H^k(M;\mathbb R)$ from the integral cohomology to the cohomology with coefficients in $\mathbb R$, which is isomorphic to the De Rham cohomology. As a previous question already revealed, the images of this map are precisely the classes of differential $k$-forms $[\omega]$ that yield integers when integrated over a $k$-cycle $\sigma$, $$ \int_{\sigma} \omega \in \mathbb{Z}  \quad\text{ whenever } d\sigma = 0$$ Let us call them ""integral forms"". Motivated by the cup product on cohomology, my question/request is the following: Give a direct proof that the wedge product $[\omega\wedge\eta]\in H^{k+l}(M,\mathbb R)$ of two integral forms $\omega\in \Omega^k(M)$ and $\eta\in \Omega^l(M)$ is again an integral form. This should be true because the cup product is mapped to the wedge product, but the point of the exercise is to prove this statement directly, without constructing the singular cohomology $H^k(M,\mathbb Z)$ or homology first. Maybe I also have to make sure that the condition of being an integral form is something that can be ""checked effectively"" without singular homology; this might be subject to a new question.",,"['differential-geometry', 'algebraic-topology', 'homology-cohomology', 'differential-forms']"
41,"Let $X_M^c$ be the space of vector fields on a manifold $M$ with compact support. Prove that $X_M^c=[X_M^c,X_M^c]$",Let  be the space of vector fields on a manifold  with compact support. Prove that,"X_M^c M X_M^c=[X_M^c,X_M^c]","Let $X_M^c$ be the space of vector fields on a manifold $M$ with compact support. Prove that $X_M^c=[X_M^c,X_M^c]$. Proving that $[X_M^c,X_M^c]\subset X_M^c$ is relatively simple. However, I have not been able to prove $X_M^c\subset [X_M^c,X_M^c]$. Any clues?","Let $X_M^c$ be the space of vector fields on a manifold $M$ with compact support. Prove that $X_M^c=[X_M^c,X_M^c]$. Proving that $[X_M^c,X_M^c]\subset X_M^c$ is relatively simple. However, I have not been able to prove $X_M^c\subset [X_M^c,X_M^c]$. Any clues?",,[]
42,Graph of symplectomorphism is symplectomorphic to the image of a closed $1$-form.,Graph of symplectomorphism is symplectomorphic to the image of a closed -form.,1,"Let $(M,\omega)$ be a symplectic manifold, $(T^*M, \omega_{\rm can})$ its cotangent bundle, and consider the twisted product $M\times \overline{M} = (M\times M, \omega \oplus (-\omega))$. Consider a symplectomorphism $\varphi \in {\rm Sp}(M,\omega)$ which is $C^1$-close to the identity ${\rm Id}_M: M \to M$. We know that: the diagonal $\Delta \subseteq M\times \overline{M}$ is Lagrangian; the graph $\Gamma_\varphi\subseteq M \times \overline{M}$ is Lagrangian; $M \cong 0^{T^*M} \subseteq T^*M$ is Lagrangian. Ok. Assume that $U$ is a neighborhood of $\Delta$ in $M\times M$ which contains $\Gamma_\varphi$, $U_0$ is a neighborhood of $M \cong \Delta$ in $T^*M$, and that $F: U \to U_0$ is a symplectomorphism such that $F(x,x) = x \cong 0_x$, for all $x \in M$. Let $L = F(\Gamma_\varphi)$. I want to check that there is a closed form $\sigma \in \Omega^1(M)$ $C^1$-close to the zero section such that $L = {\rm Im}\;\sigma$. Since $F$ is a symplectomorphism, we have that $L$ is also Lagrangian, so once we find $\sigma$, it will be closed (I already have the result ""${\rm Im}\,\sigma$ is Lagrangian iff ${\rm d}\sigma = 0$""). So I'd guess that it suffices to show that $L$ intersect each cotangent space to $M$ exactly once. But it is not clear to me that if $x \in M$, then $F(x,\varphi(x)) \in T_x^*M$. The $C^1$-close to the zero section I guess it is automatic, in some sense, since $L\subseteq U_0$ (it was never made clear what exactly is meant by ""$C^1$-close"", although one can guess). I'd like some help filling up these details, and to be sure nothing I said so far is wrong. Thanks!","Let $(M,\omega)$ be a symplectic manifold, $(T^*M, \omega_{\rm can})$ its cotangent bundle, and consider the twisted product $M\times \overline{M} = (M\times M, \omega \oplus (-\omega))$. Consider a symplectomorphism $\varphi \in {\rm Sp}(M,\omega)$ which is $C^1$-close to the identity ${\rm Id}_M: M \to M$. We know that: the diagonal $\Delta \subseteq M\times \overline{M}$ is Lagrangian; the graph $\Gamma_\varphi\subseteq M \times \overline{M}$ is Lagrangian; $M \cong 0^{T^*M} \subseteq T^*M$ is Lagrangian. Ok. Assume that $U$ is a neighborhood of $\Delta$ in $M\times M$ which contains $\Gamma_\varphi$, $U_0$ is a neighborhood of $M \cong \Delta$ in $T^*M$, and that $F: U \to U_0$ is a symplectomorphism such that $F(x,x) = x \cong 0_x$, for all $x \in M$. Let $L = F(\Gamma_\varphi)$. I want to check that there is a closed form $\sigma \in \Omega^1(M)$ $C^1$-close to the zero section such that $L = {\rm Im}\;\sigma$. Since $F$ is a symplectomorphism, we have that $L$ is also Lagrangian, so once we find $\sigma$, it will be closed (I already have the result ""${\rm Im}\,\sigma$ is Lagrangian iff ${\rm d}\sigma = 0$""). So I'd guess that it suffices to show that $L$ intersect each cotangent space to $M$ exactly once. But it is not clear to me that if $x \in M$, then $F(x,\varphi(x)) \in T_x^*M$. The $C^1$-close to the zero section I guess it is automatic, in some sense, since $L\subseteq U_0$ (it was never made clear what exactly is meant by ""$C^1$-close"", although one can guess). I'd like some help filling up these details, and to be sure nothing I said so far is wrong. Thanks!",,"['differential-geometry', 'smooth-manifolds', 'differential-forms', 'symplectic-geometry']"
43,Recovering a principal connection from its monodromy,Recovering a principal connection from its monodromy,,"Given a principal bundle $P \to M$ with structure group $G$ ($M$ and $G$ are connected), it is well known that one can recover the data of $P$ and a flat connection $\Gamma \in \Omega^{1}(P, \mathfrak{g})$ up to gauge transformation from the data of the monodromy representation $\Phi: \pi_{1}(M) \to G$. My question is whether one can generalize this to non-flat connections in the following specific way. Suppose again that $M$ is a connected manifold, and $G$ a connected Lie group, $H \subseteq G$ a closed connected subgroup and $H' \subseteq G$ a Lie subgroup whose identity component is $H$ and in which $H$ is normal. Let $\Phi: \pi_{1}(M) \to H'/H$ be a representation. Can one construct a principal bundle $P \to M$ with structure group $G$ and a connection $\Gamma \in \Omega^{1}(P, \mathfrak{g})$ such that the holonomy group, restricted holonomy group and monodromy representation are respectively $H'$, $H$ and $\Phi$, up to conjugation? If the answer to the above is yes, is the pair $(P, \Gamma)$ uniquely determined up to gauge transformations, in the sense that if $(P', \Gamma')$ is another such pair then $P$ and $P'$ can be identified as principal bundles and $\Gamma'$ and $\Gamma$ differ by a gauge transformation? If it simplifies the question, we may assume that $M$ is a compact, orientable surface and $G$ is compact, connected and simply connected, so that the only principal bundle is the trivial one $M \times G \to M$.","Given a principal bundle $P \to M$ with structure group $G$ ($M$ and $G$ are connected), it is well known that one can recover the data of $P$ and a flat connection $\Gamma \in \Omega^{1}(P, \mathfrak{g})$ up to gauge transformation from the data of the monodromy representation $\Phi: \pi_{1}(M) \to G$. My question is whether one can generalize this to non-flat connections in the following specific way. Suppose again that $M$ is a connected manifold, and $G$ a connected Lie group, $H \subseteq G$ a closed connected subgroup and $H' \subseteq G$ a Lie subgroup whose identity component is $H$ and in which $H$ is normal. Let $\Phi: \pi_{1}(M) \to H'/H$ be a representation. Can one construct a principal bundle $P \to M$ with structure group $G$ and a connection $\Gamma \in \Omega^{1}(P, \mathfrak{g})$ such that the holonomy group, restricted holonomy group and monodromy representation are respectively $H'$, $H$ and $\Phi$, up to conjugation? If the answer to the above is yes, is the pair $(P, \Gamma)$ uniquely determined up to gauge transformations, in the sense that if $(P', \Gamma')$ is another such pair then $P$ and $P'$ can be identified as principal bundles and $\Gamma'$ and $\Gamma$ differ by a gauge transformation? If it simplifies the question, we may assume that $M$ is a compact, orientable surface and $G$ is compact, connected and simply connected, so that the only principal bundle is the trivial one $M \times G \to M$.",,"['differential-geometry', 'connections', 'principal-bundles', 'holonomy']"
44,Sobolev spaces for conformal metrics on a Riemannian manifold,Sobolev spaces for conformal metrics on a Riemannian manifold,,"Suppose we have a compact Riemmanian manifold $(M^n,g)$ without boundary, and some class $\{g_u\}$ of conformal metrics $g_u:=e^{2u}g$, where $\{u\}\subset C^\infty(M^n)$. For some $k,p$ suppose there exists a constant $C_1=C_1(g)$ such that each $u$ in this class has corresponding $W^{k,p}(M^n,g_u)$-norm bounded by $C_1$: \begin{equation} ||u||_{W^{k,p}(M^n,g_u)} \leq C_1.  \end{equation} Can we conclude there exists $C_2=C_2(g)$ such that  each $w$ in this class has $W^{k,p}(M^n,g)$-norm bounded by $C_2$, i.e.  \begin{equation} ||u||_{W^{k,p}(M^n,g)} \leq C_2? \end{equation} UPDATE: The only thing I can think of is if $p$ is high enough then from Sobolev embeddings we get a bound on the Holder norms, but is this uniform in $g$? I should think uniform bounds on the Sobolev norms does imply uniform bounds on the Holder norms. If this is the case, then in particular we get uniform bounds on all the functions $u$, in which case just doing conformal transformations in the integrals (see the comments) answers in the affirmative.","Suppose we have a compact Riemmanian manifold $(M^n,g)$ without boundary, and some class $\{g_u\}$ of conformal metrics $g_u:=e^{2u}g$, where $\{u\}\subset C^\infty(M^n)$. For some $k,p$ suppose there exists a constant $C_1=C_1(g)$ such that each $u$ in this class has corresponding $W^{k,p}(M^n,g_u)$-norm bounded by $C_1$: \begin{equation} ||u||_{W^{k,p}(M^n,g_u)} \leq C_1.  \end{equation} Can we conclude there exists $C_2=C_2(g)$ such that  each $w$ in this class has $W^{k,p}(M^n,g)$-norm bounded by $C_2$, i.e.  \begin{equation} ||u||_{W^{k,p}(M^n,g)} \leq C_2? \end{equation} UPDATE: The only thing I can think of is if $p$ is high enough then from Sobolev embeddings we get a bound on the Holder norms, but is this uniform in $g$? I should think uniform bounds on the Sobolev norms does imply uniform bounds on the Holder norms. If this is the case, then in particular we get uniform bounds on all the functions $u$, in which case just doing conformal transformations in the integrals (see the comments) answers in the affirmative.",,"['differential-geometry', 'riemannian-geometry', 'sobolev-spaces', 'conformal-geometry']"
45,Verifying Christoffel Symbols of Sasaki Metric,Verifying Christoffel Symbols of Sasaki Metric,,"In Sasaki's original 1958 paper defining his metric on the tangent bundle $TM$, he gives expressions for the Christoffel symbols, in terms only of quantities from $M$ (pg. 352). For the simple example of a 2D surface $(x,y,f(x,y))$ where the metric tensor is the first fundamental form, I wanted to compute the Christoffel symbols of the associated Sasaki metric. Unfortunately, I am unable to reproduce his results, unless i am misreading them. My question is: what are the Christoffel symbols of $TM$ for the 2D surface defined above? Here are the details of what I'm trying to do. Consider the surface defined by $z=f(x,y)$ as a manifold $(M,g)$ with metric tensor given by $$ g = \begin{bmatrix} 1 + f_x^2 & f_xf_y\\ f_xf_y & 1 + f_y^2 \end{bmatrix} $$ where $\partial_x f = f_x$ and $\partial_y f = f_y$. Let $n=2$ be the dimension. Given $g$, we can compute the Christoffel symbols $\Gamma_{jk}^i$ and Riemann curvature tensor $R_{ijk\ell}$. (These correspond to the ""manual"" quantities in the code below). Next, consider the tangent bundle $TM$ (where $M$ is as just above). We want to consider $TM$ as a Riemannian manifold $(\hat{M},g_\text{Sasaki})=(TM,\hat{g})$, where $\hat{g}$ is the Sasaki metric, defined via: $$ \begin{cases} \displaystyle\hat{g}_{jk} = g_{jk} + g_{\beta \gamma}\Gamma_{\mu j}^\beta \Gamma_{\eta k}^\gamma v^\mu v^\eta \displaystyle \\ \displaystyle \hat{g}_{j(n+k)} = g_{k\mu}\Gamma_{\lambda j}^\mu v^\lambda\\ \displaystyle\hat{g}_{(n+j)(n+k)} = g_{jk}  \end{cases} $$ written in terms of the quantities from the lower ""base"" manifold $M$, with indices going from $1$ to $2$.  $v=(v^1,v^2)$ are coordinates on the tangent space. In this case, $g$ is $2\times 2$, so $\hat{g}$ is $4\times 4$, because $T\hat{M}=TTM$. (As an aside, this is almost directly from Sasaki's paper; hopefully I did not make a notational mistake or misunderstanding. In particular, I translated  $[\lambda\;j,k]$  as  $g_{k\mu}\Gamma_{\lambda j}^\mu$. Also, I suspect my error may involve $v$, because at no point do I specify what $v$ is in the code). Overall, my goal is to compute the Christoffel symbols $\hat{\Gamma}$, Riemann tensor $\hat{R}$, Ricci tensor, and Ricci scalar of $(\hat{M},\hat{g})$, i.e. $TM$. However, I can't get my Christoffel symbols to match with the expressions given by Sasaki. In particular, he writes: \begin{align} %\begin{cases} \hat{\Gamma}^I_{(n+j)(n+k)} &= 0\\ \hat{\Gamma}^i_{(j+n)k} &= \frac{1}{2}R_{kj\lambda}^\ell v^\lambda\\ \hat{\Gamma}^{n+i}_{(n+j)k} &= \Gamma_{jk}^i - \frac{1}{2}\Gamma_{\mu h}^iR_{kj\lambda}^h v^\lambda v^\mu \\ \hat{\Gamma}^{i}_{jk} &= \Gamma_{jk}^i + \frac{1}{2}\left( R_{kh\mu}^\ell\Gamma^h_{\lambda j} + R_{j h \mu}^\ell\Gamma^h_{\lambda k} \right)\\ \hat{\Gamma}_{jk}^{n+i} &= \frac{1}{2}\left( R^\ell_{j\lambda k} + R^\ell_{k\lambda j} + 2\frac{\partial \Gamma_{jk}^i}{\partial x^\lambda} \right)v^\lambda + \frac{1}{2}\Gamma_{\eta h}^h\left( R_{k\mu\ell}^h\Gamma^\ell_{\lambda j} + R_{j\mu\ell}^h\Gamma^\ell_{\lambda k} \right)v^\lambda v^\mu v^\eta %\end{cases} \end{align} However, when I simply take the coordinates $x,y,v^1,v^2$, compute the expression for $\hat{g}$, and run it through a library to get the Christoffel symbols, it does not match with the values given by the paper. (My current code does not check all of the above expressions, just the first three.) In other words, I compute $g$, $\Gamma$, $R$, and $\hat{g}$ manually (well, actually I computed them separately with the same GR package). Then I compute $\hat{\Gamma}$ via (1) manually with Sasaki's expressions and (2) with a GR library. I then compare the expressions produced each way. Since, even in this simple case, the calculations are horribly long, here is a script to help in the computations. I used the GR package GRQuick for Mathematica (just paste into the source folder to use). (I figured the math here was more the focus than the Mathematica, else I would have posted there; let me know if that makes sense.) (** Manually define the tensors for (x,y,f(x,y)) in Cartesian coords **) ClearAll[""Global`*""] metricM[x_,y_] := Simplify[{      {  1 + D[ f[x,y], x]^2 ,                       D[ f[x,y], x] D[ f[x,y], y]  },      {  D[ f[x,y], x] D[ f[x,y], y] ,    1 + D[ f[x,y], y]^2  }  }]; metric = metricM[x,y] n=2 christoffelManual={{{(Derivative[1, 0][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)},     {(Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 2][f][x, y]*Derivative[1, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}},    {{(Derivative[0, 1][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)},     {(Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 1][f][x, y]*Derivative[0, 2][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}}}  riemannManual= {{{{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}},     {{0, -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/        (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)},      {((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}},    {{{0, ((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/        (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), 0}},     {{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}}} ricciManual= {{-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*      (-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},    {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/     (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2,     -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)}}  manualRicciScalar = -((2*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)  (** Use GRQuick to get Sasaki metric **) << ""path/to/GRQUICK.m""; (*** Construct Sasaki metric ***) v = {v1, v2}; upperG[p_,v_,j_,k_] :=  metric[[j,k]] + Sum[  (* k,j \in {1,2} *) metric[[beta,gamma]] christoffelManual[[beta,mu,j]]christoffelManual[[gamma,ell,k]]v[[mu]]v[[ell]],   {beta,1,2},{gamma,1,2},{mu,1,2},{ell,1,2} ]  offG[p_,v_,j_,k_] := Sum[ metric[[ell,k]] christoffelManual[[ell,lambda,j]] v[[lambda]], {lambda,1,2}, {ell,1,2} ] sasakiGMet[x_,y_,v1_,v2_] := FullSimplify[{ { upperG[{x,y},{v1,v2},1,1], upperG[{x,y},{v1,v2},1,2], offG[{x,y}, {v1,v2},1,1], offG[{x,y}, {v1,v2},1,2] }, { upperG[{x,y},{v1,v2},2,1], upperG[{x,y},{v1,v2},2,2], offG[{x,y}, {v1,v2},2,1], offG[{x,y}, {v1,v2},2,2] }, { offG[{x,y}, {v1,v2},1,1],    offG[{x,y}, {v1,v2},2,1],     metric[[1,1]], metric[[1,2]] }, { offG[{x,y}, {v1,v2},1,2],    offG[{x,y}, {v1,v2},2,2],     metric[[2,1]], metric[[2,2]] } }] Metin[sasakiGMet[x,y,v1,v2],{x,y,v1,v2}];  (** Checks against Sasaki's calculations **) christoffelManualSasaki = Table[ (* Upper index first *) Simplify[ Christoffel[{{i},{j,k}}] ],     {i,0,3},{j,0,3},{k,0,3} ]; (* Check 1 *) Table[christoffelManualSasaki[[ii,n+j,n+k]],{ii,1,4},{j,1,2},{k,1,2}] (* Should be all zero *) (* Check 2 *) (* Should be zeros; notice they vanish if I change the sign! *) Table[Simplify[christoffelManualSasaki[[i,n+j,k]] - (1/2)(Sum[riemannManual[[i,k,j,lambda]]v[[lambda]],{lambda,1,2}]) ],{i,1,2},{j,1,2},{k,1,2}] (* Check 3 *) Table[     FullSimplify[         christoffelManualSasaki[[n+i,n+j,k]] -          (             christoffelManual[[i,j,k]]  -               (1/2) (Sum[             christoffelManual[[i,mu,h]] riemannManual[[h,k,j,lambda]]v[[lambda]] v[[mu]],         {lambda,1,2}, {mu,1,2},{h,1,2}         ] )         )     ], {i,1,2},{j,1,2},{k,1,2} ] My hope is that there is some simple thing I am missing.","In Sasaki's original 1958 paper defining his metric on the tangent bundle $TM$, he gives expressions for the Christoffel symbols, in terms only of quantities from $M$ (pg. 352). For the simple example of a 2D surface $(x,y,f(x,y))$ where the metric tensor is the first fundamental form, I wanted to compute the Christoffel symbols of the associated Sasaki metric. Unfortunately, I am unable to reproduce his results, unless i am misreading them. My question is: what are the Christoffel symbols of $TM$ for the 2D surface defined above? Here are the details of what I'm trying to do. Consider the surface defined by $z=f(x,y)$ as a manifold $(M,g)$ with metric tensor given by $$ g = \begin{bmatrix} 1 + f_x^2 & f_xf_y\\ f_xf_y & 1 + f_y^2 \end{bmatrix} $$ where $\partial_x f = f_x$ and $\partial_y f = f_y$. Let $n=2$ be the dimension. Given $g$, we can compute the Christoffel symbols $\Gamma_{jk}^i$ and Riemann curvature tensor $R_{ijk\ell}$. (These correspond to the ""manual"" quantities in the code below). Next, consider the tangent bundle $TM$ (where $M$ is as just above). We want to consider $TM$ as a Riemannian manifold $(\hat{M},g_\text{Sasaki})=(TM,\hat{g})$, where $\hat{g}$ is the Sasaki metric, defined via: $$ \begin{cases} \displaystyle\hat{g}_{jk} = g_{jk} + g_{\beta \gamma}\Gamma_{\mu j}^\beta \Gamma_{\eta k}^\gamma v^\mu v^\eta \displaystyle \\ \displaystyle \hat{g}_{j(n+k)} = g_{k\mu}\Gamma_{\lambda j}^\mu v^\lambda\\ \displaystyle\hat{g}_{(n+j)(n+k)} = g_{jk}  \end{cases} $$ written in terms of the quantities from the lower ""base"" manifold $M$, with indices going from $1$ to $2$.  $v=(v^1,v^2)$ are coordinates on the tangent space. In this case, $g$ is $2\times 2$, so $\hat{g}$ is $4\times 4$, because $T\hat{M}=TTM$. (As an aside, this is almost directly from Sasaki's paper; hopefully I did not make a notational mistake or misunderstanding. In particular, I translated  $[\lambda\;j,k]$  as  $g_{k\mu}\Gamma_{\lambda j}^\mu$. Also, I suspect my error may involve $v$, because at no point do I specify what $v$ is in the code). Overall, my goal is to compute the Christoffel symbols $\hat{\Gamma}$, Riemann tensor $\hat{R}$, Ricci tensor, and Ricci scalar of $(\hat{M},\hat{g})$, i.e. $TM$. However, I can't get my Christoffel symbols to match with the expressions given by Sasaki. In particular, he writes: \begin{align} %\begin{cases} \hat{\Gamma}^I_{(n+j)(n+k)} &= 0\\ \hat{\Gamma}^i_{(j+n)k} &= \frac{1}{2}R_{kj\lambda}^\ell v^\lambda\\ \hat{\Gamma}^{n+i}_{(n+j)k} &= \Gamma_{jk}^i - \frac{1}{2}\Gamma_{\mu h}^iR_{kj\lambda}^h v^\lambda v^\mu \\ \hat{\Gamma}^{i}_{jk} &= \Gamma_{jk}^i + \frac{1}{2}\left( R_{kh\mu}^\ell\Gamma^h_{\lambda j} + R_{j h \mu}^\ell\Gamma^h_{\lambda k} \right)\\ \hat{\Gamma}_{jk}^{n+i} &= \frac{1}{2}\left( R^\ell_{j\lambda k} + R^\ell_{k\lambda j} + 2\frac{\partial \Gamma_{jk}^i}{\partial x^\lambda} \right)v^\lambda + \frac{1}{2}\Gamma_{\eta h}^h\left( R_{k\mu\ell}^h\Gamma^\ell_{\lambda j} + R_{j\mu\ell}^h\Gamma^\ell_{\lambda k} \right)v^\lambda v^\mu v^\eta %\end{cases} \end{align} However, when I simply take the coordinates $x,y,v^1,v^2$, compute the expression for $\hat{g}$, and run it through a library to get the Christoffel symbols, it does not match with the values given by the paper. (My current code does not check all of the above expressions, just the first three.) In other words, I compute $g$, $\Gamma$, $R$, and $\hat{g}$ manually (well, actually I computed them separately with the same GR package). Then I compute $\hat{\Gamma}$ via (1) manually with Sasaki's expressions and (2) with a GR library. I then compare the expressions produced each way. Since, even in this simple case, the calculations are horribly long, here is a script to help in the computations. I used the GR package GRQuick for Mathematica (just paste into the source folder to use). (I figured the math here was more the focus than the Mathematica, else I would have posted there; let me know if that makes sense.) (** Manually define the tensors for (x,y,f(x,y)) in Cartesian coords **) ClearAll[""Global`*""] metricM[x_,y_] := Simplify[{      {  1 + D[ f[x,y], x]^2 ,                       D[ f[x,y], x] D[ f[x,y], y]  },      {  D[ f[x,y], x] D[ f[x,y], y] ,    1 + D[ f[x,y], y]^2  }  }]; metric = metricM[x,y] n=2 christoffelManual={{{(Derivative[1, 0][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)},     {(Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 2][f][x, y]*Derivative[1, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}},    {{(Derivative[0, 1][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)},     {(Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2),      (Derivative[0, 1][f][x, y]*Derivative[0, 2][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}}}  riemannManual= {{{{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}},     {{0, -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/        (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)},      {((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}},    {{{0, ((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/        (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), 0}},     {{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},      {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}}} ricciManual= {{-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*      (-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2},    {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/     (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2,     -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)}}  manualRicciScalar = -((2*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)  (** Use GRQuick to get Sasaki metric **) << ""path/to/GRQUICK.m""; (*** Construct Sasaki metric ***) v = {v1, v2}; upperG[p_,v_,j_,k_] :=  metric[[j,k]] + Sum[  (* k,j \in {1,2} *) metric[[beta,gamma]] christoffelManual[[beta,mu,j]]christoffelManual[[gamma,ell,k]]v[[mu]]v[[ell]],   {beta,1,2},{gamma,1,2},{mu,1,2},{ell,1,2} ]  offG[p_,v_,j_,k_] := Sum[ metric[[ell,k]] christoffelManual[[ell,lambda,j]] v[[lambda]], {lambda,1,2}, {ell,1,2} ] sasakiGMet[x_,y_,v1_,v2_] := FullSimplify[{ { upperG[{x,y},{v1,v2},1,1], upperG[{x,y},{v1,v2},1,2], offG[{x,y}, {v1,v2},1,1], offG[{x,y}, {v1,v2},1,2] }, { upperG[{x,y},{v1,v2},2,1], upperG[{x,y},{v1,v2},2,2], offG[{x,y}, {v1,v2},2,1], offG[{x,y}, {v1,v2},2,2] }, { offG[{x,y}, {v1,v2},1,1],    offG[{x,y}, {v1,v2},2,1],     metric[[1,1]], metric[[1,2]] }, { offG[{x,y}, {v1,v2},1,2],    offG[{x,y}, {v1,v2},2,2],     metric[[2,1]], metric[[2,2]] } }] Metin[sasakiGMet[x,y,v1,v2],{x,y,v1,v2}];  (** Checks against Sasaki's calculations **) christoffelManualSasaki = Table[ (* Upper index first *) Simplify[ Christoffel[{{i},{j,k}}] ],     {i,0,3},{j,0,3},{k,0,3} ]; (* Check 1 *) Table[christoffelManualSasaki[[ii,n+j,n+k]],{ii,1,4},{j,1,2},{k,1,2}] (* Should be all zero *) (* Check 2 *) (* Should be zeros; notice they vanish if I change the sign! *) Table[Simplify[christoffelManualSasaki[[i,n+j,k]] - (1/2)(Sum[riemannManual[[i,k,j,lambda]]v[[lambda]],{lambda,1,2}]) ],{i,1,2},{j,1,2},{k,1,2}] (* Check 3 *) Table[     FullSimplify[         christoffelManualSasaki[[n+i,n+j,k]] -          (             christoffelManual[[i,j,k]]  -               (1/2) (Sum[             christoffelManual[[i,mu,h]] riemannManual[[h,k,j,lambda]]v[[lambda]] v[[mu]],         {lambda,1,2}, {mu,1,2},{h,1,2}         ] )         )     ], {i,1,2},{j,1,2},{k,1,2} ] My hope is that there is some simple thing I am missing.",,"['differential-geometry', 'proof-verification', 'manifolds', 'riemannian-geometry', 'tangent-bundle']"
46,Analytic Grothendieck Riemann Roch,Analytic Grothendieck Riemann Roch,,"I was wandering if is there an analytic version of the Grothendieck-Riemann-Roch theorem. If so, could you please tell me the references?","I was wandering if is there an analytic version of the Grothendieck-Riemann-Roch theorem. If so, could you please tell me the references?",,"['differential-geometry', 'algebraic-geometry', 'reference-request', 'intersection-theory', 'topological-k-theory']"
47,Change of variable and divergence,Change of variable and divergence,,"Given $x=(x_1, \cdots , x_n)$ with $dx$ being the Lebesgue measure,   suppose we do the change of variable  $h(x) = w$, a vector field   $v(x)$ is divergence free $$\text{div}(v(x)) = 0$$  then after the   change of variable $\tilde v = dh(v)$, multiplied by the new density   $\rho$ from $dx \mapsto \rho dw$, is still divergence free   $$\text{div}(\rho\tilde v(w)) = 0.$$ I worked out an example: $v= (x,-y)$ is a divergence free vector field in the Cartesian coordinate. $h(x,y) = (\sqrt{x^2+y^2}, \arctan(y/x)) = (r,\theta)$ is the change of variable from Cartesian to polar. The density $dxdy \mapsto rdrd\theta$ is $r$. The new vector field in terms of $\partial_r$ and $\partial_\theta$: $$\tilde v  = dh(v) = Jh(v) = (r(\cos^2\theta - \sin^2\theta), -2\sin\theta\cos\theta).$$ $\text{div}(r\tilde v) = 2r(\cos^2\theta - \sin^2\theta) -  2r(\cos^2\theta - \sin^2\theta)  = 0$. Now I am confused because the divergence in polar coordinate of a vector field $v(r,\theta)= (v_1, v_2)$ in my calculation is given by $$ \text{div}(v) = \partial_r v_1 + \partial_\theta v_2$$  but there is also the formula of divergence in polar coordinate given by  $$\text{div}(v)= \frac{1}{r}\partial_r (rv_1) + \frac{1}{r} \partial_\theta v_2.$$ I have a vague idea that in the second one, the directions of the vector field we are looking at are still in the Cartesian coordinate in terms of $(\cos\theta, \sin\theta)$ and $(-\sin\theta, \cos\theta)$. But this feels very unnatural to me, because with these $e_r$, $e_\theta$ instead of $\partial_r, \partial_\theta$, we do not have the formula $\tilde v = dh(v)$ Could you help me clarify this please. For Completeness, here is a sketch of the proof for the statement at the top, it is based on Liouville's theorem: The solution $\phi^t(x)$ of  $$\begin{cases} \dot y = v(y) \\ y(0) = x  \end{cases}$$   as a flow preserves measure $\rho dx$, $\int_D \rho dx = \int_{\phi^t(D)} \rho dx$ if and only if $\text{div}(\rho v) = 0$. So now it suffices to show that the solution to our new IVP after the change of variable $h(\phi^t(h^{-1}(w)))$ preserves the new volume $Jh^{-1} dw$, i.e. for each $K$  $$\int_K Jh^{-1} dw = \int_{h(\phi^t(h^{-1}(K)))} Jh^{-1} dw$$ and this is clear once we rewrite $K = h(h^{-1}(K))$ $$\int_{h(h^{-1}(K))} Jh^{-1} dw = \int_{h(\phi^t(h^{-1}(K)))} Jh^{-1} dw$$ which reduces to  $$\int_{h^{-1}(K)} dw = \int_{\phi^t(h^{-1}(K))} dw$$ and this is true by our assumption $\text{div}(v) = 0$.","Given $x=(x_1, \cdots , x_n)$ with $dx$ being the Lebesgue measure,   suppose we do the change of variable  $h(x) = w$, a vector field   $v(x)$ is divergence free $$\text{div}(v(x)) = 0$$  then after the   change of variable $\tilde v = dh(v)$, multiplied by the new density   $\rho$ from $dx \mapsto \rho dw$, is still divergence free   $$\text{div}(\rho\tilde v(w)) = 0.$$ I worked out an example: $v= (x,-y)$ is a divergence free vector field in the Cartesian coordinate. $h(x,y) = (\sqrt{x^2+y^2}, \arctan(y/x)) = (r,\theta)$ is the change of variable from Cartesian to polar. The density $dxdy \mapsto rdrd\theta$ is $r$. The new vector field in terms of $\partial_r$ and $\partial_\theta$: $$\tilde v  = dh(v) = Jh(v) = (r(\cos^2\theta - \sin^2\theta), -2\sin\theta\cos\theta).$$ $\text{div}(r\tilde v) = 2r(\cos^2\theta - \sin^2\theta) -  2r(\cos^2\theta - \sin^2\theta)  = 0$. Now I am confused because the divergence in polar coordinate of a vector field $v(r,\theta)= (v_1, v_2)$ in my calculation is given by $$ \text{div}(v) = \partial_r v_1 + \partial_\theta v_2$$  but there is also the formula of divergence in polar coordinate given by  $$\text{div}(v)= \frac{1}{r}\partial_r (rv_1) + \frac{1}{r} \partial_\theta v_2.$$ I have a vague idea that in the second one, the directions of the vector field we are looking at are still in the Cartesian coordinate in terms of $(\cos\theta, \sin\theta)$ and $(-\sin\theta, \cos\theta)$. But this feels very unnatural to me, because with these $e_r$, $e_\theta$ instead of $\partial_r, \partial_\theta$, we do not have the formula $\tilde v = dh(v)$ Could you help me clarify this please. For Completeness, here is a sketch of the proof for the statement at the top, it is based on Liouville's theorem: The solution $\phi^t(x)$ of  $$\begin{cases} \dot y = v(y) \\ y(0) = x  \end{cases}$$   as a flow preserves measure $\rho dx$, $\int_D \rho dx = \int_{\phi^t(D)} \rho dx$ if and only if $\text{div}(\rho v) = 0$. So now it suffices to show that the solution to our new IVP after the change of variable $h(\phi^t(h^{-1}(w)))$ preserves the new volume $Jh^{-1} dw$, i.e. for each $K$  $$\int_K Jh^{-1} dw = \int_{h(\phi^t(h^{-1}(K)))} Jh^{-1} dw$$ and this is clear once we rewrite $K = h(h^{-1}(K))$ $$\int_{h(h^{-1}(K))} Jh^{-1} dw = \int_{h(\phi^t(h^{-1}(K)))} Jh^{-1} dw$$ which reduces to  $$\int_{h^{-1}(K)} dw = \int_{\phi^t(h^{-1}(K))} dw$$ and this is true by our assumption $\text{div}(v) = 0$.",,"['calculus', 'real-analysis', 'differential-geometry', 'divergence-operator']"
48,What's the relation between the Darboux Frame and the Frenet-Serret on a oriented surface?,What's the relation between the Darboux Frame and the Frenet-Serret on a oriented surface?,,"I'm studying differential geometry and I'm in the part of geodesics, my professor always defines a curve that can define the tangent field but for calculating the geodesics and normal curvatures at each point $\alpha(t)$ of the curve he defines the frame $D=\{\alpha'(t),\alpha(t)\times N(\alpha(t)),N(\alpha(t))\}$ where $N$ is the Gauss application of the surface, so we get $$\alpha''=\langle\alpha'',\alpha\times N(\alpha)\rangle\,\alpha\times N(\alpha)  + \langle\alpha'',\ N(\alpha)\rangle \,N(\alpha)$$ where these coefficients are the geodesic and normal curvatures of $\alpha$ . My question is, what's the relation between $D$ and the Frenet-Serret $F=\{\alpha^{'}(t),n(t),b(t)\}$ where $n$ and $b$ are the normal and binormal of the curve, is there a relation between $n$ and $\alpha\times N(\alpha)$ , or $b$ and $N(\alpha)$ ? I'm having several dificulties about exercises involving this because I don't know how to compare results of curves, like torsion with the Darboux vectors.","I'm studying differential geometry and I'm in the part of geodesics, my professor always defines a curve that can define the tangent field but for calculating the geodesics and normal curvatures at each point of the curve he defines the frame where is the Gauss application of the surface, so we get where these coefficients are the geodesic and normal curvatures of . My question is, what's the relation between and the Frenet-Serret where and are the normal and binormal of the curve, is there a relation between and , or and ? I'm having several dificulties about exercises involving this because I don't know how to compare results of curves, like torsion with the Darboux vectors.","\alpha(t) D=\{\alpha'(t),\alpha(t)\times N(\alpha(t)),N(\alpha(t))\} N \alpha''=\langle\alpha'',\alpha\times N(\alpha)\rangle\,\alpha\times N(\alpha)  + \langle\alpha'',\ N(\alpha)\rangle \,N(\alpha) \alpha D F=\{\alpha^{'}(t),n(t),b(t)\} n b n \alpha\times N(\alpha) b N(\alpha)","['differential-geometry', 'surfaces', 'curves', 'geodesic', 'frenet-frame']"
49,How can I show that every derivation of $C^\infty(M)$ on a smooth manifold can be represented by a vector field?,How can I show that every derivation of  on a smooth manifold can be represented by a vector field?,C^\infty(M),"How can I show that every derivation of $C^\infty(M)$ on a smooth manifold can be represented by a vector field? I want to show that the space of vector fields is isomorphic to the space of derivations of $C^\infty(M)$. I know the proof when $M = \mathbb{R^n}$, but would like to do it for a general smooth manifold.","How can I show that every derivation of $C^\infty(M)$ on a smooth manifold can be represented by a vector field? I want to show that the space of vector fields is isomorphic to the space of derivations of $C^\infty(M)$. I know the proof when $M = \mathbb{R^n}$, but would like to do it for a general smooth manifold.",,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-fields']"
50,"From a ""low-level"" point of view, is the curvature form a covariant exterior derivative?","From a ""low-level"" point of view, is the curvature form a covariant exterior derivative?",,"Let $(\mathcal E,\pi,M)$ be a G-vector bundle with a linear connection. On the associated principal bundle, it is true that $\Omega=d_\omega\omega$, where $\Omega$ is the curvature form, $d_\omega=d\circ h^*$ is the covariant exterior derivative and $\omega$ is the $\mathfrak g$-valued connection form. On the other hand, if we consider the vector bundle $\mathcal E$ only, if $\psi$ is a section, we can describe its covariant derivative locally as $$ d_\omega\psi=d\psi+\omega\psi. $$ Here $\omega$ is a local Lie-algebra valued 1-form. If we ignore its pathological transformation properties under the change of a local trivialization, we may see $\omega$ as either a local section of the adjoint bundle (adjoint bundle as in $P\times_{Ad}\mathfrak g$ where $P$ is the associated principal bundle), or as a local section of $\mathcal E \otimes\mathcal E^\ast$. The action $\omega\psi$ is understood naturally if we go with the $\mathcal E \otimes\mathcal E^*$ view, otherwise if $G$ acts on the model fibre $E$ via a representation $\rho$, we may understand the action $\omega\psi$ to be happening through the corresponding Lie algebra representation $d\rho_e$. We may extend the covariant exterior derivative to an $\mathcal E$ valued $k$-form as follows: If locally $$ \psi=\sum_{\mu_1<...<\mu_k}\psi_{\mu_1...\mu_k}dx^{\mu_1}\wedge...\wedge dx^{\mu_k}, $$ then $$ d_\omega\psi=\sum_{\mu_1<...<\mu_k}d_\omega\psi_{\mu_1...\mu_k}\wedge dx^{\mu_1}\wedge...\wedge dx^{\mu_k}. $$ We may also extend $d_\omega$ to $k$-forms which take their values in the tensor product bundle constructed out of $\mathcal E$ and $\mathcal E^*$. Particularily, for a $\mathcal E \otimes \mathcal E^*$-valued $1$-form $\lambda$ we have $$ d_\omega \lambda=d_\omega\lambda_{\mu}\wedge dx^\mu=(d\lambda_\mu+\omega\lambda_\mu-\lambda_\mu\omega)\wedge dx^\mu=d\lambda+(\omega_\nu\lambda_\mu-\lambda_\mu\omega_\nu)dx^\nu\wedge dx^\mu=d\lambda+\omega\wedge\lambda+\lambda\wedge\omega.$$ If we apply this to $\omega$ itself, we get $$ d_\omega\omega=d\omega+2\omega\wedge\omega, $$ on the other hand, the curvature form is $$ \Omega=d\omega+\omega\wedge\omega. $$ So questions: Is the curvature actually the covariant exterior derivative of the connection? Doing this on the principal bundle says yes, the derivation here says no. If so, how come I get that factor of 2 here? Did I make a mistake or what? Is the covariant exterior derivative of an adjoint-bundle valued form not the same as the covariant exterior derivative of an $\mathcal E \otimes \mathcal E^*$-valued form?","Let $(\mathcal E,\pi,M)$ be a G-vector bundle with a linear connection. On the associated principal bundle, it is true that $\Omega=d_\omega\omega$, where $\Omega$ is the curvature form, $d_\omega=d\circ h^*$ is the covariant exterior derivative and $\omega$ is the $\mathfrak g$-valued connection form. On the other hand, if we consider the vector bundle $\mathcal E$ only, if $\psi$ is a section, we can describe its covariant derivative locally as $$ d_\omega\psi=d\psi+\omega\psi. $$ Here $\omega$ is a local Lie-algebra valued 1-form. If we ignore its pathological transformation properties under the change of a local trivialization, we may see $\omega$ as either a local section of the adjoint bundle (adjoint bundle as in $P\times_{Ad}\mathfrak g$ where $P$ is the associated principal bundle), or as a local section of $\mathcal E \otimes\mathcal E^\ast$. The action $\omega\psi$ is understood naturally if we go with the $\mathcal E \otimes\mathcal E^*$ view, otherwise if $G$ acts on the model fibre $E$ via a representation $\rho$, we may understand the action $\omega\psi$ to be happening through the corresponding Lie algebra representation $d\rho_e$. We may extend the covariant exterior derivative to an $\mathcal E$ valued $k$-form as follows: If locally $$ \psi=\sum_{\mu_1<...<\mu_k}\psi_{\mu_1...\mu_k}dx^{\mu_1}\wedge...\wedge dx^{\mu_k}, $$ then $$ d_\omega\psi=\sum_{\mu_1<...<\mu_k}d_\omega\psi_{\mu_1...\mu_k}\wedge dx^{\mu_1}\wedge...\wedge dx^{\mu_k}. $$ We may also extend $d_\omega$ to $k$-forms which take their values in the tensor product bundle constructed out of $\mathcal E$ and $\mathcal E^*$. Particularily, for a $\mathcal E \otimes \mathcal E^*$-valued $1$-form $\lambda$ we have $$ d_\omega \lambda=d_\omega\lambda_{\mu}\wedge dx^\mu=(d\lambda_\mu+\omega\lambda_\mu-\lambda_\mu\omega)\wedge dx^\mu=d\lambda+(\omega_\nu\lambda_\mu-\lambda_\mu\omega_\nu)dx^\nu\wedge dx^\mu=d\lambda+\omega\wedge\lambda+\lambda\wedge\omega.$$ If we apply this to $\omega$ itself, we get $$ d_\omega\omega=d\omega+2\omega\wedge\omega, $$ on the other hand, the curvature form is $$ \Omega=d\omega+\omega\wedge\omega. $$ So questions: Is the curvature actually the covariant exterior derivative of the connection? Doing this on the principal bundle says yes, the derivation here says no. If so, how come I get that factor of 2 here? Did I make a mistake or what? Is the covariant exterior derivative of an adjoint-bundle valued form not the same as the covariant exterior derivative of an $\mathcal E \otimes \mathcal E^*$-valued form?",,"['differential-geometry', 'vector-bundles', 'curvature', 'connections']"
51,Riemannian metrics on vector bundles according to Jeffrey. M. Lee's book,Riemannian metrics on vector bundles according to Jeffrey. M. Lee's book,,"According to Manifolds and differential Geometry (J. M. Lee, 2009), a Riemannian metric on a vector bundle $\pi:E\rightarrow M$ is a smooth assignment to each point $p\in M$ a scalar product $g_p$ on the fibre $\pi^{-1}(p)$ , so this is the standard definition. However, he wants to show that a choice of Riemannian metric for $E$ is a reduction of structure group from $GL(V)$ to $(O(V)$ . And he will do it using charts. Let's go. First, he says: If the vector bundle has such a structure, it is convenient to assume that a fixed inner product has is chosen on the typical fibre and that a distinguished orthonormal basis $(e_1,\dots,e_k)$ has been chosen. (Here $k$ is the rank). Now he continues: If $(U,\Psi)$ is a local trivialization, then define a local frame field $(X_1,\dots,X_k)$ simply as $$ X_a(p) = \Psi^{-1}(p,e_i) \qquad \forall p\in U, $$ for all $a=1,\dots,k$ . This is also good because he has already proven the relation between local frame fields and vector bundle charts, so it is okay. But now, he says: One can perform a Gram-Schmidt proccess in the basis $\{X_1(p),\dots,X_k(p)\}$ simultaneously for all $p\in U$ so that we have a new orthonormal basis $\{E_1(p),\dots,E_k(p)\}$ (...). Thus, $\{E_1(p),\dots,E_k(p)\}$ is a local frame called orthonormal frame. HERE the point is. Some comments: First, yo haven't a metric on $\pi^{-1}(p)$ , but in $V$ , so you must to import it. I mean, Gram-Schmidt process does not make sense at this moment. Second, since you really haven't such a metric, I think Gram-Schimdt process would look like $$ E_a(P) = \Psi^{-1}(p,W_a), $$ where $W_a$ is defined as $$ W_p = \frac{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)}{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)} $$ (here $\Psi$ is supposed to be $\Psi=(\pi,\psi)$ . If the above process is right, Lee's words don't not make sense, since $\Psi(X_a(p))=e_a$ exactly, and then it is already orthonormal. So, what is happening here? Lee's book is wrong? Is all that a mistake? Or what is he actually thinking in? Thanks EDIT Reading Riemannian Geometry and Geometric Analysis (Jürgen Jost, 2011) I realize that I am wrong: Each (real) rank $k$ vector bundle $\pi:E\rightarrow M$ with a bundle metric $g$ has structure group $(On)$ . In particular, there exists bundle charts $(U,F)$ , $F:\pi^{-1}\rightarrow U\times\mathbb{R}^k$ , for which for each point $p\in U$ , $F^{-1}(p,(e_1,\dots,e_k))$ is an orthonormal basis of $\pi^{-1}(p)$ . Since my bundle charts was arbitrary, $\{X_1,(p),\dots,X_k(p)$ cannot be an orthonormal frame, but I don't know why. I'm missing something.","According to Manifolds and differential Geometry (J. M. Lee, 2009), a Riemannian metric on a vector bundle is a smooth assignment to each point a scalar product on the fibre , so this is the standard definition. However, he wants to show that a choice of Riemannian metric for is a reduction of structure group from to . And he will do it using charts. Let's go. First, he says: If the vector bundle has such a structure, it is convenient to assume that a fixed inner product has is chosen on the typical fibre and that a distinguished orthonormal basis has been chosen. (Here is the rank). Now he continues: If is a local trivialization, then define a local frame field simply as for all . This is also good because he has already proven the relation between local frame fields and vector bundle charts, so it is okay. But now, he says: One can perform a Gram-Schmidt proccess in the basis simultaneously for all so that we have a new orthonormal basis (...). Thus, is a local frame called orthonormal frame. HERE the point is. Some comments: First, yo haven't a metric on , but in , so you must to import it. I mean, Gram-Schmidt process does not make sense at this moment. Second, since you really haven't such a metric, I think Gram-Schimdt process would look like where is defined as (here is supposed to be . If the above process is right, Lee's words don't not make sense, since exactly, and then it is already orthonormal. So, what is happening here? Lee's book is wrong? Is all that a mistake? Or what is he actually thinking in? Thanks EDIT Reading Riemannian Geometry and Geometric Analysis (Jürgen Jost, 2011) I realize that I am wrong: Each (real) rank vector bundle with a bundle metric has structure group . In particular, there exists bundle charts , , for which for each point , is an orthonormal basis of . Since my bundle charts was arbitrary, cannot be an orthonormal frame, but I don't know why. I'm missing something.","\pi:E\rightarrow M p\in M g_p \pi^{-1}(p) E GL(V) (O(V) (e_1,\dots,e_k) k (U,\Psi) (X_1,\dots,X_k) 
X_a(p) = \Psi^{-1}(p,e_i) \qquad \forall p\in U,
 a=1,\dots,k \{X_1(p),\dots,X_k(p)\} p\in U \{E_1(p),\dots,E_k(p)\} \{E_1(p),\dots,E_k(p)\} \pi^{-1}(p) V 
E_a(P) = \Psi^{-1}(p,W_a),
 W_a 
W_p = \frac{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)}{\psi\left(X_a(p)\right)-\displaystyle \sum_{b=1}^{a-1}g\bigg(\psi\left(X_b(p)\right),\psi\left(X_a(p)\right) \bigg)\psi\left(X_a(p)\right)}
 \Psi \Psi=(\pi,\psi) \Psi(X_a(p))=e_a k \pi:E\rightarrow M g (On) (U,F) F:\pi^{-1}\rightarrow U\times\mathbb{R}^k p\in U F^{-1}(p,(e_1,\dots,e_k)) \pi^{-1}(p) \{X_1,(p),\dots,X_k(p)","['differential-geometry', 'riemannian-geometry', 'vector-bundles']"
52,local trivialization of quotient manifold map,local trivialization of quotient manifold map,,"Let $G$ be a lie group acting on a smooth manifold $M$ smoothly, properly and freely. Then, there exists a unique smooth structure on the orbit space $M/G$ such that the map $\pi:M\rightarrow M/G$ is a smooth submersion. I am trying to show that this map has local trivialization property  with $G$ as fiber space i.e., given $q\in M/G$ there exists an open subset $U\subseteq M/G$ containing $q$ and a diffeomorphism $$\varphi:U\times G\rightarrow \pi^{-1}(U).$$ Local section theorem says that any smooth submersion has abundant local sections. In particular, given $p\in M$ there exists a local section of $\pi$ whose image contains $p$. Let $q=\pi(p)$ and $\sigma:U\rightarrow M$ be a local section of $\pi$ with $\sigma(q)=p$. As $\pi\circ \sigma=1_U$ we have $\sigma(a)\in \pi^{-1}(a)\subseteq \pi^{-1}(U)$ for all $a\in U$. So, we have ,$U\rightarrow \pi^{-1}(U)$ a smooth map. Define $\varphi:U\times G\rightarrow \pi^{-1}(U)$ by $(a,g)\mapsto g\sigma(a)$. As $a=\pi(\sigma(a))=\pi(g\sigma(a))$, we have $g\sigma(a)\in \sigma^{-1}(a)\subseteq \sigma^{-1}(U)$. So, we have a well defined map $U\times G\rightarrow \pi^{-1}(U)$ given by $(a,g)\mapsto g\sigma(a)$. Let $(a,g),(a',g')\in U\times G$ be such that $\varphi(a,g)=\varphi(a',g')$ i.e., $g\sigma(a)=g'\sigma(a')$. So, $\pi(g\sigma(a))=\pi(g'\sigma(a'))$ i.e., $\pi(\sigma(a))=\pi(\sigma(a'))$ i.e., $a=a'$. As the action of $G$ on $M$ is free, $g\sigma(a)=g'\sigma(a')=g'\sigma(a)$ implies $gg'$. Thus, $\varphi :U\times G\rightarrow \pi^{-1}(U)$ is injective. Let $x\in \pi^{-1}(U)$ then, $\pi(x)\in U$. This suggests to consider $(\pi(x),g)\in U\times G$ such that $\varphi(\pi(x),g)=x$ (This is with gut feeling that $\varphi$ is surjective.) i.e., $g\sigma(\pi(x))=x$. But, how do  we know there exists $g\in G$ such that $g\sigma(\pi(x))=x$? We have not assumed that the action is transitive. Am I missing something? Suppose such $g$ exists then it is clear that $\varphi$ is smooth bijective map. Its inverse  $\pi^{-1}(U)\rightarrow U\rightarrow G$ is given by $x\mapsto (\sigma(x),g)$ where $g\in G$ is such that $g\sigma(\pi(x))=x$ and I do not see how one can show that this inverse is smooth. It is smooth in first coordinate as it is just the map $\pi$.  How do we prove that $\pi^{-1}(U)\rightarrow G$ given by $x\mapsto g$ where $g$ is such that $g\sigma(\pi(x))=x$ is a smooth map. Any suggestions are welcome.","Let $G$ be a lie group acting on a smooth manifold $M$ smoothly, properly and freely. Then, there exists a unique smooth structure on the orbit space $M/G$ such that the map $\pi:M\rightarrow M/G$ is a smooth submersion. I am trying to show that this map has local trivialization property  with $G$ as fiber space i.e., given $q\in M/G$ there exists an open subset $U\subseteq M/G$ containing $q$ and a diffeomorphism $$\varphi:U\times G\rightarrow \pi^{-1}(U).$$ Local section theorem says that any smooth submersion has abundant local sections. In particular, given $p\in M$ there exists a local section of $\pi$ whose image contains $p$. Let $q=\pi(p)$ and $\sigma:U\rightarrow M$ be a local section of $\pi$ with $\sigma(q)=p$. As $\pi\circ \sigma=1_U$ we have $\sigma(a)\in \pi^{-1}(a)\subseteq \pi^{-1}(U)$ for all $a\in U$. So, we have ,$U\rightarrow \pi^{-1}(U)$ a smooth map. Define $\varphi:U\times G\rightarrow \pi^{-1}(U)$ by $(a,g)\mapsto g\sigma(a)$. As $a=\pi(\sigma(a))=\pi(g\sigma(a))$, we have $g\sigma(a)\in \sigma^{-1}(a)\subseteq \sigma^{-1}(U)$. So, we have a well defined map $U\times G\rightarrow \pi^{-1}(U)$ given by $(a,g)\mapsto g\sigma(a)$. Let $(a,g),(a',g')\in U\times G$ be such that $\varphi(a,g)=\varphi(a',g')$ i.e., $g\sigma(a)=g'\sigma(a')$. So, $\pi(g\sigma(a))=\pi(g'\sigma(a'))$ i.e., $\pi(\sigma(a))=\pi(\sigma(a'))$ i.e., $a=a'$. As the action of $G$ on $M$ is free, $g\sigma(a)=g'\sigma(a')=g'\sigma(a)$ implies $gg'$. Thus, $\varphi :U\times G\rightarrow \pi^{-1}(U)$ is injective. Let $x\in \pi^{-1}(U)$ then, $\pi(x)\in U$. This suggests to consider $(\pi(x),g)\in U\times G$ such that $\varphi(\pi(x),g)=x$ (This is with gut feeling that $\varphi$ is surjective.) i.e., $g\sigma(\pi(x))=x$. But, how do  we know there exists $g\in G$ such that $g\sigma(\pi(x))=x$? We have not assumed that the action is transitive. Am I missing something? Suppose such $g$ exists then it is clear that $\varphi$ is smooth bijective map. Its inverse  $\pi^{-1}(U)\rightarrow U\rightarrow G$ is given by $x\mapsto (\sigma(x),g)$ where $g\in G$ is such that $g\sigma(\pi(x))=x$ and I do not see how one can show that this inverse is smooth. It is smooth in first coordinate as it is just the map $\pi$.  How do we prove that $\pi^{-1}(U)\rightarrow G$ given by $x\mapsto g$ where $g$ is such that $g\sigma(\pi(x))=x$ is a smooth map. Any suggestions are welcome.",,['differential-geometry']
53,Restricting the codomain of a smooth map of manifolds to a submanifold is not necessarily smooth.,Restricting the codomain of a smooth map of manifolds to a submanifold is not necessarily smooth.,,"In John Lee's introduction to smooth manifold book he gives the following example: Example 5.28: Let $S \subset \mathbb{R}^2$ be the figure eight submanifold with the topology and smooth structure induced by the immersion $\beta:(-\pi,pi)$; $\beta(t)=(\sin2t,\sin t)$. Define a smooth map $G: \mathbb{R} \rightarrow \mathbb{R}^2$ by $G(t)=(\sin2t,\sin t)$. The image of $G$ clearly lies in $S$, but as a map from $\mathbb{R}$ to $S$ it is not even continuous because $\beta^{-1} \circ G$ is not continuous at $t=\pi$. I am confused why he is looking at the composition $\beta^{-1}\circ G$ to show that $G$ is not continuous. I think that since $\beta$ is a diffeomorphism, then if $G$ were continuous then this composition would have to be continuous. But I still don't comprehend why we need to look a the composition to show it's discontinuous. Update:   Okay so I think I've figured it out. This has to do with the topology given to the image of injective smooth immersion. It goes as follows: Let $F: N \rightarrow M$ be an injective smooth immersion. Then as in the proof of Lee's proposition 5.18, $S=F(N)$ is topologized by delcaring $U \subset S$ open iff $F^{-1}(U) \subset N$ is open. In the case at hand our $F$ is the map $\beta$. It's easy to see from how the image of $\beta$ traces out the figure-eight that at $t=\pi$ that the image of the composition $\beta^{-1}\circ G$ jumps from points near $\pi$ back down to zero which is obviously a discontinuity.","In John Lee's introduction to smooth manifold book he gives the following example: Example 5.28: Let $S \subset \mathbb{R}^2$ be the figure eight submanifold with the topology and smooth structure induced by the immersion $\beta:(-\pi,pi)$; $\beta(t)=(\sin2t,\sin t)$. Define a smooth map $G: \mathbb{R} \rightarrow \mathbb{R}^2$ by $G(t)=(\sin2t,\sin t)$. The image of $G$ clearly lies in $S$, but as a map from $\mathbb{R}$ to $S$ it is not even continuous because $\beta^{-1} \circ G$ is not continuous at $t=\pi$. I am confused why he is looking at the composition $\beta^{-1}\circ G$ to show that $G$ is not continuous. I think that since $\beta$ is a diffeomorphism, then if $G$ were continuous then this composition would have to be continuous. But I still don't comprehend why we need to look a the composition to show it's discontinuous. Update:   Okay so I think I've figured it out. This has to do with the topology given to the image of injective smooth immersion. It goes as follows: Let $F: N \rightarrow M$ be an injective smooth immersion. Then as in the proof of Lee's proposition 5.18, $S=F(N)$ is topologized by delcaring $U \subset S$ open iff $F^{-1}(U) \subset N$ is open. In the case at hand our $F$ is the map $\beta$. It's easy to see from how the image of $\beta$ traces out the figure-eight that at $t=\pi$ that the image of the composition $\beta^{-1}\circ G$ jumps from points near $\pi$ back down to zero which is obviously a discontinuity.",,"['differential-geometry', 'smooth-manifolds']"
54,Intuitive notion of Levi-Civita connection induced by a metric tensor,Intuitive notion of Levi-Civita connection induced by a metric tensor,,"I know that for a given metric tensor $g_{\mu \nu}$ on a differentiable manifold exists only one connection which: Preserves the metric form Has no torsion That's the Levi-Civita connection, and it could be derived by $g_{\mu \nu}$ . I'm wondering is if there is some intuitive/geometrical way to understand how we can obtain this connection starting from the metric form. It is clear that a parallel transport compatible with the metric has to preserve angles and length, and we can see geometrically it very well. But that is not enough in order to define it unequivocally, so, we are asking also zero torsion. How can we interpret it geometrically? Writing it very roughly, if we have an ant walking straight ahead (i.e. on a geodesic) on a $\mathbb{R}^2$ plane with a metric fom: $ds^2 = a(x,y)dx^2 + b(x,y)dxdy+c(x,y)dy^2$ how does it moves? Let's say that it calculates the new direction at each (very little) step EDIT: I add an image for making it clear: we have a mesh of the surface, and on each cell the metric form is just $G^i=a^idx^2 + b^idxdy+c^idy^2$ with $a^i,b^i,c^i \in \mathbb{R}$ linear coefficient. The ant is walking from the cell $1$ to cell $2$: how does its direction change? I think that there is an analogy with refraction of light, which could be considered as the case where the metric tensor is in the form $g_{\mu \nu}=\phi(x)\delta_{\mu \nu}$","I know that for a given metric tensor $g_{\mu \nu}$ on a differentiable manifold exists only one connection which: Preserves the metric form Has no torsion That's the Levi-Civita connection, and it could be derived by $g_{\mu \nu}$ . I'm wondering is if there is some intuitive/geometrical way to understand how we can obtain this connection starting from the metric form. It is clear that a parallel transport compatible with the metric has to preserve angles and length, and we can see geometrically it very well. But that is not enough in order to define it unequivocally, so, we are asking also zero torsion. How can we interpret it geometrically? Writing it very roughly, if we have an ant walking straight ahead (i.e. on a geodesic) on a $\mathbb{R}^2$ plane with a metric fom: $ds^2 = a(x,y)dx^2 + b(x,y)dxdy+c(x,y)dy^2$ how does it moves? Let's say that it calculates the new direction at each (very little) step EDIT: I add an image for making it clear: we have a mesh of the surface, and on each cell the metric form is just $G^i=a^idx^2 + b^idxdy+c^idy^2$ with $a^i,b^i,c^i \in \mathbb{R}$ linear coefficient. The ant is walking from the cell $1$ to cell $2$: how does its direction change? I think that there is an analogy with refraction of light, which could be considered as the case where the metric tensor is in the form $g_{\mu \nu}=\phi(x)\delta_{\mu \nu}$",,"['differential-geometry', 'riemannian-geometry', 'connections']"
55,About the second fundamental form,About the second fundamental form,,"Let $U\subset\mathbb R^3$ be an open set, and $f:U\to \mathbb R$ be a smooth function. Suppose that the level set $S=f^{-1}(\{0\})$ is non-empty, and that at each $p\in S,$ the gradient $\overrightarrow \nabla f(p)$ is not the zero vector. Then $S$ is a smooth two-dimensional surface in $U$, and $p\mapsto \overrightarrow \eta(p)=\frac{1}{||\overrightarrow \nabla f(p)||}\overrightarrow \nabla f(p)$ defines a smooth unit-length normal vector field along $S$. At each $x\in U,$ write $H(f)_{(x)}$ for the $3\times 3$ Hessian matrix specified by $$(H(f)_{(x)})_{ij}=\frac{\partial^2f}{\partial x_i\partial x_j}(x).$$ Show that , at each $p\in S$, the second fundamental form $II_p: T_p(s)\times T_p(s)\to \mathbb R$ is the symmetric bilinear map    $$II_p(\overrightarrow v,\overrightarrow w)=\frac{-1}{||\overrightarrow \nabla f(p)||}\overrightarrow v\cdot H(f)_{(p)}\overrightarrow w,$$for all $\overrightarrow v ,\overrightarrow w \in T_p(s)$. (Here, we view the tagent space $T_p(S)$ as the two-dimensional subspace $(span\{ {\overrightarrow \eta(p)}\})^{\bot}$ of $\mathbb R^3$. Edit: Actually my question is why the second fundamental form under the usual definition can be written in this way. Definition : The quadratic form $II_p$, defined in $T_p(S)$ by $II_p(v)=-<d  N_p(v),v>$ is called the second fundamental form of $S$ at $p$, where $dN_p:T_p(S)\to T_p(S)$ is the differential of the Gauss map. Hopefully, I express this problem explicitly. I was just wondering how to prove this statement. I took a diffrential geometry class last semester, and when I organized my notes this morning, I found this statement, but there was no proof... Looking forward to an understandable explaination. Thanks in advance. Edit 2 :Furthermore, show that , at each point $p\in S$, the expression   $$\phi_p(z)=det\pmatrix{-H(f)_{(p)}-zI_{3\times 3} & \overrightarrow \nabla f(p)\\\ \pm \overrightarrow \nabla f(p)& 0}$$   (the underlying matrix here is $4\times 4$) defines a second-degree polynomial whose roots $\lambda_1$ and $\lambda_2$ are $||\overrightarrow \nabla f(p)||k_1$ and $||\overrightarrow \nabla f(p)||k_2$, where $k_1$ and $k_2$ are the principal curvatures of $S$ at $p$. Also , if a non-zero vector $\pmatrix {\overrightarrow v \\c}$ lies in the kernel of the $4\times 4$ matrix $$\pmatrix{-H(f)_{(p)}-\lambda_jI_{3\times 3} & \overrightarrow \nabla f(p)\\\ \pm \overrightarrow \nabla f(p)& 0},$$   then $\vec v$ is a non-zero element of $T_p(S)$ and lies in the ""principal direction"" corresponding to $K_j$.","Let $U\subset\mathbb R^3$ be an open set, and $f:U\to \mathbb R$ be a smooth function. Suppose that the level set $S=f^{-1}(\{0\})$ is non-empty, and that at each $p\in S,$ the gradient $\overrightarrow \nabla f(p)$ is not the zero vector. Then $S$ is a smooth two-dimensional surface in $U$, and $p\mapsto \overrightarrow \eta(p)=\frac{1}{||\overrightarrow \nabla f(p)||}\overrightarrow \nabla f(p)$ defines a smooth unit-length normal vector field along $S$. At each $x\in U,$ write $H(f)_{(x)}$ for the $3\times 3$ Hessian matrix specified by $$(H(f)_{(x)})_{ij}=\frac{\partial^2f}{\partial x_i\partial x_j}(x).$$ Show that , at each $p\in S$, the second fundamental form $II_p: T_p(s)\times T_p(s)\to \mathbb R$ is the symmetric bilinear map    $$II_p(\overrightarrow v,\overrightarrow w)=\frac{-1}{||\overrightarrow \nabla f(p)||}\overrightarrow v\cdot H(f)_{(p)}\overrightarrow w,$$for all $\overrightarrow v ,\overrightarrow w \in T_p(s)$. (Here, we view the tagent space $T_p(S)$ as the two-dimensional subspace $(span\{ {\overrightarrow \eta(p)}\})^{\bot}$ of $\mathbb R^3$. Edit: Actually my question is why the second fundamental form under the usual definition can be written in this way. Definition : The quadratic form $II_p$, defined in $T_p(S)$ by $II_p(v)=-<d  N_p(v),v>$ is called the second fundamental form of $S$ at $p$, where $dN_p:T_p(S)\to T_p(S)$ is the differential of the Gauss map. Hopefully, I express this problem explicitly. I was just wondering how to prove this statement. I took a diffrential geometry class last semester, and when I organized my notes this morning, I found this statement, but there was no proof... Looking forward to an understandable explaination. Thanks in advance. Edit 2 :Furthermore, show that , at each point $p\in S$, the expression   $$\phi_p(z)=det\pmatrix{-H(f)_{(p)}-zI_{3\times 3} & \overrightarrow \nabla f(p)\\\ \pm \overrightarrow \nabla f(p)& 0}$$   (the underlying matrix here is $4\times 4$) defines a second-degree polynomial whose roots $\lambda_1$ and $\lambda_2$ are $||\overrightarrow \nabla f(p)||k_1$ and $||\overrightarrow \nabla f(p)||k_2$, where $k_1$ and $k_2$ are the principal curvatures of $S$ at $p$. Also , if a non-zero vector $\pmatrix {\overrightarrow v \\c}$ lies in the kernel of the $4\times 4$ matrix $$\pmatrix{-H(f)_{(p)}-\lambda_jI_{3\times 3} & \overrightarrow \nabla f(p)\\\ \pm \overrightarrow \nabla f(p)& 0},$$   then $\vec v$ is a non-zero element of $T_p(S)$ and lies in the ""principal direction"" corresponding to $K_j$.",,['differential-geometry']
56,Finding two tangential vectorfields with Lie-Bracket equal zero,Finding two tangential vectorfields with Lie-Bracket equal zero,,"I've been dealing with the following problem for a while and meanwhile I have no idea how to move on. Maybe one of you can help me? :) Let $M = \mathbb{R}^2\subset \mathbb{R}^3$ a manifold.  I need to find two tangent-vectorfields $\xi, \eta$ such that (i) $[\xi,\eta]=0$, but $\nabla_{\xi}\eta \neq 0$ at at least one point P (ii)$[\xi,\eta]\neq0$, but $\nabla_{\xi}\eta = 0$ at at least one point P First I calculated (for an arbitrary function $\phi$ and $\xi := \xi_1 \frac{\partial}{\partial x}+\xi_2 \frac{\partial}{\partial y}$, $\eta := \eta_1 \frac{\partial}{\partial x}+\eta_2 \frac{\partial}{\partial y}$): $[\xi,\eta] = ... = \frac{\partial \phi}{\partial x} \left[ \xi_1 \frac{\partial \eta_1}{\partial x} + \xi_2 \frac{\partial \eta_1}{\partial y}- \eta_1 \frac{\partial \xi_1}{\partial x} - \eta_2 \frac{\partial \xi_1}{\partial y}\right] + \frac{\partial \phi}{\partial y} \left[ \xi_1 \frac{\partial \eta_2}{\partial x} + \xi_2 \frac{\partial \eta_2}{\partial y}- \eta_1 \frac{\partial \xi_2}{\partial x} - \eta_2 \frac{\partial \xi_2}{\partial y}\right]$ For (ii) I get by using $\nabla_{\xi} = \nabla_{ \xi_1 \frac{\partial}{\partial x}+\xi_2 \frac{\partial}{\partial y}} = \xi_1 \nabla_{\frac{\partial}{\partial x}}+\xi_2 \nabla_{\frac{\partial}{\partial y}}$ for continous $\xi_i$ and $\eta_i$: $\nabla_{\xi}\eta = 0 \Leftrightarrow \xi_1(\frac{\partial \eta}{\partial x} <\frac{\partial \eta}{\partial x},n> + \xi_2(\frac{\partial \eta}{\partial y} <\frac{\partial \eta}{\partial y},n> = 0 $ Due to the normal vector $n$ has only a z direction because $M=\mathbb{R}^2$, the scalar product is zero and we get: $\xi_1 \frac{\partial \eta}{\partial x} + \xi_2 \frac{\partial \eta}{\partial y} = 0$ So the equation above simplifies to: $\frac{\partial \phi}{\partial x} \left[- \eta_1 \frac{\partial \xi_1}{\partial x} - \eta_2 \frac{\partial \xi_1}{\partial y}\right] + \frac{\partial \phi}{\partial y} \left[ - \eta_1 \frac{\partial \xi_2}{\partial x} - \eta_2 \frac{\partial \xi_2}{\partial y}\right] \neq 0$ Both of the brackets have to be nonzero, so the solution of these two equations gives the solution. Is this right so far? How, beside try and error, can I find out the solution of this equations? How does it work for (i)? In this case I can't eliminate anything from the first equation, because the second condition then is not equal Zero. Thanks a lot for your help!","I've been dealing with the following problem for a while and meanwhile I have no idea how to move on. Maybe one of you can help me? :) Let $M = \mathbb{R}^2\subset \mathbb{R}^3$ a manifold.  I need to find two tangent-vectorfields $\xi, \eta$ such that (i) $[\xi,\eta]=0$, but $\nabla_{\xi}\eta \neq 0$ at at least one point P (ii)$[\xi,\eta]\neq0$, but $\nabla_{\xi}\eta = 0$ at at least one point P First I calculated (for an arbitrary function $\phi$ and $\xi := \xi_1 \frac{\partial}{\partial x}+\xi_2 \frac{\partial}{\partial y}$, $\eta := \eta_1 \frac{\partial}{\partial x}+\eta_2 \frac{\partial}{\partial y}$): $[\xi,\eta] = ... = \frac{\partial \phi}{\partial x} \left[ \xi_1 \frac{\partial \eta_1}{\partial x} + \xi_2 \frac{\partial \eta_1}{\partial y}- \eta_1 \frac{\partial \xi_1}{\partial x} - \eta_2 \frac{\partial \xi_1}{\partial y}\right] + \frac{\partial \phi}{\partial y} \left[ \xi_1 \frac{\partial \eta_2}{\partial x} + \xi_2 \frac{\partial \eta_2}{\partial y}- \eta_1 \frac{\partial \xi_2}{\partial x} - \eta_2 \frac{\partial \xi_2}{\partial y}\right]$ For (ii) I get by using $\nabla_{\xi} = \nabla_{ \xi_1 \frac{\partial}{\partial x}+\xi_2 \frac{\partial}{\partial y}} = \xi_1 \nabla_{\frac{\partial}{\partial x}}+\xi_2 \nabla_{\frac{\partial}{\partial y}}$ for continous $\xi_i$ and $\eta_i$: $\nabla_{\xi}\eta = 0 \Leftrightarrow \xi_1(\frac{\partial \eta}{\partial x} <\frac{\partial \eta}{\partial x},n> + \xi_2(\frac{\partial \eta}{\partial y} <\frac{\partial \eta}{\partial y},n> = 0 $ Due to the normal vector $n$ has only a z direction because $M=\mathbb{R}^2$, the scalar product is zero and we get: $\xi_1 \frac{\partial \eta}{\partial x} + \xi_2 \frac{\partial \eta}{\partial y} = 0$ So the equation above simplifies to: $\frac{\partial \phi}{\partial x} \left[- \eta_1 \frac{\partial \xi_1}{\partial x} - \eta_2 \frac{\partial \xi_1}{\partial y}\right] + \frac{\partial \phi}{\partial y} \left[ - \eta_1 \frac{\partial \xi_2}{\partial x} - \eta_2 \frac{\partial \xi_2}{\partial y}\right] \neq 0$ Both of the brackets have to be nonzero, so the solution of these two equations gives the solution. Is this right so far? How, beside try and error, can I find out the solution of this equations? How does it work for (i)? In this case I can't eliminate anything from the first equation, because the second condition then is not equal Zero. Thanks a lot for your help!",,"['differential-geometry', 'manifolds', 'lie-groups', 'covariance', 'tangent-bundle']"
57,Condition for Ehresmann connection to be linear,Condition for Ehresmann connection to be linear,,"I am trying to get more familiar with Ehresmann-connections by looking at how they look like in local trivializations. I am roughly aware of the abstract theory, but not everything is immediately clear, hence this ""investigation"". Now, let $M$ be a smooth $n$ dimensional (real) manifold and let $\pi:E\rightarrow M$ be a rank $k$ vector bundle. Local trivializations are identified with local frames of $E$. A generic local section is written as $\psi=\psi^Ae_A$ and the index notation conventions of Einstein and Schouten are employed. A bundle chart for $E$ then looks like $(x^\mu,\psi^A)_{\mu=1,...,n;\ A=1,...,k}$, with a common domain $U$ for both the local chart on $M$ and the local trivialization of $E$ (this domain will be left implicit in this post). If a Koszul connection on $E$ is given locally by $$ \nabla_\mu\psi^A=\partial_\mu\psi^A+\omega_{\mu\ \ B}^{\ A}\psi^B, $$ then this connection determines an Ehresmann-connection on $E$ by letting $$ H_{(x,\psi)}=\text{span}(D_\mu), $$ where $$ D_\mu=\frac{\partial}{\partial x^\mu}-\omega_{\mu\ \ B}^{\ A}\psi^B\frac{\partial}{\partial\psi^A}. $$ This much is clear. However, something's unclear if I try to work the other way around . We can define the canonically existing vertical distribution as $$ V_{(x,\psi)}=\text{span}\left\{\frac{\partial}{\partial\psi^A}\right\}, $$ and is easily verified that this is independent of the local trivialization. Now, let's try to define a horizontal distribution locally as $$ H_{(x,\psi)}=\text{span}\{D_\mu\}, $$ where I look for $D_\mu$ in the form $$  D_\mu=\frac{\partial}{\partial x^\mu}+Q^A_\mu\frac{\partial}{\partial\psi^A}.$$ The reason I am looking for the horizontal frame in this form is that, the presence of $\partial/\partial x^\mu$ will ensure that $D_\mu$ can never be vertical. Question 1: If I am interested in the most general Ehresmann connection on $E$ (linearity is not assumed), is this true that any horizontal distribution has a frame in this form? Now, going further, I want to ensure that my connection is linear , in the sense that parallel transport is linear. It is natural, then that I should demand $Q^A_\mu(x,\psi)$  to have only linear dependence on the fiber coordinates, so $Q^A_\mu=-\omega^{\ A}_{\mu\ \ B}(x)\psi^B$. This will obviously give back what I started from (the covariant derivative). My problem is that Lee (Jeffrey, author of Manifolds and Differential Geometry , not to be confused with John Lee) states in the aforementioned book that the only condition for an Ehresmann connection on $E$ to be a linear connection is that it respects scalar multiplication , eg. that $(S_\lambda)_*H_{(x,\psi)}=H_{(x,\lambda\psi)}$ where $S_\lambda$ is multiplication by the scalar $\lambda$. I guess that in my own approach/notation, this means that $Q^A_\mu(x,\psi)$ is a homogenous function (of degree 1) of $\psi$. However, as far as I am aware, homogenity does not necessarily imply linearity. Question 2: What is the necessary condition for $H$ to be a linear Ehresmann-connection? Is Lee right or wrong? If he is right, then how does the form $D_\mu=\partial_\mu-\omega_{\mu\ \ B}^{\ A}\psi^B\partial_A$ come from a homogenous $Q^A_\mu$? Am I doing everything correctly?","I am trying to get more familiar with Ehresmann-connections by looking at how they look like in local trivializations. I am roughly aware of the abstract theory, but not everything is immediately clear, hence this ""investigation"". Now, let $M$ be a smooth $n$ dimensional (real) manifold and let $\pi:E\rightarrow M$ be a rank $k$ vector bundle. Local trivializations are identified with local frames of $E$. A generic local section is written as $\psi=\psi^Ae_A$ and the index notation conventions of Einstein and Schouten are employed. A bundle chart for $E$ then looks like $(x^\mu,\psi^A)_{\mu=1,...,n;\ A=1,...,k}$, with a common domain $U$ for both the local chart on $M$ and the local trivialization of $E$ (this domain will be left implicit in this post). If a Koszul connection on $E$ is given locally by $$ \nabla_\mu\psi^A=\partial_\mu\psi^A+\omega_{\mu\ \ B}^{\ A}\psi^B, $$ then this connection determines an Ehresmann-connection on $E$ by letting $$ H_{(x,\psi)}=\text{span}(D_\mu), $$ where $$ D_\mu=\frac{\partial}{\partial x^\mu}-\omega_{\mu\ \ B}^{\ A}\psi^B\frac{\partial}{\partial\psi^A}. $$ This much is clear. However, something's unclear if I try to work the other way around . We can define the canonically existing vertical distribution as $$ V_{(x,\psi)}=\text{span}\left\{\frac{\partial}{\partial\psi^A}\right\}, $$ and is easily verified that this is independent of the local trivialization. Now, let's try to define a horizontal distribution locally as $$ H_{(x,\psi)}=\text{span}\{D_\mu\}, $$ where I look for $D_\mu$ in the form $$  D_\mu=\frac{\partial}{\partial x^\mu}+Q^A_\mu\frac{\partial}{\partial\psi^A}.$$ The reason I am looking for the horizontal frame in this form is that, the presence of $\partial/\partial x^\mu$ will ensure that $D_\mu$ can never be vertical. Question 1: If I am interested in the most general Ehresmann connection on $E$ (linearity is not assumed), is this true that any horizontal distribution has a frame in this form? Now, going further, I want to ensure that my connection is linear , in the sense that parallel transport is linear. It is natural, then that I should demand $Q^A_\mu(x,\psi)$  to have only linear dependence on the fiber coordinates, so $Q^A_\mu=-\omega^{\ A}_{\mu\ \ B}(x)\psi^B$. This will obviously give back what I started from (the covariant derivative). My problem is that Lee (Jeffrey, author of Manifolds and Differential Geometry , not to be confused with John Lee) states in the aforementioned book that the only condition for an Ehresmann connection on $E$ to be a linear connection is that it respects scalar multiplication , eg. that $(S_\lambda)_*H_{(x,\psi)}=H_{(x,\lambda\psi)}$ where $S_\lambda$ is multiplication by the scalar $\lambda$. I guess that in my own approach/notation, this means that $Q^A_\mu(x,\psi)$ is a homogenous function (of degree 1) of $\psi$. However, as far as I am aware, homogenity does not necessarily imply linearity. Question 2: What is the necessary condition for $H$ to be a linear Ehresmann-connection? Is Lee right or wrong? If he is right, then how does the form $D_\mu=\partial_\mu-\omega_{\mu\ \ B}^{\ A}\psi^B\partial_A$ come from a homogenous $Q^A_\mu$? Am I doing everything correctly?",,"['differential-geometry', 'vector-bundles', 'fiber-bundles', 'connections']"
58,Geodesics of manifold and geodesics of its submanifold with induced metric,Geodesics of manifold and geodesics of its submanifold with induced metric,,"Suppose we have a riemmanian manifold $(\mathcal{M}, g)$. Let $\mathcal{N}$ be properly embedded submanifold of $\mathcal{M}$ with induced metric $\bar{g}$ from   $g$. ($\mathcal{N}$ is not necessarily totally geodesic manifold.) Let $a, b \in \mathcal{N} \subset \mathcal{M}$ be two distinct points. Say $\gamma(t)$ is unique geodesic curve on $\mathcal{M}$ with metric $g$ and $\bar{\gamma}(t)$ is also unique geodesic curve on $\mathcal{N}$ with metric $\bar{g}$ with $\gamma(0) = \bar{\gamma}(0) = a$ and $\gamma(1) = \bar{\gamma}(1) = b$. Question : If $c(t) \in \mathcal{N}$ is the closest point from $\gamma(t)\in\mathcal{M}$ to submanifold $\mathcal{N}$, then does $c(t)$ always belong to geodesic curve $\bar{\gamma}$? Actually, this is just my guess, since it holds true for $\mathcal{M} = R^{3}$, $\mathcal{N} = S^{2}$. Is it generally true? or for what condition does it hold true? Curious whether there is some relevant theorem regarding this...","Suppose we have a riemmanian manifold $(\mathcal{M}, g)$. Let $\mathcal{N}$ be properly embedded submanifold of $\mathcal{M}$ with induced metric $\bar{g}$ from   $g$. ($\mathcal{N}$ is not necessarily totally geodesic manifold.) Let $a, b \in \mathcal{N} \subset \mathcal{M}$ be two distinct points. Say $\gamma(t)$ is unique geodesic curve on $\mathcal{M}$ with metric $g$ and $\bar{\gamma}(t)$ is also unique geodesic curve on $\mathcal{N}$ with metric $\bar{g}$ with $\gamma(0) = \bar{\gamma}(0) = a$ and $\gamma(1) = \bar{\gamma}(1) = b$. Question : If $c(t) \in \mathcal{N}$ is the closest point from $\gamma(t)\in\mathcal{M}$ to submanifold $\mathcal{N}$, then does $c(t)$ always belong to geodesic curve $\bar{\gamma}$? Actually, this is just my guess, since it holds true for $\mathcal{M} = R^{3}$, $\mathcal{N} = S^{2}$. Is it generally true? or for what condition does it hold true? Curious whether there is some relevant theorem regarding this...",,"['differential-geometry', 'riemannian-geometry', 'geodesic', 'submanifold']"
59,Possible manifold quotients of spheres by finite isometric actions,Possible manifold quotients of spheres by finite isometric actions,,"Suppose I have an isometric action by a finite group on the standard round sphere $S^n$ so that the quotient $S^n/\Gamma$ is a smooth manifold. First, does this imply that the action is free? I know the converse is true, but it is not clear to me that the quotient being a smooth manifold implies that the action was free. Second, what are the possible (smooth) quotients? Certainly one sees both $S^n$ (trivial action) and $\mathbb{RP}^n$ ($\mathbb{Z}_2$ action), but are these the only ones?","Suppose I have an isometric action by a finite group on the standard round sphere $S^n$ so that the quotient $S^n/\Gamma$ is a smooth manifold. First, does this imply that the action is free? I know the converse is true, but it is not clear to me that the quotient being a smooth manifold implies that the action was free. Second, what are the possible (smooth) quotients? Certainly one sees both $S^n$ (trivial action) and $\mathbb{RP}^n$ ($\mathbb{Z}_2$ action), but are these the only ones?",,"['differential-geometry', 'riemannian-geometry', 'differential-topology', 'group-actions', 'quotient-spaces']"
60,Submanifold realization of differential forms - finding a submanifold which nontrivially intersect another submanifold,Submanifold realization of differential forms - finding a submanifold which nontrivially intersect another submanifold,,"While trying to prove de Rham's theorem on my own, I came up with the following question: If $M$ is a closed orientable $n-$manifold and $X$ is a closed   orientable $p$-submanifold of $M$ which represents a nontrivial   element of the $p$-th homology group of $M$, then is there a closed   orientable $(n-p)$-submanifold $Y$ of $M$ whose oriented   intersection number with $X$ is nonzero? I wish to know whether the above statement is true, and if it is false, then what some simple counterexamples are. Thank you in advance! Well, let me add a few words on how I came up with the question. I was trying to prove de Rham's theorem, which says that the natural map $i:H_{dR}^p(M;\mathbb{R})\rightarrow H_p(M;\mathbb{R})^*\simeq H^p(M;\mathbb{R})$ is an isomorphism. In order to prove surjectivity, I first wanted to show that if $[X]\in H_p(M;\mathbb{R})$ is a nontrivial element of the homology, then there is an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ that ""detects"" such nontrivial homology. In attempting to prove the last statement, I divided the statement into two parts: Find an element $Y\in H_{n-p}(M;\mathbb{R})$ such that $I(X, Y) \neq 0$ where $I(X,Y)$ is the oriented intersection number beween $X$ and $Y$. (Then $I(-,Y)$ is a linear functional on $H_p(M;\mathbb{R})$ under which the image of $X$ is nonzero.) Find an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ such that $\omega(X)=I(X,Y)$. At this moment, I am not even sure if either of the above two statement (finding $Y$ and finding $[\omega]$) is valid or not. But anyway I found this quite interesting, and from this I hope to understand better about the interaction between the oriented intersection number (defined differential topologically) and the de Rham cohomology.","While trying to prove de Rham's theorem on my own, I came up with the following question: If $M$ is a closed orientable $n-$manifold and $X$ is a closed   orientable $p$-submanifold of $M$ which represents a nontrivial   element of the $p$-th homology group of $M$, then is there a closed   orientable $(n-p)$-submanifold $Y$ of $M$ whose oriented   intersection number with $X$ is nonzero? I wish to know whether the above statement is true, and if it is false, then what some simple counterexamples are. Thank you in advance! Well, let me add a few words on how I came up with the question. I was trying to prove de Rham's theorem, which says that the natural map $i:H_{dR}^p(M;\mathbb{R})\rightarrow H_p(M;\mathbb{R})^*\simeq H^p(M;\mathbb{R})$ is an isomorphism. In order to prove surjectivity, I first wanted to show that if $[X]\in H_p(M;\mathbb{R})$ is a nontrivial element of the homology, then there is an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ that ""detects"" such nontrivial homology. In attempting to prove the last statement, I divided the statement into two parts: Find an element $Y\in H_{n-p}(M;\mathbb{R})$ such that $I(X, Y) \neq 0$ where $I(X,Y)$ is the oriented intersection number beween $X$ and $Y$. (Then $I(-,Y)$ is a linear functional on $H_p(M;\mathbb{R})$ under which the image of $X$ is nonzero.) Find an element $[\omega]\in H_{dR}^p(M;\mathbb{R})$ such that $\omega(X)=I(X,Y)$. At this moment, I am not even sure if either of the above two statement (finding $Y$ and finding $[\omega]$) is valid or not. But anyway I found this quite interesting, and from this I hope to understand better about the interaction between the oriented intersection number (defined differential topologically) and the de Rham cohomology.",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'homology-cohomology', 'smooth-manifolds']"
61,Reference for computing sheaf cohomology of constructible sheaves by \v{C}ech cohomology?,Reference for computing sheaf cohomology of constructible sheaves by \v{C}ech cohomology?,,"Let $X$ be a topological space. A stratification of $X$ is a decomposition into a collection of subsets $X = \amalg_i \ X_i$ (called strata) such that $X_i$'s are open in its closure, and $\partial X_i = \overline{X_i} \setminus X_i$ is again a disjiont union of strata. A sheaf $\mathcal{F}$ on $X$ is constructible with respect to a stratification $\amalg \ X_i$ if $\mathcal{F}\big|_{X_i}$ are locally constant sheaves for all $i$. I heard if the stratification satisfies some conditions, then we can calculate $H^i(X;\mathcal{F})$ by using the \v{C}ech complex of a certain open cover associated to the stratification. Does anyone know if there's reference about this? Or maybe the details are not hard? By the way, I know there's probably a page in Stack Project about this. But I concern more about manifold so I'm looking for one with more topological setting. Thanks.","Let $X$ be a topological space. A stratification of $X$ is a decomposition into a collection of subsets $X = \amalg_i \ X_i$ (called strata) such that $X_i$'s are open in its closure, and $\partial X_i = \overline{X_i} \setminus X_i$ is again a disjiont union of strata. A sheaf $\mathcal{F}$ on $X$ is constructible with respect to a stratification $\amalg \ X_i$ if $\mathcal{F}\big|_{X_i}$ are locally constant sheaves for all $i$. I heard if the stratification satisfies some conditions, then we can calculate $H^i(X;\mathcal{F})$ by using the \v{C}ech complex of a certain open cover associated to the stratification. Does anyone know if there's reference about this? Or maybe the details are not hard? By the way, I know there's probably a page in Stack Project about this. But I concern more about manifold so I'm looking for one with more topological setting. Thanks.",,"['differential-geometry', 'reference-request', 'algebraic-topology', 'complex-geometry', 'sheaf-theory']"
62,Fixed points of an involution,Fixed points of an involution,,"Let $V=\mathbb C^{2n}$ with the standard basis $\{e_1,e_2, \cdots , e_{2n}\}$ and let $\sigma$ be the involution $e_i \mapsto -e_{2n+1-i}$. This induces an involution of the Grassmannian $G(n,2n)$ of $n$ dimensional subspaces of $\mathbb C^{2n}$. Then what are the fixed points of this involution ? Does it have a nice structure ?","Let $V=\mathbb C^{2n}$ with the standard basis $\{e_1,e_2, \cdots , e_{2n}\}$ and let $\sigma$ be the involution $e_i \mapsto -e_{2n+1-i}$. This induces an involution of the Grassmannian $G(n,2n)$ of $n$ dimensional subspaces of $\mathbb C^{2n}$. Then what are the fixed points of this involution ? Does it have a nice structure ?",,"['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'representation-theory', 'projective-geometry']"
63,Change of variables for integration on manifolds,Change of variables for integration on manifolds,,"Let $M$ be an $n$ dimensional smooth manifold in $\mathbb{R}^N$, $n<N$. Let $V$ be $n$ dimensional Lebesgue volume measure. Let $f$ be a smooth injective map from $\mathbb{R}^N$ to $\mathbb{R}^N$ (note that it is $N$ not $n$) such that $f(M)$ is a transformed $n$ dimensional manifold in $\mathbb{R}^N$. Let $J_f(x)$ be the determinant of $(\frac{\partial f_i}{\partial x_j})_{1\leq i \leq N, 1 \leq j \leq N}$. Can we use the change of variable $z=f(x)$ to have the following integration on manifold:  \begin{align} \int_{f(M)} g(z)dV(z) = \int_{M} |J_f(x)| g(f(x))dV(x), \end{align} for a smooth integrable function $g$? In a simple case, suppose $M$ is a line in $\mathbb{R}^2$ connecting $(0,0)$ and $(1,1)$. Let $f(x_1,x_2)=(\alpha x_1, \beta x_2)^\prime$, i.e. $f$ rescales the x,y coordinate by $\alpha,\beta>0$ respectively. Then $J_f$ should be $\alpha\beta$. Since $f(M)$ is a line connecting $(0,0)$ and $(\alpha,\beta)$, we should have $\int_{f(M)} dV(z) = \sqrt{\alpha^2+\beta^2}$, while $ \int_{M} |J_f(x)| dV(x) = \sqrt{2}\alpha\beta$. What should be the correct form of the above change of variables formula, using the ''Jacobian'' $J_f$?","Let $M$ be an $n$ dimensional smooth manifold in $\mathbb{R}^N$, $n<N$. Let $V$ be $n$ dimensional Lebesgue volume measure. Let $f$ be a smooth injective map from $\mathbb{R}^N$ to $\mathbb{R}^N$ (note that it is $N$ not $n$) such that $f(M)$ is a transformed $n$ dimensional manifold in $\mathbb{R}^N$. Let $J_f(x)$ be the determinant of $(\frac{\partial f_i}{\partial x_j})_{1\leq i \leq N, 1 \leq j \leq N}$. Can we use the change of variable $z=f(x)$ to have the following integration on manifold:  \begin{align} \int_{f(M)} g(z)dV(z) = \int_{M} |J_f(x)| g(f(x))dV(x), \end{align} for a smooth integrable function $g$? In a simple case, suppose $M$ is a line in $\mathbb{R}^2$ connecting $(0,0)$ and $(1,1)$. Let $f(x_1,x_2)=(\alpha x_1, \beta x_2)^\prime$, i.e. $f$ rescales the x,y coordinate by $\alpha,\beta>0$ respectively. Then $J_f$ should be $\alpha\beta$. Since $f(M)$ is a line connecting $(0,0)$ and $(\alpha,\beta)$, we should have $\int_{f(M)} dV(z) = \sqrt{\alpha^2+\beta^2}$, while $ \int_{M} |J_f(x)| dV(x) = \sqrt{2}\alpha\beta$. What should be the correct form of the above change of variables formula, using the ''Jacobian'' $J_f$?",,"['differential-geometry', 'riemannian-geometry']"
64,Existence of a potential for given exact form satisfying symmetry conditions,Existence of a potential for given exact form satisfying symmetry conditions,,"Suppose that $\omega$ is an exact differential form satisfying $L_X \omega=0$ for $X$ in some Lie algebra of vector fields. When can I find $\eta$ such that $\omega=d \eta$ and $L_X \eta=0?$ What are the obstructions for this problem? Motivating example: Manifold $\mathbb R^2$, $\omega=dx \wedge dy $. I can find $\eta = \frac{1}{2} ( x dy - y dx )$ which is rotationally symmetric, $\eta = x dy$ which is invariant with respect to  translations in $y$ and $\eta= -y dx$ which is invariant with respect to translations in $x$ direction. Finding $\eta$ with all these symmetries is impossible. Formulation in the language of cohomology: Since Lie derivatives commutes with exterior derivative, algebra of differential forms invariant under an action of given group forms a chain subcomplex of de Rham complex. The question essentially asks what can be said about its cohomology. As noted in comments by Ted Shifrin, in the case of compact groups invariant potential can be found by averaging action of a group on one potential (with respect to Haar measure). This is nice and useful point, but now case of noncompact groups remains.","Suppose that $\omega$ is an exact differential form satisfying $L_X \omega=0$ for $X$ in some Lie algebra of vector fields. When can I find $\eta$ such that $\omega=d \eta$ and $L_X \eta=0?$ What are the obstructions for this problem? Motivating example: Manifold $\mathbb R^2$, $\omega=dx \wedge dy $. I can find $\eta = \frac{1}{2} ( x dy - y dx )$ which is rotationally symmetric, $\eta = x dy$ which is invariant with respect to  translations in $y$ and $\eta= -y dx$ which is invariant with respect to translations in $x$ direction. Finding $\eta$ with all these symmetries is impossible. Formulation in the language of cohomology: Since Lie derivatives commutes with exterior derivative, algebra of differential forms invariant under an action of given group forms a chain subcomplex of de Rham complex. The question essentially asks what can be said about its cohomology. As noted in comments by Ted Shifrin, in the case of compact groups invariant potential can be found by averaging action of a group on one potential (with respect to Haar measure). This is nice and useful point, but now case of noncompact groups remains.",,"['differential-geometry', 'homology-cohomology', 'differential-forms', 'symmetry', 'lie-derivative']"
65,On the definition of ugly manifolds,On the definition of ugly manifolds,,"Let $X$ be a subset of a (finite dimensional) Banach space $E$. Let's call a function $f\colon X\longrightarrow \mathbb{K}$ smooth (in whatever sense we are interested in) if there is an open neighbourhood $X\subseteq U\subseteq E$ of $X$ and a smooth function $\widetilde{f}\colon U\longrightarrow\mathbb{K}$ such that $\widetilde{f}|_{X}=f$. Then $X$ with the induced topology and the sheaf defined by $\mathcal{C}_X^\infty(V)=\left\{\text{Smooth functions }V\longrightarrow \mathbb{K}\big.\right\}$ forms a locally $\mathbb{K}$-ringed space. Let us define an ugly manifold to be a locally $\mathbb{K}$-ringed space which is locally isomorphic to a locally ringed space of the form $(X,\mathcal{C}_X^\infty)$, where $X$ is any subset of a (finite dimensional) Banach space. A manifold is a locally ringed space, locally isomorphic to $(U,\mathcal{C}_U^\infty)$ for some open subset $U$ of a Banach space. A manifold with boundary is a locally $\mathbb{R}$-ringed space, locally isomorphic to $(X,\mathcal{C}_X^\infty)$, where $X=\left\{x\in E\ \middle|\ \lambda(x)\ge 0\right\}$, for $E$ a Banach space and $\lambda$ some continous linear form on $E$; and similarly a manifold with corners can be defined. So my questions is: Which properties of open subsets, half spaces and corners spaces (if this is the correct word) are essential for the theory of manifolds to work. What breaks down for ugly manifolds? tangent spaces, differential forms, etc. come to mind here. Is there a class of subsets of (finite dimensional) Banach spaces, which lead to nice manifolds and yield a more flexible category? For example not like manifolds with boundary, which are not closed under products. Note that I know almost nothing about analysis; in particular I haven't yet taken a course on real analysis or something like that. I've only read most of Torsten Wedhorn's book Manifolds, Sheaves and Cohomology since I am more an algebraically minded type of person, so I'd appreciate, if your answer was accessible to such.","Let $X$ be a subset of a (finite dimensional) Banach space $E$. Let's call a function $f\colon X\longrightarrow \mathbb{K}$ smooth (in whatever sense we are interested in) if there is an open neighbourhood $X\subseteq U\subseteq E$ of $X$ and a smooth function $\widetilde{f}\colon U\longrightarrow\mathbb{K}$ such that $\widetilde{f}|_{X}=f$. Then $X$ with the induced topology and the sheaf defined by $\mathcal{C}_X^\infty(V)=\left\{\text{Smooth functions }V\longrightarrow \mathbb{K}\big.\right\}$ forms a locally $\mathbb{K}$-ringed space. Let us define an ugly manifold to be a locally $\mathbb{K}$-ringed space which is locally isomorphic to a locally ringed space of the form $(X,\mathcal{C}_X^\infty)$, where $X$ is any subset of a (finite dimensional) Banach space. A manifold is a locally ringed space, locally isomorphic to $(U,\mathcal{C}_U^\infty)$ for some open subset $U$ of a Banach space. A manifold with boundary is a locally $\mathbb{R}$-ringed space, locally isomorphic to $(X,\mathcal{C}_X^\infty)$, where $X=\left\{x\in E\ \middle|\ \lambda(x)\ge 0\right\}$, for $E$ a Banach space and $\lambda$ some continous linear form on $E$; and similarly a manifold with corners can be defined. So my questions is: Which properties of open subsets, half spaces and corners spaces (if this is the correct word) are essential for the theory of manifolds to work. What breaks down for ugly manifolds? tangent spaces, differential forms, etc. come to mind here. Is there a class of subsets of (finite dimensional) Banach spaces, which lead to nice manifolds and yield a more flexible category? For example not like manifolds with boundary, which are not closed under products. Note that I know almost nothing about analysis; in particular I haven't yet taken a course on real analysis or something like that. I've only read most of Torsten Wedhorn's book Manifolds, Sheaves and Cohomology since I am more an algebraically minded type of person, so I'd appreciate, if your answer was accessible to such.",,['differential-geometry']
66,How was Cartan's magic formula originally found?,How was Cartan's magic formula originally found?,,"The standard proof of Cartan's magic formula is to study derivations of the exterior algebra. One can relatively easily find that a derivation $D:\Omega(M)\rightarrow\Omega(M)$ can be reconstruced if it is known how $D$ acts on $\Omega^ 0(M)$ and $\Omega^ 1(M)$. Given $d\circ i_X+i_X\circ d$, one can then show that this is a grade $0$ derivation, and for a function $f\in\Omega^ 0(M)$, $(d\circ i_X+i_X\circ d)f=i_Xdf=Xf=\mathcal{L}_Xf$ and for an 1-form $\omega\in\Omega^1(M)$, $$(d\circ i_X+i_X\circ d)\omega=di_X\omega+i_Xd\omega=d(X^\mu\omega_\mu)+i_X(\partial_\nu\omega_\mu dx^\nu\wedge dx^\mu)=dX^\mu\omega_\mu+X^\mu d\omega_\mu+\partial_\nu\omega_\mu(dx^\nu(X)dx^\mu-dx^\mu(X)dx^\nu)=(\frac{\partial X^\mu}{\partial x^\nu}\omega_\mu+X^\mu\frac{\partial \omega_\mu}{\partial x^\nu})dx^\nu+(X^\mu\partial_\mu\omega_\nu-X^\mu\partial_\nu\omega_\mu)dx^\nu=(X^\mu\partial_\mu\omega_\nu+\omega_\mu\partial_\nu X^\mu)dx^\nu=\mathcal{L}_X\omega,$$ so by the theorem on derivations, $\mathcal{L}_X=d\circ i_X+i_X\circ d$. This proof however is rather unintuitive, and it is clear we already know what the result is. Furthermore, just looking at the geometric meaning of $\mathcal{L}_X$, it is absolutely not trivial that such a relationship between $\mathcal{L}_X,i_X$ and $d$ should even exist. I don't know if other proofs of this formula exist (probably yes), but I have tried on my own several times to use only the basic definitions of the three (anti-)derivations present in the formula to prove it, but I have failed very time. In short, I think this result is absolutely not trivial and it's name (it's a ""magic"" formula after all) seems to imply the same. I am curious how did Cartan originally realize this formula. Where did the idea came that there might be this relation after all?","The standard proof of Cartan's magic formula is to study derivations of the exterior algebra. One can relatively easily find that a derivation $D:\Omega(M)\rightarrow\Omega(M)$ can be reconstruced if it is known how $D$ acts on $\Omega^ 0(M)$ and $\Omega^ 1(M)$. Given $d\circ i_X+i_X\circ d$, one can then show that this is a grade $0$ derivation, and for a function $f\in\Omega^ 0(M)$, $(d\circ i_X+i_X\circ d)f=i_Xdf=Xf=\mathcal{L}_Xf$ and for an 1-form $\omega\in\Omega^1(M)$, $$(d\circ i_X+i_X\circ d)\omega=di_X\omega+i_Xd\omega=d(X^\mu\omega_\mu)+i_X(\partial_\nu\omega_\mu dx^\nu\wedge dx^\mu)=dX^\mu\omega_\mu+X^\mu d\omega_\mu+\partial_\nu\omega_\mu(dx^\nu(X)dx^\mu-dx^\mu(X)dx^\nu)=(\frac{\partial X^\mu}{\partial x^\nu}\omega_\mu+X^\mu\frac{\partial \omega_\mu}{\partial x^\nu})dx^\nu+(X^\mu\partial_\mu\omega_\nu-X^\mu\partial_\nu\omega_\mu)dx^\nu=(X^\mu\partial_\mu\omega_\nu+\omega_\mu\partial_\nu X^\mu)dx^\nu=\mathcal{L}_X\omega,$$ so by the theorem on derivations, $\mathcal{L}_X=d\circ i_X+i_X\circ d$. This proof however is rather unintuitive, and it is clear we already know what the result is. Furthermore, just looking at the geometric meaning of $\mathcal{L}_X$, it is absolutely not trivial that such a relationship between $\mathcal{L}_X,i_X$ and $d$ should even exist. I don't know if other proofs of this formula exist (probably yes), but I have tried on my own several times to use only the basic definitions of the three (anti-)derivations present in the formula to prove it, but I have failed very time. In short, I think this result is absolutely not trivial and it's name (it's a ""magic"" formula after all) seems to imply the same. I am curious how did Cartan originally realize this formula. Where did the idea came that there might be this relation after all?",,"['differential-geometry', 'math-history', 'differential-forms']"
67,Translation of eigenvalue and its bound,Translation of eigenvalue and its bound,,"Picture below is from AN UPPER BOUND TO THE SPECTRUM OF $\Delta$ ON A MANIFOLD OF NEGATIVE CURVATURE . First, how to get (6) from (5)  ?  The (6) implies $f^{old}=f^{new}\sqrt{g}$ . But I can't get it from $f'^{~new}=\sqrt{g}f'^{~old}$ . Because $\sqrt{g}$ and $f$ are functions of $r$ . Then integrate them , there will be not $f^{old}=f^{new}\sqrt{g}$ . Second, How to get (7) from (4) ? Thanks for any help.","Picture below is from AN UPPER BOUND TO THE SPECTRUM OF ON A MANIFOLD OF NEGATIVE CURVATURE . First, how to get (6) from (5)  ?  The (6) implies . But I can't get it from . Because and are functions of . Then integrate them , there will be not . Second, How to get (7) from (4) ? Thanks for any help.",\Delta f^{old}=f^{new}\sqrt{g} f'^{~new}=\sqrt{g}f'^{~old} \sqrt{g} f r f^{old}=f^{new}\sqrt{g},"['differential-geometry', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'riemannian-geometry', 'laplacian']"
68,"Use case of integral of differential forms on ""chains""","Use case of integral of differential forms on ""chains""",,"I'm studying Spivak's Calculus on Manifolds. There the integration of $k$-forms on $k$-chains is defined and Stokes' theorem on chains is also proved, but they are never used for other theorems. I also cannot imagine where to use it in applications or maths. Why do we need to define $k$-chains? Where can I use it? A related question, but not answered, is here: What's the advantage of defining the integral of a $k$-form over a $k$-chain?","I'm studying Spivak's Calculus on Manifolds. There the integration of $k$-forms on $k$-chains is defined and Stokes' theorem on chains is also proved, but they are never used for other theorems. I also cannot imagine where to use it in applications or maths. Why do we need to define $k$-chains? Where can I use it? A related question, but not answered, is here: What's the advantage of defining the integral of a $k$-form over a $k$-chain?",,"['differential-geometry', 'differential-forms']"
69,Trace in Riemannian geometry,Trace in Riemannian geometry,,"The first time I met the definition of the trace of the Ricci curvature $Ric$ on a Riemannian manifold (M^n,g), it was formulated thanks to local orthonormal coordinates: if $(x_{1}, \cdots, x_{n})$ are local orthonormal coordinates (i.e. $g\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j}\right)=\delta_{ij}$), then the trace of $Ric$ is $$Ric\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i}\right)$$ using the Eistein summation convention. Then I met an other definition. If $g=g_{ij}dx^i dx^j$ in local coordinates (note necessarly orthonormal), $$Tr_{g}(Ric)=g^{ij}Ric_{ij},$$ where $g^{ij}$ is the $(i,j)$ coefficient of the inverse of the matrix $(g_{ij})_{1\le i,j \le n}$. I denote this matrix $G$ in the sequel. According to this definition, the trace of $Ric$ can be understood as $$Tr\left((G^{-1})^{t}M_{Ric}\right),$$ where I write $M_{Ric}$ for the matrix $(Ric_{ij})_{1\le i,j \le n}$, and $(G^{-1})^t$ for the transpose of the matrix $G^{-1}$. My question is: why $G^{-1}$ and why not $G$? In orthonormal coordinates these matrices are the same, equal to the identity, so it has no incidence on the first definition I learnt, but still, I don't understand. Is there any deep raison for this choice?","The first time I met the definition of the trace of the Ricci curvature $Ric$ on a Riemannian manifold (M^n,g), it was formulated thanks to local orthonormal coordinates: if $(x_{1}, \cdots, x_{n})$ are local orthonormal coordinates (i.e. $g\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^j}\right)=\delta_{ij}$), then the trace of $Ric$ is $$Ric\left(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i}\right)$$ using the Eistein summation convention. Then I met an other definition. If $g=g_{ij}dx^i dx^j$ in local coordinates (note necessarly orthonormal), $$Tr_{g}(Ric)=g^{ij}Ric_{ij},$$ where $g^{ij}$ is the $(i,j)$ coefficient of the inverse of the matrix $(g_{ij})_{1\le i,j \le n}$. I denote this matrix $G$ in the sequel. According to this definition, the trace of $Ric$ can be understood as $$Tr\left((G^{-1})^{t}M_{Ric}\right),$$ where I write $M_{Ric}$ for the matrix $(Ric_{ij})_{1\le i,j \le n}$, and $(G^{-1})^t$ for the transpose of the matrix $G^{-1}$. My question is: why $G^{-1}$ and why not $G$? In orthonormal coordinates these matrices are the same, equal to the identity, so it has no incidence on the first definition I learnt, but still, I don't understand. Is there any deep raison for this choice?",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
70,Trivality of tangent bundle and complex structure,Trivality of tangent bundle and complex structure,,"Let $M$ be a smooth manifold of dimensions $2n$, and suppose  $$TM \equiv M \times \mathbb R^{2n}. $$ Does it follow that $M$ admits a complex structure? It seems like the almost complex structure defined by taking the standard (after choosing a global frame $\{ v_1, \dots, v_n\}$) one at each point on $TM$ $p \in M$: $$J_p: T_pM=\mathbb R^{2n} \rightarrow T_pM=\mathbb R^{2n},$$ given by $$J_p = \begin{bmatrix}     0 & I \\     -I & 0 \end{bmatrix}$$ is a good candidate for a complex structure. But how can we know if this is integrable? I am aware of the Newlander–Nirenberg theorem, but am wondering if there are other ways to know if I can't compute that. Thanks!","Let $M$ be a smooth manifold of dimensions $2n$, and suppose  $$TM \equiv M \times \mathbb R^{2n}. $$ Does it follow that $M$ admits a complex structure? It seems like the almost complex structure defined by taking the standard (after choosing a global frame $\{ v_1, \dots, v_n\}$) one at each point on $TM$ $p \in M$: $$J_p: T_pM=\mathbb R^{2n} \rightarrow T_pM=\mathbb R^{2n},$$ given by $$J_p = \begin{bmatrix}     0 & I \\     -I & 0 \end{bmatrix}$$ is a good candidate for a complex structure. But how can we know if this is integrable? I am aware of the Newlander–Nirenberg theorem, but am wondering if there are other ways to know if I can't compute that. Thanks!",,"['differential-geometry', 'complex-geometry']"
71,$(H^2-K) dA$ is globally invariant under inversions,is globally invariant under inversions,(H^2-K) dA,"I am reading a paper by James H. White which states that the Willmore functional is invariant under conformal mappings. Let $M$ be a smooth compact surface and $f:M\to\mathbb{R}^3$ an immersion. The Willmore functional is given by $$\mathcal{W}(f)=\int_M\;H^2\;dA,$$ where $H$ is the mean curvature and $dA$ is the induced area form. By Liouville's Theorem , all the conformal mappings can be written as combination of euclidean motions, homotheties and inversions in spheres. The fact that $\mathcal{W}$ is invariant under euclidean motions and homotheties is clear. So we have to see how $\mathcal{W}$ behaves under inversions. Since, by Gauss-Bonnet, $$\int_M (H^2-K)dA=\int_M H^2 dA - 2\pi\chi(M)=\mathcal{W}(f) - 2\pi\chi(M)$$ and $\chi(M)$ is a geometric invariant, we can focus on the quantity $(H^2-K)dA$ and prove what is left for it. So this is what I want to prove: $(H^2-K)dA$ is invariant under inversions. We can assume that the center of the inversion is $0$. If we denote the radius of the inversion by $r$, the position vector of a point on the inverted surface in terms of a point $x\in M$ is given by $$\tilde{x}=r^2{x\over\|x\|^2}.$$ First we observe that the surface form $dA$ changes under the inversion by $d\tilde{A}=\left({r\over\|x\|}\right)^4 dA$. This is easily done. Now, the next step is to compute the principal curvatures of the inverted surface $\tilde{\kappa}_1, \tilde{\kappa}_2$ in terms of $\kappa_1, \kappa_2$. In the mentioned paper, they get the following: $$\tilde{\kappa}_1=-{\|x\|^2\kappa_1-2h\over r^2},\;\tilde{\kappa}_2=-{\|x\|^2\kappa_2-2h\over r^2},$$ where we have set $h=x\cdot N$ with $N$ the surface normal vector. With this calculation the proof is almost done, but I don't know how to get these values for the inverted curvatures. My guess is that I should get first the inverted normal, say $\tilde{N}$, but my calculations get me to $\tilde{N}=\left({r\over\|x\|}\right)^4 N$, which I'm not sure is right. But even if this was the right value of $\tilde{N}$, how could I derive the principal curvatures? Any help is really appreciated.","I am reading a paper by James H. White which states that the Willmore functional is invariant under conformal mappings. Let $M$ be a smooth compact surface and $f:M\to\mathbb{R}^3$ an immersion. The Willmore functional is given by $$\mathcal{W}(f)=\int_M\;H^2\;dA,$$ where $H$ is the mean curvature and $dA$ is the induced area form. By Liouville's Theorem , all the conformal mappings can be written as combination of euclidean motions, homotheties and inversions in spheres. The fact that $\mathcal{W}$ is invariant under euclidean motions and homotheties is clear. So we have to see how $\mathcal{W}$ behaves under inversions. Since, by Gauss-Bonnet, $$\int_M (H^2-K)dA=\int_M H^2 dA - 2\pi\chi(M)=\mathcal{W}(f) - 2\pi\chi(M)$$ and $\chi(M)$ is a geometric invariant, we can focus on the quantity $(H^2-K)dA$ and prove what is left for it. So this is what I want to prove: $(H^2-K)dA$ is invariant under inversions. We can assume that the center of the inversion is $0$. If we denote the radius of the inversion by $r$, the position vector of a point on the inverted surface in terms of a point $x\in M$ is given by $$\tilde{x}=r^2{x\over\|x\|^2}.$$ First we observe that the surface form $dA$ changes under the inversion by $d\tilde{A}=\left({r\over\|x\|}\right)^4 dA$. This is easily done. Now, the next step is to compute the principal curvatures of the inverted surface $\tilde{\kappa}_1, \tilde{\kappa}_2$ in terms of $\kappa_1, \kappa_2$. In the mentioned paper, they get the following: $$\tilde{\kappa}_1=-{\|x\|^2\kappa_1-2h\over r^2},\;\tilde{\kappa}_2=-{\|x\|^2\kappa_2-2h\over r^2},$$ where we have set $h=x\cdot N$ with $N$ the surface normal vector. With this calculation the proof is almost done, but I don't know how to get these values for the inverted curvatures. My guess is that I should get first the inverted normal, say $\tilde{N}$, but my calculations get me to $\tilde{N}=\left({r\over\|x\|}\right)^4 N$, which I'm not sure is right. But even if this was the right value of $\tilde{N}$, how could I derive the principal curvatures? Any help is really appreciated.",,"['differential-geometry', 'surfaces', 'curvature', 'conformal-geometry', 'invariance']"
72,On the definition of the holomorphic tangent space,On the definition of the holomorphic tangent space,,"First of all I'll motivate my question: when we define the tangent space to a smooth manifold $M$ we can go through two different approaches that at the end give the same result. First approach We pick $U \subset X$ an open subset and $p \in U$. We define a derivation at $p$ as a $\mathbb{R}$ linear map $D: C^{\infty}_X(U) \rightarrow \mathbb{R}$ that verifies Liebntiz's condition at $p$, i.e. $D(f \, g) = D(f) \, g(p) + f(p) \, D(g)$. We then define the tangent space in $p$ at $U$ as $T_{p, U} =  \{ D: C^{\infty}_X(U) \rightarrow \mathbb{R} \; \text{derivation at $p$}\}$. Using bump functions one can prove that the inclusion $i : U \hookrightarrow X$ induces an isomorphism between the tangent spaces at $p \in U$ and so the concept of tangent space turns out to be local. Second approach We do the same except that we define a derivation as a $\mathbb{R}$ linear map $D: C^{\infty}_{p,X} \rightarrow \mathbb{R}$, where with $C^{\infty}_{p,X}$ it's the stalk at $p$ of the sheaf $C^{\infty}_X$. In this way the tangent space is defined as a local concept. My question deal with the holomorphic tangent space. It is defined via derivation at a point $p$: $\mathbb{C}$ linear map $D: \mathcal{O}_{p,X} \rightarrow \mathbb{C}$. Is the reason for which it is defined this way that we don't have a holomorphic analogous of $C^{\infty}$ partitions of unity? I guess it is, but I would like a confirmation. If we had defined the holomorphic tangent space as we did in the first approach for the smooth tangent space, what would have been the problem? Would have we had some pathological situation? Thank you!","First of all I'll motivate my question: when we define the tangent space to a smooth manifold $M$ we can go through two different approaches that at the end give the same result. First approach We pick $U \subset X$ an open subset and $p \in U$. We define a derivation at $p$ as a $\mathbb{R}$ linear map $D: C^{\infty}_X(U) \rightarrow \mathbb{R}$ that verifies Liebntiz's condition at $p$, i.e. $D(f \, g) = D(f) \, g(p) + f(p) \, D(g)$. We then define the tangent space in $p$ at $U$ as $T_{p, U} =  \{ D: C^{\infty}_X(U) \rightarrow \mathbb{R} \; \text{derivation at $p$}\}$. Using bump functions one can prove that the inclusion $i : U \hookrightarrow X$ induces an isomorphism between the tangent spaces at $p \in U$ and so the concept of tangent space turns out to be local. Second approach We do the same except that we define a derivation as a $\mathbb{R}$ linear map $D: C^{\infty}_{p,X} \rightarrow \mathbb{R}$, where with $C^{\infty}_{p,X}$ it's the stalk at $p$ of the sheaf $C^{\infty}_X$. In this way the tangent space is defined as a local concept. My question deal with the holomorphic tangent space. It is defined via derivation at a point $p$: $\mathbb{C}$ linear map $D: \mathcal{O}_{p,X} \rightarrow \mathbb{C}$. Is the reason for which it is defined this way that we don't have a holomorphic analogous of $C^{\infty}$ partitions of unity? I guess it is, but I would like a confirmation. If we had defined the holomorphic tangent space as we did in the first approach for the smooth tangent space, what would have been the problem? Would have we had some pathological situation? Thank you!",,"['differential-geometry', 'definition', 'complex-geometry']"
73,"Example of a $C^{1,1}$ surface with constant Gaussian curvate equal to 1, which is not a sphere?","Example of a  surface with constant Gaussian curvate equal to 1, which is not a sphere?","C^{1,1}","In a paper I'm reading the author talk about the construction of a $C^{1,1}$ surface with constant Gaussian curvature equal to $1$. I do not know what to imagine other then a sphere though, which makes the article difficult to read. So does someone have an example of such surface that is not a sphere?","In a paper I'm reading the author talk about the construction of a $C^{1,1}$ surface with constant Gaussian curvature equal to $1$. I do not know what to imagine other then a sphere though, which makes the article difficult to read. So does someone have an example of such surface that is not a sphere?",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'curvature']"
74,Geometric characterization of closed forms,Geometric characterization of closed forms,,"I was reading the introduction to Bott & Tu and I did not understand the following geometric characterization of closed forms that is explained there.  Let $M$ be a smooth manifold and $\omega \in \Omega^k(M)$ be a $k$ -form of $M$ . The authors claim that a form is closed (i.e. $d\omega = 0$ ) if and only if given any two $k$ -dimensional submanifolds $\Sigma_1$ and $\Sigma_2$ such that the embeddings of these two submanifolds are homotopic relative to their boundaries, then $$ \int_{\Sigma_1} \omega = \int_{\Sigma_2} \omega $$ and conversely if the above integral equality holds for all such embedded submanifolds then $\omega$ is closed.  Why are these claims true? I suppose this gives a very concrete geometric interpretation of a form being closed.  Is there a similar geometric interpretation of exact forms (i.e. with no mention of the exterior derivative)?","I was reading the introduction to Bott & Tu and I did not understand the following geometric characterization of closed forms that is explained there.  Let be a smooth manifold and be a -form of . The authors claim that a form is closed (i.e. ) if and only if given any two -dimensional submanifolds and such that the embeddings of these two submanifolds are homotopic relative to their boundaries, then and conversely if the above integral equality holds for all such embedded submanifolds then is closed.  Why are these claims true? I suppose this gives a very concrete geometric interpretation of a form being closed.  Is there a similar geometric interpretation of exact forms (i.e. with no mention of the exterior derivative)?","M \omega \in \Omega^k(M) k M d\omega = 0 k \Sigma_1 \Sigma_2 
\int_{\Sigma_1} \omega = \int_{\Sigma_2} \omega
 \omega","['differential-geometry', 'differential-topology', 'de-rham-cohomology']"
75,Structure group of quaternionic manifold,Structure group of quaternionic manifold,,"Quaternionic manifolds, also called almost hypercomplex, are defined by the existence of an ($\mathbb{R}$-linear) action of quaternions on each tangent space such that $I,J,K\in\mathbb{H}$ are global sections of $\operatorname{End} TX$. Several classes of manifolds can be defined by the reduction of their structure group from $GL(n,\mathbb{R})$ to a subgroup: $O(n)$: Riemannian manifold ($\exists g$ symmetric positive); $Sp(2(n/2),\mathbb{R})$: almost symplectic manifold ($\exists\omega$ nondegenerate $2$-form); $GL(n/2, \mathbb{C})$: almost complex manifold ($\exists J\in\operatorname{End}(TX)$ with $J^2=-1$) $U(n/2)$: almost Hermitian manifold ($\exists\omega,J$ as above) Can we put a group here? : almost hypercomplex manifold ($\exists I, J, K\in\operatorname{End}(TX)$ with $I^2=J^2=K^2=IJK=-1$) For completeness, let me recall the following.  A reduction to $G\subset GL(n,\mathbb{R})$ is a section of the quotient by $G$ of the tangent frame bundle, namely a (continuous) choice at each point of a ""copy of $G$"" ($G$-torsor) among bases of the tangent space. For example a reduction to $O(n)$ is a (continuous) choice of which bases of tangent space are orthonormal.  Similarly a reduction to $GL(n/2, \mathbb{C})$ is a choice of which bases are compatible with the almost complex structure $J$.","Quaternionic manifolds, also called almost hypercomplex, are defined by the existence of an ($\mathbb{R}$-linear) action of quaternions on each tangent space such that $I,J,K\in\mathbb{H}$ are global sections of $\operatorname{End} TX$. Several classes of manifolds can be defined by the reduction of their structure group from $GL(n,\mathbb{R})$ to a subgroup: $O(n)$: Riemannian manifold ($\exists g$ symmetric positive); $Sp(2(n/2),\mathbb{R})$: almost symplectic manifold ($\exists\omega$ nondegenerate $2$-form); $GL(n/2, \mathbb{C})$: almost complex manifold ($\exists J\in\operatorname{End}(TX)$ with $J^2=-1$) $U(n/2)$: almost Hermitian manifold ($\exists\omega,J$ as above) Can we put a group here? : almost hypercomplex manifold ($\exists I, J, K\in\operatorname{End}(TX)$ with $I^2=J^2=K^2=IJK=-1$) For completeness, let me recall the following.  A reduction to $G\subset GL(n,\mathbb{R})$ is a section of the quotient by $G$ of the tangent frame bundle, namely a (continuous) choice at each point of a ""copy of $G$"" ($G$-torsor) among bases of the tangent space. For example a reduction to $O(n)$ is a (continuous) choice of which bases of tangent space are orthonormal.  Similarly a reduction to $GL(n/2, \mathbb{C})$ is a choice of which bases are compatible with the almost complex structure $J$.",,"['differential-geometry', 'lie-groups', 'quaternions', 'principal-bundles', 'kahler-manifolds']"
76,Roadmap to Differential Geometry for Machine Learning,Roadmap to Differential Geometry for Machine Learning,,"Recently within machine learning, there are a lot of works on non-convex optimization and natural gradients methods etc which are based on differential geometry, it gives rise to increased need to learn differential geometry in machine learning community. After searching a bit, I found a possible routine might be: John Lee's book series in the order of Introduction to Topological Manifolds   -> Introduction to Smooth Manifolds    -> Riemannian Manifolds: An Introduction to Curvature Is it a ""reasonable"" path to enable one to be able to get ideas and possibly to apply new results from differential geometry community(e.g. understand new papers/presentations etc. ), and if we follow it, is it still necessary to read do Carmo's two more texts that are mentioned a lot by many friends from math department. For practical reason, since machine learning research itself already takes majority amount of time, so that there is a preference not to read another books when it is not so necessary.","Recently within machine learning, there are a lot of works on non-convex optimization and natural gradients methods etc which are based on differential geometry, it gives rise to increased need to learn differential geometry in machine learning community. After searching a bit, I found a possible routine might be: John Lee's book series in the order of Introduction to Topological Manifolds   -> Introduction to Smooth Manifolds    -> Riemannian Manifolds: An Introduction to Curvature Is it a ""reasonable"" path to enable one to be able to get ideas and possibly to apply new results from differential geometry community(e.g. understand new papers/presentations etc. ), and if we follow it, is it still necessary to read do Carmo's two more texts that are mentioned a lot by many friends from math department. For practical reason, since machine learning research itself already takes majority amount of time, so that there is a preference not to read another books when it is not so necessary.",,"['differential-geometry', 'machine-learning']"
77,Is the contraction of an harmonic form harmonic?,Is the contraction of an harmonic form harmonic?,,"As I'm still a beginner in complex differential geometry, as soon as I tried reading an article I got stuck on what (I think) should be a minor detail. I hope someone can help me a bit. Let $M$ be a complex manifold of complex dimension $m$, and let $g$ be a Kähler metric on $M$ with Kähler form $\omega$ and Ricci form $\rho$. Let $h=h_{i\bar{j}}dz^{i}\wedge d\bar{z}^{j}$ be the harmonic part of $\rho$ in the Hodge decomposition for $\bigwedge\nolimits^{1,1}M$. Can I conclude that the function $\varphi=g^{i\bar{j}}h_{i\bar{j}}$ is also harmonic? I think that the answer should be ""yes"", but I'm struggling to prove it. So far I've reasoned as follows: since $\varphi$ is a function, it is enough to show that $d\varphi=0$; moreover for functions we know that $d=\nabla$, if $\nabla$ is the Levi-Civita (or Chern) connection on $M$. Since $g$ is $\nabla$-parallel we have, for every $a=1,\dots,m,\bar{1},\dots,\bar{m}$ $$\nabla_a(g^{i\bar{j}}h_{i\bar{j}})=(\nabla_ag^{i\bar{j}})h_{i\bar{j}}+g^{i\bar{j}}(\nabla_ah_{i\bar{j}})=g^{i\bar{j}}(\nabla_ah_{i\bar{j}})$$ so to prove that $\varphi$ is harmonic it is enough to show that $h$ is parallel. However, I fail to see why this should be true. Could someone please tell me what I'm missing? Any help is greatly appreciated. edit : Since there are various different notions of ""Laplacian"" on a Kähler manifold I should have specified that the Laplacian I am talking about here is the Hodge Laplacian , $\Delta:=\bar{\partial}^*\bar{\partial}+\bar{\partial}\bar{\partial}^*$, where $\bar{\partial}^*$ is the adjoint of $\bar{\partial}$.","As I'm still a beginner in complex differential geometry, as soon as I tried reading an article I got stuck on what (I think) should be a minor detail. I hope someone can help me a bit. Let $M$ be a complex manifold of complex dimension $m$, and let $g$ be a Kähler metric on $M$ with Kähler form $\omega$ and Ricci form $\rho$. Let $h=h_{i\bar{j}}dz^{i}\wedge d\bar{z}^{j}$ be the harmonic part of $\rho$ in the Hodge decomposition for $\bigwedge\nolimits^{1,1}M$. Can I conclude that the function $\varphi=g^{i\bar{j}}h_{i\bar{j}}$ is also harmonic? I think that the answer should be ""yes"", but I'm struggling to prove it. So far I've reasoned as follows: since $\varphi$ is a function, it is enough to show that $d\varphi=0$; moreover for functions we know that $d=\nabla$, if $\nabla$ is the Levi-Civita (or Chern) connection on $M$. Since $g$ is $\nabla$-parallel we have, for every $a=1,\dots,m,\bar{1},\dots,\bar{m}$ $$\nabla_a(g^{i\bar{j}}h_{i\bar{j}})=(\nabla_ag^{i\bar{j}})h_{i\bar{j}}+g^{i\bar{j}}(\nabla_ah_{i\bar{j}})=g^{i\bar{j}}(\nabla_ah_{i\bar{j}})$$ so to prove that $\varphi$ is harmonic it is enough to show that $h$ is parallel. However, I fail to see why this should be true. Could someone please tell me what I'm missing? Any help is greatly appreciated. edit : Since there are various different notions of ""Laplacian"" on a Kähler manifold I should have specified that the Laplacian I am talking about here is the Hodge Laplacian , $\Delta:=\bar{\partial}^*\bar{\partial}+\bar{\partial}\bar{\partial}^*$, where $\bar{\partial}^*$ is the adjoint of $\bar{\partial}$.",,"['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'hodge-theory']"
78,Proof of theorema egregium of Gauss,Proof of theorema egregium of Gauss,,"My problem is to solve this exercise : Let $S \subset \mathbb{R}^3$ be a sybmanifold of dimension $2$, and $x:U \mapsto S$ a local parametrization at $p = x(u,v) \in \mathcal{S}$. We have (admitted) $$ \langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle = K \circ x(u,v)  (EG-F^2)(u,v) $$ where $x_{vv}^T$ is the tangential component of $x_{vv}$. $K$ denotes the Gaus curvature and $x_u$ is the partial derivative in $u$. Let $f$ be a local isometry bewteen $S$ and $S'$ two surfaces. Prove that $K' \circ f = K$ where $K'$ is the Gauss curvature of $S'$. I first proved that, if $x$ is a local parametrization of $S$ and $x'$ a local parametrization of $S'$ defined by $x'=f \circ x$ then : $$\begin{align*} df_{x(u,v)} ([x_{uu}]^T (u,v)) &= [x'_{uu}]^T (u,v), \\  df_{x(u,v)} ([x_{vv}]^T (u,v)) &= [x'_{vv}]^T (u,v)\\ df_{x(u,v)} ([x_{uv}]^T (u,v)) &= [x'_{uv}]^T (u,v) \end{align*}$$ Then my idea was then to prove $K' \circ x' = K \circ x$ using the formula : $$ \langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle = K \circ x(u,v)  (EG-F^2)(u,v) $$ Since $E=E', F=F', G=G'$ thus it suffices to prove : $$\langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle= \langle ({x'}_{vv}^T)_u (u,v) - ({x'}_{vu}^T)_v (u,v) , {x'}_u(u,v) \rangle$$ Since $\langle df_{x(u,v)} (X), df_{x(u,v)} (Y)\rangle =  \langle X, Y \rangle $ I want to use this identity to prove the result. $${x'}_u (u,v) = df_{x(u,v)} (x_u (u,v))$$ But this is not sufficient. How can I finish ? [I can explain some notations if you want, even if I think this is all standard]","My problem is to solve this exercise : Let $S \subset \mathbb{R}^3$ be a sybmanifold of dimension $2$, and $x:U \mapsto S$ a local parametrization at $p = x(u,v) \in \mathcal{S}$. We have (admitted) $$ \langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle = K \circ x(u,v)  (EG-F^2)(u,v) $$ where $x_{vv}^T$ is the tangential component of $x_{vv}$. $K$ denotes the Gaus curvature and $x_u$ is the partial derivative in $u$. Let $f$ be a local isometry bewteen $S$ and $S'$ two surfaces. Prove that $K' \circ f = K$ where $K'$ is the Gauss curvature of $S'$. I first proved that, if $x$ is a local parametrization of $S$ and $x'$ a local parametrization of $S'$ defined by $x'=f \circ x$ then : $$\begin{align*} df_{x(u,v)} ([x_{uu}]^T (u,v)) &= [x'_{uu}]^T (u,v), \\  df_{x(u,v)} ([x_{vv}]^T (u,v)) &= [x'_{vv}]^T (u,v)\\ df_{x(u,v)} ([x_{uv}]^T (u,v)) &= [x'_{uv}]^T (u,v) \end{align*}$$ Then my idea was then to prove $K' \circ x' = K \circ x$ using the formula : $$ \langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle = K \circ x(u,v)  (EG-F^2)(u,v) $$ Since $E=E', F=F', G=G'$ thus it suffices to prove : $$\langle (x_{vv}^T)_u (u,v) - (x_{vu}^T)_v (u,v) , x_u(u,v) \rangle= \langle ({x'}_{vv}^T)_u (u,v) - ({x'}_{vu}^T)_v (u,v) , {x'}_u(u,v) \rangle$$ Since $\langle df_{x(u,v)} (X), df_{x(u,v)} (Y)\rangle =  \langle X, Y \rangle $ I want to use this identity to prove the result. $${x'}_u (u,v) = df_{x(u,v)} (x_u (u,v))$$ But this is not sufficient. How can I finish ? [I can explain some notations if you want, even if I think this is all standard]",,"['differential-geometry', 'isometry']"
79,What are the essential tools and proof techniques for beginning smooth manifolds and differential topology?,What are the essential tools and proof techniques for beginning smooth manifolds and differential topology?,,"I am an undergraduate currently taking a first course in smooth manifolds. I feel that I understand the material intuitively. But, I'm having trouble turning my intuition into proofs. I was hoping that I could get answers to the two following questions: What are the essential basic tactics for attacking smooth manifold and differential topology problems? What are the best things to do to improve my technique and ability to solve problems? Let me give an example of what I mean. I just asked another question about showing a particular map is a submersion. I have an intuitive understanding of what is going on. In the context of the problem, I can see what is happening in the case $\pi: SO_3 \to S^2$. The idea is that if I look at a point on a sphere, and I look at the directions coming off of that point, there is a rotation of the sphere that moves it in that direction. For instance, if I'm looking at a point on the equator, there is a rotation that moves the point northward, and a rotation that moves it westward, and that's enough to show I can move the point in any direction I like. But, turning that into a proof is a little bit of a daunting task. So daunting, in fact, I was compelled to ask about it. When I asked my professor about this problem, he drew me a picture and explained the intuition. I think intuition is important, but what I'm having trouble with it turning my intuition into a proof. The reason I'm having trouble with that is I don't exactly know what the essential proof techniques are. So, I firstly want to know what these proof techniques are, and secondly want to know what I can do to be acquainted with their use. I feel I should clarify what I'm saying somewhat. When I say tools here, I mean something along the lines of ""use Sard's theorem"" or ""partitions of unity."" For example, I would say that using the regular level set theorem, instead of constructing charts, to show that some set is a manifold is a tool. I understand that showing something is s submersion requires showing its differential is surjective, that being the definition of the term. What I mean is, what are good ways to exploit the structure I have? What are the proof techniques unique to this structure?","I am an undergraduate currently taking a first course in smooth manifolds. I feel that I understand the material intuitively. But, I'm having trouble turning my intuition into proofs. I was hoping that I could get answers to the two following questions: What are the essential basic tactics for attacking smooth manifold and differential topology problems? What are the best things to do to improve my technique and ability to solve problems? Let me give an example of what I mean. I just asked another question about showing a particular map is a submersion. I have an intuitive understanding of what is going on. In the context of the problem, I can see what is happening in the case $\pi: SO_3 \to S^2$. The idea is that if I look at a point on a sphere, and I look at the directions coming off of that point, there is a rotation of the sphere that moves it in that direction. For instance, if I'm looking at a point on the equator, there is a rotation that moves the point northward, and a rotation that moves it westward, and that's enough to show I can move the point in any direction I like. But, turning that into a proof is a little bit of a daunting task. So daunting, in fact, I was compelled to ask about it. When I asked my professor about this problem, he drew me a picture and explained the intuition. I think intuition is important, but what I'm having trouble with it turning my intuition into a proof. The reason I'm having trouble with that is I don't exactly know what the essential proof techniques are. So, I firstly want to know what these proof techniques are, and secondly want to know what I can do to be acquainted with their use. I feel I should clarify what I'm saying somewhat. When I say tools here, I mean something along the lines of ""use Sard's theorem"" or ""partitions of unity."" For example, I would say that using the regular level set theorem, instead of constructing charts, to show that some set is a manifold is a tool. I understand that showing something is s submersion requires showing its differential is surjective, that being the definition of the term. What I mean is, what are good ways to exploit the structure I have? What are the proof techniques unique to this structure?",,"['differential-geometry', 'manifolds', 'differential-topology', 'problem-solving', 'smooth-manifolds']"
80,Showing that $\mathbb{R}$ is locally isometric to $S^1$,Showing that  is locally isometric to,\mathbb{R} S^1,"Show that $f:\mathbb{R}\to S^1$ given by $f(t)=e^{i t}$ is a local isometry between Riemanninan manifolds. So, basically we need to show that for each $p\in\mathbb{R}$ there exists $U\subseteq\mathbb{R}$ open with $p\in U$ such that $f:U\to f(U)$ is an isometry, i.e., $\left<{u,v}\right>_q=\left<{df_q(u),df_q(v)}\right>_{f(q)}$ for every $q\in U$ and $u,v\in T_q(U)$. I assume we can just take $T_q(U)=\mathbb{R}$ for every $q$. But I don't really know how to start. Would anyone give me a hint? How can we compute the differential $df_p$? Thank you.","Show that $f:\mathbb{R}\to S^1$ given by $f(t)=e^{i t}$ is a local isometry between Riemanninan manifolds. So, basically we need to show that for each $p\in\mathbb{R}$ there exists $U\subseteq\mathbb{R}$ open with $p\in U$ such that $f:U\to f(U)$ is an isometry, i.e., $\left<{u,v}\right>_q=\left<{df_q(u),df_q(v)}\right>_{f(q)}$ for every $q\in U$ and $u,v\in T_q(U)$. I assume we can just take $T_q(U)=\mathbb{R}$ for every $q$. But I don't really know how to start. Would anyone give me a hint? How can we compute the differential $df_p$? Thank you.",,"['differential-geometry', 'riemannian-geometry']"
81,Two definitions of the first Chern class,Two definitions of the first Chern class,,"there are two definitions of the first Chern class that I don't know how to relate - hints and references are both welcome. So, first approach: say that I have a complex vector bundle $E\to M$; I can pass to the frame bundle $F(E)\to M$, where I have a $U(n)-$action, for some $n$. Then I consider the Chern-Weil map \begin{equation} S({\frak u}(n)^*)^{U(n)}\to H^*_{U(n)}(F(E))\simeq H^*(M) \end{equation} and pick the image of the invariant polynomial $tr$, the trace. (up to some constant) Second approach: I pick a connection $D:\Gamma(E)\to \Gamma(E\otimes TM)$, with $\Gamma(\cdot)$ representing the space of sections, and consider its curvature. Work locally on some $U$ and pick a section $s$ which generates the bundle: we get $D(s)=\theta(s)\cdot s$, with $\theta(s)$ a $1-$form, and apparently the first Chern class is proportional to $d\theta(s)$. I am a bit confused: the very idea of connection seems to be absent from the first approach, so either there's a natural choice of connection, or I get the same result no matter which one I pick. Moreover, it would seem to me that also the choice of generator $s$ matters. Honestly, I don't have much of a clue about where to start tackling the problem - the two things seem quite unrelated.","there are two definitions of the first Chern class that I don't know how to relate - hints and references are both welcome. So, first approach: say that I have a complex vector bundle $E\to M$; I can pass to the frame bundle $F(E)\to M$, where I have a $U(n)-$action, for some $n$. Then I consider the Chern-Weil map \begin{equation} S({\frak u}(n)^*)^{U(n)}\to H^*_{U(n)}(F(E))\simeq H^*(M) \end{equation} and pick the image of the invariant polynomial $tr$, the trace. (up to some constant) Second approach: I pick a connection $D:\Gamma(E)\to \Gamma(E\otimes TM)$, with $\Gamma(\cdot)$ representing the space of sections, and consider its curvature. Work locally on some $U$ and pick a section $s$ which generates the bundle: we get $D(s)=\theta(s)\cdot s$, with $\theta(s)$ a $1-$form, and apparently the first Chern class is proportional to $d\theta(s)$. I am a bit confused: the very idea of connection seems to be absent from the first approach, so either there's a natural choice of connection, or I get the same result no matter which one I pick. Moreover, it would seem to me that also the choice of generator $s$ matters. Honestly, I don't have much of a clue about where to start tackling the problem - the two things seem quite unrelated.",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'connections']"
82,costruction of brownian motion on sphere?,costruction of brownian motion on sphere?,,i am trying to construct a brownian motion on the sphere using the method given in Price and williams paper.$\partial$ represents the SDE of stratonovich type which is converted to ito form in last expression   $$\partial X=n(X) \times   \partial B $$ where the $\times$ is a vector product and $n(X)$ is a unit normal vector on the surface the   $$n(X)=\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}$$ equation that i formed is $$\partial \begin{pmatrix}\cos(\theta)\sin(\phi)\\\sin(\theta)\sin(\phi)\\\cos (\phi)\end{pmatrix} =\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}\times \begin {pmatrix} \partial B_1\\\partial B_2\\\partial B_3\end {pmatrix}$$ and subsequently changing the equation back to ito form i get $$d\phi=\cot(\phi)dB_3+\frac{1}{2}dt $$ but the result in the book is given by $$d\phi=dB_3+\frac{1}{2}\cot(\phi) dt $$ i cant find where i am wrong please help the text i am referring is this,i am trying to construct a brownian motion on the sphere using the method given in Price and williams paper.$\partial$ represents the SDE of stratonovich type which is converted to ito form in last expression   $$\partial X=n(X) \times   \partial B $$ where the $\times$ is a vector product and $n(X)$ is a unit normal vector on the surface the   $$n(X)=\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}$$ equation that i formed is $$\partial \begin{pmatrix}\cos(\theta)\sin(\phi)\\\sin(\theta)\sin(\phi)\\\cos (\phi)\end{pmatrix} =\begin{pmatrix} -\cos(\theta)\cos(\phi) &&0&&0 \\ 0&& \sin(\theta)\sin(\phi) && 0\\0&& 0&& -\cos(\phi)\end {pmatrix}\times \begin {pmatrix} \partial B_1\\\partial B_2\\\partial B_3\end {pmatrix}$$ and subsequently changing the equation back to ito form i get $$d\phi=\cot(\phi)dB_3+\frac{1}{2}dt $$ but the result in the book is given by $$d\phi=dB_3+\frac{1}{2}\cot(\phi) dt $$ i cant find where i am wrong please help the text i am referring is this,,"['differential-geometry', 'stochastic-calculus', 'stochastic-differential-equations']"
83,Associative neural network learning algorithm based on proximity,Associative neural network learning algorithm based on proximity,,"For simplicity I start with a 1-layer feed-forward neural network $F$, its formula is: $$ F: \mathbb{R}^n \rightarrow \mathbb{R}^n $$ $$ y \mapsto F(x) = ⎎(W x) $$ where ⎎ is the sigmoid function, $W$ is the $n \times n$ weight matrix. The network learns to associate inputs $x$ to outputs $y$, but it is only given reward signals (both + and - rewards).  This means, if an output is correct, the network will be given a positive reward, and vice versa. The learning algorithm generates random $x$ values, outputs its $y$ value, and get the + or - reward, adjusts its weights accordingly. My idea is:  let $y_0 = F(x_0)$.  Define an $\epsilon$-neighborhood of $y_0$ as $U(y_0)$.  The pre-image of this neighborhood is $F^{-1}(U(y_0))$. Upon getting a + reward, we want the learning algorithm to adjust the weights such that the volume of the pre-image becomes bigger, ie more points near $x_0$ will be mapped to or near $y_0$.  This is a form of generalization based on proximity. If $\epsilon$ is small, the volume of $F^{-1}(U)$ is approximately equal to the volume of $U$ scaled by the Jacobian determinant: $$ \det J = \left| \frac{\partial F^{-1}(y)}{\partial y} \right|$$ Using gradient descend (as we do in back-propagation), we want to adjust weights to maximize (or minimize if negative reward) the Jacobian, ie, in the direction of $\nabla_W \cdot |J| =  \left[\frac{\partial \det J}{\partial W} \;\right]$.  This is my reasoning. Calculations: I'm not sure if this step is correct: $$ \det J = \left| \frac{\partial W^{-1}⎎^{-1}(y)}{\partial y}  \right| $$ $$ \stackrel{?}{=} \left| W^{-1} S \right| $$ where $S$ is a diagonal matrix with entries $1/({ ⎎'(⎎^{-1}(y)) })$. We seek the matrix $\frac{\partial \det J}{\partial W}$ whose entries are $\frac{\partial \det J}{\partial w}$ This involves finding the derivative of a determinant: $$ \frac{\partial}{\partial w} |J| = tr( |J| \cdot J^{-1} \cdot \frac{\partial J}{\partial w})$$  where the last factor in the above RHS is: $$ \frac{\partial J}{\partial w} = \frac{\partial W^{-1} S }{\partial w} $$ $$ \stackrel{?}{=} \frac{\partial W^{-1}}{\partial w}S + W^{-1} \frac{\partial S}{\partial w} $$ $$ \stackrel{?}{=} -W^{-1} \frac{\partial W}{\partial w} W^{-1} S + W^{-1} \hat{S} $$ where $\hat{S}$ is a diagonal matrix with entries: $$ -\frac{⎎''(⎎^{-1}(y))}{⎎'(⎎^{-1}(y))^3} ⎎'(Wx) \frac{\partial W}{\partial w} x$$ Is the above correct?","For simplicity I start with a 1-layer feed-forward neural network $F$, its formula is: $$ F: \mathbb{R}^n \rightarrow \mathbb{R}^n $$ $$ y \mapsto F(x) = ⎎(W x) $$ where ⎎ is the sigmoid function, $W$ is the $n \times n$ weight matrix. The network learns to associate inputs $x$ to outputs $y$, but it is only given reward signals (both + and - rewards).  This means, if an output is correct, the network will be given a positive reward, and vice versa. The learning algorithm generates random $x$ values, outputs its $y$ value, and get the + or - reward, adjusts its weights accordingly. My idea is:  let $y_0 = F(x_0)$.  Define an $\epsilon$-neighborhood of $y_0$ as $U(y_0)$.  The pre-image of this neighborhood is $F^{-1}(U(y_0))$. Upon getting a + reward, we want the learning algorithm to adjust the weights such that the volume of the pre-image becomes bigger, ie more points near $x_0$ will be mapped to or near $y_0$.  This is a form of generalization based on proximity. If $\epsilon$ is small, the volume of $F^{-1}(U)$ is approximately equal to the volume of $U$ scaled by the Jacobian determinant: $$ \det J = \left| \frac{\partial F^{-1}(y)}{\partial y} \right|$$ Using gradient descend (as we do in back-propagation), we want to adjust weights to maximize (or minimize if negative reward) the Jacobian, ie, in the direction of $\nabla_W \cdot |J| =  \left[\frac{\partial \det J}{\partial W} \;\right]$.  This is my reasoning. Calculations: I'm not sure if this step is correct: $$ \det J = \left| \frac{\partial W^{-1}⎎^{-1}(y)}{\partial y}  \right| $$ $$ \stackrel{?}{=} \left| W^{-1} S \right| $$ where $S$ is a diagonal matrix with entries $1/({ ⎎'(⎎^{-1}(y)) })$. We seek the matrix $\frac{\partial \det J}{\partial W}$ whose entries are $\frac{\partial \det J}{\partial w}$ This involves finding the derivative of a determinant: $$ \frac{\partial}{\partial w} |J| = tr( |J| \cdot J^{-1} \cdot \frac{\partial J}{\partial w})$$  where the last factor in the above RHS is: $$ \frac{\partial J}{\partial w} = \frac{\partial W^{-1} S }{\partial w} $$ $$ \stackrel{?}{=} \frac{\partial W^{-1}}{\partial w}S + W^{-1} \frac{\partial S}{\partial w} $$ $$ \stackrel{?}{=} -W^{-1} \frac{\partial W}{\partial w} W^{-1} S + W^{-1} \hat{S} $$ where $\hat{S}$ is a diagonal matrix with entries: $$ -\frac{⎎''(⎎^{-1}(y))}{⎎'(⎎^{-1}(y))^3} ⎎'(Wx) \frac{\partial W}{\partial w} x$$ Is the above correct?",,"['differential-geometry', 'neural-networks']"
84,Relation between the Hessian and Laplacian,Relation between the Hessian and Laplacian,,"Let $(M^{n},g)$ be a smooth Riemannian manifold of smooth boundary $\partial M$. Assume that Ricci curvature of $M$ is $Ric^{M}\geq0$,  and the second fund. form of  $\partial M$ is $II\geq c>0$. Suppose that $(\frac{\partial u}{\partial\nu})\mid_{\partial M}=0$. Is the following inequality is true $$|Hess(u)|^{2}\leq (\Delta u)^{2}$$ If yes, how I can prove it. Thank you in advance (Noting that by using Bochner formula we know that $\int_{M}\bigl((\Delta u)^{2}-|Hess(u)|^{2}\bigr)dv_{g}\geq0$).","Let $(M^{n},g)$ be a smooth Riemannian manifold of smooth boundary $\partial M$. Assume that Ricci curvature of $M$ is $Ric^{M}\geq0$,  and the second fund. form of  $\partial M$ is $II\geq c>0$. Suppose that $(\frac{\partial u}{\partial\nu})\mid_{\partial M}=0$. Is the following inequality is true $$|Hess(u)|^{2}\leq (\Delta u)^{2}$$ If yes, how I can prove it. Thank you in advance (Noting that by using Bochner formula we know that $\int_{M}\bigl((\Delta u)^{2}-|Hess(u)|^{2}\bigr)dv_{g}\geq0$).",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry']"
85,Helmholtz-Decomposition-weak Formulation in n-dimensional case,Helmholtz-Decomposition-weak Formulation in n-dimensional case,,"In the Wikipedia article about the Helmholtz-Decomposition it says in the section about Weak Formulation : For a slightly smoother vector field u ∈ H(curl, Ω), a similar decomposition holds: $\mathbf{u}=\nabla\varphi+\mathbf{v}$ $\;\;\;$where $\;\;\;\;$φ ∈ $H^1(Ω)$, v ∈ $(H^1(Ω))^d$. Does anybody know how to prove this statement or where I can find a proof? Thanks","In the Wikipedia article about the Helmholtz-Decomposition it says in the section about Weak Formulation : For a slightly smoother vector field u ∈ H(curl, Ω), a similar decomposition holds: $\mathbf{u}=\nabla\varphi+\mathbf{v}$ $\;\;\;$where $\;\;\;\;$φ ∈ $H^1(Ω)$, v ∈ $(H^1(Ω))^d$. Does anybody know how to prove this statement or where I can find a proof? Thanks",,"['calculus', 'differential-geometry', 'vector-analysis']"
86,Not understanding the foliation structure of a Poisson manifold,Not understanding the foliation structure of a Poisson manifold,,"Consider a Poisson manifold $(M, P)$ (no assumption about the rank or regularity of $P$). For each possible rank $2r$ of $P$, let $(M_r, P_r)$ be the corresponding symplectic leaf of dimension $2r$, with symplectic form $\Omega_r$ and associated non-degenerate Poisson bivector $P_r$. What is (if any) the relationship between $P_r$ and $P$? Is $i_r$ a Poisson map? Is $P_r$ unique (modulo symplectic isomorphisms of $M_r$)? I still am not able to follow the proof of its existence, but it (in fact its associated symplectic form) seems to be obtained through a glueing process, and this approach does not always produce unique results. If $x \in M_r$, then the Darboux-Weinstein theorem essentially says that there exist coordinates $(x_1, \dots, x_r, p_1, \dots, q_r, z_1, \dots, z_s)$ around $x$ such that in these coordinates $$P = \sum \limits _{i = 1} ^r \frac {\partial} {\partial x_i} \wedge \frac {\partial} {\partial p_i} + \sum \limits _{i = 1} ^s \varphi _{ij} \frac {\partial} {\partial z_i} \wedge \frac {\partial} {\partial z_j}$$ and $\varphi _{ij} (x) = 0$. If $P_x$ is the first summand, what is the relationship between $P_x$, $P_r$ and $P$? (Alternatively, if $\Omega_x$ is the symplectic form associated to $P_x$, what is the relationship between $\Omega_x$ and $\Omega_r$)? Are the coordinates $(x_1, \dots, x_r, p_1, \dots, q_r)$ introduced above Darboux coordinates around $x$ when seen as a point of $M_r$?","Consider a Poisson manifold $(M, P)$ (no assumption about the rank or regularity of $P$). For each possible rank $2r$ of $P$, let $(M_r, P_r)$ be the corresponding symplectic leaf of dimension $2r$, with symplectic form $\Omega_r$ and associated non-degenerate Poisson bivector $P_r$. What is (if any) the relationship between $P_r$ and $P$? Is $i_r$ a Poisson map? Is $P_r$ unique (modulo symplectic isomorphisms of $M_r$)? I still am not able to follow the proof of its existence, but it (in fact its associated symplectic form) seems to be obtained through a glueing process, and this approach does not always produce unique results. If $x \in M_r$, then the Darboux-Weinstein theorem essentially says that there exist coordinates $(x_1, \dots, x_r, p_1, \dots, q_r, z_1, \dots, z_s)$ around $x$ such that in these coordinates $$P = \sum \limits _{i = 1} ^r \frac {\partial} {\partial x_i} \wedge \frac {\partial} {\partial p_i} + \sum \limits _{i = 1} ^s \varphi _{ij} \frac {\partial} {\partial z_i} \wedge \frac {\partial} {\partial z_j}$$ and $\varphi _{ij} (x) = 0$. If $P_x$ is the first summand, what is the relationship between $P_x$, $P_r$ and $P$? (Alternatively, if $\Omega_x$ is the symplectic form associated to $P_x$, what is the relationship between $\Omega_x$ and $\Omega_r$)? Are the coordinates $(x_1, \dots, x_r, p_1, \dots, q_r)$ introduced above Darboux coordinates around $x$ when seen as a point of $M_r$?",,"['differential-geometry', 'smooth-manifolds', 'symplectic-geometry', 'foliations', 'poisson-geometry']"
87,"Does existence of two Killing vectors $X,Y$ with $[X,Y]\neq 0$ imply existence of a third linearly independent Killing vector?",Does existence of two Killing vectors  with  imply existence of a third linearly independent Killing vector?,"X,Y [X,Y]\neq 0","Suppose we have a Riemannian or Lorentzian manifold with two Killing vector fields $X,Y$ such that $[X,Y]\neq 0$. Does this imply existence of a third linearly independent Killing vector field $Z$? I know that $[X,Y]$ is itself a Killing vector. But e.g. for $\mathbb{H}^2$, one can choose the Killing vectors to satisfy $[H,J_+]=J_+$, $[H,J_-]=-J_-$ and $[J_+,J_-]=2H$, so we see that $[X,Y]$ does not generally provide a linearly independent Killing vector. A minimal counter-example to my claim would be to find a manifold with exactly two Killing vectors $X,Y$ satisfying $[X,Y]\neq 0$, but I seem to be unable to find such a manifold. EDIT: my original claim included further requirements on $Z$, namely that $[Z,X]\neq 0$ and $[Z,Y]\neq 0$. These follow IF we can prove the existence of a linearly independent Killing vector $Z$. Then, if e.g. $[Z,X]=0$ and $[Z,Y]\neq 0$, consider $Z^\prime = Z+Y$ which is a linearly independent Killing vector with $[Z^\prime,X]=[Y,X]\neq 0$ and $[Z^\prime,Y]=[Z,Y]\neq 0$. Finally, if both $[Z,X]=0$ and $[Z,Y]= 0$, consider $Z^{\prime\prime}=Z+X+Y$, so that $[Z^{\prime\prime},X]=[Y,X]\neq 0$ and $[Z^{\prime\prime},Y]=[X,Y]\neq 0$.","Suppose we have a Riemannian or Lorentzian manifold with two Killing vector fields $X,Y$ such that $[X,Y]\neq 0$. Does this imply existence of a third linearly independent Killing vector field $Z$? I know that $[X,Y]$ is itself a Killing vector. But e.g. for $\mathbb{H}^2$, one can choose the Killing vectors to satisfy $[H,J_+]=J_+$, $[H,J_-]=-J_-$ and $[J_+,J_-]=2H$, so we see that $[X,Y]$ does not generally provide a linearly independent Killing vector. A minimal counter-example to my claim would be to find a manifold with exactly two Killing vectors $X,Y$ satisfying $[X,Y]\neq 0$, but I seem to be unable to find such a manifold. EDIT: my original claim included further requirements on $Z$, namely that $[Z,X]\neq 0$ and $[Z,Y]\neq 0$. These follow IF we can prove the existence of a linearly independent Killing vector $Z$. Then, if e.g. $[Z,X]=0$ and $[Z,Y]\neq 0$, consider $Z^\prime = Z+Y$ which is a linearly independent Killing vector with $[Z^\prime,X]=[Y,X]\neq 0$ and $[Z^\prime,Y]=[Z,Y]\neq 0$. Finally, if both $[Z,X]=0$ and $[Z,Y]= 0$, consider $Z^{\prime\prime}=Z+X+Y$, so that $[Z^{\prime\prime},X]=[Y,X]\neq 0$ and $[Z^{\prime\prime},Y]=[X,Y]\neq 0$.",,['differential-geometry']
88,Manifold is cut along hypersurfaces; how to define a connection on this?,Manifold is cut along hypersurfaces; how to define a connection on this?,,"May $M$ be a smooth manifold with boundary $\partial M$. Metrics and Connection can be defined everywhere. But now this manifold is cut by a smooth hypersurface $A$ and the cut goes along $M \cap A$ such that it is subdivided into two manifolds $M_1,M_2$ with $M_1 \cup M_2 = M-A$ (disjoint union is used). Suppose that there is a closed interval $I = [0,1]$ such that a ""process"" $\phi (M \times I)$ with $\phi(x,0) = x$, $\phi(x,1) = z$ and $x \in M, z \in M_1 \cup M_2$ can be defined. Clearly the manifold is smooth on $M_1 \cup M_2$ but what is on the boundaries $\partial M_1 \cap A, \partial M_2 \cap A$ where a cut takes place? One observes that the normal field $n$ on $\partial M_1 \cap A, \partial M_2 \cap A$ is discontinuous which implies that the curvature and torsion is not defined there. The map $\phi(x,t)$ is also non-differentiable in Argument $t$. How can I describe the geometry on the cut Surface? I know how to describe surfaces e.g. with Gauss curvature but how do I deal with the problem given above? What area of geometry deals with such problems (It isn't Riemannian geometry because of the discontinuities, which geometry is it then?)? Every hint would be greatly appreciated?","May $M$ be a smooth manifold with boundary $\partial M$. Metrics and Connection can be defined everywhere. But now this manifold is cut by a smooth hypersurface $A$ and the cut goes along $M \cap A$ such that it is subdivided into two manifolds $M_1,M_2$ with $M_1 \cup M_2 = M-A$ (disjoint union is used). Suppose that there is a closed interval $I = [0,1]$ such that a ""process"" $\phi (M \times I)$ with $\phi(x,0) = x$, $\phi(x,1) = z$ and $x \in M, z \in M_1 \cup M_2$ can be defined. Clearly the manifold is smooth on $M_1 \cup M_2$ but what is on the boundaries $\partial M_1 \cap A, \partial M_2 \cap A$ where a cut takes place? One observes that the normal field $n$ on $\partial M_1 \cap A, \partial M_2 \cap A$ is discontinuous which implies that the curvature and torsion is not defined there. The map $\phi(x,t)$ is also non-differentiable in Argument $t$. How can I describe the geometry on the cut Surface? I know how to describe surfaces e.g. with Gauss curvature but how do I deal with the problem given above? What area of geometry deals with such problems (It isn't Riemannian geometry because of the discontinuities, which geometry is it then?)? Every hint would be greatly appreciated?",,"['differential-geometry', 'differential-topology', 'surfaces']"
89,Examples of geometric structures on real manifold that lead to almost complex structure,Examples of geometric structures on real manifold that lead to almost complex structure,,"I have a $M^{2n}$ real manifold. I am interested, if there are any well known geometric structures on manifold that lead in some natural manner to almost complex structure on $M.$ I read on wiki about compatible triples and I think one example would be triple $(M,\omega,g)$ consisting of symplectic form $\omega$ and metric tensor $g,$ such that $$g(X,Y)=\omega(X,(i_Y\omega)^\sharp)$$ for all vector fields $X,Y.$ We can define then an almost complex structure $J$ as follows: $$J(X)=(i_X\omega)^\sharp.$$ I am looking for this type of examples. Btw. I am aware that there is an almost complex structure derived from complex manifold. Edit. After Jack's comment I added compatibility condition $g(X,Y)=\omega(X,(i_Y\omega)^\sharp).$ Edit. Almost cosympletic structure from Olszak's paper looks promising, but it is odd dimensional, so no chance. Maybe someone is familiar with similar structures, but on even dimensional mfd. Remark As tessellation pointed out: ""To get a global almost complex structure the only obstruction is the gluing condition which is a purely algebraic topological obstruction."" The idea however is to define almost complex structure in some natural manner to skip the middle part in below diagram $$\text{geometric structure}\implies\text{algebraic topological obstructions vanish}\implies \text{there is an almost complex structure}$$","I have a $M^{2n}$ real manifold. I am interested, if there are any well known geometric structures on manifold that lead in some natural manner to almost complex structure on $M.$ I read on wiki about compatible triples and I think one example would be triple $(M,\omega,g)$ consisting of symplectic form $\omega$ and metric tensor $g,$ such that $$g(X,Y)=\omega(X,(i_Y\omega)^\sharp)$$ for all vector fields $X,Y.$ We can define then an almost complex structure $J$ as follows: $$J(X)=(i_X\omega)^\sharp.$$ I am looking for this type of examples. Btw. I am aware that there is an almost complex structure derived from complex manifold. Edit. After Jack's comment I added compatibility condition $g(X,Y)=\omega(X,(i_Y\omega)^\sharp).$ Edit. Almost cosympletic structure from Olszak's paper looks promising, but it is odd dimensional, so no chance. Maybe someone is familiar with similar structures, but on even dimensional mfd. Remark As tessellation pointed out: ""To get a global almost complex structure the only obstruction is the gluing condition which is a purely algebraic topological obstruction."" The idea however is to define almost complex structure in some natural manner to skip the middle part in below diagram $$\text{geometric structure}\implies\text{algebraic topological obstructions vanish}\implies \text{there is an almost complex structure}$$",,"['differential-geometry', 'tensors', 'smooth-manifolds']"
90,Taylor expansion of the square of the distance function,Taylor expansion of the square of the distance function,,"Give a smooth Riemannian manifold $(M,g)$, (i) how can one compute Taylor expansion of the square of the Riemannian distance function $d^2(x,x_0)$ at $(x',x_0)$? I've tried to use $dist=\int (g_{\mu\nu} \frac{dx^\mu}{dt} \frac{dx^\nu}{dt} )^{1/2} dt$ to expand $dist^2$, but it was so messy. BTW, I've found that a similar question has been asked at mathoverflow.net . The answer given is actually very nice but it goes a little too technical and quite cryptic to me... In particular, the final result seems to a generalised Cosine law, right?! (ii) Doesn't it make a sense to write $d^2(x,x_0)=d^2(x'+(x-x'),x_0)$ and take it as a scalar function?! Under what conditions can one assume that the square of the distance function is a polynomial? I would appreciate answers not demanding an all profound background...","Give a smooth Riemannian manifold $(M,g)$, (i) how can one compute Taylor expansion of the square of the Riemannian distance function $d^2(x,x_0)$ at $(x',x_0)$? I've tried to use $dist=\int (g_{\mu\nu} \frac{dx^\mu}{dt} \frac{dx^\nu}{dt} )^{1/2} dt$ to expand $dist^2$, but it was so messy. BTW, I've found that a similar question has been asked at mathoverflow.net . The answer given is actually very nice but it goes a little too technical and quite cryptic to me... In particular, the final result seems to a generalised Cosine law, right?! (ii) Doesn't it make a sense to write $d^2(x,x_0)=d^2(x'+(x-x'),x_0)$ and take it as a scalar function?! Under what conditions can one assume that the square of the distance function is a polynomial? I would appreciate answers not demanding an all profound background...",,"['differential-geometry', 'riemannian-geometry', 'metric-geometry']"
91,Coordinate map from cotangent space is smooth,Coordinate map from cotangent space is smooth,,"I know that for a given coordinate system of the tangent space $\partial_1,..,\partial_n$ the coordinate map is smooth, as the coordinate map $\pi_i$ of ${T_xM}$ is nothing but the composition of the chart and coordinate map in $\mathbb{R}^n$ and both of them are smooth. Unfortunately, this is less clear to me if we are talking about the cotangent space, cause then I have a coordinate system $dx_1,..,dx_n$ , but how do I see that now the coordinate projection is still smooth? If anything is unclear, please let me know.","I know that for a given coordinate system of the tangent space $\partial_1,..,\partial_n$ the coordinate map is smooth, as the coordinate map $\pi_i$ of ${T_xM}$ is nothing but the composition of the chart and coordinate map in $\mathbb{R}^n$ and both of them are smooth. Unfortunately, this is less clear to me if we are talking about the cotangent space, cause then I have a coordinate system $dx_1,..,dx_n$ , but how do I see that now the coordinate projection is still smooth? If anything is unclear, please let me know.",,"['real-analysis', 'differential-geometry', 'differential-topology', 'smooth-manifolds']"
92,Reference request: Tubular neighborhood theorem for non-closed manifolds via the exponential map.,Reference request: Tubular neighborhood theorem for non-closed manifolds via the exponential map.,,"Let $M\subset N$ be a submanifold. (Both $M$ and $N$ have no boundary, but $M\subset N$ need not to be closed as a subspace and none of them need to be compact) Choose a Riemannian metric on $N$ and identify the normal bundle $\vartheta M$ of $M$ with a subbundle of the tangent bundle of $N$ in the usual way. I'm searching for a reference with a detailed proof of the following fact: There exists a open neighborhood of the zero section in $\vartheta_M$, such that the exponential map of $N$ provides a diffeomorphism of the neighborhood to an open neighborhood of $N$ in $M$. A proof is given in Lang' ""Fundamentals of Differential Geometry"" in the case of $N\subset M$ closed as a subset. (Theorem 5.1 on page 110) A proof sketch of the general case is given as Theorem 6.5 of da Silva's Lectures on Symplectic Geometry . I searched in almost every textbook about differential geometry and topology I know, but most authors prove the theorem for compact submanifolds or at most for topological closed ones. I even began to ask myself whether the statement may actually fail in the non closed case.","Let $M\subset N$ be a submanifold. (Both $M$ and $N$ have no boundary, but $M\subset N$ need not to be closed as a subspace and none of them need to be compact) Choose a Riemannian metric on $N$ and identify the normal bundle $\vartheta M$ of $M$ with a subbundle of the tangent bundle of $N$ in the usual way. I'm searching for a reference with a detailed proof of the following fact: There exists a open neighborhood of the zero section in $\vartheta_M$, such that the exponential map of $N$ provides a diffeomorphism of the neighborhood to an open neighborhood of $N$ in $M$. A proof is given in Lang' ""Fundamentals of Differential Geometry"" in the case of $N\subset M$ closed as a subset. (Theorem 5.1 on page 110) A proof sketch of the general case is given as Theorem 6.5 of da Silva's Lectures on Symplectic Geometry . I searched in almost every textbook about differential geometry and topology I know, but most authors prove the theorem for compact submanifolds or at most for topological closed ones. I even began to ask myself whether the statement may actually fail in the non closed case.",,"['differential-geometry', 'reference-request', 'manifolds', 'smooth-manifolds', 'geometric-topology']"
93,Index of zero of a gradient vector field at a critical point,Index of zero of a gradient vector field at a critical point,,"Let $M$ be a Riemannian manifold with a Morse function $f: M \to \mathbb{R}$. The zeroes of the gradient vector field of $f$ are the critical points of $f$. How do you show that a critical point of $f$ with Morse index $k$ is a zero of the gradient vector field with index $(-1)^k$? Update, 8/29: If somebody has something they want to add as an answer, there are 50 points are on the table that will otherwise go to waste. Notes: The latter index is the degree of the Gauss map $\partial B^n \to S^{n-1}$ defined by the vector field on the boundary of a small ball $B^n$ containing the zero, as in Poincaré-Hopf. I'm looking for an argument that is intrinsic or at least preserves the Riemannian structure, maybe using the Hessian. (Here's a sketch of my unsatisfying argument: Any two Riemannian structures on $M$ define gradient vector fields for $f$ with the same critical points, and you can define a time-dependent flow connecting any two such vector fields to see that the index of every zero is preserved. Thus it suffices to invoke the Morse lemma and use a Morse chart to pull back to $\mathbb{R}^n$ with the standard Riemannian metric. From there, the claim is a simple, explicit calculation.)","Let $M$ be a Riemannian manifold with a Morse function $f: M \to \mathbb{R}$. The zeroes of the gradient vector field of $f$ are the critical points of $f$. How do you show that a critical point of $f$ with Morse index $k$ is a zero of the gradient vector field with index $(-1)^k$? Update, 8/29: If somebody has something they want to add as an answer, there are 50 points are on the table that will otherwise go to waste. Notes: The latter index is the degree of the Gauss map $\partial B^n \to S^{n-1}$ defined by the vector field on the boundary of a small ball $B^n$ containing the zero, as in Poincaré-Hopf. I'm looking for an argument that is intrinsic or at least preserves the Riemannian structure, maybe using the Hessian. (Here's a sketch of my unsatisfying argument: Any two Riemannian structures on $M$ define gradient vector fields for $f$ with the same critical points, and you can define a time-dependent flow connecting any two such vector fields to see that the index of every zero is preserved. Thus it suffices to invoke the Morse lemma and use a Morse chart to pull back to $\mathbb{R}^n$ with the standard Riemannian metric. From there, the claim is a simple, explicit calculation.)",,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'morse-theory']"
94,Chern-Gauss-Bonnet theorem for even-dimensional manifolds with boundary,Chern-Gauss-Bonnet theorem for even-dimensional manifolds with boundary,,"On the wikipedia page for the Chern-Gauss-Bonnet theorem it states that there is a generalization of the theorem for even-dimensional manifolds with boundary, but does not provide the relevant theorem or any reference. The nlab page also does not mention the case of a manifold with boundary. Could someone point me to a source which discusses the case with nonempty boundary?","On the wikipedia page for the Chern-Gauss-Bonnet theorem it states that there is a generalization of the theorem for even-dimensional manifolds with boundary, but does not provide the relevant theorem or any reference. The nlab page also does not mention the case of a manifold with boundary. Could someone point me to a source which discusses the case with nonempty boundary?",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'riemannian-geometry', 'characteristic-classes']"
95,Normal curvature of geodesic spheres,Normal curvature of geodesic spheres,,"I would like to ask the community for a reference on the following property of geodesic spheres. Let $(M,g)$ be a compact Riemannian manifold without conjugate points and $\tilde{M}$ its universal covering with the natural metric $\tilde{g}$. Given a point $\tilde{p}\in\tilde{M}$ and $R>1$, Is there some result like The inner normal field of the geodesic sphere centered at $\tilde{p}$ and with radius $R$ is a Lipschitz vector field ? I am aware that the normal curvature satisfies a Riccati equation along a geodesi radius starting at the center of the sphere, namely $\tilde{p}$. Perhaps I could get some control of the normal vector field of a geodesic sphere using this equation, but I don't know if there is this control. If someone could give me any reference on the subject, it would be really appreciated.","I would like to ask the community for a reference on the following property of geodesic spheres. Let $(M,g)$ be a compact Riemannian manifold without conjugate points and $\tilde{M}$ its universal covering with the natural metric $\tilde{g}$. Given a point $\tilde{p}\in\tilde{M}$ and $R>1$, Is there some result like The inner normal field of the geodesic sphere centered at $\tilde{p}$ and with radius $R$ is a Lipschitz vector field ? I am aware that the normal curvature satisfies a Riccati equation along a geodesi radius starting at the center of the sphere, namely $\tilde{p}$. Perhaps I could get some control of the normal vector field of a geodesic sphere using this equation, but I don't know if there is this control. If someone could give me any reference on the subject, it would be really appreciated.",,"['differential-geometry', 'reference-request', 'geodesic', 'lipschitz-functions', 'spheres']"
96,Manifolds with 'bad metrics' (reference request),Manifolds with 'bad metrics' (reference request),,"While studying some differential geometry, a thought crossed my mind that I am sure has been considered before, but I cannot find a reference for it. What can be said about spaces for which the metric has pathological behaviour? I know that this is playing fast and loose with the terminology, but bear with me. In particular I am curious about generalised metrics that change signature. My rough idea of an example is $\mathbb{R}^2$ where we have a notion of length that is asymptotically Minkowskian, but near to the origin is Euclidean. For a vector $v$ with components $(v_x, v_y)$, let  $$ ||v||^2 = f(v_x^2 + v_y^2) v_x^2 + v_y^2 = f(v \cdot v) v_x^2 + v_y^2 $$ where the $\cdot$ is the ordinary Euclidean dot product, and $f: \mathbb{R} \to \mathbb{R}$ is some nice function with  $$ \lim_{r \to 0^+} f(r) = 1\\ \lim_{r \to \infty} f(r) = -1 $$ Examples of such an $f$ include $$ 2e^{-r^2} - 1 $$ and $$ \frac{1-r}{r+1} $$ Of course it no longer makes sense to call this a metric as it's not a symmetric bilinear form. I guess we could define $$ \left<u, v\right> = f(u \cdot v) u_xv_x + u_yv_y $$ but the notation would not be appropriate. Does anyone know if such signature-changing spaces have a name? Where can I learn more about them?","While studying some differential geometry, a thought crossed my mind that I am sure has been considered before, but I cannot find a reference for it. What can be said about spaces for which the metric has pathological behaviour? I know that this is playing fast and loose with the terminology, but bear with me. In particular I am curious about generalised metrics that change signature. My rough idea of an example is $\mathbb{R}^2$ where we have a notion of length that is asymptotically Minkowskian, but near to the origin is Euclidean. For a vector $v$ with components $(v_x, v_y)$, let  $$ ||v||^2 = f(v_x^2 + v_y^2) v_x^2 + v_y^2 = f(v \cdot v) v_x^2 + v_y^2 $$ where the $\cdot$ is the ordinary Euclidean dot product, and $f: \mathbb{R} \to \mathbb{R}$ is some nice function with  $$ \lim_{r \to 0^+} f(r) = 1\\ \lim_{r \to \infty} f(r) = -1 $$ Examples of such an $f$ include $$ 2e^{-r^2} - 1 $$ and $$ \frac{1-r}{r+1} $$ Of course it no longer makes sense to call this a metric as it's not a symmetric bilinear form. I guess we could define $$ \left<u, v\right> = f(u \cdot v) u_xv_x + u_yv_y $$ but the notation would not be appropriate. Does anyone know if such signature-changing spaces have a name? Where can I learn more about them?",,"['differential-geometry', 'reference-request', 'manifolds']"
97,Stokes' theorem: Induced orientation on the boundary of a manifold,Stokes' theorem: Induced orientation on the boundary of a manifold,,"The Question Let $K = \{(x,y,z) \in \mathbb{R}^3 : x^2 + y^2 + z^2 \geq 1\}$, where $K$ is oriented via the canonical volume form on $\mathbb{R}^3$: $dx \wedge dy \wedge dz$. Let $\mathbb{S}^2$ be the unit sphere, considered as the boundary of $K$, with the orientation on $\partial K$ given by the induced orientation from $K$. Define the canonical inclusion map $j: \mathbb{S}^2 \rightarrow \mathbb{R}^3$ and the 2-form on $\mathbb{R}^3$ $\omega := (2z -x^2 - xy) dx \wedge dy - dy \wedge dz +dz \wedge dx$ Calculate \begin{align} \int\limits_{\mathbb{S}^2} j^* \omega \end{align} where $j^*$ denotes the pullback of $j$ in the usual way. Attempt at a solution Using Stokes' theorem, we have \begin{align} \int\limits_{\mathbb{S}^2} j^* \omega &= \int\limits_{\mathbb{R}^3 \backslash K} d\omega\\ &= 4 \pi \int\limits_0^1 dr\,2 r^2\\ &= \frac{8\pi}{3}\\ \end{align} The difficulty Is this correct or should the answer be $-8\pi/3$? In class we've said that for manifolds with odd dimension we will adopt the convention that the boundary will have the opposite orientation as the one induced by a volume form on the manifold. To me this means that we pick up a minus sign in this case, because by integrating $r$ from 0 to 1 we are adopting the orientation given by the volume form on $\mathbb{R}^3$. Is this true? It also seems that, using basic calculus reasoning, the result of the integral should differ by a sign change depending on if we view $\mathbb{S}^2$ as the boundary of $K$ or as the boundary of $\mathbb{R}^3 \backslash K$ (because the definition of ""outwards"" would differ for the normal vectors). Is this true? If so, how is it imposed formally? What does this mean for my question in the preceding paragraph? I'm very much interested in the ""why"" for a general case, not just the solution to this particular problem.","The Question Let $K = \{(x,y,z) \in \mathbb{R}^3 : x^2 + y^2 + z^2 \geq 1\}$, where $K$ is oriented via the canonical volume form on $\mathbb{R}^3$: $dx \wedge dy \wedge dz$. Let $\mathbb{S}^2$ be the unit sphere, considered as the boundary of $K$, with the orientation on $\partial K$ given by the induced orientation from $K$. Define the canonical inclusion map $j: \mathbb{S}^2 \rightarrow \mathbb{R}^3$ and the 2-form on $\mathbb{R}^3$ $\omega := (2z -x^2 - xy) dx \wedge dy - dy \wedge dz +dz \wedge dx$ Calculate \begin{align} \int\limits_{\mathbb{S}^2} j^* \omega \end{align} where $j^*$ denotes the pullback of $j$ in the usual way. Attempt at a solution Using Stokes' theorem, we have \begin{align} \int\limits_{\mathbb{S}^2} j^* \omega &= \int\limits_{\mathbb{R}^3 \backslash K} d\omega\\ &= 4 \pi \int\limits_0^1 dr\,2 r^2\\ &= \frac{8\pi}{3}\\ \end{align} The difficulty Is this correct or should the answer be $-8\pi/3$? In class we've said that for manifolds with odd dimension we will adopt the convention that the boundary will have the opposite orientation as the one induced by a volume form on the manifold. To me this means that we pick up a minus sign in this case, because by integrating $r$ from 0 to 1 we are adopting the orientation given by the volume form on $\mathbb{R}^3$. Is this true? It also seems that, using basic calculus reasoning, the result of the integral should differ by a sign change depending on if we view $\mathbb{S}^2$ as the boundary of $K$ or as the boundary of $\mathbb{R}^3 \backslash K$ (because the definition of ""outwards"" would differ for the normal vectors). Is this true? If so, how is it imposed formally? What does this mean for my question in the preceding paragraph? I'm very much interested in the ""why"" for a general case, not just the solution to this particular problem.",,"['differential-geometry', 'manifolds-with-boundary', 'orientation']"
98,Homogeneous metric on a homogeneous space $G/K$ - is this the same as a $G$ - invariant metric?,Homogeneous metric on a homogeneous space  - is this the same as a  - invariant metric?,G/K G,"I have trouble putting down the notion of a homogeneous Riemannian metric. Suppose we are given a Riemannian manifold $(M,g)$ on which a compact Lie group $G$ acts transitively by isometries (this means that $h^*g = g$ for any $h \in G$, i.e. for any vector fields $X,Y$ on $M$ and any point $p \in M$, $$ g_{h \cdot p} \big(h_{*,p}(X_p),h_{*,p}(Y_p)\big) = g_p\big(X_p,Y_p) \,. $$ It also means that if we fix any point $p \in M$ and denote by $K$ the isotropy subgroup associated with $p$ then there is a smooth bijection $\varphi \colon G / K \to M$ given by $\varphi(hK) =  h \cdot p$. Ok, this map then allows us to endow $G / K$ with a metric $\tilde g$ as follows: we decompose the Lie algebra $\mathfrak g$ of $G$ into $\mathfrak m \oplus \mathfrak k$ where $\mathfrak k$ is the Lie subalgebra of $K$ in $\mathfrak g$. Then we have an identification $T_pM \cong \mathfrak m \cong T_K(G/K)$, which allows us to set the value of $\tilde g$ at the point $hK$ on vector fields $X,Y$ over $G/K$ by $$ 	\tilde g_{hK}\big((L_{hK})_{*}(X_{K}),(L_{hK})_{*}(Y_{K})\big) := g_{p}\big(X_{K},Y_{K}\big) $$ where $L_{hK}$ denotes left translation in $G / K$ by $hK$ and we use the isomorphism $T_pM \cong \mathfrak m \cong T_K(G/K)$  to identify $X_K$ and $Y_K$ with elements in $T_pM$. This metric is manifestly invariant under left translation by $G$ (simply because the right hand side does not see the effect of left translation), i.e. $\tilde g$ is a $G$ - invariant metric on $G / K$. Is this also called a homogeneous metric? I know what homogeneous Riemannian manifolds are, these are precisely of the form given above, where a Lie group acts transitively by isometries, however when it comes to the notion of a homogeneous metric I would have to \emph{guess} that by this is meant the construction above .. is it correct? In other words, do we mean then that $(G/K,\tilde g)$ is a homogeneous Riemannian manifold? Thanks a lot for your feedback and help!!","I have trouble putting down the notion of a homogeneous Riemannian metric. Suppose we are given a Riemannian manifold $(M,g)$ on which a compact Lie group $G$ acts transitively by isometries (this means that $h^*g = g$ for any $h \in G$, i.e. for any vector fields $X,Y$ on $M$ and any point $p \in M$, $$ g_{h \cdot p} \big(h_{*,p}(X_p),h_{*,p}(Y_p)\big) = g_p\big(X_p,Y_p) \,. $$ It also means that if we fix any point $p \in M$ and denote by $K$ the isotropy subgroup associated with $p$ then there is a smooth bijection $\varphi \colon G / K \to M$ given by $\varphi(hK) =  h \cdot p$. Ok, this map then allows us to endow $G / K$ with a metric $\tilde g$ as follows: we decompose the Lie algebra $\mathfrak g$ of $G$ into $\mathfrak m \oplus \mathfrak k$ where $\mathfrak k$ is the Lie subalgebra of $K$ in $\mathfrak g$. Then we have an identification $T_pM \cong \mathfrak m \cong T_K(G/K)$, which allows us to set the value of $\tilde g$ at the point $hK$ on vector fields $X,Y$ over $G/K$ by $$ 	\tilde g_{hK}\big((L_{hK})_{*}(X_{K}),(L_{hK})_{*}(Y_{K})\big) := g_{p}\big(X_{K},Y_{K}\big) $$ where $L_{hK}$ denotes left translation in $G / K$ by $hK$ and we use the isomorphism $T_pM \cong \mathfrak m \cong T_K(G/K)$  to identify $X_K$ and $Y_K$ with elements in $T_pM$. This metric is manifestly invariant under left translation by $G$ (simply because the right hand side does not see the effect of left translation), i.e. $\tilde g$ is a $G$ - invariant metric on $G / K$. Is this also called a homogeneous metric? I know what homogeneous Riemannian manifolds are, these are precisely of the form given above, where a Lie group acts transitively by isometries, however when it comes to the notion of a homogeneous metric I would have to \emph{guess} that by this is meant the construction above .. is it correct? In other words, do we mean then that $(G/K,\tilde g)$ is a homogeneous Riemannian manifold? Thanks a lot for your feedback and help!!",,"['differential-geometry', 'riemannian-geometry', 'group-actions']"
99,Finding Riemannian metric from this geodesic,Finding Riemannian metric from this geodesic,,"In a $d$-dimensional Riemannian manifold, given a geodesic equation $\gamma^i(t)=a^i\phi(tb^i),i\in 1\ldots d$, where $\phi:\mathbb{R}\rightarrow\mathbb{R}$ is an increasing function, $a^i,b^i$ are constants, is it possible to determine a Riemannian metric (and the corresponding Christoffel symbols) that derives such a geodesic?","In a $d$-dimensional Riemannian manifold, given a geodesic equation $\gamma^i(t)=a^i\phi(tb^i),i\in 1\ldots d$, where $\phi:\mathbb{R}\rightarrow\mathbb{R}$ is an increasing function, $a^i,b^i$ are constants, is it possible to determine a Riemannian metric (and the corresponding Christoffel symbols) that derives such a geodesic?",,"['differential-geometry', 'riemannian-geometry']"
