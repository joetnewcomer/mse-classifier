,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can one define the Lebesgue integral with nonstandard analysis?,Can one define the Lebesgue integral with nonstandard analysis?,,"Reading Keisler's books about non-standard analysis, I have begun to suspect the possibility that there may not be an adequate characterization of the Lebesgue integral and of measure theory in general using non-standard analysis. Question: Is this an actual weakness of non-standard analysis?  Or is Keisler not doing the subject justice by failing to mention that the Lebesgue integral and its generalizations can also be well understood in the framework of nonstandard analysis? Explaining in detail how the construction of the Lebesgue integral carries over to non-standard analysis would be too broad and too much to ask or expect of any answer, so I will without hesitation accept answers only giving references to sources which discuss this issue. This is why I have tagged the question (reference-request). Background: I have been reading Keisler's books about non-standard analysis, the introductory Calculus: An Infinitesimal Approach and the more advanced and rigorous Foundations of Infinitesimal Calculus . The argument for why differentiation is more intuitive with non-standard analysis is fairly clear to me, however, I am not convinced yet that the same is true of integration. Specifically, both of Keisler's books only mention how to perform Riemann integration using non-standard analysis, but say nothing about Lebesgue integration (i.e. general integration with respect to an arbitrary measure, not just the Lebesgue measure on $\mathbb{R}$ and its subsets). In fact, the Lebesgue integral is not mentioned at all. To me at least, this seems like an unusually large omission, at least from Foundations of Infinitesimal Calculus , which seems to be fairly rigorous.","Reading Keisler's books about non-standard analysis, I have begun to suspect the possibility that there may not be an adequate characterization of the Lebesgue integral and of measure theory in general using non-standard analysis. Question: Is this an actual weakness of non-standard analysis?  Or is Keisler not doing the subject justice by failing to mention that the Lebesgue integral and its generalizations can also be well understood in the framework of nonstandard analysis? Explaining in detail how the construction of the Lebesgue integral carries over to non-standard analysis would be too broad and too much to ask or expect of any answer, so I will without hesitation accept answers only giving references to sources which discuss this issue. This is why I have tagged the question (reference-request). Background: I have been reading Keisler's books about non-standard analysis, the introductory Calculus: An Infinitesimal Approach and the more advanced and rigorous Foundations of Infinitesimal Calculus . The argument for why differentiation is more intuitive with non-standard analysis is fairly clear to me, however, I am not convinced yet that the same is true of integration. Specifically, both of Keisler's books only mention how to perform Riemann integration using non-standard analysis, but say nothing about Lebesgue integration (i.e. general integration with respect to an arbitrary measure, not just the Lebesgue measure on $\mathbb{R}$ and its subsets). In fact, the Lebesgue integral is not mentioned at all. To me at least, this seems like an unusually large omission, at least from Foundations of Infinitesimal Calculus , which seems to be fairly rigorous.",,"['measure-theory', 'reference-request', 'lebesgue-integral', 'nonstandard-analysis']"
1,Lusin's theorem from Rudin RCA,Lusin's theorem from Rudin RCA,,"Hi! Let me ask questions on Lusin's theorem from Rudin's RCA. $1)$ As we know $s_n=\varphi_n \circ f$ (from Theorem 1.17) then $$2^nt_n(x)=2^n(s_n(x)-s_{n-1}(x))=2^n(\varphi_n \circ f(x)-\varphi_{n-1} \circ f(x))=\dots$$ As $0\leq f<1$ then $$\dots=2^n\left(\dfrac{[2^nf(x)]}{2^n}-\dfrac{[2^{n-1}f(x)]}{2^{n-1}}\right)=[2^nf(x)]-2[2^{n-1}f(x)]$$ where $[\cdot]$ - integer part. Also the last equality above can be equal $0$ or $1$ since $[2\theta]-2[\theta]\in \{0,1\}$. An it's equal to $1$ if $\theta\in \bigcup \limits_{k\in \mathbb{Z}}[k+\frac{1}{2},k+1)$. So $2^nt_n(x)=1$ if $2^{n-1}f(x) \in \bigcup \limits_{k\in \mathbb{Z}}[k+\frac{1}{2},k+1)$ $\Rightarrow$ $x  \in \bigcup \limits_{k\in \mathbb{Z}}f^{-1}([2^{-(n-1)}(k+\frac{1}{2}),2^{-(n-1)}(k+1)))$. So $T_n$ is the last set and it's measurable, i.e. $T_n \in \mathfrak{M}$. Am I right? $2)$ When he write that ""$(1)$ holds if $A$ is compact and $f$ is a bounded measurable function"" what does he mean about $f$? Non-negative function or not? Is non-negative then we must replace $f$ by $\alpha^{-1}f$ where $\alpha=\sup f+1$. $3)$ Let's Go further. Let's take a look at penultimate paragraph which I marked by red line. I understood that if $A$ is any set with finite measure then by inner regularity we can find compact set $K\subset A$ such that $m(A-K)$ as small as needed. Note that $f$ outside $K$ possibly is not zero! And we can't apply above proof because there we use that $f=0$ on $A^c$. $4)$ Also why considers sets $B_n$? Also it's not obvious to me how he got the general case. Would be very grateful if somebody explain what he does in this paragraph. I spent about one day but no results :( In my opinion this paragraph is very brief and horrible.","Hi! Let me ask questions on Lusin's theorem from Rudin's RCA. $1)$ As we know $s_n=\varphi_n \circ f$ (from Theorem 1.17) then $$2^nt_n(x)=2^n(s_n(x)-s_{n-1}(x))=2^n(\varphi_n \circ f(x)-\varphi_{n-1} \circ f(x))=\dots$$ As $0\leq f<1$ then $$\dots=2^n\left(\dfrac{[2^nf(x)]}{2^n}-\dfrac{[2^{n-1}f(x)]}{2^{n-1}}\right)=[2^nf(x)]-2[2^{n-1}f(x)]$$ where $[\cdot]$ - integer part. Also the last equality above can be equal $0$ or $1$ since $[2\theta]-2[\theta]\in \{0,1\}$. An it's equal to $1$ if $\theta\in \bigcup \limits_{k\in \mathbb{Z}}[k+\frac{1}{2},k+1)$. So $2^nt_n(x)=1$ if $2^{n-1}f(x) \in \bigcup \limits_{k\in \mathbb{Z}}[k+\frac{1}{2},k+1)$ $\Rightarrow$ $x  \in \bigcup \limits_{k\in \mathbb{Z}}f^{-1}([2^{-(n-1)}(k+\frac{1}{2}),2^{-(n-1)}(k+1)))$. So $T_n$ is the last set and it's measurable, i.e. $T_n \in \mathfrak{M}$. Am I right? $2)$ When he write that ""$(1)$ holds if $A$ is compact and $f$ is a bounded measurable function"" what does he mean about $f$? Non-negative function or not? Is non-negative then we must replace $f$ by $\alpha^{-1}f$ where $\alpha=\sup f+1$. $3)$ Let's Go further. Let's take a look at penultimate paragraph which I marked by red line. I understood that if $A$ is any set with finite measure then by inner regularity we can find compact set $K\subset A$ such that $m(A-K)$ as small as needed. Note that $f$ outside $K$ possibly is not zero! And we can't apply above proof because there we use that $f=0$ on $A^c$. $4)$ Also why considers sets $B_n$? Also it's not obvious to me how he got the general case. Would be very grateful if somebody explain what he does in this paragraph. I spent about one day but no results :( In my opinion this paragraph is very brief and horrible.",,"['real-analysis', 'measure-theory']"
2,Borel measurability of a subset of a product space,Borel measurability of a subset of a product space,,"Let $X$ and $Y$ be compact metric spaces and let $\mathcal B_X$ and $\mathcal B_Y$ be their respective Borel $\sigma$-algebras. Let $\mu$ be a Borel probability measure on $X$ and let $\mathcal B^*_X$ be the $\mu$-completion of $\mathcal B_X$. If $E$ belongs to the product $\sigma$-algebra $\mathcal B^*_X\otimes\mathcal B_Y$, does there exist a $\mu$-null set $A$ in $\mathcal B_X$ such that $E\cup(A\times Y)\in\mathcal B_X\otimes\mathcal B_Y$?","Let $X$ and $Y$ be compact metric spaces and let $\mathcal B_X$ and $\mathcal B_Y$ be their respective Borel $\sigma$-algebras. Let $\mu$ be a Borel probability measure on $X$ and let $\mathcal B^*_X$ be the $\mu$-completion of $\mathcal B_X$. If $E$ belongs to the product $\sigma$-algebra $\mathcal B^*_X\otimes\mathcal B_Y$, does there exist a $\mu$-null set $A$ in $\mathcal B_X$ such that $E\cup(A\times Y)\in\mathcal B_X\otimes\mathcal B_Y$?",,"['measure-theory', 'metric-spaces', 'product-space']"
3,Proof verification : a very useful theorem (in measure theory),Proof verification : a very useful theorem (in measure theory),,"Let  $\bigcup_{n=1}^\infty E_n=E$ and $ E_{n}  \subseteq  E_{n+1} $ then $\lim\limits_{n\mapsto \infty} \mu^*(E_n) = \mu^*(E) $ even if each $E_n$ is a non-measurable set, where $\mu^*$ is outer measure. $E$ is a bounded set . Please could you verify the proof given here? The theorem is true for measurable sets. Proof for the general case: There is a subsequence { $ E_k $} such that $\mu^* (E_{k+1} ) - \mu^* (E_k ) \le \frac {\epsilon}{2^{k+1}} $ Lets first construct such subsequence : $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) \ge \mu^*(E_{n+1}) \ge \mu^*(E_n)$ Choose $E_1$ such that $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_1) \le \frac {\epsilon}{2} $ Choose $E_2$ such that $E_1 \subseteq E_2$ and  $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_2) \le \frac {\epsilon}{2^3}  $ Choose $E_3$ such that $E_2 \subseteq E_3$ and  $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_3) \le \frac {\epsilon}{2^4}  $  Then use induction Step 1: cover $E_k$ with union of open intervals $\bigcup_{i=1}^\infty I_i = L_k $ Such that $ \mu^* (L_k) \le \mu^* (E_k) +  \frac {\epsilon}{2^k} $ By Caratheodory condition $ \mu^* (E_{k+1} \bigcap L_k^c ) = \mu^* (E_{k+1} ) - \mu^* (E_{k+1} \bigcap L_k ) $ $\mu^*(E_k) \le  \mu^*(E_{k+1} \bigcap L_k ) \le \mu^*(L_k) $ Therefore  $ \mu^*(E_{k+1} \bigcap L_k^c ) \le \mu^*(E_{k+1}) - \mu^* (E_k) \le \frac {\epsilon}{2^{k+1}}$ Step 2 : Let $ G_{k+1} = E_{k+1} \bigcap L_k^c $ $ L_k \bigcup G_{k+1}$ contains $E_{k+1}$ Now cover  $ L_k \bigcup G_{k+1}$ with union of intervals $\bigcup_{i=1}^\infty I_i = H_{k+1} $ Such that $\mu^* (H_{k+1}) \le \mu^*( L_k \bigcup G_{k+1}) + \frac {\epsilon}{2^{k+1}} $ $\mu^* (H_{k+1}) \le \mu^*( L_k) + \mu^*( G_{k+1})  \le \mu^*(E_k) +  \frac { \epsilon}{2^k} +\frac { 2\epsilon}{2^{k+1} }$ Now using $H_{k+1} $ as the cover for $ E_{k+1} $ As seen  $\mu^*(E_{k+1})  \le \mu^*(H_{k+1})$  $\le \mu^*(E_{k+1})$ $+  \frac {\epsilon}{2^k}$ $+\frac {2\epsilon}{2^{k+1}}  $ Now apply step 1 and 2 to $ E_{k+1}$  and $ E_{k+2}$ and get : $  \mu^*(E_{k+2})  \le \mu^* (H_{k+2})  \le \mu^*(E_{k+2})  +  \frac { \epsilon}{2^k} +\frac { 2\epsilon}{2^{k+1} } +\frac { 2\epsilon}{2^{k+2} }$ It is obvious $ E \subseteq \bigcup_{i=1}^\infty H_k   $ $H_k \subseteq H_{k+1}$ $  \mu^*(E_{k})  \le \mu^* (H_{k})  \le \mu^*(E_{k}) + 4 \epsilon $ Notice that the theorem is valid for $H_k$ as it is a measurable set (union of intervals) So $\lim\limits_{k\mapsto \infty} \mu^*(H_k) \ge  \mu^*(E) $ $\lim\limits_{k\mapsto \infty}\mu^*(E_{k})  \le  \lim\limits_{k\mapsto \infty} \mu^*(H_k)    \le \lim\limits_{k\mapsto \infty}\mu^*(E_{k})  + 4\epsilon $ $\lim\limits_{k\mapsto \infty}\mu^*(E_{k}) \le \mu^*(E)     \le \lim\limits_{k\mapsto \infty}\mu^*(E_{k})  + 4\epsilon $ Because $\epsilon $ is arbitrary the proof is complete. Remark: The proof is straight forward for measurable sets but not so for arbitrary sets. Actually it is true and it was given as an exercise in 'The Integrals of Lebesgue, Denjoy , Perron , and Henstock (Graduate Studies in Mathematics Volume 4 )' by Russell A. Gordon . It is theorem 1.15 in the book. This theorem allows the short proofs of Dominated convergence theorem, Vitali Convergence Theorem, Monotone Convergence Theorem , Egorov's theorem and Luzin's theorem without dwelling much on the machinery of measure theory.","Let  $\bigcup_{n=1}^\infty E_n=E$ and $ E_{n}  \subseteq  E_{n+1} $ then $\lim\limits_{n\mapsto \infty} \mu^*(E_n) = \mu^*(E) $ even if each $E_n$ is a non-measurable set, where $\mu^*$ is outer measure. $E$ is a bounded set . Please could you verify the proof given here? The theorem is true for measurable sets. Proof for the general case: There is a subsequence { $ E_k $} such that $\mu^* (E_{k+1} ) - \mu^* (E_k ) \le \frac {\epsilon}{2^{k+1}} $ Lets first construct such subsequence : $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) \ge \mu^*(E_{n+1}) \ge \mu^*(E_n)$ Choose $E_1$ such that $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_1) \le \frac {\epsilon}{2} $ Choose $E_2$ such that $E_1 \subseteq E_2$ and  $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_2) \le \frac {\epsilon}{2^3}  $ Choose $E_3$ such that $E_2 \subseteq E_3$ and  $ \lim\limits_{n\mapsto \infty}\mu^*(E_n) -\mu^*(E_3) \le \frac {\epsilon}{2^4}  $  Then use induction Step 1: cover $E_k$ with union of open intervals $\bigcup_{i=1}^\infty I_i = L_k $ Such that $ \mu^* (L_k) \le \mu^* (E_k) +  \frac {\epsilon}{2^k} $ By Caratheodory condition $ \mu^* (E_{k+1} \bigcap L_k^c ) = \mu^* (E_{k+1} ) - \mu^* (E_{k+1} \bigcap L_k ) $ $\mu^*(E_k) \le  \mu^*(E_{k+1} \bigcap L_k ) \le \mu^*(L_k) $ Therefore  $ \mu^*(E_{k+1} \bigcap L_k^c ) \le \mu^*(E_{k+1}) - \mu^* (E_k) \le \frac {\epsilon}{2^{k+1}}$ Step 2 : Let $ G_{k+1} = E_{k+1} \bigcap L_k^c $ $ L_k \bigcup G_{k+1}$ contains $E_{k+1}$ Now cover  $ L_k \bigcup G_{k+1}$ with union of intervals $\bigcup_{i=1}^\infty I_i = H_{k+1} $ Such that $\mu^* (H_{k+1}) \le \mu^*( L_k \bigcup G_{k+1}) + \frac {\epsilon}{2^{k+1}} $ $\mu^* (H_{k+1}) \le \mu^*( L_k) + \mu^*( G_{k+1})  \le \mu^*(E_k) +  \frac { \epsilon}{2^k} +\frac { 2\epsilon}{2^{k+1} }$ Now using $H_{k+1} $ as the cover for $ E_{k+1} $ As seen  $\mu^*(E_{k+1})  \le \mu^*(H_{k+1})$  $\le \mu^*(E_{k+1})$ $+  \frac {\epsilon}{2^k}$ $+\frac {2\epsilon}{2^{k+1}}  $ Now apply step 1 and 2 to $ E_{k+1}$  and $ E_{k+2}$ and get : $  \mu^*(E_{k+2})  \le \mu^* (H_{k+2})  \le \mu^*(E_{k+2})  +  \frac { \epsilon}{2^k} +\frac { 2\epsilon}{2^{k+1} } +\frac { 2\epsilon}{2^{k+2} }$ It is obvious $ E \subseteq \bigcup_{i=1}^\infty H_k   $ $H_k \subseteq H_{k+1}$ $  \mu^*(E_{k})  \le \mu^* (H_{k})  \le \mu^*(E_{k}) + 4 \epsilon $ Notice that the theorem is valid for $H_k$ as it is a measurable set (union of intervals) So $\lim\limits_{k\mapsto \infty} \mu^*(H_k) \ge  \mu^*(E) $ $\lim\limits_{k\mapsto \infty}\mu^*(E_{k})  \le  \lim\limits_{k\mapsto \infty} \mu^*(H_k)    \le \lim\limits_{k\mapsto \infty}\mu^*(E_{k})  + 4\epsilon $ $\lim\limits_{k\mapsto \infty}\mu^*(E_{k}) \le \mu^*(E)     \le \lim\limits_{k\mapsto \infty}\mu^*(E_{k})  + 4\epsilon $ Because $\epsilon $ is arbitrary the proof is complete. Remark: The proof is straight forward for measurable sets but not so for arbitrary sets. Actually it is true and it was given as an exercise in 'The Integrals of Lebesgue, Denjoy , Perron , and Henstock (Graduate Studies in Mathematics Volume 4 )' by Russell A. Gordon . It is theorem 1.15 in the book. This theorem allows the short proofs of Dominated convergence theorem, Vitali Convergence Theorem, Monotone Convergence Theorem , Egorov's theorem and Luzin's theorem without dwelling much on the machinery of measure theory.",,"['measure-theory', 'proof-verification', 'lebesgue-measure', 'alternative-proof']"
4,"Let $f: [0, 1] \to \mathbb{R}$ s.t $f(0)=f(1)=0$ then measure of $A = \{h \in [0, 1] \mid \exists x \text{ such that }f(x+h) =f(x)\} \geq 1/2$.",Let  s.t  then measure of .,"f: [0, 1] \to \mathbb{R} f(0)=f(1)=0 A = \{h \in [0, 1] \mid \exists x \text{ such that }f(x+h) =f(x)\} \geq 1/2","Let $f:[0,1]\to\mathbb R$ be a continuous function s.t. $f(0)=f(1)=0$. Let $$A = \{h \in [0, 1] \mid \exists x \text{ such that }f(x+h) =f(x)\}.$$ Show that set $A$ has Lebesgue measure $\geq 1/2$. I have no clue to prove the claim. Can anyone give me some detail hints? Thank you in advance.","Let $f:[0,1]\to\mathbb R$ be a continuous function s.t. $f(0)=f(1)=0$. Let $$A = \{h \in [0, 1] \mid \exists x \text{ such that }f(x+h) =f(x)\}.$$ Show that set $A$ has Lebesgue measure $\geq 1/2$. I have no clue to prove the claim. Can anyone give me some detail hints? Thank you in advance.",,"['real-analysis', 'measure-theory', 'continuity', 'lebesgue-measure']"
5,Measurability of product measures $ \{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M}$,Measurability of product measures, \{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M},"Let $(X,\mathscr{F})$ be a measurable space, and let $M$ be the set all probability measures $\mu: \mathscr{F} \to [0,1]$. Let us denote with $\mathscr{M}$ the $\sigma$-algebra on $M$ generated by the mappings $\mu \to \mu(F)$, with $F \in \mathscr{F}$. Now fix a Borel set $B$ of $\mathbb{R}$ and $A \in \mathscr{F} \otimes \mathscr{F}$. How can we prove that $$ \{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M}? $$ [Here $(\mu\times \mu)$ stands for the product measure and $\mathscr{F}\otimes \mathscr{F}$ for the product $\sigma$-algebra] [Linked thread on MO: here]","Let $(X,\mathscr{F})$ be a measurable space, and let $M$ be the set all probability measures $\mu: \mathscr{F} \to [0,1]$. Let us denote with $\mathscr{M}$ the $\sigma$-algebra on $M$ generated by the mappings $\mu \to \mu(F)$, with $F \in \mathscr{F}$. Now fix a Borel set $B$ of $\mathbb{R}$ and $A \in \mathscr{F} \otimes \mathscr{F}$. How can we prove that $$ \{\mu \in M: (\mu \times \mu)(A) \in B\} \in \mathscr{M}? $$ [Here $(\mu\times \mu)$ stands for the product measure and $\mathscr{F}\otimes \mathscr{F}$ for the product $\sigma$-algebra] [Linked thread on MO: here]",,['real-analysis']
6,uniform boundedness principle for $L^{1}$,uniform boundedness principle for,L^{1},"i read this theorem from V.I.Bogachev vol 1 Measure Theory. A family $\mathcal{F}\subset L_{1}(\mu)$,where the measure $\mu$ takes values in $[0,+\infty]$, is norm bounded in $L_{1}(\mu)$ precisely for every $\mathcal{A}\subset A$ one has $$\sup_{f\in\mathcal{F}}|\int_{A}f d\mu |<\infty $$ Can anyone tell where i can find o simple proof of this theorem, because i can't understand the proof from Bogachev. Thanks.","i read this theorem from V.I.Bogachev vol 1 Measure Theory. A family $\mathcal{F}\subset L_{1}(\mu)$,where the measure $\mu$ takes values in $[0,+\infty]$, is norm bounded in $L_{1}(\mu)$ precisely for every $\mathcal{A}\subset A$ one has $$\sup_{f\in\mathcal{F}}|\int_{A}f d\mu |<\infty $$ Can anyone tell where i can find o simple proof of this theorem, because i can't understand the proof from Bogachev. Thanks.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'lp-spaces']"
7,"Dense subsets of the metric space of measurable sets with metric $d\left(A,B\right)=\mu\left(A\triangle B\right) $",Dense subsets of the metric space of measurable sets with metric,"d\left(A,B\right)=\mu\left(A\triangle B\right) ","Let $\left(X,\mathcal{F},\mu\right)$   be a finite measure space and define a relation on $\mathcal{F}$   by $A\sim B\iff\mu\left(A\triangle B\right)=0$  . It can be shown this is an equivalence relation, that $d\left(A,B\right):=\mu\left(A\triangle B\right)$  is a metric on the quotient $\mathcal{F}^{*}:=\frac{\mathcal{F}}{\sim}$   and that this metric space is complete. Now let $\mathcal{A}\subseteq\mathcal{F}$   be an algebra s.t $\mathcal{F}=\sigma\left(A\right)$   and let $\mathcal{A}^{*}:=\frac{\mathcal{A}}{\sim}$  , I want to show that $\mathcal{A}^{*}$   is dense in $\left(\mathcal{F}^{*},d\right)$  . To do that it would suffice to show that for any $F\in\mathcal{F}$   and any $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu\left(A\triangle F\right)<\varepsilon$   but I haven't been able to do that directly. This is very reminiscent of something I saw in a proof of Caratheodory's theorem. If you consider $\mu$   to be a measure on $\mathcal{A}$  , disregarding $\mathcal{F}$, define an outer-measure $\mu_{0}$   on $\mathcal{P}\left(X\right)$   by $$\mu_{0}\left(B\right):=\inf\left\{ \sum_{j=1}^{\infty}\mathbb{\mu}\left(A_{j}\right)\ |\ B\subseteq\bigcup_{j=1}^{\infty}A_{j}\ ,A_{j}\in\mathcal{A}\ \forall j\right\}  $$   And define a set $E\in\mathcal{P}\left(X\right)$   to be $\mu_{0}$  -measurable if for all $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu_{0}\left(A\triangle E\right)<\varepsilon$  . Then it can be shown that the collection $\mathcal{M}$   of $\mu_{0}$  -measurable sets is a $\sigma$  -algebra containing $\mathcal{F}=\sigma\left(\mathcal{A}\right)$   which proves that for any $F\in\mathcal{F}$   and any $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu_{0}\left(A\triangle F\right)<\varepsilon$  . I'm guessing one can combine this with the fact that in fact $\mu_{0}\equiv\mu$   on $\mathcal{F}$   (easily proven by $\pi-\lambda$   theorem) and get the required result. But this is a really convoluted way of proving something I feel should be fairly simple....","Let $\left(X,\mathcal{F},\mu\right)$   be a finite measure space and define a relation on $\mathcal{F}$   by $A\sim B\iff\mu\left(A\triangle B\right)=0$  . It can be shown this is an equivalence relation, that $d\left(A,B\right):=\mu\left(A\triangle B\right)$  is a metric on the quotient $\mathcal{F}^{*}:=\frac{\mathcal{F}}{\sim}$   and that this metric space is complete. Now let $\mathcal{A}\subseteq\mathcal{F}$   be an algebra s.t $\mathcal{F}=\sigma\left(A\right)$   and let $\mathcal{A}^{*}:=\frac{\mathcal{A}}{\sim}$  , I want to show that $\mathcal{A}^{*}$   is dense in $\left(\mathcal{F}^{*},d\right)$  . To do that it would suffice to show that for any $F\in\mathcal{F}$   and any $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu\left(A\triangle F\right)<\varepsilon$   but I haven't been able to do that directly. This is very reminiscent of something I saw in a proof of Caratheodory's theorem. If you consider $\mu$   to be a measure on $\mathcal{A}$  , disregarding $\mathcal{F}$, define an outer-measure $\mu_{0}$   on $\mathcal{P}\left(X\right)$   by $$\mu_{0}\left(B\right):=\inf\left\{ \sum_{j=1}^{\infty}\mathbb{\mu}\left(A_{j}\right)\ |\ B\subseteq\bigcup_{j=1}^{\infty}A_{j}\ ,A_{j}\in\mathcal{A}\ \forall j\right\}  $$   And define a set $E\in\mathcal{P}\left(X\right)$   to be $\mu_{0}$  -measurable if for all $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu_{0}\left(A\triangle E\right)<\varepsilon$  . Then it can be shown that the collection $\mathcal{M}$   of $\mu_{0}$  -measurable sets is a $\sigma$  -algebra containing $\mathcal{F}=\sigma\left(\mathcal{A}\right)$   which proves that for any $F\in\mathcal{F}$   and any $\varepsilon>0$   there exists $A\in\mathcal{A}$   s.t $\mu_{0}\left(A\triangle F\right)<\varepsilon$  . I'm guessing one can combine this with the fact that in fact $\mu_{0}\equiv\mu$   on $\mathcal{F}$   (easily proven by $\pi-\lambda$   theorem) and get the required result. But this is a really convoluted way of proving something I feel should be fairly simple....",,"['real-analysis', 'measure-theory']"
8,Dilations of Integrable Function Converge to Zero Almost Everywhere,Dilations of Integrable Function Converge to Zero Almost Everywhere,,"Suppose $f:[0,\infty)\rightarrow [0,\infty)$ is integrable. Set $f_{n}(x):=f(nx)$. I want to show that $f_{n}(x)\rightarrow 0$ almost everywhere or equivalently, the set $$\{x : \limsup_{n}f_{n}(x)\geq\delta\}$$ has measure zero, for any $\delta>0$. By dilation invariance, it's clear that $f_{n}\rightarrow 0$ in $L^{1}$ and therefore also in measure. Furthermore, we can pass to a subsequence to obtain a.e. convergence. If $f$ has compact support, then it's obvious that $f_{n}\rightarrow 0$ almost everywhere. My thought was to try approximating $f$ in $L^{1}$ by $g\in C_{c}(\mathbb{R})$ and use something like $$|\{\limsup f_{n}\geq\delta\}|\leq|\{\limsup|f_{n}-g_{n}|\geq\delta/2\}|+|\{\limsup|g_{n}|\geq\delta/2\}|$$ and go from there. But I'm not sure how to control the first term on the RHS. Any suggestions?","Suppose $f:[0,\infty)\rightarrow [0,\infty)$ is integrable. Set $f_{n}(x):=f(nx)$. I want to show that $f_{n}(x)\rightarrow 0$ almost everywhere or equivalently, the set $$\{x : \limsup_{n}f_{n}(x)\geq\delta\}$$ has measure zero, for any $\delta>0$. By dilation invariance, it's clear that $f_{n}\rightarrow 0$ in $L^{1}$ and therefore also in measure. Furthermore, we can pass to a subsequence to obtain a.e. convergence. If $f$ has compact support, then it's obvious that $f_{n}\rightarrow 0$ almost everywhere. My thought was to try approximating $f$ in $L^{1}$ by $g\in C_{c}(\mathbb{R})$ and use something like $$|\{\limsup f_{n}\geq\delta\}|\leq|\{\limsup|f_{n}-g_{n}|\geq\delta/2\}|+|\{\limsup|g_{n}|\geq\delta/2\}|$$ and go from there. But I'm not sure how to control the first term on the RHS. Any suggestions?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
9,Lipschitz continuous one-to-one mapping from subset $K\subset\mathbb{R}^n$ of positive measure to $\mathbb{R}^{n-1}$,Lipschitz continuous one-to-one mapping from subset  of positive measure to,K\subset\mathbb{R}^n \mathbb{R}^{n-1},"Let $f:\mathbb{R}^n\to \mathbb{R}^{n-1}$ and $K\subseteq \mathbb{R}^n$ be a set of positive Lebesgue measure. What kind of regularity do we have to impose on $f$ (e.g., $C^1$, Lipschitz) to conclude that $f$ cannot be one-to-one on $K$? Continuity is (in general) not enough, as demonstrated here . On the other hand, a nonvanishing Jacobian on a subset of $K$ of positive measure allows us to construct a contradiction by the coarea formula. But what if we cannot assume anything about the Jacobian? Is, e.g., Lipschitz continuous sufficient to construct a contradiction? Or do there exist Lipschitz continuous examples of one-to-one mappings? Edit: This seems to have a connection to singularity theory. Unfortunately, things like Sard's Theorem also don't help as it only tells me something about singular values but I would need some information about the possible size of singular points of a one-to-one mapping.","Let $f:\mathbb{R}^n\to \mathbb{R}^{n-1}$ and $K\subseteq \mathbb{R}^n$ be a set of positive Lebesgue measure. What kind of regularity do we have to impose on $f$ (e.g., $C^1$, Lipschitz) to conclude that $f$ cannot be one-to-one on $K$? Continuity is (in general) not enough, as demonstrated here . On the other hand, a nonvanishing Jacobian on a subset of $K$ of positive measure allows us to construct a contradiction by the coarea formula. But what if we cannot assume anything about the Jacobian? Is, e.g., Lipschitz continuous sufficient to construct a contradiction? Or do there exist Lipschitz continuous examples of one-to-one mappings? Edit: This seems to have a connection to singularity theory. Unfortunately, things like Sard's Theorem also don't help as it only tells me something about singular values but I would need some information about the possible size of singular points of a one-to-one mapping.",,"['real-analysis', 'measure-theory', 'geometric-measure-theory', 'dimension-theory-analysis', 'singularity-theory']"
10,Applications of the completeness of $L^1$,Applications of the completeness of,L^1,"I'm teaching a measure theory class.  I think one of the main motivations for the development of the Lebesgue integral is that the space $L^1(\mathbb{R})$ of integrable functions on $\mathbb{R}$ is complete under the $L^1$ norm.  You can't get this if you stick to the Riemann integral. For further motivation, I would like to find some interesting applications of this fact; preferably elementary. For instance, is there some interesting function $f$ that one can construct by writing down a sequence of approximates $f_n$, showing that the sequence is $L^1$-Cauchy, and letting $f$ be its limit?  Ideally, it would not be obvious how to construct $f$ otherwise. I can think of lots of interesting applications of the completeness of $L^2$ (e.g. Fourier series) but not so much $L^1$.","I'm teaching a measure theory class.  I think one of the main motivations for the development of the Lebesgue integral is that the space $L^1(\mathbb{R})$ of integrable functions on $\mathbb{R}$ is complete under the $L^1$ norm.  You can't get this if you stick to the Riemann integral. For further motivation, I would like to find some interesting applications of this fact; preferably elementary. For instance, is there some interesting function $f$ that one can construct by writing down a sequence of approximates $f_n$, showing that the sequence is $L^1$-Cauchy, and letting $f$ be its limit?  Ideally, it would not be obvious how to construct $f$ otherwise. I can think of lots of interesting applications of the completeness of $L^2$ (e.g. Fourier series) but not so much $L^1$.",,"['real-analysis', 'measure-theory', 'examples-counterexamples', 'motivation']"
11,Proving uniqueness in Lebesgue decomposition,Proving uniqueness in Lebesgue decomposition,,"I'm reading a book(Measure, Integral and Probability by Capinski), where in the proof of the Lebesgue decomposition theorem, it leaves to the reader to prove uniqueness. As a hint, the authors state that we should use the following proposition: «Let $\mu,\nu, \lambda_1, \lambda_2$ measures on sigma algebra $\mathcal{F}$. Then we have: i) If $\lambda_1 \perp \mu$ and $\lambda_2 \perp \mu$, then $\lambda_1+\lambda_2 \perp \lambda_2$. ii) If $ \lambda_1 \ll \mu$, and $\lambda_2 \perp \mu$, then $\lambda_1 \perp \lambda_2$. iii) If $ \nu \ll \mu$, and $\nu \perp \mu$, then $\nu=0$.» I've tried using point iii) to the subtraction of the absolutely continuous part of the two representations of the same measure, but subtraction of two measures may not necessarily be a measure... Any help would be appreciated.","I'm reading a book(Measure, Integral and Probability by Capinski), where in the proof of the Lebesgue decomposition theorem, it leaves to the reader to prove uniqueness. As a hint, the authors state that we should use the following proposition: «Let $\mu,\nu, \lambda_1, \lambda_2$ measures on sigma algebra $\mathcal{F}$. Then we have: i) If $\lambda_1 \perp \mu$ and $\lambda_2 \perp \mu$, then $\lambda_1+\lambda_2 \perp \lambda_2$. ii) If $ \lambda_1 \ll \mu$, and $\lambda_2 \perp \mu$, then $\lambda_1 \perp \lambda_2$. iii) If $ \nu \ll \mu$, and $\nu \perp \mu$, then $\nu=0$.» I've tried using point iii) to the subtraction of the absolutely continuous part of the two representations of the same measure, but subtraction of two measures may not necessarily be a measure... Any help would be appreciated.",,['measure-theory']
12,The Scorza-Dragoni theorem as a consequence of Egorov's theorem?,The Scorza-Dragoni theorem as a consequence of Egorov's theorem?,,"Scorza-Dragoni theorem (at least the version I have used) says that if you have a function $f : \Omega \times \mathbb{R}^{N} \longrightarrow \overline{\mathbb{R}}$ which satisfies: i) $x \rightarrow f(x,v)$ is measurable for all $v \in \mathbb{R}^{N}$ ii) $v \rightarrow f(x,v)$ is continuous for  almost every $x \in \Omega$ iii) $f$ is locally integrable Then for any positive $\epsilon$ there exists a compact subset of $\Omega,$ say $K,$ such that $f$ restricted to $K \times \mathbb{R}^{N}$ is a continuous function and $\vert K^{c} \vert < \epsilon$ I tried to prove this before looking for it somewhere and came up with a stupidly simple proof, which confuses me, because if this were right, the theorem wouldn't have its own name :S My reasoning is: As we have a measurable function, we can approximate it pointwise by step functionts which, in turn, can be approximated pointwise by continuous functions almost everywhere . Theorefore, by Egorov's theorem we can find $K$ such that $\vert K^{c} \vert < \epsilon$ and such that those continuous functions converge uniformly. The limit on $K$ is then continuous and clearly coincides with the restriction of $f.$ There must be some subtle technical point I am omiting, because I guess the proof of a named theorem cannot be this silly. Where is my mistake? Thanks for your help EDIT: Added the almost everywhere that was missing","Scorza-Dragoni theorem (at least the version I have used) says that if you have a function $f : \Omega \times \mathbb{R}^{N} \longrightarrow \overline{\mathbb{R}}$ which satisfies: i) $x \rightarrow f(x,v)$ is measurable for all $v \in \mathbb{R}^{N}$ ii) $v \rightarrow f(x,v)$ is continuous for  almost every $x \in \Omega$ iii) $f$ is locally integrable Then for any positive $\epsilon$ there exists a compact subset of $\Omega,$ say $K,$ such that $f$ restricted to $K \times \mathbb{R}^{N}$ is a continuous function and $\vert K^{c} \vert < \epsilon$ I tried to prove this before looking for it somewhere and came up with a stupidly simple proof, which confuses me, because if this were right, the theorem wouldn't have its own name :S My reasoning is: As we have a measurable function, we can approximate it pointwise by step functionts which, in turn, can be approximated pointwise by continuous functions almost everywhere . Theorefore, by Egorov's theorem we can find $K$ such that $\vert K^{c} \vert < \epsilon$ and such that those continuous functions converge uniformly. The limit on $K$ is then continuous and clearly coincides with the restriction of $f.$ There must be some subtle technical point I am omiting, because I guess the proof of a named theorem cannot be this silly. Where is my mistake? Thanks for your help EDIT: Added the almost everywhere that was missing",,"['measure-theory', 'proof-verification']"
13,"Integral of $f(x)=\begin{cases} \sin(x), & \text{if } \cos(x)\in \mathbb{Q}\\\sin^2(x), & \text{if }\cos(x) \notin \mathbb{Q} \end{cases}$ [closed]",Integral of  [closed],"f(x)=\begin{cases} \sin(x), & \text{if } \cos(x)\in \mathbb{Q}\\\sin^2(x), & \text{if }\cos(x) \notin \mathbb{Q} \end{cases}","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Find $\displaystyle \int_0^{\pi/2} f(x)\,dx$ if$$f(x)=\begin{cases} \sin(x), & \text{if } \cos(x)\in \mathbb{Q}\\\sin^2(x), & \text{if } \cos(x) \notin \mathbb{Q} \end{cases}$$ I am not able to solve this problem. This problem is from Real analysis by royden.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Find $\displaystyle \int_0^{\pi/2} f(x)\,dx$ if$$f(x)=\begin{cases} \sin(x), & \text{if } \cos(x)\in \mathbb{Q}\\\sin^2(x), & \text{if } \cos(x) \notin \mathbb{Q} \end{cases}$$ I am not able to solve this problem. This problem is from Real analysis by royden.",,"['real-analysis', 'measure-theory']"
14,Weak $L^p$ implies strong $L^q$ for $q<p$,Weak  implies strong  for,L^p L^q q<p,"Another prelim question... Suppose $0<q<p<\infty$, and $E\subseteq \mathbb{R}^n$ has finite measure. Suppose $f$ is in weak $L^p$, i.e. $\lambda(|f| > t) \leq N/t^p$. Show $f \in L^q(E)$ and moreover $\int_E |f|^q \leq C_{n,p,q} N^{q/p}\lambda(E)^{1-q/p}$. First let's show $f \in L^q(E)$. For $g$ a strictly increasing function with $g(0)=0$ $$ \int_E |f|^q = \sum_{k} \int_E |f|^q 1_{g(k) < f \leq g(k+1)} \leq \sum_k g^q(k+1) (\lambda(f > g(k)) \wedge \lambda(E)) $$ $$ \leq\sum_k g^q(k+1) (\frac{N}{g^p(k)} \wedge \lambda(E)) $$ so it suffices to choose $g$ such that $\sum_{k\geq M} \frac{g^q(k+1)}{g^p(k)} < \infty$ for some $M$. Taking $g(k) = 2^k$ (except $g(0)=0$) and $M>1$ this turns into $\sum_{k\geq M} 2^q (2^{(q-p)})^n < \infty$ which is of course true. Okay so we have $f \in L^q(E)$. Now what can be done to show the bound? I've tried writng $|f|^q = (|f|^p)^{q/p}$ and using Fubini and Holder $$ \int_E |f|^q = \int_0^\infty \int \frac{p}{q}t^{p/q-1} 1_{E} 1_{0\leq |f|^p \leq t}dx dt \leq \int_0^\infty\frac{p}{q}t^{p/q-1} \lambda(E)^{1-q/p} \lambda(f>t^{1/p})^{q/p}dt $$ $$ = \frac{p}{q}\lambda(E)^{1-q/p} \int_0^\infty t^{p/q-1} \lambda(f>t^{1/p})^{q/p} dt $$ but I can't get an estiamte like this to turn out to be finite.","Another prelim question... Suppose $0<q<p<\infty$, and $E\subseteq \mathbb{R}^n$ has finite measure. Suppose $f$ is in weak $L^p$, i.e. $\lambda(|f| > t) \leq N/t^p$. Show $f \in L^q(E)$ and moreover $\int_E |f|^q \leq C_{n,p,q} N^{q/p}\lambda(E)^{1-q/p}$. First let's show $f \in L^q(E)$. For $g$ a strictly increasing function with $g(0)=0$ $$ \int_E |f|^q = \sum_{k} \int_E |f|^q 1_{g(k) < f \leq g(k+1)} \leq \sum_k g^q(k+1) (\lambda(f > g(k)) \wedge \lambda(E)) $$ $$ \leq\sum_k g^q(k+1) (\frac{N}{g^p(k)} \wedge \lambda(E)) $$ so it suffices to choose $g$ such that $\sum_{k\geq M} \frac{g^q(k+1)}{g^p(k)} < \infty$ for some $M$. Taking $g(k) = 2^k$ (except $g(0)=0$) and $M>1$ this turns into $\sum_{k\geq M} 2^q (2^{(q-p)})^n < \infty$ which is of course true. Okay so we have $f \in L^q(E)$. Now what can be done to show the bound? I've tried writng $|f|^q = (|f|^p)^{q/p}$ and using Fubini and Holder $$ \int_E |f|^q = \int_0^\infty \int \frac{p}{q}t^{p/q-1} 1_{E} 1_{0\leq |f|^p \leq t}dx dt \leq \int_0^\infty\frac{p}{q}t^{p/q-1} \lambda(E)^{1-q/p} \lambda(f>t^{1/p})^{q/p}dt $$ $$ = \frac{p}{q}\lambda(E)^{1-q/p} \int_0^\infty t^{p/q-1} \lambda(f>t^{1/p})^{q/p} dt $$ but I can't get an estiamte like this to turn out to be finite.",,"['real-analysis', 'measure-theory', 'lp-spaces']"
15,Proving a set is Lebesgue Measurable [duplicate],Proving a set is Lebesgue Measurable [duplicate],,"This question already has answers here : $E$ measurable set and $m(E\cap I)\le \frac{1}{2}m(I)$ for any open interval, prove $m(E) =0$ (2 answers) Closed 8 years ago . Measure is a serious weak point of mine, and I cannot figure out this problem: Let $E \subset \mathbb{R}$ be Lebesgue measurable. Suppose that for all open intervals $I$, we have $m(E\cap I) \leq \frac{1}{2} m(I)$, where $m$ denotes Lebesgue measure. Prove that $m(E)=0$. Any help is greatly appreciated!","This question already has answers here : $E$ measurable set and $m(E\cap I)\le \frac{1}{2}m(I)$ for any open interval, prove $m(E) =0$ (2 answers) Closed 8 years ago . Measure is a serious weak point of mine, and I cannot figure out this problem: Let $E \subset \mathbb{R}$ be Lebesgue measurable. Suppose that for all open intervals $I$, we have $m(E\cap I) \leq \frac{1}{2} m(I)$, where $m$ denotes Lebesgue measure. Prove that $m(E)=0$. Any help is greatly appreciated!",,"['measure-theory', 'lebesgue-measure']"
16,Small derivative and the measure of a set.,Small derivative and the measure of a set.,,"Suppose that $f:\mathbb{R}\to\mathbb{R}$ is a differentiable function, and that on some interval $(a,b)$, $|f'|\leq1$.  Is it true that for all measurable sets $E\subset(a,b)$, $\lambda(f(E))\leq\lambda(E)$?  (Here $\lambda$ denotes Lebesgue measure.)  The intuition is that a small derivative means that $f$ is ""shrinking sets"" in some sense.","Suppose that $f:\mathbb{R}\to\mathbb{R}$ is a differentiable function, and that on some interval $(a,b)$, $|f'|\leq1$.  Is it true that for all measurable sets $E\subset(a,b)$, $\lambda(f(E))\leq\lambda(E)$?  (Here $\lambda$ denotes Lebesgue measure.)  The intuition is that a small derivative means that $f$ is ""shrinking sets"" in some sense.",,"['real-analysis', 'measure-theory', 'derivatives', 'lebesgue-measure']"
17,A question about measure set,A question about measure set,,"Suppose that a sequence of sets $\{A_n:n\in \Bbb N\}$ is increasing, and $A=\bigcup_{n=1}^\infty A_n$. If $A$ is measurable, $\mu(A)\gt 0$ and $\mu$ is an atomless measure, do there exist an $n\in \Bbb N$ and a measurable set $B$ such that $B\subset A_n$ and $\mu(B)\gt0$.","Suppose that a sequence of sets $\{A_n:n\in \Bbb N\}$ is increasing, and $A=\bigcup_{n=1}^\infty A_n$. If $A$ is measurable, $\mu(A)\gt 0$ and $\mu$ is an atomless measure, do there exist an $n\in \Bbb N$ and a measurable set $B$ such that $B\subset A_n$ and $\mu(B)\gt0$.",,['measure-theory']
18,Decay of Fourier Transform,Decay of Fourier Transform,,"I encountered the following statement, and I cannot see why it is true(if it is). Suppose $f$ is a nonnegative, bounded, compactly supported and measurable function with the following properties: $||f||_1=1$, $|\widehat f(y)|<1$ for $y\neq 0$, $|\widehat f(0)|=1$ and $\frac{d}{dy}|\widehat f(y)|^2<0$. Then, the claim which I don't quite see how it follows is the following: For small $K$ and some $r>0$ we have $$\sup_{|y|\geq K}|\widehat f(y)|^2\leq e^{-r|K|^2}.$$ From the Riemann-Lebesgue lemma all we would get is decay of the order $1/K^2.$ Thanks","I encountered the following statement, and I cannot see why it is true(if it is). Suppose $f$ is a nonnegative, bounded, compactly supported and measurable function with the following properties: $||f||_1=1$, $|\widehat f(y)|<1$ for $y\neq 0$, $|\widehat f(0)|=1$ and $\frac{d}{dy}|\widehat f(y)|^2<0$. Then, the claim which I don't quite see how it follows is the following: For small $K$ and some $r>0$ we have $$\sup_{|y|\geq K}|\widehat f(y)|^2\leq e^{-r|K|^2}.$$ From the Riemann-Lebesgue lemma all we would get is decay of the order $1/K^2.$ Thanks",,"['real-analysis', 'measure-theory', 'fourier-analysis', 'asymptotics']"
19,measure of a set invariant by rational translation,measure of a set invariant by rational translation,,"Say that a measurable subset $A$ of $[0,1]$ is ${\mathbb Q}$-stable if $a+q\in A$ whenever $a\in A,q\in{\mathbb Q}$ and $a+q\in [0,1]$. Obviously, $\emptyset$ is ${\mathbb Q}$-stable and has measure zero, and $[0,1]$ is ${\mathbb Q}$-stable and has measure one. Are there ${\mathbb Q}$-stable subsets with measure other than $0$ or $1$ ? EDIT : Let $A$ be ${\mathbb Q}$-stable. It is easy to see that if $[a,b[$ and $[c,d[$ are two subintervals of $[0,1]$ with rational endpoints and with the same length ($d-c=b-a$), then $A\cap [c,d[=(c-a)+A\cap [a,b[$ whence $\mu(A\cap [c,d[)= \mu(A\cap [a,b[)$. It follows that there is a function $\alpha : [0,1] \to {\mathbb R}_{+}$  such that $\mu(A\cap [a,b[)=\alpha(b-a)$ for any rational $a<b$ in $[0,1]$. The map $\alpha$ is obviously nondecreasing. Also, if $x,y \in {\mathbb Q}$ are nonnnegative with $x+y\leq 1$ then $(A\cap [0,x+y[)$ is the disjoint union of  $(A\cap [0,x[)$ and $(A\cap [x,x+y[)$, and hence  $\alpha(x+y)=\alpha(x)+\alpha(y)$. It follows that there is a constant $c$ such that $\alpha(t)=ct$ for any $t\in{\mathbb Q}\cap [0,1[$. By monotonicity the inequality stays true if we take $t\in [0,1[$. Not sure about  how to finish from here.","Say that a measurable subset $A$ of $[0,1]$ is ${\mathbb Q}$-stable if $a+q\in A$ whenever $a\in A,q\in{\mathbb Q}$ and $a+q\in [0,1]$. Obviously, $\emptyset$ is ${\mathbb Q}$-stable and has measure zero, and $[0,1]$ is ${\mathbb Q}$-stable and has measure one. Are there ${\mathbb Q}$-stable subsets with measure other than $0$ or $1$ ? EDIT : Let $A$ be ${\mathbb Q}$-stable. It is easy to see that if $[a,b[$ and $[c,d[$ are two subintervals of $[0,1]$ with rational endpoints and with the same length ($d-c=b-a$), then $A\cap [c,d[=(c-a)+A\cap [a,b[$ whence $\mu(A\cap [c,d[)= \mu(A\cap [a,b[)$. It follows that there is a function $\alpha : [0,1] \to {\mathbb R}_{+}$  such that $\mu(A\cap [a,b[)=\alpha(b-a)$ for any rational $a<b$ in $[0,1]$. The map $\alpha$ is obviously nondecreasing. Also, if $x,y \in {\mathbb Q}$ are nonnnegative with $x+y\leq 1$ then $(A\cap [0,x+y[)$ is the disjoint union of  $(A\cap [0,x[)$ and $(A\cap [x,x+y[)$, and hence  $\alpha(x+y)=\alpha(x)+\alpha(y)$. It follows that there is a constant $c$ such that $\alpha(t)=ct$ for any $t\in{\mathbb Q}\cap [0,1[$. By monotonicity the inequality stays true if we take $t\in [0,1[$. Not sure about  how to finish from here.",,"['measure-theory', 'lebesgue-measure']"
20,questions about Folland real analysis chapter 1 exercise,questions about Folland real analysis chapter 1 exercise,,"Here, E is a Lesbegue-measurable set on the real line. This is the exercise 30, 31 of p. 40 of Folland real analysis. I solved these problems when E is of finite measure, but the problem requires that E may be of infinite measure. I'm quite desperate about how to solve these for general cases. Could anyone show me how to prove them?","Here, E is a Lesbegue-measurable set on the real line. This is the exercise 30, 31 of p. 40 of Folland real analysis. I solved these problems when E is of finite measure, but the problem requires that E may be of infinite measure. I'm quite desperate about how to solve these for general cases. Could anyone show me how to prove them?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
21,$\mu$ is a $f$-invariant measure,is a -invariant measure,\mu f,"Let $\left(M,\sigma\left(\tau\right),\mu\right)$ a measure space where $\mu$ is a measure finite, $\tau$ is a topology in $M$, i, e, $\sigma\left(\tau\right)$ is a Borel $\sigma-$algebra. Let $\mathcal{B}\subseteq\sigma\left(\tau\right)$ a collection of open subsets such that $\sigma\left(\tau\right)$ is generated by $\mathcal{B}$, then, given $f:M\rightarrow M$ measurable, $\mu$ is $f$-invariant if and only if $\mu\left(B\right)=\mu\left(f^{-1}\left(B\right)\right)$ for all $B\in\mathcal{B}$. Remark : If the collection $\mathcal{B}$ is a algebra, then the result is immediate. In this case there are two ways to prove this result.With this in mind the first thing I thought was to show that $\mathcal{B}$ is a algebra, but this is not always true, then i try to find a algebra  containing $\mathcal{B}$ and generating $\sigma\left(\tau\right)$, but so far I failed.","Let $\left(M,\sigma\left(\tau\right),\mu\right)$ a measure space where $\mu$ is a measure finite, $\tau$ is a topology in $M$, i, e, $\sigma\left(\tau\right)$ is a Borel $\sigma-$algebra. Let $\mathcal{B}\subseteq\sigma\left(\tau\right)$ a collection of open subsets such that $\sigma\left(\tau\right)$ is generated by $\mathcal{B}$, then, given $f:M\rightarrow M$ measurable, $\mu$ is $f$-invariant if and only if $\mu\left(B\right)=\mu\left(f^{-1}\left(B\right)\right)$ for all $B\in\mathcal{B}$. Remark : If the collection $\mathcal{B}$ is a algebra, then the result is immediate. In this case there are two ways to prove this result.With this in mind the first thing I thought was to show that $\mathcal{B}$ is a algebra, but this is not always true, then i try to find a algebra  containing $\mathcal{B}$ and generating $\sigma\left(\tau\right)$, but so far I failed.",,"['measure-theory', 'lebesgue-measure', 'ergodic-theory']"
22,Measurable functions on product space,Measurable functions on product space,,"Let $(\Omega, \mathcal{H}), (E, \mathcal{E})$ and $(F,\mathcal{F})$ be measurable spaces. Let $(E \times F, \mathcal{E} \otimes \mathcal{F})$ be a product space. Define the following three functions: $X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ $Y: (\Omega, \mathcal{H} \rightarrow (F,\mathcal{F})$ $Z = (X,Y): (\Omega, \mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ Now, I am trying to show that the following: $X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ and $Y:(\Omega, \mathcal{H}) \rightarrow (F,\mathcal{F})$ are measurable $\Leftrightarrow (X,Y): (\Omega,\mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ is measurable. Here is my current work: $(\Rightarrow):$ Since X and Y are both measurable, we have \begin{align*} Z^{-1}(E \times F) &= \{w \in \Omega: Z(w) \in E \times F\}\\ &= \{w \in \Omega:(X(w),Y(w)) \in E \times F\}\\ &= \{w \in \Omega: X(w) \in E\text{ and }Y(w) \in F\}\\ &= \{w \in \Omega: X(w) \in E \} \cap \{w \in \Omega: Y(w) \in F\}\\ &= X^{-1}(E) \cap Y^{-1}(F), \end{align*} so the function $Z(w)$ is measurable for any $w \in \Omega$. $(\Leftarrow):$ On this part I'm stuck so I just wrote out my assumptions and what I want to show: We assume $Z(w)$ is measurable, so we have $Z^{-1}(A) \in \mathcal{H}$ for all $A \in \mathcal{E} \times \mathcal{F}.$ We need to show that X and Y are measurable, i.e. $X^{-1}(A) \in \Omega$ for all $B \in \mathcal{E}$ and $Y^{-1}(C) \in \Omega$ for all $C \in \mathcal{F}.$ How can I finish the rest of this proof? Unfortunately, I couldn't find anything like  of this in my book (Probability and Stochastics by Cinlar)","Let $(\Omega, \mathcal{H}), (E, \mathcal{E})$ and $(F,\mathcal{F})$ be measurable spaces. Let $(E \times F, \mathcal{E} \otimes \mathcal{F})$ be a product space. Define the following three functions: $X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ $Y: (\Omega, \mathcal{H} \rightarrow (F,\mathcal{F})$ $Z = (X,Y): (\Omega, \mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ Now, I am trying to show that the following: $X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ and $Y:(\Omega, \mathcal{H}) \rightarrow (F,\mathcal{F})$ are measurable $\Leftrightarrow (X,Y): (\Omega,\mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ is measurable. Here is my current work: $(\Rightarrow):$ Since X and Y are both measurable, we have \begin{align*} Z^{-1}(E \times F) &= \{w \in \Omega: Z(w) \in E \times F\}\\ &= \{w \in \Omega:(X(w),Y(w)) \in E \times F\}\\ &= \{w \in \Omega: X(w) \in E\text{ and }Y(w) \in F\}\\ &= \{w \in \Omega: X(w) \in E \} \cap \{w \in \Omega: Y(w) \in F\}\\ &= X^{-1}(E) \cap Y^{-1}(F), \end{align*} so the function $Z(w)$ is measurable for any $w \in \Omega$. $(\Leftarrow):$ On this part I'm stuck so I just wrote out my assumptions and what I want to show: We assume $Z(w)$ is measurable, so we have $Z^{-1}(A) \in \mathcal{H}$ for all $A \in \mathcal{E} \times \mathcal{F}.$ We need to show that X and Y are measurable, i.e. $X^{-1}(A) \in \Omega$ for all $B \in \mathcal{E}$ and $Y^{-1}(C) \in \Omega$ for all $C \in \mathcal{F}.$ How can I finish the rest of this proof? Unfortunately, I couldn't find anything like  of this in my book (Probability and Stochastics by Cinlar)",,"['measure-theory', 'products']"
23,Measurable functions such that $\int\underline{\text{lim}}f_n=0 $ and $\underline{\text{lim}}\int f_n=+\infty$. [closed],Measurable functions such that  and . [closed],\int\underline{\text{lim}}f_n=0  \underline{\text{lim}}\int f_n=+\infty,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I need to find an example of a suquence of measurable functions $ f_n \geq0$ for $ n = 1,2, ... $ such that $\int\underline{\text{lim}}f_n=0 $ and $\underline{\text{lim}}\int f_n=+\infty$. As I can define these measurable functions. Thanks","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I need to find an example of a suquence of measurable functions $ f_n \geq0$ for $ n = 1,2, ... $ such that $\int\underline{\text{lim}}f_n=0 $ and $\underline{\text{lim}}\int f_n=+\infty$. As I can define these measurable functions. Thanks",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
24,Measurable sets whose sum is not measurable.,Measurable sets whose sum is not measurable.,,"I'm looking for two measurable sets in $\Bbb{R}^2$ st their sum is not measurable. I found the example , let $A\subset \Bbb{R}$ be a non-measurable set in $\Bbb{R}$ and consider the sets $A\times \{0\}$ and $\{0\}\times \mathbb R$, these both sets have measure zero in $\Bbb{R}^2$ but their sum $A\times \mathbb R$ is non measurable in $\Bbb{R}^2$. My question is why is $A\times \mathbb R$ non measurable in $\Bbb{R}^2$?","I'm looking for two measurable sets in $\Bbb{R}^2$ st their sum is not measurable. I found the example , let $A\subset \Bbb{R}$ be a non-measurable set in $\Bbb{R}$ and consider the sets $A\times \{0\}$ and $\{0\}\times \mathbb R$, these both sets have measure zero in $\Bbb{R}^2$ but their sum $A\times \mathbb R$ is non measurable in $\Bbb{R}^2$. My question is why is $A\times \mathbb R$ non measurable in $\Bbb{R}^2$?",,"['measure-theory', 'lebesgue-measure', 'measurable-sets']"
25,Determining a charge through subsets,Determining a charge through subsets,,"A charge is a finitely additive set function $c: \mathcal{P}(\mathbb{N}) \to [0, 1]$ such that $c(\mathbb{N}) = 1$ and $c(\{n\}) = 0$ for every $n \in N$. Here $\mathcal{P}(\mathbb{N})$ is the set of all subsets of $\mathbb{N} = \{1, 2, 3, \dots\}$. Question: Does there exists a charge $c$ such that for any family $\mathcal{F}$ of size less than that of $\mathcal{P}(\mathbb{N})$ there exists another charge $d$ such that while $c, d$ agree on $F$, they do not agree on $\mathcal{P}(\mathbb{N})$? I can only show that such a $d$ exists for every $c$ if $\mathcal{F}$ is countable. Thanks!","A charge is a finitely additive set function $c: \mathcal{P}(\mathbb{N}) \to [0, 1]$ such that $c(\mathbb{N}) = 1$ and $c(\{n\}) = 0$ for every $n \in N$. Here $\mathcal{P}(\mathbb{N})$ is the set of all subsets of $\mathbb{N} = \{1, 2, 3, \dots\}$. Question: Does there exists a charge $c$ such that for any family $\mathcal{F}$ of size less than that of $\mathcal{P}(\mathbb{N})$ there exists another charge $d$ such that while $c, d$ agree on $F$, they do not agree on $\mathcal{P}(\mathbb{N})$? I can only show that such a $d$ exists for every $c$ if $\mathcal{F}$ is countable. Thanks!",,"['measure-theory', 'set-theory']"
26,"Completeness of $ L^{p} $ spaces and ""rapidly Cauchy"" sequences","Completeness of  spaces and ""rapidly Cauchy"" sequences", L^{p} ,"http://math.harvard.edu/~ctm/home/text/books/royden-fitzpatrick/royden-fitzpatrick.pdf In the book of Royden, the completeness of $ L^{p}    $ spaces has been done using what he calls ""rapidly Cauchy"" sequences. A sequence $ f_{n} \in  X $, where $ X $ is a normed linear is said to be rapidly Cauchy if there is a sequence of positive reals $ \epsilon_{k} $ such that $ \sum_{  k  = 1 } ^ { \infty}  \epsilon_{k}         $ is convergent and $$    ||        f_{k+1} - f_{k} ||    < \epsilon_{k}   ^{2}         ,       $$ for all $ k \in \mathbb{N}                                      $. However, I don't understand why do we need to square the $ \epsilon_{k} $. The proofs all work fine even if I just put $    \epsilon_{k} $ as an upper bound on the $ ||  f_{k+1} - f_{k} || $ norm.  As far as I see, all propositions and theorems up to the Reisz-Fischer Theorem remain valid. Question. What purpose does squaring the $ \epsilon_{k} $ term serve in the chapter?","http://math.harvard.edu/~ctm/home/text/books/royden-fitzpatrick/royden-fitzpatrick.pdf In the book of Royden, the completeness of $ L^{p}    $ spaces has been done using what he calls ""rapidly Cauchy"" sequences. A sequence $ f_{n} \in  X $, where $ X $ is a normed linear is said to be rapidly Cauchy if there is a sequence of positive reals $ \epsilon_{k} $ such that $ \sum_{  k  = 1 } ^ { \infty}  \epsilon_{k}         $ is convergent and $$    ||        f_{k+1} - f_{k} ||    < \epsilon_{k}   ^{2}         ,       $$ for all $ k \in \mathbb{N}                                      $. However, I don't understand why do we need to square the $ \epsilon_{k} $. The proofs all work fine even if I just put $    \epsilon_{k} $ as an upper bound on the $ ||  f_{k+1} - f_{k} || $ norm.  As far as I see, all propositions and theorems up to the Reisz-Fischer Theorem remain valid. Question. What purpose does squaring the $ \epsilon_{k} $ term serve in the chapter?",,"['measure-theory', 'lebesgue-measure', 'lp-spaces', 'complete-spaces']"
27,Inequality on length of intervals,Inequality on length of intervals,,"Let $n\ge 1$ and $\{I_j\}_{j=1}^{n}$ is a set of non-degenerate   subintervals of $[0,1]$. Then show that :   $$ \overline\sum \dfrac{1}{|I_j\cup I_k|}\geq n^2$$   Here $\overline\sum$ denotes summing over $j,k$ with $I_j\cap I_k\neq \emptyset$. This is a problem from the Miklos Schweitzer competition. But, I don't have an idea about it, can someone give me a hint or something? An idea on how to proceed would be great. Thanks a lot.","Let $n\ge 1$ and $\{I_j\}_{j=1}^{n}$ is a set of non-degenerate   subintervals of $[0,1]$. Then show that :   $$ \overline\sum \dfrac{1}{|I_j\cup I_k|}\geq n^2$$   Here $\overline\sum$ denotes summing over $j,k$ with $I_j\cap I_k\neq \emptyset$. This is a problem from the Miklos Schweitzer competition. But, I don't have an idea about it, can someone give me a hint or something? An idea on how to proceed would be great. Thanks a lot.",,"['measure-theory', 'contest-math', 'combinatorial-geometry']"
28,A function constant almost everywhere,A function constant almost everywhere,,"Q: Suppose $f:\mathbb{R}\rightarrow \mathbb{R}$ is measurable with respect to Lebesgue measure and $f(x)=f(x+1)=f(x+\pi)$ for almost every $x$. Prove that $f$ is constant almost everywhere. Proof attempt: Since the ratio of $1$ and $pi$ is irrational, given any real number $r$ we have there exist $m, n\in \mathbb{Z}$ such that $|r-(m+n \pi )|< \epsilon$, so that the set $P=\{m+n\pi : m, n\in \mathbb{Z}\}$ is everywhere dense. Now by Lusin's theorem take the interval $[a, b]$, so there is a compact set $E\subset [a,b]$ such that $\mu(E) > (b-a-\delta)$ for some arbitrarily small $\delta$ and so that $f|_{E}$ is continous. Pick a point $x$ like the one in the condition of the problem and any $y\in E$. By continuity of $f$ on $E$ and by the density of $P$ there will be a point such that $|f(x)-f(y)|=|f(x)-f(y)|=|C-f(y)|<\epsilon_{2}$. Taking the limit as $\delta \rightarrow 0$, $f$ is constant almost everywhere on the interval $[a, b]$, and since the interval is arbitrary we can say $f$ is constant almost everywhere. Does this look alright? Is there another way of doing this without invoking something like Lusin's theorem? Measurable functions can be very ugly, so are there any other results similar to Lusin's theorem that allow us to put some sort of regularity on measurable functions and gain some intuition about them? Thanks in advance!","Q: Suppose $f:\mathbb{R}\rightarrow \mathbb{R}$ is measurable with respect to Lebesgue measure and $f(x)=f(x+1)=f(x+\pi)$ for almost every $x$. Prove that $f$ is constant almost everywhere. Proof attempt: Since the ratio of $1$ and $pi$ is irrational, given any real number $r$ we have there exist $m, n\in \mathbb{Z}$ such that $|r-(m+n \pi )|< \epsilon$, so that the set $P=\{m+n\pi : m, n\in \mathbb{Z}\}$ is everywhere dense. Now by Lusin's theorem take the interval $[a, b]$, so there is a compact set $E\subset [a,b]$ such that $\mu(E) > (b-a-\delta)$ for some arbitrarily small $\delta$ and so that $f|_{E}$ is continous. Pick a point $x$ like the one in the condition of the problem and any $y\in E$. By continuity of $f$ on $E$ and by the density of $P$ there will be a point such that $|f(x)-f(y)|=|f(x)-f(y)|=|C-f(y)|<\epsilon_{2}$. Taking the limit as $\delta \rightarrow 0$, $f$ is constant almost everywhere on the interval $[a, b]$, and since the interval is arbitrary we can say $f$ is constant almost everywhere. Does this look alright? Is there another way of doing this without invoking something like Lusin's theorem? Measurable functions can be very ugly, so are there any other results similar to Lusin's theorem that allow us to put some sort of regularity on measurable functions and gain some intuition about them? Thanks in advance!",,"['measure-theory', 'lebesgue-measure']"
29,Differentiation under the integral sign and counting measure,Differentiation under the integral sign and counting measure,,"Consider a power series $f(x)=\sum_{n=1}^\infty a_nx^n$, and assume that $\displaystyle R=\lim_{n\to \infty}  \frac{a_n}{a_{n+1}}$ exists. Use differentiation under the integral sign to show that $f(x)$ is differentiable on $(-R,R)$ with derivative $f'(x)=\sum_{n=1}^\infty na_nx^{n-1}$. Hint: interpret this sum as an integral with respect to counting measure. I am confused with this hint. How can I interpret this sum as an integral and what is counting measure?","Consider a power series $f(x)=\sum_{n=1}^\infty a_nx^n$, and assume that $\displaystyle R=\lim_{n\to \infty}  \frac{a_n}{a_{n+1}}$ exists. Use differentiation under the integral sign to show that $f(x)$ is differentiable on $(-R,R)$ with derivative $f'(x)=\sum_{n=1}^\infty na_nx^{n-1}$. Hint: interpret this sum as an integral with respect to counting measure. I am confused with this hint. How can I interpret this sum as an integral and what is counting measure?",,"['real-analysis', 'measure-theory', 'derivatives', 'power-series']"
30,Convergence in measure and $L_p$ implies product converges in $L_p$,Convergence in measure and  implies product converges in,L_p L_p,"This was given on an old comp as a true or false problem: If $1<p<\infty$, $|f_n|\leq 1$, $f_n\rightarrow f$ in measure, and $g_n\rightarrow g$ in $L_p$, then $f_ng_n\rightarrow fg$ in $L_p$. I could not think of a counter example right away so here is my attempt: Since convergence in $L_p$ implies convergence in measure $g_n\rightarrow g$ in measure. Let $E_1=\{x \in X:|f_n(x)-f(x)|>\epsilon_1\}$, $E_2=\{x \in X:|g_n(x)-g(x)|>\epsilon_2\}$ and $E=E_1\cup E_2$. Then $\mu(E)=0$ (warning this is incorrect usage of convergence in measure! I'll try to post a correct version in the answers) and $$\int_X|f_ng_n-fg|^pd\mu=\int_{X\backslash E}|f_ng_n-fg+f_ng_n-f_ng_n|^pd\mu\leq\\\int_{X\backslash E}|f_n|^p|g_n-g|^pd\mu+\int_{X\backslash E}|g|^p|f_n-f|^pd\mu$$ The integral in the first part of the sum goes to zero but I'm not sure what to do with the second integral? Is the fact that $g$ is in $L_p$ and $|f_n-f|^p<\epsilon_2^p$ enough? Since $$\int_{X\backslash E}|g|^p|f_n-f|^pd\mu\leq\epsilon_2^p\int_{X\backslash E}|g|^pd\mu=M\epsilon_2^p\rightarrow0$$ when $\epsilon_2\rightarrow0$ and $M=\int_{X\backslash E}|g|^pd\mu$.","This was given on an old comp as a true or false problem: If $1<p<\infty$, $|f_n|\leq 1$, $f_n\rightarrow f$ in measure, and $g_n\rightarrow g$ in $L_p$, then $f_ng_n\rightarrow fg$ in $L_p$. I could not think of a counter example right away so here is my attempt: Since convergence in $L_p$ implies convergence in measure $g_n\rightarrow g$ in measure. Let $E_1=\{x \in X:|f_n(x)-f(x)|>\epsilon_1\}$, $E_2=\{x \in X:|g_n(x)-g(x)|>\epsilon_2\}$ and $E=E_1\cup E_2$. Then $\mu(E)=0$ (warning this is incorrect usage of convergence in measure! I'll try to post a correct version in the answers) and $$\int_X|f_ng_n-fg|^pd\mu=\int_{X\backslash E}|f_ng_n-fg+f_ng_n-f_ng_n|^pd\mu\leq\\\int_{X\backslash E}|f_n|^p|g_n-g|^pd\mu+\int_{X\backslash E}|g|^p|f_n-f|^pd\mu$$ The integral in the first part of the sum goes to zero but I'm not sure what to do with the second integral? Is the fact that $g$ is in $L_p$ and $|f_n-f|^p<\epsilon_2^p$ enough? Since $$\int_{X\backslash E}|g|^p|f_n-f|^pd\mu\leq\epsilon_2^p\int_{X\backslash E}|g|^pd\mu=M\epsilon_2^p\rightarrow0$$ when $\epsilon_2\rightarrow0$ and $M=\int_{X\backslash E}|g|^pd\mu$.",,['measure-theory']
31,Convergence of measures — revisited,Convergence of measures — revisited,,"In this thread , I asked a question about the convergence of measures. The conjecture I posed there, which turned out to be false, was supposed to be a lemma that I wanted to use to prove a proposition, outlined as follows. Consider the measurable space $(\mathbb R,\mathscr B_{\mathbb R})$. Suppose that $\{\mu_n\}_{n=1}^{\infty}$ is a sequence of finite Radon measures and $\mu$ is a finite Radon measure on $\mathbb R$. Suppose also that $$\lim_{n\to\infty}\mu_n(\mathbb R)=\mu(\mathbb R)\tag{1}$$ and that $\{\mu_n\}_{n=1}^{\infty}$ converges to $\mu$ vaguely, in the sense that $$\lim_{n\to\infty}\int f\,\mathrm d\mu_n=\int f\,\mathrm d\mu$$ for any $f\in C_c$, where $C_c$ is the space of compactly supported, continuous, real-to-real functions. For any $x\in\mathbb R$ and $n\in\mathbb N$, define \begin{align*}F_n(x)\equiv&\,\mu_n((-\infty,x]),\\F(x)\equiv&\,\mu((-\infty,x]).\end{align*} Proposition:$\quad$ For any $a\in\mathbb R$ and $\varepsilon>0$, $$\limsup_{n\to\infty}F_n(a)\leq F(a+\varepsilon).$$ I figured out a proof that I think is correct, which I now share in order to seek feedback. Your thoughts are much appreciated. Proof:$\quad$ Let $a\in\mathbb R$ and $\varepsilon>0$ be given. Also, fix $\delta>0$. Since $\mu$ is a finite Radon measure, there exists a compact set $C\subset\mathbb R$ such that $$\mu(\mathbb R)\geq\mu(C)>\mu(\mathbb R)-\frac{\delta}{5}.$$ Since compact sets are bounded, one can choose $K>0$ so large that $$-K<a<a+\varepsilon<K,$$ $C\subseteq[-K,K]$, and $$\mu(\mathbb R)\geq\mu([-K,K])>\mu(\mathbb R)-\frac{\delta}{5}.\tag{2}$$ Pick any $L>K$. Clearly, $[-K,K]\subseteq[-L,L]$. Construct a continuous function $h$ such that $h$ is 1 on $[-K,K]$, it vanishes outside $[-L,L]$, and it is linear on $[-L,-K]$ and on $[K,L]$. Then, $h\in C_c$. By vague convergence, there exists some $N_1\in\mathbb N$ such that $$\int h\,\mathrm d\mu<\int h\,\mathrm d\mu_n+\frac{2\delta}{5}\quad\forall n\geq N_1.\tag{3}$$ Also, by (1), there exists some $N_2\in\mathbb N$ such that $$\mu(\mathbb R)+\frac{\delta}{5}>\mu_n(\mathbb R)>\mu(\mathbb R)-\frac{\delta}{5}\quad\forall n\geq N_2\tag{4}.$$ Now, if $n\geq\max\{N_1,N_2\}$, then, on the one hand, \begin{align*}\mu([-K,K])=&\,\int_{[-K,K]}h\,\mathrm d\mu\leq\int h\,\mathrm d\mu<\int h\,\mathrm d\mu_n+\frac{2\delta}5\\=&\,\int_{[-L,L]}h\,\mathrm d\mu_n+\frac{2\delta}5\leq\mu_n([-L,L])+\frac{2\delta}5;\end{align*} and, on the other hand, $$\mu_n([-L,L])\leq\mu_n(\mathbb R)<\mu(\mathbb R)+\frac{\delta}{5}<\mu([-K,K])+\frac{2\delta}{5},$$ by (2) and (4). Therefore, $$\mu_n([-L,L])-\frac{2\delta}{5}<\mu([-K,K])<\mu_n([-L,L])+\frac{2\delta}{5}\quad\forall n\geq\max\{N_1,N_2\}\tag{5}.$$ Let $M>L$ be arbitrary. Construct a continuous function $g$ such that $g$ is 1 on $[-L,a]$, it vanishes outside $[-M,a+\varepsilon]$, and it is linear on $[-M,-L]$ and on $[a,a+\varepsilon]$. Then, $g\in C_c$. By vague convergence, there exists some $N_3\in\mathbb N$ such that $$\int g\,\mathrm d\mu_n<\int g\,\mathrm d\mu+\frac{\delta}{5}\quad\forall n\geq N_3.\tag{6}$$ Let $n\geq N^*\equiv\max\{N_1,N_2,N_3\}$. Then, \begin{align*} F_n(a)=&\,\mu_n((-\infty,a])=\mu_n((-\infty,-L))+\mu_n([-L,a])\\ =&\,\mu_n(\mathbb R)-\mu_n([-L,L])-\mu_n((L,\infty))+\mu_n([-L,a])\\ \leq&\,\mu_n(\mathbb R)-\mu_n([-L,L])+\mu_n([-L,a])\\ \underbrace{<}_{(5)}&\,\mu_n(\mathbb R)-\mu([-K,K])+\frac{2\delta}5+\mu_n([-L,a])\\ \underbrace{<}_{(4)}&\,\mu(\mathbb R)-\mu([-K,K])+\frac{3\delta}5+\mu_n([-L,a])\\ \underbrace{<}_{(2)}&\,\frac{4\delta}5+\mu_n([-L,a])=\int_{[-L,a]}g\,\mathrm d\mu_n+\frac{4\delta}{5}\\ \leq&\,\int g\,\mathrm d\mu_n+\frac{4\delta}{5}\underbrace{<}_{(6)}\int g\,\mathrm d\mu+\delta=\int_{[-M,a+\varepsilon]}g\,\mathrm d\mu+\delta\\ \leq&\,\mu([-M,a+\varepsilon])+\delta\leq\mu((-\infty,a+\varepsilon])+\delta=F(a+\varepsilon)+\delta. \end{align*} Since this is true for all $n\geq N^*$, it follows that $$\limsup_{n\to\infty} F_n(a)=\inf_{k\in\mathbb N}\sup_{n\geq k}F_n(a)\leq \sup_{n\geq N^*}F_n(a)\leq F(a+\varepsilon)+\delta.$$ Given that $\delta>0$ can be made arbitrarily small, the claim follows. $\blacksquare$ Note: this proposition is needed to prove Proposition 7.19(b) in Folland (1999) . The earlier printings report the result without the assumption (1), in which case the proposition I presented can be shown to be false. The errata sheet points out that the claim is true if (1) is assumed, but gives no proof. That's why I attempted to construct one. Any comments are welcome.","In this thread , I asked a question about the convergence of measures. The conjecture I posed there, which turned out to be false, was supposed to be a lemma that I wanted to use to prove a proposition, outlined as follows. Consider the measurable space $(\mathbb R,\mathscr B_{\mathbb R})$. Suppose that $\{\mu_n\}_{n=1}^{\infty}$ is a sequence of finite Radon measures and $\mu$ is a finite Radon measure on $\mathbb R$. Suppose also that $$\lim_{n\to\infty}\mu_n(\mathbb R)=\mu(\mathbb R)\tag{1}$$ and that $\{\mu_n\}_{n=1}^{\infty}$ converges to $\mu$ vaguely, in the sense that $$\lim_{n\to\infty}\int f\,\mathrm d\mu_n=\int f\,\mathrm d\mu$$ for any $f\in C_c$, where $C_c$ is the space of compactly supported, continuous, real-to-real functions. For any $x\in\mathbb R$ and $n\in\mathbb N$, define \begin{align*}F_n(x)\equiv&\,\mu_n((-\infty,x]),\\F(x)\equiv&\,\mu((-\infty,x]).\end{align*} Proposition:$\quad$ For any $a\in\mathbb R$ and $\varepsilon>0$, $$\limsup_{n\to\infty}F_n(a)\leq F(a+\varepsilon).$$ I figured out a proof that I think is correct, which I now share in order to seek feedback. Your thoughts are much appreciated. Proof:$\quad$ Let $a\in\mathbb R$ and $\varepsilon>0$ be given. Also, fix $\delta>0$. Since $\mu$ is a finite Radon measure, there exists a compact set $C\subset\mathbb R$ such that $$\mu(\mathbb R)\geq\mu(C)>\mu(\mathbb R)-\frac{\delta}{5}.$$ Since compact sets are bounded, one can choose $K>0$ so large that $$-K<a<a+\varepsilon<K,$$ $C\subseteq[-K,K]$, and $$\mu(\mathbb R)\geq\mu([-K,K])>\mu(\mathbb R)-\frac{\delta}{5}.\tag{2}$$ Pick any $L>K$. Clearly, $[-K,K]\subseteq[-L,L]$. Construct a continuous function $h$ such that $h$ is 1 on $[-K,K]$, it vanishes outside $[-L,L]$, and it is linear on $[-L,-K]$ and on $[K,L]$. Then, $h\in C_c$. By vague convergence, there exists some $N_1\in\mathbb N$ such that $$\int h\,\mathrm d\mu<\int h\,\mathrm d\mu_n+\frac{2\delta}{5}\quad\forall n\geq N_1.\tag{3}$$ Also, by (1), there exists some $N_2\in\mathbb N$ such that $$\mu(\mathbb R)+\frac{\delta}{5}>\mu_n(\mathbb R)>\mu(\mathbb R)-\frac{\delta}{5}\quad\forall n\geq N_2\tag{4}.$$ Now, if $n\geq\max\{N_1,N_2\}$, then, on the one hand, \begin{align*}\mu([-K,K])=&\,\int_{[-K,K]}h\,\mathrm d\mu\leq\int h\,\mathrm d\mu<\int h\,\mathrm d\mu_n+\frac{2\delta}5\\=&\,\int_{[-L,L]}h\,\mathrm d\mu_n+\frac{2\delta}5\leq\mu_n([-L,L])+\frac{2\delta}5;\end{align*} and, on the other hand, $$\mu_n([-L,L])\leq\mu_n(\mathbb R)<\mu(\mathbb R)+\frac{\delta}{5}<\mu([-K,K])+\frac{2\delta}{5},$$ by (2) and (4). Therefore, $$\mu_n([-L,L])-\frac{2\delta}{5}<\mu([-K,K])<\mu_n([-L,L])+\frac{2\delta}{5}\quad\forall n\geq\max\{N_1,N_2\}\tag{5}.$$ Let $M>L$ be arbitrary. Construct a continuous function $g$ such that $g$ is 1 on $[-L,a]$, it vanishes outside $[-M,a+\varepsilon]$, and it is linear on $[-M,-L]$ and on $[a,a+\varepsilon]$. Then, $g\in C_c$. By vague convergence, there exists some $N_3\in\mathbb N$ such that $$\int g\,\mathrm d\mu_n<\int g\,\mathrm d\mu+\frac{\delta}{5}\quad\forall n\geq N_3.\tag{6}$$ Let $n\geq N^*\equiv\max\{N_1,N_2,N_3\}$. Then, \begin{align*} F_n(a)=&\,\mu_n((-\infty,a])=\mu_n((-\infty,-L))+\mu_n([-L,a])\\ =&\,\mu_n(\mathbb R)-\mu_n([-L,L])-\mu_n((L,\infty))+\mu_n([-L,a])\\ \leq&\,\mu_n(\mathbb R)-\mu_n([-L,L])+\mu_n([-L,a])\\ \underbrace{<}_{(5)}&\,\mu_n(\mathbb R)-\mu([-K,K])+\frac{2\delta}5+\mu_n([-L,a])\\ \underbrace{<}_{(4)}&\,\mu(\mathbb R)-\mu([-K,K])+\frac{3\delta}5+\mu_n([-L,a])\\ \underbrace{<}_{(2)}&\,\frac{4\delta}5+\mu_n([-L,a])=\int_{[-L,a]}g\,\mathrm d\mu_n+\frac{4\delta}{5}\\ \leq&\,\int g\,\mathrm d\mu_n+\frac{4\delta}{5}\underbrace{<}_{(6)}\int g\,\mathrm d\mu+\delta=\int_{[-M,a+\varepsilon]}g\,\mathrm d\mu+\delta\\ \leq&\,\mu([-M,a+\varepsilon])+\delta\leq\mu((-\infty,a+\varepsilon])+\delta=F(a+\varepsilon)+\delta. \end{align*} Since this is true for all $n\geq N^*$, it follows that $$\limsup_{n\to\infty} F_n(a)=\inf_{k\in\mathbb N}\sup_{n\geq k}F_n(a)\leq \sup_{n\geq N^*}F_n(a)\leq F(a+\varepsilon)+\delta.$$ Given that $\delta>0$ can be made arbitrarily small, the claim follows. $\blacksquare$ Note: this proposition is needed to prove Proposition 7.19(b) in Folland (1999) . The earlier printings report the result without the assumption (1), in which case the proposition I presented can be shown to be false. The errata sheet points out that the claim is true if (1) is assumed, but gives no proof. That's why I attempted to construct one. Any comments are welcome.",,"['real-analysis', 'measure-theory', 'proof-verification']"
32,Nowhere dense set....,Nowhere dense set....,,"Let $A_n$ be a subset of continuous functions on $[0,1]$ given by: $A_n$ = {$f∈C[0,1]$:there exists $x∈[0,1]$ such that $|f(x)−f(y)|≤n|x−y|$ for all $y∈[0,1]$}. Show $A_n$ is nowhere dense, and use this fact to show that there are nowhere differentiable continuous functions on $[0,1]$. We already showed $A_n$ is closed. How to show interior of $A_n$ is empty?","Let $A_n$ be a subset of continuous functions on $[0,1]$ given by: $A_n$ = {$f∈C[0,1]$:there exists $x∈[0,1]$ such that $|f(x)−f(y)|≤n|x−y|$ for all $y∈[0,1]$}. Show $A_n$ is nowhere dense, and use this fact to show that there are nowhere differentiable continuous functions on $[0,1]$. We already showed $A_n$ is closed. How to show interior of $A_n$ is empty?",,"['real-analysis', 'measure-theory', 'baire-category']"
33,Property of a specific set with Lebesgue measure zero,Property of a specific set with Lebesgue measure zero,,"First well order $\mathbb{Q}=\{r_m\}_{m=0}^\infty$. Let $B_{m,n}$ be the open ball centered at $r_m$ with radius $2^{-(m+n)}$. Let $B=\bigcap_{n=0}^\infty\bigcup_{m=0}^\infty B_{m,n}$. Clearly $B$ has Lebesgue measure zero. But how to show it's not a union of countably many Jordan content zero sets? A set $A\subseteq\mathbb{R}$ has Lebesgue measure zero iff $\forall\epsilon>0\exists$a countable family of open intervals $\{I_n\}_{n\in\omega}(A\subseteq\bigcup_{n\in\omega}I_n\wedge\sum_{n=0}^\infty|I_n|<\epsilon)$. A set $A\subseteq\mathbb{R}$ has Jordan content zero iff $\forall\epsilon>0\exists$a finite family of open intervals $\{I_n\}_{n=0}^N(A\subseteq\bigcup_{n=0}^NI_n\wedge\sum_{n=0}^N|I_n|<\epsilon)$. I found a similar topic in this question: link","First well order $\mathbb{Q}=\{r_m\}_{m=0}^\infty$. Let $B_{m,n}$ be the open ball centered at $r_m$ with radius $2^{-(m+n)}$. Let $B=\bigcap_{n=0}^\infty\bigcup_{m=0}^\infty B_{m,n}$. Clearly $B$ has Lebesgue measure zero. But how to show it's not a union of countably many Jordan content zero sets? A set $A\subseteq\mathbb{R}$ has Lebesgue measure zero iff $\forall\epsilon>0\exists$a countable family of open intervals $\{I_n\}_{n\in\omega}(A\subseteq\bigcup_{n\in\omega}I_n\wedge\sum_{n=0}^\infty|I_n|<\epsilon)$. A set $A\subseteq\mathbb{R}$ has Jordan content zero iff $\forall\epsilon>0\exists$a finite family of open intervals $\{I_n\}_{n=0}^N(A\subseteq\bigcup_{n=0}^NI_n\wedge\sum_{n=0}^N|I_n|<\epsilon)$. I found a similar topic in this question: link",,['measure-theory']
34,A measurable function with $\int f^n$ bounded or converging as $n \to \infty$,A measurable function with  bounded or converging as,\int f^n n \to \infty,"(1) Show that, if $f^n$ is integrable for all integers $n\ge 1$ and    $\limsup_{n\to \infty} \int f^n<\infty$ then $|f|\le1$ almost everywhere. (2) Show that, if $f^n$ is integrable for all integers $n\ge 1$ then $\int f^n d\mu = c$, for every $n\in\mathbb N$ $ \Leftrightarrow f=\mathbb{1}_{A} $ a.e. for some $A\subseteq X$ with $\mu(A)=c$. (This is the edited version, i think here is not necessarily $|f|\le 1\ a.e$) Proof(1): Assume not ( $|f|\le 1$ not almost everywhere) Since $||f||_{\infty}=\inf\{M:|f(x)|\le M\quad \text{for } \mu \text{-almost everywhere  } x\in X\}$ $\Rightarrow ||f||_{\infty}>1$ then $||f||_{\infty}^{\infty}=\infty$ which is a contradiction. Is this OK?","(1) Show that, if $f^n$ is integrable for all integers $n\ge 1$ and    $\limsup_{n\to \infty} \int f^n<\infty$ then $|f|\le1$ almost everywhere. (2) Show that, if $f^n$ is integrable for all integers $n\ge 1$ then $\int f^n d\mu = c$, for every $n\in\mathbb N$ $ \Leftrightarrow f=\mathbb{1}_{A} $ a.e. for some $A\subseteq X$ with $\mu(A)=c$. (This is the edited version, i think here is not necessarily $|f|\le 1\ a.e$) Proof(1): Assume not ( $|f|\le 1$ not almost everywhere) Since $||f||_{\infty}=\inf\{M:|f(x)|\le M\quad \text{for } \mu \text{-almost everywhere  } x\in X\}$ $\Rightarrow ||f||_{\infty}>1$ then $||f||_{\infty}^{\infty}=\infty$ which is a contradiction. Is this OK?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
35,"Measure of ""badly approximable"" real numbers","Measure of ""badly approximable"" real numbers",,"This is a continuation of Application of the Borel-Cantelli Lemma . Call a real number $x$ diophantine iff $$  \exists p,c > 0 \forall q \in \mathbb Z^* \forall a \in \mathbb Z: \left | x - \frac a q \right | > \frac c {|q|^p} $$ Then almost every real number is diophantine. This is Exercise 19.2.8 from Tao Analysis II. For fixed $p> 2$ and $c > 0$ I know that the set  $$  E(p,c) := \left \{x \in [0,1] : \left | x - \frac a q \right | \leq \frac c {q^p} \text{ for infinitly many } (a,q) \in \mathbb N \times \mathbb N^* \right \} $$ has measure zero (see the link). For the question I can assume that $p > 2$ and $c,p \in \mathbb Q$. I must show that the set of non-diophantine real numbers in $[0,1]$ has measure zero. If I know that I can take a countable union of sets of measure zero, which gives a set of measure zero. Denote  $$  X := \left \{ x\in [0,1]: \forall p \in \mathbb Q_{>2} \forall c \in \mathbb Q_{>0} \exists q \in \mathbb N^* \exists a \in \mathbb N: \left |x - \frac a q \right | \leq \frac c {q^p} \right  \} $$ We have to prove that $m(X) = 0$. How can I show that $m(X) = 0$ by using the fact that $m(E(p,c)) = 0$ for every $p> 2$ and $c > 0$. I see that the pairs $(p,c)$ are countable. Does this help ?","This is a continuation of Application of the Borel-Cantelli Lemma . Call a real number $x$ diophantine iff $$  \exists p,c > 0 \forall q \in \mathbb Z^* \forall a \in \mathbb Z: \left | x - \frac a q \right | > \frac c {|q|^p} $$ Then almost every real number is diophantine. This is Exercise 19.2.8 from Tao Analysis II. For fixed $p> 2$ and $c > 0$ I know that the set  $$  E(p,c) := \left \{x \in [0,1] : \left | x - \frac a q \right | \leq \frac c {q^p} \text{ for infinitly many } (a,q) \in \mathbb N \times \mathbb N^* \right \} $$ has measure zero (see the link). For the question I can assume that $p > 2$ and $c,p \in \mathbb Q$. I must show that the set of non-diophantine real numbers in $[0,1]$ has measure zero. If I know that I can take a countable union of sets of measure zero, which gives a set of measure zero. Denote  $$  X := \left \{ x\in [0,1]: \forall p \in \mathbb Q_{>2} \forall c \in \mathbb Q_{>0} \exists q \in \mathbb N^* \exists a \in \mathbb N: \left |x - \frac a q \right | \leq \frac c {q^p} \right  \} $$ We have to prove that $m(X) = 0$. How can I show that $m(X) = 0$ by using the fact that $m(E(p,c)) = 0$ for every $p> 2$ and $c > 0$. I see that the pairs $(p,c)$ are countable. Does this help ?",,[]
36,An extension theorem in measure theory.,An extension theorem in measure theory.,,"I'm reading ""Real Analysis"" by Royden (4th ed). According to this text, a semiring $ S$ of subsets of $X$ is a nonempty collection of subsets of $X$ that is closed for finite intersections and such that, if $A,B \in S$, then $A\setminus B = \bigcup\limits_{k=1}^{n} C_{k}$, with the $C_k \in S$ and disjoint. Given a collection $S$ of subsets of $X$, a premeasure $\mu$ is a map $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ for which $\mu\left (\bigcup\limits_{k=1}^{n} E_{k}  \right ) = \sum \limits_{k=1}^{n} \mu\left ( E_k \right )$ whenever the $E_k \in S$ are disjoint and $\bigcup\limits_{k=1}^{n} E_{k}  \in S$ and $\mu\left ( E \right ) \leqslant \sum \limits_{k=1}^{\infty} \mu\left ( E_k \right )$ whenever $E, E_k \in S$ with $ E \subseteq \bigcup\limits_{k=1}^{n} E_{k}   $ and for which $\mu\left(\emptyset\right ) = 0$ if $\emptyset \in S$ . Then, the following theorem gets proven (I get all that): Let $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ be a premeasure on a semiring $S$ of subsets of $X$. Then the Carathéodory measure $\bar{\mu}$ induced by $\mu$ is an extension of $\mu$. Furthermore, if $\mu$ is $\sigma$-finite, then $\bar{\mu}$ is the unique measure on the $\sigma$-algebra of Carathéodory measurable sets that extends $\mu$. What I don't understand is why the following is a corollary of this theorem: Let $S$ be a semiring of subsets of $X$ and $\mathcal{B}$ the smallest $\sigma$-algebra of subsets of $X$ that contains $S$. Then two $\sigma$-finite measures on $\mathcal{B}$ are equal if and only if they agree on $S$ . What am I missing? Any thoughts anyone? Many thanks in advance.","I'm reading ""Real Analysis"" by Royden (4th ed). According to this text, a semiring $ S$ of subsets of $X$ is a nonempty collection of subsets of $X$ that is closed for finite intersections and such that, if $A,B \in S$, then $A\setminus B = \bigcup\limits_{k=1}^{n} C_{k}$, with the $C_k \in S$ and disjoint. Given a collection $S$ of subsets of $X$, a premeasure $\mu$ is a map $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ for which $\mu\left (\bigcup\limits_{k=1}^{n} E_{k}  \right ) = \sum \limits_{k=1}^{n} \mu\left ( E_k \right )$ whenever the $E_k \in S$ are disjoint and $\bigcup\limits_{k=1}^{n} E_{k}  \in S$ and $\mu\left ( E \right ) \leqslant \sum \limits_{k=1}^{\infty} \mu\left ( E_k \right )$ whenever $E, E_k \in S$ with $ E \subseteq \bigcup\limits_{k=1}^{n} E_{k}   $ and for which $\mu\left(\emptyset\right ) = 0$ if $\emptyset \in S$ . Then, the following theorem gets proven (I get all that): Let $\mu :S \rightarrow \left [ 0, \infty  \right ]  $ be a premeasure on a semiring $S$ of subsets of $X$. Then the Carathéodory measure $\bar{\mu}$ induced by $\mu$ is an extension of $\mu$. Furthermore, if $\mu$ is $\sigma$-finite, then $\bar{\mu}$ is the unique measure on the $\sigma$-algebra of Carathéodory measurable sets that extends $\mu$. What I don't understand is why the following is a corollary of this theorem: Let $S$ be a semiring of subsets of $X$ and $\mathcal{B}$ the smallest $\sigma$-algebra of subsets of $X$ that contains $S$. Then two $\sigma$-finite measures on $\mathcal{B}$ are equal if and only if they agree on $S$ . What am I missing? Any thoughts anyone? Many thanks in advance.",,['measure-theory']
37,"$\int_\Omega F(u_n)\to0$ implies $\int_\Omega F(au_n)\to 0$ for $a\in [0,\infty)$?",implies  for ?,"\int_\Omega F(u_n)\to0 \int_\Omega F(au_n)\to 0 a\in [0,\infty)","Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $F:[0,\infty)\to [0,\infty)$ be a convex, strictly increasing and continuous function satisfying $F(0)=0$. Suppose that $u_n\in L^\infty(\Omega)$ (Lebesgue measure) is a sequence of non-negative functions satisfying $$\int_\Omega F(u_n)\to0$$ Can I conclude that for every $a\in [0,\infty)$ the following convergence is true: $$\int_\Omega F(au_n)\to 0$$ Remark 1: Convexity and $F(0)=0$ implies that $F(ax)\leq aF(x)$ for $a\leq 1$, hence the only case that needs to be treat is the case $a>1$. Update 1: In the circumstances described abode, $u_n\to 0$ in measure. Maybe this can help... Thank you","Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $F:[0,\infty)\to [0,\infty)$ be a convex, strictly increasing and continuous function satisfying $F(0)=0$. Suppose that $u_n\in L^\infty(\Omega)$ (Lebesgue measure) is a sequence of non-negative functions satisfying $$\int_\Omega F(u_n)\to0$$ Can I conclude that for every $a\in [0,\infty)$ the following convergence is true: $$\int_\Omega F(au_n)\to 0$$ Remark 1: Convexity and $F(0)=0$ implies that $F(ax)\leq aF(x)$ for $a\leq 1$, hence the only case that needs to be treat is the case $a>1$. Update 1: In the circumstances described abode, $u_n\to 0$ in measure. Maybe this can help... Thank you",,"['measure-theory', 'convergence-divergence']"
38,strict convexity with a measure theoretic property,strict convexity with a measure theoretic property,,"Suppose $(x_n)$ is a positive sequence of reals converging to $x$. Furthermore we have a measure space $(E,\mathcal{E},\mu)$ given, with finite measure $\mu$. There are a measurables nonnegative and real valued maps $(f_{x_n})$ and a $f_x$ (depending on $x_n$ and $x$) such that for some $\epsilon >0$ given $$\lim\sup_n \mu\{y\in E:|f_{x_n}(y)-f_x(y)|>\epsilon\}>\epsilon\tag{1}$$ Moreover $$\lim\sup_n \mu\{y\in E:|f_{x_n}(y)-f_x(y)|>\epsilon,f_{x_n}(y)+f_x(y)\le \frac{1}{\epsilon}\}>\epsilon\tag{2}$$ Furthermore there is a strictly convex map $H$ given, hence $$H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))<\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))\tag{3}$$ Now we should deduce from $(2)$ and $(3)$ the existence of $\delta>0$ such that $$\lim\sup_n\mu\{H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))\le\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))-\delta\}>\delta$$ It is clear that I can find for very $n$ a $\delta(n)>0$ s.t. $$H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))\le\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))-\delta(n)$$ However I'm struggling with the uniformity in $n$ and the measure of this event.","Suppose $(x_n)$ is a positive sequence of reals converging to $x$. Furthermore we have a measure space $(E,\mathcal{E},\mu)$ given, with finite measure $\mu$. There are a measurables nonnegative and real valued maps $(f_{x_n})$ and a $f_x$ (depending on $x_n$ and $x$) such that for some $\epsilon >0$ given $$\lim\sup_n \mu\{y\in E:|f_{x_n}(y)-f_x(y)|>\epsilon\}>\epsilon\tag{1}$$ Moreover $$\lim\sup_n \mu\{y\in E:|f_{x_n}(y)-f_x(y)|>\epsilon,f_{x_n}(y)+f_x(y)\le \frac{1}{\epsilon}\}>\epsilon\tag{2}$$ Furthermore there is a strictly convex map $H$ given, hence $$H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))<\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))\tag{3}$$ Now we should deduce from $(2)$ and $(3)$ the existence of $\delta>0$ such that $$\lim\sup_n\mu\{H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))\le\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))-\delta\}>\delta$$ It is clear that I can find for very $n$ a $\delta(n)>0$ s.t. $$H(\frac{1}{2}(f_{x_n}(y)+f_x(y)))\le\frac{1}{2}(H(f_{x_n}(y))+H(f_x(y)))-\delta(n)$$ However I'm struggling with the uniformity in $n$ and the measure of this event.",,['real-analysis']
39,Doubts about Hausdorff measure.,Doubts about Hausdorff measure.,,"I am studying real analysis and I have some problems in understanding properties of Hausdorff measure. Let $\mathcal{E}_\delta$ be collection of subsets of $\mathbb{R}^N$ whose diameter is less then $\delta$. Now $\mathcal{E}_\delta$ has the property that for every $E \subseteq \mathbb{R}^N$ there exists a countable collection $\{ Q_n\}_{n \in \mathbb{N}} \subseteq \mathcal{E}_\delta$ such that $E \subseteq \bigcup_{n \in \mathbb{N}}Q_n$ (to see this we may observe that $\mathbb{R}^N$ could be partitioned in a numerable union of dyadic cubes, each with diameter arbitrarily small). Now define  $$ \mathcal{H}_{\alpha,\delta}(E)=\inf \left\{ \sum_{n \in \mathbb{N}} \text{diam}(E_n)^\alpha \,\middle|\, E \subseteq \bigcup_{n \in \mathbb{N}} \ \text{and} \  \left\{E_n \right\} \subseteq \mathcal{E}_\delta  \right\} $$ By the properties of infimum we deduce that if $\delta_1 \le \delta_2$ then $\mathcal{H}_{\alpha,\delta_2}(E) \le \mathcal{H}_{\alpha,\delta_1}(E)$. So it make sense define the Hausdorff outer $\alpha$-measure of $E$ by $$\mathcal{H}_\alpha(E)=\sup_{\delta>0} \mathcal{H}_{\alpha,\delta}=\lim_{\delta \to 0^+}\mathcal{H}_{\alpha,\delta} $$ Now $\mathcal{H}_\alpha$ is an outer measure, and if consider the collection $\mathcal{A}$ of sets $E \subseteq \mathbb{R}^N$ such that $$\mathcal{H}_\alpha(A)=\mathcal{H}_\alpha(E \cap A) + \mathcal{H}_\alpha(A\setminus E), \ \ \forall A \subseteq \mathbb{R}^N \ \ \ \ \ (*) $$ we can prove (using the Carathéodory Extension Theorem ) that $\mathcal{A}$ is a $\sigma$-algebra, and we say that $\mathcal{A}$ is the collection of Hausdorff $\alpha$-measurable sets. Now I have two questions: There are some difference between $\mathcal{A}$ and the collection of Lebesgue measurable sets? There is some subset of $\mathbb{R}^N$ that is not Hausdorff $\alpha$-measurable? For answering the second question I taken $(*)$, that for sub-additivity of outer measure holds ever with the sign $\le$ at place of $=$ and I looked for a subset $E$ of $\mathbb{R}^N$ for that exists a subset $A$ of $\mathbb{R}^N$ such that $(*)$ holds with strict inequality. For the candidate of $E$ I have taken the Vitali set $V$, and for the set $A$ I take the set $$A= \bigcup_{q \in (-1,1) \cup \mathbb{Q}} V+q$$ where $V+q$ is the translated of Vitali set (like the proof that $V$ is not Lebesgue measurable). I easy to see that $V+q_1 \cap V+q_2=\emptyset$ if $q_1 \neq q_2$. Now what remain to check is that holds the strict inequality $$ \mathcal{H}_{1}(A)<\mathcal{H}_1(V)+\mathcal{H}_1 \left(A \setminus V\right)$$ Where $$A \setminus V =\bigcup_{q \in(-1,1) \cap \mathbb{Q}\setminus \{0\} } V+q $$ Now $V \subseteq (0,1)$, then $A \subseteq (-1,2)$ so for the sub-additivity $\mathcal{H}_1(V) \le 1$ and $\mathcal{H}_1(A) \le 3$, and if we can show that $\mathcal{H}_1(A \setminus V)=\mathcal{H}_1(A)$ and $\mathcal{H}_1(V)>0$ we are done.  But if the above reasoning were false and the Vitali set were Hausdorff $1$-measurable, then the first question would have answer.","I am studying real analysis and I have some problems in understanding properties of Hausdorff measure. Let $\mathcal{E}_\delta$ be collection of subsets of $\mathbb{R}^N$ whose diameter is less then $\delta$. Now $\mathcal{E}_\delta$ has the property that for every $E \subseteq \mathbb{R}^N$ there exists a countable collection $\{ Q_n\}_{n \in \mathbb{N}} \subseteq \mathcal{E}_\delta$ such that $E \subseteq \bigcup_{n \in \mathbb{N}}Q_n$ (to see this we may observe that $\mathbb{R}^N$ could be partitioned in a numerable union of dyadic cubes, each with diameter arbitrarily small). Now define  $$ \mathcal{H}_{\alpha,\delta}(E)=\inf \left\{ \sum_{n \in \mathbb{N}} \text{diam}(E_n)^\alpha \,\middle|\, E \subseteq \bigcup_{n \in \mathbb{N}} \ \text{and} \  \left\{E_n \right\} \subseteq \mathcal{E}_\delta  \right\} $$ By the properties of infimum we deduce that if $\delta_1 \le \delta_2$ then $\mathcal{H}_{\alpha,\delta_2}(E) \le \mathcal{H}_{\alpha,\delta_1}(E)$. So it make sense define the Hausdorff outer $\alpha$-measure of $E$ by $$\mathcal{H}_\alpha(E)=\sup_{\delta>0} \mathcal{H}_{\alpha,\delta}=\lim_{\delta \to 0^+}\mathcal{H}_{\alpha,\delta} $$ Now $\mathcal{H}_\alpha$ is an outer measure, and if consider the collection $\mathcal{A}$ of sets $E \subseteq \mathbb{R}^N$ such that $$\mathcal{H}_\alpha(A)=\mathcal{H}_\alpha(E \cap A) + \mathcal{H}_\alpha(A\setminus E), \ \ \forall A \subseteq \mathbb{R}^N \ \ \ \ \ (*) $$ we can prove (using the Carathéodory Extension Theorem ) that $\mathcal{A}$ is a $\sigma$-algebra, and we say that $\mathcal{A}$ is the collection of Hausdorff $\alpha$-measurable sets. Now I have two questions: There are some difference between $\mathcal{A}$ and the collection of Lebesgue measurable sets? There is some subset of $\mathbb{R}^N$ that is not Hausdorff $\alpha$-measurable? For answering the second question I taken $(*)$, that for sub-additivity of outer measure holds ever with the sign $\le$ at place of $=$ and I looked for a subset $E$ of $\mathbb{R}^N$ for that exists a subset $A$ of $\mathbb{R}^N$ such that $(*)$ holds with strict inequality. For the candidate of $E$ I have taken the Vitali set $V$, and for the set $A$ I take the set $$A= \bigcup_{q \in (-1,1) \cup \mathbb{Q}} V+q$$ where $V+q$ is the translated of Vitali set (like the proof that $V$ is not Lebesgue measurable). I easy to see that $V+q_1 \cap V+q_2=\emptyset$ if $q_1 \neq q_2$. Now what remain to check is that holds the strict inequality $$ \mathcal{H}_{1}(A)<\mathcal{H}_1(V)+\mathcal{H}_1 \left(A \setminus V\right)$$ Where $$A \setminus V =\bigcup_{q \in(-1,1) \cap \mathbb{Q}\setminus \{0\} } V+q $$ Now $V \subseteq (0,1)$, then $A \subseteq (-1,2)$ so for the sub-additivity $\mathcal{H}_1(V) \le 1$ and $\mathcal{H}_1(A) \le 3$, and if we can show that $\mathcal{H}_1(A \setminus V)=\mathcal{H}_1(A)$ and $\mathcal{H}_1(V)>0$ we are done.  But if the above reasoning were false and the Vitali set were Hausdorff $1$-measurable, then the first question would have answer.",,"['real-analysis', 'measure-theory', 'dimension-theory-analysis']"
40,Stochastic Process measurability,Stochastic Process measurability,,"I've come across a statement that i cannot grasp. When $T=[0,\infty)$, $E=\mathbb{R}$ and $\xi=B(\mathbb{R})$ then the collection of all continuous E-valued functions is not $\xi^T$-measurable. Here we have the measurable space $(E,\xi)$ and $\xi^n=\sigma\{E_{1}\times...\times E_{n}|E_{1},...,E_{n}\in \xi\} $. Could anyone prove why this is the case?","I've come across a statement that i cannot grasp. When $T=[0,\infty)$, $E=\mathbb{R}$ and $\xi=B(\mathbb{R})$ then the collection of all continuous E-valued functions is not $\xi^T$-measurable. Here we have the measurable space $(E,\xi)$ and $\xi^n=\sigma\{E_{1}\times...\times E_{n}|E_{1},...,E_{n}\in \xi\} $. Could anyone prove why this is the case?",,"['measure-theory', 'stochastic-processes']"
41,$\delta$-fined division and Lebesgue measure $\mu$,-fined division and Lebesgue measure,\delta \mu,"Let $E$ be a measurable subset of $[0,1]$. Then we know that we can choose an open set $G$ and a closed set $F$ such that $F\subset E \subset G \subset [0,1]$. For each $t\in [0,1]$, define $$\delta(t) =  	\begin{cases} \text{dist}(t,G^c),&\text{if $t\in F$}\\ \text{min}\{\text{dist}(t,b(G)),\text{dist}(t,F)\},&\text{if $t\in G\smallsetminus F$}\\ \text{dist}(t,F),&\text{if $t\in [0,1]\smallsetminus G$.}   	\end{cases}  $$ Here we use the notation $b(G)$ to mean the boundary of $G$. Because the sets $G^c$, $b(G)$, and $F$ are closed, it follows that $\delta(t)>0$ for each $t\in [0,1].$ This defines a positive function $\delta$ defined on $[0,1].$ Cousin's Lemma therefore assures that a division $D=\{(t_i,I_i)\}_{i=1}^{n}$ exists such that for each $i=1,\dots,n$ we have $t_i\in [0,1]$ and $$I_i\subset (t_i-\delta(t_i),t_i+\delta(t_i)).$$ Some authors call $D$ as a $\delta$-fined free tagged division of $[0,1].$ My question: How do we show (if it is true) that $$(D)\sum_{t_i\in E}[\mu(I_i)-\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ and $$(D)\sum_{t_i\notin E}\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ where $\mu$ denotes the Lebesgue measure. Any tips?Thanks in advance.","Let $E$ be a measurable subset of $[0,1]$. Then we know that we can choose an open set $G$ and a closed set $F$ such that $F\subset E \subset G \subset [0,1]$. For each $t\in [0,1]$, define $$\delta(t) =  	\begin{cases} \text{dist}(t,G^c),&\text{if $t\in F$}\\ \text{min}\{\text{dist}(t,b(G)),\text{dist}(t,F)\},&\text{if $t\in G\smallsetminus F$}\\ \text{dist}(t,F),&\text{if $t\in [0,1]\smallsetminus G$.}   	\end{cases}  $$ Here we use the notation $b(G)$ to mean the boundary of $G$. Because the sets $G^c$, $b(G)$, and $F$ are closed, it follows that $\delta(t)>0$ for each $t\in [0,1].$ This defines a positive function $\delta$ defined on $[0,1].$ Cousin's Lemma therefore assures that a division $D=\{(t_i,I_i)\}_{i=1}^{n}$ exists such that for each $i=1,\dots,n$ we have $t_i\in [0,1]$ and $$I_i\subset (t_i-\delta(t_i),t_i+\delta(t_i)).$$ Some authors call $D$ as a $\delta$-fined free tagged division of $[0,1].$ My question: How do we show (if it is true) that $$(D)\sum_{t_i\in E}[\mu(I_i)-\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ and $$(D)\sum_{t_i\notin E}\mu(E\cap I_i)] \leq \mu(G\smallsetminus F)$$ where $\mu$ denotes the Lebesgue measure. Any tips?Thanks in advance.",,"['real-analysis', 'measure-theory']"
42,Upcrossing measurable,Upcrossing measurable,,"For upcrossings we have defined $S_{n}=\inf \{k>B_{n}:x_{k}>b\}$  and $B_{n}=\inf \{k>S_{n-1}:x_{k}<a\}$. The number of upcrossings over the interval $(a,b)$ is given by $U_{N}(a,b)=\max\{n:S_{n}\leq N\}$. $U(a,b)=\lim_{N\rightarrow \infty} U_{N}(a,b)$ It is stated that $S_{n}$ and $B_{n}$ are stopping times ($\{S_{n}\leq k\}\in F_{k}$) and that $U_{N}(a,b)$ is $F_{N}$-measurable and $U(a,b)$ is $F_{\infty}$-measurable, I think I managed to show that $B_{n}$ and $S_{n}$ are stopping times by: $$\{B_{n}\leq k\}=\bigcup_{i=S_{n-1}}^{k}\{x_{i}<a\}$$ As $\{x_{i}<a\}\in F_{i}\subset F_{k}$ so $\{B_{n}\leq k\}\in F_{k}$. I was wondering if I've done this correctly and I have no idea how to prove the second part. Could anyone help me with this?","For upcrossings we have defined $S_{n}=\inf \{k>B_{n}:x_{k}>b\}$  and $B_{n}=\inf \{k>S_{n-1}:x_{k}<a\}$. The number of upcrossings over the interval $(a,b)$ is given by $U_{N}(a,b)=\max\{n:S_{n}\leq N\}$. $U(a,b)=\lim_{N\rightarrow \infty} U_{N}(a,b)$ It is stated that $S_{n}$ and $B_{n}$ are stopping times ($\{S_{n}\leq k\}\in F_{k}$) and that $U_{N}(a,b)$ is $F_{N}$-measurable and $U(a,b)$ is $F_{\infty}$-measurable, I think I managed to show that $B_{n}$ and $S_{n}$ are stopping times by: $$\{B_{n}\leq k\}=\bigcup_{i=S_{n-1}}^{k}\{x_{i}<a\}$$ As $\{x_{i}<a\}\in F_{i}\subset F_{k}$ so $\{B_{n}\leq k\}\in F_{k}$. I was wondering if I've done this correctly and I have no idea how to prove the second part. Could anyone help me with this?",,['measure-theory']
43,"$\lim\limits_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = \int_X |f(x)|^2 \,dm(x)$",,"\lim\limits_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = \int_X |f(x)|^2 \,dm(x)","Question. Let $(X, M, m)$ be an arbitrary measure space. Let $f \in L^1_m(X)$. Then $$\lim_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = 0.$$ Solution. Observe that $$n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \leq n \log \left( 1 + \frac{|f(x)|}{n} \right)^2 = 2n \log \left( 1 + \frac{|f(x)|}{n} \right) \leq 2n \frac{|f(x)|}{n} = 2|f(x)|.$$ Then $n \log \left( 1 + \frac{|f(x)|^2}{n} \right)$ is dominated by $2|f(x)|$. Moreover, we have $$\lim_{n \rightarrow \infty} \frac{\log \left( 1 + \frac{|f(x)|^2}{n} \right)}{1/n} = \frac{0}{0}.$$ So we apply L'Hopital's Rule and we obtain: $$\lim_{n \rightarrow \infty} \frac{\log \left( 1 + \frac{|f(x)|^2}{n} \right)}{1/n} = \lim_{n \rightarrow \infty} \frac{\frac{-|f(x)|^2}{n^2} (-n^2)}{ 1 + \frac{|f(x)|^2}{n} } = |f(x)|^2.$$ Then by Lebesgue Dominated Convergence Theorem, we conclude that $$\lim_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = \int_X |f(x)|^2 \,dm(x).$$ Where is the proof wrong? Thanks. Added Later. I found the mistake: $n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \leq n \log \left( 1 + \frac{|f(x)|}{n} \right)^2$ is not true for all $n$. As @did suggested, dominating function should be $|f|^2$.","Question. Let $(X, M, m)$ be an arbitrary measure space. Let $f \in L^1_m(X)$. Then $$\lim_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = 0.$$ Solution. Observe that $$n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \leq n \log \left( 1 + \frac{|f(x)|}{n} \right)^2 = 2n \log \left( 1 + \frac{|f(x)|}{n} \right) \leq 2n \frac{|f(x)|}{n} = 2|f(x)|.$$ Then $n \log \left( 1 + \frac{|f(x)|^2}{n} \right)$ is dominated by $2|f(x)|$. Moreover, we have $$\lim_{n \rightarrow \infty} \frac{\log \left( 1 + \frac{|f(x)|^2}{n} \right)}{1/n} = \frac{0}{0}.$$ So we apply L'Hopital's Rule and we obtain: $$\lim_{n \rightarrow \infty} \frac{\log \left( 1 + \frac{|f(x)|^2}{n} \right)}{1/n} = \lim_{n \rightarrow \infty} \frac{\frac{-|f(x)|^2}{n^2} (-n^2)}{ 1 + \frac{|f(x)|^2}{n} } = |f(x)|^2.$$ Then by Lebesgue Dominated Convergence Theorem, we conclude that $$\lim_{n \rightarrow \infty} \int_X n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \,dm(x) = \int_X |f(x)|^2 \,dm(x).$$ Where is the proof wrong? Thanks. Added Later. I found the mistake: $n \log \left( 1 + \frac{|f(x)|^2}{n} \right) \leq n \log \left( 1 + \frac{|f(x)|}{n} \right)^2$ is not true for all $n$. As @did suggested, dominating function should be $|f|^2$.",,"['measure-theory', 'lebesgue-integral', 'fake-proofs']"
44,$\sigma$ algebra of collection of random variables,algebra of collection of random variables,\sigma,"Im doing a course on measure theory and I'm stuck on one of the exercises. Take $\{Y_{\gamma}:\gamma \in C\}$ as an arbitrary collection of random variables and $\{X_{n}: n \in N\}$ to be a countable collection of random variables I now want to show that $$\sigma \{Y_{\gamma} : \gamma \in C\}=\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$$ So i need to show that both $\sigma \{Y_{\gamma} : \gamma \in C\}\subset\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$ and $\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}\subset\sigma \{Y_{\gamma} : \gamma \in C\}$ hold. I know that for a single random variable X you have $\sigma(X)=\{X^{-1}(B): B \in Borel\}$. How do I expand this for the collection of random variables? I then also have to show that if $Fn=\sigma\{X_{1},...,X_{n}\}$ and $A=\cup_{n=1}^{\infty}F_{n}$ then $$\sigma(A)=\sigma\{X_{n}: n \in N\}$$ Can anyone help me with this?","Im doing a course on measure theory and I'm stuck on one of the exercises. Take $\{Y_{\gamma}:\gamma \in C\}$ as an arbitrary collection of random variables and $\{X_{n}: n \in N\}$ to be a countable collection of random variables I now want to show that $$\sigma \{Y_{\gamma} : \gamma \in C\}=\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$$ So i need to show that both $\sigma \{Y_{\gamma} : \gamma \in C\}\subset\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$ and $\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}\subset\sigma \{Y_{\gamma} : \gamma \in C\}$ hold. I know that for a single random variable X you have $\sigma(X)=\{X^{-1}(B): B \in Borel\}$. How do I expand this for the collection of random variables? I then also have to show that if $Fn=\sigma\{X_{1},...,X_{n}\}$ and $A=\cup_{n=1}^{\infty}F_{n}$ then $$\sigma(A)=\sigma\{X_{n}: n \in N\}$$ Can anyone help me with this?",,"['measure-theory', 'random-variables']"
45,Characteristic functions based proof problem.,Characteristic functions based proof problem.,,"I am trying to show that if $T$ be a closed bounded interval and $E$ a measurable subset of $T$. Let $\epsilon >0$, then there is a step function $h$ on $T$ and a measurable subset $F$ of $T$ for which $h=\chi_E$ on $F$ and $m(T - F)<\epsilon$. Some Thoughts towards the proof. $\forall \epsilon >0$, there is a finite disjoint collection of open intervals $\left\{ I_{k}\right\} _{k=1}^{n}$ for which if $O=U_{k=1}^{n}I_{k}$ then $$m^{*}(E-O) + m^{*}(O-E) < \epsilon.$$ Also $$\chi_{E}=\begin{cases}1, & x\in E \\ 0, & x\notin E. \end{cases} $$ So $\forall \epsilon >0$ we have $\chi_{E} = \chi_{O}$. Now $h$ being a step function looks like $$h =\sum _{i=0}^{n}\alpha _{i}\chi _{T_i}\left( x\right).$$ I am unsure how to proceed from here and show the two results. Any help would be much appreciated.","I am trying to show that if $T$ be a closed bounded interval and $E$ a measurable subset of $T$. Let $\epsilon >0$, then there is a step function $h$ on $T$ and a measurable subset $F$ of $T$ for which $h=\chi_E$ on $F$ and $m(T - F)<\epsilon$. Some Thoughts towards the proof. $\forall \epsilon >0$, there is a finite disjoint collection of open intervals $\left\{ I_{k}\right\} _{k=1}^{n}$ for which if $O=U_{k=1}^{n}I_{k}$ then $$m^{*}(E-O) + m^{*}(O-E) < \epsilon.$$ Also $$\chi_{E}=\begin{cases}1, & x\in E \\ 0, & x\notin E. \end{cases} $$ So $\forall \epsilon >0$ we have $\chi_{E} = \chi_{O}$. Now $h$ being a step function looks like $$h =\sum _{i=0}^{n}\alpha _{i}\chi _{T_i}\left( x\right).$$ I am unsure how to proceed from here and show the two results. Any help would be much appreciated.",,"['real-analysis', 'measure-theory', 'characteristic-functions']"
46,Is my counter-example correct?,Is my counter-example correct?,,"In my homework for real-analysis I was asked to prove the following statement: On $[0,1]$, for $1\leq{}p<\infty$, If $f_{n}\rightarrow{}f$ a.e. and $||f_{n}||_{p}\leq{}M \space\space\forall\space n$, show that $f_{n}\rightarrow{}f$ weakly in $L^{p}$. I thought about it for some time, but I could not come up with a proof. Then suddenly it seemed that I found a counter-example for this statement. Can anybody help me judge whether my counter-example is valid? $$ f_{n} = \begin{cases} n^{2}x, & x\in [0,\frac{1}{n}] \\ 2n-n^{2}x, & x\in[\frac{1}{n},\frac{2}{n}] \\ 0, & x\in[\frac{2}{n},1] \end{cases} $$ $$ g=1 \text{ on } [0,1] $$ $$ f=0 \text{ on } [0,1] $$ Then it seems to me that $f_{n}\rightarrow{}f$ a.e. on $[0,1]$, $f\in{}L^{1},g\in{L^{\infty}}, ||f||_{1}=1\leq2$. But $\int{f_{n}g=1\nrightarrow0=\int{fg}}$. So $f_n$ does not converge weakly to $f$ in $L^{1}$. Is my counter-example valid? If not, how can I prove the statement? Thank you!!","In my homework for real-analysis I was asked to prove the following statement: On $[0,1]$, for $1\leq{}p<\infty$, If $f_{n}\rightarrow{}f$ a.e. and $||f_{n}||_{p}\leq{}M \space\space\forall\space n$, show that $f_{n}\rightarrow{}f$ weakly in $L^{p}$. I thought about it for some time, but I could not come up with a proof. Then suddenly it seemed that I found a counter-example for this statement. Can anybody help me judge whether my counter-example is valid? $$ f_{n} = \begin{cases} n^{2}x, & x\in [0,\frac{1}{n}] \\ 2n-n^{2}x, & x\in[\frac{1}{n},\frac{2}{n}] \\ 0, & x\in[\frac{2}{n},1] \end{cases} $$ $$ g=1 \text{ on } [0,1] $$ $$ f=0 \text{ on } [0,1] $$ Then it seems to me that $f_{n}\rightarrow{}f$ a.e. on $[0,1]$, $f\in{}L^{1},g\in{L^{\infty}}, ||f||_{1}=1\leq2$. But $\int{f_{n}g=1\nrightarrow0=\int{fg}}$. So $f_n$ does not converge weakly to $f$ in $L^{1}$. Is my counter-example valid? If not, how can I prove the statement? Thank you!!",,"['real-analysis', 'measure-theory', 'examples-counterexamples']"
47,How to show a sequence is not uniformly integrable,How to show a sequence is not uniformly integrable,,"Let $(X,\Omega,\mu)$ be a measure space.  A sequence $f_n$ is said to be uniformly integrable if for every $\epsilon \gt 0$ there is a $\delta \gt 0$ such that for every measurable set $A$ with $\mu(A)\lt \delta$ , $\int_A |f_n|~d\mu \lt \epsilon$ , for every $n\in \mathbb{N}$ . A sequence is said to be tight if for every $\epsilon \gt 0$ there is a measurable set $B$ of finite measure such that $\int_{X\setminus B} |f_n|~d\mu \lt \epsilon $ , for every $n\in \mathbb{N}$ . I claim the $f_n = n\cdot 1_{[0,1/n]}$ is not uniformly integrable and $g_n = 1_{[n,n+1]}$ is not tight. Proof. Fix $\epsilon \gt 0$ . Pick $n$ sufficiently large so that for every $\delta \gt 0$ , $n\delta \gt 1/2.$ Then there is an $n$ such that $\int_A |f_n| \gt 1/2.$ Let $\mu(B)\lt \infty$ . Suppose to the contrary that $g_n$ were tight. Then $\mu\left((X\setminus B)\cap [n,n+1]\right) \lt \epsilon$ .   If I can get that $\mu(B) = \infty$ , then I would have a contradiction, but I don't see how. Is what I have done above right?","Let be a measure space.  A sequence is said to be uniformly integrable if for every there is a such that for every measurable set with , , for every . A sequence is said to be tight if for every there is a measurable set of finite measure such that , for every . I claim the is not uniformly integrable and is not tight. Proof. Fix . Pick sufficiently large so that for every , Then there is an such that Let . Suppose to the contrary that were tight. Then .   If I can get that , then I would have a contradiction, but I don't see how. Is what I have done above right?","(X,\Omega,\mu) f_n \epsilon \gt 0 \delta \gt 0 A \mu(A)\lt \delta \int_A |f_n|~d\mu \lt \epsilon n\in \mathbb{N} \epsilon \gt 0 B \int_{X\setminus B} |f_n|~d\mu \lt \epsilon  n\in \mathbb{N} f_n = n\cdot 1_{[0,1/n]} g_n = 1_{[n,n+1]} \epsilon \gt 0 n \delta \gt 0 n\delta \gt 1/2. n \int_A |f_n| \gt 1/2. \mu(B)\lt \infty g_n \mu\left((X\setminus B)\cap [n,n+1]\right) \lt \epsilon \mu(B) = \infty",['measure-theory']
48,Measuring closed balls,Measuring closed balls,,"Let $(X,\parallel \cdot \parallel)$ be Banach and  $$\mathcal{BC}(X)=\{A\subset X\colon A \text{ is closed, bounded and non-empty}\}.$$ The natural metric on this space is the Hausdorff distance $d_H$ (see http://en.wikipedia.org/wiki/Hausdorff_distance ) Let $C_x(r)$ be the closed ball around $x\in X$ with radius $r$. How can I show that the map $f\colon X\to\mathcal{BC}(X)$ where $f(x)=C_x(r)$ is continuous w.r.t. $d_H$? And is the map $g\colon X\to\mathbf{R}$ with $g(x)=\mu(C_x(R))$ Borel measurable for a Borel measure $\mu$?","Let $(X,\parallel \cdot \parallel)$ be Banach and  $$\mathcal{BC}(X)=\{A\subset X\colon A \text{ is closed, bounded and non-empty}\}.$$ The natural metric on this space is the Hausdorff distance $d_H$ (see http://en.wikipedia.org/wiki/Hausdorff_distance ) Let $C_x(r)$ be the closed ball around $x\in X$ with radius $r$. How can I show that the map $f\colon X\to\mathcal{BC}(X)$ where $f(x)=C_x(r)$ is continuous w.r.t. $d_H$? And is the map $g\colon X\to\mathbf{R}$ with $g(x)=\mu(C_x(R))$ Borel measurable for a Borel measure $\mu$?",,"['measure-theory', 'metric-spaces', 'banach-spaces']"
49,Differentiability almost everywhere of the variation of a function,Differentiability almost everywhere of the variation of a function,,"I'm stuck on the following exercise If $f: [a,b]\to \mathbb R$ is of bounded variation, $t(x) = Var(f;[a,x])$ for ($a\le x \le b$), then $t$ is $\lambda$-a.e. differentiable and $t' = |f'|$ almost everywhere. (here $\lambda$ denotes Lebesgue measure). $t$ is monotonically increasing, so is differentiable almost everywhere. Also, we have for $y<x$: $$ \begin{align} \frac{t(x)-t(y)}{x-y} &= \frac{Var(f,[y,x])}{x-y} \\ &\ge \frac{|f(x)-f(y)|}{x-y} \\ \end{align} $$ Letting $y\to x$ we obtain - at each point, where both limits exist - that $t'(x) \ge |f'(x)|$. I don't know how to prove the other inequality, though. There is also a hint in the exercise that one should use the following result: If $f_n: [a,b]\to \mathbb R$ is a sequence of montonically increasing functions such that $F = \sum_n f_n$ converges, then for almost all $x\in [a,b]$ we have    $$F'(x) = \sum_n f_n'(x)$$ But I really don't see how this could be used here... I have also thought about writing $f(x) = f^+(x) - f^-(x)$ for monotonically increasing $f^+$ and $f^-$. And then $t(x) = f^+(x) + f^-(x)$, so I would need to prove $$(f^+)'(x) + (f^-)'(x) = |(f^+)'(x) - (f^-)'(x)|$$ for almost all $x$. This is the same as saying that for almost all $x$ we either have $(f^+)'(x) = 0$ or $(f^-)'(x) = 0$. This seems like an Ansatz, which might lead to something, but I can't push it to its conclusion. Any help would be greatly appreciated. Thanks! =)","I'm stuck on the following exercise If $f: [a,b]\to \mathbb R$ is of bounded variation, $t(x) = Var(f;[a,x])$ for ($a\le x \le b$), then $t$ is $\lambda$-a.e. differentiable and $t' = |f'|$ almost everywhere. (here $\lambda$ denotes Lebesgue measure). $t$ is monotonically increasing, so is differentiable almost everywhere. Also, we have for $y<x$: $$ \begin{align} \frac{t(x)-t(y)}{x-y} &= \frac{Var(f,[y,x])}{x-y} \\ &\ge \frac{|f(x)-f(y)|}{x-y} \\ \end{align} $$ Letting $y\to x$ we obtain - at each point, where both limits exist - that $t'(x) \ge |f'(x)|$. I don't know how to prove the other inequality, though. There is also a hint in the exercise that one should use the following result: If $f_n: [a,b]\to \mathbb R$ is a sequence of montonically increasing functions such that $F = \sum_n f_n$ converges, then for almost all $x\in [a,b]$ we have    $$F'(x) = \sum_n f_n'(x)$$ But I really don't see how this could be used here... I have also thought about writing $f(x) = f^+(x) - f^-(x)$ for monotonically increasing $f^+$ and $f^-$. And then $t(x) = f^+(x) + f^-(x)$, so I would need to prove $$(f^+)'(x) + (f^-)'(x) = |(f^+)'(x) - (f^-)'(x)|$$ for almost all $x$. This is the same as saying that for almost all $x$ we either have $(f^+)'(x) = 0$ or $(f^-)'(x) = 0$. This seems like an Ansatz, which might lead to something, but I can't push it to its conclusion. Any help would be greatly appreciated. Thanks! =)",,"['real-analysis', 'measure-theory']"
50,Finite Borel measures that don't agree on $\mathbb{R}$,Finite Borel measures that don't agree on,\mathbb{R},"How would I go about finding a family $X$ of Borel sets in $\mathbb{R}$ that generate the Borel $\sigma$-algbera on $\mathbb{R}$ and two finite Borel measure $\mu$ and $\nu$ that agree on $X$ but do not agree on the whole Borel $\sigma$-algebra. I know that $X$ cannot be a $\Pi$-system, so I was thinking of using the open intervals but I'm really struggling with the measures. The only finite measures I can think of are Dirac point measures.","How would I go about finding a family $X$ of Borel sets in $\mathbb{R}$ that generate the Borel $\sigma$-algbera on $\mathbb{R}$ and two finite Borel measure $\mu$ and $\nu$ that agree on $X$ but do not agree on the whole Borel $\sigma$-algebra. I know that $X$ cannot be a $\Pi$-system, so I was thinking of using the open intervals but I'm really struggling with the measures. The only finite measures I can think of are Dirac point measures.",,['measure-theory']
51,Proving the equality case of the Rising Sun Inequality,Proving the equality case of the Rising Sun Inequality,,"I'm stuck at the finish line on a pair of Exercises from Tao's Introduction to Measure Theory: Exercise 1.6.12 (Rising Sun Inequality). Let $f : \mathbb{R} \to \mathbb{R}$ be an absolutely integrable function, and let $f^* : \mathbb{R} \to \mathbb{R}$ be the one-sided signed Hardy-Littlewood maximal function $$ f^*(x) := \sup_{h>0}\frac{1}{h}\int_{[x,x+h]}f(t)\,dt. $$ Establish the rising sun inequality $$ \lambda m(\{x\in\mathbb{R} : f^*(x) > \lambda\}) \leq \int_{\{x \in\mathbb{R} : f^*(x) > \lambda\}}f(t)\,dt $$ for all real $\lambda$ (note here that we permit $\lambda$ to be zero or negative) [...] Exercise 1.6.13. Show that the left- and right-hand sides of Exercise 1.6.12 are in fact equal when $\lambda > 0$ . ( Hint : One may first wish to try this in the case when $f$ has compact support [...]) I've proven Exercise 1.6.12, and for 1.6.13, following the hint I proved equality for the case when $f$ has compact support. My issue is on generalizing 1.6.13 to all absolutely integrable $f$ . Here's my thinking so far. If $f$ is absolutely integrable, we can define functions $f_n = f1_{[-n,n]}$ for $n \in \mathbb{N}$ and apply the compact-support case to the $f_n$ . Namely, letting $A_n := \{x \in \mathbb{R} : f_n^*(x) > \lambda\}$ and $A := \{x \in \mathbb{R} : f^*(x) > \lambda\}$ we know that $$ \lambda m(A_n) = \int_{A_n}f_n(t)\,dt $$ for each $n$ . I was hoping we could let $n \to \infty$ on both sides and be done, but it's not quite so simple, since the relationship between the sets $A_n$ and $A$ is a bit subtle. One can verify that $A = \lim_{n\to\infty} A_n$ in the sense that $1_{A_n} \to 1_A$ pointwise, but each $A_n$ is not necessarily a  subset of $A$ nor is it necessarily a subset of $A_{n+1}$ . (The issue occurs at the points in $A_n$ which are less than $-n$ .) Since $f$ is absolutely integrable we do have $\int_{A_n}f_n(t)\,dt \to \int_{A}f(t)\,dt$ by the dominated convergence theorem, but I can't (yet) justify that $m(A_n) \to m(A)$ . At best I can use Fatou's Lemma to say that $m(A) \leq \lim_{n\to\infty} m(A_n)$ , but that just yields the rising sun inequality again, which I already know. Is there something I'm missing, or should I find another method to generalize 1.6.13 from the compact-support case?","I'm stuck at the finish line on a pair of Exercises from Tao's Introduction to Measure Theory: Exercise 1.6.12 (Rising Sun Inequality). Let be an absolutely integrable function, and let be the one-sided signed Hardy-Littlewood maximal function Establish the rising sun inequality for all real (note here that we permit to be zero or negative) [...] Exercise 1.6.13. Show that the left- and right-hand sides of Exercise 1.6.12 are in fact equal when . ( Hint : One may first wish to try this in the case when has compact support [...]) I've proven Exercise 1.6.12, and for 1.6.13, following the hint I proved equality for the case when has compact support. My issue is on generalizing 1.6.13 to all absolutely integrable . Here's my thinking so far. If is absolutely integrable, we can define functions for and apply the compact-support case to the . Namely, letting and we know that for each . I was hoping we could let on both sides and be done, but it's not quite so simple, since the relationship between the sets and is a bit subtle. One can verify that in the sense that pointwise, but each is not necessarily a  subset of nor is it necessarily a subset of . (The issue occurs at the points in which are less than .) Since is absolutely integrable we do have by the dominated convergence theorem, but I can't (yet) justify that . At best I can use Fatou's Lemma to say that , but that just yields the rising sun inequality again, which I already know. Is there something I'm missing, or should I find another method to generalize 1.6.13 from the compact-support case?","f : \mathbb{R} \to \mathbb{R} f^* : \mathbb{R} \to \mathbb{R} 
f^*(x) := \sup_{h>0}\frac{1}{h}\int_{[x,x+h]}f(t)\,dt.
 
\lambda m(\{x\in\mathbb{R} : f^*(x) > \lambda\}) \leq \int_{\{x \in\mathbb{R} : f^*(x) > \lambda\}}f(t)\,dt
 \lambda \lambda \lambda > 0 f f f f f_n = f1_{[-n,n]} n \in \mathbb{N} f_n A_n := \{x \in \mathbb{R} : f_n^*(x) > \lambda\} A := \{x \in \mathbb{R} : f^*(x) > \lambda\} 
\lambda m(A_n) = \int_{A_n}f_n(t)\,dt
 n n \to \infty A_n A A = \lim_{n\to\infty} A_n 1_{A_n} \to 1_A A_n A A_{n+1} A_n -n f \int_{A_n}f_n(t)\,dt \to \int_{A}f(t)\,dt m(A_n) \to m(A) m(A) \leq \lim_{n\to\infty} m(A_n)","['real-analysis', 'measure-theory', 'inequality', 'lebesgue-integral']"
52,"If $S=(X, \mathcal{F})$ is a measurable space, $\mu,\nu$ two measure on S s.t. $\nu\ll\mu$, are all $\mu$-measurable functions also $\nu$-measurable?","If  is a measurable space,  two measure on S s.t. , are all -measurable functions also -measurable?","S=(X, \mathcal{F}) \mu,\nu \nu\ll\mu \mu \nu","Let $S = (X,\mathcal{F})$ be a measurable space, i.e. $X$ be a set and $\mathcal{F}$ be a $\sigma$ -algebra on $X$ . Suppose $\mu, \nu$ are two measures on $S$ such that $\nu$ is absolutely continuous with respect to $\mu$ , i.e. write $\nu\ll\mu$ to denote that $\forall A\in \mathcal{F}:\mu(A) = 0\implies \nu(A) = 0$ . Is it then true that every $\mu$ -measurable function $f$ is also $\nu$ -measurable? That is, if $(Y, \mathcal{G})$ is another measurable space and $f:X\to Y$ is a map such that $\forall A \in G:\text{$f^{-1}(A)\in \mathcal{F}$ and $f^{-1}(A)$ is $\mu$-measurable}$ . This can very well be a completely trivial question, but I don't recall many tools that allow one to tackle a question like this. As of now, I also don't know how to approach it: Canonically we would like to show that $$\forall A\in \mathcal{G}, B\subset X, : \nu(B) = \nu(f^{-1}(A)\cap B) + \nu(B\setminus f^{-1}(A))$$ and our only source of information is that $$\forall A\in \mathcal{G}, B\subset X, : \mu(B) = \mu(f^{-1}(A)\cap B) + \mu(B\setminus f^{-1}(A))$$ How should we apply the absolute continuity in this case?","Let be a measurable space, i.e. be a set and be a -algebra on . Suppose are two measures on such that is absolutely continuous with respect to , i.e. write to denote that . Is it then true that every -measurable function is also -measurable? That is, if is another measurable space and is a map such that . This can very well be a completely trivial question, but I don't recall many tools that allow one to tackle a question like this. As of now, I also don't know how to approach it: Canonically we would like to show that and our only source of information is that How should we apply the absolute continuity in this case?","S = (X,\mathcal{F}) X \mathcal{F} \sigma X \mu, \nu S \nu \mu \nu\ll\mu \forall A\in \mathcal{F}:\mu(A) = 0\implies \nu(A) = 0 \mu f \nu (Y, \mathcal{G}) f:X\to Y \forall A \in G:\text{f^{-1}(A)\in \mathcal{F} and f^{-1}(A) is \mu-measurable} \forall A\in \mathcal{G}, B\subset X, : \nu(B) = \nu(f^{-1}(A)\cap B) + \nu(B\setminus f^{-1}(A)) \forall A\in \mathcal{G}, B\subset X, : \mu(B) = \mu(f^{-1}(A)\cap B) + \mu(B\setminus f^{-1}(A))","['real-analysis', 'measure-theory', 'measurable-functions']"
53,Are Haar measures localizable?,Are Haar measures localizable?,,"I'm trying to prove that Haar measures are localizable. we know that Haar measures are decomposable ( see Haar measures are decomposable ) in the sense that: A measure space $(X,\mathfrak{M},\mu)$ is decomposable if: (i) $X$ is a disjoint union of measurable subsets, $X=\bigcup_{i\in I}X_{i}$ , with $\mu(X_{i})<\infty$ for all $i$ . (ii) $\mu(E)=\sum_{i\in I}\mu(E\cap X_i)$ for every measurable set $E$ of finite measure. (iii) if $E\subseteq X$ and $E\cap X_i\in \frak{M}$ for all $i$ , then $E\in\frak{M}$ . if relation (ii) holds for every $E\in \frak{M}$ , then we called $(X,\frak{M},\mu)$ localizable. $\color{blue}{\textbf{can someone tell me that is my solution correct or not?}}$ $\color{green}{\textbf{my solution:}}$ $\color{red}{\textbf{the idea of proof is to prove that:}}$ $\color{red}{\bigg[}$ there exists a measure $\lambda$ on ${\frak{B}}_G$ that is radon and translation invariant and hence is a Haar measure on $G$ and by uniqueness of haar measure, we prove that the first Haar measure $\mu$ is equal with this new measure $\lambda$ and finally, the measure $\lambda$ have a property that localizability is proved. $\color{red}{\bigg]}$ if $G$ be a locally compact group  and $(G,{\frak{B}}_G,\mu)$ be Haar measure space where ${\frak{B}}_G$ is the borel $\sigma$ -algebra, then if we define a measure $\lambda$ on ${\frak{B}}_G$ such that: \begin{equation}     \lambda(E)=     \begin{cases}       \underset{i\in I}{\sum}\mu(E\cap X_i) & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)<\infty \\       \infty & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)=\infty     \end{cases}   \end{equation} $\color{red}{\textbf{proof that $\lambda$ is a translation invariant measure:}}$ if $\{E_j\}_{j\in\mathbb{N}}$ be a family of disjoint measurable sets, then if $\underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]<\infty$ , then $\underset{i\in I}{\sum}\mu(E_j\cap X_i)<\infty$ for every $j\in\mathbb{N}$ and  we have $\lambda\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)=\underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]=\underset{i\in I}{\sum}\mu\bigg[\underset{j\in \mathbb{N}}{\bigcup}\bigg(E_j\bigcap X_i\bigg)\bigg]=\underset{i \in I}{\sum}\underset{j\in \mathbb{N}}{\sum}\mu(E_j\cap X_i)\color{red}=\underset{j\in \mathbb{N}}{\sum}\underset{i\in I}{\sum}\mu(E_j\cap X_i)=\underset{j\in\mathbb{N}}{\sum}\lambda(E_j)$ equality in red follows from following relation in measure theory. if we consider $\mu$ as counting measure and $X$ as arbitrary set. $$\int_X\underset{j\in\mathbb{N}}{\sum}f_j(x)d\mu=\underset{j\in \mathbb{N}}{\sum}\int_Xf_j(x)d\mu$$ now if $\underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]=\infty$ , then we have $\underset{j\in\mathbb{N}}{\sum}\lambda(E_j)=\infty$ and $\lambda\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)=\infty$ . also it is trivial that $\mu(\phi)=0$ and is proved that $\lambda$ is really a measure on ${\frak{B}}_G$ . it is easy to see that $\lambda$ is translation invariant. we have to prove that the measure $\lambda$ is radon. $\color{red}{\textbf{proof that $\lambda$ is finite on compact sets:}}$ if $K\in {\frak{B}}_G$ is a compact set, then $\mu(K)<\infty$ and by property (ii) of decomposability, it follows that $\underset{i\in I}{\sum}\mu(K\cap X_i)=\mu(K)<\infty$ . hence $\lambda(K)=\underset{i\in I}{\sum}\mu(K\cap X_i)<\infty$ and $\lambda$ is finite on compact sets. $\color{red}{\textbf{proof that $\lambda$ is inner regular on sets of finite measure:}}$ if $E\in{\frak{B}}_G$ and $\lambda(E)<\infty$ and for arbitrary $\epsilon>0$ , then $\lambda(E)=\underset{i\in I}{\sum}\mu(E\cap X_i)$ and by definition, there exists a finite set $F\subseteq I$ suchthat $\underset{i\in I}{\sum}\mu(E\cap X_i)-\frac{\epsilon}{2}<\underset{i\in F}{\sum}\mu(E\cap X_i)$ now since $\mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]<\mu(E)<\infty$ , then there exists a compact set $K\subseteq \underset{i\in F}{\bigcup}(E\cap X_i)\subseteq E$ such that $$\mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]-\frac{\epsilon}{2}<\mu(K)$$ and it follows that: $\lambda(E)-\epsilon=\underset{i\in I}{\sum}\mu(E\cap X_i)-\epsilon<\underset{i\in F}{\sum}\mu(E\cap X_i)-\frac{\epsilon}{2}=\mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]-\frac{\epsilon}{2}<\mu(K)$ hence we have $$ \lambda(E)-\epsilon<\mu(K) $$ where $K\subseteq E$ . hence inner regularity on sets with finite measure is proved. $\color{red}{\textbf{proof that $\lambda$ is outer regular}}$ if $E\in {\frak{B}}_G$ with $\lambda(E)=\infty$ . then since $\lambda$ is a measure and $E\subseteq G$ , then we have $\lambda(G)=\infty$ and since $G$ is open, then $\lambda$ is inner regular on sets with infinite measure. now if $E\in {\frak{B}}_G$ and $\lambda(E)<\infty$ and for arbitrary $\epsilon>0$ , since $\underset{i\in I}{\sum}\mu(E\cap X_i)=\lambda(E)<\infty$ , then $\mu(E\cap X_i)=0$ except for countable number  of $i\in \mathbb{N}\subseteq I$ . hence we have $$\lambda(E)=\underset{i\in I}{\sum}\mu(E\cap X_i)=\underset{i\in \mathbb{N}}{\sum}\mu(E\cap X_i)=\mu\bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]$$ now, there exists an open set $O_1\supseteq \bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]$ such that $\mu(O_1)<\mu\bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\epsilon$ and it follows that $$\mu(O_1)<\lambda(E)+\epsilon\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(1)$$ now, there exists a compct set $K\subseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]$ such that $$\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]<\frac{\epsilon}{2}+\mu(K)\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(2)$$ but in the case of Haar measure, the set $\{X_i\}_{i \in I}$ is equal with $\{gU'_n|g\in C, n\in\mathbb{N}\}$ and $H=\underset{n\in \mathbb{N}}{\bigcup}U'_n$ where $H$ is a open subgroup of $G$ and the set $C$ contains one poin from every coset $gH$ (for details, see Haar measures are decomposable ). know if $K\subseteq G$ be a compact set, then since $K\subseteq \underset{g\in C}{\bigcup}gH$ and $\{gH|g\in C\}$ is an open cover of $K$ , then since $K$ is compact, there exists a finite set $g_1,...,g_n$ such that $K\subseteq \underset{i=1}{\overset{n}{\bigcup}}g_iH$ . hence $K$ is subset of union of countable numbers of $X_i$ $\Bigg(K\subseteq \underset{i\in \mathbb{N'}}{\bigcup}X_i\Bigg)$ where $\mathbb{N'}$ is a countable subset of $I$ . now we have $$K\subseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]\bigcap\bigg[\underset{i\in \mathbb{N'}}{\bigcup}X_i\bigg]=\bigg[E\bigcap\bigg(\underset{i\in\mathbb{N''}}{\bigcup}X_i\bigg)\bigg]$$ where $\mathbb{N''}\subseteq I\setminus\mathbb{N}$ is a countable subset of $I$ and we have $$\mu(K)\leq\mu\bigg[E\bigcap\bigg(\underset{i\in\mathbb{N''}}{\bigcup}X_i\bigg)\bigg]=\underset{i\in \mathbb{N''}}{\sum}\mu(E\cap X_i)=0$$ because we know that if $i\in I\setminus\mathbb{N}$ , then $\mu(E\cap X_i)=0$ . hence $\mu(K)=0$ and from formula $(2)$ , we have $\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]<\frac{\epsilon}{2}+\mu(K)=\frac{\epsilon}{2}$ also there exists an open set $O_2\supseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]$ such that $\mu(O_2)<\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\frac{\epsilon}{2}$ hence we have $$\mu(O_2)<\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\frac{\epsilon}{2}<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(3)$$ and by formula $(1)$ and $(3)$ , we have $$\mu(O_1\cup O_2)\leq\mu(O_1)+\mu(O_2)<[\lambda(E)+\epsilon]+\epsilon=\lambda(E)+2\epsilon$$ where $E\subseteq \bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]\bigcup \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]\subseteq O_1\cup O_2$ . but since $\lambda(E)<\infty$ , then $\mu(O_1\cup O_2)<\infty$ and by second decomposability property of Haar measure, we have $$\infty>\mu(O_1\cup O_2)=\underset{i\in I}{\sum}\mu\bigg[\bigg(O_1\cup O_2\bigg)\cap X_i\bigg]$$ hence by definition of $\lambda$ , it follows that $$\lambda(O_1\cup O_2)=\underset{i\in I}{\sum}\mu\bigg[\bigg(O_1\cup O_2\bigg)\cap X_i\bigg]=\mu(O_1\cup O_2)<\lambda(E)+2\epsilon$$ hence we have $$ \lambda(O_1\cup O_2)<\lambda(E)+2\epsilon $$ where $E\subseteq O_1\cup O_2$ . and is proved that $\lambda$ is outer regular. $\color{red}{\textbf{proof that $\mu$ is localizable}}$ now by uniqueness of Haar measure, we know that $\lambda=\mu$ and we have: \begin{equation}     \mu(E)=\lambda(E)=     \begin{cases}       \underset{i\in I}{\sum}\mu(E\cap X_i) & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)<\infty \\       \infty & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)=\infty     \end{cases}   \end{equation} and it follows that in any case we have $\mu(E)=\underset{i\in I}{\sum}\mu(E\cap X_i)$ and second decomposability property of Haar measure  holds for every $E\in {\frak{B}}_G$ and it follows that Haar measure $\mu$ is localizable.","I'm trying to prove that Haar measures are localizable. we know that Haar measures are decomposable ( see Haar measures are decomposable ) in the sense that: A measure space is decomposable if: (i) is a disjoint union of measurable subsets, , with for all . (ii) for every measurable set of finite measure. (iii) if and for all , then . if relation (ii) holds for every , then we called localizable. there exists a measure on that is radon and translation invariant and hence is a Haar measure on and by uniqueness of haar measure, we prove that the first Haar measure is equal with this new measure and finally, the measure have a property that localizability is proved. if be a locally compact group  and be Haar measure space where is the borel -algebra, then if we define a measure on such that: if be a family of disjoint measurable sets, then if , then for every and  we have equality in red follows from following relation in measure theory. if we consider as counting measure and as arbitrary set. now if , then we have and . also it is trivial that and is proved that is really a measure on . it is easy to see that is translation invariant. we have to prove that the measure is radon. if is a compact set, then and by property (ii) of decomposability, it follows that . hence and is finite on compact sets. if and and for arbitrary , then and by definition, there exists a finite set suchthat now since , then there exists a compact set such that and it follows that: hence we have where . hence inner regularity on sets with finite measure is proved. if with . then since is a measure and , then we have and since is open, then is inner regular on sets with infinite measure. now if and and for arbitrary , since , then except for countable number  of . hence we have now, there exists an open set such that and it follows that now, there exists a compct set such that but in the case of Haar measure, the set is equal with and where is a open subgroup of and the set contains one poin from every coset (for details, see Haar measures are decomposable ). know if be a compact set, then since and is an open cover of , then since is compact, there exists a finite set such that . hence is subset of union of countable numbers of where is a countable subset of . now we have where is a countable subset of and we have because we know that if , then . hence and from formula , we have also there exists an open set such that hence we have and by formula and , we have where . but since , then and by second decomposability property of Haar measure, we have hence by definition of , it follows that hence we have where . and is proved that is outer regular. now by uniqueness of Haar measure, we know that and we have: and it follows that in any case we have and second decomposability property of Haar measure  holds for every and it follows that Haar measure is localizable.","(X,\mathfrak{M},\mu) X X=\bigcup_{i\in I}X_{i} \mu(X_{i})<\infty i \mu(E)=\sum_{i\in I}\mu(E\cap X_i) E E\subseteq X E\cap X_i\in \frak{M} i E\in\frak{M} E\in \frak{M} (X,\frak{M},\mu) \color{blue}{\textbf{can someone tell me that is my solution correct or not?}} \color{green}{\textbf{my solution:}} \color{red}{\textbf{the idea of proof is to prove that:}} \color{red}{\bigg[} \lambda {\frak{B}}_G G \mu \lambda \lambda \color{red}{\bigg]} G (G,{\frak{B}}_G,\mu) {\frak{B}}_G \sigma \lambda {\frak{B}}_G \begin{equation}
    \lambda(E)=
    \begin{cases}
      \underset{i\in I}{\sum}\mu(E\cap X_i) & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)<\infty \\
      \infty & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)=\infty
    \end{cases}
  \end{equation} \color{red}{\textbf{proof that \lambda is a translation invariant measure:}} \{E_j\}_{j\in\mathbb{N}} \underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]<\infty \underset{i\in I}{\sum}\mu(E_j\cap X_i)<\infty j\in\mathbb{N} \lambda\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)=\underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]=\underset{i\in I}{\sum}\mu\bigg[\underset{j\in \mathbb{N}}{\bigcup}\bigg(E_j\bigcap X_i\bigg)\bigg]=\underset{i \in I}{\sum}\underset{j\in \mathbb{N}}{\sum}\mu(E_j\cap X_i)\color{red}=\underset{j\in \mathbb{N}}{\sum}\underset{i\in I}{\sum}\mu(E_j\cap X_i)=\underset{j\in\mathbb{N}}{\sum}\lambda(E_j) \mu X \int_X\underset{j\in\mathbb{N}}{\sum}f_j(x)d\mu=\underset{j\in \mathbb{N}}{\sum}\int_Xf_j(x)d\mu \underset{i\in I}{\sum}\mu\bigg[\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)\bigcap X_i\bigg]=\infty \underset{j\in\mathbb{N}}{\sum}\lambda(E_j)=\infty \lambda\bigg(\underset{j\in\mathbb{N}}{\bigcup}E_j\bigg)=\infty \mu(\phi)=0 \lambda {\frak{B}}_G \lambda \lambda \color{red}{\textbf{proof that \lambda is finite on compact sets:}} K\in {\frak{B}}_G \mu(K)<\infty \underset{i\in I}{\sum}\mu(K\cap X_i)=\mu(K)<\infty \lambda(K)=\underset{i\in I}{\sum}\mu(K\cap X_i)<\infty \lambda \color{red}{\textbf{proof that \lambda is inner regular on sets of finite measure:}} E\in{\frak{B}}_G \lambda(E)<\infty \epsilon>0 \lambda(E)=\underset{i\in I}{\sum}\mu(E\cap X_i) F\subseteq I \underset{i\in I}{\sum}\mu(E\cap X_i)-\frac{\epsilon}{2}<\underset{i\in F}{\sum}\mu(E\cap X_i) \mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]<\mu(E)<\infty K\subseteq \underset{i\in F}{\bigcup}(E\cap X_i)\subseteq E \mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]-\frac{\epsilon}{2}<\mu(K) \lambda(E)-\epsilon=\underset{i\in I}{\sum}\mu(E\cap X_i)-\epsilon<\underset{i\in F}{\sum}\mu(E\cap X_i)-\frac{\epsilon}{2}=\mu\bigg[\underset{i\in F}{\bigcup}(E\cap X_i)\bigg]-\frac{\epsilon}{2}<\mu(K)  \lambda(E)-\epsilon<\mu(K)  K\subseteq E \color{red}{\textbf{proof that \lambda is outer regular}} E\in {\frak{B}}_G \lambda(E)=\infty \lambda E\subseteq G \lambda(G)=\infty G \lambda E\in {\frak{B}}_G \lambda(E)<\infty \epsilon>0 \underset{i\in I}{\sum}\mu(E\cap X_i)=\lambda(E)<\infty \mu(E\cap X_i)=0 i\in \mathbb{N}\subseteq I \lambda(E)=\underset{i\in I}{\sum}\mu(E\cap X_i)=\underset{i\in \mathbb{N}}{\sum}\mu(E\cap X_i)=\mu\bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg] O_1\supseteq \bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg] \mu(O_1)<\mu\bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\epsilon \mu(O_1)<\lambda(E)+\epsilon\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(1) K\subseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg] \mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]<\frac{\epsilon}{2}+\mu(K)\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(2) \{X_i\}_{i \in I} \{gU'_n|g\in C, n\in\mathbb{N}\} H=\underset{n\in \mathbb{N}}{\bigcup}U'_n H G C gH K\subseteq G K\subseteq \underset{g\in C}{\bigcup}gH \{gH|g\in C\} K K g_1,...,g_n K\subseteq \underset{i=1}{\overset{n}{\bigcup}}g_iH K X_i \Bigg(K\subseteq \underset{i\in \mathbb{N'}}{\bigcup}X_i\Bigg) \mathbb{N'} I K\subseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]\bigcap\bigg[\underset{i\in \mathbb{N'}}{\bigcup}X_i\bigg]=\bigg[E\bigcap\bigg(\underset{i\in\mathbb{N''}}{\bigcup}X_i\bigg)\bigg] \mathbb{N''}\subseteq I\setminus\mathbb{N} I \mu(K)\leq\mu\bigg[E\bigcap\bigg(\underset{i\in\mathbb{N''}}{\bigcup}X_i\bigg)\bigg]=\underset{i\in \mathbb{N''}}{\sum}\mu(E\cap X_i)=0 i\in I\setminus\mathbb{N} \mu(E\cap X_i)=0 \mu(K)=0 (2) \mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]<\frac{\epsilon}{2}+\mu(K)=\frac{\epsilon}{2} O_2\supseteq \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg] \mu(O_2)<\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\frac{\epsilon}{2} \mu(O_2)<\mu\bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]+\frac{\epsilon}{2}<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(3) (1) (3) \mu(O_1\cup O_2)\leq\mu(O_1)+\mu(O_2)<[\lambda(E)+\epsilon]+\epsilon=\lambda(E)+2\epsilon E\subseteq \bigg[E\bigcap\bigg(\underset{i\in \mathbb{N}}{\bigcup}X_i\bigg)\bigg]\bigcup \bigg[E\bigcap\bigg(\underset{i\in I\setminus\mathbb{N}}{\bigcup}X_i\bigg)\bigg]\subseteq O_1\cup O_2 \lambda(E)<\infty \mu(O_1\cup O_2)<\infty \infty>\mu(O_1\cup O_2)=\underset{i\in I}{\sum}\mu\bigg[\bigg(O_1\cup O_2\bigg)\cap X_i\bigg] \lambda \lambda(O_1\cup O_2)=\underset{i\in I}{\sum}\mu\bigg[\bigg(O_1\cup O_2\bigg)\cap X_i\bigg]=\mu(O_1\cup O_2)<\lambda(E)+2\epsilon  \lambda(O_1\cup O_2)<\lambda(E)+2\epsilon  E\subseteq O_1\cup O_2 \lambda \color{red}{\textbf{proof that \mu is localizable}} \lambda=\mu \begin{equation}
    \mu(E)=\lambda(E)=
    \begin{cases}
      \underset{i\in I}{\sum}\mu(E\cap X_i) & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)<\infty \\
      \infty & \;\;\;\;\;\;\;\;\;\;\;\underset{i\in I}{\sum}\mu(E\cap X_i)=\infty
    \end{cases}
  \end{equation} \mu(E)=\underset{i\in I}{\sum}\mu(E\cap X_i) E\in {\frak{B}}_G \mu","['measure-theory', 'harmonic-analysis', 'topological-groups', 'locally-compact-groups', 'haar-measure']"
54,Advection reaction equation is solved by projection of solution of continuity equation,Advection reaction equation is solved by projection of solution of continuity equation,,"Suppose an absolutely continuous curve $\mu \colon (0, \infty) \to P_2(\Omega)$ , where $P_2$ is the Wasserstein-2-space , fulfils the continuity equation $$ \label{eq:CE} \tag{CE} \partial_t \mu_t = \text{div}(\mu_t g_{\mathfrak h \mu_t}) $$ for almost all $t > 0$ in the weak sense , where $\Omega := \Theta \times \mathbb R_{\ge 0}$ , $\Theta$ is a compact connected Riemannian manifold without boundary and $$ g_{v} \colon \Omega \to T \Omega, \qquad (r, \theta) \mapsto \begin{pmatrix}             2 \alpha r \cdot J_{v}'(\theta) \\             \beta \cdot \nabla J_{v}'(\theta)         \end{pmatrix} \in \mathbb R \times T_{\theta} \Theta $$ for some fixed $\alpha, \beta > 0$ and $v \in M_+(\Theta)$ is a finite non-negative Radon measure on $\Theta$ and $J_v' \colon \Theta \to \mathbb R$ is differentiable . Show that (this is Proposition 2.1 in Lenaic Chizat 's Sparse optimization on measures with overparametrized gradient descent ) $v_t := \mathfrak h \mu_t$ fufills $$ \label{eq:advec} \tag{$\ddagger$} \partial_t v_t = -4 \alpha v_t J_{v_t}' + \beta \cdot \text{div}(v_t \nabla J_{v_t}') $$ in the weak sense for almost every $t > 0$ , where $\mathfrak h \colon P_2(\Omega) \to M_+(\Theta)$ is defined via $$ \label{eq:h} \tag{$\dagger$} \int_{\Theta} \psi(\theta) \, \text{d}(\mathfrak h \mu)(\theta) = \int_{\Omega} \psi(\theta) r^2 \, \text{d}\mu(\theta, r) \qquad \forall \psi \in \mathcal C(\Theta; \mathbb R). $$ The metric on $\Omega$ is $$ \label{eq:omega} \tag{$\star$} \langle (r_1, \partial \theta_1), (r_2, \partial \theta_2) \rangle_{(r, \theta)} := \frac{1}{\alpha} r_1 r_2 + \frac{r^2}{\beta} \langle \partial \theta_1, \partial \theta_2 \rangle_{\theta} $$ for $x = (r, \theta) \in \Omega$ and $(r_1, \partial \theta_1), (r_2, \partial \theta_2) \in T_x \Omega \cong \mathbb R \times T_{\theta} \Theta$ . My attempts. Let $\xi \colon \Theta \to \mathbb R$ be differentiable . Then for almost all $t > 0$ \begin{align} \frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta) & \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} \frac{\text{d}}{\text{d} t} \int_{\Omega} \xi(\theta) r^2 \, \text{d}\mu_t(\theta, r) \\ & \overset{\eqref{eq:CE}}{=} - \int_{\Omega} \left\langle \begin{pmatrix} \nabla \xi(\theta) \\ 2 r \end{pmatrix}, \begin{pmatrix} \beta \cdot \nabla J_{v_t}'(\theta) \\ 2 \alpha r \cdot J_{v_t}'(\theta) \end{pmatrix} \right\rangle_{(\theta, r)} \, \text{d}\mu_t(\theta, r) \\ &\overset{\eqref{eq:omega}}{=} - \int_{\Omega} \frac{1}{\alpha} (2 r) \cdot 2 \alpha r \cdot J_{v_t}'(\theta) + \frac{r^2}{\beta} \beta \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}\mu_t(\theta, r) \\ & = - \int_{\Omega}  r^2 \cdot \left( 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta}\right) \, \text{d}\mu_t(\theta, r) \\ & \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} - \int_{\Theta} 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}v_t(\theta), \end{align} because the weak formulation of \eqref{eq:CE} is $$ \frac{\text{d}}{\text{d} t} \int_{\Omega} \psi(x) \, \text{d}\mu_t(x) = - \int_{\Omega} \langle \nabla \psi(x), g_{\mathfrak{h} \mu_t}(x) \rangle_{x} \, \text{d}\mu_t(x) $$ for all differentiable maps $\psi \colon \Omega \to \mathbb R$ . But this doesn't look like the weak formulation of \eqref{eq:advec}, which should be something like $$ \frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta) = - \int_{\Theta} 4 \alpha \xi(\theta) J_{v_t}'(\theta) + \beta \langle \nabla \xi(\theta), \nabla J_{v_t}'(\theta) \rangle_{\theta} \, \text{d}v_t(\theta), $$ because the $\alpha$ and $\beta$ are missing. Is my calculation wrong (I am particularly sure about the computation of the gradient of $\xi(\theta) \cdot r^2$ ) or did I compute the weak formulation of \eqref{eq:advec} wrong?","Suppose an absolutely continuous curve , where is the Wasserstein-2-space , fulfils the continuity equation for almost all in the weak sense , where , is a compact connected Riemannian manifold without boundary and for some fixed and is a finite non-negative Radon measure on and is differentiable . Show that (this is Proposition 2.1 in Lenaic Chizat 's Sparse optimization on measures with overparametrized gradient descent ) fufills in the weak sense for almost every , where is defined via The metric on is for and . My attempts. Let be differentiable . Then for almost all because the weak formulation of \eqref{eq:CE} is for all differentiable maps . But this doesn't look like the weak formulation of \eqref{eq:advec}, which should be something like because the and are missing. Is my calculation wrong (I am particularly sure about the computation of the gradient of ) or did I compute the weak formulation of \eqref{eq:advec} wrong?","\mu \colon (0, \infty) \to P_2(\Omega) P_2  \label{eq:CE} \tag{CE}
\partial_t \mu_t = \text{div}(\mu_t g_{\mathfrak h \mu_t})
 t > 0 \Omega := \Theta \times \mathbb R_{\ge 0} \Theta 
g_{v} \colon \Omega \to T \Omega, \qquad (r, \theta)
\mapsto \begin{pmatrix}
            2 \alpha r \cdot J_{v}'(\theta) \\
            \beta \cdot \nabla J_{v}'(\theta)
        \end{pmatrix} \in \mathbb R \times T_{\theta} \Theta
 \alpha, \beta > 0 v \in M_+(\Theta) \Theta J_v' \colon \Theta \to \mathbb R v_t := \mathfrak h \mu_t  \label{eq:advec} \tag{\ddagger}
\partial_t v_t = -4 \alpha v_t J_{v_t}' + \beta \cdot \text{div}(v_t \nabla J_{v_t}')
 t > 0 \mathfrak h \colon P_2(\Omega) \to M_+(\Theta)  \label{eq:h} \tag{\dagger}
\int_{\Theta} \psi(\theta) \, \text{d}(\mathfrak h \mu)(\theta)
= \int_{\Omega} \psi(\theta) r^2 \, \text{d}\mu(\theta, r)
\qquad \forall \psi \in \mathcal C(\Theta; \mathbb R).
 \Omega  \label{eq:omega} \tag{\star}
\langle (r_1, \partial \theta_1), (r_2, \partial \theta_2) \rangle_{(r, \theta)} := \frac{1}{\alpha} r_1 r_2 + \frac{r^2}{\beta} \langle \partial \theta_1, \partial \theta_2 \rangle_{\theta}
 x = (r, \theta) \in \Omega (r_1, \partial \theta_1), (r_2, \partial \theta_2) \in T_x \Omega \cong \mathbb R \times T_{\theta} \Theta \xi \colon \Theta \to \mathbb R t > 0 \begin{align}
\frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta)
& \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} \frac{\text{d}}{\text{d} t} \int_{\Omega} \xi(\theta) r^2 \, \text{d}\mu_t(\theta, r) \\
& \overset{\eqref{eq:CE}}{=} - \int_{\Omega} \left\langle \begin{pmatrix} \nabla \xi(\theta) \\ 2 r \end{pmatrix}, \begin{pmatrix} \beta \cdot \nabla J_{v_t}'(\theta) \\ 2 \alpha r \cdot J_{v_t}'(\theta) \end{pmatrix} \right\rangle_{(\theta, r)} \, \text{d}\mu_t(\theta, r) \\
&\overset{\eqref{eq:omega}}{=} - \int_{\Omega} \frac{1}{\alpha} (2 r) \cdot 2 \alpha r \cdot J_{v_t}'(\theta) + \frac{r^2}{\beta} \beta \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}\mu_t(\theta, r) \\
& = - \int_{\Omega}  r^2 \cdot \left( 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta}\right) \, \text{d}\mu_t(\theta, r) \\
& \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} - \int_{\Theta} 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}v_t(\theta),
\end{align} 
\frac{\text{d}}{\text{d} t} \int_{\Omega} \psi(x) \, \text{d}\mu_t(x)
= - \int_{\Omega} \langle \nabla \psi(x), g_{\mathfrak{h} \mu_t}(x) \rangle_{x} \, \text{d}\mu_t(x)
 \psi \colon \Omega \to \mathbb R 
\frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta)
= - \int_{\Theta} 4 \alpha \xi(\theta) J_{v_t}'(\theta) + \beta \langle \nabla \xi(\theta), \nabla J_{v_t}'(\theta) \rangle_{\theta} \, \text{d}v_t(\theta),
 \alpha \beta \xi(\theta) \cdot r^2","['measure-theory', 'partial-differential-equations', 'gradient-flows', 'transport-equation', 'wasserstein']"
55,How large can the range of Lebesgue densities of a measurable subset of $\mathbb{R}$ be?,How large can the range of Lebesgue densities of a measurable subset of  be?,\mathbb{R},"As mentioned in the bounty, I'm actually looking for a set $E$ such that $d(D)=[0,1]$ .  The original question follows for context. Let $E \subset \mathbb{R}$ be Lebesgue measurable, let $D \subseteq \mathbb{R}$ the set of all points for which the Lebesgue density of $E$ exists, and let $d : D \to [0,1]$ denote the density. Loosely speaking, my question is about how ""large"" $d(D) \subseteq [0,1]$ can be.  Specifically, I'm wondering about the following two questions: Can $d(D)$ be uncountable? Can $d(D)$ have nonempty interior? As long as I haven't made any simple mistakes thinking about the problem, then in higher dimensions, $d$ can be surjective, but the examples I've imagined only work because a line segment in $\mathbb{R}^n$ has measure zero for $n > 1$ (so they have no apparent parallel in $\mathbb{R}$ due to Lebesgue's density theorem). For $\mathbb{R}$ , at this point I've only done the ""trivial"" case, that $d(D)$ can contain any prespecified countable set as a subset, so in particular it can be dense in $[0,1]$ .  I don't even know if I have the tools to answer the questions I'm left with.","As mentioned in the bounty, I'm actually looking for a set such that .  The original question follows for context. Let be Lebesgue measurable, let the set of all points for which the Lebesgue density of exists, and let denote the density. Loosely speaking, my question is about how ""large"" can be.  Specifically, I'm wondering about the following two questions: Can be uncountable? Can have nonempty interior? As long as I haven't made any simple mistakes thinking about the problem, then in higher dimensions, can be surjective, but the examples I've imagined only work because a line segment in has measure zero for (so they have no apparent parallel in due to Lebesgue's density theorem). For , at this point I've only done the ""trivial"" case, that can contain any prespecified countable set as a subset, so in particular it can be dense in .  I don't even know if I have the tools to answer the questions I'm left with.","E d(D)=[0,1] E \subset \mathbb{R} D \subseteq \mathbb{R} E d : D \to [0,1] d(D) \subseteq [0,1] d(D) d(D) d \mathbb{R}^n n > 1 \mathbb{R} \mathbb{R} d(D) [0,1]","['real-analysis', 'measure-theory', 'lebesgue-measure']"
56,Hausdorff dimension of $A \times A$ (Folland's exercise 11.2.15),Hausdorff dimension of  (Folland's exercise 11.2.15),A \times A,"The next question is regarding Hausdorff measure, it was taken from ""Real Analysis"" by Folland (question 11.15). If $A \subset \mathbb{R}^n$ has Hausdorff dimension of $p$ , then $A \times A \subset \mathbb{R}^{2n}$ has Hausdorff dimension $\ge 2p$ . My attempt: We can see that for any $B \subset \mathbb{R}^n$ , $\operatorname{diam}(B \times B) \le \sqrt{2\operatorname{diam}(B)}$ , and if we assume that $H_p(A)< \infty$ , then for any $\delta > 0$ , We can find $\{B_i\}_{i=1}^{\infty} \subset R^n, \operatorname{diam}(B_i) < \delta , A \subset \bigcup_{i=1}^{\infty}{B_i}, s.t$ $$\sum_{i=1}^{\infty}{\operatorname{diam}(B_i)^p} \le H_p(A) < \infty$$ So by choosing $\{ B_i \times B_i \}_{i=1}^{\infty}$ we will get that $\operatorname{diam}(B_i \times B_i) \le \sqrt{2\delta}, A \times A \subset \bigcup_{i=1}^{\infty}{B_i \times B_i}$ $$ \sum_{i=1}^{\infty}{\operatorname{diam}(B_i \times B_i)^{2p}} \le \sum_{i=1}^{\infty}{\sqrt{2\operatorname{diam}(B_i)}^{2p}} = 2\sum_{i=1}^{\infty}{\operatorname{diam}(B_i)^p} \le 2H_p(A) < \infty $$ I believe that from this we can conclude that the dimension of $A \times A \ge 2p$ but I'm not sure why, and there is still the case where $H_p(A) = \infty$ . Thanks.","The next question is regarding Hausdorff measure, it was taken from ""Real Analysis"" by Folland (question 11.15). If has Hausdorff dimension of , then has Hausdorff dimension . My attempt: We can see that for any , , and if we assume that , then for any , We can find So by choosing we will get that I believe that from this we can conclude that the dimension of but I'm not sure why, and there is still the case where . Thanks.","A \subset \mathbb{R}^n p A \times A \subset \mathbb{R}^{2n} \ge 2p B \subset \mathbb{R}^n \operatorname{diam}(B \times B) \le \sqrt{2\operatorname{diam}(B)} H_p(A)< \infty \delta > 0 \{B_i\}_{i=1}^{\infty} \subset R^n, \operatorname{diam}(B_i) < \delta , A \subset \bigcup_{i=1}^{\infty}{B_i}, s.t \sum_{i=1}^{\infty}{\operatorname{diam}(B_i)^p} \le H_p(A) < \infty \{ B_i \times B_i \}_{i=1}^{\infty} \operatorname{diam}(B_i \times B_i) \le \sqrt{2\delta}, A \times A \subset \bigcup_{i=1}^{\infty}{B_i \times B_i}  \sum_{i=1}^{\infty}{\operatorname{diam}(B_i \times B_i)^{2p}} \le \sum_{i=1}^{\infty}{\sqrt{2\operatorname{diam}(B_i)}^{2p}} = 2\sum_{i=1}^{\infty}{\operatorname{diam}(B_i)^p} \le 2H_p(A) < \infty
 A \times A \ge 2p H_p(A) = \infty","['real-analysis', 'measure-theory']"
57,Show that $\displaystyle \lim_{k\rightarrow \infty}f(k^\alpha x) \rightarrow 0$,Show that,\displaystyle \lim_{k\rightarrow \infty}f(k^\alpha x) \rightarrow 0,"Let $f$ be an integrable function over the positive real numbers. Prove that $f(k^\alpha x) \rightarrow 0$ whenever $k \rightarrow \infty$ for almost everywhere $x>0$ and any real number $\alpha>1$ . I have two attempts: (1) Use monotone convergence theorem for series. Since \begin{align*} \int \sum_{k=1}^\infty f(k^\alpha x)=\sum_{k=1}^\infty \int f(k^\alpha x) dx &= \sum_{k=1}^\infty \int \frac{1}{k^\alpha} f(y)dy \\ &=\sum_{k=1}^\infty \frac{1}{k^\alpha}  \int f(y)dy\\ &=\sum_{k=1}^\infty \frac{1}{k^\alpha}||f||_1<\infty  \end{align*} Then we have the integrand $\sum_{k=1}^\infty f(k^\alpha x)<\infty$ for almost everywhere $x>0$ . Thus, the general term $f(k^\alpha x)$ goes to zero for almost everywhere $x>0$ . I think this attempt is valid. (2) However I am trying a second solution: Let $E_n=\mathbb{R}_+ \cap (-n, n)$ which has finite measure (so that I can use the continuity of measure from below and thus Borel-Cantelli lemma). Now consider the following set: $$\{x\in E_n\mid \lim_{k\rightarrow \infty} f(k^\alpha x)=0\},$$ I want to show that for each $k\in \mathbb{N}$ and $\alpha>1$ , the set $$A_{k, \alpha}=\{x\in E_n| |f(k^\alpha x)|> M\}$$ has measure zero on each $E_n$ , where $M$ is any positive real number depends on $k, \alpha$ . Choose $M=\frac{1}{k^{\alpha-2}}$ , then I want to use Markov's inequality to show that \begin{align*} \mu(A_{k, \alpha})=\mu\{x \in E_n| |f(k^\alpha x)|> \frac{1}{k^{\alpha-2}}\}&<k^{\alpha-2}||f||_1 \\ &= k^{\alpha-2} \int \frac{1}{k^{\alpha}} f(y) dy \\ &=\frac{1}{k^2} ||f||_1  \end{align*} Then by Borel-Cantelli lemma, $$\mu(\limsup A_k)=\mu(\bigcap_{N=1}^\infty \bigcup_{k=N}^\infty A_k)=0$$ Can somebody help me to validate this approach?","Let be an integrable function over the positive real numbers. Prove that whenever for almost everywhere and any real number . I have two attempts: (1) Use monotone convergence theorem for series. Since Then we have the integrand for almost everywhere . Thus, the general term goes to zero for almost everywhere . I think this attempt is valid. (2) However I am trying a second solution: Let which has finite measure (so that I can use the continuity of measure from below and thus Borel-Cantelli lemma). Now consider the following set: I want to show that for each and , the set has measure zero on each , where is any positive real number depends on . Choose , then I want to use Markov's inequality to show that Then by Borel-Cantelli lemma, Can somebody help me to validate this approach?","f f(k^\alpha x) \rightarrow 0 k \rightarrow \infty x>0 \alpha>1 \begin{align*}
\int \sum_{k=1}^\infty f(k^\alpha x)=\sum_{k=1}^\infty \int f(k^\alpha x) dx &= \sum_{k=1}^\infty \int \frac{1}{k^\alpha} f(y)dy \\
&=\sum_{k=1}^\infty \frac{1}{k^\alpha}  \int f(y)dy\\
&=\sum_{k=1}^\infty \frac{1}{k^\alpha}||f||_1<\infty 
\end{align*} \sum_{k=1}^\infty f(k^\alpha x)<\infty x>0 f(k^\alpha x) x>0 E_n=\mathbb{R}_+ \cap (-n, n) \{x\in E_n\mid \lim_{k\rightarrow \infty} f(k^\alpha x)=0\}, k\in \mathbb{N} \alpha>1 A_{k, \alpha}=\{x\in E_n| |f(k^\alpha x)|> M\} E_n M k, \alpha M=\frac{1}{k^{\alpha-2}} \begin{align*}
\mu(A_{k, \alpha})=\mu\{x \in E_n| |f(k^\alpha x)|> \frac{1}{k^{\alpha-2}}\}&<k^{\alpha-2}||f||_1 \\
&= k^{\alpha-2} \int \frac{1}{k^{\alpha}} f(y) dy \\
&=\frac{1}{k^2} ||f||_1 
\end{align*} \mu(\limsup A_k)=\mu(\bigcap_{N=1}^\infty \bigcup_{k=N}^\infty A_k)=0","['real-analysis', 'measure-theory', 'solution-verification', 'lebesgue-integral']"
58,"Measurable set in a square, and containing a Cartesian square","Measurable set in a square, and containing a Cartesian square",,"Let $A\subseteq [0,1]^2$ be a measurable subset with full measure, $\mu(A)=1$ . For $X\subseteq [0,1]$ , $D(X)$ denotes the diagonal of $X$ , i.e. $D(X)=\lbrace (x,x) \ | \ x \in X \rbrace$ . Question. Must there always be an $X$ with positive measure such that $(X \times X) \setminus D(X) \subseteq A$ ? My thoughts : if $A_1=(0,\frac{1}{2}) \times (\frac{1}{2},1)$ , $A_2=(\frac{1}{2},1) \times (0,\frac{1}{2})$ and $A=A_1\cup A_2$ , then $A$ has measure $\frac{1}{2}$ , and there is no $X$ containing more than two elements such that $X\times X \setminus D(X) \subseteq A$ . I tried to find similar examples with $\mu(A)\gt \frac{1}{2}$ but failed. This leads me to ask the following : Second question. Let $A$ be as above ( $A\subseteq [0,1]^2$ with $\mu(A)=1$ ). Must there always be an $X$ containing at least three elements such that $(X \times X) \setminus D(X) \subseteq A$ ? Update According to the answer linked in PhoemueX's comment below, the answer to the first question is no if $\mu(A)=1$ is replaced with $\mu(A)=1-\varepsilon$ for any $\varepsilon \gt 0$ . Indeed, this answer produces an $E\subseteq [0,1]^2$ with $\mu(E)=1-\varepsilon$ , such that $E$ contains no ""measurable rectangles"", i.e. $E$ contains no $Y\times Z$ where $Y,Z$ have positive measure. Then we may take $A=E \cup D([0,1])$ .","Let be a measurable subset with full measure, . For , denotes the diagonal of , i.e. . Question. Must there always be an with positive measure such that ? My thoughts : if , and , then has measure , and there is no containing more than two elements such that . I tried to find similar examples with but failed. This leads me to ask the following : Second question. Let be as above ( with ). Must there always be an containing at least three elements such that ? Update According to the answer linked in PhoemueX's comment below, the answer to the first question is no if is replaced with for any . Indeed, this answer produces an with , such that contains no ""measurable rectangles"", i.e. contains no where have positive measure. Then we may take .","A\subseteq [0,1]^2 \mu(A)=1 X\subseteq [0,1] D(X) X D(X)=\lbrace (x,x) \ | \ x \in X \rbrace X (X \times X) \setminus D(X) \subseteq A A_1=(0,\frac{1}{2}) \times (\frac{1}{2},1) A_2=(\frac{1}{2},1) \times (0,\frac{1}{2}) A=A_1\cup A_2 A \frac{1}{2} X X\times X \setminus D(X) \subseteq A \mu(A)\gt \frac{1}{2} A A\subseteq [0,1]^2 \mu(A)=1 X (X \times X) \setminus D(X) \subseteq A \mu(A)=1 \mu(A)=1-\varepsilon \varepsilon \gt 0 E\subseteq [0,1]^2 \mu(E)=1-\varepsilon E E Y\times Z Y,Z A=E \cup D([0,1])","['real-analysis', 'measure-theory', 'lebesgue-measure']"
59,Prove that there do not exist a Lebesgue measurable set with the following property,Prove that there do not exist a Lebesgue measurable set with the following property,,"Prove that there do not exist a Lebesgue measurable set $A$ with the following property: $A\subset \mathbb R$ such that for all $0 < a < 1$ , $m(A\cap [0,a] ) = a/2$ . My attempt is the following and I'm wondering if it makes sense. Assume by contradiction that there exists a Lebesgue measurable set $A\subset\mathbb R$ such that $m(A\cap [0,a])=a/2$ for all $a\in(0,1)$ $(\star)$ . Note that for all $0<a<b<1$ we have that $m(A\cap [0,b])- m(A\cap [0,a])= m(A\cap (a,b))$ . This is because for any two measurable sets $E,F$ we have that $m(E\cup F) -m(E)= m(F)- m(E\cap F)$ . Using the condition $(\star)$ , we have that $$m(A\cap (a,b)) = b/2-a/2= m((a,b))/2.\quad (\bullet)$$ Now, cover the interval $[0,1/2]$ using (almost disjoint) intervals $[1/2-1/3= 1/6,1/2], [1/6-1/4,1/6],\dots$ and denote each by $I_n$ for $n=1,2,\dots$ . These are intervals of length $1/(n+2)$ that only overlap at points which have measure zero. Then, by the additivity of measure we have that $$m(A\cap \cup_n I_n)=\frac{1}{2}\sum_n m(I_n).$$ Note that $\cup_n I_n= (0,1/2]$ and hence the left hand side of the above equation is $$m(A\cap \cup_n I_n)= m(A\cap [0,1/2])= 1/4.$$ Also, note that $m(I_n)= 1/(n+2)$ , and so the right hand side of the equation above is $$\frac{1}{2}\sum_n m(I_n)=\infty$$ being the harmonic sum. Hence, we get a contradiction. Edit : As pointed out in a comment the proof above is wrong. In a comment, it was suggested to use Lebesgue differentiation theorem. Here's the Lebesgue differentiation theorem from Folland: Suppose $f\in L^1_{loc}$ , then for a.e $x$ we have $$\lim_{r\to0}\frac{1}{m(E_r)}\int_{E_r}f(y)dy= f(x)$$ for every family $\{E_r\}_{r>0}$ that shrinks nicely to $x$ . By definition, a family $\{E_r\}_{r>0}$ shrinks nicely to $x$ if $E_r\subset B(r,x)$ and there is a constant $\alpha$ independent of $r$ such that $m(E_r)>\alpha m(B(x,r))$ . Fix an $a\in (0,1)$ . Let $E_r= (a-r/2,a+r/2)$ for $r>0$ , to be a family that shrinks nicely to $a$ . Then, $m(E_r)=r$ . Here, as suggested in the comment, we take $f(y)= \chi_{A\cap [0,a]}(y)$ . Then, the left hand side of the theorem becomes $$\lim_{r\to0}\frac{1}{m(E_r)}\int_{E_r}f(y)dy= \lim_{r\to0}\frac{1}{r}\int_{E_r}\chi_{A\cap [0,a]}(y)dy = \lim_{r\to0}\frac{1}{r}m({A\cap [0,a]\cap E_r}). $$ We note that ${A\cap [0,a]\cap E_r}= A\cap (a-r/2,a+r/2)$ and so $m({A\cap [0,a]\cap E_r})= m((a-r/2,a+r/2))/2= r/2$ (we used the formula $(\bullet)$ derived in the wrong solution section above.) Therefore, the left hand side of the theorem is $1/2$ . The right hand side however is \chi_{A\cap [0,a]}(a)= 1$. Therefore, we get a contradiction.","Prove that there do not exist a Lebesgue measurable set with the following property: such that for all , . My attempt is the following and I'm wondering if it makes sense. Assume by contradiction that there exists a Lebesgue measurable set such that for all . Note that for all we have that . This is because for any two measurable sets we have that . Using the condition , we have that Now, cover the interval using (almost disjoint) intervals and denote each by for . These are intervals of length that only overlap at points which have measure zero. Then, by the additivity of measure we have that Note that and hence the left hand side of the above equation is Also, note that , and so the right hand side of the equation above is being the harmonic sum. Hence, we get a contradiction. Edit : As pointed out in a comment the proof above is wrong. In a comment, it was suggested to use Lebesgue differentiation theorem. Here's the Lebesgue differentiation theorem from Folland: Suppose , then for a.e we have for every family that shrinks nicely to . By definition, a family shrinks nicely to if and there is a constant independent of such that . Fix an . Let for , to be a family that shrinks nicely to . Then, . Here, as suggested in the comment, we take . Then, the left hand side of the theorem becomes We note that and so (we used the formula derived in the wrong solution section above.) Therefore, the left hand side of the theorem is . The right hand side however is \chi_{A\cap [0,a]}(a)= 1$. Therefore, we get a contradiction.","A A\subset \mathbb R 0 < a < 1 m(A\cap [0,a] ) = a/2 A\subset\mathbb R m(A\cap [0,a])=a/2 a\in(0,1) (\star) 0<a<b<1 m(A\cap [0,b])- m(A\cap [0,a])= m(A\cap (a,b)) E,F m(E\cup F) -m(E)= m(F)- m(E\cap F) (\star) m(A\cap (a,b)) = b/2-a/2= m((a,b))/2.\quad (\bullet) [0,1/2] [1/2-1/3= 1/6,1/2], [1/6-1/4,1/6],\dots I_n n=1,2,\dots 1/(n+2) m(A\cap \cup_n I_n)=\frac{1}{2}\sum_n m(I_n). \cup_n I_n= (0,1/2] m(A\cap \cup_n I_n)= m(A\cap [0,1/2])= 1/4. m(I_n)= 1/(n+2) \frac{1}{2}\sum_n m(I_n)=\infty f\in L^1_{loc} x \lim_{r\to0}\frac{1}{m(E_r)}\int_{E_r}f(y)dy= f(x) \{E_r\}_{r>0} x \{E_r\}_{r>0} x E_r\subset B(r,x) \alpha r m(E_r)>\alpha m(B(x,r)) a\in (0,1) E_r= (a-r/2,a+r/2) r>0 a m(E_r)=r f(y)= \chi_{A\cap [0,a]}(y) \lim_{r\to0}\frac{1}{m(E_r)}\int_{E_r}f(y)dy= \lim_{r\to0}\frac{1}{r}\int_{E_r}\chi_{A\cap [0,a]}(y)dy = \lim_{r\to0}\frac{1}{r}m({A\cap [0,a]\cap E_r}).  {A\cap [0,a]\cap E_r}= A\cap (a-r/2,a+r/2) m({A\cap [0,a]\cap E_r})= m((a-r/2,a+r/2))/2= r/2 (\bullet) 1/2","['real-analysis', 'measure-theory', 'solution-verification', 'lebesgue-measure']"
60,Mean value property for harmonic functions,Mean value property for harmonic functions,,"Consider a bounded harmonic function $u:\mathbb{R}^p \to \mathbb{R}$ (i.e. $u$ is a $C^2$ function such that the Laplacian $\Delta u=0$ ). Prove, without using Liouville's theorem, the following version of the mean value property: $$\forall x \in \mathbb{R}^p,\; u(x)=\frac{1}{2^p}\int\limits_{[-1,1]^p}u(y+x)dy$$ How can we prove it?","Consider a bounded harmonic function (i.e. is a function such that the Laplacian ). Prove, without using Liouville's theorem, the following version of the mean value property: How can we prove it?","u:\mathbb{R}^p \to \mathbb{R} u C^2 \Delta u=0 \forall x \in \mathbb{R}^p,\; u(x)=\frac{1}{2^p}\int\limits_{[-1,1]^p}u(y+x)dy","['real-analysis', 'measure-theory', 'lebesgue-integral', 'harmonic-functions']"
61,$\sigma$-ring generated by trace is trace of generated $\sigma$-ring,-ring generated by trace is trace of generated -ring,\sigma \sigma,"Theorem . If $\mathbf{E}$ is any class of sets and if $\mathit{A}$ is any subset of X, then $$\text{S(E)}\space\cap \mathit{A} =\mathbf{S(E}\space\cap\mathit{A}).  $$ Proof . Denote by C the class of all sets of the form B $\cup $ $(C- \mathit{A})$ , where $$B \space \varepsilon\space\mathbf{S(E\space\cap\mathit{A})} \space\text{and}\space C\space\varepsilon\space \mathbf{S(E});$$ it is easy to verify that C is a $\sigma$ -ring. We are using Paul Halmos's Measure Theory as our textbook. One of the proofs provided is incomplete. I don't like learning things without knowing the full proof. Is there full proof that shows why $\mathcal C$ is a $\sigma$ -ring? I know I need to take two sets $G,H$ in $\mathcal C$ and prove that $G-H\in \mathcal C$ But that means I have to show that $(B_G\cup(C_G- A))-(B_H\cup(C_H-A))\in \mathcal C$ , which is just too complicated to me. I am not sure how it is easy to verify.","Theorem . If is any class of sets and if is any subset of X, then Proof . Denote by C the class of all sets of the form B , where it is easy to verify that C is a -ring. We are using Paul Halmos's Measure Theory as our textbook. One of the proofs provided is incomplete. I don't like learning things without knowing the full proof. Is there full proof that shows why is a -ring? I know I need to take two sets in and prove that But that means I have to show that , which is just too complicated to me. I am not sure how it is easy to verify.","\mathbf{E} \mathit{A} \text{S(E)}\space\cap \mathit{A} =\mathbf{S(E}\space\cap\mathit{A}).   \cup  (C- \mathit{A}) B \space \varepsilon\space\mathbf{S(E\space\cap\mathit{A})} \space\text{and}\space C\space\varepsilon\space \mathbf{S(E}); \sigma \mathcal C \sigma G,H \mathcal C G-H\in \mathcal C (B_G\cup(C_G- A))-(B_H\cup(C_H-A))\in \mathcal C","['abstract-algebra', 'measure-theory', 'elementary-set-theory']"
62,Does weak convergence of measures preserve independence of marginals?,Does weak convergence of measures preserve independence of marginals?,,"Let $X^n = (X^n_1, \dots, X^n_d) ~ q^n$ be a $d$ -dimensional random variable, where all the components are independent. That is, $X_i \perp X_j$ for $i\neq j$ , and $$q^n(X) = \prod_{i=1}^d q^n_i(X^n_i).$$ If the sequence of measures $q^n$ converges weakly to some $q^*$ , then are the resulting marginals also independent? I.e., is $$q^*(X)= \prod_{i=1}^d q^*_i?$$ Edit: convergence of marginals/joints Let the state space be $\Omega^d$ , and $\Omega$ be the state space of each component (i.e. $X_i \in \Omega$ for all $i$ ). If $q^n \xrightarrow{w} q$ , then by definition of weak convergence, $$\int f(X) q^n(dX) \rightarrow \int f(X) q(dX) \;\; \text{ for all } f \in C_b(\Omega^d) \;\;\; \text{ as }n\rightarrow \infty.$$ Since we can take $f$ to have any support in $\Omega^d$ , the above convergence of integrals holds for any combination of components; for example if $f$ has support on the first component only, then $$\int_\Omega f(X_1) q^n_1(dX_1) \rightarrow \int_\Omega f(X_1) q(dX_1).$$ I.e. the marginals converge.  This is also true for any joint, e.g. $q^n(X_1,X_2) \xrightarrow{w} q(X_1,X_2)$ . Since $q^n(X_i|X_j)q^n(X_j) = q^n(X_i,X_j)$ , and we know that $q^n(X_i,X_j) \xrightarrow{w} q(X_i,X_j)$ and $q^n(X_i) \xrightarrow{w} q(X_i)$ , then it seems like $q^n(X_1|X_2) \xrightarrow{w} q(X_1|X_2)$ would be true. Here's an attempt: for all $X_2 \in \Omega$ , \begin{align} \int q^n(X_1|X_2)f(X_1) dX_1 &= \int \frac{q^n(X_1,X_2)}{q^n(X_2)}f(X_1)dX_1  \\ &= \frac{1}{q^n(X_2)} \int q^n(X_1,X_2)f(X_1)dX_1  \\ &\rightarrow  \frac{1}{q^n(X_2)} \int q(X_1,X_2)f(X_1)dX_1 \\ &\stackrel{?}{\rightarrow} \frac{1}{q(X_2)} \int q(X_1,X_2)f(X_1)dX_1  \\ &= \int q(X_1|X_2)f(X_1)dX_1  \end{align} I don't think "" $\stackrel{?}{\rightarrow}$ "" is valid under weak convergence since this would require pointwise convergence. Is this where the proof breaks?","Let be a -dimensional random variable, where all the components are independent. That is, for , and If the sequence of measures converges weakly to some , then are the resulting marginals also independent? I.e., is Edit: convergence of marginals/joints Let the state space be , and be the state space of each component (i.e. for all ). If , then by definition of weak convergence, Since we can take to have any support in , the above convergence of integrals holds for any combination of components; for example if has support on the first component only, then I.e. the marginals converge.  This is also true for any joint, e.g. . Since , and we know that and , then it seems like would be true. Here's an attempt: for all , I don't think "" "" is valid under weak convergence since this would require pointwise convergence. Is this where the proof breaks?","X^n = (X^n_1, \dots, X^n_d) ~ q^n d X_i \perp X_j i\neq j q^n(X) = \prod_{i=1}^d q^n_i(X^n_i). q^n q^* q^*(X)= \prod_{i=1}^d q^*_i? \Omega^d \Omega X_i \in \Omega i q^n \xrightarrow{w} q \int f(X) q^n(dX) \rightarrow \int f(X) q(dX) \;\; \text{ for all } f \in C_b(\Omega^d) \;\;\; \text{ as }n\rightarrow \infty. f \Omega^d f \int_\Omega f(X_1) q^n_1(dX_1) \rightarrow \int_\Omega f(X_1) q(dX_1). q^n(X_1,X_2) \xrightarrow{w} q(X_1,X_2) q^n(X_i|X_j)q^n(X_j) = q^n(X_i,X_j) q^n(X_i,X_j) \xrightarrow{w} q(X_i,X_j) q^n(X_i) \xrightarrow{w} q(X_i) q^n(X_1|X_2) \xrightarrow{w} q(X_1|X_2) X_2 \in \Omega \begin{align}
\int q^n(X_1|X_2)f(X_1) dX_1 &= \int \frac{q^n(X_1,X_2)}{q^n(X_2)}f(X_1)dX_1 
\\
&= \frac{1}{q^n(X_2)} \int q^n(X_1,X_2)f(X_1)dX_1 
\\
&\rightarrow  \frac{1}{q^n(X_2)} \int q(X_1,X_2)f(X_1)dX_1
\\
&\stackrel{?}{\rightarrow} \frac{1}{q(X_2)} \int q(X_1,X_2)f(X_1)dX_1 
\\
&= \int q(X_1|X_2)f(X_1)dX_1 
\end{align} \stackrel{?}{\rightarrow}","['measure-theory', 'probability-distributions', 'weak-convergence', 'marginal-distribution']"
63,Are these two definitions of positive measure equivalent?,Are these two definitions of positive measure equivalent?,,"Let's consider the two following definitions of a positive measure : D1 : Let $\mu$ be an application from a $\sigma$ -algebra $T$ to $\overline{\mathbb{R}^+}$ . $\mu$ is called a (positive) measure if and only if : 1) $\mu(\emptyset)=0$ 2)for all countable collections $(A_n)_{n\in\mathbb{N}}$ of pairwise disjoint sets of T , $$\mu(\bigcup_{n \in \mathbb{N}}A_n)=\sum_{n \in \mathbb{N}}\mu(A_n)$$ D2 : Let $\mu$ be an application from a $\sigma$ -algebra $T$ to $\overline{\mathbb{R}^+}$ . $\mu$ is called a (positive) measure if and only if : $\mu(\emptyset)=0$ 2) $\mu$ is additive , which means for all disjoint pairs $A,B$ of T , $\mu(A\cup B)=\mu(A)+\mu(B)$ for all sequence $(A_n)_{n \in \mathbb{N}}$ of $T$ such that $A_{n+1}\subset{A_n} ,\forall n \in \mathbb{N}$ and $\mu(A_0)<\infty$ , we have $$\mu(\bigcap_{n \in \mathbb{N}} A_n)= \lim_{n \to \infty} \mu(A_n)$$ EDIT: I add a 4th condition : 4)for all sequence $(A_n)_{n \in \mathbb{N}}$ of $T$ such that $A_{n}\subset A_{n+1} ,\forall n \in \mathbb{N}$ , we have $$\mu(\bigcup_{n \in \mathbb{N}} A_n)= \lim_{n \to \infty} \mu(A_n)$$ I think it can show that $(D_1)\implies(D_2)$ , but does $(D_2)\implies (D_1)$ holds ? Is there a proof by equivalence ?","Let's consider the two following definitions of a positive measure : D1 : Let be an application from a -algebra to . is called a (positive) measure if and only if : 1) 2)for all countable collections of pairwise disjoint sets of T , D2 : Let be an application from a -algebra to . is called a (positive) measure if and only if : 2) is additive , which means for all disjoint pairs of T , for all sequence of such that and , we have EDIT: I add a 4th condition : 4)for all sequence of such that , we have I think it can show that , but does holds ? Is there a proof by equivalence ?","\mu \sigma T \overline{\mathbb{R}^+} \mu \mu(\emptyset)=0 (A_n)_{n\in\mathbb{N}} \mu(\bigcup_{n \in \mathbb{N}}A_n)=\sum_{n \in \mathbb{N}}\mu(A_n) \mu \sigma T \overline{\mathbb{R}^+} \mu \mu(\emptyset)=0 \mu A,B \mu(A\cup B)=\mu(A)+\mu(B) (A_n)_{n \in \mathbb{N}} T A_{n+1}\subset{A_n} ,\forall n \in \mathbb{N} \mu(A_0)<\infty \mu(\bigcap_{n \in \mathbb{N}} A_n)= \lim_{n \to \infty} \mu(A_n) (A_n)_{n \in \mathbb{N}} T A_{n}\subset A_{n+1} ,\forall n \in \mathbb{N} \mu(\bigcup_{n \in \mathbb{N}} A_n)= \lim_{n \to \infty} \mu(A_n) (D_1)\implies(D_2) (D_2)\implies (D_1)",['measure-theory']
64,Absolute continuity of $g(x) = \int_{-\infty}^{\infty} \frac{\cos(xy^3)}{1+y^2}dy$.,Absolute continuity of .,g(x) = \int_{-\infty}^{\infty} \frac{\cos(xy^3)}{1+y^2}dy,"I'm trying to determine whether the function $$g(x) = \int_{-\infty}^{\infty} \frac{\cos(xy^3)}{1+y^2} dy$$ (a) Is continuous, (b) Is uniformly continuous, (c) Is absolutely continuous, in $(-\infty, \infty)$ . Would $h(x) = \cos(xy^3)$ be absolutely continuous? If so, would it not be enough to write $\cos(xy^3)$ as an indefinite integral since we know that a function is absolutely continuous if and only if it can be written as an indefinite integral? This approach seems to be too easy, which makes me think that there is something that I'm not quite understanding. Any hints would be appreciated.","I'm trying to determine whether the function (a) Is continuous, (b) Is uniformly continuous, (c) Is absolutely continuous, in . Would be absolutely continuous? If so, would it not be enough to write as an indefinite integral since we know that a function is absolutely continuous if and only if it can be written as an indefinite integral? This approach seems to be too easy, which makes me think that there is something that I'm not quite understanding. Any hints would be appreciated.","g(x) = \int_{-\infty}^{\infty} \frac{\cos(xy^3)}{1+y^2} dy (-\infty, \infty) h(x) = \cos(xy^3) \cos(xy^3)","['measure-theory', 'lebesgue-integral', 'absolute-continuity']"
65,Does an integrable function vanish at infinity in a suitable sense?,Does an integrable function vanish at infinity in a suitable sense?,,"I'm searching for a generalization of the following observation: If $f\in L^2(\mathbb R)$ , then \begin{equation}\begin{split}\int_{[-n,\:n+1]}f(x)\:{\rm d}x&=\left\langle1_{[-n,\:n+1]},1_{\mathbb R\setminus[-n,\:n)}g\right\rangle_{L^2(\mathbb R)}\\&\le\left\|f-1_{[-n,\:n)}f\right\|_{L^2(\mathbb R)}\xrightarrow{n\to\infty}0\end{split}\tag1\end{equation} by the Cauchy-Schwarz inequality and Lebesgue's dominated convergence theorem. $(1)$ captures the idea that an integrable function should ""vanish at infinity"" in a suitable sense. Can we generalize this result to $f\in L^p(\mu)$ , where $(E,\mathcal E,\mu)$ is an arbitrary measure space and $p\ge1$ ? Maybe assuming that $\mu(E)=\infty$ and/or that $E$ is a metric/normed space with $\mathcal E=\mathcal B(E)$ ? In the case of a metric/normed space, the intuition tells me that an integrable function should ""essentially be supported in a compact set"". What's obviously true is that $$\forall f\in L^p(\mu):\not\exists B\in\mathcal E:\mu(B)=\infty\text{ and }\inf_{x\in B}|f(x)|>0\tag2.$$","I'm searching for a generalization of the following observation: If , then by the Cauchy-Schwarz inequality and Lebesgue's dominated convergence theorem. captures the idea that an integrable function should ""vanish at infinity"" in a suitable sense. Can we generalize this result to , where is an arbitrary measure space and ? Maybe assuming that and/or that is a metric/normed space with ? In the case of a metric/normed space, the intuition tells me that an integrable function should ""essentially be supported in a compact set"". What's obviously true is that","f\in L^2(\mathbb R) \begin{equation}\begin{split}\int_{[-n,\:n+1]}f(x)\:{\rm d}x&=\left\langle1_{[-n,\:n+1]},1_{\mathbb R\setminus[-n,\:n)}g\right\rangle_{L^2(\mathbb R)}\\&\le\left\|f-1_{[-n,\:n)}f\right\|_{L^2(\mathbb R)}\xrightarrow{n\to\infty}0\end{split}\tag1\end{equation} (1) f\in L^p(\mu) (E,\mathcal E,\mu) p\ge1 \mu(E)=\infty E \mathcal E=\mathcal B(E) \forall f\in L^p(\mu):\not\exists B\in\mathcal E:\mu(B)=\infty\text{ and }\inf_{x\in B}|f(x)|>0\tag2.","['measure-theory', 'lebesgue-integral', 'lp-spaces']"
66,Joint measure and absolute continuity wrt product of marginals,Joint measure and absolute continuity wrt product of marginals,,"I am trying to build intuition over the following matter: let $X,Y$ be two random variables with corresponding probability measures $P_X,P_Y$ . Assume also there exists a joint measure $P_{XY}$ such that for every measurable set $E$ $P_{XY}(\mathcal{X}\times E) = P_Y(E)$ and for every $F$ $P_{XY}(F\times \mathcal{Y}) = P_X(F)$ . My question is: is there a characterisation for when the joint is guaranteed to be absolutely continuous wrt to $P_XP_Y$ ? All the counterexamples I could come up with are somehow dimension-related or ""pathological"", like: let $P_XP_Y$ be the Lebesgue measure over the unit square and $P_{XY}$ the joint induced by $X=Y$ . If we exclude this type of settings, is the constraint of $P_X,P_Y$ being the marginals enough to guarantee absolute continuity? Does anyone have intuition on this problem?","I am trying to build intuition over the following matter: let be two random variables with corresponding probability measures . Assume also there exists a joint measure such that for every measurable set and for every . My question is: is there a characterisation for when the joint is guaranteed to be absolutely continuous wrt to ? All the counterexamples I could come up with are somehow dimension-related or ""pathological"", like: let be the Lebesgue measure over the unit square and the joint induced by . If we exclude this type of settings, is the constraint of being the marginals enough to guarantee absolute continuity? Does anyone have intuition on this problem?","X,Y P_X,P_Y P_{XY} E P_{XY}(\mathcal{X}\times E) = P_Y(E) F P_{XY}(F\times \mathcal{Y}) = P_X(F) P_XP_Y P_XP_Y P_{XY} X=Y P_X,P_Y","['measure-theory', 'random-variables', 'lebesgue-measure', 'radon-nikodym']"
67,A general notion of the support of a measure?,A general notion of the support of a measure?,,"Let $(\Omega, \mathcal A, \mu)$ be a finite measure space. If $\Omega$ is finite and $\mathcal A = 2^\Omega$ , then the support of $\mu$ is $s(\mu) = \{\omega: \mu\{\omega\} > 0\}$ . As far as I know, there isn't a very broad generalization of $s(\mu)$ to uncountable $\Omega$ . The most common approach seems to involve assuming that $\Omega$ comes equipped with a topology $\mathcal T$ that generates $\mathcal A$ . One then defines $$s(\mu) = \{\omega: \omega \in U \in \mathcal T \implies \mu(U) > 0\}.$$ That is, $\omega$ is in the support of $\mu$ if every open set containing $\omega$ has positive $\mu$ -measure. This definition coincides with the one for the finite case when $\mathcal T$ is the discrete topology. It seems to me that it would be nice to have a general notion of support that doesn't rely on $\Omega$ having a topology. Here is an idea I had. Say that a measure $\mu$ on $(\Omega, \mathcal A)$ is discrete if it is of the form $\mu = \sum_{i=1}^n \alpha_i \delta_{\omega_i}$ with $\alpha_i$ positive and $\sum_{i=1}^n\alpha_i = 1$ , and where $\delta_{\omega_i}$ is point mass at $\omega_i$ . The general definition of support that I will propose is motivated by the following interesting fact: Every finitely additive finite measure on $(\Omega, \mathcal A)$ is the pointwise limit of a net of discrete measures. That is, for all $\mu$ there is a net $(\mu_d)$ of discrete measures such that $\mu(A) = \lim_d \mu_d(A)$ for all $A \in \mathcal A$ . Let $\mathcal P$ be the set of all finitely additive measures on $(\Omega, \mathcal A)$ equipped with the topology of pointwise convergence. Now say that $\omega$ is in $s(\mu)$ if and only if every open subset of $\mathcal P$ containing $\mu$ contains a discrete measure $\nu = \sum_{i=1}^n \alpha_i \delta_{\omega_i}$ such that $\omega_i = \omega$ for some $i$ . It's clear that this definition of support generalizes the one given when $\Omega$ is finite. And while it does utilize some topology (on $\mathcal P$ ), it doesn't assume that $\Omega$ is a topological space, and can therefore be applied to any measure space whatsoever (even a finitely additive one). This is open-ended, but my question is basically: Is this a good definition of support? Has it been studied before? Does anyone have any interesting observations or comments about the definition? One potentially interesting observation is that on any space there will always be finitely additive measures $\mu$ with full support , i.e. $s(\mu) = \Omega$ . Proof. Suppose not. Then for every $\mu \in \mathcal P$ there is an open subset $N_\mu$ of $\mathcal P$ and $\omega_\mu \in \Omega$ such that no discrete measure $\nu = \sum_{i=1}^n \alpha_i \delta_{\omega_i}$ in $N_\mu$ is such that $\omega_i = \omega_\mu$ for some $i$ . The collection $\{N_\mu: \mu \in \mathcal P\}$ is an open cover of $\mathcal P$ , and thus for some $n$ and $\mu_1,...,\mu_n$ the collection $\{N_{\mu_i}: 1 \leq i \leq n\}$ covers $\mathcal P$ because $\mathcal P$ is compact ( $\mathcal P$ is a closed subset of $[0,1]^\mathcal A$ with the product topology.) But now for any positive $\alpha_i$ , $1 \leq i \leq n$ , summing to $1$ the discrete measure $\sum_{i=1}^n \alpha_i \delta_{\omega_{\mu_i}}$ is not in any of the $N_{\mu_i}$ , which is a contradiction. This raises the question: Under what conditions can one guarantee that there is a countably additive measure with full support?","Let be a finite measure space. If is finite and , then the support of is . As far as I know, there isn't a very broad generalization of to uncountable . The most common approach seems to involve assuming that comes equipped with a topology that generates . One then defines That is, is in the support of if every open set containing has positive -measure. This definition coincides with the one for the finite case when is the discrete topology. It seems to me that it would be nice to have a general notion of support that doesn't rely on having a topology. Here is an idea I had. Say that a measure on is discrete if it is of the form with positive and , and where is point mass at . The general definition of support that I will propose is motivated by the following interesting fact: Every finitely additive finite measure on is the pointwise limit of a net of discrete measures. That is, for all there is a net of discrete measures such that for all . Let be the set of all finitely additive measures on equipped with the topology of pointwise convergence. Now say that is in if and only if every open subset of containing contains a discrete measure such that for some . It's clear that this definition of support generalizes the one given when is finite. And while it does utilize some topology (on ), it doesn't assume that is a topological space, and can therefore be applied to any measure space whatsoever (even a finitely additive one). This is open-ended, but my question is basically: Is this a good definition of support? Has it been studied before? Does anyone have any interesting observations or comments about the definition? One potentially interesting observation is that on any space there will always be finitely additive measures with full support , i.e. . Proof. Suppose not. Then for every there is an open subset of and such that no discrete measure in is such that for some . The collection is an open cover of , and thus for some and the collection covers because is compact ( is a closed subset of with the product topology.) But now for any positive , , summing to the discrete measure is not in any of the , which is a contradiction. This raises the question: Under what conditions can one guarantee that there is a countably additive measure with full support?","(\Omega, \mathcal A, \mu) \Omega \mathcal A = 2^\Omega \mu s(\mu) = \{\omega: \mu\{\omega\} > 0\} s(\mu) \Omega \Omega \mathcal T \mathcal A s(\mu) = \{\omega: \omega \in U \in \mathcal T \implies \mu(U) > 0\}. \omega \mu \omega \mu \mathcal T \Omega \mu (\Omega, \mathcal A) \mu = \sum_{i=1}^n \alpha_i \delta_{\omega_i} \alpha_i \sum_{i=1}^n\alpha_i = 1 \delta_{\omega_i} \omega_i (\Omega, \mathcal A) \mu (\mu_d) \mu(A) = \lim_d \mu_d(A) A \in \mathcal A \mathcal P (\Omega, \mathcal A) \omega s(\mu) \mathcal P \mu \nu = \sum_{i=1}^n \alpha_i \delta_{\omega_i} \omega_i = \omega i \Omega \mathcal P \Omega \mu s(\mu) = \Omega \mu \in \mathcal P N_\mu \mathcal P \omega_\mu \in \Omega \nu = \sum_{i=1}^n \alpha_i \delta_{\omega_i} N_\mu \omega_i = \omega_\mu i \{N_\mu: \mu \in \mathcal P\} \mathcal P n \mu_1,...,\mu_n \{N_{\mu_i}: 1 \leq i \leq n\} \mathcal P \mathcal P \mathcal P [0,1]^\mathcal A \alpha_i 1 \leq i \leq n 1 \sum_{i=1}^n \alpha_i \delta_{\omega_{\mu_i}} N_{\mu_i}","['measure-theory', 'reference-request']"
68,Real-Valued Measurable Cardinals and Powerset Algebras,Real-Valued Measurable Cardinals and Powerset Algebras,,"I realized the only example of a nonmeasurable set I had seen (a vitali set) crucially relies on the translation invariance of the lebesgue measure. I looked around for other examples of nonmeasurable sets, and struggled to find any. This led me to ask if there are measures which can be defined on the entire powerset algebra. A moment's thought shows the dirac measure works, and indeed you can take the measure $\sum_{r_i \in \mathbb{Q}} 2^{-i} \delta_{r_i}$ to make this example slightly less trivial... But what about nonatomic measures? I'm casually acquainted with set theory, and I thought this might depend on your choice of foundations. So I asked a set theorist friend of mine, and he pointed me towards ""real-valued measurable cardinals"". The wikipedia page says ""A real valued measurable cardinal less than or equal to $\mathfrak{c}$ exists if and only if there is a countably additive extension of the lebesgue measure to all sets of real numbers if and only if there is an atomless probability measure on the power set of some nonempty set"" Where can I find a reference for this equivalence? Or, if it isn't hard, can someone post a proof here? I am comfortable with Set Theory at the level of Kunen's ""easy consistency proofs"". In particular, while I know the idea of forcing, I've never worked with it in practice. Thanks in advance ^_^","I realized the only example of a nonmeasurable set I had seen (a vitali set) crucially relies on the translation invariance of the lebesgue measure. I looked around for other examples of nonmeasurable sets, and struggled to find any. This led me to ask if there are measures which can be defined on the entire powerset algebra. A moment's thought shows the dirac measure works, and indeed you can take the measure to make this example slightly less trivial... But what about nonatomic measures? I'm casually acquainted with set theory, and I thought this might depend on your choice of foundations. So I asked a set theorist friend of mine, and he pointed me towards ""real-valued measurable cardinals"". The wikipedia page says ""A real valued measurable cardinal less than or equal to exists if and only if there is a countably additive extension of the lebesgue measure to all sets of real numbers if and only if there is an atomless probability measure on the power set of some nonempty set"" Where can I find a reference for this equivalence? Or, if it isn't hard, can someone post a proof here? I am comfortable with Set Theory at the level of Kunen's ""easy consistency proofs"". In particular, while I know the idea of forcing, I've never worked with it in practice. Thanks in advance ^_^",\sum_{r_i \in \mathbb{Q}} 2^{-i} \delta_{r_i} \mathfrak{c},"['measure-theory', 'logic', 'set-theory', 'lebesgue-measure', 'descriptive-set-theory']"
69,Continuity of the Lebesgue measure w.r.t the Hausdorff metric,Continuity of the Lebesgue measure w.r.t the Hausdorff metric,,"I have a question linked to Interplay of Hausdorff metric and Lebesgue measure . Let us denote as $\mathcal K(\mathbb{R}^n)$ the space of compact subsets of $\mathbb R^n$ endowed with the Hausdorff metric $\rho$ and let $\lambda$ be the $n$ -dimensional Lebesgue measure on $\mathbb R^n$ . I want to know if there are (sufficient) conditions under which the measure $\lambda$ is continuous w.r.t. $\rho$ , that is $$ \lim_{k\rightarrow\infty}\rho(K, K_k)=0\qquad\Rightarrow\qquad \lim_{k\rightarrow\infty}\lambda(K_k)=\lambda(K). $$ I tried to search it in the books Fractal geometry by Kenneth Falconer and Functions of Bounded Variation and Free Discontinuity Problems by Ambrosio, Fusco and Pallara but I did not find anything. In the second book it is written that, in the case $n=2$ , the Hausdorff measure (which is a rescaling of the usual $\lambda$ on $\mathbb R^n$ ) is lower-semicontinuous w.r.t. the Hausdorff metric along sequences satisfying a suitable uniform concentration property, but this is not what I am looking for. Some help? Do you have some references?","I have a question linked to Interplay of Hausdorff metric and Lebesgue measure . Let us denote as the space of compact subsets of endowed with the Hausdorff metric and let be the -dimensional Lebesgue measure on . I want to know if there are (sufficient) conditions under which the measure is continuous w.r.t. , that is I tried to search it in the books Fractal geometry by Kenneth Falconer and Functions of Bounded Variation and Free Discontinuity Problems by Ambrosio, Fusco and Pallara but I did not find anything. In the second book it is written that, in the case , the Hausdorff measure (which is a rescaling of the usual on ) is lower-semicontinuous w.r.t. the Hausdorff metric along sequences satisfying a suitable uniform concentration property, but this is not what I am looking for. Some help? Do you have some references?","\mathcal K(\mathbb{R}^n) \mathbb R^n \rho \lambda n \mathbb R^n \lambda \rho 
\lim_{k\rightarrow\infty}\rho(K, K_k)=0\qquad\Rightarrow\qquad \lim_{k\rightarrow\infty}\lambda(K_k)=\lambda(K).
 n=2 \lambda \mathbb R^n","['measure-theory', 'continuity', 'lebesgue-measure', 'hausdorff-measure', 'hausdorff-distance']"
70,"$L_p(X)$ separable if $(X,\mu)$ is separable measure space.",separable if  is separable measure space.,"L_p(X) (X,\mu)","A measure space $(X,\mu)$ is separable if there is a countable family of measurable subsets $\{E_k \}_{k=1}^\infty $ so that if $E$ is any measurable set of finite measure , then $$\mu(E \triangle E_{n_k}) \to 0 \,\,\,\,\,\,\,as \,k\to0$$ for an appropriate subsequence $\{n_k \}$ which depends on $E$ . Prove that if the measure space $X$ is separable, then $L_{p}$ is separable when $1 ≤ p < ∞$ . I try to prove it like this: We have for every measurable set $E$ with finite measure associated measurable set $E_{nk}$ s.t. $\mu(E \triangle E_{n_k})<\epsilon$ . CLAIM: The collection $$ F:= \{\sum_{i=1}^Nr\chi_{E_{n_{i}} }\}\,\,\,\,\,\,\, r\in Q  $$ is countable dense in $L^p$ . Since simple functions are dense in $L^p$ given $f \in L^p$ , Let $\epsilon >0$ and choose $\phi$ such that $\|\phi-f\|_{L^p} < \frac{\epsilon}{2}$ . Now, let $$\phi = \sum_{i=1}^{N} c_i \chi_{E_i}$$ with $E_i$ pairwise disjoint meaurable with finite measure. Let $\psi \in F$ with $$\psi = \sum_{i=1}^{N} r_i \chi_{E_{n_i}}$$ be such that $\mu(E_n \triangle E_{n_i})  < {\epsilon^p}$ with the $E_{n_i}$ pairwise disjoint. Then, \begin{eqnarray*} \left( \int_\mathbb{X} |\phi-\psi|^p \, d\mu \right)^\frac{1}{p} &\leq& \left( \int_\mathbb{X} \left(\sum_{i=1}^{N}|c_i\chi_{E_i}-r_i\chi_{E_{n_i}}| \right)^p \, d\mu  \right)^\frac{1}{p} \\ & \stackrel{Minkowski}{\leq}& \sum_{i=1}^{N} \left( \int_\mathbb{X} |c_i\chi_{E_i}-r_i\chi_{E_{n_i}}|^p \, d\mu \right)^\frac{1}{p} \\ \end{eqnarray*} I got stuck..!! I try to connect the last above inequality with symmetric difference between $E_n$ and $E_{n_i}$ but I have difficulties in that because of existences of $r_i$ and $c_i$ . I need help to complete the proof. Thanks.","A measure space is separable if there is a countable family of measurable subsets so that if is any measurable set of finite measure , then for an appropriate subsequence which depends on . Prove that if the measure space is separable, then is separable when . I try to prove it like this: We have for every measurable set with finite measure associated measurable set s.t. . CLAIM: The collection is countable dense in . Since simple functions are dense in given , Let and choose such that . Now, let with pairwise disjoint meaurable with finite measure. Let with be such that with the pairwise disjoint. Then, I got stuck..!! I try to connect the last above inequality with symmetric difference between and but I have difficulties in that because of existences of and . I need help to complete the proof. Thanks.","(X,\mu) \{E_k \}_{k=1}^\infty  E \mu(E \triangle E_{n_k}) \to 0 \,\,\,\,\,\,\,as \,k\to0 \{n_k \} E X L_{p} 1 ≤ p < ∞ E E_{nk} \mu(E \triangle E_{n_k})<\epsilon  F:= \{\sum_{i=1}^Nr\chi_{E_{n_{i}}
}\}\,\,\,\,\,\,\, r\in Q   L^p L^p f \in L^p \epsilon >0 \phi \|\phi-f\|_{L^p} < \frac{\epsilon}{2} \phi = \sum_{i=1}^{N} c_i \chi_{E_i} E_i \psi \in F \psi = \sum_{i=1}^{N} r_i \chi_{E_{n_i}} \mu(E_n \triangle E_{n_i})  < {\epsilon^p} E_{n_i} \begin{eqnarray*}
\left( \int_\mathbb{X} |\phi-\psi|^p \, d\mu \right)^\frac{1}{p} &\leq& \left( \int_\mathbb{X} \left(\sum_{i=1}^{N}|c_i\chi_{E_i}-r_i\chi_{E_{n_i}}| \right)^p \, d\mu  \right)^\frac{1}{p} \\
& \stackrel{Minkowski}{\leq}& \sum_{i=1}^{N} \left( \int_\mathbb{X} |c_i\chi_{E_i}-r_i\chi_{E_{n_i}}|^p \, d\mu \right)^\frac{1}{p} \\
\end{eqnarray*} E_n E_{n_i} r_i c_i","['measure-theory', 'lebesgue-measure']"
71,Is the square of a measure a measure?,Is the square of a measure a measure?,,"Conside $(X, \Gamma, \mu)$ to be a measure space. Define $\nu(A) = \mu(A)^2$ for any $A \in \Gamma$ , where $\Gamma$ is a topology. Is this $\nu$ a measure on $(X, \Gamma)$ ? This is what I've done: For $\nu$ to be a measure, we need $\nu(E)=\nu(E \cap A) + \nu(E \cap A^c)$ . However, $\nu(E) = \mu(E)^2 = (\mu(E \cap A) + \mu(E \cap A^c))^2 = \mu(E \cap A)^2 + 2\mu(E \cap A)\mu(E \cap A^c) + \mu(E \cap A^c)^2$ which is not $\nu(E \cap A) + \nu(E \cap A^c)$ unless $\mu(E)=0$ $\forall E \in X$ . Does this seem correct or am I completely on the wrong track? Thanks!","Conside to be a measure space. Define for any , where is a topology. Is this a measure on ? This is what I've done: For to be a measure, we need . However, which is not unless . Does this seem correct or am I completely on the wrong track? Thanks!","(X, \Gamma, \mu) \nu(A) = \mu(A)^2 A \in \Gamma \Gamma \nu (X, \Gamma) \nu \nu(E)=\nu(E \cap A) + \nu(E \cap A^c) \nu(E) = \mu(E)^2 = (\mu(E \cap A) + \mu(E \cap A^c))^2 = \mu(E \cap A)^2 + 2\mu(E \cap A)\mu(E \cap A^c) + \mu(E \cap A^c)^2 \nu(E \cap A) + \nu(E \cap A^c) \mu(E)=0 \forall E \in X","['measure-theory', 'lebesgue-measure', 'solution-verification']"
72,Another equivalent notion of ergodicity,Another equivalent notion of ergodicity,,"Let $T\colon X\to X$ be a measure preserving transformation on a probability space $(X,\mu)$ . We say that $T$ is ergodic if $A$ is measurable and $T^{-1}(A)=A$ implies that $\mu(A)\in\{0,1\}$ . I have seen that the following are equivalent: $T$ is ergodic, If $B$ is measurable and $\mu(T^{-1}(B)\Delta B)=0$ , then $\mu(B)\in\{0,1\}$ . (Here $\Delta$ stands for the symmetric difference.) However, I was reasoning as follows. If $C$ is measurable and $C\subset T^{-1}(C)$ , then $$\mu(T^{-1}(C)\Delta C)=\mu(T^{-1}(C)\setminus C)+\mu(C\setminus T^{-1}(C))=\mu(T^{-1}(C)\setminus C)\\ =\mu(T^{-1}(C))-\mu(C)=\mu(C)-\mu(C)=0.$$ So I concluded that there was another characterization of ergodicity, namely: If $C$ is measurable and $C\subset T^{-1}(C)$ , then $\mu(C)\in\{0,1\}$ . Note that it is clearly indeed also true that 3 implies 1. But I find this characterization really counterintuitive, especially since I do not encounter this definition in the literature. I think it is a nice characterization for the following reason: Suppose $T$ is ergodic and we want to show that a measurable set $C$ has either measure $0$ or $1$ . Then, by 3, it suffices to prove that $C\subset T^{-1}(C)$ . The reverse inclusion does not even have to hold! So my questions are: Is my reasoning correct, that is, is $3$ indeed equivalent to ergodicity? Why does most literature ( atleast the literature I found ) choose not to mention anything about 3?","Let be a measure preserving transformation on a probability space . We say that is ergodic if is measurable and implies that . I have seen that the following are equivalent: is ergodic, If is measurable and , then . (Here stands for the symmetric difference.) However, I was reasoning as follows. If is measurable and , then So I concluded that there was another characterization of ergodicity, namely: If is measurable and , then . Note that it is clearly indeed also true that 3 implies 1. But I find this characterization really counterintuitive, especially since I do not encounter this definition in the literature. I think it is a nice characterization for the following reason: Suppose is ergodic and we want to show that a measurable set has either measure or . Then, by 3, it suffices to prove that . The reverse inclusion does not even have to hold! So my questions are: Is my reasoning correct, that is, is indeed equivalent to ergodicity? Why does most literature ( atleast the literature I found ) choose not to mention anything about 3?","T\colon X\to X (X,\mu) T A T^{-1}(A)=A \mu(A)\in\{0,1\} T B \mu(T^{-1}(B)\Delta B)=0 \mu(B)\in\{0,1\} \Delta C C\subset T^{-1}(C) \mu(T^{-1}(C)\Delta C)=\mu(T^{-1}(C)\setminus C)+\mu(C\setminus T^{-1}(C))=\mu(T^{-1}(C)\setminus C)\\ =\mu(T^{-1}(C))-\mu(C)=\mu(C)-\mu(C)=0. C C\subset T^{-1}(C) \mu(C)\in\{0,1\} T C 0 1 C\subset T^{-1}(C) 3","['measure-theory', 'reference-request', 'ergodic-theory']"
73,Totally Cool Proof of Sierpinski's Theorem?,Totally Cool Proof of Sierpinski's Theorem?,,"Talking about Theorem. If $\mu$ is a non-atomic measure on $X$ and $0<t<\mu(X)$ then there exists $E$ with $\mu(E)=t$ . The proofs I see all use Zorn's lemma or transfinite recursion. Don't get me wrong, I think the proof by transfinite recursion is simple, natural and elegant: We try to construct $E$ as a union of sets with small measure. After we have $\omega$ of them it may be that the measure of the union is still less than $t$ , so we just go ahead and ""define"" $E_\alpha$ for countable ordinals $\alpha$ , and for some countable $\alpha$ we must have $\mu\left(\bigcup_{\beta<\alpha}E_\beta\right)=t$ . (One could easily convert that to a proof by Zorn's lemma that seems simpler and more natural than the Zorn proofs I've seen: Consider a maximal collection $(E_\alpha)$ of disjoint sets of positive measure with $\sum\mu(E_\alpha)\le t$ ...) So that's nice and ""intuitive"", but it seems like there ""should"" be a more elementary argument. There is a proof using nothing but epsilons and deltas, although it's a little bit complicated. (I kinda like the proof of the Main Lemma there; it's clear  that the ML is something tending in the direction of the theorem, and indeed the proof of the theorem from ML is straightforward.) Anyway, my question is whether anyone sees how to make the following proof work: Totally Cool Proof. Let $A$ be the ""measure algebra"", that is, the space of equivalence classes of measurable sets modulo null sets. Define a metric on $A$ by $d(E,F)=\mu(E\Delta F)=||\chi_E-\chi_F||_1$ (say we're in the case $\mu(X)<\infty$ .) Then $(A,d)$ is connected (because why? ), hence $\mu(A)$ is connected. Note I tend to believe that $(A,d)$ is in fact path-connected, because it seems to me that a limit of successive refinements of the chain obtained in proof of the $\frac12$ theorem at that link should give a path. But no points for working that out; what I'm wondering about is a totally trivial proof that there are no non--trivial clopen sets...","Talking about Theorem. If is a non-atomic measure on and then there exists with . The proofs I see all use Zorn's lemma or transfinite recursion. Don't get me wrong, I think the proof by transfinite recursion is simple, natural and elegant: We try to construct as a union of sets with small measure. After we have of them it may be that the measure of the union is still less than , so we just go ahead and ""define"" for countable ordinals , and for some countable we must have . (One could easily convert that to a proof by Zorn's lemma that seems simpler and more natural than the Zorn proofs I've seen: Consider a maximal collection of disjoint sets of positive measure with ...) So that's nice and ""intuitive"", but it seems like there ""should"" be a more elementary argument. There is a proof using nothing but epsilons and deltas, although it's a little bit complicated. (I kinda like the proof of the Main Lemma there; it's clear  that the ML is something tending in the direction of the theorem, and indeed the proof of the theorem from ML is straightforward.) Anyway, my question is whether anyone sees how to make the following proof work: Totally Cool Proof. Let be the ""measure algebra"", that is, the space of equivalence classes of measurable sets modulo null sets. Define a metric on by (say we're in the case .) Then is connected (because why? ), hence is connected. Note I tend to believe that is in fact path-connected, because it seems to me that a limit of successive refinements of the chain obtained in proof of the theorem at that link should give a path. But no points for working that out; what I'm wondering about is a totally trivial proof that there are no non--trivial clopen sets...","\mu X 0<t<\mu(X) E \mu(E)=t E \omega t E_\alpha \alpha \alpha \mu\left(\bigcup_{\beta<\alpha}E_\beta\right)=t (E_\alpha) \sum\mu(E_\alpha)\le t A A d(E,F)=\mu(E\Delta F)=||\chi_E-\chi_F||_1 \mu(X)<\infty (A,d) \mu(A) (A,d) \frac12",['measure-theory']
74,Definition of surface measure and integration on submanifolds?,Definition of surface measure and integration on submanifolds?,,"I'm reading some lecture notes of Terence Tao and at one point he says Of course we give $S^{n-1}$ the usual surface measure $d\sigma$ . though I couldn't find a definition of ""the surface measure"", just a Wikipedia article about surface area . However, I remember that in our Calc III course we introduced integration on submanifolds of $\mathbb R^n$ using the Gramian matrix and I wonder whether I can obtain the surface measure from that framework? In particular, I'm wondering whether the surface measure for some $k$ -dimensional submanifold $M$ of $\mathbb R^n$ with parameterization $\varphi\colon U\subseteq\mathbb R^k\to M$ is given by $$\sigma\colon\mathcal B^n\cap M\to[0,\infty],A\mapsto\int_AdS:=\int_{\varphi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x),$$ where $\lambda^k$ is the Lebesgue-Borel measure on $\mathbb R^k$ . References regarding this topic are also welcome. Comment to Boris Bilich's answer: (I'm appending this to my question instead of commenting under Boris Bilich's answer, because this comment is rather heavy on formulas). Even though your answer was actually helpful for me in that it helped me find a decent derivation of the surface measure, I think your statement about the integral being dependent on the choice of the parameterization is wrong, because I remember proving the contrary in Calc III. Consider the map $\psi(x):=\varphi(\lambda x),\lambda\neq0$ from your answer, where $\varphi$ is the parameterization from my question above. For $A=\varphi(B)=\psi(\frac1\lambda B)$ we have $\varphi^{-1}(A)=B=\lambda\psi^{-1}(A)$ and $$ D\psi(x) =D(\varphi\circ\lambda)(x) =D\varphi(\lambda x)\circ D\lambda(x) =\lambda D\varphi(\lambda x). $$ I think you already see, where this is going. Using the transformation theorem the $\lambda$ in the argument of the derivative will cancel the $\lambda$ outside the derivative: $$ \begin{align*} &\int_{\psi^{-1}(A)}\sqrt{\det D\psi(x)^TD\psi(x)}d\lambda^k(x) \\ &=\int_{\psi^{-1}(A)}\sqrt{\det\lambda^2D\varphi(\lambda x)^TD\varphi(\lambda x)}d\lambda^k(x) \\ &=\int_{\psi^{-1}(A)}\sqrt{\det D\varphi(\lambda x)^TD\varphi(\lambda x)}\cdot\underbrace{|\det D\lambda(x)|}_{=|\lambda|^k}d\lambda^k(x) \\ &=\int_{\lambda\psi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x) \\ &=\int_{\varphi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x) \end{align*} $$","I'm reading some lecture notes of Terence Tao and at one point he says Of course we give the usual surface measure . though I couldn't find a definition of ""the surface measure"", just a Wikipedia article about surface area . However, I remember that in our Calc III course we introduced integration on submanifolds of using the Gramian matrix and I wonder whether I can obtain the surface measure from that framework? In particular, I'm wondering whether the surface measure for some -dimensional submanifold of with parameterization is given by where is the Lebesgue-Borel measure on . References regarding this topic are also welcome. Comment to Boris Bilich's answer: (I'm appending this to my question instead of commenting under Boris Bilich's answer, because this comment is rather heavy on formulas). Even though your answer was actually helpful for me in that it helped me find a decent derivation of the surface measure, I think your statement about the integral being dependent on the choice of the parameterization is wrong, because I remember proving the contrary in Calc III. Consider the map from your answer, where is the parameterization from my question above. For we have and I think you already see, where this is going. Using the transformation theorem the in the argument of the derivative will cancel the outside the derivative:","S^{n-1} d\sigma \mathbb R^n k M \mathbb R^n \varphi\colon U\subseteq\mathbb R^k\to M \sigma\colon\mathcal B^n\cap M\to[0,\infty],A\mapsto\int_AdS:=\int_{\varphi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x), \lambda^k \mathbb R^k \psi(x):=\varphi(\lambda x),\lambda\neq0 \varphi A=\varphi(B)=\psi(\frac1\lambda B) \varphi^{-1}(A)=B=\lambda\psi^{-1}(A) 
D\psi(x)
=D(\varphi\circ\lambda)(x)
=D\varphi(\lambda x)\circ D\lambda(x)
=\lambda D\varphi(\lambda x).
 \lambda \lambda 
\begin{align*}
&\int_{\psi^{-1}(A)}\sqrt{\det D\psi(x)^TD\psi(x)}d\lambda^k(x) \\
&=\int_{\psi^{-1}(A)}\sqrt{\det\lambda^2D\varphi(\lambda x)^TD\varphi(\lambda x)}d\lambda^k(x) \\
&=\int_{\psi^{-1}(A)}\sqrt{\det D\varphi(\lambda x)^TD\varphi(\lambda x)}\cdot\underbrace{|\det D\lambda(x)|}_{=|\lambda|^k}d\lambda^k(x) \\
&=\int_{\lambda\psi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x) \\
&=\int_{\varphi^{-1}(A)}\sqrt{\det D\varphi(x)^TD\varphi(x)}d\lambda^k(x)
\end{align*}
","['measure-theory', 'surfaces']"
75,Is it true that the Haar covering numbers $(f:\varphi)$ converges to $\int_Gf\operatorname{d}\mu$ for $\varphi\to\delta$?,Is it true that the Haar covering numbers  converges to  for ?,(f:\varphi) \int_Gf\operatorname{d}\mu \varphi\to\delta,"Let $(G,\cdot,\tau)$ be a topological group whose topology is Hausdorff and locally compact and whose identity is $e.$ Denote by $\mathcal{B}_\tau$ the family of Borel subsets of $(G,\cdot,\tau)$ , i.e. the $\sigma$ -algebra of subsets of $G$ generated by $\tau$ . Let $\mu:\mathcal{B}_\tau\to[0,+\infty]$ be a left-Haar measure of $(G,\cdot,\tau)$ , i.e. a non-null left-translation-invariant Radon-measure (outer regular on the elements of $\mathcal{B_\tau}$ and inner regular on the elements of $\tau$ ) defined on $\mathcal{B}_\tau$ . Denote by $\mathcal{I}$ the family of neighborhoods of $e$ in $(G,\cdot,\tau)$ with its natural partial order (i.e. $V\le U$ iff $U\subset V$ ), that makes it a directed family. Denote by $C^+_c(G)$ the family of non-null, non-negative, continuous functions of compact support of $(G,\cdot,\tau)$ . We will say that a net $\varphi: \mathcal{I}\to C^+_c(G)$ converges to $\delta$ in $(G,\cdot,\tau,\mu)$ if: $\forall V\in\mathcal{I}, \operatorname{supp}(\varphi)\subset V$ ; $\forall V\in\mathcal{I}, \int_G\varphi\operatorname{d}\mu=1.$ If $f,\varphi\in C^+_c(G)$ define: $$A_{f,\varphi}:=\left\{\alpha>0 : \exists n\in\mathbb{N}, \exists c_1,...,c_n>0, \exists g_1,...,g_n\in G, \left(f\le\sum_{k=1}^nc_k\tau_{g_k}\varphi\right)\land\left(\alpha=\sum_{k=1}^nc_k\right)\right\}$$ where $\tau_h(\varphi)(g):=\varphi(h^{-1}g)$ and define the Haar covering number by: $$(f:\varphi):=\inf(A_{f,\varphi}).$$ If $\varphi :\mathcal{I}\to C^+_c(G)$ is a net converging to $\delta$ in $(G,\cdot,\tau,\mu)$ , is it true that the net $\left((f:\varphi_V)\right)_{V\in\mathcal{I}}$ converges to $\int_G f\operatorname{d}\mu?$ Since $$\forall f,\varphi\in C^+_c(G), \int_G f\operatorname{d}\mu\le(f:\varphi)\int_G \varphi\operatorname{d}\mu,$$ it is clear that, if the net converges at all, then the limit is greater or equal than $\int_G f\operatorname{d}\mu$ . However, I strongly believe that (since the support of $\varphi_V$ gets smaller and smaller as the net index $V$ shrinks to $\{e\}$ ) the quantity $(f:\varphi_V)$ should be a good approximation of $\int_G f\operatorname{d}\mu$ if $V$ is small enough, so that equality should hold, but I can't prove rigorously this claim. Any help?","Let be a topological group whose topology is Hausdorff and locally compact and whose identity is Denote by the family of Borel subsets of , i.e. the -algebra of subsets of generated by . Let be a left-Haar measure of , i.e. a non-null left-translation-invariant Radon-measure (outer regular on the elements of and inner regular on the elements of ) defined on . Denote by the family of neighborhoods of in with its natural partial order (i.e. iff ), that makes it a directed family. Denote by the family of non-null, non-negative, continuous functions of compact support of . We will say that a net converges to in if: ; If define: where and define the Haar covering number by: If is a net converging to in , is it true that the net converges to Since it is clear that, if the net converges at all, then the limit is greater or equal than . However, I strongly believe that (since the support of gets smaller and smaller as the net index shrinks to ) the quantity should be a good approximation of if is small enough, so that equality should hold, but I can't prove rigorously this claim. Any help?","(G,\cdot,\tau) e. \mathcal{B}_\tau (G,\cdot,\tau) \sigma G \tau \mu:\mathcal{B}_\tau\to[0,+\infty] (G,\cdot,\tau) \mathcal{B_\tau} \tau \mathcal{B}_\tau \mathcal{I} e (G,\cdot,\tau) V\le U U\subset V C^+_c(G) (G,\cdot,\tau) \varphi: \mathcal{I}\to C^+_c(G) \delta (G,\cdot,\tau,\mu) \forall V\in\mathcal{I}, \operatorname{supp}(\varphi)\subset V \forall V\in\mathcal{I}, \int_G\varphi\operatorname{d}\mu=1. f,\varphi\in C^+_c(G) A_{f,\varphi}:=\left\{\alpha>0 : \exists n\in\mathbb{N}, \exists c_1,...,c_n>0, \exists g_1,...,g_n\in G, \left(f\le\sum_{k=1}^nc_k\tau_{g_k}\varphi\right)\land\left(\alpha=\sum_{k=1}^nc_k\right)\right\} \tau_h(\varphi)(g):=\varphi(h^{-1}g) (f:\varphi):=\inf(A_{f,\varphi}). \varphi :\mathcal{I}\to C^+_c(G) \delta (G,\cdot,\tau,\mu) \left((f:\varphi_V)\right)_{V\in\mathcal{I}} \int_G f\operatorname{d}\mu? \forall f,\varphi\in C^+_c(G), \int_G f\operatorname{d}\mu\le(f:\varphi)\int_G \varphi\operatorname{d}\mu, \int_G f\operatorname{d}\mu \varphi_V V \{e\} (f:\varphi_V) \int_G f\operatorname{d}\mu V","['measure-theory', 'locally-compact-groups', 'haar-measure']"
76,Measurability of maximal functions,Measurability of maximal functions,,"I have been reading Fourier Analysis by J. Duoandikoetxea. I got stuck on proving the measurability of maximal functions. The general maximal function/operator in this book is from the following proposition: The theorem as it is stated is, in my opinion, simply false; I don't see how $T^*f$ is measurable. (PS. The definition is that $T_t$ and $T^*$ should map $L^p$ functions to measurable functions $X\to\mathbb{C}$ .) Incidentally: Well, the proof of this particular theorem carries over verbatim if we use Lebesgue outer measure instead. However, later in the book the Marcinkiewicz interpolation theorem is used for these maximal functions, so it seems that we have to prove its measurability... For specific functions (such as the famous Hardy–Littlewood maximal function), the measurability can be proved directly (in this case, one observes that it suffices to take rational $t$ ). In general, I need the measurability of the following type of maximal functions (as is used later in the book): Let $\phi\in L^1(\mathbb{R}^n)$ such that $\int\phi=1$ . Let $\phi_t=t^{-n}\phi(x/t)$ . Then $T^*f(x):=\sup_{t\in\mathbb{R}}|\phi_t*f(x)|$ is measurable. Is this true?","I have been reading Fourier Analysis by J. Duoandikoetxea. I got stuck on proving the measurability of maximal functions. The general maximal function/operator in this book is from the following proposition: The theorem as it is stated is, in my opinion, simply false; I don't see how is measurable. (PS. The definition is that and should map functions to measurable functions .) Incidentally: Well, the proof of this particular theorem carries over verbatim if we use Lebesgue outer measure instead. However, later in the book the Marcinkiewicz interpolation theorem is used for these maximal functions, so it seems that we have to prove its measurability... For specific functions (such as the famous Hardy–Littlewood maximal function), the measurability can be proved directly (in this case, one observes that it suffices to take rational ). In general, I need the measurability of the following type of maximal functions (as is used later in the book): Let such that . Let . Then is measurable. Is this true?",T^*f T_t T^* L^p X\to\mathbb{C} t \phi\in L^1(\mathbb{R}^n) \int\phi=1 \phi_t=t^{-n}\phi(x/t) T^*f(x):=\sup_{t\in\mathbb{R}}|\phi_t*f(x)|,"['real-analysis', 'measure-theory', 'fourier-analysis', 'lebesgue-integral', 'harmonic-analysis']"
77,Characterization of Wasserstein convergence,Characterization of Wasserstein convergence,,"Let $(X,d)$ be a complete metric space and define $$\mathcal{P}_2(X) := \{ \mu \text{ Borel probability measure} \mid \int_X d^2(x,x_0) d\mu(x) < \infty \text{ for some } x_0 \in X  \}$$ endowed with the Wasserstein distance $$ W^2_2(\mu, \nu) = \inf \{ \int_{X \times X} d^2(x,y) d\pi(x,y) \mid \pi \in \Gamma(\mu, \nu) \} $$ where $\Gamma(\mu, \nu)$ is the set of probability measure on $X \times X$ which marginals are $\mu$ and $\nu$ . I this setting, I am trying to understand the proof of Theorem If $\mu \in \mathcal{P}_2(X)$ and $ \{ \mu_n \} \subset \mathcal{P}_2(X)$ then $$ \mu_n \overset{W_2}{\longrightarrow} \mu \Leftrightarrow \biggl [ \mu_n  \rightharpoonup \mu \text{ and } \int_X d^2(x,x_0) d\mu_n \longrightarrow \int_X d^2(x,x_0)d\mu \text{ for some }x_0 \in X \biggr ]$$ There are 3 steps in the proof I can't completely understand, assume $(X,d)$ is compact for the first two points: Let $$Z:= \{ f \in \text{Lip}_1(X,d) \mid f(x_0)=0 \} $$ then $$\sup_{f \in \text{Lip}_1(X,d)} \biggl | \int_X f d(\mu_n -\mu) \biggr |= \sup_{f \in Z} \biggl | \int_X f d(\mu_n -\mu) \biggr | $$ Let $A \subset X$ be an open subset, then $$ \liminf_{n} \int_A d^2(x,x_0)d\mu_n \ge  \int_A d^2(x,x_0)d\mu $$ Given a sequence of compact subsets $ \{ K_k \}_{k \ge 1}$ s.t. $$ \lim_{k \to +\infty} \sup_n \int_{X \setminus K_k} d^2(x_0, \cdot)d\mu_n =0$$ define $$\mu_{n,k} := \mu_n |_{K_k} + (1-\mu_n(K_k))\delta_{x_0} $$ then, up to subsequences, $ \{ \mu_{n_k} \}_{n}$ is weak convergent. Any hint will be very appreciated!","Let be a complete metric space and define endowed with the Wasserstein distance where is the set of probability measure on which marginals are and . I this setting, I am trying to understand the proof of Theorem If and then There are 3 steps in the proof I can't completely understand, assume is compact for the first two points: Let then Let be an open subset, then Given a sequence of compact subsets s.t. define then, up to subsequences, is weak convergent. Any hint will be very appreciated!","(X,d) \mathcal{P}_2(X) := \{ \mu \text{ Borel probability measure} \mid \int_X d^2(x,x_0) d\mu(x) < \infty \text{ for some } x_0 \in X  \}  W^2_2(\mu, \nu) = \inf \{ \int_{X \times X} d^2(x,y) d\pi(x,y) \mid \pi \in \Gamma(\mu, \nu) \}  \Gamma(\mu, \nu) X \times X \mu \nu \mu \in \mathcal{P}_2(X)  \{ \mu_n \} \subset \mathcal{P}_2(X)  \mu_n \overset{W_2}{\longrightarrow} \mu \Leftrightarrow \biggl [ \mu_n  \rightharpoonup \mu \text{ and } \int_X d^2(x,x_0) d\mu_n \longrightarrow \int_X d^2(x,x_0)d\mu \text{ for some }x_0 \in X \biggr ] (X,d) Z:= \{ f \in \text{Lip}_1(X,d) \mid f(x_0)=0 \}  \sup_{f \in \text{Lip}_1(X,d)} \biggl | \int_X f d(\mu_n -\mu) \biggr |= \sup_{f \in Z} \biggl | \int_X f d(\mu_n -\mu) \biggr |  A \subset X  \liminf_{n} \int_A d^2(x,x_0)d\mu_n \ge  \int_A d^2(x,x_0)d\mu   \{ K_k \}_{k \ge 1}  \lim_{k \to +\infty} \sup_n \int_{X \setminus K_k} d^2(x_0, \cdot)d\mu_n =0 \mu_{n,k} := \mu_n |_{K_k} + (1-\mu_n(K_k))\delta_{x_0}   \{ \mu_{n_k} \}_{n}","['measure-theory', 'weak-convergence', 'optimal-transport']"
78,Exact value of Hausdorff measure of two dimensional Cantor set,Exact value of Hausdorff measure of two dimensional Cantor set,,"Let $\mathcal{C}$ denote the classical Cantor set, then it is well-known that $\mathcal{C}$ has Hausdorff dimension $\alpha = \ln 2 /\ln 3$ , and its $\alpha$ -dimensional Hausdorff measure is $\mathcal{H}_\alpha(\mathcal{C}) = 1$ . For $\mathcal{C}\times \mathcal{C}\subset \mathbb{R}^2$ , it is fairly easy to show its Hausdorff dimension is $2\alpha$ , and $0< \mathcal{H}_{2\alpha}(\mathcal{C}\times \mathcal{C}) <\infty$ . I am interested in knowing the exact value of $\mathcal{H}_{2\alpha}(\mathcal{C}\times \mathcal{C})$ . The proof for 1D case $\mathcal{H}_\alpha(\mathcal{C}) = 1$ cannot carry directly into higher dimension. This answer claims the measure is $1$ and refers to Falcon's book The Geometry of Fractal Sets . However, after really looking into the book, it does not say anything about Hausdorff measure (only Hausdorff dimension) for any non-1D set (at least at the position quoted). Nonetheless, it might be possible that the Hausdorff measure does not admit a simple closed-form, as expected for many fractals in $\mathbb{R}^n$ with $n>1$ . Any idea/reference is much appreciated.","Let denote the classical Cantor set, then it is well-known that has Hausdorff dimension , and its -dimensional Hausdorff measure is . For , it is fairly easy to show its Hausdorff dimension is , and . I am interested in knowing the exact value of . The proof for 1D case cannot carry directly into higher dimension. This answer claims the measure is and refers to Falcon's book The Geometry of Fractal Sets . However, after really looking into the book, it does not say anything about Hausdorff measure (only Hausdorff dimension) for any non-1D set (at least at the position quoted). Nonetheless, it might be possible that the Hausdorff measure does not admit a simple closed-form, as expected for many fractals in with . Any idea/reference is much appreciated.",\mathcal{C} \mathcal{C} \alpha = \ln 2 /\ln 3 \alpha \mathcal{H}_\alpha(\mathcal{C}) = 1 \mathcal{C}\times \mathcal{C}\subset \mathbb{R}^2 2\alpha 0< \mathcal{H}_{2\alpha}(\mathcal{C}\times \mathcal{C}) <\infty \mathcal{H}_{2\alpha}(\mathcal{C}\times \mathcal{C}) \mathcal{H}_\alpha(\mathcal{C}) = 1 1 \mathbb{R}^n n>1,"['real-analysis', 'measure-theory', 'fractals', 'geometric-measure-theory', 'hausdorff-measure']"
79,Show that $f: \mathbb{R}: \rightarrow \ell^{\infty}$ is not Lebesgue integrable?,Show that  is not Lebesgue integrable?,f: \mathbb{R}: \rightarrow \ell^{\infty},"Let $\{I_{n}\}_{n \in \mathbb{N}}$ be the sequence of real intervals $[0, 1/2], [1/2, 1], [0, 1/3], [1/3, 2/3]$ , and so on. Let $f_{n}: \mathbb{R} \rightarrow \mathbb{R}$ be the indicator function on $I_{n}$ . Let $f:\mathbb{R} \rightarrow \ell^{\infty}$ be $f(x) = (f_{1}(x), f_{2}(x), ...)$ . Show that $f$ is not Lebesgue measurable. I'm not sure where to start with this. I tried a contradiction proof, supposing that there exists a sequence of simple measurable functions which converge pointwise to $f$ (which would imply that $f$ is measurable). However, I'm having trouble reaching a contradiction. My intuition for this approach is that the most ""natural"" such sequence, namely $g_{n}: \mathbb{R} \rightarrow \ell^{\infty}$ where $g_{n}(x) = (f_{1}(x), f_{2}(x), ..., f_{n}(x), 0, 0, ...)$ does not work, because for any $x \in [0, 1]$ there are infinitely many intervals $I_{k}$ such that $x \in I_{k}$ , so for any $g_{n}$ , we can show $\| g_{n}(x) - f(x) \| = \frac{1}{m} + \frac{1}{m+1} + ... = \infty$ for some $m \in \mathbb{N}$ . However, it is not enough to show that the particular sequence of simple measurable functions $(g_{n})$ fails to converge pointwise to $f$ . Is there some way to fix this approach? Or should I try something else entirely?","Let be the sequence of real intervals , and so on. Let be the indicator function on . Let be . Show that is not Lebesgue measurable. I'm not sure where to start with this. I tried a contradiction proof, supposing that there exists a sequence of simple measurable functions which converge pointwise to (which would imply that is measurable). However, I'm having trouble reaching a contradiction. My intuition for this approach is that the most ""natural"" such sequence, namely where does not work, because for any there are infinitely many intervals such that , so for any , we can show for some . However, it is not enough to show that the particular sequence of simple measurable functions fails to converge pointwise to . Is there some way to fix this approach? Or should I try something else entirely?","\{I_{n}\}_{n \in \mathbb{N}} [0, 1/2], [1/2, 1], [0, 1/3], [1/3, 2/3] f_{n}: \mathbb{R} \rightarrow \mathbb{R} I_{n} f:\mathbb{R} \rightarrow \ell^{\infty} f(x) = (f_{1}(x), f_{2}(x), ...) f f f g_{n}: \mathbb{R} \rightarrow \ell^{\infty} g_{n}(x) = (f_{1}(x), f_{2}(x), ..., f_{n}(x), 0, 0, ...) x \in [0, 1] I_{k} x \in I_{k} g_{n} \| g_{n}(x) - f(x) \| = \frac{1}{m} + \frac{1}{m+1} + ... = \infty m \in \mathbb{N} (g_{n}) f",['measure-theory']
80,A function whose averages lie in a set does not need to take values in this set almost everywhere,A function whose averages lie in a set does not need to take values in this set almost everywhere,,"Let $ (X,\Sigma,\mu)$ be a finite measure space. ( $\mu(X)<\infty$ ). Let $f \in L^1(\mu)$ be a complex-valued function, and let $S \subseteq C$ be a non-closed subset. Suppose that for every $E \in \Sigma$ , $\frac{1}{\mu(E)}\int_E fd\mu \in S  $ . Is it true that $f(x) \in S$ almost everywhere? I know this is true if $S$ is closed (this is theorem 1.40 in ""Real and complex analysis"" by Rudin). I am looking for counter-examples when $S$ is not closed.","Let be a finite measure space. ( ). Let be a complex-valued function, and let be a non-closed subset. Suppose that for every , . Is it true that almost everywhere? I know this is true if is closed (this is theorem 1.40 in ""Real and complex analysis"" by Rudin). I am looking for counter-examples when is not closed."," (X,\Sigma,\mu) \mu(X)<\infty f \in L^1(\mu) S \subseteq C E \in \Sigma \frac{1}{\mu(E)}\int_E fd\mu \in S   f(x) \in S S S","['measure-theory', 'examples-counterexamples']"
81,Lebesgue Measurable Set which is not a union of a Borel set and a subset of a null $F_\sigma$ set?,Lebesgue Measurable Set which is not a union of a Borel set and a subset of a null  set?,F_\sigma,"The Lebesgue Sigma algebra is the completion of the Borel Sigma algebra under the Lebesgue measure, which means that every Lebesgue measurable set can be written as a union of a Borel set and a subset of a measure $0$ Borel set.  But my question is, what is an example of a Lebesgue measurable set which cannot be written as a union of a Borel set and a subset of a measure $0$ $F_\sigma$ set? Or does no such example exist?","The Lebesgue Sigma algebra is the completion of the Borel Sigma algebra under the Lebesgue measure, which means that every Lebesgue measurable set can be written as a union of a Borel set and a subset of a measure Borel set.  But my question is, what is an example of a Lebesgue measurable set which cannot be written as a union of a Borel set and a subset of a measure set? Or does no such example exist?",0 0 F_\sigma,"['measure-theory', 'lebesgue-measure', 'examples-counterexamples', 'descriptive-set-theory', 'borel-sets']"
82,Approximation of measurable function via simple functions [Proof],Approximation of measurable function via simple functions [Proof],,"Let's denote by $\mathfrak{M}$ the set of all measurable subsets of $\mathbb{R}^d$ . I mean the Lebesgue measure. Definition: Let $\{E_k\}_{k=1}^{N}\in\mathfrak{M}$ with $m(E_k)<\infty$ then the function of the form $\varphi(x)=\sum \limits_{k=1}^{N}a_k\chi_{E_K}(x)$ is called simple function. Theorem: Let $f:X\to [0,+\infty]$ is measurable function, then there exist the sequence of real-valued simple functions $\{s_n(x)\}_{n=1}^{\infty}$ on $X$ such that $0\leq s_1\leq s_2\leq \dots\leq f$ and $s_n\to f$ pointwise. This is the theorem from Stein Shakarchi's book but I have found the following proof (not from the book). Honestly to say two moments of the proof are quite not precise. 1) Note that we can write the function $\phi_n(x)$ in the following form $$\phi_n(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{[n,+\infty)}(x)$$ But this function is not simple simple since the interval $[n,+\infty)$ has infinite measure. 2) When we compose any function on the left with simple function, namely $\phi_n\circ f(x)$ we get the following function $$\phi_n\circ f(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{f^{-1}[n,+\infty)}(x),$$ since $f$ is measurable then we know that each set $f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)$ and $f^{-1}[n,+\infty)$ is measurable but why their measure is finite?","Let's denote by the set of all measurable subsets of . I mean the Lebesgue measure. Definition: Let with then the function of the form is called simple function. Theorem: Let is measurable function, then there exist the sequence of real-valued simple functions on such that and pointwise. This is the theorem from Stein Shakarchi's book but I have found the following proof (not from the book). Honestly to say two moments of the proof are quite not precise. 1) Note that we can write the function in the following form But this function is not simple simple since the interval has infinite measure. 2) When we compose any function on the left with simple function, namely we get the following function since is measurable then we know that each set and is measurable but why their measure is finite?","\mathfrak{M} \mathbb{R}^d \{E_k\}_{k=1}^{N}\in\mathfrak{M} m(E_k)<\infty \varphi(x)=\sum \limits_{k=1}^{N}a_k\chi_{E_K}(x) f:X\to [0,+\infty] \{s_n(x)\}_{n=1}^{\infty} X 0\leq s_1\leq s_2\leq \dots\leq f s_n\to f \phi_n(x) \phi_n(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{[n,+\infty)}(x) [n,+\infty) \phi_n\circ f(x) \phi_n\circ f(x)=\sum \limits_{k=0}^{n2^n-1}\frac{k}{2^n}\chi_{f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right)}(x)+n\chi_{f^{-1}[n,+\infty)}(x), f f^{-1}\left[\frac{k}{2^n},\frac{k+1}{2^n}\right) f^{-1}[n,+\infty)","['real-analysis', 'measure-theory']"
83,On the verification of an equality of sets,On the verification of an equality of sets,,"Only one thing is not clear to me. Proposition. Let $\{f_n\}_{n\in\mathbb {N}}$ a sequence of integrable function no-negative such that $f_{n}\le f_{n+1}$ if   \begin{equation} \lim_{n\to\infty}\int_Xf_n\;d\lambda=0, \end{equation}   then    \begin{equation} \lim_{n\to\infty}f_n<\infty\quad\text{a.e.} \end{equation} proof. \begin{equation} 0=\lim_{n\to\infty}\int_Xf_n\;d\lambda=\sup_n\int_Xf_n \;d\lambda, \end{equation} then \begin{equation} \int_Xf_n\;d\lambda=0\quad\text{for all $n\in\mathbb{N}$}, \end{equation} therefore $f_n=0$ a.e.for all $n\in\mathbb{N}$. Now \begin{equation} \lambda(\{x:f_n(x)>0\})=0. \end{equation} We observe that \begin{equation} \{x:\lim_nf_n(x)>0\}=\cup_n\{x:f_n(x)>0\}\quad(1) \end{equation} then \begin{equation} \lambda(\{x:\lim_nf_n(x)>0\})=\lambda(\cup_n\{x:f_n(x)>0\})=\lim_n\lambda(\{x:f_n(x)>0\})=0. \end{equation} Is it correct to proceed in this way for 1? If $x\in\cup_n\{x:f_n(x)>0\}$ $\Rightarrow$ $\exists n_0\in\mathbb{N}$ such that $f_{n_0}(x)>0$ $\Rightarrow$  $\sup_n\{f_n(x)>0\}$ $\Rightarrow$ $\lim_n f_n(x)=\sup_n\{f_n(x)\}>0$. Then \begin{equation} \bigcup_n\{x:f_n(x)>0\}\subseteq \{x:\lim_nf_n(x)>0\}. \end{equation} If $x\in\{x:\lim_nf_n(x)>0\}$ $\Rightarrow$ $\sup_n\{f_n(x)\}>0$ $\Rightarrow$ $\exists n_0$ such that $f_{n_0}(x)>0$ $\Rightarrow$ $x\in\cup_n\{x:f_n(x)>0\}$. Thanks!","Only one thing is not clear to me. Proposition. Let $\{f_n\}_{n\in\mathbb {N}}$ a sequence of integrable function no-negative such that $f_{n}\le f_{n+1}$ if   \begin{equation} \lim_{n\to\infty}\int_Xf_n\;d\lambda=0, \end{equation}   then    \begin{equation} \lim_{n\to\infty}f_n<\infty\quad\text{a.e.} \end{equation} proof. \begin{equation} 0=\lim_{n\to\infty}\int_Xf_n\;d\lambda=\sup_n\int_Xf_n \;d\lambda, \end{equation} then \begin{equation} \int_Xf_n\;d\lambda=0\quad\text{for all $n\in\mathbb{N}$}, \end{equation} therefore $f_n=0$ a.e.for all $n\in\mathbb{N}$. Now \begin{equation} \lambda(\{x:f_n(x)>0\})=0. \end{equation} We observe that \begin{equation} \{x:\lim_nf_n(x)>0\}=\cup_n\{x:f_n(x)>0\}\quad(1) \end{equation} then \begin{equation} \lambda(\{x:\lim_nf_n(x)>0\})=\lambda(\cup_n\{x:f_n(x)>0\})=\lim_n\lambda(\{x:f_n(x)>0\})=0. \end{equation} Is it correct to proceed in this way for 1? If $x\in\cup_n\{x:f_n(x)>0\}$ $\Rightarrow$ $\exists n_0\in\mathbb{N}$ such that $f_{n_0}(x)>0$ $\Rightarrow$  $\sup_n\{f_n(x)>0\}$ $\Rightarrow$ $\lim_n f_n(x)=\sup_n\{f_n(x)\}>0$. Then \begin{equation} \bigcup_n\{x:f_n(x)>0\}\subseteq \{x:\lim_nf_n(x)>0\}. \end{equation} If $x\in\{x:\lim_nf_n(x)>0\}$ $\Rightarrow$ $\sup_n\{f_n(x)\}>0$ $\Rightarrow$ $\exists n_0$ such that $f_{n_0}(x)>0$ $\Rightarrow$ $x\in\cup_n\{x:f_n(x)>0\}$. Thanks!",,"['measure-theory', 'proof-explanation']"
84,Pushing Lebesgue measure with Peano curve,Pushing Lebesgue measure with Peano curve,,"Let $f:[0,1]\to [0,1]^2$ be some continuous surjective function, and $\mu_n$ - the canonical Lebesgue measure on $\Bbb R^n$. So, on $[0,1]^2$ we can define two probability measures: $\mu_2$ and $\nu_2:=f_*\mu_1$ is the pushforward measure: $\nu_2(A) = \mu_1(f^{-1}(A))$ for each Borel-measurable set $A$. My guess would be that they are mutually singular for all $f$, and that it shold not be too hard to find example sets on which each of them takes $0$ values while the other assigns positive measure, however I have not practiced measure theory for a while, so can't think of anything simple. Question: I would like to know whether $\mu_2$ and $\nu_2$ are indeed mutually singular for any $f$ as above.","Let $f:[0,1]\to [0,1]^2$ be some continuous surjective function, and $\mu_n$ - the canonical Lebesgue measure on $\Bbb R^n$. So, on $[0,1]^2$ we can define two probability measures: $\mu_2$ and $\nu_2:=f_*\mu_1$ is the pushforward measure: $\nu_2(A) = \mu_1(f^{-1}(A))$ for each Borel-measurable set $A$. My guess would be that they are mutually singular for all $f$, and that it shold not be too hard to find example sets on which each of them takes $0$ values while the other assigns positive measure, however I have not practiced measure theory for a while, so can't think of anything simple. Question: I would like to know whether $\mu_2$ and $\nu_2$ are indeed mutually singular for any $f$ as above.",,['measure-theory']
85,Corollary 5 in Royden-Fitzpatrick's Real Analysis: Convergence in Measure,Corollary 5 in Royden-Fitzpatrick's Real Analysis: Convergence in Measure,,"Corollary 5: Let $\{f_n\}$ be a sequence of nonnegative integrable functions on $E$ . Then $$\lim_{n \to \infty} \int_E f_n = 0 ~~~~~~(5)$$ if and only if $$f_n \to 0 \mbox{ in measure on } E \mbox{ and } \{f_n\} \mbox{ is uniformly integrable and tight over } E ~~~~~(6)$$ Here's the part of the proof giving me trouble: First assume (5). Corollary 2 tells us that $\{f_n\}$ is uniformly integrable and tight over $E$ ... Here is corollary 2: Let $\{h_n\}$ be a sequence of nonnegative integrable functions on $E$ . Suppose that $h_n(x) \to 0$ for all most all $x \in E$ . Then $$\int_E h_n \to 0 \mbox{ iff } \{h_n\} \mbox{ uniformly integrable and tight over } E$$ How can we invoke corollary 2 if $f_n$ isn't assumed to converge pointwise a.e. to $0$ on $E$ ? EDIT: Okay. I encountered some more difficulties in the second half of the proof: To prove the converse, we argue by contradiction. Assume that (6) holds but (5) fails to hold. Then there is some $\epsilon_0 > 0$ and a subsequence $\{f_{n_k}\}$ for which $$\int_E f_{n_k} \ge \epsilon_0 \mbox{ for all } k$$ However, by theorem 4, a subsequence $\{f_{n_k}\}$ converges to $f \equiv 0$ pointwise almost everywhere on $E$ and this subsequence is uniformly integrable and tight so that, by the Vitali Convergence Theorem, we arrive at a contradiction to the existence of the above $\epsilon_0$ . This completes the proof. First, why does $\int_E f_{n_k} \ge \epsilon_0$ hold for all $k$ ? If I've properly negated the definition of the convergence of a sequence, we should actually have that there exists an $\epsilon > 0$ such that for every $N \in \Bbb{N}$ there exists an $k \ge N$ such that $\int_E f_{n_k} \ge \epsilon_0$ . Second, assuming that (5) fails certainly does give us a subsequence such that blah blah holds; and theorem 4 gives us a subsequence such that blah blah holds. But what reason is there for thinking that these subsequences are the same?","Corollary 5: Let be a sequence of nonnegative integrable functions on . Then if and only if Here's the part of the proof giving me trouble: First assume (5). Corollary 2 tells us that is uniformly integrable and tight over ... Here is corollary 2: Let be a sequence of nonnegative integrable functions on . Suppose that for all most all . Then How can we invoke corollary 2 if isn't assumed to converge pointwise a.e. to on ? EDIT: Okay. I encountered some more difficulties in the second half of the proof: To prove the converse, we argue by contradiction. Assume that (6) holds but (5) fails to hold. Then there is some and a subsequence for which However, by theorem 4, a subsequence converges to pointwise almost everywhere on and this subsequence is uniformly integrable and tight so that, by the Vitali Convergence Theorem, we arrive at a contradiction to the existence of the above . This completes the proof. First, why does hold for all ? If I've properly negated the definition of the convergence of a sequence, we should actually have that there exists an such that for every there exists an such that . Second, assuming that (5) fails certainly does give us a subsequence such that blah blah holds; and theorem 4 gives us a subsequence such that blah blah holds. But what reason is there for thinking that these subsequences are the same?",\{f_n\} E \lim_{n \to \infty} \int_E f_n = 0 ~~~~~~(5) f_n \to 0 \mbox{ in measure on } E \mbox{ and } \{f_n\} \mbox{ is uniformly integrable and tight over } E ~~~~~(6) \{f_n\} E \{h_n\} E h_n(x) \to 0 x \in E \int_E h_n \to 0 \mbox{ iff } \{h_n\} \mbox{ uniformly integrable and tight over } E f_n 0 E \epsilon_0 > 0 \{f_{n_k}\} \int_E f_{n_k} \ge \epsilon_0 \mbox{ for all } k \{f_{n_k}\} f \equiv 0 E \epsilon_0 \int_E f_{n_k} \ge \epsilon_0 k \epsilon > 0 N \in \Bbb{N} k \ge N \int_E f_{n_k} \ge \epsilon_0,"['real-analysis', 'measure-theory', 'proof-explanation']"
86,Absolute continuity of a Borel measure,Absolute continuity of a Borel measure,,"This is a question from Ph. D Qualifying Exam of real analysis. Let $F$ be an increasing function on $[0,1]$ with $F(0)=0$ and $F(1)=1$ . Let $\mu$ be a Borel measure defined by $\mu((a, b))=F(b-)-F(a+)$ and $\mu(\{0\})=\mu(\{1\})=0$ . Suppose that the function $F$ satisfies a Lipschitz condition $$|F(x)-F(y)|\le A|x-y|$$ for some $A>0$ . Let $m$ be the Lebesgue measure on $[0,1]$ . (a) Prove that $\mu \ll m$ . (b) Prove that $\dfrac{d\mu}{dm} \le A $ a.e. My attempt: (a) Since $F$ is Lipschitz continuous, it is clear that $F$ is absolutely continuous and $F$ is differentiable a.e. and $$\mu((a, b))=\int_{a}^{b}F'dm$$ by absolute continuity. Since $\mu$ is a Borel measure, it extends to $\mu(E)=\int_E F'dm$ for every Borel set $E$ .(I'm not sure for this part. Is there any related theorem or counterexample for this one?) Therefore, it suffices to show that $\int_E F' =0$ whenever $E$ is a Borel set and $m(E)=0$ , and this is obvious from the definition of Lebesgue integral. (b) From (a), $\dfrac{d\mu}{dm}=F'$ and by Lipschitz continuity, $|F'|\le A$ a.e. and the result is obvious. Am I correct? Is there any errors or logical jumps in my attempt?","This is a question from Ph. D Qualifying Exam of real analysis. Let be an increasing function on with and . Let be a Borel measure defined by and . Suppose that the function satisfies a Lipschitz condition for some . Let be the Lebesgue measure on . (a) Prove that . (b) Prove that a.e. My attempt: (a) Since is Lipschitz continuous, it is clear that is absolutely continuous and is differentiable a.e. and by absolute continuity. Since is a Borel measure, it extends to for every Borel set .(I'm not sure for this part. Is there any related theorem or counterexample for this one?) Therefore, it suffices to show that whenever is a Borel set and , and this is obvious from the definition of Lebesgue integral. (b) From (a), and by Lipschitz continuity, a.e. and the result is obvious. Am I correct? Is there any errors or logical jumps in my attempt?","F [0,1] F(0)=0 F(1)=1 \mu \mu((a, b))=F(b-)-F(a+) \mu(\{0\})=\mu(\{1\})=0 F |F(x)-F(y)|\le A|x-y| A>0 m [0,1] \mu \ll m \dfrac{d\mu}{dm} \le A  F F F \mu((a, b))=\int_{a}^{b}F'dm \mu \mu(E)=\int_E F'dm E \int_E F' =0 E m(E)=0 \dfrac{d\mu}{dm}=F' |F'|\le A","['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-measure', 'absolute-continuity']"
87,Show a function defined by an integral is Borel measurable.,Show a function defined by an integral is Borel measurable.,,"Let $f: \left [ 0, 1 \right ] \times \left [ 0, 1 \right ] \rightarrow \mathbb{R}$ satisfy: $f_x\left ( y \right ):= f\left ( x, y \right ) : \left [ 0, 1 \right ]\rightarrow \mathbb{R} $ is Riemann integrable; $f_y\left ( x \right ):= f\left ( x, y \right ) : \left [ 0, 1 \right ]\rightarrow \mathbb{R} $ is Borel measurable. Then prove that $g(x):=\int_{\left [ 0, 1 \right ]} f_x\left ( y \right ) dy$ is Borel measurable. I tried at the first consider Fubini theorem. However, it doesn't work due to the condition failure. Later I tried to prove directly from the definition of Borel measurability, and it does not go anywhere further. Also, $f$ itself may not be measurable in the product measure; and Riemann integrability does not imply Borel measurability either. Would you please give me some hints or ideas? Thank you.","Let $f: \left [ 0, 1 \right ] \times \left [ 0, 1 \right ] \rightarrow \mathbb{R}$ satisfy: $f_x\left ( y \right ):= f\left ( x, y \right ) : \left [ 0, 1 \right ]\rightarrow \mathbb{R} $ is Riemann integrable; $f_y\left ( x \right ):= f\left ( x, y \right ) : \left [ 0, 1 \right ]\rightarrow \mathbb{R} $ is Borel measurable. Then prove that $g(x):=\int_{\left [ 0, 1 \right ]} f_x\left ( y \right ) dy$ is Borel measurable. I tried at the first consider Fubini theorem. However, it doesn't work due to the condition failure. Later I tried to prove directly from the definition of Borel measurability, and it does not go anywhere further. Also, $f$ itself may not be measurable in the product measure; and Riemann integrability does not imply Borel measurability either. Would you please give me some hints or ideas? Thank you.",,"['real-analysis', 'measure-theory', 'riemann-integration', 'product-measure', 'borel-measures']"
88,"How to define the k-dimensional Lebesgue measure $\lambda^{k,n}$ on $R^n$ when $k<n$",How to define the k-dimensional Lebesgue measure  on  when,"\lambda^{k,n} R^n k<n","Rene Schilling says Which can be stated more generally: Let $B\in\mathfrak{B}(\mathbb{R}^k)$ and let $\Phi: \mathbb{R}^k\to\mathbb{R}^n$  (where $k\leq n$) be a $C^1$-map for which there exists $Q\subset \mathbb{R}^n$ with $\lambda^{k,n}(Q)=0$ such that $\Phi(x_1)=\Phi(x_2)\in \Phi(B)\setminus Q\ \Rightarrow\ x_1=x_2$. Then $$\lambda^{k,n}(\Phi(B))=\int_B\sqrt{\det((D\Phi(x))^T D\Phi(x))} \lambda^{k,k}(dx)$$ where $\lambda^{k,n}$ denotes the $k$-dimensional Lebesgue measure for subsets of $\mathbb{R}^n$. The problem is I don't know how Schilling's definition of $\lambda^k$ should be extented to define $\lambda^{k,n}$ in order to imply the more general Jacobi theorem. How should this be done and/or are there any alternative references that treats the more general problem?","Rene Schilling says Which can be stated more generally: Let $B\in\mathfrak{B}(\mathbb{R}^k)$ and let $\Phi: \mathbb{R}^k\to\mathbb{R}^n$  (where $k\leq n$) be a $C^1$-map for which there exists $Q\subset \mathbb{R}^n$ with $\lambda^{k,n}(Q)=0$ such that $\Phi(x_1)=\Phi(x_2)\in \Phi(B)\setminus Q\ \Rightarrow\ x_1=x_2$. Then $$\lambda^{k,n}(\Phi(B))=\int_B\sqrt{\det((D\Phi(x))^T D\Phi(x))} \lambda^{k,k}(dx)$$ where $\lambda^{k,n}$ denotes the $k$-dimensional Lebesgue measure for subsets of $\mathbb{R}^n$. The problem is I don't know how Schilling's definition of $\lambda^k$ should be extented to define $\lambda^{k,n}$ in order to imply the more general Jacobi theorem. How should this be done and/or are there any alternative references that treats the more general problem?",,"['measure-theory', 'reference-request', 'lebesgue-integral', 'lebesgue-measure', 'jacobian']"
89,An equivalence of $\sigma$-additivity,An equivalence of -additivity,\sigma,"Let $(\Omega, \mathcal{A})$ be a measurable space and let $\nu: \mathcal{A}\to [0, \infty)$ be finitely additive with $\nu(\emptyset)=0$. Show the following: $\nu$ is $\sigma$-additive if and only if the following holds: If $A_j \in \mathcal{A}$ with $A_1 \supseteq A_2 \supseteq \ldots$ and $\mu(A_j)\geq \delta$ for all $j \geq 1$ for some $\delta >0$ then $\cap_{j=1}^\infty A_j\neq \emptyset$. My proof for the forward direction is as follows: Suppose that $\nu$ is $\sigma$-additive. Since we also know that $\nu(\emptyset)=0$ and $\nu(A)\geq 0$ for all $A\in \mathcal{A}$ (since $\mu$ takes its values in $[0, \infty)$) then $\nu$ is a measure on $\mathcal{A}$. Let $\{A_j\}_{j=1}^\infty$ be a collection of sets in $\mathcal{A}$ such that $A_1\supseteq A_2 \supseteq \ldots$ and $\nu(A_j)\geq \delta$ for all $j\geq 1$ for some $\delta >0$. Suppose, to the contrary, that $\cap_{j=1}^\infty A_j=\emptyset$. Then $\nu(\cap_{j=1}^\infty A_j)=0$. However, by continuity from above we have $$0=\nu(\emptyset) = \nu(\cap_{j=1}^\infty A_j)=\lim_{n\to \infty} \nu(A_j)\geq \lim_{n\to \infty} \delta=\delta >0,  $$ a contradiction. Thus, $\cap_{j=1}^\infty A_j\neq \emptyset$. For the other direction I was going to consider an arbitrary collection $\{A_j\}_{j=1}^\infty$ of sets in $\mathcal{A}$ and define a new collection $\{E_n\}_{n=1}^\infty$ by $E_n=\cup_{j=1}^\infty A_j\setminus (\cup_{i=1}^n A_i)$ for each $n \geq 1$. Clearly, the $E_n$'s are decreasing, but I have no idea how to proceed from there. Your help is greatly appreciated and thank you in advance!","Let $(\Omega, \mathcal{A})$ be a measurable space and let $\nu: \mathcal{A}\to [0, \infty)$ be finitely additive with $\nu(\emptyset)=0$. Show the following: $\nu$ is $\sigma$-additive if and only if the following holds: If $A_j \in \mathcal{A}$ with $A_1 \supseteq A_2 \supseteq \ldots$ and $\mu(A_j)\geq \delta$ for all $j \geq 1$ for some $\delta >0$ then $\cap_{j=1}^\infty A_j\neq \emptyset$. My proof for the forward direction is as follows: Suppose that $\nu$ is $\sigma$-additive. Since we also know that $\nu(\emptyset)=0$ and $\nu(A)\geq 0$ for all $A\in \mathcal{A}$ (since $\mu$ takes its values in $[0, \infty)$) then $\nu$ is a measure on $\mathcal{A}$. Let $\{A_j\}_{j=1}^\infty$ be a collection of sets in $\mathcal{A}$ such that $A_1\supseteq A_2 \supseteq \ldots$ and $\nu(A_j)\geq \delta$ for all $j\geq 1$ for some $\delta >0$. Suppose, to the contrary, that $\cap_{j=1}^\infty A_j=\emptyset$. Then $\nu(\cap_{j=1}^\infty A_j)=0$. However, by continuity from above we have $$0=\nu(\emptyset) = \nu(\cap_{j=1}^\infty A_j)=\lim_{n\to \infty} \nu(A_j)\geq \lim_{n\to \infty} \delta=\delta >0,  $$ a contradiction. Thus, $\cap_{j=1}^\infty A_j\neq \emptyset$. For the other direction I was going to consider an arbitrary collection $\{A_j\}_{j=1}^\infty$ of sets in $\mathcal{A}$ and define a new collection $\{E_n\}_{n=1}^\infty$ by $E_n=\cup_{j=1}^\infty A_j\setminus (\cup_{i=1}^n A_i)$ for each $n \geq 1$. Clearly, the $E_n$'s are decreasing, but I have no idea how to proceed from there. Your help is greatly appreciated and thank you in advance!",,"['real-analysis', 'measure-theory']"
90,"$ \int_0^af = 0, \forall a \in \mathbb{R} \Rightarrow f=0$ almost everywhere",almost everywhere," \int_0^af = 0, \forall a \in \mathbb{R} \Rightarrow f=0","Let $f: \mathbb{R} \rightarrow \mathbb{R}$ a Lebesgue integrable function and $\int_0^af=0, \forall a \in \mathbb{R}$.Prove that $f=0$ almost everywhere. Here is my solution: Let $0<a<b$, then $(0,b)=(0,a) \cup [a,b)$ thus $$\int_a^bf= \int_0^bf - \int_0^af \Rightarrow \int_a^bf=0$$ Now we have that $ \mathbb{R}= \bigcup_{n \in \mathbb{Z}}[n,n+1)$ which is a disjoint union, thus $$ \int_{\mathbb{R}}f=\sum_{n \in \mathbb{Z}} \int_n^{n+1}f=0$$. Also we know that$$\{x:f(x)\neq 0\}= \{x:f(x)>0\} \cup \{x:f(x)<0\}=\{x:f(x)>0\} \cup \{x:-f(x)>0\}$$. Now $\{x:f(x)>0\}=\{x:f(x)> \frac{1}{n}\})$ thus $m(\{x:f(x)> \frac{1}{n}\})\leqslant n \int_{\mathbb{R}}f=0$ therefore $m(\{x:f(x)> \frac{1}{n}\})=0 \Rightarrow m(\{x:f(x)>0\})=0$, from the subadditivity of the Lebesgue measure and from the Markov inequality. With the same argument we can prove that $m(\{x:-f(x)>0\})=0$ Combining these we have that $$m(\{x:f(x) \neq 0\}) \leqslant m(\{x:f(x)>0\})+m(\{x:-f(x)>0\})=0$$ $\therefore$ $m(\{x:f(x) \neq 0\})=0$ $$Second-solution$$ Now $ \forall x \in \mathbb{R}$ we have in the same way as above that $\frac{1}{2 \delta}\int_{x-\delta}^{x+\delta}f(y)dy=0 ,\forall \delta>0$. From Lebesgue's differentation theorem we have that $\lim_{\delta \rightarrow 0}\frac{1}{2\delta}\int_{x-\delta}^{x+\delta}f(y)dy =f(x)$ almost everywhere. Thus $f(x)=0$ almost everywhere. Are my solutions correct? This is an exercise I found in a final exam, in undergraduate measure theory. Although it is a final exam exercise, it seemed to me enough simple,that's why I want to verify my thoughts. In case I am wrong I would appreciate any help to guide me to a correct solution. Thank you in advance.","Let $f: \mathbb{R} \rightarrow \mathbb{R}$ a Lebesgue integrable function and $\int_0^af=0, \forall a \in \mathbb{R}$.Prove that $f=0$ almost everywhere. Here is my solution: Let $0<a<b$, then $(0,b)=(0,a) \cup [a,b)$ thus $$\int_a^bf= \int_0^bf - \int_0^af \Rightarrow \int_a^bf=0$$ Now we have that $ \mathbb{R}= \bigcup_{n \in \mathbb{Z}}[n,n+1)$ which is a disjoint union, thus $$ \int_{\mathbb{R}}f=\sum_{n \in \mathbb{Z}} \int_n^{n+1}f=0$$. Also we know that$$\{x:f(x)\neq 0\}= \{x:f(x)>0\} \cup \{x:f(x)<0\}=\{x:f(x)>0\} \cup \{x:-f(x)>0\}$$. Now $\{x:f(x)>0\}=\{x:f(x)> \frac{1}{n}\})$ thus $m(\{x:f(x)> \frac{1}{n}\})\leqslant n \int_{\mathbb{R}}f=0$ therefore $m(\{x:f(x)> \frac{1}{n}\})=0 \Rightarrow m(\{x:f(x)>0\})=0$, from the subadditivity of the Lebesgue measure and from the Markov inequality. With the same argument we can prove that $m(\{x:-f(x)>0\})=0$ Combining these we have that $$m(\{x:f(x) \neq 0\}) \leqslant m(\{x:f(x)>0\})+m(\{x:-f(x)>0\})=0$$ $\therefore$ $m(\{x:f(x) \neq 0\})=0$ $$Second-solution$$ Now $ \forall x \in \mathbb{R}$ we have in the same way as above that $\frac{1}{2 \delta}\int_{x-\delta}^{x+\delta}f(y)dy=0 ,\forall \delta>0$. From Lebesgue's differentation theorem we have that $\lim_{\delta \rightarrow 0}\frac{1}{2\delta}\int_{x-\delta}^{x+\delta}f(y)dy =f(x)$ almost everywhere. Thus $f(x)=0$ almost everywhere. Are my solutions correct? This is an exercise I found in a final exam, in undergraduate measure theory. Although it is a final exam exercise, it seemed to me enough simple,that's why I want to verify my thoughts. In case I am wrong I would appreciate any help to guide me to a correct solution. Thank you in advance.",,"['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-integral', 'lebesgue-measure']"
91,Folland Real Analysis Proposition 1.3,Folland Real Analysis Proposition 1.3,,"The following is a proposition and its proof from chapter 1 of Folland's Real Analysis . 1.3 Proposition. If $A$ is countable, then $\bigotimes_{\alpha\in A}\mathcal M_\alpha$ is the $\sigma$ -algebra generated by $\left\{\prod_{\alpha\in A}E_\alpha:E_\alpha\in\mathcal M_\alpha\right\}$ . Proof. If $E_\alpha\in\mathcal M_\alpha$ , then $\pi^{-1}_\alpha\left(E_\alpha\right)=\prod_{\beta\in A}E_\beta$ where $E_\beta=X$ for $\beta\neq\alpha$ ; on the other hand, $\prod_{\alpha\in A}E_\alpha=\bigcap_{\alpha\in A}\pi^{-1}_\alpha\left(E_\alpha\right)$ . The result therefore follows from Lemma 1.1. Where is the countability of $A$ invoked? I.e., how does this argument fail for $A$ uncountable? Lemma 1.1 reads: 1.1 Lemma. If $\mathcal E\subset\mathcal M\left(\mathcal F\right)$ then $\mathcal M\left(\mathcal E\right)\subset\mathcal M\left(\mathcal F\right)$ . Here, $\mathcal M\left(\mathcal E\right)$ stands for the $\sigma$ -algebra generated by $\mathcal E$ .","The following is a proposition and its proof from chapter 1 of Folland's Real Analysis . 1.3 Proposition. If is countable, then is the -algebra generated by . Proof. If , then where for ; on the other hand, . The result therefore follows from Lemma 1.1. Where is the countability of invoked? I.e., how does this argument fail for uncountable? Lemma 1.1 reads: 1.1 Lemma. If then . Here, stands for the -algebra generated by .",A \bigotimes_{\alpha\in A}\mathcal M_\alpha \sigma \left\{\prod_{\alpha\in A}E_\alpha:E_\alpha\in\mathcal M_\alpha\right\} E_\alpha\in\mathcal M_\alpha \pi^{-1}_\alpha\left(E_\alpha\right)=\prod_{\beta\in A}E_\beta E_\beta=X \beta\neq\alpha \prod_{\alpha\in A}E_\alpha=\bigcap_{\alpha\in A}\pi^{-1}_\alpha\left(E_\alpha\right) A A \mathcal E\subset\mathcal M\left(\mathcal F\right) \mathcal M\left(\mathcal E\right)\subset\mathcal M\left(\mathcal F\right) \mathcal M\left(\mathcal E\right) \sigma \mathcal E,"['real-analysis', 'measure-theory']"
92,Algebraic structure of the extended real line $\overline{\Bbb R}$.,Algebraic structure of the extended real line .,\overline{\Bbb R},"The extended real line $\overline{\Bbb R}$ is defined to be the set $\overline{\Bbb R}=\Bbb R\cup\{\infty,-\infty\}$, where the adjoined symbols $\{\infty,-\infty\}$ represents the ""points at infinity"" in both positive and negative direction. $\overline{\Bbb R}$ can be given a topology by declaring that apart from the usual open basis, we let $(a,\infty]$ and $[-\infty,a)$ be open for any $a\in\Bbb R$. This is the two-point compactification, making $\overline{\Bbb R}$ a compact topological space. However, the algebraic structure of $\overline{\Bbb R}$ seems rather unique. We declare that for any $a\in \Bbb R$, $$\begin{align} \infty+a &= \infty \\ -\infty+a &= -\infty \\ \infty+\infty &= \infty \\ -\infty-\infty &= -\infty \\ \frac a{\infty} &= 0 =\frac a{-\infty} \end{align}$$  and for $\infty\ge a>0> b\ge -\infty$, $$\begin{align} a\cdot\infty &= \infty \\ a\cdot(-\infty) &= -\infty \\ b\cdot\infty &= -\infty \\ b\cdot(-\infty) &= \infty \\ 0\cdot\infty &=0 = 0\cdot(-\infty).\\ \end{align}$$ All other combinations, like $\infty-\infty$ or $\frac{\infty}{\infty}$, are left undefined. Yes, these all make sense but I just want to know if it fits into any bigger framework? This clearly is not in accordance with ""basics"" algebraic structures that we studied in our undergraduate years. $-\infty$ is not the additive inverse of $\infty$, neither is $\frac a{-\infty}=a\cdot{-\infty}^{-1}$  since ${-\infty}$ does not have a multiplicative inverse. Is there a general theory to this kind of algebraic structure? I am thinking about boolean algebra since $1$ in a boolean algebra also exhibits this kind of `absorbing' behaviour. Since I lack any deep knowledge in the field of algebra, I hope that someone here might be able to give an insight into this. PS. I tagged ""logic"" since I think it looks similar to boolean algebra. Please tell me if this is somehow not appropriate.","The extended real line $\overline{\Bbb R}$ is defined to be the set $\overline{\Bbb R}=\Bbb R\cup\{\infty,-\infty\}$, where the adjoined symbols $\{\infty,-\infty\}$ represents the ""points at infinity"" in both positive and negative direction. $\overline{\Bbb R}$ can be given a topology by declaring that apart from the usual open basis, we let $(a,\infty]$ and $[-\infty,a)$ be open for any $a\in\Bbb R$. This is the two-point compactification, making $\overline{\Bbb R}$ a compact topological space. However, the algebraic structure of $\overline{\Bbb R}$ seems rather unique. We declare that for any $a\in \Bbb R$, $$\begin{align} \infty+a &= \infty \\ -\infty+a &= -\infty \\ \infty+\infty &= \infty \\ -\infty-\infty &= -\infty \\ \frac a{\infty} &= 0 =\frac a{-\infty} \end{align}$$  and for $\infty\ge a>0> b\ge -\infty$, $$\begin{align} a\cdot\infty &= \infty \\ a\cdot(-\infty) &= -\infty \\ b\cdot\infty &= -\infty \\ b\cdot(-\infty) &= \infty \\ 0\cdot\infty &=0 = 0\cdot(-\infty).\\ \end{align}$$ All other combinations, like $\infty-\infty$ or $\frac{\infty}{\infty}$, are left undefined. Yes, these all make sense but I just want to know if it fits into any bigger framework? This clearly is not in accordance with ""basics"" algebraic structures that we studied in our undergraduate years. $-\infty$ is not the additive inverse of $\infty$, neither is $\frac a{-\infty}=a\cdot{-\infty}^{-1}$  since ${-\infty}$ does not have a multiplicative inverse. Is there a general theory to this kind of algebraic structure? I am thinking about boolean algebra since $1$ in a boolean algebra also exhibits this kind of `absorbing' behaviour. Since I lack any deep knowledge in the field of algebra, I hope that someone here might be able to give an insight into this. PS. I tagged ""logic"" since I think it looks similar to boolean algebra. Please tell me if this is somehow not appropriate.",,"['real-analysis', 'abstract-algebra', 'measure-theory', 'logic', 'soft-question']"
93,Essential image of sum,Essential image of sum,,"Let $\langle X,\mu\rangle$ be a measure space and for $f\colon X\rightarrow \mathbb{C}$ define $$ \operatorname{Ess\, Im}(f):=\left\{ y\in \mathbb{C}:\mu (f^{-1}(B_{\varepsilon}(y)))>0\text{ for all }\varepsilon >0\text{.}\right\} . $$ (This is the essential image of $f$, also known as the essential range .) Let $f,g\colon X\rightarrow \mathbb{C}$.  As $\operatorname{Im}(f+g)\subseteq \operatorname{Im}(f)+\operatorname{Im}(g)$, I conjectured that also $\operatorname{Ess\, Im}(f+g)\subseteq \operatorname{Ess\, Im}(f)+\operatorname{Ess\, Im}(g)$, but I have found this quite a bit more difficult to prove than I imagined.  How might I go about doing this?","Let $\langle X,\mu\rangle$ be a measure space and for $f\colon X\rightarrow \mathbb{C}$ define $$ \operatorname{Ess\, Im}(f):=\left\{ y\in \mathbb{C}:\mu (f^{-1}(B_{\varepsilon}(y)))>0\text{ for all }\varepsilon >0\text{.}\right\} . $$ (This is the essential image of $f$, also known as the essential range .) Let $f,g\colon X\rightarrow \mathbb{C}$.  As $\operatorname{Im}(f+g)\subseteq \operatorname{Im}(f)+\operatorname{Im}(g)$, I conjectured that also $\operatorname{Ess\, Im}(f+g)\subseteq \operatorname{Ess\, Im}(f)+\operatorname{Ess\, Im}(g)$, but I have found this quite a bit more difficult to prove than I imagined.  How might I go about doing this?",,['measure-theory']
94,Show that this measure theory statement is closed under countable unions,Show that this measure theory statement is closed under countable unions,,"We say that a set $ A \subset [0,1]$ is dyadic-($\epsilon,n$) if for every $\epsilon > 0$ there exist a set $B$ which is the union of dyadic interval $[p/2^n,(p+1)/2^n]$ at scale $2^{-n}$ such that $A$ and $B$ differ on a set of measure less than $\epsilon$. I want to prove the following statement: "" if $A$ is a Lebesgue measurable set, for every $\epsilon > 0$ there exist an integer $n$ such that $A$ is dyadic-($\epsilon,n$)"". I can prove this with a direct proof (regularity of measure and dyadic coverings), but I'm interested in a $\sigma$-albegra constructive proof. To conclude such proof I need to show that the claim (""for every $\epsilon > 0$ there exist an integer $n$ such that $A$ is dyadic-($\epsilon,n$)"") is closed under countable union. Hope now it makes sense. Thank you.","We say that a set $ A \subset [0,1]$ is dyadic-($\epsilon,n$) if for every $\epsilon > 0$ there exist a set $B$ which is the union of dyadic interval $[p/2^n,(p+1)/2^n]$ at scale $2^{-n}$ such that $A$ and $B$ differ on a set of measure less than $\epsilon$. I want to prove the following statement: "" if $A$ is a Lebesgue measurable set, for every $\epsilon > 0$ there exist an integer $n$ such that $A$ is dyadic-($\epsilon,n$)"". I can prove this with a direct proof (regularity of measure and dyadic coverings), but I'm interested in a $\sigma$-albegra constructive proof. To conclude such proof I need to show that the claim (""for every $\epsilon > 0$ there exist an integer $n$ such that $A$ is dyadic-($\epsilon,n$)"") is closed under countable union. Hope now it makes sense. Thank you.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
95,"Borel measurability of ""closest point selection""","Borel measurability of ""closest point selection""",,"Let $(Y,d)$ be a metric space, and let $X \subset Y$. Does there exist a Borel measurable function $\gamma: Y \to X$ such that, for all $y \in Y$, $d(y,\gamma(y)) \leq 2 \inf\{d(y,x) : x \in X\}$? I would be interested in such a selection function with the assumption that $X$ is Borel, or even closed, but I would prefer an answer that works for arbitrary $X$.","Let $(Y,d)$ be a metric space, and let $X \subset Y$. Does there exist a Borel measurable function $\gamma: Y \to X$ such that, for all $y \in Y$, $d(y,\gamma(y)) \leq 2 \inf\{d(y,x) : x \in X\}$? I would be interested in such a selection function with the assumption that $X$ is Borel, or even closed, but I would prefer an answer that works for arbitrary $X$.",,"['real-analysis', 'measure-theory', 'metric-spaces']"
96,Alternative proof : If E and F have positive measures then E+F contains an interval,Alternative proof : If E and F have positive measures then E+F contains an interval,,"The statement is following : $E, F$ are measurable subsets in $\mathbb{R}$ which have positive   measure. Then prove that $E+F=\left\{ x+y\ :\ x\in E,\ y\in F\right\}$    contains an interval. This is a problem 30 in Stein's Real analysis. I already read the proof of this by using convolusion which is here .(This problem is so-called Steinhaus theorem) Moreover, I proved that the previous problems number 28 and 29 in the book.  My goal is applying the same technique to above one, using the technique in problem number 29 : First, by problem number 28, $ \exists I^F$ and $I^E$ such that $$m(E\cap I^{E})\geq{\displaystyle \frac{9}{10}m(I^{E})} \text{ and }  m(F\cap I^{F})\ge{\displaystyle \frac{9}{10}m(I^{F})}.$$ Let $E_{0}= E\cap I^{E}$ and $F_{0}= F\cap I^{F}$ and let $e_{0}, f_{0}$ : center of $I^{E}, I^{F}$, respectively. Suppose $E_{0}+F_{0}$ does not contain an interval centered at $e_{0}+f_{0}$. Then $\exists a$ : small such that $E_{0}\cap(e_{0}+f_{0}+a-F_{0})=\phi$. But, $E_{0}\cup(e_{0}+f_{0}+a-F_{0})\subset I^{E}\cup(e_{0}+f_{0}+a-I^{F})$. Measure of left hand side is more than $\frac{9}{10}(m(I^{E})+m(I^{F}))$ but the measure of Right had side is slightly less than $\max(m(I^{E}),m(I^{F}))$. And that's it. I stopped here. I can't make any contradiction. I thought that if I can make measure of $I^E and I^F$ are equal, then I prove the problem but this one is also a big problem. Anyone can comment on this?","The statement is following : $E, F$ are measurable subsets in $\mathbb{R}$ which have positive   measure. Then prove that $E+F=\left\{ x+y\ :\ x\in E,\ y\in F\right\}$    contains an interval. This is a problem 30 in Stein's Real analysis. I already read the proof of this by using convolusion which is here .(This problem is so-called Steinhaus theorem) Moreover, I proved that the previous problems number 28 and 29 in the book.  My goal is applying the same technique to above one, using the technique in problem number 29 : First, by problem number 28, $ \exists I^F$ and $I^E$ such that $$m(E\cap I^{E})\geq{\displaystyle \frac{9}{10}m(I^{E})} \text{ and }  m(F\cap I^{F})\ge{\displaystyle \frac{9}{10}m(I^{F})}.$$ Let $E_{0}= E\cap I^{E}$ and $F_{0}= F\cap I^{F}$ and let $e_{0}, f_{0}$ : center of $I^{E}, I^{F}$, respectively. Suppose $E_{0}+F_{0}$ does not contain an interval centered at $e_{0}+f_{0}$. Then $\exists a$ : small such that $E_{0}\cap(e_{0}+f_{0}+a-F_{0})=\phi$. But, $E_{0}\cup(e_{0}+f_{0}+a-F_{0})\subset I^{E}\cup(e_{0}+f_{0}+a-I^{F})$. Measure of left hand side is more than $\frac{9}{10}(m(I^{E})+m(I^{F}))$ but the measure of Right had side is slightly less than $\max(m(I^{E}),m(I^{F}))$. And that's it. I stopped here. I can't make any contradiction. I thought that if I can make measure of $I^E and I^F$ are equal, then I prove the problem but this one is also a big problem. Anyone can comment on this?",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'alternative-proof']"
97,Nonatomic measure space over set larger than the reals,Nonatomic measure space over set larger than the reals,,"Question : Does anybody know a non-trivial nonatomic measure space over a set larger of cardinality larger than the reals? By non-trivial I mean that no set exists of cardinality equal to that of the reals, such that the complement is a null set. Background : I try to find a big list of examples of measure spaces, but I find these hard to find. Many examples either have something to do with the Lebesgue measure or are very complicated, so know I try to think of some measure spaces myself. Thank you in advance!","Question : Does anybody know a non-trivial nonatomic measure space over a set larger of cardinality larger than the reals? By non-trivial I mean that no set exists of cardinality equal to that of the reals, such that the complement is a null set. Background : I try to find a big list of examples of measure spaces, but I find these hard to find. Many examples either have something to do with the Lebesgue measure or are very complicated, so know I try to think of some measure spaces myself. Thank you in advance!",,['measure-theory']
98,Folland Real Analysis 7.3,Folland Real Analysis 7.3,,"Let $X$ be the one-point compactification of a set with the discrete topology. If $\mu$ is a Radon measure on $X$, then supp($\mu$) is countable. So if I let $X^*$ be the one-point compactification (which I assume is $X \cup \left\lbrace \infty \right\rbrace $), then my topological space is $(X^*, P(X^*))$. I know two things about the support of $\mu$ from a previous homework problem: 1) $supp(\mu)$ is the complement of $N$ where $N$ is the union of all open $U \in X^*$ with $\mu(U) = 0$. 2) $x \in supp(\mu)$ iff $\int f d\mu > 0$ for every $f \in C_c(X^*, [0,1])$ such that $f(x) > 0$ However, neither of those seem to suggest anything about the countability of the support.  I suppose if I could show there are only countably many $x \in supp(\mu)$ so that condition 2 holds, then that would work. But I don't see any way to do such a thing. Condition 1 seems easier to work with but doesn't seem to involve countability at all","Let $X$ be the one-point compactification of a set with the discrete topology. If $\mu$ is a Radon measure on $X$, then supp($\mu$) is countable. So if I let $X^*$ be the one-point compactification (which I assume is $X \cup \left\lbrace \infty \right\rbrace $), then my topological space is $(X^*, P(X^*))$. I know two things about the support of $\mu$ from a previous homework problem: 1) $supp(\mu)$ is the complement of $N$ where $N$ is the union of all open $U \in X^*$ with $\mu(U) = 0$. 2) $x \in supp(\mu)$ iff $\int f d\mu > 0$ for every $f \in C_c(X^*, [0,1])$ such that $f(x) > 0$ However, neither of those seem to suggest anything about the countability of the support.  I suppose if I could show there are only countably many $x \in supp(\mu)$ so that condition 2 holds, then that would work. But I don't see any way to do such a thing. Condition 1 seems easier to work with but doesn't seem to involve countability at all",,"['real-analysis', 'measure-theory']"
99,Likelihood ratio as Radon-Nikodym derivative,Likelihood ratio as Radon-Nikodym derivative,,"I have a question regarding Exercise 6.11, displayed above. We assume that $\mathbb{P}^{X}(E):=\mathbb{P}(X \in E)$ for $E\in\mathcal{B}^n$. I wanted to prove that last assertion and, by doing the computations backwards, I arrive at \begin{align*} \frac{f(X(\omega))}{g(X(\omega))} &=\left(\frac{f}{g}\right)(X(\omega)) \\ &=\frac{\text{d}\mathbb{P}^X}{\text{d}\mathbb{Q}^X}(X(\omega)) &\text{by 6.10, as $g>0$}\\ &\overset{?}{=}\frac{\text{d}\mathbb{P}}{\text{d}\mathbb{Q}}(\omega). \end{align*} But I am not sure about the last step; it seems a little shaky. For every Borel-set $E$, we have that $$ \mathbb{P}^X(E) = \mathbb{P}(X \in E) = \mathbb{P}\left(X^{-1}(E)\right), $$ so, when $X$ is invertible, we have that $$ \mathbb{P}^X = \mathbb{P} \circ X^{-1}, $$ and hence, by associativity of composition, we have  $$ \mathbb{P}^X \circ X= \left(\mathbb{P} \circ X^{-1}\right) \circ X= \mathbb{P} \circ \left(X^{-1} \circ X\right)=\mathbb{P}, $$ so I believe the 'shaky step' is justified for invertible $X$ (as the same goes for $\mathbb{Q}$), but I do not see why it should hold for every measurable $X$. Can anyone help me with that? Many thanks in advance!","I have a question regarding Exercise 6.11, displayed above. We assume that $\mathbb{P}^{X}(E):=\mathbb{P}(X \in E)$ for $E\in\mathcal{B}^n$. I wanted to prove that last assertion and, by doing the computations backwards, I arrive at \begin{align*} \frac{f(X(\omega))}{g(X(\omega))} &=\left(\frac{f}{g}\right)(X(\omega)) \\ &=\frac{\text{d}\mathbb{P}^X}{\text{d}\mathbb{Q}^X}(X(\omega)) &\text{by 6.10, as $g>0$}\\ &\overset{?}{=}\frac{\text{d}\mathbb{P}}{\text{d}\mathbb{Q}}(\omega). \end{align*} But I am not sure about the last step; it seems a little shaky. For every Borel-set $E$, we have that $$ \mathbb{P}^X(E) = \mathbb{P}(X \in E) = \mathbb{P}\left(X^{-1}(E)\right), $$ so, when $X$ is invertible, we have that $$ \mathbb{P}^X = \mathbb{P} \circ X^{-1}, $$ and hence, by associativity of composition, we have  $$ \mathbb{P}^X \circ X= \left(\mathbb{P} \circ X^{-1}\right) \circ X= \mathbb{P} \circ \left(X^{-1} \circ X\right)=\mathbb{P}, $$ so I believe the 'shaky step' is justified for invertible $X$ (as the same goes for $\mathbb{Q}$), but I do not see why it should hold for every measurable $X$. Can anyone help me with that? Many thanks in advance!",,['measure-theory']
