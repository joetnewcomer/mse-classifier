,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Do there exist intervals in $[0,1]$ of rational numbers?",Do there exist intervals in  of rational numbers?,"[0,1]","Basically I'm struggling to prove that if you take the indicator function $f$ on $\mathbb{Q}$ intersect $[0,1]$ and $\phi, \psi$ are step functions such that $\phi \leq f \leq \psi$ then $\phi \leq 0$ and $\psi \geq 0$ for all but finitely many $x$ As step functions can only be defined on intervals (by my definition I am working with) I'm trying to describe the places where the indicator function is 1 EDIT: so as $\mathbb{Q}$ is a set of discrete points, when we define a step function on $[0,1]$ can we can not find an interval such that the indicator function of $\mathbb{Q}$ intersect $[0,1]$ where it is 1, so can not find anywhere where $\phi > 0$? Unless we can define step functions pointwise?","Basically I'm struggling to prove that if you take the indicator function $f$ on $\mathbb{Q}$ intersect $[0,1]$ and $\phi, \psi$ are step functions such that $\phi \leq f \leq \psi$ then $\phi \leq 0$ and $\psi \geq 0$ for all but finitely many $x$ As step functions can only be defined on intervals (by my definition I am working with) I'm trying to describe the places where the indicator function is 1 EDIT: so as $\mathbb{Q}$ is a set of discrete points, when we define a step function on $[0,1]$ can we can not find an interval such that the indicator function of $\mathbb{Q}$ intersect $[0,1]$ where it is 1, so can not find anywhere where $\phi > 0$? Unless we can define step functions pointwise?",,"['real-analysis', 'measure-theory', 'integration']"
1,Second countability and products of Borel $\sigma$-algebras,Second countability and products of Borel -algebras,\sigma,"We know that the Borel $\sigma$-algebra of the Cartesian product space (with the product topology)  of two topological spaces is equal to the product of the Borel $\sigma$-algebras of the factor spaces. (The product $\sigma$-algebra can be defined via pullbacks of projection maps...) When one upgrades the above statement to a product of a countable family of topological spaces, the analagous result, namely that the Borel $\sigma$-algebra is the the product Borel $\sigma$-algebra, is  conditioned by the topological spaces being second countable. Why? My question is this: how and why does second countability make its appearance when we upgrade the finite product to countable product?  (Second countability means that the base is countable, not just locally...) My difficulty is that I do not see how suddenly second countability is important when we pass from finite to countable products.","We know that the Borel $\sigma$-algebra of the Cartesian product space (with the product topology)  of two topological spaces is equal to the product of the Borel $\sigma$-algebras of the factor spaces. (The product $\sigma$-algebra can be defined via pullbacks of projection maps...) When one upgrades the above statement to a product of a countable family of topological spaces, the analagous result, namely that the Borel $\sigma$-algebra is the the product Borel $\sigma$-algebra, is  conditioned by the topological spaces being second countable. Why? My question is this: how and why does second countability make its appearance when we upgrade the finite product to countable product?  (Second countability means that the base is countable, not just locally...) My difficulty is that I do not see how suddenly second countability is important when we pass from finite to countable products.",,['measure-theory']
2,Total variation distance and mutually singular probability measure,Total variation distance and mutually singular probability measure,,"Let $\mu$ and $\nu$ be two probability measures on $(\Omega,F)$. Let $||\mu-\nu||$ denote the total variation distance between $\mu$ and $\nu$. Show that if $||\mu-\nu||=1$ then the support of $\mu$ and $\nu$ are disjoint. I'm not familiar yet with measure theory. I tried to bound  $$||\mu-\nu||=\mu(A)-\nu(A),A=\{E \in F : \mu(E) \ge \nu(E)\}$$ with something that is less than $1$, but I didn't succeed. I think, it doesn't matter, but if does, we may assume $\Omega$ is finite.","Let $\mu$ and $\nu$ be two probability measures on $(\Omega,F)$. Let $||\mu-\nu||$ denote the total variation distance between $\mu$ and $\nu$. Show that if $||\mu-\nu||=1$ then the support of $\mu$ and $\nu$ are disjoint. I'm not familiar yet with measure theory. I tried to bound  $$||\mu-\nu||=\mu(A)-\nu(A),A=\{E \in F : \mu(E) \ge \nu(E)\}$$ with something that is less than $1$, but I didn't succeed. I think, it doesn't matter, but if does, we may assume $\Omega$ is finite.",,[]
3,Measurability of a function,Measurability of a function,,"I am having a hard time understanding a condition in building a measurable function. This is an example of a measurable function from this book (p. 55). Quoting verbatim: Consider $R_n(\omega)$, the Rademacher functions. These are measurable because they are piecewise constant; namely, for any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$, we have that $\{\omega \in I; R_n(\omega) \in A\}$ is a finite union of intervals. where $I = [0,1]$ and the $n$th Rademacher function \begin{align} R_n(\omega) = \begin{cases} 1 & \textrm{if } a_n = 1 \newline -1 & \textrm{if } a_n = 0 \end{cases} \end{align} and $a_n$ is the $n$th number in the binary expansion of $\omega \in I$. Namely, I don't get the condition placed regarding any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$ If the only values $R_n$ can take are +1 and -1, what's the point in saying that $A$ can be any interval on the extended real line? Isn't it just as valid to state $\{\omega \in I; R_n(\omega) \in \{-1,1\}\}$ and argue that the Rademacher functions are measurable?","I am having a hard time understanding a condition in building a measurable function. This is an example of a measurable function from this book (p. 55). Quoting verbatim: Consider $R_n(\omega)$, the Rademacher functions. These are measurable because they are piecewise constant; namely, for any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$, we have that $\{\omega \in I; R_n(\omega) \in A\}$ is a finite union of intervals. where $I = [0,1]$ and the $n$th Rademacher function \begin{align} R_n(\omega) = \begin{cases} 1 & \textrm{if } a_n = 1 \newline -1 & \textrm{if } a_n = 0 \end{cases} \end{align} and $a_n$ is the $n$th number in the binary expansion of $\omega \in I$. Namely, I don't get the condition placed regarding any subset $A$ of $\mathbb{R} \cup \{+\infty\} \cup \{-\infty\}$ If the only values $R_n$ can take are +1 and -1, what's the point in saying that $A$ can be any interval on the extended real line? Isn't it just as valid to state $\{\omega \in I; R_n(\omega) \in \{-1,1\}\}$ and argue that the Rademacher functions are measurable?",,['measure-theory']
4,Questions about measurable mapping and product sigma algebra,Questions about measurable mapping and product sigma algebra,,"Suppose there are three measurable spaces $(\Omega, \mathbb{F})$, $(S_i,     \mathbb{S}_i), i=1,2$, and two measurable mappings $f_i: \Omega     \rightarrow S_i, i=1,2$. Is the  mapping $f$ defined as $f(\omega):=(f_1(\omega),     f_2(\omega))$ a measurable mapping from $(\Omega, \mathbb{F})$ to $(\prod_{i=1}^2 S_i, \prod_{i=1}^2     \mathbb{S}_i)$, where $\prod_{i=1}^2     \mathbb{S}_i$ is the product sigma algebra of $\mathbb{S}_i, i=1,2$? Suppose there are four measurable spaces $(\Omega_i, \mathbb{F}_i), i=1,2$, $(S_i, \mathbb{S}_i), i=1,2$, and two measurable mappings $f_i:     \Omega_i \rightarrow S_i, i=1,2$. Is the mapping $f$ defined as $f(\omega_1,     \omega_2):=(f_1(\omega_1),     f_2(\omega_2))$ a measurable mapping from $(\prod_{i=1}^2 \Omega_i,     \prod_{i=1}^2 \mathbb{F}_i)$ to $(\prod_{i=1}^2 S_i, \prod_{i=1}^2     \mathbb{S}_i)$? In Part 1 and Part 2, conversely, if $f$ is a measurable mapping, will $f_i, i=1,2$ be measurable mappings? Can the statements in Part 1,2 and 3 be generalized to any collection of $(S_i, \mathbb{S}_i) i     \in I$ and $(\Omega_i, \mathbb{F}_i)     i \in I$? Thanks and regards! Are there some websites or books that address these questions?","Suppose there are three measurable spaces $(\Omega, \mathbb{F})$, $(S_i,     \mathbb{S}_i), i=1,2$, and two measurable mappings $f_i: \Omega     \rightarrow S_i, i=1,2$. Is the  mapping $f$ defined as $f(\omega):=(f_1(\omega),     f_2(\omega))$ a measurable mapping from $(\Omega, \mathbb{F})$ to $(\prod_{i=1}^2 S_i, \prod_{i=1}^2     \mathbb{S}_i)$, where $\prod_{i=1}^2     \mathbb{S}_i$ is the product sigma algebra of $\mathbb{S}_i, i=1,2$? Suppose there are four measurable spaces $(\Omega_i, \mathbb{F}_i), i=1,2$, $(S_i, \mathbb{S}_i), i=1,2$, and two measurable mappings $f_i:     \Omega_i \rightarrow S_i, i=1,2$. Is the mapping $f$ defined as $f(\omega_1,     \omega_2):=(f_1(\omega_1),     f_2(\omega_2))$ a measurable mapping from $(\prod_{i=1}^2 \Omega_i,     \prod_{i=1}^2 \mathbb{F}_i)$ to $(\prod_{i=1}^2 S_i, \prod_{i=1}^2     \mathbb{S}_i)$? In Part 1 and Part 2, conversely, if $f$ is a measurable mapping, will $f_i, i=1,2$ be measurable mappings? Can the statements in Part 1,2 and 3 be generalized to any collection of $(S_i, \mathbb{S}_i) i     \in I$ and $(\Omega_i, \mathbb{F}_i)     i \in I$? Thanks and regards! Are there some websites or books that address these questions?",,['measure-theory']
5,Integration over the unit square,Integration over the unit square,,"Let $f$ be Lebesgue measurable in $[0,1]$ and assume $f$ takes finitely many values. Assuming $f(x) - f(y)$ is Lebesgue measurable in $[0,1] \times [0,1]$ show that $f$ is integrable over $[0,1]$. Stuck for a while with this one. (Not homework, just practice)","Let $f$ be Lebesgue measurable in $[0,1]$ and assume $f$ takes finitely many values. Assuming $f(x) - f(y)$ is Lebesgue measurable in $[0,1] \times [0,1]$ show that $f$ is integrable over $[0,1]$. Stuck for a while with this one. (Not homework, just practice)",,['measure-theory']
6,Proof of the existence of the haar measure for compact group,Proof of the existence of the haar measure for compact group,,"I'm following these notes . In the proof of the Theorem 4 (page 3) there is an inequality that i am not able to verify. Let $G$ a compact group and $V$ an open neighbourhood of the identity. $A$ is called a $V$ -blocking set if $A \cap gVh \neq \emptyset$ for all $g,h \in G$ . For any multi-set $A=\{a_1,\dots,a_n\}$ we define the positive linear functional $L_A:C(G)\to \mathbb{R}$ by $L_A := \frac{1}{n}\sum_{i=0}^n f(a_i)$ . Let $W \subseteq V$ neighbourhoods of the identity. We choose $A$ a $W$ -blocking set and $B$ a $V$ -blocking set (Note that the blocking sets are finite and of minimum cardinality). Let $C=AB$ , then $$|L_Af-L_Cf|\leq \frac{1}{|B|}\sum_{b \in B}|L_Af-L_{Ab}f|.$$ The above inequality is obviously true if $|C|=|A||B|$ , but in general this is not verified. So ot it is the result of  simple algebraic manipulations or maybe we can traslate the blocking sets to have $|C|=|A||B|$ (a traslation of a blocking set is a blocking set and changing the blocking set is not a big deal)","I'm following these notes . In the proof of the Theorem 4 (page 3) there is an inequality that i am not able to verify. Let a compact group and an open neighbourhood of the identity. is called a -blocking set if for all . For any multi-set we define the positive linear functional by . Let neighbourhoods of the identity. We choose a -blocking set and a -blocking set (Note that the blocking sets are finite and of minimum cardinality). Let , then The above inequality is obviously true if , but in general this is not verified. So ot it is the result of  simple algebraic manipulations or maybe we can traslate the blocking sets to have (a traslation of a blocking set is a blocking set and changing the blocking set is not a big deal)","G V A V A \cap gVh \neq \emptyset g,h \in G A=\{a_1,\dots,a_n\} L_A:C(G)\to \mathbb{R} L_A := \frac{1}{n}\sum_{i=0}^n f(a_i) W \subseteq V A W B V C=AB |L_Af-L_Cf|\leq \frac{1}{|B|}\sum_{b \in B}|L_Af-L_{Ab}f|. |C|=|A||B| |C|=|A||B|","['measure-theory', 'harmonic-analysis', 'locally-compact-groups']"
7,Proving that restriction of $\sigma$-algebra is a $\sigma$-algebra,Proving that restriction of -algebra is a -algebra,\sigma \sigma,"Let $X$ be a set and $\Sigma$ be a $\sigma$ -algebra of $X$ . Show that $\Sigma \cap A = \{E \cap A: E \in \Sigma \}$ is a $\sigma$ -algebra of $X$ My attempt actually showed that this is impossible: Suppose $F \in \Sigma \cap A$ and that $\Sigma \cap A$ is a $\sigma$ -algebra of $X$ , then $F = E \cap A$ for some $E \in \Sigma$ . Since $\Sigma \cap A$ is a $\sigma$ -algebra, we have that $F^c \in \Sigma \cap A$ , but that means $F^c=E^c \cup A^c=G \cap A$ , for some $G \in \Sigma$ . Thus: $A^c \subset E^c \cup A^c \subset G \cap A \subset A$ , which is impossible. Could you guys help me find my mistake? Thank you","Let be a set and be a -algebra of . Show that is a -algebra of My attempt actually showed that this is impossible: Suppose and that is a -algebra of , then for some . Since is a -algebra, we have that , but that means , for some . Thus: , which is impossible. Could you guys help me find my mistake? Thank you",X \Sigma \sigma X \Sigma \cap A = \{E \cap A: E \in \Sigma \} \sigma X F \in \Sigma \cap A \Sigma \cap A \sigma X F = E \cap A E \in \Sigma \Sigma \cap A \sigma F^c \in \Sigma \cap A F^c=E^c \cup A^c=G \cap A G \in \Sigma A^c \subset E^c \cup A^c \subset G \cap A \subset A,['measure-theory']
8,Show that $ \mu(A_{i_1}\cap A_{i_2}\cap\dots \cap A_{i_k})>c^k-\epsilon $,Show that, \mu(A_{i_1}\cap A_{i_2}\cap\dots \cap A_{i_k})>c^k-\epsilon ,"Let $((0,1], \mathcal{B},\mu)$ be a measure space. Let $\{A_i\}_{i\ge 1}$ be a sequence of Borel measurable sets so that $\mu(A_i)\ge c$ for all $i\ge 1$ and some universal constants $c\in (0,1)$ . Show that for all $k=1,2,3,\dots$ and $\epsilon>0$ , there exists $i_1<i_2<\dots<i_k$ so that $$ \mu(A_{i_1}\cap A_{i_2}\cap\dots \cap A_{i_k})>c^k-\epsilon $$ I am stuck on this question. I try to upper bound $$ (\sum_{i=1}^n \mu(A_i))^k $$ for some $n\ge 1$ ... I also try to specific case $k=2$ : to show that $$ \mu(A_{i_1}\cap A_{i_2})>c^2-\epsilon $$ We have $$ \mu((A_{i_1}\cap A_{i_2})^c)=\mu(A_{i_1}^c\cup A_{i_2}^c)\le \mu(A_{i_1}^c)+\mu(A_{i_2}^c)\le 2(1-c) $$ So $$ \mu(A_{i_1}\cap A_{i_2})\ge 1-2(1-c)=2c-1 $$","Let be a measure space. Let be a sequence of Borel measurable sets so that for all and some universal constants . Show that for all and , there exists so that I am stuck on this question. I try to upper bound for some ... I also try to specific case : to show that We have So","((0,1], \mathcal{B},\mu) \{A_i\}_{i\ge 1} \mu(A_i)\ge c i\ge 1 c\in (0,1) k=1,2,3,\dots \epsilon>0 i_1<i_2<\dots<i_k 
\mu(A_{i_1}\cap A_{i_2}\cap\dots \cap A_{i_k})>c^k-\epsilon
 
(\sum_{i=1}^n \mu(A_i))^k
 n\ge 1 k=2 
\mu(A_{i_1}\cap A_{i_2})>c^2-\epsilon
 
\mu((A_{i_1}\cap A_{i_2})^c)=\mu(A_{i_1}^c\cup A_{i_2}^c)\le \mu(A_{i_1}^c)+\mu(A_{i_2}^c)\le 2(1-c)
 
\mu(A_{i_1}\cap A_{i_2})\ge 1-2(1-c)=2c-1
","['probability', 'measure-theory']"
9,Does the strict inequality in the Layer Cake Representation Matter?,Does the strict inequality in the Layer Cake Representation Matter?,,"I have seen both version of layer cake representation theorem stated: Let $(\Omega, \Sigma, \mu)$ be a $\sigma$ -finite measure space $f: \Omega \to [0, \infty]$ -measurable function. Then the function $x \in [0, \infty] \to \mu(\{ \omega: f(\omega) > x \})$ is Borel measurable and (Version 1) $$ \int_\Omega f \,d\mu = \int_0 ^\infty \mu(\{ \omega: f(\omega) > x \}) \,dx. $$ or (Version 2) $$ \int_\Omega f \,d\mu = \int_0 ^\infty \mu(\{ \omega: f(\omega) \geq x \}) \,dx. $$ Now going through the proof, which is just a simply application of Fubini's, I think we can conclude both of the versions to be correct (?) as Lebesgue measures have point mass zero. I wonder if I could get some confirmation on if this is true: I will write the proof for the weak inequality here, one can imagine substituting strict inequality everywhere and it seems like everything should go through? $$ \int_0^\infty f(x) d \mu(x)  = \int_0^\infty \int_0^\infty \mathbb{1}_{[0, f(x)]}(t) dt d \mu(x) = \int_0^\infty \int_0^\infty \mathbb{1}_{f(x) \geq t}(x) d \mu (x) dt = \int_0^\infty \mu \left ( \{ x : f(x) \geq t \} \right ) dt. $$ Now if this was the case , then it seems to suggest if $f$ is integrable, we must have $$ \mu(\{ \omega: f(\omega) \geq x \}) = \mu(\{ \omega: f(\omega) > x \}) $$ for Lebesgue almost every $x$ , which seems to be a nice little corollary, but I wonder if there is a better way to show this instead of invoking the Layer cake representation? Update: This is my attempt of a proof for the second question and I wonder if I could get some suggestions on if the proof is correct: Note that for Lebesgue almost every $x \geq 0$ , we have $\mu(\{ \omega: f(\omega) > x \}) = \mu(\{ \omega: f(\omega) \geq x \})$ . To see this, it suffices to note $\mu(\{ \omega: f(\omega) = x \}) > 0$ for at most countably many $x \geq 0$ . The function $x \mapsto \mu(\{ \omega: f(\omega) > x \})$ is a monotone function as $x_1 \geq x_2 \implies \mu(\{ \omega: f(\omega) > x_1 \}) \leq \mu(\{ \omega: f(\omega) > x_2 \})$ . Therefore, the function $x \mapsto \mu(\{ \omega: f(\omega) > x \})$ has at most countably many jump discontinuities. In particular, note if $\mu(\{ \omega: f(\omega) = x' \}) > 0$ for some $x'$ , then $x \mapsto \mu(\{ \omega: f(\omega) > x \})$ has a jump discontinuity at $x'$ . Indeed, let $x_n \to x'$ from the left hand side increasing. Let $\{ A_k \}_{k = 1} ^\infty$ be increasing sequence of $\mu$ -finite set from $\sigma$ -finiteness. Choose $k$ large enough so that $A_k \cap \{ \omega: f(\omega) > x' \} \not= \emptyset$ . Then $$ \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \} \cap A_k) = \mu(\{ \omega: f(\omega) \geq x' \} \cap A_k). $$ Moreover, let $x_n' \to x'$ from the right hand side decreasing, then $$ \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n' \}) = \mu(\{ \omega: f(\omega) > x' \}). $$ Therefore, we have that \begin{align*}     \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \}) &= \lim_{k \to \infty}\lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \} \cap A_k) \\     &= \mu(\{ \omega: f(\omega) \geq x' \}) \\     &> \mu(\{ \omega: f(\omega) > x' \}) \\     &= \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n' \}). \end{align*} Note this shows that $x'$ is a point of jump discontinuity. In particular, we then must have $\mu(\{ \omega: f(\omega) > x \}) = \mu(\{ \omega: f(\omega) \geq x \})$ for Lebesgue almost every $x$ as it must be except from at most countably many points from the above discussion.","I have seen both version of layer cake representation theorem stated: Let be a -finite measure space -measurable function. Then the function is Borel measurable and (Version 1) or (Version 2) Now going through the proof, which is just a simply application of Fubini's, I think we can conclude both of the versions to be correct (?) as Lebesgue measures have point mass zero. I wonder if I could get some confirmation on if this is true: I will write the proof for the weak inequality here, one can imagine substituting strict inequality everywhere and it seems like everything should go through? Now if this was the case , then it seems to suggest if is integrable, we must have for Lebesgue almost every , which seems to be a nice little corollary, but I wonder if there is a better way to show this instead of invoking the Layer cake representation? Update: This is my attempt of a proof for the second question and I wonder if I could get some suggestions on if the proof is correct: Note that for Lebesgue almost every , we have . To see this, it suffices to note for at most countably many . The function is a monotone function as . Therefore, the function has at most countably many jump discontinuities. In particular, note if for some , then has a jump discontinuity at . Indeed, let from the left hand side increasing. Let be increasing sequence of -finite set from -finiteness. Choose large enough so that . Then Moreover, let from the right hand side decreasing, then Therefore, we have that Note this shows that is a point of jump discontinuity. In particular, we then must have for Lebesgue almost every as it must be except from at most countably many points from the above discussion.","(\Omega, \Sigma, \mu) \sigma f: \Omega \to [0, \infty] x \in [0, \infty] \to \mu(\{ \omega: f(\omega) > x \}) 
\int_\Omega f \,d\mu = \int_0 ^\infty \mu(\{ \omega: f(\omega) > x \}) \,dx.
 
\int_\Omega f \,d\mu = \int_0 ^\infty \mu(\{ \omega: f(\omega) \geq x \}) \,dx.
 
\int_0^\infty f(x) d \mu(x) 
= \int_0^\infty \int_0^\infty \mathbb{1}_{[0, f(x)]}(t) dt d \mu(x)
= \int_0^\infty \int_0^\infty \mathbb{1}_{f(x) \geq t}(x) d \mu (x) dt
= \int_0^\infty \mu \left ( \{ x : f(x) \geq t \} \right ) dt.
 f 
\mu(\{ \omega: f(\omega) \geq x \}) = \mu(\{ \omega: f(\omega) > x \})
 x x \geq 0 \mu(\{ \omega: f(\omega) > x \}) = \mu(\{ \omega: f(\omega) \geq x \}) \mu(\{ \omega: f(\omega) = x \}) > 0 x \geq 0 x \mapsto \mu(\{ \omega: f(\omega) > x \}) x_1 \geq x_2 \implies \mu(\{ \omega: f(\omega) > x_1 \}) \leq \mu(\{ \omega: f(\omega) > x_2 \}) x \mapsto \mu(\{ \omega: f(\omega) > x \}) \mu(\{ \omega: f(\omega) = x' \}) > 0 x' x \mapsto \mu(\{ \omega: f(\omega) > x \}) x' x_n \to x' \{ A_k \}_{k = 1} ^\infty \mu \sigma k A_k \cap \{ \omega: f(\omega) > x' \} \not= \emptyset 
\lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \} \cap A_k) = \mu(\{ \omega: f(\omega) \geq x' \} \cap A_k).
 x_n' \to x' 
\lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n' \}) = \mu(\{ \omega: f(\omega) > x' \}).
 \begin{align*}
    \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \}) &= \lim_{k \to \infty}\lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n \} \cap A_k) \\
    &= \mu(\{ \omega: f(\omega) \geq x' \}) \\
    &> \mu(\{ \omega: f(\omega) > x' \}) \\
    &= \lim_{n \to \infty} \mu(\{ \omega: f(\omega) > x_n' \}).
\end{align*} x' \mu(\{ \omega: f(\omega) > x \}) = \mu(\{ \omega: f(\omega) \geq x \}) x","['real-analysis', 'measure-theory', 'solution-verification']"
10,weak closedness of a set with bounded functions,weak closedness of a set with bounded functions,,"Let $A$ be a compact topological space equipped with the Borel $\sigma$ -algebra, and $X=B_b(A)$ be the vector space of bounded   measurable functions. Let $Y=\mathcal M(A)$ be the vector space of finite signed measure on $A$ . Define the dual pair $<\cdot, \cdot>$ between $(X,Y)$ such that $ <f, \mu >=\int_A f(a)\mu(da) $ . Let $\sigma(X,Y)$ be the weakest topology such that for all $\mu\in Y$ , the linear map $X\ni f\mapsto <f,\mu>\in \mathbb R$ is continuous. Define the set $U=\{f\in X\mid \sup_{a\in A}|f(a)|\ge 1\}$ . Is the set $U$ closed in the $\sigma(X,Y)$ topology? I am not sure how to proceed to prove or disprove the claim.","Let be a compact topological space equipped with the Borel -algebra, and be the vector space of bounded   measurable functions. Let be the vector space of finite signed measure on . Define the dual pair between such that . Let be the weakest topology such that for all , the linear map is continuous. Define the set . Is the set closed in the topology? I am not sure how to proceed to prove or disprove the claim.","A \sigma X=B_b(A) Y=\mathcal M(A) A <\cdot, \cdot> (X,Y) 
<f, \mu >=\int_A f(a)\mu(da)
 \sigma(X,Y) \mu\in Y X\ni f\mapsto <f,\mu>\in \mathbb R U=\{f\in X\mid \sup_{a\in A}|f(a)|\ge 1\} U \sigma(X,Y)","['general-topology', 'measure-theory', 'weak-convergence']"
11,What category is this? (Objects are sets and distinguished subsets of power set),What category is this? (Objects are sets and distinguished subsets of power set),,"Let $\mathcal{C}$ be the category whose objects are sets $X$ equipped with distinguished subsets of the associated power set $\mathcal{U}_X \subset \mathcal{P}(X)$ , so that their union is all of $X$ (i.e. $\bigcup\limits_{U \in \mathcal{U}_X} U = X$ ). morphisms $(X, \mathcal{U}_X) \xrightarrow{f} (Y, \mathcal{U}_Y)$ are set functions $f: X \to Y$ so that for each element $V \in \mathcal{U}_Y$ the inverse image under $f$ is in $\mathcal{U}_X$ (i.e. $f^*: \mathcal{U}_Y \to \mathcal{U}_X$ is a function) We know that the categories $Top$ of topological spaces and continuous functions as well as $Meas$ of sets with sigma algebras and measurable functions between them are full sub categories of this category. Is there a common name for $\mathcal{C}$ ?","Let be the category whose objects are sets equipped with distinguished subsets of the associated power set , so that their union is all of (i.e. ). morphisms are set functions so that for each element the inverse image under is in (i.e. is a function) We know that the categories of topological spaces and continuous functions as well as of sets with sigma algebras and measurable functions between them are full sub categories of this category. Is there a common name for ?","\mathcal{C} X \mathcal{U}_X \subset \mathcal{P}(X) X \bigcup\limits_{U \in \mathcal{U}_X} U = X (X, \mathcal{U}_X) \xrightarrow{f} (Y, \mathcal{U}_Y) f: X \to Y V \in \mathcal{U}_Y f \mathcal{U}_X f^*: \mathcal{U}_Y \to \mathcal{U}_X Top Meas \mathcal{C}","['general-topology', 'measure-theory', 'category-theory', 'terminology']"
12,Non-zero measure sets that are stable under composition,Non-zero measure sets that are stable under composition,,"Throughout this question when I talk about relations, I am referring to relations on $\mathbb{R}$ , i.e. subsets of $\mathbb{R}^2$ One of the first examples given when the topic of composition of relations is discussed, is that of the composition of a circle with itself. This is a circle: And this is what you get when you compose the circle with itself (if the circle were represented by the relation $C=\{(x,y):x^2+y^2=1\}$ , then this is $C\circ C$ ) So the circle is not stable under composition. And neither is the unit disc. The unit square however, is. Below is its graph: Another relation which is stable under composition is the diagonal, i.e. the relation $$D = \{(x,x)|x\in \mathbb{R}\}$$ And of course the entire $\mathbb{R}^2$ . Now we have already found one relation whose graph has non-zero finite measure, and which is stable under composition, namely the unit square. Are all such relations simply the unions of squares with their diagonals lying on the main diagonal? or is there some other non-trivial non-zero measure region which has this property?","Throughout this question when I talk about relations, I am referring to relations on , i.e. subsets of One of the first examples given when the topic of composition of relations is discussed, is that of the composition of a circle with itself. This is a circle: And this is what you get when you compose the circle with itself (if the circle were represented by the relation , then this is ) So the circle is not stable under composition. And neither is the unit disc. The unit square however, is. Below is its graph: Another relation which is stable under composition is the diagonal, i.e. the relation And of course the entire . Now we have already found one relation whose graph has non-zero finite measure, and which is stable under composition, namely the unit square. Are all such relations simply the unions of squares with their diagonals lying on the main diagonal? or is there some other non-trivial non-zero measure region which has this property?","\mathbb{R} \mathbb{R}^2 C=\{(x,y):x^2+y^2=1\} C\circ C D = \{(x,x)|x\in \mathbb{R}\} \mathbb{R}^2","['measure-theory', 'relations', 'function-and-relation-composition']"
13,Intersection of a filter of clopen sets is of pozitive measure?,Intersection of a filter of clopen sets is of pozitive measure?,,"Let $X$ nonempty set and $\tau$ a compact topology on it. Let $\mu$ be a measure on the Borel $\sigma $ - algebra of $\tau$ . Suppose we have a filter $\mathcal{F}$ of clopen sets such that $\mu(f)\geq0.5$ for each $f\in \mathcal{F}$ . Is it true that \begin{equation} \mu \left(\bigcap_{f\in \mathcal{F}} f \right)\geq 0.5 ? \end{equation} or maybe just \begin{equation} \mu\left(\bigcap_{f\in \mathcal{F}} f \right)>0 ? \end{equation} But if $\tau$ is zero dimensional and compact(a Boolean space) are any of the above true? For $\mu$ regular and the topology is a Boolean Space, I am able to prove this, but is interesting if it works for $\mu$ any finite measure.","Let nonempty set and a compact topology on it. Let be a measure on the Borel - algebra of . Suppose we have a filter of clopen sets such that for each . Is it true that or maybe just But if is zero dimensional and compact(a Boolean space) are any of the above true? For regular and the topology is a Boolean Space, I am able to prove this, but is interesting if it works for any finite measure.","X \tau \mu \sigma  \tau \mathcal{F} \mu(f)\geq0.5 f\in \mathcal{F} \begin{equation}
\mu \left(\bigcap_{f\in \mathcal{F}} f \right)\geq 0.5 ?
\end{equation} \begin{equation}
\mu\left(\bigcap_{f\in \mathcal{F}} f \right)>0 ?
\end{equation} \tau \mu \mu","['general-topology', 'measure-theory', 'filters']"
14,Showing that a set similar to Cantor set has complement with measure one,Showing that a set similar to Cantor set has complement with measure one,,"Consider the Cantor set $C$ . Define a new ""Cantor"" set which we will call $C_\alpha$ for $\alpha \in (0,1)$ . We construct $C_\alpha$ by letting $C_0 = [0,1]$ , $C_1 = C_0$ but with an open interval of length $\alpha$ taken out of the center. Define $C_2$ by taking $C_1$ and taking out of each remaining half an interval of length $b \cdot \alpha$ where $b$ is the length of one of the remaining halves in $C_2$ . Continue in this manner for all sets $C_k$ with $k \in \mathbb{N}$ . Then we create our new ""Cantor"" set $C_\alpha$ by taking $C_\alpha = \displaystyle\bigcap_{i=0}^\infty C_i$ . I seek to show that the complement of $C_\alpha$ in the unit interval $[0,1]$ has measure $1$ (Notation: when I write $C_i^c$ , I mean with respect to $[0,1]$ , not all of $\mathbb{R}$ ). First, note that $|C_0^c| = 0, |C_1^c| = \alpha, |C_2^c| = 2\alpha^2$ . In general, we will see that $|C_k^c| = 2^{k-1}\alpha^k$ . Then I obtain $$\displaystyle\sum_{i=0}^\infty |C_i^c| = \displaystyle\sum_{i=0}^\infty 2^{k-1}\alpha^k = \frac{1}{2} \displaystyle\sum_{i=0}^\infty (2\alpha)^k = \dots ?$$ At this point, I get stuck because I want to eventually use $\displaystyle\sum_{k=0}^\infty x^k = \frac{1}{1-x}$ for $|x| < 1$ since I suspect that is the way to do this, but I cannot be sure that $|2\alpha| < 1$ . In fact, this won't be true for all $\alpha \in (0,1)$ whenever $\alpha \geq \frac{1}{2}$ . Any suggestions on where I should go? I'm trying to show that $\displaystyle\sum_{i=0}^\infty |C_i^c|  =1$ .","Consider the Cantor set . Define a new ""Cantor"" set which we will call for . We construct by letting , but with an open interval of length taken out of the center. Define by taking and taking out of each remaining half an interval of length where is the length of one of the remaining halves in . Continue in this manner for all sets with . Then we create our new ""Cantor"" set by taking . I seek to show that the complement of in the unit interval has measure (Notation: when I write , I mean with respect to , not all of ). First, note that . In general, we will see that . Then I obtain At this point, I get stuck because I want to eventually use for since I suspect that is the way to do this, but I cannot be sure that . In fact, this won't be true for all whenever . Any suggestions on where I should go? I'm trying to show that .","C C_\alpha \alpha \in (0,1) C_\alpha C_0 = [0,1] C_1 = C_0 \alpha C_2 C_1 b \cdot \alpha b C_2 C_k k \in \mathbb{N} C_\alpha C_\alpha = \displaystyle\bigcap_{i=0}^\infty C_i C_\alpha [0,1] 1 C_i^c [0,1] \mathbb{R} |C_0^c| = 0, |C_1^c| = \alpha, |C_2^c| = 2\alpha^2 |C_k^c| = 2^{k-1}\alpha^k \displaystyle\sum_{i=0}^\infty |C_i^c| = \displaystyle\sum_{i=0}^\infty 2^{k-1}\alpha^k = \frac{1}{2} \displaystyle\sum_{i=0}^\infty (2\alpha)^k = \dots ? \displaystyle\sum_{k=0}^\infty x^k = \frac{1}{1-x} |x| < 1 |2\alpha| < 1 \alpha \in (0,1) \alpha \geq \frac{1}{2} \displaystyle\sum_{i=0}^\infty |C_i^c|  =1","['real-analysis', 'measure-theory', 'cantor-set']"
15,Is $X$ adapted not sufficient for measurability of $X_T$ in $\mathcal F_T$ (the σ-algebra of a stopping time)?,Is  adapted not sufficient for measurability of  in  (the σ-algebra of a stopping time)?,X X_T \mathcal F_T,"Let $X$ be a stochastic process in continuous time and $T$ be a stopping time. All the standard texts I've looked at so far, as well as this excellent blog , introduce the assumption that $X$ is progressively measurable to prove that $X_T$ is $\mathcal F_T$ -measurable. Why is merely adapted $X$ not enough? Indeed the proof in the linked article seems to use ""progressive"" solely to claim ""adapted"" for the conclusion.","Let be a stochastic process in continuous time and be a stopping time. All the standard texts I've looked at so far, as well as this excellent blog , introduce the assumption that is progressively measurable to prove that is -measurable. Why is merely adapted not enough? Indeed the proof in the linked article seems to use ""progressive"" solely to claim ""adapted"" for the conclusion.",X T X X_T \mathcal F_T X,"['measure-theory', 'stochastic-processes', 'stopping-times']"
16,"Showing that $(x,r) \mapsto A_r f(x)$ is continuous",Showing that  is continuous,"(x,r) \mapsto A_r f(x)","I am studying Measure Theory from these notes . The author passes off the fact that the function $(x,r)\mapsto A_r f(x)$ is continuous where $f$ is locally integrable function as something easy. Here's the context: Here's my attempt at proving this: Let $f\in L^{1}_{loc} \left( m_{n} \right)$ . Consider the map $F: \mathbb R^{n} \times (0, \infty) \to \mathbb R$ given by $F(x,r)=A_r f(x)$ for each $(x,r) \in \mathbb R ^{n} \times (0, \infty)$ . We need to show that this map is continuous. Let $(x,r)\in \mathbb R^{n} \times (0, \infty)$ and let $\left( x_{n}, r_{n} \right)$ be a sequence in $\mathbb R ^{n} \times (0,\infty)$ converging to $(x,r)$ . We wish to show that $A_{r_n} f(x_n) \to A_r f(x)$ . We first show that $\int_{B(x_{n}, r_{n})} f(y) dy \to \int_{B(x,r)} f(y) dy$ (Call it goal $(\star)$ ). Since the sequence $\left( x_n, r_{n} \right)$ converges, it must be bounded. Therefore, there exists a constant $K>0$ such that $\lVert(x_n, r_n)\rVert_{2}<K$ for each $n \in \mathbb N$ . Hence, we have that $(x_{n}, r_{n}) \in B[0, K]$ for each $n \in \mathbb N$ . Now, note that $|f\chi_{B(x_{n}, r_{n})}| \le |f\chi_{B[0,K]}|$ for each $n\in \mathbb N$ and $f\chi_{B[0,K]}$ is in $L^{1} \left( m_{n} \right)$ by our assumption that it is locally integrable. We now show that $\chi_{B(x_{n}, r_n)}  \to \chi_{B(x,r)}$ pointwise. Let $y \in B(x,r)$ . Then we have that $\chi_{B(x,r)}(y)=1$ and hence we need to show that $\chi_{B\left( x_{n},r_{n} \right)} =1$ eventually. To see this, consider the sequences $|y-x_{n}|$ and $r_n$ . Since $|y-x_{n}| \to |y-x|$ , $r_n \to r$ and $|y-x|<r$ , we have that $|y-x_n|<r_n$ eventually. This shows that $\chi_{B(x_{n}, r_{n})}(y)=1$ eventually. A similar argument shows that if $y\not\in B(x,r)$ then $y\not\in B(x_{n},r_n)$ eventually. Hence, we have that $f\chi_{B(x_{n},r_{n})} \to f\chi_{B(x,r)}$ pointwise. Since we meet all the requirements to apply the dominated convergence, we do so to conclude $(\star)$ . Since $r_{n} \to r$ , we have that $\limsup_{n\in \mathbb N} B(0,r_{n})=\liminf_{n\in \mathbb N} B(0,r_n) = B(0,r)$ . Hence, we have by continuity of measures that $\lim_{k\in \mathbb N} m_{n} \left( B(0,r_{k}) \right) = m_{n} \left( B(0,r) \right)$ . Also, since Lebesgue measure is translation invariant, we have that $\lim_{k\in \mathbb N} m_{n} \left( B(x_k,r_{k}) \right) = m_{n} \left( B(x,r) \right)$ . Using these two facts, we have shown that $(x,r) \mapsto A_{r} f(x)$ is continuous. Although I think my argument is correct, I feel there must be easier way to prove this else the author would not have skipped the proof. I would appreciate it if people can offer an alternative and shorter proof of this.","I am studying Measure Theory from these notes . The author passes off the fact that the function is continuous where is locally integrable function as something easy. Here's the context: Here's my attempt at proving this: Let . Consider the map given by for each . We need to show that this map is continuous. Let and let be a sequence in converging to . We wish to show that . We first show that (Call it goal ). Since the sequence converges, it must be bounded. Therefore, there exists a constant such that for each . Hence, we have that for each . Now, note that for each and is in by our assumption that it is locally integrable. We now show that pointwise. Let . Then we have that and hence we need to show that eventually. To see this, consider the sequences and . Since , and , we have that eventually. This shows that eventually. A similar argument shows that if then eventually. Hence, we have that pointwise. Since we meet all the requirements to apply the dominated convergence, we do so to conclude . Since , we have that . Hence, we have by continuity of measures that . Also, since Lebesgue measure is translation invariant, we have that . Using these two facts, we have shown that is continuous. Although I think my argument is correct, I feel there must be easier way to prove this else the author would not have skipped the proof. I would appreciate it if people can offer an alternative and shorter proof of this.","(x,r)\mapsto A_r f(x) f f\in L^{1}_{loc} \left( m_{n} \right) F: \mathbb R^{n} \times (0, \infty) \to \mathbb R F(x,r)=A_r f(x) (x,r) \in \mathbb R ^{n} \times (0, \infty) (x,r)\in \mathbb R^{n} \times (0, \infty) \left( x_{n}, r_{n} \right) \mathbb R ^{n} \times (0,\infty) (x,r) A_{r_n} f(x_n) \to A_r f(x) \int_{B(x_{n}, r_{n})} f(y) dy \to \int_{B(x,r)} f(y) dy (\star) \left( x_n, r_{n} \right) K>0 \lVert(x_n, r_n)\rVert_{2}<K n \in \mathbb N (x_{n}, r_{n}) \in B[0, K] n \in \mathbb N |f\chi_{B(x_{n}, r_{n})}| \le |f\chi_{B[0,K]}| n\in \mathbb N f\chi_{B[0,K]} L^{1} \left( m_{n} \right) \chi_{B(x_{n}, r_n)}  \to \chi_{B(x,r)} y \in B(x,r) \chi_{B(x,r)}(y)=1 \chi_{B\left( x_{n},r_{n} \right)} =1 |y-x_{n}| r_n |y-x_{n}| \to |y-x| r_n \to r |y-x|<r |y-x_n|<r_n \chi_{B(x_{n}, r_{n})}(y)=1 y\not\in B(x,r) y\not\in B(x_{n},r_n) f\chi_{B(x_{n},r_{n})} \to f\chi_{B(x,r)} (\star) r_{n} \to r \limsup_{n\in \mathbb N} B(0,r_{n})=\liminf_{n\in \mathbb N} B(0,r_n) = B(0,r) \lim_{k\in \mathbb N} m_{n} \left( B(0,r_{k}) \right) = m_{n} \left( B(0,r) \right) \lim_{k\in \mathbb N} m_{n} \left( B(x_k,r_{k}) \right) = m_{n} \left( B(x,r) \right) (x,r) \mapsto A_{r} f(x)","['real-analysis', 'measure-theory', 'lp-spaces', 'alternative-proof']"
17,"Convergence a.e. of $\sum_{n=1}^{\infty} \frac{a_n}{\sqrt{\left|x-r_n\right|}}$, where $\sum_{n=1}^{\infty}\left|a_n\right|<\infty$","Convergence a.e. of , where",\sum_{n=1}^{\infty} \frac{a_n}{\sqrt{\left|x-r_n\right|}} \sum_{n=1}^{\infty}\left|a_n\right|<\infty,"Let $\left\{a_n\right\}_{n=1}^{\infty}$ and $\left\{r_n\right\}_{n=1}^{\infty}$ two sequences of real numbers, and suppose that: (i) $\sum_{n=1}^{\infty}\left|a_n\right|<\infty$ ; (ii) $r_i \neq r_j$ for all $i \neq j$ . Prove that the series $$ \sum_{n=1}^{\infty} \frac{a_n}{\sqrt{\left|x-r_n\right|}} $$ converges absolutely Lebesgue almost everywhere on $\mathbb{R}$ . I tried to compute, for each $n\geq1$ , $$\int_{\mathbb{R}} \frac{a_n}{\sqrt{\lvert x-r_n \rvert}}dx, $$ but this integral is divergent, so I'm out of ideas. Any hints?","Let and two sequences of real numbers, and suppose that: (i) ; (ii) for all . Prove that the series converges absolutely Lebesgue almost everywhere on . I tried to compute, for each , but this integral is divergent, so I'm out of ideas. Any hints?","\left\{a_n\right\}_{n=1}^{\infty} \left\{r_n\right\}_{n=1}^{\infty} \sum_{n=1}^{\infty}\left|a_n\right|<\infty r_i \neq r_j i \neq j 
\sum_{n=1}^{\infty} \frac{a_n}{\sqrt{\left|x-r_n\right|}}
 \mathbb{R} n\geq1 \int_{\mathbb{R}} \frac{a_n}{\sqrt{\lvert x-r_n \rvert}}dx, ","['integration', 'sequences-and-series', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
18,Help with Theorem 2.9.7 from Federer's Geometric Measure Theory,Help with Theorem 2.9.7 from Federer's Geometric Measure Theory,,"Suppose $\phi$ and $\psi$ are Borel regular measures (outer measures) on a metric space $X$ such that $\phi(A),\psi(A)<\infty$ for every bounded subset $A\subseteq X$ . One defines a Borel regular measure $$\psi_{\phi}(A)=\inf \{ \psi(B) \, ; \, B \, \text{is a Borel set and} \, \phi(A-B)=0 \}$$ whenever $A\subseteq X$ . The first step in the proof of Theorem 2.9.7 is to show that if $A\subseteq X$ is $\phi$ -measurable then it is also $\psi_{\phi}$ -measurable. It's clear to me that $A$ is contained in a Borel set $B$ such that $\phi(B-A)=0$ , but why does this imply $\psi_{\phi}(B-A)=0$ ? Any help would be appreciated.","Suppose and are Borel regular measures (outer measures) on a metric space such that for every bounded subset . One defines a Borel regular measure whenever . The first step in the proof of Theorem 2.9.7 is to show that if is -measurable then it is also -measurable. It's clear to me that is contained in a Borel set such that , but why does this imply ? Any help would be appreciated.","\phi \psi X \phi(A),\psi(A)<\infty A\subseteq X \psi_{\phi}(A)=\inf \{ \psi(B) \, ; \, B \, \text{is a Borel set and} \, \phi(A-B)=0 \} A\subseteq X A\subseteq X \phi \psi_{\phi} A B \phi(B-A)=0 \psi_{\phi}(B-A)=0","['real-analysis', 'measure-theory', 'geometric-measure-theory', 'outer-measure', 'borel-measures']"
19,Is this subset of a closed set Borel measurable?,Is this subset of a closed set Borel measurable?,,"Let $V \subset [0,\infty)^n$ be closed. I've been studying the following subset of $V$ for research, which has useful properties, but cannot prove or disprove it is Borel measurable. Introduce the partial ordering $\leq'$ on $[0,\infty)^n$ such that $(x_1,...,x_n) \leq' (y_1,...y_n) \iff x_k \leq y_k, \forall k$ . Consider the set $W$ of minimal elements of $V$ under $\leq'$ . That is, $$ W = \big\{ x \in V \ \big| \ \nexists y\in V, y<'x\big\}. $$ One can easily show that $W \subset \partial V$ and if $V \neq \emptyset$ then $W \neq \emptyset$ (with Zorn's lemma). I have been wondering how to prove/disprove $W$ is Borel measurable for months, gave up, and settled with taking its closure only to make it Borel measurable (if the set were measurable, everything would work out nicely). I believe this set is Borel measurable and that $\overline{W}\backslash W$ is countable (it does not seem easy to construct a counterexample to either of these, because $W$ seems to always have a nice monotone shape). However, a proof of either of these has continuously evaded me.","Let be closed. I've been studying the following subset of for research, which has useful properties, but cannot prove or disprove it is Borel measurable. Introduce the partial ordering on such that . Consider the set of minimal elements of under . That is, One can easily show that and if then (with Zorn's lemma). I have been wondering how to prove/disprove is Borel measurable for months, gave up, and settled with taking its closure only to make it Borel measurable (if the set were measurable, everything would work out nicely). I believe this set is Borel measurable and that is countable (it does not seem easy to construct a counterexample to either of these, because seems to always have a nice monotone shape). However, a proof of either of these has continuously evaded me.","V \subset [0,\infty)^n V \leq' [0,\infty)^n (x_1,...,x_n) \leq' (y_1,...y_n) \iff x_k \leq y_k, \forall k W V \leq' 
W = \big\{ x \in V \ \big| \ \nexists y\in V, y<'x\big\}.
 W \subset \partial V V \neq \emptyset W \neq \emptyset W \overline{W}\backslash W W","['measure-theory', 'order-theory', 'descriptive-set-theory']"
20,When can a sum over the sum of squares function be replaced by an integral?,When can a sum over the sum of squares function be replaced by an integral?,,"Say I have some function $f(n,x)$ . For many ""nice"" functions, I find (numerically) that \begin{equation} \sum_{n=1}^\infty r_2(n) f(n,x)\approx\pi\int_0^\infty dn f(n,x). \end{equation} Here $r_2(n)$ denotes the sum of squares function. I am aware that the average value of the sum of squares function is asymptotically $\pi$ , which is how I even thought of trying this. I am ideally looking for a way to bound the error for an arbitrary function, or for some class of reasonable functions. My intuition says we have to take into account some bounds on the derivative of the function. I tried converting the sum to 2D, but couldn't find a nice way to use the Abel-Plana formula or something related to get my bound. I also briefly tried reasoning about this measure-theoretically, but without much success.","Say I have some function . For many ""nice"" functions, I find (numerically) that Here denotes the sum of squares function. I am aware that the average value of the sum of squares function is asymptotically , which is how I even thought of trying this. I am ideally looking for a way to bound the error for an arbitrary function, or for some class of reasonable functions. My intuition says we have to take into account some bounds on the derivative of the function. I tried converting the sum to 2D, but couldn't find a nice way to use the Abel-Plana formula or something related to get my bound. I also briefly tried reasoning about this measure-theoretically, but without much success.","f(n,x) \begin{equation}
\sum_{n=1}^\infty r_2(n) f(n,x)\approx\pi\int_0^\infty dn f(n,x).
\end{equation} r_2(n) \pi","['real-analysis', 'measure-theory', 'approximation', 'approximation-theory', 'sums-of-squares']"
21,Clarification about weak topology in the space of probability measure,Clarification about weak topology in the space of probability measure,,"In Jacod and Shiryaev book , page 347, we find the definition of weak convergence of probability measures. Definition . Let $E$ be a Polish space (completely metrizable space which is also separable) and let $\mathcal{E}$ be its Borel $\sigma$ -algebra (the $\sigma$ -algebra generated by the collection of all open subsets of $E$ ). We denote by $\mathcal{P}(E)$ the space of all probability measures on $(E,\mathcal{E})$ . The weak topology on $\mathcal{P}(E)$ is defined as the coarsest topology for which the mappings $\mu\rightarrow \mu(f)$ are continuous for all bounded continuous functions $f$ on $E$ . I am not very familiar with the concept of ""coarsest topology for which a mapping"" is continuous, but this wikipedia page helps a bit. The idea is, among all those topologies that make the mapping $\mu\rightarrow \mu(f)$ continuous, to consider the smallest one. The problem is: does this topology exist? Furthermore, I see form this post that the weak topology is sometimes defined in this way. We have $\mu_n\longrightarrow\mu$ whenever $$ \int f d\mu_n \to \int f d\mu. $$ for all bounded continuous functions $f$ on $E$ . Do the two definitions coincide? Any reference would help.","In Jacod and Shiryaev book , page 347, we find the definition of weak convergence of probability measures. Definition . Let be a Polish space (completely metrizable space which is also separable) and let be its Borel -algebra (the -algebra generated by the collection of all open subsets of ). We denote by the space of all probability measures on . The weak topology on is defined as the coarsest topology for which the mappings are continuous for all bounded continuous functions on . I am not very familiar with the concept of ""coarsest topology for which a mapping"" is continuous, but this wikipedia page helps a bit. The idea is, among all those topologies that make the mapping continuous, to consider the smallest one. The problem is: does this topology exist? Furthermore, I see form this post that the weak topology is sometimes defined in this way. We have whenever for all bounded continuous functions on . Do the two definitions coincide? Any reference would help.","E \mathcal{E} \sigma \sigma E \mathcal{P}(E) (E,\mathcal{E}) \mathcal{P}(E) \mu\rightarrow \mu(f) f E \mu\rightarrow \mu(f) \mu_n\longrightarrow\mu 
\int f d\mu_n \to \int f d\mu.
 f E","['general-topology', 'measure-theory', 'weak-convergence', 'polish-spaces']"
22,How does one prove that partial functions of measurable functions of 2 var. are nearly all measurable?,How does one prove that partial functions of measurable functions of 2 var. are nearly all measurable?,,"How does one prove that if $F: X \times Y \to Z$ is measurable for a product measure, then the partial function $F(x,.) : Y \to Z$ (defined by $y \mapsto F(x,y) )$ is measurable for almost all $x$ in $X$ ? I avoid being more precise for a start so that I have the best chances of getting a usable answer for my purpose. (Some not mentioned hypotheses are probably needed.) Motivation: In the book Operator Theory in Function Spaces by Kehe Zhu integral operators are introduced with $Tf(x) = \int_X K(x,y)f(y)d\mu(y)$ where $K$ and $f$ are in $L^2$ (and therefore measurable) and to make sure that the integral exists it is necessary to have the partial functions also in $L^2$ which will be easy once they are measurable (for almost all $x$ )","How does one prove that if is measurable for a product measure, then the partial function (defined by is measurable for almost all in ? I avoid being more precise for a start so that I have the best chances of getting a usable answer for my purpose. (Some not mentioned hypotheses are probably needed.) Motivation: In the book Operator Theory in Function Spaces by Kehe Zhu integral operators are introduced with where and are in (and therefore measurable) and to make sure that the integral exists it is necessary to have the partial functions also in which will be easy once they are measurable (for almost all )","F: X \times Y \to Z F(x,.) : Y \to Z y \mapsto F(x,y) ) x X Tf(x) = \int_X K(x,y)f(y)d\mu(y) K f L^2 L^2 x","['measure-theory', 'lp-spaces', 'measurable-functions']"
23,Are two measures equal if their projections coincide?,Are two measures equal if their projections coincide?,,"Let $\mu$ and $\nu$ be two finite measures on $\mathbb{R} ^d$ .  For every $s \in \mathbb{R} ^d$ , $|s|=1$ , denote by $\mu _s$ and $\nu _s$ the orthogonal projections of $\mu$ and $\nu$ respectively on the line $\{ as: a \in \mathbb{R} \}$ . That is, for $a < b$ $$ \mu _s ( [a,b]) = \mu (\{x\in \mathbb{R} ^d: a \leq \langle x, s \rangle \leq b \}), $$ where $\langle , \rangle$ is the scalar product in $\mathbb{R} ^d$ , and similar for $\nu _s$ . Question. Assume that $\mu _s = \nu _s$ for every $s \in \mathbb{R} ^d$ , $|s|=1$ . Does it follows that $\mu = \nu$ ? The answer is obviously negative if $\mu$ and $\nu$ are not assumed to be finite (consider $\lambda$ and $2 \lambda$ with $\lambda$ being the Lebesgue measure).","Let and be two finite measures on .  For every , , denote by and the orthogonal projections of and respectively on the line . That is, for where is the scalar product in , and similar for . Question. Assume that for every , . Does it follows that ? The answer is obviously negative if and are not assumed to be finite (consider and with being the Lebesgue measure).","\mu \nu \mathbb{R} ^d s \in \mathbb{R} ^d |s|=1 \mu _s \nu _s \mu \nu \{ as: a \in \mathbb{R} \} a < b 
\mu _s ( [a,b]) = \mu (\{x\in \mathbb{R} ^d: a \leq \langle x, s \rangle \leq b \}),
 \langle , \rangle \mathbb{R} ^d \nu _s \mu _s = \nu _s s \in \mathbb{R} ^d |s|=1 \mu = \nu \mu \nu \lambda 2 \lambda \lambda","['measure-theory', 'probability-distributions', 'reference-request', 'projection']"
24,Does $f=g$ (a.e.) and $g=h$ (a.e.) imply $f=g$ (a.e.) when the measure is not complete?,Does  (a.e.) and  (a.e.) imply  (a.e.) when the measure is not complete?,f=g g=h f=g,"Let $(S,\Sigma, \mu)$ be a measure space. Let $f,g,h:S\rightarrow \overline{\mathbb{R}}$ be functions. Suppose $f = g$ a.e. and $g = h$ a.e., show that $f = h$ a.e.. My try: I can show the above claim when the measure is complete as follows: Since $f = g$ a.e., we have $\mu(\{x\in S : f(x) \neq g(x)\}) = 0$ . Similarly, since $g = h$ a.e., we have $\mu(\{x\in S : g(x) \neq h(x)\}) = 0$ . Let $E = \{x\in S : f(x) \neq h(x)\}$ . Then we have: \begin{align*} \mu(E) &= \mu(\{x\in S : f(x) \neq h(x)\}) \\ &= \mu(\{x\in S : f(x) \neq g(x) \text{ or } g(x) \neq h(x)\}) \\ &\leq \mu(\{x\in S : f(x) \neq g(x)\}) + \mu(\{x\in S : g(x) \neq h(x)\}) \\ &= 0 + 0 = 0. \end{align*} Therefore, we have $\mu(E) = 0$ , which implies that $f = h$ almost everywhere on $S$ . Question I am not sure what I should do when the measure is not complete.","Let be a measure space. Let be functions. Suppose a.e. and a.e., show that a.e.. My try: I can show the above claim when the measure is complete as follows: Since a.e., we have . Similarly, since a.e., we have . Let . Then we have: Therefore, we have , which implies that almost everywhere on . Question I am not sure what I should do when the measure is not complete.","(S,\Sigma, \mu) f,g,h:S\rightarrow \overline{\mathbb{R}} f = g g = h f = h f = g \mu(\{x\in S : f(x) \neq g(x)\}) = 0 g = h \mu(\{x\in S : g(x) \neq h(x)\}) = 0 E = \{x\in S : f(x) \neq h(x)\} \begin{align*}
\mu(E) &= \mu(\{x\in S : f(x) \neq h(x)\}) \\
&= \mu(\{x\in S : f(x) \neq g(x) \text{ or } g(x) \neq h(x)\}) \\
&\leq \mu(\{x\in S : f(x) \neq g(x)\}) + \mu(\{x\in S : g(x) \neq h(x)\}) \\
&= 0 + 0 = 0.
\end{align*} \mu(E) = 0 f = h S",['measure-theory']
25,The density of a pushforward probability measure: the reciprocal of the Jacobian determinant?,The density of a pushforward probability measure: the reciprocal of the Jacobian determinant?,,"$ \def\dee{\mathop{\mathrm{d}\!}} \def\Jac#1{\mathop{\mathbf{J}_{#1}}} $ I'm confused about how to use the change of variable formula to describe the density of a pushforward measure.  My question boils down to: which of the two formulae, (1) and (2) below, is the correct one? Let $X$ be a real-valued random variable with density $\rho_X$ wrt the Lebesgue measure and let $Y=f(X)$ be another random variable, where $f$ is a deterministic invertible transformation. What is the probability density function of $Y$ ? [Just to be clear, the connection with the push-forward is: Denote by $P_X$ the law of $X$ . Then the law of $Y$ is $P_Y = P_X \circ f^{-1} = {({P_X})}_\sharp f$ , the push-forward of $P_X$ by $f$ .] For any measurable set $E$ of outcomes for $Y$ , the probability measure of that set is $$ \begin{align} P_Y(E) = P_X(f^{-1}(E)) &= \int_{f^{-1}(E)} \rho_X(x) \dee x\\ &= \int_{E} \rho_X(f^{-1}(y)) \left|\frac{\dee}{\dee y}f^{-1}(y)\right|\dee y \end{align} $$ (using the change of variables formula for integration by substitution ) so the density of $Y$ is $$ \rho_Y(y) = \rho_X(f^{-1}(y)) \left|\frac{\dee}{\dee y}f^{-1}(y)\right| $$ The derivative in this expression generalizes to the Jacobian determinant in multivariate case (when $f$ is a diffeomorphism, I gather), giving the following formula for the density (see, e.g. this math.SE answer ) $$ \tag{1} \rho_Y(y) = \rho_X(f^{-1}(y)) \left|\det\Jac{f^{-1}}(y)\right| $$ However , a few sources (for example, Betancourt's notes see section 4.2, and some implementations, like here )* give a similar expression but with the reciprocal of the Jacobian determinant, as $$ \tag{2} \rho_Y(y) = \rho_X(f^{-1}(y)) \frac1{\left|\det\Jac{f^{-1}}(y)\right|} $$ It can't be the case that (1) and (2) both hold in general!  Is (2) just a typo, or have I misunderstood the notation they use? I know that $(\frac{\dee}{\dee x}{f}(x))^{-1}=\frac{\dee}{\dee y}{f^{-1}}(y)$ (by the inverse function theorem). This generalizes to $(\Jac{f}(x))^{-1}=\Jac{f^{-1}}(y)$ . So, I think the correct version of (2) would be ( $2^\star$ ): $$ \tag{2$^\star$} \rho_Y(y)  = \rho_X(f^{-1}(y)) \frac1{\left|\det\Jac{f}(x)\right|}\\ = \rho_X(x) \frac1{\left|\det\Jac{f}(x)\right|} $$ or, in the simpler one-dimensional case, $$ \displaystyle \rho_Y(y) = \rho_X(f^{-1}(y)) \frac1{\left|\frac{\dee}{\dee x}{f}(x)\right|} \\ = \rho_X(x) \frac1{\left|\frac{\dee}{\dee x}{f}(x)\right|} $$ But I don't know why you would write it that way (since you want an expression where $y$ is the variable, not $x$ ), instead of the way in $(1)$ . Have I just made a silly mistake reading the notations?  Is $(2)$ somehow correct? *EDIT: I think I may be interpreting Betancourt's notation wrong.  I now think any sources for $(2)$ are either based on a misunderstanding or a typo.","I'm confused about how to use the change of variable formula to describe the density of a pushforward measure.  My question boils down to: which of the two formulae, (1) and (2) below, is the correct one? Let be a real-valued random variable with density wrt the Lebesgue measure and let be another random variable, where is a deterministic invertible transformation. What is the probability density function of ? [Just to be clear, the connection with the push-forward is: Denote by the law of . Then the law of is , the push-forward of by .] For any measurable set of outcomes for , the probability measure of that set is (using the change of variables formula for integration by substitution ) so the density of is The derivative in this expression generalizes to the Jacobian determinant in multivariate case (when is a diffeomorphism, I gather), giving the following formula for the density (see, e.g. this math.SE answer ) However , a few sources (for example, Betancourt's notes see section 4.2, and some implementations, like here )* give a similar expression but with the reciprocal of the Jacobian determinant, as It can't be the case that (1) and (2) both hold in general!  Is (2) just a typo, or have I misunderstood the notation they use? I know that (by the inverse function theorem). This generalizes to . So, I think the correct version of (2) would be ( ): or, in the simpler one-dimensional case, But I don't know why you would write it that way (since you want an expression where is the variable, not ), instead of the way in . Have I just made a silly mistake reading the notations?  Is somehow correct? *EDIT: I think I may be interpreting Betancourt's notation wrong.  I now think any sources for are either based on a misunderstanding or a typo.","
\def\dee{\mathop{\mathrm{d}\!}}
\def\Jac#1{\mathop{\mathbf{J}_{#1}}}
 X \rho_X Y=f(X) f Y P_X X Y P_Y = P_X \circ f^{-1} = {({P_X})}_\sharp f P_X f E Y 
\begin{align}
P_Y(E) = P_X(f^{-1}(E))
&= \int_{f^{-1}(E)} \rho_X(x) \dee x\\
&= \int_{E} \rho_X(f^{-1}(y)) \left|\frac{\dee}{\dee y}f^{-1}(y)\right|\dee y
\end{align}
 Y 
\rho_Y(y) = \rho_X(f^{-1}(y)) \left|\frac{\dee}{\dee y}f^{-1}(y)\right|
 f 
\tag{1}
\rho_Y(y) = \rho_X(f^{-1}(y)) \left|\det\Jac{f^{-1}}(y)\right|
 
\tag{2}
\rho_Y(y) = \rho_X(f^{-1}(y)) \frac1{\left|\det\Jac{f^{-1}}(y)\right|}
 (\frac{\dee}{\dee x}{f}(x))^{-1}=\frac{\dee}{\dee y}{f^{-1}}(y) (\Jac{f}(x))^{-1}=\Jac{f^{-1}}(y) 2^\star 
\tag{2^\star}
\rho_Y(y) 
= \rho_X(f^{-1}(y)) \frac1{\left|\det\Jac{f}(x)\right|}\\
= \rho_X(x) \frac1{\left|\det\Jac{f}(x)\right|}
 
\displaystyle
\rho_Y(y) = \rho_X(f^{-1}(y)) \frac1{\left|\frac{\dee}{\dee x}{f}(x)\right|} \\
= \rho_X(x) \frac1{\left|\frac{\dee}{\dee x}{f}(x)\right|}
 y x (1) (2) (2)","['measure-theory', 'density-function', 'change-of-variable', 'jacobian', 'pushforward']"
26,How is it the Kullback-Leibler divergence is always non-negative but differential entropy can be positive or negative?,How is it the Kullback-Leibler divergence is always non-negative but differential entropy can be positive or negative?,,"According to wikipedia , we have $$  D_{KL}(f ||g ) \geq 0 $$ always, but if $f$ is the pdf of a random variable $X$ and $g$ is the density of the un-normalized Lebesgue measure i.e. the constant function $1$ , then $$ D_{KL}(f ||g ) = \int f \log(f/g) = \int f\log f = -h(X), $$ the negative of the differential entropy. Many distributions however have positive differential entropy (as shown here ). So this means the left-hand side can take negative values. What's going on here?","According to wikipedia , we have always, but if is the pdf of a random variable and is the density of the un-normalized Lebesgue measure i.e. the constant function , then the negative of the differential entropy. Many distributions however have positive differential entropy (as shown here ). So this means the left-hand side can take negative values. What's going on here?","
 D_{KL}(f ||g ) \geq 0
 f X g 1 
D_{KL}(f ||g ) = \int f \log(f/g) = \int f\log f = -h(X),
","['measure-theory', 'information-theory']"
27,Why does $|\hat{\mu}(x)|\leq|x|^{-s/2} \implies \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx<\infty$ for the Fourier transform of a measure $\mu$,Why does  for the Fourier transform of a measure,|\hat{\mu}(x)|\leq|x|^{-s/2} \implies \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx<\infty \mu,"( See edit ) I have seen the claim $|\hat{\mu}(x)|\leq|x|^{-s/2} \implies \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx<\infty$ for the Fourier transform $\hat{\mu}(\xi)\equiv \int_{\mathbb{R}^n}e^{-2\pi i x\cdot \xi}d\mu(x)$ of a finite Borel measure $\mu$ on $\mathbb{R}^n$ in quite a few places without a proof and I am honestly quite confused by it. Namely, what if the origin belongs to the support of $\hat{\mu}$ ? In that case there is no way that the integral $\int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx$ can be finite, at least with the crude approximation $$\int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx \leq \int_{\mathbb{R}^n}|x|^{-n}dx$$ Is there some good-to-know trick that one can use with the assumed inequality to conclude that $\int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx < \infty$ ? Thanks! Edit: My current understanding is that $s$ can be negative. Moreover $\mu$ is assumed to have a compact support, although I am not sure how that is helpful in this case.","( See edit ) I have seen the claim for the Fourier transform of a finite Borel measure on in quite a few places without a proof and I am honestly quite confused by it. Namely, what if the origin belongs to the support of ? In that case there is no way that the integral can be finite, at least with the crude approximation Is there some good-to-know trick that one can use with the assumed inequality to conclude that ? Thanks! Edit: My current understanding is that can be negative. Moreover is assumed to have a compact support, although I am not sure how that is helpful in this case.",|\hat{\mu}(x)|\leq|x|^{-s/2} \implies \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx<\infty \hat{\mu}(\xi)\equiv \int_{\mathbb{R}^n}e^{-2\pi i x\cdot \xi}d\mu(x) \mu \mathbb{R}^n \hat{\mu} \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx \leq \int_{\mathbb{R}^n}|x|^{-n}dx \int_{\mathbb{R}^n}|\hat{\mu}(x)|^2|x|^{s-n}dx < \infty s \mu,"['real-analysis', 'measure-theory', 'fourier-analysis', 'harmonic-analysis', 'borel-measures']"
28,Radon-Nikodym derivative with respect to product of marginal measures,Radon-Nikodym derivative with respect to product of marginal measures,,"Let $\mu$ be a (finite if necessary) measure on the product $\sigma$ -algebra $\mathcal A_1 \otimes \mathcal A_2$ of two measurable spaces $(\Sigma_1,\mathcal A_1)$ , $(\Sigma_2, \mathcal A_2)$ . The marginal measure of $\mu$ on $\mathcal A_i$ for $i\in\{1,2\}$ is defined as $$ \mu_1(A) := \mu(A\times \Sigma_2), \quad \mu_2(B) := \mu(\Sigma_1 \times B) \quad \text{for $A\in\mathcal A_1, B\in\mathcal A_2$}.$$ I wanted to know whether the Radon-Nikodym derivative $\frac{d\mu}{d(\mu_1\otimes \mu_2)}$ exists. For the existence, we have to show that $\mu$ is absolutely continuous w.r.t. the product measure $\mu_1\otimes\mu_2$ . I've tried several approaches without success, one of them is described in the following: Given $M\in\mathcal A_1\otimes \mathcal A_2$ with $(\mu_1\otimes\mu_2)(M)=0$ show $\mu(M)=0$ . Using Fubini, we compute $$ 0 = (\mu_1\otimes\mu_2)(M) = \int_{\Sigma_1}\int_{\Sigma_2} \mathbf 1_M(x,y) ~d\mu_2(y) ~d\mu_1(x) = \int_{\Sigma_1} \mu_2(\{ y \mid (x,y)\in M  \}) ~d\mu_1(x) $$ This implies $\mu_2(\{y\mid(x,y)\in M\})=0$ for $\mu_1$ -a.e. $x_1\in\Sigma_1$ (and a similar statement for $\mu_2$ -a.e. $x_2\in \Sigma_2$ ). At this point, I am unsure whether this statement is true after all (and if so whether we need additional assumptions?).","Let be a (finite if necessary) measure on the product -algebra of two measurable spaces , . The marginal measure of on for is defined as I wanted to know whether the Radon-Nikodym derivative exists. For the existence, we have to show that is absolutely continuous w.r.t. the product measure . I've tried several approaches without success, one of them is described in the following: Given with show . Using Fubini, we compute This implies for -a.e. (and a similar statement for -a.e. ). At this point, I am unsure whether this statement is true after all (and if so whether we need additional assumptions?).","\mu \sigma \mathcal A_1 \otimes \mathcal A_2 (\Sigma_1,\mathcal A_1) (\Sigma_2, \mathcal A_2) \mu \mathcal A_i i\in\{1,2\}  \mu_1(A) := \mu(A\times \Sigma_2), \quad \mu_2(B) := \mu(\Sigma_1 \times B) \quad \text{for A\in\mathcal A_1, B\in\mathcal A_2}. \frac{d\mu}{d(\mu_1\otimes \mu_2)} \mu \mu_1\otimes\mu_2 M\in\mathcal A_1\otimes \mathcal A_2 (\mu_1\otimes\mu_2)(M)=0 \mu(M)=0 
0 = (\mu_1\otimes\mu_2)(M) = \int_{\Sigma_1}\int_{\Sigma_2} \mathbf 1_M(x,y) ~d\mu_2(y) ~d\mu_1(x) = \int_{\Sigma_1} \mu_2(\{ y \mid (x,y)\in M  \}) ~d\mu_1(x)
 \mu_2(\{y\mid(x,y)\in M\})=0 \mu_1 x_1\in\Sigma_1 \mu_2 x_2\in \Sigma_2","['measure-theory', 'absolute-continuity', 'marginal-distribution', 'product-measure']"
29,Cantor Function Clarification,Cantor Function Clarification,,"I am reading some lecture notes and came across the Cantor Function. However, I have some questions about it after reading. Recall the Cantor set $C \subseteq [0, 1]$ is compact, has Hausdorff dimension $\alpha = \frac{\ln 2}{\ln 3}$ and $H^\alpha$ denotes the Hausdorff measure of dimension $\alpha$ . We define the Cantor function as: $$ f(x) = \frac{H^\alpha(C \cap [0, x])}{H^\alpha(C)}. $$ Intuitively, this is the fraction of the Cantor set that lies to the left of $x$ . Now define the function $$ g(x) = \inf\{ y: f(y) = x \}. $$ It can be observes that $f(g(x)) = x$ as $f$ is increasing and continuous and thus the infimum is achieved. The lecture note then claims $g$ is not continuous and I would like to understand the reasoning behind it. In particular, I would like to understand why: $$ g(\frac{1}{2}) = \frac{1}{3} $$ and $$ g(y) \geq \frac{2}{3} $$ for any $y > \frac{1}{2}$ .","I am reading some lecture notes and came across the Cantor Function. However, I have some questions about it after reading. Recall the Cantor set is compact, has Hausdorff dimension and denotes the Hausdorff measure of dimension . We define the Cantor function as: Intuitively, this is the fraction of the Cantor set that lies to the left of . Now define the function It can be observes that as is increasing and continuous and thus the infimum is achieved. The lecture note then claims is not continuous and I would like to understand the reasoning behind it. In particular, I would like to understand why: and for any .","C \subseteq [0, 1] \alpha = \frac{\ln 2}{\ln 3} H^\alpha \alpha 
f(x) = \frac{H^\alpha(C \cap [0, x])}{H^\alpha(C)}.
 x 
g(x) = \inf\{ y: f(y) = x \}.
 f(g(x)) = x f g 
g(\frac{1}{2}) = \frac{1}{3}
 
g(y) \geq \frac{2}{3}
 y > \frac{1}{2}","['real-analysis', 'measure-theory', 'proof-explanation', 'cantor-set', 'hausdorff-measure']"
30,Uniform Integrability and Convergence,Uniform Integrability and Convergence,,"I am trying to solve the following problem: A sequence $\{f_n\}_{n \in \mathbb{N}}$ is said to be uniformly integrable in $L(X,d\mu)$ if $$\lim_{t \to \infty}\sup_{n\ge1}\int_{\{|f|>t\}}|f_n| \, d\mu = 0.$$ Now, assume that $\mu(X) < \infty$ and $f_n \to f$ almost everywhere. If $\{f_n\}_{n \in \mathbb{N}}$ is uniformly integrable show that $f \in L(X,d\mu)$ and $$\lim_{n \to \infty}\int_{X}f_n \, d\mu = \int_{X}f \, d\mu.$$ My Intuitive Idea: Since, we have a finite measure space and pointwise convergent functions, we can use Egorov's Theorem to get uniform convergence. This allows us to get a convergence in the integral except for a set of small measure. Then, use uniform integrability to show that the integral over this small measure set vanishes. My Attempt: Fix $\epsilon > 0$ , then there exists a set $E \subset X$ such that $m(X/E) < \epsilon$ and $f_n$ converges $f$ uniformly on $E$ . Then, \begin{equation} \begin{split} \lim_{n \to \infty}\int_{X}f_n \, d\mu &= \lim_{n \to \infty}\int_{E}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\ &= \int_{E}\lim_{n \to \infty}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\ &= \int_{E}f \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \end{split} \end{equation} I do not know how to handle $$\lim_{n \to \infty}\int_{X/E}f_n \, d\mu.$$ My Questions: (1) Am I on the right track? (2) What is the intuitive meaning of uniform integrability? (3) Is the result still true for $\sigma-$ finite measure spaces? Thanks, in advance.","I am trying to solve the following problem: A sequence is said to be uniformly integrable in if Now, assume that and almost everywhere. If is uniformly integrable show that and My Intuitive Idea: Since, we have a finite measure space and pointwise convergent functions, we can use Egorov's Theorem to get uniform convergence. This allows us to get a convergence in the integral except for a set of small measure. Then, use uniform integrability to show that the integral over this small measure set vanishes. My Attempt: Fix , then there exists a set such that and converges uniformly on . Then, I do not know how to handle My Questions: (1) Am I on the right track? (2) What is the intuitive meaning of uniform integrability? (3) Is the result still true for finite measure spaces? Thanks, in advance.","\{f_n\}_{n \in \mathbb{N}} L(X,d\mu) \lim_{t \to \infty}\sup_{n\ge1}\int_{\{|f|>t\}}|f_n| \, d\mu = 0. \mu(X) < \infty f_n \to f \{f_n\}_{n \in \mathbb{N}} f \in L(X,d\mu) \lim_{n \to \infty}\int_{X}f_n \, d\mu = \int_{X}f \, d\mu. \epsilon > 0 E \subset X m(X/E) < \epsilon f_n f E \begin{equation}
\begin{split}
\lim_{n \to \infty}\int_{X}f_n \, d\mu &= \lim_{n \to \infty}\int_{E}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\
&= \int_{E}\lim_{n \to \infty}f_n \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu \\
&= \int_{E}f \, d\mu + \lim_{n \to \infty}\int_{X/E}f_n \, d\mu
\end{split}
\end{equation} \lim_{n \to \infty}\int_{X/E}f_n \, d\mu. \sigma-","['real-analysis', 'integration', 'measure-theory', 'uniform-integrability']"
31,The pre-image sigma algebra of the greatest integer function [x].,The pre-image sigma algebra of the greatest integer function [x].,,"The first exercise in my Measure and Integration book is to find the pre-image sigma algebra of various functions, namely $f(x)=x^3$ , $x^2$ and $[x]$ . You can correct me if I'm wrong but I'm fairly sure that for $x^3$ we have the power set for $\mathbb{R}$ and for $x^2$ we have the power set for $\mathbb{R^+}$ , however for $[x]$ I'm quite unsure. I don't ever really work on the greatest integer function however it's inverse must simply be for $f(x)=c$ the group all the real numbers greater than $c$ but less than $c+1$ . How could I translate this into the preimage sigma algebra? My best guess on how to class these up would be the set $\left\{x+\frac{1}{n+\epsilon}: x\in\mathbb{R}\right\}, n\in\mathbb{N}$ however I'm very apprehensive that this could be wrong as I'm fairly new to measure theory.","The first exercise in my Measure and Integration book is to find the pre-image sigma algebra of various functions, namely , and . You can correct me if I'm wrong but I'm fairly sure that for we have the power set for and for we have the power set for , however for I'm quite unsure. I don't ever really work on the greatest integer function however it's inverse must simply be for the group all the real numbers greater than but less than . How could I translate this into the preimage sigma algebra? My best guess on how to class these up would be the set however I'm very apprehensive that this could be wrong as I'm fairly new to measure theory.","f(x)=x^3 x^2 [x] x^3 \mathbb{R} x^2 \mathbb{R^+} [x] f(x)=c c c+1 \left\{x+\frac{1}{n+\epsilon}: x\in\mathbb{R}\right\}, n\in\mathbb{N}","['measure-theory', 'inverse-function', 'algebras']"
32,Cartesian product involving non-measurable Lebesgue sets,Cartesian product involving non-measurable Lebesgue sets,,"This has been asked before here and here but has not been answered correctly/completely. Here's the problem: Given, $A, B \subset \mathbb{R}$ , where $A$ is not Lebesgue-measurable while $B$ has positive Lebesgue measure. Show that $A \times B$ is $\mathscr{L}^2$ non-measurable. However, if $B$ has zero measure, then $A \times B$ is $\mathscr{L}^2$ measurable. Here $\mathscr{L}^2$ is the space of Lebesgue measurable sets in $\mathbb{R}^2$ which is obtained by completing the product sigma algebra $\mathscr{L}\otimes \mathscr{L}$ , where $\mathscr{L}$ is the sigma algebra of Lebesgue measurable sets in $\mathbb{R}$ Attempt: I could prove that $A\times B$ is $\mathscr{L}\otimes \mathscr{L}$ measurable and hence $\mathscr{L}^2$ measurable when $m(B)=0$ , since $A\times B \subset \mathbb{R}\times B$ and $m\times m( \mathbb{R}\times B)=m(\mathbb{R}) \times m(B)=0$ , i.e. $\mathbb{R}\times B$ is a null set. Since $\mathscr{L}^2$ is complete, we get $A \times B$ is $\mathscr{L}^2$ measurable. How do I show the general statement?","This has been asked before here and here but has not been answered correctly/completely. Here's the problem: Given, , where is not Lebesgue-measurable while has positive Lebesgue measure. Show that is non-measurable. However, if has zero measure, then is measurable. Here is the space of Lebesgue measurable sets in which is obtained by completing the product sigma algebra , where is the sigma algebra of Lebesgue measurable sets in Attempt: I could prove that is measurable and hence measurable when , since and , i.e. is a null set. Since is complete, we get is measurable. How do I show the general statement?","A, B \subset \mathbb{R} A B A \times B \mathscr{L}^2 B A \times B \mathscr{L}^2 \mathscr{L}^2 \mathbb{R}^2 \mathscr{L}\otimes \mathscr{L} \mathscr{L} \mathbb{R} A\times B \mathscr{L}\otimes \mathscr{L} \mathscr{L}^2 m(B)=0 A\times B \subset \mathbb{R}\times B m\times m( \mathbb{R}\times B)=m(\mathbb{R}) \times m(B)=0 \mathbb{R}\times B \mathscr{L}^2 A \times B \mathscr{L}^2","['real-analysis', 'measure-theory', 'lebesgue-measure']"
33,When does the Fourier transform of a measure vanish at a point?,When does the Fourier transform of a measure vanish at a point?,,"Given a finite Borel measure $\mu$ on $\mathbf{R}$ , consider its Fourier transform which is defined as: $$\hat{\mu}(\xi) = \int_{\mathbf{R}} e^{2\pi i x \xi} \, d\mu(x). $$ Two questions about this: Suppose that $\int_{\mathbf{R}} x^n \, d\mu(x) = 0$ for some $n \geq 1$ . Can we show that there exists a $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi) = 0$ ? More generally, is there a sufficient condition we can place on the measure $\mu$ that ensures that there exists a point $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi)=0$ ? For example, is there some multiplicative function $f(x)$ such that if $\int_{\mathbf{R}} f(x) \, d\mu(x) = 0$ , then there must exist $\xi \in \mathbf{R}$ such that $\hat{\mu}(\xi)=0$ ?","Given a finite Borel measure on , consider its Fourier transform which is defined as: Two questions about this: Suppose that for some . Can we show that there exists a such that ? More generally, is there a sufficient condition we can place on the measure that ensures that there exists a point such that ? For example, is there some multiplicative function such that if , then there must exist such that ?","\mu \mathbf{R} \hat{\mu}(\xi) = \int_{\mathbf{R}} e^{2\pi i x \xi} \, d\mu(x).  \int_{\mathbf{R}} x^n \, d\mu(x) = 0 n \geq 1 \xi \in \mathbf{R} \hat{\mu}(\xi) = 0 \mu \xi \in \mathbf{R} \hat{\mu}(\xi)=0 f(x) \int_{\mathbf{R}} f(x) \, d\mu(x) = 0 \xi \in \mathbf{R} \hat{\mu}(\xi)=0","['real-analysis', 'measure-theory', 'fourier-analysis']"
34,Question about $L^1$ space and Uniform integrability.,Question about  space and Uniform integrability.,L^1,"Let $(\Omega,\Sigma,\mu)$ be a finite measure space and let $\mathscr{F}=\{f_{\alpha}:\Omega\to \mathbb{R}:\alpha\in I\}$ be an arbitrary family of measurable real functions on $\Omega$ . $\mathscr{F}$ is uniformly integrable if the following two conditions hold: \begin{equation}     (i) \sup_{\alpha}\int_{\Omega}|f_{\alpha}|d\mu=C<\infty \hspace{1cm}      (ii) \lim_{\mu_{(A)}\to 0}\int_{A}|f_{\alpha}|d\mu=0   \end{equation} Remark: (i) follows form (ii). I want to know the difference when $\mathscr{F}\subset L^1$ and when $\mathscr{F}$ is uniformly integrable since this two looks same to me.Please help. what I understood is that here condition (ii) means that $\forall \epsilon>0  ,\hspace{0.5 cm} \exists \delta>0$ such that $\int_{A}|f_\alpha|d\mu<\epsilon$ whenever $f\in \mathscr{F}$ and for all $\mu(A)<\delta.$",Let be a finite measure space and let be an arbitrary family of measurable real functions on . is uniformly integrable if the following two conditions hold: Remark: (i) follows form (ii). I want to know the difference when and when is uniformly integrable since this two looks same to me.Please help. what I understood is that here condition (ii) means that such that whenever and for all,"(\Omega,\Sigma,\mu) \mathscr{F}=\{f_{\alpha}:\Omega\to \mathbb{R}:\alpha\in I\} \Omega \mathscr{F} \begin{equation}
    (i) \sup_{\alpha}\int_{\Omega}|f_{\alpha}|d\mu=C<\infty \hspace{1cm}
     (ii) \lim_{\mu_{(A)}\to 0}\int_{A}|f_{\alpha}|d\mu=0
  \end{equation} \mathscr{F}\subset L^1 \mathscr{F} \forall \epsilon>0  ,\hspace{0.5 cm} \exists \delta>0 \int_{A}|f_\alpha|d\mu<\epsilon f\in \mathscr{F} \mu(A)<\delta.","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'uniform-integrability']"
35,monotone convergence theorem and calculaton of Hausdorff dimension,monotone convergence theorem and calculaton of Hausdorff dimension,,"I'm reading these notes , and I'm stuck on an application of the monotone convergence theorem. In computing the Hausdorff dimension of the Koch curve (page 13), the authors show that $H^p(S^{i+1}(A)) > H^p(S^i(A))$ for all $i$ $H^p(K)$ is a finite limit of the sequence $H^p(S^{i}(A))$ where the $S^i(A)$ are the $i^{th}$ iteration of the recursive construction of the Koch curve, $K = \lim_{i \to \infty} S^i(A)$ is the Koch curve, and $p$ is the Hausdorff dimension of $K$ . $H^p(X)$ is the Hausdorff measure of a set $X$ . The authors then use the monotone convergence theorem to conclude $$H^p(\lim_{i \to \infty} S^i(A)) = \lim_{i \to \infty} H^p(S^i(A)).$$ I'm not much of an analyst and really struggling to see how this is an application of the monotone convergence theorem. I'm used to this theorem being the statement that limits commute with integrals in the case of positive integrable functions in an increasing sequence. I don't see where the functions, or the integrals are in the above statement - could someone explain what the relevant measures, integrals, and functions are? Edit : I've added a bounty because I still haven't gotten a satisfying answer here or found one any other way. I'm aware that the argument presented in the linked text might be incorrect/insufficiently rigorous, so I would also accept a rigorous computation using other methods, as long as they remain ""at the level"" of the paper (i.e. I've seen some methods that rely on Radon measures and some other measure theory background I'm not familiar with. I would accept an answer that is rigorous but doesn't use these methods).","I'm reading these notes , and I'm stuck on an application of the monotone convergence theorem. In computing the Hausdorff dimension of the Koch curve (page 13), the authors show that for all is a finite limit of the sequence where the are the iteration of the recursive construction of the Koch curve, is the Koch curve, and is the Hausdorff dimension of . is the Hausdorff measure of a set . The authors then use the monotone convergence theorem to conclude I'm not much of an analyst and really struggling to see how this is an application of the monotone convergence theorem. I'm used to this theorem being the statement that limits commute with integrals in the case of positive integrable functions in an increasing sequence. I don't see where the functions, or the integrals are in the above statement - could someone explain what the relevant measures, integrals, and functions are? Edit : I've added a bounty because I still haven't gotten a satisfying answer here or found one any other way. I'm aware that the argument presented in the linked text might be incorrect/insufficiently rigorous, so I would also accept a rigorous computation using other methods, as long as they remain ""at the level"" of the paper (i.e. I've seen some methods that rely on Radon measures and some other measure theory background I'm not familiar with. I would accept an answer that is rigorous but doesn't use these methods).",H^p(S^{i+1}(A)) > H^p(S^i(A)) i H^p(K) H^p(S^{i}(A)) S^i(A) i^{th} K = \lim_{i \to \infty} S^i(A) p K H^p(X) X H^p(\lim_{i \to \infty} S^i(A)) = \lim_{i \to \infty} H^p(S^i(A)).,"['measure-theory', 'solution-verification', 'examples-counterexamples', 'fractals', 'hausdorff-measure']"
36,"Example of a sequence of measures that does not converge to a measure despite converging ""pointwise""","Example of a sequence of measures that does not converge to a measure despite converging ""pointwise""",,"So, I am trying to solve the following problem: given a sequence of measures $(\mu_n)_{n \in \mathbb{N}}$ on $(X, A)$ such that for each $B \in A$ the limit $\lim_{n \to \infty}  \mu_n(A) \in [0, \infty]$ exists, we define $\mu(A) = \lim_{n \to \infty}  \mu_n(A)$ . I want to find an example where $\mu$ is not a measure on $A$ . Clearly $\mu(B) \geq 0 \; \forall B$ and $\mu(\emptyset) = 0$ . So the only thing that should break is the countable additivity. I have already proven that if the sequence of measures $(\mu_n)_{n \in \mathbb{N}}$ is monotonically increasing, i.e. $\mu_n(B) \leq \mu_{n+1}(B) \; \forall B \in A$ and $\forall n \in \mathbb{N}$ , $\mu$ will be a measure. I also see that $\sum_j \mu(B_j) \leq \mu(\cup_j B_j)$ for any such $\mu$ - so, for $\mu$ to not be a measure I want to create an example where $\sum_j \mu(B_j) < \mu(\cup_j B_j)$ with the strict inequality for some $(B_j)$ . The following sequence of measures almost works on $\mathbb{N}$ : $\mu_i(B) = n_i(B) / i$ , where $n_i(B)$ is the count of natural numbers less than $i$ in $B$ . For every finite set of natural numbers $C$ we have $\lim_i\mu_i(C) = 0$ , but $\lim_i \mu_i (\mathbb{N}) = 1$ , so countable additivity breaks. However, such sequence of measures does not converge ""pointwise"" for all subsets of natural numbers, and I fail to see what $\sigma$ -algebra I need to consider for it to converge on all sets. Could someone please help me, either with my example (if it is even fixable), or with any other example? Thank you very much!","So, I am trying to solve the following problem: given a sequence of measures on such that for each the limit exists, we define . I want to find an example where is not a measure on . Clearly and . So the only thing that should break is the countable additivity. I have already proven that if the sequence of measures is monotonically increasing, i.e. and , will be a measure. I also see that for any such - so, for to not be a measure I want to create an example where with the strict inequality for some . The following sequence of measures almost works on : , where is the count of natural numbers less than in . For every finite set of natural numbers we have , but , so countable additivity breaks. However, such sequence of measures does not converge ""pointwise"" for all subsets of natural numbers, and I fail to see what -algebra I need to consider for it to converge on all sets. Could someone please help me, either with my example (if it is even fixable), or with any other example? Thank you very much!","(\mu_n)_{n \in \mathbb{N}} (X, A) B \in A \lim_{n \to \infty}  \mu_n(A) \in [0, \infty] \mu(A) = \lim_{n \to \infty}  \mu_n(A) \mu A \mu(B) \geq 0 \; \forall B \mu(\emptyset) = 0 (\mu_n)_{n \in \mathbb{N}} \mu_n(B) \leq \mu_{n+1}(B) \; \forall B \in A \forall n \in \mathbb{N} \mu \sum_j \mu(B_j) \leq \mu(\cup_j B_j) \mu \mu \sum_j \mu(B_j) < \mu(\cup_j B_j) (B_j) \mathbb{N} \mu_i(B) = n_i(B) / i n_i(B) i B C \lim_i\mu_i(C) = 0 \lim_i \mu_i (\mathbb{N}) = 1 \sigma","['real-analysis', 'measure-theory']"
37,Let $\mu ^{*}$ be a arbitrary outer measure is necessarily satisfied? $\mu ^*(A \cup B) + \mu^{*}(A \cap B) \leq \mu^{*}(A)+\mu ^{*}(B)$,Let  be a arbitrary outer measure is necessarily satisfied?,\mu ^{*} \mu ^*(A \cup B) + \mu^{*}(A \cap B) \leq \mu^{*}(A)+\mu ^{*}(B),"Let $\mu ^{*}$ be a arbitrary outer measure in a set $X$ and $A,B \subset X$ , the following inequality is necessarily satisfied? $$\mu ^*(A \cup B) + \mu^{*}(A \cap B) \leq \mu^{*}(A)+\mu ^{*}(B)$$ I know that if $A$ (or $B$ ) is $\mu ^{*}-$ measurable then the equality holds but i try to show that supposing that $A,B$ are not $\mu^{*}-$ measurables. I proceded by cases: Case $1$ : $A \subset B$ in this case $A \cup B=B$ and $A \cap B=A$ then $$\mu ^*(A \cup B) + \mu^{*}(A \cap B) =\mu ^*( B) + \mu^{*}(A) $$ Case $2$ : $A \cap B =\emptyset$ in this case $\mu^{*}(A \cap B)=0$ and for subadditivity $$\mu ^{*}(A \cup B) + \mu^{*}(A \cap B)=\mu^{*}(A \cup B)+0\leq \mu^{*}(A)+\mu ^{*}(B)$$ Case $3$ : $A \cap B = \emptyset$ in this case i have problems, intuitively I think it could be true but the term $\mu^{*}(A \cap B)$ is the problem, i search counterexamples but i not sure. Any hint or help i will be very grateful.","Let be a arbitrary outer measure in a set and , the following inequality is necessarily satisfied? I know that if (or ) is measurable then the equality holds but i try to show that supposing that are not measurables. I proceded by cases: Case : in this case and then Case : in this case and for subadditivity Case : in this case i have problems, intuitively I think it could be true but the term is the problem, i search counterexamples but i not sure. Any hint or help i will be very grateful.","\mu ^{*} X A,B \subset X \mu ^*(A \cup B) + \mu^{*}(A \cap B) \leq \mu^{*}(A)+\mu ^{*}(B) A B \mu ^{*}- A,B \mu^{*}- 1 A \subset B A \cup B=B A \cap B=A \mu ^*(A \cup B) + \mu^{*}(A \cap B) =\mu ^*( B) + \mu^{*}(A)  2 A \cap B =\emptyset \mu^{*}(A \cap B)=0 \mu ^{*}(A \cup B) + \mu^{*}(A \cap B)=\mu^{*}(A \cup B)+0\leq \mu^{*}(A)+\mu ^{*}(B) 3 A \cap B = \emptyset \mu^{*}(A \cap B)","['measure-theory', 'outer-measure']"
38,The sigma algebra generated by a stochastic process is equivalently generated by finite intersections.,The sigma algebra generated by a stochastic process is equivalently generated by finite intersections.,,"I am reading a stochastic analysis script and in one proof the following 'fact' is used. Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $I \neq \emptyset$ an index set and $(S, \mathcal{S})$ a measurable space. For a process $X = (X_i)_{i \in I}$ consisting of $S$ valued $\mathcal{F}-\mathcal{S}-$ measurable random variables the following is claimed (without proof): Let $\mathcal{I} = \{\bigcap_{j \in J} X_j^{-1}(A_j)| J \subset I \text{ finite }, A_j \in \mathcal{S}\}$ , then $\sigma(\mathcal{I}) = \sigma(X_i, i \in I) (= \sigma( \bigcup_{i \in I} X_i^{-1}(\mathcal{S})))$ . The interesting direction is to show that every set $\bigcup_{i \in I} X_i^{-1}(A_i)$ , with $A_i \in \mathcal{S}$ is an element of $\sigma(\mathcal{I})$ . For uncountable $I$ , I wanted to proof it myself, but is this even correct? For example: Consider $(\Omega, \mathcal{F}, \mathbb{P}) = ([0,1], \mathcal{B}, \lambda)$ and $(S, \mathcal{S}) = (\mathbb{R}, \mathcal{B})$ and $X_i = 1_{\{i\}}$ , for $i \in I$ , where $I$ is some nonmeasureable subset of $[0,1]$ . Now, we have $\sigma(\mathcal{I}) \subset \mathcal{B}$ , but $\bigcup_{i \in I} X_i^{-1}(\{1\}) = \bigcup_{i \in I} \{i\}  = I \in \sigma(X_i, i \in I)$ . So, according to the above claim, we would have $I \in \mathcal{B}$ which is false. Am I missing something? If I am, how would you actually prove it?","I am reading a stochastic analysis script and in one proof the following 'fact' is used. Let be a probability space, an index set and a measurable space. For a process consisting of valued measurable random variables the following is claimed (without proof): Let , then . The interesting direction is to show that every set , with is an element of . For uncountable , I wanted to proof it myself, but is this even correct? For example: Consider and and , for , where is some nonmeasureable subset of . Now, we have , but . So, according to the above claim, we would have which is false. Am I missing something? If I am, how would you actually prove it?","(\Omega, \mathcal{F}, \mathbb{P}) I \neq \emptyset (S, \mathcal{S}) X = (X_i)_{i \in I} S \mathcal{F}-\mathcal{S}- \mathcal{I} = \{\bigcap_{j \in J} X_j^{-1}(A_j)| J \subset I \text{ finite }, A_j \in \mathcal{S}\} \sigma(\mathcal{I}) = \sigma(X_i, i \in I) (= \sigma( \bigcup_{i \in I} X_i^{-1}(\mathcal{S}))) \bigcup_{i \in I} X_i^{-1}(A_i) A_i \in \mathcal{S} \sigma(\mathcal{I}) I (\Omega, \mathcal{F}, \mathbb{P}) = ([0,1], \mathcal{B}, \lambda) (S, \mathcal{S}) = (\mathbb{R}, \mathcal{B}) X_i = 1_{\{i\}} i \in I I [0,1] \sigma(\mathcal{I}) \subset \mathcal{B} \bigcup_{i \in I} X_i^{-1}(\{1\}) = \bigcup_{i \in I} \{i\}  = I \in \sigma(X_i, i \in I) I \in \mathcal{B}","['probability', 'measure-theory', 'stochastic-processes', 'stochastic-analysis']"
39,Why outer measure of Vitali set is greater than 0 or equals to 0?,Why outer measure of Vitali set is greater than 0 or equals to 0?,,"In the following conservation (link below) https://www.researchgate.net/post/Bounds_on_the_outer_measure_of_Vitali_Set_in_0_1 There is a person who said that outer measure of the Vitali set on $[0,1]$ is greater than 0. Anyone can tells me why?",In the following conservation (link below) https://www.researchgate.net/post/Bounds_on_the_outer_measure_of_Vitali_Set_in_0_1 There is a person who said that outer measure of the Vitali set on is greater than 0. Anyone can tells me why?,"[0,1]","['measure-theory', 'lebesgue-measure', 'outer-measure']"
40,DCT in a proof of (vague) portmanteau theorem over locally compact metric spaces,DCT in a proof of (vague) portmanteau theorem over locally compact metric spaces,,"Let $(X,d)$ be a locally compact metric space and let $\mathscr{B}$ be the Borel sets. Let $\mu_n,\mu:\mathscr{B}\to [0,\infty]$ be regular measures over $(X,\mathscr{B})$ . We say $\mu_n$ converges vaguely  to $\mu$ (or $\mu_n \stackrel{\textrm{v}}{\to}\mu$ ) if $\int_Xud\mu_n\to \int_Xud\mu$ for all compactly supported continuous $u$ (i.e. $u \in C_c(X))$ . As part of a proof of a portmanteau theorem, I read that $$\mu_n(B)\to\mu(B),\,\forall B \in \mathscr{B}\textrm{ relatively compact s.t. }\mu(\partial B)=0\implies\mu_n \stackrel{\textrm{v}}{\to}\mu$$ In the proof of this passage, it is first shown that $\{t>0:\mu(\partial\{u\geq t\})>0\}$ has Lebesgue measure zero. Then, a DCT is applied as following $$\begin{aligned}\lim_{n \to \infty}\int_{(0,\infty)}\mu_n\{u\geq t\}dt&=\lim_{n \to \infty}\int_{(0,\|u\|_\infty)}\mu_n\{u\geq t\}dt\color{red}{\stackrel{(?)}{=}}\\ &=\int_{(0,\|u\|_\infty)}\lim_{n \to \infty}\mu_n\{u\geq t\}dt=\\ &=\int_{(0,\|u\|_\infty)}\mu\{u\geq t\}dt\end{aligned}$$ While the rest seems to me clear, I do not understand the $\color{red}{(?)}$ passage and how DCT has been applied. For example, if $M:=\sup_n\mu_n(X)<\infty$ we would have $$\mu_n\{u\geq t\}\mathbf{1}_{(0,\|u\|_\infty)}(t)\leq M\mathbf{1}_{(0,\|u\|_\infty)}(t)\in L^1(dt)$$ and we could use DCT and take the limit over $\{t>0:\mu(\partial\{u\geq t\})=0\}$ . However, I don't see how DCT is used seemingly without assumptions on $\mu_n$ with the exception of regularity. Is $(X,d)$ being locally compact involved here? Help appreciated.","Let be a locally compact metric space and let be the Borel sets. Let be regular measures over . We say converges vaguely  to (or ) if for all compactly supported continuous (i.e. . As part of a proof of a portmanteau theorem, I read that In the proof of this passage, it is first shown that has Lebesgue measure zero. Then, a DCT is applied as following While the rest seems to me clear, I do not understand the passage and how DCT has been applied. For example, if we would have and we could use DCT and take the limit over . However, I don't see how DCT is used seemingly without assumptions on with the exception of regularity. Is being locally compact involved here? Help appreciated.","(X,d) \mathscr{B} \mu_n,\mu:\mathscr{B}\to [0,\infty] (X,\mathscr{B}) \mu_n \mu \mu_n \stackrel{\textrm{v}}{\to}\mu \int_Xud\mu_n\to \int_Xud\mu u u \in C_c(X)) \mu_n(B)\to\mu(B),\,\forall B \in \mathscr{B}\textrm{ relatively compact s.t. }\mu(\partial B)=0\implies\mu_n \stackrel{\textrm{v}}{\to}\mu \{t>0:\mu(\partial\{u\geq t\})>0\} \begin{aligned}\lim_{n \to \infty}\int_{(0,\infty)}\mu_n\{u\geq t\}dt&=\lim_{n \to \infty}\int_{(0,\|u\|_\infty)}\mu_n\{u\geq t\}dt\color{red}{\stackrel{(?)}{=}}\\
&=\int_{(0,\|u\|_\infty)}\lim_{n \to \infty}\mu_n\{u\geq t\}dt=\\
&=\int_{(0,\|u\|_\infty)}\mu\{u\geq t\}dt\end{aligned} \color{red}{(?)} M:=\sup_n\mu_n(X)<\infty \mu_n\{u\geq t\}\mathbf{1}_{(0,\|u\|_\infty)}(t)\leq M\mathbf{1}_{(0,\|u\|_\infty)}(t)\in L^1(dt) \{t>0:\mu(\partial\{u\geq t\})=0\} \mu_n (X,d)","['real-analysis', 'general-topology', 'measure-theory', 'metric-spaces', 'weak-convergence']"
41,sigma-algebra on the image of a random variable,sigma-algebra on the image of a random variable,,"Usually a random variable is considered to be a function $X: (\Omega, \sigma, P) \to (\mathbb{R}, B(\mathbb{R}))$ but I wonder what advantage choosing $B(\mathbb{R})$ as a sigma algebra on $\mathbb{R}$ has over using the pushforward of $\sigma$ under $X$ .",Usually a random variable is considered to be a function but I wonder what advantage choosing as a sigma algebra on has over using the pushforward of under .,"X: (\Omega, \sigma, P) \to (\mathbb{R}, B(\mathbb{R})) B(\mathbb{R}) \mathbb{R} \sigma X","['probability', 'measure-theory', 'pushforward']"
42,What is the intuition for defining the measurable sets in this manner?,What is the intuition for defining the measurable sets in this manner?,,"I am following a construction of a measure on subsets of $\mathbb{R}$ . The idea is to first define the semi-algebra of intervals and a ""measure"" $\mu$ on this semi-algebra which acts as we expect a length function should. i.e. $\mu(I)=b-a$ for intervals $[a,b)$ (note: the intervals can be open or closed on either side), $\mu(I+x)=\mu(I)$ (length is translation invariant), and $\mu(E)=\sum\mu(E_i)$ where $E_i$ are the disjoint union of $E$ . Given this, I can quite easily show that we can extend this to a $\sigma$ -additive measure $\nu$ , on the algebra generated by this semi-algebra of intervals. My question is regarding the extension of this $\nu$ to $\pi$ on the $\sigma$ -algebra containing this algebra. The idea as I understand is to first define an outer measure $\pi^*$ on all subsets of $\mathbb{R}$ . An outer measure satisfies the following properties: $\mu(\emptyset)=0$ . For $E\subseteq F$ , $\mu(E)\leq\mu(F)$ . For $E\subseteq\bigcup E_i$ , $\mu(E)\leq\sum\mu(E_i)$ We define $\pi^*(E)$ as $\inf\limits_{\{E_i\}}\nu(E_i)$ , where the $E_i$ are elements of the algebra and cover $E$ . It is easy to check this is an outer measure. Here is where I am confused about intutition: The next step is to define a collection of measurable sets $\mathcal{U}$ using this outer measure by stipulating that a set $S\subseteq\mathbb{R}$ is measurable if for every $E\subseteq\mathbb{R}$ $\pi^*(E)=\pi^*(A\cap E)+\pi^*(A^c\cap E)$ . I am struggling to understand intuitively why these sets should be the measurable ones? Can anyone elucidate this condition for me? I understand that from here we can show that this measurable space is a $\sigma$ -algebra containing the algebra and that $\pi^*$ on this space extends $\nu$ . But I'm struggling with the definition of $\mathcal{U}$ .","I am following a construction of a measure on subsets of . The idea is to first define the semi-algebra of intervals and a ""measure"" on this semi-algebra which acts as we expect a length function should. i.e. for intervals (note: the intervals can be open or closed on either side), (length is translation invariant), and where are the disjoint union of . Given this, I can quite easily show that we can extend this to a -additive measure , on the algebra generated by this semi-algebra of intervals. My question is regarding the extension of this to on the -algebra containing this algebra. The idea as I understand is to first define an outer measure on all subsets of . An outer measure satisfies the following properties: . For , . For , We define as , where the are elements of the algebra and cover . It is easy to check this is an outer measure. Here is where I am confused about intutition: The next step is to define a collection of measurable sets using this outer measure by stipulating that a set is measurable if for every . I am struggling to understand intuitively why these sets should be the measurable ones? Can anyone elucidate this condition for me? I understand that from here we can show that this measurable space is a -algebra containing the algebra and that on this space extends . But I'm struggling with the definition of .","\mathbb{R} \mu \mu(I)=b-a [a,b) \mu(I+x)=\mu(I) \mu(E)=\sum\mu(E_i) E_i E \sigma \nu \nu \pi \sigma \pi^* \mathbb{R} \mu(\emptyset)=0 E\subseteq F \mu(E)\leq\mu(F) E\subseteq\bigcup E_i \mu(E)\leq\sum\mu(E_i) \pi^*(E) \inf\limits_{\{E_i\}}\nu(E_i) E_i E \mathcal{U} S\subseteq\mathbb{R} E\subseteq\mathbb{R} \pi^*(E)=\pi^*(A\cap E)+\pi^*(A^c\cap E) \sigma \pi^* \nu \mathcal{U}","['real-analysis', 'measure-theory', 'outer-measure']"
43,Couldn't understand decomposition inside derivation of option valuation using Martingale method,Couldn't understand decomposition inside derivation of option valuation using Martingale method,,"In the derivation of option valuation using Martingale method in continuous time framework of my book named ""Brownian Motion Calculus by Ubbo F Wiersema"" I have faced some issue. I add the derivation below: In the continuous time setting, start from the standard SDE for the stock price, $$\frac{dS_t}{S_t}=\mu dt+\sigma dB_t$$ Introduce the discounted stock price, $$S^{\star}_t\stackrel{\text{def}}{=}\frac{S_t}{e^{rt}}$$ Ito's formula for $S^{\star}_t$ as a function of $t$ and $S$ gives, $$\frac{dS^{\star}_t}{S^{\star}_t}=(\mu-r)dt+\sigma dB_t=\sigma\left[ \frac{\mu-r}{\sigma}dt+dB_t \right]=\sigma\left[ \phi dt+dB_t \right]$$ The probability density of $B_t$ at $B_t=x$ is, $$\frac{1}{\sqrt t \sqrt{2\pi}}\exp\left[-\frac12\left(\frac{x}{\sqrt t}\right)^2\right]$$ This can be decomposed into the product of two terms, $$\frac{1}{\sqrt t \sqrt{2\pi}}\exp\left[-\frac12\left(\frac{\phi t+x}{\sqrt t}\right)^2\right]\exp\left[\frac12 \phi^2 t+\phi x\right]$$ With $y \stackrel{\text { def }}{=} \varphi t+x$ the first term can be written as $$ \frac{1}{\sqrt{t} \sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(\frac{y}{\sqrt{t}}\right)^{2}\right] $$ which is the probability density of another Brownian motion, say $\widehat{B}(t)$ , at $\widehat{B}(t)=y$ . It defines $\widehat{B}(t) \stackrel{\text { def }}{=} \varphi t+B(t)$ , so $\widehat{d} \widehat{B}(t)=\varphi d t+d B(t)$ . Substituting the latter into the SDE for $S^{\star}$ gives $$ \frac{d S^{\star}(t)}{S^{\star}(t)}=\sigma d \widehat{B}(t) \quad \text { and } \quad \frac{d S(t)}{S(t)}=r d t+\sigma d \widehat{B}(t) $$ This says that under the probability distribution of Brownian motion $\widehat{B}(t)$ , $S^{\star}$ is a martingale. I couldn't understand how they bring the decomposition like this? Another thing is, ""Why we need to sustain martingale?"". Does it mean we couldn't predict the future regardless of all prior knowledge, as it introduce arbitrage? @Ali, give an answer to show the decomposition. $$ \exp\left[-\frac{1}{2}\left( \frac{\phi t + x}{\sqrt{t}}\right)^{2}\right]= \exp\left[-\frac{1}{2}\left( \phi^{2}t+2\phi x + x^{2}/t\right)\right]= \exp\left[-\frac{1}{2} \phi^{2}t-\phi x\right] \exp\left[-\frac{1}{2t}x^{2}\right] $$ But, still, I couldn't get any intuition of that decomposition. Like, I want to know why this decomposition was introduced, and its meaning in the context of option valuation. Does this related with Girsanov transformation ?","In the derivation of option valuation using Martingale method in continuous time framework of my book named ""Brownian Motion Calculus by Ubbo F Wiersema"" I have faced some issue. I add the derivation below: In the continuous time setting, start from the standard SDE for the stock price, Introduce the discounted stock price, Ito's formula for as a function of and gives, The probability density of at is, This can be decomposed into the product of two terms, With the first term can be written as which is the probability density of another Brownian motion, say , at . It defines , so . Substituting the latter into the SDE for gives This says that under the probability distribution of Brownian motion , is a martingale. I couldn't understand how they bring the decomposition like this? Another thing is, ""Why we need to sustain martingale?"". Does it mean we couldn't predict the future regardless of all prior knowledge, as it introduce arbitrage? @Ali, give an answer to show the decomposition. But, still, I couldn't get any intuition of that decomposition. Like, I want to know why this decomposition was introduced, and its meaning in the context of option valuation. Does this related with Girsanov transformation ?","\frac{dS_t}{S_t}=\mu dt+\sigma dB_t S^{\star}_t\stackrel{\text{def}}{=}\frac{S_t}{e^{rt}} S^{\star}_t t S \frac{dS^{\star}_t}{S^{\star}_t}=(\mu-r)dt+\sigma dB_t=\sigma\left[ \frac{\mu-r}{\sigma}dt+dB_t \right]=\sigma\left[ \phi dt+dB_t \right] B_t B_t=x \frac{1}{\sqrt t \sqrt{2\pi}}\exp\left[-\frac12\left(\frac{x}{\sqrt t}\right)^2\right] \frac{1}{\sqrt t \sqrt{2\pi}}\exp\left[-\frac12\left(\frac{\phi t+x}{\sqrt t}\right)^2\right]\exp\left[\frac12 \phi^2 t+\phi x\right] y \stackrel{\text { def }}{=} \varphi t+x 
\frac{1}{\sqrt{t} \sqrt{2 \pi}} \exp \left[-\frac{1}{2}\left(\frac{y}{\sqrt{t}}\right)^{2}\right]
 \widehat{B}(t) \widehat{B}(t)=y \widehat{B}(t) \stackrel{\text { def }}{=} \varphi t+B(t) \widehat{d} \widehat{B}(t)=\varphi d t+d B(t) S^{\star} 
\frac{d S^{\star}(t)}{S^{\star}(t)}=\sigma d \widehat{B}(t) \quad \text { and } \quad \frac{d S(t)}{S(t)}=r d t+\sigma d \widehat{B}(t)
 \widehat{B}(t) S^{\star} 
\exp\left[-\frac{1}{2}\left(
\frac{\phi t + x}{\sqrt{t}}\right)^{2}\right]=
\exp\left[-\frac{1}{2}\left(
\phi^{2}t+2\phi x + x^{2}/t\right)\right]=
\exp\left[-\frac{1}{2}
\phi^{2}t-\phi x\right]
\exp\left[-\frac{1}{2t}x^{2}\right]
","['measure-theory', 'stochastic-calculus', 'martingales']"
44,Equivalent definition of essential supremum,Equivalent definition of essential supremum,,"Let $(X,\mathcal{A},\mu)$ be a measure space and let $f\colon X\to [-\infty,+\infty]$ be a measurable function. Denote with $\mathcal{N}_\mu$ the collection of $\mu$ -null sets. On same text the definition of essential supremum is $$\operatorname{esssup}f:=\inf\left\{\sup_{x\in X\setminus N} f(x)\;\middle|\; N\in\mathcal{N}_\mu \right\}\tag 1$$ In other texts it is: $$\operatorname{esssup}f:=\inf\left\{a\ge 0\;\middle|\;\mu\left(\{x\in X\;\middle|\; f(x)>a\}\right)=0         \right\}\tag2$$ Question Are $(1)$ and $(2)$ equivalent? Why?",Let be a measure space and let be a measurable function. Denote with the collection of -null sets. On same text the definition of essential supremum is In other texts it is: Question Are and equivalent? Why?,"(X,\mathcal{A},\mu) f\colon X\to [-\infty,+\infty] \mathcal{N}_\mu \mu \operatorname{esssup}f:=\inf\left\{\sup_{x\in X\setminus N} f(x)\;\middle|\; N\in\mathcal{N}_\mu \right\}\tag 1 \operatorname{esssup}f:=\inf\left\{a\ge 0\;\middle|\;\mu\left(\{x\in X\;\middle|\; f(x)>a\}\right)=0         \right\}\tag2 (1) (2)","['real-analysis', 'measure-theory', 'supremum-and-infimum']"
45,Haar measure on isomorphic subgroups,Haar measure on isomorphic subgroups,,"Let $G$ be an abelian locally compact Hausdorff group endowed with a chosen Haar measure $\mu$ . Moreover, let $H,N$ be subgroups of $G$ where $N$ is discrete. Then we have the isomorphic quotient groups $$\frac{(H+N)}{N}\cong\frac{H}{H\cap N}.$$ If we put the natural counting measure on the discrete subgroups, then we get a unique induced measure on the quotient. Now I wonder whether the groups in the isomorphism have the same volume under the canonical measures? Or maybe a better formulation is, whether the pushforward measure induced by the canonical measure on the left hand side coincides with the canonical measure on the right hand side? Edit: We assume that the restricted measure on $H$ is nonzero, and therefore a Haar measure. On $N$ we denote the measure by $\lambda$ , and on $H\cap N$ the restricted measure by $\lambda_{H}$ . On $G$ we have the measure $\mu$ , and on the quotient $G/N$ the measure $\nu_{N}$ . The unique induced measure on $G/(H\cap N)$ is denoted by $\nu_{H}$ . We want to show that $\nu_{N}((H+N)/N) = \nu_{H}(H/(H\cap N))$ (if it is true). I guess that if this it true, one needs the quotient integral formula. But I dont exactly see how to obtain it here. $$\nu_{N}((H+N)/N)=\int_{G/N}\chi_{(H+N)/N}(x)\mathrm{d}\nu_{N}(x)$$ $$\nu_{H}((H/(H\cap N))=\int_{G/(H\cap N)}\chi_{H/(H\cap N)}(x)\mathrm{d}\nu_{H}(x),$$ where the integrands are the characteristic funtions. The reason why I think the quotient integral formula is needed, is that the measure on $H\cap N$ is just the restriction of the measure on $N$ . And therefore you might get a nice equality when you can write the integral $$\int_{G/N}\chi_{(H+N)/N}(x)\mathrm{d}\nu_{N}(x) = \int_{G/N}\int_{N}f(yn)\mathrm{d}\lambda\mathrm{d}\nu_{N}(yN),$$ for some integrable $f$ .","Let be an abelian locally compact Hausdorff group endowed with a chosen Haar measure . Moreover, let be subgroups of where is discrete. Then we have the isomorphic quotient groups If we put the natural counting measure on the discrete subgroups, then we get a unique induced measure on the quotient. Now I wonder whether the groups in the isomorphism have the same volume under the canonical measures? Or maybe a better formulation is, whether the pushforward measure induced by the canonical measure on the left hand side coincides with the canonical measure on the right hand side? Edit: We assume that the restricted measure on is nonzero, and therefore a Haar measure. On we denote the measure by , and on the restricted measure by . On we have the measure , and on the quotient the measure . The unique induced measure on is denoted by . We want to show that (if it is true). I guess that if this it true, one needs the quotient integral formula. But I dont exactly see how to obtain it here. where the integrands are the characteristic funtions. The reason why I think the quotient integral formula is needed, is that the measure on is just the restriction of the measure on . And therefore you might get a nice equality when you can write the integral for some integrable .","G \mu H,N G N \frac{(H+N)}{N}\cong\frac{H}{H\cap N}. H N \lambda H\cap N \lambda_{H} G \mu G/N \nu_{N} G/(H\cap N) \nu_{H} \nu_{N}((H+N)/N) = \nu_{H}(H/(H\cap N)) \nu_{N}((H+N)/N)=\int_{G/N}\chi_{(H+N)/N}(x)\mathrm{d}\nu_{N}(x) \nu_{H}((H/(H\cap N))=\int_{G/(H\cap N)}\chi_{H/(H\cap N)}(x)\mathrm{d}\nu_{H}(x), H\cap N N \int_{G/N}\chi_{(H+N)/N}(x)\mathrm{d}\nu_{N}(x) = \int_{G/N}\int_{N}f(yn)\mathrm{d}\lambda\mathrm{d}\nu_{N}(yN), f","['group-theory', 'measure-theory', 'borel-measures']"
46,How to find a fractal with a predetermined Hausdorff dimension? [duplicate],How to find a fractal with a predetermined Hausdorff dimension? [duplicate],,"This question already has answers here : Given a real number $d , (1<d<2)$, is there a fractal with fractal dimension $d$? [duplicate] (1 answer) Is there a general metod to construct a fractal? (1 answer) Closed 2 years ago . For many patterns that display self-similarity, the Hausdorff dimension can be found . Sometimes the dimension is calculated and approximate - as is the case with the Feigenbaum attractor - but often its closed form in terms of known mathematical constants be obtained - for instance, the Hausdorff dimension of the Cantor set is $ \log_{3}(2)$ . I am interested in the inverse problem: suppose we consider a mathematical constant like $\pi^{-1}$ or $\gamma e$ . Can we always find and describe a fractal whose Hausdorff dimension is equal to this preset number?","This question already has answers here : Given a real number $d , (1<d<2)$, is there a fractal with fractal dimension $d$? [duplicate] (1 answer) Is there a general metod to construct a fractal? (1 answer) Closed 2 years ago . For many patterns that display self-similarity, the Hausdorff dimension can be found . Sometimes the dimension is calculated and approximate - as is the case with the Feigenbaum attractor - but often its closed form in terms of known mathematical constants be obtained - for instance, the Hausdorff dimension of the Cantor set is . I am interested in the inverse problem: suppose we consider a mathematical constant like or . Can we always find and describe a fractal whose Hausdorff dimension is equal to this preset number?", \log_{3}(2) \pi^{-1} \gamma e,"['measure-theory', 'fractals']"
47,Why does the monotone convergence fail here,Why does the monotone convergence fail here,,"I am looking at the example $f_{n}(x) = n \chi_{(0, \frac{1}{n}]}$ . This converges to $0$ pointwise and graphing it out we can see that its a series of rectangles of area 1 but with growing height. I can see that the dominated convergence theorem would fail, since I can't find a bound for all $f_{n} as the heights are getting arbitrarily large. But I cannot see why the Monotone convergence theorem fails. It seems that the sequence is monotone and the value of each individual integral is finite?","I am looking at the example . This converges to pointwise and graphing it out we can see that its a series of rectangles of area 1 but with growing height. I can see that the dominated convergence theorem would fail, since I can't find a bound for all $f_{n} as the heights are getting arbitrarily large. But I cannot see why the Monotone convergence theorem fails. It seems that the sequence is monotone and the value of each individual integral is finite?","f_{n}(x) = n \chi_{(0, \frac{1}{n}]} 0","['measure-theory', 'lebesgue-integral', 'monotone-functions']"
48,A sequence in $L^p$ that converges in measure but not weakly and vice versa,A sequence in  that converges in measure but not weakly and vice versa,L^p,"I am able to cook up an example A sequence in $L^p$ that converges in measure but not weakly. Namely, let $f_n = n \chi_{[0, 1/n]}$ for $n \in \mathbb{N}.$ Then we have that $\{f_n \}$ converges in measure on $[0, 1]$ but it does not converge weakly in $L^p([0, 1]).$ My question is can we cook up an example for the reverse? i.e. can we find a sequence of functions in $L^p$ that converges weakly but not in measure?","I am able to cook up an example A sequence in that converges in measure but not weakly. Namely, let for Then we have that converges in measure on but it does not converge weakly in My question is can we cook up an example for the reverse? i.e. can we find a sequence of functions in that converges weakly but not in measure?","L^p f_n = n \chi_{[0, 1/n]} n \in \mathbb{N}. \{f_n \} [0, 1] L^p([0, 1]). L^p","['measure-theory', 'convergence-divergence', 'lp-spaces', 'weak-convergence']"
49,A sequence of measurable functions doesn't converge with the following properties,A sequence of measurable functions doesn't converge with the following properties,,"Let $\{f_n\}$ be a sequence of measurable functions defined on $[0,1]$ with the following properties: $f_n(x)\in[0,1]$ for any $x\in[0,1]$ and $n\geq 1$ . $\lim_{n\to\infty} \int_{[0,1]} f_n = 0$ . $\{f_n(x)\}$ doesn't converge for any $x\in[0,1]$ . My thought was to construct a sequence of functions that are zero almost everywhere to satisfy 2). For example, the Dirichlet function on $[0,1]$ and doesn't depend on $n$ . But this sequence of functions seems not to satisfy 3) as it would converge to $1$ for any $x\in\mathbb{Q}$ . How do I construct such a sequence of functions? Any hints?","Let be a sequence of measurable functions defined on with the following properties: for any and . . doesn't converge for any . My thought was to construct a sequence of functions that are zero almost everywhere to satisfy 2). For example, the Dirichlet function on and doesn't depend on . But this sequence of functions seems not to satisfy 3) as it would converge to for any . How do I construct such a sequence of functions? Any hints?","\{f_n\} [0,1] f_n(x)\in[0,1] x\in[0,1] n\geq 1 \lim_{n\to\infty} \int_{[0,1]} f_n = 0 \{f_n(x)\} x\in[0,1] [0,1] n 1 x\in\mathbb{Q}","['real-analysis', 'measure-theory']"
50,Lebesgue Outer Measure Null Set Proof,Lebesgue Outer Measure Null Set Proof,,"I am trying to solve the following proof: Let $||$ be the Lebesgue outer measure. Show that if $|B|=0$ then $|A\cup B|=|A|$ . If I consider $B=\{x_1,x_2,....\}$ this is easy enough. Consider an arbitrary open covering of $A \subset \cup_{i=1}^{\infty} I_i$ . Let us consider the open covering for $B\subset\cup_{n=1}^{\infty}(x_n-\frac{\epsilon}{2^n},x_n+\frac{\epsilon}{2^n})$ . Then Consider the open covering of $A\cup B\subset \cup_{n=1}^{\infty}\bigg\{ I_n\cup (x_n-\frac{\epsilon}{2^n},x_n+\frac{\epsilon}{2^n})\bigg\}$ . Then we get $$|A\cup B|\le \sum_{n=1}^{\infty}l(I_n)+\epsilon\sum_{n=0}^{\infty}\frac{1}{2^n}= \sum_{n=1}^{\infty}l(I_n)+2\epsilon.$$ Since the covering for A was arbitrary: $$|A\cup B|\le |A|+2\epsilon.$$ Letting $\epsilon \rightarrow 0$ $$|A\cup B|\le |A|.$$ The reverse inequality holds by monotonicity. I can't think of another set $B$ that would have measure zero that is not a countable set of singletons. If there is can anyone provide an example?",I am trying to solve the following proof: Let be the Lebesgue outer measure. Show that if then . If I consider this is easy enough. Consider an arbitrary open covering of . Let us consider the open covering for . Then Consider the open covering of . Then we get Since the covering for A was arbitrary: Letting The reverse inequality holds by monotonicity. I can't think of another set that would have measure zero that is not a countable set of singletons. If there is can anyone provide an example?,"|| |B|=0 |A\cup B|=|A| B=\{x_1,x_2,....\} A \subset \cup_{i=1}^{\infty} I_i B\subset\cup_{n=1}^{\infty}(x_n-\frac{\epsilon}{2^n},x_n+\frac{\epsilon}{2^n}) A\cup B\subset \cup_{n=1}^{\infty}\bigg\{ I_n\cup (x_n-\frac{\epsilon}{2^n},x_n+\frac{\epsilon}{2^n})\bigg\} |A\cup B|\le \sum_{n=1}^{\infty}l(I_n)+\epsilon\sum_{n=0}^{\infty}\frac{1}{2^n}= \sum_{n=1}^{\infty}l(I_n)+2\epsilon. |A\cup B|\le |A|+2\epsilon. \epsilon \rightarrow 0 |A\cup B|\le |A|. B","['measure-theory', 'lebesgue-measure', 'outer-measure']"
51,Why $1_{T=\infty}X_{\infty}$ is $\mathcal{F}_T$-measurable for a martingale?,Why  is -measurable for a martingale?,1_{T=\infty}X_{\infty} \mathcal{F}_T,"For a filtration $\mathcal{F}_0\subset\dots\subset \mathcal{F}_t\subset\dots\subset \mathcal{F}_{\infty}$ . We know that if $X$ is $\mathcal{F}_0$ -measurable, then $X$ is also $\mathcal{F}_t$ -measurable for $t\ge 0$ . I have a question about the martingale $X_t$ (which $\mathcal{F}_t$ measurable) is  that given a stopping time $T$ , why $1_{T=\infty}X_{\infty}$ is $\mathcal{F}_T$ -measurable? It is clear that $1_{T=\infty}$ is $\mathcal{F}_T$ -measurable. But because $X_{\infty}$ is $\mathcal{F}_{\infty}$ -measurable. How can we say $X_{\infty}$ is also $\mathcal{F}_{T}$ -measurable?","For a filtration . We know that if is -measurable, then is also -measurable for . I have a question about the martingale (which measurable) is  that given a stopping time , why is -measurable? It is clear that is -measurable. But because is -measurable. How can we say is also -measurable?",\mathcal{F}_0\subset\dots\subset \mathcal{F}_t\subset\dots\subset \mathcal{F}_{\infty} X \mathcal{F}_0 X \mathcal{F}_t t\ge 0 X_t \mathcal{F}_t T 1_{T=\infty}X_{\infty} \mathcal{F}_T 1_{T=\infty} \mathcal{F}_T X_{\infty} \mathcal{F}_{\infty} X_{\infty} \mathcal{F}_{T},"['probability', 'measure-theory', 'stochastic-processes']"
52,$A_n\subseteq A: \mu(A_n)\xrightarrow{n}0 \Rightarrow \int_{A_n} f \xrightarrow{n} 0 $ [duplicate],[duplicate],A_n\subseteq A: \mu(A_n)\xrightarrow{n}0 \Rightarrow \int_{A_n} f \xrightarrow{n} 0 ,"This question already has an answer here : I must prove that $\lim_{\mu(A)\rightarrow 0}\int_{A}\lvert f \lvert{\rm d}\mu=0$. (1 answer) Closed 2 years ago . Let $f\in L^1(A)$ and $A_n\subseteq A: \mu(A_n)\xrightarrow{n\to\infty}0$ , show that $$\int_{A_n} f \xrightarrow{n\to\infty}0 $$ What i tried: We can write $f$ as following: $$f = f \cdot 1_{\{|f| >M\}} +f \cdot 1_{\{|f| \le M\}}, M>0.  $$ Note: if $f\in L^1(A)$ and $g_n(x) = |f(x)| \cdot 1_{\{|f| \ge n\}}$ then $$\int_A g_n \xrightarrow{n\to\infty}0 \qquad (*)$$ because $|g_n(x)|\le |f(x)|\in L^1(A) $ and $\lim g_n = 0$ hence, from dominated convergence theorem we got $(*)$ $$\int_{A_n}f = \int_{A_n}f \cdot 1_{\{|f| >M\}} +\int_{A_n}f \cdot 1_{\{|f| \le M\}}  $$ $$\int_{A_n}f \cdot 1_{\{|f| \le M\}} \le M\mu(A_n)\xrightarrow{n\to\infty}0$$ let $\epsilon >0$ , we can choose M large enough s.t: $$\int_{A_n}f \cdot 1_{\{|f| >M\}}\le \int_{A}f \cdot 1_{\{|f| >M\}} \le \epsilon.$$ is my approath correct? Thank you!","This question already has an answer here : I must prove that $\lim_{\mu(A)\rightarrow 0}\int_{A}\lvert f \lvert{\rm d}\mu=0$. (1 answer) Closed 2 years ago . Let and , show that What i tried: We can write as following: Note: if and then because and hence, from dominated convergence theorem we got let , we can choose M large enough s.t: is my approath correct? Thank you!","f\in L^1(A) A_n\subseteq A: \mu(A_n)\xrightarrow{n\to\infty}0 \int_{A_n} f \xrightarrow{n\to\infty}0  f f = f \cdot 1_{\{|f| >M\}} +f \cdot 1_{\{|f| \le M\}}, M>0.   f\in L^1(A) g_n(x) = |f(x)| \cdot 1_{\{|f| \ge n\}} \int_A g_n \xrightarrow{n\to\infty}0 \qquad (*) |g_n(x)|\le |f(x)|\in L^1(A)  \lim g_n = 0 (*) \int_{A_n}f = \int_{A_n}f \cdot 1_{\{|f| >M\}} +\int_{A_n}f \cdot 1_{\{|f| \le M\}}   \int_{A_n}f \cdot 1_{\{|f| \le M\}} \le M\mu(A_n)\xrightarrow{n\to\infty}0 \epsilon >0 \int_{A_n}f \cdot 1_{\{|f| >M\}}\le \int_{A}f \cdot 1_{\{|f| >M\}} \le \epsilon.","['real-analysis', 'measure-theory', 'lebesgue-measure']"
53,Question on Egorov's Theorem: How do you find such $E_{\epsilon}$ sets?,Question on Egorov's Theorem: How do you find such  sets?,E_{\epsilon},"Egorov's Theorem is as follows: Let $X$ be a finite measure space.  If $f_n\rightarrow f$ pointwise a.e., then for all $\epsilon>0$ , there exists $E_{\epsilon}\subset X$ such that $m(E_{\epsilon})<\epsilon$ and $f_n\rightarrow f$ uniformly on $X\setminus E_\epsilon$ . I don't have a specific problem in front of me, but suppose we had a problem where we were given some hypothesis, and we had to find such a $E_\epsilon$ .  Is there a standard method to find such a set?  Could you maybe provide some examples?  I (believe I) understand the proof of Egorov's theorem, but I am having a hard time actually finding such sets, rather than just claiming such sets exist.  One last question: since $X$ is a finite measure space, then we can use $f_n\rightarrow f$ in measure in the original claim, correct?  Thank you!!","Egorov's Theorem is as follows: Let be a finite measure space.  If pointwise a.e., then for all , there exists such that and uniformly on . I don't have a specific problem in front of me, but suppose we had a problem where we were given some hypothesis, and we had to find such a .  Is there a standard method to find such a set?  Could you maybe provide some examples?  I (believe I) understand the proof of Egorov's theorem, but I am having a hard time actually finding such sets, rather than just claiming such sets exist.  One last question: since is a finite measure space, then we can use in measure in the original claim, correct?  Thank you!!",X f_n\rightarrow f \epsilon>0 E_{\epsilon}\subset X m(E_{\epsilon})<\epsilon f_n\rightarrow f X\setminus E_\epsilon E_\epsilon X f_n\rightarrow f,"['real-analysis', 'measure-theory', 'pointwise-convergence']"
54,Two definitions of ergodicity,Two definitions of ergodicity,,"Definition A: Let $(X,\mathcal{A},\mu)$ be a probability space. Let $T: X\rightarrow X$ is $\mu$ -invariant ( $\mu(T^{-1}E)=\mu(E)$ for all $E\in \mathcal A$ ). Then $T$ is ergodic if for every $E\in \mathcal{A}$ with $T^{-1}(E) = E$ , we have $\mu(E)=0$ or $1$ . Definition B: Let $(X,\mathcal{A},\mu)$ be a probability space. Let $T: X\rightarrow X$ is $\mu$ -invariant ( $\mu(T^{-1}E)=\mu(E)$ for all $E\in \mathcal A$ ). Then $T$ is ergodic if for every $E\in \mathcal{A}$ with $T^{-1}(E) \subset E$ , we have $\mu(E)=0$ or $1$ . The difference between two definitions is $T^{-1}(E) = E$ vs. $T^{-1}(E) \subset E$ . Definition A comes from Definition 2.13 of the book by Einsiedler and Ward and Definition B is from the entry ""Ergodicity"" of Wikipedia . There are more things to check for the Definition B. So B is stronger than A. Can we prove they are equivalent?","Definition A: Let be a probability space. Let is -invariant ( for all ). Then is ergodic if for every with , we have or . Definition B: Let be a probability space. Let is -invariant ( for all ). Then is ergodic if for every with , we have or . The difference between two definitions is vs. . Definition A comes from Definition 2.13 of the book by Einsiedler and Ward and Definition B is from the entry ""Ergodicity"" of Wikipedia . There are more things to check for the Definition B. So B is stronger than A. Can we prove they are equivalent?","(X,\mathcal{A},\mu) T: X\rightarrow X \mu \mu(T^{-1}E)=\mu(E) E\in \mathcal A T E\in \mathcal{A} T^{-1}(E) = E \mu(E)=0 1 (X,\mathcal{A},\mu) T: X\rightarrow X \mu \mu(T^{-1}E)=\mu(E) E\in \mathcal A T E\in \mathcal{A} T^{-1}(E) \subset E \mu(E)=0 1 T^{-1}(E) = E T^{-1}(E) \subset E","['measure-theory', 'ergodic-theory']"
55,Lebesgue Integral Over Step Function,Lebesgue Integral Over Step Function,,"Given the step function \begin{equation}   g(x,y) =     \begin{cases}       \frac{1}{x^2} & 0<y<x<1\\       -\frac{1}{y^2} & 0<x<y<1\\       0 & \text{otherwise}     \end{cases}        \end{equation} I want to show that $$\int_{(0,1)}\int_{(0,1)} g(x,y) \, d\lambda(x)\,d\lambda(y) \neq \int_{(0,1)}\int_{(0,1)} g(x,y) \,d\lambda(y)\,d\lambda(x)$$ However, when trying to use the relation with Riemann integrability I end up with divergent integrals such as $$\int_0^x \int_0^1 \frac{1}{x^2} \, dx \, dy - \int_0^1 \int_0^y \frac{1}{y^2} \, dx \, dy$$ I also considered using limits such as following one, but again I end up with divergence. $$\lim_{k \rightarrow\infty} \int_{(\frac{1}{k},1)}\lim_{k \rightarrow\infty} \int_{(\frac{1}{k},1)}g(x,y) \, dx \, dy$$ I would really appreciate any help!","Given the step function I want to show that However, when trying to use the relation with Riemann integrability I end up with divergent integrals such as I also considered using limits such as following one, but again I end up with divergence. I would really appreciate any help!","\begin{equation}
  g(x,y) =
    \begin{cases}
      \frac{1}{x^2} & 0<y<x<1\\
      -\frac{1}{y^2} & 0<x<y<1\\
      0 & \text{otherwise}
    \end{cases}       
\end{equation} \int_{(0,1)}\int_{(0,1)} g(x,y) \, d\lambda(x)\,d\lambda(y) \neq \int_{(0,1)}\int_{(0,1)} g(x,y) \,d\lambda(y)\,d\lambda(x) \int_0^x \int_0^1 \frac{1}{x^2} \, dx \, dy - \int_0^1 \int_0^y \frac{1}{y^2} \, dx \, dy \lim_{k \rightarrow\infty} \int_{(\frac{1}{k},1)}\lim_{k \rightarrow\infty} \int_{(\frac{1}{k},1)}g(x,y) \, dx \, dy","['measure-theory', 'lebesgue-measure', 'riemann-integration', 'measurable-functions']"
56,Lemma by Riemann-Lebesgue,Lemma by Riemann-Lebesgue,,"The purpose of this problem is that I want to prove that for any $\lambda$ integrable function $f$ on a bounded closed interval $[a, b]$ holds $$ \lim _{n \rightarrow \infty} \int_{[a, b]} f(x) \sin (n x) d \lambda=0. $$ I have submitted a proof below.",The purpose of this problem is that I want to prove that for any integrable function on a bounded closed interval holds I have submitted a proof below.,"\lambda f [a, b] 
\lim _{n \rightarrow \infty} \int_{[a, b]} f(x) \sin (n x) d \lambda=0.
","['measure-theory', 'lebesgue-measure']"
57,Can you prove that $\Bbb R$ is uncountable using the Lebesgue measure?,Can you prove that  is uncountable using the Lebesgue measure?,\Bbb R,"I have been studying measure theory from the ground up, and am quite excited by the seeming power it holds. I thought of this last evening, and I wish to ask if the following proof of uncountability is fully rigorous: Note: In the lecture notes I have been reading, to develop the measure-theoretic tools I use in this proof, the uncountability of $\Bbb R$ was not used, so I believe this avoids circular reasoning. Any countable subset $Q$ of $\Bbb R$ admits an enumeration of points $\{q_n:n\in\Bbb N\}$ , i.e. that $x\in Q\iff\exists n\in\Bbb N:q_n=x$ , and $q_n=q_m\iff n=m$ , by definition of countability. The Lebesgue outer measure $\mu^*$ is defined as the infimum of the volume of countable rectangular covers of that set; taking some arbitrary $\varepsilon\gt0$ , one can construct the cover of ""rectangles"" $R_n=[q_n-\varepsilon\cdot2^{-(1+n)},q_n+\varepsilon\cdot2^{-(1+n)}]$ . By construction, $\bigcup_{n\in\Bbb N}R_n\supseteq Q$ , and $\sum_{n\in\Bbb N}\mu(R_n)=\varepsilon$ from the geometric series. The outer measure is defined with the infimum of covers, so $\mu^*(Q)\le\varepsilon$ as $\{R_n\}$ is a valid countable cover of $Q$ . It follows from $\varepsilon$ as arbitrary that $\mu^*(Q)=0$ , and also that $\mu(Q)=0$ - null sets w.r.t the outer measure are Lebesgue measurable. Now take any non-trivial closed interval $[a,b]$ in $\Bbb R$ ; as it is a ""rectangle"", it has Lebesgue measure $|b-a|\neq0$ , (by definition of the outer measure, right?) Thus any closed interval in $\Bbb R$ cannot be countable, as otherwise it would have null measure (furthermore it cannot be reached as a countable limit of countable sets, since the measure is $\sigma$ -additive and the set would still have $0$ measure). Thus the reals are uncountable, and this argument generalises easily to $\Bbb R^n,\Bbb C^n$ . Is this rigorously sufficient as a proof? It feels like cheating somehow, but I can't place my finger on why I feel that, and I certainly can't see any mistakes or circular reasoning.","I have been studying measure theory from the ground up, and am quite excited by the seeming power it holds. I thought of this last evening, and I wish to ask if the following proof of uncountability is fully rigorous: Note: In the lecture notes I have been reading, to develop the measure-theoretic tools I use in this proof, the uncountability of was not used, so I believe this avoids circular reasoning. Any countable subset of admits an enumeration of points , i.e. that , and , by definition of countability. The Lebesgue outer measure is defined as the infimum of the volume of countable rectangular covers of that set; taking some arbitrary , one can construct the cover of ""rectangles"" . By construction, , and from the geometric series. The outer measure is defined with the infimum of covers, so as is a valid countable cover of . It follows from as arbitrary that , and also that - null sets w.r.t the outer measure are Lebesgue measurable. Now take any non-trivial closed interval in ; as it is a ""rectangle"", it has Lebesgue measure , (by definition of the outer measure, right?) Thus any closed interval in cannot be countable, as otherwise it would have null measure (furthermore it cannot be reached as a countable limit of countable sets, since the measure is -additive and the set would still have measure). Thus the reals are uncountable, and this argument generalises easily to . Is this rigorously sufficient as a proof? It feels like cheating somehow, but I can't place my finger on why I feel that, and I certainly can't see any mistakes or circular reasoning.","\Bbb R Q \Bbb R \{q_n:n\in\Bbb N\} x\in Q\iff\exists n\in\Bbb N:q_n=x q_n=q_m\iff n=m \mu^* \varepsilon\gt0 R_n=[q_n-\varepsilon\cdot2^{-(1+n)},q_n+\varepsilon\cdot2^{-(1+n)}] \bigcup_{n\in\Bbb N}R_n\supseteq Q \sum_{n\in\Bbb N}\mu(R_n)=\varepsilon \mu^*(Q)\le\varepsilon \{R_n\} Q \varepsilon \mu^*(Q)=0 \mu(Q)=0 [a,b] \Bbb R |b-a|\neq0 \Bbb R \sigma 0 \Bbb R^n,\Bbb C^n","['measure-theory', 'set-theory', 'lebesgue-measure', 'real-numbers']"
58,"How to understand the operation ""choose a random subset"" in combinatorics?","How to understand the operation ""choose a random subset"" in combinatorics?",,"Hello I'm reading Tao and Vu's book additive combinatorics ，and I can not fully convince myself to believe the proof of Theorem 1.13 . In the proof, they constructed a set by the following way(It seems that I'm not allowed to upload picture now, so I type it down) Define a set $B\subset\mathbb{Z}^+$ randomly by requiring the events $n\in B$ (for $n\in \mathbb{Z}^+$ ) to be jointly independent with probability $\textbf{P}(n\in B)=\min\bigg(C\sqrt{\frac{\log n}{n}},1\bigg)$ , where $C$ is a large constant to be chosen later. Since I've not seen such a method before, I have several questions: If one talks about randomness , then there should be a probability space. In the proof they choose a set $B$ randomly , what is the probability space $(\Omega,\mathcal{F},\mathbb{P})$ here? Relating to the first question, how could I require that events $\{n\in B\}_{n\in\mathbb{Z}^+}$ to be jointly independent? Why could I require that events $\{n\in B\}_{n\in\mathbb{Z}^+}$ have the assigned probability? Any comments should be helpful! [1]: https://i.sstatic.net/AWZN5.png","Hello I'm reading Tao and Vu's book additive combinatorics ，and I can not fully convince myself to believe the proof of Theorem 1.13 . In the proof, they constructed a set by the following way(It seems that I'm not allowed to upload picture now, so I type it down) Define a set randomly by requiring the events (for ) to be jointly independent with probability , where is a large constant to be chosen later. Since I've not seen such a method before, I have several questions: If one talks about randomness , then there should be a probability space. In the proof they choose a set randomly , what is the probability space here? Relating to the first question, how could I require that events to be jointly independent? Why could I require that events have the assigned probability? Any comments should be helpful! [1]: https://i.sstatic.net/AWZN5.png","B\subset\mathbb{Z}^+ n\in B n\in \mathbb{Z}^+ \textbf{P}(n\in B)=\min\bigg(C\sqrt{\frac{\log n}{n}},1\bigg) C B (\Omega,\mathcal{F},\mathbb{P}) \{n\in B\}_{n\in\mathbb{Z}^+} \{n\in B\}_{n\in\mathbb{Z}^+}","['probability', 'combinatorics', 'measure-theory', 'discrete-mathematics', 'additive-combinatorics']"
59,A question from Sheldon Axler Section 2A Exercise 5 [closed],A question from Sheldon Axler Section 2A Exercise 5 [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question The question would be : $A$ is a set of closed subsets of $\mathbb{R}$ such that $\bigcap_{F\in A}=\emptyset$ . Show that if $A$ contains at least one bounded set, that there exists an integer $n$ and $F_{1},\dotso, F_{n}$ in $A$ so that $\bigcap F_{i}=\emptyset$ .","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . The community reviewed whether to reopen this question 2 years ago and left it closed: Original close reason(s) were not resolved Improve this question The question would be : is a set of closed subsets of such that . Show that if contains at least one bounded set, that there exists an integer and in so that .","A \mathbb{R} \bigcap_{F\in A}=\emptyset A n F_{1},\dotso, F_{n} A \bigcap F_{i}=\emptyset","['real-analysis', 'measure-theory']"
60,How to prove this function is measurable?,How to prove this function is measurable?,,"Suppose $\{f_n\}$ is a sequence of measurable functions on $[0,1]$ . For any $x \in [0,1]$ , suppose that $\exists$ $N$ s.t. $f_n(x)=0$ for all $n\ge N$ . Define function $h$ as the smallest index $n$ for which $f_n(x)=0$ , i.e. $h(x) = inf\{n:f_n(x)=0\}$ . If I want to show that h is measurable function, what should I do? Actually, I've tried a lot. I thought my definition of $g_n := \chi_{\{0\}}(f_n(x))$ is good because it used the condition that $\{f_n\}$ is measurable, but not useful to prove it. Or definition? But I still don't know how to show the inverse is a $\sigma$ -algebra.","Suppose is a sequence of measurable functions on . For any , suppose that s.t. for all . Define function as the smallest index for which , i.e. . If I want to show that h is measurable function, what should I do? Actually, I've tried a lot. I thought my definition of is good because it used the condition that is measurable, but not useful to prove it. Or definition? But I still don't know how to show the inverse is a -algebra.","\{f_n\} [0,1] x \in [0,1] \exists N f_n(x)=0 n\ge N h n f_n(x)=0 h(x) = inf\{n:f_n(x)=0\} g_n := \chi_{\{0\}}(f_n(x)) \{f_n\} \sigma","['real-analysis', 'measure-theory', 'measurable-functions']"
61,"Why does the finiteness of the Haar measure of Siegel set implies that $SL(n,\mathbb Z)$ is a lattice?",Why does the finiteness of the Haar measure of Siegel set implies that  is a lattice?,"SL(n,\mathbb Z)","Let $G=\operatorname{SL}(n,\mathbb R)$ and $\Gamma =\operatorname{SL}(n, \mathbb Z)$ . Suppose we have already shown that $G=\Sigma_{t,u} \Gamma$ for some subset $\Sigma_{t,u}$ of $G$ , called Siegel set. Let $\mu$ be a Haar measure on $G$ . Suppose also we have shown that $\mu(\Sigma_{t,u})$ is finite. I wonder how to show that there exists a $G$ -invariant measure on $G/\Gamma$ such that $\mu(G/\Gamma)$ is finite. First obstacle: Let $\pi\colon G\to G/\Gamma$ be the canonical projection. I am not sure if the pushforward measure $\pi_*\mu$ on $G/\Gamma$ is $G$ -invariant or not. Since it is unclear to me whether $$\mu(\pi(gU))=\mu(g\pi(U))$$ or not. Second obstacle: I don't see $\mu(\Sigma_{t,u})$ being finite implies $\pi_*\mu(G/\Gamma)$ being finite.","Let and . Suppose we have already shown that for some subset of , called Siegel set. Let be a Haar measure on . Suppose also we have shown that is finite. I wonder how to show that there exists a -invariant measure on such that is finite. First obstacle: Let be the canonical projection. I am not sure if the pushforward measure on is -invariant or not. Since it is unclear to me whether or not. Second obstacle: I don't see being finite implies being finite.","G=\operatorname{SL}(n,\mathbb R) \Gamma =\operatorname{SL}(n, \mathbb Z) G=\Sigma_{t,u} \Gamma \Sigma_{t,u} G \mu G \mu(\Sigma_{t,u}) G G/\Gamma \mu(G/\Gamma) \pi\colon G\to G/\Gamma \pi_*\mu G/\Gamma G \mu(\pi(gU))=\mu(g\pi(U)) \mu(\Sigma_{t,u}) \pi_*\mu(G/\Gamma)","['measure-theory', 'lie-groups', 'haar-measure']"
62,Mollification of Functions of bounded variation,Mollification of Functions of bounded variation,,"Let $\eta_{\epsilon}$ be a standard mollifier. For $f\in L^{\infty}(\mathbb{R})$ we have $|f^{\epsilon}(x)|\leq \int\limits_{R}|f(x-y)|\eta_{\epsilon}(y)dy \leq ||f||_{\infty},$ which implies $||f^{\epsilon}||_{\infty} \leq ||f||_{\infty}.$ Thus convolution does not increase the $L^{\infty}$ norm. Similarly, if $TV(f)<\infty$ do we have $TV(f^{\epsilon}) \leq TV(f)?$ If not, can we  get $TV(f^{\epsilon}) \leq C TV(f)?$ for some $C$ independent of $\epsilon?$ Defintion: Total variaton and Functions of bounded variation Let $f: \mathbb{R} \rightarrow \mathbb{R}$ and Let $ \mathcal{P} =\left\{P=\{ x_0, \dots , x_{n_P}\} \mid P\text{ is a partition of }  \mathbb{R} \text{ satisfying } x_i\leq x_{i+1}\text{ for } 0\leq i\leq n_P-1 \right\} $ Total variation of $f$ is defined by $TV(f)=\sup_{P \in \mathcal{P}} \sum_{i=0}^{n_{P}-1} | f(x_{i+1})-f(x_i) |.$ A function $f$ is called function of bounded variation if $TV(f)<\infty.$","Let be a standard mollifier. For we have which implies Thus convolution does not increase the norm. Similarly, if do we have If not, can we  get for some independent of Defintion: Total variaton and Functions of bounded variation Let and Let Total variation of is defined by A function is called function of bounded variation if","\eta_{\epsilon} f\in L^{\infty}(\mathbb{R}) |f^{\epsilon}(x)|\leq \int\limits_{R}|f(x-y)|\eta_{\epsilon}(y)dy \leq ||f||_{\infty}, ||f^{\epsilon}||_{\infty} \leq ||f||_{\infty}. L^{\infty} TV(f)<\infty TV(f^{\epsilon}) \leq TV(f)? TV(f^{\epsilon}) \leq C TV(f)? C \epsilon? f: \mathbb{R} \rightarrow \mathbb{R} 
\mathcal{P} =\left\{P=\{ x_0, \dots , x_{n_P}\} \mid P\text{ is a partition of }  \mathbb{R} \text{ satisfying } x_i\leq x_{i+1}\text{ for } 0\leq i\leq n_P-1 \right\}  f TV(f)=\sup_{P \in \mathcal{P}} \sum_{i=0}^{n_{P}-1} | f(x_{i+1})-f(x_i) |. f TV(f)<\infty.","['real-analysis', 'measure-theory', 'convolution', 'bounded-variation', 'total-variation']"
63,The set that $(f_n)$ converges to a real or a rational number is measurable,The set that  converges to a real or a rational number is measurable,(f_n),"Let $(f_n(x)):\Omega\rightarrow \mathbb{R}$ be a sequence of measurable functions, the sets $$A=\{x \in \Omega: (f_n(x)) \text{ converges to a real number}\}$$ $$B=\{x \in \Omega: (f_n(x)) \text{ converges to a rational number}\}$$ $$C=\{x \in \Omega: (f_n(x)) \text{ converges to an irrational number}\}$$ are measurable? This type of question is answered in many places, but there are a few confusions that I have after reading. For example: The set that $(f_n)$ converges to a real number is measurable , it says $\{x \in \Omega: (f_n(x)) \text{ converges to a real number}\}$ is equivalent to $\{x \in \Omega: (f_n(x)) \text{ is Cauchy}\}$ . Here are my confusions: I understand that $\mathbb{R}$ is complete, but why do we work with Cauchy instead of convergence itself? Here: $$A=\{x\in\Omega: \forall k \in \mathbb{N},\, \exists N \in \mathbb{N} \text{ s.t. } \forall n>N,\, |f_n(x)-r_x| < 1/k\}$$ where $r_x\in\mathbb{R}$ is the pointwise limit of $(f_n(x))$ , $x\in \Omega$ . Then $$A = \bigcap_{k\in\mathbb{N}}\bigcup_{N\in\mathbb{N}}\bigcap_{n > N} \{x\in\Omega:|f_n(x)-r_x|<1/k\}$$ Since $r_x$ are constants, therefore the set $\{x\in\Omega:|f_n(x)-r_x|<1/k\}$ is measurable, and therefore $A$ is measurable. (right???) I don't see why we can't work with convergence directly. Suppose what they did in the link is correct, why can we ignore what number that $(f_n(x))$ converges to? What if $f_n(x)$ converges to a rational (set $B$ ), or an irrational (set $C$ )? The arguments are the same? And does that mean $B=C$ if we only need $(f_n(x))$ to be Cauchy? It does not feel right. Thanks for any insights and help.","Let be a sequence of measurable functions, the sets are measurable? This type of question is answered in many places, but there are a few confusions that I have after reading. For example: The set that converges to a real number is measurable , it says is equivalent to . Here are my confusions: I understand that is complete, but why do we work with Cauchy instead of convergence itself? Here: where is the pointwise limit of , . Then Since are constants, therefore the set is measurable, and therefore is measurable. (right???) I don't see why we can't work with convergence directly. Suppose what they did in the link is correct, why can we ignore what number that converges to? What if converges to a rational (set ), or an irrational (set )? The arguments are the same? And does that mean if we only need to be Cauchy? It does not feel right. Thanks for any insights and help.","(f_n(x)):\Omega\rightarrow \mathbb{R} A=\{x \in \Omega: (f_n(x)) \text{ converges to a real number}\} B=\{x \in \Omega: (f_n(x)) \text{ converges to a rational number}\} C=\{x \in \Omega: (f_n(x)) \text{ converges to an irrational number}\} (f_n) \{x \in \Omega: (f_n(x)) \text{ converges to a real number}\} \{x \in \Omega: (f_n(x)) \text{ is Cauchy}\} \mathbb{R} A=\{x\in\Omega: \forall k \in \mathbb{N},\, \exists N \in \mathbb{N} \text{ s.t. } \forall n>N,\, |f_n(x)-r_x| < 1/k\} r_x\in\mathbb{R} (f_n(x)) x\in \Omega A = \bigcap_{k\in\mathbb{N}}\bigcup_{N\in\mathbb{N}}\bigcap_{n > N} \{x\in\Omega:|f_n(x)-r_x|<1/k\} r_x \{x\in\Omega:|f_n(x)-r_x|<1/k\} A (f_n(x)) f_n(x) B C B=C (f_n(x))","['real-analysis', 'calculus', 'sequences-and-series', 'measure-theory', 'sequence-of-function']"
64,Show that countable/co-countable sigma-algebra is strictly smaller than Powerset,Show that countable/co-countable sigma-algebra is strictly smaller than Powerset,,"I have a question regarding the countable/co-countable $\sigma$ -algebra. I will write first its definition: Example. Let $X$ be an uncountable infinite set. Then $$ \mathcal{A} = \{A \subseteq X\mid A\text{ is at most countable or } A^c\text{ is at most countable}\} $$ is a $\sigma$ -algebra, which is strictly smaller than $\mathcal{P}(X) = 2^X$ . (stated in Wikipedia ) Now to prove that $\mathcal{A}$ is a $\sigma$ -algebra is quite easy, but how can we prove that $\mathcal{A} \subsetneq \mathcal{P}(X)$ ? With $X=\mathbb{R}$ we can write $B=(-\infty,0]$ with $B^c=(0,+\infty)$ , both are uncountable, with $$ B\in \mathcal{P}(X) \quad \text{ and }\quad B\notin \mathcal{A} $$ So $\mathcal{A} \subsetneq\mathcal{P}(X)$ . But with a general $X$ how can we do it?","I have a question regarding the countable/co-countable -algebra. I will write first its definition: Example. Let be an uncountable infinite set. Then is a -algebra, which is strictly smaller than . (stated in Wikipedia ) Now to prove that is a -algebra is quite easy, but how can we prove that ? With we can write with , both are uncountable, with So . But with a general how can we do it?","\sigma X  \mathcal{A} = \{A \subseteq X\mid A\text{ is at most countable or } A^c\text{ is at most countable}\}  \sigma \mathcal{P}(X) = 2^X \mathcal{A} \sigma \mathcal{A} \subsetneq \mathcal{P}(X) X=\mathbb{R} B=(-\infty,0] B^c=(0,+\infty)  B\in \mathcal{P}(X) \quad \text{ and }\quad B\notin \mathcal{A}  \mathcal{A} \subsetneq\mathcal{P}(X) X","['measure-theory', 'elementary-set-theory']"
65,why $\Lambda_N g = \Lambda_n g $?,why ?,\Lambda_N g = \Lambda_n g ,"In Rudin RCA theorem $2.20 $ Page no: $51$ Rudin say that if $n >N$ , then we have $$\Lambda_N g =\Lambda_n g \leq \Lambda_n f \leq \Lambda_n h = \Lambda_N h$$ Here I'm confused that why $\Lambda_N g =\Lambda_n g $ ? My attempt: It is given that $g$ is constant on each box in $\{\Omega_n\}$ Now if $n > N$ , then $$\Lambda_n g :=  2^{-nk} \sum\limits_{x \in P_n} g(x)$$ Now  using the Property : For $\{\Omega_n\}$ , if $Q\in \Omega_r$ , then vol $(Q)=2^{-rk}$ ; and if $n>r$ , the set $P_n$ has exactly $2^{(n-r)k}$ points in $Q$ we  have $$\Lambda_n g :=  2^{-nk} g(x)\sum\limits_{x \in P_n}.1=2^{-nk} g(x)2^{(n-N)k}=2^{-Nk}g(x)$$ $$\implies 2^{-Nk}g(x) \neq \Lambda_N g :=  2^{-Nk} \sum\limits_{x \in P_n} g(x)$$ Therefore $$\Lambda_N g \neq  \Lambda_n g$$","In Rudin RCA theorem Page no: Rudin say that if , then we have Here I'm confused that why ? My attempt: It is given that is constant on each box in Now if , then Now  using the Property : For , if , then vol ; and if , the set has exactly points in we  have Therefore","2.20  51 n >N \Lambda_N g =\Lambda_n g \leq \Lambda_n f \leq \Lambda_n h = \Lambda_N h \Lambda_N g =\Lambda_n g  g \{\Omega_n\} n > N \Lambda_n g :=  2^{-nk} \sum\limits_{x \in P_n} g(x) \{\Omega_n\} Q\in \Omega_r (Q)=2^{-rk} n>r P_n 2^{(n-r)k} Q \Lambda_n g :=  2^{-nk} g(x)\sum\limits_{x \in P_n}.1=2^{-nk} g(x)2^{(n-N)k}=2^{-Nk}g(x) \implies 2^{-Nk}g(x) \neq \Lambda_N g :=  2^{-Nk} \sum\limits_{x \in P_n} g(x) \Lambda_N g \neq
 \Lambda_n g",['measure-theory']
66,When does $A\times B$ measurable imply both $A$ and $B$ measurable? Is Fubini's applicable?,When does  measurable imply both  and  measurable? Is Fubini's applicable?,A\times B A B,"When $A\subset\mathbb R^n$ and $B\subset\mathbb R^m$ are Lebesgue measurable, then so is $A\times B\subset \mathbb R^{n+m}$ and $\mu(A\times B)=\mu(A)\cdot\mu(B)$ . I'm being loose with the notation here assuming that we can understand that each $\mu$ is Lebesgue measure on the appropriate Euclidean space in each instance and ignoring any technical issues with specifying $\mathbb R^{n+m}$ vs $\mathbb R^{n}\times\mathbb R^{m}$ . I'm using the definition of Lebesgue outer measure: $$\mu^*(E)=\inf\left\{\sum v(I_k)\mid E\subset \bigcup I_k, \text{ with closed boxes } I_k \right\}$$ and $\mu(E)=\mu^*(E)$ exists when for any $\epsilon>0$ there is an open set $G\supset E$ such that $\mu^*(G\setminus E)<\epsilon$ . I'd like to avoid the Carathéodory's criterion It is also true that nonmeasurable $A$ and measure zero $B$ gives $A\times B$ measurable with measure zero. Thus $A\times B$ measurable doesn't imply that $A$ and $B$ are both measurable. (Always meaning Lebesgue measurable etc.) So I am wondering under what additional conditions, if any, do we have $A\times B$ measurable implying that $A$ and $B$ are both measurable? Is $\mu(A\times B)>0$ sufficient? Will Fubini's theorem will give us something here? Certainly $\mu(A\times B)=\mu^*(A\times B)=\mu^*(A)\cdot \mu^*(B)$ . We also have that $\mathbf 1_{A\times B}$ the characteristic function on a measurable set and is thus measurable, and in fact $\mathbf 1_{A\times B}(x,y)=\mathbf 1_{A}(x)\cdot\mathbf 1_{B}(y)$ . Thus we get $$\int_{\mathbb R^{n+m}}\mathbf 1_A(x)\mathbf 1_B(y)=\int_{\mathbb R^{n+m}}\mathbf 1_{A\times B}(x,y)=\mu(A\times B)>0$$ But I don't quite see how I can say anything about $A$ and $B$ or $\mathbf 1_A$ and $\mathbf 1_B$ individually. If I try to use Fubini's to iterate the integral, I end up with $\mu(A)\mu(B)$ . Thus if Fubini's is true then it makes mean think that $A$ and $B$ have to both be measurable when $\mu(A\times B)>0$ . I don't see how Fubini's can be applied to $\mathbf 1_{A\times B}$ if we don't have specific knowledge about the measurability of $A$ and $B$ . Can I just say that $$0<\mu(A\times B)=\int_{\mathbb R^{n}}\mathbf 1_A(x) \cdot \int_{\mathbb R^{m}}\mathbf 1_B(y)$$ and then I get to conclude that the right side must be the product of two positive numbers and hence $A$ and $B$ must both be measurable? That just feels a bit uncomfortable... Now I'm not even sure if Fubini's is even relavant here. When one set is nonmeasurable: If $A\subset\mathbb R^n$ is nonmeasurable and $B\subset\mathbb R^m$ is measure zero, then I can almost work it out with Fubini's but not quite. I do believe we trivially get that $\mu(A\times B)=0$ though without much work. $$\begin{aligned} \int_{y\in\mathbb R^m}\mathbf 1_{A\times B}(x,y)&= \begin{cases} \mu(B) &\text{ if } x\in A\\ 0 &\text{ if } x\not\in A\\ \end{cases}\\ &=0\cdot 1_{A}(x)=0\end{aligned}$$ Thus giving $\int_{\mathbb R^{n+m}}\mathbf 1_{A\times B} =\int_{\mathbb R^{n}}\int_{\mathbb R^{m}} \mathbf 1_{A\times B}=\int_{\mathbb R^{n}}0=0$ which is what I would hope for. If we iterate the integral in the other order, then I run into issues though since $$ \int_{x\in\mathbb R^n}\mathbf 1_{A\times B}(x,y) = \mathbf 1_{B}(y) \cdot \int_{x\in\mathbb R^n}\mathbf 1_{A}(x)$$ But $\mu(A)$ is undefined! For the purpose of this problem though, I can define $\int_{x\in\mathbb R^n}\mathbf 1_{A}(x)$ to be whatever I want though giving zero for the final result, but that kinda bothers me. I think maybe Fubini's theorem doesn't apply here since it starts off with the product measure? I am sure there is probably some technical matter I am overlooking or making some mistake that is easy to fix.","When and are Lebesgue measurable, then so is and . I'm being loose with the notation here assuming that we can understand that each is Lebesgue measure on the appropriate Euclidean space in each instance and ignoring any technical issues with specifying vs . I'm using the definition of Lebesgue outer measure: and exists when for any there is an open set such that . I'd like to avoid the Carathéodory's criterion It is also true that nonmeasurable and measure zero gives measurable with measure zero. Thus measurable doesn't imply that and are both measurable. (Always meaning Lebesgue measurable etc.) So I am wondering under what additional conditions, if any, do we have measurable implying that and are both measurable? Is sufficient? Will Fubini's theorem will give us something here? Certainly . We also have that the characteristic function on a measurable set and is thus measurable, and in fact . Thus we get But I don't quite see how I can say anything about and or and individually. If I try to use Fubini's to iterate the integral, I end up with . Thus if Fubini's is true then it makes mean think that and have to both be measurable when . I don't see how Fubini's can be applied to if we don't have specific knowledge about the measurability of and . Can I just say that and then I get to conclude that the right side must be the product of two positive numbers and hence and must both be measurable? That just feels a bit uncomfortable... Now I'm not even sure if Fubini's is even relavant here. When one set is nonmeasurable: If is nonmeasurable and is measure zero, then I can almost work it out with Fubini's but not quite. I do believe we trivially get that though without much work. Thus giving which is what I would hope for. If we iterate the integral in the other order, then I run into issues though since But is undefined! For the purpose of this problem though, I can define to be whatever I want though giving zero for the final result, but that kinda bothers me. I think maybe Fubini's theorem doesn't apply here since it starts off with the product measure? I am sure there is probably some technical matter I am overlooking or making some mistake that is easy to fix.","A\subset\mathbb R^n B\subset\mathbb R^m A\times B\subset \mathbb R^{n+m} \mu(A\times B)=\mu(A)\cdot\mu(B) \mu \mathbb R^{n+m} \mathbb R^{n}\times\mathbb R^{m} \mu^*(E)=\inf\left\{\sum v(I_k)\mid E\subset \bigcup I_k, \text{ with closed boxes } I_k \right\} \mu(E)=\mu^*(E) \epsilon>0 G\supset E \mu^*(G\setminus E)<\epsilon A B A\times B A\times B A B A\times B A B \mu(A\times B)>0 \mu(A\times B)=\mu^*(A\times B)=\mu^*(A)\cdot \mu^*(B) \mathbf 1_{A\times B} \mathbf 1_{A\times B}(x,y)=\mathbf 1_{A}(x)\cdot\mathbf 1_{B}(y) \int_{\mathbb R^{n+m}}\mathbf 1_A(x)\mathbf 1_B(y)=\int_{\mathbb R^{n+m}}\mathbf 1_{A\times B}(x,y)=\mu(A\times B)>0 A B \mathbf 1_A \mathbf 1_B \mu(A)\mu(B) A B \mu(A\times B)>0 \mathbf 1_{A\times B} A B 0<\mu(A\times B)=\int_{\mathbb R^{n}}\mathbf 1_A(x) \cdot \int_{\mathbb R^{m}}\mathbf 1_B(y) A B A\subset\mathbb R^n B\subset\mathbb R^m \mu(A\times B)=0 \begin{aligned}
\int_{y\in\mathbb R^m}\mathbf 1_{A\times B}(x,y)&=
\begin{cases}
\mu(B) &\text{ if } x\in A\\
0 &\text{ if } x\not\in A\\
\end{cases}\\
&=0\cdot 1_{A}(x)=0\end{aligned} \int_{\mathbb R^{n+m}}\mathbf 1_{A\times B} =\int_{\mathbb R^{n}}\int_{\mathbb R^{m}} \mathbf 1_{A\times B}=\int_{\mathbb R^{n}}0=0 
\int_{x\in\mathbb R^n}\mathbf 1_{A\times B}(x,y) = \mathbf 1_{B}(y) \cdot \int_{x\in\mathbb R^n}\mathbf 1_{A}(x) \mu(A) \int_{x\in\mathbb R^n}\mathbf 1_{A}(x)","['measure-theory', 'lebesgue-measure', 'fubini-tonelli-theorems']"
67,The Cantor distribution is singular (with respect to lebesgue measure),The Cantor distribution is singular (with respect to lebesgue measure),,"If we define the Cantor distribution $\mu$ as the distribution that has $F=$ "" Cantor function "" as it's cumulative distribution function, how do we show that $\mu$ is singular with respect to the Lebesgue measure? If $\lambda$ is the Lebesgue measure I have to show that if $\lambda(A)=0$ then $\mu(A)=0$ . For a point-set $\{x\}\subset\mathbb{R}$ it does hold since $\lambda(\{x\})=0$ and $$\mu(\{x\})=\mu(\bigcap\limits_{n=1}^{\infty}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu(\bigcap\limits_{n=1}^{N}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu((x-\frac1N,x])\lim\limits_{N\to\infty}F(x)-F(x-\frac1N)=0$$ since $F$ is continuous. But how to show the property for a general $A$ $\lambda$ -measurable?","If we define the Cantor distribution as the distribution that has "" Cantor function "" as it's cumulative distribution function, how do we show that is singular with respect to the Lebesgue measure? If is the Lebesgue measure I have to show that if then . For a point-set it does hold since and since is continuous. But how to show the property for a general -measurable?","\mu F= \mu \lambda \lambda(A)=0 \mu(A)=0 \{x\}\subset\mathbb{R} \lambda(\{x\})=0 \mu(\{x\})=\mu(\bigcap\limits_{n=1}^{\infty}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu(\bigcap\limits_{n=1}^{N}(x-\frac1n,x])=\lim\limits_{N\to\infty}\mu((x-\frac1N,x])\lim\limits_{N\to\infty}F(x)-F(x-\frac1N)=0 F A \lambda","['real-analysis', 'measure-theory']"
68,Finding the Radon-Nikodym Derivative for Given Measures $\mu$ and $\nu$,Finding the Radon-Nikodym Derivative for Given Measures  and,\mu \nu,"I am currently reading about the Radon-Nikodym derivative and came across a problem in my textbook the author attempts to work through. The problem is as follows: Given $(\Omega, \mathcal{F})$ , Let $\Omega = [0,1]$ with Lebesgue measure $m$ and consider measures $\mu, \nu$ given by densites $\chi_{A}$ , $\chi_{B}$ respectively. Find a condition on the sets $A,B$ so that $\mu$ dominates $\nu$ and find the Radon-Nikodym derivative $\frac{d\nu}{d\mu}.$ While this question is pretty straightforward, I have a few questions about his work: First assume that $m(A) \neq 0$ . Then $B \subset A$ clearly implies that $\mu$ dominates $\nu$ . Now consider the partition $\mathcal{P} := \{B, A \setminus B, \Omega \setminus A\}$ of $\Omega$ . Therefore for a set $F \in \mathcal{F}$ , $$\nu(F)=m(F \cap B) =\int_{F \cap B}\chi_{B}dm=\int_{F \cap B}\chi_{B}d\mu.$$ My Questions: In the first line: I don't think I understand why we are employing the Lebesgue measure to show that $\mu$ dominates $\nu$ , Could someone explain this in more detail since it is not as clear to me as the author makes it out to be? My definition of a measure dominating another is the following: $\mu$ dominates $\nu$ $\iff$ $0\leq \nu(F) \leq \mu(F)$ $\forall F \in \mathcal{F}$ . I understand why we chose the partition $\mathcal{P} := \{B, A \setminus B, \Omega \setminus A\}$ , however, i'm not following why $\nu(F) = m(F \cap B)$ and how we conclude this equals $\int_{F \cap B}\chi_{B}d\mu$ ? Does this maybe have something to do with the Lebesgue decomposition? I am pretty new to this information, so i'm sure I am just overlooking something.","I am currently reading about the Radon-Nikodym derivative and came across a problem in my textbook the author attempts to work through. The problem is as follows: Given , Let with Lebesgue measure and consider measures given by densites , respectively. Find a condition on the sets so that dominates and find the Radon-Nikodym derivative While this question is pretty straightforward, I have a few questions about his work: First assume that . Then clearly implies that dominates . Now consider the partition of . Therefore for a set , My Questions: In the first line: I don't think I understand why we are employing the Lebesgue measure to show that dominates , Could someone explain this in more detail since it is not as clear to me as the author makes it out to be? My definition of a measure dominating another is the following: dominates . I understand why we chose the partition , however, i'm not following why and how we conclude this equals ? Does this maybe have something to do with the Lebesgue decomposition? I am pretty new to this information, so i'm sure I am just overlooking something.","(\Omega, \mathcal{F}) \Omega = [0,1] m \mu, \nu \chi_{A} \chi_{B} A,B \mu \nu \frac{d\nu}{d\mu}. m(A) \neq 0 B \subset A \mu \nu \mathcal{P} := \{B, A \setminus B, \Omega \setminus A\} \Omega F \in \mathcal{F} \nu(F)=m(F \cap B) =\int_{F \cap B}\chi_{B}dm=\int_{F \cap B}\chi_{B}d\mu. \mu \nu \mu \nu \iff 0\leq \nu(F) \leq \mu(F) \forall F \in \mathcal{F} \mathcal{P} := \{B, A \setminus B, \Omega \setminus A\} \nu(F) = m(F \cap B) \int_{F \cap B}\chi_{B}d\mu","['real-analysis', 'integration', 'measure-theory', 'lebesgue-measure', 'radon-nikodym']"
69,"Bounded random variables $X,Y$ satisfying $\mathbb{E}(X^mY^n) = \mathbb{E}(X^m)\mathbb{E}(Y^n)$ for every $m, n\in\mathbb{N}$ are independent",Bounded random variables  satisfying  for every  are independent,"X,Y \mathbb{E}(X^mY^n) = \mathbb{E}(X^m)\mathbb{E}(Y^n) m, n\in\mathbb{N}","Suppose $X, Y$ are bounded random variables and we have that for every $m, n$ positive integers, $\mathbb{E}[X^mY^n] = \mathbb{E}[X^m]\mathbb{E}[Y^n]$ . Then show that $X, Y$ are independent. I have some idea of how this is supposed to go: Using linearity, etc, $\mathbb{E}[f(X)g(Y)]$ = $\mathbb{E}[f(X)]\mathbb{E}[g(Y)]$ for all polynomials $f, g$ . After this we use limit theorems to extend this across all measurable functions, and thus characteristic functions, which will let us conclude that for every measurable set $A, B$ , we have that $\mathbb{E}[1_{X \in A}\cdot 1_{Y \in B}] = \mathbb{E}[1_{X \in A}\cdot 1_{Y\in B}]$ which reduces to $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$ which gives independence. But all the limit identities and how to use them has never been natural to me, so I wanted to verify and ask for help for the details. First, for continuous functions $f, g$ , we use the Stone-Weierstrass theorem to get polynomials sequences $f_n, g_n$ that converge uniformly to $f, g$ on the bounded interval that $X, Y$ belong to. Then $\mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)]$ , and similar for $Y, g$ . Which theorem exactly are we using here for this convergence (assuming I'm not doing something completely wrong of course); dominated convergence theorem? Once we get this, we also then demonstrate that $\mathbb{E}[f_n(X)g_n(Y)] \rightarrow \mathbb{E}[f(X)g(Y)]$ which requires showing $f_ng_n \rightarrow fg$ , but this just levarages standard analysis techniques and uses the uniform convergence, am I correct? Next we want to extend this to all measurable functions $f, g$ . For this we use the idea that there are sequences $f_n, g_n$ that will converge a.e pointwise to $f, g$ . Is this enough to conclude that $\mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)]$ , and similar for $Y, g$ ? It seems we need stronger assumptions here. I'm not entirely sure how valid this last step is and would appreciate some detail.","Suppose are bounded random variables and we have that for every positive integers, . Then show that are independent. I have some idea of how this is supposed to go: Using linearity, etc, = for all polynomials . After this we use limit theorems to extend this across all measurable functions, and thus characteristic functions, which will let us conclude that for every measurable set , we have that which reduces to which gives independence. But all the limit identities and how to use them has never been natural to me, so I wanted to verify and ask for help for the details. First, for continuous functions , we use the Stone-Weierstrass theorem to get polynomials sequences that converge uniformly to on the bounded interval that belong to. Then , and similar for . Which theorem exactly are we using here for this convergence (assuming I'm not doing something completely wrong of course); dominated convergence theorem? Once we get this, we also then demonstrate that which requires showing , but this just levarages standard analysis techniques and uses the uniform convergence, am I correct? Next we want to extend this to all measurable functions . For this we use the idea that there are sequences that will converge a.e pointwise to . Is this enough to conclude that , and similar for ? It seems we need stronger assumptions here. I'm not entirely sure how valid this last step is and would appreciate some detail.","X, Y m, n \mathbb{E}[X^mY^n] = \mathbb{E}[X^m]\mathbb{E}[Y^n] X, Y \mathbb{E}[f(X)g(Y)] \mathbb{E}[f(X)]\mathbb{E}[g(Y)] f, g A, B \mathbb{E}[1_{X \in A}\cdot 1_{Y \in B}] = \mathbb{E}[1_{X \in A}\cdot 1_{Y\in B}] P(X \in A, Y \in B) = P(X \in A)P(Y \in B) f, g f_n, g_n f, g X, Y \mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)] Y, g \mathbb{E}[f_n(X)g_n(Y)] \rightarrow \mathbb{E}[f(X)g(Y)] f_ng_n \rightarrow fg f, g f_n, g_n f, g \mathbb{E}[f_n(X)] \rightarrow \mathbb{E}[f(X)] Y, g","['probability', 'measure-theory', 'probability-limit-theorems']"
70,Support of a measure on Borel sets not well defined.,Support of a measure on Borel sets not well defined.,,"Let $(X, \tau$ ) be a topological space and let $B$ be the Borel $\sigma$ -algebra generated by $\tau$ . Let $(X,B,\mu)$ be a measure space. Then the support of the distribution $\mu$ is defined as : $$\operatorname{supp}({\mu})=\{x\in X : \mu(U)>0\text{ for all U open neighborhood of }x\}.$$ Now in the wikipedia article about  Radon measures , it is written A common problem is to find a good notion of a measure on a topological space that is compatible with the topology in some sense. One way to do this is to define a measure on the Borel sets of the topological space. In general there are several problems with this: for example, such a measure may not have a well defined support. Another approach to measure theory is to restrict to locally compact Hausdorff spaces[...] But I don't see why the support is not well defined when we use the above expression.","Let ) be a topological space and let be the Borel -algebra generated by . Let be a measure space. Then the support of the distribution is defined as : Now in the wikipedia article about  Radon measures , it is written A common problem is to find a good notion of a measure on a topological space that is compatible with the topology in some sense. One way to do this is to define a measure on the Borel sets of the topological space. In general there are several problems with this: for example, such a measure may not have a well defined support. Another approach to measure theory is to restrict to locally compact Hausdorff spaces[...] But I don't see why the support is not well defined when we use the above expression.","(X, \tau B \sigma \tau (X,B,\mu) \mu \operatorname{supp}({\mu})=\{x\in X : \mu(U)>0\text{ for all U open neighborhood of }x\}.",['measure-theory']
71,Is any subset of $\mathbb{R}$ a Borel set?,Is any subset of  a Borel set?,\mathbb{R},"Consider $S \subset \mathbb{R}$ . Define for all $n \in \{1,2,3,\ldots\}$ \begin{align*} S_n := \bigcup_{a \in S} \left (a - \frac{1}{n}, a + \frac{1}{n}\right) \end{align*} Since arbitrary union of open sets is open, $S_n$ is open for all $n$ . Now \begin{align*} S = \bigcap_{n=1}^{\infty} S_n \end{align*} Hence $S$ is the intersection of countably many open sets, therefore, it is a Borel set. Are my steps correct or is there something wrong? If there is something wrong, could you point out which step exactly?","Consider . Define for all Since arbitrary union of open sets is open, is open for all . Now Hence is the intersection of countably many open sets, therefore, it is a Borel set. Are my steps correct or is there something wrong? If there is something wrong, could you point out which step exactly?","S \subset \mathbb{R} n \in \{1,2,3,\ldots\} \begin{align*}
S_n := \bigcup_{a \in S} \left (a - \frac{1}{n}, a + \frac{1}{n}\right)
\end{align*} S_n n \begin{align*}
S = \bigcap_{n=1}^{\infty} S_n
\end{align*} S","['real-analysis', 'measure-theory', 'borel-sets']"
72,Uncountable chain of negligible sets,Uncountable chain of negligible sets,,"Let $(E,\mathcal{A},m)$ be a (non empty) measure space, with $m$ a complete measure, it's easy to prove that an uncountable union of negligible sets does not need to be negligible or even measurable. But, now, let $(I,<)$ be a totally ordered set ( $I\neq \emptyset$ and I not countable) and $(A_i)_{i\in I}$ be an increasing family of negligible sets (for $m$ ) ( ie $\forall i\in I \ \ m(A_i)=0$ and $\forall (i,j)\in I² \ \ i<j \implies A_i \subset A_j$ ). Is $A=\bigcup_{i\in I} A_i$ measurable and $m(A)=0$ ? Thanks.","Let be a (non empty) measure space, with a complete measure, it's easy to prove that an uncountable union of negligible sets does not need to be negligible or even measurable. But, now, let be a totally ordered set ( and I not countable) and be an increasing family of negligible sets (for ) ( ie and ). Is measurable and ? Thanks.","(E,\mathcal{A},m) m (I,<) I\neq \emptyset (A_i)_{i\in I} m \forall i\in I \ \ m(A_i)=0 \forall (i,j)\in I² \ \ i<j \implies A_i \subset A_j A=\bigcup_{i\in I} A_i m(A)=0",['measure-theory']
73,Conditional Expectation of X with respect to a $\sigma$-algebra $\mathcal{G}$,Conditional Expectation of X with respect to a -algebra,\sigma \mathcal{G},"I read this definition from my lecture handout: If X is a random variable on a countable probability space $(\Omega,\mathcal{F},\mathbb{P})$ , then the conditional expectation $\mathbb{E}_\mathbb{P}(X|\mathcal{G})$ of X with respect to $\mathcal{G}$ is defined as a random variable which satisfies, for every $\omega\in A_i$ , $$\mathbb{E}_\mathbb{P}(X|\mathcal{G})(\omega)=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})\mathbb{1}_{A_i}}{\mathbb{P}(A_i)}\quad\quad \forall A_i\in \mathcal{P}$$ $\mathcal{P}$ is a countable partition that generates $\mathcal{G}$ . And I have the following questions: Some of the other materials give this definition as a conditional expectation of X with respect to the whole $\sigma$ -field $\mathcal{G}$ , which without indicating the small omega, i.e.: $$\mathbb{E}_\mathbb{P}(X|\mathcal{G})=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})\mathbb{1}_{A_i}}{\mathbb{P}(A_i)}.$$ I personally support this definition, because $\mathbb{E}_\mathbb{P}(X|\mathcal{G})(\omega)$ seems to be a partial condition and it should be equivalent to $\mathbb{E}_\mathbb{P}(X|\mathcal{G})\mathbb{1}_{A_i}=\mathbb{E}_\mathbb{P}(X|A_{i})$ . So which one is the correct definition? Why we have two indicator functions over there? As per my logic, $\mathbb{E}_\mathbb{P}(X|\mathcal{G})=\sum_{i\in I}\mathbb{E}_\mathbb{P}(X|A_i)=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})}{\mathbb{P}(A_i)}.$ I don't know where is the other $\mathbb{1}_{A_i}$ comes from.","I read this definition from my lecture handout: If X is a random variable on a countable probability space , then the conditional expectation of X with respect to is defined as a random variable which satisfies, for every , is a countable partition that generates . And I have the following questions: Some of the other materials give this definition as a conditional expectation of X with respect to the whole -field , which without indicating the small omega, i.e.: I personally support this definition, because seems to be a partial condition and it should be equivalent to . So which one is the correct definition? Why we have two indicator functions over there? As per my logic, I don't know where is the other comes from.","(\Omega,\mathcal{F},\mathbb{P}) \mathbb{E}_\mathbb{P}(X|\mathcal{G}) \mathcal{G} \omega\in A_i \mathbb{E}_\mathbb{P}(X|\mathcal{G})(\omega)=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})\mathbb{1}_{A_i}}{\mathbb{P}(A_i)}\quad\quad \forall A_i\in \mathcal{P} \mathcal{P} \mathcal{G} \sigma \mathcal{G} \mathbb{E}_\mathbb{P}(X|\mathcal{G})=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})\mathbb{1}_{A_i}}{\mathbb{P}(A_i)}. \mathbb{E}_\mathbb{P}(X|\mathcal{G})(\omega) \mathbb{E}_\mathbb{P}(X|\mathcal{G})\mathbb{1}_{A_i}=\mathbb{E}_\mathbb{P}(X|A_{i}) \mathbb{E}_\mathbb{P}(X|\mathcal{G})=\sum_{i\in I}\mathbb{E}_\mathbb{P}(X|A_i)=\sum_{i\in I}\frac{\mathbb{E}_\mathbb{P}(X\mathbb{1}_{A_i})}{\mathbb{P}(A_i)}. \mathbb{1}_{A_i}","['measure-theory', 'conditional-probability', 'conditional-expectation', 'filtrations']"
74,For $0<p<1$ showing $\Big(\int_\Omega |f|^pd\mu\Big)^{1/p}\leq \frac{1}{R_0} + \Big(\int_\Omega |f_{R_0}|^p\Big)^{1/p} $,For  showing,0<p<1 \Big(\int_\Omega |f|^pd\mu\Big)^{1/p}\leq \frac{1}{R_0} + \Big(\int_\Omega |f_{R_0}|^p\Big)^{1/p} ,"In this problem Limit of $L^p$ norm when $p\to0$ , the writer states that for $0<p<1$ we have that $$\Big(\int_\Omega |f|^pd\mu\Big)^{1/p}\leq \frac{1}{R_0} + \Big(\int_\Omega |f_{R_0}|^p\Big)^{1/p} $$ where $\mu$ is a positive measure such that $\mu(\Omega)=1$ and $f_{R_0}=|f|1_A$ where $A={\{x: |f(x)|\geq \frac{1}{R_0}\}}$ . I see that $$\int_\Omega |f|^pd\mu = \int_A |f|^pd\mu + \int_{A^c}|f|^pd\mu \leq \int_\Omega |f_{R_0}|^pd\mu + \frac{1}{R_0^p}$$ But I know that $a^{1/p} + b^{1/p}\leq (a+b)^{1/p}$ where $a,b\geq0$ . So I am not sure how to distribute the the $1/p$ power.","In this problem Limit of $L^p$ norm when $p\to0$ , the writer states that for we have that where is a positive measure such that and where . I see that But I know that where . So I am not sure how to distribute the the power.","0<p<1 \Big(\int_\Omega |f|^pd\mu\Big)^{1/p}\leq \frac{1}{R_0} + \Big(\int_\Omega |f_{R_0}|^p\Big)^{1/p}  \mu \mu(\Omega)=1 f_{R_0}=|f|1_A A={\{x: |f(x)|\geq \frac{1}{R_0}\}} \int_\Omega |f|^pd\mu = \int_A |f|^pd\mu + \int_{A^c}|f|^pd\mu \leq \int_\Omega |f_{R_0}|^pd\mu + \frac{1}{R_0^p} a^{1/p} + b^{1/p}\leq (a+b)^{1/p} a,b\geq0 1/p","['real-analysis', 'integration', 'measure-theory', 'inequality', 'lp-spaces']"
75,Natural density extended to real density?,Natural density extended to real density?,,"The natural density of the set $A \subseteq \mathbb{N}$ is defined as $$\delta(A)=\lim_{n \rightarrow \infty}\frac{ \# \{k \in A | k \leq n \} }{ \# \{k \in \mathbb{N} | k \leq n \} }.$$ My idea was to generalize this to sets with greater cardinality: For example take the set $B = \{x \in \mathbb{C} | \ \lvert x \rvert \leq \frac{1}{2} \}$ instead of $A$ and the unit disk $U = \{x \in \mathbb{C} | \ \lvert x \rvert \leq 1 \}$ instead of $\mathbb{N}$ . Now we know by some easy geometrical calculations that the ratio is $\frac{1}{4}$ . How do we get this by a concept similar to the natural density or other densities with countable sets? Is there a density concept (with limits) for general sets, including uncountable ones like $\mathbb{R}$ ? Thanks for your ideas, comments and answers!","The natural density of the set is defined as My idea was to generalize this to sets with greater cardinality: For example take the set instead of and the unit disk instead of . Now we know by some easy geometrical calculations that the ratio is . How do we get this by a concept similar to the natural density or other densities with countable sets? Is there a density concept (with limits) for general sets, including uncountable ones like ? Thanks for your ideas, comments and answers!",A \subseteq \mathbb{N} \delta(A)=\lim_{n \rightarrow \infty}\frac{ \# \{k \in A | k \leq n \} }{ \# \{k \in \mathbb{N} | k \leq n \} }. B = \{x \in \mathbb{C} | \ \lvert x \rvert \leq \frac{1}{2} \} A U = \{x \in \mathbb{C} | \ \lvert x \rvert \leq 1 \} \mathbb{N} \frac{1}{4} \mathbb{R},"['combinatorics', 'measure-theory', 'density-function', 'natural-numbers']"
76,Haar measure on compact group completely positive,Haar measure on compact group completely positive,,"Is it true that the Haar measure $\mu$ on a compact group $G$ is always completely positive, i.e. every nonempty open set has positive measure? I think I have a very simple proof of it, but honestly, the fact I tried Googling this fact and couldn’t find any mention of it, so I’m second-guessing my argument, which is as follows: Let $G$ be a compact group, and $U \subseteq G$ a nonempty open subset of $G$ . Then $\mathscr{U} = \{ g U : g \in G \}$ is an open cover of $G$ , so there exist $g_1, \ldots, g_n \in G$ such that $G = \bigcup_{j = 1}^n g_j U$ . Then $1 = \mu(G) \leq \sum_{j = 1}^n \mu (g_j U) = n \cdot \mu(U)$ . Thus $\mu(U) \geq \frac{1}{n} >0$ .","Is it true that the Haar measure on a compact group is always completely positive, i.e. every nonempty open set has positive measure? I think I have a very simple proof of it, but honestly, the fact I tried Googling this fact and couldn’t find any mention of it, so I’m second-guessing my argument, which is as follows: Let be a compact group, and a nonempty open subset of . Then is an open cover of , so there exist such that . Then . Thus .","\mu G G U \subseteq G G \mathscr{U} = \{ g U : g \in G \} G g_1, \ldots, g_n \in G G = \bigcup_{j = 1}^n g_j U 1 = \mu(G) \leq \sum_{j = 1}^n \mu (g_j U) = n \cdot \mu(U) \mu(U) \geq \frac{1}{n} >0","['measure-theory', 'haar-measure']"
77,Integration of function using Hausdorff measure of Cantor Set,Integration of function using Hausdorff measure of Cantor Set,,"I am learning geometry on fractal shapes, along with how fractional calculus can relate to said geometry. At the moment I am trying to understand integration over a Hausdorff measure. According to Falconer's The Geometry of Fractal Sets, the middle-third Cantor set has a $\log_3 2$ -Hausdorff measure of $1$ . I would like to describe this relation as $\int_{C} 1 \; \mathrm{d}H^{s}(x)=1$ , where $C$ is the Cantor set, and $s = \log_3 2$ . My question is : How would the integral $$\int_{C} (e^x + x)\; \mathrm{d}H^{s}(x)$$ be evaluated? I'm not entirely sure where to begin in evaluating this, since this is new to me. I would appreciate resources as well, but I think an answer to this problem will give me the tools I need to evaluate other functions on other fractal sets. Thank you.","I am learning geometry on fractal shapes, along with how fractional calculus can relate to said geometry. At the moment I am trying to understand integration over a Hausdorff measure. According to Falconer's The Geometry of Fractal Sets, the middle-third Cantor set has a -Hausdorff measure of . I would like to describe this relation as , where is the Cantor set, and . My question is : How would the integral be evaluated? I'm not entirely sure where to begin in evaluating this, since this is new to me. I would appreciate resources as well, but I think an answer to this problem will give me the tools I need to evaluate other functions on other fractal sets. Thank you.",\log_3 2 1 \int_{C} 1 \; \mathrm{d}H^{s}(x)=1 C s = \log_3 2 \int_{C} (e^x + x)\; \mathrm{d}H^{s}(x),"['measure-theory', 'fractals', 'hausdorff-measure', 'fractal-analysis']"
78,Haar measure on Lie Group is unique,Haar measure on Lie Group is unique,,My question is Why is the Haar measure on a Lie Group unique upto scalar multiple? I know how to show it for $\mathbb R^n$ because there I have countable many open balls that form a base and the measure of the unit ball around 0 gives the constant scalar. How to show for general Lie Group?,My question is Why is the Haar measure on a Lie Group unique upto scalar multiple? I know how to show it for because there I have countable many open balls that form a base and the measure of the unit ball around 0 gives the constant scalar. How to show for general Lie Group?,\mathbb R^n,"['measure-theory', 'lie-groups', 'haar-measure']"
79,Constructing an open non Jordan measurable set,Constructing an open non Jordan measurable set,,"I am trying to construct an example of a bounded, open, non Jordan measurable set. I enumerate the rationals in $(0,1)^2$ by $\{q_n\}_{n=1}^\infty$ and define $$B_n=\Big(q_n^{(1)}-\frac{1}{2^{n+1}}, q_n^{(1)}+ \frac{1}{2^{n+1}} \Big) \times \Big(q_n^{(2)}-\frac{1}{2^{n+1}}, q_n^{(2)}+ \frac{1}{2^{n+1}} \Big)\cap (0,1)^2,$$ where $q_n=\big( q_n^{(1)},q_n^{(2)} \big)$ . I then define $B=\cup_{n=1}^\infty B_n$ , and try to show that $B$ is not Jordan measurable. I denote by $J^*$ the Jordan outer measure and by $J_*$ the Jordan inner measure, and am trying to show that $J^*(B)>J_*(B)$ . I think I've shown that $J^*(B)=1$ since $\overline{B}=[0,1]^2$ , but I'm having problems showing that $J_*(B)\leq \frac{1}{3}$ . If I define $B_N= \cup_{n=1}^N B_n$ , I can show that $J^*(B_N) \leq \frac{1}{3} \cdot \big( 1-\frac{1}{4^N} \big)$ , but since I only have finite additivity and not $\sigma$ -additivity, I am struggling to show that $J_*(B)\leq \frac{1}{3}$ . At some point I thought to myself that this was enough, but I ca't figure out how to show that any elementary subset $L\subset B$ , a finite union of rectangles, $m(L)\leq \frac{1}{3}$ . I think that this should be a relatively simple argument that I'm not seeing, and would appreciate any useful suggestions.","I am trying to construct an example of a bounded, open, non Jordan measurable set. I enumerate the rationals in by and define where . I then define , and try to show that is not Jordan measurable. I denote by the Jordan outer measure and by the Jordan inner measure, and am trying to show that . I think I've shown that since , but I'm having problems showing that . If I define , I can show that , but since I only have finite additivity and not -additivity, I am struggling to show that . At some point I thought to myself that this was enough, but I ca't figure out how to show that any elementary subset , a finite union of rectangles, . I think that this should be a relatively simple argument that I'm not seeing, and would appreciate any useful suggestions.","(0,1)^2 \{q_n\}_{n=1}^\infty B_n=\Big(q_n^{(1)}-\frac{1}{2^{n+1}}, q_n^{(1)}+ \frac{1}{2^{n+1}} \Big) \times \Big(q_n^{(2)}-\frac{1}{2^{n+1}}, q_n^{(2)}+ \frac{1}{2^{n+1}} \Big)\cap (0,1)^2, q_n=\big( q_n^{(1)},q_n^{(2)} \big) B=\cup_{n=1}^\infty B_n B J^* J_* J^*(B)>J_*(B) J^*(B)=1 \overline{B}=[0,1]^2 J_*(B)\leq \frac{1}{3} B_N= \cup_{n=1}^N B_n J^*(B_N) \leq \frac{1}{3} \cdot \big( 1-\frac{1}{4^N} \big) \sigma J_*(B)\leq \frac{1}{3} L\subset B m(L)\leq \frac{1}{3}","['real-analysis', 'measure-theory', 'proof-writing']"
80,Borel-Cantelli Lemma - is the measurability assumption necessary?,Borel-Cantelli Lemma - is the measurability assumption necessary?,,"I've seen this version of the Borel-Cantelli Lemma in Stein and Shakarchi: Let $(E_k)_{k=1}^{\infty}$ be a countable family of measurable subsets of $\mathbb{R}^d$ satisfying $$\sum_{k=1}^{\infty}m(E_k) < \infty$$ Let $E$ be the set of $x\in \mathbb{R}^d$ such that $x\in E_k$ for infinitely many $k$ . Then $E$ is measurable and $m(E) = 0$ . Now in proving this it seems straightforward enough to show that the tail of the sequence goes to $0$ , so for any $\varepsilon > 0$ , choose $K\in\mathbb{N}$ such that $\sum_{k=K}^\infty m(A_k) < \varepsilon$ . Now by definition of $E$ , we have $E\subset \bigcup_{k=K}^{\infty}E_k$ so by monotonicity and subadditivity of the exterior measure, $m_*(E) \leq \sum_{k=K}^\infty m(A_k) < \varepsilon$ which proves the result. But did we need the measurability assumption? I did not use it anywhere in this argument, so is that a mistake on my part or would this hold for a collection of sets which may not all be measurable, but the series of their exterior measures still converges.","I've seen this version of the Borel-Cantelli Lemma in Stein and Shakarchi: Let be a countable family of measurable subsets of satisfying Let be the set of such that for infinitely many . Then is measurable and . Now in proving this it seems straightforward enough to show that the tail of the sequence goes to , so for any , choose such that . Now by definition of , we have so by monotonicity and subadditivity of the exterior measure, which proves the result. But did we need the measurability assumption? I did not use it anywhere in this argument, so is that a mistake on my part or would this hold for a collection of sets which may not all be measurable, but the series of their exterior measures still converges.",(E_k)_{k=1}^{\infty} \mathbb{R}^d \sum_{k=1}^{\infty}m(E_k) < \infty E x\in \mathbb{R}^d x\in E_k k E m(E) = 0 0 \varepsilon > 0 K\in\mathbb{N} \sum_{k=K}^\infty m(A_k) < \varepsilon E E\subset \bigcup_{k=K}^{\infty}E_k m_*(E) \leq \sum_{k=K}^\infty m(A_k) < \varepsilon,"['measure-theory', 'borel-cantelli-lemmas', 'outer-measure']"
81,$\int_{\Bbb{T}} e_n(\lambda) |\varphi(\lambda)|^2 = 0$ for all $n \neq 0$ implies $|\varphi|^2$ is constant almost surely,for all  implies  is constant almost surely,\int_{\Bbb{T}} e_n(\lambda) |\varphi(\lambda)|^2 = 0 n \neq 0 |\varphi|^2,"Consider the circle group $\Bbb{T}\subseteq \Bbb{C}$ with its Haar measure $d \lambda$ . I have the following situation: $\varphi \in L^2(\Bbb{T})$ has norm $1$ , i.e. $$\Vert \varphi\Vert_2^2 = \int_\Bbb{T} |\varphi|^2 d \lambda=1$$ Put $e_n(\lambda) = \lambda^n, n \in \Bbb{Z}$ . We have the following situation $$n \neq 0 \implies \int_\Bbb{T} e_n |\varphi|^2 d \lambda = 0$$ Can I deduce that $|\varphi|^2$ is constant almost surely? Attempt: I tried to show that $|\varphi|^2 \in L^2(\Bbb{T})$ , so that $$|\varphi|^ 2 = \sum_{n \in \Bbb{Z}}\langle |\varphi|^2, e_n\rangle e_n= \langle |\varphi|^2, e_0\rangle e_0$$ by Plancherel's theorem. However, I don't succeed in showing that $|\varphi|^2 \in L^2(\Bbb{T})$","Consider the circle group with its Haar measure . I have the following situation: has norm , i.e. Put . We have the following situation Can I deduce that is constant almost surely? Attempt: I tried to show that , so that by Plancherel's theorem. However, I don't succeed in showing that","\Bbb{T}\subseteq \Bbb{C} d \lambda \varphi \in L^2(\Bbb{T}) 1 \Vert \varphi\Vert_2^2 = \int_\Bbb{T} |\varphi|^2 d \lambda=1 e_n(\lambda) = \lambda^n, n \in \Bbb{Z} n \neq 0 \implies \int_\Bbb{T} e_n |\varphi|^2 d \lambda = 0 |\varphi|^2 |\varphi|^2 \in L^2(\Bbb{T}) |\varphi|^ 2 = \sum_{n \in \Bbb{Z}}\langle |\varphi|^2, e_n\rangle e_n= \langle |\varphi|^2, e_0\rangle e_0 |\varphi|^2 \in L^2(\Bbb{T})","['measure-theory', 'fourier-analysis']"
82,Show that $\mu (X)< \infty$,Show that,\mu (X)< \infty,"Let $(X,A,\mu)$ be a measure space and $f:X\rightarrow ]0, \infty[$ summable such that $\frac{1}{f}$ is also summable. Show that $\mu (X)< \infty$ What I did was applying cauchy-schwarz inequality on $f$ and $\frac{1}{f}$ , $\mu (X)^2=\left ( \int_{X}^{}\left | f \right |\left | \frac{1}{f} \right |d\mu \right )^2\leq \left ( \int_{X}^{}|f|^2d\mu \right )\left ( \int_{X}^{} \frac{1}{|f|^2}d\mu\right )$ How can I continue ? I was thinking of considering cases for $f$ when it is bounded and when not, but I don't know if it's useful","Let be a measure space and summable such that is also summable. Show that What I did was applying cauchy-schwarz inequality on and , How can I continue ? I was thinking of considering cases for when it is bounded and when not, but I don't know if it's useful","(X,A,\mu) f:X\rightarrow ]0, \infty[ \frac{1}{f} \mu (X)< \infty f \frac{1}{f} \mu (X)^2=\left ( \int_{X}^{}\left | f \right |\left | \frac{1}{f} \right |d\mu \right )^2\leq \left ( \int_{X}^{}|f|^2d\mu \right )\left ( \int_{X}^{} \frac{1}{|f|^2}d\mu\right ) f","['measure-theory', 'cauchy-schwarz-inequality']"
83,"$\rho(f,g)=\int_E \min(1,|f-g|)dm$. Prove that $f_n$ converges to $f$ in measure if and only if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow\infty$",. Prove that  converges to  in measure if and only if  as,"\rho(f,g)=\int_E \min(1,|f-g|)dm f_n f \rho(f_n,f)\rightarrow 0 n\rightarrow\infty","Question :  Suppose $m$ is a finitemeasure on a measurable space $E$ .  Define $\rho(f,g)=\int_E \min(1,|f-g|)dm$ .  Prove that $f_n$ converges to $f$ in measure if and only if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow\infty$ . My Thoughts : For the backwards direction, if $\rho(f_n,f)\rightarrow 0$ as $n\rightarrow 0$ , then we have that $\lim_{n\rightarrow\infty}\int_E\min(1,|f_n-f|)dm=\lim_{n\rightarrow\infty}\int_E|f_n-f|dm=0$ , and so we have uniform convergence, which implies in measure convergence.  For the forward direction, I am not really sure if I should consider cases, that is, when $1$ is the minimum and then when $f_n-f$ is the minimum and show that if $1$ is the minimum then the statement can't be true, and so $f_n-f$ must be the minimum and then show that the only way we get in measure convergence is if that integral equals $0$ ... but I am not quite sure how to do that.   Any thoughts, suggestions, etc. are greatly appreciated!  Thank you.","Question :  Suppose is a finitemeasure on a measurable space .  Define .  Prove that converges to in measure if and only if as . My Thoughts : For the backwards direction, if as , then we have that , and so we have uniform convergence, which implies in measure convergence.  For the forward direction, I am not really sure if I should consider cases, that is, when is the minimum and then when is the minimum and show that if is the minimum then the statement can't be true, and so must be the minimum and then show that the only way we get in measure convergence is if that integral equals ... but I am not quite sure how to do that.   Any thoughts, suggestions, etc. are greatly appreciated!  Thank you.","m E \rho(f,g)=\int_E \min(1,|f-g|)dm f_n f \rho(f_n,f)\rightarrow 0 n\rightarrow\infty \rho(f_n,f)\rightarrow 0 n\rightarrow 0 \lim_{n\rightarrow\infty}\int_E\min(1,|f_n-f|)dm=\lim_{n\rightarrow\infty}\int_E|f_n-f|dm=0 1 f_n-f 1 f_n-f 0","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
84,"Two sequences $f_n$ and $g_n$ such that $\int_{[0,1]}f_n g_n$ does not go to $0$ as $n\rightarrow\infty$, with these conditions on $f_n$ and $g_n$","Two sequences  and  such that  does not go to  as , with these conditions on  and","f_n g_n \int_{[0,1]}f_n g_n 0 n\rightarrow\infty f_n g_n","Question: Suppose $f_n, g_n:[0,1]\rightarrow\mathbb{R}$ are measurable functions such that $f_n\rightarrow 0$ a.e. on $[0,1]$ and $\sup_n\int_{[0,1]}|g_n|dx<\infty$ . Give an example of two sequences $f_n$ and $g_n$ such that $\int_{[0,1]}f_n g_n$ does not go to $0$ as $n\rightarrow\infty$ . Prove that for any such sequences $f_n$ and $g_n$ , and every $\epsilon>0$ , there exists a measurable set $E\subset[0,1]$ such that $m(E)>1-\epsilon$ and $\int_Ef_n g_ndx\rightarrow 0$ . My thoughts:  I was thinking of doing something like $f_n=n\chi_{(0,\frac{1}{n}]}$ , which I believe would converge pointwise to $1$ a.e...I am just having a hard time trying to think of a $g_n$ that would work such that the integral of their product over $[0,1]$ wouldn't go to $0$ .... For the second question, I immediately was thinking Egorov, but I haven't quite been able to figure out how to use it here. Any suggestions, ideas, etc. are appreciated!  Thank you.","Question: Suppose are measurable functions such that a.e. on and . Give an example of two sequences and such that does not go to as . Prove that for any such sequences and , and every , there exists a measurable set such that and . My thoughts:  I was thinking of doing something like , which I believe would converge pointwise to a.e...I am just having a hard time trying to think of a that would work such that the integral of their product over wouldn't go to .... For the second question, I immediately was thinking Egorov, but I haven't quite been able to figure out how to use it here. Any suggestions, ideas, etc. are appreciated!  Thank you.","f_n, g_n:[0,1]\rightarrow\mathbb{R} f_n\rightarrow 0 [0,1] \sup_n\int_{[0,1]}|g_n|dx<\infty f_n g_n \int_{[0,1]}f_n g_n 0 n\rightarrow\infty f_n g_n \epsilon>0 E\subset[0,1] m(E)>1-\epsilon \int_Ef_n g_ndx\rightarrow 0 f_n=n\chi_{(0,\frac{1}{n}]} 1 g_n [0,1] 0","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
85,Counterexample to finiteness of KL divergence?,Counterexample to finiteness of KL divergence?,,"Suppose $P,Q$ are two probability distributions on a measurable space $(X, \mathcal F)$ . The KL-divergence between $P$ and $Q$ is defined as \begin{equation} D_{KL}[P||Q] = \int_X \log \frac {dP}{dQ}dP  \end{equation} when $P$ is absolutely continuous wrt $Q$ , and $ + \infty$ otherwise. So we know that $P$ not absolutely continuous wrt $Q$ yields $D_{KL}[P\|Q]=+\infty$ . My question is whether the converse holds: are there distributions with $P \ll Q$ (absolutely continuous) and $D_{KL}[P\|Q]=+\infty$ ?","Suppose are two probability distributions on a measurable space . The KL-divergence between and is defined as when is absolutely continuous wrt , and otherwise. So we know that not absolutely continuous wrt yields . My question is whether the converse holds: are there distributions with (absolutely continuous) and ?","P,Q (X, \mathcal F) P Q \begin{equation}
D_{KL}[P||Q] = \int_X \log \frac {dP}{dQ}dP 
\end{equation} P Q  + \infty P Q D_{KL}[P\|Q]=+\infty P \ll Q D_{KL}[P\|Q]=+\infty","['measure-theory', 'probability-distributions', 'examples-counterexamples', 'absolute-continuity', 'information-geometry']"
86,"Is this space subspace of $[0,1]^{\mathbb{N}}$ Polish?",Is this space subspace of  Polish?,"[0,1]^{\mathbb{N}}","Let $D := \{ x \in [0, 1]^{\mathbb{N}} \mid \forall n: x_n = 1 \Rightarrow x_{n+1} = 1 \}$ be the set of sequences in $[0, 1]$ such that if $x_n = 1$ for some $n$ then $x_{n+m} = 1$ for all $m \geq 0$ . I know that $[0, 1]^{\mathbb{N}}$ is Polish. Is $D$ with the subspace topology also Polish? I can represent $D$ as a countable union of pairwise disjoint closed sets $D = (\{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times \{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times [0, 1) \times \{ 1 \} \times \{ 1 \} \dots) \cup \dots \cup ([0, 1) \times [0, 1) \times \dots)$ but there is no theorem stating that such subsets are necessarily Polish. I can also represent $D$ as a countable intersection as follows: translate the condition $x_n = 1 \Rightarrow x_{n+1} = 1$ into the set $A = ([0, 1) \times [0, 1]) \cup (\{ 1 \} \times \{ 1 \})$ . Then $D = (A \times [0, 1] \times [0, 1] \times \dots) \cap ([0, 1] \times A \times [0,1] \times [0,1] \times \dots) \cap ([0,1] \times [0,1] \times A \times [0,1] \times [0,1] \times \dots) \cap \dots$ . To show that $D$ is Polish it is enough to prove that $A$ is Polish. (Then the sets $A \times [0,1] \times \dots$ and so on are all Polish (as countable products of Polish spaces are Polish) and therefore their countable intersection $D$ is Polish.) $A$ with the Euclidean metric is not complete. Is it possible to construct a compatible complete metric on $A$ ?",Let be the set of sequences in such that if for some then for all . I know that is Polish. Is with the subspace topology also Polish? I can represent as a countable union of pairwise disjoint closed sets but there is no theorem stating that such subsets are necessarily Polish. I can also represent as a countable intersection as follows: translate the condition into the set . Then . To show that is Polish it is enough to prove that is Polish. (Then the sets and so on are all Polish (as countable products of Polish spaces are Polish) and therefore their countable intersection is Polish.) with the Euclidean metric is not complete. Is it possible to construct a compatible complete metric on ?,"D := \{ x \in [0, 1]^{\mathbb{N}} \mid \forall n: x_n = 1 \Rightarrow x_{n+1} = 1 \} [0, 1] x_n = 1 n x_{n+m} = 1 m \geq 0 [0, 1]^{\mathbb{N}} D D D = (\{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times \{ 1 \} \times \{ 1 \} \times \dots) \cup ([0, 1) \times [0, 1) \times \{ 1 \} \times \{ 1 \} \dots) \cup \dots \cup ([0, 1) \times [0, 1) \times \dots) D x_n = 1 \Rightarrow x_{n+1} = 1 A = ([0, 1) \times [0, 1]) \cup (\{ 1 \} \times \{ 1 \}) D = (A \times [0, 1] \times [0, 1] \times \dots) \cap ([0, 1] \times A \times [0,1] \times [0,1] \times \dots) \cap ([0,1] \times [0,1] \times A \times [0,1] \times [0,1] \times \dots) \cap \dots D A A \times [0,1] \times \dots D A A","['measure-theory', 'descriptive-set-theory']"
87,limit of the mollifying sequence,limit of the mollifying sequence,,"Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ be an $L^1(\mathbb{R}^2; \mathbb{R})$ function. Let $A \subset \mathbb{R}$ be a measurable set. Let $\eta: \mathbb{R}\rightarrow \mathbb{R} \in C_c^{\infty}(\mathbb{R}),$ with support in $[-1,1]$ such that $\int\limits_{\mathbb{R}}\eta(x)dx=1.$ Then consider the following limit \begin{eqnarray} \lim\limits_{\epsilon \rightarrow 0}\frac{1}{\epsilon}\int\limits_{\mathbb{R}} \int\limits_{A} f(x,y)\eta\left(\frac{x-y}{\epsilon}\right)dy dx. \end{eqnarray} What is the value of the limit? How to prove it. P.S: Define $\eta_{\epsilon}(x):=\frac{1}{\epsilon}\eta(\frac{x}{\epsilon}).$ Then $\eta_{\epsilon} \rightarrow \delta_0.$ So, I think the limit is, \begin{eqnarray} \int\limits_{A} f(x,x)dx. \end{eqnarray} is it correct? How to prove it?","Let be an function. Let be a measurable set. Let with support in such that Then consider the following limit What is the value of the limit? How to prove it. P.S: Define Then So, I think the limit is, is it correct? How to prove it?","f:\mathbb{R}^2 \rightarrow \mathbb{R} L^1(\mathbb{R}^2; \mathbb{R}) A \subset \mathbb{R} \eta: \mathbb{R}\rightarrow \mathbb{R} \in C_c^{\infty}(\mathbb{R}), [-1,1] \int\limits_{\mathbb{R}}\eta(x)dx=1. \begin{eqnarray}
\lim\limits_{\epsilon \rightarrow 0}\frac{1}{\epsilon}\int\limits_{\mathbb{R}}
\int\limits_{A} f(x,y)\eta\left(\frac{x-y}{\epsilon}\right)dy dx.
\end{eqnarray} \eta_{\epsilon}(x):=\frac{1}{\epsilon}\eta(\frac{x}{\epsilon}). \eta_{\epsilon} \rightarrow \delta_0. \begin{eqnarray}
\int\limits_{A} f(x,x)dx.
\end{eqnarray}","['real-analysis', 'integration', 'measure-theory']"
88,"If $f$ is measurable, can we write $f = r \cdot \exp(i\varphi)$ for $r, \varphi$ measurable?","If  is measurable, can we write  for  measurable?","f f = r \cdot \exp(i\varphi) r, \varphi","It is well known, that if we have an interval $[a,b] \subset \mathbb{R}$ and a continuous curve $c \colon [a,b] \to \mathbb{R}^2$ with $c(t) \neq 0$ for all $t$ , then there exist continuous functions $r \colon [a,b] \to (0,\infty)$ and $\varphi \colon [a,b] \to \mathbb{R}$ so that $$c(t) = r(t)(\cos(\varphi(t)), \sin(\varphi(t)))$$ holds for all $t \in [a,b]$ . This motivates the following question: If $(X, \mathcal{A}, \mu)$ is a measure space and $f \colon X \to \mathbb{C}$ is measurable, do there exist measurable functions $r \colon X \to [0, \infty)$ (note that $r$ is allowed to be 0) and $\varphi \colon X \to \mathbb{R}$ so that $$f(x) = r(x)(\cos(\varphi(x)) + i \sin(\varphi(x)))$$ I know that $\varphi$ (if existent) certainly will not be unique and that $r$ can indeed be found quite easily by $$r(x) = |f(x)|$$ So the main struggle is with finding $\varphi$ . Can we prove that there always exists such a measurable $\varphi$ ? Edit: As pointed out in the comments, the statement holds for simple functions $f = \sum \alpha_k \chi_{A_k}$ , by simply setting $r = |f|$ and $\varphi = \sum \varphi_k \chi_{A_k}$ , where the $\varphi_k \in \mathbb{R}$ are chosen such that $f(x) = r(x) \exp(i\varphi_k)$ , since then by construction $$f = r \cdot \exp(i\varphi)$$ Now it is clear, that if we have an arbitrary measurable function $f$ , then we can approximate $f$ by simple function, thus by what we have seen before, we may find a sequence of simple functions $\{\varphi_n\}$ such that $$r(x)\exp(i\varphi_n(x)) \to f(x)$$ for all $x \in X$ . However, this does not guarantee, that there exists some $\varphi \colon X \to \mathbb{R}$ so that $\varphi_n(x) \to \varphi(x)$ and $r(x)\exp(i\varphi(x)) = f(x)$ for all $x$ .","It is well known, that if we have an interval and a continuous curve with for all , then there exist continuous functions and so that holds for all . This motivates the following question: If is a measure space and is measurable, do there exist measurable functions (note that is allowed to be 0) and so that I know that (if existent) certainly will not be unique and that can indeed be found quite easily by So the main struggle is with finding . Can we prove that there always exists such a measurable ? Edit: As pointed out in the comments, the statement holds for simple functions , by simply setting and , where the are chosen such that , since then by construction Now it is clear, that if we have an arbitrary measurable function , then we can approximate by simple function, thus by what we have seen before, we may find a sequence of simple functions such that for all . However, this does not guarantee, that there exists some so that and for all .","[a,b] \subset \mathbb{R} c \colon [a,b] \to \mathbb{R}^2 c(t) \neq 0 t r \colon [a,b] \to (0,\infty) \varphi \colon [a,b] \to \mathbb{R} c(t) = r(t)(\cos(\varphi(t)), \sin(\varphi(t))) t \in [a,b] (X, \mathcal{A}, \mu) f \colon X \to \mathbb{C} r \colon X \to [0, \infty) r \varphi \colon X \to \mathbb{R} f(x) = r(x)(\cos(\varphi(x)) + i \sin(\varphi(x))) \varphi r r(x) = |f(x)| \varphi \varphi f = \sum \alpha_k \chi_{A_k} r = |f| \varphi = \sum \varphi_k \chi_{A_k} \varphi_k \in \mathbb{R} f(x) = r(x) \exp(i\varphi_k) f = r \cdot \exp(i\varphi) f f \{\varphi_n\} r(x)\exp(i\varphi_n(x)) \to f(x) x \in X \varphi \colon X \to \mathbb{R} \varphi_n(x) \to \varphi(x) r(x)\exp(i\varphi(x)) = f(x) x","['measure-theory', 'polar-coordinates']"
89,On Borel $\sigma$-algebra of subset as a subspace,On Borel -algebra of subset as a subspace,\sigma,"Let $S$ be a subset of the set of real numbers $\mathbb{R}$ , let $\mathcal{B}$ be the Borel $\sigma$ -algebra generated by all open subsets of $\mathbb{R}$ . Consider $S$ as a topological space endowed with the subspace topology (i.e., the topology inherited from $\mathbb{R}$ ), and let ${\mathcal{B}}_S$ denote the Borel $\sigma$ -algebra generated by all open subsets of S. Is it true that ${\mathcal{B}}_S\subset \mathcal{B}$ ? (Here, the set $S$ is not necessarily a Borel set in $\mathbb{R}$ .) I think, in general, this is not true. However, I could not find a counter-example.","Let be a subset of the set of real numbers , let be the Borel -algebra generated by all open subsets of . Consider as a topological space endowed with the subspace topology (i.e., the topology inherited from ), and let denote the Borel -algebra generated by all open subsets of S. Is it true that ? (Here, the set is not necessarily a Borel set in .) I think, in general, this is not true. However, I could not find a counter-example.",S \mathbb{R} \mathcal{B} \sigma \mathbb{R} S \mathbb{R} {\mathcal{B}}_S \sigma {\mathcal{B}}_S\subset \mathcal{B} S \mathbb{R},"['measure-theory', 'borel-sets']"
90,When is the integral of a function well defined with respect to a signed measure?,When is the integral of a function well defined with respect to a signed measure?,,"When is the integral of a function well defined with respect to a signed measure? Hello friends, I have a question. I appreciate who can guide me a little. Is the next: Let $ (\Omega, \Sigma, \mu) $ be a measure space, where $ \mu $ is a signed measure. If $f $ is measurable in $ (\Omega, \Sigma) $ when does it make sense to talk about the integral of $f $ with respect to $\mu$ ? The natural thing is to think of defining it in the following way: $$\int_{\Omega} fd\mu: = \int_{\Omega}fd\mu_{+}-\int_{\Omega}fd\mu_ {-},$$ where $\mu = \mu_ {+}-\mu_{-},$ but something like $ \infty- \infty $ can happen, right? Are there other conditions to define the integral in signed measures?","When is the integral of a function well defined with respect to a signed measure? Hello friends, I have a question. I appreciate who can guide me a little. Is the next: Let be a measure space, where is a signed measure. If is measurable in when does it make sense to talk about the integral of with respect to ? The natural thing is to think of defining it in the following way: where but something like can happen, right? Are there other conditions to define the integral in signed measures?"," (\Omega, \Sigma, \mu)   \mu  f   (\Omega, \Sigma)  f  \mu \int_{\Omega} fd\mu: = \int_{\Omega}fd\mu_{+}-\int_{\Omega}fd\mu_ {-}, \mu = \mu_ {+}-\mu_{-},  \infty- \infty ","['integration', 'measure-theory']"
91,Show that: $ \sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e $,Show that:, \sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e ,"Let $(\Omega,\mathcal{A},\mu)$ be a finite mesure space, and $\{f_n\}$ and $\{g_n\}$ are two $L^1$ -bounded sequence, such that : $$ \sum_{n\geq 1}{\frac{1}{n}(F_n(f_n)(\omega)-g_n(\omega))}<\infty\qquad a.e $$ with: $F_n(f_n)=f_n1_{|f_n|\leq n}$ Show that: $$ \sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e $$ My effort: according to $\sup_n\|f_n\|_1<\infty$ , there exists $n_0\geq 1$ , such that: for all $n\geq 1$ we have $$|f_n|\leq n_0~~  a.e.$$ Then for all $n\geq n_0$ : $$F_n(f_n)=f_n$$ hence, we have the desired result. Is what I wrote correct?","Let be a finite mesure space, and and are two -bounded sequence, such that : with: Show that: My effort: according to , there exists , such that: for all we have Then for all : hence, we have the desired result. Is what I wrote correct?","(\Omega,\mathcal{A},\mu) \{f_n\} \{g_n\} L^1 
\sum_{n\geq 1}{\frac{1}{n}(F_n(f_n)(\omega)-g_n(\omega))}<\infty\qquad a.e
 F_n(f_n)=f_n1_{|f_n|\leq n} 
\sum_{n\geq 1}{\frac{1}{n}(f_n(\omega)-g_n(\omega))}<\infty\qquad a.e
 \sup_n\|f_n\|_1<\infty n_0\geq 1 n\geq 1 |f_n|\leq n_0~~  a.e. n\geq n_0 F_n(f_n)=f_n","['probability', 'measure-theory', 'lebesgue-measure']"
92,A set with positive Lebesgue Measure and not Borel measurable,A set with positive Lebesgue Measure and not Borel measurable,,I know that Lebesgue measure is completion of Borel measure and there is zero Lebesgue measured set that is not Borel measurable. However I could not be sure that is there any set with positive Lebesgue measure which is not Borel measurable. I appreciate for any explanation or suggest etc.,I know that Lebesgue measure is completion of Borel measure and there is zero Lebesgue measured set that is not Borel measurable. However I could not be sure that is there any set with positive Lebesgue measure which is not Borel measurable. I appreciate for any explanation or suggest etc.,,"['measure-theory', 'lebesgue-measure', 'borel-measures']"
93,Smoothing measure by convolution,Smoothing measure by convolution,,"I'm reading Optimal Transport for Applied Mathematicians by Fillipo Santambrogio. At one point he says that taking the convolution of a measure with a smooth mollifier, i.e $\eta_\varepsilon \in C^\infty_c (X)$ such that $$ \int_{\mathbb{R}^d} \eta_\varepsilon = 1$$ then considering $$ \mu * \eta_\varepsilon $$ we obtain an absolutely continuous (with respect to the d dimensional lebesgue measure) smoothing of $\mu$ . However, I am somewhat struggling to understand how this is the case. For example, if I consider the dirac measure $\delta_0$ at 0 on $\mathbb{R}$ , then take $\eta_\varepsilon * \delta_0$ , I should have $$ \eta_\varepsilon * \delta_0 (\{0\}) = \int_{\{0\}} 1 d\eta_\varepsilon * \delta_0 = \int_{\{0\}} 1 * \eta_\varepsilon d(\delta_0) = \int_{\{0\}} \left( \int_\mathbb{R} 1 \cdot \eta_\varepsilon(z) dz \right) d(\delta_0) = \int_{\{0\}} 1 d(\delta_0) = 1$$ which would seem to imply that $\delta_0 * \eta_\varepsilon$ gives mass to a set of lebesgue measure zero, which obviously means it cannot be absolutely continuous. What am I missing here?","I'm reading Optimal Transport for Applied Mathematicians by Fillipo Santambrogio. At one point he says that taking the convolution of a measure with a smooth mollifier, i.e such that then considering we obtain an absolutely continuous (with respect to the d dimensional lebesgue measure) smoothing of . However, I am somewhat struggling to understand how this is the case. For example, if I consider the dirac measure at 0 on , then take , I should have which would seem to imply that gives mass to a set of lebesgue measure zero, which obviously means it cannot be absolutely continuous. What am I missing here?",\eta_\varepsilon \in C^\infty_c (X)  \int_{\mathbb{R}^d} \eta_\varepsilon = 1  \mu * \eta_\varepsilon  \mu \delta_0 \mathbb{R} \eta_\varepsilon * \delta_0  \eta_\varepsilon * \delta_0 (\{0\}) = \int_{\{0\}} 1 d\eta_\varepsilon * \delta_0 = \int_{\{0\}} 1 * \eta_\varepsilon d(\delta_0) = \int_{\{0\}} \left( \int_\mathbb{R} 1 \cdot \eta_\varepsilon(z) dz \right) d(\delta_0) = \int_{\{0\}} 1 d(\delta_0) = 1 \delta_0 * \eta_\varepsilon,"['measure-theory', 'convolution', 'optimal-transport']"
94,Are integrals in Riemann-Lebesgue theorem Riemann or Lebesgue,Are integrals in Riemann-Lebesgue theorem Riemann or Lebesgue,,"Riemann-Lebesgue theorem says that if $f$ is Lebesgue-integrable on $\mathbb R$ that \begin{equation} \lim_{n\to+\infty}\int_{-\infty}^{+\infty}f(x)\cos(nx)\,dx=0. \end{equation} Are integrals $\int_{-\infty}^{+\infty}f(x)\cos(nx)\,dx$ Riemann improper integrals or Lebesgue integrals? If they are Riemann, why do they exist?","Riemann-Lebesgue theorem says that if is Lebesgue-integrable on that Are integrals Riemann improper integrals or Lebesgue integrals? If they are Riemann, why do they exist?","f \mathbb R \begin{equation}
\lim_{n\to+\infty}\int_{-\infty}^{+\infty}f(x)\cos(nx)\,dx=0.
\end{equation} \int_{-\infty}^{+\infty}f(x)\cos(nx)\,dx","['measure-theory', 'lebesgue-integral', 'riemann-integration']"
95,"Is $C^1[0,1]$ a measurable subset of $C[0,1]$?",Is  a measurable subset of ?,"C^1[0,1] C[0,1]","I am wondering whether $C^1([0,1],\mathbb{R})$ , the set of continuously differentiable functions, is an element of the Borel $\sigma$ -algebra of $(C[0,1],\|\cdot \|_\infty)$ . As far as I know, it is neither open nor closed, but I feel like it would be natural for this to be true. If this is not the case, what about the set of (not necessarily continuously) differentiable functions?","I am wondering whether , the set of continuously differentiable functions, is an element of the Borel -algebra of . As far as I know, it is neither open nor closed, but I feel like it would be natural for this to be true. If this is not the case, what about the set of (not necessarily continuously) differentiable functions?","C^1([0,1],\mathbb{R}) \sigma (C[0,1],\|\cdot \|_\infty)","['measure-theory', 'derivatives', 'continuity', 'borel-sets']"
96,Measure on the power set of the natural number,Measure on the power set of the natural number,,"The problem is the following. Let $X = \mathbb{N}$ , and $A = P(X)$ (A is the power set of the natural number). Fix some sequence $(a_n)_{n=1}^{\infty} \subset [0, \infty)$ such that $\sum^\infty_{n=1} a_n < \infty$ . Define $$\mu(A) = \sum_{n \in A} a_n$$ Show that $\mu$ is a measure. The condition I am having trouble with is the countable additivity. So I would have to show that for disjoint collection $(A_n)_{n = 1}^\infty \subset P(X)$ , we have $$\mu(\cup A_n) = \sum_{n \in \cup A_n} a_n = \sum_{i = 1}^\infty \mu(A_i) = \sum_{i = 1}^\infty  \sum_{n \in A_i} a_n$$ Intuitively, this seems obvious as $A_i$ forms a partition, so summing over the partition and then adding them again should yield the same result. But I don't know how to write this intuition out mathematically, and I also know that intuition can be wrong with things like infinite sums. So anyone could help me on writing the proof out, I would be really grateful. Thank you!","The problem is the following. Let , and (A is the power set of the natural number). Fix some sequence such that . Define Show that is a measure. The condition I am having trouble with is the countable additivity. So I would have to show that for disjoint collection , we have Intuitively, this seems obvious as forms a partition, so summing over the partition and then adding them again should yield the same result. But I don't know how to write this intuition out mathematically, and I also know that intuition can be wrong with things like infinite sums. So anyone could help me on writing the proof out, I would be really grateful. Thank you!","X = \mathbb{N} A = P(X) (a_n)_{n=1}^{\infty} \subset [0, \infty) \sum^\infty_{n=1} a_n < \infty \mu(A) = \sum_{n \in A} a_n \mu (A_n)_{n = 1}^\infty \subset P(X) \mu(\cup A_n) = \sum_{n \in \cup A_n} a_n = \sum_{i = 1}^\infty \mu(A_i) = \sum_{i = 1}^\infty  \sum_{n \in A_i} a_n A_i",['measure-theory']
97,If $\int_0^1 f(x)g(x)dx <C \|g\|_1$ then there exists $M>0$ s.t. $f(x)<M$ a.e.,If  then there exists  s.t.  a.e.,\int_0^1 f(x)g(x)dx <C \|g\|_1 M>0 f(x)<M,"Let $f$ be a function on the interval $[0,1]$ . If $\int_0^1 f(x)g(x)\,dx <C \|g\|_1$ for all nonnegative function $g\in L^1[0,1]$ then show that there is a constant $M>0$ such that $f(x)<M$ almost everywhere in $[0,1]$ . Attempt. Suppose not. Then there is a subset $A\subseteq [0,1]$ with $m(A)>0$ such that $f(x)=\infty$ for all $x\in A$ . So, $\int_0^1f(x)g(x)dx\geq\int_Af(x)g(x)\,dx=m(A)\cdot\infty=\infty$ , contradiction. I would be glad if someone could check my attempt or give a hint. Thanks!","Let be a function on the interval . If for all nonnegative function then show that there is a constant such that almost everywhere in . Attempt. Suppose not. Then there is a subset with such that for all . So, , contradiction. I would be glad if someone could check my attempt or give a hint. Thanks!","f [0,1] \int_0^1 f(x)g(x)\,dx <C \|g\|_1 g\in L^1[0,1] M>0 f(x)<M [0,1] A\subseteq [0,1] m(A)>0 f(x)=\infty x\in A \int_0^1f(x)g(x)dx\geq\int_Af(x)g(x)\,dx=m(A)\cdot\infty=\infty","['real-analysis', 'measure-theory']"
98,Is there a lower bound to density at boundary points of a convex set?,Is there a lower bound to density at boundary points of a convex set?,,"Let $X \subset \mathbb R^d$ be convex and compact. For each $x \in X$ define $$D(x) = \lim_{r \to 0^+}\frac{\mu(X \cap B(x,r))}{\mu(B(x,r))}$$ where $B(r,d)$ is the ball with centre $x$ and radius $r$ and $\mu$ is the Lebesgue measure. The density measures what proportion of the ball is contained in $X$ as $r$ becomes very small. For example if $X$ is a polygon then $D(x) = 1$ at interior points; and $D(x) = 1/2$ at every point on an edge but not a vertex; while for $x$ a vertex the density $D(x)$ is the angle at that vertex. Thus for polytopes at least $$\min\{D(x): x \in X\} = \min\{D(v): v \in X  \text{ is a vertex}\}>0.$$ For smooth bodies I would imagine $D(x) = 1/2$ at every boundary point, since the boundary is locally approximated by a hyperplane. Hence we have $\min\{D(x): x \in X\}  =1/2$ For more general maybe-not-smooth bodies, is is known that $\min\{D(x): x \in X\}  >0$ ?","Let be convex and compact. For each define where is the ball with centre and radius and is the Lebesgue measure. The density measures what proportion of the ball is contained in as becomes very small. For example if is a polygon then at interior points; and at every point on an edge but not a vertex; while for a vertex the density is the angle at that vertex. Thus for polytopes at least For smooth bodies I would imagine at every boundary point, since the boundary is locally approximated by a hyperplane. Hence we have For more general maybe-not-smooth bodies, is is known that ?","X \subset \mathbb R^d x \in X D(x) = \lim_{r \to 0^+}\frac{\mu(X \cap B(x,r))}{\mu(B(x,r))} B(r,d) x r \mu X r X D(x) = 1 D(x) = 1/2 x D(x) \min\{D(x): x \in X\} = \min\{D(v): v \in X  \text{ is a vertex}\}>0. D(x) = 1/2 \min\{D(x): x \in X\}  =1/2 \min\{D(x): x \in X\}  >0","['measure-theory', 'reference-request', 'convex-analysis', 'convex-geometry', 'geometric-measure-theory']"
99,Finding a dominating function for a uniformly $L^p$-bounded family of functions,Finding a dominating function for a uniformly -bounded family of functions,L^p,"Suppose I have a collection of real-valued functions $\{f_n\}_{n\in\mathbb N}$ on a $\sigma$ -finite (which we can strengthen to finite if necessary) measure space $(X,\mathcal A,\mu)$ satisfying $f_n\overset{\textrm{a. s.}}{\to}f$ for some $f$ , and a real number $\varepsilon>0$ satisfying, for some $1\leq p<\infty$ and all $n\in\mathbb N$ , $\lVert f_n\rVert_p\leq\varepsilon$ . So the result I want is $\lVert f_n\rVert_p\to\lVert f\rVert_p$ as $n\to\infty$ . I'm pretty sure this is immediate from the continuity of $p$ -norms for $1\leq p<\infty$ , but I thought I'd try to run through the argument by definition and apply the dominated convergence theorem, $$\lim_{n\to\infty}\lVert f_n\rVert_p=\lim_{n\to\infty}\left(\int|f_n|^p\,\mathrm d\mu\right)^{1/p}\overset{(\ast)}{=}\left(\int|f|\,\mathrm d\mu\right)^{1/p}=\lVert f\rVert_p,$$ where $(\ast)$ is the application. I first need to find a good function to dominate the integrand uniformly across $n$ . The best I could come up with is $$g(x):=\sum_{k=1}^\infty k\mathbf1_{\left\{k-1<\sup_{n\geq1}|f_n(x)|^p\leq k\right\}}(x),$$ which seems to satisfy $f(x)\leq|g(x)|$ relatively tightly, but then checking for $L^p$ integrability I still can't get better than the form $$\lVert g\rVert_p^p=\int g^p\,\mathrm d\mu=\sum_{k=1}^\infty k^p\mu\left\{k-1<\sup_{n\geq1}|f_n(x)|^p\leq k\right\}.$$ Am I missing some obvious, better dominating function? Is my constructed $g$ a good dominator, i.e. is it $L^p$ ?","Suppose I have a collection of real-valued functions on a -finite (which we can strengthen to finite if necessary) measure space satisfying for some , and a real number satisfying, for some and all , . So the result I want is as . I'm pretty sure this is immediate from the continuity of -norms for , but I thought I'd try to run through the argument by definition and apply the dominated convergence theorem, where is the application. I first need to find a good function to dominate the integrand uniformly across . The best I could come up with is which seems to satisfy relatively tightly, but then checking for integrability I still can't get better than the form Am I missing some obvious, better dominating function? Is my constructed a good dominator, i.e. is it ?","\{f_n\}_{n\in\mathbb N} \sigma (X,\mathcal A,\mu) f_n\overset{\textrm{a. s.}}{\to}f f \varepsilon>0 1\leq p<\infty n\in\mathbb N \lVert f_n\rVert_p\leq\varepsilon \lVert f_n\rVert_p\to\lVert f\rVert_p n\to\infty p 1\leq p<\infty \lim_{n\to\infty}\lVert f_n\rVert_p=\lim_{n\to\infty}\left(\int|f_n|^p\,\mathrm d\mu\right)^{1/p}\overset{(\ast)}{=}\left(\int|f|\,\mathrm d\mu\right)^{1/p}=\lVert f\rVert_p, (\ast) n g(x):=\sum_{k=1}^\infty k\mathbf1_{\left\{k-1<\sup_{n\geq1}|f_n(x)|^p\leq k\right\}}(x), f(x)\leq|g(x)| L^p \lVert g\rVert_p^p=\int g^p\,\mathrm d\mu=\sum_{k=1}^\infty k^p\mu\left\{k-1<\sup_{n\geq1}|f_n(x)|^p\leq k\right\}. g L^p","['real-analysis', 'measure-theory']"
