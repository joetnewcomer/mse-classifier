,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability to find connected pixels,Probability to find connected pixels,,"Say I have an image, with pixels that can be either $0$ or $1$. For simplicity, assume it's a $2D$ image (though I'd be interested in a $3D$ solution as well). A pixel has $8$ neighbors (if that's too complicated, we can drop to $4$-connectedness). Two neighboring pixels with value $1$ are considered to be connected. If I know the probability $p$ that an individual pixel is $1$, and if I can assume that all pixels are independent, how many groups of at least $k$ connected pixels should I expect to find in an image of size $n\times n$? What I really need is a good way of calculating the probability of $k$ pixels being connected given the individual pixel probabilities. I have started to write down a tree to cover all the possibilities up to $k=3$, but even then, it becomes really ugly really fast. Is there a more clever way to go about this?","Say I have an image, with pixels that can be either $0$ or $1$. For simplicity, assume it's a $2D$ image (though I'd be interested in a $3D$ solution as well). A pixel has $8$ neighbors (if that's too complicated, we can drop to $4$-connectedness). Two neighboring pixels with value $1$ are considered to be connected. If I know the probability $p$ that an individual pixel is $1$, and if I can assume that all pixels are independent, how many groups of at least $k$ connected pixels should I expect to find in an image of size $n\times n$? What I really need is a good way of calculating the probability of $k$ pixels being connected given the individual pixel probabilities. I have started to write down a tree to cover all the possibilities up to $k=3$, but even then, it becomes really ugly really fast. Is there a more clever way to go about this?",,"['probability', 'graph-theory']"
1,Probability of a random cyclic quadrilateral enclosing a fixed point in its circle,Probability of a random cyclic quadrilateral enclosing a fixed point in its circle,,"I finally found a single integral solving the natural generalisation of the problem discussed here : For $n\ge1$ pick $n+2$ points uniformly at random on the unit circle. What is the probability $P_n(x)$ of the convex hull of the points containing $X=(x,0)$ where $0\le x\le1$ ? If the convex hull does not contain $X$ exactly one of the following cases must hold: All $n+2$ points are on the same side of the $x$ -axis ( $OX$ ). This happens with probability $2^{-(n+1)}$ . There is a point $V$ with Weierstrass parameter $v>0$ and another point $T$ with parameter $t<k/v$ where $k=\frac{x-1}{x+1}$ , and none of the remaining points' parameters are between $t$ and $v$ . All points thus lie ""left"" of the segment $TV$ which lies ""left"" of $X$ . The probability of a point falling in the arc $TV$ is $\frac{\arctan v-\arctan t}\pi$ , while $t,v$ are Cauchy-distributed and can be selected from the pool of points in $(n+2)(n+1)$ ways. This case's contribution to the overall probability is thus $$\frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\int_{-\infty}^{k/v}\frac1{1+v^2}\frac1{1+t^2}\left(1-\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv$$ There is a point $V$ with Weierstrass parameter $v>0$ and another point $T$ with parameter $k/v<t<0$ and all of the remaining points' parameters are between $t$ and $v$ , i.e. they are ""right"" of $TV$ which in turn is ""right"" of $X$ . By similar reasoning to the previous case the present case's contribution is $$\frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\int_{k/v}^0\frac1{1+v^2}\frac1{1+t^2}\left(\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv$$ Putting everything together we have $$P_n(x)=1-2^{-(n+1)}-\frac{(n+2)(n+1)}{\pi^2}\left(\int_0^\infty\int_{-\infty}^{k/v}\frac1{1+v^2}\frac1{1+t^2}\left(1-\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv + \int_0^\infty\int_{k/v}^0\frac1{1+v^2}\frac1{1+t^2}\left(\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv\right)$$ This can be turned into a single integral by expanding and solving the $t$ integral. Define the polynomial $$Q(V,K)=\sum_{i=0}^n\sum_{j=0}^i\binom ni\binom ij\frac{(-V)^{i-j}}{\pi^i}\frac{K^{j+1}-(-\pi/2)^{j+1}}{j+1}+\sum_{i=0}^n\binom ni\frac{V^{n-i}}{\pi^n}\frac{(-K)^{i+1}}{i+1}$$ Then $$P_n(x)=1-2^{-(n+1)}-\frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\frac{Q(\arctan v,\arctan k/v)}{1+v^2}\,dv$$ I already worked out that $$P_1(x)=\frac14-\frac3{2\pi^2}\operatorname{Li}_2(x^2)$$ The new surprising thing, though, is that numerical calculations strongly suggest $$\boxed{P_2(x)=2P_1(x)}$$ i.e. it is exactly twice as likely that four random points on the unit circle will enclose $X$ than will three random points, no matter where $X$ is. This relation does not extend to $P_3(x)$ and beyond. How can the boxed relation be proved?","I finally found a single integral solving the natural generalisation of the problem discussed here : For pick points uniformly at random on the unit circle. What is the probability of the convex hull of the points containing where ? If the convex hull does not contain exactly one of the following cases must hold: All points are on the same side of the -axis ( ). This happens with probability . There is a point with Weierstrass parameter and another point with parameter where , and none of the remaining points' parameters are between and . All points thus lie ""left"" of the segment which lies ""left"" of . The probability of a point falling in the arc is , while are Cauchy-distributed and can be selected from the pool of points in ways. This case's contribution to the overall probability is thus There is a point with Weierstrass parameter and another point with parameter and all of the remaining points' parameters are between and , i.e. they are ""right"" of which in turn is ""right"" of . By similar reasoning to the previous case the present case's contribution is Putting everything together we have This can be turned into a single integral by expanding and solving the integral. Define the polynomial Then I already worked out that The new surprising thing, though, is that numerical calculations strongly suggest i.e. it is exactly twice as likely that four random points on the unit circle will enclose than will three random points, no matter where is. This relation does not extend to and beyond. How can the boxed relation be proved?","n\ge1 n+2 P_n(x) X=(x,0) 0\le x\le1 X n+2 x OX 2^{-(n+1)} V v>0 T t<k/v k=\frac{x-1}{x+1} t v TV X TV \frac{\arctan v-\arctan t}\pi t,v (n+2)(n+1) \frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\int_{-\infty}^{k/v}\frac1{1+v^2}\frac1{1+t^2}\left(1-\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv V v>0 T k/v<t<0 t v TV X \frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\int_{k/v}^0\frac1{1+v^2}\frac1{1+t^2}\left(\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv P_n(x)=1-2^{-(n+1)}-\frac{(n+2)(n+1)}{\pi^2}\left(\int_0^\infty\int_{-\infty}^{k/v}\frac1{1+v^2}\frac1{1+t^2}\left(1-\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv + \int_0^\infty\int_{k/v}^0\frac1{1+v^2}\frac1{1+t^2}\left(\frac{\arctan v-\arctan t}\pi\right)^n\,dt\,dv\right) t Q(V,K)=\sum_{i=0}^n\sum_{j=0}^i\binom ni\binom ij\frac{(-V)^{i-j}}{\pi^i}\frac{K^{j+1}-(-\pi/2)^{j+1}}{j+1}+\sum_{i=0}^n\binom ni\frac{V^{n-i}}{\pi^n}\frac{(-K)^{i+1}}{i+1} P_n(x)=1-2^{-(n+1)}-\frac{(n+2)(n+1)}{\pi^2}\int_0^\infty\frac{Q(\arctan v,\arctan k/v)}{1+v^2}\,dv P_1(x)=\frac14-\frac3{2\pi^2}\operatorname{Li}_2(x^2) \boxed{P_2(x)=2P_1(x)} X X P_3(x)","['probability', 'integration', 'definite-integrals', 'geometric-probability']"
2,Probability of rolling a full house with 5 dice,Probability of rolling a full house with 5 dice,,"I am trying to understand the probability of rolling a full house with 5 dice. I can think of two methods. However, they disagree and I would like to understand why. (1) For method 1, we compute the number of ways to roll a full house (with order mattering), and divide by the number of ordered rolls of 5 dice. This gives $$P =  \frac{6\binom{5}3 5\binom{2}2}{6^5} \approx 0.0386. $$ This is also the accepted answer across multiple sources online. (2) For method 2, we compute the number of possible full house rolls (with order NOT mattering), and divide by the number of rolls of 5 dice, again with order NOT mattering. The former is given by $2\binom{6}2$ . The latter is a case of unordered sampling with replacement. The number of ways to obtain $k$ objects from $n$ in this case is $$ \binom{n + k - 1}{k}. $$ Therefore, overall I would expect the probability of rolling a full house to be $$ P = \frac{2\binom{6}2}{\binom{6 + 5 - 1}5} = 0.119. $$ Why does this disagree with method 1?","I am trying to understand the probability of rolling a full house with 5 dice. I can think of two methods. However, they disagree and I would like to understand why. (1) For method 1, we compute the number of ways to roll a full house (with order mattering), and divide by the number of ordered rolls of 5 dice. This gives This is also the accepted answer across multiple sources online. (2) For method 2, we compute the number of possible full house rolls (with order NOT mattering), and divide by the number of rolls of 5 dice, again with order NOT mattering. The former is given by . The latter is a case of unordered sampling with replacement. The number of ways to obtain objects from in this case is Therefore, overall I would expect the probability of rolling a full house to be Why does this disagree with method 1?",P =  \frac{6\binom{5}3 5\binom{2}2}{6^5} \approx 0.0386.  2\binom{6}2 k n  \binom{n + k - 1}{k}.   P = \frac{2\binom{6}2}{\binom{6 + 5 - 1}5} = 0.119. ,"['probability', 'combinatorics', 'probability-distributions']"
3,What's the probability of stumbling onto a Hamiltonian path?,What's the probability of stumbling onto a Hamiltonian path?,,"Suppose we have a graph $G$ , which for sake of convenience we'll require to be vertex-transitive. Then there's a natural notion of a random path: start at any vertex $v_1$ (and this is where the vertex-transitivity is used), and from a vertex $v_i$ choose $v_{i+1}$ with equal probability from all the neighbors of $v_i$ that haven't been visited yet. If $v_i$ has no unchosen neighbors, the path terminates. If $G$ has any Hamiltonian paths, then clearly there is a non-zero probability that a path chosen this way will be Hamiltonian; the question is, what is the probability that it is? There are a couple of trivial cases: if we have a cycle graph $C_n$ or a complete graph $K_n$ then the probability is clearly $1$ . (For $C_n$ once we've made our first choice we have no other choices to make, and for $K_n$ as long as there are unused vertices there's a path from that vertex.) But already for a graph as simple as $D_{2n}$ (two copies of $C_n$ with edges between corresponding nodes) it's not clear to me what the probability is, or even what the asymptotics are. Has this probability been studied, either for specific graphs $G$ (the Petersen graph immediately springs to mind) or for families of graphs like $D_{2n}$ or $\mathbb{Z}_2^n$ ? Is there any known characterization of the graphs where a Hamiltonian path will always be found this way? Does anyone have references to similar problems? Many thanks in advance!","Suppose we have a graph , which for sake of convenience we'll require to be vertex-transitive. Then there's a natural notion of a random path: start at any vertex (and this is where the vertex-transitivity is used), and from a vertex choose with equal probability from all the neighbors of that haven't been visited yet. If has no unchosen neighbors, the path terminates. If has any Hamiltonian paths, then clearly there is a non-zero probability that a path chosen this way will be Hamiltonian; the question is, what is the probability that it is? There are a couple of trivial cases: if we have a cycle graph or a complete graph then the probability is clearly . (For once we've made our first choice we have no other choices to make, and for as long as there are unused vertices there's a path from that vertex.) But already for a graph as simple as (two copies of with edges between corresponding nodes) it's not clear to me what the probability is, or even what the asymptotics are. Has this probability been studied, either for specific graphs (the Petersen graph immediately springs to mind) or for families of graphs like or ? Is there any known characterization of the graphs where a Hamiltonian path will always be found this way? Does anyone have references to similar problems? Many thanks in advance!",G v_1 v_i v_{i+1} v_i v_i G C_n K_n 1 C_n K_n D_{2n} C_n G D_{2n} \mathbb{Z}_2^n,"['probability', 'combinatorics', 'graph-theory', 'hamiltonian-path']"
4,Identically distributed random variables and events of probability $0$,Identically distributed random variables and events of probability,0,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $X_1,\dots,X_{n+1}:\Omega\to \mathbb{R}$ be random variables. Suppose that the random variables are identically distributed, i.e. $$\mathbb{P}\circ X_1^{-1}(B) = \ldots = \mathbb{P}\circ X_{n+1}^{-1}(B), \ \ \forall B \in \mathcal{B}(\mathbb{R}).$$ Also suppose that there exist real-valued functions $f:\mathbb{R} \to \mathbb{R}$ and $h:\mathbb{R} \to \mathbb{R}$ such that, $$(\mathbb{P}\circ X_1^{-1})(\{x_1\in \mathbb{R}: f(x_1)\not = h(x_1) \}) \stackrel{\text{(1)}}{=} \mathbb{P}[\{\omega \in \Omega :f(X_1(\omega))\not = h(X_1(\omega))\}] = 0.$$ Now consider the remaining random variables as a random vector $X(\omega) = (X_2(\omega),\ldots , X_{n+1}(\omega)):\Omega \to \mathbb{R}^n$ . I want to prove that, $$(\mathbb{P}\circ X^{-1})(\{(x_2,\ldots , x_{n+1})\in \mathbb{R}^n: f(x_2)\not = h(x_2), \ldots, f(x_{n+1})\not = h(x_{n+1}) \}) \stackrel{\text{(2)}}{=} \mathbb{P}[\{\omega \in \Omega :f(X_2(\omega))\not = h(X_2(\omega)),\dots , f(X_{n+1}(\omega))\not = h(X_{n+1}(\omega))\}] = 0.$$ I don't know whether $(1)$ and $(2)$ are true but anyway, here is my proof. My try: Note that $$\mathbb{P}[\{\omega \in \Omega :f(X_2(\omega))\not = h(X_2(\omega)),\ldots , f(X_{n+1}(\omega)) \not = h(X_{n+1}(\omega))\}] = \mathbb{P}[B_2 \cap \ldots \cap B_{n+1}],$$ where $B_j = \{\omega \in \Omega: f(X_j(\omega))\not = h(X_j(\omega))\}$ and $j=2,\ldots , n+1$ . We know $\mathbb{P}[B_j] = 0$ , since random variables are identically distributed, and that the events of probability $0$ are independent of all other events. So this implies that, $$\mathbb{P}[B_2 \cap \dots \cap B_{n+1}] = \mathbb{P}[B_2]\ldots \mathbb{P}[B_{n+1}] = 0.$$ Is this reasoning correct? Is it possible to use this line of reasoning with push-forward measure $\mathbb{P}\circ X^{-1}?$ The push-forward measure assigns probability to a vector of real numbers, so I don't know how to describe the correct subset of $\mathbb{R}^n$ and apply the measure to it.","Let be a probability space and be random variables. Suppose that the random variables are identically distributed, i.e. Also suppose that there exist real-valued functions and such that, Now consider the remaining random variables as a random vector . I want to prove that, I don't know whether and are true but anyway, here is my proof. My try: Note that where and . We know , since random variables are identically distributed, and that the events of probability are independent of all other events. So this implies that, Is this reasoning correct? Is it possible to use this line of reasoning with push-forward measure The push-forward measure assigns probability to a vector of real numbers, so I don't know how to describe the correct subset of and apply the measure to it.","(\Omega,\mathcal{F},\mathbb{P}) X_1,\dots,X_{n+1}:\Omega\to \mathbb{R} \mathbb{P}\circ X_1^{-1}(B) = \ldots = \mathbb{P}\circ X_{n+1}^{-1}(B), \ \ \forall B \in \mathcal{B}(\mathbb{R}). f:\mathbb{R} \to \mathbb{R} h:\mathbb{R} \to \mathbb{R} (\mathbb{P}\circ X_1^{-1})(\{x_1\in \mathbb{R}: f(x_1)\not = h(x_1) \}) \stackrel{\text{(1)}}{=} \mathbb{P}[\{\omega \in \Omega :f(X_1(\omega))\not = h(X_1(\omega))\}] = 0. X(\omega) = (X_2(\omega),\ldots , X_{n+1}(\omega)):\Omega \to \mathbb{R}^n (\mathbb{P}\circ X^{-1})(\{(x_2,\ldots , x_{n+1})\in \mathbb{R}^n: f(x_2)\not = h(x_2), \ldots, f(x_{n+1})\not = h(x_{n+1}) \}) \stackrel{\text{(2)}}{=} \mathbb{P}[\{\omega \in \Omega :f(X_2(\omega))\not = h(X_2(\omega)),\dots , f(X_{n+1}(\omega))\not = h(X_{n+1}(\omega))\}] = 0. (1) (2) \mathbb{P}[\{\omega \in \Omega :f(X_2(\omega))\not = h(X_2(\omega)),\ldots , f(X_{n+1}(\omega)) \not = h(X_{n+1}(\omega))\}] = \mathbb{P}[B_2 \cap \ldots \cap B_{n+1}], B_j = \{\omega \in \Omega: f(X_j(\omega))\not = h(X_j(\omega))\} j=2,\ldots , n+1 \mathbb{P}[B_j] = 0 0 \mathbb{P}[B_2 \cap \dots \cap B_{n+1}] = \mathbb{P}[B_2]\ldots \mathbb{P}[B_{n+1}] = 0. \mathbb{P}\circ X^{-1}? \mathbb{R}^n","['probability', 'probability-theory', 'measure-theory', 'random-variables', 'measurable-functions']"
5,"Probability that among $n$ random people, at least two have coinciding or successive birthdays","Probability that among  random people, at least two have coinciding or successive birthdays",n,"I found the following riddle: What is the probability that among $n$ people chosen randomly, at least two of them have their birthdays with at most one day difference. Note: December 31 and January 1 are considered as having one day difference. For simplicity, we will consider that a year always contains 365 days. I've found that the probability is $$P\left( n\right) = 1-\prod\limits_{i=n+1}^{2n-1} \left( 1-\frac{i}{365}\right) $$ Numerically, it gives the following (for example): $P\left( 14\right) \approx 53.75$ , $P\left( 24\right) \approx 90.86$ , and $P\left( 33\right) \approx 99.07$ . I'm not sure about my reasoning, since it is not rigorous and the results are quite surprising. So I wonder if anyone can check if these results are true and give a simple and comprehensive solution. Thank you!","I found the following riddle: What is the probability that among people chosen randomly, at least two of them have their birthdays with at most one day difference. Note: December 31 and January 1 are considered as having one day difference. For simplicity, we will consider that a year always contains 365 days. I've found that the probability is Numerically, it gives the following (for example): , , and . I'm not sure about my reasoning, since it is not rigorous and the results are quite surprising. So I wonder if anyone can check if these results are true and give a simple and comprehensive solution. Thank you!","n P\left( n\right) =
1-\prod\limits_{i=n+1}^{2n-1}
\left( 1-\frac{i}{365}\right)  P\left( 14\right) \approx 53.75 P\left( 24\right) \approx 90.86 P\left( 33\right) \approx 99.07","['probability', 'puzzle', 'birthday']"
6,"Bacteria either die or double depending on whether it turns left or right. If we start with $n$ bacteria, what's the best long-term survival strategy?","Bacteria either die or double depending on whether it turns left or right. If we start with  bacteria, what's the best long-term survival strategy?",n,"Start with $n\geq 4$ bacteria. At each round i.e. turn , you get to choose how many bacteria go left; the remaining bacteria must go right. Each bacteria either dies, or, survives and reproduces creating another healthy bacteria, depending on whether it goes left or right (assume bacteria do not overlap or any other shenanigans). In other words, either left is certain death (for all the bacteria who go left) and right is certain reproduction (for all the bacteria who go right), or right is certain death (for all the bacteria who go right) and left is certain reproduction (for all the bacteria who go left). Each scenario has a $50$ % chance of happening each round/turn, independently of all other rounds/turns. What is the best or approximately the best strategy to maximise the likelihood that there are $k>n$ bacteria at the end of $t$ rounds/turns? [The ""left or right"" is arbitrary. I could also say ""Either goes through door $1$ or door $2$ "", or any other binary decision.] For example, Start with $n=1000$ bacteria, and let $A_j$ be the number of bacteria at the $j$ -th turn. We want to maximise the chance that there are at least $k=10,000$ bacteria by the $50$ th round/turn, i.e. maximise the chance that $A_{50}\geq 10,000.$ A strategy that is guaranteed to fail is to make $500$ go left and $500$ go right for every round/turn, for then the population will always be $0 + 500\times 2 = 1000,$ contrary to our aim of reaching a population of $10,000.$ We are better off taking some risk in the first round/turn, for example make $550$ go left and $450$ go right. Then there is a $50$ % chance we increase the population up to $0 + 550\times 2 = 1100,$ and we are closer to our goal of $10,000.$ On the other hand, there is a $50$ % chance we decrease the population to $450\times 2 + 0 = 900,$ taking us further away from our goal. Obviously in order to risk increasing the bacteria population, you must risk reducing the number of bacteria by the same amount (I guess it's a zero sum game), and since we only care about reaching $10,000$ bacteria in total, all possible strategies have a high probability of failure. My suspicion is that either all strategies that try to be successful have the same likelihood of working, or, the best strategy is something like: Send $0.45A_t$ bacteria left and the remaining $0.55A_t$ right at every round/turn. But maybe sending all bacteria left for three rounds/turns until there are $8,000,$ (with $12.5$ % probability) and then doing something like in the second half of the previous sentence for up to $10,000?$ Edit: maybe we require Markov chains to help, although I have not studied the topic of Markov chains before.","Start with bacteria. At each round i.e. turn , you get to choose how many bacteria go left; the remaining bacteria must go right. Each bacteria either dies, or, survives and reproduces creating another healthy bacteria, depending on whether it goes left or right (assume bacteria do not overlap or any other shenanigans). In other words, either left is certain death (for all the bacteria who go left) and right is certain reproduction (for all the bacteria who go right), or right is certain death (for all the bacteria who go right) and left is certain reproduction (for all the bacteria who go left). Each scenario has a % chance of happening each round/turn, independently of all other rounds/turns. What is the best or approximately the best strategy to maximise the likelihood that there are bacteria at the end of rounds/turns? [The ""left or right"" is arbitrary. I could also say ""Either goes through door or door "", or any other binary decision.] For example, Start with bacteria, and let be the number of bacteria at the -th turn. We want to maximise the chance that there are at least bacteria by the th round/turn, i.e. maximise the chance that A strategy that is guaranteed to fail is to make go left and go right for every round/turn, for then the population will always be contrary to our aim of reaching a population of We are better off taking some risk in the first round/turn, for example make go left and go right. Then there is a % chance we increase the population up to and we are closer to our goal of On the other hand, there is a % chance we decrease the population to taking us further away from our goal. Obviously in order to risk increasing the bacteria population, you must risk reducing the number of bacteria by the same amount (I guess it's a zero sum game), and since we only care about reaching bacteria in total, all possible strategies have a high probability of failure. My suspicion is that either all strategies that try to be successful have the same likelihood of working, or, the best strategy is something like: Send bacteria left and the remaining right at every round/turn. But maybe sending all bacteria left for three rounds/turns until there are (with % probability) and then doing something like in the second half of the previous sentence for up to Edit: maybe we require Markov chains to help, although I have not studied the topic of Markov chains before.","n\geq 4 50 k>n t 1 2 n=1000 A_j j k=10,000 50 A_{50}\geq 10,000. 500 500 0 + 500\times 2 = 1000, 10,000. 550 450 50 0 + 550\times 2 = 1100, 10,000. 50 450\times 2 + 0 = 900, 10,000 0.45A_t 0.55A_t 8,000, 12.5 10,000?","['probability', 'statistics', 'normal-distribution', 'markov-chains', 'game-theory']"
7,Sum of conditional expectations of a bounded stochastic process,Sum of conditional expectations of a bounded stochastic process,,"Is there a proof for the following statement or is there a counter-example? Let $\{X_t\}$ be a stochastic process adapted to the filtration $\{\mathcal{F}_t\}$ . Assuming $0 \leq X_t \leq 1$ , and $\sum_{t=1}^{T} X_t \leq c$ almost surely for some fixed $c \in \mathbb{R}$ . then it holds that: \begin{align}     \sum_{t=1}^{T} \mathbb{E}[X_t | \mathcal{F}_{t-1}] \leq c. \end{align}","Is there a proof for the following statement or is there a counter-example? Let be a stochastic process adapted to the filtration . Assuming , and almost surely for some fixed . then it holds that:","\{X_t\} \{\mathcal{F}_t\} 0 \leq X_t \leq 1 \sum_{t=1}^{T} X_t \leq c c \in \mathbb{R} \begin{align}
    \sum_{t=1}^{T} \mathbb{E}[X_t | \mathcal{F}_{t-1}] \leq c.
\end{align}","['probability', 'probability-theory', 'stochastic-processes', 'conditional-expectation', 'markov-process']"
8,Show that $L^p$ convergence is unique almost surely,Show that  convergence is unique almost surely,L^p,"It'd be of great help if someone could double-check if my proof is correct/rigorous. Problem: For any $p>0$ , if $X_n\to X$ and $X_n\to Y$ in $L^p$ , then $X=Y$ almost surely My proof: We start with the case of $p\geq 1$ . We have that $\lVert X_n -X \rVert_p\to 0$ , therefore by Markov's inequality: $$\mathbb{P}(\lvert X_n -X\rvert>\epsilon)\leq \frac{\mathbb{E}\lvert X_n-X\rvert}{\epsilon}\to 0$$ as $n$ goes to $\infty$ . Same thing with $Y$ . So then we have $$\mathbb{P}(\lvert X-Y\rvert >\epsilon)\leq \frac{\mathbb{E}(\lvert X-Y\rvert)}{\epsilon}= \frac{\mathbb{E}(\lvert X-X_n + X_n -Y\rvert)}{\epsilon}\leq \frac{\mathbb{E}(\lvert X-X_n\rvert + \lvert X_n -Y\rvert)}{\epsilon}=\frac{\mathbb{E}(\lvert X-X_n\rvert) + \mathbb{E}(\lvert X_n -Y\rvert)}{\epsilon}$$ which converges to $0$ as $n$ goes to infinity. Therefore, we have that $\mathbb{P}(X\neq Y)=0$ and we are done. As for $0<p<1$ , a similar (or rather generalized) argument can be made through showing that $L_p$ convergence yields convergence in probability.","It'd be of great help if someone could double-check if my proof is correct/rigorous. Problem: For any , if and in , then almost surely My proof: We start with the case of . We have that , therefore by Markov's inequality: as goes to . Same thing with . So then we have which converges to as goes to infinity. Therefore, we have that and we are done. As for , a similar (or rather generalized) argument can be made through showing that convergence yields convergence in probability.",p>0 X_n\to X X_n\to Y L^p X=Y p\geq 1 \lVert X_n -X \rVert_p\to 0 \mathbb{P}(\lvert X_n -X\rvert>\epsilon)\leq \frac{\mathbb{E}\lvert X_n-X\rvert}{\epsilon}\to 0 n \infty Y \mathbb{P}(\lvert X-Y\rvert >\epsilon)\leq \frac{\mathbb{E}(\lvert X-Y\rvert)}{\epsilon}= \frac{\mathbb{E}(\lvert X-X_n + X_n -Y\rvert)}{\epsilon}\leq \frac{\mathbb{E}(\lvert X-X_n\rvert + \lvert X_n -Y\rvert)}{\epsilon}=\frac{\mathbb{E}(\lvert X-X_n\rvert) + \mathbb{E}(\lvert X_n -Y\rvert)}{\epsilon} 0 n \mathbb{P}(X\neq Y)=0 0<p<1 L_p,"['probability', 'probability-theory', 'measure-theory', 'convergence-divergence', 'expected-value']"
9,Maximal Inequality for Expectation of Random Variables,Maximal Inequality for Expectation of Random Variables,,"Let $Z_1, Z_2, ..., Z_n$ be non-negative random variables, not necessarily independent. Then, show the expectation of the product of the random variables is less than or equal to the integral of the product of the quantile functions. In other words, show that $$\mathbb{E}(Z_1Z_2...Z_n) \leq \int_{0}^{1} Q_{Z_1}(u)Q_{Z_2}(u)...Q_{Z_n}(u)~du,$$ where $Q_{Z_{i}}$ is the quantile function of $Z_i$ . The only way I currently see to establish the inequality for the expectation is by using Holding's inequality. But I'm not sure how to proceed with using the quantile functions. I'm guessing I need to use Fubini-Tonelli at some point.","Let be non-negative random variables, not necessarily independent. Then, show the expectation of the product of the random variables is less than or equal to the integral of the product of the quantile functions. In other words, show that where is the quantile function of . The only way I currently see to establish the inequality for the expectation is by using Holding's inequality. But I'm not sure how to proceed with using the quantile functions. I'm guessing I need to use Fubini-Tonelli at some point.","Z_1, Z_2, ..., Z_n \mathbb{E}(Z_1Z_2...Z_n) \leq \int_{0}^{1} Q_{Z_1}(u)Q_{Z_2}(u)...Q_{Z_n}(u)~du, Q_{Z_{i}} Z_i","['probability', 'probability-theory', 'fubini-tonelli-theorems']"
10,"What's more likely to show up first when rolling a die, 556 or 234?","What's more likely to show up first when rolling a die, 556 or 234?",,"What's more likely to show up first when rolling a $6$ -sided die, $556$ or $234$ ? The expected number of rolls of getting $556$ is solving for $a$ in the following equations: $$a = {5\over6}(a + 1) + {1\over6}(b + 1)$$ $$b = {5\over6}(a + 1) + {1\over6}(c + 1)$$ $$c = {2\over3}(a + 1) + {1\over6}(c + 1) + {1\over6}$$ Solving, we get $a = 216$ , $b = 210$ , $c = 174$ , so the expected number of rolls it takes to get $556$ is $216$ . The expected number of rolls is getting $234$ is solving for $x$ in the following equations: $$x = {5\over6}(x + 1) + {1\over6}(y + 1)$$ $$y = {2\over3}(x + 1) + {1\over6}(y + 1) + {1\over6}(z + 1)$$ $$z = {2\over3}(x + 1) + {1\over6}(y + 1) + {1\over6}$$ Solving, we get $x = 216$ , $y = 210$ , $z = 180$ , so the expected number of rolls it takes to get $234$ is also $216$ . So I have two questions: Given that the expected number of rolls for getting $556$ and $234$ is $216$ for both, does it follow that they're equally likely to show up first when rolling a $6$ -sided die? If not, which one is more likely to show up first? And what's the calculation that would demonstrate this? Without writing out the Markov chain and calculating, on an intuitive level, how do we see which one is more likely to show up first (or that both of them are equally likely to show up first)?","What's more likely to show up first when rolling a -sided die, or ? The expected number of rolls of getting is solving for in the following equations: Solving, we get , , , so the expected number of rolls it takes to get is . The expected number of rolls is getting is solving for in the following equations: Solving, we get , , , so the expected number of rolls it takes to get is also . So I have two questions: Given that the expected number of rolls for getting and is for both, does it follow that they're equally likely to show up first when rolling a -sided die? If not, which one is more likely to show up first? And what's the calculation that would demonstrate this? Without writing out the Markov chain and calculating, on an intuitive level, how do we see which one is more likely to show up first (or that both of them are equally likely to show up first)?",6 556 234 556 a a = {5\over6}(a + 1) + {1\over6}(b + 1) b = {5\over6}(a + 1) + {1\over6}(c + 1) c = {2\over3}(a + 1) + {1\over6}(c + 1) + {1\over6} a = 216 b = 210 c = 174 556 216 234 x x = {5\over6}(x + 1) + {1\over6}(y + 1) y = {2\over3}(x + 1) + {1\over6}(y + 1) + {1\over6}(z + 1) z = {2\over3}(x + 1) + {1\over6}(y + 1) + {1\over6} x = 216 y = 210 z = 180 234 216 556 234 216 6,"['probability', 'combinatorics', 'expected-value', 'markov-chains', 'dice']"
11,Expectation of real zeroes of random algebraic polynomials.,Expectation of real zeroes of random algebraic polynomials.,,"I am currently working on calculating the expectation of real zeroes of random n-th degree algebraic polynomials with independently and identically distributed random variables as coefficients. That is, the expectation of real zeroes for: $$X_0 + X_1x+X_2x^2 +X_3x^3+...+X_{n-1}x^{n-1}$$ M. Kac had tackled this problem for $X_i \sim N(0,1)$ in his paper in 1943 . However, I am trying to extend his results to the random coefficients following a t-distribution or a Laplace distribution. In seeing the tedious calculations through for each case (both the Laplace and the t-distribution), it turns out that the expectation of real zeroes that I am getting is exactly the same as that of Kac - for both distributions. I was just wondering if this intuitively makes sense. Since all three distributions have a different probability density function, this seems rather counter-intuitive to me.","I am currently working on calculating the expectation of real zeroes of random n-th degree algebraic polynomials with independently and identically distributed random variables as coefficients. That is, the expectation of real zeroes for: M. Kac had tackled this problem for in his paper in 1943 . However, I am trying to extend his results to the random coefficients following a t-distribution or a Laplace distribution. In seeing the tedious calculations through for each case (both the Laplace and the t-distribution), it turns out that the expectation of real zeroes that I am getting is exactly the same as that of Kac - for both distributions. I was just wondering if this intuitively makes sense. Since all three distributions have a different probability density function, this seems rather counter-intuitive to me.","X_0 + X_1x+X_2x^2 +X_3x^3+...+X_{n-1}x^{n-1} X_i \sim N(0,1)","['real-analysis', 'probability', 'analysis', 'statistics', 'polynomials']"
12,"implement a fair 0-1 random variable using a biased coin with head p, while minimizing the expected number of coin tosses to $1/H(p)$","implement a fair 0-1 random variable using a biased coin with head p, while minimizing the expected number of coin tosses to",1/H(p),"I recently encountered an intriguing question during a mathematical interview: How can one construct a fair binary random variable that outputs either $0$ or $1$ using a biased coin with a head-up probability of $ p $ , while minimizing the expected number of coin tosses? I am aware of the conventional method for simulating a fair coin from a biased one. This method involves the following steps: Toss the biased coin twice. If the outcomes are both heads (HH) or both tails (TT), disregard the results and start anew. If the outcomes are heads-tails (HT), output $0$ . If the outcomes are tails-heads (TH), output $1$ . With this approach, the expected number of coin tosses $ n $ can be calculated as: \begin{align*}     n &= 2 + (p^2 + (1 - p)^2) n \\     &\Rightarrow n = \frac{2}{2p(1 - p)} \end{align*} However, the interviewer raised a more challenging aspect: devise and implement a strategy such that the expected number of coin tosses approximates the optimal $ \frac{1}{H(p)} $ , where $ H(p) = -p \log_2(p) - (1 - p) \log_2(1 - p) $ represents the entropy? I suspect that this is a systematically solvable problem. Are there any published works that delve into this issue?","I recently encountered an intriguing question during a mathematical interview: How can one construct a fair binary random variable that outputs either or using a biased coin with a head-up probability of , while minimizing the expected number of coin tosses? I am aware of the conventional method for simulating a fair coin from a biased one. This method involves the following steps: Toss the biased coin twice. If the outcomes are both heads (HH) or both tails (TT), disregard the results and start anew. If the outcomes are heads-tails (HT), output . If the outcomes are tails-heads (TH), output . With this approach, the expected number of coin tosses can be calculated as: However, the interviewer raised a more challenging aspect: devise and implement a strategy such that the expected number of coin tosses approximates the optimal , where represents the entropy? I suspect that this is a systematically solvable problem. Are there any published works that delve into this issue?","0 1  p  0 1  n  \begin{align*}
    n &= 2 + (p^2 + (1 - p)^2) n \\
    &\Rightarrow n = \frac{2}{2p(1 - p)}
\end{align*}  \frac{1}{H(p)}   H(p) = -p \log_2(p) - (1 - p) \log_2(1 - p) ","['probability', 'discrete-mathematics', 'optimization', 'stochastic-processes', 'information-theory']"
13,"Find the distribution of $Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\}$ and converges in distribution",Find the distribution of  and converges in distribution,"Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\}","Let $(U_n)_n$ be a sequence of i.i.d random variables such that $U_{n} \sim U[0,1] \forall n$ . Define $Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\}$ , prove that $Y_n$ converges in distribution to a variable $Y$ , whose law must identify. Hint: Investigate beta distribution. My attempt: My idea was to use the distribution of the maximum in this case, thus obtaining that, for $n\in \mathbb{N}$ : $$\mathbb{P}(Y_{n}\leq y)=\mathbb{P}\left(\bigcap_{i=1}^{n}\{\frac{U_{i}}{i}\leq y\}\right)=\prod_{i=1}^{n}\mathbb{P}\left(\frac{U_i}{i}\leq y\right)$$ It follows: $$\mathbb{P}(Y_{1}\leq y)=y1_{[0,1]}(y)+1_{(1,+\infty)}(y)$$ $$\mathbb{P}(Y_{2}\leq y)=2y^{2}1_{[0,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y)$$ $$\mathbb{P}(Y_{3}\leq y)=6y^{3}1_{[0,1/3]}(y)+2y^{2}1_{(1/3,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y)$$ $$\vdots$$ Assuming that this development is correct. What would be the expression for $\mathbb{P}(Y_{n}\leq y)$ ? Does $Y_n$ converge in distribution to a beta random variable? Actualization: I obtain $\forall n\geq 2$ : $$\mathbb{P}(Y_{n}\leq y)=n!y^{n}1_{[0,1/n]}(y)+\sum_{k=1}^{n-1}k!y^{k}1_{\left(\frac{1}{k+1},\frac{1}{k}\right]}(y) + 1_{(1,+\infty)}(y)$$ But I can't see to which distribution this expression should converge.","Let be a sequence of i.i.d random variables such that . Define , prove that converges in distribution to a variable , whose law must identify. Hint: Investigate beta distribution. My attempt: My idea was to use the distribution of the maximum in this case, thus obtaining that, for : It follows: Assuming that this development is correct. What would be the expression for ? Does converge in distribution to a beta random variable? Actualization: I obtain : But I can't see to which distribution this expression should converge.","(U_n)_n U_{n} \sim U[0,1] \forall n Y_{n}=\max\{U_{1}, \frac{U_{2}}{2}, \ldots, \frac{U_{n}}{n}\} Y_n Y n\in \mathbb{N} \mathbb{P}(Y_{n}\leq y)=\mathbb{P}\left(\bigcap_{i=1}^{n}\{\frac{U_{i}}{i}\leq y\}\right)=\prod_{i=1}^{n}\mathbb{P}\left(\frac{U_i}{i}\leq y\right) \mathbb{P}(Y_{1}\leq y)=y1_{[0,1]}(y)+1_{(1,+\infty)}(y) \mathbb{P}(Y_{2}\leq y)=2y^{2}1_{[0,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y) \mathbb{P}(Y_{3}\leq y)=6y^{3}1_{[0,1/3]}(y)+2y^{2}1_{(1/3,1/2]}(y)+y1_{(1/2,1]}(y)+1_{(1,+\infty)}(y) \vdots \mathbb{P}(Y_{n}\leq y) Y_n \forall n\geq 2 \mathbb{P}(Y_{n}\leq y)=n!y^{n}1_{[0,1/n]}(y)+\sum_{k=1}^{n-1}k!y^{k}1_{\left(\frac{1}{k+1},\frac{1}{k}\right]}(y) + 1_{(1,+\infty)}(y)","['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'uniform-distribution']"
14,Distribution of midpoints in a unit disk,Distribution of midpoints in a unit disk,,"I'm trying to find a probability distribution $m(r,\theta)$ defined over a unit disk which represents the probability of a point being the midpoint of two randomly chosen points in said disk. I think that I'm pretty close to the answer, but I'm off by a factor of 16 and I don't understand why. Given that the distribution of points is uniform, i.e. $f(r,\theta) = \frac{1}{\pi}$ , my reasoning is as follows: The first and second points chosen are $P_{1}$ and $P_{2}$ respectively. If we fix the first point chosen inside the disk, the set of points which are possible midpoints for $P_{1}P_{2}$ form a disk of radius $\frac{1}{2}$ . (Edit: see the figure below for an illustration) Since for each possible $P_{1}$ there is a unique circle of size $\frac{\pi}{4}$ generated representing all the possible midpoints where $P_{1}$ is one of the points, then $m(r,\theta)$ should be proportional to the total ""height"" of all the unique circles that overlap onto the point $(r,\theta)$ , if we imagine each of the radius- $\frac{1}{2}$ circles as having some infinitesimal ""height"". I found the ""height"" of the overlapping circles to be $2(\frac{\arccos{r}}{4}-\frac{r}{2}\sqrt{\frac{1}{4}-\frac{r^{2}}{4}}) = \frac{1}{2}(\arccos{r}-r\sqrt{1-r^{2}})$ . This is the area of overlap between two circles of size $\frac{\pi}{4}$ , reason being that since the center of the radius- $\frac{1}{2}$ disks we formed in step 2 will fall within a radius- $\frac{1}{2}$ disk that is concentric to the unit disk, then the set of radius- $\frac{1}{2}$ disks which do not overlap onto $(r,\theta)$ must be more than a distance of $\frac{1}{2}$ from this point. Hence, the set of radius- $\frac{1}{2}$ disks which do form the ""height"" at point $(r,\theta)$ will have centers within a distance of $\frac{1}{2}$ from the point, and this is the leaf-shaped area between two circles - essentially the expression above. I'm not sure whether this is the correct way to be thinking about the ""height"" at the point - or if ""height"" is even the right way to think about it - so I would appreciate if anyone can point out a more rigorous direction. Assuming step 3 is correct, then because $f(r,\theta) = \frac{1}{\pi}$ , then since we are choosing 2 points, we scale step 3 by $\frac{1}{\pi^{2}}$ . However, if we take this as $m(r,\theta)$ , then $\int_{0}^{1}\int_{0}^{2\pi}m(r,\theta)r d\theta dr = \frac{1}{16}$ . I'm not very well versed in geomtery and probability, so there is definitely something wrong with my logic. Can anyone point me to where the missing factor of 16 comes from, or whether my entire chain of logic is incorrect? Figure for step 1: We just need to show that the boundary of the set of possible midpoints forms a circle. Consider the diameter that goes through $P_{1}$ and the center of the circle. If $P_{2}$ is on either $D_{1}$ or $D_{2}$ , then the midpoint will be at $M_{1}$ or $M_{2}$ respectively. Consider if $P_{2}$ is anywhere else on the larger circle, let's say $A$ (any point on the circle will form the boundary case), then its midpoint we call $X$ . $M_{1}P_{1} = \frac{1}{2}D_{1}P_{1}, XP_{1} = \frac{1}{2}AP_{1}$ and $\angle{M_{1}P_{1}X} = \angle{D_{1}P_{1}A}$ , so $M_{1}P_{1}X$ and $D_{1}P_{1}A$ are similar triangles by a factor of $\frac{1}{2}$ . A similar argument can be applied for $D_{2}$ and $M_{2}$ . Hence we have that $D_{1}D_{2}A$ is similar to $M_{1}M_{2}X$ by a factor of $\frac{1}{2}$ . Since $D_{1}D_{2}A$ is a right triangle, so is $M_{1}M_{2}X$ , and as A varies, X will trace out a circle of radius $\frac{1}{2}$ . P.S. I am quite sure that other than the factor of 16, everything else should be correct, because this is part of a larger problem that I am solving, which I have shown to be correct assuming that the factor of 16 is there.","I'm trying to find a probability distribution defined over a unit disk which represents the probability of a point being the midpoint of two randomly chosen points in said disk. I think that I'm pretty close to the answer, but I'm off by a factor of 16 and I don't understand why. Given that the distribution of points is uniform, i.e. , my reasoning is as follows: The first and second points chosen are and respectively. If we fix the first point chosen inside the disk, the set of points which are possible midpoints for form a disk of radius . (Edit: see the figure below for an illustration) Since for each possible there is a unique circle of size generated representing all the possible midpoints where is one of the points, then should be proportional to the total ""height"" of all the unique circles that overlap onto the point , if we imagine each of the radius- circles as having some infinitesimal ""height"". I found the ""height"" of the overlapping circles to be . This is the area of overlap between two circles of size , reason being that since the center of the radius- disks we formed in step 2 will fall within a radius- disk that is concentric to the unit disk, then the set of radius- disks which do not overlap onto must be more than a distance of from this point. Hence, the set of radius- disks which do form the ""height"" at point will have centers within a distance of from the point, and this is the leaf-shaped area between two circles - essentially the expression above. I'm not sure whether this is the correct way to be thinking about the ""height"" at the point - or if ""height"" is even the right way to think about it - so I would appreciate if anyone can point out a more rigorous direction. Assuming step 3 is correct, then because , then since we are choosing 2 points, we scale step 3 by . However, if we take this as , then . I'm not very well versed in geomtery and probability, so there is definitely something wrong with my logic. Can anyone point me to where the missing factor of 16 comes from, or whether my entire chain of logic is incorrect? Figure for step 1: We just need to show that the boundary of the set of possible midpoints forms a circle. Consider the diameter that goes through and the center of the circle. If is on either or , then the midpoint will be at or respectively. Consider if is anywhere else on the larger circle, let's say (any point on the circle will form the boundary case), then its midpoint we call . and , so and are similar triangles by a factor of . A similar argument can be applied for and . Hence we have that is similar to by a factor of . Since is a right triangle, so is , and as A varies, X will trace out a circle of radius . P.S. I am quite sure that other than the factor of 16, everything else should be correct, because this is part of a larger problem that I am solving, which I have shown to be correct assuming that the factor of 16 is there.","m(r,\theta) f(r,\theta) = \frac{1}{\pi} P_{1} P_{2} P_{1}P_{2} \frac{1}{2} P_{1} \frac{\pi}{4} P_{1} m(r,\theta) (r,\theta) \frac{1}{2} 2(\frac{\arccos{r}}{4}-\frac{r}{2}\sqrt{\frac{1}{4}-\frac{r^{2}}{4}}) = \frac{1}{2}(\arccos{r}-r\sqrt{1-r^{2}}) \frac{\pi}{4} \frac{1}{2} \frac{1}{2} \frac{1}{2} (r,\theta) \frac{1}{2} \frac{1}{2} (r,\theta) \frac{1}{2} f(r,\theta) = \frac{1}{\pi} \frac{1}{\pi^{2}} m(r,\theta) \int_{0}^{1}\int_{0}^{2\pi}m(r,\theta)r d\theta dr = \frac{1}{16} P_{1} P_{2} D_{1} D_{2} M_{1} M_{2} P_{2} A X M_{1}P_{1} = \frac{1}{2}D_{1}P_{1}, XP_{1} = \frac{1}{2}AP_{1} \angle{M_{1}P_{1}X} = \angle{D_{1}P_{1}A} M_{1}P_{1}X D_{1}P_{1}A \frac{1}{2} D_{2} M_{2} D_{1}D_{2}A M_{1}M_{2}X \frac{1}{2} D_{1}D_{2}A M_{1}M_{2}X \frac{1}{2}","['probability', 'integration', 'geometry']"
15,Prove that $\limsup \ \frac{B\left(t\right)}{\sqrt{t\ }\log t}=0$,Prove that,\limsup \ \frac{B\left(t\right)}{\sqrt{t\ }\log t}=0,Let $B(t)$ be a Standard Brownian Motion. We need to prove that $\underset{t \to \infty}\limsup \dfrac{B\left(t\right)}{\sqrt{t}\cdot\ln(t)}=0$ I was thinking if we could use the Blumenthal's $0-1$ law along the lines of the proof for $\underset{t \rightarrow \infty}\limsup \dfrac{B(t)}{\sqrt{t}}=\infty$ . But I am not sure about how to argue in this case.,Let be a Standard Brownian Motion. We need to prove that I was thinking if we could use the Blumenthal's law along the lines of the proof for . But I am not sure about how to argue in this case.,B(t) \underset{t \to \infty}\limsup \dfrac{B\left(t\right)}{\sqrt{t}\cdot\ln(t)}=0 0-1 \underset{t \rightarrow \infty}\limsup \dfrac{B(t)}{\sqrt{t}}=\infty,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'brownian-motion']"
16,How to count - probability puzzle,How to count - probability puzzle,,"A $3 \times 3 \times 3$ big cube consists of $1 \times 1 \times 1$ smaller cubes. The big cube is painted black on the outside. Suppose we disassemble the cube and randomly put it back together. What is the probability of perfectly assembling the cube i.e. all faces are black again? Do you think my partial progress is correct? If not, could you provide a hint/clue (without giving away the entire solution)? Solution (My Attempt) . There are $8$ corner(vertex) cubes, having $3$ faces black - label them $V$ There are $12$ edge cubes, having $2$ faces black - label them $E$ There are $6$ center of face cubes, having $1$ face black - label it $C$ There is $1$ origin cube, that is not black - label it $O$ For the $1 \times 1 \times 1$ cube, there are $6$ choices for the top face, and for each such choice, $4$ choices for an adjacent face. This completely determines the orientation. So, there are $24$ distinguishable orientations of the unit cube. The probability that a $V$ cube is correctly oriented = $\frac{1}{24}$ . The probability that a $E$ cube is correctly oriented = $\frac{1}{24}$ . The probability that a $C$ cube is correctly oriented = $\frac{4}{24}$ . The probability that a $O$ cube is correctly oriented = $1$ . Furthermore, we can swap one corner cube for another, one edge cube for another and so forth leaving the outer appearance unchanged. So, there are $\frac{27!}{8!12!6!1!}$ favourable arrangements of the cubes. Putting it all together: $$P \{\text{Perfectly assembling the cube} \} = \frac{1}{24^8} \times \frac{1}{24^{12}} \times \left(\frac{4}{24}\right)^6 \times \frac{\frac{27!}{8!12!6!1!}}{27!}$$","A big cube consists of smaller cubes. The big cube is painted black on the outside. Suppose we disassemble the cube and randomly put it back together. What is the probability of perfectly assembling the cube i.e. all faces are black again? Do you think my partial progress is correct? If not, could you provide a hint/clue (without giving away the entire solution)? Solution (My Attempt) . There are corner(vertex) cubes, having faces black - label them There are edge cubes, having faces black - label them There are center of face cubes, having face black - label it There is origin cube, that is not black - label it For the cube, there are choices for the top face, and for each such choice, choices for an adjacent face. This completely determines the orientation. So, there are distinguishable orientations of the unit cube. The probability that a cube is correctly oriented = . The probability that a cube is correctly oriented = . The probability that a cube is correctly oriented = . The probability that a cube is correctly oriented = . Furthermore, we can swap one corner cube for another, one edge cube for another and so forth leaving the outer appearance unchanged. So, there are favourable arrangements of the cubes. Putting it all together:",3 \times 3 \times 3 1 \times 1 \times 1 8 3 V 12 2 E 6 1 C 1 O 1 \times 1 \times 1 6 4 24 V \frac{1}{24} E \frac{1}{24} C \frac{4}{24} O 1 \frac{27!}{8!12!6!1!} P \{\text{Perfectly assembling the cube} \} = \frac{1}{24^8} \times \frac{1}{24^{12}} \times \left(\frac{4}{24}\right)^6 \times \frac{\frac{27!}{8!12!6!1!}}{27!},"['probability', 'combinatorics', 'solution-verification', 'puzzle']"
17,Question on Cauchy-distribution.,Question on Cauchy-distribution.,,"Question: Let $X, Y$ be independent and Cauchy-distributed and define $Z:=$ $X+Y$ . Show that $Z / 2=\frac{X+Y}{2}$ is Cauchy-distributed. My attempt: I think that we can find the density of $Z$ first. For any fixed $a \in \mathbb{R}$ , the derivative of the function $$ h(y):= \begin{cases}\frac{1}{4 a+a^3}\left(\log \left(\left(1+y^2\right) /\left(1+(a-y)^2\right)\right)+\operatorname{aatan}(y)-a \operatorname{atan}(a-y)\right) & a \neq 0, \\ \frac{1}{4}\left(\frac{2 y}{1+y^2}+2 \operatorname{atan}(y)\right) & a=0,\end{cases} $$ is given by $$ h^{\prime}(y)=\frac{1}{1+(a-y)^2} \frac{1}{1+y^2} . $$ where atan $: \mathbb{R} \rightarrow(-\pi / 2, \pi / 2)$ is the inverse of the tangent function which satisfies $h(\infty)=\frac{\pi}{4+a^2}$ and $h(-\infty)=\frac{-\pi}{4+a^2}$ where these expression are meant as the respective limits. And if $X_1, \ldots, X_n$ are independent Cauchy-distributed random variables, then the average $\frac{1}{n} \sum_{k=1}^n X_k$ is Cauchy-distributed. But I'm not sure how to solve this question. Help would be appreciated. Thank you.","Question: Let be independent and Cauchy-distributed and define . Show that is Cauchy-distributed. My attempt: I think that we can find the density of first. For any fixed , the derivative of the function is given by where atan is the inverse of the tangent function which satisfies and where these expression are meant as the respective limits. And if are independent Cauchy-distributed random variables, then the average is Cauchy-distributed. But I'm not sure how to solve this question. Help would be appreciated. Thank you.","X, Y Z:= X+Y Z / 2=\frac{X+Y}{2} Z a \in \mathbb{R} 
h(y):= \begin{cases}\frac{1}{4 a+a^3}\left(\log \left(\left(1+y^2\right) /\left(1+(a-y)^2\right)\right)+\operatorname{aatan}(y)-a \operatorname{atan}(a-y)\right) & a \neq 0, \\ \frac{1}{4}\left(\frac{2 y}{1+y^2}+2 \operatorname{atan}(y)\right) & a=0,\end{cases}
 
h^{\prime}(y)=\frac{1}{1+(a-y)^2} \frac{1}{1+y^2} .
 : \mathbb{R} \rightarrow(-\pi / 2, \pi / 2) h(\infty)=\frac{\pi}{4+a^2} h(-\infty)=\frac{-\pi}{4+a^2} X_1, \ldots, X_n \frac{1}{n} \sum_{k=1}^n X_k","['probability', 'probability-theory', 'probability-distributions']"
18,Find a large subset of any $n$ integers where $a_1+2a_2=2a_3+2a_4$ is impossible.,Find a large subset of any  integers where  is impossible.,n a_1+2a_2=2a_3+2a_4,"Let $B=\left\{ b_{1},...,b_{n}\right\} $ a set of distinct positive integers. Show that there exists a subset $A\subseteq B$ , such that $|A|>\frac{1}{10} \cdot n$ , and such that there does not exist $a_1,a_2,a_3,a_4 \in A$ such that $a_1+2a_2=2a_3+2a_4$ . ( $n  \geq 1$ ) I have no clue where to start, I do have a few hints: consider $p=4k+3$ and consider $(1/2,2/3]$ , (specifically that $3\cdot (1/2,2/3]\cap 4\cdot(1/2,2/3] = \emptyset$ ). It should involve random variables and expectations, but I guess it is not the only way to solve, so any way would be highly appreciated. Thanks in advance.","Let a set of distinct positive integers. Show that there exists a subset , such that , and such that there does not exist such that . ( ) I have no clue where to start, I do have a few hints: consider and consider , (specifically that ). It should involve random variables and expectations, but I guess it is not the only way to solve, so any way would be highly appreciated. Thanks in advance.","B=\left\{ b_{1},...,b_{n}\right\}  A\subseteq B |A|>\frac{1}{10} \cdot n a_1,a_2,a_3,a_4 \in A a_1+2a_2=2a_3+2a_4 n 
\geq 1 p=4k+3 (1/2,2/3] 3\cdot (1/2,2/3]\cap 4\cdot(1/2,2/3] = \emptyset","['probability', 'combinatorics', 'discrete-mathematics']"
19,"Random walk's leading, asymptotic haven't-returned-to-origin probability","Random walk's leading, asymptotic haven't-returned-to-origin probability",,"In $1d$ and $2d$ , the probability that a simple random walk of length $n$ never returns to the origin asymptotes to $0$ as $n \to \infty$ . What is the leading asymptotic behavior of this decay at large $n$ ? A nice proof of recurrence in $1d$ and $2d$ is given here , where it's shown that the expected number of returns to the origin is, up to multiplicative constants, $\sim \sqrt{n}$ and $\sim \log(n)$ in $1d$ and $2d$ respectively. With an asymptotically infinite number of returns, the probability of returning must be $1$ . I'm tempted that these expected number of returns roughly point to the asymptotic probability of never returning to the origin in $n$ steps. That is, I anticipate that, up to multiplicative constants, the probability of never returning in a walk of $n$ steps in $1d$ and $2d$ is $\sim \frac{1}{\sqrt{n}}$ and $\sim \frac{1}{\log(n)}$ respectively. This is just a guess, but I show below the $1d$ guess is in fact correct. One can show that in $1d$ , the guess of $\sim \frac{1}{\sqrt{n}}$ up to multiplicative factors is correct for the probability of no returns in $n$ steps. One can find the entire distribution of the number of returns in time $2n$ in $1d$ ; the probability of $k$ returns is $\frac{\binom{2n-k}{n-k}}{2^{2n}}2^k$ . The probability of no returns in $2n$ steps is then $\frac{\binom{2n}{n}}{2^{2n}}$ (which is curiously the probability of returning on exactly the $2n$ th step); this probability goes as $\sim \frac{1}{\sqrt{\pi n}}$ , confirming the guess. Thus, only the $2d$ case is left to investigate. At one point, I found a somewhat complicated recursion relation for the exact probability of never returning to the origin in $2n$ steps; I'm going to try to dig that up. However, I anticipate there are simpler methods of estimating the asymptotic probability of no return up to multiplicative constants that won't need to first pass through calculating the exact probability of never returning.","In and , the probability that a simple random walk of length never returns to the origin asymptotes to as . What is the leading asymptotic behavior of this decay at large ? A nice proof of recurrence in and is given here , where it's shown that the expected number of returns to the origin is, up to multiplicative constants, and in and respectively. With an asymptotically infinite number of returns, the probability of returning must be . I'm tempted that these expected number of returns roughly point to the asymptotic probability of never returning to the origin in steps. That is, I anticipate that, up to multiplicative constants, the probability of never returning in a walk of steps in and is and respectively. This is just a guess, but I show below the guess is in fact correct. One can show that in , the guess of up to multiplicative factors is correct for the probability of no returns in steps. One can find the entire distribution of the number of returns in time in ; the probability of returns is . The probability of no returns in steps is then (which is curiously the probability of returning on exactly the th step); this probability goes as , confirming the guess. Thus, only the case is left to investigate. At one point, I found a somewhat complicated recursion relation for the exact probability of never returning to the origin in steps; I'm going to try to dig that up. However, I anticipate there are simpler methods of estimating the asymptotic probability of no return up to multiplicative constants that won't need to first pass through calculating the exact probability of never returning.",1d 2d n 0 n \to \infty n 1d 2d \sim \sqrt{n} \sim \log(n) 1d 2d 1 n n 1d 2d \sim \frac{1}{\sqrt{n}} \sim \frac{1}{\log(n)} 1d 1d \sim \frac{1}{\sqrt{n}} n 2n 1d k \frac{\binom{2n-k}{n-k}}{2^{2n}}2^k 2n \frac{\binom{2n}{n}}{2^{2n}} 2n \sim \frac{1}{\sqrt{\pi n}} 2d 2n,"['probability', 'stochastic-processes', 'asymptotics', 'random-walk']"
20,Find an example where bounded difference inequality is useful,Find an example where bounded difference inequality is useful,,"Question: Is there an example, where the bounded difference property gives better concentration than what we get from using the sub-gaussian bound? I could not find any examples myself. But I believe there must exist some, otherwise I see no point in introducing the bounded difference concentration inequality. Definitions: Bounded difference property. We say that $f:\mathbb{R}^n\rightarrow\mathbb{R}$ satisfies the bounded difference property, if for all $k\in[n]$ there exists a $L_k\geq 0$ , such that for all $x\in\mathbb{R}^n$ and any $t\in\mathbb{R}$ it holds that $|f(x)-f(x+te_k)|\leq L_k$ . Here, $e_k\in\mathbb{R}^n$ is the $k$ -th unit vector. One can show that $f$ satisfies the bounded difference property, if and only if $\|f\|_\infty<+\infty$ . To be specific, if $f$ is bounded, using the triangular inequality, $$ |f(x)-f(x+te_k)|\leq 2\|f\|_\infty $$ On the other hand, suppose that $f$ satisfies the bounded difference inequality. Let $x^k:=(x_1,\ldots,x_k,0,\ldots,0)$ . Then: $$ |f(x)|= \left|f(0)+\sum_{k=1}^n f(x^k)-f(x^{k-1})\right |\leq |f(0)|+\sum_{k=1}^nL_k $$ Since the choice of $0$ was arbitrary, we find: $$ \|f\|_\infty\leq \inf_{y\in\mathbb{R}} |f(y)|+\sum_{k=1}^nL_k $$ The following is Corollary 2.21 in Wainwright's ""High-Dimensional Statistics"": Concentration from bounded difference property. Suppose that $f$ satisfies the bounded difference property, and that the random vector $X:=(X_1,\ldots,X_n)$ has independent components. Then, for all $t>0$ , $$ \mathbb{P}\left[ |f(X)-\mathbb{E}[f(X)]|\geq t\right] \leq 2\exp\left(-\frac{2t^2}{\sum_{k=1}^n L_k^2}\right). $$ On the other hand, as we have shown above, any $f$ which satisfies the bounded difference property is also bounded. Hence, we can directly use a sub-gaussian tail bound. From (2.11) in Wainwright's ""High-Dimensional Statistics"", we get the following. Sub-gaussian concentration for bounded random variables. If there exist $a,b>0$ , such that $a<f(x)<b$ , then, for all $t>0$ : $$ \mathbb{P}\left[|f(X)-\mathbb{E}[f(X)]|\geq t\right]\leq 2\exp\left(-\frac{2t^2}{(b-a)^2}\right) $$","Question: Is there an example, where the bounded difference property gives better concentration than what we get from using the sub-gaussian bound? I could not find any examples myself. But I believe there must exist some, otherwise I see no point in introducing the bounded difference concentration inequality. Definitions: Bounded difference property. We say that satisfies the bounded difference property, if for all there exists a , such that for all and any it holds that . Here, is the -th unit vector. One can show that satisfies the bounded difference property, if and only if . To be specific, if is bounded, using the triangular inequality, On the other hand, suppose that satisfies the bounded difference inequality. Let . Then: Since the choice of was arbitrary, we find: The following is Corollary 2.21 in Wainwright's ""High-Dimensional Statistics"": Concentration from bounded difference property. Suppose that satisfies the bounded difference property, and that the random vector has independent components. Then, for all , On the other hand, as we have shown above, any which satisfies the bounded difference property is also bounded. Hence, we can directly use a sub-gaussian tail bound. From (2.11) in Wainwright's ""High-Dimensional Statistics"", we get the following. Sub-gaussian concentration for bounded random variables. If there exist , such that , then, for all :","f:\mathbb{R}^n\rightarrow\mathbb{R} k\in[n] L_k\geq 0 x\in\mathbb{R}^n t\in\mathbb{R} |f(x)-f(x+te_k)|\leq L_k e_k\in\mathbb{R}^n k f \|f\|_\infty<+\infty f 
|f(x)-f(x+te_k)|\leq 2\|f\|_\infty
 f x^k:=(x_1,\ldots,x_k,0,\ldots,0) 
|f(x)|= \left|f(0)+\sum_{k=1}^n f(x^k)-f(x^{k-1})\right |\leq |f(0)|+\sum_{k=1}^nL_k
 0 
\|f\|_\infty\leq \inf_{y\in\mathbb{R}} |f(y)|+\sum_{k=1}^nL_k
 f X:=(X_1,\ldots,X_n) t>0 
\mathbb{P}\left[
|f(X)-\mathbb{E}[f(X)]|\geq t\right]
\leq 2\exp\left(-\frac{2t^2}{\sum_{k=1}^n L_k^2}\right).
 f a,b>0 a<f(x)<b t>0 
\mathbb{P}\left[|f(X)-\mathbb{E}[f(X)]|\geq t\right]\leq 2\exp\left(-\frac{2t^2}{(b-a)^2}\right)
","['probability', 'probability-theory', 'inequality', 'concentration-of-measure']"
21,"If population keep trying till they have girl child, what will be the probability of population having more girls than boys and vice versa?","If population keep trying till they have girl child, what will be the probability of population having more girls than boys and vice versa?",,"I was solving this problem: In a world where everyone wants a girl child, each family continues having babies till they have a girl. What do you think will the boy to girl ratio be eventually? (Assuming probability of having a boy or a girl is the same) The solution given was: Suppose there are N couples. First time, N/2 girls and N/2 boys are born (ignoring aberrations). N/2 couples retire, and rest half try another child. Next time, N/4 couples give birth to N/4 girls and rest N/4 boys. Thus, even in second iteration, ratio is 1:1. It can now be seen that this ratio always remain same, no matter how many times people try to give birth to a favored gender. My doubt is that will following be the case: P(population will have more girls)= P(population will have equal number of boys and girls)= 1/2 Consider there are 16 couples 8 give birth to girls and hence stop. 8 give birth to boys, so they give another chance. 4 give birth to girls and hence stop. 4 give birth to boys, so they give another chance. 2 give birth to girls and hence stop. 2 give birth to boys, so they give another chance. 1 give birth to a girl and hence stop. 1 give birth to a boy, so they give another chance. Note till now there Number of boys = Number of girls Now probability that a single remaining couple give birth to a girl is 1/2 . In that case they will stop and there will be one more girl than boys in the population. Probability that a single remaining couple give birth to a boy is 1/2 , in which case they will give another chance in which they will again have a 1/2 probability of giving birth to boys, thus again balancing girl-boy ratio . So am I correct with two facts: Fact 1 : P(population will have more girls than girls)= P(population will have equal number of boys and girls)= 1/2 Fact 2 : P(population will have more boys than girls) = 0","I was solving this problem: In a world where everyone wants a girl child, each family continues having babies till they have a girl. What do you think will the boy to girl ratio be eventually? (Assuming probability of having a boy or a girl is the same) The solution given was: Suppose there are N couples. First time, N/2 girls and N/2 boys are born (ignoring aberrations). N/2 couples retire, and rest half try another child. Next time, N/4 couples give birth to N/4 girls and rest N/4 boys. Thus, even in second iteration, ratio is 1:1. It can now be seen that this ratio always remain same, no matter how many times people try to give birth to a favored gender. My doubt is that will following be the case: P(population will have more girls)= P(population will have equal number of boys and girls)= 1/2 Consider there are 16 couples 8 give birth to girls and hence stop. 8 give birth to boys, so they give another chance. 4 give birth to girls and hence stop. 4 give birth to boys, so they give another chance. 2 give birth to girls and hence stop. 2 give birth to boys, so they give another chance. 1 give birth to a girl and hence stop. 1 give birth to a boy, so they give another chance. Note till now there Number of boys = Number of girls Now probability that a single remaining couple give birth to a girl is 1/2 . In that case they will stop and there will be one more girl than boys in the population. Probability that a single remaining couple give birth to a boy is 1/2 , in which case they will give another chance in which they will again have a 1/2 probability of giving birth to boys, thus again balancing girl-boy ratio . So am I correct with two facts: Fact 1 : P(population will have more girls than girls)= P(population will have equal number of boys and girls)= 1/2 Fact 2 : P(population will have more boys than girls) = 0",,"['probability', 'geometric-distribution']"
22,Upper bound on hitting probability for a non-simple one-dimensional random walk,Upper bound on hitting probability for a non-simple one-dimensional random walk,,"Consider the random walk $S_n=\sum_{k=1}^n X_k$ where $(X_n)$ is an i.i.d. sequence of variables with distribution $P(X_n=1)=P(X_n=-2)=\frac{1}{2}$ . I am trying to evaluate the probability $P(E)$ where $E$ is the event $E=\lbrace \exists n, S_n \geq 1 \rbrace$ . If we define the stopping time $\tau={\sf min}(n\ | \ S_n \geq 1)$ (or $\infty$ if the sums never reach $1$ ), it is easy to see that $P(\tau=k)$ is nonzero iff $k$ is congruent to $1$ modulo $3$ . I have computed the first values of $P(\tau=k)$ and $s_k=\sum_{j=1}^k P(\tau=j)$ : $$ \begin{array}{|c|c|c|c|} \hline k & 1 & 4 & 7 & 10 & 13 & 16 \\ \hline P(\tau=k) & \frac{1}{2} & \frac{1}{16} & \frac{3}{2^7} & \frac{3}{2^8} &  \frac{55}{2^{13}} & \frac{273}{2^{16}} \\ \hline s_k & 0.5 & 0.56 & 0.59 & 0.6 & 0.6 & 0.61 \\ \hline \end{array} $$ Question. Is it true that $P(E)\leq 0.7$ ? My thoughts : one can introduce $f(k)=P(\lbrace \exists n, S_n \geq k)$ . Then for $k\geq 1$ one has the linear recurrence $f(k)=\frac{f(k-1)+f(k+2)}{2}$ , with $f(0)=1$ and $f(1)=P(E)$ . The characteristic polynomial associated to this recurrence is $X^3-2X+1=(X-1)(X^2+X-1)$ , and its root are $1$ and $\frac{-1\pm\sqrt{5}}{2}$ . So there are constants $c_1,c_2,c_3$ such that $f(k)=c_1+c_2\big(\frac{-1+\sqrt{5}}{2}\big)^k+c_3\big(\frac{-1-\sqrt{5}}{2}\big)^k$ . Because of $0\leq f(k)\leq 1$ and $\big|\frac{1+\sqrt{5}}{2}\big| \gt 1$ it follows that $c_3=0$ .  I am stuck after this however because the only relation I can see is $f(0)=1$ , which leaves one degree of freedom.","Consider the random walk where is an i.i.d. sequence of variables with distribution . I am trying to evaluate the probability where is the event . If we define the stopping time (or if the sums never reach ), it is easy to see that is nonzero iff is congruent to modulo . I have computed the first values of and : Question. Is it true that ? My thoughts : one can introduce . Then for one has the linear recurrence , with and . The characteristic polynomial associated to this recurrence is , and its root are and . So there are constants such that . Because of and it follows that .  I am stuck after this however because the only relation I can see is , which leaves one degree of freedom.","S_n=\sum_{k=1}^n X_k (X_n) P(X_n=1)=P(X_n=-2)=\frac{1}{2} P(E) E E=\lbrace \exists n, S_n \geq 1 \rbrace \tau={\sf min}(n\ | \ S_n \geq 1) \infty 1 P(\tau=k) k 1 3 P(\tau=k) s_k=\sum_{j=1}^k P(\tau=j) 
\begin{array}{|c|c|c|c|}
\hline
k & 1 & 4 & 7 & 10 & 13 & 16 \\
\hline
P(\tau=k) & \frac{1}{2} & \frac{1}{16} & \frac{3}{2^7} & \frac{3}{2^8} &  \frac{55}{2^{13}} & \frac{273}{2^{16}} \\
\hline
s_k & 0.5 & 0.56 & 0.59 & 0.6 & 0.6 & 0.61 \\
\hline
\end{array}
 P(E)\leq 0.7 f(k)=P(\lbrace \exists n, S_n \geq k) k\geq 1 f(k)=\frac{f(k-1)+f(k+2)}{2} f(0)=1 f(1)=P(E) X^3-2X+1=(X-1)(X^2+X-1) 1 \frac{-1\pm\sqrt{5}}{2} c_1,c_2,c_3 f(k)=c_1+c_2\big(\frac{-1+\sqrt{5}}{2}\big)^k+c_3\big(\frac{-1-\sqrt{5}}{2}\big)^k 0\leq f(k)\leq 1 \big|\frac{1+\sqrt{5}}{2}\big| \gt 1 c_3=0 f(0)=1","['probability', 'stochastic-processes', 'random-walk']"
23,Probability of being close to a cycle permutation is $o(1)$,Probability of being close to a cycle permutation is,o(1),"I'm trying to prove that in some sense, cycle (maybe circular is a better wording?) permutations are ""sparse"" in the set of all permutations $S_n$ . Let's assume permutations distribute uniformly out of the $n!$ combinations. It is clear that the probability of getting a cycle permutation is $\frac{1}{n}$ . My question is what happens when we ""dilate"" the set according the the Hamming distance $$d(\sigma, \pi) = \frac{1}{n}\left |\left \{ i: \sigma(i)\ne \pi(i)\right \}\right |$$ Then denote the event of being $\epsilon$ -close to a cycle, i.e. $d(\sigma, \text{set of all cycles})<\epsilon$ , for instance for $\epsilon = \frac{1}{4}$ . How can I show this occurs in probability $o(1)$ if this is even true? I tried to upper-bound the probability by considering in how many ways I can degrade any $\frac{n}{4}$ indices of a given cycle, while still remaining a permutation, and got the bound $\frac{(n-1)!\binom{n}{n/4}(\frac{n}{4})!}{n!}$ which is way too loose. I thought of maybe representing the number of changes to get a cycle as a sum of indicator random variables somehow, and bound the probability to deviate from the expectation.","I'm trying to prove that in some sense, cycle (maybe circular is a better wording?) permutations are ""sparse"" in the set of all permutations . Let's assume permutations distribute uniformly out of the combinations. It is clear that the probability of getting a cycle permutation is . My question is what happens when we ""dilate"" the set according the the Hamming distance Then denote the event of being -close to a cycle, i.e. , for instance for . How can I show this occurs in probability if this is even true? I tried to upper-bound the probability by considering in how many ways I can degrade any indices of a given cycle, while still remaining a permutation, and got the bound which is way too loose. I thought of maybe representing the number of changes to get a cycle as a sum of indicator random variables somehow, and bound the probability to deviate from the expectation.","S_n n! \frac{1}{n} d(\sigma, \pi) = \frac{1}{n}\left |\left \{ i: \sigma(i)\ne \pi(i)\right \}\right | \epsilon d(\sigma, \text{set of all cycles})<\epsilon \epsilon = \frac{1}{4} o(1) \frac{n}{4} \frac{(n-1)!\binom{n}{n/4}(\frac{n}{4})!}{n!}","['probability', 'combinatorics', 'permutations']"
24,The probability of throwing $n$ dice with each result being contained in a set,The probability of throwing  dice with each result being contained in a set,n,"I recently asked this question on MSE: The probability of throwing two dice with each result being contained in a set and although I am happy with the answer, I cannot figure out how this generalizes to $n$ or even 3 dice. To state the case for $n$ dice: If we have the sets $S_1, S_2, \dots, S_n$ of possible outcomes and we throw $n$ indistinguishable dice (with the same number of sides) simultaneously, what is the probability that each die is contained in different sets, that is, what is the probability that the first is contained in set $S_{i_1}$ , the second is contained in $S_{i_2}$ , the third in $S_{i_3}$ , $\dots$ and the $n$ -th in $S_{i_n}$ with $i_1 \neq i_2 \neq i_3 \neq \dots \neq i_n$ . An example for $n=2$ : When have 2 dice and two sets $A$ and $B$ being $\{ 1, 2, 4\}$ and $\{ 1, 2, 5\}$ , respectively. We will end up with the possibilities of $\{ 1,1 \}, \{ 2,2 \}$ which account for a $\frac{1}{36}$ probability each and $\{ 1,2 \}$ , $\{ 1,4 \}$ , $\{ 1,5 \}$ , $\{ 2,4 \}$ , $\{ 2,5 \}$ , $\{ 4,5 \}$ accounting for a $\frac{2}{36}$ probability each, for a total chance of $\frac{14}{36}=\frac{7}{18}$ . As @user2661923 correctly pointed out in the other question, you could also determine this by calculating $\frac{(2\times 3^2) - 2^2}{36} = \frac{14}{36} = \frac{7}{18}$ . Formula for $n=2$ : In general the chance for $n=2$ dice with sets $A$ and $B$ is: $$\frac{2! \# A \# B - \#(A\cap B)^2}{6^2}$$ . Formula for $n=3$ : This is where I got stuck, I could not obtain the formula for three dice with the sets $A$ , $B$ and $C$ . However, I came this far: $$\frac{3! \#A \#B \#C - 3\#A\#(B\cap C)^2 - 3\#B\#(A\cap C)^2 - 3\#C\#(A\cap B)^2 \pm \dots}{6^3}$$ I do not know what should be at the dots. My question: What is the correct formula for $n=3$ (and for larger $n$ )? I also wrote some python code to check some cases and provide support , mostly so that double work is avoided; everthing can be controlled by changing the variable sets (add anoter list to add a die). from itertools import product from sympy.utilities.iterables import multiset_permutations from collections import Counter   # sets = [[1, 2, 3], [3, 4, 5], [4, 5, 6]] sets = [[1, 2, 4], [1, 2, 5]]  n_dice = len(correct) counter = Counter()  for roll in product(range(1, max(max(i) for i in sets)+1), repeat=n_dice):     times = 0     for perm in multiset_permutations(roll):         if [perm[i] in sets[i] for i in range(n_dice)] == [True]*n_dice:             times = 1     if times > 0:         counter[tuple(sorted(roll))] += times  count = 0 for k, v in sorted(counter.items()):     count += v     print(f'total: {count}, dice roll: {k}, multiplicity: {v}')","I recently asked this question on MSE: The probability of throwing two dice with each result being contained in a set and although I am happy with the answer, I cannot figure out how this generalizes to or even 3 dice. To state the case for dice: If we have the sets of possible outcomes and we throw indistinguishable dice (with the same number of sides) simultaneously, what is the probability that each die is contained in different sets, that is, what is the probability that the first is contained in set , the second is contained in , the third in , and the -th in with . An example for : When have 2 dice and two sets and being and , respectively. We will end up with the possibilities of which account for a probability each and , , , , , accounting for a probability each, for a total chance of . As @user2661923 correctly pointed out in the other question, you could also determine this by calculating . Formula for : In general the chance for dice with sets and is: . Formula for : This is where I got stuck, I could not obtain the formula for three dice with the sets , and . However, I came this far: I do not know what should be at the dots. My question: What is the correct formula for (and for larger )? I also wrote some python code to check some cases and provide support , mostly so that double work is avoided; everthing can be controlled by changing the variable sets (add anoter list to add a die). from itertools import product from sympy.utilities.iterables import multiset_permutations from collections import Counter   # sets = [[1, 2, 3], [3, 4, 5], [4, 5, 6]] sets = [[1, 2, 4], [1, 2, 5]]  n_dice = len(correct) counter = Counter()  for roll in product(range(1, max(max(i) for i in sets)+1), repeat=n_dice):     times = 0     for perm in multiset_permutations(roll):         if [perm[i] in sets[i] for i in range(n_dice)] == [True]*n_dice:             times = 1     if times > 0:         counter[tuple(sorted(roll))] += times  count = 0 for k, v in sorted(counter.items()):     count += v     print(f'total: {count}, dice roll: {k}, multiplicity: {v}')","n n S_1, S_2, \dots, S_n n S_{i_1} S_{i_2} S_{i_3} \dots n S_{i_n} i_1 \neq i_2 \neq i_3 \neq \dots \neq i_n n=2 A B \{ 1, 2, 4\} \{ 1, 2, 5\} \{ 1,1 \}, \{ 2,2 \} \frac{1}{36} \{ 1,2 \} \{ 1,4 \} \{ 1,5 \} \{ 2,4 \} \{ 2,5 \} \{ 4,5 \} \frac{2}{36} \frac{14}{36}=\frac{7}{18} \frac{(2\times 3^2) - 2^2}{36} = \frac{14}{36} = \frac{7}{18} n=2 n=2 A B \frac{2! \# A \# B - \#(A\cap B)^2}{6^2} n=3 A B C \frac{3! \#A \#B \#C - 3\#A\#(B\cap C)^2 - 3\#B\#(A\cap C)^2 - 3\#C\#(A\cap B)^2 \pm \dots}{6^3} n=3 n","['probability', 'combinatorics', 'dice']"
25,What if I have different information from the Bayes Theorm diseases question?,What if I have different information from the Bayes Theorm diseases question?,,"I'm studying Bayes' Rule and came across the diseases problem. And wonder if it also works in other circumstances. Let us say $D$ is the event having the diseases, $T$ is the event testing positive for the diseases and $N$ is the event testing negative . Usually, we will be given with the probability of $P(D)$ , $P(T|D)$ and $P(N|\overline{D})$ . So we can figure out $P(D|T) = \frac{P(T|D)P(D)}{P(T|D)P(D)+P(T|\overline{D})P(\overline{D})}$ . But What if I know $P(D)$ , $P(D|T)$ and $P(\overline{D}|N)$ , and trying to figure out $P(T|D)$ . Is that possible? So far I can only get $$P(T|D) = \frac{P(\overline{D}|T)[P(\overline{D}|T)P(T))+P(D|T)P(T)]}{P(D)} = \frac{P(\overline{D}|T)[P(T|\overline{D})P(\overline{D})+P(T|D)P(D)]}{P(D)}$$ It seems like if I don't know $P(T)$ or $P(T|D)$ itself I can' find the answer. I wonder if there is a way to figure this out knowing the Bayes' Rule. Thank you.","I'm studying Bayes' Rule and came across the diseases problem. And wonder if it also works in other circumstances. Let us say is the event having the diseases, is the event testing positive for the diseases and is the event testing negative . Usually, we will be given with the probability of , and . So we can figure out . But What if I know , and , and trying to figure out . Is that possible? So far I can only get It seems like if I don't know or itself I can' find the answer. I wonder if there is a way to figure this out knowing the Bayes' Rule. Thank you.",D T N P(D) P(T|D) P(N|\overline{D}) P(D|T) = \frac{P(T|D)P(D)}{P(T|D)P(D)+P(T|\overline{D})P(\overline{D})} P(D) P(D|T) P(\overline{D}|N) P(T|D) P(T|D) = \frac{P(\overline{D}|T)[P(\overline{D}|T)P(T))+P(D|T)P(T)]}{P(D)} = \frac{P(\overline{D}|T)[P(T|\overline{D})P(\overline{D})+P(T|D)P(D)]}{P(D)} P(T) P(T|D),"['probability', 'bayes-theorem']"
26,Probability of rolling $n$ dice that are each are greater than or equal to $x$ with a given pool of possible positive modifiers applied on each dice,Probability of rolling  dice that are each are greater than or equal to  with a given pool of possible positive modifiers applied on each dice,n x,"I am currently analyzing a tabletop games probabilities. Successful rolls in the game are determined by rolling $n$ number of dice and counting the number of dice that are greater than or equal to a certain value (some pre-determined threshold $x$ ; for instance, values could be between 1 through 6 from a six sided die). For example, suppose my threshold $x=3$ ; if I roll $10$ six sided die, what is the probability that $4$ dice would land on a $3$ or greater? Additionally, the game allows for a positive pool of modifiers to be applied on the dice after they are rolled, such that it can bring them over the determined threshold $x$ and have it count as a success. For example, suppose I roll three six sided die. Let $n_i$ represent the value of the die, and let $n_1=2$ , $n_2=3$ , and $n_3=6$ . Suppose I have a threshold of $x=4$ have a pool of $+3$ points to apply on any one of those die. I would be able to distribute all those points on both $n_1$ and $n_2$ such that I now have three successes instead of only one (where now $n_1=2+2=4$ , $n_2=3+1=4$ , and $n_3=6$ .) How are the probabilities of rolling $n$ dice that are each are greater than or equal to $x$ affected by the number of points in the modifier pool? I have attempted to develop a formula specifically to answer the last question above so that I can analyze the distribution of a certain number of dice with different thresholds. I started with thinking of it as a binomial distribution, however, I am uncertain how it is affected by the modifiers. EDIT : After almost a year since asking the question I think I have something close to a solution, but not exact. From my analysis, the probability computation for a combination of the number of dice, modifiers, successes required, and dice sides is incredibly complex to generalize. Here is a dropbox link of my analysis (very informal), where I attempted to find a distribution I've labeled $tdw(n,f,d,s)$ (to answer probability statements such as $Pr(X=x_{2}|n=7,f=4,d=4,s=3)$ , where $x_{2}$ denotes getting 2 successes - here I defined the threshold to be $d$ , the number of sides of the dice to be $s$ , and the total number of available modifiers to be $f$ ) which in effect is a modified binomial distribution with extra parameters. I have no understanding of how to create a discrete distribution like this formally, however. The framework I attempted to create used two 3 dimensional matrixes of different sizes depending on the value of $f$ and $n$ . These would track the probabilities of a certain combination of $n$ , $f$ , $d$ , and $s$ . This idea, however, is completely made up and may have no basis in solving this kind of problem, however, for the $i=0$ case, the method always correctly solves the probability when compared to the probability I calculated manually.","I am currently analyzing a tabletop games probabilities. Successful rolls in the game are determined by rolling number of dice and counting the number of dice that are greater than or equal to a certain value (some pre-determined threshold ; for instance, values could be between 1 through 6 from a six sided die). For example, suppose my threshold ; if I roll six sided die, what is the probability that dice would land on a or greater? Additionally, the game allows for a positive pool of modifiers to be applied on the dice after they are rolled, such that it can bring them over the determined threshold and have it count as a success. For example, suppose I roll three six sided die. Let represent the value of the die, and let , , and . Suppose I have a threshold of have a pool of points to apply on any one of those die. I would be able to distribute all those points on both and such that I now have three successes instead of only one (where now , , and .) How are the probabilities of rolling dice that are each are greater than or equal to affected by the number of points in the modifier pool? I have attempted to develop a formula specifically to answer the last question above so that I can analyze the distribution of a certain number of dice with different thresholds. I started with thinking of it as a binomial distribution, however, I am uncertain how it is affected by the modifiers. EDIT : After almost a year since asking the question I think I have something close to a solution, but not exact. From my analysis, the probability computation for a combination of the number of dice, modifiers, successes required, and dice sides is incredibly complex to generalize. Here is a dropbox link of my analysis (very informal), where I attempted to find a distribution I've labeled (to answer probability statements such as , where denotes getting 2 successes - here I defined the threshold to be , the number of sides of the dice to be , and the total number of available modifiers to be ) which in effect is a modified binomial distribution with extra parameters. I have no understanding of how to create a discrete distribution like this formally, however. The framework I attempted to create used two 3 dimensional matrixes of different sizes depending on the value of and . These would track the probabilities of a certain combination of , , , and . This idea, however, is completely made up and may have no basis in solving this kind of problem, however, for the case, the method always correctly solves the probability when compared to the probability I calculated manually.","n x x=3 10 4 3 x n_i n_1=2 n_2=3 n_3=6 x=4 +3 n_1 n_2 n_1=2+2=4 n_2=3+1=4 n_3=6 n x tdw(n,f,d,s) Pr(X=x_{2}|n=7,f=4,d=4,s=3) x_{2} d s f f n n f d s i=0","['probability', 'statistics', 'probability-distributions', 'binomial-distribution', 'dice']"
27,Challenge: a Bit-flipping Game,Challenge: a Bit-flipping Game,,"I was just thinking about brain teasers the other day and came up with this one that turned out to be more difficult than I was anticipating. Suppose we play a game where we start with a bit string of $l$ zeroes (in my example $l=8$ ), 00000000 At each step of the game, we choose a bit at random from the bit string and flip it, like 01000000 The game terminates whenever we return back to our initial state of all zeroes. My question is this: What is the (closed-form) expected value of the length of the game as a function of $l$ ? My (incomplete) approach: First, I found the answer for verification purposes by programming the game with a couple different values of $l$ in python, which gave me the hypothesis that the expected value should be $2^l$ . My formal proof for how this is the case is what I'm seeking. I started by conceptualizing the bit string differently, as a string of integers from $0$ to $l-1$ with a dividing line between them. On the LHS of the line would be the indices of 1 in the bit string and the RHS would be indices of 0 in the bit string. This would encode a state like this: $$ \texttt{10111000}\qquad \Longrightarrow \qquad \texttt{0234 | 1567} $$ Then, each iteration of the game is simply choosing one of these numbers at random, and putting it on the other side of the dividing line. If we call the set of integers on the LHS $L$ and those on the RHS $R$ , then the probability that the line moves left is $|L|\;/\;l$ and the probability that it moves right is $|R|\;/\;l$ . In this sense, we can sort of model the bit-flipping process as a one-dimensional random walk, terminating whenever the walker reaches the LHS, or $|L| = 0$ . This is why I consider the process to be a Martingale, even though the probability that the walker moves one direction or the other actually changes depending on where it is. That said, I don't actually know anything about Martingales other than that they are essentially random walks with a terminating condition (like gambling or w/e). I'm just not sure how to continue from here, can anyone solve this problem?","I was just thinking about brain teasers the other day and came up with this one that turned out to be more difficult than I was anticipating. Suppose we play a game where we start with a bit string of zeroes (in my example ), 00000000 At each step of the game, we choose a bit at random from the bit string and flip it, like 01000000 The game terminates whenever we return back to our initial state of all zeroes. My question is this: What is the (closed-form) expected value of the length of the game as a function of ? My (incomplete) approach: First, I found the answer for verification purposes by programming the game with a couple different values of in python, which gave me the hypothesis that the expected value should be . My formal proof for how this is the case is what I'm seeking. I started by conceptualizing the bit string differently, as a string of integers from to with a dividing line between them. On the LHS of the line would be the indices of 1 in the bit string and the RHS would be indices of 0 in the bit string. This would encode a state like this: Then, each iteration of the game is simply choosing one of these numbers at random, and putting it on the other side of the dividing line. If we call the set of integers on the LHS and those on the RHS , then the probability that the line moves left is and the probability that it moves right is . In this sense, we can sort of model the bit-flipping process as a one-dimensional random walk, terminating whenever the walker reaches the LHS, or . This is why I consider the process to be a Martingale, even though the probability that the walker moves one direction or the other actually changes depending on where it is. That said, I don't actually know anything about Martingales other than that they are essentially random walks with a terminating condition (like gambling or w/e). I'm just not sure how to continue from here, can anyone solve this problem?","l l=8 l l 2^l 0 l-1 
\texttt{10111000}\qquad \Longrightarrow \qquad \texttt{0234 | 1567}
 L R |L|\;/\;l |R|\;/\;l |L| = 0","['probability', 'algorithms', 'martingales', 'game-theory']"
28,Bound central moments of even order with raw moments of same order,Bound central moments of even order with raw moments of same order,,"Let $(\Omega, \mathcal A, P)$ be a probability space and consider a real-valued random variable $X \colon \Omega \to \mathbb{R}$ . It holds $$ \mathrm{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 \leq \mathbb{E}[X^2]. $$ Is this true for higher moments of even order? Precisely, does it hold for $p = 1, 2, \ldots$ $$ \mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq C(p)\mathbb{E}[X^{2p}], $$ for some positive constant $C(p)$ depending only on $p$ and such that $C(1) = 1$ ? Edit: In this thread it is proved that the inequality above does not hold for $C(p) = 1$ for all $p = 1,2,\ldots$ Still, could it hold with a $p$ -dependent proportionality constant? Edit 2: It is possible to prove that the inequality holds with $C(p) = 2^{2p}$ using Hlder's and Jensen's inequality. In particular, Hlder's inequality yields for any real numbers $a$ and $b$ $$ (a-b)^{2p} \leq 2^{2p-1}(a^{2p}+b^{2p}), $$ so that by linearity of $\mathbb{E}$ $$ \mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq 2^{2p-1}\left(\mathbb{E}[X^{2p}]+\mathbb{E}[X]^{2p}\right). $$ Noew Jensen's inequality yields $\mathbb{E}[X]^{2p} \leq \mathbb{E}[X^{2p}]$ and we can conclude that $$ \mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq 2^{2p-1} \cdot 2 \mathbb{E}[X^{2p}]  =2^{2p}\mathbb{E}[X^{2p}]. $$ Is there any sharper bound? In this way, for $p = 1$ we obtain $C(1) = 4$ instead of $C(1) = 1$ .","Let be a probability space and consider a real-valued random variable . It holds Is this true for higher moments of even order? Precisely, does it hold for for some positive constant depending only on and such that ? Edit: In this thread it is proved that the inequality above does not hold for for all Still, could it hold with a -dependent proportionality constant? Edit 2: It is possible to prove that the inequality holds with using Hlder's and Jensen's inequality. In particular, Hlder's inequality yields for any real numbers and so that by linearity of Noew Jensen's inequality yields and we can conclude that Is there any sharper bound? In this way, for we obtain instead of .","(\Omega, \mathcal A, P) X \colon \Omega \to \mathbb{R} 
\mathrm{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 \leq \mathbb{E}[X^2].
 p = 1, 2, \ldots 
\mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq C(p)\mathbb{E}[X^{2p}],
 C(p) p C(1) = 1 C(p) = 1 p = 1,2,\ldots p C(p) = 2^{2p} a b 
(a-b)^{2p} \leq 2^{2p-1}(a^{2p}+b^{2p}),
 \mathbb{E} 
\mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq 2^{2p-1}\left(\mathbb{E}[X^{2p}]+\mathbb{E}[X]^{2p}\right).
 \mathbb{E}[X]^{2p} \leq \mathbb{E}[X^{2p}] 
\mathbb{E}[(X - \mathbb{E}[X])^{2p}] \leq 2^{2p-1} \cdot 2 \mathbb{E}[X^{2p}]  =2^{2p}\mathbb{E}[X^{2p}].
 p = 1 C(1) = 4 C(1) = 1","['probability', 'inequality', 'expected-value']"
29,"How is calculated the frequency of a pair, a flush of 2 cards, a straight of 2 cards and a straight flush of 2 cards (52 cards, hand of 2, 3, 4, etc)?","How is calculated the frequency of a pair, a flush of 2 cards, a straight of 2 cards and a straight flush of 2 cards (52 cards, hand of 2, 3, 4, etc)?",,"Introduction Before starting, I would like to specify a few things: The deck has 52 cards. From 1 (Ace) to 10, J, Q, K, all in four different suits: spades, diamonds, club and hearts. I don't add jokers because that is far beyond my possibilities of calculations. For better precision, I won't use chance, instead I would use combinations or frequency / total possible combinations. This is based on poker, but it isn't exactly poker. I mean, for example, the frequency on a pair in 5-cards poker is $2860={13 \choose 1}{4 \choose 2}{12 \choose 3}{4 \choose 1}^3$ , this formula that can be found on Wikipedia already excludes the chance of having not two but three or four cards with the same rank (three or four of a kind) and also excludes the chance of a full house (three of a kind + pair). What I want to discover, is not the frequency of a pair, instead, is the frequency of having at least two cards of the same rank. I'm not using the rules of poker, so I don't want to remove from the frequency the combinations that are ""better"". For example, the hand Q Q Q J J, which normally would be a full house, for this calculation I want it to be included in the ""pair"" calculation, because if you have three Qs, that means that you have at least a pair of Q, same with the Js. What do I want? What I want to calculate is the frequency of drawing: At least two cards of the same rank (a pair). At least two cards of the same suit (a flush of 2). At least two consecutive cards (a straight of 2). At least two consecutive cards of the same suit (a straight of 2 flushed). All the previous frequencies I wanted to calculate them with: A 2-card hand. A 3-card hand. A 4-card hand. A 5-card hand. A 6-card hand. A 7-card hand. My Calculations Before starting to show my math I will show you how I got it. At wikipedia, the chance of a four of a kind if a 5-card deck is $642={13 \choose 1}{4 \choose 4}{12 \choose 1}{4 \choose 1}$ . I understand this as choose one of 13 ranks, then choose all four suits of that rank, for the last card choose one other rank and then one suit for that card. Then I tried to recreate the formula with different reasoning. $642={13 \choose 1}{4 \choose 4}{52-4 \choose 1}$ which I understand as choose one of 13 ranks, then choose all four suits of that rank, finally choose one card other than the four previously used . Below I will show you a table with my math. Hand 2 cards 3 cards 4 cards 5 cards 6 cards 7 cards Total combinations $1.326={52 \choose 2}$ $22.100={52 \choose 3}$ $270.725={52 \choose 4}$ $2.598.960={52 \choose 5}$ $20.358.520={52 \choose 6}$ $133.784.560={52 \choose 7}$ Pair $78={13 \choose 1}{4 \choose 2}$ $3.900={13 \choose 1}{4 \choose 2}{52-2 \choose 1}$ $95.550={13 \choose 1}{4 \choose 2}{52-2 \choose 2}$ $1.528.800={13 \choose 1}{4 \choose 2}{52-2 \choose 3}$ $17.963.400={13 \choose 1}{4 \choose 2}{52-2 \choose 4}$ $165.263.280={13 \choose 1}{4 \choose 2}{52-2 \choose 5}$ Flush of 2 $312={13 \choose 2}{4 \choose 1}$ $15.600={13 \choose 2}{4 \choose 1}{52-2 \choose 1}$ $382.200={13 \choose 2}{4 \choose 1}{52-2 \choose 2}$ $6.115.200={13 \choose 2}{4 \choose 1}{52-2 \choose 3}$ $71.856.600={13 \choose 2}{4 \choose 1}{52-2 \choose 4}$ $661.053.120={13 \choose 2}{4 \choose 1}{52-2 \choose 5}$ Straight of 2 $208={13 \choose 1}{4 \choose 1}^2$ $10.400={13 \choose 1}{4 \choose 1}^2{52-2 \choose 1}$ $254.800={13 \choose 1}{4 \choose 1}^2{52-2 \choose 2}$ $4.076.800={13 \choose 1}{4 \choose 1}^2{52-2 \choose 3}$ $47.902.400={13 \choose 1}{4 \choose 1}^2{52-2 \choose 4}$ $440.702.080={13 \choose 1}{4 \choose 1}^2{52-2 \choose 5}$ Straight of 2 flushed* $52={13 \choose 1}{4 \choose 1}$ $2.600={13 \choose 1}{4 \choose 1}{52-2 \choose 1}$ $63.700={13 \choose 1}{4 \choose 1}{52-2 \choose 2}$ $1.019.200={13 \choose 1}{4 \choose 1}{52-2 \choose 3}$ $11.975.600={13 \choose 1}{4 \choose 1}{52-2 \choose 4}$ $110.175.520={13 \choose 1}{4 \choose 1}{52-2 \choose 5}$ *At 12 cards $27.917.689.800={13 \choose 1}{4 \choose 1}{52-2 \choose 10}$ while the total number is $15.820.024.220={52 \choose 12}$ My problem is that as you can see, when you draw multiple hands, the combinations of for example a pair becomes higher than the total possible combination, a thing that is absurd and can be easily demonstrated with an example hand: 1, 2, 3, 4, 5, 6, 7, there are 7 different cards, none is a pair. Of course, a flush of 2 cards is allowed to get 100% if you draw 5 cards (it is impossible to get 5 different suits because there only exist 4 different); however, it should not reach 100% in a 4-card hand (an easy example would be drawing a spade, a club, a diamond and a heart, none is repeated). Question: What am I missing with my calculations? As my method of calculation of the extra cards after forming what I want (for example, the three cards remaining after having a pair using 5 cards) I used ${52-2 \choose 3}$ instead of what appears in Wikipedia, I made an experiment trying to get the same results of Wikipedia with my method. The frequency of three of a kind in Wikipedia is $54.912={13 \choose 1}{4 \choose 3}{12 \choose 2}{4 \choose 1}^2$ which I understand as choose one card of the 13 ranks, then choose three of the four suits for that card, finally choose 2 cards that aren't from the previous rank, these cards each can be of any suit . If I use ${13 \choose 1}{4 \choose 3}{52-4 \choose 2}=58.656$ I have to eliminate the frequency in which that two extra cards are a pair, because that would fall into Full House from normal poker (following Wikipedia), so $58.656-3.744=54.912$ which is fine. Now I go one step further. If I use ${13 \choose 1}{4 \choose 3}{52-3 \choose 2}=61.152$ I have to eliminate the frequency in which that two extra cards are a pair (because of full house), and the frequency in that the remaining card of the suit appears and transform my three of a kind into a four of a kind $61.152-3.744-624=56.784$ which isn't 54.912. I discovered that if I multiply (in the previous formula) the frequency of a full house by 1.5, or I multiply the frequency of a four of a kind by 4 I get exactly 54.912, but I'm not sure why, and that might be what makes my math surpass the 100% (when comparing the frequency/total possible combinations). Do you have any idea what I'm doing wrong? What would be considered an answer? An explanation of which mathematical expression I am understanding wrong, a correct expression to replace that part, an explanation of what means that suggested new expression and one example using any of the combinations that appear in my table above that surpass the 100% using that new suggested expression. For example: ""When you say this expression ... you are wrong because that means instead ... What you have to use is ... because that means ... For example, if we use this formula to get the frequency of a pair with a 7-cards hand (in which your math surpassed 100%), we get ... which is correct because ..."" Note: I'm not a math teacher, and I'm not studying for a math career, so please try to not be too much complicated in the explanation. I just know combinations because at university we had 3 classes of hypergeometric distributions (I'm studying business administration). This is not for the university, work or gambling, actually, it is for Dungeons & Dragons 5e.","Introduction Before starting, I would like to specify a few things: The deck has 52 cards. From 1 (Ace) to 10, J, Q, K, all in four different suits: spades, diamonds, club and hearts. I don't add jokers because that is far beyond my possibilities of calculations. For better precision, I won't use chance, instead I would use combinations or frequency / total possible combinations. This is based on poker, but it isn't exactly poker. I mean, for example, the frequency on a pair in 5-cards poker is , this formula that can be found on Wikipedia already excludes the chance of having not two but three or four cards with the same rank (three or four of a kind) and also excludes the chance of a full house (three of a kind + pair). What I want to discover, is not the frequency of a pair, instead, is the frequency of having at least two cards of the same rank. I'm not using the rules of poker, so I don't want to remove from the frequency the combinations that are ""better"". For example, the hand Q Q Q J J, which normally would be a full house, for this calculation I want it to be included in the ""pair"" calculation, because if you have three Qs, that means that you have at least a pair of Q, same with the Js. What do I want? What I want to calculate is the frequency of drawing: At least two cards of the same rank (a pair). At least two cards of the same suit (a flush of 2). At least two consecutive cards (a straight of 2). At least two consecutive cards of the same suit (a straight of 2 flushed). All the previous frequencies I wanted to calculate them with: A 2-card hand. A 3-card hand. A 4-card hand. A 5-card hand. A 6-card hand. A 7-card hand. My Calculations Before starting to show my math I will show you how I got it. At wikipedia, the chance of a four of a kind if a 5-card deck is . I understand this as choose one of 13 ranks, then choose all four suits of that rank, for the last card choose one other rank and then one suit for that card. Then I tried to recreate the formula with different reasoning. which I understand as choose one of 13 ranks, then choose all four suits of that rank, finally choose one card other than the four previously used . Below I will show you a table with my math. Hand 2 cards 3 cards 4 cards 5 cards 6 cards 7 cards Total combinations Pair Flush of 2 Straight of 2 Straight of 2 flushed* *At 12 cards while the total number is My problem is that as you can see, when you draw multiple hands, the combinations of for example a pair becomes higher than the total possible combination, a thing that is absurd and can be easily demonstrated with an example hand: 1, 2, 3, 4, 5, 6, 7, there are 7 different cards, none is a pair. Of course, a flush of 2 cards is allowed to get 100% if you draw 5 cards (it is impossible to get 5 different suits because there only exist 4 different); however, it should not reach 100% in a 4-card hand (an easy example would be drawing a spade, a club, a diamond and a heart, none is repeated). Question: What am I missing with my calculations? As my method of calculation of the extra cards after forming what I want (for example, the three cards remaining after having a pair using 5 cards) I used instead of what appears in Wikipedia, I made an experiment trying to get the same results of Wikipedia with my method. The frequency of three of a kind in Wikipedia is which I understand as choose one card of the 13 ranks, then choose three of the four suits for that card, finally choose 2 cards that aren't from the previous rank, these cards each can be of any suit . If I use I have to eliminate the frequency in which that two extra cards are a pair, because that would fall into Full House from normal poker (following Wikipedia), so which is fine. Now I go one step further. If I use I have to eliminate the frequency in which that two extra cards are a pair (because of full house), and the frequency in that the remaining card of the suit appears and transform my three of a kind into a four of a kind which isn't 54.912. I discovered that if I multiply (in the previous formula) the frequency of a full house by 1.5, or I multiply the frequency of a four of a kind by 4 I get exactly 54.912, but I'm not sure why, and that might be what makes my math surpass the 100% (when comparing the frequency/total possible combinations). Do you have any idea what I'm doing wrong? What would be considered an answer? An explanation of which mathematical expression I am understanding wrong, a correct expression to replace that part, an explanation of what means that suggested new expression and one example using any of the combinations that appear in my table above that surpass the 100% using that new suggested expression. For example: ""When you say this expression ... you are wrong because that means instead ... What you have to use is ... because that means ... For example, if we use this formula to get the frequency of a pair with a 7-cards hand (in which your math surpassed 100%), we get ... which is correct because ..."" Note: I'm not a math teacher, and I'm not studying for a math career, so please try to not be too much complicated in the explanation. I just know combinations because at university we had 3 classes of hypergeometric distributions (I'm studying business administration). This is not for the university, work or gambling, actually, it is for Dungeons & Dragons 5e.",2860={13 \choose 1}{4 \choose 2}{12 \choose 3}{4 \choose 1}^3 642={13 \choose 1}{4 \choose 4}{12 \choose 1}{4 \choose 1} 642={13 \choose 1}{4 \choose 4}{52-4 \choose 1} 1.326={52 \choose 2} 22.100={52 \choose 3} 270.725={52 \choose 4} 2.598.960={52 \choose 5} 20.358.520={52 \choose 6} 133.784.560={52 \choose 7} 78={13 \choose 1}{4 \choose 2} 3.900={13 \choose 1}{4 \choose 2}{52-2 \choose 1} 95.550={13 \choose 1}{4 \choose 2}{52-2 \choose 2} 1.528.800={13 \choose 1}{4 \choose 2}{52-2 \choose 3} 17.963.400={13 \choose 1}{4 \choose 2}{52-2 \choose 4} 165.263.280={13 \choose 1}{4 \choose 2}{52-2 \choose 5} 312={13 \choose 2}{4 \choose 1} 15.600={13 \choose 2}{4 \choose 1}{52-2 \choose 1} 382.200={13 \choose 2}{4 \choose 1}{52-2 \choose 2} 6.115.200={13 \choose 2}{4 \choose 1}{52-2 \choose 3} 71.856.600={13 \choose 2}{4 \choose 1}{52-2 \choose 4} 661.053.120={13 \choose 2}{4 \choose 1}{52-2 \choose 5} 208={13 \choose 1}{4 \choose 1}^2 10.400={13 \choose 1}{4 \choose 1}^2{52-2 \choose 1} 254.800={13 \choose 1}{4 \choose 1}^2{52-2 \choose 2} 4.076.800={13 \choose 1}{4 \choose 1}^2{52-2 \choose 3} 47.902.400={13 \choose 1}{4 \choose 1}^2{52-2 \choose 4} 440.702.080={13 \choose 1}{4 \choose 1}^2{52-2 \choose 5} 52={13 \choose 1}{4 \choose 1} 2.600={13 \choose 1}{4 \choose 1}{52-2 \choose 1} 63.700={13 \choose 1}{4 \choose 1}{52-2 \choose 2} 1.019.200={13 \choose 1}{4 \choose 1}{52-2 \choose 3} 11.975.600={13 \choose 1}{4 \choose 1}{52-2 \choose 4} 110.175.520={13 \choose 1}{4 \choose 1}{52-2 \choose 5} 27.917.689.800={13 \choose 1}{4 \choose 1}{52-2 \choose 10} 15.820.024.220={52 \choose 12} {52-2 \choose 3} 54.912={13 \choose 1}{4 \choose 3}{12 \choose 2}{4 \choose 1}^2 {13 \choose 1}{4 \choose 3}{52-4 \choose 2}=58.656 58.656-3.744=54.912 {13 \choose 1}{4 \choose 3}{52-3 \choose 2}=61.152 61.152-3.744-624=56.784,"['probability', 'combinatorics', 'card-games', 'poker']"
30,Doubt regarding Conditional Expectation,Doubt regarding Conditional Expectation,,"Let $X,Y$ be IID random variable that are uniformly distributed on $[0,1]$ . Does the following equation hold? $$\text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_Y(y)\,\text{d}y$$ This would then imply that $$\text{E}[X\vert X\geq Y] = \int_0^1 \text{E}[X\vert X\geq y]\,\text{d}y$$ where $$f_{X\vert X\geq y}(x) =\begin{cases}\frac{1}{1-y}&y\leq x\leq 1\\0&\text{otherwise} \end{cases}$$ such that $$\text{E}[X\vert X\geq y] = \int_y^1 x\,\frac{1}{1-y}\,\text{d}x = \frac{1+y}{2}$$ Finally, we obtain $$\text{E}[X\vert X\geq Y] = \int_0^1 \frac{1+y}{2}\,\text{d}y = \frac{3}{4}$$ which is not correct. Hence, there must be an error somewhere. I appreciate your help! For completeness, the (presumably) correct solution is given below. $$\text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} x f_{X\vert X\geq Y}(x)\,\text{d}x$$ Using Bayes' rule, we obtain \begin{align} f_{X\vert X\geq Y}(x) &= \frac{\text{Pr}[X\geq Y\vert X = x] f_X(x)}{\text{Pr}[X\geq Y]}\\ &= \frac{\text{Pr}[Y\leq x] f_X(x)}{1/2}\\ &= \begin{cases} 2x& x\in[0,1]\\ 0&\text{otherwise} \end{cases} \end{align} such that $$\text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} x \cdot 2x\,\text{d}x = \frac{2}{3}$$ Answer All credit goes to @Thomas who found the mistake in my initial approach. Thank you @Thomas and thanks to those who added helpful answers or comments. The main issue lies in my very first equation, namely $$\text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_Y(y)\,\text{d}y$$ As @Thomas suggested, the density $f_Y(y)$ should also be conditioned on $X\geq Y$ , that is, $f_{Y\vert X\geq Y}(y)$ . The corrected equation is given as $$\text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_{Y\vert X\geq Y}(y)\,\text{d}y$$ with \begin{align} f_{Y\vert X\geq Y}(y) &= \frac{P(X\geq Y\vert Y = y)f_Y(y)}{P(X\geq Y)}\\ &= \frac{P(X\geq y)f_Y(y)}{P(X\geq Y)}\\ &= \begin{cases} \frac{1-y}{1/2} &0\leq y \leq 1\\ 0 &\text{otherwise} \end{cases}\\ &= \begin{cases} 2(1-y) &0\leq y \leq 1\\ 0 &\text{otherwise} \end{cases} \end{align} This results in the following solution. \begin{align} \text{E}[X\vert X\geq Y] &= \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_{Y\vert X\geq Y}(y)\,\text{d}y\\ &= \int_0^1 \text{E}[X\vert X\geq y]\,2(1-y)\,\text{d}y\\ &= \int_0^1 \frac{1+y}{2}\,2(1-y)\,\text{d}y\\ &= \int_0^1 (1-y^2)\,\text{d}y\\ &= \left[y - \frac{1}{3}\,y^3\right]_0^1\\ &= \frac{2}{3} \end{align} where $\text{E}[X\vert X\geq y] = \frac{1+y}{2}$ follows from the computations above (initial approach).","Let be IID random variable that are uniformly distributed on . Does the following equation hold? This would then imply that where such that Finally, we obtain which is not correct. Hence, there must be an error somewhere. I appreciate your help! For completeness, the (presumably) correct solution is given below. Using Bayes' rule, we obtain such that Answer All credit goes to @Thomas who found the mistake in my initial approach. Thank you @Thomas and thanks to those who added helpful answers or comments. The main issue lies in my very first equation, namely As @Thomas suggested, the density should also be conditioned on , that is, . The corrected equation is given as with This results in the following solution. where follows from the computations above (initial approach).","X,Y [0,1] \text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_Y(y)\,\text{d}y \text{E}[X\vert X\geq Y] = \int_0^1 \text{E}[X\vert X\geq y]\,\text{d}y f_{X\vert X\geq y}(x) =\begin{cases}\frac{1}{1-y}&y\leq x\leq 1\\0&\text{otherwise}
\end{cases} \text{E}[X\vert X\geq y] = \int_y^1 x\,\frac{1}{1-y}\,\text{d}x = \frac{1+y}{2} \text{E}[X\vert X\geq Y] = \int_0^1 \frac{1+y}{2}\,\text{d}y = \frac{3}{4} \text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} x f_{X\vert X\geq Y}(x)\,\text{d}x \begin{align}
f_{X\vert X\geq Y}(x) &= \frac{\text{Pr}[X\geq Y\vert X = x] f_X(x)}{\text{Pr}[X\geq Y]}\\
&= \frac{\text{Pr}[Y\leq x] f_X(x)}{1/2}\\
&= \begin{cases}
2x& x\in[0,1]\\
0&\text{otherwise}
\end{cases}
\end{align} \text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} x \cdot 2x\,\text{d}x = \frac{2}{3} \text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_Y(y)\,\text{d}y f_Y(y) X\geq Y f_{Y\vert X\geq Y}(y) \text{E}[X\vert X\geq Y] = \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_{Y\vert X\geq Y}(y)\,\text{d}y \begin{align}
f_{Y\vert X\geq Y}(y) &= \frac{P(X\geq Y\vert Y = y)f_Y(y)}{P(X\geq Y)}\\
&= \frac{P(X\geq y)f_Y(y)}{P(X\geq Y)}\\
&= \begin{cases}
\frac{1-y}{1/2} &0\leq y \leq 1\\
0 &\text{otherwise}
\end{cases}\\
&= \begin{cases}
2(1-y) &0\leq y \leq 1\\
0 &\text{otherwise}
\end{cases}
\end{align} \begin{align}
\text{E}[X\vert X\geq Y] &= \int_{-\infty}^{\infty} \text{E}[X\vert X\geq y]f_{Y\vert X\geq Y}(y)\,\text{d}y\\
&= \int_0^1 \text{E}[X\vert X\geq y]\,2(1-y)\,\text{d}y\\
&= \int_0^1 \frac{1+y}{2}\,2(1-y)\,\text{d}y\\
&= \int_0^1 (1-y^2)\,\text{d}y\\
&= \left[y - \frac{1}{3}\,y^3\right]_0^1\\
&= \frac{2}{3}
\end{align} \text{E}[X\vert X\geq y] = \frac{1+y}{2}","['probability', 'probability-theory', 'expected-value', 'conditional-probability']"
31,Kelly betting: why do we maximize the expected value of the logarithm of wealth?,Kelly betting: why do we maximize the expected value of the logarithm of wealth?,,"Introduction The Kelly betting criterion is a betting strategy for repeated games of chance which works by wagering a fixed proportion of one's bankroll each time. That is, suppose I play a game of chance where I wager an amount $a$ , win with probability $p$ and payout $(1+b)a$ , and lose with probability $(1-p)$ with payout $0$ . The Kelly betting criteria then advises wagering the proporition $$p+\frac{p-1}{b}$$ of my bankroll at each opportunity, and this formula is derived from maximizing the expected value of the logarithm of wealth. See Wikipedia for more details. Question How do we get to the point of deciding to maximize the expected value of the logarithm of wealth? I'm also interested in why one should choose such a strategy - why should we just bet a fixed amount each time and not adjust our strategy to events as they occur? Work My (probably somewhat nave) attempt at working this out has an error somewhere but I'm not sure where it is. My idea is that if one bets a fixed proportion, one can actually calculate the expected change in bankroll over some fixed term: if we bet a proportion $f$ of our bankroll each time, winning multiplies our stash by $1+bf$ and losing multiplies it by $1-f$ . Starting with, say, one unit of money, and running for $n$ trials, the expected value to finish with is $$2^{-n}\sum_{i=0}^{n} \binom{n}{i} p^i(1-p)^{n-i}(1+bf)^i(1-f)^{n-i}=2^{-n}(1+f(bp+p-1))^n$$ which doesn't maximize at all like the Kelly criteria. What error am I making here?","Introduction The Kelly betting criterion is a betting strategy for repeated games of chance which works by wagering a fixed proportion of one's bankroll each time. That is, suppose I play a game of chance where I wager an amount , win with probability and payout , and lose with probability with payout . The Kelly betting criteria then advises wagering the proporition of my bankroll at each opportunity, and this formula is derived from maximizing the expected value of the logarithm of wealth. See Wikipedia for more details. Question How do we get to the point of deciding to maximize the expected value of the logarithm of wealth? I'm also interested in why one should choose such a strategy - why should we just bet a fixed amount each time and not adjust our strategy to events as they occur? Work My (probably somewhat nave) attempt at working this out has an error somewhere but I'm not sure where it is. My idea is that if one bets a fixed proportion, one can actually calculate the expected change in bankroll over some fixed term: if we bet a proportion of our bankroll each time, winning multiplies our stash by and losing multiplies it by . Starting with, say, one unit of money, and running for trials, the expected value to finish with is which doesn't maximize at all like the Kelly criteria. What error am I making here?",a p (1+b)a (1-p) 0 p+\frac{p-1}{b} f 1+bf 1-f n 2^{-n}\sum_{i=0}^{n} \binom{n}{i} p^i(1-p)^{n-i}(1+bf)^i(1-f)^{n-i}=2^{-n}(1+f(bp+p-1))^n,"['probability', 'gambling']"
32,In what scenarios does one have a closed form equation for the Pearson Correlation - especially s.t. changing parameters changes correlation?,In what scenarios does one have a closed form equation for the Pearson Correlation - especially s.t. changing parameters changes correlation?,,"I want to understand when I can create distributions and random variables (e.g. functions) such that when I change the parameters (or distributions) that specify the distribution (or the parameters of the functions that output random variables) I have changes in the correlation. A closed form equation for the correlation would be really nice for example, so that if I change a parameter of the distribution it's clear the correlation would change. So we have: $$ corr(X,Y) = \mathbb E_{X, Y \sim p(x, y \mid \theta_X, \theta_Y)}[ Z_X Z_Y ]$$ where $Z_X, Z_Y$ are the standardized r.v.s (e.g. $(x - \mu_x) / \sigma_x)$ . My hope is to get conditions for where the above varies smoothly or I can control how it varies based on the functions for the random variables I choose and the distributions I choose. I know that the above integral can be complicated - especially for closed form things based on a question I previously asked that required Lebgegue integration - so this is why I am asking here. It would also be nice to be able to somehow separate the distributions $p(x \mid \theta_X), p(y \mid \theta_Y)$ but have them be correlated e.g. they are both normal with similar means or their support sets are similar...or something. The reason for this is that $X, Y$ are in fact two ""tasks"" that are different but correlated, e.g. classifying handwritten digits vs classifying language characters. The tasks can be sampled separately, but in fact are highly correlated. Thus, in a way you can think of $Z_X, Z_Y$ as a standardized (regression) prediction of a model on two related tasks I suppose. How does one define (adjustable) random variables and distributions such one can vary smoothly the correlation? Current attempt ( inspired from MIT's lecture L12.10 RES.6-012 ): Define $X = Z + X'$ and $Y = Z + Y'$ where $Z, X', Y'$ are independent and centered. The R.Vs are correlated by $Z$ . Thus the correlation (closed form) equation is: $$  corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y} = \frac{\mathbb E[X Y]}{\sigma_X \sigma_Y} = \frac{\sigma^2_Z}{\sigma_X \sigma_Y} = \frac{\sigma^2_Z}{(\sigma_{X'} + \sigma_Z )(\sigma_{Y'} + \sigma_Z)}$$ which makes we wonder if this is really what I am looking for...which feels weird because I am not even ""sampling"" two tasks as I described above. Also, this made me think that whatever distribution and rvs/functions I choose, the values will be wrt their standard deviation. So the closed form equation depends on the standard deviation value that comes form the closed form of the distribution I choose. Similarly, it made me realize that the curcial thing for getting closed form equation is computing the covariance, really in closed form. Or the computing $\mathbb E[Z_X Z_Y]$ (or $\mathbb E[X Y]$ ) - a closed form for an integral/expecation of product of values.","I want to understand when I can create distributions and random variables (e.g. functions) such that when I change the parameters (or distributions) that specify the distribution (or the parameters of the functions that output random variables) I have changes in the correlation. A closed form equation for the correlation would be really nice for example, so that if I change a parameter of the distribution it's clear the correlation would change. So we have: where are the standardized r.v.s (e.g. . My hope is to get conditions for where the above varies smoothly or I can control how it varies based on the functions for the random variables I choose and the distributions I choose. I know that the above integral can be complicated - especially for closed form things based on a question I previously asked that required Lebgegue integration - so this is why I am asking here. It would also be nice to be able to somehow separate the distributions but have them be correlated e.g. they are both normal with similar means or their support sets are similar...or something. The reason for this is that are in fact two ""tasks"" that are different but correlated, e.g. classifying handwritten digits vs classifying language characters. The tasks can be sampled separately, but in fact are highly correlated. Thus, in a way you can think of as a standardized (regression) prediction of a model on two related tasks I suppose. How does one define (adjustable) random variables and distributions such one can vary smoothly the correlation? Current attempt ( inspired from MIT's lecture L12.10 RES.6-012 ): Define and where are independent and centered. The R.Vs are correlated by . Thus the correlation (closed form) equation is: which makes we wonder if this is really what I am looking for...which feels weird because I am not even ""sampling"" two tasks as I described above. Also, this made me think that whatever distribution and rvs/functions I choose, the values will be wrt their standard deviation. So the closed form equation depends on the standard deviation value that comes form the closed form of the distribution I choose. Similarly, it made me realize that the curcial thing for getting closed form equation is computing the covariance, really in closed form. Or the computing (or ) - a closed form for an integral/expecation of product of values."," corr(X,Y) = \mathbb E_{X, Y \sim p(x, y \mid \theta_X, \theta_Y)}[ Z_X Z_Y ] Z_X, Z_Y (x - \mu_x) / \sigma_x) p(x \mid \theta_X), p(y \mid \theta_Y) X, Y Z_X, Z_Y X = Z + X' Y = Z + Y' Z, X', Y' Z   corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y} = \frac{\mathbb E[X Y]}{\sigma_X \sigma_Y} = \frac{\sigma^2_Z}{\sigma_X \sigma_Y} = \frac{\sigma^2_Z}{(\sigma_{X'} + \sigma_Z )(\sigma_{Y'} + \sigma_Z)} \mathbb E[Z_X Z_Y] \mathbb E[X Y]","['probability', 'statistics', 'probability-distributions', 'covariance', 'correlation']"
33,Probability for a random variable to be greater than its mean,Probability for a random variable to be greater than its mean,,"I'm looking for a general lower bound on $\mathbb{P}(X \geq \mathbb{E}(X))$ (or, equivalently, on $\mathbb{P}(X \leq \mathbb{E}(X))$ ). My informal (and naive) reasonning so far I can think of 2 ways to make this probability arbitrarily small: Stacking all the probability mass on a single point -- consider, e.g., $X_\epsilon = \begin{cases} 0 &\text{ w.p. }& 1-\epsilon, \\ 1 &\text{ w.p. }& \epsilon. \end{cases}$ Taking a small amount of probability mass to infinity -- consider, e.g., for a given random variable $Y$ , the random variable $\tilde{Y}_\epsilon$ obtained from $Y$ according to $\tilde{Y}_\epsilon = \begin{cases} Y &\text{ w.p. }& 1-\epsilon, \\ Y + 1/ \epsilon^2 &\text{ w.p. }& \epsilon. \end{cases}$ These examples suggest that the desired lower bound should depend positively on the variance of $X$ (example 1.) and negatively on the ``diameter'' of $X$ (example 2.), that is, $$ \text{diam}(X) = \text{sup}~ ( \text{supp}(X)) - \text{inf}~ ( \text{supp}(X)).$$ (To put it simply, assume that $X \in [a,b]$ almost surely and make the lower bound a function of $b-a$ .) Are you aware of such result? If not, do you think that my hopes are justified, or did I miss a counter-example? Edit: A natural candidate would be $$ \mathbb{P}(X \geq \mathbb{E}(X)) \geq \frac{\text{Var}(X)}{(b-a)^2}. $$ Do you have any specific counter-example for this inequality?","I'm looking for a general lower bound on (or, equivalently, on ). My informal (and naive) reasonning so far I can think of 2 ways to make this probability arbitrarily small: Stacking all the probability mass on a single point -- consider, e.g., Taking a small amount of probability mass to infinity -- consider, e.g., for a given random variable , the random variable obtained from according to These examples suggest that the desired lower bound should depend positively on the variance of (example 1.) and negatively on the ``diameter'' of (example 2.), that is, (To put it simply, assume that almost surely and make the lower bound a function of .) Are you aware of such result? If not, do you think that my hopes are justified, or did I miss a counter-example? Edit: A natural candidate would be Do you have any specific counter-example for this inequality?","\mathbb{P}(X \geq \mathbb{E}(X)) \mathbb{P}(X \leq \mathbb{E}(X)) X_\epsilon = \begin{cases} 0 &\text{ w.p. }& 1-\epsilon, \\ 1 &\text{ w.p. }& \epsilon. \end{cases} Y \tilde{Y}_\epsilon Y \tilde{Y}_\epsilon = \begin{cases} Y &\text{ w.p. }& 1-\epsilon, \\ Y + 1/ \epsilon^2 &\text{ w.p. }& \epsilon. \end{cases} X X  \text{diam}(X) = \text{sup}~ ( \text{supp}(X)) - \text{inf}~ ( \text{supp}(X)). X \in [a,b] b-a  \mathbb{P}(X \geq \mathbb{E}(X)) \geq \frac{\text{Var}(X)}{(b-a)^2}. ","['probability', 'probability-theory', 'expected-value', 'upper-lower-bounds']"
34,Minimize the expected value of the product of 2 normally distributed variables,Minimize the expected value of the product of 2 normally distributed variables,,"So, there are 2 variables, $X$ and $Y$ , both are normally distributed. We are given that $E(X)=E(Y)=0$ and $Var(X)=2$ , while $Var(Y)=8$ . Additionally, $Corr(X,Y)=-\frac{1}{2}$ . The question is to find the smallest value of $E(X^5Y^3)$ . My first instinct was to somehow use the definition of covariance: $$Cov(X^5,Y^3)=E(X^5Y^3)-E(X^5)E(Y^3)$$ $$E(X^5Y^3)=Cov(X^5,Y^3)+E(X^5)E(Y^3)$$ I knew that I could find the $E(Y^3)$ using the moment generating function. Since we are given that $Y\sim N(0,8)$ , the moment generating function is $$M_Y(t)=e^{4t^2}$$ So, $$E(Y^3)=\frac{d^3}{dt^3}M_Y(0)=0\implies E(X^5Y^3)=Cov(X^5,Y^3)$$ The same goes for $E(X^5)=\frac{d^5}{dt^5}M_X(0)=0$ . Another idea is to now play with the definition: $$Cov(X,X^4Y^3)=E(X^5Y^3)-E(X)E(X^4Y^3)=E(X^5Y^3)$$ So that $$Cov(X,X^4Y^3)=Cov(X^5,Y^3)$$ Because we are given the correlation for a reason, I got $Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}=-\frac{1}{2}=\frac{Cov(X,Y)}{4} \implies Cov(X,Y)=-2$ . However, I do not see the connection with my previous result. Perhaps I need to use some different method and not covariance. Can anyone point me in the right direction? $\pmb{Edit:}$ I have used a suspicious formula from the paper by Kan, URL: https://www-2.rotman.utoronto.ca/~kan/papers/moment.pdf on page 5 and got the following result for my particular case: $$E(X^5Y^3)=\frac{45}{128}\sum_{j=0}^{1}{\frac{-1}{(2-j)!(1-j)!(2j+1)!}}=\frac{45}{128}\left(-\frac{1}{2}-\frac{1}{6}\right)=-\frac{15}{64}=-0.234375$$ But this result requires verification. Can anyone tell me if the formula is legit and if yes, then did I use it correctly? $\pmb{Edit\space 2:}$ The question about the formula is resolved. I have also found that $E(X^5Y^3)=5760\sqrt{7}Corr(X^5,Y^3)$ from the definition of correlation coefficient, so the question is: is it possible to minimize the correlation coefficient now?","So, there are 2 variables, and , both are normally distributed. We are given that and , while . Additionally, . The question is to find the smallest value of . My first instinct was to somehow use the definition of covariance: I knew that I could find the using the moment generating function. Since we are given that , the moment generating function is So, The same goes for . Another idea is to now play with the definition: So that Because we are given the correlation for a reason, I got . However, I do not see the connection with my previous result. Perhaps I need to use some different method and not covariance. Can anyone point me in the right direction? I have used a suspicious formula from the paper by Kan, URL: https://www-2.rotman.utoronto.ca/~kan/papers/moment.pdf on page 5 and got the following result for my particular case: But this result requires verification. Can anyone tell me if the formula is legit and if yes, then did I use it correctly? The question about the formula is resolved. I have also found that from the definition of correlation coefficient, so the question is: is it possible to minimize the correlation coefficient now?","X Y E(X)=E(Y)=0 Var(X)=2 Var(Y)=8 Corr(X,Y)=-\frac{1}{2} E(X^5Y^3) Cov(X^5,Y^3)=E(X^5Y^3)-E(X^5)E(Y^3) E(X^5Y^3)=Cov(X^5,Y^3)+E(X^5)E(Y^3) E(Y^3) Y\sim N(0,8) M_Y(t)=e^{4t^2} E(Y^3)=\frac{d^3}{dt^3}M_Y(0)=0\implies E(X^5Y^3)=Cov(X^5,Y^3) E(X^5)=\frac{d^5}{dt^5}M_X(0)=0 Cov(X,X^4Y^3)=E(X^5Y^3)-E(X)E(X^4Y^3)=E(X^5Y^3) Cov(X,X^4Y^3)=Cov(X^5,Y^3) Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}=-\frac{1}{2}=\frac{Cov(X,Y)}{4} \implies Cov(X,Y)=-2 \pmb{Edit:} E(X^5Y^3)=\frac{45}{128}\sum_{j=0}^{1}{\frac{-1}{(2-j)!(1-j)!(2j+1)!}}=\frac{45}{128}\left(-\frac{1}{2}-\frac{1}{6}\right)=-\frac{15}{64}=-0.234375 \pmb{Edit\space 2:} E(X^5Y^3)=5760\sqrt{7}Corr(X^5,Y^3)","['probability', 'optimization', 'normal-distribution', 'expected-value', 'correlation']"
35,Maximize grade in a multiple choice test using probability?,Maximize grade in a multiple choice test using probability?,,"This is a probability problem. Suppose you take a multiple-choice test consisting of $20$ questions whose answers are equally distributed (so, each letter corresponds to $4$ correct answers). Each question has $5$ alternatives, only one of them is correct. Further, in each question you're in equal doubt between the right and a wrong answer (so, the probability of correctly guessing it is $50\%),$ as follows: Is there an optimal choice of answers such that the grade is maximized? I don't really know the answer, but I believe it is affirmative, maybe using conditional probability. Remark. I thought to approach the problem in several steps. In each step, we shall choose the best answer. Step 1: In the first step, we shall compare the probability of getting each alternative right. As to the letter A in this step, the probability of getting it right should be $\frac{4}{6}$ (?), since we know there are 4 right answers between the 6 we choose (we must improve this idea). Here we should take into account the 50% hypothesis (?).  Maybe the probability of getting A right should be smaller, since I can expect to get half of my choices right (?). Maybe the numbers are not correct, I just want to illustrate the idea. Next, we compute the probability of getting B correct, then C, then D and then E. We shall choose the letter more likely to happen. Step 2: In the next step we shall proceed as in the first one, but disregarding the letter we have chosen and disregarding the questions we have answered in the first step. This will change the probabilities. Again we choose the more likely answer. We repeat the process till the last choice is made. In each step, a letter will be chosen and disregarded in the next step, so the procedure will end.","This is a probability problem. Suppose you take a multiple-choice test consisting of questions whose answers are equally distributed (so, each letter corresponds to correct answers). Each question has alternatives, only one of them is correct. Further, in each question you're in equal doubt between the right and a wrong answer (so, the probability of correctly guessing it is as follows: Is there an optimal choice of answers such that the grade is maximized? I don't really know the answer, but I believe it is affirmative, maybe using conditional probability. Remark. I thought to approach the problem in several steps. In each step, we shall choose the best answer. Step 1: In the first step, we shall compare the probability of getting each alternative right. As to the letter A in this step, the probability of getting it right should be (?), since we know there are 4 right answers between the 6 we choose (we must improve this idea). Here we should take into account the 50% hypothesis (?).  Maybe the probability of getting A right should be smaller, since I can expect to get half of my choices right (?). Maybe the numbers are not correct, I just want to illustrate the idea. Next, we compute the probability of getting B correct, then C, then D and then E. We shall choose the letter more likely to happen. Step 2: In the next step we shall proceed as in the first one, but disregarding the letter we have chosen and disregarding the questions we have answered in the first step. This will change the probabilities. Again we choose the more likely answer. We repeat the process till the last choice is made. In each step, a letter will be chosen and disregarded in the next step, so the procedure will end.","20 4 5 50\%), \frac{4}{6}","['probability', 'conditional-probability']"
36,Geometric intuition behind Cauchy not having a mean,Geometric intuition behind Cauchy not having a mean,,"I'm trying to follow the geometric intuition behind the Cauchy distribution in the book ""An introduction to probability theory and its applications"" by Feller volume 2, first edition. On page 51, he describes the density of the Cauchy distribution as: $$\gamma_t = \frac{t}{(t^2+x^2)\pi}$$ He then describes an experiment where a ray of light is emitted horizontally onto a vertical mirror from a source O. The light strikes the mirror at point A and the mirror can rotate about a vertical axis passing through A. This is shown in the figure below. The light reflects off the mirror and strikes the wall O is on at a distance $X$ from O. The first assertion is that if $\phi$ is uniformly distributed between $(-\frac{\pi}{2}, \frac{\pi}{2})$ , $X$ has the density given by $\gamma_t$ . I managed to prove this. Then he says that its apparent that if this experiment is repeated $n$ times and the average taken, then this average $\frac{X_1+X_2+\dots X_n}{n}$ will have the same distribution as $X_1$ . I didn't follow this part. I guess I could derive it from the density, but Feller seems to be hinting at some kind of obvious geometric intuition which I'm completely missing.","I'm trying to follow the geometric intuition behind the Cauchy distribution in the book ""An introduction to probability theory and its applications"" by Feller volume 2, first edition. On page 51, he describes the density of the Cauchy distribution as: He then describes an experiment where a ray of light is emitted horizontally onto a vertical mirror from a source O. The light strikes the mirror at point A and the mirror can rotate about a vertical axis passing through A. This is shown in the figure below. The light reflects off the mirror and strikes the wall O is on at a distance from O. The first assertion is that if is uniformly distributed between , has the density given by . I managed to prove this. Then he says that its apparent that if this experiment is repeated times and the average taken, then this average will have the same distribution as . I didn't follow this part. I guess I could derive it from the density, but Feller seems to be hinting at some kind of obvious geometric intuition which I'm completely missing.","\gamma_t = \frac{t}{(t^2+x^2)\pi} X \phi (-\frac{\pi}{2}, \frac{\pi}{2}) X \gamma_t n \frac{X_1+X_2+\dots X_n}{n} X_1","['probability', 'convergence-divergence']"
37,"Given $n>2$ and $1<k<n$. Is it possible to exist $n$ events(probability>0), s.t. for any $k$ among them are independent while any $k+1$ are not?","Given  and . Is it possible to exist  events(probability>0), s.t. for any  among them are independent while any  are not?",n>2 1<k<n n k k+1,"For example when $k=2$ , consider $n+1$ disjoint events : $E=\{ e_0,e_1,...,e_n\}$ with the probability that $P(e_0)=a,P(e_i)=b,1\leq i\leq n.$ We define $n$ events $E_1,E_2,...,E_n$ such that $E_i=\{e_0\} \cup\{ e_i \}$ .For any $1\leq i<j<k\leq n$ we obtain: $P(E_i)P(E_j)P(E_k)=(a+b)^3,P(E_i)P(E_j)=(a+b)^2,P(E_i \cap E_j)=a,P(E_i\cap E_j\cap E_k)=a.$ We can easily prove the existence of  (a,b) satisfying $(a+b)^2=a,0<a,b<1,a+nb<1$ for any given n, which means that for any $2$ events are independent while any $3$ are not. So a more genreal question is that given $n>2$ and $1<k<n$ . Is it possible to exist $n$ events, s.t. for any $k$ among them are independent while any $k+1$ are not? Beased the proof above, we know that k=2 is OK.","For example when , consider disjoint events : with the probability that We define events such that .For any we obtain: We can easily prove the existence of  (a,b) satisfying for any given n, which means that for any events are independent while any are not. So a more genreal question is that given and . Is it possible to exist events, s.t. for any among them are independent while any are not? Beased the proof above, we know that k=2 is OK.","k=2 n+1 E=\{ e_0,e_1,...,e_n\} P(e_0)=a,P(e_i)=b,1\leq i\leq n. n E_1,E_2,...,E_n E_i=\{e_0\} \cup\{ e_i \} 1\leq i<j<k\leq n P(E_i)P(E_j)P(E_k)=(a+b)^3,P(E_i)P(E_j)=(a+b)^2,P(E_i \cap E_j)=a,P(E_i\cap E_j\cap E_k)=a. (a+b)^2=a,0<a,b<1,a+nb<1 2 3 n>2 1<k<n n k k+1","['probability', 'probability-theory', 'discrete-mathematics', 'elementary-set-theory']"
38,Combinatorics question: N people selecting k objects (without replacement) from field of K total objects. Odds all objects are selected?,Combinatorics question: N people selecting k objects (without replacement) from field of K total objects. Odds all objects are selected?,,"Title is a bit verbose so here's a scenario: Suppose 4 friends go out to a restaurant, and each of them will order 3 items from a total list of 9 items. Each item ordered by a single person is different. If each person's selection of items is completely random, what is the probability that between the 4 friends, all 9 items on the menu are sampled at least once? This type of problem would be simmed pretty easily, but I am very interested in the theoretical method that would be used to arrive at the answer. Here's what I think so far: If each person has (9 choose 3) item combinations (orders), then the total number of order combinations should be ((9 choose 3) ^ 4) / (4!) (since we don't care about who orders what, just that all items are covered). So all that's left is to quantify those order combinations in which every item is covered, and then divide by that total. However, this is where I'm stuck. It has occurred to me that one way to solve this would be to just add up all of the possible ways for the scenario to succeed. If the items are numbered 1-9 and each {} represents an order, this would look like: P({1,2,3}, {1,2,3}, {4,5,6}, {7,8,9}) + P({1,2,3},{3,4,5},{5,6,7},{7,8,9}) + ... But that type of breakdown seems like a nightmare especially at higher numbers. It feels like there should be a way to make clever use of a choose function for a relatively neat solution. Thanks for taking the time to read this, and I appreciate any help that may be offered toward finding a solution. Edit: After mulling this over, I think this can actually be solved with just straight probability without even worrying about the # of combinations. The probability that all items are covered would be 1 - the sum of 1 item, 2 items... 6 items not covered = 1 - Sum(i = 1 to i = 6) {((9-i) (8-i) (7-i)/(9x8x7))^4}. Doing that yields 76.8909%, which seems like a reasonable outcome (I haven't checked this for correctness). Even if the above approach works, I would be interested in knowing if there are any clever ways to quantify the number of combinations where every item is covered. Thanks!","Title is a bit verbose so here's a scenario: Suppose 4 friends go out to a restaurant, and each of them will order 3 items from a total list of 9 items. Each item ordered by a single person is different. If each person's selection of items is completely random, what is the probability that between the 4 friends, all 9 items on the menu are sampled at least once? This type of problem would be simmed pretty easily, but I am very interested in the theoretical method that would be used to arrive at the answer. Here's what I think so far: If each person has (9 choose 3) item combinations (orders), then the total number of order combinations should be ((9 choose 3) ^ 4) / (4!) (since we don't care about who orders what, just that all items are covered). So all that's left is to quantify those order combinations in which every item is covered, and then divide by that total. However, this is where I'm stuck. It has occurred to me that one way to solve this would be to just add up all of the possible ways for the scenario to succeed. If the items are numbered 1-9 and each {} represents an order, this would look like: P({1,2,3}, {1,2,3}, {4,5,6}, {7,8,9}) + P({1,2,3},{3,4,5},{5,6,7},{7,8,9}) + ... But that type of breakdown seems like a nightmare especially at higher numbers. It feels like there should be a way to make clever use of a choose function for a relatively neat solution. Thanks for taking the time to read this, and I appreciate any help that may be offered toward finding a solution. Edit: After mulling this over, I think this can actually be solved with just straight probability without even worrying about the # of combinations. The probability that all items are covered would be 1 - the sum of 1 item, 2 items... 6 items not covered = 1 - Sum(i = 1 to i = 6) {((9-i) (8-i) (7-i)/(9x8x7))^4}. Doing that yields 76.8909%, which seems like a reasonable outcome (I haven't checked this for correctness). Even if the above approach works, I would be interested in knowing if there are any clever ways to quantify the number of combinations where every item is covered. Thanks!",,"['probability', 'combinatorics']"
39,What is $p$-value? [duplicate],What is -value? [duplicate],p,"This question already has answers here : Understanding the P-value (5 answers) Closed 2 years ago . Tell me about this $p$ -value in relatively simple but not too simple terms. I've been reading many academic publications of late and come across it quite a few times without having a clear idea what it means. It's something about probability, isn't it? If it's less than, I believe, $0.05$ , then it's, whatever it is, not a simple coincidence but a real correlation, right?","This question already has answers here : Understanding the P-value (5 answers) Closed 2 years ago . Tell me about this -value in relatively simple but not too simple terms. I've been reading many academic publications of late and come across it quite a few times without having a clear idea what it means. It's something about probability, isn't it? If it's less than, I believe, , then it's, whatever it is, not a simple coincidence but a real correlation, right?",p 0.05,"['probability', 'p-value']"
40,Directly Computing Posterior Distribution for Gaussian Likelihood and Prior,Directly Computing Posterior Distribution for Gaussian Likelihood and Prior,,"my first question so apologies in advance. I'm currently studying posterior distributions and for practice sake I'm trying to directly compute the posterior distribution for the mean of a normal random variable (unit variance) with standard normal prior. I'm trying to validate if this is correct (note that this is for observing ONE new data point). The posterior distribution is defined as $$p(\theta\mid x)=\frac{p(x\mid\theta)p(\theta)}{\int_\theta p(x\mid\theta) p(\theta) \, d\theta}$$ and I am getting $$p(\theta\mid x)=\frac{1}{\sqrt{\pi}}e^{-\frac{1}{4}x^2+x\theta-\theta^2}$$ I did a couple sanity checks, $$\int_{-\infty}^\infty p(\theta\mid X=0)\,d\theta=\int_{-\infty}^\infty \frac{1}{\sqrt{\pi}} e^{-\theta^2} \, d\theta=1$$ $$\int_{-\infty}^\infty p(\theta\mid X=2) \, d\theta=\int_{-\infty}^\infty \frac{1}{\sqrt{\pi}} e^{-1+2\theta-\theta^2} \, d\theta=1$$ Is this the correct analytical solution? My derivation is as follows: $$\text{Let } X \sim N(\theta,1)$$ $$\text{Let } \theta \sim N(0,1)$$ The likelihood (dependent on theta): $$p(x\mid\theta)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(x-\theta)^2}$$ The prior: $$p(\theta)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}\theta^2}$$ The joint density: $$p(x\mid\theta)p(\theta)=\frac{1}{2\pi}e^{-\frac{1}{2}(x-\theta)^2}e^{-\frac{1}{2}\theta^2}$$ $$=\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\frac{1}{2}\theta^2}e^{-\frac{1}{2}\theta^2}$$ $$=\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2}$$ sanity check : $$\int_{-\infty}^\infty \int_{-\infty}^\infty \frac{1}{2\pi}e^{-\frac{1}{2} x^2 + x\theta-\theta^2} \, dx \, d\theta=1$$ The marginal: $$p(x)=\int_\theta p(x\mid\theta)p(\theta) \, d\theta$$ $$=\frac{1}{2\pi}e^{-\frac{1}{2}x^2} \int_{-\infty}^\infty e^{-\theta^2+\theta x} \, d\theta$$ $$=\frac{1}{2\pi}e^{-\frac{1}{2}x^2}\Biggl[\sqrt{\pi}e^{\frac{1}{4}x^2}\Biggl] \text{by Gaussian integral}$$ $$=\frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2}$$ sanity check: $$\int_{-\infty}^\infty \frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2} \, dx=1$$ The posterior: $$p(\theta\mid x)=\frac{p(x\mid\theta)p(\theta)}{\int_\theta p(x\mid \theta) p(\theta) \, d\theta} = \frac{\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2}}{\frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2}}$$ $$=\frac{\sqrt{\pi}}{\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2+\frac{1}{4}x^2}$$ $$=\frac{1}{\sqrt{\pi}}e^{-\frac{1}{4}x^2+x\theta-\theta^2}$$","my first question so apologies in advance. I'm currently studying posterior distributions and for practice sake I'm trying to directly compute the posterior distribution for the mean of a normal random variable (unit variance) with standard normal prior. I'm trying to validate if this is correct (note that this is for observing ONE new data point). The posterior distribution is defined as and I am getting I did a couple sanity checks, Is this the correct analytical solution? My derivation is as follows: The likelihood (dependent on theta): The prior: The joint density: sanity check : The marginal: sanity check: The posterior:","p(\theta\mid x)=\frac{p(x\mid\theta)p(\theta)}{\int_\theta p(x\mid\theta) p(\theta) \, d\theta} p(\theta\mid x)=\frac{1}{\sqrt{\pi}}e^{-\frac{1}{4}x^2+x\theta-\theta^2} \int_{-\infty}^\infty p(\theta\mid X=0)\,d\theta=\int_{-\infty}^\infty \frac{1}{\sqrt{\pi}} e^{-\theta^2} \, d\theta=1 \int_{-\infty}^\infty p(\theta\mid X=2) \, d\theta=\int_{-\infty}^\infty \frac{1}{\sqrt{\pi}} e^{-1+2\theta-\theta^2} \, d\theta=1 \text{Let } X \sim N(\theta,1) \text{Let } \theta \sim N(0,1) p(x\mid\theta)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(x-\theta)^2} p(\theta)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}\theta^2} p(x\mid\theta)p(\theta)=\frac{1}{2\pi}e^{-\frac{1}{2}(x-\theta)^2}e^{-\frac{1}{2}\theta^2} =\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\frac{1}{2}\theta^2}e^{-\frac{1}{2}\theta^2} =\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2} \int_{-\infty}^\infty \int_{-\infty}^\infty \frac{1}{2\pi}e^{-\frac{1}{2} x^2 + x\theta-\theta^2} \, dx \, d\theta=1 p(x)=\int_\theta p(x\mid\theta)p(\theta) \, d\theta =\frac{1}{2\pi}e^{-\frac{1}{2}x^2} \int_{-\infty}^\infty e^{-\theta^2+\theta x} \, d\theta =\frac{1}{2\pi}e^{-\frac{1}{2}x^2}\Biggl[\sqrt{\pi}e^{\frac{1}{4}x^2}\Biggl] \text{by Gaussian integral} =\frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2} \int_{-\infty}^\infty \frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2} \, dx=1 p(\theta\mid x)=\frac{p(x\mid\theta)p(\theta)}{\int_\theta p(x\mid \theta) p(\theta) \, d\theta} = \frac{\frac{1}{2\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2}}{\frac{1}{2\sqrt{\pi}}e^{-\frac{1}{4}x^2}} =\frac{\sqrt{\pi}}{\pi}e^{-\frac{1}{2}x^2+x\theta-\theta^2+\frac{1}{4}x^2} =\frac{1}{\sqrt{\pi}}e^{-\frac{1}{4}x^2+x\theta-\theta^2}","['probability', 'statistics', 'bayesian']"
41,Haar measure of the orthogonal group and Lie algebra,Haar measure of the orthogonal group and Lie algebra,,"I am looking to find the expression of the Haar measure of the $SO(3)$ group as a function of the Lie algebra basis $$ R(x,y,z) = \text{exp}\left( x L_x + yL_y + zL_z \right) $$ where $L_x, L_y, L_z$ is the usual basis of antisymmetric matrices. In other words, what is the function $f(x,y,z)$ such that $d\mu(R) = f(x,y,z)dxdydz$ ?","I am looking to find the expression of the Haar measure of the group as a function of the Lie algebra basis where is the usual basis of antisymmetric matrices. In other words, what is the function such that ?","SO(3) 
R(x,y,z) = \text{exp}\left( x L_x + yL_y + zL_z \right)
 L_x, L_y, L_z f(x,y,z) d\mu(R) = f(x,y,z)dxdydz","['probability', 'group-theory', 'measure-theory', 'differential-geometry', 'haar-measure']"
42,"$X:= \sum_{j=1}^Z Z_j$, where $Z \sim$ Po$(\gamma)$ and $Z_j$'s are independent",", where  Po and 's are independent",X:= \sum_{j=1}^Z Z_j Z \sim (\gamma) Z_j,"Let $m\in \mathbb N$ and suppose that $Z_n, n\in \mathbb N$ , is a sequence of independent random vectors in $\mathbb R^m$ with common distribution $\mathbb P(Z_1 = e_i) = p_i, i\in \{ 1,...,m\}$ , where $e_i$ is the $i-$ th unit vector in $\mathbb R^m$ and $p_1+ \cdots+ p_m = 1$ . Let $Z \sim$ Po $(\gamma)$ , independent of $(Z_1, Z_2,...).$ Show that the components of the random vector $X := \sum_{j=1}^Z Z_j$ are independent and Poisson distributed with parameters $p_1\gamma, ..., p_m \gamma$ . This can be proved if we show that $$\mathbb P(X_1 = k_1, ... , X_n = k_n) = \prod_{j=1}^n \mathbb P(X_j = k_j) = \prod_{j=1}^n \text{Po}(k_j; p_i \gamma).$$ How to prove the above equation? Is there any other easy way to prove the statement? Can we argue that the components of $X$ are indepedent by that $Z_n, n\in \mathbb N$ , is a sequence of independent random vectors?","Let and suppose that , is a sequence of independent random vectors in with common distribution , where is the th unit vector in and . Let Po , independent of Show that the components of the random vector are independent and Poisson distributed with parameters . This can be proved if we show that How to prove the above equation? Is there any other easy way to prove the statement? Can we argue that the components of are indepedent by that , is a sequence of independent random vectors?","m\in \mathbb N Z_n, n\in \mathbb N \mathbb R^m \mathbb P(Z_1 = e_i) = p_i, i\in \{ 1,...,m\} e_i i- \mathbb R^m p_1+ \cdots+ p_m = 1 Z \sim (\gamma) (Z_1, Z_2,...). X := \sum_{j=1}^Z Z_j p_1\gamma, ..., p_m \gamma \mathbb P(X_1 = k_1, ... , X_n = k_n) = \prod_{j=1}^n \mathbb P(X_j = k_j) = \prod_{j=1}^n \text{Po}(k_j; p_i \gamma). X Z_n, n\in \mathbb N","['probability', 'probability-theory', 'poisson-distribution']"
43,A drunkard flipping switches in a dark room,A drunkard flipping switches in a dark room,,"There are $n$ switches in a dark room controlling a single light; all the switches must be on for the light to be on. Initially all the switches are off. A drunkard left in the room wakes up from a hangover and repeatedly picks a switch uniformly at random and flips it. What is the expected number of flips the drunkard takes to turn on the light ? I answered the $n=4$ case here , but the weird result of $\frac{64}3$ enticed me to generalise the problem, for which I have rewritten the setting. If $E_k$ is the expected number of flips needed with $k$ switches on, the $E_k$ satisfy the following tridiagonal system: $$\begin{bmatrix}1&-1&0&\dots&0&0\\-\frac1n&1&\frac1n-1&\dots&0&0\\0&-\frac2n&1&\dots&0&0\\\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\0&0&0&\dots&1&-\frac2n\\0&0&0&\dots&\frac1n-1&1\end{bmatrix}\begin{bmatrix}E_0\\E_1\\E_2\\\vdots\\E_{n-2}\\E_{n-1}\end{bmatrix}=\begin{bmatrix}1\\1\\1\\\vdots\\1\\1\end{bmatrix}$$ The $(i,j)$ entry of the square matrix is $1$ if $i=j$ , $-\frac jn$ if $i=j+1$ , $\frac{i-1}n-1$ if $i=j-1$ and $0$ otherwise. The answer to the problem proper is then $E_0$ , the first few values of which are (starting from $n=1$ ) $$1,4,10,\frac{64}3,\frac{128}3,\frac{416}5,\frac{2416}{15},\frac{32768}{105},\frac{21248}{35},\frac{74752}{63}$$ After nosing around and actually solving the tridiagonal system using a dedicated algorithm I found a formula for $E_0$ at any $n$ : $$E_0(n)=2^{n-1}F(n-1)\text{ where }F(n)=\sum_{k=0}^n\frac1{\binom nk}\tag1$$ Now $F$ has been discussed at length on this site, including here , here and here , and is A048625 / A048626 in the OEIS. Hence the generating function for $E_0$ may be obtained: $$\sum_{n=0}^\infty E_0(n)z^n=z\left(\frac{\log(1-2z)}{2(z-1)}\right)'$$ The appearance of $F(n)$ was a pleasant surprise for me, and now I have no proof because this was all numerical experimentation. How can $(1)$ be proved? I found $(1)$ by tracing the variables in the tridiagonal matrix algorithm applied to the above square matrix turned upside-down. I found that at the end (using the notation on Wikipedia) $d_n=2^{n-1}$ and $b_n=\frac1{F(n-1)}$ , but trying to expand everything symbolically only produces a huge tree of fractions.","There are switches in a dark room controlling a single light; all the switches must be on for the light to be on. Initially all the switches are off. A drunkard left in the room wakes up from a hangover and repeatedly picks a switch uniformly at random and flips it. What is the expected number of flips the drunkard takes to turn on the light ? I answered the case here , but the weird result of enticed me to generalise the problem, for which I have rewritten the setting. If is the expected number of flips needed with switches on, the satisfy the following tridiagonal system: The entry of the square matrix is if , if , if and otherwise. The answer to the problem proper is then , the first few values of which are (starting from ) After nosing around and actually solving the tridiagonal system using a dedicated algorithm I found a formula for at any : Now has been discussed at length on this site, including here , here and here , and is A048625 / A048626 in the OEIS. Hence the generating function for may be obtained: The appearance of was a pleasant surprise for me, and now I have no proof because this was all numerical experimentation. How can be proved? I found by tracing the variables in the tridiagonal matrix algorithm applied to the above square matrix turned upside-down. I found that at the end (using the notation on Wikipedia) and , but trying to expand everything symbolically only produces a huge tree of fractions.","n n=4 \frac{64}3 E_k k E_k \begin{bmatrix}1&-1&0&\dots&0&0\\-\frac1n&1&\frac1n-1&\dots&0&0\\0&-\frac2n&1&\dots&0&0\\\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\0&0&0&\dots&1&-\frac2n\\0&0&0&\dots&\frac1n-1&1\end{bmatrix}\begin{bmatrix}E_0\\E_1\\E_2\\\vdots\\E_{n-2}\\E_{n-1}\end{bmatrix}=\begin{bmatrix}1\\1\\1\\\vdots\\1\\1\end{bmatrix} (i,j) 1 i=j -\frac jn i=j+1 \frac{i-1}n-1 i=j-1 0 E_0 n=1 1,4,10,\frac{64}3,\frac{128}3,\frac{416}5,\frac{2416}{15},\frac{32768}{105},\frac{21248}{35},\frac{74752}{63} E_0 n E_0(n)=2^{n-1}F(n-1)\text{ where }F(n)=\sum_{k=0}^n\frac1{\binom nk}\tag1 F E_0 \sum_{n=0}^\infty E_0(n)z^n=z\left(\frac{\log(1-2z)}{2(z-1)}\right)' F(n) (1) (1) d_n=2^{n-1} b_n=\frac1{F(n-1)}","['probability', 'summation', 'binomial-coefficients', 'expected-value', 'random-walk']"
44,How to prove the variance of this function of a normal random variable is decreasing?,How to prove the variance of this function of a normal random variable is decreasing?,,"Partial answers found here and here . Suppose $\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$ and $\Phi(x)=\int_{-\infty}^x\phi(t)dt=\frac{1}2 \text{Erfc}[-\frac{x}{\sqrt{2}}]$ where Erfc is the complementary error function. These are the density and distribution function of a standard normal random variable. Define the function $g(\mu)=\int_{-\infty}^{\infty}\Phi(x) \phi(x-\mu)dx$ . $g(\mu)$ is the expected value of $\Phi(X)$ when $X$ has a normal distribution with mean $\mu$ and variance 1. Differentiate under the integral to observe that $$g'(\mu)=\int_{-\infty}^{\infty}\Phi(x)(x-\mu) \phi(x-\mu)dx=\frac{\phi\left(\frac{\mu}{\sqrt{2}}\right)}{\sqrt{2}}$$ Since $g'(\mu)$ is always positive, $g(\mu)$ is an increasing function. Furthermore, define the function $h(\mu)=\int_{-\infty}^{\infty}(\Phi(x)-g(\mu))^2 \phi(x-\mu)dx$ . $h(\mu)$ is the variance of $\Phi(X)$ when $X$ has a normal distribution with mean $\mu$ and variance 1. I can shown that: $h(0)=\frac{1}{12}$ $h'(0)=0$ $h''(0)=-\frac{1}{2 \pi}+\frac{1}{2 \sqrt{3}\pi} \approx -0.06727$ $\lim_{\mu\rightarrow \infty}h(\mu)=0$ $h(\mu)=h(-\mu)$ so that $h$ is an even function. I can draw $h(x)$ for $x \in [0,4]$ I can also find all the terms of the Taylor series for $h(\mu)$ at $\mu=0$ . But, I cannot show the derivative is never $0$ for $\mu \ne 0$ . Is it possible to prove that $h(\mu)$ is decreasing for $\mu>0$ ?","Partial answers found here and here . Suppose and where Erfc is the complementary error function. These are the density and distribution function of a standard normal random variable. Define the function . is the expected value of when has a normal distribution with mean and variance 1. Differentiate under the integral to observe that Since is always positive, is an increasing function. Furthermore, define the function . is the variance of when has a normal distribution with mean and variance 1. I can shown that: so that is an even function. I can draw for I can also find all the terms of the Taylor series for at . But, I cannot show the derivative is never for . Is it possible to prove that is decreasing for ?","\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \Phi(x)=\int_{-\infty}^x\phi(t)dt=\frac{1}2 \text{Erfc}[-\frac{x}{\sqrt{2}}] g(\mu)=\int_{-\infty}^{\infty}\Phi(x) \phi(x-\mu)dx g(\mu) \Phi(X) X \mu g'(\mu)=\int_{-\infty}^{\infty}\Phi(x)(x-\mu) \phi(x-\mu)dx=\frac{\phi\left(\frac{\mu}{\sqrt{2}}\right)}{\sqrt{2}} g'(\mu) g(\mu) h(\mu)=\int_{-\infty}^{\infty}(\Phi(x)-g(\mu))^2 \phi(x-\mu)dx h(\mu) \Phi(X) X \mu h(0)=\frac{1}{12} h'(0)=0 h''(0)=-\frac{1}{2 \pi}+\frac{1}{2 \sqrt{3}\pi} \approx -0.06727 \lim_{\mu\rightarrow \infty}h(\mu)=0 h(\mu)=h(-\mu) h h(x) x \in [0,4] h(\mu) \mu=0 0 \mu \ne 0 h(\mu) \mu>0","['calculus', 'probability', 'integration', 'derivatives', 'normal-distribution']"
45,Deadly disease and probability to die,Deadly disease and probability to die,,"NHS records show that of patients suffering from a certain disease, 75% die of it. In a specific hospital, there are 100 patients. What is the probability that 25 to 65 will die? Clearly this is an example of use of binomial distribution. I don't know, however, how to deal with the range 25 to 65. If the question was for exactly 25 patients to die, it would be $P = \binom {100}{25}0.75^{25}.0.25^{75}$ but I don't know how to take into account the range. Thank you.","NHS records show that of patients suffering from a certain disease, 75% die of it. In a specific hospital, there are 100 patients. What is the probability that 25 to 65 will die? Clearly this is an example of use of binomial distribution. I don't know, however, how to deal with the range 25 to 65. If the question was for exactly 25 patients to die, it would be but I don't know how to take into account the range. Thank you.",P = \binom {100}{25}0.75^{25}.0.25^{75},"['probability', 'combinatorics']"
46,"We throw 2 fair dice together 6 times. What is the probability of getting 3 ""doubles"", i.e. 3 times the same number in both dice?","We throw 2 fair dice together 6 times. What is the probability of getting 3 ""doubles"", i.e. 3 times the same number in both dice?",,"We throw 2 fair dice together 6 times. What is the probability of getting 3 ""doubles"", i.e. 3 times the same number in both dice? My attempt: For the first draw of 2 dice together, the sample space has 36 possible outcomes and the ones with the same number in both dice are $(1,1), (2,2)...(6,6)$ so a total of 6. The probability for one throw is $P_1 = \frac {6}{36} = \frac {1}{6}$ Therefore for 2 such throws, the probability to get doubles is $(\frac {1}{6})^2$ . The probability to get doubles in 3 out of 6 throws is $(\frac {1}{6})^3*(\frac {5}{6})^3$ ?? Is this correct? or maybe $\frac {6^3}{36^6}$ ? Thank you!","We throw 2 fair dice together 6 times. What is the probability of getting 3 ""doubles"", i.e. 3 times the same number in both dice? My attempt: For the first draw of 2 dice together, the sample space has 36 possible outcomes and the ones with the same number in both dice are so a total of 6. The probability for one throw is Therefore for 2 such throws, the probability to get doubles is . The probability to get doubles in 3 out of 6 throws is ?? Is this correct? or maybe ? Thank you!","(1,1), (2,2)...(6,6) P_1 = \frac {6}{36} = \frac {1}{6} (\frac {1}{6})^2 (\frac {1}{6})^3*(\frac {5}{6})^3 \frac {6^3}{36^6}","['probability', 'combinatorics']"
47,Random Walk Probability in a Circle,Random Walk Probability in a Circle,,"Consider a circular arrangement of 8 people as shown below: Let's say person 1 has a candy which is passed around with equal probability either to the left or right. All the other people do the same. a) Find the probability that the person 3 gets the candy before person 6. b) Find the expected number of times the candy will be passed before the person 5 gets it for the first time. For a) I could just break the circle between 3 and 4 and consider them siting in a straight line as, $3\hspace{10pt}2\hspace{10pt}1\hspace{10pt}8\hspace{10pt}7\hspace{10pt}6$ Now how do I go about calculating the probability? Do I take different cases? I think using conditional probability I could get some recurrence relation. Not sure how to go about b). Any help is appreciated. Thanks!","Consider a circular arrangement of 8 people as shown below: Let's say person 1 has a candy which is passed around with equal probability either to the left or right. All the other people do the same. a) Find the probability that the person 3 gets the candy before person 6. b) Find the expected number of times the candy will be passed before the person 5 gets it for the first time. For a) I could just break the circle between 3 and 4 and consider them siting in a straight line as, Now how do I go about calculating the probability? Do I take different cases? I think using conditional probability I could get some recurrence relation. Not sure how to go about b). Any help is appreciated. Thanks!",3\hspace{10pt}2\hspace{10pt}1\hspace{10pt}8\hspace{10pt}7\hspace{10pt}6,"['probability', 'random-walk']"
48,Expected number of coin tosses until $HH$ in a row,Expected number of coin tosses until  in a row,HH,"I was asked the following problem: Given a coin with $\displaystyle P( H) =p,\ P( T) =1-p$ , what is the expected number of tosses until we receive two $\displaystyle H$ in a row? I may use the fact that the expected number of tosses until the first $\displaystyle H$ is $\displaystyle \frac{1}{p}$ . My solution: Let's denote $\displaystyle X_{2} =number\ of\ tosses\ until\ HH\ ( including\ the\ HH)$ . We want to find $\displaystyle E[ X_{2}]$ . At the same time, let's denote $\displaystyle X_{1} =number\ of\ tosses\ until\ H\ ( including\ H)$ . From the given we know that $\displaystyle E[ X_{1}] =\frac{1}{p}$ . Let's now try to simplify the expression $\displaystyle E[ X_{2}]$ with the Law of Total Probability. Let's denote two events: $\displaystyle A=after\ the\ 1^{st} \ H\ appears,\ the\ next\ toss\ is\ an\ H$ . $\displaystyle A^{c} =after\ the\ 1^{st} \ H\ appears,\ the\ next\ toss\ is\ a\ T$ . Let's also assume that the number of tosses until the first $\displaystyle H$ is some number $\displaystyle r$ . Since every toss is independent from each other, we know that $\displaystyle P( A) =P( H) =p$ . At the same, from the same reason, we will get $\displaystyle P\left( A^{c}\right) =P( T) =1-p$ . From the \ Law of Total Probability then, we can define: $\displaystyle E[ X_{2}] =P( A) \cdotp E[ X|A] +P\left( A^{c}\right) \cdotp E\left[ X|A^{c}\right]$ . $\displaystyle =p\cdotp E[ X|A] +( 1-p) \cdotp E\left[ X|A^{c}\right]$ . But,  $\displaystyle E[ X|A]$ = the expected number of tosses until the first HH, if we know that we had exactly $\displaystyle r$ tosses until the first $\displaystyle H$ , and after that we had an $\displaystyle H$ . Basically, this means we received $\displaystyle HH$ consecutively for the first time! So we will stop tossing here. The number of tosses, in this case, will be is $\displaystyle r+1$ . We know the expected value of $\displaystyle r$ is $\displaystyle E[ X_{1}] =\frac{1}{p}$ . So: $\displaystyle E[ X|A] =\frac{1}{p} +1$ .  $\displaystyle E\left[ X|A^{c}\right]$ = the expected number of tosses, if we know that we had exaclty $\displaystyle r$ tosses until the first $\displaystyle H$ , and after that we had a $\displaystyle T$ . Also, in this case, we tossed the coin $\displaystyle r+1$ times, but we won't be stopping, since we didn't achieve the $\displaystyle HH$ consecutively. The opposite, we are left facing the same problem recursively. Each toss is independent from the previous one, so after the $\displaystyle r+1$ , we have to ""start over"", and have again $\displaystyle E[ X_{2}]$ expected tosses. So: $\displaystyle E\left[ X|A^{c}\right] =\frac{1}{p} +1+E[ X_{2}]$ . Overall plugging into our initial equation we get: $\displaystyle  \begin{array}{{>{\displaystyle}l}} E[ X_{2}] =p\cdotp \left(\frac{1}{p} +1\right) +( 1-p) \cdotp \left(\frac{1}{p} +1+E[ X_{2}]\right)\\ =1+p+\frac{1}{p} +1+E[ X_{2}] -1-p\cdotp E[ X_{2}]\\ \Rightarrow \\ p\cdotp E[ X_{2}] =\frac{1}{p} +1\\ \Rightarrow \\ E[ X_{2}] =\frac{1+p}{p^{2}} . \end{array}$ I'm confident this solution is correct, by looking at this other question: Expected value of number of trials to get k SUCCESSIVE successes . I basically plugged in my numbers into their solution. Despite this, they used a different method it seems in the first passage, which I don't really understand where it's derived. At the same time, I feel like my answers use a lot of words especially for the cases of $\displaystyle E[ X|A] ,\ E\left[ X|A^{c}\right]$ . I hoped to have some formula to use instead of having to explain the solution ""logically"". Any advice?","I was asked the following problem: Given a coin with , what is the expected number of tosses until we receive two in a row? I may use the fact that the expected number of tosses until the first is . My solution: Let's denote . We want to find . At the same time, let's denote . From the given we know that . Let's now try to simplify the expression with the Law of Total Probability. Let's denote two events: . . Let's also assume that the number of tosses until the first is some number . Since every toss is independent from each other, we know that . At the same, from the same reason, we will get . From the \ Law of Total Probability then, we can define: . . But,  = the expected number of tosses until the first HH, if we know that we had exactly tosses until the first , and after that we had an . Basically, this means we received consecutively for the first time! So we will stop tossing here. The number of tosses, in this case, will be is . We know the expected value of is . So: .  = the expected number of tosses, if we know that we had exaclty tosses until the first , and after that we had a . Also, in this case, we tossed the coin times, but we won't be stopping, since we didn't achieve the consecutively. The opposite, we are left facing the same problem recursively. Each toss is independent from the previous one, so after the , we have to ""start over"", and have again expected tosses. So: . Overall plugging into our initial equation we get: I'm confident this solution is correct, by looking at this other question: Expected value of number of trials to get k SUCCESSIVE successes . I basically plugged in my numbers into their solution. Despite this, they used a different method it seems in the first passage, which I don't really understand where it's derived. At the same time, I feel like my answers use a lot of words especially for the cases of . I hoped to have some formula to use instead of having to explain the solution ""logically"". Any advice?","\displaystyle P( H) =p,\ P( T) =1-p \displaystyle H \displaystyle H \displaystyle \frac{1}{p} \displaystyle X_{2} =number\ of\ tosses\ until\ HH\ ( including\ the\ HH) \displaystyle E[ X_{2}] \displaystyle X_{1} =number\ of\ tosses\ until\ H\ ( including\ H) \displaystyle E[ X_{1}] =\frac{1}{p} \displaystyle E[ X_{2}] \displaystyle A=after\ the\ 1^{st} \ H\ appears,\ the\ next\ toss\ is\ an\ H \displaystyle A^{c} =after\ the\ 1^{st} \ H\ appears,\ the\ next\ toss\ is\ a\ T \displaystyle H \displaystyle r \displaystyle P( A) =P( H) =p \displaystyle P\left( A^{c}\right) =P( T) =1-p \displaystyle E[ X_{2}] =P( A) \cdotp E[ X|A] +P\left( A^{c}\right) \cdotp E\left[ X|A^{c}\right] \displaystyle =p\cdotp E[ X|A] +( 1-p) \cdotp E\left[ X|A^{c}\right] \displaystyle E[ X|A] \displaystyle r \displaystyle H \displaystyle H \displaystyle HH \displaystyle r+1 \displaystyle r \displaystyle E[ X_{1}] =\frac{1}{p} \displaystyle E[ X|A] =\frac{1}{p} +1 \displaystyle E\left[ X|A^{c}\right] \displaystyle r \displaystyle H \displaystyle T \displaystyle r+1 \displaystyle HH \displaystyle r+1 \displaystyle E[ X_{2}] \displaystyle E\left[ X|A^{c}\right] =\frac{1}{p} +1+E[ X_{2}] \displaystyle  \begin{array}{{>{\displaystyle}l}}
E[ X_{2}] =p\cdotp \left(\frac{1}{p} +1\right) +( 1-p) \cdotp \left(\frac{1}{p} +1+E[ X_{2}]\right)\\
=1+p+\frac{1}{p} +1+E[ X_{2}] -1-p\cdotp E[ X_{2}]\\
\Rightarrow \\
p\cdotp E[ X_{2}] =\frac{1}{p} +1\\
\Rightarrow \\
E[ X_{2}] =\frac{1+p}{p^{2}} .
\end{array} \displaystyle E[ X|A] ,\ E\left[ X|A^{c}\right]","['probability', 'expected-value']"
49,Strong law of large numbers under equivalent measures,Strong law of large numbers under equivalent measures,,"Suppose $\{X_n\}$ is a sequence of square-integrable i.i.d. random variables under the measure $\mathbb{P}$ . Under the strong law of large numbers we have that \begin{align*} \mathbb{P}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{P}}[X_1]\right)=1. \end{align*} If $\mathbb{Q}$ is an equivalent measure to $\mathbb{P}$ with $\frac{d\mathbb{Q}}{d\mathbb{P}}\in L^2(\mathbb{P})$ then each $X_i$ is still integrable under $\mathbb{Q}$ and the strong law of large numbers applied to $\mathbb{Q}$ will give \begin{align*} \mathbb{Q}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{Q}}[X_1]\right)=1. \end{align*} As the measures are equivalent, this also means that \begin{align*} \mathbb{P}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{Q}}[X_1]\right)=1 \end{align*} which implies that $\mathbb{E}_{\mathbb{P}}[X_1]=\mathbb{E}_{\mathbb{Q}}[X_1]$ . However this is generally not the case. Can anyone find where the argument above breaks down?","Suppose is a sequence of square-integrable i.i.d. random variables under the measure . Under the strong law of large numbers we have that If is an equivalent measure to with then each is still integrable under and the strong law of large numbers applied to will give As the measures are equivalent, this also means that which implies that . However this is generally not the case. Can anyone find where the argument above breaks down?","\{X_n\} \mathbb{P} \begin{align*}
\mathbb{P}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{P}}[X_1]\right)=1.
\end{align*} \mathbb{Q} \mathbb{P} \frac{d\mathbb{Q}}{d\mathbb{P}}\in L^2(\mathbb{P}) X_i \mathbb{Q} \mathbb{Q} \begin{align*}
\mathbb{Q}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{Q}}[X_1]\right)=1.
\end{align*} \begin{align*}
\mathbb{P}\left(\lim_{n\to\infty}\frac{1}{n}\sum_{j=1}^nX_j=\mathbb{E}_{\mathbb{Q}}[X_1]\right)=1
\end{align*} \mathbb{E}_{\mathbb{P}}[X_1]=\mathbb{E}_{\mathbb{Q}}[X_1]","['probability', 'probability-theory', 'law-of-large-numbers']"
50,a coupling probability problem and random walk game,a coupling probability problem and random walk game,,"There are 3 players and one dealer in a casino. The dealer chooses a player randomly( $p_1=\frac{1}{3}$ ). The chosen player tosses a coin( $p_2=\frac{1}{2}$ ). If the coin lands head, the chosen player will get 3 dollar, the dealer and the other two players will lose 1 dollar each. If the coin lands tail, the chosen player will lose 3 dollar, the dealer and the other two players will get 1 dollar each. This game repeats $n$ times. Let $x_{1n},x_{2n},x_{3n}$ be the total net profit(or loss) of players and let $y_n$ be the total net profit(or loss) of the dealer. Let $g(n)=prob(y_n>max(x_{in}) )$ For example, $g(1)=0, g(3)=\frac{1}{36}$ . Prove: $g(n)$ is increasing as odd number $n$ goes $n+2$ comments: By intuition, by central limit theorem, It seems that $x_i$ will goes $0$ more deeply than $y_i$ . However, the coupling structure makes this problem not easy.","There are 3 players and one dealer in a casino. The dealer chooses a player randomly( ). The chosen player tosses a coin( ). If the coin lands head, the chosen player will get 3 dollar, the dealer and the other two players will lose 1 dollar each. If the coin lands tail, the chosen player will lose 3 dollar, the dealer and the other two players will get 1 dollar each. This game repeats times. Let be the total net profit(or loss) of players and let be the total net profit(or loss) of the dealer. Let For example, . Prove: is increasing as odd number goes comments: By intuition, by central limit theorem, It seems that will goes more deeply than . However, the coupling structure makes this problem not easy.","p_1=\frac{1}{3} p_2=\frac{1}{2} n x_{1n},x_{2n},x_{3n} y_n g(n)=prob(y_n>max(x_{in}) ) g(1)=0, g(3)=\frac{1}{36} g(n) n n+2 x_i 0 y_i","['probability', 'probability-distributions', 'random-walk', 'order-statistics', 'coupling']"
51,Boy and girl probability,Boy and girl probability,,"How many births must occur in a family, in order to have one boy and one girl with probability > 80%? Here is my attempt: If we have n births, all possible arrangements of Bs and Gs (GBGGBBGBG etc) are $2^{n}$ . Of those, only one is GGGGG... (only girls) and one is BBBBB... (only boys). All others have both sexes. So in order to find n, we must solve the inequality: $\frac{2^{n} - 2}{2^{n}}\ge 0.80$ . Is this correct? And how do we solve it? Thank you!","How many births must occur in a family, in order to have one boy and one girl with probability > 80%? Here is my attempt: If we have n births, all possible arrangements of Bs and Gs (GBGGBBGBG etc) are . Of those, only one is GGGGG... (only girls) and one is BBBBB... (only boys). All others have both sexes. So in order to find n, we must solve the inequality: . Is this correct? And how do we solve it? Thank you!",2^{n} \frac{2^{n} - 2}{2^{n}}\ge 0.80,['probability']
52,Statistics problem about Possibility principle,Statistics problem about Possibility principle,,"I have a question about the following problem from the first edition of Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang. This is problem 68 from Chapter 4. Each of 111 people names his or her 5 favorite movies out of a list of 11 movies. Show that there are 2 movies such that at least 21 of the people name both of these movies as favorites. The possibility principle states that The possibility principle: Let A be the event that a randomly chosen object in a collection has a certain property. If P(A) > 0, then there exists an object with the property. Is it enough to state that the probability of two specific movies being chosen by at least 21 people is ${111\choose 21}{(2/11)}^{21} $ (where 2/11 is the probability of the two movies being chosen by a specific person) and therefore since this probability is greater than 0 then by the possibility principle there exist two  movies that are chosen by at least 21 people? But then it could also be said that there are 5 movies that are chosen by all 111 people.","I have a question about the following problem from the first edition of Introduction to Probability by Joseph K. Blitzstein and Jessica Hwang. This is problem 68 from Chapter 4. Each of 111 people names his or her 5 favorite movies out of a list of 11 movies. Show that there are 2 movies such that at least 21 of the people name both of these movies as favorites. The possibility principle states that The possibility principle: Let A be the event that a randomly chosen object in a collection has a certain property. If P(A) > 0, then there exists an object with the property. Is it enough to state that the probability of two specific movies being chosen by at least 21 people is (where 2/11 is the probability of the two movies being chosen by a specific person) and therefore since this probability is greater than 0 then by the possibility principle there exist two  movies that are chosen by at least 21 people? But then it could also be said that there are 5 movies that are chosen by all 111 people.",{111\choose 21}{(2/11)}^{21} ,"['probability', 'statistics', 'expected-value', 'random']"
53,Inclusion exclusion in a combinatorics question,Inclusion exclusion in a combinatorics question,,"The question :- Suppose we have an infinite number of Red balls, Green balls, White balls, and Blue balls, and we need to select $10$ balls.  We are required to find the probability that a selection contains balls of all the different colours. (The essence of having an ""infinite"" no. of balls is that the composition remains the same after each draw, so the probabilities aren't affected). Approach-1 : Suppose the no. of Red,Green,White,Blue balls selected are $r,g,w,b$ . Then : Favourable cases: No. of integer solutions of the equation $r+g+w+b=10$ , such that $r,g,w,b >0$ = $9\choose 3$ = $84$ . Total cases: No. of integer solutions of the equation $r+g+w+b=10$ , such that $r,g,w,b \geq 0$ = $13\choose3$ = $286$ . Which gives the (correct answer) as $42/143$ . Approach 2 : Each selection has $4$ options: i.e select $r,g,w$ or $b$ . Therefore, there are $4^{10}$ total options. By the principle of inclusion-exclusion, the favorable cases must be: $4^{10}$ - $4\choose1$$3^{10}$ + $4\choose2$$2^{10}$ - $4\choose3$$1^{10}$ . However, this approach doesnt give the correct answer. Whats wrong in using the IEP here?","The question :- Suppose we have an infinite number of Red balls, Green balls, White balls, and Blue balls, and we need to select balls.  We are required to find the probability that a selection contains balls of all the different colours. (The essence of having an ""infinite"" no. of balls is that the composition remains the same after each draw, so the probabilities aren't affected). Approach-1 : Suppose the no. of Red,Green,White,Blue balls selected are . Then : Favourable cases: No. of integer solutions of the equation , such that = = . Total cases: No. of integer solutions of the equation , such that = = . Which gives the (correct answer) as . Approach 2 : Each selection has options: i.e select or . Therefore, there are total options. By the principle of inclusion-exclusion, the favorable cases must be: - + - . However, this approach doesnt give the correct answer. Whats wrong in using the IEP here?","10 r,g,w,b r+g+w+b=10 r,g,w,b >0 9\choose 3 84 r+g+w+b=10 r,g,w,b \geq 0 13\choose3 286 42/143 4 r,g,w b 4^{10} 4^{10} 4\choose13^{10} 4\choose22^{10} 4\choose31^{10}","['probability', 'combinatorics', 'inclusion-exclusion']"
54,Bounds on expectation of Gaussian random vectors,Bounds on expectation of Gaussian random vectors,,"Let $X\in\mathbb{R}^n$ and $Y\in\mathbb{R}^m$ , $n\geq m$ , be independent standard Gaussian random vectors and define $D\in \mathbb{R}^{m\times m}$ , a positive-definite (symmetric) matrix. I want to prove that $$ -E\|X\|_2+E\|Y\|_2\leq -\sqrt{n}+\sqrt{m}\quad\quad (\text{1}) $$ and $$ \dfrac{E\|\sqrt{D}Y\|_2}{\sqrt{tr(D)}}\leq \dfrac{E\|Y\|_2}{\sqrt{m}}\quad\quad (\text{2}) $$ (Here $\|x\|_2=\sqrt{x^{T}x}$ , $tr(D)$ is the trace of $D$ and $\sqrt{D}$ is such that $(\sqrt{D})^2=D$ .) For (1) I know by Jensen's inequality that $E\|X\|_2\leq \sqrt{n}$ and $E\|Y\|_2\leq \sqrt{m}$ . But how this implies (1)? For (2) I know (again by Jensen) that $E\|\sqrt{D}Y\|_2\leq \sqrt{tr(D)}$ but that doesn't help me to obtain the bound since $E\|Y\|_2/\sqrt{m}\leq 1$ . Any help will be appreciated.","Let and , , be independent standard Gaussian random vectors and define , a positive-definite (symmetric) matrix. I want to prove that and (Here , is the trace of and is such that .) For (1) I know by Jensen's inequality that and . But how this implies (1)? For (2) I know (again by Jensen) that but that doesn't help me to obtain the bound since . Any help will be appreciated.","X\in\mathbb{R}^n Y\in\mathbb{R}^m n\geq m D\in \mathbb{R}^{m\times m} 
-E\|X\|_2+E\|Y\|_2\leq -\sqrt{n}+\sqrt{m}\quad\quad (\text{1})
 
\dfrac{E\|\sqrt{D}Y\|_2}{\sqrt{tr(D)}}\leq \dfrac{E\|Y\|_2}{\sqrt{m}}\quad\quad (\text{2})
 \|x\|_2=\sqrt{x^{T}x} tr(D) D \sqrt{D} (\sqrt{D})^2=D E\|X\|_2\leq \sqrt{n} E\|Y\|_2\leq \sqrt{m} E\|\sqrt{D}Y\|_2\leq \sqrt{tr(D)} E\|Y\|_2/\sqrt{m}\leq 1","['probability', 'inequality', 'normal-distribution', 'normed-spaces', 'expected-value']"
55,Four bridge hands with no two people having 8 or more cards of the same suit between them.,Four bridge hands with no two people having 8 or more cards of the same suit between them.,,I am trying to solve this problem: A 52-card deck is dealt out to 4 people (13 to each). What is the probability that no two people have 8 or more cards of the same suit between them? It seems to me that there are only 4! ways for this to be possible (when each player has four of a different suit and three of each of the others). This seems to be too small but I'm unsure of how to count all the possible satisfying combinations there are. I also can't quite figure out the denominator. Is it ${52 \choose 13}{39 \choose 13}{26 \choose 13}$ ? Or $\frac{52!}{13!^4}$ ?,I am trying to solve this problem: A 52-card deck is dealt out to 4 people (13 to each). What is the probability that no two people have 8 or more cards of the same suit between them? It seems to me that there are only 4! ways for this to be possible (when each player has four of a different suit and three of each of the others). This seems to be too small but I'm unsure of how to count all the possible satisfying combinations there are. I also can't quite figure out the denominator. Is it ? Or ?,{52 \choose 13}{39 \choose 13}{26 \choose 13} \frac{52!}{13!^4},"['probability', 'combinatorics']"
56,Probability of one sample mean being maximal among a set of other sample means,Probability of one sample mean being maximal among a set of other sample means,,"Let $\mathcal{D}$ be a distribution, and consider a finite set of sample means $x_i$ of $k_i$ draws from $\mathcal{D}$ ( $k_i$ can be different for each mean). I want to show that if $x_i$ and $x_j$ have $k_i\leq k_j$ draws, $\mathbb{P}(x_i =\max_\ell x_\ell)\geq \mathbb{P}(x_j =\max_\ell x_\ell)$ . I also suspect that if $\mathcal{D}$ meets some kind of regularity condition, then if the first inequality is strict, so is the second. I know that sample variance decreases as $\dfrac{var(\mathcal{D})}{k_i}$ , but I'm not sure how to prove the full result. EDIT: Not true in general. Is it true for the uniform distribution on $[0,1]$ ? If so, why? Here's the distribution of sample means for uniform $\mathcal{D}$ : For $k_1=1,k_2=3,k_3=10$ , we have $x_1$ maximal about 42% of the time, $x_2$ maximal about 31% of the time, and $x_3$ maximal about 27% of the time. So far, numerical evidence supports the conjecture for the following distributions: uniform normal Bernoulli( $.5$ ) geometric( $.5$ ), geometric( $.1$ ) beta( $.5,.5$ ), beta( $2,5$ ) Numerical evidence contradicts the conjecture for: Bernoulli( $.2 $ ) exponential (the conjecture holds for $k=[1,5,10,27]$ but not for $k=[1,5,10]$ or $k=[1,10]$ ) library(ggplot2) n = 50000 # number of draws for histogram  k = c(1,3,10)  out <- c() for (i in 1:length(k)) {   out[[i]] = replicate( n, mean( runif(k[[i]]) ) ) }  df <- data.frame(   samples=factor(rep(k, each=n)),   value=c(out, recursive=TRUE)   ) p<-ggplot(df, aes(x=value, fill=samples, color=samples))+   geom_histogram(position=""identity"", alpha=0.5, binwidth=.01) p  # Count how often each sample mean is optimal among x1,...,x(length(k)) tallies = c(1:length(k))*0 for (i in 1:n) {     samples <- c()     for (j in 1:length(k)) {       samples[[j]] = sample(out[[j]],1)    }    tallies[[which.max(samples)]] = tallies[[which.max(samples)]] + 1 } tallies = tallies/n  print(k) print(tallies)","Let be a distribution, and consider a finite set of sample means of draws from ( can be different for each mean). I want to show that if and have draws, . I also suspect that if meets some kind of regularity condition, then if the first inequality is strict, so is the second. I know that sample variance decreases as , but I'm not sure how to prove the full result. EDIT: Not true in general. Is it true for the uniform distribution on ? If so, why? Here's the distribution of sample means for uniform : For , we have maximal about 42% of the time, maximal about 31% of the time, and maximal about 27% of the time. So far, numerical evidence supports the conjecture for the following distributions: uniform normal Bernoulli( ) geometric( ), geometric( ) beta( ), beta( ) Numerical evidence contradicts the conjecture for: Bernoulli( ) exponential (the conjecture holds for but not for or ) library(ggplot2) n = 50000 # number of draws for histogram  k = c(1,3,10)  out <- c() for (i in 1:length(k)) {   out[[i]] = replicate( n, mean( runif(k[[i]]) ) ) }  df <- data.frame(   samples=factor(rep(k, each=n)),   value=c(out, recursive=TRUE)   ) p<-ggplot(df, aes(x=value, fill=samples, color=samples))+   geom_histogram(position=""identity"", alpha=0.5, binwidth=.01) p  # Count how often each sample mean is optimal among x1,...,x(length(k)) tallies = c(1:length(k))*0 for (i in 1:n) {     samples <- c()     for (j in 1:length(k)) {       samples[[j]] = sample(out[[j]],1)    }    tallies[[which.max(samples)]] = tallies[[which.max(samples)]] + 1 } tallies = tallies/n  print(k) print(tallies)","\mathcal{D} x_i k_i \mathcal{D} k_i x_i x_j k_i\leq k_j \mathbb{P}(x_i =\max_\ell x_\ell)\geq \mathbb{P}(x_j =\max_\ell x_\ell) \mathcal{D} \dfrac{var(\mathcal{D})}{k_i} [0,1] \mathcal{D} k_1=1,k_2=3,k_3=10 x_1 x_2 x_3 .5 .5 .1 .5,.5 2,5 .2  k=[1,5,10,27] k=[1,5,10] k=[1,10]","['probability', 'probability-distributions']"
57,Does this version of law of large numbers holds true?,Does this version of law of large numbers holds true?,,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space, $(\mathcal{X},\mathcal{F}_{\mathcal{X}})$ be a measurable space and $X,X_1,...,X_n,...$ be a sequence of $\mathbb{P}$ -i.i.d. random variables from $(\Omega,\mathcal{F})$ into $(\mathcal{X},\mathcal{F}_{\mathcal{X}})$ . If $A\in\mathcal{F}_{\mathcal{X}}$ then we know from the law of large numbers that $$\exists F\in\mathcal{F}, \left(\mathbb{P}(F)=0\right)\land\left(\forall\omega\in F^c, \mathbb{P}(X\in A)=\lim_{n\to+\infty}\frac{1}{n}\sum_{k=1}^n\chi_A(X_k(\omega))\right).$$ Then, by Egoroff theorem, we also know that $$\forall\varepsilon>0, \exists F\in\mathcal{F}, \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right).$$ So $$\forall A\in\mathcal{F}_{\mathcal{X}}, \forall\varepsilon>0, \exists F\in\mathcal{F},\\ \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right).$$ I'm wondering if this result holds uniformly in $A$ , i.e. is it true that $$\forall\varepsilon>0, \exists F\in\mathcal{F},\\ \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\forall A\in\mathcal{F}_{\mathcal{X}},\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right)?$$","Let be a probability space, be a measurable space and be a sequence of -i.i.d. random variables from into . If then we know from the law of large numbers that Then, by Egoroff theorem, we also know that So I'm wondering if this result holds uniformly in , i.e. is it true that","(\Omega,\mathcal{F},\mathbb{P}) (\mathcal{X},\mathcal{F}_{\mathcal{X}}) X,X_1,...,X_n,... \mathbb{P} (\Omega,\mathcal{F}) (\mathcal{X},\mathcal{F}_{\mathcal{X}}) A\in\mathcal{F}_{\mathcal{X}} \exists F\in\mathcal{F}, \left(\mathbb{P}(F)=0\right)\land\left(\forall\omega\in F^c, \mathbb{P}(X\in A)=\lim_{n\to+\infty}\frac{1}{n}\sum_{k=1}^n\chi_A(X_k(\omega))\right). \forall\varepsilon>0, \exists F\in\mathcal{F}, \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right). \forall A\in\mathcal{F}_{\mathcal{X}}, \forall\varepsilon>0, \exists F\in\mathcal{F},\\ \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right). A \forall\varepsilon>0, \exists F\in\mathcal{F},\\ \left(\mathbb{P}(F)<\varepsilon\right)\land\left(\forall A\in\mathcal{F}_{\mathcal{X}},\lim_{n\to+\infty}\left\|\mathbb{P}(X\in A)-\frac{1}{n}\sum_{k=1}^n\chi_A(X_k)\right\|_{L^\infty(F^c)}=0\right)?","['probability', 'probability-distributions', 'law-of-large-numbers']"
58,Coupon collectors problem: variance calculation missing a term.,Coupon collectors problem: variance calculation missing a term.,,"EDIT: for a consolidated answer to the general variance in a coupon collectors problem with unequal probabilities, see here: https://math.stackexchange.com/a/3454032/155881 In example 5.17 of the book on Introduction to probability models by Ross , he solves the coupon collector's problem, where there are $n$ coupons, each with probability $p_j$ of being collected per draw (with $\sum_{j=1}^n p_j=1$ ). He uses the Poisson process to come up with the following expression for the expected value of $X$ , the number of coupons to be collected for completing the collection: $$E(X) = \int\limits_0^\infty P(X>t)dt = \int\limits_0^\infty \left(1-\prod\limits_{j=1}^n (1-e^{-p_j t})\right)dt$$ Using the fact that $\int_0^\infty e^{-pt}=\frac 1 p$ , $$E(X)=\sum \frac 1 p_j -\sum_{i<j} \frac{1}{p_i+p_j}+\dots +(-1)^{n-1}\frac{1}{p_1+\dots+p_n}$$ Now, I want to use the same approach to calculate the variance. Per comment by @BGM here and also this question , we can use the following expression to get $E(X^2)$ : $$E(X^2) = \int\limits_0^\infty 2tP(X>t)dt = \int\limits_0^\infty 2t\left(1-\prod\limits_{j=1}^n(1-e^{-p_j t})\right)dt$$ Using the fact that $\int\limits_0^\infty te^{-pt}=\frac{1}{p^2}$ and the same algebra as for $E(X)$ we get: $$\frac{E(X^2)}{2} = \sum \frac {1} {p_j^2} -\sum_{i<j} \frac{1}{(p_i+p_j)^2}+\dots +(-1)^{n-1}\frac{1}{(p_1+\dots+p_n)^2} $$ Now, let's consider the special case where all coupons have an equal probability of being selected. In other words, $p_j=\frac 1 n \; \forall \; j$ . Approach-1 We get: $$\frac{E(X^2)}{2} = n^2\left(\sum\limits_{k=1}^n (-1)^{k-1}\frac{n\choose k}{k^2}\right)$$ Per my answer to the question here , this summation yields: $$E(X^2) = 2n^2\left( \sum_{j=1}^n\sum_{k=1}^j\frac{1}{jk}\right)\tag{1}$$ Approach-2 But per this paper , the variance for this special case is: $$V(X) = n^2\sum_{j=1}^m\frac{1}{j^2}-n\sum_{j=1}^m\frac{1}{j} $$ and this would mean that: $$E(X^2) = V(X)+E(X)^2 = n^2\sum_{j=1}^m\frac{1}{j^2}-n\sum_{j=1}^m\frac{1}{j}+\left(n\sum_{j=1}^m\frac{1}{j}\right)^2$$ If we visualize a $j-k$ grid, it's easy to see that this is the same as: $$E(X^2) = 2n^2\left( \sum_{j=1}^n\sum_{k=1}^j\frac{1}{jk}\right)-n\sum_{j=1}^m\frac{1}{j}\tag{2}$$ If we compare equation (1) from approach-1 and equation (2) from approach-2, it's clear that equation (1) has a missing $-n\sum_{j=1}^m\frac{1}{j}$ term. And equation (2) has been verified using other methods. This indicates that there is some small mistake with approach-1 that is making us miss this term. I haven't been able to spot what this issue is. Hoping someone else might.","EDIT: for a consolidated answer to the general variance in a coupon collectors problem with unequal probabilities, see here: https://math.stackexchange.com/a/3454032/155881 In example 5.17 of the book on Introduction to probability models by Ross , he solves the coupon collector's problem, where there are coupons, each with probability of being collected per draw (with ). He uses the Poisson process to come up with the following expression for the expected value of , the number of coupons to be collected for completing the collection: Using the fact that , Now, I want to use the same approach to calculate the variance. Per comment by @BGM here and also this question , we can use the following expression to get : Using the fact that and the same algebra as for we get: Now, let's consider the special case where all coupons have an equal probability of being selected. In other words, . Approach-1 We get: Per my answer to the question here , this summation yields: Approach-2 But per this paper , the variance for this special case is: and this would mean that: If we visualize a grid, it's easy to see that this is the same as: If we compare equation (1) from approach-1 and equation (2) from approach-2, it's clear that equation (1) has a missing term. And equation (2) has been verified using other methods. This indicates that there is some small mistake with approach-1 that is making us miss this term. I haven't been able to spot what this issue is. Hoping someone else might.",n p_j \sum_{j=1}^n p_j=1 X E(X) = \int\limits_0^\infty P(X>t)dt = \int\limits_0^\infty \left(1-\prod\limits_{j=1}^n (1-e^{-p_j t})\right)dt \int_0^\infty e^{-pt}=\frac 1 p E(X)=\sum \frac 1 p_j -\sum_{i<j} \frac{1}{p_i+p_j}+\dots +(-1)^{n-1}\frac{1}{p_1+\dots+p_n} E(X^2) E(X^2) = \int\limits_0^\infty 2tP(X>t)dt = \int\limits_0^\infty 2t\left(1-\prod\limits_{j=1}^n(1-e^{-p_j t})\right)dt \int\limits_0^\infty te^{-pt}=\frac{1}{p^2} E(X) \frac{E(X^2)}{2} = \sum \frac {1} {p_j^2} -\sum_{i<j} \frac{1}{(p_i+p_j)^2}+\dots +(-1)^{n-1}\frac{1}{(p_1+\dots+p_n)^2}  p_j=\frac 1 n \; \forall \; j \frac{E(X^2)}{2} = n^2\left(\sum\limits_{k=1}^n (-1)^{k-1}\frac{n\choose k}{k^2}\right) E(X^2) = 2n^2\left( \sum_{j=1}^n\sum_{k=1}^j\frac{1}{jk}\right)\tag{1} V(X) = n^2\sum_{j=1}^m\frac{1}{j^2}-n\sum_{j=1}^m\frac{1}{j}  E(X^2) = V(X)+E(X)^2 = n^2\sum_{j=1}^m\frac{1}{j^2}-n\sum_{j=1}^m\frac{1}{j}+\left(n\sum_{j=1}^m\frac{1}{j}\right)^2 j-k E(X^2) = 2n^2\left( \sum_{j=1}^n\sum_{k=1}^j\frac{1}{jk}\right)-n\sum_{j=1}^m\frac{1}{j}\tag{2} -n\sum_{j=1}^m\frac{1}{j},"['probability', 'summation', 'coupon-collector']"
59,Coin Flip: Expected number of flips,Coin Flip: Expected number of flips,,"Two Players are playing a coin flips game. The game ends when at least one player has a Head. Whoever gets the Head first would be the winner, and the other would be the loser. The loser will continue to flip until he gets a Head. What's the expected number of flips for the winner? What about the loser?  the probability of ending a game is 3/4 since the only case of continuing is both tails, which has a probability of 1/4; so the expected number of flips for the winner would be 1/(3/4) = 4/3. I'm wondering if the expected number of flips for the loser is (4/3) + 2","Two Players are playing a coin flips game. The game ends when at least one player has a Head. Whoever gets the Head first would be the winner, and the other would be the loser. The loser will continue to flip until he gets a Head. What's the expected number of flips for the winner? What about the loser?  the probability of ending a game is 3/4 since the only case of continuing is both tails, which has a probability of 1/4; so the expected number of flips for the winner would be 1/(3/4) = 4/3. I'm wondering if the expected number of flips for the loser is (4/3) + 2",,"['probability', 'statistics']"
60,Chance of winning a raffle with a special rule,Chance of winning a raffle with a special rule,,"A person is hosting a raffle event. There are 1000 participants in the raffle. The raffle draw will produce one winner. The Special Rule The host is also 1 of 1000 participants, but he announces he will not claim the prize, so, if the host wins the raffle, a re-draw will happen and he will be removed from the second draw which makes the total number of participant to 999. Question What is the probability of me winning the raffle? Note This might be a really silly question, but i cant seem to come up with an answer :). My attempts: Answer 1. Chance is $1/1000 + 1/1000 * 1/999$ = (chance of me winning first round + chance of host winning * chance of me winning second round) Answer 2. Chance is $1/999$ because logically speaking, there are 999 people who can win, chance is just 1/999. Edit : just did a calculation to actually calculate above 2 answers, they have the same result :)","A person is hosting a raffle event. There are 1000 participants in the raffle. The raffle draw will produce one winner. The Special Rule The host is also 1 of 1000 participants, but he announces he will not claim the prize, so, if the host wins the raffle, a re-draw will happen and he will be removed from the second draw which makes the total number of participant to 999. Question What is the probability of me winning the raffle? Note This might be a really silly question, but i cant seem to come up with an answer :). My attempts: Answer 1. Chance is = (chance of me winning first round + chance of host winning * chance of me winning second round) Answer 2. Chance is because logically speaking, there are 999 people who can win, chance is just 1/999. Edit : just did a calculation to actually calculate above 2 answers, they have the same result :)",1/1000 + 1/1000 * 1/999 1/999,['probability']
61,Classic Hat Probability Problem,Classic Hat Probability Problem,,"This is a textbook example and I am confused about the explanation. This question was asked by different people in stack-exchange already but I couldn't find the solution to my question. Here's the problem: At a party $n$ man take their hats. The hats are then mixed up and each man randomly selects one. We say that a match occurs if a man selects his own hat. What is the probability of no matches? What is the probability of exactly $k$ matches? Solution (summarized): $P_n = P(E) =$ the event that no matches occur, dependence on $n$ , $M =$ first man selects his own hat $M^c=$ first man does not select his own hat So, $P_n = P(E) = P(E|M)P(M) + P(E|M^c)P(M^c)$ Since $P(E|M) = 0$ , we get $P(E)=P(E|M^c)* \frac{n-1}{n}$ Here's my question: the solution says $P(E|M^c)$ is the probability of no matches when $(n1)$ men select from a set of $n  1$ hats that does not contain the hat of one of these men. This can happen in either of two mutually exclusive ways. Either there are no matches and the extra man does not select the extra hat (this being the hat of the man that chose first), or there are no matches and the extra man does select the extra hat. Therefore, we get $P(E|M^c)= P(E|M^c)=P_{n1}+ \frac{1}{n-1}*P_{n2}$ What does the bolded part exactly mean? Who is the extra man? Is he the last person to choose the hat? If so, if the extra man does select the extra hat, shouldn't the probability of no matches be $0$ . Can we do this question in  a different way? like setting $X_i=$ the $i^{th}$ person selecting his hat, and the probability of no matches will be $P(\sum_{i=1}^n X_i = 0)$","This is a textbook example and I am confused about the explanation. This question was asked by different people in stack-exchange already but I couldn't find the solution to my question. Here's the problem: At a party man take their hats. The hats are then mixed up and each man randomly selects one. We say that a match occurs if a man selects his own hat. What is the probability of no matches? What is the probability of exactly matches? Solution (summarized): the event that no matches occur, dependence on , first man selects his own hat first man does not select his own hat So, Since , we get Here's my question: the solution says is the probability of no matches when men select from a set of hats that does not contain the hat of one of these men. This can happen in either of two mutually exclusive ways. Either there are no matches and the extra man does not select the extra hat (this being the hat of the man that chose first), or there are no matches and the extra man does select the extra hat. Therefore, we get What does the bolded part exactly mean? Who is the extra man? Is he the last person to choose the hat? If so, if the extra man does select the extra hat, shouldn't the probability of no matches be . Can we do this question in  a different way? like setting the person selecting his hat, and the probability of no matches will be",n k P_n = P(E) = n M = M^c= P_n = P(E) = P(E|M)P(M) + P(E|M^c)P(M^c) P(E|M) = 0 P(E)=P(E|M^c)* \frac{n-1}{n} P(E|M^c) (n1) n  1 P(E|M^c)= P(E|M^c)=P_{n1}+ \frac{1}{n-1}*P_{n2} 0 X_i= i^{th} P(\sum_{i=1}^n X_i = 0),['probability']
62,A question on giving prizes when there is no restriction on the number of prizes per person,A question on giving prizes when there is no restriction on the number of prizes per person,,"A group consisting of $3$ men and $6$ women attends a prizegiving ceremony. If $ 5$ prizes are awarded at random to members of the group, find the probability that exactly $3 $ of the prizes are awarded to women if a) There is a restriction of at most one prize per person b) There is no restriction on the number of prizes per person I did part a) and got the same result as the solution but I failed at getting the same answer for part b). When I looked at the working outs of both parts, I noticed a significant difference in the ways two parts are solved. This is the working out for part a) (which is also similar to my working out) a) $\frac{6C3\times 3C2}{9C5} = \frac{10}{21}\ $ And this is the working out of part b)  b) $\ 5C3 \times (\frac{3}{9})^{2} \times (\frac{6}{9})^{3}\  = \frac{80}{243}\ $ I'm so confused why part b) is done in such a different way than part a) and as a student, how can I know when to consider the numerator and denominator separately like part a) and when to find the probability of each component and times all of them together like part b)? Also, can we solve part b) in a similar way like part a)? Does anyone have any tips on how to distinguish these sorts of methods? Thank you very much for helping.","A group consisting of men and women attends a prizegiving ceremony. If prizes are awarded at random to members of the group, find the probability that exactly of the prizes are awarded to women if a) There is a restriction of at most one prize per person b) There is no restriction on the number of prizes per person I did part a) and got the same result as the solution but I failed at getting the same answer for part b). When I looked at the working outs of both parts, I noticed a significant difference in the ways two parts are solved. This is the working out for part a) (which is also similar to my working out) a) And this is the working out of part b)  b) I'm so confused why part b) is done in such a different way than part a) and as a student, how can I know when to consider the numerator and denominator separately like part a) and when to find the probability of each component and times all of them together like part b)? Also, can we solve part b) in a similar way like part a)? Does anyone have any tips on how to distinguish these sorts of methods? Thank you very much for helping.",3 6  5 3  \frac{6C3\times 3C2}{9C5} = \frac{10}{21}\  \ 5C3 \times (\frac{3}{9})^{2} \times (\frac{6}{9})^{3}\  = \frac{80}{243}\ ,"['probability', 'combinatorics', 'combinations']"
63,Distinct balls into distinct boxes,Distinct balls into distinct boxes,,"We have $n$ distinct balls ( $n>7$ ) and want to randomly (and independently) distribute them into $N$ distinct boxes ( $N>n$ ) which are placed one next to the other. a) What is the probability that all balls are placed in consecutive boxes? b) What is the probability that all balls are placed in consecutive boxes and balls with number $1$ , $4$ and $7$ are also placed in consecutive boxes? I am not sure but I will try: a) There is a block of n balls which must be placed in one of the $N-n+1$ gaps formed if we arrange the boxes and fill $n$ consecutive of them. So there are $N-n+1$ places place this block. The $n$ balls in the block can be arranged in $n!$ ways. Also the N boxes can be arranged in $N!$ ways. So all in all we have $n!N!(N-n+1)$ . b) Again we have $N!$ ways to arrange the boxes but the balls can be arranged in $(n-3)!$ ways, right? I don't know what is the total number of ways to place all balls in the boxes - plus that I see no restriction regarding the number of balls per box. Any help?","We have distinct balls ( ) and want to randomly (and independently) distribute them into distinct boxes ( ) which are placed one next to the other. a) What is the probability that all balls are placed in consecutive boxes? b) What is the probability that all balls are placed in consecutive boxes and balls with number , and are also placed in consecutive boxes? I am not sure but I will try: a) There is a block of n balls which must be placed in one of the gaps formed if we arrange the boxes and fill consecutive of them. So there are places place this block. The balls in the block can be arranged in ways. Also the N boxes can be arranged in ways. So all in all we have . b) Again we have ways to arrange the boxes but the balls can be arranged in ways, right? I don't know what is the total number of ways to place all balls in the boxes - plus that I see no restriction regarding the number of balls per box. Any help?",n n>7 N N>n 1 4 7 N-n+1 n N-n+1 n n! N! n!N!(N-n+1) N! (n-3)!,"['probability', 'combinatorics']"
64,Variance of a non-homogeneous Poisson process,Variance of a non-homogeneous Poisson process,,"I am trying to derive the mean and variance of a non-homogeneous Poisson process. For a homogeneous Poisson process with parameter $\lambda$ , our class notes show the following derivation for the mean, $\mathbb{E}[N(s)]$ , and variance, $var[N(s)]$ , of the number of events over a duration of $s$ : $ \begin{align} \quad \mathbb{E}[N(s)]  &= \sum_{n=0}^{\infty} n \cdot P(N(s) = n) \\ &= 0 + \sum_{n=1}^{\infty} n \cdot P(N(s) = n) \\ &= \sum_{n=1}^{\infty} n e^{-\lambda s} \frac{(\lambda s)^n}{n!} \\ &= \sum_{n=1}^{\infty} e^{-\lambda s} \frac{(\lambda s)^n}{(n-1)!} \\ &= (\lambda s) (e^{-\lambda s}) \sum_{n=1}^{\infty} \frac{(\lambda s)^{n-1}}{(n-1)!} \\ &= (\lambda s) (e^{-\lambda s}) (e^{\lambda s}) \\ &= \lambda s \end{align} $ $ \begin{align} \quad \mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )] &= \sum_{n=0}^{\infty} n(n-1) \cdot P(N(s) = n) \\ &= 0 + 0 + \sum_{n=2}^{\infty} n(n-1) e^{-\lambda s} \frac{(\lambda s)^n}{n!} \\ &= \sum_{n=2}^{\infty} e^{-\lambda s} \frac{(\lambda s)^n}{(n-2)!} \\ &= (\lambda s)^2 (e^{-\lambda s}) \sum_{n=2}^{\infty} \frac{(\lambda s)^{n-2}}{(n-2)!} \\ &= (\lambda s)^2 (e^{-\lambda s}) (e^{\lambda s}) \\ &= (\lambda s)^2 \end{align} $ $ \begin{align} \quad var[N(s)] &= \mathbb{E}[(N(s))^2] - \left ( \mathbb{E}[N(s)] \right )^2 \\ &= \mathbb{E}[(N(s))^2] - \mathbb{E}[N(s)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\ &= \mathbb{E}[(N(s))^2 - N(s)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\ &= \mathbb{E}[(N(s))(N(s) - 1)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\ &= (\lambda s)^2 + \lambda s - (\lambda s)^2 \\ &= \lambda s \end{align} $ where we used the Taylor expansion $e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}$ in the infinite sums. When I try to apply this to a non-homogeneous process with parameter $\lambda(t)$ that is dependent on $t$ , I get the mean: $ \begin{align} \quad \mathbb{E}[N(s)]  &= \lim_{\delta r \to 0} \sum_{r=0}^s \left ( \sum_{n=0}^{\infty} n \cdot P(N_r(\delta r) = n) \right ) \\ &= \int_0^s \left ( \sum_{n=0}^{\infty} n \cdot P(N_r(\delta r) = n) \right ) \\ &= \int_0^s \left ( \sum_{n=1}^{\infty} n e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^n}{n!} \right ) \\ &= \int_0^s \left ( \lambda(r) dr \sum_{n=1}^{\infty} e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^{n-1}}{(n-1)!} \right ) \\ &= \int_0^s \left ( \lambda(r) dr \right ) \left ( e^{-\lambda(r) dr} \right ) \left ( e^{\lambda(r) dr} \right ) \\ &= \int_0^s \lambda(r) dr \\ &= \Lambda(t, s) \end{align} $ But when I try to derive the $\mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )]$ term, I get stuck: $ \begin{align} \quad \mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )] &= \int_0^s \left ( \sum_{n=0}^{\infty} n(n-1) \cdot P(N_r(dr) = n) \right ) \\ &= \int_0^s \left ( \sum_{n=2}^{\infty} n(n-1) e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^n}{n!} \right ) \\ &= \int_0^s \left ( \left ( \lambda(r) dr \right )^2 e^{-\lambda(r) dr} \sum_{n=2}^{\infty} \frac{(\lambda(r) dr)^{n-2}}{(n-2)!} \right ) \\ &= \int_0^s \left ( \left ( \lambda(r) dr \right )^2 \left ( e^{-\lambda(r) dr}  \right ) \left ( e^{-\lambda(r) dr} \right ) \right ) \\ &= \int_0^s \left ( \lambda(r) dr \right )^2 \\ &=^? \left ( \int_0^s \lambda(r) dr \right )^2 \end{align} $ If the last line is true, then the variance becomes $\Lambda(t, s)$ like I would expect. However, I feel like this is generally not true, and to be honest I'm not even sure how to interpret the square inside of the integral, which is making me question my derivation altogether...","I am trying to derive the mean and variance of a non-homogeneous Poisson process. For a homogeneous Poisson process with parameter , our class notes show the following derivation for the mean, , and variance, , of the number of events over a duration of : where we used the Taylor expansion in the infinite sums. When I try to apply this to a non-homogeneous process with parameter that is dependent on , I get the mean: But when I try to derive the term, I get stuck: If the last line is true, then the variance becomes like I would expect. However, I feel like this is generally not true, and to be honest I'm not even sure how to interpret the square inside of the integral, which is making me question my derivation altogether...","\lambda \mathbb{E}[N(s)] var[N(s)] s 
\begin{align}
\quad \mathbb{E}[N(s)] 
&= \sum_{n=0}^{\infty} n \cdot P(N(s) = n) \\
&= 0 + \sum_{n=1}^{\infty} n \cdot P(N(s) = n) \\
&= \sum_{n=1}^{\infty} n e^{-\lambda s} \frac{(\lambda s)^n}{n!} \\
&= \sum_{n=1}^{\infty} e^{-\lambda s} \frac{(\lambda s)^n}{(n-1)!} \\
&= (\lambda s) (e^{-\lambda s}) \sum_{n=1}^{\infty} \frac{(\lambda s)^{n-1}}{(n-1)!} \\
&= (\lambda s) (e^{-\lambda s}) (e^{\lambda s}) \\
&= \lambda s
\end{align}
 
\begin{align}
\quad \mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )]
&= \sum_{n=0}^{\infty} n(n-1) \cdot P(N(s) = n) \\
&= 0 + 0 + \sum_{n=2}^{\infty} n(n-1) e^{-\lambda s} \frac{(\lambda s)^n}{n!} \\
&= \sum_{n=2}^{\infty} e^{-\lambda s} \frac{(\lambda s)^n}{(n-2)!} \\
&= (\lambda s)^2 (e^{-\lambda s}) \sum_{n=2}^{\infty} \frac{(\lambda s)^{n-2}}{(n-2)!} \\
&= (\lambda s)^2 (e^{-\lambda s}) (e^{\lambda s}) \\
&= (\lambda s)^2
\end{align}
 
\begin{align}
\quad var[N(s)]
&= \mathbb{E}[(N(s))^2] - \left ( \mathbb{E}[N(s)] \right )^2 \\
&= \mathbb{E}[(N(s))^2] - \mathbb{E}[N(s)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\
&= \mathbb{E}[(N(s))^2 - N(s)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\
&= \mathbb{E}[(N(s))(N(s) - 1)] + \mathbb{E}[N(s)] - \left ( \mathbb{E}[N(s)] \right )^2 \\
&= (\lambda s)^2 + \lambda s - (\lambda s)^2 \\
&= \lambda s
\end{align}
 e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} \lambda(t) t 
\begin{align}
\quad \mathbb{E}[N(s)] 
&= \lim_{\delta r \to 0} \sum_{r=0}^s \left ( \sum_{n=0}^{\infty} n \cdot P(N_r(\delta r) = n) \right ) \\
&= \int_0^s \left ( \sum_{n=0}^{\infty} n \cdot P(N_r(\delta r) = n) \right ) \\
&= \int_0^s \left ( \sum_{n=1}^{\infty} n e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^n}{n!} \right ) \\
&= \int_0^s \left ( \lambda(r) dr \sum_{n=1}^{\infty} e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^{n-1}}{(n-1)!} \right ) \\
&= \int_0^s \left ( \lambda(r) dr \right ) \left ( e^{-\lambda(r) dr} \right ) \left ( e^{\lambda(r) dr} \right ) \\
&= \int_0^s \lambda(r) dr \\
&= \Lambda(t, s)
\end{align}
 \mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )] 
\begin{align}
\quad \mathbb{E}[\left ( N(s) \right ) \left ( N(s) - 1 \right )]
&= \int_0^s \left ( \sum_{n=0}^{\infty} n(n-1) \cdot P(N_r(dr) = n) \right ) \\
&= \int_0^s \left ( \sum_{n=2}^{\infty} n(n-1) e^{-\lambda(r) dr} \frac{(\lambda(r) dr)^n}{n!} \right ) \\
&= \int_0^s \left ( \left ( \lambda(r) dr \right )^2 e^{-\lambda(r) dr} \sum_{n=2}^{\infty} \frac{(\lambda(r) dr)^{n-2}}{(n-2)!} \right ) \\
&= \int_0^s \left ( \left ( \lambda(r) dr \right )^2 \left ( e^{-\lambda(r) dr}  \right ) \left ( e^{-\lambda(r) dr} \right ) \right ) \\
&= \int_0^s \left ( \lambda(r) dr \right )^2 \\
&=^? \left ( \int_0^s \lambda(r) dr \right )^2
\end{align}
 \Lambda(t, s)","['probability', 'poisson-distribution', 'poisson-process']"
65,Is there an extension of Donsker's invariance principle for not identically distributed random variables?,Is there an extension of Donsker's invariance principle for not identically distributed random variables?,,"As proved in Donsker-Prohorov's Invariance principle, for i.i.d random variables $\xi_1,\xi_2,\cdots$ , its partial sums $S_n(t)=\sum_{i=1}^{[nt]}\xi_i$ converge to Brownian motion $W(t)$ in distribution. What if the random variables $\xi_1,\xi_2,\cdots$ are independent but not identically distributed(i.e, same mean as 0 but different variance $v_i^2$ )? Did someone prove a similar result for not identically distributed cases? If not, how should I prove this by following the original proof? I would appreciate if someone can help!","As proved in Donsker-Prohorov's Invariance principle, for i.i.d random variables , its partial sums converge to Brownian motion in distribution. What if the random variables are independent but not identically distributed(i.e, same mean as 0 but different variance )? Did someone prove a similar result for not identically distributed cases? If not, how should I prove this by following the original proof? I would appreciate if someone can help!","\xi_1,\xi_2,\cdots S_n(t)=\sum_{i=1}^{[nt]}\xi_i W(t) \xi_1,\xi_2,\cdots v_i^2","['probability', 'functional-analysis', 'stochastic-processes', 'central-limit-theorem', 'functional-inequalities']"
66,Almost sure definition of Ito's lemma but integral terms are defined in $L^2$,Almost sure definition of Ito's lemma but integral terms are defined in,L^2,"I am aware that this question is related to this but I thought it would be useful to clarify a few things. I am reading this book to get a quick overview of stochastic calculus. It introduces the Ito's lemma in an almost sure sense, However, the term $\int_0^T F'_x(t,W(t)) dW(t)$ is defined in the book as a limit of sums which converge in $L^2$ . In the proof of Ito's Lemma, the book always mentions that if the convergence is $L^2$ , there is a subsequence that converges almost surely. With this in mind, is it OK then to define stochastic integrals $\int_0^T f(t,W(t)) \,dW(t)$ in the almost sense? I find this confusing since this integral may not even be defined for an abritrary continuous function $f$ especially if $f$ and $W$ don't simultaneously satisfy certain variation conditions. OR, should I interpret it in this manner: Define the stochastic integral in $L^2$ and for those which converge in $L^2$ , we can also define the a.s. convergence using the subsequence argument? Hoping for clarification on the issue. Thanks!","I am aware that this question is related to this but I thought it would be useful to clarify a few things. I am reading this book to get a quick overview of stochastic calculus. It introduces the Ito's lemma in an almost sure sense, However, the term is defined in the book as a limit of sums which converge in . In the proof of Ito's Lemma, the book always mentions that if the convergence is , there is a subsequence that converges almost surely. With this in mind, is it OK then to define stochastic integrals in the almost sense? I find this confusing since this integral may not even be defined for an abritrary continuous function especially if and don't simultaneously satisfy certain variation conditions. OR, should I interpret it in this manner: Define the stochastic integral in and for those which converge in , we can also define the a.s. convergence using the subsequence argument? Hoping for clarification on the issue. Thanks!","\int_0^T F'_x(t,W(t)) dW(t) L^2 L^2 \int_0^T f(t,W(t)) \,dW(t) f f W L^2 L^2","['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
67,Transform probability density from low to high dimension with Jacobian,Transform probability density from low to high dimension with Jacobian,,"$\vec{X}$ is a vector of random variables in $\mathbb{R}^{n}$ $\rho_{\vec{X}}(\vec{x})$ is probability density of $\vec{X}$ . $\vec{y} = f(\vec{x})$ is a vector in $\mathbb{R}^{m}$ $\vec{Y} = f(\vec{X})$ is a vector of random variables in $\mathbb{R}^{m}$ $\rho_{\vec{Y}}(\vec{y})$ is probability density of $\vec{Y}$ . $m \gt n$ The goal is to find $\rho_{\vec{Y}}(\vec{y})$ given $\rho_{\vec{X}}(\vec{x})$ and $f(\vec{x})$ . When does the following trick work? $\rho_{\vec{Y}}(\vec{y}) d\vec{y} = \rho_{\vec{X}}(\vec{x}) d\vec{x}$ $\rho_{\vec{Y}}(\vec{y}) \det(\left \lvert J \right \rvert) = \rho_{\vec{X}}(\vec{x})$ For $n = 2, m = 4$ , $$ J = \left[ \begin{matrix}  a_{11} & a_{12} & 0 & 0 \\ a_{21} & a_{22} & 0 & 0 \\ a_{31} & a_{32} & 1 & 0 \\ a_{41} & a_{42} & 0 & 1 \\ \end{matrix} \right]$$ where: $ a_{ij} = \frac{\partial{y_i}}{\partial{x_j}} $ The lower right corner of J is a block of identity matrix $\det$ is determinant The explanation of the trick says it tries to augment the transform from: $\vec{x} \rightarrow \vec{y}$ to $(x_{1}, x_{2}, y_{3}, y_{4}) \rightarrow (y_{1}, y_{2}, y_{3}, y_{4})$ and then integrate the extra dimensions out. What if $\frac{\partial y_{1}(\vec{x})}{\partial{y_3}(\vec{x})} \ne 0$ ? If the trick doesn't always work, what is the general method to do this? Update: add an example Example ( Unit simplex transform or Stick breaking transform ) Let $\vec{x} = (x_1, x_2, x_3, \ldots, x_{K})$ be a point on the probability simplex: $0 \le x_{n} \le 1$ $x_1 + x_2 + x_3 + ... x_{K} = 1$ The transformation $\vec{z} = (z_{1}, \ldots, z_{K-1}) = f^{-1}(\vec{x})$ maps from the probability simplex to a hypercube: $z_{l} = \log(x_{l}) - \log(x_{l+1} + ... + x_{K})$ For ease of derivation, I define the following: Let ${b_{l} = [1 + \exp(z_{l})]^{-1}}$ Let $c_{l} = 1 - b_{l} = [1 + \exp(-z_{l})]^{-1}$ Then, $$ x_{m} = \begin{cases} c_{1} & \text{if } m = 1 \\ \prod_{l=1}^{K-1} b_{l} & \text{if } m = K \\ c_{m} \prod_{l=1}^{m-1} b_{l} & \text{otherwise} \end{cases}$$ For $K = 3$ , $$ J = \left[ \begin{matrix}  a_{11} & a_{12} & 0  \\ a_{21} & a_{22} & 0  \\ a_{31} & a_{32} & 1  \\ \end{matrix} \right]$$ where $a_{ij} = \frac{\partial x_{i}}{\partial z_j}$ Since $a_{12} = 0$ , $ \det(J) = a_{11}a_{22}$ For higher K, only the diagonal terms contribute to the determinant. $-\log[\det(J)] = \sum_{l=1}^{K-1} (K-l)\log[b_{l}] + \log[c_{l}]$ By testing over many randomly selected values, I verify that the above expression is equivalent to the expression in section ""Absolute Jacobian Determinant of the Unit-Simplex Inverse Transform"" in Stan , which mentioned the Jacobian is triangular. But the manual and Betancourt 2010 didn't say the exact form of the Jacobian ...","is a vector of random variables in is probability density of . is a vector in is a vector of random variables in is probability density of . The goal is to find given and . When does the following trick work? For , where: The lower right corner of J is a block of identity matrix is determinant The explanation of the trick says it tries to augment the transform from: to and then integrate the extra dimensions out. What if ? If the trick doesn't always work, what is the general method to do this? Update: add an example Example ( Unit simplex transform or Stick breaking transform ) Let be a point on the probability simplex: The transformation maps from the probability simplex to a hypercube: For ease of derivation, I define the following: Let Let Then, For , where Since , For higher K, only the diagonal terms contribute to the determinant. By testing over many randomly selected values, I verify that the above expression is equivalent to the expression in section ""Absolute Jacobian Determinant of the Unit-Simplex Inverse Transform"" in Stan , which mentioned the Jacobian is triangular. But the manual and Betancourt 2010 didn't say the exact form of the Jacobian ...","\vec{X} \mathbb{R}^{n} \rho_{\vec{X}}(\vec{x}) \vec{X} \vec{y} = f(\vec{x}) \mathbb{R}^{m} \vec{Y} = f(\vec{X}) \mathbb{R}^{m} \rho_{\vec{Y}}(\vec{y}) \vec{Y} m \gt n \rho_{\vec{Y}}(\vec{y}) \rho_{\vec{X}}(\vec{x}) f(\vec{x}) \rho_{\vec{Y}}(\vec{y}) d\vec{y} = \rho_{\vec{X}}(\vec{x}) d\vec{x} \rho_{\vec{Y}}(\vec{y}) \det(\left \lvert J \right \rvert) = \rho_{\vec{X}}(\vec{x}) n = 2, m = 4  J = \left[ \begin{matrix} 
a_{11} & a_{12} & 0 & 0 \\
a_{21} & a_{22} & 0 & 0 \\
a_{31} & a_{32} & 1 & 0 \\
a_{41} & a_{42} & 0 & 1 \\
\end{matrix} \right]  a_{ij} = \frac{\partial{y_i}}{\partial{x_j}}  \det \vec{x} \rightarrow \vec{y} (x_{1}, x_{2}, y_{3}, y_{4}) \rightarrow (y_{1}, y_{2}, y_{3}, y_{4}) \frac{\partial y_{1}(\vec{x})}{\partial{y_3}(\vec{x})} \ne 0 \vec{x} = (x_1, x_2, x_3, \ldots, x_{K}) 0 \le x_{n} \le 1 x_1 + x_2 + x_3 + ... x_{K} = 1 \vec{z} = (z_{1}, \ldots, z_{K-1}) = f^{-1}(\vec{x}) z_{l} = \log(x_{l}) - \log(x_{l+1} + ... + x_{K}) {b_{l} = [1 + \exp(z_{l})]^{-1}} c_{l} = 1 - b_{l} = [1 + \exp(-z_{l})]^{-1}  x_{m} = \begin{cases}
c_{1} & \text{if } m = 1 \\
\prod_{l=1}^{K-1} b_{l} & \text{if } m = K \\
c_{m} \prod_{l=1}^{m-1} b_{l} & \text{otherwise}
\end{cases} K = 3  J = \left[ \begin{matrix} 
a_{11} & a_{12} & 0  \\
a_{21} & a_{22} & 0  \\
a_{31} & a_{32} & 1  \\
\end{matrix} \right] a_{ij} = \frac{\partial x_{i}}{\partial z_j} a_{12} = 0  \det(J) = a_{11}a_{22} -\log[\det(J)] = \sum_{l=1}^{K-1} (K-l)\log[b_{l}] + \log[c_{l}]","['calculus', 'probability', 'probability-theory', 'multivariable-calculus', 'monte-carlo']"
68,Book recommendation - probability with measure theory?,Book recommendation - probability with measure theory?,,"I am looking for a book that deals with the fundamentals of probability (e.g. probability spaces, distribution functions, expectation, etc.) but from a measure-theoretical perspective (e.g. defining the expectation in terms of the integral w.r.t. a measure derived from the CDF). My Background Probability: I have already taken basic and not-so-basic probability classes. These have dealt with the fundamentals of probability in a rather rigorous manner, so I am quite familiar with it. However, these courses have never involved measure theory more than simply discussing the Borel $\sigma$ -algebra. Measure theory: I have already taken a course that has dealt with the lebesgue measure very rigorously. I have also done some reading on my own about some basic measure theory (in particular the first chapter of Bogachev's Measure Theory). What I'm looking for: I always found it bizarre how expectation was defined differently for discrete and continuous random variables (and RVs that were neither were totally ignored). I then learned that this could be resolved by defining measures with the distribution functions, and integrating with respect to these measures. However, I never saw this explained fully, and I have not been able to find a book on probability that explains this either. I am looking for a book that starts from the very basics of probability and measure theory, and builds up probability using these tools. Preferably the book will also show how these general definitions become the simple ones we all know in special cases (e.g. if the measure is discrete, the expecation is just a sum). Thank you for any recommendations!","I am looking for a book that deals with the fundamentals of probability (e.g. probability spaces, distribution functions, expectation, etc.) but from a measure-theoretical perspective (e.g. defining the expectation in terms of the integral w.r.t. a measure derived from the CDF). My Background Probability: I have already taken basic and not-so-basic probability classes. These have dealt with the fundamentals of probability in a rather rigorous manner, so I am quite familiar with it. However, these courses have never involved measure theory more than simply discussing the Borel -algebra. Measure theory: I have already taken a course that has dealt with the lebesgue measure very rigorously. I have also done some reading on my own about some basic measure theory (in particular the first chapter of Bogachev's Measure Theory). What I'm looking for: I always found it bizarre how expectation was defined differently for discrete and continuous random variables (and RVs that were neither were totally ignored). I then learned that this could be resolved by defining measures with the distribution functions, and integrating with respect to these measures. However, I never saw this explained fully, and I have not been able to find a book on probability that explains this either. I am looking for a book that starts from the very basics of probability and measure theory, and builds up probability using these tools. Preferably the book will also show how these general definitions become the simple ones we all know in special cases (e.g. if the measure is discrete, the expecation is just a sum). Thank you for any recommendations!",\sigma,"['probability', 'measure-theory', 'book-recommendation']"
69,The probability of winning a peculiar dice game,The probability of winning a peculiar dice game,,"I'm a high school teacher, and students in my probability class created the following fun conundrum. We've been stuck on it for a couple of weeks: Consider this dice game played with one fair $n$ -sided dice. On the first turn, a roll of $n$ wins, while a roll of $1$ loses. On any other result, the player rolls again. On the 2nd roll, a roll of $n$ wins, while a roll of $1$ or $2$ loses. On any other roll, the game continues. On roll $k$ , the player wins with a roll of $n$ and loses with a roll of $k$ or below. What is the probability of winning as $n \to \infty$ ?. The game must be won in no more than $n - 1$ turns, and for any given $n$ , $$ \mathrm{P}\left(win\right) = {1 \over n} + \sum_{i = 2}^{n - 1}\frac{\left(n - 2\right)!}{\left(n - i - 1\right)!\, n^{i}} $$ Here is where I'm stuck. Does: $$ \lim_{n \to \infty}\mathrm{P}\left(win\right) = 0? $$ or does $\mathrm{P}\left(win\right)$ converge on some other nonzero probability as $n \to \infty$ ?. How might one show this?.","I'm a high school teacher, and students in my probability class created the following fun conundrum. We've been stuck on it for a couple of weeks: Consider this dice game played with one fair -sided dice. On the first turn, a roll of wins, while a roll of loses. On any other result, the player rolls again. On the 2nd roll, a roll of wins, while a roll of or loses. On any other roll, the game continues. On roll , the player wins with a roll of and loses with a roll of or below. What is the probability of winning as ?. The game must be won in no more than turns, and for any given , Here is where I'm stuck. Does: or does converge on some other nonzero probability as ?. How might one show this?.","n n 1 n 1 2 k n k n \to \infty n - 1 n 
\mathrm{P}\left(win\right)
=
{1 \over n} +
\sum_{i = 2}^{n - 1}\frac{\left(n - 2\right)!}{\left(n - i - 1\right)!\, n^{i}}
 
\lim_{n \to \infty}\mathrm{P}\left(win\right) = 0?
 \mathrm{P}\left(win\right) n \to \infty","['probability', 'sequences-and-series', 'convergence-divergence']"
70,"Picking $6$ numbers from $\{1, \ldots, 49\}$, what is the chance that the difference between at least $2$ of them is $= 1$?","Picking  numbers from , what is the chance that the difference between at least  of them is ?","6 \{1, \ldots, 49\} 2 = 1","You choose $6$ different natural numbers from $\{1, \ldots, 49\}$ . What is the probability that at least $2$ of these numbers have a difference equal to $1$ ? E.g. $1, 2, 10, 20, 30, 31$ - you'd have $2$ pairs $(1,2), (30,31)$ with the difference $= 1$ . I tried solving it by taking the inverse probability $P(\neg A)$ < No $2$ numbers have a difference of $1$ >, however, I encounter some difficulties with some special cases. For the first number, you'd have $49$ options. For the second number however, you'd have $46$ options (removing the previous number, and the $2$ surrounding it - which would give a diff. of $1$ ). However if the first number was $1$ or $49$ , you'd have $47$ options for the your second number, as there could only be $1$ number that would give you a diff of $1$ ( $2/48$ ). It only gets more complicated if two numbers are $x$ and $x+2$ , because the next number cannot be $\{x-1,x+1,x+3\}$ . Thank you.","You choose different natural numbers from . What is the probability that at least of these numbers have a difference equal to ? E.g. - you'd have pairs with the difference . I tried solving it by taking the inverse probability < No numbers have a difference of >, however, I encounter some difficulties with some special cases. For the first number, you'd have options. For the second number however, you'd have options (removing the previous number, and the surrounding it - which would give a diff. of ). However if the first number was or , you'd have options for the your second number, as there could only be number that would give you a diff of ( ). It only gets more complicated if two numbers are and , because the next number cannot be . Thank you.","6 \{1, \ldots, 49\} 2 1 1, 2, 10, 20, 30, 31 2 (1,2), (30,31) = 1 P(\neg A) 2 1 49 46 2 1 1 49 47 1 1 2/48 x x+2 \{x-1,x+1,x+3\}","['probability', 'combinatorics']"
71,Is every filtration the natural filtration of some stochastic process?,Is every filtration the natural filtration of some stochastic process?,,"We have a notion of natural filtrations, which intuitively represents the history of the process as the process evolves over time. We also have a notion of filtrations in general, which are increasing sequence of sub-sigma algebras. Naturally, the latter concept is more abstract than the former, and I am having trouble getting a concrete grip on the latter. In particular, if we have a stochastic process X, and a filter F, I tend to look at F as a natural filtration (although we only know it's a filtration in general, and not necessarily a natural one) of some other process Y. Can we do that? As to why I am doing what I am doing, in many practical scenarios (like quantitative finance, which I am studying), we would be directly observing the process Y (say Y is the share price process) and hence our information would be the natural filtration of Y, but we might be interested in a slightly different process X (which might be the log of the share price or some other functional transformation say). In this scenario, the natural filtration of Y is simply a filtration from the perspective of X , and not a natural one. Thanks a lot in advance!","We have a notion of natural filtrations, which intuitively represents the history of the process as the process evolves over time. We also have a notion of filtrations in general, which are increasing sequence of sub-sigma algebras. Naturally, the latter concept is more abstract than the former, and I am having trouble getting a concrete grip on the latter. In particular, if we have a stochastic process X, and a filter F, I tend to look at F as a natural filtration (although we only know it's a filtration in general, and not necessarily a natural one) of some other process Y. Can we do that? As to why I am doing what I am doing, in many practical scenarios (like quantitative finance, which I am studying), we would be directly observing the process Y (say Y is the share price process) and hence our information would be the natural filtration of Y, but we might be interested in a slightly different process X (which might be the log of the share price or some other functional transformation say). In this scenario, the natural filtration of Y is simply a filtration from the perspective of X , and not a natural one. Thanks a lot in advance!",,"['probability', 'measure-theory', 'filtrations']"
72,Variance of a sub-Gaussian random variable,Variance of a sub-Gaussian random variable,,"For a zero mean sub-Gaussian R.V. we know that: $$ \mathbb{E}[e^{\lambda X}]\le e^{\frac{\lambda^2\sigma^2}{2}},\qquad\forall\lambda\in \mathbb{R}$$ From Taylor series expansion and equating the terms of the same power for $\lambda$ it can be easily obtained that: $$\mathbb{E}[X^2]\le \sigma^2$$ Is it possible to prove that $\mathbb{E}[X^2]=\sigma^2$ for the minimum $\sigma^2$ that the inequality $ \mathbb{E}[e^{\lambda X}]\le e^{\frac{\lambda^2\sigma^2}{2}}$ holds?",For a zero mean sub-Gaussian R.V. we know that: From Taylor series expansion and equating the terms of the same power for it can be easily obtained that: Is it possible to prove that for the minimum that the inequality holds?," \mathbb{E}[e^{\lambda X}]\le e^{\frac{\lambda^2\sigma^2}{2}},\qquad\forall\lambda\in \mathbb{R} \lambda \mathbb{E}[X^2]\le \sigma^2 \mathbb{E}[X^2]=\sigma^2 \sigma^2  \mathbb{E}[e^{\lambda X}]\le e^{\frac{\lambda^2\sigma^2}{2}}","['probability', 'inequality', 'random-variables', 'moment-generating-functions']"
73,Approximate Borel set by compact set,Approximate Borel set by compact set,,"I have proven the following: Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $\mathcal{A}$ an algebra such that $\sigma(\mathcal{A})=\mathcal{F}$ . Then for every $\varepsilon>0$ and $B\in\mathcal{F}$ we got that there is a set $A\in\mathcal{A}$ such that $\mathbb{P}(A\Delta B)\leq \varepsilon$ . (here $\Delta$ is the symmetric difference) I want to show: Let $\mathbb{P}$ be a probability measure on $(\mathbb{R}^{n},\mathcal{B}(\mathbb{R}^{n}))$ , where $\mathcal{B}(\mathbb{R}^{n})$ is the Borel algebra of subsets of $\mathbb{R}^{n}$ . Using the previous fact, show that for any $\varepsilon>0$ and $B\in\mathcal{B}(\mathbb{R}^{n})$ , that there is a compact set $A\in\mathcal{B}(\mathbb{R}^{n})$ such that $A\subseteq B$ and $\mathbb{P}(B\setminus A) \leq \varepsilon$ . Any suggestions?","I have proven the following: Let be a probability space and an algebra such that . Then for every and we got that there is a set such that . (here is the symmetric difference) I want to show: Let be a probability measure on , where is the Borel algebra of subsets of . Using the previous fact, show that for any and , that there is a compact set such that and . Any suggestions?","(\Omega,\mathcal{F},\mathbb{P}) \mathcal{A} \sigma(\mathcal{A})=\mathcal{F} \varepsilon>0 B\in\mathcal{F} A\in\mathcal{A} \mathbb{P}(A\Delta B)\leq \varepsilon \Delta \mathbb{P} (\mathbb{R}^{n},\mathcal{B}(\mathbb{R}^{n})) \mathcal{B}(\mathbb{R}^{n}) \mathbb{R}^{n} \varepsilon>0 B\in\mathcal{B}(\mathbb{R}^{n}) A\in\mathcal{B}(\mathbb{R}^{n}) A\subseteq B \mathbb{P}(B\setminus A) \leq \varepsilon","['probability', 'probability-theory', 'measure-theory']"
74,What is the asymptotic order of $\sum_{k=0}^n {n\choose k}^2$?,What is the asymptotic order of ?,\sum_{k=0}^n {n\choose k}^2,"What is the asymptotic order of $\sum_{k=0}^n {n\choose k}^2$ ? That is, find $g(n)$ such that $$\lim_{n\to \infty}\frac{\sum_{k=0}^n {n\choose k}^2}{g(n)}=1$$ We can expand the binomial coefficient and use Stirling's approximation but I can not determine g(n).","What is the asymptotic order of ? That is, find such that We can expand the binomial coefficient and use Stirling's approximation but I can not determine g(n).",\sum_{k=0}^n {n\choose k}^2 g(n) \lim_{n\to \infty}\frac{\sum_{k=0}^n {n\choose k}^2}{g(n)}=1,"['probability', 'asymptotics']"
75,IID random variables $(X_n)$ have $\sum e^{X_n} c^n < \infty$ a.s.,IID random variables  have  a.s.,(X_n) \sum e^{X_n} c^n < \infty,"I'm working on the following exercise: Let $X_1, X_2, \ldots$ be i.i.d. nonnegative random variables. By virtue of the Borel-Cantelli lemma, show that for every $c \in (0,1)$ , $$ \sum_{n=1}^\infty  e^{X_n} c^n \begin{cases} < \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] < \infty; \\ = \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] = \infty \end{cases} $$ I'm trying to show $\sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty$ for some large $M > 0$ . For then, Borel-Cantelli gives us that $$ \mathbb P\left[\limsup \left\{ \sum_{k=1}^n e^{X_k} c^k \geq M\right\}\right] = \mathbb P\left[\sum_{k=1}^\infty e^{X_k} c^k \geq M\right] = 0$$ and we're done. But I don't know how to show $\sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty$ . Any suggestions?","I'm working on the following exercise: Let be i.i.d. nonnegative random variables. By virtue of the Borel-Cantelli lemma, show that for every , I'm trying to show for some large . For then, Borel-Cantelli gives us that and we're done. But I don't know how to show . Any suggestions?","X_1, X_2, \ldots c \in (0,1) 
\sum_{n=1}^\infty  e^{X_n} c^n \begin{cases}
< \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] < \infty; \\
= \infty \textrm{ a.s.} & \textrm{if } \mathbb E[X_1] = \infty
\end{cases}
 \sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty M > 0  \mathbb P\left[\limsup \left\{ \sum_{k=1}^n e^{X_k} c^k \geq M\right\}\right] = \mathbb P\left[\sum_{k=1}^\infty e^{X_k} c^k \geq M\right] = 0 \sum_{n=1}^\infty \mathbb P\left[\sum_{k=1}^n e^{X_k} c^k \geq M\right] < \infty","['probability', 'probability-theory', 'measure-theory', 'convergence-divergence', 'borel-cantelli-lemmas']"
76,"A coin is weighted, such that the probability of heads in any given toss is twice that of tails.","A coin is weighted, such that the probability of heads in any given toss is twice that of tails.",,"A coin is weighted, such that the probability of heads in any given toss is twice that of tails. A player tosses two such coins. The player wins 4 if 2 tails occur and 1 if 1 tail occurs. The player should lose less than what amount of money if no tails occur for the game to be favourable to the player? What I have done so far: $P(H) + P(T) = 1$ $P(H) = 2P(T)$ $1 = 2P(T) + P(T)$ $P(T) = 1/3$ $2P(T) = P(H) = 2/3$","A coin is weighted, such that the probability of heads in any given toss is twice that of tails. A player tosses two such coins. The player wins 4 if 2 tails occur and 1 if 1 tail occurs. The player should lose less than what amount of money if no tails occur for the game to be favourable to the player? What I have done so far:",P(H) + P(T) = 1 P(H) = 2P(T) 1 = 2P(T) + P(T) P(T) = 1/3 2P(T) = P(H) = 2/3,[]
77,"A box contains 10 balls, which are 6 W and 4 B. Assume you pick one by one, without replacement","A box contains 10 balls, which are 6 W and 4 B. Assume you pick one by one, without replacement",,"What is the probability that only $1$ out of the first $4$ you picked are black? So it is clear that we have picked $4$ balls. Our $4$ spots can be as follows: $\mathrm{BWWW}$ $\mathrm{WBWW}$ $\mathrm{WWBW}$ $\mathrm{WWWB}$ $4$ ways to orient this. There are $6$ W balls, from those we must pick $3$ . There are $4$ B balls, from those we must pick $1$ . Thus: $$\frac{\displaystyle\binom{6}{3}\binom{4}{1}}{\displaystyle\binom{10}{4}}$$ Is this correct?","What is the probability that only out of the first you picked are black? So it is clear that we have picked balls. Our spots can be as follows: ways to orient this. There are W balls, from those we must pick . There are B balls, from those we must pick . Thus: Is this correct?",1 4 4 4 \mathrm{BWWW} \mathrm{WBWW} \mathrm{WWBW} \mathrm{WWWB} 4 6 3 4 1 \frac{\displaystyle\binom{6}{3}\binom{4}{1}}{\displaystyle\binom{10}{4}},"['probability', 'statistics', 'probability-distributions']"
78,Confusion about distribution of marbles among 5 persons. Example by Kahneman and Tversky,Confusion about distribution of marbles among 5 persons. Example by Kahneman and Tversky,,"I came across the article Subjective Probability: A Judgment of Representativeness   Daniel Kahneman and Amos Tversky and in particular their following example I have a lot of difficulties in understanding the question In many rounds of the game, will there be more results of type I or of type II? My difficulties are the following. IMHO the question leads to misunderstandings. There are two possible scenarios that I'm considering. 1 case: Does the order of the numbers play a role? If so, than, it should be equally likely to get the event $$44543 \qquad \text{or} \qquad 44444$$ 2 case: Does the order of the numbers not play a role? If so, than it is way more likely, to get the event containing three $4$, one $5$ and one $3$, than to get all five $4$s. This is because the number of strings of length $5$ containing three $4$, one $5$ and one $3$ is $$\frac{5!}{3!} = 5\cdot 4 = 20.$$ The problem is that I don't see any other scenario, but the author says The uniform distribution of marbles II (so the event that we get five $4$s) is, objectively, more probable than the nonuniform distribution I. I looked out what it meant for him the word ""objectively"" and it is intended to be as precise as a mathematical explanation should be.","I came across the article Subjective Probability: A Judgment of Representativeness   Daniel Kahneman and Amos Tversky and in particular their following example I have a lot of difficulties in understanding the question In many rounds of the game, will there be more results of type I or of type II? My difficulties are the following. IMHO the question leads to misunderstandings. There are two possible scenarios that I'm considering. 1 case: Does the order of the numbers play a role? If so, than, it should be equally likely to get the event $$44543 \qquad \text{or} \qquad 44444$$ 2 case: Does the order of the numbers not play a role? If so, than it is way more likely, to get the event containing three $4$, one $5$ and one $3$, than to get all five $4$s. This is because the number of strings of length $5$ containing three $4$, one $5$ and one $3$ is $$\frac{5!}{3!} = 5\cdot 4 = 20.$$ The problem is that I don't see any other scenario, but the author says The uniform distribution of marbles II (so the event that we get five $4$s) is, objectively, more probable than the nonuniform distribution I. I looked out what it meant for him the word ""objectively"" and it is intended to be as precise as a mathematical explanation should be.",,"['probability', 'combinatorics']"
79,What is the Probability of Choosing 3 Specific Balls from a 15-Ball Set?,What is the Probability of Choosing 3 Specific Balls from a 15-Ball Set?,,"My high school geometry textbook includes the following problem as an example: Three pool balls are chosen at random from a set numbered from 1 to 15.  What is the probability that the pool balls chosen are numbered 5, 7, and 9? My answer is $\frac{1}{455}$.  The text book's answer is $\frac{6}{455}$. Which answer is correct? I arrive at my answer, as follows: The probability of the desired result is the ratio of the number of outcomes that yield the desired result to the total number of possible outcomes. The desired result, balls 5, 7 and 9, together form a single 3-ball combination; a single outcome: $$ 1 $$ The total number of possible 3-ball combinations is: $$ \frac{15!}{3!(15-3)!} = \frac{(15 \cdot 14 \cdot 13)}{6} = \frac{2730}{6} = 455 $$ Thus, the ratio described in (1), above, is $1\colon455$, and the answer is: $$ \frac{1}{455} $$ There are at least two alternative approaches that yield the same answer: Rather than using combinations, one might use permutations, in which case the numerator is the $3!$ permutations that yield the desired result, and the denominator  is the $\frac{15!}{(15-3)!}$ permutations that could occur in choosing 3 balls, which is equal to $\frac{6}{2730}$ = $\frac{1}{455}$. Or, one could use the product of the odds of each selection being a success:  $\frac{3}{15} \cdot \frac{2}{14} \cdot \frac{1}{13}$ = $\frac{6}{2730}$ = $\frac{1}{455}$. HOWEVER , my textbook says the solution is: $$ \frac{3!}{\frac{15!}{3!(15 - 3)!}} = \frac{6}{455} $$ The textbook's statement of the problem and solution is here: Lesson 13-3, Permutations and Combinations: Problem 6 .  I believe the textbook's solution compares a number of permutations in the numerator to a number of combinations in the denominator, which seems to me to be a matter of apples and oranges.","My high school geometry textbook includes the following problem as an example: Three pool balls are chosen at random from a set numbered from 1 to 15.  What is the probability that the pool balls chosen are numbered 5, 7, and 9? My answer is $\frac{1}{455}$.  The text book's answer is $\frac{6}{455}$. Which answer is correct? I arrive at my answer, as follows: The probability of the desired result is the ratio of the number of outcomes that yield the desired result to the total number of possible outcomes. The desired result, balls 5, 7 and 9, together form a single 3-ball combination; a single outcome: $$ 1 $$ The total number of possible 3-ball combinations is: $$ \frac{15!}{3!(15-3)!} = \frac{(15 \cdot 14 \cdot 13)}{6} = \frac{2730}{6} = 455 $$ Thus, the ratio described in (1), above, is $1\colon455$, and the answer is: $$ \frac{1}{455} $$ There are at least two alternative approaches that yield the same answer: Rather than using combinations, one might use permutations, in which case the numerator is the $3!$ permutations that yield the desired result, and the denominator  is the $\frac{15!}{(15-3)!}$ permutations that could occur in choosing 3 balls, which is equal to $\frac{6}{2730}$ = $\frac{1}{455}$. Or, one could use the product of the odds of each selection being a success:  $\frac{3}{15} \cdot \frac{2}{14} \cdot \frac{1}{13}$ = $\frac{6}{2730}$ = $\frac{1}{455}$. HOWEVER , my textbook says the solution is: $$ \frac{3!}{\frac{15!}{3!(15 - 3)!}} = \frac{6}{455} $$ The textbook's statement of the problem and solution is here: Lesson 13-3, Permutations and Combinations: Problem 6 .  I believe the textbook's solution compares a number of permutations in the numerator to a number of combinations in the denominator, which seems to me to be a matter of apples and oranges.",,"['probability', 'combinatorics', 'permutations', 'combinations']"
80,Two points of a square $K$ determine a diagonal of another square that is contained in $K$,Two points of a square  determine a diagonal of another square that is contained in,K K,"Let $K:=[0,1]^2$ be a square on $\mathbb{R}^{2}$ . We select 2 random points $A$ , $B$ $\in [0,1]^{2}$ in this square. What is the probability that the square whose diagonal is the line segment $AB$ , is contained in $K$ ? I found that if we fix coordinates of $A=(x,y)\in [0,1]^{2}$ , then the probability equals $$\int\limits_{0}^{1}\int\limits_{0}^{1}[1-(x-y)^{2}-(1-x-y)^{2}\times\textbf{1}(x+y<1)]dxdy \, ,$$ where: $\textbf{1}(x+y<1):=1$ if $x+y<1$ and $\textbf{1}(x+y<1):=0$ otherwise. Some attempts(or some elements of stream of consciousness) I tackled other problems from geometric probability, but this problem cannot be solved by standard methods(i.e. by finding dependency between given information in question, then making, at least, rough plot on cartesian coordinate system and integrate the area under the graph of detected dependencies within specific constraints). I have completely, even intuitively, idea how to come towards such solution. The only thing, which comes to my mind, is that in this problem we should consider complement of given event, i.e. set of these points that determine square not contained completely in the square $K$ . This may account for minus signs. So, presumably, the probability that we choose inapropriately is $$\int\limits_{0}^{1}\int\limits_{0}^{1}[(x-y)^{2} + (1-x-y)^{2}\times\textbf{1}(x+y<1)] dxdy $$ However, this is just intuition after solving hitherto plenty of problems from, let say, ""elementary"" probability... Motivation for knowing method of solving this problem I am very interested in getting to know how to derive quite rigorously solution to this problem. I would be very thankful for help. Note : this question is neither from any current mathematical contest nor a part of any ""homework""/""coursework"".","Let be a square on . We select 2 random points , in this square. What is the probability that the square whose diagonal is the line segment , is contained in ? I found that if we fix coordinates of , then the probability equals where: if and otherwise. Some attempts(or some elements of stream of consciousness) I tackled other problems from geometric probability, but this problem cannot be solved by standard methods(i.e. by finding dependency between given information in question, then making, at least, rough plot on cartesian coordinate system and integrate the area under the graph of detected dependencies within specific constraints). I have completely, even intuitively, idea how to come towards such solution. The only thing, which comes to my mind, is that in this problem we should consider complement of given event, i.e. set of these points that determine square not contained completely in the square . This may account for minus signs. So, presumably, the probability that we choose inapropriately is However, this is just intuition after solving hitherto plenty of problems from, let say, ""elementary"" probability... Motivation for knowing method of solving this problem I am very interested in getting to know how to derive quite rigorously solution to this problem. I would be very thankful for help. Note : this question is neither from any current mathematical contest nor a part of any ""homework""/""coursework"".","K:=[0,1]^2 \mathbb{R}^{2} A B \in [0,1]^{2} AB K A=(x,y)\in [0,1]^{2} \int\limits_{0}^{1}\int\limits_{0}^{1}[1-(x-y)^{2}-(1-x-y)^{2}\times\textbf{1}(x+y<1)]dxdy \, , \textbf{1}(x+y<1):=1 x+y<1 \textbf{1}(x+y<1):=0 K \int\limits_{0}^{1}\int\limits_{0}^{1}[(x-y)^{2} + (1-x-y)^{2}\times\textbf{1}(x+y<1)] dxdy ","['probability', 'contest-math', 'recreational-mathematics', 'geometric-probability']"
81,Probability of at least two being grey,Probability of at least two being grey,,"Say we have $11$ grey and $15$ white mice, so $26$ in total in a container we can't see. We want to take $5$ of them home. What is the probability of at least two of them being grey ? 2 grey: The probability of the first being grey is $\frac{11}{26}$ the second grey is $\frac{10}{25}$, the last three white $\frac{15\cdot 14 \cdot 13}{24\cdot 23\cdot 22}$. 3 grey: $\frac{11\cdot 10 \cdot 9 \cdot 15\cdot 14\cdot 13}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 4 grey: $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 15\cdot 14}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 5 grey:  $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 7\cdot 15}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ And the probability of at least $2$ grey is the sum of these?","Say we have $11$ grey and $15$ white mice, so $26$ in total in a container we can't see. We want to take $5$ of them home. What is the probability of at least two of them being grey ? 2 grey: The probability of the first being grey is $\frac{11}{26}$ the second grey is $\frac{10}{25}$, the last three white $\frac{15\cdot 14 \cdot 13}{24\cdot 23\cdot 22}$. 3 grey: $\frac{11\cdot 10 \cdot 9 \cdot 15\cdot 14\cdot 13}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 4 grey: $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 15\cdot 14}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ 5 grey:  $\frac{11\cdot 10 \cdot 9 \cdot 8 \cdot 7\cdot 15}{26\cdot 25\cdot 24\cdot 23\cdot 22}$ And the probability of at least $2$ grey is the sum of these?",,['probability']
82,Symmetric random walk passes through 1,Symmetric random walk passes through 1,,"I am working on the following problem (which I couldn't find on the website so far): Show that a symmetric random walk ($1$ dimensional) starting from the origin visits the point $1$ with probability $1$. My attempt so far (an adaptation of the recurrence proof from Probability An Introduction $2^{nd}$ edition by Grimmett and Welsh -p.170). Let $S_n$ be the r.v. which represents where (on the $X$-axis) the random walk is at time $n$. And let $X_n$ be the random variable representing the move that has happened at time $n$. Of course, $X_i=\pm1$ and $$ P(X_i=1) = P(X_i=-1)=\frac{1}{2} \mbox{ as it is symmetric} $$ Hence, we can write $S_n = X_1 + \dots + X_n$. In order to be at point $1$ we would need to have had an odd number of moves ($m+1$ to the right and $m$ to the left). Hence we cannot be at point $1$ after an even number of moves. Hence, $$ P(S_{2m}=1) = 0, \mbox{  } m\geq0 \tag{1} $$ and  $$ P(S_{2m+1} = 1) = \binom{2m+1}{m}\frac{1}{2^{2m+1}}, \mbox{ } m\geq0 \tag{2} $$ Let, now, $A_n = \left \{ S_n = 1\right \}$ for the event that the walk visits point $1$ at time $n$, and: $$ B_n = \left\{ S_n = 1, S_k\neq1 \mbox{ for } 1\leq k\leq n-1 \right\} $$ for the event that the first visit of the walk through point $1$ occurs at time $n$. If $A_n$ occurs, then exactly one of $B_1, \dots , B_n$ occurs, giving that: $$ P(A_n) = \sum_{k=1}^{n}P(A_n\cap B_k). $$ Now, $A_n\cap B_k$ is the event that the walk goes through $1$ for the first time at time $k$ and then again in another $n-k$ steps. Hence: $$ P(A_n\cap B_k) = P(B_k)P(A_{n-k}), \mbox{for } 2\leq k \leq n \tag{3} $$ I have doubts that in the equation above, the boundaries are correct i.e. not sure if $n\geq 2$ since transitions in disjoint intervals of time are independent of each other. We write $f_n = P(B_n)$ and $u_n = P(A_n)$. Hence, from the above equations we get that: $$ u_n = \sum_{k=2}^{n} f_{k}u_{n-k}, \mbox{ for } n=1,2,\dots $$ We know the $u_i$s from $(1)$ and $(2)$ and we want to find the $f_k$. Given that the summation we got above is a convolution, we can use probability generating functions.  $$ U(s) = \sum_{n=0}^{\infty}u_ns^n $$ $$ F(s) = \sum_{n=0}^{\infty}f_ns^n $$ noting that $u_0 = 0$ and $f_0 = 0$, we have, from $(3)$ that: $$ \sum_{n=2}^{\infty}u_ns^n = F(s)U(s) $$  Hence $U(s) - \frac{1}{2}s = F(s)U(s)$. Hence  $$F(s) = 1 - \frac{1}{2sU(s)} $$ And we can find out (not so easily), that: $$ U(s) = \frac{1-\sqrt{1-s^2}}{s\sqrt{1-s^2}}, |s|<1  $$ Hence,  $$ F(s) = 1-\frac{s\sqrt{1-s^2}}{2s-2s\sqrt{1-s^2}}, |s|<1  $$ We get the probability we are interested in by taking the limit in the above equation as $s\to 1$, which yields $1$. I am not sure if I manipulated the (summation) indexes correctly. I would appreciate comments on this proof as well as an alternative proof if anybody knows one.","I am working on the following problem (which I couldn't find on the website so far): Show that a symmetric random walk ($1$ dimensional) starting from the origin visits the point $1$ with probability $1$. My attempt so far (an adaptation of the recurrence proof from Probability An Introduction $2^{nd}$ edition by Grimmett and Welsh -p.170). Let $S_n$ be the r.v. which represents where (on the $X$-axis) the random walk is at time $n$. And let $X_n$ be the random variable representing the move that has happened at time $n$. Of course, $X_i=\pm1$ and $$ P(X_i=1) = P(X_i=-1)=\frac{1}{2} \mbox{ as it is symmetric} $$ Hence, we can write $S_n = X_1 + \dots + X_n$. In order to be at point $1$ we would need to have had an odd number of moves ($m+1$ to the right and $m$ to the left). Hence we cannot be at point $1$ after an even number of moves. Hence, $$ P(S_{2m}=1) = 0, \mbox{  } m\geq0 \tag{1} $$ and  $$ P(S_{2m+1} = 1) = \binom{2m+1}{m}\frac{1}{2^{2m+1}}, \mbox{ } m\geq0 \tag{2} $$ Let, now, $A_n = \left \{ S_n = 1\right \}$ for the event that the walk visits point $1$ at time $n$, and: $$ B_n = \left\{ S_n = 1, S_k\neq1 \mbox{ for } 1\leq k\leq n-1 \right\} $$ for the event that the first visit of the walk through point $1$ occurs at time $n$. If $A_n$ occurs, then exactly one of $B_1, \dots , B_n$ occurs, giving that: $$ P(A_n) = \sum_{k=1}^{n}P(A_n\cap B_k). $$ Now, $A_n\cap B_k$ is the event that the walk goes through $1$ for the first time at time $k$ and then again in another $n-k$ steps. Hence: $$ P(A_n\cap B_k) = P(B_k)P(A_{n-k}), \mbox{for } 2\leq k \leq n \tag{3} $$ I have doubts that in the equation above, the boundaries are correct i.e. not sure if $n\geq 2$ since transitions in disjoint intervals of time are independent of each other. We write $f_n = P(B_n)$ and $u_n = P(A_n)$. Hence, from the above equations we get that: $$ u_n = \sum_{k=2}^{n} f_{k}u_{n-k}, \mbox{ for } n=1,2,\dots $$ We know the $u_i$s from $(1)$ and $(2)$ and we want to find the $f_k$. Given that the summation we got above is a convolution, we can use probability generating functions.  $$ U(s) = \sum_{n=0}^{\infty}u_ns^n $$ $$ F(s) = \sum_{n=0}^{\infty}f_ns^n $$ noting that $u_0 = 0$ and $f_0 = 0$, we have, from $(3)$ that: $$ \sum_{n=2}^{\infty}u_ns^n = F(s)U(s) $$  Hence $U(s) - \frac{1}{2}s = F(s)U(s)$. Hence  $$F(s) = 1 - \frac{1}{2sU(s)} $$ And we can find out (not so easily), that: $$ U(s) = \frac{1-\sqrt{1-s^2}}{s\sqrt{1-s^2}}, |s|<1  $$ Hence,  $$ F(s) = 1-\frac{s\sqrt{1-s^2}}{2s-2s\sqrt{1-s^2}}, |s|<1  $$ We get the probability we are interested in by taking the limit in the above equation as $s\to 1$, which yields $1$. I am not sure if I manipulated the (summation) indexes correctly. I would appreciate comments on this proof as well as an alternative proof if anybody knows one.",,"['probability', 'proof-verification', 'stochastic-processes', 'random-walk']"
83,Probability of two friends sit one near the other,Probability of two friends sit one near the other,,"Probability of two friends sitting together Hi, I have the following problem and I would like to ensure that I solved it correctly. In a class-room there are 4 rows of chairs, 3 chairs per raw. The teacher randomly allocates 12 pupils to 12 possible chairs. John and Jack are two friends. What is the probability that they will sit one near the other (i.e., the adjacent chairs of the same row)? My solution:  1) For each row, there are 2 solutions that satisfy  John and Jack (unordered; I do not care where each one sits). There are 4 rows. So, number of satisfactory solutions is: 2 x 4 = 8 2) Total number of possibilities John and Jack might sit (unordered sampling) is: 12! / 10! * 2 ! = 66. 3) Probability is: 8 / 66 = 0.121 Am I right? Many thanks.","Probability of two friends sitting together Hi, I have the following problem and I would like to ensure that I solved it correctly. In a class-room there are 4 rows of chairs, 3 chairs per raw. The teacher randomly allocates 12 pupils to 12 possible chairs. John and Jack are two friends. What is the probability that they will sit one near the other (i.e., the adjacent chairs of the same row)? My solution:  1) For each row, there are 2 solutions that satisfy  John and Jack (unordered; I do not care where each one sits). There are 4 rows. So, number of satisfactory solutions is: 2 x 4 = 8 2) Total number of possibilities John and Jack might sit (unordered sampling) is: 12! / 10! * 2 ! = 66. 3) Probability is: 8 / 66 = 0.121 Am I right? Many thanks.",,"['probability', 'combinatorics']"
84,Why isn't the probability that Alice will have classes every weekday $\dfrac{5\times \binom{5}{2}}{30\choose 7}$? [duplicate],Why isn't the probability that Alice will have classes every weekday ? [duplicate],\dfrac{5\times \binom{5}{2}}{30\choose 7},"This question already has an answer here : Why isn't the probability that Alice will have classes every weekday $\dfrac{6^5 \times 25 \times 24}{30\choose 7}$?? (1 answer) Closed 2 years ago . Blitzstein's Introduction to Probability (2019 2 ed) Ch 1, Exercise 54, p 51. Alice attends a small college in which each class meets only once a week. She is deciding between $30$ non-overlapping classes. There are $6$ classes to choose from for each day of the week, Monday through Friday. Trusting in the benevolence of randomness, Alice decides to register for $7$ randomly selected classes out of the $30$ , with all choices equally likely. What is the probability that she will have classes every day, Monday through Friday? $($ This problem can be done either directly using the naive definition of probability, or using inclusion-exclusion. $)$ My thinking was to first assign one class to each of the $5$ days, $6^5$ ways of doing this. Then multiply this with the probability of selecting remain $2$ classes such that $a)$ either they both are on the same day, or $b)$ on two different days. Probability for $(a)= 5\times \binom{5}{2}$ . Prob. of $(b)=\binom{5}{2}\times 5$ . This gives total no. of ways to assign classes as required. Then divide this by $\binom{30}{7}$ $($ total no of ways to assign classes randomly $)$ . But this gives a probability greater than $1$ . Where is my thinking wrong? All classes are equally likely, and I don't think the process of choosing follows order of days.","This question already has an answer here : Why isn't the probability that Alice will have classes every weekday $\dfrac{6^5 \times 25 \times 24}{30\choose 7}$?? (1 answer) Closed 2 years ago . Blitzstein's Introduction to Probability (2019 2 ed) Ch 1, Exercise 54, p 51. Alice attends a small college in which each class meets only once a week. She is deciding between non-overlapping classes. There are classes to choose from for each day of the week, Monday through Friday. Trusting in the benevolence of randomness, Alice decides to register for randomly selected classes out of the , with all choices equally likely. What is the probability that she will have classes every day, Monday through Friday? This problem can be done either directly using the naive definition of probability, or using inclusion-exclusion. My thinking was to first assign one class to each of the days, ways of doing this. Then multiply this with the probability of selecting remain classes such that either they both are on the same day, or on two different days. Probability for . Prob. of . This gives total no. of ways to assign classes as required. Then divide this by total no of ways to assign classes randomly . But this gives a probability greater than . Where is my thinking wrong? All classes are equally likely, and I don't think the process of choosing follows order of days.",30 6 7 30 ( ) 5 6^5 2 a) b) (a)= 5\times \binom{5}{2} (b)=\binom{5}{2}\times 5 \binom{30}{7} ( ) 1,['probability']
85,Convergence of conditional expectations given a sequence of random variables,Convergence of conditional expectations given a sequence of random variables,,"I am trying to prove the following statemt: Let $(\Omega, \mathcal A, P)$ be a probability space. Let $(Z_n)_{n\in \mathbb N}$ be i.i.d. random variables with $Z_1 \in \mathcal L^1$. Let $\theta \in \mathcal L^1$ be independent from $(Z_n)_{n\in \mathbb N}$ and define $\forall n\in \mathbb N: Y_n := Z_n + \theta$. Then   $$\mathbb E[\theta \mid Y_1, Y_2, \dots, Y_n] \longrightarrow \theta$$   $P$-a.s. as $n\to \infty$. I was trying to apply Lvy's martingale convergence theorem: $$\mathbb E[\theta \mid Y_1, Y_2, \dots, Y_n] \longrightarrow \mathbb E[\theta \mid \mathcal F_{\infty}]$$ where $\mathcal F_\infty $ is the smallest $\sigma$-algebra generated by all $Y_n$. Now it remains to show $\theta = \mathbb E[\theta \mid \mathcal F_\infty]$, but here is where I am stuck. Is this the right direction I am going?","I am trying to prove the following statemt: Let $(\Omega, \mathcal A, P)$ be a probability space. Let $(Z_n)_{n\in \mathbb N}$ be i.i.d. random variables with $Z_1 \in \mathcal L^1$. Let $\theta \in \mathcal L^1$ be independent from $(Z_n)_{n\in \mathbb N}$ and define $\forall n\in \mathbb N: Y_n := Z_n + \theta$. Then   $$\mathbb E[\theta \mid Y_1, Y_2, \dots, Y_n] \longrightarrow \theta$$   $P$-a.s. as $n\to \infty$. I was trying to apply Lvy's martingale convergence theorem: $$\mathbb E[\theta \mid Y_1, Y_2, \dots, Y_n] \longrightarrow \mathbb E[\theta \mid \mathcal F_{\infty}]$$ where $\mathcal F_\infty $ is the smallest $\sigma$-algebra generated by all $Y_n$. Now it remains to show $\theta = \mathbb E[\theta \mid \mathcal F_\infty]$, but here is where I am stuck. Is this the right direction I am going?",,"['probability', 'probability-theory', 'convergence-divergence', 'expectation', 'martingales']"
86,Almost sure convergence of sequence of discrete uniforms to continuous uniform,Almost sure convergence of sequence of discrete uniforms to continuous uniform,,"Let $X_n$ $(n=1,2,\dots)$ be a sequence of discrete random variables, where the distribution of $X_n$ is the discrete uniform over $\{0, 1/n, 2/n,\dots,1 \}$. Let $U$ be a random variable whose distribution is the continuous uniform over $[0,1]$. Does $X_n \to U$ almost surely? My approach is to use Borel-Cantelli to check that $\sum_n\Pr[|X_n-U|>\epsilon] < \infty$, but it appears that for $n>2$ and $\epsilon_n < 1/(n+1)$, we have $\Pr[|X_n-U|>\epsilon_n] = 1-2n{\epsilon}_n/(n+1)$, whose sum does not converge. Is there another approach? If the convergence does not happen almost surely, is it possible for any discrete random variable to converge almost surely to a continuous random variable? (It is clear in the example above that that $X_n \to^\mathrm{D} U$ i.e. convegence in distribution.)","Let $X_n$ $(n=1,2,\dots)$ be a sequence of discrete random variables, where the distribution of $X_n$ is the discrete uniform over $\{0, 1/n, 2/n,\dots,1 \}$. Let $U$ be a random variable whose distribution is the continuous uniform over $[0,1]$. Does $X_n \to U$ almost surely? My approach is to use Borel-Cantelli to check that $\sum_n\Pr[|X_n-U|>\epsilon] < \infty$, but it appears that for $n>2$ and $\epsilon_n < 1/(n+1)$, we have $\Pr[|X_n-U|>\epsilon_n] = 1-2n{\epsilon}_n/(n+1)$, whose sum does not converge. Is there another approach? If the convergence does not happen almost surely, is it possible for any discrete random variable to converge almost surely to a continuous random variable? (It is clear in the example above that that $X_n \to^\mathrm{D} U$ i.e. convegence in distribution.)",,"['probability', 'sequences-and-series', 'probability-theory', 'convergence-divergence', 'borel-cantelli-lemmas']"
87,How to label the events in a probability problem?,How to label the events in a probability problem?,,"I'm starting a statistics and probability class and it's still pretty hard for me to ""name"" my probability events, which I think makes it very difficult to solve problems. I'll pick an example from my exercises to illustrate my problem : We asked 1000 persons which magazines do they regularly read between magazine A, B and C. We obtained the following results : 60% read A, 50% read B, 50% read C. There are 20% which read B and C, 30% read A and C and 30% read A and B. There is 10% of the 1000 persons who read the 3 magazines. Given one person, calculate the probability that this person: Reads A or C. Doesn't read a magazine at all Reads A but not B Reads only one magazine. So, in this example the events were labelled : A = {Probability that this person reads A} B = {Probability that this person reads B} C = {Probability that this person reads C} If this were an exercise, I might have started by naming the probability event according to the question so : X = {Probability that this person read's A or C} Y = {Probability that this person doesn't read a magazine} etc.. or something like that. I would have messed around for a while, not being able to find the answer, and at some point I would have figured out the events like they are labelled in the example. I know that this example is pretty easy to figure out, but in more complex exercices I find it difficult to label the events properly. IMO, it's kind of like not being able to identify variables properly in an algebra problem. Without proper variables it's impossible to figure out the answer. So, I'm sure there's a ""way to follow"" in order to label the events in a probability problem and I would like to find out what it is. Edit For my current problem, there are three cards. One with a red face, red background. The other with a red face, black background and the last with black face black background. I need to find the probability that given a picked card where the face is red, the background is black. I am not looking for answers to the problem I'd just like to know how I'm supposed to figure out what should be the labels to my events. One per card? One per face color?","I'm starting a statistics and probability class and it's still pretty hard for me to ""name"" my probability events, which I think makes it very difficult to solve problems. I'll pick an example from my exercises to illustrate my problem : We asked 1000 persons which magazines do they regularly read between magazine A, B and C. We obtained the following results : 60% read A, 50% read B, 50% read C. There are 20% which read B and C, 30% read A and C and 30% read A and B. There is 10% of the 1000 persons who read the 3 magazines. Given one person, calculate the probability that this person: Reads A or C. Doesn't read a magazine at all Reads A but not B Reads only one magazine. So, in this example the events were labelled : A = {Probability that this person reads A} B = {Probability that this person reads B} C = {Probability that this person reads C} If this were an exercise, I might have started by naming the probability event according to the question so : X = {Probability that this person read's A or C} Y = {Probability that this person doesn't read a magazine} etc.. or something like that. I would have messed around for a while, not being able to find the answer, and at some point I would have figured out the events like they are labelled in the example. I know that this example is pretty easy to figure out, but in more complex exercices I find it difficult to label the events properly. IMO, it's kind of like not being able to identify variables properly in an algebra problem. Without proper variables it's impossible to figure out the answer. So, I'm sure there's a ""way to follow"" in order to label the events in a probability problem and I would like to find out what it is. Edit For my current problem, there are three cards. One with a red face, red background. The other with a red face, black background and the last with black face black background. I need to find the probability that given a picked card where the face is red, the background is black. I am not looking for answers to the problem I'd just like to know how I'm supposed to figure out what should be the labels to my events. One per card? One per face color?",,"['probability', 'elementary-probability']"
88,Bernstein inequality,Bernstein inequality,,"Let us assume $X_1, ..., X_n$ are independent random variables bounded by the interval $[a_i, b_i]$ and $S_n = X_1 + ... + X_n$ . When $|X_i - E[X_i]|\leq M$ ,  the Bernstein's inequality suggests the following.  It can be asumed that $M = \max_{i} \big\{b_i - E[X_i]\big\}$ . $$P(S_n - E[S_n] > t) \leq \exp{\left(\frac{-t^2}{2\sum_{i=1}^{n}\operatorname{Var} (X_i) + \frac{2}{3} Mt}\right)}.$$ Now, I have a case where $Y_1, ..., Y_{n_1}$ are independent random variables bounded by the interval $[c_i, d_i]$ and $S_{n_1} = Y_1 + ... + Y_{n_1}$ .  In addition, $Z_1, ..., Z_{n_2}$ are independent random variables bounded by the interval $[e_i, f_i]$ and $S_{n_2} = Z_1 + ... + Z_{n_2}$ . $Y_i$ 's and $Z_i$ 's are also independent.  Let, $M_1 = \max_{i} \big\{d_i - E[Y_i]\big\}$ and $M_2 = \max_{i} \big\{f_i - E[Z_i]\big\}$ .  I would like to have a Bernstein's bound for $P(S_{n_1}+S_{n_2} -E[S_{n_1}+S_{n_2}] > t)$ . My try: $$\begin{align} &P(S_{n_1}+S_{n_2} -E[S_{n_1}+S_{n_2}] > t) \\ &\leq \exp{\left(\frac{-t^2}{2\big[\sum_{i=1}^{n_1}\operatorname{Var} (Y_i)+ \sum_{i=1}^{n_2}\operatorname{Var} (Z_i)\big] + \frac{2}{3} [M_1 + M_2] t}\right)}. \end{align}$$ I am wondering whether the above equation is correct.","Let us assume are independent random variables bounded by the interval and . When ,  the Bernstein's inequality suggests the following.  It can be asumed that . Now, I have a case where are independent random variables bounded by the interval and .  In addition, are independent random variables bounded by the interval and . 's and 's are also independent.  Let, and .  I would like to have a Bernstein's bound for . My try: I am wondering whether the above equation is correct.","X_1, ..., X_n [a_i, b_i] S_n = X_1 + ... + X_n |X_i - E[X_i]|\leq M M = \max_{i} \big\{b_i - E[X_i]\big\} P(S_n - E[S_n] > t) \leq \exp{\left(\frac{-t^2}{2\sum_{i=1}^{n}\operatorname{Var} (X_i) + \frac{2}{3} Mt}\right)}. Y_1, ..., Y_{n_1} [c_i, d_i] S_{n_1} = Y_1 + ... + Y_{n_1} Z_1, ..., Z_{n_2} [e_i, f_i] S_{n_2} = Z_1 + ... + Z_{n_2} Y_i Z_i M_1 = \max_{i} \big\{d_i - E[Y_i]\big\} M_2 = \max_{i} \big\{f_i - E[Z_i]\big\} P(S_{n_1}+S_{n_2} -E[S_{n_1}+S_{n_2}] > t) \begin{align}
&P(S_{n_1}+S_{n_2} -E[S_{n_1}+S_{n_2}] > t) \\
&\leq \exp{\left(\frac{-t^2}{2\big[\sum_{i=1}^{n_1}\operatorname{Var} (Y_i)+ \sum_{i=1}^{n_2}\operatorname{Var} (Z_i)\big] + \frac{2}{3} [M_1 + M_2] t}\right)}. \end{align}","['probability', 'inequality', 'random-variables', 'independence']"
89,What is the probability of getting caught?,What is the probability of getting caught?,,"You have a math exam of $180$ minutes. However, the teacher doesn't stay in the classroom the entire time. He randomly enters the classroom $3$ times. Each time he spends $30$ seconds before he leaves again. One of the student figures he can cheat by looking up the answers in his book. The act of taking out his book, finding the answer and putting his book back in his bag takes $1$ minute. The student wants to make sure that the probability of not getting caught is at least $99.9\%$. Consider the student caught when some part of the $30$ secondes overlap with some part of the $1$ minute. Note: the student doesn't know whether the teacher is in the classroom, so it is possible that he takes out his book while the teacher is already present. How many times can the student takes out his book while maintaining a $99.9\%$ chance (minimum) of not getting caught? I translated the question since English isn't my native language I honestly don't know how to even approach this question. I tried a lot of binomials but nothing makes sense. I figured it should be someting like 180 choose n (where n is the number of times he cheats) over n*2 choose 3. I didn't want to do n*60 choose 90 since that doesn't incorporate the fact that the teacher stays in the classroom for 30 consecutive seconds. But all of it doesn't make sense. Working with seconds instead of 180 minutes yields entirely different results while I would expect them to be the same. It's driving me crazy. If someone could help me out it would mean the world.","You have a math exam of $180$ minutes. However, the teacher doesn't stay in the classroom the entire time. He randomly enters the classroom $3$ times. Each time he spends $30$ seconds before he leaves again. One of the student figures he can cheat by looking up the answers in his book. The act of taking out his book, finding the answer and putting his book back in his bag takes $1$ minute. The student wants to make sure that the probability of not getting caught is at least $99.9\%$. Consider the student caught when some part of the $30$ secondes overlap with some part of the $1$ minute. Note: the student doesn't know whether the teacher is in the classroom, so it is possible that he takes out his book while the teacher is already present. How many times can the student takes out his book while maintaining a $99.9\%$ chance (minimum) of not getting caught? I translated the question since English isn't my native language I honestly don't know how to even approach this question. I tried a lot of binomials but nothing makes sense. I figured it should be someting like 180 choose n (where n is the number of times he cheats) over n*2 choose 3. I didn't want to do n*60 choose 90 since that doesn't incorporate the fact that the teacher stays in the classroom for 30 consecutive seconds. But all of it doesn't make sense. Working with seconds instead of 180 minutes yields entirely different results while I would expect them to be the same. It's driving me crazy. If someone could help me out it would mean the world.",,"['probability', 'probability-theory', 'binomial-coefficients']"
90,Variance of $S^2$ taken from Normal Distribution,Variance of  taken from Normal Distribution,S^2,"Suppose that $Y_1,Y_2,...,Y_n$ is a random sample of size $n$ where $Y_i$~$N(0,\sigma^2)$.  Let $\bar Y$ and $S^2$ denote the usual sample mean and variance. Find the the variance of $S^2$. In this problem, I'm assuming that $S^2=\frac{\sum_{i=1}^{n}(Y_i-\bar Y)^2}{n-1}$.  I know that the difference of normal random variables is normal (since $\bar Y$ is normal), so I get a chi squared random variable in the numerator and then obtain the following result: $$V(S^2)=\frac{2n(\sigma^2+\frac{\sigma^2}{n})^2}{(n-1)^2}$$ But I have a lingering suspicion that this isn't correct.  Did I make an assumption somewhere that I shouldn't have?","Suppose that $Y_1,Y_2,...,Y_n$ is a random sample of size $n$ where $Y_i$~$N(0,\sigma^2)$.  Let $\bar Y$ and $S^2$ denote the usual sample mean and variance. Find the the variance of $S^2$. In this problem, I'm assuming that $S^2=\frac{\sum_{i=1}^{n}(Y_i-\bar Y)^2}{n-1}$.  I know that the difference of normal random variables is normal (since $\bar Y$ is normal), so I get a chi squared random variable in the numerator and then obtain the following result: $$V(S^2)=\frac{2n(\sigma^2+\frac{\sigma^2}{n})^2}{(n-1)^2}$$ But I have a lingering suspicion that this isn't correct.  Did I make an assumption somewhere that I shouldn't have?",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'sampling']"
91,Recommendation on probability textbook,Recommendation on probability textbook,,"Most posts here asked for a probability textbook which does not assume measure-theoretic background. However, I have a quite concrete background of measure-theory and am looking for a probability textbook which is very measure-theoretic and written for pure mathematicians, not engineers. (I am a third-year graduate student and I have studied at least 4 different real-analysis textbooks including Follands, Steins, Roydens, Rudins and etc. However, I have never studied probability theory before, and I need to study this theory now.)","Most posts here asked for a probability textbook which does not assume measure-theoretic background. However, I have a quite concrete background of measure-theory and am looking for a probability textbook which is very measure-theoretic and written for pure mathematicians, not engineers. (I am a third-year graduate student and I have studied at least 4 different real-analysis textbooks including Follands, Steins, Roydens, Rudins and etc. However, I have never studied probability theory before, and I need to study this theory now.)",,"['probability', 'probability-theory', 'book-recommendation']"
92,"For two random variables $X_1 + X_2$ and $\min(X_1,X_2)$ find the joint-distribution and the covariance",For two random variables  and  find the joint-distribution and the covariance,"X_1 + X_2 \min(X_1,X_2)","Let $X_1,X_2$ be independent random variables. Moreover $X_1,X_2$ are discrete uniform distributed({$1,...,N$}) We define: $A:=  X_1+X_2$ $B:= \min(X_1,X_2)$ Find joint-distribution of $A$ and $B$  and calculate covariance of $A$ and $B$. I don't really have a clue how to find the joint-distribution of $A$ and $B$. So for this task I really need some help. Maybe you can give me a hint and I try to solve it then. I would edit this question with my attempt until I find the joint-distribution. Edit : Let us start with the joint distribution. $P(A=a,B=b) =P(B=b|A=a)\cdot P(A=a)$. In the answers below I saw that: $ P(A=a)=\frac{1}{N^2}\left\{ \begin{array}{lr}a-1& 2\leq a \leq N+1 \\ 2N+1-a & N+2\leq a \leq 2N \end{array} \right. $ I understand why this formula holds for $P(A=a)$ but only with the example. I don't know how we can show it. Moreover We have to find $P(B=b|A=a)$. I think a) is clear now. Will try to edit my attempt in a few days. Edit for the second part : I will write $Cov$ for covariance. So we have to calculate $Cov(A,B)$. We already know that: $Cov(A,B) = E(AB) - E(A)E(B) $ (expected value) All we have to compute is the expected value for $AB,A,B$. Thanks to the user ""mathemagical"". I already know the value of $E(A), E(B)$. I even understand the rest of the answer except how we can calculate $E(Z)$.","Let $X_1,X_2$ be independent random variables. Moreover $X_1,X_2$ are discrete uniform distributed({$1,...,N$}) We define: $A:=  X_1+X_2$ $B:= \min(X_1,X_2)$ Find joint-distribution of $A$ and $B$  and calculate covariance of $A$ and $B$. I don't really have a clue how to find the joint-distribution of $A$ and $B$. So for this task I really need some help. Maybe you can give me a hint and I try to solve it then. I would edit this question with my attempt until I find the joint-distribution. Edit : Let us start with the joint distribution. $P(A=a,B=b) =P(B=b|A=a)\cdot P(A=a)$. In the answers below I saw that: $ P(A=a)=\frac{1}{N^2}\left\{ \begin{array}{lr}a-1& 2\leq a \leq N+1 \\ 2N+1-a & N+2\leq a \leq 2N \end{array} \right. $ I understand why this formula holds for $P(A=a)$ but only with the example. I don't know how we can show it. Moreover We have to find $P(B=b|A=a)$. I think a) is clear now. Will try to edit my attempt in a few days. Edit for the second part : I will write $Cov$ for covariance. So we have to calculate $Cov(A,B)$. We already know that: $Cov(A,B) = E(AB) - E(A)E(B) $ (expected value) All we have to compute is the expected value for $AB,A,B$. Thanks to the user ""mathemagical"". I already know the value of $E(A), E(B)$. I even understand the rest of the answer except how we can calculate $E(Z)$.",,"['probability', 'probability-distributions', 'random-variables', 'covariance']"
93,Probability problem that involves number theory,Probability problem that involves number theory,,"Let $k \in Z^+$. Assume integers 1, 2, 3, . . . , 3k+ 1 are written down randomly. Calculate the probability that at no time during this process, the sum of the integers is a positive integer divisible by 3? Attempt: I am trying to approach this by finding the complement of what's being asked which is the number times the sum of the integers is divisible by 3. The sample space I think is $\prod_{i = 0}^{3k+1}(3(i)+1)!$ since that's I think the number of trees we can generate by doing this process. I think my sample space is off. The right way is to  figure out how many sequences can we have at some time i where $1 \leq i \leq 3k+1$ during the process. This is: $(3k+1) +(3K+1)(3k) + (3k+1)(3k)(3k-1)+ ... + (3k+1)!$ I also have the feeling that this is done by using states. There are just three state where the sum can be at any time and these are: 0mod3, 1mod3 and 2mod3. We have to find all the possible ways we can reach the state 0mod3 somehow.","Let $k \in Z^+$. Assume integers 1, 2, 3, . . . , 3k+ 1 are written down randomly. Calculate the probability that at no time during this process, the sum of the integers is a positive integer divisible by 3? Attempt: I am trying to approach this by finding the complement of what's being asked which is the number times the sum of the integers is divisible by 3. The sample space I think is $\prod_{i = 0}^{3k+1}(3(i)+1)!$ since that's I think the number of trees we can generate by doing this process. I think my sample space is off. The right way is to  figure out how many sequences can we have at some time i where $1 \leq i \leq 3k+1$ during the process. This is: $(3k+1) +(3K+1)(3k) + (3k+1)(3k)(3k-1)+ ... + (3k+1)!$ I also have the feeling that this is done by using states. There are just three state where the sum can be at any time and these are: 0mod3, 1mod3 and 2mod3. We have to find all the possible ways we can reach the state 0mod3 somehow.",,"['probability', 'number-theory']"
94,Expected value of the sign of a normal random variable,Expected value of the sign of a normal random variable,,"Let $x\in\Bbb{R}$ be a normal random variable with mean $\bar{x}$ and variance $\sigma_x^2$. I'm curious about a new variable that is defined as the sign of $s$, say $s=\operatorname{sgn}(x)\in\{\pm1\}$. What is the expected value of this variable? Based on the answers below, $$ \Bbb{E}[s] = (-1)\cdot P(x<0) + 1\cdot P(x>0) = -P\left(\frac{x-\bar{x}}{\sigma_x}<-\frac{\bar{x}}{\sigma_x}\right) + P\left(\frac{x-\bar{x}}{\sigma_x}>-\frac{\bar{x}}{\sigma_x}\right) \implies \Bbb{E}[s] = -P\left(z < -\frac{\bar{x}}{\sigma_x}\right) + P\left(z > -\frac{\bar{x}}{\sigma_x}\right), $$ where $z\sim\mathcal{N}(0,1)$ is the standard normal variable. Thus, $$ \Bbb{E}[s] = -\Phi\left(-\frac{\bar{x}}{\sigma_x}\right) + 1 - \Phi\left(-\frac{\bar{x}}{\sigma_x}\right) = 1 - 2\Phi\left(-\frac{\bar{x}}{\sigma_x}\right), $$ where $\Phi$ is the cumulative distribution function of the standard normal variable. Thus, $$ \Bbb{E}[s] = \operatorname{erf} \left( \frac{\bar{x}}{\sqrt{2}\sigma_x} \right). $$","Let $x\in\Bbb{R}$ be a normal random variable with mean $\bar{x}$ and variance $\sigma_x^2$. I'm curious about a new variable that is defined as the sign of $s$, say $s=\operatorname{sgn}(x)\in\{\pm1\}$. What is the expected value of this variable? Based on the answers below, $$ \Bbb{E}[s] = (-1)\cdot P(x<0) + 1\cdot P(x>0) = -P\left(\frac{x-\bar{x}}{\sigma_x}<-\frac{\bar{x}}{\sigma_x}\right) + P\left(\frac{x-\bar{x}}{\sigma_x}>-\frac{\bar{x}}{\sigma_x}\right) \implies \Bbb{E}[s] = -P\left(z < -\frac{\bar{x}}{\sigma_x}\right) + P\left(z > -\frac{\bar{x}}{\sigma_x}\right), $$ where $z\sim\mathcal{N}(0,1)$ is the standard normal variable. Thus, $$ \Bbb{E}[s] = -\Phi\left(-\frac{\bar{x}}{\sigma_x}\right) + 1 - \Phi\left(-\frac{\bar{x}}{\sigma_x}\right) = 1 - 2\Phi\left(-\frac{\bar{x}}{\sigma_x}\right), $$ where $\Phi$ is the cumulative distribution function of the standard normal variable. Thus, $$ \Bbb{E}[s] = \operatorname{erf} \left( \frac{\bar{x}}{\sqrt{2}\sigma_x} \right). $$",,"['probability', 'normal-distribution', 'expectation']"
95,"""How much of the big picture have I seen already?"" problem","""How much of the big picture have I seen already?"" problem",,"TL;DR / Theoretic formulation Let $X_1, X_2, ..., X_k$ be a sequence of i.i.d. random variables with $X_i \sim \mathcal{U}\{1, 2, ..., n\}$ (discrete uniform distribution). The parameter $n$ is unknown. Let $U$ be the number of unique values seen in the sequence. Given $k$ and $U$ , how to estimate $n$ ? The problem Let $A = \{a_1, a_2, ..., a_n\}$ be a set of ""concepts"" that you will have to learn, for example for a university course. As you don't see the big picture of the topic yet, you don't have an idea of how big $n$ is, and you want to estimate $n$ . In a few days, you speak with $k$ different people - each time it's a one-to-one discussion with a friend who studied the topic before, and who is supposed to master all the $n$ concepts perfectly. Each friend chooses a concept uniformly-randomly in the set $A$ , and speaks to you about it. At the end of the $k$ discussions, you write down $u$ , the number of unique concepts seen. Goal: how to estimate $n$ , as a function of $k$ and $u$ ? Example 1: if among $k=15$ discussions, one concept has been discussed twice (so there's 1 repetition), another concept has been discussed three times (2 repetitions), and all others just once, then the total number of repetitions is $3$ , and the number of unique concepts discussed is $u=12$ . Then you can imagine that if you'd proceed with even more discussions, there will be many new unseen concepts to appear. Thus $n$ is probably large. Example 2: if among $k=15$ discussions, one concept has been discussed $10$ times, another $3$ times, and two other concepts once each, then $u = 4$ . As many people spoke about the same concept (however they chose it randomly!), it gives the impression that you probably have seen most of the whole subject. Thus $n$ is not so big. How to estimate $n$ ? Other applications A) You are new in the city, and you don't know how big ( $n$ ) it is. Each time you go to a bar you see new people you haven't seen before => $k \approx u$ => $n$ is probably big. If on the other hand, you always see the same people again and again ( $u$ much smaller than $k$ ), then $n$ is probably small. B) You're writing a book, and ask $k$ friends to proofread it. Each friend reports $1$ mistake randomly among the mistakes he has seen. If the total number of unique mistakes seen by the readers is much much less than $k$ , i.e. many repetitions in the reported mistakes, it means you've probably covered most of the mistakes (assuming the distribution is uniform, etc.). If, on the other hand, each proofreader reports a mistake that nobody else has reported, this is bad news for you: there are probably many more mistakes to find in the book!","TL;DR / Theoretic formulation Let be a sequence of i.i.d. random variables with (discrete uniform distribution). The parameter is unknown. Let be the number of unique values seen in the sequence. Given and , how to estimate ? The problem Let be a set of ""concepts"" that you will have to learn, for example for a university course. As you don't see the big picture of the topic yet, you don't have an idea of how big is, and you want to estimate . In a few days, you speak with different people - each time it's a one-to-one discussion with a friend who studied the topic before, and who is supposed to master all the concepts perfectly. Each friend chooses a concept uniformly-randomly in the set , and speaks to you about it. At the end of the discussions, you write down , the number of unique concepts seen. Goal: how to estimate , as a function of and ? Example 1: if among discussions, one concept has been discussed twice (so there's 1 repetition), another concept has been discussed three times (2 repetitions), and all others just once, then the total number of repetitions is , and the number of unique concepts discussed is . Then you can imagine that if you'd proceed with even more discussions, there will be many new unseen concepts to appear. Thus is probably large. Example 2: if among discussions, one concept has been discussed times, another times, and two other concepts once each, then . As many people spoke about the same concept (however they chose it randomly!), it gives the impression that you probably have seen most of the whole subject. Thus is not so big. How to estimate ? Other applications A) You are new in the city, and you don't know how big ( ) it is. Each time you go to a bar you see new people you haven't seen before => => is probably big. If on the other hand, you always see the same people again and again ( much smaller than ), then is probably small. B) You're writing a book, and ask friends to proofread it. Each friend reports mistake randomly among the mistakes he has seen. If the total number of unique mistakes seen by the readers is much much less than , i.e. many repetitions in the reported mistakes, it means you've probably covered most of the mistakes (assuming the distribution is uniform, etc.). If, on the other hand, each proofreader reports a mistake that nobody else has reported, this is bad news for you: there are probably many more mistakes to find in the book!","X_1, X_2, ..., X_k X_i \sim \mathcal{U}\{1, 2, ..., n\} n U k U n A = \{a_1, a_2, ..., a_n\} n n k n A k u n k u k=15 3 u=12 n k=15 10 3 u = 4 n n n k \approx u n u k n k 1 k","['probability', 'probability-theory', 'statistics', 'estimation', 'parameter-estimation']"
96,What is the space of random variables equipped with the expectation inner product?,What is the space of random variables equipped with the expectation inner product?,,"While studying probability, I was always fascinated at how random variables seem to satisfy a host of well-known inequalities from linear algebra, such as the Cauchy Schwartz inequality. It was when I read this article on Wikipedia did I realize that you could define an inner product on the space of random variables. Recall that a random variable is a function that assigns outcomes to real numbers. Therefore, if we equip the set of random variables with the inner product taken as an expectation, i.e.,  ${\displaystyle \langle X,Y\rangle \triangleq  \operatorname {\mathbb{E}} (XY)}$, we obtain an inner product space of these functions. Observe that $\mathbb{E} (XY)$ is the correlation of $X,Y$. It seems that this space is under-discussed in applied probability literature. Can someone elaborate if there is a name for this particular inner product space, i.e. ""correlation space"" ? Is this inner product space complete, i.e., a Hilbert space?","While studying probability, I was always fascinated at how random variables seem to satisfy a host of well-known inequalities from linear algebra, such as the Cauchy Schwartz inequality. It was when I read this article on Wikipedia did I realize that you could define an inner product on the space of random variables. Recall that a random variable is a function that assigns outcomes to real numbers. Therefore, if we equip the set of random variables with the inner product taken as an expectation, i.e.,  ${\displaystyle \langle X,Y\rangle \triangleq  \operatorname {\mathbb{E}} (XY)}$, we obtain an inner product space of these functions. Observe that $\mathbb{E} (XY)$ is the correlation of $X,Y$. It seems that this space is under-discussed in applied probability literature. Can someone elaborate if there is a name for this particular inner product space, i.e. ""correlation space"" ? Is this inner product space complete, i.e., a Hilbert space?",,"['probability', 'probability-theory', 'reference-request', 'vector-spaces', 'hilbert-spaces']"
97,finding a distribution given marginals and correlation matrix,finding a distribution given marginals and correlation matrix,,"Given a $2 \times 2$ correlation matrix $A$ and distributions $g(x)$ (say a fixed Gaussian distribution) and $h(y)$(say a fixed exponential distribution), can we find 'a' distribution $f(x,y)$, such that $g(x)$ and $h(y)$ are the marginal distributions of $f(x,y)$ with correlation matrix $A$?","Given a $2 \times 2$ correlation matrix $A$ and distributions $g(x)$ (say a fixed Gaussian distribution) and $h(y)$(say a fixed exponential distribution), can we find 'a' distribution $f(x,y)$, such that $g(x)$ and $h(y)$ are the marginal distributions of $f(x,y)$ with correlation matrix $A$?",,"['probability', 'probability-distributions']"
98,An urn containing $r$ red balls and $b$ blue balls.,An urn containing  red balls and  blue balls.,r b,"Suppose an urn contains $r$ red balls and $b$ blue balls. Suppose $n$ balls are drawn sequentially without replacement. Find the probability that $k$ of the $n$ balls are blue and that the first one is blue. My try: Let $A$ be event first ball is blue and $B$ be event $k$ of $n$ balls are blue. I want to find $P(A \cap B)$ . In total we have ${r+b \choose n }$ outcomes in sample space. for the number of ways $A \cap B$ occurs we have first one is blue, and so we have $b-1$ blue balls from there we pick $k$ of them so ${b - 1 \choose k}$ and for red balls we have ${r \choose n - k}$ . Therefore $$ P(A \cap B) = \frac{ b {b - 1 \choose k} {r \choose n - k} }{{r+b \choose n } }. $$ Is this correct?","Suppose an urn contains red balls and blue balls. Suppose balls are drawn sequentially without replacement. Find the probability that of the balls are blue and that the first one is blue. My try: Let be event first ball is blue and be event of balls are blue. I want to find . In total we have outcomes in sample space. for the number of ways occurs we have first one is blue, and so we have blue balls from there we pick of them so and for red balls we have . Therefore Is this correct?",r b n k n A B k n P(A \cap B) {r+b \choose n } A \cap B b-1 k {b - 1 \choose k} {r \choose n - k}  P(A \cap B) = \frac{ b {b - 1 \choose k} {r \choose n - k} }{{r+b \choose n } }. ,"['probability', 'proof-verification']"
99,What's the probability of guessing a secret code if the attempts are limited and you stop at the first success?,What's the probability of guessing a secret code if the attempts are limited and you stop at the first success?,,"Some time ago I tried to answer a question on Security Stack Exchange, but I realised I'm not sure I got the maths right, and I'm here to ask for help. The scenario is as follows: somebody is trying to break into another user's account. That account is protected by a password and by a so-called ""second factor"" (like a code sent vis SMS, or generated by an app like Google Authenticator), and the hypothesis is that the attacker knows the password, so the only protection is given by this code. If it is a 3-digit code, there are 1000 possible codes, and with a single attempt the probability to guess it is $p = \frac{1}{1000}$. This is easy. The point where I'm stuck at is calculating the probability of guessing the right code if he has more than one attempt. For example, he can try at most 3 times, and after that the account is locked for protection, and it's game over. What's the probability of success, in that case? Here's what I tried. First of all, we have to establish whether the correct code is the same for all three attempts, or whether it changes every time. I've explored both cases. Case A: the code is always the same. I think this can be modelled with a hypergeometric variable. As Wikipedia says, it's ""the probability of k successes in n draws, without replacement, from a finite population of size N that contains exactly K successes, wherein each draw is either a success or a failure"". In our case, with N = 1000, K = 1, n = 3, k = 1, it's $$ \require{cancel} P_{Code\,is\,guessed} = \frac{\binom{1}{1} \binom{1000-1}{3-1}}{\binom{1000}{3}} = \frac{\binom{999}{2}}{\binom{1000}{3}} = \frac{\frac{999!}{2!\cdot\cancel{997!}}}{\frac{1000!}{3!\cdot\cancel{997!}}} = \frac{\frac{\cancel{999!}}{\cancel{2}}}{\frac{1000\cdot\cancel{999!}}{3\cdot\cancel{2}\cdot1}} = \frac{3}{1000} $$ To confirm this, I've drawn a tree of the possible outcomes: at every node there's a guess. The green branch corresponds to guessing the right code, the red branch to not guessing it and proceeding to the next attempt (unless it's the last one): The probability of ending up at a certain leaf is the product of all the probabilities of the intermediate nodes, and the probability of reaching any of the ""green"" leaves is simply the sum, as they are independent events. Therefore, $$ P_{Code\,is\,guessed} = \frac{1}{1000} + (\frac{\cancel{999}}{1000} \cdot \frac{1}{\cancel{999}}) + (\frac{\cancel{999}}{1000} \cdot \frac{\cancel{998}}{\cancel{999}} \cdot \frac{1}{\cancel{998}}) = \frac{1}{1000} + \frac{1}{1000} + \frac{1}{1000} = \frac{3}{1000} $$ This looks good, because it's the same result. I'm fairly confident it's correct. Is it right? Case B: the code changes every time I tried to apply the same reasoning to the case where the code changes at every failed attempt. Intuitively, the fact that the code changes every time means that for his second attempt the attacker can't restrict the range to 999 possible codes, but he has to consider, again, 1000. I think this corresponds to a binomial distribution where he tries to have k = 1 successes in n = 3 attempts, but I already have my doubts: if we guess the right code, we immediately stop, but I think the binomial assumes that we make 3 attempts in any case, that is, even if we guess the right code at the first attempt, the binomial assumes we try (and fail) 2 more times. Anyway, with $p=\frac{1}{1000}$, n=3, k=1, the probability is $$ P_{Code\,is\,guessed} = \binom{n}{k} \cdot p^k \cdot (1-p)^{(n-k)} = \binom{3}{1} \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^{(3-1)} = 3 \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^2 = 0.002994003 $$ Again, to confirm the result I tried building the tree: And in this case, $$ P_{Code\,is\,guessed} = \frac{1}{1000} + \frac{999}{1000} \cdot \frac{1}{1000}  + (\frac{999}{1000})^2 \cdot \frac{1}{1000} = 0.002997001 $$ which is different from the previous result, the one that I got using the binomial! This means at least one of these calculations is wrong (and possibly both), but I'm not sure where the error is. Anyway the tree convinces me more, and as I said I suspect that the problem is that the binomial isn't the right choice here, because it assumes that the attacker always makes 3 attempts, and this is not realistic in this scenario. So, these are my questions: Are my calculations correct for case A (the code is always the same)? For case B, I'm sure there's an error. Where is it? I even tried simplifying the problem to rolling a die trying to get a certain face, and if the result is not the desired one, rolling one more time. I think the trick might be that if the first roll is successful we don't have to add the probability of guessing at the second roll, because there simply won't be a second roll. But, again, I'm confused.","Some time ago I tried to answer a question on Security Stack Exchange, but I realised I'm not sure I got the maths right, and I'm here to ask for help. The scenario is as follows: somebody is trying to break into another user's account. That account is protected by a password and by a so-called ""second factor"" (like a code sent vis SMS, or generated by an app like Google Authenticator), and the hypothesis is that the attacker knows the password, so the only protection is given by this code. If it is a 3-digit code, there are 1000 possible codes, and with a single attempt the probability to guess it is $p = \frac{1}{1000}$. This is easy. The point where I'm stuck at is calculating the probability of guessing the right code if he has more than one attempt. For example, he can try at most 3 times, and after that the account is locked for protection, and it's game over. What's the probability of success, in that case? Here's what I tried. First of all, we have to establish whether the correct code is the same for all three attempts, or whether it changes every time. I've explored both cases. Case A: the code is always the same. I think this can be modelled with a hypergeometric variable. As Wikipedia says, it's ""the probability of k successes in n draws, without replacement, from a finite population of size N that contains exactly K successes, wherein each draw is either a success or a failure"". In our case, with N = 1000, K = 1, n = 3, k = 1, it's $$ \require{cancel} P_{Code\,is\,guessed} = \frac{\binom{1}{1} \binom{1000-1}{3-1}}{\binom{1000}{3}} = \frac{\binom{999}{2}}{\binom{1000}{3}} = \frac{\frac{999!}{2!\cdot\cancel{997!}}}{\frac{1000!}{3!\cdot\cancel{997!}}} = \frac{\frac{\cancel{999!}}{\cancel{2}}}{\frac{1000\cdot\cancel{999!}}{3\cdot\cancel{2}\cdot1}} = \frac{3}{1000} $$ To confirm this, I've drawn a tree of the possible outcomes: at every node there's a guess. The green branch corresponds to guessing the right code, the red branch to not guessing it and proceeding to the next attempt (unless it's the last one): The probability of ending up at a certain leaf is the product of all the probabilities of the intermediate nodes, and the probability of reaching any of the ""green"" leaves is simply the sum, as they are independent events. Therefore, $$ P_{Code\,is\,guessed} = \frac{1}{1000} + (\frac{\cancel{999}}{1000} \cdot \frac{1}{\cancel{999}}) + (\frac{\cancel{999}}{1000} \cdot \frac{\cancel{998}}{\cancel{999}} \cdot \frac{1}{\cancel{998}}) = \frac{1}{1000} + \frac{1}{1000} + \frac{1}{1000} = \frac{3}{1000} $$ This looks good, because it's the same result. I'm fairly confident it's correct. Is it right? Case B: the code changes every time I tried to apply the same reasoning to the case where the code changes at every failed attempt. Intuitively, the fact that the code changes every time means that for his second attempt the attacker can't restrict the range to 999 possible codes, but he has to consider, again, 1000. I think this corresponds to a binomial distribution where he tries to have k = 1 successes in n = 3 attempts, but I already have my doubts: if we guess the right code, we immediately stop, but I think the binomial assumes that we make 3 attempts in any case, that is, even if we guess the right code at the first attempt, the binomial assumes we try (and fail) 2 more times. Anyway, with $p=\frac{1}{1000}$, n=3, k=1, the probability is $$ P_{Code\,is\,guessed} = \binom{n}{k} \cdot p^k \cdot (1-p)^{(n-k)} = \binom{3}{1} \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^{(3-1)} = 3 \cdot \frac{1}{1000} \cdot (\frac{999}{1000})^2 = 0.002994003 $$ Again, to confirm the result I tried building the tree: And in this case, $$ P_{Code\,is\,guessed} = \frac{1}{1000} + \frac{999}{1000} \cdot \frac{1}{1000}  + (\frac{999}{1000})^2 \cdot \frac{1}{1000} = 0.002997001 $$ which is different from the previous result, the one that I got using the binomial! This means at least one of these calculations is wrong (and possibly both), but I'm not sure where the error is. Anyway the tree convinces me more, and as I said I suspect that the problem is that the binomial isn't the right choice here, because it assumes that the attacker always makes 3 attempts, and this is not realistic in this scenario. So, these are my questions: Are my calculations correct for case A (the code is always the same)? For case B, I'm sure there's an error. Where is it? I even tried simplifying the problem to rolling a die trying to get a certain face, and if the result is not the desired one, rolling one more time. I think the trick might be that if the first roll is successful we don't have to add the probability of guessing at the second roll, because there simply won't be a second roll. But, again, I'm confused.",,"['probability', 'probability-distributions', 'binomial-distribution']"
