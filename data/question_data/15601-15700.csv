,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Give an example of a function $f$ satisfying $\lim_{x\to 0}(f(x)f(2x))=0$,but $\lim_{x\to 0}f(x)$ does not exists","Give an example of a function  satisfying ,but  does not exists",f \lim_{x\to 0}(f(x)f(2x))=0 \lim_{x\to 0}f(x),Question: Give an example of a function $f$ satisfying the condition $$\lim_{x\to 0}(f(x)f(2x))=0$$ and such that $$\lim_{x\to 0}f(x)$$ does not exists. I think this question have many example. But now I can't to find any example. Thank you,Question: Give an example of a function $f$ satisfying the condition $$\lim_{x\to 0}(f(x)f(2x))=0$$ and such that $$\lim_{x\to 0}f(x)$$ does not exists. I think this question have many example. But now I can't to find any example. Thank you,,"['calculus', 'analysis', 'examples-counterexamples']"
1,Evaluate $\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx$,Evaluate,\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx,$$\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx $$ Help me please. I don't know any ways of solution. Thank you.,$$\int_0^1\frac{x\ln x}{(1+x^2)^2}\ dx $$ Help me please. I don't know any ways of solution. Thank you.,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
2,Integration of $1/(1+\sin x)$,Integration of,1/(1+\sin x),"I solved it using $t=\tan(\frac{x}{2})$ substitution and got $-2/(1+\tan(x/2))+C$, but in my math book solution is $\tan(x/2-\pi/4)+C$. Are those the same expressions and if they are, how do I transform from one to another, or are one(or both) solutions incorrect ?","I solved it using $t=\tan(\frac{x}{2})$ substitution and got $-2/(1+\tan(x/2))+C$, but in my math book solution is $\tan(x/2-\pi/4)+C$. Are those the same expressions and if they are, how do I transform from one to another, or are one(or both) solutions incorrect ?",,"['calculus', 'integration', 'trigonometry']"
3,How can I express the sum of $\sin a+\sin2a+\sin3a+\cdots+\sin(n-1)a$?,How can I express the sum of ?,\sin a+\sin2a+\sin3a+\cdots+\sin(n-1)a,"I want to sum up the partials of a harmonic series, how do I do it? If I was using the 'Lagrange trigonometric identity to solve this problem', how would I plot it on Wolfram mathematica (using which input)?","I want to sum up the partials of a harmonic series, how do I do it? If I was using the 'Lagrange trigonometric identity to solve this problem', how would I plot it on Wolfram mathematica (using which input)?",,"['calculus', 'trigonometry', 'summation', 'problem-solving', 'applications']"
4,Find integral $\int_0^1 \frac{\ln(1+x^2)}{1+x^2} \ dx$ (most likely substitution),Find integral  (most likely substitution),\int_0^1 \frac{\ln(1+x^2)}{1+x^2} \ dx,"$$\int_0^1 \frac{\ln(1+x^2)}{1+x^2} \ dx$$ I tried letting $x^2=\tan \theta$ but it didn't work. What should I do? Please don't give full solution, just a hint and I will continue.","$$\int_0^1 \frac{\ln(1+x^2)}{1+x^2} \ dx$$ I tried letting $x^2=\tan \theta$ but it didn't work. What should I do? Please don't give full solution, just a hint and I will continue.",,"['calculus', 'integration', 'definite-integrals']"
5,Find $\int_{0}^{2\pi} \sqrt{2+2\sin x}dx$,Find,\int_{0}^{2\pi} \sqrt{2+2\sin x}dx,"I'm trying to find the result of the integral in the title. I know the result is 8 (according to my calculator and also wolframalpha), but I integrated it multiplying it by $$ \frac{\sqrt{1-\sin(x)}}{\sqrt{1-\sin(x)}}  $$ after putting de $\sqrt{2}$ out. After that, substitution $u = 1-\sin(x)$ , but my surprise is that it turns out to be 0 when I evaluate the new limits. ¿Can somebody point out my mistake? I found that in some forum, someone integrated something alike, a bit different, but the result is the same that I got: Link and as you can see, if you convert your integration limits, you get that if $x = 0$ , $u = 1 $ and if $ x = 2\pi$ , then $u = 1$ , so of course, you'll get $ 0$ .","I'm trying to find the result of the integral in the title. I know the result is 8 (according to my calculator and also wolframalpha), but I integrated it multiplying it by after putting de out. After that, substitution , but my surprise is that it turns out to be 0 when I evaluate the new limits. ¿Can somebody point out my mistake? I found that in some forum, someone integrated something alike, a bit different, but the result is the same that I got: Link and as you can see, if you convert your integration limits, you get that if , and if , then , so of course, you'll get .","
\frac{\sqrt{1-\sin(x)}}{\sqrt{1-\sin(x)}} 
 \sqrt{2} u = 1-\sin(x) x = 0 u = 1   x = 2\pi u = 1  0","['calculus', 'integration']"
6,Continuity at a point implies continuity on an interval?,Continuity at a point implies continuity on an interval?,,"If $f(x)$ is continuous at $a$, then is there a $\sigma$ such that $f(x)$ is also continuous on $(a-\sigma, a+\sigma)$? This looks very intuitive, but I don't know how to prove it.","If $f(x)$ is continuous at $a$, then is there a $\sigma$ such that $f(x)$ is also continuous on $(a-\sigma, a+\sigma)$? This looks very intuitive, but I don't know how to prove it.",,['calculus']
7,Arclength of the curve $y= \ln( \sec x)$ $ 0 \le x \le \pi/4$,Arclength of the curve,y= \ln( \sec x)  0 \le x \le \pi/4,"Arclength of the curve $y= \ln( \sec x)$ $ 0 \le x \le \pi/4$ I know that I have to find its derivative which is easy, it is $\tan x$ Then I put it into the arclength formula $$\int \sqrt {1 - \tan^2 x}$$ From here I am not sure what to do, I put it in wolfram and it got something massive looking. I know I can't use u substitution and I am pretty certain I have to algebraicly manipulate this before I can continue but I do not know how.","Arclength of the curve $y= \ln( \sec x)$ $ 0 \le x \le \pi/4$ I know that I have to find its derivative which is easy, it is $\tan x$ Then I put it into the arclength formula $$\int \sqrt {1 - \tan^2 x}$$ From here I am not sure what to do, I put it in wolfram and it got something massive looking. I know I can't use u substitution and I am pretty certain I have to algebraicly manipulate this before I can continue but I do not know how.",,['calculus']
8,How can a function have a vertical tangent and be continuous?,How can a function have a vertical tangent and be continuous?,,"I read somewhere that, ""a function with a vertical tangent may be continuous but not differentiable."" Is this correct and, if so, what is an example of it? I can't think how a function with an asymptote can be continuous.","I read somewhere that, ""a function with a vertical tangent may be continuous but not differentiable."" Is this correct and, if so, what is an example of it? I can't think how a function with an asymptote can be continuous.",,"['calculus', 'limits', 'derivatives']"
9,Proving $a_n = \frac{(-1)^n n}{n+1}$ has no limit,Proving  has no limit,a_n = \frac{(-1)^n n}{n+1},"I want to prove the sequence $$a_n = \frac{(-1)^n\cdot n}{n+1}$$ has no limit as $\,n\to+\infty$ . I tried to work with inequalities to get that $\,|a_n-L|\geqslant\varepsilon\,$ and the way I tried to solve it was to divide into cases: $\,L\geqslant0\,$ or $\,L<0\,.$ When I did the case with $\,L\geqslant0\,,\,$ I chose an even $\,n\,$ and I found there is $\,\varepsilon=L\,$ for which this is true, but I don't know if I am allowed to represent $\,\varepsilon\,$ with $\,L\,$ or should I represent it as a number. And I would also be glad if someone could show me the way to solve this because my prof hasn't shown us this although he gave us to do that.","I want to prove the sequence has no limit as . I tried to work with inequalities to get that and the way I tried to solve it was to divide into cases: or When I did the case with I chose an even and I found there is for which this is true, but I don't know if I am allowed to represent with or should I represent it as a number. And I would also be glad if someone could show me the way to solve this because my prof hasn't shown us this although he gave us to do that.","a_n = \frac{(-1)^n\cdot n}{n+1} \,n\to+\infty \,|a_n-L|\geqslant\varepsilon\, \,L\geqslant0\, \,L<0\,. \,L\geqslant0\,,\, \,n\, \,\varepsilon=L\, \,\varepsilon\, \,L\,","['calculus', 'sequences-and-series', 'limits', 'epsilon-delta']"
10,Advanced calculus book recommendations.,Advanced calculus book recommendations.,,"What calculus books should I use to learn more advanced calculus after Stewart's, Larson's book and Thomas' book? I just finished a calculus $3$ course and I want to learn more about calculus. Also, it seems that famous calculus book like Thomas', Larson's and Stewart's books are considered basic and elementary books and they don't cover many topics in calculus like special functions, proofs of many theorems and rigorous arguments, etc.I figured that rigour and proofs is in a separate course called Real analysis and I found some good sources to learn it, but I don't want to learn rigorous mathematics yet,I want a book that has more theorems of calculus that elementary books like Stewart didn't cover like (the proof of $\pi$ is irrational, more techniques of integrals and special functions, etc ...) or cover them in more detail and depth and I am not sure what books to use to learn more about these topics  or to learn more advanced calculus.","What calculus books should I use to learn more advanced calculus after Stewart's, Larson's book and Thomas' book? I just finished a calculus course and I want to learn more about calculus. Also, it seems that famous calculus book like Thomas', Larson's and Stewart's books are considered basic and elementary books and they don't cover many topics in calculus like special functions, proofs of many theorems and rigorous arguments, etc.I figured that rigour and proofs is in a separate course called Real analysis and I found some good sources to learn it, but I don't want to learn rigorous mathematics yet,I want a book that has more theorems of calculus that elementary books like Stewart didn't cover like (the proof of is irrational, more techniques of integrals and special functions, etc ...) or cover them in more detail and depth and I am not sure what books to use to learn more about these topics  or to learn more advanced calculus.",3 \pi,"['calculus', 'integration']"
11,Why must delta be defined in terms of epsilon only?,Why must delta be defined in terms of epsilon only?,,"I'm a mathematics tutor trying to get a better understanding of the theory of epsilon-delta limit proofs. I can prove linear and constant epsilon delta proofs easily, and I understand the proof form and definitions, but nonlinear ones stump me. For example, take Problem 4., Page 3 here: $$ \lim_{x \rightarrow 2} {x^2 + x - 2} = 4 $$ The paper works through it as follows: \begin{align} |f(x)-L| < \epsilon &\implies |(x^2+x-2) - 4| < \epsilon \\ &\implies |(x^2+x-6)| < \epsilon \\ &\implies|x+3||x-2| < \epsilon \\ &\implies |x-2| < \frac{\epsilon}{|x+3|} \end{align} Now, this is the point where I would add $$ \text{let} \ \delta = \frac{\epsilon}{|x+3|} $$ However, no source I've seen does that. This is where I get a little confused. The epsilon-delta definition means that the expression $$ \lim_{x\rightarrow c }f(x) = L $$ is equivalent to $$ \forall\epsilon >0 \ \exists\delta>0 \ s.t. 0 < |x-c| < \delta \implies |f(x) - L|<\epsilon. $$ Now, the definition has no qualifications for $x$ . $x$ is just the input of the function. However, the paper goes on to say ""In general delta must be in terms of epsilon only, without any extra variables."" Why? The proof, when done ""forward"", goes through just fine for $\epsilon: \epsilon(\delta, x)$ . And intuitively, this makes sense: for some parts of $f(x)$ , the limits on epsilon will be different. However, every source I've seen finds limits on $|x+3|$ in some region and uses a constant in its place. Why must this be done? Why not leave $|x+3|$ in the denominator and be done with it?","I'm a mathematics tutor trying to get a better understanding of the theory of epsilon-delta limit proofs. I can prove linear and constant epsilon delta proofs easily, and I understand the proof form and definitions, but nonlinear ones stump me. For example, take Problem 4., Page 3 here: The paper works through it as follows: Now, this is the point where I would add However, no source I've seen does that. This is where I get a little confused. The epsilon-delta definition means that the expression is equivalent to Now, the definition has no qualifications for . is just the input of the function. However, the paper goes on to say ""In general delta must be in terms of epsilon only, without any extra variables."" Why? The proof, when done ""forward"", goes through just fine for . And intuitively, this makes sense: for some parts of , the limits on epsilon will be different. However, every source I've seen finds limits on in some region and uses a constant in its place. Why must this be done? Why not leave in the denominator and be done with it?","
\lim_{x \rightarrow 2} {x^2 + x - 2} = 4
 \begin{align}
|f(x)-L| < \epsilon &\implies |(x^2+x-2) - 4| < \epsilon \\
&\implies |(x^2+x-6)| < \epsilon \\
&\implies|x+3||x-2| < \epsilon \\
&\implies |x-2| < \frac{\epsilon}{|x+3|}
\end{align} 
\text{let} \ \delta = \frac{\epsilon}{|x+3|}
 
\lim_{x\rightarrow c }f(x) = L
 
\forall\epsilon >0 \ \exists\delta>0 \ s.t. 0 < |x-c| < \delta \implies |f(x) - L|<\epsilon.
 x x \epsilon: \epsilon(\delta, x) f(x) |x+3| |x+3|","['calculus', 'limits', 'epsilon-delta']"
12,General formula for a sum of quadratic sequence,General formula for a sum of quadratic sequence,,"I understand that the general formula for a sum of quadratic sequence is : $\displaystyle \sum_{i=1}^n {i^2} = \frac{n(n+1)(2n+1)}{6}$ However, my question is that does $i$ here has to be single term always? Can I still use the formula if I am calculating $\displaystyle \sum_{i=1}^n {(1+i)^2} $ ? For example, I was trying to calculate $\displaystyle \sum_{i=1}^3 {(2+i)^2} $ , and this is what I did $\displaystyle \frac{(2+n)((2+n)+1)(2(2+n)+1)}{6}$ $\displaystyle \frac{(2+n)(3+n)(2n+5)}{6}$ $\displaystyle \frac{(5)(6)(11)}{6} = 55$ However, the right answer is 50. I would like to know what is happening here? And why I can't use this formula directly?","I understand that the general formula for a sum of quadratic sequence is : However, my question is that does here has to be single term always? Can I still use the formula if I am calculating ? For example, I was trying to calculate , and this is what I did However, the right answer is 50. I would like to know what is happening here? And why I can't use this formula directly?",\displaystyle \sum_{i=1}^n {i^2} = \frac{n(n+1)(2n+1)}{6} i \displaystyle \sum_{i=1}^n {(1+i)^2}  \displaystyle \sum_{i=1}^3 {(2+i)^2}  \displaystyle \frac{(2+n)((2+n)+1)(2(2+n)+1)}{6} \displaystyle \frac{(2+n)(3+n)(2n+5)}{6} \displaystyle \frac{(5)(6)(11)}{6} = 55,"['calculus', 'summation']"
13,"A puzzling ""failure"" of the Chain Rule","A puzzling ""failure"" of the Chain Rule",,"Consider the standard transformation equations between Cartesian and polar coordinates: \begin{align*} x&=r \cos \theta\\ y&=r \sin \theta \end{align*} and the inverse: $r=\sqrt{x^2+y^2}, \theta=\arctan\frac{y}{x}$. Now consider the following product of derivatives: ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r}}.$ By the chain rule ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r} =  \frac{\partial r}{\partial r} = 1}.$ However, if we calculate each multiplicand in isolation, then transform the  mixed-coordinate result into a single coordinate system, we get: \begin{align*} \frac{\partial r(x,y)}{\partial y}& =\frac{y}{\sqrt{x^2+y^2}}=\sin\theta\\ \frac{\partial y(r,\theta)}{\partial r}& = \sin\theta \end{align*} and therefore, ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r} = \sin^2\theta}$ But we've shown by the chain rule that $f=1$! :giantfireball: I must be abusing the chain rule in some way (in the original context in which I stumbled on this, the correct result is $\sin^2\theta$), but I can't see what I did wrong.  What's going on?","Consider the standard transformation equations between Cartesian and polar coordinates: \begin{align*} x&=r \cos \theta\\ y&=r \sin \theta \end{align*} and the inverse: $r=\sqrt{x^2+y^2}, \theta=\arctan\frac{y}{x}$. Now consider the following product of derivatives: ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r}}.$ By the chain rule ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r} =  \frac{\partial r}{\partial r} = 1}.$ However, if we calculate each multiplicand in isolation, then transform the  mixed-coordinate result into a single coordinate system, we get: \begin{align*} \frac{\partial r(x,y)}{\partial y}& =\frac{y}{\sqrt{x^2+y^2}}=\sin\theta\\ \frac{\partial y(r,\theta)}{\partial r}& = \sin\theta \end{align*} and therefore, ${\displaystyle f=\frac{\partial r(x,y)}{\partial y}\frac{\partial y(r,\theta)}{\partial r} = \sin^2\theta}$ But we've shown by the chain rule that $f=1$! :giantfireball: I must be abusing the chain rule in some way (in the original context in which I stumbled on this, the correct result is $\sin^2\theta$), but I can't see what I did wrong.  What's going on?",,"['calculus', 'chain-rule']"
14,"Compute the following limit, possibly using a Riemann Sum","Compute the following limit, possibly using a Riemann Sum",,$$\lim _{n\to \infty }\sum _{k=1}^n\frac{1}{n+k+\frac{k}{n^2}}$$ I unsuccessfully tried to find two different Riemann Sums converging to the same value close to the given sum so I could use the Squeeze Theorem. Is there any other way to solve this?,$$\lim _{n\to \infty }\sum _{k=1}^n\frac{1}{n+k+\frac{k}{n^2}}$$ I unsuccessfully tried to find two different Riemann Sums converging to the same value close to the given sum so I could use the Squeeze Theorem. Is there any other way to solve this?,,"['calculus', 'limits', 'riemann-sum']"
15,Calculate limit with L'Hopital's rule,Calculate limit with L'Hopital's rule,,"I want to calculate the limit $\displaystyle{\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}}$ . I have done the following: It holds that $\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}=\frac{0}{0}$ . So, we can use L'Hopital's rule: \begin{align*}\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}&=\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x} \\ &=\lim_{x\rightarrow 0}\frac{\left (x^2\cos \left (\frac{1}{x}\right )\right )'}{\left (\sin x\right )'} =\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )+x^2\cdot \left (-\sin \left (\frac{1}{x}\right )\right )\cdot \left (\frac{1}{x}\right )'}{\cos x} \\ &=\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )-x^2\cdot \sin \left (\frac{1}{x}\right )\cdot \left (-\frac{1}{x^2}\right )}{\cos x} \\ & =\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )+\sin \left (\frac{1}{x}\right )}{\cos x}=\lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )+\sin \left (\frac{1}{x}\right )\right ) \\ & =\lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )\right )+\lim_{x\rightarrow 0}\left (\sin \left (\frac{1}{x}\right )\right )\end{align*} We calculate the two limits separately $\lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )\right )$ : \begin{equation*}\left |\cos \left (\frac{1}{x}\right )\right |\leq 1 \Rightarrow -1\leq \cos \left (\frac{1}{x}\right )\leq 1  \Rightarrow -2x\leq 2x\cdot \cos \left (\frac{1}{x}\right )\leq  2x\end{equation*} we consider the limit $x\rightarrow 0$ and we get \begin{equation*}\lim_{x\rightarrow 0} \left (2x\cdot \cos \left (\frac{1}{x}\right ) \right )=0\end{equation*} How can we calculate the limit $\lim_{x\rightarrow 0}\left (\sin \left (\frac{1}{x}\right )\right )$ ?","I want to calculate the limit . I have done the following: It holds that . So, we can use L'Hopital's rule: We calculate the two limits separately : we consider the limit and we get How can we calculate the limit ?",\displaystyle{\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}} \lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}=\frac{0}{0} \begin{align*}\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x}&=\lim_{x\rightarrow 0}\frac{x^2\cos \left (\frac{1}{x}\right )}{\sin x} \\ &=\lim_{x\rightarrow 0}\frac{\left (x^2\cos \left (\frac{1}{x}\right )\right )'}{\left (\sin x\right )'} =\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )+x^2\cdot \left (-\sin \left (\frac{1}{x}\right )\right )\cdot \left (\frac{1}{x}\right )'}{\cos x} \\ &=\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )-x^2\cdot \sin \left (\frac{1}{x}\right )\cdot \left (-\frac{1}{x^2}\right )}{\cos x} \\ & =\lim_{x\rightarrow 0}\frac{2x\cdot \cos \left (\frac{1}{x}\right )+\sin \left (\frac{1}{x}\right )}{\cos x}=\lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )+\sin \left (\frac{1}{x}\right )\right ) \\ & =\lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )\right )+\lim_{x\rightarrow 0}\left (\sin \left (\frac{1}{x}\right )\right )\end{align*} \lim_{x\rightarrow 0}\left (2x\cdot \cos \left (\frac{1}{x}\right )\right ) \begin{equation*}\left |\cos \left (\frac{1}{x}\right )\right |\leq 1 \Rightarrow -1\leq \cos \left (\frac{1}{x}\right )\leq 1  \Rightarrow -2x\leq 2x\cdot \cos \left (\frac{1}{x}\right )\leq  2x\end{equation*} x\rightarrow 0 \begin{equation*}\lim_{x\rightarrow 0} \left (2x\cdot \cos \left (\frac{1}{x}\right ) \right )=0\end{equation*} \lim_{x\rightarrow 0}\left (\sin \left (\frac{1}{x}\right )\right ),"['calculus', 'limits']"
16,Determining compositions of trig functions by knowing Euler's identity etc,Determining compositions of trig functions by knowing Euler's identity etc,,"How does one determine: $$\cos^2(\arctan(x))?$$ I know what it is equal to, since its in the tables. But without working with many trigonometric identities, its not clear how to find such things. How would you see this with the minimal number of trig identities? $\cos^2(\arctan(x))=\cos(\arctan(x))\cos(\arctan(x))=\frac{1}{\sqrt{1+x^2}}\frac{1}{\sqrt{1+x^2}}=\frac1{1+x^2}.$ The one identity I used here, I didn't know. It seems in similar situations, on an exam, I would have massive trouble without these identities. Can all of these sorts of things be solved by knowing something about Eulers identity and such?","How does one determine: $$\cos^2(\arctan(x))?$$ I know what it is equal to, since its in the tables. But without working with many trigonometric identities, its not clear how to find such things. How would you see this with the minimal number of trig identities? $\cos^2(\arctan(x))=\cos(\arctan(x))\cos(\arctan(x))=\frac{1}{\sqrt{1+x^2}}\frac{1}{\sqrt{1+x^2}}=\frac1{1+x^2}.$ The one identity I used here, I didn't know. It seems in similar situations, on an exam, I would have massive trouble without these identities. Can all of these sorts of things be solved by knowing something about Eulers identity and such?",,"['calculus', 'trigonometry']"
17,Integration of power series,Integration of power series,,"I am trying to find an approximate solution of: \begin{equation} \int_{0}^{+\infty} e^{-x}dx \ (=1) \end{equation} from the power series expansion of : \begin{equation} e^{-x}= 1-x+(1/2)\cdot x^2-(1/6)\cdot x^3+(1/24)\cdot x^4-(1/120)\cdot x^5+O(x^6) \end{equation} My Problem is that when I integrate the series term by term, the polynomials wont behave well with the $\infty$ term.. Can you help me please","I am trying to find an approximate solution of: \begin{equation} \int_{0}^{+\infty} e^{-x}dx \ (=1) \end{equation} from the power series expansion of : \begin{equation} e^{-x}= 1-x+(1/2)\cdot x^2-(1/6)\cdot x^3+(1/24)\cdot x^4-(1/120)\cdot x^5+O(x^6) \end{equation} My Problem is that when I integrate the series term by term, the polynomials wont behave well with the $\infty$ term.. Can you help me please",,"['calculus', 'integration', 'power-series']"
18,How to find x and y coordinates based on the given distance?,How to find x and y coordinates based on the given distance?,,"The problem says:  Find the point (coordinates $(x,y)=~?$) which is symmetrical to the point $(4,-2) $ considering the given equation $y=2x-3$ I have found the perpendicular line-slope $y=-~\frac{1}{2}x$ and the  intersection point which is shown in the graph $\left(\frac{6}{5},\frac{-3}{5}\right)$ I'm somehow unable to find the $x$ and $y$ I have found the distance based on the point and point distance equation:$$d(p_1,p_2)= \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\sqrt{\left(\frac{6}{5}-4\right)^2+\left(-\frac{3}{5}+2\right)^2}= \frac{7\sqrt{5}}{5}$$ $$d_1=d_2=d(p_1,p_2)$$ So now I know the distance, the min. distance to the unknown point is the same. What is the easiest way to find the symmetrical $x$ and $y$ coordinates? (This is a high school problem)","The problem says:  Find the point (coordinates $(x,y)=~?$) which is symmetrical to the point $(4,-2) $ considering the given equation $y=2x-3$ I have found the perpendicular line-slope $y=-~\frac{1}{2}x$ and the  intersection point which is shown in the graph $\left(\frac{6}{5},\frac{-3}{5}\right)$ I'm somehow unable to find the $x$ and $y$ I have found the distance based on the point and point distance equation:$$d(p_1,p_2)= \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\sqrt{\left(\frac{6}{5}-4\right)^2+\left(-\frac{3}{5}+2\right)^2}= \frac{7\sqrt{5}}{5}$$ $$d_1=d_2=d(p_1,p_2)$$ So now I know the distance, the min. distance to the unknown point is the same. What is the easiest way to find the symmetrical $x$ and $y$ coordinates? (This is a high school problem)",,"['calculus', 'algebra-precalculus', 'slope']"
19,Why does $\frac{|x|}{x^2}$ reduce to $\frac{1}{|x|}$?,Why does  reduce to ?,\frac{|x|}{x^2} \frac{1}{|x|},"This simplification confused me: $$.....=\frac{|x|}{x^2} = \frac{1}{|x|}$$ I get cancelling a degree of x, but why must you introduce the abs. val sign in the denominator?  Is it because the left side is guarateed to be positive, so you must retain that in the final expression ?","This simplification confused me: $$.....=\frac{|x|}{x^2} = \frac{1}{|x|}$$ I get cancelling a degree of x, but why must you introduce the abs. val sign in the denominator?  Is it because the left side is guarateed to be positive, so you must retain that in the final expression ?",,"['calculus', 'algebra-precalculus']"
20,Help in evaluating $\displaystyle\int\ \cos^2\Big(\arctan\big(\sin\left(\text{arccot}(x)\right)\big)\Big)\ \text{d}x$,Help in evaluating,\displaystyle\int\ \cos^2\Big(\arctan\big(\sin\left(\text{arccot}(x)\right)\big)\Big)\ \text{d}x,"Is there an easy way to prove this result? $$\int\ \cos^2\Big(\arctan\big(\sin\left( \text{arccot}(x)\right)\big)\Big)\ \text{d}x = x - \frac{1}{\sqrt{2}}\arctan\left(\frac{x}{\sqrt{2}}\right)$$ I tried some substitutions but I got nothing helpful, like: $x = \cot (z)$ I also tried the crazy one: $x = \cot(\arcsin(\tan(\arccos(z))))$ Any hint? Thank you!","Is there an easy way to prove this result? I tried some substitutions but I got nothing helpful, like: I also tried the crazy one: Any hint? Thank you!",\int\ \cos^2\Big(\arctan\big(\sin\left( \text{arccot}(x)\right)\big)\Big)\ \text{d}x = x - \frac{1}{\sqrt{2}}\arctan\left(\frac{x}{\sqrt{2}}\right) x = \cot (z) x = \cot(\arcsin(\tan(\arccos(z)))),"['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
21,Fallacy limit problem - Where is the mistake?,Fallacy limit problem - Where is the mistake?,,"This problem comes from our text book. Evaluate  $$ \lim\limits_{x \to 0}\frac{2^x-1-x}{x^2} $$ without using either L'Hopital's rule or Taylor series. The picture below shows the solution given by the text book. Many of the people who responded to this question say that the limit diverges. But according to the solution (see the attached image) given by the text book the limit is  $ \frac{(\ln2)^2}{2} $. Is there an error in the solution given in the attached image? Note : This problem ( and the solution) comes from Cengage, a long time favourite of the students preparing for IIT JEE  Exam (IITs are India's most prestigious engineering institutes.)  It is suprising that no student/teacher has found this mistake all these days. However, once posted on Stackexchange, the fallacy was resolved in a very short time. Thanks to all the people who responded to this problem. Now the mistake in the book's solution is found.","This problem comes from our text book. Evaluate  $$ \lim\limits_{x \to 0}\frac{2^x-1-x}{x^2} $$ without using either L'Hopital's rule or Taylor series. The picture below shows the solution given by the text book. Many of the people who responded to this question say that the limit diverges. But according to the solution (see the attached image) given by the text book the limit is  $ \frac{(\ln2)^2}{2} $. Is there an error in the solution given in the attached image? Note : This problem ( and the solution) comes from Cengage, a long time favourite of the students preparing for IIT JEE  Exam (IITs are India's most prestigious engineering institutes.)  It is suprising that no student/teacher has found this mistake all these days. However, once posted on Stackexchange, the fallacy was resolved in a very short time. Thanks to all the people who responded to this problem. Now the mistake in the book's solution is found.",,"['calculus', 'limits', 'limits-without-lhopital']"
22,How to find $\lim\limits_{x\to 2}f(x)$ if $\lim\limits_{x\to 2}\frac{f(x)-5}{x-2}=100$?,How to find  if ?,\lim\limits_{x\to 2}f(x) \lim\limits_{x\to 2}\frac{f(x)-5}{x-2}=100,"How to find $\lim\limits_{x\to 2}f(x)$ if $\lim\limits_{x\to 2}\frac{f(x)-5}{x-2}=100$? I suppose that we do not use L'Hopital rule here. Then $\lim\limits_{x\to 2}f(x)-5=0$, then $\lim\limits_{x\to 2}f(x)=5.$ I highly doubt the answer, could someone help me understand?","How to find $\lim\limits_{x\to 2}f(x)$ if $\lim\limits_{x\to 2}\frac{f(x)-5}{x-2}=100$? I suppose that we do not use L'Hopital rule here. Then $\lim\limits_{x\to 2}f(x)-5=0$, then $\lim\limits_{x\to 2}f(x)=5.$ I highly doubt the answer, could someone help me understand?",,"['calculus', 'limits', 'functions']"
23,How to recognize an improper integral?,How to recognize an improper integral?,,"I think $\displaystyle \int ^{4} _0 \frac{\sin x}{x} dx$ is not an improper integral. Is this true? If not  true, then  how can one recongnise improper integrals in general?","I think $\displaystyle \int ^{4} _0 \frac{\sin x}{x} dx$ is not an improper integral. Is this true? If not  true, then  how can one recongnise improper integrals in general?",,['calculus']
24,Easy Double Sums Question: $\sum_{m=1}^{\infty} \sum_{n=1}^{\infty} \frac{1}{(m+n)!}$,Easy Double Sums Question:,\sum_{m=1}^{\infty} \sum_{n=1}^{\infty} \frac{1}{(m+n)!},"How to calculate $\sum_{m=1}^{\infty} \sum_{n=1}^{\infty} \dfrac{1}{(m+n)!} $ ? I don't know how to approach it . Please help :) P.S.I am new to Double Sums and am not able to find any good sources to study it , can anyone help please ?","How to calculate $\sum_{m=1}^{\infty} \sum_{n=1}^{\infty} \dfrac{1}{(m+n)!} $ ? I don't know how to approach it . Please help :) P.S.I am new to Double Sums and am not able to find any good sources to study it , can anyone help please ?",,"['calculus', 'sequences-and-series', 'factorial']"
25,Two methods to integrate?,Two methods to integrate?,,Are both methods to solve this equation correct? $$\int \frac{x}{\sqrt{1 + 2x^2}}  dx$$ Method One:  $$u=2x^2$$ $$\frac{1}{4}\int \frac{1}{\sqrt{1^2 + \sqrt{u^2}}}  du$$ $$\frac{1}{4}log(\sqrt{u}+\sqrt{{u} +1})+C$$ $$\frac{1}{4}log(\sqrt{2}x+\sqrt{2x^2+1})+C$$ Method Two $$u=1+2x^2$$ $$\frac{1}{4}\int\frac{du}{\sqrt{u}}$$ $$\frac{1}{2}\sqrt{u}+C$$ $$\frac{1}{2}\sqrt{1+2x^2}+C$$ I am confused why I get two different answers.,Are both methods to solve this equation correct? $$\int \frac{x}{\sqrt{1 + 2x^2}}  dx$$ Method One:  $$u=2x^2$$ $$\frac{1}{4}\int \frac{1}{\sqrt{1^2 + \sqrt{u^2}}}  du$$ $$\frac{1}{4}log(\sqrt{u}+\sqrt{{u} +1})+C$$ $$\frac{1}{4}log(\sqrt{2}x+\sqrt{2x^2+1})+C$$ Method Two $$u=1+2x^2$$ $$\frac{1}{4}\int\frac{du}{\sqrt{u}}$$ $$\frac{1}{2}\sqrt{u}+C$$ $$\frac{1}{2}\sqrt{1+2x^2}+C$$ I am confused why I get two different answers.,,"['calculus', 'integration']"
26,"Find the point on a plane $3x + 4y + z = 1$ that is closest to $(1,0,1)$",Find the point on a plane  that is closest to,"3x + 4y + z = 1 (1,0,1)","Is anyone able to help me with regards to this question? Find the point on a plane $3x + 4y + z = 1$ that is closest to $(1,0,1)$ https://i.sstatic.net/NaFG0.png","Is anyone able to help me with regards to this question? Find the point on a plane $3x + 4y + z = 1$ that is closest to $(1,0,1)$ https://i.sstatic.net/NaFG0.png",,"['calculus', 'algebra-precalculus']"
27,Recursive square root problem [duplicate],Recursive square root problem [duplicate],,"This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) Closed 10 years ago . Give a precise meaning to evaluate the following:   $$\large{\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\dotsb}}}}}$$ Since I think it has a recursive structure (does it?), I reduce the equation to $$ p=\sqrt{1+p} $$ $$ p^2=1+p $$ $$ p^2-p-1=0 $$ $$ p=\frac{1\pm\sqrt{5}}{2} $$ Did I do this right?","This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) Closed 10 years ago . Give a precise meaning to evaluate the following:   $$\large{\sqrt{1+\sqrt{1+\sqrt{1+\sqrt{1+\dotsb}}}}}$$ Since I think it has a recursive structure (does it?), I reduce the equation to $$ p=\sqrt{1+p} $$ $$ p^2=1+p $$ $$ p^2-p-1=0 $$ $$ p=\frac{1\pm\sqrt{5}}{2} $$ Did I do this right?",,"['calculus', 'sequences-and-series', 'recurrence-relations', 'nested-radicals']"
28,"Given $\lim_{x \rightarrow a}f(x)+\frac1{\left|f(x)\right|}=0$, what is $\lim_{x \rightarrow a}f(x)$?","Given , what is ?",\lim_{x \rightarrow a}f(x)+\frac1{\left|f(x)\right|}=0 \lim_{x \rightarrow a}f(x),"Another question I am struggling with: Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be defined in a neighborhood of $a$ (except maybe $a$ itself) and suppose that, $\lim_{x \rightarrow a}\left(f(x)+\dfrac{1}{\left|f(x)\right|}\right)=0$ . Find $\lim_{x \rightarrow a}f(x)$ , and prove by definition, that this is indeed the limit. Thank you all for your answers!! But.. How can I prove by definition that this is indeed the limit? take $\epsilon>0$ , I have to show that there exists a $\delta>0$ such that, $|x-a| \leq \delta$ implies $|f(x)+1| \leq \epsilon$ . now, I do know that there exists an $\delta_1>0$ , such that $|f(x)+\frac{1}{|f(x)|}|< \epsilon$ .Or, $\frac{\epsilon}{k}$ for some constant $k$ But, how can I continue from there?","Another question I am struggling with: Let be defined in a neighborhood of (except maybe itself) and suppose that, . Find , and prove by definition, that this is indeed the limit. Thank you all for your answers!! But.. How can I prove by definition that this is indeed the limit? take , I have to show that there exists a such that, implies . now, I do know that there exists an , such that .Or, for some constant But, how can I continue from there?",f:\mathbb{R} \rightarrow \mathbb{R} a a \lim_{x \rightarrow a}\left(f(x)+\dfrac{1}{\left|f(x)\right|}\right)=0 \lim_{x \rightarrow a}f(x) \epsilon>0 \delta>0 |x-a| \leq \delta |f(x)+1| \leq \epsilon \delta_1>0 |f(x)+\frac{1}{|f(x)|}|< \epsilon \frac{\epsilon}{k} k,"['calculus', 'limits']"
29,"Asymptotic solution to the integral $\int_{-\pi/2}^{\pi/2} (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x$",Asymptotic solution to the integral,"\int_{-\pi/2}^{\pi/2} (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x","Recently, I have posted a question on how to find a reduction formula for the trigonometric integral $$\int (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x.$$ This problem seems to be tough, however. When trying to solve (as proposed in a comment on my previous question) the integral using the Binomial theorem, one obtains a sum that seems to be quite complicated. Thus, there seems to be only a little chance for a reasonable reduction formula to exist. As a consequence, I became interested in solving the integral asymptotically. So my question is how to obtain a reasonable asymptotic estimate for the following definite integral, as $n \to \infty$: $$\int_{-\pi/2}^{\pi/2} (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x.$$ I have tried to use the Laplace's method , but with my small knowledge and without any experience, I have not succeeded. Thus, I would be grateful for hints.","Recently, I have posted a question on how to find a reduction formula for the trigonometric integral $$\int (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x.$$ This problem seems to be tough, however. When trying to solve (as proposed in a comment on my previous question) the integral using the Binomial theorem, one obtains a sum that seems to be quite complicated. Thus, there seems to be only a little chance for a reasonable reduction formula to exist. As a consequence, I became interested in solving the integral asymptotically. So my question is how to obtain a reasonable asymptotic estimate for the following definite integral, as $n \to \infty$: $$\int_{-\pi/2}^{\pi/2} (\alpha + \sin x)^n \cos^2 x\,\mathrm{d}x.$$ I have tried to use the Laplace's method , but with my small knowledge and without any experience, I have not succeeded. Thus, I would be grateful for hints.",,"['calculus', 'integration', 'asymptotics']"
30,Is there a simple proof that a power series can be differentiated term by term?,Is there a simple proof that a power series can be differentiated term by term?,,"I know that the derivative of the sum of a power series can be calculated by summing the derivatives of the terms, and that the resulting series has the same radius of convergence as the original. The proofs I've seen, however, have either been quite long and involved, relying on several lemmas (e.g., the one on ProofWiki) or waved their hands in some difficult spots. Does anyone know of a simpler approach?","I know that the derivative of the sum of a power series can be calculated by summing the derivatives of the terms, and that the resulting series has the same radius of convergence as the original. The proofs I've seen, however, have either been quite long and involved, relying on several lemmas (e.g., the one on ProofWiki) or waved their hands in some difficult spots. Does anyone know of a simpler approach?",,"['calculus', 'derivatives', 'power-series']"
31,"What is $\;\int xe^{-x^2} \,dx\;?$",What is,"\;\int xe^{-x^2} \,dx\;?","What is $$\int xe^{-x^2} dx\quad?$$ I used substitution to rewrite it as $$\int -\dfrac{1}{2}e^u\, du$$ but this is too hard for me to evaluate. When I used wolfram alpha for $\int e^{-x^2} dx$ I got a weird answer involving a so called error function and pi and such (I'm guessing it has something to do with Euler's identity, but I'm fairly certain this is above my textbook's level).","What is $$\int xe^{-x^2} dx\quad?$$ I used substitution to rewrite it as $$\int -\dfrac{1}{2}e^u\, du$$ but this is too hard for me to evaluate. When I used wolfram alpha for $\int e^{-x^2} dx$ I got a weird answer involving a so called error function and pi and such (I'm guessing it has something to do with Euler's identity, but I'm fairly certain this is above my textbook's level).",,"['calculus', 'integration', 'indefinite-integrals']"
32,"Find the equation of the tangent line to the polar curve at given $(x,y)$.",Find the equation of the tangent line to the polar curve at given .,"(x,y)","Find the equation(s) of the tangent line(s) to the curve given $(x,y)$ point. $$r=1-2\sin(\theta )$$ at $(0,0)$.  I am not sure how to go about find the the tangent line. Do I need to convert from polar to rectangular? Thanks!","Find the equation(s) of the tangent line(s) to the curve given $(x,y)$ point. $$r=1-2\sin(\theta )$$ at $(0,0)$.  I am not sure how to go about find the the tangent line. Do I need to convert from polar to rectangular? Thanks!",,['calculus']
33,Strictly formal proof of $ \displaystyle \lim_{x \to 0} \frac{\sin(x)}{x} = 1 $.,Strictly formal proof of ., \displaystyle \lim_{x \to 0} \frac{\sin(x)}{x} = 1 ,"I’m looking for a proof of $ \displaystyle \lim_{x \to 0} \frac{\sin(x)}{x} = 1 $ that does not use other trigonometric functions or any first-order approximation to the sine function. Is this possible? The other proofs that I’ve seen on this website don’t really fit these stringent requirements, so I was hoping to see a different kind of demonstration altogether. Thanks!!","I’m looking for a proof of $ \displaystyle \lim_{x \to 0} \frac{\sin(x)}{x} = 1 $ that does not use other trigonometric functions or any first-order approximation to the sine function. Is this possible? The other proofs that I’ve seen on this website don’t really fit these stringent requirements, so I was hoping to see a different kind of demonstration altogether. Thanks!!",,"['calculus', 'limits', 'trigonometry']"
34,Euler and infinity,Euler and infinity,,"What do people mean when they say that Euler treated infinity differently? I read in various books that, today, mathematicians would not approve of Euler's methods and his proofs lacked rigor. Can anyone elaborate? Edit: If I remember correctly Euler's original solution to the Basel problem is as follows. Using Taylor series for $\sin (s)/s$ we write $$\sin (s)/s = 1 - {s^2}/3! + {s^4}/5! -  \cdots $$ but $\sin (s)/s$ vanishes at $\pm \pi$, $\pm 2\pi$, etc. hence $$\frac{{\sin s}}{s} = {\left( {1 - \frac{s}{\pi }} \right)}{\left( {1 + \frac{s}{\pi }} \right)}{\left( {1 - \frac{s}{{2\pi }}} \right)}{\left( {1 + \frac{s}{{2\pi }}} \right)}{\left( {1 - \frac{s}{{3\pi }}} \right)}{\left( {1 + \frac{s}{{3\pi }}} \right)} \cdots$$ or $$\frac{{\sin s}}{s} = {\left( {1 - \frac{{{s^2}}}{{{1^2}\pi^2}}} \right)}{\left( {1 - \frac{{{s^2}}}{{{2^2}{\pi ^2}}}} \right)}{\left( {1 - \frac{{{s^2}}}{{{3^2}{\pi ^2}}}} \right)} \cdots$$ which is $$\frac{{\sin s}}{s} = 1 - \frac{{{s^2}}}{{{\pi ^2}}}{\left( {\frac{1}{{{1^2}}} + \frac{1}{{{2^2}}} + \frac{1}{{{3^2}}} +  \cdots } \right)} +  \cdots.$$ Equating coefficients yields $$\zeta (2) = \frac{{{\pi ^2}}}{6}.$$ But $\pm \pi$, $\pm 2\pi$, etc. are also roots of ${e^s}\sin (s)/s$, correct? So equating coefficients does not give ${\pi ^2}/6$.","What do people mean when they say that Euler treated infinity differently? I read in various books that, today, mathematicians would not approve of Euler's methods and his proofs lacked rigor. Can anyone elaborate? Edit: If I remember correctly Euler's original solution to the Basel problem is as follows. Using Taylor series for $\sin (s)/s$ we write $$\sin (s)/s = 1 - {s^2}/3! + {s^4}/5! -  \cdots $$ but $\sin (s)/s$ vanishes at $\pm \pi$, $\pm 2\pi$, etc. hence $$\frac{{\sin s}}{s} = {\left( {1 - \frac{s}{\pi }} \right)}{\left( {1 + \frac{s}{\pi }} \right)}{\left( {1 - \frac{s}{{2\pi }}} \right)}{\left( {1 + \frac{s}{{2\pi }}} \right)}{\left( {1 - \frac{s}{{3\pi }}} \right)}{\left( {1 + \frac{s}{{3\pi }}} \right)} \cdots$$ or $$\frac{{\sin s}}{s} = {\left( {1 - \frac{{{s^2}}}{{{1^2}\pi^2}}} \right)}{\left( {1 - \frac{{{s^2}}}{{{2^2}{\pi ^2}}}} \right)}{\left( {1 - \frac{{{s^2}}}{{{3^2}{\pi ^2}}}} \right)} \cdots$$ which is $$\frac{{\sin s}}{s} = 1 - \frac{{{s^2}}}{{{\pi ^2}}}{\left( {\frac{1}{{{1^2}}} + \frac{1}{{{2^2}}} + \frac{1}{{{3^2}}} +  \cdots } \right)} +  \cdots.$$ Equating coefficients yields $$\zeta (2) = \frac{{{\pi ^2}}}{6}.$$ But $\pm \pi$, $\pm 2\pi$, etc. are also roots of ${e^s}\sin (s)/s$, correct? So equating coefficients does not give ${\pi ^2}/6$.",,"['calculus', 'math-history', 'nonstandard-analysis']"
35,$\int_0^1 {\frac{{\ln (1 - x)}}{x}}$ without power series,without power series,\int_0^1 {\frac{{\ln (1 - x)}}{x}},Is there a way to calculate $$\int_0^1{ \ln (1 - x)\over x}\;dx$$ without using power series?,Is there a way to calculate $$\int_0^1{ \ln (1 - x)\over x}\;dx$$ without using power series?,,"['calculus', 'integration']"
36,Evaluating $\int_{0}^{1} \frac{x^{2} + 1}{x^{4} + 1 } \ dx$,Evaluating,\int_{0}^{1} \frac{x^{2} + 1}{x^{4} + 1 } \ dx,"How do I evaluate  $$\int_{0}^{1} \frac{x^{2} + 1}{x^{4} + 1 } \ dx$$ I tried using substitution but I am getting stuck. If there was $x^3$ term in the numerator, then this would have been easy, but this one doesn't.","How do I evaluate  $$\int_{0}^{1} \frac{x^{2} + 1}{x^{4} + 1 } \ dx$$ I tried using substitution but I am getting stuck. If there was $x^3$ term in the numerator, then this would have been easy, but this one doesn't.",,"['calculus', 'integration', 'definite-integrals']"
37,"Evaluating $\int\frac{x^{1/2}}{1+x^2}\,dx.$",Evaluating,"\int\frac{x^{1/2}}{1+x^2}\,dx.","Compute $$\int\frac{x^{1/2}}{1+x^2}\,dx.$$ All I can think of is some integration by substitution. But ran into something scary. Anyone have any tricks?","Compute $$\int\frac{x^{1/2}}{1+x^2}\,dx.$$ All I can think of is some integration by substitution. But ran into something scary. Anyone have any tricks?",,"['calculus', 'integration', 'indefinite-integrals']"
38,Intuitive Understanding About the Implicit Function Theorem,Intuitive Understanding About the Implicit Function Theorem,,"In multivariable calculus, given a function like $F(x,y,z) =0$, the implicit function $z=f(x,y)$ exists if and only if $\frac{\partial F}{\partial z} \not = 0$. And the implicit function is given by $\frac{dz}{dy}=-\frac{\frac{\partial F}{\partial y}}{\frac{\partial F}{\partial z}}$. The theorem can be proved by mathematical reasoning . But I want to know whether there is some intuitive understanding of the theorem, say geometry intuition in the three dimensional space, etc.","In multivariable calculus, given a function like $F(x,y,z) =0$, the implicit function $z=f(x,y)$ exists if and only if $\frac{\partial F}{\partial z} \not = 0$. And the implicit function is given by $\frac{dz}{dy}=-\frac{\frac{\partial F}{\partial y}}{\frac{\partial F}{\partial z}}$. The theorem can be proved by mathematical reasoning . But I want to know whether there is some intuitive understanding of the theorem, say geometry intuition in the three dimensional space, etc.",,['calculus']
39,"Convergence of the Integral $ \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx$",Convergence of the Integral," \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx","Here is an old question from my real analysis exam. It has been bugging me for the good part of a year. Does the following integral converge? $$ \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx$$ I'm pretty sure the comparison test is the way to go. Any insight would be greatly appreciated. Thanks.","Here is an old question from my real analysis exam. It has been bugging me for the good part of a year. Does the following integral converge? $$ \int_0^1 \frac{1}{\sqrt{\sin x}} \, dx$$ I'm pretty sure the comparison test is the way to go. Any insight would be greatly appreciated. Thanks.",,"['calculus', 'definite-integrals']"
40,"Why is this function continuous, unlike the Dirichlet function?","Why is this function continuous, unlike the Dirichlet function?",,"My teacher showed us this function and told us it was continuous at all non-$\mathbb{Q}$ points: $$ f(x) = \begin{cases}   x & \text{ if } x\in\mathbb{Q} \\\\   0 & \text{ if }x\notin\mathbb{Q} \end{cases} $$ However, Wolfram MathWorld says the Dirichlet function , which is very similar, is discontinuous at all points. Why is one continuous and the other not?","My teacher showed us this function and told us it was continuous at all non-$\mathbb{Q}$ points: $$ f(x) = \begin{cases}   x & \text{ if } x\in\mathbb{Q} \\\\   0 & \text{ if }x\notin\mathbb{Q} \end{cases} $$ However, Wolfram MathWorld says the Dirichlet function , which is very similar, is discontinuous at all points. Why is one continuous and the other not?",,"['calculus', 'analysis']"
41,The derivative of a product of more than two functions,The derivative of a product of more than two functions,,"I'm trying to generalize the product rule to more than the product of two functions using the fact that I can treat the product of $n$-1 functions as a single one. Here is an example of what I mean: $[f(x)g(x)h(x)]' = [f(x)p(x)]'$ where $p(x) = g(x)h(x)$ $[f(x)p(x)]' = f'(x)p(x) + f(x)p'(x) = f'(x)p(x) + f(x)[g(x)h(x)]'$ $f'(x)p(x) + f(x)[g(x)h(x)]' = f'(x)g(x)h(x) + f(x)[g'(x)h(x) + g(x)h'(x)]'$ which equals $f'(x)g(x)h(x) + f(x)g'(x)h(x) + f(x)g(x)h'(x)$ I generalized this as follows: $$\Big[\prod_{i=1}^{n}f_i(x)\Big]'= f_1'(x)g_1(x) + f_1(x)g'_1(x)$$ where $g_m(x)=$$\prod_{i=1}^{n-m}f_i(x)$, and $g'_{m-1}=[f_m(x)g_m(x)]'=f'_m(x)g_m(x) + f_m(x)g'_m(x)$. Now, I do realize that this is a generalization, and there is  really nothing to prove, but say I wanted to prove that $$\Big[\prod_{i=1}^{n}f_i(x)\Big]'=\sum_{i=1}^{n}f'_i(x)h_i(x)$$ where $h_i(x)=\frac{1}{f_i(x)}\prod_{j=1}^nf_j(x)$, how would I go about doing this (using the generalization above)? I apologize if my notation is hard to understand. Thank you.","I'm trying to generalize the product rule to more than the product of two functions using the fact that I can treat the product of $n$-1 functions as a single one. Here is an example of what I mean: $[f(x)g(x)h(x)]' = [f(x)p(x)]'$ where $p(x) = g(x)h(x)$ $[f(x)p(x)]' = f'(x)p(x) + f(x)p'(x) = f'(x)p(x) + f(x)[g(x)h(x)]'$ $f'(x)p(x) + f(x)[g(x)h(x)]' = f'(x)g(x)h(x) + f(x)[g'(x)h(x) + g(x)h'(x)]'$ which equals $f'(x)g(x)h(x) + f(x)g'(x)h(x) + f(x)g(x)h'(x)$ I generalized this as follows: $$\Big[\prod_{i=1}^{n}f_i(x)\Big]'= f_1'(x)g_1(x) + f_1(x)g'_1(x)$$ where $g_m(x)=$$\prod_{i=1}^{n-m}f_i(x)$, and $g'_{m-1}=[f_m(x)g_m(x)]'=f'_m(x)g_m(x) + f_m(x)g'_m(x)$. Now, I do realize that this is a generalization, and there is  really nothing to prove, but say I wanted to prove that $$\Big[\prod_{i=1}^{n}f_i(x)\Big]'=\sum_{i=1}^{n}f'_i(x)h_i(x)$$ where $h_i(x)=\frac{1}{f_i(x)}\prod_{j=1}^nf_j(x)$, how would I go about doing this (using the generalization above)? I apologize if my notation is hard to understand. Thank you.",,"['calculus', 'products']"
42,"An Alternate Proof to a Theorem Involving ""e""","An Alternate Proof to a Theorem Involving ""e""",,"In a paper, it was claimed that $\lim_{x \to \infty} (1-\frac{f(x)}{x})^x \sim e^{-f(x)}$ when $\frac{(f(x))^2}{x}$ is $o(1)$. I proved the claim in the following way; however, I'm seeking a simpler proof. Define $g(x) = \frac{(1-f(x)/x)^x}{x}$ and $h(x) = \frac{e^{-x}}{x}$. To prove the theorem, we must show that $\lim_{x \to \infty} \frac{g(x)}{h(f(x))} = 1$ when $\frac{(f(x))^2}{x}$ is $o(1)$. To this end, we use the binary expansion for $g(x)$, and Taylor series for $h(x)$: $\lim_{x \to \infty} g(x) = \lim_{x \to \infty} \frac{(x-f(x))^x}{x^{x+1}} = \lim_{x \to \infty} \frac{x^x - \binom{x}{1}x^{x-1}f(x) + \binom{x}{2}x^{x-2}(f(x))^2 - \cdots}{x^{x+1}} = \lim_{x \to \infty} \frac{1-f(x)}{x}$ (The last identity follows from the fact that $\frac{(f(x))^2}{x}$ is $o(1)$; that is $\lim_{x \to \infty} \frac{(f(x))^2}{x} = 0$.) Now, since $h(x) \sim \frac{1 - x + x^2/2 - \cdots}{x}$, we have $h(f(x)) \sim \frac{1 - f(x) + (f(x))^2/2 - \cdots}{x}$, and $\lim_{x \to \infty} h(f(x)) = \lim_{x \to \infty} \frac{1-f(x)}{x}$. (Again, the last identity follows from the fact that $\frac{(f(x))^2}{x}$ is $o(1)$.) Combining the two limits, we see that $\lim_{x \to \infty} \frac{g(x)}{h(f(x))} = 1$. As I said, this proof is long, and to me, it is not appealing. Does anyone know a better proof?","In a paper, it was claimed that $\lim_{x \to \infty} (1-\frac{f(x)}{x})^x \sim e^{-f(x)}$ when $\frac{(f(x))^2}{x}$ is $o(1)$. I proved the claim in the following way; however, I'm seeking a simpler proof. Define $g(x) = \frac{(1-f(x)/x)^x}{x}$ and $h(x) = \frac{e^{-x}}{x}$. To prove the theorem, we must show that $\lim_{x \to \infty} \frac{g(x)}{h(f(x))} = 1$ when $\frac{(f(x))^2}{x}$ is $o(1)$. To this end, we use the binary expansion for $g(x)$, and Taylor series for $h(x)$: $\lim_{x \to \infty} g(x) = \lim_{x \to \infty} \frac{(x-f(x))^x}{x^{x+1}} = \lim_{x \to \infty} \frac{x^x - \binom{x}{1}x^{x-1}f(x) + \binom{x}{2}x^{x-2}(f(x))^2 - \cdots}{x^{x+1}} = \lim_{x \to \infty} \frac{1-f(x)}{x}$ (The last identity follows from the fact that $\frac{(f(x))^2}{x}$ is $o(1)$; that is $\lim_{x \to \infty} \frac{(f(x))^2}{x} = 0$.) Now, since $h(x) \sim \frac{1 - x + x^2/2 - \cdots}{x}$, we have $h(f(x)) \sim \frac{1 - f(x) + (f(x))^2/2 - \cdots}{x}$, and $\lim_{x \to \infty} h(f(x)) = \lim_{x \to \infty} \frac{1-f(x)}{x}$. (Again, the last identity follows from the fact that $\frac{(f(x))^2}{x}$ is $o(1)$.) Combining the two limits, we see that $\lim_{x \to \infty} \frac{g(x)}{h(f(x))} = 1$. As I said, this proof is long, and to me, it is not appealing. Does anyone know a better proof?",,"['calculus', 'asymptotics']"
43,An approximation of an integral,An approximation of an integral,,"Is there any good way to approximate following integral? $$\int_0^{0.5}\frac{x^2}{\sqrt{2\pi}\sigma}\cdot \exp\left(-\frac{(x^2-\mu)^2}{2\sigma^2}\right)\mathrm dx$$ $\mu$ is between $0$ and $0.25$, the problem is in $\sigma$ which is always positive, but it can be arbitrarily small. I was trying to expand it using Taylor series, but terms looks more or less this $\pm a_n\cdot\frac{x^{2n+3}}{\sigma^{2n}}$ and that can be arbitrarily large, so the error is significant.","Is there any good way to approximate following integral? $$\int_0^{0.5}\frac{x^2}{\sqrt{2\pi}\sigma}\cdot \exp\left(-\frac{(x^2-\mu)^2}{2\sigma^2}\right)\mathrm dx$$ $\mu$ is between $0$ and $0.25$, the problem is in $\sigma$ which is always positive, but it can be arbitrarily small. I was trying to expand it using Taylor series, but terms looks more or less this $\pm a_n\cdot\frac{x^{2n+3}}{\sigma^{2n}}$ and that can be arbitrarily large, so the error is significant.",,"['calculus', 'integration', 'approximation']"
44,Integrals of the square root of a cubic polynomial,Integrals of the square root of a cubic polynomial,,"Say I have a function $$V(x)=A(x-x_1)(x-x_2)(x-x_3)$$ where $x_1$, $x_2$, $x_3$ are the three roots in increasing order and $A$ is positive. Clearly $V(x)$ is positive at large $x > x_3$, negative between $x_2$ and $x_3$, and so on. Now, say I wish to evaluate $$\int_{x_2}^{x_3}\sqrt{-V(x)}\mathrm dx$$ How do I do it?","Say I have a function $$V(x)=A(x-x_1)(x-x_2)(x-x_3)$$ where $x_1$, $x_2$, $x_3$ are the three roots in increasing order and $A$ is positive. Clearly $V(x)$ is positive at large $x > x_3$, negative between $x_2$ and $x_3$, and so on. Now, say I wish to evaluate $$\int_{x_2}^{x_3}\sqrt{-V(x)}\mathrm dx$$ How do I do it?",,['calculus']
45,Can a discontinuous function have a continuous derivative?,Can a discontinuous function have a continuous derivative?,,"Main Question: Is it possible for a function f to have a derivative at a point x but be discontinuous at that point? Consider a function that is defined as follows: $$f(x)=\begin{cases} x^2 & x \leq c \\ax+b & x > c \end{cases}$$ We are asked to find constants a,b,c such that the derivative of f at c exists.  Consider the situation where $a=2c$ .  Following the limit definition of the derivative, we have that $f'(c)$ is equals to: $$\lim_{h\to0}\frac{f(c+h)-f(c)}{h}$$ provided that the limit is defined. To see that, we may examine the limit as $x\to0-$ and as $x\to0+$ . $$\begin{equation}\lim_{h\to0+}\frac{f(c+h)-f(c)}{h} \\ =\lim_{h\to0+}\frac{a(c+h)+b-(ac+b)}{h}\end{equation}\\=\lim_{h\to0+}\frac{ah}{h}\\=a=2c$$ For when $x\to0-$ : $$\begin{equation}\lim_{h\to0-}\frac{f(c+h)-f(c)}{h} \\ =\lim_{h\to0-}\frac{(c+h)^2-c^2}{h}\end{equation}\\=\lim_{h\to0-}\frac{2ch+h^2}{h}\\=2c$$ Thus, by definition if $a=2c$ then for all values b $f'(c)$ exists and is equal to 2c.  Here is the issue, if $f'(c)$ exists for all values of b with the aforementioned condition then it could certainly be possible that $f(x)$ is discontinuous at c which contradicts an earlier theorem which states that if a function f has a derivative at a point x, then it is also continuous at x. This is an example graph in desmos: https://www.desmos.com/calculator/acym19fdm2 . This creates a situation where the function f has a derivative at the point x but it is not continuous at that point.  Am I doing something wrong here? Edit: As X-Rui and many others in the comments and answers pointed out, my error was in computing the right-hand limit.  f(c) should always be equal to $c^2$ regardless of the limit since c is constant and f(c) was so defined.  Hence the right-hand side limit computation should be as follows: $$\begin{equation}\lim_{h\to0+}\frac{f(c+h)-f(c)}{h} \\ = \lim_{h\to0+}\frac{a(c+h)+b-c^2}{h}\end{equation}$$ From here we intend to find an values of a,b,c such that this limit will agree with the value of the left limit of 2c.  Assume that there exists such a value c, then since f is differentiable at c f is continuous at c.  Hence $ac+b=c^2$ by continuity (as pointed out by stoic-santiago).  Then the limit above simplifies to $$\lim_{h\to0+}\frac{a(c+h)+b-(ac+b)}{h}=a$$ Hence our requirement of differentiability simplifies to the requirement that $a=2c$ (along with the above requirement for continuity). Therefore, any a,b,c satisfying the two conditions $ac+b=c^2$ and $a=2c$ will suffice.","Main Question: Is it possible for a function f to have a derivative at a point x but be discontinuous at that point? Consider a function that is defined as follows: We are asked to find constants a,b,c such that the derivative of f at c exists.  Consider the situation where .  Following the limit definition of the derivative, we have that is equals to: provided that the limit is defined. To see that, we may examine the limit as and as . For when : Thus, by definition if then for all values b exists and is equal to 2c.  Here is the issue, if exists for all values of b with the aforementioned condition then it could certainly be possible that is discontinuous at c which contradicts an earlier theorem which states that if a function f has a derivative at a point x, then it is also continuous at x. This is an example graph in desmos: https://www.desmos.com/calculator/acym19fdm2 . This creates a situation where the function f has a derivative at the point x but it is not continuous at that point.  Am I doing something wrong here? Edit: As X-Rui and many others in the comments and answers pointed out, my error was in computing the right-hand limit.  f(c) should always be equal to regardless of the limit since c is constant and f(c) was so defined.  Hence the right-hand side limit computation should be as follows: From here we intend to find an values of a,b,c such that this limit will agree with the value of the left limit of 2c.  Assume that there exists such a value c, then since f is differentiable at c f is continuous at c.  Hence by continuity (as pointed out by stoic-santiago).  Then the limit above simplifies to Hence our requirement of differentiability simplifies to the requirement that (along with the above requirement for continuity). Therefore, any a,b,c satisfying the two conditions and will suffice.",f(x)=\begin{cases} x^2 & x \leq c \\ax+b & x > c \end{cases} a=2c f'(c) \lim_{h\to0}\frac{f(c+h)-f(c)}{h} x\to0- x\to0+ \begin{equation}\lim_{h\to0+}\frac{f(c+h)-f(c)}{h} \\ =\lim_{h\to0+}\frac{a(c+h)+b-(ac+b)}{h}\end{equation}\\=\lim_{h\to0+}\frac{ah}{h}\\=a=2c x\to0- \begin{equation}\lim_{h\to0-}\frac{f(c+h)-f(c)}{h} \\ =\lim_{h\to0-}\frac{(c+h)^2-c^2}{h}\end{equation}\\=\lim_{h\to0-}\frac{2ch+h^2}{h}\\=2c a=2c f'(c) f'(c) f(x) c^2 \begin{equation}\lim_{h\to0+}\frac{f(c+h)-f(c)}{h} \\ = \lim_{h\to0+}\frac{a(c+h)+b-c^2}{h}\end{equation} ac+b=c^2 \lim_{h\to0+}\frac{a(c+h)+b-(ac+b)}{h}=a a=2c ac+b=c^2 a=2c,"['calculus', 'continuity']"
46,How many roots has the following equation?,How many roots has the following equation?,,"I would please like your guidance to find, depending on $a$ , how many roots the following equation has: $x^4+4x+a=0$ , where $a$ is a real parameter. I tried to use Bolzano's Theorem for a specific interval but I am afraid that my approach would not be accurate. Thank you very much in advance.","I would please like your guidance to find, depending on , how many roots the following equation has: , where is a real parameter. I tried to use Bolzano's Theorem for a specific interval but I am afraid that my approach would not be accurate. Thank you very much in advance.",a x^4+4x+a=0 a,['calculus']
47,"How do you evaluate $\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx$? [duplicate]",How do you evaluate ? [duplicate],"\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx","This question already has answers here : How to integrate the product of two or more polynomials raised to some powers, not necessarily integral (5 answers) Problem about evaluating $\int_0^1 {3x^3 -x^2 +2x -4\over \sqrt {x^2-3x+2} } \; dx $ [duplicate] (2 answers) Closed 4 years ago . Saw this problem on a FaceBook meme that said the pin code to his ATM debit card is the solution to the following problem: $$\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx$$ I was trying to see how we could break this up into an easier integrals but nothing comes to mind at first glance. Perhaps complex integration is possible?","This question already has answers here : How to integrate the product of two or more polynomials raised to some powers, not necessarily integral (5 answers) Problem about evaluating $\int_0^1 {3x^3 -x^2 +2x -4\over \sqrt {x^2-3x+2} } \; dx $ [duplicate] (2 answers) Closed 4 years ago . Saw this problem on a FaceBook meme that said the pin code to his ATM debit card is the solution to the following problem: I was trying to see how we could break this up into an easier integrals but nothing comes to mind at first glance. Perhaps complex integration is possible?","\int_{0}^{1} \frac{(3x^3-x^2+2x-4)}{\sqrt{x^2-3x+2}} \, dx","['calculus', 'integration', 'complex-analysis', 'definite-integrals']"
48,$\int \frac{dx}{\sin x-\cos x}$,,\int \frac{dx}{\sin x-\cos x},"Evaluate $$\int \frac{dx}{\sin{x}-\cos{x}} $$ I know it can be done by Weierstrass substitution. But I am looking for new/simple approach. For example I tried: $$\int \frac{1}{\sin{x}-\cos{x}} \cdot \frac{\sin{x}+\cos{x}}{\sin{x}+\cos{x}}dx=\int \frac{\sin{x}+\cos{x}}{-\cos{2x}}dx ,$$ but I can't continue from here.",Evaluate I know it can be done by Weierstrass substitution. But I am looking for new/simple approach. For example I tried: but I can't continue from here.,"\int \frac{dx}{\sin{x}-\cos{x}}  \int \frac{1}{\sin{x}-\cos{x}} \cdot \frac{\sin{x}+\cos{x}}{\sin{x}+\cos{x}}dx=\int \frac{\sin{x}+\cos{x}}{-\cos{2x}}dx ,","['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
49,Evaluate the limit of $\sum_{n=1}^{\infty}\frac{n^2}{n!}$,Evaluate the limit of,\sum_{n=1}^{\infty}\frac{n^2}{n!},"Evaluate the limit of: $$\sum_{n=1}^{\infty}\frac{n^2}{n!}$$ Hints I am given: 1- The exponential series of type $\sum_{n=0}^{\infty}\frac{x^n}{n!}$ converge into $e^x$ for any $x\in R$ 2- Any series of type $\sum_{n=0}^{\infty}\frac{P(n)}{n!}x^n$ , being $P(n)$ a polynomial of any level and $\forall x\in R$ , it also converges. 3- $\sum_{n=1}^{\infty}a_{n-1}=\sum_{n=0}^{\infty}a_{n}$ What is the limit of this series? According to the hints it is convergent, this is what I tried so far: $\sum_{n=1}^{\infty}\frac{n^2}{n!}=\sum_{n=1}^{\infty}\frac{n^2}{n(n-1)!}=\sum_{n=1}^{\infty}\frac{n}{(n-1)!}$ Applying hint 3: $\sum_{n=0}^{\infty}\frac{n+1}{n!}$ Split the series in 2: $\sum_{n=0}^{\infty}\frac{n+1}{n!}=\sum_{n=0}^{\infty}\frac{n}{n!}+\sum_{n=0}^{\infty}\frac{1}{n!}$ Applying hint 1, with $x=1$ to the second part: $\sum_{n=0}^{\infty}\frac{n+1}{n!}=e+\sum_{n=0}^{\infty}\frac{n}{n!}$ I dont know how to keep going, I know that the series $\sum_{n=0}^{\infty}\frac{n}{n!}$ converges into $e$ therefore the result of the whole series is 2 times $e$ but I dont understand why!","Evaluate the limit of: Hints I am given: 1- The exponential series of type converge into for any 2- Any series of type , being a polynomial of any level and , it also converges. 3- What is the limit of this series? According to the hints it is convergent, this is what I tried so far: Applying hint 3: Split the series in 2: Applying hint 1, with to the second part: I dont know how to keep going, I know that the series converges into therefore the result of the whole series is 2 times but I dont understand why!",\sum_{n=1}^{\infty}\frac{n^2}{n!} \sum_{n=0}^{\infty}\frac{x^n}{n!} e^x x\in R \sum_{n=0}^{\infty}\frac{P(n)}{n!}x^n P(n) \forall x\in R \sum_{n=1}^{\infty}a_{n-1}=\sum_{n=0}^{\infty}a_{n} \sum_{n=1}^{\infty}\frac{n^2}{n!}=\sum_{n=1}^{\infty}\frac{n^2}{n(n-1)!}=\sum_{n=1}^{\infty}\frac{n}{(n-1)!} \sum_{n=0}^{\infty}\frac{n+1}{n!} \sum_{n=0}^{\infty}\frac{n+1}{n!}=\sum_{n=0}^{\infty}\frac{n}{n!}+\sum_{n=0}^{\infty}\frac{1}{n!} x=1 \sum_{n=0}^{\infty}\frac{n+1}{n!}=e+\sum_{n=0}^{\infty}\frac{n}{n!} \sum_{n=0}^{\infty}\frac{n}{n!} e e,"['calculus', 'sequences-and-series']"
50,Limit as x tends to infinity of a product of two functions where one is an integral and the other tends to 0,Limit as x tends to infinity of a product of two functions where one is an integral and the other tends to 0,,"Any hints on how to best approach this problem? $$\lim_{x\to+\infty} \dfrac{1}{x} \int_{1}^{x} \dfrac{t^3}{1+t^3} dt$$ The first point of confusion for me is that $\dfrac{1}{x} \rightarrow 0$ as $ x \rightarrow +\infty$, so by evaluating the limit for $\dfrac{1}{x}$ and the integral separately and multiplying their limits afterwards should result in $0$, but I highly suspect that this is too simple of a solution that it must be wrong. Secondly, my hunch is that to evaluate the limit of the integral I could find a function with a smaller area than $\dfrac{t^3}{1+t^3}$ on the listed interval and show that the limit tends to $\infty$ and this would be sufficient to show that $\dfrac{t^3}{1+t^3}$ must also tend to $\infty$ since it has a larger area. Is this the right approach and any hints as to how I could find a function with smaller area that I can show tends to $\infty$?","Any hints on how to best approach this problem? $$\lim_{x\to+\infty} \dfrac{1}{x} \int_{1}^{x} \dfrac{t^3}{1+t^3} dt$$ The first point of confusion for me is that $\dfrac{1}{x} \rightarrow 0$ as $ x \rightarrow +\infty$, so by evaluating the limit for $\dfrac{1}{x}$ and the integral separately and multiplying their limits afterwards should result in $0$, but I highly suspect that this is too simple of a solution that it must be wrong. Secondly, my hunch is that to evaluate the limit of the integral I could find a function with a smaller area than $\dfrac{t^3}{1+t^3}$ on the listed interval and show that the limit tends to $\infty$ and this would be sufficient to show that $\dfrac{t^3}{1+t^3}$ must also tend to $\infty$ since it has a larger area. Is this the right approach and any hints as to how I could find a function with smaller area that I can show tends to $\infty$?",,"['calculus', 'integration']"
51,"Evaluate the closed form of $\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b\sin^2x+c\cos^2x}\mathrm dx=f(a,b,c)$",Evaluate the closed form of,"\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b\sin^2x+c\cos^2x}\mathrm dx=f(a,b,c)","Last question of this form I am very curious to what is the closed form of: Assume where $a,b,c > 0$ $$\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b\sin^2x+c\cos^2x}\mathrm dx=f(a,b,c)\tag1$$ $$b\sin^2x+c\cos^2x$$ $$=b(1-\cos^2 x)+c\cos^2 x$$ $$=b-(b-c)\cos^2 x$$ $$\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b-(b-c)\cos^2x}\mathrm dx\tag2$$ $u=a\tan^2x\implies du=2a\tan x\sec^2 x dx$ ${u-a\over a}=\sec^2 x$ $${\sqrt{a}\over 2}\int_{0}^{\infty}{\arctan(u)\over \sqrt{u}(bu+ac-2ab)}\mathrm du\tag3$$ $u=y^2\implies du=2ydy$ $$\sqrt{a}\int_{0}^{\infty}{\arctan(y^2)\over by^2+ac-2ab}\mathrm dy\tag4$$ $b=P$ and $ac-2ab=Q$ Take the form of: $$\int_{0}^{\infty}{\arctan(y^2)\over Py^2+Q}\mathrm dy\tag5$$ Apply $arctan(y)$ series $$\sum_{n=0}^{\infty}{(-1)^n\over 2n+1}\int_{0}^{\infty}{y^{4n+2}\over Py^2+Q}\mathrm dy\tag6$$","Last question of this form I am very curious to what is the closed form of: Assume where $a,b,c > 0$ $$\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b\sin^2x+c\cos^2x}\mathrm dx=f(a,b,c)\tag1$$ $$b\sin^2x+c\cos^2x$$ $$=b(1-\cos^2 x)+c\cos^2 x$$ $$=b-(b-c)\cos^2 x$$ $$\int_{0}^{\pi/2}{\arctan(a\tan^2x)\over b-(b-c)\cos^2x}\mathrm dx\tag2$$ $u=a\tan^2x\implies du=2a\tan x\sec^2 x dx$ ${u-a\over a}=\sec^2 x$ $${\sqrt{a}\over 2}\int_{0}^{\infty}{\arctan(u)\over \sqrt{u}(bu+ac-2ab)}\mathrm du\tag3$$ $u=y^2\implies du=2ydy$ $$\sqrt{a}\int_{0}^{\infty}{\arctan(y^2)\over by^2+ac-2ab}\mathrm dy\tag4$$ $b=P$ and $ac-2ab=Q$ Take the form of: $$\int_{0}^{\infty}{\arctan(y^2)\over Py^2+Q}\mathrm dy\tag5$$ Apply $arctan(y)$ series $$\sum_{n=0}^{\infty}{(-1)^n\over 2n+1}\int_{0}^{\infty}{y^{4n+2}\over Py^2+Q}\mathrm dy\tag6$$",,['calculus']
52,$\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}dx$,,\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}dx,"$$\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}\,dx$$ My attempt, I changed it to $\int \frac{x^2}{\sqrt{x^4+x^2+1}} \, dx-\int \frac 1 {x^2\sqrt{x^4+x^2+1}} \, dx$, but I stuck here. Any method to solve this integral? Thanks in advance.","$$\int \frac{x^4-1}{x^2\sqrt{x^4+x^2+1}}\,dx$$ My attempt, I changed it to $\int \frac{x^2}{\sqrt{x^4+x^2+1}} \, dx-\int \frac 1 {x^2\sqrt{x^4+x^2+1}} \, dx$, but I stuck here. Any method to solve this integral? Thanks in advance.",,"['calculus', 'integration']"
53,Calculus - Infinite Series,Calculus - Infinite Series,,"Decide whether the infinite series converges of diverges. $$\sum_{n=1}^\infty \frac{2^n+3^n}{3^n+4^n}$$ My thought process: The nth term test doesn't seem viable after initial use. The comparison function I derived for DCT/LCT is: $\frac{3^n}{4^n}$.    I cannot create an appropriate inequality between the given function and my comparison function I found, so I tried LCT. I am aware that  $\sum_{i=1}^\infty \frac{3^n}{4^n}$ is geometric and because the common ratio (r) is $ \frac{3}{4}$, $-1<r<1$ the series converges, however I cannot compute the limit LCT requires. Application of the root test would seem unbeneficial because roots do not split over sums. As for the ratio test I was also unsuccessful in proceeding with the computation of the limit. The above are the only tests I have learned as of right now. My question is what test should I be looking to utilize to determine convergence or divergence?","Decide whether the infinite series converges of diverges. $$\sum_{n=1}^\infty \frac{2^n+3^n}{3^n+4^n}$$ My thought process: The nth term test doesn't seem viable after initial use. The comparison function I derived for DCT/LCT is: $\frac{3^n}{4^n}$.    I cannot create an appropriate inequality between the given function and my comparison function I found, so I tried LCT. I am aware that  $\sum_{i=1}^\infty \frac{3^n}{4^n}$ is geometric and because the common ratio (r) is $ \frac{3}{4}$, $-1<r<1$ the series converges, however I cannot compute the limit LCT requires. Application of the root test would seem unbeneficial because roots do not split over sums. As for the ratio test I was also unsuccessful in proceeding with the computation of the limit. The above are the only tests I have learned as of right now. My question is what test should I be looking to utilize to determine convergence or divergence?",,"['calculus', 'sequences-and-series']"
54,Avoiding circular logic using L'Hospital's rule,Avoiding circular logic using L'Hospital's rule,,"Often, using L'Hospital's rule can make a limit much simpler to evaluate, but in some circumstances it can be incorrect to use the rule even when all of its criteria are met - one example being the evaluation of $\lim_{x\to0}\frac{\sin x}{x}$ , which relies on $\frac{d}{dx}\sin x=\cos x$ being known, which itself relies on the limit we are trying to prove! How, when considering using L'Hospital's rule, can examples like this one be spotted in order to avoid circular logic? At first glance, I wouldn't have known that the proof was circular, and I'm concerned that I might make similar mistakes with other functions.","Often, using L'Hospital's rule can make a limit much simpler to evaluate, but in some circumstances it can be incorrect to use the rule even when all of its criteria are met - one example being the evaluation of , which relies on being known, which itself relies on the limit we are trying to prove! How, when considering using L'Hospital's rule, can examples like this one be spotted in order to avoid circular logic? At first glance, I wouldn't have known that the proof was circular, and I'm concerned that I might make similar mistakes with other functions.",\lim_{x\to0}\frac{\sin x}{x} \frac{d}{dx}\sin x=\cos x,"['calculus', 'limits', 'logic']"
55,Calculus: why do we define rate of change as $dy/dx$?,Calculus: why do we define rate of change as ?,dy/dx,"I'm just starting to learn Calculus using Morris Klines' awesome book, ""Calculus, an intuitive and physical approach."" I really like it so far. I'm just at the beginning, and after learning how to differentiate I was wondering why rate of change is defined exactly the same for every function. Allow me to explain. If we deal, for example, with functions the describe distance traveled over time, and we search for the exact speed at a specific time along this distance, then I totally understand why we define the rate of change as $\frac{dy}{dx}$ - it follows perfectly the physical way speed is defined and being calculated: speed=distance/time. Here, $dy$=difference in distance='a distance' and $dx$=difference in time='an amount of time'. So it makes sense to me. All that is left to do is make $dx$ (time) approach 0 and calculate the result. My confusion comes when we deal with other kinds of physical quantities. Physical quantities whose very physical definition\calculation has nothing to do with division. As an example, let us view the area of a rectangle: $A=a*b$. Allow me to differentiate it, please, so you'll see what I mean. (Do forgive me as I do not know how to write subscripts on this forum.) Let us assume a is a constant and b is the independant variable. It follows then that for $b=b_1$ we get: $a_1 = a\cdot b_1.$ $a_2 = a\cdot (b_1+db)=a\cdot b_1+a\cdot d_b.$ $da = a_2-a_1=a\cdot b_1+a\cdot db-a\cdot b_1 = a\cdot db.$ So far, so good. But then, in the book, for some odd and strange reason, we simpy divide both sides of the equation by $db$. As mentioned above, the area of a rectangle is defined by MULTIPLYING two adjacent sides. It has nothing to do with division. So finding the rate of change of the rectangle area should also have nothing to do with divison. (In my opinion, of course, and I'll sooon explain why.) You may tell me that 'the rate of change of the rectangles' area' is just half the sentence - it needs to be in relation to something - and that is where the divison comes from. When you look at the relation between two things mathematically - you divide them. Hence, relation is a quotient by definition. But I disagree, and here is why. IMO, right where we stopped when we found the derivative of the rectangles' area IS the definition of 'rate of change in the area of the rectangle with relation to one of its sides' - it is right there in the last equation - it is the difference in areas ($dA$) between a rectangle whose side is $b_1$ and another whose side is slightly longer, $b_1+db$. I see here three variables: $dA$, $b_1$ and $db$. To me, that equation is also a mathematical relation between them that explains how they change with relation to one another. Following this logic - all we need to do now is let db get smaller and smaller until it reaches $0$ to find the exact change in area at $b_1$. But when we do so, the entire right side equals $0$. (Which stands to reason, by the way, because what it actually means is that we subtract the areas of two identical rectangles - so it should indeed zero and cancel out.) To me, this seems like the right way to calculate the rate of change IN THIS PARTICULAR SITUATION - an area of a rectangle with one side fixed as the other varies, as compared to dividing $dA$ by $db$. It seems to me that at times, using $\frac{dy}{dx}$ really is the right and logical choice, and in others, we use it to kind of ""cheat"" because it is an algebraic trick that yields us a solution other than 0. So, why is it that we define the rate of change EXACTLY the same for every function?","I'm just starting to learn Calculus using Morris Klines' awesome book, ""Calculus, an intuitive and physical approach."" I really like it so far. I'm just at the beginning, and after learning how to differentiate I was wondering why rate of change is defined exactly the same for every function. Allow me to explain. If we deal, for example, with functions the describe distance traveled over time, and we search for the exact speed at a specific time along this distance, then I totally understand why we define the rate of change as $\frac{dy}{dx}$ - it follows perfectly the physical way speed is defined and being calculated: speed=distance/time. Here, $dy$=difference in distance='a distance' and $dx$=difference in time='an amount of time'. So it makes sense to me. All that is left to do is make $dx$ (time) approach 0 and calculate the result. My confusion comes when we deal with other kinds of physical quantities. Physical quantities whose very physical definition\calculation has nothing to do with division. As an example, let us view the area of a rectangle: $A=a*b$. Allow me to differentiate it, please, so you'll see what I mean. (Do forgive me as I do not know how to write subscripts on this forum.) Let us assume a is a constant and b is the independant variable. It follows then that for $b=b_1$ we get: $a_1 = a\cdot b_1.$ $a_2 = a\cdot (b_1+db)=a\cdot b_1+a\cdot d_b.$ $da = a_2-a_1=a\cdot b_1+a\cdot db-a\cdot b_1 = a\cdot db.$ So far, so good. But then, in the book, for some odd and strange reason, we simpy divide both sides of the equation by $db$. As mentioned above, the area of a rectangle is defined by MULTIPLYING two adjacent sides. It has nothing to do with division. So finding the rate of change of the rectangle area should also have nothing to do with divison. (In my opinion, of course, and I'll sooon explain why.) You may tell me that 'the rate of change of the rectangles' area' is just half the sentence - it needs to be in relation to something - and that is where the divison comes from. When you look at the relation between two things mathematically - you divide them. Hence, relation is a quotient by definition. But I disagree, and here is why. IMO, right where we stopped when we found the derivative of the rectangles' area IS the definition of 'rate of change in the area of the rectangle with relation to one of its sides' - it is right there in the last equation - it is the difference in areas ($dA$) between a rectangle whose side is $b_1$ and another whose side is slightly longer, $b_1+db$. I see here three variables: $dA$, $b_1$ and $db$. To me, that equation is also a mathematical relation between them that explains how they change with relation to one another. Following this logic - all we need to do now is let db get smaller and smaller until it reaches $0$ to find the exact change in area at $b_1$. But when we do so, the entire right side equals $0$. (Which stands to reason, by the way, because what it actually means is that we subtract the areas of two identical rectangles - so it should indeed zero and cancel out.) To me, this seems like the right way to calculate the rate of change IN THIS PARTICULAR SITUATION - an area of a rectangle with one side fixed as the other varies, as compared to dividing $dA$ by $db$. It seems to me that at times, using $\frac{dy}{dx}$ really is the right and logical choice, and in others, we use it to kind of ""cheat"" because it is an algebraic trick that yields us a solution other than 0. So, why is it that we define the rate of change EXACTLY the same for every function?",,['calculus']
56,Do limits evaluated at infinity exist?,Do limits evaluated at infinity exist?,,"Here is some limit: $$\lim_{x \to b} f(x)$$ We know that for a limit to exist, we must have $$\lim_{x \to b+} f(x) = \lim_{x \to b-} f(x)$$ So I am confused because, when $b=+\infty$ we can only evaluate this limit from the left side and not the right side.  We can't approach infinity from a higher infinity. Does this mean that limits evaluated at infinity don't exist and therefore none of the limit laws like addition apply to limits evaluated at infinity? EDIT: So does that mean I can use the limit laws such as addition, composition, etc on limits evaluated at infinity as long as the limits tend to a finite value? I.e. $$\lim_{x \to \infty} [f(x) + g(x)] = \lim_{x \to \infty} f(x) + \lim_{x \to \infty} g(x)$$ as long as both of the separate limits are some finite value? And so on, for multiplication, composition, etc?","Here is some limit: $$\lim_{x \to b} f(x)$$ We know that for a limit to exist, we must have $$\lim_{x \to b+} f(x) = \lim_{x \to b-} f(x)$$ So I am confused because, when $b=+\infty$ we can only evaluate this limit from the left side and not the right side.  We can't approach infinity from a higher infinity. Does this mean that limits evaluated at infinity don't exist and therefore none of the limit laws like addition apply to limits evaluated at infinity? EDIT: So does that mean I can use the limit laws such as addition, composition, etc on limits evaluated at infinity as long as the limits tend to a finite value? I.e. $$\lim_{x \to \infty} [f(x) + g(x)] = \lim_{x \to \infty} f(x) + \lim_{x \to \infty} g(x)$$ as long as both of the separate limits are some finite value? And so on, for multiplication, composition, etc?",,['calculus']
57,"Using the ratio test for the series $\sum \frac1{3^n-2^n}$, I can't compute the limit","Using the ratio test for the series , I can't compute the limit",\sum \frac1{3^n-2^n},"$$\sum_{n=1}^{\infty} \frac{1}{3^n-2^n}$$ I know this series is convergent and using the ratio test. But I can't conclude the proving. $$\begin{align}\lim_{n\to\infty} \left| \frac{\frac{1}{3^{n+1}-2^{n+1}}}{ \frac{1}{3^n-2^n}}\right| &= \lim_{n\to\infty} \left| \frac{3^n-2^n}{ 3^{n+1} - 2^{n+1}}  \right|\\ &= \lim_{n\to\infty} \left| \frac{1-(\frac{2}{3})^n}{ 3(1-2^{n+1}/3^{n+1})}\right| \end{align}$$ By using calculation, the limit is 0. But I can't compute this limit by myself without using calculation. Any help?","$$\sum_{n=1}^{\infty} \frac{1}{3^n-2^n}$$ I know this series is convergent and using the ratio test. But I can't conclude the proving. $$\begin{align}\lim_{n\to\infty} \left| \frac{\frac{1}{3^{n+1}-2^{n+1}}}{ \frac{1}{3^n-2^n}}\right| &= \lim_{n\to\infty} \left| \frac{3^n-2^n}{ 3^{n+1} - 2^{n+1}}  \right|\\ &= \lim_{n\to\infty} \left| \frac{1-(\frac{2}{3})^n}{ 3(1-2^{n+1}/3^{n+1})}\right| \end{align}$$ By using calculation, the limit is 0. But I can't compute this limit by myself without using calculation. Any help?",,"['calculus', 'sequences-and-series', 'limits']"
58,$\lim \frac{\cos{x}}{x^2}$ as x goes to infinity,as x goes to infinity,\lim \frac{\cos{x}}{x^2},$\displaystyle \lim_{x \to \infty} \frac{\cos{x}}{x^2} =\lim_{x \to \infty} \frac{\frac{d}{dx} \cos{x}}{\frac{d}{dx}x^2} = -\frac{1}{2}\lim_{x \to \infty}\frac{\sin{x}}{x}$. But $-\frac{1}{x} \le \frac{\sin{x}}{x} \le \frac{1}{x}$ so $\displaystyle -\lim_{x \to \infty}\frac{1}{x} \le \lim_{x \to \infty}\frac{\sin{x}}{x} \le \lim_{x \to \infty}\frac{1}{x} \iff 0 \le \lim_{x \to \infty}\frac{\sin{x}}{x} \le 0 \iff \lim_{x \to \infty}\frac{\sin{x}}{x} = 0.$ Therefore $\displaystyle \lim_{x \to \infty} \frac{\cos{x}}{x^2} = 0.$ Is the above correct?,$\displaystyle \lim_{x \to \infty} \frac{\cos{x}}{x^2} =\lim_{x \to \infty} \frac{\frac{d}{dx} \cos{x}}{\frac{d}{dx}x^2} = -\frac{1}{2}\lim_{x \to \infty}\frac{\sin{x}}{x}$. But $-\frac{1}{x} \le \frac{\sin{x}}{x} \le \frac{1}{x}$ so $\displaystyle -\lim_{x \to \infty}\frac{1}{x} \le \lim_{x \to \infty}\frac{\sin{x}}{x} \le \lim_{x \to \infty}\frac{1}{x} \iff 0 \le \lim_{x \to \infty}\frac{\sin{x}}{x} \le 0 \iff \lim_{x \to \infty}\frac{\sin{x}}{x} = 0.$ Therefore $\displaystyle \lim_{x \to \infty} \frac{\cos{x}}{x^2} = 0.$ Is the above correct?,,"['calculus', 'limits', 'proof-verification']"
59,Height/Radius ratio for maximum volume cylinder of given surface area,Height/Radius ratio for maximum volume cylinder of given surface area,,"I am a bit confused by this problem I have encountered: A right circular cylindrical container with a closed top is to be constructed with a fixed surface area. Find the ratio of the height to the radius which will maximize the volume. I know the volume to be $ \pi{r}^2h$, but I don't see what equation I should be solving for. How can I solve for the ratio? Thanks","I am a bit confused by this problem I have encountered: A right circular cylindrical container with a closed top is to be constructed with a fixed surface area. Find the ratio of the height to the radius which will maximize the volume. I know the volume to be $ \pi{r}^2h$, but I don't see what equation I should be solving for. How can I solve for the ratio? Thanks",,"['calculus', 'optimization']"
60,Differentiable approximation of the absolute value function [duplicate],Differentiable approximation of the absolute value function [duplicate],,"This question already has answers here : Approximate $|x|$ with a smooth function (5 answers) Closed 3 years ago . Are there any good approximations of the absolute value function which are $C^2$ or at least $C^1$? I've thought about working with exponentials and then adding in more terms to keep the function from growing too fast away from zero, but I was hoping to find something a bit neater.","This question already has answers here : Approximate $|x|$ with a smooth function (5 answers) Closed 3 years ago . Are there any good approximations of the absolute value function which are $C^2$ or at least $C^1$? I've thought about working with exponentials and then adding in more terms to keep the function from growing too fast away from zero, but I was hoping to find something a bit neater.",,"['calculus', 'derivatives', 'approximation-theory']"
61,Evaluating $\lim_{n\to\infty}\small\left(\frac{1}{\sqrt{n}\sqrt{n+1}}+\frac{1}{\sqrt{n}\sqrt{n+2}}+\cdots+\frac{1}{\sqrt{n}\sqrt{n+n}}\right)$,Evaluating,\lim_{n\to\infty}\small\left(\frac{1}{\sqrt{n}\sqrt{n+1}}+\frac{1}{\sqrt{n}\sqrt{n+2}}+\cdots+\frac{1}{\sqrt{n}\sqrt{n+n}}\right),"Problem: Evaluate $$ \lim_{n\to\infty}\left(\frac{1}{\sqrt{n}\sqrt{n+1}}+\frac{1}{\sqrt{n}\sqrt{n+2}}+\cdots+\frac{1}{\sqrt{n}\sqrt{n+n}}\right). $$ I have decent familiarity with limits, but I don't see how integrals are related to this problem at all (this problem is in the section on integrals in my textbook). It looks to me like this limit would be $0$ or is that off base?","Problem: Evaluate $$ \lim_{n\to\infty}\left(\frac{1}{\sqrt{n}\sqrt{n+1}}+\frac{1}{\sqrt{n}\sqrt{n+2}}+\cdots+\frac{1}{\sqrt{n}\sqrt{n+n}}\right). $$ I have decent familiarity with limits, but I don't see how integrals are related to this problem at all (this problem is in the section on integrals in my textbook). It looks to me like this limit would be $0$ or is that off base?",,"['calculus', 'integration', 'limits', 'summation', 'radicals']"
62,Proof that $\sum\limits_{i=1}^n \cos \sqrt{i}$ is unbounded.,Proof that  is unbounded.,\sum\limits_{i=1}^n \cos \sqrt{i},"Please advice how to prove that $\sum\limits_{i=1}^n \cos \sqrt{i}$ is unbounded. By this I mean there exists no positive real $B$ such that for any natural $n$ $$-B <\sum\limits_{i=1}^n \cos \sqrt{i} < B$$ UPD: it looks like the sum is not bounded (it follows from Euler–Maclaurin formula), so it seems it is just necessary to fill out details.","Please advice how to prove that $\sum\limits_{i=1}^n \cos \sqrt{i}$ is unbounded. By this I mean there exists no positive real $B$ such that for any natural $n$ $$-B <\sum\limits_{i=1}^n \cos \sqrt{i} < B$$ UPD: it looks like the sum is not bounded (it follows from Euler–Maclaurin formula), so it seems it is just necessary to fill out details.",,"['calculus', 'sequences-and-series', 'summation']"
63,Calculation of $\int\frac1{\tan \frac{x}{2}+1}dx$,Calculation of,\int\frac1{\tan \frac{x}{2}+1}dx,"Calculation of $\displaystyle \int\frac{1}{\tan \frac{x}{2}+1}dx$ $\bf{My\; Try}::$ Let $\displaystyle I = \displaystyle \int\frac{1}{\tan \frac{x}{2}+1}dx$, Now let $\displaystyle \tan \frac{x}{2}=t\;,$ Then $\displaystyle dx=\frac{2}{1+t^2}dt$ So $\displaystyle I = 2\int\frac{1}{(1+t)\cdot (1+t^2)}dt$ Now Using Partial fraction, $\displaystyle \frac{1}{(1+t)\cdot (1+t^2)} = \frac{A}{1+t}+\frac{Bt+C}{1+t^2}\Rightarrow 1=A(1+t^2)+(Bt+C)(1+t)$ Now put $(1+t)=0\Rightarrow t=-1\;,$ We get $\displaystyle 1=2A\Rightarrow A = \frac{1}{2}.$ Now Put $(1+t^2)=0\Rightarrow t^2=-1\;,$ We Get $1=Bt^2+(B+C)t+C$ So $\displaystyle 1=\left(-B+C\right)+(B+C)$. So Solving equation...$B+C=0$ and $-B+C=1$ So $\displaystyle B=-\frac{1}{2}$ and $\displaystyle C=\frac{1}{2}$ So $\displaystyle I = 2\int\frac{1}{(1+t)\cdot (1+t^2)}dt = \int\frac{1}{1+t}dt+\int\frac{-t+1}{1+t^2}dt$ So $\displaystyle I = \frac{1}{1+t}dt-\frac{1}{2}\int\frac{2t}{1+t^2}dt+\int \frac{1}{1+t^2}dt$ So $\displaystyle I = \ln \left|1+t\right|-\frac{1}{2}\ln \left|1+t^2\right|+\tan^{-1}(t)+\mathcal{C}$ So $\displaystyle I = \ln \left|1+\tan \frac{x}{2}\right|-\frac{1}{2}\ln \left|1+\tan^2 \frac{x}{2}\right|+\frac{x}{2}+\mathcal{C}$ Can we solve it without using partial fraction? If yes then please explain to me. Thanks","Calculation of $\displaystyle \int\frac{1}{\tan \frac{x}{2}+1}dx$ $\bf{My\; Try}::$ Let $\displaystyle I = \displaystyle \int\frac{1}{\tan \frac{x}{2}+1}dx$, Now let $\displaystyle \tan \frac{x}{2}=t\;,$ Then $\displaystyle dx=\frac{2}{1+t^2}dt$ So $\displaystyle I = 2\int\frac{1}{(1+t)\cdot (1+t^2)}dt$ Now Using Partial fraction, $\displaystyle \frac{1}{(1+t)\cdot (1+t^2)} = \frac{A}{1+t}+\frac{Bt+C}{1+t^2}\Rightarrow 1=A(1+t^2)+(Bt+C)(1+t)$ Now put $(1+t)=0\Rightarrow t=-1\;,$ We get $\displaystyle 1=2A\Rightarrow A = \frac{1}{2}.$ Now Put $(1+t^2)=0\Rightarrow t^2=-1\;,$ We Get $1=Bt^2+(B+C)t+C$ So $\displaystyle 1=\left(-B+C\right)+(B+C)$. So Solving equation...$B+C=0$ and $-B+C=1$ So $\displaystyle B=-\frac{1}{2}$ and $\displaystyle C=\frac{1}{2}$ So $\displaystyle I = 2\int\frac{1}{(1+t)\cdot (1+t^2)}dt = \int\frac{1}{1+t}dt+\int\frac{-t+1}{1+t^2}dt$ So $\displaystyle I = \frac{1}{1+t}dt-\frac{1}{2}\int\frac{2t}{1+t^2}dt+\int \frac{1}{1+t^2}dt$ So $\displaystyle I = \ln \left|1+t\right|-\frac{1}{2}\ln \left|1+t^2\right|+\tan^{-1}(t)+\mathcal{C}$ So $\displaystyle I = \ln \left|1+\tan \frac{x}{2}\right|-\frac{1}{2}\ln \left|1+\tan^2 \frac{x}{2}\right|+\frac{x}{2}+\mathcal{C}$ Can we solve it without using partial fraction? If yes then please explain to me. Thanks",,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
64,Wolfram alpha says that $\int_{-\infty}^\infty e^{-ix^2}dx = \sqrt{\frac{\pi}{i}}$,Wolfram alpha says that,\int_{-\infty}^\infty e^{-ix^2}dx = \sqrt{\frac{\pi}{i}},Wolfram alpha says that  $$ \int_{-\infty}^\infty e^{-ix^2}dx = \sqrt{\frac{\pi}{i}}$$ holds. But it has two different values ($\sqrt{i}$).  How should I understand this?,Wolfram alpha says that  $$ \int_{-\infty}^\infty e^{-ix^2}dx = \sqrt{\frac{\pi}{i}}$$ holds. But it has two different values ($\sqrt{i}$).  How should I understand this?,,"['calculus', 'integration', 'complex-analysis', 'improper-integrals']"
65,maximum area of a rectangle inscribed in a semi - circle with radius r.,maximum area of a rectangle inscribed in a semi - circle with radius r.,,"A rectangle is inscribed in a semi circle with radius $r$ with one of its sides at the diameter of the semi circle. Find the dimensions of the rectangle so that its area is a maximum. My Try: Let length of the side be $x$, Then the length of the other side is $2\sqrt{r^2 -x^2}$, as shown in the image. Then the area function is $$A(x) = 2x\sqrt{r^2-x^2}$$ $$\begin{align}A'(x) &= 2\sqrt{r^2-x^2}-\frac{4x}{\sqrt{r^2-x^2}}\\ &=\frac{2}{\sqrt{r^2-x^2}} (r^2 - 2x -x^2)\end{align}$$ setting $A'(x) = 0$, $$\implies x^2 +2x -r^2 = 0$$ Solving, I obtained: $$x = -1 \pm \sqrt{1+r^2}$$ That however is not the correct answer, I cannot see where I've gone wrong? Can someone point out any errors and guide me the correct direction. I have a feeling that I have erred in the differentiation. Also how do I show that area obtained is a maximum, because the double derivative test here is long and tedious. Thanks!","A rectangle is inscribed in a semi circle with radius $r$ with one of its sides at the diameter of the semi circle. Find the dimensions of the rectangle so that its area is a maximum. My Try: Let length of the side be $x$, Then the length of the other side is $2\sqrt{r^2 -x^2}$, as shown in the image. Then the area function is $$A(x) = 2x\sqrt{r^2-x^2}$$ $$\begin{align}A'(x) &= 2\sqrt{r^2-x^2}-\frac{4x}{\sqrt{r^2-x^2}}\\ &=\frac{2}{\sqrt{r^2-x^2}} (r^2 - 2x -x^2)\end{align}$$ setting $A'(x) = 0$, $$\implies x^2 +2x -r^2 = 0$$ Solving, I obtained: $$x = -1 \pm \sqrt{1+r^2}$$ That however is not the correct answer, I cannot see where I've gone wrong? Can someone point out any errors and guide me the correct direction. I have a feeling that I have erred in the differentiation. Also how do I show that area obtained is a maximum, because the double derivative test here is long and tedious. Thanks!",,"['calculus', 'derivatives', 'area', 'maxima-minima']"
66,Finding the integral of $\frac{x}{e^x + 1}$ [duplicate],Finding the integral of  [duplicate],\frac{x}{e^x + 1},"This question already has answers here : How to find $ \int_0^\infty \dfrac x{1+e^x}\ dx$ (5 answers) Closed 9 years ago . I've having some difficulty with finding this integral: $$ \int_0 ^{\infty} \frac{x}{e^x + 1}$$ Now usually I would use the monotone convergence theorem to write (using geometric series): $$f_n (x) = \sum_0 ^n (-1)^k x e^{-(k+1)x},$$ but this isn't a sequence of positive terms, so how do we justify moving the integral inside? Thanks.","This question already has answers here : How to find $ \int_0^\infty \dfrac x{1+e^x}\ dx$ (5 answers) Closed 9 years ago . I've having some difficulty with finding this integral: $$ \int_0 ^{\infty} \frac{x}{e^x + 1}$$ Now usually I would use the monotone convergence theorem to write (using geometric series): $$f_n (x) = \sum_0 ^n (-1)^k x e^{-(k+1)x},$$ but this isn't a sequence of positive terms, so how do we justify moving the integral inside? Thanks.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'lebesgue-integral']"
67,Find the limit of $ \lim_{x \to 7} \frac{\sqrt{x+2}-\sqrt[3]{x+20}}{\sqrt[4]{x+9}-2} $ [closed],Find the limit of  [closed], \lim_{x \to 7} \frac{\sqrt{x+2}-\sqrt[3]{x+20}}{\sqrt[4]{x+9}-2} ,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I need to evaluate the limit without using L'Hopital's rule. $$\Large \lim_{x \to 7} \frac{\sqrt{x+2}-\sqrt[3]{x+20}}{\sqrt[4]{x+9}-2} $$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I need to evaluate the limit without using L'Hopital's rule. $$\Large \lim_{x \to 7} \frac{\sqrt{x+2}-\sqrt[3]{x+20}}{\sqrt[4]{x+9}-2} $$",,"['calculus', 'limits', 'radicals', 'limits-without-lhopital']"
68,$p(x)\geq 0 \forall x\Rightarrow p(x)+p'(x)+p''(x)+...+p^{(n)}(x)\geq 0$ [duplicate],[duplicate],p(x)\geq 0 \forall x\Rightarrow p(x)+p'(x)+p''(x)+...+p^{(n)}(x)\geq 0,"This question already has answers here : Sum of derivatives of a polynomial (3 answers) Closed 10 years ago . $p(x)\geq 0 \forall x \in \mathbb{R} \Rightarrow p(x)+p'(x)+p''(x)+...+p^{(n)}(x)\geq 0$, where p(x) is a polynomial of degree n. I showed: $a_{n}+...+a_{0}\geq 0$, $p(x)+p'(x)+p''(x)+...+p^{(n)}(x)=\sum_{m=0}^{n}\sum_{k=m}^{n}a_{k}\frac{n!}{(n-k)!}p(x)^{(k-m)}=\sum_{k=0}^{n}\sum_{m=0}^{k}a_{k}\frac{n!}{(n-k)!}p(x)^{(k-m)}$","This question already has answers here : Sum of derivatives of a polynomial (3 answers) Closed 10 years ago . $p(x)\geq 0 \forall x \in \mathbb{R} \Rightarrow p(x)+p'(x)+p''(x)+...+p^{(n)}(x)\geq 0$, where p(x) is a polynomial of degree n. I showed: $a_{n}+...+a_{0}\geq 0$, $p(x)+p'(x)+p''(x)+...+p^{(n)}(x)=\sum_{m=0}^{n}\sum_{k=m}^{n}a_{k}\frac{n!}{(n-k)!}p(x)^{(k-m)}=\sum_{k=0}^{n}\sum_{m=0}^{k}a_{k}\frac{n!}{(n-k)!}p(x)^{(k-m)}$",,"['calculus', 'polynomials', 'derivatives']"
69,Limits at infinity,Limits at infinity,,"I'm working with limits at infinity and stumbled upon this exercise where I want to evaluate the indicated limit: $$\lim_{x \to \infty} \frac{1}{\sqrt{x^2-2x}-x}$$ I tried to solve it by doing the following: $$\lim_{x \to \infty} \frac{1}{\sqrt{x^2-2x}-x} = \lim_{x \to \infty} \frac{1}{\sqrt{x^2} \sqrt{1-\frac{2}{x}}-x} = \lim_{x \to \infty} \frac{1}{x \sqrt{1-\frac{2}{x}}-x} = \lim_{x \to \infty} \frac{\frac{1}{x}}{\sqrt{1-\frac{2}{x}}-1}$$ But the answer should be $-1$, so what I did must be wrong. How do you evaluate this limit the best way possible?","I'm working with limits at infinity and stumbled upon this exercise where I want to evaluate the indicated limit: $$\lim_{x \to \infty} \frac{1}{\sqrt{x^2-2x}-x}$$ I tried to solve it by doing the following: $$\lim_{x \to \infty} \frac{1}{\sqrt{x^2-2x}-x} = \lim_{x \to \infty} \frac{1}{\sqrt{x^2} \sqrt{1-\frac{2}{x}}-x} = \lim_{x \to \infty} \frac{1}{x \sqrt{1-\frac{2}{x}}-x} = \lim_{x \to \infty} \frac{\frac{1}{x}}{\sqrt{1-\frac{2}{x}}-1}$$ But the answer should be $-1$, so what I did must be wrong. How do you evaluate this limit the best way possible?",,"['calculus', 'limits', 'infinity']"
70,"I am almost certain the book is wrong on this ""proof"" of a limit.","I am almost certain the book is wrong on this ""proof"" of a limit.",,"Advanced Mathematics by Mingming Chen, Zhengyou Guo Jingxian Yu, Jinqiu Li. Chemical Industry Press pg 28, section 1.4.2 Example 2. Prove $$\lim_{x \to 1} \frac{1}{x-1} = \infty$$ Proof $\;\forall\, M > 0$, we want to find $\delta > 0$ such that $\left\lvert \frac{1}{x-1} \right\rvert > M$ for $ 0 < \vert x -1 \vert < \delta$. Since $\left\lvert \frac{1}{x-1} \right\rvert > M $ is equivalent to $\left\lvert x -1 \right\rvert < \frac{1}{M}$, take $\delta = \frac{1}{M}$ Then for all $x$ satisfying $0 < \vert x-1 \vert < \delta = \frac{1}{M}$, we have $\left\lvert \frac{1}{x-1}\right\rvert > M$ Therefore, $\lim_{x \to 1} \frac{1}{x-1} = \infty$ requested by Chris Culter 1.4.2 Infinity Quantity, Definition 1 : If the limit of a function $f\left(x\right)$ as $x \rightarrow x_0$ (or $x \rightarrow \infty$) is 0, then the function $f\left(x\right)$ is called an infinitesimal quantity with respect to $x\rightarrow x_0$ (or $x\rightarrow \infty$). Theorem 1 The necessary and sufficient condition for $\lim f\left(x\right) = A$ is $f\left(x\right) = A + \alpha\left(x\right)$, where $\alpha\left(x\right)$ is an infinitesimal quantity. Definition 2 Suppose that we have a function $f$ fancy looking one sorry cannot find the LaTeX command for that : $\mathring{U}\left(x_0\right) \to \mathbb{R}$. If $\,\forall\, M >0,\;\exists \, \delta >0$, such that  $\vert f\left(x\right) \vert > M$ for all $x$ satisfying $0 < \vert x-x_0 \vert < \delta$, then $f\left(x\right)$ is called an infinity as $x \to x_0$, denoted by $$\lim_{x\to x_0} f(x) = \infty\,\mbox{ or } f(x) \to \infty \mbox{ as } x\to x_0 $$ If we use $f(x) > M$ (or $f(x) < -M$) instead of $\vert f(x) \vert >M$ in the above definition then $f(x)$ is called a positive (or negative) infinity as $x \to x_0$, denoted by  $$\lim_{x\to x_0} f(x) = +\infty \left(\mbox{ or } \lim_{x\to x_0} f(x) = -\infty\right)$$ I am confused because $$\lim_{x \to 1^-} \frac{1}{x-1} \neq \lim_{x \to 1^+} \frac{1}{x-1}$$ So then the limit is DNE Did I miss something?","Advanced Mathematics by Mingming Chen, Zhengyou Guo Jingxian Yu, Jinqiu Li. Chemical Industry Press pg 28, section 1.4.2 Example 2. Prove $$\lim_{x \to 1} \frac{1}{x-1} = \infty$$ Proof $\;\forall\, M > 0$, we want to find $\delta > 0$ such that $\left\lvert \frac{1}{x-1} \right\rvert > M$ for $ 0 < \vert x -1 \vert < \delta$. Since $\left\lvert \frac{1}{x-1} \right\rvert > M $ is equivalent to $\left\lvert x -1 \right\rvert < \frac{1}{M}$, take $\delta = \frac{1}{M}$ Then for all $x$ satisfying $0 < \vert x-1 \vert < \delta = \frac{1}{M}$, we have $\left\lvert \frac{1}{x-1}\right\rvert > M$ Therefore, $\lim_{x \to 1} \frac{1}{x-1} = \infty$ requested by Chris Culter 1.4.2 Infinity Quantity, Definition 1 : If the limit of a function $f\left(x\right)$ as $x \rightarrow x_0$ (or $x \rightarrow \infty$) is 0, then the function $f\left(x\right)$ is called an infinitesimal quantity with respect to $x\rightarrow x_0$ (or $x\rightarrow \infty$). Theorem 1 The necessary and sufficient condition for $\lim f\left(x\right) = A$ is $f\left(x\right) = A + \alpha\left(x\right)$, where $\alpha\left(x\right)$ is an infinitesimal quantity. Definition 2 Suppose that we have a function $f$ fancy looking one sorry cannot find the LaTeX command for that : $\mathring{U}\left(x_0\right) \to \mathbb{R}$. If $\,\forall\, M >0,\;\exists \, \delta >0$, such that  $\vert f\left(x\right) \vert > M$ for all $x$ satisfying $0 < \vert x-x_0 \vert < \delta$, then $f\left(x\right)$ is called an infinity as $x \to x_0$, denoted by $$\lim_{x\to x_0} f(x) = \infty\,\mbox{ or } f(x) \to \infty \mbox{ as } x\to x_0 $$ If we use $f(x) > M$ (or $f(x) < -M$) instead of $\vert f(x) \vert >M$ in the above definition then $f(x)$ is called a positive (or negative) infinity as $x \to x_0$, denoted by  $$\lim_{x\to x_0} f(x) = +\infty \left(\mbox{ or } \lim_{x\to x_0} f(x) = -\infty\right)$$ I am confused because $$\lim_{x \to 1^-} \frac{1}{x-1} \neq \lim_{x \to 1^+} \frac{1}{x-1}$$ So then the limit is DNE Did I miss something?",,"['calculus', 'limits', 'proof-verification', 'fake-proofs']"
71,Some theorems in euclidean geometry have incomplete proofs,Some theorems in euclidean geometry have incomplete proofs,,"I have seen that, in euclidean geometry, proofs of some theorems use one instance of the 'geometric shape'(on which the theorem is based) to proof the theorem.  Like,  the proof of 'A straight line that divides any two sides of a triangle proportionally, is parallel to the third side' use only one instance of a triangle---like: ∆ABC is the instance Then, constructions are added to this diagram to prove the theorem. Clearly, the proof is not general.Because, only a triangle is in view.  Therefore, this proof is not precise. We have had a general proof, must be having.I haven't yet visualized what the general proof might be. So, why do people call the above type of proof ,a proof?Is it a complete mathematical proof?","I have seen that, in euclidean geometry, proofs of some theorems use one instance of the 'geometric shape'(on which the theorem is based) to proof the theorem.  Like,  the proof of 'A straight line that divides any two sides of a triangle proportionally, is parallel to the third side' use only one instance of a triangle---like: ∆ABC is the instance Then, constructions are added to this diagram to prove the theorem. Clearly, the proof is not general.Because, only a triangle is in view.  Therefore, this proof is not precise. We have had a general proof, must be having.I haven't yet visualized what the general proof might be. So, why do people call the above type of proof ,a proof?Is it a complete mathematical proof?",,"['calculus', 'linear-algebra', 'geometry', 'euclidean-geometry', 'analytic-geometry']"
72,What makes a Maclaurin Series special or important compared to the general Taylor Series?,What makes a Maclaurin Series special or important compared to the general Taylor Series?,,"I realize that the Maclaurin Series is a special form of the Taylor Series where the series is centered at $x=0$, but I have to wonder what's special about it such that it deserves its own special designation? On that point, how would you know (or care) which point to choose as the center of a Taylor Series?","I realize that the Maclaurin Series is a special form of the Taylor Series where the series is centered at $x=0$, but I have to wonder what's special about it such that it deserves its own special designation? On that point, how would you know (or care) which point to choose as the center of a Taylor Series?",,"['calculus', 'power-series']"
73,Series expansion of $\sqrt{\log(1+x)}$ at $x=0$,Series expansion of  at,\sqrt{\log(1+x)} x=0,Mathematica gives the following series expansion of $\sqrt{\log(1+x)}$ at $x=0$. $$ x^{1/2}-\frac{1}{4}x^{3/2}+\frac{13}{96}x^{5/2}-\cdots $$ You can find it from Wolfram alpha too. How can I obtain the expansion? Obviously Taylor expansion is impossible because $\sqrt{\log(1+x)}$ is not analytic at $x=0$. Taylor expansion of the $\log(1+x)$ at $x=1$ is possible. But I don't know how to take sequre root on the expanded series. I think I have not learned about square root of a series from calculs or analysis course. From what material can I study about such things?,Mathematica gives the following series expansion of $\sqrt{\log(1+x)}$ at $x=0$. $$ x^{1/2}-\frac{1}{4}x^{3/2}+\frac{13}{96}x^{5/2}-\cdots $$ You can find it from Wolfram alpha too. How can I obtain the expansion? Obviously Taylor expansion is impossible because $\sqrt{\log(1+x)}$ is not analytic at $x=0$. Taylor expansion of the $\log(1+x)$ at $x=1$ is possible. But I don't know how to take sequre root on the expanded series. I think I have not learned about square root of a series from calculs or analysis course. From what material can I study about such things?,,"['calculus', 'analysis']"
74,A constrained extremum problem,A constrained extremum problem,,"Find the maximum possible value of $$A = a^{333} + b^{333}+c^{333}$$ subject to the constraints $$a+b+c=0$$ and $$a^2+b^2+c^2=1,$$ where $a,b,c\in \mathbb{R}$ Thank you for helping me.","Find the maximum possible value of $$A = a^{333} + b^{333}+c^{333}$$ subject to the constraints $$a+b+c=0$$ and $$a^2+b^2+c^2=1,$$ where $a,b,c\in \mathbb{R}$ Thank you for helping me.",,['calculus']
75,Why does this limit not exist?,Why does this limit not exist?,,Working through some limit exercises. The answer sheet says the limit below does not exist. Is this correct. Shouldn't it be $-\infty$? $$\lim_{x \to 0^+} \left( \frac{1}{\sqrt{x^2+1}} - \frac{1}{x} \right)\ \ \ $$,Working through some limit exercises. The answer sheet says the limit below does not exist. Is this correct. Shouldn't it be $-\infty$? $$\lim_{x \to 0^+} \left( \frac{1}{\sqrt{x^2+1}} - \frac{1}{x} \right)\ \ \ $$,,"['calculus', 'limits']"
76,$\int \frac{dx}{x\log(x)}$,,\int \frac{dx}{x\log(x)},"I think I'm having a bad day. I was just trying to use integration by parts on the following integral:  $$\int \frac{dx}{x\log(x)}$$ Which yields $$\int \frac{dx}{x\log(x)} = 1 + \int \frac{dx}{x\log(x)}$$ Now, if I were to subtract  $$\int \frac{dx}{x\log(x)}$$ from both sides, it would seem that $0 = 1$. What is going on here? Aside: I do know the integral evaluates to  $$\log(\log(x))$$ plus a constant.","I think I'm having a bad day. I was just trying to use integration by parts on the following integral:  $$\int \frac{dx}{x\log(x)}$$ Which yields $$\int \frac{dx}{x\log(x)} = 1 + \int \frac{dx}{x\log(x)}$$ Now, if I were to subtract  $$\int \frac{dx}{x\log(x)}$$ from both sides, it would seem that $0 = 1$. What is going on here? Aside: I do know the integral evaluates to  $$\log(\log(x))$$ plus a constant.",,['calculus']
77,Calculate: $\lim_{n \rightarrow\infty}\left(\frac{3^{-n}\sin(3^{(1-n)})}{\tan(3^{1-2n})} \right)$,Calculate:,\lim_{n \rightarrow\infty}\left(\frac{3^{-n}\sin(3^{(1-n)})}{\tan(3^{1-2n})} \right),How to calculate following limit without using L'Hospital rule? $$\lim_{n \rightarrow\infty}\left(\frac{3^{-n}\sin(3^{(1-n)})}{\tan(3^{1-2n})} \right)$$,How to calculate following limit without using L'Hospital rule? $$\lim_{n \rightarrow\infty}\left(\frac{3^{-n}\sin(3^{(1-n)})}{\tan(3^{1-2n})} \right)$$,,"['calculus', 'limits']"
78,How to compute the following integral?,How to compute the following integral?,,"$$\int\frac{\sqrt{1+x^2}}{x}dx$$ I tried letting $x=\tan\theta\ $ where $\frac{-\pi}{2} < \theta < \frac{\pi}{2}$ so that $dx = \sec^2\theta\,d\theta$ and after making the substitution one gets to $$\int\frac{\sec^3\theta}{\tan\theta} d\theta$$ which is equivalent to $$\int\frac{1}{\cos^2\theta\sin\theta}d\theta$$ After this, I don't know how to proceed. I tried looking for the same integral elsewhere and I found a solution that involves a method called partial fraction decomposition, I believe. But, I have not been taught that method yet and this integral appears on the section of the book that I am currently working on.","$$\int\frac{\sqrt{1+x^2}}{x}dx$$ I tried letting $x=\tan\theta\ $ where $\frac{-\pi}{2} < \theta < \frac{\pi}{2}$ so that $dx = \sec^2\theta\,d\theta$ and after making the substitution one gets to $$\int\frac{\sec^3\theta}{\tan\theta} d\theta$$ which is equivalent to $$\int\frac{1}{\cos^2\theta\sin\theta}d\theta$$ After this, I don't know how to proceed. I tried looking for the same integral elsewhere and I found a solution that involves a method called partial fraction decomposition, I believe. But, I have not been taught that method yet and this integral appears on the section of the book that I am currently working on.",,"['calculus', 'integration']"
79,"Series Divergence - Apostol Calculus Vol I, Section 10.20 #7","Series Divergence - Apostol Calculus Vol I, Section 10.20 #7",,"Prove that $\displaystyle\sum_{n=2}^\infty\frac {(-1)^n}{\sqrt{n}+(-1)^n} $ diverges. It is easy to see that this absolutely diverges, however how can it be proven to diverge in general? The idea as posted in another forum was to group the terms in the sequence as follows: $$\sum_{n=2}^\infty \frac{(-1)^n}{\sqrt{n}+(-1)^n}=-\sum_{n=1}^\infty \left(\frac{1}{\sqrt{2n+1}-1}-\frac 1 {\sqrt{2n}+1}\right)$$ and then show that this sequence diverges. I did end up getting an answer from that forum (thank you!) however it depended on results from WolframAlpha which seem extremely difficult to solve by hand. This question is from Apostol's Calculus, written in 1969, so I'd like to have a solution which doesn't depend on WolframAlpha.","Prove that $\displaystyle\sum_{n=2}^\infty\frac {(-1)^n}{\sqrt{n}+(-1)^n} $ diverges. It is easy to see that this absolutely diverges, however how can it be proven to diverge in general? The idea as posted in another forum was to group the terms in the sequence as follows: $$\sum_{n=2}^\infty \frac{(-1)^n}{\sqrt{n}+(-1)^n}=-\sum_{n=1}^\infty \left(\frac{1}{\sqrt{2n+1}-1}-\frac 1 {\sqrt{2n}+1}\right)$$ and then show that this sequence diverges. I did end up getting an answer from that forum (thank you!) however it depended on results from WolframAlpha which seem extremely difficult to solve by hand. This question is from Apostol's Calculus, written in 1969, so I'd like to have a solution which doesn't depend on WolframAlpha.",,"['calculus', 'divergent-series']"
80,"Find out $\int_0^\infty\frac{x^2+ax+1}{1+x^4}\arctan\frac1x\,{\rm d}x$.",Find out .,"\int_0^\infty\frac{x^2+ax+1}{1+x^4}\arctan\frac1x\,{\rm d}x","$$ \mbox{Find out}\quad\int_{0}^{\infty}\frac{x^{2} + ax +1}{1 + x^{4}}\,\arctan\left(\frac{1}{x}\right){\rm d}x $$ My attempt: \begin{align}I &= \int_{0}^{\infty} \frac{x^2 + ax + 1}{1 + x^4}\,\arctan\left(\frac{1}{x}\right){\rm d}x \\[2mm] & = \int_{0}^{\infty} \frac{x^2 + ax + x}{1 + x^4}\,\arctan\left(x\right) {\rm d}x\qquad\qquad \left[x \mapsto \frac{1}{x}\right] \\[2mm] \implies 2I & = \int_{0}^{\infty} \frac{\left(x^{2} + ax + 1\right) \left[\arctan\left(1/x\right) + \arctan\left(x\right)\right]}{1+x^4}{\rm d}x \\[2mm] & = \frac{\pi}{2}\int_{0}^{\infty}\frac{x^{2} + ax + 1}{1+x^4}{\rm d}x \end{align} No idea how to proceed (I'm expecting cooler approaches without Feymann here) .",My attempt: No idea how to proceed (I'm expecting cooler approaches without Feymann here) .,"
\mbox{Find out}\quad\int_{0}^{\infty}\frac{x^{2} + ax +1}{1 + x^{4}}\,\arctan\left(\frac{1}{x}\right){\rm d}x
 \begin{align}I &= \int_{0}^{\infty}
\frac{x^2 + ax + 1}{1 + x^4}\,\arctan\left(\frac{1}{x}\right){\rm d}x
\\[2mm] & = \int_{0}^{\infty}
\frac{x^2 + ax + x}{1 + x^4}\,\arctan\left(x\right)
{\rm d}x\qquad\qquad \left[x \mapsto \frac{1}{x}\right]
\\[2mm] \implies 2I & = \int_{0}^{\infty}
\frac{\left(x^{2} + ax + 1\right)
\left[\arctan\left(1/x\right) + \arctan\left(x\right)\right]}{1+x^4}{\rm d}x
\\[2mm] & =
\frac{\pi}{2}\int_{0}^{\infty}\frac{x^{2} + ax + 1}{1+x^4}{\rm d}x
\end{align}","['calculus', 'integration', 'improper-integrals']"
81,Finding the limit of $n(\ln2-\sum_{k=1}^n\frac{1}{n+k})$.,Finding the limit of .,n(\ln2-\sum_{k=1}^n\frac{1}{n+k}),"Let $$A_n:=\frac{1}{n+1}+\cdots+\frac{1}{2n}.$$ It is well known that $A_n$ is an increasing sequence, and $\lim_{n\rightarrow \infty}A_n=\ln(2)$ . Motivated by how fast $A_n$ converges to $ln(2)$ , I would like to know the limit below $$\lim_{n\rightarrow\infty}n\left(\ln(2)-A_n\right).$$ First, since $1/(1+x)$ is a strictly decreasing function, we have $$\ln 2=\int_0^1 \frac{1}{1+x}\, dx<\frac{1}{n}\sum_{k=0}^{n-1}\frac{1}{1+k/n}=\frac{1}{n}+\cdots+\frac{1}{2n-1}.$$ Therefore, we have $$\ln(2)-A_n<\left(\frac{1}{n}+\cdots+\frac{1}{2n-1}\right)-\left(\frac{1}{n+1}+\cdots+\frac{1}{2n}\right)=\frac{1}{n}-\frac{1}{2n}=\frac{1}{2n}.$$ Hence $B_n:=n(\ln2-A_n)$ is bounded from above, and $$\limsup_{n\rightarrow\infty}B_n\le \frac{1}{2}.$$ Furthermore, since $b_n:=1/(\ln 2-A_n)$ is strictly increasing, by the Stolz theorem, we have $$\lim_{n\rightarrow \infty}B_n=\lim_{n\rightarrow \infty}\frac{1}{b_{n+1}-b_n}=\lim_{n\rightarrow \infty}4(1+\frac{1}{2n})B_nB_{n+1}.$$ Therefore, if $B_n$ has a limit, then the limit has to be $0$ or $1/4$ . However, first, I have some trouble in showing the monotonicity of $B_n$ , and more importantly, I don't know how to exclude the possibility that the limit of $B_n$ cannot be $0$ . Any ideas or comments are fully appreciated.","Let It is well known that is an increasing sequence, and . Motivated by how fast converges to , I would like to know the limit below First, since is a strictly decreasing function, we have Therefore, we have Hence is bounded from above, and Furthermore, since is strictly increasing, by the Stolz theorem, we have Therefore, if has a limit, then the limit has to be or . However, first, I have some trouble in showing the monotonicity of , and more importantly, I don't know how to exclude the possibility that the limit of cannot be . Any ideas or comments are fully appreciated.","A_n:=\frac{1}{n+1}+\cdots+\frac{1}{2n}. A_n \lim_{n\rightarrow \infty}A_n=\ln(2) A_n ln(2) \lim_{n\rightarrow\infty}n\left(\ln(2)-A_n\right). 1/(1+x) \ln 2=\int_0^1 \frac{1}{1+x}\, dx<\frac{1}{n}\sum_{k=0}^{n-1}\frac{1}{1+k/n}=\frac{1}{n}+\cdots+\frac{1}{2n-1}. \ln(2)-A_n<\left(\frac{1}{n}+\cdots+\frac{1}{2n-1}\right)-\left(\frac{1}{n+1}+\cdots+\frac{1}{2n}\right)=\frac{1}{n}-\frac{1}{2n}=\frac{1}{2n}. B_n:=n(\ln2-A_n) \limsup_{n\rightarrow\infty}B_n\le \frac{1}{2}. b_n:=1/(\ln 2-A_n) \lim_{n\rightarrow \infty}B_n=\lim_{n\rightarrow \infty}\frac{1}{b_{n+1}-b_n}=\lim_{n\rightarrow \infty}4(1+\frac{1}{2n})B_nB_{n+1}. B_n 0 1/4 B_n B_n 0","['calculus', 'sequences-and-series']"
82,Computation of $\displaystyle{\sum_{n=1}^{\infty}\frac{\sin nx \cdot \sin ny}{n^2}}$,Computation of,\displaystyle{\sum_{n=1}^{\infty}\frac{\sin nx \cdot \sin ny}{n^2}},First I used the identity $$\sin nx \cdot \sin ny=\cos(n(x-y))-\cos(n(x+y))$$ and the sum turned into the following $$\sum_{n=1}^{\infty}\frac{\sin nx \cdot \sin ny}{n^2}=\sum_{n=1}^{\infty}\frac{\cos(n(x-y))}{n^2}-\sum_{n=1}^{\infty}\frac{\cos(n(x+y))}{n^2}$$ because both series converge. And now we have to calculate the two sums above that have the form $$\sum_{n=1}^{\infty}\frac{\cos(na)}{n^2}$$ for $a\in \mathbb R$ . Then I tried the following: $$\sum_{n=1}^{\infty}\frac{\cos(na)}{n^2}=\textrm{Re}\sum_{n=1}^{\infty}\frac{e^{ina}}{n^2}$$ but then things are getting a bit difficult because the function $\textrm{Li}_2(z)$ appears and I don't know how to handle it from there... Thanks for the help in advance!,First I used the identity and the sum turned into the following because both series converge. And now we have to calculate the two sums above that have the form for . Then I tried the following: but then things are getting a bit difficult because the function appears and I don't know how to handle it from there... Thanks for the help in advance!,\sin nx \cdot \sin ny=\cos(n(x-y))-\cos(n(x+y)) \sum_{n=1}^{\infty}\frac{\sin nx \cdot \sin ny}{n^2}=\sum_{n=1}^{\infty}\frac{\cos(n(x-y))}{n^2}-\sum_{n=1}^{\infty}\frac{\cos(n(x+y))}{n^2} \sum_{n=1}^{\infty}\frac{\cos(na)}{n^2} a\in \mathbb R \sum_{n=1}^{\infty}\frac{\cos(na)}{n^2}=\textrm{Re}\sum_{n=1}^{\infty}\frac{e^{ina}}{n^2} \textrm{Li}_2(z),"['calculus', 'sequences-and-series', 'derivatives', 'complex-numbers', 'summation']"
83,Are there any nice expressions for $\int_0^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x$?,Are there any nice expressions for ?,\int_0^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x,"In some applied mathematics (ocean modelling) I was doing I came across the integral $$I(k)=\int_0^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x,$$ where $k\geq 0$ is a constant that depends on the parameters (e.g. flow speed) I wish to use. I was wondering whether anyone knows of a neat expression for this integral, even in terms of Bessel functions? I'm particularly interested in the real part of this integral, that is $$\Re(I(k))=\int_k^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x.$$ I was hoping for a solution similar this question but have had no luck. An asymptotic expression (for large $k$ ) for $I(k)$ or $\Re(I(k))$ would also be really useful.","In some applied mathematics (ocean modelling) I was doing I came across the integral where is a constant that depends on the parameters (e.g. flow speed) I wish to use. I was wondering whether anyone knows of a neat expression for this integral, even in terms of Bessel functions? I'm particularly interested in the real part of this integral, that is I was hoping for a solution similar this question but have had no luck. An asymptotic expression (for large ) for or would also be really useful.","I(k)=\int_0^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x, k\geq 0 \Re(I(k))=\int_k^\infty e^{-x^2}\sqrt{x^2-k^2}\ \mathrm{d}x. k I(k) \Re(I(k))","['calculus', 'integration', 'definite-integrals', 'asymptotics', 'bessel-functions']"
84,How to find $\lim_{x\to 2}\frac{|x-2|}{2x-x^2}$,How to find,\lim_{x\to 2}\frac{|x-2|}{2x-x^2},"$$\lim_{x\to 2}\frac{|x-2|}{2x-x^2}$$ I know the answer of the left hand limit is $1/2$ ; while the right hand limit is $-1/2$ . But I don't understand how do you get that? If I factor $-x$ from the denominator, I'll get $(-2+x)$ which cancels out with the numerator. Then I'll get $1/-x$ . If I plug in the limit of $2$ from the left hand, it would be $1/2$ . Wouldn't it also be $1/2$ from the right hand, as well? I'm getting confused on how to work this out. Please help, thank you!","I know the answer of the left hand limit is ; while the right hand limit is . But I don't understand how do you get that? If I factor from the denominator, I'll get which cancels out with the numerator. Then I'll get . If I plug in the limit of from the left hand, it would be . Wouldn't it also be from the right hand, as well? I'm getting confused on how to work this out. Please help, thank you!",\lim_{x\to 2}\frac{|x-2|}{2x-x^2} 1/2 -1/2 -x (-2+x) 1/-x 2 1/2 1/2,"['calculus', 'algebra-precalculus', 'limits', 'factoring']"
85,Examples of non-trivial exclusively irrational integrals?,Examples of non-trivial exclusively irrational integrals?,,"One very famous integral is $$\int_{\mathbb{R}} \frac{\cos(x)}{x^2 +1} \, dx = \frac{\pi}{e} \tag{1}$$ as is shown in the answers to this question . I find this integral particularly interesting as the result is written exclusively as a combination (by ""combination"" I mean a product/quotient/addition/exponentiation/logarithm) of irrational numbers, where I'm using "" exclusively irrational "" here to mean that the answer doesn't involve other factors of rational numbers combined with the irrationals. For example, the integral: $$\int_{0}^{\infty} \frac{x^2}{e^x-1}\, dx = 2 \zeta(3)$$ I would not consider being ""exclusively"" irrational because of the factor of $2$ multiplying $\zeta(3)$ . I decided to look for other exclusively irrational integrals similar to $(1)$ which combine several irrational numbers in their result, but to my surprise, I couldn't find many examples similar to this. Most of the results I found where "" single-irrational "", like the following integrals: $$ \int_{\mathbb{R}} e^{-x^2}\, dx = \sqrt{\pi}, \qquad \int_{0}^{1} \ln\left(\ln\left(\frac{1}{x}\right)\right)\, dx=-\gamma, \qquad \int_{1}^{\infty}\frac{\ln(x)}{1+x^2} \, dx = G$$ which, although they are exclusively irrational, they can also be written in terms of a single famous irrational (hence the moniker I gave them). Some other common finds were ""near-misses"" like: $$\int _0^{\infty }e^{-x}\ln ^2\left(x\right)\ dx = \gamma^2 + \frac{\pi^2}{6}, \qquad \int_{1}^{\infty} \frac{(x^4 - 6x^2+1)\ln(\ln(x))}{(1+x^2)^3}\, dx = \frac{2G}{\pi}$$ In fact, the only other exclusively irrational integral which wasn't also a single-irrational that I found was the integral $$ \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi}\tag{2}$$ Of course, there are trivial integrals that indeed give exclusively irrational results. For example $$\int_{0}^{\frac{\pi}{e}} 1 \, dx = \frac{\pi}{e} $$ but I would like to avoid these types of integrals. Another type is the ""disguised"" solution, which would be something like $$ \int_{\mathbb{R}} \frac{\sin(x)}{\color{purple}{e}x}\, dx= \frac{\pi}{e}, \qquad \int_{-1}^1\frac{1}{\color{purple}{4}x}\sqrt{\frac{1+x}{1-x}}\ln\left(\frac{2\,x^2+2\,x+1}{2\,x^2-2\,x+1}\right)\ dx =\pi \, \text{arccot}\left(\sqrt{\varphi} \right)$$ which in reality are just single-irrational solutions or near-misses where we just multiplied a $\color{purple}{\text{factor}}$ on both sides. I would also like to avoid these types of integrals. My question is: Does anyone know any exclusively irrational integrals like $(1)$ and $(2)$ where you combine several different irrationals in the result?  Preferably avoiding single-irrational, disguised, or trivial integrals like my other examples. Ideally I would like results that exclusively combine irrational (and also very likely but still unproven to be irrational ) numbers such as $e,\,\pi$ , Golden ratio $\varphi ,\, \zeta(\text{Odd integer}),\,\ln(\text{Prime number}),\, \sqrt{\text{Prime number}}$ , Euler-Mascheroni constant and Catalan's constant; Where by ""combination"" I mean that these numbers are being added/multiplied/divided/exponentiated or being the argument of a trig function, in a way that doesn't simplify to factors of rational numbers, i.e. without something like $\ln\left(e^2\right)$ . Any help or suggestions are greatly appreciated. Thank you very much!","One very famous integral is as is shown in the answers to this question . I find this integral particularly interesting as the result is written exclusively as a combination (by ""combination"" I mean a product/quotient/addition/exponentiation/logarithm) of irrational numbers, where I'm using "" exclusively irrational "" here to mean that the answer doesn't involve other factors of rational numbers combined with the irrationals. For example, the integral: I would not consider being ""exclusively"" irrational because of the factor of multiplying . I decided to look for other exclusively irrational integrals similar to which combine several irrational numbers in their result, but to my surprise, I couldn't find many examples similar to this. Most of the results I found where "" single-irrational "", like the following integrals: which, although they are exclusively irrational, they can also be written in terms of a single famous irrational (hence the moniker I gave them). Some other common finds were ""near-misses"" like: In fact, the only other exclusively irrational integral which wasn't also a single-irrational that I found was the integral Of course, there are trivial integrals that indeed give exclusively irrational results. For example but I would like to avoid these types of integrals. Another type is the ""disguised"" solution, which would be something like which in reality are just single-irrational solutions or near-misses where we just multiplied a on both sides. I would also like to avoid these types of integrals. My question is: Does anyone know any exclusively irrational integrals like and where you combine several different irrationals in the result?  Preferably avoiding single-irrational, disguised, or trivial integrals like my other examples. Ideally I would like results that exclusively combine irrational (and also very likely but still unproven to be irrational ) numbers such as , Golden ratio , Euler-Mascheroni constant and Catalan's constant; Where by ""combination"" I mean that these numbers are being added/multiplied/divided/exponentiated or being the argument of a trig function, in a way that doesn't simplify to factors of rational numbers, i.e. without something like . Any help or suggestions are greatly appreciated. Thank you very much!","\int_{\mathbb{R}} \frac{\cos(x)}{x^2 +1} \, dx = \frac{\pi}{e} \tag{1} \int_{0}^{\infty} \frac{x^2}{e^x-1}\, dx = 2 \zeta(3) 2 \zeta(3) (1)  \int_{\mathbb{R}} e^{-x^2}\, dx = \sqrt{\pi}, \qquad \int_{0}^{1} \ln\left(\ln\left(\frac{1}{x}\right)\right)\, dx=-\gamma, \qquad \int_{1}^{\infty}\frac{\ln(x)}{1+x^2} \, dx = G \int _0^{\infty }e^{-x}\ln ^2\left(x\right)\ dx = \gamma^2 + \frac{\pi^2}{6}, \qquad \int_{1}^{\infty} \frac{(x^4 - 6x^2+1)\ln(\ln(x))}{(1+x^2)^3}\, dx = \frac{2G}{\pi}  \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi}\tag{2} \int_{0}^{\frac{\pi}{e}} 1 \, dx = \frac{\pi}{e}   \int_{\mathbb{R}} \frac{\sin(x)}{\color{purple}{e}x}\, dx= \frac{\pi}{e}, \qquad \int_{-1}^1\frac{1}{\color{purple}{4}x}\sqrt{\frac{1+x}{1-x}}\ln\left(\frac{2\,x^2+2\,x+1}{2\,x^2-2\,x+1}\right)\ dx =\pi \, \text{arccot}\left(\sqrt{\varphi} \right) \color{purple}{\text{factor}} (1) (2) e,\,\pi \varphi ,\, \zeta(\text{Odd integer}),\,\ln(\text{Prime number}),\, \sqrt{\text{Prime number}} \ln\left(e^2\right)","['calculus', 'integration', 'definite-integrals', 'irrational-numbers', 'big-list']"
86,Is Riemann integration only concerned with rates of change?,Is Riemann integration only concerned with rates of change?,,"Consider the Riemann integrable function $f(x)$ . Whenever I see the expression $$ \int_a^b f(x) \ dx $$ I read this as $$ \int_a^b \frac{dF(x)}{dx} \ dx $$ where $F(x)$ is the antiderivative of $f(x)$ . In other words, I consider every Riemann integral to be concerned with integrating a ""rate of change"", which in this case is $\frac{dF(x)}{dx}$ . Is this thinking correct? That is, do all Riemann integrals take in a ""rate of change"" as an input?","Consider the Riemann integrable function . Whenever I see the expression I read this as where is the antiderivative of . In other words, I consider every Riemann integral to be concerned with integrating a ""rate of change"", which in this case is . Is this thinking correct? That is, do all Riemann integrals take in a ""rate of change"" as an input?","f(x) 
\int_a^b f(x) \ dx
 
\int_a^b \frac{dF(x)}{dx} \ dx
 F(x) f(x) \frac{dF(x)}{dx}","['calculus', 'integration', 'riemann-integration']"
87,Prove $\{a_n\}$ converges.,Prove  converges.,\{a_n\},"Suppose $a_1,a_2>0$ and $a_{n+2}=2+\dfrac{1}{a_{n+1}^2}+\dfrac{1}{a_n^2}(n\ge 1)$ . Prove $\{a_n\}$ converges. First, we may show $\{a_n\}$ is bounded for $n\ge 3$ , since $$2 \le a_{n+2}\le 2+\frac{1}{2^2}+\frac{1}{2^2}=\frac{5}{2},~~~~~~ \forall n \ge 1.$$ But how to go on?","Suppose and . Prove converges. First, we may show is bounded for , since But how to go on?","a_1,a_2>0 a_{n+2}=2+\dfrac{1}{a_{n+1}^2}+\dfrac{1}{a_n^2}(n\ge 1) \{a_n\} \{a_n\} n\ge 3 2 \le a_{n+2}\le 2+\frac{1}{2^2}+\frac{1}{2^2}=\frac{5}{2},~~~~~~ \forall n \ge 1.","['calculus', 'sequences-and-series', 'limits']"
88,Cauchy's formula for repeated integrals proof by induction,Cauchy's formula for repeated integrals proof by induction,,I was trying to follow along with the proof on Wikipedia for Cauchy's formula for repeated integrals and I'm stuck on the last step. How do you go from $$\int_a^x \frac {d}{dy} \left( \int_a^y (y-t)^nf(t)dt\right) dy$$ to $$\int_a^x (x-t)^nf(t) dt$$,I was trying to follow along with the proof on Wikipedia for Cauchy's formula for repeated integrals and I'm stuck on the last step. How do you go from to,\int_a^x \frac {d}{dy} \left( \int_a^y (y-t)^nf(t)dt\right) dy \int_a^x (x-t)^nf(t) dt,"['calculus', 'integration', 'multivariable-calculus', 'derivatives']"
89,Fresnel integral $\int\limits_0^\infty\sin(x^2) dx$ calculation,Fresnel integral  calculation,\int\limits_0^\infty\sin(x^2) dx,"I'm trying to calculate the improper Fresnel integral $\int\limits_0^\infty\sin(x^2)dx$ calculation. It uses several substitutions. There's one substitution that is not clear for me. I could not understand how to get the right side from the left one. What subtitution is done here? $$\int\limits_0^\infty\frac{v^2}{1+v^4} dv = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du.$$ Fresnel integral calculation: In the beginning put $x^2=t$ and then: $$\int\limits_0^\infty\sin(x^2) dx = \frac{1}{2}\int\limits_0^\infty\frac{\sin t}{\sqrt{t}}dt$$ Then changing variable in Euler-Poisson integral we have: $$\frac{2}{\sqrt\pi}\int_0^\infty e^{-tu^2}du =\frac{1}{\sqrt{t} }$$ The next step is to put this integral instead of $\frac{1}{\sqrt{t}}$ . $$\int\limits_0^\infty\sin(x^2)dx = \frac{1}{\sqrt\pi}\int\limits_0^\infty\sin(t)\int_0^\infty\ e^{-tu^2}dudt = \frac{1}{\sqrt\pi}\int\limits_0^\infty\int\limits_0^\infty \sin (t) e^{-tu^2}dtdu$$ And the inner integral $\int\limits_0^\infty \sin (t) e^{-tu^2}dt$ is equal to $\frac{1}{1+u^4}$ . The next calculation: $$\int\limits_0^\infty \frac{du}{1+u^4} = \int\limits_0^\infty \frac{v^2dv}{1+v^4} = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du = \frac{1}{2} \int\limits_0^\infty\frac{d(u-\frac{1}{u})}{u^2+\frac{1}{u^2}} $$ $$= \frac{1}{2} \int\limits_{-\infty}^{\infty}\frac{ds}{2+s^2}=\frac{1}{\sqrt2}\arctan\frac{s}{\sqrt2} \Big|_{-\infty}^\infty = \frac{\pi}{2\sqrt2} $$ In this calculation the Dirichle's test is needed to check the integral $\int_0^\infty\frac{\sin t}{\sqrt{t}}dt$ convergence. It's needed also to substantiate the reversing the order of integration ( $dudt = dtdu$ ). All these integrals exist in a Lebesgue sense, and Tonelli theorem justifies reversing the order of integration. The final result is $$\frac{1}{\sqrt\pi}\frac{\pi}{2\sqrt2}=\frac{1}{2}\sqrt\frac{\pi}{2}$$","I'm trying to calculate the improper Fresnel integral calculation. It uses several substitutions. There's one substitution that is not clear for me. I could not understand how to get the right side from the left one. What subtitution is done here? Fresnel integral calculation: In the beginning put and then: Then changing variable in Euler-Poisson integral we have: The next step is to put this integral instead of . And the inner integral is equal to . The next calculation: In this calculation the Dirichle's test is needed to check the integral convergence. It's needed also to substantiate the reversing the order of integration ( ). All these integrals exist in a Lebesgue sense, and Tonelli theorem justifies reversing the order of integration. The final result is",\int\limits_0^\infty\sin(x^2)dx \int\limits_0^\infty\frac{v^2}{1+v^4} dv = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du. x^2=t \int\limits_0^\infty\sin(x^2) dx = \frac{1}{2}\int\limits_0^\infty\frac{\sin t}{\sqrt{t}}dt \frac{2}{\sqrt\pi}\int_0^\infty e^{-tu^2}du =\frac{1}{\sqrt{t} } \frac{1}{\sqrt{t}} \int\limits_0^\infty\sin(x^2)dx = \frac{1}{\sqrt\pi}\int\limits_0^\infty\sin(t)\int_0^\infty\ e^{-tu^2}dudt = \frac{1}{\sqrt\pi}\int\limits_0^\infty\int\limits_0^\infty \sin (t) e^{-tu^2}dtdu \int\limits_0^\infty \sin (t) e^{-tu^2}dt \frac{1}{1+u^4} \int\limits_0^\infty \frac{du}{1+u^4} = \int\limits_0^\infty \frac{v^2dv}{1+v^4} = \frac{1}{2}\int\limits_0^\infty\frac{1+u^2}{1+u^4} du = \frac{1}{2} \int\limits_0^\infty\frac{d(u-\frac{1}{u})}{u^2+\frac{1}{u^2}}  = \frac{1}{2} \int\limits_{-\infty}^{\infty}\frac{ds}{2+s^2}=\frac{1}{\sqrt2}\arctan\frac{s}{\sqrt2} \Big|_{-\infty}^\infty = \frac{\pi}{2\sqrt2}  \int_0^\infty\frac{\sin t}{\sqrt{t}}dt dudt = dtdu \frac{1}{\sqrt\pi}\frac{\pi}{2\sqrt2}=\frac{1}{2}\sqrt\frac{\pi}{2},"['calculus', 'integration', 'analysis', 'definite-integrals', 'improper-integrals']"
90,Does $(1+\frac12-\frac13) + (\frac14+\frac15-\frac16)+(\frac17+\frac18-\frac19)+\cdots$ converge?,Does  converge?,(1+\frac12-\frac13) + (\frac14+\frac15-\frac16)+(\frac17+\frac18-\frac19)+\cdots,"Does the series $$S=\left(1+\frac{1}{2}-\frac{1}{3} \right) + \left(\frac{1}{4}+\frac{1}{5}-\frac{1}{6} \right)+\left(\frac{1}{7}+\frac{1}{8}-\frac{1}{9}\right)+\cdots$$ converge? Here's my attempt at a solution: $$S = \sum_{n=1}^{\infty}\frac{1}{n}-2\sum_{n=1}^{\infty}\frac{1}{3n}=\sum_{n=1}^{\infty}\frac{1}{3n}=\frac{1}{3}\sum_{n=1}^{\infty}\frac{1}{n}$$ As we can ""rewrite"" this series as one third of the harmonical series (that diverges), we conclude the divergence of $S$ . Is this right? Which other convergence tests could be used?","Does the series converge? Here's my attempt at a solution: As we can ""rewrite"" this series as one third of the harmonical series (that diverges), we conclude the divergence of . Is this right? Which other convergence tests could be used?",S=\left(1+\frac{1}{2}-\frac{1}{3} \right) + \left(\frac{1}{4}+\frac{1}{5}-\frac{1}{6} \right)+\left(\frac{1}{7}+\frac{1}{8}-\frac{1}{9}\right)+\cdots S = \sum_{n=1}^{\infty}\frac{1}{n}-2\sum_{n=1}^{\infty}\frac{1}{3n}=\sum_{n=1}^{\infty}\frac{1}{3n}=\frac{1}{3}\sum_{n=1}^{\infty}\frac{1}{n} S,"['calculus', 'sequences-and-series', 'proof-verification', 'convergence-divergence', 'divergent-series']"
91,Evaluation of a Fresnel type integral.,Evaluation of a Fresnel type integral.,,"I was evaluating the following complex integral via gamma function: $\int_0^\infty \sin (x^p) \,dx$ $\;$ for $p \gt 1$ , so I expressed it as an imaginary part of $\int_0^\infty \exp(-ix^p) \, dx$ $\;$ for $p \gt 1$ The formula of the gamma function is $\Gamma (z) = \int_0^\infty x^{z-1} e^{-x} \, dx  $ I used the substitution $-y^{1/p}=xi$ , $\;$ $\;$ $dx= \frac 1 p y^{\frac{1}{p}-1}i \, dy$ $\;$ $\;$ and $\;$ $\;$ $\frac {1}{p} = \alpha$ Then $\int_0^\infty \alpha i y^{\alpha-1}e^{-y} \, dx = \alpha i \Gamma (\alpha) = \ i \frac {1}{p} \Gamma (\frac {1}{p})$ The solution according to my textbook is $\  \frac {1}{p} \Gamma (\frac {1}{p}) \sin (\frac {\pi}{2p})$ But I think $\sin (\frac {\pi}{2p})$ is right if I have ${i}^p$ , but I got just $i$ . My solution is then $\  \frac {1}{p} \Gamma (\frac {1}{p}) \sin (\frac {\pi}{2}) =\frac {1}{p} \Gamma (\frac {1}{p})$ . Did I miss something important? EDIT I tried to calculate this integral for $p = 2$ and the textbook is right, but why?","I was evaluating the following complex integral via gamma function: for , so I expressed it as an imaginary part of for The formula of the gamma function is I used the substitution , and Then The solution according to my textbook is But I think is right if I have , but I got just . My solution is then . Did I miss something important? EDIT I tried to calculate this integral for and the textbook is right, but why?","\int_0^\infty \sin (x^p) \,dx \; p \gt 1 \int_0^\infty \exp(-ix^p) \, dx \; p \gt 1 \Gamma (z) = \int_0^\infty x^{z-1} e^{-x} \, dx   -y^{1/p}=xi \; \; dx= \frac 1 p y^{\frac{1}{p}-1}i \, dy \; \; \; \; \frac {1}{p} = \alpha \int_0^\infty \alpha i y^{\alpha-1}e^{-y} \, dx = \alpha i \Gamma (\alpha) = \ i \frac {1}{p} \Gamma (\frac {1}{p}) \  \frac {1}{p} \Gamma (\frac {1}{p}) \sin (\frac {\pi}{2p}) \sin (\frac {\pi}{2p}) {i}^p i \  \frac {1}{p} \Gamma (\frac {1}{p}) \sin (\frac {\pi}{2}) =\frac {1}{p} \Gamma (\frac {1}{p}) p = 2","['calculus', 'integration', 'complex-analysis']"
92,How to recognize a sum as a Riemann Sum [duplicate],How to recognize a sum as a Riemann Sum [duplicate],,"This question already has answers here : Infinite Series $1+\frac12-\frac23+\frac14+\frac15-\frac26+\cdots$ (5 answers) Closed 6 years ago . Evaluate $$\frac{1}{1}+\frac{1}{2}-\frac{2}{3}+\frac{1}{4}+\frac{1}{5}-\frac{2}{6}+\frac{1}{7}+\frac{1}{8}-\frac{2}{9}+\cdots+\frac{1}{3n+1}+\frac{1}{3n+2}-\frac{2}{3n+3}+\cdots$$ answer choices: a) $\ln 2$ b) $\ln 3$ c) $e^2$ d) $\dfrac 9 {25}$ Looking at the answer choices, I am almost certain that we need to rearrange the sum into a Riemann sum, but I am stuck on how to do so. Also are there any general techniques to recognize/rearrange summations such as these into Riemann sums? This problem is from a competition, so I would need to solve these problems quickly. Thanks!","This question already has answers here : Infinite Series $1+\frac12-\frac23+\frac14+\frac15-\frac26+\cdots$ (5 answers) Closed 6 years ago . Evaluate $$\frac{1}{1}+\frac{1}{2}-\frac{2}{3}+\frac{1}{4}+\frac{1}{5}-\frac{2}{6}+\frac{1}{7}+\frac{1}{8}-\frac{2}{9}+\cdots+\frac{1}{3n+1}+\frac{1}{3n+2}-\frac{2}{3n+3}+\cdots$$ answer choices: a) $\ln 2$ b) $\ln 3$ c) $e^2$ d) $\dfrac 9 {25}$ Looking at the answer choices, I am almost certain that we need to rearrange the sum into a Riemann sum, but I am stuck on how to do so. Also are there any general techniques to recognize/rearrange summations such as these into Riemann sums? This problem is from a competition, so I would need to solve these problems quickly. Thanks!",,['calculus']
93,What is $e^{-\int \tan(t)dt}$?,What is ?,e^{-\int \tan(t)dt},"I know that $-\int \tan(t)dt$ = $\ln |\cos t|$ (letting $C=0$). So I would think that $e^{-\int \tan(t)dt}$ would be equal to $e^{\ln |\cos t|} = |\cos t|$. However, my math textbook and Wolfram Alpha both say that $e^{-\int \tan(t)dt}=e^{\ln (\cos t)} = \cos t$. Why can the absolute value be ignored when taking the indefinite integral in this case? Context: Finding an integrating factor for $x' = x\tan(t) + \sin(t)$. But Wolfram Alpha also gave me this answer without any differential equations context.","I know that $-\int \tan(t)dt$ = $\ln |\cos t|$ (letting $C=0$). So I would think that $e^{-\int \tan(t)dt}$ would be equal to $e^{\ln |\cos t|} = |\cos t|$. However, my math textbook and Wolfram Alpha both say that $e^{-\int \tan(t)dt}=e^{\ln (\cos t)} = \cos t$. Why can the absolute value be ignored when taking the indefinite integral in this case? Context: Finding an integrating factor for $x' = x\tan(t) + \sin(t)$. But Wolfram Alpha also gave me this answer without any differential equations context.",,"['calculus', 'integration', 'ordinary-differential-equations']"
94,deriving the formula of the torsion of a curve,deriving the formula of the torsion of a curve,,"in our class we defined the torsion $τ(s)$ of a curve $γ$ parameterized by arc length this way  $τ(s) = B'(s) \cdot N(s) $ where $B(s)$ is the binormal vector and $N(s)$ the normal vector in many other pdf's and books it's defined this way ($τ(s) =  -B'(s) \cdot N(s)$) but let's stick to the first definiton. we were given in our class other formulas to compute the torsion : $$τ(s) = -\frac{\det(γ'(s),γ''(s),γ'''(s))}{||γ''(s)||^2} $$ $$τ(t) = -\frac{\det(γ'(t),γ''(t),γ'''(t))}{||γ'(t)\timesγ''(s)||^2}$$ ok the first one is used when the curve is parameterized by arc length and the second one can be used to compute the torsion of any regular curve $γ$ whether $||γ'|| = 1$ or not I tried proving them both and i think I've been able to prove the first one : $$\begin{align} τ(s) = B'(s) \cdot N(s) = (T(s)\times N(s))' \times N(s) =(T'(s) \times N(s) + T(s) \times N'(s)) \cdot N(s)\end{align}$$ since the curve is parameterized by arc length $T'(s) = N(s)$ so $T'(s) \times N(s) =0$ $$\begin{align} τ(s) =( T(s) \times N'(s)) \cdot N(s)=\det( T(s) , N'(s),N(s)) \end{align}$$ $$\begin{align} =-\det( T(s) , N(s),N'(s)) =-\det(γ'(s),\frac{γ''(s)}{||γ''(s)||},\frac{γ'''(s)}{||γ''(s)||}) = -\frac{\det(γ'(s),γ''(s),γ'''(s))}{||γ''(s)||^2}\end{align}$$ check this proof and tell me If I proved it right for the second one I tried replacing $γ'(s)$ by $γ(s^{-1}(t))'$ where $s(t) = \int_0^t ||γ'(u)||du$ did the same thing for $γ'(s)$ and $γ''(s)$ applied the chain rule but got stuck any help or hints concerning the second formula would be appreciated. Thank you !","in our class we defined the torsion $τ(s)$ of a curve $γ$ parameterized by arc length this way  $τ(s) = B'(s) \cdot N(s) $ where $B(s)$ is the binormal vector and $N(s)$ the normal vector in many other pdf's and books it's defined this way ($τ(s) =  -B'(s) \cdot N(s)$) but let's stick to the first definiton. we were given in our class other formulas to compute the torsion : $$τ(s) = -\frac{\det(γ'(s),γ''(s),γ'''(s))}{||γ''(s)||^2} $$ $$τ(t) = -\frac{\det(γ'(t),γ''(t),γ'''(t))}{||γ'(t)\timesγ''(s)||^2}$$ ok the first one is used when the curve is parameterized by arc length and the second one can be used to compute the torsion of any regular curve $γ$ whether $||γ'|| = 1$ or not I tried proving them both and i think I've been able to prove the first one : $$\begin{align} τ(s) = B'(s) \cdot N(s) = (T(s)\times N(s))' \times N(s) =(T'(s) \times N(s) + T(s) \times N'(s)) \cdot N(s)\end{align}$$ since the curve is parameterized by arc length $T'(s) = N(s)$ so $T'(s) \times N(s) =0$ $$\begin{align} τ(s) =( T(s) \times N'(s)) \cdot N(s)=\det( T(s) , N'(s),N(s)) \end{align}$$ $$\begin{align} =-\det( T(s) , N(s),N'(s)) =-\det(γ'(s),\frac{γ''(s)}{||γ''(s)||},\frac{γ'''(s)}{||γ''(s)||}) = -\frac{\det(γ'(s),γ''(s),γ'''(s))}{||γ''(s)||^2}\end{align}$$ check this proof and tell me If I proved it right for the second one I tried replacing $γ'(s)$ by $γ(s^{-1}(t))'$ where $s(t) = \int_0^t ||γ'(u)||du$ did the same thing for $γ'(s)$ and $γ''(s)$ applied the chain rule but got stuck any help or hints concerning the second formula would be appreciated. Thank you !",,"['calculus', 'geometry', 'curves']"
95,Calculating $\int \sqrt{1 + x^{-2}}dx$,Calculating,\int \sqrt{1 + x^{-2}}dx,I would like to find $$\int \sqrt{1 + x^{-2}}dx$$ I have found that it is equivalent to $$ \int \frac{\sqrt{1 + x^2}}{x}dx $$ but I am not sure what to do about it. With trig substitution $x = \tan(x)$ I get $$ \int \frac{1}{\sin(\theta)\cos^2(\theta)}d\theta $$ but that seems to be a dead end.,I would like to find $$\int \sqrt{1 + x^{-2}}dx$$ I have found that it is equivalent to $$ \int \frac{\sqrt{1 + x^2}}{x}dx $$ but I am not sure what to do about it. With trig substitution $x = \tan(x)$ I get $$ \int \frac{1}{\sin(\theta)\cos^2(\theta)}d\theta $$ but that seems to be a dead end.,,"['calculus', 'integration', 'trigonometric-integrals']"
96,Intuitive Proof of the Chain Rule in 1 Variable,Intuitive Proof of the Chain Rule in 1 Variable,,"Is there a simple and intuitive way to prove the chain rule, that is, if $y$ is a function of $u$ and $u$ is a function of $x$, then why is $\frac{dy}{dx}$ = $\frac{dy}{du}$ $\cdot$ $\frac{du}{dx}$ ? This could just be an intuitive argument. PS: The only proofs I found were based off of confusing definitions.","Is there a simple and intuitive way to prove the chain rule, that is, if $y$ is a function of $u$ and $u$ is a function of $x$, then why is $\frac{dy}{dx}$ = $\frac{dy}{du}$ $\cdot$ $\frac{du}{dx}$ ? This could just be an intuitive argument. PS: The only proofs I found were based off of confusing definitions.",,"['calculus', 'intuition']"
97,$n$-derivative of function $f(x)=e^x \sin x$ at $x=0$,-derivative of function  at,n f(x)=e^x \sin x x=0,I have function $f(x) = e^x \sin{x}$ and must found $f^{(n)}(0)$ $f'(x) = e^x(\sin{x} + \cos{x}) $ $f''(x) = 2 e^x \cos{x}$ $f'''(x) = 2 e^x (\cos{x} - \sin{x})$ $f''''(x) = -4 e^x \sin{x}$ $f'''''(x) = -4 e^x (\sin{x} + \cos{x})$ I think $f^{(n)}(0) = \alpha (-1)^n x^{2n+1}$ but I can't find $\alpha$,I have function and must found I think but I can't find,f(x) = e^x \sin{x} f^{(n)}(0) f'(x) = e^x(\sin{x} + \cos{x})  f''(x) = 2 e^x \cos{x} f'''(x) = 2 e^x (\cos{x} - \sin{x}) f''''(x) = -4 e^x \sin{x} f'''''(x) = -4 e^x (\sin{x} + \cos{x}) f^{(n)}(0) = \alpha (-1)^n x^{2n+1} \alpha,"['calculus', 'derivatives', 'taylor-expansion']"
98,Integrate $I=\int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx$,Integrate,I=\int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx,"How to prove  \begin{align}  I &= \int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx \\    &= \frac{\pi}{256}\left[ \frac{11\pi^4}{120}+2{\pi^2}\ln^2{2}-2\ln^4{2}-12\zeta{(3)}\ln{2} \right] \end{align}  By asking  $$x=\sqrt{2}y$$ then using integration by parts, we have  $$I=\frac{\pi^5}{2048}-\frac{1}{4}\int_0^1{\arcsin^4\left( \frac{z}{\sqrt{2}}\right) }\frac{dz}{\sqrt{1-x^2}}$$ But how to calculate this integral? I would appreciate your help","How to prove  \begin{align}  I &= \int_0^1\frac{\arcsin{(x)}\arcsin{(x\sqrt\frac{1}{2})}}{\sqrt{2-x^2}}dx \\    &= \frac{\pi}{256}\left[ \frac{11\pi^4}{120}+2{\pi^2}\ln^2{2}-2\ln^4{2}-12\zeta{(3)}\ln{2} \right] \end{align}  By asking  $$x=\sqrt{2}y$$ then using integration by parts, we have  $$I=\frac{\pi^5}{2048}-\frac{1}{4}\int_0^1{\arcsin^4\left( \frac{z}{\sqrt{2}}\right) }\frac{dz}{\sqrt{1-x^2}}$$ But how to calculate this integral? I would appreciate your help",,"['calculus', 'integration', 'definite-integrals']"
99,"Number of all positive continuous function $f(x)$ in $\left[0,1\right]$",Number of all positive continuous function  in,"f(x) \left[0,1\right]","Number of all positive continuous function $f(x)$ in $\left[0,1\right]$ which satisfy $\displaystyle \int^{1}_{0}f(x)dx=1$ and $\displaystyle \int^{1}_{0}xf(x)dx=\alpha$ and $\displaystyle \int^{1}_{0}x^2f(x)dx=\alpha^2$ Where $\alpha$ is a given real numbers. $\bf{My\; Try::}$ :: Adding $(1)$ and $(3)$ and subtracting $2\times  (2),$ we. Get $$\displaystyle \int^{1}_{0}(x-1)^2f(x)dx=(\alpha-1)^2$$ now how can I solve it after that, Thanks","Number of all positive continuous function in which satisfy and and Where is a given real numbers. :: Adding and and subtracting we. Get now how can I solve it after that, Thanks","f(x) \left[0,1\right] \displaystyle \int^{1}_{0}f(x)dx=1 \displaystyle \int^{1}_{0}xf(x)dx=\alpha \displaystyle \int^{1}_{0}x^2f(x)dx=\alpha^2 \alpha \bf{My\; Try::} (1) (3) 2\times  (2), \displaystyle \int^{1}_{0}(x-1)^2f(x)dx=(\alpha-1)^2",['calculus']
