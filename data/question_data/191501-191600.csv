,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why should we convert degree to radian while differentiating? [duplicate],Why should we convert degree to radian while differentiating? [duplicate],,"This question already has answers here : Why does the derivative of sine only work for radians? (17 answers) Closed 7 years ago . While graphing the sine function, it is always assumed that x is in radians.Similarly while differentiating the sinx function x is always in radians and we have to multiply by a constant if x is given to us in degrees, before differentiating. Is radian just a convention for trigonometric functions or is there some other reason?Why are we able to differentiate a function directly when x is in radians and not when it is in degrees?","This question already has answers here : Why does the derivative of sine only work for radians? (17 answers) Closed 7 years ago . While graphing the sine function, it is always assumed that x is in radians.Similarly while differentiating the sinx function x is always in radians and we have to multiply by a constant if x is given to us in degrees, before differentiating. Is radian just a convention for trigonometric functions or is there some other reason?Why are we able to differentiate a function directly when x is in radians and not when it is in degrees?",,"['trigonometry', 'derivatives', 'angle']"
1,Find derivative of Taylor series,Find derivative of Taylor series,,"How would one differentiate a function in this form? $$f(x) = f(a)+{\frac {f'(a)}{1!}}(x-a)+{\frac {f''(a)}{2!}}(x-a)^{2}+{\frac {f'''(a)}{3!}}(x-a)^{3}$$ I'm sorry if this is something obvious, I'm not great with maths. I tried searching for the answer with no luck.","How would one differentiate a function in this form? $$f(x) = f(a)+{\frac {f'(a)}{1!}}(x-a)+{\frac {f''(a)}{2!}}(x-a)^{2}+{\frac {f'''(a)}{3!}}(x-a)^{3}$$ I'm sorry if this is something obvious, I'm not great with maths. I tried searching for the answer with no luck.",,"['derivatives', 'taylor-expansion']"
2,Prove $\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}}$,Prove,\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}},"Let $f:[a,b]\rightarrow \mathbb{R}$ be a positive and differentiable function. Prove: $$\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}}$$ I tried to apply the MVT and make some algebraic manipulations, but got stuck. Any help appreciated.","Let $f:[a,b]\rightarrow \mathbb{R}$ be a positive and differentiable function. Prove: $$\frac{f(b)}{f(a)}=e^{(b-a)\frac{f'(c)}{f(c)}}$$ I tried to apply the MVT and make some algebraic manipulations, but got stuck. Any help appreciated.",,"['calculus', 'derivatives']"
3,Partial Derivatives of Polar Coordinates,Partial Derivatives of Polar Coordinates,,"I'm asked to show the following four derivatives from the polar coordinate conversions.  ($x = r\cos \theta$, $y=r\sin \theta$, and $r^2=x^2+y^2$) $$ \frac{\partial r}{\partial x} = \cos \theta \ , \ \frac{\partial r}{\partial y} = \sin\theta \ , \ \frac{\partial \theta}{\partial x} = \frac{-\sin \theta}{r} \ , \frac{\partial \theta}{\partial y} = \frac{\cos \theta}{r}$$ I've shown the fist two relatively easy, but I'm not sure how to show $$\frac{\partial \theta}{\partial x} = \frac{-\sin \theta}{r} \ , \frac{\partial \theta}{\partial y} = \frac{\cos \theta}{r}$$ I know how to do this for $$\frac{\partial x}{\partial \theta} \ \ \text{and} \ \ \frac{\partial y}{\partial \theta}$$ Any help would be appreciated, thank you.","I'm asked to show the following four derivatives from the polar coordinate conversions.  ($x = r\cos \theta$, $y=r\sin \theta$, and $r^2=x^2+y^2$) $$ \frac{\partial r}{\partial x} = \cos \theta \ , \ \frac{\partial r}{\partial y} = \sin\theta \ , \ \frac{\partial \theta}{\partial x} = \frac{-\sin \theta}{r} \ , \frac{\partial \theta}{\partial y} = \frac{\cos \theta}{r}$$ I've shown the fist two relatively easy, but I'm not sure how to show $$\frac{\partial \theta}{\partial x} = \frac{-\sin \theta}{r} \ , \frac{\partial \theta}{\partial y} = \frac{\cos \theta}{r}$$ I know how to do this for $$\frac{\partial x}{\partial \theta} \ \ \text{and} \ \ \frac{\partial y}{\partial \theta}$$ Any help would be appreciated, thank you.",,"['derivatives', 'partial-derivative', 'polar-coordinates']"
4,"Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points.","Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points.",,"Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points. From what I have seen, the only case in which I have found a tangent line at 2 points is when the tangent line is horizontal. Is there any other way to approach it?","Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points. From what I have seen, the only case in which I have found a tangent line at 2 points is when the tangent line is horizontal. Is there any other way to approach it?",,"['calculus', 'derivatives']"
5,Prove $\frac{d^2y}{dx^2}=-\frac{\frac{d^2x}{dy^2}}{(\frac{dx}{dy})^3}$,Prove,\frac{d^2y}{dx^2}=-\frac{\frac{d^2x}{dy^2}}{(\frac{dx}{dy})^3},"Prove $$\dfrac{d^2y}{dx^2}=-\dfrac{\dfrac{d^2x}{dy^2}}{\left(\dfrac{dx}{dy}\right)^3}$$ Tried $$\dfrac{dy}{dx}=\dfrac{1}{\dfrac{dx}{dy}}$$ So $$\dfrac{d^2y}{dx^2}=\dfrac{d}{dx}\left(\dfrac{dy}{dx}\right)=\dfrac{-\dfrac{d}{dx}\left(\dfrac{dx}{dy}\right)}{\left(\dfrac{dx}{dy}\right)^2}$$ But cannot go any further, any help? Thanks~","Prove $$\dfrac{d^2y}{dx^2}=-\dfrac{\dfrac{d^2x}{dy^2}}{\left(\dfrac{dx}{dy}\right)^3}$$ Tried $$\dfrac{dy}{dx}=\dfrac{1}{\dfrac{dx}{dy}}$$ So $$\dfrac{d^2y}{dx^2}=\dfrac{d}{dx}\left(\dfrac{dy}{dx}\right)=\dfrac{-\dfrac{d}{dx}\left(\dfrac{dx}{dy}\right)}{\left(\dfrac{dx}{dy}\right)^2}$$ But cannot go any further, any help? Thanks~",,['derivatives']
6,Derivative of Hadamard product with kernels,Derivative of Hadamard product with kernels,,"I want to calculate $$ \frac{\partial(A \circ X^\top X)}{\partial(X)}, $$ where $ \circ $ is Hadamard product (elementwise product), $X \in R^{r \times n}$, $A \in R^{n \times n}$, and $\frac{\partial A}{\partial X}=0$. So far, I found that $$ \frac{\partial(A \circ B)}{\partial(C)} = \frac{\partial(A)}{\partial(C)} \circ B + A \circ \frac{\partial(B)}{\partial(C)},$$ from here ( generic rule matrix differentiation (Hadamard Product, element-wise) ) In my case, $B=X^\top X$ and $C=X$. Therefore, $$ \frac{\partial(A \circ X^\top X)}{\partial(X)} = A \circ 2X^\top .$$ However, $A\in R^{n\times n}$ and $X^\top \in R^{n \times r}$. Therefore, I can't do the Hadamard product. How can I do this?","I want to calculate $$ \frac{\partial(A \circ X^\top X)}{\partial(X)}, $$ where $ \circ $ is Hadamard product (elementwise product), $X \in R^{r \times n}$, $A \in R^{n \times n}$, and $\frac{\partial A}{\partial X}=0$. So far, I found that $$ \frac{\partial(A \circ B)}{\partial(C)} = \frac{\partial(A)}{\partial(C)} \circ B + A \circ \frac{\partial(B)}{\partial(C)},$$ from here ( generic rule matrix differentiation (Hadamard Product, element-wise) ) In my case, $B=X^\top X$ and $C=X$. Therefore, $$ \frac{\partial(A \circ X^\top X)}{\partial(X)} = A \circ 2X^\top .$$ However, $A\in R^{n\times n}$ and $X^\top \in R^{n \times r}$. Therefore, I can't do the Hadamard product. How can I do this?",,"['derivatives', 'hadamard-product']"
7,When do differential operators commute?,When do differential operators commute?,,"Given that the equation of motion of a particle placed on the apex of Norton's Dome is $$\frac{d^2 r}{dt^2}=r^{1/2}\qquad\longleftarrow\text{as proved in this previous question}\tag{1}$$ Solve this non-linear equation by multiplying both sides by $$2\frac{dr}{dt}$$ and integrating to find that $$r(t)=\frac{\left(t-T\right)^4}{144}$$ for any $T\ge 0$. Pre-multiplying both sides of $(1)$ by $$2\frac{dr}{dt}$$ gives $$2\color{red}{\frac{dr}{dt}}\color{blue}{\left(\frac{d^2r}{dt^2}\right)}=2\frac{dr}{dt}r^{1/2}\tag{2}$$ Rewriting $(2)$ $\bbox[yellow]{\text{with the order of the red and blue factors switched}}$ gives: $$2\color{blue}{\frac{d^2r}{dt^2}}\color{red}{\left(\frac{dr}{dt}\right)}=2\frac{dr}{dt}r^{1/2}\tag{3}$$ The reason for the switch is because the blue factor in $(3)$ is the derivative of the red factor (I had to write it this way in order to integrate by inspection). Integrating both sides gives $$\left(\frac{dr}{dt}\right)^2=\frac{4}{3}r^{3/2}+C\tag{4}$$ In obtaining $(4)$ from $(3)$ I used the chain rule on the RHS, namely $$\frac{d}{dt}=\frac{d}{dr}\cdot\frac{dr}{dt}$$ Finally, my question is all about the validity of the sentence highlighted in yellow. I am aware that differential operators do not commute in general. So is it plausible for me to simply switch the order of the red and blue factors as I did in getting from $(2)$ to $(3)$? Many thanks.","Given that the equation of motion of a particle placed on the apex of Norton's Dome is $$\frac{d^2 r}{dt^2}=r^{1/2}\qquad\longleftarrow\text{as proved in this previous question}\tag{1}$$ Solve this non-linear equation by multiplying both sides by $$2\frac{dr}{dt}$$ and integrating to find that $$r(t)=\frac{\left(t-T\right)^4}{144}$$ for any $T\ge 0$. Pre-multiplying both sides of $(1)$ by $$2\frac{dr}{dt}$$ gives $$2\color{red}{\frac{dr}{dt}}\color{blue}{\left(\frac{d^2r}{dt^2}\right)}=2\frac{dr}{dt}r^{1/2}\tag{2}$$ Rewriting $(2)$ $\bbox[yellow]{\text{with the order of the red and blue factors switched}}$ gives: $$2\color{blue}{\frac{d^2r}{dt^2}}\color{red}{\left(\frac{dr}{dt}\right)}=2\frac{dr}{dt}r^{1/2}\tag{3}$$ The reason for the switch is because the blue factor in $(3)$ is the derivative of the red factor (I had to write it this way in order to integrate by inspection). Integrating both sides gives $$\left(\frac{dr}{dt}\right)^2=\frac{4}{3}r^{3/2}+C\tag{4}$$ In obtaining $(4)$ from $(3)$ I used the chain rule on the RHS, namely $$\frac{d}{dt}=\frac{d}{dr}\cdot\frac{dr}{dt}$$ Finally, my question is all about the validity of the sentence highlighted in yellow. I am aware that differential operators do not commute in general. So is it plausible for me to simply switch the order of the red and blue factors as I did in getting from $(2)$ to $(3)$? Many thanks.",,"['derivatives', 'proof-explanation', 'classical-mechanics']"
8,Prove the identity $\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2$ when $p+q = 1$,Prove the identity  when,\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2 p+q = 1,"If $p+q=1$, then show that $$\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2.$$ I was able to solve this by differentiating the expression twice and then relating the given variables. But the method turned out to be pretty tedious, moreover it took me a while to figure it out. Is there any method I can employ to solve this?","If $p+q=1$, then show that $$\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2.$$ I was able to solve this by differentiating the expression twice and then relating the given variables. But the method turned out to be pretty tedious, moreover it took me a while to figure it out. Is there any method I can employ to solve this?",,"['combinatorics', 'derivatives', 'summation']"
9,Differentiation Calculus: $\tan^{-1} \text{Problem}$,Differentiation Calculus:,\tan^{-1} \text{Problem},"Well, Today at Math Revision exam I have to answer for $\frac{dy}{dx}$ Question:$$ y= \arctan\frac{{2x}}{{1+x^2}}$$ I got the answer $$ \frac{2}{1+(\frac{2x}{1+x})^2}\frac{cos(2\tan^{-1}x)}{1+x^2}$$ i think this not correct. I have to know the right solution with steps.","Well, Today at Math Revision exam I have to answer for $\frac{dy}{dx}$ Question:$$ y= \arctan\frac{{2x}}{{1+x^2}}$$ I got the answer $$ \frac{2}{1+(\frac{2x}{1+x})^2}\frac{cos(2\tan^{-1}x)}{1+x^2}$$ i think this not correct. I have to know the right solution with steps.",,"['calculus', 'real-analysis', 'derivatives']"
10,Frechet derivative for bilinear map,Frechet derivative for bilinear map,,"Let $\mathbb{X}, \mathbb{Y}$ and $\mathbb{Z}$ be normed spaces and let $f$ be a bounded bilinear map. Show that $f$ is Frechet differentiable at every $(x,y) \in \mathbb{X} \times \mathbb{Y}$ and find its Frechet derivative. (View f as a map $\mathbb{X} \times \mathbb{Y} \rightarrow \mathbb{Z}$). What I have tried: I think the derivative is the function itself but I'm not sure how to set it out formally. I know how to do it for single normed spaces but I am confused with the bilinear map stuff.","Let $\mathbb{X}, \mathbb{Y}$ and $\mathbb{Z}$ be normed spaces and let $f$ be a bounded bilinear map. Show that $f$ is Frechet differentiable at every $(x,y) \in \mathbb{X} \times \mathbb{Y}$ and find its Frechet derivative. (View f as a map $\mathbb{X} \times \mathbb{Y} \rightarrow \mathbb{Z}$). What I have tried: I think the derivative is the function itself but I'm not sure how to set it out formally. I know how to do it for single normed spaces but I am confused with the bilinear map stuff.",,"['derivatives', 'frechet-derivative']"
11,Population dynamics,Population dynamics,,I don't understand why we make the three assumptions underlined above.,I don't understand why we make the three assumptions underlined above.,,"['derivatives', 'continuity', 'dynamical-systems']"
12,Why can't $\sin(1/x)$ be differentiated?,Why can't  be differentiated?,\sin(1/x),"I've read in textbooks that $\sin(\frac 1x)$ can't be differentiated because it oscillates too rapidly, but so what? Why does oscillation stop it from being differentiated?","I've read in textbooks that can't be differentiated because it oscillates too rapidly, but so what? Why does oscillation stop it from being differentiated?",\sin(\frac 1x),"['calculus', 'derivatives', 'trigonometry']"
13,What is actual result of derivative?,What is actual result of derivative?,,"I'm pretty new to derivatives and I'm not sure if I understand the concept well. Let's say we have function $f(x) = x^2$.If we set $x=3$, our example point is set at coordinates $(3,9)$.Using formula we can find derivative of $f(x)$:  $f'(x)=6$. My question is: what does this number $6$ mean? From what I've read, it should be slope of the chosen point. Is the slope defined by one number? What is actual use of such slope? Thanks!","I'm pretty new to derivatives and I'm not sure if I understand the concept well. Let's say we have function $f(x) = x^2$.If we set $x=3$, our example point is set at coordinates $(3,9)$.Using formula we can find derivative of $f(x)$:  $f'(x)=6$. My question is: what does this number $6$ mean? From what I've read, it should be slope of the chosen point. Is the slope defined by one number? What is actual use of such slope? Thanks!",,"['calculus', 'derivatives']"
14,What rule can I use to compute $\frac{d^{107}}{dx^{107}} \sin x$?,What rule can I use to compute ?,\frac{d^{107}}{dx^{107}} \sin x,Did I miss something in my calculus class? I don't remember anything concerning this type of problem: Compute $$\frac{d^{107}}{dx^{107}} \sin x.$$ So what is the rule here?,Did I miss something in my calculus class? I don't remember anything concerning this type of problem: Compute $$\frac{d^{107}}{dx^{107}} \sin x.$$ So what is the rule here?,,"['calculus', 'derivatives']"
15,Can we take out a constant while differentiating?,Can we take out a constant while differentiating?,,"In the solved example above, rather than taking $a^2x^4$ together and differentiating $a^2 = 0$, we differentiated $x^4$ and took out $a^2$. Why? Couldn't we have differentiated $a^2$ and gotten the answer zero?","In the solved example above, rather than taking $a^2x^4$ together and differentiating $a^2 = 0$, we differentiated $x^4$ and took out $a^2$. Why? Couldn't we have differentiated $a^2$ and gotten the answer zero?",,"['calculus', 'derivatives']"
16,Am I using the chain rule correctly?,Am I using the chain rule correctly?,,"I'm supposed to find $y'$ and $y''$ of this function: $$y=e^{\alpha x} \sin\beta x$$ This is what I have done so far: $$y'=e^{\alpha x}\sin\beta x\cdot \alpha x'\sin\beta x\cdot \sin'\beta x \cdot \beta x$$ $$y'=e^{\alpha x}\sin\beta x\cdot \alpha \sin\beta x\cdot \cos\beta x \cdot \beta$$ I tried to find $y''$, but my answer was really messy so I must not have done the first derivative correctly. What have I done wrong?","I'm supposed to find $y'$ and $y''$ of this function: $$y=e^{\alpha x} \sin\beta x$$ This is what I have done so far: $$y'=e^{\alpha x}\sin\beta x\cdot \alpha x'\sin\beta x\cdot \sin'\beta x \cdot \beta x$$ $$y'=e^{\alpha x}\sin\beta x\cdot \alpha \sin\beta x\cdot \cos\beta x \cdot \beta$$ I tried to find $y''$, but my answer was really messy so I must not have done the first derivative correctly. What have I done wrong?",,"['calculus', 'derivatives']"
17,Derivative of$ \sqrt{x^2}$,Derivative of, \sqrt{x^2},"I found the Derivative of $\sqrt{x^2}$ to be  1 using simplifications and the power rule, but when I checked the answer, it was in fact $=\frac{x}{\left|x\right|}$ and not $=1$. What could have been wong with my approach? $f(x)=(x^2)^{1/2}=x^{2/2}=x \\f'(x)=1$","I found the Derivative of $\sqrt{x^2}$ to be  1 using simplifications and the power rule, but when I checked the answer, it was in fact $=\frac{x}{\left|x\right|}$ and not $=1$. What could have been wong with my approach? $f(x)=(x^2)^{1/2}=x^{2/2}=x \\f'(x)=1$",,"['calculus', 'derivatives']"
18,Differentiating both sides of an inequality with monotonic functions,Differentiating both sides of an inequality with monotonic functions,,"If $f(x)\le g(x)$ for all real $x$ for monotonic functions $f$ and $g$ (say, both increasing), does it follow that $f'(x)\le g'(x)$? (Note: I've seen several questions asking the same thing without the condition of monotonicity, but the counterexamples given always involve a non-monotonic function, and it seems to me that this condition might be sufficient; I haven't been able to come up with any counterexamples myself.) If not, is the stronger condition that $f^{(n)}(x)$ and $g^{(n)}(x)$ are monotone for either all natural $n$ or all $n\le N$ for some $N$ sufficient?","If $f(x)\le g(x)$ for all real $x$ for monotonic functions $f$ and $g$ (say, both increasing), does it follow that $f'(x)\le g'(x)$? (Note: I've seen several questions asking the same thing without the condition of monotonicity, but the counterexamples given always involve a non-monotonic function, and it seems to me that this condition might be sufficient; I haven't been able to come up with any counterexamples myself.) If not, is the stronger condition that $f^{(n)}(x)$ and $g^{(n)}(x)$ are monotone for either all natural $n$ or all $n\le N$ for some $N$ sufficient?",,"['calculus', 'inequality', 'derivatives']"
19,How to simplify $y = \frac{\sin\rho + \sin2\rho}{\cos\rho + \cos2\rho}$,How to simplify,y = \frac{\sin\rho + \sin2\rho}{\cos\rho + \cos2\rho},"How can I simplify this function before I differentiate it? $$y = \frac{\sin\rho + \sin2\rho}{\cos\rho + \cos2\rho}$$ Of course you could immediately start off by using the quotient rule, but that gives a very long and convoluted expression which takes forever to simplify. I know that one of the possible simplifications of the function pre-differentiation is $$y = \tan\frac{3p}{2}$$ However I do not know how this is done. If anyone could shed some light on this or show steps for an equally simple simplification of the original function, this would be much appreciated.","How can I simplify this function before I differentiate it? $$y = \frac{\sin\rho + \sin2\rho}{\cos\rho + \cos2\rho}$$ Of course you could immediately start off by using the quotient rule, but that gives a very long and convoluted expression which takes forever to simplify. I know that one of the possible simplifications of the function pre-differentiation is $$y = \tan\frac{3p}{2}$$ However I do not know how this is done. If anyone could shed some light on this or show steps for an equally simple simplification of the original function, this would be much appreciated.",,"['calculus', 'trigonometry', 'derivatives']"
20,is $f\left(x\right)\:=\:\left|x\right|^3$ twice differentiable?,is  twice differentiable?,f\left(x\right)\:=\:\left|x\right|^3,"Consider the function $f\left(x\right)\:=\:\left|x\right|^3$ , $f:\mathbb{R}\rightarrow \mathbb{R}$. 1) Is it twice differentiable? And if so, how can I prove this and calculate it? 2) If it does, can I conclude it has third differentiable for every $x$? So far, for 1, I believe is true but I really stuck in the proof: $$\lim _{h\to 0}\left(\frac{f\left(x+h\right)-f\left(x\right)}{h}\right)\:=\:\lim _{h\to 0}\left(\frac{\left|x+h\right|^3-\left|x\right|^3}{h}\right)\:=\:\lim_{h\to 0}\left(\frac{\left(\left|x+h\right|^{\:}-\left|x\right|\right)\left(\left|x+h\right|^2\cdot \left|x+h\right|\left|x\right|+\left|x\right|^2\right)}{h}\right)\:$$ But how to continue from here? I also tried this approach:  $$\lim _{x\to x_0}\left(\frac{f\left(x\right)-f\left(x_0\right)}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left|x\right|^3-\left|x_0\right|^3}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left(\left|x\right|^{\:}-\left|x_0\right|\right)\left(\left|x\right|^2+\left|x\right|\left|x_0\right|+\left|x_0\right|^2\right)}{x-x_0}\right)\:\:$$ I have serious problem with the next step. Can someone guide me what tricks I need to do? Thanks in advance!","Consider the function $f\left(x\right)\:=\:\left|x\right|^3$ , $f:\mathbb{R}\rightarrow \mathbb{R}$. 1) Is it twice differentiable? And if so, how can I prove this and calculate it? 2) If it does, can I conclude it has third differentiable for every $x$? So far, for 1, I believe is true but I really stuck in the proof: $$\lim _{h\to 0}\left(\frac{f\left(x+h\right)-f\left(x\right)}{h}\right)\:=\:\lim _{h\to 0}\left(\frac{\left|x+h\right|^3-\left|x\right|^3}{h}\right)\:=\:\lim_{h\to 0}\left(\frac{\left(\left|x+h\right|^{\:}-\left|x\right|\right)\left(\left|x+h\right|^2\cdot \left|x+h\right|\left|x\right|+\left|x\right|^2\right)}{h}\right)\:$$ But how to continue from here? I also tried this approach:  $$\lim _{x\to x_0}\left(\frac{f\left(x\right)-f\left(x_0\right)}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left|x\right|^3-\left|x_0\right|^3}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left(\left|x\right|^{\:}-\left|x_0\right|\right)\left(\left|x\right|^2+\left|x\right|\left|x_0\right|+\left|x_0\right|^2\right)}{x-x_0}\right)\:\:$$ I have serious problem with the next step. Can someone guide me what tricks I need to do? Thanks in advance!",,"['calculus', 'derivatives']"
21,Surjective differentiable function from R to R²,Surjective differentiable function from R to R²,,"How can I prove there is no function $f: \mathbb{R} \rightarrow \mathbb{R}²$ of class $C¹$ that is surjective? This is an exercise from Analysis on Manifolds, from Munkres. The exercise gives a hint that is: $f(\mathbb{R})$ does not contain an open subset from $\mathbb{R}²$.","How can I prove there is no function $f: \mathbb{R} \rightarrow \mathbb{R}²$ of class $C¹$ that is surjective? This is an exercise from Analysis on Manifolds, from Munkres. The exercise gives a hint that is: $f(\mathbb{R})$ does not contain an open subset from $\mathbb{R}²$.",,"['real-analysis', 'derivatives']"
22,Derivative of mutual information,Derivative of mutual information,,"Here is the definition of mutual information $$I(X;Y) = \int_Y \int_X p(x,y) \log{ \left(\frac{p(x,y)}{p(x)\,p(y)} \right) } \, \mathrm d x \, \mathrm d y$$ where $X$ and $Y$ are two random variables, $p(x)$ and $p(y)$ are their PDFs, and $p(x,y)$ is the joint PDF. I am wondering what is the derivative of $I(x;y)$ with respect to $X$, or $Y$? Namely, $$\frac{\mathrm d}{\mathrm dX} I(X;Y) = \, ?$$ $$\frac{\mathrm d}{\mathrm dY} I(X;Y) = \, ?$$ Thanks.","Here is the definition of mutual information $$I(X;Y) = \int_Y \int_X p(x,y) \log{ \left(\frac{p(x,y)}{p(x)\,p(y)} \right) } \, \mathrm d x \, \mathrm d y$$ where $X$ and $Y$ are two random variables, $p(x)$ and $p(y)$ are their PDFs, and $p(x,y)$ is the joint PDF. I am wondering what is the derivative of $I(x;y)$ with respect to $X$, or $Y$? Namely, $$\frac{\mathrm d}{\mathrm dX} I(X;Y) = \, ?$$ $$\frac{\mathrm d}{\mathrm dY} I(X;Y) = \, ?$$ Thanks.",,"['calculus', 'derivatives', 'calculus-of-variations', 'information-theory']"
23,Derivative conundrum...,Derivative conundrum...,,"I've spent almost 6 total hours hacking at this problem. And I always end up by a factor of 3 in one of the terms when checked against Wolfram's derivative calculator, which is correct when I manually calculate the derivative directly from the source equation in excel. I'd love to have someone show me where I'm making my error. Here we go... y = 3t(5t + 4)^5  ln(y) = ln(3t(5t + 4)^5)  ln(y) = 5*ln(3t(5t + 4))  d/dt(ln(y)) = d/dt(5*ln(3t(5t + 4)))  d/dt(ln(y)) = d/dt(5)*d/dt(ln(3t(5t + 4)))  d/dt(ln(y)) = d/dt(ln(3t(5t + 4)))  d/dt(ln(y)) = 1/(3t(5t + 4)) *d/dt(3t(5t + 4))  d/dt(ln(y))*(3t(5t + 4)) = d/dt(3t(5t + 4))  d/dt(ln(y))*(3t(5t + 4)) = d/dt(15t^2 + 12t)  d/dt(ln(y))*(3t(5t + 4)) = d/dt(15t^2) + d/dt(12t)  d/dt(ln(y))*(3t(5t + 4)) = 15*d/dt(t^2) + 12*dt/dt(t)  d/dt(ln(y))*(3t(5t + 4)) = 15*d/dt(t^2) + 12  d/dt(ln(y))*(3t(5t + 4)) = 15*2t*dt/dt + 12  d/dt(ln(y))*(3t(5t + 4)) = 15*2t + 12  d/dt(ln(y))*(3t(5t + 4)) = 30t + 12  d/dt(ln(y)) = (30t + 12)/(3t(5t + 4))  1/y*d/dt = (30t + 12)/(3t(5t + 4))  d/dt = y*(30t + 12)/(3t(5t + 4))  d/dt = 3t(5t + 4)^5 *(30t + 12)/(3t(5t + 4))  d/dt = (5t + 4)^4 *(30t + 12)  d/dt = [6(5t + 4)^4 *(5t + 2)] Wolfram: d/dt = 6(5t + 4)^4 *(15t + 2) Amended approach as per nbubis: The log method was presented as an easy way to handle complex exponents. So I adopted it for all exponent handling. y = 3t(5t + 4)^5  d/dt(y) = d/dt(3t(5t + 4)^5)  F(t) = f(t)*g(h(t))  f(t) = 3t  f'(t) = 3  g(t) = (t)^5  g'(t) = 5(t)^4  h(t) = 5t + 4  h'(t) = 5  F'(t) = f'(t)*g(h(t)) + f(t)*g'(h(t))  F'(t) = f'(t)*g(h(t)) + f(t)*g'(h(t))*h'(t)  F'(t) = 3*(5t + 4)^5 + 3t*5(5t + 4)^4*5  F'(t) = 3*(5t + 4)^5 + 75t(5t + 4)^4 How did you remove ^5? Duh, common factor!!! F'(t) = (3*(5t + 4) + 75t)(5t + 4)^4  F'(t) = 3(5t + 4 + 25t)(5t + 4)^4  F'(t) = 3(30t + 4)(5t + 4)^4  F'(t) = 3*2(15t + 2)(5t + 4)^4  F'(t) = [6(15t + 2)(5t + 4)^4] Thanks! And now for the complete log method: y = 3t(5t + 4)^5  ln(y) = ln(3t(5t + 4)^5)  ln(y) = ln(3) + ln(t) + ln((5t + 4)^5)  ln(y) = ln(3) + ln(t) + 5*ln(5t + 4)  d/dt(ln(y)) = d/dt(ln(3)) + d/dt(ln(t)) + d/dt(5*ln(5t + 4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5*d/dt(ln(5t + 4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*d/dt(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t) + d/dt(4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t) + 0)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(5*dt/dt)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(5)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 25/(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*dt/dt + 25/(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t + 25/(5t + 4)  d/dt(ln(y))3 = d/dt(3) + 3/t + 3*25/(5t + 4)  d/dt(ln(y))3 = 0 + 3/t + 75/(5t + 4)  d/dt(ln(y))3 = 3/t + 75/(5t + 4)  d/dt(ln(y))3t = 3 + 75t/(5t + 4)  d/dt(ln(y))3t(5t + 4) = 3(5t + 4) + 75t  d/dt(ln(y)) = (3(5t + 4) + 75t)/3t(5t + 4)  1/y*dy/dt = (3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = y(3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = 3t(5t + 4)^5 *(3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = (5t + 4)^4 *(3(5t + 4) + 75t)  dy/dt = (5t + 4)^4 *(15t + 12 + 75t)  dy/dt = (5t + 4)^4 *(90t + 12)  dy/dt = [6(5t + 4)^4 *(15t + 2)]!!! This has been very educational.","I've spent almost 6 total hours hacking at this problem. And I always end up by a factor of 3 in one of the terms when checked against Wolfram's derivative calculator, which is correct when I manually calculate the derivative directly from the source equation in excel. I'd love to have someone show me where I'm making my error. Here we go... y = 3t(5t + 4)^5  ln(y) = ln(3t(5t + 4)^5)  ln(y) = 5*ln(3t(5t + 4))  d/dt(ln(y)) = d/dt(5*ln(3t(5t + 4)))  d/dt(ln(y)) = d/dt(5)*d/dt(ln(3t(5t + 4)))  d/dt(ln(y)) = d/dt(ln(3t(5t + 4)))  d/dt(ln(y)) = 1/(3t(5t + 4)) *d/dt(3t(5t + 4))  d/dt(ln(y))*(3t(5t + 4)) = d/dt(3t(5t + 4))  d/dt(ln(y))*(3t(5t + 4)) = d/dt(15t^2 + 12t)  d/dt(ln(y))*(3t(5t + 4)) = d/dt(15t^2) + d/dt(12t)  d/dt(ln(y))*(3t(5t + 4)) = 15*d/dt(t^2) + 12*dt/dt(t)  d/dt(ln(y))*(3t(5t + 4)) = 15*d/dt(t^2) + 12  d/dt(ln(y))*(3t(5t + 4)) = 15*2t*dt/dt + 12  d/dt(ln(y))*(3t(5t + 4)) = 15*2t + 12  d/dt(ln(y))*(3t(5t + 4)) = 30t + 12  d/dt(ln(y)) = (30t + 12)/(3t(5t + 4))  1/y*d/dt = (30t + 12)/(3t(5t + 4))  d/dt = y*(30t + 12)/(3t(5t + 4))  d/dt = 3t(5t + 4)^5 *(30t + 12)/(3t(5t + 4))  d/dt = (5t + 4)^4 *(30t + 12)  d/dt = [6(5t + 4)^4 *(5t + 2)] Wolfram: d/dt = 6(5t + 4)^4 *(15t + 2) Amended approach as per nbubis: The log method was presented as an easy way to handle complex exponents. So I adopted it for all exponent handling. y = 3t(5t + 4)^5  d/dt(y) = d/dt(3t(5t + 4)^5)  F(t) = f(t)*g(h(t))  f(t) = 3t  f'(t) = 3  g(t) = (t)^5  g'(t) = 5(t)^4  h(t) = 5t + 4  h'(t) = 5  F'(t) = f'(t)*g(h(t)) + f(t)*g'(h(t))  F'(t) = f'(t)*g(h(t)) + f(t)*g'(h(t))*h'(t)  F'(t) = 3*(5t + 4)^5 + 3t*5(5t + 4)^4*5  F'(t) = 3*(5t + 4)^5 + 75t(5t + 4)^4 How did you remove ^5? Duh, common factor!!! F'(t) = (3*(5t + 4) + 75t)(5t + 4)^4  F'(t) = 3(5t + 4 + 25t)(5t + 4)^4  F'(t) = 3(30t + 4)(5t + 4)^4  F'(t) = 3*2(15t + 2)(5t + 4)^4  F'(t) = [6(15t + 2)(5t + 4)^4] Thanks! And now for the complete log method: y = 3t(5t + 4)^5  ln(y) = ln(3t(5t + 4)^5)  ln(y) = ln(3) + ln(t) + ln((5t + 4)^5)  ln(y) = ln(3) + ln(t) + 5*ln(5t + 4)  d/dt(ln(y)) = d/dt(ln(3)) + d/dt(ln(t)) + d/dt(5*ln(5t + 4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5*d/dt(ln(5t + 4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*d/dt(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t) + d/dt(4))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t) + 0)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(d/dt(5t))  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(5*dt/dt)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 5/(5t + 4)*(5)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*d/dt(t) + 25/(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t*dt/dt + 25/(5t + 4)  d/dt(ln(y)) = 1/3*d/dt(3) + 1/t + 25/(5t + 4)  d/dt(ln(y))3 = d/dt(3) + 3/t + 3*25/(5t + 4)  d/dt(ln(y))3 = 0 + 3/t + 75/(5t + 4)  d/dt(ln(y))3 = 3/t + 75/(5t + 4)  d/dt(ln(y))3t = 3 + 75t/(5t + 4)  d/dt(ln(y))3t(5t + 4) = 3(5t + 4) + 75t  d/dt(ln(y)) = (3(5t + 4) + 75t)/3t(5t + 4)  1/y*dy/dt = (3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = y(3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = 3t(5t + 4)^5 *(3(5t + 4) + 75t)/3t(5t + 4)  dy/dt = (5t + 4)^4 *(3(5t + 4) + 75t)  dy/dt = (5t + 4)^4 *(15t + 12 + 75t)  dy/dt = (5t + 4)^4 *(90t + 12)  dy/dt = [6(5t + 4)^4 *(15t + 2)]!!! This has been very educational.",,"['calculus', 'derivatives']"
24,Local minimum of $f(x) = 4x + \frac{9\pi^2}{x} + \sin x$,Local minimum of,f(x) = 4x + \frac{9\pi^2}{x} + \sin x,"What's the minimum value of the function $$f(x) = 4x + \frac{9\pi^2}{x} + \sin x$$ for $0 < x < +\infty$? The answer should be $12\pi - 1$, but I get stuck with the expression involving both $\cos x$ and $x^2$ in the derivative. Taking the derivative, we have: $$f'(x) = 4 - \frac{9\pi^2}{x^2} + \cos x.$$ In order to find the local extrema of the function, we set $f'(x) = 0$. Therefore, \begin{align} 4 - \frac{9\pi^2}{x^2} + \cos x &= 0 \\ 4x^2 - 9\pi^2 + x^2 \cos x &= 0 \\ x^2 (4 + \cos x) &= 9\pi^2. \end{align} However, I'm not sure what to do from here or if, indeed, I'm doing it right at all. Any help would be appreciated.","What's the minimum value of the function $$f(x) = 4x + \frac{9\pi^2}{x} + \sin x$$ for $0 < x < +\infty$? The answer should be $12\pi - 1$, but I get stuck with the expression involving both $\cos x$ and $x^2$ in the derivative. Taking the derivative, we have: $$f'(x) = 4 - \frac{9\pi^2}{x^2} + \cos x.$$ In order to find the local extrema of the function, we set $f'(x) = 0$. Therefore, \begin{align} 4 - \frac{9\pi^2}{x^2} + \cos x &= 0 \\ 4x^2 - 9\pi^2 + x^2 \cos x &= 0 \\ x^2 (4 + \cos x) &= 9\pi^2. \end{align} However, I'm not sure what to do from here or if, indeed, I'm doing it right at all. Any help would be appreciated.",,"['calculus', 'trigonometry', 'derivatives', 'optimization']"
25,derivative with respect to a vector/matrix [duplicate],derivative with respect to a vector/matrix [duplicate],,"This question already has answers here : Derivative of Quadratic Form (5 answers) Closed 12 months ago . please excuse the stupid question but I cant find anything online.. If $$f(\vec{x}) = \vec{x}^TA\vec{x}$$ with $A$ being a matrix, then  $$ \frac{df}{d\vec{x}} = \vec{x}^T(A+A^T)$$ Can someone tell me why this is? And I am also interested in knowing what the derivatives of the following termes are: $$ \frac{d}{d\vec{x}}\vec{x}^T A, \qquad \frac{d}{d\vec{x}}A \vec{x}$$ as well as the derivatives with respect to a matrix H $$  \frac{d}{dH}H A , \qquad \frac{d}{dH}A H^T$$ Many thanks for your help.","This question already has answers here : Derivative of Quadratic Form (5 answers) Closed 12 months ago . please excuse the stupid question but I cant find anything online.. If $$f(\vec{x}) = \vec{x}^TA\vec{x}$$ with $A$ being a matrix, then  $$ \frac{df}{d\vec{x}} = \vec{x}^T(A+A^T)$$ Can someone tell me why this is? And I am also interested in knowing what the derivatives of the following termes are: $$ \frac{d}{d\vec{x}}\vec{x}^T A, \qquad \frac{d}{d\vec{x}}A \vec{x}$$ as well as the derivatives with respect to a matrix H $$  \frac{d}{dH}H A , \qquad \frac{d}{dH}A H^T$$ Many thanks for your help.",,"['derivatives', 'vectors', 'matrix-calculus']"
26,The $257^{\text{th}}$ derivative of $e^{-t} \sin t$,The  derivative of,257^{\text{th}} e^{-t} \sin t,How to find the $257^{\text{th}}$ derivative of $e^{-t} \sin t$. I got the wrong values in the end. Not very sure how to go on after calculating $2^{\large\frac{257}{2}}e^{\large\frac{3i}{4}}$.,How to find the $257^{\text{th}}$ derivative of $e^{-t} \sin t$. I got the wrong values in the end. Not very sure how to go on after calculating $2^{\large\frac{257}{2}}e^{\large\frac{3i}{4}}$.,,"['calculus', 'derivatives']"
27,"Let $f(x)=\int_0^1|t-x|t~dt$ for all real $x$. Sketch the graph of $f(x)$, what is the minimum value of $f(x)$","Let  for all real . Sketch the graph of , what is the minimum value of",f(x)=\int_0^1|t-x|t~dt x f(x) f(x),"Let $f(x)=\int_0^1|t-x|t~dt$ for all real $x$. Sketch the graph of $f(x)$, what is the minimum value of $f(x)$ I could not in any way understand how to approach this problem. I think I will be able to plot the graph if I know how the function looks like, so one can wish to avoid that part. To find the minimum value I thought of differentiating the function. But, there is $x$ on one side and $t$ along with $x$ on the other side. I got really confuse how should I do that. Please help.","Let $f(x)=\int_0^1|t-x|t~dt$ for all real $x$. Sketch the graph of $f(x)$, what is the minimum value of $f(x)$ I could not in any way understand how to approach this problem. I think I will be able to plot the graph if I know how the function looks like, so one can wish to avoid that part. To find the minimum value I thought of differentiating the function. But, there is $x$ on one side and $t$ along with $x$ on the other side. I got really confuse how should I do that. Please help.",,"['real-analysis', 'integration', 'derivatives', 'definite-integrals']"
28,Finding maximum value for a function,Finding maximum value for a function,,I was working on this question to find the following function's maximum value.Let $$y=f(x)={{(\sqrt{-3+4x-x^2}+4)}}^2 + (x-5)^2$$ where $$1 \le x \le 3$$.I have to find it's maximum value. I tried by simple method of taking $$\frac{dy}{dx}=0$$ and got the answer.But this path was pretty lenghty and tiresome.Is there any short method possible for this?,I was working on this question to find the following function's maximum value.Let $$y=f(x)={{(\sqrt{-3+4x-x^2}+4)}}^2 + (x-5)^2$$ where $$1 \le x \le 3$$.I have to find it's maximum value. I tried by simple method of taking $$\frac{dy}{dx}=0$$ and got the answer.But this path was pretty lenghty and tiresome.Is there any short method possible for this?,,"['derivatives', 'optimization', 'quadratics', 'radicals']"
29,Differentiating $f(x)^{g(x)}$,Differentiating,f(x)^{g(x)},"Is there any general rule for what the derivative of $f(x)^{g(x)}$ (where $f(x),g(x)$ are differentiable functions) is in terms of $f(x),g(x),f'(x),g'(x)$. In other words is there something analogous to product,chain and quotient rules for such expressions?","Is there any general rule for what the derivative of $f(x)^{g(x)}$ (where $f(x),g(x)$ are differentiable functions) is in terms of $f(x),g(x),f'(x),g'(x)$. In other words is there something analogous to product,chain and quotient rules for such expressions?",,"['calculus', 'derivatives']"
30,"For non-negative $f$ such that $\int_1^\infty |f'(t)|dt < \infty$, $\sum f(k)$ and $\int_1^\infty f(t)dt$ converge or diverge together","For non-negative  such that ,  and  converge or diverge together",f \int_1^\infty |f'(t)|dt < \infty \sum f(k) \int_1^\infty f(t)dt,"Suppose that $f\in C^1([1, \infty))$, $f>0$, and $\int_{1}^\infty |f'(t)|dt < \infty$. I want to show that $\sum_1^\infty f(k)$ and $\int_1^\infty f(t)dt$ are either both convergent or both divergent. One approach might be to try to show that  $\lim_{n\to \infty}(\sum_1^n f(k) - \int_1^n f(t)dt)< \infty$, which is true under the additional hypothesis that $f$ is monotonically decreasing. But I haven't gotten anywhere in proving this, and I suspect it isn't true. One thing I have come up with is that $\forall \epsilon >0$, $f$ is eventually Lipschitz with Lipschitz constant $\epsilon$, which we can see as follows: take $x_{\epsilon}$ such that $\forall x > x_{\epsilon}$ $|f'(x)|<\epsilon$. Then $\forall x,y > x_{\epsilon}$ we have $|f(x) - f(y)| = |\int_{y}^{x}f'(t)dt| \leq \int_x^y|f'(t)|dt \leq |y-x|\varepsilon$. But I'm having trouble leveraging this information into a solution. Any ideas?","Suppose that $f\in C^1([1, \infty))$, $f>0$, and $\int_{1}^\infty |f'(t)|dt < \infty$. I want to show that $\sum_1^\infty f(k)$ and $\int_1^\infty f(t)dt$ are either both convergent or both divergent. One approach might be to try to show that  $\lim_{n\to \infty}(\sum_1^n f(k) - \int_1^n f(t)dt)< \infty$, which is true under the additional hypothesis that $f$ is monotonically decreasing. But I haven't gotten anywhere in proving this, and I suspect it isn't true. One thing I have come up with is that $\forall \epsilon >0$, $f$ is eventually Lipschitz with Lipschitz constant $\epsilon$, which we can see as follows: take $x_{\epsilon}$ such that $\forall x > x_{\epsilon}$ $|f'(x)|<\epsilon$. Then $\forall x,y > x_{\epsilon}$ we have $|f(x) - f(y)| = |\int_{y}^{x}f'(t)dt| \leq \int_x^y|f'(t)|dt \leq |y-x|\varepsilon$. But I'm having trouble leveraging this information into a solution. Any ideas?",,"['calculus', 'sequences-and-series', 'derivatives']"
31,Differentiating $ y= xe^{1\over x} $,Differentiating, y= xe^{1\over x} ,"Can someone please help me? I'm trying, but I really can't find the second derivative of $y= xe^{1/x}$. Thanks!","Can someone please help me? I'm trying, but I really can't find the second derivative of $y= xe^{1/x}$. Thanks!",,"['calculus', 'derivatives']"
32,Graph Concavity Test,Graph Concavity Test,,"I'm studying for my final, and I'm having a problem with one of the questions. Everything before hand has been going fine and is correct, but I'm not understanding this part of the concavity test. $$f(x) = \frac{2(x+1)}{3x^2}$$ $$f'(x) =-\frac{2(x+2)}{3x^3}$$ $$f''(x) = \frac{4(x+3)}{3x^4}$$ For the increasing and decreasing test I found that the critical point is -2: $$2(x+2)=0$$ $$x = -2$$ (This part is probably done differently than most of you do this), here's the chart of the I/D 2(x+2), Before -2 you will get a negative number, and after -2 you will get a positive number. Therefore, f'(x), before -2 will give you a negative number, and after you will get a positive number, so f(x) before -2 will be decreasing and after it will be increasing. Where -2 is your local minimum. (By this I mean; 2(x+2), any number before -2 (ie. -10) it will give you a negative number.) As for the concavity test, I did the same thing basically; $$4(x + 3) = 0$$ $$x = -3$$ However, my textbook says that x = 0 is also a critical point, I don't understand where you get this from. If anyone can explain this I would appreciate it, also if there's a more simple way of doing these tests I would love to hear it, thanks.","I'm studying for my final, and I'm having a problem with one of the questions. Everything before hand has been going fine and is correct, but I'm not understanding this part of the concavity test. $$f(x) = \frac{2(x+1)}{3x^2}$$ $$f'(x) =-\frac{2(x+2)}{3x^3}$$ $$f''(x) = \frac{4(x+3)}{3x^4}$$ For the increasing and decreasing test I found that the critical point is -2: $$2(x+2)=0$$ $$x = -2$$ (This part is probably done differently than most of you do this), here's the chart of the I/D 2(x+2), Before -2 you will get a negative number, and after -2 you will get a positive number. Therefore, f'(x), before -2 will give you a negative number, and after you will get a positive number, so f(x) before -2 will be decreasing and after it will be increasing. Where -2 is your local minimum. (By this I mean; 2(x+2), any number before -2 (ie. -10) it will give you a negative number.) As for the concavity test, I did the same thing basically; $$4(x + 3) = 0$$ $$x = -3$$ However, my textbook says that x = 0 is also a critical point, I don't understand where you get this from. If anyone can explain this I would appreciate it, also if there's a more simple way of doing these tests I would love to hear it, thanks.",,"['calculus', 'derivatives']"
33,Differentiation of summation of summation,Differentiation of summation of summation,,"According to http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf , (45) and (46) (p. 6), differention of  $$\alpha = \sum_{j=1}^n\sum_{i=1}^n a_{ij} x_i x_j $$ with respect to the k-th element of x yields: $$\frac{\partial\alpha}{\partial x_k} = \sum_{j=1}^n a_{kj} x_j + \sum_{i=1}^n a_{ik} x_i $$ Note that a does not depend on x. How is this result obtained? From differentiation with summation symbol , I understood how to derive one summation. The function above seems to be of form f(g(x)) to me, so I would apply the chain rule.  But how can the result contain a + then, indicating some form of the product rule was used?","According to http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf , (45) and (46) (p. 6), differention of  $$\alpha = \sum_{j=1}^n\sum_{i=1}^n a_{ij} x_i x_j $$ with respect to the k-th element of x yields: $$\frac{\partial\alpha}{\partial x_k} = \sum_{j=1}^n a_{kj} x_j + \sum_{i=1}^n a_{ik} x_i $$ Note that a does not depend on x. How is this result obtained? From differentiation with summation symbol , I understood how to derive one summation. The function above seems to be of form f(g(x)) to me, so I would apply the chain rule.  But how can the result contain a + then, indicating some form of the product rule was used?",,"['derivatives', 'summation']"
34,find the derivative of $e^{-2t} \cos(4t)$,find the derivative of,e^{-2t} \cos(4t),"hello guys im kind of confused and my book those not give me answer to this problem i wonder if someone can confirm my answer or if I'm simply wrong. If I'm wrong then please correct me, don't just tell me I'm wrong. I'm asked to find the derivative of the following  $$ y= e^{-2t} \cos4t$$ here is how i did it step 1  by the product rule- $$y'= e^{-2t} \frac{d}{dt}(\cos(4t))+\cos(4t) \frac{d}{dt} (e^{-2t}) $$ step 2 - find the derivatives of the two functions using chain rule $$e^{-2t}(\cos(4t)(-\sin(4t)(4)))+ \cos(4t)(e^{-2t}(-2))$$ did i approached this correctly? is this the correct answer.  Thanks in advance of any adivce you guys can offer. Im really leary about the $(\cos(4t)(-\sin(4t)(4)))$ im not sure if this part is right or not? Thanks Miguel","hello guys im kind of confused and my book those not give me answer to this problem i wonder if someone can confirm my answer or if I'm simply wrong. If I'm wrong then please correct me, don't just tell me I'm wrong. I'm asked to find the derivative of the following  $$ y= e^{-2t} \cos4t$$ here is how i did it step 1  by the product rule- $$y'= e^{-2t} \frac{d}{dt}(\cos(4t))+\cos(4t) \frac{d}{dt} (e^{-2t}) $$ step 2 - find the derivatives of the two functions using chain rule $$e^{-2t}(\cos(4t)(-\sin(4t)(4)))+ \cos(4t)(e^{-2t}(-2))$$ did i approached this correctly? is this the correct answer.  Thanks in advance of any adivce you guys can offer. Im really leary about the $(\cos(4t)(-\sin(4t)(4)))$ im not sure if this part is right or not? Thanks Miguel",,"['calculus', 'derivatives']"
35,Find $F'(x)$ given $ \int_x^{x+2} (4t+1) \ \mathrm{dt}$,Find  given,F'(x)  \int_x^{x+2} (4t+1) \ \mathrm{dt},"Given the problem find $F'(x)$: $$ \int_x^{x+2} (4t+1) \  \mathrm{dt}$$ I just feel stuck and don't know where to go with this, we learned the second fundamental theorem of calculus today but i don't know where to plug it in. What i did: chain rule doesn't really take into effect here(*1) so just replace t with $x$ $F'(x) = 4x + 1$ though the answer is just 8, what am i doing wrong?","Given the problem find $F'(x)$: $$ \int_x^{x+2} (4t+1) \  \mathrm{dt}$$ I just feel stuck and don't know where to go with this, we learned the second fundamental theorem of calculus today but i don't know where to plug it in. What i did: chain rule doesn't really take into effect here(*1) so just replace t with $x$ $F'(x) = 4x + 1$ though the answer is just 8, what am i doing wrong?",,['derivatives']
36,How do I set up this related rates problem? [closed],How do I set up this related rates problem? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I seem to have problems with these sort of questions, can someone shed some light on this for me? You are holding a reel with a line, attached to a balloon, spooling from it. The balloon was released from a spot on level ground 20ft from you and is rising straight up. How fast is the balloon rising when the reel indicateds that 25 feet of line is out and that more is spooling from it at 3 feet per second? Also, how high is the balloon at that same point? What do I need to do to set up the equation here?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I seem to have problems with these sort of questions, can someone shed some light on this for me? You are holding a reel with a line, attached to a balloon, spooling from it. The balloon was released from a spot on level ground 20ft from you and is rising straight up. How fast is the balloon rising when the reel indicateds that 25 feet of line is out and that more is spooling from it at 3 feet per second? Also, how high is the balloon at that same point? What do I need to do to set up the equation here?",,"['calculus', 'derivatives']"
37,Calculating derivative using definition for $f(x)=\frac{x - \sin x}{x^2}$,Calculating derivative using definition for,f(x)=\frac{x - \sin x}{x^2},"Really stuck on this one.... $\displaystyle f(x) = \frac{x - \sin{x}}{x^{2}}$ for $x \neq 0$ and $0$ when  $x = 0$ Using the definition of the derivative, find $f'(0)$ I know the definition is $$ \lim_{h \to 0}  \frac{f(x+h)-f(x)}{h}$$ The way I did it was to say $$\lim_{h\to 0}\frac{\frac{(x+h)-\sin(x+h)}{(x+h)^2} - \frac{x - \sin x}{x^2}}{h}$$ $$=\lim_{h\to 0}\frac{\frac{1-\cos(x+h)}{(x+h)^2} - 2\left(\frac{(x+h) - \sin(x+h)}{(x+h)^3}\right)}{1}$$ (using L'Hôpitals Rule) which is $$ \frac{1-\cos(x)}{x^2} -\frac{2(x-\sin x)}{x^3}.$$  But then we cant use this to find $f'(0)$ because the denominator it 0!!! Where am I going wrong?","Really stuck on this one.... $\displaystyle f(x) = \frac{x - \sin{x}}{x^{2}}$ for $x \neq 0$ and $0$ when  $x = 0$ Using the definition of the derivative, find $f'(0)$ I know the definition is $$ \lim_{h \to 0}  \frac{f(x+h)-f(x)}{h}$$ The way I did it was to say $$\lim_{h\to 0}\frac{\frac{(x+h)-\sin(x+h)}{(x+h)^2} - \frac{x - \sin x}{x^2}}{h}$$ $$=\lim_{h\to 0}\frac{\frac{1-\cos(x+h)}{(x+h)^2} - 2\left(\frac{(x+h) - \sin(x+h)}{(x+h)^3}\right)}{1}$$ (using L'Hôpitals Rule) which is $$ \frac{1-\cos(x)}{x^2} -\frac{2(x-\sin x)}{x^3}.$$  But then we cant use this to find $f'(0)$ because the denominator it 0!!! Where am I going wrong?",,"['calculus', 'derivatives']"
38,Is it possible to find the $n$th derivative of Gamma function?,Is it possible to find the th derivative of Gamma function?,n,"By repeatedly differentiating $\Gamma(x)$ , I noticed that $$\frac{d^{n}}{{dx}^{n}}\Gamma(x)=\sum_{k=0}^{n-1}\binom{n-1}{k}\psi^{(n-k-1)}(x)\,\frac{d^{k}}{{dx}^{k}}\Gamma(x),$$ where $\psi^{(a)}(x)$ is the polygamma function. I don't find this expression useful as the derivative of $\Gamma(x)$ appears on both sides. Is it possible to establish a closed form for this derivative? Thank you.","By repeatedly differentiating , I noticed that where is the polygamma function. I don't find this expression useful as the derivative of appears on both sides. Is it possible to establish a closed form for this derivative? Thank you.","\Gamma(x) \frac{d^{n}}{{dx}^{n}}\Gamma(x)=\sum_{k=0}^{n-1}\binom{n-1}{k}\psi^{(n-k-1)}(x)\,\frac{d^{k}}{{dx}^{k}}\Gamma(x), \psi^{(a)}(x) \Gamma(x)","['derivatives', 'closed-form', 'gamma-function', 'binomial-theorem', 'polygamma']"
39,Why does this proof work: $\sum\limits_{n=1}^ \infty \left(\frac{1}{4n-1} - \frac{1}{4n}\right)= \frac{\ln(64)- \pi}{8}$?,Why does this proof work: ?,\sum\limits_{n=1}^ \infty \left(\frac{1}{4n-1} - \frac{1}{4n}\right)= \frac{\ln(64)- \pi}{8},$$f(x):= \sum_{n=1}^ \infty \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right)$$ $$f'(x) = \sum_{n=1}^ \infty ( x^{4n-2}- x^{4n-1})= \frac{x^2}{(1+x)(1+x^2)}$$ $$\int_0 ^1 \frac{x^2}{(1+x)(1+x^2)}= \frac{\ln(64)- \pi}{8} $$ This proof is not correct because $f_N(x) := \sum\limits_{n=1}^ \infty \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right) $ and $f_N'(x)=\sum\limits_{n=1}^ N( x^{4n-2}- x^{4n-1})= x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1}$ doesn't converge uniformly so the the derivative and the sum couldn't be interchanged but the answer is correct. Is it a coincidence ? Is there is other condition to interchange sum and  derivative that don't require uniform convergence? Is there is a way to justify this ? Any other conditions? I am pretty sure I can generate an infinite cases where this interchange work from this example by changing the '4' to any other  integer greater than 1. So why does this work ?,This proof is not correct because and doesn't converge uniformly so the the derivative and the sum couldn't be interchanged but the answer is correct. Is it a coincidence ? Is there is other condition to interchange sum and  derivative that don't require uniform convergence? Is there is a way to justify this ? Any other conditions? I am pretty sure I can generate an infinite cases where this interchange work from this example by changing the '4' to any other  integer greater than 1. So why does this work ?,f(x):= \sum_{n=1}^ \infty \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right) f'(x) = \sum_{n=1}^ \infty ( x^{4n-2}- x^{4n-1})= \frac{x^2}{(1+x)(1+x^2)} \int_0 ^1 \frac{x^2}{(1+x)(1+x^2)}= \frac{\ln(64)- \pi}{8}  f_N(x) := \sum\limits_{n=1}^ \infty \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right)  f_N'(x)=\sum\limits_{n=1}^ N( x^{4n-2}- x^{4n-1})= x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1},"['real-analysis', 'derivatives', 'summation', 'examples-counterexamples', 'uniform-convergence']"
40,find ${dy}/{dx}$ of $x\sqrt{1+y} + y\sqrt{1+x} = 0$,find  of,{dy}/{dx} x\sqrt{1+y} + y\sqrt{1+x} = 0,"Question My approach I tried by applying basic product rule, but could not proceed further; don't know how to eliminate the y factors in the solution. How to prove it?","Question My approach I tried by applying basic product rule, but could not proceed further; don't know how to eliminate the y factors in the solution. How to prove it?",,"['calculus', 'derivatives']"
41,Finding the smallest positive integer $n$ such that $f_n(x)=\cos(x)\cos(2x)\cdots\cos(nx)$ satisfies $|f_n''(0)|>2023$. (Putnam 2023 A1),Finding the smallest positive integer  such that  satisfies . (Putnam 2023 A1),n f_n(x)=\cos(x)\cos(2x)\cdots\cos(nx) |f_n''(0)|>2023,"Putnam 2023, Problem A1: For a positive integer $n$ , let $f_n(x)=\cos (x) \cos (2 x) \cos (3 x) \cdots \cos (n x)$ . Find the smallest $n$ such that $|f_n''(0)|>2023$ . Note: Here, $f_n''(x)$ denotes the double derivative of $f_n(x)$ . My Attempt : Observe that we can write $$f_n(x)=\cos (x) \cos (2 x) \cos (3 x) \cdots \cos (n x)=\frac{1}{2^n}. \prod \limits_{k=1}^n ({e^{ikx} + e^{-ikx}})$$ But how can I get from here that $$|f_n''(0)| = \frac{n(n+1)(2n+1)}{6} > 2023 \quad\Longrightarrow\quad n \geq 18$$ Any help would be appreciated.","Putnam 2023, Problem A1: For a positive integer , let . Find the smallest such that . Note: Here, denotes the double derivative of . My Attempt : Observe that we can write But how can I get from here that Any help would be appreciated.",n f_n(x)=\cos (x) \cos (2 x) \cos (3 x) \cdots \cos (n x) n |f_n''(0)|>2023 f_n''(x) f_n(x) f_n(x)=\cos (x) \cos (2 x) \cos (3 x) \cdots \cos (n x)=\frac{1}{2^n}. \prod \limits_{k=1}^n ({e^{ikx} + e^{-ikx}}) |f_n''(0)| = \frac{n(n+1)(2n+1)}{6} > 2023 \quad\Longrightarrow\quad n \geq 18,"['real-analysis', 'calculus', 'derivatives', 'inequality', 'trigonometry']"
42,Derivative of the Dirac delta function,Derivative of the Dirac delta function,,"So, I was reading about the Dirac delta function and how its differentiation works. So, pretty much all texts and online sources I saw, define it using the integral: $$ \int_{-\infty}^{+\infty}x\dfrac{d\delta(x)}{dx} dx= \left. x\delta(x)\right|_{-\infty}^{\infty}-\int_{-\infty}^{+\infty}\delta(x)dx$$ and here all of them say the first term is zero, as $δ(x)$ is zero at infinities. But, won't $x$ be equal to infinity at that point? Won't this mean that the first term is not zero? My point stands, even if there was a function $f(x)$ instead of $x$ in the L.H.S. of the above equation. I originally had this doubt while solving problem 1.46 in Introduction to electrodynamics by D. J. Griffiths . Any help on this matter would be much appreciated.","So, I was reading about the Dirac delta function and how its differentiation works. So, pretty much all texts and online sources I saw, define it using the integral: and here all of them say the first term is zero, as is zero at infinities. But, won't be equal to infinity at that point? Won't this mean that the first term is not zero? My point stands, even if there was a function instead of in the L.H.S. of the above equation. I originally had this doubt while solving problem 1.46 in Introduction to electrodynamics by D. J. Griffiths . Any help on this matter would be much appreciated.", \int_{-\infty}^{+\infty}x\dfrac{d\delta(x)}{dx} dx= \left. x\delta(x)\right|_{-\infty}^{\infty}-\int_{-\infty}^{+\infty}\delta(x)dx δ(x) x f(x) x,['derivatives']
43,Series expansion of $\left(\frac{\sin x}{x}\right)^a$ at $x=0$,Series expansion of  at,\left(\frac{\sin x}{x}\right)^a x=0,"I need a series expansion at $x=0$ (with nth term please) for $$f(x)= \left(\frac{\sin x}{x}\right)^a$$ where $a>0$ is a real number. We know that $$\sin x=x-\frac{x^3}{3!}+\frac{x^5}{5!}-...$$ So we have $$\frac{\sin x}{x}=1-\frac{x^2}{3!}+\frac{x^4}{5!}-...$$ Now if we take $y= -\frac{x^2}{3!}+\frac{x^4}{5!}-...$ then $$\left(\frac{\sin x}{x}\right)^a=(1+y)^a$$ Then by Binomial theorem we have $$\left(\frac{\sin x}{x}\right)^a=1+a y+\frac{a(a-1)}{2!}y^2+ +\frac{a(a-1)(a-2)}{3!}y^3+...   $$ Now I am stuck to calculate $y^2,y^3,...$ Another approach $$f(x)= \left(\frac{\sin x}{x}\right)^a$$ So on differentiation $$f'(x)=a  \left(\frac{\sin x}{x}\right)^{a-1} \left(\frac{x\cos x-\sin x}{x^2}\right) $$ So we have taking the limit of above function as $x\to 0$ $$f'(0)=0$$ This is again where I am stuck. Any help would be surely appreciated. Thank you.",I need a series expansion at (with nth term please) for where is a real number. We know that So we have Now if we take then Then by Binomial theorem we have Now I am stuck to calculate Another approach So on differentiation So we have taking the limit of above function as This is again where I am stuck. Any help would be surely appreciated. Thank you.,"x=0 f(x)= \left(\frac{\sin x}{x}\right)^a a>0 \sin x=x-\frac{x^3}{3!}+\frac{x^5}{5!}-... \frac{\sin x}{x}=1-\frac{x^2}{3!}+\frac{x^4}{5!}-... y= -\frac{x^2}{3!}+\frac{x^4}{5!}-... \left(\frac{\sin x}{x}\right)^a=(1+y)^a \left(\frac{\sin x}{x}\right)^a=1+a y+\frac{a(a-1)}{2!}y^2+ +\frac{a(a-1)(a-2)}{3!}y^3+...    y^2,y^3,... f(x)= \left(\frac{\sin x}{x}\right)^a f'(x)=a  \left(\frac{\sin x}{x}\right)^{a-1} \left(\frac{x\cos x-\sin x}{x^2}\right)  x\to 0 f'(0)=0","['real-analysis', 'calculus', 'derivatives', 'trigonometry', 'taylor-expansion']"
44,Commutation of differentiation with any linear map,Commutation of differentiation with any linear map,,"Consider $A$ and $B$ are two linear operators in finite-dimensional vector space. So to commute, they should share something special. For matrix $A$ to commute with all other is quite restrictive: it would only true for multiply of identity. However differential is also linear operator and it commutes with any matrix $A$ : $$ f(x) = A\phi(x), [D_{(x_0)}A\circ\phi(x)](h) = A[D_{(x_0)}\phi(x)](h). $$ This is quite a puzzle for me from this perspective.","Consider and are two linear operators in finite-dimensional vector space. So to commute, they should share something special. For matrix to commute with all other is quite restrictive: it would only true for multiply of identity. However differential is also linear operator and it commutes with any matrix : This is quite a puzzle for me from this perspective.","A B A A 
f(x) = A\phi(x), [D_{(x_0)}A\circ\phi(x)](h) = A[D_{(x_0)}\phi(x)](h).
","['derivatives', 'differential-geometry', 'linear-transformations']"
45,Integral of symplectic form?,Integral of symplectic form?,,"It is often said that ""differential forms are used for integration"". Typically people like to talk about the integral $\int_M \omega$ of a differential form $\omega$ , and exterior derivative, one of the most important operation of differential form, is defined such that Stokes' theorem $\int_{\partial M} \omega = \int_M \mathrm{d} \omega$ can hold. Symplectic manifold is a manifold equipped with a symplectic 2-form $\omega$ . Therefore, according to the former consideration, it should be interesting to talk about integral of the symplectic form on a two-dimensional submanifold of a symplectic manifold. However, it seems that people in the field of symplectic geometry is quite indifferent on this. Why?","It is often said that ""differential forms are used for integration"". Typically people like to talk about the integral of a differential form , and exterior derivative, one of the most important operation of differential form, is defined such that Stokes' theorem can hold. Symplectic manifold is a manifold equipped with a symplectic 2-form . Therefore, according to the former consideration, it should be interesting to talk about integral of the symplectic form on a two-dimensional submanifold of a symplectic manifold. However, it seems that people in the field of symplectic geometry is quite indifferent on this. Why?",\int_M \omega \omega \int_{\partial M} \omega = \int_M \mathrm{d} \omega \omega,"['derivatives', 'differential-geometry', 'smooth-manifolds', 'symplectic-geometry', 'submanifold']"
46,How can I argue that $f(x) = (2-x)^3-x+\frac{3}{2}$ is decreasing with a polynomial?,How can I argue that  is decreasing with a polynomial?,f(x) = (2-x)^3-x+\frac{3}{2},"$$f(x) = (2-x)^3-x+\frac{3}{2}$$ I have to give a mathematical argument for the said function in the title being decreasing. My first thought was finding $f'(x)$ but I got a polynomial and for that reason I don't know how to argue that it is decreasing since $f'(x)<0$ has to be true. What I mean is that I can't see it in the polynomial, which is: $f'(x)=-3x^2+12x-13$ . However, the second derivative gives me something I can work with: $f''(x)=-6x+12$ . So my question is, how do I argue that $f(x) = (2-x)^3-x+3/2$ is decreasing with the first derivative being a polynomial, $f'(x)=-3x^2+12x-13$ ?","I have to give a mathematical argument for the said function in the title being decreasing. My first thought was finding but I got a polynomial and for that reason I don't know how to argue that it is decreasing since has to be true. What I mean is that I can't see it in the polynomial, which is: . However, the second derivative gives me something I can work with: . So my question is, how do I argue that is decreasing with the first derivative being a polynomial, ?",f(x) = (2-x)^3-x+\frac{3}{2} f'(x) f'(x)<0 f'(x)=-3x^2+12x-13 f''(x)=-6x+12 f(x) = (2-x)^3-x+3/2 f'(x)=-3x^2+12x-13,"['calculus', 'derivatives']"
47,Why is the Radon–Nikodym theorem important in probability?,Why is the Radon–Nikodym theorem important in probability?,,"I was reading this Wikipedia page and came across the following statement: The Radon–Nikodym theorem essentially states that, under certain conditions, any measure ν can be expressed in this way with respect to another measure μ on the same space. The function  f  is then called the Radon–Nikodym derivative and is denoted by {\displaystyle {\tfrac {d\nu }{d\mu }}}{\displaystyle {\tfrac {d\nu }{d\mu }}}. 1 An important application is in probability theory, leading to the probability density function of a random variable. I am trying to understand why this important - i.e., why is the Radon–Nikodym theorem important in defining the probability density function of a random variable? In the courses I have taken in statistics/probability (engineering), we were always shown the definition of a probability distribution (of a random variable) without any mention of the Radon-Nikodym theorem. I would have never even known that such a theorem existed, let alone that such a theorem would be so important in defining the probability density of a random variable. Why is the Radon-Nikodym theorem so important in defining the probability density of a random variable? Is it really that important that it can not be defined without this theorem?","I was reading this Wikipedia page and came across the following statement: The Radon–Nikodym theorem essentially states that, under certain conditions, any measure ν can be expressed in this way with respect to another measure μ on the same space. The function  f  is then called the Radon–Nikodym derivative and is denoted by {\displaystyle {\tfrac {d\nu }{d\mu }}}{\displaystyle {\tfrac {d\nu }{d\mu }}}. 1 An important application is in probability theory, leading to the probability density function of a random variable. I am trying to understand why this important - i.e., why is the Radon–Nikodym theorem important in defining the probability density function of a random variable? In the courses I have taken in statistics/probability (engineering), we were always shown the definition of a probability distribution (of a random variable) without any mention of the Radon-Nikodym theorem. I would have never even known that such a theorem existed, let alone that such a theorem would be so important in defining the probability density of a random variable. Why is the Radon-Nikodym theorem so important in defining the probability density of a random variable? Is it really that important that it can not be defined without this theorem?",,"['probability', 'derivatives']"
48,Mechanics of the second derivative test?,Mechanics of the second derivative test?,,"I am trying to understand why $f'(x)=0$ and $f''(x)>0 $ together imply a local minimum, and why $f'(x)=0$ and $f''(x)<0$ together imply local maximum. I am new to calculus and don't know multivariable calculus, so please give the reasoning or proof in terms of single-variable calculus. An intuitive explanation is preferred but a rigorous proof is also fine.","I am trying to understand why and together imply a local minimum, and why and together imply local maximum. I am new to calculus and don't know multivariable calculus, so please give the reasoning or proof in terms of single-variable calculus. An intuitive explanation is preferred but a rigorous proof is also fine.",f'(x)=0 f''(x)>0  f'(x)=0 f''(x)<0,"['calculus', 'derivatives', 'maxima-minima']"
49,The formula for $g\frac{d}{dg}g\frac{d}{dg}...g\frac{d}{dg}f(g)$,The formula for,g\frac{d}{dg}g\frac{d}{dg}...g\frac{d}{dg}f(g),"Yesterday, I asked if there is a formula given by a finite sum for the expression. Having experimented with Wolfram Alpha I found that it can be represented as $$ \sum_{j=0}^{n}a_{j}g^{j}\frac{d^{j}}{dg^{j}}f(g),$$ where $a^{j}$ is given by the coefficient attached to $z^{n-1}$ in the sum expansion of the generating function $$\frac{z^{j}}{(1-jz)(1-(j-1)z)...(1-z)},$$ assuming I did not make any mistakes. How does one go about proving it? In the title there are $n$ iterations of $g\frac{d}{dg}$ .","Yesterday, I asked if there is a formula given by a finite sum for the expression. Having experimented with Wolfram Alpha I found that it can be represented as where is given by the coefficient attached to in the sum expansion of the generating function assuming I did not make any mistakes. How does one go about proving it? In the title there are iterations of ."," \sum_{j=0}^{n}a_{j}g^{j}\frac{d^{j}}{dg^{j}}f(g), a^{j} z^{n-1} \frac{z^{j}}{(1-jz)(1-(j-1)z)...(1-z)}, n g\frac{d}{dg}","['sequences-and-series', 'derivatives', 'summation', 'generating-functions', 'theorem-provers']"
50,"If $ax^2 + 2hxy + by^2 = 0$ (here $a, b, h$ are real constants), then find $\frac{dy}{dx}$.","If  (here  are real constants), then find .","ax^2 + 2hxy + by^2 = 0 a, b, h \frac{dy}{dx}","Question: If $ax^2 + 2hxy + by^2 = 0$ (Where $a, b, h$ are real constants), then find $\dfrac{dy}{dx}$ . Following choices are given:- $\dfrac yx$ $\dfrac xy$ $\dfrac {-y}x$ $\dfrac {-x}y$ My work: Differentiating the equation given, $$2ax + 2h \left[y + x \dfrac{dy}{dx} \right] + 2by \dfrac{dy}{dx} = 0 $$ $$\implies \dfrac{dy}{dx} = \dfrac{-(ax+ hy)}{(hx+ by)}$$ Although I obtained $\dfrac{dy}{dx}$ , but there is no such option given. I need to write the answer is terms of $x$ and $y$ only. I tried to find the value of $h$ from the given equation and substituted in the value of $\dfrac{dy}{dx}$ but that seems not working here. What would be the appropriate way to solve this question?","Question: If (Where are real constants), then find . Following choices are given:- My work: Differentiating the equation given, Although I obtained , but there is no such option given. I need to write the answer is terms of and only. I tried to find the value of from the given equation and substituted in the value of but that seems not working here. What would be the appropriate way to solve this question?","ax^2 + 2hxy + by^2 = 0 a, b, h \dfrac{dy}{dx} \dfrac yx \dfrac xy \dfrac {-y}x \dfrac {-x}y 2ax + 2h \left[y + x \dfrac{dy}{dx} \right] + 2by \dfrac{dy}{dx} = 0  \implies \dfrac{dy}{dx} = \dfrac{-(ax+ hy)}{(hx+ by)} \dfrac{dy}{dx} x y h \dfrac{dy}{dx}",['calculus']
51,Solve $ \int_0^\infty x^n e^{-\lambda x} dx $ by differentiating under integral sign,Solve  by differentiating under integral sign, \int_0^\infty x^n e^{-\lambda x} dx ,"I have only found information regarding doing this by integration by parts. By differentiating under the integral sign, I let $$I_n = \int_0^\infty x^n e^{-\lambda x} dx $$ and get $\frac{dI_n}{d\lambda} = -I_{n+1} $ and therefore $\frac{dI_n}{d\lambda} = -\frac{n+1}{\lambda} I_n$ . Proceeding from here I solve the ODE to get $I_n = Ae^{-\frac{n+1}{\lambda}x}$ . This is clearly wrong. What went wrong? I am unsure how to proceed with this differentiation of the integral approach to solve this problem.","I have only found information regarding doing this by integration by parts. By differentiating under the integral sign, I let and get and therefore . Proceeding from here I solve the ODE to get . This is clearly wrong. What went wrong? I am unsure how to proceed with this differentiation of the integral approach to solve this problem.",I_n = \int_0^\infty x^n e^{-\lambda x} dx  \frac{dI_n}{d\lambda} = -I_{n+1}  \frac{dI_n}{d\lambda} = -\frac{n+1}{\lambda} I_n I_n = Ae^{-\frac{n+1}{\lambda}x},"['calculus', 'integration', 'derivatives']"
52,Curvature as a rate of change in slope,Curvature as a rate of change in slope,,"While working with some  formulas on cantilever in mechanical engineering , in some places it assumes that $\frac{1}{R} =\kappa = \frac{d^{2} y}{d x^{2}}$ But I know That $k=\frac{y^{\prime \prime}}{(1+y^{\prime 2})^{\frac{3}{2}}}$ So It Is Very Counterintuitive to me , So Someone please help me","While working with some  formulas on cantilever in mechanical engineering , in some places it assumes that But I know That So It Is Very Counterintuitive to me , So Someone please help me",\frac{1}{R} =\kappa = \frac{d^{2} y}{d x^{2}} k=\frac{y^{\prime \prime}}{(1+y^{\prime 2})^{\frac{3}{2}}},"['calculus', 'derivatives', 'physics', 'classical-mechanics', 'curvature']"
53,Dilemma regarding first fundamental theorem of Calculus,Dilemma regarding first fundamental theorem of Calculus,,"In the book Principles of mathematical analysis by Walter Rudin these are the statements which I came across Corollary 5.12 $\space\space\space$ If $f$ is differentiable on $[a,b]$ then $f'$ cannot have any simple discontinuities on $[a,b]$ . But $f'$ may have discontinuties of the second kind. Theorem 6.20 $\space\space\space$ Let $f$ $\in$ $\mathscr{R}$ on $[a,b].$ For $a\le x \le b,$ put $$F(x)=\int_a^xf(t)dt.$$ Then $F$ is continuous on $[a,b]$ ; furthermore, if $f$ is continuous at a point $x_0$ of $[a,b]$ , then $F$ is differentiable at $x_0$ , and $$F'(x_0)=f(x_0).$$ Theorem 6.21 $\space\space\space$ If $f$ $\in$ $\mathscr{R}$ on $[a,b]$ and if there is a differentiable function $F$ on $[a,b]$ such that $F'=f$ , then $$\int_a^b{f(x)dx}=F(b)-F(a).$$ Now the problem is, we can have a differentiable function $F$ on $[a,b]$ such that $F'= f$ and $f$ is discontinuous, although the discontinuity will be of second kind according to the statement $1$ . If these discontinuities are finite then $f\in\mathscr{R}.$ Let's assume a point $c\in[a,b]$ where $f$ is discontinuous (discontinuity of the second kind). Since, $f\in\mathscr{R}$ let's define a function $$G=\int_a^xf(t)dt\tag{1}$$ for $x\in[a,b]$ . Then according to the statement $2$ , $G(x)$ is clearly not differentiable at $c$ since $f$ is discontinuous at $c$ . Now, from statement $3$ we can also say that $$\int_a^xf(t)dt=F(x)-F(a)\tag{2}$$ if $x\in[a,b]$ . Thus from equations $(1)$ and $(2)$ we have $$F(x)-F(a)=G(x)$$ which would make $G(x)$ differentiable for all $x\in[a,b]$ but we know that $G(x)$ is not differentiable at $c$ . So, this is a paradox which means I am wrong somewhere but try as I might I am not able to find it. It'd be a great help if someone can point out the error. Edit: $\mathscr{R}$ here denotes the set of Riemann-integrable functions","In the book Principles of mathematical analysis by Walter Rudin these are the statements which I came across Corollary 5.12 If is differentiable on then cannot have any simple discontinuities on . But may have discontinuties of the second kind. Theorem 6.20 Let on For put Then is continuous on ; furthermore, if is continuous at a point of , then is differentiable at , and Theorem 6.21 If on and if there is a differentiable function on such that , then Now the problem is, we can have a differentiable function on such that and is discontinuous, although the discontinuity will be of second kind according to the statement . If these discontinuities are finite then Let's assume a point where is discontinuous (discontinuity of the second kind). Since, let's define a function for . Then according to the statement , is clearly not differentiable at since is discontinuous at . Now, from statement we can also say that if . Thus from equations and we have which would make differentiable for all but we know that is not differentiable at . So, this is a paradox which means I am wrong somewhere but try as I might I am not able to find it. It'd be a great help if someone can point out the error. Edit: here denotes the set of Riemann-integrable functions","\space\space\space f [a,b] f' [a,b] f' \space\space\space f \in \mathscr{R} [a,b]. a\le x \le b, F(x)=\int_a^xf(t)dt. F [a,b] f x_0 [a,b] F x_0 F'(x_0)=f(x_0). \space\space\space f \in \mathscr{R} [a,b] F [a,b] F'=f \int_a^b{f(x)dx}=F(b)-F(a). F [a,b] F'= f f 1 f\in\mathscr{R}. c\in[a,b] f f\in\mathscr{R} G=\int_a^xf(t)dt\tag{1} x\in[a,b] 2 G(x) c f c 3 \int_a^xf(t)dt=F(x)-F(a)\tag{2} x\in[a,b] (1) (2) F(x)-F(a)=G(x) G(x) x\in[a,b] G(x) c \mathscr{R}","['real-analysis', 'calculus', 'derivatives', 'riemann-integration']"
54,Derivative of $\cos^{-1}\sqrt{\frac{1+x}2}$ using substitution,Derivative of  using substitution,\cos^{-1}\sqrt{\frac{1+x}2},"Find the derivative of $$\cos^{-1}\sqrt{\frac{1+x}2}.$$ I'm learning differentiation and calculus for the first time. I can easily find the derivative of the given expression by chain rule. But the book from which I'm learning calculus encourages finding derivatives of inverse trigonometric functions of algebraic functions with substitution rather than using chain rule. So, I want to find the derivative of this function with substitution. Here is my attempt to do that: Let $x=\cos2\theta$ , then $\theta=\frac{\cos^{-1}x}2$ . Now, $\begin{align}\cos^{-1}\sqrt{\frac{1+x}2} &= \cos^{-1}\left(\frac1{\sqrt2}\sqrt{1+\cos2\theta}\right)\\ &= \cos^{-1}\left(\frac1{\sqrt2}\sqrt{1+\cos^2\theta-1}\right)\\ &= \cos^{-1}\left(\frac1{\sqrt2}\cos\theta\right) \end{align}$ I can't proceed further from here. Can we write this as $\frac1{\sqrt2}\theta$ ? And please do not give a solution using chain rule, as this would be of no help to me.","Find the derivative of I'm learning differentiation and calculus for the first time. I can easily find the derivative of the given expression by chain rule. But the book from which I'm learning calculus encourages finding derivatives of inverse trigonometric functions of algebraic functions with substitution rather than using chain rule. So, I want to find the derivative of this function with substitution. Here is my attempt to do that: Let , then . Now, I can't proceed further from here. Can we write this as ? And please do not give a solution using chain rule, as this would be of no help to me.","\cos^{-1}\sqrt{\frac{1+x}2}. x=\cos2\theta \theta=\frac{\cos^{-1}x}2 \begin{align}\cos^{-1}\sqrt{\frac{1+x}2} &= \cos^{-1}\left(\frac1{\sqrt2}\sqrt{1+\cos2\theta}\right)\\ &= \cos^{-1}\left(\frac1{\sqrt2}\sqrt{1+\cos^2\theta-1}\right)\\ &= \cos^{-1}\left(\frac1{\sqrt2}\cos\theta\right)
\end{align} \frac1{\sqrt2}\theta","['calculus', 'derivatives', 'trigonometry', 'inverse-function', 'substitution']"
55,Finding whether $\int_{0}^{\pi/2}\frac{\rm dt}{\sqrt{1-x\cos^2{t}}}$ is increasing or decreasing,Finding whether  is increasing or decreasing,\int_{0}^{\pi/2}\frac{\rm dt}{\sqrt{1-x\cos^2{t}}},"I'm trying to find if $$f(x)=\int_{0}^{\pi/2}\dfrac{\rm dt}{\sqrt{1-x\cos^2{t}}}\;,\;\text{where}\; x \in (0,1)$$ is increasing or decreasing. My Attempt: Using DUIS to find $f'(x)$ , We get $$f'(x)=\int_{0}^{\pi/2}\dfrac{\cos^2t\;\rm dt}{{2(1-x\cos^2{t})}^{3/2}}$$ How to proceed further?","I'm trying to find if is increasing or decreasing. My Attempt: Using DUIS to find , We get How to proceed further?","f(x)=\int_{0}^{\pi/2}\dfrac{\rm dt}{\sqrt{1-x\cos^2{t}}}\;,\;\text{where}\; x \in (0,1) f'(x) f'(x)=\int_{0}^{\pi/2}\dfrac{\cos^2t\;\rm dt}{{2(1-x\cos^2{t})}^{3/2}}","['calculus', 'derivatives', 'inequality', 'definite-integrals']"
56,What is the source of this derivative formula,What is the source of this derivative formula,,"We have just proved the n-th derivative of $f(x)=e^{-x}p(x)$ , where $p(x)$ is a polynomial. We got: $$f(x)^{(n)}= e^{-x}(-1)^n\sum_{k=0}^{n}\binom{n}{k}(-1)^kp^{(k)}$$ Even though I do not completely understand the proof, I wonder, if there is a more general formula for expressions similar to this or if it has a name, so that I can look it up.","We have just proved the n-th derivative of , where is a polynomial. We got: Even though I do not completely understand the proof, I wonder, if there is a more general formula for expressions similar to this or if it has a name, so that I can look it up.",f(x)=e^{-x}p(x) p(x) f(x)^{(n)}= e^{-x}(-1)^n\sum_{k=0}^{n}\binom{n}{k}(-1)^kp^{(k)},"['real-analysis', 'calculus', 'derivatives']"
57,Second normal derivative on a curved boundary,Second normal derivative on a curved boundary,,"The motivation is that I am trying to understand the equation $$\tag{1}\label{eq:1}u_{nn} - \Delta u = -(\kappa u_n + u_{tt})$$ on the boundary $\partial\Omega$ of some bounded open set $\Omega\subset\mathbb R^2$ ( $\kappa$ is the signed curvature of the boundary). Basically, if $\partial \Omega$ is piecewise straight, then $\kappa=0$ and the tangential $t$ and normal $n$ simply form a local coordinate system by rotating the standard coordinates and hence \eqref{eq:1} is clear since the Laplacian $\Delta u := D^2u(x_1,x_1) + D^2u(x_2,x_2) = D^2u(t,t) + D^2u(n,n)$ is invariant under such rotation. In the case of arbitrary, say piecewise $C^2$ , boundary I am a bit confused. What does $u_{tt}$ and $u_{nn}$ even stand for, it cannot simply be $D^2u(t,t)$ and $D^2u(n,n)$ since then there would be no curvature term in \eqref{eq:1}. My intuition for $u_{tt}$ : The tangential derivative $u_t=\frac{\partial}{\partial t} u=\nabla u\cdot t$ can be written as $\frac{d}{ds}u(\gamma(s))$ for some arc-length parametrisation $\gamma$ of the boundary. Hence $u_{tt} = \frac{d^2}{ds^2}u(\gamma(s)) = D^2u(\gamma'(s), \gamma'(s)) + \nabla u\cdot \gamma''(s)= D^2u(t(s), t(s)) - \kappa u_n$ since $\gamma'(s)= t(s), \gamma''(s) = -\kappa n(s)$ . For $u_{nn}$ : The normal derivative $\frac{\partial}{\partial n} u_n$ as a directional derivative is the limit when approaching the boundary normally, but $u_n$ is only defined on the boundary. So does this mean that for any extension $n^*$ of the normal field $n$ , that $\frac{\partial}{\partial n} u_n = \frac{\partial}{\partial n} u_{n^*}$ is equal? And how to see this? Is there a better way of interpreting $u_{nn}$ in the first place? I guess I am making this way to complicated - thanks for your help!","The motivation is that I am trying to understand the equation on the boundary of some bounded open set ( is the signed curvature of the boundary). Basically, if is piecewise straight, then and the tangential and normal simply form a local coordinate system by rotating the standard coordinates and hence \eqref{eq:1} is clear since the Laplacian is invariant under such rotation. In the case of arbitrary, say piecewise , boundary I am a bit confused. What does and even stand for, it cannot simply be and since then there would be no curvature term in \eqref{eq:1}. My intuition for : The tangential derivative can be written as for some arc-length parametrisation of the boundary. Hence since . For : The normal derivative as a directional derivative is the limit when approaching the boundary normally, but is only defined on the boundary. So does this mean that for any extension of the normal field , that is equal? And how to see this? Is there a better way of interpreting in the first place? I guess I am making this way to complicated - thanks for your help!","\tag{1}\label{eq:1}u_{nn} - \Delta u = -(\kappa u_n + u_{tt}) \partial\Omega \Omega\subset\mathbb R^2 \kappa \partial \Omega \kappa=0 t n \Delta u := D^2u(x_1,x_1) + D^2u(x_2,x_2) = D^2u(t,t) + D^2u(n,n) C^2 u_{tt} u_{nn} D^2u(t,t) D^2u(n,n) u_{tt} u_t=\frac{\partial}{\partial t} u=\nabla u\cdot t \frac{d}{ds}u(\gamma(s)) \gamma u_{tt} = \frac{d^2}{ds^2}u(\gamma(s)) = D^2u(\gamma'(s), \gamma'(s)) + \nabla u\cdot \gamma''(s)= D^2u(t(s), t(s)) - \kappa u_n \gamma'(s)= t(s), \gamma''(s) = -\kappa n(s) u_{nn} \frac{\partial}{\partial n} u_n u_n n^* n \frac{\partial}{\partial n} u_n = \frac{\partial}{\partial n} u_{n^*} u_{nn}","['derivatives', 'differential-geometry', 'partial-derivative', 'plane-curves', 'laplacian']"
58,How to find $F^{(n+1)}(x)$ if $F(x)=\int_0^x(x-t)^nu(t)dt$?,How to find  if ?,F^{(n+1)}(x) F(x)=\int_0^x(x-t)^nu(t)dt,"if $F(x)=\int_0^x(x-t)^nu(t)dt$ then find $F^{(n+1)}(x)$ from Leibniz rule $a(x)=0,b(x)=x,a'(x)=0,b'(x)=1$ and $G'(x)=n(x-t)^{n-1}\\$ so $F^{(1)}(x)=n\int_0^x(x-t)^{n-1}u(t)dt$ and $F^{(n)}(x)=n.(n-1).(n-2)...1\int_0^x(x-t)^{n-n}u(t)dt=n!\int_0^xu(t)dt$ . How can I continue from here? is it $F^{(n+1)}(x)=0$ because applying Leibniz rule one more time gives $G'(x)=0$ ?",if then find from Leibniz rule and so and . How can I continue from here? is it because applying Leibniz rule one more time gives ?,"F(x)=\int_0^x(x-t)^nu(t)dt F^{(n+1)}(x) a(x)=0,b(x)=x,a'(x)=0,b'(x)=1 G'(x)=n(x-t)^{n-1}\\ F^{(1)}(x)=n\int_0^x(x-t)^{n-1}u(t)dt F^{(n)}(x)=n.(n-1).(n-2)...1\int_0^x(x-t)^{n-n}u(t)dt=n!\int_0^xu(t)dt F^{(n+1)}(x)=0 G'(x)=0","['calculus', 'derivatives', 'leibniz-integral-rule']"
59,Values of k such that $f(x)=x^k|x|$ is 3 times differentiable at the origin,Values of k such that  is 3 times differentiable at the origin,f(x)=x^k|x|,"We must find values of k such that $f(x)=x^k|x|$ is 3 times differentiable at the origin. Firstly we can view the question as a product of two functions $g(x)=x^k$ and $h(x)=|x|$ You may obtain the result of triple product rule as a function in terms of $f'$ s and $h'$ s It is clear to me that $h'$ nor $h''$ is not differentiable at the origin since the denominator of both contains a x, however I was unable to obtain a third derivative of h Thus all terms containing a h prime terms must be cancelled out by the f components, which clearly have zeros at $k=0,1,2$ respectively of their times differentiated This leads to the only solution being $k=0$ which cancels out all of the absolute value terms, but I suspect that this cannot be correct, is my intuition correct or is there some piece I am missing to solve this? EDIT : should be product of functions not composition","We must find values of k such that is 3 times differentiable at the origin. Firstly we can view the question as a product of two functions and You may obtain the result of triple product rule as a function in terms of s and s It is clear to me that nor is not differentiable at the origin since the denominator of both contains a x, however I was unable to obtain a third derivative of h Thus all terms containing a h prime terms must be cancelled out by the f components, which clearly have zeros at respectively of their times differentiated This leads to the only solution being which cancels out all of the absolute value terms, but I suspect that this cannot be correct, is my intuition correct or is there some piece I am missing to solve this? EDIT : should be product of functions not composition","f(x)=x^k|x| g(x)=x^k h(x)=|x| f' h' h' h'' k=0,1,2 k=0","['real-analysis', 'calculus', 'derivatives', 'absolute-value']"
60,How to get the derivative based on the function?,How to get the derivative based on the function?,,"Based on $f(x) = x^2$ , we know $f'(x) = 2x$ . If $x = y^2$ Then $f(y) = (y^2)^2 = y^4$ , and $f'(y) = 4y^3$ . My question is if we only know $f'(x) = 2x$ $x = y^2$ How to get $f'(y) = 4y^3$ ? Any hint or formula will be helpful. Thanks","Based on , we know . If Then , and . My question is if we only know How to get ? Any hint or formula will be helpful. Thanks",f(x) = x^2 f'(x) = 2x x = y^2 f(y) = (y^2)^2 = y^4 f'(y) = 4y^3 f'(x) = 2x x = y^2 f'(y) = 4y^3,['derivatives']
61,Does comparing a function against $x^N$ ensure $N$ times differentiable?,Does comparing a function against  ensure  times differentiable?,x^N N,"If $$\lim_{x \to 0} \frac{f(x)}{x^N} = 0,$$ does that automatically ensure that $f$ has an $N^\text{th}$ derivative at $0$ ? Noting that that would require an $(N-1)^\text{st}$ derivative in an interval around $0$ , it seems unlikely to me that this implication is true, but I also can't find a counterexample. Note that the corresponding question for a more general Taylor polynomial would be: does $$\lim_{\Delta x \to 0} \frac{f(x_0+\Delta x)-g(x_0 + \Delta x)}{(\Delta x)^N} = 0,$$ with $g$ a degree $N$ polynomial, force $f$ to be $N$ times differentiable at $x_0$ with Taylor polynomial $g(x)$ ? This question is equivalent by an appropriate substitution. Note that the statement is true for $N=1$ , and can be considered true for $N=0$ if you define $0$ times differentiable at a point as continuous at that point. So a counterexample would have to be constructed for $N \ge 2$ .","If does that automatically ensure that has an derivative at ? Noting that that would require an derivative in an interval around , it seems unlikely to me that this implication is true, but I also can't find a counterexample. Note that the corresponding question for a more general Taylor polynomial would be: does with a degree polynomial, force to be times differentiable at with Taylor polynomial ? This question is equivalent by an appropriate substitution. Note that the statement is true for , and can be considered true for if you define times differentiable at a point as continuous at that point. So a counterexample would have to be constructed for .","\lim_{x \to 0} \frac{f(x)}{x^N} = 0, f N^\text{th} 0 (N-1)^\text{st} 0 \lim_{\Delta x \to 0} \frac{f(x_0+\Delta x)-g(x_0 + \Delta x)}{(\Delta x)^N} = 0, g N f N x_0 g(x) N=1 N=0 0 N \ge 2","['calculus', 'derivatives', 'taylor-expansion']"
62,"Determine $f^{(22)}(0)$, when $f(x)=x^{19}\ln(1+2x)$","Determine , when",f^{(22)}(0) f(x)=x^{19}\ln(1+2x),"""Determine $f^{(22)}(0)$ , when $f(x)=x^{19}\ln(1+2x)$ ."" Here is my attempt. First, I wrote $f=gh$ , where $g=x^{19}$ and $h=\ln(1+2x)$ . The derivatives of both of these functions behave predictably at $x=0$ . For example, $g^{19} = 19!$ , taking further derivatives simply yields zero, and previous derivatives at $x=0$ are also zero, since they contain $x$ as a multiplier. The derivatives of $h$ behave according to this sequence $$\frac{{x_n}}{(1+2x)^n}$$ where ${x_n}=\{2,-4,16,-96,768,...\}.$ The denominator is $(1+2x)^n=(1+2 \cdot 0)^n=1^n =1$ , so the value of $h'$ is simply the value of the sequence at $n\in \Bbb{N}.$ Next I tried to find a pattern in the application of the product rule with $f=gh$ . Multiple applications yields $$f^1=g^1h+gh^1$$ $$f^2=g^2h+g^1h^1+g^1h^1+gh^2$$ $$f^3 = g^3h+g^2h^1+g^2h^1+g^1h^2+g^2h^1+g^1h^2+g^1h^2+gh^3$$ $$...$$ The idea was to find a way to connect $g^{19}$ with the correct values of $h'$ , then compute the value of $f^{22}$ with the help of these simple derivatives. I haven't found one yet, but I think it might be possible to find a pattern in repeated applications of the product rule, but before that I wanted to ask whether there is some flaw in my work. Also, I'm not entirely sure about this but might this https://en.wikipedia.org/wiki/General_Leibniz_rule help here?","""Determine , when ."" Here is my attempt. First, I wrote , where and . The derivatives of both of these functions behave predictably at . For example, , taking further derivatives simply yields zero, and previous derivatives at are also zero, since they contain as a multiplier. The derivatives of behave according to this sequence where The denominator is , so the value of is simply the value of the sequence at Next I tried to find a pattern in the application of the product rule with . Multiple applications yields The idea was to find a way to connect with the correct values of , then compute the value of with the help of these simple derivatives. I haven't found one yet, but I think it might be possible to find a pattern in repeated applications of the product rule, but before that I wanted to ask whether there is some flaw in my work. Also, I'm not entirely sure about this but might this https://en.wikipedia.org/wiki/General_Leibniz_rule help here?","f^{(22)}(0) f(x)=x^{19}\ln(1+2x) f=gh g=x^{19} h=\ln(1+2x) x=0 g^{19} = 19! x=0 x h \frac{{x_n}}{(1+2x)^n} {x_n}=\{2,-4,16,-96,768,...\}. (1+2x)^n=(1+2 \cdot 0)^n=1^n =1 h' n\in \Bbb{N}. f=gh f^1=g^1h+gh^1 f^2=g^2h+g^1h^1+g^1h^1+gh^2 f^3 = g^3h+g^2h^1+g^2h^1+g^1h^2+g^2h^1+g^1h^2+g^1h^2+gh^3 ... g^{19} h' f^{22}","['real-analysis', 'derivatives']"
63,Distance between two curves,Distance between two curves,,"Consider the following subsets of the plane: $$ C_1=\{(x,y): x>0, y=\frac{1}{x}\} $$ and $$ C_2=\{(x,y):x<0,y=-1+\frac{1}{x}\}. $$ Given any two points $P=(x,y)$ and $Q=(u,v)$ of the plane, their distance $d(P,Q)$ is defined by $$ d(P,Q)=\sqrt{(x-u)^2+(y-v)^2}. $$ Show that there exists a unique choice of points $P_0\in C_1$ and $Q_0\in C_2$ such that $$ d(P_0,Q_0)\leq d(P,Q) \mbox{ for all } P\in C_1 \mbox{ and } Q\in C_2. $$ Here if I take two points $p(x,\frac{1}{x}) \in C_1$ and $Q(-x, -1-\frac{1}{x}) \in C_2$ for $x>0$ , then I take their distance and take the derivative and prove that there exists a unique point at which the minima occurs. But I cannot justify my choice of the point $Q \in C_2$ , the point could have been $Q(-x^{'} ,-1-\frac{1}{x^{'}})$ . But my intuition says that the minimum will occur when I take the same variable for both the points and also it has something to do with the symmetry of the curves.  My problem is I am not being able to give a mathematical proof of my intuition.","Consider the following subsets of the plane: and Given any two points and of the plane, their distance is defined by Show that there exists a unique choice of points and such that Here if I take two points and for , then I take their distance and take the derivative and prove that there exists a unique point at which the minima occurs. But I cannot justify my choice of the point , the point could have been . But my intuition says that the minimum will occur when I take the same variable for both the points and also it has something to do with the symmetry of the curves.  My problem is I am not being able to give a mathematical proof of my intuition.","
C_1=\{(x,y): x>0, y=\frac{1}{x}\}
 
C_2=\{(x,y):x<0,y=-1+\frac{1}{x}\}.
 P=(x,y) Q=(u,v) d(P,Q) 
d(P,Q)=\sqrt{(x-u)^2+(y-v)^2}.
 P_0\in C_1 Q_0\in C_2 
d(P_0,Q_0)\leq d(P,Q) \mbox{ for all } P\in C_1 \mbox{ and } Q\in C_2.
 p(x,\frac{1}{x}) \in C_1 Q(-x, -1-\frac{1}{x}) \in C_2 x>0 Q \in C_2 Q(-x^{'} ,-1-\frac{1}{x^{'}})","['calculus', 'derivatives', 'curves', 'plane-curves']"
64,"Prove that if $f$ is continuous and differentiable on $\mathbb{R}$ and has three roots, then its derivative $f′$ has at least two roots.","Prove that if  is continuous and differentiable on  and has three roots, then its derivative  has at least two roots.",f \mathbb{R} f′,"I know that we are supposed to use Mean Value THeorem for this question. So from the theorem, if $f$ is continuous on an interval $[a,b]$ and has two roots, this means that there is a point $c\in [a,b]$ where $f'(x)=0.$ But is this logic correct for $3$ roots? I am not sure if I understand how to construct a proof here.","I know that we are supposed to use Mean Value THeorem for this question. So from the theorem, if is continuous on an interval and has two roots, this means that there is a point where But is this logic correct for roots? I am not sure if I understand how to construct a proof here.","f [a,b] c\in [a,b] f'(x)=0. 3","['calculus', 'derivatives', 'continuity']"
65,"$f(x) = \frac{4 + x}{2 + x - x^2}$, calculate $f^{(9)}(1)$",", calculate",f(x) = \frac{4 + x}{2 + x - x^2} f^{(9)}(1),"$f(x) = \frac{4 + x}{2 + x - x^2}$ , calculate $f^{(9)}(1)$ , where $f^{(9)}$ is the $9$ -th derivative of $f$ . Domain of $f$ is $\mathbb{R} - \{-1, 2\}$ . I've got that $f(x) = \frac{1}{1 - (-x)} + \frac{1}{1 - \frac{1}{2}x} = \sum_{n=0}^\infty ((-1)^n + 2^{-n})x^n$ , but there is a problem that $\frac{1}{1 - (-x)} = \sum_{n=0}^\infty (-1)^nx^n$ is convergent only for $|x| < 1$ , so not for $1$ . How can I go about this?",", calculate , where is the -th derivative of . Domain of is . I've got that , but there is a problem that is convergent only for , so not for . How can I go about this?","f(x) = \frac{4 + x}{2 + x - x^2} f^{(9)}(1) f^{(9)} 9 f f \mathbb{R} - \{-1, 2\} f(x) = \frac{1}{1 - (-x)} + \frac{1}{1 - \frac{1}{2}x} = \sum_{n=0}^\infty ((-1)^n + 2^{-n})x^n \frac{1}{1 - (-x)} = \sum_{n=0}^\infty (-1)^nx^n |x| < 1 1","['sequences-and-series', 'derivatives', 'taylor-expansion', 'partial-fractions']"
66,"Differentiation applied in Physics, need to clear a little doubt.","Differentiation applied in Physics, need to clear a little doubt.",,"So, again my over-curiosity arose a problem for me, this time in Physics class. Being able to solve the questions sir gave me before the time limit, I was told to solve another, a little tougher. This is the exact words of my Physics Teacher : ""A particle of unit mass undergoes $1$ -dimensional motion such that its velocity expressed as a function of its position is: $$V(x) = bx^{-2n}$$ where, $b$ and $n$ are constants, and $x$ denotes the position of the particle. Prove that, Acceleration $a$ varies with $x$ ."" Now, I spent a lot of time and came up with this : $$a = \frac{dv}{dt} = \left(\frac{dv}{dx}\right)\left(\frac{dx}{dt}\right)$$ By definition, $\frac{dx}{dt} = V(t)$ . But Velocity is expressed as a function of position, not time. Despite that, I went ahead and put $V(x)$ . That gave me $$a = \frac{dv}{dt} = \left(\frac{dv}{dx}\right)\left(\frac{dx}{dt}\right)$$ $$= \frac{d}{dx}(bx^{-2n}) * V(x)$$ $$= -2nbx^{-2n - 1} * bx^{-2n}$$ $$= -2nb^2x^{-4n - 1}$$ My teacher said I was correct. But what about $V(t)$ ? The function I put into calculation is $V(x)$ , not the $V(t)$ we're supposed to put normally. Is $V(x) = V(t)$ ? If it is, How can we prove it? How can we proceed with this?","So, again my over-curiosity arose a problem for me, this time in Physics class. Being able to solve the questions sir gave me before the time limit, I was told to solve another, a little tougher. This is the exact words of my Physics Teacher : ""A particle of unit mass undergoes -dimensional motion such that its velocity expressed as a function of its position is: where, and are constants, and denotes the position of the particle. Prove that, Acceleration varies with ."" Now, I spent a lot of time and came up with this : By definition, . But Velocity is expressed as a function of position, not time. Despite that, I went ahead and put . That gave me My teacher said I was correct. But what about ? The function I put into calculation is , not the we're supposed to put normally. Is ? If it is, How can we prove it? How can we proceed with this?",1 V(x) = bx^{-2n} b n x a x a = \frac{dv}{dt} = \left(\frac{dv}{dx}\right)\left(\frac{dx}{dt}\right) \frac{dx}{dt} = V(t) V(x) a = \frac{dv}{dt} = \left(\frac{dv}{dx}\right)\left(\frac{dx}{dt}\right) = \frac{d}{dx}(bx^{-2n}) * V(x) = -2nbx^{-2n - 1} * bx^{-2n} = -2nb^2x^{-4n - 1} V(t) V(x) V(t) V(x) = V(t),"['calculus', 'derivatives']"
67,"Find $f^{(n)}(0) \text{ for } n = 1,2,3,...$",Find,"f^{(n)}(0) \text{ for } n = 1,2,3,...","Find $f^{(n)}(0) \text{ for } n = 1,2,3,...$ where $$ f(x) = \begin{cases} \frac{e^x - 1}{x}, & \text{when } x \neq 0 \\ 1, & \text{when } x = 0 \\ \end{cases} $$ My approach I decided to calculate some first $f$ derivatives. In that case I defined: $$ g(x) = \frac{e^x - 1}{x} \text{ for } x\neq0$$ $$g'(x) = ...= \frac{e^x x-e^x+1}{x^2} $$ $$g''(x) = \text{..a lot of calculus..} =\frac{e^x x^2-2 e^x x+2 e^x-2}{x^3} $$ $$ g^{(3)}(x) = ... = \frac{e^x x^3-3 e^x x^2+6 e^x x-6 e^x+6}{x^4}  $$ $$ g^{(4)}(x) = \frac{e^x x^4-4 e^x x^3+12 e^x x^2-24 e^x x+24 e^x-24}{x^5}$$ But I don't see a pattern. Some of last factors are $n!$ . Denominator is $x^{n-1}$ . But for the rest I haven't got idea. I know also that for $n>0$ $$ f^{(n)}(x) = \begin{cases} \frac{e^x - 1}{x}, & \text{when } x \neq 0 \\ 0, & \text{when } x = 0 \\ \end{cases} $$ so theoretically the answer is just $ 0 $ but I am not sure if solution can be so simple...",Find where My approach I decided to calculate some first derivatives. In that case I defined: But I don't see a pattern. Some of last factors are . Denominator is . But for the rest I haven't got idea. I know also that for so theoretically the answer is just but I am not sure if solution can be so simple...,"f^{(n)}(0) \text{ for } n = 1,2,3,...  f(x) = \begin{cases}
\frac{e^x - 1}{x}, & \text{when } x \neq 0 \\
1, & \text{when } x = 0 \\
\end{cases}  f  g(x) = \frac{e^x - 1}{x} \text{ for } x\neq0 g'(x) = ...= \frac{e^x x-e^x+1}{x^2}  g''(x) = \text{..a lot of calculus..} =\frac{e^x x^2-2 e^x x+2 e^x-2}{x^3}   g^{(3)}(x) = ... = \frac{e^x x^3-3 e^x x^2+6 e^x x-6 e^x+6}{x^4}    g^{(4)}(x) = \frac{e^x x^4-4 e^x x^3+12 e^x x^2-24 e^x x+24 e^x-24}{x^5} n! x^{n-1} n>0  f^{(n)}(x) = \begin{cases}
\frac{e^x - 1}{x}, & \text{when } x \neq 0 \\
0, & \text{when } x = 0 \\
\end{cases}   0 ","['real-analysis', 'derivatives']"
68,a non-zero continuous function with compact support and its derivatives are zero at zero,a non-zero continuous function with compact support and its derivatives are zero at zero,,"I am looking for a continuous function with support compact, which its derivates are zero at zero, it means $f'(0)=0$ , $f''(0)=0$ ..., I have seen this question All derivatives zero at a point $\implies$ constant function? . So, I know that one answers is a flat function but the difference is that I want a function such that $f(0)\neq0$ Maybe, that function is piecewise function or something different. I've tried to build it but I couldn't, any help, please?","I am looking for a continuous function with support compact, which its derivates are zero at zero, it means , ..., I have seen this question All derivatives zero at a point $\implies$ constant function? . So, I know that one answers is a flat function but the difference is that I want a function such that Maybe, that function is piecewise function or something different. I've tried to build it but I couldn't, any help, please?",f'(0)=0 f''(0)=0 f(0)\neq0,"['real-analysis', 'derivatives', 'continuity']"
69,Why are the local extrema of a log-transformed function equal to local extrema of the original function?,Why are the local extrema of a log-transformed function equal to local extrema of the original function?,,"I am studying maximum likelihood and to simplify taking the derivative of the likelihood function, it is often transformed by the natural log before taking the derivative. I have read in other posts that this is because the logarithm is a monotonic function, so its extrema will be the same as the original function. However, I do not understand why this is the case. Can someone explain intuitively why the transformation does not affect the local extrema?","I am studying maximum likelihood and to simplify taking the derivative of the likelihood function, it is often transformed by the natural log before taking the derivative. I have read in other posts that this is because the logarithm is a monotonic function, so its extrema will be the same as the original function. However, I do not understand why this is the case. Can someone explain intuitively why the transformation does not affect the local extrema?",,"['derivatives', 'logarithms', 'maximum-likelihood', 'monotone-functions']"
70,Conclusions about derivability of a function $f(x)=x\left|{\log{x}}\right|$,Conclusions about derivability of a function,f(x)=x\left|{\log{x}}\right|,"I want to study the derivability of this function $$f(x)=x\left|{\log{x}}\right|$$ My textbook says the function is defined for $x>0$ (easy to understand for me, the argument of the logarithm must be positive) and it says: ""it can certainly be derived for $x\neq 1$"". I wonder how my textbook reached this conclusion without deriving the function first. I'm aware derivatives are defined like this: $$\lim_{h\rightarrow0}{\frac{f(x_0+h)-f(x_0)}{h}}$$ Although I can't understand how we can reach conclusions about derivability just by looking at the function. Any hints?","I want to study the derivability of this function $$f(x)=x\left|{\log{x}}\right|$$ My textbook says the function is defined for $x>0$ (easy to understand for me, the argument of the logarithm must be positive) and it says: ""it can certainly be derived for $x\neq 1$"". I wonder how my textbook reached this conclusion without deriving the function first. I'm aware derivatives are defined like this: $$\lim_{h\rightarrow0}{\frac{f(x_0+h)-f(x_0)}{h}}$$ Although I can't understand how we can reach conclusions about derivability just by looking at the function. Any hints?",,['derivatives']
71,"$\frac{d}{dx} \int_a^b f(x,t) dt =\int_a^b \frac{\partial}{\partial x}f(x,t)dt?$",,"\frac{d}{dx} \int_a^b f(x,t) dt =\int_a^b \frac{\partial}{\partial x}f(x,t)dt?","I have studied Advanced Calculus by Fitzpatrick which discusses the so called the Second Fundamental Theorem (Differentiating Integrals) but it is when the upper or lower limits of integral is a function of $x$ and differentiation is on $x$. But differentiation of the type in the title is not discussed at all and is used in another textbook without a proof; so what is a clear proof for equation $$\dfrac{d}{dx} \int_a^b f(x,t) \ dt =\int_a^b \frac{\partial}{\partial x}f(x,t) \ dt?$$","I have studied Advanced Calculus by Fitzpatrick which discusses the so called the Second Fundamental Theorem (Differentiating Integrals) but it is when the upper or lower limits of integral is a function of $x$ and differentiation is on $x$. But differentiation of the type in the title is not discussed at all and is used in another textbook without a proof; so what is a clear proof for equation $$\dfrac{d}{dx} \int_a^b f(x,t) \ dt =\int_a^b \frac{\partial}{\partial x}f(x,t) \ dt?$$",,"['real-analysis', 'integration']"
72,Partial derivative of $e^{x^2 + 2y^2 + 3z^2}$,Partial derivative of,e^{x^2 + 2y^2 + 3z^2},"Find $f_y$ of $e^{x^2 + 2y^2 + 3z^2}$ How do I do this ? I am trying to follow the formula of - $\frac{d}{dx} e^{ax +b} = ae^{ax+b} $ Since I am differentiating the independent variable of y, Why isn’t the partial derivative $ (f_y)$ of $e^{x^2 + 2y^2 + 3z^2} = 2e^{x^2 + 2y^2 + 3z^2} \frac{\partial}{\partial y} (x^2 + 2y^2 + 3z^2) $ ? In fact the workings is - $e^{x^2 + 2y^2 + 3z^2} \frac{\partial}{\partial y} (x^2 + 2y^2 + 3z^2) $ Why isn’t the ‘2’ infront if $e$ ?","Find $f_y$ of $e^{x^2 + 2y^2 + 3z^2}$ How do I do this ? I am trying to follow the formula of - $\frac{d}{dx} e^{ax +b} = ae^{ax+b} $ Since I am differentiating the independent variable of y, Why isn’t the partial derivative $ (f_y)$ of $e^{x^2 + 2y^2 + 3z^2} = 2e^{x^2 + 2y^2 + 3z^2} \frac{\partial}{\partial y} (x^2 + 2y^2 + 3z^2) $ ? In fact the workings is - $e^{x^2 + 2y^2 + 3z^2} \frac{\partial}{\partial y} (x^2 + 2y^2 + 3z^2) $ Why isn’t the ‘2’ infront if $e$ ?",,"['calculus', 'derivatives', 'partial-derivative']"
73,Proof of dy=f’(x)dx,Proof of dy=f’(x)dx,,"I’ve been wondering about the usage of $dy=f’(x)dx$ in my textbook. There’s not a single justification of how it is proved and it just states that it is true. Since $dy/dx$ can’t be assumed as a fraction, I’m guessing there’s more to it than just multiplying by $dx$ on both sides. Are there any proofs to this equation? Also with some research, I found this “proof”. Can it be done this way? $dy=f’(x)dx$ “proof” (Please keep this in high school level)","I’ve been wondering about the usage of $dy=f’(x)dx$ in my textbook. There’s not a single justification of how it is proved and it just states that it is true. Since $dy/dx$ can’t be assumed as a fraction, I’m guessing there’s more to it than just multiplying by $dx$ on both sides. Are there any proofs to this equation? Also with some research, I found this “proof”. Can it be done this way? $dy=f’(x)dx$ “proof” (Please keep this in high school level)",,['derivatives']
74,Let $f'(x)=e^{x^2}$; compute $\lim_{x\to0}\frac{f(2)-f(x+2)}x$,Let ; compute,f'(x)=e^{x^2} \lim_{x\to0}\frac{f(2)-f(x+2)}x,"Let $f : [0,\infty] \to \mathbb{R}$ be a function such that its derivative $f'(x)=e^{x^2}$. Compute $$\lim_{x\to 0} \frac{f(2)-f(x+2)}{x}$$ The definition of the derivative is $$f'(a)= \lim_{x\to 0} \frac{f(a+x)-f(a)}{x}$$ so if $f'(a)=e^{a^2}$ then $$e^{a^2}=\lim_{x\to 0} \frac{f(a+x)-f(a)}{x}$$ if $a=2$ then $$e^{a^2}=\lim_{x\to 0} \frac{f(2+x)-f(2)}{x}$$ I'm a little bit stumped here, my naive approach would be to multiply both sides by $(-1)$ and get that the answer is $-e^{2^2}$ but I don't think I can do that.","Let $f : [0,\infty] \to \mathbb{R}$ be a function such that its derivative $f'(x)=e^{x^2}$. Compute $$\lim_{x\to 0} \frac{f(2)-f(x+2)}{x}$$ The definition of the derivative is $$f'(a)= \lim_{x\to 0} \frac{f(a+x)-f(a)}{x}$$ so if $f'(a)=e^{a^2}$ then $$e^{a^2}=\lim_{x\to 0} \frac{f(a+x)-f(a)}{x}$$ if $a=2$ then $$e^{a^2}=\lim_{x\to 0} \frac{f(2+x)-f(2)}{x}$$ I'm a little bit stumped here, my naive approach would be to multiply both sides by $(-1)$ and get that the answer is $-e^{2^2}$ but I don't think I can do that.",,"['calculus', 'derivatives']"
75,Find the derivative of this function at $x_o = \pi$,Find the derivative of this function at,x_o = \pi,"Find the derivative of $g(x)= (\tan \left|x\right| + x )\sin(x) $ at $x_o = \pi$. I tried to solve it using $\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$, but I got stuck at this point: $\lim_{h \to 0} \ \frac {\tan \left|\pi+ h\right| + \pi+h )\sin(\pi+h)-\tan \left|\pi\right| + \pi )\sin(\pi)}{h}$. Since $h \to 0$, it seems to me that the derivative is $0$, but I have no idea how to prove it.","Find the derivative of $g(x)= (\tan \left|x\right| + x )\sin(x) $ at $x_o = \pi$. I tried to solve it using $\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$, but I got stuck at this point: $\lim_{h \to 0} \ \frac {\tan \left|\pi+ h\right| + \pi+h )\sin(\pi+h)-\tan \left|\pi\right| + \pi )\sin(\pi)}{h}$. Since $h \to 0$, it seems to me that the derivative is $0$, but I have no idea how to prove it.",,"['calculus', 'derivatives']"
76,How to show that $\frac{d^n}{dx^n} (x^2-1)^n = 2^n \cdot n!$ for $x=1$,How to show that  for,\frac{d^n}{dx^n} (x^2-1)^n = 2^n \cdot n! x=1,"I am trying to show that $$ \frac{d^n}{dx^n} (x^2-1)^n = 2^n \cdot n!, $$ for $x = 1$. I tried to prove it by induction but I failed because I lack  axioms and rules for this type of derivatives. Can someone give me a hint?","I am trying to show that $$ \frac{d^n}{dx^n} (x^2-1)^n = 2^n \cdot n!, $$ for $x = 1$. I tried to prove it by induction but I failed because I lack  axioms and rules for this type of derivatives. Can someone give me a hint?",,"['real-analysis', 'derivatives', 'legendre-polynomials']"
77,Why must it be true that approximating all the derivatives gives you the original function?,Why must it be true that approximating all the derivatives gives you the original function?,,"I am trying to understand the intuition behind Taylor/Maclaurin series. You have some differentiable function $f(x)$ and you want to make a series $g(x)$ where $f^{n}(x) = g^{n}(x)$, i.e. the $n$th derivatives of each give you the same output for some input. Assuming we have this matching derivative output concept in place, how do we know this necessarily means $f(x)$ and $g(x)$ are equivalent representations of each other? Normally these approximations are made in the neighborhood of $x=0$ (and yes we could use $x=a$ but for simplicity I'd like to stick with $0$), so it makes sense that $f(x)$ and $g(x)$ are equal for any $n$th derivative you want to compute at $x=0$ since that is how we derived $g(x)$ in the first place. But what exactly lets us then take $g(x)$ and say ""This will also work for any other $x$, not just $0$, since it is an equivalent to $f(x)$""? In other words I don't see why it is obvious that through the method of creating the Taylor/Maclaurin series $g(x)$ we must necessarily have an equivalent for $f(x)$.","I am trying to understand the intuition behind Taylor/Maclaurin series. You have some differentiable function $f(x)$ and you want to make a series $g(x)$ where $f^{n}(x) = g^{n}(x)$, i.e. the $n$th derivatives of each give you the same output for some input. Assuming we have this matching derivative output concept in place, how do we know this necessarily means $f(x)$ and $g(x)$ are equivalent representations of each other? Normally these approximations are made in the neighborhood of $x=0$ (and yes we could use $x=a$ but for simplicity I'd like to stick with $0$), so it makes sense that $f(x)$ and $g(x)$ are equal for any $n$th derivative you want to compute at $x=0$ since that is how we derived $g(x)$ in the first place. But what exactly lets us then take $g(x)$ and say ""This will also work for any other $x$, not just $0$, since it is an equivalent to $f(x)$""? In other words I don't see why it is obvious that through the method of creating the Taylor/Maclaurin series $g(x)$ we must necessarily have an equivalent for $f(x)$.",,"['calculus', 'sequences-and-series', 'derivatives', 'taylor-expansion']"
78,What will be the derivative $2 (\ln (x))^{x/2}$?,What will be the derivative ?,2 (\ln (x))^{x/2},"I'm not sure, that my steps are valid, so $ln(f(x))=ln \cdot (2 \cdot ln(x))^{x/2}=x^{2} \cdot ln \cdot(ln(x))$ so I get $\frac{1}{f(x)} \cdot f'(x)$ and I have to multiply both sides with $f(x)$, am I right?","I'm not sure, that my steps are valid, so $ln(f(x))=ln \cdot (2 \cdot ln(x))^{x/2}=x^{2} \cdot ln \cdot(ln(x))$ so I get $\frac{1}{f(x)} \cdot f'(x)$ and I have to multiply both sides with $f(x)$, am I right?",,['derivatives']
79,"How to prove that $|\ln(2+\sin(x)) - \ln(2+\sin(y))| <= |x-y| \space \forall \space x,y \in \mathbb R$",How to prove that,"|\ln(2+\sin(x)) - \ln(2+\sin(y))| <= |x-y| \space \forall \space x,y \in \mathbb R","Question states Prove that for all $x$ and $y$ $\in R$, the following inequality is true: $\lvert \ln(2+\sin(x)) - \ln(2+\sin(y))\rvert \le \lvert x-y\rvert$ i've gotten to the point that $\frac{y-x}{2+\sin(c)}  = \ln\frac{2+\sin(y)}{2+\sin(x)}$  (y-x divided by 2+sin(c) is my f dash c from the mean value theorem I asked my teacher that i should use mean value theorem here so please don't use anything other than this, but i have no idea how to push this problem further. Also this is my first post so i'm sorry for the f dash (c) thing, mathjax is hard","Question states Prove that for all $x$ and $y$ $\in R$, the following inequality is true: $\lvert \ln(2+\sin(x)) - \ln(2+\sin(y))\rvert \le \lvert x-y\rvert$ i've gotten to the point that $\frac{y-x}{2+\sin(c)}  = \ln\frac{2+\sin(y)}{2+\sin(x)}$  (y-x divided by 2+sin(c) is my f dash c from the mean value theorem I asked my teacher that i should use mean value theorem here so please don't use anything other than this, but i have no idea how to push this problem further. Also this is my first post so i'm sorry for the f dash (c) thing, mathjax is hard",,"['calculus', 'derivatives', 'inequality']"
80,Partial derivative of a summation,Partial derivative of a summation,,"Simple question but not sure why for, $ f = \frac{\lambda}{2}\sum_{j=1}^{D} w_j^2$ $$\frac{\partial f}{\partial wj}= \lambda w_j$$ I would have thought the answer would be $\frac{\partial f}{\partial wj}= \lambda \sum_{j=1}^{D} w_j^2$ Since we get the derivative of $w_j^2$ which is $2w_j$, pull out the 2, getting rid of $\frac{\lambda}{2}$, and multiply by $w_j$.","Simple question but not sure why for, $ f = \frac{\lambda}{2}\sum_{j=1}^{D} w_j^2$ $$\frac{\partial f}{\partial wj}= \lambda w_j$$ I would have thought the answer would be $\frac{\partial f}{\partial wj}= \lambda \sum_{j=1}^{D} w_j^2$ Since we get the derivative of $w_j^2$ which is $2w_j$, pull out the 2, getting rid of $\frac{\lambda}{2}$, and multiply by $w_j$.",,"['derivatives', 'partial-derivative']"
81,"What's the derivative wrt. $x$ of $\int_0^x f(x-s)\,ds$?",What's the derivative wrt.  of ?,"x \int_0^x f(x-s)\,ds","I know how to compute the derivative of $f(x-s)$ and by the fundamental theorem of calculus the derivative of $\int_0^x f(s)\,ds$ is $f(x)$. But I can't figure out how to do it when they're mashed together as in $\int_0^x f(x-s)\,ds$. The presence of the $s$ inside $f(x-s)$ prevents me from factoring out $f$ and using the product rule.","I know how to compute the derivative of $f(x-s)$ and by the fundamental theorem of calculus the derivative of $\int_0^x f(s)\,ds$ is $f(x)$. But I can't figure out how to do it when they're mashed together as in $\int_0^x f(x-s)\,ds$. The presence of the $s$ inside $f(x-s)$ prevents me from factoring out $f$ and using the product rule.",,['derivatives']
82,Given that $f'(x)g(x) = g'(x)f(x)$ show that g has a root,Given that  show that g has a root,f'(x)g(x) = g'(x)f(x),"I'm given a question which reads: ""suppose $f(x)g'(x) = f'(x)g(x)$ for all $x \in (a,b)$. Let $r_{1}, r_{2} \in (a,b)$ where $r_{1} < r_{2}$ be two consecutive roots of $f$. Also, $f(x) \ne 0$ for any $x \in (r1, r2)$. Furthermore assume that $g(r_{1}) \ne 0$ and $g(r_{2}) \ne 0$. Show that g must have a root in $(r_{1}, r_{2})$. My attempt: We know that $f(r_{1}) = f(r_{2}) = 0$. So $0 = g(r_{1})f'(r_{1})$. Since $g(r_{1}) \ne 0$, it follows that $f'(r_{1}) = 0$. A similar argument can be made for $r_{2}$. Now, since $f(r_{1}) = 0$ and $f(r_{2}) = 0$, then there must be a $x_{1} \in(r_{1}, r_{2})$ such that $f'(x_{1}) = 0$. So, $f(x_{1})g'(x_{1}) = g(x_{1})f'(x_{1}) \to f(x_{1})g'(x_{1}) = 0 \to g'(x_{1}) = 0$, which means that g has an extremeum at that point. That's about as far as I can get before getting stuck.","I'm given a question which reads: ""suppose $f(x)g'(x) = f'(x)g(x)$ for all $x \in (a,b)$. Let $r_{1}, r_{2} \in (a,b)$ where $r_{1} < r_{2}$ be two consecutive roots of $f$. Also, $f(x) \ne 0$ for any $x \in (r1, r2)$. Furthermore assume that $g(r_{1}) \ne 0$ and $g(r_{2}) \ne 0$. Show that g must have a root in $(r_{1}, r_{2})$. My attempt: We know that $f(r_{1}) = f(r_{2}) = 0$. So $0 = g(r_{1})f'(r_{1})$. Since $g(r_{1}) \ne 0$, it follows that $f'(r_{1}) = 0$. A similar argument can be made for $r_{2}$. Now, since $f(r_{1}) = 0$ and $f(r_{2}) = 0$, then there must be a $x_{1} \in(r_{1}, r_{2})$ such that $f'(x_{1}) = 0$. So, $f(x_{1})g'(x_{1}) = g(x_{1})f'(x_{1}) \to f(x_{1})g'(x_{1}) = 0 \to g'(x_{1}) = 0$, which means that g has an extremeum at that point. That's about as far as I can get before getting stuck.",,['derivatives']
83,"A circle centered at $(0,2)$ is tangent to $y=x^2$ at exactly two points. What is its radius? [closed]",A circle centered at  is tangent to  at exactly two points. What is its radius? [closed],"(0,2) y=x^2","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A circle is centered at $(0,2)$ and is tangent to $y=x^2$ at exactly two points. What is the radius of the circle? Don't really have an idea at how to solve the problem. Help is appreciated!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A circle is centered at $(0,2)$ and is tangent to $y=x^2$ at exactly two points. What is the radius of the circle? Don't really have an idea at how to solve the problem. Help is appreciated!",,"['derivatives', 'circles', 'conic-sections', 'tangent-line']"
84,How to differentiate $\sqrt[5]{1/x}$,How to differentiate,\sqrt[5]{1/x},Hey guys I could use some help with this derivative: $$\sqrt[5]{1/x}$$ This is what I have so far: $$=-\dfrac{1}{5}\left(\dfrac{1}{x}\right)^{-6/5}$$ Having trouble simplifying this to my given solution so I don't know if it is correct. Given solution: $$-\frac{1}{5x\sqrt[5]{x}}$$,Hey guys I could use some help with this derivative: $$\sqrt[5]{1/x}$$ This is what I have so far: $$=-\dfrac{1}{5}\left(\dfrac{1}{x}\right)^{-6/5}$$ Having trouble simplifying this to my given solution so I don't know if it is correct. Given solution: $$-\frac{1}{5x\sqrt[5]{x}}$$,,"['calculus', 'derivatives']"
85,Two points on curve that have common tangent line,Two points on curve that have common tangent line,,"Find the two points on the curve $y=x^4-2x^2-x$ that have a common tangent line. My solution: Suppose that these two point are $(p,f(p))$ and $(q,f(q))$ providing that $p \neq q$. Since they have a common tangent line then: $y'(p)=y'(q),$ i.e. $4p^3-4p-1=4q^3-4q-1$ and after cancellation we get: $p^2+pq+q^2=1$. Tangent lines to curve at points $(p,f(p))$ and $(q,f(q))$ are $y=y(p)+y'(p)(x-p)$ and $y=y(q)+y'(q)(x-q)$, respectively. I have tried to put $x=q$ in the first and $x=p$ in the second equations but my efforts were unsuccesfull. Can anyone explain me how to tackle that problem?","Find the two points on the curve $y=x^4-2x^2-x$ that have a common tangent line. My solution: Suppose that these two point are $(p,f(p))$ and $(q,f(q))$ providing that $p \neq q$. Since they have a common tangent line then: $y'(p)=y'(q),$ i.e. $4p^3-4p-1=4q^3-4q-1$ and after cancellation we get: $p^2+pq+q^2=1$. Tangent lines to curve at points $(p,f(p))$ and $(q,f(q))$ are $y=y(p)+y'(p)(x-p)$ and $y=y(q)+y'(q)(x-q)$, respectively. I have tried to put $x=q$ in the first and $x=p$ in the second equations but my efforts were unsuccesfull. Can anyone explain me how to tackle that problem?",,['derivatives']
86,If $\dfrac{d\theta}{dt} = \omega$ then show that $\dfrac{d^2 \theta}{dt^2} = \omega \dfrac{d\omega}{d\theta}$.,If  then show that .,\dfrac{d\theta}{dt} = \omega \dfrac{d^2 \theta}{dt^2} = \omega \dfrac{d\omega}{d\theta},"Let $$ \frac{d\theta}{dt} = \omega$$ show that $\frac{d^2\theta}{dt^2}$ can be expressed as $$\omega\frac{d\omega}{d\theta}$$ My approach is as follows: $$\frac{d^2\theta}{dt^2} = \frac{d}{dt}\biggl(\frac{d\theta}{dt}\biggl)$$ if we substitute $dt=\frac{d\theta}{\omega}$ then $$\frac{d^2\theta}{dt^2} = \frac{d}{\frac{d\theta}{\omega}}\biggl(\frac{d\theta}{\frac{d\theta}{\omega}}\biggl) = \frac{d(\omega)}{d\theta}\biggl({\frac{d\theta}{d\theta}\omega}\biggl) = \omega\frac{d\omega}{d\theta}$$ However, I have a feeling that this approach is mathematically incorrect. Hence I was wondering what other approaches are there, with mathematical rigor . Moreover, when changing variables of derivatives like this, be it first or second derivatives, are there any general rules that apply?","Let $$ \frac{d\theta}{dt} = \omega$$ show that $\frac{d^2\theta}{dt^2}$ can be expressed as $$\omega\frac{d\omega}{d\theta}$$ My approach is as follows: $$\frac{d^2\theta}{dt^2} = \frac{d}{dt}\biggl(\frac{d\theta}{dt}\biggl)$$ if we substitute $dt=\frac{d\theta}{\omega}$ then $$\frac{d^2\theta}{dt^2} = \frac{d}{\frac{d\theta}{\omega}}\biggl(\frac{d\theta}{\frac{d\theta}{\omega}}\biggl) = \frac{d(\omega)}{d\theta}\biggl({\frac{d\theta}{d\theta}\omega}\biggl) = \omega\frac{d\omega}{d\theta}$$ However, I have a feeling that this approach is mathematically incorrect. Hence I was wondering what other approaches are there, with mathematical rigor . Moreover, when changing variables of derivatives like this, be it first or second derivatives, are there any general rules that apply?",,"['derivatives', 'change-of-variable']"
87,"2nd derivative test , Maximum point","2nd derivative test , Maximum point",,"A study shows that a human body reaction R to a dosage D of a certain drug is given by $$ R = D^2(\frac{k}{2} - \frac{D}{3}) $$ Show that he rate of change in the reaction $R$ with respect to the dosage $D$ is maximum if $D = K/2 $ My first derivative is $R' = KD - D^2 $, Dosage for maximum reaction = $k$ My second derivative is $R''= K - 2D $ $R(\frac{k}{2}) = k - 2(\frac{k}{2}) = 0 $ But 0 is neither negative or positive , how do I show that it's a maximum (negative) ?","A study shows that a human body reaction R to a dosage D of a certain drug is given by $$ R = D^2(\frac{k}{2} - \frac{D}{3}) $$ Show that he rate of change in the reaction $R$ with respect to the dosage $D$ is maximum if $D = K/2 $ My first derivative is $R' = KD - D^2 $, Dosage for maximum reaction = $k$ My second derivative is $R''= K - 2D $ $R(\frac{k}{2}) = k - 2(\frac{k}{2}) = 0 $ But 0 is neither negative or positive , how do I show that it's a maximum (negative) ?",,"['calculus', 'derivatives']"
88,Finding derivatives value at $x=0$,Finding derivatives value at,x=0,"So i have function: $$f(x)=x^{10} \ln(x+1)$$ And i need to find what value its 2016th derivative has at $x=0$. So first I got its Taylor expansion around $x=0$ It's like this: $$f(x)= x^{10} \sum_{n=0}^{\infty} \frac{(-1)^{n+1}x^n}{n}$$ So  now is it enough to just look at the 2016th coefficient which is $-\frac{1}{2016}$ since its derivative at $x=0$? Perhaps I understand it wrongly, but want to check it somehow. Thank you in advance for any help I may get.","So i have function: $$f(x)=x^{10} \ln(x+1)$$ And i need to find what value its 2016th derivative has at $x=0$. So first I got its Taylor expansion around $x=0$ It's like this: $$f(x)= x^{10} \sum_{n=0}^{\infty} \frac{(-1)^{n+1}x^n}{n}$$ So  now is it enough to just look at the 2016th coefficient which is $-\frac{1}{2016}$ since its derivative at $x=0$? Perhaps I understand it wrongly, but want to check it somehow. Thank you in advance for any help I may get.",,"['calculus', 'derivatives', 'taylor-expansion']"
89,"What does the partial derivative notation $\frac{\partial (f,g)}{\partial (x,y)}$ mean?",What does the partial derivative notation  mean?,"\frac{\partial (f,g)}{\partial (x,y)}","I am currently reading an old math book which contains the following unexplained notation: Let $f(x,y)$ and $g(x,y)$ be functions $\mathbb{R}^2\rightarrow \mathbb{R}$. The notation $$\frac{\partial(f,g)}{\partial(x,y)}$$ apparently refers to a function of the form $\mathbb{R}^2\rightarrow \mathbb{R}$. I am not sure, but I suspect it may be defined as $$\frac{\partial(f,g)}{\partial(x,y)} \equiv \frac{\partial f}{\partial x}\frac{\partial g}{\partial y}-\frac{\partial f}{\partial y}\frac{\partial g}{\partial x}.$$ Is this notation/definition common in any particular field? And especially if so, could there be an obvious interpretation of the following notation, which this book also uses without explanation? $$\frac{\partial[f,g]}{\partial(x,y)}$$ Thanks for your help. Edit: I believe @Fred is correct that the parentheses are used to denote the Jacobian. Here is the notation, as used in a simplified excerpt of Calculating Curves by Ron Doerfler and others: $$ \left\{ \begin{array}{c} 0 = \frac{\partial u}{\partial y} f_1(x) + \frac{\partial v}{\partial y}\\ 0 = \frac{\partial u}{\partial x}  f_2(y) + \frac{\partial v}{\partial x}\\ \end{array}\right.$$ Let us assume that $\frac{\partial(u,v)}{\partial(x,y)}=0$. Then the   above equations yield that $$\frac{\partial u}{\partial x}\frac{\partial u}{\partial y}[f_1(x) -  f_2(y)] = 0.$$ Thus we can posit that $$\frac{\partial(u,v)}{\partial(x,y)} = \frac{\partial u}{\partial x}\frac{\partial v}{\partial y}-\frac{\partial v}{\partial  x}\frac{\partial u}{\partial y} = e^\theta.$$ I am still unsure about the meaning of the square bracket notation. The  square brackets are a little more difficult to place in context, but here is an attempt: $$g_3(z) = u f_3(z) + v$$ We clearly have $\frac{\partial[g_3(z), z]}{\partial(x,y)} = 0$. By substituting the above equation and observing that $\frac{\partial[f_3(z), z]}{\partial(x,y)} = 0$, we obtain $$f_3(z)\frac{\partial(u,z)}{\partial(x,y)} + \frac{\partial(v,z)}{\partial(x,y)} = 0.$$ Possibly the square brackets are simply an alias for round brackets which are used to avoid potentially visually-noisy nested round brackets(?).","I am currently reading an old math book which contains the following unexplained notation: Let $f(x,y)$ and $g(x,y)$ be functions $\mathbb{R}^2\rightarrow \mathbb{R}$. The notation $$\frac{\partial(f,g)}{\partial(x,y)}$$ apparently refers to a function of the form $\mathbb{R}^2\rightarrow \mathbb{R}$. I am not sure, but I suspect it may be defined as $$\frac{\partial(f,g)}{\partial(x,y)} \equiv \frac{\partial f}{\partial x}\frac{\partial g}{\partial y}-\frac{\partial f}{\partial y}\frac{\partial g}{\partial x}.$$ Is this notation/definition common in any particular field? And especially if so, could there be an obvious interpretation of the following notation, which this book also uses without explanation? $$\frac{\partial[f,g]}{\partial(x,y)}$$ Thanks for your help. Edit: I believe @Fred is correct that the parentheses are used to denote the Jacobian. Here is the notation, as used in a simplified excerpt of Calculating Curves by Ron Doerfler and others: $$ \left\{ \begin{array}{c} 0 = \frac{\partial u}{\partial y} f_1(x) + \frac{\partial v}{\partial y}\\ 0 = \frac{\partial u}{\partial x}  f_2(y) + \frac{\partial v}{\partial x}\\ \end{array}\right.$$ Let us assume that $\frac{\partial(u,v)}{\partial(x,y)}=0$. Then the   above equations yield that $$\frac{\partial u}{\partial x}\frac{\partial u}{\partial y}[f_1(x) -  f_2(y)] = 0.$$ Thus we can posit that $$\frac{\partial(u,v)}{\partial(x,y)} = \frac{\partial u}{\partial x}\frac{\partial v}{\partial y}-\frac{\partial v}{\partial  x}\frac{\partial u}{\partial y} = e^\theta.$$ I am still unsure about the meaning of the square bracket notation. The  square brackets are a little more difficult to place in context, but here is an attempt: $$g_3(z) = u f_3(z) + v$$ We clearly have $\frac{\partial[g_3(z), z]}{\partial(x,y)} = 0$. By substituting the above equation and observing that $\frac{\partial[f_3(z), z]}{\partial(x,y)} = 0$, we obtain $$f_3(z)\frac{\partial(u,z)}{\partial(x,y)} + \frac{\partial(v,z)}{\partial(x,y)} = 0.$$ Possibly the square brackets are simply an alias for round brackets which are used to avoid potentially visually-noisy nested round brackets(?).",,"['derivatives', 'partial-derivative']"
90,Show that if $y=x^{n-1}e^{1/x}$ then $D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}}$,Show that if  then,y=x^{n-1}e^{1/x} D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}},Show that if $y=x^{n-1}e^{1/x}$ then $D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}}$ $y_1={{\rm e}^{{x}^{-1}}} \left( {x}^{n-2}n-{x}^{n-2}-{x}^{n-3} \right) $ $y_2={\frac {{{\rm e}^{{x}^{-1}}} \left(  \left( -1+ \left( n-2 \right) x  \right)  \left( n-1 \right) {x}^{n-2}-{x}^{n-3} \left( -1+ \left( n-3  \right) x \right)  \right) }{{x}^{2}}} $ I want to use Leibnitz rules for successive differentiation. Please help.,Show that if $y=x^{n-1}e^{1/x}$ then $D^ny=\frac{(-1)^ne^{1/x}}{x^{n+1}}$ $y_1={{\rm e}^{{x}^{-1}}} \left( {x}^{n-2}n-{x}^{n-2}-{x}^{n-3} \right) $ $y_2={\frac {{{\rm e}^{{x}^{-1}}} \left(  \left( -1+ \left( n-2 \right) x  \right)  \left( n-1 \right) {x}^{n-2}-{x}^{n-3} \left( -1+ \left( n-3  \right) x \right)  \right) }{{x}^{2}}} $ I want to use Leibnitz rules for successive differentiation. Please help.,,"['calculus', 'derivatives']"
91,Proof of Intermediate value theorem in non-standard analysis.,Proof of Intermediate value theorem in non-standard analysis.,,"A real function is continuous on $[a,b]$ such that either $f(a) > 0 >f(b)$ or $f(a) < 0 < f(b)$, then prove that $f(c) = 0$ for some $c \in (a,b)$. Proof :- We divide $[a,b]^*$ in $H$ equal parts, where $H$ is a positive infinite hyperinteger. We get, $$a, a +\delta, a+2\delta,\ ... \ , a+ H\delta = b$$ Let $a + K\delta$ be the last partition point at which $f(a+ K\delta) <0$, Thus $$f(a+K\delta) < 0 \le f(a+(K+1)\delta)$$ Since $f$ is continous $f(a+K\delta) \approx f(a+(K+1)\delta)$, thus $f(a+K\delta) \approx 0$, Let $c = st(a+ K\delta)$ Therefore $f(c)= st(f(a+ K\delta)) =0 $ I have two questions, Shouldn't it be $f^*(x)$ everywhere instead of $f(x)$ because a real function won't have a hyperreal number in its domain. Like it should be $f^*(a+K\delta) <0$ in the third line because $a+K\delta$ is not a real number it is a hyperreal number. Why does $f(a+K\delta) \approx f(a+(K+1)\delta)$ ? Can't it be $f(a+K\delta) = 1000$ and $f(a+(K+1)\delta) = 2000$ ? Then those two are not infinitely close, right?","A real function is continuous on $[a,b]$ such that either $f(a) > 0 >f(b)$ or $f(a) < 0 < f(b)$, then prove that $f(c) = 0$ for some $c \in (a,b)$. Proof :- We divide $[a,b]^*$ in $H$ equal parts, where $H$ is a positive infinite hyperinteger. We get, $$a, a +\delta, a+2\delta,\ ... \ , a+ H\delta = b$$ Let $a + K\delta$ be the last partition point at which $f(a+ K\delta) <0$, Thus $$f(a+K\delta) < 0 \le f(a+(K+1)\delta)$$ Since $f$ is continous $f(a+K\delta) \approx f(a+(K+1)\delta)$, thus $f(a+K\delta) \approx 0$, Let $c = st(a+ K\delta)$ Therefore $f(c)= st(f(a+ K\delta)) =0 $ I have two questions, Shouldn't it be $f^*(x)$ everywhere instead of $f(x)$ because a real function won't have a hyperreal number in its domain. Like it should be $f^*(a+K\delta) <0$ in the third line because $a+K\delta$ is not a real number it is a hyperreal number. Why does $f(a+K\delta) \approx f(a+(K+1)\delta)$ ? Can't it be $f(a+K\delta) = 1000$ and $f(a+(K+1)\delta) = 2000$ ? Then those two are not infinitely close, right?",,"['real-analysis', 'derivatives']"
92,How does Horner method evaluate the derivative of a function,How does Horner method evaluate the derivative of a function,,"From my understanding, Horner method is mainly used to evaluate polynomial functions by altering the equation into a simpler recursive relation with lesser number of operations. Say for example, I was given $f (x) = 4x^4 + 3x^3 +2x^2+x+5$ This can be rewritten as $5 +x (1+x (2+x (3+x (4)))$ Were we can evaluate the function as a recurrent relation of simpler terms starting from: $b_n=4 $ $b_{n-1} = 3 + b_n* x$ And $b_0$ would be the whole term evaluated and therefore the image of the function.  What I want to understand how is running horner method to the $b_n$ values result in the derivative?","From my understanding, Horner method is mainly used to evaluate polynomial functions by altering the equation into a simpler recursive relation with lesser number of operations. Say for example, I was given $f (x) = 4x^4 + 3x^3 +2x^2+x+5$ This can be rewritten as $5 +x (1+x (2+x (3+x (4)))$ Were we can evaluate the function as a recurrent relation of simpler terms starting from: $b_n=4 $ $b_{n-1} = 3 + b_n* x$ And $b_0$ would be the whole term evaluated and therefore the image of the function.  What I want to understand how is running horner method to the $b_n$ values result in the derivative?",,"['derivatives', 'numerical-methods']"
93,Why the slope of $e^x$ at any point is it's value at that point?,Why the slope of  at any point is it's value at that point?,e^x,I know that we can differentiate $e^x$ by using limits. But why is it that it is the derivative of it's own? Or is it the case that there must exist a function which should be it's own derivative and we have defined it to be $e^x$?,I know that we can differentiate $e^x$ by using limits. But why is it that it is the derivative of it's own? Or is it the case that there must exist a function which should be it's own derivative and we have defined it to be $e^x$?,,"['calculus', 'derivatives', 'exponential-function', 'intuition']"
94,Absolute minimum of $f(x) = \sqrt{2x^2-3x+4} + \sqrt{x^2-2x}$,Absolute minimum of,f(x) = \sqrt{2x^2-3x+4} + \sqrt{x^2-2x},I've got the domain of function and I've attempted to find the first derivative at zero but it results in a quartic equation that is too difficult for me to solve. $f'(x) = \frac{4x-3}{\sqrt{2x^2-3x+4}} + \frac{2x-2}{\sqrt{x^2-2x}}$ For $f'(x) = 0$: $(4x-3)^2(x^2-2x) = (2-2x)^2(2x^2-3x+4)$ Therefore $8x^4-28x^3+9x^2+26x-16 = 0$ I've probably made an error in my calculations but I'm sure that this is not how you approach the question and I'm not quite sure how to do it otherwise. According to the textbook the answer is 2.,I've got the domain of function and I've attempted to find the first derivative at zero but it results in a quartic equation that is too difficult for me to solve. $f'(x) = \frac{4x-3}{\sqrt{2x^2-3x+4}} + \frac{2x-2}{\sqrt{x^2-2x}}$ For $f'(x) = 0$: $(4x-3)^2(x^2-2x) = (2-2x)^2(2x^2-3x+4)$ Therefore $8x^4-28x^3+9x^2+26x-16 = 0$ I've probably made an error in my calculations but I'm sure that this is not how you approach the question and I'm not quite sure how to do it otherwise. According to the textbook the answer is 2.,,"['calculus', 'derivatives', 'optimization', 'radicals', 'maxima-minima']"
95,How is logarithmic differentiation of possibly negative functions justified?,How is logarithmic differentiation of possibly negative functions justified?,,"For example, take the common example $\frac{d}{dx}(\cos x) ^{\sin x}$. The usual method for this is $$ y = (\cos x) ^{\sin x}\\ \ln y = \sin x \ln \cos x\\ \frac{d}{dx}\ln y = \frac{d}{dx} \sin x \ln \cos x\\ \frac{1}{y} \frac{dy}{dx} = \cos x \ln \cos x + \sin x \frac{1}{\cos x} \sin x\\ \frac{dy}{dx} = (\cos x) ^{\sin x} \left( \cos x \ln \cos x + \sin x \tan x \right) $$ Now, of course, $\ln \cos x$ isn't valid for all $x$. Does it mean that wherever $\ln \cos x$ is undefined, the derivative does not exist? Or am I incorrectly pre-assuming that I can take the natural logarithm of both sides in the first place?","For example, take the common example $\frac{d}{dx}(\cos x) ^{\sin x}$. The usual method for this is $$ y = (\cos x) ^{\sin x}\\ \ln y = \sin x \ln \cos x\\ \frac{d}{dx}\ln y = \frac{d}{dx} \sin x \ln \cos x\\ \frac{1}{y} \frac{dy}{dx} = \cos x \ln \cos x + \sin x \frac{1}{\cos x} \sin x\\ \frac{dy}{dx} = (\cos x) ^{\sin x} \left( \cos x \ln \cos x + \sin x \tan x \right) $$ Now, of course, $\ln \cos x$ isn't valid for all $x$. Does it mean that wherever $\ln \cos x$ is undefined, the derivative does not exist? Or am I incorrectly pre-assuming that I can take the natural logarithm of both sides in the first place?",,"['derivatives', 'logarithms', 'implicit-differentiation']"
96,Finding the 19th derivative of $\frac{x-1}{e^x}$ using taylor series,Finding the 19th derivative of  using taylor series,\frac{x-1}{e^x},"Full context: The problem is multiple choice and originally asks to find the 19th derivative which I prefer to do by Taylor Series. My method get's the answer (after plugging in $x=0$) but it is a bit unsatisfying since it relies on there being multiple choice options and I am wondering if there is a less multiple choice-y way to do the question under time pressure. I took  $$f(x)=e^{-x}(x-1)=\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n+1}-\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n}$$ A taylor series centered at zero. Then we can equate  $$ \frac{f^{(n)}(0)}{n!}=a_n\Rightarrow \frac{f^{(19)}(0)}{19!}=\frac{1}{18!}+\frac{1}{19!}\Rightarrow f^{(19)}(0)=20 $$ Then plugging in, only one solution satisfies $f^{(19)}(0)=20$: $(20-x)e^{-x}$. I am wondering: Is there a more sound way to find a closed form solution? I tend to not be great at looking for a pattern, especially under pressure, so if that is your method please explain how you go about seeing a pattern quickly after a couple of computations.","Full context: The problem is multiple choice and originally asks to find the 19th derivative which I prefer to do by Taylor Series. My method get's the answer (after plugging in $x=0$) but it is a bit unsatisfying since it relies on there being multiple choice options and I am wondering if there is a less multiple choice-y way to do the question under time pressure. I took  $$f(x)=e^{-x}(x-1)=\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n+1}-\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n}$$ A taylor series centered at zero. Then we can equate  $$ \frac{f^{(n)}(0)}{n!}=a_n\Rightarrow \frac{f^{(19)}(0)}{19!}=\frac{1}{18!}+\frac{1}{19!}\Rightarrow f^{(19)}(0)=20 $$ Then plugging in, only one solution satisfies $f^{(19)}(0)=20$: $(20-x)e^{-x}$. I am wondering: Is there a more sound way to find a closed form solution? I tend to not be great at looking for a pattern, especially under pressure, so if that is your method please explain how you go about seeing a pattern quickly after a couple of computations.",,"['calculus', 'derivatives', 'taylor-expansion']"
97,"Is $(x^2+y^2+z^2) \ \sin \frac{1}{\sqrt{x^2+y^2+z^2}}$ Differentiable in $(0,0,0)$?",Is  Differentiable in ?,"(x^2+y^2+z^2) \ \sin \frac{1}{\sqrt{x^2+y^2+z^2}} (0,0,0)","$$f(x,y,z)=\begin{cases} (x^2+y^2+z^2) \ \sin \frac{1}{\sqrt{x^2+y^2+z^2}} \qquad (x,y,z) \ne (0,0,0) \\ \\ 0 \qquad (x,y,z)=(0,0,0) \end{cases} $$ At first, I study the continuity in the origin. I apply the concept of sequential continuity: $x_n \rightarrow x_0 \Rightarrow f(x_n) \rightarrow f(x_0)$ So, $x_n=\frac{1}{n}  $ $$x_n \rightarrow 0 \Rightarrow f(x_n,x_n,x_n) \rightarrow f(0,0,0)=0$$ $$\lim_{n\rightarrow +\infty} \frac{3}{n^2} \ \sin \frac{1}{\frac{\sqrt{3}}{n}}=0 $$ How can I continue the study of differentiation? Thanks!","$$f(x,y,z)=\begin{cases} (x^2+y^2+z^2) \ \sin \frac{1}{\sqrt{x^2+y^2+z^2}} \qquad (x,y,z) \ne (0,0,0) \\ \\ 0 \qquad (x,y,z)=(0,0,0) \end{cases} $$ At first, I study the continuity in the origin. I apply the concept of sequential continuity: $x_n \rightarrow x_0 \Rightarrow f(x_n) \rightarrow f(x_0)$ So, $x_n=\frac{1}{n}  $ $$x_n \rightarrow 0 \Rightarrow f(x_n,x_n,x_n) \rightarrow f(0,0,0)=0$$ $$\lim_{n\rightarrow +\infty} \frac{3}{n^2} \ \sin \frac{1}{\frac{\sqrt{3}}{n}}=0 $$ How can I continue the study of differentiation? Thanks!",,"['real-analysis', 'derivatives', 'continuity']"
98,Find the 8th derivative of the function $h(x) = xe^x $using sequences,Find the 8th derivative of the function using sequences,h(x) = xe^x ,"How do you find the 8th derivative of $h(x) = x e^x $ without doing it ""manually"". I know that $\displaystyle e^x = \sum_{i=0}^n \frac{x^n}{n!} $ so that $\displaystyle h(x) = x \sum_{i=0}^n \frac{x^n}{n!}  = \sum_{i=0}^n \frac{x^{n+1}}{n!}  $ I can't figure out what to do from here. Edit: I forgot to mention that we want to find the derivative evaluated at $x=0$, so $h^{(8)}(0)$.","How do you find the 8th derivative of $h(x) = x e^x $ without doing it ""manually"". I know that $\displaystyle e^x = \sum_{i=0}^n \frac{x^n}{n!} $ so that $\displaystyle h(x) = x \sum_{i=0}^n \frac{x^n}{n!}  = \sum_{i=0}^n \frac{x^{n+1}}{n!}  $ I can't figure out what to do from here. Edit: I forgot to mention that we want to find the derivative evaluated at $x=0$, so $h^{(8)}(0)$.",,"['sequences-and-series', 'derivatives', 'taylor-expansion']"
99,Finite Difference Approximation of Derivative [closed],Finite Difference Approximation of Derivative [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I want to build a finite-difference approximation of this derivative: $\frac{\partial^2T }{\partial x^2}$ There are given an error of approximation: $O(\Delta x^{4})$ and nodal values of function:$ T_{i-2},T_{i-1},T_{i+1},T_{i+2}$ Can you show me the steps of solving this problem. Or give some well-explained tutorials about this. I would appreciate any help.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I want to build a finite-difference approximation of this derivative: $\frac{\partial^2T }{\partial x^2}$ There are given an error of approximation: $O(\Delta x^{4})$ and nodal values of function:$ T_{i-2},T_{i-1},T_{i+1},T_{i+2}$ Can you show me the steps of solving this problem. Or give some well-explained tutorials about this. I would appreciate any help.",,"['derivatives', 'optimization', 'numerical-methods', 'finite-differences']"
