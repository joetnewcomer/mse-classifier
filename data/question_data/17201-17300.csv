,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove that $\lim_{x\to\infty} f(x) = 0$ [duplicate],Prove that  [duplicate],\lim_{x\to\infty} f(x) = 0,"This question already has answers here : If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$ (4 answers) Closed 7 years ago . Let $f:\mathbb{R}\to\mathbb{R}$ which is continuously differentiable ($f\in C^1$). Lets assume $\int_0^\infty f < \infty$ and $f'(x)$ is bounded. Show that $\lim_{x\to\infty}f(x) = 0$. All I could think of is doing integration by parts: $$ \int_0^\infty f(x)\,dx = \sum_{n=1}^\infty \int_{n-1}^n 1\cdot f(x)\,dx = \sum_{n=1}^\infty \left( \left.xf(x)\vphantom{\frac11}\right|_{n-1}^n - \int_{n-1}^n xf'(x) \, dx  \right)$$","This question already has answers here : If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$ (4 answers) Closed 7 years ago . Let $f:\mathbb{R}\to\mathbb{R}$ which is continuously differentiable ($f\in C^1$). Lets assume $\int_0^\infty f < \infty$ and $f'(x)$ is bounded. Show that $\lim_{x\to\infty}f(x) = 0$. All I could think of is doing integration by parts: $$ \int_0^\infty f(x)\,dx = \sum_{n=1}^\infty \int_{n-1}^n 1\cdot f(x)\,dx = \sum_{n=1}^\infty \left( \left.xf(x)\vphantom{\frac11}\right|_{n-1}^n - \int_{n-1}^n xf'(x) \, dx  \right)$$",,"['calculus', 'integration']"
1,"Infinite Double Exponential Sum, with Functional Equation $g(x) = g(\sqrt{x})$","Infinite Double Exponential Sum, with Functional Equation",g(x) = g(\sqrt{x}),What is a closed form for $$ \lim_{n\to-\infty}\sum_{i=n}^{\infty}\frac{x^{2^i}(x^{2^i}-1)}{(x^{2^{i+2}}+1)} $$ The series has the form: $$... \frac{x^{\frac{1}{4}}(x^{\frac{1}{4}}-1)}{x+1} + \frac{x^{\frac{1}{2}}(x^{\frac{1}{2}}-1)}{x^{2}+1}  + \frac{x(x-1)}{x^4+1} +\frac{x^2(x^2-1)}{x^8+1}  ... $$ Among other things the closed form satisfies $$g(x) = g\left(\sqrt{x}\right)$$ where we select the principal square root.,What is a closed form for $$ \lim_{n\to-\infty}\sum_{i=n}^{\infty}\frac{x^{2^i}(x^{2^i}-1)}{(x^{2^{i+2}}+1)} $$ The series has the form: $$... \frac{x^{\frac{1}{4}}(x^{\frac{1}{4}}-1)}{x+1} + \frac{x^{\frac{1}{2}}(x^{\frac{1}{2}}-1)}{x^{2}+1}  + \frac{x(x-1)}{x^4+1} +\frac{x^2(x^2-1)}{x^8+1}  ... $$ Among other things the closed form satisfies $$g(x) = g\left(\sqrt{x}\right)$$ where we select the principal square root.,,"['calculus', 'sequences-and-series', 'convergence-divergence', 'functional-equations', 'exponential-sum']"
2,Prove that the eigenvalues of the Legendre equation are integers,Prove that the eigenvalues of the Legendre equation are integers,,"The Legendre equation, $$\frac{d}{dx}((1-x^2)y') + \lambda y = 0$$ is an irregular Sturm-Liouville problem with $p(x) = 1 - x^2$, so that -1 and 1 are its singular points. I have been trying since yesterday to prove that its eigenvalues are necessarily integers without any kind of success. How can one prove it?","The Legendre equation, $$\frac{d}{dx}((1-x^2)y') + \lambda y = 0$$ is an irregular Sturm-Liouville problem with $p(x) = 1 - x^2$, so that -1 and 1 are its singular points. I have been trying since yesterday to prove that its eigenvalues are necessarily integers without any kind of success. How can one prove it?",,"['calculus', 'ordinary-differential-equations', 'eigenvalues-eigenvectors']"
3,Signing $y''$ from $\log(\frac{x+y}{x})=x+y$,Signing  from,y'' \log(\frac{x+y}{x})=x+y,"Suppose that $x,y>0$ are positive reals such that $y$ is defined implicitly in terms of $x$ via:   $$ \log\left(\frac{x+y}{x}\right)=x+y.\tag{$\star$} $$   I would like study the sign of $y''$. Attempt : Write ($\star$) as $$ \log(x+y)-\log(x)=x+y. $$ Differentiate both sides w.r.t. $x$ yields $$ \frac{1+y'}{x+y}-\frac{1}{x}=1+y'\tag{$\star\star$} $$ which can be solved to get  $$ 1+y'=\frac{x+y}{x(1-x-y)}\cdot $$ Differentiate both sides of ($\star\star$) w.r.t. $x$ to get $$ \frac{(x+y)y''-(1+y')^2}{(x+y)^2}+\frac{1}{x^2}=y'' $$ which, after feeding to Mathematica while using $1+y'$ found above, gives $$ y''=\frac{(x+y-2) (x+y)^2}{x^2 (x+y-1)^3} $$ which can clearly take on positive and negative values depending on $x+y$. Indeed, looking back at ($\star$), we can freely vary $x+y$: to have $x+y=r>0$, simply set $$ x=e^{-r}r,\quad y=(1-e^{-r})r. $$ Is my attempt here reasonable to you? The reason I'm not confident is that if I feed ($\star$) directly to Mathematica, I get $$ y=-x-\text{ProductLog}[-x] $$ where (according to Help File) $\text{ProductLog}[z]$ gives the principal solution for $w$ in $z=we^w$. Then I plotted $$ \partial_x(\partial_x(-x-\text{ProductLog}[-x])) $$ and saw something that is only positive: What is going on? Can someone please explain this seeming discrepancy?","Suppose that $x,y>0$ are positive reals such that $y$ is defined implicitly in terms of $x$ via:   $$ \log\left(\frac{x+y}{x}\right)=x+y.\tag{$\star$} $$   I would like study the sign of $y''$. Attempt : Write ($\star$) as $$ \log(x+y)-\log(x)=x+y. $$ Differentiate both sides w.r.t. $x$ yields $$ \frac{1+y'}{x+y}-\frac{1}{x}=1+y'\tag{$\star\star$} $$ which can be solved to get  $$ 1+y'=\frac{x+y}{x(1-x-y)}\cdot $$ Differentiate both sides of ($\star\star$) w.r.t. $x$ to get $$ \frac{(x+y)y''-(1+y')^2}{(x+y)^2}+\frac{1}{x^2}=y'' $$ which, after feeding to Mathematica while using $1+y'$ found above, gives $$ y''=\frac{(x+y-2) (x+y)^2}{x^2 (x+y-1)^3} $$ which can clearly take on positive and negative values depending on $x+y$. Indeed, looking back at ($\star$), we can freely vary $x+y$: to have $x+y=r>0$, simply set $$ x=e^{-r}r,\quad y=(1-e^{-r})r. $$ Is my attempt here reasonable to you? The reason I'm not confident is that if I feed ($\star$) directly to Mathematica, I get $$ y=-x-\text{ProductLog}[-x] $$ where (according to Help File) $\text{ProductLog}[z]$ gives the principal solution for $w$ in $z=we^w$. Then I plotted $$ \partial_x(\partial_x(-x-\text{ProductLog}[-x])) $$ and saw something that is only positive: What is going on? Can someone please explain this seeming discrepancy?",,['calculus']
4,Calculus II: Comparison Test,Calculus II: Comparison Test,,I have this math problem where I have to show that a sum converges. Is this correct? Thanks $$\sum_{n=1}^{\infty}\frac{2n-1}{ne^n}$$ I chose $\sum_{n=1}^{\infty}\frac{2n}{ne^n}$ to compare it to. Which simplifies to $\sum_{n=1}^{\infty}\frac{2}{e^n}$ Which is the same as $\sum_{n=1}^{\infty}2(\frac{1}{e})^n$. Since $\frac{1}{e}$ is $ < 1 $;  $\sum_{n=1}^{\infty}\frac{2n-1}{ne^n}$ converges,I have this math problem where I have to show that a sum converges. Is this correct? Thanks $$\sum_{n=1}^{\infty}\frac{2n-1}{ne^n}$$ I chose $\sum_{n=1}^{\infty}\frac{2n}{ne^n}$ to compare it to. Which simplifies to $\sum_{n=1}^{\infty}\frac{2}{e^n}$ Which is the same as $\sum_{n=1}^{\infty}2(\frac{1}{e})^n$. Since $\frac{1}{e}$ is $ < 1 $;  $\sum_{n=1}^{\infty}\frac{2n-1}{ne^n}$ converges,,"['calculus', 'sequences-and-series', 'riemann-sum']"
5,Integral of a product of five Bessel functions of order $0$,Integral of a product of five Bessel functions of order,0,"Does the following integral have a closed form? $$ \mathcal{J}(2,3,5,7,11) = \int_0^\infty x J_0(x\sqrt{2})J_0(x\sqrt{3})J_0(x\sqrt{5})J_0(x\sqrt{7})J_0(x\sqrt{11})\,dx. $$ I know that some similar integrals do have a closed form $$ \mathcal{J}(2,3,5) = \frac{1}{\pi \sqrt{6}} \approx 0.12995. $$ $$ \mathcal{J}(2,3,5,7) = \frac{1}{\pi^2 210^{1/4}}K(\tfrac14\sqrt\alpha) \approx 0.110411, \qquad 43-672\alpha+42\alpha^2 = 0, \qquad \alpha\approx 15.9358. $$ (Here $K(k)$ is the complete elliptic integral of the first kind with modulus $k$.) Numerically, the integral is approximately $$ 0.061064349908721692\ldots, $$ but I could not find a symbolic value for this constant.","Does the following integral have a closed form? $$ \mathcal{J}(2,3,5,7,11) = \int_0^\infty x J_0(x\sqrt{2})J_0(x\sqrt{3})J_0(x\sqrt{5})J_0(x\sqrt{7})J_0(x\sqrt{11})\,dx. $$ I know that some similar integrals do have a closed form $$ \mathcal{J}(2,3,5) = \frac{1}{\pi \sqrt{6}} \approx 0.12995. $$ $$ \mathcal{J}(2,3,5,7) = \frac{1}{\pi^2 210^{1/4}}K(\tfrac14\sqrt\alpha) \approx 0.110411, \qquad 43-672\alpha+42\alpha^2 = 0, \qquad \alpha\approx 15.9358. $$ (Here $K(k)$ is the complete elliptic integral of the first kind with modulus $k$.) Numerically, the integral is approximately $$ 0.061064349908721692\ldots, $$ but I could not find a symbolic value for this constant.",,"['calculus', 'definite-integrals', 'special-functions', 'closed-form', 'bessel-functions']"
6,"Prove that $\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx =\frac{\pi e}{24} $",Prove that,"\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx =\frac{\pi e}{24} ","I've found here the following integral. $$I = \int_{0}^{1}\sin{(\pi (1-x))}x^x(1-x)^{1-x}\,dx=\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx=\frac{\pi e}{24}$$ I've never seen it before and I also didn't find the evaluation on math.se. How could we verify it? If it is a well-known integral, then could you give a reference?","I've found here the following integral. $$I = \int_{0}^{1}\sin{(\pi (1-x))}x^x(1-x)^{1-x}\,dx=\int_{0}^{1}\sin{(\pi x)}x^x(1-x)^{1-x}\,dx=\frac{\pi e}{24}$$ I've never seen it before and I also didn't find the evaluation on math.se. How could we verify it? If it is a well-known integral, then could you give a reference?",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
7,Wicked domain of integration in a triple integral,Wicked domain of integration in a triple integral,,"I am dealing with a domain of integration of the form: $\left(\frac{x-y}{x+y}\right)^2+\left(\frac{y-z}{y+z}\right)^2+\left(\frac{x-z}{x+z}\right)^2\leq k$ The region looks like this (for $k=0.2$): It becomes just a line for the limit case $k=0$ and the full first octant when $k=3$. All my efforts so far were unfruitful: Use Mathematica's ""Reduce"" command in order to get the limits (untreatable). Several different change of variables. Approximating it to an infinite pyramid/cone Profiting from the symmetry (also of my density function) and take only one third of this region, for instance intersecting it with $x - y \leq 0$ and $z - x \geq 0$. The idea was to be able to integrate there and just multiply the result by 3. Integrate only on the extended ""shadows"" (projections?) and meet the results afterwards. Truncate it with a plane $x+y+z<a$ with the intention to let $a\to\infty$ after integration And more efforts I'm ashamed to share. Could you please provide me with some further ideas? Does anyone even know if this surface has a name? I would like to avoid going numerical. Is there a way to solve it numerically, but not completely? I need a sharp estimate of the final integral as a function of $k$. The fact that is improper doesn't bother me, since the integrand is well defined for unbounded regions. Update : I tried applying the divergence theorem, but the expression of the normal vector is incredibly discouraging (more than 125 lines in Mathematica). I doubt that I could integrate that (didn't even try). Any ideas...?","I am dealing with a domain of integration of the form: $\left(\frac{x-y}{x+y}\right)^2+\left(\frac{y-z}{y+z}\right)^2+\left(\frac{x-z}{x+z}\right)^2\leq k$ The region looks like this (for $k=0.2$): It becomes just a line for the limit case $k=0$ and the full first octant when $k=3$. All my efforts so far were unfruitful: Use Mathematica's ""Reduce"" command in order to get the limits (untreatable). Several different change of variables. Approximating it to an infinite pyramid/cone Profiting from the symmetry (also of my density function) and take only one third of this region, for instance intersecting it with $x - y \leq 0$ and $z - x \geq 0$. The idea was to be able to integrate there and just multiply the result by 3. Integrate only on the extended ""shadows"" (projections?) and meet the results afterwards. Truncate it with a plane $x+y+z<a$ with the intention to let $a\to\infty$ after integration And more efforts I'm ashamed to share. Could you please provide me with some further ideas? Does anyone even know if this surface has a name? I would like to avoid going numerical. Is there a way to solve it numerically, but not completely? I need a sharp estimate of the final integral as a function of $k$. The fact that is improper doesn't bother me, since the integrand is well defined for unbounded regions. Update : I tried applying the divergence theorem, but the expression of the normal vector is incredibly discouraging (more than 125 lines in Mathematica). I doubt that I could integrate that (didn't even try). Any ideas...?",,"['calculus', 'integration', 'surfaces']"
8,Integration of product of functions(Special form),Integration of product of functions(Special form),,"Sir, I have been doing a proof related to one research topic. But after a long effort, I got ended up in a messy integration equation. Could you give me some suggestions to solve this equations? (Any method like substitutions etc are welcome). Kind of stucked my work because of this. I am giving you the integration equation as follows NB :: ""*"" notation also implies multiplication. Means $a \times b = ab=a*b$ Given Data in the question $   \lambda(t)  =   \left(\sqrt{\left( \frac{t}{2}A- a   \right )^2+\left(   \frac{t }{2}B- b   \right )^2+\left( \frac{t }{2}C- c    \right )^2} \right) \\= \sqrt{ \frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2)  }  \tag 1$ We here imply only positive square root. A,B,C,a,b and c are constants we cant alter the values. Only t is a variable here. 2.   $\phi(t)_0=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}A- a  \right)   \tag2$                      $\phi(t)_1=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}B- b  \right)     \tag3$   $\phi(t)_2=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}C- c  \right)     \tag2$ We have two  sets of questions. SET 1 is the original problem. I have added SET 2 as supplementary  because solving this will lead to the solution of SET 1. Any solution to either set 1 or set 2 is welcome. Main issue I face here is the difficulty to take out square root from sin . Note that A,B,C,a,b,c can have any real values. It is not necessary that the $\frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2) $ has equal roots Question SET 1 Is there anyway to solve $  \int \phi(t)_0 cos \left( \frac{t}{2}\lambda(t)\right) \ dt\tag 5$? Is there anyway to solve $  \int \phi(t)_0 \phi(t)_1 \ dt \tag 6$ ? Is there anyway to solve $  \int \phi(t)_1 \phi(t)_2 \ dt \tag 7$  ? SET 2 Is there anyway to solve $\displaystyle \int t^2\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c}  \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t^2\frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname dt \tag8$? Is there anyway to solve $\displaystyle  \int t \frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{ \sqrt{ at^2+bt+c}} \operatorname dt \tag8$? Some attempts currently I am trying Thinking about the possiblity of exponent expression of sin x and cos x  as here Thinking about the possibility of  product form results of sin xcos x  as here Thinking about substitution method by utilizing property $ax^2+bx+c =a \left(x+ \frac{b}{2a}\right)^2-\frac{b^2-4ac}{4a}$  as done here NB : So far I couldnot solve it. Main issue here is the square root inside trigonometric terms. It is difficult to convert it in to a solvable propblem Thanks for taking time to read my doubt. Hope nice suggestions and discussions","Sir, I have been doing a proof related to one research topic. But after a long effort, I got ended up in a messy integration equation. Could you give me some suggestions to solve this equations? (Any method like substitutions etc are welcome). Kind of stucked my work because of this. I am giving you the integration equation as follows NB :: ""*"" notation also implies multiplication. Means $a \times b = ab=a*b$ Given Data in the question $   \lambda(t)  =   \left(\sqrt{\left( \frac{t}{2}A- a   \right )^2+\left(   \frac{t }{2}B- b   \right )^2+\left( \frac{t }{2}C- c    \right )^2} \right) \\= \sqrt{ \frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2)  }  \tag 1$ We here imply only positive square root. A,B,C,a,b and c are constants we cant alter the values. Only t is a variable here. 2.   $\phi(t)_0=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}A- a  \right)   \tag2$                      $\phi(t)_1=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}B- b  \right)     \tag3$   $\phi(t)_2=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}C- c  \right)     \tag2$ We have two  sets of questions. SET 1 is the original problem. I have added SET 2 as supplementary  because solving this will lead to the solution of SET 1. Any solution to either set 1 or set 2 is welcome. Main issue I face here is the difficulty to take out square root from sin . Note that A,B,C,a,b,c can have any real values. It is not necessary that the $\frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2) $ has equal roots Question SET 1 Is there anyway to solve $  \int \phi(t)_0 cos \left( \frac{t}{2}\lambda(t)\right) \ dt\tag 5$? Is there anyway to solve $  \int \phi(t)_0 \phi(t)_1 \ dt \tag 6$ ? Is there anyway to solve $  \int \phi(t)_1 \phi(t)_2 \ dt \tag 7$  ? SET 2 Is there anyway to solve $\displaystyle \int t^2\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c}  \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t^2\frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname dt \tag8$? Is there anyway to solve $\displaystyle  \int t \frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{ \sqrt{ at^2+bt+c}} \operatorname dt \tag8$? Some attempts currently I am trying Thinking about the possiblity of exponent expression of sin x and cos x  as here Thinking about the possibility of  product form results of sin xcos x  as here Thinking about substitution method by utilizing property $ax^2+bx+c =a \left(x+ \frac{b}{2a}\right)^2-\frac{b^2-4ac}{4a}$  as done here NB : So far I couldnot solve it. Main issue here is the square root inside trigonometric terms. It is difficult to convert it in to a solvable propblem Thanks for taking time to read my doubt. Hope nice suggestions and discussions",,"['calculus', 'integration', 'indefinite-integrals']"
9,Width of the Eiffel Tower as a function of height?,Width of the Eiffel Tower as a function of height?,,"In the preface of Advanced Engineering Mathematics, 2nd Ed. by Zill and Cullen, it is claimed that the function relating the width of the Eiffel Tower as to the distance from its top, $x \mapsto f(x)$, is given by the solution of the following equation: $$ af(x)\int_0^{x}f(t)^2\,dt=x\int_0^x f(t)\,dt - \int_0^x tf(t)\,dt $$ The authors invite readers who can solve this equation to email them the solution, and I have always wondered why they do this. Is it an open problem?","In the preface of Advanced Engineering Mathematics, 2nd Ed. by Zill and Cullen, it is claimed that the function relating the width of the Eiffel Tower as to the distance from its top, $x \mapsto f(x)$, is given by the solution of the following equation: $$ af(x)\int_0^{x}f(t)^2\,dt=x\int_0^x f(t)\,dt - \int_0^x tf(t)\,dt $$ The authors invite readers who can solve this equation to email them the solution, and I have always wondered why they do this. Is it an open problem?",,"['calculus', 'functional-equations']"
10,"Studying the function $f(x) = x^4-6x^2$ using derivatives: minima, maxima, inflection, concavity","Studying the function  using derivatives: minima, maxima, inflection, concavity",f(x) = x^4-6x^2,"(I know this is my second question today, but I'm explaining what I'm doing so I hope it's okay) Consider the graph of $f(x) = x^4-6x^2$. a) Find the relative maxima and minima (both x and y coordinates). I actually forgot how to do this.. not the point of my question though. b) Find the coordinates of the point(s) of inflection. So for this, you take the derivative of the derivative, correct? $f'(x) = 4x^3-12x$ $f''(x) = 12x^2-12.$ $f''(x)=0 \Leftrightarrow 12x^2 = 12 \Leftrightarrow x = -1, 1.$ So the points are $(-1,5)$ and $(1,5)$ (y coordinate from plugging back into the original)? c) Determine the interval(s) on which the function is increasing. When I set the derivative equal to zero to find the potential turning points, I get 0, rad 3, and negative rad 3. Forgot what to do from here. Not important. d) Determine the interval(s) on which the function is concave up. I get $(-\infty,-1) \cup (1,\infty)$ *Answer only what you want. Any help is appreciated! Source: http://online.math.uh.edu/apcalculus/exams/AB_SECTION_II_version_1.pdf - #4","(I know this is my second question today, but I'm explaining what I'm doing so I hope it's okay) Consider the graph of $f(x) = x^4-6x^2$. a) Find the relative maxima and minima (both x and y coordinates). I actually forgot how to do this.. not the point of my question though. b) Find the coordinates of the point(s) of inflection. So for this, you take the derivative of the derivative, correct? $f'(x) = 4x^3-12x$ $f''(x) = 12x^2-12.$ $f''(x)=0 \Leftrightarrow 12x^2 = 12 \Leftrightarrow x = -1, 1.$ So the points are $(-1,5)$ and $(1,5)$ (y coordinate from plugging back into the original)? c) Determine the interval(s) on which the function is increasing. When I set the derivative equal to zero to find the potential turning points, I get 0, rad 3, and negative rad 3. Forgot what to do from here. Not important. d) Determine the interval(s) on which the function is concave up. I get $(-\infty,-1) \cup (1,\infty)$ *Answer only what you want. Any help is appreciated! Source: http://online.math.uh.edu/apcalculus/exams/AB_SECTION_II_version_1.pdf - #4",,"['calculus', 'derivatives']"
11,Surface parametrization and calculating its area,Surface parametrization and calculating its area,,"I have to find the parametric equation of the surface of the sphere inside the cylinder and above the $z=0$ plane, as shown in this picture. $$ \text{Sphere: }x^2 + y^2 + z^2 = 1\\ \text{Cylinder: }x^2 + y^2 = x $$ I came up with this: $$ \vec r(x,y)=\left(x, y, \sqrt{1-(x^2 + y^2)}\right), \qquad (x,y) \in D $$ With $D$ being the projection of the cylinder on the $XY$ plane. However, it doesn't feel right, because the cylinder isn't on $(0,0)$. Could it be this? $$ \vec r(r,\theta)=\left(r \cos(\theta) + r, r \sin(\theta), \sqrt{1-r^2}\right), \qquad r\in[0,0.5],\  \theta\in [0,2\Pi] $$ Update : Seeing as the cylinder is shifted on the x axis (its center is on $(0.5, 0)$ with $r=0.5$), I thought about shifting the coordinate system so that $(0,0)$ is on the center of the cylinder. Here's the new equation and the new parametric surface: $$ \text{Sphere: }(x+0.5)^2 + y^2 + z^2 = 1\\ \text{Cylinder: }x^2 + y^2 = 0.5^2 $$ $$ \vec r(r,\theta)= \begin{cases} r \cos(\theta) \\ r \sin(\theta) \\ \sqrt{1-(r \cos{\theta} + 0.5)^2 - r^2 \sin^2{\theta}} = \sqrt{0.75 -r^2 - r \cos{\theta}} \end{cases}, \ \ r\in[0,0.5],\  \theta\in [0,2\Pi] $$ Is this better? Then I have to calculate $\vec r_r$ and $\vec r_\theta$. $$ \text{A} = \int_0^{2\Pi} \int_0^{0.5} \left\lVert \vec r_r \times \vec r_\theta \right\rVert r\operatorname d\!r \operatorname d\!\theta\, $$ However , I haven't taken into consideration that it's only the surface above the $z=0$ plane. I could always divide the answer by 2, but the $z$ part of $\vec r(r,\theta)$ has a square root. Does that mean that it's only considering the positive part of the $z$ axis (because it has to be positive)?","I have to find the parametric equation of the surface of the sphere inside the cylinder and above the $z=0$ plane, as shown in this picture. $$ \text{Sphere: }x^2 + y^2 + z^2 = 1\\ \text{Cylinder: }x^2 + y^2 = x $$ I came up with this: $$ \vec r(x,y)=\left(x, y, \sqrt{1-(x^2 + y^2)}\right), \qquad (x,y) \in D $$ With $D$ being the projection of the cylinder on the $XY$ plane. However, it doesn't feel right, because the cylinder isn't on $(0,0)$. Could it be this? $$ \vec r(r,\theta)=\left(r \cos(\theta) + r, r \sin(\theta), \sqrt{1-r^2}\right), \qquad r\in[0,0.5],\  \theta\in [0,2\Pi] $$ Update : Seeing as the cylinder is shifted on the x axis (its center is on $(0.5, 0)$ with $r=0.5$), I thought about shifting the coordinate system so that $(0,0)$ is on the center of the cylinder. Here's the new equation and the new parametric surface: $$ \text{Sphere: }(x+0.5)^2 + y^2 + z^2 = 1\\ \text{Cylinder: }x^2 + y^2 = 0.5^2 $$ $$ \vec r(r,\theta)= \begin{cases} r \cos(\theta) \\ r \sin(\theta) \\ \sqrt{1-(r \cos{\theta} + 0.5)^2 - r^2 \sin^2{\theta}} = \sqrt{0.75 -r^2 - r \cos{\theta}} \end{cases}, \ \ r\in[0,0.5],\  \theta\in [0,2\Pi] $$ Is this better? Then I have to calculate $\vec r_r$ and $\vec r_\theta$. $$ \text{A} = \int_0^{2\Pi} \int_0^{0.5} \left\lVert \vec r_r \times \vec r_\theta \right\rVert r\operatorname d\!r \operatorname d\!\theta\, $$ However , I haven't taken into consideration that it's only the surface above the $z=0$ plane. I could always divide the answer by 2, but the $z$ part of $\vec r(r,\theta)$ has a square root. Does that mean that it's only considering the positive part of the $z$ axis (because it has to be positive)?",,"['calculus', 'parametric']"
12,The second derivative as a limit,The second derivative as a limit,,"It is well-known that if $f$ is twice differentiable at $a$, then $$ f''(a) = \lim_{h\to 0} \frac{f(a+2h)-2f(a+h) + f(a)}{h^2}. $$ See e.g. this question or this question . On the other hand, the RHS limit may exist without $f$ being twice differentiable.  For instance, if $f(x) = x^3 \sin(1/x)$ for $x\neq 0$ and $f(0)=0$, then at $a=0$ the RHS is $2h(4\sin(1/2h) - \sin(1/h))$, which has limit $0$; but this function $f$ is not twice differentiable at $0$. My question is, under what additional hypotheses can we conclude from the existence of the RHS limit that $f$ is twice differentiable? We probably need to assume that $f$ is once differentiable on a neighborhood of $a$, but that is not sufficient since the counterexample above is in fact smooth at all points $x\neq 0$.  For the same reason, it is not sufficient to assume that the above limit exists for all $a$ in some neighborhood. Note that this is not the same as this question , which is asking for a limit definition of the second derivative that doesn't require extra hypotheses; here I'm asking what extra hypotheses can be added to this particular definition to make it work.","It is well-known that if $f$ is twice differentiable at $a$, then $$ f''(a) = \lim_{h\to 0} \frac{f(a+2h)-2f(a+h) + f(a)}{h^2}. $$ See e.g. this question or this question . On the other hand, the RHS limit may exist without $f$ being twice differentiable.  For instance, if $f(x) = x^3 \sin(1/x)$ for $x\neq 0$ and $f(0)=0$, then at $a=0$ the RHS is $2h(4\sin(1/2h) - \sin(1/h))$, which has limit $0$; but this function $f$ is not twice differentiable at $0$. My question is, under what additional hypotheses can we conclude from the existence of the RHS limit that $f$ is twice differentiable? We probably need to assume that $f$ is once differentiable on a neighborhood of $a$, but that is not sufficient since the counterexample above is in fact smooth at all points $x\neq 0$.  For the same reason, it is not sufficient to assume that the above limit exists for all $a$ in some neighborhood. Note that this is not the same as this question , which is asking for a limit definition of the second derivative that doesn't require extra hypotheses; here I'm asking what extra hypotheses can be added to this particular definition to make it work.",,"['calculus', 'real-analysis', 'derivatives']"
13,Integral $I=\int_0^1 \frac{\log x \log (1+x) \log(1-x) \log(1+x^2)\log(1-x^2)}{x^{3/2}}dx$,Integral,I=\int_0^1 \frac{\log x \log (1+x) \log(1-x) \log(1+x^2)\log(1-x^2)}{x^{3/2}}dx,"Hi I am trying to integrate and obtain a closed form result for $$ I:=\int_0^1 \frac{\log x \log (1+x) \log(1-x) \log(1+x^2)\log(1-x^2)}{x^{3/2}}dx. $$ Here is what I tried (but I do not think this is a smart way because of all the sums): writing $$ I=\int_0^1 \frac{dx\log x}{x^{3/2}} \sum_{n=1}^\infty\frac{ (-1)^{n}x^n}{n}\sum_{m=1}^\infty \frac{x^m}{m}\sum_{l=1}^\infty \frac{(-1)^lx^{2l}}{l}\sum_{p=1}^\infty \frac{(-1)^p(-x^2)^{p}}{p}. $$ Now we can write $$ \sum_{n=1}^\infty\frac{ (-1)^{n}}{n}\sum_{m=1}^\infty \frac{1}{m}\sum_{l=1}^\infty \frac{(-1)^l}{l}\sum_{p=1}^\infty \frac{1}{p} \int_0^1  x^{n+m+2l+2p-3/2}\log x \, dx.  $$  We can simplify this as $$ \sum_{n=1}^\infty \frac{ (-1)^{n}}{n}v\sum_{m=1}^\infty \frac{1}{m}\sum_{l=1}^\infty \frac{(-1)^l}{l}\sum_{p=1}^\infty \frac{1}{p}\left[ \frac{-1}{\big(  n+m+2l+2p -\frac{1}{2}  \big)^2}\right]. $$ I am stuck as to what to do From here,  note above I used $$ -\sum_{n=1}^\infty \frac{x^n}{n}=\log(1-x),\quad \log(1+x)=-\sum_{n=1}^\infty \frac{(-1)^{n}x^n}{n},\quad \int_0^1 x^n \log x \, dx =\frac{-1}{(n+1)^2}. $$","Hi I am trying to integrate and obtain a closed form result for $$ I:=\int_0^1 \frac{\log x \log (1+x) \log(1-x) \log(1+x^2)\log(1-x^2)}{x^{3/2}}dx. $$ Here is what I tried (but I do not think this is a smart way because of all the sums): writing $$ I=\int_0^1 \frac{dx\log x}{x^{3/2}} \sum_{n=1}^\infty\frac{ (-1)^{n}x^n}{n}\sum_{m=1}^\infty \frac{x^m}{m}\sum_{l=1}^\infty \frac{(-1)^lx^{2l}}{l}\sum_{p=1}^\infty \frac{(-1)^p(-x^2)^{p}}{p}. $$ Now we can write $$ \sum_{n=1}^\infty\frac{ (-1)^{n}}{n}\sum_{m=1}^\infty \frac{1}{m}\sum_{l=1}^\infty \frac{(-1)^l}{l}\sum_{p=1}^\infty \frac{1}{p} \int_0^1  x^{n+m+2l+2p-3/2}\log x \, dx.  $$  We can simplify this as $$ \sum_{n=1}^\infty \frac{ (-1)^{n}}{n}v\sum_{m=1}^\infty \frac{1}{m}\sum_{l=1}^\infty \frac{(-1)^l}{l}\sum_{p=1}^\infty \frac{1}{p}\left[ \frac{-1}{\big(  n+m+2l+2p -\frac{1}{2}  \big)^2}\right]. $$ I am stuck as to what to do From here,  note above I used $$ -\sum_{n=1}^\infty \frac{x^n}{n}=\log(1-x),\quad \log(1+x)=-\sum_{n=1}^\infty \frac{(-1)^{n}x^n}{n},\quad \int_0^1 x^n \log x \, dx =\frac{-1}{(n+1)^2}. $$",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'summation']"
14,Calculation of $\lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2}$,Calculation of,\lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2},"Calculation of $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2}$ $\bf{My\; Try::}$ Given $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2} = \lim_{x\rightarrow 0}\frac{\sin (\pi (1-\sin^2 x))}{x^2}$ $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi \sin^2 x)}{\pi\sin^2 x} \times \pi \times \lim_{x\rightarrow 0} \frac{\sin^2 x}{x^2} = \pi$ Is there is any other method by which we can solve the above question. If yes, The please help me . Thanks","Calculation of $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2}$ $\bf{My\; Try::}$ Given $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi\cos^2 x)}{x^2} = \lim_{x\rightarrow 0}\frac{\sin (\pi (1-\sin^2 x))}{x^2}$ $\displaystyle \lim_{x\rightarrow 0}\frac{\sin (\pi \sin^2 x)}{\pi\sin^2 x} \times \pi \times \lim_{x\rightarrow 0} \frac{\sin^2 x}{x^2} = \pi$ Is there is any other method by which we can solve the above question. If yes, The please help me . Thanks",,['calculus']
15,When should one use the two-point compactification of $\mathbb R$?,When should one use the two-point compactification of ?,\mathbb R,"The real line $\mathbb R$ has a one-point compactification $\mathbb R\cup\{\infty\}$, where this ""$\infty$"" is at both ends of the line, so that the compactification is topologically a circle. It also has a two-point compactification $\mathbb R\cup\{\pm\infty\}$. With rational functions $\lim\limits_{x\to\pm\infty}$ doesn't depend on whether it's $+$ or $-$.  With vertical asymptotes, if one wishes to distinguish between two different ways of blowing up, one could say $f(x)\to\infty\!-$, i.e. $f(x)$ approaches $\infty$ from below, instead of $f(x)\to+\infty$, and similarly for the other direction.  That makes rational functions continuous everywhere, including the points where they have vertical asymptotes and the point $x=\infty$. With trigonometric functions, one can take the domain to be $\mathbb R/2\pi\mathbb Z$ and the codomain to be $\mathbb R\cup\{\infty\}$ and treat vertical asymptotes as with rational functions.  That also makes trigonometric functions continuous even at points where they have vertical asymptotes, and the function $\theta\mapsto\tan(\theta/2)$ becomes a homeomorphism from $\mathbb R/2\pi\mathbb Z$ to $\mathbb R\cup\{\infty\}$. This seems like a more felicitous way of doing things than any that involves two infinities. When, then, should one distinguish between $\pm\infty$?  Part of the answer seems to be with exponential functions: $$ e^x\to\begin{cases} 0 & \text{as }x\to-\infty, \\ \infty & \text{as }x\to+\infty. \end{cases} $$ In that case, it doesn't seem to make as much sense to say ""as $x\to\infty\!+$"" and ""as $x\to\infty\!-$"".  Similarly $$ \arctan x \to \pm\frac\pi2\text{ according as }x\to\pm\infty. $$ Is there more to the story than that?  If not, should we abandon $\pm$ in the case of rational functions and trigonometric functions?","The real line $\mathbb R$ has a one-point compactification $\mathbb R\cup\{\infty\}$, where this ""$\infty$"" is at both ends of the line, so that the compactification is topologically a circle. It also has a two-point compactification $\mathbb R\cup\{\pm\infty\}$. With rational functions $\lim\limits_{x\to\pm\infty}$ doesn't depend on whether it's $+$ or $-$.  With vertical asymptotes, if one wishes to distinguish between two different ways of blowing up, one could say $f(x)\to\infty\!-$, i.e. $f(x)$ approaches $\infty$ from below, instead of $f(x)\to+\infty$, and similarly for the other direction.  That makes rational functions continuous everywhere, including the points where they have vertical asymptotes and the point $x=\infty$. With trigonometric functions, one can take the domain to be $\mathbb R/2\pi\mathbb Z$ and the codomain to be $\mathbb R\cup\{\infty\}$ and treat vertical asymptotes as with rational functions.  That also makes trigonometric functions continuous even at points where they have vertical asymptotes, and the function $\theta\mapsto\tan(\theta/2)$ becomes a homeomorphism from $\mathbb R/2\pi\mathbb Z$ to $\mathbb R\cup\{\infty\}$. This seems like a more felicitous way of doing things than any that involves two infinities. When, then, should one distinguish between $\pm\infty$?  Part of the answer seems to be with exponential functions: $$ e^x\to\begin{cases} 0 & \text{as }x\to-\infty, \\ \infty & \text{as }x\to+\infty. \end{cases} $$ In that case, it doesn't seem to make as much sense to say ""as $x\to\infty\!+$"" and ""as $x\to\infty\!-$"".  Similarly $$ \arctan x \to \pm\frac\pi2\text{ according as }x\to\pm\infty. $$ Is there more to the story than that?  If not, should we abandon $\pm$ in the case of rational functions and trigonometric functions?",,"['calculus', 'real-analysis', 'general-topology']"
16,"Does there exist $f:(0,\infty)\to(0,\infty)$ such that $f'=f^{-1}$?",Does there exist  such that ?,"f:(0,\infty)\to(0,\infty) f'=f^{-1}","Recently the following question was posed: does there exist a differentiable bijection $f:\mathbb R\to\mathbb R$ such that $f'=f^{-1}$ ? (Here, $f^{-1}$ is the inverse of $f$ with respect to composition of functions.) The answer, as it turns out, is negative, because such a bijection is monotonic, which implies that the derivative cannot be bijective. There seem to be no such problems if we instead search for a bijection $f:(0,\infty)\to(0,\infty)$ such that $f'=f^{-1}$ , so the following variation of the question seems interesting: Does there exist a differentiable bijection $f:(0,\infty)\to(0,\infty)$ such that $f'=f^{-1}$ ? ( Edit: as mentioned at the end of this question, the question of existence has been resolved. Is the solution unique?) Here's the first idea: if there is a function $f:(0,\infty)\to(0,\infty)$ such that $f'(x)=f^{-1}(x)$ holds for all $x\in(0,\infty)$ , then $$f'(f(x))=f^{-1}(f(x))=x$$ also must hold for all $x$ , since $f$ is bijective. This immediately reminds us of the chain rule, so we multiply by $f'(x)$ to yield $$f'(f(x))f'(x)=xf'(x)$$ which is equivalent to $$f'(f(x))f'(x)=xf'(x)+f(x)-f(x).$$ This implies (integrate from $1$ to $x$ , for instance) that there is a primitive function $F$ of $f$ such that $$f(f(x)) = x f(x) - F(x)$$ holds for all $x\in(0,\infty)$ , so we may try solving this equation instead. I don't know if this is any easier than the original problem, though. Maybe some kind of fixed point principle might work to show existence? It would be very nice if it turns out that there is a nice characterization of such functions. Edit: At the link pointed out by Christian Blatter in the comments there is an explicit solution ( $f(x)=\frac{x^\phi}{\phi^{\phi-1}}$ , where $\phi=\frac{1+\sqrt5}{2}$ is the golden ratio), so maybe it would also be interesting to know: Is this solution unique?","Recently the following question was posed: does there exist a differentiable bijection such that ? (Here, is the inverse of with respect to composition of functions.) The answer, as it turns out, is negative, because such a bijection is monotonic, which implies that the derivative cannot be bijective. There seem to be no such problems if we instead search for a bijection such that , so the following variation of the question seems interesting: Does there exist a differentiable bijection such that ? ( Edit: as mentioned at the end of this question, the question of existence has been resolved. Is the solution unique?) Here's the first idea: if there is a function such that holds for all , then also must hold for all , since is bijective. This immediately reminds us of the chain rule, so we multiply by to yield which is equivalent to This implies (integrate from to , for instance) that there is a primitive function of such that holds for all , so we may try solving this equation instead. I don't know if this is any easier than the original problem, though. Maybe some kind of fixed point principle might work to show existence? It would be very nice if it turns out that there is a nice characterization of such functions. Edit: At the link pointed out by Christian Blatter in the comments there is an explicit solution ( , where is the golden ratio), so maybe it would also be interesting to know: Is this solution unique?","f:\mathbb R\to\mathbb R f'=f^{-1} f^{-1} f f:(0,\infty)\to(0,\infty) f'=f^{-1} f:(0,\infty)\to(0,\infty) f'=f^{-1} f:(0,\infty)\to(0,\infty) f'(x)=f^{-1}(x) x\in(0,\infty) f'(f(x))=f^{-1}(f(x))=x x f f'(x) f'(f(x))f'(x)=xf'(x) f'(f(x))f'(x)=xf'(x)+f(x)-f(x). 1 x F f f(f(x)) = x f(x) - F(x) x\in(0,\infty) f(x)=\frac{x^\phi}{\phi^{\phi-1}} \phi=\frac{1+\sqrt5}{2}",['analysis']
17,Transversality condition equation,Transversality condition equation,,"I'm somewhat baffled:  I have a problem in  calculus of variations: $$ \int_0^T \!(x-\dot x^2)dt,\qquad x(0)=0,\qquad x(T)=T^2-2. $$ Let $ F(t,x, \dot x) =x-\dot x^2. $ I calculate all the necessary derivatives: $$F_x=1 \qquad F_{\dot x} = -2\dot x \qquad \frac{d}{dt}F_{\dot x} = -2\ddot x$$ and write down an Euler-Lagrange equation: $1+2\ddot x=0$ And calculate my quotients: $$x=c_1t+c_2-\frac{t^2}{4} \qquad x(0)=0 \Longrightarrow  c_2=0$$ And then I get stuck: I know that if I have $$ J = \int_{t_1}^{t_2} F(t,x,\dot x) dt $$and the right end follows a curve $x=\varphi(t)$, the transversality condition should hold: $$ F(t_2,x_2, \dot x_2) + [\dot \varphi(t_2)-\dot x_2]F_{\dot x}(t_2,x_2, \dot x_2) =0 $$ where $x_2=x(t_2)$. But I can't wrap my mind about it: what is $\varphi$ in my case, and how would the transversality equation look like?  Please help with any hints.","I'm somewhat baffled:  I have a problem in  calculus of variations: $$ \int_0^T \!(x-\dot x^2)dt,\qquad x(0)=0,\qquad x(T)=T^2-2. $$ Let $ F(t,x, \dot x) =x-\dot x^2. $ I calculate all the necessary derivatives: $$F_x=1 \qquad F_{\dot x} = -2\dot x \qquad \frac{d}{dt}F_{\dot x} = -2\ddot x$$ and write down an Euler-Lagrange equation: $1+2\ddot x=0$ And calculate my quotients: $$x=c_1t+c_2-\frac{t^2}{4} \qquad x(0)=0 \Longrightarrow  c_2=0$$ And then I get stuck: I know that if I have $$ J = \int_{t_1}^{t_2} F(t,x,\dot x) dt $$and the right end follows a curve $x=\varphi(t)$, the transversality condition should hold: $$ F(t_2,x_2, \dot x_2) + [\dot \varphi(t_2)-\dot x_2]F_{\dot x}(t_2,x_2, \dot x_2) =0 $$ where $x_2=x(t_2)$. But I can't wrap my mind about it: what is $\varphi$ in my case, and how would the transversality equation look like?  Please help with any hints.",,"['calculus', 'calculus-of-variations']"
18,"Why can I integrate something like ""infinitesimal part"" to calculate the length, area, volume, etc.?","Why can I integrate something like ""infinitesimal part"" to calculate the length, area, volume, etc.?",,"Let me try to elaborate the question by an example: I want to calculate the length of a straight line like $y=x$ between $[0, 1]$. By conventional way I would do a definite integration of integrand $\sqrt{dx^2 + dy^2}$. But why I can not choose other kind of ""measure"" of that ""infinitesimal part""? For example, an integrand looks like Manhattan distance $dx + dy$, or probability? Is there any criterion to choose which kind of integrand in integration? P.S. You may notice that I use the word ""measure"". Actually I do not know the exact definition of that word in mathematics.","Let me try to elaborate the question by an example: I want to calculate the length of a straight line like $y=x$ between $[0, 1]$. By conventional way I would do a definite integration of integrand $\sqrt{dx^2 + dy^2}$. But why I can not choose other kind of ""measure"" of that ""infinitesimal part""? For example, an integrand looks like Manhattan distance $dx + dy$, or probability? Is there any criterion to choose which kind of integrand in integration? P.S. You may notice that I use the word ""measure"". Actually I do not know the exact definition of that word in mathematics.",,"['calculus', 'real-analysis']"
19,slowness of growth of polynomials,slowness of growth of polynomials,,"How to show that for any $d\in\mathbb{N}$ and $\delta>0$ there exists $\varepsilon=\varepsilon(d,\delta)>0$ such that is $f$ is a polynomial of degree $d$, and $$|f(t)|\leq 1,\quad t\in[0,1],$$ then $$|f(t)|<1+\delta,\quad t\in[0,1+\varepsilon].$$  (This is an exercise from ""Introduction to Ratner Theorems..."" by D.W. Morris). It is immediate for $d=0,1,2$, but I am probably lacking some trick to approach the general case. Any help is greatly appreciated.","How to show that for any $d\in\mathbb{N}$ and $\delta>0$ there exists $\varepsilon=\varepsilon(d,\delta)>0$ such that is $f$ is a polynomial of degree $d$, and $$|f(t)|\leq 1,\quad t\in[0,1],$$ then $$|f(t)|<1+\delta,\quad t\in[0,1+\varepsilon].$$  (This is an exercise from ""Introduction to Ratner Theorems..."" by D.W. Morris). It is immediate for $d=0,1,2$, but I am probably lacking some trick to approach the general case. Any help is greatly appreciated.",,"['calculus', 'real-analysis']"
20,Riemann integrable proof,Riemann integrable proof,,"Let $f:[-1,1]$ be Riemann integrable and $\psi(x)=x\ sin(\frac{1}{x})$ for $0<x\leq1$ and $\psi(0)=0$.  Show that $x\mapsto f(\psi(x))$ is Riemann integrable over $[0,1]$. Also, just curious ... does the same conclusion hold if $\psi$ is changed to $\psi(x)=\sqrt{x}\ sin(\frac{1}{x})$ for $x>0$? Appreciated for all the help!","Let $f:[-1,1]$ be Riemann integrable and $\psi(x)=x\ sin(\frac{1}{x})$ for $0<x\leq1$ and $\psi(0)=0$.  Show that $x\mapsto f(\psi(x))$ is Riemann integrable over $[0,1]$. Also, just curious ... does the same conclusion hold if $\psi$ is changed to $\psi(x)=\sqrt{x}\ sin(\frac{1}{x})$ for $x>0$? Appreciated for all the help!",,['calculus']
21,Log-concave functions whose sums are still log-concave: possible to find a subset?,Log-concave functions whose sums are still log-concave: possible to find a subset?,,"Rationale: I am puzzled by a problem of log-concavity, which arises in population dynamics where the curvature of the logarithm of sums is a quantity of interest. It is well-known that sums of log-convex functions are log-convex (used in Cohen 1980, ref. below).  However, not all sums of log-concave functions are also log-concave. This is important to me because many convex functions are log-concave. My investigation so far suggests that log-concavity of the sum is frequent when the functions are log-concave but convex, and similar. I would therefore like to delineate the set of real-valued log-concave AND convex functions whose sums are log-concave, conditional on some further restrictions. Any hint appreciated. Formal definition of the problem: Let $r(x) = \ln(b(x)+s(x))$ be the quantity of interest, with $b$ and $s$ functions obeying properties P0-4. P0: Defined over some interval $I=[0, x_c] , x_c \in \mathbb{R}^{+}$ P1: Positive P2: Increasing P3: Convex P4: Log-concave ($\forall x \in I, \ln(f(x))''<0$, $f=b,s$) What additional conditions on $b(x)$ and $s(x)$ are needed to obtain $r''(x)<0$? Two instructive cases: Let's assume $b(x)=b_m f(x), s(x)=s_m f(x)$, with $f(x)$ obeying P0-4.  Then $r(x) = \ln(b_m f(x)+s_m f(x))= \ln(s_m+b_m) + \ln(f(x))$.  If $b,s$ obey P0-4, then $\ln(f(x))''<0$ which implies $r''(x)<0$. Here the two functions are nearly equal, but numerical investigations suggest that whenever first and second derivatives of $b(x)$ and $s(x)$ are relatively close, log-concavity follows. Power functions are good examples of convex yet log-concave functions. Let us assume that $s(x)=x^{1+\alpha}$ and $b(x)=x^\beta$, $\alpha,\beta>0$. Using $\alpha = 1$ so that $s(x) = x^2$, one can show numerically that $r(x)$ is concave if $\beta<6$. When $\beta>6$, for some values $x_0 \approx 1$, we observe $r''(x_0)>0$. General question: Q0. Has this problem been treated previously? If yes, for what kind of functions? Polynomials? Questions on possible ways to tackle the problem: Q1. A sufficient condition for log-concavity of the sum ($r''(x)<0$) is log-concavity of $1+b(x)/s(x)$. Could that lead somewhere, studying properties of the ratio $b(x)/s(x)$? Q2. Flipping the problem on its head, log-convexity of the sum (i.e. $r''(x)>0$) yields a necessary condition $b''(x)s(x)-b'(x)s'(x)>0$ (or equivalent one exchanging $b$ and $s$). Proof: developing $f''(x)f(x)-f'(x)^2>0$ with $f=b+s$. Rewriting the above expression suggests $k(x)=b'(x)/s(x)$ has to verify $\ln(k(x))'>0$.  Is this a worthwhile thread of research, or should I try directly to get sufficient conditions? Q3. Numerical investigations suggest that two conditions are necessary to meet $\exists x_0 \in I, r''(x_0)>0$: $s(x_0)$ and $b(x_0)$ of commensurate values. Otherwise, the behaviour of one function dominates that of the other, $\ln(b(x)+s(x)) \approx_{x_0} \ln(b(x))$, if $b(x_0)>>s(x_0)$. $s''(x_0)$ and $b''(x_0)$ are very dissimilar (e.g. $6 \times 5 >> 2$ for $x \approx 1$ in the power function example with $\alpha=1$). Could these be used to derive more general criteria? Biblio: Cohen, J. E. (1980). Convexity properties of products of random nonnegative matrices. Proceedings of the National Academy of Sciences, 77(7), 3749-3752.","Rationale: I am puzzled by a problem of log-concavity, which arises in population dynamics where the curvature of the logarithm of sums is a quantity of interest. It is well-known that sums of log-convex functions are log-convex (used in Cohen 1980, ref. below).  However, not all sums of log-concave functions are also log-concave. This is important to me because many convex functions are log-concave. My investigation so far suggests that log-concavity of the sum is frequent when the functions are log-concave but convex, and similar. I would therefore like to delineate the set of real-valued log-concave AND convex functions whose sums are log-concave, conditional on some further restrictions. Any hint appreciated. Formal definition of the problem: Let $r(x) = \ln(b(x)+s(x))$ be the quantity of interest, with $b$ and $s$ functions obeying properties P0-4. P0: Defined over some interval $I=[0, x_c] , x_c \in \mathbb{R}^{+}$ P1: Positive P2: Increasing P3: Convex P4: Log-concave ($\forall x \in I, \ln(f(x))''<0$, $f=b,s$) What additional conditions on $b(x)$ and $s(x)$ are needed to obtain $r''(x)<0$? Two instructive cases: Let's assume $b(x)=b_m f(x), s(x)=s_m f(x)$, with $f(x)$ obeying P0-4.  Then $r(x) = \ln(b_m f(x)+s_m f(x))= \ln(s_m+b_m) + \ln(f(x))$.  If $b,s$ obey P0-4, then $\ln(f(x))''<0$ which implies $r''(x)<0$. Here the two functions are nearly equal, but numerical investigations suggest that whenever first and second derivatives of $b(x)$ and $s(x)$ are relatively close, log-concavity follows. Power functions are good examples of convex yet log-concave functions. Let us assume that $s(x)=x^{1+\alpha}$ and $b(x)=x^\beta$, $\alpha,\beta>0$. Using $\alpha = 1$ so that $s(x) = x^2$, one can show numerically that $r(x)$ is concave if $\beta<6$. When $\beta>6$, for some values $x_0 \approx 1$, we observe $r''(x_0)>0$. General question: Q0. Has this problem been treated previously? If yes, for what kind of functions? Polynomials? Questions on possible ways to tackle the problem: Q1. A sufficient condition for log-concavity of the sum ($r''(x)<0$) is log-concavity of $1+b(x)/s(x)$. Could that lead somewhere, studying properties of the ratio $b(x)/s(x)$? Q2. Flipping the problem on its head, log-convexity of the sum (i.e. $r''(x)>0$) yields a necessary condition $b''(x)s(x)-b'(x)s'(x)>0$ (or equivalent one exchanging $b$ and $s$). Proof: developing $f''(x)f(x)-f'(x)^2>0$ with $f=b+s$. Rewriting the above expression suggests $k(x)=b'(x)/s(x)$ has to verify $\ln(k(x))'>0$.  Is this a worthwhile thread of research, or should I try directly to get sufficient conditions? Q3. Numerical investigations suggest that two conditions are necessary to meet $\exists x_0 \in I, r''(x_0)>0$: $s(x_0)$ and $b(x_0)$ of commensurate values. Otherwise, the behaviour of one function dominates that of the other, $\ln(b(x)+s(x)) \approx_{x_0} \ln(b(x))$, if $b(x_0)>>s(x_0)$. $s''(x_0)$ and $b''(x_0)$ are very dissimilar (e.g. $6 \times 5 >> 2$ for $x \approx 1$ in the power function example with $\alpha=1$). Could these be used to derive more general criteria? Biblio: Cohen, J. E. (1980). Convexity properties of products of random nonnegative matrices. Proceedings of the National Academy of Sciences, 77(7), 3749-3752.",,"['calculus', 'functions', 'logarithms', 'convex-analysis']"
22,Need an $ f $ so that $ 0 < -\left(f'(x) + \frac{f''(x)}{f'(x)}\right) < \epsilon/x $ and $ e^{f(x)}/x \stackrel{x \to \infty}{\longrightarrow} 0 $.,Need an  so that  and ., f   0 < -\left(f'(x) + \frac{f''(x)}{f'(x)}\right) < \epsilon/x   e^{f(x)}/x \stackrel{x \to \infty}{\longrightarrow} 0 ,"First-time poster. Please forgive me if I do something unorthodox. To be more specific, I need a function $f:[0,+\infty)\to[0,+\infty)$ so that $f$ is nondegenerate, nondecreasing, continuous, $$\lim_{x\to+\infty}\frac{e^{f(x)}}{x}=0$$ and  $\forall\,\varepsilon>0\,\exists\,x_0\geq0$ such that $$0<-\left(f'(x)+\frac{f''(x)}{f'(x)}\right)<\frac{\varepsilon}{x}$$ for $x>x_0$. I've tried a good number of functions and I just can't get it to work.  I'm beginning to think there may be no such function. Also, it would be fine if $f$ is not an elementary function.  Like start with $f'$ and get an antiderivative. Thanks in advance.","First-time poster. Please forgive me if I do something unorthodox. To be more specific, I need a function $f:[0,+\infty)\to[0,+\infty)$ so that $f$ is nondegenerate, nondecreasing, continuous, $$\lim_{x\to+\infty}\frac{e^{f(x)}}{x}=0$$ and  $\forall\,\varepsilon>0\,\exists\,x_0\geq0$ such that $$0<-\left(f'(x)+\frac{f''(x)}{f'(x)}\right)<\frac{\varepsilon}{x}$$ for $x>x_0$. I've tried a good number of functions and I just can't get it to work.  I'm beginning to think there may be no such function. Also, it would be fine if $f$ is not an elementary function.  Like start with $f'$ and get an antiderivative. Thanks in advance.",,['calculus']
23,Watson's Lemma Extension,Watson's Lemma Extension,,"We all know that Watson's Lemma is used to approximate the integral $$ F\left( s \right)=\int_0^\infty  {{e^{ - st}}f\left( t \right)dt}  $$ for large $s$.  However, for arbitrary $s$, are there any methods to approximate $F(s)$?","We all know that Watson's Lemma is used to approximate the integral $$ F\left( s \right)=\int_0^\infty  {{e^{ - st}}f\left( t \right)dt}  $$ for large $s$.  However, for arbitrary $s$, are there any methods to approximate $F(s)$?",,"['calculus', 'approximation']"
24,"Simple Power Series Expansion for Problems similar to $f = (1 + \epsilon \,x)^{1/\epsilon}$",Simple Power Series Expansion for Problems similar to,"f = (1 + \epsilon \,x)^{1/\epsilon}","I was flicking through a book on perturbation methods and saw a simple question asking the reader to expand the following expression for $f$ in a power series (up to the first 2 terms): $f = (1 + \epsilon \,x)^{1/\epsilon}$, where $\epsilon$ is a small parameter. I'm sure this is very simple, but I wasn't certain about the best way to approach this. A quick look at mathematica tells me the solution is $e^x - \frac{1}{2} (e^x x^2) \,\epsilon + ...$. How would I go about getting this answer - and more importantly, how would I systematically find series expansions for problems similar to this one?","I was flicking through a book on perturbation methods and saw a simple question asking the reader to expand the following expression for $f$ in a power series (up to the first 2 terms): $f = (1 + \epsilon \,x)^{1/\epsilon}$, where $\epsilon$ is a small parameter. I'm sure this is very simple, but I wasn't certain about the best way to approach this. A quick look at mathematica tells me the solution is $e^x - \frac{1}{2} (e^x x^2) \,\epsilon + ...$. How would I go about getting this answer - and more importantly, how would I systematically find series expansions for problems similar to this one?",,['power-series']
25,Good introductory book for matrix calculus,Good introductory book for matrix calculus,,Hi I am an electronics graduate and working on image processing for the past one year...I have a basic exposure to linear algebra(thanks to Gilbert Strang..!!!). Now I am facing problems with matrix calculus and its notation because many image processing algorithms are using matrix and vector calculus...please refer me some introductory book for matrix calculus or linear algebra books containing calculus concepts...just out of curosity...will a multivariate calculus book serve the introductions i am looking for?? if yes...do suggest be one...,Hi I am an electronics graduate and working on image processing for the past one year...I have a basic exposure to linear algebra(thanks to Gilbert Strang..!!!). Now I am facing problems with matrix calculus and its notation because many image processing algorithms are using matrix and vector calculus...please refer me some introductory book for matrix calculus or linear algebra books containing calculus concepts...just out of curosity...will a multivariate calculus book serve the introductions i am looking for?? if yes...do suggest be one...,,"['calculus', 'linear-algebra', 'matrices', 'reference-request', 'multivariable-calculus']"
26,Adjoint of the infinitesimal generator of a stochastic process,Adjoint of the infinitesimal generator of a stochastic process,,"I need help seeing that  $$ \mathcal{L}^* g = -\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2} $$ is the adjoint operator of $$ \mathcal{L} = b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2} $$ in the $L^2$ sense $\langle \mathcal{L}f,g\rangle = \langle f,\mathcal{L}^*g\rangle$, where $b(x)$ and $\sigma(x)$ are some suitable functions. Doing the computations I arrive to  $$ \eqalign{ \langle \mathcal{L}f,g\rangle &= \int_{\mathbb{R}} \left(b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2}\right)g dx = \cdots\text{by parts x2} \cr  &= \int_{\mathbb{R}}f\left(-\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2}\right)dx +   \left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty}\ . } $$ So basically I need help understanding in what circumstances $$ \left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty} = 0 $$ so that $\mathcal{L}^*$ is the adjoint of $\mathcal{L}$. (Reference Robert V.Kohn ch1 pg 14 .)","I need help seeing that  $$ \mathcal{L}^* g = -\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2} $$ is the adjoint operator of $$ \mathcal{L} = b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2} $$ in the $L^2$ sense $\langle \mathcal{L}f,g\rangle = \langle f,\mathcal{L}^*g\rangle$, where $b(x)$ and $\sigma(x)$ are some suitable functions. Doing the computations I arrive to  $$ \eqalign{ \langle \mathcal{L}f,g\rangle &= \int_{\mathbb{R}} \left(b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2}\right)g dx = \cdots\text{by parts x2} \cr  &= \int_{\mathbb{R}}f\left(-\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2}\right)dx +   \left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty}\ . } $$ So basically I need help understanding in what circumstances $$ \left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty} = 0 $$ so that $\mathcal{L}^*$ is the adjoint of $\mathcal{L}$. (Reference Robert V.Kohn ch1 pg 14 .)",,"['calculus', 'functional-analysis', 'partial-differential-equations', 'operator-theory']"
27,How does one determine $n$-spheres of curvature?,How does one determine -spheres of curvature?,n,"I am aware of circles of curvature and I am simply wondering to what extent does this generalize to $n$-dimensions.  Specifically, if some surface in $n$-dimensional space is represented parametricaly, how does one determine the $n$-sphere of curvature at any given point?","I am aware of circles of curvature and I am simply wondering to what extent does this generalize to $n$-dimensions.  Specifically, if some surface in $n$-dimensional space is represented parametricaly, how does one determine the $n$-sphere of curvature at any given point?",,"['calculus', 'analysis', 'differential-geometry']"
28,Is continuity at a point only defined for points in the domain?,Is continuity at a point only defined for points in the domain?,,"I'm using Michael Spivak's Calculus , 3rd edition textbook. Without ado, I'll state the definition given for continuity at a point: DEFINITION $\;\;\;\;$The function $f$ is continuous at $a$ if: $$\lim_{x\to a}f(x) = f(a)$$ And I might as well give the definition for the limit at a point: DEFINITION $\;\;\;\;$The function $f$ approaches the limit $l$ near $a$ means: for every $\epsilon>0$ there is some $\delta>0$ such that, for all $x$, if $0<|x-a|<\delta$, then $|f(x)-l|<\epsilon$. It is clear, then, that in order to verify whether a function is continuous at a point $a$, we need to compute $f(a)$, and this is only possible if $a$ is in the domain of $f$. So, what happens when a point $a$ is not in the domain of $f$? On this matter, I've had some people telling me that statements about continuity only make for points in the domain of $f$. Spivak himself also mentions in the Continuity chapter of his textbook that ""We also often simply say that a function is continuous if it is continuous at $x$ for all $x$ in its domain."" But that means functions like $f(x) = \frac{1}{x}$, $f(x) = \frac{1}{x^2-1}$ and $f(x) = \sin{\frac{1}{x}}$ can all be said to be continuous. It just doesn't seem right, in fact I always thought these were textbook examples of discontinuous functions. It also means that we can't say that $f(x) = \frac{1}{x}$ is discontinuous at $0$, because we don't even know the value of $f(0)$ in order to decide whether it's continuous or not. Are all of these conclusions correct, or did I misinterpret the definitions? I'd love if someone could shed some light on this, I'm having a hard time wrapping my head around it.","I'm using Michael Spivak's Calculus , 3rd edition textbook. Without ado, I'll state the definition given for continuity at a point: DEFINITION $\;\;\;\;$The function $f$ is continuous at $a$ if: $$\lim_{x\to a}f(x) = f(a)$$ And I might as well give the definition for the limit at a point: DEFINITION $\;\;\;\;$The function $f$ approaches the limit $l$ near $a$ means: for every $\epsilon>0$ there is some $\delta>0$ such that, for all $x$, if $0<|x-a|<\delta$, then $|f(x)-l|<\epsilon$. It is clear, then, that in order to verify whether a function is continuous at a point $a$, we need to compute $f(a)$, and this is only possible if $a$ is in the domain of $f$. So, what happens when a point $a$ is not in the domain of $f$? On this matter, I've had some people telling me that statements about continuity only make for points in the domain of $f$. Spivak himself also mentions in the Continuity chapter of his textbook that ""We also often simply say that a function is continuous if it is continuous at $x$ for all $x$ in its domain."" But that means functions like $f(x) = \frac{1}{x}$, $f(x) = \frac{1}{x^2-1}$ and $f(x) = \sin{\frac{1}{x}}$ can all be said to be continuous. It just doesn't seem right, in fact I always thought these were textbook examples of discontinuous functions. It also means that we can't say that $f(x) = \frac{1}{x}$ is discontinuous at $0$, because we don't even know the value of $f(0)$ in order to decide whether it's continuous or not. Are all of these conclusions correct, or did I misinterpret the definitions? I'd love if someone could shed some light on this, I'm having a hard time wrapping my head around it.",,"['calculus', 'real-analysis', 'definition']"
29,Why is the negative of the gradient the direction of greatest descent? [duplicate],Why is the negative of the gradient the direction of greatest descent? [duplicate],,This question already has answers here : Why is gradient in the direction of ascent but not descent? (6 answers) Closed 10 months ago . I imagine it as if one is going up a physical hill. It doesn't seem like there's a guarantee that going in the opposite direction of greatest increase in height will necessarily be the direction of greatest decrease in height.,This question already has answers here : Why is gradient in the direction of ascent but not descent? (6 answers) Closed 10 months ago . I imagine it as if one is going up a physical hill. It doesn't seem like there's a guarantee that going in the opposite direction of greatest increase in height will necessarily be the direction of greatest decrease in height.,,"['calculus', 'multivariable-calculus']"
30,Modeling path of a rolling ellipse,Modeling path of a rolling ellipse,,"I'm trying to solve Project Euler problem 525 . My approach is to find a parametric equation that can model the path of the center point as it rolls, then take the arc length of that function for one rotation. A rotated ellipse can be expressed with the equation: $$\frac{(x\cos\theta-y\sin\theta)^2}{a^2}+\frac{(x\sin\theta+y\cos\theta)^2}{b^2}=1$$ And in order to make this ellipse lie tangent or ""rest"" on the x axis when rotated $\theta$ degrees, there is a y shift of: $\sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. Here is a visual representation of this. Therefore the y component of my final equation will be: $y(\theta) = \sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. The x component of the equation is harder. After $\theta$ degrees of rotation, the point of the ellipse touching the x axis will have traveled a distance equal to the arc length of the ellipse from 0 to $\theta$. This can be expressed with the arc length formula using the parametric form of an ellipse: $$L(\theta) = \int_{0}^{\theta} \sqrt{y'(\theta)^2 + x'(\theta)^2} d\theta$$ This almost solves it, but there is an additional horizontal distance between the tangent point and the center point as seen in the picture below. How do I express this extra x-distance? I think it might not even require any calculus. (Note, I don't want a solution to the problem, that takes the fun out of the problem. Just some help to get through this step or a point in the right direction.)","I'm trying to solve Project Euler problem 525 . My approach is to find a parametric equation that can model the path of the center point as it rolls, then take the arc length of that function for one rotation. A rotated ellipse can be expressed with the equation: $$\frac{(x\cos\theta-y\sin\theta)^2}{a^2}+\frac{(x\sin\theta+y\cos\theta)^2}{b^2}=1$$ And in order to make this ellipse lie tangent or ""rest"" on the x axis when rotated $\theta$ degrees, there is a y shift of: $\sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. Here is a visual representation of this. Therefore the y component of my final equation will be: $y(\theta) = \sqrt{a^2\sin^2\theta+b^2\cos^2\theta}$. The x component of the equation is harder. After $\theta$ degrees of rotation, the point of the ellipse touching the x axis will have traveled a distance equal to the arc length of the ellipse from 0 to $\theta$. This can be expressed with the arc length formula using the parametric form of an ellipse: $$L(\theta) = \int_{0}^{\theta} \sqrt{y'(\theta)^2 + x'(\theta)^2} d\theta$$ This almost solves it, but there is an additional horizontal distance between the tangent point and the center point as seen in the picture below. How do I express this extra x-distance? I think it might not even require any calculus. (Note, I don't want a solution to the problem, that takes the fun out of the problem. Just some help to get through this step or a point in the right direction.)",,"['calculus', 'recreational-mathematics', 'simulation', 'project-euler']"
31,"Torsion and curvature of the curve $X(t) = (at, bt^2, ct^3)$",Torsion and curvature of the curve,"X(t) = (at, bt^2, ct^3)","Hey all I am looking for help on a problem. I will post it, and than I will add what I have tried and my ideas etc.  The question has been up now for a few days, I'm sure someone out there can help! I even put a bounty, I have spent a lot of time on this question! I am interested in calculating the torsion ($\tau$) and curvature ($\kappa$) of the curve $$X(t)=(at,bt^2,ct^3), \quad t   \ge   0 $$ and $a$, $b$, and $c$ are all positive constants. So here is what I am having problems with. It seems like there are so many different formulas for curvature, and there are also the Frenet–Serret formulas so I am having issues deciding how to do it. I was thinking maybe I could reparametrize with respect to arc length, which would give me it in terms of unit length so I could use some of Frenet–Serret formulas, but I am not confident in that. What I did so far was I calculated $X'(t)=(a,2bt,3ct^2)$ and $|X'(t)|=\sqrt{a^2+4b^2 t^2 +9c^2 t^4}$. Then I  calculated $$X''(t)=(0, 2b, 6ct)$$ and $$|X''(t)|=2\sqrt{b^{2}+9c^{2}t^{2}}.$$ I also know that the unit tangent, $$T(t)={X'(t)\over|X'(t)|}$$ and the unit normal is $$N(t)={T'(t) \over |T'(t)|}$$ and that the binormal is $B= T \times N$. But I am really not sure how to take it further. I know that in arc length parametrzation we would have $dT/ds= \kappa N$ and $dN/ds=-\kappa T + \tau B$ and $dB/ds= -\tau N$. Should I keep it in the form it is and use the equation $$\kappa={|X'(t) \times X''(t)|\over |X'(t)|^3}?$$ A few of the other things I am thinking of is that maybe I could solve for torsion by the following: I know that $T$, $B$ and $N$ form an orthonormal basis of $\mathbb R^{3}$ so can and when we write $N'=\alpha T + \tau B$ , is the coefficient, $\tau$  the definition of torsion? Moreover, noting $B= T \times N$, we have $$B'= T'\times N + T \times N' = T \times N' =T \times (\alpha T+\tau B) = \tau T \times B= -\tau N $$  (because $N=B \times T$ so $T \times B=-N)$. I think this is how I understand the derivation for that equation. Is it only in arc length parametrization that I can use the Frenet equations for example? However, I think I should be able to do it just using the regular formulas, and not an arc length parametrization as the integral would be tough. I did conform this as well, so in terms of the basics of this question I'd like to do it without arc length parametrization. I am also interested in seeing a intuitive derivation of the torsion formula (the one with the triple product). I apologize if I didn't show enough work, this is all I could do but I am very happy to learn it. Thanks a lot to any help! UPDATE: I am wondering about the validity of what I now have. In addition to above I computed $X'''(t)=(0,0,6c)$ $X' \times X''= (6bct^2,-6act,2ab)$ $(X' \times X'') \cdot X''' = (12abc)$ $|X' \times X''| = 2 \sqrt {9b^2c^2t^4+9a^2c^2t^2+a^2b^2}$. Now can I just apply the formulas $$\tau = \frac{ (X' \times X'') \cdot X'''}{|X' \times X''|^2}.$$","Hey all I am looking for help on a problem. I will post it, and than I will add what I have tried and my ideas etc.  The question has been up now for a few days, I'm sure someone out there can help! I even put a bounty, I have spent a lot of time on this question! I am interested in calculating the torsion ($\tau$) and curvature ($\kappa$) of the curve $$X(t)=(at,bt^2,ct^3), \quad t   \ge   0 $$ and $a$, $b$, and $c$ are all positive constants. So here is what I am having problems with. It seems like there are so many different formulas for curvature, and there are also the Frenet–Serret formulas so I am having issues deciding how to do it. I was thinking maybe I could reparametrize with respect to arc length, which would give me it in terms of unit length so I could use some of Frenet–Serret formulas, but I am not confident in that. What I did so far was I calculated $X'(t)=(a,2bt,3ct^2)$ and $|X'(t)|=\sqrt{a^2+4b^2 t^2 +9c^2 t^4}$. Then I  calculated $$X''(t)=(0, 2b, 6ct)$$ and $$|X''(t)|=2\sqrt{b^{2}+9c^{2}t^{2}}.$$ I also know that the unit tangent, $$T(t)={X'(t)\over|X'(t)|}$$ and the unit normal is $$N(t)={T'(t) \over |T'(t)|}$$ and that the binormal is $B= T \times N$. But I am really not sure how to take it further. I know that in arc length parametrzation we would have $dT/ds= \kappa N$ and $dN/ds=-\kappa T + \tau B$ and $dB/ds= -\tau N$. Should I keep it in the form it is and use the equation $$\kappa={|X'(t) \times X''(t)|\over |X'(t)|^3}?$$ A few of the other things I am thinking of is that maybe I could solve for torsion by the following: I know that $T$, $B$ and $N$ form an orthonormal basis of $\mathbb R^{3}$ so can and when we write $N'=\alpha T + \tau B$ , is the coefficient, $\tau$  the definition of torsion? Moreover, noting $B= T \times N$, we have $$B'= T'\times N + T \times N' = T \times N' =T \times (\alpha T+\tau B) = \tau T \times B= -\tau N $$  (because $N=B \times T$ so $T \times B=-N)$. I think this is how I understand the derivation for that equation. Is it only in arc length parametrization that I can use the Frenet equations for example? However, I think I should be able to do it just using the regular formulas, and not an arc length parametrization as the integral would be tough. I did conform this as well, so in terms of the basics of this question I'd like to do it without arc length parametrization. I am also interested in seeing a intuitive derivation of the torsion formula (the one with the triple product). I apologize if I didn't show enough work, this is all I could do but I am very happy to learn it. Thanks a lot to any help! UPDATE: I am wondering about the validity of what I now have. In addition to above I computed $X'''(t)=(0,0,6c)$ $X' \times X''= (6bct^2,-6act,2ab)$ $(X' \times X'') \cdot X''' = (12abc)$ $|X' \times X''| = 2 \sqrt {9b^2c^2t^4+9a^2c^2t^2+a^2b^2}$. Now can I just apply the formulas $$\tau = \frac{ (X' \times X'') \cdot X'''}{|X' \times X''|^2}.$$",,"['calculus', 'parametric', 'curves']"
32,Differential equation: $y'-\tan x \cdot y=e^{2x}$,Differential equation:,y'-\tan x \cdot y=e^{2x},I am having difficulty solving the differential equation $y'-\tan x \cdot y=e^{2x}$. Here is my attempt Any help is appreciated.,I am having difficulty solving the differential equation $y'-\tan x \cdot y=e^{2x}$. Here is my attempt Any help is appreciated.,,"['calculus', 'ordinary-differential-equations']"
33,Help to resolve a Double Integral,Help to resolve a Double Integral,,"I'm doing a workout guide about double integrals and I came across an exercise that I could not resolve for a while. $$\int_0^2\int_1^2 \frac{x}{\sqrt{1+x^2+y^2}} \,\mathrm dx\,\mathrm dy$$ I guess that the easier order of integration is $dxdy$, because if I try to integrate respect to $y$ first, I would have to deal with the integral of a root of $1+x^2+y^2$, while outside of the root there's no $y$. I tried Integration by substitution (with $u = 1 + x^2 + y^2$ and $du = 2xdx$) to solve the inner integral, but then I felt I couldn't solve the outside integral. Any hints you can give me?.","I'm doing a workout guide about double integrals and I came across an exercise that I could not resolve for a while. $$\int_0^2\int_1^2 \frac{x}{\sqrt{1+x^2+y^2}} \,\mathrm dx\,\mathrm dy$$ I guess that the easier order of integration is $dxdy$, because if I try to integrate respect to $y$ first, I would have to deal with the integral of a root of $1+x^2+y^2$, while outside of the root there's no $y$. I tried Integration by substitution (with $u = 1 + x^2 + y^2$ and $du = 2xdx$) to solve the inner integral, but then I felt I couldn't solve the outside integral. Any hints you can give me?.",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
34,How to solve $ \int_0^{\pi} \sin{2x}\sin{x} dx $?,How to solve ?, \int_0^{\pi} \sin{2x}\sin{x} dx ,"How to solve $$\int_0^{\pi} \sin{2x}\sin{x} dx$$ Edit: Sorry! I should have described more. This is not a homework. Recently, Out of the blue I got interest in physics and started reading and solving problems. This is part of a physics problem where I got stuck (because I forgot all high school formulae.). Thanks all of you guys for wonderful solutions.","How to solve $$\int_0^{\pi} \sin{2x}\sin{x} dx$$ Edit: Sorry! I should have described more. This is not a homework. Recently, Out of the blue I got interest in physics and started reading and solving problems. This is part of a physics problem where I got stuck (because I forgot all high school formulae.). Thanks all of you guys for wonderful solutions.",,"['calculus', 'integration', 'trigonometry']"
35,Derivative of $f(x)=e^7+\ln(4)$.,Derivative of .,f(x)=e^7+\ln(4),"I need to differentiate $$f(x)=e^7+\ln(4).$$ I know that $\dfrac d{dx}e^x = e^x$ and $\dfrac d{dx}\ln(x) = \dfrac {1}{x}$. I recently learned this, but I get stuck when it comes to solving this problem using real numbers. Can someone guide me with an example?","I need to differentiate $$f(x)=e^7+\ln(4).$$ I know that $\dfrac d{dx}e^x = e^x$ and $\dfrac d{dx}\ln(x) = \dfrac {1}{x}$. I recently learned this, but I get stuck when it comes to solving this problem using real numbers. Can someone guide me with an example?",,"['calculus', 'derivatives']"
36,Find the tenth derivative of $x^2e^x$,Find the tenth derivative of,x^2e^x,"If $$f(x) = x^2e^x$$ find $$f^{({10})}x$$ I'm not familiar with doing the series expansion for this and the solution that was provided to me did not help me at all, as it wasn't explained. I think it's ""Higher Leibnitz Rule"", but I'm unsure. I could differentiate the function 10 times, but the solutions uses summation. How would I go about doing this?","If $$f(x) = x^2e^x$$ find $$f^{({10})}x$$ I'm not familiar with doing the series expansion for this and the solution that was provided to me did not help me at all, as it wasn't explained. I think it's ""Higher Leibnitz Rule"", but I'm unsure. I could differentiate the function 10 times, but the solutions uses summation. How would I go about doing this?",,"['calculus', 'derivatives']"
37,How can I solve $\cos^2 x + \sin x +1 = 0$?,How can I solve ?,\cos^2 x + \sin x +1 = 0,"The solution set of the equation $$\cos^2 x + \sin x +1 = 0$$ is? I haven't studied trigonometry, I'm kinda lost on this issue ...","The solution set of the equation $$\cos^2 x + \sin x +1 = 0$$ is? I haven't studied trigonometry, I'm kinda lost on this issue ...",,"['calculus', 'algebra-precalculus', 'trigonometry']"
38,Show that $\int_0^\infty e^{-x}\cos x \text{dx}=\int_0^\infty e^{-x} \sin x \text{dx}$,Show that,\int_0^\infty e^{-x}\cos x \text{dx}=\int_0^\infty e^{-x} \sin x \text{dx},"Show that $\int_0^\infty e^{-x}\cos x \ \text{d}x=\int_0^\infty e^{-x} \sin x \ \text{d}x$ using integration by parts. For the LHS, I got: $-e^{-x} \cos x-\int e^{-x} \sin x \ \text{d}x$ I'm not sure how to show that the RHS integral is equal to this...","Show that $\int_0^\infty e^{-x}\cos x \ \text{d}x=\int_0^\infty e^{-x} \sin x \ \text{d}x$ using integration by parts. For the LHS, I got: $-e^{-x} \cos x-\int e^{-x} \sin x \ \text{d}x$ I'm not sure how to show that the RHS integral is equal to this...",,"['calculus', 'integration']"
39,How to prove that $2\sqrt{3}$ is greater than $\pi$,How to prove that  is greater than,2\sqrt{3} \pi,"Without calculator, how to prove that $2 \sqrt{3} > \pi$ ? The level is baccalauréat grade. I confirm it's not a school exercise at all, as I left school like 35 years ago.","Without calculator, how to prove that ? The level is baccalauréat grade. I confirm it's not a school exercise at all, as I left school like 35 years ago.",2 \sqrt{3} > \pi,['calculus']
40,How can I integrate $\int\frac{e^{2x}-1}{\sqrt{e^{3x}+e^x} } \mathop{dx}$?,How can I integrate ?,\int\frac{e^{2x}-1}{\sqrt{e^{3x}+e^x} } \mathop{dx},"How can I evaluate this integral $$\int\dfrac{e^{2x}-1}{\sqrt{e^{3x}+e^x} } \mathop{dx}=\;\;?$$ My attempt : I tried using substitution $e^x=\tan\theta$ , $e^x\ dx=\sec^2\theta\ d\theta$ , $dx=\sec\theta \csc\theta \ d\theta.$ $$\int\dfrac{\tan^2\theta-1}{\sqrt{\tan^3\theta+\tan\theta } }\ \sec\theta \csc\theta\ d\theta $$ $$=\int\dfrac{\tan^2\theta-1}{\sec\theta\sqrt{\tan\theta } }\ \sec\theta \csc\theta d\theta. $$ I used $\tan\theta= \dfrac{1}{\cot\theta}$ $$=\int\dfrac{1-\cot^2\theta}{\cot^{3/2}\theta }\csc\theta d\theta $$ $$=\int(\cot^{-3/2}\theta-\sqrt{\cot\theta} )\csc\theta d\theta. $$ I got stuck here. I can't see whether further substitution will work or not. Will integration by parts work? Please help me solve this integral. I am learning calculus. Thank in advance.","How can I evaluate this integral My attempt : I tried using substitution , , I used I got stuck here. I can't see whether further substitution will work or not. Will integration by parts work? Please help me solve this integral. I am learning calculus. Thank in advance.",\int\dfrac{e^{2x}-1}{\sqrt{e^{3x}+e^x} } \mathop{dx}=\;\;? e^x=\tan\theta e^x\ dx=\sec^2\theta\ d\theta dx=\sec\theta \csc\theta \ d\theta. \int\dfrac{\tan^2\theta-1}{\sqrt{\tan^3\theta+\tan\theta } }\ \sec\theta \csc\theta\ d\theta  =\int\dfrac{\tan^2\theta-1}{\sec\theta\sqrt{\tan\theta } }\ \sec\theta \csc\theta d\theta.  \tan\theta= \dfrac{1}{\cot\theta} =\int\dfrac{1-\cot^2\theta}{\cot^{3/2}\theta }\csc\theta d\theta  =\int(\cot^{-3/2}\theta-\sqrt{\cot\theta} )\csc\theta d\theta. ,['calculus']
41,"L'Hospital rule, exponental ratio","L'Hospital rule, exponental ratio",,"$$\lim_{x\to ∞} \frac {x^{1000000}} {e^x}$$ could anyone please provide some hits with what result I will end up? After all applyings of L'Hospital rule, I will get $\frac {n} {e^x}$, where $n$ is large number before I got out of the $x$ powers. So, will it be the limit $0$ then? Since the infinity is nothing I have $\frac {n} {0}.$ Or will it be just the $\infty$?","$$\lim_{x\to ∞} \frac {x^{1000000}} {e^x}$$ could anyone please provide some hits with what result I will end up? After all applyings of L'Hospital rule, I will get $\frac {n} {e^x}$, where $n$ is large number before I got out of the $x$ powers. So, will it be the limit $0$ then? Since the infinity is nothing I have $\frac {n} {0}.$ Or will it be just the $\infty$?",,"['calculus', 'limits']"
42,Derivative of a product and derivative of quotient of functions theorem: I don't understand its proof,Derivative of a product and derivative of quotient of functions theorem: I don't understand its proof,,"I'm studying for math exam and one of the questions that often appears is related to derivative of a product of two functions. The theorem says that $(f(x)g(x))'=f'(x)g(x)+f(x)g'(x)$. The proof goes like this: $f(x+h)g(x+h)-f(x)g(x)=(f(x+h)-f(x))g(x)+(g(x+h)-g(x))f(x)$ After that we divide the equation by h and let h approach 0. Now what I don't understand is how they got the right side of the proof. Same problem with quotient: Theorem says: $\left(\frac{f(x)} {g(x)}\right)'=\frac{f'(x)g(x)-f(x)g'(x)} {g^2(x)}$ The above comes from $\frac {f(x+h)} {g(x+h)} - \frac {f(x)} {g(x)} = \frac{(f(x+h)-f(x))g(x)-(g(x+6h)-g(x))f(x)} {g(x+h)g(x)}$ I can see from where $f(x+h)g(x)$ comes, but I can't see from where $f(x)g(x)$ came.","I'm studying for math exam and one of the questions that often appears is related to derivative of a product of two functions. The theorem says that $(f(x)g(x))'=f'(x)g(x)+f(x)g'(x)$. The proof goes like this: $f(x+h)g(x+h)-f(x)g(x)=(f(x+h)-f(x))g(x)+(g(x+h)-g(x))f(x)$ After that we divide the equation by h and let h approach 0. Now what I don't understand is how they got the right side of the proof. Same problem with quotient: Theorem says: $\left(\frac{f(x)} {g(x)}\right)'=\frac{f'(x)g(x)-f(x)g'(x)} {g^2(x)}$ The above comes from $\frac {f(x+h)} {g(x+h)} - \frac {f(x)} {g(x)} = \frac{(f(x+h)-f(x))g(x)-(g(x+6h)-g(x))f(x)} {g(x+h)g(x)}$ I can see from where $f(x+h)g(x)$ comes, but I can't see from where $f(x)g(x)$ came.",,['calculus']
43,Bolzano–Weierstrass theorem conclusion,Bolzano–Weierstrass theorem conclusion,,"Can I conclude from Bolzano–Weierstrass theorem that there is more than one convergent subsequence, or the theorem tells me that there's only one ? To be more clear, given a bounded sequence $X_n$, not ecessarily converges, can I conclude there are two different subsequences $X_{n_k}$ that converges to $L_1$ and $X_{n_l}$ that converges to $L_2$?","Can I conclude from Bolzano–Weierstrass theorem that there is more than one convergent subsequence, or the theorem tells me that there's only one ? To be more clear, given a bounded sequence $X_n$, not ecessarily converges, can I conclude there are two different subsequences $X_{n_k}$ that converges to $L_1$ and $X_{n_l}$ that converges to $L_2$?",,['calculus']
44,What is the use of the chain rule?,What is the use of the chain rule?,,"While studying calculus at home, I reached derivatives, and a book mentioned the chain rule. The book didn't go into much detail, and the internet searches gave me little information, so I was hoping that someone could enlighten me on this fundamental principle of calculus.","While studying calculus at home, I reached derivatives, and a book mentioned the chain rule. The book didn't go into much detail, and the internet searches gave me little information, so I was hoping that someone could enlighten me on this fundamental principle of calculus.",,['calculus']
45,Calculating $\ln(1+\sqrt3)$,Calculating,\ln(1+\sqrt3),"I distributed the natural logarithm and got $(0 + 0.549)$ [placing the values in a calculator]. However, the answer key states that the answer is $1.0051$. Where did I go wrong?","I distributed the natural logarithm and got $(0 + 0.549)$ [placing the values in a calculator]. However, the answer key states that the answer is $1.0051$. Where did I go wrong?",,"['calculus', 'algebra-precalculus', 'logarithms']"
46,"Does the recursive sequence $a_1 = 1, a_n = a_{n-1}+\frac{1}{a_{n-1}}$ converge?",Does the recursive sequence  converge?,"a_1 = 1, a_n = a_{n-1}+\frac{1}{a_{n-1}}","Does the recursive sequence $a_1 = 1, a_n = a_{n-1}+\frac{1}{a_{n-1}}$ converge? Since the function $x+1/x$ is strictly monotonic increasing for all $x>1$, I don't think that the limit converges, but I'm not sure. Can anybody tell me whether the sequence is converging or not?","Does the recursive sequence $a_1 = 1, a_n = a_{n-1}+\frac{1}{a_{n-1}}$ converge? Since the function $x+1/x$ is strictly monotonic increasing for all $x>1$, I don't think that the limit converges, but I'm not sure. Can anybody tell me whether the sequence is converging or not?",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
47,Why does $\frac{d}{dx}\sin(x) = \cos (x)$?,Why does ?,\frac{d}{dx}\sin(x) = \cos (x),Why? Can someone give me a link or explain below. Thanks,Why? Can someone give me a link or explain below. Thanks,,"['calculus', 'trigonometry']"
48,"Maximizing the sum of two numbers, the sum of whose squares is constant","Maximizing the sum of two numbers, the sum of whose squares is constant",,"How could we prove that if the sum of the squares of two numbers is a constant, then the sum of the numbers would have its maximum value  when the numbers are equal? This result is also true for more than two numbers. I tested the results by taking various values and brute-force-ish approach. However I am interested to know a formal proof of the same. This is probably an mild extention to this problem . I encountered this result while searching for a easy solution for the same.","How could we prove that if the sum of the squares of two numbers is a constant, then the sum of the numbers would have its maximum value  when the numbers are equal? This result is also true for more than two numbers. I tested the results by taking various values and brute-force-ish approach. However I am interested to know a formal proof of the same. This is probably an mild extention to this problem . I encountered this result while searching for a easy solution for the same.",,"['calculus', 'algebra-precalculus', 'inequality', 'optimization']"
49,Find the limit of $(1-\cos x)/(x\sin x)$ as $x \to 0$,Find the limit of  as,(1-\cos x)/(x\sin x) x \to 0,"Can you please help me solve: $$\lim_{x \rightarrow 0} \frac{1- \cos x}{x \sin x}$$ Every time I try to calculate it I find another solution and before I get used to bad habits, I'd like to see how it can be solved right, so I'll know how to approach trigonometric limits. I tried to convert $\cos x$ to $\sin x$ by $\pi -x$, but I think it's wrong. Should I use another identity?","Can you please help me solve: $$\lim_{x \rightarrow 0} \frac{1- \cos x}{x \sin x}$$ Every time I try to calculate it I find another solution and before I get used to bad habits, I'd like to see how it can be solved right, so I'll know how to approach trigonometric limits. I tried to convert $\cos x$ to $\sin x$ by $\pi -x$, but I think it's wrong. Should I use another identity?",,"['calculus', 'limits', 'trigonometry']"
50,Distance traveled by a bouncing ball with exponentially diminishing rebounds,Distance traveled by a bouncing ball with exponentially diminishing rebounds,,"This is kind of an odd question, but can somebody please tell me that I am crazy with the following question, I did the math, and what I am told to prove is simply wrong: Question: Show that a ball dropped from height of h feet and bounces in such a way that each bounce is $\frac34$ of the height of the bounce before travels a total distance of 7 h feet. My Work: $$\sum_{n=0}^{\infty} h \left(\frac34\right)^n = 4h$$ Obviously 4 h does not equal 7 h .  What does the community get? I know that my calculations are correct, see Wolfram Alpha and it confirms my calculations, that only leaves my formula, or the teacher being incorrect... Edit: Thanks everyone for pointing out my flaw, it should be something like: $$\sum_{n=0}^{\infty} -h + 2h \left(\frac34\right)^n = 7h$$ Thanks in advance for any help!","This is kind of an odd question, but can somebody please tell me that I am crazy with the following question, I did the math, and what I am told to prove is simply wrong: Question: Show that a ball dropped from height of h feet and bounces in such a way that each bounce is $\frac34$ of the height of the bounce before travels a total distance of 7 h feet. My Work: $$\sum_{n=0}^{\infty} h \left(\frac34\right)^n = 4h$$ Obviously 4 h does not equal 7 h .  What does the community get? I know that my calculations are correct, see Wolfram Alpha and it confirms my calculations, that only leaves my formula, or the teacher being incorrect... Edit: Thanks everyone for pointing out my flaw, it should be something like: $$\sum_{n=0}^{\infty} -h + 2h \left(\frac34\right)^n = 7h$$ Thanks in advance for any help!",,"['calculus', 'sequences-and-series']"
51,Integrate $\ln (x)$ without integration by parts,Integrate  without integration by parts,\ln (x),I know with integration by parts the answer is $x\ln(x) - x$ but I was wondering how to do this without integration by parts.,I know with integration by parts the answer is but I was wondering how to do this without integration by parts.,x\ln(x) - x,"['calculus', 'integration', 'indefinite-integrals']"
52,Derivative of a large product,Derivative of a large product,,"I need help computing $$ \frac{d}{dx}\prod_{n=1}^{2014}\left(x+\frac{1}{n}\right)\biggr\rvert_{x=0} $$ The answer provided is $\frac{2015}{2\cdot 2013!}$ , however, I do not know how to arrive at this answer. Does anyone have any suggestions?","I need help computing $$ \frac{d}{dx}\prod_{n=1}^{2014}\left(x+\frac{1}{n}\right)\biggr\rvert_{x=0} $$ The answer provided is $\frac{2015}{2\cdot 2013!}$ , however, I do not know how to arrive at this answer. Does anyone have any suggestions?",,"['calculus', 'sequences-and-series']"
53,Square root of both sides [closed],Square root of both sides [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question If you have the equation: $x^2=2$ You get: $x=\pm \sqrt{2}$ But what do you do actually do? What do you multiply both sides with to get this answer? You take the square root of both sides, but the square root of what? If you understand what i mean?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question If you have the equation: $x^2=2$ You get: $x=\pm \sqrt{2}$ But what do you do actually do? What do you multiply both sides with to get this answer? You take the square root of both sides, but the square root of what? If you understand what i mean?",,['calculus']
54,Prove/disprove: if $\lim\limits_{ n\to\infty} f(n)=\infty$ then $\lim\limits_{ n\to\infty}f(f(n))=\infty$,Prove/disprove: if  then,\lim\limits_{ n\to\infty} f(n)=\infty \lim\limits_{ n\to\infty}f(f(n))=\infty,"Let $f(x)$ a continuous function on $\Bbb{R}$. Prove/disprove: If $\lim\limits_{n\to\infty} f(n)=\infty$, then $\lim\limits_{n\to\infty}f(f(n))=\infty,$ where the limits are taken over $n \in \mathbb N$. I have an hunch this statement isn't always true, but couldn't find a proper function to show this.","Let $f(x)$ a continuous function on $\Bbb{R}$. Prove/disprove: If $\lim\limits_{n\to\infty} f(n)=\infty$, then $\lim\limits_{n\to\infty}f(f(n))=\infty,$ where the limits are taken over $n \in \mathbb N$. I have an hunch this statement isn't always true, but couldn't find a proper function to show this.",,"['calculus', 'limits', 'functions', 'continuity']"
55,Lack of rigour in Spivak's Calculus book?,Lack of rigour in Spivak's Calculus book?,,"I logged on today with this exact question: Ellipse definition I found it disconcerting for him to say that it was clear that $a > c$ when $a$ could be equal to $c$ (a straight line) or maybe even less than $c$ (if complex numbers are allowed). So he is assuming that we don't want a straight line, and also that complex numbers aren't allowed. Neither of those assumptions were stated or explained. I don't even know whether complex numbers would work, whether any sum at all could be arrived at. It's also not stated that the formula wouldn't work for a straight line; it's just glossed over by saying it 'clearly' couldn't be a straight line. I picked up Spivak's book because I had heard it was extremely rigourous, but now I'm wondering a) whether the unstated assumption and lack of addressing conceivable possibilities is common in his book, and b) whether there were any other book recommendations to learn calculus with the requirement of rigour in mind. I'm a bit hesitant to continue, as I may be unable to tell whether something 'clear' to him is not clear to me due to me not understanding it properly, or due to not being aware of his assumptions. As I'm trying to learn this on my own, that's not a favourable position for me to be in.","I logged on today with this exact question: Ellipse definition I found it disconcerting for him to say that it was clear that $a > c$ when $a$ could be equal to $c$ (a straight line) or maybe even less than $c$ (if complex numbers are allowed). So he is assuming that we don't want a straight line, and also that complex numbers aren't allowed. Neither of those assumptions were stated or explained. I don't even know whether complex numbers would work, whether any sum at all could be arrived at. It's also not stated that the formula wouldn't work for a straight line; it's just glossed over by saying it 'clearly' couldn't be a straight line. I picked up Spivak's book because I had heard it was extremely rigourous, but now I'm wondering a) whether the unstated assumption and lack of addressing conceivable possibilities is common in his book, and b) whether there were any other book recommendations to learn calculus with the requirement of rigour in mind. I'm a bit hesitant to continue, as I may be unable to tell whether something 'clear' to him is not clear to me due to me not understanding it properly, or due to not being aware of his assumptions. As I'm trying to learn this on my own, that's not a favourable position for me to be in.",,"['calculus', 'reference-request', 'book-recommendation']"
56,Why is $\log(1+e^x) - \frac{x}{2}$ even?,Why is  even?,\log(1+e^x) - \frac{x}{2},"I'm dealing with Fourier series and I'm trying to figure out $\log(1+e^x) - \frac{x}{2}$ is even??? I've tried the $f(-x) = f(x)$ method but it doesn't give me the equality. But I've plotted it, and it is even? :S","I'm dealing with Fourier series and I'm trying to figure out $\log(1+e^x) - \frac{x}{2}$ is even??? I've tried the $f(-x) = f(x)$ method but it doesn't give me the equality. But I've plotted it, and it is even? :S",,"['calculus', 'functions']"
57,Is there anyway to show $\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1$ other than taking derivatives?,Is there anyway to show  other than taking derivatives?,\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1,"The purpose is to show $\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1$ for any $x,y\in\Bbb{R}$. Taking partial derivatives with respect to $x,y$ respectively $\frac{{\partial \frac{{\cos x - \cos y}}{{x - y}}}}{{\partial x}} = 0$, $\frac{{\partial \frac{{\cos x - \cos y}}{{x - y}}}}{{\partial y}} = 0$ gives $\sin x={ - \frac{{\cos x - \cos y}}{{x - y}}}$ and  $\sin y={ - \frac{{\cos x - \cos y}}{{x - y}}}$. Plugging them back and we have the desired result $\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1$. What I want to ask is, is there more decent way to show the inequity? Taking derivatives looks clumsy. Hope someone can help. Thank you!","The purpose is to show $\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1$ for any $x,y\in\Bbb{R}$. Taking partial derivatives with respect to $x,y$ respectively $\frac{{\partial \frac{{\cos x - \cos y}}{{x - y}}}}{{\partial x}} = 0$, $\frac{{\partial \frac{{\cos x - \cos y}}{{x - y}}}}{{\partial y}} = 0$ gives $\sin x={ - \frac{{\cos x - \cos y}}{{x - y}}}$ and  $\sin y={ - \frac{{\cos x - \cos y}}{{x - y}}}$. Plugging them back and we have the desired result $\left| {\frac{{\cos x - \cos y}}{{x - y}}} \right| \le 1$. What I want to ask is, is there more decent way to show the inequity? Taking derivatives looks clumsy. Hope someone can help. Thank you!",,"['calculus', 'real-analysis', 'trigonometry']"
58,Suppose $a_n+b_n$ converges. Does $a_n*b_n$ converges also?,Suppose  converges. Does  converges also?,a_n+b_n a_n*b_n,"$a_n, b_n$ - sequences Suppose $a_n+b_n$ converges. Does $a_n b_n$ converge also? I tried thinking if I can learn something about $a_n$ and $b_n$ by the assumption $a_n b_n$ converges. I also tried to develop this equation $|a_n b_n - L| < \epsilon$ assuming it is converging. I didn't get any bright conclusions. Will be glad help.","$a_n, b_n$ - sequences Suppose $a_n+b_n$ converges. Does $a_n b_n$ converge also? I tried thinking if I can learn something about $a_n$ and $b_n$ by the assumption $a_n b_n$ converges. I also tried to develop this equation $|a_n b_n - L| < \epsilon$ assuming it is converging. I didn't get any bright conclusions. Will be glad help.",,"['calculus', 'limits']"
59,Limit of $\frac{(x^x)}{(x!)}$ as $x$ approaches infinity,Limit of  as  approaches infinity,\frac{(x^x)}{(x!)} x,"So, I'm learning limits right now in calculus class. When $x$ approaches infinity, what does this expression approach? $$\frac{(x^x)}{(x!)}$$ Why?  Since, the bottom is $x!$, doesn't it mean that the bottom goes to zero faster, therefore the whole thing approaches 0?","So, I'm learning limits right now in calculus class. When $x$ approaches infinity, what does this expression approach? $$\frac{(x^x)}{(x!)}$$ Why?  Since, the bottom is $x!$, doesn't it mean that the bottom goes to zero faster, therefore the whole thing approaches 0?",,"['calculus', 'limits']"
60,Which principle is violated here in the logarithmic equation?,Which principle is violated here in the logarithmic equation?,,"I'm a beginner to mathematics and I'm stuck with a calculus exercise. It seems like I violate a principle, but I cannot yet see what I did wrong here. I hope a second look from a 3rd person will help. The equation I need to solve is: \begin{equation} 16^{x}+4^{(x+1)}=12 \end{equation} With as $x=\frac{1}{2}$ as only real solution. I understand that this can be solved with substitution, but I especially want to solve this problem with writing everything in the same base. Attempt: \begin{aligned} &16^{x}+4^{(x+1)}=12 \\ &\left(4^{2}\right)^{x}+4^{(x+1)}=12 \\ &4^{2 \cdot x}+4^{(x+1)}=12 \\ &4^{2 \cdot x}+4^{(x+1)}=4^{\left(\frac{\log (12)}{\log (4)}\right)} \\ &2 \cdot x+x+1=\frac{\log (12)}{\log (4)} \\ &3 \cdot x=\frac{\log (12)}{\log (4)}-1 \\ &x=\frac{1}{3}\left(\frac{\log (12)}{\log (4)}-1\right) \end{aligned} Could I please get feedback?","I'm a beginner to mathematics and I'm stuck with a calculus exercise. It seems like I violate a principle, but I cannot yet see what I did wrong here. I hope a second look from a 3rd person will help. The equation I need to solve is: With as as only real solution. I understand that this can be solved with substitution, but I especially want to solve this problem with writing everything in the same base. Attempt: Could I please get feedback?","\begin{equation}
16^{x}+4^{(x+1)}=12
\end{equation} x=\frac{1}{2} \begin{aligned}
&16^{x}+4^{(x+1)}=12 \\
&\left(4^{2}\right)^{x}+4^{(x+1)}=12 \\
&4^{2 \cdot x}+4^{(x+1)}=12 \\
&4^{2 \cdot x}+4^{(x+1)}=4^{\left(\frac{\log (12)}{\log (4)}\right)} \\
&2 \cdot x+x+1=\frac{\log (12)}{\log (4)} \\
&3 \cdot x=\frac{\log (12)}{\log (4)}-1 \\
&x=\frac{1}{3}\left(\frac{\log (12)}{\log (4)}-1\right)
\end{aligned}","['calculus', 'algebra-precalculus']"
61,"Is $\int_{\sin x}^{\cos x}x\, dx$ not a well-defined integral?",Is  not a well-defined integral?,"\int_{\sin x}^{\cos x}x\, dx","Consider the integral $$\int_a^bx\, dx$$ where $a=\sin x$ , and $b=\cos x$ . How can we evaluate this particular integral, if $a$ and $b$ are both functions of $x$ , which is the variable with respect to which we are integrating?","Consider the integral where , and . How can we evaluate this particular integral, if and are both functions of , which is the variable with respect to which we are integrating?","\int_a^bx\, dx a=\sin x b=\cos x a b x","['calculus', 'integration']"
62,"integration by parts $\int \frac{x^{2}+4x}{x+2}\,dx$",integration by parts,"\int \frac{x^{2}+4x}{x+2}\,dx","$$\int \frac{x^{2}+4x}{x+2}\,dx$$ I have written it in this form: $$\int \frac{(x+2)^{2}-4}{x+2}\,dx$$: on this stage I try to do integration by parts, which gets me to : $$\frac{x^{2}}{2}+2x-4\ln\left | {x+2} \right |$$ but it's wrong for some reason. The right answer is : $$\frac{x^{2}+4x+4}{2}-4\ln\left | x+2 \right |$$ Where am I wrong?","$$\int \frac{x^{2}+4x}{x+2}\,dx$$ I have written it in this form: $$\int \frac{(x+2)^{2}-4}{x+2}\,dx$$: on this stage I try to do integration by parts, which gets me to : $$\frac{x^{2}}{2}+2x-4\ln\left | {x+2} \right |$$ but it's wrong for some reason. The right answer is : $$\frac{x^{2}+4x+4}{2}-4\ln\left | x+2 \right |$$ Where am I wrong?",,"['calculus', 'integration', 'definite-integrals']"
63,How can I find $\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right)$ without l'Hopital's Rule?,How can I find  without l'Hopital's Rule?,\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right),"How do I evaluate $$\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right)$$ I know it's the indeterminate form since the numerator and denominator both approach 0, but I can't use l'Hopital's rule so I'm not sure how to go about finding the limit.","How do I evaluate $$\lim_{x \to 0}\left(\frac{e^{2\sin x}-1}{x}\right)$$ I know it's the indeterminate form since the numerator and denominator both approach 0, but I can't use l'Hopital's rule so I'm not sure how to go about finding the limit.",,"['calculus', 'limits', 'limits-without-lhopital']"
64,Evaluate $\lim _{n\to \infty }\int _{0}^{1}nx^ne^{x^2}dx$,Evaluate,\lim _{n\to \infty }\int _{0}^{1}nx^ne^{x^2}dx,"Evaluate $\lim _{n\to \infty }\int _{0}^{1}nx^ne^{x^2}dx.$ I applied the mean value thorem of integral to $\int _{0}^{1}nx^ne^{x^2}dx.$ We get $c\in (0,1):$ $$\int _{0}^{1}nx^ne^{x^2}dx=(1-0)nc^ne^{c^2}.$$ Taking limit ( $\lim_{n\to \infty}$ )on the both side, We get, $$\lim_{n\to \infty}\int _{0}^{1}nx^ne^{x^2}dx=\lim_{n\to \infty} nc^ne^{c^2}=0.$$ My answer in the examination was wrong. I don't know the correct answer. Where is my mistake?","Evaluate I applied the mean value thorem of integral to We get Taking limit ( )on the both side, We get, My answer in the examination was wrong. I don't know the correct answer. Where is my mistake?","\lim _{n\to \infty }\int _{0}^{1}nx^ne^{x^2}dx. \int _{0}^{1}nx^ne^{x^2}dx. c\in (0,1): \int _{0}^{1}nx^ne^{x^2}dx=(1-0)nc^ne^{c^2}. \lim_{n\to \infty} \lim_{n\to \infty}\int _{0}^{1}nx^ne^{x^2}dx=\lim_{n\to \infty} nc^ne^{c^2}=0.","['real-analysis', 'calculus', 'integration', 'fake-proofs']"
65,$\int_ {0}^{\infty} \frac{(e^{3x}-e^x)dx}{x(e^x+1)(e^{3x}+1)}$ [duplicate],[duplicate],\int_ {0}^{\infty} \frac{(e^{3x}-e^x)dx}{x(e^x+1)(e^{3x}+1)},"This question already has answers here : Finding $\int_{0}^{\infty} \frac{e^{3x}-e^x}{x(e^{3x}+1)(e^x+1)} dx$ (2 answers) Evaluate the integral: $\int_{0}^{\infty}\frac{\mathrm{e}^{3x}-\mathrm{e}^{x}}{x\left(\mathrm{e}^{3x}+1\right)\left(\mathrm{e}^{x}+1\right)} \, dx$ [duplicate] (2 answers) Closed 3 years ago . $$\int_ {0}^{\infty} \frac{(e^{3x}-e^x) \ \mathrm dx}{x(e^x+1)(e^{3x}+1)}$$ I tried converting it to $$\int_ {0}^{\infty} \frac{\big((e^{3x}+1)-(e^x+1)\big) \ \mathrm dx}{x(e^x+1)(e^{3x}+1)}$$ integral-calculator.com says no antiderivative found. I would like to see how it is solved by Feynman's Trick.","This question already has answers here : Finding $\int_{0}^{\infty} \frac{e^{3x}-e^x}{x(e^{3x}+1)(e^x+1)} dx$ (2 answers) Evaluate the integral: $\int_{0}^{\infty}\frac{\mathrm{e}^{3x}-\mathrm{e}^{x}}{x\left(\mathrm{e}^{3x}+1\right)\left(\mathrm{e}^{x}+1\right)} \, dx$ [duplicate] (2 answers) Closed 3 years ago . I tried converting it to integral-calculator.com says no antiderivative found. I would like to see how it is solved by Feynman's Trick.",\int_ {0}^{\infty} \frac{(e^{3x}-e^x) \ \mathrm dx}{x(e^x+1)(e^{3x}+1)} \int_ {0}^{\infty} \frac{\big((e^{3x}+1)-(e^x+1)\big) \ \mathrm dx}{x(e^x+1)(e^{3x}+1)},"['calculus', 'integration', 'improper-integrals']"
66,How to evaluate the following limit: $\lim_{x\to 0}\frac{12^x-4^x}{9^x-3^x}$?,How to evaluate the following limit: ?,\lim_{x\to 0}\frac{12^x-4^x}{9^x-3^x},How can I compute this limit $$\lim_{x\to 0}\dfrac{12^x-4^x}{9^x-3^x}\text{?}$$ My solution is here: $$\lim_{x\to 0}\dfrac{12^x-4^x}{9^x-3^x}=\dfrac{1-1}{1-1} = \dfrac{0}{0}$$ I used L'H $\hat{\mathrm{o}}$ pital's rule: \begin{align*} \lim_{x\to 0}\dfrac{12^x\ln12-4^x\ln4}{9^x\ln9-3^x\ln3}&=\dfrac{\ln12-\ln4}{\ln9-\ln3} \\ &=\dfrac{\ln(12/4)}{\ln(9/3)} \\ &=\dfrac{\ln(3)}{\ln(3)} \\ &=1 \end{align*} My answer comes out to be $1$ . Can I evaluate this limit without L'H $\hat{\mathrm{o}}$ pital's rule? Thanks.,How can I compute this limit My solution is here: I used L'H pital's rule: My answer comes out to be . Can I evaluate this limit without L'H pital's rule? Thanks.,"\lim_{x\to 0}\dfrac{12^x-4^x}{9^x-3^x}\text{?} \lim_{x\to 0}\dfrac{12^x-4^x}{9^x-3^x}=\dfrac{1-1}{1-1} = \dfrac{0}{0} \hat{\mathrm{o}} \begin{align*}
\lim_{x\to 0}\dfrac{12^x\ln12-4^x\ln4}{9^x\ln9-3^x\ln3}&=\dfrac{\ln12-\ln4}{\ln9-\ln3}
\\ &=\dfrac{\ln(12/4)}{\ln(9/3)}
\\ &=\dfrac{\ln(3)}{\ln(3)}
\\ &=1
\end{align*} 1 \hat{\mathrm{o}}",['calculus']
67,How to take $\int_0^{+\infty} \frac{x^2+1}{x^4+1}dx$?,How to take ?,\int_0^{+\infty} \frac{x^2+1}{x^4+1}dx,"The integral: $$\int_0^{+\infty} \frac{x^2+1}{x^4+1}dx$$ If num were greater than denum I would just devide it normally with long division, but it is not, how should I handle it then?","The integral: $$\int_0^{+\infty} \frac{x^2+1}{x^4+1}dx$$ If num were greater than denum I would just devide it normally with long division, but it is not, how should I handle it then?",,"['calculus', 'improper-integrals']"
68,Derivative of a function w.r.t. another function.,Derivative of a function w.r.t. another function.,,"How is this? I'm getting $(-\tan(x))$. Here's my attempt: Let $u=\sin(x)$ and $v=\cos(x)$. Then, the derivative we seek is, $$\frac{\mathrm dv}{\mathrm du}$$ Using chain rule, we have, $$\frac{\mathrm dv}{\mathrm du}=\frac{\mathrm dv}{\mathrm dx}\cdot \frac{\mathrm dx}{\mathrm du}=(-\sin(x))\cdot\frac{1}{\cos(x)}=(-\tan(x))$$ I can't find my flaw. Please help. Here's the W|A link (shortened by Bit.ly) if anyone wants to verify.","How is this? I'm getting $(-\tan(x))$. Here's my attempt: Let $u=\sin(x)$ and $v=\cos(x)$. Then, the derivative we seek is, $$\frac{\mathrm dv}{\mathrm du}$$ Using chain rule, we have, $$\frac{\mathrm dv}{\mathrm du}=\frac{\mathrm dv}{\mathrm dx}\cdot \frac{\mathrm dx}{\mathrm du}=(-\sin(x))\cdot\frac{1}{\cos(x)}=(-\tan(x))$$ I can't find my flaw. Please help. Here's the W|A link (shortened by Bit.ly) if anyone wants to verify.",,"['calculus', 'derivatives']"
69,Find $\lim \limits_{x\to 0}\frac{\log\left(\cos x\right)}{x^2}$ without L'Hopital,Find  without L'Hopital,\lim \limits_{x\to 0}\frac{\log\left(\cos x\right)}{x^2},"$$\lim_{x\to 0}\frac{\log\left(\cos x\right)}{x^2}$$ I've been triyng to: show $\displaystyle -\frac{\pi}{2}<x<\frac{\pi}{2}\Rightarrow\frac{\log\left(\cos x\right)}{x^2}<-\frac{1}{2}$ find a function so that $\displaystyle f(x)<\frac{\log\left(\cos x\right)}{x^2}$ and $\displaystyle \lim\limits_{x\to0}f(x) = -\frac{1}{2}$ And then apply the squeeze principle, but haven't managed any of these.","$$\lim_{x\to 0}\frac{\log\left(\cos x\right)}{x^2}$$ I've been triyng to: show $\displaystyle -\frac{\pi}{2}<x<\frac{\pi}{2}\Rightarrow\frac{\log\left(\cos x\right)}{x^2}<-\frac{1}{2}$ find a function so that $\displaystyle f(x)<\frac{\log\left(\cos x\right)}{x^2}$ and $\displaystyle \lim\limits_{x\to0}f(x) = -\frac{1}{2}$ And then apply the squeeze principle, but haven't managed any of these.",,"['calculus', 'limits', 'trigonometry', 'logarithms', 'limits-without-lhopital']"
70,Is it possible to convert a divergent series by subtracting a constant?,Is it possible to convert a divergent series by subtracting a constant?,,"This question came to my mind after learning about the existence of the Euler Mascheroni constant. I think that if each term of the divergent series is depressed by a certain amount then maybe the series might become convergent. However, this is just my fancy and if there is solid argument that proves that this is impossible then I would greatly appreciate as I was planning to do research on this question.","This question came to my mind after learning about the existence of the Euler Mascheroni constant. I think that if each term of the divergent series is depressed by a certain amount then maybe the series might become convergent. However, this is just my fancy and if there is solid argument that proves that this is impossible then I would greatly appreciate as I was planning to do research on this question.",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
71,How should I solve integrals of this type?,How should I solve integrals of this type?,,"The general form of the integral I want to solve is: $$ \int e^{bx}\sin(ax)  dx$$ Euler's formula has a nice connection, but the i makes it too complicated. Doing it by parts doesn't seem to get me anywhere. Do you have any tips for how to begin solving this?","The general form of the integral I want to solve is: $$ \int e^{bx}\sin(ax)  dx$$ Euler's formula has a nice connection, but the i makes it too complicated. Doing it by parts doesn't seem to get me anywhere. Do you have any tips for how to begin solving this?",,"['calculus', 'integration']"
72,How to prove that $\lim\limits_{n\to\infty} \frac{n!}{n^2}$ diverges to infinity?,How to prove that  diverges to infinity?,\lim\limits_{n\to\infty} \frac{n!}{n^2},"$\lim\limits_{n\to\infty} \dfrac{n!}{n^2} \rightarrow \lim\limits_{n\to\infty}\dfrac{\left(n-1\right)!}{n}$ I can understand that this will go to infinity because the numerator grows faster. I am trying to apply L'Hôpital's rule to this; however, have not been able to figure out how to take the derivative of $\left(n-1\right)!$ So how does one take the derivative of a factorial?","$\lim\limits_{n\to\infty} \dfrac{n!}{n^2} \rightarrow \lim\limits_{n\to\infty}\dfrac{\left(n-1\right)!}{n}$ I can understand that this will go to infinity because the numerator grows faster. I am trying to apply L'Hôpital's rule to this; however, have not been able to figure out how to take the derivative of $\left(n-1\right)!$ So how does one take the derivative of a factorial?",,"['calculus', 'limits', 'derivatives', 'factorial']"
73,What Is The Limit Of The Sequence: $\frac{n^3}{{((3n)!)^\frac{1}{n}}}$,What Is The Limit Of The Sequence:,\frac{n^3}{{((3n)!)^\frac{1}{n}}},What (if exists) the $\lim \limits_{n\to \infty}\dfrac{n^3}{{((3n)!)^\frac{1}{n}}}$? I have no idea where to begin. Maybe I could use the ratio test? Please try to keep it as elementary as possible because we are only in the beginning of the course. Thanks a lot.,What (if exists) the $\lim \limits_{n\to \infty}\dfrac{n^3}{{((3n)!)^\frac{1}{n}}}$? I have no idea where to begin. Maybe I could use the ratio test? Please try to keep it as elementary as possible because we are only in the beginning of the course. Thanks a lot.,,"['calculus', 'real-analysis', 'sequences-and-series']"
74,"If $|f(x)|$ is a differentiable function, then $f(x)$ is also?","If  is a differentiable function, then  is also?",|f(x)| f(x),"If $|f(x)|$ is a differentiable function,  then  $f(x)$ is also a  differentiable function. Why is this wrong? Can you find a counterexample please? It seems like a true sentence.","If $|f(x)|$ is a differentiable function,  then  $f(x)$ is also a  differentiable function. Why is this wrong? Can you find a counterexample please? It seems like a true sentence.",,"['calculus', 'real-analysis', 'examples-counterexamples']"
75,"Calculate $I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx$",Calculate,"I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx","Question $$I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx$$ My try $$ I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx \\ = \int_{-1}^1 \log(1-x) \, \left(\log2 + \sum_{n=1}^{+\infty} \frac{(-1)^{n-1}}{2^n \, n} \, (x-1)^n \right) \, dx \\ = \log2 \int_{-1}^1 \log(1-x) \, dx + \int_{-1}^1 \log(1-x) \, \sum_{n=1}^{+\infty} \frac{(-1)^{n-1}}{2^n \, n} \, (x-1)^n \, dx \\ = \log2 \, (2\log2 - 2) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{-1}^1 (x-1)^n \, \log(1-x) \, dx \right) \\ \overset{\begin{subarray}{c} t=1-x \\ dx=-dt \end{subarray}}{=}\, 2\log2 \, (\log2 - 1) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{0}^2 (-t)^n \, \log{t} \, dt \right) \\ = 2\log2 \, (\log2 - 1) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{0}^2 (-1)^n t^n \log{t} \, dt \right) $$",Question My try,"I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx 
I = \int_{-1}^1 \log(1-x) \, \log(1+x) \, dx \\
= \int_{-1}^1 \log(1-x) \, \left(\log2 + \sum_{n=1}^{+\infty} \frac{(-1)^{n-1}}{2^n \, n} \, (x-1)^n \right) \, dx \\
= \log2 \int_{-1}^1 \log(1-x) \, dx + \int_{-1}^1 \log(1-x) \, \sum_{n=1}^{+\infty} \frac{(-1)^{n-1}}{2^n \, n} \, (x-1)^n \, dx \\
= \log2 \, (2\log2 - 2) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{-1}^1 (x-1)^n \, \log(1-x) \, dx \right) \\
\overset{\begin{subarray}{c} t=1-x \\ dx=-dt \end{subarray}}{=}\, 2\log2 \, (\log2 - 1) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{0}^2 (-t)^n \, \log{t} \, dt \right) \\
= 2\log2 \, (\log2 - 1) + \sum_{n=1}^{+\infty} \left( \frac{(-1)^{n-1}}{2^n \, n} \int_{0}^2 (-1)^n t^n \log{t} \, dt \right)
","['real-analysis', 'calculus', 'integration', 'definite-integrals']"
76,Regular Season Problem 11 from 2023 MIT Integration Bee,Regular Season Problem 11 from 2023 MIT Integration Bee,,"$$ \int \left(\sqrt{2\log x}+ \frac{1}{\sqrt{2\log x}} \right) dx $$ I am stuck on this problem from This years integration bee. I have tried substitution but it is not giving the correct answer which is $x\sqrt{2\log x}$ I supposed $\sqrt{2\log x}$ as $t$ and differentiated it wrt $x$ , and substituted it in the above integral. But the solution has an extra $(\frac {2\log x+1}{3})$ , i dont know how and why?","I am stuck on this problem from This years integration bee. I have tried substitution but it is not giving the correct answer which is I supposed as and differentiated it wrt , and substituted it in the above integral. But the solution has an extra , i dont know how and why?","
\int \left(\sqrt{2\log x}+ \frac{1}{\sqrt{2\log x}} \right) dx
 x\sqrt{2\log x} \sqrt{2\log x} t x (\frac {2\log x+1}{3})","['calculus', 'integration', 'indefinite-integrals', 'substitution']"
77,Calculating $ \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) $,Calculating, \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) ,"To solve $ \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) $ I have separated the function in two limits: \begin{align} \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) = \lim_{x \to 0} \frac{x}{|x|} \cdot \lim_{x \to 0} \sin{x} \end{align} Now solving independently: \begin{align} \lim_{x \to 0} \frac{x}{|x|} =  \lim_{x \to 0} \text{sign}(x) \, \, \, \text{does not exist} \end{align} And: \begin{align} \lim_{x \to 0} \sin{x} = 0 \end{align} I've checked graphically and I'm aware that the limit is $ 0 $ , however, I'm not sure that multiplying ""undefined"" by $ 0 $ is something allowed. Can I do this? If not, what could be another way of solving the limit? Edit: Just realized I can split the function in a different way, knowing that $ \lim_{x \to 0} \frac{\sin{x}}{|x|} = 1 $ \begin{align} \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) = \lim_{x \to 0} (\frac{|x|\cdot\sin{x}}{x}) = \lim_{x \to 0} |x| \cdot \lim_{x \to 0} \frac{\sin{x}}{x} = 0 \cdot 1 = 0 \end{align} How about this second approach?","To solve I have separated the function in two limits: Now solving independently: And: I've checked graphically and I'm aware that the limit is , however, I'm not sure that multiplying ""undefined"" by is something allowed. Can I do this? If not, what could be another way of solving the limit? Edit: Just realized I can split the function in a different way, knowing that How about this second approach?"," \lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|})  \begin{align}
\lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) =
\lim_{x \to 0} \frac{x}{|x|} \cdot \lim_{x \to 0} \sin{x}
\end{align} \begin{align}
\lim_{x \to 0} \frac{x}{|x|} =  \lim_{x \to 0} \text{sign}(x) \, \, \, \text{does not exist}
\end{align} \begin{align}
\lim_{x \to 0} \sin{x} = 0
\end{align}  0   0   \lim_{x \to 0} \frac{\sin{x}}{|x|} = 1  \begin{align}
\lim_{x \to 0} (\frac{x\cdot\sin{x}}{|x|}) =
\lim_{x \to 0} (\frac{|x|\cdot\sin{x}}{x}) =
\lim_{x \to 0} |x| \cdot \lim_{x \to 0} \frac{\sin{x}}{x} = 0 \cdot 1 = 0
\end{align}","['calculus', 'limits', 'solution-verification']"
78,"When converting a Riemann sum to an integral, how does one decide the bounds of the converted Riemann sum?","When converting a Riemann sum to an integral, how does one decide the bounds of the converted Riemann sum?",,"Context problem: $$ \lim_{n\to \infty} \frac{1}{n} \sum_{r=1}^{r=2n} \frac{r}{\sqrt{r^2+n^2}}$$ So the thing messing me up is the '2n' in the upper of sum, I've already figured out that the function which this rienman integral is ( $ \int \frac{x}{\sqrt{1+x^2}}$ )","Context problem: So the thing messing me up is the '2n' in the upper of sum, I've already figured out that the function which this rienman integral is ( )", \lim_{n\to \infty} \frac{1}{n} \sum_{r=1}^{r=2n} \frac{r}{\sqrt{r^2+n^2}}  \int \frac{x}{\sqrt{1+x^2}},"['calculus', 'integration']"
79,Evaluating the integral $\int \sqrt{1 + \frac{1}{x^2}} dx$,Evaluating the integral,\int \sqrt{1 + \frac{1}{x^2}} dx,$$\int \sqrt{1 + \frac{1}{x^2}} dx$$ This is from the problem calculating the arc length of $y=\log{x}$. I tried $x = \sinh{t}$ or $\frac{1}{x} = \tan{t}$ but all failed.,$$\int \sqrt{1 + \frac{1}{x^2}} dx$$ This is from the problem calculating the arc length of $y=\log{x}$. I tried $x = \sinh{t}$ or $\frac{1}{x} = \tan{t}$ but all failed.,,"['calculus', 'integration', 'indefinite-integrals']"
80,$\frac{1}{\infty}$ - is this equal $0$? [duplicate],- is this equal ? [duplicate],\frac{1}{\infty} 0,"This question already has answers here : One divided by Infinity? (5 answers) Closed 10 years ago . I've seen that wolfram alpha says: $$\frac{1}{\infty} = 0$$ Well, I'm sure that: $$\lim_{x\to \infty}\frac{1}{x} = 0$$ But does $\frac{1}{\infty}$ only make sense when we calculate it's limit? Because for me, $1$ divided by any large amount of number will be always almost zero.","This question already has answers here : One divided by Infinity? (5 answers) Closed 10 years ago . I've seen that wolfram alpha says: Well, I'm sure that: But does only make sense when we calculate it's limit? Because for me, divided by any large amount of number will be always almost zero.",\frac{1}{\infty} = 0 \lim_{x\to \infty}\frac{1}{x} = 0 \frac{1}{\infty} 1,"['calculus', 'limits', 'infinity']"
81,"What is the relationship between $\int f(x) \, dx$ and $\int 1/f(x) \, dx$?",What is the relationship between  and ?,"\int f(x) \, dx \int 1/f(x) \, dx","So many integration problems would be made so easy if we were just allowed to work with the reciprocal of a function. Is there a way to relate $\int f(x) \, dx$ and $\int 1/f(x) \, dx$ ? How about if you had limits of integration? Thanks. P.S. If there is no relationship, is it proven that there is no relationship or has someone just not found it yet?","So many integration problems would be made so easy if we were just allowed to work with the reciprocal of a function. Is there a way to relate $\int f(x) \, dx$ and $\int 1/f(x) \, dx$ ? How about if you had limits of integration? Thanks. P.S. If there is no relationship, is it proven that there is no relationship or has someone just not found it yet?",,"['calculus', 'integration', 'definite-integrals']"
82,Sum of the series $\sum_{n=1}^\infty \frac{(-1)^n}{n2^{n+1}}$,Sum of the series,\sum_{n=1}^\infty \frac{(-1)^n}{n2^{n+1}},"How do I calculate the sum of this series (studying for a test, not homework)? $$\sum_{n=1}^\infty \frac{(-1)^n}{n2^{n+1}}$$","How do I calculate the sum of this series (studying for a test, not homework)? $$\sum_{n=1}^\infty \frac{(-1)^n}{n2^{n+1}}$$",,"['calculus', 'sequences-and-series']"
83,Evaluating ${\scriptsize\lim \limits_{x \to 0}} \frac{1}{{{x^3}}}\int_0^x {\frac{{{t^2}}}{{1 + {t^4}}}dt}$,Evaluating,{\scriptsize\lim \limits_{x \to 0}} \frac{1}{{{x^3}}}\int_0^x {\frac{{{t^2}}}{{1 + {t^4}}}dt},Could someone give a suggestion to calculate this limit please? $$\mathop {\lim }\limits_{x \to 0} \frac{1}{{{x^3}}}\int_0^x {\frac{{{t^2}}}{{1 + {t^4}}}dt}$$ Thanks in advance.,Could someone give a suggestion to calculate this limit please? $$\mathop {\lim }\limits_{x \to 0} \frac{1}{{{x^3}}}\int_0^x {\frac{{{t^2}}}{{1 + {t^4}}}dt}$$ Thanks in advance.,,"['calculus', 'limits', 'analysis']"
84,How I get the nth derivative of the function $y = e^x x^2$,How I get the nth derivative of the function,y = e^x x^2,I'm totally confused. Please anyone help me. $y' = e^x x^2 + 2 e^xx$ $y''= e^x x^2 + 4 e^xx + 2e^x$ $y'''= e^x x^2 + 6 e^xx + 6 e^x$ next $y''''$ but I failed to get any pattern.,I'm totally confused. Please anyone help me. next but I failed to get any pattern.,y' = e^x x^2 + 2 e^xx y''= e^x x^2 + 4 e^xx + 2e^x y'''= e^x x^2 + 6 e^xx + 6 e^x y'''',"['calculus', 'derivatives']"
85,Integrate $\frac{\theta \sin \theta}{1+\cos^2 \theta}$ with respect to $\theta$,Integrate  with respect to,\frac{\theta \sin \theta}{1+\cos^2 \theta} \theta,"Integrate : $$\int_0^\pi \frac{\theta \sin \theta}{1+\cos^2 \theta} d\theta$$ I tried to do a substitution by letting : $u=\cos \theta \implies  du=-\sin\theta\ d\theta$ But I have a problem with that $\theta$ , I don't know how to get bogged down in this variable, I tried some simplifications, but it gets complicated, here's what I've done : \begin{align} \frac{\theta \sin \theta}{1+\cos^2 \theta}&=\frac{\theta \sin\theta}{1+\frac{1+\cos 2\theta}{2}}\\ &=\frac{2\theta \sin \theta}{3+\cos 2\theta}\\ &=\frac{\theta 2\sin \theta \cos\theta}{\cos\theta(3+\cos 2\theta)}\\ &=\frac{\theta \sin 2\theta}{\cos\theta(3+\cos 2\theta)} \end{align} Any hints ? Thanks in advance !","Integrate : I tried to do a substitution by letting : But I have a problem with that , I don't know how to get bogged down in this variable, I tried some simplifications, but it gets complicated, here's what I've done : Any hints ? Thanks in advance !","\int_0^\pi \frac{\theta \sin \theta}{1+\cos^2 \theta} d\theta u=\cos \theta \implies  du=-\sin\theta\ d\theta \theta \begin{align}
\frac{\theta \sin \theta}{1+\cos^2 \theta}&=\frac{\theta \sin\theta}{1+\frac{1+\cos 2\theta}{2}}\\
&=\frac{2\theta \sin \theta}{3+\cos 2\theta}\\
&=\frac{\theta 2\sin \theta \cos\theta}{\cos\theta(3+\cos 2\theta)}\\
&=\frac{\theta \sin 2\theta}{\cos\theta(3+\cos 2\theta)}
\end{align}","['calculus', 'integration']"
86,Prove that $n \ln(n) - n \le \ln(n!)$ without Stirling,Prove that  without Stirling,n \ln(n) - n \le \ln(n!),"I need to prove that  $n \ln(n) - n \le \ln(n!)$. I have solved this but I've used the Stirling substitution for the factorial term which does not seem good to me in this proof. I am sure that there must be a direct way to solve this. One way I can think about tackling this problem is simply breaking the left and right hand side into primary terms: $$\ln(n!) = \ln(n) + \ln(n-1) + \ln(n-2) + \dots + \ln(2) + \ln(1)$$ $$n \ln(n) - n = n (\ln(n)-1) = (\ln(n) - 1) + (\ln(n) -1) + \dots + (\ln(n) -1)$$ I need to somehow show that the the top expression is greater than the bottom expression, but I can only be sure that $\ln(n) > \ln(n) -1$ and that $ \ln(n-1)>\ln(n) - 1$ What can I do about the rest?","I need to prove that  $n \ln(n) - n \le \ln(n!)$. I have solved this but I've used the Stirling substitution for the factorial term which does not seem good to me in this proof. I am sure that there must be a direct way to solve this. One way I can think about tackling this problem is simply breaking the left and right hand side into primary terms: $$\ln(n!) = \ln(n) + \ln(n-1) + \ln(n-2) + \dots + \ln(2) + \ln(1)$$ $$n \ln(n) - n = n (\ln(n)-1) = (\ln(n) - 1) + (\ln(n) -1) + \dots + (\ln(n) -1)$$ I need to somehow show that the the top expression is greater than the bottom expression, but I can only be sure that $\ln(n) > \ln(n) -1$ and that $ \ln(n-1)>\ln(n) - 1$ What can I do about the rest?",,"['calculus', 'algebra-precalculus', 'logarithms']"
87,Given $f(x)=x(x-1)(x-2)...(x-10)$ what is the derivative $f'(0)$?,Given  what is the derivative ?,f(x)=x(x-1)(x-2)...(x-10) f'(0),"$$f: \Bbb R \to \Bbb R; x \mapsto f(x)=x(x-1)(x-2)\cdots(x-10)$$   Evaluate $f'(0)$! I've tried to set the factors apart, but I only know that $(fg)'=f'g+fg'$. I don't know how I should apply that rule for any $n$ amount of factors. I also thought of actually doing the multiplication, but I don't know what shortcut I should use, and multiplicating one after the other takes extremely long.","$$f: \Bbb R \to \Bbb R; x \mapsto f(x)=x(x-1)(x-2)\cdots(x-10)$$   Evaluate $f'(0)$! I've tried to set the factors apart, but I only know that $(fg)'=f'g+fg'$. I don't know how I should apply that rule for any $n$ amount of factors. I also thought of actually doing the multiplication, but I don't know what shortcut I should use, and multiplicating one after the other takes extremely long.",,"['calculus', 'derivatives']"
88,How to prove that $\sum_{1}^{\infty} \frac{1}{n^3} \le 1.5$,How to prove that,\sum_{1}^{\infty} \frac{1}{n^3} \le 1.5,"I have this sequence:  $$\sum_{1}^{\infty} \frac{1}{n^3}$$ and I need to prove that:  $\sum_{1}^{\infty} \frac{1}{n^3} \le 1.5$ So basically I know that this sequence converges using the integral test, but I don't know how to prove the above statement. Some help?","I have this sequence:  $$\sum_{1}^{\infty} \frac{1}{n^3}$$ and I need to prove that:  $\sum_{1}^{\infty} \frac{1}{n^3} \le 1.5$ So basically I know that this sequence converges using the integral test, but I don't know how to prove the above statement. Some help?",,"['calculus', 'sequences-and-series', 'inequality', 'convergence-divergence']"
89,Showing that ln$(xy)$ = ln $x$+ln $y$,Showing that ln = ln +ln,(xy) x y,"Let ln $x\  =\ \int_1^x \frac{1}{t}\ dt.$ How do I show that ln$(xy)$ = ln $x$+ln $y$ where $x$ and $y$ are positive reals. I read the following proof from Limaye book. Fix $y\in (0,\infty).$ Consider $f(x)=$ ln $xy$ -ln $x$. Then  $f'(x)= \frac{1}{xy}.y-\frac{1}{x}=0 \ \forall\  x \in (0,\infty). $ $\therefore f$ is constant.  $f(x)=f(1)=$ ln $y$ - ln $1 = $ ln $y.$ $ \therefore f(x) =  $ln$ (xy) - $ln$ x = $ln$  y\ \implies\   $ln$ (xy) = $ln$ \ x + $ ln$\   y$ I feels that this proof is so constructive. Im wondering to know some alternative proofs. Thanks in Advance...","Let ln $x\  =\ \int_1^x \frac{1}{t}\ dt.$ How do I show that ln$(xy)$ = ln $x$+ln $y$ where $x$ and $y$ are positive reals. I read the following proof from Limaye book. Fix $y\in (0,\infty).$ Consider $f(x)=$ ln $xy$ -ln $x$. Then  $f'(x)= \frac{1}{xy}.y-\frac{1}{x}=0 \ \forall\  x \in (0,\infty). $ $\therefore f$ is constant.  $f(x)=f(1)=$ ln $y$ - ln $1 = $ ln $y.$ $ \therefore f(x) =  $ln$ (xy) - $ln$ x = $ln$  y\ \implies\   $ln$ (xy) = $ln$ \ x + $ ln$\   y$ I feels that this proof is so constructive. Im wondering to know some alternative proofs. Thanks in Advance...",,"['calculus', 'real-analysis', 'algebra-precalculus']"
90,Evaluate $\int\cos(\ln x^2)dx$,Evaluate,\int\cos(\ln x^2)dx,"$$\int\cos(\ln x^2)dx$$ I've learned substitution method, integration by parts, and some other basic methods for integration, but I have no idea how to start this question. How should I start this question?","$$\int\cos(\ln x^2)dx$$ I've learned substitution method, integration by parts, and some other basic methods for integration, but I have no idea how to start this question. How should I start this question?",,"['calculus', 'integration', 'indefinite-integrals']"
91,Evaluating the primitive $\int \frac{\mathrm dx}{e^{2x} + e^x + 1} $,Evaluating the primitive,\int \frac{\mathrm dx}{e^{2x} + e^x + 1} ,Could someone help me evaluate this? $$\int \frac{\mathrm dx}{e^{2x} + e^x + 1} $$ I tried to solve it for hours with no success. I tried Wolframalpha but it's giving a step by step solution that is too long that in an exam I won't even have the time to write the solution. Thanks in advance.,Could someone help me evaluate this? $$\int \frac{\mathrm dx}{e^{2x} + e^x + 1} $$ I tried to solve it for hours with no success. I tried Wolframalpha but it's giving a step by step solution that is too long that in an exam I won't even have the time to write the solution. Thanks in advance.,,"['calculus', 'integration']"
92,How to disprove this fallacy that derivatives of $x^2$ and $x+x+x+\dots\quad(x\text{ times})$ are not same. [duplicate],How to disprove this fallacy that derivatives of  and  are not same. [duplicate],x^2 x+x+x+\dots\quad(x\text{ times}),"This question already has answers here : Closed 11 years ago . Possible Duplicate: Where is the flaw in this argument of a proof that 1=2? (Derivative of repeated addition) \begin{align*} x^2 &= \underbrace{x + x + x + \dots + x}_{x \text{ times}}, \\ \therefore \frac{\mathrm{d}}{\mathrm{d}x} (x^2) &= \frac{\mathrm{d}}{\mathrm{d}x} (\underbrace{x + x + x + \dots + x}_{x \text{ times}}) \\ &= \underbrace{1 + 1 + 1 + \dots + 1}_{x \text{ times}} \\ &= x. \end{align*} But we know that $$ \frac{\mathrm{d}}{\mathrm{d}x} (x^2) = 2x. $$ So what is the problem? My take is that we cannot differentiate both sides because $\underbrace{{x+x+x+\cdots+x}}_{x \text{  times}}$ is not fixed and thus $1$ is not equal to $2$ .",This question already has answers here : Closed 11 years ago . Possible Duplicate: Where is the flaw in this argument of a proof that 1=2? (Derivative of repeated addition) But we know that So what is the problem? My take is that we cannot differentiate both sides because is not fixed and thus is not equal to .,"\begin{align*}
x^2 &= \underbrace{x + x + x + \dots + x}_{x \text{ times}}, \\
\therefore \frac{\mathrm{d}}{\mathrm{d}x} (x^2)
&= \frac{\mathrm{d}}{\mathrm{d}x} (\underbrace{x + x + x + \dots + x}_{x \text{ times}}) \\
&= \underbrace{1 + 1 + 1 + \dots + 1}_{x \text{ times}} \\
&= x.
\end{align*}  \frac{\mathrm{d}}{\mathrm{d}x} (x^2) = 2x.  \underbrace{{x+x+x+\cdots+x}}_{x \text{  times}} 1 2","['calculus', 'derivatives', 'fake-proofs']"
93,"Proving the integral inequality $2≤\int_{-1}^1 \sqrt{1+x^6} \,dx ≤ 2\sqrt{2} $",Proving the integral inequality,"2≤\int_{-1}^1 \sqrt{1+x^6} \,dx ≤ 2\sqrt{2} ","I am trying to prove that $$2≤\int_{-1}^1 \sqrt{1+x^6} \,dx ≤ 2\sqrt{2} $$ I learned that the equation $${d\over dx}\int_{g(x)}^{h(x)} f(t)\,dt = f(h(x))h'(x) - f(g(x))g'(x)  $$ is true due to Fundamental Theorem of Calculus and Chain Rule, and I was thinking about taking the derivative to all side of the inequality, but I am not sure that it is the correct way to prove this. Can I ask for a  help to prove the inequality correctly? Any help would be appreciated! Thanks!","I am trying to prove that I learned that the equation is true due to Fundamental Theorem of Calculus and Chain Rule, and I was thinking about taking the derivative to all side of the inequality, but I am not sure that it is the correct way to prove this. Can I ask for a  help to prove the inequality correctly? Any help would be appreciated! Thanks!","2≤\int_{-1}^1 \sqrt{1+x^6} \,dx ≤ 2\sqrt{2}  {d\over dx}\int_{g(x)}^{h(x)} f(t)\,dt = f(h(x))h'(x) - f(g(x))g'(x)  ","['calculus', 'integration', 'derivatives', 'inequality']"
94,Does $\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)$ have a closed form solution?,Does  have a closed form solution?,\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right),"I need to know whether $$\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)$$has a close form solution? It is easy to prove this series converge ,because $\frac11+\frac12+\frac 13+...+\frac1 n \sim \ln n$ so $$\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)\sim\sum_{n=1}^{\infty} \frac{\ln n}{2^n}<\sum_{n=1}^{\infty} \frac{n}{2^n}=4$$ I tried to get the answer by a MATLAb program: suppose $$\quad{a_k=\sum_{n=1}^{k} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)\\a_=0.5\\a_2=    0.8750   \\a_3= 1.1042 \\a_4=   1.2344\\a_5=    1.3057\\\vdots\\a_{20}=1.3863\\\vdots\\a_{100}= 1.3863\\\vdots\\a_{10000}= 1.3863\\\vdots\\a_{10^6}<1.5}$$ So I think It converges to $1.3863 \leq \lim_{k\to \infty}a_k \leq 1.5$ My question is about an analytic solution, Does it exist? Thanks in advance for any Idea.","I need to know whether $$\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)$$has a close form solution? It is easy to prove this series converge ,because $\frac11+\frac12+\frac 13+...+\frac1 n \sim \ln n$ so $$\sum_{n=1}^{\infty} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)\sim\sum_{n=1}^{\infty} \frac{\ln n}{2^n}<\sum_{n=1}^{\infty} \frac{n}{2^n}=4$$ I tried to get the answer by a MATLAb program: suppose $$\quad{a_k=\sum_{n=1}^{k} \frac{1}{2^n}\left(\frac11+\frac12+\frac 13+...+\frac1 n\right)\\a_=0.5\\a_2=    0.8750   \\a_3= 1.1042 \\a_4=   1.2344\\a_5=    1.3057\\\vdots\\a_{20}=1.3863\\\vdots\\a_{100}= 1.3863\\\vdots\\a_{10000}= 1.3863\\\vdots\\a_{10^6}<1.5}$$ So I think It converges to $1.3863 \leq \lim_{k\to \infty}a_k \leq 1.5$ My question is about an analytic solution, Does it exist? Thanks in advance for any Idea.",,"['calculus', 'sequences-and-series', 'power-series']"
95,Help proving an inequality in calculus $0 \leq \frac{x\ln(x)}{x^2-1}\leq \frac{1}{2}$,Help proving an inequality in calculus,0 \leq \frac{x\ln(x)}{x^2-1}\leq \frac{1}{2},"So as the title states, I need help with proving this inequality: $$0 \leq \frac{x\ln(x)}{x^2-1}\leq \frac{1}{2} $$ Also an important thisn is that $x>1$. So I thought I could look different kinds fo x, but it's a subject of calculus, so perhaps it's related to Lagrange's or Rolle's theorem, but i cannot get an idea, i tried changing the inequality but it's not really working, so any help with solution would be really appreciated. Thank you in advance.","So as the title states, I need help with proving this inequality: $$0 \leq \frac{x\ln(x)}{x^2-1}\leq \frac{1}{2} $$ Also an important thisn is that $x>1$. So I thought I could look different kinds fo x, but it's a subject of calculus, so perhaps it's related to Lagrange's or Rolle's theorem, but i cannot get an idea, i tried changing the inequality but it's not really working, so any help with solution would be really appreciated. Thank you in advance.",,"['calculus', 'inequality']"
96,Is limit of function -1/0 ok?,Is limit of function -1/0 ok?,,"A quick question, i'm determining the limit of this function: $$\lim_{x→1}\frac{x^2 - 2x}{x^2 -2x +1}$$ When I divide numerator and denominator by $x^2$ and fill in $1$, I get $-1/0$. This is an illegal form right? Or does it indicate it is going to $∞$ or $-∞$?","A quick question, i'm determining the limit of this function: $$\lim_{x→1}\frac{x^2 - 2x}{x^2 -2x +1}$$ When I divide numerator and denominator by $x^2$ and fill in $1$, I get $-1/0$. This is an illegal form right? Or does it indicate it is going to $∞$ or $-∞$?",,"['calculus', 'limits']"
97,Improper integral of a rational function:$\int_0^\infty \frac{5t^6}{1+t^{10}}dt$,Improper integral of a rational function:,\int_0^\infty \frac{5t^6}{1+t^{10}}dt,Find the value of the integral $$\int_0^\infty \frac{x^{\frac25}}{1+x^2}dx.$$ I tried the substitution $x=t^5$ to obtain $$\int_0^\infty \frac{5t^6}{1+t^{10}}dt.$$ Now we can factor the denominator to polynomials of degree two (because we can easily find all roots of polynomial occured in the denominator of the former integral by using complex numbers) and then by using partial fraction decomposition method find the integral! Is there any simple method to find the integral value??!!,Find the value of the integral $$\int_0^\infty \frac{x^{\frac25}}{1+x^2}dx.$$ I tried the substitution $x=t^5$ to obtain $$\int_0^\infty \frac{5t^6}{1+t^{10}}dt.$$ Now we can factor the denominator to polynomials of degree two (because we can easily find all roots of polynomial occured in the denominator of the former integral by using complex numbers) and then by using partial fraction decomposition method find the integral! Is there any simple method to find the integral value??!!,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
98,Prove $\int_{\mathbb{R^{+}}} \frac{\sin^3 {(\pi x^2)} \cos {(4x^2)}}{x^5} dx=\frac{\pi}{32} (3\pi-4)^2$,Prove,\int_{\mathbb{R^{+}}} \frac{\sin^3 {(\pi x^2)} \cos {(4x^2)}}{x^5} dx=\frac{\pi}{32} (3\pi-4)^2,"How do you arrive at the result $$I=\displaystyle\int_{\mathbb{R^{+}}} \dfrac{\sin^3 {(\pi x^2)} \cos {(4x^2)}}{x^5} dx=\dfrac{\pi}{32} (3\pi-4)^2\ ?$$ Wolfram Alpha agrees numerically . I tried replacing $\sin p$ by $\dfrac{e^{ip}-e^{-ip}}{2i}$ and similarly for $\cos p$, but in vain.","How do you arrive at the result $$I=\displaystyle\int_{\mathbb{R^{+}}} \dfrac{\sin^3 {(\pi x^2)} \cos {(4x^2)}}{x^5} dx=\dfrac{\pi}{32} (3\pi-4)^2\ ?$$ Wolfram Alpha agrees numerically . I tried replacing $\sin p$ by $\dfrac{e^{ip}-e^{-ip}}{2i}$ and similarly for $\cos p$, but in vain.",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
99,Simple proof of irrationality of e,Simple proof of irrationality of e,,Is this reasoning correct? Assume $e=\frac{p}{q}$ where $p$ and $q$ are natural numbers taking natural log on both sides and using the fact that natural $\ln e = 1$. We come up with  $1 = \ln\left(\frac{p}{q}\right)$. Taking derivative on both sides $0 = \large\frac{1}{\frac{p}{q}}$ taking $\frac{p}{q}$ to other side results in  $0 = 1$ absurdity  therefore $e=\frac{p}{q}$ is false and hence $e$ is irrational. What do you think guys?,Is this reasoning correct? Assume $e=\frac{p}{q}$ where $p$ and $q$ are natural numbers taking natural log on both sides and using the fact that natural $\ln e = 1$. We come up with  $1 = \ln\left(\frac{p}{q}\right)$. Taking derivative on both sides $0 = \large\frac{1}{\frac{p}{q}}$ taking $\frac{p}{q}$ to other side results in  $0 = 1$ absurdity  therefore $e=\frac{p}{q}$ is false and hence $e$ is irrational. What do you think guys?,,"['calculus', 'proof-verification']"
