,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Computation of a Hilbert Samuel function,Computation of a Hilbert Samuel function,,"I am trying to solve the following exercise from Eisenbud's Commutative Algebra with a View Toward Algebraic Geometry: Exercise 12.1: Let $f\in R = k[x,y,z]_{(x,y,z)}$ be a homogeneous form of degree $d$ , monic in $x$ . Show that $(y,z)$ is an ideal of finite colength on $M = R/(f)$ . Compute the corresponding Hilbert-Samuel functions. I am aware that a similar question has been asked here: Compute the Hilbert-Samuel function . Nonetheless, since there are no answers or comments at the linked post, I'm posting it again here. Here is what I have tried: I have been able to show that $(y,z)$ has finite colength on $M$ , as it's quite easy to see that some large power of $(x,y,z)$ is contained in $(y,z) + \text{ann } M$ . For the second part however, I think I am stuck. To find the Hilbert Samuel polynomial, I need to compute the length of the module $M_n = (y,z)^nM/(y,z)^{n+1}M$ . I am tempted to think that this length is $d(n+1)$ , because as far as I can see the $M_n$ is a finite dimensional $k$ vector space, with basis $\{x^ay^bz^c |0\le a\le d - 1, b + c = n\}$ . However, I'm not sure if this is useful, or how I can translate this to a statement about the length of $M_n$ . I would be glad if someone could point out how to proceed.","I am trying to solve the following exercise from Eisenbud's Commutative Algebra with a View Toward Algebraic Geometry: Exercise 12.1: Let be a homogeneous form of degree , monic in . Show that is an ideal of finite colength on . Compute the corresponding Hilbert-Samuel functions. I am aware that a similar question has been asked here: Compute the Hilbert-Samuel function . Nonetheless, since there are no answers or comments at the linked post, I'm posting it again here. Here is what I have tried: I have been able to show that has finite colength on , as it's quite easy to see that some large power of is contained in . For the second part however, I think I am stuck. To find the Hilbert Samuel polynomial, I need to compute the length of the module . I am tempted to think that this length is , because as far as I can see the is a finite dimensional vector space, with basis . However, I'm not sure if this is useful, or how I can translate this to a statement about the length of . I would be glad if someone could point out how to proceed.","f\in R = k[x,y,z]_{(x,y,z)} d x (y,z) M = R/(f) (y,z) M (x,y,z) (y,z) + \text{ann } M M_n = (y,z)^nM/(y,z)^{n+1}M d(n+1) M_n k \{x^ay^bz^c |0\le a\le d - 1, b + c = n\} M_n","['abstract-algebra', 'ring-theory', 'commutative-algebra', 'modules', 'hilbert-polynomial']"
1,"$A \oplus B \cong A \oplus C$ implies $B \cong C$ where $A,B,C$ are finitely generated $R$ modules and $R$ is a PID",implies  where  are finitely generated  modules and  is a PID,"A \oplus B \cong A \oplus C B \cong C A,B,C R R","There are number of similar questions to this, but I have read through them all and the answers either rely on results that I don't have access to or I'm unsure how to translate them to this situation. The exact problem is as follows. Suppose $R$ is a PID, $A,B$ and $C$ are finitely generated $R$ modules and that $A \oplus B \cong A \oplus C$ , then $B \cong C$ . It seems like we should be able to apply the structure theorem for finitely generated modules over a PID. In the version I'm most familiar with, this result says that given a PID $R$ and an $R$ module $M$ , we have that $$ M \cong R^n \oplus R/(a_1) \oplus ...\oplus R/(a_m) $$ where $n \in \mathbb{N}$ , $a_i \in R$ , and $a_1|a_2|...|a_n$ . Further, if $$ M \cong R^s \oplus R/(b_1) \oplus ...\oplus R/(b_t) $$ and $b_1|...b|t$ , then we have that $n=s$ , $m=t$ and $a_i$ is associate to $b_i$ for all $a_i$ . Applying that to this problem at hand, we can write down decompositions for $A,B$ , and $C$ : $$ A \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) $$ $$ B \cong R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m) $$ $$ C \cong R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n) $$ So we have that $$ R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n)  $$ $$ R^{a+b}\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^{a+c} \oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(c_1)\oplus ... \oplus R/(c_n)  $$ What I would like to do here is to apply the uniqueness part of the structure theorem I referenced above, but it is not at all clear to me why the divisibility condition on the invariant factors would still hold, since now we have factors from from $A$ and $B$ on the left hand side and the same problem on the right. What am I missing here? Is this easier to understand with the elementary divisor form? Also as I mentioned at the beginning, I know there are some similar questions already posed, but I have read them and I am still unsure, so if you give a link to another question please try to explain more precisely how that question applies.","There are number of similar questions to this, but I have read through them all and the answers either rely on results that I don't have access to or I'm unsure how to translate them to this situation. The exact problem is as follows. Suppose is a PID, and are finitely generated modules and that , then . It seems like we should be able to apply the structure theorem for finitely generated modules over a PID. In the version I'm most familiar with, this result says that given a PID and an module , we have that where , , and . Further, if and , then we have that , and is associate to for all . Applying that to this problem at hand, we can write down decompositions for , and : So we have that What I would like to do here is to apply the uniqueness part of the structure theorem I referenced above, but it is not at all clear to me why the divisibility condition on the invariant factors would still hold, since now we have factors from from and on the left hand side and the same problem on the right. What am I missing here? Is this easier to understand with the elementary divisor form? Also as I mentioned at the beginning, I know there are some similar questions already posed, but I have read them and I am still unsure, so if you give a link to another question please try to explain more precisely how that question applies.","R A,B C R A \oplus B \cong A \oplus C B \cong C R R M 
M \cong R^n \oplus R/(a_1) \oplus ...\oplus R/(a_m)
 n \in \mathbb{N} a_i \in R a_1|a_2|...|a_n 
M \cong R^s \oplus R/(b_1) \oplus ...\oplus R/(b_t)
 b_1|...b|t n=s m=t a_i b_i a_i A,B C 
A \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l)
 
B \cong R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m)
 
C \cong R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n)
 
R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^b\oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^a\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R^c\oplus R/(c_1)\oplus ... \oplus R/(c_n) 
 
R^{a+b}\oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(b_1)\oplus ... \oplus R/(b_m) \cong R^{a+c} \oplus R/(a_1)\oplus ... \oplus R/(a_l) \oplus R/(c_1)\oplus ... \oplus R/(c_n) 
 A B","['abstract-algebra', 'modules', 'principal-ideal-domains']"
2,"Nondiscrete topology making $(Z,+)$ a topological group.",Nondiscrete topology making  a topological group.,"(Z,+)","In Fourier Analysis on Number Fields , D. Ramakrishnan and R. J. Valenza propose the following exercise : While the (a) is quite clear, I had a lot more trouble with the (b). My idea for it was the following: Following the hint, we'll use the fact that the orbit of a rotation on the circle is either periodic or dense to find another element of $U\cap G$ . Let $p_1,\dotsc,p_k:\mathscr{G}\to S^1$ be the projections which satisfy $p_i(U)\neq S^1$ and consider the sequence $(j(1)^n)_{n\in\mathbf{Z}}$ . We start with $M=\mathbf{Z}$ and, for each $i$ , if $p_i(j(1)^n)$ is periodic in $n$ , we remove all the $n\in M$ such that $p_i(j(1)^n)\neq p_i(j(1))$ ; if $p_i(j(1)^n)$ is dense in $S^1$ , we remove all the $n\in M$ such that $p_i(j(1)^n)\notin p_i(U)$ . In the end $M$ is still an infinite set. Then, if $n\in M-\{1\}$ , $j(1)^n$ is another element of $U\cap G$ other than $j(1)$ . This contradicts the fact that $U\cap G$ is a singleton. I believe the bold sentence is true but I'm not so confident about it. Of course $M$ is infinite after the first stage but I haven't found an argument to justify it being infinite after the second stage. I would appreciate some clarification and would also find it interesting if someone had another solution for this exercise. (In the first stage, each one of the $p_i(j(1)^n)$ is of the form $e^{2\pi i q_in}$ , where $q_i$ is a rational number. If $m$ is the lcm of the denominators of the $q_i$ , then $M=m\mathbf{Z}$ after this stage.)","In Fourier Analysis on Number Fields , D. Ramakrishnan and R. J. Valenza propose the following exercise : While the (a) is quite clear, I had a lot more trouble with the (b). My idea for it was the following: Following the hint, we'll use the fact that the orbit of a rotation on the circle is either periodic or dense to find another element of . Let be the projections which satisfy and consider the sequence . We start with and, for each , if is periodic in , we remove all the such that ; if is dense in , we remove all the such that . In the end is still an infinite set. Then, if , is another element of other than . This contradicts the fact that is a singleton. I believe the bold sentence is true but I'm not so confident about it. Of course is infinite after the first stage but I haven't found an argument to justify it being infinite after the second stage. I would appreciate some clarification and would also find it interesting if someone had another solution for this exercise. (In the first stage, each one of the is of the form , where is a rational number. If is the lcm of the denominators of the , then after this stage.)","U\cap G p_1,\dotsc,p_k:\mathscr{G}\to S^1 p_i(U)\neq S^1 (j(1)^n)_{n\in\mathbf{Z}} M=\mathbf{Z} i p_i(j(1)^n) n n\in M p_i(j(1)^n)\neq p_i(j(1)) p_i(j(1)^n) S^1 n\in M p_i(j(1)^n)\notin p_i(U) M n\in M-\{1\} j(1)^n U\cap G j(1) U\cap G M p_i(j(1)^n) e^{2\pi i q_in} q_i m q_i M=m\mathbf{Z}","['abstract-algebra', 'general-topology', 'topological-groups']"
3,Convolution algebra as a bialgebra?,Convolution algebra as a bialgebra?,,"Context Let $(A, \mu, \eta, \Delta, \epsilon)$ be a bialgebra over a field $k$ . Consider the vector space $\mathrm{End}(A)$ over $k$ . Define the convolution product $$*: \mathrm{End}(A)\otimes \mathrm{End}(A) \rightarrow \mathrm{End}(A); \qquad f \otimes g \mapsto \mu \circ (f \otimes g)\circ \Delta.$$ Define the unit map $$\overline \eta: k \rightarrow \mathrm{End}(A); \qquad 1 \mapsto  \eta \circ \epsilon.$$ Then $(\mathrm{End}(A), *, \overline \eta)$ becomes an associative, unital algebra. Questions Can $(\mathrm{End}(A), *, \overline \eta)$ be made into a bialgebra? Does it become a Hopf algebra that way? Is there a canonical way?","Context Let be a bialgebra over a field . Consider the vector space over . Define the convolution product Define the unit map Then becomes an associative, unital algebra. Questions Can be made into a bialgebra? Does it become a Hopf algebra that way? Is there a canonical way?","(A, \mu, \eta, \Delta, \epsilon) k \mathrm{End}(A) k *: \mathrm{End}(A)\otimes \mathrm{End}(A) \rightarrow \mathrm{End}(A); \qquad f \otimes g \mapsto \mu \circ (f \otimes g)\circ \Delta. \overline \eta: k \rightarrow \mathrm{End}(A); \qquad 1 \mapsto  \eta \circ \epsilon. (\mathrm{End}(A), *, \overline \eta) (\mathrm{End}(A), *, \overline \eta)","['abstract-algebra', 'convolution', 'hopf-algebras']"
4,Splitting field and Galois group of $(x^5-1)(x^2+1)$ over $\mathbb{Q}$,Splitting field and Galois group of  over,(x^5-1)(x^2+1) \mathbb{Q},"Consider $p(x) = (x^5-1)(x^2+1)$ . Then, its splitting field is $\mathbb{Q}(e^{\frac{2\pi i}{5}}, i)$ . Thus, $f\in \text{Gal}(\mathbb{Q}(e^{\frac{2\pi i}{5}}, i)/\mathbb{Q})$ maps $\omega = e^{\frac{2\pi i}{5}}$ to any of $\omega^k$ for $k=1,...,4$ and $i$ to $\pm i$ . In that way, I can conclude that $|\text{Gal}(\mathbb{Q}(e^{\frac{2\pi i}{5}}, i)/\mathbb{Q})|= 4 \cdot 2 = 8$ . Now, how do I know which of the groups of order $8$ it is? It might be $\mathbb{Z}_2 \times \mathbb{Z}_4$ because of element orders but I am not sure.","Consider . Then, its splitting field is . Thus, maps to any of for and to . In that way, I can conclude that . Now, how do I know which of the groups of order it is? It might be because of element orders but I am not sure.","p(x) = (x^5-1)(x^2+1) \mathbb{Q}(e^{\frac{2\pi i}{5}}, i) f\in \text{Gal}(\mathbb{Q}(e^{\frac{2\pi i}{5}}, i)/\mathbb{Q}) \omega = e^{\frac{2\pi i}{5}} \omega^k k=1,...,4 i \pm i |\text{Gal}(\mathbb{Q}(e^{\frac{2\pi i}{5}}, i)/\mathbb{Q})|= 4 \cdot 2 = 8 8 \mathbb{Z}_2 \times \mathbb{Z}_4","['abstract-algebra', 'field-theory', 'galois-theory', 'splitting-field']"
5,Group of order $3k$ has subgroup of index $3$ - simple proof,Group of order  has subgroup of index  - simple proof,3k 3,"Suppose $G$ is a group of order $3k$ with $gcd(k,6) = 1$ (so $2 \nmid k, 3 \nmid k$ ). Why does $G$ always have a subgroup of index $3$ ? If there is a subgroup of index $3$ then it will be normal - this question is about the existence of such a subgroup though. The result actually follows from Feit-Thompson and existence of Hall subgroups but this is too overpowered. I'm looking for an simple proof, something like: If $G$ is a counterexample with $|G|$ minimal and $H$ is a nontrivial normal subgroup with $3 \nmid |H|$ , then $G/H$ has a subgroup of index $3$ , and its preimage in $G$ would then be index $3$ in $G$ . So WLOG every nontrivial normal subgroup of $G$ has order divisible by $3$ . How can one finish the argument?","Suppose is a group of order with (so ). Why does always have a subgroup of index ? If there is a subgroup of index then it will be normal - this question is about the existence of such a subgroup though. The result actually follows from Feit-Thompson and existence of Hall subgroups but this is too overpowered. I'm looking for an simple proof, something like: If is a counterexample with minimal and is a nontrivial normal subgroup with , then has a subgroup of index , and its preimage in would then be index in . So WLOG every nontrivial normal subgroup of has order divisible by . How can one finish the argument?","G 3k gcd(k,6) = 1 2 \nmid k, 3 \nmid k G 3 3 G |G| H 3 \nmid |H| G/H 3 G 3 G G 3","['abstract-algebra', 'group-theory', 'finite-groups']"
6,"Finite non-Abelian group $|G| = pq$, $p>q$ primes, prove: $q\ |\ p-1$","Finite non-Abelian group ,  primes, prove:",|G| = pq p>q q\ |\ p-1,"I have a finite noncommutative group $G$ with $pq$ elements, where $p, q$ are prime numbers. So $|G| = pq$ and $p > q$ . I need to prove that $p-1$ is divisible by $q$ . (so that $q\ |\ p-1$ ) I think I am supposed to use centralizers. (Centralizers for element $a \in G$ is a set $R(a) = \{g^{-1}ag\ |\ g \in G\}$ .) I have proved that there exist one and one only subgroup with $p$ elements and that there are $p-1$ elements with order $p$ in the group $G$ . I am not sure if this is useful. How could I prove that $p-1$ is divisible by $q$ ? EDIT: Thank you for your answers, I will look into it. I haven't learned about Sylows theorems or groups yet. Is there any other way to prove this without using Sylow?","I have a finite noncommutative group with elements, where are prime numbers. So and . I need to prove that is divisible by . (so that ) I think I am supposed to use centralizers. (Centralizers for element is a set .) I have proved that there exist one and one only subgroup with elements and that there are elements with order in the group . I am not sure if this is useful. How could I prove that is divisible by ? EDIT: Thank you for your answers, I will look into it. I haven't learned about Sylows theorems or groups yet. Is there any other way to prove this without using Sylow?","G pq p, q |G| = pq p > q p-1 q q\ |\ p-1 a \in G R(a) = \{g^{-1}ag\ |\ g \in G\} p p-1 p G p-1 q","['abstract-algebra', 'group-theory', 'finite-groups']"
7,On Atiyah-Macdonald Exercise 3.26,On Atiyah-Macdonald Exercise 3.26,,"I am trying to prove the exercise 3.26 on Atiyah-Macdonlad: Let $(B_{\alpha},g_{\alpha \beta})$ a direct system of rings and $B$ the direct limit. For each $\alpha$, let $f_{\alpha}:A\rightarrow B_{\alpha}$ be a ring homomorphism such that $g_{\alpha \beta}\circ f_{\alpha}=f_{\beta}$ whenever $\alpha\leq \beta$. Then $f_{\alpha}$ induce $f:A\rightarrow B$. Show that    $$f^{\ast}(\mathrm{Spec}(B))=\bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))$$ Following the hint, I figured out  $$\begin{aligned}\mathfrak{p}\notin f^{\ast}(\mathrm{Spec}(B)) &\Leftrightarrow  \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0\end{aligned}$$ and $$\begin{aligned}\mathfrak{p}\notin \bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))&\Leftrightarrow  B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha\end{aligned}$$ By exercise 2.21 on Atiyah-Macdonald, we have $$ \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0 \Rightarrow B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha$$ But I have no idea how to prove the converse, which is true according to Atiyah-Macdonald. Since the direct limit is the direct sum modulo something, consider the direct sum of $B_{\alpha}$. The zero rings will be killed. The quotient part is unknown but intuitively should not be the direct sum of the rest non-zero rings. Does the fact that $B_{\alpha}\otimes_A k(\mathfrak{p})$ is a $k$-module matter here? Any hint and answers are welcomed!","I am trying to prove the exercise 3.26 on Atiyah-Macdonlad: Let $(B_{\alpha},g_{\alpha \beta})$ a direct system of rings and $B$ the direct limit. For each $\alpha$, let $f_{\alpha}:A\rightarrow B_{\alpha}$ be a ring homomorphism such that $g_{\alpha \beta}\circ f_{\alpha}=f_{\beta}$ whenever $\alpha\leq \beta$. Then $f_{\alpha}$ induce $f:A\rightarrow B$. Show that    $$f^{\ast}(\mathrm{Spec}(B))=\bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))$$ Following the hint, I figured out  $$\begin{aligned}\mathfrak{p}\notin f^{\ast}(\mathrm{Spec}(B)) &\Leftrightarrow  \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0\end{aligned}$$ and $$\begin{aligned}\mathfrak{p}\notin \bigcap f_{\alpha}^{\ast}(\mathrm{Spec}(B_{\alpha}))&\Leftrightarrow  B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha\end{aligned}$$ By exercise 2.21 on Atiyah-Macdonald, we have $$ \varinjlim(B_{\alpha}\otimes_A k(\mathfrak{p}))=0 \Rightarrow B_{\alpha}\otimes_A k(\mathfrak{p})=0 \text{  for some }\alpha$$ But I have no idea how to prove the converse, which is true according to Atiyah-Macdonald. Since the direct limit is the direct sum modulo something, consider the direct sum of $B_{\alpha}$. The zero rings will be killed. The quotient part is unknown but intuitively should not be the direct sum of the rest non-zero rings. Does the fact that $B_{\alpha}\otimes_A k(\mathfrak{p})$ is a $k$-module matter here? Any hint and answers are welcomed!",,"['abstract-algebra', 'commutative-algebra']"
8,What is the classification of 1-dimensional commutative formal group laws over $\mathbb{Z}$ up to isomorphism?,What is the classification of 1-dimensional commutative formal group laws over  up to isomorphism?,\mathbb{Z},"All 1-dimensional commutative formal group laws over a field $k$ of characteristic $\geq$ 0 are classified up to isomorphism by the characteristic of $k$ and their height. This is result of Michel Lazard. Additionally, all 1-d commutative formal group laws over $\mathbb{Q}$ are isomorphic. What is known about the classification of 1-dimensional commutative formal group laws over rings of characteristic 0?","All 1-dimensional commutative formal group laws over a field $k$ of characteristic $\geq$ 0 are classified up to isomorphism by the characteristic of $k$ and their height. This is result of Michel Lazard. Additionally, all 1-d commutative formal group laws over $\mathbb{Q}$ are isomorphic. What is known about the classification of 1-dimensional commutative formal group laws over rings of characteristic 0?",,"['abstract-algebra', 'algebraic-geometry', 'algebraic-topology', 'formal-groups']"
9,"$(\mathbb{Q},+)$ has no maximal subgroup.",has no maximal subgroup.,"(\mathbb{Q},+)","Definition. A maximal subgroup of a group G is a proper subgroup $M$ of $G$ such that there are no subgroup $H$ of $G$ such that $M<H<G$. Now, I want to solve the following problem: Problem: $(\mathbb{Q},+)$ has no maximal subgroup. There are solutions available here . But I find these hard to me...So I try to solve this own... My Solution: Suppose that $M$ be a maximal subgroup of $(\mathbb{Q},+)$. Then by Fourth Isomorphism Theorem the subgroups of $\mathbb{Q}/M$ are only $\{0\}$ and $\mathbb{Q}/M$. And then $\mathbb{Q}/M$ must be a finite group, Since it can be proved that A group is finite if and only if it has finite number of subgroups ( See here ).  Therefore $[\mathbb{Q}:M]=|\mathbb{Q}/M|<\infty$. Therefore $M$ becomes a proper subgroup of finite index of $(\mathbb{Q},+)$, and which, we know, is not possible. (*because, $(\mathbb{Q},+)$ has no proper subgroup of finite index). Hence we get a contradiction. *Theorem. $(\mathbb{Q},+)$ has no proper subgroup of finite index Proof: Suppose $H \le \mathbb{Q}$ such that $[\mathbb{Q}:H]=|\mathbb{Q}/H|=n$ (say) Now let $q \in \mathbb{Q}$. Then $(q+H)^n=H$ i.e. $nq+H=H$ i.e., $nq \in H$. Since $q$ is arbitrary in $\mathbb{Q}$ so this means $n\mathbb{Q} \subset H$. But look $n\mathbb{Q}=\mathbb{Q}$, since $q \mapsto nq$ is an automorphism of $\mathbb{Q}$. Hence $H=\mathbb{Q}$. Is this solution correct? Thank you..","Definition. A maximal subgroup of a group G is a proper subgroup $M$ of $G$ such that there are no subgroup $H$ of $G$ such that $M<H<G$. Now, I want to solve the following problem: Problem: $(\mathbb{Q},+)$ has no maximal subgroup. There are solutions available here . But I find these hard to me...So I try to solve this own... My Solution: Suppose that $M$ be a maximal subgroup of $(\mathbb{Q},+)$. Then by Fourth Isomorphism Theorem the subgroups of $\mathbb{Q}/M$ are only $\{0\}$ and $\mathbb{Q}/M$. And then $\mathbb{Q}/M$ must be a finite group, Since it can be proved that A group is finite if and only if it has finite number of subgroups ( See here ).  Therefore $[\mathbb{Q}:M]=|\mathbb{Q}/M|<\infty$. Therefore $M$ becomes a proper subgroup of finite index of $(\mathbb{Q},+)$, and which, we know, is not possible. (*because, $(\mathbb{Q},+)$ has no proper subgroup of finite index). Hence we get a contradiction. *Theorem. $(\mathbb{Q},+)$ has no proper subgroup of finite index Proof: Suppose $H \le \mathbb{Q}$ such that $[\mathbb{Q}:H]=|\mathbb{Q}/H|=n$ (say) Now let $q \in \mathbb{Q}$. Then $(q+H)^n=H$ i.e. $nq+H=H$ i.e., $nq \in H$. Since $q$ is arbitrary in $\mathbb{Q}$ so this means $n\mathbb{Q} \subset H$. But look $n\mathbb{Q}=\mathbb{Q}$, since $q \mapsto nq$ is an automorphism of $\mathbb{Q}$. Hence $H=\mathbb{Q}$. Is this solution correct? Thank you..",,"['abstract-algebra', 'group-theory', 'proof-verification', 'maximal-subgroup']"
10,Prove that $xy=yx$,Prove that,xy=yx,"Let $(G,\cdot)$ be a group and $f,g:G\rightarrow G,f(x)=x^6,g(x)=x^{10}$ are homomorphisms, where $f$ is injective. Prove that $xy=yx$ . We know that $(xy)^{10}=x^{10}y^{10},(xy)^{6}=x^{6}y^{6},(xy)^{9}=y^{9}x^{9},(xy)^{5}=y^{5}x^{5},x^{9}y^{10}=y^{10}x^{9}$ and $x^{5}y^{6}=y^{6}x^{5}$ , but I couldn't use these results in a productive way.","Let be a group and are homomorphisms, where is injective. Prove that . We know that and , but I couldn't use these results in a productive way.","(G,\cdot) f,g:G\rightarrow G,f(x)=x^6,g(x)=x^{10} f xy=yx (xy)^{10}=x^{10}y^{10},(xy)^{6}=x^{6}y^{6},(xy)^{9}=y^{9}x^{9},(xy)^{5}=y^{5}x^{5},x^{9}y^{10}=y^{10}x^{9} x^{5}y^{6}=y^{6}x^{5}","['abstract-algebra', 'group-theory']"
11,Universal property of images in category theory,Universal property of images in category theory,,"Let $\mathcal{A}$ be an additive category with all kernels and cokernels and $f:A\to B$ a morphism. If $e:B\to \text{coker}(f)$ is the canonical epimorphism, define $\text{im}(f):=\ker(e)$ , with a canonical monomorphism $i:\text{im}(f)\to B$ . Prove that: $1)$ There is a unique $\pi:A\to\text{im}(f)$ such that $i\circ\pi=f$ $2)$ If there is a monomorphism $i':C\to B$ and a morphism $\pi':A\to C$ such that $i'\circ\pi'=f$ , then there is a unique morphism $\mu:\text{im}(f)\to C$ such that $\mu\circ\pi=\pi'$ and $i'\circ\mu=i$ . For part $1)$ , I used the fact that $e\circ f=0$ (by definition of $\text{coker(f)}$ ), so by the universal property of $\ker(e)$ , there is a unique $\pi$ such that $i\circ\pi=f$ For $2)$ , I've shown that if there is another $\mu'$ with these properties, then $i'\circ \mu=i=i'\circ \mu'$ and, since $i'$ is a monomorphism, then $\mu'=\mu$ , so $\mu$ is unique. Furthermore, assuming $i'\circ\mu=i$ , we get $i'\circ\mu\circ\pi=i\circ\pi=f=i'\circ\pi'$ and, since $i'$ is a monomorphism, $\mu\circ\pi=\pi'$ , which means we only need to find $\mu$ with $i'\circ\mu=i$ . Here is where I'm stuck, because I don't know how to come up with an arrow $\textit{leaving }\text{im}(f)$ , since the universal property of $\ker(e)$ can only give an arrow $\textit{arriving}$ at it.","Let be an additive category with all kernels and cokernels and a morphism. If is the canonical epimorphism, define , with a canonical monomorphism . Prove that: There is a unique such that If there is a monomorphism and a morphism such that , then there is a unique morphism such that and . For part , I used the fact that (by definition of ), so by the universal property of , there is a unique such that For , I've shown that if there is another with these properties, then and, since is a monomorphism, then , so is unique. Furthermore, assuming , we get and, since is a monomorphism, , which means we only need to find with . Here is where I'm stuck, because I don't know how to come up with an arrow , since the universal property of can only give an arrow at it.",\mathcal{A} f:A\to B e:B\to \text{coker}(f) \text{im}(f):=\ker(e) i:\text{im}(f)\to B 1) \pi:A\to\text{im}(f) i\circ\pi=f 2) i':C\to B \pi':A\to C i'\circ\pi'=f \mu:\text{im}(f)\to C \mu\circ\pi=\pi' i'\circ\mu=i 1) e\circ f=0 \text{coker(f)} \ker(e) \pi i\circ\pi=f 2) \mu' i'\circ \mu=i=i'\circ \mu' i' \mu'=\mu \mu i'\circ\mu=i i'\circ\mu\circ\pi=i\circ\pi=f=i'\circ\pi' i' \mu\circ\pi=\pi' \mu i'\circ\mu=i \textit{leaving }\text{im}(f) \ker(e) \textit{arriving},"['abstract-algebra', 'commutative-algebra', 'category-theory', 'additive-categories']"
12,$R$ is integrally closed in $S$ iff $R[x]$ is integrally closed in $S[x]$,is integrally closed in  iff  is integrally closed in,R S R[x] S[x],"The title is the question. The parts in bold below are where I'm stuck. This is what I've tried (much of this is just me explaining a hint I received): This comes from Eisenbud 3.17. The hint in the back of the book states: First reduce to the case where $R$ is Noetherian by passing to a   subring finitely generated over $\mathbb{Z}$. This part I'm completely lost at. After that the hint goes on to say that $f(x)\in S[x]$ is integral over $R[x]$, then $M:=R[x][f(x)]\subset S[x]$ is a finitely generated $R[x]$-module. This follows from one of the theorems in the section. Let $\text{coef}(M)$ be the submodule of $S$ generated by all coefficients of   elements of $M$. Show that $\text{coef}(M)$ is a finitely generated   $R$-module. We know that $f$ is integral so satisfies some equation: $$f(x)^n+b_{n-1}f(x)^{n-1}+\ldots+b_1f(x)+b_0=0\;\;\;\;\;b_i\in R[x]$$ This means that $M$ is finitely generated as an $R[x]$-module by $\{1,f(x),\ldots,f^n(x)\}$. From this, it's easy to see that $\text{coef}(M)$ is finitely generated. The hint goes on If $\alpha$ is the leading coefficient of $f$, show that $R[\alpha]\subset\text{coef}(M)$; it follows that $R[\alpha]$ is a finitely generated $R$-module so $\alpha$ is integral over $R$. Shouldn't this just follow since $R\subset\text{coef}(M)$ and $\alpha\in\text{coef}(M)$...? Finally, Use induction on the degree and the fact that integral elements form a ring to show that $f\in R[x]$. If $f(x)$ has degree $0$ we are done since the leading coefficient of $f$ is just a constant integral over $R$. And since $R$ is equal to its integral closure, $f\in R[x]$. Now assume $f$ has degree $n$ and the coefficients on lesser degree terms are integral in $R$. Well, the leading coefficient is integral over $R$ and all the lower coefficients are integral over $R$ by induction so all the coefficients of $f$ are integral over $R$. Since $R$ is integrally closed this implies $f(x)\in R[x]$.","The title is the question. The parts in bold below are where I'm stuck. This is what I've tried (much of this is just me explaining a hint I received): This comes from Eisenbud 3.17. The hint in the back of the book states: First reduce to the case where $R$ is Noetherian by passing to a   subring finitely generated over $\mathbb{Z}$. This part I'm completely lost at. After that the hint goes on to say that $f(x)\in S[x]$ is integral over $R[x]$, then $M:=R[x][f(x)]\subset S[x]$ is a finitely generated $R[x]$-module. This follows from one of the theorems in the section. Let $\text{coef}(M)$ be the submodule of $S$ generated by all coefficients of   elements of $M$. Show that $\text{coef}(M)$ is a finitely generated   $R$-module. We know that $f$ is integral so satisfies some equation: $$f(x)^n+b_{n-1}f(x)^{n-1}+\ldots+b_1f(x)+b_0=0\;\;\;\;\;b_i\in R[x]$$ This means that $M$ is finitely generated as an $R[x]$-module by $\{1,f(x),\ldots,f^n(x)\}$. From this, it's easy to see that $\text{coef}(M)$ is finitely generated. The hint goes on If $\alpha$ is the leading coefficient of $f$, show that $R[\alpha]\subset\text{coef}(M)$; it follows that $R[\alpha]$ is a finitely generated $R$-module so $\alpha$ is integral over $R$. Shouldn't this just follow since $R\subset\text{coef}(M)$ and $\alpha\in\text{coef}(M)$...? Finally, Use induction on the degree and the fact that integral elements form a ring to show that $f\in R[x]$. If $f(x)$ has degree $0$ we are done since the leading coefficient of $f$ is just a constant integral over $R$. And since $R$ is equal to its integral closure, $f\in R[x]$. Now assume $f$ has degree $n$ and the coefficients on lesser degree terms are integral in $R$. Well, the leading coefficient is integral over $R$ and all the lower coefficients are integral over $R$ by induction so all the coefficients of $f$ are integral over $R$. Since $R$ is integrally closed this implies $f(x)\in R[x]$.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'integral-extensions']"
13,Does product and sum rule characterize the derivative?,Does product and sum rule characterize the derivative?,,"If $F$ is a field (one can do it in any ring, but lets restrict ourselves to fields), then we can define a formal derivative of a polynomial  $$ f(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots + a_1x+a_0 \in F[x]$$ as $$ D_xf(x)=na_nx^{n-1}+(n-1)a_{n-1}x^{n-2}+\cdots+2a_2x+a_1 \in F[x].$$ With this definition, one can prove the usual rules for the derivative of the sum and product of polynomials, they are \begin{equation}\tag{1} D_x(f(x)+g(x))=D_x(f(x))+D_x(g(x)) \end{equation} and \begin{equation}\tag{2} D_x(f(x)g(x))=D_x(f(x))g(x)+D_x(g(x))f(x). \end{equation} From the product rule we can deduce that $D_x(\lambda f(x))=\lambda D_x(f(x))$ for any $\lambda \in F$ and $f(x) \in F[x],$ so the derivative is a linear map. Question I was wondering if the relations (1) and (2) does in fact characterize the formal derivative of a polynomial, at least in fields such as $\mathbb{R}$ and $\mathbb{C}$. I mean, if I have a linear map $L:\mathbb{C}[x]\to\mathbb{C}[x]$ (or $L:\mathbb{R}[x]\to\mathbb{R}[x]$) that satisfies (1) and (2), does it necessarily be the formal derivative? Also, I was wondering if this can be generalized to general linear maps between smooth functions from $\mathbb{R}^n$ to $\mathbb{R}^n$ (or from $\mathbb{R}$ to $\mathbb{R}$), so that if $L:C^{\infty}(\mathbb{R}^n) \to C^{\infty}(\mathbb{R}^n)$ is a linear map that satisfies (1) and (2), then $L$ must be the derivative. If not, I was wondering if there is some other conditions that $L$ must satisfy to guarantee that is must be the derivative. I appreciate any comments on the problem. Note: I had a little problem with the tags of this question, as I asked by formal derivative between fields but also consider the question to general linear maps between $\mathbb{R}^n$ and $\mathbb{R}^n$. I appreciate if someone could help me with the tags too.","If $F$ is a field (one can do it in any ring, but lets restrict ourselves to fields), then we can define a formal derivative of a polynomial  $$ f(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots + a_1x+a_0 \in F[x]$$ as $$ D_xf(x)=na_nx^{n-1}+(n-1)a_{n-1}x^{n-2}+\cdots+2a_2x+a_1 \in F[x].$$ With this definition, one can prove the usual rules for the derivative of the sum and product of polynomials, they are \begin{equation}\tag{1} D_x(f(x)+g(x))=D_x(f(x))+D_x(g(x)) \end{equation} and \begin{equation}\tag{2} D_x(f(x)g(x))=D_x(f(x))g(x)+D_x(g(x))f(x). \end{equation} From the product rule we can deduce that $D_x(\lambda f(x))=\lambda D_x(f(x))$ for any $\lambda \in F$ and $f(x) \in F[x],$ so the derivative is a linear map. Question I was wondering if the relations (1) and (2) does in fact characterize the formal derivative of a polynomial, at least in fields such as $\mathbb{R}$ and $\mathbb{C}$. I mean, if I have a linear map $L:\mathbb{C}[x]\to\mathbb{C}[x]$ (or $L:\mathbb{R}[x]\to\mathbb{R}[x]$) that satisfies (1) and (2), does it necessarily be the formal derivative? Also, I was wondering if this can be generalized to general linear maps between smooth functions from $\mathbb{R}^n$ to $\mathbb{R}^n$ (or from $\mathbb{R}$ to $\mathbb{R}$), so that if $L:C^{\infty}(\mathbb{R}^n) \to C^{\infty}(\mathbb{R}^n)$ is a linear map that satisfies (1) and (2), then $L$ must be the derivative. If not, I was wondering if there is some other conditions that $L$ must satisfy to guarantee that is must be the derivative. I appreciate any comments on the problem. Note: I had a little problem with the tags of this question, as I asked by formal derivative between fields but also consider the question to general linear maps between $\mathbb{R}^n$ and $\mathbb{R}^n$. I appreciate if someone could help me with the tags too.",,"['abstract-algebra', 'multivariable-calculus', 'derivatives', 'field-theory', 'linear-transformations']"
14,Associanize a magma,Associanize a magma,,"This is a thing I have been thinking on and gotten a bit frustrated so I share my thoughts here in hope for clarification. Let $M$ be a magma, that is a set with an underlying binary operation which we denote $\cdot$. The binary operation is not necessarily associative, that is we do not necessarily have  $$a\cdot (b\cdot c)=(a\cdot b)\cdot c$$ Here is the issue at hand, in group theory we can ""make"" a group abelian by taking the quotient with its commutator subgrouop, $G/[G,G]$, which is abelian, I am wondering if there is something similar for magmas but for associativity. Of course having dealt with universal algebra, semirings and semigroups (which is the target here in a way) what I need to work with is a relation, more specificly a congruence relation so I figured I would start defining it as such. So I started by saying that $e \mathrel{R} f$, or $(e,f)\in R$, if there exists some $a,b,c\in M$ such that $(a\cdot b)\cdot c = e$ and $a\cdot (b\cdot c) = f$, seemed like a good place to start for me in my quest, only that I realized that there is not necessarily a unit in a magma so we do not have $x \mathrel{R} x$ which is a requirement, well let's just throw those in too then I thought. Which is the reflexive closure of $R$, that is $\text{Cl}_\text{ref}(R)$ from before. Next I thought about transitivity which is required and I got absolutely nowhere there in my attempts primarily because I could not find anyway to proceed after setting up the equalities with elements and all. I pretty much felt it was impossible so I figured ""Let's just do the congruence closure and call it a day"" $\text{Cl}_\text{cng}(R)$. Which would of course be a congruence by the very definition but I feel it's a bit ""cheap"" so to speak. And quite frankly I am not entirely certain that it will yield satisfactory results. So the question is more ""is there a way to make a magma associative that is better than this?"".","This is a thing I have been thinking on and gotten a bit frustrated so I share my thoughts here in hope for clarification. Let $M$ be a magma, that is a set with an underlying binary operation which we denote $\cdot$. The binary operation is not necessarily associative, that is we do not necessarily have  $$a\cdot (b\cdot c)=(a\cdot b)\cdot c$$ Here is the issue at hand, in group theory we can ""make"" a group abelian by taking the quotient with its commutator subgrouop, $G/[G,G]$, which is abelian, I am wondering if there is something similar for magmas but for associativity. Of course having dealt with universal algebra, semirings and semigroups (which is the target here in a way) what I need to work with is a relation, more specificly a congruence relation so I figured I would start defining it as such. So I started by saying that $e \mathrel{R} f$, or $(e,f)\in R$, if there exists some $a,b,c\in M$ such that $(a\cdot b)\cdot c = e$ and $a\cdot (b\cdot c) = f$, seemed like a good place to start for me in my quest, only that I realized that there is not necessarily a unit in a magma so we do not have $x \mathrel{R} x$ which is a requirement, well let's just throw those in too then I thought. Which is the reflexive closure of $R$, that is $\text{Cl}_\text{ref}(R)$ from before. Next I thought about transitivity which is required and I got absolutely nowhere there in my attempts primarily because I could not find anyway to proceed after setting up the equalities with elements and all. I pretty much felt it was impossible so I figured ""Let's just do the congruence closure and call it a day"" $\text{Cl}_\text{cng}(R)$. Which would of course be a congruence by the very definition but I feel it's a bit ""cheap"" so to speak. And quite frankly I am not entirely certain that it will yield satisfactory results. So the question is more ""is there a way to make a magma associative that is better than this?"".",,"['abstract-algebra', 'relations', 'semigroups', 'magma', 'congruence-relations']"
15,Why integral domain is also called entire ring?,Why integral domain is also called entire ring?,,"I remember reading somewhere (most probably in Lang's Algebra ) that integral domain in also known by the name ""entire ring"". I was thinking that is it somehow connected with complex analysis, but unfortunately I could not figure out much. I know that if $ \Omega$ is a domain in $\mathbb C$ then $R=\{f: \Omega \to \mathbb C: f \text { is holomorphic}\}$ is an integral domain. Is it true that every integral domain can be obtained as ring of holomorphic function of some domain? Also what might be the possible reason for using the terminology 'entire ring' for integral domain?","I remember reading somewhere (most probably in Lang's Algebra ) that integral domain in also known by the name ""entire ring"". I was thinking that is it somehow connected with complex analysis, but unfortunately I could not figure out much. I know that if $ \Omega$ is a domain in $\mathbb C$ then $R=\{f: \Omega \to \mathbb C: f \text { is holomorphic}\}$ is an integral domain. Is it true that every integral domain can be obtained as ring of holomorphic function of some domain? Also what might be the possible reason for using the terminology 'entire ring' for integral domain?",,"['abstract-algebra', 'complex-analysis', 'ring-theory', 'integral-domain']"
16,An example of prime ideal $P$ such that $\bigcap_{n=1}^{\infty}P^n$ is not prime,An example of prime ideal  such that  is not prime,P \bigcap_{n=1}^{\infty}P^n,I am looking for an example of prime ideal $P$ such that $\bigcap_{n=1}^{\infty}P^n$ is not prime. In a Prüfer domain such an intersection is always a prime ideal.,I am looking for an example of prime ideal $P$ such that $\bigcap_{n=1}^{\infty}P^n$ is not prime. In a Prüfer domain such an intersection is always a prime ideal.,,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'maximal-and-prime-ideals']"
17,Can $G$ have a Sylow -5 subgroups and Sylow -3 subgroups [CSIR-NET-DEC-2015],Can  have a Sylow -5 subgroups and Sylow -3 subgroups [CSIR-NET-DEC-2015],G,"Let $G$ be a simple group of order $60$. Then $G$ has six Sylow -5 subgroups. $G$ has four Sylow -3 subgroups. $G$ has a cyclic subgroup of order 6. $G$ has a unique element of order $2$. $60=2^2.3.5$ No. of Sylow -5 subgroups =$1+5k$  divides 12.So $1+5k=1,6\implies n_5=1,6\implies n_5=6$ as $G$ is a simple group. Consider $n_3=1+3k$ divides $20\implies 1+3k=1,4,10\implies 1+3k=4,10$. If $n_3=4$ then we have $8 $ elements of order $3$ and $A_5$ has 20 elements of order $3$ which is a contradiction.Hence $n_3=10$. Since  $A_5$ has no  element  of order $6$.So 3 is false. $A_5$ has many elements of order $2$ viz. $(12)(34),(13)(24),,$. Hence $1$ is correct only .Please can someone check whether I am correct /not?","Let $G$ be a simple group of order $60$. Then $G$ has six Sylow -5 subgroups. $G$ has four Sylow -3 subgroups. $G$ has a cyclic subgroup of order 6. $G$ has a unique element of order $2$. $60=2^2.3.5$ No. of Sylow -5 subgroups =$1+5k$  divides 12.So $1+5k=1,6\implies n_5=1,6\implies n_5=6$ as $G$ is a simple group. Consider $n_3=1+3k$ divides $20\implies 1+3k=1,4,10\implies 1+3k=4,10$. If $n_3=4$ then we have $8 $ elements of order $3$ and $A_5$ has 20 elements of order $3$ which is a contradiction.Hence $n_3=10$. Since  $A_5$ has no  element  of order $6$.So 3 is false. $A_5$ has many elements of order $2$ viz. $(12)(34),(13)(24),,$. Hence $1$ is correct only .Please can someone check whether I am correct /not?",,"['abstract-algebra', 'group-theory']"
18,Are pseudoheaps and heaps the same thing?,Are pseudoheaps and heaps the same thing?,,"An exercise in a category textbook asked me to show that the category of pointed heaps and the category of groups are isomorphic. But my proof somehow didn't use the most unintuitive of the defining equations of a heap at all, i.e. $[[a,b,c],d,e] = [a,[d,c,b],e]$. According to wikipedia : Formally, a heap is an algebraic structure consisting of a non-empty set $H$ with a ternary operation denoted $[x,y,z]\in H$ that satisfies the para-associative law   $$[[a,b,c],d,e] = [a,[d,c,b],e] = [a,b,[c,d,e]] \ \forall \ a,b,c,d,e \in H$$ the identity law   $$[a,a,x] = [x,a,a] = x \ \forall \ a,x \in H.$$ A group can be regarded as a heap under the operation $[x,y,z] = xy^{-1}z$. Conversely, let $H$ be a heap, and choose an element $e \in H$. The binary operation $x*y = [x,e,y]$ makes $H$ into a group with identity $e$ and inverse  $x^{-1} = [e,x,e]$. A heap can thus be regarded as a group in which the identity has yet to be decided. But the case were $[[a,b,c],d,e] = [a,[d,c,b],e]$ is omitted seems to be called pseudoheap: A pseudoheap or pseudogroud satisfies the partial para-associative condition   $$[[a,b,c],d,e] = [a,b,[c,d,e]].$$ The Mathematical Structures repository didn't contain heaps at all. Another document document mentioning heaps defined pseudo-associative and semiheaps, but not pseudoheaps. (I think I heard of heaps before, but don't remember where anymore.) I asked automatic theorem provers whether the unintuitive equation follows from the other equations, and apparently it does: prover9: pseudoheap.in -> pseudoheap.out E-theorem prover: pseudoheap.lop -> pseudoheap.proof Was it simply a bad idea of wikipedia to mention pseudoheaps at all, because they are utterly unimportant? Did I just misinterpret the definition of pseudoheap from wikipedia? Is there some better source of information about heaps (and pseudoheaps)?","An exercise in a category textbook asked me to show that the category of pointed heaps and the category of groups are isomorphic. But my proof somehow didn't use the most unintuitive of the defining equations of a heap at all, i.e. $[[a,b,c],d,e] = [a,[d,c,b],e]$. According to wikipedia : Formally, a heap is an algebraic structure consisting of a non-empty set $H$ with a ternary operation denoted $[x,y,z]\in H$ that satisfies the para-associative law   $$[[a,b,c],d,e] = [a,[d,c,b],e] = [a,b,[c,d,e]] \ \forall \ a,b,c,d,e \in H$$ the identity law   $$[a,a,x] = [x,a,a] = x \ \forall \ a,x \in H.$$ A group can be regarded as a heap under the operation $[x,y,z] = xy^{-1}z$. Conversely, let $H$ be a heap, and choose an element $e \in H$. The binary operation $x*y = [x,e,y]$ makes $H$ into a group with identity $e$ and inverse  $x^{-1} = [e,x,e]$. A heap can thus be regarded as a group in which the identity has yet to be decided. But the case were $[[a,b,c],d,e] = [a,[d,c,b],e]$ is omitted seems to be called pseudoheap: A pseudoheap or pseudogroud satisfies the partial para-associative condition   $$[[a,b,c],d,e] = [a,b,[c,d,e]].$$ The Mathematical Structures repository didn't contain heaps at all. Another document document mentioning heaps defined pseudo-associative and semiheaps, but not pseudoheaps. (I think I heard of heaps before, but don't remember where anymore.) I asked automatic theorem provers whether the unintuitive equation follows from the other equations, and apparently it does: prover9: pseudoheap.in -> pseudoheap.out E-theorem prover: pseudoheap.lop -> pseudoheap.proof Was it simply a bad idea of wikipedia to mention pseudoheaps at all, because they are utterly unimportant? Did I just misinterpret the definition of pseudoheap from wikipedia? Is there some better source of information about heaps (and pseudoheaps)?",,"['abstract-algebra', 'group-theory', 'reference-request', 'universal-algebra']"
19,"How can we show that all the solutions are given by $X_m(a), Y_m(a)$?",How can we show that all the solutions are given by ?,"X_m(a), Y_m(a)","Let $F$ be an integral domain with characteristic $2$. Let $a\in F[t]$ and $a \notin F$. Let $\alpha (a)$ be a root of the equation $x^2+ax+1=0$. We define two sequences $X_m(a), Y_m(a) \in F[t], m \in \mathbb{Z}$ by $$X_m(a)+\alpha (a)Y_m(a)=(\alpha (a))^m=(a+\alpha (a))^{-m} \tag 1$$ Lemma. Let $F$ be an integral domain with characteristic $p=2$. Let $a \in F[t], a \notin F$. For all $m, n \in \mathbb{Z}$ we have : $X_m(a)$ (resp. $Y_m(a)$) is equal to the polynomial obtained by substituting $a$ for $t$ in $X_m(t)$ (resp. $Y_m(t)$). The degree of the polynomial $X_m(t)$ is $m-2$, if $m \geq 2$. The degree of the polynomial $Y_m(t)$ is $m-1$, if $m \geq 2$. $X_{-m}=X_m(a)+aY_m(a)$ $Y_{-m}(a)=Y_m(a)$ All solutions $X, Y \in F[t]$ of the equation $$X^2+aXY+Y^2=1\tag 2$$ are given by $X_m(a), Y_m(a)$, with $m \in \mathbb{Z}$. I want to prove this lemma but I am facing some difficulties at $2$. First I showed that $(X_m(a), Y_m(a))$ is a solution of the equation $(2)$. But how could we show that all the solutions of the equation $(2)$ are given by $X_m(a), Y_m(a)$. I have no idea how to do that... Could you give me some hints? $$$$ EDIT: At the paper that I am looking I found the corresponding lemma for the case that the characteristic is not $2$ and its proof: PROOF. $$$$ I want to try to do the same for the case $\text{char}=2$ but first I have to clarify some points at the proof above. Why do we consider the field $K=R(t)(a)$? Is $S$ the set of points at which the functions of $K$ are not defined?","Let $F$ be an integral domain with characteristic $2$. Let $a\in F[t]$ and $a \notin F$. Let $\alpha (a)$ be a root of the equation $x^2+ax+1=0$. We define two sequences $X_m(a), Y_m(a) \in F[t], m \in \mathbb{Z}$ by $$X_m(a)+\alpha (a)Y_m(a)=(\alpha (a))^m=(a+\alpha (a))^{-m} \tag 1$$ Lemma. Let $F$ be an integral domain with characteristic $p=2$. Let $a \in F[t], a \notin F$. For all $m, n \in \mathbb{Z}$ we have : $X_m(a)$ (resp. $Y_m(a)$) is equal to the polynomial obtained by substituting $a$ for $t$ in $X_m(t)$ (resp. $Y_m(t)$). The degree of the polynomial $X_m(t)$ is $m-2$, if $m \geq 2$. The degree of the polynomial $Y_m(t)$ is $m-1$, if $m \geq 2$. $X_{-m}=X_m(a)+aY_m(a)$ $Y_{-m}(a)=Y_m(a)$ All solutions $X, Y \in F[t]$ of the equation $$X^2+aXY+Y^2=1\tag 2$$ are given by $X_m(a), Y_m(a)$, with $m \in \mathbb{Z}$. I want to prove this lemma but I am facing some difficulties at $2$. First I showed that $(X_m(a), Y_m(a))$ is a solution of the equation $(2)$. But how could we show that all the solutions of the equation $(2)$ are given by $X_m(a), Y_m(a)$. I have no idea how to do that... Could you give me some hints? $$$$ EDIT: At the paper that I am looking I found the corresponding lemma for the case that the characteristic is not $2$ and its proof: PROOF. $$$$ I want to try to do the same for the case $\text{char}=2$ but first I have to clarify some points at the proof above. Why do we consider the field $K=R(t)(a)$? Is $S$ the set of points at which the functions of $K$ are not defined?",,"['abstract-algebra', 'number-theory', 'elementary-number-theory', 'integral-domain']"
20,"$A$ regular, $k'/k$ transcendental. How to prove that $A \otimes_k k'$ is regular?","regular,  transcendental. How to prove that  is regular?",A k'/k A \otimes_k k',Let $k$ be a field and $k'$ a purely transcendental extension of $k$. Let now $A$ be an integral finitely generated $k$-algebra. How to prove that if $A$ is regular then $A \otimes_k k'$ is also   regular? Thank you!,Let $k$ be a field and $k'$ a purely transcendental extension of $k$. Let now $A$ be an integral finitely generated $k$-algebra. How to prove that if $A$ is regular then $A \otimes_k k'$ is also   regular? Thank you!,,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'field-theory']"
21,"Let $G$ a finite group such that $\lvert G \rvert=pm$, with $p$ a prime and $\gcd(p,m)=1$. $G$ has an unique Sylow $p$-subgroup $P$. Prove $P\lhd G$.","Let  a finite group such that , with  a prime and .  has an unique Sylow -subgroup . Prove .","G \lvert G \rvert=pm p \gcd(p,m)=1 G p P P\lhd G","I just made this exercise, left as homework, and I'm almost sure that I did something wrong, or at least that there's a better way to solve it. Here it goes: Let $G$ a finite group such that $\lvert G \rvert=pm$, with $p$ a prime and $\gcd(p,m)=1$. Suppose that $G$ has an unique Sylow $p$-subgroup $P$. Prove that $P\trianglelefteq G$. My try: Proof: The Sylow $p$-subgroups $P$ of $G$ are, in our case, the subgroups of $G$ with order $p$. There's only one, so $\lvert P \rvert=p$. We know that, if $N_G(P)$ denotes the normaliser of $P$ in $G$, verifies this: $P\trianglelefteq N_G(P)$, because $P\leq G$. Also we know that the normaliser $P$ is exactly the centralizer of $P$, that is a subgroup of $G$. Then: \begin{equation} P\trianglelefteq N_G(P)=G_P\leq G \implies P \trianglelefteq G. \end{equation} We started Sylow today, so I used some lemmas we proved this week to make this proof, but it seems to me that there's something wrong. I would like my proof to be criticized. Thank you.","I just made this exercise, left as homework, and I'm almost sure that I did something wrong, or at least that there's a better way to solve it. Here it goes: Let $G$ a finite group such that $\lvert G \rvert=pm$, with $p$ a prime and $\gcd(p,m)=1$. Suppose that $G$ has an unique Sylow $p$-subgroup $P$. Prove that $P\trianglelefteq G$. My try: Proof: The Sylow $p$-subgroups $P$ of $G$ are, in our case, the subgroups of $G$ with order $p$. There's only one, so $\lvert P \rvert=p$. We know that, if $N_G(P)$ denotes the normaliser of $P$ in $G$, verifies this: $P\trianglelefteq N_G(P)$, because $P\leq G$. Also we know that the normaliser $P$ is exactly the centralizer of $P$, that is a subgroup of $G$. Then: \begin{equation} P\trianglelefteq N_G(P)=G_P\leq G \implies P \trianglelefteq G. \end{equation} We started Sylow today, so I used some lemmas we proved this week to make this proof, but it seems to me that there's something wrong. I would like my proof to be criticized. Thank you.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
22,$S_{n+1}$ not isomorphic to subgroup of $S_n \times S_n$,not isomorphic to subgroup of,S_{n+1} S_n \times S_n,"I've been asked to prove that there is no injective homomorphism from $S_{n+1}$ to $S_n \times S_n$ for $n\ge4$. This seems to me to follow from the fact that $S_{n+1}$ cannot be recognized as a direct product of two of its subgroups, essentially because it has only one normal subgroup.  Are there any ways to do this via order considerations, as this was my first impulse upon seeing the problem.","I've been asked to prove that there is no injective homomorphism from $S_{n+1}$ to $S_n \times S_n$ for $n\ge4$. This seems to me to follow from the fact that $S_{n+1}$ cannot be recognized as a direct product of two of its subgroups, essentially because it has only one normal subgroup.  Are there any ways to do this via order considerations, as this was my first impulse upon seeing the problem.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
23,Limits in category of cones.,Limits in category of cones.,,"I'm trying to do exercise 2.17.2 in Borceux's ""Handbook of Categorical Algebra"": Consider a functor $F: \mathfrak{D} \to \mathfrak{C}$ and the category of cones on $F$. Show that $F$ has a limit if and only if the functor $U$ from the category of cones on $F$ to $\mathfrak{C}$ mapping a cone to its vertex has a colimit. Here is what I thought, however I'm not sure if I should take a different approach or just fill the gaps in the proof.  I hope you can help me: $\Rightarrow$ If $F$ has a limit $L$ we know that  limit is a terminal object in the category of cones on $F$ .So the inclusion functor is a final functor. And we get the result. $\Leftarrow$ Now suppose $U$ has a colimit $L$, now we fix some $D \in \mathfrak{D}$ and there exists morphisms from each cone vertex to $FD$. This makes $FD$ the vertex of a cocone $\implies \exists ! ~ \alpha_D: L \to FD$. So $(L, \alpha_D)$ is a cone such that for every other cone $C_i, ~ \exists ~ h_i: C_i \to L$.  How do I prove uniqueness of the factorization? PS: I edited the first implication because I found a proposition that helped me. So i just need to finish the last one.","I'm trying to do exercise 2.17.2 in Borceux's ""Handbook of Categorical Algebra"": Consider a functor $F: \mathfrak{D} \to \mathfrak{C}$ and the category of cones on $F$. Show that $F$ has a limit if and only if the functor $U$ from the category of cones on $F$ to $\mathfrak{C}$ mapping a cone to its vertex has a colimit. Here is what I thought, however I'm not sure if I should take a different approach or just fill the gaps in the proof.  I hope you can help me: $\Rightarrow$ If $F$ has a limit $L$ we know that  limit is a terminal object in the category of cones on $F$ .So the inclusion functor is a final functor. And we get the result. $\Leftarrow$ Now suppose $U$ has a colimit $L$, now we fix some $D \in \mathfrak{D}$ and there exists morphisms from each cone vertex to $FD$. This makes $FD$ the vertex of a cocone $\implies \exists ! ~ \alpha_D: L \to FD$. So $(L, \alpha_D)$ is a cone such that for every other cone $C_i, ~ \exists ~ h_i: C_i \to L$.  How do I prove uniqueness of the factorization? PS: I edited the first implication because I found a proposition that helped me. So i just need to finish the last one.",,"['abstract-algebra', 'category-theory']"
24,"Let $G$ be a group. The inverse of $(g\cdot h)=h^{-1}\cdot g^{-1}$, with $g, h \in G$.","Let  be a group. The inverse of , with .","G (g\cdot h)=h^{-1}\cdot g^{-1} g, h \in G","If this is obvious and a silly question, I'm sorry. As a part of an exercise, I had to see that the inverse of $(g\cdot h)$, with $g$ and $h$ in a group $G$ is $h^{-1}\cdot g^{-1}$. I proved it by this way: Let $e$ be the neutral element on $G$: \begin{equation} (g\cdot h)^{-1} \cdot (g\cdot h)= e \\ \Downarrow \\(g\cdot h)^{-1} \cdot (g\cdot h)\cdot h^{-1}= e \cdot h^{-1}\\ \Downarrow\\ (g\cdot h)^{-1} \cdot g\cdot (h\cdot h^{-1})= e \cdot h^{-1} \\ \Downarrow\\ (g\cdot h)^{-1} \cdot g\cdot e= h^{-1} \\ \Downarrow \\ (g\cdot h)^{-1} \cdot g\cdot g^{-1}= h^{-1} \cdot g^{-1} \\ \Downarrow \\ (g\cdot h)^{-1} = h^{-1}\cdot g^{-1} \end{equation} Is that proof correct? Can I multiply the equation with elements of $G$ on both sides? Thank you!","If this is obvious and a silly question, I'm sorry. As a part of an exercise, I had to see that the inverse of $(g\cdot h)$, with $g$ and $h$ in a group $G$ is $h^{-1}\cdot g^{-1}$. I proved it by this way: Let $e$ be the neutral element on $G$: \begin{equation} (g\cdot h)^{-1} \cdot (g\cdot h)= e \\ \Downarrow \\(g\cdot h)^{-1} \cdot (g\cdot h)\cdot h^{-1}= e \cdot h^{-1}\\ \Downarrow\\ (g\cdot h)^{-1} \cdot g\cdot (h\cdot h^{-1})= e \cdot h^{-1} \\ \Downarrow\\ (g\cdot h)^{-1} \cdot g\cdot e= h^{-1} \\ \Downarrow \\ (g\cdot h)^{-1} \cdot g\cdot g^{-1}= h^{-1} \cdot g^{-1} \\ \Downarrow \\ (g\cdot h)^{-1} = h^{-1}\cdot g^{-1} \end{equation} Is that proof correct? Can I multiply the equation with elements of $G$ on both sides? Thank you!",,"['abstract-algebra', 'group-theory']"
25,Is annihilator of maximal submodule is a maximal ideal?,Is annihilator of maximal submodule is a maximal ideal?,,"Let $R$ be a commutative ring with identity element and $M$ is an $R$-module. We know the annihilator of a submodule $N$ of $M$ ($I=(N:M)$) is an ideal in $R$. If $N$ is a maximal submodule of $M$, is ideal $I$ (annihilator of $N$ in $M$) maximal in $R$?","Let $R$ be a commutative ring with identity element and $M$ is an $R$-module. We know the annihilator of a submodule $N$ of $M$ ($I=(N:M)$) is an ideal in $R$. If $N$ is a maximal submodule of $M$, is ideal $I$ (annihilator of $N$ in $M$) maximal in $R$?",,"['abstract-algebra', 'modules', 'maximal-and-prime-ideals']"
26,"Proof of $\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)$",Proof of,"\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)","How can we prove that $\DeclareMathOperator\Hom{Hom}\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)$ without using the fact that $\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \mathbb Z/d \mathbb Z$ and $\Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)\cong \mathbb Z/d \mathbb Z$, where $d=$ GCD$(m,n)$? It's not too hard to prove the two latest isomorphisms but it would be interesting to derive one from another using the first isomorphism.","How can we prove that $\DeclareMathOperator\Hom{Hom}\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)$ without using the fact that $\mathbb Z/n\mathbb Z\bigotimes_{\mathbb Z}\mathbb Z/m\mathbb Z \cong \mathbb Z/d \mathbb Z$ and $\Hom(\mathbb Z/n\mathbb Z, \mathbb Z/m\mathbb Z)\cong \mathbb Z/d \mathbb Z$, where $d=$ GCD$(m,n)$? It's not too hard to prove the two latest isomorphisms but it would be interesting to derive one from another using the first isomorphism.",,['abstract-algebra']
27,Cancellation of Direct Product in Grp,Cancellation of Direct Product in Grp,,"I'm thinking to the famous problem of cancellation property in Grp, i.e: $$G_1 \times G_2 \cong G_1 \times G_3 \Rightarrow G_2 \cong G_3. $$ Clearly there are many counterexamples like $\prod_{i \in \omega}\mathbb{Z}_i$ or $ \oplus_{i \in \omega}\mathbb{Z}_i$ but these counterexamples can be bypassed by giving a definition. We say that a group G is $\Pi$-compact iff $$G \cong \prod_{i\in I}G_i, \  G_i \neq \{e\} \ \Rightarrow |I| < \infty.$$ We say that a group G is $\Sigma$-compact iff $$G \cong \oplus_{i\in I}G_i, \  G_i \neq \{e\} \ \Rightarrow |I| < \infty.$$ We say that a group is $\times$-compact iff it's $\Pi$ and $\Sigma$ compact. I've been working on many conjectures and with Seirios' help many of them have been solved. I'll tick ($\checkmark$) proved ones and refuse ($\neg$) false ones. $$\checkmark? \ \ \ \ \ \  \ \  G_1,G_2 \times\text{-compact} \Rightarrow G_1 \times G_2 \times\text{-compact}  $$ $$\checkmark \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \   G \text{ finitely generated} \Rightarrow G \times\text{-compact} $$ $$\neg \ \ \ \ \ \  \ \ \ \  \ \ \ \ H <G, G \times\text{-compact}  \Rightarrow H \times\text{-compact}   $$ $$\neg \ \ H \triangleleft G, \ \ \ \  H,G \times\text{-compact}  \Rightarrow G/H \times\text{-compact}   $$  $$\neg \ \ \ \ \ G \times\text{-compact} \Rightarrow \text{cancellation property holds}.$$ What's clearly true is that: finite groups are $\times$-compact (and I've seen on the web that cancellation property holds for them), simple groups are $\times$-compact, free groups are $\times$-compact . Applying $(3) \wedge (4)$ on free groups we may get (2) but $(3) \wedge (4)$ have to be false because any group is quotient of a free group. $$ \neg ( (3) \wedge (4)).$$ As Seirios has observed for countable groups it holds that $\times$-compact $\Leftrightarrow$ $\Sigma$-compact. Again Seirios noted, here is proved that cancellation is not true for finitely presented groups so if (2) is true (5) is false. $$ (2) \Rightarrow \neg (5)  $$ Seirios proved (2) here . A sketch of proof for (1). Let's assume that $G_1 \times G_2$ is not $\times$-compact. So $G_1 \times G_2 \cong \prod_{i\in \nu}P_i$. Let's call $\pi_1$ projection on first coordinate. So $G_1\cong \pi_1 (G_1 \times G_2) \cong \pi_1(\prod P_i) \cong \prod (\pi_1 P_i)$ so finitely many $P_i$ are not in $\{0\} \times G_2$. Same argument on the other side rise to absurd $\square.$ Is this correct? I have a counterexample for (4). Let's consider $G:=*_{i \in \omega}\mathbb{Z}_i$ Since it's free it's $\times$-compact. Its commutator [G,G] is $\times$-compact but quotient $$G/[G,G] \cong \oplus_{i \in \omega} \mathbb{Z} $$ which is not $\times$-compact. $$ \neg (4) .$$ Since this $$(2) \Rightarrow \neg (3).$$ News : None.","I'm thinking to the famous problem of cancellation property in Grp, i.e: $$G_1 \times G_2 \cong G_1 \times G_3 \Rightarrow G_2 \cong G_3. $$ Clearly there are many counterexamples like $\prod_{i \in \omega}\mathbb{Z}_i$ or $ \oplus_{i \in \omega}\mathbb{Z}_i$ but these counterexamples can be bypassed by giving a definition. We say that a group G is $\Pi$-compact iff $$G \cong \prod_{i\in I}G_i, \  G_i \neq \{e\} \ \Rightarrow |I| < \infty.$$ We say that a group G is $\Sigma$-compact iff $$G \cong \oplus_{i\in I}G_i, \  G_i \neq \{e\} \ \Rightarrow |I| < \infty.$$ We say that a group is $\times$-compact iff it's $\Pi$ and $\Sigma$ compact. I've been working on many conjectures and with Seirios' help many of them have been solved. I'll tick ($\checkmark$) proved ones and refuse ($\neg$) false ones. $$\checkmark? \ \ \ \ \ \  \ \  G_1,G_2 \times\text{-compact} \Rightarrow G_1 \times G_2 \times\text{-compact}  $$ $$\checkmark \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \   G \text{ finitely generated} \Rightarrow G \times\text{-compact} $$ $$\neg \ \ \ \ \ \  \ \ \ \  \ \ \ \ H <G, G \times\text{-compact}  \Rightarrow H \times\text{-compact}   $$ $$\neg \ \ H \triangleleft G, \ \ \ \  H,G \times\text{-compact}  \Rightarrow G/H \times\text{-compact}   $$  $$\neg \ \ \ \ \ G \times\text{-compact} \Rightarrow \text{cancellation property holds}.$$ What's clearly true is that: finite groups are $\times$-compact (and I've seen on the web that cancellation property holds for them), simple groups are $\times$-compact, free groups are $\times$-compact . Applying $(3) \wedge (4)$ on free groups we may get (2) but $(3) \wedge (4)$ have to be false because any group is quotient of a free group. $$ \neg ( (3) \wedge (4)).$$ As Seirios has observed for countable groups it holds that $\times$-compact $\Leftrightarrow$ $\Sigma$-compact. Again Seirios noted, here is proved that cancellation is not true for finitely presented groups so if (2) is true (5) is false. $$ (2) \Rightarrow \neg (5)  $$ Seirios proved (2) here . A sketch of proof for (1). Let's assume that $G_1 \times G_2$ is not $\times$-compact. So $G_1 \times G_2 \cong \prod_{i\in \nu}P_i$. Let's call $\pi_1$ projection on first coordinate. So $G_1\cong \pi_1 (G_1 \times G_2) \cong \pi_1(\prod P_i) \cong \prod (\pi_1 P_i)$ so finitely many $P_i$ are not in $\{0\} \times G_2$. Same argument on the other side rise to absurd $\square.$ Is this correct? I have a counterexample for (4). Let's consider $G:=*_{i \in \omega}\mathbb{Z}_i$ Since it's free it's $\times$-compact. Its commutator [G,G] is $\times$-compact but quotient $$G/[G,G] \cong \oplus_{i \in \omega} \mathbb{Z} $$ which is not $\times$-compact. $$ \neg (4) .$$ Since this $$(2) \Rightarrow \neg (3).$$ News : None.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
28,A group indecomposability question.,A group indecomposability question.,,"Pretty sure it is impossible if everything is finite, $|G_i|$ must be a prime or a power of a prime, then either LHS and RHS have different group sizes or they have different number of elements of a particular order. I just don't know about the infinity case, feels like it might not be true for some special case. Need help please.","Pretty sure it is impossible if everything is finite, $|G_i|$ must be a prime or a power of a prime, then either LHS and RHS have different group sizes or they have different number of elements of a particular order. I just don't know about the infinity case, feels like it might not be true for some special case. Need help please.",,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
29,"XOR is commutative, associative, and its own inverse. Are there any other such functions?","XOR is commutative, associative, and its own inverse. Are there any other such functions?",,"In particular, I was musing on this trick for swapping two values in a program without allocating any new variables. Wikipedia proves its correctness , and the proof picqued my curiosity. It relies on the following four properties of XOR: Commutativity: $A \oplus B = B \oplus A$ Associativity: $(A \oplus B) \oplus C = A \oplus (B \oplus C)$ Identity exists: there is a bit string, 0, (of length N) such that $A \oplus 0 = A$ for any $A$ Each element is its own inverse: for each $A$, $A \oplus A = 0$. I suspect that it'd be trivial to construct another group for which those four properties of XOR hold, so I'm not interested in the assertion that other such groups exist . Instead, I ask: Are there any other functions over bit strings that satisfy these same properties? If so, what are some examples? If not, can we prove that? (For example, my first thought was $|x - y|$ while interpreting the binary strings as integers, which satisfies commutativity, identity existence, and each element being its own inverse, but not associativity.)","In particular, I was musing on this trick for swapping two values in a program without allocating any new variables. Wikipedia proves its correctness , and the proof picqued my curiosity. It relies on the following four properties of XOR: Commutativity: $A \oplus B = B \oplus A$ Associativity: $(A \oplus B) \oplus C = A \oplus (B \oplus C)$ Identity exists: there is a bit string, 0, (of length N) such that $A \oplus 0 = A$ for any $A$ Each element is its own inverse: for each $A$, $A \oplus A = 0$. I suspect that it'd be trivial to construct another group for which those four properties of XOR hold, so I'm not interested in the assertion that other such groups exist . Instead, I ask: Are there any other functions over bit strings that satisfy these same properties? If so, what are some examples? If not, can we prove that? (For example, my first thought was $|x - y|$ while interpreting the binary strings as integers, which satisfies commutativity, identity existence, and each element being its own inverse, but not associativity.)",,['abstract-algebra']
30,Dummit and Foote as a First Text in Abstract Algebra,Dummit and Foote as a First Text in Abstract Algebra,,"I'm wondering how Dummit and Foote (3rd ed.) would fair as a first text in Abstract Algebra. I've researched this question  on this site, and found a few opinions, which conflicted. Some people said it is better as a reference text, or something to read after one has a fair deal of exposure to the main ideas of abstract algebra, while others have said it is fine for a beginner. Is a text such as Herstein's Topics in Algebra , Artin's Algebra , or Fraleigh's A First Course in Algebra a better choice? Here's a summary of the parts of my mathematical background that I presume are relevant. I've covered most of Spivak's famed Calculus text (in particular the section on fields, constructing $\mathbf{R}$ from $\mathbf{Q}$, and showing the uniqueness of $\mathbf{R}$ which is probably the most relevant to abstract algebra) so I am totally comfortable with rigorous proofs. I also have a solid knowledge of elementary number theory; the parts that I guess are most relevant to abstract algebra are that I have done some work with modular arithmetic (up to proving fundamental results like Euler's Theorem and the Law of Quadratic Reciprocity), the multiplicative group $(\mathbf{Z}/n\mathbf{Z})^{\times}$ (e.g. which ones are cyclic), polynomial rings such as $\mathbf{Z}[x],$ and studying the division algorithm and unique factorization in $\mathbf{Z}[\sqrt{d}]$ (for $d \in \mathbf{Z}$). I have only a little bit of experience with linear algebra (about the first 30 pages or so of Halmos' Finite Dimensional Vector Spaces and a little bit of computational knowledge with matrices) though. With this said, I don't have much exposure to actual abstract algebra. I know what a group, ring, field, and vector space are but I haven't worked much with these structures (i.e. I can give a definition, but I have little intuition and only small lists of examples). I have no doubt that Dummit and Foote is comprehensive enough for my purposes (I hope to use it mostly for the sections on group theory, ring theory, and Galois Theory), but is it a good text for building intuition and lists of examples in abstract algebra for someone who has basically none of this? Will I, more than just learning theorems and basic techniques, develop a more abstract and intuitive understanding of the fundamental structures (groups, rings, modules, etc.)? It is a very large and supposedly dense text, so will the grand ""picture"" of group theory, for example, be lost? I've heard it is a book for people who have some basic intuition in group and ring theory, and I hesitate to put myself in this category given my description of my relevant knowledge in the paragraph above. Do you think the text is right for me, or would I be more successful with one of the three texts I mentioned in the first paragraph? Thanks for reading this (lengthy) question. I look forward to your advice!","I'm wondering how Dummit and Foote (3rd ed.) would fair as a first text in Abstract Algebra. I've researched this question  on this site, and found a few opinions, which conflicted. Some people said it is better as a reference text, or something to read after one has a fair deal of exposure to the main ideas of abstract algebra, while others have said it is fine for a beginner. Is a text such as Herstein's Topics in Algebra , Artin's Algebra , or Fraleigh's A First Course in Algebra a better choice? Here's a summary of the parts of my mathematical background that I presume are relevant. I've covered most of Spivak's famed Calculus text (in particular the section on fields, constructing $\mathbf{R}$ from $\mathbf{Q}$, and showing the uniqueness of $\mathbf{R}$ which is probably the most relevant to abstract algebra) so I am totally comfortable with rigorous proofs. I also have a solid knowledge of elementary number theory; the parts that I guess are most relevant to abstract algebra are that I have done some work with modular arithmetic (up to proving fundamental results like Euler's Theorem and the Law of Quadratic Reciprocity), the multiplicative group $(\mathbf{Z}/n\mathbf{Z})^{\times}$ (e.g. which ones are cyclic), polynomial rings such as $\mathbf{Z}[x],$ and studying the division algorithm and unique factorization in $\mathbf{Z}[\sqrt{d}]$ (for $d \in \mathbf{Z}$). I have only a little bit of experience with linear algebra (about the first 30 pages or so of Halmos' Finite Dimensional Vector Spaces and a little bit of computational knowledge with matrices) though. With this said, I don't have much exposure to actual abstract algebra. I know what a group, ring, field, and vector space are but I haven't worked much with these structures (i.e. I can give a definition, but I have little intuition and only small lists of examples). I have no doubt that Dummit and Foote is comprehensive enough for my purposes (I hope to use it mostly for the sections on group theory, ring theory, and Galois Theory), but is it a good text for building intuition and lists of examples in abstract algebra for someone who has basically none of this? Will I, more than just learning theorems and basic techniques, develop a more abstract and intuitive understanding of the fundamental structures (groups, rings, modules, etc.)? It is a very large and supposedly dense text, so will the grand ""picture"" of group theory, for example, be lost? I've heard it is a book for people who have some basic intuition in group and ring theory, and I hesitate to put myself in this category given my description of my relevant knowledge in the paragraph above. Do you think the text is right for me, or would I be more successful with one of the three texts I mentioned in the first paragraph? Thanks for reading this (lengthy) question. I look forward to your advice!",,"['abstract-algebra', 'reference-request', 'book-recommendation']"
31,Describe all the quotient groups of $\mathbb{Z} \oplus \mathbb{Z}$,Describe all the quotient groups of,\mathbb{Z} \oplus \mathbb{Z},"I'm thinking about a problem in algebraic topology of how to determine all the $k$-fold covers of $\mathbb{T}^2$, where $k$ is a certain integer. In thinking about the problem, I came upon the following question: It's clear that every homomorphism $\phi:\mathbb{Z} \oplus \mathbb{Z} \to \mathbb{Z} \oplus \mathbb{Z}$ can be represented by a $2\times 2$ matrix over the integers (i.e. $\phi = \begin{pmatrix} a & b \\ c& d \end{pmatrix}$ where $a,b,c,d \in \mathbb{Z}$). If $\phi$ has a kernel, can we necessarily say that the quotient group $\mathbb{Z} \oplus \mathbb{Z} / \ker(\phi)$ has the form $\mathbb{Z}_m \oplus \mathbb{Z}_n$, where $m$ and $n$ are some integers? If not, can we still nicely represent all the quotient groups of $\mathbb{Z} \oplus \mathbb{Z} / \ker(\phi)$, where $\phi: \mathbb{Z} \oplus \mathbb{Z} \to \mathbb{Z} \oplus \mathbb{Z}$? Moreover, how does the matrix representation of $\phi$ relate to the quotient groups? For example, does the determinant of the matrix give you all or most of the information you need to find the quotient groups? My motivation in considering this is, as I mentioned, $k$-fold covers of $\mathbb{T}^2$. The fundamental group of $\mathbb{T}^2$ is of course $\mathbb{Z} \oplus \mathbb{Z}$. I want to relate the determinant of $\phi$ to how many times a covering map covers $\mathbb{T}^2$. For example, a $k$-fold cover $p: \mathbb{T}^2 \to \mathbb{T}^2$ would have $\det(p_\star) = k$. Where $p_\star: \pi_1(\mathbb{T}^2) \to \pi_1(\mathbb{T}^2)$ is the induced homomorphism . I'm not sure that this is true, but it motivated my question. Thanks for your help!","I'm thinking about a problem in algebraic topology of how to determine all the $k$-fold covers of $\mathbb{T}^2$, where $k$ is a certain integer. In thinking about the problem, I came upon the following question: It's clear that every homomorphism $\phi:\mathbb{Z} \oplus \mathbb{Z} \to \mathbb{Z} \oplus \mathbb{Z}$ can be represented by a $2\times 2$ matrix over the integers (i.e. $\phi = \begin{pmatrix} a & b \\ c& d \end{pmatrix}$ where $a,b,c,d \in \mathbb{Z}$). If $\phi$ has a kernel, can we necessarily say that the quotient group $\mathbb{Z} \oplus \mathbb{Z} / \ker(\phi)$ has the form $\mathbb{Z}_m \oplus \mathbb{Z}_n$, where $m$ and $n$ are some integers? If not, can we still nicely represent all the quotient groups of $\mathbb{Z} \oplus \mathbb{Z} / \ker(\phi)$, where $\phi: \mathbb{Z} \oplus \mathbb{Z} \to \mathbb{Z} \oplus \mathbb{Z}$? Moreover, how does the matrix representation of $\phi$ relate to the quotient groups? For example, does the determinant of the matrix give you all or most of the information you need to find the quotient groups? My motivation in considering this is, as I mentioned, $k$-fold covers of $\mathbb{T}^2$. The fundamental group of $\mathbb{T}^2$ is of course $\mathbb{Z} \oplus \mathbb{Z}$. I want to relate the determinant of $\phi$ to how many times a covering map covers $\mathbb{T}^2$. For example, a $k$-fold cover $p: \mathbb{T}^2 \to \mathbb{T}^2$ would have $\det(p_\star) = k$. Where $p_\star: \pi_1(\mathbb{T}^2) \to \pi_1(\mathbb{T}^2)$ is the induced homomorphism . I'm not sure that this is true, but it motivated my question. Thanks for your help!",,"['abstract-algebra', 'matrices', 'algebraic-topology', 'modules']"
32,Groups of order $pq$ have a proper normal subgroup,Groups of order  have a proper normal subgroup,pq,"I am doing the following exercise from [Birkhoff and MacLane, A survey of modern algebra]: Let $G$ be a group of order $pq$ ($p,q$ primes).  Show that either $G$ is cyclic or contains an element of order $p$ (or $q$).  In the second case, show that $G$ contains either $1$ normal or $q$ conjugate subgroups of order $p$.  In the latter case the $pq-(p-1)q=q$ elements not of order $p$ form a normal subgroup.  Infer that $G$ always has a proper normal subgroup. I think I was able to prove $G$ has a proper normal subgroup, but without quite establishing that the number of subgroups of order $p$ is 1 or $q$. Here is my solution: Suppose $G$ is cyclic and $G=\langle x \rangle$.  Then, $\langle x^p \rangle$ has order $q$ and is normal, so we are done.  So suppose $G$ is not cyclic.  Let $x \in G-1$.  By Lagrange's theorem, the order of $x$ is $p$, say.  Let $H:=\langle x \rangle$.  $G$ acts on all subgroups of order $p$ by conjugation.  In this action, the stabilizer of $H$ is the normalizer $N_G(H)$.  Since $N_G(H) \supseteq H$, $|N_G(H)|$ equals $p$ or $qp$.  Hence the orbit containing $H$ has length $q$ or 1 (by the orbit-stabilizer lemma).  If this value is 1, then $H$ is normal, so we are done.  If this value is $q$, then there are $pq-(p-1)q=q$ remaining nonidentity elements in $G$ that are not in any conjugate of $H$. Case 1: If any of these $q$ elements, say some $y \in G$, has order $p$, then $K:=\langle y \rangle$ is either normal (so we are done) or has $q$ conjugate subgroups (in which case the conjugates of $H$ and of $K$ together contain $q(p-1)+q(p-1)+1>qp$ elements, a contradiction). Case 2:  If none of the $q$ elements has order $p$, then they all have order 1 or $q$, and hence form a cyclic subgroup $K$ of order $q$.  $K$ must be normal, since otherwise $g^{-1}Kg \ne K$ for some $g \in G$, whereas $K$ already exhausted all the elements of $G$ of order $q$. Thus, $G$ has a normal subgroup of order $p$ or $q$. While I have shown the group is not simple, I think I haven't shown yet that the number of subgroups of order $p$ is 1 or $q$.  The proof only establishes that the number of distinct conjugates of $H$ is 1 or $q$.  Any suggestions on how to prove (using elementary methods) that any other subgroup of order $p$ would have to be conjugate to $H$? In other words, I need to rule out Case 1 in the proof.","I am doing the following exercise from [Birkhoff and MacLane, A survey of modern algebra]: Let $G$ be a group of order $pq$ ($p,q$ primes).  Show that either $G$ is cyclic or contains an element of order $p$ (or $q$).  In the second case, show that $G$ contains either $1$ normal or $q$ conjugate subgroups of order $p$.  In the latter case the $pq-(p-1)q=q$ elements not of order $p$ form a normal subgroup.  Infer that $G$ always has a proper normal subgroup. I think I was able to prove $G$ has a proper normal subgroup, but without quite establishing that the number of subgroups of order $p$ is 1 or $q$. Here is my solution: Suppose $G$ is cyclic and $G=\langle x \rangle$.  Then, $\langle x^p \rangle$ has order $q$ and is normal, so we are done.  So suppose $G$ is not cyclic.  Let $x \in G-1$.  By Lagrange's theorem, the order of $x$ is $p$, say.  Let $H:=\langle x \rangle$.  $G$ acts on all subgroups of order $p$ by conjugation.  In this action, the stabilizer of $H$ is the normalizer $N_G(H)$.  Since $N_G(H) \supseteq H$, $|N_G(H)|$ equals $p$ or $qp$.  Hence the orbit containing $H$ has length $q$ or 1 (by the orbit-stabilizer lemma).  If this value is 1, then $H$ is normal, so we are done.  If this value is $q$, then there are $pq-(p-1)q=q$ remaining nonidentity elements in $G$ that are not in any conjugate of $H$. Case 1: If any of these $q$ elements, say some $y \in G$, has order $p$, then $K:=\langle y \rangle$ is either normal (so we are done) or has $q$ conjugate subgroups (in which case the conjugates of $H$ and of $K$ together contain $q(p-1)+q(p-1)+1>qp$ elements, a contradiction). Case 2:  If none of the $q$ elements has order $p$, then they all have order 1 or $q$, and hence form a cyclic subgroup $K$ of order $q$.  $K$ must be normal, since otherwise $g^{-1}Kg \ne K$ for some $g \in G$, whereas $K$ already exhausted all the elements of $G$ of order $q$. Thus, $G$ has a normal subgroup of order $p$ or $q$. While I have shown the group is not simple, I think I haven't shown yet that the number of subgroups of order $p$ is 1 or $q$.  The proof only establishes that the number of distinct conjugates of $H$ is 1 or $q$.  Any suggestions on how to prove (using elementary methods) that any other subgroup of order $p$ would have to be conjugate to $H$? In other words, I need to rule out Case 1 in the proof.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
33,$(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ is a cyclic group,is a cyclic group,(\mathbb{Z}/p^r\mathbb{Z})^{\ast},"I would like to prove that the group $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ of the invertible elements of $\mathbb{Z}/p^r\mathbb{Z}$ with $p>2$ prime and $r>0$ is cyclic. My text suggests to start proving that the kernel $W$ of the canonical  homomorphism  $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}\to(\mathbb{Z}/p\mathbb{Z})^{\ast}$ is a cyclic group by verifying that $1+p$ has order $p^{r-1}$ in $W$. I suppose, but I am not sure, that the said canonical homomorphism might be the projection $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}\to(\mathbb{Z}/p\mathbb{Z})^{\ast}:a\mapsto\bar{a}$, and I would say that the kernel of the map   is $\{\bar{1}, \overline{1+p},\overline{1+2p}...,\overline{1+(p^{r-1}-1)p}\}$, so it has order $p^{r-1}$ (and therefore if the group generated by $1+p$ has the same order, it must be the kernel itself). But I haven't been able to prove that $p^{r-1}$ is the least natural number $m$ such that $(\overline{1+p})^{m}=\bar{1}$... Furthermore, once proved that $W\subset(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ is cyclic, I don't know how to see that $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ is cyclic too... Has anybody got any ideas? I $\infty$-ly thank you in advance!!!","I would like to prove that the group $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ of the invertible elements of $\mathbb{Z}/p^r\mathbb{Z}$ with $p>2$ prime and $r>0$ is cyclic. My text suggests to start proving that the kernel $W$ of the canonical  homomorphism  $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}\to(\mathbb{Z}/p\mathbb{Z})^{\ast}$ is a cyclic group by verifying that $1+p$ has order $p^{r-1}$ in $W$. I suppose, but I am not sure, that the said canonical homomorphism might be the projection $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}\to(\mathbb{Z}/p\mathbb{Z})^{\ast}:a\mapsto\bar{a}$, and I would say that the kernel of the map   is $\{\bar{1}, \overline{1+p},\overline{1+2p}...,\overline{1+(p^{r-1}-1)p}\}$, so it has order $p^{r-1}$ (and therefore if the group generated by $1+p$ has the same order, it must be the kernel itself). But I haven't been able to prove that $p^{r-1}$ is the least natural number $m$ such that $(\overline{1+p})^{m}=\bar{1}$... Furthermore, once proved that $W\subset(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ is cyclic, I don't know how to see that $(\mathbb{Z}/p^r\mathbb{Z})^{\ast}$ is cyclic too... Has anybody got any ideas? I $\infty$-ly thank you in advance!!!",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups', 'cyclic-groups']"
34,Properties of squares in $\mathbb Q_p$,Properties of squares in,\mathbb Q_p,"Let $\mathbb Q_p$ be the field of $p$-adic numbers. I know that for $p \neq 2$ an element $x=p^n u \in \mathbb Q_p^\times$ (with $n \in \mathbb Z$ and $u \in \mathbb Z_p^\times$) is a square if and only if $n$ is even and the image $\overline{u}$ of $u$ in $\mathbb F_p^\times$ (by the homomorphism $\mathbb Z_p \to \mathbb Z_p / p \mathbb Z_p \cong \mathbb F_p$) is a square. And for the prime number $p=2$ I know that an element $x=p^n u \in \mathbb Q_2^\times$ is a square if and only if $n$ is even and $u \equiv 1 \pmod 8$. Now, how to prove that for $p \neq 2$ the quotient group $\mathbb Q_p^\times /  \mathbb Q_p^{\times^2}$ is isomorphic to the group $\mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z$ and that $\left \{ 1,p,u,up \right \}$ is a system of representatives, where $u \in \mathbb Z_p^\times$ is such that $\left ( \frac{u}{p} \right )=-1 $? And that $\mathbb Q_2^\times /  \mathbb Q_2^{\times^2}$ is isomorphic to the group $\mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z$ and that $\left \{ \pm 1,\pm 5,\pm 2,\pm 10 \right \}$ is a system of representatives?","Let $\mathbb Q_p$ be the field of $p$-adic numbers. I know that for $p \neq 2$ an element $x=p^n u \in \mathbb Q_p^\times$ (with $n \in \mathbb Z$ and $u \in \mathbb Z_p^\times$) is a square if and only if $n$ is even and the image $\overline{u}$ of $u$ in $\mathbb F_p^\times$ (by the homomorphism $\mathbb Z_p \to \mathbb Z_p / p \mathbb Z_p \cong \mathbb F_p$) is a square. And for the prime number $p=2$ I know that an element $x=p^n u \in \mathbb Q_2^\times$ is a square if and only if $n$ is even and $u \equiv 1 \pmod 8$. Now, how to prove that for $p \neq 2$ the quotient group $\mathbb Q_p^\times /  \mathbb Q_p^{\times^2}$ is isomorphic to the group $\mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z$ and that $\left \{ 1,p,u,up \right \}$ is a system of representatives, where $u \in \mathbb Z_p^\times$ is such that $\left ( \frac{u}{p} \right )=-1 $? And that $\mathbb Q_2^\times /  \mathbb Q_2^{\times^2}$ is isomorphic to the group $\mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z \times \mathbb Z / 2\mathbb Z$ and that $\left \{ \pm 1,\pm 5,\pm 2,\pm 10 \right \}$ is a system of representatives?",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory', 'p-adic-number-theory']"
35,The size of commuting subset of a Group.,The size of commuting subset of a Group.,,"Let $G$ be a group such that if $H$ is a subset of $G\setminus Z(G)$ and any two element of $H$ commute, then $H$ is finite. Is it true that the set of all the sizes of such $H$ has a maximum element? Thanks in advance.","Let $G$ be a group such that if $H$ is a subset of $G\setminus Z(G)$ and any two element of $H$ commute, then $H$ is finite. Is it true that the set of all the sizes of such $H$ has a maximum element? Thanks in advance.",,"['abstract-algebra', 'group-theory']"
36,Computing Sylow $p$-subgroups of classical groups,Computing Sylow -subgroups of classical groups,p,"Let $p>4$ be prime, and let $G=GL_2(\mathbb{F}_p)$, $H=O_3(\mathbb{F}_p)$, and $K=Sp_4(\mathbb{F}_p)$. We know that $|G|=p(p-1)^2(p+1)$, so that a Sylow $p$-subgroup of $G$ is isomorphic to $\mathbb{Z}/p\mathbb{Z}$.  In fact, there are $p+1$ such subgroups.  Can we write down a generator for each one? We also know that $|H|=2p(p+1)(p-1)$, so that a Sylow $p$-subgroup of $H$ is isomorphic to $\mathbb{Z}/p\mathbb{Z}$.  Are there also $p+1$ such subgroups, and can we write down generators? Finally, we know that $|K|=p^4(p-1)^2(p+1)^2(p^2+1)$.  What is the isomorphism class of a Sylow $p$-subgroup of $K$, how many are there, and can we write down generators and relations? I remember I solved the first question, involving $G$, but the solution escapes me at the moment.  The other two are standard extensions of the first problem that I am also interested in. Any reference and/or partial solution is appreciated.  Thanks! Edit: To address the comments, I would like to be able to explicitly write down matrices that generate the subgroups, one for each subgroup.  As noted by Tobias, the matrix: $$\begin{pmatrix}1&a\\0&1\end{pmatrix}$$ for $a\ne 0$, generates one Sylow $p$-subgroup of $G$, so I'd like to find $p$ more matrices of order $p$ that generate distinct subgroups.  These matrices should be indexed by our field $\mathbb{F}_p$.  They are certain to be conjugates of the above matrix, but two arbitrary conjugates may generate the same subgroup. Edit 2: I've just solved the question for $G$.  Here is a list of generators for the $p+1$ Sylow $p$-subgroups of $G$: $$\begin{pmatrix}1&1\\0&1\end{pmatrix},\;\begin{pmatrix}1&0\\1&1\end{pmatrix},\;\begin{pmatrix}2&a\\-a^{-1}&0\end{pmatrix}$$ where $a=1,\ldots,p-1$.  Each matrix has order $p$, and generates a distinct subgroup.","Let $p>4$ be prime, and let $G=GL_2(\mathbb{F}_p)$, $H=O_3(\mathbb{F}_p)$, and $K=Sp_4(\mathbb{F}_p)$. We know that $|G|=p(p-1)^2(p+1)$, so that a Sylow $p$-subgroup of $G$ is isomorphic to $\mathbb{Z}/p\mathbb{Z}$.  In fact, there are $p+1$ such subgroups.  Can we write down a generator for each one? We also know that $|H|=2p(p+1)(p-1)$, so that a Sylow $p$-subgroup of $H$ is isomorphic to $\mathbb{Z}/p\mathbb{Z}$.  Are there also $p+1$ such subgroups, and can we write down generators? Finally, we know that $|K|=p^4(p-1)^2(p+1)^2(p^2+1)$.  What is the isomorphism class of a Sylow $p$-subgroup of $K$, how many are there, and can we write down generators and relations? I remember I solved the first question, involving $G$, but the solution escapes me at the moment.  The other two are standard extensions of the first problem that I am also interested in. Any reference and/or partial solution is appreciated.  Thanks! Edit: To address the comments, I would like to be able to explicitly write down matrices that generate the subgroups, one for each subgroup.  As noted by Tobias, the matrix: $$\begin{pmatrix}1&a\\0&1\end{pmatrix}$$ for $a\ne 0$, generates one Sylow $p$-subgroup of $G$, so I'd like to find $p$ more matrices of order $p$ that generate distinct subgroups.  These matrices should be indexed by our field $\mathbb{F}_p$.  They are certain to be conjugates of the above matrix, but two arbitrary conjugates may generate the same subgroup. Edit 2: I've just solved the question for $G$.  Here is a list of generators for the $p+1$ Sylow $p$-subgroups of $G$: $$\begin{pmatrix}1&1\\0&1\end{pmatrix},\;\begin{pmatrix}1&0\\1&1\end{pmatrix},\;\begin{pmatrix}2&a\\-a^{-1}&0\end{pmatrix}$$ where $a=1,\ldots,p-1$.  Each matrix has order $p$, and generates a distinct subgroup.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'lie-groups', 'sylow-theory']"
37,Minimal right ideals of a simple ring are generated by idempotents,Minimal right ideals of a simple ring are generated by idempotents,,Let $M$ be a minimal right ideal of a simple ring $R$. Show that $M$ contains an idempotent $e$ such that $M = eR$.,Let $M$ be a minimal right ideal of a simple ring $R$. Show that $M$ contains an idempotent $e$ such that $M = eR$.,,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
38,A problem on which of the following rings are integral domains?,A problem on which of the following rings are integral domains?,,"Which of the following rings are integral domains? (a) $\mathbb{R}[x]$, the ring of all polynomials in one variable with real coefficients. (b) $M_n(\mathbb{R}) $. (c) the ring of complex analytic functions defined on the unit disc of the complex plane (with pointwise addition and multiplication as the ring operations). Only (a) & (c) are correct. Am I right?","Which of the following rings are integral domains? (a) $\mathbb{R}[x]$, the ring of all polynomials in one variable with real coefficients. (b) $M_n(\mathbb{R}) $. (c) the ring of complex analytic functions defined on the unit disc of the complex plane (with pointwise addition and multiplication as the ring operations). Only (a) & (c) are correct. Am I right?",,['abstract-algebra']
39,Constructing Idempotent Generator of Idempotent Ideal,Constructing Idempotent Generator of Idempotent Ideal,,"Exercise 2.1 in Matsumura's Commutative Ring Theory reads as follows: ""Let $A$ be a commutative ring and $I$ an ideal that is finitely generated and $I=I^2$. Then $I$ is generated by an idempotent."" In trying to solve it, i first followed a constructive approach, where e.g. for the case of two generators i tried to construct an idempotent generator. However, it seemed difficult. Then i realized that i could apply Nakayama's lemma to the $A$-module $I$ and the existence of the idempotent generator follows. My question is: How could one go about finding this idempotent generator? Is there a systematic way?","Exercise 2.1 in Matsumura's Commutative Ring Theory reads as follows: ""Let $A$ be a commutative ring and $I$ an ideal that is finitely generated and $I=I^2$. Then $I$ is generated by an idempotent."" In trying to solve it, i first followed a constructive approach, where e.g. for the case of two generators i tried to construct an idempotent generator. However, it seemed difficult. Then i realized that i could apply Nakayama's lemma to the $A$-module $I$ and the existence of the idempotent generator follows. My question is: How could one go about finding this idempotent generator? Is there a systematic way?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'constructive-mathematics']"
40,Generator of the multiplicative groups of units in $\mathbb{Z_5[x]}/(x^{2}+3x+3)$,Generator of the multiplicative groups of units in,\mathbb{Z_5[x]}/(x^{2}+3x+3),"I would like to find a generator of the multiplicative groups of units in $\mathbb{Z_5[x]}/(x^{2}+3x+3)$. This is a field since $x^{2}+3x+3$ is irreducible, so every coset with $bx+a\not=0$ as a representative should be a unit... I do not understand how to go from here though... Since $b\not=0$ we have $4$ diffrent choices for $b$ and $5$ different options for coefficient $a$ hence $24$ elements in the multiplicative group of units. Should any $bx+a$ with order $24$ be a generator? How do I go from here?","I would like to find a generator of the multiplicative groups of units in $\mathbb{Z_5[x]}/(x^{2}+3x+3)$. This is a field since $x^{2}+3x+3$ is irreducible, so every coset with $bx+a\not=0$ as a representative should be a unit... I do not understand how to go from here though... Since $b\not=0$ we have $4$ diffrent choices for $b$ and $5$ different options for coefficient $a$ hence $24$ elements in the multiplicative group of units. Should any $bx+a$ with order $24$ be a generator? How do I go from here?",,"['abstract-algebra', 'field-theory']"
41,Determining all Sylow $p$-subgroups of $S_n$ up to isomorphism?,Determining all Sylow -subgroups of  up to isomorphism?,p S_n,"I'm trying to understand a classification of all Sylow $p$ subgroups of $S_n$. Let $Z_p$ be the subgroup of $S_p$ generated by $(12\cdots p)$. Then $Z_p\wr Z_p$ has order $p^p\cdot p=p^{p+1}$, and is isomorphic to a subgroup of $S_{p^2}$. Define inductively $Z_p^{\wr r}$ by $Z_p^{\wr 1}=Z_p$ and $Z_p^{\wr k+1}=Z_p^{\wr k}\wr Z_p$. It is easy to show by induction that $Z_p^{\wr r}$ has order $p^{(p^{r-1}+p^{r-2}+\cdots+1)}$, and since by inductively assuming $Z_p^{\wr r-1}$ is isomorphic to a subgroup of $S_{p^{r-1}}$ and $Z_p$ isomorphic to a subgroup of $S_p$, then $Z_p^{\wr r}$ is isomorphic to a subgroup of $S_{p^r}$. However, I can't make the jump that if $n=a_0+a_1p+\cdots+a_kp^k$ is the base $p$ expansion, then any Sylow $p$-subgroup is isomorphic to  $$ \underbrace{Z_p^{\wr 1}\times\cdots\times Z_p^{\wr 1}}_{a_1}\times \underbrace{Z_p^{\wr 2}\times\cdots\times Z_p^{\wr 2}}_{a_2}\times\cdots\times \underbrace{Z_p^{\wr k}\times\cdots\times Z_p^{\wr k}}_{a_k}. $$ I know this group has order $$ (p)^{a_1}(p^{p+1})^{a_2}\cdots(p^{(p^{k-1}+p^{k-2}+\cdots+1)})^{a_k}=p^{\sum_{i=1}^k a_i(1+\cdots+p^{i-1})}=p^{\nu_p(n!)} $$ which is the order of any Sylow $p$-subgroup of $S_n$, based on the formula here . However, I couldn't find an epimorphism from any Sylow $p$-subgroup onto this product, or vice versa. Is it clear how this is isomorphic to a subgroup of $S_n$? Then I understand that the isomorphism would just follow from the Sylow theorems. Thanks.","I'm trying to understand a classification of all Sylow $p$ subgroups of $S_n$. Let $Z_p$ be the subgroup of $S_p$ generated by $(12\cdots p)$. Then $Z_p\wr Z_p$ has order $p^p\cdot p=p^{p+1}$, and is isomorphic to a subgroup of $S_{p^2}$. Define inductively $Z_p^{\wr r}$ by $Z_p^{\wr 1}=Z_p$ and $Z_p^{\wr k+1}=Z_p^{\wr k}\wr Z_p$. It is easy to show by induction that $Z_p^{\wr r}$ has order $p^{(p^{r-1}+p^{r-2}+\cdots+1)}$, and since by inductively assuming $Z_p^{\wr r-1}$ is isomorphic to a subgroup of $S_{p^{r-1}}$ and $Z_p$ isomorphic to a subgroup of $S_p$, then $Z_p^{\wr r}$ is isomorphic to a subgroup of $S_{p^r}$. However, I can't make the jump that if $n=a_0+a_1p+\cdots+a_kp^k$ is the base $p$ expansion, then any Sylow $p$-subgroup is isomorphic to  $$ \underbrace{Z_p^{\wr 1}\times\cdots\times Z_p^{\wr 1}}_{a_1}\times \underbrace{Z_p^{\wr 2}\times\cdots\times Z_p^{\wr 2}}_{a_2}\times\cdots\times \underbrace{Z_p^{\wr k}\times\cdots\times Z_p^{\wr k}}_{a_k}. $$ I know this group has order $$ (p)^{a_1}(p^{p+1})^{a_2}\cdots(p^{(p^{k-1}+p^{k-2}+\cdots+1)})^{a_k}=p^{\sum_{i=1}^k a_i(1+\cdots+p^{i-1})}=p^{\nu_p(n!)} $$ which is the order of any Sylow $p$-subgroup of $S_n$, based on the formula here . However, I couldn't find an epimorphism from any Sylow $p$-subgroup onto this product, or vice versa. Is it clear how this is isomorphic to a subgroup of $S_n$? Then I understand that the isomorphism would just follow from the Sylow theorems. Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
42,"How can I prove that, in this group, elements of this form are distinct?","How can I prove that, in this group, elements of this form are distinct?",,"In the group $G=\langle x,y,z\mid xy=yx,zx=x^2z,zy=yz\rangle$, how can I prove that the elements of the form $x^iy^jz^k$ are all distinct? As Arturo is asking I'm editing this question:  I want to understand what is a set of normal forms. At the beginning I thought that it was $x^iy^jz^k$, but they made me notice that is not so obvious how $z^{-1}x$ can be written in this form. Actually I think I proved that it cannot be, in fact: if $z^{-1}x=x^iy^jz^k$ then conjugating by $z$ we obtain $xz^{-1}=zx^iy^jz^{k-1}=x^{2i}y^jz^k$ and so $z^{-1}=x^{2i-1}y^jz^k$ and so $1=x^{2i-1}y^jz^{k+1}$, I also proved that if $x^iy^jz^k=1$ then $i=j=k=0$, and so we have $2i-1=0$ that has no solution in $\mathbb{Z}$. So could you tell me how can I compute a set of normal forms? (they don't have to be too complicated because I'm asked to draw the cayley graph)","In the group $G=\langle x,y,z\mid xy=yx,zx=x^2z,zy=yz\rangle$, how can I prove that the elements of the form $x^iy^jz^k$ are all distinct? As Arturo is asking I'm editing this question:  I want to understand what is a set of normal forms. At the beginning I thought that it was $x^iy^jz^k$, but they made me notice that is not so obvious how $z^{-1}x$ can be written in this form. Actually I think I proved that it cannot be, in fact: if $z^{-1}x=x^iy^jz^k$ then conjugating by $z$ we obtain $xz^{-1}=zx^iy^jz^{k-1}=x^{2i}y^jz^k$ and so $z^{-1}=x^{2i-1}y^jz^k$ and so $1=x^{2i-1}y^jz^{k+1}$, I also proved that if $x^iy^jz^k=1$ then $i=j=k=0$, and so we have $2i-1=0$ that has no solution in $\mathbb{Z}$. So could you tell me how can I compute a set of normal forms? (they don't have to be too complicated because I'm asked to draw the cayley graph)",,"['abstract-algebra', 'group-theory', 'group-presentation']"
43,Injective map between power series ring,Injective map between power series ring,,"Suppose $k$ is a field and let $n > m$. Does there exist injective homomorphisms  $$ k [[x_1, x_2, \ldots, x_n]] \rightarrow k[[x_1, x_2, \ldots, x_m]]\ ?$$","Suppose $k$ is a field and let $n > m$. Does there exist injective homomorphisms  $$ k [[x_1, x_2, \ldots, x_n]] \rightarrow k[[x_1, x_2, \ldots, x_m]]\ ?$$",,"['abstract-algebra', 'commutative-algebra', 'power-series']"
44,The UFD field lemma,The UFD field lemma,,"This page contains a result which it refers to as the UFD field lemma. I was wondering if anybody knew of any other references which discuss this result--this page is the only place I've seen it. The UFD field lemma appears to assert that if $R$ is a unique factorization domain containing infinitely many prime elements, if $F$ is the field of fractions of $R$, and if $A$ is a finitely generated $R$-algebra which is a field and is algebraic over $F$, then $A$ does not contain $F$. I'm looking for other sources because I find the exposition on that page a little hard to follow.","This page contains a result which it refers to as the UFD field lemma. I was wondering if anybody knew of any other references which discuss this result--this page is the only place I've seen it. The UFD field lemma appears to assert that if $R$ is a unique factorization domain containing infinitely many prime elements, if $F$ is the field of fractions of $R$, and if $A$ is a finitely generated $R$-algebra which is a field and is algebraic over $F$, then $A$ does not contain $F$. I'm looking for other sources because I find the exposition on that page a little hard to follow.",,"['abstract-algebra', 'commutative-algebra', 'unique-factorization-domains']"
45,Prove that R is an integral domain,Prove that R is an integral domain,,"I'm studying for my qualifying exam and I came across the following question in one of the old question bank. Consider the affine space given by four $2\times 2$ matrices, i.e., $\mathbb{A}^{16}\cong M(\mathbb{C})_{2\times 2}^4$ . Now, consider the algebraic set $V$ given by the vanishing of the relation $AB-CD=0$ , where the matrices are as follows: $A=(a_{ij}), B=(b_{ij}), C=(c_{ij})$ and $D=(d_{ij})$ . Prove that $V$ is irreducible in $\mathbb{A}^{16}$ . In other words, I want to prove that the following ring $R=\mathbb{C}[a_{11},a_{12},a_{21},a_{22}, b_{11},\dotsc, d_{21},d_{22}]/I$ , where $I=(a_{11}b_{11}+a_{12}b_{21}−c_{11}d_{11}−c_{12}d_{21},\,a_{11}b_{12}+ a_{12}b_{22}−c_{11}d_{12}−c_{12}d_{22},\,a_{21}b_{11}+a_{22}b_{21}−c_{21}d_{11}−c_{22}d_{21},\,a_{21}b_{12}+a_{22}b_{22}−c_{21}d_{12}−c_{22}d_{22})$ $R$ is an integral domain. I've been trying to follow the same idea as in this post ( https://math.stackexchange.com/a/4303220/884739 ), but I'm having hard time trying to figure out what the correct change of coordinate should be, so that I can embed this ring $R$ inside some field and hence, conclude that $R$ is an integral domain.","I'm studying for my qualifying exam and I came across the following question in one of the old question bank. Consider the affine space given by four matrices, i.e., . Now, consider the algebraic set given by the vanishing of the relation , where the matrices are as follows: and . Prove that is irreducible in . In other words, I want to prove that the following ring , where is an integral domain. I've been trying to follow the same idea as in this post ( https://math.stackexchange.com/a/4303220/884739 ), but I'm having hard time trying to figure out what the correct change of coordinate should be, so that I can embed this ring inside some field and hence, conclude that is an integral domain.","2\times 2 \mathbb{A}^{16}\cong M(\mathbb{C})_{2\times 2}^4 V AB-CD=0 A=(a_{ij}), B=(b_{ij}), C=(c_{ij}) D=(d_{ij}) V \mathbb{A}^{16} R=\mathbb{C}[a_{11},a_{12},a_{21},a_{22}, b_{11},\dotsc, d_{21},d_{22}]/I I=(a_{11}b_{11}+a_{12}b_{21}−c_{11}d_{11}−c_{12}d_{21},\,a_{11}b_{12}+
a_{12}b_{22}−c_{11}d_{12}−c_{12}d_{22},\,a_{21}b_{11}+a_{22}b_{21}−c_{21}d_{11}−c_{22}d_{21},\,a_{21}b_{12}+a_{22}b_{22}−c_{21}d_{12}−c_{22}d_{22}) R R R","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'representation-theory', 'quiver']"
46,Non-commutative vector space,Non-commutative vector space,,"A field acting on an abelian group is called a vector space. Is there a name for a field acting on a non-abelian group? What I mean is a group $G$ a field $F$ , and an operation $F \times G \to G$ , $(a, x) \mapsto x^a$ such that: $x^0 = e$ $x^1 = x$ $x^{a+b} = x^ax^b$ $x^{ab} = (x^a)^b$ Is there a name for this kind of structure? Why aren't they studied?","A field acting on an abelian group is called a vector space. Is there a name for a field acting on a non-abelian group? What I mean is a group a field , and an operation , such that: Is there a name for this kind of structure? Why aren't they studied?","G F F \times G \to G (a, x) \mapsto x^a x^0 = e x^1 = x x^{a+b} = x^ax^b x^{ab} = (x^a)^b",['abstract-algebra']
47,$GL_3(\mathbb{F}_2)$ is a simple group,is a simple group,GL_3(\mathbb{F}_2),"I'm trying to prove that $G := GL_3(\mathbb{F}_2)$ , the group of $3 \times 3$ matrices with entries in $\mathbb{F}_2$ is a simple group. The steps outlined for me look like: 1) Construct a list of representatives for the conjugacy classes of $G$ . 2) Compute the size of each of these conjugacy classes. 3) Show that $G$ is simple. I was able to solve step (1) using the fact that every matrix in $G$ is conjugate to a unique block matrix, where each of the blocks are companion matrices of a list of invariant factors. That is, for each matrix $A \in G$ there exists unique (up to associates) $\delta_1 \mid \cdots \mid \delta_n$ , $\delta_i \in \mathbb{F}_2[x]$ such that $A \sim $ diag(Com( $\delta_1$ ), $\ldots$ , Com( $\delta_n$ )). Using this fact I was able to construct the following list of representatives for conjugacy classes of matrices: $$ \begin{bmatrix}  0 & 0 & 1\\ 1 & 0 & 0 \\ 0 & 1 & 0  \end{bmatrix} , \begin{bmatrix}  0 & 0 & 1\\ 1 & 0 & 1 \\ 0 & 1 & 0  \end{bmatrix}, \begin{bmatrix}  0 & 0 & 1\\ 1 & 0 & 1 \\ 0 & 1 & 1  \end{bmatrix}, \begin{bmatrix}  0 & 0 & 1\\ 1 & 0 & 0 \\ 0 & 1 & 1  \end{bmatrix} , \begin{bmatrix}  1 & 0 & 0\\ 0 & 0 & 1 \\ 0 & 1 & 0  \end{bmatrix},  \begin{bmatrix}  1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1  \end{bmatrix} $$ I get a little stuck on part (2). I know the size of the conjugacy class of each of the above matrices is equal to the index of the centralizer. I could compute the centralizer of each of the above matrices directly and that would give me the answer but I'm a little hesitant to just multiply matrices for 10-15 minutes. This problem was on a practice qualifying exam so I suspect that there is a faster/more clever way to compute the sizes of these conjugacy classes. This is really what I want. One idea I have: Two matrices are conjugate if and only if they have the same list of invariant factors. For many of the matrices the list of invariant factors is a single degree 3 polynomial. In this case I know both the minimal polynomial and characteristic polynomial of any matrix conjugate to my representative. These observations do not seem to make the computation much faster though. I suspect that once I can do (2), (3) will follow relatively quickly.","I'm trying to prove that , the group of matrices with entries in is a simple group. The steps outlined for me look like: 1) Construct a list of representatives for the conjugacy classes of . 2) Compute the size of each of these conjugacy classes. 3) Show that is simple. I was able to solve step (1) using the fact that every matrix in is conjugate to a unique block matrix, where each of the blocks are companion matrices of a list of invariant factors. That is, for each matrix there exists unique (up to associates) , such that diag(Com( ), , Com( )). Using this fact I was able to construct the following list of representatives for conjugacy classes of matrices: I get a little stuck on part (2). I know the size of the conjugacy class of each of the above matrices is equal to the index of the centralizer. I could compute the centralizer of each of the above matrices directly and that would give me the answer but I'm a little hesitant to just multiply matrices for 10-15 minutes. This problem was on a practice qualifying exam so I suspect that there is a faster/more clever way to compute the sizes of these conjugacy classes. This is really what I want. One idea I have: Two matrices are conjugate if and only if they have the same list of invariant factors. For many of the matrices the list of invariant factors is a single degree 3 polynomial. In this case I know both the minimal polynomial and characteristic polynomial of any matrix conjugate to my representative. These observations do not seem to make the computation much faster though. I suspect that once I can do (2), (3) will follow relatively quickly.","G := GL_3(\mathbb{F}_2) 3 \times 3 \mathbb{F}_2 G G G A \in G \delta_1 \mid \cdots \mid \delta_n \delta_i \in \mathbb{F}_2[x] A \sim  \delta_1 \ldots \delta_n 
\begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 0 \\
0 & 1 & 0 
\end{bmatrix} , \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 1 \\
0 & 1 & 0 
\end{bmatrix}, \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 1 \\
0 & 1 & 1 
\end{bmatrix}, \begin{bmatrix} 
0 & 0 & 1\\
1 & 0 & 0 \\
0 & 1 & 1 
\end{bmatrix} , \begin{bmatrix} 
1 & 0 & 0\\
0 & 0 & 1 \\
0 & 1 & 0 
\end{bmatrix}, 
\begin{bmatrix} 
1 & 0 & 0\\
0 & 1 & 0 \\
0 & 0 & 1 
\end{bmatrix}
","['abstract-algebra', 'matrices', 'group-theory']"
48,Problem 2B.4 in Finite Group Theory by Isaacs,Problem 2B.4 in Finite Group Theory by Isaacs,,"Suppose a finite group $G$ has more than one Sylow-2 subgroup and any two intersects trivially. Show $G$ contains exactly one conjugacy class of involutions. Here are some of my thoughts: Suppose not, then there exist involutions $s,t$ such that they are not conjugate. $s,t$ generates a dihedral group $D_{2n}$ . $n$ is even since $s,t$ are not conjugate in $D_{2n}$ . If $n$ is not a power of 2, then $D_{2n}$ has more than one Sylow 2 subgroups and $D_{2n}$ are generated by them. But any two of the Sylow 2 subgroups of $D_{2n}$ has a nontrival intersection, and any two Sylow-2 subgroups of G intersects trivally, so all  Sylow 2 subgroups of $D_{2n}$ must lie in the same  Sylow-2 subgroup of $G$ . So $D_{2n}$ lie in a Sylow-2 subgroup of $G$ , this leads a contradiction. But what if $n$ is a power of 2?","Suppose a finite group has more than one Sylow-2 subgroup and any two intersects trivially. Show contains exactly one conjugacy class of involutions. Here are some of my thoughts: Suppose not, then there exist involutions such that they are not conjugate. generates a dihedral group . is even since are not conjugate in . If is not a power of 2, then has more than one Sylow 2 subgroups and are generated by them. But any two of the Sylow 2 subgroups of has a nontrival intersection, and any two Sylow-2 subgroups of G intersects trivally, so all  Sylow 2 subgroups of must lie in the same  Sylow-2 subgroup of . So lie in a Sylow-2 subgroup of , this leads a contradiction. But what if is a power of 2?","G G s,t s,t D_{2n} n s,t D_{2n} n D_{2n} D_{2n} D_{2n} D_{2n} G D_{2n} G n","['abstract-algebra', 'group-theory', 'sylow-theory']"
49,"How to prove $\{G_i\to F\}$ is open covering only if $\forall$ field $K$, $F(Spec K)=\cup_iG_i(Spec(K))$?","How to prove  is open covering only if  field , ?",\{G_i\to F\} \forall K F(Spec K)=\cup_iG_i(Spec(K)),"This is an exercise in Eisenbud, Harris, Geometry of Schemes VI-11 as this part is skipped in Mumford Algebraic Geometry II. I think I figured out a way to do it but I am not totally sure. $\{G_i\to F\}$ is a collection of open subfunctors with $F:Schemes\to Set$ where open subfunctors means for all $h_R=Hom(-,Spec(R)),\phi\in Nat(h_R,F)$ , $G_i\times_\phi h_R$ is a subfunctor of $h_R$ where pullback is defined on affine objects. Now $\{G_i\to F\}$ is called covering if for any scheme $X$ with $h_X=Hom(-,X)$ and any $\phi\in Nat(h_X,F)$ , $G_i\times_Fh_X$ is representable as $h_{U_i}$ with $U_i$ covering $X$ . Show that $\{G_i\to F\}$ is open covering iff $F(Spec(K))=\cup G_i(Spec(K))$ for all field $K$ . Forward direction is trivial by applying all functors to $Spec(K)$ . The fiber product has either 1 element or none by embedding into $Hom(Spec(K), Spec(K))=Hom(K,K)=\{1_K\}$ . It follows equality of $F(Spec(K))=\cup G_i(Spec(K))$ . I am kind of having trouble with reverse direction. If $F$ is representable as a scheme, then it boils down to prove the statement for affine schemes where $G_i$ will be identified as hom functor of open subschemes of affine scheme. Use all residue fields to detect the missing points of covering. Then I can see it indeed forms a covering. $\textbf{Q:}$ How do I prove the converse statement? I am also kind of having trobule to grasp the main point of the converse statement. What is the geometric meaning?","This is an exercise in Eisenbud, Harris, Geometry of Schemes VI-11 as this part is skipped in Mumford Algebraic Geometry II. I think I figured out a way to do it but I am not totally sure. is a collection of open subfunctors with where open subfunctors means for all , is a subfunctor of where pullback is defined on affine objects. Now is called covering if for any scheme with and any , is representable as with covering . Show that is open covering iff for all field . Forward direction is trivial by applying all functors to . The fiber product has either 1 element or none by embedding into . It follows equality of . I am kind of having trouble with reverse direction. If is representable as a scheme, then it boils down to prove the statement for affine schemes where will be identified as hom functor of open subschemes of affine scheme. Use all residue fields to detect the missing points of covering. Then I can see it indeed forms a covering. How do I prove the converse statement? I am also kind of having trobule to grasp the main point of the converse statement. What is the geometric meaning?","\{G_i\to F\} F:Schemes\to Set h_R=Hom(-,Spec(R)),\phi\in Nat(h_R,F) G_i\times_\phi h_R h_R \{G_i\to F\} X h_X=Hom(-,X) \phi\in Nat(h_X,F) G_i\times_Fh_X h_{U_i} U_i X \{G_i\to F\} F(Spec(K))=\cup G_i(Spec(K)) K Spec(K) Hom(Spec(K), Spec(K))=Hom(K,K)=\{1_K\} F(Spec(K))=\cup G_i(Spec(K)) F G_i \textbf{Q:}","['abstract-algebra', 'algebraic-geometry', 'category-theory']"
50,Does this property characterize abelian groups?,Does this property characterize abelian groups?,,"Let $G$ be a group. Suppose there exists an integer $k>1$ and a non-identity permutation $\pi \in S_k$ such that for all $x_1, x_2 \cdots x_k \neq \mathbf{1} \in G$ we have that $x_1x_2x_3 \cdots x_k = x_{\pi(1)}x_{\pi(2)}x_{\pi(3)} \cdots x_{\pi(k)}$ . Must $G$ be abelian? This question is motivated by this . I've attempted to use Andrés technique in the linked post again here, but to no avail. I've also attempted to look at classical non-abelian groups like $S_3$ and $GL_n(\mathbf{C})$ for counterexamples but also to no avail. If this is false, is it possible that there's some conditions on the permutation $\pi$ which makes this true? Because, again looking over the linked post, it is clear that some permutations force abelianness.","Let be a group. Suppose there exists an integer and a non-identity permutation such that for all we have that . Must be abelian? This question is motivated by this . I've attempted to use Andrés technique in the linked post again here, but to no avail. I've also attempted to look at classical non-abelian groups like and for counterexamples but also to no avail. If this is false, is it possible that there's some conditions on the permutation which makes this true? Because, again looking over the linked post, it is clear that some permutations force abelianness.","G k>1 \pi \in S_k x_1, x_2 \cdots x_k \neq \mathbf{1} \in G x_1x_2x_3 \cdots x_k = x_{\pi(1)}x_{\pi(2)}x_{\pi(3)} \cdots x_{\pi(k)} G S_3 GL_n(\mathbf{C}) \pi","['abstract-algebra', 'group-theory', 'permutations']"
51,Some concrete examples of $M_q(2)$ points,Some concrete examples of  points,M_q(2),"Given $q \in \mathbb{C}$ invertible, Kassel says that an $M_q(2)$ point of an $R$ algebra is a $m=\left(\begin{array}{cc} A & B\\ C & D \end{array}\right)\in R^{4}$ such that $A,\,B,\,C,\,D \in R$ satisfy the following relations $$CA=qAC,$$ $$ DB=qBD, $$ $$BA=qAB,$$ $$DC=qCD,$$ $$BC=CB,$$ $$DA-qCB=AD-\left(q^{-1}\right)BC.$$ Can anybody give me a concrete example of $M_3(\mathbb{C})$ matrices that form such a point? If it's not possible in $M_3(\mathbb{C})$ , every other concrete example is well accepted. Thanks in advance","Given invertible, Kassel says that an point of an algebra is a such that satisfy the following relations Can anybody give me a concrete example of matrices that form such a point? If it's not possible in , every other concrete example is well accepted. Thanks in advance","q \in \mathbb{C} M_q(2) R m=\left(\begin{array}{cc}
A & B\\
C & D
\end{array}\right)\in R^{4} A,\,B,\,C,\,D \in R CA=qAC,  DB=qBD,  BA=qAB, DC=qCD, BC=CB, DA-qCB=AD-\left(q^{-1}\right)BC. M_3(\mathbb{C}) M_3(\mathbb{C})","['abstract-algebra', 'matrices', 'representation-theory', 'hopf-algebras', 'quantum-groups']"
52,$G$ is cyclic iff $f(H) = H$ for every automorphism $f$,is cyclic iff  for every automorphism,G f(H) = H f,"Let $(G,\cdot)$ be a finite group, $|G| = n \in \mathbb{N}, n \geq 2$ such that $n$ is not divisible with the cube of any prime number. Prove that $G$ is cyclic $\iff$ $\forall f \in Aut(G), f(H) = H$ , for every subgroup $H$ of $G$ . For the direct implication, I tried assuming the contrary and then try to use the fact that $G = <x>$ , but I couldn't solve the problem. For the inverse implication, using the inner automorphisms, we get that every subgroup $H$ of $G$ is normal. But I don't know how to use the fact that $n$ is not divisible with the cube of any prime number in order to prove that $G$ is cyclic.","Let be a finite group, such that is not divisible with the cube of any prime number. Prove that is cyclic , for every subgroup of . For the direct implication, I tried assuming the contrary and then try to use the fact that , but I couldn't solve the problem. For the inverse implication, using the inner automorphisms, we get that every subgroup of is normal. But I don't know how to use the fact that is not divisible with the cube of any prime number in order to prove that is cyclic.","(G,\cdot) |G| = n \in \mathbb{N}, n \geq 2 n G \iff \forall f \in Aut(G), f(H) = H H G G = <x> H G n G","['abstract-algebra', 'group-theory', 'finite-groups']"
53,How do I show that formal logarithm is the inverse of the formal exponential?,How do I show that formal logarithm is the inverse of the formal exponential?,,"Let $A$ be a unital commutative and associative $\mathbb{Q}$-algebra. Define $exp(f):=\sum_{n=0}^\infty \frac{f^n}{n!}$ for each $f\in XA[[X]]$. Define $log(f):=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n} (f-1)^n$ for each $f\in 1+XA[[X]]$. Hence, we have two maps $exp:XA[[X]]\rightarrow 1+XA[[X]]$ and $log:1+XA[[X]]\rightarrow XA[[X]]$. I am trying to prove that $log$ map is the inverse of the $exp$ map. The first thing I tried is to directly show $log\circ exp=id$ and $exp\circ log = id$ by checking if the identities hold for every element $f$, but this does not work well since this way involves too many calculations. For example, $$[X^n]exp(log(f))=[X^n]\sum_{k=0}^n log(f)^k/k! = \sum_{k=0}^n \frac{1}{k!} [X^n]log(f)^k= \sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k$$. Thus, we have to show that $$\sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k=[X^n]f$$. But this calculation is really a nightmare.. Is there a clever way to show this? If not, how do I wisely calculate to show the above identity? Thank you in advance.","Let $A$ be a unital commutative and associative $\mathbb{Q}$-algebra. Define $exp(f):=\sum_{n=0}^\infty \frac{f^n}{n!}$ for each $f\in XA[[X]]$. Define $log(f):=\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n} (f-1)^n$ for each $f\in 1+XA[[X]]$. Hence, we have two maps $exp:XA[[X]]\rightarrow 1+XA[[X]]$ and $log:1+XA[[X]]\rightarrow XA[[X]]$. I am trying to prove that $log$ map is the inverse of the $exp$ map. The first thing I tried is to directly show $log\circ exp=id$ and $exp\circ log = id$ by checking if the identities hold for every element $f$, but this does not work well since this way involves too many calculations. For example, $$[X^n]exp(log(f))=[X^n]\sum_{k=0}^n log(f)^k/k! = \sum_{k=0}^n \frac{1}{k!} [X^n]log(f)^k= \sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k$$. Thus, we have to show that $$\sum_{k=0}^n \frac{1}{k!} [X^n](\sum_{l=1}^k \frac{(-1)^{l+1}}{l} (f-1)^l)^k=[X^n]f$$. But this calculation is really a nightmare.. Is there a clever way to show this? If not, how do I wisely calculate to show the above identity? Thank you in advance.",,"['abstract-algebra', 'combinatorics', 'discrete-mathematics', 'formal-power-series']"
54,"Let $H \leq G$ be a subgroup with finite index $n$. Show for every $g \in Z(G)$, $g^n \in H$.","Let  be a subgroup with finite index . Show for every , .",H \leq G n g \in Z(G) g^n \in H,"Let $H \leq G$ be a subgroup with finite index $n$ . Show for every $g \in Z(G)$ , $g^n \in H$ . I am given a hint: Consider $C = \langle g \rangle$ and show the left multiplication action of $C$ on $G/H$ has orbits of size $|C/(C\cap H)|$ . Proof of hint: Let $g \in Z(G)$ and $C = \langle g \rangle$ act on $G/H$ by left multiplication.  For any $xH \in G/H$ , $(g^kx)H = x(g^kH)$ which shows $g^k \in \text{Stab}_C(xH)$ if and only if $g^k \in H$ .  By the orbit stabilizer theorem, $|\text{Orb}_C(xH)| = [C:\text{Stab}_C(xH)] = |C/(C\cap H)|$ . $\square$ I am having trouble proving the result from here.  I have not yet used the assumption that $H$ has finite index in $G$ which seems essential for finishing this proof.  Any help would be appreciated.","Let be a subgroup with finite index . Show for every , . I am given a hint: Consider and show the left multiplication action of on has orbits of size . Proof of hint: Let and act on by left multiplication.  For any , which shows if and only if .  By the orbit stabilizer theorem, . I am having trouble proving the result from here.  I have not yet used the assumption that has finite index in which seems essential for finishing this proof.  Any help would be appreciated.",H \leq G n g \in Z(G) g^n \in H C = \langle g \rangle C G/H |C/(C\cap H)| g \in Z(G) C = \langle g \rangle G/H xH \in G/H (g^kx)H = x(g^kH) g^k \in \text{Stab}_C(xH) g^k \in H |\text{Orb}_C(xH)| = [C:\text{Stab}_C(xH)] = |C/(C\cap H)| \square H G,"['abstract-algebra', 'group-theory']"
55,Minimum product of degrees of generators of finite field extension,Minimum product of degrees of generators of finite field extension,,"Suppose $L/K$ is a finite extension of fields. Is is always true that $$\min_{\substack{\{\alpha_1, \ldots, \alpha_n\} \\ L = K(\alpha_1, \ldots, \alpha_n)}} \left(\prod_{i=1}^n [K(\alpha_i): K] \right) = [L:K]?$$ By the primitive element theorem, this is certainly true if $L/K$ is separable. But what if $L/K$ is an arbitrary finite extension?","Suppose $L/K$ is a finite extension of fields. Is is always true that $$\min_{\substack{\{\alpha_1, \ldots, \alpha_n\} \\ L = K(\alpha_1, \ldots, \alpha_n)}} \left(\prod_{i=1}^n [K(\alpha_i): K] \right) = [L:K]?$$ By the primitive element theorem, this is certainly true if $L/K$ is separable. But what if $L/K$ is an arbitrary finite extension?",,"['abstract-algebra', 'number-theory', 'field-theory', 'galois-theory']"
56,A reference/proof request for a result on real radical extensions,A reference/proof request for a result on real radical extensions,,"I am looking for an English reference or a proof of the following result due to Holder: ""Let $ f(x) $ be an irreducible polynomial over a real field $ K $. If all the roots of $ f(x) $ are real and expressible by real radicals (in the sense that they lie in some real radical extension of $ K $), then the Galois group of $ f $ over $ K $ is a $ 2 $-group."" (quoted verbatim from this article .) In the linked article, there is a reference, but it is German. I have found a page on this result on planetmath, but their argument depends on this proof , where I do not see how $ L' = F'(\sqrt[n]{\beta}) $ implies that $ L = F(\sqrt[n]{\beta}) $, or even that $ \beta \in F $ in the first place. I would appreciate it if someone provided an English reference for this result, or even better, posted a proof sketch as an answer. Note: The planetmath references have made a previous appearance on the site in the comments section of this question , but Gerry Myerson's proof sketch is extremely lacking. (I do not see how to make his argument work, concretely.)","I am looking for an English reference or a proof of the following result due to Holder: ""Let $ f(x) $ be an irreducible polynomial over a real field $ K $. If all the roots of $ f(x) $ are real and expressible by real radicals (in the sense that they lie in some real radical extension of $ K $), then the Galois group of $ f $ over $ K $ is a $ 2 $-group."" (quoted verbatim from this article .) In the linked article, there is a reference, but it is German. I have found a page on this result on planetmath, but their argument depends on this proof , where I do not see how $ L' = F'(\sqrt[n]{\beta}) $ implies that $ L = F(\sqrt[n]{\beta}) $, or even that $ \beta \in F $ in the first place. I would appreciate it if someone provided an English reference for this result, or even better, posted a proof sketch as an answer. Note: The planetmath references have made a previous appearance on the site in the comments section of this question , but Gerry Myerson's proof sketch is extremely lacking. (I do not see how to make his argument work, concretely.)",,"['abstract-algebra', 'field-theory', 'galois-theory']"
57,Why should I learn modern category theory if my interest mainly is structured sets?,Why should I learn modern category theory if my interest mainly is structured sets?,,"A long time ago I studied mathematics at the University of Stockholm. I had a romantic view of modern algebra and manage to make the first two algebra courses by self studies in order to immediately study homological algebra, Galois theory and such topics. That is not the best way to study. Later as a graduate student I did rather well - until the gaps in my basic knowledge and abilities began to affect too much. Then I stopped focusing on mathematics about 35 years ago. I did self studies in category theory because we were supposed to do that and because it was a good idea. Category theory worked fine with the mathematics evolved at 1950 or so. The universal definitions and duality simplified a lot of mathematics as tensor products and injective/projective modules etc and the functors opened new possibilities. The last 40 years or so the interest in and the development of category theory has exploded and seems nowaday be very abstract but also very consistent. My question is, what modern category theory could be    interesting for a person mainly interested in the mathematics concerning structured sets? The bounty will soon expire and there is 50+ in reputation to earn - aren't there anything to express on this topic?","A long time ago I studied mathematics at the University of Stockholm. I had a romantic view of modern algebra and manage to make the first two algebra courses by self studies in order to immediately study homological algebra, Galois theory and such topics. That is not the best way to study. Later as a graduate student I did rather well - until the gaps in my basic knowledge and abilities began to affect too much. Then I stopped focusing on mathematics about 35 years ago. I did self studies in category theory because we were supposed to do that and because it was a good idea. Category theory worked fine with the mathematics evolved at 1950 or so. The universal definitions and duality simplified a lot of mathematics as tensor products and injective/projective modules etc and the functors opened new possibilities. The last 40 years or so the interest in and the development of category theory has exploded and seems nowaday be very abstract but also very consistent. My question is, what modern category theory could be    interesting for a person mainly interested in the mathematics concerning structured sets? The bounty will soon expire and there is 50+ in reputation to earn - aren't there anything to express on this topic?",,"['abstract-algebra', 'soft-question', 'category-theory', 'big-picture']"
58,Additivity of trace,Additivity of trace,,"Let $A$ be a finitely generated abelian group and $\alpha:A\to A$ be an endomorphism. Since $A=A_{free}\oplus A_{torsion}$, we can induce $\bar \alpha:A_{free}\to A_{free}$, i.e. $\bar\alpha$ is a map from $\oplus\mathbb Z$ to itself. Write $\bar\alpha$ as  a matrix form and define $tr(\alpha)=tr(\bar\alpha)$ as the trace of the matrix. Assume we have short exact sequence of finitely generated abelian groups $A,B,C$ and endomorphisms $\alpha,\beta,\gamma$ where the following diagram commutes. $$\begin{array}{c} 0 & \to & A & \to & B & \to & C & \to & 0 \\ & & \!\downarrow \alpha && \!\downarrow\beta && \!\downarrow\gamma & \\ 0 & \to & A & \to & B & \to & C & \to & 0\end{array}$$ Prove $tr(\beta)=tr(\alpha)+tr(\gamma)$.","Let $A$ be a finitely generated abelian group and $\alpha:A\to A$ be an endomorphism. Since $A=A_{free}\oplus A_{torsion}$, we can induce $\bar \alpha:A_{free}\to A_{free}$, i.e. $\bar\alpha$ is a map from $\oplus\mathbb Z$ to itself. Write $\bar\alpha$ as  a matrix form and define $tr(\alpha)=tr(\bar\alpha)$ as the trace of the matrix. Assume we have short exact sequence of finitely generated abelian groups $A,B,C$ and endomorphisms $\alpha,\beta,\gamma$ where the following diagram commutes. $$\begin{array}{c} 0 & \to & A & \to & B & \to & C & \to & 0 \\ & & \!\downarrow \alpha && \!\downarrow\beta && \!\downarrow\gamma & \\ 0 & \to & A & \to & B & \to & C & \to & 0\end{array}$$ Prove $tr(\beta)=tr(\alpha)+tr(\gamma)$.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'exact-sequence']"
59,Probability that two random matrices span the full matrix algebra,Probability that two random matrices span the full matrix algebra,,"Given two matrices $A$ and $B$ drawn at random in $\mathbb{R}^{n\times n}$, what is the probability that the matrix algebra generated by $A$ and $B$ is the full matrix algebra $\mathbb{R}^{n\times n}$? That is, if $\mathcal{A}$ is the set of matrices defined by $A,B\in \mathcal{A}$ and $XY\in \mathcal{A}$ for all $X,Y\in\mathcal{A}$, what is the probability that $\mathcal{A}$ contains $n^2$ linearly independent matrices? I have the intuition that this should occur with probability one, but I can't manage to prove it. If that helps, using Burnside's theorem I think that this is equivalent to the fact that there are no common invariant subspaces for all matrices in $\mathcal{A}$ except for $\{0\}$ and $\mathbb{R}^n$.","Given two matrices $A$ and $B$ drawn at random in $\mathbb{R}^{n\times n}$, what is the probability that the matrix algebra generated by $A$ and $B$ is the full matrix algebra $\mathbb{R}^{n\times n}$? That is, if $\mathcal{A}$ is the set of matrices defined by $A,B\in \mathcal{A}$ and $XY\in \mathcal{A}$ for all $X,Y\in\mathcal{A}$, what is the probability that $\mathcal{A}$ contains $n^2$ linearly independent matrices? I have the intuition that this should occur with probability one, but I can't manage to prove it. If that helps, using Burnside's theorem I think that this is equivalent to the fact that there are no common invariant subspaces for all matrices in $\mathcal{A}$ except for $\{0\}$ and $\mathbb{R}^n$.",,"['abstract-algebra', 'matrices']"
60,Problem with the ring $R=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q &\Bbb Q\end{bmatrix}$ and its ideal $D=\begin{bmatrix}0&0\\ \Bbb Q & \Bbb Q\end{bmatrix}$,Problem with the ring  and its ideal,R=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q &\Bbb Q\end{bmatrix} D=\begin{bmatrix}0&0\\ \Bbb Q & \Bbb Q\end{bmatrix},"Let us consider the ring $ R:=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q & \Bbb Q\end{bmatrix} $ and its two-sided ideal $ D:=\begin{bmatrix}0 & 0\\ \Bbb Q & \Bbb Q\end{bmatrix} $. Let then consider the free right $R$-module $F_R:=\bigoplus_{\lambda\in\Lambda}x_{\lambda}R$. I must show that $$ \bigcap_{n\ge1}nF_R=\bigoplus_{\lambda\in\Lambda}x_{\lambda}D=F_RD\;\;. $$ I proved the first equality using the fact that $\bigcap_{n\ge1}nR=D$. The second inequality: observing that $D\unlhd R$ (i.e. $D$ is a two-sided ideal of $R$) we have that $D=RD$, from which we would have $$ \bigoplus_{\lambda\in\Lambda}x_{\lambda}D =\bigoplus_{\lambda\in\Lambda}x_{\lambda}RD =\underbrace{\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}_{=F_R}D $$ my problem is with the last equality in this last line: $""\supseteq""$ is obvious. What I cannot prove is the other inclusion $""\subseteq""$. I try writing the generic element of LHS, say $\sum_{\lambda\in F}x_{\lambda}r_{\lambda}d_{\lambda}=x_1r_1d_1+\cdots+x_nr_nd_n$, for some finite $F\subseteq\Lambda,\;|F|=n$. Then I should find some $d\in D$ and $r_1',\dots,r_n'\in R$ such that $x_1r_1d_1+\cdots+x_nr_nd_n=(x_1r_1'+\cdots+x_nr_n')d$: in such a way this last element would be in $ {\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}D $ which is our RHS and I would have finished. I tried to write out the matrices to find $d$ and the $r_j$'s, even doing some not elegant computations, but I didn't found any way to go out! Can someone help me? Many thanks! EDIT: see my answer below.","Let us consider the ring $ R:=\begin{bmatrix}\Bbb Z & 0\\ \Bbb Q & \Bbb Q\end{bmatrix} $ and its two-sided ideal $ D:=\begin{bmatrix}0 & 0\\ \Bbb Q & \Bbb Q\end{bmatrix} $. Let then consider the free right $R$-module $F_R:=\bigoplus_{\lambda\in\Lambda}x_{\lambda}R$. I must show that $$ \bigcap_{n\ge1}nF_R=\bigoplus_{\lambda\in\Lambda}x_{\lambda}D=F_RD\;\;. $$ I proved the first equality using the fact that $\bigcap_{n\ge1}nR=D$. The second inequality: observing that $D\unlhd R$ (i.e. $D$ is a two-sided ideal of $R$) we have that $D=RD$, from which we would have $$ \bigoplus_{\lambda\in\Lambda}x_{\lambda}D =\bigoplus_{\lambda\in\Lambda}x_{\lambda}RD =\underbrace{\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}_{=F_R}D $$ my problem is with the last equality in this last line: $""\supseteq""$ is obvious. What I cannot prove is the other inclusion $""\subseteq""$. I try writing the generic element of LHS, say $\sum_{\lambda\in F}x_{\lambda}r_{\lambda}d_{\lambda}=x_1r_1d_1+\cdots+x_nr_nd_n$, for some finite $F\subseteq\Lambda,\;|F|=n$. Then I should find some $d\in D$ and $r_1',\dots,r_n'\in R$ such that $x_1r_1d_1+\cdots+x_nr_nd_n=(x_1r_1'+\cdots+x_nr_n')d$: in such a way this last element would be in $ {\left(\bigoplus_{\lambda\in\Lambda}x_{\lambda}R\right)}D $ which is our RHS and I would have finished. I tried to write out the matrices to find $d$ and the $r_j$'s, even doing some not elegant computations, but I didn't found any way to go out! Can someone help me? Many thanks! EDIT: see my answer below.",,"['abstract-algebra', 'ring-theory', 'modules', 'direct-sum']"
61,When is the quotient ring finite?,When is the quotient ring finite?,,"My question is in the title: Given a commutative ring $R$ with identity $1\neq 0$ and an ideal $M$ of $R$. For what condition of $M$, the quotient ring $R/M$ is finite? My question comes from the theorem: if $M$ is a maximal ideal, then $M$ is a prime ideal. In general, the converse is not true. However, we know that if $M$ is a prime ideal then $R/M$ is an integral domain, and if $R/M$ is also finite, then it is a field, and the converse holds. Thank you so much for any help.","My question is in the title: Given a commutative ring $R$ with identity $1\neq 0$ and an ideal $M$ of $R$. For what condition of $M$, the quotient ring $R/M$ is finite? My question comes from the theorem: if $M$ is a maximal ideal, then $M$ is a prime ideal. In general, the converse is not true. However, we know that if $M$ is a prime ideal then $R/M$ is an integral domain, and if $R/M$ is also finite, then it is a field, and the converse holds. Thank you so much for any help.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
62,Hecke characters of imaginary quadratic fields,Hecke characters of imaginary quadratic fields,,"Let $K$ be a number field and let $\mathfrak m$ be an integral ideal. Let $I(\mathfrak m)$ be the group of fractional ideals of $K$ coprime with $\mathfrak m$. Let $P(\mathfrak m)$ be the group of principal fractional ideals coprime with $\mathfrak m$. Finally, let $K_{\mathfrak m}$ be the set of elements of $K$ which are coprime with $\mathfrak m$. Recall that there is a map $K\to \mathbb R\otimes K\simeq (\mathbb R)^{r_1}\times (\mathbb C)^{r_2}$ which sends $\alpha\mapsto 1\otimes\alpha$ where $r_1$ (resp. $r_2$) is the number of real (resp. complex) places of $K$. A Hecke character of $K$ of conductor $\mathfrak m$ and infinity type $\chi_{\infty}$ is a homomorphism $$\chi\colon I(\mathfrak m)\to \mathbb C^*$$ such that there exists a continuous homomorphism $$\chi_{\infty}\colon (\mathbb R^*)^{r_1}\times (\mathbb C^*)^{r_2}\to \mathbb C^*$$ with the property that $$\chi((\alpha))=\chi_{\infty}(1\otimes \alpha)^{-1} \text{ for all }\alpha \in K_{\mathfrak m}$$ Now my question is the following: assume that $K$ is an imaginary quadratic field. How do I know that there exist nontrivial Hecke characters on $K$? When $K$ has class number $1$ everything is easy, for example when $K=\mathbb Q(i)\subseteq \mathbb C$ one can just take $\mathfrak m=\mathcal O_K$ and $\chi_n(\alpha)=\left(\frac{\alpha}{|\alpha|}\right)^{4n}$ for $n\in \mathbb Z$. Then $\chi_{n,\infty}(\alpha)=(\alpha/|\alpha|)^{-4n}$ and we're ok. But what happens in the general case? Is it possible to write down explicitely a nontrivial Hecke character? And is it true that given an infinity type $\chi_{\infty}$ there always exist a Hecke character with infinity type $\chi_{\infty}$?","Let $K$ be a number field and let $\mathfrak m$ be an integral ideal. Let $I(\mathfrak m)$ be the group of fractional ideals of $K$ coprime with $\mathfrak m$. Let $P(\mathfrak m)$ be the group of principal fractional ideals coprime with $\mathfrak m$. Finally, let $K_{\mathfrak m}$ be the set of elements of $K$ which are coprime with $\mathfrak m$. Recall that there is a map $K\to \mathbb R\otimes K\simeq (\mathbb R)^{r_1}\times (\mathbb C)^{r_2}$ which sends $\alpha\mapsto 1\otimes\alpha$ where $r_1$ (resp. $r_2$) is the number of real (resp. complex) places of $K$. A Hecke character of $K$ of conductor $\mathfrak m$ and infinity type $\chi_{\infty}$ is a homomorphism $$\chi\colon I(\mathfrak m)\to \mathbb C^*$$ such that there exists a continuous homomorphism $$\chi_{\infty}\colon (\mathbb R^*)^{r_1}\times (\mathbb C^*)^{r_2}\to \mathbb C^*$$ with the property that $$\chi((\alpha))=\chi_{\infty}(1\otimes \alpha)^{-1} \text{ for all }\alpha \in K_{\mathfrak m}$$ Now my question is the following: assume that $K$ is an imaginary quadratic field. How do I know that there exist nontrivial Hecke characters on $K$? When $K$ has class number $1$ everything is easy, for example when $K=\mathbb Q(i)\subseteq \mathbb C$ one can just take $\mathfrak m=\mathcal O_K$ and $\chi_n(\alpha)=\left(\frac{\alpha}{|\alpha|}\right)^{4n}$ for $n\in \mathbb Z$. Then $\chi_{n,\infty}(\alpha)=(\alpha/|\alpha|)^{-4n}$ and we're ok. But what happens in the general case? Is it possible to write down explicitely a nontrivial Hecke character? And is it true that given an infinity type $\chi_{\infty}$ there always exist a Hecke character with infinity type $\chi_{\infty}$?",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
63,Why would we a priori expect $V(I)$ to satisfy axioms to define the closed sets for a topology on $\text{Proj}(S)$?,Why would we a priori expect  to satisfy axioms to define the closed sets for a topology on ?,V(I) \text{Proj}(S),"The topological space $\text{Proj}(S)$ has the underlying set$$\text{Proj}(S) = \{\mathfrak{p} \text{ a homogeneous prime such that }S_+ \not\subseteq \mathfrak{p}\},$$and the closed sets are the loci $V(I) = \{\mathfrak{p} \in \text{Proj}(S) : I \subseteq \mathfrak{p}\}$ for homogeneous ideals $I$ of $S$, where $S$ is an $\mathbf{N}$-graded ring. Perhaps this question is a bit silly since its such a straightforward check, but why would we a priori, intuitively and/or geometrically, expect such $V(I)$'s to satisfy the axioms to define the closed sets for a topology on $\text{Proj}(S)$? Edit: The comment by Hoot mentions schemes. Could I have an explanation that tries to avoid schemes if possible? Edit: Someone typed out a perfectly good response only to have deleted it? Why?","The topological space $\text{Proj}(S)$ has the underlying set$$\text{Proj}(S) = \{\mathfrak{p} \text{ a homogeneous prime such that }S_+ \not\subseteq \mathfrak{p}\},$$and the closed sets are the loci $V(I) = \{\mathfrak{p} \in \text{Proj}(S) : I \subseteq \mathfrak{p}\}$ for homogeneous ideals $I$ of $S$, where $S$ is an $\mathbf{N}$-graded ring. Perhaps this question is a bit silly since its such a straightforward check, but why would we a priori, intuitively and/or geometrically, expect such $V(I)$'s to satisfy the axioms to define the closed sets for a topology on $\text{Proj}(S)$? Edit: The comment by Hoot mentions schemes. Could I have an explanation that tries to avoid schemes if possible? Edit: Someone typed out a perfectly good response only to have deleted it? Why?",,['abstract-algebra']
64,Reducible polynomials in $\mathbb{Z}[X]$,Reducible polynomials in,\mathbb{Z}[X],"Let $(a_n)_{n\geq 1}$ be a strictly increasing sequence of integers and $k$ an integer different from $0$. There exists among the polynomials    $$ (X-a_1)(X-a_2)\cdots(X-a_n)+k,\ n\geq 1 $$   only a finite number of reducible polynomials in $\mathbb{Z}[X]$? I think this must be true, but I have yet no proof. Any idea / solution? Thank you! Nicholas Tatsis","Let $(a_n)_{n\geq 1}$ be a strictly increasing sequence of integers and $k$ an integer different from $0$. There exists among the polynomials    $$ (X-a_1)(X-a_2)\cdots(X-a_n)+k,\ n\geq 1 $$   only a finite number of reducible polynomials in $\mathbb{Z}[X]$? I think this must be true, but I have yet no proof. Any idea / solution? Thank you! Nicholas Tatsis",,"['abstract-algebra', 'polynomials', 'factoring', 'irreducible-polynomials']"
65,Intuitive explanation of Four Lemma,Intuitive explanation of Four Lemma,,"In the Short Five Lemma where the rows are exact, it is a fact that  $$\alpha \text{ and }\gamma \text{ injective (surjective) }\implies \beta \text{ injective (surjective)}.$$ I've heard this fact summarized as ""if $\beta\left.\right|_A$ is injective (surjective) and $\tilde{\beta}:B/A \to B'/\beta(A)$ is injective (surjective), then $\beta$ is injective (surjective)"". This explanation makes a good deal of sense to me, and I'm looking for a similar explanation for the four lemma , and also for questions like this: In these cases, we could talk about $B$ containing $A / \ker \psi$, and induced maps on this. Is this the way to go? Would it be advantageous to consider this from a categorical perspective? I'm trying to have exercises like the above be not a collection of random facts, but a picture of what's really going on, and explanations like the one above are very helpful.","In the Short Five Lemma where the rows are exact, it is a fact that  $$\alpha \text{ and }\gamma \text{ injective (surjective) }\implies \beta \text{ injective (surjective)}.$$ I've heard this fact summarized as ""if $\beta\left.\right|_A$ is injective (surjective) and $\tilde{\beta}:B/A \to B'/\beta(A)$ is injective (surjective), then $\beta$ is injective (surjective)"". This explanation makes a good deal of sense to me, and I'm looking for a similar explanation for the four lemma , and also for questions like this: In these cases, we could talk about $B$ containing $A / \ker \psi$, and induced maps on this. Is this the way to go? Would it be advantageous to consider this from a categorical perspective? I'm trying to have exercises like the above be not a collection of random facts, but a picture of what's really going on, and explanations like the one above are very helpful.",,"['abstract-algebra', 'category-theory', 'modules', 'homological-algebra']"
66,Commutative generators of a group,Commutative generators of a group,,"If a group has commutative generators is the group always abelian? I have a question dealing with how to determine if a Cayley graph of a group is an abelian group. It seems that if the generators commute then the entire group will be abelian because all elements will be a ""power"" of the generators.","If a group has commutative generators is the group always abelian? I have a question dealing with how to determine if a Cayley graph of a group is an abelian group. It seems that if the generators commute then the entire group will be abelian because all elements will be a ""power"" of the generators.",,"['abstract-algebra', 'group-theory']"
67,Finitely generated graded modules over $K[x]$,Finitely generated graded modules over,K[x],"I need some help on this exercise from A Course in Ring Theory by Donald S. Passman Find all finitely generated graded $K[x]$-modules up to abstract isomorphism. Remember, $K[x]$ is a principal ideal domain. The result is supposedly similar to the well-known structure theorem in the non-graded case. So let $M$ be a finitely generated $K[x]$-module with a minimal generating set of homogeneous elements $\alpha_1, \ldots, \alpha_n$ with $d_i$ the degree of $\alpha_i$ (such a set exists because every element of M is a sum of homogeneous elements). We then get a surjective graded homomorphism $$\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n) \to M,\;e_i \mapsto \alpha_i,$$ where $K[x](d_i)$ denotes the graded module $K[x]$ with its grading shifted upwards by $d_i$ and $e_i = (0,\ldots,1,\ldots,0)$. So the homomorphism theorem for graded modules states that $M$ is - as a graded $K[x]$-module - isomorphic to $$\left(\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n)\right)/\ker(\phi).$$ How do I go on now? Obviously $\ker(\phi)$ is a graded submodule of something like a free-graded $K[x]$-module . Is there maybe an analogue to the elementary divisors theorem for the graded case which lets me express this quotient in a nice way ? Thanks for helping me out!","I need some help on this exercise from A Course in Ring Theory by Donald S. Passman Find all finitely generated graded $K[x]$-modules up to abstract isomorphism. Remember, $K[x]$ is a principal ideal domain. The result is supposedly similar to the well-known structure theorem in the non-graded case. So let $M$ be a finitely generated $K[x]$-module with a minimal generating set of homogeneous elements $\alpha_1, \ldots, \alpha_n$ with $d_i$ the degree of $\alpha_i$ (such a set exists because every element of M is a sum of homogeneous elements). We then get a surjective graded homomorphism $$\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n) \to M,\;e_i \mapsto \alpha_i,$$ where $K[x](d_i)$ denotes the graded module $K[x]$ with its grading shifted upwards by $d_i$ and $e_i = (0,\ldots,1,\ldots,0)$. So the homomorphism theorem for graded modules states that $M$ is - as a graded $K[x]$-module - isomorphic to $$\left(\phi \colon K[x](d_1) \oplus \ldots \oplus K[x](d_n)\right)/\ker(\phi).$$ How do I go on now? Obviously $\ker(\phi)$ is a graded submodule of something like a free-graded $K[x]$-module . Is there maybe an analogue to the elementary divisors theorem for the graded case which lets me express this quotient in a nice way ? Thanks for helping me out!",,"['abstract-algebra', 'principal-ideal-domains', 'finitely-generated', 'graded-modules']"
68,Homogeneous polynomials between vector spaces,Homogeneous polynomials between vector spaces,,"Consider $\mathbb{C}$ vector space $V$ = span$(e_1,\cdots,e_n)$. Consider the following algebra embedding $$ \mathbb{C}[X_1,\cdots,X_n]\hookrightarrow F(V,\mathbb{C})$$ where $f\mapsto(\sum_i a_i e_i\mapsto f(a_1,\cdots,a_n))$. Denote the image as $O(V)$, call its elements polynomials on $V$. Define a polynomial to be homogeneous of degree $p$ if $f(tv) = t^p f(v)$ for all $v\in V$ and $t\in\mathbb{C}$. I'm thinking about a different way of characterizing homogenous polynomials of degree $p$. Consider the map $i_p:V\to S^p(V)$ sending $v\mapsto \underbrace{v\otimes\cdots\otimes v}_{p}$, if we have any linear map $g:S^p(V)\to \mathbb{C}$, then I want to show 1) $g\circ i_p$ is indeed in $O(V)$ (and clearly homogeneous of degree p) 2) Every homogeneous polynomial can be obtained this way. Is the above true, and how to show that? If indeed true, then I can generalize and define homogeneous polynomials of degree p from $V$ to a vector space $W$ using the second way. Define a function $f$ to be polynomial of degree $p$ from $V$ to $W$ if there is linear map $g:S^p(V)\to W$ such that $f = g\circ i_p$. Is this the same as all function from $V$ to $W$ such that $f(tv) = t^pf(v)$ for all $v\in V$ and $t\in\mathbb{C}$? And is this a good way to define the space of homogeneous polynomials between two vector spaces?","Consider $\mathbb{C}$ vector space $V$ = span$(e_1,\cdots,e_n)$. Consider the following algebra embedding $$ \mathbb{C}[X_1,\cdots,X_n]\hookrightarrow F(V,\mathbb{C})$$ where $f\mapsto(\sum_i a_i e_i\mapsto f(a_1,\cdots,a_n))$. Denote the image as $O(V)$, call its elements polynomials on $V$. Define a polynomial to be homogeneous of degree $p$ if $f(tv) = t^p f(v)$ for all $v\in V$ and $t\in\mathbb{C}$. I'm thinking about a different way of characterizing homogenous polynomials of degree $p$. Consider the map $i_p:V\to S^p(V)$ sending $v\mapsto \underbrace{v\otimes\cdots\otimes v}_{p}$, if we have any linear map $g:S^p(V)\to \mathbb{C}$, then I want to show 1) $g\circ i_p$ is indeed in $O(V)$ (and clearly homogeneous of degree p) 2) Every homogeneous polynomial can be obtained this way. Is the above true, and how to show that? If indeed true, then I can generalize and define homogeneous polynomials of degree p from $V$ to a vector space $W$ using the second way. Define a function $f$ to be polynomial of degree $p$ from $V$ to $W$ if there is linear map $g:S^p(V)\to W$ such that $f = g\circ i_p$. Is this the same as all function from $V$ to $W$ such that $f(tv) = t^pf(v)$ for all $v\in V$ and $t\in\mathbb{C}$? And is this a good way to define the space of homogeneous polynomials between two vector spaces?",,"['abstract-algebra', 'algebraic-geometry', 'polynomials']"
69,Ultraproduct of the algebraic closure of finite fields,Ultraproduct of the algebraic closure of finite fields,,"Ok, I have done a little research on the next problem, and there are simple proofs of it using model theory, logic and the Łoś's theorem. But here, the idea is to prove it using only Field Theory, Galois Theory and the basic theory of transcendental extensions. This is the problem: Let $W$ be the set of prime numbers and let $\mathfrak{U}$ be a non principal ultrafilter over $W$. For every prime $p$, let $\overline{\mathbb{F}_p}$ denote an algebraic closure of $\mathbb{F}_p$. In the following product $$ \prod_{p\in W} \overline{\mathbb{F}_p}, $$ define the equivalence relation $(a_p)\sim (b_p)$ if and only if $\{p\in W: a_p=b_p\}$ belongs to $\mathfrak{U}$. Let $$ A=\prod_{p \in W} \overline{\mathbb{F}_p} ~/~ \sim $$ denote the set of equivalence classes, such that $[a_p]$ is the class of $(a_p)$. Show that $A$ is not countable. Show that $A$ is isomorphic to $\mathbb{C}$. Proving that the addition and product ($[a_p]+[b_p]=[a_p+b_p]$, $[a_p][b_p]=[a_pb_p]$) are well defined on $A$ and that $\text{char}(A)=0$ is tedious but quiet straightforward. On the other hand proving (1) and (2) has been a rather difficult task. For (1), I honestly have no idea how to proceed; and for (2) I've tried using the fact that $\mathbb{C}$ has an infinite number of automorphism, but I haven't had any luck. Also I think that in order to prove (2) I actually need to show that $|A|=2^{\aleph_0}$. Any suggestions on how to proceed will be really appreciated. Thanks in advance for any help you provide.","Ok, I have done a little research on the next problem, and there are simple proofs of it using model theory, logic and the Łoś's theorem. But here, the idea is to prove it using only Field Theory, Galois Theory and the basic theory of transcendental extensions. This is the problem: Let $W$ be the set of prime numbers and let $\mathfrak{U}$ be a non principal ultrafilter over $W$. For every prime $p$, let $\overline{\mathbb{F}_p}$ denote an algebraic closure of $\mathbb{F}_p$. In the following product $$ \prod_{p\in W} \overline{\mathbb{F}_p}, $$ define the equivalence relation $(a_p)\sim (b_p)$ if and only if $\{p\in W: a_p=b_p\}$ belongs to $\mathfrak{U}$. Let $$ A=\prod_{p \in W} \overline{\mathbb{F}_p} ~/~ \sim $$ denote the set of equivalence classes, such that $[a_p]$ is the class of $(a_p)$. Show that $A$ is not countable. Show that $A$ is isomorphic to $\mathbb{C}$. Proving that the addition and product ($[a_p]+[b_p]=[a_p+b_p]$, $[a_p][b_p]=[a_pb_p]$) are well defined on $A$ and that $\text{char}(A)=0$ is tedious but quiet straightforward. On the other hand proving (1) and (2) has been a rather difficult task. For (1), I honestly have no idea how to proceed; and for (2) I've tried using the fact that $\mathbb{C}$ has an infinite number of automorphism, but I haven't had any luck. Also I think that in order to prove (2) I actually need to show that $|A|=2^{\aleph_0}$. Any suggestions on how to proceed will be really appreciated. Thanks in advance for any help you provide.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'finite-fields', 'filters']"
70,Galois group of $f(x) = x^5 + x - 1$ over $\mathbb{Q}$,Galois group of  over,f(x) = x^5 + x - 1 \mathbb{Q},"I'm trying to compute the Galois group of the quintic polynomial $f(x) = x^5 + x - 1$. I first decomposed $f(x)$ into irreducible factors $f(x) = g(x)h(x)$ where $g(x) = x^2 - x + 1$ and $h(x) = x^3 + x^2 - 1$. I denoted by $K_g$, $K_h$ the splitting fields of $g(x), h(x)$ over $\mathbb{Q}$, respectively, and saw that $G_g = {\rm Gal}(K_g/\mathbb{Q}) \cong \mathbb{Z}_2$, $G_h = {\rm Gal}(K_h/\mathbb{Q}) \cong S_3$ where $S_3$ is the symmetric group on three letters. Then the splitting field of $f(x)$ over $\mathbb{Q}$ is $K_gK_h$ (compositum). Guessing that the Galois group $G_f$ of $f(x)$ is $\mathbb{Z}_2 \times S_3$, I have tried to show that $K_g \cap K_h = \mathbb{Q}$. Actually, it suffices to show that $\sqrt{-3}$ does not belong to $K_h$ but I'm stuck on here. Could anyone give me an idea? (If $K_g \cap K_h \neq \mathbb{Q}$, then $\mathbb{Q} \subsetneq K_g \subsetneq K_h$, so Galois theorem asserts ${\rm Gal}(K_h/K_g) \cong A_3$, but failed to reach a contradiction.) Thank for your answer.","I'm trying to compute the Galois group of the quintic polynomial $f(x) = x^5 + x - 1$. I first decomposed $f(x)$ into irreducible factors $f(x) = g(x)h(x)$ where $g(x) = x^2 - x + 1$ and $h(x) = x^3 + x^2 - 1$. I denoted by $K_g$, $K_h$ the splitting fields of $g(x), h(x)$ over $\mathbb{Q}$, respectively, and saw that $G_g = {\rm Gal}(K_g/\mathbb{Q}) \cong \mathbb{Z}_2$, $G_h = {\rm Gal}(K_h/\mathbb{Q}) \cong S_3$ where $S_3$ is the symmetric group on three letters. Then the splitting field of $f(x)$ over $\mathbb{Q}$ is $K_gK_h$ (compositum). Guessing that the Galois group $G_f$ of $f(x)$ is $\mathbb{Z}_2 \times S_3$, I have tried to show that $K_g \cap K_h = \mathbb{Q}$. Actually, it suffices to show that $\sqrt{-3}$ does not belong to $K_h$ but I'm stuck on here. Could anyone give me an idea? (If $K_g \cap K_h \neq \mathbb{Q}$, then $\mathbb{Q} \subsetneq K_g \subsetneq K_h$, so Galois theorem asserts ${\rm Gal}(K_h/K_g) \cong A_3$, but failed to reach a contradiction.) Thank for your answer.",,['abstract-algebra']
71,Classify Finite Abelian Groups of Order 8,Classify Finite Abelian Groups of Order 8,,"Without using the fundamental theorem of finite abelian groups, show that, if $G$ is a finite abelian group of order 8, then $G$ is isomorphic to one of $\mathbb{Z} / 8\mathbb{Z}$, $\mathbb{Z} / 4\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z}$, or $\mathbb{Z} / 2\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z}$ I started by choosing some element $e \neq g \in G$.  By Lagrange's theorem, the order of $g$ is either $2$, $4$, or $8$.  If the order of $g$ is $8$, then $\langle g \rangle = G$, and so $G \cong \mathbb{Z} / 8 \mathbb{Z}$.  I'm not totally sure what to do next.  If the order of $g$ is $2$, do I consider $G / \langle g \rangle$ and show that this quotient is isomorphic to $\mathbb{Z} / 4 \mathbb{Z}$ or $\mathbb{Z} / 2 \mathbb{Z} \times \mathbb{Z} / 2 \mathbb{Z}$?","Without using the fundamental theorem of finite abelian groups, show that, if $G$ is a finite abelian group of order 8, then $G$ is isomorphic to one of $\mathbb{Z} / 8\mathbb{Z}$, $\mathbb{Z} / 4\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z}$, or $\mathbb{Z} / 2\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z} \times \mathbb{Z} / 2\mathbb{Z}$ I started by choosing some element $e \neq g \in G$.  By Lagrange's theorem, the order of $g$ is either $2$, $4$, or $8$.  If the order of $g$ is $8$, then $\langle g \rangle = G$, and so $G \cong \mathbb{Z} / 8 \mathbb{Z}$.  I'm not totally sure what to do next.  If the order of $g$ is $2$, do I consider $G / \langle g \rangle$ and show that this quotient is isomorphic to $\mathbb{Z} / 4 \mathbb{Z}$ or $\mathbb{Z} / 2 \mathbb{Z} \times \mathbb{Z} / 2 \mathbb{Z}$?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
72,$\operatorname{Aut}(G)$ contains an involution $\sigma$ with no nontrivial fixed point,contains an involution  with no nontrivial fixed point,\operatorname{Aut}(G) \sigma,"I am just reading some algebra books on my own, and it seems the following exercise appears in so many of them: Let $G$ be a finite group with $\sigma\in\operatorname{Aut}(G)$ satisfying 1)$\sigma^2=\text{id}$ and 2)$\sigma(g)\neq g$ for $g\neq e$. Prove $G$ is abelian. The proof itself is not so difficult, but I am wondering whether this statement is of some importance. Searching for such a $\sigma\in\operatorname{Aut}(G)$ does not seem to me to be a very efficient way to show $G$ is abelian. So does this statement have some nice applications? Why does it appear in so many algebra books? Thanks!","I am just reading some algebra books on my own, and it seems the following exercise appears in so many of them: Let $G$ be a finite group with $\sigma\in\operatorname{Aut}(G)$ satisfying 1)$\sigma^2=\text{id}$ and 2)$\sigma(g)\neq g$ for $g\neq e$. Prove $G$ is abelian. The proof itself is not so difficult, but I am wondering whether this statement is of some importance. Searching for such a $\sigma\in\operatorname{Aut}(G)$ does not seem to me to be a very efficient way to show $G$ is abelian. So does this statement have some nice applications? Why does it appear in so many algebra books? Thanks!",,"['abstract-algebra', 'group-theory', 'reference-request', 'finite-groups']"
73,"Construction(s) of new integral domains from ""old ones""","Construction(s) of new integral domains from ""old ones""",,"Given an integral domain $D$, there are several ways how to construct a new integral domain related to D. For example, one can consider a ring of polynomials/formal power series/formal Laurent series in one/two/infinite indeterminates, a localization $S^{-1}D$, where $S \subseteq D$ is some multiplicatively closed subset, etc. Note that all these constructions ""depend"" only on one domain, i.e. $D$. In the case of general rings, there is in a way much more possibilities: Since category of rings is both complete and co-complete, one can consider limits/colimits of arbitrary diagram in $\mathcal{Ring}$. In particular, it is possible to have products of arbitrary nonempty family of rings. This is, however, almost never an integral domain (i.e. if the family contains at least two rings). So the question is the following: Is there some universal construction, which, given two or more abstract integral domains, produces a new integral domain, related to the given ones? By abstract domains I mean that the construction does not assume some relation between the domains (i.e. one doesn't need to be, for example, subring of the other, so that the construction would produce some ring in between). By universal I mean that the construction does not assume much about the structure of the given domains except the fact that they are domains (for example, does not need them to be of the form $F[x], K[x]$ for some fields $F,K$). (In fact, if the ""initial"" rings were not domains and the resulting ring would be, such construction would interest me as well). Edit: An example I encountered is: Ultraproduct of collection of integral domains is again an integral domain. This construction satisfies the conditions universal and abstract as I described them, however, it can give a ""new"" domain only if we consider infinite collections of domains. Another interesting example is mentioned by Zhen Lin in comments.","Given an integral domain $D$, there are several ways how to construct a new integral domain related to D. For example, one can consider a ring of polynomials/formal power series/formal Laurent series in one/two/infinite indeterminates, a localization $S^{-1}D$, where $S \subseteq D$ is some multiplicatively closed subset, etc. Note that all these constructions ""depend"" only on one domain, i.e. $D$. In the case of general rings, there is in a way much more possibilities: Since category of rings is both complete and co-complete, one can consider limits/colimits of arbitrary diagram in $\mathcal{Ring}$. In particular, it is possible to have products of arbitrary nonempty family of rings. This is, however, almost never an integral domain (i.e. if the family contains at least two rings). So the question is the following: Is there some universal construction, which, given two or more abstract integral domains, produces a new integral domain, related to the given ones? By abstract domains I mean that the construction does not assume some relation between the domains (i.e. one doesn't need to be, for example, subring of the other, so that the construction would produce some ring in between). By universal I mean that the construction does not assume much about the structure of the given domains except the fact that they are domains (for example, does not need them to be of the form $F[x], K[x]$ for some fields $F,K$). (In fact, if the ""initial"" rings were not domains and the resulting ring would be, such construction would interest me as well). Edit: An example I encountered is: Ultraproduct of collection of integral domains is again an integral domain. This construction satisfies the conditions universal and abstract as I described them, however, it can give a ""new"" domain only if we consider infinite collections of domains. Another interesting example is mentioned by Zhen Lin in comments.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'soft-question']"
74,Degree of transitive constituents is odd implies $|G|$ is odd,Degree of transitive constituents is odd implies  is odd,|G|,"I want to prove that: the order of a permutation group $G \le S^\Omega$ is odd if and only if the degrees of all transitive constituents of $G$ and the degrees of all transitive constituents of each $G_\alpha (\alpha \in \Omega)$ are odd.  This is Exercise 3.13 in Wielandt's text. (Let me recall that if $\Delta \subseteq \Omega$ is a fixed block of $G$, then $G$ restricted to $\Delta$, denoted $G^\Delta$, is called a constituent.  It is transitive iff $\Delta$ is a minimal fixed block (i.e. an orbit).  So the assertion asks to show that $|G|$ is odd iff each orbit of $G$ and each orbit of each $G_\alpha$ has odd length.) The hint given is to use these three facts: (i) $|G_\alpha|~|\alpha^G|=|G|$. (ii) $|G:G_{\alpha \beta}| = |\alpha^G| |\beta^{G_\alpha}| = |\beta^G| |\alpha^{G_\beta}|$. (iii) If prime $p$ divides $|G|$, then $G$ contains an element whose cycle decomposition contains a $p$-cycle. The implication is proved using (ii): If $|\alpha^G|$ or $|\beta^{G_\alpha}|$ is even for any $\alpha,\beta$, then by (ii) $|G|$ is even.  How do I prove the converse?","I want to prove that: the order of a permutation group $G \le S^\Omega$ is odd if and only if the degrees of all transitive constituents of $G$ and the degrees of all transitive constituents of each $G_\alpha (\alpha \in \Omega)$ are odd.  This is Exercise 3.13 in Wielandt's text. (Let me recall that if $\Delta \subseteq \Omega$ is a fixed block of $G$, then $G$ restricted to $\Delta$, denoted $G^\Delta$, is called a constituent.  It is transitive iff $\Delta$ is a minimal fixed block (i.e. an orbit).  So the assertion asks to show that $|G|$ is odd iff each orbit of $G$ and each orbit of each $G_\alpha$ has odd length.) The hint given is to use these three facts: (i) $|G_\alpha|~|\alpha^G|=|G|$. (ii) $|G:G_{\alpha \beta}| = |\alpha^G| |\beta^{G_\alpha}| = |\beta^G| |\alpha^{G_\beta}|$. (iii) If prime $p$ divides $|G|$, then $G$ contains an element whose cycle decomposition contains a $p$-cycle. The implication is proved using (ii): If $|\alpha^G|$ or $|\beta^{G_\alpha}|$ is even for any $\alpha,\beta$, then by (ii) $|G|$ is even.  How do I prove the converse?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
75,The index of $\xi_4^*$ in $\xi_4$,The index of  in,\xi_4^* \xi_4,"Just seeing if i'm right: With the set of solutions for $z^4=1$: $\xi_4=\{1,i,-1,-i\}$, one can construct the group of the $4$th roots of unity: $(\xi_4,\cdot_\mathbb{C})$ and its multiplicative subgroup $(\xi_4^*,\cdot_\mathbb{C})$ with $\xi_4^*=\{1,-1\}$. What is the Index $[ \xi_4 : \xi_4^* ]$? I'd say through Lagrange: $$ [ \xi_4 : \xi_4^* ] =\frac{|\xi_4|}{|\xi_4^*|}=\frac{4}{2}=2.$$ Or counting the cosets of $\xi_4^*$:  $$1\cdot\xi_4^*=\{1,-1\}= -1\cdot\xi_4^*,\quad i\cdot\xi_4^*=\{i,-i\}= -i\cdot\xi_4^*$$ we get two. Is this correct?","Just seeing if i'm right: With the set of solutions for $z^4=1$: $\xi_4=\{1,i,-1,-i\}$, one can construct the group of the $4$th roots of unity: $(\xi_4,\cdot_\mathbb{C})$ and its multiplicative subgroup $(\xi_4^*,\cdot_\mathbb{C})$ with $\xi_4^*=\{1,-1\}$. What is the Index $[ \xi_4 : \xi_4^* ]$? I'd say through Lagrange: $$ [ \xi_4 : \xi_4^* ] =\frac{|\xi_4|}{|\xi_4^*|}=\frac{4}{2}=2.$$ Or counting the cosets of $\xi_4^*$:  $$1\cdot\xi_4^*=\{1,-1\}= -1\cdot\xi_4^*,\quad i\cdot\xi_4^*=\{i,-i\}= -i\cdot\xi_4^*$$ we get two. Is this correct?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
76,$S$-Units notation and Dirichlet's unit theorem,-Units notation and Dirichlet's unit theorem,S,"I'm having a hard time understanding some notions of a paper I'm working on. Let $L/K$ be a finite normal extension of number fields and $S$ be a set of places of $K$ prime to $p$ where $p$ denotes an odd prime. The author defines a group $$R_{K,S} = \{x \in \mathbb{Z}_p \otimes E_K, x \equiv 1 \mod \nu, \nu \in S\}$$ where $E_K$ denotes the groups of units of $K$. Several questions arise: 1) Is $R_{K,S}$ equal the groups of $S$-units of $K$, $\mathcal{O}_{K,S}^\times = \{a\in K, v_{\mathfrak{p}}(a) = 0 \  \forall \mathfrak{p} \notin S \}$ as defined on page 451 of Neukirch, Schmidt, Wingberg: Cohomology of Number Fields, tensored with $\mathbb{Z}_p$? 2) What ""happens"" when tensoring over $\mathbb{Z}_p$? I know that you can make any group into a $\mathbb{Z}_p$-module but is there any intuition why one would do that? Does the above group arise naturally as a kernel of some map? 3) Is there a more natural notion of the above group in terms of ideles? 4) A general question on Dirichlet's unit theorem for $S$-units: Is there a version without any constraints on $S$, i.e. without having to assume that the archimedian places are in $S$, i.e. $S_\infty \subset S$? EDIT : Is $x \equiv 1 \mod \nu$ for $\nu \in S$ just an untypical notion of $S$ being a modulus $S = \prod_{\nu} \nu$? Thank you for your help! :) Tom EDIT (11/29/2013) : For 1): My guess (above) is not right, but: Is $R_{K,S} = E_{K,S,1} \otimes \Bbb Z_p$, where $E_{K,S,1}$ denote the subgroup of $E_K$ that are principal units at every place $\nu \in S$? For 2): I know now that tensoring over $\Bbb Z_p$ kills the prime-to-$p$-part and every module becomes a $\Bbb Z_p$-module, one can therefore speak of the $\Bbb Z_p$-rank of every module. For 4): I now know that there can't be any version without the infinite places, because they are essential to the proof. But how can I actually use the Dirichlet unit theorem as stated in Neukirch, Schmidt, Wingberg: Cohomology of Number Fields 2nd edition 2008 , proposition (8.7.2) to compute the $\Bbb Z_p$-rank of a $\Bbb Z_p$-submodule of $\mathcal{O}_{K,S}^\times$ of finite index?","I'm having a hard time understanding some notions of a paper I'm working on. Let $L/K$ be a finite normal extension of number fields and $S$ be a set of places of $K$ prime to $p$ where $p$ denotes an odd prime. The author defines a group $$R_{K,S} = \{x \in \mathbb{Z}_p \otimes E_K, x \equiv 1 \mod \nu, \nu \in S\}$$ where $E_K$ denotes the groups of units of $K$. Several questions arise: 1) Is $R_{K,S}$ equal the groups of $S$-units of $K$, $\mathcal{O}_{K,S}^\times = \{a\in K, v_{\mathfrak{p}}(a) = 0 \  \forall \mathfrak{p} \notin S \}$ as defined on page 451 of Neukirch, Schmidt, Wingberg: Cohomology of Number Fields, tensored with $\mathbb{Z}_p$? 2) What ""happens"" when tensoring over $\mathbb{Z}_p$? I know that you can make any group into a $\mathbb{Z}_p$-module but is there any intuition why one would do that? Does the above group arise naturally as a kernel of some map? 3) Is there a more natural notion of the above group in terms of ideles? 4) A general question on Dirichlet's unit theorem for $S$-units: Is there a version without any constraints on $S$, i.e. without having to assume that the archimedian places are in $S$, i.e. $S_\infty \subset S$? EDIT : Is $x \equiv 1 \mod \nu$ for $\nu \in S$ just an untypical notion of $S$ being a modulus $S = \prod_{\nu} \nu$? Thank you for your help! :) Tom EDIT (11/29/2013) : For 1): My guess (above) is not right, but: Is $R_{K,S} = E_{K,S,1} \otimes \Bbb Z_p$, where $E_{K,S,1}$ denote the subgroup of $E_K$ that are principal units at every place $\nu \in S$? For 2): I know now that tensoring over $\Bbb Z_p$ kills the prime-to-$p$-part and every module becomes a $\Bbb Z_p$-module, one can therefore speak of the $\Bbb Z_p$-rank of every module. For 4): I now know that there can't be any version without the infinite places, because they are essential to the proof. But how can I actually use the Dirichlet unit theorem as stated in Neukirch, Schmidt, Wingberg: Cohomology of Number Fields 2nd edition 2008 , proposition (8.7.2) to compute the $\Bbb Z_p$-rank of a $\Bbb Z_p$-submodule of $\mathcal{O}_{K,S}^\times$ of finite index?",,"['abstract-algebra', 'number-theory', 'p-adic-number-theory', 'class-field-theory']"
77,Automorphisms of composite fields of finite extensions,Automorphisms of composite fields of finite extensions,,"If $\phi:\mathbb{Q}(a_1\ldots,a_n)\rightarrow\mathbb{Q}(b_1,\ldots,b_n)$ is an isomorphism of finite extensions of $\mathbb{Q}$ such that $\phi(a_i)=b_i$, can one extend $\phi$ to an automorphism $\sigma$ of the composite $\mathbb{Q}(a_1,\ldots,a_n,b_1,\ldots,b_n)$? Is ther an obvious counter-example?","If $\phi:\mathbb{Q}(a_1\ldots,a_n)\rightarrow\mathbb{Q}(b_1,\ldots,b_n)$ is an isomorphism of finite extensions of $\mathbb{Q}$ such that $\phi(a_i)=b_i$, can one extend $\phi$ to an automorphism $\sigma$ of the composite $\mathbb{Q}(a_1,\ldots,a_n,b_1,\ldots,b_n)$? Is ther an obvious counter-example?",,"['abstract-algebra', 'field-theory', 'extension-field']"
78,Point Derivation on an Algebra,Point Derivation on an Algebra,,"I want to solve the following exercise. Let A be an $\mathbb{R}$-algebra. A $derivation$ on A is a $\mathbb{R}$-linear map $D: A \to A$ obeying the Leibniz rule   $$  D(ab) = D(a)b + aD(b)  $$   for all $a,b \in A$. Now let M be a manifold. Show that the algebra   $$   C(M) = \{ f: M \to \mathbb{R} : f \textrm{ continuous } \} $$   has no non-trivial derivations, i.e. for every linear map $D : C(M) \to C(M)$ obeying the Leibniz rule, it follows that $D = 0$. Hint: Use that every $f \ge 0$ can be written as a square. I have some difficulties in understanding. I am currently reading about manifolds and tangent spaces, and I read that the tangent space could be defined as the space of all point derivations $D : C^{\infty}(M) \to \mathbb{R}$, but this space is more than just the trivial derivation $D = 0$, does it make a huge difference if I am considering smooth vs. just continuous functions? And in the exercise, how does the hint help me? I can write every $f \ge 0$ as $(\sqrt{f})^2$, and then $$  D(g^2) = 2gD(g) = gD(g+g) $$ with $g = \sqrt{f}$, does it follow that $D = 0$?.","I want to solve the following exercise. Let A be an $\mathbb{R}$-algebra. A $derivation$ on A is a $\mathbb{R}$-linear map $D: A \to A$ obeying the Leibniz rule   $$  D(ab) = D(a)b + aD(b)  $$   for all $a,b \in A$. Now let M be a manifold. Show that the algebra   $$   C(M) = \{ f: M \to \mathbb{R} : f \textrm{ continuous } \} $$   has no non-trivial derivations, i.e. for every linear map $D : C(M) \to C(M)$ obeying the Leibniz rule, it follows that $D = 0$. Hint: Use that every $f \ge 0$ can be written as a square. I have some difficulties in understanding. I am currently reading about manifolds and tangent spaces, and I read that the tangent space could be defined as the space of all point derivations $D : C^{\infty}(M) \to \mathbb{R}$, but this space is more than just the trivial derivation $D = 0$, does it make a huge difference if I am considering smooth vs. just continuous functions? And in the exercise, how does the hint help me? I can write every $f \ge 0$ as $(\sqrt{f})^2$, and then $$  D(g^2) = 2gD(g) = gD(g+g) $$ with $g = \sqrt{f}$, does it follow that $D = 0$?.",,"['abstract-algebra', 'differential-geometry']"
79,Determine the irreducible polynomial for $\alpha=\sqrt{3}+\sqrt{5}$ over $\mathbb{Q}(\sqrt{10})$,Determine the irreducible polynomial for  over,\alpha=\sqrt{3}+\sqrt{5} \mathbb{Q}(\sqrt{10}),"I've already found that the irreducible polynomial of $\alpha$ over $\mathbb{Q}$ is $x^4-16x^2+4$ .  I've also found that $\mathbb{Q}(\sqrt{3}+\sqrt{5})=\mathbb{Q}(\sqrt{3},\sqrt{5})$ and that $\mathbb{Q}(\sqrt{3},\sqrt{5},\sqrt{10})=\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5})$ .  Since $[\mathbb{Q}(\sqrt{10}):\mathbb{Q}]=2$ and $[{\mathbb{Q}(\sqrt{3},\sqrt{5}):\mathbb{Q}}]=4$ , $[\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}):\mathbb{Q}(\sqrt{3},\sqrt{5})]$ must be either 1 or 2. I know it's 2 but I'm having a hard time proving that $\mathbb{Q}(\sqrt{3},\sqrt{5})\neq\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5})$ .  I'm trying to show that $\sqrt{2}\not\in\mathbb{Q}(\sqrt{3},\sqrt{5})$ but I'm not having much luck. The solution in the link below uses a theorem of Galois theory we haven't covered yet so I don't feel comfortable using it.  Here is what we have covered that I suspect is relevant but haven't figured out how to use yet: Let $K$ and $K^\prime$ be extensions of the same field $F$ .  An isomorphism $\varphi:K\to K^\prime$ that restricts to the identity on $F$ is an isomorphism    of field extensions. Let $F$ be a field and $\alpha$ and $\beta$ be elements of field extensions $K/F$ and $L/F$ .  Suppose $\alpha$ an $\beta$ are algebraic over $F$ .  There is an isomorphism of fields $\sigma:F(\alpha)\to F(\beta)$ that is the identity on $F$ and that sends $\alpha\leadsto\beta$ if and only if the irreducible polynomials for $\alpha$ and $\beta$ over $F$ are equal. Let $\varphi:K\to K^\prime$ be an isomorphism of field extensions of $F$ , and let $f$ be a polynomial with coefficients in $F$ . Let $\alpha$ be a root of $f$ in $K$ , and let $\alpha^\prime=\varphi(\alpha)$ be its image in $K^\prime$ .  Then $\alpha^\prime$ is also a root of $f$ . If I start by assuming that $\mathbb{Q}(\sqrt{3},\sqrt{5})=\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5})$ then I suspect the three statements above will lead to a contradiction somewhere.  I just don't have a good firm grasp of how to put them into practice yet. Any help is appreciated.  Thanks,","I've already found that the irreducible polynomial of over is .  I've also found that and that .  Since and , must be either 1 or 2. I know it's 2 but I'm having a hard time proving that .  I'm trying to show that but I'm not having much luck. The solution in the link below uses a theorem of Galois theory we haven't covered yet so I don't feel comfortable using it.  Here is what we have covered that I suspect is relevant but haven't figured out how to use yet: Let and be extensions of the same field .  An isomorphism that restricts to the identity on is an isomorphism    of field extensions. Let be a field and and be elements of field extensions and .  Suppose an are algebraic over .  There is an isomorphism of fields that is the identity on and that sends if and only if the irreducible polynomials for and over are equal. Let be an isomorphism of field extensions of , and let be a polynomial with coefficients in . Let be a root of in , and let be its image in .  Then is also a root of . If I start by assuming that then I suspect the three statements above will lead to a contradiction somewhere.  I just don't have a good firm grasp of how to put them into practice yet. Any help is appreciated.  Thanks,","\alpha \mathbb{Q} x^4-16x^2+4 \mathbb{Q}(\sqrt{3}+\sqrt{5})=\mathbb{Q}(\sqrt{3},\sqrt{5}) \mathbb{Q}(\sqrt{3},\sqrt{5},\sqrt{10})=\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}) [\mathbb{Q}(\sqrt{10}):\mathbb{Q}]=2 [{\mathbb{Q}(\sqrt{3},\sqrt{5}):\mathbb{Q}}]=4 [\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}):\mathbb{Q}(\sqrt{3},\sqrt{5})] \mathbb{Q}(\sqrt{3},\sqrt{5})\neq\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}) \sqrt{2}\not\in\mathbb{Q}(\sqrt{3},\sqrt{5}) K K^\prime F \varphi:K\to K^\prime F F \alpha \beta K/F L/F \alpha \beta F \sigma:F(\alpha)\to F(\beta) F \alpha\leadsto\beta \alpha \beta F \varphi:K\to K^\prime F f F \alpha f K \alpha^\prime=\varphi(\alpha) K^\prime \alpha^\prime f \mathbb{Q}(\sqrt{3},\sqrt{5})=\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5})","['abstract-algebra', 'field-theory']"
80,"Terminology: center (of a group, of a ring, ...)","Terminology: center (of a group, of a ring, ...)",,"What is the etymology of the word ""center"" as used in abstract algebra, e.g. the center of a group, or of an algebra? My best guess is that it might've come from matrix algebras, where often the center just consists of (scalar) diagonal matrices, whose nonzero coefficients appear in the ""center"" of the matrix.","What is the etymology of the word ""center"" as used in abstract algebra, e.g. the center of a group, or of an algebra? My best guess is that it might've come from matrix algebras, where often the center just consists of (scalar) diagonal matrices, whose nonzero coefficients appear in the ""center"" of the matrix.",,"['abstract-algebra', 'terminology', 'math-history']"
81,Quotient group properties,Quotient group properties,,Let $H$ and $E$ be normal subgroups of a group $G$ such that $$G/H \cong E.$$ Under what sort of conditions would we also have $$G/E \cong H?$$ Thanks.,Let $H$ and $E$ be normal subgroups of a group $G$ such that $$G/H \cong E.$$ Under what sort of conditions would we also have $$G/E \cong H?$$ Thanks.,,"['abstract-algebra', 'group-theory']"
82,Roots of unity and field extensions,Roots of unity and field extensions,,"Can we always break an arbitrary field extension $L/K$ into an extension $F/K$ in which the only roots of unity of $F$ are those in $K$, followed by an extension $L/F$ which is of the form $L=F(\{\omega_i\})$ where the $\omega_i$ are roots of unity? What if we restrict to $L/K$ separable, or finite?","Can we always break an arbitrary field extension $L/K$ into an extension $F/K$ in which the only roots of unity of $F$ are those in $K$, followed by an extension $L/F$ which is of the form $L=F(\{\omega_i\})$ where the $\omega_i$ are roots of unity? What if we restrict to $L/K$ separable, or finite?",,"['abstract-algebra', 'field-theory']"
83,"Example of a cocommutative, non-unimodular Hopf algebra?","Example of a cocommutative, non-unimodular Hopf algebra?",,"1. Definitions: Unimodularity and cocommutativity Let $H$ be a Hopf algebra over a field $\mathbb k$ . We call $H$ unimodular if the space of left integrals $I_l(H)$ is equal to the space of right integrals $I_r(H)$ . We call $H$ cocommutative if $\tau_{H,H} \circ \Delta = \Delta$ . Here, $\Delta$ denotes the coproduct of $H$ , while $\tau: H \otimes H \rightarrow H \otimes H; v \otimes w \mapsto w \otimes v$ is the twist map. 2. Question In my lecture notes it says that there are cocommutative, non-unimodular Hopf algebras. What would be an example? Apparently, an example is given in Hopf algebras and their action on rings by Susan Montgomery. However, due to the pandemic I am unable to get it from the library. If you have a copy and could write down the relevant section, that would be very much appreciated. 3. My ideas so far The Taft-Hopf algebra $H$ over a field $\mathbb k$ is not an example: If $H$ is commutative (i.e. root of unity $\zeta =1_{\mathbb k}$ ), then $H$ is unimodular. In this case, it is even isomorphic to the boring group algebra of the zero group. Otherwise, $H$ is not cocommutative (even though it is non-unimodular then). Non-cocommutativity follows easily from the observation that the square of the antipode is not the identity (if $\zeta \neq 1_{\mathbb k} $ ). Group algebras: As the coproduct of a group algebra is given by the diagonal map any group algebra is cocommutative. However, any group algebra $\mathbb k[G]$ over a finite group $G$ is unimodular, since $$I_l=I_r=\mathbb k \cdot \sum\limits_{g\in G} g$$ What about infinite groups? Regarding the universal enveloping algebra, tensor algebra, symmetric algebra, alternating algebra I am not sure. What can be said here? Maybe the following proposition turns out to be useful: A finite dimensional Hopf algebra $H$ is unimodular iff its distinguished group-like element/modular element $a \in G(H^*)$ is equal to the counit $\epsilon_H$ . Here, the modular element $a$ is the unique linear form such that $t\cdot h = t a(h)$ for all $h\in H, t\in I_l(H)$ . It exists because $t\cdot h \in I_l(H)$ and $I_l(H)$ is one dimensional. It can be shown to be a morphism of algebras, hence a group-like element in $H^*$ .","1. Definitions: Unimodularity and cocommutativity Let be a Hopf algebra over a field . We call unimodular if the space of left integrals is equal to the space of right integrals . We call cocommutative if . Here, denotes the coproduct of , while is the twist map. 2. Question In my lecture notes it says that there are cocommutative, non-unimodular Hopf algebras. What would be an example? Apparently, an example is given in Hopf algebras and their action on rings by Susan Montgomery. However, due to the pandemic I am unable to get it from the library. If you have a copy and could write down the relevant section, that would be very much appreciated. 3. My ideas so far The Taft-Hopf algebra over a field is not an example: If is commutative (i.e. root of unity ), then is unimodular. In this case, it is even isomorphic to the boring group algebra of the zero group. Otherwise, is not cocommutative (even though it is non-unimodular then). Non-cocommutativity follows easily from the observation that the square of the antipode is not the identity (if ). Group algebras: As the coproduct of a group algebra is given by the diagonal map any group algebra is cocommutative. However, any group algebra over a finite group is unimodular, since What about infinite groups? Regarding the universal enveloping algebra, tensor algebra, symmetric algebra, alternating algebra I am not sure. What can be said here? Maybe the following proposition turns out to be useful: A finite dimensional Hopf algebra is unimodular iff its distinguished group-like element/modular element is equal to the counit . Here, the modular element is the unique linear form such that for all . It exists because and is one dimensional. It can be shown to be a morphism of algebras, hence a group-like element in .","H \mathbb k H I_l(H) I_r(H) H \tau_{H,H} \circ \Delta = \Delta \Delta H \tau: H \otimes H \rightarrow H \otimes H; v \otimes w \mapsto w \otimes v H \mathbb k H \zeta =1_{\mathbb k} H H \zeta \neq 1_{\mathbb k}  \mathbb k[G] G I_l=I_r=\mathbb k \cdot \sum\limits_{g\in G} g H a \in G(H^*) \epsilon_H a t\cdot h = t a(h) h\in H, t\in I_l(H) t\cdot h \in I_l(H) I_l(H) H^*","['abstract-algebra', 'modules', 'representation-theory', 'examples-counterexamples', 'hopf-algebras']"
84,$f(1)+f(-1)=0$ prove $f(x)$ does not divide $x^n -1$,prove  does not divide,f(1)+f(-1)=0 f(x) x^n -1,Let $f(x)$ be an irreducible polynomial in $\Bbb Z[x]$ satisfying $f(1)+f(-1)=0$ .  Prove that $f(x)$ does not divide $x^n-1$ for any positive integer $n$ . with $f(1)+f(-1)=0$ it means sum of all even terms is $0;$ how is that related to divisibility to $x^n -1$ ? I can't figure out and would appreciate any help. Thanks!,Let be an irreducible polynomial in satisfying .  Prove that does not divide for any positive integer . with it means sum of all even terms is how is that related to divisibility to ? I can't figure out and would appreciate any help. Thanks!,f(x) \Bbb Z[x] f(1)+f(-1)=0 f(x) x^n-1 n f(1)+f(-1)=0 0; x^n -1,"['abstract-algebra', 'number-theory', 'polynomials', 'cyclotomic-polynomials']"
85,"A property for some finite groups (especially ${\rm PSL}(2,13)$)",A property for some finite groups (especially ),"{\rm PSL}(2,13)","Let $G$ be a finite group of order $n$ and consider the following property: (P) for every factorization $n=ab$ there exist subsets $A$ and $B$ such that $|A|=a$ , $|B|=b$ and $G=AB$ . ( $AB=\{ab:a\in A, b\in B\}$ ) Note. If $G$ has the property that for every divisor $d$ of $n$ there exists a subgroup of $G$ with order $d$ or $n/d$ , then we can show that $G$ enjoys (P) . Therefore, (P) is true for all finite abelian groups, and also one can check that the groups $S_n$ , $A_n$ and ${\rm PSL}(2,n)$ , where $n\leq 8$ , have the property. Now, is (P) true for ${\rm PSL}(2,13)$ ? (we think this is a good candidate for a probable counterexample.) Thanks in advance.","Let be a finite group of order and consider the following property: (P) for every factorization there exist subsets and such that , and . ( ) Note. If has the property that for every divisor of there exists a subgroup of with order or , then we can show that enjoys (P) . Therefore, (P) is true for all finite abelian groups, and also one can check that the groups , and , where , have the property. Now, is (P) true for ? (we think this is a good candidate for a probable counterexample.) Thanks in advance.","G n n=ab A B |A|=a |B|=b G=AB AB=\{ab:a\in A, b\in B\} G d n G d n/d G S_n A_n {\rm PSL}(2,n) n\leq 8 {\rm PSL}(2,13)","['abstract-algebra', 'group-theory', 'finite-groups', 'gap']"
86,Find the minimal polynomial of $a$,Find the minimal polynomial of,a,"Let $a=\sqrt[4]2+\sqrt2$ a) Is it true that $\mathbb Q(a)=\mathbb Q(\sqrt2, \sqrt[4]2)$ ? b) Find the minimal polynomial of $a$ over $\mathbb Q$ c) Find the minimal polynomial of $a$ over $\mathbb Q(\sqrt2)$ d) Is it true that $\sqrt[3]2\in \mathbb Q(a)$ ? In b) I have: $$a=\sqrt[4]2+\sqrt2$$ $$a^2-2\sqrt2a+2=\sqrt2$$ $$a^4-4a^2-8a+2=0$$ So we get the polynomial $f(a)=a^4-4a^2-8a+2$ and from Eisenstein's criterion we know that it is irreductible polynomial over $\mathbb Q$ so it is minimal polynomial over $\mathbb Q$ . In c) I have: $$g(a)=a^2-3\sqrt2a+2$$ But I don't know how to do a) and d)",Let a) Is it true that ? b) Find the minimal polynomial of over c) Find the minimal polynomial of over d) Is it true that ? In b) I have: So we get the polynomial and from Eisenstein's criterion we know that it is irreductible polynomial over so it is minimal polynomial over . In c) I have: But I don't know how to do a) and d),"a=\sqrt[4]2+\sqrt2 \mathbb Q(a)=\mathbb Q(\sqrt2, \sqrt[4]2) a \mathbb Q a \mathbb Q(\sqrt2) \sqrt[3]2\in \mathbb Q(a) a=\sqrt[4]2+\sqrt2 a^2-2\sqrt2a+2=\sqrt2 a^4-4a^2-8a+2=0 f(a)=a^4-4a^2-8a+2 \mathbb Q \mathbb Q g(a)=a^2-3\sqrt2a+2","['abstract-algebra', 'minimal-polynomials']"
87,Finite groups with all maximal subgroups isomorphic,Finite groups with all maximal subgroups isomorphic,,"Suppose $G$ is a finite group such that any two maximal subgroups of $G$ are isomorphic. What can be said about such a group? Can they be classified? The finite groups that have a unique maximal subgroup are exactly the cyclic groups of prime power order, $\mathbb{Z}/p^n\mathbb{Z}$ - these are the simplest examples of such groups. Also powers of $\mathbb{Z}/p^n\mathbb{Z}$ , i.e. $(\mathbb{Z}/p^n\mathbb{Z})^m = \mathbb{Z}/p^n\mathbb{Z} \times \ldots \times \mathbb{Z}/p^n\mathbb{Z}$ , have this property, and I think this covers all abelian groups with this property. In general I think such a group has to be a $p$ -group, by considering maximal subgroups containing Sylow subgroups for different primes. This paper https://bib.irb.hr/datoteka/402744.SiCh.pdf calls such groups isomaximal , but seems to only handle $2$ -groups up to order $64$ . Further question: what about groups $G$ such that any two maximal subgroups are isomorphic under some automorphism of $G$ (i.e. $\operatorname{Aut}(G)$ acts transitively on the set of maximal subgroups)? (Note: if this is strengthened to any two maximal subgroups being conjugate, then by this answer it becomes the same as having a unique maximal subgroup.)","Suppose is a finite group such that any two maximal subgroups of are isomorphic. What can be said about such a group? Can they be classified? The finite groups that have a unique maximal subgroup are exactly the cyclic groups of prime power order, - these are the simplest examples of such groups. Also powers of , i.e. , have this property, and I think this covers all abelian groups with this property. In general I think such a group has to be a -group, by considering maximal subgroups containing Sylow subgroups for different primes. This paper https://bib.irb.hr/datoteka/402744.SiCh.pdf calls such groups isomaximal , but seems to only handle -groups up to order . Further question: what about groups such that any two maximal subgroups are isomorphic under some automorphism of (i.e. acts transitively on the set of maximal subgroups)? (Note: if this is strengthened to any two maximal subgroups being conjugate, then by this answer it becomes the same as having a unique maximal subgroup.)",G G \mathbb{Z}/p^n\mathbb{Z} \mathbb{Z}/p^n\mathbb{Z} (\mathbb{Z}/p^n\mathbb{Z})^m = \mathbb{Z}/p^n\mathbb{Z} \times \ldots \times \mathbb{Z}/p^n\mathbb{Z} p 2 64 G G \operatorname{Aut}(G),"['abstract-algebra', 'group-theory', 'finite-groups', 'group-isomorphism']"
88,Abelian subgroup contained in a normal subgroup; a trick about elements of order $3$,Abelian subgroup contained in a normal subgroup; a trick about elements of order,3,"Let $A$ be a normal subgroup of $G$. Suppose that every element in $G\,\backslash\, A$ has order $\bf 3$. Then $[B,B^x]=1$ for all Abelian subgroups $B\leq A$ and $x\in G\,\backslash\, A$. I have been told that my task must have something to do with Chapter VI, On the isomorphism of a Group with Itself , para 66. of the famous book—“Burnside, W.: Theory of Groups of Finite Order , 2nd edn., Cambridge 1911; Dover Publications, New York 1955”. [ It’s a trick about order $3$, which was mentioned in the comments and Derek Holt’s answer below. ] Although we‘ve made many attempts indeed and have made a breakthrough (Derek Holt’s answer), yet we haven’t been able to figure out how to use the normality of $A$ and abelianity of $ B$, on which I’m still struggling... It would be greatly appreciated if you are kind enough to provide a reasonable answer! PS: It’s exercise 1.5.6 of the book The Theory of Finite Groups, An Introduction . Berlin: Springer, 2004.","Let $A$ be a normal subgroup of $G$. Suppose that every element in $G\,\backslash\, A$ has order $\bf 3$. Then $[B,B^x]=1$ for all Abelian subgroups $B\leq A$ and $x\in G\,\backslash\, A$. I have been told that my task must have something to do with Chapter VI, On the isomorphism of a Group with Itself , para 66. of the famous book—“Burnside, W.: Theory of Groups of Finite Order , 2nd edn., Cambridge 1911; Dover Publications, New York 1955”. [ It’s a trick about order $3$, which was mentioned in the comments and Derek Holt’s answer below. ] Although we‘ve made many attempts indeed and have made a breakthrough (Derek Holt’s answer), yet we haven’t been able to figure out how to use the normality of $A$ and abelianity of $ B$, on which I’m still struggling... It would be greatly appreciated if you are kind enough to provide a reasonable answer! PS: It’s exercise 1.5.6 of the book The Theory of Finite Groups, An Introduction . Berlin: Springer, 2004.",,['abstract-algebra']
89,How to find unit group of $\Bbb Z[x]/(nx)$?,How to find unit group of ?,\Bbb Z[x]/(nx),"I am trying to work out the group structure of the group of units of $$\Bbb Z[x]/(nx)$$ where $n\ge 2$ is an integer. So finding the units isn't the hard part, they will be of the form $u+t$ where $u$ is a unit of $\Bbb Z$ and $t$ is a nilpotent element of the polynomial ring. The difficult part is trying to work out how they multiply. As far as I can tell these groups don't seem to have any torison, which is probably why I couldn't understand their structure. Is there any way to determine what the group structure might be?","I am trying to work out the group structure of the group of units of $$\Bbb Z[x]/(nx)$$ where $n\ge 2$ is an integer. So finding the units isn't the hard part, they will be of the form $u+t$ where $u$ is a unit of $\Bbb Z$ and $t$ is a nilpotent element of the polynomial ring. The difficult part is trying to work out how they multiply. As far as I can tell these groups don't seem to have any torison, which is probably why I couldn't understand their structure. Is there any way to determine what the group structure might be?",,"['abstract-algebra', 'group-theory', 'ring-theory']"
90,Abelian group structure on roots of a polynomial,Abelian group structure on roots of a polynomial,,"Assume $f \in \Bbb Z[x]$ is a monic polynomial,  s.t for every commutative ring $R$,  the solutions of $f(x)=0$ in $R$ can be endowed with an abelian group structure that is functorial respect to $R$. Some examples of  f include $ f(x)=x^n-1,   f(x)=x$ , with the group structure inherited from the additive group or the unit group. But there is an example with new group structure: $ f(x)=x^2-x$ with group operation given by $(x,y) \mapsto (x-y)^2$. So are there other types of such polynomial？How to classify all such $f$？ A neccesary condition is $f$ has root in every $R$ hence $f $ must have a linear factor.","Assume $f \in \Bbb Z[x]$ is a monic polynomial,  s.t for every commutative ring $R$,  the solutions of $f(x)=0$ in $R$ can be endowed with an abelian group structure that is functorial respect to $R$. Some examples of  f include $ f(x)=x^n-1,   f(x)=x$ , with the group structure inherited from the additive group or the unit group. But there is an example with new group structure: $ f(x)=x^2-x$ with group operation given by $(x,y) \mapsto (x-y)^2$. So are there other types of such polynomial？How to classify all such $f$？ A neccesary condition is $f$ has root in every $R$ hence $f $ must have a linear factor.",,"['abstract-algebra', 'number-theory']"
91,What space corresponds to the localisation of the ring of continuous functions?,What space corresponds to the localisation of the ring of continuous functions?,,"Suppose $A$ is a commutative Banach algebra. By Gelfand duality there is a compactum $X$ such that $A = C(X)$ is the ring of continuous functions. The space $X$ can be recovered as the space of characters on $A$. That is to say multiplicative linear functionals $A \to \mathbb R$ under the weak$^*$ topology. Observe this topology on the space of characters does not depend on the topology of $A$. Now let $f \in C(X)$ be any non-invertible element. In other words $f$ has a zero. We can localise the ring $C(X)$ at $f$ to get the ring of 'formal fractions' $C(X)_f = \displaystyle  \{\frac{g}{f^n} \colon g \in C(X), n \in \mathbb N\}$. There is a natural embedding $C(X) \to C(X)_f$ but I am unaware if $C(X)_f$ carries a compatible Banach algebra structure. By this I mean a norm under which it is complete and the embedding is an isometry. Nevertheless we can consider the space of characters on $C(X)_f$ and give that the weak$^*$ topology. Under what conditions is the character space of $C(X)_f$ some compactum $Y$? When will we have $C_f(X) = C(Y)$? Does $Y$ have a topological characterisation in terms of the space $X$ and function $f$?","Suppose $A$ is a commutative Banach algebra. By Gelfand duality there is a compactum $X$ such that $A = C(X)$ is the ring of continuous functions. The space $X$ can be recovered as the space of characters on $A$. That is to say multiplicative linear functionals $A \to \mathbb R$ under the weak$^*$ topology. Observe this topology on the space of characters does not depend on the topology of $A$. Now let $f \in C(X)$ be any non-invertible element. In other words $f$ has a zero. We can localise the ring $C(X)$ at $f$ to get the ring of 'formal fractions' $C(X)_f = \displaystyle  \{\frac{g}{f^n} \colon g \in C(X), n \in \mathbb N\}$. There is a natural embedding $C(X) \to C(X)_f$ but I am unaware if $C(X)_f$ carries a compatible Banach algebra structure. By this I mean a norm under which it is complete and the embedding is an isometry. Nevertheless we can consider the space of characters on $C(X)_f$ and give that the weak$^*$ topology. Under what conditions is the character space of $C(X)_f$ some compactum $Y$? When will we have $C_f(X) = C(Y)$? Does $Y$ have a topological characterisation in terms of the space $X$ and function $f$?",,"['abstract-algebra', 'functional-analysis', 'banach-algebras', 'localization', 'gelfand-representation']"
92,degree of K(x) over K(F/G),degree of K(x) over K(F/G),,"This is an ungraded assignment from a course on Galois theory on Coursera, so I hope it's OK to ask the question here. ""Let $F(x)/G(x) \in K(x)$ be a rational function over a field $K$ . Show that the extension $K(x)/K(F/G)$ is algebraic and compute its degree."" Ok, the first part was easy for me: the polynomial $p(y) = F(x)/G(x) \cdot G(y) - F(y)$ has $x$ as its root. This shows algebraicity. For the second part, my guess is that $p(y)$ is also the minimal polynomial, so if I assume that $F,G$ are coprime, then the degree is a $\max(\deg F,\deg G)$ . Is that right? And if it is, how to prove that $p(y)$ is in fact minimal?","This is an ungraded assignment from a course on Galois theory on Coursera, so I hope it's OK to ask the question here. ""Let be a rational function over a field . Show that the extension is algebraic and compute its degree."" Ok, the first part was easy for me: the polynomial has as its root. This shows algebraicity. For the second part, my guess is that is also the minimal polynomial, so if I assume that are coprime, then the degree is a . Is that right? And if it is, how to prove that is in fact minimal?","F(x)/G(x) \in K(x) K K(x)/K(F/G) p(y) = F(x)/G(x) \cdot G(y) - F(y) x p(y) F,G \max(\deg F,\deg G) p(y)","['abstract-algebra', 'field-theory', 'minimal-polynomials']"
93,Is a non-separable algebraic field extension $k \subset E$ normal if $\mathrm{Aut}_{E}(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_{k}(\bar{k})$?,Is a non-separable algebraic field extension  normal if  is a normal subgroup of ?,k \subset E \mathrm{Aut}_{E}(\bar{k}) \mathrm{Aut}_{k}(\bar{k}),"Over a perfect field $k$ it is well known that an algebraic field extension $k \subseteq E$ is normal if and only if $\mathrm{Aut}_{E}(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_{k}(\bar{k})$, as in the infinite Galois correspondence closed normal subgroups of $\mathrm{Aut}_k(\bar{k})$ correspond exactly to normal field extensions of $k$. Here $\bar{k}$ denotes an algebraic closure of $k$. Is the same true when $k$ is not perfect? The closest I have gotten to providing an answer is the following: The group $\mathrm{Aut}_k(\bar{k})$ acts on the set of $k$-algebra homomorphisms $E \to \bar{k}$ by postcomposition. The stabiliser of the inclusion $E \subseteq \bar{k}$ is given by $\mathrm{Aut}_E(\bar{k})$; as by assumption $\mathrm{Aut}_E(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_k(\bar{k})$ we see that it is the stabiliser of all $k$-algebra homomorphisms $E \to \bar{k}$, and therefore any conjugate of $E$ must lie within the purely inseparable closure of $E$, as this field coincides with the fixed field of $\mathrm{Aut}_E(\bar{k})$.","Over a perfect field $k$ it is well known that an algebraic field extension $k \subseteq E$ is normal if and only if $\mathrm{Aut}_{E}(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_{k}(\bar{k})$, as in the infinite Galois correspondence closed normal subgroups of $\mathrm{Aut}_k(\bar{k})$ correspond exactly to normal field extensions of $k$. Here $\bar{k}$ denotes an algebraic closure of $k$. Is the same true when $k$ is not perfect? The closest I have gotten to providing an answer is the following: The group $\mathrm{Aut}_k(\bar{k})$ acts on the set of $k$-algebra homomorphisms $E \to \bar{k}$ by postcomposition. The stabiliser of the inclusion $E \subseteq \bar{k}$ is given by $\mathrm{Aut}_E(\bar{k})$; as by assumption $\mathrm{Aut}_E(\bar{k})$ is a normal subgroup of $\mathrm{Aut}_k(\bar{k})$ we see that it is the stabiliser of all $k$-algebra homomorphisms $E \to \bar{k}$, and therefore any conjugate of $E$ must lie within the purely inseparable closure of $E$, as this field coincides with the fixed field of $\mathrm{Aut}_E(\bar{k})$.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
94,Proving that a group of order $pqr$ (with conditions on those primes) is abelian.,Proving that a group of order  (with conditions on those primes) is abelian.,pqr,"I'm doing this exercise: Let $G$ be a group, with $|G|=pqr$ , $p,q,r$ different primes, $q<r$ , $r \not\equiv 1$ (mod $q$ ), $qr<p$ . Also suppose that $p \not\equiv 1$ (mod $r$ ), $p \not\equiv 1$ (mod $q$ ). Let $C$ (the commutator of $G$ ) and $K$ be subgroups of $G$ , with $C \leq K$ , $K \trianglelefteq G$ and $|K|=q$ . $K$ is the unique Sylow $q$ -subgroup on $G$ (so $K \trianglelefteq G$ ). Let $G/K$ be an abelian group (in particular, $G/C$ is an abelian group). Prove that $C=\langle[a,b]=aba^{-1}b^{-1} \mid a,b\in G \rangle=\{e\}$ and $G$ is abelian . I really don't know how to prove this. By Lagrange I saw that the order of $C$ could be $1$ or $q$ , but the option $|C|=q$ is still a valid option, so I don't know how to show that $C=\{e\}$ . Thank you.","I'm doing this exercise: Let be a group, with , different primes, , (mod ), . Also suppose that (mod ), (mod ). Let (the commutator of ) and be subgroups of , with , and . is the unique Sylow -subgroup on (so ). Let be an abelian group (in particular, is an abelian group). Prove that and is abelian . I really don't know how to prove this. By Lagrange I saw that the order of could be or , but the option is still a valid option, so I don't know how to show that . Thank you.","G |G|=pqr p,q,r q<r r \not\equiv 1 q qr<p p \not\equiv 1 r p \not\equiv 1 q C G K G C \leq K K \trianglelefteq G |K|=q K q G K \trianglelefteq G G/K G/C C=\langle[a,b]=aba^{-1}b^{-1} \mid a,b\in G \rangle=\{e\} G C 1 q |C|=q C=\{e\}","['abstract-algebra', 'group-theory', 'finite-groups']"
95,Prove $\sqrt{-7} \not\in \mathbb{Z}\left[\frac{2+3\sqrt{-7}}{4}\right]$,Prove,\sqrt{-7} \not\in \mathbb{Z}\left[\frac{2+3\sqrt{-7}}{4}\right],"I have the following problem. Consider the ring $\mathbb{Z}$ and define:   $$x = \sqrt{-7}\qquad z = \frac{2+3x}{4}$$   Show that $\mathbb{Z}[x] \not\subset \mathbb{Z}[z]$ and $\mathbb{Z}[z] \not\subset \mathbb{Z}[x]$. First of all, I describe the ring extensions: \begin{align} \mathbb{Z}[x]  &= \left\{a_0 + a_1 x + a_2 x^2 +a_3 x^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\}\\ &= \left\{a + b x \ | \ a,b \in \mathbb{Z}\right\} \end{align} Where we use $x^2 + 7 = 0$ ($x$ is an algebraic integer). On the other hand \begin{align} \mathbb{Z}[z]  &= \left\{a_0 + a_1 z + a_2 z^2 +a_3 z^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\} \end{align} admits no further simplification (we have $16z^2 - 16z + 67 = 0 \Rightarrow z$ is not an algebraic integer). I think it is easy to show $z \not\in \mathbb{Z}[x]$. To see this, assume you can find $a,b\in \mathbb{Z}$ such that $z = a+bx$. Now consider this identity in $\mathbb{Q}(x) = \mathbb{Q}[x]$, where $\{1,x\}$ is a basis. Since  $$z=\frac{2}{4} + \frac{3}{4}\!x= a +bx $$ it must be $a=\frac{2}{4}$, $b=\frac{3}{4}$, so $a, b$ are not in $\mathbb{Z}$. Thus $z\not\in\mathbb{Z}[x]$. Is this correct? Any idea for the other part?","I have the following problem. Consider the ring $\mathbb{Z}$ and define:   $$x = \sqrt{-7}\qquad z = \frac{2+3x}{4}$$   Show that $\mathbb{Z}[x] \not\subset \mathbb{Z}[z]$ and $\mathbb{Z}[z] \not\subset \mathbb{Z}[x]$. First of all, I describe the ring extensions: \begin{align} \mathbb{Z}[x]  &= \left\{a_0 + a_1 x + a_2 x^2 +a_3 x^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\}\\ &= \left\{a + b x \ | \ a,b \in \mathbb{Z}\right\} \end{align} Where we use $x^2 + 7 = 0$ ($x$ is an algebraic integer). On the other hand \begin{align} \mathbb{Z}[z]  &= \left\{a_0 + a_1 z + a_2 z^2 +a_3 z^3 + \ldots  \ | \ a_i \in \mathbb{Z}\right\} \end{align} admits no further simplification (we have $16z^2 - 16z + 67 = 0 \Rightarrow z$ is not an algebraic integer). I think it is easy to show $z \not\in \mathbb{Z}[x]$. To see this, assume you can find $a,b\in \mathbb{Z}$ such that $z = a+bx$. Now consider this identity in $\mathbb{Q}(x) = \mathbb{Q}[x]$, where $\{1,x\}$ is a basis. Since  $$z=\frac{2}{4} + \frac{3}{4}\!x= a +bx $$ it must be $a=\frac{2}{4}$, $b=\frac{3}{4}$, so $a, b$ are not in $\mathbb{Z}$. Thus $z\not\in\mathbb{Z}[x]$. Is this correct? Any idea for the other part?",,"['abstract-algebra', 'ring-theory', 'extension-field']"
96,Are the identities $\{(xy)^p = x^p y^p : p \mbox{ is prime}\}$ logically independent?,Are the identities  logically independent?,\{(xy)^p = x^p y^p : p \mbox{ is prime}\},"For each positive integer $n$, let $\eta_n$ denote the following identity in the language of monoids. $$(xy)^n = x^n y^n$$ For example, $\eta_2$ is the identity $xyxy = xxyy.$ Question. Is it true that for any subset $Q$ of the prime numbers $\{2,3,5,\ldots\}$, there exists a monoid $M$ such that for all prime numbers $p,$ $M$ satisfies $\eta_p$ iff $p \in Q$? In other words, is $\{\eta_2,\eta_3,\eta_5,\ldots\}$ a logically independent set of sentences? (In the presence of the monoid axioms). For example (and I may be overlooking something obvious here), but I do not think that $(xy)^5 = x^5 y^5$ follows from just $(xy)^2=x^2 y^2$ and $(xy)^3 = x^3y^3$.","For each positive integer $n$, let $\eta_n$ denote the following identity in the language of monoids. $$(xy)^n = x^n y^n$$ For example, $\eta_2$ is the identity $xyxy = xxyy.$ Question. Is it true that for any subset $Q$ of the prime numbers $\{2,3,5,\ldots\}$, there exists a monoid $M$ such that for all prime numbers $p,$ $M$ satisfies $\eta_p$ iff $p \in Q$? In other words, is $\{\eta_2,\eta_3,\eta_5,\ldots\}$ a logically independent set of sentences? (In the presence of the monoid axioms). For example (and I may be overlooking something obvious here), but I do not think that $(xy)^5 = x^5 y^5$ follows from just $(xy)^2=x^2 y^2$ and $(xy)^3 = x^3y^3$.",,"['abstract-algebra', 'monoid']"
97,The only fixed-point free automorphism of order $2$ is $\phi(a)=a^{-1}$(in a finite group),The only fixed-point free automorphism of order  is (in a finite group),2 \phi(a)=a^{-1},"I got the problem in  Dummit and Foote's Algebra book to prove if $G$ is a finite group that has an automorphism $\phi$  in which if $a=\phi(a)$ then $a=1$. And which satisfies $\phi(\phi(a))=a$ for all $a$ then $G$ is abelian. Here is what I did: I first prove the map $\omega(a)=a^{-1}\phi(a)$ is injective(and since the group is finite and the domain is the same as the co-domain this proves it is also bijective): $a^{-1}\phi(a)=b^{-1}\phi(b)\implies ba^{-1}\phi(a)=\phi(b)\implies ba^{-1}=\phi(b)\phi(a)^{-1}=\phi(ba^{-1})\implies ba^{-1}=1\implies b=a$. So every element in $G$ is of the form $a^{-1}\phi(a)$. Notice $\phi(a^{-1}\phi(a))=\phi(a^{-1})a$. Which is the inverse of $a^{-1}\phi(a)$ which tells us $\phi(g)=g^{-1}$. From here we get $\phi(ab)=b^{-1}a^{-1}=a^{-1}b^{-1}=\phi(a) \phi(b)$ multiplying by $a$ and $b$ on both sides gives $ab=ba$ as desired. My question is: is what I did correct (especially everything up to the point where I conclude $\phi(a)=a^{-1}$)? Normally I wouldn't ask this, but the fact that it asked me to prove something much weaker instead of characterizing the automorphism uniquely makes me doubt it is OK.","I got the problem in  Dummit and Foote's Algebra book to prove if $G$ is a finite group that has an automorphism $\phi$  in which if $a=\phi(a)$ then $a=1$. And which satisfies $\phi(\phi(a))=a$ for all $a$ then $G$ is abelian. Here is what I did: I first prove the map $\omega(a)=a^{-1}\phi(a)$ is injective(and since the group is finite and the domain is the same as the co-domain this proves it is also bijective): $a^{-1}\phi(a)=b^{-1}\phi(b)\implies ba^{-1}\phi(a)=\phi(b)\implies ba^{-1}=\phi(b)\phi(a)^{-1}=\phi(ba^{-1})\implies ba^{-1}=1\implies b=a$. So every element in $G$ is of the form $a^{-1}\phi(a)$. Notice $\phi(a^{-1}\phi(a))=\phi(a^{-1})a$. Which is the inverse of $a^{-1}\phi(a)$ which tells us $\phi(g)=g^{-1}$. From here we get $\phi(ab)=b^{-1}a^{-1}=a^{-1}b^{-1}=\phi(a) \phi(b)$ multiplying by $a$ and $b$ on both sides gives $ab=ba$ as desired. My question is: is what I did correct (especially everything up to the point where I conclude $\phi(a)=a^{-1}$)? Normally I wouldn't ask this, but the fact that it asked me to prove something much weaker instead of characterizing the automorphism uniquely makes me doubt it is OK.",,"['abstract-algebra', 'proof-verification']"
98,Show any group of order $275$ has an element of order $5$.,Show any group of order  has an element of order .,275 5,"This is what I have. Note: I'm not allowed Cauchy's theorem or Sylow theorems. Let $|G| = 275$. So I know $275 = 5\times5\times11$. If I assume that $G$ is cyclic then there exists $x\in G$ such that $|x| = 275$. Then $|x^{55}| = 5$ and I'm done. If $G$ is not cyclic then I assume it contains no elements of order $275$. Then all elements of $G$ have order $1,5,11,25,55$. It has an element of order $5$ then I stop because we're done. So I look at an element of order $|x| = 25 \text{ or } 55$ but then wouldn't $|x^{5 \text{ or } 11}| = 5$ so I'd be done here also. Thus I can say $G$ has elements of order $11$ only. So for each element of order $11$ I can look at $\langle x\rangle$ and this will have $|\langle x\rangle|=11$ for each distinct such subgroup I'll get $10$ distinct elements and so if there are k such subgroups I'll have $10k + 1$ elements and $275 = 10k+1 \iff 274 = 10k$ but $10$ doesn't divide $274$ so $G$ must have an element of order $5$. Is this enough or do I need to show more and perhaps more importantly does this work? (edit: spelling)","This is what I have. Note: I'm not allowed Cauchy's theorem or Sylow theorems. Let $|G| = 275$. So I know $275 = 5\times5\times11$. If I assume that $G$ is cyclic then there exists $x\in G$ such that $|x| = 275$. Then $|x^{55}| = 5$ and I'm done. If $G$ is not cyclic then I assume it contains no elements of order $275$. Then all elements of $G$ have order $1,5,11,25,55$. It has an element of order $5$ then I stop because we're done. So I look at an element of order $|x| = 25 \text{ or } 55$ but then wouldn't $|x^{5 \text{ or } 11}| = 5$ so I'd be done here also. Thus I can say $G$ has elements of order $11$ only. So for each element of order $11$ I can look at $\langle x\rangle$ and this will have $|\langle x\rangle|=11$ for each distinct such subgroup I'll get $10$ distinct elements and so if there are k such subgroups I'll have $10k + 1$ elements and $275 = 10k+1 \iff 274 = 10k$ but $10$ doesn't divide $274$ so $G$ must have an element of order $5$. Is this enough or do I need to show more and perhaps more importantly does this work? (edit: spelling)",,"['abstract-algebra', 'group-theory', 'finite-groups']"
99,Amenable group rings embeddable in skew fields,Amenable group rings embeddable in skew fields,,"I'm looking for a reference of the following fact: given a (countable?) amenable group $G$ and a (skew) field $K$, the following are equivalent: (1) the group ring $K[G]$ is a domain; (2) $K[G]$ is a (left and right) Ore domain. I think to remember that this result is due to Beno Eckmann but, unfortunately, I cannot remember in which paper. I tried to look for this result and I'm not able to find it at the moment. Any reference would be strongly appreciated!","I'm looking for a reference of the following fact: given a (countable?) amenable group $G$ and a (skew) field $K$, the following are equivalent: (1) the group ring $K[G]$ is a domain; (2) $K[G]$ is a (left and right) Ore domain. I think to remember that this result is due to Beno Eckmann but, unfortunately, I cannot remember in which paper. I tried to look for this result and I'm not able to find it at the moment. Any reference would be strongly appreciated!",,"['abstract-algebra', 'group-theory', 'reference-request', 'ring-theory']"
