,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Covariance of two expectation estimators that used different numbers of samples,Covariance of two expectation estimators that used different numbers of samples,,"Say I have two estimates of the mean of two functions: $$Q^1_{N_1}=\frac{1}{N_1}\sum_{i=1}^{N_1}f^1(X_i), \quad Q^2_{N_2}=\frac{1}{N_2}\sum_{i=1}^{N_2}f^2(X_i),$$ where each sample $X_i$ is identical when $i \leqslant \min(N_1, N_2)$ and is selected from the probability distribution $X$, and I want to calculate the covariance of the two estimators $\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})$. Lemna 3.2 of this paper attempts to prove that $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})=\frac{\mathrm{Cov}(f^1(X), f^2(X))}{\max(N_1,N_2)}=\frac{\sqrt{\mathrm{Var(f^1(X)) \mathrm{Var}(f^2(X))}}}{\max(N_1,N_2)}\rho_{12},$$ where $\rho_{12}:=\dfrac{\mathrm{Cov}(f^1(X), f^2(X))}{\sqrt{\mathrm{Var}(f^1(X)) \mathrm{Var}(f^2(X))}}$. I am pretty sure that the important piece there is $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2}) = \frac{\mathrm{Cov}(f^1(X), f^2(X))}{\max(N_1,N_2)}.$$ This has been a hard proof for me to follow , so I am asking this community for help. I would say my biggest source of confusion is where the $\max(N_1, N_2)$ term comes from. Here is what I have tried so far. My result is simillar to that in the paper, except I have a minimum instead of a maximum. Can anyone help give me insight as to where the maximum operator comes into play? The covariance of $Q^1_{N_1}$ and $Q^2_{N_2}$ may be calulated as \begin{align*} &\mathrel{\phantom{=}}{} \mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})\\ &=\frac{1}{\min(N_1,N_2)}\sum_{i=1}^{\min(N_1, N_2)}\left(\left(f^1(x_i) - \frac{1}{N_1}\sum_{j=1}^{N_1}f^1(x_j)\right)\left(f^2(x_i) - \frac{1}{N_2}\sum_{j=1}^{N_2}f^2(x_j)\right)\right), \end{align*} where the minimum of $N_1$ and $N_2$ are the number of samples common to both estimators. Only $\min(N_1,N_2)$ samples are common to both estimators, so we must use at most $\min(N_1,N_2)$ samples to estimate the covariance. Assuming the number of samples is large, we can say $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})= \frac{1}{\min(N_1,N_2)}\mathrm{Cov}(f^1(X), f^2(X))=\frac{\sqrt{\mathrm{Var(f^1(X)) \mathrm{Var}(f^2(X))}}}{\min(N_1,N_2)}\rho_{12}.$$","Say I have two estimates of the mean of two functions: $$Q^1_{N_1}=\frac{1}{N_1}\sum_{i=1}^{N_1}f^1(X_i), \quad Q^2_{N_2}=\frac{1}{N_2}\sum_{i=1}^{N_2}f^2(X_i),$$ where each sample $X_i$ is identical when $i \leqslant \min(N_1, N_2)$ and is selected from the probability distribution $X$, and I want to calculate the covariance of the two estimators $\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})$. Lemna 3.2 of this paper attempts to prove that $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})=\frac{\mathrm{Cov}(f^1(X), f^2(X))}{\max(N_1,N_2)}=\frac{\sqrt{\mathrm{Var(f^1(X)) \mathrm{Var}(f^2(X))}}}{\max(N_1,N_2)}\rho_{12},$$ where $\rho_{12}:=\dfrac{\mathrm{Cov}(f^1(X), f^2(X))}{\sqrt{\mathrm{Var}(f^1(X)) \mathrm{Var}(f^2(X))}}$. I am pretty sure that the important piece there is $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2}) = \frac{\mathrm{Cov}(f^1(X), f^2(X))}{\max(N_1,N_2)}.$$ This has been a hard proof for me to follow , so I am asking this community for help. I would say my biggest source of confusion is where the $\max(N_1, N_2)$ term comes from. Here is what I have tried so far. My result is simillar to that in the paper, except I have a minimum instead of a maximum. Can anyone help give me insight as to where the maximum operator comes into play? The covariance of $Q^1_{N_1}$ and $Q^2_{N_2}$ may be calulated as \begin{align*} &\mathrel{\phantom{=}}{} \mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})\\ &=\frac{1}{\min(N_1,N_2)}\sum_{i=1}^{\min(N_1, N_2)}\left(\left(f^1(x_i) - \frac{1}{N_1}\sum_{j=1}^{N_1}f^1(x_j)\right)\left(f^2(x_i) - \frac{1}{N_2}\sum_{j=1}^{N_2}f^2(x_j)\right)\right), \end{align*} where the minimum of $N_1$ and $N_2$ are the number of samples common to both estimators. Only $\min(N_1,N_2)$ samples are common to both estimators, so we must use at most $\min(N_1,N_2)$ samples to estimate the covariance. Assuming the number of samples is large, we can say $$\mathrm{Cov}(Q^1_{N_1}, Q^2_{N_2})= \frac{1}{\min(N_1,N_2)}\mathrm{Cov}(f^1(X), f^2(X))=\frac{\sqrt{\mathrm{Var(f^1(X)) \mathrm{Var}(f^2(X))}}}{\min(N_1,N_2)}\rho_{12}.$$",,"['probability', 'covariance']"
1,What is the probability that it takes more than seven rolls of a fair $6$-sided die to roll a six?,What is the probability that it takes more than seven rolls of a fair -sided die to roll a six?,6,"What is the probability that it takes more than seven rolls of a fair $6$-sided die to roll a six? The probability of rolling a six per roll is $1/6$. Therefore, the probability of rolling something other than a 6 is $5/6$. So wouldn't the probability that you don't roll a six within the first $7$ rolls just be $(5/6)^7$?","What is the probability that it takes more than seven rolls of a fair $6$-sided die to roll a six? The probability of rolling a six per roll is $1/6$. Therefore, the probability of rolling something other than a 6 is $5/6$. So wouldn't the probability that you don't roll a six within the first $7$ rolls just be $(5/6)^7$?",,['probability']
2,The Mabinogion sheep problem,The Mabinogion sheep problem,,"$\textbf{The Mabinogion sheep problem}$ By David Williams There is a magical flock of sheep, some black, some white. We sacrifice poetry for precision in specifying its behaviour. At each of times 1,2,3,… a sheep (chosen randomly from the entire flock, independently of previous events) bleats; if this bleating sheep is white, one black sheep (if any remain) instantly becomes white; if the bleating sheep is black, then one white sheep (if any remain) instantly becomes black. No births or deaths occur. The controlled system. Suppose now that the system can be controlled in that just after time 0 and just after every magical transition time 1,2,…, any number of white sheep may be removed from the system. (White sheep may be removed on numerous occasions.) The object is to maximize the expected final number of black sheep. Policy $\bf{A}$ : at each time of decision, do nothing if there are more   black sheep than white sheep or if no blakc sheep remain; otherwise,   immediately reduce the white population to one less than the black   population. We define the value function $V : Z^{+} × {Z} ^{+} → [0, ∞)$ so that $V (w, b)$ is the expected final number of   black sheep under Policy $\bf{A}$ if there are $w$ white sheep and $b$ black sheep at the start. As a result,   V has the following properties, a1) $V(0,b)=b, V(w,0)=0$ . a2) $V(w,b)=V(w-1,b)$ whenever $w\ge b>0$ a3) $V(w,b) = \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ whenever $0<w<b$ $\textbf{Question (a)}$ : Show that under the policy $\textbf{A}$, $V(W_n,B_n)$ is a martingale w.r.t. filtration $\mathcal{F}$, where $\{W_n,B_n\}$ is number of white and black sheep after $n_{th}$ time. $\textbf{Question (b)}$ : Suppose $V(w,b) \ge \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ and $V(w,b) \ge V(w-1,b)$ whenever $w\ge0$ and $b \ge 0$. Show that for any other policies, $V(W_n,B_n)$ is a super-martingale w.r.t. filtration $\mathcal{F}$. Recently, I am studying martingale and its application. And I am very curious about this question in the textbook. This is a famous stochastic control problem by David Williams, called The Mabinogion sheep problem. The following is described in (Williams, David (1991), Probability with martingales, Cambridge Mathematical Textbooks, Cambridge University Press) In the David Williams's book, he just mentioned about a1)-a3) three properties but not proved them. $\textbf{My attempt}$: $\textbf{The property a1)-a3) are what we have known, they are very easy to show.}$ $\textbf{For my proof to Question (a)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1) =V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a martingale w.r.t. $\mathcal{F_n}$ $\textbf{For my proof to Question (b)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1)  < V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a super-martingale w.r.t. $\mathcal{F_n}$ Do I miss some points for proving (a) and (b)? Could you help me to check my answer? $\textbf{Edit:}$ . $\textbf{This question has not been answered for Question (a) and (b)}!$ . $\textbf{Could I get some helps from these two question? Thank you so much!}$","$\textbf{The Mabinogion sheep problem}$ By David Williams There is a magical flock of sheep, some black, some white. We sacrifice poetry for precision in specifying its behaviour. At each of times 1,2,3,… a sheep (chosen randomly from the entire flock, independently of previous events) bleats; if this bleating sheep is white, one black sheep (if any remain) instantly becomes white; if the bleating sheep is black, then one white sheep (if any remain) instantly becomes black. No births or deaths occur. The controlled system. Suppose now that the system can be controlled in that just after time 0 and just after every magical transition time 1,2,…, any number of white sheep may be removed from the system. (White sheep may be removed on numerous occasions.) The object is to maximize the expected final number of black sheep. Policy $\bf{A}$ : at each time of decision, do nothing if there are more   black sheep than white sheep or if no blakc sheep remain; otherwise,   immediately reduce the white population to one less than the black   population. We define the value function $V : Z^{+} × {Z} ^{+} → [0, ∞)$ so that $V (w, b)$ is the expected final number of   black sheep under Policy $\bf{A}$ if there are $w$ white sheep and $b$ black sheep at the start. As a result,   V has the following properties, a1) $V(0,b)=b, V(w,0)=0$ . a2) $V(w,b)=V(w-1,b)$ whenever $w\ge b>0$ a3) $V(w,b) = \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ whenever $0<w<b$ $\textbf{Question (a)}$ : Show that under the policy $\textbf{A}$, $V(W_n,B_n)$ is a martingale w.r.t. filtration $\mathcal{F}$, where $\{W_n,B_n\}$ is number of white and black sheep after $n_{th}$ time. $\textbf{Question (b)}$ : Suppose $V(w,b) \ge \frac{w}{w+b}V(w+1,b-1)+\frac{b}{w+b}V(w-1,b+1)$ and $V(w,b) \ge V(w-1,b)$ whenever $w\ge0$ and $b \ge 0$. Show that for any other policies, $V(W_n,B_n)$ is a super-martingale w.r.t. filtration $\mathcal{F}$. Recently, I am studying martingale and its application. And I am very curious about this question in the textbook. This is a famous stochastic control problem by David Williams, called The Mabinogion sheep problem. The following is described in (Williams, David (1991), Probability with martingales, Cambridge Mathematical Textbooks, Cambridge University Press) In the David Williams's book, he just mentioned about a1)-a3) three properties but not proved them. $\textbf{My attempt}$: $\textbf{The property a1)-a3) are what we have known, they are very easy to show.}$ $\textbf{For my proof to Question (a)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1) =V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a martingale w.r.t. $\mathcal{F_n}$ $\textbf{For my proof to Question (b)}$ $E\{V(W_{n+1},B_{n+1})|\mathcal{F_n}\} = \frac{W_n}{W_n+B_n}V(W_{n}+1,B_{n}-1) + \frac{B_n}{W_n+B_n}V(W_{n}-1,B_{n}+1)  < V(W_{n},B_{n})$. Therefore, $V(W_{n},B_{n})$ is a super-martingale w.r.t. $\mathcal{F_n}$ Do I miss some points for proving (a) and (b)? Could you help me to check my answer? $\textbf{Edit:}$ . $\textbf{This question has not been answered for Question (a) and (b)}!$ . $\textbf{Could I get some helps from these two question? Thank you so much!}$",,"['probability', 'probability-theory', 'stochastic-processes', 'markov-chains', 'martingales']"
3,Haar measure on orthogonal group,Haar measure on orthogonal group,,"I have a few question regarding the Haar measure on the orthogonal, or unitary, or indeed Lie, groups. Let me consider $SO(N)$. If I were to define a probability measure on $SO(N)$, I would proceed like this. Every such matrix is the exponential of a real antisymmetric matrix, $O=e^M$. The antisymmetry constraint is much simpler than the orthogonality constraint, and I could simply put a Gaussian measure on the off-diagonal elements of $M$, thereby inducing a probability measure on $SO(N)$. First question: Is the Haar measure on $SO(N)$ related at all to the above procedure? Also, I have seen in the literature the expression $d\mu(O)=O^TdO$ to indicate the Haar measure, with the argument that this is invariant under adjoint action since $O\mapsto AO$ leaves it invariant as $(AO)^Td(AO)=O^TA^TAdO=O^TdO$. Fine. But, second question: What is meant by $dO$ in the above notation? If $O=e^M$, then I suppose $dO=OdM$ and then $O^TdO=dM$. Does this make any sense?","I have a few question regarding the Haar measure on the orthogonal, or unitary, or indeed Lie, groups. Let me consider $SO(N)$. If I were to define a probability measure on $SO(N)$, I would proceed like this. Every such matrix is the exponential of a real antisymmetric matrix, $O=e^M$. The antisymmetry constraint is much simpler than the orthogonality constraint, and I could simply put a Gaussian measure on the off-diagonal elements of $M$, thereby inducing a probability measure on $SO(N)$. First question: Is the Haar measure on $SO(N)$ related at all to the above procedure? Also, I have seen in the literature the expression $d\mu(O)=O^TdO$ to indicate the Haar measure, with the argument that this is invariant under adjoint action since $O\mapsto AO$ leaves it invariant as $(AO)^Td(AO)=O^TA^TAdO=O^TdO$. Fine. But, second question: What is meant by $dO$ in the above notation? If $O=e^M$, then I suppose $dO=OdM$ and then $O^TdO=dM$. Does this make any sense?",,"['probability', 'group-theory', 'differential-geometry', 'harmonic-analysis']"
4,On probability matching,On probability matching,,"Probability matching is the strategy of betting on different events proportionally to the probability of them happening. In standard decision theory, that's quite a bit worse than just betting all your money on the most likely event. (Assuming linear utility of money.) However, when the utility of the good bet on is not linear, this can make sense. If there is enough food for a population, split over two locations, it makes sense for the population to split matching the ratios. In Nassim Talebs Antifragility the Author writes: The idea of comparative advantage has an analog in probability: if you sample from an urn (with replacement) and get a black ball 60 percent of the time, and a white one 40 percent, the optimal strategy, according to textbooks, is to bet 100 percent of the time on black. The strategy of 60 percent of the time on black and 40 percent on white is called ""probability matching"" and considered to be an error in the decision-science literature. (...) People's instinct to engage in probability matching appears to be sound, not a mistake. In nature, probabilities are unstable (or unknown), and probability matching is similar to redundancy, as a buffer. So if the probabilites change, in other words, if there is another layer of randomness, then the optimal strategy is probability matching. I have tried some simulations using an urn-model as described, but with stochastically fluctuating $p$ (adding some uniform noise to $p$ after every draw), and in all my simulations, probability matching still performed worse. So is the quote nonsense, or are there actual precise conditions making probability matching optimal in the urn model, or at least in a more sophisticated model (not invoking non-linear utilities)? If the quote is sound, but there are no such precise conditions (or they are not feasible to formulate for you), what is the intuition behind it?","Probability matching is the strategy of betting on different events proportionally to the probability of them happening. In standard decision theory, that's quite a bit worse than just betting all your money on the most likely event. (Assuming linear utility of money.) However, when the utility of the good bet on is not linear, this can make sense. If there is enough food for a population, split over two locations, it makes sense for the population to split matching the ratios. In Nassim Talebs Antifragility the Author writes: The idea of comparative advantage has an analog in probability: if you sample from an urn (with replacement) and get a black ball 60 percent of the time, and a white one 40 percent, the optimal strategy, according to textbooks, is to bet 100 percent of the time on black. The strategy of 60 percent of the time on black and 40 percent on white is called ""probability matching"" and considered to be an error in the decision-science literature. (...) People's instinct to engage in probability matching appears to be sound, not a mistake. In nature, probabilities are unstable (or unknown), and probability matching is similar to redundancy, as a buffer. So if the probabilites change, in other words, if there is another layer of randomness, then the optimal strategy is probability matching. I have tried some simulations using an urn-model as described, but with stochastically fluctuating $p$ (adding some uniform noise to $p$ after every draw), and in all my simulations, probability matching still performed worse. So is the quote nonsense, or are there actual precise conditions making probability matching optimal in the urn model, or at least in a more sophisticated model (not invoking non-linear utilities)? If the quote is sound, but there are no such precise conditions (or they are not feasible to formulate for you), what is the intuition behind it?",,"['probability', 'decision-theory']"
5,"Showing $P(S_m<m, \forall\ 1\leq m\leq n | S_n)=\max\{0, 1-S_n/n\}$",Showing,"P(S_m<m, \forall\ 1\leq m\leq n | S_n)=\max\{0, 1-S_n/n\}","Let $X_1, X_2,\ldots$ be a sequence of iid random variables such that for each $i$, $X_i$ takes value as nonnegative integer and is in $L^1$. Let $ S_n = \sum_{i=1}^n X_i$. How to show that \begin{equation} P(S_m<m, \forall\ 1\leq m\leq n | S_n)=\max\{0, 1-S_n/n\} ? \end{equation} I think that there is something to do with martingales, but I am not really sure where to start. Thanks!","Let $X_1, X_2,\ldots$ be a sequence of iid random variables such that for each $i$, $X_i$ takes value as nonnegative integer and is in $L^1$. Let $ S_n = \sum_{i=1}^n X_i$. How to show that \begin{equation} P(S_m<m, \forall\ 1\leq m\leq n | S_n)=\max\{0, 1-S_n/n\} ? \end{equation} I think that there is something to do with martingales, but I am not really sure where to start. Thanks!",,"['probability', 'conditional-expectation', 'martingales']"
6,What does the notation $\pi$ mean in probability and statistics,What does the notation  mean in probability and statistics,\pi,"I have noticed that in the presentation of probability distribution, sometimes a certain probability is dentoed by $\pi(...)$. For example, in the wike page of Beta binomial distribution https://en.wikipedia.org/wiki/Beta-binomial_distribution , they use $P(X=k|p,n)$ to denote the distribution of $X$, while using $\pi(p|\alpha,\beta) = Beta(\alpha,\beta)$ to denote the distribution of $p$. May I ask why the notation $\pi$ is used here? Is there a specific meaning?","I have noticed that in the presentation of probability distribution, sometimes a certain probability is dentoed by $\pi(...)$. For example, in the wike page of Beta binomial distribution https://en.wikipedia.org/wiki/Beta-binomial_distribution , they use $P(X=k|p,n)$ to denote the distribution of $X$, while using $\pi(p|\alpha,\beta) = Beta(\alpha,\beta)$ to denote the distribution of $p$. May I ask why the notation $\pi$ is used here? Is there a specific meaning?",,"['probability', 'statistics']"
7,Binomial Coefficient deck of cards probability question,Binomial Coefficient deck of cards probability question,,"A regular deck of 52 playing cards has 13 ranks in 4 suits. The ranks of Jack, Queen, King and Ace of each suit are top cards. Suppose you are randomly dealt seven cards. What is the probability of getting three top cards in the same suit and any four cards in another suit (but all four in one suit)? This is what I was thinking of calculating but am completely unsure: $$    { \begin{pmatrix}     4 \\     3 \\     \end{pmatrix}   × \begin{pmatrix}     39 \\     4 \\     \end{pmatrix}  × \begin{pmatrix}     9 \\     4 \\     \end{pmatrix} \over \begin{pmatrix}     52 \\     7 \\     \end{pmatrix} } =  0.30986...$$ Any help appreciated. Thanks.","A regular deck of 52 playing cards has 13 ranks in 4 suits. The ranks of Jack, Queen, King and Ace of each suit are top cards. Suppose you are randomly dealt seven cards. What is the probability of getting three top cards in the same suit and any four cards in another suit (but all four in one suit)? This is what I was thinking of calculating but am completely unsure: $$    { \begin{pmatrix}     4 \\     3 \\     \end{pmatrix}   × \begin{pmatrix}     39 \\     4 \\     \end{pmatrix}  × \begin{pmatrix}     9 \\     4 \\     \end{pmatrix} \over \begin{pmatrix}     52 \\     7 \\     \end{pmatrix} } =  0.30986...$$ Any help appreciated. Thanks.",,"['probability', 'combinatorics', 'binomial-coefficients']"
8,conditional expected value given the random variable is less than another random variable,conditional expected value given the random variable is less than another random variable,,"Assume two independent random variables $X$ and $Y$ with p.d.f. $f(x)$ and $g(y)$. For simplicity, both $X$ and $Y$ are positive. How to find $E[X|X<Y]$? We know  $P(X<Y)=\int_0^\infty\int_0^yf(x)dxg(y)dy$. Is it true that $E[X|X<Y]=\int_0^\infty\int_0^yxf(x)dxg(y)dy$?","Assume two independent random variables $X$ and $Y$ with p.d.f. $f(x)$ and $g(y)$. For simplicity, both $X$ and $Y$ are positive. How to find $E[X|X<Y]$? We know  $P(X<Y)=\int_0^\infty\int_0^yf(x)dxg(y)dy$. Is it true that $E[X|X<Y]=\int_0^\infty\int_0^yxf(x)dxg(y)dy$?",,['probability']
9,1st Yr Probability: question about marginal and joint pdfs for $3$ uniform continuous independent random variables,1st Yr Probability: question about marginal and joint pdfs for  uniform continuous independent random variables,3,"Background I'm trying to improve my understanding of the relationship between marginal and joint pdfs for calculating specific probabilities. The Problem $X$, $Y$, $Z$ are independent and uniformly distributed $(0,1)$. What is $P(X>YZ)$? My question The book solution is below, but I'm wondering if I can solve this with the marginal distribution of $X$ alone. The marginal pdf of $X$ is $f_X(x) = 1$ In theory with $f_X(x)$ I can calculate any probability for $X$. I believe that is the whole point of having a pdf for a random variable. Therefore:$$P(X>YZ) = \int_{YZ}^{1}dx$$ $$=1-YZ$$ But this definitely isn't the right answer (which as you see below is $3/4$). The book solution makes complete sense to me. My question is why can't we get the answer from the marginal pdf of $X$? Shouldn't a marginal pdf for a RV answer all probability statements for that RV? Thanks for your help and patience! Book Solution","Background I'm trying to improve my understanding of the relationship between marginal and joint pdfs for calculating specific probabilities. The Problem $X$, $Y$, $Z$ are independent and uniformly distributed $(0,1)$. What is $P(X>YZ)$? My question The book solution is below, but I'm wondering if I can solve this with the marginal distribution of $X$ alone. The marginal pdf of $X$ is $f_X(x) = 1$ In theory with $f_X(x)$ I can calculate any probability for $X$. I believe that is the whole point of having a pdf for a random variable. Therefore:$$P(X>YZ) = \int_{YZ}^{1}dx$$ $$=1-YZ$$ But this definitely isn't the right answer (which as you see below is $3/4$). The book solution makes complete sense to me. My question is why can't we get the answer from the marginal pdf of $X$? Shouldn't a marginal pdf for a RV answer all probability statements for that RV? Thanks for your help and patience! Book Solution",,['probability']
10,How to make this an unbiased estimator of $σ^2$,How to make this an unbiased estimator of,σ^2,"Suppose $X_1, X_2, . . . , X_6$ is a random sample of a normal random variable with mean µ and variance $σ^2$ . Determine c such that c[$(X_1 − X_2)^2$ + $(X_3 − X_4)^2$ + $(X_5 − X_6)^2$] is an unbiased estimator of $σ^2$. I've attempted to get the second moments of the $(X_i − X_j)$'s and then to use these and solve for c So far I managed to find $E[X_i − X_j]$ = µ-µ = 0 and $Var[X_i − X_j]$ = $Var[X_i]$ + $Var[X_j]$ - 2$Cov[X_i,X_j]$ = 2$σ^2$- 2$Cov[X_i,X_j]$ Thus $E[(X_i − X_j)^2]$ = 2$σ^2$- 2$Cov[X_i,X_j]$ or $E[(X_i − X_j)^2]$ = 2$σ^2$+2$µ^2$ - $E[X_iX_j]$ Does anyone have any hints on how to progress from here, there's no mention in the question that the sample is i.i.d","Suppose $X_1, X_2, . . . , X_6$ is a random sample of a normal random variable with mean µ and variance $σ^2$ . Determine c such that c[$(X_1 − X_2)^2$ + $(X_3 − X_4)^2$ + $(X_5 − X_6)^2$] is an unbiased estimator of $σ^2$. I've attempted to get the second moments of the $(X_i − X_j)$'s and then to use these and solve for c So far I managed to find $E[X_i − X_j]$ = µ-µ = 0 and $Var[X_i − X_j]$ = $Var[X_i]$ + $Var[X_j]$ - 2$Cov[X_i,X_j]$ = 2$σ^2$- 2$Cov[X_i,X_j]$ Thus $E[(X_i − X_j)^2]$ = 2$σ^2$- 2$Cov[X_i,X_j]$ or $E[(X_i − X_j)^2]$ = 2$σ^2$+2$µ^2$ - $E[X_iX_j]$ Does anyone have any hints on how to progress from here, there's no mention in the question that the sample is i.i.d",,"['probability', 'statistics', 'normal-distribution', 'random']"
11,"In a hand of 13 cards, what is the probability that all cards have different values","In a hand of 13 cards, what is the probability that all cards have different values",,"I'm going to go through my thoughts, tell me if I'm right. There are $52\choose 13$ different hands with 13 cards. Each value has to appear once with 4 suits for each so there are $ 4^{13}$ different hands with each number once. So i conclude that the probability is $\frac{4^{13}}{52\choose13} \approx 1.1\times 10^{-4}$. I am really bad a probability so any help and/or tips on approaching problems at first year university level with would be appreciated (I can only find very basic or high level probability stuff with no intermediate level)","I'm going to go through my thoughts, tell me if I'm right. There are $52\choose 13$ different hands with 13 cards. Each value has to appear once with 4 suits for each so there are $ 4^{13}$ different hands with each number once. So i conclude that the probability is $\frac{4^{13}}{52\choose13} \approx 1.1\times 10^{-4}$. I am really bad a probability so any help and/or tips on approaching problems at first year university level with would be appreciated (I can only find very basic or high level probability stuff with no intermediate level)",,['probability']
12,Show that $\hat{\theta}$ is not minimax.,Show that  is not minimax.,\hat{\theta},"Let $\hat{\theta}$ be an unbiased estimator of an unknown parameter $\theta\in\mathbb{R}$. Assuming $\theta\neq 0$ we have the following loss function $$L(\theta,a) = \dfrac{(a - \theta)^2}{\theta^2}$$ Exercise: Assume that $0\leq R(\theta,T) <\infty$ for any estimator $T$. Show that $\hat{\theta}$ is not minimax. Given solution: We consider an estimator $T = c\hat{\theta}$. In this case the risk function is given by $$R(\theta, c\hat\theta) = \operatorname{E}_\theta\bigg[\dfrac{(c\hat\theta - \theta)^2}{\theta^2}\bigg]  \\= (1-c)^2 + c^2R(\theta,\hat\theta)$$ where the second term vanishes because $R(\theta, \hat\theta) = 0$, as $\hat\theta$ is unbiased. We look for a constant $c$ such that $$\sup_{\theta \in \mathbb{R}}R(\theta, c\hat\theta) < \sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta),$$ which is equivalent to \begin{equation}\sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta) > \dfrac{(1-c)^2}{1-c^2} = \dfrac{1-c}{1+c} =:g(c).\tag{1}\end{equation} Since $g:[0,1]\to[0,1]$ is continuous and decreasing, $(1)$ holds for all $c\in(0,1)$ if $\sup_\theta R(\theta,\hat\theta_n) > 1.$ If $\sup_\theta R(\theta,\hat\theta_n) \leq 1$, then there exists a $c^{*}$ such that $(1)$ holds for all $c\geq c^{*}$. What I don't understand about this solution: We have that $R(\theta, \hat\theta) = 0$ since $\hat\theta$ is unbiased, and $(R,c\hat\theta) = c^2 - 2c + 1$, as is indicated in the solution. Now, $c^2 -2c + 1 \geq 0,$ so there is no $c^{*}$ such that $R(\theta, c\hat\theta) < R(\theta, \hat\theta).$ Obviously I'm missing something, as I don't understand the subscript $n$ that is used in the last few lines in the solution. It seems to me that since in this solution $R(\theta,\hat\theta)$ can be larger than zero, $R(\theta,\hat\theta)$ depends on $\theta$. Question: Is the given solution correct? If so; what's wrong with my reasoning? How can $R(\theta, \hat\theta)> 0$? Thanks!","Let $\hat{\theta}$ be an unbiased estimator of an unknown parameter $\theta\in\mathbb{R}$. Assuming $\theta\neq 0$ we have the following loss function $$L(\theta,a) = \dfrac{(a - \theta)^2}{\theta^2}$$ Exercise: Assume that $0\leq R(\theta,T) <\infty$ for any estimator $T$. Show that $\hat{\theta}$ is not minimax. Given solution: We consider an estimator $T = c\hat{\theta}$. In this case the risk function is given by $$R(\theta, c\hat\theta) = \operatorname{E}_\theta\bigg[\dfrac{(c\hat\theta - \theta)^2}{\theta^2}\bigg]  \\= (1-c)^2 + c^2R(\theta,\hat\theta)$$ where the second term vanishes because $R(\theta, \hat\theta) = 0$, as $\hat\theta$ is unbiased. We look for a constant $c$ such that $$\sup_{\theta \in \mathbb{R}}R(\theta, c\hat\theta) < \sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta),$$ which is equivalent to \begin{equation}\sup_{\theta\in\mathbb{R}}R(\theta, \hat\theta) > \dfrac{(1-c)^2}{1-c^2} = \dfrac{1-c}{1+c} =:g(c).\tag{1}\end{equation} Since $g:[0,1]\to[0,1]$ is continuous and decreasing, $(1)$ holds for all $c\in(0,1)$ if $\sup_\theta R(\theta,\hat\theta_n) > 1.$ If $\sup_\theta R(\theta,\hat\theta_n) \leq 1$, then there exists a $c^{*}$ such that $(1)$ holds for all $c\geq c^{*}$. What I don't understand about this solution: We have that $R(\theta, \hat\theta) = 0$ since $\hat\theta$ is unbiased, and $(R,c\hat\theta) = c^2 - 2c + 1$, as is indicated in the solution. Now, $c^2 -2c + 1 \geq 0,$ so there is no $c^{*}$ such that $R(\theta, c\hat\theta) < R(\theta, \hat\theta).$ Obviously I'm missing something, as I don't understand the subscript $n$ that is used in the last few lines in the solution. It seems to me that since in this solution $R(\theta,\hat\theta)$ can be larger than zero, $R(\theta,\hat\theta)$ depends on $\theta$. Question: Is the given solution correct? If so; what's wrong with my reasoning? How can $R(\theta, \hat\theta)> 0$? Thanks!",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
13,Prove or disprove the following inequality,Prove or disprove the following inequality,,"If $X$ is a non-constant random variable with $X \geq 0$ then $$[E(X^{\alpha+1})]^{\alpha}-[E(X^{\alpha})]^{\alpha+1} > 0$$  for  $\alpha=1,2,3,4,...$ It is easy for $\alpha=1$, because this is same as variance. But for other values of $\alpha$, I am confused. Also I could not find any counter example for $\alpha=2,3$ etc. But how to prove then if this is correct. Please help me. Thanks.","If $X$ is a non-constant random variable with $X \geq 0$ then $$[E(X^{\alpha+1})]^{\alpha}-[E(X^{\alpha})]^{\alpha+1} > 0$$  for  $\alpha=1,2,3,4,...$ It is easy for $\alpha=1$, because this is same as variance. But for other values of $\alpha$, I am confused. Also I could not find any counter example for $\alpha=2,3$ etc. But how to prove then if this is correct. Please help me. Thanks.",,"['probability', 'functional-analysis', 'inequality', 'expectation', 'integral-inequality']"
14,Prove that this sequence is a submartingale,Prove that this sequence is a submartingale,,"Let $X_1, X_2,\cdots$ be i.i.d. random variable on $(\Omega, \mathbb F)$ with $EX_1=0$ and $VX_1 = \sigma^2$. Consider a filtration $\mathbb F_n = \mathbb F(X_1,\cdots, X_n)$. I want to show that $Y_n = \left( \sum_{k=1}^n X_k \right)^2$ is a   submartingale. This is my attempt: \begin{eqnarray} E[Y_{n+1} | \mathbb F_n] &= E \left[ \left( \sum_{k=1}^{n+1} X_k \right)^2 \,\,\big|\,\, \mathbb F_n \right] \\ &= E \left[ \sum_{i,j=1}^{n+1} X_iX_j \,\,\big|\,\, \mathbb F_n \right] \\ &= \sum_{i,j=1}^{n+1} E \left[ X_i \,\,\big|\,\, \mathbb F_n \right] E \left[ X_j \,\,\big|\,\, \mathbb F_n \right] \\ &= \sum_{i,j=1}^{n} X_i X_j + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right] \\ &= Y_n + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right] \end{eqnarray} How can I proceed from here? Of course if I knew $X_i\geq 0$ I would be done, but as is I don't know what to do next. Moreover, I'm not sure how to show that $E |Y_n| < \infty$ when we don't know that $X_i\geq 0$. Any help is MUCH appreciated.","Let $X_1, X_2,\cdots$ be i.i.d. random variable on $(\Omega, \mathbb F)$ with $EX_1=0$ and $VX_1 = \sigma^2$. Consider a filtration $\mathbb F_n = \mathbb F(X_1,\cdots, X_n)$. I want to show that $Y_n = \left( \sum_{k=1}^n X_k \right)^2$ is a   submartingale. This is my attempt: \begin{eqnarray} E[Y_{n+1} | \mathbb F_n] &= E \left[ \left( \sum_{k=1}^{n+1} X_k \right)^2 \,\,\big|\,\, \mathbb F_n \right] \\ &= E \left[ \sum_{i,j=1}^{n+1} X_iX_j \,\,\big|\,\, \mathbb F_n \right] \\ &= \sum_{i,j=1}^{n+1} E \left[ X_i \,\,\big|\,\, \mathbb F_n \right] E \left[ X_j \,\,\big|\,\, \mathbb F_n \right] \\ &= \sum_{i,j=1}^{n} X_i X_j + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right] \\ &= Y_n + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right] \end{eqnarray} How can I proceed from here? Of course if I knew $X_i\geq 0$ I would be done, but as is I don't know what to do next. Moreover, I'm not sure how to show that $E |Y_n| < \infty$ when we don't know that $X_i\geq 0$. Any help is MUCH appreciated.",,"['probability', 'probability-theory', 'martingales']"
15,"Verify that $\Theta\mid X\sim N(\mu_1,\sigma_1^2)$",Verify that,"\Theta\mid X\sim N(\mu_1,\sigma_1^2)","Suppose that $X_1,\ldots,X_n\mid\Theta = \theta\stackrel{iid}{\sim}N(\theta, \sigma^2)$ and $\Theta\sim N(\mu_0, \sigma_0^2)$ where we assume $\sigma^2$ to be known. The parameter $\mu_0$ and $\sigma_0^2$ are also assumed to be known and are part of the prior specification. If we set $X = (X_1,\ldots,X_n)$ , then $$\Theta\mid X \sim N(\mu_1, \sigma_1^2)$$ with $\mu_1 = \sigma_1^2\bigg(\dfrac{\mu_0}{\sigma_0^2} + \dfrac{n\overline{X_n}}{\sigma^2}\bigg)$ and $\dfrac{1}{\sigma_1^2} = \dfrac{1}{\sigma_0^2} + \dfrac{1}{\sigma^2}.$ Exercise: Verify the above calculations. What I've tried: I know that $f_{\Theta\mid X}(\theta\mid x) \propto f_{X\mid\Theta}(x\mid\theta)\, f_\Theta(\theta)$ . Hence, $$f_{\Theta\mid X}(\theta\mid x)\propto \prod_{i = 1}^n\dfrac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\dfrac{(x_i-\theta)^2}{2\sigma^2}\bigg)}\dfrac{1}{\sqrt{2\pi\sigma_0^2}}\exp\bigg(-\dfrac{(\theta-\mu_0)^2}{2\sigma_0^2}\bigg).$$ I tried to look at this product and find the matching distribution by just looking at the exponential and the rest of the function separately. If we fast forward through some calculations, and just look at the exponential we get: $\exp\bigg[-\bigg(\dfrac{\sum_{i = 1}^nx_i^2 - 2\theta\sum_{i =1}^n x_i + n\theta^2}{2\sigma^2} + \dfrac{n\theta^2 - 2n\theta\mu_0 + n\mu_0^2}{2\sigma_0^2}\bigg)\bigg]$ . I can see that the $\sum_{i = 1}^nx_i$ part can be written as $n\overline{X_n}$ , but don't know how to make the other terms cancel out. I looked at the other part of the function as well: $$\bigg(\dfrac{1}{\sqrt{2\pi\sigma^2}}\bigg)^n\dfrac{1}{\sqrt{2\pi\sigma_0^2}},$$ but again I'm not sure how this translates to $1/\sigma_1^2 = 1/\sigma_0^2 + 1/\sigma^2$ . Question: How do I solve this exercise and show that $\Theta\mid X \sim N(\mu_1,\sigma_1^2)$ ? Thanks in advance!","Suppose that and where we assume to be known. The parameter and are also assumed to be known and are part of the prior specification. If we set , then with and Exercise: Verify the above calculations. What I've tried: I know that . Hence, I tried to look at this product and find the matching distribution by just looking at the exponential and the rest of the function separately. If we fast forward through some calculations, and just look at the exponential we get: . I can see that the part can be written as , but don't know how to make the other terms cancel out. I looked at the other part of the function as well: but again I'm not sure how this translates to . Question: How do I solve this exercise and show that ? Thanks in advance!","X_1,\ldots,X_n\mid\Theta = \theta\stackrel{iid}{\sim}N(\theta, \sigma^2) \Theta\sim N(\mu_0, \sigma_0^2) \sigma^2 \mu_0 \sigma_0^2 X = (X_1,\ldots,X_n) \Theta\mid X \sim N(\mu_1, \sigma_1^2) \mu_1 = \sigma_1^2\bigg(\dfrac{\mu_0}{\sigma_0^2} + \dfrac{n\overline{X_n}}{\sigma^2}\bigg) \dfrac{1}{\sigma_1^2} = \dfrac{1}{\sigma_0^2} + \dfrac{1}{\sigma^2}. f_{\Theta\mid X}(\theta\mid x) \propto f_{X\mid\Theta}(x\mid\theta)\, f_\Theta(\theta) f_{\Theta\mid X}(\theta\mid x)\propto \prod_{i = 1}^n\dfrac{1}{\sqrt{2\pi\sigma^2}}\exp{\bigg(-\dfrac{(x_i-\theta)^2}{2\sigma^2}\bigg)}\dfrac{1}{\sqrt{2\pi\sigma_0^2}}\exp\bigg(-\dfrac{(\theta-\mu_0)^2}{2\sigma_0^2}\bigg). \exp\bigg[-\bigg(\dfrac{\sum_{i = 1}^nx_i^2 - 2\theta\sum_{i =1}^n x_i + n\theta^2}{2\sigma^2} + \dfrac{n\theta^2 - 2n\theta\mu_0 + n\mu_0^2}{2\sigma_0^2}\bigg)\bigg] \sum_{i = 1}^nx_i n\overline{X_n} \bigg(\dfrac{1}{\sqrt{2\pi\sigma^2}}\bigg)^n\dfrac{1}{\sqrt{2\pi\sigma_0^2}}, 1/\sigma_1^2 = 1/\sigma_0^2 + 1/\sigma^2 \Theta\mid X \sim N(\mu_1,\sigma_1^2)","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'normal-distribution']"
16,Basu's theorem for normal sample mean and variance,Basu's theorem for normal sample mean and variance,,"I'm working on the following problem: Suppose that $X \sim N(\mu,\sigma^2)$. Let the sample mean and variance, $\overline{X}$ and $S^2$ be defined as usual so that $\mathbb{E} S^2 = \sigma^2$. Prove that the sample mean is independent of the sample variance. Given that both $\mu$ and $\sigma^2$ are unknown, find the MVUE for $\mu \sigma^2$. The second part is simple. Given that $\overline{X}$ and $S^2$ are independent, and that $(\overline{X}, S^2)$ is a jointly complete and sufficient statistic for $(\mu, \sigma^2)$, we have that $\phi ( \overline{X}, S^2) = \overline{X} S^2$ is unbiased for $\mu \sigma^2$. By Lehmann-Schefee, $\phi$ is the MVUE for $\mu \sigma^2$. To prove independence, I would like to implore Basu's Theorem. This says, briefly, that any boundedly (which I will ignore) complete sufficient statistic is independent of any ancillary statistic. It is not hard to show that the normal distribution is exponential class. Moreover, given known variance, we get that $\sum X_i$ is a complete and sufficient statistic for $\mu$. It is clear that $S^2$ is ancillary, since (accept my abuse of notation) for any $a \in \mathbb{R}$, $$ S^2+a = \frac{1}{n-1} \sum_{i=1}^n \Big( X_i + a - \frac{1}{n}\sum_{i=1}^n \big( X_i + a  \big) \Big)^2 = \frac{1}{n-1} \sum_{i=1}^n \Big( X_i - \overline{X}\Big)^2   $$ so that $S^2$ is location invariant, and hence ancillary. So, if we were only interested in estimating $\mu$, we would be done. My question is, how do I deal with applying Basu's theorem when I have a jointly complete and sufficient statistic. Does it suffice to only show that $\sum X$ is complete and sufficient statistic for $\mu$ even though I'm estimating a function of $\mu$ and $\sigma^2$? Note: there is a similar (mostly unanswered), but not identical question here: UMVUE using complete and sufficient statistic","I'm working on the following problem: Suppose that $X \sim N(\mu,\sigma^2)$. Let the sample mean and variance, $\overline{X}$ and $S^2$ be defined as usual so that $\mathbb{E} S^2 = \sigma^2$. Prove that the sample mean is independent of the sample variance. Given that both $\mu$ and $\sigma^2$ are unknown, find the MVUE for $\mu \sigma^2$. The second part is simple. Given that $\overline{X}$ and $S^2$ are independent, and that $(\overline{X}, S^2)$ is a jointly complete and sufficient statistic for $(\mu, \sigma^2)$, we have that $\phi ( \overline{X}, S^2) = \overline{X} S^2$ is unbiased for $\mu \sigma^2$. By Lehmann-Schefee, $\phi$ is the MVUE for $\mu \sigma^2$. To prove independence, I would like to implore Basu's Theorem. This says, briefly, that any boundedly (which I will ignore) complete sufficient statistic is independent of any ancillary statistic. It is not hard to show that the normal distribution is exponential class. Moreover, given known variance, we get that $\sum X_i$ is a complete and sufficient statistic for $\mu$. It is clear that $S^2$ is ancillary, since (accept my abuse of notation) for any $a \in \mathbb{R}$, $$ S^2+a = \frac{1}{n-1} \sum_{i=1}^n \Big( X_i + a - \frac{1}{n}\sum_{i=1}^n \big( X_i + a  \big) \Big)^2 = \frac{1}{n-1} \sum_{i=1}^n \Big( X_i - \overline{X}\Big)^2   $$ so that $S^2$ is location invariant, and hence ancillary. So, if we were only interested in estimating $\mu$, we would be done. My question is, how do I deal with applying Basu's theorem when I have a jointly complete and sufficient statistic. Does it suffice to only show that $\sum X$ is complete and sufficient statistic for $\mu$ even though I'm estimating a function of $\mu$ and $\sigma^2$? Note: there is a similar (mostly unanswered), but not identical question here: UMVUE using complete and sufficient statistic",,"['probability', 'statistics', 'independence']"
17,Minimal eigenvalue inequality,Minimal eigenvalue inequality,,"My problem is to show that $$\lambda_{\min}(PA) \leq  \lambda_{\min}((D-M)A) ,$$ where $A$ is an arbitrary $n\times n$ symmetric positive definite matrix and $P$ is a diagonal matrix with $\frac{1}{A_{ii}}$ as the $i$-th diagonal element and $D$ is a diagonal matrix with the $i$-th diagonal element equal to $\sum_{j = 1}^n\frac{p_{ij}A_{jj}}{\det_{ij}}$ and $M$ is a symmetric matrix with $M_{ij} = \frac{p_{ij}A_{ij}}{\det_{ij}}$, where $p_{ij}$ are probabilities with $p_{ii} = 0,\, \forall i$,  $p_{ij} = \frac{1}{n-1}$ for $i\neq j$, and $\det_{ij} = A_{ii}A_{jj} - A_{ij}^2$ for $i \neq j$, and $\det_{ii} = 1$ for all $i$. $A_{ij}$ is the element on the $i$-th row and $j$-th column. I have tried many simulations and this statement always holds, even with some special cases $2$ can be substituted by arbitrary large constant, but I am not able to contstruct a proof except when $A$ is diagonal.","My problem is to show that $$\lambda_{\min}(PA) \leq  \lambda_{\min}((D-M)A) ,$$ where $A$ is an arbitrary $n\times n$ symmetric positive definite matrix and $P$ is a diagonal matrix with $\frac{1}{A_{ii}}$ as the $i$-th diagonal element and $D$ is a diagonal matrix with the $i$-th diagonal element equal to $\sum_{j = 1}^n\frac{p_{ij}A_{jj}}{\det_{ij}}$ and $M$ is a symmetric matrix with $M_{ij} = \frac{p_{ij}A_{ij}}{\det_{ij}}$, where $p_{ij}$ are probabilities with $p_{ii} = 0,\, \forall i$,  $p_{ij} = \frac{1}{n-1}$ for $i\neq j$, and $\det_{ij} = A_{ii}A_{jj} - A_{ij}^2$ for $i \neq j$, and $\det_{ii} = 1$ for all $i$. $A_{ij}$ is the element on the $i$-th row and $j$-th column. I have tried many simulations and this statement always holds, even with some special cases $2$ can be substituted by arbitrary large constant, but I am not able to contstruct a proof except when $A$ is diagonal.",,"['linear-algebra', 'probability', 'eigenvalues-eigenvectors', 'positive-definite']"
18,Minimal matrix eigenvalue of matrices with the same structure,Minimal matrix eigenvalue of matrices with the same structure,,"My problem is to show that $$2\lambda_{min}(PA) \leq  \lambda_{min}((D-M)A) ,$$ where $A$ is arbitrary $nxn$ symmetric positive definite matrix and $P$ is diagonal matrix, which has $\frac{1}{nA_{ii}}$ on the $i$-th element on the diagonal and $D$ is diagonal matrix with $i$-th diagonal element equals to $2\sum_{j = 1}^n\frac{p_{ij}A_{jj}}{Det_{ij}}$ and $M$ is symmetric matrix with $M_{ij} = 2\frac{p_{ij}A_{ij}}{Det_{ij}}$, where $p_{ij}$ are probabilities with $p_{ii} = 0$  for all $i$,  $p_{ij} = \frac{1}{n(n-1)}$ for $i\neq j$, and $Det_{ij} = A_{ii}A_{jj} - A_{ij}^2$ for $i \neq j$, and $Det_{ii} = 1$ for all $i$. $A_{ij}$ corresponds to the element in the $i$-th row and $j$-th column. I tried many experiments and this statement always holds, even with some special cases $2$ can be substituted by arbitrary large constant, but I cannot get any theoretical proof.","My problem is to show that $$2\lambda_{min}(PA) \leq  \lambda_{min}((D-M)A) ,$$ where $A$ is arbitrary $nxn$ symmetric positive definite matrix and $P$ is diagonal matrix, which has $\frac{1}{nA_{ii}}$ on the $i$-th element on the diagonal and $D$ is diagonal matrix with $i$-th diagonal element equals to $2\sum_{j = 1}^n\frac{p_{ij}A_{jj}}{Det_{ij}}$ and $M$ is symmetric matrix with $M_{ij} = 2\frac{p_{ij}A_{ij}}{Det_{ij}}$, where $p_{ij}$ are probabilities with $p_{ii} = 0$  for all $i$,  $p_{ij} = \frac{1}{n(n-1)}$ for $i\neq j$, and $Det_{ij} = A_{ii}A_{jj} - A_{ij}^2$ for $i \neq j$, and $Det_{ii} = 1$ for all $i$. $A_{ij}$ corresponds to the element in the $i$-th row and $j$-th column. I tried many experiments and this statement always holds, even with some special cases $2$ can be substituted by arbitrary large constant, but I cannot get any theoretical proof.",,"['linear-algebra', 'probability', 'eigenvalues-eigenvectors']"
19,How do these authors get to this result?,How do these authors get to this result?,,"I am not sure if this question satisfies the guidelines, but here goes. I'm reading a paper (text is below) from a financial mathematics journal, and the authors make a calculation step that I don't get. They reach the conclusion that $$E_i(\theta)=\frac{\alpha y + \beta x_i}{\alpha +\beta}$$ Whereas I would guess that the result should be either $$E_i(\theta)=y$$ or $$E_i(\theta):=E_i(\theta|x_i)=E_i(x_i)-E_i(\epsilon_i)=x_i$$ In the second case I'm interpreting the expectation as conditional expectation, and this seems to me the most sensible interpretation. However the author's result is completely different as you can see, and I have no idea how they get to that result . In fact, if this weren't published in a peer reviewed journal, I would assume they made a very weird mistake. But since it's in a peer reviewed journal, I must miss something. Here is the entire text: Here is some context: Here is the part my question is about: How do they get to this result? How should I interpret the setup of their problem so that the conclusion makes sense?","I am not sure if this question satisfies the guidelines, but here goes. I'm reading a paper (text is below) from a financial mathematics journal, and the authors make a calculation step that I don't get. They reach the conclusion that Whereas I would guess that the result should be either or In the second case I'm interpreting the expectation as conditional expectation, and this seems to me the most sensible interpretation. However the author's result is completely different as you can see, and I have no idea how they get to that result . In fact, if this weren't published in a peer reviewed journal, I would assume they made a very weird mistake. But since it's in a peer reviewed journal, I must miss something. Here is the entire text: Here is some context: Here is the part my question is about: How do they get to this result? How should I interpret the setup of their problem so that the conclusion makes sense?",E_i(\theta)=\frac{\alpha y + \beta x_i}{\alpha +\beta} E_i(\theta)=y E_i(\theta):=E_i(\theta|x_i)=E_i(x_i)-E_i(\epsilon_i)=x_i,"['probability', 'finance', 'conditional-expectation']"
20,Probability of Occurence of HEART or EARTH,Probability of Occurence of HEART or EARTH,,"This is one of the questions I came across and I could only solve it partially. The question went A man is randomly typing on a keyboard. Then, what is the probability that the word HEART comes before EARTH? My attempts The first $4$ letters of EARTH are the same as last 4 of HEART. For EARTH to appear before HEART, any letter other than H must've appeared first and then should be followed by EART and then a H later on. For HEART to appear first before EARTH, only the letter H must've appeared first and then may be followed by EART. Since, the number of letters to appear in the case of HEART is less than EARTH, the probability of occurrence of HEART is more than that of EARTH. To calculate how much, I'm just considering in case of EARTH first: $$P(E)=\frac{25}{26}.\frac{1}{26}.\frac{1}{26}.\frac{1}{26}$$ HEART first: $$P(E)=\frac{1}{26}.\frac{25}{26}.\frac{25}{26}.\frac{25}{26}$$ This obviously isn't correct, since it doesn't give any individual probability for the occurrence of each letter. So, can anyone calculate the probability for each of these two?","This is one of the questions I came across and I could only solve it partially. The question went A man is randomly typing on a keyboard. Then, what is the probability that the word HEART comes before EARTH? My attempts The first $4$ letters of EARTH are the same as last 4 of HEART. For EARTH to appear before HEART, any letter other than H must've appeared first and then should be followed by EART and then a H later on. For HEART to appear first before EARTH, only the letter H must've appeared first and then may be followed by EART. Since, the number of letters to appear in the case of HEART is less than EARTH, the probability of occurrence of HEART is more than that of EARTH. To calculate how much, I'm just considering in case of EARTH first: $$P(E)=\frac{25}{26}.\frac{1}{26}.\frac{1}{26}.\frac{1}{26}$$ HEART first: $$P(E)=\frac{1}{26}.\frac{25}{26}.\frac{25}{26}.\frac{25}{26}$$ This obviously isn't correct, since it doesn't give any individual probability for the occurrence of each letter. So, can anyone calculate the probability for each of these two?",,['probability']
21,Simulating truncated normal distribution,Simulating truncated normal distribution,,"The truncated normal distribution has pdf: $$f(x;\mu,\sigma,a,b) = \frac{\varphi\left(\frac{x-\mu}{\sigma}\right)}{\sigma\left(\Phi\left(\frac{b-\mu}{\sigma}\right)-\Phi\left(\frac{a-\mu}{\sigma}\right)\right)}.$$ And $f=0$ otherwise. Here $\varphi(x) = \frac{\exp\left(-\frac{x^2}{2}\right)}{\sqrt{2\pi}}$, $\Phi(x) = \frac{1}{2}(1+\operatorname{erf}(x/\sqrt{2}))$ and $a<b$, $\sigma>0$. I want to draw samples using only the normal distribution (using Python 2.7), and i do this by taking a value from the normal distribution with the same mean $\mu$ and sd $\sigma$ over and over again until this value lies between $a,b$. I have made a histogram using a sample size of 100.000 and plotted it with this pdf and it looks similar. My question is: are these distributions the same?","The truncated normal distribution has pdf: $$f(x;\mu,\sigma,a,b) = \frac{\varphi\left(\frac{x-\mu}{\sigma}\right)}{\sigma\left(\Phi\left(\frac{b-\mu}{\sigma}\right)-\Phi\left(\frac{a-\mu}{\sigma}\right)\right)}.$$ And $f=0$ otherwise. Here $\varphi(x) = \frac{\exp\left(-\frac{x^2}{2}\right)}{\sqrt{2\pi}}$, $\Phi(x) = \frac{1}{2}(1+\operatorname{erf}(x/\sqrt{2}))$ and $a<b$, $\sigma>0$. I want to draw samples using only the normal distribution (using Python 2.7), and i do this by taking a value from the normal distribution with the same mean $\mu$ and sd $\sigma$ over and over again until this value lies between $a,b$. I have made a histogram using a sample size of 100.000 and plotted it with this pdf and it looks similar. My question is: are these distributions the same?",,"['probability', 'statistics', 'normal-distribution', 'density-function']"
22,Average of two random variables - CDF comparison,Average of two random variables - CDF comparison,,"Given are two independent random variables $X$ and $Y$ with different probability density functions $f_X(t)$ and $f_Y(t)$.  It is furthermore given that the cumulative distribution function $F_X(x) = \int_{-\infty}^x f_X(t)\,dt$ of $X$ is always larger than or equal to $F_Y(x)=\int_{-\infty}^x f_Y(t)\,dt$ of $Y$. That is $\forall x \in \mathbb{R}: F_X(x) \geq F_Y(x).$ A third random variable $Z$ with $f_Z(t)$ is defined as $Z = \frac{X+Y}{2}$.  My assumption is that $F_X(x)$ is always larger than or equal to $F_Z(x) = \int_{-\infty}^x f_Z(t)\,dt$, too. That is $\forall x \in \mathbb{R}: F_X(x) \geq F_Z(x).$ Is this a valid assumption and if yes, how to prove it? Under which conditions does it hold if it is not a universally valid assumption? The plots below depict the cumulative distribution functions as well as the probability density functions of exemplary X,Y and Z. Edit : I was able to show it for two given uniform distributions as follows. However, I assume it should also be possible to prove it for two arbitrary distributions. PDFs: $f_X(t) = \begin{cases} \frac{1}{2} & \text{for } 0 \leq t \leq 2,\\ 0 & \text{otherwise} \end{cases}$, $f_Y(t) = \begin{cases} \frac{1}{2} & \text{for } 4 \leq t \leq 6,\\ 0 & \text{otherwise} \end{cases}$ CDFs: $F_X(x) = \begin{cases} 0 & \text{for } x < 0,\\ \frac{x}{2} & \text{for } 0 \leq x \leq 2,\\ 1 & \text{for } x > 2 \end{cases}$, $F_Y(x) = \begin{cases} 0 & \text{for } x < 4,\\ \frac{x-4}{2} & \text{for } 4 \leq x \leq 6,\\ 1 & \text{for } x > 6 \end{cases}$, $\forall x \in \mathbb{R}: F_X(x) \geq F_Y(x)$ obviously holds, because $F_X(x) = 1$ for all $x$ where $F_Y(x) > 0$. The addition of X and Y is described by the convolution of $f_X(t)$ and $f_Y(t)$ as $f_{X+Y}(t) = (f_X * f_Y)(t) = \int_{-\infty}^\infty f_X(\tau)\cdot f_Y(t-\tau)\,d\tau = \begin{cases}     -1+\frac{t}{4} & \text{for } 4 \leq t \leq 6\\     2 - \frac{t}{4} & \text{for } 6 < t \leq 8\\     0 & \text{otherwise} \end{cases}$ and (as far as I know) dividing by 2 corresponds to scaling on both axes, so $f_Z(t) = 2\cdot f_{X+Y}(2t) = \begin{cases}     -2+t & \text{for } 2 \leq t \leq 3\\     4 - t & \text{for } 3 < t \leq 4\\     0 & \text{otherwise.} \end{cases}$ From this we get the CDF of Z: $F_Z(x) = \int_{-\infty}^x f_Z(t)\,dt = \begin{cases} 0 & \text{for } x < 2,\\ \frac{1}{2} x^2 -2x+2 & \text{for } 2 \leq x \leq 3,\\ -\frac{1}{2} x^2 + 4x -7& \text{for } 3 < x \leq 4,\\  1 & \text{for } x > 4 \end{cases}$ $\forall x \in \mathbb{R}: F_X(x) \geq F_Z(x)$ holds, too, because $F_X(x) = 1$ for all $x$ where $F_Z(x) > 0$.","Given are two independent random variables $X$ and $Y$ with different probability density functions $f_X(t)$ and $f_Y(t)$.  It is furthermore given that the cumulative distribution function $F_X(x) = \int_{-\infty}^x f_X(t)\,dt$ of $X$ is always larger than or equal to $F_Y(x)=\int_{-\infty}^x f_Y(t)\,dt$ of $Y$. That is $\forall x \in \mathbb{R}: F_X(x) \geq F_Y(x).$ A third random variable $Z$ with $f_Z(t)$ is defined as $Z = \frac{X+Y}{2}$.  My assumption is that $F_X(x)$ is always larger than or equal to $F_Z(x) = \int_{-\infty}^x f_Z(t)\,dt$, too. That is $\forall x \in \mathbb{R}: F_X(x) \geq F_Z(x).$ Is this a valid assumption and if yes, how to prove it? Under which conditions does it hold if it is not a universally valid assumption? The plots below depict the cumulative distribution functions as well as the probability density functions of exemplary X,Y and Z. Edit : I was able to show it for two given uniform distributions as follows. However, I assume it should also be possible to prove it for two arbitrary distributions. PDFs: $f_X(t) = \begin{cases} \frac{1}{2} & \text{for } 0 \leq t \leq 2,\\ 0 & \text{otherwise} \end{cases}$, $f_Y(t) = \begin{cases} \frac{1}{2} & \text{for } 4 \leq t \leq 6,\\ 0 & \text{otherwise} \end{cases}$ CDFs: $F_X(x) = \begin{cases} 0 & \text{for } x < 0,\\ \frac{x}{2} & \text{for } 0 \leq x \leq 2,\\ 1 & \text{for } x > 2 \end{cases}$, $F_Y(x) = \begin{cases} 0 & \text{for } x < 4,\\ \frac{x-4}{2} & \text{for } 4 \leq x \leq 6,\\ 1 & \text{for } x > 6 \end{cases}$, $\forall x \in \mathbb{R}: F_X(x) \geq F_Y(x)$ obviously holds, because $F_X(x) = 1$ for all $x$ where $F_Y(x) > 0$. The addition of X and Y is described by the convolution of $f_X(t)$ and $f_Y(t)$ as $f_{X+Y}(t) = (f_X * f_Y)(t) = \int_{-\infty}^\infty f_X(\tau)\cdot f_Y(t-\tau)\,d\tau = \begin{cases}     -1+\frac{t}{4} & \text{for } 4 \leq t \leq 6\\     2 - \frac{t}{4} & \text{for } 6 < t \leq 8\\     0 & \text{otherwise} \end{cases}$ and (as far as I know) dividing by 2 corresponds to scaling on both axes, so $f_Z(t) = 2\cdot f_{X+Y}(2t) = \begin{cases}     -2+t & \text{for } 2 \leq t \leq 3\\     4 - t & \text{for } 3 < t \leq 4\\     0 & \text{otherwise.} \end{cases}$ From this we get the CDF of Z: $F_Z(x) = \int_{-\infty}^x f_Z(t)\,dt = \begin{cases} 0 & \text{for } x < 2,\\ \frac{1}{2} x^2 -2x+2 & \text{for } 2 \leq x \leq 3,\\ -\frac{1}{2} x^2 + 4x -7& \text{for } 3 < x \leq 4,\\  1 & \text{for } x > 4 \end{cases}$ $\forall x \in \mathbb{R}: F_X(x) \geq F_Z(x)$ holds, too, because $F_X(x) = 1$ for all $x$ where $F_Z(x) > 0$.",,"['probability', 'probability-distributions', 'random-variables']"
23,Two probabilities of the same thing,Two probabilities of the same thing,,"Consider this minesweeper situation. The 3 I've circled tells us that there is a mine in one of A, B and C. So, this means the probability that the mine is in A is $\frac{1}{3}$. And the 4 I've circled (and the 2 below it) tells that there is a mine in A or D. This makes the probability of finding a mine in A = $\frac{1}{2}$. So, how to combine these two probabilities to get the actual probability of finding a mine in A? I thought of this: There are two possibilities: Either there is a single mine in A or there is one mine in D and one in B or C. These two possibilities are equally likely, I guess. So, the probability that there's a mine in A is $\frac{1}{2}$. If that was correct, then is there any other approach to this? EDIT: Also, the circled 3 tells that that the probability that a mine is in B or C=$\frac{2}{3}$. But if we consider the 3 to the right of the circled 3, it tells us that there is a single mine in one of B,C,E and F, which makes the probability of finding a mine in B or C=$\frac{1}{2}$. Again, there are two probabilities of finding a mine in B or C.","Consider this minesweeper situation. The 3 I've circled tells us that there is a mine in one of A, B and C. So, this means the probability that the mine is in A is $\frac{1}{3}$. And the 4 I've circled (and the 2 below it) tells that there is a mine in A or D. This makes the probability of finding a mine in A = $\frac{1}{2}$. So, how to combine these two probabilities to get the actual probability of finding a mine in A? I thought of this: There are two possibilities: Either there is a single mine in A or there is one mine in D and one in B or C. These two possibilities are equally likely, I guess. So, the probability that there's a mine in A is $\frac{1}{2}$. If that was correct, then is there any other approach to this? EDIT: Also, the circled 3 tells that that the probability that a mine is in B or C=$\frac{2}{3}$. But if we consider the 3 to the right of the circled 3, it tells us that there is a single mine in one of B,C,E and F, which makes the probability of finding a mine in B or C=$\frac{1}{2}$. Again, there are two probabilities of finding a mine in B or C.",,[]
24,Probability of not finding a joker among 54 cards until the 54th draw?,Probability of not finding a joker among 54 cards until the 54th draw?,,"I manage a ""Joker Poker Raffle"" for a veterans club in Shelton, WA.  We start each round with 54 cards (4 suits @ 13 cards plus 1 mini Joker and 1 Jackpot Joker) sealed in identical envelopes.  Each Saturday we sell tickets and then draw one ticket from a tumbler.  The person with the winning ticket selects one envelope.  If the selected envelope contains the Joker, the Jackpot is awarded, if not the game goes on.  The current round has gone for 53 weeks without a Jackpot win.  Folk are asking me what are the odds. I wonder if the question can be viewed as flipping a fair coin 53 times and getting 53 heads and then getting 1 tail? In addition, several players take the position that inasmuch as everybody knows that the last envelope contains the Joker, we should end this round and start a new round with 54 new envelopes.  Their thinking is that the first 53 draws posed dual risk; i.e. the risk that one's ticket would be selected plus the risk that the winning ticket holder would select the envelope with the Joker.  Obviously, on the 54th draw, there is only singular risk. Can you mathematicians help us veterans?  (A)  Is not identifying the Joker until the 54th draw a rare event, or can we expect this to happen frequently and (B) Is it fair to allow the person whose ticket is selected next Saturday to claim the Jackpot, or should we start a new round with 54 envelopes? Thank you Brian Walsh","I manage a ""Joker Poker Raffle"" for a veterans club in Shelton, WA.  We start each round with 54 cards (4 suits @ 13 cards plus 1 mini Joker and 1 Jackpot Joker) sealed in identical envelopes.  Each Saturday we sell tickets and then draw one ticket from a tumbler.  The person with the winning ticket selects one envelope.  If the selected envelope contains the Joker, the Jackpot is awarded, if not the game goes on.  The current round has gone for 53 weeks without a Jackpot win.  Folk are asking me what are the odds. I wonder if the question can be viewed as flipping a fair coin 53 times and getting 53 heads and then getting 1 tail? In addition, several players take the position that inasmuch as everybody knows that the last envelope contains the Joker, we should end this round and start a new round with 54 new envelopes.  Their thinking is that the first 53 draws posed dual risk; i.e. the risk that one's ticket would be selected plus the risk that the winning ticket holder would select the envelope with the Joker.  Obviously, on the 54th draw, there is only singular risk. Can you mathematicians help us veterans?  (A)  Is not identifying the Joker until the 54th draw a rare event, or can we expect this to happen frequently and (B) Is it fair to allow the person whose ticket is selected next Saturday to claim the Jackpot, or should we start a new round with 54 envelopes? Thank you Brian Walsh",,['probability']
25,Suspicious proof of continuous mapping theorem on random variables,Suspicious proof of continuous mapping theorem on random variables,,"My textbook has this theorem: Suppose that $X_1,X_2,\cdots$ converges in probability to a random variable $X$ and that $h$ is a continuous function. Then $h(X_1), h(X_2),\cdots$ converges in probability to $h(X)$ Failed to come up with a proof immediately, I looked at the proof provided in the solution : If $h$ is continuous, given $\epsilon > 0$ there exits $\delta>0$ such that $|h(x_n)−h(x)| < \epsilon$  for $|x_n−x| < \delta$. Since $X_1,\cdots, X_n$ converges in probability to the random variable $X$, then $\lim_{n\to\infty} P(|X_n − X| < \delta) = 1$. Thus $\lim_{n\to\infty} P(|h(X_n) − h(X)| < \epsilon) = 1$. The part follows ""since"" does not really make sense to me. I think the subtly lies in the fact that $X_n$ is a random variable (that is, a function defined on some sigma-algebra $\Omega$). So for a given $\omega \in \Omega$, for a given $n$, and for a given $\epsilon >0$, we indeed can find $\delta$ such that $$|X_n( \omega) - X (\omega)| < \delta \text{ implies that } |h(X_n( \omega) - h(X (\omega))|<\epsilon$$ , but the choice of such $\delta$ seems to depend on $\omega$ and $n$? My expectation was that, in the end, we want something like $$\{\omega\in \Omega: |X_n(\omega) - X(\omega)|<\delta\} \subset \{ \omega\in\Omega: |h(X_n(\omega) - h(X(\omega))| < \epsilon\}$$","My textbook has this theorem: Suppose that $X_1,X_2,\cdots$ converges in probability to a random variable $X$ and that $h$ is a continuous function. Then $h(X_1), h(X_2),\cdots$ converges in probability to $h(X)$ Failed to come up with a proof immediately, I looked at the proof provided in the solution : If $h$ is continuous, given $\epsilon > 0$ there exits $\delta>0$ such that $|h(x_n)−h(x)| < \epsilon$  for $|x_n−x| < \delta$. Since $X_1,\cdots, X_n$ converges in probability to the random variable $X$, then $\lim_{n\to\infty} P(|X_n − X| < \delta) = 1$. Thus $\lim_{n\to\infty} P(|h(X_n) − h(X)| < \epsilon) = 1$. The part follows ""since"" does not really make sense to me. I think the subtly lies in the fact that $X_n$ is a random variable (that is, a function defined on some sigma-algebra $\Omega$). So for a given $\omega \in \Omega$, for a given $n$, and for a given $\epsilon >0$, we indeed can find $\delta$ such that $$|X_n( \omega) - X (\omega)| < \delta \text{ implies that } |h(X_n( \omega) - h(X (\omega))|<\epsilon$$ , but the choice of such $\delta$ seems to depend on $\omega$ and $n$? My expectation was that, in the end, we want something like $$\{\omega\in \Omega: |X_n(\omega) - X(\omega)|<\delta\} \subset \{ \omega\in\Omega: |h(X_n(\omega) - h(X(\omega))| < \epsilon\}$$",,"['probability', 'analysis', 'measure-theory']"
26,Monotonicity property of $\chi^2$ quantiles,Monotonicity property of  quantiles,\chi^2,"Suppose $\alpha$ is ""small"". Let $a(v)$ be the quantile for $\chi^2(v)$ distribution corresponding to $\alpha$ probability i.e. if $A\sim \chi^2(v)$ then $P[A\leq a(v)]=\alpha$. Here $v$ is the degrees of freedom of the chi-square distribution. I have a feeling that whenever $v_1<v_2$, $\dfrac{a(v_1)}{v_1}<\dfrac{a(v_2)}{v_2}$. At least simulations show this. Is this correct? Can a rigorous proof be given? Or any reference for that matter?","Suppose $\alpha$ is ""small"". Let $a(v)$ be the quantile for $\chi^2(v)$ distribution corresponding to $\alpha$ probability i.e. if $A\sim \chi^2(v)$ then $P[A\leq a(v)]=\alpha$. Here $v$ is the degrees of freedom of the chi-square distribution. I have a feeling that whenever $v_1<v_2$, $\dfrac{a(v_1)}{v_1}<\dfrac{a(v_2)}{v_2}$. At least simulations show this. Is this correct? Can a rigorous proof be given? Or any reference for that matter?",,"['probability', 'probability-theory', 'inequality', 'probability-distributions']"
27,I need help with this conditional probability question,I need help with this conditional probability question,,"This question was provided in tutorial session: Your friends Alice and Bob are both talented test-takers, but they can sometimes get distracted by their philosophies. Alice is an optimist, and she always wants to believe a statement is true. When given a true/false statement that is true, Alice gets the correct answer with probability 80%, but for false statements, she gets the correct answer only 35% of the time. On the other hand, Bob is a skeptic, and he tends to doubt the truth of statements. If a statement is true, he will get the correct answer with probability 15%, but if a statement is false, he will get the correct answer 85% of the time. (a) Your teacher receives a bonus if all of her students achieve at least 50%, so she wants to design a true/false test on which both Alice and Bob will expect to receive at least this score. What percentage of statements on the test would you set to true in order to achieve this? (b) Your teacher is now being bribed to make Alice's score as high as possible. However, she does not want Bob to fail the class. What percentage of statements should be true in order to maximize Alice's expected score while keeping Bob's expected score no less than 43%? (c) You are now taking a true/false test with Alice and Bob. You cannot read the language in which the test is written, but you can see both Alice's and Bob's answers for each question; Alice's answers are independent of Bob's. You also know that each statement on the test is true with probability 50%. How should you fill out your answer sheet to achieve the highest possible expected score? What will your expected score be? (d) Now imagine that you need to create an answer key for the test. You can look at the answer sheets for as many optimists (people who answer true questions correctly with probability 75% and false questions correctly with probability 40%) and pessimists (people who answer true questions correctly with probability 40% and false questions correctly with probability 90%) as you like. The students mistakes are independent of each other. You know that each statement on the test is true with probability 30%. How would you create an answer key that is at least 77% correct in expectation? My approach:: Let C be the event that answer is correct and S be the event that the statement is true. Then for Alice:  P(C|S) = 0.8 and P(C|S') = 0.35 and for Bob: P(C|S) = 0.15 and P(C|S') = 0.85 (a) We need to make P(C) >= 0.5 for both of them because both need to achieve at least 50%. Suppose P(S) = x, P(S') = 1-x then for Alice: P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.8x + (1-x)*0.35 >=0.5 Solving we get x >= 0.33 Similarly for Bob we get x <= 0.43 So according to the question, % of questions set to true should be between 33-43% (b) Since Bob's score needs to be at least 43%, we have for Bob : P(C) >= 0.43 P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.15x + (1-x)*0.85 >=0.43 x<=0.7 So 70% statements should be true. I am not sure about this. (c) I have no clue about this one. (d) For Optimists:  P(C|S) = 0.75 and P(C|S') = 0.4 and for pessimists: P(C|S) = 0.4 and P(C|S') = 0.9 P(S) = 0.3(given) Optimists are expected to answer P(C) = 0.3*0.75+0.7*0.4=0.505 i.e 50.5% times correctly and pessimists are expected to answer P(C) = 0.3*0.4+0.7*0.9=0.75 i.e 75% times correctly. How can I achieve now at least 77% correct answer key because copying pessimists' answer only gives 75%? Is my method correct? How to approach these kind of questions?","This question was provided in tutorial session: Your friends Alice and Bob are both talented test-takers, but they can sometimes get distracted by their philosophies. Alice is an optimist, and she always wants to believe a statement is true. When given a true/false statement that is true, Alice gets the correct answer with probability 80%, but for false statements, she gets the correct answer only 35% of the time. On the other hand, Bob is a skeptic, and he tends to doubt the truth of statements. If a statement is true, he will get the correct answer with probability 15%, but if a statement is false, he will get the correct answer 85% of the time. (a) Your teacher receives a bonus if all of her students achieve at least 50%, so she wants to design a true/false test on which both Alice and Bob will expect to receive at least this score. What percentage of statements on the test would you set to true in order to achieve this? (b) Your teacher is now being bribed to make Alice's score as high as possible. However, she does not want Bob to fail the class. What percentage of statements should be true in order to maximize Alice's expected score while keeping Bob's expected score no less than 43%? (c) You are now taking a true/false test with Alice and Bob. You cannot read the language in which the test is written, but you can see both Alice's and Bob's answers for each question; Alice's answers are independent of Bob's. You also know that each statement on the test is true with probability 50%. How should you fill out your answer sheet to achieve the highest possible expected score? What will your expected score be? (d) Now imagine that you need to create an answer key for the test. You can look at the answer sheets for as many optimists (people who answer true questions correctly with probability 75% and false questions correctly with probability 40%) and pessimists (people who answer true questions correctly with probability 40% and false questions correctly with probability 90%) as you like. The students mistakes are independent of each other. You know that each statement on the test is true with probability 30%. How would you create an answer key that is at least 77% correct in expectation? My approach:: Let C be the event that answer is correct and S be the event that the statement is true. Then for Alice:  P(C|S) = 0.8 and P(C|S') = 0.35 and for Bob: P(C|S) = 0.15 and P(C|S') = 0.85 (a) We need to make P(C) >= 0.5 for both of them because both need to achieve at least 50%. Suppose P(S) = x, P(S') = 1-x then for Alice: P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.8x + (1-x)*0.35 >=0.5 Solving we get x >= 0.33 Similarly for Bob we get x <= 0.43 So according to the question, % of questions set to true should be between 33-43% (b) Since Bob's score needs to be at least 43%, we have for Bob : P(C) >= 0.43 P(C) = P(C|S)P(S) + P(C|S')P(S') = 0.15x + (1-x)*0.85 >=0.43 x<=0.7 So 70% statements should be true. I am not sure about this. (c) I have no clue about this one. (d) For Optimists:  P(C|S) = 0.75 and P(C|S') = 0.4 and for pessimists: P(C|S) = 0.4 and P(C|S') = 0.9 P(S) = 0.3(given) Optimists are expected to answer P(C) = 0.3*0.75+0.7*0.4=0.505 i.e 50.5% times correctly and pessimists are expected to answer P(C) = 0.3*0.4+0.7*0.9=0.75 i.e 75% times correctly. How can I achieve now at least 77% correct answer key because copying pessimists' answer only gives 75%? Is my method correct? How to approach these kind of questions?",,"['probability', 'probability-theory', 'discrete-mathematics', 'bayes-theorem']"
28,Probability of getting a defined value by freely assembling the top 3 results of a D4+D6+D8+D10 roll,Probability of getting a defined value by freely assembling the top 3 results of a D4+D6+D8+D10 roll,,"I'm trying to compute the probability of getting a given value with the following rules : Roll one 4 sided dice + one 6 sided dice + one 8 sided dice + one 10 sided dice. Pick the 3 largest results. Choose a value by selecting one dice, assembling 2 dice or even summing all 3 dice. Example: I roll 2 on the 4 sided dice I roll 1 on the 6 sided dice I roll 6 on the 8 sided dice I roll 5 on the 10 sided dice I pick the 3 largest results : 2,6,5 Then, I can choose any of the following values: 2, 6, 5, 2+6=8, 2+5=7, 6+5=11, 2+6+5=13 What is the probability of getting a 2 or a 15 or even a 24 with this rules? In fact, I am searching for a way to generalize this problem so that I can change the number of dice or the number of sides of each dice or even the number of top dice to keep. I created a computer program to obtain this probabilities using brute force, but I would like a more elegant and faster solution.","I'm trying to compute the probability of getting a given value with the following rules : Roll one 4 sided dice + one 6 sided dice + one 8 sided dice + one 10 sided dice. Pick the 3 largest results. Choose a value by selecting one dice, assembling 2 dice or even summing all 3 dice. Example: I roll 2 on the 4 sided dice I roll 1 on the 6 sided dice I roll 6 on the 8 sided dice I roll 5 on the 10 sided dice I pick the 3 largest results : 2,6,5 Then, I can choose any of the following values: 2, 6, 5, 2+6=8, 2+5=7, 6+5=11, 2+6+5=13 What is the probability of getting a 2 or a 15 or even a 24 with this rules? In fact, I am searching for a way to generalize this problem so that I can change the number of dice or the number of sides of each dice or even the number of top dice to keep. I created a computer program to obtain this probabilities using brute force, but I would like a more elegant and faster solution.",,"['probability', 'combinatorics', 'dice']"
29,Bayes classification with a simple example of mail classification,Bayes classification with a simple example of mail classification,,"Every mail is described by a bag of words: $x = (x_1, . . . , x_l)$, where $x_i \in \{0, 1\}$ indicates whether the $i$th word is present or not. We have $n$ training samples ${(x^1,y^1),....(x^n,y^n)}$, where ""$y$"" indicates if the mail is relevant or not relevant, and we want to classify mails accordingly as either relevant or not relevant. Task 1: Determine joint distribution, prior and the class conditional distributions $P(x_i|y)$? Task 2: Consider the class posterior distribution $P(y | x)$ and assume that the cost $c_{1 \to 0}$ for classifying a relevant message as irrelevant is larger than the cost $c_{0 \to 1}$ of classifying an irrelevant message as relevant. The cost of classifying correctly is assumed to be zero. How does the classication rule change? Edit of my answers --- Task 1: We can think of this as a Bernoulli trial, where a word $w_i$ is either in the document or it is not. Hence we get $\operatorname{argmax}_y \prod_{i=1}^n P(x_i|y) = \prod_{i=1}^n P(w_i|k)^{x_i}  \cdot (1-P(x_i|y))^{1-x_i}$ $x_i$ is the binary variable indicating if the word $w_i$ is present or not. With Maximum Likelihood, we can estimate $P(y)$ as the fraction of the documents belonging to the corresponding class.  The class-conditional distribution can be calculated similarly: For instance $P(x=x1|y)$, are the fraction of ""$x1$"" datasamples in class $y$. Questions: Is $P(w_i|k)^{x_i} \cdot (1-P(x_i|y))^{1-x_i}$ the joint distribution (it looks like a conditional distribution)? Any hints for task2?","Every mail is described by a bag of words: $x = (x_1, . . . , x_l)$, where $x_i \in \{0, 1\}$ indicates whether the $i$th word is present or not. We have $n$ training samples ${(x^1,y^1),....(x^n,y^n)}$, where ""$y$"" indicates if the mail is relevant or not relevant, and we want to classify mails accordingly as either relevant or not relevant. Task 1: Determine joint distribution, prior and the class conditional distributions $P(x_i|y)$? Task 2: Consider the class posterior distribution $P(y | x)$ and assume that the cost $c_{1 \to 0}$ for classifying a relevant message as irrelevant is larger than the cost $c_{0 \to 1}$ of classifying an irrelevant message as relevant. The cost of classifying correctly is assumed to be zero. How does the classication rule change? Edit of my answers --- Task 1: We can think of this as a Bernoulli trial, where a word $w_i$ is either in the document or it is not. Hence we get $\operatorname{argmax}_y \prod_{i=1}^n P(x_i|y) = \prod_{i=1}^n P(w_i|k)^{x_i}  \cdot (1-P(x_i|y))^{1-x_i}$ $x_i$ is the binary variable indicating if the word $w_i$ is present or not. With Maximum Likelihood, we can estimate $P(y)$ as the fraction of the documents belonging to the corresponding class.  The class-conditional distribution can be calculated similarly: For instance $P(x=x1|y)$, are the fraction of ""$x1$"" datasamples in class $y$. Questions: Is $P(w_i|k)^{x_i} \cdot (1-P(x_i|y))^{1-x_i}$ the joint distribution (it looks like a conditional distribution)? Any hints for task2?",,"['probability', 'statistics']"
30,Problem related to integrals and probability densities.,Problem related to integrals and probability densities.,,"Suppose $X_1, X_2$ are independent random variables, with the same support $[0,1]$, on the same probability space with densities $f_1,f_2$ respectively. By support I mean, $f_i$'s are $0$ outside $[0,1]$. We have that $$\int_{x} f_1(x)f_2(z-x) \,dx = \int_{x} g_1(x)g_2(z-x) \,dx$$ for all $z \in [0,2]$ and $g_i(y) = f_i(1-y)$ for both $i=\{1,2\}$. We also have that $$ f_i(x) \leq f_i(1-x), \forall x \in [0.5,1]$$ for both $i=\{1,2\}$. I want to conclude that $$ f_1(x)f_2(z-x) = f_1(1-x)f_2(1-(z-x)) $$ for some $z$. My try: Rewrite (1) as $$\int_{x} (f_1(1-x)f_2(1-(z-x)) - f_1(x)f_2(z-x)) \,dx = 0. \quad (*)$$ For $z=1.5$, since we can restrict our interest to $0\leq z-x \leq 1$, we'll have both $x$ and $(z-x)$ exceeding $0.5$. Now from (2) we'll have $$ f_1(x) \leq f_1(1-x) ~\text{and} \\ f_2(z-x) \leq f_2(1-(z-x)).$$ So $$f_1(1-x)f_2(1-(z-x)) - f_1(x)f_2(z-x) \geq 0.$$ With $(*)$ we can in fact conclude $$ f_1(x)f_2(z-x) = f_1(1-x)f_2(1-(z-x)).$$ Now if the above conclusion holds can we say more? That is, from (2) I want to further conclude that $$ f_1(x) = f_1(1-x) $$ and $$f_2(z-x) =f_2(1-(z-x))$$ for some $z$. Please comment on both the above conclusions I made. Thanks in advance for any help! Please feel free to make any further conclusions from these facts too, it'd be interesting to know them.","Suppose $X_1, X_2$ are independent random variables, with the same support $[0,1]$, on the same probability space with densities $f_1,f_2$ respectively. By support I mean, $f_i$'s are $0$ outside $[0,1]$. We have that $$\int_{x} f_1(x)f_2(z-x) \,dx = \int_{x} g_1(x)g_2(z-x) \,dx$$ for all $z \in [0,2]$ and $g_i(y) = f_i(1-y)$ for both $i=\{1,2\}$. We also have that $$ f_i(x) \leq f_i(1-x), \forall x \in [0.5,1]$$ for both $i=\{1,2\}$. I want to conclude that $$ f_1(x)f_2(z-x) = f_1(1-x)f_2(1-(z-x)) $$ for some $z$. My try: Rewrite (1) as $$\int_{x} (f_1(1-x)f_2(1-(z-x)) - f_1(x)f_2(z-x)) \,dx = 0. \quad (*)$$ For $z=1.5$, since we can restrict our interest to $0\leq z-x \leq 1$, we'll have both $x$ and $(z-x)$ exceeding $0.5$. Now from (2) we'll have $$ f_1(x) \leq f_1(1-x) ~\text{and} \\ f_2(z-x) \leq f_2(1-(z-x)).$$ So $$f_1(1-x)f_2(1-(z-x)) - f_1(x)f_2(z-x) \geq 0.$$ With $(*)$ we can in fact conclude $$ f_1(x)f_2(z-x) = f_1(1-x)f_2(1-(z-x)).$$ Now if the above conclusion holds can we say more? That is, from (2) I want to further conclude that $$ f_1(x) = f_1(1-x) $$ and $$f_2(z-x) =f_2(1-(z-x))$$ for some $z$. Please comment on both the above conclusions I made. Thanks in advance for any help! Please feel free to make any further conclusions from these facts too, it'd be interesting to know them.",,"['calculus', 'probability', 'probability-theory', 'measure-theory', 'density-function']"
31,What is the expected total number of topological sorts in a Directed a cyclic graph with $n$ vertices?,What is the expected total number of topological sorts in a Directed a cyclic graph with  vertices?,n,"I know that a DAG with $n$ vertices can have $O(n!)$ topological sorts. However, I am interested in knowing the expected number of topological sorts in a randomly generated DAG?","I know that a DAG with $n$ vertices can have $O(n!)$ topological sorts. However, I am interested in knowing the expected number of topological sorts in a randomly generated DAG?",,"['probability', 'graph-theory', 'order-theory', 'random-graphs', 'directed-graphs']"
32,"Solution verification: picking $5$-card hands from standard deck of $52$, with conditions","Solution verification: picking -card hands from standard deck of , with conditions",5 52,"Problem A 5-card hand is dealt from a perfectly shuffled deck of playing cards. What is the probability of each of the following events? (a) The hand has at least one club. (b) The hand has at least two cards with the same rank. (c) The hand has exactly one club or exactly one spade. (d) The hand has at least one club or at least one spade. My solutions (a) By complement, if there are no clubs, that means we have $13$ ranks but only $3$ suits to choose from, for a total of $39$ cards from which to pick $5$ : $p(E) = 1 - \frac{{39 \choose 5}}{{52 \choose 5}}$ (b) By complement, if at least $2$ cards have the same rank, then the negation of this statement is that no $2$ cards have the same rank, i.e. all $5$ cards are different ranks. This means that we only have $13$ cards to choose from (I think), so I got: $p(E) = 1 - \frac{{13 \choose 5}}{{52 \choose 5}}$ (c) Let $C$ denote the set of outcomes that are exactly $1$ club, and let $S$ denote the set of outcomes that are exactly $1$ spade. These are not mutually exclusive. $p(C \cup S) = p(C) + p(S) - p(C \cap S)$ $p(C)$ : one of the cards is a club, leaving us with $13$ ranks and $3$ suits to choose from (and we choose $4$ cards): ${39 \choose 4}$ $p(S)$ : same logic as above, so we have ${39 \choose 4}$ again $P(C \cap S)$ : one club and one spade, $3$ cards left to choose from $2$ suits of $13$ ranks each, meaning we choose $3$ from $26$ cards: ${26 \choose 3}$ I got: $\frac{2\cdot {39 \choose 4}-{26 \choose 3}}{{52 \choose 5}}$ (d) : at least $1$ club or at least $1$ spade; we can use complement to find the probability of $0$ clubs AND $0$ spades and subtract this from $1$ . If there are no clubs or spades, then we have $13$ cards and $2$ suits to choose from, and we pick $5$ cards, so that's ${26 \choose 5}$ . I got: $p(E) = 1 - \frac{{26 \choose 5}}{{52 \choose 5}}$ Questions/concerns I'd really appreciate if you could verify my work, as the solutions are not available. I'm particularly curious if I did part (b) correctly.","Problem A 5-card hand is dealt from a perfectly shuffled deck of playing cards. What is the probability of each of the following events? (a) The hand has at least one club. (b) The hand has at least two cards with the same rank. (c) The hand has exactly one club or exactly one spade. (d) The hand has at least one club or at least one spade. My solutions (a) By complement, if there are no clubs, that means we have ranks but only suits to choose from, for a total of cards from which to pick : (b) By complement, if at least cards have the same rank, then the negation of this statement is that no cards have the same rank, i.e. all cards are different ranks. This means that we only have cards to choose from (I think), so I got: (c) Let denote the set of outcomes that are exactly club, and let denote the set of outcomes that are exactly spade. These are not mutually exclusive. : one of the cards is a club, leaving us with ranks and suits to choose from (and we choose cards): : same logic as above, so we have again : one club and one spade, cards left to choose from suits of ranks each, meaning we choose from cards: I got: (d) : at least club or at least spade; we can use complement to find the probability of clubs AND spades and subtract this from . If there are no clubs or spades, then we have cards and suits to choose from, and we pick cards, so that's . I got: Questions/concerns I'd really appreciate if you could verify my work, as the solutions are not available. I'm particularly curious if I did part (b) correctly.",13 3 39 5 p(E) = 1 - \frac{{39 \choose 5}}{{52 \choose 5}} 2 2 5 13 p(E) = 1 - \frac{{13 \choose 5}}{{52 \choose 5}} C 1 S 1 p(C \cup S) = p(C) + p(S) - p(C \cap S) p(C) 13 3 4 {39 \choose 4} p(S) {39 \choose 4} P(C \cap S) 3 2 13 3 26 {26 \choose 3} \frac{2\cdot {39 \choose 4}-{26 \choose 3}}{{52 \choose 5}} 1 1 0 0 1 13 2 5 {26 \choose 5} p(E) = 1 - \frac{{26 \choose 5}}{{52 \choose 5}},"['probability', 'combinatorics', 'discrete-mathematics', 'solution-verification', 'card-games']"
33,Odds of guessing a sequence of cards in order,Odds of guessing a sequence of cards in order,,"For a deck of 52 cards, find the number m such that $P$(by random guessing we get more than m correct guesses) < $1/10000.$ I was thinking along the lines of - if there is m correct guesses, there are $(52-m)!$ possible arrangements with a correct guess. So the probability of m correct guesses is $(52-m)!/52!=k$ and the solution is given by $k<1/10000$. Is my reasoning correct? If not how to solve this problem?","For a deck of 52 cards, find the number m such that $P$(by random guessing we get more than m correct guesses) < $1/10000.$ I was thinking along the lines of - if there is m correct guesses, there are $(52-m)!$ possible arrangements with a correct guess. So the probability of m correct guesses is $(52-m)!/52!=k$ and the solution is given by $k<1/10000$. Is my reasoning correct? If not how to solve this problem?",,"['probability', 'self-learning']"
34,Probability that a random binary matrix is invertible - what is going on?,Probability that a random binary matrix is invertible - what is going on?,,"This is a follow-up to this question: Probability that a random binary matrix is invertible? The answer says that the probability of a random $\{0,1\}$, $n \times n$ matrix to be invertible is: $$p(n)=\prod_{k=1}^{n}(1-2^{-k})\;,$$ For a $32\times32$, that's about 0.288. But, when I generate a random matrix in Matlab, and check its rank, it's always 32! The code is: A=randi([0 1],32,32);rank(A) . You can even try it online here . Is the answer wrong? Is Matlab/Octave wrong? Please help me solve the mystery. Thanks!","This is a follow-up to this question: Probability that a random binary matrix is invertible? The answer says that the probability of a random $\{0,1\}$, $n \times n$ matrix to be invertible is: $$p(n)=\prod_{k=1}^{n}(1-2^{-k})\;,$$ For a $32\times32$, that's about 0.288. But, when I generate a random matrix in Matlab, and check its rank, it's always 32! The code is: A=randi([0 1],32,32);rank(A) . You can even try it online here . Is the answer wrong? Is Matlab/Octave wrong? Please help me solve the mystery. Thanks!",,"['linear-algebra', 'probability', 'matrices', 'random-matrices']"
35,Bound improvement in Poincare inequality,Bound improvement in Poincare inequality,,"Let $f \in L^{2}(\mathbb{R}^{d}, \gamma)$ be a square integrable function w.r.t to the Gaussian measure $\gamma$ such that $\int_{\mathbb{R}^{d}}{f(x) \,dx } = 0$. I've bumped into a research paper in which author asserts that the inequality $$\int_{\mathbb{R}^{d}}{f^{2}\, d \gamma} \leq \frac{1}{2} \int_{\mathbb{R}^{d}}{\| \nabla f \|^{2} \,d \gamma}$$ holds for any such function $f$.  On the first glance, it looks as an improved version of the classical Poincare inequality which states that $$\int_{\mathbb{R}^{d}}{f^{2}\, d \gamma } \leq \int_{\mathbb{R}^{d}}{\|\nabla f\|^{2}\, d \gamma}$$ for any $L^{2}$ function that is orthogonal to the constant function (equivalently, with mean $0$). The questions are: (1) Is it possible to prove these inequalities via the  Fourier series techniques? (seems as if it is reasonable to consider the Fourier expansion of $f$ w.r.t to the orthogonal system consisting of Hermite polynomials and the try to obtain the inequality somehow, probably, with the use of the Parserval's identity). The same approach is known to be  working quite well for the $1$-dimensional Wirtinger inequality. (2) The general Poincare inequality states that for a given region $\Omega$ and $1 \leq p < \infty$ there exists a constant $C := C_{\Omega, p}$ such that for any $u \in W_{0}^{1, p}$  $$\|u\|_{L^{p}(\Omega)} \leq C \|\nabla u\|_{L^{p}(\Omega)}$$ So, under some mild assumptions (e.g. $\mathbb{E}(f) = 0$ ) is it possible to find the best lower bound for $C$? (as suggested, for $C=\frac{1}{2}$ the very first inequality holds)","Let $f \in L^{2}(\mathbb{R}^{d}, \gamma)$ be a square integrable function w.r.t to the Gaussian measure $\gamma$ such that $\int_{\mathbb{R}^{d}}{f(x) \,dx } = 0$. I've bumped into a research paper in which author asserts that the inequality $$\int_{\mathbb{R}^{d}}{f^{2}\, d \gamma} \leq \frac{1}{2} \int_{\mathbb{R}^{d}}{\| \nabla f \|^{2} \,d \gamma}$$ holds for any such function $f$.  On the first glance, it looks as an improved version of the classical Poincare inequality which states that $$\int_{\mathbb{R}^{d}}{f^{2}\, d \gamma } \leq \int_{\mathbb{R}^{d}}{\|\nabla f\|^{2}\, d \gamma}$$ for any $L^{2}$ function that is orthogonal to the constant function (equivalently, with mean $0$). The questions are: (1) Is it possible to prove these inequalities via the  Fourier series techniques? (seems as if it is reasonable to consider the Fourier expansion of $f$ w.r.t to the orthogonal system consisting of Hermite polynomials and the try to obtain the inequality somehow, probably, with the use of the Parserval's identity). The same approach is known to be  working quite well for the $1$-dimensional Wirtinger inequality. (2) The general Poincare inequality states that for a given region $\Omega$ and $1 \leq p < \infty$ there exists a constant $C := C_{\Omega, p}$ such that for any $u \in W_{0}^{1, p}$  $$\|u\|_{L^{p}(\Omega)} \leq C \|\nabla u\|_{L^{p}(\Omega)}$$ So, under some mild assumptions (e.g. $\mathbb{E}(f) = 0$ ) is it possible to find the best lower bound for $C$? (as suggested, for $C=\frac{1}{2}$ the very first inequality holds)",,"['probability', 'functional-analysis', 'measure-theory', 'partial-differential-equations', 'geometric-measure-theory']"
36,Tail Probability for Student's t-Distribution,Tail Probability for Student's t-Distribution,,"Let $n$ be a positive integer, $t < 0$, and let $F_n$ the cumulative distribution function of Student's t-distribution with $n$ degrees of freedom. Then it is a well known fact (which I always found stated without proof) that the sequence $(F_n(t))_{n=1}^{\infty}$ is strictly decreasing. Do you know some proof of the fact that $(F_n(t))_{n=1}^{\infty}$ is a strictly decreasing sequence? NOTE. Note that since we have $F_n(t) \rightarrow \Phi(t)$ as $n \rightarrow \infty$, where $\Phi$ is the cumulative distribution function of the standard normal distribution, from the proof of the monotonicity property above we would get the well known inequality $F_n(t) > \Phi(t)$ for all $n$ (which I found always quoted without proof, too).","Let $n$ be a positive integer, $t < 0$, and let $F_n$ the cumulative distribution function of Student's t-distribution with $n$ degrees of freedom. Then it is a well known fact (which I always found stated without proof) that the sequence $(F_n(t))_{n=1}^{\infty}$ is strictly decreasing. Do you know some proof of the fact that $(F_n(t))_{n=1}^{\infty}$ is a strictly decreasing sequence? NOTE. Note that since we have $F_n(t) \rightarrow \Phi(t)$ as $n \rightarrow \infty$, where $\Phi$ is the cumulative distribution function of the standard normal distribution, from the proof of the monotonicity property above we would get the well known inequality $F_n(t) > \Phi(t)$ for all $n$ (which I found always quoted without proof, too).",,"['probability', 'probability-theory', 'statistics', 'special-functions', 'statistical-inference']"
37,"Process bounded at stopped times, constant between.","Process bounded at stopped times, constant between.",,"I have a positive pure jump  process $Y_t$, which is progressive w.r.t. the filtration ($F_t$) and has jump-times $(\tau_j)$. I know that $\sup_{j\in \mathbb{N}}\mathbb{E} Y_{\tau_j}<\infty$ and $\tau_j\rightarrow \infty$ for $j\rightarrow \infty$ almost surely. Does it hold that $\sup_{t<\infty}\mathbb{E}Y_t$ is bounded as well? If not, does there exist a simple counter-example?","I have a positive pure jump  process $Y_t$, which is progressive w.r.t. the filtration ($F_t$) and has jump-times $(\tau_j)$. I know that $\sup_{j\in \mathbb{N}}\mathbb{E} Y_{\tau_j}<\infty$ and $\tau_j\rightarrow \infty$ for $j\rightarrow \infty$ almost surely. Does it hold that $\sup_{t<\infty}\mathbb{E}Y_t$ is bounded as well? If not, does there exist a simple counter-example?",,"['probability', 'probability-theory', 'stochastic-processes', 'martingales', 'stopping-times']"
38,Is the fractional part of Brownian motion equidistributed almost surely?,Is the fractional part of Brownian motion equidistributed almost surely?,,"Let $B(t)$ be a standard Brownian motion on $\mathbb{R}$, starting at $0$. Let $\pi: \mathbb{R} \to [0,1)$ be the fractional part of a real number, $\pi(1.2) = .2$, etc. I morally identify this with the map $exp : \mathbb{R} \to S^1$. Question: Is it true that, almost surely, the fraction part of Brownian motion will traverse $[0,1)$ in an asymptotically equidistributed fashion? Precisely... Let $A \subset [0,1)$ be measurable. If we denote by $B(A) = \lim_{N \to \infty} \frac{ |t : \pi (B(t)) \in A| }{N}$, is $B(A)$ the same as the Lebesgue measure of $A$ (almost surely)? Here $|t : \pi B(t) \in A|$ refers to the Lebesgue measure of the set of $t$ so that $\pi B(t) \in A$. Based on some computer experiments (with a truncation of the Levy construction for Brownian motion) it seems true but I can't prove it. I want to prove it like this: 1) The limiting distribution shouldn't care about the starting point. 2) Thus the limiting distribution on $S^1$ is invariant under the action of $\mathbb{R}$. 3) Therefore by uniqueness it must be the Haar measure. I can't verify 1)... also its not clear that the formula $B(A)$ is even well defined, so it's not clear that it gives rise to a distribution on $S^1$, invariant or not. (Though I think once $B(A)$ is shown to be well defined it should be clear that it is a probability measure... total measure one is clear, non-negativity is clear, countable additive would follow from analogous properties of the Lebesgue measure on the reals...)","Let $B(t)$ be a standard Brownian motion on $\mathbb{R}$, starting at $0$. Let $\pi: \mathbb{R} \to [0,1)$ be the fractional part of a real number, $\pi(1.2) = .2$, etc. I morally identify this with the map $exp : \mathbb{R} \to S^1$. Question: Is it true that, almost surely, the fraction part of Brownian motion will traverse $[0,1)$ in an asymptotically equidistributed fashion? Precisely... Let $A \subset [0,1)$ be measurable. If we denote by $B(A) = \lim_{N \to \infty} \frac{ |t : \pi (B(t)) \in A| }{N}$, is $B(A)$ the same as the Lebesgue measure of $A$ (almost surely)? Here $|t : \pi B(t) \in A|$ refers to the Lebesgue measure of the set of $t$ so that $\pi B(t) \in A$. Based on some computer experiments (with a truncation of the Levy construction for Brownian motion) it seems true but I can't prove it. I want to prove it like this: 1) The limiting distribution shouldn't care about the starting point. 2) Thus the limiting distribution on $S^1$ is invariant under the action of $\mathbb{R}$. 3) Therefore by uniqueness it must be the Haar measure. I can't verify 1)... also its not clear that the formula $B(A)$ is even well defined, so it's not clear that it gives rise to a distribution on $S^1$, invariant or not. (Though I think once $B(A)$ is shown to be well defined it should be clear that it is a probability measure... total measure one is clear, non-negativity is clear, countable additive would follow from analogous properties of the Lebesgue measure on the reals...)",,"['probability', 'lebesgue-measure', 'brownian-motion']"
39,Proving Brownian Motion and the Time Integral of Brownian Motion form a 2d Markov Process,Proving Brownian Motion and the Time Integral of Brownian Motion form a 2d Markov Process,,"I want to show the following: Let $W_t$ be a 1 dimensions brownian motion and $V_t= \int_{0}^{t} W_sds.$ Prove that the pair $(W_t,V_t)$ is a two-dimensional Markov process. I know that the Brownian Motion alone is a Markov Process.  The time integral of Brownian Motion is not a Markov Process, but I know it is normally distributed from these two questions: previous question 1 and previous question 2. In order to show that $(W_t,V_t)$ is a Markov Process I know I need to verify that is $s,t \ge 0$ and then $P(X_{s+t}|F_s)=P(X_{s+t}|X_s)$ almost surely.  How can I apply the information I know about $W_t$ alone being a Markov Process and $V_t$ being normally distributed to verify this fact?","I want to show the following: Let $W_t$ be a 1 dimensions brownian motion and $V_t= \int_{0}^{t} W_sds.$ Prove that the pair $(W_t,V_t)$ is a two-dimensional Markov process. I know that the Brownian Motion alone is a Markov Process.  The time integral of Brownian Motion is not a Markov Process, but I know it is normally distributed from these two questions: previous question 1 and previous question 2. In order to show that $(W_t,V_t)$ is a Markov Process I know I need to verify that is $s,t \ge 0$ and then $P(X_{s+t}|F_s)=P(X_{s+t}|X_s)$ almost surely.  How can I apply the information I know about $W_t$ alone being a Markov Process and $V_t$ being normally distributed to verify this fact?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus']"
40,"If something has a $12\%$ probability of occurring every decade, what is the probability that it will occur in $100$ years?","If something has a  probability of occurring every decade, what is the probability that it will occur in  years?",12\% 100,"If something has a $12\%$ probability of occurring every $10$ years, what is the probability that it will occur in $100$ years? And also in $150$ years? Is the formula for this as simple as $1-{0.88}^{10}$ or is it more complicated?","If something has a $12\%$ probability of occurring every $10$ years, what is the probability that it will occur in $100$ years? And also in $150$ years? Is the formula for this as simple as $1-{0.88}^{10}$ or is it more complicated?",,"['probability', 'statistics']"
41,"If I have a jar with $n$ jelly beans in it, what is the probability that I am missing at least one of the 49 flavors?","If I have a jar with  jelly beans in it, what is the probability that I am missing at least one of the 49 flavors?",n,"Assuming each flavor is equally likely to appear. I initially thought it would be just: $1 - 49 \left( \frac{48}{49} \right)^n$ But then I realized that couldn't be right because some configurations would be overcounted (resulting in a negative probability with a small enough $n$, like 100). I wrote a program to calculate it, so I have approximations of several of the probabilities, but I would like to know how do it with a general formula (ideally with a variable number of flavors as well).","Assuming each flavor is equally likely to appear. I initially thought it would be just: $1 - 49 \left( \frac{48}{49} \right)^n$ But then I realized that couldn't be right because some configurations would be overcounted (resulting in a negative probability with a small enough $n$, like 100). I wrote a program to calculate it, so I have approximations of several of the probabilities, but I would like to know how do it with a general formula (ideally with a variable number of flavors as well).",,"['probability', 'combinatorics', 'statistics']"
42,Probability of choosing same multiple,Probability of choosing same multiple,,"Will E. Pikett randomly selects an odd integer less than $100$ that is a multiple of $3$. Betty Wont randomly selects an odd integer less than $100$ that is a multiple of $5$. What is the probability that they selected the same number? My approach: The number of odd integers that are less than $100$ and a multiple of $3$ is $17$. As for odd multiples of $5$, that is $10$. There are $3$ factors in common: $15$, $45$, and $75$. So the probability of choosing one of these three factors for Will is $\frac{3}{17}$. The probability that Betty will choose the same number is $\frac{1}{10}$ (Betty could have chosen first I suppose). So the probability that they both chose the same factor is $\frac{3}{170}$, but obviously I'm incorrect. Where in my work did I make an erroneous decision, and what is the result of choosing such a decision.  Thanks.","Will E. Pikett randomly selects an odd integer less than $100$ that is a multiple of $3$. Betty Wont randomly selects an odd integer less than $100$ that is a multiple of $5$. What is the probability that they selected the same number? My approach: The number of odd integers that are less than $100$ and a multiple of $3$ is $17$. As for odd multiples of $5$, that is $10$. There are $3$ factors in common: $15$, $45$, and $75$. So the probability of choosing one of these three factors for Will is $\frac{3}{17}$. The probability that Betty will choose the same number is $\frac{1}{10}$ (Betty could have chosen first I suppose). So the probability that they both chose the same factor is $\frac{3}{170}$, but obviously I'm incorrect. Where in my work did I make an erroneous decision, and what is the result of choosing such a decision.  Thanks.",,['probability']
43,When does zero cross-quadratic variation imply independence of Brownian motions?,When does zero cross-quadratic variation imply independence of Brownian motions?,,"We know that if $X$, $Y$ are Normal random variables with zero covariance then they are independent if and only if they are bivariate Normal, i.e. $aX+bY$ is Normal for all a,b. Similarly if $B_t$, $W_t$ are Brownian motions with zero cross-quadratic variation $\langle B,W\rangle_t$, and $aB_t+bW_t$ is Normal for all $a$, $b$ and $t$ then I can prove they are independent. Does anybody know of a weaker sufficient condition? I can show that $B_t$ and $cB_{\frac{t}{c^2}}$ have zero cross-quadratic variation for all $c\neq 1$ yet are dependent so I do need an extra condition. My advisor thinks that if the Brownian motions are adapted to the same filtration then that is sufficient but I'm not convinced and I can't find anything in the literature that explores this topic.","We know that if $X$, $Y$ are Normal random variables with zero covariance then they are independent if and only if they are bivariate Normal, i.e. $aX+bY$ is Normal for all a,b. Similarly if $B_t$, $W_t$ are Brownian motions with zero cross-quadratic variation $\langle B,W\rangle_t$, and $aB_t+bW_t$ is Normal for all $a$, $b$ and $t$ then I can prove they are independent. Does anybody know of a weaker sufficient condition? I can show that $B_t$ and $cB_{\frac{t}{c^2}}$ have zero cross-quadratic variation for all $c\neq 1$ yet are dependent so I do need an extra condition. My advisor thinks that if the Brownian motions are adapted to the same filtration then that is sufficient but I'm not convinced and I can't find anything in the literature that explores this topic.",,"['probability', 'brownian-motion', 'independence', 'quadratic-variation', 'filtrations']"
44,How to complete this simple example of the Vitali-Hahn-Saks Theorem?,How to complete this simple example of the Vitali-Hahn-Saks Theorem?,,"I'm studying the Vitali-Hahn-Saks Theorem and I need some help with an example in which the conclusion of the theorem fails. Theorem. Let $(\Omega,\mathcal{F}, P)$ be a finite measure space, and let $(P_n)$ a sequence of finite measures on $(\Omega, \mathcal{F})$ each of which is absolutely continuous with respect to $P$. Suppose the sequence $(P_n(\Omega))$ is bounded. If $(P_n)$ converges setwise to the set function $P_\infty$, then $(P_n)$ is uniformly absolutely continuous with respect to $P$ ($\forall \epsilon > 0, \exists \delta>0, \forall n, \forall A \in \mathcal{F}, P(A) < \delta$ implies $P_n(A) < \epsilon$). Moreover, $P_\infty$ is a finite measure that is absolutely continuous with respect to $P$. I thought I'd cook up a simple example where uniform absolute continuity fails in order to see how setwise convergence fails. Start with a countable probability space given by $P(\omega_n) = 2^{-n}$. Let the events $E_n = \Omega - \cup_{i=1}^n \{\omega_i\}$. And let $P_n = P(\cdot \mid E_n)$. Note that $\inf_n\{P(E_n) \}=0$. The sequence $(P_n)$ is not uniformly absolutely continuous with respect to $P$. To see that let $\epsilon = 1/2$, and let $\delta > 0$ be given. For large enough $n$, $P(E_n) < \delta$ but $P_n(E_n) = 1 > \epsilon.$ Question. How to see that $(P_n)$ does not converge setwise? I've played around with a few example events $A$, but $(P_n(A))$ always converges. Hints are appreciated.","I'm studying the Vitali-Hahn-Saks Theorem and I need some help with an example in which the conclusion of the theorem fails. Theorem. Let $(\Omega,\mathcal{F}, P)$ be a finite measure space, and let $(P_n)$ a sequence of finite measures on $(\Omega, \mathcal{F})$ each of which is absolutely continuous with respect to $P$. Suppose the sequence $(P_n(\Omega))$ is bounded. If $(P_n)$ converges setwise to the set function $P_\infty$, then $(P_n)$ is uniformly absolutely continuous with respect to $P$ ($\forall \epsilon > 0, \exists \delta>0, \forall n, \forall A \in \mathcal{F}, P(A) < \delta$ implies $P_n(A) < \epsilon$). Moreover, $P_\infty$ is a finite measure that is absolutely continuous with respect to $P$. I thought I'd cook up a simple example where uniform absolute continuity fails in order to see how setwise convergence fails. Start with a countable probability space given by $P(\omega_n) = 2^{-n}$. Let the events $E_n = \Omega - \cup_{i=1}^n \{\omega_i\}$. And let $P_n = P(\cdot \mid E_n)$. Note that $\inf_n\{P(E_n) \}=0$. The sequence $(P_n)$ is not uniformly absolutely continuous with respect to $P$. To see that let $\epsilon = 1/2$, and let $\delta > 0$ be given. For large enough $n$, $P(E_n) < \delta$ but $P_n(E_n) = 1 > \epsilon.$ Question. How to see that $(P_n)$ does not converge setwise? I've played around with a few example events $A$, but $(P_n(A))$ always converges. Hints are appreciated.",,"['real-analysis', 'probability', 'limits', 'probability-theory', 'measure-theory']"
45,Is the maximum of a probability distribution function of a Binomial distribution always the expected value?,Is the maximum of a probability distribution function of a Binomial distribution always the expected value?,,"Consider some $X \sim B(n,p)$. I know that $E[X] = np$. I was looking at practice problems on the binomial distribution. One of the exercises asked the following: Given a histogram and $n$ for some $B(n,p)$, find $p$. (The histograms look like those in the attached image, obviously with $p$ removed.) The solution seems to be to find the value $k$ for which the histogram is maximal (by reading it off the histogram.) Then, $p = \frac{k}{n}$, since apparently $k$ is the expected value. Obviously, the mean and mode don't coincide for an arbitrary probability distribution. So does this mean that for any $B(n,p)$, the mean and mode are equal? Also: What happens if there are two maxima, like in the figure below?","Consider some $X \sim B(n,p)$. I know that $E[X] = np$. I was looking at practice problems on the binomial distribution. One of the exercises asked the following: Given a histogram and $n$ for some $B(n,p)$, find $p$. (The histograms look like those in the attached image, obviously with $p$ removed.) The solution seems to be to find the value $k$ for which the histogram is maximal (by reading it off the histogram.) Then, $p = \frac{k}{n}$, since apparently $k$ is the expected value. Obviously, the mean and mode don't coincide for an arbitrary probability distribution. So does this mean that for any $B(n,p)$, the mean and mode are equal? Also: What happens if there are two maxima, like in the figure below?",,"['probability', 'statistics', 'probability-distributions']"
46,Probability that friends meet.,Probability that friends meet.,,Two friends decide to meet between 1:00 PM and 2:00 PM on a given day. There is a condition that whoever arrives first will not wait for the other for more than $15$ minutes. What is the probability that they meet ? How to solve this problem using Random Variables mathematically ?,Two friends decide to meet between 1:00 PM and 2:00 PM on a given day. There is a condition that whoever arrives first will not wait for the other for more than minutes. What is the probability that they meet ? How to solve this problem using Random Variables mathematically ?,15,"['probability', 'probability-distributions']"
47,Calculating $\int_{-\infty}^{\infty}\frac{x^i}{((x^2+a)^2+b^2)^{\frac{3}{2}}}dx$,Calculating,\int_{-\infty}^{\infty}\frac{x^i}{((x^2+a)^2+b^2)^{\frac{3}{2}}}dx,"I am looking for whether the integral $$\int_{-\infty}^{\infty}\frac{x^i}{((x^2+a)^2+b^2)^{\frac{3}{2}}}dx$$ where $i=0,\ldots, 4$ and $a,b>0$ are parameters can be calculated in an elementary way. I myself got stuck and online calculators gave quite horribly looking answers. It would be especially nice to see a connection to probability (i.e. interpreting the above as moments of some known distribution), as the background of the question, which is a PDE problem, would actually suggest there might be one.","I am looking for whether the integral $$\int_{-\infty}^{\infty}\frac{x^i}{((x^2+a)^2+b^2)^{\frac{3}{2}}}dx$$ where $i=0,\ldots, 4$ and $a,b>0$ are parameters can be calculated in an elementary way. I myself got stuck and online calculators gave quite horribly looking answers. It would be especially nice to see a connection to probability (i.e. interpreting the above as moments of some known distribution), as the background of the question, which is a PDE problem, would actually suggest there might be one.",,"['calculus', 'probability', 'integration']"
48,Continuity of a function (Real Analysis),Continuity of a function (Real Analysis),,"In Stochastic process, Bass claim (without proof) the function $f:\mathbb{R} \to \mathbb{R}$ defined by $f(x)=\int_{A} e^{\tfrac{-(y-x)^2}{2t}}dy$ is continuous, where $A$ is a Borel measurable set. He says use dominated convergence theorem, it is clear. But I get confused here. Because, HOW? I tried to use the definition of continuity ($\epsilon-\delta$ argument) to prove it, for instance, $|\int_{A} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ $ \leq |\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ +$|\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ The first term I think we can use the dominated convergent theorem, and the second one use the fact that the integrand is $L^{1}$-integrable, but I can't give a good $\epsilon-\delta$ argument, can someone help? Furthermore, if the $f$ becomes $f(x)=\int_{A} F(y)e^{\tfrac{-(y-x)^2}{2t}}dy$ where $F$ is bounded measurable, will it be continuous still? It is important since it might gives a sufficient condition for Strong Markov Process but the author never mention. Thanks!","In Stochastic process, Bass claim (without proof) the function $f:\mathbb{R} \to \mathbb{R}$ defined by $f(x)=\int_{A} e^{\tfrac{-(y-x)^2}{2t}}dy$ is continuous, where $A$ is a Borel measurable set. He says use dominated convergence theorem, it is clear. But I get confused here. Because, HOW? I tried to use the definition of continuity ($\epsilon-\delta$ argument) to prove it, for instance, $|\int_{A} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ $ \leq |\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ +$|\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ The first term I think we can use the dominated convergent theorem, and the second one use the fact that the integrand is $L^{1}$-integrable, but I can't give a good $\epsilon-\delta$ argument, can someone help? Furthermore, if the $f$ becomes $f(x)=\int_{A} F(y)e^{\tfrac{-(y-x)^2}{2t}}dy$ where $F$ is bounded measurable, will it be continuous still? It is important since it might gives a sufficient condition for Strong Markov Process but the author never mention. Thanks!",,"['real-analysis', 'probability', 'stochastic-processes']"
49,What is the symbol that looks like an up arrow?,What is the symbol that looks like an up arrow?,,What are the symbols that look like an up arrow and a down arrow?,What are the symbols that look like an up arrow and a down arrow?,,"['probability', 'statistics', 'probability-distributions', 'markov-chains']"
50,Probability density of a stochastic process,Probability density of a stochastic process,,"Good morning, recently I had to solve the two-dimensional SDE, and the solution process I found was $$\left\{\begin{array}{rcl}\xi^1_t&=&\xi^1_0+\int_0^t dw(s),\\ \xi_2^t&=&\xi_0^2+\int_0^t(\xi_s^1)^2ds\end{array}\right.,$$ where $w(t)$ is a standard one-dimensional brownian motion. Then $\xi_t^1$ has a normal distribution with mean $\xi_0^1$ and variance $t$. What kind of process is $\xi_t^2$? More generally what can I say on the whole process $(\xi_t^1,\xi_t^2)$ (as a Joint process)? I didn't find any reference in the literature unfortunately so that's why I'm asking. Thank you for all your kind replies.","Good morning, recently I had to solve the two-dimensional SDE, and the solution process I found was $$\left\{\begin{array}{rcl}\xi^1_t&=&\xi^1_0+\int_0^t dw(s),\\ \xi_2^t&=&\xi_0^2+\int_0^t(\xi_s^1)^2ds\end{array}\right.,$$ where $w(t)$ is a standard one-dimensional brownian motion. Then $\xi_t^1$ has a normal distribution with mean $\xi_0^1$ and variance $t$. What kind of process is $\xi_t^2$? More generally what can I say on the whole process $(\xi_t^1,\xi_t^2)$ (as a Joint process)? I didn't find any reference in the literature unfortunately so that's why I'm asking. Thank you for all your kind replies.",,"['probability', 'reference-request', 'stochastic-processes', 'stochastic-calculus', 'stochastic-differential-equations']"
51,"If a sequence of random variables $X_n$ are asymptotically Normal, in what sense is $e^{X_n}$ asymptotically Normal as well?","If a sequence of random variables  are asymptotically Normal, in what sense is  asymptotically Normal as well?",X_n e^{X_n},"If a sequence of random variables $X_n$ are asymptotically Normal, in what sense is $e^{X_n}$ asymptotically Normal as well? I read the following inside a book: Is it surprising that if $X_n$ is approximately Normal for $n$ large, then $e^{X_n}$ is also approximately Normal for $n$ large? Asymptotically, exponential functions are linear. But then again, asymptotically any two people have the same age, and this is even a better approximation since they differ only by a constant. John Maynard Keynes said “In the long run we are all dead”; in the short run, should we be happy to be asymptotically right but exponentially wrong? I am confused what the author is trying to say here. Is he trying to say that while $e^{X_n}$ is also approximately Normal for $n$ large, it is a bad approximation? Thanks.","If a sequence of random variables $X_n$ are asymptotically Normal, in what sense is $e^{X_n}$ asymptotically Normal as well? I read the following inside a book: Is it surprising that if $X_n$ is approximately Normal for $n$ large, then $e^{X_n}$ is also approximately Normal for $n$ large? Asymptotically, exponential functions are linear. But then again, asymptotically any two people have the same age, and this is even a better approximation since they differ only by a constant. John Maynard Keynes said “In the long run we are all dead”; in the short run, should we be happy to be asymptotically right but exponentially wrong? I am confused what the author is trying to say here. Is he trying to say that while $e^{X_n}$ is also approximately Normal for $n$ large, it is a bad approximation? Thanks.",,"['probability', 'probability-theory', 'asymptotics']"
52,Convolution that is equiprobable to a uniform distribution,Convolution that is equiprobable to a uniform distribution,,"I am struggling with finding two distributions a and b on the non non-negative integers (both not concentrated at 0, this is t trivial) such that the convolution of a and b is the equiprobable  distribution on the set 0,1,...n-1 n is not a prime number. Any ideas?","I am struggling with finding two distributions a and b on the non non-negative integers (both not concentrated at 0, this is t trivial) such that the convolution of a and b is the equiprobable  distribution on the set 0,1,...n-1 n is not a prime number. Any ideas?",,"['probability', 'probability-theory', 'convolution']"
53,Expected value of distance between two points chosen at random on the edges of a unit cube,Expected value of distance between two points chosen at random on the edges of a unit cube,,"Consider the probability space formed by the set $A$ of the edges of the unit cube $[0,1]^3$ in $\mathbb{R}^3$, the corresponding Borel $\sigma$- algebra, and the normalized length measure. Compute the expected value of the distance of $2$ distinct points chosen independently and uniformly in $A$. My attempt: I know that the expected value can be calculated as  $$\int \int \int \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+(x_3-y_3)^2}\,dx\,dy\,dz. $$ But since the points are all chosen on the edges, then depending on the edge some of coordinates are fixed value, for example $0$ or $1$. But there are many scenarios for example two points are on the same edge, or two points are chosen on two jointed edges and etc. How do I calculate the total expected value? Help please.","Consider the probability space formed by the set $A$ of the edges of the unit cube $[0,1]^3$ in $\mathbb{R}^3$, the corresponding Borel $\sigma$- algebra, and the normalized length measure. Compute the expected value of the distance of $2$ distinct points chosen independently and uniformly in $A$. My attempt: I know that the expected value can be calculated as  $$\int \int \int \sqrt{(x_1-y_1)^2+(x_2-y_2)^2+(x_3-y_3)^2}\,dx\,dy\,dz. $$ But since the points are all chosen on the edges, then depending on the edge some of coordinates are fixed value, for example $0$ or $1$. But there are many scenarios for example two points are on the same edge, or two points are chosen on two jointed edges and etc. How do I calculate the total expected value? Help please.",,"['probability', 'expectation']"
54,Integer solutions question simple,Integer solutions question simple,,"Suppose I have: $$x_1 + x_2 + x_3 + x_4 = 12$$ and I want to find all solutions $x_i \geq 1$ Well firstly I can give 1 to each x, so that leaves me with: $$x_1 + x_2 + x_3 + x_4 = 8$$ Then, I can just make 3 dividers, like such: $$x_1 | x_2 | x_3 | x_4$$ and so my answer is $$\binom{8+3}{3} = \binom{11}{3}$$ My sheet says: $\textit{Theorem}$: The number of ways to distribute $r$ identical objects into $n$ distinct boxes with at least $one$ object in each box is: $$\binom{r-1}{n-1}$$ As you can see, this formula works, cause $\binom{12-1}{4-1} = \binom{11}{3}$ But I'm not sure where they got this formula, and why it works?","Suppose I have: $$x_1 + x_2 + x_3 + x_4 = 12$$ and I want to find all solutions $x_i \geq 1$ Well firstly I can give 1 to each x, so that leaves me with: $$x_1 + x_2 + x_3 + x_4 = 8$$ Then, I can just make 3 dividers, like such: $$x_1 | x_2 | x_3 | x_4$$ and so my answer is $$\binom{8+3}{3} = \binom{11}{3}$$ My sheet says: $\textit{Theorem}$: The number of ways to distribute $r$ identical objects into $n$ distinct boxes with at least $one$ object in each box is: $$\binom{r-1}{n-1}$$ As you can see, this formula works, cause $\binom{12-1}{4-1} = \binom{11}{3}$ But I'm not sure where they got this formula, and why it works?",,"['probability', 'combinatorics']"
55,How to estimate expected total variation distance between conditional probabilities?,How to estimate expected total variation distance between conditional probabilities?,,"Let $(\Omega, \mathcal{F})$ be a measurable space and let $(\mathcal{F}_n)$ be a filtration on this space. Let $P$ and $Q$ be probability measures on $(\Omega, \mathcal{F})$ and suppose that for all $n$, the conditional probabilities of $P$ and $Q$ given $\mathcal{F}_n$ are regular, i.e. $P(\cdot \mid \mathcal{F}_n)(\omega)$ and $Q(\cdot \mid \mathcal{F}_n)(\omega)$ are probability measures on $(\Omega, \mathcal{F})$ for all $\omega \in \Omega$. For convenience, write $P^n = P(\cdot \mid \mathcal{F}_n)$ and similarly for $Q^n$. Let $d$ be the total variation distance, i.e. $d(P,Q) = \sup_{A \in \mathcal{F}}|P(A) - Q(A)|$. I need some help proving the following. Claim. If $d(P,Q) < \alpha \beta$, then $P(\{\omega: d(P^n(\omega), Q^n(\omega)) > \alpha\}) < \beta$. (The Lemma on p.405 of this paper .) My first thought was to use Markov's inequality to get $$P(d(P^n, Q^n) > \alpha) \leq \alpha^{-1}E_P(d(P^n, Q^n)).$$ Now, the claim would follow if I could show that $d(P^n, Q^n)< \alpha \beta$ a.s. ($P$), but the best I can do is use the triangle inequality to get $$d(P^n, Q^n) \leq d(P^n,P) + d(Q^n, Q) + d(P,Q) < 2 + \alpha \beta.$$ Then $P(d(P^n, Q^n) > \alpha) < 2/\alpha + \beta$. I'm stuck trying to improve this. Addendum. On second thought, the above estimate doesn't improve the trivial estimate $P(d(P^n, Q^n) > \alpha) \leq 1$ for small $\alpha$, so probably a different approach is needed. Perhaps we can show that $d(P^n, Q^n) < d(P,Q)$ a.s. (P), but I don't see how to do it yet. Hints are appreciated.","Let $(\Omega, \mathcal{F})$ be a measurable space and let $(\mathcal{F}_n)$ be a filtration on this space. Let $P$ and $Q$ be probability measures on $(\Omega, \mathcal{F})$ and suppose that for all $n$, the conditional probabilities of $P$ and $Q$ given $\mathcal{F}_n$ are regular, i.e. $P(\cdot \mid \mathcal{F}_n)(\omega)$ and $Q(\cdot \mid \mathcal{F}_n)(\omega)$ are probability measures on $(\Omega, \mathcal{F})$ for all $\omega \in \Omega$. For convenience, write $P^n = P(\cdot \mid \mathcal{F}_n)$ and similarly for $Q^n$. Let $d$ be the total variation distance, i.e. $d(P,Q) = \sup_{A \in \mathcal{F}}|P(A) - Q(A)|$. I need some help proving the following. Claim. If $d(P,Q) < \alpha \beta$, then $P(\{\omega: d(P^n(\omega), Q^n(\omega)) > \alpha\}) < \beta$. (The Lemma on p.405 of this paper .) My first thought was to use Markov's inequality to get $$P(d(P^n, Q^n) > \alpha) \leq \alpha^{-1}E_P(d(P^n, Q^n)).$$ Now, the claim would follow if I could show that $d(P^n, Q^n)< \alpha \beta$ a.s. ($P$), but the best I can do is use the triangle inequality to get $$d(P^n, Q^n) \leq d(P^n,P) + d(Q^n, Q) + d(P,Q) < 2 + \alpha \beta.$$ Then $P(d(P^n, Q^n) > \alpha) < 2/\alpha + \beta$. I'm stuck trying to improve this. Addendum. On second thought, the above estimate doesn't improve the trivial estimate $P(d(P^n, Q^n) > \alpha) \leq 1$ for small $\alpha$, so probably a different approach is needed. Perhaps we can show that $d(P^n, Q^n) < d(P,Q)$ a.s. (P), but I don't see how to do it yet. Hints are appreciated.",,"['probability', 'probability-theory', 'measure-theory']"
56,Probability that a 5-card poker hand contains a flush or a three of a kind,Probability that a 5-card poker hand contains a flush or a three of a kind,,"Please excuse me if I don't type this right, this is my first posted question. I hope I do this right.... I'm having problems with a question from my Intro to Math Analysis course. It is not from any book, but a worksheet that the professor made himself. I need to find the probability of getting a flush or a three of a kind in a 5-card poker hand. It is a standard deck, and I need to exclude ""better hands"", like straight flushes and full houses. I know the denominator is ${52\choose {5}}$. For the numerator I have calculated the following: Number of ways to get a flush but not a straight flush: $4\cdot {13\choose {5}} -4 \cdot 10 $ Number of ways to get a three of a kind but not a full house: $13 \cdot {4\choose {3}} \cdot 4 \cdot{12\choose {1}}  \cdot4 \cdot{11\choose {1}} $ I know I need to add these together, and I know I don't have to worry about subtracting the number of hands that have been counted in both because you can't have a three of a kind of the same suit anyway. So I have a numerator of $114,932$. But this is far from the answer, which has a numerator of $60,020$. Please help. Thank you.","Please excuse me if I don't type this right, this is my first posted question. I hope I do this right.... I'm having problems with a question from my Intro to Math Analysis course. It is not from any book, but a worksheet that the professor made himself. I need to find the probability of getting a flush or a three of a kind in a 5-card poker hand. It is a standard deck, and I need to exclude ""better hands"", like straight flushes and full houses. I know the denominator is ${52\choose {5}}$. For the numerator I have calculated the following: Number of ways to get a flush but not a straight flush: $4\cdot {13\choose {5}} -4 \cdot 10 $ Number of ways to get a three of a kind but not a full house: $13 \cdot {4\choose {3}} \cdot 4 \cdot{12\choose {1}}  \cdot4 \cdot{11\choose {1}} $ I know I need to add these together, and I know I don't have to worry about subtracting the number of hands that have been counted in both because you can't have a three of a kind of the same suit anyway. So I have a numerator of $114,932$. But this is far from the answer, which has a numerator of $60,020$. Please help. Thank you.",,['probability']
57,Upper bound for sum of binomial coefficients,Upper bound for sum of binomial coefficients,,"I need to provide a reasonable upper bound for the following sum for large $N$, and a given $c \in (0,1], q \in [0, 1]$: $$ \sum_{n= [ c N ] }^{N} \binom{N}{n} q^n $$ Is there a good formula for such an upper bound? It is not clear to me under which conditions on $c$ and $q$ it diverges to infinity with $N$ or it goes to 0 exponentially fast with $N$. Note that for any $q$ and $N$, $$ \sum_{n= 0 }^{N} \binom{N}{n} q^n = ( 1 + q)^N. $$","I need to provide a reasonable upper bound for the following sum for large $N$, and a given $c \in (0,1], q \in [0, 1]$: $$ \sum_{n= [ c N ] }^{N} \binom{N}{n} q^n $$ Is there a good formula for such an upper bound? It is not clear to me under which conditions on $c$ and $q$ it diverges to infinity with $N$ or it goes to 0 exponentially fast with $N$. Note that for any $q$ and $N$, $$ \sum_{n= 0 }^{N} \binom{N}{n} q^n = ( 1 + q)^N. $$",,"['probability', 'sequences-and-series', 'combinatorics', 'binomial-coefficients']"
58,"How do I find a mean and variance of ratio of two random variables for given mean, variance, and co-variance?","How do I find a mean and variance of ratio of two random variables for given mean, variance, and co-variance?",,"Given two random variables $X$ and $Y$ with mean of $\mu_X$ and $\mu_Y$, variances of $\sigma_X^2$ and $\sigma_Y^2$, and covariance of $C_{XY}$, how to find the approximation of the mean and variance of $Z = \frac{Y}{X}$ in terms of  $\mu_X$,  $\mu_Y$, $\sigma_X^2$, $\sigma_Y^2$, and $C_{XY}$?","Given two random variables $X$ and $Y$ with mean of $\mu_X$ and $\mu_Y$, variances of $\sigma_X^2$ and $\sigma_Y^2$, and covariance of $C_{XY}$, how to find the approximation of the mean and variance of $Z = \frac{Y}{X}$ in terms of  $\mu_X$,  $\mu_Y$, $\sigma_X^2$, $\sigma_Y^2$, and $C_{XY}$?",,"['probability', 'probability-distributions', 'random-variables', 'means']"
59,How to solve this conditional pdf?,How to solve this conditional pdf?,,"I have a joint distribution$$f_{XY}(x,y) = (2\pi\sigma^2)^{-1}\text {exp}\left(-{{x^2+y^2}\over{2\sigma^2}}\right)$$ I need to calculate $$f_{xy}(x,y|x^2+y^2<b^2)$$ I think I should use bayes theorem transfer it and calculate $$f_{xy}(x^2+y^2<b^2|x,y) \ \ \ \ *$$ what confuses me is if function * equates to $$f_{xy}(x^2+y^2<b^2)$$ If it's valid, then  $$f_{xy}(x,y|x^2+y^2<b^2)={{f_{xy}(x^2+y^2<b^2|x,y) \cdot f_{xy}(x,y)}\over{f_{xy}(x^2+y^2<b^2)}} = \\ =f_{xy}(x,y)$$ So I think it should be wrong. Then how to explain the condition of function * please? Thank you very much. I have solution: I wonder if $$F_{xy}(x,y|x^2+y^2<b^2) = F_{x}(-\sqrt{b^2-y^2}<x<\sqrt{b^2-y^2} ) + F_{y}(-\sqrt{b^2-x^2} <y<\sqrt{b^2-y^2}) = \\F_{x}(\sqrt{b^2-y^2})-F_{x}(-\sqrt{b^2-y^2})+F_{y}(\sqrt{b^2-x^2})-F_{y}(-\sqrt{b^2-x^2})$$ is correct? it is easy to calculate $f_{x}$ and $f_{y}$, then I can know $F_{x}$ and $F_{y}$, then it is easy to calculate $F_{xy}(x,y|x^2+y^2<b^2)$ like above. Finally what I need to do is differentiate it. But I don't know if it's valid.","I have a joint distribution$$f_{XY}(x,y) = (2\pi\sigma^2)^{-1}\text {exp}\left(-{{x^2+y^2}\over{2\sigma^2}}\right)$$ I need to calculate $$f_{xy}(x,y|x^2+y^2<b^2)$$ I think I should use bayes theorem transfer it and calculate $$f_{xy}(x^2+y^2<b^2|x,y) \ \ \ \ *$$ what confuses me is if function * equates to $$f_{xy}(x^2+y^2<b^2)$$ If it's valid, then  $$f_{xy}(x,y|x^2+y^2<b^2)={{f_{xy}(x^2+y^2<b^2|x,y) \cdot f_{xy}(x,y)}\over{f_{xy}(x^2+y^2<b^2)}} = \\ =f_{xy}(x,y)$$ So I think it should be wrong. Then how to explain the condition of function * please? Thank you very much. I have solution: I wonder if $$F_{xy}(x,y|x^2+y^2<b^2) = F_{x}(-\sqrt{b^2-y^2}<x<\sqrt{b^2-y^2} ) + F_{y}(-\sqrt{b^2-x^2} <y<\sqrt{b^2-y^2}) = \\F_{x}(\sqrt{b^2-y^2})-F_{x}(-\sqrt{b^2-y^2})+F_{y}(\sqrt{b^2-x^2})-F_{y}(-\sqrt{b^2-x^2})$$ is correct? it is easy to calculate $f_{x}$ and $f_{y}$, then I can know $F_{x}$ and $F_{y}$, then it is easy to calculate $F_{xy}(x,y|x^2+y^2<b^2)$ like above. Finally what I need to do is differentiate it. But I don't know if it's valid.",,"['probability', 'statistics', 'probability-distributions']"
60,Balls and Bins Variation (Multiple Rounds),Balls and Bins Variation (Multiple Rounds),,"Consider the following balls and bins experiment: we repeatedly throw a fixed number of balls randomly into a shrinking set of bins. The experiment starts with $n$ balls and $n$ bins. In each round $k,$ we throw $n$ balls into the remaining bins, and then discard any non-empty bins; thus, only bins that are empty at the end of round $k$ survive to round $k + 1$. What is the expected number of rounds before every bin among the initial $n$ is nonempty? In general, assuming we are conducting the standard balls-and-bins experiment, then given $m$ balls and $n$ bins, we know that the expected number of bins that are empty is $n(1 - \frac{1}{n})^m$. With this in mind, I've attempted to consider each round in the above experiment as an instance of the standard balls into bins problem, and have reformulated the question into an equivalent one, thus: Suppose that for each round, exactly the expected number of bins are empty. Then after how many rounds does the experiment end? However, the expected number formula quickly gets unwieldy. But consider the function defined for any integer $i \geq 0$: $f(i+1) = 2^{f(i)}$ for $i \geq 1$ and $f(0) = 1$ Could I use an induction argument to show that, after round $i$ and before round $i + 1$ (assuming that exactly the expected number of bins are empty for each round), we have that $\frac{n}{f(i+1)} \leq \textit{number of empty bins} < \frac{n}{f(i)}$ and try to tightly bound the solution from above?","Consider the following balls and bins experiment: we repeatedly throw a fixed number of balls randomly into a shrinking set of bins. The experiment starts with $n$ balls and $n$ bins. In each round $k,$ we throw $n$ balls into the remaining bins, and then discard any non-empty bins; thus, only bins that are empty at the end of round $k$ survive to round $k + 1$. What is the expected number of rounds before every bin among the initial $n$ is nonempty? In general, assuming we are conducting the standard balls-and-bins experiment, then given $m$ balls and $n$ bins, we know that the expected number of bins that are empty is $n(1 - \frac{1}{n})^m$. With this in mind, I've attempted to consider each round in the above experiment as an instance of the standard balls into bins problem, and have reformulated the question into an equivalent one, thus: Suppose that for each round, exactly the expected number of bins are empty. Then after how many rounds does the experiment end? However, the expected number formula quickly gets unwieldy. But consider the function defined for any integer $i \geq 0$: $f(i+1) = 2^{f(i)}$ for $i \geq 1$ and $f(0) = 1$ Could I use an induction argument to show that, after round $i$ and before round $i + 1$ (assuming that exactly the expected number of bins are empty for each round), we have that $\frac{n}{f(i+1)} \leq \textit{number of empty bins} < \frac{n}{f(i)}$ and try to tightly bound the solution from above?",,"['probability', 'expectation', 'balls-in-bins']"
61,Inequality of probablity.,Inequality of probablity.,,"Let $(S,F,P)$ be probability space and $X :S \rightarrow \mathbb{R}$ be random variable with mean 0 and variance 1. Let $c \geq 0$. I want to show that $P(X \geq c) \leq \frac{1}{1+c^2}.$ I already know Chebychev inequality $P(X\geq) \leq 1/c^2$ when $c > 0$. If this inequality holds, $1/1+c^2$ will be better estimates. Could you help me?","Let $(S,F,P)$ be probability space and $X :S \rightarrow \mathbb{R}$ be random variable with mean 0 and variance 1. Let $c \geq 0$. I want to show that $P(X \geq c) \leq \frac{1}{1+c^2}.$ I already know Chebychev inequality $P(X\geq) \leq 1/c^2$ when $c > 0$. If this inequality holds, $1/1+c^2$ will be better estimates. Could you help me?",,['probability']
62,Popcorn Probability,Popcorn Probability,,"Question: The time to microwave a bag of popcorn using the automatic setting can be treated as a random variable having a normal distribution with mean 2 min and standard deviation 15 seconds. three independent bags of popcorn A,B and C are selected. The two bags A and B are put into a microwave immediately. As soon as bag A pops, the bag C is put into microwave. Find the probability that B pops before C. I really don't know where do start. I think it would be something along the lines of P(B pops before A)*P(B pops before c - 2). Any help would be greatly appreciated,  thanks.","Question: The time to microwave a bag of popcorn using the automatic setting can be treated as a random variable having a normal distribution with mean 2 min and standard deviation 15 seconds. three independent bags of popcorn A,B and C are selected. The two bags A and B are put into a microwave immediately. As soon as bag A pops, the bag C is put into microwave. Find the probability that B pops before C. I really don't know where do start. I think it would be something along the lines of P(B pops before A)*P(B pops before c - 2). Any help would be greatly appreciated,  thanks.",,"['probability', 'normal-distribution', 'standard-deviation', 'independence', 'means']"
63,Probability : Two dice are thrown r times.,Probability : Two dice are thrown r times.,,"Two dice are thrown r times. Find the probability $p_r$ that each of the six combinations $(1,1),\ldots,(6,6)$ appears at least once. My approach : As per my understanding will this be 1 - Pr(at least one of the pair does not occur in $r$ trials) ?  So will this be $1 - (\Sigma_{i=1}^6\frac{(-1)^{(i-1)} * {^6}C_i*(36-i)^r}{36^r})$ ?","Two dice are thrown r times. Find the probability $p_r$ that each of the six combinations $(1,1),\ldots,(6,6)$ appears at least once. My approach : As per my understanding will this be 1 - Pr(at least one of the pair does not occur in $r$ trials) ?  So will this be $1 - (\Sigma_{i=1}^6\frac{(-1)^{(i-1)} * {^6}C_i*(36-i)^r}{36^r})$ ?",,"['probability', 'probability-theory', 'probability-distributions']"
64,Understanding Conditional Probability with More than 2 Events,Understanding Conditional Probability with More than 2 Events,,"Is there a difference between: $$p(y|x,z) = \frac{p(y,x|z)}{p(x|z)}$$ and $$p(y|x,z) = \frac{p(y,x,z)}{p(x,z)}$$ I was working on a problem that asks one to prove $p(x, y|z) = p(x|z)p(y|x, z)$ and the second one just came to my mind.","Is there a difference between: $$p(y|x,z) = \frac{p(y,x|z)}{p(x|z)}$$ and $$p(y|x,z) = \frac{p(y,x,z)}{p(x,z)}$$ I was working on a problem that asks one to prove $p(x, y|z) = p(x|z)p(y|x, z)$ and the second one just came to my mind.",,['probability']
65,Connection between the Kalman filter and the multivariate normal distribution,Connection between the Kalman filter and the multivariate normal distribution,,"Consider at dynamic linear model where $$ \theta_{1} \sim N(\mu_{1}, W_{1}), $$ $$ \theta_{i}=G\theta_{i-1} + w_{i}, w_{i}\sim N(0,W), $$ $$ Y_{i} = F\theta_{i} + v_{i}, v_{i}\sim N(0,V) $$ and $ \theta_{1}, w_{i}, v_{i} $ all independent random vectors. Let $ \theta_{0:t} : = (\theta_{t}, \theta_{t-1},\ldots, \theta_{0}) $ and $ Y_{1:t}:= (Y_{t},Y_{t-1},\ldots, Y_{1})$. A generel result from multivariate normal distribution is as follows: Suppose $ Y|X=x \sim N(Ax,V)$ and $ X \sim N(\mu, \Sigma) $. Then $ Y\sim(A\mu, A\Sigma A^{T} + V) $. Question 1: How do I see, that the joint density of $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? From the definitions above, we have $Y_{t}|\theta_{t}$ is normal and $\theta_{t}|\theta_{t-1}$ is normal. From the general result the joint densities of $(Y_{t},\theta_{t})$ and $(\theta_t, \theta_{t-1})$ is also normal. In fact, since a dynamic linear model is also a state space model, it can be shown (and I have) that $$p(\theta_{0:t}, y_{1:t}) = p(\theta_0)\prod_{j=1}^{t}p(y_j | \theta_j)p(\theta_j  | \theta_{j-1}).$$ But I can not complete the puzzle; i.e why is $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? Question 2: Assume we know  $$ \theta_{n-1}\mid Y_{1:n-1} = y_{1:n-1} \sim N(\hat \theta_{n-1}, \Sigma_{n-1}).$$ Now, how do I apply the generel result stated above, to see that $$ \theta_{n}\mid Y_{1:n-1} = y_{1:n-1} \sim N(G\hat \theta_{n-1}, G\Sigma_{n-1}G^{T} + W).$$ Of course we have $E[\theta_n | Y_{1:n-1}] = G\hat \theta_{n-1}$ and $Var[\theta_n | Y_{1:n-1}] = G\Sigma_{n-1}G^{T} + W$. But I am not sure why $\theta_{n}\mid Y_{1:n-1}$ is normally distributed. My guess is, that I can apply the result about linear combinations of Gaussians is again Gaussian.","Consider at dynamic linear model where $$ \theta_{1} \sim N(\mu_{1}, W_{1}), $$ $$ \theta_{i}=G\theta_{i-1} + w_{i}, w_{i}\sim N(0,W), $$ $$ Y_{i} = F\theta_{i} + v_{i}, v_{i}\sim N(0,V) $$ and $ \theta_{1}, w_{i}, v_{i} $ all independent random vectors. Let $ \theta_{0:t} : = (\theta_{t}, \theta_{t-1},\ldots, \theta_{0}) $ and $ Y_{1:t}:= (Y_{t},Y_{t-1},\ldots, Y_{1})$. A generel result from multivariate normal distribution is as follows: Suppose $ Y|X=x \sim N(Ax,V)$ and $ X \sim N(\mu, \Sigma) $. Then $ Y\sim(A\mu, A\Sigma A^{T} + V) $. Question 1: How do I see, that the joint density of $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? From the definitions above, we have $Y_{t}|\theta_{t}$ is normal and $\theta_{t}|\theta_{t-1}$ is normal. From the general result the joint densities of $(Y_{t},\theta_{t})$ and $(\theta_t, \theta_{t-1})$ is also normal. In fact, since a dynamic linear model is also a state space model, it can be shown (and I have) that $$p(\theta_{0:t}, y_{1:t}) = p(\theta_0)\prod_{j=1}^{t}p(y_j | \theta_j)p(\theta_j  | \theta_{j-1}).$$ But I can not complete the puzzle; i.e why is $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? Question 2: Assume we know  $$ \theta_{n-1}\mid Y_{1:n-1} = y_{1:n-1} \sim N(\hat \theta_{n-1}, \Sigma_{n-1}).$$ Now, how do I apply the generel result stated above, to see that $$ \theta_{n}\mid Y_{1:n-1} = y_{1:n-1} \sim N(G\hat \theta_{n-1}, G\Sigma_{n-1}G^{T} + W).$$ Of course we have $E[\theta_n | Y_{1:n-1}] = G\hat \theta_{n-1}$ and $Var[\theta_n | Y_{1:n-1}] = G\Sigma_{n-1}G^{T} + W$. But I am not sure why $\theta_{n}\mid Y_{1:n-1}$ is normally distributed. My guess is, that I can apply the result about linear combinations of Gaussians is again Gaussian.",,"['probability', 'normal-distribution', 'kalman-filter']"
66,Any good practice material for expected value and variance?,Any good practice material for expected value and variance?,,"I am trying to learn more about probability mass functions, density functions, expected value, and variance. Are there any online materials or quizzes (with answers and explanations) that I can use to test my understanding?","I am trying to learn more about probability mass functions, density functions, expected value, and variance. Are there any online materials or quizzes (with answers and explanations) that I can use to test my understanding?",,"['probability', 'statistics', 'reference-request', 'expectation', 'variance']"
67,Probability of at least k distinct events occuring after N trials,Probability of at least k distinct events occuring after N trials,,"Given a finite set $|S|$ of distinct events, each with a $1/|S|$ probability of occurrence, what is the probability that at least k distinct events occur after N trials? For every trial, there is guaranteed to be exactly one event that occurs. Events are repeatable. For instance, take $S = \{rain, sun, snow\}$. After $N=10$ days, what is the probability that at least $k=2$ distinct types of weather have occurred? In my specific problem, I have $|S| = 35$, so a method of approximation would be preferred.","Given a finite set $|S|$ of distinct events, each with a $1/|S|$ probability of occurrence, what is the probability that at least k distinct events occur after N trials? For every trial, there is guaranteed to be exactly one event that occurs. Events are repeatable. For instance, take $S = \{rain, sun, snow\}$. After $N=10$ days, what is the probability that at least $k=2$ distinct types of weather have occurred? In my specific problem, I have $|S| = 35$, so a method of approximation would be preferred.",,"['probability', 'statistics']"
68,"When randomly selecting n unique edges from a complete graph, what is the probability distribution for the numbers of covered vertices?","When randomly selecting n unique edges from a complete graph, what is the probability distribution for the numbers of covered vertices?",,"Assume that we have a complete graph $G = \{V,E\}$, where $V$ is the vertices set and $E$ is the edges set. We randomly select $n$ unique edges from $G$ ($n \le |E|$), and these edges cover $m$ vertices. The problem is: what is the probability distribution for $m$? ========================================= I read a helpful post: Given a random labelled simple graph with n edges, when is it more likely to get a graph with more edges than vertices? ========================================== Now I am trying to transform this problem to picking random element pairs from a set, and I find this post could be helpful since it asked a very similar question. https://stackoverflow.com/questions/15793172/efficiently-generating-unique-pairs-of-integers Could anyone please help me?","Assume that we have a complete graph $G = \{V,E\}$, where $V$ is the vertices set and $E$ is the edges set. We randomly select $n$ unique edges from $G$ ($n \le |E|$), and these edges cover $m$ vertices. The problem is: what is the probability distribution for $m$? ========================================= I read a helpful post: Given a random labelled simple graph with n edges, when is it more likely to get a graph with more edges than vertices? ========================================== Now I am trying to transform this problem to picking random element pairs from a set, and I find this post could be helpful since it asked a very similar question. https://stackoverflow.com/questions/15793172/efficiently-generating-unique-pairs-of-integers Could anyone please help me?",,"['probability', 'combinatorics', 'probability-theory', 'graph-theory', 'probability-distributions']"
69,probability/combinatorics question with marbles,probability/combinatorics question with marbles,,"An urn has 20 green out of 50 marbles. Draw all 50 marbles without replacement. Let X = # of green marble runs of any length. Example : GGGG BBB GG BB G BB. . . In the above example, there are 3 runs in the first 14 trials. To get X, we would have to examine the entire sequence of the 50 trials. Find P(X=1) For X=1 runs, that means that all 20 green marbles are together. There are 31 spots where that run could be. I came up with the answer $\frac{20 \choose 20}{50 \choose 20} * 31 $ Is this correct? The biggest trouble that I have in computing my answer is that the green marbles have to be in a row . If the green marbles didn't have to be in a row then would it just be ${50 \choose 20}$?","An urn has 20 green out of 50 marbles. Draw all 50 marbles without replacement. Let X = # of green marble runs of any length. Example : GGGG BBB GG BB G BB. . . In the above example, there are 3 runs in the first 14 trials. To get X, we would have to examine the entire sequence of the 50 trials. Find P(X=1) For X=1 runs, that means that all 20 green marbles are together. There are 31 spots where that run could be. I came up with the answer $\frac{20 \choose 20}{50 \choose 20} * 31 $ Is this correct? The biggest trouble that I have in computing my answer is that the green marbles have to be in a row . If the green marbles didn't have to be in a row then would it just be ${50 \choose 20}$?",,"['probability', 'combinatorics', 'statistics']"
70,Expected number of virus cells,Expected number of virus cells,,"I've found this question in a past programming assignment from a course I'm currently reading. Its statement looks like this : A recent lab accident resulted in the creation of an extremely dangerous virus that replicates so rapidly it's hard to predict exactly how many cells it will contain after a given period of time. However, a lab technician made the following observations about its growth per millisecond: $\bullet$ The probability of the number of virus cells growing by a factor of $a$ is $0.5$ $\bullet$ The probability of the number of virus cells growing by a factor of $b$ is $0.5$ Given a, b, and knowing that initially there is only a single cell of virus, calculate the expected number of virus cells after $t$ milliseconds. As this number can be very large, print your answer modulo $(10^9 + 7)$ . As I have no prior training in probability or combinatorics, this problem doesn't make much sense to me . I've done some searching about expected values in the context of probability, but I can't see how to model the data I'm given. Perhaps there's something very obvious I'm missing, but I'm not able to see it at the moment. How would you solve this?","I've found this question in a past programming assignment from a course I'm currently reading. Its statement looks like this : A recent lab accident resulted in the creation of an extremely dangerous virus that replicates so rapidly it's hard to predict exactly how many cells it will contain after a given period of time. However, a lab technician made the following observations about its growth per millisecond: The probability of the number of virus cells growing by a factor of is The probability of the number of virus cells growing by a factor of is Given a, b, and knowing that initially there is only a single cell of virus, calculate the expected number of virus cells after milliseconds. As this number can be very large, print your answer modulo . As I have no prior training in probability or combinatorics, this problem doesn't make much sense to me . I've done some searching about expected values in the context of probability, but I can't see how to model the data I'm given. Perhaps there's something very obvious I'm missing, but I'm not able to see it at the moment. How would you solve this?",\bullet a 0.5 \bullet b 0.5 t (10^9 + 7),"['probability', 'algorithms']"
71,Problem 48 in A First Course in Probability,Problem 48 in A First Course in Probability,,"I have an issue with problem 48 Chapter 2, page 51 in Sheldon Ross' A First Course in Probability (9th edition). The problem is as follows, Given 20 people, what is the probability that among the 12 months in the year, there are 4 months containing exactly 2 birthdays and 4 containing exactly 3 birthdays? So originally I computed $$\dfrac{\dbinom{12}{4,4,4}\dbinom{20}{2,2,2,2,3,3,3,3}}{12^{20}}\approx.00106$$ Which matches other peoples solutions and the older edition's (8 and lower) solution in the back of the book (it is definitely the same problem). However, the 9th edition has another solution of .01697, which I found to be using the same methodology as above but mixing the months that have 2 and 3 birthdays, ie $$\dfrac{\dbinom{12}{4,4,4}\cdot 4\cdot 4\cdot \dbinom{20}{2,2,2,2,3,3,3,3}}{12^{20}}$$ My question is, which would be correct regardless if my reasoning may be flawed in the second, (ie maybe the computation is right but my reason is wrong), why would Ross update the problem with a different solution if the first was correct? Is this just a mistake in the update? Thanks","I have an issue with problem 48 Chapter 2, page 51 in Sheldon Ross' A First Course in Probability (9th edition). The problem is as follows, Given 20 people, what is the probability that among the 12 months in the year, there are 4 months containing exactly 2 birthdays and 4 containing exactly 3 birthdays? So originally I computed $$\dfrac{\dbinom{12}{4,4,4}\dbinom{20}{2,2,2,2,3,3,3,3}}{12^{20}}\approx.00106$$ Which matches other peoples solutions and the older edition's (8 and lower) solution in the back of the book (it is definitely the same problem). However, the 9th edition has another solution of .01697, which I found to be using the same methodology as above but mixing the months that have 2 and 3 birthdays, ie $$\dfrac{\dbinom{12}{4,4,4}\cdot 4\cdot 4\cdot \dbinom{20}{2,2,2,2,3,3,3,3}}{12^{20}}$$ My question is, which would be correct regardless if my reasoning may be flawed in the second, (ie maybe the computation is right but my reason is wrong), why would Ross update the problem with a different solution if the first was correct? Is this just a mistake in the update? Thanks",,"['probability', 'combinatorics']"
72,Probability of 4 specific numbers (1-3000) occuring in a sample of 400,Probability of 4 specific numbers (1-3000) occuring in a sample of 400,,"How to calculate the probability that four specific, distinct numbers from the range 1 - 3000 occur at least once in a fixed sample of 400 random numbers from the range 1-3000? The numbers in the sample can repeat as they were randomly generated. My intuition would be that it is basically a set of four ""scans"" of the 400 numbers, so the probability of hitting the 1/3000 searched number in each of the scans is roughly 400/3000 = 2/15. This would give the total probability count as (2/15)x(2/15)x(2/15)x(2/15) = 16/50625 = 0,000316. However, I'm not sure if this accounts (and if it should account) for the fact that it is a fixed sample so it's not ""re-rolled"" for each of the four scans. Thanks for any advice.","How to calculate the probability that four specific, distinct numbers from the range 1 - 3000 occur at least once in a fixed sample of 400 random numbers from the range 1-3000? The numbers in the sample can repeat as they were randomly generated. My intuition would be that it is basically a set of four ""scans"" of the 400 numbers, so the probability of hitting the 1/3000 searched number in each of the scans is roughly 400/3000 = 2/15. This would give the total probability count as (2/15)x(2/15)x(2/15)x(2/15) = 16/50625 = 0,000316. However, I'm not sure if this accounts (and if it should account) for the fact that it is a fixed sample so it's not ""re-rolled"" for each of the four scans. Thanks for any advice.",,"['probability', 'combinatorics']"
73,Probability of picking a uniquely colored ball,Probability of picking a uniquely colored ball,,"I came across an interesting problem on probability which is as follows: Consider that there are two buckets A and B. A has N differently numbered balls {1,2,3,...,N} while B has a subset of balls that are already in A. e.g. N = 5, A = {#1,#2,#3,#4,#5} and B = {#1,#4,#5} What is the probability of picking d balls from bucket A such that exactly one ball is new to B e.g. d = 2, Picked = {#2,#4} and #2 is unique The answer can I could derive is  $$ \text{Prob} = \frac{\binom r{d-1}(N-r)}{\binom N{d}}  $$ Now I wanted to generalize the above problem, but failed. The problem is as follows. Consider that there are N different numbered balls that exist {1,2,...,N}. Moreover, there are two buckets A having n and B having m uniquely numbered balls. A and B might have balls of the same color. e.g. N = 10, A = {#1,#2,#3} and B = {#2,#3,#4} What is the probability P that if we pick d balls from A, exactly 1 ball is absent in B. e.g. d = 2. So we pick {#1,#2} and #1 is unique to bucket B. The answer can I could derive is: Given we know the number of balls common in A and B as k, $$ \text{Prob} = \frac{\binom k{d-1}(m-k)}{\binom n{d}}  $$ Did I miss anything important?","I came across an interesting problem on probability which is as follows: Consider that there are two buckets A and B. A has N differently numbered balls {1,2,3,...,N} while B has a subset of balls that are already in A. e.g. N = 5, A = {#1,#2,#3,#4,#5} and B = {#1,#4,#5} What is the probability of picking d balls from bucket A such that exactly one ball is new to B e.g. d = 2, Picked = {#2,#4} and #2 is unique The answer can I could derive is  $$ \text{Prob} = \frac{\binom r{d-1}(N-r)}{\binom N{d}}  $$ Now I wanted to generalize the above problem, but failed. The problem is as follows. Consider that there are N different numbered balls that exist {1,2,...,N}. Moreover, there are two buckets A having n and B having m uniquely numbered balls. A and B might have balls of the same color. e.g. N = 10, A = {#1,#2,#3} and B = {#2,#3,#4} What is the probability P that if we pick d balls from A, exactly 1 ball is absent in B. e.g. d = 2. So we pick {#1,#2} and #1 is unique to bucket B. The answer can I could derive is: Given we know the number of balls common in A and B as k, $$ \text{Prob} = \frac{\binom k{d-1}(m-k)}{\binom n{d}}  $$ Did I miss anything important?",,['probability']
74,Coin flipping probability taking turns between players,Coin flipping probability taking turns between players,,"I've worked out the result to a basic coin flipping problem and want to generalize it. The basic problem is: there are N players, and they take turns of flipping a coin (in the same cyclical order) until the first person to get 1 heads wins. Coin is not necessarily fair so give it probability p of Heads. The answer I worked out is as follows. Say P(m) represents the probability that player m (of the N players) wins. Then: $$ P(m) = \frac{(1-p)^{m-1}p}{1-(1-p)^{N}} $$  This is because for player m to win, the m-1 preceding players must get tails with probability (1-p). It also uses the convergence formula for the sum of a geometric series. ---------------------------------------------------------------------------- Now my question is how to generalize this from: ""winning""= first person to get 1 Heads, to ""winning""= first person to get K heads? In other words, players take turns (in the same order as before) of flipping a coin a single time. Once all the players have flipped, then as before, the cycle repeats from player 1. But this time, the winner is the first person to get K heads (not necessarily in a row) before anyone else gets K heads. I'm having difficulty because the tree of possibilities expands very quickly. For instance, I'd be happy to at least see the derivation for the case of K=2.","I've worked out the result to a basic coin flipping problem and want to generalize it. The basic problem is: there are N players, and they take turns of flipping a coin (in the same cyclical order) until the first person to get 1 heads wins. Coin is not necessarily fair so give it probability p of Heads. The answer I worked out is as follows. Say P(m) represents the probability that player m (of the N players) wins. Then: $$ P(m) = \frac{(1-p)^{m-1}p}{1-(1-p)^{N}} $$  This is because for player m to win, the m-1 preceding players must get tails with probability (1-p). It also uses the convergence formula for the sum of a geometric series. ---------------------------------------------------------------------------- Now my question is how to generalize this from: ""winning""= first person to get 1 Heads, to ""winning""= first person to get K heads? In other words, players take turns (in the same order as before) of flipping a coin a single time. Once all the players have flipped, then as before, the cycle repeats from player 1. But this time, the winner is the first person to get K heads (not necessarily in a row) before anyone else gets K heads. I'm having difficulty because the tree of possibilities expands very quickly. For instance, I'd be happy to at least see the derivation for the case of K=2.",,['probability']
75,Splitting Line Segments and Finding Expected Value,Splitting Line Segments and Finding Expected Value,,"Consider a line segment which has a length of $2n-3$. It is split into $n$ segments at random. It is guaranteed that $n\ge 3$ and $n\in \mathbb{Z}$. These smaller lines are then used as the sides of a convex $n$-polygon. However, the lines are arranged in a way that the area is maximum. Additionally, there are ${2n-4}\choose {n-1}$ total ways to split the original line and occur with same probability. How can we find the expected value of the area? If we work out the case for $n=3$, there will have to be $2$ splits. All three smaller lines have to be of the same size if we look at the above conditions. So now, we have a triangle whose sides are all $1$ and so the area is $\frac{1}{4}\sqrt{3}$. $n=3$ seems to be a simple case. What about for larger $n$? Can we derive a formula for general $n$, or is each case independent of one another?","Consider a line segment which has a length of $2n-3$. It is split into $n$ segments at random. It is guaranteed that $n\ge 3$ and $n\in \mathbb{Z}$. These smaller lines are then used as the sides of a convex $n$-polygon. However, the lines are arranged in a way that the area is maximum. Additionally, there are ${2n-4}\choose {n-1}$ total ways to split the original line and occur with same probability. How can we find the expected value of the area? If we work out the case for $n=3$, there will have to be $2$ splits. All three smaller lines have to be of the same size if we look at the above conditions. So now, we have a triangle whose sides are all $1$ and so the area is $\frac{1}{4}\sqrt{3}$. $n=3$ seems to be a simple case. What about for larger $n$? Can we derive a formula for general $n$, or is each case independent of one another?",,"['probability', 'combinatorics', 'geometry', 'statistics', 'expectation']"
76,Limit theorem for changed time,Limit theorem for changed time,,"This post seems long, but its almost everything proofed in this post. Only one step seems to be left, for the desired proof. I would be very gratefull for any help. The setup Given a Levy-Process $U_{t}$ with  with $E(U_t)=0$ (then $U_t$ is a martingale). Let $U_t$ have finite variance $Var(U_t)=tVar(U_1)$ and $Var(U_1)=\sigma^{2}$ and the limit theorem  holds: \begin{align} F_t:=\sqrt{t}\left(\frac{U_t}{t}-E(U_1) \right)=\frac{U_t}{\sqrt{t}}\xrightarrow{d}\mathcal{N}(0,\sigma^{2})\quad as \,\,t\rightarrow \infty.\tag1 \end{align} Let $K_t$ a non-decreasing positive ($K_{t}>0$ a.s.) process with cadlag-paths with the property that $K_{t}\rightarrow \infty$ almost sureley, as $t\rightarrow \infty$. I want to show that  \begin{align} F_{K_t}:=\frac{U_{K_t}}{\sqrt{K_{t}}} \xrightarrow{d}\mathcal{N}(0,\sigma^{2})\quad as \,\,t\rightarrow \infty. \tag2 \end{align} For this one requires a positive non-random cadlag-function $a(t)$ with $a(t)\rightarrow \infty$ as $t\rightarrow \infty$ such that \begin{align} \frac{K_{t}}{a(t)}\rightarrow \theta\quad P\, a.s. \tag3 \end{align} holds. Where $\theta$ is a positive random-variable. Then the convergence in distribution of $F_{t}\xrightarrow{d} \mathcal{N}(0,\sigma^{2})$ implies the convergence in distribution of $F_{K_t}\xrightarrow{d} \mathcal{N}(0,\sigma^{2})$. The original question from my old account is posted here .  However with my reputation here, i am able to start a bounty for the question. The suggestion of the proof are the following: For simplicity it is said, that $\theta=1$ and $\sigma^{2}=1$ So that we have $K_{t}\in ((1-\epsilon)a(t),(1+\epsilon)a(t))$ for large $t$. For $0<\theta<\infty$ we could do the same procedure and get the same result. This is how we go on: For small $m$ we have $$ P(U_{K_t}<x\sqrt{K_t})\leq P\left(K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))\right)+P\left(U_{a_t}<x\sqrt{(1+\epsilon)a(t)}+m\cdot \sqrt{\epsilon a(t))}\right)+ P\left(\sup_{s\in ((1-\epsilon)a(t),(1+\epsilon)a(t))}|U_{s}-U_{a(t)}|>m\cdot \sqrt{\epsilon a(t))}\right) $$ The first term converges to 0 due to (3). The second term converges to $\Phi(x+m)$ (Why?) by the central limit theorem (1) applied to $U_{a(t)}$. The third term is bounded by martingale inequalitys $L^{2}$ by a factor $$\frac{1}{(m\cdot \sqrt{\epsilon a(t))})^{2}}$$ Otherwise we can state $$ P(U_{K_t}<x\sqrt{K_t})\geq Z\xrightarrow{d} \Phi(x-m) $$ So we have sandwiched it and the desired result (2) holds for arbitrary $0<\theta<\infty$. HOWEVER (hopefolly the last step) We have with $(3)$ convegence to a strict positive finite randomvariable $\theta$. What is left to proof, considering, that $\theta$ is regarded as a random variable? Some additional stuffto understand the inequalities $$ P(U_{k_t}<x \sqrt{K_t})\\ \leq P[U_{k_t}<x \sqrt{K_t},K_{t}\in((1-\epsilon) a(t),(1+\epsilon) a(t))]+P[U_{K_t}<x\sqrt{K_t},K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))] \\ \leq P[K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))]+ P[U_{k_t}<x \sqrt{K_t},K_{t}\in((1-\epsilon) a(t),(1+\epsilon) a(t))] \\ \leq P[K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))]  \\ +P(U_{K_{t}}<x\sqrt{(1+ \epsilon)a(t)},|U_{K_t}-U_{a(t)}|\leq m\sqrt{\epsilon a(t)},|U_{K_t}-U_{a(t)}|> m\sqrt{\epsilon a(t)}] \\ \leq P[U_{a(t)}<x\sqrt{(1+\epsilon)a(t)}+m \sqrt{\epsilon a(t)}] + P\left(\sup_{s\in ((1-\epsilon)a(t),(1+\epsilon)a(t))}|U_{s}-U_{a(t)}|>m\cdot \sqrt{\epsilon a(t))}\right)+P\left(K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))\right) $$","This post seems long, but its almost everything proofed in this post. Only one step seems to be left, for the desired proof. I would be very gratefull for any help. The setup Given a Levy-Process $U_{t}$ with  with $E(U_t)=0$ (then $U_t$ is a martingale). Let $U_t$ have finite variance $Var(U_t)=tVar(U_1)$ and $Var(U_1)=\sigma^{2}$ and the limit theorem  holds: \begin{align} F_t:=\sqrt{t}\left(\frac{U_t}{t}-E(U_1) \right)=\frac{U_t}{\sqrt{t}}\xrightarrow{d}\mathcal{N}(0,\sigma^{2})\quad as \,\,t\rightarrow \infty.\tag1 \end{align} Let $K_t$ a non-decreasing positive ($K_{t}>0$ a.s.) process with cadlag-paths with the property that $K_{t}\rightarrow \infty$ almost sureley, as $t\rightarrow \infty$. I want to show that  \begin{align} F_{K_t}:=\frac{U_{K_t}}{\sqrt{K_{t}}} \xrightarrow{d}\mathcal{N}(0,\sigma^{2})\quad as \,\,t\rightarrow \infty. \tag2 \end{align} For this one requires a positive non-random cadlag-function $a(t)$ with $a(t)\rightarrow \infty$ as $t\rightarrow \infty$ such that \begin{align} \frac{K_{t}}{a(t)}\rightarrow \theta\quad P\, a.s. \tag3 \end{align} holds. Where $\theta$ is a positive random-variable. Then the convergence in distribution of $F_{t}\xrightarrow{d} \mathcal{N}(0,\sigma^{2})$ implies the convergence in distribution of $F_{K_t}\xrightarrow{d} \mathcal{N}(0,\sigma^{2})$. The original question from my old account is posted here .  However with my reputation here, i am able to start a bounty for the question. The suggestion of the proof are the following: For simplicity it is said, that $\theta=1$ and $\sigma^{2}=1$ So that we have $K_{t}\in ((1-\epsilon)a(t),(1+\epsilon)a(t))$ for large $t$. For $0<\theta<\infty$ we could do the same procedure and get the same result. This is how we go on: For small $m$ we have $$ P(U_{K_t}<x\sqrt{K_t})\leq P\left(K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))\right)+P\left(U_{a_t}<x\sqrt{(1+\epsilon)a(t)}+m\cdot \sqrt{\epsilon a(t))}\right)+ P\left(\sup_{s\in ((1-\epsilon)a(t),(1+\epsilon)a(t))}|U_{s}-U_{a(t)}|>m\cdot \sqrt{\epsilon a(t))}\right) $$ The first term converges to 0 due to (3). The second term converges to $\Phi(x+m)$ (Why?) by the central limit theorem (1) applied to $U_{a(t)}$. The third term is bounded by martingale inequalitys $L^{2}$ by a factor $$\frac{1}{(m\cdot \sqrt{\epsilon a(t))})^{2}}$$ Otherwise we can state $$ P(U_{K_t}<x\sqrt{K_t})\geq Z\xrightarrow{d} \Phi(x-m) $$ So we have sandwiched it and the desired result (2) holds for arbitrary $0<\theta<\infty$. HOWEVER (hopefolly the last step) We have with $(3)$ convegence to a strict positive finite randomvariable $\theta$. What is left to proof, considering, that $\theta$ is regarded as a random variable? Some additional stuffto understand the inequalities $$ P(U_{k_t}<x \sqrt{K_t})\\ \leq P[U_{k_t}<x \sqrt{K_t},K_{t}\in((1-\epsilon) a(t),(1+\epsilon) a(t))]+P[U_{K_t}<x\sqrt{K_t},K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))] \\ \leq P[K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))]+ P[U_{k_t}<x \sqrt{K_t},K_{t}\in((1-\epsilon) a(t),(1+\epsilon) a(t))] \\ \leq P[K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))]  \\ +P(U_{K_{t}}<x\sqrt{(1+ \epsilon)a(t)},|U_{K_t}-U_{a(t)}|\leq m\sqrt{\epsilon a(t)},|U_{K_t}-U_{a(t)}|> m\sqrt{\epsilon a(t)}] \\ \leq P[U_{a(t)}<x\sqrt{(1+\epsilon)a(t)}+m \sqrt{\epsilon a(t)}] + P\left(\sup_{s\in ((1-\epsilon)a(t),(1+\epsilon)a(t))}|U_{s}-U_{a(t)}|>m\cdot \sqrt{\epsilon a(t))}\right)+P\left(K_{t}\notin ((1-\epsilon) a(t),(1+\epsilon) a(t))\right) $$",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'martingales']"
77,"$\lim_{n \to\infty} E(|S_n|)= \infty$ for $(X_n)_{n \geq 1}$ i.i.d. real RV with Var$(X_1)=1, E(X_1)=0$",for  i.i.d. real RV with Var,"\lim_{n \to\infty} E(|S_n|)= \infty (X_n)_{n \geq 1} (X_1)=1, E(X_1)=0","Problem: For $(X_n)_{n \geq 1}$ i.i.d. real RV with Var$(X_1)=1$ and $E(X_1)=0$ and $S_n$ denoting the partial sum of the RVs we have $$\lim_{n \to \infty} E(|S_n|)=\infty $$ My Approach: I have managed to show, thanks to the central limit theorem , that $\exists p >0$ such that for large enough $n \in \mathbb{N}$ (i.e. $n \geq n_0$) we have  \begin{align}P (|S_n| \geq \sqrt{n}) \geq p>0, \ \forall n \geq n_0 \tag{*} \end{align} I do want to use * to conclude the statement. My idea was now to use that for a positive RV $X$ we have  $$E(X)= \int_0^\infty P(X \geq x) dx $$ However I am having trouble to connect this with my result (*) because evidently we have $P(|S_n| \geq \sqrt{n}) \geq P(|S_n| \geq n)$ I can write $$E(|S_n|) = \int_0^\infty P (|S_n| \geq x ) dx = \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq x)dx \\ \geq \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq i) dx = \sum_{i=1}^\infty P(|S_n| \geq i ) $$ I assume that I am on the wrong track. Maybe someone could provide me a hint to get me in the right direction again using (*) to conclude the statement in the problem.","Problem: For $(X_n)_{n \geq 1}$ i.i.d. real RV with Var$(X_1)=1$ and $E(X_1)=0$ and $S_n$ denoting the partial sum of the RVs we have $$\lim_{n \to \infty} E(|S_n|)=\infty $$ My Approach: I have managed to show, thanks to the central limit theorem , that $\exists p >0$ such that for large enough $n \in \mathbb{N}$ (i.e. $n \geq n_0$) we have  \begin{align}P (|S_n| \geq \sqrt{n}) \geq p>0, \ \forall n \geq n_0 \tag{*} \end{align} I do want to use * to conclude the statement. My idea was now to use that for a positive RV $X$ we have  $$E(X)= \int_0^\infty P(X \geq x) dx $$ However I am having trouble to connect this with my result (*) because evidently we have $P(|S_n| \geq \sqrt{n}) \geq P(|S_n| \geq n)$ I can write $$E(|S_n|) = \int_0^\infty P (|S_n| \geq x ) dx = \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq x)dx \\ \geq \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq i) dx = \sum_{i=1}^\infty P(|S_n| \geq i ) $$ I assume that I am on the wrong track. Maybe someone could provide me a hint to get me in the right direction again using (*) to conclude the statement in the problem.",,"['probability', 'probability-theory', 'central-limit-theorem']"
78,Conditional independence if and only factorization applies,Conditional independence if and only factorization applies,,"Murphy, in his Machine Learning: A Probabilistic Perspective , defines two conditionally independent random variables essentially as follows: $X$ and $Y$ are conditionally independent given $Z$, i.e., $X  \perp Y \mid Z$, if and only if $$p(X, Y \mid Z) = p(X \mid Z)p(Y \mid Z)\text{.}$$ where $p$ denotes the (conditional) pmfs/pdfs. (I'm not a fan of the notation, but let's put that aside for now.) One theorem in here is: $X \perp Y \mid Z$ iff there exist functions $g$ and $h$ such that   $$p(x, y \mid z) = g(x, z)h(y,z)$$ for all $x, y, z$ such that $p(z) >  0$. ""$\Longrightarrow$"" is easy to see from the definition. The difficulty with ""$\Longleftarrow$"" is that it's hard to show that $g$ and $h$ are unique, and $g(x,z) = p(X \mid Z)$ and $h(y, z) = p(Y \mid Z)$. At least, I think this is what I need to show. I've tried using $$p(X, Y \mid Z) = \dfrac{p(X, Y, Z)}{p(Z)}$$ but this does not lend itself to clean factoring, as desired in the theorem.","Murphy, in his Machine Learning: A Probabilistic Perspective , defines two conditionally independent random variables essentially as follows: $X$ and $Y$ are conditionally independent given $Z$, i.e., $X  \perp Y \mid Z$, if and only if $$p(X, Y \mid Z) = p(X \mid Z)p(Y \mid Z)\text{.}$$ where $p$ denotes the (conditional) pmfs/pdfs. (I'm not a fan of the notation, but let's put that aside for now.) One theorem in here is: $X \perp Y \mid Z$ iff there exist functions $g$ and $h$ such that   $$p(x, y \mid z) = g(x, z)h(y,z)$$ for all $x, y, z$ such that $p(z) >  0$. ""$\Longrightarrow$"" is easy to see from the definition. The difficulty with ""$\Longleftarrow$"" is that it's hard to show that $g$ and $h$ are unique, and $g(x,z) = p(X \mid Z)$ and $h(y, z) = p(Y \mid Z)$. At least, I think this is what I need to show. I've tried using $$p(X, Y \mid Z) = \dfrac{p(X, Y, Z)}{p(Z)}$$ but this does not lend itself to clean factoring, as desired in the theorem.",,['probability']
79,What happens when $X$ equals its own expected value?,What happens when  equals its own expected value?,X,"Let $X$ denote a random variable with “moments” $M_1:=E(X)$, $M_2:=E(X^2)$, . . . (the first four of which, at least, are assumed to be finite). Show that $M_4+6M_2(M_1)^2\ge 4M_3(M_1)+3(M_1)^4$ Under what circumstances would you get equality? I figured out the first part which is just basically $E((X-E(X))^4)\ge 0$.  But the second part when $E((X-E(X))^4)=0$ I suppose this makes $X-E(X)=0$ and I got $X=E(X)$ which I'm not sure what this means. Does that mean all possible $X$ are the same with the same probability? The answer might be simple but somehow I am confused.","Let $X$ denote a random variable with “moments” $M_1:=E(X)$, $M_2:=E(X^2)$, . . . (the first four of which, at least, are assumed to be finite). Show that $M_4+6M_2(M_1)^2\ge 4M_3(M_1)+3(M_1)^4$ Under what circumstances would you get equality? I figured out the first part which is just basically $E((X-E(X))^4)\ge 0$.  But the second part when $E((X-E(X))^4)=0$ I suppose this makes $X-E(X)=0$ and I got $X=E(X)$ which I'm not sure what this means. Does that mean all possible $X$ are the same with the same probability? The answer might be simple but somehow I am confused.",,['probability']
80,Probability to pick a certain amount of balls of some color,Probability to pick a certain amount of balls of some color,,"Suppose there are 100 balls in a box. 20 balls are blue, 30 balls are green and 50 balls are yellow. Now we randomly pick out 10 balls out of the box (one ball after the other) and we don't put the balls back in the box. What's the probability of picking exactly 2 blue balls, 3 green balls and 5 yellow balls? My wrong attempt of a solution is $(\frac{20}{100} *  \frac{19}{99}) + (\frac{30}{98 }* \frac{29}{97 }* \frac{28}{96}) + (\frac{50}{95 }* \frac{49}{94 }* \frac{48}{93 }* \frac{47}{92 }* \frac{46}{91})$ the correct solution seems to be $(\frac{20}{100} *  \frac{19}{99}) * (\frac{30}{98 }* \frac{29}{97 }* \frac{28}{96}) * (\frac{50}{95 }* \frac{49}{94 }* \frac{48}{93 }* \frac{47}{92 }* \frac{46}{91})  *(\frac{10!}{2!3!5!})$ Thanks for your help fellas!","Suppose there are 100 balls in a box. 20 balls are blue, 30 balls are green and 50 balls are yellow. Now we randomly pick out 10 balls out of the box (one ball after the other) and we don't put the balls back in the box. What's the probability of picking exactly 2 blue balls, 3 green balls and 5 yellow balls? My wrong attempt of a solution is the correct solution seems to be Thanks for your help fellas!",(\frac{20}{100} *  \frac{19}{99}) + (\frac{30}{98 }* \frac{29}{97 }* \frac{28}{96}) + (\frac{50}{95 }* \frac{49}{94 }* \frac{48}{93 }* \frac{47}{92 }* \frac{46}{91}) (\frac{20}{100} *  \frac{19}{99}) * (\frac{30}{98 }* \frac{29}{97 }* \frac{28}{96}) * (\frac{50}{95 }* \frac{49}{94 }* \frac{48}{93 }* \frac{47}{92 }* \frac{46}{91})  *(\frac{10!}{2!3!5!}),['probability']
81,"30 ball bearings, five are defective. Choose 10 probability.","30 ball bearings, five are defective. Choose 10 probability.",,"Could someone confirm my solutions for a combinatorics question? Question: In a group of 30 ball bearings, 5 are defective.  If 10 of the ball   bearings are chosen, what is the probability that: a) None of them are defective? b) Exactly two are defective? Part (a) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. Since only the non-defective ball bearings are chosen, 10 of the 25 non-defective ball bearings are chosen to make up the set, $\dbinom{25}{10}$. Part (a) Answer: $P = \frac{\dbinom{25}{10}}{\dbinom{30}{10}}$ Part (b) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. There are exactly two defective ball bearings in the set of 10 chosen ones; thus, two of the defective ball bearings must be chosen from the set of five, $\dbinom{5}{2}$. Afterwards, additional eight ball bearings must be chosen and they must be non-defective, so they must be chosen from the 25 available non-defective ball bearings, $\dbinom{25}{8}$. Part (b) Answer: $P = \frac{\dbinom{5}{2}\dbinom{25}{8}}{\dbinom{30}{10}}$","Could someone confirm my solutions for a combinatorics question? Question: In a group of 30 ball bearings, 5 are defective.  If 10 of the ball   bearings are chosen, what is the probability that: a) None of them are defective? b) Exactly two are defective? Part (a) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. Since only the non-defective ball bearings are chosen, 10 of the 25 non-defective ball bearings are chosen to make up the set, $\dbinom{25}{10}$. Part (a) Answer: $P = \frac{\dbinom{25}{10}}{\dbinom{30}{10}}$ Part (b) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. There are exactly two defective ball bearings in the set of 10 chosen ones; thus, two of the defective ball bearings must be chosen from the set of five, $\dbinom{5}{2}$. Afterwards, additional eight ball bearings must be chosen and they must be non-defective, so they must be chosen from the 25 available non-defective ball bearings, $\dbinom{25}{8}$. Part (b) Answer: $P = \frac{\dbinom{5}{2}\dbinom{25}{8}}{\dbinom{30}{10}}$",,"['probability', 'combinatorics']"
82,Minimize the probability of getting the same sum of two rolls.,Minimize the probability of getting the same sum of two rolls.,,"If you can design two dice that not necessarily fair and not necessarily weighted in the same manner, then roll twice. How can you minimize the probability of getting the same sum of the two rolls? My thought is since the probability of rolling the same sum of two fair dice is $\dfrac{6^2+2\times(1^2+2^2+3^2+4^2+5^2)}{36^2}$. Our goal is to minimize the numerator by changing the weight of each side of the dice. If we make one die with side $1$ weighted more and the other die with side $6$ weighted more, then we may reduce the probability of getting the same sum. Am I right? I have no idea what's next. Can someone help me please? Thanks.","If you can design two dice that not necessarily fair and not necessarily weighted in the same manner, then roll twice. How can you minimize the probability of getting the same sum of the two rolls? My thought is since the probability of rolling the same sum of two fair dice is $\dfrac{6^2+2\times(1^2+2^2+3^2+4^2+5^2)}{36^2}$. Our goal is to minimize the numerator by changing the weight of each side of the dice. If we make one die with side $1$ weighted more and the other die with side $6$ weighted more, then we may reduce the probability of getting the same sum. Am I right? I have no idea what's next. Can someone help me please? Thanks.",,['probability']
83,Expected number of ordered sub-sequences in a sequence,Expected number of ordered sub-sequences in a sequence,,"Let $S$ be a sequence of integers, of length $n$. Compute the expected value of ordered sub-sequences contained with-in it. Am I correct in assuming, that there is a need for a set $N$, from which the elements of $S$ are picked, in order to be able do draw conclusions about the expected value? Can we make the set $\mathbb{N}$? How does the problem change if we expand our set to $\mathbb{Q}$? How may I go about constructing a distribution, that allows such computations? My attempt, falls short. Let $E_l$ be the event of picking an ordered sequence of length $l$. Let $c_l$ be the last integer chosen. $\mathrm{p(E_{l+1} | E_l)} = \mathrm{p(E_l)}\mathrm{p(\mathbb{1}_{n>c})}$ $\mathrm{p(\mathbb{1}_{n>c})} = 1- \frac{c_l}{|N|}$ $\mathrm{p(E_{l+1} | E_l)} = \mathrm{p(E_l)} - \frac{c_l\mathrm{p(E_l)}}{|N|}$ As the $c_l$ is unknown, I am unable to solve the recurrence. Should I treat it like a random variable as well (similar to how the variance is taken as a random variable in $T$ distribution)? Example: Let $N\subset\mathbb{N}$, and the sequence chosen at random (with repetition) is $S=\{3,2,4,2,4,3,4,5\}$ S contains two ordered sub-sequences, namely $sS_1=\{2,4\}$ , $sS_2=\{2,4\}$, $sS_3=\{3,4,5\}$ The number of ordered sub-sequences is three. Please forgive any non-formalities, I am an amateur exploring his interest.","Let $S$ be a sequence of integers, of length $n$. Compute the expected value of ordered sub-sequences contained with-in it. Am I correct in assuming, that there is a need for a set $N$, from which the elements of $S$ are picked, in order to be able do draw conclusions about the expected value? Can we make the set $\mathbb{N}$? How does the problem change if we expand our set to $\mathbb{Q}$? How may I go about constructing a distribution, that allows such computations? My attempt, falls short. Let $E_l$ be the event of picking an ordered sequence of length $l$. Let $c_l$ be the last integer chosen. $\mathrm{p(E_{l+1} | E_l)} = \mathrm{p(E_l)}\mathrm{p(\mathbb{1}_{n>c})}$ $\mathrm{p(\mathbb{1}_{n>c})} = 1- \frac{c_l}{|N|}$ $\mathrm{p(E_{l+1} | E_l)} = \mathrm{p(E_l)} - \frac{c_l\mathrm{p(E_l)}}{|N|}$ As the $c_l$ is unknown, I am unable to solve the recurrence. Should I treat it like a random variable as well (similar to how the variance is taken as a random variable in $T$ distribution)? Example: Let $N\subset\mathbb{N}$, and the sequence chosen at random (with repetition) is $S=\{3,2,4,2,4,3,4,5\}$ S contains two ordered sub-sequences, namely $sS_1=\{2,4\}$ , $sS_2=\{2,4\}$, $sS_3=\{3,4,5\}$ The number of ordered sub-sequences is three. Please forgive any non-formalities, I am an amateur exploring his interest.",,"['probability', 'probability-theory', 'probability-distributions']"
84,Average area of a random triangle inscribed in a semicircle,Average area of a random triangle inscribed in a semicircle,,"Let's say we have a triangle lying inside a semicircle ($R=1$), two vertices on the diameter ($x= \pm 1,~~y=0$), while the third somewhere on the circle in the first quadrant. It's pretty basic stuff, I just wanted to check if I'm doing this correctly. The area of any such triangle is: $$S=\frac{1}{2} 2R y=y=\sqrt{1-x^2}$$ 1) The distribution of vertex positions is constant in $x$ on $x \in (0,1)$. $$f(x)=1$$ $$<S>=\int_0^1 \sqrt{1-x^2}~ dx=\frac{\pi}{4}$$ 2) The distribution is constant in $y$ on $y \in (0,1)$. $$<S>=\int_0^1 y~ dy=\frac{1}{2}$$ 3) The distribution is constant in polar angle $\phi$ for $\phi \in (0, \pi/2)$. $$f(\phi)=\frac{2}{\pi}$$ $$S=\sin \phi$$ $$<S>=\frac{2}{\pi} \int_0^{\pi/2} \sin \phi~d \phi=\frac{2}{\pi}$$ So am I doing this correct? I wanted to check if my basics are right, before moving on to more complicated probability problems","Let's say we have a triangle lying inside a semicircle ($R=1$), two vertices on the diameter ($x= \pm 1,~~y=0$), while the third somewhere on the circle in the first quadrant. It's pretty basic stuff, I just wanted to check if I'm doing this correctly. The area of any such triangle is: $$S=\frac{1}{2} 2R y=y=\sqrt{1-x^2}$$ 1) The distribution of vertex positions is constant in $x$ on $x \in (0,1)$. $$f(x)=1$$ $$<S>=\int_0^1 \sqrt{1-x^2}~ dx=\frac{\pi}{4}$$ 2) The distribution is constant in $y$ on $y \in (0,1)$. $$<S>=\int_0^1 y~ dy=\frac{1}{2}$$ 3) The distribution is constant in polar angle $\phi$ for $\phi \in (0, \pi/2)$. $$f(\phi)=\frac{2}{\pi}$$ $$S=\sin \phi$$ $$<S>=\frac{2}{\pi} \int_0^{\pi/2} \sin \phi~d \phi=\frac{2}{\pi}$$ So am I doing this correct? I wanted to check if my basics are right, before moving on to more complicated probability problems",,"['probability', 'geometry', 'geometric-probability']"
85,$X<Y$ a.s. but $\mathrm{AV@R}_\alpha[X] = \mathrm{AV@R}_\alpha[Y]$,a.s. but,X<Y \mathrm{AV@R}_\alpha[X] = \mathrm{AV@R}_\alpha[Y],"$\newcommand{\avar}{\mathrm{AV@R}_{\alpha}} \renewcommand{\Re}{\mathbb{R}}$Let $(\Omega, \mathscr{F}, \mathrm{P})$ be a probability space and define $\mathcal{Z}:=\mathcal{L}_p(\Omega, \mathscr{F}, \mathrm{P})$ for some $p\in [1,\infty)$. The average value-at-risk of a $X\in\mathcal{Z}$ - often referred to as expected shotfall or conditional value-at-risk is defined as $$ \avar[X] := \inf_{t\in\Re}\{t+\alpha^{-1}\mathbb{E}[(X-t)_+]\}, $$ where $\mathbb{E}$ is the expectation operator and $(\cdot)_+$ is defined as $(Z)_+=\max\{0, Z\}$. There are a few other useful formulae. For example $$ \avar[X] = \mathbb{E}[X\mid X\geq \Phi_X^{-1}(1-\alpha)], $$ where $\Phi_X^{-1}$ is the inverse cumulative distribution function of $X$, and, the dual representation $$ \avar[X] = \sup_{\zeta\in\mathfrak{A}}\langle \zeta, X\rangle $$ where $\langle \zeta, X\rangle:=\int_{\Omega}\zeta X \mathrm{dP}$ and $\mathfrak{A}:=\left\{\zeta\in \mathcal{L}_q(\Omega,\mathscr{F},\mathrm{P}) \mid \mathbb{E}[\zeta]=1, \zeta\in[0,\alpha^{-1}]\ \text{a.s.}\right\}$. Given that $X\leq Y$ almost surely we know that $\avar[X]\leq \avar[Y]$ by the monotonicity property of $\mathrm{AV@R}[\cdot]$. However, I I believe it is not true that $\avar[X]< \avar[Y]$ whenever $X<Y$ (a.s.). My question. I suspect that this assertion is false, but I would like to find a counterexample. My guess. If we take $X<Y$ (a.s.) then, since all $\zeta\in\mathfrak{A}$ are nonnegative (a.s.), we have $\langle \zeta, X\rangle \leq \langle \zeta, Y\rangle $ from which we can infer $\avar[X]\leq \avar[Y]$, but not $\avar[X]<\avar[Y]$. Intuition. In order to acquire some intuition about this problem, I create the figure below. The CDFs of the two variables don't have the same shape, they have different value-at-risk values, but the same average value-at-risk, it is $X<Y$. The CDF of $X$ after its value-at-risk moves faster to $1$ and as a result its average value-at-risk is further away from its value-at-risk. On the other hand, the CDF of $Y$ exhibits a more sluggish ascend and the two AV@Rs coincide.","$\newcommand{\avar}{\mathrm{AV@R}_{\alpha}} \renewcommand{\Re}{\mathbb{R}}$Let $(\Omega, \mathscr{F}, \mathrm{P})$ be a probability space and define $\mathcal{Z}:=\mathcal{L}_p(\Omega, \mathscr{F}, \mathrm{P})$ for some $p\in [1,\infty)$. The average value-at-risk of a $X\in\mathcal{Z}$ - often referred to as expected shotfall or conditional value-at-risk is defined as $$ \avar[X] := \inf_{t\in\Re}\{t+\alpha^{-1}\mathbb{E}[(X-t)_+]\}, $$ where $\mathbb{E}$ is the expectation operator and $(\cdot)_+$ is defined as $(Z)_+=\max\{0, Z\}$. There are a few other useful formulae. For example $$ \avar[X] = \mathbb{E}[X\mid X\geq \Phi_X^{-1}(1-\alpha)], $$ where $\Phi_X^{-1}$ is the inverse cumulative distribution function of $X$, and, the dual representation $$ \avar[X] = \sup_{\zeta\in\mathfrak{A}}\langle \zeta, X\rangle $$ where $\langle \zeta, X\rangle:=\int_{\Omega}\zeta X \mathrm{dP}$ and $\mathfrak{A}:=\left\{\zeta\in \mathcal{L}_q(\Omega,\mathscr{F},\mathrm{P}) \mid \mathbb{E}[\zeta]=1, \zeta\in[0,\alpha^{-1}]\ \text{a.s.}\right\}$. Given that $X\leq Y$ almost surely we know that $\avar[X]\leq \avar[Y]$ by the monotonicity property of $\mathrm{AV@R}[\cdot]$. However, I I believe it is not true that $\avar[X]< \avar[Y]$ whenever $X<Y$ (a.s.). My question. I suspect that this assertion is false, but I would like to find a counterexample. My guess. If we take $X<Y$ (a.s.) then, since all $\zeta\in\mathfrak{A}$ are nonnegative (a.s.), we have $\langle \zeta, X\rangle \leq \langle \zeta, Y\rangle $ from which we can infer $\avar[X]\leq \avar[Y]$, but not $\avar[X]<\avar[Y]$. Intuition. In order to acquire some intuition about this problem, I create the figure below. The CDFs of the two variables don't have the same shape, they have different value-at-risk values, but the same average value-at-risk, it is $X<Y$. The CDF of $X$ after its value-at-risk moves faster to $1$ and as a result its average value-at-risk is further away from its value-at-risk. On the other hand, the CDF of $Y$ exhibits a more sluggish ascend and the two AV@Rs coincide.",,"['probability', 'measure-theory', 'risk-assessment']"
86,Probability of winning dice roll-off with a re-roll,Probability of winning dice roll-off with a re-roll,,"I am looking to find the probability of winning a basic dice roll-off using a 6 sided die if one of the players can re-roll their die.  The main thing that is throwing me off is that player 2 can re-roll the die but doesn't have to, and if the first roll or the re-roll equals player 1's roll then the process restarts. Example 1: Player 1 - Rolls a 2 Player 2 - Rolls a 4 (win) Example 2:  Player 1 - Rolls a 2 Player 2 - Rolls a 1, re-rolls and gets a 5 (win) Example 3:  Player 1 - Rolls a 5 Player 2 - Rolls a 5 At this point player 2 can call it a tie and start fresh, or use his re-roll to attempt and roll a 6, although this doesn't seem to be his best option to win. Example 4:  Player 1 - Rolls a 4 Player 2 - Rolls a 4 At this point player 2 decides to call it a tie, and then they both re-roll.  Player 2 still has the ability to then re-roll his result in this round. Player 1 - Rolls a 3 Player 2 - Rolls a 2, re-rolls and gets a 1 (loss)","I am looking to find the probability of winning a basic dice roll-off using a 6 sided die if one of the players can re-roll their die.  The main thing that is throwing me off is that player 2 can re-roll the die but doesn't have to, and if the first roll or the re-roll equals player 1's roll then the process restarts. Example 1: Player 1 - Rolls a 2 Player 2 - Rolls a 4 (win) Example 2:  Player 1 - Rolls a 2 Player 2 - Rolls a 1, re-rolls and gets a 5 (win) Example 3:  Player 1 - Rolls a 5 Player 2 - Rolls a 5 At this point player 2 can call it a tie and start fresh, or use his re-roll to attempt and roll a 6, although this doesn't seem to be his best option to win. Example 4:  Player 1 - Rolls a 4 Player 2 - Rolls a 4 At this point player 2 decides to call it a tie, and then they both re-roll.  Player 2 still has the ability to then re-roll his result in this round. Player 1 - Rolls a 3 Player 2 - Rolls a 2, re-rolls and gets a 1 (loss)",,"['probability', 'dice']"
87,Consecutive strings of heads problem,Consecutive strings of heads problem,,"So the question asks: We toss a fair coin $n$ times and record the outcome as a sequence of H and T. We say that there is a run of heads if there is a consecutive string H...H which starts either at the first toss or after the coin lands tails and which ends either at the last toss or before the coin lands tails. For example, the sequence HTHHTHHHHTTHH has four runs of heads. Find the expected number of runs of heads. So far I have: Suppose the probability that all $K$ tosses have the same type of toss equal to the probability of all heads in $K$ tosses + probability of all tails in $K$ tosses. Sets of subsequent $K$ tosses $=(n-k+1)$ Expected number of runs of heads equals the number of subsequent $K$ tosses times the probability that one set of $K$ tosses is a streak $= (n-k+1)\times 2\times (1/2)^k$ But I am really not sure about my solution, is this the right way to do this kind of probability problem?","So the question asks: We toss a fair coin $n$ times and record the outcome as a sequence of H and T. We say that there is a run of heads if there is a consecutive string H...H which starts either at the first toss or after the coin lands tails and which ends either at the last toss or before the coin lands tails. For example, the sequence HTHHTHHHHTTHH has four runs of heads. Find the expected number of runs of heads. So far I have: Suppose the probability that all $K$ tosses have the same type of toss equal to the probability of all heads in $K$ tosses + probability of all tails in $K$ tosses. Sets of subsequent $K$ tosses $=(n-k+1)$ Expected number of runs of heads equals the number of subsequent $K$ tosses times the probability that one set of $K$ tosses is a streak $= (n-k+1)\times 2\times (1/2)^k$ But I am really not sure about my solution, is this the right way to do this kind of probability problem?",,['probability']
88,How to compute the $p$ value? and the correct explanation of the overall experiment.(Is my answer correct?),How to compute the  value? and the correct explanation of the overall experiment.(Is my answer correct?),p,"Hello community first of all thanks for helping me with my math problems. Here I'm again with hypothesis  test exercise. I want to know if I made some mistake in my answer and if someone can help me to calculate the value $p$ for the problem, (I'm not sure how to do it). Thank you so much! Problem statement: Karl conducted an experiment to study whether honey bees have color vision. He trained bees to feed on a dish of sugar water that was set on a colored card. Later he set the colored card (without the sugar water) onto an array of four cards colored in grey. The experiment was repeated with the colored tile in different positions on the array. Of $27$ incoming bees who landed on a tile, twelve landed first on the colored tile. i) Define the population and sample involved in this experiment. Explain how this experiment can be used to test whether bees have color vision. ii) Define a parameter of interest and state a null hypothesis and alternative hypothesis involving this parameter. Hint: If bees could not see in color, what proportion of incoming bees would you expect to first land on the blue card? If you are using symbols, define what they represent. iii) Conduct a statistical hypothesis test to answer the question whether bees can see in color (at significance level $\alpha= 0.05$). Report the $p$-value of your test together with a conclusion sentence. Show your work. My work: i) Because the bees are incentives with (I suppose $4$ dish with water) and the one with sugar was blue, then Karl must to change the position of the blue dish for making sure the bees don’t use their memory if they have it. After some time, he can take away the water and leave the blue card, with the others gray cards, knowing the proportion of the bees landed in the blue card, compared with the others gray cards. He can inferred that bees can distinguises blue over gray, because the only difference among the cards are the color, and no other sense is involve he can conclude bees are not color blind. Population: All honeybees fed with the dish of sugar water that was set on the colored card varying the position. Sample: $27$ incoming honeybees fed with the dish of sugar water that was set on the colored card, which landed on a tile. ii) Parameter of interest: proportion of bees that land first in the blue tail $\mathbf{H_0:}$ The proportion of bees land first in a blue tail is equal to the proportion of bees landed first in other card. That means that bees are color blind (Extra: also it is possible they has no memory at all, that why he change position to discard such possibility) $\mathbf{H_a:}$ If the proportion of bees that first landed in blue car is greater than the bees landed first in other card then bees aren’t color blind. It can differentiate blue color from others (at least one more color). iii) $P=12/27$ (bees land first in blue card) $Q=1-12/27$ (in other card in the example 3) Sample size $=27$ Significance level $= 0.05$ Because is a small sample I use $t$ distribution. df $=27-1$  $\alpha=0.025/2$ Test statistic $=  p \pm t\sqrt{pq/n}$ Questions: Part i It is correct my answer? If not what or where is my mistakes. Part ii It is correct my answer? If not what or where is my mistakes. Part iii 1) How to compute the $p$ value, in this case? I need help in this part. 2) My answer for part iii. second question , if I know $p$, then if the $p$ value is smaller than the significance level of $0.05$ then I reject $H_0$ and I  accept $H_a$, honey bees can see blue color.","Hello community first of all thanks for helping me with my math problems. Here I'm again with hypothesis  test exercise. I want to know if I made some mistake in my answer and if someone can help me to calculate the value $p$ for the problem, (I'm not sure how to do it). Thank you so much! Problem statement: Karl conducted an experiment to study whether honey bees have color vision. He trained bees to feed on a dish of sugar water that was set on a colored card. Later he set the colored card (without the sugar water) onto an array of four cards colored in grey. The experiment was repeated with the colored tile in different positions on the array. Of $27$ incoming bees who landed on a tile, twelve landed first on the colored tile. i) Define the population and sample involved in this experiment. Explain how this experiment can be used to test whether bees have color vision. ii) Define a parameter of interest and state a null hypothesis and alternative hypothesis involving this parameter. Hint: If bees could not see in color, what proportion of incoming bees would you expect to first land on the blue card? If you are using symbols, define what they represent. iii) Conduct a statistical hypothesis test to answer the question whether bees can see in color (at significance level $\alpha= 0.05$). Report the $p$-value of your test together with a conclusion sentence. Show your work. My work: i) Because the bees are incentives with (I suppose $4$ dish with water) and the one with sugar was blue, then Karl must to change the position of the blue dish for making sure the bees don’t use their memory if they have it. After some time, he can take away the water and leave the blue card, with the others gray cards, knowing the proportion of the bees landed in the blue card, compared with the others gray cards. He can inferred that bees can distinguises blue over gray, because the only difference among the cards are the color, and no other sense is involve he can conclude bees are not color blind. Population: All honeybees fed with the dish of sugar water that was set on the colored card varying the position. Sample: $27$ incoming honeybees fed with the dish of sugar water that was set on the colored card, which landed on a tile. ii) Parameter of interest: proportion of bees that land first in the blue tail $\mathbf{H_0:}$ The proportion of bees land first in a blue tail is equal to the proportion of bees landed first in other card. That means that bees are color blind (Extra: also it is possible they has no memory at all, that why he change position to discard such possibility) $\mathbf{H_a:}$ If the proportion of bees that first landed in blue car is greater than the bees landed first in other card then bees aren’t color blind. It can differentiate blue color from others (at least one more color). iii) $P=12/27$ (bees land first in blue card) $Q=1-12/27$ (in other card in the example 3) Sample size $=27$ Significance level $= 0.05$ Because is a small sample I use $t$ distribution. df $=27-1$  $\alpha=0.025/2$ Test statistic $=  p \pm t\sqrt{pq/n}$ Questions: Part i It is correct my answer? If not what or where is my mistakes. Part ii It is correct my answer? If not what or where is my mistakes. Part iii 1) How to compute the $p$ value, in this case? I need help in this part. 2) My answer for part iii. second question , if I know $p$, then if the $p$ value is smaller than the significance level of $0.05$ then I reject $H_0$ and I  accept $H_a$, honey bees can see blue color.",,"['probability', 'statistics', 'statistical-inference', 'hypothesis-testing', 'descriptive-statistics']"
89,markov chain: 2 state chain,markov chain: 2 state chain,,"I have a machine. It has two states, broken or working.  If it is working, then it will be broken with probability $q=0.1$. If the machine is working, I will make \$1000 dollar a day. If it is broken, then repairman will charge charge me \$ $200/(1-p) $ a day to repair. He will fix the machine with probability p. Assume the transition from broken to working (and wise versa) is independent. Find p that maximize the expected profit. Attempt: 2 state markov chain. Let state 0 be working, and let state 1 be broken. The state transition matrix is: \begin{pmatrix}   1-q & q \\     p & 1-p  \\  \end{pmatrix} The steady state distribution is calculated by (omit showing my calculation process here since it is well-known) : $\pi_0=q/(p+q),  \pi_1=p/(p+q)$ The expected profit is: $1000*\pi_0-200/(1-p)*\pi_1$.  (Do you think this is correct)?","I have a machine. It has two states, broken or working.  If it is working, then it will be broken with probability $q=0.1$. If the machine is working, I will make \$1000 dollar a day. If it is broken, then repairman will charge charge me \$ $200/(1-p) $ a day to repair. He will fix the machine with probability p. Assume the transition from broken to working (and wise versa) is independent. Find p that maximize the expected profit. Attempt: 2 state markov chain. Let state 0 be working, and let state 1 be broken. The state transition matrix is: \begin{pmatrix}   1-q & q \\     p & 1-p  \\  \end{pmatrix} The steady state distribution is calculated by (omit showing my calculation process here since it is well-known) : $\pi_0=q/(p+q),  \pi_1=p/(p+q)$ The expected profit is: $1000*\pi_0-200/(1-p)*\pi_1$.  (Do you think this is correct)?",,"['probability', 'probability-distributions', 'markov-chains', 'markov-process']"
90,What is the probability that nobody receives the same ranking twice?,What is the probability that nobody receives the same ranking twice?,,"Four players compete in a tournament and are ranked $1$ to $4$. They then compete in another tournament and are again ranked from $1$ to $4$. Suppose that their performances in the second tournament, so that the two sets of rankings are independent.   What is the probability that nobody receives the same ranking twice? One way to do it: Let the notation $(2,3,1,4)$ represent the result that the player who finished 1st in tournament 1 finished 2nd in tournament 2, the player who finished 2nd in tournament 1 finished 3rd in tournament 2, the player who finished 3rd in tournament 1 finished 1st in tournament 2, and the player who finished 4th in tournament 1 finished 4th in tournament 2. Total outcomes= $4! = 24$ The results where no player receives the same ranking in the two tournaments are: $$(2,1,4,3), (2,3,4,1), (2,4,1,3), (3,1,4,2), (3,4,1,2) (3,4,2,1), (4,1,2,3), (4,3,1,2),(4,3,2,1)$$ There are nine of these results and so the required probability is $9/24 = 3/8$ If anyone could give me another way of doing this question to give me an intuition into whats going on behind the numbers, it would help a lot. Thank you!","Four players compete in a tournament and are ranked $1$ to $4$. They then compete in another tournament and are again ranked from $1$ to $4$. Suppose that their performances in the second tournament, so that the two sets of rankings are independent.   What is the probability that nobody receives the same ranking twice? One way to do it: Let the notation $(2,3,1,4)$ represent the result that the player who finished 1st in tournament 1 finished 2nd in tournament 2, the player who finished 2nd in tournament 1 finished 3rd in tournament 2, the player who finished 3rd in tournament 1 finished 1st in tournament 2, and the player who finished 4th in tournament 1 finished 4th in tournament 2. Total outcomes= $4! = 24$ The results where no player receives the same ranking in the two tournaments are: $$(2,1,4,3), (2,3,4,1), (2,4,1,3), (3,1,4,2), (3,4,1,2) (3,4,2,1), (4,1,2,3), (4,3,1,2),(4,3,2,1)$$ There are nine of these results and so the required probability is $9/24 = 3/8$ If anyone could give me another way of doing this question to give me an intuition into whats going on behind the numbers, it would help a lot. Thank you!",,"['probability', 'permutations', 'combinations']"
91,From marginal distribution to joint distribution,From marginal distribution to joint distribution,,"Consider two sequences of real-valued random variables, $\{X_n\}_n$ and $\{T_n\}_n$. Let $\rightarrow_d$ denote convergence in distribution. Assume (1) $X_n\rightarrow_d L$ as $n\rightarrow \infty$, where $L$ is a random variable (2) $T_n\rightarrow_d \Delta$  as $n\rightarrow \infty$, where $\Delta\sim N(0,1)$ Statement : there exists a subsequence $\{ X_{n_j}, T_{n_j}\}_j$ such that $(X_{n_j}, T_{n_j})\rightarrow_d(L,\Delta)$ as $j\rightarrow \infty$, where $S$ is a a random variable. [the statement is used in the proof of Theorem 7.10 page 98 of van der Vaart ""Asymptotic Statistics""] Question : could you help me to show the statement? Attempt : I understand that (i) (1) implies $X_n=O_P(1)$ (ii) (2) implies $T_n=O_P(1)$ (iii) (i)+(ii) implies $(T_n,X_n)=O_P(1)$ (iv) (iii) implies that there exists a subsequence $\{ X_{n_j}, T_{n_j}\}_j$ such that $(X_{n_j}, T_{n_j})\rightarrow_d(S,M)$ as $j\rightarrow \infty$, where $M$ is a a random variable (Prohorov's Theorem). (v) Hence, $S\sim L$ and $M\sim \Delta$ (vi) Why $(S,M)\sim (L,\Delta)$?","Consider two sequences of real-valued random variables, $\{X_n\}_n$ and $\{T_n\}_n$. Let $\rightarrow_d$ denote convergence in distribution. Assume (1) $X_n\rightarrow_d L$ as $n\rightarrow \infty$, where $L$ is a random variable (2) $T_n\rightarrow_d \Delta$  as $n\rightarrow \infty$, where $\Delta\sim N(0,1)$ Statement : there exists a subsequence $\{ X_{n_j}, T_{n_j}\}_j$ such that $(X_{n_j}, T_{n_j})\rightarrow_d(L,\Delta)$ as $j\rightarrow \infty$, where $S$ is a a random variable. [the statement is used in the proof of Theorem 7.10 page 98 of van der Vaart ""Asymptotic Statistics""] Question : could you help me to show the statement? Attempt : I understand that (i) (1) implies $X_n=O_P(1)$ (ii) (2) implies $T_n=O_P(1)$ (iii) (i)+(ii) implies $(T_n,X_n)=O_P(1)$ (iv) (iii) implies that there exists a subsequence $\{ X_{n_j}, T_{n_j}\}_j$ such that $(X_{n_j}, T_{n_j})\rightarrow_d(S,M)$ as $j\rightarrow \infty$, where $M$ is a a random variable (Prohorov's Theorem). (v) Hence, $S\sim L$ and $M\sim \Delta$ (vi) Why $(S,M)\sim (L,\Delta)$?",,"['probability', 'probability-distributions', 'proof-verification']"
92,The distribution of the x-coordinate on unit circle,The distribution of the x-coordinate on unit circle,,"I'm trying to determine the distribution of the x-coordinate (uniformly distributed) on the unit circle (density function). I've seen some threads on this, such as this , where they use the method of the marginal density. I'm wondering why one can't simply use the formula for the density function for a uniformly distributed function  $$\frac{1}{b-a}$$ for $x \in \mathrm{[a,b]}$, which would give the result $\frac{1}{1-(-1)} = \frac{1}{2}?$","I'm trying to determine the distribution of the x-coordinate (uniformly distributed) on the unit circle (density function). I've seen some threads on this, such as this , where they use the method of the marginal density. I'm wondering why one can't simply use the formula for the density function for a uniformly distributed function  $$\frac{1}{b-a}$$ for $x \in \mathrm{[a,b]}$, which would give the result $\frac{1}{1-(-1)} = \frac{1}{2}?$",,"['probability', 'statistics', 'probability-distributions', 'uniform-distribution']"
93,General equation for the change of variable (random variables' functions),General equation for the change of variable (random variables' functions),,"I have learned that for monotonic functions, one can obtain the formula for the pdf of a random variable, by using the following: $$f_Y(y) = \left| \frac{dx}{dy}\right|f_X(x)$$ where $x$ is $g^{-1}(y)$ and $Y=g(X)$ Then I have the following in my notes: ""the most general equation for change of variables (includes non-monotonic functions)"": $$f_Y(y) = \int_{-\infty}^{+\infty}\delta (g(x)-y)f_X(x)dx$$ I am not quite sure where that formula comes from, and why it holds. And how would I evaluate it... Do you have some examples perhaps? I don't know how I would evaluate that integral. I know that: $$\int_{-\infty}^{+\infty}\delta (x-x_0) dx=1$$ and that $$\int_{-\infty}^{+\infty}g(x) \delta(x-x_0) dx=g(x_0)$$","I have learned that for monotonic functions, one can obtain the formula for the pdf of a random variable, by using the following: $$f_Y(y) = \left| \frac{dx}{dy}\right|f_X(x)$$ where $x$ is $g^{-1}(y)$ and $Y=g(X)$ Then I have the following in my notes: ""the most general equation for change of variables (includes non-monotonic functions)"": $$f_Y(y) = \int_{-\infty}^{+\infty}\delta (g(x)-y)f_X(x)dx$$ I am not quite sure where that formula comes from, and why it holds. And how would I evaluate it... Do you have some examples perhaps? I don't know how I would evaluate that integral. I know that: $$\int_{-\infty}^{+\infty}\delta (x-x_0) dx=1$$ and that $$\int_{-\infty}^{+\infty}g(x) \delta(x-x_0) dx=g(x_0)$$",,"['probability', 'probability-distributions', 'dirac-delta']"
94,Probability problem: length of new segments,Probability problem: length of new segments,,"I have a line of length $l$. I divide the line in $n$ segments. I do this by choosing $n - 1$ random points (I mean that the $n - 1$ points are uniformly distributed from $0$ to $l$). I want to add a new random point. If this new point does not coincide with an old one, it will ""destroy"" an old segment and create two new segments: 4 points, 5 segments: ----------|---------|---------------|-----|-------  1 new point, 6 segments: ----------|---------|---|-----------|-----|-------                         ^ The question I'm trying to answer is: how long are these two new segments on average? From the construction method, I think that the answer is $l / (n + 1)$ (that is, the length over the new number of segments). However I'm not sure for two reasons: I can't find a way to prove it; $l / (n + 1)$ is the average length of all segments, but I'm interested only in the new ones. Could you shed some light on this?","I have a line of length $l$. I divide the line in $n$ segments. I do this by choosing $n - 1$ random points (I mean that the $n - 1$ points are uniformly distributed from $0$ to $l$). I want to add a new random point. If this new point does not coincide with an old one, it will ""destroy"" an old segment and create two new segments: 4 points, 5 segments: ----------|---------|---------------|-----|-------  1 new point, 6 segments: ----------|---------|---|-----------|-----|-------                         ^ The question I'm trying to answer is: how long are these two new segments on average? From the construction method, I think that the answer is $l / (n + 1)$ (that is, the length over the new number of segments). However I'm not sure for two reasons: I can't find a way to prove it; $l / (n + 1)$ is the average length of all segments, but I'm interested only in the new ones. Could you shed some light on this?",,"['probability', 'uniform-distribution']"
95,Calculate the discrete probability density of $Z=XY$,Calculate the discrete probability density of,Z=XY,"$X$ and $Y$ are independent aleatory variables. $X$ : Poisson with 1 such as parameter $Y$ : Bernoulli with $\frac{1}{2}$ such as parameter Calculate the discrete probability density of  $Z=XY$ $$P(Z=0)=P(\{X=0\} \cup \{Y=0\})= \\=P(X=0)+P(Y=0)-P(X=0, Y=0)=\frac{1}{e}+\frac{1}{2}-\frac{1}{2e}=\frac{e+1}{2e} \\ \\  \forall n \in \mathbb{N^*}, P(Z=n)=P(X=n, Y=1)=\frac{1}{2 \ e \ n!}  $$ Is it correct?","$X$ and $Y$ are independent aleatory variables. $X$ : Poisson with 1 such as parameter $Y$ : Bernoulli with $\frac{1}{2}$ such as parameter Calculate the discrete probability density of  $Z=XY$ $$P(Z=0)=P(\{X=0\} \cup \{Y=0\})= \\=P(X=0)+P(Y=0)-P(X=0, Y=0)=\frac{1}{e}+\frac{1}{2}-\frac{1}{2e}=\frac{e+1}{2e} \\ \\  \forall n \in \mathbb{N^*}, P(Z=n)=P(X=n, Y=1)=\frac{1}{2 \ e \ n!}  $$ Is it correct?",,['probability']
96,Swapping the $i$th largest card between $2$ hands of cards,Swapping the th largest card between  hands of cards,i 2,"Introduction to ""game"" There are $2$ players and $2n$ cards, labelled $1, 1, 2, 2, 3, 3, 4, 4, \dots, n, n$. ($2$ of each card from $1$ to $n$) Firstly, the $2n$ players are each given $n$ cards randomly. More specifically, a random ordering of the $2n$ cards is achieved and the first player gets the first $n$ cards, the second player gets the other $n$ cards. We can assume each player can see all the cards. On every turn, each player will sort his hand of cards. Label the cards in the hands $a_1, a_2, a_3,\dots, a_n, b_1, b_2, b_3,\dots, b_n$. The players find a pair of cards $a_i\neq b_i$. Then they exchange the cards $a_i$ and $b_i$. After which, the turn ends. Clearly if $a_i=b_i$ for all $i$, then $a_i=b_i=i$, and the ""game"" terminates. Example Let $n=4$. We call the $2$ players $A, B$. At the start of the game, they receive: $A: 1, 1, 2, 2$ $B: 3, 3, 4, 4$ Turn 1: They decide to swap the first card. $A: \color{red}{3}, 1, 2, 2$ $B: \color{red}{1}, 3, 4, 4$ Before the second turn starts, they sort their cards. $A: 1, 2, 2, 3$ $B: 1, 3, 4, 4$ Turn 2: This time, they decide to swap the third card. They cannot swap the first card as the numbers on the first card are the same. $A: 1, 2, \color{red}{4}, 3$ $B: 1, 3, \color{red}{2}, 4$ They sort their cards. $A: 1, 2, 3, 4$ $B: 1, 2, 3, 4$ The ""game"" ends as the players both have $1, 2, 3, 4$. This game ends in $2$ turns. Questions about this ""game"" Will it terminate? (The answer is yes, and an idea of a bound based on the monovariant will be added as a self-answer.) In how many moves (at most) does it take for a $2n$ card game to terminate? What arrangements will cause it to take such a long time to terminate? Assuming that the players pick the next card to exchange randomly (among all the possible moves, choose a valid move, each valid move with equal probability), what is the expected number of moves for the game to terminate? Ideas about the question: As suggested by hardmath: If we constrain the players to take the lowest card that works or the highest card that works, the game will definitely end in at most $n-1$ turns. Both cases are symmetrical, so we work on highest. Base case: if $n=1$, no moves have to be done. Otherwise, $n>1$. We now proceed on the inductive step. Suppose the highest cards of the players are different. If they are the same, we delete them, reducing to the $n-1$ case, which can be done in at most $n-2$ moves. Otherwise, one player has both the highest card. When the move is done, a copy of the highest card is given to the other player. Now, both players have the highest card, and it can be deleted. In total, there are $1+(n-2)=n-1$ moves for this. From this, we can obtain that on average, the game ends in $O(n^2)$ turns, as it takes (on average) $O(n)$ turns for the highest card to be swapped. Code (for reference): I ran a Monte Carlo simulation of random games. A simulation of $1000$ games of $1000$ cards gave an average number of swaps of $1310.703$. C++ code for reference: #include <cstdio> #include <algorithm> #include <cmath> using namespace std; int N; int K; int maxCounter = 0; int sumCounter = 0; int counter; int arr[999999]; /** Results: (X cards, 10^6 rounds) 1 -> 0 0 2 -> 1 0.334546 (guess: 1/3) 3 -> 2 0.733746 4 -> 3 1.180559 5 -> 5 1.667006 (guess: 5/3) 6 -> 6 2.179321 7 -> 8 2.721661 8 -> 9 3.283566 9 -> 10 3.867299 10 -> 12 4.471352 Other things I tried: (cards, rounds) 100 1000 -> 143 84.411 200 1000 -> 307 197.332 300 1000 -> 503 319.691 500 1000 -> 960 580.373 1000 1000 -> 1910 1310.703 **/ int main(void) {     srand(23);     printf(""Number of cards: "");     scanf(""%d"", &N);     for (int i=0;i<N;i++) {         arr[i] = arr[i+N] = i;     }     printf(""Number of rounds: "");     scanf(""%d"", &K);     for (int j=0;j<K;j++) {         random_shuffle(arr, arr+2*N);         counter = 0;         while (counter>=0) {             sort(arr, arr+N);             sort(arr+N, arr+2*N);             int pass = 1;             for (int i=0;i<N;i++) {                 if (arr[i] != arr[i+N]) {                     pass = 0;                     break;                 }             }             if (pass) break;             counter++;             int theMove = rand()%N;             while (arr[theMove] == arr[theMove+N]) theMove = rand()%N;             int temp = arr[theMove];             arr[theMove] = arr[theMove+N];             arr[theMove+N] = temp;         }         //printf(""%d "", counter);         maxCounter = max(maxCounter, counter);         sumCounter += counter;         if (j%(K/100) == 0) printf(""Done: %d\n"", j);     }     printf(""Maximum: %d\nAverage: %lf\n"", maxCounter, sumCounter/(double)K);     return 0; } Results of the code: The average number of moves appear to grow faster than $O(n)$.","Introduction to ""game"" There are $2$ players and $2n$ cards, labelled $1, 1, 2, 2, 3, 3, 4, 4, \dots, n, n$. ($2$ of each card from $1$ to $n$) Firstly, the $2n$ players are each given $n$ cards randomly. More specifically, a random ordering of the $2n$ cards is achieved and the first player gets the first $n$ cards, the second player gets the other $n$ cards. We can assume each player can see all the cards. On every turn, each player will sort his hand of cards. Label the cards in the hands $a_1, a_2, a_3,\dots, a_n, b_1, b_2, b_3,\dots, b_n$. The players find a pair of cards $a_i\neq b_i$. Then they exchange the cards $a_i$ and $b_i$. After which, the turn ends. Clearly if $a_i=b_i$ for all $i$, then $a_i=b_i=i$, and the ""game"" terminates. Example Let $n=4$. We call the $2$ players $A, B$. At the start of the game, they receive: $A: 1, 1, 2, 2$ $B: 3, 3, 4, 4$ Turn 1: They decide to swap the first card. $A: \color{red}{3}, 1, 2, 2$ $B: \color{red}{1}, 3, 4, 4$ Before the second turn starts, they sort their cards. $A: 1, 2, 2, 3$ $B: 1, 3, 4, 4$ Turn 2: This time, they decide to swap the third card. They cannot swap the first card as the numbers on the first card are the same. $A: 1, 2, \color{red}{4}, 3$ $B: 1, 3, \color{red}{2}, 4$ They sort their cards. $A: 1, 2, 3, 4$ $B: 1, 2, 3, 4$ The ""game"" ends as the players both have $1, 2, 3, 4$. This game ends in $2$ turns. Questions about this ""game"" Will it terminate? (The answer is yes, and an idea of a bound based on the monovariant will be added as a self-answer.) In how many moves (at most) does it take for a $2n$ card game to terminate? What arrangements will cause it to take such a long time to terminate? Assuming that the players pick the next card to exchange randomly (among all the possible moves, choose a valid move, each valid move with equal probability), what is the expected number of moves for the game to terminate? Ideas about the question: As suggested by hardmath: If we constrain the players to take the lowest card that works or the highest card that works, the game will definitely end in at most $n-1$ turns. Both cases are symmetrical, so we work on highest. Base case: if $n=1$, no moves have to be done. Otherwise, $n>1$. We now proceed on the inductive step. Suppose the highest cards of the players are different. If they are the same, we delete them, reducing to the $n-1$ case, which can be done in at most $n-2$ moves. Otherwise, one player has both the highest card. When the move is done, a copy of the highest card is given to the other player. Now, both players have the highest card, and it can be deleted. In total, there are $1+(n-2)=n-1$ moves for this. From this, we can obtain that on average, the game ends in $O(n^2)$ turns, as it takes (on average) $O(n)$ turns for the highest card to be swapped. Code (for reference): I ran a Monte Carlo simulation of random games. A simulation of $1000$ games of $1000$ cards gave an average number of swaps of $1310.703$. C++ code for reference: #include <cstdio> #include <algorithm> #include <cmath> using namespace std; int N; int K; int maxCounter = 0; int sumCounter = 0; int counter; int arr[999999]; /** Results: (X cards, 10^6 rounds) 1 -> 0 0 2 -> 1 0.334546 (guess: 1/3) 3 -> 2 0.733746 4 -> 3 1.180559 5 -> 5 1.667006 (guess: 5/3) 6 -> 6 2.179321 7 -> 8 2.721661 8 -> 9 3.283566 9 -> 10 3.867299 10 -> 12 4.471352 Other things I tried: (cards, rounds) 100 1000 -> 143 84.411 200 1000 -> 307 197.332 300 1000 -> 503 319.691 500 1000 -> 960 580.373 1000 1000 -> 1910 1310.703 **/ int main(void) {     srand(23);     printf(""Number of cards: "");     scanf(""%d"", &N);     for (int i=0;i<N;i++) {         arr[i] = arr[i+N] = i;     }     printf(""Number of rounds: "");     scanf(""%d"", &K);     for (int j=0;j<K;j++) {         random_shuffle(arr, arr+2*N);         counter = 0;         while (counter>=0) {             sort(arr, arr+N);             sort(arr+N, arr+2*N);             int pass = 1;             for (int i=0;i<N;i++) {                 if (arr[i] != arr[i+N]) {                     pass = 0;                     break;                 }             }             if (pass) break;             counter++;             int theMove = rand()%N;             while (arr[theMove] == arr[theMove+N]) theMove = rand()%N;             int temp = arr[theMove];             arr[theMove] = arr[theMove+N];             arr[theMove+N] = temp;         }         //printf(""%d "", counter);         maxCounter = max(maxCounter, counter);         sumCounter += counter;         if (j%(K/100) == 0) printf(""Done: %d\n"", j);     }     printf(""Maximum: %d\nAverage: %lf\n"", maxCounter, sumCounter/(double)K);     return 0; } Results of the code: The average number of moves appear to grow faster than $O(n)$.",,"['probability', 'combinatorics', 'expectation']"
97,Calculating probability for unconventional 6 sided die,Calculating probability for unconventional 6 sided die,,"Let's consider this situation. We have $3$ different $6$-sided dice. The first die has five blank sides + one '$1$' side. The second die has four blank sides + two '$1$' sides. The third die has $4$ blank sides + one '$1$' side + one '$2$' side. In an other form : 1st die : $1,0,0,0,0,0$ 2nd die : $1,1,0,0,0,0$ 3rd die : $1,2,0,0,0,0$ I am trying to calculate the different probabilities of each possible sum outcome (sum of $0,1,2,3$ and $4$). Would it be fair to assume that what follows is true? The probability of having a sum of $1$ on the $3$ dice is equal to (1st dice, 2nd dice, third dice) : $\frac{1}{6} (1) \times \frac{4}{6} (0) \times \frac{4}{6} (0)  +  \frac{5}{6} (0) \times \frac{2}{6} (1) \times \frac{4}{6} (0) + \frac{5}{6} (0) \times \frac{4}{6} (0) \times \frac{1}{6} (1) = \frac{76}{216}$ or $35.19\%$ For the sum of $1$, I assumed that to have this sum, only one die can have '$1$' and the other two '$0$' so I find the probability for each set of dice (chance of '$1$' $\times$ chance of not '$1$' $\times$ chance of not '$1$'). I understand that this will be different for the sum of $2$ since the dice combination will be different (sometimes only $1$ dice is needed while the other time two dice will be needed) but I would like to confirm that my reasoning is accurate. I am terrible with the notions of probability and it's been a few days now that this has been in my head and I wasn't able to find an answer to my assumption anywhere on the internet since I don't know how to really word it. Thank you for your time.  Jeph edit : Corrected the sum of the probability, miscalculated, put $4\times 4$ as $8$ instead of $16$.","Let's consider this situation. We have $3$ different $6$-sided dice. The first die has five blank sides + one '$1$' side. The second die has four blank sides + two '$1$' sides. The third die has $4$ blank sides + one '$1$' side + one '$2$' side. In an other form : 1st die : $1,0,0,0,0,0$ 2nd die : $1,1,0,0,0,0$ 3rd die : $1,2,0,0,0,0$ I am trying to calculate the different probabilities of each possible sum outcome (sum of $0,1,2,3$ and $4$). Would it be fair to assume that what follows is true? The probability of having a sum of $1$ on the $3$ dice is equal to (1st dice, 2nd dice, third dice) : $\frac{1}{6} (1) \times \frac{4}{6} (0) \times \frac{4}{6} (0)  +  \frac{5}{6} (0) \times \frac{2}{6} (1) \times \frac{4}{6} (0) + \frac{5}{6} (0) \times \frac{4}{6} (0) \times \frac{1}{6} (1) = \frac{76}{216}$ or $35.19\%$ For the sum of $1$, I assumed that to have this sum, only one die can have '$1$' and the other two '$0$' so I find the probability for each set of dice (chance of '$1$' $\times$ chance of not '$1$' $\times$ chance of not '$1$'). I understand that this will be different for the sum of $2$ since the dice combination will be different (sometimes only $1$ dice is needed while the other time two dice will be needed) but I would like to confirm that my reasoning is accurate. I am terrible with the notions of probability and it's been a few days now that this has been in my head and I wasn't able to find an answer to my assumption anywhere on the internet since I don't know how to really word it. Thank you for your time.  Jeph edit : Corrected the sum of the probability, miscalculated, put $4\times 4$ as $8$ instead of $16$.",,['probability']
98,Minimum and maximum bound on mean of product of three pairwise uncorrelated random variables,Minimum and maximum bound on mean of product of three pairwise uncorrelated random variables,,"There are three  pairwise uncorrelated random variables $X, Y, Z$ $$E(X) = E(Y) = E(Z) = 0$$ $$E(X^2) = E(Y^2) = E(Z^2) = \sigma^2$$ How we could find minimum and maximum bound on $E(XYZ)$? I have thougth to play with covariance but I stuck at repeating similiar actions with no effort and have no idea what to do.","There are three  pairwise uncorrelated random variables $X, Y, Z$ $$E(X) = E(Y) = E(Z) = 0$$ $$E(X^2) = E(Y^2) = E(Z^2) = \sigma^2$$ How we could find minimum and maximum bound on $E(XYZ)$? I have thougth to play with covariance but I stuck at repeating similiar actions with no effort and have no idea what to do.",,"['probability', 'discrete-mathematics', 'correlation', 'means']"
99,Probability distribution for 1-dimensional random walk with pauses,Probability distribution for 1-dimensional random walk with pauses,,"The problem could be stated as follows :  we have some random walker in an unbounded 1-dimensional lattice, such that there is a 50% chance the walker doesn't move at all, a 25 % chance the walker moves to the left, and 25% chance the walker moves to the right. What is the probability of the walker ending up at some point in the lattice in $N$ steps? If we now denote the position of the walker as an integer i.e. $1$ would refer moving one site in the lattice to the right, and $-1$ would refer to moving to the left. Then what sort of a distribution would describe the probability that the in $N$ steps the walker would end up at some specific point on the lattice? My intuition says that I am looking for sums of the terms in an $N$-tuple that add up to the point in the site. For instance the tuple described by $(1,1,-1,0,...,0)$ would put the walker at $1$ for the end point.","The problem could be stated as follows :  we have some random walker in an unbounded 1-dimensional lattice, such that there is a 50% chance the walker doesn't move at all, a 25 % chance the walker moves to the left, and 25% chance the walker moves to the right. What is the probability of the walker ending up at some point in the lattice in $N$ steps? If we now denote the position of the walker as an integer i.e. $1$ would refer moving one site in the lattice to the right, and $-1$ would refer to moving to the left. Then what sort of a distribution would describe the probability that the in $N$ steps the walker would end up at some specific point on the lattice? My intuition says that I am looking for sums of the terms in an $N$-tuple that add up to the point in the site. For instance the tuple described by $(1,1,-1,0,...,0)$ would put the walker at $1$ for the end point.",,"['probability', 'random-walk']"
