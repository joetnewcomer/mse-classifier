,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proving Stone's Formula for Constructively obtaining the Spectral Measure for $A=A^\star$,Proving Stone's Formula for Constructively obtaining the Spectral Measure for,A=A^\star,"Let $A$ be a bounded or unbounded selfadjoint linear operator on a complex Hilbert space $H$ with spectral representation $A=\int_{\sigma}\lambda \, dE(\lambda)$ given by the Spectral Theorem for Selfadjoint Operators. Stone's Formula gives a way to constructively obtain the spectral measure $E[a,b]$ of a finite interval as a strong (vector) limit: $$ \frac{1}{2}\{E[a,b]+E(a,b)\}x=\lim_{\varepsilon\downarrow 0}\frac{1}{2\pi i}\int_a^b \{R(u+i\varepsilon)-R(u-i\varepsilon)\}x\,du,\;\;\; x \in H, $$ where $R$ is the resolvent operator $R(\lambda)=(A-\lambda I)^{-1}$. Question: What is the easiest way to prove that Stone's Formula is valid? Application: This may be viewed as a generalized residue of the resolvent function. If $A$ has isolated spectrum, then such an integral may be evaluated using residues of the resolvent.","Let $A$ be a bounded or unbounded selfadjoint linear operator on a complex Hilbert space $H$ with spectral representation $A=\int_{\sigma}\lambda \, dE(\lambda)$ given by the Spectral Theorem for Selfadjoint Operators. Stone's Formula gives a way to constructively obtain the spectral measure $E[a,b]$ of a finite interval as a strong (vector) limit: $$ \frac{1}{2}\{E[a,b]+E(a,b)\}x=\lim_{\varepsilon\downarrow 0}\frac{1}{2\pi i}\int_a^b \{R(u+i\varepsilon)-R(u-i\varepsilon)\}x\,du,\;\;\; x \in H, $$ where $R$ is the resolvent operator $R(\lambda)=(A-\lambda I)^{-1}$. Question: What is the easiest way to prove that Stone's Formula is valid? Application: This may be viewed as a generalized residue of the resolvent function. If $A$ has isolated spectrum, then such an integral may be evaluated using residues of the resolvent.",,"['functional-analysis', 'fourier-analysis', 'operator-theory', 'spectral-theory']"
1,Differentiation in Besov–Zygmund spaces,Differentiation in Besov–Zygmund spaces,,"This is my second question in a short time on Besov spaces. I apologize. I am having a rough time with them and I really need to understand this spaces quickly. The Besov spaces $B^s_{\infty,\infty}(\mathbb{R^n})$ for $s \in \mathbb{R}$ are defined by the following: A tempered distribution $u \in \mathcal{S}'(\mathbb{R^n})$ is said to be in the Besov space $B^s_{\infty,\infty}(\mathbb{R^n})$ if we have that  $$ \|u\|_{B^s_{\infty,\infty}(\mathbb{R^n})}:=\sup_{j \in \mathbb{N}} 2^{js} \|\varphi_j(D)u\|_{L^{\infty}} < \infty $$ Where $\varphi_j$, $j \ge 0$ is a Littlewood–Paley partition of unity, and $\varphi_j(D)u:=\mathcal{F}^{-1} \varphi_j \mathcal{F}u$ Question My question is: given $u \in B^s_{\infty,\infty}(\mathbb{R^n})$, is its distributional derivative $\partial_{x_i}u$ in the space $B^{s-1}_{\infty,\infty}$? How I tried My calculations show that $\varphi_j(D)u_{x_i} = (\varphi_j(D)u)_{x_i}$, so for a schwartz function $\phi \in \mathcal{S}$ we have $$|(\varphi_j(D)u_{x_i},\phi)|=|(\varphi_j(D)u,\phi_{x_i})|$$ Taking the supremum on $\phi$ with $\|\phi\|_{L^1}=1$ in the expression above we should obtain $\|\varphi_j(D)u_{x_i}\|_{L^{\infty}}$ but from this I do not get any good decay for $\|\varphi_j(D)u_{x_i}\|_{L^{\infty}}$, since the differential operators are unbounded in $L^1$ Remark This result is true for $s>1$ non integer since it can be proved that the Besov spaces $B^s_{\infty,\infty}$ coincide with the Hölder spaces $C^s$ for $s>0$ non integer. For integer $s\ge 1$ it is also true since they coincide with the Zygmund spaces defined in my other question here Besov–Zygmund spaces and the Inverse Function Theorem, is the Inverse Zygmund? In the classical references I do not find this result, so I begin to doubt whether it is true, since it should be easy to prove and should be among the basic properties on Besov spaces that are in any book, but it seems it is not the case (maybe it is just too easy for the books and I don't see it). Than you for any help.","This is my second question in a short time on Besov spaces. I apologize. I am having a rough time with them and I really need to understand this spaces quickly. The Besov spaces $B^s_{\infty,\infty}(\mathbb{R^n})$ for $s \in \mathbb{R}$ are defined by the following: A tempered distribution $u \in \mathcal{S}'(\mathbb{R^n})$ is said to be in the Besov space $B^s_{\infty,\infty}(\mathbb{R^n})$ if we have that  $$ \|u\|_{B^s_{\infty,\infty}(\mathbb{R^n})}:=\sup_{j \in \mathbb{N}} 2^{js} \|\varphi_j(D)u\|_{L^{\infty}} < \infty $$ Where $\varphi_j$, $j \ge 0$ is a Littlewood–Paley partition of unity, and $\varphi_j(D)u:=\mathcal{F}^{-1} \varphi_j \mathcal{F}u$ Question My question is: given $u \in B^s_{\infty,\infty}(\mathbb{R^n})$, is its distributional derivative $\partial_{x_i}u$ in the space $B^{s-1}_{\infty,\infty}$? How I tried My calculations show that $\varphi_j(D)u_{x_i} = (\varphi_j(D)u)_{x_i}$, so for a schwartz function $\phi \in \mathcal{S}$ we have $$|(\varphi_j(D)u_{x_i},\phi)|=|(\varphi_j(D)u,\phi_{x_i})|$$ Taking the supremum on $\phi$ with $\|\phi\|_{L^1}=1$ in the expression above we should obtain $\|\varphi_j(D)u_{x_i}\|_{L^{\infty}}$ but from this I do not get any good decay for $\|\varphi_j(D)u_{x_i}\|_{L^{\infty}}$, since the differential operators are unbounded in $L^1$ Remark This result is true for $s>1$ non integer since it can be proved that the Besov spaces $B^s_{\infty,\infty}$ coincide with the Hölder spaces $C^s$ for $s>0$ non integer. For integer $s\ge 1$ it is also true since they coincide with the Zygmund spaces defined in my other question here Besov–Zygmund spaces and the Inverse Function Theorem, is the Inverse Zygmund? In the classical references I do not find this result, so I begin to doubt whether it is true, since it should be easy to prove and should be among the basic properties on Besov spaces that are in any book, but it seems it is not the case (maybe it is just too easy for the books and I don't see it). Than you for any help.",,"['functional-analysis', 'fourier-analysis', 'banach-spaces', 'sobolev-spaces', 'besov-space']"
2,Compactness of the Volterra opelator,Compactness of the Volterra opelator,,"The Volterra operator is given as \begin{eqnarray} (Vf)(x)=\int_0^xK(x,y)f(y)\,{\rm d}y. \end{eqnarray} By the Arzelà–Ascoli theorem, $V\colon C^0[0,1]\rightarrow C^0[0,1]$ is compact operator.  But, if $V\colon C^0[0,1]\rightarrow C^1[0,1]$, is this a compact operator?","The Volterra operator is given as \begin{eqnarray} (Vf)(x)=\int_0^xK(x,y)f(y)\,{\rm d}y. \end{eqnarray} By the Arzelà–Ascoli theorem, $V\colon C^0[0,1]\rightarrow C^0[0,1]$ is compact operator.  But, if $V\colon C^0[0,1]\rightarrow C^1[0,1]$, is this a compact operator?",,"['functional-analysis', 'operator-theory', 'compactness', 'compact-operators']"
3,"Continuous linear image of closed, bounded, and convex set of a Hilbert Space is compact","Continuous linear image of closed, bounded, and convex set of a Hilbert Space is compact",,"Is my proof of this proposition correct ? And is this proposition well known? Proposition: Let $C$ be a closed, bounded, and convex set in a separable Hilbert space $H$. Let $L : H \to \mathbb{R}^n$ be a continuous linear transformation. Then $L(C)$ is compact in $\mathbb{R}^n$. Proof: Since $H$ is a Banach space, and $C$ is closed and convex, $C$ is weakly closed (Mazur's Theorem in Lang's Real Analysis ).  Since $H$ is a reflexive Banach space, closed balls are weakly compact  (Kakutani's Theorem).  Since $C$ is bounded it is contained in a weakly compact ball, and since $C$ is weakly closed, $C$ is weakly compact. Since $L$ is continuous in the strong topologies, it is continuous in the weak topologies (this fact seems to be well known).  So $L(C)$ is weakly compact in  $\mathbb{R}^n$, and since the weak and strong topologies on  $\mathbb{R}^n$ are the same,  $L(C)$ is compact in  $\mathbb{R}^n$.  $\square$ Convexity is essential. Otherwise I have a counterexample. This is not a homework problem.  The motivation comes from the physics of color. In my case $H$ is $L^2([380,780])$ where 380 and 780 are wavelengths of light in nanometers.  $C$ is the subset of functions that take values in $[0,1]$ and each such function represents the spectral reflectance (or spectral transmittance) of a material over this interval of wavelengths.   $\mathbb{R}^n$ is the 3D space of CIEXYZ tristimulus coordinates.  $L$ is the linear mapping from the reflectance of the material to CIEXYZ, for a fixed spectral illuminant.  $L(C)$ is the set of all possible material colors for the given illuminant. Thank you.","Is my proof of this proposition correct ? And is this proposition well known? Proposition: Let $C$ be a closed, bounded, and convex set in a separable Hilbert space $H$. Let $L : H \to \mathbb{R}^n$ be a continuous linear transformation. Then $L(C)$ is compact in $\mathbb{R}^n$. Proof: Since $H$ is a Banach space, and $C$ is closed and convex, $C$ is weakly closed (Mazur's Theorem in Lang's Real Analysis ).  Since $H$ is a reflexive Banach space, closed balls are weakly compact  (Kakutani's Theorem).  Since $C$ is bounded it is contained in a weakly compact ball, and since $C$ is weakly closed, $C$ is weakly compact. Since $L$ is continuous in the strong topologies, it is continuous in the weak topologies (this fact seems to be well known).  So $L(C)$ is weakly compact in  $\mathbb{R}^n$, and since the weak and strong topologies on  $\mathbb{R}^n$ are the same,  $L(C)$ is compact in  $\mathbb{R}^n$.  $\square$ Convexity is essential. Otherwise I have a counterexample. This is not a homework problem.  The motivation comes from the physics of color. In my case $H$ is $L^2([380,780])$ where 380 and 780 are wavelengths of light in nanometers.  $C$ is the subset of functions that take values in $[0,1]$ and each such function represents the spectral reflectance (or spectral transmittance) of a material over this interval of wavelengths.   $\mathbb{R}^n$ is the 3D space of CIEXYZ tristimulus coordinates.  $L$ is the linear mapping from the reflectance of the material to CIEXYZ, for a fixed spectral illuminant.  $L(C)$ is the set of all possible material colors for the given illuminant. Thank you.",,"['functional-analysis', 'proof-verification', 'convex-analysis', 'hilbert-spaces']"
4,Convex weak* sequentially closed subset of the dual of a separable Banach space is weak* closed,Convex weak* sequentially closed subset of the dual of a separable Banach space is weak* closed,,"I'm studying Conway's a course in Functional Analysis by myself. The following is  corollary 6.12.7 of this book. If $X$ is a separable Banach space and $A$ is a convex subset of $X^*$ that is weak* sequentially closed, then $A$ is weak* closed. Proof: Because X is separable, $r(ball X^*)$ is weak* metrizable for every $r>0$. So if A is weak* sequentially closed, $A\cap (r(ball X^*))$ is weak* closed for every $r>0$. Hence the Krein-Smulian theorem applies. My problem: I do not know how A is weak* sequentially closed implies $A\cap (r(ball X^*))$ is weak* closed for every $r>0$.","I'm studying Conway's a course in Functional Analysis by myself. The following is  corollary 6.12.7 of this book. If $X$ is a separable Banach space and $A$ is a convex subset of $X^*$ that is weak* sequentially closed, then $A$ is weak* closed. Proof: Because X is separable, $r(ball X^*)$ is weak* metrizable for every $r>0$. So if A is weak* sequentially closed, $A\cap (r(ball X^*))$ is weak* closed for every $r>0$. Hence the Krein-Smulian theorem applies. My problem: I do not know how A is weak* sequentially closed implies $A\cap (r(ball X^*))$ is weak* closed for every $r>0$.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
5,When is $M+N$ closed,When is  closed,M+N,"Let $X$ be a Banach space and $M,N$ be closed subspaces. If the range of linear  transformation $x\to (x+M)\oplus (x+N)$ from $X$ into $X/M\oplus X/N$ is closed show that $M+N$ is closed. or using $M^\perp+ N^\perp $ is norm closed to show $M+N$ is closed","Let $X$ be a Banach space and $M,N$ be closed subspaces. If the range of linear  transformation $x\to (x+M)\oplus (x+N)$ from $X$ into $X/M\oplus X/N$ is closed show that $M+N$ is closed. or using $M^\perp+ N^\perp $ is norm closed to show $M+N$ is closed",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
6,Extending weak solution to global weak solution of parabolic PDE,Extending weak solution to global weak solution of parabolic PDE,,"Fix $T > 0.$ Let $V \subset H \subset V^*$ be a Gelfand triple. Consider the linear parabolic PDE $$u_t - Au = f\quad\text{in $L^2(0,T;V^*)$}$$ $$u(0) = u_0$$ where $u_0 \in H$ and $f \in L^2(0,T;V^*)$ and $A$ is some elliptic smooth operator. we know that this problem has a unique solution  $$u \in L^2(0,T;V), u_t \in L^2(0,T;V^*)$$ by using a Galerkin method for example. Questions: What exactly does it mean to say that we can extend $u$ to a global solution? I assume this means we can write $u \in L^2(0,\infty;V)$ and that $u$ solves the PDE I wrote above on $[0,\infty)$. How is $f$ extended from $[0,T]$ -- do we assume we are given such an extension. Under what conditions does one obtain a global solution? (I tried all the other threads). Any reference to source that talks about this in detail would be appreciated too. Thanks. Edit : This is confusing. Some papers consider a PDE and say that ""because we have existence of $u \in L^2(0,T;V)$ for any $T>0$, we have global existence"". other papers say solve the IVP, and then solve another IVP with $\tilde u(0) = u(T)$ and in this way extend the solution Please someone give me authoritative reference on this topic.","Fix $T > 0.$ Let $V \subset H \subset V^*$ be a Gelfand triple. Consider the linear parabolic PDE $$u_t - Au = f\quad\text{in $L^2(0,T;V^*)$}$$ $$u(0) = u_0$$ where $u_0 \in H$ and $f \in L^2(0,T;V^*)$ and $A$ is some elliptic smooth operator. we know that this problem has a unique solution  $$u \in L^2(0,T;V), u_t \in L^2(0,T;V^*)$$ by using a Galerkin method for example. Questions: What exactly does it mean to say that we can extend $u$ to a global solution? I assume this means we can write $u \in L^2(0,\infty;V)$ and that $u$ solves the PDE I wrote above on $[0,\infty)$. How is $f$ extended from $[0,T]$ -- do we assume we are given such an extension. Under what conditions does one obtain a global solution? (I tried all the other threads). Any reference to source that talks about this in detail would be appreciated too. Thanks. Edit : This is confusing. Some papers consider a PDE and say that ""because we have existence of $u \in L^2(0,T;V)$ for any $T>0$, we have global existence"". other papers say solve the IVP, and then solve another IVP with $\tilde u(0) = u(T)$ and in this way extend the solution Please someone give me authoritative reference on this topic.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'sobolev-spaces']"
7,Closure of numerical range contains spectrum,Closure of numerical range contains spectrum,,"Let $A: D(A) \subset \mathcal{H} \to \mathcal{H}$ be a densely defined operator on a Hilbert space $\mathcal{H}$ with adjoint operator $A^{*}$. Given that $D(A) = D(A^{*})$ I'm trying to show that the spectrum $\sigma(A)$ is a subset of the closure of the numerical range of A: $N(A)=\{ \langle x, Ax \rangle \vert \|x\| = 1, x \in D(A) \}$. If $A$ is closed, I think we can argue as follows: $ \| (z - A)x \| \geq \vert \langle x, (z-A)x \rangle \vert \geq \inf_{\|x\|=1} \vert z - \langle x, Ax \rangle\vert$. So if $z \notin \overline{N(A)}$ we have that $(z - A)$ is injective und the inverse $(z - A)^{-1}$ is bounded on the range of $A$. By contradiction Ran$(z-A) = \mathcal H$ and hence $z$ has to be in the resolvent set of $A$. What I am not sure about is: Is the above proof right? If $A$ is not closed, does $\sigma(A) \subset \overline{N(A)}$ hold? Can anyone help?  Thanking you in advance!","Let $A: D(A) \subset \mathcal{H} \to \mathcal{H}$ be a densely defined operator on a Hilbert space $\mathcal{H}$ with adjoint operator $A^{*}$. Given that $D(A) = D(A^{*})$ I'm trying to show that the spectrum $\sigma(A)$ is a subset of the closure of the numerical range of A: $N(A)=\{ \langle x, Ax \rangle \vert \|x\| = 1, x \in D(A) \}$. If $A$ is closed, I think we can argue as follows: $ \| (z - A)x \| \geq \vert \langle x, (z-A)x \rangle \vert \geq \inf_{\|x\|=1} \vert z - \langle x, Ax \rangle\vert$. So if $z \notin \overline{N(A)}$ we have that $(z - A)$ is injective und the inverse $(z - A)^{-1}$ is bounded on the range of $A$. By contradiction Ran$(z-A) = \mathcal H$ and hence $z$ has to be in the resolvent set of $A$. What I am not sure about is: Is the above proof right? If $A$ is not closed, does $\sigma(A) \subset \overline{N(A)}$ hold? Can anyone help?  Thanking you in advance!",,"['functional-analysis', 'analysis', 'operator-theory', 'spectral-theory']"
8,Measurability of a total variation metric,Measurability of a total variation metric,,"Let $X$ be a standard Borel space and let us denote by $\mathcal P(X)$ the space of Borel probability measures on $X$ endowed with the topology of weak convergence. Define $d:\mathcal P(X)\times \mathcal P(X)\to [0,1]$ by $$   d(p,q) := \sup_{A\in \mathcal B(X)}|p(A) - q(A)| $$ to be the total variation metric on $\mathcal P(X)$. I wonder whether $d$ is a measurable function. Since the topology induced by $d$ is stronger than the weak convergence, it is not a continuous function on $\mathcal P(X)$ and hence I can't use this argument to show the measurability. Perhaps, there is a way of showing measurability of $d$ based on the fact that the $\sigma$-algebra of $\mathcal P(X)$ can be equivalently defined as the one generated by evaluation maps $\theta_A(p):=p(A)$.","Let $X$ be a standard Borel space and let us denote by $\mathcal P(X)$ the space of Borel probability measures on $X$ endowed with the topology of weak convergence. Define $d:\mathcal P(X)\times \mathcal P(X)\to [0,1]$ by $$   d(p,q) := \sup_{A\in \mathcal B(X)}|p(A) - q(A)| $$ to be the total variation metric on $\mathcal P(X)$. I wonder whether $d$ is a measurable function. Since the topology induced by $d$ is stronger than the weak convergence, it is not a continuous function on $\mathcal P(X)$ and hence I can't use this argument to show the measurability. Perhaps, there is a way of showing measurability of $d$ based on the fact that the $\sigma$-algebra of $\mathcal P(X)$ can be equivalently defined as the one generated by evaluation maps $\theta_A(p):=p(A)$.",,"['functional-analysis', 'measure-theory', 'probability-theory', 'descriptive-set-theory']"
9,Can $f*g = f+g$ for $f$ and $g$ compactly supported?,Can  for  and  compactly supported?,f*g = f+g f g,"Let $f$ and $g$ be  continuous, compactly-supported functions $\mathbb{R} \to \mathbb{C}$. Can it happen that $f*g  = f+g$? Here, $f*g$ denotes the convolution $$(f*g)(s) = \int_\mathbb{R} f(t) g(s-t) \ dt.$$ Edit: Discount the solution $f=g=0$. My thoughts: My feeling is that the answer is ""no"". We are asking for a certain identity to hold in the dense subalgebra $C_c(\mathbb{R})$ of the Banach algebra $L^1(\mathbb{R})$. If there is a pair such that this happens, then without loss of generality, $\|f\|_1 < 1$. But then, the series $$h = f + f*f + f*f*f + \ldots$$ converges in $L^1(\mathbb{R})$. It is not hard to see that $g = -h$ has $f*g = f+g$. I think there can only be one $g$ satisfying $f+g = f*g$, so this is the one. But, my sense is that the interated convolutions in the sum are making the support spread out. Could somebody please clarify this for me?","Let $f$ and $g$ be  continuous, compactly-supported functions $\mathbb{R} \to \mathbb{C}$. Can it happen that $f*g  = f+g$? Here, $f*g$ denotes the convolution $$(f*g)(s) = \int_\mathbb{R} f(t) g(s-t) \ dt.$$ Edit: Discount the solution $f=g=0$. My thoughts: My feeling is that the answer is ""no"". We are asking for a certain identity to hold in the dense subalgebra $C_c(\mathbb{R})$ of the Banach algebra $L^1(\mathbb{R})$. If there is a pair such that this happens, then without loss of generality, $\|f\|_1 < 1$. But then, the series $$h = f + f*f + f*f*f + \ldots$$ converges in $L^1(\mathbb{R})$. It is not hard to see that $g = -h$ has $f*g = f+g$. I think there can only be one $g$ satisfying $f+g = f*g$, so this is the one. But, my sense is that the interated convolutions in the sum are making the support spread out. Could somebody please clarify this for me?",,"['functional-analysis', 'convolution', 'banach-algebras']"
10,"If $a$ and $b$ commute in a $C^*$-algebra and $a$ is normal, then $f(a)$ and $b$ commute for any continuous $f$","If  and  commute in a -algebra and  is normal, then  and  commute for any continuous",a b C^* a f(a) b f,"I'm trying to find a way to demonstrate the following: Let $(A,*,\|\cdot\|)$ be a unital $C^*$-algebra. If $a,b\in A$ commute and $a\in A$ is normal (i.e. $a^*a=aa^*$), then for every continuous function $f:$Sp$(a)\to\mathbb{C}$, $f(a)$ and $b$ commute (where Sp$(a)$ denotes the spectrum of $a$ and $f(a)$ is given by functional calculus). So far, I've been trying to show that $\|f(a)b-bf(a)\|=0$ knowing that $ab=ba$ or, equivalently, $\|ab-ba\|=0$, but I've got nowhere with this. Any hint/suggestion would be greatly appreciated.","I'm trying to find a way to demonstrate the following: Let $(A,*,\|\cdot\|)$ be a unital $C^*$-algebra. If $a,b\in A$ commute and $a\in A$ is normal (i.e. $a^*a=aa^*$), then for every continuous function $f:$Sp$(a)\to\mathbb{C}$, $f(a)$ and $b$ commute (where Sp$(a)$ denotes the spectrum of $a$ and $f(a)$ is given by functional calculus). So far, I've been trying to show that $\|f(a)b-bf(a)\|=0$ knowing that $ab=ba$ or, equivalently, $\|ab-ba\|=0$, but I've got nowhere with this. Any hint/suggestion would be greatly appreciated.",,"['functional-analysis', 'banach-spaces']"
11,Projective limit of Banach spaces,Projective limit of Banach spaces,,"Let $(X_s)_{s \in (0,s_1)}$ be an increasing sequence of Banach spaces with the property that if $0<s<r<s_1$, then $$ \|u\|_{X_s} \leq \|u\|_{X_r}. $$ We define $$\tilde{X}_s = \projlim_{r>s} {X_r}.$$ Please help me understand the spaces $\tilde{X}_s$. Context: If it helps, the context of my question is PDE. The spaces $X_s$ are actually function spaces such that a differential operator brings an element of $X_s$ to a larger space $X_r$. At the top of my head, the questions I have are: What are the elements of $\tilde{X}_s$? What kind of a space is this? I think I have read somewhere that $\tilde{X}_s$ will turn out to be a Frechet space. Is this correct? If I apply a differential operator to an element of $\tilde{X}_s$, what happens? Note: I have already looked at some of the answers here regarding projective limit or inverse limit but all of them were too advanced for me to understand. If I have missed an answer that might be helpful in my case, feel free to give me the link instead. Thanks!","Let $(X_s)_{s \in (0,s_1)}$ be an increasing sequence of Banach spaces with the property that if $0<s<r<s_1$, then $$ \|u\|_{X_s} \leq \|u\|_{X_r}. $$ We define $$\tilde{X}_s = \projlim_{r>s} {X_r}.$$ Please help me understand the spaces $\tilde{X}_s$. Context: If it helps, the context of my question is PDE. The spaces $X_s$ are actually function spaces such that a differential operator brings an element of $X_s$ to a larger space $X_r$. At the top of my head, the questions I have are: What are the elements of $\tilde{X}_s$? What kind of a space is this? I think I have read somewhere that $\tilde{X}_s$ will turn out to be a Frechet space. Is this correct? If I apply a differential operator to an element of $\tilde{X}_s$, what happens? Note: I have already looked at some of the answers here regarding projective limit or inverse limit but all of them were too advanced for me to understand. If I have missed an answer that might be helpful in my case, feel free to give me the link instead. Thanks!",,"['functional-analysis', 'partial-differential-equations', 'banach-spaces']"
12,Construct dense subspace of codimension $n$ for all $n$,Construct dense subspace of codimension  for all,n n,"I want to prove the following: Let $X$ be an infinite dimensional normed space. For all integer $n\geq1$: $X$ has a dense subspace of codimension $n$, i.e. a subspace $L$ such that $\dim(X/L)=n$. How can i do this? My first thought was: Take a basis $e_1,e_2,\ldots$ such that $X=Span(e_1,e_2,\ldots)$ and let $L=Span(e_2,e_3,\ldots)$ than $\dim(X/L)=1$. On the same way you can go on. Is this the right method to conclude the result? Thank you.","I want to prove the following: Let $X$ be an infinite dimensional normed space. For all integer $n\geq1$: $X$ has a dense subspace of codimension $n$, i.e. a subspace $L$ such that $\dim(X/L)=n$. How can i do this? My first thought was: Take a basis $e_1,e_2,\ldots$ such that $X=Span(e_1,e_2,\ldots)$ and let $L=Span(e_2,e_3,\ldots)$ than $\dim(X/L)=1$. On the same way you can go on. Is this the right method to conclude the result? Thank you.",,['functional-analysis']
13,Existence for linear wave equation using energy inequality.,Existence for linear wave equation using energy inequality.,,"I'm reading through Sogge's Lectures on Nonlinear Wave Equations and am confused by the proof of existence for the linear inhomogeneous problem. Sorry for the long setup. (Theorem) Let $s \in \mathbb{Z}$. Then for every $f \in H^{s+1}(\mathbb{R}^n)$, $g \in H^s(\mathbb{R}^n)$ and $F \in L^1([0,T];H^s(\mathbb{R}^n))$ there is a unique $$ u \in C([0,T];H^{s+1}) \cap C^1([0,T];H^s) $$ solving $$ \begin{cases} Lu=F, &0 < t <T \\ u_{t=0}=f, \partial_tu_{t=0}=g \end{cases} $$ where $$ L=\sum_{j,k=0}^n g^{jk}(t,x)\partial_j\partial_k u + \sum_{j=0}^n b^j(t,x)\partial_j u + a(t,x)u $$ has $C^\infty$ coefficients with uniform bounds on each derivative. Here $g^{jk}$ is symmetric and close to the d'Alembertian in the sense: $$ \sum |g^{jk}(t,x)-g_0^{jk}| < \frac12 $$ where $g_0^{jk}=\text{diag}(1,-1,\dots,-1)$ are the coefficients of $\square$. The proof makes use of the following energy-type inequality: $$ \sum_{|\alpha|\leq1} \|\partial^\alpha u(t,\cdot)\|_{H^s}  \leq C_{s,T}\left( \sum_{|\alpha|\leq1} \|\partial^\alpha u(0,\cdot)\|_{H^s} + \int_0^t \|Lu(\tau,\cdot)\|_{H^s} \; d\tau\right). \tag{1} $$ The relevant text: Proceed assuming $f=g=0$. If $\psi \in C_0^\infty((-\infty,T)\times\mathbb{R}^n)$ then applying the above energy inequality to $L^*$, with $t$ replaced by $T-t$, yields $$ \|\psi(t,\cdot)\|_{H^{-s}} \leq C\int_0^T\|L^*\psi(\tau,\cdot)\|_{H^{-s-1}} \; d\tau. \tag{2} $$ Hence, since $H^s$ and $H^{-s}$ are dual spaces, for fixed $F \in L^1([0,T];H^s)$ we have $$ |\langle F,\psi \rangle|   = \left|\int_0^T \langle F(t,\cdot),\psi(t,\cdot)\rangle \; dt\right|   \leq C' \int_0^T \|L^*\psi(t,\cdot)\|_{H^{-s-1}} \; dt. \tag{3} $$ So, by the Hahn-Banach Theorem, there is a $u \in L^{\infty}([0,T];H^{s+1})$ satisfying $u=0$ when $t<0$ and, moreover, $$ \langle F,\psi \rangle = \langle u,L^*\psi \rangle,  \qquad \forall \psi \in C_0^{\infty}((-\infty,T)\times\mathbb{R}^n). $$ Consequently, $Lu=F$ in $(0,T)\times\mathbb{R}^n$ in the sense of distributions. Questions: When applying the energy inequality (1), how does $L^*\psi$ end up in the $H^{-s-1}$ norm in (2)? How exactly is the Hahn-Banach Theorem applied? The linear functional $\langle F, \cdot \rangle$ is bounded by the sublinear function on the right hand side of (3) for all $\psi \in C_0^\infty((-\infty,T)\times\mathbb{R}^n)$. I don't understand the details which provide the existence of $u$. A similar question is asked here .","I'm reading through Sogge's Lectures on Nonlinear Wave Equations and am confused by the proof of existence for the linear inhomogeneous problem. Sorry for the long setup. (Theorem) Let $s \in \mathbb{Z}$. Then for every $f \in H^{s+1}(\mathbb{R}^n)$, $g \in H^s(\mathbb{R}^n)$ and $F \in L^1([0,T];H^s(\mathbb{R}^n))$ there is a unique $$ u \in C([0,T];H^{s+1}) \cap C^1([0,T];H^s) $$ solving $$ \begin{cases} Lu=F, &0 < t <T \\ u_{t=0}=f, \partial_tu_{t=0}=g \end{cases} $$ where $$ L=\sum_{j,k=0}^n g^{jk}(t,x)\partial_j\partial_k u + \sum_{j=0}^n b^j(t,x)\partial_j u + a(t,x)u $$ has $C^\infty$ coefficients with uniform bounds on each derivative. Here $g^{jk}$ is symmetric and close to the d'Alembertian in the sense: $$ \sum |g^{jk}(t,x)-g_0^{jk}| < \frac12 $$ where $g_0^{jk}=\text{diag}(1,-1,\dots,-1)$ are the coefficients of $\square$. The proof makes use of the following energy-type inequality: $$ \sum_{|\alpha|\leq1} \|\partial^\alpha u(t,\cdot)\|_{H^s}  \leq C_{s,T}\left( \sum_{|\alpha|\leq1} \|\partial^\alpha u(0,\cdot)\|_{H^s} + \int_0^t \|Lu(\tau,\cdot)\|_{H^s} \; d\tau\right). \tag{1} $$ The relevant text: Proceed assuming $f=g=0$. If $\psi \in C_0^\infty((-\infty,T)\times\mathbb{R}^n)$ then applying the above energy inequality to $L^*$, with $t$ replaced by $T-t$, yields $$ \|\psi(t,\cdot)\|_{H^{-s}} \leq C\int_0^T\|L^*\psi(\tau,\cdot)\|_{H^{-s-1}} \; d\tau. \tag{2} $$ Hence, since $H^s$ and $H^{-s}$ are dual spaces, for fixed $F \in L^1([0,T];H^s)$ we have $$ |\langle F,\psi \rangle|   = \left|\int_0^T \langle F(t,\cdot),\psi(t,\cdot)\rangle \; dt\right|   \leq C' \int_0^T \|L^*\psi(t,\cdot)\|_{H^{-s-1}} \; dt. \tag{3} $$ So, by the Hahn-Banach Theorem, there is a $u \in L^{\infty}([0,T];H^{s+1})$ satisfying $u=0$ when $t<0$ and, moreover, $$ \langle F,\psi \rangle = \langle u,L^*\psi \rangle,  \qquad \forall \psi \in C_0^{\infty}((-\infty,T)\times\mathbb{R}^n). $$ Consequently, $Lu=F$ in $(0,T)\times\mathbb{R}^n$ in the sense of distributions. Questions: When applying the energy inequality (1), how does $L^*\psi$ end up in the $H^{-s-1}$ norm in (2)? How exactly is the Hahn-Banach Theorem applied? The linear functional $\langle F, \cdot \rangle$ is bounded by the sublinear function on the right hand side of (3) for all $\psi \in C_0^\infty((-\infty,T)\times\mathbb{R}^n)$. I don't understand the details which provide the existence of $u$. A similar question is asked here .",,"['functional-analysis', 'partial-differential-equations']"
14,Many other solutions of the Cauchy's Functional Equation,Many other solutions of the Cauchy's Functional Equation,,"By reading the Cauchy's Functional Equations on the Wiki,  it is said that On the other hand, if no further conditions are imposed on f, then (assuming the axiom of choice) there are infinitely many other functions that satisfy the equation. This was proved in 1905 by Georg Hamel using Hamel bases. Such functions are sometimes called Hamel functions. Could anyone give a more explicit explanation of these many other solutions ? Besides the trivial solution of the form $f(x)=C x$, where $C$ is a constant, and the solution above constructed by the Hamel Basis, are there any more solutions existing?","By reading the Cauchy's Functional Equations on the Wiki,  it is said that On the other hand, if no further conditions are imposed on f, then (assuming the axiom of choice) there are infinitely many other functions that satisfy the equation. This was proved in 1905 by Georg Hamel using Hamel bases. Such functions are sometimes called Hamel functions. Could anyone give a more explicit explanation of these many other solutions ? Besides the trivial solution of the form $f(x)=C x$, where $C$ is a constant, and the solution above constructed by the Hamel Basis, are there any more solutions existing?",,"['functional-analysis', 'functional-equations']"
15,Show $f_n \rightarrow f$ in $L^2(\mathbb R)$ if $f_n(x) = f(x + x_n)$ where $x_n \rightarrow 0$,Show  in  if  where,f_n \rightarrow f L^2(\mathbb R) f_n(x) = f(x + x_n) x_n \rightarrow 0,"This is an old qualifying exam question. My attempt was to say \begin{align}\|f_n - f\|_{L^2(\mathbb R)}^2 &= \int_{\mathbb R} (f(x+x_n) - f(x))^2\\ &= \|f(x+x_n)\| + \|f(x)\| - 2 \int_{\mathbb R} f(x+x_n)f(x) \mathsf dx\end{align} Now I want to say that $$f(x+x_n)f(x) \stackrel{n\to\infty}\longrightarrow f(x)^2$$ but I don't think that is valid unless $f$ was continuous in order to bring the limit inside to the $x_n$. I also tried thinking about $$f(x+x_n) - f(x) = x_n\frac{f(x+x_n) - f(x)}{x_n}$$ which would approach $f'$ but again, this need not exist. Anyway, I am stumped. Suggestions? Thanks!","This is an old qualifying exam question. My attempt was to say \begin{align}\|f_n - f\|_{L^2(\mathbb R)}^2 &= \int_{\mathbb R} (f(x+x_n) - f(x))^2\\ &= \|f(x+x_n)\| + \|f(x)\| - 2 \int_{\mathbb R} f(x+x_n)f(x) \mathsf dx\end{align} Now I want to say that $$f(x+x_n)f(x) \stackrel{n\to\infty}\longrightarrow f(x)^2$$ but I don't think that is valid unless $f$ was continuous in order to bring the limit inside to the $x_n$. I also tried thinking about $$f(x+x_n) - f(x) = x_n\frac{f(x+x_n) - f(x)}{x_n}$$ which would approach $f'$ but again, this need not exist. Anyway, I am stumped. Suggestions? Thanks!",,"['functional-analysis', 'measure-theory', 'convergence-divergence']"
16,Convergence of eigenvalues for sequence of compressions of a compact operator,Convergence of eigenvalues for sequence of compressions of a compact operator,,"Suppose $H$ is a separable Hilbert space, $A$ is a Hilbert Schmidt operator on $H$, and $P_n$ is an increasing sequence of finite rank orthogonal projections of $H$ (so $P_nx\rightarrow x$ for all $x\in H$).  Then we certainly have that, for $A_n=P_nAP_n$, $A_n\rightarrow A$ in the Hilbert-Schmidt norm; see for example this very complete post on Approximating a Hilbert-Schmidt operator .  My follow-up question: If the singular values of an operator are always ordered from largest to smallest, including multiplicities, is it (trivially?) true that the $k^\mathrm{th}$ singular value of the the sequence of operators $\{A_n\}_{n\ge k}$ converges to the $k^\mathrm{th}$ singular value of $A$? Thanks!","Suppose $H$ is a separable Hilbert space, $A$ is a Hilbert Schmidt operator on $H$, and $P_n$ is an increasing sequence of finite rank orthogonal projections of $H$ (so $P_nx\rightarrow x$ for all $x\in H$).  Then we certainly have that, for $A_n=P_nAP_n$, $A_n\rightarrow A$ in the Hilbert-Schmidt norm; see for example this very complete post on Approximating a Hilbert-Schmidt operator .  My follow-up question: If the singular values of an operator are always ordered from largest to smallest, including multiplicities, is it (trivially?) true that the $k^\mathrm{th}$ singular value of the the sequence of operators $\{A_n\}_{n\ge k}$ converges to the $k^\mathrm{th}$ singular value of $A$? Thanks!",,"['functional-analysis', 'eigenvalues-eigenvectors', 'compact-operators']"
17,"Minimizing continuous, convex and coercive functions in non-reflexive Banach spaces","Minimizing continuous, convex and coercive functions in non-reflexive Banach spaces",,"Let $X$ be a infinite dimensional real Banach space. If $X$ is reflexive, then any continuous, convex coervive function $f:X\rightarrow\mathbb{R}$ has a minimum value, that is assumed for some point $x\in X$. This happens because of two motives: 1 - The ball is compact in the weak topology. 2 - $f$ is weakly sequentially lower semi-continuous. Note that we can only assume $f$ lower semi continuous to get this result. On the other hand, if $X$ is not reflexive, we don't have 1 and in the same conditions for $f$, it is possible for $f$ not satisfy 2. So my question is: How to construct $f: X\rightarrow 0$ continuous, convex and coercive, with $X$ non-reflexive, and in such a way that $f$ don't attain a minimum value in some point of $X$? More specifically: I- It is possible for $f$ to be unbounded below? II- It is possible for $f$ to be bounded below, but the minimum is not assumed for any point in $x$? Thanks","Let $X$ be a infinite dimensional real Banach space. If $X$ is reflexive, then any continuous, convex coervive function $f:X\rightarrow\mathbb{R}$ has a minimum value, that is assumed for some point $x\in X$. This happens because of two motives: 1 - The ball is compact in the weak topology. 2 - $f$ is weakly sequentially lower semi-continuous. Note that we can only assume $f$ lower semi continuous to get this result. On the other hand, if $X$ is not reflexive, we don't have 1 and in the same conditions for $f$, it is possible for $f$ not satisfy 2. So my question is: How to construct $f: X\rightarrow 0$ continuous, convex and coercive, with $X$ non-reflexive, and in such a way that $f$ don't attain a minimum value in some point of $X$? More specifically: I- It is possible for $f$ to be unbounded below? II- It is possible for $f$ to be bounded below, but the minimum is not assumed for any point in $x$? Thanks",,"['functional-analysis', 'banach-spaces']"
18,Weak holomorphicity implies smooth and holomorphic.,Weak holomorphicity implies smooth and holomorphic.,,"This is an extension of a previously asked question: A function $f\in L^2(D)$ is weakly holomorphic if, for every $\phi\in \mathcal{C}^{\infty}_c(D)$, $$\int_D f\partial_{\bar{z}}\phi = 0.$$ I'm trying to show that each such $f$ is smooth on the interior of $D$ and is in fact a strong solution to $\partial_{\bar{z}}f=0$; i.e., $f$ is holomorphic in the usual sense. Here's what I've proven so far: Let $B$ be a bounded open set in $\mathbb{R}^n$ and $f\in L^p(D)$ for $1<p<\infty$. Let $g$ be a smooth, non-negative function supported in the unit ball with Lebesgue integral 1 and consider the mollifier $$f_{\epsilon}(x)=\epsilon^{-n}\int_{B}g(\frac{x-y}{\epsilon})f(y)dy$$ where $x\in B$ and $\epsilon<|x,\partial B|$. Then, $f_{\epsilon}\rightarrow f$ uniformly in the $L^p$ sense as $\epsilon\rightarrow 0$. Consequently, $f$ can be approximated by smooth, compactly supported functions in $B$. Now, supposing this is true in the complex case if we just replace $B$ with the unit disk $D$ (I haven't proven this, but I think it's correct...) then I'm essentially done if I can demonstrate that my mollifying functions are holomorphic since I already know they're smooth. I'm not quite sure where the hypothesis would come into play, however. Anyway, is this the correct route? Thanks.","This is an extension of a previously asked question: A function $f\in L^2(D)$ is weakly holomorphic if, for every $\phi\in \mathcal{C}^{\infty}_c(D)$, $$\int_D f\partial_{\bar{z}}\phi = 0.$$ I'm trying to show that each such $f$ is smooth on the interior of $D$ and is in fact a strong solution to $\partial_{\bar{z}}f=0$; i.e., $f$ is holomorphic in the usual sense. Here's what I've proven so far: Let $B$ be a bounded open set in $\mathbb{R}^n$ and $f\in L^p(D)$ for $1<p<\infty$. Let $g$ be a smooth, non-negative function supported in the unit ball with Lebesgue integral 1 and consider the mollifier $$f_{\epsilon}(x)=\epsilon^{-n}\int_{B}g(\frac{x-y}{\epsilon})f(y)dy$$ where $x\in B$ and $\epsilon<|x,\partial B|$. Then, $f_{\epsilon}\rightarrow f$ uniformly in the $L^p$ sense as $\epsilon\rightarrow 0$. Consequently, $f$ can be approximated by smooth, compactly supported functions in $B$. Now, supposing this is true in the complex case if we just replace $B$ with the unit disk $D$ (I haven't proven this, but I think it's correct...) then I'm essentially done if I can demonstrate that my mollifying functions are holomorphic since I already know they're smooth. I'm not quite sure where the hypothesis would come into play, however. Anyway, is this the correct route? Thanks.",,"['complex-analysis', 'functional-analysis', 'partial-differential-equations']"
19,"How to find an orthonormal basis for $L^2(\mathbb{R},\mathbb{C})$?",How to find an orthonormal basis for ?,"L^2(\mathbb{R},\mathbb{C})","Consider the Hilbert space $X:=L^2(\mathbb{R},\mathbb{C})$ Now consider the operator that takes the second derivative, i.e. $A := \partial_{x}^2$, i.e. $A: H^2(\mathbb{R},\mathbb{C}) \subset X \to X$ I need to know if there are $(\alpha_n) \subset \mathbb{C}$ for $n \in \mathbb{N}$ and an orthonormal basis $\lbrace e_n : ~  n \in \mathbb{Z}_+ \rbrace$ of $X$ such that $ A e_n = \alpha_n e_n.$ and additionally I need to calculate the $\lbrace a_n \rbrace$, so I guess I need the basis in closed form. Any hint?","Consider the Hilbert space $X:=L^2(\mathbb{R},\mathbb{C})$ Now consider the operator that takes the second derivative, i.e. $A := \partial_{x}^2$, i.e. $A: H^2(\mathbb{R},\mathbb{C}) \subset X \to X$ I need to know if there are $(\alpha_n) \subset \mathbb{C}$ for $n \in \mathbb{N}$ and an orthonormal basis $\lbrace e_n : ~  n \in \mathbb{Z}_+ \rbrace$ of $X$ such that $ A e_n = \alpha_n e_n.$ and additionally I need to calculate the $\lbrace a_n \rbrace$, so I guess I need the basis in closed form. Any hint?",,"['functional-analysis', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'hilbert-spaces', 'eigenfunctions']"
20,Does there exist a diagonal dominance concept for integral kernels?,Does there exist a diagonal dominance concept for integral kernels?,,"A self-adjoint diagonally dominant square matrix $M$ with nonnegative diagonal is positive semi-definite. Does there exist a similar concept for integration kernels that define compact operators over, say, $L^2(\mathbb{R}^n)$? Let me be more specific: Suppose $M$ is a self-adjoint square matrix. $M$ is diagonally dominant if and only if, for all $i$, $$ |M_{ii}| \geq \sum_{j\neq i} |M_{ij}|. $$ $M$ is invertible. Suppose the diagonal satisfies $M_{ii}\geq 0$. Then $M$ is automatiaclly positive semidefinite. Thus, a simple criterion on the matrix elements determine whether $M$ is positive semidefinite -- a question which in general would involve computation of the whole spectrum of $M$. Let us turn to integration kernels. Suppose $u:\mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{C}$ is (for simplicity assumed to be) a Schwartz  function, such that we may define a compact operator $U$ over $L^2(\mathbb{R}^n)$ using $u$ as integration kernel, viz, $$ [U\phi](x)  := \int_{\mathbb{R}^n} u(x,y)\phi(y) d^n y. $$ Assume $u(x,y) = \overline{u(y,x)}$ such that $U$ is self-adjoint. $u(x,y)$ is analogous to the matrix elements $M_{ij}$ of $M$. Does there exist some sort of criterion for $u(x,y)$ analogous to $M$ being diagonally dominant, that guarantees $U\geq 0$? I.e., can we say something about whether $U$ is postive semidefinite by studying the behavior of $u(x,y)$ near the diagonal $x=y$? In general, positive semidefiniteness of $U$ is much harder to ascertain, i.e., we would have to study the spectrum of $U$.","A self-adjoint diagonally dominant square matrix $M$ with nonnegative diagonal is positive semi-definite. Does there exist a similar concept for integration kernels that define compact operators over, say, $L^2(\mathbb{R}^n)$? Let me be more specific: Suppose $M$ is a self-adjoint square matrix. $M$ is diagonally dominant if and only if, for all $i$, $$ |M_{ii}| \geq \sum_{j\neq i} |M_{ij}|. $$ $M$ is invertible. Suppose the diagonal satisfies $M_{ii}\geq 0$. Then $M$ is automatiaclly positive semidefinite. Thus, a simple criterion on the matrix elements determine whether $M$ is positive semidefinite -- a question which in general would involve computation of the whole spectrum of $M$. Let us turn to integration kernels. Suppose $u:\mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{C}$ is (for simplicity assumed to be) a Schwartz  function, such that we may define a compact operator $U$ over $L^2(\mathbb{R}^n)$ using $u$ as integration kernel, viz, $$ [U\phi](x)  := \int_{\mathbb{R}^n} u(x,y)\phi(y) d^n y. $$ Assume $u(x,y) = \overline{u(y,x)}$ such that $U$ is self-adjoint. $u(x,y)$ is analogous to the matrix elements $M_{ij}$ of $M$. Does there exist some sort of criterion for $u(x,y)$ analogous to $M$ being diagonally dominant, that guarantees $U\geq 0$? I.e., can we say something about whether $U$ is postive semidefinite by studying the behavior of $u(x,y)$ near the diagonal $x=y$? In general, positive semidefiniteness of $U$ is much harder to ascertain, i.e., we would have to study the spectrum of $U$.",,"['functional-analysis', 'compact-operators']"
21,Behaviour of the spectrum of a compact operator w.r.t. perturbations.,Behaviour of the spectrum of a compact operator w.r.t. perturbations.,,"Suppose $A$ and $B$ are linear compact operators on a Hilbert space with $\sigma(A)$ and $\sigma(B)$ as their spectrum. Is it possible to obtain some continuity result of $\sigma(A+\epsilon B)$ as $\epsilon\downarrow 0$ towards $\sigma(A)$? Is the limiting behavior of the form ""$\sigma(A)+\epsilon \sigma(B)$''? Thanks in advance!","Suppose $A$ and $B$ are linear compact operators on a Hilbert space with $\sigma(A)$ and $\sigma(B)$ as their spectrum. Is it possible to obtain some continuity result of $\sigma(A+\epsilon B)$ as $\epsilon\downarrow 0$ towards $\sigma(A)$? Is the limiting behavior of the form ""$\sigma(A)+\epsilon \sigma(B)$''? Thanks in advance!",,"['functional-analysis', 'operator-theory', 'compact-operators']"
22,Universal separable Banach algebras,Universal separable Banach algebras,,"The well-known Banach–Mazur theorem says that $C([0, 1])$ is a universal separable Banach space, in the sense that if $X$ is any separable Banach space then there is a map $f : X \to C([0, 1])$ which is both linear and isometric.  Note that $C([0, 1])$ also has the structure of a Banach algebra. My question is this: Is $C([0, 1])$ universal for separable commutative Banach algebras?  Of course a separable Banach algebra is a separable Banach space, so there is a linear isometry into $C([0, 1])$, but I'm asking if that map can also be taken to preserve the multiplication operation. If $C([0, 1])$ is not universal for separable commutative Banach algebras, does there exist such a universal object?  I'm interested mostly in ZFC results, but would also not mind hearing consistent answers (especially if they are consistent with $\neg CH$).","The well-known Banach–Mazur theorem says that $C([0, 1])$ is a universal separable Banach space, in the sense that if $X$ is any separable Banach space then there is a map $f : X \to C([0, 1])$ which is both linear and isometric.  Note that $C([0, 1])$ also has the structure of a Banach algebra. My question is this: Is $C([0, 1])$ universal for separable commutative Banach algebras?  Of course a separable Banach algebra is a separable Banach space, so there is a linear isometry into $C([0, 1])$, but I'm asking if that map can also be taken to preserve the multiplication operation. If $C([0, 1])$ is not universal for separable commutative Banach algebras, does there exist such a universal object?  I'm interested mostly in ZFC results, but would also not mind hearing consistent answers (especially if they are consistent with $\neg CH$).",,"['functional-analysis', 'banach-spaces', 'banach-algebras']"
23,Question about definition of Sobolev spaces,Question about definition of Sobolev spaces,,"I'm trying to understand the following definition: which can also be found here on page 136. Question 1: Closure with respect to what norm? It's not given in the definition. Question 2: Do I have this right: I can view $C^\infty$ as a dense subspace of $H^k$ via the map (embedding) $f \mapsto (D^\alpha f)_\alpha$ where the tuple $f$ is mapped to consists of all derivatives $D^\alpha f$ such that $|\alpha| \leq k$. Then this is cool because if we have this we can extend any linear operator $T: C^\infty \to C^n$ continuously to all of $H^k$ so that anything we can do to smooth functions we can also do to Sobolev functions. That is, even if the functions don't have a strong $\alpha$-th derivative we can treat them as if they did. Thanks for your help.","I'm trying to understand the following definition: which can also be found here on page 136. Question 1: Closure with respect to what norm? It's not given in the definition. Question 2: Do I have this right: I can view $C^\infty$ as a dense subspace of $H^k$ via the map (embedding) $f \mapsto (D^\alpha f)_\alpha$ where the tuple $f$ is mapped to consists of all derivatives $D^\alpha f$ such that $|\alpha| \leq k$. Then this is cool because if we have this we can extend any linear operator $T: C^\infty \to C^n$ continuously to all of $H^k$ so that anything we can do to smooth functions we can also do to Sobolev functions. That is, even if the functions don't have a strong $\alpha$-th derivative we can treat them as if they did. Thanks for your help.",,"['functional-analysis', 'sobolev-spaces']"
24,The ratio of two $L^p$ norms,The ratio of two  norms,L^p,"Let $f$ be a non-negative function on a measure space $(X,\mu)$ with $\mu(X) = 1$. Is there a known characterization of when $$\lim_{n \rightarrow \infty } \frac{\|f^n\|_p}{\|f^n\|_q } = 1,$$ for $1 \leq p < q \leq \infty$? Since $\mu$ is a probability measure, we know that this limit is always less than 1, but I am seeking to characterize (in terms of $p$ and $q$) the functions such that the limit is in fact precisely 1.","Let $f$ be a non-negative function on a measure space $(X,\mu)$ with $\mu(X) = 1$. Is there a known characterization of when $$\lim_{n \rightarrow \infty } \frac{\|f^n\|_p}{\|f^n\|_q } = 1,$$ for $1 \leq p < q \leq \infty$? Since $\mu$ is a probability measure, we know that this limit is always less than 1, but I am seeking to characterize (in terms of $p$ and $q$) the functions such that the limit is in fact precisely 1.",,"['measure-theory', 'functional-analysis']"
25,Generalized notions of mixture,Generalized notions of mixture,,"A subset $S$ of a real vector space is convex if it is closed under finite mixtures: for any $\lambda_1,\ldots,\lambda_n>0$ such that $\lambda_1+\cdots+\lambda_n=1$ and any $x_1,\ldots,x_n\in S$, $\lambda_1x_1+\cdots+\lambda_nx_n\in S$.  In a normed space, we can generalize and talk about countable mixtures, defined in the obvious way.  I suspect that with still more structure, we can define even more general notions of mixture (using some kind of integration, perhaps).  But how does it go?  Are there examples of sets closed under countable mixtures but not arbitrary mixtures? If it helps, what I am most interested in is mixtures of probability measures and mixtures of finitely-additive probability measures.","A subset $S$ of a real vector space is convex if it is closed under finite mixtures: for any $\lambda_1,\ldots,\lambda_n>0$ such that $\lambda_1+\cdots+\lambda_n=1$ and any $x_1,\ldots,x_n\in S$, $\lambda_1x_1+\cdots+\lambda_nx_n\in S$.  In a normed space, we can generalize and talk about countable mixtures, defined in the obvious way.  I suspect that with still more structure, we can define even more general notions of mixture (using some kind of integration, perhaps).  But how does it go?  Are there examples of sets closed under countable mixtures but not arbitrary mixtures? If it helps, what I am most interested in is mixtures of probability measures and mixtures of finitely-additive probability measures.",,"['measure-theory', 'functional-analysis', 'probability-theory']"
26,solution for the degenerate parabolic PDE,solution for the degenerate parabolic PDE,,"Look at $u_t=a(x)u_{xx}$ if I have $a(x)\geq a_0>0$ then I can see in all books that $C^{2,1}$ solution exist and it is unique. However, if $a(x)\geq0$, that is degenerate, I see in Friedman's book the construction of $K_{\epsilon}$: sequence convergent uniformly to $K$ which is the solution of the degenerate equation. But he doesn't state the property of the latter. What are the problems of those equations? Looks like I have problem constructing a weak solution because I lack coercivity property, so I have little hope to have it $C^{2,1}$. But what class a solution of the degenerate equation belongs to? thnaks!","Look at $u_t=a(x)u_{xx}$ if I have $a(x)\geq a_0>0$ then I can see in all books that $C^{2,1}$ solution exist and it is unique. However, if $a(x)\geq0$, that is degenerate, I see in Friedman's book the construction of $K_{\epsilon}$: sequence convergent uniformly to $K$ which is the solution of the degenerate equation. But he doesn't state the property of the latter. What are the problems of those equations? Looks like I have problem constructing a weak solution because I lack coercivity property, so I have little hope to have it $C^{2,1}$. But what class a solution of the degenerate equation belongs to? thnaks!",,"['functional-analysis', 'partial-differential-equations']"
27,Boundary of invertibles in a normed algebra,Boundary of invertibles in a normed algebra,,"A student and I are reading the book Introduction to Banach Spaces and Algebras, by Allan, and we're stuck.  Exercise 4.5 says: Let $A$ be a normed algebra with unit sphere $S$.  Let $a\in A$.  Then $a$ is a topological divisor of 0 if   $$ \inf\{\|ab\|+\|ba\|:b\in S \}=0. $$   Prove that every element in the frontier of $G(A)$ is a topological divisor of $0$. Here $G(A)$ is the collection of invertible elements of $A$.  I assume that the question really means to say that $A$ is a unital normed algebra.  Then the book already essentially proves this result for Banach algebras (Corollary 4.13). So if $B$ is the completion of $A$, and if $a$ is still in the frontier of $G(B)$, then we're done (the infimum obviously doesn't change if we replace $S$ by the unit sphere of $B$). Conversely, if there is an example of $a\in\partial G(A)$ with $a\in G(B)$, then we have a counter-example to the exercise.  So my question is: If $a\in\partial G(A)$ and $B$ is the completion of $A$, then is $a\in\partial G(B)$? Edit: Embarrassingly, I think I can now answer this! Let $A$ be the complex polynomials, interpreted as an algebra of continuous functions on the interval $[0,1]$.  A little bit of algebra shows that $G(A)$ consists of just the constant polynomials.  So $G(A)$ is actually closed (not open, which would be the case if $A$ were Banach).  So being careful about what ""frontier"" means, I guess $G(A)$ is its own frontier.  But then the exercise is trivially false, as the frontier of $G(A)$ contains invertibles. So the exercise seems wrong.  But somehow my counter-example seems cheap.  So a new question: Can the frontier of $G(A)$ contain a non-invertible element which is invertible in $B$?  Are there examples where $G(A)$ is open?","A student and I are reading the book Introduction to Banach Spaces and Algebras, by Allan, and we're stuck.  Exercise 4.5 says: Let $A$ be a normed algebra with unit sphere $S$.  Let $a\in A$.  Then $a$ is a topological divisor of 0 if   $$ \inf\{\|ab\|+\|ba\|:b\in S \}=0. $$   Prove that every element in the frontier of $G(A)$ is a topological divisor of $0$. Here $G(A)$ is the collection of invertible elements of $A$.  I assume that the question really means to say that $A$ is a unital normed algebra.  Then the book already essentially proves this result for Banach algebras (Corollary 4.13). So if $B$ is the completion of $A$, and if $a$ is still in the frontier of $G(B)$, then we're done (the infimum obviously doesn't change if we replace $S$ by the unit sphere of $B$). Conversely, if there is an example of $a\in\partial G(A)$ with $a\in G(B)$, then we have a counter-example to the exercise.  So my question is: If $a\in\partial G(A)$ and $B$ is the completion of $A$, then is $a\in\partial G(B)$? Edit: Embarrassingly, I think I can now answer this! Let $A$ be the complex polynomials, interpreted as an algebra of continuous functions on the interval $[0,1]$.  A little bit of algebra shows that $G(A)$ consists of just the constant polynomials.  So $G(A)$ is actually closed (not open, which would be the case if $A$ were Banach).  So being careful about what ""frontier"" means, I guess $G(A)$ is its own frontier.  But then the exercise is trivially false, as the frontier of $G(A)$ contains invertibles. So the exercise seems wrong.  But somehow my counter-example seems cheap.  So a new question: Can the frontier of $G(A)$ contain a non-invertible element which is invertible in $B$?  Are there examples where $G(A)$ is open?",,"['functional-analysis', 'banach-algebras']"
28,Example of a non-algebraic $\ell^2$-function in two variables,Example of a non-algebraic -function in two variables,\ell^2,"Let's call an $\ell^2$-function $\mathbb{N} \times \mathbb{N} \to \mathbb{C}$ algebraic if it is in the image of the natural algebra homomorphism $\ell^2(\mathbb{N}) \otimes \ell^2(\mathbb{N}) \to \ell^2(\mathbb{N} \times \mathbb{N})$, where on the left hand side we consider the usual, non-completed tensor product. In other words, $f(m,n)$ is algebraic iff it may be written as $\sum_{i=1}^{k} g_i(m) h_i(n)$ for some $k \in \mathbb{N}$ and $\ell^2$-functions $g_i,h_i$. Probably there are abstract reasons for the existence of non-algebraic functions. But I would like to know an explicit example of an $\ell^2$-function together with a concise and complete proof that it is not algebraic. For example: Question . Can you give a proof that the $\ell^2$-function $(n,m) \mapsto \dfrac{1}{2^{n \cdot m}}$ is not algebraic?","Let's call an $\ell^2$-function $\mathbb{N} \times \mathbb{N} \to \mathbb{C}$ algebraic if it is in the image of the natural algebra homomorphism $\ell^2(\mathbb{N}) \otimes \ell^2(\mathbb{N}) \to \ell^2(\mathbb{N} \times \mathbb{N})$, where on the left hand side we consider the usual, non-completed tensor product. In other words, $f(m,n)$ is algebraic iff it may be written as $\sum_{i=1}^{k} g_i(m) h_i(n)$ for some $k \in \mathbb{N}$ and $\ell^2$-functions $g_i,h_i$. Probably there are abstract reasons for the existence of non-algebraic functions. But I would like to know an explicit example of an $\ell^2$-function together with a concise and complete proof that it is not algebraic. For example: Question . Can you give a proof that the $\ell^2$-function $(n,m) \mapsto \dfrac{1}{2^{n \cdot m}}$ is not algebraic?",,"['functional-analysis', 'functions', 'hilbert-spaces', 'tensor-products']"
29,Confusion regarding Riesz's lemma,Confusion regarding Riesz's lemma,,"Wikipedia (and my teacher) state Riesz's lemma as follows: Let $X$ be a normed linear space and $Y$  be a subspace in $X$. If there exists $0 < r < 1$ such that for every $x\in X$ with $||x|| =1$ , one has $d(x, Y) < r$, then $Y$ is dense in $X$. Wikipedia then goes on to say In other words, for every proper closed subspace Y, one can always find a vector x on the unit sphere of X such that d(x, Y) is less than and arbitrarily close to 1. This is in fact the way Riesz's lemma is stated in several other places (e.g. appendix B of the book A Taste of Topology by Volker Runde). Now, I don't see how these two statements are so quickly equivalent. The second one seems to be the contrapositive of the first one. But this would mean that ""non dense subspace"" is the same as ""proper closed subspace"". This doesn't seem to be true: I thought, for instance, of $C([0,1])$, the space of continuous functions on $[0,1]$ with the supremum norm, and of the subspace of differentiable functions. It's a dense subspace which is not closed. What is (obviously) true is that proper closed subspaces are not dense. So, correct me if I'm wrong, but it seems that to say ""in other words"" is innacurate, as the second statement is stronger than the first one! Is my reasoning correct?","Wikipedia (and my teacher) state Riesz's lemma as follows: Let $X$ be a normed linear space and $Y$  be a subspace in $X$. If there exists $0 < r < 1$ such that for every $x\in X$ with $||x|| =1$ , one has $d(x, Y) < r$, then $Y$ is dense in $X$. Wikipedia then goes on to say In other words, for every proper closed subspace Y, one can always find a vector x on the unit sphere of X such that d(x, Y) is less than and arbitrarily close to 1. This is in fact the way Riesz's lemma is stated in several other places (e.g. appendix B of the book A Taste of Topology by Volker Runde). Now, I don't see how these two statements are so quickly equivalent. The second one seems to be the contrapositive of the first one. But this would mean that ""non dense subspace"" is the same as ""proper closed subspace"". This doesn't seem to be true: I thought, for instance, of $C([0,1])$, the space of continuous functions on $[0,1]$ with the supremum norm, and of the subspace of differentiable functions. It's a dense subspace which is not closed. What is (obviously) true is that proper closed subspaces are not dense. So, correct me if I'm wrong, but it seems that to say ""in other words"" is innacurate, as the second statement is stronger than the first one! Is my reasoning correct?",,['functional-analysis']
30,Different norms on a product space $X \times Y$,Different norms on a product space,X \times Y,"It is well known how to define standard product topology on a product space $\prod_{i \in I} X_i$. Assume now that $(X,\lVert \, \cdot \, \rVert_{X})$ and $(Y,\lVert \, \cdot \, \rVert_{Y})$ are normed spaces and that the space $X \times Y$ is also equipped with a norm $\lVert \, \cdot \, \rVert_{X \times Y}$. Is it true that all norms on $X \times Y$ are equivalent? It is quite easy to prove this if $\lVert \, \cdot \, \rVert_{X \times Y}$ is one of the p -norms, i.e. $\lVert (x,y) \rVert_p = (\lVert x \rVert_X^p + \lVert y \rVert_Y^p)^{1/p}$. All such norms are equivalent. We only need to know that all norms on a finite dimensional space are equivalent (in this case we use it for $\mathbb{R}^2$). How it is general case?","It is well known how to define standard product topology on a product space $\prod_{i \in I} X_i$. Assume now that $(X,\lVert \, \cdot \, \rVert_{X})$ and $(Y,\lVert \, \cdot \, \rVert_{Y})$ are normed spaces and that the space $X \times Y$ is also equipped with a norm $\lVert \, \cdot \, \rVert_{X \times Y}$. Is it true that all norms on $X \times Y$ are equivalent? It is quite easy to prove this if $\lVert \, \cdot \, \rVert_{X \times Y}$ is one of the p -norms, i.e. $\lVert (x,y) \rVert_p = (\lVert x \rVert_X^p + \lVert y \rVert_Y^p)^{1/p}$. All such norms are equivalent. We only need to know that all norms on a finite dimensional space are equivalent (in this case we use it for $\mathbb{R}^2$). How it is general case?",,"['functional-analysis', 'normed-spaces']"
31,Invariant Subspaces (Hardy Space),Invariant Subspaces (Hardy Space),,"Suppose $M_1$ and $M_2$ are invariant subspaces of the unilateral shift U such that $M_1$ subset $M_2$ and $M_1$ is of codimension strictly larger than $1$ in $M_2$. Show that there exists $M$ invariant under $U$ satisfying $M_1 \subset M \subset M_2$ where the inclusions are strict. All subspaces are closed. This problem is from the Springer GTM: ""An introduction to operators on the Hardy-Hilbert space"". Edit: Perhaps I can take $M := U M_2$? Maybe I should give that some more thought.","Suppose $M_1$ and $M_2$ are invariant subspaces of the unilateral shift U such that $M_1$ subset $M_2$ and $M_1$ is of codimension strictly larger than $1$ in $M_2$. Show that there exists $M$ invariant under $U$ satisfying $M_1 \subset M \subset M_2$ where the inclusions are strict. All subspaces are closed. This problem is from the Springer GTM: ""An introduction to operators on the Hardy-Hilbert space"". Edit: Perhaps I can take $M := U M_2$? Maybe I should give that some more thought.",,"['complex-analysis', 'functional-analysis']"
32,"Does sequence of monomials form a Frame in $L^2[0,1]$?",Does sequence of monomials form a Frame in ?,"L^2[0,1]","A sequence $(x_n)_{n \in \mathbb{N}}$ is said to be Frame, if there exist constants $A,B > 0$ such that $$ A \lVert x \rVert^2 \leq \sum_{n=0}^{\infty} \lvert (x,x_n) \rvert^2 \leq B \lVert x \rVert^2$$ for all $x \in H$ . Consider the Hilbertspace $L^2[0,1]$ endowed with the Lebesgue measure and the sequence of monomials, i.e. the functions $x_n(t) = t^n, t \in [0,1], n \in \mathbb{N}$ . Using Hilbert's inequality one can verify that $(x_n)_{n \in \mathbb{N}}$ fulfills $$\sum_{n=0}^{\infty} \lvert (f,x_n)\rvert^2 \leq B \lVert f \rVert^2$$ for all $f \in L^2[0,1]$ . Furthermore it is a consequence of Lusin's theorem that the span of $(x_n)_{n \in \mathbb{N}}$ is dense in $L^2[0,1]$ . My question is if $(x_n)_{n \in \mathbb{N}}$ is a frame, that is it fulfills the lower frame bound. Since I have no idea from what I could infer a lower bound, my first thought was that it is not a frame. Since a frame provides expansions of the form $$ f = \sum_{n=0}^{\infty}a_n x^n$$ with complex coefficients $a_n$ where the series converges unconditionally and hence also in $L^2$ -norm, I'm trying to find a $f \in L^2[0,1]$ which does not have a power series expansion of this form. Is this true or is $(x_n)_{n \in \mathbb{N}}$ a frame after all (or something inbetween, since the latter statement, if false, does not imply that $(x_n)_{n \in \mathbb{N}}$ is a frame).","A sequence is said to be Frame, if there exist constants such that for all . Consider the Hilbertspace endowed with the Lebesgue measure and the sequence of monomials, i.e. the functions . Using Hilbert's inequality one can verify that fulfills for all . Furthermore it is a consequence of Lusin's theorem that the span of is dense in . My question is if is a frame, that is it fulfills the lower frame bound. Since I have no idea from what I could infer a lower bound, my first thought was that it is not a frame. Since a frame provides expansions of the form with complex coefficients where the series converges unconditionally and hence also in -norm, I'm trying to find a which does not have a power series expansion of this form. Is this true or is a frame after all (or something inbetween, since the latter statement, if false, does not imply that is a frame).","(x_n)_{n \in \mathbb{N}} A,B > 0  A \lVert x \rVert^2 \leq \sum_{n=0}^{\infty} \lvert (x,x_n) \rvert^2 \leq B \lVert x \rVert^2 x \in H L^2[0,1] x_n(t) = t^n, t \in [0,1], n \in \mathbb{N} (x_n)_{n \in \mathbb{N}} \sum_{n=0}^{\infty} \lvert (f,x_n)\rvert^2 \leq B \lVert f \rVert^2 f \in L^2[0,1] (x_n)_{n \in \mathbb{N}} L^2[0,1] (x_n)_{n \in \mathbb{N}}  f = \sum_{n=0}^{\infty}a_n x^n a_n L^2 f \in L^2[0,1] (x_n)_{n \in \mathbb{N}} (x_n)_{n \in \mathbb{N}}","['functional-analysis', 'polynomials', 'frame-theory']"
33,Riesz representation theorem for functionals acting on Hölder $C^\alpha$ functions,Riesz representation theorem for functionals acting on Hölder  functions,C^\alpha,"Assume you have a linear functional $F:C^\alpha(\mathbb R^n) \mapsto\mathbb R$ such that $$ |F(f)| \leq \vert f \vert_{C^\alpha(\mathbb R^n)}  $$ but only depending on the Holder seminorm, that is, $$ |f|_{C^\alpha} = \sup_{x,y}|x-y|^{-\alpha} |f(x)- f(y)|. $$ Can I assert that $F(f) = \int_{\mathbb R^n} g \cdot f \, dm$ for some $g \in H^p(\mathbb R^n)$ with $\Vert g \Vert_{H^p}\lesssim 1$ where $H^p$ is the real Hardy space? Is there any reference for Riesz representation theorems on Holder-Hardy spaces? Edit: My idea why something like this might be true, is that we have $$ \int_{\mathbb R^n} f g \, dm \lesssim \vert f \vert_{C^\alpha} \Vert g \Vert_{H^p} $$ where $\Vert g \Vert_{H^p}$ is the atomic $H^p$ norm. Note that the dual of $H^p$ is the homogeneous space of Holder functions of order $n(1/p − 1)$ .","Assume you have a linear functional such that but only depending on the Holder seminorm, that is, Can I assert that for some with where is the real Hardy space? Is there any reference for Riesz representation theorems on Holder-Hardy spaces? Edit: My idea why something like this might be true, is that we have where is the atomic norm. Note that the dual of is the homogeneous space of Holder functions of order .","F:C^\alpha(\mathbb R^n) \mapsto\mathbb R 
|F(f)| \leq \vert f \vert_{C^\alpha(\mathbb R^n)} 
 
|f|_{C^\alpha} = \sup_{x,y}|x-y|^{-\alpha} |f(x)- f(y)|.
 F(f) = \int_{\mathbb R^n} g \cdot f \, dm g \in H^p(\mathbb R^n) \Vert g \Vert_{H^p}\lesssim 1 H^p 
\int_{\mathbb R^n} f g \, dm \lesssim \vert f \vert_{C^\alpha} \Vert g \Vert_{H^p}
 \Vert g \Vert_{H^p} H^p H^p n(1/p − 1)","['functional-analysis', 'harmonic-analysis', 'duality-theorems', 'hardy-spaces']"
34,$\int _0^1f^2\left(x\right)dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=0$,,\int _0^1f^2\left(x\right)dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=0,"Let $   f  $ be an increasingly continuous function over $[0,1]$ such that: $$\int _0^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=0$$ Find all functions $f$ with these properties. Attempt.: First, the function $f$ is integrable therefore the computations with integrals work there. Then I did the following: $$\int _0^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=$$ $$\int _0^{\sqrt{3}-1}(f\left(x\right))^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=$$ $$\int _0^{\sqrt{3}-1}\left(f\left(x\right)-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-\int _0^{\sqrt{3}-1}\left(x+1\right)^2dx+1=0$$ Since $$-\int _0^{\sqrt{3}-1}\left(x+1\right)^2dx=-\frac{6\sqrt{3}-10}{3}-3+\sqrt{3}$$ Then $$\int _0^{\sqrt{3}-1}\left(f\left(x\right)dx-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-\frac{6\sqrt{3}-10}{3}-2+\sqrt{3}=0$$ $$\int _0^{\sqrt{3}-1}\left(f\left(x\right)dx-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx+\frac{-3\sqrt{3}+4}{3}=0$$ How should I continue from there? I got stuck there. I am not sure this is going to lead me somewhere. Maybe I should have started differently. Has somebody an idea what the functions look like?","Let be an increasingly continuous function over such that: Find all functions with these properties. Attempt.: First, the function is integrable therefore the computations with integrals work there. Then I did the following: Since Then How should I continue from there? I got stuck there. I am not sure this is going to lead me somewhere. Maybe I should have started differently. Has somebody an idea what the functions look like?","   f   [0,1] \int _0^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1=0 f f \int _0^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1= \int _0^{\sqrt{3}-1}(f\left(x\right))^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-2\int _0^{\sqrt{3}-1}\:\left(x+1\right)f\left(x\right)dx\:+1= \int _0^{\sqrt{3}-1}\left(f\left(x\right)-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-\int _0^{\sqrt{3}-1}\left(x+1\right)^2dx+1=0 -\int _0^{\sqrt{3}-1}\left(x+1\right)^2dx=-\frac{6\sqrt{3}-10}{3}-3+\sqrt{3} \int _0^{\sqrt{3}-1}\left(f\left(x\right)dx-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx-\frac{6\sqrt{3}-10}{3}-2+\sqrt{3}=0 \int _0^{\sqrt{3}-1}\left(f\left(x\right)dx-\left(x+1\right)\right)^2dx+\int _{\sqrt{3}-1}^1(f\left(x\right))^2dx+\frac{-3\sqrt{3}+4}{3}=0","['functional-analysis', 'functions', 'continuity']"
35,Vector space translation continuous implies addition continuous?,Vector space translation continuous implies addition continuous?,,"In here , it is proved if a topology on a vector space makes the addition function continuous, then the translation is also continuous everywhere. My question is whether the inverse is still true: Let $V$ be a vector space with a topology $\tau$ . If, for every $x\in V$ , the translation $T_x: V\to V$ , $T_x(y):=x+y$ , is continuous, is it guaranteed the addition $+: V\times V \to V$ is also continuous? I know if the translations are continuous everywhere, then they are homeomorphisms, regardless of whether the addition is also continuous. At this point, I'm not assuming anything regarding the scalar multiplications, as in, it's not known whether it is continuous.","In here , it is proved if a topology on a vector space makes the addition function continuous, then the translation is also continuous everywhere. My question is whether the inverse is still true: Let be a vector space with a topology . If, for every , the translation , , is continuous, is it guaranteed the addition is also continuous? I know if the translations are continuous everywhere, then they are homeomorphisms, regardless of whether the addition is also continuous. At this point, I'm not assuming anything regarding the scalar multiplications, as in, it's not known whether it is continuous.",V \tau x\in V T_x: V\to V T_x(y):=x+y +: V\times V \to V,"['functional-analysis', 'topological-vector-spaces', 'product-space']"
36,Property of an operator that is Fredholm and compact?,Property of an operator that is Fredholm and compact?,,"I have been asked this question at my course on Functional Analysis, to tell something about an operator that is both compact and Fredholm. The answer needs to be related to the spaces between which our operator acts. What I know is that a Fredholm operator is already a bounded linear map between Banach Spaces (let's call them $X$ and $Y$ ). I also know that the spectrum of a compact operator is the same as the point spectrum, and that it is at most countable. I was hoping to somehow show using these facts that $Y$ must be finite dimensional. Maybe we could show that the image is finite dimensional, and hence show that $Y$ is also. But for now this is just speculation. Thanks in advance!","I have been asked this question at my course on Functional Analysis, to tell something about an operator that is both compact and Fredholm. The answer needs to be related to the spaces between which our operator acts. What I know is that a Fredholm operator is already a bounded linear map between Banach Spaces (let's call them and ). I also know that the spectrum of a compact operator is the same as the point spectrum, and that it is at most countable. I was hoping to somehow show using these facts that must be finite dimensional. Maybe we could show that the image is finite dimensional, and hence show that is also. But for now this is just speculation. Thanks in advance!",X Y Y Y,"['functional-analysis', 'compact-operators']"
37,"If $A$ is a $W^*$-algebra, how to construct a nice predual for $M_n(A)$?","If  is a -algebra, how to construct a nice predual for ?",A W^* M_n(A),"Let $A$ be a $W^*$ -algebra. By concretely representing $A \subseteq B(H)$ as a von Neumann algebra and using that $M_n(A) \subseteq B(H^{n})$ , one can check that $M_n(A)$ is again a $W^*$ -algebra such that $\sigma$ -weak convergence in $M_n(A)$ is given by entrywise $\sigma$ -weak convergence of all entries. However, I'm wondering if it is also possible to deduce this fact from Sakai's predual theorem. I.e., given a $W^*$ -algebra $A$ , it it possible to construct a Banach space $F$ together with an isometric isomorphism $$\Phi: M_n(A) \to F^*$$ so that it becomes clear that $\sigma$ -weak convergence in $M_n(A)$ is given entrywise? Very naively, we can fix a predual $A_*$ for $A$ and then we want to do something like $$M_n(A) \cong M_n((A_*)^*) \cong M_n(A_*)^*$$ but it is not clear to me how to turn $M_n(A_*)$ in a Banach space such that we obtain an isometry.","Let be a -algebra. By concretely representing as a von Neumann algebra and using that , one can check that is again a -algebra such that -weak convergence in is given by entrywise -weak convergence of all entries. However, I'm wondering if it is also possible to deduce this fact from Sakai's predual theorem. I.e., given a -algebra , it it possible to construct a Banach space together with an isometric isomorphism so that it becomes clear that -weak convergence in is given entrywise? Very naively, we can fix a predual for and then we want to do something like but it is not clear to me how to turn in a Banach space such that we obtain an isometry.",A W^* A \subseteq B(H) M_n(A) \subseteq B(H^{n}) M_n(A) W^* \sigma M_n(A) \sigma W^* A F \Phi: M_n(A) \to F^* \sigma M_n(A) A_* A M_n(A) \cong M_n((A_*)^*) \cong M_n(A_*)^* M_n(A_*),"['functional-analysis', 'banach-spaces', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
38,Is $BV$ the dual of a separable Banach space?,Is  the dual of a separable Banach space?,BV,"In literature I am reading right now, it says $BV(\Omega)$ , where $\Omega \subset \mathbb{R}^n$ an open bounded set, is the dual of a separable space. Is it a dual separable Banach space, or not a Banach space at all? I am asking, because I want to use the weak-* compactness theorem Banach Alaoglu on this space, but then $BV(\Omega)$ needs to be the dual of a separable Banach space.","In literature I am reading right now, it says , where an open bounded set, is the dual of a separable space. Is it a dual separable Banach space, or not a Banach space at all? I am asking, because I want to use the weak-* compactness theorem Banach Alaoglu on this space, but then needs to be the dual of a separable Banach space.",BV(\Omega) \Omega \subset \mathbb{R}^n BV(\Omega),"['functional-analysis', 'banach-spaces', 'bounded-variation']"
39,Is the following operator (related to the Dirac's delta) bounded?,Is the following operator (related to the Dirac's delta) bounded?,,"Consider $\eta \colon [-1,0] \to \mathbb{R}$ of bounded variation and define the (delay) operator $\Phi \colon \mathcal{C}[-1,0] \to \mathbb{R}$ by $$\Phi f = \int_{-1}^{0} f d \eta$$ for $f \in \mathcal{C}[-1,0]$ where the integral is the Riemann-Stieltjes integral. $\Phi$ is a bounded linear operator acting on $\mathcal{C}[-1,0]$ and so by continuous embeddings it is a bounded linear operator acting on the Sobolev space $W^{1,2}[-1,0]$ . Now [Bátkai, András, and Susanna Piazzera. Semigroups for delay equations. CRC Press, 2005.] p.69 example 3.28 claims that $$\Phi f= f(-1), f \in W^{1,2}[-1,0]$$ is representable in the integral form before and it is a bounded linear operator. But $\eta$ in this case should be the Dirac's delta in $-1$ , i.e. $\eta = \delta_{-1}$ . It feels weird that it is a bounded linear operator on $W^{1,2}$ when usually distributions are defined as linear continuous functionals on $C_{0}^{\infty}$ which is a much smaller space? I mean ok this should be another way to define functionals from distributions right? From the point of view of calcultions it seems like that: $$|\Phi f|= |f(-1)| \leq |f|_{\mathcal{C}^0} \leq C |f|_{W^{1,2}}$$ where $|\cdot|_{\mathcal{C}^0}$ is the sup norm. Anyway since $\eta= \delta_{-1}$ is not a function can you define the Riemann-Stieltjes integral correctly?","Consider of bounded variation and define the (delay) operator by for where the integral is the Riemann-Stieltjes integral. is a bounded linear operator acting on and so by continuous embeddings it is a bounded linear operator acting on the Sobolev space . Now [Bátkai, András, and Susanna Piazzera. Semigroups for delay equations. CRC Press, 2005.] p.69 example 3.28 claims that is representable in the integral form before and it is a bounded linear operator. But in this case should be the Dirac's delta in , i.e. . It feels weird that it is a bounded linear operator on when usually distributions are defined as linear continuous functionals on which is a much smaller space? I mean ok this should be another way to define functionals from distributions right? From the point of view of calcultions it seems like that: where is the sup norm. Anyway since is not a function can you define the Riemann-Stieltjes integral correctly?","\eta \colon [-1,0] \to \mathbb{R} \Phi \colon \mathcal{C}[-1,0] \to \mathbb{R} \Phi f = \int_{-1}^{0} f d \eta f \in \mathcal{C}[-1,0] \Phi \mathcal{C}[-1,0] W^{1,2}[-1,0] \Phi f= f(-1), f \in W^{1,2}[-1,0] \eta -1 \eta = \delta_{-1} W^{1,2} C_{0}^{\infty} |\Phi f|= |f(-1)| \leq |f|_{\mathcal{C}^0} \leq C |f|_{W^{1,2}} |\cdot|_{\mathcal{C}^0} \eta= \delta_{-1}","['functional-analysis', 'measure-theory', 'operator-theory', 'distribution-theory', 'semigroup-of-operators']"
40,"In precisely what sense is the universal representation of a C*-algebra ""universal""?","In precisely what sense is the universal representation of a C*-algebra ""universal""?",,"Recently I started learning about the universal representation of a C*-algebra $A$ , which is the direct sum the GNS representations corresponding to each state $\rho\in S(A)$ . Let me denote it $\pi_u : A\to\mathcal{B}(H_u)$ . Certainly it's remarkably useful to know that every C*-algebra is *-isomorphic to a norm-closed subalgebra of some $\mathcal{B}(H)$ . However, I have yet to really see in what sense this representation is ""universal"". Why attach that qualifier? The tag ""universal"" suggests this representation has some relationship to all other (faithful?) representations $\pi : A\to\mathcal{B}(H)$ . The wikipedia entry on the universal representation says that if $\pi$ is any other representation, then there exists a ""projection $P$ in the center of $\overline{\pi_u(A)}$ (all closures will be taken wrt the weak operator topology), and a *-isomorphism $\alpha : \overline{\pi_u(A)}P\to\overline{\pi(A)}$ such that $$ \pi(a) = \alpha(\pi_u(a)P)\tag{*} $$ Wikipedia provides no reference for this result, which annoys me as I'd like to try to understand a few things: Where does this projection $P$ come from? Why is it necessary that it be in the center of $\overline{\pi_u(A)}$ ? Is (*)  the best we can do? The projection $P$ seems crucial, but it also muddles what would've otherwise been a simpler ""universality"" result, akin to the universality of, say, the Stone-Cech compactification. In particular, I was trying to prove that if $\pi_u$ admits a weak expectation (a unital, completely positive contraction $\varphi : \mathcal B(H)\to\overline{\pi_u(A)}$ such that $\varphi(\pi_u(a)) = \pi_u(a)$ for all $a$ ), then $\pi$ also admits a weak expectation. The proof would've been straightforward, if not for the projection $P$ , and I can't see how to ""get around it"". (I know now that you can prove this using Arveson's extension theorem, but $P$ still irks me). Is there a sense in which the universal representation is functorial? Can anyone help me understand what I'm missing?","Recently I started learning about the universal representation of a C*-algebra , which is the direct sum the GNS representations corresponding to each state . Let me denote it . Certainly it's remarkably useful to know that every C*-algebra is *-isomorphic to a norm-closed subalgebra of some . However, I have yet to really see in what sense this representation is ""universal"". Why attach that qualifier? The tag ""universal"" suggests this representation has some relationship to all other (faithful?) representations . The wikipedia entry on the universal representation says that if is any other representation, then there exists a ""projection in the center of (all closures will be taken wrt the weak operator topology), and a *-isomorphism such that Wikipedia provides no reference for this result, which annoys me as I'd like to try to understand a few things: Where does this projection come from? Why is it necessary that it be in the center of ? Is (*)  the best we can do? The projection seems crucial, but it also muddles what would've otherwise been a simpler ""universality"" result, akin to the universality of, say, the Stone-Cech compactification. In particular, I was trying to prove that if admits a weak expectation (a unital, completely positive contraction such that for all ), then also admits a weak expectation. The proof would've been straightforward, if not for the projection , and I can't see how to ""get around it"". (I know now that you can prove this using Arveson's extension theorem, but still irks me). Is there a sense in which the universal representation is functorial? Can anyone help me understand what I'm missing?","A \rho\in S(A) \pi_u : A\to\mathcal{B}(H_u) \mathcal{B}(H) \pi : A\to\mathcal{B}(H) \pi P \overline{\pi_u(A)} \alpha : \overline{\pi_u(A)}P\to\overline{\pi(A)} 
\pi(a) = \alpha(\pi_u(a)P)\tag{*}
 P \overline{\pi_u(A)} P \pi_u \varphi : \mathcal B(H)\to\overline{\pi_u(A)} \varphi(\pi_u(a)) = \pi_u(a) a \pi P P","['functional-analysis', 'representation-theory', 'operator-algebras', 'c-star-algebras']"
41,Proving an inequality for operators.,Proving an inequality for operators.,,"Let $\mathbb P_n$ be the space of all $n \times n$ self-adjoint positive definite matrices. Consider the function $\varphi: \mathbb P_n \longrightarrow \mathbb R$ defined by $$\varphi (A) = -\text {tr}\ (A \log A).$$ Show that for all $t \in (0,1)$ $$\varphi ((1 - t) A + t B) \leq (1 - t) \varphi (A) + t \varphi (B) - \eta (t,1-t)$$ where $\eta (t,1 - t) = t \log (t) + (1 - t) \log (1 - t).$ I know that $\varphi$ is operator concave. But I don't have any idea as to how to bound $\varphi$ from above. Could anyone please give me some hint? Thanks a bunch!",Let be the space of all self-adjoint positive definite matrices. Consider the function defined by Show that for all where I know that is operator concave. But I don't have any idea as to how to bound from above. Could anyone please give me some hint? Thanks a bunch!,"\mathbb P_n n \times n \varphi: \mathbb P_n \longrightarrow \mathbb R \varphi (A) = -\text {tr}\ (A \log A). t \in (0,1) \varphi ((1 - t) A + t B) \leq (1 - t) \varphi (A) + t \varphi (B) - \eta (t,1-t) \eta (t,1 - t) = t \log (t) + (1 - t) \log (1 - t). \varphi \varphi","['functional-analysis', 'convex-analysis', 'positive-definite', 'self-adjoint-operators', 'matrix-analysis']"
42,Mistaken proof that every bounded linear operator on $L^2$ has an integral kernel,Mistaken proof that every bounded linear operator on  has an integral kernel,L^2,"I have been staring at this for several hours already, still unable to find my own error. I know, it is embarassing, but I need your help to spot it, please. Thank you. Claim: Every bounded linear operator on $L^2$ has an integral kernel (and in fact is Hilbert-Schmidt). Proof: Let $(X,m)$ be a space with measure, and let $U : L^2(X) \to L^2(X)$ be a bounded linear operator. Define $I : L^2(X) \otimes _{alg} L^2(X) \to \mathbb C$ (the tensor product being the algebraic one, not the topological one) by $$I(f \otimes g) = \int _X f \ Ug \ \mathrm d m \ .$$ Notice that $I$ is linear and that, using the Cauchy-Schwarz inequality, $$|I (f \otimes g)| \le \| f \| _{L^2} \ \| Ug \| _{L^2} \le \| U \| \ \| f \| _{L^2} \ \| g \| _{L^2} = \| U \| \ \| f \otimes g \| _{L^2(X \times X)} \ ,$$ which means that we may extend $I$ by continuity to the whole of $L^2(X \times X)$ . By Riesz's theorem, it follows that there exists $k \in L^2 (X \times X)$ such that $I (F) = \int _{X \times X} \bar k \ F \ \mathrm d (m \times m)$ . In particular, if $F = f \otimes g$ , it follows that $$ \int _X f(x) \ (Ug)(x) \ \mathrm d m (x) = \int _X f(x) \left( \int _X \overline {k(x,y)} \ g(y) \ \mathrm d m (y) \right) \mathrm d m (x) \ ,$$ whence, since $f$ is arbitrary, it follows that $$ (Ug)(x) = \int _X \overline {k(x,y)} \ f(y) \ \mathrm d m (y) \ ,$$ for almost all $x$ , which is obviously not true. Where am I losing it?","I have been staring at this for several hours already, still unable to find my own error. I know, it is embarassing, but I need your help to spot it, please. Thank you. Claim: Every bounded linear operator on has an integral kernel (and in fact is Hilbert-Schmidt). Proof: Let be a space with measure, and let be a bounded linear operator. Define (the tensor product being the algebraic one, not the topological one) by Notice that is linear and that, using the Cauchy-Schwarz inequality, which means that we may extend by continuity to the whole of . By Riesz's theorem, it follows that there exists such that . In particular, if , it follows that whence, since is arbitrary, it follows that for almost all , which is obviously not true. Where am I losing it?","L^2 (X,m) U : L^2(X) \to L^2(X) I : L^2(X) \otimes _{alg} L^2(X) \to \mathbb C I(f \otimes g) = \int _X f \ Ug \ \mathrm d m \ . I |I (f \otimes g)| \le \| f \| _{L^2} \ \| Ug \| _{L^2} \le \| U \| \ \| f \| _{L^2} \ \| g \| _{L^2} = \| U \| \ \| f \otimes g \| _{L^2(X \times X)} \ , I L^2(X \times X) k \in L^2 (X \times X) I (F) = \int _{X \times X} \bar k \ F \ \mathrm d (m \times m) F = f \otimes g  \int _X f(x) \ (Ug)(x) \ \mathrm d m (x) = \int _X f(x) \left( \int _X \overline {k(x,y)} \ g(y) \ \mathrm d m (y) \right) \mathrm d m (x) \ , f  (Ug)(x) = \int _X \overline {k(x,y)} \ f(y) \ \mathrm d m (y) \ , x","['functional-analysis', 'measure-theory', 'operator-theory', 'hilbert-spaces', 'lp-spaces']"
43,Characterization of functions in the Sobolev space $H_0^2(U)$ as zero trace functions in $H^2(U)$,Characterization of functions in the Sobolev space  as zero trace functions in,H_0^2(U) H^2(U),"Firstly, I am wondering if there exists a trace operator $$T:H^2(U)\rightarrow L^2(\partial U)$$ such that it satisfies analogous properties to that of the usual trace operator for functions in $W^{1,p}(U)$ . Secondly, I would like to know if the functions $u\in H_0^2(U)$ are those characterized by the following two conditions $$Tu=0,\quad\frac{\partial u}{\partial\nu}=0\quad\text{on }\partial U$$ Motivation : In problem 3 of section 6 of Evans' PDE book, second edition, it is asserted that the weak formulation corresponding to the boundary problem of the biharmonic equation $$\begin{cases} 		\Delta^2u&=f\quad\text{in }U\\ 		u=\frac{\partial u}{\partial\nu}&=0\quad\text{on }\partial U\end{cases}$$ is $$\int_U\Delta u\Delta vdx=\int_U fv$$ for each $v\in H_0^2(U)$ . However, if we want to derive the latter identity, after integrating the equation of the problem, we find out through the third Green identity, that $$\int_U\Delta^2uvdx=\int_U\Delta u\Delta vdx+\int_{\partial U}v\frac{\partial\Delta u}{\partial\nu}dS-\int_{\partial U}\Delta u\frac{\partial v}{\partial\nu}dS$$ In order to obtain the idenity proposed by Evans, we have to impose the boundary conditions $$\frac{\partial v}{\partial\nu}=0,\quad v=0\quad\text{on}\partial U$$ for every $v$ in our space of weak solutions. However, how can we conclude that this completely characterizes functions in $H_0^2(U)$ ? I understand this should be a characterization of such a space, and via aproximation by functions with compact support I can get an idea of why this must be the case, but there is no mention of this fact in Evans' book. I would like to have some references to learn more about this, and the notion of the trace operator extended to other Sobolev spaces, because I am only familiar with the aforementioned book. Thanks in advance for your answers.","Firstly, I am wondering if there exists a trace operator such that it satisfies analogous properties to that of the usual trace operator for functions in . Secondly, I would like to know if the functions are those characterized by the following two conditions Motivation : In problem 3 of section 6 of Evans' PDE book, second edition, it is asserted that the weak formulation corresponding to the boundary problem of the biharmonic equation is for each . However, if we want to derive the latter identity, after integrating the equation of the problem, we find out through the third Green identity, that In order to obtain the idenity proposed by Evans, we have to impose the boundary conditions for every in our space of weak solutions. However, how can we conclude that this completely characterizes functions in ? I understand this should be a characterization of such a space, and via aproximation by functions with compact support I can get an idea of why this must be the case, but there is no mention of this fact in Evans' book. I would like to have some references to learn more about this, and the notion of the trace operator extended to other Sobolev spaces, because I am only familiar with the aforementioned book. Thanks in advance for your answers.","T:H^2(U)\rightarrow L^2(\partial U) W^{1,p}(U) u\in H_0^2(U) Tu=0,\quad\frac{\partial u}{\partial\nu}=0\quad\text{on }\partial U \begin{cases}
		\Delta^2u&=f\quad\text{in }U\\
		u=\frac{\partial u}{\partial\nu}&=0\quad\text{on }\partial U\end{cases} \int_U\Delta u\Delta vdx=\int_U fv v\in H_0^2(U) \int_U\Delta^2uvdx=\int_U\Delta u\Delta vdx+\int_{\partial U}v\frac{\partial\Delta u}{\partial\nu}dS-\int_{\partial U}\Delta u\frac{\partial v}{\partial\nu}dS \frac{\partial v}{\partial\nu}=0,\quad v=0\quad\text{on}\partial U v H_0^2(U)","['functional-analysis', 'partial-differential-equations', 'reference-request', 'sobolev-spaces', 'trace-map']"
44,Orthogonality of generalized eigenbases of self-adjoint operators,Orthogonality of generalized eigenbases of self-adjoint operators,,"As mentioned in another of my recent questions , given some operator on a Hilbert space, we can construct a Gelfand triple in order to ""recover"" eigenfunctions corresponding to elements of the spectrum which do not strictly have corresponding eigenfunctions in the Hilbert space ""proper."" For example, the momentum operator $i\frac{d}{dx}$ has no ""proper"" eigenfunctions in $L_2(\mathbb{R})$ , but it does have sinusoidal eigenfunctions in the Gelfand triple $H^s(\mathbb{R}) \subseteq L_2(\mathbb{R}) \subseteq H^{-s}(\mathbb{R})$ . In the finite-dimensional case, we have a theorem that every Hermitian operator has an orthogonal eigenbasis. Does this generalize to the infinite-dimensional case of self-adjoint operators? Immediately, we encounter a problem: the sinusoids $t \to e^{ikt}$ are not ""proper"" elements of $L_2(\mathbb{R})$ (they fail to be square-integrable).  So, we cannot say precisely that these eigenfunctions are orthogonal with respect to the inner product on the Hilbert space.  Can we state something weaker? Perhaps we can recover a notion of ""limiting orthogonality"" by approximating our eigenfunctions with sequences of functions that are elements of $L_2(\mathbb{R})$ (e.g. approximating a sinusoid by a sequence of sinc functions with slower and slower decay)?  Maybe there's some other approach entirely?  Or is this a doomed endeavor, and there is no useful generalization to be found?","As mentioned in another of my recent questions , given some operator on a Hilbert space, we can construct a Gelfand triple in order to ""recover"" eigenfunctions corresponding to elements of the spectrum which do not strictly have corresponding eigenfunctions in the Hilbert space ""proper."" For example, the momentum operator has no ""proper"" eigenfunctions in , but it does have sinusoidal eigenfunctions in the Gelfand triple . In the finite-dimensional case, we have a theorem that every Hermitian operator has an orthogonal eigenbasis. Does this generalize to the infinite-dimensional case of self-adjoint operators? Immediately, we encounter a problem: the sinusoids are not ""proper"" elements of (they fail to be square-integrable).  So, we cannot say precisely that these eigenfunctions are orthogonal with respect to the inner product on the Hilbert space.  Can we state something weaker? Perhaps we can recover a notion of ""limiting orthogonality"" by approximating our eigenfunctions with sequences of functions that are elements of (e.g. approximating a sinusoid by a sequence of sinc functions with slower and slower decay)?  Maybe there's some other approach entirely?  Or is this a doomed endeavor, and there is no useful generalization to be found?",i\frac{d}{dx} L_2(\mathbb{R}) H^s(\mathbb{R}) \subseteq L_2(\mathbb{R}) \subseteq H^{-s}(\mathbb{R}) t \to e^{ikt} L_2(\mathbb{R}) L_2(\mathbb{R}),"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
45,Operator targeting $\ell^2$-direct sum of Hilbert spaces continuous if all its projections are continuous?,Operator targeting -direct sum of Hilbert spaces continuous if all its projections are continuous?,\ell^2,"Let $(U, \|\cdot\|_U)$ be a Banach space, $(H_k, \|\cdot\|_k)_{k\in\mathbb{N}}$ be a sequence of Hilbert spaces and denote by $$\tag{1}H:=\bigoplus_{k=1}^\infty H_k \equiv \left\{h=(h_k)\ \middle| \ h_k \in H_k, \,\forall k\in\mathbb{N} \quad \text{and} \quad \|h\|_H^2:=\sum_{k=1}^\infty\|h_k\|_k^2 < \infty \right\}$$ the $\ell^2$ -direct sum of these spaces (which is known to be a Hilbert space itself). Let further $\pi_k : H \rightarrow H_k$ , $\pi_k((h_k)) := h_k$ , be the projection of $H$ onto its $k^{\mathrm{th}}$ -component. Question: Is it true, then, that a (not necessarily linear) map $T : U \rightarrow H$ is $\textit{continuous}$ if its projections $$\tag{2}T_k := \pi_k\circ T \quad \text{are continuous} \quad \text{for each } \ k\in\mathbb{N}?$$ Remark: If necessary, it may be assumed that each of the $H_k$ are finite-dimensional. Any references, hints or proofs (or indeed counterexamples) that cover this are appreciated! (This is not a homework question.)","Let be a Banach space, be a sequence of Hilbert spaces and denote by the -direct sum of these spaces (which is known to be a Hilbert space itself). Let further , , be the projection of onto its -component. Question: Is it true, then, that a (not necessarily linear) map is if its projections Remark: If necessary, it may be assumed that each of the are finite-dimensional. Any references, hints or proofs (or indeed counterexamples) that cover this are appreciated! (This is not a homework question.)","(U, \|\cdot\|_U) (H_k, \|\cdot\|_k)_{k\in\mathbb{N}} \tag{1}H:=\bigoplus_{k=1}^\infty H_k \equiv \left\{h=(h_k)\ \middle| \ h_k \in H_k, \,\forall k\in\mathbb{N} \quad \text{and} \quad \|h\|_H^2:=\sum_{k=1}^\infty\|h_k\|_k^2 < \infty \right\} \ell^2 \pi_k : H \rightarrow H_k \pi_k((h_k)) := h_k H k^{\mathrm{th}} T : U \rightarrow H \textit{continuous} \tag{2}T_k := \pi_k\circ T \quad \text{are continuous} \quad \text{for each } \ k\in\mathbb{N}? H_k","['functional-analysis', 'continuity', 'operator-theory', 'hilbert-spaces', 'operator-algebras']"
46,Weak Convergence in Infinite Hilbert space,Weak Convergence in Infinite Hilbert space,,"Let $H$ be an infinite Hilbert space. Show: For all $x \in H$ with $\|x\|\leq1$ , there exists a sequence $(u_n)$ in $H$ with $\| u_n\|=1 $ such that $u_n \rightharpoonup x$ . My attempt: Since $H$ is infinite, there exists a countable subspace $K$ with $x\in K$ . By Gram-Schmidt, we can find a orthonormal basis $(y_n)$ for $K$ . Hence, $x=\sum_{k=1}^\infty a_k y_k$ for some $a_k \in \mathbb{F}$ Let $u_n= \frac {\sum_{k=1}^n a_k y_k}{\|\sum_{k=1}^n a_k y_k \|}$ . Then $\| u_n\|=1$ . Hence, we are done. Could someone please check my proof, and let me know if it makes sense? If not, could you please let me know where it went wrong? Thanks!","Let be an infinite Hilbert space. Show: For all with , there exists a sequence in with such that . My attempt: Since is infinite, there exists a countable subspace with . By Gram-Schmidt, we can find a orthonormal basis for . Hence, for some Let . Then . Hence, we are done. Could someone please check my proof, and let me know if it makes sense? If not, could you please let me know where it went wrong? Thanks!",H x \in H \|x\|\leq1 (u_n) H \| u_n\|=1  u_n \rightharpoonup x H K x\in K (y_n) K x=\sum_{k=1}^\infty a_k y_k a_k \in \mathbb{F} u_n= \frac {\sum_{k=1}^n a_k y_k}{\|\sum_{k=1}^n a_k y_k \|} \| u_n\|=1,"['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
47,If $H^*$ is isomorphic with $H$ is H always a Hilbert space?,If  is isomorphic with  is H always a Hilbert space?,H^* H,"If $H$ is a Hilbert space then $H^*$ is isomorphic with $H$ . I am asking if we have a vector space H equipped with inner product ( , ) and $H^*$ is isomorphic with $H$ is it true to say that $H$ is Hilbert? Edit:I am also interested for cases that the norm of H is not the ordinary norm given from inner product","If is a Hilbert space then is isomorphic with . I am asking if we have a vector space H equipped with inner product ( , ) and is isomorphic with is it true to say that is Hilbert? Edit:I am also interested for cases that the norm of H is not the ordinary norm given from inner product",H H^* H H^* H H,"['functional-analysis', 'hilbert-spaces']"
48,Question about functionals on $L^p$ spaces,Question about functionals on  spaces,L^p,"Suppose $(X,\mathcal A,\mu)$ be a compact topological space with a regular Borel measure $\mu$ . In particular $\mu$ is a finite measure. Assume $f\in L^1(X)$ .Suppose $1\leq p<\infty$ and $D\subset L^p(X)$ is a dense subset. Assume that the map $$T_f:D\rightarrow \mathbb C$$ $$h\mapsto \int_Xhfd\mu $$ is a bounded linear functional. Then is $f$ necessarily in $L^{p'}$ where $\frac{1}{p}+\frac{1}{p'}=1$ ? I know that $T_f$ extends uniquely to a bounded linear functional $$T_f:L^p(X)\rightarrow \mathbb C$$ So $\exists! \ g\in L^{p'}(X)$ such that $T_f(h)=\displaystyle\int_Xhgd\mu=T_g(h) $ Since $C(X)\hookrightarrow L^p(X)$ is continuous, we get $T_f,T_g\in C(X)^*=\mathcal M(X)$ , the space of regular complex Borel measures. The corresponding complex measures are $$\mu_f(K)=\displaystyle\int_K fd\mu $$ $$\mu_g(K)=\displaystyle\int_K gd\mu $$ But $T_f, T_g$ agree on $C(X)$ and hence $\mu_g=\mu_f$ i.e. for all $K\subset X$ , compact $$\int_K fd\mu=\int_K g d\mu $$ $$\implies f=g \ \text{a.e.}$$ In particular $f\in L^{p'}(X)$ . I hope this is an okay solution. I would be glad if someone can give an alterbative solution without using complex measures.","Suppose be a compact topological space with a regular Borel measure . In particular is a finite measure. Assume .Suppose and is a dense subset. Assume that the map is a bounded linear functional. Then is necessarily in where ? I know that extends uniquely to a bounded linear functional So such that Since is continuous, we get , the space of regular complex Borel measures. The corresponding complex measures are But agree on and hence i.e. for all , compact In particular . I hope this is an okay solution. I would be glad if someone can give an alterbative solution without using complex measures.","(X,\mathcal A,\mu) \mu \mu f\in L^1(X) 1\leq p<\infty D\subset L^p(X) T_f:D\rightarrow \mathbb C h\mapsto \int_Xhfd\mu  f L^{p'} \frac{1}{p}+\frac{1}{p'}=1 T_f T_f:L^p(X)\rightarrow \mathbb C \exists! \ g\in L^{p'}(X) T_f(h)=\displaystyle\int_Xhgd\mu=T_g(h)  C(X)\hookrightarrow L^p(X) T_f,T_g\in C(X)^*=\mathcal M(X) \mu_f(K)=\displaystyle\int_K fd\mu  \mu_g(K)=\displaystyle\int_K gd\mu  T_f, T_g C(X) \mu_g=\mu_f K\subset X \int_K fd\mu=\int_K g d\mu  \implies f=g \ \text{a.e.} f\in L^{p'}(X)","['functional-analysis', 'analysis', 'measure-theory', 'solution-verification', 'alternative-proof']"
49,Proof that a minimum problem has no solution,Proof that a minimum problem has no solution,,"Please I have an exam in a few days, can you help me with the following exercise? Let $A=\{x\in\mathbb{R}^2: 1<|x|<2\}$ and $M\geqslant 0$ . On the set $\mathcal{A}_{M}=\{u\in C(\bar{A})\cap C^1(A):u=0 \text{ on } |x| \text{ and } u=M \text{ on } |x|=1\}$ consider the area functional: \begin{equation*} F:\mathcal{A}_{M}\to[0,\infty] \end{equation*} \begin{equation*} F(u)=\int_A\sqrt{1+|\nabla u(x)|^{2}} \, dx \end{equation*} I have to prove the following statement: 3) There exists $M_0$ such that for $M>M_0$ the minimum problem has no solution in the class $\mathcal{A}_M$ Solution: I've computed the Euler Lagrange equation in the strong form for the functional: \begin{equation*} F(\phi)= 2\pi\int_1^2 \sqrt{1+\phi'(r)}rdr \end{equation*} Obtained from the previous one using the fact that $u$ is radial and computing a change of variables with polar coordinates. The explicit solution of the strong form of the Euler Lagrange equation is: \begin{equation*} \phi(r)=\phi(1)-\int_1^r \dfrac{C}{\sqrt{t^2-C^2}}=M-\log\bigg({\dfrac{x+\sqrt{x^2-C^2}}{1+\sqrt{1-C^2}}}\bigg) \end{equation*} $C$ is a real constant. Can someone help me to find an appropriate concusion of this proof?","Please I have an exam in a few days, can you help me with the following exercise? Let and . On the set consider the area functional: I have to prove the following statement: 3) There exists such that for the minimum problem has no solution in the class Solution: I've computed the Euler Lagrange equation in the strong form for the functional: Obtained from the previous one using the fact that is radial and computing a change of variables with polar coordinates. The explicit solution of the strong form of the Euler Lagrange equation is: is a real constant. Can someone help me to find an appropriate concusion of this proof?","A=\{x\in\mathbb{R}^2: 1<|x|<2\} M\geqslant 0 \mathcal{A}_{M}=\{u\in C(\bar{A})\cap C^1(A):u=0 \text{ on } |x| \text{ and } u=M \text{ on } |x|=1\} \begin{equation*}
F:\mathcal{A}_{M}\to[0,\infty]
\end{equation*} \begin{equation*}
F(u)=\int_A\sqrt{1+|\nabla u(x)|^{2}} \, dx
\end{equation*} M_0 M>M_0 \mathcal{A}_M \begin{equation*}
F(\phi)= 2\pi\int_1^2 \sqrt{1+\phi'(r)}rdr
\end{equation*} u \begin{equation*}
\phi(r)=\phi(1)-\int_1^r \dfrac{C}{\sqrt{t^2-C^2}}=M-\log\bigg({\dfrac{x+\sqrt{x^2-C^2}}{1+\sqrt{1-C^2}}}\bigg)
\end{equation*} C","['functional-analysis', 'analysis', 'calculus-of-variations', 'functional-calculus']"
50,Can weak convergence of probability measures be characterized by countably many functions without having a limit a priori?,Can weak convergence of probability measures be characterized by countably many functions without having a limit a priori?,,"Let $(\mu_n)_{n \geq 1}$ be a sequence of Borel probability measures on $\mathbb{R}^d$ . I'd like to know the following: Does there exist a countable family $(f_k)_{k \geq 1}$ of continuous, bounded real-valued functions with the following property: If $\text{lim}_{n}\int f_k d\mu_n$ exists in $\mathbb{R}$ for each $k \geq 1$ , then there exists a unique Borel probability measure $\mu$ such that $\mu_n \underset{n \to \infty}{\longrightarrow} \mu$ weakly? Clearly, it'd be sufficient to take a countable, dense subset of $C_b(\mathbb{R}^d)$ - only problem, such set doesn't exist ;-). On the other hand, the Riesz-Markov-representation theorem shows that a dense countable subset of $C_0(\mathbb{R}^d)$ (the continuous functions vanishing at infinity) [which exists - $C_0$ is separable] is ""too small"" in the sense that it allows mass to spread out at infinity, which yields that the limit measure $\mu$ is in general only a sub-probability measure. Next, I was thinking about the uniformly continuous bounded functions - but again: not separable. Next thought: Consider the vector space spanned by $C_0$ and $1$ . But for this vector lattice, the positive, linear, normalized functional $J: f \mapsto \text{lim}_n\int f d\mu_n$ is not continuous (also called $\sigma$ -continuous), meaning it does not hold $f_l \to 0$ pointwise decreasing from above $\implies$ $J(f) \to 0$ (which is, however, true for the vector lattice $C_0$ , which is essential for the proof of Riesz-Markov representation). Hence the classical Daniell-Stone theory does not apply, so we cannot obtain the desired limit measure (at least not by this method). Any comment or help on this is much appreciated!","Let be a sequence of Borel probability measures on . I'd like to know the following: Does there exist a countable family of continuous, bounded real-valued functions with the following property: If exists in for each , then there exists a unique Borel probability measure such that weakly? Clearly, it'd be sufficient to take a countable, dense subset of - only problem, such set doesn't exist ;-). On the other hand, the Riesz-Markov-representation theorem shows that a dense countable subset of (the continuous functions vanishing at infinity) [which exists - is separable] is ""too small"" in the sense that it allows mass to spread out at infinity, which yields that the limit measure is in general only a sub-probability measure. Next, I was thinking about the uniformly continuous bounded functions - but again: not separable. Next thought: Consider the vector space spanned by and . But for this vector lattice, the positive, linear, normalized functional is not continuous (also called -continuous), meaning it does not hold pointwise decreasing from above (which is, however, true for the vector lattice , which is essential for the proof of Riesz-Markov representation). Hence the classical Daniell-Stone theory does not apply, so we cannot obtain the desired limit measure (at least not by this method). Any comment or help on this is much appreciated!",(\mu_n)_{n \geq 1} \mathbb{R}^d (f_k)_{k \geq 1} \text{lim}_{n}\int f_k d\mu_n \mathbb{R} k \geq 1 \mu \mu_n \underset{n \to \infty}{\longrightarrow} \mu C_b(\mathbb{R}^d) C_0(\mathbb{R}^d) C_0 \mu C_0 1 J: f \mapsto \text{lim}_n\int f d\mu_n \sigma f_l \to 0 \implies J(f) \to 0 C_0,"['functional-analysis', 'probability-theory', 'measure-theory', 'weak-convergence']"
51,The spectrum of the Volterra operator is $\{0\}$,The spectrum of the Volterra operator is,\{0\},I'm asked to prove that the spectrum of the Volterra operator $$V(f(x))= \int_0^x f(y)dy$$ given by $$ \sigma (V)= \{ \lambda \in \mathbb{C} | V-\lambda1 \text{ is not invertible} \}$$ contains only zero. This needs to be done by first showing that $0 \in \sigma (V)$ and then that all other complex numbers cannot belong to the spectrum. I don't see how to prove either one of those steps so any hints would really help.,I'm asked to prove that the spectrum of the Volterra operator given by contains only zero. This needs to be done by first showing that and then that all other complex numbers cannot belong to the spectrum. I don't see how to prove either one of those steps so any hints would really help.,V(f(x))= \int_0^x f(y)dy  \sigma (V)= \{ \lambda \in \mathbb{C} | V-\lambda1 \text{ is not invertible} \} 0 \in \sigma (V),"['functional-analysis', 'operator-theory']"
52,The RKHS with kernel $\exp\{x y\}$,The RKHS with kernel,\exp\{x y\},"I would like to understand the reproducing kernel Hilbert space (RKHS) $\mathcal{H}$ of real valued functions defined on $\mathbb{R}$ generated by or associated with the kernel $$ K(x,y) = \exp\{x y\} \text{ for }x,y\in\mathbb{R}.$$ This is a ""real"" version of Segal-Bargmann space but I am not sure what properties carry over from the complex setting. Questions What are the functions contained in $\mathcal{H}$ ? Can they be characterised by an integral conditions such as for Segal-Bargmann? Is there an orthonormal Eigenbasis from Mercer's theorem, even though the domain of $K$ is non-compact and the kernel not bounded? Is there an explicit form for the Eigenbasis?","I would like to understand the reproducing kernel Hilbert space (RKHS) of real valued functions defined on generated by or associated with the kernel This is a ""real"" version of Segal-Bargmann space but I am not sure what properties carry over from the complex setting. Questions What are the functions contained in ? Can they be characterised by an integral conditions such as for Segal-Bargmann? Is there an orthonormal Eigenbasis from Mercer's theorem, even though the domain of is non-compact and the kernel not bounded? Is there an explicit form for the Eigenbasis?","\mathcal{H} \mathbb{R}  K(x,y) = \exp\{x y\} \text{ for }x,y\in\mathbb{R}. \mathcal{H} K","['complex-analysis', 'functional-analysis', 'hilbert-spaces', 'reproducing-kernel-hilbert-spaces']"
53,Von Neumann Algebras and Convergence in the Strong$^\star$ Topology,Von Neumann Algebras and Convergence in the Strong Topology,^\star,"Let $\mathbb{A}$ be a von Neumann algebra, and let $f : \mathbb{A} \rightarrow \mathbb{A}$ be an ultra-continuous mapping (normal mapping) and let $(x_n)_{n\in \mathbb{N}}$ be a bounded sequence of $\mathbb{A}$ such that $x_n \rightarrow x$ in the strong $^\star$ topology. In this case, can it be inferred that the sequence $(f(x_n))_{n\in \mathbb{N}}$ is convergent in the strong $^\star$ topology to $f(x)$ ?","Let be a von Neumann algebra, and let be an ultra-continuous mapping (normal mapping) and let be a bounded sequence of such that in the strong topology. In this case, can it be inferred that the sequence is convergent in the strong topology to ?",\mathbb{A} f : \mathbb{A} \rightarrow \mathbb{A} (x_n)_{n\in \mathbb{N}} \mathbb{A} x_n \rightarrow x ^\star (f(x_n))_{n\in \mathbb{N}} ^\star f(x),"['functional-analysis', 'functions', 'operator-algebras', 'von-neumann-algebras']"
54,Hyperplanes and convex sets in Hilbert space,Hyperplanes and convex sets in Hilbert space,,"The simplest Hahn-Banach extension theorem in Hilbert space $X$ avoids the use of the axiom of choice by virtue of the Riesz representation theorem. But what about the version of the theorem where the sought-for linear functional is required to remain below a given sub-linear or convex function? Also, to which extent can we separate 2 disjoint convex sets by a hyperplane without Zorn? Can we assert that any hyperplane $H\subset X$ has a translate that is tangent to a given bounded closed convex subset $C\subset X$ ?","The simplest Hahn-Banach extension theorem in Hilbert space avoids the use of the axiom of choice by virtue of the Riesz representation theorem. But what about the version of the theorem where the sought-for linear functional is required to remain below a given sub-linear or convex function? Also, to which extent can we separate 2 disjoint convex sets by a hyperplane without Zorn? Can we assert that any hyperplane has a translate that is tangent to a given bounded closed convex subset ?",X H\subset X C\subset X,"['functional-analysis', 'convex-analysis', 'hahn-banach-theorem']"
55,Why does weak-$L^2$ convergence not imply pointwise convergence for continuous functions?,Why does weak- convergence not imply pointwise convergence for continuous functions?,L^2,"This question shows that $L^2$ convergence does not show pointwise convergence, even when the functions involved are continuous.  This strongly contradicts my intuition, because I thought that weak- $L^2$ convergence sufficed for the same. What is wrong with the following proof? Let $\{\psi_\delta\}_{\delta}$ be approximate identities and continuous $\{f_n\}\rightharpoonup f_{\infty}$ in $L^2$ .  We claim $f_{\infty}(0)=\lim_{n\to\infty}{f_n(0)}$ . To see this, fix $\epsilon$ .  There exists $\alpha$ such that for any $\delta<\alpha$ and continuous $g$ , $$\epsilon>|g(0)-\langle g,\psi_{\delta}\rangle|$$ For such $\delta$ , then, $$\epsilon+\langle g,\psi_{\delta}\rangle>g(0)$$ Now let $g=|f_{\infty}-f_n|$ ; we have $$\epsilon+\langle|f_{\infty}-f_n|,\psi_{\delta}\rangle>|f_{\infty}(0)-f_n(0)|$$ As $\{f_n\}\rightharpoonup f_{\infty}$ , we have $\lim_{n\to\infty}{\langle|f_{\infty}-f_n|,\psi_{\delta}\rangle}=0$ for any $\delta$ .  So take $n\to\infty$ ; we obtain $$\epsilon>\limsup_{n\to\infty}{|f_{\infty}(0)-f_n(0)|}$$ Now take $\epsilon\to0^+$ . Worked example We can test this with the example from the cited question: in $L^2([0,1])\cap C([0,1])$ , take $f_n(x)=\ln{\!(n)}e^{-nx}$ and $\psi_{\delta}(x)=\frac{1}{\delta}\chi_{[0,1]}\left(\frac{x}{\delta}\right)$ .  As $n\to\infty$ , $$\|f_n\|_2=\ln{(n)}\sqrt{\frac{1-e^{-2n}}{2n}}\to0$$ so $\{f_n\}_n\to0$ , and thus $\{f_n\}_n\rightharpoonup0$ . $f_n(0)=\ln{(n)}$ , so we should expect $$\lim_{\delta\to0^+}{\int_0^1{f_n(x)\psi_{\delta}(x)\,dx}}=\ln{(n)}$$ On the other hand, weak convergence should give $$\lim_{n\to\infty}{\int_0^1{f_n(x)\psi_{\delta}(x)\,dx}}=\int_0^1{0\cdot\psi_{\delta}(x)\,dx}=0$$ Well, $$\int_0^1{f_n(x)\psi_{\delta}(x)\,dx}=\frac{\ln{(n)}(1-e^{-n\delta})}{n\delta}$$ Taking $n\to\infty$ does yield $0$ , and $\delta\to0^+$ yields $\ln{(n)}$ !  What gives?","This question shows that convergence does not show pointwise convergence, even when the functions involved are continuous.  This strongly contradicts my intuition, because I thought that weak- convergence sufficed for the same. What is wrong with the following proof? Let be approximate identities and continuous in .  We claim . To see this, fix .  There exists such that for any and continuous , For such , then, Now let ; we have As , we have for any .  So take ; we obtain Now take . Worked example We can test this with the example from the cited question: in , take and .  As , so , and thus . , so we should expect On the other hand, weak convergence should give Well, Taking does yield , and yields !  What gives?","L^2 L^2 \{\psi_\delta\}_{\delta} \{f_n\}\rightharpoonup f_{\infty} L^2 f_{\infty}(0)=\lim_{n\to\infty}{f_n(0)} \epsilon \alpha \delta<\alpha g \epsilon>|g(0)-\langle g,\psi_{\delta}\rangle| \delta \epsilon+\langle g,\psi_{\delta}\rangle>g(0) g=|f_{\infty}-f_n| \epsilon+\langle|f_{\infty}-f_n|,\psi_{\delta}\rangle>|f_{\infty}(0)-f_n(0)| \{f_n\}\rightharpoonup f_{\infty} \lim_{n\to\infty}{\langle|f_{\infty}-f_n|,\psi_{\delta}\rangle}=0 \delta n\to\infty \epsilon>\limsup_{n\to\infty}{|f_{\infty}(0)-f_n(0)|} \epsilon\to0^+ L^2([0,1])\cap C([0,1]) f_n(x)=\ln{\!(n)}e^{-nx} \psi_{\delta}(x)=\frac{1}{\delta}\chi_{[0,1]}\left(\frac{x}{\delta}\right) n\to\infty \|f_n\|_2=\ln{(n)}\sqrt{\frac{1-e^{-2n}}{2n}}\to0 \{f_n\}_n\to0 \{f_n\}_n\rightharpoonup0 f_n(0)=\ln{(n)} \lim_{\delta\to0^+}{\int_0^1{f_n(x)\psi_{\delta}(x)\,dx}}=\ln{(n)} \lim_{n\to\infty}{\int_0^1{f_n(x)\psi_{\delta}(x)\,dx}}=\int_0^1{0\cdot\psi_{\delta}(x)\,dx}=0 \int_0^1{f_n(x)\psi_{\delta}(x)\,dx}=\frac{\ln{(n)}(1-e^{-n\delta})}{n\delta} n\to\infty 0 \delta\to0^+ \ln{(n)}","['functional-analysis', 'continuity', 'weak-convergence', 'fake-proofs']"
56,On the definition of Schwartz functions,On the definition of Schwartz functions,,"$$ \mathcal{S}(\mathbb{R}^{n})=\Big\{f\in C^{\infty}(\mathbb{R}^{n})\,\Big|\; \sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|<\infty\, \forall \alpha,\beta\, \text{multi indexes}\Big\}. $$ I can't find why is necessary the derivate condition; can you give me an example of a function such that $\sup_{\mathbb{R}^{n}}|x^{\alpha}f(x)| < \infty \,\forall \alpha \,\text{multi index}$ but exists $\beta$ such that $\sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|=\infty$ ?",I can't find why is necessary the derivate condition; can you give me an example of a function such that but exists such that ?,"
\mathcal{S}(\mathbb{R}^{n})=\Big\{f\in C^{\infty}(\mathbb{R}^{n})\,\Big|\; \sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|<\infty\, \forall \alpha,\beta\, \text{multi indexes}\Big\}.
 \sup_{\mathbb{R}^{n}}|x^{\alpha}f(x)| < \infty \,\forall \alpha \,\text{multi index} \beta \sup_{\mathbb{R}^{n}}|x^{\alpha}D^{\beta}f(x)|=\infty","['functional-analysis', 'definition', 'schwartz-space']"
57,"A strange norm in the polynomial space $\mathbb{P}[0,1]$. A contradiction?",A strange norm in the polynomial space . A contradiction?,"\mathbb{P}[0,1]","Let us define a norm $\|f\|=\sup_{k\geq 0}\sup_{t\in [0,1]}|f^{(k)}(t)|$. It is easy to see that in the polynomial space $\mathbb{P}[0,1]$ space, the norm $\|\|$ is well-defined. What is the dimension of the completion of $(\mathbb{P}[0,1],\|\|)$ under this norm ? It seems to be finite dimensional, because one can show that the unit ball in this new Banach space $X$ is compact as follows: We only need to show that every bounded sequence $\{f_n\}$ in $X$ has a convergent subsequence. That is a repeated application of the Ascoli-Arzelà theorem and Cantor's diagonal argument; the boundedness of $\{f^{(k+1)}_n\}$ implies the equicontinuity of $\{ f^{(k)}_n\}$. For details of this argument, we can refer to Is there no norm in $C^\infty ([a,b])$? Since it is a normed space with Montel-Heine-Borel property, it has to be finite dimensional. On the other hand,  $\mathbb{P}[0,1]$ is already infinite dimensional. Then $X$ has to be at least infinite dimensional. Something must be wrong. references: Every normed space has a completion?","Let us define a norm $\|f\|=\sup_{k\geq 0}\sup_{t\in [0,1]}|f^{(k)}(t)|$. It is easy to see that in the polynomial space $\mathbb{P}[0,1]$ space, the norm $\|\|$ is well-defined. What is the dimension of the completion of $(\mathbb{P}[0,1],\|\|)$ under this norm ? It seems to be finite dimensional, because one can show that the unit ball in this new Banach space $X$ is compact as follows: We only need to show that every bounded sequence $\{f_n\}$ in $X$ has a convergent subsequence. That is a repeated application of the Ascoli-Arzelà theorem and Cantor's diagonal argument; the boundedness of $\{f^{(k+1)}_n\}$ implies the equicontinuity of $\{ f^{(k)}_n\}$. For details of this argument, we can refer to Is there no norm in $C^\infty ([a,b])$? Since it is a normed space with Montel-Heine-Borel property, it has to be finite dimensional. On the other hand,  $\mathbb{P}[0,1]$ is already infinite dimensional. Then $X$ has to be at least infinite dimensional. Something must be wrong. references: Every normed space has a completion?",,"['functional-analysis', 'fake-proofs']"
58,"Searching for a proof that in a normed functional space of $C^0[0,1]$ with sup norm, that norm is nowhere differentiable.","Searching for a proof that in a normed functional space of  with sup norm, that norm is nowhere differentiable.","C^0[0,1]","Having a normed linear space $S=C^0[0,1]$ of continuous functions $f:[0,1] \rightarrow \Bbb R%$, with sup norm: $\|f\|=\sup_{\space x \in [0,1]}|f(x)|$, prove that $F(f)=\|f\|$ is nowhere differentiable in $S$, that is, for all $f_0 \in S$, there is no linear operator $A:S \rightarrow \Bbb R$ such that : $$\lim_{\space \|h\| \rightarrow 0} \frac{\|F(f_0-h)-F(f_0)-A(h)\|}{\|h\|}=0$$ where $h \in S$. Could someone state the proof, or link to it?","Having a normed linear space $S=C^0[0,1]$ of continuous functions $f:[0,1] \rightarrow \Bbb R%$, with sup norm: $\|f\|=\sup_{\space x \in [0,1]}|f(x)|$, prove that $F(f)=\|f\|$ is nowhere differentiable in $S$, that is, for all $f_0 \in S$, there is no linear operator $A:S \rightarrow \Bbb R$ such that : $$\lim_{\space \|h\| \rightarrow 0} \frac{\|F(f_0-h)-F(f_0)-A(h)\|}{\|h\|}=0$$ where $h \in S$. Could someone state the proof, or link to it?",,"['functional-analysis', 'functional-calculus']"
59,spectral projector of the Laplacian on $\mathbb{R}^d$,spectral projector of the Laplacian on,\mathbb{R}^d,"I have been reading some notes on spectral theorem for unbounded operator on Hilbert spaces and my toy example is the Laplacian on $\mathbb{R}^d$. The author says that as an ""application"" one can define the spectral projector of the operator. For the Laplacian on $\mathbb{R}^d$ the spectral projector is  $$ \chi_{[0, a]}(-\Delta)$$ where $\chi_A$ denotes the characteristic function of a set $A$, subset of the its spectrum, i.e. of $[0,\infty)$. Then, I saw the claim $$\chi_{[0, a]}(-\Delta): L^2(\mathbb{R}^d)\rightarrow E_a$$ where $E_a$ is the subspace of all $L^2(\mathbb{R}^d)$-functions with Fourier Transform supported in $[-a,a]^d$. I am trying to figure out now what $\chi_{[0, a]}(-\Delta) f$ for any $L^2$-function $f$ is but I am lost. Can anybody explain me that? I understand that in some sense the spectral projector gets rid of all the eigenvalues bigger than $a$, but what this has to do with Fourier Transform? Any help is welcome.","I have been reading some notes on spectral theorem for unbounded operator on Hilbert spaces and my toy example is the Laplacian on $\mathbb{R}^d$. The author says that as an ""application"" one can define the spectral projector of the operator. For the Laplacian on $\mathbb{R}^d$ the spectral projector is  $$ \chi_{[0, a]}(-\Delta)$$ where $\chi_A$ denotes the characteristic function of a set $A$, subset of the its spectrum, i.e. of $[0,\infty)$. Then, I saw the claim $$\chi_{[0, a]}(-\Delta): L^2(\mathbb{R}^d)\rightarrow E_a$$ where $E_a$ is the subspace of all $L^2(\mathbb{R}^d)$-functions with Fourier Transform supported in $[-a,a]^d$. I am trying to figure out now what $\chi_{[0, a]}(-\Delta) f$ for any $L^2$-function $f$ is but I am lost. Can anybody explain me that? I understand that in some sense the spectral projector gets rid of all the eigenvalues bigger than $a$, but what this has to do with Fourier Transform? Any help is welcome.",,"['functional-analysis', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'operator-theory', 'spectral-theory']"
60,"Is $L^{p}(I,X)\cong L^{p}(I) \widehat{\otimes_{\pi}}X$?",Is ?,"L^{p}(I,X)\cong L^{p}(I) \widehat{\otimes_{\pi}}X","It is well known that $$L^{1}(I,X) \cong L^{1}(I) \widehat{\otimes_{\pi}}X$$ For any compact interval (I,m) with the Lebesgue measure and any Banach space X. Is it still true when $1<p<\infty$ that $$L^{p}(I,X) \cong L^{p}(I) \widehat{\otimes_{\pi}}X$$ If not, can we embed one of them in the other ?","It is well known that $$L^{1}(I,X) \cong L^{1}(I) \widehat{\otimes_{\pi}}X$$ For any compact interval (I,m) with the Lebesgue measure and any Banach space X. Is it still true when $1<p<\infty$ that $$L^{p}(I,X) \cong L^{p}(I) \widehat{\otimes_{\pi}}X$$ If not, can we embed one of them in the other ?",,"['functional-analysis', 'banach-spaces', 'tensor-products', 'tensors']"
61,"$f:\mathbb{Q} \rightarrow \mathbb{R}$, with conditions on $f$",", with conditions on",f:\mathbb{Q} \rightarrow \mathbb{R} f,"I would like to find all functions : $f:\mathbb{Q} \rightarrow \mathbb{R}$ such that : $f(x) \geq 0$, $\forall x \in \mathbb{Q}$ and the equality holds only if $x = 0$ $f(x\cdot y) = f(x)\cdot f(y)$, $\forall x, y \in \mathbb{Q}$ $f(x+y) \leq\max\{f(x), f(y)\}$ Any suggestions, ideas ? What I found : $f$ is even $f(x) = 1/f(1/x)$ $f(kx) \leq f(x)$ with $k \in \mathbb{N}$ and $f(kx) \leq 1$","I would like to find all functions : $f:\mathbb{Q} \rightarrow \mathbb{R}$ such that : $f(x) \geq 0$, $\forall x \in \mathbb{Q}$ and the equality holds only if $x = 0$ $f(x\cdot y) = f(x)\cdot f(y)$, $\forall x, y \in \mathbb{Q}$ $f(x+y) \leq\max\{f(x), f(y)\}$ Any suggestions, ideas ? What I found : $f$ is even $f(x) = 1/f(1/x)$ $f(kx) \leq f(x)$ with $k \in \mathbb{N}$ and $f(kx) \leq 1$",,"['functional-analysis', 'functional-equations']"
62,Interpretation of Besov Space parameters,Interpretation of Besov Space parameters,,"I've been reading about Besov spaces (my reference thus far has been ""Mathematical foundations of infinite-dimensional statistical models"" (Nickl & Gine), and I've been struggling a bit with the interpretation of the parameters given when describing a Besov space. I normally see the spaces written as $B_{pq}^s$. I understand that the $s$ represents something akin to Holder continuity / level of differentiability, but getting a concrete hold on what each of $p,q,s$ ($q$ in particular) has been something of a tricky task. In particular, I'm looking for a description of what each of $p,q,s$ tells us about the space in question. I can look up inclusions/equivalences to e.g. Holder/Sobolev spaces on my own. I'm interested in the slightly more qualitative side of matters. Edit: Thanks to Ian's helpful comment, I feel relatively at peace with my understanding of $s$ and $p$ - right now, my focus is on getting a qualitative understanding of how $q$ affects the type of functions lying in a given Besov space. I current have it in my head as some control over the tail decay of the wavelet coefficients, but this is still quite unsatisfying; it doesn't tell me as much about the function as I'd like.","I've been reading about Besov spaces (my reference thus far has been ""Mathematical foundations of infinite-dimensional statistical models"" (Nickl & Gine), and I've been struggling a bit with the interpretation of the parameters given when describing a Besov space. I normally see the spaces written as $B_{pq}^s$. I understand that the $s$ represents something akin to Holder continuity / level of differentiability, but getting a concrete hold on what each of $p,q,s$ ($q$ in particular) has been something of a tricky task. In particular, I'm looking for a description of what each of $p,q,s$ tells us about the space in question. I can look up inclusions/equivalences to e.g. Holder/Sobolev spaces on my own. I'm interested in the slightly more qualitative side of matters. Edit: Thanks to Ian's helpful comment, I feel relatively at peace with my understanding of $s$ and $p$ - right now, my focus is on getting a qualitative understanding of how $q$ affects the type of functions lying in a given Besov space. I current have it in my head as some control over the tail decay of the wavelet coefficients, but this is still quite unsatisfying; it doesn't tell me as much about the function as I'd like.",,"['functional-analysis', 'intuition', 'wavelets', 'besov-space']"
63,Don't follow proof that Hadamard differentiable implies compactly differentiable,Don't follow proof that Hadamard differentiable implies compactly differentiable,,"A function $f:X \to Y$ between Banach spaces is said to be compactly differentiable if there is a function $f'_x:X\rightarrow Y$ such that $$\lim_{t \to 0} \frac{f(x+th) - f(x) }{t} -f'_x(h) =0$$ where the limit holds uniformly in $h \in K \subset X$ , where $K$ is a compact set. We say $f$ has a Hadamard derivative if $$\lim_{n \to \infty} \frac{f(x+t_nh_n) - f(x)}{t_n} - f'_x(h)=0$$ holds where $h_n \to h$ and $t_n \to 0$ are any sequences. There is a result (Prop. 3.3 of this ) that states Hadamard diff. implies compact diff. The proof starts as follows. Let $f$ be Hadamard diff., then in order to show it's also compact diff. it is enough to show that for any compact set $S$ and sequences $h_n \in S$ and $t_n \to 0$ , we have $$\lim_{n \to \infty} \frac{f(x+t_nh_n) - f(x)}{t_n} -f'_x(h_n) = 0.$$ The rest is omitted. Question : how is this limit enough to show it? I don't see where the uniformity comes in at all. Could someone explain it please?","A function between Banach spaces is said to be compactly differentiable if there is a function such that where the limit holds uniformly in , where is a compact set. We say has a Hadamard derivative if holds where and are any sequences. There is a result (Prop. 3.3 of this ) that states Hadamard diff. implies compact diff. The proof starts as follows. Let be Hadamard diff., then in order to show it's also compact diff. it is enough to show that for any compact set and sequences and , we have The rest is omitted. Question : how is this limit enough to show it? I don't see where the uniformity comes in at all. Could someone explain it please?",f:X \to Y f'_x:X\rightarrow Y \lim_{t \to 0} \frac{f(x+th) - f(x) }{t} -f'_x(h) =0 h \in K \subset X K f \lim_{n \to \infty} \frac{f(x+t_nh_n) - f(x)}{t_n} - f'_x(h)=0 h_n \to h t_n \to 0 f S h_n \in S t_n \to 0 \lim_{n \to \infty} \frac{f(x+t_nh_n) - f(x)}{t_n} -f'_x(h_n) = 0.,"['functional-analysis', 'derivatives', 'banach-spaces']"
64,Proof: Inequality in Mercer's theorem,Proof: Inequality in Mercer's theorem,,"In the outline of the Mercer's theorem proof there is an inequality assumed without any explanation: $$\sum_{i=0}^{\infty} \lambda_i \vert e_i(t) e_i(s) \vert \le \sup_{x \in [a,b]} \vert K(x,x)\vert^2$$ Why does this need to hold?","In the outline of the Mercer's theorem proof there is an inequality assumed without any explanation: $$\sum_{i=0}^{\infty} \lambda_i \vert e_i(t) e_i(s) \vert \le \sup_{x \in [a,b]} \vert K(x,x)\vert^2$$ Why does this need to hold?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
65,A continuous bijection from $l_2 $ onto a subset of $l_2$ whose inverse is everywhere discontinuous.,A continuous bijection from  onto a subset of  whose inverse is everywhere discontinuous.,l_2  l_2,"I was reading an article from AMM, titled, A continuous bijection from $l_2 $ onto a subset of $l_2$ whose inverse is everywhere discontinuous. In this he constructed the function $T:l_2\rightarrow l_1$ as $T(x)=$$(\sigma(x_1)x_1^2, \cdots,\sigma(x_i)x_i^2, \cdots )$ And shown this function to be bijective, continuous whose inverse is everywhere discontinuous. My question is, What's the motivation behind this example? Why did the author find this example? What's the importance of this example?","I was reading an article from AMM, titled, A continuous bijection from $l_2 $ onto a subset of $l_2$ whose inverse is everywhere discontinuous. In this he constructed the function $T:l_2\rightarrow l_1$ as $T(x)=$$(\sigma(x_1)x_1^2, \cdots,\sigma(x_i)x_i^2, \cdots )$ And shown this function to be bijective, continuous whose inverse is everywhere discontinuous. My question is, What's the motivation behind this example? Why did the author find this example? What's the importance of this example?",,['functional-analysis']
66,Monotone sequence of orthogonal projections on a complex Hilbert space,Monotone sequence of orthogonal projections on a complex Hilbert space,,"Suppose $P_n$ is a monotone sequence of orthogonal projections on a complex Hilbert space $\mathcal{H}$, i.e. $V_n= Im(P_n)$ is a decreasing or increasing sequence of subspaces and $P_n^\star=P_n$ and $P_n^2=P_n$ for all $n$. I want to prove that the sequence $\Vert P_n z \Vert$ is monotone for all $z\in \mathcal{H}$, but I can't quite see where to start. Somehow the $V_n$ being monotone should play into it, but I can't see how, since I can't find any obvious relations between elements of $V_n$ and $V_{n+1}$.","Suppose $P_n$ is a monotone sequence of orthogonal projections on a complex Hilbert space $\mathcal{H}$, i.e. $V_n= Im(P_n)$ is a decreasing or increasing sequence of subspaces and $P_n^\star=P_n$ and $P_n^2=P_n$ for all $n$. I want to prove that the sequence $\Vert P_n z \Vert$ is monotone for all $z\in \mathcal{H}$, but I can't quite see where to start. Somehow the $V_n$ being monotone should play into it, but I can't see how, since I can't find any obvious relations between elements of $V_n$ and $V_{n+1}$.",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
67,Does the operation of completion preserve injectivity?,Does the operation of completion preserve injectivity?,,"It seems to me I saw a counterexample somewhere, but I can't find it, can anybody help me? Let $\varphi:X\to Y$ be a linear continuous map of locally convex spaces, and $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$ the corresponding linear continuous map of their completions. If $\varphi:X\to Y$ is injective, is $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$ injective as well? I think, the answer must be ""no"", so another question is Under which conditions the injectivity of $\varphi:X\to Y$ implies the injectivity of $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$?","It seems to me I saw a counterexample somewhere, but I can't find it, can anybody help me? Let $\varphi:X\to Y$ be a linear continuous map of locally convex spaces, and $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$ the corresponding linear continuous map of their completions. If $\varphi:X\to Y$ is injective, is $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$ injective as well? I think, the answer must be ""no"", so another question is Under which conditions the injectivity of $\varphi:X\to Y$ implies the injectivity of $\widetilde{\varphi}:\widetilde{X}\to\widetilde{Y}$?",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
68,Minkowski-like inequality for the trace of outer products of random vectors,Minkowski-like inequality for the trace of outer products of random vectors,,I am wondering if the following inequality is correct and can be shown? Let $A$ and $B$ be random vectors of dimension $n$.  Then for $ p \ge 1$ \begin{align} E^{\frac{1}{2p}} \left[ \left| Tr \left\{(A-B)(A-B)^T \right\} \right|^p \right] \le E^{\frac{1}{2p}} \left[\left| Tr \left\{AA^T \right\} \right|^{p} \right]+ E^{\frac{1}{2p}} \left[\left| Tr \left\{BB^T \right\} \right|^{p}\right] \end{align} For $n=1$ the inequality becomes \begin{align} E^{\frac{1}{2p}} \left[  |A-B|^{2p} \right] \le E^{\frac{1}{2p}} \left[|A|^{2p}\right]+ E^{\frac{1}{2p}} \left[ |B|^{2p}\right] \end{align} which simply follows from Minkowski inequality. How would one even start proving an inequality like this? If you can also point me to some similar result it will be great.  The only related discussion on this cite that I found is here Any help would be greatly appreciated. Thank you,I am wondering if the following inequality is correct and can be shown? Let $A$ and $B$ be random vectors of dimension $n$.  Then for $ p \ge 1$ \begin{align} E^{\frac{1}{2p}} \left[ \left| Tr \left\{(A-B)(A-B)^T \right\} \right|^p \right] \le E^{\frac{1}{2p}} \left[\left| Tr \left\{AA^T \right\} \right|^{p} \right]+ E^{\frac{1}{2p}} \left[\left| Tr \left\{BB^T \right\} \right|^{p}\right] \end{align} For $n=1$ the inequality becomes \begin{align} E^{\frac{1}{2p}} \left[  |A-B|^{2p} \right] \le E^{\frac{1}{2p}} \left[|A|^{2p}\right]+ E^{\frac{1}{2p}} \left[ |B|^{2p}\right] \end{align} which simply follows from Minkowski inequality. How would one even start proving an inequality like this? If you can also point me to some similar result it will be great.  The only related discussion on this cite that I found is here Any help would be greatly appreciated. Thank you,,"['functional-analysis', 'probability-theory', 'inequality', 'expectation', 'random-matrices']"
69,Prove Operator is a Projector,Prove Operator is a Projector,,"Let $\mathscr{H}$ be a complex Hilbert space. A projector is a linear map $P:\mathscr{H}\to\mathscr{H}$ such that $P\circ P = P$. I'm trying to prove the following claim, from the information given in the following picture (a snapshot of page 2 in Friedrich's book ""Pertrubation of Spectra in Hilbert Space""): Claim: For any interval $\mathscr{I}\subseteq\mathbb{R}$, the map $\eta_{\mathscr{I}}(A)$ is a projector. I have the following problems: 1) The author defined the $f$ map $\mathscr{H}^\mathscr{H}\to\mathscr{H}^\mathscr{H}$ only for polynomials $f$ (not even power series). I am not sure how to define $\eta_{\mathscr{I}}(A)$, the characteristic function, from the definitions given. I have looked on Wikipedia which helped but I'm still not sure how it relates to the definitions given so far. 2) Suppose you somehow ""swallow"" that $\eta_{\mathscr{I}}(A)$ is the identity mapping if $\mathscr{I}$ contains the spectrum of $A$ (which hasn't been defined yet) and is the zero mapping otherwise. How do you prove the claim, strictly from the fact that $\left[\eta_{\mathscr{I}}(\alpha)\right]^2=\eta_{\mathscr{I}}(\alpha)$?","Let $\mathscr{H}$ be a complex Hilbert space. A projector is a linear map $P:\mathscr{H}\to\mathscr{H}$ such that $P\circ P = P$. I'm trying to prove the following claim, from the information given in the following picture (a snapshot of page 2 in Friedrich's book ""Pertrubation of Spectra in Hilbert Space""): Claim: For any interval $\mathscr{I}\subseteq\mathbb{R}$, the map $\eta_{\mathscr{I}}(A)$ is a projector. I have the following problems: 1) The author defined the $f$ map $\mathscr{H}^\mathscr{H}\to\mathscr{H}^\mathscr{H}$ only for polynomials $f$ (not even power series). I am not sure how to define $\eta_{\mathscr{I}}(A)$, the characteristic function, from the definitions given. I have looked on Wikipedia which helped but I'm still not sure how it relates to the definitions given so far. 2) Suppose you somehow ""swallow"" that $\eta_{\mathscr{I}}(A)$ is the identity mapping if $\mathscr{I}$ contains the spectrum of $A$ (which hasn't been defined yet) and is the zero mapping otherwise. How do you prove the claim, strictly from the fact that $\left[\eta_{\mathscr{I}}(\alpha)\right]^2=\eta_{\mathscr{I}}(\alpha)$?",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory', 'banach-algebras']"
70,"Properties of Sobolev spaces $W^{k,\infty}(\Omega)$",Properties of Sobolev spaces,"W^{k,\infty}(\Omega)","I'm looking for different properties of spaces $W^{k,\infty}(\Omega)$ for bounded domain $\Omega \subset \mathbb R^n$ and $k \geq 1$ that I couldn't find in literature. References are wery welcome. Extension. Theorem 12.15 of Giovanni Leoni ""A first course in Sobolev spaces"" tells us that if $\Omega$ has Lipshitz boundary then there exists a continuous linear extension operator from $W^{1,\infty}(\Omega)$ to $W^{1,\infty}(\mathbb R^n)$. What about spaces $W^{k,\infty}$ for $k \geq 2$? Does there exist a continuous extension operator in the case of $C^k$ boundary $\partial \Omega$? Trace. Theorem 5, p. 131 of Evans ""Measure theory and fine properties of functions"" tells us that $f \in W^{1,\infty}_\text{loc}(\Omega)$ if and only if $f$ is locally Lipshitz in $\Omega$. If I'm not mistaken, combining this with the above extension result we obtain that for any $f \in W^{1,\infty}(\Omega)$ we can define its trace on $\partial D$ as an element of $W^{1,\infty}(\partial \Omega)$ if $\partial \Omega \in C^1$. To do this we extend $f$ to $\widetilde f \in W^{1,\infty}(\mathbb R^n)$ so that $\widetilde f|_{\partial D}$ is the restriction of the Lipshitz function which is Lipshitz and hence $W^{1,\infty}(\partial D)$. Is it true in general that the trace operator continuously maps $W^{k,\infty}(\Omega)$ to $W^{k,\infty}(\partial \Omega)$ if $k \geq 1$, $\partial \Omega \in C^k$? (Intuitively it must be true since taking trace on $W^{k,p}$ ""costs"" 1/p smoothness). Extension from boundary. Let $f \in W^{1,\infty}(\partial D)$. Then (as above) $f$ is Lipshitz. Then by the Kirszbraun theorem $f$ can be extended to a Lipshitz $\widetilde f$ (the extension not necessarily linear) on $\mathbb R^n$ and hence to $\widetilde f|_\Omega \in W^{1,\infty}(\Omega)$. Does the same result hold for $f \in W^{k,\infty}(\partial D)$, $k \geq 2$? Any comments are very welcome.","I'm looking for different properties of spaces $W^{k,\infty}(\Omega)$ for bounded domain $\Omega \subset \mathbb R^n$ and $k \geq 1$ that I couldn't find in literature. References are wery welcome. Extension. Theorem 12.15 of Giovanni Leoni ""A first course in Sobolev spaces"" tells us that if $\Omega$ has Lipshitz boundary then there exists a continuous linear extension operator from $W^{1,\infty}(\Omega)$ to $W^{1,\infty}(\mathbb R^n)$. What about spaces $W^{k,\infty}$ for $k \geq 2$? Does there exist a continuous extension operator in the case of $C^k$ boundary $\partial \Omega$? Trace. Theorem 5, p. 131 of Evans ""Measure theory and fine properties of functions"" tells us that $f \in W^{1,\infty}_\text{loc}(\Omega)$ if and only if $f$ is locally Lipshitz in $\Omega$. If I'm not mistaken, combining this with the above extension result we obtain that for any $f \in W^{1,\infty}(\Omega)$ we can define its trace on $\partial D$ as an element of $W^{1,\infty}(\partial \Omega)$ if $\partial \Omega \in C^1$. To do this we extend $f$ to $\widetilde f \in W^{1,\infty}(\mathbb R^n)$ so that $\widetilde f|_{\partial D}$ is the restriction of the Lipshitz function which is Lipshitz and hence $W^{1,\infty}(\partial D)$. Is it true in general that the trace operator continuously maps $W^{k,\infty}(\Omega)$ to $W^{k,\infty}(\partial \Omega)$ if $k \geq 1$, $\partial \Omega \in C^k$? (Intuitively it must be true since taking trace on $W^{k,p}$ ""costs"" 1/p smoothness). Extension from boundary. Let $f \in W^{1,\infty}(\partial D)$. Then (as above) $f$ is Lipshitz. Then by the Kirszbraun theorem $f$ can be extended to a Lipshitz $\widetilde f$ (the extension not necessarily linear) on $\mathbb R^n$ and hence to $\widetilde f|_\Omega \in W^{1,\infty}(\Omega)$. Does the same result hold for $f \in W^{k,\infty}(\partial D)$, $k \geq 2$? Any comments are very welcome.",,"['functional-analysis', 'reference-request', 'sobolev-spaces']"
71,"Reproducing kernel Hilbert space, why?","Reproducing kernel Hilbert space, why?",,"Let $K: X \times X \rightarrow \mathbb{C}$ be a positive definite kernel on a set $X$, i.e. for any $x_1, \cdots, x_n \in X$, the matrix $$ [K(x_i, x_j)]_{ij} \in \mathbb{C}^{n \times n} $$ is positive definite. The reproducing kernel Hilbert space $\mathcal{H}_K$ with kernel $K$ is the Hilbert space closure of the set $\{ K_x(y) = K(x,y)\}$ with the inner product $$ \langle K_x(y), K_{x'}(y) \rangle_{\mathcal{H}_K} = K(x, x').  $$ Question Consider the vector space of functions on $X$ (no additional structure is assumed on $X$). Define an inner product by $$ \langle \delta_x, \delta_{x'} \rangle = K(x, x').  $$ Then the resulting Hilbert space $\mathcal{H}$ is isomorphic to $\mathcal{H}_{K}$ via the isomorphism $$ \delta_x(y) \mapsto K_x(y). $$ $\mathcal{H}$ seems a much more natural and straight forward object than $\mathcal{H}_K$, so what is gained by the ""reproducing kernel"" construction? The reproducing kernel construction makes pointwise evaluation an element of the dual...why is this useful? In particular, what are some examples of specific contexts where $\mathcal{H}_K$ is more handy than $\mathcal{H}$ (I am guessing they must exist)?","Let $K: X \times X \rightarrow \mathbb{C}$ be a positive definite kernel on a set $X$, i.e. for any $x_1, \cdots, x_n \in X$, the matrix $$ [K(x_i, x_j)]_{ij} \in \mathbb{C}^{n \times n} $$ is positive definite. The reproducing kernel Hilbert space $\mathcal{H}_K$ with kernel $K$ is the Hilbert space closure of the set $\{ K_x(y) = K(x,y)\}$ with the inner product $$ \langle K_x(y), K_{x'}(y) \rangle_{\mathcal{H}_K} = K(x, x').  $$ Question Consider the vector space of functions on $X$ (no additional structure is assumed on $X$). Define an inner product by $$ \langle \delta_x, \delta_{x'} \rangle = K(x, x').  $$ Then the resulting Hilbert space $\mathcal{H}$ is isomorphic to $\mathcal{H}_{K}$ via the isomorphism $$ \delta_x(y) \mapsto K_x(y). $$ $\mathcal{H}$ seems a much more natural and straight forward object than $\mathcal{H}_K$, so what is gained by the ""reproducing kernel"" construction? The reproducing kernel construction makes pointwise evaluation an element of the dual...why is this useful? In particular, what are some examples of specific contexts where $\mathcal{H}_K$ is more handy than $\mathcal{H}$ (I am guessing they must exist)?",,"['functional-analysis', 'hilbert-spaces', 'machine-learning']"
72,At most $n$ functions satisfy $f(x)=\bigl(x-f(a_1)\bigr)\bigl(x-f(a_2)\bigr)\dots\bigl(x-f(a_n)\bigr)$?,At most  functions satisfy ?,n f(x)=\bigl(x-f(a_1)\bigr)\bigl(x-f(a_2)\bigr)\dots\bigl(x-f(a_n)\bigr),"Some background: I was trying to solve the functional equation $f\bigl(f(x)\bigr)=\sin x$ . I realized that $f(\pi n)$ is a root of $f$ for all integers $n$ , because $f\bigl(f(\pi n)\bigr)=\sin(\pi n)=0$ . Thus, we can write $f$ as $f(x)=A\bigl(x-f(0)\bigr)\bigl(x-f(\pi)\bigr)\bigl(x-f(-\pi)\bigr)\dots$ . The problem now is to find all functions $f$ that solve this. I couldn't even begin on this, so I decided to try letting the constant $A$ equal $1$ , and to try some simpler versions first. E.g. For $f(x)=x-f(0)$ we find the unique solution $f(x)=x$ ; for $f(x)=\bigl(x-f(0)\bigr)\Bigl(x-f\left(\sqrt{2}\right)\Bigr)$ we find two solutions, namely $f(x)\in \left\{x^2-1,x^2-2\left(\sqrt{2}-1\right)x\right\}$ . I solved many more examples, and then conjectured that: Let $a_i\in \mathbb{C}$ for $i=1,2,\dots,n$ . Prove that the functional equation $f(x)=\bigl(x-f(a_1)\bigr)\bigl(x-f(a_2)\bigr)\dots\bigl(x-f(a_n)\bigr)$ has exactly $n$ distinct solutions. Finally, I realized that if this is proved, then it would ""follow"" (I don't know if this is rigorous but I hope someone knows how to make it rigorous) that our original functional equation $f(x)=\bigl(x-f(0)\bigr)\bigl(x-f(\pi)\bigr)\bigl(x-f(-\pi)\bigr)\dots$ (I put $A=1$ ) has infinitely many solutions. Thanks for reading.","Some background: I was trying to solve the functional equation . I realized that is a root of for all integers , because . Thus, we can write as . The problem now is to find all functions that solve this. I couldn't even begin on this, so I decided to try letting the constant equal , and to try some simpler versions first. E.g. For we find the unique solution ; for we find two solutions, namely . I solved many more examples, and then conjectured that: Let for . Prove that the functional equation has exactly distinct solutions. Finally, I realized that if this is proved, then it would ""follow"" (I don't know if this is rigorous but I hope someone knows how to make it rigorous) that our original functional equation (I put ) has infinitely many solutions. Thanks for reading.","f\bigl(f(x)\bigr)=\sin x f(\pi n) f n f\bigl(f(\pi n)\bigr)=\sin(\pi n)=0 f f(x)=A\bigl(x-f(0)\bigr)\bigl(x-f(\pi)\bigr)\bigl(x-f(-\pi)\bigr)\dots f A 1 f(x)=x-f(0) f(x)=x f(x)=\bigl(x-f(0)\bigr)\Bigl(x-f\left(\sqrt{2}\right)\Bigr) f(x)\in \left\{x^2-1,x^2-2\left(\sqrt{2}-1\right)x\right\} a_i\in \mathbb{C} i=1,2,\dots,n f(x)=\bigl(x-f(a_1)\bigr)\bigl(x-f(a_2)\bigr)\dots\bigl(x-f(a_n)\bigr) n f(x)=\bigl(x-f(0)\bigr)\bigl(x-f(\pi)\bigr)\bigl(x-f(-\pi)\bigr)\dots A=1","['algebra-precalculus', 'functional-analysis', 'functions', 'functional-equations', 'conjectures']"
73,Spectral theorem in Quantum Mechanics,Spectral theorem in Quantum Mechanics,,"In Quantum Mechanics one often looks at self-adjoint(unbounded and closed) linear operators $A,B$ that are defined dense on $L^2$. My question is: Is it true that if we have $[A,B]=0$, where $[,]$ is the commutator, that we find some sort of same eigenbasis for both operators? My problem is: In Physics this result is often just blindly transfered from the finite dimensional case and I wanted to ask whether there is some sort of similar result for the actual case?","In Quantum Mechanics one often looks at self-adjoint(unbounded and closed) linear operators $A,B$ that are defined dense on $L^2$. My question is: Is it true that if we have $[A,B]=0$, where $[,]$ is the commutator, that we find some sort of same eigenbasis for both operators? My problem is: In Physics this result is often just blindly transfered from the finite dimensional case and I wanted to ask whether there is some sort of similar result for the actual case?",,"['functional-analysis', 'operator-theory']"
74,Weak and almost everywhere convergence,Weak and almost everywhere convergence,,"Let $\Omega\subset\mathbb{R}^n$ be a bounded domain. Suppose that $p\in (1,\infty)$ . Assume that the sequence $u_n\in L^p(\Omega)$ satisfies: There is $u,w\in L^p(\Omega)$ such that $u_n\to u$ a.e. in $\Omega$ and $u_n$ weakly converge to w in $L^p(\Omega)$ . Can we conclude that $u=w$ ? I was trying to prove this result by using Mazur lemma , which says that the sequence $$v_n=\sum_{k=n}^{f(n)}\alpha_{k,n}u_k\to w\ \mbox{in}\ L^p(\Omega)$$ where $f(n)\geq n$ and $\sum_{k=n}^{f(n)}\alpha_{k,n}=1$ . We can assume without loss of generality that $v_n(x)\to w(x)$ a.e. in $\Omega$ . Now, I want to use the fact that $u_n$ to $u$ a.e. everywhere to conclude that $v_n\to u$ a.e. Can I do this? Update: I think I could finish the proof, please verify it to me. Fix $x\in \Omega$ such that $u_n(x)\to u(x)$ . Note that $$|v_n(x)-u(x)|=\left|\sum_{k=n}^{f(n)}\alpha_{k,n}(u_k(x)-u(x))\right|\leq \sum_{k=n}^{f(n)}|\alpha_{k,n}(u_k(x)-u(x))|\tag{1}$$ For any $\delta>0$ choose $N$ um such a way that if $n\geq N$ then $|u_n(x)-u(x)|\leq\delta$ then, from $(1)$ we conclude that $$|v_n(x)-u(x)|\leq \delta$$","Let be a bounded domain. Suppose that . Assume that the sequence satisfies: There is such that a.e. in and weakly converge to w in . Can we conclude that ? I was trying to prove this result by using Mazur lemma , which says that the sequence where and . We can assume without loss of generality that a.e. in . Now, I want to use the fact that to a.e. everywhere to conclude that a.e. Can I do this? Update: I think I could finish the proof, please verify it to me. Fix such that . Note that For any choose um such a way that if then then, from we conclude that","\Omega\subset\mathbb{R}^n p\in (1,\infty) u_n\in L^p(\Omega) u,w\in L^p(\Omega) u_n\to u \Omega u_n L^p(\Omega) u=w v_n=\sum_{k=n}^{f(n)}\alpha_{k,n}u_k\to w\ \mbox{in}\ L^p(\Omega) f(n)\geq n \sum_{k=n}^{f(n)}\alpha_{k,n}=1 v_n(x)\to w(x) \Omega u_n u v_n\to u x\in \Omega u_n(x)\to u(x) |v_n(x)-u(x)|=\left|\sum_{k=n}^{f(n)}\alpha_{k,n}(u_k(x)-u(x))\right|\leq \sum_{k=n}^{f(n)}|\alpha_{k,n}(u_k(x)-u(x))|\tag{1} \delta>0 N n\geq N |u_n(x)-u(x)|\leq\delta (1) |v_n(x)-u(x)|\leq \delta","['functional-analysis', 'weak-convergence']"
75,Weak Derivatives and Lp spaces,Weak Derivatives and Lp spaces,,"I just want to know how to prove two properties of weak derivatives and $L^{p}$ spaces if they are true, the first one just involves weak derivatives: If we have a locally summable function $u: U \rightarrow \mathbb{R}$ and we have its weak derivative $D^{ \alpha}u$ for $|\alpha| = k$ then how would you show that that $D^{\alpha}u$ exists for $|\alpha| < k $. Secondly, if $D^{\alpha}u \in L^{p}(U)$ for $|\alpha| = k$ then how would you show that $D^{\alpha}u \in L^{p}(U)$ for $\alpha < k$? Thanks!","I just want to know how to prove two properties of weak derivatives and $L^{p}$ spaces if they are true, the first one just involves weak derivatives: If we have a locally summable function $u: U \rightarrow \mathbb{R}$ and we have its weak derivative $D^{ \alpha}u$ for $|\alpha| = k$ then how would you show that that $D^{\alpha}u$ exists for $|\alpha| < k $. Secondly, if $D^{\alpha}u \in L^{p}(U)$ for $|\alpha| = k$ then how would you show that $D^{\alpha}u \in L^{p}(U)$ for $\alpha < k$? Thanks!",,"['functional-analysis', 'lp-spaces', 'weak-derivatives']"
76,Does an irreducible operator generate an exact $C^{*}$-algebra?,Does an irreducible operator generate an exact -algebra?,C^{*},"Let $H$ be an infinite dimensional separable Hilbert space and $B(H)$ the algebra of bounded operators. Definition : An operator $T \in B(H)$ is irreducible if $W^{*}(T)=B(H)$ . Definition : A $C^{*}$ -algebra is exact if it preserves exact sequences under the minimum tensor product. Property : A $C^{*}$ -algebra is exact if and only if : it's nuclearly embeddable into $B(H)$ . it's isomorphic to a subalgebra of the Cuntz algebra $\mathcal{O}_2$ . Does an irreducible operator generate an exact $C^{*}$ -algebra ? Counter-example : Is there a non-exact singly generated $C^{*}$ -algebra ? And does every $C^{*}$ -algebra admit an irreducible faithful representation ? (it's ok for the simple $C^{*}$ -algebras). Remark : $C^{∗}$ -algebras book (Eds Cuntz Echterhoff) : by definition, a discrete group $Γ$ is exact if $C^{∗}_{r}(\Gamma)$ is exact. If $Γ$ is amenable, then $C^{∗}_{r}(\Gamma)$ is nuclear and so exact. Then, the amenable groups are exact. Next, Adams (1994) proves also that the hyperbolic groups are exact, in particular the free groups are exact.  Gromov built non-exact discrete random groups (see @OwenSizemore comment).","Let be an infinite dimensional separable Hilbert space and the algebra of bounded operators. Definition : An operator is irreducible if . Definition : A -algebra is exact if it preserves exact sequences under the minimum tensor product. Property : A -algebra is exact if and only if : it's nuclearly embeddable into . it's isomorphic to a subalgebra of the Cuntz algebra . Does an irreducible operator generate an exact -algebra ? Counter-example : Is there a non-exact singly generated -algebra ? And does every -algebra admit an irreducible faithful representation ? (it's ok for the simple -algebras). Remark : -algebras book (Eds Cuntz Echterhoff) : by definition, a discrete group is exact if is exact. If is amenable, then is nuclear and so exact. Then, the amenable groups are exact. Next, Adams (1994) proves also that the hyperbolic groups are exact, in particular the free groups are exact.  Gromov built non-exact discrete random groups (see @OwenSizemore comment).",H B(H) T \in B(H) W^{*}(T)=B(H) C^{*} C^{*} B(H) \mathcal{O}_2 C^{*} C^{*} C^{*} C^{*} C^{∗} Γ C^{∗}_{r}(\Gamma) Γ C^{∗}_{r}(\Gamma),"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
77,About completeness of $l^{\infty}$ with respect to sup norm,About completeness of  with respect to sup norm,l^{\infty},"Let $l^{\infty}$ be the space of all bounded sequences of real numbers $(x_n)_{n =1}^{\infty}$ with the sup norm. I have to show that $l^{\infty}$ is complete with respect to this norm. Proof: In the proof below I am confused with the sequence $x^n = (x_1^{n},x_2^{n}\ldots )$. I am not able to visualize this sequence. How this sequence can be formed? Is $(x^{n})$ is collection of cauchy sequences? $x_1^{n}$,$x_2^{n}$ are different cauchy sequences they may be converging to different points so how can we assume that $(x^{n})$ will converge to fixed point $x$? Please help me to understand this. Any numerical example supporting this will be very much helpful.  Thanks","Let $l^{\infty}$ be the space of all bounded sequences of real numbers $(x_n)_{n =1}^{\infty}$ with the sup norm. I have to show that $l^{\infty}$ is complete with respect to this norm. Proof: In the proof below I am confused with the sequence $x^n = (x_1^{n},x_2^{n}\ldots )$. I am not able to visualize this sequence. How this sequence can be formed? Is $(x^{n})$ is collection of cauchy sequences? $x_1^{n}$,$x_2^{n}$ are different cauchy sequences they may be converging to different points so how can we assume that $(x^{n})$ will converge to fixed point $x$? Please help me to understand this. Any numerical example supporting this will be very much helpful.  Thanks",,['functional-analysis']
78,Zeta Regularized Determinant of Laplacian,Zeta Regularized Determinant of Laplacian,,"Can anyone point me to a resource where the zeta regularized determinant of the Laplacian is explicitly computed for simple two dimensional surfaces, say a rectangle or torus or cylinder?","Can anyone point me to a resource where the zeta regularized determinant of the Laplacian is explicitly computed for simple two dimensional surfaces, say a rectangle or torus or cylinder?",,"['functional-analysis', 'reference-request', 'riemannian-geometry']"
79,Examples of Banach spaces,Examples of Banach spaces,,"Which of the following are Banach spaces? A. The set of all real-valued functions $f$, $g$ which are functions of an independent real variable $t$ and are defined and continuous on the closed interval $[0,1]$, with norm $$\|f\|=\max_{t \in [0,1]} |f(t)|. $$ B. The set of all continuous real-valued functions on $[0,1]$ and $$\|f\|=\int_0^1 f(t) dt. $$ C. All polynomials on $(0,1)$ with complex coefficients with $$\|f\| = \sup_{t \in [0,1]} |f(t)|. $$ My answer: A. Yes, it is a Banach space as the set of all real-valued continuous functions on $[0,1]$ is complete with respect to the metric $$d(f,g)=\max_{t \in [0,1]} |f(t)-g(t)|.$$ Is it correct? I'm not able to complete parts B. and C. .","Which of the following are Banach spaces? A. The set of all real-valued functions $f$, $g$ which are functions of an independent real variable $t$ and are defined and continuous on the closed interval $[0,1]$, with norm $$\|f\|=\max_{t \in [0,1]} |f(t)|. $$ B. The set of all continuous real-valued functions on $[0,1]$ and $$\|f\|=\int_0^1 f(t) dt. $$ C. All polynomials on $(0,1)$ with complex coefficients with $$\|f\| = \sup_{t \in [0,1]} |f(t)|. $$ My answer: A. Yes, it is a Banach space as the set of all real-valued continuous functions on $[0,1]$ is complete with respect to the metric $$d(f,g)=\max_{t \in [0,1]} |f(t)-g(t)|.$$ Is it correct? I'm not able to complete parts B. and C. .",,"['functional-analysis', 'banach-spaces']"
80,The weak topology of a product,The weak topology of a product,,"Let $E$ and $F$ be normed vector spaces and let $E^{\sigma}$, resp. $F^{\sigma}$ be $E$, resp. $F$ with the weak topology associated with the elements of the duals $E^*$, resp. $F^*$. Then, for $(E\times F)^{\sigma}$, being $E \times F$ with the weak topology induced by the elements of $(E\times F)^*$, apparently, one should have that $E^{\sigma}\times F^{\sigma}=(E\times F)^{\sigma}$ (I'm not sure about additional conditions on $E$ and $F$, perhaps they should be Banach). I have established that $\Pi : E^*\times F^*\longrightarrow (E\times F)^* $, with $\Pi(f,g)(x,y)= f(x)+g(y), \forall (x,y) \in E  \times F $, $\forall (f,g) \in E^*  \times F^*$ is a homeomorphism, but after that, I ran out of ideas. Anyone out there with a rather elegant explanation? To avoid further spam, many thanks in advance.","Let $E$ and $F$ be normed vector spaces and let $E^{\sigma}$, resp. $F^{\sigma}$ be $E$, resp. $F$ with the weak topology associated with the elements of the duals $E^*$, resp. $F^*$. Then, for $(E\times F)^{\sigma}$, being $E \times F$ with the weak topology induced by the elements of $(E\times F)^*$, apparently, one should have that $E^{\sigma}\times F^{\sigma}=(E\times F)^{\sigma}$ (I'm not sure about additional conditions on $E$ and $F$, perhaps they should be Banach). I have established that $\Pi : E^*\times F^*\longrightarrow (E\times F)^* $, with $\Pi(f,g)(x,y)= f(x)+g(y), \forall (x,y) \in E  \times F $, $\forall (f,g) \in E^*  \times F^*$ is a homeomorphism, but after that, I ran out of ideas. Anyone out there with a rather elegant explanation? To avoid further spam, many thanks in advance.",,"['functional-analysis', 'topological-vector-spaces']"
81,Exercise Functional Analysis,Exercise Functional Analysis,,"Let $\mathcal{F}$ be the set of all functions $f: \mathbb{R} \rightarrow \mathbb{R}$. Consider an operator $\mathcal{O}: \mathcal{F} \rightarrow \mathcal{F}$ such that: $\mathcal{O}( f_1 + f_2) = \mathcal{O}(f_1) + \mathcal{O}(f_2) \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( f_1 \cdot f_2) = \mathcal{O}(f_1) \cdot f_2 + \mathcal{O}(f_2)\cdot f_1 \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( \mathbb{1}) = \mathbb{0} $. Question. Find all operators satisfying the above properties. Notation. The sum $f := f_1 + f_2$ is defined as $f(x) := f_1(x) + f_2(x)$ for all $x \in \mathbb{R}$. The product $f := f_1 \cdot f_2$ is defined as $f(x) := f_1(x) f_2(x)$ for all $x \in \mathbb{R}$. $\mathbb{1}$ denotes the constant function $f(x) = 1$ for all $x \in \mathbb{R}$. $\mathbb{0}$ denotes the constant function $f(x) = 0$ for all $x \in \mathbb{R}$. Comments. Trivially, $\mathcal{O}(f) := \mathbb{0}$ satisfies the properties. Also the derivative, i.e. $\mathcal{O}(f) := df/dx$ does, whenever $\mathcal{F}$ is the set of differentiable functions. I am not able to prove if those are the only ones, even for this particular $\mathcal{F}$.","Let $\mathcal{F}$ be the set of all functions $f: \mathbb{R} \rightarrow \mathbb{R}$. Consider an operator $\mathcal{O}: \mathcal{F} \rightarrow \mathcal{F}$ such that: $\mathcal{O}( f_1 + f_2) = \mathcal{O}(f_1) + \mathcal{O}(f_2) \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( f_1 \cdot f_2) = \mathcal{O}(f_1) \cdot f_2 + \mathcal{O}(f_2)\cdot f_1 \ \text{for all } f_1, f_2 \in \mathcal{F}$; $\mathcal{O}( \mathbb{1}) = \mathbb{0} $. Question. Find all operators satisfying the above properties. Notation. The sum $f := f_1 + f_2$ is defined as $f(x) := f_1(x) + f_2(x)$ for all $x \in \mathbb{R}$. The product $f := f_1 \cdot f_2$ is defined as $f(x) := f_1(x) f_2(x)$ for all $x \in \mathbb{R}$. $\mathbb{1}$ denotes the constant function $f(x) = 1$ for all $x \in \mathbb{R}$. $\mathbb{0}$ denotes the constant function $f(x) = 0$ for all $x \in \mathbb{R}$. Comments. Trivially, $\mathcal{O}(f) := \mathbb{0}$ satisfies the properties. Also the derivative, i.e. $\mathcal{O}(f) := df/dx$ does, whenever $\mathcal{F}$ is the set of differentiable functions. I am not able to prove if those are the only ones, even for this particular $\mathcal{F}$.",,"['functional-analysis', 'functions']"
82,Polynomial root (using contraction mapping principle),Polynomial root (using contraction mapping principle),,"I am asked to provide an iterative algorithm which would lead to finding a real root of this polynomial: $$6x^5-x^3+6x-6=0$$ It is required to rely on the contraction mapping principle and Banach fixed-point theorem . At the moment I think I can rewrite $$f(x) = \sqrt[5]{x^3/6-x+1}$$ and try to prove that in a complete metric space $\langle \, \mathbb{R}, d \, \rangle$ I have a contraction mapping $f:\mathbb{R} \rightarrow \mathbb{R}$ and consequently a unique fixed-point is my solution. I already see it's going to be messy (contraction mapping proof part) and the idea of it makes me sick... Besides those 6'es in the initial polynomial temps to rewrite $$ x = \sqrt[3]{6} \sqrt[3]{x^5+x-1}$$ but I see no good coming out of it. Since I'm very new to functional analysis and metric spaces I decided to ask you for suggestions about the most suave way to do it. The final answer (fixed point) will be $x \approx 0.78$ so I'd love to get the contraction mapping over $[0;1]$, $[-1;1]$, $[0;2]$, $[-2;2]$ or something like that which would be easy to prove (contractility that is) without calculator... But I can't find it!","I am asked to provide an iterative algorithm which would lead to finding a real root of this polynomial: $$6x^5-x^3+6x-6=0$$ It is required to rely on the contraction mapping principle and Banach fixed-point theorem . At the moment I think I can rewrite $$f(x) = \sqrt[5]{x^3/6-x+1}$$ and try to prove that in a complete metric space $\langle \, \mathbb{R}, d \, \rangle$ I have a contraction mapping $f:\mathbb{R} \rightarrow \mathbb{R}$ and consequently a unique fixed-point is my solution. I already see it's going to be messy (contraction mapping proof part) and the idea of it makes me sick... Besides those 6'es in the initial polynomial temps to rewrite $$ x = \sqrt[3]{6} \sqrt[3]{x^5+x-1}$$ but I see no good coming out of it. Since I'm very new to functional analysis and metric spaces I decided to ask you for suggestions about the most suave way to do it. The final answer (fixed point) will be $x \approx 0.78$ so I'd love to get the contraction mapping over $[0;1]$, $[-1;1]$, $[0;2]$, $[-2;2]$ or something like that which would be easy to prove (contractility that is) without calculator... But I can't find it!",,"['functional-analysis', 'metric-spaces']"
83,Prove that $L^1$ is a Banach algebra with multiplication defined by convolution,Prove that  is a Banach algebra with multiplication defined by convolution,L^1,"To be more specific, prove that $L^1(\mathbb{R}^n)$ with multiplication defined by convolution: $$ (f\cdot g)(x)=\int_\mathbb{R^n}f(x-y)g(y)dy $$ is a Banach algebra. All the properties of Banach algebra are easily proved except the last one: $$ \|f\cdot g\|\le \|f\|\|g\|. $$ Could anyone give me a hint? Actually I found a proof on the web, but I don't see why the last equality holds. $$\|f* g\|_1  = \int |f*g(x)|dx \le \iint |f(x-y) g(y)|dydx = \|f\|_1 \|g\|_1$$","To be more specific, prove that with multiplication defined by convolution: is a Banach algebra. All the properties of Banach algebra are easily proved except the last one: Could anyone give me a hint? Actually I found a proof on the web, but I don't see why the last equality holds.","L^1(\mathbb{R}^n) 
(f\cdot g)(x)=\int_\mathbb{R^n}f(x-y)g(y)dy
 
\|f\cdot g\|\le \|f\|\|g\|.
 \|f* g\|_1  = \int |f*g(x)|dx \le \iint |f(x-y) g(y)|dydx = \|f\|_1 \|g\|_1",['functional-analysis']
84,Computing the spectral decomposition for the multiplication operator $f(x) = \frac{1}{1+x^2}$,Computing the spectral decomposition for the multiplication operator,f(x) = \frac{1}{1+x^2},"I am trying to use the spectral theorem for self adjoint operators to decompose the spectrum of the multiplication operator $f(x) = \frac{1}{1+x^2}$ on $L^2(\mathbb{R}).$ This is a problem in Teschl's ""Mathematical Applications to Quantum Mechanics."" Here is what I have done so far. The function $f \in L^\infty(\mathbb{R})$ so it is a bounded operator and its spectrum is equal to the closure of the range of $f$ which is the interval $[0,1].$ There are clearly no eigenvectors since $g = \frac{g}{1+x^2}$ implies that $g=0$ a.e. If $\psi(x) \in L^2(\mathbb{R})$ then the spectral measure is defined by $$\mu_\psi(\Omega) = \langle\psi, \chi_{f^{-1}(\Omega)} \psi \rangle$$ for $\Omega \subset \mathbb{R}$ measurable. Since $f$ is smooth and everywhere 2 to 1, if $\Omega$ is a set of Lebesgue measure $0$ then so is $f^{-1}(\Omega)$ so $\mu_\psi$ is absolutely continuous with respect to the Lebesgue measure for all $\psi.$ Therefore the spectrum is entirely absolutely continuous. I am having trouble finding a spectral basis so that I can decompose the operator into a direct sum of multiplication operators on finite measure spaces. There doesn't seem to be a general procedure for doing this and I can't think of a good place to start.","I am trying to use the spectral theorem for self adjoint operators to decompose the spectrum of the multiplication operator $f(x) = \frac{1}{1+x^2}$ on $L^2(\mathbb{R}).$ This is a problem in Teschl's ""Mathematical Applications to Quantum Mechanics."" Here is what I have done so far. The function $f \in L^\infty(\mathbb{R})$ so it is a bounded operator and its spectrum is equal to the closure of the range of $f$ which is the interval $[0,1].$ There are clearly no eigenvectors since $g = \frac{g}{1+x^2}$ implies that $g=0$ a.e. If $\psi(x) \in L^2(\mathbb{R})$ then the spectral measure is defined by $$\mu_\psi(\Omega) = \langle\psi, \chi_{f^{-1}(\Omega)} \psi \rangle$$ for $\Omega \subset \mathbb{R}$ measurable. Since $f$ is smooth and everywhere 2 to 1, if $\Omega$ is a set of Lebesgue measure $0$ then so is $f^{-1}(\Omega)$ so $\mu_\psi$ is absolutely continuous with respect to the Lebesgue measure for all $\psi.$ Therefore the spectrum is entirely absolutely continuous. I am having trouble finding a spectral basis so that I can decompose the operator into a direct sum of multiplication operators on finite measure spaces. There doesn't seem to be a general procedure for doing this and I can't think of a good place to start.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
85,Evaluation map is not continuous always.,Evaluation map is not continuous always.,,"Let $E$ be a not normable locally convex space, define  $$F: E'\times E\to \mathbb R$$ $$(f,e)\to f(e)$$ I have to show that $F$ is not continuous when $E'\times E$ is given product topology. I was reading an article and i came across with this fact.. Please give me atleast a hint to start.. My try:  I know that $E$ is normable if and only if origin has a convex bounded neighborhood.  So i was trying to produce any such neighborhood to contradict to assumption.  Assume $F$ is continuous, then we have $\{(f,e): a<f(e)<b\}$ is open in product topology of $E'\times E$, for any $a,b\in \mathbb R$. This means there is some open set $U'$ in $E'$ and $U$ in $E$ such that $$U'\times U\subset \{(f,e): a<f(e)<b\}$$ Now let $V:=\{e\in E: a<f(e)<b;\forall f\in U'\}$, this is open convex neighborhood of origin, but how to prove this is bounded.   Or we have any other way to produce such a neighborhood. Thanks for your time.","Let $E$ be a not normable locally convex space, define  $$F: E'\times E\to \mathbb R$$ $$(f,e)\to f(e)$$ I have to show that $F$ is not continuous when $E'\times E$ is given product topology. I was reading an article and i came across with this fact.. Please give me atleast a hint to start.. My try:  I know that $E$ is normable if and only if origin has a convex bounded neighborhood.  So i was trying to produce any such neighborhood to contradict to assumption.  Assume $F$ is continuous, then we have $\{(f,e): a<f(e)<b\}$ is open in product topology of $E'\times E$, for any $a,b\in \mathbb R$. This means there is some open set $U'$ in $E'$ and $U$ in $E$ such that $$U'\times U\subset \{(f,e): a<f(e)<b\}$$ Now let $V:=\{e\in E: a<f(e)<b;\forall f\in U'\}$, this is open convex neighborhood of origin, but how to prove this is bounded.   Or we have any other way to produce such a neighborhood. Thanks for your time.",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
86,Compute spectral/projection-valued measures explicitly?,Compute spectral/projection-valued measures explicitly?,,"Spectral/projection-valued measures have very handy applications theoretically, but I got stuck when asked to compute explicitly certain projection-valued measures. Let's focus on the following: Let $ N: {\mathcal{L}^{2}}([0,1]) \to {\mathcal{L}^{2}}([0,1]) $ be the normal operator defined by   $$ \forall f \in {\mathcal{L}^{2}}([0,1]),\forall t \in [0,1]: \quad [N(f)](t) \stackrel{\text{def}}{=} t \cdot f(t). $$   What is the projection-valued measure corresponding to $ N $? As $ \sigma(N) = [0,1] $, we need a projection-valued measure $ P $ supported on $ [0,1] $. Theoretically , it should be defined just by $$ P(E) = {\chi_{E}}(N), $$ where $ \chi_{E} $ is the characteristic function of $ E \subseteq [0,1] $ and $ {\chi_{E}}(N) $ is obtained via the Borel functional calculus of $ N $. However, to find $ {\chi_{E}}(N) $, we need to find a sequence of polynomial functions converging to $ \chi_{E} $, which is not an easy job. I somehow feel that the projection-valued measure is given simply by $ P(E) = {\chi_{E}}(N) $, but I am not sure. Can someone give a hint on how to compute the spectral/projection-valued measure explicitly? Thanks!","Spectral/projection-valued measures have very handy applications theoretically, but I got stuck when asked to compute explicitly certain projection-valued measures. Let's focus on the following: Let $ N: {\mathcal{L}^{2}}([0,1]) \to {\mathcal{L}^{2}}([0,1]) $ be the normal operator defined by   $$ \forall f \in {\mathcal{L}^{2}}([0,1]),\forall t \in [0,1]: \quad [N(f)](t) \stackrel{\text{def}}{=} t \cdot f(t). $$   What is the projection-valued measure corresponding to $ N $? As $ \sigma(N) = [0,1] $, we need a projection-valued measure $ P $ supported on $ [0,1] $. Theoretically , it should be defined just by $$ P(E) = {\chi_{E}}(N), $$ where $ \chi_{E} $ is the characteristic function of $ E \subseteq [0,1] $ and $ {\chi_{E}}(N) $ is obtained via the Borel functional calculus of $ N $. However, to find $ {\chi_{E}}(N) $, we need to find a sequence of polynomial functions converging to $ \chi_{E} $, which is not an easy job. I somehow feel that the projection-valued measure is given simply by $ P(E) = {\chi_{E}}(N) $, but I am not sure. Can someone give a hint on how to compute the spectral/projection-valued measure explicitly? Thanks!",,"['functional-analysis', 'measure-theory', 'operator-theory', 'hilbert-spaces', 'operator-algebras']"
87,Prove that energy functional cannot be minimized,Prove that energy functional cannot be minimized,,"As an exercise I want to show that for $$E(v)=\int_0^1 \frac 1 2 x^5 (v'(x))^2  - v(x) dx $$ and $H_0^1(0,1) = \{ v \in H^1(0,1) : v(0)=v(1)=0 \}$ there exists no solution to the problem $$\min_{v\in H_0^1} E(v).$$ Actually I have no clue how to find (or construct?) such a function $v$ with which I can prove this. Who can help?","As an exercise I want to show that for $$E(v)=\int_0^1 \frac 1 2 x^5 (v'(x))^2  - v(x) dx $$ and $H_0^1(0,1) = \{ v \in H^1(0,1) : v(0)=v(1)=0 \}$ there exists no solution to the problem $$\min_{v\in H_0^1} E(v).$$ Actually I have no clue how to find (or construct?) such a function $v$ with which I can prove this. Who can help?",,"['functional-analysis', 'sobolev-spaces']"
88,Compactness in $C_0(\mathbb{R})$,Compactness in,C_0(\mathbb{R}),"Is there a compact set in $C_0(\mathbb{R})$ (continuous functions vanishing at infinity) that contains the unit sphere of $C_0^1(\mathbb{R})$ (differentiable functions in $C_0(\mathbb{R})$ such that the derivative is also in $C_0(\mathbb{R})$)? The norm in the Banach space $C_0^1(\mathbb{R})$ being defined as $\|f\|_1:=\max(\|f\|,\|f'\|)$.","Is there a compact set in $C_0(\mathbb{R})$ (continuous functions vanishing at infinity) that contains the unit sphere of $C_0^1(\mathbb{R})$ (differentiable functions in $C_0(\mathbb{R})$ such that the derivative is also in $C_0(\mathbb{R})$)? The norm in the Banach space $C_0^1(\mathbb{R})$ being defined as $\|f\|_1:=\max(\|f\|,\|f'\|)$.",,"['functional-analysis', 'compactness']"
89,Help showing subadditivity of a map,Help showing subadditivity of a map,,"I'm stuck with the following problem. Show that the map: $$ r(x)=\inf\limits_{k\in\mathbb{N}}\limsup\limits_{m\to\infty}\frac{1}{k}\sum\limits_{j=0}^{k-1}S^j(x)(m) $$ is subadditive on $\ell_\infty(\mathbb{N})$. Here  $$ S:\ell_\infty(\mathbb{N})\to\ell_\infty(\mathbb{N}): (x(1),x(2),x(3),\ldots)\mapsto(0,x(1),x(2),x(3),\ldots) $$ Any help greatly appreciated!","I'm stuck with the following problem. Show that the map: $$ r(x)=\inf\limits_{k\in\mathbb{N}}\limsup\limits_{m\to\infty}\frac{1}{k}\sum\limits_{j=0}^{k-1}S^j(x)(m) $$ is subadditive on $\ell_\infty(\mathbb{N})$. Here  $$ S:\ell_\infty(\mathbb{N})\to\ell_\infty(\mathbb{N}): (x(1),x(2),x(3),\ldots)\mapsto(0,x(1),x(2),x(3),\ldots) $$ Any help greatly appreciated!",,['functional-analysis']
90,References on similarity orbits of operators,References on similarity orbits of operators,,"Given an operator $T\in\mathcal{L}(\mathcal{H})$, where $\mathcal{H}$ is a separable Hilbert space, the similarity orbit of $T$ is defined by \begin{equation} SO(T)=\{STS^{-1}:S\in\mathcal{L}(\mathcal{H})\}. \end{equation} I read about this theory in some papers but I wonder whether there is some good books discussing this issue systematically. I am particularly interested in properties like what is the infimum of norm of operators in $SO(T)$ and how far is the orbit from diagonal operators? compact operators? finite rank operators? Thanks!","Given an operator $T\in\mathcal{L}(\mathcal{H})$, where $\mathcal{H}$ is a separable Hilbert space, the similarity orbit of $T$ is defined by \begin{equation} SO(T)=\{STS^{-1}:S\in\mathcal{L}(\mathcal{H})\}. \end{equation} I read about this theory in some papers but I wonder whether there is some good books discussing this issue systematically. I am particularly interested in properties like what is the infimum of norm of operators in $SO(T)$ and how far is the orbit from diagonal operators? compact operators? finite rank operators? Thanks!",,"['functional-analysis', 'operator-theory']"
91,Prove that the Lipschitz constant cannot be less than $1$,Prove that the Lipschitz constant cannot be less than,1,"I was asked to study the following map: let $I=[0,1]$ and let $f(s)=\log(1+s^2)$ for any $s\in\mathbb R$. For every $u\in L^1(I,\mathbb R)$ we set $$(F(u))(x)=\int_0^xf(u(t))\mathrm d t.$$ First of all I had shown that $F$ maps $L^1(I,\mathbb R)$ into itself. Then the second point was to show that $F$ is Lipschitz continuous from $L^1(I,\mathbb R)$ into itself with Lipschitz constant less than or equal than $1$, and I've done that. Finally the problem asked to show that the Lipschitz constant couldn't be less than $1$. My first approach was to use the Caccioppoli Banach lemma to derive a sort of a contradiction. However if you study the integral equation $$\begin{cases}u(x)=\int_0^x\log(1+u(t)^2)\mathrm d t\\ u(0)=0,\end{cases}$$ then by unicity of the solution one sees that $u\equiv 0$ is the only fixed point... if I am not mistaken. Then i tried to find a sequence of function $u_\lambda\in L^1(I,\mathbb R)$, with $\lambda<1$ such that, $\|Fu_\lambda\|_{L^1}>\lambda\|u_\lambda\|_{L^1}$, but i had no success. Can anybody help me please? thank you... EDIT: As I have written in the comment after DId answer, I don't think that his method matches my idea of proceeding in the exercise.. as it is written, it sounds troublesome to me.. Can anyone help me in finishing the problem? Ps: sorry for accepting the answer, but as I wrote in the comment, I rushed in checking the detail because that kind of functions were also my first candidate to solve the exercise. However, let me again thank Did for answering.","I was asked to study the following map: let $I=[0,1]$ and let $f(s)=\log(1+s^2)$ for any $s\in\mathbb R$. For every $u\in L^1(I,\mathbb R)$ we set $$(F(u))(x)=\int_0^xf(u(t))\mathrm d t.$$ First of all I had shown that $F$ maps $L^1(I,\mathbb R)$ into itself. Then the second point was to show that $F$ is Lipschitz continuous from $L^1(I,\mathbb R)$ into itself with Lipschitz constant less than or equal than $1$, and I've done that. Finally the problem asked to show that the Lipschitz constant couldn't be less than $1$. My first approach was to use the Caccioppoli Banach lemma to derive a sort of a contradiction. However if you study the integral equation $$\begin{cases}u(x)=\int_0^x\log(1+u(t)^2)\mathrm d t\\ u(0)=0,\end{cases}$$ then by unicity of the solution one sees that $u\equiv 0$ is the only fixed point... if I am not mistaken. Then i tried to find a sequence of function $u_\lambda\in L^1(I,\mathbb R)$, with $\lambda<1$ such that, $\|Fu_\lambda\|_{L^1}>\lambda\|u_\lambda\|_{L^1}$, but i had no success. Can anybody help me please? thank you... EDIT: As I have written in the comment after DId answer, I don't think that his method matches my idea of proceeding in the exercise.. as it is written, it sounds troublesome to me.. Can anyone help me in finishing the problem? Ps: sorry for accepting the answer, but as I wrote in the comment, I rushed in checking the detail because that kind of functions were also my first candidate to solve the exercise. However, let me again thank Did for answering.",,['functional-analysis']
92,Bounded extension,Bounded extension,,"What are the easiest examples of a pairs of Banach spaces $X,Y$ such that $X\subseteq Y$ ($X$ is a closed linear subspace of $Y$) there is a bounded linear map $T\colon X\to Y$; there is no bounded extension $\hat{T}\colon Y\to Y$ of $T$? Needless to say, I am interested in the structure of the operator $T$ rather than in its existence.","What are the easiest examples of a pairs of Banach spaces $X,Y$ such that $X\subseteq Y$ ($X$ is a closed linear subspace of $Y$) there is a bounded linear map $T\colon X\to Y$; there is no bounded extension $\hat{T}\colon Y\to Y$ of $T$? Needless to say, I am interested in the structure of the operator $T$ rather than in its existence.",,"['functional-analysis', 'banach-spaces']"
93,Weak convergence,Weak convergence,,"Let $H$ be a Hilbert space with inner product $\langle\cdot,\cdot\rangle$ and let $V,W$ be two closed subspaces. For $x_0\in H$ we may define the sequence of projections $$x_{2n+1}=P_W(x_{2n}), \qquad x_{2n+2}=P_V(x_{2n+1}).$$ I intend to prove that if $V\cap W=\{0\}$, then $x_n\rightarrow 0$. In the first place, one can easily show that $||x_{n+1}||^2=\langle x_{n+1},x_n\rangle$, from which one easily deduces that the sequence of norms is decreasing, so that $\lVert x_n\rVert\to\ell\geq 0$. Then one can also show that if $V\cap W=\{0\}$ and a subsequemce $\{x_{2n_k}\}_k$ converges weakly to some $x$, then the sequence $\{x_{2n_k+1}\}_k$ also converges weakly to $x$, whence $x=0$. So now it suffices to prove that a subsequence $\{x_{2n_k+1}\}$ converges weakly to something. For this, I first note that $$\lVert x_n\rVert^2=\langle x_{n+1},x_{n-2}\rangle=\cdots=\langle x_{2n-1},x_0\rangle$$ And now I would like to use that the sequence of norms converges and Riesz's representation theorem to conclude weak convergence but I am unsure as to how to proceed, since while it is true that any functional in $H$ is of the for $\langle \cdot,x_0\rangle$, varying $x_0$ also varies the sequence $\{x_{2n-1}\}$. Thanks in advance for any insight.","Let $H$ be a Hilbert space with inner product $\langle\cdot,\cdot\rangle$ and let $V,W$ be two closed subspaces. For $x_0\in H$ we may define the sequence of projections $$x_{2n+1}=P_W(x_{2n}), \qquad x_{2n+2}=P_V(x_{2n+1}).$$ I intend to prove that if $V\cap W=\{0\}$, then $x_n\rightarrow 0$. In the first place, one can easily show that $||x_{n+1}||^2=\langle x_{n+1},x_n\rangle$, from which one easily deduces that the sequence of norms is decreasing, so that $\lVert x_n\rVert\to\ell\geq 0$. Then one can also show that if $V\cap W=\{0\}$ and a subsequemce $\{x_{2n_k}\}_k$ converges weakly to some $x$, then the sequence $\{x_{2n_k+1}\}_k$ also converges weakly to $x$, whence $x=0$. So now it suffices to prove that a subsequence $\{x_{2n_k+1}\}$ converges weakly to something. For this, I first note that $$\lVert x_n\rVert^2=\langle x_{n+1},x_{n-2}\rangle=\cdots=\langle x_{2n-1},x_0\rangle$$ And now I would like to use that the sequence of norms converges and Riesz's representation theorem to conclude weak convergence but I am unsure as to how to proceed, since while it is true that any functional in $H$ is of the for $\langle \cdot,x_0\rangle$, varying $x_0$ also varies the sequence $\{x_{2n-1}\}$. Thanks in advance for any insight.",,"['functional-analysis', 'convergence-divergence', 'hilbert-spaces']"
94,Is the boundary of a compact convex set given by the union of its proper faces?,Is the boundary of a compact convex set given by the union of its proper faces?,,"Let $C$ be a compact convex subset of a finite-dimensional real vector space $V$ with non-empty interior (where $V$ is equipped with the unique Hausdorff linear topology, i.e. with the standard topology on $\mathbb{R}^n \cong V$). Is the boundary of $C$ given by the union of all proper faces of $C$? Recall that a convex subset $F$ of $C$ is a face of $C$ if $\lambda x + (1-\lambda) y \in F$ for some $x, y \in C$ and for some $0 < \lambda < 1$ implies $x, y \in F$. A face $F$ of $C$ is a proper face if $F \neq C$. If the above is true, I'd like to know how to prove it. Moreover, I wonder whether the statement is still true if the set is only closed and what one can say about the more general case of any (not necessarily finite-dimensional) locally convex space $V$.","Let $C$ be a compact convex subset of a finite-dimensional real vector space $V$ with non-empty interior (where $V$ is equipped with the unique Hausdorff linear topology, i.e. with the standard topology on $\mathbb{R}^n \cong V$). Is the boundary of $C$ given by the union of all proper faces of $C$? Recall that a convex subset $F$ of $C$ is a face of $C$ if $\lambda x + (1-\lambda) y \in F$ for some $x, y \in C$ and for some $0 < \lambda < 1$ implies $x, y \in F$. A face $F$ of $C$ is a proper face if $F \neq C$. If the above is true, I'd like to know how to prove it. Moreover, I wonder whether the statement is still true if the set is only closed and what one can say about the more general case of any (not necessarily finite-dimensional) locally convex space $V$.",,"['functional-analysis', 'convex-analysis']"
95,Question about continuous functional calculus and its application,Question about continuous functional calculus and its application,,"I recently started learning about the topic functional calculus. My problem is that I have no idea on how to use it for, say, solving problems, exercises etc. Here is a short review of what I learned so far. The idea behind functional calculus seems to be that one would like to ""apply"" a function $f$ to an operator $T$ . If for example $f: \mathbb{R} \rightarrow \mathbb{R}$ and $T: H_1 \rightarrow H_2$ , the term $f(T)$ does not make any sense, since the domain of $f$ is $\mathbb{R}$ . But one could still make sense of the term $f(T)$ . For example, if we consider a matrix $M \in M_{n \times m }$ and $f$ to be a polynomial, for example $f(x)=3x^3-x^2$ . Then $f(M)$ could be viewed as $3M^3-M^2$ , which are defined for matrices, so everything is fine. Let $H$ denote a complex Hilbert space. And $L(H)$ denote the set of bounded and linear operators on $H$ . Then the range of $T$ was introduced as $R(T):=\{\langle Tx,x\rangle: \lVert x\rVert =1\}$ . It is mentioned that $R(T)$ is bounded, thus $R(T)$ is compact. Then it is shown that for $T \in L(H)$ , $\sigma(T) \subset \overline{R(T)}$ . (Where $\sigma(T)$ denotes the spectrum of $T$ .) If T is self-adjoint, then $\sigma(T) \subset [m(T),M(T)]$ , where $m(T):=\inf\{\langle Tx,x\rangle :\lVert x\rVert=1\}$ and $M(T):=\sup\{\langle Tx,x\rangle :\lVert x\rVert=1\}$ . After those technicalities, it is mentioned that one wants to define $f(T)$ for $f \in C(\sigma(T))$ . Let $f$ be a polynomial with complex coefficients, i.e. $f(t):=\sum_{k=0}^nc_kt^k$ . Then $f(T)$ means the operator $\sum_{k=0}^nc_kT^k$ . One crucial thing seems to be that polynomials are dense in the set of continuous functions. Let $t$ denote the identity function and $1$ denote the constant function $t \mapsto 1$ . Theorem (Continuous functional calculus) Let T \in L(H) be self-adjoint. Then there exists exactly one map $\Phi: C(\sigma(T)) \rightarrow L(H)$ such that $\Phi(t)=T, \Phi(1)=Id$ $\Phi$ is linear, $\Phi(fg)= \phi(f)\phi(g)$ and $\Phi( \overline{f})=\Phi(f)^*$ $\Phi$ is continuous We call $\Phi$ the continuous functional calculus of $T$ . We will write $f(T):=\Phi(f)$ for $f\in C(\sigma(T))$ . As mentioned at the beginning, I have no idea on how to approach a problem using (continuous) functional calculus. For example, I tried to find some exercise that should be solvable by using functional calculi, but I do not know how to approach those neither how to use functional calculus. Here are some of the Problems I found: Let $T \in L(H)$ be self-adjoint and $\lambda \in \mathbb{C} \setminus(\sigma(T))$ . Then $d(\lambda, \sigma(T))=\lVert (T-\lambda Id)^{-1}\rVert^{-1}$ Let $T \in L(H)$ be self-adjoint and f \in C(\sigma(T)). Show that the following are equivalent: (i) $f(T)$ is a positive operator (ii) $f \geq 0$ If $T \in L(H)$ is a self-adjoint Operator, then there exist two positive operators $T_1,T_2 \in L(H)$ such that $T=T_1-T_2$ (Are $T_1$ and $T_2$ unique?) I assume that I am missing some crucial idea or point, and that's the reason why I have no clue in how to approach the problems above. Small Edit: My guess in approaching problems by using functional calculus is to define the function $\Phi$ (that is literally called continuous functional calculus of $T$ ) and then to try to use some denseness argument to get to the result. But how does one ""find"" $\Phi$ . In the Theorem, it is stated that there exists (exactly one) $\Phi$ , but not how to find it.","I recently started learning about the topic functional calculus. My problem is that I have no idea on how to use it for, say, solving problems, exercises etc. Here is a short review of what I learned so far. The idea behind functional calculus seems to be that one would like to ""apply"" a function to an operator . If for example and , the term does not make any sense, since the domain of is . But one could still make sense of the term . For example, if we consider a matrix and to be a polynomial, for example . Then could be viewed as , which are defined for matrices, so everything is fine. Let denote a complex Hilbert space. And denote the set of bounded and linear operators on . Then the range of was introduced as . It is mentioned that is bounded, thus is compact. Then it is shown that for , . (Where denotes the spectrum of .) If T is self-adjoint, then , where and . After those technicalities, it is mentioned that one wants to define for . Let be a polynomial with complex coefficients, i.e. . Then means the operator . One crucial thing seems to be that polynomials are dense in the set of continuous functions. Let denote the identity function and denote the constant function . Theorem (Continuous functional calculus) Let T \in L(H) be self-adjoint. Then there exists exactly one map such that is linear, and is continuous We call the continuous functional calculus of . We will write for . As mentioned at the beginning, I have no idea on how to approach a problem using (continuous) functional calculus. For example, I tried to find some exercise that should be solvable by using functional calculi, but I do not know how to approach those neither how to use functional calculus. Here are some of the Problems I found: Let be self-adjoint and . Then Let be self-adjoint and f \in C(\sigma(T)). Show that the following are equivalent: (i) is a positive operator (ii) If is a self-adjoint Operator, then there exist two positive operators such that (Are and unique?) I assume that I am missing some crucial idea or point, and that's the reason why I have no clue in how to approach the problems above. Small Edit: My guess in approaching problems by using functional calculus is to define the function (that is literally called continuous functional calculus of ) and then to try to use some denseness argument to get to the result. But how does one ""find"" . In the Theorem, it is stated that there exists (exactly one) , but not how to find it.","f T f: \mathbb{R} \rightarrow \mathbb{R} T: H_1 \rightarrow H_2 f(T) f \mathbb{R} f(T) M \in M_{n \times m } f f(x)=3x^3-x^2 f(M) 3M^3-M^2 H L(H) H T R(T):=\{\langle Tx,x\rangle: \lVert x\rVert =1\} R(T) R(T) T \in L(H) \sigma(T) \subset \overline{R(T)} \sigma(T) T \sigma(T) \subset [m(T),M(T)] m(T):=\inf\{\langle Tx,x\rangle :\lVert x\rVert=1\} M(T):=\sup\{\langle Tx,x\rangle :\lVert x\rVert=1\} f(T) f \in C(\sigma(T)) f f(t):=\sum_{k=0}^nc_kt^k f(T) \sum_{k=0}^nc_kT^k t 1 t \mapsto 1 \Phi: C(\sigma(T)) \rightarrow L(H) \Phi(t)=T, \Phi(1)=Id \Phi \Phi(fg)= \phi(f)\phi(g) \Phi( \overline{f})=\Phi(f)^* \Phi \Phi T f(T):=\Phi(f) f\in C(\sigma(T)) T \in L(H) \lambda \in \mathbb{C} \setminus(\sigma(T)) d(\lambda, \sigma(T))=\lVert (T-\lambda Id)^{-1}\rVert^{-1} T \in L(H) f(T) f \geq 0 T \in L(H) T_1,T_2 \in L(H) T=T_1-T_2 T_1 T_2 \Phi T \Phi \Phi","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'functional-calculus']"
96,Three topologies on the space of sections of a vector bundle,Three topologies on the space of sections of a vector bundle,,"Let $E\to M$ be a Riemannian vector bundle over an oriented Riemannian manifold $(M,g)$ with a connection $\nabla$ . Let $\Gamma(E)$ denote the vector space of sections of $E\to M$ . For $\sigma \in \Gamma(E)$ , its Sobolev $k$ -norm $(k=1,2,\dots)$ is defined by $$ |\sigma|_k^2:=\int_M ||\sigma||^2+||\nabla \sigma||^2+\cdots+||\nabla^k \sigma||^2 v_g$$ where $v_g$ is the volume form of $M$ . The completion of the space $V^k(E):=\{\sigma \in \Gamma(E):|\sigma|_k<\infty\}$ is denoted by $W^k(E)$ . I want to compare three different topologies on $V^k(E)$ . By definition of $W^k(E)$ we have $V^k(E)\subset W^k(E)$ , and the norm $|\cdot |_k$ on $W^k(E)$ defines a topology on $W^k(E)$ , and hence on $V^k(E)$ . Second, since $\Gamma(E)$ is a vector space it has a topology: the  weak topology determined by all finite-dimensional subspaces (cf. Infinite Dimensional Topological Vector Space ). Since $V^k(E)\subset \Gamma(E)$ , we have another topology on $V^k(E)$ . Finally, there is a topology $V^k(E)$ induced by the $C^\infty$ -topology ( https://en.wikipedia.org/wiki/Whitney_topologies#Whitney_C%E2%88%9E-topology ) of $C^\infty(M,E)$ . Are these three topologies the same? Is there a ""natural"" choice of a topology of $\Gamma(E)$ that are used commonly?","Let be a Riemannian vector bundle over an oriented Riemannian manifold with a connection . Let denote the vector space of sections of . For , its Sobolev -norm is defined by where is the volume form of . The completion of the space is denoted by . I want to compare three different topologies on . By definition of we have , and the norm on defines a topology on , and hence on . Second, since is a vector space it has a topology: the  weak topology determined by all finite-dimensional subspaces (cf. Infinite Dimensional Topological Vector Space ). Since , we have another topology on . Finally, there is a topology induced by the -topology ( https://en.wikipedia.org/wiki/Whitney_topologies#Whitney_C%E2%88%9E-topology ) of . Are these three topologies the same? Is there a ""natural"" choice of a topology of that are used commonly?","E\to M (M,g) \nabla \Gamma(E) E\to M \sigma \in \Gamma(E) k (k=1,2,\dots)  |\sigma|_k^2:=\int_M ||\sigma||^2+||\nabla \sigma||^2+\cdots+||\nabla^k \sigma||^2 v_g v_g M V^k(E):=\{\sigma \in \Gamma(E):|\sigma|_k<\infty\} W^k(E) V^k(E) W^k(E) V^k(E)\subset W^k(E) |\cdot |_k W^k(E) W^k(E) V^k(E) \Gamma(E) V^k(E)\subset \Gamma(E) V^k(E) V^k(E) C^\infty C^\infty(M,E) \Gamma(E)","['functional-analysis', 'differential-geometry', 'sobolev-spaces', 'vector-bundles', 'complete-spaces']"
97,Reduced groupoid $C^*$-algebra,Reduced groupoid -algebra,C^*,"I was reading Ozawa's book and in Chapter 5 they discuss $C^* $ -algebras of locally compact Hausforff étale groupoids. I have a question regarding the reduced $C^* $ -algebra construction. It is first defined by considering the $* $ -algebra $C_c(G)$ and endow it with a $C_0(G^{(0)})$ -valued inner product defined for $f,g \in C_c(G)$ and $x \in G^{(0)}$ by $$ \langle f,g \rangle(x) = \sum\limits_{\gamma \in G_x}\overline{f(\gamma)}g(\gamma). $$ Thus we obtain the Hilbert module $L^2(G)$ completing $C_c(G)$ for this inner product. Now we define the left regular representation $\lambda: C_c(G) \xrightarrow{} B(L^2(G))$ by $$ \lambda(f)g = f* g, \quad \text{ for } f,g \in C_c(G), $$ and endow $C_c(G)$ with the norm $\|f\|_\lambda := \|\lambda(f)\|.$ Completing for this norm, we obtain the reduced groupoid $C^* $ -algebra, denoted by $C_\lambda^* (G)$ . However, there is a footnote saying that we can consider a Hilbert space instead of module by letting $\mu$ be a regular Borel measure with full support on $G^{(0)}$ and defining an inner product on $C_c(G)$ by $$ \langle f,g \rangle_\mu := \int_{G^{(0)}} \langle f,g \rangle(x) d\mu, $$ obtaining the Hilber space $L^2(G,\mu)$ through completion. We can then consider the same regular representation on $B(L^2(G,\mu))$ and complete $C_c(G)$ for the norm $\|f\|_{\lambda,\mu} := \|\lambda(f) \|_{B(L^2(G,\mu))}$ and lets denote this by $C_{\lambda,\mu}^* (G)$ . My question is how do these norms relate. The first one is $$ \|f\|_\lambda^2 = \|\lambda(f)\|_{B(L^2(G))}^2 = \sup\limits_{\|g\|_{L^2(G)}=1} \|f * g \|_{L^2(G)}^2 = \sup\limits_{\|g\|_{L^2(G)}=1} \| \langle f * g, f * g \rangle \|_\infty. $$ while the second, $$ \| f \|_{\lambda,\mu}^2 = \| \lambda(f) \|_{B(L^2(G,\mu))}^2 = \sup\limits_{\| g \|_{L^2(G,\mu)} = 1} \| f * g \|_{L^2(G,\mu)}^2 = \sup\limits_{\| g \|_{L^2(G,\mu)}=1} \int_{G^{(0)}} \langle f * g, f * g \rangle(x) d\mu .  $$ We can see that in case 1 the norm is obtained by taking taking the infinity norm of $\langle f* g,f* g \rangle$ but on the second we take the $L^1$ norm of the same function. Because of this I'm having troubles believing these form the same $C^* $ -algebra, did I misunderstand something?","I was reading Ozawa's book and in Chapter 5 they discuss -algebras of locally compact Hausforff étale groupoids. I have a question regarding the reduced -algebra construction. It is first defined by considering the -algebra and endow it with a -valued inner product defined for and by Thus we obtain the Hilbert module completing for this inner product. Now we define the left regular representation by and endow with the norm Completing for this norm, we obtain the reduced groupoid -algebra, denoted by . However, there is a footnote saying that we can consider a Hilbert space instead of module by letting be a regular Borel measure with full support on and defining an inner product on by obtaining the Hilber space through completion. We can then consider the same regular representation on and complete for the norm and lets denote this by . My question is how do these norms relate. The first one is while the second, We can see that in case 1 the norm is obtained by taking taking the infinity norm of but on the second we take the norm of the same function. Because of this I'm having troubles believing these form the same -algebra, did I misunderstand something?","C^*  C^*  *  C_c(G) C_0(G^{(0)}) f,g \in C_c(G) x \in G^{(0)} 
\langle f,g \rangle(x) = \sum\limits_{\gamma \in G_x}\overline{f(\gamma)}g(\gamma).
 L^2(G) C_c(G) \lambda: C_c(G) \xrightarrow{} B(L^2(G)) 
\lambda(f)g = f* g, \quad \text{ for } f,g \in C_c(G),
 C_c(G) \|f\|_\lambda := \|\lambda(f)\|. C^*  C_\lambda^* (G) \mu G^{(0)} C_c(G) 
\langle f,g \rangle_\mu := \int_{G^{(0)}} \langle f,g \rangle(x) d\mu,
 L^2(G,\mu) B(L^2(G,\mu)) C_c(G) \|f\|_{\lambda,\mu} := \|\lambda(f) \|_{B(L^2(G,\mu))} C_{\lambda,\mu}^* (G) 
\|f\|_\lambda^2 = \|\lambda(f)\|_{B(L^2(G))}^2 = \sup\limits_{\|g\|_{L^2(G)}=1} \|f * g \|_{L^2(G)}^2 = \sup\limits_{\|g\|_{L^2(G)}=1} \| \langle f * g, f * g \rangle \|_\infty.
  \| f \|_{\lambda,\mu}^2 = \| \lambda(f) \|_{B(L^2(G,\mu))}^2 = \sup\limits_{\| g \|_{L^2(G,\mu)} = 1} \| f * g \|_{L^2(G,\mu)}^2 = \sup\limits_{\| g \|_{L^2(G,\mu)}=1} \int_{G^{(0)}} \langle f * g, f * g \rangle(x) d\mu . 
 \langle f* g,f* g \rangle L^1 C^* ","['functional-analysis', 'operator-algebras', 'c-star-algebras', 'groupoids']"
98,How to show the continuity of the Laplacian of the heat kernel (in t),How to show the continuity of the Laplacian of the heat kernel (in t),,"Let $K_t(x):=(4\pi t)^{-\frac{d}{2}}e^{-\frac{x^2}{4t}}$ be the heat kernel for $t > 0$ . How can I show that the function $t \mapsto (\Delta K_t)*f$ is continuous in $L^p(\mathbb{R}^d)$ (associated with the $L^p$ norm) for $f \in C_c^{\infty}(\mathbb{R}^d)$ ? I have proven the the continuity of this function $t \mapsto(\Delta K_t)*f(x)$ for every $x$ but clearly this is not sufficient. I have that $\lvert| \Delta K_t |\rvert_{1}\leq \frac{d}{2t}+ \frac{1}{2}(4 \pi t)^{-d/2}(\frac{\pi}{t})^{1/2}$ , but I can't find the correct bound function to use this.","Let be the heat kernel for . How can I show that the function is continuous in (associated with the norm) for ? I have proven the the continuity of this function for every but clearly this is not sufficient. I have that , but I can't find the correct bound function to use this.",K_t(x):=(4\pi t)^{-\frac{d}{2}}e^{-\frac{x^2}{4t}} t > 0 t \mapsto (\Delta K_t)*f L^p(\mathbb{R}^d) L^p f \in C_c^{\infty}(\mathbb{R}^d) t \mapsto(\Delta K_t)*f(x) x \lvert| \Delta K_t |\rvert_{1}\leq \frac{d}{2t}+ \frac{1}{2}(4 \pi t)^{-d/2}(\frac{\pi}{t})^{1/2},"['functional-analysis', 'partial-differential-equations', 'heat-equation']"
99,Is $T$ totally bounded when $C_u(T)$ is separable?,Is  totally bounded when  is separable?,T C_u(T),"I'm seeking help with a question regarding the space of bounded and uniformly continuous functions $C_u(T,d)$ , where $(T,d)$ is a metric space. In this context, $C_u(T)$ is a closed subspace of $C_b(T)$ , therefore it is a Banach space as well. In the second edition of Giné and Nickl's Mathematical Foundations of Infinite-Dimensional Statistical Models (2021), page 17 , a statement reads, The Banach space $C_u(T,d)$ is separable if (and only if) $(T,d)$ is totally bounded. While I've been struggling with the proof of the ""only if"" part for the past three weeks, I've also attempted to construct counterexamples. I'm now seeking additional ideas or guidance to approach this problem. Here is what I have tried so far: I proved $C_b(T,d)$ is separable if and only if $(T,d)$ is compact, following Conway's A Course in Functional Analysis (2007) Theorem V.6.6 (p.140). If we can prove ""when $C_u(T,d)$ is separable, the completion of $T$ , denoted as $\overline{T}$ , is compact,"" we can prove the version for $C_u(T,d)$ . However, obtaining the Banach space isomorphism $C_u(T)\simeq_{\mathrm{Ban}}C_b(\overline{T})$ proves challenging, although $C_u(T)\simeq_{\mathrm{Ban}}C_u(\overline{T})$ is a relatively straightforward result. Abandoning the use of the $C_b(T)$ version's result, I examined other paths. If $C_u(T)$ is separable, the closed unit ball of the dual space $B^*\subset C_u(T)^*$ is metrizable. Coupled with the fact $B^*$ is always $w^*$ -compact, we find $B^*$ to be $w^*$ -sequentially compact. Hoping this would offer a proof to the original problem, I turned to the property of a metric space being totally bounded if and only if every sequence has a Cauchy subsequence. For an arbitrary sequence $\{x_n\}\subset T$ , we obtain a $w^*$ -convergent subsequence $\{\delta_{x_{n_k}}\}\subset B^*$ . However, attempts to prove $\{x_{n_k}\}\subset T$ as a Cauchy sequence by evaluating at some specially constructed $f_1,f_2,\cdots\in C_u(T)$ have been unsuccessful. Thank you for any suggestions or insights you can provide. Update: I also posted the same query on mathoverflow","I'm seeking help with a question regarding the space of bounded and uniformly continuous functions , where is a metric space. In this context, is a closed subspace of , therefore it is a Banach space as well. In the second edition of Giné and Nickl's Mathematical Foundations of Infinite-Dimensional Statistical Models (2021), page 17 , a statement reads, The Banach space is separable if (and only if) is totally bounded. While I've been struggling with the proof of the ""only if"" part for the past three weeks, I've also attempted to construct counterexamples. I'm now seeking additional ideas or guidance to approach this problem. Here is what I have tried so far: I proved is separable if and only if is compact, following Conway's A Course in Functional Analysis (2007) Theorem V.6.6 (p.140). If we can prove ""when is separable, the completion of , denoted as , is compact,"" we can prove the version for . However, obtaining the Banach space isomorphism proves challenging, although is a relatively straightforward result. Abandoning the use of the version's result, I examined other paths. If is separable, the closed unit ball of the dual space is metrizable. Coupled with the fact is always -compact, we find to be -sequentially compact. Hoping this would offer a proof to the original problem, I turned to the property of a metric space being totally bounded if and only if every sequence has a Cauchy subsequence. For an arbitrary sequence , we obtain a -convergent subsequence . However, attempts to prove as a Cauchy sequence by evaluating at some specially constructed have been unsuccessful. Thank you for any suggestions or insights you can provide. Update: I also posted the same query on mathoverflow","C_u(T,d) (T,d) C_u(T) C_b(T) C_u(T,d) (T,d) C_b(T,d) (T,d) C_u(T,d) T \overline{T} C_u(T,d) C_u(T)\simeq_{\mathrm{Ban}}C_b(\overline{T}) C_u(T)\simeq_{\mathrm{Ban}}C_u(\overline{T}) C_b(T) C_u(T) B^*\subset C_u(T)^* B^* w^* B^* w^* \{x_n\}\subset T w^* \{\delta_{x_{n_k}}\}\subset B^* \{x_{n_k}\}\subset T f_1,f_2,\cdots\in C_u(T)","['functional-analysis', 'function-spaces']"
