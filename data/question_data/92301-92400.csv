,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Entire function with $f(z)=\sin(f(z))$ must be constant?,Entire function with  must be constant?,f(z)=\sin(f(z)),"I'm trying to show why an entire function with the property $f(z)= \sin(f(z))$ everywhere must be constant. Is it sufficient to say that when taking the derivatives, we will get $f'(z)=f'(z) \cdot \cos(f(z))$, so either $f'$ is zero, so $f$ constant, or $\cos(f)=1$, so $f(z)=2 \pi k$ for all $z$, which means that by continuity, $f$ cannot be $2 \pi k_1$ at $z_1$ and $2 \pi k_2$ at $z_2$ for different $k$ (since in the image, along any path from $2\pi k_1$ to $2\pi k_2$, $f$ would not be $1$ anymore), so $f=2\pi k_0$ for some $k_0$, so again, $f$ constant. Do we have the right to use normal chain rule here, since I first tried to use Cauchy-Riemann equations, and did not succeed with that. Or does this require some properties of sine, or is my solution even correct??","I'm trying to show why an entire function with the property $f(z)= \sin(f(z))$ everywhere must be constant. Is it sufficient to say that when taking the derivatives, we will get $f'(z)=f'(z) \cdot \cos(f(z))$, so either $f'$ is zero, so $f$ constant, or $\cos(f)=1$, so $f(z)=2 \pi k$ for all $z$, which means that by continuity, $f$ cannot be $2 \pi k_1$ at $z_1$ and $2 \pi k_2$ at $z_2$ for different $k$ (since in the image, along any path from $2\pi k_1$ to $2\pi k_2$, $f$ would not be $1$ anymore), so $f=2\pi k_0$ for some $k_0$, so again, $f$ constant. Do we have the right to use normal chain rule here, since I first tried to use Cauchy-Riemann equations, and did not succeed with that. Or does this require some properties of sine, or is my solution even correct??",,"['complex-analysis', 'solution-verification', 'functional-equations']"
1,Determine the Winding Numbers of the Chinese Unicom Symbol,Determine the Winding Numbers of the Chinese Unicom Symbol,,"I'm practicing with Winding Numbers , and encountered an interesting example. You might be familiar with this liantong symbol, the logo of China Unicom: Suppose we make this into a fully closed and connected curve, and try to determine the Winding Numbers of the various points in the symbol. For instance: Find the winding numbers of the closed curve shown below at $z_1,z_2,z_3,z_4,z_5$ It seems to me that for each $z$, the winding number $W(z)$ is: $W(z_1)=0$ (since it is outside the curve) $W(z_2)=1$ (since it falls to the left of the curve in one loop) $W(z_3)=-2$ (since it falls to the right of the curve in two loops) $W(z_4)=0$ (since it falls to the right and to the left of the curve twice each, cancelling out) $W(z_5)=-1$ (since it falls to the right of the curve in one loop) Would you agree with these winding numbers (and given reasoning)? Thank you for your help!","I'm practicing with Winding Numbers , and encountered an interesting example. You might be familiar with this liantong symbol, the logo of China Unicom: Suppose we make this into a fully closed and connected curve, and try to determine the Winding Numbers of the various points in the symbol. For instance: Find the winding numbers of the closed curve shown below at $z_1,z_2,z_3,z_4,z_5$ It seems to me that for each $z$, the winding number $W(z)$ is: $W(z_1)=0$ (since it is outside the curve) $W(z_2)=1$ (since it falls to the left of the curve in one loop) $W(z_3)=-2$ (since it falls to the right of the curve in two loops) $W(z_4)=0$ (since it falls to the right and to the left of the curve twice each, cancelling out) $W(z_5)=-1$ (since it falls to the right of the curve in one loop) Would you agree with these winding numbers (and given reasoning)? Thank you for your help!",,"['complex-analysis', 'plane-curves', 'winding-number']"
2,Deriving an expression for $\cos^4 x + \sin^4 x$,Deriving an expression for,\cos^4 x + \sin^4 x,"Derive the identity $\cos^4 x + \sin^4 x=\frac{1}{4} \cos (4x) +\frac{3}{4}$ I know $e^{i4x}=\cos (4x) + i \sin (4x)=(\cos x +i \sin x)^4$. Then I use the binomial theorem to expand this fourth power, and comparing real and imaginary parts, I conclude that $\cos^4 x + \sin^4 x = \cos (4x) + 6 \cos^2 (x) \sin^2 (x)$. So now I need to show that $\cos (4x) + 6 \cos^2 (x) \sin^2 (x)=\frac{1}{4} \cos (4x) +\frac{3}{4}$, which has stumped me.","Derive the identity $\cos^4 x + \sin^4 x=\frac{1}{4} \cos (4x) +\frac{3}{4}$ I know $e^{i4x}=\cos (4x) + i \sin (4x)=(\cos x +i \sin x)^4$. Then I use the binomial theorem to expand this fourth power, and comparing real and imaginary parts, I conclude that $\cos^4 x + \sin^4 x = \cos (4x) + 6 \cos^2 (x) \sin^2 (x)$. So now I need to show that $\cos (4x) + 6 \cos^2 (x) \sin^2 (x)=\frac{1}{4} \cos (4x) +\frac{3}{4}$, which has stumped me.",,"['complex-analysis', 'trigonometry', 'complex-numbers']"
3,Can it be proved that a Meromorphic function only has a countable number of poles?,Can it be proved that a Meromorphic function only has a countable number of poles?,,"One definition I have seen is that a Meromorphic function has at most a countable number of poles. Another says that a function f is Meromorphic if every point is either a pole or the function is analytic there. Now first an easy question, but I am unsure of it: 1. That poles are isolated, that is usually taken as a definition of the pole? Now come the hard question: 2. Can it be proved that if we use definition 2 of a Meromorphic function it can at most have a coutnable number of poles? If the answer to question 1 is yes, I guess we can assume for contradiction that it has more than a countable number of poles, and then show that it must have a limit point, and hence not be isolated? Is this hard to prove? PS: I think an equivalent question for 2 in terms of $\mathbb{R}^2$ is that lets say that the set A is bigger than just beeing countable(I don't know if this implies if it is uncountable?). Then the set A must have a sequence of distinct points, with a limit point in $\mathbb{R}^2$. But I don't think the limit point must be in A? Is this something we can prove?","One definition I have seen is that a Meromorphic function has at most a countable number of poles. Another says that a function f is Meromorphic if every point is either a pole or the function is analytic there. Now first an easy question, but I am unsure of it: 1. That poles are isolated, that is usually taken as a definition of the pole? Now come the hard question: 2. Can it be proved that if we use definition 2 of a Meromorphic function it can at most have a coutnable number of poles? If the answer to question 1 is yes, I guess we can assume for contradiction that it has more than a countable number of poles, and then show that it must have a limit point, and hence not be isolated? Is this hard to prove? PS: I think an equivalent question for 2 in terms of $\mathbb{R}^2$ is that lets say that the set A is bigger than just beeing countable(I don't know if this implies if it is uncountable?). Then the set A must have a sequence of distinct points, with a limit point in $\mathbb{R}^2$. But I don't think the limit point must be in A? Is this something we can prove?",,['complex-analysis']
4,Show that $\displaystyle u=\frac{1}{2}\log(x^2+y^2)$ is harmonic and find its harmonic conjugate function,Show that  is harmonic and find its harmonic conjugate function,\displaystyle u=\frac{1}{2}\log(x^2+y^2),"Show that $\displaystyle u=\frac{1}{2}\log(x^2+y^2)$ is harmonic and find its harmonic conjugate function. I did the first part to show that $\displaystyle \frac{\partial^2 u}{\partial x^2}+\frac{\partial^2 u}{\partial y^2}=0$ Now, to find v: $\displaystyle\frac{\partial u}{\partial x}=\frac{x}{x^2+y^2}=\frac{\partial v}{\partial y}$ I get $\displaystyle v=\tan^{-1}(\frac{y}{x})$ $\displaystyle\frac{\partial u}{\partial y}=\frac{y}{x^2+y^2}=-\frac{\partial v}{\partial x}$ Here I get $\displaystyle v=-\tan^{-1}(\frac{x}{y})$ What did I do wrong here ?","Show that $\displaystyle u=\frac{1}{2}\log(x^2+y^2)$ is harmonic and find its harmonic conjugate function. I did the first part to show that $\displaystyle \frac{\partial^2 u}{\partial x^2}+\frac{\partial^2 u}{\partial y^2}=0$ Now, to find v: $\displaystyle\frac{\partial u}{\partial x}=\frac{x}{x^2+y^2}=\frac{\partial v}{\partial y}$ I get $\displaystyle v=\tan^{-1}(\frac{y}{x})$ $\displaystyle\frac{\partial u}{\partial y}=\frac{y}{x^2+y^2}=-\frac{\partial v}{\partial x}$ Here I get $\displaystyle v=-\tan^{-1}(\frac{x}{y})$ What did I do wrong here ?",,"['complex-analysis', 'partial-derivative']"
5,Is $f(z)=\bar{z}$ continuous?,Is  continuous?,f(z)=\bar{z},"I have $z\in \mathbb{C}$, is $f(z)=\bar{z}$ continuous on the whole complex plane? Note that $\bar{z}$ is the conjugate of $z\in \mathbb{C}$ I was thinking that if $z$ is on the real line, then $f(z)=z$, but if $z$ is on the imaginary line, then $f(z)=-z$, so I am still questioning about that. I'm sorry if I am asking something so trivial, but lots of things do not seem that straight forward to me. Thank you for input.","I have $z\in \mathbb{C}$, is $f(z)=\bar{z}$ continuous on the whole complex plane? Note that $\bar{z}$ is the conjugate of $z\in \mathbb{C}$ I was thinking that if $z$ is on the real line, then $f(z)=z$, but if $z$ is on the imaginary line, then $f(z)=-z$, so I am still questioning about that. I'm sorry if I am asking something so trivial, but lots of things do not seem that straight forward to me. Thank you for input.",,"['complex-analysis', 'continuity']"
6,Pole of order $\ge 2 \; \Rightarrow \;$ not injective,Pole of order  not injective,\ge 2 \; \Rightarrow \;,Let $D \subseteq \mathbb{C}$ be open and $f : D \rightarrow \mathbb{C}$ meromorphic with a pole of order $\ge 2$ in $a \in D$. Then $f$ is not injective. Is there an easy proof to this? This is not homework; it comes from user8268's answer in entire 1-1 function .,Let $D \subseteq \mathbb{C}$ be open and $f : D \rightarrow \mathbb{C}$ meromorphic with a pole of order $\ge 2$ in $a \in D$. Then $f$ is not injective. Is there an easy proof to this? This is not homework; it comes from user8268's answer in entire 1-1 function .,,['complex-analysis']
7,Analytic Capacity,Analytic Capacity,,For a compact set $K\subset\mathbb{C}$ the analytic capacity is defined as $$\gamma(K)=\sup\{|f^\prime(\infty)|:f\in M_K\}$$ where $M_K$ is the set of bounded holomorphic functions on $\mathbb{C}\backslash K$ with $\|f\|_\infty\le 1$ and $f(\infty)=0$. I have two questions. What is the intuition behind this definition? What does $f^\prime(\infty)$ mean? It doesn't seem to be $\lim_{z\rightarrow\infty}f^\prime(z)$ so I'm confused. It would also help me if somebody could point out a nice expository lecture notes/article on this topic (preferrably available online).,For a compact set $K\subset\mathbb{C}$ the analytic capacity is defined as $$\gamma(K)=\sup\{|f^\prime(\infty)|:f\in M_K\}$$ where $M_K$ is the set of bounded holomorphic functions on $\mathbb{C}\backslash K$ with $\|f\|_\infty\le 1$ and $f(\infty)=0$. I have two questions. What is the intuition behind this definition? What does $f^\prime(\infty)$ mean? It doesn't seem to be $\lim_{z\rightarrow\infty}f^\prime(z)$ so I'm confused. It would also help me if somebody could point out a nice expository lecture notes/article on this topic (preferrably available online).,,"['complex-analysis', 'reference-request']"
8,"Entire, $|f(z)|\le1+\sqrt{|z|}$ implies $f$ is constant","Entire,  implies  is constant",|f(z)|\le1+\sqrt{|z|} f,"I am stuck on the following question. Given that $f$ is an entire function with $|f(z)|\le1+\sqrt{|z|}$ for all $z\in \mathbb{C}$, show that $f$ is constant. Can anyone give me a hint to get me started? OK, based on one of the hints below, I define: $$g(z)=\frac{f(z)-f(0)}{z}$$ Now, let me assume that this is entire by defining $g(0)=f'(0)$. Is that fair, and if so, why? Continuing, $$\begin{align*} \left|g(z)\right| &=\left|\frac{f(z)-f(0)}{z}\right|\\ &\le \left|\frac{f(z)}{z}\right|+\left|\frac{f(0)}{z}\right|\\ &=\frac{|f(z)|}{|z|}+\frac{|f(0)|}{|z|}\\ &\le\frac{1+\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\ &=\frac{1}{|z|}+\frac{\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\ &=\frac{1}{|z|}+\frac{1}{\sqrt{|z|}}+\frac{|f(0)|}{|z|}\\ &\le 1+1+|f(0)|\\ &=2+|f(0)|, \end{align*} $$ provided $|z|\ge 1$. Next, $g$ is entire on the disk $D=\{z:\,|z|\le 1\}$, which is compact, so it must assume a maximum value on this disk, say $|g(z)|\le M$ on $D$. Taking $M_s$ as the smaller of $2+|f(0)|$ and $M$, we have $|g(z)\le M_s$ for all $z\in C$. Now, by Liouville's Theorem, $g$ is constant. However, going back to the beginning of the argument, my only worry is whether $g$ is made entire by defining $g(0)=f'(0)$. I am not sure that is valid. Can someone comment on this and also comment on the above if there are errors? Thanks.","I am stuck on the following question. Given that $f$ is an entire function with $|f(z)|\le1+\sqrt{|z|}$ for all $z\in \mathbb{C}$, show that $f$ is constant. Can anyone give me a hint to get me started? OK, based on one of the hints below, I define: $$g(z)=\frac{f(z)-f(0)}{z}$$ Now, let me assume that this is entire by defining $g(0)=f'(0)$. Is that fair, and if so, why? Continuing, $$\begin{align*} \left|g(z)\right| &=\left|\frac{f(z)-f(0)}{z}\right|\\ &\le \left|\frac{f(z)}{z}\right|+\left|\frac{f(0)}{z}\right|\\ &=\frac{|f(z)|}{|z|}+\frac{|f(0)|}{|z|}\\ &\le\frac{1+\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\ &=\frac{1}{|z|}+\frac{\sqrt{|z|}}{|z|}+\frac{|f(0)|}{|z|}\\ &=\frac{1}{|z|}+\frac{1}{\sqrt{|z|}}+\frac{|f(0)|}{|z|}\\ &\le 1+1+|f(0)|\\ &=2+|f(0)|, \end{align*} $$ provided $|z|\ge 1$. Next, $g$ is entire on the disk $D=\{z:\,|z|\le 1\}$, which is compact, so it must assume a maximum value on this disk, say $|g(z)|\le M$ on $D$. Taking $M_s$ as the smaller of $2+|f(0)|$ and $M$, we have $|g(z)\le M_s$ for all $z\in C$. Now, by Liouville's Theorem, $g$ is constant. However, going back to the beginning of the argument, my only worry is whether $g$ is made entire by defining $g(0)=f'(0)$. I am not sure that is valid. Can someone comment on this and also comment on the above if there are errors? Thanks.",,['complex-analysis']
9,Is Wikipedia incorrect on the Cauchy - Riemann equations (sufficient condition for differentiability)?,Is Wikipedia incorrect on the Cauchy - Riemann equations (sufficient condition for differentiability)?,,"According to Wikipedia , ""Moreover, the equations are necessary and sufficient conditions for complex differentiation once we assume that its real and imaginary parts are differentiable real functions of two variables.""  I've always thought that the C-R equations holding alone isn't sufficient for differentability.  You would need the continuity of the partial derivatives, right?  The talk page made me more confused.","According to Wikipedia , ""Moreover, the equations are necessary and sufficient conditions for complex differentiation once we assume that its real and imaginary parts are differentiable real functions of two variables.""  I've always thought that the C-R equations holding alone isn't sufficient for differentability.  You would need the continuity of the partial derivatives, right?  The talk page made me more confused.",,['complex-analysis']
10,How to show that e.g. $\cos(z)$ is analytic using Cauchy- Riemann differential equations?,How to show that e.g.  is analytic using Cauchy- Riemann differential equations?,\cos(z),"How to show that e.g. $\cos(z)$ is analytic using Cauchy-Riemann differential equations [$u_x(x,y)=v_y(x,y)$ and $u_y(x,y)=-v_x(x,y)$]?  Do all analytic functions satisfy Cauchy-Riemann differential equations (CRDE)?  What is the relationship between analyticity of complex functions and Cauchy-Riemann differential equations?  I know that holomorphic (analytic?) functions satisfy CRDE, but are functions that satisfy CRDE always analytic (holomorphic)?","How to show that e.g. $\cos(z)$ is analytic using Cauchy-Riemann differential equations [$u_x(x,y)=v_y(x,y)$ and $u_y(x,y)=-v_x(x,y)$]?  Do all analytic functions satisfy Cauchy-Riemann differential equations (CRDE)?  What is the relationship between analyticity of complex functions and Cauchy-Riemann differential equations?  I know that holomorphic (analytic?) functions satisfy CRDE, but are functions that satisfy CRDE always analytic (holomorphic)?",,[]
11,Can the argument of an algebraic number be an irrational number times pi?,Can the argument of an algebraic number be an irrational number times pi?,,This is mainly out of curiosity.  Let $\nu$ be an algebraic number.  Can Arg($\nu$) be of the form $\pi \times \mu$ for an irrational number $\mu$?,This is mainly out of curiosity.  Let $\nu$ be an algebraic number.  Can Arg($\nu$) be of the form $\pi \times \mu$ for an irrational number $\mu$?,,"['complex-analysis', 'algebraic-number-theory']"
12,On functions with Fourier transform having compact support,On functions with Fourier transform having compact support,,"I have another question from Stein & Shakarchi, Complex Analysis. The problem is the following: Suppose $\hat{f}$ has compact support contained in $\left[-M,M\right]$ and let $f(z) = \sum_{n=0}^{\infty}{a_{n}z^{n}}$. Show that  $$a_{n}= \frac{(2\pi i)^{n}}{n!} \int_{-M}^{M}{\hat{f}(\xi)\xi^{n} d \xi },\ \text{and so that}\ \ \lim_{n \rightarrow \infty}{\sup{(n! |a_{n}|)^{1/n}}} \leq 2 \pi M.$$ Conversely, if $f(z) = \sum_{n=0}^{\infty}{a_{n}z^{n}}$ is any power series with $\lim_{n \rightarrow \infty}{\sup{(n! |a_{n}|)^{1/n}} }\leq 2 \pi M$, then show that $f$ is entire and for every $\epsilon > 0$ there exists $A_{\epsilon} > 0$ such that $|f(z)| \leq A_{\epsilon}e^{2\pi (M+ \epsilon) |z|}.$ I managed to show that $a_{n}= \frac{(2\pi i)^{n}}{n!} \int_{-M}^{M}{\hat{f}(\xi)\xi^{n} d \xi }$ by using the inversion formula and by changing the order of summation, but I am kind of stuck at the next step and don't see how to deduce the inequality after simplyfing.","I have another question from Stein & Shakarchi, Complex Analysis. The problem is the following: Suppose $\hat{f}$ has compact support contained in $\left[-M,M\right]$ and let $f(z) = \sum_{n=0}^{\infty}{a_{n}z^{n}}$. Show that  $$a_{n}= \frac{(2\pi i)^{n}}{n!} \int_{-M}^{M}{\hat{f}(\xi)\xi^{n} d \xi },\ \text{and so that}\ \ \lim_{n \rightarrow \infty}{\sup{(n! |a_{n}|)^{1/n}}} \leq 2 \pi M.$$ Conversely, if $f(z) = \sum_{n=0}^{\infty}{a_{n}z^{n}}$ is any power series with $\lim_{n \rightarrow \infty}{\sup{(n! |a_{n}|)^{1/n}} }\leq 2 \pi M$, then show that $f$ is entire and for every $\epsilon > 0$ there exists $A_{\epsilon} > 0$ such that $|f(z)| \leq A_{\epsilon}e^{2\pi (M+ \epsilon) |z|}.$ I managed to show that $a_{n}= \frac{(2\pi i)^{n}}{n!} \int_{-M}^{M}{\hat{f}(\xi)\xi^{n} d \xi }$ by using the inversion formula and by changing the order of summation, but I am kind of stuck at the next step and don't see how to deduce the inequality after simplyfing.",,['complex-analysis']
13,Is $z=0$ a pole of $1/\sqrt{z}$?,Is  a pole of ?,z=0 1/\sqrt{z},"Consider the function $f:z\mapsto 1/\sqrt{z}$ , defined, say on the right half-plane $Re(z)>0$ .  (We can resolve ambiguity by  taking the branch that is positive for real $z$ ). Let $U$ be the right half-plane, and $a=0$ . Then the following conditions, lifted from Wikipedia's page on essential singularities , appear to hold: 1) $f(z)$ is not defined at $a$ but is analytic in the region $U$ .  Moreover, every open neighborhood of $a$ has non-empty intersection with $U$ . 2) $\lim_{z\rightarrow a}f(z)$ does not exist. 3) $\lim_{z\rightarrow a}{1\over f(z)}$ exists (and is equal to zero). According to that Wikipedia page, it follows that $a=0$ is a pole of $f$ . But it seems to me that $f$ has no Laurent series at $a=0$ , which makes me skeptical that this really is a pole. This seems to leave three possibilities:  Either Wikipedia is wrong, or I am wrong, or I have misunderstood Wikipedia.  Which of these is correct?","Consider the function , defined, say on the right half-plane .  (We can resolve ambiguity by  taking the branch that is positive for real ). Let be the right half-plane, and . Then the following conditions, lifted from Wikipedia's page on essential singularities , appear to hold: 1) is not defined at but is analytic in the region .  Moreover, every open neighborhood of has non-empty intersection with . 2) does not exist. 3) exists (and is equal to zero). According to that Wikipedia page, it follows that is a pole of . But it seems to me that has no Laurent series at , which makes me skeptical that this really is a pole. This seems to leave three possibilities:  Either Wikipedia is wrong, or I am wrong, or I have misunderstood Wikipedia.  Which of these is correct?",f:z\mapsto 1/\sqrt{z} Re(z)>0 z U a=0 f(z) a U a U \lim_{z\rightarrow a}f(z) \lim_{z\rightarrow a}{1\over f(z)} a=0 f f a=0,"['complex-analysis', 'singularity']"
14,Xmas Maths 2017: The value of a $\color{red}m^{\color{green}{ince}\ \color{orange}{\pi}}$ and $\color{red}\pi^{\color{green}{ie}}$,Xmas Maths 2017: The value of a  and,\color{red}m^{\color{green}{ince}\ \color{orange}{\pi}} \color{red}\pi^{\color{green}{ie}},"In the spirit of the festive season! (i) Evaluate $$\large \color{red}m^{\color{green}i\color{orange}n\color{red}c\color{green}e\;\color{red}\pi}$$ given that $m=12\;\;\text{(month when mince pies are consumed)}\\ n=5\;\;\text{(number of points of the star on a mince pie)}\\ c=2.997\times 10^{8}s^{-1}\; \text{(rate at which mince pies are consumed!)}\\ $ (ii) It is well known that $e^{i\pi}=-1$, but what is the value of $$\large\color{red}\pi^{\color{green}{ie}}$$ ? Merry Christmas!","In the spirit of the festive season! (i) Evaluate $$\large \color{red}m^{\color{green}i\color{orange}n\color{red}c\color{green}e\;\color{red}\pi}$$ given that $m=12\;\;\text{(month when mince pies are consumed)}\\ n=5\;\;\text{(number of points of the star on a mince pie)}\\ c=2.997\times 10^{8}s^{-1}\; \text{(rate at which mince pies are consumed!)}\\ $ (ii) It is well known that $e^{i\pi}=-1$, but what is the value of $$\large\color{red}\pi^{\color{green}{ie}}$$ ? Merry Christmas!",,"['complex-analysis', 'recreational-mathematics']"
15,Complex numbers as exponents [duplicate],Complex numbers as exponents [duplicate],,This question already has answers here : Understanding imaginary exponents (6 answers) Closed 7 years ago . Is there any formula to calculate $2^i$ for example? What about $x^z$? I was surfing through different pages and I couldn't seem to find a formula like de Moivre's with $z^x$.,This question already has answers here : Understanding imaginary exponents (6 answers) Closed 7 years ago . Is there any formula to calculate $2^i$ for example? What about $x^z$? I was surfing through different pages and I couldn't seem to find a formula like de Moivre's with $z^x$.,,"['complex-analysis', 'complex-numbers']"
16,The sum of the residues of a meromorphic differential form on a compact Riemann surface is zero,The sum of the residues of a meromorphic differential form on a compact Riemann surface is zero,,How can one see that the sum of the residues of a meromorphic function on a Riemann surface $ \Sigma_g$ of positive genus is always zero? This is not true for the Riemann sphere $\mathbb{CP}^1$.,How can one see that the sum of the residues of a meromorphic function on a Riemann surface $ \Sigma_g$ of positive genus is always zero? This is not true for the Riemann sphere $\mathbb{CP}^1$.,,"['complex-analysis', 'riemann-surfaces', 'complex-geometry']"
17,why holomorphic function $f$ can't extends continuously to its boundary such that $f(z)=1/z$?,why holomorphic function  can't extends continuously to its boundary such that ?,f f(z)=1/z,Show that there is no holomorphic function $f$ in the unit disc $\Bbb{D}$ that extends continuously to $\partial \Bbb{D}$ such that $$f(z)=\frac{1}{z}$$ for $z \in \partial \Bbb{D}$. where $\Bbb{D}=\{z\in \Bbb{C} : |z|<1\}$,Show that there is no holomorphic function $f$ in the unit disc $\Bbb{D}$ that extends continuously to $\partial \Bbb{D}$ such that $$f(z)=\frac{1}{z}$$ for $z \in \partial \Bbb{D}$. where $\Bbb{D}=\{z\in \Bbb{C} : |z|<1\}$,,['complex-analysis']
18,How to integrate $f( \theta ) = \frac{1}{a + \sin( \theta ) }$?,How to integrate ?,f( \theta ) = \frac{1}{a + \sin( \theta ) },"Let $a > 1$. I am wondering how evaluate the integral: $$ \int_{0}^{2 \pi } \frac{1}{a + \sin( \theta) } d \theta $$ by means of methods of complex analysis. In the homework assignment, the following hint is given: write $\sin( \theta ) = (e^{i \theta } - e^{- i \theta} ) / 2i $ and interpret the integral (after some algebraic manipulations) as a complex line integral of a rational function over the positively oriented unit circle. I write $\theta := t$, so I'll have to type less. This is how I approached the question: We know, from the definition of the complex line integral, that $$ \int_{ \alpha } f(t) dt = \int_{a}^{b} f( \alpha (t) ) \alpha ' (t) .$$ In our case, we have $\alpha(t) = e^{i t}$. So, if we want to rewrite our ""ordinary"" integral as a complex line integral, we have the equation $$ f( \alpha (t) ) \cdot e^{i t} = \frac{1}{a + \frac{ e^{i t} - 1/e^{i t} }{2i} } $$. If we divide both sides by $e^{i t}$, and rewrite the denominator of the resulting fraction a bit, we obtain: $$f( \alpha (t)) = \frac{2i}{e^{2 i t} + 2 i a e^{i t} -1 } . $$ Since we already noted, that $ \alpha(t) = e^{i t} $, I thought that, based on this, we can deduce that $$f(t) = \frac{2i}{t^2 + 2 i a t - 1} $$. From here, I'm not entirely sure how to proceed. One possibility is to find the roots of the polynomial in the denominator of the fraction in the integral, by means of the (abc)-rule. We obtain the roots $t_1 =i a - \sqrt{1 -a} $ and $t_2 = i a + \sqrt{ 1 - a }$. We know, that $a >1 $, so we can rewrite these roots: $t_1 = i a - i \sqrt{a-1} = i(a - \sqrt{a-1} $ , and $t_2 = i a + i \sqrt{a-1} = i (a + \sqrt{a-1} ) $, so we can rewrite our integral as follows: $$ \int_{ \alpha } \frac{1}{ (t - t_1) (t-t_2) } $$ . But how do we proceed from here? We don't know the value of $a$, so we don't know how ""big"" the roots are. Could we use the Cauchy Integral Formula? Or something else? How do we use that we integrate over a positively orientated unit circle?","Let $a > 1$. I am wondering how evaluate the integral: $$ \int_{0}^{2 \pi } \frac{1}{a + \sin( \theta) } d \theta $$ by means of methods of complex analysis. In the homework assignment, the following hint is given: write $\sin( \theta ) = (e^{i \theta } - e^{- i \theta} ) / 2i $ and interpret the integral (after some algebraic manipulations) as a complex line integral of a rational function over the positively oriented unit circle. I write $\theta := t$, so I'll have to type less. This is how I approached the question: We know, from the definition of the complex line integral, that $$ \int_{ \alpha } f(t) dt = \int_{a}^{b} f( \alpha (t) ) \alpha ' (t) .$$ In our case, we have $\alpha(t) = e^{i t}$. So, if we want to rewrite our ""ordinary"" integral as a complex line integral, we have the equation $$ f( \alpha (t) ) \cdot e^{i t} = \frac{1}{a + \frac{ e^{i t} - 1/e^{i t} }{2i} } $$. If we divide both sides by $e^{i t}$, and rewrite the denominator of the resulting fraction a bit, we obtain: $$f( \alpha (t)) = \frac{2i}{e^{2 i t} + 2 i a e^{i t} -1 } . $$ Since we already noted, that $ \alpha(t) = e^{i t} $, I thought that, based on this, we can deduce that $$f(t) = \frac{2i}{t^2 + 2 i a t - 1} $$. From here, I'm not entirely sure how to proceed. One possibility is to find the roots of the polynomial in the denominator of the fraction in the integral, by means of the (abc)-rule. We obtain the roots $t_1 =i a - \sqrt{1 -a} $ and $t_2 = i a + \sqrt{ 1 - a }$. We know, that $a >1 $, so we can rewrite these roots: $t_1 = i a - i \sqrt{a-1} = i(a - \sqrt{a-1} $ , and $t_2 = i a + i \sqrt{a-1} = i (a + \sqrt{a-1} ) $, so we can rewrite our integral as follows: $$ \int_{ \alpha } \frac{1}{ (t - t_1) (t-t_2) } $$ . But how do we proceed from here? We don't know the value of $a$, so we don't know how ""big"" the roots are. Could we use the Cauchy Integral Formula? Or something else? How do we use that we integrate over a positively orientated unit circle?",,['complex-analysis']
19,How do I find $\frac{\text{d}}{\text{d}z}\left(z\bar{z}\right)$?,How do I find ?,\frac{\text{d}}{\text{d}z}\left(z\bar{z}\right),"I am seeking $\frac{\text{d}}{\text{d}z}\left(z\bar{z}\right)$ where $f(z)=z\bar{z}.$ And I know that I need to use the following definition of the derivative: $$f'(z)=\lim_{\Delta z\to 0}{\frac{f(z_0+\Delta z)-f(z_0)}{\Delta z}}.$$ However, I'm not sure if I'm using the definition correctly when I plug in $f(z)$: \begin{align*} f'(z)&=\lim_{\Delta z\to 0}{\frac{(z+\Delta z)(\overline{z+\Delta z})-z\bar{z}}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)+\bar{z}\Delta z}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)}{\Delta z}}+\lim_{\Delta z\to 0}{\frac{\bar{z}\Delta z}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)}{\Delta z}}+\bar{z} \end{align*} Assuming that I've maneuvered the limit above properly, I'm not sure how to continue from the final line...","I am seeking $\frac{\text{d}}{\text{d}z}\left(z\bar{z}\right)$ where $f(z)=z\bar{z}.$ And I know that I need to use the following definition of the derivative: $$f'(z)=\lim_{\Delta z\to 0}{\frac{f(z_0+\Delta z)-f(z_0)}{\Delta z}}.$$ However, I'm not sure if I'm using the definition correctly when I plug in $f(z)$: \begin{align*} f'(z)&=\lim_{\Delta z\to 0}{\frac{(z+\Delta z)(\overline{z+\Delta z})-z\bar{z}}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)+\bar{z}\Delta z}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)}{\Delta z}}+\lim_{\Delta z\to 0}{\frac{\bar{z}\Delta z}{\Delta z}}\\&=\lim_{\Delta z\to 0}{\frac{\overline{\Delta z}(z+\Delta z)}{\Delta z}}+\bar{z} \end{align*} Assuming that I've maneuvered the limit above properly, I'm not sure how to continue from the final line...",,"['complex-analysis', 'limits', 'derivatives']"
20,Is there an elementary method for evaluating $\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)}$?,Is there an elementary method for evaluating ?,\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)},I found a way to evaluate $\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)}$ using the assumption that $s\in\mathbb{R}$ and $0<s<1$. Apparently it should be easily extended to all $s\in\mathbb{C}$ with $0<Re(s)<1$. I posted my solution here: http://thetactician.net/Math/Analysis/Integral1.pdf I'm pretty sure there's a more concise method for evaluating it...and I'd also like to make the extension to $\mathbb{C}$ more rigorous. Any ideas?,I found a way to evaluate $\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)}$ using the assumption that $s\in\mathbb{R}$ and $0<s<1$. Apparently it should be easily extended to all $s\in\mathbb{C}$ with $0<Re(s)<1$. I posted my solution here: http://thetactician.net/Math/Analysis/Integral1.pdf I'm pretty sure there's a more concise method for evaluating it...and I'd also like to make the extension to $\mathbb{C}$ more rigorous. Any ideas?,,['complex-analysis']
21,Explicit Riemann mappings,Explicit Riemann mappings,,"Typical proofs of the Riemann mapping theorem are not terribly explicit (one maximizes a functional, or something equivalent, such as using Dirichlet's principle ). The theorem states that if $U$ is a simply connected open subset of the plane, then there is a biholomorphism between $U$ and the unit disk. I imagine, due to the wild generality of the result, no explicit construction can be expected in general. However, in many concrete cases, I would think a construction ""by hand"" should be possible; and in applications (to problems in engineering, for example), this would almost be a requirement. Do you know of such a construction, or of a reference where these constructions are discussed? (The answer may of course only apply to certain families of open sets.) I know of a very nice reference: ""Schwarz-Christoffel Mapping"", by Tobin A. Driscoll and Lloyd N. Trefethen, Cambridge Monographs on Applied and Computational Mathematics (No. 8). The Schwarz-Christoffel Mappings explicitly give us biholomorphisms between the upper half plane and the interior of simple polygons . I am hoping for additional examples.","Typical proofs of the Riemann mapping theorem are not terribly explicit (one maximizes a functional, or something equivalent, such as using Dirichlet's principle ). The theorem states that if $U$ is a simply connected open subset of the plane, then there is a biholomorphism between $U$ and the unit disk. I imagine, due to the wild generality of the result, no explicit construction can be expected in general. However, in many concrete cases, I would think a construction ""by hand"" should be possible; and in applications (to problems in engineering, for example), this would almost be a requirement. Do you know of such a construction, or of a reference where these constructions are discussed? (The answer may of course only apply to certain families of open sets.) I know of a very nice reference: ""Schwarz-Christoffel Mapping"", by Tobin A. Driscoll and Lloyd N. Trefethen, Cambridge Monographs on Applied and Computational Mathematics (No. 8). The Schwarz-Christoffel Mappings explicitly give us biholomorphisms between the upper half plane and the interior of simple polygons . I am hoping for additional examples.",,"['complex-analysis', 'reference-request']"
22,Intuition behind Liouville's theorem,Intuition behind Liouville's theorem,,"This post , currently closed, asks  for the intuition behind Liouville's theorem , which states that every bounded entire function is constant; I find the answers unsatisfactory and hand-wavy. I am looking for a more focused, precise description of what is going on. Is there a geometrical understanding of what is going on? I try to visualize a non-constant analytic function, to understand why unboundedness is necessary along some direction, but it isn't working for me.","This post , currently closed, asks  for the intuition behind Liouville's theorem , which states that every bounded entire function is constant; I find the answers unsatisfactory and hand-wavy. I am looking for a more focused, precise description of what is going on. Is there a geometrical understanding of what is going on? I try to visualize a non-constant analytic function, to understand why unboundedness is necessary along some direction, but it isn't working for me.",,"['complex-analysis', 'intuition']"
23,Complex analysis prerequisites for Silverman's The Arithmetic of Elliptic Curves,Complex analysis prerequisites for Silverman's The Arithmetic of Elliptic Curves,,"I would like to take a course on elliptic curves using Silverman's The Arithmetic of Elliptic Curves next year. I would be taking complex analysis concurrently, but it was listed as a formal prerequisite, so I was planning to learn some complex analysis beforehand. What topics from complex analysis (esp. chapters from Stein's book) would I need to know to do elliptic curves over $\mathbb{C}$ ?","I would like to take a course on elliptic curves using Silverman's The Arithmetic of Elliptic Curves next year. I would be taking complex analysis concurrently, but it was listed as a formal prerequisite, so I was planning to learn some complex analysis beforehand. What topics from complex analysis (esp. chapters from Stein's book) would I need to know to do elliptic curves over ?",\mathbb{C},"['complex-analysis', 'elliptic-curves']"
24,Branch points of the Lambert W function,Branch points of the Lambert W function,,"Let $W_{k}(z)$ be the k th branch of the Lambert W function . My question pertains to the branch point that the principal branch $W_{0}(z)$ shares with $W_{-1}(z)$ and $W_{1}(z)$ at $z = - \frac{1}{e}$. By the inverse function theorem, $z=f(w)=we^{w}$ is not invertible in the neighborhood of a point where $f'(w) = e^{w}(1+w)=0$. So $f(w)$ is not invertible in the neighborhood of $w=-1$. The principal branch of the Lambert W function assumes the value $-1$ at the point $z= -\frac{1}{e}$.  And by choice of closure, $W_{-1}(-\frac{1}{e})=-1$. The branch $W_{1}(z)$ does not include any portion of the real axis. So why then does $W_{1}(z)$ have a branch point at $z= -\frac{1}{e}$ when $W_{1}(-\frac{1}{e}) \ne -1$? EDIT : Sources that state $W_{1}(z)$ has a branch point at $z = - \frac{1}{e}$ include Wolfram Alpha , Maple , and this paper (page 17). What also bothers me is that the singularity in question is a square-root singularity. (Notice that expanding at $w=-1$, we get $z = -\frac{1}{e} +\mathcal{O} \left((w+1)^{2}\right)$.) Three branches sharing a square-root singularity seems a bit strange.","Let $W_{k}(z)$ be the k th branch of the Lambert W function . My question pertains to the branch point that the principal branch $W_{0}(z)$ shares with $W_{-1}(z)$ and $W_{1}(z)$ at $z = - \frac{1}{e}$. By the inverse function theorem, $z=f(w)=we^{w}$ is not invertible in the neighborhood of a point where $f'(w) = e^{w}(1+w)=0$. So $f(w)$ is not invertible in the neighborhood of $w=-1$. The principal branch of the Lambert W function assumes the value $-1$ at the point $z= -\frac{1}{e}$.  And by choice of closure, $W_{-1}(-\frac{1}{e})=-1$. The branch $W_{1}(z)$ does not include any portion of the real axis. So why then does $W_{1}(z)$ have a branch point at $z= -\frac{1}{e}$ when $W_{1}(-\frac{1}{e}) \ne -1$? EDIT : Sources that state $W_{1}(z)$ has a branch point at $z = - \frac{1}{e}$ include Wolfram Alpha , Maple , and this paper (page 17). What also bothers me is that the singularity in question is a square-root singularity. (Notice that expanding at $w=-1$, we get $z = -\frac{1}{e} +\mathcal{O} \left((w+1)^{2}\right)$.) Three branches sharing a square-root singularity seems a bit strange.",,"['complex-analysis', 'lambert-w']"
25,What did Johann Bernoulli wrong in his proof of $\ln z=\ln (-z)$?,What did Johann Bernoulli wrong in his proof of ?,\ln z=\ln (-z),"Some people say, Johann Bernoulli has proven $\ln z=\ln (-z)$ in the following way $$\ln ((-z)^2 )=\ln(z^2)\;\;\;\Rightarrow\;\;\;2\ln(-z)=2\ln z\;\;\;\Rightarrow\;\;\;\ln (-z)=\ln z$$ While the statement is not true, I'm unable to figure out what exactly went wrong: Since $(-z)^2=z^2$ for all $z\in\mathbb{C}$, it holds $\ln ((-z)^2 )=\ln(z^2)$, too. By definition of $a^b=e^{b\ln a}$ for all $a\in\mathbb{C}^{-},b\in\mathbb{C}$ it follows $\ln (e^{2\ln z})=\ln (e^{2\ln (-z)})$ for all $z\in\mathbb{C}\setminus\mathbb{R}$ Further, for $z=re^{i\varphi}$ we've got $$\ln (e^{2\ln z})=\ln (r^2)+i\pi +i\text{arg}_0(e^{i(2\varphi -\pi)})=2\ln r+2i\varphi$$ and $$\ln z=\ln r+i\varphi$$ So, it seems like $2 \ln z=\ln (z^2)$ holds, too (at least for all $z\in\mathbb{C}\setminus\mathbb{R}$). So, what is wrong here? PS: Let's define $$\mathbb{C}^{-}:=\left\{z\in\mathbb{C} : \text{Re }z>0\vee \text{Im}\ne 0\right\}$$","Some people say, Johann Bernoulli has proven $\ln z=\ln (-z)$ in the following way $$\ln ((-z)^2 )=\ln(z^2)\;\;\;\Rightarrow\;\;\;2\ln(-z)=2\ln z\;\;\;\Rightarrow\;\;\;\ln (-z)=\ln z$$ While the statement is not true, I'm unable to figure out what exactly went wrong: Since $(-z)^2=z^2$ for all $z\in\mathbb{C}$, it holds $\ln ((-z)^2 )=\ln(z^2)$, too. By definition of $a^b=e^{b\ln a}$ for all $a\in\mathbb{C}^{-},b\in\mathbb{C}$ it follows $\ln (e^{2\ln z})=\ln (e^{2\ln (-z)})$ for all $z\in\mathbb{C}\setminus\mathbb{R}$ Further, for $z=re^{i\varphi}$ we've got $$\ln (e^{2\ln z})=\ln (r^2)+i\pi +i\text{arg}_0(e^{i(2\varphi -\pi)})=2\ln r+2i\varphi$$ and $$\ln z=\ln r+i\varphi$$ So, it seems like $2 \ln z=\ln (z^2)$ holds, too (at least for all $z\in\mathbb{C}\setminus\mathbb{R}$). So, what is wrong here? PS: Let's define $$\mathbb{C}^{-}:=\left\{z\in\mathbb{C} : \text{Re }z>0\vee \text{Im}\ne 0\right\}$$",,"['complex-analysis', 'logarithms', 'fake-proofs']"
26,Prove that this holomorphic function is constant,Prove that this holomorphic function is constant,,"Suppose $f$ is a non-vanishing continuous function on $\bar{\mathbb{D}}$ that is holomorphic in $\mathbb{D}$. Prove that if $$|f(z)|=1~~~\text{whenever}~~~|z|=1$$ then $f$ is constant. I have proved this by showing that the function $$F(z)=\left\{\begin{array}{cc}f(z)&\text{when}~~|z|\leq1\\ 1/\bar{f}(\bar{z})&\text{otherwise}\end{array}\right.$$ is bounded and entire. Is there any other more elegant way to do this problem, because my method is turning out to be too gruesome for this beautiful problem. Thanks in advance!","Suppose $f$ is a non-vanishing continuous function on $\bar{\mathbb{D}}$ that is holomorphic in $\mathbb{D}$. Prove that if $$|f(z)|=1~~~\text{whenever}~~~|z|=1$$ then $f$ is constant. I have proved this by showing that the function $$F(z)=\left\{\begin{array}{cc}f(z)&\text{when}~~|z|\leq1\\ 1/\bar{f}(\bar{z})&\text{otherwise}\end{array}\right.$$ is bounded and entire. Is there any other more elegant way to do this problem, because my method is turning out to be too gruesome for this beautiful problem. Thanks in advance!",,['complex-analysis']
27,Maximize absolute value of complex logarithm,Maximize absolute value of complex logarithm,,"I'm trying to solve exercise 9 in chapter 14 of Real & Complex Analysis of Walter Rudin: Suppose $g \in H(U), |\Re(g)|<1$ in $U$ , and $g(0)=0$ . Prove that $$|g(re^{it})|\le\frac2\pi\log\frac{1+r}{1-r}$$ $U$ is the unit disc. My thoughts: Call $\Omega = \{x+iy:-1<x<1\}$ . I constructed a one-to-one conformal mapping from $\Omega$ to $ U$ : $$f(z) = -i\frac{\exp(\frac\pi2iz)-1}{\exp(\frac\pi2iz)+1}$$ I applied the Schwarz lemma to $f\circ g$ to get: $$\left| \frac{\exp(\frac\pi2ig(re^{it}))-1}{\exp(\frac\pi2ig(re^{it}))+1} \right| \le r$$ But no matter how I manipulate it, I cannot get $|g(re^{it})|$ out of it. Another approach: Use the inverse of $f$ : $$f^{-1}(z) = \frac2{\pi i}\log\frac{1+iz}{1-iz}$$ By using this question and the maximum modulus principle I get: $$|g(re^{it})| \le \max_{t\in[0,2\pi]} |f^{-1}(re^{it})|$$ The right side reaches its maximum at $re^{3\pi i/2}$ per wolfram alpha, but I cannot do it via algebra or calculus (equations and derivatives too complicated). I feel there is an easier way and I'm missing something. What is it?","I'm trying to solve exercise 9 in chapter 14 of Real & Complex Analysis of Walter Rudin: Suppose in , and . Prove that is the unit disc. My thoughts: Call . I constructed a one-to-one conformal mapping from to : I applied the Schwarz lemma to to get: But no matter how I manipulate it, I cannot get out of it. Another approach: Use the inverse of : By using this question and the maximum modulus principle I get: The right side reaches its maximum at per wolfram alpha, but I cannot do it via algebra or calculus (equations and derivatives too complicated). I feel there is an easier way and I'm missing something. What is it?","g \in H(U), |\Re(g)|<1 U g(0)=0 |g(re^{it})|\le\frac2\pi\log\frac{1+r}{1-r} U \Omega = \{x+iy:-1<x<1\} \Omega  U f(z) = -i\frac{\exp(\frac\pi2iz)-1}{\exp(\frac\pi2iz)+1} f\circ g \left| \frac{\exp(\frac\pi2ig(re^{it}))-1}{\exp(\frac\pi2ig(re^{it}))+1} \right| \le r |g(re^{it})| f f^{-1}(z) = \frac2{\pi i}\log\frac{1+iz}{1-iz} |g(re^{it})| \le \max_{t\in[0,2\pi]} |f^{-1}(re^{it})| re^{3\pi i/2}","['complex-analysis', 'conformal-geometry']"
28,Uniqueness theorem for harmonic function,Uniqueness theorem for harmonic function,,"So far in complex analysis books I have studied about Uniqueness theorem: If $f$ is analytic in a domain $D$ and if its set of zeroes has a limit point in $D$ then $f\equiv 0$ on $D$, I want to know is this result holds for harmonic functions?","So far in complex analysis books I have studied about Uniqueness theorem: If $f$ is analytic in a domain $D$ and if its set of zeroes has a limit point in $D$ then $f\equiv 0$ on $D$, I want to know is this result holds for harmonic functions?",,['complex-analysis']
29,Calculating $\prod (\omega^j - \omega^k)$ where $\omega^n=1$.,Calculating  where .,\prod (\omega^j - \omega^k) \omega^n=1,"Let $1, \omega, \dots, \omega^{n-1}$ be the roots of the equation $z^n-1=0$, so that the roots form a regular $n$-gon in the complex plane. I would like to calculate $$ \prod_{j \ne k} (\omega^j - \omega^k)$$ where the product runs over all $j \ne k$ with $0 \le j,k < n$. My attempt so far Noting that if $k-j = d$ then $\omega^j - \omega^k = \omega^j(1-\omega^d)$, I can re-write the product as $$ \prod_{d=1}^{\lfloor n/2 \rfloor} \omega^{n(n-1)/2}(1-\omega^d)^n$$ I thought this would be useful but it hasn't led me anywhere. Alternatively I could exploit the symmetry $\overline{1-\omega^d} = 1-\omega^{n-d}$ somehow, so that the terms in the product are of the form $|1-\omega^d|^2$. I tried this and ended up with a product which looked like $$\prod_{j=0}^{n-1} |1 - \omega^j|^n $$ (with awkward multiplicative powers of $-1$ left out). This appears to be useful, but calculating it explicitly is proving harder than I'd have thought. The answer I'm expecting to find is something like $n^n$. My motivation for this comes from Galois theory. I'm trying to calculate the discriminant of the polynomial $X^n+pX+q$. I know that it must be of the form $ap^n+bq^{n-1}$ for some $a,b \in \mathbb{Z}$, and putting $p=0,q=-1$, the polynomial becomes $X^n-1$. This has roots $1, \omega, \dots, \omega^{n-1}$, so that $(-1)^{n-1}b$ is (a multiple of) the product you see above. An expression for $a$ can be found similarly by setting $p=-1,q=0$.","Let $1, \omega, \dots, \omega^{n-1}$ be the roots of the equation $z^n-1=0$, so that the roots form a regular $n$-gon in the complex plane. I would like to calculate $$ \prod_{j \ne k} (\omega^j - \omega^k)$$ where the product runs over all $j \ne k$ with $0 \le j,k < n$. My attempt so far Noting that if $k-j = d$ then $\omega^j - \omega^k = \omega^j(1-\omega^d)$, I can re-write the product as $$ \prod_{d=1}^{\lfloor n/2 \rfloor} \omega^{n(n-1)/2}(1-\omega^d)^n$$ I thought this would be useful but it hasn't led me anywhere. Alternatively I could exploit the symmetry $\overline{1-\omega^d} = 1-\omega^{n-d}$ somehow, so that the terms in the product are of the form $|1-\omega^d|^2$. I tried this and ended up with a product which looked like $$\prod_{j=0}^{n-1} |1 - \omega^j|^n $$ (with awkward multiplicative powers of $-1$ left out). This appears to be useful, but calculating it explicitly is proving harder than I'd have thought. The answer I'm expecting to find is something like $n^n$. My motivation for this comes from Galois theory. I'm trying to calculate the discriminant of the polynomial $X^n+pX+q$. I know that it must be of the form $ap^n+bq^{n-1}$ for some $a,b \in \mathbb{Z}$, and putting $p=0,q=-1$, the polynomial becomes $X^n-1$. This has roots $1, \omega, \dots, \omega^{n-1}$, so that $(-1)^{n-1}b$ is (a multiple of) the product you see above. An expression for $a$ can be found similarly by setting $p=-1,q=0$.",,"['complex-analysis', 'polynomials', 'galois-theory']"
30,Show that $f=$ identity,Show that  identity,f=,Let $D$ be the closed unit disk in $\mathbb{C}$ and let $f:D\to D$ be a function such that: $f$ is equal to the identity function $\mathrm{Id}$ specifically on the unit circle ($\partial D$) $f$ is continuous on $D$ $f\circ f=\mathrm{Id}$ on $D$ How do we show that $f=\mathrm{Id}$ on all of $D$?,Let $D$ be the closed unit disk in $\mathbb{C}$ and let $f:D\to D$ be a function such that: $f$ is equal to the identity function $\mathrm{Id}$ specifically on the unit circle ($\partial D$) $f$ is continuous on $D$ $f\circ f=\mathrm{Id}$ on $D$ How do we show that $f=\mathrm{Id}$ on all of $D$?,,['complex-analysis']
31,Presheaf which is not a sheaf -- holomorphic functions which admit a holomorphic square root,Presheaf which is not a sheaf -- holomorphic functions which admit a holomorphic square root,,"I'm thinking about a problem in Ravi Vakil's algebraic geometry notes http://math.stanford.edu/~vakil/216blog/ (Exercise 3.2B) and I'm having trouble with the second part of the exercise as my understanding of complex analysis is quite rudimentary. If to every open set $U\subset \mathbb{C}$ we associate the ring of holomorphic functions which admit a holomorphic square root, this defines a presheaf on $\mathbb{C}$ (I can see this). Apparently however this is not a sheaf -- supposedly it fails to satisfy the gluing property. To prove this, we need to take an open cover $\{U_i\}$ of some open $U\subseteq \mathbb{C}$, a holomorphic function $f_i:U_i\to \mathbb{C}$ for each $i$ which has a holomorphic square root (i.e. there exists a holomorphic function $g_i$ for each $i$ such that $f_i(z)=g_i(z)^2$ for all $z\in U_i$), which all agree nicely on the intersections of the various open sets, but such that it is impossible to find a holomorphic function $f:U\to \mathbb{C}$ with a holomorphic function which restricts to $f_i$ on each $U_i$. Any help would be great -- my problem is in showing that such a function cannot exist.","I'm thinking about a problem in Ravi Vakil's algebraic geometry notes http://math.stanford.edu/~vakil/216blog/ (Exercise 3.2B) and I'm having trouble with the second part of the exercise as my understanding of complex analysis is quite rudimentary. If to every open set $U\subset \mathbb{C}$ we associate the ring of holomorphic functions which admit a holomorphic square root, this defines a presheaf on $\mathbb{C}$ (I can see this). Apparently however this is not a sheaf -- supposedly it fails to satisfy the gluing property. To prove this, we need to take an open cover $\{U_i\}$ of some open $U\subseteq \mathbb{C}$, a holomorphic function $f_i:U_i\to \mathbb{C}$ for each $i$ which has a holomorphic square root (i.e. there exists a holomorphic function $g_i$ for each $i$ such that $f_i(z)=g_i(z)^2$ for all $z\in U_i$), which all agree nicely on the intersections of the various open sets, but such that it is impossible to find a holomorphic function $f:U\to \mathbb{C}$ with a holomorphic function which restricts to $f_i$ on each $U_i$. Any help would be great -- my problem is in showing that such a function cannot exist.",,"['complex-analysis', 'algebraic-geometry', 'sheaf-theory']"
32,On the integral $\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}}$,On the integral,\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}},"In the book Asymptotics and Special Functions by Frank Olver, an integral formula of Legendre reads $$\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}}=\frac{1}{2(e^\lambda-1)}-\frac{1}{2\lambda}+\frac{1}{4}\text{ for }\lambda>0$$ Which is then used to prove an already-well-known integral (by repeatedly differentiating with respect to $\lambda$ and setting $\lambda=0$ in the formula above): $$\int_0^\infty{\frac{x^{2s-1}\mathrm{d}x}{e^{2\pi x}-1}}=(-1)^{s-1}\frac{B_{2s}}{4s}\text{ for }s>1$$ However, the author introduced, that the first formula can be obtained by straightforwardly integrating the function $\frac{e^{-i\lambda{z}}}{e^{2\pi{z}}-1}$ , in which $\lambda>0$ , around a rectangle with vertices at $0,K,K+i,i$ , and indentations at $0$ and $i$ . Then let $K\to\infty$ and the indentations shrink to zero. I literally don't see how this works, if simply applied residue theorem, and how are the integrals combined. Could someone please show me more details about the process producing the first formula through such integration? Very appreciative. Ps. I'm not a native English speaker, so I got confused with what he intrinsically meant by the term ""indentations"", the contour wasn't drawn so there's not an illustration ;) EDIT. HUUUGE gratitude to Mark Viola, I finally figured out the method. The core is to only consider the imaginary part of the integral, which won't diverge. (Added) Here's a modified version of my first approach following Mark's answer: (Equivalent) Choose $0<\delta<\frac{1}{2}$ $$I=\int_\delta^K{\frac{e^{-i\lambda{x}}\mathrm{d}x}{e^{2\pi x}-1}}+\int_K^\delta{\frac{e^{-i\lambda(x+i)}\mathrm{d}x}{e^{2\pi(x+i)}-1}}+\int_K^{K+i}{\frac{e^{-i\lambda{x}}\mathrm{d}x}{e^{2\pi{x}}-1}}+e^\lambda\int_0^{\frac{3}{2}\pi}{\frac{e^{-i\lambda\delta{e^{i\theta}}}i\delta{e^{i\theta}}\mathrm{d}\theta}{e^{2\pi\delta{e^{i\theta}}}-1}}+\int_{\frac{\pi}{2}}^{2\pi}{\frac{e^{-i\lambda\delta{e^{i\theta}}}i\delta{e^{i\theta}}\mathrm{d}\theta}{e^{2\pi\delta{e^{i\theta}}}-1}}+\int_{\delta{i}}^{i-\delta{i}}{\frac{e^{-i\lambda x}\mathrm{d}x}{e^{2\pi x}-1}}=I_1+I_2+I_3+I_4+I_5+I_6$$ $I=i(e^\lambda+1)$ by residue theorem. Taking the limit, $$\Im(I_1+I_2)=\int_0^\infty{\Im(\frac{e^{-i\lambda{x}}}{e^{2\pi x}-1})\mathrm{d}x}(1-e^\lambda)=(e^\lambda-1)\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}}$$ $$\left|I_3\right|\le\max_{0\le{x}\le1}{\left|\frac{e^{-i\lambda(ix+K)}}{e^{2\pi(ix+K)}-1}\right|}\to 0$$ $$\Im(I_4)=e^{\lambda}\int_0^{\frac{3}{2}\pi}{\Im(\frac{ie^\lambda}{2\pi}+O(\delta))\mathrm{d}\theta}=\frac{3e^\lambda}{4}$$ $$\Im(I_5)=\int_{\frac{\pi}{2}}^{2\pi}{\Im(\frac{ie^\lambda}{2\pi}+O(\delta))\mathrm{d}\theta}=\frac{3}{4}$$ $$\Im(I_6)=-\int_\delta^{1-\delta}{\Im(i\frac{e^{\lambda x}}{e^{2\pi ix}-1})\mathrm{d}x}=-\int_\delta^{1-\delta}{-\frac{e^{\lambda x}}{2}\mathrm{d}x}=_{\delta\to0}\frac{e^\lambda-1}{2\lambda}$$ Combine the results and we get the result.","In the book Asymptotics and Special Functions by Frank Olver, an integral formula of Legendre reads Which is then used to prove an already-well-known integral (by repeatedly differentiating with respect to and setting in the formula above): However, the author introduced, that the first formula can be obtained by straightforwardly integrating the function , in which , around a rectangle with vertices at , and indentations at and . Then let and the indentations shrink to zero. I literally don't see how this works, if simply applied residue theorem, and how are the integrals combined. Could someone please show me more details about the process producing the first formula through such integration? Very appreciative. Ps. I'm not a native English speaker, so I got confused with what he intrinsically meant by the term ""indentations"", the contour wasn't drawn so there's not an illustration ;) EDIT. HUUUGE gratitude to Mark Viola, I finally figured out the method. The core is to only consider the imaginary part of the integral, which won't diverge. (Added) Here's a modified version of my first approach following Mark's answer: (Equivalent) Choose by residue theorem. Taking the limit, Combine the results and we get the result.","\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}}=\frac{1}{2(e^\lambda-1)}-\frac{1}{2\lambda}+\frac{1}{4}\text{ for }\lambda>0 \lambda \lambda=0 \int_0^\infty{\frac{x^{2s-1}\mathrm{d}x}{e^{2\pi x}-1}}=(-1)^{s-1}\frac{B_{2s}}{4s}\text{ for }s>1 \frac{e^{-i\lambda{z}}}{e^{2\pi{z}}-1} \lambda>0 0,K,K+i,i 0 i K\to\infty 0<\delta<\frac{1}{2} I=\int_\delta^K{\frac{e^{-i\lambda{x}}\mathrm{d}x}{e^{2\pi x}-1}}+\int_K^\delta{\frac{e^{-i\lambda(x+i)}\mathrm{d}x}{e^{2\pi(x+i)}-1}}+\int_K^{K+i}{\frac{e^{-i\lambda{x}}\mathrm{d}x}{e^{2\pi{x}}-1}}+e^\lambda\int_0^{\frac{3}{2}\pi}{\frac{e^{-i\lambda\delta{e^{i\theta}}}i\delta{e^{i\theta}}\mathrm{d}\theta}{e^{2\pi\delta{e^{i\theta}}}-1}}+\int_{\frac{\pi}{2}}^{2\pi}{\frac{e^{-i\lambda\delta{e^{i\theta}}}i\delta{e^{i\theta}}\mathrm{d}\theta}{e^{2\pi\delta{e^{i\theta}}}-1}}+\int_{\delta{i}}^{i-\delta{i}}{\frac{e^{-i\lambda x}\mathrm{d}x}{e^{2\pi x}-1}}=I_1+I_2+I_3+I_4+I_5+I_6 I=i(e^\lambda+1) \Im(I_1+I_2)=\int_0^\infty{\Im(\frac{e^{-i\lambda{x}}}{e^{2\pi x}-1})\mathrm{d}x}(1-e^\lambda)=(e^\lambda-1)\int_0^\infty{\frac{\sin(\lambda x)\mathrm{d}x}{e^{2\pi x}-1}} \left|I_3\right|\le\max_{0\le{x}\le1}{\left|\frac{e^{-i\lambda(ix+K)}}{e^{2\pi(ix+K)}-1}\right|}\to 0 \Im(I_4)=e^{\lambda}\int_0^{\frac{3}{2}\pi}{\Im(\frac{ie^\lambda}{2\pi}+O(\delta))\mathrm{d}\theta}=\frac{3e^\lambda}{4} \Im(I_5)=\int_{\frac{\pi}{2}}^{2\pi}{\Im(\frac{ie^\lambda}{2\pi}+O(\delta))\mathrm{d}\theta}=\frac{3}{4} \Im(I_6)=-\int_\delta^{1-\delta}{\Im(i\frac{e^{\lambda x}}{e^{2\pi ix}-1})\mathrm{d}x}=-\int_\delta^{1-\delta}{-\frac{e^{\lambda x}}{2}\mathrm{d}x}=_{\delta\to0}\frac{e^\lambda-1}{2\lambda}","['complex-analysis', 'contour-integration']"
33,"Cauchy's Theorem, Stokes' Theorem, de Rham Cohomology","Cauchy's Theorem, Stokes' Theorem, de Rham Cohomology",,"I've been struggling these last couple of days to see the connection, if at all there is one, between the following facts: For holomorphic functions $f$, $\mathrm{d}(f(z)\mathrm{d}z) = 0$. In a simply connected domain, a holomorphic function has a primitive, i.e. there exists a function $g$ defined over this domain such that $g'=f$. The de Rham Cohomology ""measures the failure of closed forms to be exact"". Trying to convince myself that Cauchy's theorem is somehow geometrically intuitive led me to the one-line proof where point 1 above is combined with Stoke's theorem, which in turn has led me to wonder if there was something going on at the level of differential forms over $\mathbb{C}$. I apologise if the question is unclear; as I said, I have the feeling like there's a revelation about holomorphic functions dancing just out of my reach.","I've been struggling these last couple of days to see the connection, if at all there is one, between the following facts: For holomorphic functions $f$, $\mathrm{d}(f(z)\mathrm{d}z) = 0$. In a simply connected domain, a holomorphic function has a primitive, i.e. there exists a function $g$ defined over this domain such that $g'=f$. The de Rham Cohomology ""measures the failure of closed forms to be exact"". Trying to convince myself that Cauchy's theorem is somehow geometrically intuitive led me to the one-line proof where point 1 above is combined with Stoke's theorem, which in turn has led me to wonder if there was something going on at the level of differential forms over $\mathbb{C}$. I apologise if the question is unclear; as I said, I have the feeling like there's a revelation about holomorphic functions dancing just out of my reach.",,"['complex-analysis', 'de-rham-cohomology']"
34,Prove that a square-integrable entire function is identically zero,Prove that a square-integrable entire function is identically zero,,"Suppose $f$ is entire and    $$\iint_\mathbb{C}|f(z)|^2dxdy < \infty$$Prove that $f\equiv 0.$ So far I have: Suppose $f$ is bounded. Then $f$ is constant by virtue of Liouville and so the conclusion is obvious.  Thus, assume $f$ non-bounded.  Then  $$\Big|\iint_\mathbb{C}f^2(z)dA\Big| \leq \iint_\mathbb{C}|f(z)|^2dxdy < \infty$$ We can parameterize \begin{align*} \iint_\mathbb{C}f^2(z)dA &= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;d\theta\;rdr \\ &= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;ire^{i\theta}[-i\frac{1}{r}e^{-i\theta}]d\theta\;rdr \\ &= \int_0^{\infty}\oint_{C_R}f^2(z)\;[-i\frac{1}{z}]dz\;rdr \\ &= \int_0^{\infty}2\pi r dr\frac{1}{2\pi i}\oint_{C_R}\frac{f^2(z)}{z}dz \\ \\ &= 2\pi f^2(0)\int_0^\infty rdr  \end{align*} Whence f(0) = 0.  And I have no idea where to go from there. The ""entire"" bit seems to suggest Liouville but I have already dealt with the bounded case.  Please advise ...","Suppose $f$ is entire and    $$\iint_\mathbb{C}|f(z)|^2dxdy < \infty$$Prove that $f\equiv 0.$ So far I have: Suppose $f$ is bounded. Then $f$ is constant by virtue of Liouville and so the conclusion is obvious.  Thus, assume $f$ non-bounded.  Then  $$\Big|\iint_\mathbb{C}f^2(z)dA\Big| \leq \iint_\mathbb{C}|f(z)|^2dxdy < \infty$$ We can parameterize \begin{align*} \iint_\mathbb{C}f^2(z)dA &= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;d\theta\;rdr \\ &= \int_0^{\infty}\int_0^{2\pi}f^2(re^{i\theta})\;ire^{i\theta}[-i\frac{1}{r}e^{-i\theta}]d\theta\;rdr \\ &= \int_0^{\infty}\oint_{C_R}f^2(z)\;[-i\frac{1}{z}]dz\;rdr \\ &= \int_0^{\infty}2\pi r dr\frac{1}{2\pi i}\oint_{C_R}\frac{f^2(z)}{z}dz \\ \\ &= 2\pi f^2(0)\int_0^\infty rdr  \end{align*} Whence f(0) = 0.  And I have no idea where to go from there. The ""entire"" bit seems to suggest Liouville but I have already dealt with the bounded case.  Please advise ...",,"['complex-analysis', 'contour-integration', 'complex-integration', 'entire-functions']"
35,"Going from $f = u(x,y) +iv(x,y)$ to $f(z) = f(x+iy)$",Going from  to,"f = u(x,y) +iv(x,y) f(z) = f(x+iy)","Quick question: Quite often, when doing stuff in Complex Analysis, I'm asked to put something of the form $f = u+iv$ into the form $f(z)$. I HATE this step, because it always amounts to me just looking at it, and trying to sorta guess half way, and work backwards from the guess. It's time-consuming, tedious and clumsy. This will not do. I'm now looking for appropriate theory (in the ideal case, an algorithm), or some other simple approach that will remove much of the guess work, remove stuff like the 'magically noticing' obscure trig identities, and just make the whole thing a bit more palatable. What are some good tactics? Thanks in advance.","Quick question: Quite often, when doing stuff in Complex Analysis, I'm asked to put something of the form $f = u+iv$ into the form $f(z)$. I HATE this step, because it always amounts to me just looking at it, and trying to sorta guess half way, and work backwards from the guess. It's time-consuming, tedious and clumsy. This will not do. I'm now looking for appropriate theory (in the ideal case, an algorithm), or some other simple approach that will remove much of the guess work, remove stuff like the 'magically noticing' obscure trig identities, and just make the whole thing a bit more palatable. What are some good tactics? Thanks in advance.",,['complex-analysis']
36,Can I conjugate a complex number : $\sqrt{a+ib}$?,Can I conjugate a complex number : ?,\sqrt{a+ib},"Can I conjugate a complex number: $\sqrt{a+ib}$  ? Actually my maths school teacher says and argues with each and every student that we can't conjugate $\sqrt{a+ib}$  to $\sqrt{a-ib}$  because according to him $\sqrt{a+ib}$ isn't a complex number. Please give some proofs, or some good explanations along with replies. PS : Sorry for double post, my previous question wasn't understood properly by the reply-ers because of absence of $\sqrt{}$ symbol :(","Can I conjugate a complex number: $\sqrt{a+ib}$  ? Actually my maths school teacher says and argues with each and every student that we can't conjugate $\sqrt{a+ib}$  to $\sqrt{a-ib}$  because according to him $\sqrt{a+ib}$ isn't a complex number. Please give some proofs, or some good explanations along with replies. PS : Sorry for double post, my previous question wasn't understood properly by the reply-ers because of absence of $\sqrt{}$ symbol :(",,"['complex-analysis', 'complex-numbers']"
37,Convergence of $\{nz^n\}_1^{\infty}.$,Convergence of,\{nz^n\}_1^{\infty}.,"Discuss completely the convergence and uniform convergence of the sequence $\{nz^n\}_1^{\infty}.$ If $|z|\geq 1$, then $|nz^n|=n|z|^n\geq n$ diverges, so the sequence $nz^n$ also diverges. If $|z|<1$, it should converge to $0$. So for any $\varepsilon$, we must find $N$ such that $|nz^n|=n|z|^n<\varepsilon$, or in other words $|z|^n<\dfrac{\varepsilon}{n}$ for all $n\geq N$. It should be true since the left hand side converges rapidly to $0$, but how to prove it rigorously? Then finally, the sequence doesn't converge uniformly in the open disk $|z|<1$, because if it did, for any $\varepsilon$ we must have $N$ such that $|z|^n<\dfrac{\varepsilon}{n}$ for all $|z|<1$ and all $n\geq N$. But we can choose $|z|$ large enough (close enough to $1$) to break this inequality. So my question is: how to prove that for any $a\in(-1,1)$ and any $\epsilon>0$, there exists $N$ such that $a^n<\dfrac{\varepsilon}{n}$ for all $n\geq N$.","Discuss completely the convergence and uniform convergence of the sequence $\{nz^n\}_1^{\infty}.$ If $|z|\geq 1$, then $|nz^n|=n|z|^n\geq n$ diverges, so the sequence $nz^n$ also diverges. If $|z|<1$, it should converge to $0$. So for any $\varepsilon$, we must find $N$ such that $|nz^n|=n|z|^n<\varepsilon$, or in other words $|z|^n<\dfrac{\varepsilon}{n}$ for all $n\geq N$. It should be true since the left hand side converges rapidly to $0$, but how to prove it rigorously? Then finally, the sequence doesn't converge uniformly in the open disk $|z|<1$, because if it did, for any $\varepsilon$ we must have $N$ such that $|z|^n<\dfrac{\varepsilon}{n}$ for all $|z|<1$ and all $n\geq N$. But we can choose $|z|$ large enough (close enough to $1$) to break this inequality. So my question is: how to prove that for any $a\in(-1,1)$ and any $\epsilon>0$, there exists $N$ such that $a^n<\dfrac{\varepsilon}{n}$ for all $n\geq N$.",,['complex-analysis']
38,prove that the entire function f is a polynomial.,prove that the entire function f is a polynomial.,,"Suppose that $f$ is an entire function, and that in every power series $f(z)=\sum_{n=0}^{\infty} c_{n}(z-a)^n$ at least one coefficient is 0. Prove that $f$ is a polnomial. Hint: $n!c_{n}=f^{(n)}(a)$ Actually, this is a Rudin's book's exercise. I tried Cauchy inequality, and Liouville's theorem ( for $g(z)=\sum_{n=m}^{\infty} c_{n}(z-a)^n$ is bounded) but failed. I really want to solve that, but I don't have any idea. I need your help.","Suppose that $f$ is an entire function, and that in every power series $f(z)=\sum_{n=0}^{\infty} c_{n}(z-a)^n$ at least one coefficient is 0. Prove that $f$ is a polnomial. Hint: $n!c_{n}=f^{(n)}(a)$ Actually, this is a Rudin's book's exercise. I tried Cauchy inequality, and Liouville's theorem ( for $g(z)=\sum_{n=m}^{\infty} c_{n}(z-a)^n$ is bounded) but failed. I really want to solve that, but I don't have any idea. I need your help.",,"['complex-analysis', 'polynomials', 'power-series']"
39,Principal divisors on a compact Riemann surface,Principal divisors on a compact Riemann surface,,"Let $X$ be a compact Riemann surface, and $f$ a meromorphic function on X. There's a theorem telling us that $\deg(\mathrm{div}(f)) = 0$ . But is the inverse statement also true? I mean, is it true that: if $D$ is a divisor on $X$ with $\deg(D) = 0$ , then exists a meromorphic function $f$ on $X$ such that $D = \mathrm{div}(f)$ ? Thanks!","Let be a compact Riemann surface, and a meromorphic function on X. There's a theorem telling us that . But is the inverse statement also true? I mean, is it true that: if is a divisor on with , then exists a meromorphic function on such that ? Thanks!",X f \deg(\mathrm{div}(f)) = 0 D X \deg(D) = 0 f X D = \mathrm{div}(f),"['complex-analysis', 'riemann-surfaces']"
40,The conformal map $f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right)$,The conformal map,f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right),"I want to show that $f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right)$ is a conformal map from the set of $z$ such that $0<|z|<1$ onto $\mathbb{C} \setminus [-1,1]$. I find that $f'(z)=\frac{(z+1)(z-1)}{2z^2}$ so this means that $f$ is conformal except for $z=1$ or $z=-1$ which is ok since they're not in the domain of $f$. So $f$ is a conformal mapping. Now for $z=re^{i\theta}$, we find $w=\frac{1}{2}\left(z+\frac{1}{z}\right)=re^{i\theta}+\frac{e^{-i\theta}}{r}$ which gives $u=(r+\frac{1}{r})\frac{cos(\theta)}{2}$ and $v=(r-\frac{1}{r})\frac{sin(\theta)}{2}$. When we compute we end up with $\frac{u^2}{(r+1/r)^2} + \frac{v^2}{(r-1/r)^2}=\frac{1}{4}$ which means that circles about the origin, i.e  the ones such that $|z|<1$ are mapped to ellipses. Finally if $[-1,1]$ were in the image then this means that the unit circle has been mapped by $f$ since would take $r=1$ which implies $-1<u<1$ ($v=0$ here). Is the exercise complete or do I need to add more justification as to why $f$ maps the punctured interior of the unit disc to the whole plane? EDIT: I corrected the typo in the equation of the ellipse, it should be $\frac{1}{4}$ like in Zarrax's answer","I want to show that $f(z)=\frac{1}{2}\left(z+\frac{1}{z}\right)$ is a conformal map from the set of $z$ such that $0<|z|<1$ onto $\mathbb{C} \setminus [-1,1]$. I find that $f'(z)=\frac{(z+1)(z-1)}{2z^2}$ so this means that $f$ is conformal except for $z=1$ or $z=-1$ which is ok since they're not in the domain of $f$. So $f$ is a conformal mapping. Now for $z=re^{i\theta}$, we find $w=\frac{1}{2}\left(z+\frac{1}{z}\right)=re^{i\theta}+\frac{e^{-i\theta}}{r}$ which gives $u=(r+\frac{1}{r})\frac{cos(\theta)}{2}$ and $v=(r-\frac{1}{r})\frac{sin(\theta)}{2}$. When we compute we end up with $\frac{u^2}{(r+1/r)^2} + \frac{v^2}{(r-1/r)^2}=\frac{1}{4}$ which means that circles about the origin, i.e  the ones such that $|z|<1$ are mapped to ellipses. Finally if $[-1,1]$ were in the image then this means that the unit circle has been mapped by $f$ since would take $r=1$ which implies $-1<u<1$ ($v=0$ here). Is the exercise complete or do I need to add more justification as to why $f$ maps the punctured interior of the unit disc to the whole plane? EDIT: I corrected the typo in the equation of the ellipse, it should be $\frac{1}{4}$ like in Zarrax's answer",,['complex-analysis']
41,A power series with decreasing positive coefficients has no zeroes in the disk [duplicate],A power series with decreasing positive coefficients has no zeroes in the disk [duplicate],,"This question already has answers here : Let $(a_n)_{n \geq 0}$ be a strictly decreasing sequence of positive real numbers , and let $z \in \mathbb C$ , $|z| < 1$. (2 answers) Closed 4 years ago . Let $\sum_{n=0}^\infty a_n z^n$ be a formal complex power series, with $a_n$ strictly decreasing to 1 as $n\to \infty$ . It is easy to see that the radius of convergence is 1, so that this power series represents a function $f$ holomorphic on the disk. The question is to Show that f has no zeroes on the disk. I've been looking at this a while and feel and tried a few different things. $\cdot$ One easy observation is the similarity of this series with $\frac{1}{1-z}$ , whose coefficients do not strictly decrease but which otherwise is an example of the thing to be proven. $\cdot$ Rouché's theorem doesn't seem to have an immediate application—I've tried comparing $f$ to $\frac{1}{1-z}$ or to its partial sums by Rouché. $\cdot$ If the partial sums had no zeroes, then neither would $f$ by Hurwitz's theorem $\cdot$ If we could show the function had positive real part we'd obviously be done, which seems highly plausible—the condition gives that $f(-1) = \sum a_n \cos\pi n > 0$ , but I don't know how to extend this argument to arguments other than $\pi$ . Besides, if this technique were to work, it seems it would rely most on algebraic manipulations of power series, and I would vastly prefer a classical complex analytic approach (argument principle, Rouché's theorem, etc) Please advise!","This question already has answers here : Let $(a_n)_{n \geq 0}$ be a strictly decreasing sequence of positive real numbers , and let $z \in \mathbb C$ , $|z| < 1$. (2 answers) Closed 4 years ago . Let be a formal complex power series, with strictly decreasing to 1 as . It is easy to see that the radius of convergence is 1, so that this power series represents a function holomorphic on the disk. The question is to Show that f has no zeroes on the disk. I've been looking at this a while and feel and tried a few different things. One easy observation is the similarity of this series with , whose coefficients do not strictly decrease but which otherwise is an example of the thing to be proven. Rouché's theorem doesn't seem to have an immediate application—I've tried comparing to or to its partial sums by Rouché. If the partial sums had no zeroes, then neither would by Hurwitz's theorem If we could show the function had positive real part we'd obviously be done, which seems highly plausible—the condition gives that , but I don't know how to extend this argument to arguments other than . Besides, if this technique were to work, it seems it would rely most on algebraic manipulations of power series, and I would vastly prefer a classical complex analytic approach (argument principle, Rouché's theorem, etc) Please advise!",\sum_{n=0}^\infty a_n z^n a_n n\to \infty f \cdot \frac{1}{1-z} \cdot f \frac{1}{1-z} \cdot f \cdot f(-1) = \sum a_n \cos\pi n > 0 \pi,"['complex-analysis', 'power-series']"
42,$g\circ f$ non-constant polynomials then $f$ and $g$ are polynomials?,non-constant polynomials then  and  are polynomials?,g\circ f f g,"Let $f$, $g$ be non-constant entire functions. If the composition  $g\circ f$ is a non-constant polynomial, can we conclude $f$ and $g$ are polynomials?","Let $f$, $g$ be non-constant entire functions. If the composition  $g\circ f$ is a non-constant polynomial, can we conclude $f$ and $g$ are polynomials?",,['complex-analysis']
43,Are bounded analytic functions on the unit disk continuous on the unit circle?,Are bounded analytic functions on the unit disk continuous on the unit circle?,,"Let $f(z)$ be holomorphic on the open disk $\mathbb{D} = \{z \in \mathbb{C}: |z| < 1\}$. Moreover, let $f$ be bounded on the boundary of $\mathbb{D}$, i.e. $$ \sup_{\varphi \in [0,2\pi]} |f(e^{i\varphi})| < \infty $$ (This class of functions is sometimes called $H^\infty$). My question regards the boundary function $\tilde{f}(\varphi) := \lim_{r \rightarrow 1} f(r e^{i\varphi})$. Is it continuous?","Let $f(z)$ be holomorphic on the open disk $\mathbb{D} = \{z \in \mathbb{C}: |z| < 1\}$. Moreover, let $f$ be bounded on the boundary of $\mathbb{D}$, i.e. $$ \sup_{\varphi \in [0,2\pi]} |f(e^{i\varphi})| < \infty $$ (This class of functions is sometimes called $H^\infty$). My question regards the boundary function $\tilde{f}(\varphi) := \lim_{r \rightarrow 1} f(r e^{i\varphi})$. Is it continuous?",,"['complex-analysis', 'continuity', 'analyticity', 'hardy-spaces']"
44,Riemann-Roch Theorem,Riemann-Roch Theorem,,Could somebody give a simple plain English explanation as to what the Riemann-Roch theorem is about to somebody who knows only standard one-variable complex analysis. Thanks.,Could somebody give a simple plain English explanation as to what the Riemann-Roch theorem is about to somebody who knows only standard one-variable complex analysis. Thanks.,,"['complex-analysis', 'algebraic-geometry']"
45,How find the maximum value of $|bc|$,How find the maximum value of,|bc|,"Question: Given complex numbers $a,b,c$, we have that $|az^2 + bz +c| \leq 1$ holds true for any complex number $z, |z| \leq 1$. Find the maximum value of $|bc|$ It is said this is answer is $$|bc|\le \dfrac{3\sqrt{3}}{16}$$ My idea: let $z=1$,then $$|a+b+c|\le 1$$ let $z=-1$,then $$|a-b+c|\le 1$$ let $z=0$, then $$|c|\le 1$$ let $|\theta|=1$,then we have $$|a(z/\theta)^2+b(z/\theta)+c|\le 1\Longrightarrow |az^2+b\theta z+c\theta^2|\le 1$$ and only this can't solve this problem,Thank you","Question: Given complex numbers $a,b,c$, we have that $|az^2 + bz +c| \leq 1$ holds true for any complex number $z, |z| \leq 1$. Find the maximum value of $|bc|$ It is said this is answer is $$|bc|\le \dfrac{3\sqrt{3}}{16}$$ My idea: let $z=1$,then $$|a+b+c|\le 1$$ let $z=-1$,then $$|a-b+c|\le 1$$ let $z=0$, then $$|c|\le 1$$ let $|\theta|=1$,then we have $$|a(z/\theta)^2+b(z/\theta)+c|\le 1\Longrightarrow |az^2+b\theta z+c\theta^2|\le 1$$ and only this can't solve this problem,Thank you",,"['complex-analysis', 'inequality']"
46,Looking for guidance on a Fourier integral,Looking for guidance on a Fourier integral,,"Working with a Fourier transform problem, I've encountered the following integral: $$ \int_{-\infty}^{\infty}\frac{\exp\left(-a^2x^2+ibx\right)}{x^2+c^2}dx $$ where $a$, $b$, and $c$ are real coefficients.  Mathematica claims that this has no closed-form solution, but I suspect (hope?) that's not the case.  Unfortunately, my background in complex analysis is limited to some panic-studying I did to make it through a field theory course a decade ago.  I've spent the weekend dusting that off, but am still stumped... I know there's a pole at $z=ci$.  If I take (to me) the obvious extension of the integral to the complex plane by simply replacing $x$ with $z$, I can even calculate its residue as: $$ \frac{\exp\left(a^2c^2-bc\right)}{2ci} $$ My hope was to integrate over a semicircle in the positive half-plane, and use this residue to get the integral along the real axis.  However, with this extension, the integral over the semicircle of radius R doesn't seem to be zero (or possibly even converge) with R going to infinity -- or at least, Jordan's lemma doesn't give me any reason to believe so, since the $-a^2z^2$ part becomes unfriendly on the imaginary axis. I vaguely recall there being a strategy for dealing with this sort of problem.  I specifically recall the strategy not being to use $zz^*$, since explicit dependence on the complex conjugate was a no-go.  For the life of me, though, I can't recall what the strategy was . If anybody can (a) refresh my memory on this; (b) give a solution method; or (c) explain why no closed form solution exists, that would be much appreciated.  Thanks in advance for any help you can offer!","Working with a Fourier transform problem, I've encountered the following integral: $$ \int_{-\infty}^{\infty}\frac{\exp\left(-a^2x^2+ibx\right)}{x^2+c^2}dx $$ where $a$, $b$, and $c$ are real coefficients.  Mathematica claims that this has no closed-form solution, but I suspect (hope?) that's not the case.  Unfortunately, my background in complex analysis is limited to some panic-studying I did to make it through a field theory course a decade ago.  I've spent the weekend dusting that off, but am still stumped... I know there's a pole at $z=ci$.  If I take (to me) the obvious extension of the integral to the complex plane by simply replacing $x$ with $z$, I can even calculate its residue as: $$ \frac{\exp\left(a^2c^2-bc\right)}{2ci} $$ My hope was to integrate over a semicircle in the positive half-plane, and use this residue to get the integral along the real axis.  However, with this extension, the integral over the semicircle of radius R doesn't seem to be zero (or possibly even converge) with R going to infinity -- or at least, Jordan's lemma doesn't give me any reason to believe so, since the $-a^2z^2$ part becomes unfriendly on the imaginary axis. I vaguely recall there being a strategy for dealing with this sort of problem.  I specifically recall the strategy not being to use $zz^*$, since explicit dependence on the complex conjugate was a no-go.  For the life of me, though, I can't recall what the strategy was . If anybody can (a) refresh my memory on this; (b) give a solution method; or (c) explain why no closed form solution exists, that would be much appreciated.  Thanks in advance for any help you can offer!",,"['complex-analysis', 'fourier-analysis', 'contour-integration', 'residue-calculus']"
47,"Intuitive reason for why many complex integrals vanish when the path is ""blown-up""?","Intuitive reason for why many complex integrals vanish when the path is ""blown-up""?",,"It is a standard trick for evaluating difficult integrals along the real line to consider a closed-contour and ""blow-up"" the complex part till it vanishes, leaving us with the residues picked up along the way. This is usually done by bounding the magnitude of the integral from above with something that tends to $0$. My question is, is there an intuitive reason for why we should expect this? My thought was that, if we project the complex plane onto a Riemann sphere, the path which appears to enlarge is actually shrunk to the point at $\infty$. I drew a (not very pretty) picture to illustrate what I mean: In blue is a semi-circular contour in the upper-half plane, centered at the origin, and in red is the stereographic projection of this contour onto a Riemann sphere. It is clear that as the radius of the blue semi-circle $\to\infty$, the red semi-circle that corresponds to the complex portion of the contour is shrunk to the north pole of the sphere. Is this a good way of thinking about it and is this a good enough reason for the integral along that arc to vanish (as long as it does not encounter poles on the way)?","It is a standard trick for evaluating difficult integrals along the real line to consider a closed-contour and ""blow-up"" the complex part till it vanishes, leaving us with the residues picked up along the way. This is usually done by bounding the magnitude of the integral from above with something that tends to $0$. My question is, is there an intuitive reason for why we should expect this? My thought was that, if we project the complex plane onto a Riemann sphere, the path which appears to enlarge is actually shrunk to the point at $\infty$. I drew a (not very pretty) picture to illustrate what I mean: In blue is a semi-circular contour in the upper-half plane, centered at the origin, and in red is the stereographic projection of this contour onto a Riemann sphere. It is clear that as the radius of the blue semi-circle $\to\infty$, the red semi-circle that corresponds to the complex portion of the contour is shrunk to the north pole of the sphere. Is this a good way of thinking about it and is this a good enough reason for the integral along that arc to vanish (as long as it does not encounter poles on the way)?",,"['complex-analysis', 'contour-integration', 'complex-integration']"
48,"Explaining the convergence of $\int_{0}^{1} \sin \left(\frac{1}{x} \right) \, dx$ using the properties of essential singularities",Explaining the convergence of  using the properties of essential singularities,"\int_{0}^{1} \sin \left(\frac{1}{x} \right) \, dx","Because the function $\frac{1}{z}$ has a pole at $z=0$, the integral $\int_{0}^{1} \frac{dx}{x} $ doesn't converge. On the other hand, the integral $\int_{0}^{1} \sin \left(\frac{1}{x} \right) \, dx $ converges even though the function $\sin \left(\frac{1}{z} \right)$ has an essential singularity at $z=0$. Can an essential singularity be a weaker singularity than an pole? EDIT : Originally I had $\int_{0}^{1} \sin \left(\frac{1}{x^{2}} \right) \, dx$ (which converges despite the fact that $\sin \left(\frac{1}{z^{2}} \right)$ has an essential singularity at $z=0$).","Because the function $\frac{1}{z}$ has a pole at $z=0$, the integral $\int_{0}^{1} \frac{dx}{x} $ doesn't converge. On the other hand, the integral $\int_{0}^{1} \sin \left(\frac{1}{x} \right) \, dx $ converges even though the function $\sin \left(\frac{1}{z} \right)$ has an essential singularity at $z=0$. Can an essential singularity be a weaker singularity than an pole? EDIT : Originally I had $\int_{0}^{1} \sin \left(\frac{1}{x^{2}} \right) \, dx$ (which converges despite the fact that $\sin \left(\frac{1}{z^{2}} \right)$ has an essential singularity at $z=0$).",,['complex-analysis']
49,A holomorphic bijection from the open unit disc to the complex plane,A holomorphic bijection from the open unit disc to the complex plane,,"By Liouville's theorem, there is no non-constant holomorphic function from the complex plane to the unit disc. I wonder what the converse is like--surely there are holomorphic functions on the open unit disc into the complex plane, but are there any bijective ones?","By Liouville's theorem, there is no non-constant holomorphic function from the complex plane to the unit disc. I wonder what the converse is like--surely there are holomorphic functions on the open unit disc into the complex plane, but are there any bijective ones?",,['complex-analysis']
50,$f$ is entire without any zeros then there is an entire function $g$ such that $f=e^g$,is entire without any zeros then there is an entire function  such that,f g f=e^g,"$f$ is entire without any zeros then there is an entire function $g$ such that $f=e^g$ What I think is since $f$ do not have any zero for some bounded domain, I can define a branch of logarithm $(\log f)$ on that domain which will gives my desired result $f =e^{\log f}$. I don't know if I am doing it right? If this is right I don't know how do I argue $(\log f)$ is entire. Hint please.","$f$ is entire without any zeros then there is an entire function $g$ such that $f=e^g$ What I think is since $f$ do not have any zero for some bounded domain, I can define a branch of logarithm $(\log f)$ on that domain which will gives my desired result $f =e^{\log f}$. I don't know if I am doing it right? If this is right I don't know how do I argue $(\log f)$ is entire. Hint please.",,['complex-analysis']
51,On the roots of $2z-\sin(2z)$,On the roots of,2z-\sin(2z),"Recently I have been working on an approach to numerically find the roots of the equation $$ 2z-\sin(2z)=0$$ As you can see below, I was able to find all the roots in a specific, bounded domain So far so good. However, I have some observations, which makes me formulate some statements, of which I am not sure if they are correct. 1. The zeros lie on a fixed curve per quadrant. I now that if $z$ is a zero, than so will $z^*$ (the conjugate), $-z$ and $-z^*$. This limits my root-finding to one quadrant (speed up of factor 4 hooray!). But, is it true there are no zeros outside this 'curve'? 2. The zeros reach an asymptote Considering one curve, I get the feeling that, numbering the roots $z_n$ in increasing distance from the origin, $$ \lim_{n\to\infty} Re(z_n)-Re(z_{n-1})=\pi.$$ And maybe, but less convinced $$ \lim_{n\to\infty} Im(z_n)-Im(z_{n-1})=0.$$ Is there proof for either of the above statements? Did I miss any exact, closed form solution to the problem?","Recently I have been working on an approach to numerically find the roots of the equation $$ 2z-\sin(2z)=0$$ As you can see below, I was able to find all the roots in a specific, bounded domain So far so good. However, I have some observations, which makes me formulate some statements, of which I am not sure if they are correct. 1. The zeros lie on a fixed curve per quadrant. I now that if $z$ is a zero, than so will $z^*$ (the conjugate), $-z$ and $-z^*$. This limits my root-finding to one quadrant (speed up of factor 4 hooray!). But, is it true there are no zeros outside this 'curve'? 2. The zeros reach an asymptote Considering one curve, I get the feeling that, numbering the roots $z_n$ in increasing distance from the origin, $$ \lim_{n\to\infty} Re(z_n)-Re(z_{n-1})=\pi.$$ And maybe, but less convinced $$ \lim_{n\to\infty} Im(z_n)-Im(z_{n-1})=0.$$ Is there proof for either of the above statements? Did I miss any exact, closed form solution to the problem?",,"['complex-analysis', 'roots']"
52,The Argument Principle used to prove the Fundamental Theorem of Algebra,The Argument Principle used to prove the Fundamental Theorem of Algebra,,"Greene and Krantz pose the following problem in Function Theory of One Complex Variable , Ch. 5 problem 3: Give another proof of the fundamental theorem of algebra as follows:   Let $P(z)$ be a non-constant polynomial. Fix $Q\in \mathbb{C}$.   Consider    \begin{equation}  \frac{1}{2\pi i} \oint_{\partial D(Q,R)} \frac{P'(z)}{P(z)}\,dz.  \end{equation}   Argue that as $R\to +\infty$, this   expression tends to a nonzero constant. I was thinking along these lines: Since we do not know $P(z)$ factors completely, let us write $$ P(z) = \prod_j (z - \alpha_j) \, g(z),$$ where $g(z)$ is an irreducible polynomial. Now $$ \frac{P'(z)}{P(z)} = \sum_k \frac{1}{z-\alpha_k} + \frac{g'(z)}{g(z)}.$$ Each of the terms $1/(z-\alpha_k)$ adds $1$ to the integral expression. As $R \to \infty$, all the $\alpha_k$ are eventually inside $D(Q,R)$, whereas the term $g'(z)/g(z)$ approaches zero, since the denominator has a higher degree. Is the reasoning correct ? Can someone offer a simpler argument ?","Greene and Krantz pose the following problem in Function Theory of One Complex Variable , Ch. 5 problem 3: Give another proof of the fundamental theorem of algebra as follows:   Let $P(z)$ be a non-constant polynomial. Fix $Q\in \mathbb{C}$.   Consider    \begin{equation}  \frac{1}{2\pi i} \oint_{\partial D(Q,R)} \frac{P'(z)}{P(z)}\,dz.  \end{equation}   Argue that as $R\to +\infty$, this   expression tends to a nonzero constant. I was thinking along these lines: Since we do not know $P(z)$ factors completely, let us write $$ P(z) = \prod_j (z - \alpha_j) \, g(z),$$ where $g(z)$ is an irreducible polynomial. Now $$ \frac{P'(z)}{P(z)} = \sum_k \frac{1}{z-\alpha_k} + \frac{g'(z)}{g(z)}.$$ Each of the terms $1/(z-\alpha_k)$ adds $1$ to the integral expression. As $R \to \infty$, all the $\alpha_k$ are eventually inside $D(Q,R)$, whereas the term $g'(z)/g(z)$ approaches zero, since the denominator has a higher degree. Is the reasoning correct ? Can someone offer a simpler argument ?",,['complex-analysis']
53,Pointwise Cauchy-Riemann equations suffice?,Pointwise Cauchy-Riemann equations suffice?,,"Another question just now reminded me of something I realized a while ago I didn't know how to do: Say $V\subset\Bbb C$ is open, $f:V\to\Bbb C$ , $f=u+iv$ , and at every point of $V$ the partials of $u$ and $v$ exist and satisfy the Cauchy-Riemann equations. How do we show that $f$ is holomorphic? I mean it seems it ""must"" follow. But note if you think this is totally trivial it's possible you're wrong; for instance it's not clear how the hypothesis implies that $f'(z)$ exists.","Another question just now reminded me of something I realized a while ago I didn't know how to do: Say is open, , , and at every point of the partials of and exist and satisfy the Cauchy-Riemann equations. How do we show that is holomorphic? I mean it seems it ""must"" follow. But note if you think this is totally trivial it's possible you're wrong; for instance it's not clear how the hypothesis implies that exists.",V\subset\Bbb C f:V\to\Bbb C f=u+iv V u v f f'(z),"['complex-analysis', 'cauchy-riemann-equations']"
54,"Calculate the value of $\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx$",Calculate the value of,"\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx","I'm asked to evaluate the integral $\displaystyle\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx$ . I tried defining a funcion $f(z)=\frac{e^{(1/2+i)\operatorname{Log}(z)}}{z^2+1}$ , taking $\operatorname{Log}$ with a branch cut along the positive real axis: ( $\operatorname{Log}(z)=\ln(|z|)+i\arg(z))$ . Using residue theorem with the ""pacman"" contour. However when trying to bound the integral around a small circle around $0$ , I cannot conclude it converges to $0$ . My attempt was $|\int_{\gamma_\epsilon}f|\leq 2\pi\epsilon|e^{(0.5+i)(\ln|\epsilon|+i\theta))}|\frac{1}{\epsilon^2-1}\leq C\epsilon^{-0.5}.$ I'd love it if someone could either suggest a different way to bound the integral around $0$ of this function, or maybe suggest an easier complex function to work  with. Edit: The wonderful ""Related"" algorithm of this site managed to link me to this answer Looking at it , a more general statement is proved, but the proof fails when we have $\alpha=0.5+i$ (The circle around $0$ doesn`t converge to $0$ by the proof given there, as a matter of fact any $\alpha$ with $Re(\alpha)>0$ would fail.)","I'm asked to evaluate the integral . I tried defining a funcion , taking with a branch cut along the positive real axis: ( . Using residue theorem with the ""pacman"" contour. However when trying to bound the integral around a small circle around , I cannot conclude it converges to . My attempt was I'd love it if someone could either suggest a different way to bound the integral around of this function, or maybe suggest an easier complex function to work  with. Edit: The wonderful ""Related"" algorithm of this site managed to link me to this answer Looking at it , a more general statement is proved, but the proof fails when we have (The circle around doesn`t converge to by the proof given there, as a matter of fact any with would fail.)","\displaystyle\int_0^\infty \frac{\sqrt{x}\cos(\ln(x))}{x^2+1}\,dx f(z)=\frac{e^{(1/2+i)\operatorname{Log}(z)}}{z^2+1} \operatorname{Log} \operatorname{Log}(z)=\ln(|z|)+i\arg(z)) 0 0 |\int_{\gamma_\epsilon}f|\leq 2\pi\epsilon|e^{(0.5+i)(\ln|\epsilon|+i\theta))}|\frac{1}{\epsilon^2-1}\leq C\epsilon^{-0.5}. 0 \alpha=0.5+i 0 0 \alpha Re(\alpha)>0","['complex-analysis', 'contour-integration', 'residue-calculus']"
55,Laurent series for $f (z)=\frac {\sin (2 \pi z)}{z (z^2 + 1)}$,Laurent series for,f (z)=\frac {\sin (2 \pi z)}{z (z^2 + 1)},"How Can find the Laurent series for this function valid for $0 <|z-i|<2$ $$f (z)=\frac {\sin (2 \pi z)}{z (z^2 +1)}$$ Let $g (z) = \sin (\pi z)$ $$\sin (\pi z ) = \sin( 2 \pi  (z - i)) \cos (2 \pi i) + \cos (2 \pi  (z-i)) \sin (2 \pi i )$$ And Let $h (z)= \frac {1}{z^2 + 1}$ $$\frac {1}{z (z^2 + 1)}= \frac {1}{i (1 -(-(z-i))}[\frac {1/2i}{z-i} +\frac {-1/2i}{2i (1-(-\frac {z-i}{2i}))}]$$ So it's easy to find expansion for $g (z)$ and $h (z)$ and then multiply the two expansions We notice that $ f $ has simple pole at $z = i$ So, we can get the principal part easily Or using this  $$2 \pi i a_1 = \int_{|z-i|=1} f (z) dz$$ Is there a trick to find the Laurent series quickly ? This question was in my exam .I Calculated the principal part , but I didn't have enough time to calculate the exact form for the analytic part . Thank you","How Can find the Laurent series for this function valid for $0 <|z-i|<2$ $$f (z)=\frac {\sin (2 \pi z)}{z (z^2 +1)}$$ Let $g (z) = \sin (\pi z)$ $$\sin (\pi z ) = \sin( 2 \pi  (z - i)) \cos (2 \pi i) + \cos (2 \pi  (z-i)) \sin (2 \pi i )$$ And Let $h (z)= \frac {1}{z^2 + 1}$ $$\frac {1}{z (z^2 + 1)}= \frac {1}{i (1 -(-(z-i))}[\frac {1/2i}{z-i} +\frac {-1/2i}{2i (1-(-\frac {z-i}{2i}))}]$$ So it's easy to find expansion for $g (z)$ and $h (z)$ and then multiply the two expansions We notice that $ f $ has simple pole at $z = i$ So, we can get the principal part easily Or using this  $$2 \pi i a_1 = \int_{|z-i|=1} f (z) dz$$ Is there a trick to find the Laurent series quickly ? This question was in my exam .I Calculated the principal part , but I didn't have enough time to calculate the exact form for the analytic part . Thank you",,"['complex-analysis', 'laurent-series']"
56,Characteristic functions of random variables are non-negative definite,Characteristic functions of random variables are non-negative definite,,"Let $(\Omega, \mathcal{F}, P)$ be a probability space and $X:\Omega\to\mathbb{R}$ a random variable. How to prove that the characteristic function $\varphi_X(t) = E[e^{itX}] =\int_{\Omega}e^{itX(\omega)}dP(\omega)$ , is non-negative definite? I didn't know the concept of non-negative definiteness for complex functions, and the only definition I've found is the followig: The function $f:\mathbb{R}\to\mathbb{C}$ is said to be non-negative definite when: $$\sum_{1\leq i, k\leq n}f(x_i-x_k)\xi_i\bar{\xi_k}\geq 0$$ for every choice of $n\in\mathbb{N}$ , $x_1, \,...,\,x_n \in \mathbb{R}$ and $\xi_1, \,...,\,\xi_n \in \mathbb{C}$ . From this definition, I can't see how to prove the statement. Is there an equivalent definition which makes it easier? If not, how do we prove it?","Let be a probability space and a random variable. How to prove that the characteristic function , is non-negative definite? I didn't know the concept of non-negative definiteness for complex functions, and the only definition I've found is the followig: The function is said to be non-negative definite when: for every choice of , and . From this definition, I can't see how to prove the statement. Is there an equivalent definition which makes it easier? If not, how do we prove it?","(\Omega, \mathcal{F}, P) X:\Omega\to\mathbb{R} \varphi_X(t) = E[e^{itX}] =\int_{\Omega}e^{itX(\omega)}dP(\omega) f:\mathbb{R}\to\mathbb{C} \sum_{1\leq i, k\leq n}f(x_i-x_k)\xi_i\bar{\xi_k}\geq 0 n\in\mathbb{N} x_1, \,...,\,x_n \in \mathbb{R} \xi_1, \,...,\,\xi_n \in \mathbb{C}","['complex-analysis', 'probability-theory', 'characteristic-functions']"
57,Degree of $P$ as a smooth function equals its polynomial degree $d$.,Degree of  as a smooth function equals its polynomial degree .,P d,"Let $M,N$ be connected oriented manifolds such that $\partial M=\partial N=\emptyset$. Let $F:M\to N $ be a smooth proper map (i.e. for every $K\subset N$ compact, $F^{-1}(K)$ is compact). We define the degree of $F$ as $$ deg(F):=\sum_{p\in F^{-1}(q)}\varepsilon(p) $$ where $q$ is a regular value of $F$ and  $$ \varepsilon(p)=\begin{cases}    +1       & \quad \text{if F preserves the orientation near $p$ }\\     -1  & \quad \text{if F reverves the orientation near $p$}\\   \end{cases} $$ Let $P$ be a complex polynomial of degree $d$. Considering $P$ as a map from $\mathbb{R}^2$ to $\mathbb{R}^2$, I proved that $P$ is smooth, proper (if and only if is polynomial degree $d$ is positive). I want to show that the degree of $P$ as a smooth function equals its degree as a polynomial. (Somehow I think the fundamental theorem of algebra should be involved) Any hints?","Let $M,N$ be connected oriented manifolds such that $\partial M=\partial N=\emptyset$. Let $F:M\to N $ be a smooth proper map (i.e. for every $K\subset N$ compact, $F^{-1}(K)$ is compact). We define the degree of $F$ as $$ deg(F):=\sum_{p\in F^{-1}(q)}\varepsilon(p) $$ where $q$ is a regular value of $F$ and  $$ \varepsilon(p)=\begin{cases}    +1       & \quad \text{if F preserves the orientation near $p$ }\\     -1  & \quad \text{if F reverves the orientation near $p$}\\   \end{cases} $$ Let $P$ be a complex polynomial of degree $d$. Considering $P$ as a map from $\mathbb{R}^2$ to $\mathbb{R}^2$, I proved that $P$ is smooth, proper (if and only if is polynomial degree $d$ is positive). I want to show that the degree of $P$ as a smooth function equals its degree as a polynomial. (Somehow I think the fundamental theorem of algebra should be involved) Any hints?",,"['complex-analysis', 'differential-geometry', 'polynomials', 'manifolds', 'differential-topology']"
58,"why $f$ is holomorphic if $f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta)\, d \zeta}{\zeta - z}$?",why  is holomorphic if ?,"f f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta)\, d \zeta}{\zeta - z}","I'm reading Gong Sheng's Concise Complex Analysis to get some basic understanding. On $\S 2.4$ page 61 Theorem 2.15 (Hurwitz Theorem) it says Theorem 2.15 (Hurwitz Theorem) Let $\{f_j\}$ be a sequence of holomorphic functions on $U\subseteq \mathbb C$ that converges uniformly to a function $f$ on    every compact subset of $U$. If $f_j$ is never equal to zero on $U$ for all $j$, then    $f$ is either identically zero or never equal to zero on $U$. Proof: For an arbitrary point $z \in U \subseteq \mathbb C$, choose a simple closed curve $\gamma$ in $U$ such that the inside of $\gamma$ contains $z$.    Since $f_j$ is holomorphic on $U$, by Cauchy integral formula we have $$f_j(z)=\frac{1}{2\pi i}\int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}$$   Since $\{f_j\}$ converges uniformly on every compact subset of $U$, we have    $$\lim\limits_{j\to \infty} f_j(z) = \lim\limits_{j\to \infty} \frac{1}{2\pi j} \int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}  = \frac{1}{2\pi j} \int_\gamma \lim\limits_{j\to \infty} \frac{f_j(\zeta)\,d \zeta}{\zeta-z} $$   It follows that $$f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$$   Hence, $f(z)$ is a holomorphic function.    Similarly, we can prove that $\{f_j'(z)\}$ converges uniformly to $f'(z)$ on every compact subset of $U$. If $f(z)$ is not identically zero, then by Theorem 2.13, the zeros of $f$ are  discrete. Let $\gamma$ be a curve that does not pass through these zeros. Then    $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} \to \frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta}$$   as $j\to \infty$.   By the assumption and Theorem 2.14, we have    $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} = 0$$   Therefore  $$\frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta} = 0$$   and $f(z)$ has no zero on $U$. I wonder why $f(z)$ is a holomorphic function once $f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$? So far from that book I only know such ways to determine a function is holomorphic By definition, that is $f(z)$ is holomorphic in $U$, iff $\forall z\in U$, $\lim_{h\to 0} \frac{f(z+h)-f(z)}{h}$ exists, here $h \in \mathbb C$. Cauchy-Riemann equation, that is, if $f(z) \in \mathscr L ^1 (U)$ and fulfills the Cauchy-Riemann equation $\frac{\partial f}{\partial x} = -i \frac{\partial f}{\partial y}$, then $f$ is holomorphic on $U$, here $z=x+iy$. Power series expansion (Taylor series): $f(z)$ is holomorphic in $U$ iff $f$ has a power series expansion $\forall z \in U$. Morera theorem:  If $f(z)$ is continuous on $U$ and  the integral of $f$ along any rectifiable closed curve is zero, then $f(z)$ is  holomorphic on $U$. It seems none of such 1-4 could get to the conclusion that $f(z)$ is a holomorphic function?","I'm reading Gong Sheng's Concise Complex Analysis to get some basic understanding. On $\S 2.4$ page 61 Theorem 2.15 (Hurwitz Theorem) it says Theorem 2.15 (Hurwitz Theorem) Let $\{f_j\}$ be a sequence of holomorphic functions on $U\subseteq \mathbb C$ that converges uniformly to a function $f$ on    every compact subset of $U$. If $f_j$ is never equal to zero on $U$ for all $j$, then    $f$ is either identically zero or never equal to zero on $U$. Proof: For an arbitrary point $z \in U \subseteq \mathbb C$, choose a simple closed curve $\gamma$ in $U$ such that the inside of $\gamma$ contains $z$.    Since $f_j$ is holomorphic on $U$, by Cauchy integral formula we have $$f_j(z)=\frac{1}{2\pi i}\int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}$$   Since $\{f_j\}$ converges uniformly on every compact subset of $U$, we have    $$\lim\limits_{j\to \infty} f_j(z) = \lim\limits_{j\to \infty} \frac{1}{2\pi j} \int_\gamma \frac{f_j(\zeta)\,d \zeta}{\zeta-z}  = \frac{1}{2\pi j} \int_\gamma \lim\limits_{j\to \infty} \frac{f_j(\zeta)\,d \zeta}{\zeta-z} $$   It follows that $$f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$$   Hence, $f(z)$ is a holomorphic function.    Similarly, we can prove that $\{f_j'(z)\}$ converges uniformly to $f'(z)$ on every compact subset of $U$. If $f(z)$ is not identically zero, then by Theorem 2.13, the zeros of $f$ are  discrete. Let $\gamma$ be a curve that does not pass through these zeros. Then    $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} \to \frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta}$$   as $j\to \infty$.   By the assumption and Theorem 2.14, we have    $$\frac{1}{2\pi i} \int_\gamma \frac{f_j'(\zeta)}{f_j(\zeta)\, d \zeta} = 0$$   Therefore  $$\frac{1}{2\pi i} \int_\gamma \frac{f'(\zeta)}{f(\zeta)\, d \zeta} = 0$$   and $f(z)$ has no zero on $U$. I wonder why $f(z)$ is a holomorphic function once $f(z) = \frac{1}{2\pi i} \int_\gamma \frac{f(\zeta) \, d \zeta}{\zeta - z}$? So far from that book I only know such ways to determine a function is holomorphic By definition, that is $f(z)$ is holomorphic in $U$, iff $\forall z\in U$, $\lim_{h\to 0} \frac{f(z+h)-f(z)}{h}$ exists, here $h \in \mathbb C$. Cauchy-Riemann equation, that is, if $f(z) \in \mathscr L ^1 (U)$ and fulfills the Cauchy-Riemann equation $\frac{\partial f}{\partial x} = -i \frac{\partial f}{\partial y}$, then $f$ is holomorphic on $U$, here $z=x+iy$. Power series expansion (Taylor series): $f(z)$ is holomorphic in $U$ iff $f$ has a power series expansion $\forall z \in U$. Morera theorem:  If $f(z)$ is continuous on $U$ and  the integral of $f$ along any rectifiable closed curve is zero, then $f(z)$ is  holomorphic on $U$. It seems none of such 1-4 could get to the conclusion that $f(z)$ is a holomorphic function?",,['complex-analysis']
59,"contour integration of a function with two branch points: $\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$",contour integration of a function with two branch points:,"\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1","Many of us have seen the evaluation of the integral $$\int^{\infty}_0 \frac{dx}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ It can be solved using contour integration or beta function . I thought of how to solve the integral $$\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ It can be solved using real methods as follows consider the following integral $$\int^{\infty}_0 x^{-p}(1+x)^{s-1} dx= \frac{\Gamma(1-p)\Gamma(p-s)}{\Gamma(1-s)}$$ Differentiating with respect to $s$ we get $$\int^{\infty}_0 x^{-p}(1+x)^{s-1}\log(1+x) dx=\frac{\Gamma(1-p)\Gamma(p-s)}{\Gamma(1-s)} \left(\psi_0 (1-s)- \psi_0(p-s)\right)$$ at $s =0$ we get $$\int^{\infty}_0 x^{-p}\frac{\log(1+x)}{1+x} dx=\frac{\pi}{\sin(\pi p)} \left(\psi_0 (1)- \psi_0(p)\right)$$ where i used the reflection formula . Statement of question How to solve the following integral using contour integration $$\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ I thought we can use the following contour So the function $$F(z) = \frac{e^{-p \log(z)}\log(1+z)}{(1+z)} $$ is analytic in and on the contour by choosing the branch cut of $e^{-p \log(z)}$ as  $0\leq \text{Arg}(z)<2\pi$ and the branch cut of $\log(1+z)$  as $0\leq \text{Arg}(z+1)<2\pi$ so the function $F(z)$ is analytic everywhere except at $z\geq -1$ . I am finding difficulty finding the integral on the branch point $z=-1$ it seems there is a contribution of the branch point and the pole . Please don't make any substitutions or simplifications for the integral. Feel free to use another contour if my choice was wrong .","Many of us have seen the evaluation of the integral $$\int^{\infty}_0 \frac{dx}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ It can be solved using contour integration or beta function . I thought of how to solve the integral $$\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ It can be solved using real methods as follows consider the following integral $$\int^{\infty}_0 x^{-p}(1+x)^{s-1} dx= \frac{\Gamma(1-p)\Gamma(p-s)}{\Gamma(1-s)}$$ Differentiating with respect to $s$ we get $$\int^{\infty}_0 x^{-p}(1+x)^{s-1}\log(1+x) dx=\frac{\Gamma(1-p)\Gamma(p-s)}{\Gamma(1-s)} \left(\psi_0 (1-s)- \psi_0(p-s)\right)$$ at $s =0$ we get $$\int^{\infty}_0 x^{-p}\frac{\log(1+x)}{1+x} dx=\frac{\pi}{\sin(\pi p)} \left(\psi_0 (1)- \psi_0(p)\right)$$ where i used the reflection formula . Statement of question How to solve the following integral using contour integration $$\int^{\infty}_0 \frac{\log(1+x)}{x^p(1+x)}\, dx \,\,\, 0<\Re(p)<1$$ I thought we can use the following contour So the function $$F(z) = \frac{e^{-p \log(z)}\log(1+z)}{(1+z)} $$ is analytic in and on the contour by choosing the branch cut of $e^{-p \log(z)}$ as  $0\leq \text{Arg}(z)<2\pi$ and the branch cut of $\log(1+z)$  as $0\leq \text{Arg}(z+1)<2\pi$ so the function $F(z)$ is analytic everywhere except at $z\geq -1$ . I am finding difficulty finding the integral on the branch point $z=-1$ it seems there is a contribution of the branch point and the pole . Please don't make any substitutions or simplifications for the integral. Feel free to use another contour if my choice was wrong .",,"['complex-analysis', 'definite-integrals', 'improper-integrals', 'contour-integration']"
60,Complex Exponent of Complex Numbers,Complex Exponent of Complex Numbers,,"How does one find the algebraic solution of a Complex number raised to the power of another Complex number? Here is the work I have done so far, if there are any mistakes please inform me. A real number with a Complex Exponent : $$A \in \Bbb R, \space z \in \Bbb C,\space z = x + iy$$ $$A^z = A^{x+iy} = A^xA^{iy}$$ $$\implies e^{iy\ln A} = A^{iy}$$ $$\exp(iy\ln A) = \cos (y\ln A)+i\sin(y\ln A)$$ $$A^z = A^x[\cos (y\ln A)+i\sin(y\ln A)]$$ A Complex number with a Complex Exponent : [Using previous variables] $$C \in \Bbb C,\space C = a +bi\space|\space re^{i\theta}, \theta =\arg C$$ $$C^z = (a+ib)^z$$ [After previous mistake the following notes are inaccurate] $$C^z = a^x[\cos (y\ln a)+i\sin(y\ln a)] + ib^xib^{iy}$$ And this is as far as I could go as the expansion of $ib^xib^{iy}$ is being problematic. Could I have some help with this expansion?","How does one find the algebraic solution of a Complex number raised to the power of another Complex number? Here is the work I have done so far, if there are any mistakes please inform me. A real number with a Complex Exponent : $$A \in \Bbb R, \space z \in \Bbb C,\space z = x + iy$$ $$A^z = A^{x+iy} = A^xA^{iy}$$ $$\implies e^{iy\ln A} = A^{iy}$$ $$\exp(iy\ln A) = \cos (y\ln A)+i\sin(y\ln A)$$ $$A^z = A^x[\cos (y\ln A)+i\sin(y\ln A)]$$ A Complex number with a Complex Exponent : [Using previous variables] $$C \in \Bbb C,\space C = a +bi\space|\space re^{i\theta}, \theta =\arg C$$ $$C^z = (a+ib)^z$$ [After previous mistake the following notes are inaccurate] $$C^z = a^x[\cos (y\ln a)+i\sin(y\ln a)] + ib^xib^{iy}$$ And this is as far as I could go as the expansion of $ib^xib^{iy}$ is being problematic. Could I have some help with this expansion?",,"['complex-analysis', 'exponentiation']"
61,What is the right treatment for $0^i$?,What is the right treatment for ?,0^i,"I need to calculate a limit of a complex expression (had it in a physics research) that contains a term $(r-b)^p$ for $r\rightarrow b+$ where $r,b$ are reals, and $p$ is complex, let's suppose for simplicity $p=i$. At the beginning, I put it equals to $0$ as an obvious thing, but strangely enough, ""Mathematica"" gives me something strange: $e^{2i\operatorname{Interval}[0,\pi]}$, then I thought maybe I was wrong with ""obviousity"" of the result, because we can actually put (formally) $0=e^{-\infty+i\phi}$, then if we use $a^b=e^{b\log a}$ we have $0^i=e^{-i\infty-\phi}$ (where all $2\pi k$ included in the infinity or $\phi$). This result seems to be very strange for me (it will introduce a new parameter $\phi$ into my theory), and I found no example for this, especially that I know one needs to be careful with branches when making such tricks, but I have no clue if that is correct or wrong, any help will be appreciated.","I need to calculate a limit of a complex expression (had it in a physics research) that contains a term $(r-b)^p$ for $r\rightarrow b+$ where $r,b$ are reals, and $p$ is complex, let's suppose for simplicity $p=i$. At the beginning, I put it equals to $0$ as an obvious thing, but strangely enough, ""Mathematica"" gives me something strange: $e^{2i\operatorname{Interval}[0,\pi]}$, then I thought maybe I was wrong with ""obviousity"" of the result, because we can actually put (formally) $0=e^{-\infty+i\phi}$, then if we use $a^b=e^{b\log a}$ we have $0^i=e^{-i\infty-\phi}$ (where all $2\pi k$ included in the infinity or $\phi$). This result seems to be very strange for me (it will introduce a new parameter $\phi$ into my theory), and I found no example for this, especially that I know one needs to be careful with branches when making such tricks, but I have no clue if that is correct or wrong, any help will be appreciated.",,"['complex-analysis', 'complex-numbers']"
62,Riemann zeta function and modulus,Riemann zeta function and modulus,,"The functional equation for the zeta function $ζ(s)$ is given by $ζ(s)=f(s)ζ(1-s)$ (a) We know that if $Re(s)=1/2$, then $|f(s)|=1$. My question is about the case where $|f(s)|=1$ outside the critical line. Is this case possible, i.e., (b) Is this implication ""if $|f(s)|=1$ then $Re(s)=1/2$"" correct?","The functional equation for the zeta function $ζ(s)$ is given by $ζ(s)=f(s)ζ(1-s)$ (a) We know that if $Re(s)=1/2$, then $|f(s)|=1$. My question is about the case where $|f(s)|=1$ outside the critical line. Is this case possible, i.e., (b) Is this implication ""if $|f(s)|=1$ then $Re(s)=1/2$"" correct?",,"['complex-analysis', 'zeta-functions']"
63,"Solving $\forall x \in \mathbb{R}_+^*, f'(x) = f\left(\frac1{x}\right)$",Solving,"\forall x \in \mathbb{R}_+^*, f'(x) = f\left(\frac1{x}\right)","I recently came across this equation : $$\forall x \in \mathbb{R}_+^*, f'(x) = f\left(\frac1{x}\right)$$where $f \in \mathcal{C}^1(\mathbb{R}, \mathbb{R})$. I've done the following, but I'm stuck at the end. Could you give me pointers? Thanks! Differentiating yields $$\forall x, f''(x) = -\frac1{x^2}f(x) \tag{$S_0$}$$Solutions in the form $$x \mapsto \frac1{x^\phi}$$ work iff $\phi(\phi+1) = -1 $, ie. $\phi = \frac{-1 \pm i \sqrt{3}}{2} =e^{\pm 2i\pi/3} = j, \overline{j}$. Elements of the vector space generated by the free pair $(x^j, x^\overline{j})$ are therefore solutions of ($S_0$). I then feed $\lambda x^j + \mu x^\overline{j}$ in the original equation, which yields $-\lambda j\frac1{x^{j+1}}-\mu\overline{j}\frac1{x^{\overline{j} + 1}} = \frac{x^{j + \overline{j}}}{\lambda x^\overline{j} + \mu x^j}$, then $(-\lambda j x^{\overline{j}+1} - \mu \overline{j} x^{j+1})(\lambda x^{\overline{j}} + \mu x^j) = x^{1+j+\overline{j}} = x^0 = 1$, and $-\lambda^2 j x^{2\overline{j} + 1} - \mu^2 \overline{j} x^{2j+1} - \lambda\mu(j + \overline{j}) = 0 $. Thus, $$ \lambda^2 j x^{-2i\sin(2\pi/3)} + \mu^2 \overline{j} x^{2i\sin(2\pi/3)} = \lambda\mu$$ Does that mean that no solutions can be found to the original equation, except the trivial $x \mapsto 0$ one? Or that I didn't take the right approach? I can't figure out how to handle the last equality.","I recently came across this equation : $$\forall x \in \mathbb{R}_+^*, f'(x) = f\left(\frac1{x}\right)$$where $f \in \mathcal{C}^1(\mathbb{R}, \mathbb{R})$. I've done the following, but I'm stuck at the end. Could you give me pointers? Thanks! Differentiating yields $$\forall x, f''(x) = -\frac1{x^2}f(x) \tag{$S_0$}$$Solutions in the form $$x \mapsto \frac1{x^\phi}$$ work iff $\phi(\phi+1) = -1 $, ie. $\phi = \frac{-1 \pm i \sqrt{3}}{2} =e^{\pm 2i\pi/3} = j, \overline{j}$. Elements of the vector space generated by the free pair $(x^j, x^\overline{j})$ are therefore solutions of ($S_0$). I then feed $\lambda x^j + \mu x^\overline{j}$ in the original equation, which yields $-\lambda j\frac1{x^{j+1}}-\mu\overline{j}\frac1{x^{\overline{j} + 1}} = \frac{x^{j + \overline{j}}}{\lambda x^\overline{j} + \mu x^j}$, then $(-\lambda j x^{\overline{j}+1} - \mu \overline{j} x^{j+1})(\lambda x^{\overline{j}} + \mu x^j) = x^{1+j+\overline{j}} = x^0 = 1$, and $-\lambda^2 j x^{2\overline{j} + 1} - \mu^2 \overline{j} x^{2j+1} - \lambda\mu(j + \overline{j}) = 0 $. Thus, $$ \lambda^2 j x^{-2i\sin(2\pi/3)} + \mu^2 \overline{j} x^{2i\sin(2\pi/3)} = \lambda\mu$$ Does that mean that no solutions can be found to the original equation, except the trivial $x \mapsto 0$ one? Or that I didn't take the right approach? I can't figure out how to handle the last equality.",,"['complex-analysis', 'ordinary-differential-equations', 'functional-equations']"
64,Complex differentiabilty,Complex differentiabilty,,"I know that: 1) A function $f:\mathbb{R}^2\to \mathbb{R}^2$, when differentiable at a point, has a $2\times 2$ matrix as a derivative, which is a linear transformation from $\mathbb{R}^2\to \mathbb{R}^2$ best approximating the function linearly in some neighbourhood. 2) There is a ring homomorphism $\mathbb{C} \to Mat_{2x2}(\mathbb{R})$ as $a+ib \longmapsto \left[\begin{array}{11}a & -b\\b & a \end{array}\right]$ 3) For a function $f:\mathbb{C} \to \mathbb{C}$, I can define complex differentiabilty as the best $\mathbb{C}$-linear approximation of the function locally at a point, i.e., $f'(z_0):h \mapsto f'(z_0)h$ Now, I want to combine these three observations, so that the Cauchy-Riemann equation falls out by considering a complex differentiable function as a function from $\mathbb{R}^2\to \mathbb{R}^2$ and connect the jacobian with the $\mathbb{C}$-linear transformation via the homomorphism. I am having trouble even formulating a proposition that I can prove. Do I define something called 'Complexfying an $\mathbb{R}^2$-operator'? Any help will be appreciated. The upshot will be that I can then 'shift' the proofs of some of the basic results of holomorphic functions (such as the fact that if the partial derivatives of the co-ordinate functions exist and are continuous then the function will be holomorphic, etc) to that of multivariable calculus.","I know that: 1) A function $f:\mathbb{R}^2\to \mathbb{R}^2$, when differentiable at a point, has a $2\times 2$ matrix as a derivative, which is a linear transformation from $\mathbb{R}^2\to \mathbb{R}^2$ best approximating the function linearly in some neighbourhood. 2) There is a ring homomorphism $\mathbb{C} \to Mat_{2x2}(\mathbb{R})$ as $a+ib \longmapsto \left[\begin{array}{11}a & -b\\b & a \end{array}\right]$ 3) For a function $f:\mathbb{C} \to \mathbb{C}$, I can define complex differentiabilty as the best $\mathbb{C}$-linear approximation of the function locally at a point, i.e., $f'(z_0):h \mapsto f'(z_0)h$ Now, I want to combine these three observations, so that the Cauchy-Riemann equation falls out by considering a complex differentiable function as a function from $\mathbb{R}^2\to \mathbb{R}^2$ and connect the jacobian with the $\mathbb{C}$-linear transformation via the homomorphism. I am having trouble even formulating a proposition that I can prove. Do I define something called 'Complexfying an $\mathbb{R}^2$-operator'? Any help will be appreciated. The upshot will be that I can then 'shift' the proofs of some of the basic results of holomorphic functions (such as the fact that if the partial derivatives of the co-ordinate functions exist and are continuous then the function will be holomorphic, etc) to that of multivariable calculus.",,['complex-analysis']
65,$f(z) = z + f(z^2)$ outside the unit disk?,outside the unit disk?,f(z) = z + f(z^2),"The function $$ f(z) = \sum_{n=0}^\infty z^{2^n} $$ which satisfies the functional equation $f(z) = z + f(z^2)$ is a classic example of a function analytic in $\mathbb{D} = \{z:|z|<1\}$ that cannot be analytically extended beyond the boundary anywhere. My question is, are there any other analytic solutions to $f(z) = z +f(z^2)$ defined on a different domain, $\Omega\subseteq \mathbb{C}\setminus\mathbb{D}$ ?","The function which satisfies the functional equation is a classic example of a function analytic in that cannot be analytically extended beyond the boundary anywhere. My question is, are there any other analytic solutions to defined on a different domain, ?","
f(z) = \sum_{n=0}^\infty z^{2^n}
 f(z) = z + f(z^2) \mathbb{D} = \{z:|z|<1\} f(z) = z +f(z^2) \Omega\subseteq \mathbb{C}\setminus\mathbb{D}","['complex-analysis', 'power-series', 'functional-equations', 'analytic-functions', 'analytic-continuation']"
66,Methods for calculating the number of zeros of a polynomial with a specified real part?,Methods for calculating the number of zeros of a polynomial with a specified real part?,,"Given a polynomial with real coefficients is there a method (e.g. from algebra or complex analysis) to calculate the number of complex zeros with a specified real part? Background. This question is motivated by my tests related to this problem . Let $p>3$ be a prime number. Let $G_p(x)=(x+1)^p-x^p-1$, and let $$F_p(x)=\frac{(x+1)^p-x^p-1}{px(x+1)(x^2+x+1)^{n_p}}$$ where the exponent $n_p$ is equal to $1$ (resp. $2$) when $p\equiv-1\pmod 6$ (resp. $p\equiv1\pmod 6$). The answer by Lord Shark the Unknown (loc. linked) implies that $F_p(x)$ is a monic polynomial with integer coefficients. The degree of $F_p$ is equal to $6\lfloor(p-3)/6\rfloor$. I can show that the complex zeros of $F_p(x)$ come in groups of six. Each of the form $\alpha,-\alpha-1,1/\alpha,-1/(\alpha+1),-\alpha/(\alpha+1),-(\alpha+1)/\alpha.$ That is, orbits of a familiar group (isomorphic to $S_3$) of fractional linear transformations. My conjecture. Exactly one third of the zeros of $F_p(x)$ have real part equal to $-1/2$. I tested this with Mathematica for a few of the smallest primes and it seems to hold. Also, each sextet of zeros of the above form seems to be stable under complex conjugation, and seems to contain a complex conjugate pair of numbers with real part $=-1/2$.  Anyway, I am curious about the number of zeros $z=s+it$ of the polynomial $F_p(x)$ on the line $s=-1/2$. Summary and thoughts. Any general method or formula is welcome, but I will be extra grateful if you want to test a method on the polynomial $G_p(x)$ or $F_p(x)$ :-) My first idea was to try the following: Given a polynomial $P(x)=\prod_i(x-z_i)$ is there a way of getting $R(x):=\prod_i(x-z_i-\overline{z_i})$? If this can be done, then we get the answer by calculating the multiplicity of $-1$ as a zero of $R(x)$. May be a method for calculating the number of real zeros can be used with suitable substitution that maps the real axes to the line $s=-1/2$ (need to check on this)? Of course, if you can prove that $F_p(x)$ is irreducible it is better that you post the answer to the linked question. The previous bounty expired, but that can be fixed.","Given a polynomial with real coefficients is there a method (e.g. from algebra or complex analysis) to calculate the number of complex zeros with a specified real part? Background. This question is motivated by my tests related to this problem . Let $p>3$ be a prime number. Let $G_p(x)=(x+1)^p-x^p-1$, and let $$F_p(x)=\frac{(x+1)^p-x^p-1}{px(x+1)(x^2+x+1)^{n_p}}$$ where the exponent $n_p$ is equal to $1$ (resp. $2$) when $p\equiv-1\pmod 6$ (resp. $p\equiv1\pmod 6$). The answer by Lord Shark the Unknown (loc. linked) implies that $F_p(x)$ is a monic polynomial with integer coefficients. The degree of $F_p$ is equal to $6\lfloor(p-3)/6\rfloor$. I can show that the complex zeros of $F_p(x)$ come in groups of six. Each of the form $\alpha,-\alpha-1,1/\alpha,-1/(\alpha+1),-\alpha/(\alpha+1),-(\alpha+1)/\alpha.$ That is, orbits of a familiar group (isomorphic to $S_3$) of fractional linear transformations. My conjecture. Exactly one third of the zeros of $F_p(x)$ have real part equal to $-1/2$. I tested this with Mathematica for a few of the smallest primes and it seems to hold. Also, each sextet of zeros of the above form seems to be stable under complex conjugation, and seems to contain a complex conjugate pair of numbers with real part $=-1/2$.  Anyway, I am curious about the number of zeros $z=s+it$ of the polynomial $F_p(x)$ on the line $s=-1/2$. Summary and thoughts. Any general method or formula is welcome, but I will be extra grateful if you want to test a method on the polynomial $G_p(x)$ or $F_p(x)$ :-) My first idea was to try the following: Given a polynomial $P(x)=\prod_i(x-z_i)$ is there a way of getting $R(x):=\prod_i(x-z_i-\overline{z_i})$? If this can be done, then we get the answer by calculating the multiplicity of $-1$ as a zero of $R(x)$. May be a method for calculating the number of real zeros can be used with suitable substitution that maps the real axes to the line $s=-1/2$ (need to check on this)? Of course, if you can prove that $F_p(x)$ is irreducible it is better that you post the answer to the linked question. The previous bounty expired, but that can be fixed.",,"['complex-analysis', 'polynomials']"
67,does the identity $\ln(z^n) = n\times\ln(z)$ hold for complex variables ?!,does the identity  hold for complex variables ?!,\ln(z^n) = n\times\ln(z),"This was a problem in a complex textbook: is the collection of all values of $\ln(i^2)$ the same as the collection of all values of $2\ln(i)$ ? And I guess the answer is no as the first will yield the set of values $i(\pi + 2k\pi)$ while the second yields $2\ln(i) = 2(\ln(1) + (\pi/2 + 2k\pi) i) = i(\pi + 4k\pi)$ which contradicts the identity given in Dennis Zill's textbook page 182 stating that $(iii) \ln z^n = n\ln z$ . Just a random thought came to my mind after writing this question. the first identity on the same page states that $(i) \ln(z_1 z_2 ) = \ln z_1 + \ln z_2$ . this and the third identity seem to be equivalent by substituting both $z_1$ and $z_2$ by $i$ . So, $$\ln(i \times i) = \ln(i) + \ln(i) = i\times(\pi/2 + 2k\pi) + i \times (\pi/2 + 2n\pi) = i \times \pi + 2s\pi$$ which is correct but this implies one of two things: $\ln(i) + \ln(i) \neq 2\ln(i)$ $2\times \ln(i)$ is not a multiple of the multi-valued function $\ln$ but rather a sum of two instances of $\ln(i)$ . Which both seems very odd, So what am I getting wrong?! Edit n is an integer and ln is the multivalued function while Ln is the principal value","This was a problem in a complex textbook: is the collection of all values of the same as the collection of all values of ? And I guess the answer is no as the first will yield the set of values while the second yields which contradicts the identity given in Dennis Zill's textbook page 182 stating that . Just a random thought came to my mind after writing this question. the first identity on the same page states that . this and the third identity seem to be equivalent by substituting both and by . So, which is correct but this implies one of two things: is not a multiple of the multi-valued function but rather a sum of two instances of . Which both seems very odd, So what am I getting wrong?! Edit n is an integer and ln is the multivalued function while Ln is the principal value",\ln(i^2) 2\ln(i) i(\pi + 2k\pi) 2\ln(i) = 2(\ln(1) + (\pi/2 + 2k\pi) i) = i(\pi + 4k\pi) (iii) \ln z^n = n\ln z (i) \ln(z_1 z_2 ) = \ln z_1 + \ln z_2 z_1 z_2 i \ln(i \times i) = \ln(i) + \ln(i) = i\times(\pi/2 + 2k\pi) + i \times (\pi/2 + 2n\pi) = i \times \pi + 2s\pi \ln(i) + \ln(i) \neq 2\ln(i) 2\times \ln(i) \ln \ln(i),"['complex-analysis', 'logarithms']"
68,Are Inverse Trig functions a different form of log?,Are Inverse Trig functions a different form of log?,,"When studying complex analysis, we realize that trigonometric functions are nothing but exponentials, and we can define real trigonometric functions in terms of complex exponentials.  I was wondering if we can apply this logic to define inverse trigonometric functions (arcsin, for example) in terms of complex logarithms, who are the inverse functions of complex exponentials. Can we? Is it appropriate?","When studying complex analysis, we realize that trigonometric functions are nothing but exponentials, and we can define real trigonometric functions in terms of complex exponentials.  I was wondering if we can apply this logic to define inverse trigonometric functions (arcsin, for example) in terms of complex logarithms, who are the inverse functions of complex exponentials. Can we? Is it appropriate?",,"['complex-analysis', 'trigonometry', 'inverse-function']"
69,Show that $p_n(a)\neq 0$ if $|a|=n$,Show that  if,p_n(a)\neq 0 |a|=n,"I am working the next problem: Consider the polynomials    $$ p_n(z)=\sum_{j=0}^{n}\frac{z^j}{j!} $$   For $n \geq 2$, show that if $a \in \mathbb{C}$ is such that $|a|=1$ or $|a|=n$, then $p_n(a)\neq 0$ The case $|a|=1$ has already been answer here on the last comment of this question , however I still have no clue for the case $|a|=n$. Any help? I have tried a lot of things, as you can see on the other question but nothing good.","I am working the next problem: Consider the polynomials    $$ p_n(z)=\sum_{j=0}^{n}\frac{z^j}{j!} $$   For $n \geq 2$, show that if $a \in \mathbb{C}$ is such that $|a|=1$ or $|a|=n$, then $p_n(a)\neq 0$ The case $|a|=1$ has already been answer here on the last comment of this question , however I still have no clue for the case $|a|=n$. Any help? I have tried a lot of things, as you can see on the other question but nothing good.",,"['complex-analysis', 'exponential-function', 'roots']"
70,Entire function $f(z)$ bounded for $\mathrm{Re}(z)^2 > 1$?,Entire function  bounded for ?,f(z) \mathrm{Re}(z)^2 > 1,Let $z$ be a complex number and $\mathrm{Re}$ denote the real part. Does there exist a nonconstant entire function $f(z)$ such that $f(z)$ is bounded for  $\mathrm{Re}(z)^2 > 1$ ?,Let $z$ be a complex number and $\mathrm{Re}$ denote the real part. Does there exist a nonconstant entire function $f(z)$ such that $f(z)$ is bounded for  $\mathrm{Re}(z)^2 > 1$ ?,,['complex-analysis']
71,Fourier transform of a function of compact support,Fourier transform of a function of compact support,,"My professor occasionally assigns optional difficult problems which we do not turn in from Stein and Shakarchi's Complex Analysis .  I am currently studying for a test in that class and try to get all of these optional problems answered.  One problem he gave us is Problem 2 from Chapter 4 on page 132 which you can find here http://carlossicoli.free.fr/S/Stein_E.M.,_Shakarchi_R.-Complex_Analysis-Princeton_univ_press(2003).pdf I am currently working on part (a) Suppose f has bounded support and is of class $C^2$.  For $z \in \mathbb{C}$, let $\hat{f}(z)=\int_{-\infty}^{\infty} f(t)e^{-2\pi izt} dt$.  I am supposed to observe that $\hat{f}$ is an entire function, and using integration by parts show that for fixed $a\ge 0$ then $|y|\le a$ implies that for some constant $C_a$, $|\hat{f}(x+iy)|\le \frac{C_a}{1+x^2}$.  It says observe $\hat{f}$ is an entire function so I assume it is something simple but I don't see it.  Maybe I will have to evaluate the integral first. Which leads me to the integration by parts.  I am struggling with that without knowing the function f specifically.  I tried using $f$ as $u$ and the exponential function as $dv$ but got nowhere.  Thus, I am here asking for your help.  Thanks!","My professor occasionally assigns optional difficult problems which we do not turn in from Stein and Shakarchi's Complex Analysis .  I am currently studying for a test in that class and try to get all of these optional problems answered.  One problem he gave us is Problem 2 from Chapter 4 on page 132 which you can find here http://carlossicoli.free.fr/S/Stein_E.M.,_Shakarchi_R.-Complex_Analysis-Princeton_univ_press(2003).pdf I am currently working on part (a) Suppose f has bounded support and is of class $C^2$.  For $z \in \mathbb{C}$, let $\hat{f}(z)=\int_{-\infty}^{\infty} f(t)e^{-2\pi izt} dt$.  I am supposed to observe that $\hat{f}$ is an entire function, and using integration by parts show that for fixed $a\ge 0$ then $|y|\le a$ implies that for some constant $C_a$, $|\hat{f}(x+iy)|\le \frac{C_a}{1+x^2}$.  It says observe $\hat{f}$ is an entire function so I assume it is something simple but I don't see it.  Maybe I will have to evaluate the integral first. Which leads me to the integration by parts.  I am struggling with that without knowing the function f specifically.  I tried using $f$ as $u$ and the exponential function as $dv$ but got nowhere.  Thus, I am here asking for your help.  Thanks!",,"['complex-analysis', 'fourier-analysis']"
72,Integrate: $\int_0^{\pi} \log ( 1 - 2 r \cos \theta + r^2)d\theta$,Integrate:,\int_0^{\pi} \log ( 1 - 2 r \cos \theta + r^2)d\theta,"If $r \in \Bbb R$ how to integrate $\displaystyle \int_0^{\pi} \log ( 1  - 2 r \cos \theta + r^2)d\theta$? I need some hints. Special case, if $r = 1$ then I know the above integral is zero . Here is my working \begin{align*} \int_0^{\pi}\log (1 - 2 r \cos \theta + r^2)d\theta &= \int_0^\pi\log ((1 - re^{i \theta})(1 -re^{-i\theta} )) d\theta\\   &= \int_0^\pi \log(1 - r e^{i\theta})d\theta + \int_0^\pi\log(1 - re^{-i\theta})d\theta\\   &= \int_0^{2\pi} \log( 1 - re^{i\theta})d\theta \\  &= 0 \end{align*}","If $r \in \Bbb R$ how to integrate $\displaystyle \int_0^{\pi} \log ( 1  - 2 r \cos \theta + r^2)d\theta$? I need some hints. Special case, if $r = 1$ then I know the above integral is zero . Here is my working \begin{align*} \int_0^{\pi}\log (1 - 2 r \cos \theta + r^2)d\theta &= \int_0^\pi\log ((1 - re^{i \theta})(1 -re^{-i\theta} )) d\theta\\   &= \int_0^\pi \log(1 - r e^{i\theta})d\theta + \int_0^\pi\log(1 - re^{-i\theta})d\theta\\   &= \int_0^{2\pi} \log( 1 - re^{i\theta})d\theta \\  &= 0 \end{align*}",,"['complex-analysis', 'definite-integrals']"
73,What does $ e^{iz} $ mean? It was used to define complex sine in my book.,What does  mean? It was used to define complex sine in my book., e^{iz} ,"I have been trying to understand the notion of complex sine that was defined in my book. The book first starts out defining $ e^{z} $ as $$ \text{If } z = x + iy, \text{ then } e^z = e^{x}\cos y + ie^x\sin y $$ Next, the book states that for any $ y \in \mathbb{R} $: $$ \begin{eqnarray} e^{iy} &=& \cos y + i \sin y\\ e^{-iy} &=& \cos y - i \sin y\\ \implies \sin \ y &=& \frac{1}{2i}(e^{iy} - e^{-iy}) \end{eqnarray} $$ I followed up to this point, but then they generalized this to define $\sin z \text{ for } z \in \mathbb{C} $. This is the definition they gave: $$ \sin z = \frac{1}{2i}(e^{iz} - e^{-iz}) $$ I do not understand want $ e^{iz} $ means in this equation. If $ z = x + iy $ then does $ e^{iz} = e^{-y + ix} = e^{-y}\cos x + ie^{-y}\sin x $. Is this correct, or does it mean something else?","I have been trying to understand the notion of complex sine that was defined in my book. The book first starts out defining $ e^{z} $ as $$ \text{If } z = x + iy, \text{ then } e^z = e^{x}\cos y + ie^x\sin y $$ Next, the book states that for any $ y \in \mathbb{R} $: $$ \begin{eqnarray} e^{iy} &=& \cos y + i \sin y\\ e^{-iy} &=& \cos y - i \sin y\\ \implies \sin \ y &=& \frac{1}{2i}(e^{iy} - e^{-iy}) \end{eqnarray} $$ I followed up to this point, but then they generalized this to define $\sin z \text{ for } z \in \mathbb{C} $. This is the definition they gave: $$ \sin z = \frac{1}{2i}(e^{iz} - e^{-iz}) $$ I do not understand want $ e^{iz} $ means in this equation. If $ z = x + iy $ then does $ e^{iz} = e^{-y + ix} = e^{-y}\cos x + ie^{-y}\sin x $. Is this correct, or does it mean something else?",,['complex-analysis']
74,Determine complex polynomial,Determine complex polynomial,,"Problem Let $P(z) = z^n + a_{n−1}z^{n−1} + \cdots + a_1z + a_0$ be a polynomial of degree $n > 0$. Show that if $\lvert P(z) \lvert \le 1$ whenever $\lvert z \rvert = 1$ then $P(z) = z^n$. I have tried to see $\dfrac{P(z)}{z^n}$, but nothing happens. I wonder which theorems should I use to solve this. I think hints are enough. Thanks.","Problem Let $P(z) = z^n + a_{n−1}z^{n−1} + \cdots + a_1z + a_0$ be a polynomial of degree $n > 0$. Show that if $\lvert P(z) \lvert \le 1$ whenever $\lvert z \rvert = 1$ then $P(z) = z^n$. I have tried to see $\dfrac{P(z)}{z^n}$, but nothing happens. I wonder which theorems should I use to solve this. I think hints are enough. Thanks.",,"['complex-analysis', 'polynomials', 'maximum-principle']"
75,Euler's product formula for $\sin(\pi z)$ and the gamma function,Euler's product formula for  and the gamma function,\sin(\pi z),"I want to derive Euler's infinite product formula $$\displaystyle \sin(\pi z) = \pi z \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right)$$ by using Euler's reflection equation $\Gamma(z)\Gamma(1-z) \sin(\pi z) = \pi$ and the definition of $\Gamma(z)$ as an infinite product, namely $$\displaystyle \Gamma(z) := \frac{1}{z} \prod_{k=1}^\infty \frac{(1+\frac{1}{k})^z}{1+\frac{z}{k}}.$$ To be precise, I obtain that $$\sin(\pi z) = \pi z(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right)$$ hence I wish to prove $$(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right) = \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right).$$ I multiplied things out and got it to the form $$(1-z) \prod_{k=1}^\infty \frac{1 + \frac{1}{k} + \frac{z(1-z)}{k^2}}{1 + \frac{1}{k}} = (1-z) \prod_{k=1}^\infty \left( 1 + \frac{\frac{z(1-z)}{k}}{1+\frac{1}{k}}\right)$$ however the $(1-z)$ factor out front is giving me some trouble; I'm not sure how to proceed.","I want to derive Euler's infinite product formula $$\displaystyle \sin(\pi z) = \pi z \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right)$$ by using Euler's reflection equation $\Gamma(z)\Gamma(1-z) \sin(\pi z) = \pi$ and the definition of $\Gamma(z)$ as an infinite product, namely $$\displaystyle \Gamma(z) := \frac{1}{z} \prod_{k=1}^\infty \frac{(1+\frac{1}{k})^z}{1+\frac{z}{k}}.$$ To be precise, I obtain that $$\sin(\pi z) = \pi z(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right)$$ hence I wish to prove $$(1-z) \left( \prod_{k=1}^\infty \frac{1+\frac{z}{k}}{(1+\frac{1}{k})^z} \right) \left( \prod_{k=1}^\infty \frac{1+\frac{1-z}{k}}{(1+\frac{1}{k})^{1-z}} \right) = \prod_{k=1}^\infty \left( 1 - \frac{z^2}{k^2} \right).$$ I multiplied things out and got it to the form $$(1-z) \prod_{k=1}^\infty \frac{1 + \frac{1}{k} + \frac{z(1-z)}{k^2}}{1 + \frac{1}{k}} = (1-z) \prod_{k=1}^\infty \left( 1 + \frac{\frac{z(1-z)}{k}}{1+\frac{1}{k}}\right)$$ however the $(1-z)$ factor out front is giving me some trouble; I'm not sure how to proceed.",,"['complex-analysis', 'special-functions', 'gamma-function']"
76,Two conformal maps $\phi_i : \Omega \to \Omega$ are identical if they coincide at two different points,Two conformal maps  are identical if they coincide at two different points,\phi_i : \Omega \to \Omega,"I'm studying some complex analysis in preparation for a qualifier exam and I'm doing exercise $6.12$ from Robert Greene and Steven Krantz' book Function Theory of One Complex Variable. I have $\Omega$ a simply connected domain in $\mathbb{C}$, with $P,Q \in \Omega$ two different points. $\phi_1 : \Omega \to \Omega$ and $\phi_2 : \Omega \to \Omega$ are conformal maps (that is, bijective and holomorphic) such that $\phi_1(P) = \phi_2(P)$ and $\phi_1(Q) = \phi_2(Q)$. Then the question is to prove that $\phi_1 \equiv \phi_2$. I don't know why but I've been thinking about how to approach this without success for quite some time now. I've thought of maybe using the Riemann mapping theorem to say that there's a conformal map $\phi:\Omega \to \mathbb{D}$ to the open unit disk, and similar things but I'm not getting anywhere really. Thus I would really appreciate some help with this problem, maybe some hints on how to proceed would be very appreciated. Thanks in advance for any help.","I'm studying some complex analysis in preparation for a qualifier exam and I'm doing exercise $6.12$ from Robert Greene and Steven Krantz' book Function Theory of One Complex Variable. I have $\Omega$ a simply connected domain in $\mathbb{C}$, with $P,Q \in \Omega$ two different points. $\phi_1 : \Omega \to \Omega$ and $\phi_2 : \Omega \to \Omega$ are conformal maps (that is, bijective and holomorphic) such that $\phi_1(P) = \phi_2(P)$ and $\phi_1(Q) = \phi_2(Q)$. Then the question is to prove that $\phi_1 \equiv \phi_2$. I don't know why but I've been thinking about how to approach this without success for quite some time now. I've thought of maybe using the Riemann mapping theorem to say that there's a conformal map $\phi:\Omega \to \mathbb{D}$ to the open unit disk, and similar things but I'm not getting anywhere really. Thus I would really appreciate some help with this problem, maybe some hints on how to proceed would be very appreciated. Thanks in advance for any help.",,['complex-analysis']
77,When does differentiability imply analyticity?,When does differentiability imply analyticity?,,"Suppose that a complex valued function $f:\mathbb{C}\to\mathbb{C}$ is complex differentiable at $z$, that is, $\lim\limits_{\Delta z \to 0}\frac{f(z+\Delta z)-f(z)}{\Delta z} = f'(z)$ exists and is finite. Suppose also that $f$ is continuous in some neighborhood of $z$ (or some open ball around $z$). Would this imply that $f$ is analytic at $z$ (or maybe in a neighborhood around it)? Can you give a counterexample? Can you think of a function that is analytic at a single isolated point?","Suppose that a complex valued function $f:\mathbb{C}\to\mathbb{C}$ is complex differentiable at $z$, that is, $\lim\limits_{\Delta z \to 0}\frac{f(z+\Delta z)-f(z)}{\Delta z} = f'(z)$ exists and is finite. Suppose also that $f$ is continuous in some neighborhood of $z$ (or some open ball around $z$). Would this imply that $f$ is analytic at $z$ (or maybe in a neighborhood around it)? Can you give a counterexample? Can you think of a function that is analytic at a single isolated point?",,['complex-analysis']
78,Why does the Riemann zeta function have zeros in the complex plane? How is it possible to find them?,Why does the Riemann zeta function have zeros in the complex plane? How is it possible to find them?,,"I ask this because, according to Euler's product formula, Riemann's zeta function =(1/something), so how could that be zero? Also, how could one find zeros that are on the negative side and find a zero in the ""critical strip"", that is, when the real part of the input is between 0 and 1?","I ask this because, according to Euler's product formula, Riemann's zeta function =(1/something), so how could that be zero? Also, how could one find zeros that are on the negative side and find a zero in the ""critical strip"", that is, when the real part of the input is between 0 and 1?",,"['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
79,Singularity of $1/(1-z)$ at $z=1$,Singularity of  at,1/(1-z) z=1,"My book claims that $1/(1-z)$ has an essential singularity at $z=1$ by writing out the Laurent series and showing that there are infinitly many terms. Why isn't this just a pole of order 1? We can write this as $-1/(z-1)$, then the numerator is a nonvanishing analytic function, and the denominator is of the form $(z-1)$, so it seems like by definition this should be a pole, and not an essential singularity. What am I missing here? If anyone is curious: the book is the Princeton Review for the GRE Math Subject Test, 4th edition, p. 312-313 Their argument is this. Consider the region $1 < |z| < \infty$ and write $f(z) = \frac{1}{1-z} = \frac{1}{z(\frac{1}{z}-1)} = -\frac{1}{z} \cdot \frac{1}{z-\frac{1}{z}}$. Then if $|z| > 1$, then $|1/z| < 1$, so we can expand $\frac{1}{1-z} = -\frac{1}{z} \cdot \frac{1}{1-\frac{1}{z}}= -\frac{1}{z} (1 + (\frac{1}{z} + \frac{1}{z}^2 + \cdots) = \frac{1}{z} - (\frac{1}{z})^2 - (\frac{1}{z})^3 - \cdots$ for $|z| > 1$. Since this has infinitely many terms in the Laurent series, $z=1$ is an essential singularity.","My book claims that $1/(1-z)$ has an essential singularity at $z=1$ by writing out the Laurent series and showing that there are infinitly many terms. Why isn't this just a pole of order 1? We can write this as $-1/(z-1)$, then the numerator is a nonvanishing analytic function, and the denominator is of the form $(z-1)$, so it seems like by definition this should be a pole, and not an essential singularity. What am I missing here? If anyone is curious: the book is the Princeton Review for the GRE Math Subject Test, 4th edition, p. 312-313 Their argument is this. Consider the region $1 < |z| < \infty$ and write $f(z) = \frac{1}{1-z} = \frac{1}{z(\frac{1}{z}-1)} = -\frac{1}{z} \cdot \frac{1}{z-\frac{1}{z}}$. Then if $|z| > 1$, then $|1/z| < 1$, so we can expand $\frac{1}{1-z} = -\frac{1}{z} \cdot \frac{1}{1-\frac{1}{z}}= -\frac{1}{z} (1 + (\frac{1}{z} + \frac{1}{z}^2 + \cdots) = \frac{1}{z} - (\frac{1}{z})^2 - (\frac{1}{z})^3 - \cdots$ for $|z| > 1$. Since this has infinitely many terms in the Laurent series, $z=1$ is an essential singularity.",,['complex-analysis']
80,Tricky steepest descent applied to an inverse Fourier transform,Tricky steepest descent applied to an inverse Fourier transform,,"I answered a question a while ago on solving a PDE, and ended up with the solution in terms of an inverse Fourier transform but left it at that. I'm curious to try and approximate it now, using the method of steepest descent. The integral is explicitly given by, $$\int_{-\infty}^\infty \frac{\mathrm dk}{2\pi} \,\underbrace{e^{ixk}}_{f(k)} \, \exp \underbrace{\left[t \left( ik-ak^2-ibk^3\right)\right]}_{t\phi(k)}$$ for $t\geq 0$ and $a,b \neq 0$. I would be interested in the behaviour as $t\to\infty$. As I understand it, the method of steepest descents is considering the integral over contours of constant $\mathrm{Im} \, \phi(k)$, and applying Watson's lemma (or the Laplace method for just the first term in the asymptotic expansion). If we take $k = x+iy$, then $\mathrm{Im}\, \phi(k) = x - bx^3-2axy + 3bxy^2 $ which we desire to be constant. I have a plot of these contours for $a = b = 1$ and $\phi = 1$ (blue) as well as $\phi = -1$ (red): Changing the sign of $b$ gives completely different contours, so I'll settle for thinking of $b > 0$ for now. Now, the integrand has no poles, so the integral over any Jordan curve must vanish. However, if I am to apply this to compute the integrals over all the contours, I still have the problem that I cannot use these to form a closed curve; they only seem to 'meet' at infinity and asymptote some line. How would one go about applying steepest descents in this case? In addition, one of the contours must be along $(-\infty, \infty)$ on the real axis, but it seems I can only 'join' with the contours at two finite points. However, in the limit $c \to \infty$ for $\mathrm{Im} \, \phi = -c$, there is a contour, since the left and right contours spread out. Any other approaches to the integral other than steepest descents is of course also appreciated.","I answered a question a while ago on solving a PDE, and ended up with the solution in terms of an inverse Fourier transform but left it at that. I'm curious to try and approximate it now, using the method of steepest descent. The integral is explicitly given by, $$\int_{-\infty}^\infty \frac{\mathrm dk}{2\pi} \,\underbrace{e^{ixk}}_{f(k)} \, \exp \underbrace{\left[t \left( ik-ak^2-ibk^3\right)\right]}_{t\phi(k)}$$ for $t\geq 0$ and $a,b \neq 0$. I would be interested in the behaviour as $t\to\infty$. As I understand it, the method of steepest descents is considering the integral over contours of constant $\mathrm{Im} \, \phi(k)$, and applying Watson's lemma (or the Laplace method for just the first term in the asymptotic expansion). If we take $k = x+iy$, then $\mathrm{Im}\, \phi(k) = x - bx^3-2axy + 3bxy^2 $ which we desire to be constant. I have a plot of these contours for $a = b = 1$ and $\phi = 1$ (blue) as well as $\phi = -1$ (red): Changing the sign of $b$ gives completely different contours, so I'll settle for thinking of $b > 0$ for now. Now, the integrand has no poles, so the integral over any Jordan curve must vanish. However, if I am to apply this to compute the integrals over all the contours, I still have the problem that I cannot use these to form a closed curve; they only seem to 'meet' at infinity and asymptote some line. How would one go about applying steepest descents in this case? In addition, one of the contours must be along $(-\infty, \infty)$ on the real axis, but it seems I can only 'join' with the contours at two finite points. However, in the limit $c \to \infty$ for $\mathrm{Im} \, \phi = -c$, there is a contour, since the left and right contours spread out. Any other approaches to the integral other than steepest descents is of course also appreciated.",,"['complex-analysis', 'asymptotics', 'fourier-transform']"
81,"Is there an analytic function $f$ on $B(0,1)$ the open ball with radius 1 such that $f(1/n)=e^{-n}$ for $n=2,3,4,...$?",Is there an analytic function  on  the open ball with radius 1 such that  for ?,"f B(0,1) f(1/n)=e^{-n} n=2,3,4,...","Is there an analytic function $f$ on $B(0,1)\subset\mathbb{C}$ such that $f(1/n)=e^{-n}$ for $n=2,3,4,...$? I know the following doesn't work: Let $g(z)=\exp(-1/z)$. Then, $f=g$ on a sequence with a limit point in $B(0,1)$ and so $f=g$ on $B(0,1)$. Since $g$ is not $\mathbb{C}$-differentiable at $0$, neither is $f$ and so such a function cannot exist. This is not the solution because you cannot use the identity principle with a non analytic function like $\exp(-1/z)$ is not analytic at $z=0$. Any help using the identity principle another way?","Is there an analytic function $f$ on $B(0,1)\subset\mathbb{C}$ such that $f(1/n)=e^{-n}$ for $n=2,3,4,...$? I know the following doesn't work: Let $g(z)=\exp(-1/z)$. Then, $f=g$ on a sequence with a limit point in $B(0,1)$ and so $f=g$ on $B(0,1)$. Since $g$ is not $\mathbb{C}$-differentiable at $0$, neither is $f$ and so such a function cannot exist. This is not the solution because you cannot use the identity principle with a non analytic function like $\exp(-1/z)$ is not analytic at $z=0$. Any help using the identity principle another way?",,['complex-analysis']
82,Motivation for the definition of modular forms,Motivation for the definition of modular forms,,"I've just started to study modular forms and I was wondering about how one would motivate the definition. I agree that $f\left( \frac{az + b}{c z + d} \right) = (cz + d)^k f(z)$ is an interesting property, although I do not quite see where it arises from. But I find the conditions that $f$ is holomorphic on $\mathbf{H}$ or that $f$ is holomorphic at the cusp a bit confusing. Why wouldn't I assert that $f$ is holomorphic on the whole complex plane? And what is the motivation for being holomorphic at the cusp?","I've just started to study modular forms and I was wondering about how one would motivate the definition. I agree that $f\left( \frac{az + b}{c z + d} \right) = (cz + d)^k f(z)$ is an interesting property, although I do not quite see where it arises from. But I find the conditions that $f$ is holomorphic on $\mathbf{H}$ or that $f$ is holomorphic at the cusp a bit confusing. Why wouldn't I assert that $f$ is holomorphic on the whole complex plane? And what is the motivation for being holomorphic at the cusp?",,"['complex-analysis', 'modular-forms']"
83,Complex Numbers and their relationship with higher Mathematics,Complex Numbers and their relationship with higher Mathematics,,"Let $z_1, z_2, \cdots, z_n$ be complex numbers satisfying $$|z_1|+|z_2|+\cdots +|z_n|=1.$$ Prove that there is a non-empty subset of $\{z_1,z_2,\cdots,z_n\}$ the sum of whose elements has modulus at least $1/4.$ It was a problem from the Chinese Mathematical Olympiad and hence it has an elementary and beautiful solution. But the author also remarked that the bound $1/4$ can actually be improved to $1/\pi$ using higher mathematics. I tried to do it myself but have failed, can anyone help? I learned basic complex analysis, thanks.","Let $z_1, z_2, \cdots, z_n$ be complex numbers satisfying $$|z_1|+|z_2|+\cdots +|z_n|=1.$$ Prove that there is a non-empty subset of $\{z_1,z_2,\cdots,z_n\}$ the sum of whose elements has modulus at least $1/4.$ It was a problem from the Chinese Mathematical Olympiad and hence it has an elementary and beautiful solution. But the author also remarked that the bound $1/4$ can actually be improved to $1/\pi$ using higher mathematics. I tried to do it myself but have failed, can anyone help? I learned basic complex analysis, thanks.",,"['complex-analysis', 'complex-numbers', 'contest-math']"
84,Cosh and Sinh analogs,Cosh and Sinh analogs,,"We know that  $$\cosh{x}+\sinh{x}=e^x$$ and that his can be expressed as $$\frac{e^x+e^{-x}}{2}+\frac{e^x-e^{-x}}{2}=\frac{(e^x+e^x)+(e^{-x}-e^{-x})}{2}=e^x$$ and this works out nicely because the $e^{-x}$ cancel.  Now consider a ""higher order"" cosh equation of the form  $$C(x)=\frac{e^{\omega^0x}+e^{\omega^1 x}+e^{\omega^2x }}{3}$$ where $\omega^k$ are the 3rd roots of unity; $\omega^k=e^{\frac{2i\pi k}{3}}$.  I would like to devise an analagous expression $$C(x)+S_1(x)+S_2(x)=e^x$$ with functions of the form $C$.  My first reaction was $$S_1=\frac{e^{\omega^0x}-2e^{\omega^1 x}+e^{\omega^2x }}{3};  S_2=\frac{e^{\omega^0x}+e^{\omega^1 x}-2e^{\omega^2x }}{3}$$ and indeed $$(C+S_1+S_2)(x)=\frac1{3}\left[(3e^{\omega^0 x})+(e^{\omega^1 x}-2e^{\omega^1 x}+e^{\omega^1 x})+(e^{\omega^2 x}+e^{\omega^2 x}-2e^{\omega^2 x})\right]=e^x$$ My intuition was that this was correct; since in the case of $\cosh$ and $\sinh$, the 2nd roots of unity correspond to $1$ and $-1$.  But my second thought was that there was no need for subtraction of $2e^{\omega^k x}$ for $k=1,2$.  Perhaps there was a way to keep all the signs positive and find an $a,b$ such that  $$e^{\omega^1 x}+e^{a\omega^1 x}+e^{b\omega^1 x}=0$$ $$e^{\omega^2 x}+e^{a\omega^2 x}+e^{b\omega^2 x}=0$$ I thought this would keep things a little more ""symmetrical"" and reduce the need for a $-2$ coefficient around the nontrivial roots of unity.  I tried some things to get values for $a,b$ but have been unsuccessful.  Should I just be happy with my original $S_1, S_2$ or are there choices for $a,b$ that would keep the symmetry?","We know that  $$\cosh{x}+\sinh{x}=e^x$$ and that his can be expressed as $$\frac{e^x+e^{-x}}{2}+\frac{e^x-e^{-x}}{2}=\frac{(e^x+e^x)+(e^{-x}-e^{-x})}{2}=e^x$$ and this works out nicely because the $e^{-x}$ cancel.  Now consider a ""higher order"" cosh equation of the form  $$C(x)=\frac{e^{\omega^0x}+e^{\omega^1 x}+e^{\omega^2x }}{3}$$ where $\omega^k$ are the 3rd roots of unity; $\omega^k=e^{\frac{2i\pi k}{3}}$.  I would like to devise an analagous expression $$C(x)+S_1(x)+S_2(x)=e^x$$ with functions of the form $C$.  My first reaction was $$S_1=\frac{e^{\omega^0x}-2e^{\omega^1 x}+e^{\omega^2x }}{3};  S_2=\frac{e^{\omega^0x}+e^{\omega^1 x}-2e^{\omega^2x }}{3}$$ and indeed $$(C+S_1+S_2)(x)=\frac1{3}\left[(3e^{\omega^0 x})+(e^{\omega^1 x}-2e^{\omega^1 x}+e^{\omega^1 x})+(e^{\omega^2 x}+e^{\omega^2 x}-2e^{\omega^2 x})\right]=e^x$$ My intuition was that this was correct; since in the case of $\cosh$ and $\sinh$, the 2nd roots of unity correspond to $1$ and $-1$.  But my second thought was that there was no need for subtraction of $2e^{\omega^k x}$ for $k=1,2$.  Perhaps there was a way to keep all the signs positive and find an $a,b$ such that  $$e^{\omega^1 x}+e^{a\omega^1 x}+e^{b\omega^1 x}=0$$ $$e^{\omega^2 x}+e^{a\omega^2 x}+e^{b\omega^2 x}=0$$ I thought this would keep things a little more ""symmetrical"" and reduce the need for a $-2$ coefficient around the nontrivial roots of unity.  I tried some things to get values for $a,b$ but have been unsuccessful.  Should I just be happy with my original $S_1, S_2$ or are there choices for $a,b$ that would keep the symmetry?",,"['complex-analysis', 'complex-numbers', 'special-functions', 'exponential-function']"
85,Calculating Inverse Laplace Transform of stretched exponential,Calculating Inverse Laplace Transform of stretched exponential,,"I am trying to solve a Laplace transform problem that has gotten way over my head in terms of complex analysis knowledge. I would like to solve the Inverse Laplace Transform $(s\rightarrow t)$ of $$\frac{1}{s^{\alpha+1}}\exp(-s^{\alpha}),\qquad \alpha\in(0,1)$$ I have tried a few things so far and have run into the limits of my knowledge. This will involve an integral of the form $$\frac{1}{2\pi i}\lim_{T\rightarrow\infty}\int_{c-iT}^{c+iT}\,ds\,\frac{1}{s^{\alpha+1}}\exp(-s^{\alpha}+st)$$ I feel like some kind of residue evaluation is the only way to approach this. Naively, to calculate the residue at $s=0$, I'd expand the exponential and look for the term proportional to $s^{-1}$ (there is only one such term), and the proportionality factor is my residue. However, I am concerned about the branching induced by the fractional power of $\alpha$, and I am not sure how to treat that in my evaluation of the residue. I also tried the substitution $u=s^{-\alpha}$, which leads to the integral $$\int_{\gamma}\,du\,\exp(-\frac{1}{u}+t(\frac{1}{u})^{1/\alpha}),$$ where the contour integral is now around the circle of radus 1/2 centered at $u=1/2$. This doesn't help much with the branching issue, and I don't know how to deal with the essential singularity at the origin--is the contour just deformed to include (or not include) this singularity? I have a bad feeling that the fractional power might make my desired integrals undefined. In that case I have tried some method of converting the Laplace transform of a function $LT[f(t)](s)$ to the Mellin transform $MT[f(t)](q)$ by the integral $$MT[f(t)](q) = \frac{1}{\Gamma(1-q)}\int_{0}^{\infty}\,ds\, s^{-q}LT[f(t)](s),$$ though I am worried about convergence issues here, too. However, it might be the only way to proceed in order to get some reasonably tractable/numerically solvable analytic expression or integral.","I am trying to solve a Laplace transform problem that has gotten way over my head in terms of complex analysis knowledge. I would like to solve the Inverse Laplace Transform $(s\rightarrow t)$ of $$\frac{1}{s^{\alpha+1}}\exp(-s^{\alpha}),\qquad \alpha\in(0,1)$$ I have tried a few things so far and have run into the limits of my knowledge. This will involve an integral of the form $$\frac{1}{2\pi i}\lim_{T\rightarrow\infty}\int_{c-iT}^{c+iT}\,ds\,\frac{1}{s^{\alpha+1}}\exp(-s^{\alpha}+st)$$ I feel like some kind of residue evaluation is the only way to approach this. Naively, to calculate the residue at $s=0$, I'd expand the exponential and look for the term proportional to $s^{-1}$ (there is only one such term), and the proportionality factor is my residue. However, I am concerned about the branching induced by the fractional power of $\alpha$, and I am not sure how to treat that in my evaluation of the residue. I also tried the substitution $u=s^{-\alpha}$, which leads to the integral $$\int_{\gamma}\,du\,\exp(-\frac{1}{u}+t(\frac{1}{u})^{1/\alpha}),$$ where the contour integral is now around the circle of radus 1/2 centered at $u=1/2$. This doesn't help much with the branching issue, and I don't know how to deal with the essential singularity at the origin--is the contour just deformed to include (or not include) this singularity? I have a bad feeling that the fractional power might make my desired integrals undefined. In that case I have tried some method of converting the Laplace transform of a function $LT[f(t)](s)$ to the Mellin transform $MT[f(t)](q)$ by the integral $$MT[f(t)](q) = \frac{1}{\Gamma(1-q)}\int_{0}^{\infty}\,ds\, s^{-q}LT[f(t)](s),$$ though I am worried about convergence issues here, too. However, it might be the only way to proceed in order to get some reasonably tractable/numerically solvable analytic expression or integral.",,"['complex-analysis', 'laplace-transform', 'contour-integration']"
86,Can $f(g(x))$ be a polynomial?,Can  be a polynomial?,f(g(x)),Let $f(x)$ and $g(x)$ be nonpolynomial real-entire functions. Is it possible that $f(g(x))$ is equal to a polynomial ? edit Some comments : I was thinking about iterations. So for instance $f(f(x)) = $ some polynomial. However such $f$ are usually (Always ?) not entire because of the fact that a non-linear polynomial has more than 1 fixpoint. This lead me to consider adding the strong condition $(f(g(x)) - g(f(x)))^2$ is not indentically $0$. But I guess that is a followup question. edit 2 Real-entire means entire and real-analytic.,Let $f(x)$ and $g(x)$ be nonpolynomial real-entire functions. Is it possible that $f(g(x))$ is equal to a polynomial ? edit Some comments : I was thinking about iterations. So for instance $f(f(x)) = $ some polynomial. However such $f$ are usually (Always ?) not entire because of the fact that a non-linear polynomial has more than 1 fixpoint. This lead me to consider adding the strong condition $(f(g(x)) - g(f(x)))^2$ is not indentically $0$. But I guess that is a followup question. edit 2 Real-entire means entire and real-analytic.,,"['complex-analysis', 'polynomials', 'taylor-expansion', 'function-and-relation-composition']"
87,The integral $\int_{|z|=2}\log\frac{z+1}{z-1}dz$,The integral,\int_{|z|=2}\log\frac{z+1}{z-1}dz,"Let $\log$ be the branch of the logarithm that extends the usual real logarithm, and consider on $D=\Bbb C\smallsetminus [-1,1]$ the function $$f(z)=\log\frac{z+1}{z-1}$$ I have to find the integral of $f$ around the circle $|z|=2$. Now, as an example, consider the integral $$\int_{|z|=2}\frac{e^{z+z^{-1}}}{1-z^2}dz$$ Using the biholomorphic mapping $B(0,1)^\times\to D$ that sends $z\to \frac 1 2(z+z^{-1})$ I got the integral $$\frac 1 2\int_\gamma \frac{e^{2z}}{1-z^2}dz$$ and $\gamma$ is a closed path inside $B(0,1)^{\times}$. This means the integral vanishes. I am trying to do something similar here. So if I take $w=\frac{z+1}{z-1}$, I get that $\frac{(w-1)^2}2=\frac{2}{(z-1)^2}$ and $dw=-2dz/(z-1)^2$, so I ultimately want to look at $$-2\int_{\gamma^{-}}\frac{ \log w}{(w-1)^2}dw$$ where $\gamma$ is a circle that passes through $1/3,3,-3/5+4/5 i$. Using the computer I got the circle is $$(x-5/3)^2+(y-5/2)^2=\frac{7225}{900}$$ Add This circle's orientation is now reversed. Even without this one sees $1$ is an interior point, so the integral should equal, by Cauchy, $4\pi i$ (not $-4\pi i$). Can anyone confirm this is correct, and/or suggest another approach?","Let $\log$ be the branch of the logarithm that extends the usual real logarithm, and consider on $D=\Bbb C\smallsetminus [-1,1]$ the function $$f(z)=\log\frac{z+1}{z-1}$$ I have to find the integral of $f$ around the circle $|z|=2$. Now, as an example, consider the integral $$\int_{|z|=2}\frac{e^{z+z^{-1}}}{1-z^2}dz$$ Using the biholomorphic mapping $B(0,1)^\times\to D$ that sends $z\to \frac 1 2(z+z^{-1})$ I got the integral $$\frac 1 2\int_\gamma \frac{e^{2z}}{1-z^2}dz$$ and $\gamma$ is a closed path inside $B(0,1)^{\times}$. This means the integral vanishes. I am trying to do something similar here. So if I take $w=\frac{z+1}{z-1}$, I get that $\frac{(w-1)^2}2=\frac{2}{(z-1)^2}$ and $dw=-2dz/(z-1)^2$, so I ultimately want to look at $$-2\int_{\gamma^{-}}\frac{ \log w}{(w-1)^2}dw$$ where $\gamma$ is a circle that passes through $1/3,3,-3/5+4/5 i$. Using the computer I got the circle is $$(x-5/3)^2+(y-5/2)^2=\frac{7225}{900}$$ Add This circle's orientation is now reversed. Even without this one sees $1$ is an interior point, so the integral should equal, by Cauchy, $4\pi i$ (not $-4\pi i$). Can anyone confirm this is correct, and/or suggest another approach?",,['complex-analysis']
88,Rank of a jet bundle of a vector bundle.,Rank of a jet bundle of a vector bundle.,,"I am trying to understand the jet bundles but currently I am stuck on the following questions: Let $\pi: E\rightarrow X$ be a smooth (holomorphic) vector bundle of rank $k$ over a smooth (complex) manifold $X$. I know that the bundle $J_k(E)$ of k-jets of $E$ has the structure of a vector bundle over $X$. I would like to know however what the rank of this vector bundle is. Is $J_k(E)$ holomorphic in the case when $(E, \pi, X)$ is holomorphic? Moreover, when $\pi: E\rightarrow X$ is a fiber bundle with structure group $G$, can we view $J_1(E)$ as the associated principal bundle $P$ associated to $E$ or am I wrong? I have seen an interpretation of $J_1(E)$ as some sort of an ""extended frame bundle"" of E in the sense that its fiber consists of the set of all pairs comprising a basis of $T_pX$   $(T^{1, 0}_pX)$ and a basis of $E_p$, $p\in X$ P.S.: I am new here and I really hope that I don't annoy the experienced audience in this forum with trivialities. I would appreciate any help or suggestions or simply good references. Thank you in advance for your competent help.","I am trying to understand the jet bundles but currently I am stuck on the following questions: Let $\pi: E\rightarrow X$ be a smooth (holomorphic) vector bundle of rank $k$ over a smooth (complex) manifold $X$. I know that the bundle $J_k(E)$ of k-jets of $E$ has the structure of a vector bundle over $X$. I would like to know however what the rank of this vector bundle is. Is $J_k(E)$ holomorphic in the case when $(E, \pi, X)$ is holomorphic? Moreover, when $\pi: E\rightarrow X$ is a fiber bundle with structure group $G$, can we view $J_1(E)$ as the associated principal bundle $P$ associated to $E$ or am I wrong? I have seen an interpretation of $J_1(E)$ as some sort of an ""extended frame bundle"" of E in the sense that its fiber consists of the set of all pairs comprising a basis of $T_pX$   $(T^{1, 0}_pX)$ and a basis of $E_p$, $p\in X$ P.S.: I am new here and I really hope that I don't annoy the experienced audience in this forum with trivialities. I would appreciate any help or suggestions or simply good references. Thank you in advance for your competent help.",,"['complex-analysis', 'ordinary-differential-equations', 'differential-geometry']"
89,Let $f$ be an analytic function such that if $|z|=\frac{1}{2}$ then $f(z)\in \mathbb{R}$. Prove that $f$ is constant.,Let  be an analytic function such that if  then . Prove that  is constant.,f |z|=\frac{1}{2} f(z)\in \mathbb{R} f,Let $f: \mathbb{D} \rightarrow \mathbb{C}$ be an analytic function such that if $|z|=\frac{1}{2}$ then $f(z)\in \mathbb{R}$. Prove that $f$ is constant. ($\mathbb{D}$ is the unit disk) Any hints are appreciated,Let $f: \mathbb{D} \rightarrow \mathbb{C}$ be an analytic function such that if $|z|=\frac{1}{2}$ then $f(z)\in \mathbb{R}$. Prove that $f$ is constant. ($\mathbb{D}$ is the unit disk) Any hints are appreciated,,['complex-analysis']
90,Characterizing holomorphic functions in  $L^2(\Bbb C^n)$,Characterizing holomorphic functions in,L^2(\Bbb C^n),"One of my homework problems this week is to ""characterize all holomorphic functions in $L^2(\Bbb C^n)$"". I'm sorry for not being able to provide much work on my progress, but that is because I really don't know where to begin. Any help would be greatly appreciated!","One of my homework problems this week is to ""characterize all holomorphic functions in $L^2(\Bbb C^n)$"". I'm sorry for not being able to provide much work on my progress, but that is because I really don't know where to begin. Any help would be greatly appreciated!",,"['complex-analysis', 'several-complex-variables']"
91,Explicit example of a non-trivial zero of Riemann zeta function,Explicit example of a non-trivial zero of Riemann zeta function,,"Assume we are given the Riemann zeta function on $\mathrm{Re}(s) > 0$ by: $$\zeta(s) = \dfrac{s}{s-1} - s\int_1^{\infty} \dfrac{\{u\}}{u^{s+1}}du$$ My question is: can you give me explicitely a real number $t>0$ such that $$\zeta(1/2 + it) = 0$$ (and providing a proof that this is exactly a zero of $\zeta$). I saw questions like Show how to calculate the Riemann zeta function for the first non-trivial zero or Proving a known zero of the Riemann Zeta has real part exactly 1/2 ,  but none of them seem to give a concrete and exact example (I don't want to have approximations, nor to use a computer). It is actually possible to have an exact value for (at least) one zero of $\zeta$ ? Maybe this is not possible, this is why I'm asking.","Assume we are given the Riemann zeta function on $\mathrm{Re}(s) > 0$ by: $$\zeta(s) = \dfrac{s}{s-1} - s\int_1^{\infty} \dfrac{\{u\}}{u^{s+1}}du$$ My question is: can you give me explicitely a real number $t>0$ such that $$\zeta(1/2 + it) = 0$$ (and providing a proof that this is exactly a zero of $\zeta$). I saw questions like Show how to calculate the Riemann zeta function for the first non-trivial zero or Proving a known zero of the Riemann Zeta has real part exactly 1/2 ,  but none of them seem to give a concrete and exact example (I don't want to have approximations, nor to use a computer). It is actually possible to have an exact value for (at least) one zero of $\zeta$ ? Maybe this is not possible, this is why I'm asking.",,"['complex-analysis', 'examples-counterexamples', 'riemann-zeta']"
92,"For which values $a, b \in \mathbb{R}$ the function $u(x,y) = ax^2+2xy+by^2$ is it the real part of a holomorphic function in $\mathbb{C}$",For which values  the function  is it the real part of a holomorphic function in,"a, b \in \mathbb{R} u(x,y) = ax^2+2xy+by^2 \mathbb{C}","For which values $a, b \in \mathbb{R}$ the function $$u(x,y) =  ax^2+2xy+by^2$$ is  the real part of a holomorphic function in   $\mathbb{C}$. I think we have to take Cauchy-Riemann theorem , but I don't know how to find these two constant from a certain function $f(x,y) = u(x,y)+i v(x,y)$. Is anyone could help me?","For which values $a, b \in \mathbb{R}$ the function $$u(x,y) =  ax^2+2xy+by^2$$ is  the real part of a holomorphic function in   $\mathbb{C}$. I think we have to take Cauchy-Riemann theorem , but I don't know how to find these two constant from a certain function $f(x,y) = u(x,y)+i v(x,y)$. Is anyone could help me?",,['complex-analysis']
93,Can the real part of an entire function be bounded above by a polynomial? [duplicate],Can the real part of an entire function be bounded above by a polynomial? [duplicate],,"This question already has an answer here : Polynomial bounded real part of an entire function (1 answer) Closed 4 years ago . Let $f:\mathbb{C}\to \mathbb{C}$ be an entire function such that $Re(f)\le |p(z)|$ for some polynomial, can we derive that $f(z)$ is a polynomial. If $p(z)$ is constant, then this can be shown by considering $e^f$. If we instead consider $|u(z)|\le |p(z)|$, then it can also be shown. But if we do not establish the lowerbound, then I cannot figure out how to generlize the proof.","This question already has an answer here : Polynomial bounded real part of an entire function (1 answer) Closed 4 years ago . Let $f:\mathbb{C}\to \mathbb{C}$ be an entire function such that $Re(f)\le |p(z)|$ for some polynomial, can we derive that $f(z)$ is a polynomial. If $p(z)$ is constant, then this can be shown by considering $e^f$. If we instead consider $|u(z)|\le |p(z)|$, then it can also be shown. But if we do not establish the lowerbound, then I cannot figure out how to generlize the proof.",,"['complex-analysis', 'harmonic-analysis']"
94,"Real-analytic function of two complex variables, holomorphic in first and anti-holo in second, which vanishes on the diagonal is identically zero.","Real-analytic function of two complex variables, holomorphic in first and anti-holo in second, which vanishes on the diagonal is identically zero.",,"The following theorem is stated as being a well-known result of the theory of several complex variables in a book I am reading (on a more or less unrelated subject): Let $f:\mathbb C^2\to\mathbb C$ be a real-analytic function such that   $f$ is holomorphic in the first variable and anti-holomorphic in the   second variable. If $f(z,z) = 0$ for all $z\in\mathbb C$, then   $f=0$ identically. 1) Can somebody point me to a reference where this is proved, or provide a proof that does not use extensive machinery of several complex variables? 2) What is the necessity of specifying real-analyticity? Is it false that holomorphicity and anti-holomorphicitiy respectively in the two variables implies real-analyticity?","The following theorem is stated as being a well-known result of the theory of several complex variables in a book I am reading (on a more or less unrelated subject): Let $f:\mathbb C^2\to\mathbb C$ be a real-analytic function such that   $f$ is holomorphic in the first variable and anti-holomorphic in the   second variable. If $f(z,z) = 0$ for all $z\in\mathbb C$, then   $f=0$ identically. 1) Can somebody point me to a reference where this is proved, or provide a proof that does not use extensive machinery of several complex variables? 2) What is the necessity of specifying real-analyticity? Is it false that holomorphicity and anti-holomorphicitiy respectively in the two variables implies real-analyticity?",,"['complex-analysis', 'several-complex-variables']"
95,Complex equation has two roots inside $|z|=1$,Complex equation has two roots inside,|z|=1,"Prove that the equation $z^3[\exp(1-z)]=1$ has exactly $2$ roots inside $|z|=1$. I have tried applying Rouche Theorem , without any result...","Prove that the equation $z^3[\exp(1-z)]=1$ has exactly $2$ roots inside $|z|=1$. I have tried applying Rouche Theorem , without any result...",,['complex-analysis']
96,"Given an entire function which is real on the real axis and imaginary on the imaginary axis, prove that it is an odd function.","Given an entire function which is real on the real axis and imaginary on the imaginary axis, prove that it is an odd function.",,"Given an entire function which is real on the real axis and imaginary on the imaginary axis, prove that it is an odd function. By a Corollary: If $f$ analytic in a region symmetric with respect to the real axis and if $f$ is real for real $z$, then $f(z) = \overline{f(\bar z)} $. So that, $f(z) = u(x+iy) + iv(x+iy) = u(x-iy) - iv(x-iy)$ $f(-z) = u(-x-iy) + iv(-x-iy) = u(-x+iy) - iv(-x+iy)$ $-f(-z) = -u(-x+iy) + iv(-x+iy)$ It looks close to the answer but what else can I do by using Schwartz reflection principle??","Given an entire function which is real on the real axis and imaginary on the imaginary axis, prove that it is an odd function. By a Corollary: If $f$ analytic in a region symmetric with respect to the real axis and if $f$ is real for real $z$, then $f(z) = \overline{f(\bar z)} $. So that, $f(z) = u(x+iy) + iv(x+iy) = u(x-iy) - iv(x-iy)$ $f(-z) = u(-x-iy) + iv(-x-iy) = u(-x+iy) - iv(-x+iy)$ $-f(-z) = -u(-x+iy) + iv(-x+iy)$ It looks close to the answer but what else can I do by using Schwartz reflection principle??",,['complex-analysis']
97,"A UCLA Qualifying Complex Analyis Problem , possibly related to Phragmén-Lindelöf Theorem","A UCLA Qualifying Complex Analyis Problem , possibly related to Phragmén-Lindelöf Theorem",,"Let $f$ be a bounded analytic function on the open right half plane such that $f(x) \to 0, x\to 0$ along the positive real axis. Suppose $0<\phi<\pi/2$. Prove that $f(z) \to 0, z \to 0$ uniformly in the sector $|\arg z|\le|\phi|$. Remark: I guess it cannot be proved just by Montel's theorem as in one of the answer.  I am reading Chapter VI GTM 11, Functions of a Complex Variable. And a corollary of Phragmén-Lindelöf Theorem (cf page 139) is similar to my question. The corollary states that Corollary Suppose f is analytic on $G=\{z:|\arg z|\le\pi/2a\}$ and there is a constant such that $\limsup_{z\to w}|f(z)|\le M$ for all $w\in \partial G$. If there are positive constants $P$ and $b<a$ such that $$|f(z)|\le P \exp(|z|^b)$$ then $|f(z)|\le M$ on $G$. The proof of the corollary is just using the Phragmén-Lindelöf Theorem with $\phi(z)=\exp(-z^c)$.","Let $f$ be a bounded analytic function on the open right half plane such that $f(x) \to 0, x\to 0$ along the positive real axis. Suppose $0<\phi<\pi/2$. Prove that $f(z) \to 0, z \to 0$ uniformly in the sector $|\arg z|\le|\phi|$. Remark: I guess it cannot be proved just by Montel's theorem as in one of the answer.  I am reading Chapter VI GTM 11, Functions of a Complex Variable. And a corollary of Phragmén-Lindelöf Theorem (cf page 139) is similar to my question. The corollary states that Corollary Suppose f is analytic on $G=\{z:|\arg z|\le\pi/2a\}$ and there is a constant such that $\limsup_{z\to w}|f(z)|\le M$ for all $w\in \partial G$. If there are positive constants $P$ and $b<a$ such that $$|f(z)|\le P \exp(|z|^b)$$ then $|f(z)|\le M$ on $G$. The proof of the corollary is just using the Phragmén-Lindelöf Theorem with $\phi(z)=\exp(-z^c)$.",,['complex-analysis']
98,"Exercise: Evaluating integration $\int_{|z|=r} \frac{1}{(z-a)(z-b)}dz$, $|a|<r<|b|$","Exercise: Evaluating integration ,",\int_{|z|=r} \frac{1}{(z-a)(z-b)}dz |a|<r<|b|,"This is an exercise from Stein-Shakarchi's Complex Analysis: evaluate integration $$\int_{|z|=r} \frac{1}{(z-a)(z-b)}dz, \,\,\,\, |a|<r<|b|. $$ The problem I am facing is the following. It is sufficient to find $\int_{|z|=r} \frac{1}{z-a}dz$ and $\int_{|z|=r} \frac{1}{z-b}dz$ (and use partial fraction methd). This exercise is in first chapter, where the author introduces the integration of $f$ over a parametrized smooth curve $\gamma$. However, I didn't find any theorem in first chapter applicble to evaluate this integration. I tried to evaluate it through parametrization $\gamma(t)=re^{it}$ for $0\leq t\leq 2\pi$. Then $$\int_{|z|=r} \frac{1}{z-a}dz=\int_0^{2\pi} \frac{rie^{it}}{re^{it}-a}dt$$. But I couldn't solve this last integration. Can you help me? I have seen that this can be solved using some Cauchy's integration formua; BUT, this is taken in second chapter of the book, whereas this exercise is in first chapter.","This is an exercise from Stein-Shakarchi's Complex Analysis: evaluate integration $$\int_{|z|=r} \frac{1}{(z-a)(z-b)}dz, \,\,\,\, |a|<r<|b|. $$ The problem I am facing is the following. It is sufficient to find $\int_{|z|=r} \frac{1}{z-a}dz$ and $\int_{|z|=r} \frac{1}{z-b}dz$ (and use partial fraction methd). This exercise is in first chapter, where the author introduces the integration of $f$ over a parametrized smooth curve $\gamma$. However, I didn't find any theorem in first chapter applicble to evaluate this integration. I tried to evaluate it through parametrization $\gamma(t)=re^{it}$ for $0\leq t\leq 2\pi$. Then $$\int_{|z|=r} \frac{1}{z-a}dz=\int_0^{2\pi} \frac{rie^{it}}{re^{it}-a}dt$$. But I couldn't solve this last integration. Can you help me? I have seen that this can be solved using some Cauchy's integration formua; BUT, this is taken in second chapter of the book, whereas this exercise is in first chapter.",,['complex-analysis']
99,Irreducibility of holomorphic functions in a neighborhood of a point,Irreducibility of holomorphic functions in a neighborhood of a point,,"Let $D \subset \mathbb C^n$ be a domain and let $f \in \mathscr O(D)$, $f \not\equiv 0$ be a holomorphic function. Define  $$     V_f = \bigl\{ z \in D : f(z) = 0 \bigr\}. $$ Let $p \in V_f$. Suppose that $f$ is irreducible in the ring of germs $\mathscr O_p$. Is it true that there exists a neighborhood $U$ of point $p$ such that $f$ is irreducible in $\mathscr O_q$ for all $q \in V_f \cap U$? Maybe I should use somehow the property that if two functions in $\mathscr O_p$ are relatively prime then they will be relatively prime in $\mathscr O_q$ for $q$ close to $p$? Update. If $f$ is reducible in $\mathscr O_q$ then $f = f_1 f_2$ in a neighborhood of $q$ with $f_1(q)=f_2(q)=0$. This implies that $f(q)=0$ and $\frac{\partial f(q)}{\partial z_k}=0$, $k=1$, $\dots$, $n$. If at point $p$ some $\frac{\partial f(p)}{\partial z_k} \neq 0$ then the statement is true. Update 2. Suppose that $f$ divides all $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$ so that we have $$    \frac{\partial f}{\partial z_k} = fh_k, \quad k =1,\ldots,n, $$ in a neighborhood of $p$ with holomorhic $h_k$, $h_k(0) = 0$. Differentiating these equalities we obtain $$    \frac{\partial^2 f}{\partial z_k \partial z_l} = \frac{\partial f}{\partial z_l} h_k + f \frac{\partial h_k}{\partial z_l}, $$ this implies $\frac{\partial^2 f(p)}{\partial z_k z_l} = 0$ for all $k$, $l$. We can continue this process showing that all derivatives of $f$ at $p$ are equal to zero so that $f \equiv 0$. The only remaining case when the statement may be false is when all $\frac{\partial f}{\partial z_k}(p)=0$ and $f$ doesn't divide some $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$.","Let $D \subset \mathbb C^n$ be a domain and let $f \in \mathscr O(D)$, $f \not\equiv 0$ be a holomorphic function. Define  $$     V_f = \bigl\{ z \in D : f(z) = 0 \bigr\}. $$ Let $p \in V_f$. Suppose that $f$ is irreducible in the ring of germs $\mathscr O_p$. Is it true that there exists a neighborhood $U$ of point $p$ such that $f$ is irreducible in $\mathscr O_q$ for all $q \in V_f \cap U$? Maybe I should use somehow the property that if two functions in $\mathscr O_p$ are relatively prime then they will be relatively prime in $\mathscr O_q$ for $q$ close to $p$? Update. If $f$ is reducible in $\mathscr O_q$ then $f = f_1 f_2$ in a neighborhood of $q$ with $f_1(q)=f_2(q)=0$. This implies that $f(q)=0$ and $\frac{\partial f(q)}{\partial z_k}=0$, $k=1$, $\dots$, $n$. If at point $p$ some $\frac{\partial f(p)}{\partial z_k} \neq 0$ then the statement is true. Update 2. Suppose that $f$ divides all $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$ so that we have $$    \frac{\partial f}{\partial z_k} = fh_k, \quad k =1,\ldots,n, $$ in a neighborhood of $p$ with holomorhic $h_k$, $h_k(0) = 0$. Differentiating these equalities we obtain $$    \frac{\partial^2 f}{\partial z_k \partial z_l} = \frac{\partial f}{\partial z_l} h_k + f \frac{\partial h_k}{\partial z_l}, $$ this implies $\frac{\partial^2 f(p)}{\partial z_k z_l} = 0$ for all $k$, $l$. We can continue this process showing that all derivatives of $f$ at $p$ are equal to zero so that $f \equiv 0$. The only remaining case when the statement may be false is when all $\frac{\partial f}{\partial z_k}(p)=0$ and $f$ doesn't divide some $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$.",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'germs']"
