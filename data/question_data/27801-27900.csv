,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Given a die, what is the probability that the second roll of a die will be less than the first roll?","Given a die, what is the probability that the second roll of a die will be less than the first roll?",,If you are given a die and asked to roll it twice. What is the probability that the value of the second roll will be less than the value of the first roll?,If you are given a die and asked to roll it twice. What is the probability that the value of the second roll will be less than the value of the first roll?,,"['probability', 'dice']"
1,Mathematician vs. Computer: A Game,Mathematician vs. Computer: A Game,,"A mathematician and a computer are playing a game: First, the mathematician chooses an integer from the range $2,...,1000$. Then, the computer chooses an integer uniformly at random from the same range. If the numbers chosen share a prime factor, the larger number wins. If they do not, the smaller number wins. (If the two numbers are the same, the game is a draw.) Which number should the mathematician choose in order to maximize his chances of winning?","A mathematician and a computer are playing a game: First, the mathematician chooses an integer from the range $2,...,1000$. Then, the computer chooses an integer uniformly at random from the same range. If the numbers chosen share a prime factor, the larger number wins. If they do not, the smaller number wins. (If the two numbers are the same, the game is a draw.) Which number should the mathematician choose in order to maximize his chances of winning?",,['probability']
2,Why do bell curves appear everywhere?,Why do bell curves appear everywhere?,,"Why do most probability graphs show a bell curve? I've been wondering why... Is it just something natural, like the fibonacci sequence?","Why do most probability graphs show a bell curve? I've been wondering why... Is it just something natural, like the fibonacci sequence?",,"['probability', 'graphing-functions']"
3,Should I put number combinations like 1111111 onto my lottery ticket?,Should I put number combinations like 1111111 onto my lottery ticket?,,"Suppose the winning combination consists of $7$ digits, each digit randomly ranging from $0$ to $9$. So the probability of $1111111$, $3141592$ and $8174249$ are the same. But $1111111$ seems (to me) far less likely to be the lucky number than $8174249$. Is my intuition simply wrong or is it correct in some sense?","Suppose the winning combination consists of $7$ digits, each digit randomly ranging from $0$ to $9$. So the probability of $1111111$, $3141592$ and $8174249$ are the same. But $1111111$ seems (to me) far less likely to be the lucky number than $8174249$. Is my intuition simply wrong or is it correct in some sense?",,"['probability', 'gambling', 'lotteries']"
4,"The ""pepperoni pizza problem""","The ""pepperoni pizza problem""",,"This problem arose in a different context at work, but I have translated it to pizza. Suppose you have a circular pizza of radius $R$. Upon this disc, $n$ pepperoni will be distributed completely randomly. All pepperoni have the same radius $r$. A pepperoni is ""free"" if it does not overlap any other pepperoni. You are free to choose $n$. Suppose you choose a small $n$. The chance that any given pepperoni is free are very large. But $n$ is small so the total number of free pepperoni is small. Suppose you choose a large $n$. The chance that any given pepperoni is free are small. But there are a lot of them. Clearly, for a given $R$ and $r$, there is some optimal $n$ that maximizes the expected number of free pepperoni. How to find this optimum? Edit: picking the answer So it looks like leonbloy's answer given the best approximation in the cases I've looked at: r/R          n* by simulation     n_free (sim)     (R/2r)^2  0.1581       12                   4.5              10  0.1          29                   10.4             25  0.01         2550                 929.7            2500 (There's only a few hundred trials in the r=0.01 sim, so 2550 might not be super accurate.) So I'm going to pick it for the answer. I'd like to thank everyone for their contributions, this has been a great learning experience. Here are a few pictures of a simulation for r/R = 0.1581, n=12: Edit after three answers posted: I wrote a little simulation. I'll paste the code below so it can be checked (edit: it's been fixed to correctly pick points randomly on a unit disc). I've looked at two three cases so far. First case, r = 0.1581, R = 1, which is roughly p = 0.1 by mzp's notation. At these parameters I got n* = 12 (free pepperoni = 4.52). Arthur's expression did not appear to be maximized here. leonbloy's answer would give 10. I also did r = 0.1, R = 1. I got n* = 29 (free pepperoni = 10.38) in this case. Arthur's expression was not maximized here and leonbloy's answer would give 25. Finally for r = 0.01 I get roughly n*=2400 as shown here: Here's my (ugly) code, now edited to properly pick random points on a disc: from __future__ import division import numpy as np # the radius of the pizza is fixed at 1 r = 0.1   # the radius of the pepperoni n_to_try = [1,5,10,20,25,27,28,29,30,31,32,33,35]  # the number of pepperoni trials = 10000# the number of trials (each trial randomly places n pepperoni)  def one_trial():     # place the pepperoni     pepperoni_coords = []     for i in range(n):         theta = np.random.rand()*np.pi*2 # a number between 0 and 2*pi         a = np.random.rand()           # a number between 0 and 1         coord_x = np.sqrt(a) * np.cos(theta) # see http://mathworld.wolfram.com/DiskPointPicking.html         coord_y = np.sqrt(a) * np.sin(theta)         pepperoni_coords.append((coord_x, coord_y))      # how many pepperoni are free?     num_free_pepperoni = 0     for i in range(n): # for each pepperoni         pepperoni_coords_copy = pepperoni_coords[:]  # copy the list so the orig is not changed         this_pepperoni = pepperoni_coords_copy.pop(i)          coord_x_1 = this_pepperoni[0]         coord_y_1 = this_pepperoni[1]         this_pepperoni_free = True         for pep in pepperoni_coords_copy: # check it against every other pepperoni             coord_x_2 = pep[0]             coord_y_2 = pep[1]             distance = np.sqrt((coord_x_1 - coord_x_2)**2 + (coord_y_1 - coord_y_2)**2)             if distance < 2*r:                 this_pepperoni_free = False                 break         if this_pepperoni_free:             num_free_pepperoni += 1      return num_free_pepperoni  for n in n_to_try:     results = []     for i in range(trials):         results.append(one_trial())     x = np.average(results)     print ""For pizza radius 1, pepperoni radius"", r, "", and number of pepperoni"", n, "":""     print ""Over"", trials, ""trials, the average number of free pepperoni was"", x     print ""Arthur's quantity:"", x* ((((1-r)/1)**(x-1) - (r/1)) / ((1-r) / 1))","This problem arose in a different context at work, but I have translated it to pizza. Suppose you have a circular pizza of radius $R$. Upon this disc, $n$ pepperoni will be distributed completely randomly. All pepperoni have the same radius $r$. A pepperoni is ""free"" if it does not overlap any other pepperoni. You are free to choose $n$. Suppose you choose a small $n$. The chance that any given pepperoni is free are very large. But $n$ is small so the total number of free pepperoni is small. Suppose you choose a large $n$. The chance that any given pepperoni is free are small. But there are a lot of them. Clearly, for a given $R$ and $r$, there is some optimal $n$ that maximizes the expected number of free pepperoni. How to find this optimum? Edit: picking the answer So it looks like leonbloy's answer given the best approximation in the cases I've looked at: r/R          n* by simulation     n_free (sim)     (R/2r)^2  0.1581       12                   4.5              10  0.1          29                   10.4             25  0.01         2550                 929.7            2500 (There's only a few hundred trials in the r=0.01 sim, so 2550 might not be super accurate.) So I'm going to pick it for the answer. I'd like to thank everyone for their contributions, this has been a great learning experience. Here are a few pictures of a simulation for r/R = 0.1581, n=12: Edit after three answers posted: I wrote a little simulation. I'll paste the code below so it can be checked (edit: it's been fixed to correctly pick points randomly on a unit disc). I've looked at two three cases so far. First case, r = 0.1581, R = 1, which is roughly p = 0.1 by mzp's notation. At these parameters I got n* = 12 (free pepperoni = 4.52). Arthur's expression did not appear to be maximized here. leonbloy's answer would give 10. I also did r = 0.1, R = 1. I got n* = 29 (free pepperoni = 10.38) in this case. Arthur's expression was not maximized here and leonbloy's answer would give 25. Finally for r = 0.01 I get roughly n*=2400 as shown here: Here's my (ugly) code, now edited to properly pick random points on a disc: from __future__ import division import numpy as np # the radius of the pizza is fixed at 1 r = 0.1   # the radius of the pepperoni n_to_try = [1,5,10,20,25,27,28,29,30,31,32,33,35]  # the number of pepperoni trials = 10000# the number of trials (each trial randomly places n pepperoni)  def one_trial():     # place the pepperoni     pepperoni_coords = []     for i in range(n):         theta = np.random.rand()*np.pi*2 # a number between 0 and 2*pi         a = np.random.rand()           # a number between 0 and 1         coord_x = np.sqrt(a) * np.cos(theta) # see http://mathworld.wolfram.com/DiskPointPicking.html         coord_y = np.sqrt(a) * np.sin(theta)         pepperoni_coords.append((coord_x, coord_y))      # how many pepperoni are free?     num_free_pepperoni = 0     for i in range(n): # for each pepperoni         pepperoni_coords_copy = pepperoni_coords[:]  # copy the list so the orig is not changed         this_pepperoni = pepperoni_coords_copy.pop(i)          coord_x_1 = this_pepperoni[0]         coord_y_1 = this_pepperoni[1]         this_pepperoni_free = True         for pep in pepperoni_coords_copy: # check it against every other pepperoni             coord_x_2 = pep[0]             coord_y_2 = pep[1]             distance = np.sqrt((coord_x_1 - coord_x_2)**2 + (coord_y_1 - coord_y_2)**2)             if distance < 2*r:                 this_pepperoni_free = False                 break         if this_pepperoni_free:             num_free_pepperoni += 1      return num_free_pepperoni  for n in n_to_try:     results = []     for i in range(trials):         results.append(one_trial())     x = np.average(results)     print ""For pizza radius 1, pepperoni radius"", r, "", and number of pepperoni"", n, "":""     print ""Over"", trials, ""trials, the average number of free pepperoni was"", x     print ""Arthur's quantity:"", x* ((((1-r)/1)**(x-1) - (r/1)) / ((1-r) / 1))",,"['probability', 'optimization', 'circles', 'geometric-probability']"
5,"I roll a die repeatedly until I get 6, and then count the number of 3s I got. What's my expected number of 3s?","I roll a die repeatedly until I get 6, and then count the number of 3s I got. What's my expected number of 3s?",,"Consider the following experiment. I roll a die repeatedly until the die returns 6, then I count the number of times 3 appeared in the random variable $X$. What is $E[X]$? Thoughts: I expect to roll the die 6 times before 6 appears (this part is geometric), and on the preceding 5 rolls each roll has a $1/5$ chance of returning a 3. Treating this as binomial, I therefore expect to count 3 once, so $E[X]=1$. Problem: Don't know how to model this problem mathematically. Hints would be appreciated.","Consider the following experiment. I roll a die repeatedly until the die returns 6, then I count the number of times 3 appeared in the random variable $X$. What is $E[X]$? Thoughts: I expect to roll the die 6 times before 6 appears (this part is geometric), and on the preceding 5 rolls each roll has a $1/5$ chance of returning a 3. Treating this as binomial, I therefore expect to count 3 once, so $E[X]=1$. Problem: Don't know how to model this problem mathematically. Hints would be appreciated.",,"['probability', 'expectation']"
6,Intuition behind using complementary CDF to compute expectation for nonnegative random variables,Intuition behind using complementary CDF to compute expectation for nonnegative random variables,,"I've read the proof for why $\int_0^\infty P(X >x)dx=E[X]$ for nonnegative random variables (located here ) and understand its mechanics, but I'm having trouble understanding the intuition behind this formula or why it should be the case at all. Does anyone have any insight on this? I bet I'm missing something obvious.","I've read the proof for why for nonnegative random variables (located here ) and understand its mechanics, but I'm having trouble understanding the intuition behind this formula or why it should be the case at all. Does anyone have any insight on this? I bet I'm missing something obvious.",\int_0^\infty P(X >x)dx=E[X],"['probability', 'statistics', 'expected-value']"
7,Would you ever stop rolling the die? [duplicate],Would you ever stop rolling the die? [duplicate],,"This question already has an answer here : Toss a fair die until the cumulative sum is a perfect square-Expected Value (1 answer) Closed 9 years ago . You have a six-sided die. You keep a cumulative total of your dice rolls. (E.g. if you roll a 3, then a 5, then a 2, your cumulative total is 10.) If your cumulative total is ever equal to a perfect square, then you lose, and you go home with nothing. Otherwise, you can choose to go home with a payout of your cumulative total, or to roll the die again. My question is about the optimal strategy for this game. In particular, this means that I am looking for an answer to this question: if my cumulative total is $n$, do I choose to roll or not to roll in order to maximize my cumulative total? Is there some integer $N$ after which the answer to this question is always to roll? I think that there is such an integer, and I conjecture that this integer is $4$. My reasoning is that the square numbers become sufficiently sparse for the expected value to always be in increased by rolling the die again. As an example, suppose your cumulative total is $35$. Rolling a $1$ and hitting 36 means we go home with nothing, so the expected value of rolling once is: $$E(Roll|35) = \frac 0 6 + \frac {37} 6 + \frac {38} 6 + \frac{39} 6 + \frac {40} {6} + \frac{41}{6} = 32.5$$ i.e. $$E(Roll|35) = \frac 1 6 \cdot (37 + 38 + 39 + 40 + 41) = 32.5$$ But the next square after $35$ is $49$. So in the event that we don't roll a $36$, we get to keep rolling the die at no risk as long as the cumulative total is less than $42$. For the sake of simplification, let's say that if we roll and don't hit $36$, then we will roll once more. That die-roll has an expected value of $3.5$. This means the expected value of rolling on $35$ is: $$E(Roll|35) = \frac 1 6 \cdot (40.5 + 41.5 + 42.5 + 43.5 + 44.5) = 35.42$$ And since $35.42 > 35$, the profit-maximizing choice is to roll again. And this strategy can be applied for every total. I don't see when this would cease to be the reasonable move, though I haven't attempted to verify it computationally. I intuitively think about this in terms of diverging sequences. I recently had this question in a job interview, and thought it was quite interesting. (And counter-intuitive, since this profit-maximizing strategy invariably results in going home with nothing.)","This question already has an answer here : Toss a fair die until the cumulative sum is a perfect square-Expected Value (1 answer) Closed 9 years ago . You have a six-sided die. You keep a cumulative total of your dice rolls. (E.g. if you roll a 3, then a 5, then a 2, your cumulative total is 10.) If your cumulative total is ever equal to a perfect square, then you lose, and you go home with nothing. Otherwise, you can choose to go home with a payout of your cumulative total, or to roll the die again. My question is about the optimal strategy for this game. In particular, this means that I am looking for an answer to this question: if my cumulative total is $n$, do I choose to roll or not to roll in order to maximize my cumulative total? Is there some integer $N$ after which the answer to this question is always to roll? I think that there is such an integer, and I conjecture that this integer is $4$. My reasoning is that the square numbers become sufficiently sparse for the expected value to always be in increased by rolling the die again. As an example, suppose your cumulative total is $35$. Rolling a $1$ and hitting 36 means we go home with nothing, so the expected value of rolling once is: $$E(Roll|35) = \frac 0 6 + \frac {37} 6 + \frac {38} 6 + \frac{39} 6 + \frac {40} {6} + \frac{41}{6} = 32.5$$ i.e. $$E(Roll|35) = \frac 1 6 \cdot (37 + 38 + 39 + 40 + 41) = 32.5$$ But the next square after $35$ is $49$. So in the event that we don't roll a $36$, we get to keep rolling the die at no risk as long as the cumulative total is less than $42$. For the sake of simplification, let's say that if we roll and don't hit $36$, then we will roll once more. That die-roll has an expected value of $3.5$. This means the expected value of rolling on $35$ is: $$E(Roll|35) = \frac 1 6 \cdot (40.5 + 41.5 + 42.5 + 43.5 + 44.5) = 35.42$$ And since $35.42 > 35$, the profit-maximizing choice is to roll again. And this strategy can be applied for every total. I don't see when this would cease to be the reasonable move, though I haven't attempted to verify it computationally. I intuitively think about this in terms of diverging sequences. I recently had this question in a job interview, and thought it was quite interesting. (And counter-intuitive, since this profit-maximizing strategy invariably results in going home with nothing.)",,"['probability', 'discrete-mathematics', 'expectation', 'gambling']"
8,Expected number of unpecked chicks - NYT article,Expected number of unpecked chicks - NYT article,,"In this article , the winner of the math competition answered this question correctly: In a barn, 100 chicks sit peacefully in a circle. Suddenly, each chick randomly pecks the chick immediately to its left or right. What is the expected number of unpecked chicks? The answer was given as 25. I am interested to know the correct method for solving this problem as well as a general way to find this out for N chicks. I was thinking of trying to solve by figuring out the number of occurrences of (something?) inside a binary string of length 100 (or N), but I don't know if that is the right way to approach it.","In this article , the winner of the math competition answered this question correctly: In a barn, 100 chicks sit peacefully in a circle. Suddenly, each chick randomly pecks the chick immediately to its left or right. What is the expected number of unpecked chicks? The answer was given as 25. I am interested to know the correct method for solving this problem as well as a general way to find this out for N chicks. I was thinking of trying to solve by figuring out the number of occurrences of (something?) inside a binary string of length 100 (or N), but I don't know if that is the right way to approach it.",,"['probability', 'expectation']"
9,Rigorous nature of combinatorics,Rigorous nature of combinatorics,,"Context: I'm a high school student, who has only ever had an introductory treatment, if that, on combinatorics. As such, the extent to which I have seen combinatoric applications is limited to situations such as ""If you need a group of 2 men and 3 women and you have 8 men and 9 women, how many possible ways can you pick the group"" (They do get slightly more complicated, but are usually similar). Question: I apologise in advance for the naive question, but at an elementary level it seems as though combinatorics (and the ensuing probability that can make use of it), seems not overly rigorous. It doesn't seem as though you can ""prove"" that the number of arrangements you deemed is the correct number. What if you forget a case? I know that you could argue that you've considered all cases, by asking if there is another case other than the ones you've considered. But, that  doesn't seem to be the way other areas of mathematics is done. If I wish to prove something, I couldn't just say ""can you find a situation where the statement is incorrect"" as we don't just assume it is correct by nature. Is combinatorics rigorous? Thanks","Context: I'm a high school student, who has only ever had an introductory treatment, if that, on combinatorics. As such, the extent to which I have seen combinatoric applications is limited to situations such as ""If you need a group of 2 men and 3 women and you have 8 men and 9 women, how many possible ways can you pick the group"" (They do get slightly more complicated, but are usually similar). Question: I apologise in advance for the naive question, but at an elementary level it seems as though combinatorics (and the ensuing probability that can make use of it), seems not overly rigorous. It doesn't seem as though you can ""prove"" that the number of arrangements you deemed is the correct number. What if you forget a case? I know that you could argue that you've considered all cases, by asking if there is another case other than the ones you've considered. But, that  doesn't seem to be the way other areas of mathematics is done. If I wish to prove something, I couldn't just say ""can you find a situation where the statement is incorrect"" as we don't just assume it is correct by nature. Is combinatorics rigorous? Thanks",,"['probability', 'combinatorics']"
10,Understanding Borel sets,Understanding Borel sets,,"I'm studying Probability theory, but I can't fully understand what are Borel sets. In my understanding, an example would be if we have a line segment [0, 1], then a Borel set on this interval is a set of all intervals in [0, 1]. Am I wrong? I just need more examples. Also I want to understand what is Borel $\sigma$-algebra.","I'm studying Probability theory, but I can't fully understand what are Borel sets. In my understanding, an example would be if we have a line segment [0, 1], then a Borel set on this interval is a set of all intervals in [0, 1]. Am I wrong? I just need more examples. Also I want to understand what is Borel $\sigma$-algebra.",,"['probability', 'measure-theory']"
11,The Monty Hall problem,The Monty Hall problem,,"I was watching the movie $21$ yesterday, and in the first 15 minutes or so the main character is in a classroom, being asked a ""trick"" question (in the sense that the teacher believes that he'll get the wrong answer) which revolves around theoretical probability. The question goes a little something like this (I'm paraphrasing, but the numbers are all exact): You're on a game show, and you're given three doors. Behind one of the doors is a brand new car, behind the other two are donkeys. With each door you have a $1/3$ chance of winning. Which door would you pick? The character picks A, as the odds are all equally in his favor. The teacher then opens door C, revealing a donkey to be behind there, and asks him if he would like to change his choice. At this point he also explains that most people change their choices out of fear; paranoia; emotion and such. The character does change his answer to B, but because (according to the movie), the odds are now in favor of door B with a $1/3$ chance of winning if door A is picked and $2/3$ if door B is picked. What I don't understand is how removing the final door increases the odds of winning if door B is picked only. Surely the split should be 50/50 now, as removal of the final door tells you nothing about the first two? I assume that I'm wrong; as I'd really like to think that they wouldn't make a movie that's so mathematically incorrect, but I just can't seem to understand why this is the case. So, if anyone could tell me whether I'm right; or if not explain why, I would be extremely grateful.","I was watching the movie yesterday, and in the first 15 minutes or so the main character is in a classroom, being asked a ""trick"" question (in the sense that the teacher believes that he'll get the wrong answer) which revolves around theoretical probability. The question goes a little something like this (I'm paraphrasing, but the numbers are all exact): You're on a game show, and you're given three doors. Behind one of the doors is a brand new car, behind the other two are donkeys. With each door you have a chance of winning. Which door would you pick? The character picks A, as the odds are all equally in his favor. The teacher then opens door C, revealing a donkey to be behind there, and asks him if he would like to change his choice. At this point he also explains that most people change their choices out of fear; paranoia; emotion and such. The character does change his answer to B, but because (according to the movie), the odds are now in favor of door B with a chance of winning if door A is picked and if door B is picked. What I don't understand is how removing the final door increases the odds of winning if door B is picked only. Surely the split should be 50/50 now, as removal of the final door tells you nothing about the first two? I assume that I'm wrong; as I'd really like to think that they wouldn't make a movie that's so mathematically incorrect, but I just can't seem to understand why this is the case. So, if anyone could tell me whether I'm right; or if not explain why, I would be extremely grateful.",21 1/3 1/3 2/3,"['probability', 'probability-theory', 'monty-hall', 'popular-math']"
12,Choose a random number between $0$ and $1$ and record its value. Keep doing it until the sum of the numbers exceeds $1$. How many tries do we need?,Choose a random number between  and  and record its value. Keep doing it until the sum of the numbers exceeds . How many tries do we need?,0 1 1,Choose a random number between $0$ and $1$ and record its value. Do this again and add the second number to the first number. Keep doing this until the sum of the numbers exceeds $1$. What's the expected value of the number of random numbers needed to accomplish this?,Choose a random number between $0$ and $1$ and record its value. Do this again and add the second number to the first number. Keep doing this until the sum of the numbers exceeds $1$. What's the expected value of the number of random numbers needed to accomplish this?,,"['probability', 'probability-theory', 'expectation']"
13,"Poisson Distribution of sum of two random independent variables $X$, $Y$","Poisson Distribution of sum of two random independent variables ,",X Y,$X \sim \mathcal{P}( \lambda) $ and $Y \sim \mathcal{P}( \mu)$ meaning that $X$ and $Y$ are Poisson distributions. What is the probability distribution law of $X + Y$. I know it is $X+Y \sim \mathcal{P}( \lambda + \mu)$ but I don't understand how to derive it.,$X \sim \mathcal{P}( \lambda) $ and $Y \sim \mathcal{P}( \mu)$ meaning that $X$ and $Y$ are Poisson distributions. What is the probability distribution law of $X + Y$. I know it is $X+Y \sim \mathcal{P}( \lambda + \mu)$ but I don't understand how to derive it.,,['probability']
14,"Product of two Gaussian PDFs is a Gaussian PDF, but Product of two Gaussian Variables is not Gaussian","Product of two Gaussian PDFs is a Gaussian PDF, but Product of two Gaussian Variables is not Gaussian",,"The Product of Two Gaussian Random Variables is not Gaussian distributed: Is the product of two Gaussian random variables also a Gaussian? Also Wolfram Mathworld So this is saying $X \sim N(\mu_1, \sigma_1^2)$ , $Y \sim N(\mu_2, \sigma_2^2)$ then $XY \sim W$ where W is some other distribution, that is not Gaussian But the product of two Gaussian PDFs is a Gaussian PDF: Calculate the product of two Gaussian PDF's Full Proof This tutorial which I am trying to understand Writes: $N(\mu_1, \sigma_1^2)\times N(\mu_2, \sigma_2^2) = N(\frac{\sigma_1^2 \mu_2 + \sigma_2^2 \mu_1}{\sigma_1^2 + \sigma_2^2},\frac{1}{\frac{1}{\sigma_1^2} + \frac{1}{\sigma_2^2}})$ What is going on here? What am I doing when I take the product of two pdfs vs. when I take the product of two variables from the pdfs? When (what physical situation) is described by one, and what by the other? (I think a few real world examples would clear things up for me)","The Product of Two Gaussian Random Variables is not Gaussian distributed: Is the product of two Gaussian random variables also a Gaussian? Also Wolfram Mathworld So this is saying , then where W is some other distribution, that is not Gaussian But the product of two Gaussian PDFs is a Gaussian PDF: Calculate the product of two Gaussian PDF's Full Proof This tutorial which I am trying to understand Writes: What is going on here? What am I doing when I take the product of two pdfs vs. when I take the product of two variables from the pdfs? When (what physical situation) is described by one, and what by the other? (I think a few real world examples would clear things up for me)","X \sim N(\mu_1, \sigma_1^2) Y \sim N(\mu_2, \sigma_2^2) XY \sim W N(\mu_1, \sigma_1^2)\times N(\mu_2, \sigma_2^2) = N(\frac{\sigma_1^2 \mu_2 + \sigma_2^2 \mu_1}{\sigma_1^2 + \sigma_2^2},\frac{1}{\frac{1}{\sigma_1^2} + \frac{1}{\sigma_2^2}})","['probability', 'intuition']"
15,How to generate a random number between 1 and 10 with a six-sided die?,How to generate a random number between 1 and 10 with a six-sided die?,,"Just for fun, I am trying to find a good method to generate a random number between 1 and 10 (uniformly) with an unbiased six-sided die. I found a way, but it may requires a lot of steps before getting the number, so I was wondering if there are more efficient methods. My method: Throw the die and call the result $n$. If $1\leq n\leq 3$ your number will be between $1$ and $5$ and if $4\leq n\leq 6$ your number will be between $6$ and $10$. Hence, we reduced to the problem of generating a random number between $1$ and $5$. Now, to get a number between $1$ and $5$, throw the die five times. If the $i$th throw got the largest result, take your number to be $i$. If there is no largest result, start again until there is. The problem is that although the probability that there will eventually be a largest result is $1$, it might take a while before getting it. Is there a more efficient way that requires only some fixed number of steps? Edit: Or if not possible, a method with a smaller expected number of rolls?","Just for fun, I am trying to find a good method to generate a random number between 1 and 10 (uniformly) with an unbiased six-sided die. I found a way, but it may requires a lot of steps before getting the number, so I was wondering if there are more efficient methods. My method: Throw the die and call the result $n$. If $1\leq n\leq 3$ your number will be between $1$ and $5$ and if $4\leq n\leq 6$ your number will be between $6$ and $10$. Hence, we reduced to the problem of generating a random number between $1$ and $5$. Now, to get a number between $1$ and $5$, throw the die five times. If the $i$th throw got the largest result, take your number to be $i$. If there is no largest result, start again until there is. The problem is that although the probability that there will eventually be a largest result is $1$, it might take a while before getting it. Is there a more efficient way that requires only some fixed number of steps? Edit: Or if not possible, a method with a smaller expected number of rolls?",,['probability']
16,Why did my friend lose all his money?,Why did my friend lose all his money?,,"Not sure if this is a question for math.se or stats.se, but here we go: Our MUD (Multi-User-Dungeon, a sort of textbased world of warcraft) has a casino where players can play a simple roulette. My friend has devised this algorithm, which he himself calls genius: Bet 1 gold If you win, bet 1 gold again If you lose, bet double what you bet before. Continue doubling until you win. He claimed you will always win exactly 1 gold using this system, since even if you lose say 8 times, you lost 1+2+4+8+16+32+64+128 gold, but then won 256 gold, which still makes you win 1 gold. He programmed this algorithm in his favorite MUD client, let it run for the night. When he woke up the morning, he was broke. Why did he lose? What is the fault in his reasoning?","Not sure if this is a question for math.se or stats.se, but here we go: Our MUD (Multi-User-Dungeon, a sort of textbased world of warcraft) has a casino where players can play a simple roulette. My friend has devised this algorithm, which he himself calls genius: Bet 1 gold If you win, bet 1 gold again If you lose, bet double what you bet before. Continue doubling until you win. He claimed you will always win exactly 1 gold using this system, since even if you lose say 8 times, you lost 1+2+4+8+16+32+64+128 gold, but then won 256 gold, which still makes you win 1 gold. He programmed this algorithm in his favorite MUD client, let it run for the night. When he woke up the morning, he was broke. Why did he lose? What is the fault in his reasoning?",,"['probability', 'stochastic-processes', 'martingales']"
17,"Distinguishing probability measure, function and distribution","Distinguishing probability measure, function and distribution",,I have a bit trouble distinguishing the following concepts: probability measure probability function (with special cases probability mass function and probability density function ) probability distribution Are some of these interchangeable? Which of these are defined with respect to probability spaces and which with respect to random variables?,I have a bit trouble distinguishing the following concepts: probability measure probability function (with special cases probability mass function and probability density function ) probability distribution Are some of these interchangeable? Which of these are defined with respect to probability spaces and which with respect to random variables?,,"['probability', 'probability-theory', 'probability-distributions']"
18,What do $\pi$ and $e$ stand for in the normal distribution formula?,What do  and  stand for in the normal distribution formula?,\pi e,"I'm a beginner in mathematics and there is one thing that I've been wondering about recently. The formula for the normal distribution is: $$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\displaystyle{\frac{(x-\mu)^2}{2\sigma^2}}},$$ However, what are $e$ and $\pi$ doing there? $\pi$ is about circles and the ratio to its diameter, for example. $e$ is mostly about exponential functions, specifically about the fact that $\frac{\mathrm{d}}{\mathrm{d}x} e^x = e^x$. It is my firm conviction that proofs and articles are available, but could someone perhaps  shed some light on this and please explain in a more 'informal' language what they stand for here? I'm very curious to know as those numbers have very different meanings as far as I'm concerned.","I'm a beginner in mathematics and there is one thing that I've been wondering about recently. The formula for the normal distribution is: $$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\displaystyle{\frac{(x-\mu)^2}{2\sigma^2}}},$$ However, what are $e$ and $\pi$ doing there? $\pi$ is about circles and the ratio to its diameter, for example. $e$ is mostly about exponential functions, specifically about the fact that $\frac{\mathrm{d}}{\mathrm{d}x} e^x = e^x$. It is my firm conviction that proofs and articles are available, but could someone perhaps  shed some light on this and please explain in a more 'informal' language what they stand for here? I'm very curious to know as those numbers have very different meanings as far as I'm concerned.",,"['probability', 'probability-distributions', 'normal-distribution', 'pi']"
19,Drunk man with a set of keys.,Drunk man with a set of keys.,,"I found this problem in a contest of years ago, but I'm not very good at probability, so I prefer to see how you do it: A man gets drunk half of the days of a month. To open his house, he has a set of keys with $5$ keys that are all very similar, and only one key lets him enter his house. Even when he arrives sober he doesn't know which key is the correct one, so he tries them one by one until he chooses the correct key. When he's drunk, he also tries the keys one by one, but he can't distinguish which keys he has tried before, so he may repeat the same key. One day we saw that he opened the door on his third try. What is the probability that he was drunk that day?","I found this problem in a contest of years ago, but I'm not very good at probability, so I prefer to see how you do it: A man gets drunk half of the days of a month. To open his house, he has a set of keys with keys that are all very similar, and only one key lets him enter his house. Even when he arrives sober he doesn't know which key is the correct one, so he tries them one by one until he chooses the correct key. When he's drunk, he also tries the keys one by one, but he can't distinguish which keys he has tried before, so he may repeat the same key. One day we saw that he opened the door on his third try. What is the probability that he was drunk that day?",5,"['probability', 'contest-math']"
20,What is the chance to get a parking ticket in half an hour if the chance to get a ticket is 80% in 1 hour?,What is the chance to get a parking ticket in half an hour if the chance to get a ticket is 80% in 1 hour?,,"This sounds more like a brain teaser, but I had some kink to think it through :( Suppose you're parking at a non-parking zone, the probability to get a parking ticket is 80% in 1 hour, what is the probability to get a ticket in half an hour? Please show how you deduce the answer. Thanks!","This sounds more like a brain teaser, but I had some kink to think it through :( Suppose you're parking at a non-parking zone, the probability to get a parking ticket is 80% in 1 hour, what is the probability to get a ticket in half an hour? Please show how you deduce the answer. Thanks!",,['probability']
21,Probability of 3 people in a room of 30 having the same birthday,Probability of 3 people in a room of 30 having the same birthday,,I have been looking at the birthday problem (http://en.wikipedia.org/wiki/Birthday_problem) and I am trying to figure out what the probability of 3 people sharing a birthday in a room of 30 people is. (Instead of 2). I thought I understood the problem but I guess not since I have no idea how to do it with 3.,I have been looking at the birthday problem (http://en.wikipedia.org/wiki/Birthday_problem) and I am trying to figure out what the probability of 3 people sharing a birthday in a room of 30 people is. (Instead of 2). I thought I understood the problem but I guess not since I have no idea how to do it with 3.,,"['probability', 'birthday']"
22,Numerical phenomenon. Who can explain?,Numerical phenomenon. Who can explain?,,"I was doing some software engineering and wanted to have a thread do something in the background to basically just waste CPU time for a certain test. While I could have done something really boring like for(i < 10000000) { j = 2 * i } , I ended up having the program start with $1$ , and then for a million steps choose a random real number $r$ in the interval $[0,R]$ (uniformly distributed) and multiply the result by $r$ at each step. When $R = 2$ , it converged to $0$ . When $R = 3$ , it exploded to infinity. So of course, the question anyone with a modicum of curiosity would ask: for what $R$ do we have the transition. And then, I tried the first number between $2$ and $3$ that we would all think of, Euler's number $e$ , and sure enough, this conjecture was right. Would love to see a proof of this. Now when I should be working, I'm instead wondering about the behavior of this script. Ironically, rather than wasting my CPUs time, I'm wasting my own time. But it's a beautiful phenomenon. I don't regret it. $\ddot\smile$","I was doing some software engineering and wanted to have a thread do something in the background to basically just waste CPU time for a certain test. While I could have done something really boring like for(i < 10000000) { j = 2 * i } , I ended up having the program start with , and then for a million steps choose a random real number in the interval (uniformly distributed) and multiply the result by at each step. When , it converged to . When , it exploded to infinity. So of course, the question anyone with a modicum of curiosity would ask: for what do we have the transition. And then, I tried the first number between and that we would all think of, Euler's number , and sure enough, this conjecture was right. Would love to see a proof of this. Now when I should be working, I'm instead wondering about the behavior of this script. Ironically, rather than wasting my CPUs time, I'm wasting my own time. But it's a beautiful phenomenon. I don't regret it.","1 r [0,R] r R = 2 0 R = 3 R 2 3 e \ddot\smile","['probability', 'stochastic-processes']"
23,Mathematical research of Pokémon,Mathematical research of Pokémon,,"In competitive Pokémon-play, two players pick a team of six Pokémon out of the 718 available. These are picked independently, that is, player $A$ is unaware of player $B$'s choice of Pokémon. Some online servers let the players see the opponents team before the match, allowing the player to change the order of its Pokémon. (Only the first matters, as this is the one that will be sent into the match first. After that, the players may switch between the chosen six freely, as explained below.) Each Pokémon is assigned four moves out of a list of moves that may or may not be unique for that Pokémon. There are currently 609 moves in the move-pool. Each move is assigned a certain type, and may be more or less effective against Pokémon of certain types. However, a Pokémon may have more than one type. In general, move effectiveness is given by $0.5\times$, $1\times$ and $2\times$. However, there are exceptions to this rule. Ferrothorn, a dual-type Pokémon of steel and grass, will take $4\times$ damage against fire moves, since both of its types are weak against fire. All moves have a certain probability that it will work. In addition, there are moves with other effects than direct damage. For instance, a move may increase one's attack, decrease your opponent's attack, or add a status deficiency on your opponent's Pokémon, such as making it fall asleep. This will make the Pokémon unable to move with a relatively high probability. If it is able to move, the status of ""asleep"" is lifted. Furthermore, each Pokémon has a ""Nature"" which increases one stat (out of Attack, Defense, Special Attack, Special Defense, Speed), while decreases another. While no longer necessary for my argument, one could go even deeper with things such as IV's and EV's for each Pokémon, which also affects its stats. A player has won when all of its opponents Pokémon are out of play. A player may change the active Pokémon freely. (That is, the ""battles"" are 1v1, but the Pokémon may be changed freely.) Has there been any serious mathematical research towards competitive Pokémon play? In particular, has there been proved that there is always a best strategy? What about the number of possible ""positions""? If there always is a best strategy, can one evaluate the likelihood of one team beating the other, given best play from both sides? (As is done with chess engines today, given a certain position.) EDIT: For the sake of simplicity, I think it is a good idea to consider two positions equal when 1) Both positions have identical teams in terms of Pokémon. (Natures, IVs, EVs and stats are omitted.) As such, one can create a one-to-one correspondence between the set of $12$ Pokémon in position $A$ and the $12$ in position $B$ by mapping $a_A \mapsto a_B$, where $a_A$ is Pokémon $a$ in position $A$. 2) $a_A$ and $a_B$ have the same moves for all $a\in A, B$.","In competitive Pokémon-play, two players pick a team of six Pokémon out of the 718 available. These are picked independently, that is, player $A$ is unaware of player $B$'s choice of Pokémon. Some online servers let the players see the opponents team before the match, allowing the player to change the order of its Pokémon. (Only the first matters, as this is the one that will be sent into the match first. After that, the players may switch between the chosen six freely, as explained below.) Each Pokémon is assigned four moves out of a list of moves that may or may not be unique for that Pokémon. There are currently 609 moves in the move-pool. Each move is assigned a certain type, and may be more or less effective against Pokémon of certain types. However, a Pokémon may have more than one type. In general, move effectiveness is given by $0.5\times$, $1\times$ and $2\times$. However, there are exceptions to this rule. Ferrothorn, a dual-type Pokémon of steel and grass, will take $4\times$ damage against fire moves, since both of its types are weak against fire. All moves have a certain probability that it will work. In addition, there are moves with other effects than direct damage. For instance, a move may increase one's attack, decrease your opponent's attack, or add a status deficiency on your opponent's Pokémon, such as making it fall asleep. This will make the Pokémon unable to move with a relatively high probability. If it is able to move, the status of ""asleep"" is lifted. Furthermore, each Pokémon has a ""Nature"" which increases one stat (out of Attack, Defense, Special Attack, Special Defense, Speed), while decreases another. While no longer necessary for my argument, one could go even deeper with things such as IV's and EV's for each Pokémon, which also affects its stats. A player has won when all of its opponents Pokémon are out of play. A player may change the active Pokémon freely. (That is, the ""battles"" are 1v1, but the Pokémon may be changed freely.) Has there been any serious mathematical research towards competitive Pokémon play? In particular, has there been proved that there is always a best strategy? What about the number of possible ""positions""? If there always is a best strategy, can one evaluate the likelihood of one team beating the other, given best play from both sides? (As is done with chess engines today, given a certain position.) EDIT: For the sake of simplicity, I think it is a good idea to consider two positions equal when 1) Both positions have identical teams in terms of Pokémon. (Natures, IVs, EVs and stats are omitted.) As such, one can create a one-to-one correspondence between the set of $12$ Pokémon in position $A$ and the $12$ in position $B$ by mapping $a_A \mapsto a_B$, where $a_A$ is Pokémon $a$ in position $A$. 2) $a_A$ and $a_B$ have the same moves for all $a\in A, B$.",,"['probability', 'combinatorics', 'soft-question', 'game-theory']"
24,How likely is it not to be anyone's best friend?,How likely is it not to be anyone's best friend?,,"A teenage acquaintance of mine lamented: Every one of my friends is better friends with somebody else. Thanks to my knowledge of mathematics I could inform her that she's not alone and $e^{-1}\approx 37\%$ of all people could be expected to be in the same situation, which I'm sure cheered her up immensely. This number assumes that friendships are distributed randomly, such that each person in a population of $n$ chooses a best friend at random. Then the probability that any given person is not anyone's best friend is $(1-\frac{1}{n-1})^{n-1}$, which tends to $e^{-1}$ for large $n$. Afterwards I'm not sure this is actually the best way to analyze the claim. Perhaps instead we should imagine assigning a random ""friendship strength"" to each edge in the complete graph on $n$ vertices, in which case my friend's lament would be ""every vertex I'm connected to has an edge with higher weight than my edge to it"". This is not the same as ""everyone choses a best friend at random"", because it guarantees that there's at least one pair of people who're mutually best friends, namely the two ends of the edge with the highest weight. (Of course, some people are not friends at all; we can handle that by assigning low weights to their mutual edges. As long as everyone has at least one actual friend, this won't change who are whose best friends). (It doesn't matter which distribution the friendship weights are chosen by, as long as it's continuous -- because all that matters is the relative order between the weights. Equivalently, one may simply choose a random total order on the $n(n-1)/2$ edges in the complete graph). In this model, what is the probability that a given person is not anyone's best friend? By linearity of expectations, the probability of being mutually best friends with anyone is $\frac{n-1}{2n-3}\approx\frac 12$ (much better than in the earlier model), but that doesn't take into account the possibility that some poor soul has me as their best friend whereas I myself has other better friends. Linearity of expectation doesn't seem to help here -- it tells me that the expected number of people whose best friend I am is $1$, but not the probability of this number being $0$. (Edit: Several paragraphs of numerical results now moved to a significantly expanded answer)","A teenage acquaintance of mine lamented: Every one of my friends is better friends with somebody else. Thanks to my knowledge of mathematics I could inform her that she's not alone and $e^{-1}\approx 37\%$ of all people could be expected to be in the same situation, which I'm sure cheered her up immensely. This number assumes that friendships are distributed randomly, such that each person in a population of $n$ chooses a best friend at random. Then the probability that any given person is not anyone's best friend is $(1-\frac{1}{n-1})^{n-1}$, which tends to $e^{-1}$ for large $n$. Afterwards I'm not sure this is actually the best way to analyze the claim. Perhaps instead we should imagine assigning a random ""friendship strength"" to each edge in the complete graph on $n$ vertices, in which case my friend's lament would be ""every vertex I'm connected to has an edge with higher weight than my edge to it"". This is not the same as ""everyone choses a best friend at random"", because it guarantees that there's at least one pair of people who're mutually best friends, namely the two ends of the edge with the highest weight. (Of course, some people are not friends at all; we can handle that by assigning low weights to their mutual edges. As long as everyone has at least one actual friend, this won't change who are whose best friends). (It doesn't matter which distribution the friendship weights are chosen by, as long as it's continuous -- because all that matters is the relative order between the weights. Equivalently, one may simply choose a random total order on the $n(n-1)/2$ edges in the complete graph). In this model, what is the probability that a given person is not anyone's best friend? By linearity of expectations, the probability of being mutually best friends with anyone is $\frac{n-1}{2n-3}\approx\frac 12$ (much better than in the earlier model), but that doesn't take into account the possibility that some poor soul has me as their best friend whereas I myself has other better friends. Linearity of expectation doesn't seem to help here -- it tells me that the expected number of people whose best friend I am is $1$, but not the probability of this number being $0$. (Edit: Several paragraphs of numerical results now moved to a significantly expanded answer)",,"['probability', 'recreational-mathematics', 'random-graphs']"
25,How can a probability density be greater than one and integrate to one,How can a probability density be greater than one and integrate to one,,"Wikipedia says: The probability density function is nonnegative everywhere, and its integral over the entire space is equal to one. and it also says. Unlike a probability, a probability density function can take on values greater than one; for example, the uniform distribution on the interval $[0, \frac{1}{2}]$ has probability density $f(x) = 2$ for $0 ≤ x ≤ \frac{1}{2}$ and $f(x) = 0$ elsewhere. How are these two things compatible?","Wikipedia says: The probability density function is nonnegative everywhere, and its integral over the entire space is equal to one. and it also says. Unlike a probability, a probability density function can take on values greater than one; for example, the uniform distribution on the interval $[0, \frac{1}{2}]$ has probability density $f(x) = 2$ for $0 ≤ x ≤ \frac{1}{2}$ and $f(x) = 0$ elsewhere. How are these two things compatible?",,"['probability', 'probability-distributions', 'integration']"
26,Probability for the length of the longest run in $n$ Bernoulli trials,Probability for the length of the longest run in  Bernoulli trials,n,"Suppose a biased coin (probability of head being $p$) was flipped $n$ times. I would like to find the probability that the length of the longest run of heads, say $\ell_n$, exceeds a given number $m$, i.e. $\mathbb{P}(\ell_n > m)$. It suffices to find the probability that length of any run of heads exceeds $m$. I was trying to approach the problem by fixing a run of $m+1$ heads, and counting the number of such configurations, but did not get anywhere. It is easy to simulate it: I would appreciate any advice on how to analytically solve this problem, i.e. express an answer in terms of a sum or an integral. Thank you.","Suppose a biased coin (probability of head being $p$) was flipped $n$ times. I would like to find the probability that the length of the longest run of heads, say $\ell_n$, exceeds a given number $m$, i.e. $\mathbb{P}(\ell_n > m)$. It suffices to find the probability that length of any run of heads exceeds $m$. I was trying to approach the problem by fixing a run of $m+1$ heads, and counting the number of such configurations, but did not get anywhere. It is easy to simulate it: I would appreciate any advice on how to analytically solve this problem, i.e. express an answer in terms of a sum or an integral. Thank you.",,"['probability', 'combinatorics']"
27,"There are 4 cups of liquid. Three are water and one is poison. If you were to drink 3 of the 4 cups, what is the probability of being poisoned?","There are 4 cups of liquid. Three are water and one is poison. If you were to drink 3 of the 4 cups, what is the probability of being poisoned?",,"In Season 5 Episode 16 of Agents of Shield, one of the characters decides to prove she can't die by pouring three glasses of water and one of poison; she then randomly drinks three of the four cups. I was wondering how to compute the probability of her drinking the one with poison. I thought to label the four cups $\alpha, \beta, \gamma, \delta$ with events $A = \{\alpha \text{ is water}\}, \ a = \{\alpha \text{ is poison}\}$ $B = \{\beta \text{ is water}\},\ b = \{\beta \text{ is poison}\}$ $C = \{\gamma \text{ is water}\},\ c = \{\gamma \text{ is poison}\}$ $D = \{\delta \text{ is water}\},\ d = \{\delta \text{ is poison}\}$ If she were to drink in order, then I would calculate $P(a) = {1}/{4}$. Next $$P(b|A) = \frac{P(A|b)P(b)}{P(A)}$$ Next $P(c|A \cap B)$, which I'm not completely sure how to calculate. My doubt is that I shouldn't order the cups because that assumes $\delta$ is the poisoned cup. I am also unsure how I would calculate the conditional probabilities (I know about Bayes theorem, I mean more what numbers to put in the particular case). Thank you for you help.","In Season 5 Episode 16 of Agents of Shield, one of the characters decides to prove she can't die by pouring three glasses of water and one of poison; she then randomly drinks three of the four cups. I was wondering how to compute the probability of her drinking the one with poison. I thought to label the four cups $\alpha, \beta, \gamma, \delta$ with events $A = \{\alpha \text{ is water}\}, \ a = \{\alpha \text{ is poison}\}$ $B = \{\beta \text{ is water}\},\ b = \{\beta \text{ is poison}\}$ $C = \{\gamma \text{ is water}\},\ c = \{\gamma \text{ is poison}\}$ $D = \{\delta \text{ is water}\},\ d = \{\delta \text{ is poison}\}$ If she were to drink in order, then I would calculate $P(a) = {1}/{4}$. Next $$P(b|A) = \frac{P(A|b)P(b)}{P(A)}$$ Next $P(c|A \cap B)$, which I'm not completely sure how to calculate. My doubt is that I shouldn't order the cups because that assumes $\delta$ is the poisoned cup. I am also unsure how I would calculate the conditional probabilities (I know about Bayes theorem, I mean more what numbers to put in the particular case). Thank you for you help.",,['probability']
28,Is it generally accepted that if you throw a dart at a number line you will NEVER hit a rational number?,Is it generally accepted that if you throw a dart at a number line you will NEVER hit a rational number?,,"In the book ""Zero: The Biography of a Dangerous Idea"", author Charles Seife claims that a dart thrown at the real number line would never hit a rational number. He doesn't say that it's only ""unlikely"" or that the probability approaches zero or anything like that. He says that it will never happen because the irrationals take up all the space on the number line and the rationals take up no space. This idea almost makes sense to me, but I can't wrap my head around why it should be impossible to get really lucky and hit, say, 0, dead on. Presumably we're talking about a magic super sharp dart that makes contact with the number line in exactly one point. Why couldn't that point be a rational? A point takes up no space, but it almost sounds like he's saying the points don't even exist somehow. Does anybody else buy this? I found one academic paper online which ridiculed the comment, but offered no explanation. Here's the original quote: ""How big are the rational numbers? They take up no space at all. It's a tough concept to swallow, but it's true. Even though there are rational numbers everywhere on the number line, they take up no space at all. If we were to throw a dart at the number line, it would never hit a rational number. Never. And though the rationals are tiny, the irrationals aren't, since we can't make a seating chart and cover them one by one; there will always be uncovered irrationals left over. Kronecker hated the irrationals, but they take up all the space in the number line. The infinity of the rationals is nothing more than a zero.""","In the book ""Zero: The Biography of a Dangerous Idea"", author Charles Seife claims that a dart thrown at the real number line would never hit a rational number. He doesn't say that it's only ""unlikely"" or that the probability approaches zero or anything like that. He says that it will never happen because the irrationals take up all the space on the number line and the rationals take up no space. This idea almost makes sense to me, but I can't wrap my head around why it should be impossible to get really lucky and hit, say, 0, dead on. Presumably we're talking about a magic super sharp dart that makes contact with the number line in exactly one point. Why couldn't that point be a rational? A point takes up no space, but it almost sounds like he's saying the points don't even exist somehow. Does anybody else buy this? I found one academic paper online which ridiculed the comment, but offered no explanation. Here's the original quote: ""How big are the rational numbers? They take up no space at all. It's a tough concept to swallow, but it's true. Even though there are rational numbers everywhere on the number line, they take up no space at all. If we were to throw a dart at the number line, it would never hit a rational number. Never. And though the rationals are tiny, the irrationals aren't, since we can't make a seating chart and cover them one by one; there will always be uncovered irrationals left over. Kronecker hated the irrationals, but they take up all the space in the number line. The infinity of the rationals is nothing more than a zero.""",,"['probability', 'infinity']"
29,Chance of meeting in a bar,Chance of meeting in a bar,,"Two people have to spend exactly 15 consecutive minutes in a bar on a given day, between 12:00 and 13:00. Assuming uniform arrival times, what is the probability they will meet? I am mainly interested to see how people would model this formally. I came up with the answer 50% (wrong!) based on the assumptions that: independent uniform arrival they will meet iff they actually overlap by some $\epsilon > 0$ we can measure time continuously but my methods felt a little ad hoc to me, and I would like to learn to make it more formal. Also I'm curious whether people think the problem is formulated unambiguously. I added the assumption of independent arrival myself for instance, because I think without such an assumption the problem is not well defined.","Two people have to spend exactly 15 consecutive minutes in a bar on a given day, between 12:00 and 13:00. Assuming uniform arrival times, what is the probability they will meet? I am mainly interested to see how people would model this formally. I came up with the answer 50% (wrong!) based on the assumptions that: independent uniform arrival they will meet iff they actually overlap by some $\epsilon > 0$ we can measure time continuously but my methods felt a little ad hoc to me, and I would like to learn to make it more formal. Also I'm curious whether people think the problem is formulated unambiguously. I added the assumption of independent arrival myself for instance, because I think without such an assumption the problem is not well defined.",,"['probability', 'soft-question', 'probability-theory']"
30,Average Distance Between Random Points on a Line Segment,Average Distance Between Random Points on a Line Segment,,"Suppose I have a line segment of length $L$.  I now select two points at random along the segment.  What is the expected value of the distance between the two points, and why?","Suppose I have a line segment of length $L$.  I now select two points at random along the segment.  What is the expected value of the distance between the two points, and why?",,['probability']
31,"product distribution of two uniform distribution, what about 3 or more","product distribution of two uniform distribution, what about 3 or more",,"Say $X_1, X_2, \ldots, X_n$ are independent and identically distributed uniform random variables on the interval $(0,1)$. What is the product distribution of two of such random variables, e.g., $Z_2 = X_1 \cdot X_2$? What if there are 3; $Z_3 = X_1 \cdot X_2 \cdot X_3$? What if there are $n$ of such uniform variables? $Z_n = X_1 \cdot X_2 \cdot \ldots \cdot X_n$?","Say $X_1, X_2, \ldots, X_n$ are independent and identically distributed uniform random variables on the interval $(0,1)$. What is the product distribution of two of such random variables, e.g., $Z_2 = X_1 \cdot X_2$? What if there are 3; $Z_3 = X_1 \cdot X_2 \cdot X_3$? What if there are $n$ of such uniform variables? $Z_n = X_1 \cdot X_2 \cdot \ldots \cdot X_n$?",,"['probability', 'uniform-distribution']"
32,"If we randomly select 25 integers between 1 and 100, how many consecutive integers should we expect?","If we randomly select 25 integers between 1 and 100, how many consecutive integers should we expect?",,"Question: Suppose we have one hundred seats, numbered 1 through 100. We randomly select 25 of these seats. What is the expected number of selected pairs of seats that are consecutive? (To clarify: we would count two consecutive selected seats as a single pair.) For example, if the selected seats are all consecutive (eg 1-25), then we have 24 consecutive pairs (eg 1&2, 2&3, 3&4, ..., 24&25). The probability of this happening is 75/($_{100}C_{25}$). So this contributes $24\cdot 75/(_{100}C_{25}$) to the expected number of consecutive pairs. Motivation : I teach. Near the end of an exam, when most of the students have left, I notice that there are still many pairs of students next to each other. I want to know if the number that remain should be expected or not.","Question: Suppose we have one hundred seats, numbered 1 through 100. We randomly select 25 of these seats. What is the expected number of selected pairs of seats that are consecutive? (To clarify: we would count two consecutive selected seats as a single pair.) For example, if the selected seats are all consecutive (eg 1-25), then we have 24 consecutive pairs (eg 1&2, 2&3, 3&4, ..., 24&25). The probability of this happening is 75/($_{100}C_{25}$). So this contributes $24\cdot 75/(_{100}C_{25}$) to the expected number of consecutive pairs. Motivation : I teach. Near the end of an exam, when most of the students have left, I notice that there are still many pairs of students next to each other. I want to know if the number that remain should be expected or not.",,['probability']
33,What does it mean to integrate with respect to the distribution function?,What does it mean to integrate with respect to the distribution function?,,"If $f(x)$ is a density function and $F(x)$ is a distribution function of a random variable $X$ then I understand that the expectation of x is often written as: $$E(X) = \int x f(x) dx$$ where the bounds of integration are implicitly $-\infty$ and $\infty$. The idea of multiplying x by the probability of x and summing makes sense in the discrete case, and it's easy to see how it generalises to the continuous case.  However, in Larry Wasserman's book All of Statistics he writes the expectation as follows: $$E(X) = \int x dF(x)$$ I guess my calculus is a bit rusty, in that I'm not that familiar with the idea of integrating over functions of $x$ rather than just $x$. What does it mean to integrate over the distribution function? Is there an analogous process to repeated summing in the discrete case? Is there a visual analogy? UPDATE: I just found the following extract from Wasserman's book (p.47): The notation $\int x d F(x)$ deserves some comment. We use it merely   as a convenient unifying notation so that we don't have to write   $\sum_x x f(x)$ for discrete random variables and $\int x f(x) dx$ for   continuous random variables, but you should be aware that $\int x d F(x)$  has a precise meaning that is discussed in a real analysis   course. Thus, I would be interested in any insights that could be shared about what is the precise meaning that would be discussed in a real analysis course?","If $f(x)$ is a density function and $F(x)$ is a distribution function of a random variable $X$ then I understand that the expectation of x is often written as: $$E(X) = \int x f(x) dx$$ where the bounds of integration are implicitly $-\infty$ and $\infty$. The idea of multiplying x by the probability of x and summing makes sense in the discrete case, and it's easy to see how it generalises to the continuous case.  However, in Larry Wasserman's book All of Statistics he writes the expectation as follows: $$E(X) = \int x dF(x)$$ I guess my calculus is a bit rusty, in that I'm not that familiar with the idea of integrating over functions of $x$ rather than just $x$. What does it mean to integrate over the distribution function? Is there an analogous process to repeated summing in the discrete case? Is there a visual analogy? UPDATE: I just found the following extract from Wasserman's book (p.47): The notation $\int x d F(x)$ deserves some comment. We use it merely   as a convenient unifying notation so that we don't have to write   $\sum_x x f(x)$ for discrete random variables and $\int x f(x) dx$ for   continuous random variables, but you should be aware that $\int x d F(x)$  has a precise meaning that is discussed in a real analysis   course. Thus, I would be interested in any insights that could be shared about what is the precise meaning that would be discussed in a real analysis course?",,"['probability', 'statistics', 'integration', 'random-variables']"
34,Is the Law of Large Numbers empirically proven?,Is the Law of Large Numbers empirically proven?,,"Does this reflect the real world and what is the empirical evidence behind this? Layman here so please avoid abstract math in your response. The Law of Large Numbers states that the average of the results from multiple trials will tend to converge to its expected value (e.g. 0.5 in a coin toss experiment) as the sample size increases. The way I understand it, while the first 10 coin tosses may result in an average closer to 0 or 1 rather than 0.5, after 1000 tosses a statistician would expect the average to be very close to 0.5 and definitely 0.5 with an infinite number of trials. Given that a coin has no memory and each coin toss is independent, what physical laws would determine that the average of all trials will eventually reach 0.5. More specifically, why does a statistician believe that a random event with 2 possible outcomes will have a close to equal amount of both outcomes over say 10,000 trials? What prevents the coin to fall 9900 times on heads instead of 5200? Finally, since gambling and insurance institutions rely on such expectations, are there any experiments that have conclusively shown the validity of the LLN in the real world? EDIT: I do differentiate between the LLN and the Gambler's fallacy. My question is NOT if or why any specific outcome or series of outcomes become more likely with more trials--that's obviously false--but why the mean of all outcomes tends toward the expected value? FURTHER EDIT: LLN seems to rely on two assumptions in order to work: The universe is indifferent towards the result of any one trial, because each outcome is equally likely The universe is NOT indifferent towards any one particular outcome coming up too frequently and dominating the rest. Obviously, we as humans would label 50/50 or a similar distribution of a coin toss experiment ""random"" , but if heads or tails turns out to be say 60-70% after thousands of trials, we would suspect there is something wrong with the coin and it isn't fair. Thus, if the universe is truly indifferent towards the average of large samples, there is no way we can have true randomness and consistent predictions--there will always be a suspicion of bias unless the total distribution is not somehow kept in check by something that preserves the relative frequencies. Why is the universe NOT indifferent towards big samples of coin tosses? What is the objective reason for this phenomenon? NOTE: A good explanation would not be circular: justifying probability with probabilistic assumptions (e.g. ""it's just more likely""). Please check your answers, as most of them fall into  this trap.","Does this reflect the real world and what is the empirical evidence behind this? Layman here so please avoid abstract math in your response. The Law of Large Numbers states that the average of the results from multiple trials will tend to converge to its expected value (e.g. 0.5 in a coin toss experiment) as the sample size increases. The way I understand it, while the first 10 coin tosses may result in an average closer to 0 or 1 rather than 0.5, after 1000 tosses a statistician would expect the average to be very close to 0.5 and definitely 0.5 with an infinite number of trials. Given that a coin has no memory and each coin toss is independent, what physical laws would determine that the average of all trials will eventually reach 0.5. More specifically, why does a statistician believe that a random event with 2 possible outcomes will have a close to equal amount of both outcomes over say 10,000 trials? What prevents the coin to fall 9900 times on heads instead of 5200? Finally, since gambling and insurance institutions rely on such expectations, are there any experiments that have conclusively shown the validity of the LLN in the real world? EDIT: I do differentiate between the LLN and the Gambler's fallacy. My question is NOT if or why any specific outcome or series of outcomes become more likely with more trials--that's obviously false--but why the mean of all outcomes tends toward the expected value? FURTHER EDIT: LLN seems to rely on two assumptions in order to work: The universe is indifferent towards the result of any one trial, because each outcome is equally likely The universe is NOT indifferent towards any one particular outcome coming up too frequently and dominating the rest. Obviously, we as humans would label 50/50 or a similar distribution of a coin toss experiment ""random"" , but if heads or tails turns out to be say 60-70% after thousands of trials, we would suspect there is something wrong with the coin and it isn't fair. Thus, if the universe is truly indifferent towards the average of large samples, there is no way we can have true randomness and consistent predictions--there will always be a suspicion of bias unless the total distribution is not somehow kept in check by something that preserves the relative frequencies. Why is the universe NOT indifferent towards big samples of coin tosses? What is the objective reason for this phenomenon? NOTE: A good explanation would not be circular: justifying probability with probabilistic assumptions (e.g. ""it's just more likely""). Please check your answers, as most of them fall into  this trap.",,"['probability', 'statistics', 'applications', 'law-of-large-numbers']"
35,"If a coin toss is observed to come up as heads many times, does that affect the probability of the next toss?","If a coin toss is observed to come up as heads many times, does that affect the probability of the next toss?",,"A two-sided coin has just been minted with two different sides (heads and tails). It has never been flipped before. Basic understanding of probability suggests that the probability of flipping heads is .5 and tails is .5. Unexpectedly, you flip the coin a very large number of times and it always lands on heads. Is the probability of flipping heads/tails still .5 each? Or has it changed in favor of tails because the probability should tend to .5 heads and .5 tails as you approach an infinite number of trials? I understand that flipping coins is generally a stochastic process, but does that change at all if you see a large number of trials bias to one side?","A two-sided coin has just been minted with two different sides (heads and tails). It has never been flipped before. Basic understanding of probability suggests that the probability of flipping heads is .5 and tails is .5. Unexpectedly, you flip the coin a very large number of times and it always lands on heads. Is the probability of flipping heads/tails still .5 each? Or has it changed in favor of tails because the probability should tend to .5 heads and .5 tails as you approach an infinite number of trials? I understand that flipping coins is generally a stochastic process, but does that change at all if you see a large number of trials bias to one side?",,"['probability', 'stochastic-processes']"
36,Coin flipping probability game ; 7 flips vs 8 flips,Coin flipping probability game ; 7 flips vs 8 flips,,"Your friend flips a coin 7 times and you flip a coin 8 times; the person who got the most tails wins. If you get an equal amount, your friend wins. There is a 50% chance of you winning the game and a 50% chance of your friend winning. How can I prove this? The way I see it, you get one more flip than your friend so you have a 50% chance of winning if there is a 50% chance of getting a tails. I even wrote a little script to confirm this suspicion: from random import choice  coin = ['H', 'T']  def flipCoin(count, side):     num = 0     for i in range(0, count):         if choice(coin) == side:             num += 1     return num   games = 0 wins = 0 plays = 88888  for i in range(0, plays):     you = flipCoin(8, 'T')     friend = flipCoin(7, 'T')     games += 1     if you > friend:         wins += 1  print('Games: ' + str(games) + ' Wins: ' + str(wins)) probability = wins/games * 100.0 print('Probability: ' + str(probability) + ' from ' + str(plays) + ' games.') and as expected, Games: 88888 Wins: 44603 Probability: 50.17887678876789 from 88888 games. But how can I prove this?","Your friend flips a coin 7 times and you flip a coin 8 times; the person who got the most tails wins. If you get an equal amount, your friend wins. There is a 50% chance of you winning the game and a 50% chance of your friend winning. How can I prove this? The way I see it, you get one more flip than your friend so you have a 50% chance of winning if there is a 50% chance of getting a tails. I even wrote a little script to confirm this suspicion: from random import choice  coin = ['H', 'T']  def flipCoin(count, side):     num = 0     for i in range(0, count):         if choice(coin) == side:             num += 1     return num   games = 0 wins = 0 plays = 88888  for i in range(0, plays):     you = flipCoin(8, 'T')     friend = flipCoin(7, 'T')     games += 1     if you > friend:         wins += 1  print('Games: ' + str(games) + ' Wins: ' + str(wins)) probability = wins/games * 100.0 print('Probability: ' + str(probability) + ' from ' + str(plays) + ' games.') and as expected, Games: 88888 Wins: 44603 Probability: 50.17887678876789 from 88888 games. But how can I prove this?",,"['probability', 'discrete-mathematics']"
37,What's the probability that a sequence of coin flips never has twice as many heads as tails?,What's the probability that a sequence of coin flips never has twice as many heads as tails?,,"I gave my friend this problem as a brainteaser; while her attempted solution didn't work, it raised an interesting question. I flip a fair coin repeatedly and record the results.  I stop as soon as the number of heads is equal to twice the number of tails (for example, I will stop after seeing HHT or THTHHH or TTTHHHHHH).  What's the probability that I never stop? I've tried to just compute the answer directly, but the terms got ugly pretty quickly.  I'm hoping for a hint towards a slick solution, but I will keep trying to brute force an answer in the meantime.","I gave my friend this problem as a brainteaser; while her attempted solution didn't work, it raised an interesting question. I flip a fair coin repeatedly and record the results.  I stop as soon as the number of heads is equal to twice the number of tails (for example, I will stop after seeing HHT or THTHHH or TTTHHHHHH).  What's the probability that I never stop? I've tried to just compute the answer directly, but the terms got ugly pretty quickly.  I'm hoping for a hint towards a slick solution, but I will keep trying to brute force an answer in the meantime.",,['probability']
38,Is the largest root of a random polynomial more likely to be real than complex?,Is the largest root of a random polynomial more likely to be real than complex?,,"Posted on MO since it is unanswered in MSE It is known that the number of real roots of a random polynomial with real coefficients is much smaller than the number of complex roots. WLOG, assume that the coefficients are uniformly random in $(-1,1)$ for if not then we can divide each coefficient by the coefficient with the largest absolutely value to scale each coefficient to $(-1,1)$ . Then the number of real roots of a polynomial of degree $n$ is asymptotic to $\displaystyle \frac{2\log n}{\pi} + o(1)$ . Similar asymptotics hold for other distribution of the coefficients however for the rest of this post we assume that the coefficients are uniformly random in $(-1,1)$ . This means that the number of complex roots is approximately $\displaystyle n - \frac{2\log n}{\pi}$ . Definition 1 : The largest root of a polynomial is the root with the largest modulus. Definition 2 : The smallest root of a polynomial is the root with the smallest modulus. The above graph shows the roots of a polynomial of degree $101$ ; the largest root is in the top right corner in green. Is the largest or the smallest root more likely to be complex or real? The naive guess is that the largest or the smallest root is more likely to be complex than real because there are exponentially more complex roots than real roots as seen from the above asymptotic. However, experimental data shows that Probability that the largest root is real is equal to the probability that the smallest root is real and this probability is greater than that of either of them being complex. This probability decreases to $1/2$ as $n \to \infty$ as shown in the above graph (created using a Monte Carlo simulation with $10^5$ trails for each value of $n$ ). Note : Instead of uniform distribution, if we assume that the coefficients are normally distributed with mean $0$ and standard deviation $1$ and scaled to $(-1,1)$ , the above observation and limiting probabilities hold. It is counter intuitive that despite being much exponentially fewer in number, real roots are more likely to contain the largest as well as the smallest roots. In this sense, the largest as well as the smallest roots is biased towards reals . Question 1 : What is the reason for this bias? Question 2 : Does the probability that the largest (or the smallest) root of a polynomial of degree $n$ is real approach $\frac{1}{2}$ as $n \to \infty$ ? Update 2-May-2024 : We can quantify the observed bias as follows. Let $P(L|R)$ be the probability that a root is the largest given that it is real and let $P(L|C)$ be the probability that a root is the largest given that it is complex. Similarly, let $P(S|R)$ be the probability that a root is the smallest given that it is real and let $P(S|C)$ be the probability that a root is the smallest given that it is complex. Then the experimental data says that $$ P(L|R) = P(S|R) \approx \frac{\pi}{4\log n}, $$ $$ P(L|C) = P(S|C) \approx \frac{\pi}{2n\pi - 4\log n}. $$ Related : What is the probability that the absolute value of the roots of a polynomial of degree $n$ is greater than $x$ ?","Posted on MO since it is unanswered in MSE It is known that the number of real roots of a random polynomial with real coefficients is much smaller than the number of complex roots. WLOG, assume that the coefficients are uniformly random in for if not then we can divide each coefficient by the coefficient with the largest absolutely value to scale each coefficient to . Then the number of real roots of a polynomial of degree is asymptotic to . Similar asymptotics hold for other distribution of the coefficients however for the rest of this post we assume that the coefficients are uniformly random in . This means that the number of complex roots is approximately . Definition 1 : The largest root of a polynomial is the root with the largest modulus. Definition 2 : The smallest root of a polynomial is the root with the smallest modulus. The above graph shows the roots of a polynomial of degree ; the largest root is in the top right corner in green. Is the largest or the smallest root more likely to be complex or real? The naive guess is that the largest or the smallest root is more likely to be complex than real because there are exponentially more complex roots than real roots as seen from the above asymptotic. However, experimental data shows that Probability that the largest root is real is equal to the probability that the smallest root is real and this probability is greater than that of either of them being complex. This probability decreases to as as shown in the above graph (created using a Monte Carlo simulation with trails for each value of ). Note : Instead of uniform distribution, if we assume that the coefficients are normally distributed with mean and standard deviation and scaled to , the above observation and limiting probabilities hold. It is counter intuitive that despite being much exponentially fewer in number, real roots are more likely to contain the largest as well as the smallest roots. In this sense, the largest as well as the smallest roots is biased towards reals . Question 1 : What is the reason for this bias? Question 2 : Does the probability that the largest (or the smallest) root of a polynomial of degree is real approach as ? Update 2-May-2024 : We can quantify the observed bias as follows. Let be the probability that a root is the largest given that it is real and let be the probability that a root is the largest given that it is complex. Similarly, let be the probability that a root is the smallest given that it is real and let be the probability that a root is the smallest given that it is complex. Then the experimental data says that Related : What is the probability that the absolute value of the roots of a polynomial of degree is greater than ?","(-1,1) (-1,1) n \displaystyle \frac{2\log n}{\pi} + o(1) (-1,1) \displaystyle n - \frac{2\log n}{\pi} 101 1/2 n \to \infty 10^5 n 0 1 (-1,1) n \frac{1}{2} n \to \infty P(L|R) P(L|C) P(S|R) P(S|C) 
P(L|R) = P(S|R) \approx \frac{\pi}{4\log n},
 
P(L|C) = P(S|C) \approx \frac{\pi}{2n\pi - 4\log n}.
 n x","['probability', 'algebra-precalculus', 'limits', 'polynomials', 'roots']"
39,Probability that random moves in the game 2048 will win,Probability that random moves in the game 2048 will win,,"I have recently played the game 2048 , created by Gabriele Cirulli, which is fun.  I suggest trying if you have not.  But my brother posed this question to me about the game: If he were to write a script that made random moves in the game 2048, what is the probability that it would win the game? Combinatorics is not my area, so I did not even attempt to answer this, knowing this seems like a difficult question to answer.  But I thought someone here might have a good idea. Also, since we are not concerned with time, just with winning, we can assume that every random move actually results in a tile moving. Addendum While the answers below shed light on the problem, only BoZenKhaa came close to providing a probability, even if it was an upper bound.  So I would like to modify the question to: Can we find decent upper and lower bounds for this probability?","I have recently played the game 2048 , created by Gabriele Cirulli, which is fun.  I suggest trying if you have not.  But my brother posed this question to me about the game: If he were to write a script that made random moves in the game 2048, what is the probability that it would win the game? Combinatorics is not my area, so I did not even attempt to answer this, knowing this seems like a difficult question to answer.  But I thought someone here might have a good idea. Also, since we are not concerned with time, just with winning, we can assume that every random move actually results in a tile moving. Addendum While the answers below shed light on the problem, only BoZenKhaa came close to providing a probability, even if it was an upper bound.  So I would like to modify the question to: Can we find decent upper and lower bounds for this probability?",,"['probability', 'combinatorics', 'popular-math']"
40,Striking applications of linearity of expectation,Striking applications of linearity of expectation,,"Linearity of expectation is a very simple and ""obvious"" statement, but has many non-trivial applications, e.g., to analyze randomized algorithms (for instance, the coupon collector's problem ), or in some proofs where dealing with non-independent random variables would otherwise make any calculation daunting. What are the cleanest, most elegant, or striking applications of the linearity of expectation you've encountered?","Linearity of expectation is a very simple and ""obvious"" statement, but has many non-trivial applications, e.g., to analyze randomized algorithms (for instance, the coupon collector's problem ), or in some proofs where dealing with non-independent random variables would otherwise make any calculation daunting. What are the cleanest, most elegant, or striking applications of the linearity of expectation you've encountered?",,"['probability', 'reference-request', 'expected-value', 'big-list']"
41,Why does the median minimize $E(|X-c|)$?,Why does the median minimize ?,E(|X-c|),"Suppose $X$ is a real-valued random variable and let $P_X$ denote the distribution of $X$. Then $$ E(|X-c|) = \int_\mathbb{R} |x-c| dP_X(x). $$ The medians of $X$ are defined as any number $m \in \mathbb{R}$ such that $P(X \leq m) \geq \frac{1}{2}$ and $P(X \geq m) \geq \frac{1}{2}$. Why do the medians solve $$ \min_{c \in \mathbb{R}} E(|X-c|) \, ? $$","Suppose $X$ is a real-valued random variable and let $P_X$ denote the distribution of $X$. Then $$ E(|X-c|) = \int_\mathbb{R} |x-c| dP_X(x). $$ The medians of $X$ are defined as any number $m \in \mathbb{R}$ such that $P(X \leq m) \geq \frac{1}{2}$ and $P(X \geq m) \geq \frac{1}{2}$. Why do the medians solve $$ \min_{c \in \mathbb{R}} E(|X-c|) \, ? $$",,"['probability', 'probability-theory', 'probability-distributions', 'expected-value', 'median']"
42,The two-daughter-problem [duplicate],The two-daughter-problem [duplicate],,"This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 7 years ago . When hearing about the two-daughter problem, I first thought it to be quite clear (after, of course, at first falling into the trap like many of us), but on the second glance, I encountered some serious problems with my understanding. The original problem seems to be quite easy: Assume that the only thing you know about a man with two kids is that at least one of the kids is a daughter. What is the probability that the other kid is a daughter as well? (Boys and girls are assumed to be born equally often.) After the first impulse (""1/2 of course!""), it becomes clear that it is only 1/3. The problem can be mapped to a situation where from the multitude of families with two children, only those with M/M are ruled out, while the equally often cases F/F, F/M and M/F remain, making F/F only one third of all remaining cases. But now, meet Mr. Smith. I don't know much about him (except that he has two children), but when he approached me, he told me: ""I am so happy! Victoria just got the scholarship she wanted!"" Now what is the probability that Victoria has a sister? Since I only know that Mr. Smith has two children, and one is obviously a girl, I am tempted to map this onto the two-daughter-problem, leading to the answer ""1/3"". But wait! What if I ask Mr. Smith first, if Victoria is his elder daughter? Assume his answer is yes (and ignore any problems with twins - even then one is typically a few seconds ""older"" than the other). So now I know that from the cases (F/F, F/M, M/F), M/F also drops out. And now, the probability for F/F just rose to 1/2. Okay, but what if his answer is no? Then Victoria is the younger one, and F/M drops out. Again, the probability rises to 1/2. So I'm going to just ask him: ""Well, Mr. Smith, is Victoria your elder daughter? Wait - don't answer, because whatever you may answer, it doesn't matter. The probability just rose from 1/3 to 1/2."" Or, even better, I do not even have to ask him, just thinking about the question will shift probabilities to 1/2, which means that the original probability for Victoria having a sister must already have been 1/2. But then the mapping to the two-daughter-problem is obviously false. Where is my error? Making things worse, I could also create a setup where Mr. Smith just tells me: ""I have two kids, and at least one of them is a girl."" I then ask him: ""Oh, can you give me a name of a daughter of yours?"" and he answers: ""Sure. Victoria."" (Side note: I have a gut feeling that this has something to do with how to assume probability distributions behind situations, similar to the Two envelopes problem , but I can't figure this out completely yet.) -------- UPDATE -------- It seems that my error is that the question ""Is Victoria the older child?"" does not change the probabilities. If I know for sure that Mr. Smith was picked from an equally distributed (M/F, F/M, F/F) sample, then the knowledge that Victoria is the older child does not change anything, as was pointed out  here, and the probability for her having a sister is 1/3. But it is very interesting that solely from the sentence ""Victoria just got the scholarship she wanted!"" I can NOT infer that Mr. Smith is indeed chosen from this uniform distribution. Imagine that all kids have the same chance to get a scholarship, and the happy father will tell us if it is the case. Then it is actually twice as probable that Mr. Smith will tell us about his daughter's success if he has two girls, so the weighting of the four possibilities (M/M, F/M, M/F, F/F) is (0, 1, 1, 2). And in this case, the probability of Victoria having a sister is 1/2. So another problem in my reasoning is the mapping of Mr. Smith's statement to the two-daughter-problem. Simply put, without knowing more about the circumstances that led to Mr. Smith telling me about Victoria, I simply can't say if the probability is 1/3 or 1/2. Now I've got a headache...","This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 7 years ago . When hearing about the two-daughter problem, I first thought it to be quite clear (after, of course, at first falling into the trap like many of us), but on the second glance, I encountered some serious problems with my understanding. The original problem seems to be quite easy: Assume that the only thing you know about a man with two kids is that at least one of the kids is a daughter. What is the probability that the other kid is a daughter as well? (Boys and girls are assumed to be born equally often.) After the first impulse (""1/2 of course!""), it becomes clear that it is only 1/3. The problem can be mapped to a situation where from the multitude of families with two children, only those with M/M are ruled out, while the equally often cases F/F, F/M and M/F remain, making F/F only one third of all remaining cases. But now, meet Mr. Smith. I don't know much about him (except that he has two children), but when he approached me, he told me: ""I am so happy! Victoria just got the scholarship she wanted!"" Now what is the probability that Victoria has a sister? Since I only know that Mr. Smith has two children, and one is obviously a girl, I am tempted to map this onto the two-daughter-problem, leading to the answer ""1/3"". But wait! What if I ask Mr. Smith first, if Victoria is his elder daughter? Assume his answer is yes (and ignore any problems with twins - even then one is typically a few seconds ""older"" than the other). So now I know that from the cases (F/F, F/M, M/F), M/F also drops out. And now, the probability for F/F just rose to 1/2. Okay, but what if his answer is no? Then Victoria is the younger one, and F/M drops out. Again, the probability rises to 1/2. So I'm going to just ask him: ""Well, Mr. Smith, is Victoria your elder daughter? Wait - don't answer, because whatever you may answer, it doesn't matter. The probability just rose from 1/3 to 1/2."" Or, even better, I do not even have to ask him, just thinking about the question will shift probabilities to 1/2, which means that the original probability for Victoria having a sister must already have been 1/2. But then the mapping to the two-daughter-problem is obviously false. Where is my error? Making things worse, I could also create a setup where Mr. Smith just tells me: ""I have two kids, and at least one of them is a girl."" I then ask him: ""Oh, can you give me a name of a daughter of yours?"" and he answers: ""Sure. Victoria."" (Side note: I have a gut feeling that this has something to do with how to assume probability distributions behind situations, similar to the Two envelopes problem , but I can't figure this out completely yet.) -------- UPDATE -------- It seems that my error is that the question ""Is Victoria the older child?"" does not change the probabilities. If I know for sure that Mr. Smith was picked from an equally distributed (M/F, F/M, F/F) sample, then the knowledge that Victoria is the older child does not change anything, as was pointed out  here, and the probability for her having a sister is 1/3. But it is very interesting that solely from the sentence ""Victoria just got the scholarship she wanted!"" I can NOT infer that Mr. Smith is indeed chosen from this uniform distribution. Imagine that all kids have the same chance to get a scholarship, and the happy father will tell us if it is the case. Then it is actually twice as probable that Mr. Smith will tell us about his daughter's success if he has two girls, so the weighting of the four possibilities (M/M, F/M, M/F, F/F) is (0, 1, 1, 2). And in this case, the probability of Victoria having a sister is 1/2. So another problem in my reasoning is the mapping of Mr. Smith's statement to the two-daughter-problem. Simply put, without knowing more about the circumstances that led to Mr. Smith telling me about Victoria, I simply can't say if the probability is 1/3 or 1/2. Now I've got a headache...",,['probability']
43,Colliding Bullets,Colliding Bullets,,"I saw this problem yesterday on reddit and I can't come up with a reasonable way to work it out. Once per second, a bullet is fired starting from $x=0$ with a uniformly random speed in $[0,1]$ . If two bullets collide, they both disappear. If we fire $N$ bullets, what is the probability that at least one bullet escapes to infinity? What if we fire an infinite number of bullets? Attempt. If $N$ is two, then it's equal to the probability that the first bullet is faster than the second, which is $\dfrac{1}{2}$ . If $N$ is odd, the probability of three bullets or more colliding in the same spot is $0$ , so we can safely ignore this event. And since collisions destroy two bullets then there will be an odd number of bullets at the end. So at least one escapes to infinity. For infinite bullets, I suspect that no single bullet will escape to infinity, but that they'll reach any arbitrarily big number. Although, I'm not sure on how I'd begin proving it. Is there a closed form solution for even $N$ ? Or some sort of asymptotic behavior?","I saw this problem yesterday on reddit and I can't come up with a reasonable way to work it out. Once per second, a bullet is fired starting from with a uniformly random speed in . If two bullets collide, they both disappear. If we fire bullets, what is the probability that at least one bullet escapes to infinity? What if we fire an infinite number of bullets? Attempt. If is two, then it's equal to the probability that the first bullet is faster than the second, which is . If is odd, the probability of three bullets or more colliding in the same spot is , so we can safely ignore this event. And since collisions destroy two bullets then there will be an odd number of bullets at the end. So at least one escapes to infinity. For infinite bullets, I suspect that no single bullet will escape to infinity, but that they'll reach any arbitrarily big number. Although, I'm not sure on how I'd begin proving it. Is there a closed form solution for even ? Or some sort of asymptotic behavior?","x=0 [0,1] N N \dfrac{1}{2} N 0 N","['probability', 'random-variables', 'asymptotics', 'recreational-mathematics']"
44,"Exam with $12$ yes/no questions (half yes, half no) and $8$ correct needed to pass, is it better to answer randomly or answer exactly 6 times yes?","Exam with  yes/no questions (half yes, half no) and  correct needed to pass, is it better to answer randomly or answer exactly 6 times yes?",12 8,"In an exam with $12$ yes/no questions with $8$ correct needed to pass, is it better to answer randomly or answer exactly $6$ times yes and 6 times no, given that the answer 'yes' is correct for exactly $6$ questions? I have calculated the probability of passing by guessing randomly and it is $$\sum_{k=8}^{12} {{12}\choose{k}}0.5^k0.5^{n-k}=0.194$$ Now given that the answer 'yes' is right exactly $6$ times, is it better to guess 'yes' and 'no' $6$ times each? My idea is that it can be modelled by drawing balls without replacement. The balls we draw are the correct answers to the questions. Looking at the first question, we still know that there are $6$ yes and no's that are correct. The chance that a yes is right is $\frac{6}{12}$ and the chance that a no is right is also $\frac{6}{12}$ . Of course the probability in the next question depends on what the first right answer was. If yes was right, yes will be right with a probability of $5/11$ and a no is right with the chance $6/11$ .  If no was right, the probabilities would change places. Now that we have to make the choice $12$ times and make the distinction which one was right, we get $2^{12}$ paths total. We cannot know what the correct answers to the previous questions were. So we are drawing $12$ balls at once, but from what urn? It cannot contain $24$ balls with $12$ yes and $12$ no's. Is this model even correct? Is there a more elegant way to approach that? I am asking for hints, not solutions, as I'm feeling stuck. Thank you. Edit : After giving @David K's answer more thought, I noticed that the question can be described by the hypergeometric distribution , which yields the desired result.","In an exam with yes/no questions with correct needed to pass, is it better to answer randomly or answer exactly times yes and 6 times no, given that the answer 'yes' is correct for exactly questions? I have calculated the probability of passing by guessing randomly and it is Now given that the answer 'yes' is right exactly times, is it better to guess 'yes' and 'no' times each? My idea is that it can be modelled by drawing balls without replacement. The balls we draw are the correct answers to the questions. Looking at the first question, we still know that there are yes and no's that are correct. The chance that a yes is right is and the chance that a no is right is also . Of course the probability in the next question depends on what the first right answer was. If yes was right, yes will be right with a probability of and a no is right with the chance .  If no was right, the probabilities would change places. Now that we have to make the choice times and make the distinction which one was right, we get paths total. We cannot know what the correct answers to the previous questions were. So we are drawing balls at once, but from what urn? It cannot contain balls with yes and no's. Is this model even correct? Is there a more elegant way to approach that? I am asking for hints, not solutions, as I'm feeling stuck. Thank you. Edit : After giving @David K's answer more thought, I noticed that the question can be described by the hypergeometric distribution , which yields the desired result.",12 8 6 6 \sum_{k=8}^{12} {{12}\choose{k}}0.5^k0.5^{n-k}=0.194 6 6 6 \frac{6}{12} \frac{6}{12} 5/11 6/11 12 2^{12} 12 24 12 12,"['probability', 'combinatorics']"
45,Probability that a quadratic equation has real roots,Probability that a quadratic equation has real roots,,"Problem The premise is almost the same as in this question . I'll restate for convenience. Let $A$ , $B$ , $C$ be independent random variables uniformly distributed between $(-1,+1)$ . What is the probability that the polynomial $Ax^2+Bx+C$ has real roots? Note: The distribution is now $-1$ to $+1$ instead of $0$ to $1$ . My Attempt Preparation When the coefficients are sampled from $\mathcal{U}(0,1)$ , the probability for the discriminant to be non-negative that is, $P(B^2-4AC\geq0) \approx 25.4\% $ . This value can be obtained theoretically as well as experimentally. The link I shared above to the older question has several good answers discussing both approaches. Changing the sampling interval to $(-1, +1)$ makes things a bit difficult from the theoretical perspective. Experimentally, it is rather simple. This is the code I wrote to simulate the experiment for $\mathcal{U}(0,1)$ . Changing it from (0, theta) to (-1, +1) gives me an average probability of $62.7\%$ with a standard deviation of $0.3\%$ I plotted the simulated PDF and CDF. In that order, they are: So I'm aiming to find a CDF that looks like the second image. Theoretical Approach The approach that I find easy to understand is outlined in this answer . Proceeding in a similar manner, we have $$ f_A(a) = \begin{cases} \frac{1}{2}, &-1\leq a\leq+1\\ 0,           &\text{ otherwise} \end{cases} $$ The PDFs are similar for $B$ and $C$ . The CDF for $A$ is $$ F_A(a) = \begin{cases} \frac{a + 1}{2}, &-1\leq a\geq +1\\ 0,&a<-1\\ 1,&a>+1 \end{cases} $$ Let us assume $X=AC$ . I proceed to calculate the CDF for $X$ (for $x>0$ ) as: $$ \begin{align} F_X(x) &= P(X\leq x)\\ &= P(AC\leq x)\\ &= \int_{c=-1}^{+1}P(Ac\leq x)f_C(c)dc\\ &= \frac{1}{2}\left(\int_{c=-1}^{+1}P(Ac\leq x)dc\right)\\ &= \frac{1}{2}\left(\int_{c=-1}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\ \end{align} $$ We take a quick detour to make some observations. First, when $0<c<x$ , we have $\frac{x}{c}>1$ . Similarly, $-x<c<0$ implies $\frac{x}{c}<-1$ . Also, $A$ is constrained to the interval $[-1, +1]$ . Also, we're only interested when $x\geq 0$ because $B^2\geq 0$ . Continuing, the calculation $$ \begin{align} F_X(x) &= \frac{1}{2}\left(\int_{c=-1}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\ &= \frac{1}{2}\left(\int_{c=-1}^{-x}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=-x}^{0}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=0}^{x}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=x}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\ &= \frac{1}{2}\left(\int_{c=-1}^{-x}P\left(A\leq \frac{x}{c}\right)dc + 0 + 1 + \int_{c=x}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\ &= \frac{1}{2}\left(\int_{c=-1}^{-x}\frac{x+c}{2c}dc + 0 + 1 + \int_{c=x}^{+1}\frac{x+c}{2c}dc\right)\\ &= \frac{1}{2}\left(\frac{1}{2}(-x+x(\log(-x)-\log(-1)+1) + 0 + 1 + \frac{1}{2}(-x+x(-\log(x)-\log(1)+1)\right)\\ &= \frac{1}{2}\left(2 + \frac{1}{2}(-x+x(\log(x)) -x + x(-\log(x))\right)\\ &= 1 - x \end{align} $$ I don't think this is correct. My Specific Questions What mistake am I making? Can I even obtain the CDF through integration? Is there an easier way? I used this approach because I was able to understand it well. There are shorter approaches possible (as is evident with the $\mathcal{U}(0,1)$ case) but perhaps I need to read more before I can comprehend them. Any pointers in the right direction would be helpful.","Problem The premise is almost the same as in this question . I'll restate for convenience. Let , , be independent random variables uniformly distributed between . What is the probability that the polynomial has real roots? Note: The distribution is now to instead of to . My Attempt Preparation When the coefficients are sampled from , the probability for the discriminant to be non-negative that is, . This value can be obtained theoretically as well as experimentally. The link I shared above to the older question has several good answers discussing both approaches. Changing the sampling interval to makes things a bit difficult from the theoretical perspective. Experimentally, it is rather simple. This is the code I wrote to simulate the experiment for . Changing it from (0, theta) to (-1, +1) gives me an average probability of with a standard deviation of I plotted the simulated PDF and CDF. In that order, they are: So I'm aiming to find a CDF that looks like the second image. Theoretical Approach The approach that I find easy to understand is outlined in this answer . Proceeding in a similar manner, we have The PDFs are similar for and . The CDF for is Let us assume . I proceed to calculate the CDF for (for ) as: We take a quick detour to make some observations. First, when , we have . Similarly, implies . Also, is constrained to the interval . Also, we're only interested when because . Continuing, the calculation I don't think this is correct. My Specific Questions What mistake am I making? Can I even obtain the CDF through integration? Is there an easier way? I used this approach because I was able to understand it well. There are shorter approaches possible (as is evident with the case) but perhaps I need to read more before I can comprehend them. Any pointers in the right direction would be helpful.","A B C (-1,+1) Ax^2+Bx+C -1 +1 0 1 \mathcal{U}(0,1) P(B^2-4AC\geq0) \approx 25.4\%  (-1, +1) \mathcal{U}(0,1) 62.7\% 0.3\% 
f_A(a) = \begin{cases}
\frac{1}{2}, &-1\leq a\leq+1\\
0,           &\text{ otherwise}
\end{cases}
 B C A 
F_A(a) = \begin{cases}
\frac{a + 1}{2}, &-1\leq a\geq +1\\
0,&a<-1\\
1,&a>+1
\end{cases}
 X=AC X x>0 
\begin{align}
F_X(x) &= P(X\leq x)\\
&= P(AC\leq x)\\
&= \int_{c=-1}^{+1}P(Ac\leq x)f_C(c)dc\\
&= \frac{1}{2}\left(\int_{c=-1}^{+1}P(Ac\leq x)dc\right)\\
&= \frac{1}{2}\left(\int_{c=-1}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\
\end{align}
 0<c<x \frac{x}{c}>1 -x<c<0 \frac{x}{c}<-1 A [-1, +1] x\geq 0 B^2\geq 0 
\begin{align}
F_X(x) &= \frac{1}{2}\left(\int_{c=-1}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\
&= \frac{1}{2}\left(\int_{c=-1}^{-x}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=-x}^{0}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=0}^{x}P\left(A\leq \frac{x}{c}\right)dc + \int_{c=x}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\
&= \frac{1}{2}\left(\int_{c=-1}^{-x}P\left(A\leq \frac{x}{c}\right)dc + 0 + 1 + \int_{c=x}^{+1}P\left(A\leq \frac{x}{c}\right)dc\right)\\
&= \frac{1}{2}\left(\int_{c=-1}^{-x}\frac{x+c}{2c}dc + 0 + 1 + \int_{c=x}^{+1}\frac{x+c}{2c}dc\right)\\
&= \frac{1}{2}\left(\frac{1}{2}(-x+x(\log(-x)-\log(-1)+1) + 0 + 1 + \frac{1}{2}(-x+x(-\log(x)-\log(1)+1)\right)\\
&= \frac{1}{2}\left(2 + \frac{1}{2}(-x+x(\log(x)) -x + x(-\log(x))\right)\\
&= 1 - x
\end{align}
 \mathcal{U}(0,1)","['probability', 'integration', 'probability-distributions', 'uniform-distribution']"
46,Bayes' rule with 3 variables,Bayes' rule with 3 variables,,"I have been using Sebastian Thrun's course on AI and I have encountered a slightly difficult problem with probability theory. He poses the following statement: $$   P(R \mid H,S) = \frac{P(H \mid R,S) \; P(R \mid S)}{P(H \mid S)} $$ I understand he used Bayes' Rule to get the RHS equation, but fail to see how he did this. If somebody could provide a breakdown of the application of the rule in this problem that would be great.","I have been using Sebastian Thrun's course on AI and I have encountered a slightly difficult problem with probability theory. He poses the following statement: $$   P(R \mid H,S) = \frac{P(H \mid R,S) \; P(R \mid S)}{P(H \mid S)} $$ I understand he used Bayes' Rule to get the RHS equation, but fail to see how he did this. If somebody could provide a breakdown of the application of the rule in this problem that would be great.",,"['probability', 'bayes-theorem']"
47,"Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$",Explain why  for every nonnegative random variable,"E(X) = \int_0^\infty (1-F_X (t)) \, dt X","Let $X$ be a non-negative random variable and $F_{X}$ the corresponding CDF. Show,   $$E(X) = \int_0^\infty (1-F_X (t)) \, dt$$   when $X$ has : a) a discrete distribution, b) a continuous distribution. I assumed that for the case of a continuous distribution, since $F_X (t) = \mathbb{P}(X\leq t)$, then $1-F_X (t) = 1- \mathbb{P}(X\leq t) = \mathbb{P}(X>  t)$. Although how useful integrating that is, I really have no idea.","Let $X$ be a non-negative random variable and $F_{X}$ the corresponding CDF. Show,   $$E(X) = \int_0^\infty (1-F_X (t)) \, dt$$   when $X$ has : a) a discrete distribution, b) a continuous distribution. I assumed that for the case of a continuous distribution, since $F_X (t) = \mathbb{P}(X\leq t)$, then $1-F_X (t) = 1- \mathbb{P}(X\leq t) = \mathbb{P}(X>  t)$. Although how useful integrating that is, I really have no idea.",,"['probability', 'probability-theory', 'expected-value', 'faq']"
48,Coin Flip Probability Independent or Not?,Coin Flip Probability Independent or Not?,,"I give you a hat which has $10$ coins inside of it. $1$ out of the $10$ have two heads on it, and the rest of them are fair. You draw a coin at random from the jar and flip it $5$ times. If you flip heads $5$ times in a row, what is the probability that you get heads on your next flip? I tried to approach this question by using Bayes: Let $R$ be the event that the coin with both heads is drawn and $F$ be the event that $5$ heads are flipped in a row. Then $$\begin{align*} P(R|F) &=  \frac{P(F|R)P(R)}{P(F)} \\ &= \frac{1\cdot 1/10}{1\cdot 1/10 + 1/2^5\cdot 9/10} \\ &= 32/41 \end{align*}$$ Thus the probability that you get heads on the next flip is $$\begin{align*} P(H|R)P(R) + P(H|R')P(R') &= 1\cdot 32/41 + 1/2\cdot (1 - 32/41) \\ &= 73/82 \end{align*}$$ However, according to my friend, this is a trick question because the flip after the first $5$ flips is independent of the first $5$ flips, and therefore the correct probability is $$1\cdot 1/10+1/2\cdot 9/10 = 11/20$$ Is this true or not?","I give you a hat which has coins inside of it. out of the have two heads on it, and the rest of them are fair. You draw a coin at random from the jar and flip it times. If you flip heads times in a row, what is the probability that you get heads on your next flip? I tried to approach this question by using Bayes: Let be the event that the coin with both heads is drawn and be the event that heads are flipped in a row. Then Thus the probability that you get heads on the next flip is However, according to my friend, this is a trick question because the flip after the first flips is independent of the first flips, and therefore the correct probability is Is this true or not?","10 1 10 5 5 R F 5 \begin{align*}
P(R|F) &=  \frac{P(F|R)P(R)}{P(F)} \\ &= \frac{1\cdot 1/10}{1\cdot 1/10 + 1/2^5\cdot 9/10} \\ &= 32/41
\end{align*} \begin{align*}
P(H|R)P(R) + P(H|R')P(R') &= 1\cdot 32/41 + 1/2\cdot (1 - 32/41) \\ &= 73/82
\end{align*} 5 5 1\cdot 1/10+1/2\cdot 9/10 = 11/20","['probability', 'statistics']"
49,"If nine coins are tossed, what is the probability that the number of heads is even?","If nine coins are tossed, what is the probability that the number of heads is even?",,"If nine coins are tossed, what is the probability that the number of heads is even? So there can either be 0 heads, 2 heads, 4 heads, 6 heads, or 8 heads. We have $n = 9$ trials, find the probability of each $k$ for $k = 0, 2, 4, 6, 8$ $n = 9, k = 0$ $$\binom{9}{0}\bigg(\frac{1}{2}\bigg)^0\bigg(\frac{1}{2}\bigg)^{9}$$ $n = 9, k = 2$ $$\binom{9}{2}\bigg(\frac{1}{2}\bigg)^2\bigg(\frac{1}{2}\bigg)^{7}$$ $n = 9, k = 4$ $$\binom{9}{4}\bigg(\frac{1}{2}\bigg)^4\bigg(\frac{1}{2}\bigg)^{5}$$ $n = 9, k = 6$ $$\binom{9}{6}\bigg(\frac{1}{2}\bigg)^6\bigg(\frac{1}{2}\bigg)^{3}$$ $n = 9, k = 8$ $$\binom{9}{8}\bigg(\frac{1}{2}\bigg)^8\bigg(\frac{1}{2}\bigg)^{1}$$ Add all of these up: $$=.64$$ so there's a 64% chance of probability?","If nine coins are tossed, what is the probability that the number of heads is even? So there can either be 0 heads, 2 heads, 4 heads, 6 heads, or 8 heads. We have trials, find the probability of each for Add all of these up: so there's a 64% chance of probability?","n = 9 k k = 0, 2, 4, 6, 8 n = 9, k = 0 \binom{9}{0}\bigg(\frac{1}{2}\bigg)^0\bigg(\frac{1}{2}\bigg)^{9} n = 9, k = 2 \binom{9}{2}\bigg(\frac{1}{2}\bigg)^2\bigg(\frac{1}{2}\bigg)^{7} n = 9, k = 4 \binom{9}{4}\bigg(\frac{1}{2}\bigg)^4\bigg(\frac{1}{2}\bigg)^{5} n = 9, k = 6 \binom{9}{6}\bigg(\frac{1}{2}\bigg)^6\bigg(\frac{1}{2}\bigg)^{3} n = 9, k = 8 \binom{9}{8}\bigg(\frac{1}{2}\bigg)^8\bigg(\frac{1}{2}\bigg)^{1} =.64","['probability', 'discrete-mathematics', 'solution-verification']"
50,The expected payoff of a dice game,The expected payoff of a dice game,,There's a question in my Olympiad questions book which I can't seem to solve: You have the option to throw a die up to three times.  You will earn the face value of the die.  You have the option to stop after each throw and walk away with the money earned. The earnings are not additive. What is the expected payoff of this game? I found a solution here but I don't understand it.,There's a question in my Olympiad questions book which I can't seem to solve: You have the option to throw a die up to three times.  You will earn the face value of the die.  You have the option to stop after each throw and walk away with the money earned. The earnings are not additive. What is the expected payoff of this game? I found a solution here but I don't understand it.,,"['probability', 'dice']"
51,Multiplication of a random variable with constant,Multiplication of a random variable with constant,,Suppose $X$ is a random variable which follows standard normal distribution then how is $KX$ ($K$ is constant) defined. Why does it follow a normal distribution with mean $0$ and variance $K^2$.  Thank You.,Suppose $X$ is a random variable which follows standard normal distribution then how is $KX$ ($K$ is constant) defined. Why does it follow a normal distribution with mean $0$ and variance $K^2$.  Thank You.,,"['probability', 'probability-distributions']"
52,Precise definition of the support of a random variable,Precise definition of the support of a random variable,,"$\newcommand{\F}{\mathcal{F}} \newcommand{\powset}[1]{\mathcal{P}(#1)}$ I am reading lecture notes which contradict my understanding of random variables. Suppose we have a probability space $(\Omega, \mathcal{F}, Pr)$ , where $\Omega$ is the set of outcomes $\F \subseteq \powset{\Omega}$ is the collection of events, a $\sigma$ -algebra $\Pr:\Omega\to[0,1]$ is the mapping outcomes to their probabilities. If we take the standard definition of a random variable $X$ , it is actually a function from the sample space to real values, i.e. $X:\Omega \to \mathbb{R}$ . What now confuses me is the precise definition of the term support . According to Wikipedia : the support of a function is the set of points where the function is   not zero valued. Now, applying this definition to our random variable $X$ , these lectures notes say: Random Variables – A random variable is a real valued function defined   on the sample space of an experiment. Associated with each random    variable is a probability density function (pdf) for the random   variable. The  sample space is also called the support of a random   variable. I am not entirely convinced with the line the sample space is also callled the support of a random variable . Why would $\Omega$ be the support of $X$ ? What if the random variable $X$ so happened to map some element $\omega \in \Omega$ to the real number $0$ , then that element would not be in the support? What is even more confusing is, when we talk about support, do we mean that of $X$ or that of the distribution function $\Pr$ ? This answer says that: It is more accurate to speak of the support of the distribution than   that of the support of the random variable. Do we interpret the support to be the set of outcomes in $\Omega$ which have a non-zero probability, the set of values that $X$ can take with non-zero probability? I think being precise is important, although my literature does not seem very rigorous.","I am reading lecture notes which contradict my understanding of random variables. Suppose we have a probability space , where is the set of outcomes is the collection of events, a -algebra is the mapping outcomes to their probabilities. If we take the standard definition of a random variable , it is actually a function from the sample space to real values, i.e. . What now confuses me is the precise definition of the term support . According to Wikipedia : the support of a function is the set of points where the function is   not zero valued. Now, applying this definition to our random variable , these lectures notes say: Random Variables – A random variable is a real valued function defined   on the sample space of an experiment. Associated with each random    variable is a probability density function (pdf) for the random   variable. The  sample space is also called the support of a random   variable. I am not entirely convinced with the line the sample space is also callled the support of a random variable . Why would be the support of ? What if the random variable so happened to map some element to the real number , then that element would not be in the support? What is even more confusing is, when we talk about support, do we mean that of or that of the distribution function ? This answer says that: It is more accurate to speak of the support of the distribution than   that of the support of the random variable. Do we interpret the support to be the set of outcomes in which have a non-zero probability, the set of values that can take with non-zero probability? I think being precise is important, although my literature does not seem very rigorous.","\newcommand{\F}{\mathcal{F}} \newcommand{\powset}[1]{\mathcal{P}(#1)} (\Omega, \mathcal{F}, Pr) \Omega \F \subseteq \powset{\Omega} \sigma \Pr:\Omega\to[0,1] X X:\Omega \to \mathbb{R} X \Omega X X \omega \in \Omega 0 X \Pr \Omega X","['probability', 'probability-theory', 'probability-distributions']"
53,"If a 1 meter rope is cut at two uniformly randomly chosen points, what is the average length of the smallest piece?","If a 1 meter rope is cut at two uniformly randomly chosen points, what is the average length of the smallest piece?",,"If a $1$ meter rope is cut at two uniformly randomly chosen points (to give three pieces), what is the average length of the smallest piece? I got this question as a mathematical puzzle from a friend. It looks similar to MathOverflow question If you break a stick at two points chosen uniformly, the probability the three resulting sticks form a triangle is 1/4. However, in this case, I have to find the expected length of the smallest segment. The two points where the rope is cut are selected uniformly at random. I tried simulating it and I got an average value of $0.1114$. I suspect the answer is $1/9$ but I don't have any rigorous math to back it up. How do I solve this problem?","If a $1$ meter rope is cut at two uniformly randomly chosen points (to give three pieces), what is the average length of the smallest piece? I got this question as a mathematical puzzle from a friend. It looks similar to MathOverflow question If you break a stick at two points chosen uniformly, the probability the three resulting sticks form a triangle is 1/4. However, in this case, I have to find the expected length of the smallest segment. The two points where the rope is cut are selected uniformly at random. I tried simulating it and I got an average value of $0.1114$. I suspect the answer is $1/9$ but I don't have any rigorous math to back it up. How do I solve this problem?",,"['probability', 'expectation']"
54,How to find a random axis or unit vector in 3D?,How to find a random axis or unit vector in 3D?,,"I would like to generate a random axis or unit vector in 3D . In 2D it would be easy, I could just pick an angle between 0 and 2*Pi and use the unit vector pointing in that direction. But in 3D I don't know how can I pick a random point on a surface of a sphere . If I pick two angles the distribution won't be uniform on the surface of the sphere. There would be more points at the poles and less points at the equator. If I pick a random point in the (-1,-1,-1):(1,1,1) cube and normalise it, then there would be more chance that a point gets choosen along the diagonals than from the center of the sides. So thats not good either. But then what's the good solution?","I would like to generate a random axis or unit vector in 3D . In 2D it would be easy, I could just pick an angle between 0 and 2*Pi and use the unit vector pointing in that direction. But in 3D I don't know how can I pick a random point on a surface of a sphere . If I pick two angles the distribution won't be uniform on the surface of the sphere. There would be more points at the poles and less points at the equator. If I pick a random point in the (-1,-1,-1):(1,1,1) cube and normalise it, then there would be more chance that a point gets choosen along the diagonals than from the center of the sides. So thats not good either. But then what's the good solution?",,"['probability', 'geometry', 'random']"
55,Intuition for probability density function as a Radon-Nikodym derivative,Intuition for probability density function as a Radon-Nikodym derivative,,"If someone asked me what it meant for $X$ to be standard normally distributed, I would tell them it means $X$ has probability density function $f(x) = \frac{1}{\sqrt{2\pi}}\mathrm e^{-x^2/2}$ for all $x \in \mathbb{R}$. More rigorously, I could alternatively say that $f$ is the Radon-Nikodym derivative of the distribution measure of $X$ w.r.t. the Lebesgue measure on $\mathbb{R}$, or $f = \frac{\mathrm d \mu_X}{\mathrm d\lambda}$.  As I understand it, $f$ re-weights the values $x \in \mathbb{R}$ in such a way that $$ \int_B \mathrm d\mu_X = \int_B f\, \mathrm d\lambda $$ for all Borel sets $B$.  In particular, the graph of $f$ lies below one everywhere: so it seems like $f$ is re-weighting each $x \in \mathbb{R}$ to a smaller value, but I don't really have any intuition for this.  I'm seeking more insight into viewing $f$ as a change of measure, rather than a sort of distribution describing how likely $X$ is. In addition, does it make sense to ask ""which came first?""  The definition for the standard normal pdf as just a function used to compute probabilities, or the pdf as a change of measure?","If someone asked me what it meant for $X$ to be standard normally distributed, I would tell them it means $X$ has probability density function $f(x) = \frac{1}{\sqrt{2\pi}}\mathrm e^{-x^2/2}$ for all $x \in \mathbb{R}$. More rigorously, I could alternatively say that $f$ is the Radon-Nikodym derivative of the distribution measure of $X$ w.r.t. the Lebesgue measure on $\mathbb{R}$, or $f = \frac{\mathrm d \mu_X}{\mathrm d\lambda}$.  As I understand it, $f$ re-weights the values $x \in \mathbb{R}$ in such a way that $$ \int_B \mathrm d\mu_X = \int_B f\, \mathrm d\lambda $$ for all Borel sets $B$.  In particular, the graph of $f$ lies below one everywhere: so it seems like $f$ is re-weighting each $x \in \mathbb{R}$ to a smaller value, but I don't really have any intuition for this.  I'm seeking more insight into viewing $f$ as a change of measure, rather than a sort of distribution describing how likely $X$ is. In addition, does it make sense to ask ""which came first?""  The definition for the standard normal pdf as just a function used to compute probabilities, or the pdf as a change of measure?",,"['probability', 'probability-theory', 'probability-distributions']"
56,"On average, how many friends would I need to have to have at least one friend's birthday every day? [duplicate]","On average, how many friends would I need to have to have at least one friend's birthday every day? [duplicate]",,"This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 7 years ago . I know that because of the birthday problem, even after 365 friends, you're going to have a lot of doubles and that there's also an infinitesimal chance that even with infinite friends that there's one day left out. But I was curious how many friends you'd need on average to have every day represented (this is ignoring leap day and assuming birthdays are equally distributed). Or to generalize it further, given n unique boxes and you're placing balls in them with an equal 1/n chance for the ball to go into any box, how many balls would you have to place on average before every box had at least one ball?","This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 7 years ago . I know that because of the birthday problem, even after 365 friends, you're going to have a lot of doubles and that there's also an infinitesimal chance that even with infinite friends that there's one day left out. But I was curious how many friends you'd need on average to have every day represented (this is ignoring leap day and assuming birthdays are equally distributed). Or to generalize it further, given n unique boxes and you're placing balls in them with an equal 1/n chance for the ball to go into any box, how many balls would you have to place on average before every box had at least one ball?",,"['probability', 'coupon-collector']"
57,How many fair dice exist?,How many fair dice exist?,,"We know a coin is a fair die with a 50-50 probability for two alternatives. Similarly, all five Platonic solids are fair dice. That makes six solids that can be fair dice, but can there be more? One example could be a two tetrahedra pasted together along one face. The resulting solid is not platonic since two vertices have three faces meeting at them while three of them have four faces meeting at them. However, this too can be a regular die as far as I can tell since all faces are identical. The question is, how many solids can exist that can be used as fair dice?","We know a coin is a fair die with a 50-50 probability for two alternatives. Similarly, all five Platonic solids are fair dice. That makes six solids that can be fair dice, but can there be more? One example could be a two tetrahedra pasted together along one face. The resulting solid is not platonic since two vertices have three faces meeting at them while three of them have four faces meeting at them. However, this too can be a regular die as far as I can tell since all faces are identical. The question is, how many solids can exist that can be used as fair dice?",,"['probability', 'geometry', 'polyhedra', 'platonic-solids']"
58,Why is this coin-flipping probability problem unsolved?,Why is this coin-flipping probability problem unsolved?,,"You play a game flipping a fair coin.  You may stop after any trial, at which point you are paid in dollars  the percentage of heads flipped.  So if on the first trial you flip a head, you should stop and earn \$100 because you have 100% heads.  If you flip a tail then a head, you could either stop and earn \$50, or continue on, hoping the ratio will exceed 1/2.  This second strategy is superior. A paper by Medina and Zeilberger ( arXiv:0907.0032v2 [math.PR] ) says that it is an unsolved problem to determine if it is better to continue or stop after you have flipped 5 heads in 8 trials: accept \$62.50 or hope for more.  It is easy to simulate this problem and it is clear from even limited experimental data that it is better to continue (perhaps more than 70% chance you'll improve over \$62.50): My question is basically: Why is this difficult to prove?  Presumably it is not that difficult to write out an expression for the expectation of exceeding 5/8 in terms of the cumulative binomial distribution. ( 5 Dec 2013 ). A paper on this topic was just published: Olle Häggström, Johan Wästlund. ""Rigorous computer analysis of the Chow-Robbins game."" (pre-journal arXiv link ). The American Mathematical Monthly , Vol. 120, No. 10, December 2013. ( Jstor link ). From the Abstract: ""In particular, we confirm that with 5 heads and 3 tails, stopping is optimal.""","You play a game flipping a fair coin.  You may stop after any trial, at which point you are paid in dollars  the percentage of heads flipped.  So if on the first trial you flip a head, you should stop and earn \$100 because you have 100% heads.  If you flip a tail then a head, you could either stop and earn \$50, or continue on, hoping the ratio will exceed 1/2.  This second strategy is superior. A paper by Medina and Zeilberger ( arXiv:0907.0032v2 [math.PR] ) says that it is an unsolved problem to determine if it is better to continue or stop after you have flipped 5 heads in 8 trials: accept \$62.50 or hope for more.  It is easy to simulate this problem and it is clear from even limited experimental data that it is better to continue (perhaps more than 70% chance you'll improve over \$62.50): My question is basically: Why is this difficult to prove?  Presumably it is not that difficult to write out an expression for the expectation of exceeding 5/8 in terms of the cumulative binomial distribution. ( 5 Dec 2013 ). A paper on this topic was just published: Olle Häggström, Johan Wästlund. ""Rigorous computer analysis of the Chow-Robbins game."" (pre-journal arXiv link ). The American Mathematical Monthly , Vol. 120, No. 10, December 2013. ( Jstor link ). From the Abstract: ""In particular, we confirm that with 5 heads and 3 tails, stopping is optimal.""",,"['probability', 'probability-theory', 'binomial-distribution', 'simulation']"
59,"Good books on ""advanced"" probabilities","Good books on ""advanced"" probabilities",,"what are some good books on probabilities  and measure theory? I already know basic probabalities, but I'm interested in sigma-algrebas, filtrations, stopping times etc, with possibly examples of ""real life"" situations where they would be used thanks","what are some good books on probabilities  and measure theory? I already know basic probabalities, but I'm interested in sigma-algrebas, filtrations, stopping times etc, with possibly examples of ""real life"" situations where they would be used thanks",,"['probability', 'probability-theory', 'reference-request', 'book-recommendation']"
60,Intuitive interpretation of limsup and liminf of sequences of sets?,Intuitive interpretation of limsup and liminf of sequences of sets?,,"What is an intuitive interpretation of the 'events' $$\limsup A_n:=\bigcap_{n=0}^{\infty}\bigcup_{k=n}^{\infty}A_k$$ and $$\liminf A_n:=\bigcup_{n=0}^{\infty}\bigcap_{k=n}^{\infty}A_k$$ when $A_n$ are subsets of a measured space $(\Omega, F,\mu)$. Of the first it should be that 'an infinite number of those events is verified', but I don't see how to explain (or interpret this). Thanks for any help!","What is an intuitive interpretation of the 'events' $$\limsup A_n:=\bigcap_{n=0}^{\infty}\bigcup_{k=n}^{\infty}A_k$$ and $$\liminf A_n:=\bigcup_{n=0}^{\infty}\bigcap_{k=n}^{\infty}A_k$$ when $A_n$ are subsets of a measured space $(\Omega, F,\mu)$. Of the first it should be that 'an infinite number of those events is verified', but I don't see how to explain (or interpret this). Thanks for any help!",,"['probability', 'measure-theory', 'elementary-set-theory', 'limsup-and-liminf']"
61,"Regarding a Coin Toss Experiment by Neil DeGrasse Tyson, and its validity","Regarding a Coin Toss Experiment by Neil DeGrasse Tyson, and its validity",,"In one of his interviews, Clip Link , Neil DeGrasse Tyson discusses a coin toss experiment. It goes something like this: Line up 1000 people, each given a coin, to be flipped simultaneously Ask each one to flip if heads the person can continue If the person gets tails they are out The game continues until 1* person remains He says the ""winner"" should not feel too surprised or lucky because there would be another winner if we re-run the experiment! This leads him to talk about our place in the Universe. I realised, however, that there need not be a winner at all , and that the winner should feel lucky and be surprised! (Because the last, say, three people can all flip tails) Then, I ran an experiment by writing a program with the following parameters: Bias of the coin : 0.0001 - 0.8999  (8999 values) Number of people : 10000 Number of times experiment run per Bias : 1000 I plotted the Probability of 1 Winner vs Bias The plot was interesting with zig-zag for low bias (for heads) and a smooth one after p = 0.2 . (Also, there is a 73% chance of a single winner for a fair coin). Is there an analytic expression for the function $$f(p) = (\textrm{probability of $1$ winner with a coin of bias $p$}) \textbf{?}$$ I tried doing something and got here: $$ f(p)=p\left(\sum_{i=0}^{e n d} X_i=N-1\right) $$ where $X_i=\operatorname{Binomial}\left(N-\sum_{j=0}^{i-1} X_j, p\right)$ and $X_0=\operatorname{Binomial}(N, p)$","In one of his interviews, Clip Link , Neil DeGrasse Tyson discusses a coin toss experiment. It goes something like this: Line up 1000 people, each given a coin, to be flipped simultaneously Ask each one to flip if heads the person can continue If the person gets tails they are out The game continues until 1* person remains He says the ""winner"" should not feel too surprised or lucky because there would be another winner if we re-run the experiment! This leads him to talk about our place in the Universe. I realised, however, that there need not be a winner at all , and that the winner should feel lucky and be surprised! (Because the last, say, three people can all flip tails) Then, I ran an experiment by writing a program with the following parameters: Bias of the coin : 0.0001 - 0.8999  (8999 values) Number of people : 10000 Number of times experiment run per Bias : 1000 I plotted the Probability of 1 Winner vs Bias The plot was interesting with zig-zag for low bias (for heads) and a smooth one after p = 0.2 . (Also, there is a 73% chance of a single winner for a fair coin). Is there an analytic expression for the function I tried doing something and got here: where and","f(p) = (\textrm{probability of 1 winner with a coin of bias p}) \textbf{?} 
f(p)=p\left(\sum_{i=0}^{e n d} X_i=N-1\right)
 X_i=\operatorname{Binomial}\left(N-\sum_{j=0}^{i-1} X_j, p\right) X_0=\operatorname{Binomial}(N, p)","['probability', 'combinatorics', 'graphing-functions', 'binomial-distribution', 'analyticity']"
62,"What is the difference between ""probability density function"" and ""probability distribution function""?","What is the difference between ""probability density function"" and ""probability distribution function""?",,Whats the difference between probability density function and probability distribution function ?,Whats the difference between probability density function and probability distribution function ?,,"['probability', 'probability-distributions', 'terminology', 'density-function']"
63,Identity for simple 1D random walk,Identity for simple 1D random walk,,"The question is to find a purely probabilistic proof of the following identity, valid for every integer $n\geqslant1$, where $(S_n)_{n\geqslant0}$ denotes a standard simple random walk: $$ E[(S_n)^2;S_{2n}=0]=\frac{n}2\,P[S_{2n-2}=0]. $$ Standard simple random walk is defined as $S_0=0$ and $S_n=\sum\limits_{k=1}^nX_k$ for every $n\geqslant1$, where $(X_k)_{k\geqslant1}$ is an i.i.d. sequence such that $P[X_k=+1]=P[X_k=-1]=\frac12$. Of course, the RHS of the identity is $$ \frac{n}{2^{2n-1}}\,{2n-2\choose n-1}. $$ For a combinatorial proof, see this MSE question and its comments. For an accessible introduction to the subject, see the corresponding chapter of the Chance project .","The question is to find a purely probabilistic proof of the following identity, valid for every integer $n\geqslant1$, where $(S_n)_{n\geqslant0}$ denotes a standard simple random walk: $$ E[(S_n)^2;S_{2n}=0]=\frac{n}2\,P[S_{2n-2}=0]. $$ Standard simple random walk is defined as $S_0=0$ and $S_n=\sum\limits_{k=1}^nX_k$ for every $n\geqslant1$, where $(X_k)_{k\geqslant1}$ is an i.i.d. sequence such that $P[X_k=+1]=P[X_k=-1]=\frac12$. Of course, the RHS of the identity is $$ \frac{n}{2^{2n-1}}\,{2n-2\choose n-1}. $$ For a combinatorial proof, see this MSE question and its comments. For an accessible introduction to the subject, see the corresponding chapter of the Chance project .",,"['probability', 'random-walk']"
64,Is it possible to get all possible sums with the same probability if I throw two unfair dice together?,Is it possible to get all possible sums with the same probability if I throw two unfair dice together?,,"I throw 2 unfair dice, suppose that $p_i$ is the probability that the first die can give an $i$ if I throw it, for $i =1,2,3,..6$ and $q_i$ the probability that the second die can give an $i$ . If I throw the dice together, is it possible to get all possible sums $2,3,4,...12$ with the same probability? Here's what I've tried so far, the probability that I get a $2$ if I throw both dice is $p_1q_1$ , the probability that I get $3$ is $p_1q_2+p_2q_1$ , and generally the probability that I get $n$ is $$\sum_{i+j=n} p_iq_j$$ where $i=1,2,...6$ , $j=1,2,...6$ . So now in order for all possible sums to appear with the same probability, it must be true that $$p_1q_1=p_1q_2+p_2q_1$$ $$p_1q_2+p_2q_1=p_1q_3+p_2q_2+p_3q_1$$ $$........$$ has a solution, this is where I am stuck I can't find a way to prove that the system above has a solution, can you help?","I throw 2 unfair dice, suppose that is the probability that the first die can give an if I throw it, for and the probability that the second die can give an . If I throw the dice together, is it possible to get all possible sums with the same probability? Here's what I've tried so far, the probability that I get a if I throw both dice is , the probability that I get is , and generally the probability that I get is where , . So now in order for all possible sums to appear with the same probability, it must be true that has a solution, this is where I am stuck I can't find a way to prove that the system above has a solution, can you help?","p_i i i =1,2,3,..6 q_i i 2,3,4,...12 2 p_1q_1 3 p_1q_2+p_2q_1 n \sum_{i+j=n} p_iq_j i=1,2,...6 j=1,2,...6 p_1q_1=p_1q_2+p_2q_1 p_1q_2+p_2q_1=p_1q_3+p_2q_2+p_3q_1 ........","['probability', 'dice']"
65,Does Monty Hall logic apply to this real world situation?,Does Monty Hall logic apply to this real world situation?,,"I recently posted a tweet claiming I had encountered a real life Monty Hall dilemma . Based on the resulting discussion, I'm not sure I have. The Scenario I have 3 tacos (A,B,C) where tacos A and C are filled with beans, and taco B is filled with steak. I have no foreknowledge of the filling of any tacos. My wife only knows that taco C is filled with beans. My wife and I both know that I want steak. After I pick taco A, my wife informs me taco C is filled with beans. I switch my pick from taco A to taco B, thinking the logic behind the Monty Hall problem is relevant to my choice. Edit for clarity Timing:  The contents of taco C were not revealed to me until after I had made my selection of taco A. My knowledge of what my wife knew:  When she told me the contents of taco C, I knew that she had previously opened taco C.  I also knew that she had no other knowledge of the contents of the other tacos. Questions Even though my wife does not know the fillings of all the tacos, does her revealing that taco C is definitively not the taco I want after I've made my initial selection satisfy the logic for me switching (from A to B) if I thought it would give me a 66.6% chance of getting the steak taco? If this is not a Monty Hall situation, is there any benefit in me switching?","I recently posted a tweet claiming I had encountered a real life Monty Hall dilemma . Based on the resulting discussion, I'm not sure I have. The Scenario I have 3 tacos (A,B,C) where tacos A and C are filled with beans, and taco B is filled with steak. I have no foreknowledge of the filling of any tacos. My wife only knows that taco C is filled with beans. My wife and I both know that I want steak. After I pick taco A, my wife informs me taco C is filled with beans. I switch my pick from taco A to taco B, thinking the logic behind the Monty Hall problem is relevant to my choice. Edit for clarity Timing:  The contents of taco C were not revealed to me until after I had made my selection of taco A. My knowledge of what my wife knew:  When she told me the contents of taco C, I knew that she had previously opened taco C.  I also knew that she had no other knowledge of the contents of the other tacos. Questions Even though my wife does not know the fillings of all the tacos, does her revealing that taco C is definitively not the taco I want after I've made my initial selection satisfy the logic for me switching (from A to B) if I thought it would give me a 66.6% chance of getting the steak taco? If this is not a Monty Hall situation, is there any benefit in me switching?",,"['probability', 'proof-explanation', 'monty-hall']"
66,Expected number of people to not get shot?,Expected number of people to not get shot?,,"Suppose $n$ gangsters are randomly positioned in a square room such that the positions of any three gangsters do not form an isosceles triangle. At midnight, each gangster shoots the person that is nearest to him. (A person can get shot more than once but each person can only shoot one person) How many people are expected to survive? (I.e. what is the expected value of the number of people who do not get shot?) E.g. For one person, the expected value is 1. For two people, it is zero since they both get shot. For three, the value is 1 since they form the vertices of a scalene triangle. I'm just interested in what happens as $n \rightarrow \infty$. Thanks for your help!","Suppose $n$ gangsters are randomly positioned in a square room such that the positions of any three gangsters do not form an isosceles triangle. At midnight, each gangster shoots the person that is nearest to him. (A person can get shot more than once but each person can only shoot one person) How many people are expected to survive? (I.e. what is the expected value of the number of people who do not get shot?) E.g. For one person, the expected value is 1. For two people, it is zero since they both get shot. For three, the value is 1 since they form the vertices of a scalene triangle. I'm just interested in what happens as $n \rightarrow \infty$. Thanks for your help!",,"['probability', 'recreational-mathematics', 'puzzle', 'average', 'geometric-probability']"
67,What is the difference between Average and Expected value?,What is the difference between Average and Expected value?,,"Question : What is the difference between Average and Expected value? I have been going through the definition of expected value on Wikipedia beneath all that jargon it seems that the expected value of a distribution is the average value of the distribution. Did I get it right ? If yes, then what is the point of introducing a new term ? Why not just stick with the average value of the distribution ?","Question : What is the difference between Average and Expected value? I have been going through the definition of expected value on Wikipedia beneath all that jargon it seems that the expected value of a distribution is the average value of the distribution. Did I get it right ? If yes, then what is the point of introducing a new term ? Why not just stick with the average value of the distribution ?",,"['probability', 'definition', 'expected-value', 'average']"
68,Determining variance from sum of two random correlated variables,Determining variance from sum of two random correlated variables,,"I understand that the variance of the sum of two independent normally distributed random variables is the sum of the variances, but how does this change when the two random variables are correlated?","I understand that the variance of the sum of two independent normally distributed random variables is the sum of the variances, but how does this change when the two random variables are correlated?",,"['probability', 'probability-theory', 'standard-deviation', 'correlation', 'variance']"
69,Convergence of $np(n)$ where $p(n)=\sum_{j=\lceil n/2\rceil}^{n-1} {p(j)\over j}$,Convergence of  where,np(n) p(n)=\sum_{j=\lceil n/2\rceil}^{n-1} {p(j)\over j},"Some years ago I was interested in the following Markov chain whose state space is the positive integers. The chain begins at state ""1"",  and from state ""n"" the chain next jumps to a state uniformly selected from {n+1,n+2,...,2n}. As time goes on, this chain goes to infinity, with occasional large jumps. In any case, the chain is quite unlikely to hit any particular large n. If you define p(n) to be the probability that this chain visits state ""n"", then p(n) goes to zero like c/n for some  constant c. In fact, $$    np(n) \to c = {1\over 2\log(2)-1} = 2.588699. \tag1$$ In order to prove this convergence, I recast it as an analytic  problem. Using the Markov property, you can see that the sequence satisfies: $$   p(1)=1\quad\mbox{ and }\quad p(n)=\sum_{\lceil n/2\rceil}^{n-1} {p(j)\over j}\mbox{ for }n>1.  \tag2$$ For some weeks, using generating functions etc. I tried and failed to find an analytic proof of the convergence in (1). Finally, at a conference in 2003 Tom Mountford showed me a (non-trivial) probabilistic proof. So the result is true, but since then I've continued to wonder if I missed something obvious. Perhaps there is a standard technique for showing that (2) implies (1). Question: Is there a direct (short?, analytic?) proof of (1)? Perhaps someone who understands sequences better than I do could take a shot at this. Update: I'm digging through my old notes on this. I now remember that I had a proof (using generating functions) that if $\ np(n)$ converges, then the limit is $1\over{2\log (2)-1}$. It was the convergence that eluded me. I also found some curiosities like: $\sum_{n=1}^\infty {p(n)\over n(2n+1)}={1\over 2}.$ Another update : Here is the conditional result mentioned above. As in Qiaochu's answer, define $Q$ to be the generating function of $p(n)/n$, that is,  $Q(t)=\sum_{n=1}^\infty {p(n)\over n} t^n$ for $0\leq t<1$.  Differentiating gives  $$Q^\prime(t)=1+{Q(t)-Q(t^2)\over 1-t}.$$  This is slightly different from Qiaochu's expression because  $p(n)\neq \sum_{j=\lceil n/2\rceil}^{n-1} {p(j)\over j}$ when $n=1$,  so that $p(1)$ has to be treated  separately. Differentiating again and multiplying by $1-t$, we get  $$(1-t)Q^{\prime\prime}(t)=-1+2\left[Q^\prime(t)-t Q^\prime(t^2)\right],$$  that is,  $$(1-t)\sum_{j=0}^\infty (j+1) p(j+2) t^j =  -1+2\left[\sum_{j=1}^\infty (jp(j)) {t^j-t^{2j}\over j}\right].$$ Assume that $\lim_n np(n)=c$ exists. Letting $t\to 1$ above the left hand side gives $c$,  while the right hand side is $-1+2c\log(2)$ and hence $c={1\over 2\log(2)-1}$. Note: $\sum_{j=1}^\infty {t^j-t^{2j}\over j}=\log(1+t).$ New update: (Sept. 2) Here's an alternative proof of the conditional result that my colleague Terry Gannon  showed me in 2003. Start with the sum $\sum_{n=2}^{2N}\ p(n)$, substitute the formula in the title,  exchange the variables $j$ and $n$, and rearrange to establish the identity: $${1\over 2}=\sum_{j=N+1}^{2N} {j-N\over j}\ {p(j)}.$$ If $jp(j)\to c$, then $1/2=\lim_{N\to\infty} \sum_{j=N+1}^{2N} {j-N\over j^2}\  c=(\log(2)-1/2)\  c,$ so that $c={1\over 2\log(2)-1}$. New update: (Sept. 8) Despite the nice answers and interesting discussion below, I am still holding out for an (nice?, short?) analytic proof of convergence. Basic Tauberian theory is allowed :) New update: (Sept 13) I have posted a sketch of the probabilistic proof of convergence under ""A fun and frustrating recurrence sequence"" in the ""Publications"" section of my homepage. Final Update: (Sept 15th) The deadline is approaching, so I have decided to award the bounty to T..  Modulo the details(!), it seems that the probabilistic approach is the most likely to lead to a proof. My sincere thanks to everyone who worked on the problem, including those who tried it but  didn't post anything. In a sense, I did get an answer to my question: there doesn't seem to be an easy, or standard proof to handle this particular sequence.","Some years ago I was interested in the following Markov chain whose state space is the positive integers. The chain begins at state ""1"",  and from state ""n"" the chain next jumps to a state uniformly selected from {n+1,n+2,...,2n}. As time goes on, this chain goes to infinity, with occasional large jumps. In any case, the chain is quite unlikely to hit any particular large n. If you define p(n) to be the probability that this chain visits state ""n"", then p(n) goes to zero like c/n for some  constant c. In fact, $$    np(n) \to c = {1\over 2\log(2)-1} = 2.588699. \tag1$$ In order to prove this convergence, I recast it as an analytic  problem. Using the Markov property, you can see that the sequence satisfies: $$   p(1)=1\quad\mbox{ and }\quad p(n)=\sum_{\lceil n/2\rceil}^{n-1} {p(j)\over j}\mbox{ for }n>1.  \tag2$$ For some weeks, using generating functions etc. I tried and failed to find an analytic proof of the convergence in (1). Finally, at a conference in 2003 Tom Mountford showed me a (non-trivial) probabilistic proof. So the result is true, but since then I've continued to wonder if I missed something obvious. Perhaps there is a standard technique for showing that (2) implies (1). Question: Is there a direct (short?, analytic?) proof of (1)? Perhaps someone who understands sequences better than I do could take a shot at this. Update: I'm digging through my old notes on this. I now remember that I had a proof (using generating functions) that if $\ np(n)$ converges, then the limit is $1\over{2\log (2)-1}$. It was the convergence that eluded me. I also found some curiosities like: $\sum_{n=1}^\infty {p(n)\over n(2n+1)}={1\over 2}.$ Another update : Here is the conditional result mentioned above. As in Qiaochu's answer, define $Q$ to be the generating function of $p(n)/n$, that is,  $Q(t)=\sum_{n=1}^\infty {p(n)\over n} t^n$ for $0\leq t<1$.  Differentiating gives  $$Q^\prime(t)=1+{Q(t)-Q(t^2)\over 1-t}.$$  This is slightly different from Qiaochu's expression because  $p(n)\neq \sum_{j=\lceil n/2\rceil}^{n-1} {p(j)\over j}$ when $n=1$,  so that $p(1)$ has to be treated  separately. Differentiating again and multiplying by $1-t$, we get  $$(1-t)Q^{\prime\prime}(t)=-1+2\left[Q^\prime(t)-t Q^\prime(t^2)\right],$$  that is,  $$(1-t)\sum_{j=0}^\infty (j+1) p(j+2) t^j =  -1+2\left[\sum_{j=1}^\infty (jp(j)) {t^j-t^{2j}\over j}\right].$$ Assume that $\lim_n np(n)=c$ exists. Letting $t\to 1$ above the left hand side gives $c$,  while the right hand side is $-1+2c\log(2)$ and hence $c={1\over 2\log(2)-1}$. Note: $\sum_{j=1}^\infty {t^j-t^{2j}\over j}=\log(1+t).$ New update: (Sept. 2) Here's an alternative proof of the conditional result that my colleague Terry Gannon  showed me in 2003. Start with the sum $\sum_{n=2}^{2N}\ p(n)$, substitute the formula in the title,  exchange the variables $j$ and $n$, and rearrange to establish the identity: $${1\over 2}=\sum_{j=N+1}^{2N} {j-N\over j}\ {p(j)}.$$ If $jp(j)\to c$, then $1/2=\lim_{N\to\infty} \sum_{j=N+1}^{2N} {j-N\over j^2}\  c=(\log(2)-1/2)\  c,$ so that $c={1\over 2\log(2)-1}$. New update: (Sept. 8) Despite the nice answers and interesting discussion below, I am still holding out for an (nice?, short?) analytic proof of convergence. Basic Tauberian theory is allowed :) New update: (Sept 13) I have posted a sketch of the probabilistic proof of convergence under ""A fun and frustrating recurrence sequence"" in the ""Publications"" section of my homepage. Final Update: (Sept 15th) The deadline is approaching, so I have decided to award the bounty to T..  Modulo the details(!), it seems that the probabilistic approach is the most likely to lead to a proof. My sincere thanks to everyone who worked on the problem, including those who tried it but  didn't post anything. In a sense, I did get an answer to my question: there doesn't seem to be an easy, or standard proof to handle this particular sequence.",,['sequences-and-series']
70,Who discovered this number-guessing paradox?,Who discovered this number-guessing paradox?,,"In this math.se post I described in some detail a certain paradox, which I will summarize: $A$ writes two distinct numbers on slips of paper. $B$ selects one of the slips at random (equiprobably), examines its number, and then, without having seen the other number, predicts whether the number on her slip is the larger or smaller of the two.   $B$ can obviously achieve success with probability $\frac12$ by flipping a coin, and it seems impossible that she could do better. However, there is a strategy $B$ can follow that is guaranteed to  produce a correct prediction with probability strictly greater than $\frac12$. The strategy, in short, is: Prior to selecting the slip, $B$ should select some probability distribution $D$ on $\Bbb R$ that is everywhere positive.  A normal distribution will suffice. $B$ should generate a random number $y\in \Bbb R$ distributed according to $D$. Let $x$ be the number on the slip selected by $B$.  If $x>y$, then $B$ predicts that $x$ is the larger of the two numbers; if $x<y$ she predicts that $x$ is the smaller of the two numbers. ($y=x$ occurs with probability $0$ and can be disregarded.) I omit the analysis that shows that this method predicts correctly with probability strictly greater than $\frac12$; the details are in the other post. I ended the other post with “I have heard this paradox attributed to Feller, but I'm afraid I don't have a reference.” I would like a reference.","In this math.se post I described in some detail a certain paradox, which I will summarize: $A$ writes two distinct numbers on slips of paper. $B$ selects one of the slips at random (equiprobably), examines its number, and then, without having seen the other number, predicts whether the number on her slip is the larger or smaller of the two.   $B$ can obviously achieve success with probability $\frac12$ by flipping a coin, and it seems impossible that she could do better. However, there is a strategy $B$ can follow that is guaranteed to  produce a correct prediction with probability strictly greater than $\frac12$. The strategy, in short, is: Prior to selecting the slip, $B$ should select some probability distribution $D$ on $\Bbb R$ that is everywhere positive.  A normal distribution will suffice. $B$ should generate a random number $y\in \Bbb R$ distributed according to $D$. Let $x$ be the number on the slip selected by $B$.  If $x>y$, then $B$ predicts that $x$ is the larger of the two numbers; if $x<y$ she predicts that $x$ is the smaller of the two numbers. ($y=x$ occurs with probability $0$ and can be disregarded.) I omit the analysis that shows that this method predicts correctly with probability strictly greater than $\frac12$; the details are in the other post. I ended the other post with “I have heard this paradox attributed to Feller, but I'm afraid I don't have a reference.” I would like a reference.",,"['probability', 'reference-request', 'math-history', 'paradoxes']"
71,Computing the Expectation of the Square of a Random Variable: $ \text{E}[X^{2}] $.,Computing the Expectation of the Square of a Random Variable: ., \text{E}[X^{2}] ,"What is the rule for computing $ \text{E}[X^{2}] $, where $ \text{E} $ is the expectation operator and $ X $ is a random variable? Let $ S $ be a sample space, and let $ p(x) $ denote the probability mass function of $ X $. Is $$ \text{E}[X^{2}] = \sum_{x \in S} x^{2} \cdot p(x), $$ or do I also need to square the $ x $ appearing in $ p(x) $?","What is the rule for computing $ \text{E}[X^{2}] $, where $ \text{E} $ is the expectation operator and $ X $ is a random variable? Let $ S $ be a sample space, and let $ p(x) $ denote the probability mass function of $ X $. Is $$ \text{E}[X^{2}] = \sum_{x \in S} x^{2} \cdot p(x), $$ or do I also need to square the $ x $ appearing in $ p(x) $?",,"['probability', 'random-variables']"
72,Probability that n points on a circle are in one semicircle,Probability that n points on a circle are in one semicircle,,"Choose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.","Choose n points randomly from a circle, how to calculate the probability that all the points are in one semicircle? Any hint is appreciated.",,"['probability', 'geometric-probability']"
73,The expected outcome of a random game of chess?,The expected outcome of a random game of chess?,,"Imagine a game of chess where both players generate a list of legal moves and pick one uniformly at random. Q : What is the expected outcome for white? 1 point for black checkmated, 0.5 for a draw, 0 for white checkmated.  So the expected outcome is given by $$\mathrm{Pr}[\text{black checkmated}]+0.5\ \mathrm{Pr}[\text{draw}].$$ Neither player resigns, nor are there any draw offers or claims. As a chess player, I'm curious if white (who plays first) has some advantage here. I'm not expecting an exact answer to be possible.  Partial results (e.g. that the expectation is >0.5) and experimental results are welcome.  (The expectation is not 0 or 1, since there are possible games where white does not win and where black does not win.) I'm guessing this has been looked at before, so I decided to ask first (rather than implement a chess engine that makes random moves and hope to find something other than ""draw, draw, draw, draw, ..."").  Searching for ""random game of chess"" lists Chess960 and other randomized variants, which is not what I want. Technicalities: En passant capturing, castling, pawn promotion, etc. all apply as usual. The FIDE Laws of Chess will be updated 1 July 2014 with the following: 9.6 If one or both of the following occur(s) then the game is drawn: a. the same position has appeared, as in 9.2b, for at least five   consecutive alternate moves by each player. b. any consecutive   series of 75 moves have been completed by each player without the   movement of any pawn and without any capture. If the last move   resulted in checkmate, that shall take precedence. This means that games of chess must be finite, and thus there is a finite number of possible games of chess.","Imagine a game of chess where both players generate a list of legal moves and pick one uniformly at random. Q : What is the expected outcome for white? 1 point for black checkmated, 0.5 for a draw, 0 for white checkmated.  So the expected outcome is given by $$\mathrm{Pr}[\text{black checkmated}]+0.5\ \mathrm{Pr}[\text{draw}].$$ Neither player resigns, nor are there any draw offers or claims. As a chess player, I'm curious if white (who plays first) has some advantage here. I'm not expecting an exact answer to be possible.  Partial results (e.g. that the expectation is >0.5) and experimental results are welcome.  (The expectation is not 0 or 1, since there are possible games where white does not win and where black does not win.) I'm guessing this has been looked at before, so I decided to ask first (rather than implement a chess engine that makes random moves and hope to find something other than ""draw, draw, draw, draw, ..."").  Searching for ""random game of chess"" lists Chess960 and other randomized variants, which is not what I want. Technicalities: En passant capturing, castling, pawn promotion, etc. all apply as usual. The FIDE Laws of Chess will be updated 1 July 2014 with the following: 9.6 If one or both of the following occur(s) then the game is drawn: a. the same position has appeared, as in 9.2b, for at least five   consecutive alternate moves by each player. b. any consecutive   series of 75 moves have been completed by each player without the   movement of any pawn and without any capture. If the last move   resulted in checkmate, that shall take precedence. This means that games of chess must be finite, and thus there is a finite number of possible games of chess.",,"['probability', 'recreational-mathematics', 'combinatorial-game-theory']"
74,Expected Value of a Binomial distribution?,Expected Value of a Binomial distribution?,,"If $\mathrm P(X=k)=\binom nkp^k(1-p)^{n-k}$ for a binomial distribution, then from the definition of the expected value $$\mathrm E(X) = \sum^n_{k=0}k\mathrm P(X=k)=\sum^n_{k=0}k\binom nkp^k(1-p)^{n-k}$$ but the expected value of a Binomal distribution is $np$,  so how is $$\sum^n_{k=0}k\binom nkp^k(1-p)^{n-k}=np$$","If $\mathrm P(X=k)=\binom nkp^k(1-p)^{n-k}$ for a binomial distribution, then from the definition of the expected value $$\mathrm E(X) = \sum^n_{k=0}k\mathrm P(X=k)=\sum^n_{k=0}k\binom nkp^k(1-p)^{n-k}$$ but the expected value of a Binomal distribution is $np$,  so how is $$\sum^n_{k=0}k\binom nkp^k(1-p)^{n-k}=np$$",,"['probability', 'combinatorics']"
75,"On average, how many times must I roll a dice until I get a $6$?","On average, how many times must I roll a dice until I get a ?",6,"On average, how many times must I roll a dice until I get a $6$? I got this question from a book called Fifty Challenging Problems in Probability. The answer is $6$, and I understand the solution the book has given me. However, I want to know why the following logic does not work: The chance that we do not get a $6$ is $5/6$. In order to find the number of dice rolls needed, I want the probability of there being a $6$ in $n$ rolls being $1/2$ in order to find the average. So I solve the equation $(5/6)^n=1/2$, which gives me $n=3.8$-ish. That number makes sense to me intuitively, where the number $6$ does not make sense intuitively. I feel like on average, I would need to roll about $3$-$4$ times to get a $6$. Sometimes, I will have to roll less than $3$-$4$ times, and sometimes I will have to roll more than $3$-$4$ times. Please note that I am not asking how to solve this question, but what is wrong with my logic above. Thank you!","On average, how many times must I roll a dice until I get a $6$? I got this question from a book called Fifty Challenging Problems in Probability. The answer is $6$, and I understand the solution the book has given me. However, I want to know why the following logic does not work: The chance that we do not get a $6$ is $5/6$. In order to find the number of dice rolls needed, I want the probability of there being a $6$ in $n$ rolls being $1/2$ in order to find the average. So I solve the equation $(5/6)^n=1/2$, which gives me $n=3.8$-ish. That number makes sense to me intuitively, where the number $6$ does not make sense intuitively. I feel like on average, I would need to roll about $3$-$4$ times to get a $6$. Sometimes, I will have to roll less than $3$-$4$ times, and sometimes I will have to roll more than $3$-$4$ times. Please note that I am not asking how to solve this question, but what is wrong with my logic above. Thank you!",,"['probability', 'expectation', 'dice']"
76,Conditional and joint probability manipulations when there are 3 variables,Conditional and joint probability manipulations when there are 3 variables,,"I'm having trouble verifying why the following is correct. $$p(x, y \mid z)= p(x \mid y, z) p(y \mid z)$$ I tried grouping the $(x, y)$ together and split by the conditional, which gives me $$p(x, y \mid z) = p(z\mid x, y) p(x, y)/p(z)$$ However, this did not bring me any closer. I'm uncertain about what kind of manipulations are allowed given more than 2 variables. Say an expression like: $$p(a, b, c)$$ Then I know from the chain rule that I can break it down to: $$p(a, b, c)=p(a \mid b, c) p(b, c) = p(a \mid b, c) p(b \mid c) p(c)$$ Is it allowed to split by the second comma: $$p(a, b, c) = p(a, b \mid c) p(c) ?$$ And even more complicated and expression like: $$p(a|b,c)$$ Am I allowed to rewrite this expression by grouping (a|b) together to give me something like $$p(a|b,c)=p((a|b)|c)p(c)$$ And does this expression even make sense?","I'm having trouble verifying why the following is correct. I tried grouping the together and split by the conditional, which gives me However, this did not bring me any closer. I'm uncertain about what kind of manipulations are allowed given more than 2 variables. Say an expression like: Then I know from the chain rule that I can break it down to: Is it allowed to split by the second comma: And even more complicated and expression like: Am I allowed to rewrite this expression by grouping (a|b) together to give me something like And does this expression even make sense?","p(x, y \mid z)= p(x \mid y, z) p(y \mid z) (x, y) p(x, y \mid z) = p(z\mid x, y) p(x, y)/p(z) p(a, b, c) p(a, b, c)=p(a \mid b, c) p(b, c) = p(a \mid b, c) p(b \mid c) p(c) p(a, b, c) = p(a, b \mid c) p(c) ? p(a|b,c) p(a|b,c)=p((a|b)|c)p(c)","['probability', 'probability-theory']"
77,Expected Number of Single Socks when Matching Socks,Expected Number of Single Socks when Matching Socks,,"Whenever I go through the big pile of socks that just went through the laundry, and have to find the matching pairs, I usually do this like I am a simple automaton: I randomly pick a sock, and see if it matches any of the single socks I picked out earlier and that haven't found a match yet. If there is a match, I will fold the two socks together and put them in the 'done' pile, otherwise I will add the single sock to the 'no match yet' pile of single socks, and pick out another random sock. So, as I was doing this last night, I started thinking about this, and figured that the following would be true: The 'no match yet' pile can be expected to slowly grow, up to some point somewhere in the 'middle' of the process, after which the pile will gradually shrink, and eventually go down back to $0$. In fact, my intuition is that the expected number of loose socks as a function of the number of socks picked so far, is a symmetric function, with the maximum being when I have picked half of the socks. So, my questions are: With $n$ pairs of socks, what is the expected number of loose socks that are in my 'no match yet' pile after having picked $k$ socks? Is it true that this function is a symmetric function, and that the maximum is for $k=n$? (if so, I figure there must be a conceptual way of looking at the problem that makes this immediately clear, without using any formulas ... what is that way? Is it just that I can think of reversing the process?) Of course, this is all assuming there are $n$ pairs of socks total, and that there are no single socks in the original pile, and while this is something that never seems to apply to the pile of socks coming through my actual laundry, let's assume for the sake of mathematical simplicity that there really just are $n$ pairs of socks.","Whenever I go through the big pile of socks that just went through the laundry, and have to find the matching pairs, I usually do this like I am a simple automaton: I randomly pick a sock, and see if it matches any of the single socks I picked out earlier and that haven't found a match yet. If there is a match, I will fold the two socks together and put them in the 'done' pile, otherwise I will add the single sock to the 'no match yet' pile of single socks, and pick out another random sock. So, as I was doing this last night, I started thinking about this, and figured that the following would be true: The 'no match yet' pile can be expected to slowly grow, up to some point somewhere in the 'middle' of the process, after which the pile will gradually shrink, and eventually go down back to $0$. In fact, my intuition is that the expected number of loose socks as a function of the number of socks picked so far, is a symmetric function, with the maximum being when I have picked half of the socks. So, my questions are: With $n$ pairs of socks, what is the expected number of loose socks that are in my 'no match yet' pile after having picked $k$ socks? Is it true that this function is a symmetric function, and that the maximum is for $k=n$? (if so, I figure there must be a conceptual way of looking at the problem that makes this immediately clear, without using any formulas ... what is that way? Is it just that I can think of reversing the process?) Of course, this is all assuming there are $n$ pairs of socks total, and that there are no single socks in the original pile, and while this is something that never seems to apply to the pile of socks coming through my actual laundry, let's assume for the sake of mathematical simplicity that there really just are $n$ pairs of socks.",,['probability']
78,Odds of winning at minesweeper with perfect play,Odds of winning at minesweeper with perfect play,,"How would someone go about doing this? Assume that the first ""click"" will never be a bomb, and that the number of mines and the area are both known. Rather hoping there is a clever way to do this, but I will not be so surprised if there isn't. EDIT: I would assume (though without any real proof) that a program could be written that could solve minesweeper in linear time (as the board gets bigger linearly, if the mines/area ratio stays the same). It would seem to me that in general no more than 9 blocks need to be considered (the high end of what i've see playing minesweeper at expert) to determine if its a mine its a safe square the odds that its a mine That would support my earlier assertion. EDIT 2: This would also seem to contradict the fact that minesweeper is NP complete, and with probably not so much work one (maybe even I, but probably not) could write an algorithm that can play a perfect game of minesweeper that would have a linearly increasing runtime which would contradict (summery of) the paper here . So I guess this raises the next question which is: where is the flaw in my logic? EDIT 3: I really am more interesting in the odds than in the algorithm to solve minesweeper. And it would be helpful to me if someone could explain why the number of checks/tests/calculations one has to do does not rise linearly with respect to area.","How would someone go about doing this? Assume that the first ""click"" will never be a bomb, and that the number of mines and the area are both known. Rather hoping there is a clever way to do this, but I will not be so surprised if there isn't. EDIT: I would assume (though without any real proof) that a program could be written that could solve minesweeper in linear time (as the board gets bigger linearly, if the mines/area ratio stays the same). It would seem to me that in general no more than 9 blocks need to be considered (the high end of what i've see playing minesweeper at expert) to determine if its a mine its a safe square the odds that its a mine That would support my earlier assertion. EDIT 2: This would also seem to contradict the fact that minesweeper is NP complete, and with probably not so much work one (maybe even I, but probably not) could write an algorithm that can play a perfect game of minesweeper that would have a linearly increasing runtime which would contradict (summery of) the paper here . So I guess this raises the next question which is: where is the flaw in my logic? EDIT 3: I really am more interesting in the odds than in the algorithm to solve minesweeper. And it would be helpful to me if someone could explain why the number of checks/tests/calculations one has to do does not rise linearly with respect to area.",,['probability']
79,Why is the error function defined as it is?,Why is the error function defined as it is?,,"$\newcommand{\erf}{\operatorname{erf}}$ This may be a very naïve question, but here goes. The error function $\erf$ is defined by $$\erf(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2}dt.$$ Of course, it is closely related to the normal cdf $$\Phi(x) = P(N < x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-t^2/2}dt$$ (where $N \sim N(0,1)$ is a standard normal) by the expression $\erf(x) = 2\Phi(x \sqrt{2})-1$. My question is: Why is it natural or useful to define $\erf$ normalized in this way? I may be biased: as a probabilist, I think much more naturally in terms of $\Phi$.  However, anytime I want to compute something, I find that my calculator or math library only provides $\erf$, and I have to go check a textbook or Wikipedia to remember where all the $1$s and $2$s go.  Being charitable, I have to assume that $\erf$ was invented for some reason other than to cause me annoyance, so I would like to know what it is.  If nothing else, it might help me remember the definition. Wikipedia says: The standard normal cdf is used more often in probability and statistics, and the error function is used more often in other branches of mathematics. So perhaps a practitioner of one of these mysterious ""other branches of mathematics"" would care to enlighten me. The most reasonable expression I've found is that $$P(|N| < x) = \erf(x/\sqrt{2}).$$ This at least gets rid of all but one of the apparently spurious constants, but still has a peculiar $\sqrt{2}$ floating around.","$\newcommand{\erf}{\operatorname{erf}}$ This may be a very naïve question, but here goes. The error function $\erf$ is defined by $$\erf(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2}dt.$$ Of course, it is closely related to the normal cdf $$\Phi(x) = P(N < x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-t^2/2}dt$$ (where $N \sim N(0,1)$ is a standard normal) by the expression $\erf(x) = 2\Phi(x \sqrt{2})-1$. My question is: Why is it natural or useful to define $\erf$ normalized in this way? I may be biased: as a probabilist, I think much more naturally in terms of $\Phi$.  However, anytime I want to compute something, I find that my calculator or math library only provides $\erf$, and I have to go check a textbook or Wikipedia to remember where all the $1$s and $2$s go.  Being charitable, I have to assume that $\erf$ was invented for some reason other than to cause me annoyance, so I would like to know what it is.  If nothing else, it might help me remember the definition. Wikipedia says: The standard normal cdf is used more often in probability and statistics, and the error function is used more often in other branches of mathematics. So perhaps a practitioner of one of these mysterious ""other branches of mathematics"" would care to enlighten me. The most reasonable expression I've found is that $$P(|N| < x) = \erf(x/\sqrt{2}).$$ This at least gets rid of all but one of the apparently spurious constants, but still has a peculiar $\sqrt{2}$ floating around.",,"['probability', 'statistics', 'special-functions', 'normal-distribution']"
80,Limit associated with a recursion,Limit associated with a recursion,,"Update : a full solution to the recursion below has now been found, and it is discussed here . If $z_n < 2y_n$ then $y_{n+1} = 4y_n - 2z_n$ $z_{n+1} = 2z_n + 3$ Else $y_{n+1} = 4y_n$ $z_{n+1} = 2 z_n - 1$ Consider the following limit: $$\lim_{n\rightarrow\infty} \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{$\star$}$$ The limit may or may not exist, and it may or may not depend on the initial conditions. Let us assume that the initial values $y_1$ and $z_1$ are strictly positive integers. Question : If $y_1 \neq 2 z_1$ and $2y_1 \neq z_1$ , is it true that $(\star)$ is always $1$ , and otherwise the limit is always $3$ ? Now let's the fun begin... Let $d_n=\frac14(z_n-2z_{n-1}+1)$ . The sequence $d_n$ represents the binary digits of some unknown number $x$ , a number that depends on the initial conditions. It turns out that if $y_1=2, z_1=5$ then that number is $x=\sqrt{2}$ . You may ask: so what? Here is where it becomes fascinating: If you answer my question about the limit converging to $1$ , say for $y_1=2, z_1=5$ , then you proved that exactly 50% of the binary digits of $\sqrt{2}$ are zero. An article about this recursion (with connection to the digits distribution) can be found here . An application to the gaming industry can be found in section 2.1 in the following article . The source code I used in my computations is accessible here (Perl code using the Bignum library for exact arithmetic.) I can produce a large number of $z_n$ on request, for those interested and not familiar with high precision computing. Hints and expectations The case with the limit converging towards $1$ , I call it the standard case . At this point, the result about the limit is still a conjecture. It is based on the fact that for a number such as $\sqrt{2}$ , the distribution of the binary digits is believed to be uniform on $\{0,1\}$ . Generally speaking, the limit is equal to $4p-1$ where $p$ is the proportion of binary digits equal to one in the number $x$ in question: this fact is easy to prove, almost trivial, as the formula in the limit was built with that goal in mind. Also note that in the standard case, you can never have $y_n = 2z_n$ or $2y_n = z_n$ at any iteration $n$ , otherwise, it would force the convergence towards $3$ according to this conjecture, and imply that $x$ is rational. Also, if the limit, rather than being $1$ was (say) $1.2$ , it would imply that 55% of the binary digits of $\sqrt{2}$ are equal to one. Even proving (in the standard case) that the limit is strictly above $-1$ or strictly below $3$ would be a spectacular discovery: it would imply that the proportion of digits of $\sqrt{2}$ equal to zero is strictly positive (that is, it does not tend to zero as you look at longer and longer sequences of successive digits.) To this day, whether this fact is true or not remains a mystery. I don't know if proving my conjecture is easy, extremely difficult, or impossible to prove or disprove. But I will accept any answer that brings some light to help answer my question, even if it is just a reference to relevant, very interesting previous work. Also, insights about the case where $y_1$ or $z_1$ are not integers, are welcome: for the few cases I tested so far, the limit was equal to $1$ , unless $y_1=2z_1$ or $2y_1 = z_1$ , but convergence can be slow when we are close to $y_1=2z_1$ or $2y_1 = z_1$ . Below is a chart showing convergence to $1$ (relatively slow, of the order $1/\sqrt{n}$ just like for the central limit theorem - not a coincidence - and chaotic) using $y_1=2, z_1=5$ . The X-axis represents $n$ , the number of iterations. The convergence is much faster when the limit is $3$ . Suggested path to solve this problem One way to handle this problem is to consider the sequence $d_n$ of digits of $x$ as a realization of an ergodic stochastic process. Such processes have an equilibrium distribution, called attractor in chaos theory, even though the dynamical system considered here is entirely deterministic. See my article on the theory of randomness, here , and my book Applied Stochastic Processes, Chaos Modeling, and Probabilistic Properties of Numeration Systems , here . The equilibrium distribution is solution to a stochastic integral equation. Here we are dealing with discrete values, and with a discrete stochastic equation that seems to only have two solutions (the standard case, and the other one.)  Assume that the probability (at any iteration $n$ ) for $d_n$ to be equal to one, is $p$ . At equilibrium, the probability for $d_{n+1}$ to be equal to one, must also be $p$ . This yields a stochastic equation, based on the recurrence system mentioned in the introduction, and the only unknown is $p$ . In order for the equilibrium to hold (that is, solving this equation with respect to $p$ ) must yield $p=1/2$ in the standard case. Update: One thing that could also help is looking at what happens with non-integer initial values. For instance, $y_1 \rightarrow 2, z_1 \rightarrow 5$ . I did notice during this experiment that $y_1=1.2, z=5.3$ leads to the non standard case, with the limit converging to $3$ and $x$ being a rational number. So the definition of the standard case needs some refinement (at least to handle non-integer initial values) and examples leading to the non-standard case (though rare) may be more numerous than initially thought. Another interesting chart Here I try to build a second order approximation for the limit. Let $$L(n)= \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{$\star$}$$ I am interested in the error $E(n) = \sqrt{n}\cdot \Big(L(n)-1\Big)$ . In a traditional problem, you would expect $E(n)$ to tend to a constant as $n \rightarrow\infty$ . Not here, the error behaves like a Brownian motion, again, just like in the central limit theorem. Yet the system is fully deterministic here. Note that I used $y(1)=2, z(1)=5$ to produce the chart below. While I did not test it, I would expect that the same Brownian behavior occurs regardless of the initial conditions, as long as we are dealing with the standard case. Also, if you look closely at the above chart, I believe it is NOT a true Brownian motion. It is too regular, and most importantly, the error seems to be bounded. The (apparently) bounded error, together with the non-dependence on the initial conditions (yet to be verified) for the probabilistic behavior, makes me think that this problem, after all, might be solvable. And maybe another way to sole this problem is to get good enough asymptotic expansions for $y_n$ and $z_n$ . Note The recursion mentioned here is identical to the one featured in section 2.1 in this article after the change of variable $z_n = 4x_n + 1$ . An additional change of variables, $w_n=z_n - 2y_n$ , could prove useful. A different approach If the goal is to prove that that binary digits of $\sqrt{2}$ are uniformly distributed, a different approach is as follows. Consider the sequence $q_k=2^{-\{ k \log_2 3 \}}$ where the brackets represent the fractional part function. The number $q_k$ is rational, it has a period of $2 \cdot 3^{k-1}$ in its binary expansion, and the proportion of digits equal to zero is always 50%. The median of $\{q_1, q_2, \cdots q_n\}$ tends to $\sqrt{2}/2$ and if $n$ is odd, it is equal to one of the $q_k (1\leq k\leq n$ ): it is the middle value when these numbers are ordered. Thus the proportion of zero in the median is always exactly 50% if $n$ is odd. But is this also true at the limit as $n\rightarrow \infty$ ? Not necessarily, this is not the case if you consider the minimum or the maximum, instead of the median. So it is more complicated: some $q_k$ (infinitely many) must be removed to guarantee this fact, and they must be chosen carefully so as to not change the value of the limiting median. One way to do this successfully is as follows. Keep only those $q_k$ that satisfy $|p_m(q_k) - \frac{1}{2}| < \frac{C}{\log m}$ for all $m=2,3, \cdots, \lfloor \log k\rfloor$ where $p_m(\alpha)$ is the proportion of digits of $\alpha$ that are equal to 1 among the first $m$ digits, and $C$ is a constant. Would this eventually eliminate $\sqrt{2}/2$ ? Probably not. Would this impact the limiting value of the median? Probably not. But these are extremely challenging questions. It is probably not hard to compute the exact proportion of $q_k$ that you eliminated by doing so. Yet it is not impossible that $\sqrt{2}/2$ can't be reached anymore after applying this thinning process, but only a neighboring irrational that shares (say) the same first $10^{10,000}$ digits. Update: If the $q_k$ being removed were evenly spread (they may not), we are left with the same limit distribution (that of $2^{-X}$ where $X$ is uniform on $[0, 1]$ ). Thus its median $\sqrt{2}/2$ would stay the same. Or perhaps, after removing the set $S$ all those $q_k$ , the median $M_n$ computed on $\{q_1,\cdots,q_n\} \setminus S$ still satisfies $|M_n - \frac{\sqrt{2}}{2}|<\frac{D}{\log n}$ , where $D$ is a constant. That would be enough to prove the main result. If you are only interested in finding a classic math constant $\alpha$ with 50% zeros and 50% ones in its binary expansion, then replace the median $M_n$ by the closest number to $\alpha$ among $\{ q_1, \cdots, q_n\}$ . An example is $\alpha = \frac{1}{2 \log 2}$ . This number is the expectation of the distribution in question, instead of the median. One interesting fact related to this number is the following. The $m$ - th digit of $q_k$ averaged over all $k=1,2,\cdots$ is denoted as $\mu_m$ . Its exact value is known and discussed in a previous MST question ( here ). For $m>1$ , the sequence $\mu_m$ is strictly increasing and converges exponentially fast to $\frac{1}{2}$ . An immediate consequence of the definition of $\mu_m$ is that $$\sum_{m=1}^\infty \frac{\mu_m}{2^m} = \frac{1}{2\log 2}.$$ Also, less obvious to prove but not difficult: we have $\mu_1=1$ and for $m>1$ , we have: $$\mu_m = \frac{1}{\log 2}\cdot\log \frac{2^{2^{m-1}} \cdot (2^{m-1})!^3 }{(2^{m-2})!^2 \cdot (2^m)!}  .$$ More on this in my next article. Conclusions and next steps It looks like $\sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1)$ . This is enough to prove the main result in this discussion, but this asymptotic relationship has yet to be proved (or disproved). A weaker result, possibly easier to prove, is the following: $(\log n) \cdot \Big(L(n) - 1\Big) = o(1)$ . This is also enough to prove the main result. See chart below illustrating this conjecture. Another approach discussed in the section A different approach , does not seem to be easier. A related question is whether or not, for two irrational numbers $\alpha, \beta$ linearly independent on the set of rational numbers, the correlation between the digits of $\alpha$ and $\beta$ in base $b$ is zero. To prove this, it suffices to prove that the sequences $\{ b^n\alpha\}$ and $\{ b^n\beta\}$ are not correlated. It was proved that this was true for the sequences $\{ n\alpha\}$ and $\{ n\beta\}$ , see here . Unfortunately, this does not help. Here the brackets represent the fractional part function. But this epitomizes the issue that we are dealing with here. If $\alpha$ is irrational, then $\{n\alpha\}$ (sometimes called $n \alpha \mbox{ modulo } 1$ ) is equidistributed, regardless of $\alpha$ (irrational). But $\{b^n\alpha\}$ is equidistributed only for almost all irrational numbers. The first sequence is sometimes referred to as a universally good averaging sequence , while the latter is termed a universally bad averaging sequence : see this Wikipedia entry . A weaker conjecture is the following: infinitely many irrational numbers $\sqrt{r}$ with $r$ a rational number, have 50% zeros and 50% ones in their binary expansion. You might be able to prove it without being able to name a single of these numbers satisfying this property (I tried and failed so far; it is probably still a mystery today.) Finally, if you are interested to see how chaotic the behavior of non-normal numbers is (contrasted with supposedly normal numbers such as $\sqrt{2}$ ), read my recent MSE discussion, here . It gives some nice insights about what makes a number such as $\sqrt{2}, \pi, e$ or $\log 2$ stand out. Update The relation $\sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1)$ is a direct consequence of the Berry-Essen theorem , a refinement of the central limit theorem that applies in this case. It would be true here if the digits of (say) $\sqrt{2}$ were i.i.d. with a Bernouilli distribution of parameter $p=\frac{1}{2}$ , as they appear to be. Thus proving this asymptotic result for $\sqrt{2}$ would be very difficult at best, impossible at worst. But a weaker result might be reachable. Along the same lines, see a new question (with answer) that I posted recently on MSE, here , and also here . It shows what would happen if $\sqrt{2}$ was a well-behaved but non-normal number, say with 75% of its digits equal to $1$ . Update #2 I wrote an article based on this question and some other related questions, You can read here .","Update : a full solution to the recursion below has now been found, and it is discussed here . If then Else Consider the following limit: The limit may or may not exist, and it may or may not depend on the initial conditions. Let us assume that the initial values and are strictly positive integers. Question : If and , is it true that is always , and otherwise the limit is always ? Now let's the fun begin... Let . The sequence represents the binary digits of some unknown number , a number that depends on the initial conditions. It turns out that if then that number is . You may ask: so what? Here is where it becomes fascinating: If you answer my question about the limit converging to , say for , then you proved that exactly 50% of the binary digits of are zero. An article about this recursion (with connection to the digits distribution) can be found here . An application to the gaming industry can be found in section 2.1 in the following article . The source code I used in my computations is accessible here (Perl code using the Bignum library for exact arithmetic.) I can produce a large number of on request, for those interested and not familiar with high precision computing. Hints and expectations The case with the limit converging towards , I call it the standard case . At this point, the result about the limit is still a conjecture. It is based on the fact that for a number such as , the distribution of the binary digits is believed to be uniform on . Generally speaking, the limit is equal to where is the proportion of binary digits equal to one in the number in question: this fact is easy to prove, almost trivial, as the formula in the limit was built with that goal in mind. Also note that in the standard case, you can never have or at any iteration , otherwise, it would force the convergence towards according to this conjecture, and imply that is rational. Also, if the limit, rather than being was (say) , it would imply that 55% of the binary digits of are equal to one. Even proving (in the standard case) that the limit is strictly above or strictly below would be a spectacular discovery: it would imply that the proportion of digits of equal to zero is strictly positive (that is, it does not tend to zero as you look at longer and longer sequences of successive digits.) To this day, whether this fact is true or not remains a mystery. I don't know if proving my conjecture is easy, extremely difficult, or impossible to prove or disprove. But I will accept any answer that brings some light to help answer my question, even if it is just a reference to relevant, very interesting previous work. Also, insights about the case where or are not integers, are welcome: for the few cases I tested so far, the limit was equal to , unless or , but convergence can be slow when we are close to or . Below is a chart showing convergence to (relatively slow, of the order just like for the central limit theorem - not a coincidence - and chaotic) using . The X-axis represents , the number of iterations. The convergence is much faster when the limit is . Suggested path to solve this problem One way to handle this problem is to consider the sequence of digits of as a realization of an ergodic stochastic process. Such processes have an equilibrium distribution, called attractor in chaos theory, even though the dynamical system considered here is entirely deterministic. See my article on the theory of randomness, here , and my book Applied Stochastic Processes, Chaos Modeling, and Probabilistic Properties of Numeration Systems , here . The equilibrium distribution is solution to a stochastic integral equation. Here we are dealing with discrete values, and with a discrete stochastic equation that seems to only have two solutions (the standard case, and the other one.)  Assume that the probability (at any iteration ) for to be equal to one, is . At equilibrium, the probability for to be equal to one, must also be . This yields a stochastic equation, based on the recurrence system mentioned in the introduction, and the only unknown is . In order for the equilibrium to hold (that is, solving this equation with respect to ) must yield in the standard case. Update: One thing that could also help is looking at what happens with non-integer initial values. For instance, . I did notice during this experiment that leads to the non standard case, with the limit converging to and being a rational number. So the definition of the standard case needs some refinement (at least to handle non-integer initial values) and examples leading to the non-standard case (though rare) may be more numerous than initially thought. Another interesting chart Here I try to build a second order approximation for the limit. Let I am interested in the error . In a traditional problem, you would expect to tend to a constant as . Not here, the error behaves like a Brownian motion, again, just like in the central limit theorem. Yet the system is fully deterministic here. Note that I used to produce the chart below. While I did not test it, I would expect that the same Brownian behavior occurs regardless of the initial conditions, as long as we are dealing with the standard case. Also, if you look closely at the above chart, I believe it is NOT a true Brownian motion. It is too regular, and most importantly, the error seems to be bounded. The (apparently) bounded error, together with the non-dependence on the initial conditions (yet to be verified) for the probabilistic behavior, makes me think that this problem, after all, might be solvable. And maybe another way to sole this problem is to get good enough asymptotic expansions for and . Note The recursion mentioned here is identical to the one featured in section 2.1 in this article after the change of variable . An additional change of variables, , could prove useful. A different approach If the goal is to prove that that binary digits of are uniformly distributed, a different approach is as follows. Consider the sequence where the brackets represent the fractional part function. The number is rational, it has a period of in its binary expansion, and the proportion of digits equal to zero is always 50%. The median of tends to and if is odd, it is equal to one of the ): it is the middle value when these numbers are ordered. Thus the proportion of zero in the median is always exactly 50% if is odd. But is this also true at the limit as ? Not necessarily, this is not the case if you consider the minimum or the maximum, instead of the median. So it is more complicated: some (infinitely many) must be removed to guarantee this fact, and they must be chosen carefully so as to not change the value of the limiting median. One way to do this successfully is as follows. Keep only those that satisfy for all where is the proportion of digits of that are equal to 1 among the first digits, and is a constant. Would this eventually eliminate ? Probably not. Would this impact the limiting value of the median? Probably not. But these are extremely challenging questions. It is probably not hard to compute the exact proportion of that you eliminated by doing so. Yet it is not impossible that can't be reached anymore after applying this thinning process, but only a neighboring irrational that shares (say) the same first digits. Update: If the being removed were evenly spread (they may not), we are left with the same limit distribution (that of where is uniform on ). Thus its median would stay the same. Or perhaps, after removing the set all those , the median computed on still satisfies , where is a constant. That would be enough to prove the main result. If you are only interested in finding a classic math constant with 50% zeros and 50% ones in its binary expansion, then replace the median by the closest number to among . An example is . This number is the expectation of the distribution in question, instead of the median. One interesting fact related to this number is the following. The - th digit of averaged over all is denoted as . Its exact value is known and discussed in a previous MST question ( here ). For , the sequence is strictly increasing and converges exponentially fast to . An immediate consequence of the definition of is that Also, less obvious to prove but not difficult: we have and for , we have: More on this in my next article. Conclusions and next steps It looks like . This is enough to prove the main result in this discussion, but this asymptotic relationship has yet to be proved (or disproved). A weaker result, possibly easier to prove, is the following: . This is also enough to prove the main result. See chart below illustrating this conjecture. Another approach discussed in the section A different approach , does not seem to be easier. A related question is whether or not, for two irrational numbers linearly independent on the set of rational numbers, the correlation between the digits of and in base is zero. To prove this, it suffices to prove that the sequences and are not correlated. It was proved that this was true for the sequences and , see here . Unfortunately, this does not help. Here the brackets represent the fractional part function. But this epitomizes the issue that we are dealing with here. If is irrational, then (sometimes called ) is equidistributed, regardless of (irrational). But is equidistributed only for almost all irrational numbers. The first sequence is sometimes referred to as a universally good averaging sequence , while the latter is termed a universally bad averaging sequence : see this Wikipedia entry . A weaker conjecture is the following: infinitely many irrational numbers with a rational number, have 50% zeros and 50% ones in their binary expansion. You might be able to prove it without being able to name a single of these numbers satisfying this property (I tried and failed so far; it is probably still a mystery today.) Finally, if you are interested to see how chaotic the behavior of non-normal numbers is (contrasted with supposedly normal numbers such as ), read my recent MSE discussion, here . It gives some nice insights about what makes a number such as or stand out. Update The relation is a direct consequence of the Berry-Essen theorem , a refinement of the central limit theorem that applies in this case. It would be true here if the digits of (say) were i.i.d. with a Bernouilli distribution of parameter , as they appear to be. Thus proving this asymptotic result for would be very difficult at best, impossible at worst. But a weaker result might be reachable. Along the same lines, see a new question (with answer) that I posted recently on MSE, here , and also here . It shows what would happen if was a well-behaved but non-normal number, say with 75% of its digits equal to . Update #2 I wrote an article based on this question and some other related questions, You can read here .","z_n < 2y_n y_{n+1} = 4y_n - 2z_n z_{n+1} = 2z_n + 3 y_{n+1} = 4y_n z_{n+1} = 2 z_n - 1 \lim_{n\rightarrow\infty} \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{\star} y_1 z_1 y_1 \neq 2 z_1 2y_1 \neq z_1 (\star) 1 3 d_n=\frac14(z_n-2z_{n-1}+1) d_n x y_1=2, z_1=5 x=\sqrt{2} 1 y_1=2, z_1=5 \sqrt{2} z_n 1 \sqrt{2} \{0,1\} 4p-1 p x y_n = 2z_n 2y_n = z_n n 3 x 1 1.2 \sqrt{2} -1 3 \sqrt{2} y_1 z_1 1 y_1=2z_1 2y_1 = z_1 y_1=2z_1 2y_1 = z_1 1 1/\sqrt{n} y_1=2, z_1=5 n 3 d_n x n d_n p d_{n+1} p p p p=1/2 y_1 \rightarrow 2, z_1 \rightarrow 5 y_1=1.2, z=5.3 3 x L(n)= \frac{1}{n}\left(z_{n+1} - \sum_{k=1}^n z_k\right) \tag{\star} E(n) = \sqrt{n}\cdot \Big(L(n)-1\Big) E(n) n \rightarrow\infty y(1)=2, z(1)=5 y_n z_n z_n = 4x_n + 1 w_n=z_n - 2y_n \sqrt{2} q_k=2^{-\{ k \log_2 3 \}} q_k 2 \cdot 3^{k-1} \{q_1, q_2, \cdots q_n\} \sqrt{2}/2 n q_k (1\leq k\leq n n n\rightarrow \infty q_k q_k |p_m(q_k) - \frac{1}{2}| < \frac{C}{\log m} m=2,3, \cdots, \lfloor \log k\rfloor p_m(\alpha) \alpha m C \sqrt{2}/2 q_k \sqrt{2}/2 10^{10,000} q_k 2^{-X} X [0, 1] \sqrt{2}/2 S q_k M_n \{q_1,\cdots,q_n\} \setminus S |M_n - \frac{\sqrt{2}}{2}|<\frac{D}{\log n} D \alpha M_n \alpha \{ q_1, \cdots, q_n\} \alpha = \frac{1}{2 \log 2} m q_k k=1,2,\cdots \mu_m m>1 \mu_m \frac{1}{2} \mu_m \sum_{m=1}^\infty \frac{\mu_m}{2^m} = \frac{1}{2\log 2}. \mu_1=1 m>1 \mu_m = \frac{1}{\log 2}\cdot\log \frac{2^{2^{m-1}} \cdot (2^{m-1})!^3 }{(2^{m-2})!^2 \cdot (2^m)!}  . \sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1) (\log n) \cdot \Big(L(n) - 1\Big) = o(1) \alpha, \beta \alpha \beta b \{ b^n\alpha\} \{ b^n\beta\} \{ n\alpha\} \{ n\beta\} \alpha \{n\alpha\} n \alpha \mbox{ modulo } 1 \alpha \{b^n\alpha\} \sqrt{r} r \sqrt{2} \sqrt{2}, \pi, e \log 2 \sqrt{n}\cdot\Big(L(n) - 1\Big) = O(1) \sqrt{2} p=\frac{1}{2} \sqrt{2} \sqrt{2} 1","['probability', 'sequences-and-series', 'number-theory', 'recreational-mathematics', 'recursion']"
81,"Picking two random real numbers between 0 and 1, why isn't the probability that the first is greater than the second exactly 50%?","Picking two random real numbers between 0 and 1, why isn't the probability that the first is greater than the second exactly 50%?",,"I attempted to answer this question on Quora, and was told that I am thinking about the problem incorrectly. The question was: Two distinct real numbers between 0 and 1 are written on two sheets of   paper. You have to select one of the sheets randomly and declare   whether the number you see is the biggest or smallest of the two. How   can one expect to be correct more than half the times you play this   game? My answer was that it was impossible, as the probability should always be 50% for the following reason: You can't! Here's why: The set of real numbers between (0, 1) is known as an Uncountably Infinite Set   ( https://en.wikipedia.org/wiki/Uncountable_set ). A set that is   uncountable has the following interesting property: Let $\mathbb{S}$ be an uncountably infinite set. Let, $a, b, c, d \in \mathbb{S} (a \neq b, c \neq d)$. If $x$ is an uncountably infinite subset of   $\mathbb{S}$, containing all elements in $\mathbb{S}$ on the interval $(a, b)$; and $y$   is another uncountably infinite subset of $\mathbb{S}$, which contains all   elements of $\mathbb{S}$ on the interval $(c, d),$ $x$ and $y$ have the same   cardinality (size)! So for example, the set of all real numbers between (0, 1) is actually   the exact same size as the set of all real numbers between (0, 2)!   It is also the same size as the set of all real numbers between (0,   0.00001). In fact, if you have an uncountably infinite set on the interval $(a, b)$, and $a<n<b$, then then exactly 50% of the numbers   in the set are greater than $n$, and 50% are less than $n$, no matter   what you choose for $n$. This is important because it tells us   something unintuitive about our probability in this case.  Let's say   the first number you picked is 0.03. You might think ""Well, 97% of the   other possible numbers are larger than this, so the other number is   probably larger."" You would be wrong! There are actually exactly as many numbers between (0, 0.03) as there are between (0.03, 1). Even   if you picked 0.03, half of the other possible numbers are smaller   than it, and half of the other possible numbers are larger than it. This means there is still a 50% probability that the other number is larger, and a 50% probability that it is smaller! "" But how can that be? "" you ask, "" why isn't $\frac{a-b}{2}$ the   midpoint? "" The real question is, why is it that we believe that   $\frac{a-b}{2}$ is the midpoint to begin with? The reason is probably   the following: it seems to make the most sense for discrete   (finite/countably infinite) sets. For example, if instead of the real   numbers, we took the set of all multiples of $0.001$ on the interval   $[0, 1]$. Now it makes sense to say that 0.5 is the midpoint, as we   know that the number of numbers below 0.5 is equal to the number of   numbers above 0.5. If we were to try to say that the midpoint is 0.4,   we would find that there are now more numbers above 0.4 then there are   below 0.4. This no longer applies when talking about the set of all   real numbers $\mathbb{R}$. Strangely enough, we can no longer talk   about having a midpoint in $\mathbb{R}$, because every number in   $\mathbb{R}$ could be considered a midpoint. For any point in   $\mathbb{R}$, the numbers above it and the numbers below it always   have the same cardinality. See the Wikipedia article on Cardinality of the continuum   ( https://en.wikipedia.org/wiki/Cardinality_of_the_continuum ). My question is, from a mathematical point of view, is this correct? The person who told me that this is wrong is fairly well known, and not someone who I would assume to often be wrong, especially for these types of problems. The reasoning given for my answer being wrong was as follows: Your conclusion is not correct. You're right that the set of real   numbers between 0 and 1 is uncountable infinite, and most of what you   said here is correct. But that last part is incorrect. If you picked a   random real number between 0 and 1, the number does have a 97% chance   of being above 0.03. Let's look at this another way. Let K = {all   integers divisible by 125423423}. Let M = {all integers not divisible   by 125423423}. K and M are the same size, right? Does this mean, if   you picked an random integer, it has a 50% chance of being in K and a   50% chance or not? A random integer has a 50% chance of being   divisible by 125423423? The reason I disagreed with this response was because the last sentence should actually be true. If the set of all numbers that are divisible by 125423423 is the same size as the set of numbers that aren't, there should be a 50% probability of picking a random number from the first set, and a 50% chance that a number would be picked from the second. This is cirtainly the case with finite sets. If there are 2 disjoint, finite sets with equal cardinality, and you choose a random number from the union of the two sets, there should be a 50% chance that the number came from the first set, and a 50% chance that the number came from the second set. Can this idea be generalized for infinite sets of equal cardinality? Is my answer wrong? If so, am I missing something about how cardinalities of two set relate to the probability of choosing a number from one of them? Where did I go wrong in my logic?","I attempted to answer this question on Quora, and was told that I am thinking about the problem incorrectly. The question was: Two distinct real numbers between 0 and 1 are written on two sheets of   paper. You have to select one of the sheets randomly and declare   whether the number you see is the biggest or smallest of the two. How   can one expect to be correct more than half the times you play this   game? My answer was that it was impossible, as the probability should always be 50% for the following reason: You can't! Here's why: The set of real numbers between (0, 1) is known as an Uncountably Infinite Set   ( https://en.wikipedia.org/wiki/Uncountable_set ). A set that is   uncountable has the following interesting property: Let $\mathbb{S}$ be an uncountably infinite set. Let, $a, b, c, d \in \mathbb{S} (a \neq b, c \neq d)$. If $x$ is an uncountably infinite subset of   $\mathbb{S}$, containing all elements in $\mathbb{S}$ on the interval $(a, b)$; and $y$   is another uncountably infinite subset of $\mathbb{S}$, which contains all   elements of $\mathbb{S}$ on the interval $(c, d),$ $x$ and $y$ have the same   cardinality (size)! So for example, the set of all real numbers between (0, 1) is actually   the exact same size as the set of all real numbers between (0, 2)!   It is also the same size as the set of all real numbers between (0,   0.00001). In fact, if you have an uncountably infinite set on the interval $(a, b)$, and $a<n<b$, then then exactly 50% of the numbers   in the set are greater than $n$, and 50% are less than $n$, no matter   what you choose for $n$. This is important because it tells us   something unintuitive about our probability in this case.  Let's say   the first number you picked is 0.03. You might think ""Well, 97% of the   other possible numbers are larger than this, so the other number is   probably larger."" You would be wrong! There are actually exactly as many numbers between (0, 0.03) as there are between (0.03, 1). Even   if you picked 0.03, half of the other possible numbers are smaller   than it, and half of the other possible numbers are larger than it. This means there is still a 50% probability that the other number is larger, and a 50% probability that it is smaller! "" But how can that be? "" you ask, "" why isn't $\frac{a-b}{2}$ the   midpoint? "" The real question is, why is it that we believe that   $\frac{a-b}{2}$ is the midpoint to begin with? The reason is probably   the following: it seems to make the most sense for discrete   (finite/countably infinite) sets. For example, if instead of the real   numbers, we took the set of all multiples of $0.001$ on the interval   $[0, 1]$. Now it makes sense to say that 0.5 is the midpoint, as we   know that the number of numbers below 0.5 is equal to the number of   numbers above 0.5. If we were to try to say that the midpoint is 0.4,   we would find that there are now more numbers above 0.4 then there are   below 0.4. This no longer applies when talking about the set of all   real numbers $\mathbb{R}$. Strangely enough, we can no longer talk   about having a midpoint in $\mathbb{R}$, because every number in   $\mathbb{R}$ could be considered a midpoint. For any point in   $\mathbb{R}$, the numbers above it and the numbers below it always   have the same cardinality. See the Wikipedia article on Cardinality of the continuum   ( https://en.wikipedia.org/wiki/Cardinality_of_the_continuum ). My question is, from a mathematical point of view, is this correct? The person who told me that this is wrong is fairly well known, and not someone who I would assume to often be wrong, especially for these types of problems. The reasoning given for my answer being wrong was as follows: Your conclusion is not correct. You're right that the set of real   numbers between 0 and 1 is uncountable infinite, and most of what you   said here is correct. But that last part is incorrect. If you picked a   random real number between 0 and 1, the number does have a 97% chance   of being above 0.03. Let's look at this another way. Let K = {all   integers divisible by 125423423}. Let M = {all integers not divisible   by 125423423}. K and M are the same size, right? Does this mean, if   you picked an random integer, it has a 50% chance of being in K and a   50% chance or not? A random integer has a 50% chance of being   divisible by 125423423? The reason I disagreed with this response was because the last sentence should actually be true. If the set of all numbers that are divisible by 125423423 is the same size as the set of numbers that aren't, there should be a 50% probability of picking a random number from the first set, and a 50% chance that a number would be picked from the second. This is cirtainly the case with finite sets. If there are 2 disjoint, finite sets with equal cardinality, and you choose a random number from the union of the two sets, there should be a 50% chance that the number came from the first set, and a 50% chance that the number came from the second set. Can this idea be generalized for infinite sets of equal cardinality? Is my answer wrong? If so, am I missing something about how cardinalities of two set relate to the probability of choosing a number from one of them? Where did I go wrong in my logic?",,"['probability', 'real-numbers']"
82,Pdf of the difference of two exponentially distributed random variables,Pdf of the difference of two exponentially distributed random variables,,"Suppose we have two independent random variables $Y$ and $X$ , both being exponentially distributed with respective parameters $\mu$ and $\lambda$ . How can we calculate the pdf of $Y-X$ ?","Suppose we have two independent random variables and , both being exponentially distributed with respective parameters and . How can we calculate the pdf of ?",Y X \mu \lambda Y-X,"['probability', 'probability-distributions', 'exponential-distribution']"
83,What is the chance that a rabbit won't fall off a table if you put it somewhere and it moves.,What is the chance that a rabbit won't fall off a table if you put it somewhere and it moves.,,"If you would put a rabbit randomly on a circular table with radius $r= 1$ meter and it moves $1$ meter in a random direction, what is the chance it won't fall off? I tried to do this using integrals, but then I noticed you need a double integral or something and since I'm in the 5th form I don't know how that works.","If you would put a rabbit randomly on a circular table with radius meter and it moves meter in a random direction, what is the chance it won't fall off? I tried to do this using integrals, but then I noticed you need a double integral or something and since I'm in the 5th form I don't know how that works.",r= 1 1,['probability']
84,How to determine if coin comes up heads more often than tails?,How to determine if coin comes up heads more often than tails?,,"Not a math student, so forgive me if the question seems trivial or if I pose it ""wrong"". Here goes... Say I'm flipping a coin a n times. I am not sure if it's a ""fair"" coin, meaning I am not sure if it will come up heads and tails each with a propability of exactly 0.5. Now, if after n throws it has come up heads exactly as many times as it has come up tails, then obviously there's nothing to indicate that the coin is not fair. But my intuition tells me that it would be improbable even for a completely fair coin to come up with heads and tails an exact even number of times given a large amount of tosses. My question is this: How ""off"" should the result be for it to be probable that the coin is not fair? IOW, how many more tosses should come up heads rather than tails in a series of n throws before I should assume the coin is weighted? Update Someone mentioned Pearson's chi-square test but then for some reason deleted their answer. Can someone confirm if that is indeed the right place to look for the answer?","Not a math student, so forgive me if the question seems trivial or if I pose it ""wrong"". Here goes... Say I'm flipping a coin a n times. I am not sure if it's a ""fair"" coin, meaning I am not sure if it will come up heads and tails each with a propability of exactly 0.5. Now, if after n throws it has come up heads exactly as many times as it has come up tails, then obviously there's nothing to indicate that the coin is not fair. But my intuition tells me that it would be improbable even for a completely fair coin to come up with heads and tails an exact even number of times given a large amount of tosses. My question is this: How ""off"" should the result be for it to be probable that the coin is not fair? IOW, how many more tosses should come up heads rather than tails in a series of n throws before I should assume the coin is weighted? Update Someone mentioned Pearson's chi-square test but then for some reason deleted their answer. Can someone confirm if that is indeed the right place to look for the answer?",,['probability']
85,Solutions to $\binom{n}{5} = 2 \binom{m}{5}$,Solutions to,\binom{n}{5} = 2 \binom{m}{5},"In Finite Mathematics by Lial et al. (10th ed.), problem 8.3.34 says: On National Public Radio, the Weekend Edition program posed the   following probability problem: Given a certain number of balls, of   which some are blue, pick 5 at random.  The probability that all 5 are   blue is 1/2.  Determine the original number of balls and decide how   many were blue. If there are $n$ balls, of which $m$ are blue, then the probability that 5 randomly chosen balls are all blue is $\binom{m}{5} / \binom{n}{5}$.  We want this to be $1/2$, so $\binom{n}{5} = 2\binom{m}{5}$; equivalently, $n(n-1)(n-2)(n-3)(n-4) = 2 m(m-1)(m-2)(m-3)(m-4)$. I'll denote these quantities as $[n]_5$ and $2 [m]_5$ (this is a notation for the so-called ""falling factorial."") A little fooling around will show that $[m+1]_5 = \frac{m+1}{m-4}[m]_5$. Solving $\frac{m+1}{m-4} = 2$ shows that the only solution with $n = m + 1$ has $m = 9$, $n = 10$. Is this the only solution? You can check that $n = m + 2$ doesn't yield any integer solutions, by using the quadratic formula to solve $(m + 2)(m  +1) = 2(m - 3)(m - 4)$.  I have ruled out $n = m + 3$ or $n = m + 4$ with similar checks.  For $n \geq m + 5$, solutions would satisfy a quintic equation, which of course has no general formula to find solutions. Note that, as $n$ gets bigger, the ratio of successive values of $\binom{n}{5}$ gets smaller; $\binom{n+1}{5} = \frac{n+1}{n-4}\binom{n}{5}$ and $\frac{n+1}{n-4}$ is less than 2—in fact, it approaches 1. So it seems possible that, for some $k$, $\binom{n+k}{5}$ could be $2 \binom{n}{5}$. This is now a question at MathOverflow .","In Finite Mathematics by Lial et al. (10th ed.), problem 8.3.34 says: On National Public Radio, the Weekend Edition program posed the   following probability problem: Given a certain number of balls, of   which some are blue, pick 5 at random.  The probability that all 5 are   blue is 1/2.  Determine the original number of balls and decide how   many were blue. If there are $n$ balls, of which $m$ are blue, then the probability that 5 randomly chosen balls are all blue is $\binom{m}{5} / \binom{n}{5}$.  We want this to be $1/2$, so $\binom{n}{5} = 2\binom{m}{5}$; equivalently, $n(n-1)(n-2)(n-3)(n-4) = 2 m(m-1)(m-2)(m-3)(m-4)$. I'll denote these quantities as $[n]_5$ and $2 [m]_5$ (this is a notation for the so-called ""falling factorial."") A little fooling around will show that $[m+1]_5 = \frac{m+1}{m-4}[m]_5$. Solving $\frac{m+1}{m-4} = 2$ shows that the only solution with $n = m + 1$ has $m = 9$, $n = 10$. Is this the only solution? You can check that $n = m + 2$ doesn't yield any integer solutions, by using the quadratic formula to solve $(m + 2)(m  +1) = 2(m - 3)(m - 4)$.  I have ruled out $n = m + 3$ or $n = m + 4$ with similar checks.  For $n \geq m + 5$, solutions would satisfy a quintic equation, which of course has no general formula to find solutions. Note that, as $n$ gets bigger, the ratio of successive values of $\binom{n}{5}$ gets smaller; $\binom{n+1}{5} = \frac{n+1}{n-4}\binom{n}{5}$ and $\frac{n+1}{n-4}$ is less than 2—in fact, it approaches 1. So it seems possible that, for some $k$, $\binom{n+k}{5}$ could be $2 \binom{n}{5}$. This is now a question at MathOverflow .",,"['probability', 'combinatorics', 'binomial-coefficients', 'diophantine-equations']"
86,"Intuition is silent: Find the probability that the smallest circle enclosing $n$ random points on a disk lies completely on the disk, as $n\to\infty$.","Intuition is silent: Find the probability that the smallest circle enclosing  random points on a disk lies completely on the disk, as .",n n\to\infty,"On a disk, choose $n$ uniformly random points. Then draw the smallest circle enclosing those points. ( Here are some algorithms for doing so.) The circle may or may not lie completely on the disk. For example, with $n=7$ , here are examples of both cases. What is $\lim\limits_{n\to\infty}\{\text{Probability that the circle lies completely on the disk}\}$ ? Is the limiting probability $0$ ? Or $1$ ? Or something in between? My geometrical intuition fails to tell me anything. The case $n=2$ I have only been able to find that, when $n=2$ , the probability that the smallest enclosing circle lies completely on the disk, is $2/3$ . Without loss of generality, assume that the perimeter of the disk is $x^2+y^2=1$ , and the two points are $(x,y)$ and $(0,\sqrt t)$ where $t$ is uniformly distributed in $[0,1]$ . The smallest enclosing circle has centre $C\left(\frac{x}{2}, \frac{y+\sqrt t}{2}\right)$ and radius $r=\frac12\sqrt{x^2+(y-\sqrt t)^2}$ . If the smallest enclosing circle lies completely on the disk, then $C$ lies within $1-r$ of the origin. That is, $$\sqrt{\left(\frac{x}{2}\right)^2+\left(\frac{y+\sqrt t}{2}\right)^2}\le 1-\frac12\sqrt{x^2+(y-\sqrt t)^2}$$ which is equivalent to $$\frac{x^2}{1-t}+y^2\le1$$ The area of this region is $\pi\sqrt{1-t}$ , and the area of the disk is $\pi$ , so the probability that the smallest enclosing circle lies completely on the disk is $\sqrt{1-t}$ . Integrating from $t=0$ to $t=1$ , the probability is $\int_0^1 \sqrt{1-t}dt=2/3$ . Edit From the comments, @Varun Vejalla has run trials that suggest that, for small values of $n$ , the probability (that the enclosing circle lies completely on the disk) is $\frac{n}{2n-1}$ , and that the limiting probability is $\frac12$ . There should be a way to prove these results. Edit2 I seek to generalize this question here .","On a disk, choose uniformly random points. Then draw the smallest circle enclosing those points. ( Here are some algorithms for doing so.) The circle may or may not lie completely on the disk. For example, with , here are examples of both cases. What is ? Is the limiting probability ? Or ? Or something in between? My geometrical intuition fails to tell me anything. The case I have only been able to find that, when , the probability that the smallest enclosing circle lies completely on the disk, is . Without loss of generality, assume that the perimeter of the disk is , and the two points are and where is uniformly distributed in . The smallest enclosing circle has centre and radius . If the smallest enclosing circle lies completely on the disk, then lies within of the origin. That is, which is equivalent to The area of this region is , and the area of the disk is , so the probability that the smallest enclosing circle lies completely on the disk is . Integrating from to , the probability is . Edit From the comments, @Varun Vejalla has run trials that suggest that, for small values of , the probability (that the enclosing circle lies completely on the disk) is , and that the limiting probability is . There should be a way to prove these results. Edit2 I seek to generalize this question here .","n n=7 \lim\limits_{n\to\infty}\{\text{Probability that the circle lies completely on the disk}\} 0 1 n=2 n=2 2/3 x^2+y^2=1 (x,y) (0,\sqrt t) t [0,1] C\left(\frac{x}{2}, \frac{y+\sqrt t}{2}\right) r=\frac12\sqrt{x^2+(y-\sqrt t)^2} C 1-r \sqrt{\left(\frac{x}{2}\right)^2+\left(\frac{y+\sqrt t}{2}\right)^2}\le 1-\frac12\sqrt{x^2+(y-\sqrt t)^2} \frac{x^2}{1-t}+y^2\le1 \pi\sqrt{1-t} \pi \sqrt{1-t} t=0 t=1 \int_0^1 \sqrt{1-t}dt=2/3 n \frac{n}{2n-1} \frac12","['probability', 'integration', 'geometry', 'limits', 'circles']"
87,Probability that 3 points in a plane form a triangle,Probability that 3 points in a plane form a triangle,,"This question was asked in a test and I got it right. The answer key gives $\frac12$. Problem : If 3 distinct points are chosen on a plane, find the probability that they form a triangle. Attempt 1 : The 3rd point will either be collinear or non-collinear with the other 2 points. Hence the probability is $\frac12$, assuming that collinearity and non-collinearity of the 3 points are equally likely events. Attempt 2 : Now suppose we take the midpoint (say $M$) of 2 of the points (say $A$ and $B$). We can draw an infinite number of lines passing through $M$, out of which only 1 line will pass through $A$ and $B$. Keeping this in mind, we can choose the 3rd point $C$ on any of those infinite lines, excluding the one passing through $A$ and $B$. Now it seems as if the probability will be tending to 1. What is wrong with attempt 2? Or is the answer actually 1 and not $\frac12$?","This question was asked in a test and I got it right. The answer key gives $\frac12$. Problem : If 3 distinct points are chosen on a plane, find the probability that they form a triangle. Attempt 1 : The 3rd point will either be collinear or non-collinear with the other 2 points. Hence the probability is $\frac12$, assuming that collinearity and non-collinearity of the 3 points are equally likely events. Attempt 2 : Now suppose we take the midpoint (say $M$) of 2 of the points (say $A$ and $B$). We can draw an infinite number of lines passing through $M$, out of which only 1 line will pass through $A$ and $B$. Keeping this in mind, we can choose the 3rd point $C$ on any of those infinite lines, excluding the one passing through $A$ and $B$. Now it seems as if the probability will be tending to 1. What is wrong with attempt 2? Or is the answer actually 1 and not $\frac12$?",,"['probability', 'triangles', 'geometric-probability']"
88,"If you draw two cards, what is the probability that the second card is a queen?","If you draw two cards, what is the probability that the second card is a queen?",,"We had this question arise in class today and I still don't understand the answer given. We were to assume that drawing cards are independent events. We were asked what the probability that the second card drawn is a queen if we take two from the deck. The answer given was 4/52, which seems counter-intuitive to me. How is the probability still 4/52 if there was a card drawn before it? What if the first card drawn was a queen?","We had this question arise in class today and I still don't understand the answer given. We were to assume that drawing cards are independent events. We were asked what the probability that the second card drawn is a queen if we take two from the deck. The answer given was 4/52, which seems counter-intuitive to me. How is the probability still 4/52 if there was a card drawn before it? What if the first card drawn was a queen?",,['probability']
89,Do I have a misconception about probability?,Do I have a misconception about probability?,,"I have come across this text recently. I was confused, asked a friend, she was also not certain. Can you explain please? What author is talking about here? I don't understand.   Is the problem with the phrase ""on average""? Innumerable misconceptions about probability. For example, suppose I toss a fair coin 100 times. On every “heads”, I take one step to the north. On every “tails”, I take one step to the south. After the 100th step, how far away am I, on average, from where I started? (Most kids – and more than a few teachers – say “zero” ... which is not the right answer.) In a way it is pointless to talk about misconceptions, when you don't explain the misconceptions... Source: https://www.av8n.com/physics/pedagogy.htm Section 4.2 Miscellaneous Misconceptions, item number 5","I have come across this text recently. I was confused, asked a friend, she was also not certain. Can you explain please? What author is talking about here? I don't understand.   Is the problem with the phrase ""on average""? Innumerable misconceptions about probability. For example, suppose I toss a fair coin 100 times. On every “heads”, I take one step to the north. On every “tails”, I take one step to the south. After the 100th step, how far away am I, on average, from where I started? (Most kids – and more than a few teachers – say “zero” ... which is not the right answer.) In a way it is pointless to talk about misconceptions, when you don't explain the misconceptions... Source: https://www.av8n.com/physics/pedagogy.htm Section 4.2 Miscellaneous Misconceptions, item number 5",,"['probability', 'average']"
90,Probability that two random numbers are coprime is $\frac{6}{\pi^2}$,Probability that two random numbers are coprime is,\frac{6}{\pi^2},"This is a really natural question for which I know a stunning solution. So I admit I have a solution, however I would like to see if anybody will come up with something different. The question is What is the probability that two numbers randomly chosen are coprime? More formally, calculate the limit as $n\to\infty$ of the probability that two randomly chosen numbers, both less than $n$ are coprime.","This is a really natural question for which I know a stunning solution. So I admit I have a solution, however I would like to see if anybody will come up with something different. The question is What is the probability that two numbers randomly chosen are coprime? More formally, calculate the limit as $n\to\infty$ of the probability that two randomly chosen numbers, both less than $n$ are coprime.",,"['probability', 'elementary-number-theory', 'prime-numbers', 'riemann-zeta', 'integers']"
91,Boy Born on a Tuesday - is it just a language trick?,Boy Born on a Tuesday - is it just a language trick?,,"The following probability question appeared in an earlier thread : I have two children. One is a boy born on a Tuesday. What is the probability I have two boys? The claim was that it is not actually a mathematical problem and it is only a language problem. If one wanted to restate this problem formally the obvious way would be like so: Definition : Sex is defined as an element of the set $\\{\text{boy},\text{girl}\\}$. Definition : Birthday is defined as an element of the set $\\{\text{Monday},\text{Tuesday},\text{Wednesday},\text{Thursday},\text{Friday},\text{Saturday},\text{Sunday}\\}$ Definition : A Child is defined to be an ordered pair: (sex $\times$ birthday). Let $(x,y)$ be a pair of children, Define an auxiliary predicate $H(s,b) :\\!\\!\iff s = \text{boy} \text{ and } b = \text{Tuesday}$. Calculate $P(x \text{ is a boy and } y \text{ is a boy}|H(x) \text{ or } H(y))$ I don't see any other sensible way to formalize this question. To actually solve this problem now requires no thought (infact it is thinking which leads us to guess incorrect answers), we just compute $$ \begin{align*} & P(x \text{ is a boy and } y \text{ is a boy}|H(x) \text{ or } H(y)) \\\\ =& \frac{P(x\text{ is a boy and }y\text{ is a boy and }(H(x)\text{ or }H(y)))}         {P(H(x)\text{ or }H(y))} \\\\ =& \frac{P((x\text{ is a boy and }y\text{ is a boy and }H(x))\text{ or }(x\text{ is a boy and }y\text{ is a boy and }H(y)))}         {P(H(x)) + P(H(y)) - P(H(x))P(H(y))} \\\\ =& \frac{\begin{align*} &P(x\text{ is a boy and }y\text{ is a boy and }x\text{ born on Tuesday}) \\\\    + &P(x\text{ is a boy and }y\text{ is a boy and }y\text{ born on Tuesday}) \\\\    - &P(x\text{ is a boy and }y\text{ is a boy and }x\text{ born on Tuesday and }y\text{ born on Tuesday}) \\\\    \end{align*}}    {P(H(x)) + P(H(y)) - P(H(x))P(H(y))} \\\\ =& \frac{1/2 \cdot 1/2 \cdot 1/7 + 1/2 \cdot 1/2 \cdot 1/7 - 1/2 \cdot 1/2 \cdot 1/7 \cdot 1/7}         {1/2 \cdot 1/7 + 1/2 \cdot 1/7 - 1/2 \cdot 1/7 \cdot 1/2 \cdot 1/7} \\\\ =& 13/27 \end{align*} $$ Now what I am wondering is, does this refute the claim that this puzzle is just a language problem or add to it? Was there a lot of room for misinterpreting the questions which I just missed?","The following probability question appeared in an earlier thread : I have two children. One is a boy born on a Tuesday. What is the probability I have two boys? The claim was that it is not actually a mathematical problem and it is only a language problem. If one wanted to restate this problem formally the obvious way would be like so: Definition : Sex is defined as an element of the set $\\{\text{boy},\text{girl}\\}$. Definition : Birthday is defined as an element of the set $\\{\text{Monday},\text{Tuesday},\text{Wednesday},\text{Thursday},\text{Friday},\text{Saturday},\text{Sunday}\\}$ Definition : A Child is defined to be an ordered pair: (sex $\times$ birthday). Let $(x,y)$ be a pair of children, Define an auxiliary predicate $H(s,b) :\\!\\!\iff s = \text{boy} \text{ and } b = \text{Tuesday}$. Calculate $P(x \text{ is a boy and } y \text{ is a boy}|H(x) \text{ or } H(y))$ I don't see any other sensible way to formalize this question. To actually solve this problem now requires no thought (infact it is thinking which leads us to guess incorrect answers), we just compute $$ \begin{align*} & P(x \text{ is a boy and } y \text{ is a boy}|H(x) \text{ or } H(y)) \\\\ =& \frac{P(x\text{ is a boy and }y\text{ is a boy and }(H(x)\text{ or }H(y)))}         {P(H(x)\text{ or }H(y))} \\\\ =& \frac{P((x\text{ is a boy and }y\text{ is a boy and }H(x))\text{ or }(x\text{ is a boy and }y\text{ is a boy and }H(y)))}         {P(H(x)) + P(H(y)) - P(H(x))P(H(y))} \\\\ =& \frac{\begin{align*} &P(x\text{ is a boy and }y\text{ is a boy and }x\text{ born on Tuesday}) \\\\    + &P(x\text{ is a boy and }y\text{ is a boy and }y\text{ born on Tuesday}) \\\\    - &P(x\text{ is a boy and }y\text{ is a boy and }x\text{ born on Tuesday and }y\text{ born on Tuesday}) \\\\    \end{align*}}    {P(H(x)) + P(H(y)) - P(H(x))P(H(y))} \\\\ =& \frac{1/2 \cdot 1/2 \cdot 1/7 + 1/2 \cdot 1/2 \cdot 1/7 - 1/2 \cdot 1/2 \cdot 1/7 \cdot 1/7}         {1/2 \cdot 1/7 + 1/2 \cdot 1/7 - 1/2 \cdot 1/7 \cdot 1/2 \cdot 1/7} \\\\ =& 13/27 \end{align*} $$ Now what I am wondering is, does this refute the claim that this puzzle is just a language problem or add to it? Was there a lot of room for misinterpreting the questions which I just missed?",,['probability']
92,Intuitive explanation of the tower property of conditional expectation,Intuitive explanation of the tower property of conditional expectation,,"I understand how to define conditional expectation and how to prove that it exists. Further, I think I understand what conditional expectation means intuitively. I can also prove the tower property, that is if $X$ and $Y$ are random variables (or $Y$ a $\sigma$-field) then we have that $$\mathbb E[X] = \mathbb{E}[\mathbb E [X | Y]].$$ My question is: What is the intuitive meaning of this? It seems quite puzzling to me. (I could find similar questions but not this one.)","I understand how to define conditional expectation and how to prove that it exists. Further, I think I understand what conditional expectation means intuitively. I can also prove the tower property, that is if $X$ and $Y$ are random variables (or $Y$ a $\sigma$-field) then we have that $$\mathbb E[X] = \mathbb{E}[\mathbb E [X | Y]].$$ My question is: What is the intuitive meaning of this? It seems quite puzzling to me. (I could find similar questions but not this one.)",,"['probability', 'probability-theory', 'intuition', 'conditional-expectation']"
93,A variant of the Monty Hall problem,A variant of the Monty Hall problem,,"Everybody knows the famous Monty Hall problem ; way too much ink has been spilled over it already. Let's take it as a given and consider the following variant of the problem that I thought up this morning. Suppose Monty has three apples. Two of them have worms in them, and one doesn't. (For the purposes of this problem, let's assume that finding a worm in your apple is an undesirable outcome). He gives three ""contestants"" one apple each, then he picks one that he knows has a worm in his apple and instructs him to bite into it. The poor contestant does so, finds (half of) a worm in it, and runs off-stage in disgust. Now consider the situations of the two remaining contestants. Each one has a classical Monty Hall problem facing him. From player A's perspective, one ""door"" has been ""opened"" and revealed to have a ""goat""; using the same logic as before, he should choose to switch apples with player B. The paradox is that player B can use the same logic to conclude that he should switch apples with player A. Therefore, each of the two remaining contestants agree that they should switch apples, and they'll both be better off! Of course, this can't be the case. Exactly one of them gets a worm no matter what. Where is the flaw in the logic? Where does the analogy between this variant of the problem and the classical version break down?","Everybody knows the famous Monty Hall problem ; way too much ink has been spilled over it already. Let's take it as a given and consider the following variant of the problem that I thought up this morning. Suppose Monty has three apples. Two of them have worms in them, and one doesn't. (For the purposes of this problem, let's assume that finding a worm in your apple is an undesirable outcome). He gives three ""contestants"" one apple each, then he picks one that he knows has a worm in his apple and instructs him to bite into it. The poor contestant does so, finds (half of) a worm in it, and runs off-stage in disgust. Now consider the situations of the two remaining contestants. Each one has a classical Monty Hall problem facing him. From player A's perspective, one ""door"" has been ""opened"" and revealed to have a ""goat""; using the same logic as before, he should choose to switch apples with player B. The paradox is that player B can use the same logic to conclude that he should switch apples with player A. Therefore, each of the two remaining contestants agree that they should switch apples, and they'll both be better off! Of course, this can't be the case. Exactly one of them gets a worm no matter what. Where is the flaw in the logic? Where does the analogy between this variant of the problem and the classical version break down?",,"['probability', 'recreational-mathematics', 'puzzle', 'paradoxes', 'monty-hall']"
94,What is the proof that covariance matrices are always semi-definite?,What is the proof that covariance matrices are always semi-definite?,,"Suppose that we have two different discreet signal vectors of $N^\text{th}$ dimension, namely $\mathbf{x}[i]$ and $\mathbf{y}[i]$, each one having a total of $M$ set of samples/vectors. $\mathbf{x}[m] = [x_{m,1} \,\,\,\,\, x_{m,2} \,\,\,\,\, x_{m,3} \,\,\,\,\, ... \,\,\,\,\, x_{m,N}]^\text{T}; \,\,\,\,\,\,\, 1 \leq m \leq M$ $\mathbf{y}[m] = [y_{m,1} \,\,\,\,\, y_{m,2} \,\,\,\,\, y_{m,3} \,\,\,\,\, ... \,\,\,\,\, y_{m,N}]^\text{T}; \,\,\,\,\,\,\,\,\, 1 \leq m \leq M$ And, I build up a covariance matrix in-between these signals. $\{C\}_{ij} = E\left\{(\mathbf{x}[i] - \bar{\mathbf{x}}[i])^\text{T}(\mathbf{y}[j] - \bar{\mathbf{y}}[j])\right\}; \,\,\,\,\,\,\,\,\,\,\,\, 1 \leq i,j \leq M $ Where, $E\{\}$ is the ""expected value"" operator. What is the proof that, for all arbitrary values of $\mathbf{x}$ and $\mathbf{y}$ vector sets, the covariance matrix $C$ is always semi-definite ($C \succeq0$) (i.e.; not negative definte; all of its eigenvalues are non-negative)?","Suppose that we have two different discreet signal vectors of $N^\text{th}$ dimension, namely $\mathbf{x}[i]$ and $\mathbf{y}[i]$, each one having a total of $M$ set of samples/vectors. $\mathbf{x}[m] = [x_{m,1} \,\,\,\,\, x_{m,2} \,\,\,\,\, x_{m,3} \,\,\,\,\, ... \,\,\,\,\, x_{m,N}]^\text{T}; \,\,\,\,\,\,\, 1 \leq m \leq M$ $\mathbf{y}[m] = [y_{m,1} \,\,\,\,\, y_{m,2} \,\,\,\,\, y_{m,3} \,\,\,\,\, ... \,\,\,\,\, y_{m,N}]^\text{T}; \,\,\,\,\,\,\,\,\, 1 \leq m \leq M$ And, I build up a covariance matrix in-between these signals. $\{C\}_{ij} = E\left\{(\mathbf{x}[i] - \bar{\mathbf{x}}[i])^\text{T}(\mathbf{y}[j] - \bar{\mathbf{y}}[j])\right\}; \,\,\,\,\,\,\,\,\,\,\,\, 1 \leq i,j \leq M $ Where, $E\{\}$ is the ""expected value"" operator. What is the proof that, for all arbitrary values of $\mathbf{x}$ and $\mathbf{y}$ vector sets, the covariance matrix $C$ is always semi-definite ($C \succeq0$) (i.e.; not negative definte; all of its eigenvalues are non-negative)?",,"['probability', 'matrices', 'vector-spaces', 'proof-writing', 'positive-semidefinite']"
95,A disc contains $n$ random points. Each point is connected to its nearest neighbor. What does the average cluster size approach as $n\to\infty$?,A disc contains  random points. Each point is connected to its nearest neighbor. What does the average cluster size approach as ?,n n\to\infty,"A disc contains $n$ independent uniformly random points. Each point is connected by a line segment to its nearest neighbor, forming clusters of connected points. For example, here are $20$ random points and $7$ clusters, with an average cluster size of $\frac{20}{7}$ . What does the average cluster size approach as $n\to\infty$ ? My attempt: I made a random point generator that generates $20$ random points. The average cluster size is usually approximately $3$ . I considered what happens when we add a new random point to a large set of random points. Adding the point either causes no change in the number of clusters, or it causes the number of clusters to increase by $1$ ( Edit: this is not true, as noted by @TonyK in the comments). The probability that adding a new point increases the number of clusters by $1$ , is the reciprocal of the answer to my question. (Analogy: Imagine guests arriving to a party; if 25% of guests bring a bottle of wine, then the expectation of the average number of guests per bottle of wine is $4$ .) But I haven't worked out this probability. Context: This question was inspired by the question Stars in the universe - probability of mutual nearest neighbors . Edit: Postd on MO .","A disc contains independent uniformly random points. Each point is connected by a line segment to its nearest neighbor, forming clusters of connected points. For example, here are random points and clusters, with an average cluster size of . What does the average cluster size approach as ? My attempt: I made a random point generator that generates random points. The average cluster size is usually approximately . I considered what happens when we add a new random point to a large set of random points. Adding the point either causes no change in the number of clusters, or it causes the number of clusters to increase by ( Edit: this is not true, as noted by @TonyK in the comments). The probability that adding a new point increases the number of clusters by , is the reciprocal of the answer to my question. (Analogy: Imagine guests arriving to a party; if 25% of guests bring a bottle of wine, then the expectation of the average number of guests per bottle of wine is .) But I haven't worked out this probability. Context: This question was inspired by the question Stars in the universe - probability of mutual nearest neighbors . Edit: Postd on MO .",n 20 7 \frac{20}{7} n\to\infty 20 3 1 1 4,"['probability', 'geometry', 'expected-value', 'geometric-probability', 'percolation']"
96,Minesweeper - Chance of one-click win,Minesweeper - Chance of one-click win,,"I'd like to know if it's possible to calculate the odds of winning a game of Minesweeper (on easy difficulty) in a single click. This page documents a bug that occurs if you do so, and they calculate the odds to around 1 in 800,000.  However, this is based on the older version of Minesweeper, which had a fixed number of preset boards, so not every arrangement of mines was possible.  (Also the board size in the current version is 9x9, while the old one was 8x8.  Let's ignore the intermediate and expert levels for now - I assume those odds are nearly impossible, though a generalized solution that could solve for any W×H and mine-count would be cool too, but a lot more work I'd think.)  In general, the increased board size (with the same number of mines), as well as the removal of the preset boards would both probably make such an event far more common. So, assuming a 9x9 board with 10 mines, and assuming every possible arrangement of mines is equally likely (not true given the pseudo-random nature of computer random number generators, but let's pretend), and knowing that the first click is always safe (assume the described behavior on that site still holds - if you click on a mine in the first click, it's moved to the first available square in the upper-left corner), we'd need to first calculate the number of boards that are 1-click solvable.  That is, boards with only one opening, and no numbered squares that are not adjacent to that opening.  The total number of boards is easy enough: $\frac{(W×H)!}{((W×H)-M)! ×M!}$ or $\frac{81!}{71!×10!} \approx 1.878×10^{12}$.  (Trickier is figuring out which boards are not one-click solvable unless you click on a mine and move it.  We can maybe ignore the first-click-safe rule if it over-complicates things.)  Valid arrangements would have all 10 mines either on the edges or far enough away from each other to avoid creating numbers which don't touch the opening.  Then it's a simple matter of counting how many un-numbered spaces exist on each board and dividing by 81. Is this a calculation that can reasonably be represented in a mathematical formula?  Or would it make more sense to write a program to test every possible board configuration?  (Unfortunately, the numbers we're dealing with get pretty close to the maximum value storable in a 64-bit integer, so overflow is very likely here.  For example, the default Windows calculator completely borks the number unless you multiply by hand from 81 down to 72.)","I'd like to know if it's possible to calculate the odds of winning a game of Minesweeper (on easy difficulty) in a single click. This page documents a bug that occurs if you do so, and they calculate the odds to around 1 in 800,000.  However, this is based on the older version of Minesweeper, which had a fixed number of preset boards, so not every arrangement of mines was possible.  (Also the board size in the current version is 9x9, while the old one was 8x8.  Let's ignore the intermediate and expert levels for now - I assume those odds are nearly impossible, though a generalized solution that could solve for any W×H and mine-count would be cool too, but a lot more work I'd think.)  In general, the increased board size (with the same number of mines), as well as the removal of the preset boards would both probably make such an event far more common. So, assuming a 9x9 board with 10 mines, and assuming every possible arrangement of mines is equally likely (not true given the pseudo-random nature of computer random number generators, but let's pretend), and knowing that the first click is always safe (assume the described behavior on that site still holds - if you click on a mine in the first click, it's moved to the first available square in the upper-left corner), we'd need to first calculate the number of boards that are 1-click solvable.  That is, boards with only one opening, and no numbered squares that are not adjacent to that opening.  The total number of boards is easy enough: $\frac{(W×H)!}{((W×H)-M)! ×M!}$ or $\frac{81!}{71!×10!} \approx 1.878×10^{12}$.  (Trickier is figuring out which boards are not one-click solvable unless you click on a mine and move it.  We can maybe ignore the first-click-safe rule if it over-complicates things.)  Valid arrangements would have all 10 mines either on the edges or far enough away from each other to avoid creating numbers which don't touch the opening.  Then it's a simple matter of counting how many un-numbered spaces exist on each board and dividing by 81. Is this a calculation that can reasonably be represented in a mathematical formula?  Or would it make more sense to write a program to test every possible board configuration?  (Unfortunately, the numbers we're dealing with get pretty close to the maximum value storable in a 64-bit integer, so overflow is very likely here.  For example, the default Windows calculator completely borks the number unless you multiply by hand from 81 down to 72.)",,"['probability', 'combinatorics', 'recreational-mathematics']"
97,Free throw interview question,Free throw interview question,,"I recently had an interview question that posed the following... Suppose you are shooting free throws and each shot has a 60% chance of going in (there are no ""learning"" or ""depreciation"" effects, all have the some probability no matter how many shots you take). Now there are three scenarios where you can win $1000 Make at least 2 out of 3 Make at least 4 out of 6 Make at least 20 out of 30 My initial thought is that each are equally appealing as they all require the same percentage of free throw shots.  However when using a binomial calculator (which this process seems to be) the P (X > x) seems to be the highest for scenario 1.  Is this due to the number of combinations?","I recently had an interview question that posed the following... Suppose you are shooting free throws and each shot has a 60% chance of going in (there are no ""learning"" or ""depreciation"" effects, all have the some probability no matter how many shots you take). Now there are three scenarios where you can win $1000 Make at least 2 out of 3 Make at least 4 out of 6 Make at least 20 out of 30 My initial thought is that each are equally appealing as they all require the same percentage of free throw shots.  However when using a binomial calculator (which this process seems to be) the P (X > x) seems to be the highest for scenario 1.  Is this due to the number of combinations?",,"['probability', 'expected-value']"
98,Does convergence in distribution implies convergence of expectation?,Does convergence in distribution implies convergence of expectation?,,"If we have a sequence of random variables $X_1,X_2,\ldots,X_n$ converges in distribution to $X$, i.e. $X_n \rightarrow_d X$, then is $$ \lim_{n \to \infty} E(X_n) = E(X) $$ correct? I know that converge in distribution implies $E(g(X_n)) \to E(g(X))$ when $g$ is a bounded continuous function.  Can we apply this property here?","If we have a sequence of random variables $X_1,X_2,\ldots,X_n$ converges in distribution to $X$, i.e. $X_n \rightarrow_d X$, then is $$ \lim_{n \to \infty} E(X_n) = E(X) $$ correct? I know that converge in distribution implies $E(g(X_n)) \to E(g(X))$ when $g$ is a bounded continuous function.  Can we apply this property here?",,"['probability', 'probability-theory', 'convergence-divergence']"
99,Inequality for expected value,Inequality for expected value,,"A colleague popped into my office this afternoon and asked me the following question. He told me there is a  clever proof when $n=2$. I couldn't do anything with it, so I thought I'd post it here and see what happens. Prove or find a counterexample For positive, i.i.d. random variables $Z_1,\dots, Z_n$  with finite mean, and positive constants $a_1,\dots, a_n$, we have $$\mathbb{E}\left({\sum_{i=1}^n a_i^2 Z_i\over\sum_{i=1}^n a_i Z_i}\right) \leq {\sum_{i=1}^n a_i^2\over\sum_{i=1}^n a_i}.$$ Added: This problem originates from the thesis of a student in Computer and Electrical Engineering at the University of Alberta. Here is the response from his supervisor: ""Many thanks for this!  It is a nice result in addition to being useful in a practical problem of antenna placement.""","A colleague popped into my office this afternoon and asked me the following question. He told me there is a  clever proof when $n=2$. I couldn't do anything with it, so I thought I'd post it here and see what happens. Prove or find a counterexample For positive, i.i.d. random variables $Z_1,\dots, Z_n$  with finite mean, and positive constants $a_1,\dots, a_n$, we have $$\mathbb{E}\left({\sum_{i=1}^n a_i^2 Z_i\over\sum_{i=1}^n a_i Z_i}\right) \leq {\sum_{i=1}^n a_i^2\over\sum_{i=1}^n a_i}.$$ Added: This problem originates from the thesis of a student in Computer and Electrical Engineering at the University of Alberta. Here is the response from his supervisor: ""Many thanks for this!  It is a nice result in addition to being useful in a practical problem of antenna placement.""",,['probability']
