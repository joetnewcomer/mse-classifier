,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Trigonometric Limit without L'Hopital,Trigonometric Limit without L'Hopital,,"I am having problems solving this limit without L'Hopital or series. $$   \lim_{ x\to 0 } \frac{x\cos(x) - \sin(x)}{2  x^3} $$ I tried some trigonometric manipulations without success. I tried Trigonometric identities with no luck and separating $$  \frac{x\cos(x)}{2  x^3}   and   \frac{sin(x)}{2  x^3} $$ lead me nowhere, each of this limits are infinity. I kow the result is $$   \lim_{ x\to 0 } \frac{x\cos(x) - \sin(x)}{2  x^3} = \frac{-1}{6} $$","I am having problems solving this limit without L'Hopital or series. $$   \lim_{ x\to 0 } \frac{x\cos(x) - \sin(x)}{2  x^3} $$ I tried some trigonometric manipulations without success. I tried Trigonometric identities with no luck and separating $$  \frac{x\cos(x)}{2  x^3}   and   \frac{sin(x)}{2  x^3} $$ lead me nowhere, each of this limits are infinity. I kow the result is $$   \lim_{ x\to 0 } \frac{x\cos(x) - \sin(x)}{2  x^3} = \frac{-1}{6} $$",,"['limits', 'trigonometry', 'limits-without-lhopital']"
1,Limit as $n\to\infty$ of $\frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+...+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)}$,Limit as  of,n\to\infty \frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+...+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)},The task is to get the limit below: $$\lim_{n\rightarrow \infty}\frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+\cdots+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)}$$ I used Stolz but I don't know how to subtract the sequence.,The task is to get the limit below: $$\lim_{n\rightarrow \infty}\frac{\frac{n}{1}+\frac{n-1}{2}+\frac{n-3}{3}+\cdots+\frac{2}{n-1}+\frac{1}{n}}{\ln(n!)}$$ I used Stolz but I don't know how to subtract the sequence.,,"['real-analysis', 'limits']"
2,"How to prove $\lim\limits_{(x,y)\to(0,0)}\frac{{x^3{y^2}}}{{{x^4} + {3y^4}}} = 0$?",How to prove ?,"\lim\limits_{(x,y)\to(0,0)}\frac{{x^3{y^2}}}{{{x^4} + {3y^4}}} = 0","To prove that $$\lim\limits_{(x,y)\to(0,0)}\frac{{x^3{y^2}}}{{{x^4} + {3y^4}}} = 0$$ I start with  $$\left| {\frac{{{x^3}{y^2}}}{{{x^4} + 3{y^4}}}} \right| \leqslant \left| {\frac{{{x^3}{y^2}}}{{{x^4}}}} \right| = \left| {\frac{{{y^2}}}{x}} \right|.$$ But I do not know how to show $| {\frac{{{y^2}}}{x}}|$ is bounded using the hypothesis that $0<|x|<\delta$, $0<|y|<\delta$ and $0<\sqrt{x^2+y^2}<\delta$ since the quarters powers of $x$ and $y$  are very difficult to manage. Even setting $\delta=1$ gets me nowhere.","To prove that $$\lim\limits_{(x,y)\to(0,0)}\frac{{x^3{y^2}}}{{{x^4} + {3y^4}}} = 0$$ I start with  $$\left| {\frac{{{x^3}{y^2}}}{{{x^4} + 3{y^4}}}} \right| \leqslant \left| {\frac{{{x^3}{y^2}}}{{{x^4}}}} \right| = \left| {\frac{{{y^2}}}{x}} \right|.$$ But I do not know how to show $| {\frac{{{y^2}}}{x}}|$ is bounded using the hypothesis that $0<|x|<\delta$, $0<|y|<\delta$ and $0<\sqrt{x^2+y^2}<\delta$ since the quarters powers of $x$ and $y$  are very difficult to manage. Even setting $\delta=1$ gets me nowhere.",,"['calculus', 'real-analysis', 'limits', 'multivariable-calculus']"
3,Prove $\lim_{x\to\infty} \left( \sqrt{x+1} - \sqrt{x} \right) = 0$,Prove,\lim_{x\to\infty} \left( \sqrt{x+1} - \sqrt{x} \right) = 0,"My attempt: I tried manipulating the formula, but I couldn't do anything useful. I tried to find another function $f(x)$ such that $\lim_{x\to\infty} f(x) = 0$ and $f(x) \geq  \sqrt{x+1} - \sqrt{x} $ for all $x$. $f(x) = \frac1x$ fails but I think $f(x) = \frac{1}{\sqrt{x}}$ would work (not sure how to verify this). I'm not sure how to proceed.","My attempt: I tried manipulating the formula, but I couldn't do anything useful. I tried to find another function $f(x)$ such that $\lim_{x\to\infty} f(x) = 0$ and $f(x) \geq  \sqrt{x+1} - \sqrt{x} $ for all $x$. $f(x) = \frac1x$ fails but I think $f(x) = \frac{1}{\sqrt{x}}$ would work (not sure how to verify this). I'm not sure how to proceed.",,['limits']
4,Infinite sequence series. Limit,Infinite sequence series. Limit,,"If $0<x<1$ and $$A_n=\frac{x}{1-x^2}+\frac{x^2}{1-x^4}+\ldots+\frac{x^{2^n}}{1-x^{2^{n+1}}},$$ then $\lim_{n\to\infty} A_n$ is $$\text{a) }\ \dfrac{x}{1-x} \qquad\qquad \text{b) }\ \frac{1}{1-x} \qquad\qquad \text{c) }\ \frac{1}{1+x} \qquad\qquad \text{d) }\ \frac{x}{1+x}$$ How to do this? Not able to convert in any standard form.","If $0<x<1$ and $$A_n=\frac{x}{1-x^2}+\frac{x^2}{1-x^4}+\ldots+\frac{x^{2^n}}{1-x^{2^{n+1}}},$$ then $\lim_{n\to\infty} A_n$ is $$\text{a) }\ \dfrac{x}{1-x} \qquad\qquad \text{b) }\ \frac{1}{1-x} \qquad\qquad \text{c) }\ \frac{1}{1+x} \qquad\qquad \text{d) }\ \frac{x}{1+x}$$ How to do this? Not able to convert in any standard form.",,"['calculus', 'sequences-and-series', 'limits']"
5,Prove that if $a_{2n} \rightarrow g$ and $a_{2n+1} \rightarrow g$ then $a_n \rightarrow g$ [duplicate],Prove that if  and  then  [duplicate],a_{2n} \rightarrow g a_{2n+1} \rightarrow g a_n \rightarrow g,This question already has an answer here : Convergence of a sequence whose even and odd subsequences converge [duplicate] (1 answer) Closed 9 years ago . The problem is in the question: Prove that if sequences $a_{2n} \rightarrow g$ and $a_{2n+1} \rightarrow g$ then $a_n \rightarrow g$. I don't know how to prove that - it seems obvious when we look at the definition that for sufficiently large $n$ (let's say $n>N$) we have $|a_{2n}-g|$ and $|a_{2n+1}-g|$ less than any given $\epsilon$ and these  are all elements of $a_n$ when $n>N$ (even and odd terms). Does this need more formal proof?,This question already has an answer here : Convergence of a sequence whose even and odd subsequences converge [duplicate] (1 answer) Closed 9 years ago . The problem is in the question: Prove that if sequences $a_{2n} \rightarrow g$ and $a_{2n+1} \rightarrow g$ then $a_n \rightarrow g$. I don't know how to prove that - it seems obvious when we look at the definition that for sufficiently large $n$ (let's say $n>N$) we have $|a_{2n}-g|$ and $|a_{2n+1}-g|$ less than any given $\epsilon$ and these  are all elements of $a_n$ when $n>N$ (even and odd terms). Does this need more formal proof?,,"['sequences-and-series', 'limits']"
6,Showing $\left\{ \frac{1}{n^n}\sum_{k=1}^{n}{k^k} \right\}_{n \in \mathbb{N}}\rightarrow 1$,Showing,\left\{ \frac{1}{n^n}\sum_{k=1}^{n}{k^k} \right\}_{n \in \mathbb{N}}\rightarrow 1,"I would like to prove: $$\left\{ \frac{1}{n^n}\sum_{k=1}^{n}{k^k} \right\}_{n \in \mathbb{N}}\rightarrow 1$$ I found a proof applying Stolz criterion but I need to use the fact that: $$\left\{\left(\frac{n}{n+1}\right)^n\right\}\text{ is bounded}\tag{$\ast$}$$ I would like to calculate this limit without using $(\ast)$ and preferably using basic limit criterion and properties. ( Sorry about mispellings or mistakes, English is not my native language. )","I would like to prove: $$\left\{ \frac{1}{n^n}\sum_{k=1}^{n}{k^k} \right\}_{n \in \mathbb{N}}\rightarrow 1$$ I found a proof applying Stolz criterion but I need to use the fact that: $$\left\{\left(\frac{n}{n+1}\right)^n\right\}\text{ is bounded}\tag{$\ast$}$$ I would like to calculate this limit without using $(\ast)$ and preferably using basic limit criterion and properties. ( Sorry about mispellings or mistakes, English is not my native language. )",,"['calculus', 'sequences-and-series', 'limits']"
7,"Multiple choice question about limits and continuity? (Or, $\tan x$ is continuous?!)","Multiple choice question about limits and continuity? (Or,  is continuous?!)",\tan x,"I'm doing a test about limits and continuity and got these two wrong. $\mathbf{Q1}$: The function $f(x) = \tan x$: $\hspace{1em}\mathtt{a)}$ is continuous $\hspace{1em}\mathtt{b)}$ is discontinuous $\hspace{1em}\mathtt{c)}$ is increasing $\hspace{1em}\mathtt{d)}$ is even According to my professor the right one is $\mathtt{a)}$, but I don't see how $\tan x$ can be continuous. In fact, my answer was $\mathtt{b)}$, because it's discontinuous at $x = \frac\pi2 + k\pi$, with $k \in \mathbb{Z}$. Is there a definition of continuity according to which $\tan x$ is continuous? $\mathbf{Q2}$: Between the following, select the correct sentence $\hspace{1em}\mathtt{a)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ then $f$ is increasing $\hspace{1em}\mathtt{b)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ then there exist an half line $(r, +\infty)$ on which $f$ can be inverted $\hspace{1em}\mathtt{c)}$ the fact that $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ does not imply that $f$'s domain contains half lines of the form $(r, +\infty)$ $\hspace{1em}\mathtt{d)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ and $f$ can be inverted, then $\displaystyle\lim_{x \to +\infty}f^{-1}(x) = +\infty$ Here the correct one is $\mathtt{c)}$, while I replied $\mathtt{d)}$. I thought that given the premises in $\mathtt{d)}$, $f$ would be monotone increasing and thus $f^{-1}$ would be as well. Examples: $\exp(x)$ and $\ln x$, $x$ and $x$, $x^2$ (with $x > 0$) and $\sqrt{x}$... Apart from $\mathtt{a)}$, which is obviously wrong, can you explain me the other answers?","I'm doing a test about limits and continuity and got these two wrong. $\mathbf{Q1}$: The function $f(x) = \tan x$: $\hspace{1em}\mathtt{a)}$ is continuous $\hspace{1em}\mathtt{b)}$ is discontinuous $\hspace{1em}\mathtt{c)}$ is increasing $\hspace{1em}\mathtt{d)}$ is even According to my professor the right one is $\mathtt{a)}$, but I don't see how $\tan x$ can be continuous. In fact, my answer was $\mathtt{b)}$, because it's discontinuous at $x = \frac\pi2 + k\pi$, with $k \in \mathbb{Z}$. Is there a definition of continuity according to which $\tan x$ is continuous? $\mathbf{Q2}$: Between the following, select the correct sentence $\hspace{1em}\mathtt{a)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ then $f$ is increasing $\hspace{1em}\mathtt{b)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ then there exist an half line $(r, +\infty)$ on which $f$ can be inverted $\hspace{1em}\mathtt{c)}$ the fact that $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ does not imply that $f$'s domain contains half lines of the form $(r, +\infty)$ $\hspace{1em}\mathtt{d)}$ if $\displaystyle\lim_{x \to +\infty} f(x) = +\infty$ and $f$ can be inverted, then $\displaystyle\lim_{x \to +\infty}f^{-1}(x) = +\infty$ Here the correct one is $\mathtt{c)}$, while I replied $\mathtt{d)}$. I thought that given the premises in $\mathtt{d)}$, $f$ would be monotone increasing and thus $f^{-1}$ would be as well. Examples: $\exp(x)$ and $\ln x$, $x$ and $x$, $x^2$ (with $x > 0$) and $\sqrt{x}$... Apart from $\mathtt{a)}$, which is obviously wrong, can you explain me the other answers?",,"['calculus', 'limits', 'trigonometry', 'continuity']"
8,$1/\infty$ is zero or infinitesimal? [closed],is zero or infinitesimal? [closed],1/\infty,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Since $\infty>0$, so $1/\infty >0$, thus I think $1/\infty$ should be infinitesimal, but the calculus book says  $$\lim_{x \to \infty} \frac{1}{x}= 0$$ So is $1/\infty$ zero or infinitesimal ? P.S. I mean are $1/\infty$ and $\lim_{x \to \infty} 1/x$ the same thing here?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Since $\infty>0$, so $1/\infty >0$, thus I think $1/\infty$ should be infinitesimal, but the calculus book says  $$\lim_{x \to \infty} \frac{1}{x}= 0$$ So is $1/\infty$ zero or infinitesimal ? P.S. I mean are $1/\infty$ and $\lim_{x \to \infty} 1/x$ the same thing here?",,"['calculus', 'limits', 'infinity', 'nonstandard-analysis', 'infinitesimals']"
9,Limit of a sequence defined by recursive relation : $ a_n = \sqrt{a_{n-1}a_{n-2}}$,Limit of a sequence defined by recursive relation :, a_n = \sqrt{a_{n-1}a_{n-2}},"We're given a sequence defined by the recursive relation: $$a_n = \sqrt{a_{n-1}a_{n-2}}$$ $a_1$ and $a_2$ are positive constants. We have to show the following: The sequences $\{ b_n \} = \{ a_{2n-1} \}$ and $\{ c_n \} = \{ a_{2n} \} $ are monotonic, and if one is increasing, the other is decreasing. The limit of the sequence $\{ a_n \} $ is $ \left(a_1a_2^2\right)^{\frac13} $ Now, I have proved the first part. Besides that, I have also proved a few other things: If $a_1 > a_2$, then: a. $ \{ b_n \} $ decreases, and $ \{ c_n \} $ increases. b. $ c_n < b_n $ If $a_1 < a_2$, we just flip $\{ b_n \}$ and $\{c_n\}$ Besides, I have also shown that both the sequences : $\{b_n\}$ and $\{ c_n\}$ have the same limit. What I don't know, is how to evaluate the limit.","We're given a sequence defined by the recursive relation: $$a_n = \sqrt{a_{n-1}a_{n-2}}$$ $a_1$ and $a_2$ are positive constants. We have to show the following: The sequences $\{ b_n \} = \{ a_{2n-1} \}$ and $\{ c_n \} = \{ a_{2n} \} $ are monotonic, and if one is increasing, the other is decreasing. The limit of the sequence $\{ a_n \} $ is $ \left(a_1a_2^2\right)^{\frac13} $ Now, I have proved the first part. Besides that, I have also proved a few other things: If $a_1 > a_2$, then: a. $ \{ b_n \} $ decreases, and $ \{ c_n \} $ increases. b. $ c_n < b_n $ If $a_1 < a_2$, we just flip $\{ b_n \}$ and $\{c_n\}$ Besides, I have also shown that both the sequences : $\{b_n\}$ and $\{ c_n\}$ have the same limit. What I don't know, is how to evaluate the limit.",,"['sequences-and-series', 'limits', 'recurrence-relations']"
10,How to prove that $ \lim_{n\to\infty}\left( \sum_{r=1}^n \dfrac 1 {\sqrt{n^2 + r}} \right) = 1$,How to prove that, \lim_{n\to\infty}\left( \sum_{r=1}^n \dfrac 1 {\sqrt{n^2 + r}} \right) = 1,"We have to show that  $$ \lim_{n\to\infty} \left( \dfrac 1 {\sqrt{n^2 +1}} +\dfrac 1 {\sqrt{n^2 +2}} + \dfrac 1 {\sqrt{n^2 +3}} + \ldots + \dfrac 1 {\sqrt{n^2 +n}} \right) = 1$$ Now, I thought of doing it as a definite integral, however the terms don't translate into a function of $\left(\dfrac r n\right)$. I tried searching wolfram-alpha, but it used Hurwitz-zeta function, of which I have no clue. (This is an assignment problem)","We have to show that  $$ \lim_{n\to\infty} \left( \dfrac 1 {\sqrt{n^2 +1}} +\dfrac 1 {\sqrt{n^2 +2}} + \dfrac 1 {\sqrt{n^2 +3}} + \ldots + \dfrac 1 {\sqrt{n^2 +n}} \right) = 1$$ Now, I thought of doing it as a definite integral, however the terms don't translate into a function of $\left(\dfrac r n\right)$. I tried searching wolfram-alpha, but it used Hurwitz-zeta function, of which I have no clue. (This is an assignment problem)",,"['calculus', 'sequences-and-series', 'limits']"
11,"If $f$ satisfies $\forall x\in\Bbb{R},0\leq f'(x), f''(x)$ and if $\exists a\in\Bbb{R}$ such that $0<f'(a)$, Then $lim_{x\to\infty}f(x)=\infty$","If  satisfies  and if  such that , Then","f \forall x\in\Bbb{R},0\leq f'(x), f''(x) \exists a\in\Bbb{R} 0<f'(a) lim_{x\to\infty}f(x)=\infty","I got this problem: Let $f:\mathbb{R}\to\mathbb{R}$ be a twice  differentiable function that satisfy $\forall x\in\mathbb{R},0\leq f'(x)$ and $0\leq f''(x)$ Prove that if $\exists a\in\mathbb{R}$ such that $0<f'(a)$, Then $lim_{x\to\infty}f(x)=\infty$ I tried to show that for each $0<M$ there exist $0<N$ such that for all $N<x$, $M<f(x)$, but I got stuck choosing an $N$ that satisfies the condition. Thanks on any hint.","I got this problem: Let $f:\mathbb{R}\to\mathbb{R}$ be a twice  differentiable function that satisfy $\forall x\in\mathbb{R},0\leq f'(x)$ and $0\leq f''(x)$ Prove that if $\exists a\in\mathbb{R}$ such that $0<f'(a)$, Then $lim_{x\to\infty}f(x)=\infty$ I tried to show that for each $0<M$ there exist $0<N$ such that for all $N<x$, $M<f(x)$, but I got stuck choosing an $N$ that satisfies the condition. Thanks on any hint.",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
12,Why does $\int_{-\infty}^{\infty} f(x) dx \ne \lim\limits_{t \to \infty} \int_{-t}^{t} f(x) dx$?,Why does ?,\int_{-\infty}^{\infty} f(x) dx \ne \lim\limits_{t \to \infty} \int_{-t}^{t} f(x) dx,I just get this is in my head. How come LHS is not equal to RHS.,I just get this is in my head. How come LHS is not equal to RHS.,,"['calculus', 'integration', 'limits', 'definite-integrals']"
13,one-sided limit $\lim_{x \rightarrow 0^+} f(x)$ where wolfram alpha does not help,one-sided limit  where wolfram alpha does not help,\lim_{x \rightarrow 0^+} f(x),"The function $f$ is defined as follows: $$f(x):=\sum_{j=1}^{\infty} \frac{x^j}{j!} e^{-x}$$ It's easy to see that $f(0)=0$. But I am interested in the value  $$\lim_{x \rightarrow 0^+} f(x).$$ Even Wolfram Alpha does not help here. I tried to plot this function, but this doesn't work neither. And my calculator doesn't give a solution for concrete values of $x$, so I have no idea how to get on here.","The function $f$ is defined as follows: $$f(x):=\sum_{j=1}^{\infty} \frac{x^j}{j!} e^{-x}$$ It's easy to see that $f(0)=0$. But I am interested in the value  $$\lim_{x \rightarrow 0^+} f(x).$$ Even Wolfram Alpha does not help here. I tried to plot this function, but this doesn't work neither. And my calculator doesn't give a solution for concrete values of $x$, so I have no idea how to get on here.",,['limits']
14,Limits with factorial,Limits with factorial,,"I'm having difficulties understanding all limits with factorial... Actually, what I don't understand is not the limit concept but how to simplify factorial... Example : $$\lim\limits_{n \to \infty} \frac{(n+1)!((n+1)^2 + 1)}{(n^2+1)(n+2)!}$$ I know that it's supposed to give $0$ as I have the answer, but I'd like to understand how to do it as each time I get a limit with factorial I get stuck. Thanks.","I'm having difficulties understanding all limits with factorial... Actually, what I don't understand is not the limit concept but how to simplify factorial... Example : $$\lim\limits_{n \to \infty} \frac{(n+1)!((n+1)^2 + 1)}{(n^2+1)(n+2)!}$$ I know that it's supposed to give $0$ as I have the answer, but I'd like to understand how to do it as each time I get a limit with factorial I get stuck. Thanks.",,"['limits', 'factorial']"
15,Proof of $e^x - 1 \geq x$ for ${x: -1 \leq x < 0}$ [duplicate],Proof of  for  [duplicate],e^x - 1 \geq x {x: -1 \leq x < 0},"This question already has answers here : Simplest or nicest proof that $1+x \le e^x$ (26 answers) Closed 10 years ago . Is this valid, and how can i prove that it holds. Proof of  $$e^x - 1 \geq x \text{ for } {x:-1 \leq x < 0}$$","This question already has answers here : Simplest or nicest proof that $1+x \le e^x$ (26 answers) Closed 10 years ago . Is this valid, and how can i prove that it holds. Proof of  $$e^x - 1 \geq x \text{ for } {x:-1 \leq x < 0}$$",,['limits']
16,Solving $\lim_{x\to0} x * \ln x$,Solving,\lim_{x\to0} x * \ln x,"I needed to solve $$\lim_{x \to 0} x * \ln x.$$ and I wasn't sure how I would do it so I looked up the answer. They used L'Hoptial to solve this and I don't understand why this works. $\lim_{x\to0} x * \ln x = \lim_{x\to0} \frac{\ln x}{1/x} $ but I can't use L'Hopital here because this is $\frac{\text{undefined}}{0}$ , so I looked up if $\ln 0$ is really undefined and it turns out that the limit of $\ln 0$ is $- \infty$ My textbook says I can only use L'Hopital with $\frac{\infty}{\infty}$ or $\frac{0}{0}$ , so why am I allowed to use L'Hopital in this case?","I needed to solve and I wasn't sure how I would do it so I looked up the answer. They used L'Hoptial to solve this and I don't understand why this works. but I can't use L'Hopital here because this is , so I looked up if is really undefined and it turns out that the limit of is My textbook says I can only use L'Hopital with or , so why am I allowed to use L'Hopital in this case?",\lim_{x \to 0} x * \ln x. \lim_{x\to0} x * \ln x = \lim_{x\to0} \frac{\ln x}{1/x}  \frac{\text{undefined}}{0} \ln 0 \ln 0 - \infty \frac{\infty}{\infty} \frac{0}{0},['limits']
17,"If $\lim_{n\to\infty}x_n=\alpha$, show $\lim_{n\to\infty}(x_1x_2\dots x_n)^{1/n} =\alpha$. [closed]","If , show . [closed]",\lim_{n\to\infty}x_n=\alpha \lim_{n\to\infty}(x_1x_2\dots x_n)^{1/n} =\alpha,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If $\lim_{n\to\infty} x_n = \alpha$ and $x_n \gt 0$ for all $n$, show that $$\lim_{n \to \infty}(x_1x_2\dots x_n)^{1/n} = \alpha.$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If $\lim_{n\to\infty} x_n = \alpha$ and $x_n \gt 0$ for all $n$, show that $$\lim_{n \to \infty}(x_1x_2\dots x_n)^{1/n} = \alpha.$$",,"['real-analysis', 'limits']"
18,Evaluate $\lim_{n\to\infty}(\sqrt{4n^2+n}-2n)$ [duplicate],Evaluate  [duplicate],\lim_{n\to\infty}(\sqrt{4n^2+n}-2n),"This question already has answers here : How would you prove that $\lim\limits_{n\to\infty}(\sqrt{4n^2+n}-2n)=\frac14$? (4 answers) Closed 6 years ago . Evaluate the following limit: $$\displaystyle\lim_{n\to\infty}(\sqrt{4n^2+n}-2n)$$ So far I've come up with this: $\displaystyle\lim_{n\to\infty}(\sqrt{4n^2+n}-2n)$ = $\displaystyle\lim_{n\to\infty}(\sqrt{4n^2(1+\frac{1}{4n}})-2n)$  = $\displaystyle\lim_{n\to\infty}(2n\sqrt{(1+\frac{1}{4n}})-2n)$ = $\displaystyle\lim_{n\to\infty}(2n(\sqrt{(1+\frac{1}{4n}})-1))$. I think it's pretty clear from here that this goes to infinity, but how can I justify that the 2n grows stronger to infinity than the part in the brackets goes to zero? I know standard rules about exponential functions growing harder than polynomials, but not about this.","This question already has answers here : How would you prove that $\lim\limits_{n\to\infty}(\sqrt{4n^2+n}-2n)=\frac14$? (4 answers) Closed 6 years ago . Evaluate the following limit: $$\displaystyle\lim_{n\to\infty}(\sqrt{4n^2+n}-2n)$$ So far I've come up with this: $\displaystyle\lim_{n\to\infty}(\sqrt{4n^2+n}-2n)$ = $\displaystyle\lim_{n\to\infty}(\sqrt{4n^2(1+\frac{1}{4n}})-2n)$  = $\displaystyle\lim_{n\to\infty}(2n\sqrt{(1+\frac{1}{4n}})-2n)$ = $\displaystyle\lim_{n\to\infty}(2n(\sqrt{(1+\frac{1}{4n}})-1))$. I think it's pretty clear from here that this goes to infinity, but how can I justify that the 2n grows stronger to infinity than the part in the brackets goes to zero? I know standard rules about exponential functions growing harder than polynomials, but not about this.",,"['calculus', 'real-analysis', 'limits', 'radicals']"
19,Limit of sequence with floor function,Limit of sequence with floor function,,"$$ \mbox{How do I compute}\quad \lim_{n \to \infty}% \left\lfloor\sqrt[4]{\vphantom{\Large A}n^{4} + 4n^{3}}-n\right\rfloor\ {\large ?} $$ I know that could use squeeze theorem, but for that I would need to find two sequences, which I don't know how to find. For floor function I know that I can somehow use $x - 1 < \left\lfloor x\right\rfloor \leq x$. Thank you","$$ \mbox{How do I compute}\quad \lim_{n \to \infty}% \left\lfloor\sqrt[4]{\vphantom{\Large A}n^{4} + 4n^{3}}-n\right\rfloor\ {\large ?} $$ I know that could use squeeze theorem, but for that I would need to find two sequences, which I don't know how to find. For floor function I know that I can somehow use $x - 1 < \left\lfloor x\right\rfloor \leq x$. Thank you",,"['calculus', 'limits', 'ceiling-and-floor-functions']"
20,Limit $\lim_{n\to\infty}n\frac{\sin\frac{1}{n}-\frac{1}{n}}{1+\frac{1}{n}}$,Limit,\lim_{n\to\infty}n\frac{\sin\frac{1}{n}-\frac{1}{n}}{1+\frac{1}{n}},"I need to find a limit of a sequence: $$\lim_{n\to\infty}n\frac{\sin\frac{1}{n}-\frac{1}{n}}{1+\frac{1}{n}}$$ I tried to divide numerator and denominator by n, but it didn't help, as the limit became $\frac{0}{0}$. I tried other things, but always got an indefinite limit. I know that the limit is 0, but I just don't know how to show it. It's probably something really simple, but I'm totally stuck.","I need to find a limit of a sequence: $$\lim_{n\to\infty}n\frac{\sin\frac{1}{n}-\frac{1}{n}}{1+\frac{1}{n}}$$ I tried to divide numerator and denominator by n, but it didn't help, as the limit became $\frac{0}{0}$. I tried other things, but always got an indefinite limit. I know that the limit is 0, but I just don't know how to show it. It's probably something really simple, but I'm totally stuck.",,"['sequences-and-series', 'limits']"
21,"A question regarding (ε, δ)-definition of limit","A question regarding (ε, δ)-definition of limit",,"Definition $\lim_{x \rightarrow a} f(x) = L$ means, $\forall \epsilon >0, \exists \delta >0; 0 < |x-a|< \delta \Rightarrow |f(x) - L|< \epsilon$, with $x, a, L \in \mathbb{R}$. I understand this is THE definition of limit and I should follow as it is stated But I just can't understand why it is written this way. To me, $\lim_{x \rightarrow a} f(x) = L$ means, $\forall \delta >0, \exists \epsilon >0; 0 < |x-a|< \delta \Rightarrow |f(x) - L|< \epsilon$, with $x, a, L \in \mathbb{R}$ this way of writing(choosing $ \delta > 0$ first and finding corresponding $\epsilon$) seems to work as well as choosing epsilon first. For every function I(first year in college) can think of, I can pick any delta I want FIRST and still find corresponding $\epsilon$. Rest of the definition also fits So here's my question: Is it possible that we choose delta first and still make it work?","Definition $\lim_{x \rightarrow a} f(x) = L$ means, $\forall \epsilon >0, \exists \delta >0; 0 < |x-a|< \delta \Rightarrow |f(x) - L|< \epsilon$, with $x, a, L \in \mathbb{R}$. I understand this is THE definition of limit and I should follow as it is stated But I just can't understand why it is written this way. To me, $\lim_{x \rightarrow a} f(x) = L$ means, $\forall \delta >0, \exists \epsilon >0; 0 < |x-a|< \delta \Rightarrow |f(x) - L|< \epsilon$, with $x, a, L \in \mathbb{R}$ this way of writing(choosing $ \delta > 0$ first and finding corresponding $\epsilon$) seems to work as well as choosing epsilon first. For every function I(first year in college) can think of, I can pick any delta I want FIRST and still find corresponding $\epsilon$. Rest of the definition also fits So here's my question: Is it possible that we choose delta first and still make it work?",,"['calculus', 'limits']"
22,Can this expression be reduced to a difference quotient?,Can this expression be reduced to a difference quotient?,,"Setting up an equation I've come into this factor: $\displaystyle \lim_{h\rightarrow0}\frac{1-\frac{f(x+h)+f(x-h)}{2f(x)}}{h}; \quad f\in \mathcal{C}^\infty$ To me this looks more or less like a derivative, but I've not been able to reduce it to a common difference quotient. Is that actually $df/dx$ or there's more?","Setting up an equation I've come into this factor: $\displaystyle \lim_{h\rightarrow0}\frac{1-\frac{f(x+h)+f(x-h)}{2f(x)}}{h}; \quad f\in \mathcal{C}^\infty$ To me this looks more or less like a derivative, but I've not been able to reduce it to a common difference quotient. Is that actually $df/dx$ or there's more?",,"['limits', 'derivatives']"
23,A limit problem $0\log \cfrac{0}{0}=0$,A limit problem,0\log \cfrac{0}{0}=0,How can we show that $$0\log \cfrac{0}{0}=0 ?$$ PS. Not homework. This is taken as a convention in the book Elements of Information Theory by Cover. And the books claims it's by continuity (Page 31). It is used in other places in the book too. and Page 19 The copy rights of these extracts belongs to the book publisher. Thanks.,How can we show that $$0\log \cfrac{0}{0}=0 ?$$ PS. Not homework. This is taken as a convention in the book Elements of Information Theory by Cover. And the books claims it's by continuity (Page 31). It is used in other places in the book too. and Page 19 The copy rights of these extracts belongs to the book publisher. Thanks.,,"['real-analysis', 'limits', 'information-theory']"
24,How to prove that $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^n = e^{-k}$ and $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^k = 1$?,How to prove that  and ?,\lim_{n\rightarrow\infty} (1-\frac{k}{n})^n = e^{-k} \lim_{n\rightarrow\infty} (1-\frac{k}{n})^k = 1,How to prove that $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^n = e^{-k}$ and $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^k = 1$? Any answer will be appreciated. Thanks.,How to prove that $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^n = e^{-k}$ and $\lim_{n\rightarrow\infty} (1-\frac{k}{n})^k = 1$? Any answer will be appreciated. Thanks.,,[]
25,convergence of an ugly sequence,convergence of an ugly sequence,,"Determine the convergence of the sequence $$a_n=\frac{2n+\cos (n^2)}{n+(-1)^n\sqrt{n}+\sin n}$$. I knew that there is a short solution useing the L'hopital's rule (and it converges to 2), but the theorem is not allowed, but then I dont know how to prove it converges, somebody please help.","Determine the convergence of the sequence $$a_n=\frac{2n+\cos (n^2)}{n+(-1)^n\sqrt{n}+\sin n}$$. I knew that there is a short solution useing the L'hopital's rule (and it converges to 2), but the theorem is not allowed, but then I dont know how to prove it converges, somebody please help.",,"['real-analysis', 'limits', 'elementary-functions']"
26,Calculate limits $ \lim_{x\to+\infty} \frac{3x-1}{x^2+1}$ and $\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1}$,Calculate limits  and, \lim_{x\to+\infty} \frac{3x-1}{x^2+1} \lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1},I want to calculate the following limits $$\begin{matrix} \lim_{x\to+\infty} \frac{3x-1}{x^2+1} & \text{(1)} \\ \lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} & \text{(2)} \end{matrix}$$ In both cases we have indeterminate forms. Using L'Hôpital's rule on $\text{(1)}$  gives $$\lim_{x\to+\infty} \frac{3x-1}{x^2+1} = \lim_{x\to+\infty}\frac{3}{2x} = 0$$ Using L'Hôpital's rule on $\text{(2)}$ gives $$\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} = \lim_{x\to-\infty}\frac{9x^2}{4x} = \lim_{x\to-\infty}\frac{18x}{4} = -\infty$$ Is this correct?,I want to calculate the following limits $$\begin{matrix} \lim_{x\to+\infty} \frac{3x-1}{x^2+1} & \text{(1)} \\ \lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} & \text{(2)} \end{matrix}$$ In both cases we have indeterminate forms. Using L'Hôpital's rule on $\text{(1)}$  gives $$\lim_{x\to+\infty} \frac{3x-1}{x^2+1} = \lim_{x\to+\infty}\frac{3}{2x} = 0$$ Using L'Hôpital's rule on $\text{(2)}$ gives $$\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} = \lim_{x\to-\infty}\frac{9x^2}{4x} = \lim_{x\to-\infty}\frac{18x}{4} = -\infty$$ Is this correct?,,['limits']
27,Limit of absolute value of sequence,Limit of absolute value of sequence,,Prove that if $\lim \{a_n\}\to a$ then $\lim \{|a_n|\}\to|a|$. Is the converse true? I don't know where to start. Should I break this into 2 cases?,Prove that if $\lim \{a_n\}\to a$ then $\lim \{|a_n|\}\to|a|$. Is the converse true? I don't know where to start. Should I break this into 2 cases?,,"['calculus', 'limits']"
28,Finding the limit as $n\to\infty$,Finding the limit as,n\to\infty,This is how I proceeded with this question but the answer in my book is given to be 0. Is my method correct? Please help so that I can correct myself in case of any mistake.,This is how I proceeded with this question but the answer in my book is given to be 0. Is my method correct? Please help so that I can correct myself in case of any mistake.,,['limits']
29,Simple limit problem: $\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})$,Simple limit problem:,\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4}),While trying to help my sister with her homework she gave me the next limit: $$\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})$$ I know the conventional way of solving it would be (That's what i showed her): $$\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})=\lim_{x\to2}\left(\frac{x+2-4}{x^2-4}\right)=\lim_{x\to2}\left(\frac{x-2}{(x+2)(x-2)}\right)=\lim_{x\to2}\left(\frac{1}{x+2}\right)=\frac14$$ But she gave me the next answer: $$\begin{align} \lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})&=\lim_{x\to2}\frac{1}{x-2}-4\lim\frac{1}{x^2-4}\\ &=\lim_{x\to2}\frac{1}{x-2}-4\lim_{x\to2}\frac{1}{x+2}\lim_{x\to2}\frac{1}{x-2}\\ &=\lim_{x\to2}\frac{1}{x-2}-4\frac14\lim_{x\to2}\frac{1}{x-2}\\ &=\lim_{x\to2}\frac{1}{x-2}-\lim_{x\to2}\frac{1}{x-2}\\ &=0 \end{align}$$ I actually couldn't explain her why is she wrong. Cause technically it looks fine. What am i missing?,While trying to help my sister with her homework she gave me the next limit: $$\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})$$ I know the conventional way of solving it would be (That's what i showed her): $$\lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})=\lim_{x\to2}\left(\frac{x+2-4}{x^2-4}\right)=\lim_{x\to2}\left(\frac{x-2}{(x+2)(x-2)}\right)=\lim_{x\to2}\left(\frac{1}{x+2}\right)=\frac14$$ But she gave me the next answer: $$\begin{align} \lim_{x\to2}(\frac{1}{x-2}-\frac{4}{x^2-4})&=\lim_{x\to2}\frac{1}{x-2}-4\lim\frac{1}{x^2-4}\\ &=\lim_{x\to2}\frac{1}{x-2}-4\lim_{x\to2}\frac{1}{x+2}\lim_{x\to2}\frac{1}{x-2}\\ &=\lim_{x\to2}\frac{1}{x-2}-4\frac14\lim_{x\to2}\frac{1}{x-2}\\ &=\lim_{x\to2}\frac{1}{x-2}-\lim_{x\to2}\frac{1}{x-2}\\ &=0 \end{align}$$ I actually couldn't explain her why is she wrong. Cause technically it looks fine. What am i missing?,,"['calculus', 'limits']"
30,$\lim_{x\rightarrow 0^+}x^x$,,\lim_{x\rightarrow 0^+}x^x,"How can I calculate $\lim_{x\rightarrow 0^+}x^x$? I can only write it in the form $e^{x\ln x}$. I would like to use L'Hospital rule somehow, but I can't write it in form of fractions.","How can I calculate $\lim_{x\rightarrow 0^+}x^x$? I can only write it in the form $e^{x\ln x}$. I would like to use L'Hospital rule somehow, but I can't write it in form of fractions.",,"['calculus', 'limits']"
31,How to prove this result on limit?,How to prove this result on limit?,,"$$\lim_{x \to 0}  \frac{({a+x^m})^{\frac{1}{n}}-({a-x^m})^{\frac{1}{n}}}{x^m}=\frac{2}{n}a^{\frac{1}{n}-1}$$ I have tried it using L'Hôpital's rule , but I don't get any way out of that. Any Help will be appreciated. Thanks.","$$\lim_{x \to 0}  \frac{({a+x^m})^{\frac{1}{n}}-({a-x^m})^{\frac{1}{n}}}{x^m}=\frac{2}{n}a^{\frac{1}{n}-1}$$ I have tried it using L'Hôpital's rule , but I don't get any way out of that. Any Help will be appreciated. Thanks.",,"['calculus', 'real-analysis', 'limits']"
32,How to find $\;\lim_{x\to 0} \frac{x}{2-\sqrt{4}-2x}\;$ without using L'Hôpital's rule?,How to find  without using L'Hôpital's rule?,\;\lim_{x\to 0} \frac{x}{2-\sqrt{4}-2x}\;,"Well, I'm studying calculus and doing some exercises. First of all, from the answers that were given by my teacher the result of this limit should be $4$. I'm beginning my calculus class now but I've already studied calculus by myself before so I know how to apply l'Hôpital's Rule to this limit, following l'Hôpital's I get $-1$, the step-by-step resolution answer from WolframAlpha gives me $-1$ as well. I thought of all I know about factoring and simplifying equations but I'm not able to actually solve it without l'Hôpital's. Any hint or way about how to do it? $$\lim\limits_{x\to 0}  \frac{x}{2-\sqrt{4}-2x}$$","Well, I'm studying calculus and doing some exercises. First of all, from the answers that were given by my teacher the result of this limit should be $4$. I'm beginning my calculus class now but I've already studied calculus by myself before so I know how to apply l'Hôpital's Rule to this limit, following l'Hôpital's I get $-1$, the step-by-step resolution answer from WolframAlpha gives me $-1$ as well. I thought of all I know about factoring and simplifying equations but I'm not able to actually solve it without l'Hôpital's. Any hint or way about how to do it? $$\lim\limits_{x\to 0}  \frac{x}{2-\sqrt{4}-2x}$$",,"['calculus', 'limits']"
33,Limit of an integral.,Limit of an integral.,,"$$\lim_{n\to\infty}   \int_{-\infty}^{\infty} \frac{1}{(1+x^2)^n}\,dx $$ Mathematica tells me the answer is 0, but how can I go about actually proving it mathematically?","$$\lim_{n\to\infty}   \int_{-\infty}^{\infty} \frac{1}{(1+x^2)^n}\,dx $$ Mathematica tells me the answer is 0, but how can I go about actually proving it mathematically?",,"['calculus', 'real-analysis', 'limits']"
34,proving that the following limit exist,proving that the following limit exist,,"How can I prove that the following limit exist? $$ \mathop {\lim }\limits_{x,y \to 0} \frac{{x^2  + y^4 }} {{\left| x \right| + 3\left| y \right|}} $$ I tried a lot of tricks. At least assuming that this limit exist, I can prove using some special path (for example y=x) that the limit is zero. But how can I prove the existence?","How can I prove that the following limit exist? $$ \mathop {\lim }\limits_{x,y \to 0} \frac{{x^2  + y^4 }} {{\left| x \right| + 3\left| y \right|}} $$ I tried a lot of tricks. At least assuming that this limit exist, I can prove using some special path (for example y=x) that the limit is zero. But how can I prove the existence?",,"['limits', 'multivariable-calculus']"
35,Find $\lim_{n\to\infty}n\sqrt[n]{a_{1}a_{2}\cdots a_{n}}$ given the sum converges,Find  given the sum converges,\lim_{n\to\infty}n\sqrt[n]{a_{1}a_{2}\cdots a_{n}},$a_{n}>0$ and $\displaystyle\sum_{n=1}^{\infty}a_{n}$ converge. Find the value of $\displaystyle\lim_{n\to\infty}n\sqrt[n]{a_{1}a_{2}\cdots a_{n}}$,$a_{n}>0$ and $\displaystyle\sum_{n=1}^{\infty}a_{n}$ converge. Find the value of $\displaystyle\lim_{n\to\infty}n\sqrt[n]{a_{1}a_{2}\cdots a_{n}}$,,"['real-analysis', 'sequences-and-series', 'limits']"
36,Weird calculus limit,Weird calculus limit,,How to find the following limit? $$ \lim_{n \to \infty} \dfrac{ 5^\frac{1}{n!} - 4^\frac{1}{n!}  }{ 3^\frac{1}{n!} - 2^\frac{1}{n!}   } $$ Edit done to the question. Thank you!,How to find the following limit? $$ \lim_{n \to \infty} \dfrac{ 5^\frac{1}{n!} - 4^\frac{1}{n!}  }{ 3^\frac{1}{n!} - 2^\frac{1}{n!}   } $$ Edit done to the question. Thank you!,,"['calculus', 'analysis', 'limits']"
37,Calculate:$\lim_{x \rightarrow (-1)^{+}}\left(\frac{\sqrt{\pi}-\sqrt{\cos^{-1}x}}{\sqrt{x+1}} \right)$,Calculate:,\lim_{x \rightarrow (-1)^{+}}\left(\frac{\sqrt{\pi}-\sqrt{\cos^{-1}x}}{\sqrt{x+1}} \right),How to calculate following with out using L'Hospital rule $$\lim_{x \rightarrow (-1)^{+}}\left(\frac{\sqrt{\pi}-\sqrt{\cos^{-1}x}}{\sqrt{x+1}} \right)$$,How to calculate following with out using L'Hospital rule $$\lim_{x \rightarrow (-1)^{+}}\left(\frac{\sqrt{\pi}-\sqrt{\cos^{-1}x}}{\sqrt{x+1}} \right)$$,,"['calculus', 'limits']"
38,$\lim_{x\to c}f'(x)=L$ implies $f'(c)=L$ [duplicate],implies  [duplicate],\lim_{x\to c}f'(x)=L f'(c)=L,"This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 6 years ago . Let $f:[a,b]\to\mathbb{R}$ be differentiable on $[a,b]$ and let $c \in(a,b)$. Suppose that $\lim_{x\to c}f'(x)=L$ some $L \in\mathbb{R}$. Without using L'Hospital's Rule, prove that $f'(c)=L$. Hint: Use the Mean Value Theorem and the e-d definition of f'(c). Any leads would be much appreaciated. Thanks.","This question already has answers here : Prove that $f'(a)=\lim_{x\rightarrow a}f'(x)$. (6 answers) Closed 6 years ago . Let $f:[a,b]\to\mathbb{R}$ be differentiable on $[a,b]$ and let $c \in(a,b)$. Suppose that $\lim_{x\to c}f'(x)=L$ some $L \in\mathbb{R}$. Without using L'Hospital's Rule, prove that $f'(c)=L$. Hint: Use the Mean Value Theorem and the e-d definition of f'(c). Any leads would be much appreaciated. Thanks.",,"['real-analysis', 'limits', 'derivatives']"
39,Limit $\lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} $ [closed],Limit  [closed],\lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} ,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question $\displaystyle  \lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} $,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question $\displaystyle  \lim_{n \rightarrow \infty}\frac{1 \cdot 3 \cdot 5 \dots \cdot (2n-1)}{2 \cdot 4 \cdot 6 \cdot \dots \cdot (2n)} $,,"['calculus', 'limits']"
40,Sequence of solutions to $x\sin x=1$,Sequence of solutions to,x\sin x=1,"Moderator Note: At the time that this question was posted, it was from an ongoing contest. The relevant deadline has now passed. Consider a sequence $x_n, n\ge1$ formed by positive solutions to $x \sin{x}=1$. How can we find $$\lim _{n\rightarrow \infty}(n(x_{2n+1}-2\pi n))= L$$ and $$\lim _{n\rightarrow \infty}(n^3(x_{2n+1}-2\pi n- \frac{L}{n}))= L_2$$ ?","Moderator Note: At the time that this question was posted, it was from an ongoing contest. The relevant deadline has now passed. Consider a sequence $x_n, n\ge1$ formed by positive solutions to $x \sin{x}=1$. How can we find $$\lim _{n\rightarrow \infty}(n(x_{2n+1}-2\pi n))= L$$ and $$\lim _{n\rightarrow \infty}(n^3(x_{2n+1}-2\pi n- \frac{L}{n}))= L_2$$ ?",,"['sequences-and-series', 'trigonometry', 'limits']"
41,Compute $\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2}$,Compute,\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2},"What's the strategy one may use when facing a limit like this one? I think it's more important to know the possible ways to go than the answer itself. It's a problem that came to my mind again when I was working on a different problem. $$\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2}$$ Any suggestion, hint are very welcome.","What's the strategy one may use when facing a limit like this one? I think it's more important to know the possible ways to go than the answer itself. It's a problem that came to my mind again when I was working on a different problem. $$\lim_{x\to\infty} \frac{{(x!)}^{\frac{1}{x}-1} (x\Gamma(x+1) \psi^{(0)}(x+1)-x! \log(x!))}{x^2}$$ Any suggestion, hint are very welcome.",,"['calculus', 'real-analysis', 'limits', 'special-functions']"
42,If $f:D\to \mathbb{R}$ is continuous and exists $(x_n)\in D$ such as that $x_n\to a\notin D$ and $f(x_n)\to \ell$ then $\lim_{x\to a}f(x)=\ell$?,If  is continuous and exists  such as that  and  then ?,f:D\to \mathbb{R} (x_n)\in D x_n\to a\notin D f(x_n)\to \ell \lim_{x\to a}f(x)=\ell,"Assertion: If $f:X\setminus\left\{a\right\}\to \mathbb{R}$ is continuous and there exists  a sequence $(x_n):\mathbb{N}\to X\setminus\left\{a\right\}$ such as that $x_n\to a$ and $f(x_n)\to \ell$ prove that $\lim_{x\to a}f(x)=\ell$ I have three questions: 1) Is the assertion correct? If not, please provide counter-examples. In that case can the assertion become correct if we require that $f$ is monotonic, differentiable etc.? 2)Is my proof correct? If not, please pinpoint the problem and give a hint to the right direcition. Personally, what makes me doubt it are the choices of $N$ and $\delta$ since they depend on another 3)If the proof is correct, then is there a way to shorten it? My Proof: Let $\epsilon>0$. Since $f(x_n)\to \ell$   \begin{equation} \exists N_1\in \mathbb{N}:n\ge N_1\Rightarrow \left|f(x_n)-\ell\right|<\frac{\epsilon}{2}\end{equation} Thus, $\left|f(x_{N_1})-\ell\right|<\frac{\epsilon}{2}$ and by the continuity of $f$ at $x_{N_1}$,  \begin{equation} \exists \delta_1>0:\left|x-x_{N_1}\right|<\delta_1\Rightarrow \left|f(x)-f(x_{N_1})\right|<\frac{\epsilon}{2} \end{equation} Since $x_n\to a$,  \begin{equation} \exists N_2\in \mathbb{N}:n\ge N_2\Rightarrow \left|x_n-a\right|<\delta_1\end{equation} Thus, $\left|x_{N_2}-a\right|<\delta_1$ and by letting $N=\max\left\{N_1,N_2\right\}$,  \begin{gather} 0<\left|x-a\right|<\delta_1\Rightarrow \left|x-x_N+x_N-a\right|<\delta_1\Rightarrow \left|x-x_N\right|-\left|x_N-a\right|<\delta_1\\ 0<\left|x-a\right|<\delta_1\Rightarrow \left|x-x_N\right|<\delta_1+\left|x_N-a\right| \end{gather}  By the continuity of $f$ at $x_N$,  \begin{equation} \exists \delta_3>0:0<\left|x-x_N\right|<\delta_3\Rightarrow \left|f(x)-f(x_N)\right|<\frac{\epsilon}{2} \end{equation} Thus, letting $\delta=\max\left\{\delta_1+\left|x_N-a\right|,\delta_3\right\}>0$ we have that,  \begin{gather} 0<\left|x-a\right|<\delta\Rightarrow \left|x-x_N\right|<\delta\Rightarrow \left|f(x)-\ell+\ell-f(x_N)\right|<\frac{\epsilon}{2}\Rightarrow \left|f(x)-\ell\right|-\left|f(x_N)-\ell\right|<\frac{\epsilon}{2}\\ 0<\left|x-a\right|<\delta\Rightarrow\left|f(x)-\ell\right|<\left|f(x_N)-\ell\right|+\frac{\epsilon}{2}<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon \end{gather} We conclude that $\lim_{x\to a}f(x)=\ell$ Thank you in advance EDIT: The proof is false. One of the mistakes is in this part: ""Thus, letting $\delta=\max\left\{\delta_1+\left|x_N-a\right|,\delta_3\right\}>0$ we have that,  \begin{gather} 0<\left|x-a\right|<\delta{\color{Red} \Rightarrow} \left|x-x_N\right|<\delta{\color{Red} \Rightarrow} \left|f(x)-\ell+\ell-f(x_N)\right|<\frac{\epsilon}{2}\end{gather}""","Assertion: If $f:X\setminus\left\{a\right\}\to \mathbb{R}$ is continuous and there exists  a sequence $(x_n):\mathbb{N}\to X\setminus\left\{a\right\}$ such as that $x_n\to a$ and $f(x_n)\to \ell$ prove that $\lim_{x\to a}f(x)=\ell$ I have three questions: 1) Is the assertion correct? If not, please provide counter-examples. In that case can the assertion become correct if we require that $f$ is monotonic, differentiable etc.? 2)Is my proof correct? If not, please pinpoint the problem and give a hint to the right direcition. Personally, what makes me doubt it are the choices of $N$ and $\delta$ since they depend on another 3)If the proof is correct, then is there a way to shorten it? My Proof: Let $\epsilon>0$. Since $f(x_n)\to \ell$   \begin{equation} \exists N_1\in \mathbb{N}:n\ge N_1\Rightarrow \left|f(x_n)-\ell\right|<\frac{\epsilon}{2}\end{equation} Thus, $\left|f(x_{N_1})-\ell\right|<\frac{\epsilon}{2}$ and by the continuity of $f$ at $x_{N_1}$,  \begin{equation} \exists \delta_1>0:\left|x-x_{N_1}\right|<\delta_1\Rightarrow \left|f(x)-f(x_{N_1})\right|<\frac{\epsilon}{2} \end{equation} Since $x_n\to a$,  \begin{equation} \exists N_2\in \mathbb{N}:n\ge N_2\Rightarrow \left|x_n-a\right|<\delta_1\end{equation} Thus, $\left|x_{N_2}-a\right|<\delta_1$ and by letting $N=\max\left\{N_1,N_2\right\}$,  \begin{gather} 0<\left|x-a\right|<\delta_1\Rightarrow \left|x-x_N+x_N-a\right|<\delta_1\Rightarrow \left|x-x_N\right|-\left|x_N-a\right|<\delta_1\\ 0<\left|x-a\right|<\delta_1\Rightarrow \left|x-x_N\right|<\delta_1+\left|x_N-a\right| \end{gather}  By the continuity of $f$ at $x_N$,  \begin{equation} \exists \delta_3>0:0<\left|x-x_N\right|<\delta_3\Rightarrow \left|f(x)-f(x_N)\right|<\frac{\epsilon}{2} \end{equation} Thus, letting $\delta=\max\left\{\delta_1+\left|x_N-a\right|,\delta_3\right\}>0$ we have that,  \begin{gather} 0<\left|x-a\right|<\delta\Rightarrow \left|x-x_N\right|<\delta\Rightarrow \left|f(x)-\ell+\ell-f(x_N)\right|<\frac{\epsilon}{2}\Rightarrow \left|f(x)-\ell\right|-\left|f(x_N)-\ell\right|<\frac{\epsilon}{2}\\ 0<\left|x-a\right|<\delta\Rightarrow\left|f(x)-\ell\right|<\left|f(x_N)-\ell\right|+\frac{\epsilon}{2}<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon \end{gather} We conclude that $\lim_{x\to a}f(x)=\ell$ Thank you in advance EDIT: The proof is false. One of the mistakes is in this part: ""Thus, letting $\delta=\max\left\{\delta_1+\left|x_N-a\right|,\delta_3\right\}>0$ we have that,  \begin{gather} 0<\left|x-a\right|<\delta{\color{Red} \Rightarrow} \left|x-x_N\right|<\delta{\color{Red} \Rightarrow} \left|f(x)-\ell+\ell-f(x_N)\right|<\frac{\epsilon}{2}\end{gather}""",,"['calculus', 'real-analysis', 'limits', 'continuity']"
43,Binomial fraction sum to infinity,Binomial fraction sum to infinity,,"Compute the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac {\dbinom{n}{k}}{\dbinom{2n-1}{k}}$$ Here i tried to give some k values to the sum hoping to see a possible pattern,  but i didn't figure out any such a pattern. I wonder if there is an easy way to solve such a limit.","Compute the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac {\dbinom{n}{k}}{\dbinom{2n-1}{k}}$$ Here i tried to give some k values to the sum hoping to see a possible pattern,  but i didn't figure out any such a pattern. I wonder if there is an easy way to solve such a limit.",,"['limits', 'binomial-coefficients']"
44,Compute $\lim \limits_{x\to\infty} (\frac{x-2}{x+2})^x$,Compute,\lim \limits_{x\to\infty} (\frac{x-2}{x+2})^x,Compute $$\lim \limits_{x\to\infty} (\frac{x-2}{x+2})^x$$ I did $$\lim_{x\to\infty} (\frac{x-2}{x+2})^x = \lim_{x\to\infty} \exp(x\cdot \ln(\frac{x-2}{x+2})) =  \exp( \lim_{x\to\infty} x\cdot \ln(\frac{x-2}{x+2}))$$ But how do I continue? The hint is to use L Hopital's Rule. I tried changing to $$\exp(\lim_{x\to\infty} \frac{\ln(x-2)-\ln(x+2)}{1/x})$$ This is $$(\infty - \infty )/0 = 0/0$$ But I find that I can keep differentiating?,Compute $$\lim \limits_{x\to\infty} (\frac{x-2}{x+2})^x$$ I did $$\lim_{x\to\infty} (\frac{x-2}{x+2})^x = \lim_{x\to\infty} \exp(x\cdot \ln(\frac{x-2}{x+2})) =  \exp( \lim_{x\to\infty} x\cdot \ln(\frac{x-2}{x+2}))$$ But how do I continue? The hint is to use L Hopital's Rule. I tried changing to $$\exp(\lim_{x\to\infty} \frac{\ln(x-2)-\ln(x+2)}{1/x})$$ This is $$(\infty - \infty )/0 = 0/0$$ But I find that I can keep differentiating?,,['limits']
45,Intuition behind growth rate of some functions,Intuition behind growth rate of some functions,,"This one really crushed my intuition. Let say a function $f$ grows faster than a function $g$ if $ \lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty $ Which of the following functions grows the fastest : $2^{n/2}$ $3^{n/3}$ $5^{n/5}$ $1000^{1000/n}$ $10000^{10000/n}$ My bet would be on either function 1. or 5. but as it turns out, function 2. is growing the fastest. After doing some calculations I was able to assure myself that that is really so. But my main doubt is still there. Why is this obvious? How can one intuitively explain this behavior?","This one really crushed my intuition. Let say a function $f$ grows faster than a function $g$ if $ \lim_{n \to \infty} \frac{f(n)}{g(n)} = \infty $ Which of the following functions grows the fastest : $2^{n/2}$ $3^{n/3}$ $5^{n/5}$ $1000^{1000/n}$ $10000^{10000/n}$ My bet would be on either function 1. or 5. but as it turns out, function 2. is growing the fastest. After doing some calculations I was able to assure myself that that is really so. But my main doubt is still there. Why is this obvious? How can one intuitively explain this behavior?",,"['soft-question', 'limits', 'asymptotics', 'intuition']"
46,"Using $\epsilon$-$\delta$ approach to prove that $\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0$?",Using - approach to prove that ?,"\epsilon \delta \lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0","As the title indicates, Using $\epsilon$-$\delta$ approach to prove that $$\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0$$?","As the title indicates, Using $\epsilon$-$\delta$ approach to prove that $$\lim_{(x,y,z)\rightarrow (0,0,0)}\frac {y^3-1000xy^2+z^5}{x^2+y^2+z^4}=0$$?",,"['calculus', 'limits', 'multivariable-calculus']"
47,"$f(x)$ monotonic integrable function and $\lim_{x\to \infty}\frac{1}{x}\int_{0}^{x}f(t)dt=a$, Prove: $\lim_{x\to \infty}f(x)=a$","monotonic integrable function and , Prove:",f(x) \lim_{x\to \infty}\frac{1}{x}\int_{0}^{x}f(t)dt=a \lim_{x\to \infty}f(x)=a,"Let $f(x)$ be a monotonic increasing function on $[0,\infty)$ and for every $x>0$ it is integrable in $[0,x]$, so that $\lim_{x\to \infty}\frac{1}{x}\int_{0}^{x}f(t)dt=a$. I need to prove that  $\lim_{x\to \infty}f(x)=a$. I tried to use the limit definition: $|\frac{1}{x}\int_{0}^{x}f(t)dt -a|<\epsilon$ and to use the fact that $\int_{0}^{x}f(t)dt\geq x\inf f(x)$, but I can't see how does it help me eventually. I would love your help with this. Thanks a lot!","Let $f(x)$ be a monotonic increasing function on $[0,\infty)$ and for every $x>0$ it is integrable in $[0,x]$, so that $\lim_{x\to \infty}\frac{1}{x}\int_{0}^{x}f(t)dt=a$. I need to prove that  $\lim_{x\to \infty}f(x)=a$. I tried to use the limit definition: $|\frac{1}{x}\int_{0}^{x}f(t)dt -a|<\epsilon$ and to use the fact that $\int_{0}^{x}f(t)dt\geq x\inf f(x)$, but I can't see how does it help me eventually. I would love your help with this. Thanks a lot!",,"['calculus', 'integration', 'limits']"
48,Continuity of this function at $x=0$,Continuity of this function at,x=0,The following function is not defined at $x=0$: $$f(x) = \frac{\log(1+ax) - \log(1-bx)}{x} .$$ What would be the value of $f(0)$ so that it is continuous at $x=0$?,The following function is not defined at $x=0$: $$f(x) = \frac{\log(1+ax) - \log(1-bx)}{x} .$$ What would be the value of $f(0)$ so that it is continuous at $x=0$?,,"['real-analysis', 'limits']"
49,"When using the method of substituting variables to find the limit, why can we still use the original numbers that need to be approximated?","When using the method of substituting variables to find the limit, why can we still use the original numbers that need to be approximated?",,"I'm trying to solve this problem: Assume $$f(x+\frac{1}{x}) = x^2 + \frac{1}{x^2}$$ then $$\lim_{x\to 3} f(x) = ?$$ I saw the answer is $$t = x+\frac{1}{x}$$ $$\lim_{x\to 3} f(x) = \lim_{t\to 3} t^2 - 2 = 7$$ I am a little confused, since we have set $t=x+\frac{1}{x}$ , why $x\to 3$ doesn't become $t\to \frac{10}{3}$ ? This question may be a bit low-level, but I am really not good at math. Thank you for your help!","I'm trying to solve this problem: Assume then I saw the answer is I am a little confused, since we have set , why doesn't become ? This question may be a bit low-level, but I am really not good at math. Thank you for your help!",f(x+\frac{1}{x}) = x^2 + \frac{1}{x^2} \lim_{x\to 3} f(x) = ? t = x+\frac{1}{x} \lim_{x\to 3} f(x) = \lim_{t\to 3} t^2 - 2 = 7 t=x+\frac{1}{x} x\to 3 t\to \frac{10}{3},['limits']
50,Why does Im($(-1/10^n)^{-1/10^n}$) turn into the digits of pi as integer n gets larger?,Why does Im() turn into the digits of pi as integer n gets larger?,(-1/10^n)^{-1/10^n},"$(-.001)^{-.001} \approx 1.007 - .0031634i$ , $(-.000001)^{-.000001} \approx 1.000014 - .00000314164$ , and $(-.000000001)^{-.000000001} \approx 1.0000000207 - .00000000314159271i$ . Notice that as we approach 0 from the negative direction for $x^x$ by  magnitudes of ten, the imaginary component more closely approximates pi, divided by an increasing power of ten. Why does this happen?",", , and . Notice that as we approach 0 from the negative direction for by  magnitudes of ten, the imaginary component more closely approximates pi, divided by an increasing power of ten. Why does this happen?",(-.001)^{-.001} \approx 1.007 - .0031634i (-.000001)^{-.000001} \approx 1.000014 - .00000314164 (-.000000001)^{-.000000001} \approx 1.0000000207 - .00000000314159271i x^x,"['calculus', 'limits', 'complex-numbers', 'pi']"
51,A quicker route to $\def\o{{\tt1}}\def\b{\beta}\lim_{\b\to0} \frac{2(\o-\cos\b)-\b\sin\b}{2(\o-\cos\b)\b^2}$,A quicker route to,\def\o{{\tt1}}\def\b{\beta}\lim_{\b\to0} \frac{2(\o-\cos\b)-\b\sin\b}{2(\o-\cos\b)\b^2},I encountered this limit while calculating the $\varphi$ function for a $3\times 3$ skew-symmetric matrix $${ \def\o{{\tt1}}\def\b{\beta}\lim_{\b\to0} \frac{2(\o-\cos\b)-\b\sin\b}{2(\o-\cos\b)\b^2} = \frac{\o}{12} \\ }$$ The interesting part is that it took four applications of L'Hospital's Rule to resolve the limit. My question is: Are there any trigonometric identities that can reduce the number of derivatives that are required?,I encountered this limit while calculating the function for a skew-symmetric matrix The interesting part is that it took four applications of L'Hospital's Rule to resolve the limit. My question is: Are there any trigonometric identities that can reduce the number of derivatives that are required?,"\varphi 3\times 3 {
\def\o{{\tt1}}\def\b{\beta}\lim_{\b\to0} \frac{2(\o-\cos\b)-\b\sin\b}{2(\o-\cos\b)\b^2} = \frac{\o}{12} \\
}","['limits', 'derivatives']"
52,Show that the sequence $(3n-2)!!!/(3^n\cdot n!)$ converges to $0$.,Show that the sequence  converges to .,(3n-2)!!!/(3^n\cdot n!) 0,"I came across this sequence while trying to prove that an alternating series converges by Leibniz's test. Here's the question and my answer . Define a sequence $\{a_n\}_{n\in\mathbb N}$ as follows. $$a_{n} =\frac{( 3n-2) !!!}{3^{n} \cdotp n!}=\frac{1}{3} \cdot \frac{4}{6} \cdot \frac{7}{9} \cdots \frac{3n-2}{3n}$$ I have shown that it is convergent. Numerically, I found that it converges to $0$ ... However, I struggled to find the limit. Here's what I did: Consider the sequence $$b_n=\left(\frac{1}{n}\left(\frac{1}{3} +\frac{4}{6} +\frac{7}{9} +\cdots +\frac{3n-2}{3n}\right)\right)^{n}$$ $a_1=b_1$ , however, for all $n\geq 2$ , $0<a_n<b_n\tag*{}$ (by A.M.-G.M. inequality). Show that $\lim b_n=0$ and conclude by sandwich theorem that $\lim a_n=0$ . $$\begin{aligned} b_{n} & =\left(\frac{1}{n}\sum _{j=1}^{n}\left( 1-\frac{2}{3j}\right)\right)^{n}\\  & =\left( 1-\frac{2}{3n} \cdot \sum _{j=1}^{n}\frac{1}{j}\right)^{n} \end{aligned}$$ $$\color{blue}{\Rightarrow \lim b_n=\exp\left(-\frac{2}{3}\lim \sum _{j=1}^{n}\frac{1}{j}\right)}$$ This is a partial sum sequence of a well-known divergent series. $$\therefore \lim b_n=\lim_{x\to\infty}\exp\left(-\frac{2}{3}x\right)=0$$ I hope there is no mistake in my approach though I have doubts about the step which is coloured in blue: Is it always justified that $\lim (1+f(n)/n)^n$ will be same as $\lim\exp(f(n))$ ? I have done this in high school calculus without giving it much thought, however, I would want to introspect and analyze. I would also like to know if there's any alternate yet simpler way to find this limit... I have also thought of a generalization inspired by this post . We can rewrite in terms of binomial coefficients: $$a_n=\binom{-1/3}{n} (-1)^n$$ I am adding this, in case it's useful.","I came across this sequence while trying to prove that an alternating series converges by Leibniz's test. Here's the question and my answer . Define a sequence as follows. I have shown that it is convergent. Numerically, I found that it converges to ... However, I struggled to find the limit. Here's what I did: Consider the sequence , however, for all , (by A.M.-G.M. inequality). Show that and conclude by sandwich theorem that . This is a partial sum sequence of a well-known divergent series. I hope there is no mistake in my approach though I have doubts about the step which is coloured in blue: Is it always justified that will be same as ? I have done this in high school calculus without giving it much thought, however, I would want to introspect and analyze. I would also like to know if there's any alternate yet simpler way to find this limit... I have also thought of a generalization inspired by this post . We can rewrite in terms of binomial coefficients: I am adding this, in case it's useful.","\{a_n\}_{n\in\mathbb N} a_{n} =\frac{( 3n-2) !!!}{3^{n} \cdotp n!}=\frac{1}{3} \cdot \frac{4}{6} \cdot \frac{7}{9} \cdots \frac{3n-2}{3n} 0 b_n=\left(\frac{1}{n}\left(\frac{1}{3} +\frac{4}{6} +\frac{7}{9} +\cdots +\frac{3n-2}{3n}\right)\right)^{n} a_1=b_1 n\geq 2 0<a_n<b_n\tag*{} \lim b_n=0 \lim a_n=0 \begin{aligned}
b_{n} & =\left(\frac{1}{n}\sum _{j=1}^{n}\left( 1-\frac{2}{3j}\right)\right)^{n}\\
 & =\left( 1-\frac{2}{3n} \cdot \sum _{j=1}^{n}\frac{1}{j}\right)^{n}
\end{aligned} \color{blue}{\Rightarrow \lim b_n=\exp\left(-\frac{2}{3}\lim \sum _{j=1}^{n}\frac{1}{j}\right)} \therefore \lim b_n=\lim_{x\to\infty}\exp\left(-\frac{2}{3}x\right)=0 \lim (1+f(n)/n)^n \lim\exp(f(n)) a_n=\binom{-1/3}{n} (-1)^n","['sequences-and-series', 'limits', 'solution-verification']"
53,"Given the function $f(x)=\left(3x^{\frac75}\!-\!\frac{\pi}x\right)\!\cdot\!\cos\left(\frac{\pi}2\!-\!x\right)$. Calculate $\,\lim\limits_{x\to0}f(x)$",Given the function . Calculate,"f(x)=\left(3x^{\frac75}\!-\!\frac{\pi}x\right)\!\cdot\!\cos\left(\frac{\pi}2\!-\!x\right) \,\lim\limits_{x\to0}f(x)","Given the function $f(x)=\left(3x^{\frac75}\!-\!\dfrac{\pi}x\right)\!\cdot\!\cos\left(\dfrac{\pi}2\!-\!x\right)$ . Calculate the limit $\,\lim\limits_{x\to0}f(x)\;.$ So I started by using the definition of the derivative that $$f'(x_{0})=\lim_{x \to x_{0}}\frac{f(x)-f(x_{0})}{x-x_0}$$ after doing that I tried to set $x_{0} = 0$ since then u get the limit to $x \to 0$ , but the problem is that $f(0)$ is not defined, because if I substitute $x=0$ in the function I get $f(0)=(0-\infty)\cdot{}0$ which is undefined, same goes for $f'(0)$ Now I can't seem to find the solution, so I'm asking the question here","Given the function . Calculate the limit So I started by using the definition of the derivative that after doing that I tried to set since then u get the limit to , but the problem is that is not defined, because if I substitute in the function I get which is undefined, same goes for Now I can't seem to find the solution, so I'm asking the question here","f(x)=\left(3x^{\frac75}\!-\!\dfrac{\pi}x\right)\!\cdot\!\cos\left(\dfrac{\pi}2\!-\!x\right) \,\lim\limits_{x\to0}f(x)\;. f'(x_{0})=\lim_{x \to x_{0}}\frac{f(x)-f(x_{0})}{x-x_0} x_{0} = 0 x \to 0 f(0) x=0 f(0)=(0-\infty)\cdot{}0 f'(0)","['calculus', 'limits', 'derivatives']"
54,Differentiability implies continuity proof doubt,Differentiability implies continuity proof doubt,,"I have a question in one of the steps taken to prove that a differentiable function at a point a is also continuous there. On Spivak book, the proof is done in the following manner: Looking at the limit as h approaches zero of the difference f(a+h)-f(a) we say that is equal to the limit as h approaches zero of the product of the secant line slope between points (a,f(a)) and (a+h,f(a+h)) times h. Now, the limit of the quotient exists since f is differentiable by hypothesis at a and the limit as h tends to zero of h exists and equals zero. Hence, the whole limit can be said to equal some real number f’(a) times 0 which as a whole is just 0. Now, this next step is where my doubt is. Having concluded that the limit as h approaches zero of the difference f(a+h)-f(a) equals 0, it looks like this limit is equal to the difference if the separate limits as h approaches zero of f(a+h) and f(a) exist; so by subtracting by f(a) from both sides, we conclude that the limit of f(a+h) as h approaches zero equals f(a) which I know is equivalent to saying that f is continuous at a. My doubt is why can you say that the limit of the difference is the difference of limits in this case? Don’t you need to verify that the separate limits exist to do that (as it was done similarly to say that whole limit = f’(a) * 0 )?","I have a question in one of the steps taken to prove that a differentiable function at a point a is also continuous there. On Spivak book, the proof is done in the following manner: Looking at the limit as h approaches zero of the difference f(a+h)-f(a) we say that is equal to the limit as h approaches zero of the product of the secant line slope between points (a,f(a)) and (a+h,f(a+h)) times h. Now, the limit of the quotient exists since f is differentiable by hypothesis at a and the limit as h tends to zero of h exists and equals zero. Hence, the whole limit can be said to equal some real number f’(a) times 0 which as a whole is just 0. Now, this next step is where my doubt is. Having concluded that the limit as h approaches zero of the difference f(a+h)-f(a) equals 0, it looks like this limit is equal to the difference if the separate limits as h approaches zero of f(a+h) and f(a) exist; so by subtracting by f(a) from both sides, we conclude that the limit of f(a+h) as h approaches zero equals f(a) which I know is equivalent to saying that f is continuous at a. My doubt is why can you say that the limit of the difference is the difference of limits in this case? Don’t you need to verify that the separate limits exist to do that (as it was done similarly to say that whole limit = f’(a) * 0 )?",,"['real-analysis', 'calculus', 'limits']"
55,A question about a limit with two parameters,A question about a limit with two parameters,,Determine the values of the two real parameters $a$ and $b$ such that $$\lim_{x \to 0}\frac{\sin x-(ax^3+bx)}{x^3}=1$$ I immediately have thought of the Hopital theorem. We have: $$\lim_{x \to 0}\frac{\sin x-(ax^3+bx)}{x^3}=\lim_{x \to 0}\frac{\cos x-3ax^2-b}{3x^2}=\lim_{x \to 0}\frac{1-b}{3x^2}\equiv 1$$ Now I am not able to find $a$ and $b$ .,Determine the values of the two real parameters and such that I immediately have thought of the Hopital theorem. We have: Now I am not able to find and .,a b \lim_{x \to 0}\frac{\sin x-(ax^3+bx)}{x^3}=1 \lim_{x \to 0}\frac{\sin x-(ax^3+bx)}{x^3}=\lim_{x \to 0}\frac{\cos x-3ax^2-b}{3x^2}=\lim_{x \to 0}\frac{1-b}{3x^2}\equiv 1 a b,"['calculus', 'limits']"
56,A different solution for checking convergence of $a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2}$,A different solution for checking convergence of,a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2},"Analyse the convergence of $$a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2}$$ and find the point of convergence if it does converge. I proved that it converges to $0$ noting that $$\frac{1}{n^2} \le a_n \le (n+1)\times \frac{1}{n^2}$$ and using Sandwich Theorem. But I was following a book by Arihant which gives the following solution (and I am quoting it without changing any notations) Define $a_n=\frac n{(n+n)^2}$ so that $\lim_{n\to \infty} a_n=0$ . Now, use Cauchy's Theorem to get $$0=\lim_{n\to \infty} \left(\frac{a_1+\dots a_n}n\right)=\lim_{n\to \infty} \left(\frac{1}{(n+1)^2}+\dots \frac 1{(2n)^2}\right)$$ and hence the result follows. I believe this solution is absolutely rubbish (although it would be good to have a check). But, I do like the idea and the approach. Can this approach (with necessary modifications) be used to solve these kind of limits?","Analyse the convergence of and find the point of convergence if it does converge. I proved that it converges to noting that and using Sandwich Theorem. But I was following a book by Arihant which gives the following solution (and I am quoting it without changing any notations) Define so that . Now, use Cauchy's Theorem to get and hence the result follows. I believe this solution is absolutely rubbish (although it would be good to have a check). But, I do like the idea and the approach. Can this approach (with necessary modifications) be used to solve these kind of limits?",a_n=\frac{1}{n^2}+\frac{1}{(n+1)^2}+\dots+\frac{1}{(2n)^2} 0 \frac{1}{n^2} \le a_n \le (n+1)\times \frac{1}{n^2} a_n=\frac n{(n+n)^2} \lim_{n\to \infty} a_n=0 0=\lim_{n\to \infty} \left(\frac{a_1+\dots a_n}n\right)=\lim_{n\to \infty} \left(\frac{1}{(n+1)^2}+\dots \frac 1{(2n)^2}\right),"['sequences-and-series', 'limits', 'convergence-divergence', 'solution-verification', 'summation']"
57,$\lim_{x\to\infty} \left(\sqrt[3]{x^3+x^2+1}-\sqrt[3]{x^3-x^2+1}\right)$,,\lim_{x\to\infty} \left(\sqrt[3]{x^3+x^2+1}-\sqrt[3]{x^3-x^2+1}\right),"this is like an idea, the procedure is longer. Can someone please tell me if this is ok or if there is a better solution (hopefully shorter) \begin{align} &\lim_{x\to\infty} \left(\sqrt[3]{x^3+x^2+1}-\sqrt[3]{x^3-x^2+1}\right) \\ &=\sqrt[3]{x^3+x^2+1} - \sqrt[3]{x^3-x^2+1}\\ &=\frac{2x^2}{\sqrt[3]{(x^3+x^2+1)^2} + \sqrt[3]{(x^3+x^2+1)(x^3-x^2+1)} + \sqrt[3]{(x^3-x^2+1)^2}}\\ &= \frac{2}{3}. \end{align}","this is like an idea, the procedure is longer. Can someone please tell me if this is ok or if there is a better solution (hopefully shorter)","\begin{align}
&\lim_{x\to\infty} \left(\sqrt[3]{x^3+x^2+1}-\sqrt[3]{x^3-x^2+1}\right) \\
&=\sqrt[3]{x^3+x^2+1} - \sqrt[3]{x^3-x^2+1}\\
&=\frac{2x^2}{\sqrt[3]{(x^3+x^2+1)^2} + \sqrt[3]{(x^3+x^2+1)(x^3-x^2+1)} + \sqrt[3]{(x^3-x^2+1)^2}}\\
&= \frac{2}{3}.
\end{align}","['calculus', 'limits']"
58,Limit $\lim _{t\to \infty} \int_t^\infty t \frac {\sin^2 (u)}{u^2} du$,Limit,\lim _{t\to \infty} \int_t^\infty t \frac {\sin^2 (u)}{u^2} du,"Does the limit $\displaystyle{\lim _{t \to \infty}  t \cdot \int_t^\infty \frac {\sin^2 (u)}{u^2} \mathrm{d}u}$ exist? Intuitively, since $\sin(t) > \frac 1 2$ holds for at least half of a period, I would assume that the integral $\int_t^\infty \frac {\sin^2 (u)}{u^2} \mathrm{d}u$ behaves approximately as $\int_t^\infty \frac {1}{u^2} \mathrm{d}u$ . But the latter is $\frac 1 t$ , so it seems that the limit diverges. Is it true?","Does the limit exist? Intuitively, since holds for at least half of a period, I would assume that the integral behaves approximately as . But the latter is , so it seems that the limit diverges. Is it true?",\displaystyle{\lim _{t \to \infty}  t \cdot \int_t^\infty \frac {\sin^2 (u)}{u^2} \mathrm{d}u} \sin(t) > \frac 1 2 \int_t^\infty \frac {\sin^2 (u)}{u^2} \mathrm{d}u \int_t^\infty \frac {1}{u^2} \mathrm{d}u \frac 1 t,"['limits', 'improper-integrals']"
59,Which functions besides $\ln{x}$ make $ \lim \limits_{N \to \infty} \sum_{n=1}^N f'(n) -f(N) $ converge?,Which functions besides  make  converge?,\ln{x}  \lim \limits_{N \to \infty} \sum_{n=1}^N f'(n) -f(N) ,"Using a very hand-wavy argument, I convinced myself that if, instead of $f(x)=\ln{x}$ , we let $f(x)=\sqrt{x}$ , we should still get something finite and small. Wasn't really sure where to start to prove it, so ran a program to see what happens for large N instead. $$ L = \lim \limits_{N \to \infty} \sum_{n=1}^N \frac{1}{2\sqrt{n}}  -\sqrt{N} $$ It seems like $L$ approaches about $-0.73018$ but couldn't really tell if it wasn't just running away to negative infinity really really slowly. What tactics might we use to prove/disprove convergence here? Edit: I've since discovered that this number is exactly $\frac{1}{2}\zeta(\frac{1}{2})$ Why $\zeta (1/2)=-1.4603545088...$?","Using a very hand-wavy argument, I convinced myself that if, instead of , we let , we should still get something finite and small. Wasn't really sure where to start to prove it, so ran a program to see what happens for large N instead. It seems like approaches about but couldn't really tell if it wasn't just running away to negative infinity really really slowly. What tactics might we use to prove/disprove convergence here? Edit: I've since discovered that this number is exactly Why $\zeta (1/2)=-1.4603545088...$?",f(x)=\ln{x} f(x)=\sqrt{x}  L = \lim \limits_{N \to \infty} \sum_{n=1}^N \frac{1}{2\sqrt{n}}  -\sqrt{N}  L -0.73018 \frac{1}{2}\zeta(\frac{1}{2}),"['limits', 'convergence-divergence', 'euler-mascheroni-constant']"
60,Limits of Sequences,Limits of Sequences,,"I'm having trouble calculating this limit directly : $$\lim_{n\to\infty}\frac{(2n＋1)(2n＋3)\cdots(4n＋1)}{(2n)(2n＋2)\cdots(4n)}$$ It can be calculated using the inventory method and the result is: $$\lim_{n\to\infty}\frac{(2n＋1)(2n＋3)\cdots(4n＋1)}{(2n)(2n＋2)\cdots(4n)} ＝\sqrt {2}$$ But the limit method is not smart, I need help doing this in a direct way. This is the first time I am asking a question on this site. I apologize if it is not a good question.","I'm having trouble calculating this limit directly : It can be calculated using the inventory method and the result is: But the limit method is not smart, I need help doing this in a direct way. This is the first time I am asking a question on this site. I apologize if it is not a good question.",\lim_{n\to\infty}\frac{(2n＋1)(2n＋3)\cdots(4n＋1)}{(2n)(2n＋2)\cdots(4n)} \lim_{n\to\infty}\frac{(2n＋1)(2n＋3)\cdots(4n＋1)}{(2n)(2n＋2)\cdots(4n)} ＝\sqrt {2},['limits']
61,Does convergence of arithmetic mean imply convergence of geometric mean?,Does convergence of arithmetic mean imply convergence of geometric mean?,,"Let $x_n$ be a sequence of positive real numbers, which is not convergent. ( $x_n$ does not converge to a finite number, nor to infinity). Define $$ A_n = \frac{x_1 + x_2 + \cdots + x_n}{n} \quad \text{ and }\quad G_n = \sqrt[n]{x_1x_2...x_n}.$$ Does the convergence of $A_n$ imply the convergence of $G_n$ or vice versa? I know that if $x_n \to L \in \mathbb{R}\cup\{\infty\}$ , then both $A_n,G_n$ converge to $L$ . But here I assume $x_n$ is not convergent. I also wonder if adding a boundedness assumption on $x_n$ changes anything.","Let be a sequence of positive real numbers, which is not convergent. ( does not converge to a finite number, nor to infinity). Define Does the convergence of imply the convergence of or vice versa? I know that if , then both converge to . But here I assume is not convergent. I also wonder if adding a boundedness assumption on changes anything.","x_n x_n  A_n = \frac{x_1 + x_2 + \cdots + x_n}{n} \quad \text{ and }\quad G_n = \sqrt[n]{x_1x_2...x_n}. A_n G_n x_n \to L \in \mathbb{R}\cup\{\infty\} A_n,G_n L x_n x_n","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'means']"
62,What is an easy way to understand the Intermediate value theorem?,What is an easy way to understand the Intermediate value theorem?,,"Let $f(x) = \sqrt{x^2-4}$ , Use Intermediate value theorem to show that $f(x) = 5\sin x$ has a solution for $2<x<3$ , The never truly understand the theorem fully, so I am working on examples to see if makes sense. so, $\sqrt{x^2-4} = 5\sin x$ , $g(x) =\sqrt{x^2-4} - 5\sin x = 0$ $g(2) = \sqrt{2^2 -4} - 5\sin (2) = -4.546 (<0)$ $g(3) = \sqrt{3^2-4} - 5\sin(4) = 1.5304 (>0)$ I am just following step by step from what I learned how to solve it, but I never knew the meaning of doing it. Example, Why must we find $g(2), g(3)$ ? and also $g(2)= -4.546 (<0)$ what does this values and $<0$ really mean? And from here, I need to apply the theorem to get to a conclusion which Im unclear of as I don't really understand the theorem","Let , Use Intermediate value theorem to show that has a solution for , The never truly understand the theorem fully, so I am working on examples to see if makes sense. so, , I am just following step by step from what I learned how to solve it, but I never knew the meaning of doing it. Example, Why must we find ? and also what does this values and really mean? And from here, I need to apply the theorem to get to a conclusion which Im unclear of as I don't really understand the theorem","f(x) = \sqrt{x^2-4} f(x) = 5\sin x 2<x<3 \sqrt{x^2-4} = 5\sin x g(x) =\sqrt{x^2-4} - 5\sin x = 0 g(2) = \sqrt{2^2 -4} - 5\sin (2) = -4.546 (<0) g(3) = \sqrt{3^2-4} - 5\sin(4) = 1.5304 (>0) g(2), g(3) g(2)= -4.546 (<0) <0","['limits', 'functions']"
63,limit $\lim_{k \to \infty} \int_{0}^{1} \frac{kx^k}{1+x} dx$,limit,\lim_{k \to \infty} \int_{0}^{1} \frac{kx^k}{1+x} dx,"Consider the following sequence of functions and their integrals on $[0,1]$ . Evaluate the limit of the following integral if possible $$\lim_{k \to \infty} \int_{0}^{1} \frac{kx^k}{1+x} dx$$ At first glance, I do not know if the limit exists or not. Wolfram alpha will not take the limit for me, but it did evaluate the integral. The result is terms of a function I do not understand, but from looking at the series expansion: $$x^k \left(\frac{kx}{k+1} - \frac{kx^2}{k+2} + \frac{kx^3}{k+3} - \dots\right)$$ it appears as though the limit is $0$ since $x \in [0,1]$ . However, I have attempted the problem two different ways, and I am getting that the result is infinity. I am curious where I maybe going wrong. Note: I am not looking for an answer. I just want to see where my logic is wrong (mainly in my 2nd attempt) so that I can try to make the correction. Attempt 1: I can pull the $k$ outside the integral and get $$\lim_{k \to \infty} k \int_{0}^{1} \frac{x^k}{1 + x} dx$$ . Now, $|\frac{x^k}{1+x}| \leq \frac{1}{1+x} = g(x)$ since we are on $[0,1]$ . Since $g(x)$ is integrable, and dominates $f(x)$ , the dominated convergence theorem tells me I can pass the limit inside. $$\int_{0}^{1} \lim_{k \to \infty} \frac{kx^k}{1+x} dx = \infty $$ due to the factor of $k$ . Now, outside of the fact that I have not done measure theory for quite some time, I am uncertain about this for two reasons. One, DCT refers to Lebesgue integrable functions. I am always hesitant when I use it during a discussion of Riemann integration. Secondly, while I am definitely allowed to pull the $k$ outside of the integral, I am not sure I am allowed to apply DCT on the result without $k$ , and then put the $k$ back inside along with the limit. If I had to dominate $\frac{kx^k}{1 + x}$ , I am not sure it would work. These uncertainties made me want to try to brute force this with Riemann integration. Attempt 2: I will rewrite the integral as $$\lim_{k \to \infty} k \int_{0}^{1} \frac{x^k}{(\sqrt{1 + x})^2}dx$$ so that I can apply Trigonometric substitution. I would get $\sec(\theta) = \sqrt{1 + x}$ $\tan(\theta) = \sqrt{x}$ $\tan^2(\theta) = x$ $2\tan(\theta)\sec^2(\theta)d\theta = dx$ Substituting, $$\lim_{k \to \infty} k \int \frac{\tan^{2k}(\theta)}{\sec^2(\theta)} 2 \tan(\theta) \sec^2(\theta) d\theta$$ Cleaning this up, $$\lim_{k \to \infty} 2k \int \tan^{2k+1}(\theta) d\theta$$ Now, I can pull out 2 of the tangents. $$\lim_{k \to \infty} 2k \int \tan^{2k - 1}(\theta) \tan^2(\theta)d\theta$$ Using the identity $\tan^2(\theta) = \sec^2(\theta) - 1$ , $$\lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) \sec^2(\theta) d\theta - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta$$ The first integral can be done with $u$ -substitution. Let $u = \tan(\theta)$ . Then, $du = \sec^2(\theta) d\theta$ $$\lim_{k \to \infty} 2k \left[\frac{u^{2k}}{2k}\right] - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta$$ Now, I can back substitute. $$\lim_{k \to \infty} 2k \left[\frac{\tan^{2k}(\theta)}{2k}\right] - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta$$ Again, $$\lim_{k \to \infty} 2k \left[\frac{x^k}{2k}\right]_{0}^{1} - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta$$ Evaluating, $$\lim_{k \to \infty} 2k \frac{1}{2k} - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta$$ At this point, I can say the first limit is $1$ . Now, I still have an odd power of tangent in the second integral. So, I can repeat this process again $$1 - \lim_{k \to \infty} 2k \int \tan^{2k - 3}(\theta) \sec^2(\theta) d\theta + \lim_{k \to \infty} 2k \int \tan^{2k - 3}(\theta) d\theta$$ Then, $$1 - \lim_{k \to \infty} 2k \left[\frac{u^{2k-2}}{2k-2}\right] + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta)$$ Again, $$1 - \lim_{k \to \infty} 2k \left[\frac{\tan^{2k-2}(\theta)}{2k-2}\right] + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta)$$ Then, $$1 - \lim_{k \to \infty} 2k \left[\frac{x^{k-1}}{2k-2}\right]_{0}^{1} + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta)$$ Evaluating, $$1 - \lim_{k \to \infty} 2k \frac{1}{2k-2} + \lim_{k \to \infty} \int \tan^{2k-3}(\theta) d\theta$$ Then, this limit is also $1$ $$1 - 1 + \lim_{k \to \infty} 2k \int \tan^{2k-3}(\theta) d\theta)$$ So, $$\int \tan^{2k-3}(\theta) d\theta)$$ Well, this is very nice. I have ended up with a single integral with an odd power of tangent. So, I can repeat these two steps over and over until I am left with. $$\lim_{k \to \infty} 2k \int \tan(\theta) d\theta$$ after going through all of the powers. Well, this integral I know $$\lim_{k \to \infty} 2k \left[- \ln|\cos(\theta)| \right]$$ Going back to our trig sub, we can see that $$\cos(\theta) = \frac{1}{\sqrt{1 + x}}$$ . Therefore, $$\lim_{k \to \infty} 2k \left[ -\ln|\frac{1}{\sqrt{1+x}}|\right]_{0}^{1}$$ Evaluating, $$\lim_{k \to \infty} -2k\ln|\frac{1}{\sqrt{2}}| = \infty$$ This matched the result I got before, and I will much better about this because I just used straight up integration rather than a sophisticated tool that I don't know very well, the dominated convergence theorem. My uncertainty lies in that the answer does not appear to be $\infty$ based on the power series wolfram alpha gave. Does anyone see where I am going wrong?","Consider the following sequence of functions and their integrals on . Evaluate the limit of the following integral if possible At first glance, I do not know if the limit exists or not. Wolfram alpha will not take the limit for me, but it did evaluate the integral. The result is terms of a function I do not understand, but from looking at the series expansion: it appears as though the limit is since . However, I have attempted the problem two different ways, and I am getting that the result is infinity. I am curious where I maybe going wrong. Note: I am not looking for an answer. I just want to see where my logic is wrong (mainly in my 2nd attempt) so that I can try to make the correction. Attempt 1: I can pull the outside the integral and get . Now, since we are on . Since is integrable, and dominates , the dominated convergence theorem tells me I can pass the limit inside. due to the factor of . Now, outside of the fact that I have not done measure theory for quite some time, I am uncertain about this for two reasons. One, DCT refers to Lebesgue integrable functions. I am always hesitant when I use it during a discussion of Riemann integration. Secondly, while I am definitely allowed to pull the outside of the integral, I am not sure I am allowed to apply DCT on the result without , and then put the back inside along with the limit. If I had to dominate , I am not sure it would work. These uncertainties made me want to try to brute force this with Riemann integration. Attempt 2: I will rewrite the integral as so that I can apply Trigonometric substitution. I would get Substituting, Cleaning this up, Now, I can pull out 2 of the tangents. Using the identity , The first integral can be done with -substitution. Let . Then, Now, I can back substitute. Again, Evaluating, At this point, I can say the first limit is . Now, I still have an odd power of tangent in the second integral. So, I can repeat this process again Then, Again, Then, Evaluating, Then, this limit is also So, Well, this is very nice. I have ended up with a single integral with an odd power of tangent. So, I can repeat these two steps over and over until I am left with. after going through all of the powers. Well, this integral I know Going back to our trig sub, we can see that . Therefore, Evaluating, This matched the result I got before, and I will much better about this because I just used straight up integration rather than a sophisticated tool that I don't know very well, the dominated convergence theorem. My uncertainty lies in that the answer does not appear to be based on the power series wolfram alpha gave. Does anyone see where I am going wrong?","[0,1] \lim_{k \to \infty} \int_{0}^{1} \frac{kx^k}{1+x} dx x^k \left(\frac{kx}{k+1} - \frac{kx^2}{k+2} + \frac{kx^3}{k+3} - \dots\right) 0 x \in [0,1] k \lim_{k \to \infty} k \int_{0}^{1} \frac{x^k}{1 + x} dx |\frac{x^k}{1+x}| \leq \frac{1}{1+x} = g(x) [0,1] g(x) f(x) \int_{0}^{1} \lim_{k \to \infty} \frac{kx^k}{1+x} dx = \infty  k k k k \frac{kx^k}{1 + x} \lim_{k \to \infty} k \int_{0}^{1} \frac{x^k}{(\sqrt{1 + x})^2}dx \sec(\theta) = \sqrt{1 + x} \tan(\theta) = \sqrt{x} \tan^2(\theta) = x 2\tan(\theta)\sec^2(\theta)d\theta = dx \lim_{k \to \infty} k \int \frac{\tan^{2k}(\theta)}{\sec^2(\theta)} 2 \tan(\theta) \sec^2(\theta) d\theta \lim_{k \to \infty} 2k \int \tan^{2k+1}(\theta) d\theta \lim_{k \to \infty} 2k \int \tan^{2k - 1}(\theta) \tan^2(\theta)d\theta \tan^2(\theta) = \sec^2(\theta) - 1 \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) \sec^2(\theta) d\theta - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta u u = \tan(\theta) du = \sec^2(\theta) d\theta \lim_{k \to \infty} 2k \left[\frac{u^{2k}}{2k}\right] - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta \lim_{k \to \infty} 2k \left[\frac{\tan^{2k}(\theta)}{2k}\right] - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta \lim_{k \to \infty} 2k \left[\frac{x^k}{2k}\right]_{0}^{1} - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta \lim_{k \to \infty} 2k \frac{1}{2k} - \lim_{k \to \infty} 2k \int \tan^{2k-1}(\theta) d\theta 1 1 - \lim_{k \to \infty} 2k \int \tan^{2k - 3}(\theta) \sec^2(\theta) d\theta + \lim_{k \to \infty} 2k \int \tan^{2k - 3}(\theta) d\theta 1 - \lim_{k \to \infty} 2k \left[\frac{u^{2k-2}}{2k-2}\right] + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta) 1 - \lim_{k \to \infty} 2k \left[\frac{\tan^{2k-2}(\theta)}{2k-2}\right] + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta) 1 - \lim_{k \to \infty} 2k \left[\frac{x^{k-1}}{2k-2}\right]_{0}^{1} + \lim_{k \to \infty} \int \tan^{2k - 3}(\theta) 1 - \lim_{k \to \infty} 2k \frac{1}{2k-2} + \lim_{k \to \infty} \int \tan^{2k-3}(\theta) d\theta 1 1 - 1 + \lim_{k \to \infty} 2k \int \tan^{2k-3}(\theta) d\theta) \int \tan^{2k-3}(\theta) d\theta) \lim_{k \to \infty} 2k \int \tan(\theta) d\theta \lim_{k \to \infty} 2k \left[- \ln|\cos(\theta)| \right] \cos(\theta) = \frac{1}{\sqrt{1 + x}} \lim_{k \to \infty} 2k \left[ -\ln|\frac{1}{\sqrt{1+x}}|\right]_{0}^{1} \lim_{k \to \infty} -2k\ln|\frac{1}{\sqrt{2}}| = \infty \infty","['real-analysis', 'limits', 'riemann-integration', 'trigonometric-integrals', 'sequence-of-function']"
64,"Evaluate: $\lim_{n\to\infty} \int_{[0,\infty)} (1+x/n)^{-n}\sin(x/n)\,dx.$",Evaluate:,"\lim_{n\to\infty} \int_{[0,\infty)} (1+x/n)^{-n}\sin(x/n)\,dx.","Evaluate: $$\lim_{n\to\infty} \int_0^{\infty} \left(1+\frac xn\right)^{-n}\sin \frac xn\,dx.$$ I have tried to use the (Lebesgue) dominated convergence theorem to evaluate the same. At first I noticed that: $\left|\left(1+\frac xn\right)^{-n}\sin \frac xn\right|\le\left|\left(1+\frac xn\right)^{-n}\right|\le1\text{ for all positive }x \text{ and for all natural }n\tag*{}.$ Since $g(x)=1$ is Lebesgue integrable for each $x\in[0,\infty).$ So by DCT, the given limit equals: $$\int_0^{\infty} \lim_{n\to\infty}  \left(1+\frac xn\right)^{-n}\sin \frac xn\,dx=\int_0^{\infty}e^{-x}\cdot0\,dx=0.$$ This question was asked in our end term exam this semester and so I don't know the correct answer to this question. Therefore, just to check whether I have evaluated the limit correctly I am posting the same here on MSE. If I have gone wrong somewhere, please point out and give some insights. Thanks in advance.","Evaluate: I have tried to use the (Lebesgue) dominated convergence theorem to evaluate the same. At first I noticed that: Since is Lebesgue integrable for each So by DCT, the given limit equals: This question was asked in our end term exam this semester and so I don't know the correct answer to this question. Therefore, just to check whether I have evaluated the limit correctly I am posting the same here on MSE. If I have gone wrong somewhere, please point out and give some insights. Thanks in advance.","\lim_{n\to\infty} \int_0^{\infty} \left(1+\frac xn\right)^{-n}\sin \frac xn\,dx. \left|\left(1+\frac xn\right)^{-n}\sin \frac xn\right|\le\left|\left(1+\frac xn\right)^{-n}\right|\le1\text{ for all positive }x \text{ and for all natural }n\tag*{}. g(x)=1 x\in[0,\infty). \int_0^{\infty} \lim_{n\to\infty}  \left(1+\frac xn\right)^{-n}\sin \frac xn\,dx=\int_0^{\infty}e^{-x}\cdot0\,dx=0.","['limits', 'measure-theory']"
65,Find $\lim_{x\to 0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)}$ without using the L'Hopital's rule or Taylor's series,Find  without using the L'Hopital's rule or Taylor's series,\lim_{x\to 0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)},"This limit is proposed to be solved without using the L'Hopital's rule or Taylor series: $$ \lim_{x\to0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)}, $$ where $a,b=const$ . I know how to calculate this limit using the L'Hopital's rule: $$ \lim_{x\to0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)}= \lim_{x\to0}\frac{\frac{2a\sin (ax)\cos (ax)}{\sin^2(ax)}}{\frac{2b\sin (bx)\cos (bx)}{\sin^2(bx)}}= \lim_{x\to0}\frac{a}{b}\cdot\frac{\sin (ax)\cos (ax)}{\sin (bx)\cos (bx)}\cdot\frac{\sin^2(bx)}{\sin^2(ax)} $$ (using the asymptotic equivalence $\sin x\sim x$ ) $$ =\lim_{x\to0}\frac{a}{b}\cdot\frac{ax}{bx}\cdot\frac{(bx)^2}{(ax)^2}=1, $$ but I don't know to calculate this limit without derivatives.",This limit is proposed to be solved without using the L'Hopital's rule or Taylor series: where . I know how to calculate this limit using the L'Hopital's rule: (using the asymptotic equivalence ) but I don't know to calculate this limit without derivatives.,"
\lim_{x\to0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)},
 a,b=const 
\lim_{x\to0}\frac{\ln\sin^2(ax)}{\ln\sin^2(bx)}=
\lim_{x\to0}\frac{\frac{2a\sin (ax)\cos (ax)}{\sin^2(ax)}}{\frac{2b\sin (bx)\cos (bx)}{\sin^2(bx)}}=
\lim_{x\to0}\frac{a}{b}\cdot\frac{\sin (ax)\cos (ax)}{\sin (bx)\cos (bx)}\cdot\frac{\sin^2(bx)}{\sin^2(ax)}
 \sin x\sim x 
=\lim_{x\to0}\frac{a}{b}\cdot\frac{ax}{bx}\cdot\frac{(bx)^2}{(ax)^2}=1,
","['calculus', 'limits', 'logarithms', 'limits-without-lhopital']"
66,"Finding $\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right)$",Finding,"\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right)","What is the limit of $\,\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right)$ ? My thought was $\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\left(\frac{1}{\sin^2 x} - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\left(\frac{1}{x^2} - \frac{1}{x^2} \right) = 0$ . I used $\lim\limits_{x\to 0} \frac{\sin x}{x} = 1$ . But $\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\frac{x^2-\sin^2x}{x^2\sin^2x}$ and if I apply L'Hospital's Rule four times at the second expression, I get $\lim\limits_{x\to 0}\,\left(\frac{8\cos 2x}{24\cos 2x - 32\sin 2x - 8x^2\cos 2x}\right) = \frac {1}{3}$ . What am I missing?","What is the limit of ? My thought was . I used . But and if I apply L'Hospital's Rule four times at the second expression, I get . What am I missing?","\,\lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right) \lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\left(\frac{1}{\sin^2 x} - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\left(\frac{1}{x^2} - \frac{1}{x^2} \right) = 0 \lim\limits_{x\to 0} \frac{\sin x}{x} = 1 \lim\limits_{x\to 0}\,\left(\csc^2x - \frac{1}{x^2}\right) = \lim\limits_{x\to 0}\,\frac{x^2-\sin^2x}{x^2\sin^2x} \lim\limits_{x\to 0}\,\left(\frac{8\cos 2x}{24\cos 2x - 32\sin 2x - 8x^2\cos 2x}\right) = \frac {1}{3}","['calculus', 'limits', 'solution-verification']"
67,Proving a derivative exists given the limit of f',Proving a derivative exists given the limit of f',,"I have almost finished a problem from Baby Rudin, but I can't quite figure out the last step. The problem is as follows (5.9): Let $f$ be: a continuous real function on $\mathbb{R}^{1}$ , of which it is known that $f'(x)$ exists for all $x\neq0$ , and $f'(x) \rightarrow 3$ as $x \rightarrow 0$ . Does it follow that $f'(0)$ exists? Here's what I have so far: By (1), there exists a $\delta_{1}$ with $|x|<\delta_{1} \rightarrow |f(x)-f(0)|<\frac{\epsilon}{3}$ . By (2), there exists a $\delta_{2}$ with $|x-t|<\delta_{2}, x\neq0 \rightarrow |\frac{f(t)-f(x)}{t-x}-f'(x)|<\frac{\epsilon}{3}$ . By (3), there exists a $\delta_{3}$ with $x\neq0, |x|<\delta_{3} \rightarrow |f'(x)-3|<\frac{\epsilon}{3}$ . So when $|x|<\min(\delta_{1},\delta_{3})$ , $|x-t|<\min(\delta_{2},1)$ : $|\frac{f(t)-f(x)}{t-x}-f'(x)|+|f'(x)-3|+ |f(x)-f(0)| < \epsilon$ $|\frac{f(t)-f(x)}{t-x}-f'(x)+f'(x)-3+f(x)-f(0)| < \epsilon$ $|\frac{f(t)-f(x)}{t-x}-f'(x)+f'(x)-3+\frac{f(x)-f(0)}{t-x}| < \epsilon$ $|\frac{f(t)-f(0)}{t-x}-3|<\epsilon$ Which is very close to $|\frac{f(t)-f(0)}{t}-3|<\epsilon$ which would yield a solution to the problem. But I can't figure out what condition to put on x or t-x to get from $|\frac{f(t)-f(0)}{t-x}-3|<\epsilon$ to $|\frac{f(t)-f(0)}{t}-3|<\epsilon$ . Any help would be very, very appreciated.","I have almost finished a problem from Baby Rudin, but I can't quite figure out the last step. The problem is as follows (5.9): Let be: a continuous real function on , of which it is known that exists for all , and as . Does it follow that exists? Here's what I have so far: By (1), there exists a with . By (2), there exists a with . By (3), there exists a with . So when , : Which is very close to which would yield a solution to the problem. But I can't figure out what condition to put on x or t-x to get from to . Any help would be very, very appreciated.","f \mathbb{R}^{1} f'(x) x\neq0 f'(x) \rightarrow 3 x \rightarrow 0 f'(0) \delta_{1} |x|<\delta_{1} \rightarrow |f(x)-f(0)|<\frac{\epsilon}{3} \delta_{2} |x-t|<\delta_{2}, x\neq0 \rightarrow |\frac{f(t)-f(x)}{t-x}-f'(x)|<\frac{\epsilon}{3} \delta_{3} x\neq0, |x|<\delta_{3} \rightarrow |f'(x)-3|<\frac{\epsilon}{3} |x|<\min(\delta_{1},\delta_{3}) |x-t|<\min(\delta_{2},1) |\frac{f(t)-f(x)}{t-x}-f'(x)|+|f'(x)-3|+ |f(x)-f(0)| < \epsilon |\frac{f(t)-f(x)}{t-x}-f'(x)+f'(x)-3+f(x)-f(0)| < \epsilon |\frac{f(t)-f(x)}{t-x}-f'(x)+f'(x)-3+\frac{f(x)-f(0)}{t-x}| < \epsilon |\frac{f(t)-f(0)}{t-x}-3|<\epsilon |\frac{f(t)-f(0)}{t}-3|<\epsilon |\frac{f(t)-f(0)}{t-x}-3|<\epsilon |\frac{f(t)-f(0)}{t}-3|<\epsilon","['real-analysis', 'calculus', 'limits', 'analysis']"
68,"Behavior of $f(n)=\sum_{i,j<n} \left(\frac{1}{i}-\frac{1}{j}\right)^2$",Behavior of,"f(n)=\sum_{i,j<n} \left(\frac{1}{i}-\frac{1}{j}\right)^2","Does the following sum over positive integers have a name/asymptotic closed form? $$f(n)=\sum_{i,j<n} \left(\frac{1}{i}-\frac{1}{j}\right)^2$$ In particular I'm wondering if it eventually grows linearly or sublinearly",Does the following sum over positive integers have a name/asymptotic closed form? In particular I'm wondering if it eventually grows linearly or sublinearly,"f(n)=\sum_{i,j<n} \left(\frac{1}{i}-\frac{1}{j}\right)^2","['sequences-and-series', 'limits']"
69,How to solve this limit related to series [closed],How to solve this limit related to series [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need just an idea to solve the following limit? I tried everything without success $\lim_{N\rightarrow+\infty}\frac{1}{N}\sum_{k=1}^{N-1} \left(\frac{k}{k+1}\right)^N$ Source https://artofproblemsolving.com/community/c7h495716p2783297","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need just an idea to solve the following limit? I tried everything without success Source https://artofproblemsolving.com/community/c7h495716p2783297",\lim_{N\rightarrow+\infty}\frac{1}{N}\sum_{k=1}^{N-1} \left(\frac{k}{k+1}\right)^N,"['sequences-and-series', 'limits']"
70,Does the prime number theorem tell us that the next prime number is guaranteed to be relatively nearby?,Does the prime number theorem tell us that the next prime number is guaranteed to be relatively nearby?,,"Let $\ p_n\ $ be the $\ n$ -th prime number. Does the prime number theorem , $\Large{\lim_{x\to\infty}\frac{\pi(x)}{\left[ \frac{x}{\log(x)}\right]} = 1},$ imply that: $ \displaystyle\lim_{n\to\infty}\ \frac{p_n}{p_{n+1}} = 1\ ?$ Edit: I totally get where the vote-to-closes come from and I kind of agree with them. Yeah this is not the question I intended to ask actually. I think I've done an X-Y communication thingy. I'll leave the question and accept the answer though. But I have learned something about prime numbers along the way in reading the answers...","Let be the -th prime number. Does the prime number theorem , imply that: Edit: I totally get where the vote-to-closes come from and I kind of agree with them. Yeah this is not the question I intended to ask actually. I think I've done an X-Y communication thingy. I'll leave the question and accept the answer though. But I have learned something about prime numbers along the way in reading the answers...","\ p_n\  \ n \Large{\lim_{x\to\infty}\frac{\pi(x)}{\left[ \frac{x}{\log(x)}\right]} = 1},  \displaystyle\lim_{n\to\infty}\ \frac{p_n}{p_{n+1}} = 1\ ?","['limits', 'number-theory', 'prime-numbers', 'prime-gaps']"
71,Why $\lim\limits_{n \to +\infty} \bigg(\dfrac{n+1}{n+2}\bigg)^n = \frac{1}{e}$?,Why ?,\lim\limits_{n \to +\infty} \bigg(\dfrac{n+1}{n+2}\bigg)^n = \frac{1}{e},"I tried to solve this limit: $\lim\limits_{n \to +\infty} \bigg(\dfrac{n+1}{n+2}\bigg)^n$ . My approach was to re-write it as $\lim\limits_{n \to +\infty} \bigg(\dfrac{n}{n+2} + \dfrac{1}{n+2}\bigg)^n$ , and since $\dfrac{n}{n+2}$ tends to 1 and $\dfrac{1}{n+2} \sim \dfrac{1}{n}$ as $n \to +\infty$ , I figured the solution would be $e$ , as $\lim\limits_{n \to +\infty} \bigg(1+\dfrac{1}{n}\bigg)^n = e$ . I suppose I've done something wrong, since by plotting the function I noticed the solution is $\dfrac{1}{e}$ . Where is my error?","I tried to solve this limit: . My approach was to re-write it as , and since tends to 1 and as , I figured the solution would be , as . I suppose I've done something wrong, since by plotting the function I noticed the solution is . Where is my error?",\lim\limits_{n \to +\infty} \bigg(\dfrac{n+1}{n+2}\bigg)^n \lim\limits_{n \to +\infty} \bigg(\dfrac{n}{n+2} + \dfrac{1}{n+2}\bigg)^n \dfrac{n}{n+2} \dfrac{1}{n+2} \sim \dfrac{1}{n} n \to +\infty e \lim\limits_{n \to +\infty} \bigg(1+\dfrac{1}{n}\bigg)^n = e \dfrac{1}{e},['limits']
72,Limit Problem using L'Hospital's Rule Transformation,Limit Problem using L'Hospital's Rule Transformation,,"Find $\lim _{x \rightarrow 0}\left[x /\left(e^{x}-1\right)\right]^{1 / x}$ It seems obvious that the initial step should be taken using an exponential function, where the new form yields $\frac{\ln(\frac{x}{e^x-1})}{x}$ . However, L'Hospital's rule does not work in this case. Are there any possible alternatives to transform the given expression?","Find It seems obvious that the initial step should be taken using an exponential function, where the new form yields . However, L'Hospital's rule does not work in this case. Are there any possible alternatives to transform the given expression?",\lim _{x \rightarrow 0}\left[x /\left(e^{x}-1\right)\right]^{1 / x} \frac{\ln(\frac{x}{e^x-1})}{x},"['limits', 'derivatives']"
73,Will the limit exist?,Will the limit exist?,,"If $$f(x) = \begin{cases} \frac{\sin([x]+x)}{[x]+x} &\textrm{if } x \neq 0, \\ 1 &\textrm{if } x = 0, \end{cases}$$ where [.] is the greatest integer function, then does $\lim_{x \to 0}f(x)$ exist or not? I thought of using the property that $\lim_{x \to 0} \frac{\sin g(x)}{g(x)}=1$ by which I thought that the limit should exist but my book said otherwise. What did I miss? Is there anything else that should be applied?","If where [.] is the greatest integer function, then does exist or not? I thought of using the property that by which I thought that the limit should exist but my book said otherwise. What did I miss? Is there anything else that should be applied?","f(x) = \begin{cases} \frac{\sin([x]+x)}{[x]+x} &\textrm{if } x \neq 0, \\ 1 &\textrm{if } x = 0, \end{cases} \lim_{x \to 0}f(x) \lim_{x \to 0} \frac{\sin g(x)}{g(x)}=1","['calculus', 'limits', 'functions', 'ceiling-and-floor-functions']"
74,How could I approach $\lim_{n\to\infty}\left(\frac{1+\cos\left(\frac{1}{2^{n}}\right)}{2}\right)^n$?,How could I approach ?,\lim_{n\to\infty}\left(\frac{1+\cos\left(\frac{1}{2^{n}}\right)}{2}\right)^n,"So, about the following limit: $$\lim_{n\to\infty} \left( \frac{1+\cos(\frac{1}{2^{n}})}{2} \right)^n$$ I tried several things to evaluate it, namely looking at it as $\cos(\frac{1}{2^{n+1}})^{2n}$ instead or as $\exp(2n \cdot \ln({\cos(\frac{1}{2^{n+1}})})$ and then trying to show that the limit of $n\cdot\ln({\cos(\frac{1}{2^{n+1}})})$ is $0$ (for example using L'Hopital's rule), but I haven't been very successful (though it is possible I gave up too early). I'm just not sure how to approach this cosine-exponential combo. I believe the limit is $1$ , so things like the root test weren't very helpful in this case, either. I'd really appreciate a direction/hint, a full solution, or anything inbetween.","So, about the following limit: I tried several things to evaluate it, namely looking at it as instead or as and then trying to show that the limit of is (for example using L'Hopital's rule), but I haven't been very successful (though it is possible I gave up too early). I'm just not sure how to approach this cosine-exponential combo. I believe the limit is , so things like the root test weren't very helpful in this case, either. I'd really appreciate a direction/hint, a full solution, or anything inbetween.",\lim_{n\to\infty} \left( \frac{1+\cos(\frac{1}{2^{n}})}{2} \right)^n \cos(\frac{1}{2^{n+1}})^{2n} \exp(2n \cdot \ln({\cos(\frac{1}{2^{n+1}})}) n\cdot\ln({\cos(\frac{1}{2^{n+1}})}) 0 1,"['sequences-and-series', 'limits', 'trigonometry', 'exponential-function']"
75,If the following piecewise function is continuous,If the following piecewise function is continuous,,"If the following piecewise function is continuous, what is the value of $\alpha$ $ f(x,y)= \begin{cases}  arctan(\dfrac{|x|+|y|}{x^2+y^2})&\text{if}\, (x,y)\ne(0,0)\\  \alpha&\text{if}\, (x,y)=(0,0) \end{cases} $ First I think I need to evaluate the limit of this function but I couldn't find the following limit $$\lim\limits_{(x,y)\to(0,0)}arctan(\dfrac{|x|+|y|}{x^2+y^2})  $$ I checked this limit from wolfarm calculator but that says this limit does not exist. So what can I do here ? please help","If the following piecewise function is continuous, what is the value of First I think I need to evaluate the limit of this function but I couldn't find the following limit I checked this limit from wolfarm calculator but that says this limit does not exist. So what can I do here ? please help","\alpha 
f(x,y)=
\begin{cases}
 arctan(\dfrac{|x|+|y|}{x^2+y^2})&\text{if}\, (x,y)\ne(0,0)\\
 \alpha&\text{if}\, (x,y)=(0,0)
\end{cases}
 \lim\limits_{(x,y)\to(0,0)}arctan(\dfrac{|x|+|y|}{x^2+y^2})  ","['limits', 'multivariable-calculus']"
76,Prove that limit doesn't exists at all,Prove that limit doesn't exists at all,,"I have a function $f(x)=\frac{1}{x}+\sin(\frac{1}{x})$ which I have proved that $\lim_{x \to0^+}f(x)=\infty$ , and I need to prove that $\lim_{x \to0^+}f'(x) \ne -\infty$ . I have got that $f'(x)=-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}$ I am trying to prove that: $$\lim_{x \to 0^+}-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}$$ Does not equal to $-\infty$ (or to prove that it doesn't exists at all). I have tried to assume by contradiction that $$\lim_{x \to 0^+}-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}=-\infty$$ So there exists $\delta_{1}>0$ such that for every $0<x<\delta_{1}$ we say that $$f(x)<\square $$ We choose $\delta=\delta_{1}$ , and let $0<x<\delta$ so: $$f(x)=-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}=-\frac{1}{x^2}(1+\cos(\frac{1}{x}))\le -\frac{2}{x^2}<\frac{2}{\delta^2}=k$$ I do not know what to choose instead of $\square$ , and if what I did is correct. Appreciate your help! I have also tried to think about the continuity of $f$ , and saying that it is not bounded so it can't be continuous, so the limit doesn't exists. Thanks a lot!","I have a function which I have proved that , and I need to prove that . I have got that I am trying to prove that: Does not equal to (or to prove that it doesn't exists at all). I have tried to assume by contradiction that So there exists such that for every we say that We choose , and let so: I do not know what to choose instead of , and if what I did is correct. Appreciate your help! I have also tried to think about the continuity of , and saying that it is not bounded so it can't be continuous, so the limit doesn't exists. Thanks a lot!",f(x)=\frac{1}{x}+\sin(\frac{1}{x}) \lim_{x \to0^+}f(x)=\infty \lim_{x \to0^+}f'(x) \ne -\infty f'(x)=-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2} \lim_{x \to 0^+}-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2} -\infty \lim_{x \to 0^+}-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}=-\infty \delta_{1}>0 0<x<\delta_{1} f(x)<\square  \delta=\delta_{1} 0<x<\delta f(x)=-\frac{1}{x^2}-\frac{\cos(\frac{1}{x})}{x^2}=-\frac{1}{x^2}(1+\cos(\frac{1}{x}))\le -\frac{2}{x^2}<\frac{2}{\delta^2}=k \square f,"['calculus', 'limits', 'derivatives', 'proof-writing', 'solution-verification']"
77,Problem in proof that $ \lim_{x\to0}\frac{\sin(x)}{x}$=$1$,Problem in proof that =, \lim_{x\to0}\frac{\sin(x)}{x} 1,I'm having some confusion on understanding the proof that $$\lim_{x\to 0}\frac{\sin x}{x}=1.$$ In the proof on khanacademy and on other various sources we always end up with the inequality $$\cos(x)\le\frac{\sin(x)}{x}\le1\ $$ And then we apply the squeeze theorem. However in the proof we always say that it is valid for any non zero x however if this is true how can we ever say that the inequality is less than or equal to each other my question is why isn't the inequality this instead $$\cos(x)<\frac{\sin(x)}{x}<1 $$ No one seems to explain how they make the less than or equal to statement true so which one is correct?,I'm having some confusion on understanding the proof that In the proof on khanacademy and on other various sources we always end up with the inequality And then we apply the squeeze theorem. However in the proof we always say that it is valid for any non zero x however if this is true how can we ever say that the inequality is less than or equal to each other my question is why isn't the inequality this instead No one seems to explain how they make the less than or equal to statement true so which one is correct?,"\lim_{x\to 0}\frac{\sin x}{x}=1. \cos(x)\le\frac{\sin(x)}{x}\le1\
 \cos(x)<\frac{\sin(x)}{x}<1
","['calculus', 'limits']"
78,"If $\,\lim_{p\to\infty} \sum_{j=1}^n a_j\cos(p\pi \theta_j) \to 0,\,$ then $\,a_1 = \dots = a_n = 0$.",If  then .,"\,\lim_{p\to\infty} \sum_{j=1}^n a_j\cos(p\pi \theta_j) \to 0,\, \,a_1 = \dots = a_n = 0","The exercise Let $n \geq 1$ , $0 < \theta_1 < \dots < \theta_n < 1$ and $a_1, \dots, a_n \in \mathbb{R}^n$ . Assume $ \sum_{j=1}^n a_j\cos(\pi p \theta_j) \underset{p \to +\infty}{\longrightarrow} 0$ ( $p \in \mathbb{N}$ ). Show $a_1 = \dots = a_n = 0$ . My try I tried to prove this by induction over $n$ . I succeeded for $n = 1$ , but I have no clue to show how the property can be used for $n \geq 2$ .","The exercise Let , and . Assume ( ). Show . My try I tried to prove this by induction over . I succeeded for , but I have no clue to show how the property can be used for .","n \geq 1 0 < \theta_1 < \dots < \theta_n < 1 a_1, \dots, a_n \in \mathbb{R}^n  \sum_{j=1}^n a_j\cos(\pi p \theta_j) \underset{p \to +\infty}{\longrightarrow} 0 p \in \mathbb{N} a_1 = \dots = a_n = 0 n n = 1 n \geq 2","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'trigonometry']"
79,show that the limits does not exist (multivariable),show that the limits does not exist (multivariable),,"So my professor give me this problem Show that the limit does not exist $$\lim_{(x,y) \to (0,0)} \frac {xy^3\cos x}{2x^2+y^6}$$ So what I ended up doing is approach $(0,0)$ along the $x$ -axis $$\lim_{x \to 0} \frac {0}{2x^2} = 0$$ and approach $(0,0)$ along the $y$ -axis $$\lim_{y \to 0} \frac {0}{y^6} = 0.$$ Then I approach the $(0,0)$ along $y = x$ axis $$\lim_{x \to 0} \frac {x^2\cos x}{2+x^4} = 0$$ And so I thought the limit does exist, but my professor insists that the limit does not exist. Did I do something wrong ? Thank you. *sorry i wrote the wrong problem","So my professor give me this problem Show that the limit does not exist So what I ended up doing is approach along the -axis and approach along the -axis Then I approach the along axis And so I thought the limit does exist, but my professor insists that the limit does not exist. Did I do something wrong ? Thank you. *sorry i wrote the wrong problem","\lim_{(x,y) \to (0,0)} \frac {xy^3\cos x}{2x^2+y^6} (0,0) x \lim_{x \to 0} \frac {0}{2x^2} = 0 (0,0) y \lim_{y \to 0} \frac {0}{y^6} = 0. (0,0) y = x \lim_{x \to 0} \frac {x^2\cos x}{2+x^4} = 0","['limits', 'multivariable-calculus']"
80,Existence of a limit of a function given that the derivative at the point exists,Existence of a limit of a function given that the derivative at the point exists,,"Suppose $f(x)$ is continuous in a neighbourhood of $a$ , and $f'(a)$ exists. Does the limit $$\lim_{x \rightarrow a} \frac{f(x) - f(2a -x)}{2(x-a)}$$ always exist?","Suppose is continuous in a neighbourhood of , and exists. Does the limit always exist?",f(x) a f'(a) \lim_{x \rightarrow a} \frac{f(x) - f(2a -x)}{2(x-a)},"['limits', 'derivatives']"
81,Why is this method wrong on calculating this multivariable limit?,Why is this method wrong on calculating this multivariable limit?,,"So, I was studying Apostol's book while studying on the site ""Brilliant"" methods of calculating multivariable limits... In particular, in $R^2$ we have polar coordinates to switch on and we have: $\lim_{{(x,y)}\to(0,0)}f(x,y) = L$ iff $\lim_{r\to0^+}f(r\cos(\theta),r\sin(\theta)) = L$ since the statement $0\lt\sqrt{x^2+y^2}\lt\delta$ can be translated into $0\lt r \lt \delta$ from the $\epsilon-\delta$ definition of the limit while $x = r\cos(\theta)$ and $y = r\sin(\theta)$ (so the limit exists iff the limit exists in polar coordinates and it's $\theta-independent$ ) (taken from Brilliant) But then Apostol came with the following function: $f(x,y) = \frac{xy^2}{x^2+y^4}$ if $x\neq 0$ and $f(0,y) = 0$ and things got messy in my mind because, if we switch to polar coordinates, it becomes $f(r\cos(\theta),r\sin(\theta)) = \frac{r\cos(\theta)\sin^2(\theta)}{\cos^2(\theta)+\sin^4(\theta)}$ if $r$ is different from $0$ and if we make $r\to0$ we'd have have $\lim_{r\to0^+}f(r\cos(\theta),r\sin(\theta)) = 0$ But, if you choose the curve $x = y^2$ , we have $f(y^2,y) = \frac{1}{2}$ and so if we approach the origin by that curve we'd have $\lim_{y\to0}f(y^2,y) = \frac{1}{2}$ and by such we'd have the limit approaching $2$ different values which would mean the limit actually doesn't exist So my doubt is about what is wrong about the procedure using polar coordinates instead of trying different curves, why the polar coordinate method didn't show me that the limit is ""angle dependent"" (and it doesn't exist in practice)? Did I make any mistakes in the procedure?","So, I was studying Apostol's book while studying on the site ""Brilliant"" methods of calculating multivariable limits... In particular, in we have polar coordinates to switch on and we have: iff since the statement can be translated into from the definition of the limit while and (so the limit exists iff the limit exists in polar coordinates and it's ) (taken from Brilliant) But then Apostol came with the following function: if and and things got messy in my mind because, if we switch to polar coordinates, it becomes if is different from and if we make we'd have have But, if you choose the curve , we have and so if we approach the origin by that curve we'd have and by such we'd have the limit approaching different values which would mean the limit actually doesn't exist So my doubt is about what is wrong about the procedure using polar coordinates instead of trying different curves, why the polar coordinate method didn't show me that the limit is ""angle dependent"" (and it doesn't exist in practice)? Did I make any mistakes in the procedure?","R^2 \lim_{{(x,y)}\to(0,0)}f(x,y) = L \lim_{r\to0^+}f(r\cos(\theta),r\sin(\theta)) = L 0\lt\sqrt{x^2+y^2}\lt\delta 0\lt r \lt \delta \epsilon-\delta x = r\cos(\theta) y = r\sin(\theta) \theta-independent f(x,y) = \frac{xy^2}{x^2+y^4} x\neq 0 f(0,y) = 0 f(r\cos(\theta),r\sin(\theta)) = \frac{r\cos(\theta)\sin^2(\theta)}{\cos^2(\theta)+\sin^4(\theta)} r 0 r\to0 \lim_{r\to0^+}f(r\cos(\theta),r\sin(\theta)) = 0 x = y^2 f(y^2,y) = \frac{1}{2} \lim_{y\to0}f(y^2,y) = \frac{1}{2} 2","['limits', 'multivariable-calculus', 'polar-coordinates']"
82,How do I evaluate t$\lim_{n\to\infty} \sum_{i=1}^n \left[\sqrt{1+ \frac{2i}{n}}\right]\frac{2}{n}$? (From MIT OCW 18.01 sc final Q7(a)),How do I evaluate t? (From MIT OCW 18.01 sc final Q7(a)),\lim_{n\to\infty} \sum_{i=1}^n \left[\sqrt{1+ \frac{2i}{n}}\right]\frac{2}{n},"This was one of the questions on the final for MIT's 18.01: $$\lim_{n\to\infty} \sum_{i=1}^n \left[\sqrt{1+ \frac{2i}{n}}\right]\frac{2}{n}$$ The answer converts it to an integral, but I'm not sure how they made that logical step. Is this using L'Hopital's rule somehow?","This was one of the questions on the final for MIT's 18.01: The answer converts it to an integral, but I'm not sure how they made that logical step. Is this using L'Hopital's rule somehow?",\lim_{n\to\infty} \sum_{i=1}^n \left[\sqrt{1+ \frac{2i}{n}}\right]\frac{2}{n},"['calculus', 'limits']"
83,$\alpha$ is unique if $f(x) \leq \alpha \leq g(x)$ for all $x$ and $\lim_{x\to a} ( g(x)-f(x)) = 0$,is unique if  for all  and,\alpha f(x) \leq \alpha \leq g(x) x \lim_{x\to a} ( g(x)-f(x)) = 0,"Let's say we have a function $f$ and another one as $g$ , both are functions of, say, $x$ . Let $\alpha$ be the number which lies between $f$ and $g$ for every $x$ , that is $$ ∀x ( f(x) \leq \alpha \leq g(x) )$$ It is a given condition that $$\lim_{x\to a} ( g(x)-f(x)) = 0$$ Now, I want to know what does it mean to say "" $\alpha$ is the only number in between $f$ and $g$ in the limiting process as $x$ goes to $a$ "". My understanding speaks like this: The given condition that difference between $g$ and $f$ reduces to zero as $x$ goes to $a$ rigorously means that we can make $g(x)$ as close to $f(x)$ as we desire, and since $\alpha$ is always going to lie between them, a stage would come when $\alpha$ will be the only number in between them. But the flaw in my understanding is that it violates the elementary statement ""Between any two numbers there lies infinitely many numbers, no matter how they close they are"". So, no matter how close we can make $g$ to $f$ there always gonna lie infinitely many numbers not just $\alpha$ .","Let's say we have a function and another one as , both are functions of, say, . Let be the number which lies between and for every , that is It is a given condition that Now, I want to know what does it mean to say "" is the only number in between and in the limiting process as goes to "". My understanding speaks like this: The given condition that difference between and reduces to zero as goes to rigorously means that we can make as close to as we desire, and since is always going to lie between them, a stage would come when will be the only number in between them. But the flaw in my understanding is that it violates the elementary statement ""Between any two numbers there lies infinitely many numbers, no matter how they close they are"". So, no matter how close we can make to there always gonna lie infinitely many numbers not just .","f g x \alpha f g x 
∀x ( f(x) \leq \alpha \leq g(x) ) \lim_{x\to a} ( g(x)-f(x)) = 0 \alpha f g x a g f x a g(x) f(x) \alpha \alpha g f \alpha","['real-analysis', 'calculus', 'limits', 'real-numbers']"
84,$\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n}$,,\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n},"How to calculate the limit below? $$\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n}$$ Since I used Riemann integration to work out that $$\lim_{n\to\infty}[\frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}]=1$$ , I've been trying to express $$\frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}=(1+\frac{C}{2^n}+o(\frac{1}{2^n})),\quad n\to+\infty$$ Can anyone render me some hints?","How to calculate the limit below? Since I used Riemann integration to work out that , I've been trying to express Can anyone render me some hints?","\lim_{n\to\infty}\{\frac{3}{n}\sum_{k=1}^n[1+8\sin^2(\frac{k\pi}{n})]^{-1}\}^{2^n} \lim_{n\to\infty}[\frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}]=1 \frac{3}{n}\sum_{k=1}^n(1+8\sin^2(\frac{k\pi}{n}))^{-1}=(1+\frac{C}{2^n}+o(\frac{1}{2^n})),\quad n\to+\infty","['real-analysis', 'limits', 'analysis']"
85,Evaluating the limit $\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt$,Evaluating the limit,\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt,"$$\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt$$ This is a compound question from me. I don't know how to begin evaluating this limit. My guess would be that I would have to find the value of this Riemann's integral and then plug the result into the limit. Is this the right direction to head? Which brings me to... I am also stuck trying to resolve the integral. I tried integrating by substitution, trying with both $u = t^2$ and $u = \sin(t^2)$ , but both have lead me to finding that $t$ or $dt$ popping back into the equation sooner or later and I'm not quite sure how to handle that. Any hints as to how I can integrate that function? Thank you.","This is a compound question from me. I don't know how to begin evaluating this limit. My guess would be that I would have to find the value of this Riemann's integral and then plug the result into the limit. Is this the right direction to head? Which brings me to... I am also stuck trying to resolve the integral. I tried integrating by substitution, trying with both and , but both have lead me to finding that or popping back into the equation sooner or later and I'm not quite sure how to handle that. Any hints as to how I can integrate that function? Thank you.",\lim_{x\to0}\frac{1}{x^3}\int_{0}^{x}\sin(\sin(t^2))dt u = t^2 u = \sin(t^2) t dt,"['real-analysis', 'calculus', 'limits', 'riemann-integration']"
86,Limit with criteria $\lim_{n \to \infty}n \cdot \left [ \frac1e \left (1+\frac{1}{n+1} \right )^{n+1}-1 \right ]$ [duplicate],Limit with criteria  [duplicate],\lim_{n \to \infty}n \cdot \left [ \frac1e \left (1+\frac{1}{n+1} \right )^{n+1}-1 \right ],"This question already has answers here : How do I find this limit: $\lim_{n\to\infty} \left[ n-{n\over e}\left(1+{1\over n}\right)^n \right]$? (8 answers) Closed 3 years ago . $$\lim_{n \to \infty}n \cdot \left [ \frac{\left (1+\frac{1}{n+1} \right )^{n+1}}{e}-1 \right ]$$ I was trying to calculate a limit that drove me to this case of Raabe-Duhamel's test, but I don't know how to finish it. Please give me a hint or a piece of advise. I cannot use any of the solution below, but they are clear and good. I'm trying to prove it using squeeze theorem like this: $$\lim_{n \to \infty}n \cdot \left [ \frac{\left (1+\frac{1}{n+1} \right )^{n+1}}{e}-1 \right ]=\frac{-1}{e} \cdot\lim_{n \to \infty}n \cdot \left [e- \left (1+\frac{1}{n+1} \right )^{n+1} \right ]$$ I found this: $$\frac{e}{2n+2}<e- \left (1+\frac{1}{n} \right )^{n}<\frac{e}{2n+1}$$ Is this true? How can I prove this? Thanks for the answers.","This question already has answers here : How do I find this limit: $\lim_{n\to\infty} \left[ n-{n\over e}\left(1+{1\over n}\right)^n \right]$? (8 answers) Closed 3 years ago . I was trying to calculate a limit that drove me to this case of Raabe-Duhamel's test, but I don't know how to finish it. Please give me a hint or a piece of advise. I cannot use any of the solution below, but they are clear and good. I'm trying to prove it using squeeze theorem like this: I found this: Is this true? How can I prove this? Thanks for the answers.",\lim_{n \to \infty}n \cdot \left [ \frac{\left (1+\frac{1}{n+1} \right )^{n+1}}{e}-1 \right ] \lim_{n \to \infty}n \cdot \left [ \frac{\left (1+\frac{1}{n+1} \right )^{n+1}}{e}-1 \right ]=\frac{-1}{e} \cdot\lim_{n \to \infty}n \cdot \left [e- \left (1+\frac{1}{n+1} \right )^{n+1} \right ] \frac{e}{2n+2}<e- \left (1+\frac{1}{n} \right )^{n}<\frac{e}{2n+1},['limits']
87,"Find $\lim_{(x,y)\rightarrow (0,0)}\frac{\sin (xy)}{x+y}$",Find,"\lim_{(x,y)\rightarrow (0,0)}\frac{\sin (xy)}{x+y}","Find $$\lim_{(x,y)\rightarrow (0,0)}\frac{\sin (xy)}{x+y}$$ exist or DNE. $f(x,y)$ along the lines $y=mx$ \begin{align} \lim_{(x,mx)\rightarrow (0,0)}\frac{\sin (mx^2)}{x+mx}&=\lim_{x\rightarrow 0}\left(\frac{\sin (mx^2)}{x}\frac{1}{1+m}\right)\\ &=0 \end{align} By applying L'Hospital's Rule, we can show this limit is $0$ except when $m=-1$ . But the answer says limit DNE. Maybe I have to choose different path. Then I think whyn't choose $y=mx^n$ and again find limit $0$ . I don't use polar or spherical coordinates because here is no $x^2+y^2$ terms. Eventually I can't use $\lim_{p\rightarrow a}f(g(p))=f(\lim_{p\rightarrow a}g(p))($ usage of continuiuty $)$ also. Is there another approach for this problem $?$","Find exist or DNE. along the lines By applying L'Hospital's Rule, we can show this limit is except when . But the answer says limit DNE. Maybe I have to choose different path. Then I think whyn't choose and again find limit . I don't use polar or spherical coordinates because here is no terms. Eventually I can't use usage of continuiuty also. Is there another approach for this problem","\lim_{(x,y)\rightarrow (0,0)}\frac{\sin (xy)}{x+y} f(x,y) y=mx \begin{align}
\lim_{(x,mx)\rightarrow (0,0)}\frac{\sin (mx^2)}{x+mx}&=\lim_{x\rightarrow 0}\left(\frac{\sin (mx^2)}{x}\frac{1}{1+m}\right)\\
&=0
\end{align} 0 m=-1 y=mx^n 0 x^2+y^2 \lim_{p\rightarrow a}f(g(p))=f(\lim_{p\rightarrow a}g(p))( ) ?","['limits', 'analysis', 'multivariable-calculus']"
88,Finding limit of $a_n = \frac{1}{n|\sin n|}$,Finding limit of,a_n = \frac{1}{n|\sin n|},"Let $a_n = \frac{1}{n|\sin n|}$ . Find $\lim_{n\to \infty} a_n$ if it exists. It's known that $b_n = \frac{1}{n\sin n}$ is divergent but what about $a_n = \frac{1}{n|\sin n|}$ ? I tried to show that $a_n$ converges to $0$ using definition but I am stuck on $\frac{1}{|\sin n|} \lt \epsilon$ . Also attempting to show $\sum_{n=1}^\infty a_n$ converges with different tests, like comparison test , was unsuccessful.","Let . Find if it exists. It's known that is divergent but what about ? I tried to show that converges to using definition but I am stuck on . Also attempting to show converges with different tests, like comparison test , was unsuccessful.",a_n = \frac{1}{n|\sin n|} \lim_{n\to \infty} a_n b_n = \frac{1}{n\sin n} a_n = \frac{1}{n|\sin n|} a_n 0 \frac{1}{|\sin n|} \lt \epsilon \sum_{n=1}^\infty a_n,"['sequences-and-series', 'limits']"
89,"Does $\lim_{\epsilon \to 0^+} \frac{\int_0^\epsilon f}{\epsilon^{1/q}} = 0$ hold for all $f\in L^p[0,1]$.",Does  hold for all .,"\lim_{\epsilon \to 0^+} \frac{\int_0^\epsilon f}{\epsilon^{1/q}} = 0 f\in L^p[0,1]","Fix $1 < p < \infty$ and choose $f\in L^p[0,1]$ . Let $q = \frac{p}{p-1}$ denote the Hölder conjugate of $p$ . I am trying to prove the following statement: $$\lim_{\epsilon \to 0^+} \frac{\int_0^\epsilon f}{\epsilon^{1/q}} = 0$$ $$\rule{10cm}{1pt}$$ My attempt: Hoping to apply L'Hôpital's Rule, I took derivatives of top and bottom $$\frac{q\cdot F'(\epsilon)}{\epsilon^{-1/p}}$$ where $F'(\epsilon) = \frac{d}{d\epsilon}\int_0^\epsilon f$ . I know that $F'(\epsilon) = f$ a.e. on $[0,1]$ and I also know that if $|f|$ grows at least as fast as $\epsilon^{-1/p}$ as $\epsilon \to 0^+$ , then $f \notin L^p[0,1]$ . But I'm having trouble using those facts to prove something like $$\limsup_{\epsilon \to 0^+}\frac{|F'(\epsilon)|}{\epsilon^{-1/p}} = 0$$ For example, is it possible that $|F'(\epsilon)| \geq \epsilon^{-1/p}$ on a small enough set that $F' \in L^p[0,1]$ ?","Fix and choose . Let denote the Hölder conjugate of . I am trying to prove the following statement: My attempt: Hoping to apply L'Hôpital's Rule, I took derivatives of top and bottom where . I know that a.e. on and I also know that if grows at least as fast as as , then . But I'm having trouble using those facts to prove something like For example, is it possible that on a small enough set that ?","1 < p < \infty f\in L^p[0,1] q = \frac{p}{p-1} p \lim_{\epsilon \to 0^+} \frac{\int_0^\epsilon f}{\epsilon^{1/q}} = 0 \rule{10cm}{1pt} \frac{q\cdot F'(\epsilon)}{\epsilon^{-1/p}} F'(\epsilon) = \frac{d}{d\epsilon}\int_0^\epsilon f F'(\epsilon) = f [0,1] |f| \epsilon^{-1/p} \epsilon \to 0^+ f \notin L^p[0,1] \limsup_{\epsilon \to 0^+}\frac{|F'(\epsilon)|}{\epsilon^{-1/p}} = 0 |F'(\epsilon)| \geq \epsilon^{-1/p} F' \in L^p[0,1]","['real-analysis', 'limits']"
90,How to evaluate $ \lim_{x \to 0} [\frac{\sin x \tan x}{x^2}] $where [] is GIF,How to evaluate where [] is GIF, \lim_{x \to 0} [\frac{\sin x \tan x}{x^2}] ,"$$ \lim_{x \to 0} \biggl[\frac{\sin x \tan x}{x^2}\biggl] $$ where [] is GIF. The challenge I'm facing is the fact that while $\frac{\sin x}{x}< 1, \frac{\tan x}{x} >  1$ . Now their product is becoming a bit undetermined as to will it be $>1$ or $< 1 $ . How do i solve it then ?? My first thought was to use the series expansion, which yields $\biggr[1+ \frac{x^2}{3}...\biggl]$ how can I be sure that the further negative terms that are coming in this infinite series will not overpower the $\frac{x^2}{3}$ term and make the whole value < 1","where [] is GIF. The challenge I'm facing is the fact that while . Now their product is becoming a bit undetermined as to will it be or . How do i solve it then ?? My first thought was to use the series expansion, which yields how can I be sure that the further negative terms that are coming in this infinite series will not overpower the term and make the whole value < 1"," \lim_{x \to 0} \biggl[\frac{\sin x \tan x}{x^2}\biggl]  \frac{\sin x}{x}< 1, \frac{\tan x}{x} >  1 >1 < 1  \biggr[1+ \frac{x^2}{3}...\biggl] \frac{x^2}{3}","['calculus', 'limits']"
91,Finding the limit: $\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n}$,Finding the limit:,\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n},Find the given limit $$\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n}$$ I'm able to find one part in denominator of this limit i.e. $\lim_{n\to \infty} (\pi ^{n} + e^{n})^{1/n} = \pi$ So there will be a $\pi$ in the denominator of the answer. How to find the rest part $?$,Find the given limit I'm able to find one part in denominator of this limit i.e. So there will be a in the denominator of the answer. How to find the rest part,\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n} \lim_{n\to \infty} (\pi ^{n} + e^{n})^{1/n} = \pi \pi ?,['limits']
92,How to use the derivative definition to prove the derivative of a straight horizontal line is zero,How to use the derivative definition to prove the derivative of a straight horizontal line is zero,,"If I have the function $f(x)=2$ then $f'(x)$ will obviously be equal to zero because at any x-value on the $f(x)$ function, the slope is zero. What I am trying to do is prove that $f'(x)=0$ using the derivative definition $f'(x)=\lim_{z\to x}\frac{f(z)-f(x)}{z-x}$ where $(x,f(x))$ will be the point where our tangent line connects to $f(x)$ and where $(z,f(z))$ is our arbitrary point that will get infinitely closer to $(x,f(x))$ . I keep getting an indeterminate answer and I can't find a way around this.","If I have the function then will obviously be equal to zero because at any x-value on the function, the slope is zero. What I am trying to do is prove that using the derivative definition where will be the point where our tangent line connects to and where is our arbitrary point that will get infinitely closer to . I keep getting an indeterminate answer and I can't find a way around this.","f(x)=2 f'(x) f(x) f'(x)=0 f'(x)=\lim_{z\to x}\frac{f(z)-f(x)}{z-x} (x,f(x)) f(x) (z,f(z)) (x,f(x))",['calculus']
93,"What is the difference between ""arbitrarily close"" and ""sufficiently close"" in term of limits?","What is the difference between ""arbitrarily close"" and ""sufficiently close"" in term of limits?",,"The definition of limit as always “the limit of $f(x)$ , as $x$ approaches $a$ , equals $L$ ” means we can   make the values of $f(x)$ arbitrarily close to $L$ by restricting x to   be sufficiently close to $a$ but not equal to $a$ . What exactly mean by phrases ""arbitrarily close"" for $f(x)$ and ""sufficiently close"" for $x$ ? Are they interchangeable ?","The definition of limit as always “the limit of , as approaches , equals ” means we can   make the values of arbitrarily close to by restricting x to   be sufficiently close to but not equal to . What exactly mean by phrases ""arbitrarily close"" for and ""sufficiently close"" for ? Are they interchangeable ?",f(x) x a L f(x) L a a f(x) x,"['calculus', 'limits', 'terminology']"
94,Resolving $\lim\limits_{x \to \infty} (x-{\sqrt x})$,Resolving,\lim\limits_{x \to \infty} (x-{\sqrt x}),"I'm relearning limits and I'm stuck at an exercise. I have to resolve the following limit $$\lim\limits_{x \to \infty} (x-{\sqrt x})$$ If I use $\infty$ instead of $x$ , it'll be $\infty - \infty$ and it gets undefined. I tried rewriting the square root to $x^{1/2}$ but then it remains undefined. How can I resolve this kind of problem?","I'm relearning limits and I'm stuck at an exercise. I have to resolve the following limit If I use instead of , it'll be and it gets undefined. I tried rewriting the square root to but then it remains undefined. How can I resolve this kind of problem?",\lim\limits_{x \to \infty} (x-{\sqrt x}) \infty x \infty - \infty x^{1/2},"['calculus', 'limits']"
95,Evaluate $\lim_{x \to 0} \frac{\cos (\sin x) - \cos x}{x^4}$ [duplicate],Evaluate  [duplicate],\lim_{x \to 0} \frac{\cos (\sin x) - \cos x}{x^4},"This question already has answers here : Calculating limit of function (3 answers) Closed 5 years ago . Evaluate $\displaystyle \lim_{x\to0} \frac{\cos (\sin x) - \cos x}{x^4}$ The answer stated is $\displaystyle {1 \over 6}$ . What I've tried: $$\displaystyle \lim_{x\to0} \frac{\cos (\sin x) - \cos x}{x^4}$$ $$=\displaystyle \lim_{x\to0} \frac{\cos (\sin x) -1+1- \cos x}{x^4}$$ $$=\displaystyle \lim_{x\to0} \frac{1- \cos x}{x^4} - \frac {1-\cos (\sin x)}{x^4}$$ $$=\displaystyle \lim_{x\to0} \frac{2 \sin^2(\frac {x}{2})}{x^4} - \frac {2 \sin^2(\frac {\sin x}{2})}{x^4}$$ $$=\displaystyle \lim_{x\to0} \left(\frac{\sin(\frac {x}{2})}{x} \right)^2. \left( \dfrac{1}{2x^2} \right) - \frac {2 \sin^2(\frac {\sin x}{2})}{x^4}$$ I'm not sure how I can evaluate the limit by proceeding this way. All help will be appreciated. P.S. I'd prefer not using L'Hôpital's rule, it can get really messy. EDIT : I should have mentioned that I would prefer if the solution does not use taylor series approximations (or any approximations) for that matter.","This question already has answers here : Calculating limit of function (3 answers) Closed 5 years ago . Evaluate The answer stated is . What I've tried: I'm not sure how I can evaluate the limit by proceeding this way. All help will be appreciated. P.S. I'd prefer not using L'Hôpital's rule, it can get really messy. EDIT : I should have mentioned that I would prefer if the solution does not use taylor series approximations (or any approximations) for that matter.",\displaystyle \lim_{x\to0} \frac{\cos (\sin x) - \cos x}{x^4} \displaystyle {1 \over 6} \displaystyle \lim_{x\to0} \frac{\cos (\sin x) - \cos x}{x^4} =\displaystyle \lim_{x\to0} \frac{\cos (\sin x) -1+1- \cos x}{x^4} =\displaystyle \lim_{x\to0} \frac{1- \cos x}{x^4} - \frac {1-\cos (\sin x)}{x^4} =\displaystyle \lim_{x\to0} \frac{2 \sin^2(\frac {x}{2})}{x^4} - \frac {2 \sin^2(\frac {\sin x}{2})}{x^4} =\displaystyle \lim_{x\to0} \left(\frac{\sin(\frac {x}{2})}{x} \right)^2. \left( \dfrac{1}{2x^2} \right) - \frac {2 \sin^2(\frac {\sin x}{2})}{x^4},"['calculus', 'limits', 'limits-without-lhopital']"
96,Evaluating $\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e + \frac{1}{2}ex}{x^2}$ without expansions in limits,Evaluating  without expansions in limits,\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e + \frac{1}{2}ex}{x^2},"Evaluate $\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e  + \frac{1}{2}ex}{x^2}$ One way that I can immediately think of is expanding each of the terms and solving like, $$(1+x)^{1/x} = e^{\log_e (1+x)^{1/x}} = e^{\frac{1}{x} (x-\frac{x^2}{2} -\frac{x^3}{3}+...)}$$ and then after complete expansion of each and every and substuting into back to limit and solving I get $\frac{11e}{24}$ as an answer. Now, this is a relatively long and complicated way to solve as you can see. I want to know if there is an easier way to solve this problem. Please help. Thank you!","Evaluate One way that I can immediately think of is expanding each of the terms and solving like, and then after complete expansion of each and every and substuting into back to limit and solving I get as an answer. Now, this is a relatively long and complicated way to solve as you can see. I want to know if there is an easier way to solve this problem. Please help. Thank you!",\lim\limits_{x \to 0} \frac{(1+x)^{1/x} - e  + \frac{1}{2}ex}{x^2} (1+x)^{1/x} = e^{\log_e (1+x)^{1/x}} = e^{\frac{1}{x} (x-\frac{x^2}{2} -\frac{x^3}{3}+...)} \frac{11e}{24},"['calculus', 'limits']"
97,square root n limit,square root n limit,,$$(x_{n})_{n\geq 2}\ \ x_{n}=\sqrt[n]{1+\sum_{k=2}^{n}(k-1)(k-1)!} $$ $$\lim_{n\rightarrow \infty }\frac{x_{n}}{n}=?$$ I'm trying to solve the sum I but I don't know how to rewrite it.Can you give me some hints? edit: The sum $\sum_{k=2}^{n}(k-1)(k-1)!$ should be $(n! - 1)$ so $x_{n}=\sqrt[n]{n!}$ .The limit would be $\lim_{n\rightarrow \infty } \sqrt[n]{\frac{n!}{n^{n}}}$ .If I use cauchy d'alembert criterion and make some simplifications I would get $e^{-1}$ (the right answer)My problem is that sum.How I obtain $n! - 1$ ?,I'm trying to solve the sum I but I don't know how to rewrite it.Can you give me some hints? edit: The sum should be so .The limit would be .If I use cauchy d'alembert criterion and make some simplifications I would get (the right answer)My problem is that sum.How I obtain ?,(x_{n})_{n\geq 2}\ \ x_{n}=\sqrt[n]{1+\sum_{k=2}^{n}(k-1)(k-1)!}  \lim_{n\rightarrow \infty }\frac{x_{n}}{n}=? \sum_{k=2}^{n}(k-1)(k-1)! (n! - 1) x_{n}=\sqrt[n]{n!} \lim_{n\rightarrow \infty } \sqrt[n]{\frac{n!}{n^{n}}} e^{-1} n! - 1,"['calculus', 'limits']"
98,Evaluate $\lim\limits_{n\to \infty} \left( \cos(1/n)-\sin(1/n) \right) ^n $?,Evaluate ?,\lim\limits_{n\to \infty} \left( \cos(1/n)-\sin(1/n) \right) ^n ,"How to calculate $\lim\limits_{n\to \infty} \left( \cos(1/n)-\sin(1/n) \right) ^n $ ? Since $\lim\limits_{n\to \infty} \frac {\cos(1/n)-\sin(1/n) }{1-1/n} = 1  $ , I guess that the limit above is $\frac{1}{e}$ , but since the form $(\to 1)^{\to \infty}$ is indeterminate, I don't know how to prove it formally. Thanks!","How to calculate ? Since , I guess that the limit above is , but since the form is indeterminate, I don't know how to prove it formally. Thanks!",\lim\limits_{n\to \infty} \left( \cos(1/n)-\sin(1/n) \right) ^n  \lim\limits_{n\to \infty} \frac {\cos(1/n)-\sin(1/n) }{1-1/n} = 1   \frac{1}{e} (\to 1)^{\to \infty},"['calculus', 'limits']"
99,Interchanging $\limsup$ and $\sup$,Interchanging  and,\limsup \sup,"Let $f_n: \mathcal{X} \to [0,1]$ be a sequence of functions and $\alpha \in (0,1)$ . I want to show that $$ \limsup_{n \to \infty} \sup_{x \in \mathcal{X}} f_n(x) \leq \alpha $$ implies $$ \sup_{x \in \mathcal{X}} \limsup_{n \to \infty} f_n(x) \leq \alpha $$ but my $\limsup$ 's are a little rusty. Any tips?",Let be a sequence of functions and . I want to show that implies but my 's are a little rusty. Any tips?,"f_n: \mathcal{X} \to [0,1] \alpha \in (0,1) 
\limsup_{n \to \infty} \sup_{x \in \mathcal{X}} f_n(x) \leq \alpha
 
\sup_{x \in \mathcal{X}} \limsup_{n \to \infty} f_n(x) \leq \alpha
 \limsup",['limits']
