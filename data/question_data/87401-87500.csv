,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Hahn-Banach extension of positive functional is positive,Hahn-Banach extension of positive functional is positive,,"Consider the following lemma from Takesaki's book ""Theory of operator algebra I"": Why is the sentence ""Any Hahn-Banach extension of a positive linear functional on a $C^*$ -subalgebra of $A$ is positive"" true? Attempt: Let $B\subseteq A$ a $C^*$ -algebra and $\omega: B \to \mathbb{C}$ positive. If I can show that $\|\omega\|= \omega(b)$ for some positive $b \in B$ , then a Hahn-Banach extension $\widetilde{\omega}: A \to \mathbb{C}$ satisfies $\|\widetilde{\omega}\| = \widetilde{\omega}(b)$ as well and thus the lemma implies the result. But is it true that the operator norm of a positive functional is attained at a positive element of the unit ball? Any help/comments are highly appreciated!","Consider the following lemma from Takesaki's book ""Theory of operator algebra I"": Why is the sentence ""Any Hahn-Banach extension of a positive linear functional on a -subalgebra of is positive"" true? Attempt: Let a -algebra and positive. If I can show that for some positive , then a Hahn-Banach extension satisfies as well and thus the lemma implies the result. But is it true that the operator norm of a positive functional is attained at a positive element of the unit ball? Any help/comments are highly appreciated!",C^* A B\subseteq A C^* \omega: B \to \mathbb{C} \|\omega\|= \omega(b) b \in B \widetilde{\omega}: A \to \mathbb{C} \|\widetilde{\omega}\| = \widetilde{\omega}(b),"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras', 'hahn-banach-theorem']"
1,"$\left|\int_0^1\frac d{dt}u(tx)\,dt\right|\le\int_0^1\sum_{i=1}^N|x_i|\left|\frac{\partial u(tx)}{\partial x_i}\right|dt$ for $u\in C^1_c(\Bbb{R}^N)$",for,"\left|\int_0^1\frac d{dt}u(tx)\,dt\right|\le\int_0^1\sum_{i=1}^N|x_i|\left|\frac{\partial u(tx)}{\partial x_i}\right|dt u\in C^1_c(\Bbb{R}^N)","It’s my first question so excuse me if it is probably not very well written. Reading the proof of Morrey's inequality (Theorem 9.12 in "" Functional  Analysis,  Sobolev  Spaces  and  Partial  Differential  Equations "" by H. Brezis) I got stuck at the following inequality: $$|u(x)-u(0)|=\left|\int_{0}^{1} \frac{d}{dt}u(tx)\,dt \right|\leq \int_{0}^{1}\sum_{i=1}^{N}|x_{i}|\left| \frac{\partial u (tx)}{\partial x_{i}}\right| dt$$ with $x \in \mathbb{R}^{N} $ and $u \in C^{1}_{c}(\mathbb{R}^{N})$ . I'm new to advanced math, so can someone give me some hints about it? I apologize if it’s something trivial. Thank a lot for your kindness!  :)","It’s my first question so excuse me if it is probably not very well written. Reading the proof of Morrey's inequality (Theorem 9.12 in "" Functional  Analysis,  Sobolev  Spaces  and  Partial  Differential  Equations "" by H. Brezis) I got stuck at the following inequality: with and . I'm new to advanced math, so can someone give me some hints about it? I apologize if it’s something trivial. Thank a lot for your kindness!  :)","|u(x)-u(0)|=\left|\int_{0}^{1} \frac{d}{dt}u(tx)\,dt \right|\leq \int_{0}^{1}\sum_{i=1}^{N}|x_{i}|\left| \frac{\partial u (tx)}{\partial x_{i}}\right| dt x \in \mathbb{R}^{N}  u \in C^{1}_{c}(\mathbb{R}^{N})","['real-analysis', 'integration', 'functional-analysis', 'inequality', 'partial-derivative']"
2,Inverse Mapping Theorem implies Open Mapping Theorem,Inverse Mapping Theorem implies Open Mapping Theorem,,"I need to assume that the Inverse Mapping Theorem is true and deduce from it the Open Mapping Theorem . It is immediate to show that the OMP implies IMP. The converse however seems harder. This is since somehow we should use IMP on a bounded linear function $T$ which we should assume is surjective, but not injective. (If it is injective then we can easily see that OMP follows.) For concreteness let $T: X \to Y$ be a surjective continuous linear map between Banach spaces. To actually use the statement, I suppose we should restrict $X$ to some set $M$ such that $T$ there is a bijection. Hence by the IMP, $T$ is indeed open. Other than that I don't see how can we show it is still open in the complement of $M$ . Can someone help me prove this implication?","I need to assume that the Inverse Mapping Theorem is true and deduce from it the Open Mapping Theorem . It is immediate to show that the OMP implies IMP. The converse however seems harder. This is since somehow we should use IMP on a bounded linear function which we should assume is surjective, but not injective. (If it is injective then we can easily see that OMP follows.) For concreteness let be a surjective continuous linear map between Banach spaces. To actually use the statement, I suppose we should restrict to some set such that there is a bijection. Hence by the IMP, is indeed open. Other than that I don't see how can we show it is still open in the complement of . Can someone help me prove this implication?",T T: X \to Y X M T T M,['functional-analysis']
3,The cluster point set of $\{\frac{1}{n}\sum_{k=0}^{n-1} \delta_{T^kx}\}$ is connected,The cluster point set of  is connected,\{\frac{1}{n}\sum_{k=0}^{n-1} \delta_{T^kx}\},"Question: Let $X$ be a compact metric space and $T:X\to X$ is a continuous map. Arbitrarily fixed $x\in X$ , let $\delta_{T^kx}$ denote the Dirac measure mass at $T^kx$ . Prove The cluster  set of the sequence $\{\frac{1}{n}\sum_{K=0}^{n-1} \delta_{T^kx} \in C(X)^*:n\in \Bbb{N}_{+}\}$ is connected, for the weak-star topology. My observation: Denote its cluster set by $E$ . By Banach-Alaogu theorem, $E$ is a nonempty compact set, and every measure in $E$ is $T$ -invariant. But it seems not necessarily being convex. To prove the connection. Suppose $H: E\to \{0,1\}$ be a continuous map, it enough to prove $H$ is constant. But I don’t know how to make $H$ be specific. Another observation is that every nonempty open set of $w^*$ -topology is quit big, by definition which contains an finite codimensional subspace. I also consider some simple examples. Let $X=\mathbb{T}$ , with rotation transform, in this case $E$ contains one element-the Lebesgue measure. If $X=[0,1]$ , $Tx=x^2$ , $E=\{\delta_0\}$ when $x\neq 1$ , and $E=\{\delta_1\}$ otherwise. Unfortunately such exampleS don’t give me some useful information because $\#E=1$ .","Question: Let be a compact metric space and is a continuous map. Arbitrarily fixed , let denote the Dirac measure mass at . Prove The cluster  set of the sequence is connected, for the weak-star topology. My observation: Denote its cluster set by . By Banach-Alaogu theorem, is a nonempty compact set, and every measure in is -invariant. But it seems not necessarily being convex. To prove the connection. Suppose be a continuous map, it enough to prove is constant. But I don’t know how to make be specific. Another observation is that every nonempty open set of -topology is quit big, by definition which contains an finite codimensional subspace. I also consider some simple examples. Let , with rotation transform, in this case contains one element-the Lebesgue measure. If , , when , and otherwise. Unfortunately such exampleS don’t give me some useful information because .","X T:X\to X x\in X \delta_{T^kx} T^kx \{\frac{1}{n}\sum_{K=0}^{n-1} \delta_{T^kx} \in C(X)^*:n\in \Bbb{N}_{+}\} E E E T H: E\to \{0,1\} H H w^* X=\mathbb{T} E X=[0,1] Tx=x^2 E=\{\delta_0\} x\neq 1 E=\{\delta_1\} \#E=1","['functional-analysis', 'measure-theory', 'dynamical-systems', 'weak-topology']"
4,Convolution of two $L^1$ functions,Convolution of two  functions,L^1,"Let $f,g\in L^1(\mathbb{R};\mathbb{R}).$ Define the convolution $f*g:\mathbb{R} \rightarrow \mathbb{R},$ by $(f*g)(x)=\int\limits_{y\in \mathbb{R}}f(x-y)g(y)dy.$ Note that Fubini's theorem and translation invariance of Lebesgue measure implies that \begin{eqnarray} \int\limits_{R}\int\limits_{R} |f(x-y)g(y)|dydx = ||f||_{L^1(\mathbb{R})}||g||_{L^1(\mathbb{R})}. \end{eqnarray} Now, again invoking Fubini's theorem we get, $(f*g)(x)=\int\limits_{y\in \mathbb{R}}f(x-y)g(y)dy < \infty$ for a.e. $x\in \mathbb{R}.$ Furthermore, $f*g \in L^1(\mathbb{R}).$ Question: Do we have $|(f*g)(x)|< \infty $ for all $x\in \mathbb{R}?$ If yes, how to prove it, if not, what are the  counter examples?","Let Define the convolution by Note that Fubini's theorem and translation invariance of Lebesgue measure implies that Now, again invoking Fubini's theorem we get, for a.e. Furthermore, Question: Do we have for all If yes, how to prove it, if not, what are the  counter examples?","f,g\in L^1(\mathbb{R};\mathbb{R}). f*g:\mathbb{R} \rightarrow \mathbb{R}, (f*g)(x)=\int\limits_{y\in \mathbb{R}}f(x-y)g(y)dy. \begin{eqnarray}
\int\limits_{R}\int\limits_{R} |f(x-y)g(y)|dydx = ||f||_{L^1(\mathbb{R})}||g||_{L^1(\mathbb{R})}.
\end{eqnarray} (f*g)(x)=\int\limits_{y\in \mathbb{R}}f(x-y)g(y)dy < \infty x\in \mathbb{R}. f*g \in L^1(\mathbb{R}). |(f*g)(x)|< \infty  x\in \mathbb{R}?","['functional-analysis', 'analysis', 'measure-theory', 'convolution']"
5,Motivation of the Proof of the Hille-Yosida Theorem,Motivation of the Proof of the Hille-Yosida Theorem,,"Let $X$ be a Banach space and $A$ be a linear map from a subspace of $X$ to $X$ . The Hille-Yosida theorem gives a necessary and sufficient condition for $A$ to be an infinitesimal generator of a semigroup of class $C_0$ . The precise statement of the theorem is given in the following form. $A$ generates a semigroup of class $C_0$ , say $\left\{ S(t) \right\}_{t\geq0}$ such that $\Vert S(t) \Vert \leq Me^{\omega t}$ with $M>0$ and $\omega\in\mathbb{R}$ , if and only if $A$ is closed and $D(A)$ , the domain of $A$ , is dense in $X$ , every real $\lambda>\omega$ belongs to the resolvent set of $A$ and for such $\lambda$ and for all positive integers $n$ , $$\Vert (\lambda I - A)^{-n} \Vert \leq \frac{M}{(\lambda-\omega)^n}.$$ To simplify unnecessary complications, let us assume $\omega=0$ ; there is no loss of generality in assuming this. Moreover, let us denote the map $(\lambda I-A)^{-1}$ simply by $R_{\lambda}$ when $\lambda$ is in the resolvent set of $A$ . The only if part is easy to check. For the if part, we first construct a family of semigroups, one for each $\lambda>\omega=0$ , as follows: Let $A_{\lambda}:=-\lambda I + \lambda^2 R_{\lambda}$ and consider $$S_{\lambda}(t):=e^{tA_{\lambda}}=e^{t(-\lambda I + \lambda^2 R_{\lambda})}=e^{-\lambda t}\sum_{k=0}^{\infty} \frac{\lambda^{2k}t^k}{k!}R_{\lambda}^{k},\quad\text{for each } t\geq0.$$ It can be checked that $\left\{ S_{\lambda}(t) \right\}_{t\geq0}$ is a semigroup of class $C_0$ and satisfies the uniform bound $\Vert S_{\lambda}(t) \Vert \leq M$ , by using condition 2 from the statement of the theorem. It is then proved that for each $u\in D(A)$ and $t\geq0$ , the limit $$\lim_{\lambda\to\infty} S_{\lambda}(t)u$$ exists. Subsequently, it is proved that the limit actually exists for all $u\in X$ , and we denote this limit by $S(t)u$ . After checking subtle convergence and continuity issues, we can show that $\left\{ S(t) \right\}_{t\geq0}$ is a semigroup of class $C_0$ and that $\Vert S(t) \Vert \leq M$ holds. Finally, we show that the infinitesimal generator of this semigroup is exactly $A$ , completing the proof. My question is about how one can come up with the semigroups $\left\{ S_{\lambda}(t) \right\}_{t\geq0}$ in the above proof. What is the motivation for introducing them? I can see that if $\left\{T(t)\right\}_{t\geq0}$ is a semigroup, having $A$ as its infinitesimal generator, we must have $$T(t)u-S_{\lambda}(t)u=\int_{0}^{t} \frac{d}{ds}[S_{\lambda}(t-s)T(s)u]\,ds=\int_{0}^{t} -S_{\lambda}(t-s)T(s)(A_{\lambda}u-Au)\,ds$$ where $u\in D(A)$ and $t\geq0$ . Letting $\lambda\to\infty$ above implies that $T(t)u$ must be the limit of $S_{\lambda}(t)u$ , so we see that the semigroup $\left\{T(t)\right\}_{t\geq0}$ is actually unique and that the family of semigroups $\left\{ S_{\lambda}(t) \right\}_{t\geq0}$ , indexed by $\lambda$ , approximates the semigroup $\left\{T(t)\right\}_{t\geq0}$ as $\lambda$ approaches $\infty$ . The argument is very clear but I can't get the idea behind the construction of $\left\{ S_{\lambda}(t) \right\}_{t\geq0}$ . Can someone please explain this, with concrete examples if possible?","Let be a Banach space and be a linear map from a subspace of to . The Hille-Yosida theorem gives a necessary and sufficient condition for to be an infinitesimal generator of a semigroup of class . The precise statement of the theorem is given in the following form. generates a semigroup of class , say such that with and , if and only if is closed and , the domain of , is dense in , every real belongs to the resolvent set of and for such and for all positive integers , To simplify unnecessary complications, let us assume ; there is no loss of generality in assuming this. Moreover, let us denote the map simply by when is in the resolvent set of . The only if part is easy to check. For the if part, we first construct a family of semigroups, one for each , as follows: Let and consider It can be checked that is a semigroup of class and satisfies the uniform bound , by using condition 2 from the statement of the theorem. It is then proved that for each and , the limit exists. Subsequently, it is proved that the limit actually exists for all , and we denote this limit by . After checking subtle convergence and continuity issues, we can show that is a semigroup of class and that holds. Finally, we show that the infinitesimal generator of this semigroup is exactly , completing the proof. My question is about how one can come up with the semigroups in the above proof. What is the motivation for introducing them? I can see that if is a semigroup, having as its infinitesimal generator, we must have where and . Letting above implies that must be the limit of , so we see that the semigroup is actually unique and that the family of semigroups , indexed by , approximates the semigroup as approaches . The argument is very clear but I can't get the idea behind the construction of . Can someone please explain this, with concrete examples if possible?","X A X X A C_0 A C_0 \left\{ S(t) \right\}_{t\geq0} \Vert S(t) \Vert \leq Me^{\omega t} M>0 \omega\in\mathbb{R} A D(A) A X \lambda>\omega A \lambda n \Vert (\lambda I - A)^{-n} \Vert \leq \frac{M}{(\lambda-\omega)^n}. \omega=0 (\lambda I-A)^{-1} R_{\lambda} \lambda A \lambda>\omega=0 A_{\lambda}:=-\lambda I + \lambda^2 R_{\lambda} S_{\lambda}(t):=e^{tA_{\lambda}}=e^{t(-\lambda I + \lambda^2 R_{\lambda})}=e^{-\lambda t}\sum_{k=0}^{\infty} \frac{\lambda^{2k}t^k}{k!}R_{\lambda}^{k},\quad\text{for each } t\geq0. \left\{ S_{\lambda}(t) \right\}_{t\geq0} C_0 \Vert S_{\lambda}(t) \Vert \leq M u\in D(A) t\geq0 \lim_{\lambda\to\infty} S_{\lambda}(t)u u\in X S(t)u \left\{ S(t) \right\}_{t\geq0} C_0 \Vert S(t) \Vert \leq M A \left\{ S_{\lambda}(t) \right\}_{t\geq0} \left\{T(t)\right\}_{t\geq0} A T(t)u-S_{\lambda}(t)u=\int_{0}^{t} \frac{d}{ds}[S_{\lambda}(t-s)T(s)u]\,ds=\int_{0}^{t} -S_{\lambda}(t-s)T(s)(A_{\lambda}u-Au)\,ds u\in D(A) t\geq0 \lambda\to\infty T(t)u S_{\lambda}(t)u \left\{T(t)\right\}_{t\geq0} \left\{ S_{\lambda}(t) \right\}_{t\geq0} \lambda \left\{T(t)\right\}_{t\geq0} \lambda \infty \left\{ S_{\lambda}(t) \right\}_{t\geq0}","['functional-analysis', 'ordinary-differential-equations', 'spectral-theory', 'semigroup-of-operators', 'parabolic-pde']"
6,Fubini's theorem on locally compact Hausdorff spaces without measure theory,Fubini's theorem on locally compact Hausdorff spaces without measure theory,,"Suppose that $X$ is a locally compact Hausdorff space. For a Radon measure $\mu$ on $X$ , let $I_{\mu}\colon C_{c}(X)\to\mathbb{C}$ be the positive linear functional defined by $I_{\mu}(f):=\int_{X}f \ \text{d}\mu$ . The Riesz representation theorem imples that the assignment $\mu\mapsto I_{\mu}$ implements a one-to-one correspondence between (positive) Radon measures on $X$ and positive linear functionals on $C_{c}(X)$ . So one could define an integral on $X$ as a positive linear functional $I\colon C_{c}(X)\to\mathbb{C}$ . This definition does not rely on measure theory. I was wondering whether we could prove Fubini's theorem in this setting, i.e. without refering to measure theory. More precisely, does anyone know a proof or reference of the following statement without measure theory? Let $I$ and $J$ be positive linear functionals (i.e. integrals) on locally compact Hausdorff spaces $X$ and $Y$ , respectively. For $f\in C_{c}(X\times Y)$ and $y\in Y$ we define $f^{y}\colon X\to\mathbb{C}$ via $f^{y}(x):=f(x,y)$ . For $x\in X$ we define $f_{x}\colon Y\to\mathbb{C}$ similarly. The functions $x\mapsto J(f_{x})$ and $y\mapsto I(f^{y})$ are compactly supported and $$I(x\mapsto J(f_{x}))=J(y\mapsto I(f^{y})).$$","Suppose that is a locally compact Hausdorff space. For a Radon measure on , let be the positive linear functional defined by . The Riesz representation theorem imples that the assignment implements a one-to-one correspondence between (positive) Radon measures on and positive linear functionals on . So one could define an integral on as a positive linear functional . This definition does not rely on measure theory. I was wondering whether we could prove Fubini's theorem in this setting, i.e. without refering to measure theory. More precisely, does anyone know a proof or reference of the following statement without measure theory? Let and be positive linear functionals (i.e. integrals) on locally compact Hausdorff spaces and , respectively. For and we define via . For we define similarly. The functions and are compactly supported and","X \mu X I_{\mu}\colon C_{c}(X)\to\mathbb{C} I_{\mu}(f):=\int_{X}f \ \text{d}\mu \mu\mapsto I_{\mu} X C_{c}(X) X I\colon C_{c}(X)\to\mathbb{C} I J X Y f\in C_{c}(X\times Y) y\in Y f^{y}\colon X\to\mathbb{C} f^{y}(x):=f(x,y) x\in X f_{x}\colon Y\to\mathbb{C} x\mapsto J(f_{x}) y\mapsto I(f^{y}) I(x\mapsto J(f_{x}))=J(y\mapsto I(f^{y})).","['real-analysis', 'functional-analysis', 'measure-theory', 'geometric-measure-theory', 'fubini-tonelli-theorems']"
7,Given a real sequence $\{ c_n \}$ does there exist a smooth function g such that $c_n = \int_0^1 t^n g(t) dt$ for all $n \in \mathbb{N}$,Given a real sequence  does there exist a smooth function g such that  for all,\{ c_n \} c_n = \int_0^1 t^n g(t) dt n \in \mathbb{N},"Are either of the following 2 claims correct? Let $\{ c_n \}_{n \in \mathbb{N}}$ be a real sequence. Suppose that there exists an $N \in \mathbb{N}$ such that for all $n > N$ we have $c_n = 0$ . There exists $f \in C^{\infty}(\mathbb{R})$ such that $f(t) = f(2\pi + t)$ for all $t \in \mathbb{R}$ and \begin{align} c_n = \int_{0}^{2\pi} t^n f(t) \ dt \qquad \text{for all } n \in \mathbb{N} \end{align} There exists $g \in C^{\infty}(\mathbb{R})$ such that $\text{support}(g) = [0,1]$ and \begin{align} c_n = \int_{0}^{1} t^n g(t) \ dt \qquad \text{for all } n \in \mathbb{N} \end{align} Any advice or ideas on how to prove/disprove the claims will be greatly appreciated. If this result exists already, then a reference would be great. EDIT: AN IDEA FOR PART 2 Let \begin{align} g(t) = \sum_{m=0}^{\infty} a_m t^m \end{align} on $[0,1]$ and $g(t) = 0$ elsewhere, then \begin{align} \int_{0}^1 t^n g(t) dt &= \int_0^1 t^n \sum_{m=0}^{\infty} a_m t^m dt \\ &= \sum_{m=0}^{\infty}a_m\int_0^1 t^{n+m} dt \\ &= \sum_{m=0}^{\infty}\frac{a_m}{n+m+1} \\ &= \sum_{m=0}^{\infty} b_{nm}a_m \end{align} where $b_{nm} = 1/(n+m+1)$ . Now we define the operator $B : \ell^2 \to \ell^2$ on the Hilbert space of summable sequences $\ell^2$ by \begin{align} B(a)_n = \sum_{m=0}^{\infty} b_{nm} a_m. \end{align} If $B$ is surjective, then there exists an $a \in \ell^2$ such that $B(a) = c$ . But is $B$ surjective? I think a similar argument may work for part 1.","Are either of the following 2 claims correct? Let be a real sequence. Suppose that there exists an such that for all we have . There exists such that for all and There exists such that and Any advice or ideas on how to prove/disprove the claims will be greatly appreciated. If this result exists already, then a reference would be great. EDIT: AN IDEA FOR PART 2 Let on and elsewhere, then where . Now we define the operator on the Hilbert space of summable sequences by If is surjective, then there exists an such that . But is surjective? I think a similar argument may work for part 1.","\{ c_n \}_{n \in \mathbb{N}} N \in \mathbb{N} n > N c_n = 0 f \in C^{\infty}(\mathbb{R}) f(t) = f(2\pi + t) t \in \mathbb{R} \begin{align}
c_n = \int_{0}^{2\pi} t^n f(t) \ dt \qquad \text{for all } n \in \mathbb{N}
\end{align} g \in C^{\infty}(\mathbb{R}) \text{support}(g) = [0,1] \begin{align}
c_n = \int_{0}^{1} t^n g(t) \ dt \qquad \text{for all } n \in \mathbb{N}
\end{align} \begin{align}
g(t) = \sum_{m=0}^{\infty} a_m t^m
\end{align} [0,1] g(t) = 0 \begin{align}
\int_{0}^1 t^n g(t) dt &= \int_0^1 t^n \sum_{m=0}^{\infty} a_m t^m dt \\
&= \sum_{m=0}^{\infty}a_m\int_0^1 t^{n+m} dt \\
&= \sum_{m=0}^{\infty}\frac{a_m}{n+m+1} \\
&= \sum_{m=0}^{\infty} b_{nm}a_m
\end{align} b_{nm} = 1/(n+m+1) B : \ell^2 \to \ell^2 \ell^2 \begin{align}
B(a)_n = \sum_{m=0}^{\infty} b_{nm} a_m.
\end{align} B a \in \ell^2 B(a) = c B","['real-analysis', 'integration', 'functional-analysis']"
8,Approximation of absolute value function using polynomial,Approximation of absolute value function using polynomial,,"By Stone-Weierstrass theorem, the set of polynomial is dense in $C[a,b]$ , I am wondering what is the sequence of polynomial which can approximate absolute value function $|x|$ ? I know using $\sqrt{x^{2}+1/n}$ can approximate it but it is not a polynomial.","By Stone-Weierstrass theorem, the set of polynomial is dense in , I am wondering what is the sequence of polynomial which can approximate absolute value function ? I know using can approximate it but it is not a polynomial.","C[a,b] |x| \sqrt{x^{2}+1/n}","['real-analysis', 'functional-analysis']"
9,Question on a proof involving linear algebra,Question on a proof involving linear algebra,,"I've encountered the following proof, but I'm stuck at the last step. Let $X \subset \mathbb{R}^s$ be a vector space. Let $p(x): X \to \mathbb{R}$ be a linear transformation such that $p(x)$ must be positive if every element of $x \in X$ is positive. Create $$M = \{ (-p(x), x); x \in X \}$$ Then $M$ is a vector space given the linearity of $p(x)$ . In fact, $M$ cannot consist entirely of positive elements, so $M$ is a hyperplane that only intersects the positive orthant of $\mathbb{R}_+^{s+1}$ at the point $0$ . I understand everything above, but at the end, it says: We can then create a linear function $F : \mathbb{R}^{s+1} \to \mathbb{R}$ such that $F(-p,x) = 0$ for $(-p,x) \in M$ , and $F(-p,x) > 0$ for $(-p,x) \in \mathbb{R}_+^{s+1}$ except the origin. I don't understand how this follows. How can you be sure that you can create such a function? Is there a theorem that I'm missing?","I've encountered the following proof, but I'm stuck at the last step. Let be a vector space. Let be a linear transformation such that must be positive if every element of is positive. Create Then is a vector space given the linearity of . In fact, cannot consist entirely of positive elements, so is a hyperplane that only intersects the positive orthant of at the point . I understand everything above, but at the end, it says: We can then create a linear function such that for , and for except the origin. I don't understand how this follows. How can you be sure that you can create such a function? Is there a theorem that I'm missing?","X \subset \mathbb{R}^s p(x): X \to \mathbb{R} p(x) x \in X M = \{ (-p(x), x); x \in X \} M p(x) M M \mathbb{R}_+^{s+1} 0 F : \mathbb{R}^{s+1} \to \mathbb{R} F(-p,x) = 0 (-p,x) \in M F(-p,x) > 0 (-p,x) \in \mathbb{R}_+^{s+1}","['linear-algebra', 'functional-analysis']"
10,Weak convergence of the vector norm a vector field?,Weak convergence of the vector norm a vector field?,,"Suppose $\Omega\subset\mathbb{R}^n$ and $\mathbf{v}^k:\Omega\rightarrow \mathbb{R}^m$ is a sequence of vector fields on $\Omega$ that converges weakly in $L^p(\Omega,\mathbb{R}^m)$ to $\mathbf{v}$ . Does the vector (finite-dimensional) norm, i.e. $\left\lvert\mathbf{v}^k\right\rvert:\Omega\rightarrow\mathbb{R}$ converge weakly in $L^p(\Omega)$ to $\left\lvert\mathbf{v}\right\rvert$ ?","Suppose and is a sequence of vector fields on that converges weakly in to . Does the vector (finite-dimensional) norm, i.e. converge weakly in to ?","\Omega\subset\mathbb{R}^n \mathbf{v}^k:\Omega\rightarrow \mathbb{R}^m \Omega L^p(\Omega,\mathbb{R}^m) \mathbf{v} \left\lvert\mathbf{v}^k\right\rvert:\Omega\rightarrow\mathbb{R} L^p(\Omega) \left\lvert\mathbf{v}\right\rvert","['real-analysis', 'functional-analysis', 'lp-spaces', 'weak-convergence']"
11,"Show that $T: L^2([0, \infty )) \to C_0([0,\infty))$ is compact operator.",Show that  is compact operator.,"T: L^2([0, \infty )) \to C_0([0,\infty))","Let $C_0 \left( [0,\infty) \right)$ be the set of continuous functions on $[0,\infty)$ vanishing at $\infty$ , which is Banach space with $\lVert f \rVert_\infty = \underset{t \in [0,\infty)}{\sup} |f(t)|$ . Define $T \in B\left(L^2([0,\infty)), C_0 ([0,\infty)) \right)$ by $$Tf(t) = \frac{1}{1+t} \int_0^t f(s) ds.$$ Show that $T$ is a compact operator. Hint: To show that $TB_{L^2 [0,\infty)}$ is totally bounded, take sufficiently large $R >0$ such that $\underset{t \ge R}{\sup} |Tf(t)|$ is uniformly small for $f \in B_{L^2[0,\infty)}$ , and then apply the Ascoli-Arzela theorem to the restriction of $TB_{L^2[0,\infty)}$ to $[0,R]$ . I do not know how to apply this hint. Edited: I have seen some similar questions in the web, but all of them was on closed intervals. In this case the interval is not bounded, so at first -as I know- I have to prove that $T$ is bounded, which is not realy clear when the interval is not bounded. And After that I need to prove the compactness of the operator, by definition or by theorems, Could you please show me steps (hints) that i can follow. My proof till now: First let's show the boundedness of $T$ . $|Tf(t)| \le \frac{1}{1+t} \int_0^t f(s)ds \le \|f\|_2 \frac{t}{1+t}$ . So, $\|T\| \le 1$ Is is OK?","Let be the set of continuous functions on vanishing at , which is Banach space with . Define by Show that is a compact operator. Hint: To show that is totally bounded, take sufficiently large such that is uniformly small for , and then apply the Ascoli-Arzela theorem to the restriction of to . I do not know how to apply this hint. Edited: I have seen some similar questions in the web, but all of them was on closed intervals. In this case the interval is not bounded, so at first -as I know- I have to prove that is bounded, which is not realy clear when the interval is not bounded. And After that I need to prove the compactness of the operator, by definition or by theorems, Could you please show me steps (hints) that i can follow. My proof till now: First let's show the boundedness of . . So, Is is OK?","C_0 \left( [0,\infty) \right) [0,\infty) \infty \lVert f \rVert_\infty = \underset{t \in [0,\infty)}{\sup} |f(t)| T \in B\left(L^2([0,\infty)), C_0 ([0,\infty)) \right) Tf(t) = \frac{1}{1+t} \int_0^t f(s) ds. T TB_{L^2 [0,\infty)} R >0 \underset{t \ge R}{\sup} |Tf(t)| f \in B_{L^2[0,\infty)} TB_{L^2[0,\infty)} [0,R] T T |Tf(t)| \le \frac{1}{1+t} \int_0^t f(s)ds \le \|f\|_2 \frac{t}{1+t} \|T\| \le 1","['functional-analysis', 'compact-operators']"
12,Is Donald Cohn's second edition of Measure Theory good? [closed],Is Donald Cohn's second edition of Measure Theory good? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 3 years ago . Improve this question I read (most of) Baby Rudin, and now i am interested in learning more stuff about real analysis, in particular measure theory and functional analysis. Is ""Measure Theory: Second Edition"" by Donald L. Cohn a good introduction book in these subjects? (good = comprehensive, has a lot of medium/hard practice problems and more importantly, counterexamples). If not, are there any companion books/notes i can use while reading it?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 3 years ago . Improve this question I read (most of) Baby Rudin, and now i am interested in learning more stuff about real analysis, in particular measure theory and functional analysis. Is ""Measure Theory: Second Edition"" by Donald L. Cohn a good introduction book in these subjects? (good = comprehensive, has a lot of medium/hard practice problems and more importantly, counterexamples). If not, are there any companion books/notes i can use while reading it?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'book-recommendation']"
13,Infinitely Many Disjoint Balls Contained In Unit Ball,Infinitely Many Disjoint Balls Contained In Unit Ball,,"I am trying to solve a portion Problem 16 of Chapter 2 from Methods of Modern Mathematical Physics by Simon and Reed. The task is to show that the unit ball in an infinite dimensional Hilbert space contains infinitely many disjoint balls of radius $\sqrt{2}/4$ . My approach is shown below. By Theorem 2.5, I know that every Hilbert space contains an orthonormal basis $\{a_n\}_{n = 1}^{\infty}$ . I define the sequence of balls $\{B_n\}_{n=1}^{\infty}$ such that $$B_n = \{x\ :\ \|x - a_n/2\| < \sqrt{2}/4\}.$$ If $a \in B_n$ , we observe that $$\|a\| \leq \|a - a_n/2\| + \|a_n/2\| < \sqrt{2}/4 + 1/2 < 1.$$ Thus, $B_n$ is contained in the unit ball. For $m \neq n$ , we can observe that $$\|a_m/2 - a_n/2\| \leq \|x - a_m/2\| + \|x - a_n/2\| < \sqrt{2}/4 + \sqrt{2}/4 = \sqrt{2}/2.$$ However, this last inequality does not guarantee that $B_m \cap B_n = \emptyset$ . Are there any suggestions for how to ensure that $B_m \cap B_n = \emptyset$ ?","I am trying to solve a portion Problem 16 of Chapter 2 from Methods of Modern Mathematical Physics by Simon and Reed. The task is to show that the unit ball in an infinite dimensional Hilbert space contains infinitely many disjoint balls of radius . My approach is shown below. By Theorem 2.5, I know that every Hilbert space contains an orthonormal basis . I define the sequence of balls such that If , we observe that Thus, is contained in the unit ball. For , we can observe that However, this last inequality does not guarantee that . Are there any suggestions for how to ensure that ?",\sqrt{2}/4 \{a_n\}_{n = 1}^{\infty} \{B_n\}_{n=1}^{\infty} B_n = \{x\ :\ \|x - a_n/2\| < \sqrt{2}/4\}. a \in B_n \|a\| \leq \|a - a_n/2\| + \|a_n/2\| < \sqrt{2}/4 + 1/2 < 1. B_n m \neq n \|a_m/2 - a_n/2\| \leq \|x - a_m/2\| + \|x - a_n/2\| < \sqrt{2}/4 + \sqrt{2}/4 = \sqrt{2}/2. B_m \cap B_n = \emptyset B_m \cap B_n = \emptyset,"['functional-analysis', 'analysis', 'hilbert-spaces', 'normed-spaces']"
14,Spectrum of bilateral shift,Spectrum of bilateral shift,,"Let $T:l^2(\mathbb{Z})\longrightarrow l^2(\mathbb{Z})$ and define $T(\{x_n\})=\{x_{n-1}\}.$ Some reference tells me that the spectrum of $T$ is $\mathbb{T}=\{\lambda\in\mathbb{C}:|\lambda|=1 \}.$ What I'm sure is that for $\lambda=1$ then $T-\lambda I$ is not invertible. But, I'm not quite sure that for $\lambda\in\mathbb{T}$ other than $\lambda=1$ , $T-\lambda I$ also not invertible. For example, even for $\lambda=-1$ or $\lambda=\frac{\sqrt{2}}{2}+i\frac{\sqrt{2}}{2},$ I can't see why $T-\lambda I$ is not invertible and (for example) if $\lambda=\sqrt{2}+i\sqrt{2}\notin\mathbb{T}$ , then $T-\lambda I$ (perhaps) invertible. Any help would be appreciated. Thank you","Let and define Some reference tells me that the spectrum of is What I'm sure is that for then is not invertible. But, I'm not quite sure that for other than , also not invertible. For example, even for or I can't see why is not invertible and (for example) if , then (perhaps) invertible. Any help would be appreciated. Thank you","T:l^2(\mathbb{Z})\longrightarrow l^2(\mathbb{Z}) T(\{x_n\})=\{x_{n-1}\}. T \mathbb{T}=\{\lambda\in\mathbb{C}:|\lambda|=1 \}. \lambda=1 T-\lambda I \lambda\in\mathbb{T} \lambda=1 T-\lambda I \lambda=-1 \lambda=\frac{\sqrt{2}}{2}+i\frac{\sqrt{2}}{2}, T-\lambda I \lambda=\sqrt{2}+i\sqrt{2}\notin\mathbb{T} T-\lambda I","['functional-analysis', 'spectral-theory']"
15,Most direct way to prove the domain of $A^2$ is dense.,Most direct way to prove the domain of  is dense.,A^2,Let $A\colon \operatorname D(A)\to \mathcal H$ be a (generally unbounded but densely defined) self-adjoint operator in a Hilbert space. $$\operatorname D(A^2):=\{\psi \in \operatorname D(A) \text{ s.t. }A\psi \in \operatorname D(A)\}.$$ What is the most direct way to prove that $\operatorname D(A^2)$ is dense in $\mathcal H$ ? Or it is necessary to use the full machinery of the spectral theorem?,Let be a (generally unbounded but densely defined) self-adjoint operator in a Hilbert space. What is the most direct way to prove that is dense in ? Or it is necessary to use the full machinery of the spectral theorem?,A\colon \operatorname D(A)\to \mathcal H \operatorname D(A^2):=\{\psi \in \operatorname D(A) \text{ s.t. }A\psi \in \operatorname D(A)\}. \operatorname D(A^2) \mathcal H,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators', 'self-adjoint-operators']"
16,What is the derivative of digamma function?,What is the derivative of digamma function?,,"I want to know $(\frac{\Gamma'(\alpha)}{\Gamma(\alpha)})'$ . My goal is to show $\alpha $ times this derivative of digamma is greater than 1. The background of question is to show $\bar{x}$ is not asymptotically efficient for Gamma( $\alpha$ ,1), because the ratio of Var $\bar{x}$ and Cramer-Rao Lower Bound is greater than 1. I can show that this ratio is $\alpha $ times this derivative of digamma. But I don't know how to show it is >1.","I want to know . My goal is to show times this derivative of digamma is greater than 1. The background of question is to show is not asymptotically efficient for Gamma( ,1), because the ratio of Var and Cramer-Rao Lower Bound is greater than 1. I can show that this ratio is times this derivative of digamma. But I don't know how to show it is >1.",(\frac{\Gamma'(\alpha)}{\Gamma(\alpha)})' \alpha  \bar{x} \alpha \bar{x} \alpha ,"['functional-analysis', 'statistics', 'statistical-inference', 'gamma-function']"
17,Can you project unto closed subspaces of normed spaces that are not necessarily pre-Hilbert?,Can you project unto closed subspaces of normed spaces that are not necessarily pre-Hilbert?,,"I'm working through some notes for my signal processing class and they introduce the whole notion of pre-Hilbert spaces (inner product spaces) essentially only in order to be able to project elements onto closed subspaces. My question is: suppose $V$ is a general normed space (not necessarily derived from an inner product) and $U \subset V$ is a complete subset, can we not use the same proof to show that $\forall v \in V, \exists u \in U$ such that $||u-v||$ is minimal? In that case, the only thing the inner product does is to make the projection orthogonal, right?","I'm working through some notes for my signal processing class and they introduce the whole notion of pre-Hilbert spaces (inner product spaces) essentially only in order to be able to project elements onto closed subspaces. My question is: suppose is a general normed space (not necessarily derived from an inner product) and is a complete subset, can we not use the same proof to show that such that is minimal? In that case, the only thing the inner product does is to make the projection orthogonal, right?","V U \subset V \forall v \in V, \exists u \in U ||u-v||",['functional-analysis']
18,Existence of a complete norm on $\ell^2$ which extends $\|۰\|_1$ (on $\ell^1$),Existence of a complete norm on  which extends  (on ),\ell^2 \|۰\|_1 \ell^1,"We know that norm-1 is a complete norm on $\ell^1.$ Also $\ell^1$ is a subspace of $\ell^2.$ Now, is there a complete norm on $\ell^2$ which extends norm-1 (on $\ell^1$ )?","We know that norm-1 is a complete norm on Also is a subspace of Now, is there a complete norm on which extends norm-1 (on )?",\ell^1. \ell^1 \ell^2. \ell^2 \ell^1,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
19,Questions about Definition of Vector Spaces,Questions about Definition of Vector Spaces,,"I know that a vector space is over a field and has the operations of addition (among elements, which are called vectors) and scalar multiplication (in which a field element acts on a vector to yield a vector). Now, I want to reconcile this understanding with my previous intuition by asking some questions. Why can't a vector space have cross products/dot products defined inside it? What problems would be run into? In general, what kinds of ""products"" can we define in a vector space? Over what fields is $\mathbf{R}^n$ considered a vector space? Is it correct that vector space isomorphism only exists in the same field? Or can we claim that different vector spaces in different fields are isomorphic? What is the intuition used to extend vector spaces to infinite dimensions in functional analysis? Why do we only have to check for closure under addition and scalar multiplication to prove that a set is a vector space when a vector space has six (or seven, depending on how you count) axioms? I'm studying linear algebra for the second time in a proof-based context, so answers relevant to this level would be appreciated!","I know that a vector space is over a field and has the operations of addition (among elements, which are called vectors) and scalar multiplication (in which a field element acts on a vector to yield a vector). Now, I want to reconcile this understanding with my previous intuition by asking some questions. Why can't a vector space have cross products/dot products defined inside it? What problems would be run into? In general, what kinds of ""products"" can we define in a vector space? Over what fields is considered a vector space? Is it correct that vector space isomorphism only exists in the same field? Or can we claim that different vector spaces in different fields are isomorphic? What is the intuition used to extend vector spaces to infinite dimensions in functional analysis? Why do we only have to check for closure under addition and scalar multiplication to prove that a set is a vector space when a vector space has six (or seven, depending on how you count) axioms? I'm studying linear algebra for the second time in a proof-based context, so answers relevant to this level would be appreciated!",\mathbf{R}^n,"['linear-algebra', 'abstract-algebra', 'functional-analysis', 'vector-spaces']"
20,Is the Banach Algebra generated by a separable subset separable?,Is the Banach Algebra generated by a separable subset separable?,,"Let $A$ be a Banach algebra and $S \subset A$ a subset. Suppose $B$ is the Banach algebra generated by $S$ and that $S$ is a separable subset of $A$ . Does this imply that $B$ is separable? My intuition says the answer is yes , but I can't quite prove it. Here's my progress. For any $T \subset A$ , I define $$ W(T):=\{ t_1\cdots t_m : m \in \mathbb{N}, t_j \in T\} \subset A $$ By definition of Banach algebra generated by a set we have that $$ B_1:=\left\{ \sum_{k=1}^n \lambda_k w_k  : n \in \mathbb{N}, \lambda_k \in \mathbb{C} , w_k \in W(S) \right\} $$ is a dense subset of $B$ . Let $D$ be a countable dense subset of $S$ . I claim that $$ B_2:=\left\{ \sum_{k=1}^n \lambda_k w_k : n \in \mathbb{N}, \lambda_k \in \mathbb{Q}+i\mathbb{Q} , w_k \in W(D) \right\} $$ is a countable dense subset of $B$ . That $B_2$ is countable is clear. I can't quite prove that is dense because I am having issues showing that an any element of $W(S)$ is arbitrarily close to an element in $W(D)$ . I would appreciate any help with this. It might as well be that my intuition is wrong or that I am trying to prove it in a complicated way. Thanks in advance.","Let be a Banach algebra and a subset. Suppose is the Banach algebra generated by and that is a separable subset of . Does this imply that is separable? My intuition says the answer is yes , but I can't quite prove it. Here's my progress. For any , I define By definition of Banach algebra generated by a set we have that is a dense subset of . Let be a countable dense subset of . I claim that is a countable dense subset of . That is countable is clear. I can't quite prove that is dense because I am having issues showing that an any element of is arbitrarily close to an element in . I would appreciate any help with this. It might as well be that my intuition is wrong or that I am trying to prove it in a complicated way. Thanks in advance.","A S \subset A B S S A B T \subset A 
W(T):=\{ t_1\cdots t_m : m \in \mathbb{N}, t_j \in T\} \subset A
 
B_1:=\left\{ \sum_{k=1}^n \lambda_k w_k  : n \in \mathbb{N}, \lambda_k \in \mathbb{C} , w_k \in W(S) \right\}
 B D S 
B_2:=\left\{ \sum_{k=1}^n \lambda_k w_k : n \in \mathbb{N}, \lambda_k \in \mathbb{Q}+i\mathbb{Q} , w_k \in W(D) \right\}
 B B_2 W(S) W(D)","['functional-analysis', 'banach-algebras', 'separable-spaces']"
21,"$C^1[0,1]$ is not banach using the closed graph theory",is not banach using the closed graph theory,"C^1[0,1]","Show that $C^1[0,1]$ is not a banach space using the closed graph theory with the maximum norm. First, look at the derivative operator: $D:C^1[0,1]\to C[0,1]$ , $D(f)=f'$ . We can check that $D$ is linear and not bounded (by taking an example such as a polynomial $x^{n+1}$ ). Thus $D$ is not continuos. I'm not sure, if it is possible to show that $D$ has a closed graph (a linear map $T:X\to Y$ has a closed graph if $x_n\subset X$ such that $x_n\to x$ and $T_{x_n}\to y$ then $Tx=y$ ).So if by contradiction, we assume that $C^1[0,1]$ is banach with the sup norm, then get by the closed graph theory  that $D$ is continuos, which is not true according to what we've said.","Show that is not a banach space using the closed graph theory with the maximum norm. First, look at the derivative operator: , . We can check that is linear and not bounded (by taking an example such as a polynomial ). Thus is not continuos. I'm not sure, if it is possible to show that has a closed graph (a linear map has a closed graph if such that and then ).So if by contradiction, we assume that is banach with the sup norm, then get by the closed graph theory  that is continuos, which is not true according to what we've said.","C^1[0,1] D:C^1[0,1]\to C[0,1] D(f)=f' D x^{n+1} D D T:X\to Y x_n\subset X x_n\to x T_{x_n}\to y Tx=y C^1[0,1] D",['functional-analysis']
22,Can you prove that $f(x) = 0$ for every linear functional $f$ implies $x=0$ in a normed space without using Hahn-Banach?,Can you prove that  for every linear functional  implies  in a normed space without using Hahn-Banach?,f(x) = 0 f x=0,"In the context of another problem, I have to use the fact that if $f(x) = 0$ for all $f$ , then $x=0$ . I constructed my own proof of this using the Hahn-Banach theorem, which goes like this: Proof : Assume that $x \neq 0$ . Construct a functional $g$ in the following way: let $g(x) = 1$ and on $\text{span}(x)$ let $g$ be linear (this is well-defined on $\text{span}(x)$ ). By Hahn-Banach, $g$ can be continuously extended to the whole space, which contradicts the assumption that every functional is zero in $x$ . This is probably overkill for such a simple-looking statement, but I have no idea how to prove it in a more elementary way. Edit : I actually found a way to circumvent using Hahn-Banach (but not the axiom of choice). It goes like this: Proof : Assume that $x \neq 0$ . Let $(e_i)_{i \in I}$ be a basis of our vector space (where $I$ is some index set). Suppose that $x = \sum_{i \in I} x_i e_i$ . Since $x \neq 0$ , there exists an $x_i$ which is not zero, let's call its index $j$ . Construct the following linear functional $g$ : On $e_j$ , let $g$ be 1, on every other basis vector, let $g$ be zero. In that case $$g(x) = g(\sum_{i \in I} x_i e_i) = \sum_{i \in I} x_i g(e_i) = x_j g(e_j) = x_j \neq 0 $$ which is a contradiction.","In the context of another problem, I have to use the fact that if for all , then . I constructed my own proof of this using the Hahn-Banach theorem, which goes like this: Proof : Assume that . Construct a functional in the following way: let and on let be linear (this is well-defined on ). By Hahn-Banach, can be continuously extended to the whole space, which contradicts the assumption that every functional is zero in . This is probably overkill for such a simple-looking statement, but I have no idea how to prove it in a more elementary way. Edit : I actually found a way to circumvent using Hahn-Banach (but not the axiom of choice). It goes like this: Proof : Assume that . Let be a basis of our vector space (where is some index set). Suppose that . Since , there exists an which is not zero, let's call its index . Construct the following linear functional : On , let be 1, on every other basis vector, let be zero. In that case which is a contradiction.",f(x) = 0 f x=0 x \neq 0 g g(x) = 1 \text{span}(x) g \text{span}(x) g x x \neq 0 (e_i)_{i \in I} I x = \sum_{i \in I} x_i e_i x \neq 0 x_i j g e_j g g g(x) = g(\sum_{i \in I} x_i e_i) = \sum_{i \in I} x_i g(e_i) = x_j g(e_j) = x_j \neq 0 ,"['functional-analysis', 'vector-spaces']"
23,Compact operators in $\bigoplus_{i \in I} H_i$,Compact operators in,\bigoplus_{i \in I} H_i,"Let $\{H_i: i \in I\}$ be a collection of Hilbert spaces. We can form the Hilbert space direct sum $$H:= \bigoplus_{i \in I} H_i$$ Question : Is there a ""nice"" dense subset of $B_0(H)$ (compact operators on the direct sum $H$ )? For example, something like the operators $$\left\{\bigoplus_{i \in I}  T_i \ \Bigg| \ T_i \in F(H_i), \text{all but  finitely many $T_i$ are zero}\right\}$$ where $F(H_i)$ are the finite-rank operators on $H_i$ .","Let be a collection of Hilbert spaces. We can form the Hilbert space direct sum Question : Is there a ""nice"" dense subset of (compact operators on the direct sum )? For example, something like the operators where are the finite-rank operators on .","\{H_i: i \in I\} H:= \bigoplus_{i \in I} H_i B_0(H) H \left\{\bigoplus_{i \in I}  T_i \ \Bigg| \ T_i \in F(H_i), \text{all but  finitely many T_i are zero}\right\} F(H_i) H_i",['functional-analysis']
24,What is 'Operator valued function is holomorphic' ? Does Neumann series imply holomorphic?,What is 'Operator valued function is holomorphic' ? Does Neumann series imply holomorphic?,,"Let $H_1$ and $H_2$ be Hilbert spaces and $K(w):H_1 \rightarrow H_2$ be an operator for given $w\in\Omega\subset\mathbb{C}$ .(like a resolvent. It would not be resolvent.) In complex analysis, a function $f:\Omega \rightarrow \mathbb{C}$ is holomorphic if $$f'(w_0):=\lim_{w\rightarrow w_0} \frac{f(w)-f(w_0)}{w-w_0}$$ exists for every $w_0\in\Omega$ . And its limit takes modulus. However, since an operator valued function $w \mapsto K(w) $ is not complex value, $\left|\frac{K(w)-K(w_0)}{w-w_0}\right|$ cannot be defined. So, I can GUESS its limit is defined in operator norm, i.e. if $K'(w_0)$ is defined such that $$\left\|\frac{K(w)-K(w_0)}{w-w_0} - K'(w_0)\right\|_{H_1 \rightarrow H_2} \rightarrow 0 \quad as \quad w \rightarrow w_0,$$ $K(w_0)$ is holomorphic for $w_0 \in \Omega$ . In my book, there is no mention about this detail. By the way, consider the Neumann series, $$(I-K(w))^{-1} = \sum_k^\infty (K(w))^k.$$ In order to show $(I-K(w))^{-1}$ is holomorphic, I can think about 'analytic' first (since analytic and holomorphic is equivalent in $\mathbb{C}$ ) and Neumann series say ' $K(w)$ is analytic for each $w$ '. But, again,  it is not complex number. Questions What is definition of 'Operator valued function is holomorphic' ? Is my guess right ? Does it suffice to show existence of its Neumann series ? If then, why ?","Let and be Hilbert spaces and be an operator for given .(like a resolvent. It would not be resolvent.) In complex analysis, a function is holomorphic if exists for every . And its limit takes modulus. However, since an operator valued function is not complex value, cannot be defined. So, I can GUESS its limit is defined in operator norm, i.e. if is defined such that is holomorphic for . In my book, there is no mention about this detail. By the way, consider the Neumann series, In order to show is holomorphic, I can think about 'analytic' first (since analytic and holomorphic is equivalent in ) and Neumann series say ' is analytic for each '. But, again,  it is not complex number. Questions What is definition of 'Operator valued function is holomorphic' ? Is my guess right ? Does it suffice to show existence of its Neumann series ? If then, why ?","H_1 H_2 K(w):H_1 \rightarrow H_2 w\in\Omega\subset\mathbb{C} f:\Omega \rightarrow \mathbb{C} f'(w_0):=\lim_{w\rightarrow w_0} \frac{f(w)-f(w_0)}{w-w_0} w_0\in\Omega w \mapsto K(w)  \left|\frac{K(w)-K(w_0)}{w-w_0}\right| K'(w_0) \left\|\frac{K(w)-K(w_0)}{w-w_0} - K'(w_0)\right\|_{H_1 \rightarrow H_2} \rightarrow 0 \quad as \quad w \rightarrow w_0, K(w_0) w_0 \in \Omega (I-K(w))^{-1} = \sum_k^\infty (K(w))^k. (I-K(w))^{-1} \mathbb{C} K(w) w","['complex-analysis', 'functional-analysis']"
25,"$\mathcal{B}(\mathcal{X},\mathcal{Y})$ is Banach space iff $\mathcal{Y}$ is Banach space.",is Banach space iff  is Banach space.,"\mathcal{B}(\mathcal{X},\mathcal{Y}) \mathcal{Y}","Taken from Conway's A course in Functional Analysis Chapter 3 Section 2 Problem 1 Problem Statement: Show that for $\mathcal{B}(\mathcal{X}, \mathbb{F})\neq (0)$ , $\mathcal{B}(\mathcal{X},\mathcal{Y})$ is a Banach space if and only if $\mathcal{Y}$ is a Banach space. In the forward direction, we suppose that $\mathcal{B}(\mathcal{X}, \mathbb{F})$ is a Banach space. Then $\{T_n\} \in \mathcal{B}(\mathcal{X}, \mathbb{F})$ is a Cauchy sequence and therefore it converges to $T\in \mathcal{B}(\mathcal{X}, \mathbb{F})$ . This means that $\sup\{||(T_n - T)(x)||: ||x|| = 1\} \rightarrow 0$ as $n \rightarrow \infty$ . Now consider a sequence $y_n \in \mathcal{Y}$ . We hope to show that this sequence converges to $y\in \mathcal{Y}$ . If I can write $y_n = T_n(x)$ then since $T_n$ is Cauchy, it must follow that $T_n(x)$ converges to some $y \in \mathcal{Y}$ . But I'm not sure how to make this clear. Any tips is greatly appreciated!","Taken from Conway's A course in Functional Analysis Chapter 3 Section 2 Problem 1 Problem Statement: Show that for , is a Banach space if and only if is a Banach space. In the forward direction, we suppose that is a Banach space. Then is a Cauchy sequence and therefore it converges to . This means that as . Now consider a sequence . We hope to show that this sequence converges to . If I can write then since is Cauchy, it must follow that converges to some . But I'm not sure how to make this clear. Any tips is greatly appreciated!","\mathcal{B}(\mathcal{X}, \mathbb{F})\neq (0) \mathcal{B}(\mathcal{X},\mathcal{Y}) \mathcal{Y} \mathcal{B}(\mathcal{X}, \mathbb{F}) \{T_n\} \in \mathcal{B}(\mathcal{X}, \mathbb{F}) T\in \mathcal{B}(\mathcal{X}, \mathbb{F}) \sup\{||(T_n - T)(x)||: ||x|| = 1\} \rightarrow 0 n \rightarrow \infty y_n \in \mathcal{Y} y\in \mathcal{Y} y_n = T_n(x) T_n T_n(x) y \in \mathcal{Y}","['real-analysis', 'functional-analysis', 'banach-spaces']"
26,The diameter of the set of projections in a C*-algebra is at most 1,The diameter of the set of projections in a C*-algebra is at most 1,,"Let $p,q$ be projections in a $C^*$ -algebra $A$ . I am trying to show that $\|p-q\|\leq1$ , but I can't. If the projections $p,q$ commute, then this is easy: we set $C=C^*(1,p,q)$ and this is an abelian $C^*$ -algebra. By the Gelfand representation, we have that $\sigma(x+y)\subset\sigma(x)+\sigma(y)$ in an abelian C*-algebra, thus $\sigma_A(p-q)=\sigma_C(p-q)\subset\sigma_C(p)-\sigma_C(q)\subset\{-1,0,1\}$ and therefore $\|p-q\|\leq1$ . But what about the general case?","Let be projections in a -algebra . I am trying to show that , but I can't. If the projections commute, then this is easy: we set and this is an abelian -algebra. By the Gelfand representation, we have that in an abelian C*-algebra, thus and therefore . But what about the general case?","p,q C^* A \|p-q\|\leq1 p,q C=C^*(1,p,q) C^* \sigma(x+y)\subset\sigma(x)+\sigma(y) \sigma_A(p-q)=\sigma_C(p-q)\subset\sigma_C(p)-\sigma_C(q)\subset\{-1,0,1\} \|p-q\|\leq1","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
27,Interpolation Inequality (Sobolev embedding),Interpolation Inequality (Sobolev embedding),,"Let $\Omega$ be a $C^1$ domain, for any $\epsilon>0, 0<|\alpha|<k$ , there exists a $C_\epsilon$ such that $$||D^\alpha u||_{L^p}\leq \epsilon||u||_{W^{k,p}}+C_\epsilon||u||_{L^p}$$ for all $u\in W^{k,p}$ . I was trying to prove it by contradiction. $\forall n \in \mathbb{N}, \exists u_n \in W^{k,p}$ such that $||D^\alpha u_n||_{L^p}>\epsilon||u_n||_{W^{k,p}}+n||u_n||_{L^p}$ . Anyone could give me a hint about using Sobolev compactness embedding? I was trying to use the $W^{k,p}\subset \subset L^p$ . However, I do not how to show that the sequence is bounded in $sup$ . By taking normalisation, $v_n=\frac{u_n}{||u_n||_{W^{k,p}}}$ , we would have $$\frac{1}{||u_n||_{W^{k,p}}}||D^\alpha u_n||_{L^p}>\epsilon+\frac{n}{||u_n||_{W^{k,p}}}||u_n||_{L^p}$$","Let be a domain, for any , there exists a such that for all . I was trying to prove it by contradiction. such that . Anyone could give me a hint about using Sobolev compactness embedding? I was trying to use the . However, I do not how to show that the sequence is bounded in . By taking normalisation, , we would have","\Omega C^1 \epsilon>0, 0<|\alpha|<k C_\epsilon ||D^\alpha u||_{L^p}\leq \epsilon||u||_{W^{k,p}}+C_\epsilon||u||_{L^p} u\in W^{k,p} \forall n \in \mathbb{N}, \exists u_n \in W^{k,p} ||D^\alpha u_n||_{L^p}>\epsilon||u_n||_{W^{k,p}}+n||u_n||_{L^p} W^{k,p}\subset \subset L^p sup v_n=\frac{u_n}{||u_n||_{W^{k,p}}} \frac{1}{||u_n||_{W^{k,p}}}||D^\alpha u_n||_{L^p}>\epsilon+\frac{n}{||u_n||_{W^{k,p}}}||u_n||_{L^p}","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
28,Homotopy between idempotents of small difference,Homotopy between idempotents of small difference,,"Let $A$ be a unital $C^*$ -algebra. It is known that if $p$ and $q$ are projections in $A$ with $$\|p-q\|<1,$$ then $p$ and $q$ are homotopic through a path of projections. Question: Does a similar statement hold for idempotents? More precisely, if $e$ and $f$ are idempotents in $A$ , does there exist $\delta>0$ such that $e$ and $f$ are homotopic through idempotents whenever $$\|e-f\|<\delta?$$","Let be a unital -algebra. It is known that if and are projections in with then and are homotopic through a path of projections. Question: Does a similar statement hold for idempotents? More precisely, if and are idempotents in , does there exist such that and are homotopic through idempotents whenever","A C^* p q A \|p-q\|<1, p q e f A \delta>0 e f \|e-f\|<\delta?","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
29,Why is the fractional Sobolev space defined like this?,Why is the fractional Sobolev space defined like this?,,"I was reading Fractional Sobolev space topic. $s\in (0,1)$ , $p\in [1,\infty)$ , $$ W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{n/p+s}}\in L^p(\Omega\times \Omega)\right\} $$ . But I do know why there is extra term of $n/p$ come in power. Natural extension of integer Sobolev space should be $$ W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{s}}\in L^p(\Omega\times \Omega)\right\} $$ . Please any one through some light on such definition of Sobolev space. Edit: I though may be this because of integrability possible iff $(n/p+s)p>n$ . But I am not sure. Any Help will be appreciated.","I was reading Fractional Sobolev space topic. , , . But I do know why there is extra term of come in power. Natural extension of integer Sobolev space should be . Please any one through some light on such definition of Sobolev space. Edit: I though may be this because of integrability possible iff . But I am not sure. Any Help will be appreciated.","s\in (0,1) p\in [1,\infty) 
W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{n/p+s}}\in L^p(\Omega\times \Omega)\right\}
 n/p 
W^{s,p}(\Omega)=\left\{u\in L^p(\Omega)|\frac{|u(x)-u(y)|}{|x-y|^{s}}\in L^p(\Omega\times \Omega)\right\}
 (n/p+s)p>n","['functional-analysis', 'partial-differential-equations', 'definition', 'sobolev-spaces', 'fractional-sobolev-spaces']"
30,Showing Holder's inequality holds for $p=\infty$ and $q=1$,Showing Holder's inequality holds for  and,p=\infty q=1,"We're asked to show that Holder's inequality (for the case when $1/p + 1/q = 1$ ) holds for the case when $p=\infty$ and $q=1$ . The inequality is given to us in the following form. $\sum\limits_{i=0}^\infty \vert a_ix_i \vert \leq \vert \vert a \vert \vert_q \vert \vert x \vert \vert_p$ Here's my proof and I'd like to make sure that the logic is sound. $$ \begin{align*}    \sum \vert a_i x_i \vert &\leq \vert \vert a \vert \vert_\infty \vert \vert x \vert \vert_1 &&\text{plug in variables} \\                             &= \max(\vert a \vert) \vert \vert a \vert \vert_1 &&\text{value of infinite norm} \end{align*} $$ Now divide by $\max(\vert a \vert)$ $$ \sum \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \vert \vert x \vert \vert_1 $$ We know that $\sum\limits_{i=o}^\infty \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \sum \vert x_i \vert $ because $\cfrac{|a_i|}{\max(|a|)} \leq 1\, \forall a_i \in a \in \ell_\infty $ . Now we have that $\sum \vert x_i \vert \leq \vert \vert x \vert \vert_1$ . These are, in fact, equal to each other. So we see that our case when $p=\infty$ and $q=1$ holds. If there something I ought to do to make the proof easier to understand, please let me know.","We're asked to show that Holder's inequality (for the case when ) holds for the case when and . The inequality is given to us in the following form. Here's my proof and I'd like to make sure that the logic is sound. Now divide by We know that because . Now we have that . These are, in fact, equal to each other. So we see that our case when and holds. If there something I ought to do to make the proof easier to understand, please let me know.","1/p + 1/q = 1 p=\infty q=1 \sum\limits_{i=0}^\infty \vert a_ix_i \vert \leq \vert \vert a \vert \vert_q \vert \vert x \vert \vert_p 
\begin{align*}
   \sum \vert a_i x_i \vert &\leq \vert \vert a \vert \vert_\infty \vert \vert x \vert \vert_1 &&\text{plug in variables} \\
                            &= \max(\vert a \vert) \vert \vert a \vert \vert_1 &&\text{value of infinite norm}
\end{align*}
 \max(\vert a \vert) 
\sum \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \vert \vert x \vert \vert_1
 \sum\limits_{i=o}^\infty \cfrac{\vert a_i x_i \vert}{\max(\vert a \vert)} \leq \sum \vert x_i \vert  \cfrac{|a_i|}{\max(|a|)} \leq 1\, \forall a_i \in a \in \ell_\infty  \sum \vert x_i \vert \leq \vert \vert x \vert \vert_1 p=\infty q=1","['functional-analysis', 'solution-verification', 'holder-inequality']"
31,"Prove that $\inf\limits_{z \in S^{\perp}} \| x - z \| = \sup \left \{ \lvert \langle x , y \rangle \rvert\ \big |\ y \in S, \|y \| \leq 1 \right \}.$",Prove that,"\inf\limits_{z \in S^{\perp}} \| x - z \| = \sup \left \{ \lvert \langle x , y \rangle \rvert\ \big |\ y \in S, \|y \| \leq 1 \right \}.","Let $H$ be a Hilbert space and $S$ be a subspace of $H.$ Let $x \in H$ and $\left \|x \right \| = 1.$ Prove that $$\inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \| = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}.$$ My attempt $:$ Let $L = \inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \|$ and $M = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}.$ If $x \in S^{\perp}$ then clearly $L = 0$ and $M = 0$ (because if $x \in S^{\perp}$ then for any $y \in S$ we have $\left \langle x,y \right \rangle = 0$ ). Also if $x \in S$ then we have \begin{align*} L & = \inf\limits_{z \in S^{\perp}} \sqrt {\|x\|^2 + \|z\|^2} \\ & = \inf\limits_{z \in S^{\perp}} \sqrt {1 + \|z\|^2} \\ & = \sqrt {1 + \inf\limits_{z \in S^{\perp}} \|z\|^2} \\ & = 1 \end{align*} and for all $y \in S$ with $\|y\| \leq 1$ we have by Cauchy Schwarz's inequality $$\left \lvert \langle x,y \rangle \right \rvert \leq \|x\| \|y\| \leq 1.$$ This shows that $M \leq 1.$ Also since $x \in S$ with $\|x\| = 1$ we have by taking $y = x$ $$\langle x,x \rangle = \|x\|^2 = 1.$$ So $M = 1.$ Therefore $L = M$ holds if $x \in S \cup S^{\perp}.$ Now $H = S \oplus S^{\perp}.$ So every element of $H$ can be written as $x = u + v,$ where $u \in S$ and $v \in S^{\perp}.$ For this case \begin{align*} \|(u+v) - z \|^2 & = \|u+v\|^2 + \|z\|^2 - \langle v , z \rangle  - \langle z , v \rangle \\ & = \|u+v\|^2 + \|z\|^2 - 2 \mathfrak {R} \left ( \langle v,z \rangle \right ) \\ & \geq \|u+v\|^2 + \|z\|^2 - 2 \left \lvert \langle v , z \rangle \right \rvert \\ & \geq \|u+v\|^2 + \|z\|^2 - 2\|v\| \|z\| \\ & = \left (\|u+v\|^2 - \|v\|^2 \right ) + \left (\|z\| - \|v\| \right )^2 \\ & \geq \|u+v\|^2 - \|v\|^2 \end{align*} So by taking $z = v$ we have $$L = \sqrt {\|u+v\|^2 - \|v\|^2} = \sqrt {\|u\|^2 + 2 \mathfrak {R} \langle u,v \rangle} = \|u\|\ \ (\text {since}\ u \perp v).$$ Now for any $y \in S$ with $\|y\| \leq 1$ we have \begin{align*} \left \lvert \langle u + v , y \rangle \right \rvert & = \left \lvert \langle u , y \rangle + \langle v , y \rangle \right \rvert \\ & = \left \lvert \langle u,y \rangle \right \rvert\ \ \ \ \ \ \ \ (\text {Since}\ v \perp y ) \\ & \leq \|u\| \|y\| \\ & \leq \|u\| \end{align*} Now if $u = 0$ then $x = v \in S^{\perp}$ in which case we have already proved that $L = M.$ So WLOG we may assume that $u \neq 0.$ Then by taking $y = \dfrac {u} {\|u\|}$ we have $M = \|u\|.$ So in this case also we have $L = M,$ as required. QED Does my proof hold good? Please check it. Thanks in advance. EDIT $:$ I don't think that what I did is correct. Because Hilbert space can't have such decomposition unless $S$ was given to be closed.",Let be a Hilbert space and be a subspace of Let and Prove that My attempt Let and If then clearly and (because if then for any we have ). Also if then we have and for all with we have by Cauchy Schwarz's inequality This shows that Also since with we have by taking So Therefore holds if Now So every element of can be written as where and For this case So by taking we have Now for any with we have Now if then in which case we have already proved that So WLOG we may assume that Then by taking we have So in this case also we have as required. QED Does my proof hold good? Please check it. Thanks in advance. EDIT I don't think that what I did is correct. Because Hilbert space can't have such decomposition unless was given to be closed.,"H S H. x \in H \left \|x \right \| = 1. \inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \| = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}. : L = \inf\limits_{z \in S^{\perp}} \left  \|x - z  \right \| M = \sup \left \{\left \lvert \left \langle x , y \right \rangle \right \rvert\ \big |\ y \in S, \left \|y \right \| \leq 1 \right \}. x \in S^{\perp} L = 0 M = 0 x \in S^{\perp} y \in S \left \langle x,y \right \rangle = 0 x \in S \begin{align*} L & = \inf\limits_{z \in S^{\perp}} \sqrt {\|x\|^2 + \|z\|^2} \\ & = \inf\limits_{z \in S^{\perp}} \sqrt {1 + \|z\|^2} \\ & = \sqrt {1 + \inf\limits_{z \in S^{\perp}} \|z\|^2} \\ & = 1 \end{align*} y \in S \|y\| \leq 1 \left \lvert \langle x,y \rangle \right \rvert \leq \|x\| \|y\| \leq 1. M \leq 1. x \in S \|x\| = 1 y = x \langle x,x \rangle = \|x\|^2 = 1. M = 1. L = M x \in S \cup S^{\perp}. H = S \oplus S^{\perp}. H x = u + v, u \in S v \in S^{\perp}. \begin{align*} \|(u+v) - z \|^2 & = \|u+v\|^2 + \|z\|^2 - \langle v , z \rangle  - \langle z , v \rangle \\ & = \|u+v\|^2 + \|z\|^2 - 2 \mathfrak {R} \left ( \langle v,z \rangle \right ) \\ & \geq \|u+v\|^2 + \|z\|^2 - 2 \left \lvert \langle v , z \rangle \right \rvert \\ & \geq \|u+v\|^2 + \|z\|^2 - 2\|v\| \|z\| \\ & = \left (\|u+v\|^2 - \|v\|^2 \right ) + \left (\|z\| - \|v\| \right )^2 \\ & \geq \|u+v\|^2 - \|v\|^2 \end{align*} z = v L = \sqrt {\|u+v\|^2 - \|v\|^2} = \sqrt {\|u\|^2 + 2 \mathfrak {R} \langle u,v \rangle} = \|u\|\ \ (\text {since}\ u \perp v). y \in S \|y\| \leq 1 \begin{align*} \left \lvert \langle u + v , y \rangle \right \rvert & = \left \lvert \langle u , y \rangle + \langle v , y \rangle \right \rvert \\ & = \left \lvert \langle u,y \rangle \right \rvert\ \ \ \ \ \ \ \ (\text {Since}\ v \perp y ) \\ & \leq \|u\| \|y\| \\ & \leq \|u\| \end{align*} u = 0 x = v \in S^{\perp} L = M. u \neq 0. y = \dfrac {u} {\|u\|} M = \|u\|. L = M, : S","['functional-analysis', 'vector-spaces', 'solution-verification', 'hilbert-spaces']"
32,About the hypotheses of Schauder Theorem,About the hypotheses of Schauder Theorem,,I know that Schauder Theorem says: $T: E \to F$ is an compact operator iff $T^{*}: F^{*} \to E^{*}$ is an compact operator. My doubt is: what are the hypotheses about $E$ and $F$ ? Is it enough that they are just normed spaces or do they need to be Banach spaces? Or $E$ normed and $F$ Banach? appreciate...,I know that Schauder Theorem says: is an compact operator iff is an compact operator. My doubt is: what are the hypotheses about and ? Is it enough that they are just normed spaces or do they need to be Banach spaces? Or normed and Banach? appreciate...,T: E \to F T^{*}: F^{*} \to E^{*} E F E F,"['functional-analysis', 'banach-spaces', 'compact-operators']"
33,why $x_m$ converges weakly to $x_\infty$?,why  converges weakly to ?,x_m x_\infty,"Let $(X,\|.\|)$ be reflexive Banach space and $Y$ be a closed separable subspace of $X$ $\big((Y ,\|.\|)$ is clearly a separable reflexive Banach space $\big)$ , then the dual space $Y^*$ of $Y$ is separable. Let $\{y_n^*\}$ be a countable dense subset of $Y^*$ . Let $\{x_m\}$ be a bounded sequence in $X$ , such that $$ \langle y_n^*, x_m\rangle\underset{m}{\to }z_n\qquad \forall n $$ With $z_n\in\mathbb{R}$ . We suppose that the sequence $\{x_m\}$ has a subsequece $\{x_{m_i}\}$ weakly convergente in $Y$ to an element $x_\infty$ . Then $$ \langle y_n^*, x_\infty\rangle=z_n\qquad \forall n\qquad (*) $$ Since $\{y_n^*\}$ separates the points of $Y$ , it follows from $(*)$ that every limit point of $\{x_m\}$ must equal $x_\infty$ . My problem I don't understand why : we can conclude that $x_m$ converges weakly to $x_\infty$ This result was used in the article Infinite-Dimentional Extension of a Theorem of Komlos of Erik J.Balder , on pages 186-187. In the context of the article, the auther says that: "" $\{s_n(t)\}$ converges weakly to a point $y_t$ in $Y$ ."" But i don't understand why. An idea please.","Let be reflexive Banach space and be a closed separable subspace of is clearly a separable reflexive Banach space , then the dual space of is separable. Let be a countable dense subset of . Let be a bounded sequence in , such that With . We suppose that the sequence has a subsequece weakly convergente in to an element . Then Since separates the points of , it follows from that every limit point of must equal . My problem I don't understand why : we can conclude that converges weakly to This result was used in the article Infinite-Dimentional Extension of a Theorem of Komlos of Erik J.Balder , on pages 186-187. In the context of the article, the auther says that: "" converges weakly to a point in ."" But i don't understand why. An idea please.","(X,\|.\|) Y X \big((Y ,\|.\|) \big) Y^* Y \{y_n^*\} Y^* \{x_m\} X 
\langle y_n^*, x_m\rangle\underset{m}{\to }z_n\qquad \forall n
 z_n\in\mathbb{R} \{x_m\} \{x_{m_i}\} Y x_\infty 
\langle y_n^*, x_\infty\rangle=z_n\qquad \forall n\qquad (*)
 \{y_n^*\} Y (*) \{x_m\} x_\infty x_m x_\infty \{s_n(t)\} y_t Y","['functional-analysis', 'banach-spaces', 'weak-convergence']"
34,Continuous function and non-zero measure set,Continuous function and non-zero measure set,,"Let $g:[0,1] \to\Bbb R$ be a continuous function. Let $m$ denote the Lebesgue measure in this interval. Suppose that it takes a constant value in $A \subset [0,1]$ , and $m(A) \neq 0$ . It is certain that $g$ is constant in a interval in $[0,1]$ ?","Let be a continuous function. Let denote the Lebesgue measure in this interval. Suppose that it takes a constant value in , and . It is certain that is constant in a interval in ?","g:[0,1] \to\Bbb R m A \subset [0,1] m(A) \neq 0 g [0,1]","['real-analysis', 'functional-analysis', 'analysis']"
35,Banach Space Inequality of functionals equivalence,Banach Space Inequality of functionals equivalence,,"Let $X$ be a Banach space with $f_1,..,f_n\in X^*$ and $c_1,...,c_n\in\mathbb{R}$ then the following are equivalent: 1. $\exists x_0\in X: f_i(x_0)=c_i,\forall i\in\{1,..,n\}$ 2. $\exists M\geq 0: |\sum_{i=1}^na_ic_i|\leq M\|\sum_{i=1}^na_if_i\|$ for every choice of $a_i\in\mathbb{R}$ The direction $1\implies 2$ is immediate by setting $f=\sum_{i=1}^na_if_i$ and noticing that $\|f\|\|x\|\geq |f(x)|$ by definition of the norm. The desired inequality is then $\|f\|\|x_0\|\geq |f(x_0)|$ where $M=\|x_0\|$ . The direction $2 \implies 1$ is not that trivial however, any ideas to proceed?","Let be a Banach space with and then the following are equivalent: 1. 2. for every choice of The direction is immediate by setting and noticing that by definition of the norm. The desired inequality is then where . The direction is not that trivial however, any ideas to proceed?","X f_1,..,f_n\in X^* c_1,...,c_n\in\mathbb{R} \exists x_0\in X: f_i(x_0)=c_i,\forall i\in\{1,..,n\} \exists M\geq 0: |\sum_{i=1}^na_ic_i|\leq M\|\sum_{i=1}^na_if_i\| a_i\in\mathbb{R} 1\implies 2 f=\sum_{i=1}^na_if_i \|f\|\|x\|\geq |f(x)| \|f\|\|x_0\|\geq |f(x_0)| M=\|x_0\| 2 \implies 1","['functional-analysis', 'banach-spaces']"
36,"Determine if $X=\{f\in C^1[0,1] | f(0)=f'(0)\}$ is complete WRT $||.||_{\infty}$ norm and show that $X$ is infinite dimensional.",Determine if  is complete WRT  norm and show that  is infinite dimensional.,"X=\{f\in C^1[0,1] | f(0)=f'(0)\} ||.||_{\infty} X","I'm having trouble determining if $X$ is complete WRT $||.||_{\infty}$ norm. I know that in order to show that I need to take a Cauchy sequence and show that it has a limit in my space $X$ or find a Cauchy sequence of functions which satisfy $f(0)=f'(0)$ and which limit lies outside of $X$ . I tried but was unable to find a counter example, therefore I believe the statement to be true, however I am not sure exactly how to go about proving it. So far I was able to prove that any $g\in X$ is of the form $f(0)+\int_0^xf(y)dy$ where $f\in C[0,1]$ if it helps. would really appreciate it if somebody could show me how to prove of disprove this statement. Thanks","I'm having trouble determining if is complete WRT norm. I know that in order to show that I need to take a Cauchy sequence and show that it has a limit in my space or find a Cauchy sequence of functions which satisfy and which limit lies outside of . I tried but was unable to find a counter example, therefore I believe the statement to be true, however I am not sure exactly how to go about proving it. So far I was able to prove that any is of the form where if it helps. would really appreciate it if somebody could show me how to prove of disprove this statement. Thanks","X ||.||_{\infty} X f(0)=f'(0) X g\in X f(0)+\int_0^xf(y)dy f\in C[0,1]","['functional-analysis', 'banach-spaces', 'examples-counterexamples', 'normed-spaces', 'complete-spaces']"
37,Motivation and applications of the duality map,Motivation and applications of the duality map,,"The duality map is defined, according to Brezis ( Functional Analysis, Sobolev Spaces and Partial Differential Equations ) as follows, where $E$ is a Banach space and $x \in E$ : $$F(x) = \{f \in E^* \ : \ ||f|| = ||x|| \text{ and } \langle f, x \rangle = ||x||^2\}$$ It is one of the exercises to prove that $$ F(x) = \{f \in E^* \ : \ ||f|| \leq ||x|| \text{ and } \langle f, x \rangle = ||x||^2\} = \{f \in E^* \ : \ \frac12 ||y||^2 - \frac12 ||x||^2 \geq \langle f, y - x \rangle \ \forall y \in E\}.$$ My question is: Where does the duality map comes from? That, is, what motivates the definition, from a historical point of view? Why is it useful? Thanks in advance.","The duality map is defined, according to Brezis ( Functional Analysis, Sobolev Spaces and Partial Differential Equations ) as follows, where is a Banach space and : It is one of the exercises to prove that My question is: Where does the duality map comes from? That, is, what motivates the definition, from a historical point of view? Why is it useful? Thanks in advance.","E x \in E F(x) = \{f \in E^* \ : \ ||f|| = ||x|| \text{ and } \langle f, x \rangle = ||x||^2\} 
F(x) = \{f \in E^* \ : \ ||f|| \leq ||x|| \text{ and } \langle f, x \rangle = ||x||^2\} = \{f \in E^* \ : \ \frac12 ||y||^2 - \frac12 ||x||^2 \geq \langle f, y - x \rangle \ \forall y \in E\}.","['functional-analysis', 'duality-theorems']"
38,Why is the interior of $\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\}$ empty?,Why is the interior of  empty?,\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\},Let $M=\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\}$ . How can I show that the interior of M is empty? I already showed that M is convex but I'm not sure if that's helping.,Let . How can I show that the interior of M is empty? I already showed that M is convex but I'm not sure if that's helping.,M=\{(x_n)_n \in {\displaystyle \ell ^{2}}| \sum_{n=1}^{\infty}n^2|x_n|^2 < \infty\},['functional-analysis']
39,How is Hölder's inequality with $p=q=2$ equivalent to Cauchy-Schwarz inequality?,How is Hölder's inequality with  equivalent to Cauchy-Schwarz inequality?,p=q=2,"The Cauchy-Schwarz inequality says that $$\left|\sum_i x_i y_i \right| \leq \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2}$$ Hölder's inequality for the special case $p=q=2$ says that $$\sum_i |x_i y_i| \leq \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2}$$ Clearly the former implies the latter via the triangle inequality. However, there appears to be general consensus online that the latter also implies the former. For example, mathworld [Hölder's inequality with] $p=q=2$ becomes Cauchy's inequality or Wikipedia The special case [of Hölder's inequality with] p = q = 2 gives a form of the Cauchy–Schwarz inequality. Why is this true? It seems to me that Cauchy's inequality is a stronger statement than this special case of Hölder's inequality, and so Hölder's inequality does not become Cauchy's inequality at all. This has been asked before here Why is the Cauchy Schwarz inequality a special case of Holder's inequality? but not answered. In particular, Hrit Roy's final comment on the answer is not dealt with.","The Cauchy-Schwarz inequality says that Hölder's inequality for the special case says that Clearly the former implies the latter via the triangle inequality. However, there appears to be general consensus online that the latter also implies the former. For example, mathworld [Hölder's inequality with] becomes Cauchy's inequality or Wikipedia The special case [of Hölder's inequality with] p = q = 2 gives a form of the Cauchy–Schwarz inequality. Why is this true? It seems to me that Cauchy's inequality is a stronger statement than this special case of Hölder's inequality, and so Hölder's inequality does not become Cauchy's inequality at all. This has been asked before here Why is the Cauchy Schwarz inequality a special case of Holder's inequality? but not answered. In particular, Hrit Roy's final comment on the answer is not dealt with.",\left|\sum_i x_i y_i \right| \leq \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2} p=q=2 \sum_i |x_i y_i| \leq \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2} p=q=2,"['real-analysis', 'functional-analysis', 'inequality']"
40,"Function $T:X \rightarrow X$ with least Lipschitz constant, for which $\sup_{x \in X}d(T(x),x) \le r$.","Function  with least Lipschitz constant, for which .","T:X \rightarrow X \sup_{x \in X}d(T(x),x) \le r","Let $X=(X,d)$ be a metric space and $r \ge 0$ . Question 1. What is a good upper-bound (the smaller the better) for $\inf_T Lip(T)$ where $Lip(T) := \underset{x,x' \in X,\;x \ne x'}{\sup}\; \frac{d(T(x),T(x'))}{d(x,x')}$ , and the infimum is taken over all functions $T:X \rightarrow X$ such that $\underset{x \in X}{\sup}\;d(T(x),x) \le r$ ? Question 2. Same question when $X$ is a normed vector space, e.g $\mathbb R^n$ equipped with an $\ell_p$ -norm, especially the cases $p=1,2,\infty$ . N.B.: Of course, these bounds would depend on the parameter $r$ . Also note that the an upper bound of $1$ is trivial and uninformative (gotten by taken $T =I_X$ , the identity function on $X$ ).","Let be a metric space and . Question 1. What is a good upper-bound (the smaller the better) for where , and the infimum is taken over all functions such that ? Question 2. Same question when is a normed vector space, e.g equipped with an -norm, especially the cases . N.B.: Of course, these bounds would depend on the parameter . Also note that the an upper bound of is trivial and uninformative (gotten by taken , the identity function on ).","X=(X,d) r \ge 0 \inf_T Lip(T) Lip(T) := \underset{x,x' \in X,\;x \ne x'}{\sup}\; \frac{d(T(x),T(x'))}{d(x,x')} T:X \rightarrow X \underset{x \in X}{\sup}\;d(T(x),x) \le r X \mathbb R^n \ell_p p=1,2,\infty r 1 T =I_X X","['functional-analysis', 'metric-spaces', 'lipschitz-functions']"
41,Find the kernel and range of the linear operator $Kf(x) = \int_0^1 \sin \pi (x-y) f(y)dy$,Find the kernel and range of the linear operator,Kf(x) = \int_0^1 \sin \pi (x-y) f(y)dy,"The question is the following Find the kernel and range of the linear operator $K : C([0,1]) \to C([0,1])$ defined by $$ Kf(x) = \int_0^1 \sin (\pi (x-y)) f(y)dy $$ For the kernel, I tried to solve $$ Kf(x) = \int_0^1 \sin (\pi x) \cos(\pi y)f(y)dy - \int_0^1\sin (\pi y) \cos(\pi x)f(y)dy = 0 $$ and I can't proceed further. And I have no idea how to find the range. Any hint or help is appreciated!","The question is the following Find the kernel and range of the linear operator defined by For the kernel, I tried to solve and I can't proceed further. And I have no idea how to find the range. Any hint or help is appreciated!","K : C([0,1]) \to C([0,1]) 
Kf(x) = \int_0^1 \sin (\pi (x-y)) f(y)dy
 
Kf(x) = \int_0^1 \sin (\pi x) \cos(\pi y)f(y)dy - \int_0^1\sin (\pi y) \cos(\pi x)f(y)dy = 0
","['real-analysis', 'functional-analysis']"
42,Example of a linear operator has no continuous inverse [closed],Example of a linear operator has no continuous inverse [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Construct a linear mapping $T : X → Y$ between two normed linear spaces X and Y such that T is one-to-one, onto, and continuous, but $T^ {−1}$ is not continuous. I can not find any example because of linear mapping. Thanks for any hint with that.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Construct a linear mapping between two normed linear spaces X and Y such that T is one-to-one, onto, and continuous, but is not continuous. I can not find any example because of linear mapping. Thanks for any hint with that.","T : X → Y T^
{−1}","['real-analysis', 'functional-analysis']"
43,homomorphisms of B(H),homomorphisms of B(H),,"Let $\varphi\colon B(H)\to B(H)$ is an injective $\ast-$ homomorphism ( $\varphi$ -linear, $\varphi(xy)=\varphi(x)\varphi(y)$ , $\varphi(x^{\ast})=\varphi(x)^{\ast}$ ), where $H-$ separable Hilbert space. Is it true that $\varphi$ is actually $\ast-$ isomorphism? In other words $\varphi$ is also a surjection.","Let is an injective homomorphism ( -linear, , ), where separable Hilbert space. Is it true that is actually isomorphism? In other words is also a surjection.",\varphi\colon B(H)\to B(H) \ast- \varphi \varphi(xy)=\varphi(x)\varphi(y) \varphi(x^{\ast})=\varphi(x)^{\ast} H- \varphi \ast- \varphi,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras', 'c-star-algebras']"
44,What is Banach's Homogeneous Space Problem of 1932?,What is Banach's Homogeneous Space Problem of 1932?,,"I have seen some references to Banach's homogeneous space problem from 1932 which was solved by Gowers. Could I ask what this problem actually states, I have tried searching and cannot find anything (or nothing which was free access anyway).","I have seen some references to Banach's homogeneous space problem from 1932 which was solved by Gowers. Could I ask what this problem actually states, I have tried searching and cannot find anything (or nothing which was free access anyway).",,"['functional-analysis', 'banach-spaces']"
45,When is $C_c^\infty(\mathbb R^d \setminus \{ 0 \})$ dense in $C_c^\infty(\mathbb R^d)$?,When is  dense in ?,C_c^\infty(\mathbb R^d \setminus \{ 0 \}) C_c^\infty(\mathbb R^d),Let $d\in \mathbb N$ . Under what constraints for $d$ and $p$ is $C_c^\infty(\mathbb R^d \setminus \{ 0 \})$ dense in $C_c^\infty(\mathbb R^d)$ with respect to the $L^p(\mathbb R^d)$ -norm?,Let . Under what constraints for and is dense in with respect to the -norm?,d\in \mathbb N d p C_c^\infty(\mathbb R^d \setminus \{ 0 \}) C_c^\infty(\mathbb R^d) L^p(\mathbb R^d),"['real-analysis', 'functional-analysis', 'analysis']"
46,Show that if $\phi \circ T$ is bounded for every $\phi\in Y^*$ then $T$ is bounded,Show that if  is bounded for every  then  is bounded,\phi \circ T \phi\in Y^* T,"Show that if $T:X \to Y$ is a linear map between Banach spaces and $\phi \circ T$ is bounded for every $\phi\in Y^*$ then $T$ is bounded. The given hint is to prove the contrapositive. 'Progress': Suppose $T$ is unbounded. Then there exist $x_n \in X$ such that $\left\lVert x_n\right\rVert=1$ and $\left\lVert Tx_n\right\rVert \geq n$ for all $n$ . For each $n$ there is a support functional $\phi_n$ at $Tx_n$ : $\phi_n \in Y^*, \left\lVert \phi_n\right\rVert=1, \phi_n(Tx_n)=\left\lVert Tx_n\right\rVert$ . I then applied the (contrapositive of the) Principle of Uniform Boundedness to the set of linear maps $\phi_n \circ T$ before realising that this doesn't even work because we don't know that the maps $\phi_n \circ T$ are bounded. So really I've made no progress and this is mostly to show that I've tried. Though I expect the solution will use the PUB somehow. Any small hints would be appreciated (please do not spoil the solution).",Show that if is a linear map between Banach spaces and is bounded for every then is bounded. The given hint is to prove the contrapositive. 'Progress': Suppose is unbounded. Then there exist such that and for all . For each there is a support functional at : . I then applied the (contrapositive of the) Principle of Uniform Boundedness to the set of linear maps before realising that this doesn't even work because we don't know that the maps are bounded. So really I've made no progress and this is mostly to show that I've tried. Though I expect the solution will use the PUB somehow. Any small hints would be appreciated (please do not spoil the solution).,"T:X \to Y \phi \circ T \phi\in Y^* T T x_n \in X \left\lVert x_n\right\rVert=1 \left\lVert Tx_n\right\rVert \geq n n n \phi_n Tx_n \phi_n \in Y^*, \left\lVert \phi_n\right\rVert=1, \phi_n(Tx_n)=\left\lVert Tx_n\right\rVert \phi_n \circ T \phi_n \circ T","['functional-analysis', 'unbounded-operators']"
47,Is a linear functional which is positive on linearly generating set of projections positive?,Is a linear functional which is positive on linearly generating set of projections positive?,,"Let $A$ be a unital C $^*$ algebra, and suppose there is a set of projections $P \subset \mathcal{P}(A)$ whose linear span is dense in $A$ . If $\varphi \in A^*$ has $\varphi(p) \ge 0$ for all $p \in P$ , does it follow that $\varphi \ge 0$ ? Note that this does hold if every element of $A$ can be approximated in norm by a linear combination of mutually orthogonal projections in $P$ (given any $x^*x \in A_+$ , such an approximation for $x$ will lead to an approximation of $x^*x$ by a linear combination with positive coefficients), but is there any reason to believe it in general?","Let be a unital C algebra, and suppose there is a set of projections whose linear span is dense in . If has for all , does it follow that ? Note that this does hold if every element of can be approximated in norm by a linear combination of mutually orthogonal projections in (given any , such an approximation for will lead to an approximation of by a linear combination with positive coefficients), but is there any reason to believe it in general?",A ^* P \subset \mathcal{P}(A) A \varphi \in A^* \varphi(p) \ge 0 p \in P \varphi \ge 0 A P x^*x \in A_+ x x^*x,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
48,I want to prove that two norms are equivalent but I am struggling with an upper bound,I want to prove that two norms are equivalent but I am struggling with an upper bound,,"I want to compare the usual norm on $L^2(-1,1)$ with the following: $$ \Vert f \Vert_H^{2} = \int_{-1}^1 \vert f(x) \vert^2 \frac{1}{1+x^2}dx $$ Now, for sure I have this: $$\Vert f \Vert_H \leq \Vert f \Vert_{L^2} $$ Because $\frac{1}{1+x^2} \leq 1$ I want to now find some M such that $$\Vert f \Vert_{L^2} \leq M \Vert f \Vert_{H}$$ But I am not sure how to go from here. EDIT: Forgot to say that we can assume f is measurable.","I want to compare the usual norm on with the following: Now, for sure I have this: Because I want to now find some M such that But I am not sure how to go from here. EDIT: Forgot to say that we can assume f is measurable.","L^2(-1,1)  \Vert f \Vert_H^{2} = \int_{-1}^1 \vert f(x) \vert^2 \frac{1}{1+x^2}dx  \Vert f \Vert_H \leq \Vert f \Vert_{L^2}  \frac{1}{1+x^2} \leq 1 \Vert f \Vert_{L^2} \leq M \Vert f \Vert_{H}","['functional-analysis', 'inequality', 'lp-spaces', 'upper-lower-bounds']"
49,Is there a functional (i.e. infinite-dimensional) generalization of the second partial derivative test?,Is there a functional (i.e. infinite-dimensional) generalization of the second partial derivative test?,,"For a smooth function $f: \mathbb{R}^n \to \mathbb{R}$ , we can (usually) test whether a critical point ${\bf x}_0$ (at which ${\bf \nabla} f({\bf x}_0) = {\bf 0}$ ) is a local maximum, minimum, or saddle point via the second partial derivative test , which considers the signs of the eigenvalues of the Hessian matrix $H_{ij} := \partial_i \partial_j f$ . This result can be generalized to successively more general domains of $f$ : If the domain of $f$ is an arbitrary Riemannian manifold, then the test still works, but we instead consider the eigenvalues of the tensor $H^i_{\ \ j} = g^{ik} H_{kj}$ , where $H_{kj}$ is the Hessian tensor $H_{ij} := \nabla_i \nabla_j f = \partial_i \partial_j f - \Gamma_{ij}^k \partial_k f$ , where $\Gamma_{ij}^k$ are the Christoffel symbols (of the second kind). If the domain of $f$ is an arbitrary smooth manifold with a torsion-free connection, then the Hessian (as defined directly above) is a rank- $(2,0)$ tensor rather than a rank- $(1,1)$ tensor, so we can't talk about its eigenvalues. But we can still talk about the signature of the corresponding quadratic form by Sylvester's law of inertia , so I believe the test still works. If the domain of $f$ is an arbitrary smooth manifold without a connection, then there's no natural way to define a Hessian tensor away from the critical points. But at a critical point the Hessian tensor becomes independent of the connection, so we can define it (in local coordinates) by the usual Euclidean-space formula $H_{ij} := \partial_i \partial_j f$ and use Sylvester's law of inertia as above. Now if $f$ (which I will rename $S$ ) is a smooth functional $S[q]$ , then its domain is an infinite-dimensional space of functions $q(t)$ . In this case we can still talk about critical ""points"" of the functional, which are functions $q_0(t)$ at which $S[q]$ is stationary. For example, if $S$ takes the form $$S[q] = \int_a^b L \left( q(t), \frac{dq}{dt}, t \right) dt$$ for some constants $a$ and $b$ and differentiable function $L: \mathbb{R}^3 \to \mathbb{R}$ , then the critical ""points"" $q_0(t)$ are given by the Euler-Lagrange equation $$\frac{\partial L}{\partial q} - \frac{d}{dt} \frac{\partial L}{\partial \dot{q}} = 0.$$ Is there a functional generalization of the second partial derivative test that tests whether these critical functions $q_0(t)$ are local minima, local maxima, or saddle points of the functional $F[q]$ ? (I don't know anything about quadratic forms on infinite-dimensional vector spaces, so I have no idea if there's any notion of a signature, etc.)","For a smooth function , we can (usually) test whether a critical point (at which ) is a local maximum, minimum, or saddle point via the second partial derivative test , which considers the signs of the eigenvalues of the Hessian matrix . This result can be generalized to successively more general domains of : If the domain of is an arbitrary Riemannian manifold, then the test still works, but we instead consider the eigenvalues of the tensor , where is the Hessian tensor , where are the Christoffel symbols (of the second kind). If the domain of is an arbitrary smooth manifold with a torsion-free connection, then the Hessian (as defined directly above) is a rank- tensor rather than a rank- tensor, so we can't talk about its eigenvalues. But we can still talk about the signature of the corresponding quadratic form by Sylvester's law of inertia , so I believe the test still works. If the domain of is an arbitrary smooth manifold without a connection, then there's no natural way to define a Hessian tensor away from the critical points. But at a critical point the Hessian tensor becomes independent of the connection, so we can define it (in local coordinates) by the usual Euclidean-space formula and use Sylvester's law of inertia as above. Now if (which I will rename ) is a smooth functional , then its domain is an infinite-dimensional space of functions . In this case we can still talk about critical ""points"" of the functional, which are functions at which is stationary. For example, if takes the form for some constants and and differentiable function , then the critical ""points"" are given by the Euler-Lagrange equation Is there a functional generalization of the second partial derivative test that tests whether these critical functions are local minima, local maxima, or saddle points of the functional ? (I don't know anything about quadratic forms on infinite-dimensional vector spaces, so I have no idea if there's any notion of a signature, etc.)","f: \mathbb{R}^n \to \mathbb{R} {\bf x}_0 {\bf \nabla} f({\bf x}_0) = {\bf 0} H_{ij} := \partial_i \partial_j f f f H^i_{\ \ j} = g^{ik} H_{kj} H_{kj} H_{ij} := \nabla_i \nabla_j f = \partial_i \partial_j f - \Gamma_{ij}^k \partial_k f \Gamma_{ij}^k f (2,0) (1,1) f H_{ij} := \partial_i \partial_j f f S S[q] q(t) q_0(t) S[q] S S[q] = \int_a^b L \left( q(t), \frac{dq}{dt}, t \right) dt a b L: \mathbb{R}^3 \to \mathbb{R} q_0(t) \frac{\partial L}{\partial q} - \frac{d}{dt} \frac{\partial L}{\partial \dot{q}} = 0. q_0(t) F[q]","['functional-analysis', 'calculus-of-variations', 'quadratic-forms', 'stationary-point']"
50,Understanding the defintion of dual operators,Understanding the defintion of dual operators,,"I'm reading a book about Functional Analysis, and now I've reached to the part about dual operators. I'm having some difficulties understanding the following definition - Why $A^*$ is $Y^*\rightarrow X^*$ ? We know that $\phi \in Y^*$ , i.e., $\phi:Y\rightarrow Y$ and bounded. So the image of $\phi(Ax)$ should be in $Y^*$ , shouldn't it? How come it's in $X^*$ ? ( $X^*$ is reffered here as the space of all bounded linear functionals on $X$ ).","I'm reading a book about Functional Analysis, and now I've reached to the part about dual operators. I'm having some difficulties understanding the following definition - Why is ? We know that , i.e., and bounded. So the image of should be in , shouldn't it? How come it's in ? ( is reffered here as the space of all bounded linear functionals on ).",A^* Y^*\rightarrow X^* \phi \in Y^* \phi:Y\rightarrow Y \phi(Ax) Y^* X^* X^* X,"['linear-algebra', 'functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
51,How is the dual cone of a subspace its orthogonal complement?,How is the dual cone of a subspace its orthogonal complement?,,"From Boyd and Vandenberghe's Convex Optimization : A dual cone of a subspace $V \subseteq \Bbb R^n$ is it's orthogonal   complement. $V^{*} = \{y : v^Ty = 0, \forall v \in V\}$ but the dual cone is defined by: $V^{*} = \{y : v^Ty \ge 0, \forall v \in V\}$ . Why are there no vectors $v$ such that $v^Ty > 0$ ?",From Boyd and Vandenberghe's Convex Optimization : A dual cone of a subspace is it's orthogonal   complement. but the dual cone is defined by: . Why are there no vectors such that ?,"V \subseteq \Bbb R^n V^{*} = \{y : v^Ty = 0, \forall v \in V\} V^{*} = \{y : v^Ty \ge 0, \forall v \in V\} v v^Ty > 0","['functional-analysis', 'optimization', 'convex-analysis', 'convex-optimization']"
52,Is a Rational Rotation Algebra a Cutdown of a Matrix Algebra?,Is a Rational Rotation Algebra a Cutdown of a Matrix Algebra?,,"Let $\theta=m/n$ and let $A_{\theta}$ be the rational rotation C $^{*}$ -algebra with rotation angle $\theta$ . I.e., $A_{\theta}=C^{*}(u,v)$ , where $u$ and $v$ are unitaries such that $vu=e^{2\pi i \theta}uv$ . I know from here that $A_{\theta}$ is not a full matrix algebra. Given that $A_{\theta}$ has irreducible representations only of degree $n$ , is it true that $A_{\theta}$ is a cutdown of a full matrix algebra? I.e., Is there a space $C(X,M_{n}(\mathbb{C}))$ and a projection $p\in C(X,M_{n}(\mathbb{C}))$ , such that $A_{\theta}$ is isomorphic to $pC(X,M_{n}(\mathbb{C}))p$ ?","Let and let be the rational rotation C -algebra with rotation angle . I.e., , where and are unitaries such that . I know from here that is not a full matrix algebra. Given that has irreducible representations only of degree , is it true that is a cutdown of a full matrix algebra? I.e., Is there a space and a projection , such that is isomorphic to ?","\theta=m/n A_{\theta} ^{*} \theta A_{\theta}=C^{*}(u,v) u v vu=e^{2\pi i \theta}uv A_{\theta} A_{\theta} n A_{\theta} C(X,M_{n}(\mathbb{C})) p\in C(X,M_{n}(\mathbb{C})) A_{\theta} pC(X,M_{n}(\mathbb{C}))p","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
53,Integral Operator in $L^2$,Integral Operator in,L^2,"I was trying to do this exercise and I'm wondering if I figured it out well: I have $\mathcal{H} := L^2(0,1)$ and $T$ the operator with integral kernel $K(x,y) = \min\{x,y\}$ , $x,y \in [0,1]$ . I have to show that $T$ is compact and self-adjoint. To show that is compact I was thinking to say that because $\min\{x,y\} \in [0,1]$ then \begin{equation} \dim(\operatorname{Im}T) = 1 \end{equation} (The self adjointness I think is trivial..)So T belongs to finite rank operators and so it is compact. (Is this correct?) Then it asks me to find eigenvalues and eigenvectors of $T$ and here I really don't know how to proceed...","I was trying to do this exercise and I'm wondering if I figured it out well: I have and the operator with integral kernel , . I have to show that is compact and self-adjoint. To show that is compact I was thinking to say that because then (The self adjointness I think is trivial..)So T belongs to finite rank operators and so it is compact. (Is this correct?) Then it asks me to find eigenvalues and eigenvectors of and here I really don't know how to proceed...","\mathcal{H} := L^2(0,1) T K(x,y) = \min\{x,y\} x,y \in [0,1] T \min\{x,y\} \in [0,1] \begin{equation}
\dim(\operatorname{Im}T) = 1
\end{equation} T","['functional-analysis', 'eigenvalues-eigenvectors', 'compact-operators']"
54,Functional Analysis Reference Books,Functional Analysis Reference Books,,I'm taking a measure-theory based graduate course on Functional Analysis that covers essentially Folland's Chapter 5-9.  Is there another book that I could reference that perhaps has wordier exposition that explains things in a bit more detail (not Rudin please).  Thank you.,I'm taking a measure-theory based graduate course on Functional Analysis that covers essentially Folland's Chapter 5-9.  Is there another book that I could reference that perhaps has wordier exposition that explains things in a bit more detail (not Rudin please).  Thank you.,,"['real-analysis', 'functional-analysis', 'measure-theory']"
55,When does $\mathrm{End}(X)\cong X$?,When does ?,\mathrm{End}(X)\cong X,"I noticed in lecture that for any field $\mathbb F$ , take the one-dimensional vector space $V$ over $\mathbb F$ and write $\mathbb F\cong V\cong V^\ast=\mathrm{Hom}(V,\mathbb F)\cong\mathrm{Hom}(\mathbb F,\mathbb F)=\mathrm{End}(\mathbb F)$ . This is a very basic case, so I'm just wondering, more generally, for what kinds of spaces $X$ is $\mathrm{End}(X)\cong X$ ?","I noticed in lecture that for any field , take the one-dimensional vector space over and write . This is a very basic case, so I'm just wondering, more generally, for what kinds of spaces is ?","\mathbb F V \mathbb F \mathbb F\cong V\cong V^\ast=\mathrm{Hom}(V,\mathbb F)\cong\mathrm{Hom}(\mathbb F,\mathbb F)=\mathrm{End}(\mathbb F) X \mathrm{End}(X)\cong X","['linear-algebra', 'abstract-algebra', 'functional-analysis']"
56,Dual space of $R^n$ with $\max$ norm,Dual space of  with  norm,R^n \max,"So I think it's supposed to be the $(R^n,||.||_1)$, but I can't get one of the inequalities:  So if $\lambda_k = f(e_k)$, for $f$ in the dual, $x = (x_1,...,x_n) \in R^n$ and $\{e_k\}$ basis, then: $$|f(x)|  \leq \sum|x_k||\lambda_k| \leq \max|x_k|\sum|\lambda_k|$$ Thus $\||f||\leq \sum |\lambda_k|$ But I don't see how to get the reverse inequlity...","So I think it's supposed to be the $(R^n,||.||_1)$, but I can't get one of the inequalities:  So if $\lambda_k = f(e_k)$, for $f$ in the dual, $x = (x_1,...,x_n) \in R^n$ and $\{e_k\}$ basis, then: $$|f(x)|  \leq \sum|x_k||\lambda_k| \leq \max|x_k|\sum|\lambda_k|$$ Thus $\||f||\leq \sum |\lambda_k|$ But I don't see how to get the reverse inequlity...",,"['linear-algebra', 'functional-analysis', 'normed-spaces', 'dual-spaces']"
57,Let $E$ be a separable Banach space and $A$ an uncountable subset of the unit sphere. Does $A$ have accumulation point?,Let  be a separable Banach space and  an uncountable subset of the unit sphere. Does  have accumulation point?,E A A,"Let $E$ be a separable Banach space and let $S_E=\{x \in E \ | \ |x| = 1\}$. If $A \subset S_E$ is uncountable, must $A$ have a accumulation point? Obviously if $A$ is countable the answer is no if $E$ is infinite dimensional.","Let $E$ be a separable Banach space and let $S_E=\{x \in E \ | \ |x| = 1\}$. If $A \subset S_E$ is uncountable, must $A$ have a accumulation point? Obviously if $A$ is countable the answer is no if $E$ is infinite dimensional.",,"['real-analysis', 'functional-analysis']"
58,Unique solution of an ODE with a bounded positive right-hand-side,Unique solution of an ODE with a bounded positive right-hand-side,,"Consider the initial value problem $$\dot x(t) = F(t,x), \quad t \in (0,T)$$ with given initial datum $$x(0) = x_0 \in \mathbb R.$$ More precisely we consider the integral equation $$x(t)=x(0)+\int_0^t F(s,x(s))ds.$$ $F$ may be discontinuous, but let us assume that $$0 < m < F(t,x) < M.$$ The common counter-examples to uniqueness (or existence) of ODEs (or their associated integral equations) seem to rely on $F$ switching sign, or being close to $0$ , and my intuition is that the lower bound $m<F(x)$ should imply existence of a unique solution. Question 1: Is it true that there exist a solution under the assumptions above? Question 2: Can we also prove uniqueness?","Consider the initial value problem with given initial datum More precisely we consider the integral equation may be discontinuous, but let us assume that The common counter-examples to uniqueness (or existence) of ODEs (or their associated integral equations) seem to rely on switching sign, or being close to , and my intuition is that the lower bound should imply existence of a unique solution. Question 1: Is it true that there exist a solution under the assumptions above? Question 2: Can we also prove uniqueness?","\dot x(t) = F(t,x), \quad t \in (0,T) x(0) = x_0 \in \mathbb R. x(t)=x(0)+\int_0^t F(s,x(s))ds. F 0 < m < F(t,x) < M. F 0 m<F(x)","['functional-analysis', 'ordinary-differential-equations', 'measure-theory', 'reference-request', 'integral-equations']"
59,"Let Y be a normed linear space show Y is Banach if and only if there exists Banach X and linear, open, cts T:X -> Y","Let Y be a normed linear space show Y is Banach if and only if there exists Banach X and linear, open, cts T:X -> Y",,"I want to show the following: Let $Y$ be a normed linear space. Show $Y$ is a Banach space if and only if there exists a Banach space $X$ and a linear, continuous, open, and onto mapping $T: X \rightarrow Y$. One direction is straightforward: If $Y $ is Banach, take $X = Y, T = Id$, which is linear, open, continuous and onto. My proof for the other direction has one line that I believe is false, which I mark with (***). I'm using a theorem that states that if T(X) is closed, then $$ \exists M > 0 \text{ s.t. } \forall y \in T(X), \exists x \in X \text{ s.t. } Tx = y \text{ and } \|x \| \le M \| y \|. $$ Suppose $\{y_k\}$ is a Cauchy sequence in Y. Define $\tilde{y}_1 = y_1, \tilde{y}_k = y_k - y_{k-1}$. By open mapping theorem, $T(X)=Y$ is closed. Now find $\tilde{x}_k$ s.t. $T\tilde{x}_k = \tilde{y}_k \text{ and } \|\tilde{x}_k \| \le M \| \tilde{y}_k \|$.  Since $y_k$ is Cauchy, $\| \tilde{y}_k \| = \|y_k - y_{k-1}\|$ can be made arbitrarily small for large enough k. Hence $\tilde{x}_k \rightarrow 0$ in $X$.  Define $x_k = \sum_{i=1}^k \tilde{x}_i$. Now note that $y_k = \sum_{i=1}^k \tilde{y}_i = \sum_{i=1}^k T\tilde{x}_i = T(\sum_{i=1}^k \tilde{x}_i) = Tx_k$. (***) $\|x_m - x_n\| = \|\sum_{i=n+1}^m \tilde{x}_i \|= \sum_{i=n+1}^m\| \tilde{x}_i \|$. This shows that $\{x_k\}$ is Cauchy, hence converges to some $x\in X$. Since $T$ is onto $y:=Tx$ is in $Y$. By continuity, $y_k = T x_k \rightarrow T x  = y$. Hence Y is complete.","I want to show the following: Let $Y$ be a normed linear space. Show $Y$ is a Banach space if and only if there exists a Banach space $X$ and a linear, continuous, open, and onto mapping $T: X \rightarrow Y$. One direction is straightforward: If $Y $ is Banach, take $X = Y, T = Id$, which is linear, open, continuous and onto. My proof for the other direction has one line that I believe is false, which I mark with (***). I'm using a theorem that states that if T(X) is closed, then $$ \exists M > 0 \text{ s.t. } \forall y \in T(X), \exists x \in X \text{ s.t. } Tx = y \text{ and } \|x \| \le M \| y \|. $$ Suppose $\{y_k\}$ is a Cauchy sequence in Y. Define $\tilde{y}_1 = y_1, \tilde{y}_k = y_k - y_{k-1}$. By open mapping theorem, $T(X)=Y$ is closed. Now find $\tilde{x}_k$ s.t. $T\tilde{x}_k = \tilde{y}_k \text{ and } \|\tilde{x}_k \| \le M \| \tilde{y}_k \|$.  Since $y_k$ is Cauchy, $\| \tilde{y}_k \| = \|y_k - y_{k-1}\|$ can be made arbitrarily small for large enough k. Hence $\tilde{x}_k \rightarrow 0$ in $X$.  Define $x_k = \sum_{i=1}^k \tilde{x}_i$. Now note that $y_k = \sum_{i=1}^k \tilde{y}_i = \sum_{i=1}^k T\tilde{x}_i = T(\sum_{i=1}^k \tilde{x}_i) = Tx_k$. (***) $\|x_m - x_n\| = \|\sum_{i=n+1}^m \tilde{x}_i \|= \sum_{i=n+1}^m\| \tilde{x}_i \|$. This shows that $\{x_k\}$ is Cauchy, hence converges to some $x\in X$. Since $T$ is onto $y:=Tx$ is in $Y$. By continuity, $y_k = T x_k \rightarrow T x  = y$. Hence Y is complete.",,"['functional-analysis', 'proof-verification', 'linear-transformations', 'banach-spaces', 'normed-spaces']"
60,$c_{00}$ is not contained in maximal ideal,is not contained in maximal ideal,c_{00},"As the title says the problem is to show that $c_{00}$ is not contained in any maximal ideal ( $c_{00}$ is considered lying in $c_0$ ). I am not used nonunital algebras (rings) so I don't know how to approach to questions like this. Edit: $c_0 = \{ x_n \in \mathbb{C}, n \in \mathbb{N} : \lim x_n = 0 \}$ and $c_{00}$ is subspace (subalgebra) in $c_0$ with $x_n$ nonzero for only finitely  many indexes. I am sorry, I thought the notation was standard.","As the title says the problem is to show that is not contained in any maximal ideal ( is considered lying in ). I am not used nonunital algebras (rings) so I don't know how to approach to questions like this. Edit: and is subspace (subalgebra) in with nonzero for only finitely  many indexes. I am sorry, I thought the notation was standard.","c_{00} c_{00} c_0 c_0 = \{ x_n \in \mathbb{C}, n \in \mathbb{N} : \lim x_n = 0 \} c_{00} c_0 x_n","['functional-analysis', 'ideals', 'maximal-and-prime-ideals', 'banach-algebras']"
61,Rate of weak convergence of sin(nx),Rate of weak convergence of sin(nx),,"Since $\sin(n\cdot)$ converges weakly to zero, we know that $$ \lim_{n\rightarrow\infty} \int_a^b g(x)\sin(nx)\mathrm{d}x = \int_a^b g(x)\cdot 0\,\mathrm{d}x = 0 $$ holds for all $g\in L^2([a,b])$. Is there a way to find an explicit formula for the rate of convergence in the above equation, i.e. to determine a function $C$ depending on $n$ such that $$ \left|\int_a^b g(x)\sin(nx)\mathrm{d}x\right| \le C(n), \qquad \lim_{n\rightarrow\infty}C(n) = 0 $$ holds for all $g\in A$, where $A$ is a certain subset of $L^2([a,b])$? If, for example, $A$ is the set of constant functions with $||g||_{L^\infty} < M$ for all $g\in A$, then it is easy to show that $C(n) = \frac{2}{n}M$ is such an upper bound (by integrating $\sin(nx)$). I am particularly interested in the case where $A$ is the set of continuously differentiable (or smooth) functions with $||g||_{L^\infty}<M_1$ and $||\frac{\mathrm{d}}{\mathrm{d}x}g||_{L^\infty}<M_2$ for $M_1,M_2>0$.","Since $\sin(n\cdot)$ converges weakly to zero, we know that $$ \lim_{n\rightarrow\infty} \int_a^b g(x)\sin(nx)\mathrm{d}x = \int_a^b g(x)\cdot 0\,\mathrm{d}x = 0 $$ holds for all $g\in L^2([a,b])$. Is there a way to find an explicit formula for the rate of convergence in the above equation, i.e. to determine a function $C$ depending on $n$ such that $$ \left|\int_a^b g(x)\sin(nx)\mathrm{d}x\right| \le C(n), \qquad \lim_{n\rightarrow\infty}C(n) = 0 $$ holds for all $g\in A$, where $A$ is a certain subset of $L^2([a,b])$? If, for example, $A$ is the set of constant functions with $||g||_{L^\infty} < M$ for all $g\in A$, then it is easy to show that $C(n) = \frac{2}{n}M$ is such an upper bound (by integrating $\sin(nx)$). I am particularly interested in the case where $A$ is the set of continuously differentiable (or smooth) functions with $||g||_{L^\infty}<M_1$ and $||\frac{\mathrm{d}}{\mathrm{d}x}g||_{L^\infty}<M_2$ for $M_1,M_2>0$.",,['functional-analysis']
62,Example to linear but not continuous,Example to linear but not continuous,,"We know that when $(X,\|\cdot\|_X)$ is finite dimensional normed space and $(Y,\|\cdot\|_Y)$ is arbitrary dimensional normed space if $T:X \to Y$ is linear then it is continuous (or bounded) But I cannot imagine example for when $(X,\|\cdot\|_X)$ and $(Y,\|\cdot\|_Y)$ are arbitrary dimensional normed spaces $T:X \to Y$ is linear and not bounded or continuous. Could someone give any simple example please? Thanks","We know that when $(X,\|\cdot\|_X)$ is finite dimensional normed space and $(Y,\|\cdot\|_Y)$ is arbitrary dimensional normed space if $T:X \to Y$ is linear then it is continuous (or bounded) But I cannot imagine example for when $(X,\|\cdot\|_X)$ and $(Y,\|\cdot\|_Y)$ are arbitrary dimensional normed spaces $T:X \to Y$ is linear and not bounded or continuous. Could someone give any simple example please? Thanks",,"['functional-analysis', 'vector-spaces', 'normed-spaces']"
63,Is weakly compact subset weakly separable?,Is weakly compact subset weakly separable?,,"Let $X$ be a Banach space and $K$ be a weakly compact subset of $X$, i.e. compact set with respect to the $\sigma(X, X^{*})$-topology. Is it true that $K$ is weakly separable?  Since weak topology is never metrizable for infinite dimensional space, it is impossible to construct a countable dense subset using a metric. Also, I tried to use Eberlein-Smulian theorem, which states that weakly compactness is equivalent to weakly sequentially compactness. But this isn't helpful to me.","Let $X$ be a Banach space and $K$ be a weakly compact subset of $X$, i.e. compact set with respect to the $\sigma(X, X^{*})$-topology. Is it true that $K$ is weakly separable?  Since weak topology is never metrizable for infinite dimensional space, it is impossible to construct a countable dense subset using a metric. Also, I tried to use Eberlein-Smulian theorem, which states that weakly compactness is equivalent to weakly sequentially compactness. But this isn't helpful to me.",,['functional-analysis']
64,A corollary of Hahn–Banach theorem and a generalized limit function of $\ell_\infty$,A corollary of Hahn–Banach theorem and a generalized limit function of,\ell_\infty,"A corollary of Hahn–Banach theorem states that Let $E$ be a normed vector space, $M$ a proper closed subspace and $x \in E$. If $d(x,M) = \delta > 0$, so exists $f \in E'$ such that $\|f\|=1$, $f(x)=\delta$ and $f(m)=0$  $\forall m \in M $. Consider $T: \ell_\infty \rightarrow \ell_\infty$ a bounded linear operator defined by $$T(x_1,x_2,x_3,\dots) = (x_2,x_3,\dots).$$ Let $M=\{ x-T(x) : x \in \ell_\infty\}$, so $M$ is a subspace of $\ell_\infty$. If $e=(1,1,1,\dots) \in \ell_\infty$, so $d(e,M)=1>0$. Then, applying the corollary above in $\overline{M} $, exists $f \in \ell_\infty'$ such that $\|f\|=1$, $f(e)=d(x, \overline{M}) = d(e, M) =1$ and $f(x)=0~\forall x \in M\subset \overline{M} $. I was able to show that $$f(x_1,x_2,x_3,\dots) = f(x_2,x_3,\dots) ~~\forall (x_n) \in \ell_\infty.$$ Besides that, we have that $\forall x = (x_n) \in c = \{ (x_n) \in \ell_\infty : x_n \text{ is convergent} \}$ $$f(x) = \lim_{n \rightarrow \infty} x_n$$ Now, let $x=(x_n), y=(y_n) \in \ell_\infty$ such that $x_n \geq y_n$ $\forall n \in \mathbb{N}$. How can I show that $f(x) \geq f(y)$?","A corollary of Hahn–Banach theorem states that Let $E$ be a normed vector space, $M$ a proper closed subspace and $x \in E$. If $d(x,M) = \delta > 0$, so exists $f \in E'$ such that $\|f\|=1$, $f(x)=\delta$ and $f(m)=0$  $\forall m \in M $. Consider $T: \ell_\infty \rightarrow \ell_\infty$ a bounded linear operator defined by $$T(x_1,x_2,x_3,\dots) = (x_2,x_3,\dots).$$ Let $M=\{ x-T(x) : x \in \ell_\infty\}$, so $M$ is a subspace of $\ell_\infty$. If $e=(1,1,1,\dots) \in \ell_\infty$, so $d(e,M)=1>0$. Then, applying the corollary above in $\overline{M} $, exists $f \in \ell_\infty'$ such that $\|f\|=1$, $f(e)=d(x, \overline{M}) = d(e, M) =1$ and $f(x)=0~\forall x \in M\subset \overline{M} $. I was able to show that $$f(x_1,x_2,x_3,\dots) = f(x_2,x_3,\dots) ~~\forall (x_n) \in \ell_\infty.$$ Besides that, we have that $\forall x = (x_n) \in c = \{ (x_n) \in \ell_\infty : x_n \text{ is convergent} \}$ $$f(x) = \lim_{n \rightarrow \infty} x_n$$ Now, let $x=(x_n), y=(y_n) \in \ell_\infty$ such that $x_n \geq y_n$ $\forall n \in \mathbb{N}$. How can I show that $f(x) \geq f(y)$?",,['functional-analysis']
65,Discontinuous linear operator,Discontinuous linear operator,,"Let $X = C ^ \infty ([0,1] , \mathbb R )$ and let $\|\cdot\|$ be any norm   of $X$. Define the operator $T:X\to X$ by $T(f) = \frac{df}{dx}$. Show that $T$ is not a continuous linear operator from $( X , \|\cdot\| )$   into $(X , \|\cdot\| )$, Hint : Use the function $f_a (x) = \exp(ax) , a \in \mathbb R$. My answer is : $T$ is discountinuous if there is $f_a (x)  , a \in \mathbb R$, $X = C ^ \infty ([0,1] , \mathbb R )$ such that $\|Tf_a\| \to \infty$ as $a \to \infty$. $\|Tf_a\|= \|T(e^{ax}) \| = \|a e^{ax} \| \to \infty$ as $a \to \infty$. Thus $T$ is not continuous. Is my answer true?","Let $X = C ^ \infty ([0,1] , \mathbb R )$ and let $\|\cdot\|$ be any norm   of $X$. Define the operator $T:X\to X$ by $T(f) = \frac{df}{dx}$. Show that $T$ is not a continuous linear operator from $( X , \|\cdot\| )$   into $(X , \|\cdot\| )$, Hint : Use the function $f_a (x) = \exp(ax) , a \in \mathbb R$. My answer is : $T$ is discountinuous if there is $f_a (x)  , a \in \mathbb R$, $X = C ^ \infty ([0,1] , \mathbb R )$ such that $\|Tf_a\| \to \infty$ as $a \to \infty$. $\|Tf_a\|= \|T(e^{ax}) \| = \|a e^{ax} \| \to \infty$ as $a \to \infty$. Thus $T$ is not continuous. Is my answer true?",,"['functional-analysis', 'proof-verification', 'continuity', 'operator-theory']"
66,Commutator of bounded operators and tensor product,Commutator of bounded operators and tensor product,,"Let $E$ be an infinite-dimensional complex Hilbert space, $E\otimes E$ be the Hilbert space tensor product and $$\mathcal{L}(E)^+=\left\{A\in \mathcal{L}(E);\,\langle Ax,x\rangle\geq 0,\;\forall\;x\in E\;\right\}.$$ Let $A,B,C,D\in \mathcal{L}(E)$ and $S_1,S_2\in \mathcal{L}(E)^+$ be non zero operators such that $$(S_1\otimes S_2)[A\otimes C,B\otimes D]=0.$$ I want to find sufficient conditions under which $S_1[A,B]=S_2[C,D]=0$ i.e. $S_1AB=S_1BA$ and $S_2CD=S_2DC$ . My attempt: Since $(S_1\otimes S_2)[A\otimes C,B\otimes D]=0$ , then $(S_1\otimes S_2)(A\otimes C)(B\otimes D)=(S_1\otimes S_2)(B\otimes D)(A\otimes C)$ . Hence $$S_1AB\otimes S_2CD=S_1BA\otimes S_2DC.$$ By using the following result: Lemma: Let $A_1, A_2,B_1, B_2\in \mathcal{L}(E)$ be non-zero operators. The following conditions are equivalent: $A_1\otimes B_1=A_2\otimes B_2$ . There exists $z\in \mathbb{C}^*$ such that $A_1 =zA_2$ and $B_1= z^{-1}B_2$ . We deduce the existence of $z\in \mathbb{C}^*$ such that $S_1AB=zS_1BA$ and $S_2CD=z^{-1}S_2DC$ . When we get $$z=1?$$","Let be an infinite-dimensional complex Hilbert space, be the Hilbert space tensor product and Let and be non zero operators such that I want to find sufficient conditions under which i.e. and . My attempt: Since , then . Hence By using the following result: Lemma: Let be non-zero operators. The following conditions are equivalent: . There exists such that and . We deduce the existence of such that and . When we get","E E\otimes E \mathcal{L}(E)^+=\left\{A\in \mathcal{L}(E);\,\langle Ax,x\rangle\geq 0,\;\forall\;x\in E\;\right\}. A,B,C,D\in \mathcal{L}(E) S_1,S_2\in \mathcal{L}(E)^+ (S_1\otimes S_2)[A\otimes C,B\otimes D]=0. S_1[A,B]=S_2[C,D]=0 S_1AB=S_1BA S_2CD=S_2DC (S_1\otimes S_2)[A\otimes C,B\otimes D]=0 (S_1\otimes S_2)(A\otimes C)(B\otimes D)=(S_1\otimes S_2)(B\otimes D)(A\otimes C) S_1AB\otimes S_2CD=S_1BA\otimes S_2DC. A_1, A_2,B_1, B_2\in \mathcal{L}(E) A_1\otimes B_1=A_2\otimes B_2 z\in \mathbb{C}^* A_1 =zA_2 B_1= z^{-1}B_2 z\in \mathbb{C}^* S_1AB=zS_1BA S_2CD=z^{-1}S_2DC z=1?","['functional-analysis', 'operator-theory', 'tensor-products']"
67,Dual and bidual spaces of $B(H)$ in norm topology,Dual and bidual spaces of  in norm topology,B(H),"I would like to ask whether any description of the dual and double dual spaces exists for the Banach space $B(H)$ - space of bounded linear operators on infinitely dimensional Hilbert space. Can we identify them with some other known Banach spaces, such as we do with the duals in other topologies on $B(H)$?","I would like to ask whether any description of the dual and double dual spaces exists for the Banach space $B(H)$ - space of bounded linear operators on infinitely dimensional Hilbert space. Can we identify them with some other known Banach spaces, such as we do with the duals in other topologies on $B(H)$?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'dual-spaces']"
68,Spectral theorem for Fourier transform,Spectral theorem for Fourier transform,,"The Fourier transform restricts to an isometry $F$ of the subspace of real even functions in $L^2(\mathbb{R}^n)$. Also $F$ is self adjoint since $$\int F(u)v = \int u F(v)$$ for real even functions. If this is correct, how does the spectral theorem reads when applied to $F$? Namely, what are the spectrum (I guess $-1$ and $1$) and the projection-valued measure? Can we describe eigenspaces explicitly if they exist?","The Fourier transform restricts to an isometry $F$ of the subspace of real even functions in $L^2(\mathbb{R}^n)$. Also $F$ is self adjoint since $$\int F(u)v = \int u F(v)$$ for real even functions. If this is correct, how does the spectral theorem reads when applied to $F$? Namely, what are the spectrum (I guess $-1$ and $1$) and the projection-valued measure? Can we describe eigenspaces explicitly if they exist?",,['functional-analysis']
69,"On $\mathcal{C}([0,1])$, whether the operator $(\Lambda f)(x)=xf(x)$ is compact.","On , whether the operator  is compact.","\mathcal{C}([0,1]) (\Lambda f)(x)=xf(x)","On the Banach space $\mathcal{C}([0,1])$, whether the operator  $(\Lambda f)(x)=xf(x)$ is compact. We use the following definition of compact operator. A bounded linear operator $\Lambda:X \to Y$ is compact if, for every bounded sequence $(x_n)_{n\ge1}$ of points in $X$, there exists a subsequence $(x_{n_j})_{j \ge 1}$ such that $\Lambda x_{n_j}$ converges. Intuitively, I think it is not compact, but I cannot find a sequence as a counterexample. Can someone give a counterexample or some hints of the proof?","On the Banach space $\mathcal{C}([0,1])$, whether the operator  $(\Lambda f)(x)=xf(x)$ is compact. We use the following definition of compact operator. A bounded linear operator $\Lambda:X \to Y$ is compact if, for every bounded sequence $(x_n)_{n\ge1}$ of points in $X$, there exists a subsequence $(x_{n_j})_{j \ge 1}$ such that $\Lambda x_{n_j}$ converges. Intuitively, I think it is not compact, but I cannot find a sequence as a counterexample. Can someone give a counterexample or some hints of the proof?",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces']"
70,Show that the following is a vector space,Show that the following is a vector space,,"I am asked to prove that  $$ X=\left\{x=(x_n)_{n\in \mathbb N} :\sum_{n\in \mathbb N} |x_n|^{p(n)}<\infty \right\}$$ with $p(n)>0$ is a linear space iff $\sup_n p(n)<\infty $ The direction $(\Leftarrow)$, that is, that $\sup_n p(n)<\infty$ implies $X$ is linear is not that difficult. I do not know how to prove the other direction $(\Rightarrow)$.","I am asked to prove that  $$ X=\left\{x=(x_n)_{n\in \mathbb N} :\sum_{n\in \mathbb N} |x_n|^{p(n)}<\infty \right\}$$ with $p(n)>0$ is a linear space iff $\sup_n p(n)<\infty $ The direction $(\Leftarrow)$, that is, that $\sup_n p(n)<\infty$ implies $X$ is linear is not that difficult. I do not know how to prove the other direction $(\Rightarrow)$.",,"['linear-algebra', 'functional-analysis', 'vector-spaces']"
71,"Show that closed subspace of differentiable functions is of finite dimension (using Arzela-Ascoli's, Riesz', and Banach's theorems)","Show that closed subspace of differentiable functions is of finite dimension (using Arzela-Ascoli's, Riesz', and Banach's theorems)",,"Let $F\subseteq C^1([0,1],\mathbb{R})$ be a closed subspace of $C([0,1],\mathbb{R})$. Show that $F$ is of finite dimension. So, I considered the norm $\Vert f\Vert_1=\Vert f\Vert_\infty+\Vert f'\Vert_\infty$ and showed that $(F,\Vert\cdot\Vert_1)$ is a Banach space. Next, using Arzela-Ascoli, I showed that $\overline{\mathbb{B}}_{(F,\Vert\cdot\Vert_1)}(0,1)$ is compact in $(F,\Vert\cdot\Vert_\infty)$. At this point, I got help and was told to show that $\Vert\cdot\Vert_\infty$ and $\Vert\cdot\Vert_1$ are equivalent norms on $F$ and that I could use the open mapping theorem to do so... How? The next step would be to use the Riesz compactness theorem to conclude that $F$ is, in fact, of finite dimension. But, in which step, exactly, did we need the closedness of $F$? I have the feeling of not having talked about it explicitly.","Let $F\subseteq C^1([0,1],\mathbb{R})$ be a closed subspace of $C([0,1],\mathbb{R})$. Show that $F$ is of finite dimension. So, I considered the norm $\Vert f\Vert_1=\Vert f\Vert_\infty+\Vert f'\Vert_\infty$ and showed that $(F,\Vert\cdot\Vert_1)$ is a Banach space. Next, using Arzela-Ascoli, I showed that $\overline{\mathbb{B}}_{(F,\Vert\cdot\Vert_1)}(0,1)$ is compact in $(F,\Vert\cdot\Vert_\infty)$. At this point, I got help and was told to show that $\Vert\cdot\Vert_\infty$ and $\Vert\cdot\Vert_1$ are equivalent norms on $F$ and that I could use the open mapping theorem to do so... How? The next step would be to use the Riesz compactness theorem to conclude that $F$ is, in fact, of finite dimension. But, in which step, exactly, did we need the closedness of $F$? I have the feeling of not having talked about it explicitly.",,"['real-analysis', 'functional-analysis', 'banach-spaces', 'compactness', 'arzela-ascoli']"
72,Defining the range and domain of Composite functions as well as plotting graphs of composite functions,Defining the range and domain of Composite functions as well as plotting graphs of composite functions,,"Consider a function $$f(x)=\vert{\vert {x-3} \vert -2}\vert$$ for $0\le x\le 4$ And $$g(x)= 4-\vert {2-x}\vert$$ for $-1\le x\le 3$ Where $\vert .\vert$ represents modulus function. Now the problem is that I want to draw the graph of $f(g(x))$. Now I could make cases by the finding the critical points of the modulus functions and then plot the graph. But this seems to be a very tedious task. I want to know if there is any other way to plot the graph of such composite functions without taking so much of cases.  Any help would be greatly appreciated. $\mathbf {Edit :} $ CY Aries' method seems to be very appropriate for this question but what if the question asks for some cubic or quadratic function. e. g.  $$f(x) = \begin{cases} 1+x^3,  & \text{$x\le 0$} \\ x^2-1, & \text{$x\ge 0$} \end{cases}$$ and $$g(x) = \begin{cases} (x-1)^{\frac{1}{3}},  & \text{$x\le 0$} \\ (x+1)^{\frac{1}{2}}, & \text{$x\ge 0$} \end{cases}$$ Then plot $g(f(x))$. Now that method won't work here. I am also supposed to define the non-uniform function $g(f(x))$","Consider a function $$f(x)=\vert{\vert {x-3} \vert -2}\vert$$ for $0\le x\le 4$ And $$g(x)= 4-\vert {2-x}\vert$$ for $-1\le x\le 3$ Where $\vert .\vert$ represents modulus function. Now the problem is that I want to draw the graph of $f(g(x))$. Now I could make cases by the finding the critical points of the modulus functions and then plot the graph. But this seems to be a very tedious task. I want to know if there is any other way to plot the graph of such composite functions without taking so much of cases.  Any help would be greatly appreciated. $\mathbf {Edit :} $ CY Aries' method seems to be very appropriate for this question but what if the question asks for some cubic or quadratic function. e. g.  $$f(x) = \begin{cases} 1+x^3,  & \text{$x\le 0$} \\ x^2-1, & \text{$x\ge 0$} \end{cases}$$ and $$g(x) = \begin{cases} (x-1)^{\frac{1}{3}},  & \text{$x\le 0$} \\ (x+1)^{\frac{1}{2}}, & \text{$x\ge 0$} \end{cases}$$ Then plot $g(f(x))$. Now that method won't work here. I am also supposed to define the non-uniform function $g(f(x))$",,"['functional-analysis', 'functions', 'graphing-functions']"
73,A problem about the inverse of Riesz's representation theorem,A problem about the inverse of Riesz's representation theorem,,"Let $X$ be an inner product space. For any bounded linear functional $f$ on X, there exists a unique $x_f \in X$ s.t. for any $x \in X$, $f(x)=\langle x, x_f\rangle$, and $\|f\|=\|x_f\|$. Show that $X$ is a Hilbert space. Remember: It is true that Riesz's representation theorem doesn't hold for an incomplete inner product space, but we cannot use it to solve this problem because they are completely different. Here's my idea: Let $\{x_n\}$ be a Cauchy sequence. For a given functional $f$, by the fact that $|\langle x_n, x_f\rangle| ≦ \|x_f\|\|x_n\|$, we have $\{\langle x_n, x_f\rangle\}$ is a Cauchy sequence. However, we can't immediately find a $x$ s.t. $\{\langle x_n, x_f\rangle\} \rightarrow \{\langle x, x_f\rangle\}$. Any hint will be most welcomed.","Let $X$ be an inner product space. For any bounded linear functional $f$ on X, there exists a unique $x_f \in X$ s.t. for any $x \in X$, $f(x)=\langle x, x_f\rangle$, and $\|f\|=\|x_f\|$. Show that $X$ is a Hilbert space. Remember: It is true that Riesz's representation theorem doesn't hold for an incomplete inner product space, but we cannot use it to solve this problem because they are completely different. Here's my idea: Let $\{x_n\}$ be a Cauchy sequence. For a given functional $f$, by the fact that $|\langle x_n, x_f\rangle| ≦ \|x_f\|\|x_n\|$, we have $\{\langle x_n, x_f\rangle\}$ is a Cauchy sequence. However, we can't immediately find a $x$ s.t. $\{\langle x_n, x_f\rangle\} \rightarrow \{\langle x, x_f\rangle\}$. Any hint will be most welcomed.",,"['functional-analysis', 'riesz-representation-theorem']"
74,"Does $(Ax)(t) = \int_{0}^{t} x(s) ds$ has eigenvectors for $A : C[0,1] \to C[0,1]$?",Does  has eigenvectors for ?,"(Ax)(t) = \int_{0}^{t} x(s) ds A : C[0,1] \to C[0,1]","The question is as follows: Consider the operator $A : C[0,1] \to C[0,1]$ given by $(Ax)(t) = \int_{0}^{t} x(s) ds.$ Does $A$ has eigenvectors? Also find its spectrum $\sigma(A)?$ $\textbf{Some efforts:}$ If $\lambda \neq 0$ were an eigenvalue of $A$ with an eigenvector $x$, then we have $x(t) = \frac{1}{\lambda} \int_{0}^{t} x(s) ds $. This means that $x$ is absolutly continuous and $x'(t) = \frac{x(t)}{\lambda}$ with initial value $x(0)=0$. This imply that $x(t) = 0$ for $t \in [0,1]$ is the only eigenvector. And since $\sigma(A)$ can not be empty, we have $\sigma(A) = \{ 0 \}$. And zero is not an eigenvalue of $A$. Can you please let me know if I have any misunderstanding and if my calculation is wrong? Thanks!","The question is as follows: Consider the operator $A : C[0,1] \to C[0,1]$ given by $(Ax)(t) = \int_{0}^{t} x(s) ds.$ Does $A$ has eigenvectors? Also find its spectrum $\sigma(A)?$ $\textbf{Some efforts:}$ If $\lambda \neq 0$ were an eigenvalue of $A$ with an eigenvector $x$, then we have $x(t) = \frac{1}{\lambda} \int_{0}^{t} x(s) ds $. This means that $x$ is absolutly continuous and $x'(t) = \frac{x(t)}{\lambda}$ with initial value $x(0)=0$. This imply that $x(t) = 0$ for $t \in [0,1]$ is the only eigenvector. And since $\sigma(A)$ can not be empty, we have $\sigma(A) = \{ 0 \}$. And zero is not an eigenvalue of $A$. Can you please let me know if I have any misunderstanding and if my calculation is wrong? Thanks!",,"['real-analysis', 'functional-analysis', 'operator-theory']"
75,"Is $W_0(A_1^*,A_2^*)=\overline{ W_0(A_1,A_2)}$?",Is ?,"W_0(A_1^*,A_2^*)=\overline{ W_0(A_1,A_2)}","Let $E$ be a complex Hilbert space. Let $A_1,A_2\in \mathcal{L}(E)$. Let \begin{eqnarray*} W_0(A_1,A_2) &=&\{(\lambda_1,\lambda_2)\in \mathbb{C}^2;\;\exists\,(x_n)_n;\;\|x_n\|=1,\;(\langle A_1 x_n\; ,\;x_n\rangle,\,\langle A_2 x_n\; ,\;x_n\rangle)\to (\lambda_1,\lambda_2),\\ &&\phantom{++++++++++}\;\hbox{and}\;\displaystyle\lim_{n\rightarrow+\infty}(\|A_1x_n\|^2+\|A_2x_n\|^2)=\|A_1\|^2+\|A_2\|^2\;\}. \end{eqnarray*} How to show that    $$W_0(A_1^*,A_2^*)=\overline{ W_0(A_1,A_2)}:=\{(\overline{\lambda_1},\overline{\lambda_2});\;(\lambda_1,\lambda_2)\in W_0(A_1,A_2)\,\}?$$ I try as follows: $(\lambda_1,\lambda_2)\in W_0(A_1^*,A_2^*)$ if and only if there exists $(y_n)_n$ such that $\|y_n\|=1$, $(\langle A_1 y_n\; ,\;y_n\rangle,\,\langle A_2 y_n\; ,\;y_n\rangle)\to (\overline{\lambda_1},\overline{\lambda_2})$ and $\displaystyle\lim_{n\rightarrow+\infty}(\|A_1^*y_n\|^2+\|A_2^*y_n\|^2)\rightarrow \|A_1\|^2+\|A_2\|^2$ I stuck here, because I think that $\|A_1^*y_n\|$ is not in general equal to  $\|A_1y_n\|$. If the result is false, I want to construct a counter-example. I think it is true only for normal operators. Thank you!!","Let $E$ be a complex Hilbert space. Let $A_1,A_2\in \mathcal{L}(E)$. Let \begin{eqnarray*} W_0(A_1,A_2) &=&\{(\lambda_1,\lambda_2)\in \mathbb{C}^2;\;\exists\,(x_n)_n;\;\|x_n\|=1,\;(\langle A_1 x_n\; ,\;x_n\rangle,\,\langle A_2 x_n\; ,\;x_n\rangle)\to (\lambda_1,\lambda_2),\\ &&\phantom{++++++++++}\;\hbox{and}\;\displaystyle\lim_{n\rightarrow+\infty}(\|A_1x_n\|^2+\|A_2x_n\|^2)=\|A_1\|^2+\|A_2\|^2\;\}. \end{eqnarray*} How to show that    $$W_0(A_1^*,A_2^*)=\overline{ W_0(A_1,A_2)}:=\{(\overline{\lambda_1},\overline{\lambda_2});\;(\lambda_1,\lambda_2)\in W_0(A_1,A_2)\,\}?$$ I try as follows: $(\lambda_1,\lambda_2)\in W_0(A_1^*,A_2^*)$ if and only if there exists $(y_n)_n$ such that $\|y_n\|=1$, $(\langle A_1 y_n\; ,\;y_n\rangle,\,\langle A_2 y_n\; ,\;y_n\rangle)\to (\overline{\lambda_1},\overline{\lambda_2})$ and $\displaystyle\lim_{n\rightarrow+\infty}(\|A_1^*y_n\|^2+\|A_2^*y_n\|^2)\rightarrow \|A_1\|^2+\|A_2\|^2$ I stuck here, because I think that $\|A_1^*y_n\|$ is not in general equal to  $\|A_1y_n\|$. If the result is false, I want to construct a counter-example. I think it is true only for normal operators. Thank you!!",,"['linear-algebra', 'functional-analysis']"
76,Removing points from the discrete spectrum of a self-adjoint operator,Removing points from the discrete spectrum of a self-adjoint operator,,"I'm currently following the chapter 6 of Gerald Teschl's book ""Mathematical Methods in Quantum Mechanics"" and got stuck in something that seems irrelevant but is killing me anyway. As a example of how inestable is the discrete spectrum, it is stated in the book that: Given an self-adjoint operator $A$ and $\lambda_0\in \sigma_{dis}(A)$, we can easily remove this eigenvalue with a finite rank perturbation of arbitrarily small norm. In fact, consider  $$A+\varepsilon P_{\{\lambda_0\}}(A).$$ While it is easy to see that such perturbation is of finite rank and its norm is arbitrarily small, understanding why $\lambda_0$ can not be an eigenvalue anymore is not clear at all. I'd appreciate any help with this.","I'm currently following the chapter 6 of Gerald Teschl's book ""Mathematical Methods in Quantum Mechanics"" and got stuck in something that seems irrelevant but is killing me anyway. As a example of how inestable is the discrete spectrum, it is stated in the book that: Given an self-adjoint operator $A$ and $\lambda_0\in \sigma_{dis}(A)$, we can easily remove this eigenvalue with a finite rank perturbation of arbitrarily small norm. In fact, consider  $$A+\varepsilon P_{\{\lambda_0\}}(A).$$ While it is easy to see that such perturbation is of finite rank and its norm is arbitrarily small, understanding why $\lambda_0$ can not be an eigenvalue anymore is not clear at all. I'd appreciate any help with this.",,"['functional-analysis', 'operator-theory', 'mathematical-physics', 'spectral-theory']"
77,Boundary conditions for spherical harmonics,Boundary conditions for spherical harmonics,,"How does the constraint that the solution to $ \\ $  $$\left((1-x^2)y'\right)' - \frac{m^2}{1-x^2}y = \lambda y$$ $ \\ $ be square integrable on $[-1,1]$, force the solution to be bounded at $\pm 1$?","How does the constraint that the solution to $ \\ $  $$\left((1-x^2)y'\right)' - \frac{m^2}{1-x^2}y = \lambda y$$ $ \\ $ be square integrable on $[-1,1]$, force the solution to be bounded at $\pm 1$?",,"['functional-analysis', 'ordinary-differential-equations', 'spherical-harmonics']"
78,Equivalent characterization of compactness for a bounded operator,Equivalent characterization of compactness for a bounded operator,,"This question is related to a question I asked yesterday: Toeplitz operator on Bergman space Consider a linear bounded operator $T: H \rightarrow H$, where $H$ is a Hilbert space of holomorphic functions on the unit disc $\mathbb{D}$ in $\mathbb{C}$ (in my case, even a reproducing kernel Hilbert space), and suppose that the unit ball in $H$ is a normal family (every sequence of the unit ball in $H$ has a subsequence that converges uniformly on compact subsets of $\mathbb{D}$). Is it true that $T$ is compact on $H$ if and only if every bounded sequence $(f_n)$ in $H$ with $$f_n \rightarrow 0$$ as $n \rightarrow \infty$ uniformly on compact subsets of $\mathbb{D}$ has a subsequence $(f_{n_k})$ such that $$Tf_{n_k} \rightarrow 0$$ as $k \rightarrow \infty$ in $H$? I am also interested in references where I may find similar results.","This question is related to a question I asked yesterday: Toeplitz operator on Bergman space Consider a linear bounded operator $T: H \rightarrow H$, where $H$ is a Hilbert space of holomorphic functions on the unit disc $\mathbb{D}$ in $\mathbb{C}$ (in my case, even a reproducing kernel Hilbert space), and suppose that the unit ball in $H$ is a normal family (every sequence of the unit ball in $H$ has a subsequence that converges uniformly on compact subsets of $\mathbb{D}$). Is it true that $T$ is compact on $H$ if and only if every bounded sequence $(f_n)$ in $H$ with $$f_n \rightarrow 0$$ as $n \rightarrow \infty$ uniformly on compact subsets of $\mathbb{D}$ has a subsequence $(f_{n_k})$ such that $$Tf_{n_k} \rightarrow 0$$ as $k \rightarrow \infty$ in $H$? I am also interested in references where I may find similar results.",,"['functional-analysis', 'operator-theory']"
79,Characterization of Parseval Frame,Characterization of Parseval Frame,,"Let $H$ be a Hilbert space, and let $e_j\in H$ for every $j\in\mathbb N$. Is it possible to show that $$\left\|f\right\|^2=\sum_{j=1}^\infty\left|\langle f,e_j\rangle\right|^2\text{ for every }f\in H\text{ if and only if }f=\sum_{j=1}^\infty\langle f,e_j\rangle e_j\text{ for every }f\in H\tag*{?}$$ I get the feeling that we need $e_j\perp e_k$ if $j\neq k$.","Let $H$ be a Hilbert space, and let $e_j\in H$ for every $j\in\mathbb N$. Is it possible to show that $$\left\|f\right\|^2=\sum_{j=1}^\infty\left|\langle f,e_j\rangle\right|^2\text{ for every }f\in H\text{ if and only if }f=\sum_{j=1}^\infty\langle f,e_j\rangle e_j\text{ for every }f\in H\tag*{?}$$ I get the feeling that we need $e_j\perp e_k$ if $j\neq k$.",,"['functional-analysis', 'analysis', 'hilbert-spaces', 'inner-products', 'orthogonality']"
80,Is it always okay to drop higher order terms out in Taylor approximation?,Is it always okay to drop higher order terms out in Taylor approximation?,,"In many books that one comes across with regarding statistics, function approximation, optimization etc. it is almost certain that you run into Taylor expansion, be it multidimensional or one-dimensional : $$f(x)=f(a)+\frac{f'(a)}{1!}(x-a)+\frac{f''(a)}{2!}(x-a)^2+\frac{f'''(a)}{3!}(x- a)^3+\cdots,$$ and almost always one can see the authors drop out the higher order terms in the Taylor approximations, i.e. terms with derivatives $\geq 3$. I came to realize that I've never seen a well justified explanation on why the terms with derivatives $\geq 3$ are always dropped out. My question is: What is the justification for this? Why the magic number of $3$? Why not $4$? or $900$? UPDATE: An example illustrating what partly motivated my question: Let us consider a situation where we approximate a probability distribution with the normal distribution using Fisher information. If I remember correctly, in normal approximation using Fisher information we also ""drop out"" higher orders than 3 out. Lets also say that we are dealing with an application where we need ""a very high precision"", higher than we can obtain with the ""2nd order"" normal approximation. In order to use the normal approximation, would we now need to derive a more higher order normal approximation?","In many books that one comes across with regarding statistics, function approximation, optimization etc. it is almost certain that you run into Taylor expansion, be it multidimensional or one-dimensional : $$f(x)=f(a)+\frac{f'(a)}{1!}(x-a)+\frac{f''(a)}{2!}(x-a)^2+\frac{f'''(a)}{3!}(x- a)^3+\cdots,$$ and almost always one can see the authors drop out the higher order terms in the Taylor approximations, i.e. terms with derivatives $\geq 3$. I came to realize that I've never seen a well justified explanation on why the terms with derivatives $\geq 3$ are always dropped out. My question is: What is the justification for this? Why the magic number of $3$? Why not $4$? or $900$? UPDATE: An example illustrating what partly motivated my question: Let us consider a situation where we approximate a probability distribution with the normal distribution using Fisher information. If I remember correctly, in normal approximation using Fisher information we also ""drop out"" higher orders than 3 out. Lets also say that we are dealing with an application where we need ""a very high precision"", higher than we can obtain with the ""2nd order"" normal approximation. In order to use the normal approximation, would we now need to derive a more higher order normal approximation?",,"['functional-analysis', 'statistics', 'taylor-expansion', 'approximation']"
81,"Let A be any C* algebra,prove $M_n(A^{**})\cong M_n(A)^{**}$","Let A be any C* algebra,prove",M_n(A^{**})\cong M_n(A)^{**},"Let A be any C* algebra,prove $M_n(A^{**})\cong M_n(A)^{**}$,where $A^{**}$ is the double dual of $A$.Who can give me any hints or any reference books about the isomorphism about matrix algebras. I'd like to thank in advance anyone who takes some time to help me out.","Let A be any C* algebra,prove $M_n(A^{**})\cong M_n(A)^{**}$,where $A^{**}$ is the double dual of $A$.Who can give me any hints or any reference books about the isomorphism about matrix algebras. I'd like to thank in advance anyone who takes some time to help me out.",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
82,Frechet Derivative of Evaluation function,Frechet Derivative of Evaluation function,,"This is an exercise from Jack K.Hales book on ODEs Let $X=C^1([0,1],\mathbb{R}^n) \times [0,1]$ and consider $$ w:X\longrightarrow \mathbb{R}^n $$ where $w(f,t)=f(t)\in \mathbb{R}^n$. The point is to show that $w$ is Frechet differentiable and calculate it's derivative. Some thoughts are that if we fix $f\in C^1([0,1],\mathbb{R}^n)$ then $$ |f(t+h)-f(t)+D_{t}(f)h|\leq r(t,h) $$ with $\frac{ r(t,h)}{h}\longrightarrow 0$ for some function $r$ and $D_{t}(f)$ denoting the total derivative of the vector valued $f$ at $t$. Now would it be correct to define the operator $$ D:X\longrightarrow \mathbb{R}^n $$ with $D(f,t)=D_{t}(f)$ to be the Frechet derivative of $w$?","This is an exercise from Jack K.Hales book on ODEs Let $X=C^1([0,1],\mathbb{R}^n) \times [0,1]$ and consider $$ w:X\longrightarrow \mathbb{R}^n $$ where $w(f,t)=f(t)\in \mathbb{R}^n$. The point is to show that $w$ is Frechet differentiable and calculate it's derivative. Some thoughts are that if we fix $f\in C^1([0,1],\mathbb{R}^n)$ then $$ |f(t+h)-f(t)+D_{t}(f)h|\leq r(t,h) $$ with $\frac{ r(t,h)}{h}\longrightarrow 0$ for some function $r$ and $D_{t}(f)$ denoting the total derivative of the vector valued $f$ at $t$. Now would it be correct to define the operator $$ D:X\longrightarrow \mathbb{R}^n $$ with $D(f,t)=D_{t}(f)$ to be the Frechet derivative of $w$?",,"['functional-analysis', 'ordinary-differential-equations', 'derivatives', 'frechet-derivative']"
83,Is the norm of an integral operator the essential supremum norm of its kernel?,Is the norm of an integral operator the essential supremum norm of its kernel?,,"Is the following true? Let $\mu$ be a probability measure and let $k\in L_\infty(\mu \otimes \mu)$. Define the operator $T_k\colon L_1(\mu)\to L_1(\mu)$ by $$(T_kf)(t) = \int k(t,x)f(x)\,\mu({\rm d}x).$$ Then $\|T_k\|=\|k\|_{L_\infty(\mu \otimes \mu)}$.","Is the following true? Let $\mu$ be a probability measure and let $k\in L_\infty(\mu \otimes \mu)$. Define the operator $T_k\colon L_1(\mu)\to L_1(\mu)$ by $$(T_kf)(t) = \int k(t,x)f(x)\,\mu({\rm d}x).$$ Then $\|T_k\|=\|k\|_{L_\infty(\mu \otimes \mu)}$.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
84,Extension of equivalent norms (Exercise 2.4 in “Linear Analysis” by Bollobás),Extension of equivalent norms (Exercise 2.4 in “Linear Analysis” by Bollobás),,"The following is Exercise 4 from Chapter 2 of Linear Analysis, an introductory course by Béla Bollobás. Let $X = (V, \|\cdot\|)$ be a normed space and $W$ a subspace of $V$ . Suppose $|\cdot|$ is a norm on $W$ which is equivalent to the restriction of $\|\cdot\|$ to $W$ . Show that there is a norm $\|\cdot\|_1$ on $V$ that is equivalent to $\|\cdot\|$ and whose restriction to $W$ is precisely $|\cdot|$ . ( Original scan ) In a solution of this question, must the Hahn–Banach theorem be used used or can we prove it without using Hahn–Banach?","The following is Exercise 4 from Chapter 2 of Linear Analysis, an introductory course by Béla Bollobás. Let be a normed space and a subspace of . Suppose is a norm on which is equivalent to the restriction of to . Show that there is a norm on that is equivalent to and whose restriction to is precisely . ( Original scan ) In a solution of this question, must the Hahn–Banach theorem be used used or can we prove it without using Hahn–Banach?","X = (V, \|\cdot\|) W V |\cdot| W \|\cdot\| W \|\cdot\|_1 V \|\cdot\| W |\cdot|","['functional-analysis', 'normed-spaces']"
85,Adjoint of Dirac operator,Adjoint of Dirac operator,,"I understand that a Dirac operator (on say a closed manifold $M$ and a Clifford bundle $E$) is formally self-adjoint, in the sense that for $s,t$ compactly supported smooth sections of $E$, it satisfies $$\langle Ds, t\rangle_{L^2(E)} = \langle s, Dt\rangle_{L^2(E)}.$$ My question: is $D$ still self-adjoint when viewed as a bounded operator between Sobolev spaces $H^2(M)\rightarrow H^0(M)$? My concern is that the adjoint of $D$ should be an operator from $H^0(M)\rightarrow H^2(M)$, but $D$ itself doesn't extend to a bounded operator between these two spaces.","I understand that a Dirac operator (on say a closed manifold $M$ and a Clifford bundle $E$) is formally self-adjoint, in the sense that for $s,t$ compactly supported smooth sections of $E$, it satisfies $$\langle Ds, t\rangle_{L^2(E)} = \langle s, Dt\rangle_{L^2(E)}.$$ My question: is $D$ still self-adjoint when viewed as a bounded operator between Sobolev spaces $H^2(M)\rightarrow H^0(M)$? My concern is that the adjoint of $D$ should be an operator from $H^0(M)\rightarrow H^2(M)$, but $D$ itself doesn't extend to a bounded operator between these two spaces.",,"['functional-analysis', 'differential-geometry']"
86,Show this a tempered distribution,Show this a tempered distribution,,"I want to show that $f(x) : = e^{ie^x}$ is a tempered distribution. Therefore I need to show that for all $\varphi \in \mathscr{S}(\mathbb{R})$, that $$\int_{\mathbb{R}} \varphi(x) e^{ie^x}dx < \infty.$$ Equivalently, I could show that $$\int_{\mathbb{R}} \varphi(x) \mathcal{F}(e^{ie^x})dx < \infty,$$ where $\mathcal{F}$ denotes the Fourier transform. I have had no luck with this as of yet.","I want to show that $f(x) : = e^{ie^x}$ is a tempered distribution. Therefore I need to show that for all $\varphi \in \mathscr{S}(\mathbb{R})$, that $$\int_{\mathbb{R}} \varphi(x) e^{ie^x}dx < \infty.$$ Equivalently, I could show that $$\int_{\mathbb{R}} \varphi(x) \mathcal{F}(e^{ie^x})dx < \infty,$$ where $\mathcal{F}$ denotes the Fourier transform. I have had no luck with this as of yet.",,"['functional-analysis', 'fourier-analysis']"
87,Lax-Milgram theorem on Banach space,Lax-Milgram theorem on Banach space,,"Lax-Milgram theorem states that If $B(,)$ is a symmetric,strictly positive and bounded bilinear form on Hilbert space $V$, then for any continuous functional $l$, there exists $u\in V$ s.t. $B(u,v)=l(v)$. I am wondering if this result can be extended to the case of Banach space,i.e. $B$ is defined on a Banach space $V$. By the condition of strictly positive and boundededness, we know that the topology of the Banach space is the same as the topology defined by bilinear form $B$, then we can use Riesz reprensentation theorem to prove it.","Lax-Milgram theorem states that If $B(,)$ is a symmetric,strictly positive and bounded bilinear form on Hilbert space $V$, then for any continuous functional $l$, there exists $u\in V$ s.t. $B(u,v)=l(v)$. I am wondering if this result can be extended to the case of Banach space,i.e. $B$ is defined on a Banach space $V$. By the condition of strictly positive and boundededness, we know that the topology of the Banach space is the same as the topology defined by bilinear form $B$, then we can use Riesz reprensentation theorem to prove it.",,['functional-analysis']
88,Closed and bounded subsets of $\ell_1$,Closed and bounded subsets of,\ell_1,"I am investigating closed and bounded subsets of $\ell_1$ endowed with the $\|\cdot\|_1$ norm. For concreteness, $$\ell_1 = \left\{x = (x_1,x_2,\dots)\ |\ \|x\|_1 = \sum_{i=1}^{\infty} |x_i| < \infty\right\}.$$ I am considering the following example. For all $n \in \mathbb{N}$, define the sequence $$\tilde{e}_n = (0,\dots,0,1 + 1/n,0,\dots).$$ That is, the $i$-th entry of $\tilde{e}_n$ is $0$ if $i \neq n$ and $1+1/n$ if $i = n$. Then set $A = \{\tilde{e}_1,\tilde{e}_2,\dots\} \subset \ell_1.$ Clearly $A$ is bounded, but is it closed? I believe it is vacuously closed since $A$ does not have any limit points. My end goal here is to exhibit a closed and bounded subset $A$ of $\ell_1$ such that the continuous function $f: \ell_1 \rightarrow \mathbb{R}$ defined by $f(x) = \sum_i x_i$ does not achieve its infimum on $A$.","I am investigating closed and bounded subsets of $\ell_1$ endowed with the $\|\cdot\|_1$ norm. For concreteness, $$\ell_1 = \left\{x = (x_1,x_2,\dots)\ |\ \|x\|_1 = \sum_{i=1}^{\infty} |x_i| < \infty\right\}.$$ I am considering the following example. For all $n \in \mathbb{N}$, define the sequence $$\tilde{e}_n = (0,\dots,0,1 + 1/n,0,\dots).$$ That is, the $i$-th entry of $\tilde{e}_n$ is $0$ if $i \neq n$ and $1+1/n$ if $i = n$. Then set $A = \{\tilde{e}_1,\tilde{e}_2,\dots\} \subset \ell_1.$ Clearly $A$ is bounded, but is it closed? I believe it is vacuously closed since $A$ does not have any limit points. My end goal here is to exhibit a closed and bounded subset $A$ of $\ell_1$ such that the continuous function $f: \ell_1 \rightarrow \mathbb{R}$ defined by $f(x) = \sum_i x_i$ does not achieve its infimum on $A$.",,"['real-analysis', 'functional-analysis', 'vector-spaces']"
89,Is the delta function in $L^2$ (even though it's not a function)?,Is the delta function in  (even though it's not a function)?,L^2,"I'm studying for a qualifying exam and in our study group someone asked the question whether the delta function is in $L^2$ spaces. My argument is that it is; since the delta function function can be approximated by a sequence of $L^2$ functions (say, Gaussian curves with decreasing spread), and $L^2$ spaces are complete, the delta function must be included in them as well, even though the delta function is not a proper function. This is still a question of controversy in our group, though. Is my thinking correct?","I'm studying for a qualifying exam and in our study group someone asked the question whether the delta function is in $L^2$ spaces. My argument is that it is; since the delta function function can be approximated by a sequence of $L^2$ functions (say, Gaussian curves with decreasing spread), and $L^2$ spaces are complete, the delta function must be included in them as well, even though the delta function is not a proper function. This is still a question of controversy in our group, though. Is my thinking correct?",,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'dirac-delta', 'complete-spaces']"
90,Is Jacobi Theta function same as Heat Kernel ? How to derive Jacobi Theta from Heat Kernel?,Is Jacobi Theta function same as Heat Kernel ? How to derive Jacobi Theta from Heat Kernel?,,"My understanding is that the Jacobi Theta function is fundamental solution of heat equation: $\displaystyle \vartheta (x,it)=1+2\sum _{n=1}^{\infty }\exp \left(-\pi n^{2}t\right)\cos(2\pi nx)$ The following heat kernel is also fundamental solution of heat equation: $\Phi (x,t)={\frac {1}{\sqrt {4\pi kt}}}\exp \left(-{\frac {x^{2}}{4kt}}\right)$ But I do not see how to expand above heat kernel to get Jacobi Theta function. Can anyone provide some hints on how to expand above heat kernel to get Jacobi Theta function ? Thank you.","My understanding is that the Jacobi Theta function is fundamental solution of heat equation: $\displaystyle \vartheta (x,it)=1+2\sum _{n=1}^{\infty }\exp \left(-\pi n^{2}t\right)\cos(2\pi nx)$ The following heat kernel is also fundamental solution of heat equation: $\Phi (x,t)={\frac {1}{\sqrt {4\pi kt}}}\exp \left(-{\frac {x^{2}}{4kt}}\right)$ But I do not see how to expand above heat kernel to get Jacobi Theta function. Can anyone provide some hints on how to expand above heat kernel to get Jacobi Theta function ? Thank you.",,"['complex-analysis', 'functional-analysis', 'ordinary-differential-equations', 'heat-equation']"
91,equivalence of Hilbert spaces,equivalence of Hilbert spaces,,"the question might be stupid, but I am confused. Let us consider the following Hilbert space $l_{2}^{W}$, the space of infinite sequences with a scalar product: $$ <X,Y> = \sum_{i=1}^{\infty}x_{i}y_{i}w_{i}, $$ for some vector $W= (w_{1},w_{2}, \dots)$ with $0 < w_{i} < \infty$ and $\limsup w_{i} < \infty$. I attempt to show that all spaces $l_{2}^{W}$ are all equivalent, i.e. norms generated by the scalar product are equivalent: for any $W_{1}$ and $W_{2}$ there exist $0 < C_{1} < C_{2}$ such that $C_{1} ||X||_{W_{2}} \leq ||X||_{W_{1}} \leq C_{2} ||X||_{W_{2}} $. Should one impose more constraints on the vector of weights then?","the question might be stupid, but I am confused. Let us consider the following Hilbert space $l_{2}^{W}$, the space of infinite sequences with a scalar product: $$ <X,Y> = \sum_{i=1}^{\infty}x_{i}y_{i}w_{i}, $$ for some vector $W= (w_{1},w_{2}, \dots)$ with $0 < w_{i} < \infty$ and $\limsup w_{i} < \infty$. I attempt to show that all spaces $l_{2}^{W}$ are all equivalent, i.e. norms generated by the scalar product are equivalent: for any $W_{1}$ and $W_{2}$ there exist $0 < C_{1} < C_{2}$ such that $C_{1} ||X||_{W_{2}} \leq ||X||_{W_{1}} \leq C_{2} ||X||_{W_{2}} $. Should one impose more constraints on the vector of weights then?",,"['real-analysis', 'functional-analysis', 'analysis', 'measure-theory', 'hilbert-spaces']"
92,"A question on a subspace of $C[0,1]$, that is closed in $L^{2}$","A question on a subspace of , that is closed in","C[0,1] L^{2}","Let $S$ be a subspace of $C[0,1]$, that is closed  as a subspace of $L^{2}[0,1]$. a. Show that $S$ is closed  in $(C[0,1], ||.||_{\infty})$. b. Show that there  is a constant $M$ such that for all $f\in S$, we have $||f||_{\infty} < M||f||_{2}$. c. Show that for each $y\in [0,1]$, there is a function $k_{y}$ in $L^{2}$, such that for all $f\in S$ we have $f(y)=\int k_{y}(x)f(x) dx$. My attempt: I have solved the first two questions. The first question follows from the fact that $||f||_{2}\leq ||f||_{\infty}$. Then part (b) is just the bounded inverse theorem. I am stuck at (c). I thought to define a map say $\phi: L^{2} \to \mathbb{R}$, given by $\phi(f)=f(y)$ , for a fixed $y\in [0,1]$. If $\phi$ is continuous then by Riesz's representation theorem there exists a $k_{y} \in L^{2}$ such that $$\phi(f)= \int k_{y}(x)f(x)dx = f(y)$$, and we are done. The second inequality can help in showing the continuity but only for $f\in S$. Is this map at all bounded? How can this be solved. Thanks in advance!!","Let $S$ be a subspace of $C[0,1]$, that is closed  as a subspace of $L^{2}[0,1]$. a. Show that $S$ is closed  in $(C[0,1], ||.||_{\infty})$. b. Show that there  is a constant $M$ such that for all $f\in S$, we have $||f||_{\infty} < M||f||_{2}$. c. Show that for each $y\in [0,1]$, there is a function $k_{y}$ in $L^{2}$, such that for all $f\in S$ we have $f(y)=\int k_{y}(x)f(x) dx$. My attempt: I have solved the first two questions. The first question follows from the fact that $||f||_{2}\leq ||f||_{\infty}$. Then part (b) is just the bounded inverse theorem. I am stuck at (c). I thought to define a map say $\phi: L^{2} \to \mathbb{R}$, given by $\phi(f)=f(y)$ , for a fixed $y\in [0,1]$. If $\phi$ is continuous then by Riesz's representation theorem there exists a $k_{y} \in L^{2}$ such that $$\phi(f)= \int k_{y}(x)f(x)dx = f(y)$$, and we are done. The second inequality can help in showing the continuity but only for $f\in S$. Is this map at all bounded? How can this be solved. Thanks in advance!!",,"['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-measure']"
93,Why is the space of finite Borel-measure dual to the space of finite continuous function.,Why is the space of finite Borel-measure dual to the space of finite continuous function.,,"Riesz-Representation-Theorem states that every positive linear functional $F$ for any finite continuous $f$ on a local compact space S one can find a unique borel measure, such that $$F(f)=\int f d\mu$$. Question: In the dual space there are not only positive linear functional. The dual space includes all linear functional. So according to the version of Riesz-representation theorem that I stated above, the set of finite borel-measure is only a subset of the dual space. What is the sufficient condition, that every element in the dual space can be written in the form of Riesz-Representation? Will the continuity of the functional help if we introduce the weak topology on the space? What about if I take a separable metrizable space S instead of local compact space S? Can we still apply the theorem?","Riesz-Representation-Theorem states that every positive linear functional $F$ for any finite continuous $f$ on a local compact space S one can find a unique borel measure, such that $$F(f)=\int f d\mu$$. Question: In the dual space there are not only positive linear functional. The dual space includes all linear functional. So according to the version of Riesz-representation theorem that I stated above, the set of finite borel-measure is only a subset of the dual space. What is the sufficient condition, that every element in the dual space can be written in the form of Riesz-Representation? Will the continuity of the functional help if we introduce the weak topology on the space? What about if I take a separable metrizable space S instead of local compact space S? Can we still apply the theorem?",,"['functional-analysis', 'riesz-representation-theorem']"
94,Is my proof for Schauder's theorem in non-Banach spaces correct?,Is my proof for Schauder's theorem in non-Banach spaces correct?,,"Schauder's theorem states: Let $X, Y$ be Banach spaces, let $T \in B(X, Y)$ be a bounded linear   operator. Then $T$ is compact $\iff$ $T'$ is compact, where $T' \in B(Y', X')$ is the dual operator. The $\implies$ direction is true if $X, Y$ are just normed spaces, see for example E. Kreyszig, Introductory Functional Analysis with Applications, Theorem 8.2-5, pp. 416 (you can find it on google). For the other direction I have a proof that also seems to work if $X, Y$ are just normed spaces. Is it correct? Let $T' \in B(Y', X')$ be compact. Using ""$\implies$"" we have that $T'': \in B(X'', Y'')$ is compact. Let $J_X \colon X \to X''$ be the canonical embedding, $J_Y$ similarly. It is known that $$ T'' J_X = J_Y T $$ It follows that $T = J_Y^{-1} T'' J_X$, which is well defined if you consider $J_Y^{-1} : J_y(Y) \to Y$ which is linear and bounded since it's norm-preserving. But then $T$ is compact since $T''$ is compact (If $A$ is compact and $B$ and $C$ are bounded operators, then $BAC$ is compact).","Schauder's theorem states: Let $X, Y$ be Banach spaces, let $T \in B(X, Y)$ be a bounded linear   operator. Then $T$ is compact $\iff$ $T'$ is compact, where $T' \in B(Y', X')$ is the dual operator. The $\implies$ direction is true if $X, Y$ are just normed spaces, see for example E. Kreyszig, Introductory Functional Analysis with Applications, Theorem 8.2-5, pp. 416 (you can find it on google). For the other direction I have a proof that also seems to work if $X, Y$ are just normed spaces. Is it correct? Let $T' \in B(Y', X')$ be compact. Using ""$\implies$"" we have that $T'': \in B(X'', Y'')$ is compact. Let $J_X \colon X \to X''$ be the canonical embedding, $J_Y$ similarly. It is known that $$ T'' J_X = J_Y T $$ It follows that $T = J_Y^{-1} T'' J_X$, which is well defined if you consider $J_Y^{-1} : J_y(Y) \to Y$ which is linear and bounded since it's norm-preserving. But then $T$ is compact since $T''$ is compact (If $A$ is compact and $B$ and $C$ are bounded operators, then $BAC$ is compact).",,['functional-analysis']
95,Non-negative operator & self-adjoint operator [duplicate],Non-negative operator & self-adjoint operator [duplicate],,"This question already has answers here : Show that a positive operator on a complex Hilbert space is self-adjoint (3 answers) Closed 7 years ago . I am wondering how to show that: if $A$ is a non-negative operator, then $A$ is self-adjoint. Def. 1. $A$ is non-negative if $\langle Ax,x \rangle \geq 0$ for $\forall x\in H$, where $H$ is a Hilbert space. Def. 2. $A$ is self-adjoint if $A = A^*$.","This question already has answers here : Show that a positive operator on a complex Hilbert space is self-adjoint (3 answers) Closed 7 years ago . I am wondering how to show that: if $A$ is a non-negative operator, then $A$ is self-adjoint. Def. 1. $A$ is non-negative if $\langle Ax,x \rangle \geq 0$ for $\forall x\in H$, where $H$ is a Hilbert space. Def. 2. $A$ is self-adjoint if $A = A^*$.",,"['linear-algebra', 'functional-analysis']"
96,First encounter of Sturm-Liouville problem,First encounter of Sturm-Liouville problem,,"I have been assigned to find a solution to a specific Sturm-Liouville problem as preparation for an upcoming interview. This is in fact the first time I've ever met this class of problems (being a second year mathematics student at university). Anyway I've done some research and had a good crack at the problem but I find myself not knowing whether anything I've done is right. Here is the phrasing of the question: Any linear second order ordinary differential equation can be written in the classical Sturm-Liouville form, $$L(y(x))=\lambda w(x)y(x),\;x\in[a,b],\;(1)$$ in which the operator, $L$, is self-adjoint. Typically, $(1)$ will be subject to boundary conditions of the form, $$A_1y(a) + B_1y′(a)=0,\;A_2y(b) + B_2y′(b)=0.\;(2)$$ The solution of $(1)$, subject to $(2)$, gives rise to an infinite set of eigenfunctions, $y_n(x)$, which are orthogonal with respect to one another and the weight function, $w(x)$. Each eigenfunction has an associated, real eigenvalue, $λ_n$. The conditions we are given to work with are: $$L = \frac{d^2}{dx^2} + 1,\;x ∈ [0, 1],$$   $$w(x) = 1,$$   $and,$   $$y(0) = 0,\,y'(1) = 0.$$ I am asked to find the analytic solution to this particular Sturm-Liouville problem which I worked out to be: $$y_n(x) = B_n\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right),\;n\in\mathbb Z$$ where $B_n$ is undetermined. I am asked to determine $B_n$ by imposing: $$\int_0^1y_n^2(x)\,dx=1.$$ Using this I found that $B_n=\pm\sqrt{2},$ which troubles me because in all the examples I've looked at regarding Sturm-Liouville problems a situation like this (where the constants are ambiguous) has not arisen. So I am worried I have made an error somewhere leading up to this. Anyway the next task is to represent $g(x)=x$ as an infinite series using the previously found eigenfunctions over the domain $x\in[0,1].$ Now I searched online for a method to do this and found this document: Non-homogeneous Sturm-Liouville problems . Looking at the top of the second page they give a formula for finding the coefficients/weightings to express any function over $[0,1]$ as a series of eigenfunctions. Using this and my eigenfunctions I found that $$x=\frac{8}{\pi ^2}\sum_{n=1}^\infty\frac{(-1)^n}{(2n+1)^2}\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right).$$ But I know this is completely wrong as I plotted this sum on MatLab to a sufficient number terms and it looked nothing like the function $g(x)=x$. Now if you've read this far that is much appreciated and any help you could provide would be fantastic as I really would like to do well in solving this problem. Of course I will continue to research into this topic (I've even bought a textbook on Sturm-Liouville theory!) and will keep this post updated as necessary.","I have been assigned to find a solution to a specific Sturm-Liouville problem as preparation for an upcoming interview. This is in fact the first time I've ever met this class of problems (being a second year mathematics student at university). Anyway I've done some research and had a good crack at the problem but I find myself not knowing whether anything I've done is right. Here is the phrasing of the question: Any linear second order ordinary differential equation can be written in the classical Sturm-Liouville form, $$L(y(x))=\lambda w(x)y(x),\;x\in[a,b],\;(1)$$ in which the operator, $L$, is self-adjoint. Typically, $(1)$ will be subject to boundary conditions of the form, $$A_1y(a) + B_1y′(a)=0,\;A_2y(b) + B_2y′(b)=0.\;(2)$$ The solution of $(1)$, subject to $(2)$, gives rise to an infinite set of eigenfunctions, $y_n(x)$, which are orthogonal with respect to one another and the weight function, $w(x)$. Each eigenfunction has an associated, real eigenvalue, $λ_n$. The conditions we are given to work with are: $$L = \frac{d^2}{dx^2} + 1,\;x ∈ [0, 1],$$   $$w(x) = 1,$$   $and,$   $$y(0) = 0,\,y'(1) = 0.$$ I am asked to find the analytic solution to this particular Sturm-Liouville problem which I worked out to be: $$y_n(x) = B_n\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right),\;n\in\mathbb Z$$ where $B_n$ is undetermined. I am asked to determine $B_n$ by imposing: $$\int_0^1y_n^2(x)\,dx=1.$$ Using this I found that $B_n=\pm\sqrt{2},$ which troubles me because in all the examples I've looked at regarding Sturm-Liouville problems a situation like this (where the constants are ambiguous) has not arisen. So I am worried I have made an error somewhere leading up to this. Anyway the next task is to represent $g(x)=x$ as an infinite series using the previously found eigenfunctions over the domain $x\in[0,1].$ Now I searched online for a method to do this and found this document: Non-homogeneous Sturm-Liouville problems . Looking at the top of the second page they give a formula for finding the coefficients/weightings to express any function over $[0,1]$ as a series of eigenfunctions. Using this and my eigenfunctions I found that $$x=\frac{8}{\pi ^2}\sum_{n=1}^\infty\frac{(-1)^n}{(2n+1)^2}\sin\left(\left(2n+1\right)\frac{\pi}{2}x\right).$$ But I know this is completely wrong as I plotted this sum on MatLab to a sufficient number terms and it looked nothing like the function $g(x)=x$. Now if you've read this far that is much appreciated and any help you could provide would be fantastic as I really would like to do well in solving this problem. Of course I will continue to research into this topic (I've even bought a textbook on Sturm-Liouville theory!) and will keep this post updated as necessary.",,"['functional-analysis', 'ordinary-differential-equations', 'sturm-liouville']"
97,"In $\ell^2(\mathbb{Z})$, using Fourier coefficients calculate the spectrum of the right-shift operator?","In , using Fourier coefficients calculate the spectrum of the right-shift operator?",\ell^2(\mathbb{Z}),"In $\ell^2(\mathbb{Z})$, what is the spectrum of the right-shift operator? I have looked at relevant posts on the website and noticed that someone had mentioned in hints that $\ell^2(\mathbb{Z})$ is $L^2(\mathbb{T})$ and hence the right-shift operator can be transformed into a multiplication operator. I am interested in this approach and could anyone show how this is achieved?","In $\ell^2(\mathbb{Z})$, what is the spectrum of the right-shift operator? I have looked at relevant posts on the website and noticed that someone had mentioned in hints that $\ell^2(\mathbb{Z})$ is $L^2(\mathbb{T})$ and hence the right-shift operator can be transformed into a multiplication operator. I am interested in this approach and could anyone show how this is achieved?",,"['functional-analysis', 'spectral-theory']"
98,A non-empty closed convex subset of a Banach space contains an open ball,A non-empty closed convex subset of a Banach space contains an open ball,,"In a Banach space $X$, I construct a non-empty closed and convex set $A$. The set $A$ satisfies two conditions: If $x\in A$, then $-x \in A$. $\displaystyle{X=\bigcup_{n\geq1} nA}$ Then to my intuition, I feel that $A$ contains an open ball centered at $0$. For each $x\in X$, we always can have $x/n\in A$ for some $n$. Then intuitively I can have many points clustered around $0$. What is the right way to prove this?","In a Banach space $X$, I construct a non-empty closed and convex set $A$. The set $A$ satisfies two conditions: If $x\in A$, then $-x \in A$. $\displaystyle{X=\bigcup_{n\geq1} nA}$ Then to my intuition, I feel that $A$ contains an open ball centered at $0$. For each $x\in X$, we always can have $x/n\in A$ for some $n$. Then intuitively I can have many points clustered around $0$. What is the right way to prove this?",,"['functional-analysis', 'banach-spaces']"
99,Uniform sum of positive upper semicontinuous functions is upper semicontinuous?,Uniform sum of positive upper semicontinuous functions is upper semicontinuous?,,"Let $X$ be a metric space. A real-valued function $f : X \rightarrow \mathbb{R}$ is upper semicontinuous if it satisfies one of the followings: $(1)$ For all $c \in \mathbb{R}$, its preimage $f^{-1}(-\infty,c)$ is open in $X$. $(2)$ For all $x \in X$ and all $\varepsilon>0$, there exists an open neighbourhood $U$ of $x$ such that for all $y \in U,$ we have $f(y) < f(x) + \varepsilon$. I know that finite sum of upper semicontinuous is upper semicontinuous. Question: Suppose for each natural number $n$ , $f_n$ is a non-negative upper semicontinuous function and $(f_n)$ is decreasing. Assume that $\sum_{n=1}^{\infty}(-1)^nf_n$ converges uniformly to $g$. Is $g$ an upper semicontinuous function?","Let $X$ be a metric space. A real-valued function $f : X \rightarrow \mathbb{R}$ is upper semicontinuous if it satisfies one of the followings: $(1)$ For all $c \in \mathbb{R}$, its preimage $f^{-1}(-\infty,c)$ is open in $X$. $(2)$ For all $x \in X$ and all $\varepsilon>0$, there exists an open neighbourhood $U$ of $x$ such that for all $y \in U,$ we have $f(y) < f(x) + \varepsilon$. I know that finite sum of upper semicontinuous is upper semicontinuous. Question: Suppose for each natural number $n$ , $f_n$ is a non-negative upper semicontinuous function and $(f_n)$ is decreasing. Assume that $\sum_{n=1}^{\infty}(-1)^nf_n$ converges uniformly to $g$. Is $g$ an upper semicontinuous function?",,"['real-analysis', 'functional-analysis', 'metric-spaces', 'uniform-convergence', 'semicontinuous-functions']"
