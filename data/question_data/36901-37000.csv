,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"What is the pdf of $Z=X/\max(X,Y)$ with $X,Y$ exponentials of lambda parameter?",What is the pdf of  with  exponentials of lambda parameter?,"Z=X/\max(X,Y) X,Y","Given $X,Y$ 2 independent r.v.'s both distributed as $\exp(λ)$, what is the pdf of $Z=X/\max(X,Y)$?","Given $X,Y$ 2 independent r.v.'s both distributed as $\exp(λ)$, what is the pdf of $Z=X/\max(X,Y)$?",,"['probability', 'probability-distributions', 'random-variables', 'convolution', 'actuarial-science']"
1,Cumulative Distribution Function of Sum two Weibull random variables,Cumulative Distribution Function of Sum two Weibull random variables,,"If $Y_0$ and $Y_1$ both have Weibull distribution i.e. $Y_0 \sim Weibull(\lambda_0,\beta_0)$ and $Y_1 \sim Weibull(\lambda_1,\beta_1)$  then what will be cumulative density function of $Y_0+Y_1$, i.e. $$\Pr(Y_0+Y_1<y)=\int_0^\infty \Pr(Y_0<y-z|z=Y_1)f_{Y_1}(Y_1)\ dY_1$$","If $Y_0$ and $Y_1$ both have Weibull distribution i.e. $Y_0 \sim Weibull(\lambda_0,\beta_0)$ and $Y_1 \sim Weibull(\lambda_1,\beta_1)$  then what will be cumulative density function of $Y_0+Y_1$, i.e. $$\Pr(Y_0+Y_1<y)=\int_0^\infty \Pr(Y_0<y-z|z=Y_1)f_{Y_1}(Y_1)\ dY_1$$",,"['probability', 'statistics', 'probability-distributions']"
2,Sum of product partitions of divisors,Sum of product partitions of divisors,,"Let $M(n)$ be the the set of the multiplicative partitions of $n$, and let $D(n)$ be the set of the sum of the multiplicative partitions of the divisors of $n$. eg $M(30)=\{\{30\},\{2,15\},\{3, 10\}, \{5, 6\}, \{2, 3, 5\}\}$ and $D(30)=\{30,17,13,11,10\}$ This can be normalised and plotted by pairing up the ordered set $\log D$ with $x=\{1,2,3\dots\}$, which in this case would yield the plot points $\{\{1,\log10\},\{2,\log11\},\{3,\log13\},\{4,\log17\},\{5,\log30\}\}$. It appears that  these points are normally distributed: (plot of $\log F(6\ 469\ 693\ 230)$), which is fairly obvious intuitively. Is this an incarnation of the Erdős–Kac theorem ? Likely proving this would be difficult? Notes Mathematica code for primorials (which are easiest to compute for large $n$): << Combinatorica` primorial = 10; a = Range[primorial]; b = Thread[a -> Prime[a]]; c = Apply[Times, SetPartitions[a] /. b, {2}]; ListLinePlot[Log[Sort[Map[Total[c[[#]]] &, Range[Length[c]]]]]] General code for any $n$: n = 1000; α[1, r_] := α[1, r] = 1;  α[n_, r_] := α[n, r] =  Module[{s, i}, s = Select[Divisors[n], 1 < # <= r &]; Sum[α[n/s[[i]], s[[i]]], {i, 1, Length[s]}]]; β[n_]:= α[n, n]; γ[lst_, p_] :=  Module[{t, i, j}, Union[Flatten[Table[t = lst[[i]]; t[[j]] = p*t[[j]]; Sort[t], {i, Length[lst]}, {j, Length[lst[[i]]]}], 1],  Table[Sort[Append[lst[[i]], p]], {i, Length[lst]}]]]; δ[n_] := Module[{i, j, p, e, lst = {{}}},{p, e} = Transpose[FactorInteger[n]]; Do[lst = γ[lst, p[[i]]], {i, Length[p]}, {j, e[[i]]}]; lst]; ListLinePlot[Log[Sort[Map[Total[δ[n][[#]]] &, Range[β[n]]]]],  InterpolationOrder -> 0] Colossally abundant numbers also produce relatively smooth plots: \[NumberSign][n_] := Times @@ Prime[Range[n]]; n = 2^3 3^1 \[NumberSign][5];","Let $M(n)$ be the the set of the multiplicative partitions of $n$, and let $D(n)$ be the set of the sum of the multiplicative partitions of the divisors of $n$. eg $M(30)=\{\{30\},\{2,15\},\{3, 10\}, \{5, 6\}, \{2, 3, 5\}\}$ and $D(30)=\{30,17,13,11,10\}$ This can be normalised and plotted by pairing up the ordered set $\log D$ with $x=\{1,2,3\dots\}$, which in this case would yield the plot points $\{\{1,\log10\},\{2,\log11\},\{3,\log13\},\{4,\log17\},\{5,\log30\}\}$. It appears that  these points are normally distributed: (plot of $\log F(6\ 469\ 693\ 230)$), which is fairly obvious intuitively. Is this an incarnation of the Erdős–Kac theorem ? Likely proving this would be difficult? Notes Mathematica code for primorials (which are easiest to compute for large $n$): << Combinatorica` primorial = 10; a = Range[primorial]; b = Thread[a -> Prime[a]]; c = Apply[Times, SetPartitions[a] /. b, {2}]; ListLinePlot[Log[Sort[Map[Total[c[[#]]] &, Range[Length[c]]]]]] General code for any $n$: n = 1000; α[1, r_] := α[1, r] = 1;  α[n_, r_] := α[n, r] =  Module[{s, i}, s = Select[Divisors[n], 1 < # <= r &]; Sum[α[n/s[[i]], s[[i]]], {i, 1, Length[s]}]]; β[n_]:= α[n, n]; γ[lst_, p_] :=  Module[{t, i, j}, Union[Flatten[Table[t = lst[[i]]; t[[j]] = p*t[[j]]; Sort[t], {i, Length[lst]}, {j, Length[lst[[i]]]}], 1],  Table[Sort[Append[lst[[i]], p]], {i, Length[lst]}]]]; δ[n_] := Module[{i, j, p, e, lst = {{}}},{p, e} = Transpose[FactorInteger[n]]; Do[lst = γ[lst, p[[i]]], {i, Length[p]}, {j, e[[i]]}]; lst]; ListLinePlot[Log[Sort[Map[Total[δ[n][[#]]] &, Range[β[n]]]]],  InterpolationOrder -> 0] Colossally abundant numbers also produce relatively smooth plots: \[NumberSign][n_] := Times @@ Prime[Range[n]]; n = 2^3 3^1 \[NumberSign][5];",,"['probability', 'combinatorics', 'number-theory', 'prime-numbers']"
3,Expectation Involving Two Values of Geometric Brownian Motion,Expectation Involving Two Values of Geometric Brownian Motion,,"Not sure this is the best place to ask for verification, but I can't seem to find a derivation anywhere else.  I want to calculate $\mathbb{E}[e^{\sigma(W_t + W_s)}]$, where $W_t$ and $W_s$ are two values of a standard Brownian motion and $\sigma$ is some positive constant.  WLOG assume $s < t$ and let $\mathcal{F}$ be the filtration generated by the Brownian motion.  Then using standard results I get $$ \begin{align*} \mathbb{E}[e^{\sigma(W_t + W_s)}] & = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}e^{2\sigma W_s}| \mathcal{F}_s]] \\  & = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}]e^{2\sigma W_s}] \\ & = \mathbb{E}[e^{2\sigma W_s}]e^{\frac{1}{2}\sigma^2(t-s)} \\ & = e^{2\sigma^2 s + \frac{1}{2}\sigma^2(t-s)} \\ & = e^{\frac{1}{2}\sigma^2(3s + t)}. \end{align*} $$ Thanks!","Not sure this is the best place to ask for verification, but I can't seem to find a derivation anywhere else.  I want to calculate $\mathbb{E}[e^{\sigma(W_t + W_s)}]$, where $W_t$ and $W_s$ are two values of a standard Brownian motion and $\sigma$ is some positive constant.  WLOG assume $s < t$ and let $\mathcal{F}$ be the filtration generated by the Brownian motion.  Then using standard results I get $$ \begin{align*} \mathbb{E}[e^{\sigma(W_t + W_s)}] & = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}e^{2\sigma W_s}| \mathcal{F}_s]] \\  & = \mathbb{E}[\mathbb{E}[e^{\sigma(W_t - W_s)}]e^{2\sigma W_s}] \\ & = \mathbb{E}[e^{2\sigma W_s}]e^{\frac{1}{2}\sigma^2(t-s)} \\ & = e^{2\sigma^2 s + \frac{1}{2}\sigma^2(t-s)} \\ & = e^{\frac{1}{2}\sigma^2(3s + t)}. \end{align*} $$ Thanks!",,"['probability', 'stochastic-processes', 'brownian-motion']"
4,Would you please take a look if my substantiation is correct?,Would you please take a look if my substantiation is correct?,,"The four numbers 4, 5, 6, 7 are randomly inserted into 7 .3 .4 . 6 . 48 The result is a ten-digit number - for example, 7 4 3 5 4 6 6 7 48 How high is the chance, that the number created is divisible by 36? Id say it is 100% 36 = 4 • 9 this means that the number is exactly divisible by 36,  if it is at the same time by 4 and 9. The constructed number is always divisible by 9,  since the sum of all its digits(54) is divisible by 9. And it is also divisible by 4, because their last two numbers (48) are divisible by 4.","The four numbers 4, 5, 6, 7 are randomly inserted into 7 .3 .4 . 6 . 48 The result is a ten-digit number - for example, 7 4 3 5 4 6 6 7 48 How high is the chance, that the number created is divisible by 36? Id say it is 100% 36 = 4 • 9 this means that the number is exactly divisible by 36,  if it is at the same time by 4 and 9. The constructed number is always divisible by 9,  since the sum of all its digits(54) is divisible by 9. And it is also divisible by 4, because their last two numbers (48) are divisible by 4.",,"['probability', 'puzzle']"
5,Uniform integrability of the maximum of a random walk with negative drift,Uniform integrability of the maximum of a random walk with negative drift,,"Given $S_k^{(n)} = X_1^{(n)} + ... + X_k^{(n)}$ for all $k,n\in\mathbb{N}$, where the  $X_i^{(n)}$'s are iid with mean $-\gamma$  for some $\gamma > 0$ and unit variance. Let  \begin{equation}M^{(n)} = \max_k S^{(n)}_k\end{equation} I have so far proven that $M^{(n)}$ converges in distribution to a random variable $M$ as $n\rightarrow\infty$. However, I would also like to show that $\mathbb{E}M^{(n)}\rightarrow \mathbb{E}M$ for which I need the uniform integrability of $M^{(n)}$. Does this hold true under these conditions?","Given $S_k^{(n)} = X_1^{(n)} + ... + X_k^{(n)}$ for all $k,n\in\mathbb{N}$, where the  $X_i^{(n)}$'s are iid with mean $-\gamma$  for some $\gamma > 0$ and unit variance. Let  \begin{equation}M^{(n)} = \max_k S^{(n)}_k\end{equation} I have so far proven that $M^{(n)}$ converges in distribution to a random variable $M$ as $n\rightarrow\infty$. However, I would also like to show that $\mathbb{E}M^{(n)}\rightarrow \mathbb{E}M$ for which I need the uniform integrability of $M^{(n)}$. Does this hold true under these conditions?",,"['probability', 'probability-theory', 'random-walk', 'uniform-integrability']"
6,How to calculate the distribution within a series,How to calculate the distribution within a series,,"The probability of event $A$ happening is $50.7\%$.  The probability of event $B$ happening is $49.3\%$.  What is the probability that in a series of $100$ trials, there will be at least one point where more event $B$'s will have happened than event $A$'s?","The probability of event $A$ happening is $50.7\%$.  The probability of event $B$ happening is $49.3\%$.  What is the probability that in a series of $100$ trials, there will be at least one point where more event $B$'s will have happened than event $A$'s?",,['probability']
7,What's the role of $h(x)$ (base measure) in the definition of exponential family,What's the role of  (base measure) in the definition of exponential family,h(x),"While the correct definition of exponential family is $$ f_X(x\mid\theta) = h(x) \exp \left (\eta(\theta) \cdot T(x) -A(\theta)\right ), $$ it seems that in many materials I read, they don't pay much attention to $h(x)$. Sometimes, authors just drop this term. Can somebody tell me more about the meaning of this $h(x)$ term? The most detailed description about this term I've found is ""simply reflects the underlying measure w.r.t. which $p(x\mid\theta)$ is a density."" (See http://stat-www.berkeley.edu/pub/users/mjwain/Fall2012_Stat241a/reader_ch8.pdf ). Also, some people call it ""base measure"". I kind of understand that $h(x)$ may not be important because it's trivial in most cases (1 or a constant like $1/\sqrt{2\pi}$), but for some distributions, e.g. Poisson, this term is nontrivial ($1/x!$), and it moderates the exponential term so greatly. My understanding of this term is 1) it assigns a base probability to each element in the space of $x$, and the exponential term modifies this base probability. 2) it's here so that we don't get unbounded log-partition function $A(\theta)$, in cases like Poisson. Can anybody tell me more about this $h(x)$, and any comment on my understanding of it is welcomed.","While the correct definition of exponential family is $$ f_X(x\mid\theta) = h(x) \exp \left (\eta(\theta) \cdot T(x) -A(\theta)\right ), $$ it seems that in many materials I read, they don't pay much attention to $h(x)$. Sometimes, authors just drop this term. Can somebody tell me more about the meaning of this $h(x)$ term? The most detailed description about this term I've found is ""simply reflects the underlying measure w.r.t. which $p(x\mid\theta)$ is a density."" (See http://stat-www.berkeley.edu/pub/users/mjwain/Fall2012_Stat241a/reader_ch8.pdf ). Also, some people call it ""base measure"". I kind of understand that $h(x)$ may not be important because it's trivial in most cases (1 or a constant like $1/\sqrt{2\pi}$), but for some distributions, e.g. Poisson, this term is nontrivial ($1/x!$), and it moderates the exponential term so greatly. My understanding of this term is 1) it assigns a base probability to each element in the space of $x$, and the exponential term modifies this base probability. 2) it's here so that we don't get unbounded log-partition function $A(\theta)$, in cases like Poisson. Can anybody tell me more about this $h(x)$, and any comment on my understanding of it is welcomed.",,['probability']
8,"Order 5 People of team A, 5 People of team B and 5 People of team C in line","Order 5 People of team A, 5 People of team B and 5 People of team C in line",,"I want to calculate the probability that: each candidate stands next to at least one candidate from their group. At first I thought that subtract from $1$ the probability that each team stands together,or subtract the probability that they dont stand together at all? However,  it's not enough. Note: $15! $ - Order of all people in line. Any suggestions? Thanks!","I want to calculate the probability that: each candidate stands next to at least one candidate from their group. At first I thought that subtract from $1$ the probability that each team stands together,or subtract the probability that they dont stand together at all? However,  it's not enough. Note: $15! $ - Order of all people in line. Any suggestions? Thanks!",,"['probability', 'combinatorics']"
9,Convergence rate of an estimator,Convergence rate of an estimator,,"Say we are interested in estimating some unknown real scalar parameter $\alpha$ using data. Suppose the estimator $\widehat \alpha_N$ of $\alpha$ using the data is consistent. I want to know what it means for the convergence rate to be $g(N)$. Are there any good references? Is there a formal definition? The following, I think, are equivalent ways (even redundant) to say that the convergence rate is g(N). For all large enough finite $N$, (1) $\widehat \alpha_N = \alpha + O(g(N))$ (2) $|\widehat \alpha_N - \alpha| = O(g(N))$ (3) $E[(g(N))^{-1} (\widehat \alpha_N - \alpha)]=0$ and $Var((g(N))^{-1} (\widehat \alpha_N- \alpha))=c_1$ (4) $(g(N))^{-1} (\widehat \alpha_N - \alpha) \stackrel{d}{\rightarrow} N(0,V)$ (5) $Pr((g(N))^{-1} (\widehat \alpha_N - \alpha)<\varepsilon)= c_2$ Are the above correct ways to define convergence rates? Are there any other ways to define convergence rate of an estimator?","Say we are interested in estimating some unknown real scalar parameter $\alpha$ using data. Suppose the estimator $\widehat \alpha_N$ of $\alpha$ using the data is consistent. I want to know what it means for the convergence rate to be $g(N)$. Are there any good references? Is there a formal definition? The following, I think, are equivalent ways (even redundant) to say that the convergence rate is g(N). For all large enough finite $N$, (1) $\widehat \alpha_N = \alpha + O(g(N))$ (2) $|\widehat \alpha_N - \alpha| = O(g(N))$ (3) $E[(g(N))^{-1} (\widehat \alpha_N - \alpha)]=0$ and $Var((g(N))^{-1} (\widehat \alpha_N- \alpha))=c_1$ (4) $(g(N))^{-1} (\widehat \alpha_N - \alpha) \stackrel{d}{\rightarrow} N(0,V)$ (5) $Pr((g(N))^{-1} (\widehat \alpha_N - \alpha)<\varepsilon)= c_2$ Are the above correct ways to define convergence rates? Are there any other ways to define convergence rate of an estimator?",,"['probability', 'statistics', 'convergence-divergence', 'parameter-estimation']"
10,What is a good strategy for this dice game? [duplicate],What is a good strategy for this dice game? [duplicate],,This question already has answers here : A dynamic dice game (3 answers) Closed 10 years ago . I learned the following dice game from another forum. It was not solved there. The dice game is as follows. You start tossing six dice. After each toss you  must put aside at least one of the dice tossed. You continue to toss until you have no dice remaining. You cannot reintroduce a die once it has been put aside. In order to get a score in this game you must have retained both a 2 and a 4. You get no score for them but without them you get no score at all. Your score is the sum of the remaining 4 dice. The question is  what is the maximal expected score and how to act in order to maximize your expected score. I would guess it is optimal to put  each time exactly one die aside as long you have not obtained both a 2 and a 4.,This question already has answers here : A dynamic dice game (3 answers) Closed 10 years ago . I learned the following dice game from another forum. It was not solved there. The dice game is as follows. You start tossing six dice. After each toss you  must put aside at least one of the dice tossed. You continue to toss until you have no dice remaining. You cannot reintroduce a die once it has been put aside. In order to get a score in this game you must have retained both a 2 and a 4. You get no score for them but without them you get no score at all. Your score is the sum of the remaining 4 dice. The question is  what is the maximal expected score and how to act in order to maximize your expected score. I would guess it is optimal to put  each time exactly one die aside as long you have not obtained both a 2 and a 4.,,"['probability', 'game-theory', 'dice']"
11,Examples of Talagrand's inequality,Examples of Talagrand's inequality,,I am trying to understand Talagrand's inequality and when it gives better results than Markov/Chebyshev/Chernoff.  However I find the formal definition hard to understand. Are there any nice simple examples using discrete random variables that shows its purpose?,I am trying to understand Talagrand's inequality and when it gives better results than Markov/Chebyshev/Chernoff.  However I find the formal definition hard to understand. Are there any nice simple examples using discrete random variables that shows its purpose?,,"['probability', 'self-learning']"
12,Expected Value - Uniform distribution over infinite interval,Expected Value - Uniform distribution over infinite interval,,"Question: The probability that an error is introduced into a packet is $\alpha$. Messages, consisting of one or more packets, are received at a node. Given that a message has been received free of errors, what is the expected number of packets in it? Assume that packets are never lost and that messages of all lengths are equally likely. I know I need to find the expected value and use the uniform distribution, but since it could range from length = 1 to infinity I'm unsure.  What I'm starting with: $$E[X]=\sum_{k=1}^\infty\alpha^kf_X(k)$$ Since its a uniform distribution I thought $f_X(k)$ would be a constant so I have: $$E[X]=f_X(k)\big(\sum_{k=1}^\infty\alpha^k\big)$$ $$E[X]=f_X(k)*\frac{\alpha}{1-\alpha}$$ Any hints on what to do next (how to compute the pdf when infinity is involved) or corrections would be appreciated.","Question: The probability that an error is introduced into a packet is $\alpha$. Messages, consisting of one or more packets, are received at a node. Given that a message has been received free of errors, what is the expected number of packets in it? Assume that packets are never lost and that messages of all lengths are equally likely. I know I need to find the expected value and use the uniform distribution, but since it could range from length = 1 to infinity I'm unsure.  What I'm starting with: $$E[X]=\sum_{k=1}^\infty\alpha^kf_X(k)$$ Since its a uniform distribution I thought $f_X(k)$ would be a constant so I have: $$E[X]=f_X(k)\big(\sum_{k=1}^\infty\alpha^k\big)$$ $$E[X]=f_X(k)*\frac{\alpha}{1-\alpha}$$ Any hints on what to do next (how to compute the pdf when infinity is involved) or corrections would be appreciated.",,"['probability', 'uniform-distribution']"
13,Solving Rosenthal's Example using Undergraduate Probability,Solving Rosenthal's Example using Undergraduate Probability,,"This example is based on the example given in A First Look at Rigorous Probability Theory by Rosenthal. Suppose we have a Poisson random variable $X$ with mean $\lambda > 0$. That is, \begin{align}\mathbb{P}\left(X=x\right) = \dfrac{e^{-\lambda}\lambda^{x}}{x!} \end{align} Suppose also that $Y \sim \mathcal{N}\left(0, 1\right)$. That is, \begin{align}f_{Y}(y) = \dfrac{1}{\sqrt{2\pi}}e^{-y^{2}/2}\text{, } y \in \left(-\infty, \infty\right)\text{.} \end{align} Flip a fair coin and consider a random variable $Z$. If the coin flips heads, $Z = X$. If the coin flips tails, $Z = Y$. How can one calculate, for example, $\mathbb{E}\left[Z\right]$? Possible Solution : Let $W = 1$ if heads and $W = 0$ if tails, both with probability 1/2. Then \begin{align}\mathbb{E}\left[Z\right] &= \mathbb{E}\left[Z | Z = X\right](0.5) + \mathbb{E}\left[Z | Z = Y\right](0.5) \\ &=  0.5\lambda + 0.5(0) \\ &= 0.5\lambda\text{.} \end{align} Is there anything wrong with this solution? Note that I have very little background with graduate probability theory, so any explanation as to what I am wrong is appreciated. Second Question (as given in comments): Rosenthal skips over the calculation of $\mathbb{E}\left[Z^{2}\right]$ because he wants to make a point that $Z$ is neither discrete nor continuous. Can a similar method be employed as in my proposed solution?","This example is based on the example given in A First Look at Rigorous Probability Theory by Rosenthal. Suppose we have a Poisson random variable $X$ with mean $\lambda > 0$. That is, \begin{align}\mathbb{P}\left(X=x\right) = \dfrac{e^{-\lambda}\lambda^{x}}{x!} \end{align} Suppose also that $Y \sim \mathcal{N}\left(0, 1\right)$. That is, \begin{align}f_{Y}(y) = \dfrac{1}{\sqrt{2\pi}}e^{-y^{2}/2}\text{, } y \in \left(-\infty, \infty\right)\text{.} \end{align} Flip a fair coin and consider a random variable $Z$. If the coin flips heads, $Z = X$. If the coin flips tails, $Z = Y$. How can one calculate, for example, $\mathbb{E}\left[Z\right]$? Possible Solution : Let $W = 1$ if heads and $W = 0$ if tails, both with probability 1/2. Then \begin{align}\mathbb{E}\left[Z\right] &= \mathbb{E}\left[Z | Z = X\right](0.5) + \mathbb{E}\left[Z | Z = Y\right](0.5) \\ &=  0.5\lambda + 0.5(0) \\ &= 0.5\lambda\text{.} \end{align} Is there anything wrong with this solution? Note that I have very little background with graduate probability theory, so any explanation as to what I am wrong is appreciated. Second Question (as given in comments): Rosenthal skips over the calculation of $\mathbb{E}\left[Z^{2}\right]$ because he wants to make a point that $Z$ is neither discrete nor continuous. Can a similar method be employed as in my proposed solution?",,"['probability', 'probability-theory']"
14,Expected value of measurements associated to die rolls,Expected value of measurements associated to die rolls,,"Suppose that we throw a die four times. Let $M$ be the smallest of the four rolls and let $S$ be the sum of the largest three rolls. What is $E\;[M]$ and $E\;[S]$? For $E\;[M]$ I suppose I could try and compute the distribution of $M$ and find the expected value directly, but there has to be an easier way. As for $E\;[S]$ I'm lost.","Suppose that we throw a die four times. Let $M$ be the smallest of the four rolls and let $S$ be the sum of the largest three rolls. What is $E\;[M]$ and $E\;[S]$? For $E\;[M]$ I suppose I could try and compute the distribution of $M$ and find the expected value directly, but there has to be an easier way. As for $E\;[S]$ I'm lost.",,"['probability', 'expectation']"
15,Taking Seats on a Plane: The General Case,Taking Seats on a Plane: The General Case,,"$n$ men are getting on a plane which contains $n+k$ seats. Each one has a seat number but among them, $m$ men forgot  his seat number. They get on the plane one by one. For person $X$ if he knows his seat number and if the seat is empty then he take it but if the seat if occupied then he chooses randomly a chair and sits. On the other hand if $X$ does not know his seat number them he chooses randomly a chair and sits.  What is the probability that the last $i$ persons sit on their proper seat!? (Those who forgot their seat number are not necessary the first $m$ persons who get on the plane) COMMENT: Some versions of this problem are posted to SE. You can see the following ones: Number 1 , Number 2 , Number 3","$n$ men are getting on a plane which contains $n+k$ seats. Each one has a seat number but among them, $m$ men forgot  his seat number. They get on the plane one by one. For person $X$ if he knows his seat number and if the seat is empty then he take it but if the seat if occupied then he chooses randomly a chair and sits. On the other hand if $X$ does not know his seat number them he chooses randomly a chair and sits.  What is the probability that the last $i$ persons sit on their proper seat!? (Those who forgot their seat number are not necessary the first $m$ persons who get on the plane) COMMENT: Some versions of this problem are posted to SE. You can see the following ones: Number 1 , Number 2 , Number 3",,"['probability', 'combinatorics']"
16,Convergence of random increment of two bins,Convergence of random increment of two bins,,"If bins A and B are initialized to 1, and then I continually increment one of them by 1 with a probability proportional to their values, would A/B ever converge? To demonstrate A=1 B=1 , select A or B with 50-50 -> A chosen A=2 B=1 , select A or B with 66-33 -> A chosen A=3 B=1 , etc For A=1 and B=1 it seems to diverge most of the time. But if I start from larger numbers A=100 B=100 it seems that it will converge to 50-50 after many iterations. And If I start from A=100 B=200 it would converge to 33-66 etc. So the initial value is important. What is the mathematical explanation for this behavior? Maybe the initial value  is a function of the increment (1 in this case) in some way to be able to ensure convergence.","If bins A and B are initialized to 1, and then I continually increment one of them by 1 with a probability proportional to their values, would A/B ever converge? To demonstrate A=1 B=1 , select A or B with 50-50 -> A chosen A=2 B=1 , select A or B with 66-33 -> A chosen A=3 B=1 , etc For A=1 and B=1 it seems to diverge most of the time. But if I start from larger numbers A=100 B=100 it seems that it will converge to 50-50 after many iterations. And If I start from A=100 B=200 it would converge to 33-66 etc. So the initial value is important. What is the mathematical explanation for this behavior? Maybe the initial value  is a function of the increment (1 in this case) in some way to be able to ensure convergence.",,"['probability', 'elementary-number-theory', 'statistics', 'convergence-divergence']"
17,"Understanding the difference between uniform convergence , convergence everywhere and almost sure convergence","Understanding the difference between uniform convergence , convergence everywhere and almost sure convergence",,"I'm trying to get the intuition behind convergences . I understand convergence in distribution and convergence in mean-square error . However I'm vague about the difference between  - almost sure convergence and convergence in probability - convergence everywhere and uniform convergence . I get the concept with some examples and I struggle to understand with respect to another . Is there a reference or a more generalised example to understand these concepts better ? Or if anyone who is comfortable with the concepts exists, please do explain.  thanks.","I'm trying to get the intuition behind convergences . I understand convergence in distribution and convergence in mean-square error . However I'm vague about the difference between  - almost sure convergence and convergence in probability - convergence everywhere and uniform convergence . I get the concept with some examples and I struggle to understand with respect to another . Is there a reference or a more generalised example to understand these concepts better ? Or if anyone who is comfortable with the concepts exists, please do explain.  thanks.",,"['probability', 'probability-theory', 'convergence-divergence']"
18,Essential supremum of a conditional expectation,Essential supremum of a conditional expectation,,"Given the function \begin{equation}   P(x,t) := \sup\limits_{t \le \tau \le T} E\left( g(X^{t,x}_{\tau}) \right) \end{equation} where $X^{t,x}$ is the unique solution to the SDE \begin{equation}   X_u = x + \int\limits_t^u \mu(X_s, s) \, ds + \int\limits_t^u \sigma(X_s, s) \, dB_s \end{equation} for $x >0$, $t \in [0,T]$, $u \in [t,T]$ and $\tau$ is a stopping time with $P(\tau \in [t,T]) =1$ and $g$ is a continuous R-valued function. Then we have for the process $X = X^{0,s}$ (defined analogously) \begin{equation}   P(X_t, t) = \text{ess sup}_{t \le \tau \le T} E\left(g(X_{\tau}) \, | \, \mathcal{F}_t \right) \end{equation} where $\mathcal{F}_t = \sigma(B_s: s \in [0,t])$. I found this statement but I don't know how to argue correctly to get that relation. Somehow the expectation in the definition of the function $P$ is conditioned on $X^{t,x}_t = x$ which is obviously an a.s.-event, but what happens when I have a random variable instead of a deterministic $x$? And how do I get the equality of the supremum and the essential supremum? Maybe you can have a look at my attempt I have figured out so far: \begin{align}   P(X_t, t) & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \right) \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \, | \, X^{t,X_t}_t = X_t \right) \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \, | \, X_t \right) \\             & \text{(Is the expected value $E( \cdot \, | \, X^{t,X_t}_t = X_t)$ really equal to the conditional expectation $E( \cdot \, | \, X_t)$? If so, how do I argue here precisely?)} \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, X_t \right) \\             & \text{(flow property of solutions to the SDE)} \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, \mathcal{F}_t \right) \\             & \text{(Markov property of solutions to the SDE)} \\             & = \text{ess sup}_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, \mathcal{F}_t \right) \\             & \text{(???)} \end{align} Has anyone an idea how to get the a.s. equality of $\sup$ and ess sup? I think the key to that is the measurability of the sup, but I have no idea how to prove that for the set of stopping times.","Given the function \begin{equation}   P(x,t) := \sup\limits_{t \le \tau \le T} E\left( g(X^{t,x}_{\tau}) \right) \end{equation} where $X^{t,x}$ is the unique solution to the SDE \begin{equation}   X_u = x + \int\limits_t^u \mu(X_s, s) \, ds + \int\limits_t^u \sigma(X_s, s) \, dB_s \end{equation} for $x >0$, $t \in [0,T]$, $u \in [t,T]$ and $\tau$ is a stopping time with $P(\tau \in [t,T]) =1$ and $g$ is a continuous R-valued function. Then we have for the process $X = X^{0,s}$ (defined analogously) \begin{equation}   P(X_t, t) = \text{ess sup}_{t \le \tau \le T} E\left(g(X_{\tau}) \, | \, \mathcal{F}_t \right) \end{equation} where $\mathcal{F}_t = \sigma(B_s: s \in [0,t])$. I found this statement but I don't know how to argue correctly to get that relation. Somehow the expectation in the definition of the function $P$ is conditioned on $X^{t,x}_t = x$ which is obviously an a.s.-event, but what happens when I have a random variable instead of a deterministic $x$? And how do I get the equality of the supremum and the essential supremum? Maybe you can have a look at my attempt I have figured out so far: \begin{align}   P(X_t, t) & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \right) \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \, | \, X^{t,X_t}_t = X_t \right) \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X^{t,X_t}_{\tau}) \, | \, X_t \right) \\             & \text{(Is the expected value $E( \cdot \, | \, X^{t,X_t}_t = X_t)$ really equal to the conditional expectation $E( \cdot \, | \, X_t)$? If so, how do I argue here precisely?)} \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, X_t \right) \\             & \text{(flow property of solutions to the SDE)} \\             & = \sup\limits_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, \mathcal{F}_t \right) \\             & \text{(Markov property of solutions to the SDE)} \\             & = \text{ess sup}_{t \le \tau \le T} E\left( g(X_{\tau}) \, | \, \mathcal{F}_t \right) \\             & \text{(???)} \end{align} Has anyone an idea how to get the a.s. equality of $\sup$ and ess sup? I think the key to that is the measurability of the sup, but I have no idea how to prove that for the set of stopping times.",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'stopping-times']"
19,Fair continuous election algorithm in a limited set of users,Fair continuous election algorithm in a limited set of users,,"I have an election method in mind, don't know if already exists but I think there must be. It is used in a finite set of users and continuous. Every round, somebody is picked randomly depending on the probability. Initially everybody starts with equal probability.  But with every round, the selected user's re-election probability will decrease (but will still be available to be elected nonetheless). If everything goes extremely fair and every user who has not been elected before is elected one after other, an then when everybody is elected once, the probabilities of them will be equal again. Example: John, Max & Sarah are 3 users. Scenario1: Initially: [ P(J)=%33, P(M)=%33, P(S)=%33 ]   1st round, John is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ]  2nd round, Max is elected: [ P(J)=%5, P(M)=%5, P(S)=%90 ]  3rd round, Sarah is elected: [ P(J)=%33, P(M)=%33, P(S)=%33 ] Scenario 2: Initially: [ P(J)=%33, P(M)=%33, P(S)=%33 ]   1st round, John is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ]  2nd round, John is elected again: [ P(J)=%2, P(M)=%49, P(S)=%49 ]  3rd round, Sarah is elected: [ P(J)=%5, P(M)=%85, P(S)=%10 ]  4th round, Max is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ] The probability values above are not based on a strict constant, just given for better understanding the question. The main idea, needs to be accomplished is to give a user fair election chance and still protecting the re-election chance(but smaller as his election count gets bigger) Thanks in advance","I have an election method in mind, don't know if already exists but I think there must be. It is used in a finite set of users and continuous. Every round, somebody is picked randomly depending on the probability. Initially everybody starts with equal probability.  But with every round, the selected user's re-election probability will decrease (but will still be available to be elected nonetheless). If everything goes extremely fair and every user who has not been elected before is elected one after other, an then when everybody is elected once, the probabilities of them will be equal again. Example: John, Max & Sarah are 3 users. Scenario1: Initially: [ P(J)=%33, P(M)=%33, P(S)=%33 ]   1st round, John is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ]  2nd round, Max is elected: [ P(J)=%5, P(M)=%5, P(S)=%90 ]  3rd round, Sarah is elected: [ P(J)=%33, P(M)=%33, P(S)=%33 ] Scenario 2: Initially: [ P(J)=%33, P(M)=%33, P(S)=%33 ]   1st round, John is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ]  2nd round, John is elected again: [ P(J)=%2, P(M)=%49, P(S)=%49 ]  3rd round, Sarah is elected: [ P(J)=%5, P(M)=%85, P(S)=%10 ]  4th round, Max is elected: [ P(J)=%10, P(M)=%45, P(S)=%45 ] The probability values above are not based on a strict constant, just given for better understanding the question. The main idea, needs to be accomplished is to give a user fair election chance and still protecting the re-election chance(but smaller as his election count gets bigger) Thanks in advance",,"['probability', 'voting-theory']"
20,Markov Chains Proof using Statistics,Markov Chains Proof using Statistics,,"Source: This came from ""Introduction to probability"" by Charles Miller Grinstead, and James Aurie Snell. It was located on page 407 and is Theorem 11.1 in the section 11.1 Introduction. Theorem: The Theorem 11.1 states: Let $P$ be the transition matrix of a Markov chain. The $ij$th entry $P_{ij}(n)$ of the matrix $P(n)$ gives the probability that the Markov chain, starting in the state $S_i$, will be in state $S_j$, after $n$ steps. Proof: You start with the probability distribution $Pr(X_{k+n}=S_j | X_k = S_i)$ which can be written as a$\sum_h^\infty Pr(X_{k+n}=S_j | X_{k+n-1}=S_h)Pr(X_{k+n-1}=S_h | X_k= S_i)$. Which can be simplified down even further to the $\sum_1^n P_{jh}P_{hi}^{(n-1)}$. Which can then be simplified to the final version of $P_{ij}(n)$ Class: This is for a class called Seminar. It's a class were supposed to take the year we graduate. It is a class that we do a research essay that we then present to the class and do a set of problems every week with a new topic. (I.E. functions one week, inequalities next, then derivatives, and so on). It's supposed to be a capstone class for our degree that goes over a little bit of everything from the previous three years, but makes you think more and put things together. So we're mathematically mature, but we're not graduate level or anything. If that helps. What I Need: I could use some help fleshing out this proof to a way that would be understandable for any college mathematics students. I'm doing it for a class and need to be able to teach anyone in my class to understand this proof, but statistics isn't my strong suit and any help would be appreciated.","Source: This came from ""Introduction to probability"" by Charles Miller Grinstead, and James Aurie Snell. It was located on page 407 and is Theorem 11.1 in the section 11.1 Introduction. Theorem: The Theorem 11.1 states: Let $P$ be the transition matrix of a Markov chain. The $ij$th entry $P_{ij}(n)$ of the matrix $P(n)$ gives the probability that the Markov chain, starting in the state $S_i$, will be in state $S_j$, after $n$ steps. Proof: You start with the probability distribution $Pr(X_{k+n}=S_j | X_k = S_i)$ which can be written as a$\sum_h^\infty Pr(X_{k+n}=S_j | X_{k+n-1}=S_h)Pr(X_{k+n-1}=S_h | X_k= S_i)$. Which can be simplified down even further to the $\sum_1^n P_{jh}P_{hi}^{(n-1)}$. Which can then be simplified to the final version of $P_{ij}(n)$ Class: This is for a class called Seminar. It's a class were supposed to take the year we graduate. It is a class that we do a research essay that we then present to the class and do a set of problems every week with a new topic. (I.E. functions one week, inequalities next, then derivatives, and so on). It's supposed to be a capstone class for our degree that goes over a little bit of everything from the previous three years, but makes you think more and put things together. So we're mathematically mature, but we're not graduate level or anything. If that helps. What I Need: I could use some help fleshing out this proof to a way that would be understandable for any college mathematics students. I'm doing it for a class and need to be able to teach anyone in my class to understand this proof, but statistics isn't my strong suit and any help would be appreciated.",,"['probability', 'statistics', 'probability-theory', 'markov-chains', 'markov-process']"
21,Stable Convergence in Distribution - Martingale CLT problem (Lemma 3.1 in Hall and Heyde),Stable Convergence in Distribution - Martingale CLT problem (Lemma 3.1 in Hall and Heyde),,"I'm studying Hall and Heyde's (1980) book on martingale limit theory. In their Lemma 3.1, they seem to use the identity \begin{equation} \mathrm{E}\left({\exp{(itZ)}\mathbb{1}_A}\right) = \mathrm{E}\left(\varphi_{Z}(t)\mathbb{1}_A\right)  \end{equation} where $/$ is a random variable, $\varphi_{Z}$ is the characteristic function of this random variable, and $\mathbb{1}_A$ is the indicator of an arbitrary measurable set $A$. Why is that ""ok""? It's clear for $A=\Omega$ (i.e., the whole space), but for arbitrary $A$? many thanks in advance for your help!","I'm studying Hall and Heyde's (1980) book on martingale limit theory. In their Lemma 3.1, they seem to use the identity \begin{equation} \mathrm{E}\left({\exp{(itZ)}\mathbb{1}_A}\right) = \mathrm{E}\left(\varphi_{Z}(t)\mathbb{1}_A\right)  \end{equation} where $/$ is a random variable, $\varphi_{Z}$ is the characteristic function of this random variable, and $\mathbb{1}_A$ is the indicator of an arbitrary measurable set $A$. Why is that ""ok""? It's clear for $A=\Omega$ (i.e., the whole space), but for arbitrary $A$? many thanks in advance for your help!",,"['probability', 'statistics', 'measure-theory', 'probability-theory']"
22,Show convergence in probability,Show convergence in probability,,"Let $X_1,X_2,\dots$ be I.i.d. And $S_n = X_1+X_2+\dots +X_n. $Prove if $S_n/n \to 0$ in probability then $(\max_{1\leq m \leq n}S_m)/n \to 0$ in probability. I know the idea and there is a detail I don't know how to prove.  If |Sn-Sk|$\leq$|Sn|+|Sk| and Sn/n limits to 0 in probability, how can I prove that minP(|Sn-Sk|$\leq n\delta$)$\to $ 1 as $ n \to \infty$ ($0\leq k \leq n$)","Let $X_1,X_2,\dots$ be I.i.d. And $S_n = X_1+X_2+\dots +X_n. $Prove if $S_n/n \to 0$ in probability then $(\max_{1\leq m \leq n}S_m)/n \to 0$ in probability. I know the idea and there is a detail I don't know how to prove.  If |Sn-Sk|$\leq$|Sn|+|Sk| and Sn/n limits to 0 in probability, how can I prove that minP(|Sn-Sk|$\leq n\delta$)$\to $ 1 as $ n \to \infty$ ($0\leq k \leq n$)",,"['probability', 'convergence-divergence']"
23,Winning Percentages,Winning Percentages,,A friend and I both play in an NFL pick league.  His requires that he only pick 5 games per week.  So far there have been 76 total games this year.  His record is 18 for 25. My league requires me to pick a winner for every game.  My record is 40 for 76. What would be the formula for comparing our winning percentages since my league is obviously much harder?,A friend and I both play in an NFL pick league.  His requires that he only pick 5 games per week.  So far there have been 76 total games this year.  His record is 18 for 25. My league requires me to pick a winner for every game.  My record is 40 for 76. What would be the formula for comparing our winning percentages since my league is obviously much harder?,,"['probability', 'statistics']"
24,Limiting behavior of an integral involving incomplete Gamma function,Limiting behavior of an integral involving incomplete Gamma function,,"I am wondering about the limiting behavior as $k\rightarrow\infty$ of the following integral: $$I(k)=\frac{2^{-k/2}}{\Gamma(k/2)}\int_{f(k)}^\infty t^{k/2-1}e^{-t/2}\left(\frac{\gamma\left(\frac{k}{2},\frac{t-f(k)}{2}\right)}{\Gamma(k/2)}\right)^{g(k)-1}dt$$ where $\Gamma(z)=\int_0^\infty t^{z-1}e^{-t}dt$ is the Gamma function , $\gamma(s,x)=\int_0^x t^{s-1}e^{-t}dt$ is the lower incomplete Gamma function , function $g(x)$ is asymptotically greater than $k$, i.e. $g(k)=\omega(k)$ (for example, $g(k)$ could be $k^2$), and $f(k)$ is function that is asymptotically greater than $\sqrt{k/\log(g(k))}$ (that is, $f(k)=\omega(\sqrt{k/\log(g(k))})$).  Specifically, I am wondering if $\lim_{k\rightarrow\infty}I(k)=1$ or $\lim_{k\rightarrow\infty}I(k)=0$ or if it converges to some other number. Where this comes from Suppose that I have a sequence of $g(k)$ i.i.d. random variables $X_1,X_2,\ldots,X_{g(k)}$ on $[0,\infty)$ and that I order their realizations in a decreasing order: $X^{(1)}\geq X^{(2)}\geq\ldots\geq X^{(g(x))}$.  The probability that the difference between the maximum $X^{(1)}$ in this sequence and the second largest $X^{(2)}$ exceeds $f(k)$ can be written down as follows: $$P\left[X^{(1)}-X^{(2)}\geq f(k)\right]=\int_{f(k)}^\infty f_X(t)[F_X(t-f(k))]^{g(k)-1}dt$$ where $f_X(t)$ and $F_X(t)$ are respectively the probability density and cumulative distribution functions of $X$. I am interested in learning the complimentary cumulative distribution function for the difference between largest and second-largest elements in a sequence of i.i.d. chi-squared random variables with $k$ degrees of freedom.","I am wondering about the limiting behavior as $k\rightarrow\infty$ of the following integral: $$I(k)=\frac{2^{-k/2}}{\Gamma(k/2)}\int_{f(k)}^\infty t^{k/2-1}e^{-t/2}\left(\frac{\gamma\left(\frac{k}{2},\frac{t-f(k)}{2}\right)}{\Gamma(k/2)}\right)^{g(k)-1}dt$$ where $\Gamma(z)=\int_0^\infty t^{z-1}e^{-t}dt$ is the Gamma function , $\gamma(s,x)=\int_0^x t^{s-1}e^{-t}dt$ is the lower incomplete Gamma function , function $g(x)$ is asymptotically greater than $k$, i.e. $g(k)=\omega(k)$ (for example, $g(k)$ could be $k^2$), and $f(k)$ is function that is asymptotically greater than $\sqrt{k/\log(g(k))}$ (that is, $f(k)=\omega(\sqrt{k/\log(g(k))})$).  Specifically, I am wondering if $\lim_{k\rightarrow\infty}I(k)=1$ or $\lim_{k\rightarrow\infty}I(k)=0$ or if it converges to some other number. Where this comes from Suppose that I have a sequence of $g(k)$ i.i.d. random variables $X_1,X_2,\ldots,X_{g(k)}$ on $[0,\infty)$ and that I order their realizations in a decreasing order: $X^{(1)}\geq X^{(2)}\geq\ldots\geq X^{(g(x))}$.  The probability that the difference between the maximum $X^{(1)}$ in this sequence and the second largest $X^{(2)}$ exceeds $f(k)$ can be written down as follows: $$P\left[X^{(1)}-X^{(2)}\geq f(k)\right]=\int_{f(k)}^\infty f_X(t)[F_X(t-f(k))]^{g(k)-1}dt$$ where $f_X(t)$ and $F_X(t)$ are respectively the probability density and cumulative distribution functions of $X$. I am interested in learning the complimentary cumulative distribution function for the difference between largest and second-largest elements in a sequence of i.i.d. chi-squared random variables with $k$ degrees of freedom.",,"['probability', 'integration', 'limits', 'special-functions', 'gamma-function']"
25,probability of at least a fraction of bins contain a fixed number of balls,probability of at least a fraction of bins contain a fixed number of balls,,"Consider the process of throwing m balls into n bins. Each ball is thrown into a uniformly random bin, independent of other balls. What is the probability that at least a constant fraction of bins get a fixed number of balls.","Consider the process of throwing m balls into n bins. Each ball is thrown into a uniformly random bin, independent of other balls. What is the probability that at least a constant fraction of bins get a fixed number of balls.",,['probability']
26,"Mean and variance of geometric distribution, probability","Mean and variance of geometric distribution, probability",,"$2.$ Compute the mean and variance of the geometric distribution. Hints: It is sometimes easier to compute $\text{E}[X(X-1)]$ than   $\text{E}[X^2]$. Note that   $\text{E}[X(X-1)]=\text{E}[X^2]-\text{E}[X]$. The geometric series   formula is $$\sum_{n=0}^{\infty}r^n=\frac{1}{1-r}$$ If you   differentiate this once and then again you get the useful identities:   $$\sum_{n=1}^\infty > nr^{n-1}=\frac{d}{dr}\frac{1}{1-r},\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\sum_{n=2}^\infty > n(n-1)r^{n-2}=\frac{d^2}{dr^2}\frac{1}{1-r}$$ The following is not to   be turned in. This same ""summation by differentiating"" trick can be   used in other setting. Take the binomial identity   $$(x+y)^n=\sum_{k=0}^n\binom{n}{k}x^ky^{n-k}$$ Differentiate with   respect to $x$, then set $x=p$, $y=1-p$ and you get an identity that   helps you compute the mean of the binomial distribution. Differentiate   twice and you get an identity that will lead to the variance. I am not sure where I am going wrong in trying to reach the proper solution. Can anyone help me to solve this, please?","$2.$ Compute the mean and variance of the geometric distribution. Hints: It is sometimes easier to compute $\text{E}[X(X-1)]$ than   $\text{E}[X^2]$. Note that   $\text{E}[X(X-1)]=\text{E}[X^2]-\text{E}[X]$. The geometric series   formula is $$\sum_{n=0}^{\infty}r^n=\frac{1}{1-r}$$ If you   differentiate this once and then again you get the useful identities:   $$\sum_{n=1}^\infty > nr^{n-1}=\frac{d}{dr}\frac{1}{1-r},\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\sum_{n=2}^\infty > n(n-1)r^{n-2}=\frac{d^2}{dr^2}\frac{1}{1-r}$$ The following is not to   be turned in. This same ""summation by differentiating"" trick can be   used in other setting. Take the binomial identity   $$(x+y)^n=\sum_{k=0}^n\binom{n}{k}x^ky^{n-k}$$ Differentiate with   respect to $x$, then set $x=p$, $y=1-p$ and you get an identity that   helps you compute the mean of the binomial distribution. Differentiate   twice and you get an identity that will lead to the variance. I am not sure where I am going wrong in trying to reach the proper solution. Can anyone help me to solve this, please?",,"['probability', 'probability-distributions']"
27,Random convex shapes containing a ball,Random convex shapes containing a ball,,"I'm interested in the properties of randomly generated convex shapes in $n$-dimensional space. Suppose I were to generate $v$ uniformly distributed random points on the $n$-ball of radius $R$. What is the probability that their convex hull contains the $n$-ball of radius $1$? There seems to be some knowledge of the probability that their convex hull contains the origin, which provides a handy upper bound, but I'd prefer some nontrivial lower bound. I've googled around for it and haven't found any clues. Alternatively, given these vertices, is there some reasonably swift test I could perform on them to decide whether or not their hull contains the unit ball? An estimation of this probability from experimental data would be good enough for what I'm doing.","I'm interested in the properties of randomly generated convex shapes in $n$-dimensional space. Suppose I were to generate $v$ uniformly distributed random points on the $n$-ball of radius $R$. What is the probability that their convex hull contains the $n$-ball of radius $1$? There seems to be some knowledge of the probability that their convex hull contains the origin, which provides a handy upper bound, but I'd prefer some nontrivial lower bound. I've googled around for it and haven't found any clues. Alternatively, given these vertices, is there some reasonably swift test I could perform on them to decide whether or not their hull contains the unit ball? An estimation of this probability from experimental data would be good enough for what I'm doing.",,"['probability', 'algorithms', 'convex-analysis', 'geometric-probability']"
28,Dinner table problem: with multiple tables,Dinner table problem: with multiple tables,,"Consider a party of $kn$ people and $k$ circular tables of size $n$. If they are seated randomly around the tables for two courses, what is the probability that no two people sit together at both courses? This seems to be well studied for one table. For example see ftp://db.stanford.edu/pub/cstr/reports/cs/tr/80/829/CS-TR-80-829.pdf","Consider a party of $kn$ people and $k$ circular tables of size $n$. If they are seated randomly around the tables for two courses, what is the probability that no two people sit together at both courses? This seems to be well studied for one table. For example see ftp://db.stanford.edu/pub/cstr/reports/cs/tr/80/829/CS-TR-80-829.pdf",,"['probability', 'combinatorics']"
29,Question regard almost sure convergence,Question regard almost sure convergence,,"I need an example of an i.i.d. sequence of random variables $(X_i)$ such that $$ X_1\cdot\left(\frac{1}{n}\sum_{i=1}^nX_i\right)\not\to X_1\mathbb{E}(X_1) $$ almost surely as $n\to\infty$. According to the law of large numbers the sum $\frac{1}{n}\sum_{i=1}^nX_i$ converges almost surely to $\mathbb{E}(X_1)$, so, why should I care about $X_1$?","I need an example of an i.i.d. sequence of random variables $(X_i)$ such that $$ X_1\cdot\left(\frac{1}{n}\sum_{i=1}^nX_i\right)\not\to X_1\mathbb{E}(X_1) $$ almost surely as $n\to\infty$. According to the law of large numbers the sum $\frac{1}{n}\sum_{i=1}^nX_i$ converges almost surely to $\mathbb{E}(X_1)$, so, why should I care about $X_1$?",,"['probability', 'probability-theory']"
30,Weighted Probability Problem,Weighted Probability Problem,,"Lets say, few independent events are happening. $E_1, E_2,...,E_n$. The probability of each of these events happening is given as $P_1,P_2,...,P_n$. Each of these events carry weightage, say $W_1,W_2,...,W_n$ respectively. I tried building a tree like the one shown here http://www.mathsisfun.com/data/probability-tree-diagrams.html . But its highly inefficient, for even small value of n, eg: $200$, the number of leaf nodes will be $2^{200}$. Now, how can I find the probability of getting at least weight $W$? Example: Probabilities = [0.2, 0.8] Weights       = [3, 5] It means that, for the first event, there are 20% chances for that to happen. If it happens, the weightage will become 3, 0 otherwise. In the second case, there are 80% chances for that to happen. If it happens, the weightage will become 5, 0 otherwise. Now if I want to find the probability of getting atleast Weight 4 would be like this 0.2 * 0.8 = 0.16 -> Total weight 8 (1) 0.8 * 0.8 = 0.64 -> Total weight 5 (2) 0.2 * 0.2 = 0.04 -> Total weight 3 (3) 0.8 * 0.2 = 0.16 -> Total weight 0 (4) So, the total probability of getting atleast 4 weight is 0.16 (From (1)) + 0.64 (From (2)) = 0.80 EDIT2: The sum of all the probabilities $P_i$ need not be 1 always","Lets say, few independent events are happening. $E_1, E_2,...,E_n$. The probability of each of these events happening is given as $P_1,P_2,...,P_n$. Each of these events carry weightage, say $W_1,W_2,...,W_n$ respectively. I tried building a tree like the one shown here http://www.mathsisfun.com/data/probability-tree-diagrams.html . But its highly inefficient, for even small value of n, eg: $200$, the number of leaf nodes will be $2^{200}$. Now, how can I find the probability of getting at least weight $W$? Example: Probabilities = [0.2, 0.8] Weights       = [3, 5] It means that, for the first event, there are 20% chances for that to happen. If it happens, the weightage will become 3, 0 otherwise. In the second case, there are 80% chances for that to happen. If it happens, the weightage will become 5, 0 otherwise. Now if I want to find the probability of getting atleast Weight 4 would be like this 0.2 * 0.8 = 0.16 -> Total weight 8 (1) 0.8 * 0.8 = 0.64 -> Total weight 5 (2) 0.2 * 0.2 = 0.04 -> Total weight 3 (3) 0.8 * 0.2 = 0.16 -> Total weight 0 (4) So, the total probability of getting atleast 4 weight is 0.16 (From (1)) + 0.64 (From (2)) = 0.80 EDIT2: The sum of all the probabilities $P_i$ need not be 1 always",,"['probability', 'probability-theory']"
31,Probability and independence,Probability and independence,,"I am trying to solve a particular probability question. I have a fair 10-sides die, whose sides are labelled 1 through 10. I am trying to find the probability of rolling a multiple of 5 or an odd number. I find the probability as: P(multiple of 5) OR  P(odd number)=P(multiple of 5) + P(odd number)-[P(multiple of 5) AND P(odd number)]=2/10+5/10-[(2/10)(5/10)]=6/10 (which is the correct answer) Notice that I used the assumption that rolling a multiple of 5 is independent of rolling an odd number, since I essentially multiplied their probabilities to get the answer. However, rolling a multiple of 5 INVOLVES rolling an odd number in one case, namely rolling a 5. So did I get the correct answer by fluke? Can the multiplication rule also be used to describe non-independent events sometimes ?","I am trying to solve a particular probability question. I have a fair 10-sides die, whose sides are labelled 1 through 10. I am trying to find the probability of rolling a multiple of 5 or an odd number. I find the probability as: P(multiple of 5) OR  P(odd number)=P(multiple of 5) + P(odd number)-[P(multiple of 5) AND P(odd number)]=2/10+5/10-[(2/10)(5/10)]=6/10 (which is the correct answer) Notice that I used the assumption that rolling a multiple of 5 is independent of rolling an odd number, since I essentially multiplied their probabilities to get the answer. However, rolling a multiple of 5 INVOLVES rolling an odd number in one case, namely rolling a 5. So did I get the correct answer by fluke? Can the multiplication rule also be used to describe non-independent events sometimes ?",,['probability']
32,What is the probability that the roots of $P(x) = \frac{1}{4} x^2 +Ux+V^2$ are real?,What is the probability that the roots of  are real?,P(x) = \frac{1}{4} x^2 +Ux+V^2,"Assume that $U$ and $V$  are independent normally distributed random variables, each with mean $0$ and variance $1$. Find the probability that the roots of the polynomial $P(x) = \frac{1}{4} x^2 +Ux+V^2$  are real. This is a question I had to work out on my intro probability midterm. It's clear to see by looking at the discriminant that  $$\begin{align} \Bbb P(\text{roots of }P(x)\text{ are real}) &=\Bbb P(U^2-V^2\ge0) \\ &=\Bbb P(U^2\ge  V^2) \\ &=\Bbb P(U\ge V\text{ or }-U\ge -V), \end{align}$$ but what next? I appreciate any help. Thanks in advance!","Assume that $U$ and $V$  are independent normally distributed random variables, each with mean $0$ and variance $1$. Find the probability that the roots of the polynomial $P(x) = \frac{1}{4} x^2 +Ux+V^2$  are real. This is a question I had to work out on my intro probability midterm. It's clear to see by looking at the discriminant that  $$\begin{align} \Bbb P(\text{roots of }P(x)\text{ are real}) &=\Bbb P(U^2-V^2\ge0) \\ &=\Bbb P(U^2\ge  V^2) \\ &=\Bbb P(U\ge V\text{ or }-U\ge -V), \end{align}$$ but what next? I appreciate any help. Thanks in advance!",,['probability']
33,What is the probability that the store is closed?,What is the probability that the store is closed?,,"Customers arrive at a store according to a Poisson process with a fixed rate $\lambda$ per hour. Now we only know that the store have served $m$ people during $T$ hours. What is the probability that the store is closed during this time period? (Assume the store has unlimited service capability and cannot serve customers if it is closed.) I think, if the expected number of customers $\lambda T > m$, then the store might be closed during the time period $T$. Specifically, if $m=0$ for a very large time period $T$, then the probability that the store is closed during $T$ would be close to $1$. But I’m getting stuck into the problem to formulize the probability that the store is closed during $T$. Is there any other information that has to be provided? Would you please help me?","Customers arrive at a store according to a Poisson process with a fixed rate $\lambda$ per hour. Now we only know that the store have served $m$ people during $T$ hours. What is the probability that the store is closed during this time period? (Assume the store has unlimited service capability and cannot serve customers if it is closed.) I think, if the expected number of customers $\lambda T > m$, then the store might be closed during the time period $T$. Specifically, if $m=0$ for a very large time period $T$, then the probability that the store is closed during $T$ would be close to $1$. But I’m getting stuck into the problem to formulize the probability that the store is closed during $T$. Is there any other information that has to be provided? Would you please help me?",,"['probability', 'stochastic-processes']"
34,Demonstrating a coin is not fair with as few flips as possible,Demonstrating a coin is not fair with as few flips as possible,,"Suppose you have an ""unfair"" coin, that lands heads with probability $p\in(1/2,1]$ (where $p$ is known to you). You are given some $\epsilon>0$, and want to demonstrate to someone that this coin is not fair with confidence $1-\epsilon$, using as few flips as possible. What is the optimal method for doing this? Formally, this is what I mean: define $X=\{H,T\}^\omega$, the space of infinite sequences consisting of heads and tails. This space has two probability measures on it: $\mu_p$, the probability measure coming from the unfair coin, and $\mu_{1/2}$, the probability measure that would come from a fair coin. We choose an event $E\subset X$ satisfying $\mu_{1/2}(E)\leq \epsilon$, and define a function $f_E:X\to \mathbb{Z}_{>0}\cup\{\infty\}$, $$ f(a_1,a_2,\ldots)=\inf \{n:(b_1,b_2,\ldots)\in E\text{ whenever }b_1=a_1,\ldots,b_n=a_n\}. $$ Thus $f(a_1,a_2,\ldots)$ is the number of coin flips required to establish that $(a_1,a_2,\ldots)\in E$. In particular, $f(a_1,a_2,\ldots)=\infty$ if $(a_1,a_2,\ldots)\not\in E$. We would like to choose $E$ so that the quantity $$ \int_X f(x)\,d\mu_p(x) $$ is finite and as small as possible. One possibility is to take $$ E=\{(a_1,\ldots):\exists N\geq N_0\text{ s.t. }\#\{n\leq N:a_n=H\}>\frac{\frac{1}{2}+p}{2}N\}, $$ where $N_0$ is chosen to be sufficiently large (depending on $\epsilon$). In other words, we flip at least $N_0$ times, the stop when the proportion of heads is closer to $p$ than to $\frac{1}{2}$. By choosing $N_0$ sufficiently large, we will have $\mu_{1/2}(E)\leq \epsilon$, and I believe we also get $\int_X f(x)\,d\mu_p(x)<\infty$. It seems clear that this choice of $E$ is not optimal, however.","Suppose you have an ""unfair"" coin, that lands heads with probability $p\in(1/2,1]$ (where $p$ is known to you). You are given some $\epsilon>0$, and want to demonstrate to someone that this coin is not fair with confidence $1-\epsilon$, using as few flips as possible. What is the optimal method for doing this? Formally, this is what I mean: define $X=\{H,T\}^\omega$, the space of infinite sequences consisting of heads and tails. This space has two probability measures on it: $\mu_p$, the probability measure coming from the unfair coin, and $\mu_{1/2}$, the probability measure that would come from a fair coin. We choose an event $E\subset X$ satisfying $\mu_{1/2}(E)\leq \epsilon$, and define a function $f_E:X\to \mathbb{Z}_{>0}\cup\{\infty\}$, $$ f(a_1,a_2,\ldots)=\inf \{n:(b_1,b_2,\ldots)\in E\text{ whenever }b_1=a_1,\ldots,b_n=a_n\}. $$ Thus $f(a_1,a_2,\ldots)$ is the number of coin flips required to establish that $(a_1,a_2,\ldots)\in E$. In particular, $f(a_1,a_2,\ldots)=\infty$ if $(a_1,a_2,\ldots)\not\in E$. We would like to choose $E$ so that the quantity $$ \int_X f(x)\,d\mu_p(x) $$ is finite and as small as possible. One possibility is to take $$ E=\{(a_1,\ldots):\exists N\geq N_0\text{ s.t. }\#\{n\leq N:a_n=H\}>\frac{\frac{1}{2}+p}{2}N\}, $$ where $N_0$ is chosen to be sufficiently large (depending on $\epsilon$). In other words, we flip at least $N_0$ times, the stop when the proportion of heads is closer to $p$ than to $\frac{1}{2}$. By choosing $N_0$ sufficiently large, we will have $\mu_{1/2}(E)\leq \epsilon$, and I believe we also get $\int_X f(x)\,d\mu_p(x)<\infty$. It seems clear that this choice of $E$ is not optimal, however.",,['probability']
35,Speculating on the stock exchange,Speculating on the stock exchange,,"Imagine you model each stock as a random walk (fractal) and also that you can buy and sell at any price. Suppose also that it 'walks' with the pace of 1. If you buy, for example, 1000 shares of several companies, for \$100, and you sell every falling position that hits \$95, but keep every company until it reaches \$110. Wouldn't that be a winning strategy?","Imagine you model each stock as a random walk (fractal) and also that you can buy and sell at any price. Suppose also that it 'walks' with the pace of 1. If you buy, for example, 1000 shares of several companies, for \$100, and you sell every falling position that hits \$95, but keep every company until it reaches \$110. Wouldn't that be a winning strategy?",,"['probability', 'finance', 'random-walk']"
36,Some long and good prerequisite textbooks to the graduate probability textbook by shiryaev and boas?,Some long and good prerequisite textbooks to the graduate probability textbook by shiryaev and boas?,,Some long and good prerequisite textbooks to the graduate probability textbook by shiryaev and boas? It seems that it have a big gap between this graduate textbooks and the easier ones.,Some long and good prerequisite textbooks to the graduate probability textbook by shiryaev and boas? It seems that it have a big gap between this graduate textbooks and the easier ones.,,"['probability', 'soft-question', 'book-recommendation']"
37,Neyman-Pearson lemma proof,Neyman-Pearson lemma proof,,"$\mathbf{Theorem}$ Let $\forall \alpha \in (0,1) \space \exists \space k$, such that for $W_0 = \{ x: p_1(x) \ge k p_0(x) \}$, $$\int_{W_0} p_0(x) d\mu(x)=\alpha$$ where $p_i(x)$ is the likelihood function under the hypothesis $i=0,1$. Then $\forall W$, such that  $$\int_{W_0} p_0(x) d\mu(x) = \int_W p_0(x) d\mu(x) = \alpha$$ the following inequality is true: $$\int_{W_0} p_1(x) d\mu(x) \ge \int_W p_1(x) d\mu(x)$$ That is: an $H_0$ test based on the set $W_0$ is the most powerful test. $\mathbf{Proof}$ This is taken directly from my textbook: \begin{align} \int_{W_0} p_1(x) d\mu(x) - \int_{W} p_1(x) d\mu(x) &= \int_{W_0-W} p_1(x) d\mu(x)- \int_{W-W_0} p_1(x) d\mu(x)\\ & \ge \int_{W_0-W} k p_0(x) d\mu(x)- \int_{W-W_0} k p_0(x) d\mu(x)\\ &= \int_{W_0} k p_0(x) d\mu(x) - \int_{W} k p_0(x) d\mu(x) \\ &= k \alpha - k \alpha\\ &=0 \end{align} I don't understand the magic in the first line. $$\int_{W_0-W} p_1(x) d\mu(x)- \int_{W-W_0} p_1(x) d\mu(x)$$ What is the meaning of $W_0 - W$?  These are sets, so shouldn't we have $W_0 \setminus W$ instead? I know we can't directly say that  $$\int_{W_0} p_1(x) d\mu(x) - \int_{W} p_1(x) d\mu(x) \ge \int_{W_0} k p_0(x) d\mu(x) - \int_{W} k p_0(x) d\mu(x) $$  because we only know that $\forall x \in W_0$ $$\int_{W_0} p_1(x) d\mu(x) \ge \int_{W_0} k p_0(x) d\mu(x)$$ and the same is not necessarily true for $x \in W$. But how is the intermediate step helping us? (i.e. what's going on there?)","$\mathbf{Theorem}$ Let $\forall \alpha \in (0,1) \space \exists \space k$, such that for $W_0 = \{ x: p_1(x) \ge k p_0(x) \}$, $$\int_{W_0} p_0(x) d\mu(x)=\alpha$$ where $p_i(x)$ is the likelihood function under the hypothesis $i=0,1$. Then $\forall W$, such that  $$\int_{W_0} p_0(x) d\mu(x) = \int_W p_0(x) d\mu(x) = \alpha$$ the following inequality is true: $$\int_{W_0} p_1(x) d\mu(x) \ge \int_W p_1(x) d\mu(x)$$ That is: an $H_0$ test based on the set $W_0$ is the most powerful test. $\mathbf{Proof}$ This is taken directly from my textbook: \begin{align} \int_{W_0} p_1(x) d\mu(x) - \int_{W} p_1(x) d\mu(x) &= \int_{W_0-W} p_1(x) d\mu(x)- \int_{W-W_0} p_1(x) d\mu(x)\\ & \ge \int_{W_0-W} k p_0(x) d\mu(x)- \int_{W-W_0} k p_0(x) d\mu(x)\\ &= \int_{W_0} k p_0(x) d\mu(x) - \int_{W} k p_0(x) d\mu(x) \\ &= k \alpha - k \alpha\\ &=0 \end{align} I don't understand the magic in the first line. $$\int_{W_0-W} p_1(x) d\mu(x)- \int_{W-W_0} p_1(x) d\mu(x)$$ What is the meaning of $W_0 - W$?  These are sets, so shouldn't we have $W_0 \setminus W$ instead? I know we can't directly say that  $$\int_{W_0} p_1(x) d\mu(x) - \int_{W} p_1(x) d\mu(x) \ge \int_{W_0} k p_0(x) d\mu(x) - \int_{W} k p_0(x) d\mu(x) $$  because we only know that $\forall x \in W_0$ $$\int_{W_0} p_1(x) d\mu(x) \ge \int_{W_0} k p_0(x) d\mu(x)$$ and the same is not necessarily true for $x \in W$. But how is the intermediate step helping us? (i.e. what's going on there?)",,"['probability', 'statistics', 'statistical-inference', 'hypothesis-testing']"
38,Moment Generating Function of an Unspecified Distribution,Moment Generating Function of an Unspecified Distribution,,"This is the original question - I have inserted my own attempt at it, please critique as you wish. Suppose we are interested in looking at the number of times a stock drops before it first increases in value. It is known that the stock value increases with probability $\theta$ . Let $Y$ be the number of times the stock value drops before it first increases in value. Find the MGF of Y, and hence E(Y). Now suppose that we are interested in 3 stocks. It is known that independently each stock's value will increase with probability $\theta$ . Let $Y_i$ be the number of times the stock value drops before it first increases in value for stocks 1,2 and 3 respectively. Let $V=5Y_1-3Y_2+2Y_3$ . Find the MGF of V. I assume this can be modelled as a Poisson distribution. Hence it has pdf of $p(y)=\frac{\theta^x e^{-\theta}}{y!}$ $$E(e^{ty})=\sum\limits_{y=1}^\infty e^{ty}f(y)=e^{-\theta}e^{et\theta}\sum\limits_{y=1}^\infty \frac{(e^t\theta)^y e^{-(e^t\theta)}}{y!}$$ Which would result in MFG of $e^{\theta(e^t-1)}$ . After differentiation and $t=0$ , it is obtained that $E(Y)=\theta$ . Now as per the second part of the question, I'm unsure if I proceeded it correctly - $$M_v(t)=E(e^{t(5Y_1-3Y_2+2Y_3)})=M_{Y_1}(5t)M_{Y_2}(-3t)M_{Y_3}(2t)$$ How do I further simplify it? Or did I approach it incorrectly? Thanks for all the help!","This is the original question - I have inserted my own attempt at it, please critique as you wish. Suppose we are interested in looking at the number of times a stock drops before it first increases in value. It is known that the stock value increases with probability . Let be the number of times the stock value drops before it first increases in value. Find the MGF of Y, and hence E(Y). Now suppose that we are interested in 3 stocks. It is known that independently each stock's value will increase with probability . Let be the number of times the stock value drops before it first increases in value for stocks 1,2 and 3 respectively. Let . Find the MGF of V. I assume this can be modelled as a Poisson distribution. Hence it has pdf of Which would result in MFG of . After differentiation and , it is obtained that . Now as per the second part of the question, I'm unsure if I proceeded it correctly - How do I further simplify it? Or did I approach it incorrectly? Thanks for all the help!",\theta Y \theta Y_i V=5Y_1-3Y_2+2Y_3 p(y)=\frac{\theta^x e^{-\theta}}{y!} E(e^{ty})=\sum\limits_{y=1}^\infty e^{ty}f(y)=e^{-\theta}e^{et\theta}\sum\limits_{y=1}^\infty \frac{(e^t\theta)^y e^{-(e^t\theta)}}{y!} e^{\theta(e^t-1)} t=0 E(Y)=\theta M_v(t)=E(e^{t(5Y_1-3Y_2+2Y_3)})=M_{Y_1}(5t)M_{Y_2}(-3t)M_{Y_3}(2t),"['probability', 'probability-distributions']"
39,Expectation of $X$log$(X)$ when $X$ is Poisson random variable,Expectation of log when  is Poisson random variable,X (X) X,"I am trying to compute $\mathbb{E}[X\mathrm{log}(X)]$ where $X$ is a Poisson random variable with mean $\lambda$, so $Pr(X=x) = \frac{e^{-\lambda}\lambda^x}{x!}$. My usual approach to computing $\mathbb{E}[f(X)]$ is to take the Taylor series of $f$ and use the moment generating function, which for X is $M_X(t)=e^{\lambda(e^t-1)}$, and then $\mathbb{E}[f(X)]=\sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}M_x^{(n)}(0)$ However, the Taylor series of $f(x)=x\mathrm{log}(x)$ only converges if $|x-1|<1$. Otherwise we have to rewrite the series in a form that's just as hard to work with. And trying to compute the expectation directly fails me. Are there other tricks out there for computing expectations for Poisson r.v.'s?","I am trying to compute $\mathbb{E}[X\mathrm{log}(X)]$ where $X$ is a Poisson random variable with mean $\lambda$, so $Pr(X=x) = \frac{e^{-\lambda}\lambda^x}{x!}$. My usual approach to computing $\mathbb{E}[f(X)]$ is to take the Taylor series of $f$ and use the moment generating function, which for X is $M_X(t)=e^{\lambda(e^t-1)}$, and then $\mathbb{E}[f(X)]=\sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}M_x^{(n)}(0)$ However, the Taylor series of $f(x)=x\mathrm{log}(x)$ only converges if $|x-1|<1$. Otherwise we have to rewrite the series in a form that's just as hard to work with. And trying to compute the expectation directly fails me. Are there other tricks out there for computing expectations for Poisson r.v.'s?",,['probability']
40,A basic doubt on calculating $E[g(X)]$,A basic doubt on calculating,E[g(X)],"Assume $X$ is a continuous random variable and $g$ is a measurable function. Then $g(X)$ is a random variable. Now, there are two ways to calculate $E[g(X)]$. 1) Assume $Y=g(X)$ and find the density of $Y$ from density of $X$ and then calculate $$E[g(X)]=\int_{-\infty}^\infty yf_Y(y)\,dy$$ 2) Another approach I see in books is use the formula $$E[g(X)]=\int_{-\infty}^\infty g(x)f_X(x)\,dx$$ How to prove that both method is giving the correct result ? Is the question making sense ? If $X$ is a discrete random variable then I am able to prove it, but when $X$ is continuous then I am stuck.","Assume $X$ is a continuous random variable and $g$ is a measurable function. Then $g(X)$ is a random variable. Now, there are two ways to calculate $E[g(X)]$. 1) Assume $Y=g(X)$ and find the density of $Y$ from density of $X$ and then calculate $$E[g(X)]=\int_{-\infty}^\infty yf_Y(y)\,dy$$ 2) Another approach I see in books is use the formula $$E[g(X)]=\int_{-\infty}^\infty g(x)f_X(x)\,dx$$ How to prove that both method is giving the correct result ? Is the question making sense ? If $X$ is a discrete random variable then I am able to prove it, but when $X$ is continuous then I am stuck.",,['probability']
41,Probability of a submatrix with all 1s,Probability of a submatrix with all 1s,,"I'm not an expert and while reading an article on grid coloring these two questions came to my mind: Given a $n \times n$ matrix randomly filled with values in $\{0,1\}$ ( $P(a_{ij} = 1) = 1/2$), what is the probability that it contains at least one $k \times k \quad (k \leq n)$ submatrix made of all $1$s or all $0$s (""monochromatic"") ? Given a $n \times n$ matrix randomly filled with values in $\{0,1,2,3\}$, what is the probability that it contains at least one $k \times k \quad (k \leq n)$ submatrix composed only with two distinct values (i.e. every element of the submatrix belongs to some (not fixed) $\{v_1,v_2\} \subset \{0,1,2,3\}$) ?","I'm not an expert and while reading an article on grid coloring these two questions came to my mind: Given a $n \times n$ matrix randomly filled with values in $\{0,1\}$ ( $P(a_{ij} = 1) = 1/2$), what is the probability that it contains at least one $k \times k \quad (k \leq n)$ submatrix made of all $1$s or all $0$s (""monochromatic"") ? Given a $n \times n$ matrix randomly filled with values in $\{0,1,2,3\}$, what is the probability that it contains at least one $k \times k \quad (k \leq n)$ submatrix composed only with two distinct values (i.e. every element of the submatrix belongs to some (not fixed) $\{v_1,v_2\} \subset \{0,1,2,3\}$) ?",,['probability']
42,Problems sampling from a $pdf$ over $SO\left(3\right)$,Problems sampling from a  over,pdf SO\left(3\right),"I have a probability density function over $SO\left(3\right)$, which I am trying to sample from. The $pdf$ is given as a generalized fourier series: $$ f\left(\omega,\theta,\phi\right)=\sum s_{\lambda}^{n}Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$$ where $s_{\lambda}^{n}$ are the coefficients and $Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$ are basis functions (symmetrized hyperspherical harmonics), and $SO\left(3\right)$ is parameterized by the variables $\left(\omega,\theta,\phi\right)$, which are the rotation angle, and spherical coordinates of the rotation axis, respectively. I want to sample values of $\left(\omega,\theta,\phi\right)$ (i.e. rotations) from this distribution, but I'm having trouble doing so. So far I have essentially tried two methods: rejection sampling, a discrete method. Both methods have given me something that is qualitatively similar to what I would expect, but they seem to have an erroneous uniform distribution superimposed. So I have two questions: (1) Any ideas why I might be getting this uniform noise? (2) Any suggestions of how to fix it or a better way to sample from this kind of distribution? Further Details: To check my sampling method I used some software to generate a known distribution and sample rotations. I then computed $s_{\lambda}^{n}$ from these ""correct samples"". Then I tried to generate samples myself from the spectral form of $f\left(\omega,\theta,\phi\right)$ given above. Next I calculated $s_{\lambda}^{n}$ from my samples and compared the two. My samples led to the low order terms being generally too small in magnitude and the higher order terms being too large in magnitude. The discrete method that I used consisted of generating a ""grid"" of points over $SO\left(3\right)$, and using these as the centers of bins. The bins were sized proportional to the probability density at the bin center. Then uniform samples were generated and the number that fell in each bin was then proportional to the associated probability of the respective bins. Again, both methods produced a sort of background noise which looks like a uniform distribution on top of the correct distribution. As, a side note, it seems like I ought to be able to exploit the form of this expression for efficient sampling, but I haven't made use of the spectral decomposition at all in my attempts.","I have a probability density function over $SO\left(3\right)$, which I am trying to sample from. The $pdf$ is given as a generalized fourier series: $$ f\left(\omega,\theta,\phi\right)=\sum s_{\lambda}^{n}Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$$ where $s_{\lambda}^{n}$ are the coefficients and $Z_{\lambda}^{n}\left(\omega,\theta,\phi\right)$ are basis functions (symmetrized hyperspherical harmonics), and $SO\left(3\right)$ is parameterized by the variables $\left(\omega,\theta,\phi\right)$, which are the rotation angle, and spherical coordinates of the rotation axis, respectively. I want to sample values of $\left(\omega,\theta,\phi\right)$ (i.e. rotations) from this distribution, but I'm having trouble doing so. So far I have essentially tried two methods: rejection sampling, a discrete method. Both methods have given me something that is qualitatively similar to what I would expect, but they seem to have an erroneous uniform distribution superimposed. So I have two questions: (1) Any ideas why I might be getting this uniform noise? (2) Any suggestions of how to fix it or a better way to sample from this kind of distribution? Further Details: To check my sampling method I used some software to generate a known distribution and sample rotations. I then computed $s_{\lambda}^{n}$ from these ""correct samples"". Then I tried to generate samples myself from the spectral form of $f\left(\omega,\theta,\phi\right)$ given above. Next I calculated $s_{\lambda}^{n}$ from my samples and compared the two. My samples led to the low order terms being generally too small in magnitude and the higher order terms being too large in magnitude. The discrete method that I used consisted of generating a ""grid"" of points over $SO\left(3\right)$, and using these as the centers of bins. The bins were sized proportional to the probability density at the bin center. Then uniform samples were generated and the number that fell in each bin was then proportional to the associated probability of the respective bins. Again, both methods produced a sort of background noise which looks like a uniform distribution on top of the correct distribution. As, a side note, it seems like I ought to be able to exploit the form of this expression for efficient sampling, but I haven't made use of the spectral decomposition at all in my attempts.",,"['probability', 'probability-distributions', 'rotations', 'sampling']"
43,How does the increase in overall number of events affect the peak (events/time)?,How does the increase in overall number of events affect the peak (events/time)?,,"I have a (simple?) question that I hope someone will find interesting enough to help me out with. A web site has a given number of subscribers who generate a certain amount of traffic on the web server. Hits (web requests) are distributed throughout the day and result in a peak load of x hits/second. Question: should the number of users increase (let's say double) and follow the same usage pattern, how would the peak load (hits/second) be affected? I strongly doubt that the answer is 2x hits/second and realise that more information might be needed, to start from the actual distribution of the hits and the average total hits per day. Anyone intrigued and kind enough to lend a hand? Thanks, Paolo","I have a (simple?) question that I hope someone will find interesting enough to help me out with. A web site has a given number of subscribers who generate a certain amount of traffic on the web server. Hits (web requests) are distributed throughout the day and result in a peak load of x hits/second. Question: should the number of users increase (let's say double) and follow the same usage pattern, how would the peak load (hits/second) be affected? I strongly doubt that the answer is 2x hits/second and realise that more information might be needed, to start from the actual distribution of the hits and the average total hits per day. Anyone intrigued and kind enough to lend a hand? Thanks, Paolo",,"['probability', 'statistics', 'probability-distributions']"
44,Using probability to determine dependent events,Using probability to determine dependent events,,"In my HS math class, I'm teaching Prob & Stats.  We are studying how the intersection of events can show dependence.  For example, we took a survey of students in the HS:  57% of those surveyed are in Extra-curricular Activities, 65% of those surveyed are on the Honor Roll, and 46% are both.  If these two events were independent, the the ""both"" (intersection) would be equal to their product: P(EC) * P(HR) = 37%.  Since the observed intersection is higher, these have a positive correlation. Is this valid statistics?  I.e., is this kind of data collection and statistical analysis something that is done in research, in order to show events are independent or dependent?  I'd like to be able to tell my students that ""This is how it is done in the 'Real World.'""  Can anyone give me examples of real-world situations where this is done?","In my HS math class, I'm teaching Prob & Stats.  We are studying how the intersection of events can show dependence.  For example, we took a survey of students in the HS:  57% of those surveyed are in Extra-curricular Activities, 65% of those surveyed are on the Honor Roll, and 46% are both.  If these two events were independent, the the ""both"" (intersection) would be equal to their product: P(EC) * P(HR) = 37%.  Since the observed intersection is higher, these have a positive correlation. Is this valid statistics?  I.e., is this kind of data collection and statistical analysis something that is done in research, in order to show events are independent or dependent?  I'd like to be able to tell my students that ""This is how it is done in the 'Real World.'""  Can anyone give me examples of real-world situations where this is done?",,['probability']
45,Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that $Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1]$ for i.i.d. real RVs $X$ and $Y$,Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that  for i.i.d. real RVs  and,Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1] X Y,"Doing a little reading over the break ( The Probabilistic Method by Alon and Spencer); can't come up with the solution for this seemingly simple (and perhaps even a little surprising?) result: (A-S 1.6.3) Prove that for every two independent identically distributed real random variables $X$ and $Y$ , $$Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1].$$","Doing a little reading over the break ( The Probabilistic Method by Alon and Spencer); can't come up with the solution for this seemingly simple (and perhaps even a little surprising?) result: (A-S 1.6.3) Prove that for every two independent identically distributed real random variables and ,",X Y Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1].,"['probability', 'combinatorics', 'probability-theory', 'measure-theory', 'inequality']"
46,2-dimensional percolation and a random graph,2-dimensional percolation and a random graph,,"Imagine turning the square grid defined by $\mathbb{N}^2$ in the plane into a directed graph. The vertices are $\mathbb{N}^2$ and for each vertex $(x,y)$, there is an edge pointing from it to $(x+1, y)$ and another pointing to $(x,y+1)$. Turn it into a random graph, by letting the edges appear independently at random with probability $p$. Let $p_n$ be the probability that there is a directed path from (0,0) to the set of points of taxi-cab distance $n$ to the origin. Then we see that $p_n$ is a decreasing sequence, whose limit is the probability that there is an infinite directed path. Take $n$. I want to know how close $p_n$ is to the limit. Let $r_n=p_{n+1}/p_n$. If I know tha t $r_n, r_{n+1}, \dots$ are ""large"", then somehow, I know I am ""close"" to the limit. I am trying to come up with a lower bound for $r_n$. The easiest thing, is to argue that, this equals the probability that there is a path reaching points at taxi-cab distance $n+1$ given that there is a path reaching those at distance $n$. This conditional probability is at least $(1-(1-p)^2)$, which is the probability that at one vertex there are edges pointing out from it. But this is not a good lower bound, because ideally I want to obtain a lower bound that depends on $n$ converging to $1$. Can anyone point out something useful?","Imagine turning the square grid defined by $\mathbb{N}^2$ in the plane into a directed graph. The vertices are $\mathbb{N}^2$ and for each vertex $(x,y)$, there is an edge pointing from it to $(x+1, y)$ and another pointing to $(x,y+1)$. Turn it into a random graph, by letting the edges appear independently at random with probability $p$. Let $p_n$ be the probability that there is a directed path from (0,0) to the set of points of taxi-cab distance $n$ to the origin. Then we see that $p_n$ is a decreasing sequence, whose limit is the probability that there is an infinite directed path. Take $n$. I want to know how close $p_n$ is to the limit. Let $r_n=p_{n+1}/p_n$. If I know tha t $r_n, r_{n+1}, \dots$ are ""large"", then somehow, I know I am ""close"" to the limit. I am trying to come up with a lower bound for $r_n$. The easiest thing, is to argue that, this equals the probability that there is a path reaching points at taxi-cab distance $n+1$ given that there is a path reaching those at distance $n$. This conditional probability is at least $(1-(1-p)^2)$, which is the probability that at one vertex there are edges pointing out from it. But this is not a good lower bound, because ideally I want to obtain a lower bound that depends on $n$ converging to $1$. Can anyone point out something useful?",,"['probability', 'graph-theory', 'random-graphs', 'percolation']"
47,Question about sample autocovariance function,Question about sample autocovariance function,,"I'm reading a time series analysis book and the formula for sample autocovariance is defined in the book as: $\widehat{\gamma}(h) = n^{-1}\displaystyle\sum_{t=1}^{n-h}(x_{t+h}-\bar{x})(x_t-\bar{x})$ with $\widehat{\gamma}(-h) = \widehat{\gamma}(h)\;$ for $\;h = 0,1, ..., n-1$. $\bar{x}$ is the mean. Can someone explain intuitively why we divide the sum by $n$ and not by $n-h$? The book explains the reason is, because the formula above is a non-negative definite function and so dividing by $n$ is preferred, but this doesn't explain this to me clear enough. Can someone maybe prove this or show example or something. I'm a bit confused x) To me the intuitive thing at first would be to divide by $n-h$. Is this an unbiased or biased estimator of autocovariance? Thank you for any help =)","I'm reading a time series analysis book and the formula for sample autocovariance is defined in the book as: $\widehat{\gamma}(h) = n^{-1}\displaystyle\sum_{t=1}^{n-h}(x_{t+h}-\bar{x})(x_t-\bar{x})$ with $\widehat{\gamma}(-h) = \widehat{\gamma}(h)\;$ for $\;h = 0,1, ..., n-1$. $\bar{x}$ is the mean. Can someone explain intuitively why we divide the sum by $n$ and not by $n-h$? The book explains the reason is, because the formula above is a non-negative definite function and so dividing by $n$ is preferred, but this doesn't explain this to me clear enough. Can someone maybe prove this or show example or something. I'm a bit confused x) To me the intuitive thing at first would be to divide by $n-h$. Is this an unbiased or biased estimator of autocovariance? Thank you for any help =)",,"['probability', 'statistics', 'time-series']"
48,"Coin Game, Probability and Fairness","Coin Game, Probability and Fairness",,"The following game is being played : Player $\mathrm{B}$ pays to Player $\mathrm{A}$ an amount $\mathrm{X}$ and throws a coin at most $20$ times. If at the toss $k\space (k \leq 20)$ tail is thrown, the game stops and player $\mathrm{A}$ has to pay to player $\mathrm{B}$ $2^k$ cents. Else A gets to keep the stake $\mathrm{X}$. Now the questions are: When is the game fair and what is a corresponding fair stake $\mathrm{X}$? I assume that since it is a binomial distribution, the expected value is $np$, hence here the expected value is $10$ and so $X = 10$ for a fair game. Does anything else has to be considered such that the game is fair? Now the game is changed as follows: $\mathrm{A}$ has only a capital of $50$ dollars, but he lets player $\mathrm{B}$ throw the coin $20$ times anyway. The rules are now changed such that $\mathrm{A}$ pays to player $\mathrm{B}$ $ (5000+X)$ cents if $\mathrm{B}$ throws tail for the first time at the $k$-th throw and $2^k > (5000+X)$ holds. What would be here a fair amount $\mathrm{X}$?","The following game is being played : Player $\mathrm{B}$ pays to Player $\mathrm{A}$ an amount $\mathrm{X}$ and throws a coin at most $20$ times. If at the toss $k\space (k \leq 20)$ tail is thrown, the game stops and player $\mathrm{A}$ has to pay to player $\mathrm{B}$ $2^k$ cents. Else A gets to keep the stake $\mathrm{X}$. Now the questions are: When is the game fair and what is a corresponding fair stake $\mathrm{X}$? I assume that since it is a binomial distribution, the expected value is $np$, hence here the expected value is $10$ and so $X = 10$ for a fair game. Does anything else has to be considered such that the game is fair? Now the game is changed as follows: $\mathrm{A}$ has only a capital of $50$ dollars, but he lets player $\mathrm{B}$ throw the coin $20$ times anyway. The rules are now changed such that $\mathrm{A}$ pays to player $\mathrm{B}$ $ (5000+X)$ cents if $\mathrm{B}$ throws tail for the first time at the $k$-th throw and $2^k > (5000+X)$ holds. What would be here a fair amount $\mathrm{X}$?",,"['probability', 'combinatorics', 'decision-theory']"
49,Expected area of intersection of set of special circles,Expected area of intersection of set of special circles,,"If we pick randomly three points $x_i, i=1,2,3 $ inside a circle of radius $R$, and we take all possible couples $\binom3 2$ of the intersection of two circles $B_k= \left(C(x_i,|x_i-x_j|)\cap C(x_j,|x_i-x_j|)\right) $ , $k=1,2,3$. Where in each couple, the two circles are centred at two points with radius equal to the distance between them. What is the expected area of the intersection of the three couples $$\bigcap_{i\ne j}\left(C(x_i,|x_i-x_j|)\cap C(x_j,|x_i-x_j|)\right)$$ This is part of a problem which consist in determining the region where a device is.","If we pick randomly three points $x_i, i=1,2,3 $ inside a circle of radius $R$, and we take all possible couples $\binom3 2$ of the intersection of two circles $B_k= \left(C(x_i,|x_i-x_j|)\cap C(x_j,|x_i-x_j|)\right) $ , $k=1,2,3$. Where in each couple, the two circles are centred at two points with radius equal to the distance between them. What is the expected area of the intersection of the three couples $$\bigcap_{i\ne j}\left(C(x_i,|x_i-x_j|)\cap C(x_j,|x_i-x_j|)\right)$$ This is part of a problem which consist in determining the region where a device is.",,"['probability', 'geometry']"
50,Stock behaviour probability,Stock behaviour probability,,"I found this question in a financial mathematics course exam, could anyone please help with a solution and some explanation? Thanks in advance :) A stock has beta of $2.0$ and stock specific daily volatility of $0.02$.   Suppose that yesterday’s closing price was $100$ and today the market   goes up by $1$%. What’s the probability of today’s closing price being   at least $103$?","I found this question in a financial mathematics course exam, could anyone please help with a solution and some explanation? Thanks in advance :) A stock has beta of $2.0$ and stock specific daily volatility of $0.02$.   Suppose that yesterday’s closing price was $100$ and today the market   goes up by $1$%. What’s the probability of today’s closing price being   at least $103$?",,"['probability', 'statistics']"
51,A probability question that involves $5$ dice,A probability question that involves  dice,5,"For five dice that are thrown, I am struggling to find the probability of one number showing exactly three times and a second number showing twice. For the one number showing exactly three times, the probability is: $$ {5 \choose 3} \times \left ( \frac{1}{6} \right )^{3} \times \left ( \frac{5}{6}\right )^{2} $$ However, I understand I cannot just multiply this by  $$ {5 \choose 2} \times \left ( \frac{1}{6} \right )^{2} \times \left ( \frac{5}{6}\right )^{3} $$ as this includes the probability of picking the original number twice which allows the possibility of the same number being shown $5$ times. I am unsure of what to do next, I tried to write down all the combinations manually and got $10$ possible outcomes so for example if a was the value found $3$ times and $b$ was the value obtained $2$ times one arrangement would be '$aaabb$'. However I still am unsure of what to do after I get $10$ different possibilities and I am not sure how I could even get the $10$ different combinations mathematically. Any hints or advice on what to do next would be much appreciated.","For five dice that are thrown, I am struggling to find the probability of one number showing exactly three times and a second number showing twice. For the one number showing exactly three times, the probability is: $$ {5 \choose 3} \times \left ( \frac{1}{6} \right )^{3} \times \left ( \frac{5}{6}\right )^{2} $$ However, I understand I cannot just multiply this by  $$ {5 \choose 2} \times \left ( \frac{1}{6} \right )^{2} \times \left ( \frac{5}{6}\right )^{3} $$ as this includes the probability of picking the original number twice which allows the possibility of the same number being shown $5$ times. I am unsure of what to do next, I tried to write down all the combinations manually and got $10$ possible outcomes so for example if a was the value found $3$ times and $b$ was the value obtained $2$ times one arrangement would be '$aaabb$'. However I still am unsure of what to do after I get $10$ different possibilities and I am not sure how I could even get the $10$ different combinations mathematically. Any hints or advice on what to do next would be much appreciated.",,['probability']
52,Using Bernoulli distribution approximate the $q$-th moment,Using Bernoulli distribution approximate the -th moment,q,"Let $x$ be vector in $R^n$. Let $\pi(⋅)$  be a permutation on the set $\{1,\ldots,n\}$  with a uniform distribution.  Let $|m|\leq n, m \in Z$. Using Bernoulli (or maybe some other) distribution approimate the $q$-th moment $$ E\left|\sum_{i=1}^mx_{\pi(i)}\right|^q, \quad q\geq 2. $$ Thank you.","Let $x$ be vector in $R^n$. Let $\pi(⋅)$  be a permutation on the set $\{1,\ldots,n\}$  with a uniform distribution.  Let $|m|\leq n, m \in Z$. Using Bernoulli (or maybe some other) distribution approimate the $q$-th moment $$ E\left|\sum_{i=1}^mx_{\pi(i)}\right|^q, \quad q\geq 2. $$ Thank you.",,"['probability', 'combinatorics', 'statistics', 'probability-distributions']"
53,Finding intersecting subsets for given binomial coefficient,Finding intersecting subsets for given binomial coefficient,,"My apologies if this question is more appropriate for mathisfun.com, but I can only get so far reading about combinatrics and set theory before the interlocking logic becomes totally blurred.  If this is a totally fundamental concept, feel free just to name it so I can read and understand the math myself. So the goal is to minimize repetition of questions on a quiz to avoid (or really to slow down) the creation of a master key. This is for a client and I've explained that to make this truly realistic the number of questions in the master pool would need to be huge, but I want to show them the math behind their idea. So they suggested having a 20 question pool with a given set being a 5-member subset.  I figured out that the total number of unique quizes $\binom{20}{5}$ would be $\frac{20!}{5!(20-5)!}$ or 15504 unique quizes.  But I know that most of those quizes will be near identical and that it won't take as long for cheaters to see all 20 questions to make the key. To prove this to myself (without knowing the math), I simplified the total combinations to $\binom{4}{3}$ , like so: {a, b, c, d} = { {a,b,c}; {a,b,d}; {b,c,d}; {a,c,d} } And I see that it only takes seeing any 2 quizes to see all 4 members of the master set.  So knowing that the number of combinations (binomial coefficient!) is not equivalent to number of unique appearances of the master-set, I'd like to know the actual math involved to show the client that while they have a ton of quizes, it only takes $x$ to know all members. Thanks as always. Addendum A bit more research has introduced me to the NP-complete problem known as Exact Cover, which would be (if I'm reading it right) a precise set of subsets which have a union equal to the original master-set.  I just want to clarify that this constraint of perfect overlap is not necessary for my question, only the minimum number of subsets that would result in a union that has all master-set members, regardless of repetition, in order to demonstrate how many subsets are needed to know the original set (with the assumption that the seeker of the master-set knows the total membership count). I tweaked my micro-experiment from $\binom{4}{3}$ to $\binom{4}{2}$ resulting in 6 combinations and the ability to derive the master-set no longer being possible with a specific number of arbitrary subsets. Instead I get: {a, b, c, d} = { {ab} ; {ac} ; {ad} ; {bc} ; {bd} ; {cd} } which could derive the master set using the first three ( $a$ ) groups, or the exact cover of ${ {a,b}; {c,d} }$ .  This has me thinking that the minimum subsets needed to derive the original set is equal to the number of subsets where any given member occurs (so in this case 3 $a$ s, but this doesn't match up to the $\binom{4}{3}$ , where it can be found with 2 subsets.  The next obvious solution (to me) is that the minimum number needed to derive the master-set (blindly) is half of the total number of subsets, but I would really want a link to a proof or a simple-english demonstration on how a pool of 20 questions would require 7752 subsets to know with certainty that all 20 members have appeared at least once. Again, thanks. Question as Probability: I have a bag of Scrabble tiles and I know the following: The bag contains 20 tiles, Each tile is unique (no two tiles have the same character), The tiles come from a much larger (and otherwise irrelevant) set of an expansion set including numbers and non-Roman alphabet characters, thus removing any advantage of knowing that this set of 20 comes from a larger-but-limited set (in other words, the characters are only informative to each other and I may get all Klingon or a mix of Chinese and Tamil. I should not assume anything about the set other than what is in the bag). I am allowed to perform the following steps in the order given as many times as I want: Pull out 5 tiles, Write down the characters drawn, Return the tiles to the bag. Lather, Rinse, Repeat. Also: I have magical fingers that prevent me from drawing the same set of 5 twice, thus reducing the number of draws from infinity to 15504 possible draws. My objective is to have all 20 characters written down eventually and then stop drawing characters. I know that the total number of unique combinations I could draw is $\binom{20}{5}$ which is 15504.  I also know that the minimum draws required is equal to $\lceil{20}/{5}\rceil$ , which would be very lucky.  What I am interested in is the maximum number of draws required to reveal all 20 characters.","My apologies if this question is more appropriate for mathisfun.com, but I can only get so far reading about combinatrics and set theory before the interlocking logic becomes totally blurred.  If this is a totally fundamental concept, feel free just to name it so I can read and understand the math myself. So the goal is to minimize repetition of questions on a quiz to avoid (or really to slow down) the creation of a master key. This is for a client and I've explained that to make this truly realistic the number of questions in the master pool would need to be huge, but I want to show them the math behind their idea. So they suggested having a 20 question pool with a given set being a 5-member subset.  I figured out that the total number of unique quizes would be or 15504 unique quizes.  But I know that most of those quizes will be near identical and that it won't take as long for cheaters to see all 20 questions to make the key. To prove this to myself (without knowing the math), I simplified the total combinations to , like so: {a, b, c, d} = { {a,b,c}; {a,b,d}; {b,c,d}; {a,c,d} } And I see that it only takes seeing any 2 quizes to see all 4 members of the master set.  So knowing that the number of combinations (binomial coefficient!) is not equivalent to number of unique appearances of the master-set, I'd like to know the actual math involved to show the client that while they have a ton of quizes, it only takes to know all members. Thanks as always. Addendum A bit more research has introduced me to the NP-complete problem known as Exact Cover, which would be (if I'm reading it right) a precise set of subsets which have a union equal to the original master-set.  I just want to clarify that this constraint of perfect overlap is not necessary for my question, only the minimum number of subsets that would result in a union that has all master-set members, regardless of repetition, in order to demonstrate how many subsets are needed to know the original set (with the assumption that the seeker of the master-set knows the total membership count). I tweaked my micro-experiment from to resulting in 6 combinations and the ability to derive the master-set no longer being possible with a specific number of arbitrary subsets. Instead I get: {a, b, c, d} = { {ab} ; {ac} ; {ad} ; {bc} ; {bd} ; {cd} } which could derive the master set using the first three ( ) groups, or the exact cover of .  This has me thinking that the minimum subsets needed to derive the original set is equal to the number of subsets where any given member occurs (so in this case 3 s, but this doesn't match up to the , where it can be found with 2 subsets.  The next obvious solution (to me) is that the minimum number needed to derive the master-set (blindly) is half of the total number of subsets, but I would really want a link to a proof or a simple-english demonstration on how a pool of 20 questions would require 7752 subsets to know with certainty that all 20 members have appeared at least once. Again, thanks. Question as Probability: I have a bag of Scrabble tiles and I know the following: The bag contains 20 tiles, Each tile is unique (no two tiles have the same character), The tiles come from a much larger (and otherwise irrelevant) set of an expansion set including numbers and non-Roman alphabet characters, thus removing any advantage of knowing that this set of 20 comes from a larger-but-limited set (in other words, the characters are only informative to each other and I may get all Klingon or a mix of Chinese and Tamil. I should not assume anything about the set other than what is in the bag). I am allowed to perform the following steps in the order given as many times as I want: Pull out 5 tiles, Write down the characters drawn, Return the tiles to the bag. Lather, Rinse, Repeat. Also: I have magical fingers that prevent me from drawing the same set of 5 twice, thus reducing the number of draws from infinity to 15504 possible draws. My objective is to have all 20 characters written down eventually and then stop drawing characters. I know that the total number of unique combinations I could draw is which is 15504.  I also know that the minimum draws required is equal to , which would be very lucky.  What I am interested in is the maximum number of draws required to reveal all 20 characters.","\binom{20}{5} \frac{20!}{5!(20-5)!} \binom{4}{3} x \binom{4}{3} \binom{4}{2} a { {a,b}; {c,d} } a \binom{4}{3} \binom{20}{5} \lceil{20}/{5}\rceil","['probability', 'combinatorics', 'elementary-set-theory']"
54,Modeling concurrent internet users,Modeling concurrent internet users,,"I'm feeling generous in the new year and want to open my Wifi connection to the public. I want to estimate the effect that $N$ additional users on my router would have on download times. In other words, how does my waiting time for an average piece of data degrade as the number of users increases? To keep things simple I've formalized the problem in the following way: N :         the number of users. B :         the bandwidth I have (e.g. 1024 KB/s). D(x) :    the distribution of file sizes (for simplicity sake, I'm going to assume that each piece of data is a file $x$ KB large). I(y) :     the distribution of interval between requests in seconds WT :     denote the waiting time in seconds for a file. Now I know that in the real-world a user makes parallel requests, but for this particular version of the problem a single user will only issue requests in sequence. My question is: what is E[WT]? For example, if $N = 1, E[WT]$ is simply $E[D(x)]/b$. But for $N = 2$, I get all confused because the users could have overlapping requests that could affect each others waiting time, and subsequently, $I(y)$. How do I model this problem? What branch of mathematics is suitable for it?","I'm feeling generous in the new year and want to open my Wifi connection to the public. I want to estimate the effect that $N$ additional users on my router would have on download times. In other words, how does my waiting time for an average piece of data degrade as the number of users increases? To keep things simple I've formalized the problem in the following way: N :         the number of users. B :         the bandwidth I have (e.g. 1024 KB/s). D(x) :    the distribution of file sizes (for simplicity sake, I'm going to assume that each piece of data is a file $x$ KB large). I(y) :     the distribution of interval between requests in seconds WT :     denote the waiting time in seconds for a file. Now I know that in the real-world a user makes parallel requests, but for this particular version of the problem a single user will only issue requests in sequence. My question is: what is E[WT]? For example, if $N = 1, E[WT]$ is simply $E[D(x)]/b$. But for $N = 2$, I get all confused because the users could have overlapping requests that could affect each others waiting time, and subsequently, $I(y)$. How do I model this problem? What branch of mathematics is suitable for it?",,['probability']
55,How to calculate the role of chance (vs strategy) in a card game?,How to calculate the role of chance (vs strategy) in a card game?,,"I recently played two different card games with a friend: 500 Rum and Lost Cities (modified to use a regular deck of cards). We started arguing about which game was more subject to chance. I realized that I have no idea how to measure, compare, or even articulate the chance/strategy ratio of a game, and was wondering if anyone could point me in the right direction.","I recently played two different card games with a friend: 500 Rum and Lost Cities (modified to use a regular deck of cards). We started arguing about which game was more subject to chance. I realized that I have no idea how to measure, compare, or even articulate the chance/strategy ratio of a game, and was wondering if anyone could point me in the right direction.",,"['probability', 'card-games']"
56,estimation of transition probabilities from aggregate data,estimation of transition probabilities from aggregate data,,"Please, O mathematicians, help me understand the approach to the problem of estimating transition probabilities given only aggregate data in Kalbfleisch & Lawless' 1984 paper ""Least-Squares Estimation of Transition Probabilities from Aggregate Data"". (Or some other approach—it's the estimation that interests me, not that approach in particular.) Forgive the somewhat janky but hopefully comprehensible notation. Here's my particular problem. We have some number of people; each person $i$ is in a state $X_i(t)$ at time $t$ and can move at time $t+1$ into any state $0 \ldots X_i(t)+1$ inclusive. At time $t=0$ everyone is in state $0$. The individual state transitions are unobserved; all we observe are the counts of people in a given state $j$ at time $t$: $\mathbf{M}_{t,j} = \#\{i : X_i(t) = j\}$. Because everyone starts in state $0$ at time $0$, and because you can only move to at most state $k+1$ if you were formerly in state $k$, this generates an upper-triangular matrix of counts. We want to know the probabilities of the possible state transitions $\mathbf{p}_{k,j} = \Pr(X_i(t+1) = j \mid X_i(t) = k)$ given the counts in $\mathbf{M}$. Kalbfleisch & Lawless's paper seems to be about exactly this . (The paper is available here if you want to look at it.) However, I can't figure out how to apply their approach at all. (Doubtless because of my more general ignorance.) They give a couple of examples so I wanted to work through them and hit a wall pretty quickly. Some things in particular I am failing to understand: On p. 171 several equations are defined prefaced by the clause ""if there are no structural $0$'s, so that $r = k(k-1)$"" or ""if $r = k(k-1)$"". However, in the first example, there are structural zeroes and the answers given to the examples presume that (if you dont' take the structural zeroes into account the dimensions of several matrices will differ from what they are claimed to be in the text). There are also structural zeroes in my particular problem, so I would like to know if there's a straightforward way to proceed in that case. Also on p. 171 the matrices $\mathbf{B}_t$ are defined for $t = 1, \ldots, m$, but later equations involve the summation from $t = 1 \ldots m$ of terms involving $\mathbf{B}_{t-1}$, meaning that $\mathbf{B}_0$ must be defined. Perhaps more fundamentally I don't really understand why the last column of their matrix $\mathbf{P}$ is cut off—don't we want to know e.g. $p_{13}$ as well as $p_{12}$? I suspect I am missing some very basic things, but I know very little about the subject (I'm interested in it for a particular practical problem). If anyone can help me understand how to compute what I'm after, or the mechanism described in the paper, that would be immensely helpful. Thanks.","Please, O mathematicians, help me understand the approach to the problem of estimating transition probabilities given only aggregate data in Kalbfleisch & Lawless' 1984 paper ""Least-Squares Estimation of Transition Probabilities from Aggregate Data"". (Or some other approach—it's the estimation that interests me, not that approach in particular.) Forgive the somewhat janky but hopefully comprehensible notation. Here's my particular problem. We have some number of people; each person $i$ is in a state $X_i(t)$ at time $t$ and can move at time $t+1$ into any state $0 \ldots X_i(t)+1$ inclusive. At time $t=0$ everyone is in state $0$. The individual state transitions are unobserved; all we observe are the counts of people in a given state $j$ at time $t$: $\mathbf{M}_{t,j} = \#\{i : X_i(t) = j\}$. Because everyone starts in state $0$ at time $0$, and because you can only move to at most state $k+1$ if you were formerly in state $k$, this generates an upper-triangular matrix of counts. We want to know the probabilities of the possible state transitions $\mathbf{p}_{k,j} = \Pr(X_i(t+1) = j \mid X_i(t) = k)$ given the counts in $\mathbf{M}$. Kalbfleisch & Lawless's paper seems to be about exactly this . (The paper is available here if you want to look at it.) However, I can't figure out how to apply their approach at all. (Doubtless because of my more general ignorance.) They give a couple of examples so I wanted to work through them and hit a wall pretty quickly. Some things in particular I am failing to understand: On p. 171 several equations are defined prefaced by the clause ""if there are no structural $0$'s, so that $r = k(k-1)$"" or ""if $r = k(k-1)$"". However, in the first example, there are structural zeroes and the answers given to the examples presume that (if you dont' take the structural zeroes into account the dimensions of several matrices will differ from what they are claimed to be in the text). There are also structural zeroes in my particular problem, so I would like to know if there's a straightforward way to proceed in that case. Also on p. 171 the matrices $\mathbf{B}_t$ are defined for $t = 1, \ldots, m$, but later equations involve the summation from $t = 1 \ldots m$ of terms involving $\mathbf{B}_{t-1}$, meaning that $\mathbf{B}_0$ must be defined. Perhaps more fundamentally I don't really understand why the last column of their matrix $\mathbf{P}$ is cut off—don't we want to know e.g. $p_{13}$ as well as $p_{12}$? I suspect I am missing some very basic things, but I know very little about the subject (I'm interested in it for a particular practical problem). If anyone can help me understand how to compute what I'm after, or the mechanism described in the paper, that would be immensely helpful. Thanks.",,"['probability', 'matrices', 'markov-chains', 'markov-process']"
57,Estimator for sum of independent and identically distributed (iid) variables,Estimator for sum of independent and identically distributed (iid) variables,,"Consider the Chernoff bound described in Theorem 1 of this paper : Theorem 1. Let $X_1,\ldots,X_n$ be discrete, independent random variables such that $E[X_i] = 0$ and $|X_i|<1$ for all $i$. Let $X:=\sum_{i=1}^n X_i$ and $\sigma^2$ be the variance of $X$. Then,   $$\Pr\left[|X|\ge \lambda\sigma\right] \le 2e^{-\lambda^2/4}$$   for any $0\le\lambda\le 2\sigma$. I want to apply this estimator for a computation, but the variance of the variables $X_i$ is unknown to me. Apart from that, my variables satisfy all the conditions of Theorem 1. In fact, my variables are independent and identically distributed (iid). On the other hand, there is Chebyshev's inequality for finite samples which does not require knowledge of the variance (or mean) of a given random variable and replaces it with the corresponding values of my given sample.  However, the estimator is not good enough for my application and I was wondering if there is an estimator similar to Theorem 1 but not featuring the variance of the distribution itself. Intuitively speaking, it would be nice to have the best of both worlds: If that is not possible, then what is the best bound I can achieve for a sum of iid variables, without any knowledge about their variance?","Consider the Chernoff bound described in Theorem 1 of this paper : Theorem 1. Let $X_1,\ldots,X_n$ be discrete, independent random variables such that $E[X_i] = 0$ and $|X_i|<1$ for all $i$. Let $X:=\sum_{i=1}^n X_i$ and $\sigma^2$ be the variance of $X$. Then,   $$\Pr\left[|X|\ge \lambda\sigma\right] \le 2e^{-\lambda^2/4}$$   for any $0\le\lambda\le 2\sigma$. I want to apply this estimator for a computation, but the variance of the variables $X_i$ is unknown to me. Apart from that, my variables satisfy all the conditions of Theorem 1. In fact, my variables are independent and identically distributed (iid). On the other hand, there is Chebyshev's inequality for finite samples which does not require knowledge of the variance (or mean) of a given random variable and replaces it with the corresponding values of my given sample.  However, the estimator is not good enough for my application and I was wondering if there is an estimator similar to Theorem 1 but not featuring the variance of the distribution itself. Intuitively speaking, it would be nice to have the best of both worlds: If that is not possible, then what is the best bound I can achieve for a sum of iid variables, without any knowledge about their variance?",,"['probability', 'reference-request', 'statistics']"
58,Is it a coincidence or is there an explanation for this?,Is it a coincidence or is there an explanation for this?,,"Tossing a fair coin $2n$ times. After the $i$-th toss, the number of heads is $H_{i}$ and the number of tails is $T_{i}$. Is this a mere coincidence that the probability of $H_{2k}=T_{2k}$ equals to the probability that $H_{2i}\ne T_{2i}$ for all $i\le k$? How do I understand this more easily? Is there a way to devise a one-to-one correspondence of any case that $H_{2k}=T_{2k}$ to a case that $H_{2i}\ne T_{2i}(i\le k)$?","Tossing a fair coin $2n$ times. After the $i$-th toss, the number of heads is $H_{i}$ and the number of tails is $T_{i}$. Is this a mere coincidence that the probability of $H_{2k}=T_{2k}$ equals to the probability that $H_{2i}\ne T_{2i}$ for all $i\le k$? How do I understand this more easily? Is there a way to devise a one-to-one correspondence of any case that $H_{2k}=T_{2k}$ to a case that $H_{2i}\ne T_{2i}(i\le k)$?",,['probability']
59,Poisson-binomial concentration inequality in terms of binomial concentration inequality?,Poisson-binomial concentration inequality in terms of binomial concentration inequality?,,"Let $X_i$ for $i = 1, \ldots, N$ be independent but not necessarily identically-distributed Bernoulli random variables taking values in $\{0,1\}$ where $\mathbb{P}\{X_i = 1\} = p_i$. Define $Y = \sum_{i=1}^N X_i$, so that $Y$ has a Poisson-binomial distribution. Also let $X$ be binomially distributed with parameters $N$ and $p'$ where $p'$ is such that $|p' - 1/2| \leq |p_i - 1/2|$ for all $i \in \{1, \ldots, N\}$. Now the variance of $X$ is $N(1-p')p'$ and of $Y$ is $\sum_{i=1}^N (1-p_i) p_i$ so it is clear that the variance of $X$ is larger by the assumption on $p'$. I also predict the following to hold for any $\epsilon > 0$ but I am unable to prove it: $\mathbb{P}\{|Y - \mathbb{E}[Y]| > \epsilon\} \leq  \mathbb{P}\{|X - N p'| > \epsilon\}$ Does anyone have any ideas? Many thanks!","Let $X_i$ for $i = 1, \ldots, N$ be independent but not necessarily identically-distributed Bernoulli random variables taking values in $\{0,1\}$ where $\mathbb{P}\{X_i = 1\} = p_i$. Define $Y = \sum_{i=1}^N X_i$, so that $Y$ has a Poisson-binomial distribution. Also let $X$ be binomially distributed with parameters $N$ and $p'$ where $p'$ is such that $|p' - 1/2| \leq |p_i - 1/2|$ for all $i \in \{1, \ldots, N\}$. Now the variance of $X$ is $N(1-p')p'$ and of $Y$ is $\sum_{i=1}^N (1-p_i) p_i$ so it is clear that the variance of $X$ is larger by the assumption on $p'$. I also predict the following to hold for any $\epsilon > 0$ but I am unable to prove it: $\mathbb{P}\{|Y - \mathbb{E}[Y]| > \epsilon\} \leq  \mathbb{P}\{|X - N p'| > \epsilon\}$ Does anyone have any ideas? Many thanks!",,"['probability', 'probability-theory', 'statistics', 'binomial-distribution']"
60,Bivariate Lognormal Distribution,Bivariate Lognormal Distribution,,"Is there a pdf for bivariate lognormal distribution?  Suppose there are 2 random variable $X_1$ and $X_2$  with standard normal distribution, how would the pdf of a bivariate lognormal distribution look like? Thanks!","Is there a pdf for bivariate lognormal distribution?  Suppose there are 2 random variable $X_1$ and $X_2$  with standard normal distribution, how would the pdf of a bivariate lognormal distribution look like? Thanks!",,['probability']
61,Understanding dependency graph for a set of events,Understanding dependency graph for a set of events,,"Deﬁnition 4. Let $\mathcal{E}_1 , \mathcal{E}_2 , \dots, \mathcal{E}_n$ be n events on a probability   space $Ω$. The dependency graph is a directed graph $D = (V, E)$ on   the set of vertices $V = {1, \dots , n} $ (corresponding to $\mathcal{E}_1 , \mathcal{E}_2  , \dots, \mathcal{E}_n$ ) if for each $1 ≤ i ≤ n, \mathcal{E}_i$ is mutually independent   of all the events $\{\mathcal{E}_j : (i, j) \notin E\}$. Note that the dependency graph is not unique.    For instance, consider two independent coin ﬂips with outcome H or T.   Consider the events $$\mathcal{E}_1 := \{(H, H), (H, T )\} \text{ (ﬁrst coin ﬂip is H)},$$ $$\mathcal{E}_2 := \{(H, H), (T, H)\} \text{  (second coin ﬂip is H)},$$ $$\mathcal{E}_3 := \{(H, H), (T, T )\} \text{ (both coin ﬂips are the same)}.$$ Then, two possible dependency graphs are as follows(for the left graph, the low-right vertex should be $\mathcal E_3$.): In the example, if I am correct, the three events $\mathcal{E}_1, \mathcal{E}_2, \mathcal{E}_3$ are pairwise independent but not mutually independent. But the first dependency graph shows that $\mathcal{E}_1$ is mutually independent of $\mathcal{E}_3$, $\mathcal{E}_2$ is mutually independent of $\mathcal{E}_1$, and $\mathcal{E}_3$ is mutually independent of $\mathcal{E}_2$. The second dependency graph shows that $\mathcal{E}_1$ is mutually independent of $\mathcal{E}_3$, $\mathcal{E}_3$ is mutually independent of $\mathcal{E}_1$, and $\mathcal{E}_2$ is mutually independent of $\mathcal{E}_1$. So it seems like a dependency graph of a set of events doesn't necessarily need to capture all the dependence or independence relation between events? In a dependency graph of a set of events, does existence of an edge from $A_i$ to $A_j$ imply that $A_i$ is not mutually independent of $A_j$? I think no, because in the example, the three events are pairwise independent,  but there are edges between some two of them. Is the concept an event being mutually independent of another event not a symmetric relation between events? Our usual definition for mutual independence between two events are $P(\mathcal{E}_1 \cap \mathcal{E}_2) = P(\mathcal{E}_1) P(\mathcal{E}_2)$, which seems to be a symmetric relation between events. More generally, any directed graph with minimum out degree 1 is a   dependency graph. If all events $\mathcal{E}_1 , \mathcal{E}_2 , \dots, \mathcal{E}_n$  are mutually independent, then   the empty graph is a dependency graph. Why is a directed graph with ""minimum out degree 1"" singled out in particular? Thanks and regards!","Deﬁnition 4. Let $\mathcal{E}_1 , \mathcal{E}_2 , \dots, \mathcal{E}_n$ be n events on a probability   space $Ω$. The dependency graph is a directed graph $D = (V, E)$ on   the set of vertices $V = {1, \dots , n} $ (corresponding to $\mathcal{E}_1 , \mathcal{E}_2  , \dots, \mathcal{E}_n$ ) if for each $1 ≤ i ≤ n, \mathcal{E}_i$ is mutually independent   of all the events $\{\mathcal{E}_j : (i, j) \notin E\}$. Note that the dependency graph is not unique.    For instance, consider two independent coin ﬂips with outcome H or T.   Consider the events $$\mathcal{E}_1 := \{(H, H), (H, T )\} \text{ (ﬁrst coin ﬂip is H)},$$ $$\mathcal{E}_2 := \{(H, H), (T, H)\} \text{  (second coin ﬂip is H)},$$ $$\mathcal{E}_3 := \{(H, H), (T, T )\} \text{ (both coin ﬂips are the same)}.$$ Then, two possible dependency graphs are as follows(for the left graph, the low-right vertex should be $\mathcal E_3$.): In the example, if I am correct, the three events $\mathcal{E}_1, \mathcal{E}_2, \mathcal{E}_3$ are pairwise independent but not mutually independent. But the first dependency graph shows that $\mathcal{E}_1$ is mutually independent of $\mathcal{E}_3$, $\mathcal{E}_2$ is mutually independent of $\mathcal{E}_1$, and $\mathcal{E}_3$ is mutually independent of $\mathcal{E}_2$. The second dependency graph shows that $\mathcal{E}_1$ is mutually independent of $\mathcal{E}_3$, $\mathcal{E}_3$ is mutually independent of $\mathcal{E}_1$, and $\mathcal{E}_2$ is mutually independent of $\mathcal{E}_1$. So it seems like a dependency graph of a set of events doesn't necessarily need to capture all the dependence or independence relation between events? In a dependency graph of a set of events, does existence of an edge from $A_i$ to $A_j$ imply that $A_i$ is not mutually independent of $A_j$? I think no, because in the example, the three events are pairwise independent,  but there are edges between some two of them. Is the concept an event being mutually independent of another event not a symmetric relation between events? Our usual definition for mutual independence between two events are $P(\mathcal{E}_1 \cap \mathcal{E}_2) = P(\mathcal{E}_1) P(\mathcal{E}_2)$, which seems to be a symmetric relation between events. More generally, any directed graph with minimum out degree 1 is a   dependency graph. If all events $\mathcal{E}_1 , \mathcal{E}_2 , \dots, \mathcal{E}_n$  are mutually independent, then   the empty graph is a dependency graph. Why is a directed graph with ""minimum out degree 1"" singled out in particular? Thanks and regards!",,"['probability', 'graph-theory']"
62,Fixed marginals of joint distribution: status,Fixed marginals of joint distribution: status,,"One of the well-known problems of classical probability theory is the determination of the set of all extreme points in the convex set of all probability distributions in a product Borel space $\left (X \times Y, \:\:{\cal F} \times {\cal G} \right )$ with fixed marginal distributions $\mu$ and $\nu$ on $\left (X, {\cal F} \right )$ and $\left (Y, {\cal G} \right )$ respectively. Denote this convex set by $C(\mu, \nu).$ When $X = Y = \left \{ 1,2,\ldots,n \right \},$ ${\cal F} = {\cal G}$ is the field of all subsets of $X$ and $\mu = \nu$ is the uniform distribution then the problem is answered by the Birkhoff. I do not work in probability theory. I have heard that the above result is the 'only' result in this direction. Is it true? Can someone please tell me the present status of the above problem. It is nice, if anybody can point out survey article(s) on this matter. My motivation is to look at the analogues  problem in a quantum set up. Birkhoff's theorem and methods are used in some works regarding quantum channels. Hence I want to know the present status of the problem. Advanced thanks for all the helps.","One of the well-known problems of classical probability theory is the determination of the set of all extreme points in the convex set of all probability distributions in a product Borel space $\left (X \times Y, \:\:{\cal F} \times {\cal G} \right )$ with fixed marginal distributions $\mu$ and $\nu$ on $\left (X, {\cal F} \right )$ and $\left (Y, {\cal G} \right )$ respectively. Denote this convex set by $C(\mu, \nu).$ When $X = Y = \left \{ 1,2,\ldots,n \right \},$ ${\cal F} = {\cal G}$ is the field of all subsets of $X$ and $\mu = \nu$ is the uniform distribution then the problem is answered by the Birkhoff. I do not work in probability theory. I have heard that the above result is the 'only' result in this direction. Is it true? Can someone please tell me the present status of the above problem. It is nice, if anybody can point out survey article(s) on this matter. My motivation is to look at the analogues  problem in a quantum set up. Birkhoff's theorem and methods are used in some works regarding quantum channels. Hence I want to know the present status of the problem. Advanced thanks for all the helps.",,"['probability', 'reference-request', 'soft-question']"
63,Family of distributions preserved under summing or product of their random variables,Family of distributions preserved under summing or product of their random variables,,"I wonder what families of distributions can satisfy that the sum of their any two random variables still have a distribution in the same family? what families of distributions can satisfy that the product of their any two random variables still have a distribution in the same family? My questions arose when I read this reply The sum of normal (Cauchy, Levy) random variables is normal (Cauchy,   Levy). The sum of gamma random variables is gamma if the distributions have a common scale parameter. The product of log-normal random variables is log-normal. I know it is not true that the sum of two normal distributed random variables is still normally distributed. For example, if $X$ is normally distributed, define $Y$ to be $X$ if $|X| > c$ and $Y = −X$ if $|X| < c$, where $c > 0$. Then $X+Y$ is not normally distributed. I am not sure how to verify if the other claims are right or not. What can be say about a family of distribution that satisfies the above requirements? Thanks and regards!","I wonder what families of distributions can satisfy that the sum of their any two random variables still have a distribution in the same family? what families of distributions can satisfy that the product of their any two random variables still have a distribution in the same family? My questions arose when I read this reply The sum of normal (Cauchy, Levy) random variables is normal (Cauchy,   Levy). The sum of gamma random variables is gamma if the distributions have a common scale parameter. The product of log-normal random variables is log-normal. I know it is not true that the sum of two normal distributed random variables is still normally distributed. For example, if $X$ is normally distributed, define $Y$ to be $X$ if $|X| > c$ and $Y = −X$ if $|X| < c$, where $c > 0$. Then $X+Y$ is not normally distributed. I am not sure how to verify if the other claims are right or not. What can be say about a family of distribution that satisfies the above requirements? Thanks and regards!",,['probability']
64,Varieties and Statistics,Varieties and Statistics,,"Consider a random variable $X$ that can take on the values $0,1$ and $2$. So we have $$p_i = P(X=i), \ i = 0,1,2$$ $$\sum_{i=0}^{2} p_i = 1$$ and $$0 \leq p_i \leq 1$$ So identifying a random variable $X$ is the same thing as identifying a point $(p_0,p_1,p_2) \in \mathbb{R}^3$. Now suppose $X$ is a binomial random variable. Then $$p_i = P(X = i) = \binom{2}{i} q^{i}(1-q)^{2-i}$$ and $$4p_{0}p_{2}-p_{1}^{2} = 0$$ How is this related to algebraic geometry? The above equation is an algebraic variety in $\mathbb{R}^3$?","Consider a random variable $X$ that can take on the values $0,1$ and $2$. So we have $$p_i = P(X=i), \ i = 0,1,2$$ $$\sum_{i=0}^{2} p_i = 1$$ and $$0 \leq p_i \leq 1$$ So identifying a random variable $X$ is the same thing as identifying a point $(p_0,p_1,p_2) \in \mathbb{R}^3$. Now suppose $X$ is a binomial random variable. Then $$p_i = P(X = i) = \binom{2}{i} q^{i}(1-q)^{2-i}$$ and $$4p_{0}p_{2}-p_{1}^{2} = 0$$ How is this related to algebraic geometry? The above equation is an algebraic variety in $\mathbb{R}^3$?",,"['probability', 'algebraic-geometry', 'statistics']"
65,P.D.F. of independent/dependent Uniform R.V.'s,P.D.F. of independent/dependent Uniform R.V.'s,,"I am trying to solve this: Consider a stick of length 1.  You break the stick in two   random places, X and Y. a. Define the individual   probability distribution functions of the breaking points X and Y. b. Write the joint PDF of the breaking points, if X and Y are   independent.  Sketch its  support (domain) and indicate the density   values of this domain. c. Assume that Y is such that $Y > X$. What is the joint PDF of $(X,Y)$ if it needs to be  uniform on this domain. Again, sketch its support and indicate the density value. d. The two breaking points divide the stick in three segments.    What is the probability of the left-most segment is the shortest   segment, when $Y > X$?  Sketch the area in the $X-Y$  plane that   corresponds to this event.  (Hint: to be the shortest segment the   leftmost segment  needs to satisfy two constraints simultaneously.) Solutions: a/b) $$PDF(X,Y) = 1 | (x,y) \in [0,1]\times [0,1]$$$$0|otherwise$$ c) we know that $X$~U$(0,1)$. The clause that $Y\gt X$ means that $Y$~U$(X, 1)$. Now, Y has become dependent on X, correct? Therefore, the joint PDF isn't as simple as multiplying the PDF's together. How do I get the joint PDF in this case? The answer I was given is that $$PDF(X,Y) = 2|(X,Y)\in [0,1]\times [0,1] \cap (Y > X)$$ but I'm having trouble understanding why this is... I think I understand the concept that, because $Y>X$, the area in which Y can live is halved, because, when X is chosen (since it is chosen uniformly), Y's value depends on the value of X, and the uniform distribution means that the area Y can occupy is halved. but, why does the P.D.F. = 2 in this case? Wouldn't it still be equal to 1, as in: $$PDF(X,Y) = 1|(X,Y)\in [0,1]\times [0,1] \cap (Y > X)$$ I thought the only change would be in the are for which the PDF was valid (hence the distribution needing to intersect the area where $Y>X$ d) For this one, I came up with 3 constraints: $\frac{1}{2} <Y<\frac{3}{4}$ and $X<\frac{1}{4}$ thus, $X$~U$(0,\frac{1}{4} )$ and $Y$~U$(\frac{1}{2} , \frac{3}{4})$ making $$PDF(X) = \frac{1}{\frac{1}{4}} = 4$$and $$PDF(Y)= \frac{1}{\frac{3}{4} -\frac{1}{2}} = 4$$ so joint $PDF(X,Y) = 16|\frac{1}{2} <Y<\frac{3}{4}$ and $X<\frac{1}{4}$ However, this is incorrect, and I can't rightly figure out why. Any advice as to where I'm going wrong? Thank you very much!","I am trying to solve this: Consider a stick of length 1.  You break the stick in two   random places, X and Y. a. Define the individual   probability distribution functions of the breaking points X and Y. b. Write the joint PDF of the breaking points, if X and Y are   independent.  Sketch its  support (domain) and indicate the density   values of this domain. c. Assume that Y is such that $Y > X$. What is the joint PDF of $(X,Y)$ if it needs to be  uniform on this domain. Again, sketch its support and indicate the density value. d. The two breaking points divide the stick in three segments.    What is the probability of the left-most segment is the shortest   segment, when $Y > X$?  Sketch the area in the $X-Y$  plane that   corresponds to this event.  (Hint: to be the shortest segment the   leftmost segment  needs to satisfy two constraints simultaneously.) Solutions: a/b) $$PDF(X,Y) = 1 | (x,y) \in [0,1]\times [0,1]$$$$0|otherwise$$ c) we know that $X$~U$(0,1)$. The clause that $Y\gt X$ means that $Y$~U$(X, 1)$. Now, Y has become dependent on X, correct? Therefore, the joint PDF isn't as simple as multiplying the PDF's together. How do I get the joint PDF in this case? The answer I was given is that $$PDF(X,Y) = 2|(X,Y)\in [0,1]\times [0,1] \cap (Y > X)$$ but I'm having trouble understanding why this is... I think I understand the concept that, because $Y>X$, the area in which Y can live is halved, because, when X is chosen (since it is chosen uniformly), Y's value depends on the value of X, and the uniform distribution means that the area Y can occupy is halved. but, why does the P.D.F. = 2 in this case? Wouldn't it still be equal to 1, as in: $$PDF(X,Y) = 1|(X,Y)\in [0,1]\times [0,1] \cap (Y > X)$$ I thought the only change would be in the are for which the PDF was valid (hence the distribution needing to intersect the area where $Y>X$ d) For this one, I came up with 3 constraints: $\frac{1}{2} <Y<\frac{3}{4}$ and $X<\frac{1}{4}$ thus, $X$~U$(0,\frac{1}{4} )$ and $Y$~U$(\frac{1}{2} , \frac{3}{4})$ making $$PDF(X) = \frac{1}{\frac{1}{4}} = 4$$and $$PDF(Y)= \frac{1}{\frac{3}{4} -\frac{1}{2}} = 4$$ so joint $PDF(X,Y) = 16|\frac{1}{2} <Y<\frac{3}{4}$ and $X<\frac{1}{4}$ However, this is incorrect, and I can't rightly figure out why. Any advice as to where I'm going wrong? Thank you very much!",,"['probability', 'normal-distribution']"
66,a integral of bivariate Gaussian random variables.,a integral of bivariate Gaussian random variables.,,"I met the following problem when doing estimation and detection homework.  The problem asks for a maximum likelihood estimator for (v,$\rho$) of bivariate joint Gaussian, where v is the common variance for Y1 and Y2, rho is correlation coefficient, Y1, Y2 mean zero. Given one pair of observation (y1, y2). I find that the MLE for $\rho$ is $\hat{\rho}=\frac{2y_1y_2}{y_1^2+y_2^2}$, and $\hat{v}=\frac{y_1^2+y_2^2}{2}$. now I need to show that these estimators are unbiased. The unbiasedness of $\hat{v}$ is easy. Then I need to verify $$E[\hat{\rho}]=\rho$$ I managed to show this by working through the double integral and change to polar coordinate, but the computation is heavy. Here is my question, is there a easier (neat) solution to show it is unbiased? Thanks in advance.","I met the following problem when doing estimation and detection homework.  The problem asks for a maximum likelihood estimator for (v,$\rho$) of bivariate joint Gaussian, where v is the common variance for Y1 and Y2, rho is correlation coefficient, Y1, Y2 mean zero. Given one pair of observation (y1, y2). I find that the MLE for $\rho$ is $\hat{\rho}=\frac{2y_1y_2}{y_1^2+y_2^2}$, and $\hat{v}=\frac{y_1^2+y_2^2}{2}$. now I need to show that these estimators are unbiased. The unbiasedness of $\hat{v}$ is easy. Then I need to verify $$E[\hat{\rho}]=\rho$$ I managed to show this by working through the double integral and change to polar coordinate, but the computation is heavy. Here is my question, is there a easier (neat) solution to show it is unbiased? Thanks in advance.",,"['probability', 'integration', 'probability-distributions']"
67,Distribution of Maximum of Sum of Sum of Gaussians,Distribution of Maximum of Sum of Sum of Gaussians,,"Let $X_i$ be a sequence of i.i.d. standard normal random variables. Let $Y_i=\sum_{k=1}^iX_k$ and $Z_i=\sum_{k=1}^iY_k$. I am interested in upper and lower bounds for $P(\sup_{1\leq i\leq m}|X_i|\leq c)$, $P(\sup_{1\leq i\leq m}|Y_i|\leq c)$ and $P(\sup_{1\leq i\leq m}|Z_i|\leq c)$. I managed to figure out the first two, and for the second one I got bounds of something like $1-\mbox{const}\times e^{-c^2/n}$ by considering $P(|B_t|\geq c)$ and using the reflection principle for $\tau=\inf_{t\leq m}\{t: \ |B_t|\geq c)\}$. The problem is, the same trick doesn't quite work when figuring out the $P(\sup_{1\leq i\leq m}|Z_i|\leq c)$. In fact, the best I could do was write $Z_{n+1}=Z_n+B_{n+1}$ where $B$ is a standard Brownian motion. Maybe this can become a stochastic differential equation? But, it feels intractable unless I'm missing something. I was wondering how one might get good upper and lower bounds for the supremum over $Z_i$? Maybe I'm thinking too hard and there's an easier way which doesn't resort to Brownian motion. Any help would be greatly appreciated!","Let $X_i$ be a sequence of i.i.d. standard normal random variables. Let $Y_i=\sum_{k=1}^iX_k$ and $Z_i=\sum_{k=1}^iY_k$. I am interested in upper and lower bounds for $P(\sup_{1\leq i\leq m}|X_i|\leq c)$, $P(\sup_{1\leq i\leq m}|Y_i|\leq c)$ and $P(\sup_{1\leq i\leq m}|Z_i|\leq c)$. I managed to figure out the first two, and for the second one I got bounds of something like $1-\mbox{const}\times e^{-c^2/n}$ by considering $P(|B_t|\geq c)$ and using the reflection principle for $\tau=\inf_{t\leq m}\{t: \ |B_t|\geq c)\}$. The problem is, the same trick doesn't quite work when figuring out the $P(\sup_{1\leq i\leq m}|Z_i|\leq c)$. In fact, the best I could do was write $Z_{n+1}=Z_n+B_{n+1}$ where $B$ is a standard Brownian motion. Maybe this can become a stochastic differential equation? But, it feels intractable unless I'm missing something. I was wondering how one might get good upper and lower bounds for the supremum over $Z_i$? Maybe I'm thinking too hard and there's an easier way which doesn't resort to Brownian motion. Any help would be greatly appreciated!",,"['probability', 'statistics', 'probability-theory', 'stochastic-processes', 'stochastic-integrals']"
68,probability bound,probability bound,,"Let $x_1,\ldots,x_n$ be i.i.d. random variables with continuous and concave distribution function F. It is known that for $t\geq 0$ $$ P\left(\sum_{i=1}^nx_i\leq t\right)\leq\\  \left\{ \begin{array}{rcl} \frac{1}{n!}\sum_{j=0}^k(-1)^j {n \choose j}\left(nF\left(\frac tn\right)-j\right)^n, &nF^{-1}\left(\frac kn\right)\leq t<F^{-1}\left(\frac{k+1}{n}\right), k=0,\ldots,n-1\\ 1,&t\geq nF^{-1}(1), \end{array}\right. $$ here $F^{-1}(t)=\inf\{x:F(x)\geq t\}, 0<t\leq 1$. I am wondering if it is possible to bound the RHS of the inequality above (the sum). Is it possible by adding some assumptions on random variables $x_1,...,x_n$ to bound density function F? Continuous distribution function $F$ with support $[0, \infty)$ is called concave, if $F(\lambda s+(1-\lambda t))\geq \lambda F(s)+(1-\lambda)F(t)$, for every $s,t\geq 0, 0\leq\lambda\leq 1$. Any references and ideas would be very helpful. Thank you.","Let $x_1,\ldots,x_n$ be i.i.d. random variables with continuous and concave distribution function F. It is known that for $t\geq 0$ $$ P\left(\sum_{i=1}^nx_i\leq t\right)\leq\\  \left\{ \begin{array}{rcl} \frac{1}{n!}\sum_{j=0}^k(-1)^j {n \choose j}\left(nF\left(\frac tn\right)-j\right)^n, &nF^{-1}\left(\frac kn\right)\leq t<F^{-1}\left(\frac{k+1}{n}\right), k=0,\ldots,n-1\\ 1,&t\geq nF^{-1}(1), \end{array}\right. $$ here $F^{-1}(t)=\inf\{x:F(x)\geq t\}, 0<t\leq 1$. I am wondering if it is possible to bound the RHS of the inequality above (the sum). Is it possible by adding some assumptions on random variables $x_1,...,x_n$ to bound density function F? Continuous distribution function $F$ with support $[0, \infty)$ is called concave, if $F(\lambda s+(1-\lambda t))\geq \lambda F(s)+(1-\lambda)F(t)$, for every $s,t\geq 0, 0\leq\lambda\leq 1$. Any references and ideas would be very helpful. Thank you.",,['probability']
69,Inter-arrival time distribution,Inter-arrival time distribution,,"It is known that for a Poisson process the inter-arrival time is exponentially distributed. My question, which may be nonsense, is this. Suppose you want to experimentally evaluate the distribution of inter-arrival time (not necessarily of a Poisson process). You measure the differences in the arrival time of consecutive customers, for example. But the problem is that the inter-arrival time depends on the (absolute) time the proceeding customer arrived. If it arrived earlier, the current inter-arrival would be different. So, does it make sense to measure inter-arrival times and build the distribution with those samples?","It is known that for a Poisson process the inter-arrival time is exponentially distributed. My question, which may be nonsense, is this. Suppose you want to experimentally evaluate the distribution of inter-arrival time (not necessarily of a Poisson process). You measure the differences in the arrival time of consecutive customers, for example. But the problem is that the inter-arrival time depends on the (absolute) time the proceeding customer arrived. If it arrived earlier, the current inter-arrival would be different. So, does it make sense to measure inter-arrival times and build the distribution with those samples?",,"['probability', 'statistics', 'stochastic-processes']"
70,Conditional Expectation and the floor function,Conditional Expectation and the floor function,,"I have a piece of code the produces random integers. int c = 250 - (int) floor(rand() * 50);     while (c < 0) {         c = 250 - (int) floor(rand() * 50);     } The floor() function returns the largest floating-point value less than or equal to the argument and that is equal to an integer. The rand() function returns floating-point values drawn from the standard normal distribution. Let's assume that both functions work as intended and that the pseudo random number generator works correctly, otherwise further discussion would be pointless. The question is, what is the expectation of the integers generated by this piece of code? Casting the code in mathematical terms, I want to calculate the conditional expectation $\mathbb{E}\bigl[250-\lfloor50\cdot Z\rfloor\quad\vert\quad 250-\lfloor50\cdot Z\rfloor\ge0\bigr]$ where the random variable Z is standard normal distributed, that is $Z\sim N(0,1)$. The condition stems from the fact, that the code above throws away negative integers and draws again. Note that $\lfloor250 - 50\cdot x\rfloor=250-\lfloor 50\cdot x\rfloor$ holds, so the placement of the floor function shouldn't make a difference. The question at this point is, is this mathematical model correctly describing what is going on in the code? I think so, if you think otherwise please leave a comment. The reason for the linear transformation $250-50\cdot x$ above is simply that via rand() only a standard normal distribution is available. And $X=\mu-\sigma\cdot Z$ just turns an $N(0,1)$ distribution into an $N(\mu,\sigma^2)$ distribution, here $N(250,50^2)$, so the standard normal distribution is shifted to the right and widened. Rejecting negative integers corresponds to truncating $N(250, 50^2)$ at $0$ removing the lower tail. Neglecting the floor function for a moment, my intuition is, that the truncation of the distribution and the necessary rescaling should move the mean further to the right, that is $\mathbb{E}\bigl[X\bigr]>250$ when $X\sim N_{\ge0}(250,50^2)$. Indeed Mathematica confirms N[Expectation[x,  x \[Distributed] TruncatedDistribution[{0, \[Infinity]},  TransformedDistribution[250 - 50*x, x \[Distributed] NormalDistribution[]]]], 30]  250.000074335997045245285622087 By the definition of the expectation for a continuous distribution we have $$ \mathbb{E}\bigl[250-50\cdot Z \quad \vert \quad 250-50\cdot Z\ge0\bigr]=\mathbb{E}[X]=\int_{-\infty}^\infty x f(x)\;dx $$ with $Z\sim N(0,1)$ and $X\sim N_{\ge0}(250,50^2)$. The pdf $f(x)$ of the truncated and transformed standard normal distribution is $$ f(x)=\frac{g(x)}{1-\Phi\left(\frac{0-250}{50}\right)}\qquad g(x)=\begin{cases}0&x<0\\\phi\left(\frac{x-250}{50}\right)&x\ge0\end{cases} $$ where $\phi(x)$ and $\Phi(x)$ are the pdf and cdf of the standard normal distribution. The scaling factor $1-\Phi\left(\frac{0-250}{50}\right)$ is just the probability mass that is left after truncation. Dividing by it ensures that we have a distribution. And indeed $$ \int_0^\infty f(x)\;dx=1 $$ is checked easily. Now the only way I know of incorporating the floor function, is by treating it as what it is, a piecewise constant function. The next goal is to turn this continuous distribution into a step function. Each step collects all the floating-point values that are mapped by the floor function onto the same integer. Therefore $$ h(a)=\int_a^{a+1}f(x)\;dx $$ is the height of the step $[a,a+1]$ where $a\in\mathbb{N_0}$. Checking that the step function is a probability distribution yields $$ \sum_{a=0}^\infty h(a)=1 $$ Now the sought-after expectation should simply be $$ \mathbb{E}\bigl[250-\lfloor50\cdot Z\rfloor \quad \vert \quad 250-\lfloor50\cdot Z\rfloor\ge0\bigr]=\sum_{a=0}^\infty a\cdot h(a) $$ A quick computation with Mathematica evaluates this sum to be 249.5000743384745... Which is puzzling me for two reasons. My intuition is that the mean should shift to the right, not left, despite the flooring. Actually executing the code, letting it produce a sample of random integers of size 317440000 yields a mean of 250.507 Calculating $h(0)$ and $h(250)$ and comparing them to their respective relative frequencies from the sample yields $$ \begin{align*} h(0)&=0.0000000312698&h(250)&=0.00797832\\ h(1)&=0.0000000345445&h(251)&=0.00797513\\ \hat{h}(0)&=0.0000000346522&\hat{h}(250)&=0.00796824 \end{align*} $$ A statistician may find it amusing to test whether the hypothesis that my derivation of the expectation is correct should be rejected. For me this hints an off-by-one error and it turns out that taking the right endpoint of the step and summing $$ \sum_{a=0}^\infty (a+1)\cdot h(a) $$ yields 250.50007433847... Assuming that Mathematica works correctly and the generation of the sample and its processing are correct and that this derivation actually describes what the code is doing, this suggests that I have made an off-by-one error. Unfortunately I cannot pinpoint the error. So the questions are: Can someone pinpoint an error in the modeling? Can someone pinpoint an off-by-one error? Can someone pinpoint another error? Perhaps my intuition is flawed once again and someone can confirm the expectation of $249.5+\epsilon$ by another method? Can someone confirm the expectation of $250.5+\epsilon$ by another method? Please accept my apology for this comparatively long posting, but I didn't have time to write a shorter one.","I have a piece of code the produces random integers. int c = 250 - (int) floor(rand() * 50);     while (c < 0) {         c = 250 - (int) floor(rand() * 50);     } The floor() function returns the largest floating-point value less than or equal to the argument and that is equal to an integer. The rand() function returns floating-point values drawn from the standard normal distribution. Let's assume that both functions work as intended and that the pseudo random number generator works correctly, otherwise further discussion would be pointless. The question is, what is the expectation of the integers generated by this piece of code? Casting the code in mathematical terms, I want to calculate the conditional expectation $\mathbb{E}\bigl[250-\lfloor50\cdot Z\rfloor\quad\vert\quad 250-\lfloor50\cdot Z\rfloor\ge0\bigr]$ where the random variable Z is standard normal distributed, that is $Z\sim N(0,1)$. The condition stems from the fact, that the code above throws away negative integers and draws again. Note that $\lfloor250 - 50\cdot x\rfloor=250-\lfloor 50\cdot x\rfloor$ holds, so the placement of the floor function shouldn't make a difference. The question at this point is, is this mathematical model correctly describing what is going on in the code? I think so, if you think otherwise please leave a comment. The reason for the linear transformation $250-50\cdot x$ above is simply that via rand() only a standard normal distribution is available. And $X=\mu-\sigma\cdot Z$ just turns an $N(0,1)$ distribution into an $N(\mu,\sigma^2)$ distribution, here $N(250,50^2)$, so the standard normal distribution is shifted to the right and widened. Rejecting negative integers corresponds to truncating $N(250, 50^2)$ at $0$ removing the lower tail. Neglecting the floor function for a moment, my intuition is, that the truncation of the distribution and the necessary rescaling should move the mean further to the right, that is $\mathbb{E}\bigl[X\bigr]>250$ when $X\sim N_{\ge0}(250,50^2)$. Indeed Mathematica confirms N[Expectation[x,  x \[Distributed] TruncatedDistribution[{0, \[Infinity]},  TransformedDistribution[250 - 50*x, x \[Distributed] NormalDistribution[]]]], 30]  250.000074335997045245285622087 By the definition of the expectation for a continuous distribution we have $$ \mathbb{E}\bigl[250-50\cdot Z \quad \vert \quad 250-50\cdot Z\ge0\bigr]=\mathbb{E}[X]=\int_{-\infty}^\infty x f(x)\;dx $$ with $Z\sim N(0,1)$ and $X\sim N_{\ge0}(250,50^2)$. The pdf $f(x)$ of the truncated and transformed standard normal distribution is $$ f(x)=\frac{g(x)}{1-\Phi\left(\frac{0-250}{50}\right)}\qquad g(x)=\begin{cases}0&x<0\\\phi\left(\frac{x-250}{50}\right)&x\ge0\end{cases} $$ where $\phi(x)$ and $\Phi(x)$ are the pdf and cdf of the standard normal distribution. The scaling factor $1-\Phi\left(\frac{0-250}{50}\right)$ is just the probability mass that is left after truncation. Dividing by it ensures that we have a distribution. And indeed $$ \int_0^\infty f(x)\;dx=1 $$ is checked easily. Now the only way I know of incorporating the floor function, is by treating it as what it is, a piecewise constant function. The next goal is to turn this continuous distribution into a step function. Each step collects all the floating-point values that are mapped by the floor function onto the same integer. Therefore $$ h(a)=\int_a^{a+1}f(x)\;dx $$ is the height of the step $[a,a+1]$ where $a\in\mathbb{N_0}$. Checking that the step function is a probability distribution yields $$ \sum_{a=0}^\infty h(a)=1 $$ Now the sought-after expectation should simply be $$ \mathbb{E}\bigl[250-\lfloor50\cdot Z\rfloor \quad \vert \quad 250-\lfloor50\cdot Z\rfloor\ge0\bigr]=\sum_{a=0}^\infty a\cdot h(a) $$ A quick computation with Mathematica evaluates this sum to be 249.5000743384745... Which is puzzling me for two reasons. My intuition is that the mean should shift to the right, not left, despite the flooring. Actually executing the code, letting it produce a sample of random integers of size 317440000 yields a mean of 250.507 Calculating $h(0)$ and $h(250)$ and comparing them to their respective relative frequencies from the sample yields $$ \begin{align*} h(0)&=0.0000000312698&h(250)&=0.00797832\\ h(1)&=0.0000000345445&h(251)&=0.00797513\\ \hat{h}(0)&=0.0000000346522&\hat{h}(250)&=0.00796824 \end{align*} $$ A statistician may find it amusing to test whether the hypothesis that my derivation of the expectation is correct should be rejected. For me this hints an off-by-one error and it turns out that taking the right endpoint of the step and summing $$ \sum_{a=0}^\infty (a+1)\cdot h(a) $$ yields 250.50007433847... Assuming that Mathematica works correctly and the generation of the sample and its processing are correct and that this derivation actually describes what the code is doing, this suggests that I have made an off-by-one error. Unfortunately I cannot pinpoint the error. So the questions are: Can someone pinpoint an error in the modeling? Can someone pinpoint an off-by-one error? Can someone pinpoint another error? Perhaps my intuition is flawed once again and someone can confirm the expectation of $249.5+\epsilon$ by another method? Can someone confirm the expectation of $250.5+\epsilon$ by another method? Please accept my apology for this comparatively long posting, but I didn't have time to write a shorter one.",,"['probability', 'integration', 'random', 'mathematical-modeling']"
71,Level of connectivity in a random graph,Level of connectivity in a random graph,,"If you take a random $k$-regular graph, with high probability (tending to 1 as the size of the graph grows) almost all of the nodes will be in one giant connected component. How well connected is this component? How many edges will I have to remove in order to disconnect this graph? This is motivated by an application where I generate a random connected $k$-regular graphs and then remove $r$ many random spanning trees. The concern: how large can $r$ be (on average) for a $k$-regular graph on $n$ vertices?","If you take a random $k$-regular graph, with high probability (tending to 1 as the size of the graph grows) almost all of the nodes will be in one giant connected component. How well connected is this component? How many edges will I have to remove in order to disconnect this graph? This is motivated by an application where I generate a random connected $k$-regular graphs and then remove $r$ many random spanning trees. The concern: how large can $r$ be (on average) for a $k$-regular graph on $n$ vertices?",,"['probability', 'graph-theory']"
72,Different definitions of e-property for Markov-Feller chains,Different definitions of e-property for Markov-Feller chains,,"Let $X$ be a Polish space. We consider a stochastic kernel $P:X \times \mathcal{B}_X \to [0,1]$ and the Markov semigroup $(P^{\;n})_{n\geq1}$ of iterations of $P$, which satisfy the Chapman–Kolmogorov equation. Routinely, we define a dual operator $U^n$ related to $P^n$ as follows: $$ U^n f(x) = \int\limits_{X} f(y)P^n(x,dy) ,$$ for any $f\in C(X)$. We also assume that $P$ has the Feller property; that means that $Uf \in C(X)$ for $f\in C(X)$. I know three different definitions of so-called e-property and I wonder about the relationships between them. (i) for all $f\in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$ is uniformly equicontinuous on each compact subset of $X$, (ii) for all $f\in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$  is equicontinuous in each point of $X$. (iii) for all Lipschitz functions $f \in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$  is equicontinuous in each point of $X$. I've proved that (ii) $\Rightarrow$ (i), the implication (ii) $\Rightarrow$ (iii) is obvious. I think that the implication (i) $\Rightarrow$ (ii) is true only when $X$ is additionally locally compact, am I right or may be it is more general? If one can say something more about (iii)?","Let $X$ be a Polish space. We consider a stochastic kernel $P:X \times \mathcal{B}_X \to [0,1]$ and the Markov semigroup $(P^{\;n})_{n\geq1}$ of iterations of $P$, which satisfy the Chapman–Kolmogorov equation. Routinely, we define a dual operator $U^n$ related to $P^n$ as follows: $$ U^n f(x) = \int\limits_{X} f(y)P^n(x,dy) ,$$ for any $f\in C(X)$. We also assume that $P$ has the Feller property; that means that $Uf \in C(X)$ for $f\in C(X)$. I know three different definitions of so-called e-property and I wonder about the relationships between them. (i) for all $f\in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$ is uniformly equicontinuous on each compact subset of $X$, (ii) for all $f\in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$  is equicontinuous in each point of $X$. (iii) for all Lipschitz functions $f \in C(X)$ with bounded support the family $\{U^n f: n\in\mathbb{N}\}$  is equicontinuous in each point of $X$. I've proved that (ii) $\Rightarrow$ (i), the implication (ii) $\Rightarrow$ (iii) is obvious. I think that the implication (i) $\Rightarrow$ (ii) is true only when $X$ is additionally locally compact, am I right or may be it is more general? If one can say something more about (iii)?",,"['probability', 'functional-analysis', 'stochastic-processes']"
73,Asymptotic behaviour of a two-dimensional recurrence relation,Asymptotic behaviour of a two-dimensional recurrence relation,,"This problem comes out of a research in models of firm growth. The model is simple: A firm has two parameters which are its size (number of employees) and job vacancies. A firm of size $n$ will produce job vacancies at rate $n\mu$ and $k$ job vacancies will be filled at rate $k\beta$. On the other hand, a firm is likely to quit at rate $\delta$, and new firms come into the market at rate $\alpha$ (new firm starts with 0 employee and 1 vacancy, but one can also model it as 1 employee and 0 vacancy if necessary). So in terms of math, the equation describing the relation is: $D_t s_{n,k,t}=-(n\mu+k\beta+\delta)s_{n,k,t}+(k+1)\beta s_{n-1,k+1,t}+n\mu s_{n,k-1,t}$, when (n,k) is not in the boundary, where $s_{n,k,t}$ is the probability of a firm having size $n$ and $k$ vacancies. I am particularly interested in the stationary distribution which is described by: $s_{0,1}=\frac{\alpha}{\delta+\beta}$, $s_{n,k}=0$ for $n<0$ or $k<0$, and $(n\mu+k\beta+\delta)s_{n,k}=(k+1)\beta s_{n-1,k+1}+n\mu s_{n,k-1}$. Moreover, the generating function $M(x,y)=\sum_{n=0}^{\infty}{\sum_{k=0}^{\infty}{s_{n,k}x^ny^k}}$ satisfies the PDE $\delta M=\beta(x-y)M_y+\mu x(y-1)M_x+\alpha y$. What I would like to know is the asymptotic behavior of $s_n=\sum_{k=0}^{\infty}{s_{n,k}}$, or more explicitly the tail $\sum_{n=m}^{\infty}{s_n}$ when m is very large. The empirical Data on firm size suggests that it might appear as a power law (~ $n^{-\zeta}$, where $\zeta$ is a bit larger than 1), also it may not have a finite variance ($M_{xx}(1,1)=\infty$). The one-dimensional problem, in which we only consider the size (that is, vacancies are filled immediately), is completely characterized by Yule process and also suggests the power law. Could anyone give me some insight on how to approach this problem? I've been considering this problem for a month, but since I am not familiar with highly technical tools in analysis or probability I get stuck completely. Thank you!","This problem comes out of a research in models of firm growth. The model is simple: A firm has two parameters which are its size (number of employees) and job vacancies. A firm of size $n$ will produce job vacancies at rate $n\mu$ and $k$ job vacancies will be filled at rate $k\beta$. On the other hand, a firm is likely to quit at rate $\delta$, and new firms come into the market at rate $\alpha$ (new firm starts with 0 employee and 1 vacancy, but one can also model it as 1 employee and 0 vacancy if necessary). So in terms of math, the equation describing the relation is: $D_t s_{n,k,t}=-(n\mu+k\beta+\delta)s_{n,k,t}+(k+1)\beta s_{n-1,k+1,t}+n\mu s_{n,k-1,t}$, when (n,k) is not in the boundary, where $s_{n,k,t}$ is the probability of a firm having size $n$ and $k$ vacancies. I am particularly interested in the stationary distribution which is described by: $s_{0,1}=\frac{\alpha}{\delta+\beta}$, $s_{n,k}=0$ for $n<0$ or $k<0$, and $(n\mu+k\beta+\delta)s_{n,k}=(k+1)\beta s_{n-1,k+1}+n\mu s_{n,k-1}$. Moreover, the generating function $M(x,y)=\sum_{n=0}^{\infty}{\sum_{k=0}^{\infty}{s_{n,k}x^ny^k}}$ satisfies the PDE $\delta M=\beta(x-y)M_y+\mu x(y-1)M_x+\alpha y$. What I would like to know is the asymptotic behavior of $s_n=\sum_{k=0}^{\infty}{s_{n,k}}$, or more explicitly the tail $\sum_{n=m}^{\infty}{s_n}$ when m is very large. The empirical Data on firm size suggests that it might appear as a power law (~ $n^{-\zeta}$, where $\zeta$ is a bit larger than 1), also it may not have a finite variance ($M_{xx}(1,1)=\infty$). The one-dimensional problem, in which we only consider the size (that is, vacancies are filled immediately), is completely characterized by Yule process and also suggests the power law. Could anyone give me some insight on how to approach this problem? I've been considering this problem for a month, but since I am not familiar with highly technical tools in analysis or probability I get stuck completely. Thank you!",,"['probability', 'partial-differential-equations', 'recurrence-relations']"
74,How to obtain tail bounds for a linear combination of dependent and bounded random variables?,How to obtain tail bounds for a linear combination of dependent and bounded random variables?,,"I am looking for tail bounds (preferably exponential) for a linear combination of dependent and bounded random variables. consider $$K_{ij}=\sum_{r=1}^N\sum_{c=1}^N W_{ir}C_{rc}W_{jc}$$ where $i \neq j$, $W\in \{+1, -1\}$ and $W$ follows $\operatorname{Bernoulli}(0.5)$, and $C=\operatorname{Toeplitz}(1, \rho, \rho^2, \ldots, \rho^{N-1})$, $0 \leq \rho < 1$. I will be to happy if you give me any pointer to how I can evaluate the moment generating function of $K_{ij}$ to have bound for $Pr\{K_{ij} \geq \epsilon\}\leq \min_s\exp(-s\epsilon)E[\exp(K_{ij}s)]$ based on chernoff bound ans $s \geq 0$. For a hint you can look at my another question entitled as ``How to obtain tail bounds for a sum of dependent and bounded random variables?'' which is a special case of this problem where $C_{rc}=1, 1 \leq c \leq N, 1 \leq r \leq N$. Thanks a lot in advance.","I am looking for tail bounds (preferably exponential) for a linear combination of dependent and bounded random variables. consider $$K_{ij}=\sum_{r=1}^N\sum_{c=1}^N W_{ir}C_{rc}W_{jc}$$ where $i \neq j$, $W\in \{+1, -1\}$ and $W$ follows $\operatorname{Bernoulli}(0.5)$, and $C=\operatorname{Toeplitz}(1, \rho, \rho^2, \ldots, \rho^{N-1})$, $0 \leq \rho < 1$. I will be to happy if you give me any pointer to how I can evaluate the moment generating function of $K_{ij}$ to have bound for $Pr\{K_{ij} \geq \epsilon\}\leq \min_s\exp(-s\epsilon)E[\exp(K_{ij}s)]$ based on chernoff bound ans $s \geq 0$. For a hint you can look at my another question entitled as ``How to obtain tail bounds for a sum of dependent and bounded random variables?'' which is a special case of this problem where $C_{rc}=1, 1 \leq c \leq N, 1 \leq r \leq N$. Thanks a lot in advance.",,['probability-theory']
75,the rank of nodes in the longest direct chain of a random random graph order,the rank of nodes in the longest direct chain of a random random graph order,,"I am facing this problem for a long time, I wish I can find some help in here. Let's consider a graph $G(V,E)$ such that an edge between a pair of node $u$ and $v$ exist with probability $p \in O(1)$. Let's assign identifiers for the vertices from 1 to $n$, where $n = |V|$. Now, direct each edge $(u,v)$ towards $v$ if $u > v$. We have what we call a random graph order P, which can be seen as a DAG (directed acyclic graph). We define $L = (x_1, x_2, \ldots, x_m)$ as the longest directed path in DAG (or chain in P) in P. That is,  $x_i > x_{i+1}$ for all $1 \leq i < m$.  It is known that $|L| = \Theta(n)$. Define $\textit{rank}(x_i)$ as the position of $x_i$ in the set {1, ..., n} (that is, the first, the second, ..., the n-th element in the total order constructed from the identifiers of V). Question. If we take any $x_i$ in L, what is expected rank of $x_i$? My solution was to assume that $|L| = \frac{n}{t}$, and to assume that the path $L$ partitions the graph $G$ into $|L|$ layers. Thus, for the path $L = (x_1, \ldots, x_m)$ the expected rank of $x_i = (n - (t * i)) + \frac{1}{2} * t$. What do you think?","I am facing this problem for a long time, I wish I can find some help in here. Let's consider a graph $G(V,E)$ such that an edge between a pair of node $u$ and $v$ exist with probability $p \in O(1)$. Let's assign identifiers for the vertices from 1 to $n$, where $n = |V|$. Now, direct each edge $(u,v)$ towards $v$ if $u > v$. We have what we call a random graph order P, which can be seen as a DAG (directed acyclic graph). We define $L = (x_1, x_2, \ldots, x_m)$ as the longest directed path in DAG (or chain in P) in P. That is,  $x_i > x_{i+1}$ for all $1 \leq i < m$.  It is known that $|L| = \Theta(n)$. Define $\textit{rank}(x_i)$ as the position of $x_i$ in the set {1, ..., n} (that is, the first, the second, ..., the n-th element in the total order constructed from the identifiers of V). Question. If we take any $x_i$ in L, what is expected rank of $x_i$? My solution was to assume that $|L| = \frac{n}{t}$, and to assume that the path $L$ partitions the graph $G$ into $|L|$ layers. Thus, for the path $L = (x_1, \ldots, x_m)$ the expected rank of $x_i = (n - (t * i)) + \frac{1}{2} * t$. What do you think?",,"['probability', 'graph-theory']"
76,Chi Squared Distribution for Maximum Likelihood,Chi Squared Distribution for Maximum Likelihood,,"I'm beginning to work in bioinformatics and have come across some papers that utilize chi-squared distributions to make a maximum likelihood selection. Particularly in the area using 'amplicons'. I've reimplemented some algorithms in papers, but am unsure on how to use chi-squared to make a selection. We have a matrix of data called our 'amplicon matrix', where columns are 'amplicons' and the data is a rna read, and a corresponding frequency matrix, containing the frequency of the items in the original matrix. Here is a simplified example of the amplicon matrix as well as its corresponding frequency matrix. $$ Amp =  \begin{bmatrix} 'abab' &'cgcg' &'atat' \\ 'baba' &'gtgt' &'tata' \\ 'abab' &'gtgt' &'atta \end{bmatrix} $$ $$ F =  \begin{bmatrix} 2 & 2 & 1 \\ 1 & 1 & 1 \\ 0 & 0 & 1 \end{bmatrix} $$ I need to select an initial column by two methods. The first is just by selecting one at uniform random. The chi-squared is where I'm confused. I'm using this api and not totally sure of the degrees of freedom in the system. Is it just the rank of the frequency matrix? Additionally, how is a selection made based on the return value? Will it be guarenteed to correspond to a column index? I apologize as it has been a while since I've taken any statistics, and will be refreshing my understanding in the fall. Thank you. EDIT: See comments.","I'm beginning to work in bioinformatics and have come across some papers that utilize chi-squared distributions to make a maximum likelihood selection. Particularly in the area using 'amplicons'. I've reimplemented some algorithms in papers, but am unsure on how to use chi-squared to make a selection. We have a matrix of data called our 'amplicon matrix', where columns are 'amplicons' and the data is a rna read, and a corresponding frequency matrix, containing the frequency of the items in the original matrix. Here is a simplified example of the amplicon matrix as well as its corresponding frequency matrix. $$ Amp =  \begin{bmatrix} 'abab' &'cgcg' &'atat' \\ 'baba' &'gtgt' &'tata' \\ 'abab' &'gtgt' &'atta \end{bmatrix} $$ $$ F =  \begin{bmatrix} 2 & 2 & 1 \\ 1 & 1 & 1 \\ 0 & 0 & 1 \end{bmatrix} $$ I need to select an initial column by two methods. The first is just by selecting one at uniform random. The chi-squared is where I'm confused. I'm using this api and not totally sure of the degrees of freedom in the system. Is it just the rank of the frequency matrix? Additionally, how is a selection made based on the return value? Will it be guarenteed to correspond to a column index? I apologize as it has been a while since I've taken any statistics, and will be refreshing my understanding in the fall. Thank you. EDIT: See comments.",,"['probability', 'statistics']"
77,Covariance and Random Variables,Covariance and Random Variables,,"Suppose $X$ and $Y$ are independent random variables. The mgf for $X$ is $M_{X}(t) = (1-t)^{-1}, \ t<1$. The mgf for $Y$ is $M_{Y}(t) = (1-2t)^{-1}, \ t< 0.5$. Two other random variables $U$ and $V$ are defined by $U = \frac{1}{2}(X+Y)$ and $V = \frac{1}{2}(X-Y)$. Calculate $\text{Cov}(U,V)$. So $\text{Cov}(U,V) = E(UV)-E(U)E(V)$. This is the same thing as $\text{Cov}(\frac{1}{2}(X+Y), \frac{1}{2}(X-Y))$. Expanding out, we get $\text{Cov}(\frac{1}{2}(X+Y), \frac{1}{2}(X-Y)) = \frac{1}{4} \text{Var}(X) -\frac{1}{4} \text{Cov}(X,Y)+\frac{1}{4} \text{Cov}(Y,X)-\frac{1}{4} \text{Var}(Y)$ which equals $\frac{1}{4}(\text{Var}(X)-\text{Var}(Y))$. Is there an easier way to obtain this without going through all this work? Could one use the fact $U+V = X$ and $U-V = Y$?","Suppose $X$ and $Y$ are independent random variables. The mgf for $X$ is $M_{X}(t) = (1-t)^{-1}, \ t<1$. The mgf for $Y$ is $M_{Y}(t) = (1-2t)^{-1}, \ t< 0.5$. Two other random variables $U$ and $V$ are defined by $U = \frac{1}{2}(X+Y)$ and $V = \frac{1}{2}(X-Y)$. Calculate $\text{Cov}(U,V)$. So $\text{Cov}(U,V) = E(UV)-E(U)E(V)$. This is the same thing as $\text{Cov}(\frac{1}{2}(X+Y), \frac{1}{2}(X-Y))$. Expanding out, we get $\text{Cov}(\frac{1}{2}(X+Y), \frac{1}{2}(X-Y)) = \frac{1}{4} \text{Var}(X) -\frac{1}{4} \text{Cov}(X,Y)+\frac{1}{4} \text{Cov}(Y,X)-\frac{1}{4} \text{Var}(Y)$ which equals $\frac{1}{4}(\text{Var}(X)-\text{Var}(Y))$. Is there an easier way to obtain this without going through all this work? Could one use the fact $U+V = X$ and $U-V = Y$?",,"['probability', 'moment-generating-functions']"
78,Union Bound of two events?,Union Bound of two events?,,"I am trying to understand the assumption proof of Theorem 2(Page - $7$ ) in the paper ""A Universal Law of Robustness via isoperimetry"" by Bubeck and Sellke. Inequality 1 \begin{align} \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-\mathbb{E}[f]\right) z_{i} \geq \frac{\epsilon}{8}\right) \leq 2 \exp \left(-\frac{\epsilon^{2} n d}{9^{4} c L^{2}}\right) \end{align} Since we assumed that the range of the functions is in $[-1,1]$ we have $\mathbb{E}[f] \in[-1,1]$ and hence: Inequality 2 $$ \mathbb{P}\left(\exists f \in \mathcal{F}: \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}[f] z_{i} \geq \frac{\epsilon}{8}\right) \leq \mathbb{P}\left(\left|\frac{1}{n} \sum_{i=1}^{n} z_{i}\right| \geq \frac{\epsilon}{8}\right) $$ By Hoeffding's inequality, the above quantity is smaller than $2 \exp \left(-n \epsilon^{2} / 8^{3}\right)$ (recall that $\left.\left|z_{i}\right| \leq 2\right)$ . Thus we obtain with an union bound: Inequality 3 $$ \begin{aligned} \mathbb{P}\left(\exists f \in \mathcal{F}: \frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right) z_{i} \geq \frac{\epsilon}{4}\right) & \leq|\mathcal{F}| \cdot \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-\mathbb{E}[f]\right) z_{i} \geq \frac{\epsilon}{8}\right)+\mathbb{P}\left(\left|\frac{1}{n} \sum_{i=1}^{n} z_{i}\right| \geq \frac{\epsilon}{8}\right) \\ & \leq 2|\mathcal{F}| \cdot \exp \left(-\frac{\epsilon^{2} n d}{9^{4} c L^{2}}\right)+2 \exp \left(-\frac{n \epsilon^{2}}{8^{3}}\right) \end{aligned} $$ I am not getting how Union bound is getting happened using Ineq 1 and 2. Can anyone help me with that how they able to reach last inequality?","I am trying to understand the assumption proof of Theorem 2(Page - ) in the paper ""A Universal Law of Robustness via isoperimetry"" by Bubeck and Sellke. Inequality 1 Since we assumed that the range of the functions is in we have and hence: Inequality 2 By Hoeffding's inequality, the above quantity is smaller than (recall that . Thus we obtain with an union bound: Inequality 3 I am not getting how Union bound is getting happened using Ineq 1 and 2. Can anyone help me with that how they able to reach last inequality?","7 \begin{align}
\mathbb{P}\left(\frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-\mathbb{E}[f]\right) z_{i} \geq \frac{\epsilon}{8}\right) \leq 2 \exp \left(-\frac{\epsilon^{2} n d}{9^{4} c L^{2}}\right)
\end{align} [-1,1] \mathbb{E}[f] \in[-1,1] 
\mathbb{P}\left(\exists f \in \mathcal{F}: \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}[f] z_{i} \geq \frac{\epsilon}{8}\right) \leq \mathbb{P}\left(\left|\frac{1}{n} \sum_{i=1}^{n} z_{i}\right| \geq \frac{\epsilon}{8}\right)
 2 \exp \left(-n \epsilon^{2} / 8^{3}\right) \left.\left|z_{i}\right| \leq 2\right) 
\begin{aligned}
\mathbb{P}\left(\exists f \in \mathcal{F}: \frac{1}{n} \sum_{i=1}^{n} f\left(x_{i}\right) z_{i} \geq \frac{\epsilon}{4}\right) & \leq|\mathcal{F}| \cdot \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^{n}\left(f\left(x_{i}\right)-\mathbb{E}[f]\right) z_{i} \geq \frac{\epsilon}{8}\right)+\mathbb{P}\left(\left|\frac{1}{n} \sum_{i=1}^{n} z_{i}\right| \geq \frac{\epsilon}{8}\right) \\
& \leq 2|\mathcal{F}| \cdot \exp \left(-\frac{\epsilon^{2} n d}{9^{4} c L^{2}}\right)+2 \exp \left(-\frac{n \epsilon^{2}}{8^{3}}\right)
\end{aligned}
","['probability', 'solution-verification']"
79,EM Algorithm vs Gradient Descent,EM Algorithm vs Gradient Descent,,"I was reading about the EM algorithm ( https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm ) - this algorithm is used for optimizing functions (e.g. the Likelihood Functions belonging to Statistical Models). I have heard that in the context of optimizing the Likelihood Function for Mixture Models in Statistics ( https://en.wikipedia.org/wiki/Mixture_model ), the EM algorithm is preferred to more common algorithms such as Gradient Descent. Apparently, this is because the Likelihood Function of Mixture Models is usually ""multi-modal"" (e.g. a Mixture Model is a mixture of several Normal Distributions and each Normal Distribution has a ""mode"" - therefore, a Mixture Model is almost guaranteed to be ""multi-modal""). What I am having difficulty in understand is the following point : Why should the EM algorithm be any more suited for optimizing ""Multi-Modal"" functions compared to Gradient Descent? That is, by considering the mathematical properties of ""Multi-Modal"" functions, the EM algorithm and Gradient Descent - how can we use these mathematical properties to rationalize why the EM algorithm is more suited for optimizing ""Multi-Modal"" functions compared to Gradient Descent? Thanks! Note: My guess is that perhaps the EM algorithm might be ""less computationally expensive"" compared to Gradient Descent? Do either of these algorithms have any theoretical convergence properties that could be used to explain the traditional preference of EM over Gradient Descent in ""Multi-Modal"" FUnctions? References: https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch20.pdf Thanks!","I was reading about the EM algorithm ( https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm ) - this algorithm is used for optimizing functions (e.g. the Likelihood Functions belonging to Statistical Models). I have heard that in the context of optimizing the Likelihood Function for Mixture Models in Statistics ( https://en.wikipedia.org/wiki/Mixture_model ), the EM algorithm is preferred to more common algorithms such as Gradient Descent. Apparently, this is because the Likelihood Function of Mixture Models is usually ""multi-modal"" (e.g. a Mixture Model is a mixture of several Normal Distributions and each Normal Distribution has a ""mode"" - therefore, a Mixture Model is almost guaranteed to be ""multi-modal""). What I am having difficulty in understand is the following point : Why should the EM algorithm be any more suited for optimizing ""Multi-Modal"" functions compared to Gradient Descent? That is, by considering the mathematical properties of ""Multi-Modal"" functions, the EM algorithm and Gradient Descent - how can we use these mathematical properties to rationalize why the EM algorithm is more suited for optimizing ""Multi-Modal"" functions compared to Gradient Descent? Thanks! Note: My guess is that perhaps the EM algorithm might be ""less computationally expensive"" compared to Gradient Descent? Do either of these algorithms have any theoretical convergence properties that could be used to explain the traditional preference of EM over Gradient Descent in ""Multi-Modal"" FUnctions? References: https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch20.pdf Thanks!",,"['probability', 'statistics', 'optimization', 'maximum-likelihood', 'gradient-descent']"
80,Intuition behind conditioning to events with probability zero,Intuition behind conditioning to events with probability zero,,"What's the intuition behind why the conditional expectation w.r.t. a $\sigma$ -algebra allows us to condition to events with zero probability? For example, let’s say we have two continuous random variables $X$ and $Y$ defined on $(\Omega,\mathcal{F},\mathbb{P})$ . We define the conditional probability density function of $Y$ given $X=x_0$ , as $$f_{Y|X}(y,x_0)=\frac{f_{XY}(x_0,y)}{f_X(x_0)}.$$ Even though in this definition $f_X$ has to be strictly greater than $0$ , we are still conditioning to an event with probability zero $\mathbb{P}(X=x_0)=0$ , as $X$ is a continuous r.v. I understand that the concept of conditional expectation of a random variable (and conditional probability of an event) to a $\sigma$ -algebra was introduced in order to deal with conditioning to events with probability zero, but I haven’t quite grasped the intuition behind this.","What's the intuition behind why the conditional expectation w.r.t. a -algebra allows us to condition to events with zero probability? For example, let’s say we have two continuous random variables and defined on . We define the conditional probability density function of given , as Even though in this definition has to be strictly greater than , we are still conditioning to an event with probability zero , as is a continuous r.v. I understand that the concept of conditional expectation of a random variable (and conditional probability of an event) to a -algebra was introduced in order to deal with conditioning to events with probability zero, but I haven’t quite grasped the intuition behind this.","\sigma X Y (\Omega,\mathcal{F},\mathbb{P}) Y X=x_0 f_{Y|X}(y,x_0)=\frac{f_{XY}(x_0,y)}{f_X(x_0)}. f_X 0 \mathbb{P}(X=x_0)=0 X \sigma","['probability', 'probability-theory', 'measure-theory', 'conditional-probability', 'conditional-expectation']"
81,Calculating probability of game ending after $n$ flips,Calculating probability of game ending after  flips,n,"Two players A and B flip a coin sequentially. The game finishes when the sequence TTH is formed and player A wins or the sequence HTT is formed and player B wins. What is the probability that the game will finish at the $n$ -th flip? What I did: A wins iff the sequence is $n-1$ T's followed by a single H : $\frac{1}{2^n}$ B wins iff the sequence ends with HTT and we have no two consecutive T's in the first $n-3$ flips: this happens (I think) with probability $\frac{F_{n-2}}{2^n}$ where $F_{n}$ is the $n$ -th Fibonacci number. I proved this by induction. Thus, the total probability is $\frac{F_{n-2}+1}{2^n}$ Can someone verify that this is correct and/or share how you would solve this problem? If the answer is correct, then by summing over all $n$ we can obtain an interesting identity involving the Fibonacci numbers!","Two players A and B flip a coin sequentially. The game finishes when the sequence TTH is formed and player A wins or the sequence HTT is formed and player B wins. What is the probability that the game will finish at the -th flip? What I did: A wins iff the sequence is T's followed by a single H : B wins iff the sequence ends with HTT and we have no two consecutive T's in the first flips: this happens (I think) with probability where is the -th Fibonacci number. I proved this by induction. Thus, the total probability is Can someone verify that this is correct and/or share how you would solve this problem? If the answer is correct, then by summing over all we can obtain an interesting identity involving the Fibonacci numbers!",n n-1 \frac{1}{2^n} n-3 \frac{F_{n-2}}{2^n} F_{n} n \frac{F_{n-2}+1}{2^n} n,"['probability', 'markov-chains', 'fibonacci-numbers']"
82,Probability that Carl has to wait at least 10 minutes for one of the others and for both of the others to show up?,Probability that Carl has to wait at least 10 minutes for one of the others and for both of the others to show up?,,"This question is for the other subquestions for the same problem here . For those not willing to click the link, I will post the exercise problem here as well. Alice, Bob, and Carl arrange to meet for lunch on a certain day. They arrive independently at uniformly distributed times between 1 p.m. and 1:30 p.m. For the rest of the problem, assume Carl arrives first at 1:10 p.m. and condition on this fact. (b) What is the probability that Carl will have to wait more than 10 minutes for one of the others to show up? (c) What is the probability that Carl will have to wait more than 10 minutes for both of the others to show up? Apparently, my approach to the solution has given me the answers in a swapped manner, which I can't understand why. Allow me to elaborate. My approach Let's say that the events for Alice and Bob arriving are each $A$ and $B$ i.i.d. on Unif( $10,\ 30$ ). (b) The probability that Carl will wait more than 10 minutes for at least one of the others to arrive is: (Probability that Carl waits less than 10 minutes for Alice and more than 10 for Bob) + (Probability that Carl waits less than 10 minutes for Bob and more than 10 for Alice) + (Probability that Carl waits more than 10 minutes for both) which gives me the result of $\left(\frac{1}{2} * \frac{1}{2}\right) + \left(\frac{1}{2} * \frac{1}{2}\right) + \left(\frac{1}{2} * \frac{1}{2}\right) = \frac{3}{4}$ . (c) Probability that Carl waits more than 10 minutes for both is the probability that $A$ and $B$ both fall in the interval ( $20$ , $30$ ) in the total interval ( $10$ , $30$ ). Therefore we get the probability $\frac{1}{2} * \frac{1}{2} = \frac{1}{4}$ . However, apparently the correct answer is $\frac{1}{4}$ for (b) and $\frac{3}{4}$ for (c), and I'm not entirely sure why. The rationale the textbook gives is that for (b) we need to compute the time that both of them arrive after 1:20 p.m., and for (c) we simple take the complement that both of them arrive between 1:10 and 1:20 p.m. $1 - \frac{1}{4}$ . I'm not entirely sure how these solutions make sense, though, and was hoping someone would be kind enough to provide me with some insight. Thank you.","This question is for the other subquestions for the same problem here . For those not willing to click the link, I will post the exercise problem here as well. Alice, Bob, and Carl arrange to meet for lunch on a certain day. They arrive independently at uniformly distributed times between 1 p.m. and 1:30 p.m. For the rest of the problem, assume Carl arrives first at 1:10 p.m. and condition on this fact. (b) What is the probability that Carl will have to wait more than 10 minutes for one of the others to show up? (c) What is the probability that Carl will have to wait more than 10 minutes for both of the others to show up? Apparently, my approach to the solution has given me the answers in a swapped manner, which I can't understand why. Allow me to elaborate. My approach Let's say that the events for Alice and Bob arriving are each and i.i.d. on Unif( ). (b) The probability that Carl will wait more than 10 minutes for at least one of the others to arrive is: (Probability that Carl waits less than 10 minutes for Alice and more than 10 for Bob) + (Probability that Carl waits less than 10 minutes for Bob and more than 10 for Alice) + (Probability that Carl waits more than 10 minutes for both) which gives me the result of . (c) Probability that Carl waits more than 10 minutes for both is the probability that and both fall in the interval ( , ) in the total interval ( , ). Therefore we get the probability . However, apparently the correct answer is for (b) and for (c), and I'm not entirely sure why. The rationale the textbook gives is that for (b) we need to compute the time that both of them arrive after 1:20 p.m., and for (c) we simple take the complement that both of them arrive between 1:10 and 1:20 p.m. . I'm not entirely sure how these solutions make sense, though, and was hoping someone would be kind enough to provide me with some insight. Thank you.","A B 10,\ 30 \left(\frac{1}{2} * \frac{1}{2}\right) + \left(\frac{1}{2} * \frac{1}{2}\right) + \left(\frac{1}{2} * \frac{1}{2}\right) = \frac{3}{4} A B 20 30 10 30 \frac{1}{2} * \frac{1}{2} = \frac{1}{4} \frac{1}{4} \frac{3}{4} 1 - \frac{1}{4}","['probability', 'probability-theory', 'uniform-distribution']"
83,Random Variable vs data vs random sample,Random Variable vs data vs random sample,,"I have a problem understanding the difference between random variable and random sample. I have read this thread , but still it is unclear. According to wiki random variable is a function that from a set of outcomes (events) to measurable values $\Omega$ -> $E$ where $E$ could be $\mathbb{R}$ . And random sample is a possible outcome. So, in a lecture script I have these sentences which are confusing me: let $D=\{x_1,x_2,x_3...x_n\}$ be a set of random variables. Now I want to create a concrete example for myself to understand what $\{x_1,x_2,...,x_n\}$ could be. Let's take the sample of two dice where we want to compute the probability of the sum of the figures of dice we have thrown. So we construct a random variable $X$ which just adds the thrown number of the dice: $$X:\Omega\to\mathbb{N}$$ $$X(\text{die}_1,\text{die}_2) = \text{die}_1 + \text{die}_2 $$ Where dice are uniformly distributed in $ \{ 1,\cdots,6 \} $ . And as far I know, if I throw two diсe, I have concrete values which are my random samples. Now my concrete question is: what could be in this specific example a set of random variables $D=\{x_1,x_2,x_3...x_n\}$ ? And what are then the concrete random samples? UPDATE: After reading the comments and replies, I want to underline, that I have a specific question and I would appreciate if someone could answer it explicitly: In the above example please give me a concrete $D = {x_1,x_2,...,x_n}$ as a set of random variables. I want to see how a set of random variables $D = {x_1,x_2,...,x_n}$ (more than 2 random variables) would look like in this example.","I have a problem understanding the difference between random variable and random sample. I have read this thread , but still it is unclear. According to wiki random variable is a function that from a set of outcomes (events) to measurable values -> where could be . And random sample is a possible outcome. So, in a lecture script I have these sentences which are confusing me: let be a set of random variables. Now I want to create a concrete example for myself to understand what could be. Let's take the sample of two dice where we want to compute the probability of the sum of the figures of dice we have thrown. So we construct a random variable which just adds the thrown number of the dice: Where dice are uniformly distributed in . And as far I know, if I throw two diсe, I have concrete values which are my random samples. Now my concrete question is: what could be in this specific example a set of random variables ? And what are then the concrete random samples? UPDATE: After reading the comments and replies, I want to underline, that I have a specific question and I would appreciate if someone could answer it explicitly: In the above example please give me a concrete as a set of random variables. I want to see how a set of random variables (more than 2 random variables) would look like in this example.","\Omega E E \mathbb{R} D=\{x_1,x_2,x_3...x_n\} \{x_1,x_2,...,x_n\} X X:\Omega\to\mathbb{N} X(\text{die}_1,\text{die}_2) = \text{die}_1 + \text{die}_2   \{ 1,\cdots,6 \}  D=\{x_1,x_2,x_3...x_n\} D = {x_1,x_2,...,x_n} D = {x_1,x_2,...,x_n}","['probability', 'random-variables']"
84,Are all disjoint events dependent?,Are all disjoint events dependent?,,"This is a basic question about probability theory. My reasoning goes as follows: If $A$ and $B$ are independent events, the probability they both happen is their multiplication:  $$\Pr(A \text{ and } B) = \Pr(A) \times \Pr(B)$$ If their marginal probability is not impossible, also their product is non-zero: $$\Pr(A) > 0,\, \Pr(B) > 0 \implies \Pr(A \text{ and } B) > 0$$ Hence, independent events cannot be disjoint Hence, only dependent events can be disjoint Hence, all disjoint events are dependent. Can you help me point out the error in my argument?","This is a basic question about probability theory. My reasoning goes as follows: If $A$ and $B$ are independent events, the probability they both happen is their multiplication:  $$\Pr(A \text{ and } B) = \Pr(A) \times \Pr(B)$$ If their marginal probability is not impossible, also their product is non-zero: $$\Pr(A) > 0,\, \Pr(B) > 0 \implies \Pr(A \text{ and } B) > 0$$ Hence, independent events cannot be disjoint Hence, only dependent events can be disjoint Hence, all disjoint events are dependent. Can you help me point out the error in my argument?",,"['probability', 'probability-theory']"
85,Bounded $L^2$ expectation implies convergence in $L^2.$,Bounded  expectation implies convergence in,L^2 L^2.,"In probability at least four different types of convergence are considered: $a)$ Almost sure convergence $b)$ Convergence in probability $c)$ Convergence in $L^p$ $d)$ Convergence in distribution It is known (see e.g. the book of Karr: ""Probability"", Springer) that $$a)\,\Rightarrow \, b)\,\Rightarrow \, d)$$ and that $$c)\,\Rightarrow \, b).$$ All the other implications are false and it is possible to find counterexamples to them here: Convergence types in probability theory : Counterexamples Moreover, convergence in $L^p$ implies convergence in $L^q$ if $p>q$ and the space is finite. Now, let ${x_n}$ be a family of bounded random variables defined over a given probability space that converge a.s. to a bounded random variable $x.$ The following statements are true or false? 1) If $\mathbb E(x_n^2)\leq \mathbb E(x^2)$ then $x_n$ converges to $x$ in $L^2.$ 2) If $\mathbb E(x_n^2)=1$ $\forall n$ then $lim_{n\to \infty}\mathbb E(x_n)=\mathbb E(x).$ 3) If $\mathbb E(x_n^2)=1$ and $\mathbb E(x_n^3)=c\in \mathbb R\,$ $\,\forall n$ then $x_n$ converges to $x$ in $L^2.$","In probability at least four different types of convergence are considered: $a)$ Almost sure convergence $b)$ Convergence in probability $c)$ Convergence in $L^p$ $d)$ Convergence in distribution It is known (see e.g. the book of Karr: ""Probability"", Springer) that $$a)\,\Rightarrow \, b)\,\Rightarrow \, d)$$ and that $$c)\,\Rightarrow \, b).$$ All the other implications are false and it is possible to find counterexamples to them here: Convergence types in probability theory : Counterexamples Moreover, convergence in $L^p$ implies convergence in $L^q$ if $p>q$ and the space is finite. Now, let ${x_n}$ be a family of bounded random variables defined over a given probability space that converge a.s. to a bounded random variable $x.$ The following statements are true or false? 1) If $\mathbb E(x_n^2)\leq \mathbb E(x^2)$ then $x_n$ converges to $x$ in $L^2.$ 2) If $\mathbb E(x_n^2)=1$ $\forall n$ then $lim_{n\to \infty}\mathbb E(x_n)=\mathbb E(x).$ 3) If $\mathbb E(x_n^2)=1$ and $\mathbb E(x_n^3)=c\in \mathbb R\,$ $\,\forall n$ then $x_n$ converges to $x$ in $L^2.$",,"['real-analysis', 'probability', 'probability-theory']"
86,What is a characterisation function,What is a characterisation function,,"I am reading a paper: ""Probability of Backtest Overfitting"" , and page 13 defines the relative frequency: $$f(\lambda) = \sum_{c \in C_S} \frac{\chi_{\{\lambda\}} \left( \lambda_c\right)}{|\{C_S\}|}$$ the authors say that $\mathcal{X}$ is the characterization function. I would like to know what exactly that is since I have never come across that term before. EDIT: I emailed the author of the paper, and according to him, $f(\lambda)$ is simply a PDF.","I am reading a paper: ""Probability of Backtest Overfitting"" , and page 13 defines the relative frequency: $$f(\lambda) = \sum_{c \in C_S} \frac{\chi_{\{\lambda\}} \left( \lambda_c\right)}{|\{C_S\}|}$$ the authors say that $\mathcal{X}$ is the characterization function. I would like to know what exactly that is since I have never come across that term before. EDIT: I emailed the author of the paper, and according to him, $f(\lambda)$ is simply a PDF.",,"['probability', 'measure-theory']"
87,"Find probability of exactly one $6$ in first ten rolls of die, given two $6$s in twenty rolls","Find probability of exactly one  in first ten rolls of die, given two s in twenty rolls",6 6,"I am trying to calculate the probability that, when rolling a fair die twenty times, I roll exactly one $6$ in the first ten rolls, given that I roll two $6$s in the twenty rolls. My thoughts Let $A = \{\text {Exactly one 6 in first ten rolls of a die} \}$ and $B = \{\text {Exactly two 6s in twenty rolls of a die} \}.$ Then I want to find  $$P[A\mid B] = \frac{P[A \cap B]}{P[B]}.$$ By the binomial distribution formula, we get that  $$P[B] = {20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}.$$ Furthermore I think that $P[A \cap B]$ is equal to the probability of rolling exactly one $6$ in ten rolls and then rolling exactly one $6$ in another set of ten rolls.  That is, $$P[A \cap B] = \left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2.$$ Am I correct in thinking this? If so, then it follows that the required probability is  $$P[A \mid B] = \frac{\left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2}{{20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}},$$ which, I know, can be simplified further!","I am trying to calculate the probability that, when rolling a fair die twenty times, I roll exactly one $6$ in the first ten rolls, given that I roll two $6$s in the twenty rolls. My thoughts Let $A = \{\text {Exactly one 6 in first ten rolls of a die} \}$ and $B = \{\text {Exactly two 6s in twenty rolls of a die} \}.$ Then I want to find  $$P[A\mid B] = \frac{P[A \cap B]}{P[B]}.$$ By the binomial distribution formula, we get that  $$P[B] = {20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}.$$ Furthermore I think that $P[A \cap B]$ is equal to the probability of rolling exactly one $6$ in ten rolls and then rolling exactly one $6$ in another set of ten rolls.  That is, $$P[A \cap B] = \left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2.$$ Am I correct in thinking this? If so, then it follows that the required probability is  $$P[A \mid B] = \frac{\left[{10 \choose 1} \cdot \left(\frac{1}{6}\right)^1 \cdot \left(\frac{5}{6}\right)^9\right]^2}{{20 \choose 2} \cdot \left(\frac{1}{6}\right)^2 \cdot \left(\frac{5}{6}\right)^{18}},$$ which, I know, can be simplified further!",,"['probability', 'statistics', 'binomial-distribution']"
88,How does the classification using the 0-1 loss matrix method work? [closed],How does the classification using the 0-1 loss matrix method work? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 months ago . Improve this question In this machine learning lecture the professor says: Suppose $\mathbf{X}\in\Bbb R^p$ and $g\in G$ where $G$ is a discrete   space. We have a joint probability distribution $\Pr(\mathbf{X},g)$. Our training data has some points like: $(\mathbf{x_1},g_1)$, $(\mathbf{x_2},g_2)$, $(\mathbf{x_3},g_3)$ ...   $(\mathbf{x_n},g_n)$ We now define a function $f(\mathbf{X}):\Bbb R^p \to G$. The loss $L$ is defined as a $K\times K$ matrix where $K$ is the   cardinality of $G$. It has only zeroes along the main diagonal. $L(k,l)$ is basically the cost of classifying $k$ as $l$. An example of $0-1$ loss function: \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix} $\text{EPE}(\hat{f}) = \text{E} [L(G,\hat{f})]$ (where $\text{EPE=  Expected Prediction Error}$) $=E_\mathbf{X} E_{G/\mathbf{X}} \{L[G,\hat{f}]|\mathbf{X}\}$ $\hat{f}(\mathbf{x})=\text{argmin}_g\sum_{k=1}^{k}L(k,g)\text{Pr}(k|\mathbf{X}=\mathbf{x})=\text{argmax}_g\text{Pr}(g|\mathbf{X=x})$ $\hat{f}(\mathbf{x})$ is the Bayesian Optimal Classifier. I couldn't really follow what the professor was trying to say in some of the steps. My questions are: Suppose our loss matrix is indeed: \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix} What it the use of this matrix? What does classifying $k$ as $l$ even mean? Then how do we read off the loss for (say) a certain input $\mathbf{x_i}$ from the matrix? I couldn't understand what $\hat{f}$ and $\text{EPE}(\hat{f}\mathbf{(x)})$ stand for. Could someone please explain it with a simple example?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 3 months ago . Improve this question In this machine learning lecture the professor says: Suppose $\mathbf{X}\in\Bbb R^p$ and $g\in G$ where $G$ is a discrete   space. We have a joint probability distribution $\Pr(\mathbf{X},g)$. Our training data has some points like: $(\mathbf{x_1},g_1)$, $(\mathbf{x_2},g_2)$, $(\mathbf{x_3},g_3)$ ...   $(\mathbf{x_n},g_n)$ We now define a function $f(\mathbf{X}):\Bbb R^p \to G$. The loss $L$ is defined as a $K\times K$ matrix where $K$ is the   cardinality of $G$. It has only zeroes along the main diagonal. $L(k,l)$ is basically the cost of classifying $k$ as $l$. An example of $0-1$ loss function: \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix} $\text{EPE}(\hat{f}) = \text{E} [L(G,\hat{f})]$ (where $\text{EPE=  Expected Prediction Error}$) $=E_\mathbf{X} E_{G/\mathbf{X}} \{L[G,\hat{f}]|\mathbf{X}\}$ $\hat{f}(\mathbf{x})=\text{argmin}_g\sum_{k=1}^{k}L(k,g)\text{Pr}(k|\mathbf{X}=\mathbf{x})=\text{argmax}_g\text{Pr}(g|\mathbf{X=x})$ $\hat{f}(\mathbf{x})$ is the Bayesian Optimal Classifier. I couldn't really follow what the professor was trying to say in some of the steps. My questions are: Suppose our loss matrix is indeed: \begin{bmatrix} 0 & 1 & 1 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \end{bmatrix} What it the use of this matrix? What does classifying $k$ as $l$ even mean? Then how do we read off the loss for (say) a certain input $\mathbf{x_i}$ from the matrix? I couldn't understand what $\hat{f}$ and $\text{EPE}(\hat{f}\mathbf{(x)})$ stand for. Could someone please explain it with a simple example?",,"['probability', 'matrices']"
89,Probability result in well-known paper appears to use std deviation correction of sqrt(n/(n-2.5)),Probability result in well-known paper appears to use std deviation correction of sqrt(n/(n-2.5)),,"The below problem is cited in the 1972 paper ""Subjective Probability: A Judgment of Representativeness"" by Daniel Kahneman and Amos Tversky.  The paper provides an answer to the problem for the purpose of comparing that answer with the impressions of test subjects to whom the problem was posed. The average heights of adult males and females in the US are, respectively, 5 ft 10 in. and 5 ft 4 in. Both distributions are approximately normal with a standard deviation of about 2.5 in. An investigator has selected one population by chance and has drawn from it a random sample. What do you think are the odds that he has selected the male population if (i) the sample consists of a single person whose height is 5 ft 10 in.? (ii) the sample consists of 6 persons whose average height is 5 ft 8 in.? ........ The correct odds are 16 in case (i) and 29 in case (ii). Bayes Theorem and the Gaussian PDF give odds of 17.8 and 317 for cases (i) and (ii), calculations below.  Since the problem provides a population standard deviation, using a sample standard deviation adjustor does not seem in order.  However, in case(ii) I checked a few adjustors $\sigma_{adj} = \sigma \cdot \sqrt{\frac{n}{n-k}}$ for $k = 1$ (Bessel's correction) and $k=1.5$ (alternative correction for normal distribution).  Neither returned the authors' given answer, although each moved the calculated odds in that direction. The provided answer for case(ii) IS obtained using an adjustor based on k=2.5! The question: what method could the authors be using that would provide their stated answer?  Why would k=2.5 be used? Solution using Bayes Theorem and the Gaussian PDF Case (i) Using Bayes Theorem $$P(A|B)=\frac{P(B|A)\cdot P(A)}{P(B)}$$ $$$$ $$P(male | 5'10)=\frac{P(5'10 | male)\cdot P(male)}{P(5'10)}$$ $$$$ $$P(female | 5'10)=\frac{P(5'10 | female)\cdot P(female)}{P(5'10)}$$ $$$$ Assuming $P(male)=P(female)$ which is not explicitly stated in the problem ... $$$$ $$odds=\frac{P(male | 5'10)}{P(female | 5'10)}=\frac{P(5'10 | male)}{P(5'10 | female)}$$ $$$$ Using the Gaussian PDF $$f(x)={\frac 1{\sqrt{2\pi}\sigma}e^\frac {-(x-\mu)^2}{2\sigma^2}}$$ yields ... $$\frac{P(5'10 | male)}{P(5'10 | female)}=\frac{{\frac 1{\sqrt{2\pi}\cdot 2.5}e^\frac {-(70-70)^2}{2\cdot 2.5^2}}}{{\frac 1{\sqrt{2\pi}\cdot 2.5}e^\frac {-(70-64)^2}{2\cdot 2.5^2}}}=\frac{{e^0}}{{e^{-2.88}}}=17.8$$ $$$$ Case (ii) Applying the same methodology to case (ii) with an adjusted $\sigma=\frac{2.5}{\sqrt6}=1.0206$ gives $$odds=\frac{P(5'8\,avg | male)}{P(5'8\,avg | female)}=\frac{{\frac 1{\sqrt{2\pi}\cdot 1.0206}e^\frac {-(68-70)^2}{2\cdot 1.0206^2}}}{{\frac 1{\sqrt{2\pi}\cdot 1.0206}e^\frac {-(68-64)^2}{2\cdot 1.0206^2}}}=\frac{{e^{-1.92}}}{{e^{-7.68}}}=317.4$$ $$$$ So there is a small difference (17.8 vs. 16) from the given answer in case (i) and a very large difference (317 vs. 29)in case (ii). What method could be arriving at the stated answers of 16 and 29?","The below problem is cited in the 1972 paper ""Subjective Probability: A Judgment of Representativeness"" by Daniel Kahneman and Amos Tversky.  The paper provides an answer to the problem for the purpose of comparing that answer with the impressions of test subjects to whom the problem was posed. The average heights of adult males and females in the US are, respectively, 5 ft 10 in. and 5 ft 4 in. Both distributions are approximately normal with a standard deviation of about 2.5 in. An investigator has selected one population by chance and has drawn from it a random sample. What do you think are the odds that he has selected the male population if (i) the sample consists of a single person whose height is 5 ft 10 in.? (ii) the sample consists of 6 persons whose average height is 5 ft 8 in.? ........ The correct odds are 16 in case (i) and 29 in case (ii). Bayes Theorem and the Gaussian PDF give odds of 17.8 and 317 for cases (i) and (ii), calculations below.  Since the problem provides a population standard deviation, using a sample standard deviation adjustor does not seem in order.  However, in case(ii) I checked a few adjustors $\sigma_{adj} = \sigma \cdot \sqrt{\frac{n}{n-k}}$ for $k = 1$ (Bessel's correction) and $k=1.5$ (alternative correction for normal distribution).  Neither returned the authors' given answer, although each moved the calculated odds in that direction. The provided answer for case(ii) IS obtained using an adjustor based on k=2.5! The question: what method could the authors be using that would provide their stated answer?  Why would k=2.5 be used? Solution using Bayes Theorem and the Gaussian PDF Case (i) Using Bayes Theorem $$P(A|B)=\frac{P(B|A)\cdot P(A)}{P(B)}$$ $$$$ $$P(male | 5'10)=\frac{P(5'10 | male)\cdot P(male)}{P(5'10)}$$ $$$$ $$P(female | 5'10)=\frac{P(5'10 | female)\cdot P(female)}{P(5'10)}$$ $$$$ Assuming $P(male)=P(female)$ which is not explicitly stated in the problem ... $$$$ $$odds=\frac{P(male | 5'10)}{P(female | 5'10)}=\frac{P(5'10 | male)}{P(5'10 | female)}$$ $$$$ Using the Gaussian PDF $$f(x)={\frac 1{\sqrt{2\pi}\sigma}e^\frac {-(x-\mu)^2}{2\sigma^2}}$$ yields ... $$\frac{P(5'10 | male)}{P(5'10 | female)}=\frac{{\frac 1{\sqrt{2\pi}\cdot 2.5}e^\frac {-(70-70)^2}{2\cdot 2.5^2}}}{{\frac 1{\sqrt{2\pi}\cdot 2.5}e^\frac {-(70-64)^2}{2\cdot 2.5^2}}}=\frac{{e^0}}{{e^{-2.88}}}=17.8$$ $$$$ Case (ii) Applying the same methodology to case (ii) with an adjusted $\sigma=\frac{2.5}{\sqrt6}=1.0206$ gives $$odds=\frac{P(5'8\,avg | male)}{P(5'8\,avg | female)}=\frac{{\frac 1{\sqrt{2\pi}\cdot 1.0206}e^\frac {-(68-70)^2}{2\cdot 1.0206^2}}}{{\frac 1{\sqrt{2\pi}\cdot 1.0206}e^\frac {-(68-64)^2}{2\cdot 1.0206^2}}}=\frac{{e^{-1.92}}}{{e^{-7.68}}}=317.4$$ $$$$ So there is a small difference (17.8 vs. 16) from the given answer in case (i) and a very large difference (317 vs. 29)in case (ii). What method could be arriving at the stated answers of 16 and 29?",,"['probability', 'statistics']"
90,What Jordan curve of length $1$ maximizes the expected length of a chord between two uniformly picked points on it?,What Jordan curve of length  maximizes the expected length of a chord between two uniformly picked points on it?,1,"For a (sufficiently nice) Jordan curve $\sigma :[0,1] \to \mathbb{R}^2$ with unit length and natural (w.r.t. arc length) parametrization, we denote the expected value of the distance between two points that are picked from the path independently and uniformly by $c(\sigma)$. So $$c(\sigma) = \mathbb{E}[ \space|\sigma(T_1)- \sigma(T_2)| \space],$$ where $T_1, T_2 \sim U([0,1])$ are independent. What path maximizes $c$? For example, for $\sigma =$ circle (of radius $\frac{1}{2\pi}$ to have unit perimeter), $$c(\sigma) = \frac{2}{\pi^2}$$ ( It is known that for unit circle we get $\frac{4}{\pi}$ so scaling leads to the value $\frac{2}{\pi^2}$.) Is circle the maximizing path? PS. Here is a small application for testing different kinds of paths. The circle seemed to be the best among all paths I tried out.","For a (sufficiently nice) Jordan curve $\sigma :[0,1] \to \mathbb{R}^2$ with unit length and natural (w.r.t. arc length) parametrization, we denote the expected value of the distance between two points that are picked from the path independently and uniformly by $c(\sigma)$. So $$c(\sigma) = \mathbb{E}[ \space|\sigma(T_1)- \sigma(T_2)| \space],$$ where $T_1, T_2 \sim U([0,1])$ are independent. What path maximizes $c$? For example, for $\sigma =$ circle (of radius $\frac{1}{2\pi}$ to have unit perimeter), $$c(\sigma) = \frac{2}{\pi^2}$$ ( It is known that for unit circle we get $\frac{4}{\pi}$ so scaling leads to the value $\frac{2}{\pi^2}$.) Is circle the maximizing path? PS. Here is a small application for testing different kinds of paths. The circle seemed to be the best among all paths I tried out.",,"['probability', 'differential-geometry', 'calculus-of-variations', 'plane-geometry']"
91,The eternally sleeping beauty. (Thought experiment regarding uniform distribution on the natural numbers),The eternally sleeping beauty. (Thought experiment regarding uniform distribution on the natural numbers),,"A cousin of mine recently confronted me with a thought experiment that in essence contained an analogical situation to the following problem: Assume you are a beauty with the following properties: -You know there was a first day on which you woke up. -You know each time you fall asleep, you lose your memories of the previous times you woke. -You are immortal and live in an temporally infinite universe. You are confronted with the question: What probability do you ascribe to the even ""Today is the n-th time I woke up.""? It seems to me that there is no answer within Kolmogorov's probability theory, since any day seems equally likely and you cannot have an uniform distribution over the natural numbers. Is the question not well defined? I would love to read your thoughts.","A cousin of mine recently confronted me with a thought experiment that in essence contained an analogical situation to the following problem: Assume you are a beauty with the following properties: -You know there was a first day on which you woke up. -You know each time you fall asleep, you lose your memories of the previous times you woke. -You are immortal and live in an temporally infinite universe. You are confronted with the question: What probability do you ascribe to the even ""Today is the n-th time I woke up.""? It seems to me that there is no answer within Kolmogorov's probability theory, since any day seems equally likely and you cannot have an uniform distribution over the natural numbers. Is the question not well defined? I would love to read your thoughts.",,['probability']
92,Flipping coins- percentages of heads vs tails,Flipping coins- percentages of heads vs tails,,If I flip a coin multiple times and count the number of time it fell on heads and the number of times it fell on tails and keep a track of them. In how many flips on average will the delta between percentage of heads and percentage of tails will be less than 0.1%?,If I flip a coin multiple times and count the number of time it fell on heads and the number of times it fell on tails and keep a track of them. In how many flips on average will the delta between percentage of heads and percentage of tails will be less than 0.1%?,,"['probability', 'statistics']"
93,Uniform random distribution on a unit disk,Uniform random distribution on a unit disk,,"a) A point is uniformly chosen in the unit disk $0 ≤ x^2 + y^2 ≤ 1$ . Find the probability that its   distance from the origin is less than $r$ , for $0 ≤ r ≤ 1$ . b) Compute its expected distance from the origin. c)Let the coordinates of the point be $(X, Y )$ . Determine the marginal p.d.f. of $X$ . Are $X$ and $Y$ independent? I did the part a) using geometry that the area of the circle with a radius of $r$ is divided by the area of the unit circle, such that $$P(R\leq r)=\frac{\pi r^2}{\pi\cdot 1^2}=r^2$$ Part b) is attempted to solve by differentiating the cdf, such that $$f(r)=\frac{d}{dr}r^2=2r,\hspace{3mm} E(R)=\int_{0}^1r\times 2r\,dr=\frac{2}{3}.$$ But this result does not seem to be right... And I do not know about part c) A simulation was done using python to visualize this distribution, and it gives image like this. Why are the points concentrated near the central area? from scipy.stats import uniform import matplotlib.pyplot as plt import math   r = uniform.rvs(scale =1,size=5000) pi = 3.14159265359 theta = uniform.rvs(scale =2*pi,size=5000) x = [] y = [] for i in range (5000):     x.append(r[i]*math.cos(theta[i]) )     y.append(r[i]*math.sin(theta[i]) ) fig=plt.figure() ax=fig.add_axes([0,0,2,3]) ax.scatter(x, y)```","a) A point is uniformly chosen in the unit disk . Find the probability that its   distance from the origin is less than , for . b) Compute its expected distance from the origin. c)Let the coordinates of the point be . Determine the marginal p.d.f. of . Are and independent? I did the part a) using geometry that the area of the circle with a radius of is divided by the area of the unit circle, such that Part b) is attempted to solve by differentiating the cdf, such that But this result does not seem to be right... And I do not know about part c) A simulation was done using python to visualize this distribution, and it gives image like this. Why are the points concentrated near the central area? from scipy.stats import uniform import matplotlib.pyplot as plt import math   r = uniform.rvs(scale =1,size=5000) pi = 3.14159265359 theta = uniform.rvs(scale =2*pi,size=5000) x = [] y = [] for i in range (5000):     x.append(r[i]*math.cos(theta[i]) )     y.append(r[i]*math.sin(theta[i]) ) fig=plt.figure() ax=fig.add_axes([0,0,2,3]) ax.scatter(x, y)```","0 ≤ x^2 + y^2 ≤ 1 r 0 ≤ r ≤ 1 (X, Y ) X X Y r P(R\leq r)=\frac{\pi r^2}{\pi\cdot 1^2}=r^2 f(r)=\frac{d}{dr}r^2=2r,\hspace{3mm} E(R)=\int_{0}^1r\times 2r\,dr=\frac{2}{3}.","['probability', 'probability-distributions', 'independence', 'geometric-probability']"
94,Intuition of $ P( X = a) $ for a continuous random variable?,Intuition of  for a continuous random variable?, P( X = a) ,"Let $(\Omega, {\cal B}, P )$ be a probability space, $( \mathbb{R}, {\cal R} )$ the usual  measurable space of reals and its Borel $\sigma$- algebra, and $X : \Omega \rightarrow \mathbb{R}$ a random variable. The meaning of $ P( X = a) $ is intuitive when $X$ is a discrete random variable, because it's the definition of the probability mass function. I am not sure if my question makes sense, but how should I think of $ P( X = a) $ when $X$ is a continuous random variable?","Let $(\Omega, {\cal B}, P )$ be a probability space, $( \mathbb{R}, {\cal R} )$ the usual  measurable space of reals and its Borel $\sigma$- algebra, and $X : \Omega \rightarrow \mathbb{R}$ a random variable. The meaning of $ P( X = a) $ is intuitive when $X$ is a discrete random variable, because it's the definition of the probability mass function. I am not sure if my question makes sense, but how should I think of $ P( X = a) $ when $X$ is a continuous random variable?",,"['probability', 'probability-theory', 'continuity', 'random-variables', 'intuition']"
95,Probability of drawing a pair of brown socks,Probability of drawing a pair of brown socks,,"You have a drawer with $6$ loose blue socks, and $10$ loose brown socks. If you grab two socks from the drawer in the dark (random draw), what is the probability that you draw a brown pair? I have $\frac{5}{8}=\frac{10}{16}=.625$.","You have a drawer with $6$ loose blue socks, and $10$ loose brown socks. If you grab two socks from the drawer in the dark (random draw), what is the probability that you draw a brown pair? I have $\frac{5}{8}=\frac{10}{16}=.625$.",,['probability']
96,What is the probability that the special ball is chosen?,What is the probability that the special ball is chosen?,,"I know this question is already posted here , but I doubting my own solution which is I know is wrong. It is quite basic, but I want to learn probability from scratch, so I am posting my question. Question: An urn contains $n$ balls, one of which is special. If $k$ of these balls are withdrawn one at a time, with each selection being equally likely to be any of the balls that remain at the time, what is the probability that the special ball is chosen? My approach: The number of ways in which we can select $k$ balls from a set of $n$ balls equals: $$\binom{n}{k}$$ Out of these $ \binom{n}{k}$, we have a single special ball . As such, the required probability equals: $$\frac {1} {\binom{n}{k}}$$ What am I doing wrong?","I know this question is already posted here , but I doubting my own solution which is I know is wrong. It is quite basic, but I want to learn probability from scratch, so I am posting my question. Question: An urn contains $n$ balls, one of which is special. If $k$ of these balls are withdrawn one at a time, with each selection being equally likely to be any of the balls that remain at the time, what is the probability that the special ball is chosen? My approach: The number of ways in which we can select $k$ balls from a set of $n$ balls equals: $$\binom{n}{k}$$ Out of these $ \binom{n}{k}$, we have a single special ball . As such, the required probability equals: $$\frac {1} {\binom{n}{k}}$$ What am I doing wrong?",,['probability']
97,"Probability that a $(n, \frac12)$-binomial random variable is even",Probability that a -binomial random variable is even,"(n, \frac12)","Let $X$ be a $(n, \frac12)$-Binomial RV. Show that $X$ is even with probability $\frac12$.","Let $X$ be a $(n, \frac12)$-Binomial RV. Show that $X$ is even with probability $\frac12$.",,['probability']
98,Probability of a single trial within binomial experiment vs. stand-alone bernoulli experiment,Probability of a single trial within binomial experiment vs. stand-alone bernoulli experiment,,"When a flip a coin several times, each throw is independent from another. In other words, my coin does not know what came out previous time. So, each next flip the result is unpredictable and random. Now, suppose I flipped a fair coin three times and got each time a head (head-head-head). Intuitively, the head cannot come out “head” all the time, so I can expect the on fourth throw to have higher chances to get finally a tail. But each flip is an independent event - the coin does not know what came out last time. How this paradox is resolved? Many thanks!","When a flip a coin several times, each throw is independent from another. In other words, my coin does not know what came out previous time. So, each next flip the result is unpredictable and random. Now, suppose I flipped a fair coin three times and got each time a head (head-head-head). Intuitively, the head cannot come out “head” all the time, so I can expect the on fourth throw to have higher chances to get finally a tail. But each flip is an independent event - the coin does not know what came out last time. How this paradox is resolved? Many thanks!",,"['probability', 'binomial-distribution', 'paradoxes']"
99,Fano's inequality explained intuitively?,Fano's inequality explained intuitively?,,"I am now reading through a book to understand Fano's inequality, but I remember my professor explaining it in a certain way that made it seem so logical. I will go office hours as soon as possible, but for now can someone please try to explain to me Fano's inequality but not through math just in a ""logical"" way that makes sense. Thanks a lot!!","I am now reading through a book to understand Fano's inequality, but I remember my professor explaining it in a certain way that made it seem so logical. I will go office hours as soon as possible, but for now can someone please try to explain to me Fano's inequality but not through math just in a ""logical"" way that makes sense. Thanks a lot!!",,"['probability', 'information-theory']"
