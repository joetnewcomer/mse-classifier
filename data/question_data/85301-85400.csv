,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Infer $Tf=\sum_{n=1}^\infty (f,f_n) f_n$ from frame condition.",Infer  from frame condition.,"Tf=\sum_{n=1}^\infty (f,f_n) f_n","A sequence of distinct vectors $\{f_1,f_2,...\}$ belonging to a separable Hilbert space $H$ is said to be a Frame if there exist positive contants $A$, $B$ such that, for $A<B$ and for all $f\in H$ ( frame condition ): $$A\|f\|^2\leq\sum_{n=1}^\infty |(f,f_n)|^2\leq B \|f\|^2 \ \ \ \ (\ast)$$ An operator $T$ on $H$ is said ""frame operator"" of frame $\{f_1,f_2,...\}$, if $$Tf=\sum_{n=1}^\infty (f,f_n) f_n \ \ \ \ \ \ (\ast\ast)$$ By this the $(\ast)$ becomes, $$A\|f\|^2\leq (Tf,f)\leq B \|f\|^2 \ \ \ \ \ (\ast\ast\ast)$$ My question is the following. In general, isn't possible infer $(\ast\ast)$ by $(\ast\ast\ast)$ but... are there some conditions for which it is possible? Maybe for $f$ in a dense subset of $H$?","A sequence of distinct vectors $\{f_1,f_2,...\}$ belonging to a separable Hilbert space $H$ is said to be a Frame if there exist positive contants $A$, $B$ such that, for $A<B$ and for all $f\in H$ ( frame condition ): $$A\|f\|^2\leq\sum_{n=1}^\infty |(f,f_n)|^2\leq B \|f\|^2 \ \ \ \ (\ast)$$ An operator $T$ on $H$ is said ""frame operator"" of frame $\{f_1,f_2,...\}$, if $$Tf=\sum_{n=1}^\infty (f,f_n) f_n \ \ \ \ \ \ (\ast\ast)$$ By this the $(\ast)$ becomes, $$A\|f\|^2\leq (Tf,f)\leq B \|f\|^2 \ \ \ \ \ (\ast\ast\ast)$$ My question is the following. In general, isn't possible infer $(\ast\ast)$ by $(\ast\ast\ast)$ but... are there some conditions for which it is possible? Maybe for $f$ in a dense subset of $H$?",,"['functional-analysis', 'operator-theory']"
1,"Trace theorems for arbitrary differentiability $k$, with embedding constants under control as $k\to\infty$","Trace theorems for arbitrary differentiability , with embedding constants under control as",k k\to\infty,"The usual trace theorem (with non-optimal exponents, but I don't care for those at the moment) says that $$ W^{1,p}(\Omega)\hookrightarrow L^p(\partial\Omega) $$  for Lipschitz domains. When $\Omega=\mathbb{R}^n_+$ is an upper half space, we even have $$ W^{k,p}(\mathbb{R}^n_+)\hookrightarrow W^{k-1,p}(\mathbb{R}^{n-1})\quad\forall k\in\mathbb{N} $$ and even more, the embedding constant can be chosen independent of $k$! However, I have already problems controlling the embedding constants in the case where $\Gamma\subset\partial\Omega\subset\mathbb{R}^n$ is (part of) a graph of a polynomial. It is easily shown that $$ \|f\|_{W^{k-1,p}(\Gamma)}\leq C(k)\|f\|_{W^{k,p}(\Omega)} $$ for finite $C(k)$, (works for any smooth boundary) and one way to bound $C(k)$ is: If $\phi\colon U\subset\mathbb{R}^{n-1}\to\Gamma$ is a polynomial of degree $m$ that parametrizes $\Gamma$, then we have to check that $f\circ \phi\in W^{k-1,p}(U)$. All boils down (by chain rule) to showing $$\|\sum_{|\alpha|=0}^{k-1}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C(k)\|f\|_{W^{k,p}(\Omega)}$$ where $H_{\alpha,\phi}$ is a sum of products of powers of derivatives of $\phi$ up to order $|\alpha|$. Using that all derivatives of $\phi$ vanish for $|\alpha|\geq m$, I can show with very crude arguments that $\|H_{\alpha,\phi}\|_{L^\infty(U)}\leq C_0^{|\alpha|^{C(n,m)}}$ , and conclude by applying the usual trace theorem (say with embedding constant $C_1$) to all $D^\alpha f$ and the $L^\infty$ bound to $H_{\alpha,\phi}$: $$\|\sum_{|\alpha|=0}^{k}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C_0^{k^{C(n,m)}}\sum_{|\alpha|=0}^{k-1}\|((D^{\alpha}f)\circ\phi) \|_{L^p(U)}\\ \leq C_0^{k^{C(n,m)}}C_1\sum_{|\alpha|=0}^{k-1}\|f\|_{W^{|\alpha|+1,p}(\Omega)}\\ \leq C_1 k^dC_0^{k^{C(n,m)}}\|f\|_{W^{k,p}(\Omega)} $$ This should also work if $\Gamma$ is a rigid transformation of a (part of a ) graph of a polynomial (by IFT); however, then the calculations get even messier. My questions: Are there better bounds on $C(k)$ than the one I described? Are there bounds for more general classes of boundaries than piecewise polynomial boundaries? And related to all this: is there a more intrinsic way (than using parametrizations) that allows one to capture statements like ""the boundary has only $m$ non-vanishing derivatives"" (true for pieceiwse polynomials), or ""all derivatives of the boundary are uniformly bounded"" (think of a piecewise $sin(x)$ boundary in $R^2$) Intuitively, I would think a ball is just as good as a piecewise polynomial boundary, but I fail to completely to show any bound in this case.","The usual trace theorem (with non-optimal exponents, but I don't care for those at the moment) says that $$ W^{1,p}(\Omega)\hookrightarrow L^p(\partial\Omega) $$  for Lipschitz domains. When $\Omega=\mathbb{R}^n_+$ is an upper half space, we even have $$ W^{k,p}(\mathbb{R}^n_+)\hookrightarrow W^{k-1,p}(\mathbb{R}^{n-1})\quad\forall k\in\mathbb{N} $$ and even more, the embedding constant can be chosen independent of $k$! However, I have already problems controlling the embedding constants in the case where $\Gamma\subset\partial\Omega\subset\mathbb{R}^n$ is (part of) a graph of a polynomial. It is easily shown that $$ \|f\|_{W^{k-1,p}(\Gamma)}\leq C(k)\|f\|_{W^{k,p}(\Omega)} $$ for finite $C(k)$, (works for any smooth boundary) and one way to bound $C(k)$ is: If $\phi\colon U\subset\mathbb{R}^{n-1}\to\Gamma$ is a polynomial of degree $m$ that parametrizes $\Gamma$, then we have to check that $f\circ \phi\in W^{k-1,p}(U)$. All boils down (by chain rule) to showing $$\|\sum_{|\alpha|=0}^{k-1}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C(k)\|f\|_{W^{k,p}(\Omega)}$$ where $H_{\alpha,\phi}$ is a sum of products of powers of derivatives of $\phi$ up to order $|\alpha|$. Using that all derivatives of $\phi$ vanish for $|\alpha|\geq m$, I can show with very crude arguments that $\|H_{\alpha,\phi}\|_{L^\infty(U)}\leq C_0^{|\alpha|^{C(n,m)}}$ , and conclude by applying the usual trace theorem (say with embedding constant $C_1$) to all $D^\alpha f$ and the $L^\infty$ bound to $H_{\alpha,\phi}$: $$\|\sum_{|\alpha|=0}^{k}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C_0^{k^{C(n,m)}}\sum_{|\alpha|=0}^{k-1}\|((D^{\alpha}f)\circ\phi) \|_{L^p(U)}\\ \leq C_0^{k^{C(n,m)}}C_1\sum_{|\alpha|=0}^{k-1}\|f\|_{W^{|\alpha|+1,p}(\Omega)}\\ \leq C_1 k^dC_0^{k^{C(n,m)}}\|f\|_{W^{k,p}(\Omega)} $$ This should also work if $\Gamma$ is a rigid transformation of a (part of a ) graph of a polynomial (by IFT); however, then the calculations get even messier. My questions: Are there better bounds on $C(k)$ than the one I described? Are there bounds for more general classes of boundaries than piecewise polynomial boundaries? And related to all this: is there a more intrinsic way (than using parametrizations) that allows one to capture statements like ""the boundary has only $m$ non-vanishing derivatives"" (true for pieceiwse polynomials), or ""all derivatives of the boundary are uniformly bounded"" (think of a piecewise $sin(x)$ boundary in $R^2$) Intuitively, I would think a ball is just as good as a piecewise polynomial boundary, but I fail to completely to show any bound in this case.",,"['functional-analysis', 'reference-request', 'sobolev-spaces']"
2,Intuition of weak star convergence.,Intuition of weak star convergence.,,"Given $\Omega=(0,1)$, consider the following sequence $$ v_j(x)\colon=\begin{cases} \;a &\text{if }jx-\lfloor jx \rfloor\le\theta\\ \;b &\text{otherwise} \end{cases} $$ where $a,b\in\mathbb{R}$ and $\theta\in(0,1)$. Then the $L^\infty-\text{weak}^\ast$ limit of $v_j$ is $\theta a+(1-\theta)b$. Is there any intuitive explanation of why this is the weak$^\ast$ limit of $v_j(x)$?","Given $\Omega=(0,1)$, consider the following sequence $$ v_j(x)\colon=\begin{cases} \;a &\text{if }jx-\lfloor jx \rfloor\le\theta\\ \;b &\text{otherwise} \end{cases} $$ where $a,b\in\mathbb{R}$ and $\theta\in(0,1)$. Then the $L^\infty-\text{weak}^\ast$ limit of $v_j$ is $\theta a+(1-\theta)b$. Is there any intuitive explanation of why this is the weak$^\ast$ limit of $v_j(x)$?",,"['real-analysis', 'functional-analysis', 'calculus-of-variations']"
3,Applications of Banach-Alaoglu theorem in the theory of distributions?,Applications of Banach-Alaoglu theorem in the theory of distributions?,,"Are there some interesting applications of Banach-Alaoglu theorem in the theory of distributions? The theorem provides compact subsets in the $w^*$-topology, so distributions seem a great place for applications of this theorem. (I would imagine a typical application to start with  a sequence $T_1\supset T_2\supset T_3\supset\dots$ of non-empty compact subsets of $\mathscr D'$, with the compactness of $T_n$ coming from the Banach-Alaoglu theorem; this would imply that $\bigcap_n T_n\neq\emptyset$. However, I don't know how to get an interesting sequence $T_n$, i.e. such that the fact $\bigcap_n T_n\neq\emptyset$ is non-trivial and interesting.)","Are there some interesting applications of Banach-Alaoglu theorem in the theory of distributions? The theorem provides compact subsets in the $w^*$-topology, so distributions seem a great place for applications of this theorem. (I would imagine a typical application to start with  a sequence $T_1\supset T_2\supset T_3\supset\dots$ of non-empty compact subsets of $\mathscr D'$, with the compactness of $T_n$ coming from the Banach-Alaoglu theorem; this would imply that $\bigcap_n T_n\neq\emptyset$. However, I don't know how to get an interesting sequence $T_n$, i.e. such that the fact $\bigcap_n T_n\neq\emptyset$ is non-trivial and interesting.)",,"['functional-analysis', 'distribution-theory']"
4,One more AC equivalence question,One more AC equivalence question,,"Is ""Every vector space admits a norm"" weaker than AC? I know that the statement follows from ""Every vector space has a basis"", which is equivalent to AC.","Is ""Every vector space admits a norm"" weaker than AC? I know that the statement follows from ""Every vector space has a basis"", which is equivalent to AC.",,"['functional-analysis', 'normed-spaces', 'axiom-of-choice']"
5,Is it possible to construct a 1-D linear differential operator with given spectrum $0\leq\lambda_0\leq \lambda_1\leq\dots\leq\lambda_n\le\dots$?,Is it possible to construct a 1-D linear differential operator with given spectrum ?,0\leq\lambda_0\leq \lambda_1\leq\dots\leq\lambda_n\le\dots,"Suppose one is given with a sequence $S$ of non-negative real numbers $0\leq\lambda_0\leq \lambda_1\leq\dots\leq \lambda_n\leq\dots$. Under what conditions on $S$, is it possible to construct a Linear differential operator $D$ on the space of square integrable functions on the real line, such that the eigenvalue spectrum of $D$ is given by $S$ ? Is there any way to explicitly construct such an operator ?","Suppose one is given with a sequence $S$ of non-negative real numbers $0\leq\lambda_0\leq \lambda_1\leq\dots\leq \lambda_n\leq\dots$. Under what conditions on $S$, is it possible to construct a Linear differential operator $D$ on the space of square integrable functions on the real line, such that the eigenvalue spectrum of $D$ is given by $S$ ? Is there any way to explicitly construct such an operator ?",,"['functional-analysis', 'differential-operators']"
6,Approximation of $L^2$ function by smooth functions on a manifold,Approximation of  function by smooth functions on a manifold,L^2,"Let $M$ be a $C^2$ compact Riemannian manifold with boundary. Suppose $f \in L^2(M)$ is such that $0 \leq f \leq 1$. Is it possible to find $f_n \in C^\infty(M)$ such that $0 \leq f_n \leq 1$ for all $n$ and $f_n \to f$ in $L^2(M)$? If $M$ were a bounded set this I could prove via convolution and mollification. Is it possible to do this on a manifold too?  But I don't know if I can just patch it all together. Also, does my manifold need to be $C^\infty$ to make sense of the smooth functions on it?","Let $M$ be a $C^2$ compact Riemannian manifold with boundary. Suppose $f \in L^2(M)$ is such that $0 \leq f \leq 1$. Is it possible to find $f_n \in C^\infty(M)$ such that $0 \leq f_n \leq 1$ for all $n$ and $f_n \to f$ in $L^2(M)$? If $M$ were a bounded set this I could prove via convolution and mollification. Is it possible to do this on a manifold too?  But I don't know if I can just patch it all together. Also, does my manifold need to be $C^\infty$ to make sense of the smooth functions on it?",,"['functional-analysis', 'convergence-divergence', 'manifolds', 'lp-spaces']"
7,The dual of the Banach space $C(\Omega)$,The dual of the Banach space,C(\Omega),"It is well-known that the dual of the Banach space $C([0,1])$, i.e. the space of all continuous functions on the interval, is the space of all functions of bounded variation on the interval, $BV([0,1])$.  If $\Omega$ is a compact subset of $\mathbb{R}^n$, What is the dual of $C(\Omega)$?  How about the dual of all absolutely continuous functions on $\Omega$, $AC(\Omega)$?  What do the inner products look like?","It is well-known that the dual of the Banach space $C([0,1])$, i.e. the space of all continuous functions on the interval, is the space of all functions of bounded variation on the interval, $BV([0,1])$.  If $\Omega$ is a compact subset of $\mathbb{R}^n$, What is the dual of $C(\Omega)$?  How about the dual of all absolutely continuous functions on $\Omega$, $AC(\Omega)$?  What do the inner products look like?",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
8,Two Body Schrodinger Equations,Two Body Schrodinger Equations,,"I have a question involving the eigenvalues of a two-body Schrodinger equation. Let $$H=-\frac{1}{2m}\Delta_{x_1}-\frac{1}{2m}\Delta_{x_2}+\frac{e^2}{|{{x_1}-{x_2}}|}$$ over the Hilbert space $L^2(\mathbb{R}^6)$ be self adjoint on the domain $D(H)$ ($D(H)$ would be $H^2(\mathbb{R}^6)$ would it not?). Then, let $H_f$ be the same operator restricted to the domain $D(H)\cap\mathcal{H}_f$ where $\mathcal{H_f}=\{\varphi\in L^2(\mathbb{R}^6)|\varphi(x_1,x_2)=-\varphi(x_2,x_1)\}$, i.e., $\mathcal{H_f}$ is the fermionic subspace. I want to show that $inf \sigma(H) \leq inf \sigma(H_f)$. Ideas: 1. I have shown before that $H$ has eigenvalues below zero using Birman-Schwinger. If I could somehow show that $H_f$ only has non-negative eigenvalues, this would work. 2. Use the Rayliegh-Ritz principle, i.e. $$inf\sigma(H)\leq \frac{<\psi,H\psi>}{||\psi||}$$ for all $\psi\in D(H)$ (since D(H) is self-adjoint). I'm not sure exactly how to use this though, because $H_f$ is not self adjoint, and I need it as an upper bound, not a lower. Any help is appreciated!","I have a question involving the eigenvalues of a two-body Schrodinger equation. Let $$H=-\frac{1}{2m}\Delta_{x_1}-\frac{1}{2m}\Delta_{x_2}+\frac{e^2}{|{{x_1}-{x_2}}|}$$ over the Hilbert space $L^2(\mathbb{R}^6)$ be self adjoint on the domain $D(H)$ ($D(H)$ would be $H^2(\mathbb{R}^6)$ would it not?). Then, let $H_f$ be the same operator restricted to the domain $D(H)\cap\mathcal{H}_f$ where $\mathcal{H_f}=\{\varphi\in L^2(\mathbb{R}^6)|\varphi(x_1,x_2)=-\varphi(x_2,x_1)\}$, i.e., $\mathcal{H_f}$ is the fermionic subspace. I want to show that $inf \sigma(H) \leq inf \sigma(H_f)$. Ideas: 1. I have shown before that $H$ has eigenvalues below zero using Birman-Schwinger. If I could somehow show that $H_f$ only has non-negative eigenvalues, this would work. 2. Use the Rayliegh-Ritz principle, i.e. $$inf\sigma(H)\leq \frac{<\psi,H\psi>}{||\psi||}$$ for all $\psi\in D(H)$ (since D(H) is self-adjoint). I'm not sure exactly how to use this though, because $H_f$ is not self adjoint, and I need it as an upper bound, not a lower. Any help is appreciated!",,"['functional-analysis', 'operator-theory', 'quantum-mechanics']"
9,"Two Hilbert spaces $V \subset H$, a basis for both spaces?","Two Hilbert spaces , a basis for both spaces?",V \subset H,"Let $V \subset H$ be a pair of Hilbert spaces (with different inner products). The embedding is continuous and dense, and both spaces are separable. Is it always the case that one can I find a sequence $\{v_n\}$ such that $v_n$ are an orthogonal basis in $V$ and they are also an orthonormal basis in $H$? (Eg. if $V=H^1_0$ and $H=L^2$ then the eigenfunctions of the Laplacian can be $v_n$). If $V \subset H$ is a compact embedding, I think this is related to Hilbert-Schmidt theory. But what operator do I use to apply the theory?","Let $V \subset H$ be a pair of Hilbert spaces (with different inner products). The embedding is continuous and dense, and both spaces are separable. Is it always the case that one can I find a sequence $\{v_n\}$ such that $v_n$ are an orthogonal basis in $V$ and they are also an orthonormal basis in $H$? (Eg. if $V=H^1_0$ and $H=L^2$ then the eigenfunctions of the Laplacian can be $v_n$). If $V \subset H$ is a compact embedding, I think this is related to Hilbert-Schmidt theory. But what operator do I use to apply the theory?",,"['functional-analysis', 'hilbert-spaces']"
10,Closest fixed point to a convex set,Closest fixed point to a convex set,,"Consider the compact convex sets $Y \subset X \subset \mathbb{R}^n$, and a Lipschitz continuous function $f : X \rightarrow X$. Assume that $f$ has multiple fixed points. (From Brouwer's theorem , $f$ has at least one fixed point in $X$.) Under reasonable assumptions on $f$, which fixed point iteration converge to the fixed point of $f$ that is (among) the closest to $Y$? (Partial/Approximate Answers and/or Hints are also OK!)","Consider the compact convex sets $Y \subset X \subset \mathbb{R}^n$, and a Lipschitz continuous function $f : X \rightarrow X$. Assume that $f$ has multiple fixed points. (From Brouwer's theorem , $f$ has at least one fixed point in $X$.) Under reasonable assumptions on $f$, which fixed point iteration converge to the fixed point of $f$ that is (among) the closest to $Y$? (Partial/Approximate Answers and/or Hints are also OK!)",,"['analysis', 'functional-analysis', 'operator-theory', 'convex-analysis', 'fixed-point-theorems']"
11,Weak*-complemented subspaces of $\ell_\infty$,Weak*-complemented subspaces of,\ell_\infty,"Consider $\ell_\infty$ as $\ell_1^*$. Let $X$ be an infinite-dimensional complemented subspace of $\ell_\infty$ (in partiuclar, $X$ is isomorphic to $\ell_\infty$). Can we find a further subspace $Y\subset X$ which is still isomorphic to $\ell_\infty$ but it is also range of a weak*-weak* continuous projection on $\ell_\infty$?","Consider $\ell_\infty$ as $\ell_1^*$. Let $X$ be an infinite-dimensional complemented subspace of $\ell_\infty$ (in partiuclar, $X$ is isomorphic to $\ell_\infty$). Can we find a further subspace $Y\subset X$ which is still isomorphic to $\ell_\infty$ but it is also range of a weak*-weak* continuous projection on $\ell_\infty$?",,"['functional-analysis', 'banach-spaces']"
12,Weakening Sobolev coefficient in an elliptic estimate.,Weakening Sobolev coefficient in an elliptic estimate.,,"One of the classical estimates for Sobolev norms and elliptic operators is the following: let $L$ be an elliptic operator of order $l$, then there is some $C > 0$ such that for all $u \in H^{s+l}$ ($C$ probably depends on $s$) such that we have an estimate of the form $$\|u\|_{s+l} \leq C(\|u\|_s + \|Lu\|_s)$$ My question is whether the coefficient $s$ on $\|u\|_s$ can be weakened over compact Riemannian manifolds. The question is motivated by a result that we can find a pseudo-differential operator $S$ of order $-l$ such that $SL - I = K$ continuously maps compactly supported distributions to smooth functions. This would seem to imply we can prove a form of the above estimate by writing $$u = SLu - Ku$$ Then using the continuity of inclusions $H^r \to \mathcal{E}' = \mathcal{D}'$ (compactness of $M$ key here) and $C^\infty \to H^{s+l}$ to bound the latter term, and the operator norm of $S$ to bound the former. This seems disturbing to me as it would imply we just need any information on a Sobolev norm of $u$, not the $s$ norm in particular.","One of the classical estimates for Sobolev norms and elliptic operators is the following: let $L$ be an elliptic operator of order $l$, then there is some $C > 0$ such that for all $u \in H^{s+l}$ ($C$ probably depends on $s$) such that we have an estimate of the form $$\|u\|_{s+l} \leq C(\|u\|_s + \|Lu\|_s)$$ My question is whether the coefficient $s$ on $\|u\|_s$ can be weakened over compact Riemannian manifolds. The question is motivated by a result that we can find a pseudo-differential operator $S$ of order $-l$ such that $SL - I = K$ continuously maps compactly supported distributions to smooth functions. This would seem to imply we can prove a form of the above estimate by writing $$u = SLu - Ku$$ Then using the continuity of inclusions $H^r \to \mathcal{E}' = \mathcal{D}'$ (compactness of $M$ key here) and $C^\infty \to H^{s+l}$ to bound the latter term, and the operator norm of $S$ to bound the former. This seems disturbing to me as it would imply we just need any information on a Sobolev norm of $u$, not the $s$ norm in particular.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'riemannian-geometry', 'elliptic-operators']"
13,Properties shared by equivalent norms.,Properties shared by equivalent norms.,,"I am interested in knowing about ""geometric"" properties shared by equivalent norms on a Banach space. Here I mean ""geometric"" as opposed to topological, and probably in particular with reference to the intrinsic geometry of the unit ball or sphere. Apologies for the vagueness. A pointer towards a reference will do just fine. I can give a somewhat vague example of what I mean: Where $\{e_n\}$ represents some orthonormal basis in $L^2[0,1]$, the norms defined by the closed convex hulls of $\{e_n\}$ and $\{\frac{1}{n} e_n \}$ are inequivalent. This in-equivalence is represented geometrically by the vanishing of the diameter of the latter unit ball ""in the limit,"" though that is really nothing more than a rephrasing of the definition of the equivalence of norms. I guess one could rephrase my question in the following way: what geometric difference between unit balls arise in infinite dimensional normed vector spaces that are not apparent (from the perspective of norm equivalence) in the finite case? Are there factors other than the decay of the norm of an arbitrary sequence points on the sphere? Having written this out, I now realize that the condition of being in-equivalent is (analytically) precisely that of the existence of a sequence of elements that eventually break the inequality $(c || f||_1 \leq ||f||_2 \leq C ||f||_1$) regardless of the constants used. Are there other useful to know norm-equivalence invariants?","I am interested in knowing about ""geometric"" properties shared by equivalent norms on a Banach space. Here I mean ""geometric"" as opposed to topological, and probably in particular with reference to the intrinsic geometry of the unit ball or sphere. Apologies for the vagueness. A pointer towards a reference will do just fine. I can give a somewhat vague example of what I mean: Where $\{e_n\}$ represents some orthonormal basis in $L^2[0,1]$, the norms defined by the closed convex hulls of $\{e_n\}$ and $\{\frac{1}{n} e_n \}$ are inequivalent. This in-equivalence is represented geometrically by the vanishing of the diameter of the latter unit ball ""in the limit,"" though that is really nothing more than a rephrasing of the definition of the equivalence of norms. I guess one could rephrase my question in the following way: what geometric difference between unit balls arise in infinite dimensional normed vector spaces that are not apparent (from the perspective of norm equivalence) in the finite case? Are there factors other than the decay of the norm of an arbitrary sequence points on the sphere? Having written this out, I now realize that the condition of being in-equivalent is (analytically) precisely that of the existence of a sequence of elements that eventually break the inequality $(c || f||_1 \leq ||f||_2 \leq C ||f||_1$) regardless of the constants used. Are there other useful to know norm-equivalence invariants?",,"['functional-analysis', 'reference-request', 'banach-spaces']"
14,Sequence of measurable functions converging a.e. to a measurable function?,Sequence of measurable functions converging a.e. to a measurable function?,,"I understand if $(X, \Sigma, \mu)$ is a measure space, and we have a sequence of measurable functions $f_{n}$ such that $\lim \limits_{n \to \infty} f_{n}$ exists almost everywhere d$\mu$ (a.e. d$\mu$), then it's equal to a measurable function almost everywhere.  The way this is constructed is to first call the set where the limit doesn't exist $N$ (and this clearly has measure $0$).  Then, we: Define a new sequence  $$\tilde{f_{n}} = \begin{cases} f_{n}(x) & x \not \in N \\ 0 & x \in N \end{cases}$$ and we can think of $\tilde{f_{n}}$ as $f_{n} - f_{n}\chi_{N}$, where $\chi_{N}$ is the characteristic function of the set $N$.  Clearly, $\tilde{f_{n}}$ is measurable since it is the sum of measurable functions.  And so the limit of the sequence $\{ \tilde{f_{n}} \}$ is defined everywhere and measurable.  Specifically, $$\lim \limits_{n \to \infty} \tilde{f_{n}} = \begin{cases} \lim \limits_{n \to \infty} f_{n} & x \not \in N \\ 0 & x \in N. \end{cases} $$ So we have a measurable function which is equal to $\lim \limits_{n \to \infty} f_{n}$ except on $N$.  But my question is: $\lim \limits_{n \to \infty} f_{n}$ is only defined on $X \setminus N$, which means its domain is $X \setminus N$.  Why do we say this is equal to $\lim \limits_{n \to \infty} \tilde{f_{n}}$ almost everywhere if they have different domains?  Does it make sense to talk about them not being equal on $N$ if one of them isn't even defined on $N$? I guess my question is:  If $X \subseteq X'$, and $f : X \to Y$ and $g : X' \to Y$, suppose $f = g$ on $X$ (with $X' \setminus X$ having measure $0$).  Does the statement $f = g$ a.e. even make sense?  We can't compare then on $X' \setminus X$ to say they aren't equal on it because one of the functions isn't even defined on that set. Another question that has been spawned from this question is whether it makes sense to integrate a function over a set that is not in its domain.","I understand if $(X, \Sigma, \mu)$ is a measure space, and we have a sequence of measurable functions $f_{n}$ such that $\lim \limits_{n \to \infty} f_{n}$ exists almost everywhere d$\mu$ (a.e. d$\mu$), then it's equal to a measurable function almost everywhere.  The way this is constructed is to first call the set where the limit doesn't exist $N$ (and this clearly has measure $0$).  Then, we: Define a new sequence  $$\tilde{f_{n}} = \begin{cases} f_{n}(x) & x \not \in N \\ 0 & x \in N \end{cases}$$ and we can think of $\tilde{f_{n}}$ as $f_{n} - f_{n}\chi_{N}$, where $\chi_{N}$ is the characteristic function of the set $N$.  Clearly, $\tilde{f_{n}}$ is measurable since it is the sum of measurable functions.  And so the limit of the sequence $\{ \tilde{f_{n}} \}$ is defined everywhere and measurable.  Specifically, $$\lim \limits_{n \to \infty} \tilde{f_{n}} = \begin{cases} \lim \limits_{n \to \infty} f_{n} & x \not \in N \\ 0 & x \in N. \end{cases} $$ So we have a measurable function which is equal to $\lim \limits_{n \to \infty} f_{n}$ except on $N$.  But my question is: $\lim \limits_{n \to \infty} f_{n}$ is only defined on $X \setminus N$, which means its domain is $X \setminus N$.  Why do we say this is equal to $\lim \limits_{n \to \infty} \tilde{f_{n}}$ almost everywhere if they have different domains?  Does it make sense to talk about them not being equal on $N$ if one of them isn't even defined on $N$? I guess my question is:  If $X \subseteq X'$, and $f : X \to Y$ and $g : X' \to Y$, suppose $f = g$ on $X$ (with $X' \setminus X$ having measure $0$).  Does the statement $f = g$ a.e. even make sense?  We can't compare then on $X' \setminus X$ to say they aren't equal on it because one of the functions isn't even defined on that set. Another question that has been spawned from this question is whether it makes sense to integrate a function over a set that is not in its domain.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
15,Sobolev spaces and using monotone convergence theorem (don't understand a paper),Sobolev spaces and using monotone convergence theorem (don't understand a paper),,"I'm reading this paper . In it there the following argument (see page 240). Firstly, what precisely does the author mean by the displayed equation after 66? The PDE in (65) only holds weakly.. $\frac{\partial b(\overline{v}_n)}{\partial t}$ is only in $H^1(0,T;H^{-1})\cap L^\infty(0,T;L^s)$. He just integrates it in time.. I don't follow. Secondly, I am lost with the spaces when he says that $\int_0^T \overline{v}_n(s)\;ds$ is a Cauchy sequence in the space $L^\infty(0,T;W^{1,r}_0)$. And then he uses the monotone convergence theorem to say that $\overline{v}_n$ convreges strongly in $L^1(\Omega \times (0,T))$ to some $\overline{v}$. Again a different space. Any explanation appreciated.","I'm reading this paper . In it there the following argument (see page 240). Firstly, what precisely does the author mean by the displayed equation after 66? The PDE in (65) only holds weakly.. $\frac{\partial b(\overline{v}_n)}{\partial t}$ is only in $H^1(0,T;H^{-1})\cap L^\infty(0,T;L^s)$. He just integrates it in time.. I don't follow. Secondly, I am lost with the spaces when he says that $\int_0^T \overline{v}_n(s)\;ds$ is a Cauchy sequence in the space $L^\infty(0,T;W^{1,r}_0)$. And then he uses the monotone convergence theorem to say that $\overline{v}_n$ convreges strongly in $L^1(\Omega \times (0,T))$ to some $\overline{v}$. Again a different space. Any explanation appreciated.",,"['functional-analysis', 'partial-differential-equations', 'convergence-divergence', 'sobolev-spaces', 'bochner-spaces']"
16,Positive Operators: Definition?,Positive Operators: Definition?,,Definitions Given an operator algebra $\mathcal{A}\subseteq\mathcal{B}(\mathcal{H})$ with $1\in\mathcal{A}$ Consider selfadjoint operators $A=A^*\in\mathcal{A}$. Define positive elements by: $$A\geq0:\iff\sigma(A)\geq0$$ and positive operators by: $$A\geq0:\iff\mathcal{W}(A)\geq0$$ Problem Do the numerical range and spectrum coincide:   $$A=A^*:\quad\langle\sigma(A)\rangle=\overline{\mathcal{W}(A)}$$ Attempt For bounded operators one has at least: $$\|A\|<\infty:\quad\sigma(A)\subseteq\overline{\mathcal{W}(A)}$$ So any positive operator is a positive element; but what about the converse?,Definitions Given an operator algebra $\mathcal{A}\subseteq\mathcal{B}(\mathcal{H})$ with $1\in\mathcal{A}$ Consider selfadjoint operators $A=A^*\in\mathcal{A}$. Define positive elements by: $$A\geq0:\iff\sigma(A)\geq0$$ and positive operators by: $$A\geq0:\iff\mathcal{W}(A)\geq0$$ Problem Do the numerical range and spectrum coincide:   $$A=A^*:\quad\langle\sigma(A)\rangle=\overline{\mathcal{W}(A)}$$ Attempt For bounded operators one has at least: $$\|A\|<\infty:\quad\sigma(A)\subseteq\overline{\mathcal{W}(A)}$$ So any positive operator is a positive element; but what about the converse?,,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras', 'banach-algebras']"
17,On maximal ideal spaces of a banach algebra,On maximal ideal spaces of a banach algebra,,"I am reading this article on maximal ideal spaces and there is this part that I don't quite understand very well, hope you guys can help me out. ""Let $M(A)$ denote the maximal ideal space of a commutative Banach algebra $A$. If $C$ is a Banach subalgebra of $A$ and $\lambda\in M(C)$, then the set $M_{\lambda}(A):=\{\xi\in M(A): \xi|_C=\lambda\}$ is called the fiber of $M(A)$ over $\lambda$. Hence for every Banach algebra $A\subset L^{\infty}(\mathbb{R})$ with $M(C(\dot{\mathbb{R}})\cap A)=\dot{\mathbb{R}}$ and every $\lambda\in\dot{\mathbb{R}},$ the fiber $M_{\lambda}(A)$ denotes the set of all characters (multiplicative linear functionals) of $A$ that annihilate the set $\{f\in C(\dot{\mathbb{R}})\cap A:f(\lambda)=0\}$.  Where $\dot{\mathbb{R}}$ is the compactification by one point of the real line $\mathbb{R}$"" The parts that I don't understand is where it say that the maximal ideal space of an algebra can be equal to $\dot{\mathbb{R}}$, (quote...with $M(C(\dot{\mathbb{R}})\cap A)=\dot{\mathbb{R}}$), How is this possible? And how do you prove that  the fiber $M_{\lambda}(A)$ denotes the set of all characters (multiplicative linear functionals) of $A$ that annihilate the set $\{f\in C(\dot{\mathbb{R}})\cap A:f(\lambda)=0\}$?.","I am reading this article on maximal ideal spaces and there is this part that I don't quite understand very well, hope you guys can help me out. ""Let $M(A)$ denote the maximal ideal space of a commutative Banach algebra $A$. If $C$ is a Banach subalgebra of $A$ and $\lambda\in M(C)$, then the set $M_{\lambda}(A):=\{\xi\in M(A): \xi|_C=\lambda\}$ is called the fiber of $M(A)$ over $\lambda$. Hence for every Banach algebra $A\subset L^{\infty}(\mathbb{R})$ with $M(C(\dot{\mathbb{R}})\cap A)=\dot{\mathbb{R}}$ and every $\lambda\in\dot{\mathbb{R}},$ the fiber $M_{\lambda}(A)$ denotes the set of all characters (multiplicative linear functionals) of $A$ that annihilate the set $\{f\in C(\dot{\mathbb{R}})\cap A:f(\lambda)=0\}$.  Where $\dot{\mathbb{R}}$ is the compactification by one point of the real line $\mathbb{R}$"" The parts that I don't understand is where it say that the maximal ideal space of an algebra can be equal to $\dot{\mathbb{R}}$, (quote...with $M(C(\dot{\mathbb{R}})\cap A)=\dot{\mathbb{R}}$), How is this possible? And how do you prove that  the fiber $M_{\lambda}(A)$ denotes the set of all characters (multiplicative linear functionals) of $A$ that annihilate the set $\{f\in C(\dot{\mathbb{R}})\cap A:f(\lambda)=0\}$?.",,"['functional-analysis', 'ideals', 'banach-algebras']"
18,Understanding the duals of $L^{\infty}(K)$ and $C(K)$ and weak-* compactness,Understanding the duals of  and  and weak-* compactness,L^{\infty}(K) C(K),"Let $(K\subset \mathbb{R}^n,\mathcal{B}(K),\lambda)$ be a measure space, where $\lambda$ is the Lebesgue measure and $K$ is compact. According to Wikipedia (with adapted notation), The dual Banach space $L^\infty(K)^*$ is isomorphic to the space of finitely additive signed measures on $K$ that are absolutely continuous with respect to $\lambda$. On the other hand, the Riesz-Markov theorem tells us that the dual of the (non-dense) subspace $C(K)\subset L^\infty(K)$ is the space of regular countably additive measures. Is the former included in the latter, for $K$ compact? What is the difference of the former and $L^1$? In any case, by the Hahn-Banach theorem, since we equip both $C(K)$ and $L^\infty$ with the same ($esssup$) norm, shouldn't we have an inclusion in the other way, i.e. shouldn't the dual of $L^\infty(K)$ be larger than that of $C(K)$? (Because every cts. functional on $C(K)$ can be extended to $L^\infty(K)$) Our professor today said that by shrinking our attention from $L^\infty$ to $C$, the dual grows and we can find weak-* convergent subsequences in the duals (we found that $L^1\subset (L^\infty)^*$ doesn't always have weak-* convergent subsequences...). I know that the formal reason is Banach-Alaoglu and $C$ unlike $L^\infty$ is separable, but I'm curious for what is wrong about my professors statement about shrinking the space and growing the dual and what truth is in it.","Let $(K\subset \mathbb{R}^n,\mathcal{B}(K),\lambda)$ be a measure space, where $\lambda$ is the Lebesgue measure and $K$ is compact. According to Wikipedia (with adapted notation), The dual Banach space $L^\infty(K)^*$ is isomorphic to the space of finitely additive signed measures on $K$ that are absolutely continuous with respect to $\lambda$. On the other hand, the Riesz-Markov theorem tells us that the dual of the (non-dense) subspace $C(K)\subset L^\infty(K)$ is the space of regular countably additive measures. Is the former included in the latter, for $K$ compact? What is the difference of the former and $L^1$? In any case, by the Hahn-Banach theorem, since we equip both $C(K)$ and $L^\infty$ with the same ($esssup$) norm, shouldn't we have an inclusion in the other way, i.e. shouldn't the dual of $L^\infty(K)$ be larger than that of $C(K)$? (Because every cts. functional on $C(K)$ can be extended to $L^\infty(K)$) Our professor today said that by shrinking our attention from $L^\infty$ to $C$, the dual grows and we can find weak-* convergent subsequences in the duals (we found that $L^1\subset (L^\infty)^*$ doesn't always have weak-* convergent subsequences...). I know that the formal reason is Banach-Alaoglu and $C$ unlike $L^\infty$ is separable, but I'm curious for what is wrong about my professors statement about shrinking the space and growing the dual and what truth is in it.",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'weak-convergence', 'duality-theorems']"
19,Relationship between weak and strong closure,Relationship between weak and strong closure,,"Let $E \subset X$ be a convex subset of a normed space. I want to show that the weak closure of $E$ denoted by $\overline{E}_{w}$ is the same as the strong closure of $E$ denoted by $\overline{E}$. By Hahn-Banach, $\overline{E}_{w} \subset \overline{E}$. Is it true that $\overline{E} \subset \overline{E}_{w}$? My idea is: Let $p$ be a limit point of $E$. Then there exists $p_{n} \rightarrow p$ strongly. Therefore $p_{n} \rightarrow p$ weakly. But does this imply that $p \in \overline{E}_{w}$? If the weak topology was first countable, this would but true, but the weak topology is not, so I can't just say $p$ is a limit point by just looking at sequences. Is there another way to see this?","Let $E \subset X$ be a convex subset of a normed space. I want to show that the weak closure of $E$ denoted by $\overline{E}_{w}$ is the same as the strong closure of $E$ denoted by $\overline{E}$. By Hahn-Banach, $\overline{E}_{w} \subset \overline{E}$. Is it true that $\overline{E} \subset \overline{E}_{w}$? My idea is: Let $p$ be a limit point of $E$. Then there exists $p_{n} \rightarrow p$ strongly. Therefore $p_{n} \rightarrow p$ weakly. But does this imply that $p \in \overline{E}_{w}$? If the weak topology was first countable, this would but true, but the weak topology is not, so I can't just say $p$ is a limit point by just looking at sequences. Is there another way to see this?",,"['real-analysis', 'analysis', 'functional-analysis']"
20,Duality pairing and difference with inner product in Hilbert spaces,Duality pairing and difference with inner product in Hilbert spaces,,"My question is an extension to the post How is the acting of $H^{-1}$ on $H^1_0$ defined? . Here duality pairings were discussed and even given explicit examples. Let $U$ and $V$ be Hilbert spaces such that $U\subset V$, with inner products $(\cdot , \cdot)_{U}$, $(\cdot , \cdot)_{V}$. Can we give explicit examples to understand the difference between dual pairings $\langle\cdot , \cdot\rangle_{U}$, $\langle\cdot , \cdot\rangle_{V}$ and inner products? and when is it true that for $u\in U$ and $v\in V$ $$ \langle u,v\rangle_U = (u,v)_U $$ Thanks in advance.","My question is an extension to the post How is the acting of $H^{-1}$ on $H^1_0$ defined? . Here duality pairings were discussed and even given explicit examples. Let $U$ and $V$ be Hilbert spaces such that $U\subset V$, with inner products $(\cdot , \cdot)_{U}$, $(\cdot , \cdot)_{V}$. Can we give explicit examples to understand the difference between dual pairings $\langle\cdot , \cdot\rangle_{U}$, $\langle\cdot , \cdot\rangle_{V}$ and inner products? and when is it true that for $u\in U$ and $v\in V$ $$ \langle u,v\rangle_U = (u,v)_U $$ Thanks in advance.",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
21,Gradient on Sobolev spaces,Gradient on Sobolev spaces,,"Suppose I have a function $\Phi \in L_p(\Omega)$ and $\nabla\Phi \in W^{-\alpha}_p(\Omega)$, $1<p<\infty$ and where $\Omega\subset\mathbb{R}^n$ is a bounded domain. Can I conclude that $\Phi\in W^{-\alpha+1}_p(\Omega)$ if $\alpha >0$? I have found results for $\alpha=1$ and for $\alpha <0$ (i.e. the gradient is contained in a Sobolev space with positive smoothness parameter). I would be thankfull for answers!","Suppose I have a function $\Phi \in L_p(\Omega)$ and $\nabla\Phi \in W^{-\alpha}_p(\Omega)$, $1<p<\infty$ and where $\Omega\subset\mathbb{R}^n$ is a bounded domain. Can I conclude that $\Phi\in W^{-\alpha+1}_p(\Omega)$ if $\alpha >0$? I have found results for $\alpha=1$ and for $\alpha <0$ (i.e. the gradient is contained in a Sobolev space with positive smoothness parameter). I would be thankfull for answers!",,"['analysis', 'functional-analysis', 'sobolev-spaces', 'lp-spaces']"
22,Inverse of bounded self adjoint operator on HS is self adjoint?,Inverse of bounded self adjoint operator on HS is self adjoint?,,"Let $A=A^{*}$ be a bounded self adjoint operator on a Hilbert space $\mathcal{H}$ with Range Ran$(A) = D$ dense in $\mathcal{H}$. $A$ is injective, since Ran$(B) \perp ker(B^{*}) = ker(B)$. So $A^{-1}: D \to \mathcal{H}$ is a densely defined operator and has adjoint $(A^{-1})^{*}$, defined on $D^{*}$. My intuition tells me that the inverse should be self adjoint and I know the proof for the case that $A$ is bijective: $\langle (A^{-1})^{*} A^{*} \varphi, \psi \rangle = \langle A^{*} \varphi, A^{-1} \psi \rangle = \langle \varphi, A(A^{*})^{-1} \psi \rangle = \langle \varphi, \psi \rangle$. In my case this is only true for $\psi \in D$. In the same way one gets $A^{*}(A^{-1})^{*} =$ Id. So I have $(A^{*})^{-1} = (A^{-1})^{*}$ on $D$. But how can I show know that $D=D^{*}$? Any ideas?","Let $A=A^{*}$ be a bounded self adjoint operator on a Hilbert space $\mathcal{H}$ with Range Ran$(A) = D$ dense in $\mathcal{H}$. $A$ is injective, since Ran$(B) \perp ker(B^{*}) = ker(B)$. So $A^{-1}: D \to \mathcal{H}$ is a densely defined operator and has adjoint $(A^{-1})^{*}$, defined on $D^{*}$. My intuition tells me that the inverse should be self adjoint and I know the proof for the case that $A$ is bijective: $\langle (A^{-1})^{*} A^{*} \varphi, \psi \rangle = \langle A^{*} \varphi, A^{-1} \psi \rangle = \langle \varphi, A(A^{*})^{-1} \psi \rangle = \langle \varphi, \psi \rangle$. In my case this is only true for $\psi \in D$. In the same way one gets $A^{*}(A^{-1})^{*} =$ Id. So I have $(A^{*})^{-1} = (A^{-1})^{*}$ on $D$. But how can I show know that $D=D^{*}$? Any ideas?",,"['functional-analysis', 'spectral-theory']"
23,Is this proof good? Identifying extreme points of the unit ball in a function space,Is this proof good? Identifying extreme points of the unit ball in a function space,,"I want to prove: If $K$ is compact $T_2$ then the extreme points of the unit ball of $C(K)$ are precisely the functions $f\in C(K)$ such that $|f(k)|=1$ for all $k\in K$. Here is my proof: Can someone say of this this right or where you see mistakes in the argumentation? $\impliedby$: We first want to show that all $f\in C(K)$ with $\left|f(k)\right|=1$ for all $k\in K$ are extreme points. Thus suppose we have functions $f,g:K\rightarrow\left[-1,1\right]$ and $\alpha\in\left(0,1\right)$ such that $1=\alpha f(k)+(1-\alpha)g(k)$ for all $k\in K$ then we must have $1=\left|f\right|=\left|g\right|$. $\implies$: Let $f$ be an extreme point of the unit ball $B$. Then we must have $\left\|f\right\|_{\infty}=1$, thus there exists $x_0\in K$ such that $\left|f(x_0)\right|=1$. Suppose $\left|f(x_0)\right|=1$, then we want to prove that $\left|f(k)\right|=1$ for all $k\in K$. To sake a contradiction suppose we can find $k_0\in int(K)$ such that $0<\left|f(k_0)\right|<1$ and define $\epsilon>0$ to be $\epsilon=1-\left|f(k_0)\right|>0$. Now notice that $f$ in continuous thus we may find a $\delta>0$ such that $B(x_0,\delta)\subseteq int(K)$ and $1-\frac{\epsilon}{2}<f(x)<1-\frac{\epsilon}{2}$ since $x\in B(x_0,\delta)$. Now we can apply the Urysohn's Lemma to conclude that there exists a function $h:K\rightarrow\left[-1,1\right]$ such that $h(k_0)=1$ and $h(x)=0$ if $x\notin B(x_0,\delta)$. Now we can get two new functions $f_1=f+\frac{\epsilon}{2}h$ and $f_2=f-\frac{\epsilon}{2}h$ in the unit ball. Notice that $f=\frac{1}{2}(f_1+f_2)$ therefore $f$ can not be an extreme point. Thus $\left|f(k)\right|=1$ for all $k\in K$. Thank you for remarks.","I want to prove: If $K$ is compact $T_2$ then the extreme points of the unit ball of $C(K)$ are precisely the functions $f\in C(K)$ such that $|f(k)|=1$ for all $k\in K$. Here is my proof: Can someone say of this this right or where you see mistakes in the argumentation? $\impliedby$: We first want to show that all $f\in C(K)$ with $\left|f(k)\right|=1$ for all $k\in K$ are extreme points. Thus suppose we have functions $f,g:K\rightarrow\left[-1,1\right]$ and $\alpha\in\left(0,1\right)$ such that $1=\alpha f(k)+(1-\alpha)g(k)$ for all $k\in K$ then we must have $1=\left|f\right|=\left|g\right|$. $\implies$: Let $f$ be an extreme point of the unit ball $B$. Then we must have $\left\|f\right\|_{\infty}=1$, thus there exists $x_0\in K$ such that $\left|f(x_0)\right|=1$. Suppose $\left|f(x_0)\right|=1$, then we want to prove that $\left|f(k)\right|=1$ for all $k\in K$. To sake a contradiction suppose we can find $k_0\in int(K)$ such that $0<\left|f(k_0)\right|<1$ and define $\epsilon>0$ to be $\epsilon=1-\left|f(k_0)\right|>0$. Now notice that $f$ in continuous thus we may find a $\delta>0$ such that $B(x_0,\delta)\subseteq int(K)$ and $1-\frac{\epsilon}{2}<f(x)<1-\frac{\epsilon}{2}$ since $x\in B(x_0,\delta)$. Now we can apply the Urysohn's Lemma to conclude that there exists a function $h:K\rightarrow\left[-1,1\right]$ such that $h(k_0)=1$ and $h(x)=0$ if $x\notin B(x_0,\delta)$. Now we can get two new functions $f_1=f+\frac{\epsilon}{2}h$ and $f_2=f-\frac{\epsilon}{2}h$ in the unit ball. Notice that $f=\frac{1}{2}(f_1+f_2)$ therefore $f$ can not be an extreme point. Thus $\left|f(k)\right|=1$ for all $k\in K$. Thank you for remarks.",,"['functional-analysis', 'proof-verification']"
24,"Explicit form of the homeomorphism between $C[0,1]$ and $C[0,1]\setminus 0$",Explicit form of the homeomorphism between  and,"C[0,1] C[0,1]\setminus 0","How to construct the homeomorphism between $C[0,1]$ and $C[0,1]\setminus\{\theta\}$ in the explicit form? Here, as usual, $C[0,1]$ is the Banach space of continuous functions $f:[0,1]\to\mathbb{R}$ with the norm $$ \|f\|=\max\limits_{x\in[0,1]}|f(x)|; $$ and $\theta(x)\equiv 0$ $\forall x\in[0,1]$.","How to construct the homeomorphism between $C[0,1]$ and $C[0,1]\setminus\{\theta\}$ in the explicit form? Here, as usual, $C[0,1]$ is the Banach space of continuous functions $f:[0,1]\to\mathbb{R}$ with the norm $$ \|f\|=\max\limits_{x\in[0,1]}|f(x)|; $$ and $\theta(x)\equiv 0$ $\forall x\in[0,1]$.",,['functional-analysis']
25,How can you prove that a function has no closed form integral?,How can you prove that a function has no closed form integral?,,"In the past, I've come across statements  along the lines of ""function $f(x)$ has no closed form integral"", which I assume means that there is no combination of the operations: addition/subtraction multiplication/division raising to powers and roots trigonometric functions exponential functions logarithmic functions which when differentiated gives the function $f(x)$ . I've heard this said about the function $f(x) = x^x$ , for example. What sort of techniques are used to prove statements like this? What is this branch of mathematics called? Merged with "" How to prove that some functions don't have a primitive "" by Ismael : Sometimes we are told that some functions like $\dfrac{\sin(x)}{x}$ don't have an indefinite integral, or that it can't be expressed in term of other simple functions. I wonder how we can prove that kind of assertion?","In the past, I've come across statements  along the lines of ""function has no closed form integral"", which I assume means that there is no combination of the operations: addition/subtraction multiplication/division raising to powers and roots trigonometric functions exponential functions logarithmic functions which when differentiated gives the function . I've heard this said about the function , for example. What sort of techniques are used to prove statements like this? What is this branch of mathematics called? Merged with "" How to prove that some functions don't have a primitive "" by Ismael : Sometimes we are told that some functions like don't have an indefinite integral, or that it can't be expressed in term of other simple functions. I wonder how we can prove that kind of assertion?",f(x) f(x) f(x) = x^x \dfrac{\sin(x)}{x},"['real-analysis', 'calculus', 'integration', 'faq', 'differential-algebra']"
26,strictly positive elements in $C^*$-algebra,strictly positive elements in -algebra,C^*,"Let $A$ be a $C^*\text{-algebra}$ and $A_+$ denote the positive elements. An element $a\in A_+$ is called strictly positive if $\overline{aAa}=A$. Want to find the following: a)What are the strictly positive elements of $C_0(\Omega)$ where $\Omega$ is locally compact Hausdorff space, and $C_0(\Omega)$ is the space of continuous complex valued functions that vanishes at $\infty$. b)If $A$ is unital, then $a\in A_+$ is strictly positive iff $a$ is invertible. c)if $(e_n)$ is an approximate identity of $A$, then $a:=\sum_{n=}^{\infty}\frac{1}{2^n}e_n$is strictly positive. What I tried and know: a) I know that positive elements in this space are functions with positive images, and thus, strictly positive elements are functions with positive images and now real root. is this correct? and how can I show that the positive elements are these kind of functions. b) I figures out that if $a$ in invertible then $a$ is strictly positive, but no idea how to do the other direction. c)I did this but using another characterization of strictly positive elements but want to do it with this one, and I don't know how. Thank you for your help.","Let $A$ be a $C^*\text{-algebra}$ and $A_+$ denote the positive elements. An element $a\in A_+$ is called strictly positive if $\overline{aAa}=A$. Want to find the following: a)What are the strictly positive elements of $C_0(\Omega)$ where $\Omega$ is locally compact Hausdorff space, and $C_0(\Omega)$ is the space of continuous complex valued functions that vanishes at $\infty$. b)If $A$ is unital, then $a\in A_+$ is strictly positive iff $a$ is invertible. c)if $(e_n)$ is an approximate identity of $A$, then $a:=\sum_{n=}^{\infty}\frac{1}{2^n}e_n$is strictly positive. What I tried and know: a) I know that positive elements in this space are functions with positive images, and thus, strictly positive elements are functions with positive images and now real root. is this correct? and how can I show that the positive elements are these kind of functions. b) I figures out that if $a$ in invertible then $a$ is strictly positive, but no idea how to do the other direction. c)I did this but using another characterization of strictly positive elements but want to do it with this one, and I don't know how. Thank you for your help.",,"['banach-algebras', 'c-star-algebras']"
27,$e^{iBt}e^{-iAt}$converges as operator norm,converges as operator norm,e^{iBt}e^{-iAt},"Let $A,B$ be self-adjoint operators on $H$,then we can define the strong limit $$ W=s-\lim_{t\to+\infty}e^{iBt}e^{-iAt} $$ If the limit exists, then W is called the wave operator, which is fundamental in the scattering theory. My question here is that if instead, we consider the operator norm above,then what can be said about it ? I was told that the the limit exists if and only if $A=B$, but I don't know how to prove this statement.","Let $A,B$ be self-adjoint operators on $H$,then we can define the strong limit $$ W=s-\lim_{t\to+\infty}e^{iBt}e^{-iAt} $$ If the limit exists, then W is called the wave operator, which is fundamental in the scattering theory. My question here is that if instead, we consider the operator norm above,then what can be said about it ? I was told that the the limit exists if and only if $A=B$, but I don't know how to prove this statement.",,['functional-analysis']
28,Isomorphism between spaces of sections.,Isomorphism between spaces of sections.,,"Let $M$ be a compact manifold and let $E_i \xrightarrow{\Large \pi_i} M$, $i = 1, 2$, be two (real or complex) vector bundles of the same rank $k$ over $M$. Assume we have metrics $g_1, g_2$ on $E_1$, $E_2$ respectively. We can then form Banach spaces $$\mathcal{B}_i = \Gamma^0(E_i) = \{ s : M \xrightarrow{\large C^0} E_i~\vert~ \pi_i \circ s = \mathrm{Id}_M \}$$ of continuous sections, equipped with the sup norm: $$\|s\|^i_0 = \sup_{x \in M} g_i\big(s(x), s(x)\big).$$ Question : under which conditions are $\mathcal{B}_1$ and $\mathcal{B}_2$ isomorphic as topological vector spaces ? My thoughts : I started naively trying to prove that any two such spaces are isomorphic, to see if I could find any obstruction. This is equivalent to proving that any such $\Gamma^0(E)$ is isomorphic to $C^0(M, \mathbb{R}^k)$, that is, sections of the trivial bundle. I can construct maps from $\Gamma^0(E)$ to $C^0(M, \mathbb{R}^k)$ and vice-versa by choosing a trivializing cover $\big(U_i\big)_{i = 1}^m$ for $E$ and a partition of unity $\big(\rho_i\big)_{i = 1}^m$ associated to it and then decomposing/gluing a section in the obvious way. But these maps don't seem to be inverses of each other in general, although under some special conditions they are. I can give more details later, if required. Thanks in advance!","Let $M$ be a compact manifold and let $E_i \xrightarrow{\Large \pi_i} M$, $i = 1, 2$, be two (real or complex) vector bundles of the same rank $k$ over $M$. Assume we have metrics $g_1, g_2$ on $E_1$, $E_2$ respectively. We can then form Banach spaces $$\mathcal{B}_i = \Gamma^0(E_i) = \{ s : M \xrightarrow{\large C^0} E_i~\vert~ \pi_i \circ s = \mathrm{Id}_M \}$$ of continuous sections, equipped with the sup norm: $$\|s\|^i_0 = \sup_{x \in M} g_i\big(s(x), s(x)\big).$$ Question : under which conditions are $\mathcal{B}_1$ and $\mathcal{B}_2$ isomorphic as topological vector spaces ? My thoughts : I started naively trying to prove that any two such spaces are isomorphic, to see if I could find any obstruction. This is equivalent to proving that any such $\Gamma^0(E)$ is isomorphic to $C^0(M, \mathbb{R}^k)$, that is, sections of the trivial bundle. I can construct maps from $\Gamma^0(E)$ to $C^0(M, \mathbb{R}^k)$ and vice-versa by choosing a trivializing cover $\big(U_i\big)_{i = 1}^m$ for $E$ and a partition of unity $\big(\rho_i\big)_{i = 1}^m$ associated to it and then decomposing/gluing a section in the obvious way. But these maps don't seem to be inverses of each other in general, although under some special conditions they are. I can give more details later, if required. Thanks in advance!",,"['functional-analysis', 'differential-geometry', 'topological-vector-spaces', 'vector-bundles']"
29,Question about the Spectral Theorem for Self Adjoint Operators and Eigenvalues,Question about the Spectral Theorem for Self Adjoint Operators and Eigenvalues,,"I have been working through Teschl's book ""Mathematical Methods in Quantum Mechanics with Applications to Schrodinger Operators"" and I am stuck on a problem in Chapter 3. I am trying to prove that if $A$ is a self adjoint operator and $\lambda$ is an eigenvalue for $A$, then using the Borel functional calculus $\chi_{\{\lambda\}}(A)$ is just projection onto the $\lambda$ eigenspace of $A.$ I can prove that $\chi_{\{\lambda\}}(A)\psi = \psi$ when $\psi$ is a normalized eigenvector, so all I need to show is that it takes the orthogonal complement of the eigenspace to $0.$ I have reduced this to proving that for any $\phi,$ the vector $ \chi_{\{\lambda\}}(A)\phi$ is an eigenvector with eigenvalue $\lambda,$ but I'm not sure how to prove this. (Note that $ \chi_{\{\lambda\}}(A)\phi$ may be $0,$ and in fact will be whenever $\phi$ is orthogonal to the $\lambda$ eigenspace even though I can't yet prove that.)","I have been working through Teschl's book ""Mathematical Methods in Quantum Mechanics with Applications to Schrodinger Operators"" and I am stuck on a problem in Chapter 3. I am trying to prove that if $A$ is a self adjoint operator and $\lambda$ is an eigenvalue for $A$, then using the Borel functional calculus $\chi_{\{\lambda\}}(A)$ is just projection onto the $\lambda$ eigenspace of $A.$ I can prove that $\chi_{\{\lambda\}}(A)\psi = \psi$ when $\psi$ is a normalized eigenvector, so all I need to show is that it takes the orthogonal complement of the eigenspace to $0.$ I have reduced this to proving that for any $\phi,$ the vector $ \chi_{\{\lambda\}}(A)\phi$ is an eigenvector with eigenvalue $\lambda,$ but I'm not sure how to prove this. (Note that $ \chi_{\{\lambda\}}(A)\phi$ may be $0,$ and in fact will be whenever $\phi$ is orthogonal to the $\lambda$ eigenspace even though I can't yet prove that.)",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
30,getting the fundamental solution of Laplace's equation from the heat kernel,getting the fundamental solution of Laplace's equation from the heat kernel,,"Since Laplace's equation is related to the steady state of heat flow problems, I'm guessing that there is a way to get from the heat kernel to the fundamental solution of Laplace's equation by letting $t\to \infty$ and renormalizing somehow. Is this correct? If so, in the $\mathbb{R}^2$ case how do I get from $(1)$ to $(2)$? $$(1)\hspace5ex\Phi(x,t)=\frac{1}{4\pi t}e^{-\frac{|x|^2}{4t}}$$ $$(2)\hspace5ex\Phi(x)=-\frac{1}{2\pi }\text{Log}|x|$$","Since Laplace's equation is related to the steady state of heat flow problems, I'm guessing that there is a way to get from the heat kernel to the fundamental solution of Laplace's equation by letting $t\to \infty$ and renormalizing somehow. Is this correct? If so, in the $\mathbb{R}^2$ case how do I get from $(1)$ to $(2)$? $$(1)\hspace5ex\Phi(x,t)=\frac{1}{4\pi t}e^{-\frac{|x|^2}{4t}}$$ $$(2)\hspace5ex\Phi(x)=-\frac{1}{2\pi }\text{Log}|x|$$",,"['functional-analysis', 'stochastic-processes', 'partial-differential-equations']"
31,Question about proof of Hahn-Banach lemma,Question about proof of Hahn-Banach lemma,,"I think they do something unnecessary in my notes in the proof of the following lemma: The idea of the proof is to partially order the set $\Sigma$ of pairs $(X_i, f_i)$ where $X_i$ is a linear subspace of $X$ containing $Y$ and $f_i : X_i \to \mathbb R$ is a linear map. Then apply Zorn to get a maximal element $(X^\prime, f^\prime)$ and show that $X^\prime = X$. The way to do this is by contradiction. One assumes that there is a point $z$ in $X \setminus X^\prime$ and then defines a $g$ such that $(X^{\prime \prime}, g) $ where $X^{\prime \prime} $ is spanned by $z$ and $X^\prime$ is strictly  greater than $(X^\prime, f^\prime)$ in $\Sigma$, contradicting maximality. In the notes we define $g$ in terms of $f^\prime$: If $z \in X \setminus X^\prime$ and $y \in X^{\prime \prime}$ then $g(y) = f^\prime(x^\prime) + \lambda c$ for some $\lambda$ and some $x^\prime \in X^\prime$. All we need to show is $g \leq p$. And this is the part where I think they are doing something superfluous. They pick $c \in [A,B]$ (see below) where I think it's enough to pick $c \leq B$: If those pngs aren't readable then you can also find the proof in these notes at the very start of chapter 6. Thanks for your help.","I think they do something unnecessary in my notes in the proof of the following lemma: The idea of the proof is to partially order the set $\Sigma$ of pairs $(X_i, f_i)$ where $X_i$ is a linear subspace of $X$ containing $Y$ and $f_i : X_i \to \mathbb R$ is a linear map. Then apply Zorn to get a maximal element $(X^\prime, f^\prime)$ and show that $X^\prime = X$. The way to do this is by contradiction. One assumes that there is a point $z$ in $X \setminus X^\prime$ and then defines a $g$ such that $(X^{\prime \prime}, g) $ where $X^{\prime \prime} $ is spanned by $z$ and $X^\prime$ is strictly  greater than $(X^\prime, f^\prime)$ in $\Sigma$, contradicting maximality. In the notes we define $g$ in terms of $f^\prime$: If $z \in X \setminus X^\prime$ and $y \in X^{\prime \prime}$ then $g(y) = f^\prime(x^\prime) + \lambda c$ for some $\lambda$ and some $x^\prime \in X^\prime$. All we need to show is $g \leq p$. And this is the part where I think they are doing something superfluous. They pick $c \in [A,B]$ (see below) where I think it's enough to pick $c \leq B$: If those pngs aren't readable then you can also find the proof in these notes at the very start of chapter 6. Thanks for your help.",,['functional-analysis']
32,Direct limits of completely positive maps on $C^*$-algebras vs. operator systems,Direct limits of completely positive maps on -algebras vs. operator systems,C^*,"I believe I've heard, as part of the ""lore,"" that the category (operator systems, completely positive maps) has direct limits, whereas the category ($C^*$-algebras, completely positive maps) does not.  Or perhaps one had to tweak the morphisms by specifying ""unital"" or ""contractive"".  I would appreciate either a reference that discusses direct limits of completely positive maps on some category or other, or an example (if indeed one exists) of a direct system of ($C^*$-algebras, CP maps) where the limit object is not a $C^*$-algebra?  My best guess would be to iterate a CP map from some $A$ to itself, but I don't really know what the limit would look like.","I believe I've heard, as part of the ""lore,"" that the category (operator systems, completely positive maps) has direct limits, whereas the category ($C^*$-algebras, completely positive maps) does not.  Or perhaps one had to tweak the morphisms by specifying ""unital"" or ""contractive"".  I would appreciate either a reference that discusses direct limits of completely positive maps on some category or other, or an example (if indeed one exists) of a direct system of ($C^*$-algebras, CP maps) where the limit object is not a $C^*$-algebra?  My best guess would be to iterate a CP map from some $A$ to itself, but I don't really know what the limit would look like.",,"['reference-request', 'functional-analysis', 'operator-algebras']"
33,Convergence of integrals of Radon measures,Convergence of integrals of Radon measures,,"Let $X$ be a locally compact Hausdorff space and let $\mu_n$ be a sequence of bounded variation Radon measures on $X$ such that $\int_X g \;d\mu_n \rightarrow \int_X g \;d\mu$ for each $g \in C_0 (X)$ (ie. $g(x) \rightarrow 0$ as $x \rightarrow \infty$ in the one-point compactification of $X$) and $|\mu_n|(X) \rightarrow |\mu|(X)$. Must it hold that $\int_X f \;d\mu_n \rightarrow \int_X f \;d\mu$ for each bounded continuous function $f$, even if $f$ does not tend to zero at infinity?","Let $X$ be a locally compact Hausdorff space and let $\mu_n$ be a sequence of bounded variation Radon measures on $X$ such that $\int_X g \;d\mu_n \rightarrow \int_X g \;d\mu$ for each $g \in C_0 (X)$ (ie. $g(x) \rightarrow 0$ as $x \rightarrow \infty$ in the one-point compactification of $X$) and $|\mu_n|(X) \rightarrow |\mu|(X)$. Must it hold that $\int_X f \;d\mu_n \rightarrow \int_X f \;d\mu$ for each bounded continuous function $f$, even if $f$ does not tend to zero at infinity?",,"['measure-theory', 'functional-analysis']"
34,"Why in uniformly convex Banach space every non empty, closed, convex subset contains a unique element of smallest norm?","Why in uniformly convex Banach space every non empty, closed, convex subset contains a unique element of smallest norm?",,"In Hilbert space every non empty, closed, convex subset contains a unique element of smallest norm. Why is that true also in Banach space which is uniformly convex? (normed space which is uniformly convex is a space in which for all sequences $\{x_n\}$, $\{y_n\}$ s.t $||x_n||,||y_n||\leq 1$ exists: if $\lim_n||x_n+y_n||=2$ then  $\lim_n||x_n-y_n||=0$.) I thought of defining $a=\inf\{||x|| : x\in X\}$, so exists a  sequence $\{x_n\}$ s.t $\lim_n||x_n||=\inf||x_n||=a$ and then to show that $\{x_n\}$ is a Cauchy sequence and it's limit is the element we are looking for, but i didn't manage to prove that it is Cauchy.","In Hilbert space every non empty, closed, convex subset contains a unique element of smallest norm. Why is that true also in Banach space which is uniformly convex? (normed space which is uniformly convex is a space in which for all sequences $\{x_n\}$, $\{y_n\}$ s.t $||x_n||,||y_n||\leq 1$ exists: if $\lim_n||x_n+y_n||=2$ then  $\lim_n||x_n-y_n||=0$.) I thought of defining $a=\inf\{||x|| : x\in X\}$, so exists a  sequence $\{x_n\}$ s.t $\lim_n||x_n||=\inf||x_n||=a$ and then to show that $\{x_n\}$ is a Cauchy sequence and it's limit is the element we are looking for, but i didn't manage to prove that it is Cauchy.",,['functional-analysis']
35,Linear isomorphisms with dense graph,Linear isomorphisms with dense graph,,"Is it true that for each infinite dimensional Banach space $X$ there exists a linear bijection $f: X \rightarrow X$ with a dense graph? A graph of $f$ it is the set $\Gamma(f):=\{(x, f(x)): x \in X \} \subset X \times X$. ($X\times X$ is a Banach space with natural addition and multiplication by scalars and norm defined by $\|(x,y)\|=\|x\|+\|y\|$ for $x,y \in X$.) It seems that it is true when $X$ is separable. Thanks.","Is it true that for each infinite dimensional Banach space $X$ there exists a linear bijection $f: X \rightarrow X$ with a dense graph? A graph of $f$ it is the set $\Gamma(f):=\{(x, f(x)): x \in X \} \subset X \times X$. ($X\times X$ is a Banach space with natural addition and multiplication by scalars and norm defined by $\|(x,y)\|=\|x\|+\|y\|$ for $x,y \in X$.) It seems that it is true when $X$ is separable. Thanks.",,"['functional-analysis', 'banach-spaces']"
36,Adjoint of multiplication operator on Sobolev space,Adjoint of multiplication operator on Sobolev space,,"This is sort of an idle question, and I'll admit I didn't think very hard about it. Let $H^1 = H^1(\mathbb{R}^n)$ be the Sobolev space with norm $||f||_{H^1}^2 = ||f||_{L^2(\mathbb{R}^n)}^2 + ||\nabla f||_{L^2(\mathbb{R}^n)}^2$.  Suppose $\psi \in C^1(\mathbb{R}^n)$ is a bounded function with bounded gradient.  Then the multiplication operator $Af = \psi f$ is a bounded operator on $H^1$ (with norm at most $\sqrt{||\psi||_\infty^2 + ||\nabla \psi ||_\infty^2}$ ). What is the adjoint of $A$? That is, given $g \in H^1$ we wish to find $h$ such that $$(\psi f, g) + (\nabla(\psi f),\nabla  g) = (f,h) + (\nabla f,\nabla h)$$ for all $f \in H^1$.  I tried some simple manipulations on this expression but didn't get anywhere.","This is sort of an idle question, and I'll admit I didn't think very hard about it. Let $H^1 = H^1(\mathbb{R}^n)$ be the Sobolev space with norm $||f||_{H^1}^2 = ||f||_{L^2(\mathbb{R}^n)}^2 + ||\nabla f||_{L^2(\mathbb{R}^n)}^2$.  Suppose $\psi \in C^1(\mathbb{R}^n)$ is a bounded function with bounded gradient.  Then the multiplication operator $Af = \psi f$ is a bounded operator on $H^1$ (with norm at most $\sqrt{||\psi||_\infty^2 + ||\nabla \psi ||_\infty^2}$ ). What is the adjoint of $A$? That is, given $g \in H^1$ we wish to find $h$ such that $$(\psi f, g) + (\nabla(\psi f),\nabla  g) = (f,h) + (\nabla f,\nabla h)$$ for all $f \in H^1$.  I tried some simple manipulations on this expression but didn't get anywhere.",,"['functional-analysis', 'sobolev-spaces']"
37,"Two ""different"" adjoints of exterior derivative on manifolds with boundary in the $L^2$-setting","Two ""different"" adjoints of exterior derivative on manifolds with boundary in the -setting",L^2,"The follow problem appears in the setting of $L^2$-differential forms on manifolds with boundary. An abstracted operator theoretic problem is given below. Suppose $M$ is a smooth Riemannian manifold with boundary. We have an inner product and the Hodge star on differential forms. $\langle \omega , \eta \rangle = \int_M \omega \wedge \star \eta$ We have the Cartan derivative $d$ as an unbounded operator, with its domain being suitably regular differential forms. For $\omega, \eta$ smooth and compactly supported we now have $\langle d\omega,\eta \rangle = \langle \omega, \delta \eta \rangle$ with $\delta := \star d \star$. Now, with algebraic properties of the exterior derivative, we can show more general for $\omega \in dom(d)$ and $\eta \in dom(\delta)$ $\int_M d\omega\wedge\star\eta = \int_M \omega\wedge\star \delta\eta + \int_{\partial M} \operatorname{Tr}\omega \wedge \star \operatorname{Tr}\eta$ so in general a trace term appears. In particular, $\delta$ is not the hermitian adjoint of $d$. We can fix this and define the unbounded operator $d^\ast$ with the same action as $\delta$ but smaller domain, namely $dom(d^\ast) = \{ \eta \in L^2\Lambda \mid \operatorname{Tr}\star\eta = 0 \}$ Assuming I have not committed any serious fallacies, now to my problem. This difference between $d^\ast$ and $\delta$ does not appear in the setting of manifolds with boundary, and literature on this and the $L^2$ exterior calculus is not as ubiquitous as literature on the fully smooth setting without boundary. However, both $d^\ast$ and $\delta$ are used. So, whereas $d^\ast$ is the adjoint, what is $\delta$? I am interested to understand this from a purely operator theoretic point of view (i.e. functional analysis). Of particular interst for me is whether the adjoint of a linear unbounded operator with respect to a pairing may be extended in a canonical way such that ""defects"" which disturb the adjointness-relation appear ( just as the trace terms above )?","The follow problem appears in the setting of $L^2$-differential forms on manifolds with boundary. An abstracted operator theoretic problem is given below. Suppose $M$ is a smooth Riemannian manifold with boundary. We have an inner product and the Hodge star on differential forms. $\langle \omega , \eta \rangle = \int_M \omega \wedge \star \eta$ We have the Cartan derivative $d$ as an unbounded operator, with its domain being suitably regular differential forms. For $\omega, \eta$ smooth and compactly supported we now have $\langle d\omega,\eta \rangle = \langle \omega, \delta \eta \rangle$ with $\delta := \star d \star$. Now, with algebraic properties of the exterior derivative, we can show more general for $\omega \in dom(d)$ and $\eta \in dom(\delta)$ $\int_M d\omega\wedge\star\eta = \int_M \omega\wedge\star \delta\eta + \int_{\partial M} \operatorname{Tr}\omega \wedge \star \operatorname{Tr}\eta$ so in general a trace term appears. In particular, $\delta$ is not the hermitian adjoint of $d$. We can fix this and define the unbounded operator $d^\ast$ with the same action as $\delta$ but smaller domain, namely $dom(d^\ast) = \{ \eta \in L^2\Lambda \mid \operatorname{Tr}\star\eta = 0 \}$ Assuming I have not committed any serious fallacies, now to my problem. This difference between $d^\ast$ and $\delta$ does not appear in the setting of manifolds with boundary, and literature on this and the $L^2$ exterior calculus is not as ubiquitous as literature on the fully smooth setting without boundary. However, both $d^\ast$ and $\delta$ are used. So, whereas $d^\ast$ is the adjoint, what is $\delta$? I am interested to understand this from a purely operator theoretic point of view (i.e. functional analysis). Of particular interst for me is whether the adjoint of a linear unbounded operator with respect to a pairing may be extended in a canonical way such that ""defects"" which disturb the adjointness-relation appear ( just as the trace terms above )?",,"['functional-analysis', 'operator-theory', 'differential-forms']"
38,Vector valued contraction,Vector valued contraction,,"I am familiar with the Banach Fixed Point Theorem and I have used it to prove existence and uniqueness of functional equations in Banach spaces like $C(X)$, the space of bounded continuous function $f:X\rightarrow \mathbb R$ with the sup norm $||f||=\sup_{x\in X}|f(x)|$, $X\subset \mathbb R^n$. I am trying now to show existence and, particularly, uniqueness of the solution to a system of functional equations $F: \mathbb R^2 \rightarrow \mathbb R^2$ that looks like this: $\left(\begin{array}{c} F_{1}\left(x_{1}\right)\\ F_{2}\left(x_{2}\right) \end{array}\right)=\left(\begin{array}{c} G_{1}\left[F_{1}\left(\cdot\right),F_{2}\left(\cdot\right)\right]\\ G_{2}\left[F_{1}\left(\cdot\right),F_{2}\left(\cdot\right)\right] \end{array}\right)$ Where $G_1: \mathbb R^2 \rightarrow \mathbb R$ and $G_2: \mathbb R^2 \rightarrow \mathbb R$. In general, $F_{1}$ and $F_{2}$ in the right hand side are not evaluated only at $x_1$ and $x_2$, so the problem cannot be solved pointwise. All the functions behave nicely and I have solved my problem numerically and it converges smoothly (like a contraction). I have two questions: Which Banach space is the natural one to use for functions that map into $\mathbb R^2$? Are there easy to check sufficient conditions for my two dimensional system to be a contraction, like Blackwell's Sufficient Conditions ? I have looked into some fixed-point theory books, but I haven't found anything that directly applies to my problem.","I am familiar with the Banach Fixed Point Theorem and I have used it to prove existence and uniqueness of functional equations in Banach spaces like $C(X)$, the space of bounded continuous function $f:X\rightarrow \mathbb R$ with the sup norm $||f||=\sup_{x\in X}|f(x)|$, $X\subset \mathbb R^n$. I am trying now to show existence and, particularly, uniqueness of the solution to a system of functional equations $F: \mathbb R^2 \rightarrow \mathbb R^2$ that looks like this: $\left(\begin{array}{c} F_{1}\left(x_{1}\right)\\ F_{2}\left(x_{2}\right) \end{array}\right)=\left(\begin{array}{c} G_{1}\left[F_{1}\left(\cdot\right),F_{2}\left(\cdot\right)\right]\\ G_{2}\left[F_{1}\left(\cdot\right),F_{2}\left(\cdot\right)\right] \end{array}\right)$ Where $G_1: \mathbb R^2 \rightarrow \mathbb R$ and $G_2: \mathbb R^2 \rightarrow \mathbb R$. In general, $F_{1}$ and $F_{2}$ in the right hand side are not evaluated only at $x_1$ and $x_2$, so the problem cannot be solved pointwise. All the functions behave nicely and I have solved my problem numerically and it converges smoothly (like a contraction). I have two questions: Which Banach space is the natural one to use for functions that map into $\mathbb R^2$? Are there easy to check sufficient conditions for my two dimensional system to be a contraction, like Blackwell's Sufficient Conditions ? I have looked into some fixed-point theory books, but I haven't found anything that directly applies to my problem.",,"['functional-analysis', 'functional-equations', 'fixed-point-theorems']"
39,Orthogonality relationship for solutions to the wave equation,Orthogonality relationship for solutions to the wave equation,,"If I have two plane waves $e^{i k \cdot x}$ and $e^{i k' \cdot x}$ for $x, k, k' \in \mathbb{R}^d$ , I can consider them to be orthogonal in the sense that $$\int d^dx e^{i k \cdot x} \overline{e^{i k' \cdot x}} = \delta^d(k-k').$$ Now I want to restrict them to solve to the wave equation in Minkowski spacetime $\Box \phi(x) = 0$ , where $\Box := \partial_0^2 - \sum_{i = 1}^{d-1} \partial_{i}^2$ . This means I need to have $k^2 = k'^2 = 0$ , and I'd like to enforce this using a Dirac delta function, so that I consider a basis of solutions to the equation to be $$\Phi_k(x) :=\delta(k^2)e^{i k \cdot x}.$$ I then want write down an orthogonality condition on these basis elements, and I arrive at $$\int d^dx \delta(k^2) e^{i k \cdot x} \overline{\delta(k'^2)e^{i k' \cdot x}} = \delta(k^2)\delta(k'^2)\delta^d(k-k') = \delta(k^2)^2\delta^d(k-k'),$$ where in the last equality I set $k'^2 = k^2$ on support of $\delta^d(k-k')$ . It's clear to me that I'm missing something here, because I don't want to have the square of the Dirac delta function. So how can I write down an orthogonality relationship between $\Phi_k(x)$ and $\Phi_{k'}(x)$ that doesn't introduce $\delta(k^2)^2$ ? If I restrict to $k^2 = k'^2 = 0$ without using the Dirac delta function and instead think of these as some additional constraints that I enforce algebraically then I end up with $\delta^d(k-k')$ constrained to $k^2 = k'^2 = 0$ . Then I seem to have shifted the problem so that I now have two null vectors which cover only a $d-1$ dimensional subset of $\mathbb{R}^d$ , but they're set equal using a $d$ dimensional delta function. For my usage case I anyway need to keep in the Dirac delta function.","If I have two plane waves and for , I can consider them to be orthogonal in the sense that Now I want to restrict them to solve to the wave equation in Minkowski spacetime , where . This means I need to have , and I'd like to enforce this using a Dirac delta function, so that I consider a basis of solutions to the equation to be I then want write down an orthogonality condition on these basis elements, and I arrive at where in the last equality I set on support of . It's clear to me that I'm missing something here, because I don't want to have the square of the Dirac delta function. So how can I write down an orthogonality relationship between and that doesn't introduce ? If I restrict to without using the Dirac delta function and instead think of these as some additional constraints that I enforce algebraically then I end up with constrained to . Then I seem to have shifted the problem so that I now have two null vectors which cover only a dimensional subset of , but they're set equal using a dimensional delta function. For my usage case I anyway need to keep in the Dirac delta function.","e^{i k \cdot x} e^{i k' \cdot x} x, k, k' \in \mathbb{R}^d \int d^dx e^{i k \cdot x} \overline{e^{i k' \cdot x}} = \delta^d(k-k'). \Box \phi(x) = 0 \Box := \partial_0^2 - \sum_{i = 1}^{d-1} \partial_{i}^2 k^2 = k'^2 = 0 \Phi_k(x) :=\delta(k^2)e^{i k \cdot x}. \int d^dx \delta(k^2) e^{i k \cdot x} \overline{\delta(k'^2)e^{i k' \cdot x}} = \delta(k^2)\delta(k'^2)\delta^d(k-k') = \delta(k^2)^2\delta^d(k-k'), k'^2 = k^2 \delta^d(k-k') \Phi_k(x) \Phi_{k'}(x) \delta(k^2)^2 k^2 = k'^2 = 0 \delta^d(k-k') k^2 = k'^2 = 0 d-1 \mathbb{R}^d d","['functional-analysis', 'partial-differential-equations', 'orthogonality']"
40,checking if a function is positive using Fourier coefficients,checking if a function is positive using Fourier coefficients,,"Given a function $$f(x) = \sum_{k=0}^N a_k\ \sin(k\pi x)$$ defined over the region $S = [0, 1]$, is there some way to check if $f(x) \geq 0$ for all $x \in S$ using the coefficients $\{ a_k;\ k \leq N \}$? In particular, I was hoping there'd some inequality involving the coefficients that'll enable us to check this quickly.","Given a function $$f(x) = \sum_{k=0}^N a_k\ \sin(k\pi x)$$ defined over the region $S = [0, 1]$, is there some way to check if $f(x) \geq 0$ for all $x \in S$ using the coefficients $\{ a_k;\ k \leq N \}$? In particular, I was hoping there'd some inequality involving the coefficients that'll enable us to check this quickly.",,"['functional-analysis', 'inequality', 'fourier-series']"
41,Finding the inner product given the norm [duplicate],Finding the inner product given the norm [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Norms Induced by Inner Products and the Parallelogram Law So suppose we are given a norm on a vector space. If the Parallelogram law holds does that automatically mean we have the inner product which we can find using the Polarisation identity? Or is showing the Parallelogram law holds not sufficient to show that there exists an associated inner product? Also, given that the Parallelgram law fails, e.g. $\Vert(x_1,x_2)\Vert_1 = |x_1| + |x_2|$ in $\ell^1(2)$, is there any significance in considering the Polarisation identity?","This question already has answers here : Closed 12 years ago . Possible Duplicate: Norms Induced by Inner Products and the Parallelogram Law So suppose we are given a norm on a vector space. If the Parallelogram law holds does that automatically mean we have the inner product which we can find using the Polarisation identity? Or is showing the Parallelogram law holds not sufficient to show that there exists an associated inner product? Also, given that the Parallelgram law fails, e.g. $\Vert(x_1,x_2)\Vert_1 = |x_1| + |x_2|$ in $\ell^1(2)$, is there any significance in considering the Polarisation identity?",,['functional-analysis']
42,Invertibility of Toeplitz operator in $\ell_1$,Invertibility of Toeplitz operator in,\ell_1,"Suppose we have a Toeplitz operator $$ T(a) = \begin{bmatrix} a_{0} & a_{-1} & a_{-2} & \ldots & \ldots &a_{-n+1} &\dots \\\\  a_{1} & a_0 & a_{-1} & \ddots & & \vdots \\\\\ a_{2} & a_{1} & \ddots & \ddots & \ddots& \vdots \\\\ \vdots & \ddots & \ddots & \ddots & a_{-1} & a_{-2}\\\\ \vdots & & \ddots & a_{1} & a_{0}& a_{-1} \\\\ a_{n-1} & \ldots & \ldots & a_{2} & a_{1} & a_{0} \\\\ \vdots \end{bmatrix} $$ where $a=(a_k)$, $k\in \mathbb{Z}$. In the book by Hagen, Roch and Silbermann you can find the conditions when this operator is invertible in $\ell_2$, theorem 1.31, in page 48. My question is whether there similar conditions for existence of invertibility in space $\ell_1$? The condition in the book is the following. Denote $\mathbb{T}$ the unit circle in $\mathbb{C}$. Let $a\in L^{\infty}(\mathbb{T})$ and let $$a_k=\frac{1}{2\pi}\int_0^{2\pi}a(e^{i\theta})e^{-ik\theta}d\theta$$ Theorem. 1.31 (Coburn's theorem) Let $a\in C(\mathbb{T})$. Operator $T(a)$ is invertible in $\ell_2$ if and only if $0\notin a(\mathbb{T})$ and if $\mathrm{wind}\text{ }a(\mathbb{T})=0$. Here $\mathrm{wind}\text{ }a(\mathbb{T})$ is a winding number of the curve $a(\mathbb{T})$, provided with the orientation inherited by the usual counter-clockwise orientation of the unit circle, around the origin. ( The definition taken from the book )","Suppose we have a Toeplitz operator $$ T(a) = \begin{bmatrix} a_{0} & a_{-1} & a_{-2} & \ldots & \ldots &a_{-n+1} &\dots \\\\  a_{1} & a_0 & a_{-1} & \ddots & & \vdots \\\\\ a_{2} & a_{1} & \ddots & \ddots & \ddots& \vdots \\\\ \vdots & \ddots & \ddots & \ddots & a_{-1} & a_{-2}\\\\ \vdots & & \ddots & a_{1} & a_{0}& a_{-1} \\\\ a_{n-1} & \ldots & \ldots & a_{2} & a_{1} & a_{0} \\\\ \vdots \end{bmatrix} $$ where $a=(a_k)$, $k\in \mathbb{Z}$. In the book by Hagen, Roch and Silbermann you can find the conditions when this operator is invertible in $\ell_2$, theorem 1.31, in page 48. My question is whether there similar conditions for existence of invertibility in space $\ell_1$? The condition in the book is the following. Denote $\mathbb{T}$ the unit circle in $\mathbb{C}$. Let $a\in L^{\infty}(\mathbb{T})$ and let $$a_k=\frac{1}{2\pi}\int_0^{2\pi}a(e^{i\theta})e^{-ik\theta}d\theta$$ Theorem. 1.31 (Coburn's theorem) Let $a\in C(\mathbb{T})$. Operator $T(a)$ is invertible in $\ell_2$ if and only if $0\notin a(\mathbb{T})$ and if $\mathrm{wind}\text{ }a(\mathbb{T})=0$. Here $\mathrm{wind}\text{ }a(\mathbb{T})$ is a winding number of the curve $a(\mathbb{T})$, provided with the orientation inherited by the usual counter-clockwise orientation of the unit circle, around the origin. ( The definition taken from the book )",,"['functional-analysis', 'operator-theory']"
43,Spectrum of unitary operators lie in the unit circle [duplicate],Spectrum of unitary operators lie in the unit circle [duplicate],,"This question already has answers here : If $U$ is unitary operator then spectrum $\sigma(U)$ is contained inside the unit circle (2 answers) Closed 4 years ago . $U$ - unitary operator on complex Hilbert space. Show that $\sigma(U) \subset \{z \in\mathbb C : |z| = 1\}.$ So $U$ is unitary operator if is is surjective and it preserves a scalar product and a unitary operator is a bounded linear operator $U : H → H$ on a Hilbert space H that satisfies $U^*U = UU^* = I$, where $U^*$ is the adjoint of $U$, and $I : H \to H$ is the identity operator. But how do I show that $\sigma(U) \subseteq \{z \in C : |z| = 1\}.$ ? Thanks in advance for any help","This question already has answers here : If $U$ is unitary operator then spectrum $\sigma(U)$ is contained inside the unit circle (2 answers) Closed 4 years ago . $U$ - unitary operator on complex Hilbert space. Show that $\sigma(U) \subset \{z \in\mathbb C : |z| = 1\}.$ So $U$ is unitary operator if is is surjective and it preserves a scalar product and a unitary operator is a bounded linear operator $U : H → H$ on a Hilbert space H that satisfies $U^*U = UU^* = I$, where $U^*$ is the adjoint of $U$, and $I : H \to H$ is the identity operator. But how do I show that $\sigma(U) \subseteq \{z \in C : |z| = 1\}.$ ? Thanks in advance for any help",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
44,First theorem in Topological vector spaces.,First theorem in Topological vector spaces.,,"I came across this theorem and I am disappointed not being able to understand or to have intuition to understand it . I would be glad to get help .  Theorem : If $K$ and $C$ are subset of topological vector space (TVS)  $X$ , $K$ is compact , $C$ is closed and $K \cap C =\varnothing $ then $0$ has a nbhd $V$ such that $(K+V)\cap ( C+V) = \varnothing$ My first question is how to find a symmetric nbhd? I can't seem to understand the proof. an example illustrating the continuity in  TVS. Concept behind local basis and how every other basis can be deduced from local basis. I think one example would make me move forward. Thank you for giving in your time.","I came across this theorem and I am disappointed not being able to understand or to have intuition to understand it . I would be glad to get help .  Theorem : If $K$ and $C$ are subset of topological vector space (TVS)  $X$ , $K$ is compact , $C$ is closed and $K \cap C =\varnothing $ then $0$ has a nbhd $V$ such that $(K+V)\cap ( C+V) = \varnothing$ My first question is how to find a symmetric nbhd? I can't seem to understand the proof. an example illustrating the continuity in  TVS. Concept behind local basis and how every other basis can be deduced from local basis. I think one example would make me move forward. Thank you for giving in your time.",,"['functional-analysis', 'topological-vector-spaces']"
45,Dual space $X^*$ separates points of $X$,Dual space  separates points of,X^* X,As I was reading Toplogical vector Spaces I came to a point where it was written that Dual space $X^*$ Separates points of $X$. But I am not sure whether it was mentioned in the earlier text what does Separates means in this case Although they have clarified a thing on Seminorm separating family but nothing in this regard. Can anyone help me in this what does it really means. Thnx and regards,As I was reading Toplogical vector Spaces I came to a point where it was written that Dual space $X^*$ Separates points of $X$. But I am not sure whether it was mentioned in the earlier text what does Separates means in this case Although they have clarified a thing on Seminorm separating family but nothing in this regard. Can anyone help me in this what does it really means. Thnx and regards,,"['functional-analysis', 'topological-vector-spaces']"
46,Why is $(e_n)$ not a basis for $\ell_\infty$?,Why is  not a basis for ?,(e_n) \ell_\infty,Let $(e_n)$ (where $ e_n $ has a 1 in the $n$-th place and zeros otherwise) be unit  standard vectors of $\ell_\infty$. Why is $(e_n)$ not a basis for $\ell_\infty$? Thanks.,Let $(e_n)$ (where $ e_n $ has a 1 in the $n$-th place and zeros otherwise) be unit  standard vectors of $\ell_\infty$. Why is $(e_n)$ not a basis for $\ell_\infty$? Thanks.,,"['functional-analysis', 'lp-spaces', 'schauder-basis']"
47,Basis in infinite dimensional Hilbert spaces,Basis in infinite dimensional Hilbert spaces,,"Let $H$ be a Hilbert space with a countable basis $B$. Does it mean that any vector $x\in H$ can be expressed as a finite linear combination of elements from $x$, or as an infinite linear combination? Thanks in advance","Let $H$ be a Hilbert space with a countable basis $B$. Does it mean that any vector $x\in H$ can be expressed as a finite linear combination of elements from $x$, or as an infinite linear combination? Thanks in advance",,"['functional-analysis', 'hilbert-spaces']"
48,"If $(I-T)^{-1}$ exists, can it always be written in a series representation?","If  exists, can it always be written in a series representation?",(I-T)^{-1},"If $X$ is a Banach space, and $T:X \to X$ is a bounded linear operator with norm < $1$, then $I-T$ has a bounded inverse defined by $(I-T)^{-1} = \sum_{n=0}^\infty T^n$. Thinking in terms of a converse, if $T$ is any bounded linear operator defined on $X$, then does the existence of a bounded inverse $S=(I-T)^{-1}$ imply that $S$ can be represented as $S=\sum_{n=0}^\infty T^n$?","If $X$ is a Banach space, and $T:X \to X$ is a bounded linear operator with norm < $1$, then $I-T$ has a bounded inverse defined by $(I-T)^{-1} = \sum_{n=0}^\infty T^n$. Thinking in terms of a converse, if $T$ is any bounded linear operator defined on $X$, then does the existence of a bounded inverse $S=(I-T)^{-1}$ imply that $S$ can be represented as $S=\sum_{n=0}^\infty T^n$?",,"['functional-analysis', 'operator-theory', 'banach-algebras']"
49,"The equation $\,\,\Delta u+\cos u=0\,\,$ possesses a weak solution in $\,W^{1,2}_0(D)$",The equation  possesses a weak solution in,"\,\,\Delta u+\cos u=0\,\, \,W^{1,2}_0(D)","Let $D$ be an open bounded subset in $\mathbb{R}^{n}$, with sufficiently smooth boundary. Prove that there is a weak solution in $W^{1,2}_0$$(D)$ to following equation $$\Delta u+\cos u=0.$$ Help me some hints to start. Thanks in advanced.","Let $D$ be an open bounded subset in $\mathbb{R}^{n}$, with sufficiently smooth boundary. Prove that there is a weak solution in $W^{1,2}_0$$(D)$ to following equation $$\Delta u+\cos u=0.$$ Help me some hints to start. Thanks in advanced.",,"['real-analysis', 'analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
50,"In a C*-algebra, does $a \leq b$ imply $a^2 \leq b^2$?","In a C*-algebra, does  imply ?",a \leq b a^2 \leq b^2,"While attempting to fill in the gaps in a proof of the Gelfand-Naimark-Segal representation theorem that I was given in a course in operator algebras, I found myself wondering whether, if $(u_\lambda)_\lambda$ is an approximate unit of a C*-algebra $\mathcal{A}$, it is true that so is $(u_\lambda^2)_\lambda$.  I need this fact to complete my version of the proof of existence of a cyclic vector for the GNS representation of a non-unital C*-algebra. Clearly, $(u_\lambda^2)_\lambda$ is a net of positive elements, bounded in norm by 1. But how to show that this net is increasing, knowing that $(u_\lambda)_\lambda$ is?. I wouldn't even know how to start proving something like this for an arbitrary approximate unit, but it's enough for my proof to show it for the canonical approximate unit of $\mathcal{A}$ with the usual order. So this amounts to showing (I cannot find a counterexample) that if $u_\lambda \leq u_{\lambda'}$ then $u_\lambda^2 \leq u_{\lambda'}^2$. More generally, one can ask if $a \leq b$ implies $a^2 \leq b^2$, or even $a^n \leq b^n$. As I said I'm a bit stuck with this. Thanks for your help!","While attempting to fill in the gaps in a proof of the Gelfand-Naimark-Segal representation theorem that I was given in a course in operator algebras, I found myself wondering whether, if $(u_\lambda)_\lambda$ is an approximate unit of a C*-algebra $\mathcal{A}$, it is true that so is $(u_\lambda^2)_\lambda$.  I need this fact to complete my version of the proof of existence of a cyclic vector for the GNS representation of a non-unital C*-algebra. Clearly, $(u_\lambda^2)_\lambda$ is a net of positive elements, bounded in norm by 1. But how to show that this net is increasing, knowing that $(u_\lambda)_\lambda$ is?. I wouldn't even know how to start proving something like this for an arbitrary approximate unit, but it's enough for my proof to show it for the canonical approximate unit of $\mathcal{A}$ with the usual order. So this amounts to showing (I cannot find a counterexample) that if $u_\lambda \leq u_{\lambda'}$ then $u_\lambda^2 \leq u_{\lambda'}^2$. More generally, one can ask if $a \leq b$ implies $a^2 \leq b^2$, or even $a^n \leq b^n$. As I said I'm a bit stuck with this. Thanks for your help!",,"['functional-analysis', 'operator-algebras']"
51,Interpreting a notation in calculus of variations (differentiating with respect to a derivative),Interpreting a notation in calculus of variations (differentiating with respect to a derivative),,"Consider a functional $J[y]$ defined by: $$J[y] = \int_a^b F(x, y, y') dx \tag{1}$$ Here, $F$ is a function that depends on the independent variable $x$ , the function $y(x)$ , and its derivative $$y' = \frac{dy}{dx} \tag{2}$$ . In the calculus of variations, the operation of differentiating $F$ with respect to $y'$ is involved: $$\frac{\partial F}{\partial y'} \tag{3}$$ This represents the rate of change of the function $F$ with respect to the derivative of $y$ , $y'$ . Operationally, since $y'$ is $\frac{dy}{dx}$ , this differentiation is investigating how sensitive $F$ is to changes in the rate at which $y$ changes with respect to $x$ . I find the notation $\frac{\partial F}{\partial y'}$ a bit confusing in the sense that we are differentiating a function with respect to the derivative. If we just think $y'$ is just another variable symbol and proceed normally as most books do it does not cause much problems, but my question is : What is the mathematical meaning of $\frac{\partial F}{\partial y'}$ in terms of limits? In ordinary differential calculus, we don't encounter differentiation with respect to a derivative itself. Thanks.","Consider a functional defined by: Here, is a function that depends on the independent variable , the function , and its derivative . In the calculus of variations, the operation of differentiating with respect to is involved: This represents the rate of change of the function with respect to the derivative of , . Operationally, since is , this differentiation is investigating how sensitive is to changes in the rate at which changes with respect to . I find the notation a bit confusing in the sense that we are differentiating a function with respect to the derivative. If we just think is just another variable symbol and proceed normally as most books do it does not cause much problems, but my question is : What is the mathematical meaning of in terms of limits? In ordinary differential calculus, we don't encounter differentiation with respect to a derivative itself. Thanks.","J[y] J[y] = \int_a^b F(x, y, y') dx \tag{1} F x y(x) y' = \frac{dy}{dx} \tag{2} F y' \frac{\partial F}{\partial y'} \tag{3} F y y' y' \frac{dy}{dx} F y x \frac{\partial F}{\partial y'} y' \frac{\partial F}{\partial y'}","['functional-analysis', 'multivariable-calculus', 'derivatives', 'intuition', 'calculus-of-variations']"
52,Showing that the derivative operator is not bounded on $L^2 (\mathbb{R})$,Showing that the derivative operator is not bounded on,L^2 (\mathbb{R}),"If we define $D$ as the set of functions $f \in L^2 (\mathbb{R})$ such that $f' \in L^2 (\mathbb{R})$ too, then it can be shown (I think) that the linear operator $\frac{d}{dt}: D \rightarrow L^2 (\mathbb{R})$ is not bounded with respect to the norm on $L^2 (\mathbb{R})$, which is $||f|| = \sqrt{\int_{-\infty}^{\infty}|f(t)|^2 dt}$. But I'm having trouble proving this. What I'd like to do is find a sequence $(f_n)$ in $D$ with $||f_n||=1$ $\forall n \in \mathbb{N}$ but with $||f_n '||$ increasing and becoming arbitrarily large with $n$. I understand that if we were working with the space of continuous functions on $\mathbb{R}$ instead of $L^2 (\mathbb{R})$, with the nice supremum norm, we could just use $f_n (t) = \sin(nt)$, but that won't work here. I tried the sequence $f_n(t) = \sqrt{\frac{\sin(nt)}{t}}$ because that's got a handy $L^2$-norm of $\sqrt{\pi}$ for all $n\in\mathbb{N}$, but its derivative isn't in $L^2 (\mathbb{R})$ so I feel stuck. I think I'm approaching the problem correctly, but the norm in question here isn't easy to work with -- is there a simple sequence I could use?","If we define $D$ as the set of functions $f \in L^2 (\mathbb{R})$ such that $f' \in L^2 (\mathbb{R})$ too, then it can be shown (I think) that the linear operator $\frac{d}{dt}: D \rightarrow L^2 (\mathbb{R})$ is not bounded with respect to the norm on $L^2 (\mathbb{R})$, which is $||f|| = \sqrt{\int_{-\infty}^{\infty}|f(t)|^2 dt}$. But I'm having trouble proving this. What I'd like to do is find a sequence $(f_n)$ in $D$ with $||f_n||=1$ $\forall n \in \mathbb{N}$ but with $||f_n '||$ increasing and becoming arbitrarily large with $n$. I understand that if we were working with the space of continuous functions on $\mathbb{R}$ instead of $L^2 (\mathbb{R})$, with the nice supremum norm, we could just use $f_n (t) = \sin(nt)$, but that won't work here. I tried the sequence $f_n(t) = \sqrt{\frac{\sin(nt)}{t}}$ because that's got a handy $L^2$-norm of $\sqrt{\pi}$ for all $n\in\mathbb{N}$, but its derivative isn't in $L^2 (\mathbb{R})$ so I feel stuck. I think I'm approaching the problem correctly, but the norm in question here isn't easy to work with -- is there a simple sequence I could use?",,"['functional-analysis', 'lp-spaces']"
53,Counter example: strong convergence does not imply convergence in operator norm [closed],Counter example: strong convergence does not imply convergence in operator norm [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Consider a family of operators $T_n\in\mathcal{L}(X)$ where $X$ is a separable Hilbert space. Find examples in which $T_n$ converges strongly to $T\in \mathcal{L}(X)$, i.e. $\|Tx-T_nx\|\to 0$ as $n\to \infty$ for all $x\in X$, but not in operator norm topology, i.e. $\|T-T_n\|_{op}\to 0$ as $n\to \infty$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Consider a family of operators $T_n\in\mathcal{L}(X)$ where $X$ is a separable Hilbert space. Find examples in which $T_n$ converges strongly to $T\in \mathcal{L}(X)$, i.e. $\|Tx-T_nx\|\to 0$ as $n\to \infty$ for all $x\in X$, but not in operator norm topology, i.e. $\|T-T_n\|_{op}\to 0$ as $n\to \infty$.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'uniform-convergence', 'strong-convergence']"
54,Compact operator on a Hilbert space,Compact operator on a Hilbert space,,"This is a homework problem that I'm having some trouble with, so any hints would be appreciated. Let $H$ be a Hilbert space with an orthonormal basis $\{e_n\}$. Consider the operator $F : H\rightarrow H$ defined by $$Fx = \sum_{n=1}^\infty \beta_n \langle x, e_n\rangle e_n,$$ where $\{\beta_n\}\subset \mathbb C$ Suppose that $F$ is compact. (That is, the image of any bounded sequence contains a convergent subsequence). Show that $\lim_{n\rightarrow\infty} \beta_n = 0$. The obvious approach is to choose a particular bounded sequence and try and get that to give me the result, and the first sequence I tried was obviously $\{e_n\}$. So the image of this sequence is $\{\beta_ne_n\}$, so this implies that there is a subsequence $\{\beta_{n_j}e_{n_j}\}$ which converges. But this doesn't help me and I can't see how else to approach the question.","This is a homework problem that I'm having some trouble with, so any hints would be appreciated. Let $H$ be a Hilbert space with an orthonormal basis $\{e_n\}$. Consider the operator $F : H\rightarrow H$ defined by $$Fx = \sum_{n=1}^\infty \beta_n \langle x, e_n\rangle e_n,$$ where $\{\beta_n\}\subset \mathbb C$ Suppose that $F$ is compact. (That is, the image of any bounded sequence contains a convergent subsequence). Show that $\lim_{n\rightarrow\infty} \beta_n = 0$. The obvious approach is to choose a particular bounded sequence and try and get that to give me the result, and the first sequence I tried was obviously $\{e_n\}$. So the image of this sequence is $\{\beta_ne_n\}$, so this implies that there is a subsequence $\{\beta_{n_j}e_{n_j}\}$ which converges. But this doesn't help me and I can't see how else to approach the question.",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
55,Is there an example of a non compact operator whose square is compact?,Is there an example of a non compact operator whose square is compact?,,"Is there an example of a non compact linear operator $T$ from a Banach space $X$ to itself such that $T^2$ is compact? Of course the converse is true, as $T^2$ is compact if $T$ is. Here $T^2$ means $T$ composite with $T$.","Is there an example of a non compact linear operator $T$ from a Banach space $X$ to itself such that $T^2$ is compact? Of course the converse is true, as $T^2$ is compact if $T$ is. Here $T^2$ means $T$ composite with $T$.",,"['functional-analysis', 'compactness', 'compact-operators']"
56,What is common between adjoint operator and transpose of the matrix?,What is common between adjoint operator and transpose of the matrix?,,I am confused.  What is Connection between Adjoint Operator and transpose of the Matrix? I will be very grateful if someone can help me to clarify it.,I am confused.  What is Connection between Adjoint Operator and transpose of the Matrix? I will be very grateful if someone can help me to clarify it.,,['functional-analysis']
57,Is the L2 norm positive definite?,Is the L2 norm positive definite?,,"I am learning the concept of $L^2_w[a,b]$ space - space of square-integrable functions on the interval $[a,b]$ - in the context of Hilbert spaces. After struggling to show that the space of continuous functions is not complete, I came to wonder if the $L^2_w$ norm is in fact a well-defined norm. The definition of a norm, by my understanding, is any function from a vector to a scalar satisfying: $|| a || \ge 0$ with $||a||=0$ implying $a=\mathbb{0}$ , $||\lambda a|| = |\lambda| \cdot ||a||$ , and $||a+b|| \le ||a|| + ||b||$ . My problem is with the first axiom. It feels like there are plenty of functions in $L^2_w[a,b]$ that are nonzero yet have zero norm. One such example is $f(x)=\begin{cases} 0 & (x \ne \frac{a+b}{2}) \\ 1 & (x = \frac{a+b}{2}) \end{cases}$ . These examples seem terrifying to me since, in case of Cauchy sequences in such space, $\lim_{n \rightarrow \infty}{||f_n-f||=0}$ might not imply $\lim_{n\rightarrow\infty}f_n = f$ . Am I missing something or understanding something horribly wrong? Thank you.","I am learning the concept of space - space of square-integrable functions on the interval - in the context of Hilbert spaces. After struggling to show that the space of continuous functions is not complete, I came to wonder if the norm is in fact a well-defined norm. The definition of a norm, by my understanding, is any function from a vector to a scalar satisfying: with implying , , and . My problem is with the first axiom. It feels like there are plenty of functions in that are nonzero yet have zero norm. One such example is . These examples seem terrifying to me since, in case of Cauchy sequences in such space, might not imply . Am I missing something or understanding something horribly wrong? Thank you.","L^2_w[a,b] [a,b] L^2_w || a || \ge 0 ||a||=0 a=\mathbb{0} ||\lambda a|| = |\lambda| \cdot ||a|| ||a+b|| \le ||a|| + ||b|| L^2_w[a,b] f(x)=\begin{cases} 0 & (x \ne \frac{a+b}{2}) \\ 1 & (x = \frac{a+b}{2}) \end{cases} \lim_{n \rightarrow \infty}{||f_n-f||=0} \lim_{n\rightarrow\infty}f_n = f","['functional-analysis', 'normed-spaces']"
58,Geometric implication of the Sobolev embedding,Geometric implication of the Sobolev embedding,,"It is stated in section 10 of this paper that the usual Sobolev embedding $$W^{1,1}(\mathbb{R}^n) \subset L^{n/(n-1)}(\mathbb{R}^n)$$ can be interpreted in geometrical terms as an isoperimetric statement. Although the authors said that this is well-known, I can not find such a statement in Evans classical book on PDEs. Can anyone elaborate the details here? That is, how can we derive an isoperimetric-type inequality from such a Sobolev embedding?","It is stated in section 10 of this paper that the usual Sobolev embedding can be interpreted in geometrical terms as an isoperimetric statement. Although the authors said that this is well-known, I can not find such a statement in Evans classical book on PDEs. Can anyone elaborate the details here? That is, how can we derive an isoperimetric-type inequality from such a Sobolev embedding?","W^{1,1}(\mathbb{R}^n) \subset L^{n/(n-1)}(\mathbb{R}^n)","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'geometric-functional-analysis']"
59,"The closure of differentiable functions are the continuous functions in the interval $[0,1]$",The closure of differentiable functions are the continuous functions in the interval,"[0,1]","Let $X=C([0,1])$ with the $||\cdot||_\infty$-norm. Show that $\overline{C^1([0,1])}=X$. Every differentiable function is continuous. So $C^1([0,1])\subset X$. Now I have to show $D=\overline{C^1([0,1])}\subset X$. I also have to show: $X\subset D$. So every continuous function which is not differentiable is in $\overline{D}/\dot{D}$. Every continuous function f in a compact intervall is bounded, so $||f||_\infty<\infty$. $C^1([0,1])\subset X$, so $||f||_\infty<\infty \forall f\in C^1([0,1])$. So for the functions g in the closure of $C^1([0,1])$ we have $||g||_\infty<\infty$. How can I show that these functions g are also in X? And how can I show that every continuous non-differentiable function is in $\overline{D}/\dot{D}$? Can someone help me?","Let $X=C([0,1])$ with the $||\cdot||_\infty$-norm. Show that $\overline{C^1([0,1])}=X$. Every differentiable function is continuous. So $C^1([0,1])\subset X$. Now I have to show $D=\overline{C^1([0,1])}\subset X$. I also have to show: $X\subset D$. So every continuous function which is not differentiable is in $\overline{D}/\dot{D}$. Every continuous function f in a compact intervall is bounded, so $||f||_\infty<\infty$. $C^1([0,1])\subset X$, so $||f||_\infty<\infty \forall f\in C^1([0,1])$. So for the functions g in the closure of $C^1([0,1])$ we have $||g||_\infty<\infty$. How can I show that these functions g are also in X? And how can I show that every continuous non-differentiable function is in $\overline{D}/\dot{D}$? Can someone help me?",,"['functional-analysis', 'functions', 'continuity']"
60,Are there relations between elements of $L^p$ spaces?,Are there relations between elements of  spaces?,L^p,I have read about dual spaces and the relation $1/p+1/q=1$ as mentioned in the Wikipedia page . Are there any more theorems or relations that connect elements between the $L^p$ spaces for different $p$'s?,I have read about dual spaces and the relation $1/p+1/q=1$ as mentioned in the Wikipedia page . Are there any more theorems or relations that connect elements between the $L^p$ spaces for different $p$'s?,,"['functional-analysis', 'soft-question', 'definition', 'lp-spaces']"
61,Applications of the Closed graph theorem,Applications of the Closed graph theorem,,"In functional analysis a famous theorem states that: if $X, Y$ are Banach spaces and $T: X \to Y$ is a linear operator, $T$ is continous if and only if the graph $\Gamma_T:={(x,Tx), x \in X}$ is closed in the product topology. Do you know some nice application of this theorem? Thank you!!","In functional analysis a famous theorem states that: if $X, Y$ are Banach spaces and $T: X \to Y$ is a linear operator, $T$ is continous if and only if the graph $\Gamma_T:={(x,Tx), x \in X}$ is closed in the product topology. Do you know some nice application of this theorem? Thank you!!",,['functional-analysis']
62,Why is $C_c^\infty(\Omega)$ not a normed space?,Why is  not a normed space?,C_c^\infty(\Omega),"I am watching a Coursera video on Théorie des Distributions and I am trying to understand one of the slides. Let $\Omega \subset \mathbb{R}^N$ be an open set and  $C_K^\infty(\Omega) = \{ \phi \in C^\infty(\Omega) : \mathrm{supp}(\phi)\subset K  \}$. This space has has an infinite family of norms for each $p \in \mathbb{N}$, and compact $K \subset \Omega$ - the maximum of the partial derivative: $$ ||\phi||_{p,K} = \max_{|\alpha|\leq p} \max_{x \in K} |\partial^\alpha \phi(x)|$$ Why is $C_c^\infty(\Omega)$ not a normed space , if we can compute a norm of a function in any compact subset? Here "" compact "" means closed and bounded since we are dealing with $\mathbb{R}^n$.","I am watching a Coursera video on Théorie des Distributions and I am trying to understand one of the slides. Let $\Omega \subset \mathbb{R}^N$ be an open set and  $C_K^\infty(\Omega) = \{ \phi \in C^\infty(\Omega) : \mathrm{supp}(\phi)\subset K  \}$. This space has has an infinite family of norms for each $p \in \mathbb{N}$, and compact $K \subset \Omega$ - the maximum of the partial derivative: $$ ||\phi||_{p,K} = \max_{|\alpha|\leq p} \max_{x \in K} |\partial^\alpha \phi(x)|$$ Why is $C_c^\infty(\Omega)$ not a normed space , if we can compute a norm of a function in any compact subset? Here "" compact "" means closed and bounded since we are dealing with $\mathbb{R}^n$.",,"['functional-analysis', 'compactness', 'normed-spaces', 'distribution-theory']"
63,Hilbert Spaces are Reflexive,Hilbert Spaces are Reflexive,,"I want to show that all Hilbert spaces are reflexive.  I have found the following proof on StackExchange: Hilbert Space is reflexive However, I do not understand it.  Essentially, we want to show that for all $g \in X^{**}$ , (X is some Hilbert space) there exists a unique $x \in X$ such that $g(h) = h(x)$ for all $h \in X^*$ .  Following the OP's logic, we should apply the Riesz-Fréchet Representation Theorem (RRT) twice: Pick any $g \in X^{**}$ .  Then, since $g$ is bounded on $X^*$ , by RRT there exists a unique $f \in X^*$ such that $||g|| = ||f||$ , and $g(h) = \langle h,f \rangle$ for all $h \in X^*$ .  Now apply RRT to $f$ to get a unique $x \in X$ such that $||f|| = ||x||$ and $f(y) = \langle y,x \rangle$ for all $y \in X$ .  It follows that: $f(x) = \langle x,x\rangle = ||x||^2 = ||f||^2 = \langle f,f \rangle = g(f)$ . We have shown that for any $g \in X^{**}$ that there exist unique $x \in X$ , $f \in X^*$ such that $f(x) = g(f)$ .  This is not quite what we want.  We want this to hold for a general $h \in X^*$ . According to icurays1, we have basically defined a bijective mapping $T:X^{**} \to X$ .  Why is T bijective, and why does this give us that $X$ is reflexive?","I want to show that all Hilbert spaces are reflexive.  I have found the following proof on StackExchange: Hilbert Space is reflexive However, I do not understand it.  Essentially, we want to show that for all , (X is some Hilbert space) there exists a unique such that for all .  Following the OP's logic, we should apply the Riesz-Fréchet Representation Theorem (RRT) twice: Pick any .  Then, since is bounded on , by RRT there exists a unique such that , and for all .  Now apply RRT to to get a unique such that and for all .  It follows that: . We have shown that for any that there exist unique , such that .  This is not quite what we want.  We want this to hold for a general . According to icurays1, we have basically defined a bijective mapping .  Why is T bijective, and why does this give us that is reflexive?","g \in X^{**} x \in X g(h) = h(x) h \in X^* g \in X^{**} g X^* f \in X^* ||g|| = ||f|| g(h) = \langle h,f \rangle h \in X^* f x \in X ||f|| = ||x|| f(y) = \langle y,x \rangle y \in X f(x) = \langle x,x\rangle = ||x||^2 = ||f||^2 = \langle f,f \rangle = g(f) g \in X^{**} x \in X f \in X^* f(x) = g(f) h \in X^* T:X^{**} \to X X","['functional-analysis', 'hilbert-spaces']"
64,"Metric that makes interval $[a,b]$ not complete",Metric that makes interval  not complete,"[a,b]","The interval $[a,b]$ is complete under the Euclidean metric. Is there a metric that makes $[a,b]$ not complete? Could you give general means to solve this question?","The interval $[a,b]$ is complete under the Euclidean metric. Is there a metric that makes $[a,b]$ not complete? Could you give general means to solve this question?",,"['functional-analysis', 'metric-spaces']"
65,Boundary of $L^1$ space,Boundary of  space,L^1,"Is there any rigorous or heuristic notion of boundary of $L^1$ that is studied? I mean something loosely like the collection of functions or distributions defined by $$\left\{f\notin L^1: f_n\to f\quad\text{a.e.}\quad \text{as} \quad n\to \infty \quad \text{where} \quad f_n\in L^1\right\}$$ And what kind of characterizations or properties of this ""surface"" are known? Edit: Changed to pointwise convergence.","Is there any rigorous or heuristic notion of boundary of $L^1$ that is studied? I mean something loosely like the collection of functions or distributions defined by $$\left\{f\notin L^1: f_n\to f\quad\text{a.e.}\quad \text{as} \quad n\to \infty \quad \text{where} \quad f_n\in L^1\right\}$$ And what kind of characterizations or properties of this ""surface"" are known? Edit: Changed to pointwise convergence.",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
66,Bounded sequence in a Hilbert such that all subsequences that weakly converge do so to the same limit,Bounded sequence in a Hilbert such that all subsequences that weakly converge do so to the same limit,,"Let $H$ be a Hilbert space, $a \in H$ and $(x_n)_n$ a bounded sequence in $H$ such that every subsequence of $H$ that converges weakly converges to $a$. How do you prove that $(x_n)_n$ converges weakly to $a$? The only thing I know is that there is indeed at least one subsequence of $(x_n)_n$ that converges weakly.","Let $H$ be a Hilbert space, $a \in H$ and $(x_n)_n$ a bounded sequence in $H$ such that every subsequence of $H$ that converges weakly converges to $a$. How do you prove that $(x_n)_n$ converges weakly to $a$? The only thing I know is that there is indeed at least one subsequence of $(x_n)_n$ that converges weakly.",,"['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
67,Proof that $\lim_{n\to\infty}\|x_n-x\|=0$ with weak convergence,Proof that  with weak convergence,\lim_{n\to\infty}\|x_n-x\|=0,"I want to prove that in a normed linear space $H$, that if $x_n$ is weak convergent to $x$, and $\lim_{n\to\infty} \|x_n\| = \|x\|$ then: $$\lim_{n\to\infty}\|x_n-x\|=0$$ Can I please have a hint? Also does $\langle x,x\rangle^{\frac12}=\|x\|$ or something? The impression I have is, essentially $\lim_{n\to\infty}\|x_n\|-\|x\|=\lim_{n\to\infty}\|x_n - x\|$ due to the weak convergence, otherwise in the general case: $$\|x\|-\|y\|=\|x - y\|$$ could be true, but only if they are in opposite directions. My definition of weak convergence is $\lim_{n\to\infty} \langle x_n,y\rangle =\langle x,y\rangle$, so I suspect that this is a hilbert space.","I want to prove that in a normed linear space $H$, that if $x_n$ is weak convergent to $x$, and $\lim_{n\to\infty} \|x_n\| = \|x\|$ then: $$\lim_{n\to\infty}\|x_n-x\|=0$$ Can I please have a hint? Also does $\langle x,x\rangle^{\frac12}=\|x\|$ or something? The impression I have is, essentially $\lim_{n\to\infty}\|x_n\|-\|x\|=\lim_{n\to\infty}\|x_n - x\|$ due to the weak convergence, otherwise in the general case: $$\|x\|-\|y\|=\|x - y\|$$ could be true, but only if they are in opposite directions. My definition of weak convergence is $\lim_{n\to\infty} \langle x_n,y\rangle =\langle x,y\rangle$, so I suspect that this is a hilbert space.",,['functional-analysis']
68,What does a norm $\|x\|$ goes to infinity mean?,What does a norm  goes to infinity mean?,\|x\|,I am looking into Coercive functions. The definition says : A continuous function $f : \mathbb{R}^n → \mathbb{R}$ is called coercive if $$\lim_{\|x\| \to \infty} f(x) = + \infty$$ What does a norm to infinity mean? I have two functions one of which is coercive and another not. I have trouble deciphering the difference. $$i)\space g(x) = x_1^6 + 5x_2^4 + x_3 - 3x_1x_2x_3^3; \space x \epsilon \mathbb{R}^3\implies \text{not  coercive}\\ ii)\space h(x) = x_1^4 + x_2^4 - 3x_1^3 + x_2; \space x \epsilon \mathbb{R}^2 \implies \text{coercive}$$,I am looking into Coercive functions. The definition says : A continuous function $f : \mathbb{R}^n → \mathbb{R}$ is called coercive if $$\lim_{\|x\| \to \infty} f(x) = + \infty$$ What does a norm to infinity mean? I have two functions one of which is coercive and another not. I have trouble deciphering the difference. $$i)\space g(x) = x_1^6 + 5x_2^4 + x_3 - 3x_1x_2x_3^3; \space x \epsilon \mathbb{R}^3\implies \text{not  coercive}\\ ii)\space h(x) = x_1^4 + x_2^4 - 3x_1^3 + x_2; \space x \epsilon \mathbb{R}^2 \implies \text{coercive}$$,,"['real-analysis', 'functional-analysis']"
69,showing uniqueness of a Hahn Banach extension,showing uniqueness of a Hahn Banach extension,,"I am trying to prove the following: If $H$ is a Hilbert space and $G\subseteq H$ is a closed linear subspace, then any bounded linear functional on $G$ has a unique Hahn-Banach extension on $H$. So far I have proven the first half: Recall by the Riesz Representation Theorem, that if $X$ is a Hilbert space, and $h\in X^*$, then there is a unique $y\in X$ such that $h(x)=(x,y)$ for all $x\in X$. Also, since $G$ is a closed linear subspace of $H$, then $G$ itself is a Hilbert space. Thus, there exists a unique $y\in G$ such that $f_G(x)=(x,y)$ for all $x\in G$, where $f_G\in G^*$. Let $f\in H^*$ be defined by $f(x)=(x,y)$. Then we have $f|_G=f_G$, since $g\subseteq H$, so $f$ is an extension of $f_G$ on $H$. Now suppose there exists another extension $g\in H^*$ of $f_G$ such that $g(x)=(x,z)$ for some unique $z\in G$. Then...?? How can I show uniqueness? It seems kind of difficult. Thank you for your help!!","I am trying to prove the following: If $H$ is a Hilbert space and $G\subseteq H$ is a closed linear subspace, then any bounded linear functional on $G$ has a unique Hahn-Banach extension on $H$. So far I have proven the first half: Recall by the Riesz Representation Theorem, that if $X$ is a Hilbert space, and $h\in X^*$, then there is a unique $y\in X$ such that $h(x)=(x,y)$ for all $x\in X$. Also, since $G$ is a closed linear subspace of $H$, then $G$ itself is a Hilbert space. Thus, there exists a unique $y\in G$ such that $f_G(x)=(x,y)$ for all $x\in G$, where $f_G\in G^*$. Let $f\in H^*$ be defined by $f(x)=(x,y)$. Then we have $f|_G=f_G$, since $g\subseteq H$, so $f$ is an extension of $f_G$ on $H$. Now suppose there exists another extension $g\in H^*$ of $f_G$ such that $g(x)=(x,z)$ for some unique $z\in G$. Then...?? How can I show uniqueness? It seems kind of difficult. Thank you for your help!!",,"['real-analysis', 'analysis', 'functional-analysis', 'hilbert-spaces']"
70,Invertible iff Bounded below and dense range,Invertible iff Bounded below and dense range,,"Statement: Given a Hilbert space $\mathscr{H}$ and $\mathscr{K}$ and a bounded operator $A \in \mathscr{B}(\mathscr{H}, \mathscr{K})$. Show that $A$ is invertible if and only if $A$ is bounded below and has dense range: Attempted proof: $\Rightarrow$ Since we are invertible then the range of $A$ will be equal to the $\mathscr{K}$. Furthermore, if $A$ is invertitble then $A^{-1}A = \mathbb{I}$ hence $\forall h \in \mathscr{H}\, , \|h\|=\|A^{-1}Ah\| \leq \|A^{-1}\|\|A(h)\| \rightarrow \frac{\|h\|}{\|A^{-1}\|}\leq  \|A(h)\|$ so we are bounded below. $\Leftarrow$ (this is the dirrection I get stuck in) We now assume that $A$ is bounded below and has dense range then the opeartor is invertible. Since we are bounded below then we are injective. To see this we assume by contradiction, then $\exists h\in \mathscr{H}, \, s.t. \, h \neq 0 \rightarrow A(h) = 0$, and since we are bounded below then $ \exists \delta >0 \, s.t \, \delta\|h\| \leq \|A(h)\| = 0$ so we arrive at a contradiction since the L.H.S > 0 but the R.H.S = 0. now all that remains to be shown is surjectivity. Let $\{h_n\}_{1}^{\infty}$ be a Cauchy sequence, since we are bounded from below then $\delta\|h_n-h_m\| \leq \|A(h_n-h_m)\| = \|A(h_n)-A(h_m)\|$ which implies that $\|h_n-h_m\| \leq \frac{1}{\delta}\|A(h_n)-A(h_m)\|=\frac{1}{\delta}\|A(h_n-h_m)\|\leq\frac{\|A\|}{\delta}\|h_n-h_m\|< \varepsilon$ since the last term is Cauchy we can let $\|h_n-h_m\| <\frac{\delta^2}{\|A\|} = \varepsilon$ So we know that if we are Cauchy is $\mathscr{H}$ then we are Cauchy is $\mathscr{K}$. And I don't know how to proceed from this point.","Statement: Given a Hilbert space $\mathscr{H}$ and $\mathscr{K}$ and a bounded operator $A \in \mathscr{B}(\mathscr{H}, \mathscr{K})$. Show that $A$ is invertible if and only if $A$ is bounded below and has dense range: Attempted proof: $\Rightarrow$ Since we are invertible then the range of $A$ will be equal to the $\mathscr{K}$. Furthermore, if $A$ is invertitble then $A^{-1}A = \mathbb{I}$ hence $\forall h \in \mathscr{H}\, , \|h\|=\|A^{-1}Ah\| \leq \|A^{-1}\|\|A(h)\| \rightarrow \frac{\|h\|}{\|A^{-1}\|}\leq  \|A(h)\|$ so we are bounded below. $\Leftarrow$ (this is the dirrection I get stuck in) We now assume that $A$ is bounded below and has dense range then the opeartor is invertible. Since we are bounded below then we are injective. To see this we assume by contradiction, then $\exists h\in \mathscr{H}, \, s.t. \, h \neq 0 \rightarrow A(h) = 0$, and since we are bounded below then $ \exists \delta >0 \, s.t \, \delta\|h\| \leq \|A(h)\| = 0$ so we arrive at a contradiction since the L.H.S > 0 but the R.H.S = 0. now all that remains to be shown is surjectivity. Let $\{h_n\}_{1}^{\infty}$ be a Cauchy sequence, since we are bounded from below then $\delta\|h_n-h_m\| \leq \|A(h_n-h_m)\| = \|A(h_n)-A(h_m)\|$ which implies that $\|h_n-h_m\| \leq \frac{1}{\delta}\|A(h_n)-A(h_m)\|=\frac{1}{\delta}\|A(h_n-h_m)\|\leq\frac{\|A\|}{\delta}\|h_n-h_m\|< \varepsilon$ since the last term is Cauchy we can let $\|h_n-h_m\| <\frac{\delta^2}{\|A\|} = \varepsilon$ So we know that if we are Cauchy is $\mathscr{H}$ then we are Cauchy is $\mathscr{K}$. And I don't know how to proceed from this point.",,"['analysis', 'functional-analysis', 'operator-theory', 'hilbert-spaces']"
71,to prove infinity norm is indeed norm,to prove infinity norm is indeed norm,,"to prove infinity norm of a function which is equal to supremum of absolute value of that function, is indeed a norm. I have a clue to check for the three axioms of norm. but tell me hoe to proceed","to prove infinity norm of a function which is equal to supremum of absolute value of that function, is indeed a norm. I have a clue to check for the three axioms of norm. but tell me hoe to proceed",,['functional-analysis']
72,Is there an injective operator with a dense nonclosed range?,Is there an injective operator with a dense nonclosed range?,,Let $H$ be an infinite dimensional separable Hilbert space. Is there an operators $A \in B(H)$ such that  $Im(A) \subsetneq \overline{Im(A)} = H$ and $Ker(A) = \{0\}$ ? Bonus : We can build such operators by using some compact or shift operators (see the answers). Is there others possibilities ? How classify this phenomenon ?,Let $H$ be an infinite dimensional separable Hilbert space. Is there an operators $A \in B(H)$ such that  $Im(A) \subsetneq \overline{Im(A)} = H$ and $Ker(A) = \{0\}$ ? Bonus : We can build such operators by using some compact or shift operators (see the answers). Is there others possibilities ? How classify this phenomenon ?,,"['functional-analysis', 'operator-theory']"
73,Seminorms and norms,Seminorms and norms,,"Suppose we have the following lemma: Lemma If $E_0 \hookrightarrow E$, and $E_0$ is a closed subspace then $E/E_0$ is a normed space and for $[x] \in E/E_0$ its norm is given by $||[x]|| = \text{inf}_{y \in E_0} ||x-y||$. What is the intuition of this norm besides that it ""works""? Does it just measure how close $x$ and $y$ are to being equivalent? Also does one usually try to introduce some norm on a space $E$ but finds out that it doesn't work? Thus one introduces it as a seminorm and then as a norm on $E/E_0$? In other words, is a seminorm on $E$ just a means to get a norm on $E/E_0$? Why can't one just introduce a norm on $E/E_0$ directly?","Suppose we have the following lemma: Lemma If $E_0 \hookrightarrow E$, and $E_0$ is a closed subspace then $E/E_0$ is a normed space and for $[x] \in E/E_0$ its norm is given by $||[x]|| = \text{inf}_{y \in E_0} ||x-y||$. What is the intuition of this norm besides that it ""works""? Does it just measure how close $x$ and $y$ are to being equivalent? Also does one usually try to introduce some norm on a space $E$ but finds out that it doesn't work? Thus one introduces it as a seminorm and then as a norm on $E/E_0$? In other words, is a seminorm on $E$ just a means to get a norm on $E/E_0$? Why can't one just introduce a norm on $E/E_0$ directly?",,"['intuition', 'functional-analysis']"
74,Reference request : Holomorphic functions with values in Banach spaces,Reference request : Holomorphic functions with values in Banach spaces,,"I am looking for books that deal with holomorphic functions with values in Banach spaces that discuss, state and prove analogues of classical results from classical ( $ \mathbb{C}$ -valued) Complex Analysis such as holomorphic $\Leftrightarrow$ analytic, Goursat's Lemma, Cauchy's theorem, Morera's theorem etc ; I am not looking to dig deep in to the theory, but I would rather appreciate a detailed/beginner-friendly exposition of the material I described (if such a reference exists). One result I need is that uniform limits of Banach space-valued holomorphic functions is again holomorphic (or Morera's theorem in case it implies that result just like in the scalar case) so a reference that contains the proof of that result would be very welcome. Regarding my background, I have studied some basic measure theory, Functional and Complex Analysis. Also, I have just started looking into integration for functions $f:S \rightarrow X$ where $S$ is a measure space and $X$ is a Banach space (Bochner integral), but I haven't studied holomorphic functions with values in Banach spaces before.","I am looking for books that deal with holomorphic functions with values in Banach spaces that discuss, state and prove analogues of classical results from classical ( -valued) Complex Analysis such as holomorphic analytic, Goursat's Lemma, Cauchy's theorem, Morera's theorem etc ; I am not looking to dig deep in to the theory, but I would rather appreciate a detailed/beginner-friendly exposition of the material I described (if such a reference exists). One result I need is that uniform limits of Banach space-valued holomorphic functions is again holomorphic (or Morera's theorem in case it implies that result just like in the scalar case) so a reference that contains the proof of that result would be very welcome. Regarding my background, I have studied some basic measure theory, Functional and Complex Analysis. Also, I have just started looking into integration for functions where is a measure space and is a Banach space (Bochner integral), but I haven't studied holomorphic functions with values in Banach spaces before.", \mathbb{C} \Leftrightarrow f:S \rightarrow X S X,"['complex-analysis', 'functional-analysis', 'banach-spaces']"
75,If every subsequence of $(x_n)$ has a subsequence converging weakly to $x$ then $x_n$ converges weakly to $x$.,If every subsequence of  has a subsequence converging weakly to  then  converges weakly to .,(x_n) x x_n x,Let $H$ be a Hilbert space(or a reflexive Banach space) and $(x_n)$ a sequence in $H$. Is the following proposition true? If every subsequence of $(x_n)$ has a subsequence converging weakly to $x$ then $x_n$ converges weakly to $x$. I think this is true for bounded sequences since bounded sets are weakly sequencially compact. But I couldn't prove it.,Let $H$ be a Hilbert space(or a reflexive Banach space) and $(x_n)$ a sequence in $H$. Is the following proposition true? If every subsequence of $(x_n)$ has a subsequence converging weakly to $x$ then $x_n$ converges weakly to $x$. I think this is true for bounded sequences since bounded sets are weakly sequencially compact. But I couldn't prove it.,,"['real-analysis', 'functional-analysis', 'hilbert-spaces', 'banach-spaces', 'weak-convergence']"
76,"For holomorphic functions, if $\{f_n\}\to f$ uniformly on compact sets, then the same is true for the derivatives.","For holomorphic functions, if  uniformly on compact sets, then the same is true for the derivatives.",\{f_n\}\to f,"Let $\Omega$ be an open subset in $\mathbb{C}$. Let $\{f_n\}$ be a sequence of holomorphic functions on $\Omega$ such that $f_n\to f$ pointwise and converges uniformly on any compact subset $K\subseteq \Omega$. Then by Cauchy Theorem and Morera Theorem, $f$ is holomorphic. Let $f_n$ and $f'$ be the derivatives of $f_n$ and $f$ respectively. Prove that $f_n'\to f'$ uniformly on any compact subset $K\subseteq \Omega$. How to prove?","Let $\Omega$ be an open subset in $\mathbb{C}$. Let $\{f_n\}$ be a sequence of holomorphic functions on $\Omega$ such that $f_n\to f$ pointwise and converges uniformly on any compact subset $K\subseteq \Omega$. Then by Cauchy Theorem and Morera Theorem, $f$ is holomorphic. Let $f_n$ and $f'$ be the derivatives of $f_n$ and $f$ respectively. Prove that $f_n'\to f'$ uniformly on any compact subset $K\subseteq \Omega$. How to prove?",,"['real-analysis', 'complex-analysis', 'analysis', 'functional-analysis', 'convergence-divergence']"
77,"Prove that $\int_{D}\nabla u\cdot\nabla vdx=\int_{D}uv\,dx=0$",Prove that,"\int_{D}\nabla u\cdot\nabla vdx=\int_{D}uv\,dx=0","Let $D$ be the open bounded subset in $\mathbb{R}^{n}$ with smooth boundary, $\alpha$ and $\beta$ be different  non-null real numbers, and $u$ and $v$ be in $W_0^{1,2}(D)\setminus\left\{ 0\right\} $ such that $\Delta u=\alpha u$ and $\Delta v=\beta v$ in weak solutions sense. Prove that $$\int_{D}\nabla u\cdot\nabla v\,dx=\int_{D}uv\,dx=0$$ I don't understand what ""in weak solutions sense"" means. Can anyone tell me what it means so I can solve the problem. Thanks in advanced.","Let $D$ be the open bounded subset in $\mathbb{R}^{n}$ with smooth boundary, $\alpha$ and $\beta$ be different  non-null real numbers, and $u$ and $v$ be in $W_0^{1,2}(D)\setminus\left\{ 0\right\} $ such that $\Delta u=\alpha u$ and $\Delta v=\beta v$ in weak solutions sense. Prove that $$\int_{D}\nabla u\cdot\nabla v\,dx=\int_{D}uv\,dx=0$$ I don't understand what ""in weak solutions sense"" means. Can anyone tell me what it means so I can solve the problem. Thanks in advanced.",,"['real-analysis', 'analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
78,Weak convergence of a sequence of characteristic functions,Weak convergence of a sequence of characteristic functions,,"I am trying to produce a sequence of sets $A_n \subseteq [0,1] $ such that their characteristic functions $\chi_{A_n}$ converge weakly in $L^2[0,1]$ to $\frac{1}{2}\chi_{[0,1]}$. The sequence of sets  $$A_n = \bigcup\limits_{k=0}^{2^{n-1} - 1} \left[ \frac{2k}{2^n}, \frac{2k+1}{2^n}  \right]$$ seems like it should work to me, as their characteristic functions look like they will ""average out"" to $\frac{1}{2} \chi_{[0,1]}$ as needed. However, I'm having trouble completing the actual computation. Let $g \in L^2[0,1]$, then we'd like to show that  $$ \lim_{n \to \infty}  \int_{[0,1]} \chi_{A_n} g(x) dx = \int_{[0,1]} \frac{1}{2}\chi_{[0,1]} g(x) dx = \frac{1}{2} \int_{[0,1]} g(x) dx $$ We have that $$ \int_{[0,1]} \chi_{A_n} g(x) dx = \sum\limits_{k=0}^{2^{n-1}-1} \int_{\left[ \frac{2k}{2^n}, \frac{2k+1}{2^n}   \right]  } \chi_{A_n} g(x) dx $$ Now I am stuck, as I don't see how to use a limit argument to show that this goes to the desired limit as $ n \to \infty$. Does anyone have any suggestions on how to proceed? Any help is appreciated! :)","I am trying to produce a sequence of sets $A_n \subseteq [0,1] $ such that their characteristic functions $\chi_{A_n}$ converge weakly in $L^2[0,1]$ to $\frac{1}{2}\chi_{[0,1]}$. The sequence of sets  $$A_n = \bigcup\limits_{k=0}^{2^{n-1} - 1} \left[ \frac{2k}{2^n}, \frac{2k+1}{2^n}  \right]$$ seems like it should work to me, as their characteristic functions look like they will ""average out"" to $\frac{1}{2} \chi_{[0,1]}$ as needed. However, I'm having trouble completing the actual computation. Let $g \in L^2[0,1]$, then we'd like to show that  $$ \lim_{n \to \infty}  \int_{[0,1]} \chi_{A_n} g(x) dx = \int_{[0,1]} \frac{1}{2}\chi_{[0,1]} g(x) dx = \frac{1}{2} \int_{[0,1]} g(x) dx $$ We have that $$ \int_{[0,1]} \chi_{A_n} g(x) dx = \sum\limits_{k=0}^{2^{n-1}-1} \int_{\left[ \frac{2k}{2^n}, \frac{2k+1}{2^n}   \right]  } \chi_{A_n} g(x) dx $$ Now I am stuck, as I don't see how to use a limit argument to show that this goes to the desired limit as $ n \to \infty$. Does anyone have any suggestions on how to proceed? Any help is appreciated! :)",,"['real-analysis', 'functional-analysis', 'lp-spaces']"
79,How far is a Banach algebra from being a multiplicative group?,How far is a Banach algebra from being a multiplicative group?,,"Given a Banach algebra $\mathcal{A}$, the collection of invertible elements in $\mathcal A$, $G(\mathcal{A})$ is a group. I wonder whether there is a measurement for how far $\mathcal{A}$ is from $G(\mathcal{A})$. It seems to me that such an measurement can show how 'nice' a Banach algebra is algebraically. Thanks!","Given a Banach algebra $\mathcal{A}$, the collection of invertible elements in $\mathcal A$, $G(\mathcal{A})$ is a group. I wonder whether there is a measurement for how far $\mathcal{A}$ is from $G(\mathcal{A})$. It seems to me that such an measurement can show how 'nice' a Banach algebra is algebraically. Thanks!",,"['functional-analysis', 'banach-algebras']"
80,Example where $(V^*)^*\neq V$?,Example where ?,(V^*)^*\neq V,"Let $V$ be a vector space. This answer gives a nice explanation of why the ""dual dual space"" of $V$ , i.e., $(V^*)^*$ , is isomorphic to $V$ if $\dim V<\infty.$ Can someone give an example where $\dim V=\infty$ and $(V^*)^*\ncong V$ ? I'm having a hard time imagining this. Additionally, must $V$ always be at least isomorphic to a subspace of $(V^*)^*$ ? It seems that the answer must be yes, since we can always define $\xi_{v∈ V}:V^*\to\mathbb R, \omega\mapsto\xi_v(\omega):=\omega(v).$","Let be a vector space. This answer gives a nice explanation of why the ""dual dual space"" of , i.e., , is isomorphic to if Can someone give an example where and ? I'm having a hard time imagining this. Additionally, must always be at least isomorphic to a subspace of ? It seems that the answer must be yes, since we can always define","V V (V^*)^* V \dim V<\infty. \dim V=\infty (V^*)^*\ncong V V (V^*)^* \xi_{v∈ V}:V^*\to\mathbb R, \omega\mapsto\xi_v(\omega):=\omega(v).","['functional-analysis', 'dual-spaces']"
81,Is the Space $C^\alpha$ separable?,Is the Space  separable?,C^\alpha,"Let $C^\alpha$be the space of continuous functions f(x) on [0,1]. Such that $ sup \frac{|f(x_1)-f(x_2|}{|x_1-x_2|^\alpha}$  ( $ 0\le x_1 \le x_2 \le 1$. Introduce in this space the norm $||f||_C^\alpha = |f(0)|$ + $ sup \frac{|f(x_1)-f(x_2|}{|x_1-x_2|^\alpha}$  ( $ 0\le x_1 \le x_2 \le 1$. I need to know is it separable or not and why ? I think it's not separable but don't know why ?","Let $C^\alpha$be the space of continuous functions f(x) on [0,1]. Such that $ sup \frac{|f(x_1)-f(x_2|}{|x_1-x_2|^\alpha}$  ( $ 0\le x_1 \le x_2 \le 1$. Introduce in this space the norm $||f||_C^\alpha = |f(0)|$ + $ sup \frac{|f(x_1)-f(x_2|}{|x_1-x_2|^\alpha}$  ( $ 0\le x_1 \le x_2 \le 1$. I need to know is it separable or not and why ? I think it's not separable but don't know why ?",,"['functional-analysis', 'holder-spaces']"
82,Confused about the concept of distributions and functions,Confused about the concept of distributions and functions,,"I just learned the concept of distributions, but I'm confused about the concept, so my question is simple and may looks a bit strange (sorry about that..) Firstly, I know that a distribution is a continuous linear functional, mapping from $D(\Omega)$ to a complex number. So if $f\in D'(\Omega)$, then the parameter for $f$ should be a function, right? (which I mean $f$ should be like $f(g)$ or $f(\varphi)$, ($g$ and $\varphi$ are functions), but not $f(x)$ where $x$ is a real number) And is this the main difference between a function and a functional? But I also see examples like ""let $f\in D'(\Omega)$ be a distribution defined by $f(x)=2x$ when $x>0$ and $f(x)=0$ when $x\leq 0$)"". What does this mean? Is $f$ here a distribution or a function after all? Secondly, a distribution $f$ operating on a function $\varphi$ should be defined by $<f,\varphi>$ equals something, but why both in my note and some textbooks, when discussing the multiplication by $C^{\infty}$ functions and differentiation, they all began with $<af,\varphi>=\int_\Omega af\varphi dx=<f,a\varphi> \forall \varphi \in D(\Omega)$. Here suppose $f\in C$ (or $f\in L_{loc}^{1}(\Omega)$) and $a\in C^{\infty}(\Omega)$ and $<\partial^\alpha f,\varphi>=\int_{\mathbb R^N}(\partial ^\alpha f)\varphi dx=...$ Why here the distributions are set as integral automatically? Or shall we think of distribution as integral like above when doing operations on distributions? Thanks so much!","I just learned the concept of distributions, but I'm confused about the concept, so my question is simple and may looks a bit strange (sorry about that..) Firstly, I know that a distribution is a continuous linear functional, mapping from $D(\Omega)$ to a complex number. So if $f\in D'(\Omega)$, then the parameter for $f$ should be a function, right? (which I mean $f$ should be like $f(g)$ or $f(\varphi)$, ($g$ and $\varphi$ are functions), but not $f(x)$ where $x$ is a real number) And is this the main difference between a function and a functional? But I also see examples like ""let $f\in D'(\Omega)$ be a distribution defined by $f(x)=2x$ when $x>0$ and $f(x)=0$ when $x\leq 0$)"". What does this mean? Is $f$ here a distribution or a function after all? Secondly, a distribution $f$ operating on a function $\varphi$ should be defined by $<f,\varphi>$ equals something, but why both in my note and some textbooks, when discussing the multiplication by $C^{\infty}$ functions and differentiation, they all began with $<af,\varphi>=\int_\Omega af\varphi dx=<f,a\varphi> \forall \varphi \in D(\Omega)$. Here suppose $f\in C$ (or $f\in L_{loc}^{1}(\Omega)$) and $a\in C^{\infty}(\Omega)$ and $<\partial^\alpha f,\varphi>=\int_{\mathbb R^N}(\partial ^\alpha f)\varphi dx=...$ Why here the distributions are set as integral automatically? Or shall we think of distribution as integral like above when doing operations on distributions? Thanks so much!",,"['functional-analysis', 'functions', 'partial-differential-equations', 'distribution-theory']"
83,Infinite dimensional spaces other than functional spaces,Infinite dimensional spaces other than functional spaces,,"""Functional analysis"" is the study of infinite dimensional spaces equipped with inner product, norm, topology...etc. The most interesting spaces are the spaces of functions/operators and sequences. I don't know if there's ""another kind"" of infinite dimensional spaces other than space of functions/operators/sequences which is interesting.","""Functional analysis"" is the study of infinite dimensional spaces equipped with inner product, norm, topology...etc. The most interesting spaces are the spaces of functions/operators and sequences. I don't know if there's ""another kind"" of infinite dimensional spaces other than space of functions/operators/sequences which is interesting.",,"['functional-analysis', 'soft-question', 'hilbert-spaces', 'banach-spaces', 'normed-spaces']"
84,$f\in L^1\cap L^2$ implies $\hat f \in L^1$?,implies ?,f\in L^1\cap L^2 \hat f \in L^1,Given $f\in L^1(\mathbb R^d)\cap L^2(\mathbb R^d)$. The Riemann-Lebesgue lemma and the unitarity of the Fourier transform on $L^2$ implies that $\hat f \in L^2\cap C_0$ where $C_0$ are continuous functions decaying at infinity. My professor claimed that $\hat f\in L^1$ which is not obvious in my opinion. Is this correct?,Given $f\in L^1(\mathbb R^d)\cap L^2(\mathbb R^d)$. The Riemann-Lebesgue lemma and the unitarity of the Fourier transform on $L^2$ implies that $\hat f \in L^2\cap C_0$ where $C_0$ are continuous functions decaying at infinity. My professor claimed that $\hat f\in L^1$ which is not obvious in my opinion. Is this correct?,,"['functional-analysis', 'fourier-analysis', 'lp-spaces']"
85,What are non-obvious examples of measures obtained from linear functionals by the Riesz representation theorem?,What are non-obvious examples of measures obtained from linear functionals by the Riesz representation theorem?,,"In chapter two of Rudin's ""Real and Complex Analysis"" there is a ""Riesz Representation Theorem"" that dominates the chapter. My understanding of the statement of the thm. is that given a complex-valued linear functional, $\lambda$ defined on the set of continuous functions with compact support in a ""nice"" topological space (Hausdorff and locally compact) the theorem states there is a corresponding unique positive complete measure $\mu$ defined on a sigma algebra containing all borel sets in X so that the integral of $f$ w.r.t $\mu$, $\int_{X}{f}d\mu$= $\lambda(f)$. There are a few other parts of the theorem's statement, but I stop here to ask: ""What are some examples of corresponding measures to linear functionals that are not immediately obviously translatable to a measure without the theorem?"" An example I thought of first was a linear functional that gives the n'th coefficient of some function $f$ represented by a polynomial, possibly trigonometric. But I also wondered how differentiation at a point would correspond to a measure. Are these questions well-posed? If so could you help me think about them?","In chapter two of Rudin's ""Real and Complex Analysis"" there is a ""Riesz Representation Theorem"" that dominates the chapter. My understanding of the statement of the thm. is that given a complex-valued linear functional, $\lambda$ defined on the set of continuous functions with compact support in a ""nice"" topological space (Hausdorff and locally compact) the theorem states there is a corresponding unique positive complete measure $\mu$ defined on a sigma algebra containing all borel sets in X so that the integral of $f$ w.r.t $\mu$, $\int_{X}{f}d\mu$= $\lambda(f)$. There are a few other parts of the theorem's statement, but I stop here to ask: ""What are some examples of corresponding measures to linear functionals that are not immediately obviously translatable to a measure without the theorem?"" An example I thought of first was a linear functional that gives the n'th coefficient of some function $f$ represented by a polynomial, possibly trigonometric. But I also wondered how differentiation at a point would correspond to a measure. Are these questions well-posed? If so could you help me think about them?",,"['functional-analysis', 'measure-theory', 'examples-counterexamples', 'riesz-representation-theorem']"
86,Showing when Young's Inequality is in fact equality.,Showing when Young's Inequality is in fact equality.,,The ellipses is where I'm stuck. I don't think a simple algebraic manipulation will work here.,The ellipses is where I'm stuck. I don't think a simple algebraic manipulation will work here.,,"['real-analysis', 'functional-analysis', 'measure-theory']"
87,Why is the set of compact operators closed in the space of all bounded operators between Banach spaces?,Why is the set of compact operators closed in the space of all bounded operators between Banach spaces?,,"Let  $X$  and $Y$ be Banach space. $B(X,Y)$ is the vector space of  all bounded linear maps from $X$ to $Y$. Also,  $K(X,Y)$ is the set of  all compact operators from $X$ to $Y$. Why is   $K(X ,Y)$ is a closed  subspace of $B(X,  Y)$?","Let  $X$  and $Y$ be Banach space. $B(X,Y)$ is the vector space of  all bounded linear maps from $X$ to $Y$. Also,  $K(X,Y)$ is the set of  all compact operators from $X$ to $Y$. Why is   $K(X ,Y)$ is a closed  subspace of $B(X,  Y)$?",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'compact-operators']"
88,Hilbert space with all subspaces closed,Hilbert space with all subspaces closed,,Does there exist an infinite-dimensional Hilbert space with all subspaces closed?,Does there exist an infinite-dimensional Hilbert space with all subspaces closed?,,"['functional-analysis', 'hilbert-spaces']"
89,Show that a finite-dimensional Banach space has a bijective compact operator,Show that a finite-dimensional Banach space has a bijective compact operator,,"It is clear that if $ T: X \rightarrow X $ is a bijective compact operator, where $ X $ is a Banach space, then $ \dim(\text{Range}(T)) = \dim(X) $, which implies that $ \dim(X) $ must be $ < \infty $. How do I prove the converse: If $ \dim(X) < \infty $, then there exists a bijective compact operator $ T: X \rightarrow X $? Thank you!","It is clear that if $ T: X \rightarrow X $ is a bijective compact operator, where $ X $ is a Banach space, then $ \dim(\text{Range}(T)) = \dim(X) $, which implies that $ \dim(X) $ must be $ < \infty $. How do I prove the converse: If $ \dim(X) < \infty $, then there exists a bijective compact operator $ T: X \rightarrow X $? Thank you!",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'compact-operators']"
90,How to find the Hilbert Adjoint operator of $T(f)(t)=\int_{0}^tf(s)\ ds$? [duplicate],How to find the Hilbert Adjoint operator of ? [duplicate],T(f)(t)=\int_{0}^tf(s)\ ds,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Finding the adjoint of an operator Consider the vector space $C[0, 1]$ with inner product, \begin{align*} \langle f, g\rangle=\int_{0}^1f(t)g(t)\ dt. \end{align*} Let $T:C[0, 1]\rightarrow C[0, 1]$ the bounded linear operador given by, \begin{align*} T(f)(t)=\int_{0}^tf(s)\ ds. \end{align*} How can I find the Hilbert adjoint operator $T^*$ of $T$?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Finding the adjoint of an operator Consider the vector space $C[0, 1]$ with inner product, \begin{align*} \langle f, g\rangle=\int_{0}^1f(t)g(t)\ dt. \end{align*} Let $T:C[0, 1]\rightarrow C[0, 1]$ the bounded linear operador given by, \begin{align*} T(f)(t)=\int_{0}^tf(s)\ ds. \end{align*} How can I find the Hilbert adjoint operator $T^*$ of $T$?",,['functional-analysis']
91,function from non separable normed space $X$ onto separable normed space $Y$.,function from non separable normed space  onto separable normed space .,X Y,Can you please give me a simple example of linear continuous mapping from non separable normed space $X$ onto separable normed space $Y$. Thanks a lot.,Can you please give me a simple example of linear continuous mapping from non separable normed space $X$ onto separable normed space $Y$. Thanks a lot.,,"['functional-analysis', 'normed-spaces']"
92,$C_{0}(\mathbb{R})$ is not Hilbert space.,is not Hilbert space.,C_{0}(\mathbb{R}),"The space $C_{0}(\mathbb{R})$ of all complex valued continuous function that vanish outside some finite interval is not an Hilbert space under the inner product $$(f,g)=\int_{-\infty}^{\infty} f(x)\overline{g(x)}\, dx$$ I tried to find out functions such that they violate parallelogram identity, but can't find out. Need help.","The space of all complex valued continuous function that vanish outside some finite interval is not an Hilbert space under the inner product I tried to find out functions such that they violate parallelogram identity, but can't find out. Need help.","C_{0}(\mathbb{R}) (f,g)=\int_{-\infty}^{\infty} f(x)\overline{g(x)}\, dx","['functional-analysis', 'analysis', 'hilbert-spaces', 'inner-products']"
93,When is a convolution equal to a product?,When is a convolution equal to a product?,,"When is a convolution of two functions equal to their product, i.e. when is $f(t) \star g(t) \equiv \int_{-\infty}^\infty \mathrm{d}\tau f(\tau) g(t-\tau)=f(t) g(t)$ ? Or equivalently, when is a Fourier transform of a product equal to the product of the relevant Fourier transforms, $\mathcal{F}[h(\omega) k(\omega)]=\mathcal{F}[h(\omega)] \mathcal{F}[k(\omega)]$ ?","When is a convolution of two functions equal to their product, i.e. when is ? Or equivalently, when is a Fourier transform of a product equal to the product of the relevant Fourier transforms, ?",f(t) \star g(t) \equiv \int_{-\infty}^\infty \mathrm{d}\tau f(\tau) g(t-\tau)=f(t) g(t) \mathcal{F}[h(\omega) k(\omega)]=\mathcal{F}[h(\omega)] \mathcal{F}[k(\omega)],"['functional-analysis', 'fourier-analysis', 'convolution']"
94,"Proving that $B(X,Y) $ is a Banach Space if $Y$ is.",Proving that  is a Banach Space if  is.,"B(X,Y)  Y","Let $B(X,Y)$ be the family of all bounded maps from $X$ to $Y,$ normed linear maps. Then, $B(X,Y) $ is a Banach Space if $Y$ is. Remark: I've seen this question before $Y$ is a Banach space if $B(X,Y)$ is a Banach space , but it is the converse of my question statement. MY TRIAL Let $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ s.t. $T_n\to T,\;\text{as}\;n\to\infty. $ So, $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ implies for each $x\in X,\;T_{n}(x)\in Y.$ Since $Y$ is complete, $T_n(x)\to T(x)\in Y,\;\text{as}\;n\to\infty,\;\forall\;x\in X. $ i.e., $T:X\to Y. $ Also, $T_n\in B(X,Y),\;\forall\;n\in \Bbb{N} $ implies there exists $K\geq 0,$ s.t. $\forall\;n\in \Bbb{N},\;\forall\;x\in X, $ \begin{align} \Vert T_n(x)\Vert \leq K \Vert x\Vert. \end{align} As $n\to\infty,$ \begin{align} \lim\limits_{n\to \infty}\Vert T_n(x)\Vert= \Vert \lim\limits_{n\to \infty}T_n(x)\Vert= \Vert T(x)\Vert\leq K \Vert x\Vert, \end{align} which implies $T\in B(X,Y)$ and hence, $ B(X,Y)$ is a Banach space. Please, kindly check if I'm right or wrong. If it turns out that I'm wrong, kindly provide an alternative proof. Regards!","Let be the family of all bounded maps from to normed linear maps. Then, is a Banach Space if is. Remark: I've seen this question before is a Banach space if is a Banach space , but it is the converse of my question statement. MY TRIAL Let s.t. So, implies for each Since is complete, i.e., Also, implies there exists s.t. As which implies and hence, is a Banach space. Please, kindly check if I'm right or wrong. If it turns out that I'm wrong, kindly provide an alternative proof. Regards!","B(X,Y) X Y, B(X,Y)  Y Y B(X,Y) T_n\in B(X,Y),\;\forall\;n\in \Bbb{N}  T_n\to T,\;\text{as}\;n\to\infty.  T_n\in B(X,Y),\;\forall\;n\in \Bbb{N}  x\in X,\;T_{n}(x)\in Y. Y T_n(x)\to T(x)\in Y,\;\text{as}\;n\to\infty,\;\forall\;x\in X.  T:X\to Y.  T_n\in B(X,Y),\;\forall\;n\in \Bbb{N}  K\geq 0, \forall\;n\in \Bbb{N},\;\forall\;x\in X,  \begin{align} \Vert T_n(x)\Vert \leq K \Vert x\Vert. \end{align} n\to\infty, \begin{align} \lim\limits_{n\to \infty}\Vert T_n(x)\Vert= \Vert \lim\limits_{n\to \infty}T_n(x)\Vert= \Vert T(x)\Vert\leq K \Vert x\Vert, \end{align} T\in B(X,Y)  B(X,Y)","['functional-analysis', 'banach-spaces', 'normed-spaces']"
95,Can a Hamel basis for an infinite-dimensional Hilbert space be orthonormal?,Can a Hamel basis for an infinite-dimensional Hilbert space be orthonormal?,,"For a finite-dimensional Hilbert space, any orthonormal basis is trivially a Hamel basis (because there's only one natural notion of ""basis"" in finite dimensions). But for an infinite-dimensional Hilbert space, no orthonormal basis is a Hamel basis, as proven here . But is it possible for a Hamel basis $B$ for an infinite-dimensional Hilbert space to form an orthonormal set , i.e. $\forall x, y \in B, \langle x, y\rangle = \delta_{xy}$ (the Kronecker delta)? (There are some linguistic issues here, because unfortunately ""a basis that is orthonormal"" is not necessarily the same thing as ""an orthonormal basis"". In the title of my question, I'm refering to an orthonormal set that is also a Hamel basis, not to an orthonormal basis.)","For a finite-dimensional Hilbert space, any orthonormal basis is trivially a Hamel basis (because there's only one natural notion of ""basis"" in finite dimensions). But for an infinite-dimensional Hilbert space, no orthonormal basis is a Hamel basis, as proven here . But is it possible for a Hamel basis $B$ for an infinite-dimensional Hilbert space to form an orthonormal set , i.e. $\forall x, y \in B, \langle x, y\rangle = \delta_{xy}$ (the Kronecker delta)? (There are some linguistic issues here, because unfortunately ""a basis that is orthonormal"" is not necessarily the same thing as ""an orthonormal basis"". In the title of my question, I'm refering to an orthonormal set that is also a Hamel basis, not to an orthonormal basis.)",,"['functional-analysis', 'hilbert-spaces', 'orthonormal', 'hamel-basis']"
96,What's the difference between quasi-concavity and concavity?,What's the difference between quasi-concavity and concavity?,,What's the intuitive difference between quasi-concavity and concavity? Can you give an example of a quasi-concave function that is not concave?,What's the intuitive difference between quasi-concavity and concavity? Can you give an example of a quasi-concave function that is not concave?,,"['real-analysis', 'functional-analysis', 'functions']"
97,Self adjoint operators on a Hilbert space,Self adjoint operators on a Hilbert space,,"Let $H$ be a Hilbert space and let $T\in \mathcal{B}(H)$ such that $T$ is self-adjoint. I want to show that if $T$ is non-zero, then $T^n\neq 0$ for all $n\in \mathbb{N}$. Suppose $n$ be the least positive integer such that $T^n=0$. Then for all $x,y\in H$, we have $\langle T^nx,y\rangle=0\implies \langle T^{n-2}x,T^2y\rangle=0$. Herefrom can I show that $T^{n-1}=0$? If it is possible, then I am done. Please suggest.","Let $H$ be a Hilbert space and let $T\in \mathcal{B}(H)$ such that $T$ is self-adjoint. I want to show that if $T$ is non-zero, then $T^n\neq 0$ for all $n\in \mathbb{N}$. Suppose $n$ be the least positive integer such that $T^n=0$. Then for all $x,y\in H$, we have $\langle T^nx,y\rangle=0\implies \langle T^{n-2}x,T^2y\rangle=0$. Herefrom can I show that $T^{n-1}=0$? If it is possible, then I am done. Please suggest.",,"['functional-analysis', 'hilbert-spaces', 'adjoint-operators']"
98,Everywhere defined operators must be bounded?,Everywhere defined operators must be bounded?,,"I have read in many places that as soon as you have an everywhere defined operator (on a Banach space), it must be automatically bounded, by the Closed Graph Theorem. However, I can't prove this using the Closed Graph Theorem (i.e., I can't prove it would be closed) and I can't find a reference for this. Is this true? Why?","I have read in many places that as soon as you have an everywhere defined operator (on a Banach space), it must be automatically bounded, by the Closed Graph Theorem. However, I can't prove this using the Closed Graph Theorem (i.e., I can't prove it would be closed) and I can't find a reference for this. Is this true? Why?",,"['functional-analysis', 'operator-theory']"
99,Does every abelian C* algebra have a single self-adjoint generator?,Does every abelian C* algebra have a single self-adjoint generator?,,Does an abelian von Neumann algebra have this property? Is there some interesting class of C* algebras that does?,Does an abelian von Neumann algebra have this property? Is there some interesting class of C* algebras that does?,,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'functional-calculus']"
