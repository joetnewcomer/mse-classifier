,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,If a set contains all accumulation points then it is closed,If a set contains all accumulation points then it is closed,,"It is a question from my complex analysis courses; If a set contains all accumulation points then it is closed Our accumulation point definition is “if a point is an accumulation point of set $S$ , every deleted neighborhood of it contains at least one point of $S$ ” Our closed set definition is “if a set is closed then it contains all boundary points” I cannot prove it without contradiction. I need direct proof. I am confused in does accumulation point mean boundary point? I need your helps. Thanks in advance","It is a question from my complex analysis courses; If a set contains all accumulation points then it is closed Our accumulation point definition is “if a point is an accumulation point of set , every deleted neighborhood of it contains at least one point of ” Our closed set definition is “if a set is closed then it contains all boundary points” I cannot prove it without contradiction. I need direct proof. I am confused in does accumulation point mean boundary point? I need your helps. Thanks in advance",S S,"['complex-analysis', 'analysis']"
1,Justification for a real number to a complex power,Justification for a real number to a complex power,,"I searched extensively online and found that everyone would agree with the following: $2^i = e^{\log{2^i}} = e^{i*\log{2}}$ . About the second equality (taking the $i$ out of the $\log$ ), it seems natural. But I cannot justify this myself. I understand that, $\log(z1*z2) = \log(z1)+\log(z2)$ , and therefore, if I have something like $\log(i^2)$ , then it's just $\log(i*i) = \log(i) + \log(i) = 2\log(i)$ , but this is because we have a rational exponent. How can I do the similar thing for $2^i$ ? Or is there some other way to justify the step pulling the $i$ out of the $log$ ? Thanks very much!","I searched extensively online and found that everyone would agree with the following: . About the second equality (taking the out of the ), it seems natural. But I cannot justify this myself. I understand that, , and therefore, if I have something like , then it's just , but this is because we have a rational exponent. How can I do the similar thing for ? Or is there some other way to justify the step pulling the out of the ? Thanks very much!",2^i = e^{\log{2^i}} = e^{i*\log{2}} i \log \log(z1*z2) = \log(z1)+\log(z2) \log(i^2) \log(i*i) = \log(i) + \log(i) = 2\log(i) 2^i i log,"['complex-analysis', 'complex-numbers']"
2,Evaluating complex integral $\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} $ via different contour,Evaluating complex integral  via different contour,\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} ,"I got an complex integral $\int_{0}^{\pi} \frac {x \sin > x}{1+a^2-2a(\cos x)} $ for $a \ge 1$ and my given contour is a   rectangle such that $|Re(z)|\le \pi$ and $0 \le |Im(z)| \le h \to  \infty$. I can rewrite the integral as $\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} =1/2\int_{- \pi}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} $ and use the substitution: $z = e^{ix}$, $\;$ $\cos x = \frac {e^{ix}-e^{-ix}}{2} = \frac {z + \frac {1}{z}}{2}$,$\;$ $dz = ie^{ix}dx$ We then received the expression for $f(z)$ as $\frac {z(-i)}{1+a^2-a(\frac {1}{z}+z)} $ and we want to find the singularities of this function. After some algebra, we get that we have two singularities at $z = a$ $\;$ & $\;$$z = \frac {1}{a}$, which are poles of the first order. To evaluate that integral we are going to use the residue theorem: $res_a = \lim_{\to a} \frac {z(-i)}{(z-1/a)}= \frac {a(-i)}{(a-1/a)}$ $res_{1/a} = \lim_{\to 1/a} \frac {z(-i)}{(z-a)}=\frac {1/a(-i)}{(-a+1/a)}$ and then $I = 2i\pi (res_a+res_{1/a})$ But this looks like the result if we were integrating around unit circle and I don't understand how that different contour changes the result to $I = \frac {\pi}{2} \frac {Ln(a+1)}{Ln(a)}$, according to my textbook. I was thinking about plugging the residues back to $z = e^{ix}$, but I don't understand how do I get that '+1', etc. There was posted the same integral, but I am interested in that different integration contour.","I got an complex integral $\int_{0}^{\pi} \frac {x \sin > x}{1+a^2-2a(\cos x)} $ for $a \ge 1$ and my given contour is a   rectangle such that $|Re(z)|\le \pi$ and $0 \le |Im(z)| \le h \to  \infty$. I can rewrite the integral as $\int_{0}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} =1/2\int_{- \pi}^{\pi} \frac {x \sin x}{1+a^2-2a(\cos x)} $ and use the substitution: $z = e^{ix}$, $\;$ $\cos x = \frac {e^{ix}-e^{-ix}}{2} = \frac {z + \frac {1}{z}}{2}$,$\;$ $dz = ie^{ix}dx$ We then received the expression for $f(z)$ as $\frac {z(-i)}{1+a^2-a(\frac {1}{z}+z)} $ and we want to find the singularities of this function. After some algebra, we get that we have two singularities at $z = a$ $\;$ & $\;$$z = \frac {1}{a}$, which are poles of the first order. To evaluate that integral we are going to use the residue theorem: $res_a = \lim_{\to a} \frac {z(-i)}{(z-1/a)}= \frac {a(-i)}{(a-1/a)}$ $res_{1/a} = \lim_{\to 1/a} \frac {z(-i)}{(z-a)}=\frac {1/a(-i)}{(-a+1/a)}$ and then $I = 2i\pi (res_a+res_{1/a})$ But this looks like the result if we were integrating around unit circle and I don't understand how that different contour changes the result to $I = \frac {\pi}{2} \frac {Ln(a+1)}{Ln(a)}$, according to my textbook. I was thinking about plugging the residues back to $z = e^{ix}$, but I don't understand how do I get that '+1', etc. There was posted the same integral, but I am interested in that different integration contour.",,"['integration', 'complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus']"
3,A topological proof of the Nullhomotopical Cauchy Integral Formula from the Circle Cauchy Integral Formula,A topological proof of the Nullhomotopical Cauchy Integral Formula from the Circle Cauchy Integral Formula,,"I believe there should be a simple topological proof of the Nullhomotopical Cauchy Integral Formula based only on the Cauchy Integral Formula over a Circle, but I can't quite finish the argument and would appreciate some help. (Hopefully I am on the right track.) Nullhomotopical Cauchy Integral Formula : Let $U\subseteq\mathbb{C}$ be an open and path-connected subset, let $z_0\in U$, and let $\gamma\subseteq U$ be some, say, smooth loop such that $z_0\notin\gamma$ and $\gamma\simeq\rm{pt.}$ in $U$, where by abuse of notation $\gamma$ stands for both the curve and its support. If $f:U\to\mathbb{C}$ is a holomorphic function, then: $$ f(z_0)\operatorname{ind}(\gamma,z_0) = \frac{1}{2\pi i}\oint_\gamma\frac{f(z)}{z-z_0}\mathrm{d}z $$ Attempted proof: I know that, being holomorphic, the 1-form $$ \omega:=\frac{f(z)}{z-z_0}\mathrm{d}z $$ is $\mathrm{d}$-closed, hence (its integral is) homotopy-invariant. Since $\gamma\subseteq U\setminus\{z_0\}$ and $[\gamma]=0$ in $\pi_1(U)$, I believe that $[\gamma]$ should induce a well-defined class $[\gamma]'$ in $\pi_1(D\setminus\{z_0\})$, where $D$ is a sufficiently small open disk around $z_0$ contained in $U$, but I don't quite see how to finish this line of reasoning rigorously, assuming it actually makes sense. Any help would be appreciated!","I believe there should be a simple topological proof of the Nullhomotopical Cauchy Integral Formula based only on the Cauchy Integral Formula over a Circle, but I can't quite finish the argument and would appreciate some help. (Hopefully I am on the right track.) Nullhomotopical Cauchy Integral Formula : Let $U\subseteq\mathbb{C}$ be an open and path-connected subset, let $z_0\in U$, and let $\gamma\subseteq U$ be some, say, smooth loop such that $z_0\notin\gamma$ and $\gamma\simeq\rm{pt.}$ in $U$, where by abuse of notation $\gamma$ stands for both the curve and its support. If $f:U\to\mathbb{C}$ is a holomorphic function, then: $$ f(z_0)\operatorname{ind}(\gamma,z_0) = \frac{1}{2\pi i}\oint_\gamma\frac{f(z)}{z-z_0}\mathrm{d}z $$ Attempted proof: I know that, being holomorphic, the 1-form $$ \omega:=\frac{f(z)}{z-z_0}\mathrm{d}z $$ is $\mathrm{d}$-closed, hence (its integral is) homotopy-invariant. Since $\gamma\subseteq U\setminus\{z_0\}$ and $[\gamma]=0$ in $\pi_1(U)$, I believe that $[\gamma]$ should induce a well-defined class $[\gamma]'$ in $\pi_1(D\setminus\{z_0\})$, where $D$ is a sufficiently small open disk around $z_0$ contained in $U$, but I don't quite see how to finish this line of reasoning rigorously, assuming it actually makes sense. Any help would be appreciated!",,"['complex-analysis', 'algebraic-topology']"
4,Linear and algebraic independence of exponentials,Linear and algebraic independence of exponentials,,"Original question Let $P_1,\ldots, P_n$ be distinct polynomials of a complex variable. We suppose that they are without constant term ( $P_i(0)=0$ ). Is it true that the functions $z\mapsto e^{P_i(z)}$ are linearly independant (over $\mathbb{C}$ ) ? Late edit: The proof given in the selected answer proves the following Theorem Let $(P_i)_{i\in I}$ a family of complex univarariate polynomials without constant term. Then if $i\mapsto P_i$ is injective, $(e^{P_i})_{i\in I}$ is a family of (entire) functions linearly independent over $\mathbb{C}[z]$ . One then has the Corollary Under the same conditions (no constant term), if the family $(P_i)_{i\in I}$ is $\mathbb{Z}$ -independant, then $(e^{P_i})_{i\in I}$ is algebraically independant with respect to $\mathbb{C}[z]$ . Proof Call $G$ the family of exponentials ( $G=(e^{P_i})_{i\in I}$ ). For every multiindex $\alpha \in \mathbb{N}^{(I)}$ , one has $$ G^\alpha=\prod_{i\in I} (e^{P_i})^{\alpha(i)}= \prod_{i\in I} (e^{\alpha(i)\,P_i})= e^{\sum_{i\in I}\alpha(i)\,P_i} $$ but the fact that $(P_i)_{i\in I}$ is $\mathbb{Z}$ -independant (linearly) implies (and is indeed equivalent to) $\alpha \mapsto \sum_{i\in I}\alpha(i)\,P_i$ is into. One has, from the theorem, that $(G^\alpha)_{\alpha \in \mathbb{N}^{(I)}}$ is $\mathbb{C}[z]$ -linearly independant which amounts to say that $G$ is algebraically independant over $\mathbb{C}[z]$ .","Original question Let be distinct polynomials of a complex variable. We suppose that they are without constant term ( ). Is it true that the functions are linearly independant (over ) ? Late edit: The proof given in the selected answer proves the following Theorem Let a family of complex univarariate polynomials without constant term. Then if is injective, is a family of (entire) functions linearly independent over . One then has the Corollary Under the same conditions (no constant term), if the family is -independant, then is algebraically independant with respect to . Proof Call the family of exponentials ( ). For every multiindex , one has but the fact that is -independant (linearly) implies (and is indeed equivalent to) is into. One has, from the theorem, that is -linearly independant which amounts to say that is algebraically independant over .","P_1,\ldots, P_n P_i(0)=0 z\mapsto e^{P_i(z)} \mathbb{C} (P_i)_{i\in I} i\mapsto P_i (e^{P_i})_{i\in I} \mathbb{C}[z] (P_i)_{i\in I} \mathbb{Z} (e^{P_i})_{i\in I} \mathbb{C}[z] G G=(e^{P_i})_{i\in I} \alpha \in \mathbb{N}^{(I)} 
G^\alpha=\prod_{i\in I} (e^{P_i})^{\alpha(i)}=
\prod_{i\in I} (e^{\alpha(i)\,P_i})=
e^{\sum_{i\in I}\alpha(i)\,P_i}
 (P_i)_{i\in I} \mathbb{Z} \alpha \mapsto \sum_{i\in I}\alpha(i)\,P_i (G^\alpha)_{\alpha \in \mathbb{N}^{(I)}} \mathbb{C}[z] G \mathbb{C}[z]","['calculus', 'complex-analysis', 'holomorphic-functions']"
5,How to properly deduce the Holomorphic Implicit Function Theorem from the Smooth Real Implicit Function Theorem?,How to properly deduce the Holomorphic Implicit Function Theorem from the Smooth Real Implicit Function Theorem?,,"I have seen at several places, incl. some notes and books, the following inference of the Holomorphic Implicit Function Theorem from the Smooth Real Function Theorem, but I believe this proof to be incorrect or rather incomplete in that it seems to be missing a non-obvious key step. I would like to know how to complete the proof if possible at all. Please note that there are of course other proofs of the Holomorphic Implicit Function Theorem that work, but my question is not about them, but about fixing this one. So, let me illustrate what I have in mind in the case of 2 complex variables: Hol. Impl. Funct. Thm. in 2 var.-s : Let $U,V \subseteq \mathbb{C}$ be open subsets and let $f:U \times V \to \mathbb{C}$ be a holomorphic function. Let $(z_0,w_0) \in U \times V$ be a point such that $f(z_0,w_0) = 0$ and $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$. Then $z_0$ has an open neighbourhood $\widetilde{U} \subseteq U$ such that there exists a holomorphic function $g: \widetilde{U} \to \mathbb{C}$ with the property $g(z_0)=w_0$ and $\forall z\in \widetilde{U}: f(z,g(z)) = 0$. Proof: By the Real Smooth Implicit Function Theorem there exist an open neighbourhood $\widetilde{U}\ni z_0$, $\widetilde{U}\subseteq U$, and a smooth $g:\widetilde{U} \to \mathbb{C}$ such that $\forall z \in \widetilde{U}: f(z,g(z))=0$ as smooth functions. Thus we only need to show that $g$ is holomorphic in $\widetilde{U}$. Since $f$ is holomorphic in both variables, one computes $$ 0 = \frac{\partial}{\partial\bar{z}} f(z,g(z)) = \frac{\partial f}{\partial w}(z,g(z)) \frac{\partial g}{\partial\bar{z}}, $$ hence at $(z_0,w_0)$ $$ 0 = \frac{\partial f}{\partial w}(z_0,w_0) \frac{\partial g}{\partial\bar{z}}(z_0), $$ from where it follows that $\frac{\partial g}{\partial\bar{z}}(z_0)=0$ since $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$ by hypothesis. $\Box$ The problem: this only shows that $g$ is complex-differentiable at the point $z_0\in\widetilde{U}$ rather than in all of $\widetilde{U}$, and none of the proofs I have seen actually justifies why the reasoning should extend to the whole neighbourhood. Attempt to rectify the problem : by continuity of $\frac{\partial f}{\partial w}$ there are neighbourhoods $U'\ni z_0$ and $V'\ni w_0$ such that $\forall (z,w)\in U'\times V': \frac{\partial f}{\partial w}(z,w)\neq 0$. So we can take $\widetilde{U}\cap U'$ instead, but this does not suffice because we only know that $g(\widetilde{U}\cap U')\cap V' \ni w_0$, so we don't actually have that $$ \forall z\in \widetilde{U}\cap U': \frac{\partial f}{\partial w}(z,g(z))\neq 0. $$ Is there a way to salvage this proof without resorting to a completely different proof strategy? (For example, a completely different strategy would be to invoke the Holomorphic Inverse Function Theorem.) Feel free to add or remove tags as you see fit.","I have seen at several places, incl. some notes and books, the following inference of the Holomorphic Implicit Function Theorem from the Smooth Real Function Theorem, but I believe this proof to be incorrect or rather incomplete in that it seems to be missing a non-obvious key step. I would like to know how to complete the proof if possible at all. Please note that there are of course other proofs of the Holomorphic Implicit Function Theorem that work, but my question is not about them, but about fixing this one. So, let me illustrate what I have in mind in the case of 2 complex variables: Hol. Impl. Funct. Thm. in 2 var.-s : Let $U,V \subseteq \mathbb{C}$ be open subsets and let $f:U \times V \to \mathbb{C}$ be a holomorphic function. Let $(z_0,w_0) \in U \times V$ be a point such that $f(z_0,w_0) = 0$ and $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$. Then $z_0$ has an open neighbourhood $\widetilde{U} \subseteq U$ such that there exists a holomorphic function $g: \widetilde{U} \to \mathbb{C}$ with the property $g(z_0)=w_0$ and $\forall z\in \widetilde{U}: f(z,g(z)) = 0$. Proof: By the Real Smooth Implicit Function Theorem there exist an open neighbourhood $\widetilde{U}\ni z_0$, $\widetilde{U}\subseteq U$, and a smooth $g:\widetilde{U} \to \mathbb{C}$ such that $\forall z \in \widetilde{U}: f(z,g(z))=0$ as smooth functions. Thus we only need to show that $g$ is holomorphic in $\widetilde{U}$. Since $f$ is holomorphic in both variables, one computes $$ 0 = \frac{\partial}{\partial\bar{z}} f(z,g(z)) = \frac{\partial f}{\partial w}(z,g(z)) \frac{\partial g}{\partial\bar{z}}, $$ hence at $(z_0,w_0)$ $$ 0 = \frac{\partial f}{\partial w}(z_0,w_0) \frac{\partial g}{\partial\bar{z}}(z_0), $$ from where it follows that $\frac{\partial g}{\partial\bar{z}}(z_0)=0$ since $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$ by hypothesis. $\Box$ The problem: this only shows that $g$ is complex-differentiable at the point $z_0\in\widetilde{U}$ rather than in all of $\widetilde{U}$, and none of the proofs I have seen actually justifies why the reasoning should extend to the whole neighbourhood. Attempt to rectify the problem : by continuity of $\frac{\partial f}{\partial w}$ there are neighbourhoods $U'\ni z_0$ and $V'\ni w_0$ such that $\forall (z,w)\in U'\times V': \frac{\partial f}{\partial w}(z,w)\neq 0$. So we can take $\widetilde{U}\cap U'$ instead, but this does not suffice because we only know that $g(\widetilde{U}\cap U')\cap V' \ni w_0$, so we don't actually have that $$ \forall z\in \widetilde{U}\cap U': \frac{\partial f}{\partial w}(z,g(z))\neq 0. $$ Is there a way to salvage this proof without resorting to a completely different proof strategy? (For example, a completely different strategy would be to invoke the Holomorphic Inverse Function Theorem.) Feel free to add or remove tags as you see fit.",,"['complex-analysis', 'complex-geometry', 'riemann-surfaces', 'several-complex-variables']"
6,Showing the Composition of Two Polynomials is a Polynomial and the Composition of Two Rational Functions is a Rational Function,Showing the Composition of Two Polynomials is a Polynomial and the Composition of Two Rational Functions is a Rational Function,,"This seems very obvious and I am having a bit of trouble producing a formal proof. sketch proof that the composition of two polynomials is a polynomial Let $$p(z_1)=a_nz^n_1+a_{n-1}z^{n-1}_1+...+a_1z_1+a_0 \\ q(z_2)=b_nz^n_2+b_{n-1}z^{n-1}_2+...+b_1z_2+b_0$$ be two complex polynomials of degree $n$ where $a_n,..,a_0\in\mathbb{C}$ and $b_n,..,b_o\in\mathbb{C}$. Now,  \begin{align} (p\circ q)(z_2)&=p(q(z_2)) \ \ \ \ \ \text{(by definition)}\\ &=a_n(q(z_2))^n+a_{n-1}(q(z_2))^{n-1}+...+a_1(q(z_2))+a_0 \end{align} which is clearly a complex polynomial of degree $n^2$. sketch proof that the composition of two rational functions is a rational function A rational function is a quotient of polynomials. Let $$a(z_1)=\frac{p(z_1)}{q(z_1)}, \ b(z_2)=\frac{p(z_2)}{q(z_2)}$$ Now,  \begin{align} (a\circ b)(z_2)&=a(b(z_2)) \ \ \ \ \ \text{(by definition)} \\ &=\frac{p\left(\frac{p(z_2)}{q(z_2)}\right)}{q\left(\frac{p(z_2)}{q(z_2)}\right)} \\ &=\frac{a_n\left(\frac{p(z_2)}{q(z_2)}\right)^n+a_{n-1}\left(\frac{p(z_2)}{q(z_2)}\right)^{n-1}+...+a_1\left(\frac{p(z_2)}{q(z_2)}\right)+a_0}{b_n\left(\frac{p(z_2)}{q(z_2)}\right)^n+b_{n-1}\left(\frac{p(z_2)}{q(z_2)}\right)^{n-1}+...+b_1\left(\frac{p(z_2)}{q(z_2)}\right)+b_0} \\ \end{align} Notice that $\left(\frac{p(z_2)}{q(z_2)}\right)^i \ \ \ \ (i=n, n-1,..,0)$ is a polynomial as  $$(f\circ g)(z_2)=f(g(z_2))=\left(\frac{p(z_2)}{q(z_2)}\right)^i$$ where $$f(x)=x^i, \ \ g(z_2)=\left(\frac{p(z_2)}{q(z_2)}\right)$$ are both polynomials.  Hence $(a\circ b)(z_2)$ is a rational function as it is the quotient of polynomials.","This seems very obvious and I am having a bit of trouble producing a formal proof. sketch proof that the composition of two polynomials is a polynomial Let $$p(z_1)=a_nz^n_1+a_{n-1}z^{n-1}_1+...+a_1z_1+a_0 \\ q(z_2)=b_nz^n_2+b_{n-1}z^{n-1}_2+...+b_1z_2+b_0$$ be two complex polynomials of degree $n$ where $a_n,..,a_0\in\mathbb{C}$ and $b_n,..,b_o\in\mathbb{C}$. Now,  \begin{align} (p\circ q)(z_2)&=p(q(z_2)) \ \ \ \ \ \text{(by definition)}\\ &=a_n(q(z_2))^n+a_{n-1}(q(z_2))^{n-1}+...+a_1(q(z_2))+a_0 \end{align} which is clearly a complex polynomial of degree $n^2$. sketch proof that the composition of two rational functions is a rational function A rational function is a quotient of polynomials. Let $$a(z_1)=\frac{p(z_1)}{q(z_1)}, \ b(z_2)=\frac{p(z_2)}{q(z_2)}$$ Now,  \begin{align} (a\circ b)(z_2)&=a(b(z_2)) \ \ \ \ \ \text{(by definition)} \\ &=\frac{p\left(\frac{p(z_2)}{q(z_2)}\right)}{q\left(\frac{p(z_2)}{q(z_2)}\right)} \\ &=\frac{a_n\left(\frac{p(z_2)}{q(z_2)}\right)^n+a_{n-1}\left(\frac{p(z_2)}{q(z_2)}\right)^{n-1}+...+a_1\left(\frac{p(z_2)}{q(z_2)}\right)+a_0}{b_n\left(\frac{p(z_2)}{q(z_2)}\right)^n+b_{n-1}\left(\frac{p(z_2)}{q(z_2)}\right)^{n-1}+...+b_1\left(\frac{p(z_2)}{q(z_2)}\right)+b_0} \\ \end{align} Notice that $\left(\frac{p(z_2)}{q(z_2)}\right)^i \ \ \ \ (i=n, n-1,..,0)$ is a polynomial as  $$(f\circ g)(z_2)=f(g(z_2))=\left(\frac{p(z_2)}{q(z_2)}\right)^i$$ where $$f(x)=x^i, \ \ g(z_2)=\left(\frac{p(z_2)}{q(z_2)}\right)$$ are both polynomials.  Hence $(a\circ b)(z_2)$ is a rational function as it is the quotient of polynomials.",,"['complex-analysis', 'functions']"
7,Sum over all inverse zeta nontrivial zeros,Sum over all inverse zeta nontrivial zeros,,Starting from the Hadamard product for the Riemann Zeta Function (assuming the product is taken over matching pairs of zeros) $$\zeta(s)=\frac{e^{(\log(2\pi)-1-\gamma/2)s}}{2(s-1)\Gamma(1+s/2)}\prod_{\rho}\left(1-\frac{s}{\rho} \right)e^{s/\rho}$$ can one derive the exact value of $\sum_{\rho} \frac{1}{\rho}$ to be $$\sum_{\rho} \frac{1}{\rho} = -\log(2\sqrt{\pi})+1+\gamma/2$$ What implications does this have?,Starting from the Hadamard product for the Riemann Zeta Function (assuming the product is taken over matching pairs of zeros) $$\zeta(s)=\frac{e^{(\log(2\pi)-1-\gamma/2)s}}{2(s-1)\Gamma(1+s/2)}\prod_{\rho}\left(1-\frac{s}{\rho} \right)e^{s/\rho}$$ can one derive the exact value of $\sum_{\rho} \frac{1}{\rho}$ to be $$\sum_{\rho} \frac{1}{\rho} = -\log(2\sqrt{\pi})+1+\gamma/2$$ What implications does this have?,,"['complex-analysis', 'riemann-zeta']"
8,Singularity Type Of $f(z^2+z)$,Singularity Type Of,f(z^2+z),"$f(z)$ has essential singularity at $z=0$, what type of singularity $f(z^2+z)$ has? $f(z)$ has essential singularity at $z=0$ so it can be written has $\sum_{n=0}^{-\infty} c_nz^n=c_0+\frac{c_{-1}}{z}+\frac{c_{-2}}{z^2}+...+$ substituting $z=z^2+z$ will leave all the power to be negative e.g  $c_0+\frac{c_{-1}}{z^2+z}+\frac{c_{-2}}{(z^2+z)^2}+...+$ So $f(z^2+z)$ has essential singularity too, moreover can we even ""get rid"" of essential singularity?","$f(z)$ has essential singularity at $z=0$, what type of singularity $f(z^2+z)$ has? $f(z)$ has essential singularity at $z=0$ so it can be written has $\sum_{n=0}^{-\infty} c_nz^n=c_0+\frac{c_{-1}}{z}+\frac{c_{-2}}{z^2}+...+$ substituting $z=z^2+z$ will leave all the power to be negative e.g  $c_0+\frac{c_{-1}}{z^2+z}+\frac{c_{-2}}{(z^2+z)^2}+...+$ So $f(z^2+z)$ has essential singularity too, moreover can we even ""get rid"" of essential singularity?",,"['complex-analysis', 'singularity']"
9,$\int_0^\infty \frac{\sqrt x}{1+x^4} dx$ by residues,by residues,\int_0^\infty \frac{\sqrt x}{1+x^4} dx,"Evaluate $\int_0^\infty \frac{\sqrt x}{1+x^4} dx$ I think I'm on the right path, but I'm not getting the right answer (which is $\frac{\pi}{4 \cos(\frac{\pi}{8})}$). Here is what I have done: Define $f(z) = \frac{\sqrt z}{1+z^4}$ on the upper half circle $\alpha$. The singularities inside this half circle are $w_1 = e^{\frac{\pi i}{4}}$ and $w_2 = -e^{\frac{-\pi i}{4}} = - \bar{w_1}$. Then the integral can be calculated as follows: $$\oint_\alpha f(z) \,dz = 2\pi i (Res(f,w_1)+Res(f,w_2))$$ Calculating residues: $Res(f,w_1) = \frac{\sqrt w_1}{4w_1^3} = \frac{e^{\frac{- \pi i}{8}}}{4i}$ $Res(f,w_2) = \frac{\sqrt w_2}{4w_2^3} = \frac{e^{\frac{ \pi i}{8}}}{4}$ From this, I can already see that this won't give me the right answer, since the final answer does not contain $i$ and my $cos$ is in the numerator ($e^{\frac{- \pi i}{8}} + e^{\frac{ \pi i}{8}} = 2cos(\frac{\pi}{8}))$ Some help would be appreciated! May be I made some mistakes calculating the residues?","Evaluate $\int_0^\infty \frac{\sqrt x}{1+x^4} dx$ I think I'm on the right path, but I'm not getting the right answer (which is $\frac{\pi}{4 \cos(\frac{\pi}{8})}$). Here is what I have done: Define $f(z) = \frac{\sqrt z}{1+z^4}$ on the upper half circle $\alpha$. The singularities inside this half circle are $w_1 = e^{\frac{\pi i}{4}}$ and $w_2 = -e^{\frac{-\pi i}{4}} = - \bar{w_1}$. Then the integral can be calculated as follows: $$\oint_\alpha f(z) \,dz = 2\pi i (Res(f,w_1)+Res(f,w_2))$$ Calculating residues: $Res(f,w_1) = \frac{\sqrt w_1}{4w_1^3} = \frac{e^{\frac{- \pi i}{8}}}{4i}$ $Res(f,w_2) = \frac{\sqrt w_2}{4w_2^3} = \frac{e^{\frac{ \pi i}{8}}}{4}$ From this, I can already see that this won't give me the right answer, since the final answer does not contain $i$ and my $cos$ is in the numerator ($e^{\frac{- \pi i}{8}} + e^{\frac{ \pi i}{8}} = 2cos(\frac{\pi}{8}))$ Some help would be appreciated! May be I made some mistakes calculating the residues?",,['complex-analysis']
10,entire function that maps real line to itself is linear [duplicate],entire function that maps real line to itself is linear [duplicate],,"This question already has an answer here : Holomorphic function satisfying $f^{-1}(\Bbb R)=\Bbb R$ is of the form $f(z)=az+b$ (1 answer) Closed 3 years ago . Let $f:\mathbb{C}\to\mathbb{C}$ be an entire function be such that $\mathbb{R}=f^{-1}(\mathbb{R})$. Show that $f$ is linear. i.e. $$\exists\ a,b\in\mathbb{R}:f(z)=az+b$$ Hint I think that $f$ must map the upper half plane and lower half plane to certain two disconnected open sets. Maybe, if we can show that $f$ is a mobius transformation, then we can then we can look at $$g(z)=\frac{f(z)-f(0)}{z}$$ and finish.","This question already has an answer here : Holomorphic function satisfying $f^{-1}(\Bbb R)=\Bbb R$ is of the form $f(z)=az+b$ (1 answer) Closed 3 years ago . Let $f:\mathbb{C}\to\mathbb{C}$ be an entire function be such that $\mathbb{R}=f^{-1}(\mathbb{R})$. Show that $f$ is linear. i.e. $$\exists\ a,b\in\mathbb{R}:f(z)=az+b$$ Hint I think that $f$ must map the upper half plane and lower half plane to certain two disconnected open sets. Maybe, if we can show that $f$ is a mobius transformation, then we can then we can look at $$g(z)=\frac{f(z)-f(0)}{z}$$ and finish.",,"['complex-analysis', 'entire-functions']"
11,Holomorphic function which is zero at every lattice point,Holomorphic function which is zero at every lattice point,,"Suppose that $f:\mathbb C \to \mathbb C$ is holomorphic and not identically zero, and that $f$ has a zero at every lattice point (point with integer coordinates) except for $(0,0)$. Show that there is a constant $c>0$ such that $|F(z_i)|>e^{c|z_i|^2}$ for a sequence $z_1,z_2,\ldots$ of complex numbers tending to infinity. If we take the supremum of $F$ over each circle of radius $R$, this should give a correct sequence (taking $R=1,2,\ldots$). I am not sure how to come up with a lower bound though.","Suppose that $f:\mathbb C \to \mathbb C$ is holomorphic and not identically zero, and that $f$ has a zero at every lattice point (point with integer coordinates) except for $(0,0)$. Show that there is a constant $c>0$ such that $|F(z_i)|>e^{c|z_i|^2}$ for a sequence $z_1,z_2,\ldots$ of complex numbers tending to infinity. If we take the supremum of $F$ over each circle of radius $R$, this should give a correct sequence (taking $R=1,2,\ldots$). I am not sure how to come up with a lower bound though.",,['complex-analysis']
12,Show that $\sum\limits_{n=0}^{\infty} \binom{3n}{n} (\frac{4}{125})^n=\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz$,Show that,\sum\limits_{n=0}^{\infty} \binom{3n}{n} (\frac{4}{125})^n=\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz,"Define $C(0;1)$ to be the circle with center $0$ and radius $1$ traversed in the counterclockwise direction. Show that    $$\sum\limits_{n=0}^{\infty} \binom{3n}{n} \left(\frac{4}{125}\right)^n=\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz \tag{1}$$ I know that $$4z^2+28z-1=4\left(z-\frac{-7+5\sqrt 2}{2}\right)\left(z-\frac{-7-5\sqrt 2}{2}\right)$$ and I managed to show that $$\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz=\frac{15\sqrt 2}{28} +\frac{5}{14}$$ by Cauchy's Integral Formula where $z=\frac{-7+5\sqrt 2}{2}$ is the only singularity in $C(0;1)$. Now my question is, is there a way to show $(1)$ by Laurent series expansion along with the binomial identity? I am clueless as to how I can proceed.","Define $C(0;1)$ to be the circle with center $0$ and radius $1$ traversed in the counterclockwise direction. Show that    $$\sum\limits_{n=0}^{\infty} \binom{3n}{n} \left(\frac{4}{125}\right)^n=\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz \tag{1}$$ I know that $$4z^2+28z-1=4\left(z-\frac{-7+5\sqrt 2}{2}\right)\left(z-\frac{-7-5\sqrt 2}{2}\right)$$ and I managed to show that $$\frac{1}{2\pi i}\int_{C(0;1)}\frac{-125}{(z-4)(4z^2+28z-1)}dz=\frac{15\sqrt 2}{28} +\frac{5}{14}$$ by Cauchy's Integral Formula where $z=\frac{-7+5\sqrt 2}{2}$ is the only singularity in $C(0;1)$. Now my question is, is there a way to show $(1)$ by Laurent series expansion along with the binomial identity? I am clueless as to how I can proceed.",,"['complex-analysis', 'complex-integration', 'binomial-theorem', 'cauchy-integral-formula']"
13,Let $f$ be entire. Assume that the function $g(z) = f(z)f(\frac{1}{z})$ is bounded on $\mathbb{C}-\{0\}$. Show that $f(z)=cz^m$,Let  be entire. Assume that the function  is bounded on . Show that,f g(z) = f(z)f(\frac{1}{z}) \mathbb{C}-\{0\} f(z)=cz^m,"This is what I have tried so far: Since $g(z)$ is bounded, then $\lim\limits_{z\rightarrow 0} zg(z)=0$ and hence $z=0$ is a removable singularity of $g(z)$. We can define $g(0) = \lim\limits_{z\rightarrow 0} f(z)f(\frac{1}{z})$ and make $g$ entire. Then $g(z)$ is a bounded entire function and hence $g$ is a constant function. In other words, $f(z)f(\frac{1}{z}) = c$ for some $c\in\mathbb{C}$ and for $z\neq 0$ I don't know how to continue from this step. I tried to prove that $f(\frac{1}{z})$ has either a pole or a removable singularity at $z=0$ to show first that $f(z)$ is a polynomial or a constant but I failed.","This is what I have tried so far: Since $g(z)$ is bounded, then $\lim\limits_{z\rightarrow 0} zg(z)=0$ and hence $z=0$ is a removable singularity of $g(z)$. We can define $g(0) = \lim\limits_{z\rightarrow 0} f(z)f(\frac{1}{z})$ and make $g$ entire. Then $g(z)$ is a bounded entire function and hence $g$ is a constant function. In other words, $f(z)f(\frac{1}{z}) = c$ for some $c\in\mathbb{C}$ and for $z\neq 0$ I don't know how to continue from this step. I tried to prove that $f(\frac{1}{z})$ has either a pole or a removable singularity at $z=0$ to show first that $f(z)$ is a polynomial or a constant but I failed.",,['complex-analysis']
14,Evaluating Trig Integrals with Residues,Evaluating Trig Integrals with Residues,,"Use residue theorem to establish the integration formula:   $$\int_0^{2\pi} \frac{\cos^2(3\theta)}{5-4\cos(2\theta)}d\theta = \frac{3\pi}{8}$$ Hi, so I'm stuck on this question. I've gotten up to computing the residues as being $z_{+/-} = 1/\sqrt2$ and $z = 0$ though I'm not sure how to go from here. EDIT: Okay I've gotten to the point of knowing that the value of the integral is equal to the sum of the residues at each singularity, though I am having difficulty with computing the residue at $z = 0$. That is the only issue I'm having left.","Use residue theorem to establish the integration formula:   $$\int_0^{2\pi} \frac{\cos^2(3\theta)}{5-4\cos(2\theta)}d\theta = \frac{3\pi}{8}$$ Hi, so I'm stuck on this question. I've gotten up to computing the residues as being $z_{+/-} = 1/\sqrt2$ and $z = 0$ though I'm not sure how to go from here. EDIT: Okay I've gotten to the point of knowing that the value of the integral is equal to the sum of the residues at each singularity, though I am having difficulty with computing the residue at $z = 0$. That is the only issue I'm having left.",,"['complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus', 'complex-integration']"
15,Modulus of Analytic Function is Bounded Above,Modulus of Analytic Function is Bounded Above,,"I have the following problem that I am stuck on: Let $f$ be analytic in $D=\{z\in\mathbb{C}\::\:|z|<1\}$ and suppose that $|f(z)|<M$ for all $z\in D$ . (a) If $f(z_{k})=0$ for $1\leq k\leq n$ , show that $$|f(z)|\leq M\prod_{k=1}^{n}\frac{|z-z_{k}|}{|1-\bar{z}_{k}z|}$$ for $|z|<1$ . (b) If $f(z_{k})=0$ for $1\leq k\leq n$ , each $z_{k}\neq 0$ , and $f(0)=Me^{i\alpha}(z_{1}z_{2}\cdots z_{n})$ , find a formula for $f$ . I honestly have no idea of where to begin with this problem. I think that Schwarz's Lemma may be needed somewhere? Thanks in advance for any help!","I have the following problem that I am stuck on: Let be analytic in and suppose that for all . (a) If for , show that for . (b) If for , each , and , find a formula for . I honestly have no idea of where to begin with this problem. I think that Schwarz's Lemma may be needed somewhere? Thanks in advance for any help!",f D=\{z\in\mathbb{C}\::\:|z|<1\} |f(z)|<M z\in D f(z_{k})=0 1\leq k\leq n |f(z)|\leq M\prod_{k=1}^{n}\frac{|z-z_{k}|}{|1-\bar{z}_{k}z|} |z|<1 f(z_{k})=0 1\leq k\leq n z_{k}\neq 0 f(0)=Me^{i\alpha}(z_{1}z_{2}\cdots z_{n}) f,"['complex-analysis', 'analytic-functions']"
16,Construct a meromorphic function on Riemann surface of genus $3$,Construct a meromorphic function on Riemann surface of genus,3,"I am working on the following questions: Let $X$ be a compact Riemann surface of genus $3$ with two points $p\neq q$ . Find a non-constant meromorphic function on $X$ with at least a double zero at $p$ and holomorphic everywhere except possibly at $q$ . What is the smallest possible pole under at $q$ we need to accept in order to guarantee the existence of such a function? and Construct an example of a Riemann surface of genus $3$ that has a holomorphic $1$ -form with a zero of order $1$ at a point $p$ , and zero of order $3$ at a different point $q$ . My attempt: The second part of the first problem is easy. I think it is just some simple application of Riemann-Roch theorem. But I am desperate to construct something on Riemann surface. Could anyone show me how to do this?","I am working on the following questions: Let be a compact Riemann surface of genus with two points . Find a non-constant meromorphic function on with at least a double zero at and holomorphic everywhere except possibly at . What is the smallest possible pole under at we need to accept in order to guarantee the existence of such a function? and Construct an example of a Riemann surface of genus that has a holomorphic -form with a zero of order at a point , and zero of order at a different point . My attempt: The second part of the first problem is easy. I think it is just some simple application of Riemann-Roch theorem. But I am desperate to construct something on Riemann surface. Could anyone show me how to do this?",X 3 p\neq q X p q q 3 1 1 p 3 q,"['complex-analysis', 'riemann-surfaces', 'divisors-algebraic-geometry']"
17,An approach to evaluating a Cauchy principal value that yields unexpected extra imaginary term,An approach to evaluating a Cauchy principal value that yields unexpected extra imaginary term,,"$\newcommand{\PV}{\operatorname{PV}}$ I have been working on evaluating the first negative moment of a random variable with a piecewise density function by means of the Cauchy principal value, i.e. \begin{equation} \tag{1} PV\!E(X^{-1})=\PV\int_{-\infty}^\infty\frac{f_X(x)}{x}\,\mathrm dx = \lim_{\epsilon\to0}\left(\int_{-\infty}^{-\epsilon}+\int_\epsilon^\infty \right)\frac{f_X(x)}{x}\,\mathrm dx, \end{equation} where $f_X$ is a probability density function. I was unable to get any traction using the definition in $(1)$ but was able to evaluate the moments of $X$ greater than one which yielded \begin{equation} \begin{aligned} E(X^{\epsilon-1}) &=\int_{-\infty}^0 x^{\epsilon-1}f_X(x)\,\mathrm dx% +\int_0^\infty x^{\epsilon-1}f_X(x)\,\mathrm dx,\\ %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% &=\int_0^\infty x^{\epsilon-1}f_X(x)\,\mathrm{d}x% -e^{\mathrm i\pi\epsilon}\int_{-\infty}^0 |x|^{\epsilon-1}f_X(x)\,\mathrm dx,\\ &\propto\Gamma(\epsilon)\left(h_1(\epsilon)-e^{i\pi\epsilon}h_2(\epsilon)\right):=\Gamma(\epsilon)D(\epsilon). \end{aligned} \end{equation} I then tried taking the limit of the moments as $\epsilon\to0$ . As $\epsilon\to0$ , $D(\epsilon)\to0$ while the gamma term blows up. However, by writing the limit as \begin{equation} \lim_{\epsilon\to0}E(X^{\epsilon-1})\propto\Gamma(\epsilon+1)D(\epsilon)/\epsilon, \end{equation} we see that it is $0/0$ indeterminant.  Using L'Hopitals rule and evaluating the limit I got something of the form \begin{equation} \lim_{\epsilon\to0}E(X^{\epsilon-1})= L-f_X(0)\pi\mathrm i. \end{equation} Numerical evaluation revealed that $L=PV\!E(X^{-1})$ ; thus, what I have found is \begin{equation} \tag{2} \lim_{\epsilon\to0}E(X^{\epsilon-1})= PV\!E(X^{-1})-f_X(0)\pi\mathrm i. \end{equation} I was able to come up with a proof of the result in $(2)$ by means of contour integration but was wondering if there other ways of getting to this result. So with that said, what is going on here? Why does adding the extra power to $t$ result in a residual imaginary term?","I have been working on evaluating the first negative moment of a random variable with a piecewise density function by means of the Cauchy principal value, i.e. where is a probability density function. I was unable to get any traction using the definition in but was able to evaluate the moments of greater than one which yielded I then tried taking the limit of the moments as . As , while the gamma term blows up. However, by writing the limit as we see that it is indeterminant.  Using L'Hopitals rule and evaluating the limit I got something of the form Numerical evaluation revealed that ; thus, what I have found is I was able to come up with a proof of the result in by means of contour integration but was wondering if there other ways of getting to this result. So with that said, what is going on here? Why does adding the extra power to result in a residual imaginary term?","\newcommand{\PV}{\operatorname{PV}} \begin{equation}
\tag{1}
PV\!E(X^{-1})=\PV\int_{-\infty}^\infty\frac{f_X(x)}{x}\,\mathrm dx = \lim_{\epsilon\to0}\left(\int_{-\infty}^{-\epsilon}+\int_\epsilon^\infty \right)\frac{f_X(x)}{x}\,\mathrm dx,
\end{equation} f_X (1) X \begin{equation}
\begin{aligned}
E(X^{\epsilon-1})
&=\int_{-\infty}^0 x^{\epsilon-1}f_X(x)\,\mathrm dx%
+\int_0^\infty x^{\epsilon-1}f_X(x)\,\mathrm dx,\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
&=\int_0^\infty x^{\epsilon-1}f_X(x)\,\mathrm{d}x%
-e^{\mathrm i\pi\epsilon}\int_{-\infty}^0 |x|^{\epsilon-1}f_X(x)\,\mathrm dx,\\
&\propto\Gamma(\epsilon)\left(h_1(\epsilon)-e^{i\pi\epsilon}h_2(\epsilon)\right):=\Gamma(\epsilon)D(\epsilon).
\end{aligned}
\end{equation} \epsilon\to0 \epsilon\to0 D(\epsilon)\to0 \begin{equation}
\lim_{\epsilon\to0}E(X^{\epsilon-1})\propto\Gamma(\epsilon+1)D(\epsilon)/\epsilon,
\end{equation} 0/0 \begin{equation}
\lim_{\epsilon\to0}E(X^{\epsilon-1})= L-f_X(0)\pi\mathrm i.
\end{equation} L=PV\!E(X^{-1}) \begin{equation}
\tag{2}
\lim_{\epsilon\to0}E(X^{\epsilon-1})= PV\!E(X^{-1})-f_X(0)\pi\mathrm i.
\end{equation} (2) t","['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration', 'cauchy-principal-value']"
18,Understanding the construction of Riemann surface for $\xi^3-z\xi^2-(a^2-1)\xi+za^2=0$.,Understanding the construction of Riemann surface for .,\xi^3-z\xi^2-(a^2-1)\xi+za^2=0,"I am reading an article which defines a Riemann surface by the following equation ($a>1$): $$\xi^3-z\xi^2-(a^2-1)\xi+za^2=0$$ The goal is to find the Riemann surface of $\xi(z)$. What I know/understand: The critical points satisfy $\frac{\partial z}{\partial \xi}=0$, which after some working out means that the branch points are $-z_1,-z_2,z_2,z_1$ ($0<z_2<z_1$) with $$z_1,z_2=\sqrt{\frac{1}{2}+a^2\pm\frac{1}{2}\sqrt{1+8a^2}}\frac{\sqrt{1+8a^2}  \pm 3}{\sqrt{1+8a^2}\pm 1}.$$  Also, the solutions of the first equation have the following behaviour: $$\xi_1(z)=z-\frac{1}{z}+O\left(\frac{1}{z^3} \right),\xi_2(z)=a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right),\xi_3(z)=-a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right)$$ as $z\rightarrow \infty$. What I don't understand: Apparently, $\xi_1,\xi_2$ and $\xi_3$ can be analytically extended to $\mathbb{C}\backslash ([-z_1,-z_2]\cup [z_2,z_1])$, $\mathbb{C}\backslash  [z_2,z_1]$ and $\mathbb{C}\backslash [-z_1,-z_2]$ respectively. On the cuts, it holds that $$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{2-}(x)=\overline{\xi_{2+}(x)},\quad z_2<x<z_1$$ and  $$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{3-}(x)=\overline{\xi_{3+}(x)},\quad -z_1<x<-z_2$$ which determines the shape of the Riemann surface. I understand that this likely requires some tedious working out, so just the idea of how to start will help a lot.","I am reading an article which defines a Riemann surface by the following equation ($a>1$): $$\xi^3-z\xi^2-(a^2-1)\xi+za^2=0$$ The goal is to find the Riemann surface of $\xi(z)$. What I know/understand: The critical points satisfy $\frac{\partial z}{\partial \xi}=0$, which after some working out means that the branch points are $-z_1,-z_2,z_2,z_1$ ($0<z_2<z_1$) with $$z_1,z_2=\sqrt{\frac{1}{2}+a^2\pm\frac{1}{2}\sqrt{1+8a^2}}\frac{\sqrt{1+8a^2}  \pm 3}{\sqrt{1+8a^2}\pm 1}.$$  Also, the solutions of the first equation have the following behaviour: $$\xi_1(z)=z-\frac{1}{z}+O\left(\frac{1}{z^3} \right),\xi_2(z)=a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right),\xi_3(z)=-a+\frac{1}{2z}+O\left(\frac{1}{z^2} \right)$$ as $z\rightarrow \infty$. What I don't understand: Apparently, $\xi_1,\xi_2$ and $\xi_3$ can be analytically extended to $\mathbb{C}\backslash ([-z_1,-z_2]\cup [z_2,z_1])$, $\mathbb{C}\backslash  [z_2,z_1]$ and $\mathbb{C}\backslash [-z_1,-z_2]$ respectively. On the cuts, it holds that $$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{2-}(x)=\overline{\xi_{2+}(x)},\quad z_2<x<z_1$$ and  $$\xi_{1+}(x)=\overline{\xi_{1-}(x)}=\xi_{3-}(x)=\overline{\xi_{3+}(x)},\quad -z_1<x<-z_2$$ which determines the shape of the Riemann surface. I understand that this likely requires some tedious working out, so just the idea of how to start will help a lot.",,"['complex-analysis', 'riemann-surfaces']"
19,Holomorphic function is injective,Holomorphic function is injective,,"Let $f:\Omega \rightarrow \mathbb{C}$ be a holomorphic function where $\Omega:=\{z\in\mathbb{C}; -1<Re(z)<|Im(z)|\}$ (i.e. $\Omega$ is open, connected, non-convex). If $|f'(z)-1|<1/4$ then $f$ is injective on $\Omega$. PS.: 1)It is obvious that it is gonna be locally injective since $f'(z)\neq 0$, $\forall z\in\Omega$ (using b)... but how can I guarantee that it is gonna be for whole $\Omega$? 2) If $\Omega$ is convex it is trivial: In fact, suppose that $a\neq b$ s.t $f(a)=f(b)$. So, consider the straight line $\gamma$, connecting $a$ to $b$, i.e. $\gamma:[0,1]\rightarrow \Omega$ is defined as $\gamma (t)=a+(b-a)t$. Since $\Omega$ is convex, this line lies in $\Omega$ and so $f$ is holomorphic here. Thus, $0=f(b)-f(a)=\displaystyle\int_{\gamma}f'(z)dz=\int_{0}^{1}f'(\gamma(t))\gamma'(t)dt=\int_{0}^{1}f'(a+(b-a)t)(b-a)dt$ As $(b-a)\in\mathbb{C}^{*}$ is just a constant (non-zero since $a\neq b$, by assumption). We have: $\displaystyle0=\int_{0}^{1}f'(a+(b-a)t)dt$ $\Rightarrow \displaystyle -1=\int_{0}^{1}(f'(a+(b-a)t)-1)dt $ (adding (-1) both sides). Now, Taking the module, we have $1=\displaystyle|\int_{0}^{1}(f'(a+(b-a)t)-1)dt|\leq \int_{0}^{1}|(f'(a+(b-a)t)-1)|dt<\int_{0}^{1}\frac{1}{4}dt=\frac{1}{4}$ (we have to use the assumption here for the last inequality). So, $1<\frac{1}{4}$, Contradiction. Therefore, $f(a)\neq f(b)$, i.e. $f$ is injective. $\square$ $\Omega$:","Let $f:\Omega \rightarrow \mathbb{C}$ be a holomorphic function where $\Omega:=\{z\in\mathbb{C}; -1<Re(z)<|Im(z)|\}$ (i.e. $\Omega$ is open, connected, non-convex). If $|f'(z)-1|<1/4$ then $f$ is injective on $\Omega$. PS.: 1)It is obvious that it is gonna be locally injective since $f'(z)\neq 0$, $\forall z\in\Omega$ (using b)... but how can I guarantee that it is gonna be for whole $\Omega$? 2) If $\Omega$ is convex it is trivial: In fact, suppose that $a\neq b$ s.t $f(a)=f(b)$. So, consider the straight line $\gamma$, connecting $a$ to $b$, i.e. $\gamma:[0,1]\rightarrow \Omega$ is defined as $\gamma (t)=a+(b-a)t$. Since $\Omega$ is convex, this line lies in $\Omega$ and so $f$ is holomorphic here. Thus, $0=f(b)-f(a)=\displaystyle\int_{\gamma}f'(z)dz=\int_{0}^{1}f'(\gamma(t))\gamma'(t)dt=\int_{0}^{1}f'(a+(b-a)t)(b-a)dt$ As $(b-a)\in\mathbb{C}^{*}$ is just a constant (non-zero since $a\neq b$, by assumption). We have: $\displaystyle0=\int_{0}^{1}f'(a+(b-a)t)dt$ $\Rightarrow \displaystyle -1=\int_{0}^{1}(f'(a+(b-a)t)-1)dt $ (adding (-1) both sides). Now, Taking the module, we have $1=\displaystyle|\int_{0}^{1}(f'(a+(b-a)t)-1)dt|\leq \int_{0}^{1}|(f'(a+(b-a)t)-1)|dt<\int_{0}^{1}\frac{1}{4}dt=\frac{1}{4}$ (we have to use the assumption here for the last inequality). So, $1<\frac{1}{4}$, Contradiction. Therefore, $f(a)\neq f(b)$, i.e. $f$ is injective. $\square$ $\Omega$:",,"['complex-analysis', 'complex-integration', 'holomorphic-functions', 'analytic-functions']"
20,Numerically solve complex differential equation,Numerically solve complex differential equation,,"I'd like to find a numerical solution to a complex differential equation of the form $ \frac{dz(t)}{dt} = f(z,t)$, where $z$ and $t$ can both be complex, with $z(0)=0$. Specifically, I'd like to determine values of $z$ for some mesh of values of $(t_r,t_c)$, where $t = t_r + t_c i$, so that I can potentially interpolate later to find $z(t)$ at any complex $t$. One approach would be to numerically solve the ODE for real $t$, find a smooth approximation to the solution (e.g. a polynomial), and then analytically continue the smooth function into the complex plane. I'm worried about the accuracy of this approach, because I don't know if the smooth function being an accurate approximation on the real axis guarantees its accuracy in other parts of the complex plane. I could also consider solving the ODE for imaginary $t$, or along any particular curve through the plane, and then analytically continue it similarly - which would at least provide consistency tests. But perhaps I should be thinking of it as a PDE rather than an ODE - I can write $\frac{\partial z}{\partial t_r} = -i \frac{\partial z}{\partial t_c} = f(z,t_r,t_c)$, but then it looks like I've got too many constraints for a usual PDE solver... Is there a more natural way to solve these types of equations numerically?","I'd like to find a numerical solution to a complex differential equation of the form $ \frac{dz(t)}{dt} = f(z,t)$, where $z$ and $t$ can both be complex, with $z(0)=0$. Specifically, I'd like to determine values of $z$ for some mesh of values of $(t_r,t_c)$, where $t = t_r + t_c i$, so that I can potentially interpolate later to find $z(t)$ at any complex $t$. One approach would be to numerically solve the ODE for real $t$, find a smooth approximation to the solution (e.g. a polynomial), and then analytically continue the smooth function into the complex plane. I'm worried about the accuracy of this approach, because I don't know if the smooth function being an accurate approximation on the real axis guarantees its accuracy in other parts of the complex plane. I could also consider solving the ODE for imaginary $t$, or along any particular curve through the plane, and then analytically continue it similarly - which would at least provide consistency tests. But perhaps I should be thinking of it as a PDE rather than an ODE - I can write $\frac{\partial z}{\partial t_r} = -i \frac{\partial z}{\partial t_c} = f(z,t_r,t_c)$, but then it looks like I've got too many constraints for a usual PDE solver... Is there a more natural way to solve these types of equations numerically?",,"['complex-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'numerical-methods', 'analytic-continuation']"
21,Prove every one-to-one conformal mapping of a disc onto another is a linear fractional transformation.,Prove every one-to-one conformal mapping of a disc onto another is a linear fractional transformation.,,"Question : Prove by use of Schwarz's lemma that every one-to-one conformal mapping of a disc onto another (or a half plane) is given by a linear fractional transformation. I have known that there exists LFT such that it maps unit disc onto itself, but if holomorphic function $f$ is a 1-1 mapping of a disc onto another disc, can we conclude $f$ is LFT? My try is simplifying the question as Every one-to-one conformal mapping of a unit disc onto itself is given by a linear fractional transformation. Am I right? Sincerely thanks for your help!","Question : Prove by use of Schwarz's lemma that every one-to-one conformal mapping of a disc onto another (or a half plane) is given by a linear fractional transformation. I have known that there exists LFT such that it maps unit disc onto itself, but if holomorphic function $f$ is a 1-1 mapping of a disc onto another disc, can we conclude $f$ is LFT? My try is simplifying the question as Every one-to-one conformal mapping of a unit disc onto itself is given by a linear fractional transformation. Am I right? Sincerely thanks for your help!",,"['complex-analysis', 'conformal-geometry']"
22,Distance of nearest zero of an analytic function,Distance of nearest zero of an analytic function,,"Prove that the distance of the nearest zero of the function $f(z)={\sum}_{s=0}^{\infty}\: c_nz^n$ to the point $z=0$ is not less than $\frac{r|c_0|}{M+|c_0|}$, where r is any number not exceeding the radius of convergence of the series, and $M(r)= \max\limits_{|z|=r}|f(z)|$. I followed the hint to first establish that the function $f(z)$ has no zero in the domain where $|f(z)-c_0|<|c_0|$. The next hint is to estimate  $|f(z)-c_0|$ using Cauchy's inequality. But, I am getting $|c_0|<M$ using that inequality and unable to proceed further. Please suggest the way forward. Thanks.","Prove that the distance of the nearest zero of the function $f(z)={\sum}_{s=0}^{\infty}\: c_nz^n$ to the point $z=0$ is not less than $\frac{r|c_0|}{M+|c_0|}$, where r is any number not exceeding the radius of convergence of the series, and $M(r)= \max\limits_{|z|=r}|f(z)|$. I followed the hint to first establish that the function $f(z)$ has no zero in the domain where $|f(z)-c_0|<|c_0|$. The next hint is to estimate  $|f(z)-c_0|$ using Cauchy's inequality. But, I am getting $|c_0|<M$ using that inequality and unable to proceed further. Please suggest the way forward. Thanks.",,"['complex-analysis', 'holomorphic-functions', 'cauchy-integral-formula', 'analytic-functions']"
23,Do both of these functions define the same branch of $\sqrt{z^2 - 1}$?,Do both of these functions define the same branch of ?,\sqrt{z^2 - 1},"Let $\sqrt{\cdot}$ be the function defined by  \begin{align} \sqrt{z} &= r^\frac{1}{2} e^{i \frac{\theta}{2}}, \\  r &= |z|, \\  \theta &= \arg(z), \\  -\pi &< \theta \le \pi \end{align} Let $$f(z) = z\sqrt{1 - \frac{1}{z}}\sqrt{1 + \frac{1}{z}}$$ and let  $$g(z) = \sqrt{z +1}\sqrt{z - 1}.$$ The functions $f$ and $g$ are both branches of the multivalued function implicitly defined by $w^2 = z^2 - 1$. Indeed $f^2(z) = g^2(z) = z^2 - 1$. Furthermore $f(x) = g(x)$ for $x > 1$, therefore $f = g$ on $\mathbb C \setminus [-1, 1]$  by the Identity theorem . Is there a more direct way to see this from how $\sqrt{\cdot}$ depends on the argument of a number? It's tempting to factor $\sqrt{z}$ from both factors of $g$ however for $\alpha, \beta \in \mathbb C$, in general $\sqrt{\alpha\beta} \neq \sqrt{\alpha}\sqrt{\beta}$. Thanks.","Let $\sqrt{\cdot}$ be the function defined by  \begin{align} \sqrt{z} &= r^\frac{1}{2} e^{i \frac{\theta}{2}}, \\  r &= |z|, \\  \theta &= \arg(z), \\  -\pi &< \theta \le \pi \end{align} Let $$f(z) = z\sqrt{1 - \frac{1}{z}}\sqrt{1 + \frac{1}{z}}$$ and let  $$g(z) = \sqrt{z +1}\sqrt{z - 1}.$$ The functions $f$ and $g$ are both branches of the multivalued function implicitly defined by $w^2 = z^2 - 1$. Indeed $f^2(z) = g^2(z) = z^2 - 1$. Furthermore $f(x) = g(x)$ for $x > 1$, therefore $f = g$ on $\mathbb C \setminus [-1, 1]$  by the Identity theorem . Is there a more direct way to see this from how $\sqrt{\cdot}$ depends on the argument of a number? It's tempting to factor $\sqrt{z}$ from both factors of $g$ however for $\alpha, \beta \in \mathbb C$, in general $\sqrt{\alpha\beta} \neq \sqrt{\alpha}\sqrt{\beta}$. Thanks.",,"['complex-analysis', 'complex-numbers', 'complex-integration', 'branch-cuts']"
24,Residue of Pole $s=1$ of $\zeta$ function,Residue of Pole  of  function,s=1 \zeta,I have trouble to understand Why the residue of the riemann $\zeta$ function is 1. I can just find that One can see this because $\lim_{s\to 1} (s-1)\zeta(s)=1$. But I do not understand how to get the 1 by using the Series representation $\zeta(s)=\sum_{n=1}^\infty \frac{1}{n^s}$,I have trouble to understand Why the residue of the riemann $\zeta$ function is 1. I can just find that One can see this because $\lim_{s\to 1} (s-1)\zeta(s)=1$. But I do not understand how to get the 1 by using the Series representation $\zeta(s)=\sum_{n=1}^\infty \frac{1}{n^s}$,,"['complex-analysis', 'riemann-zeta']"
25,Elementary integrals and Riemann surfaces,Elementary integrals and Riemann surfaces,,"An article of Brian Conrad "" Impossibility theorems for elementary integration "" says that a way of proving the following elliptic integral If $P(x)$ is a monic polynomial of degree $\ge 3$ without repeated roots, then $$\int \frac{dx}{\sqrt{ P(x)}}$$    is not an elementary integral. After that, Conrad says that this theorem is a consequence of general facts about compact Riemann surfaces, because the formula obtained by the Liouville theorem for elementary integrals is equivalent to the equality for meromorphic $1$-forms $$\left({dy}/{y}\right)=\sum c_j (dg_j)/(g_j)+dh$$ on the compact Riemann surface associated to $y^2=P(x)$, and for degree of $P>2$ the left side of the formula is a holomorphic $1$-form on $C$, and a non-zero holomorphic 1-form on a compact Riemann surface never admits an expression like the above expression. I don't know anything about Riemann surfaces, and my question is: where can I find the information to understand this reasoning? I don´t know if this it's very difficult or it's very elementary in the theory of Riemann surfaces. I appreciate any answer. Thanks","An article of Brian Conrad "" Impossibility theorems for elementary integration "" says that a way of proving the following elliptic integral If $P(x)$ is a monic polynomial of degree $\ge 3$ without repeated roots, then $$\int \frac{dx}{\sqrt{ P(x)}}$$    is not an elementary integral. After that, Conrad says that this theorem is a consequence of general facts about compact Riemann surfaces, because the formula obtained by the Liouville theorem for elementary integrals is equivalent to the equality for meromorphic $1$-forms $$\left({dy}/{y}\right)=\sum c_j (dg_j)/(g_j)+dh$$ on the compact Riemann surface associated to $y^2=P(x)$, and for degree of $P>2$ the left side of the formula is a holomorphic $1$-form on $C$, and a non-zero holomorphic 1-form on a compact Riemann surface never admits an expression like the above expression. I don't know anything about Riemann surfaces, and my question is: where can I find the information to understand this reasoning? I don´t know if this it's very difficult or it's very elementary in the theory of Riemann surfaces. I appreciate any answer. Thanks",,"['complex-analysis', 'riemann-surfaces']"
26,A question about complex integration formula using Green's theorem,A question about complex integration formula using Green's theorem,,"Use the Green's theorem (complex form) to show that $$\frac{1}{2\pi i}\int_\gamma \frac{dz}{z-p}=\begin{cases} 0 & \text{if $p$ is outside $\gamma$} \\   1& \text{if $p$ is inside $\gamma$}\\ \end{cases}$$ I proved this one by taking $z-p=re^{i\theta}$, but how could I prove it using Green's theorem?","Use the Green's theorem (complex form) to show that $$\frac{1}{2\pi i}\int_\gamma \frac{dz}{z-p}=\begin{cases} 0 & \text{if $p$ is outside $\gamma$} \\   1& \text{if $p$ is inside $\gamma$}\\ \end{cases}$$ I proved this one by taking $z-p=re^{i\theta}$, but how could I prove it using Green's theorem?",,"['complex-analysis', 'complex-integration']"
27,Convergence on $D$ vs. convergence on $\partial D$,Convergence on  vs. convergence on,D \partial D,"Let $f_n(z)$ be a sequence of holomorphic functions on some bounded domain $D$, continuously extendable to the boundary $\partial D$, which converges locally uniformly in the interior. Let us also assume that on the boundary one has pointwise convergence a.e. (of the extensions). Let us denote the limit function on $D$ as $g$, and on the boundary $\partial D$ as $h$. If for each $p \in \partial D$, the limit $\lim\limits_{z \rightarrow p} g(z)$ exists, must it be equal to $h(p)$ a.e. ? What if we instead take the case of $L^p$ convergences on the boundary with respect to some measure which is absolutely continuous with respect to the Lebesgue measure? Update: The question concerning a.e. pointwise convergence has been answered. What remains is the case of $L^p(\partial D)$ convergence.","Let $f_n(z)$ be a sequence of holomorphic functions on some bounded domain $D$, continuously extendable to the boundary $\partial D$, which converges locally uniformly in the interior. Let us also assume that on the boundary one has pointwise convergence a.e. (of the extensions). Let us denote the limit function on $D$ as $g$, and on the boundary $\partial D$ as $h$. If for each $p \in \partial D$, the limit $\lim\limits_{z \rightarrow p} g(z)$ exists, must it be equal to $h(p)$ a.e. ? What if we instead take the case of $L^p$ convergences on the boundary with respect to some measure which is absolutely continuous with respect to the Lebesgue measure? Update: The question concerning a.e. pointwise convergence has been answered. What remains is the case of $L^p(\partial D)$ convergence.",,"['complex-analysis', 'measure-theory', 'pointwise-convergence']"
28,Do holomorphic functions necessarily blow up at the edge of their maximal domain of definition?,Do holomorphic functions necessarily blow up at the edge of their maximal domain of definition?,,"If a holomorphic function $f$ is defined on some open set $\Omega$, then any connected open set $U$ containing $\Omega$ either has the property that there exists a holomorphic extension of $f$ on $U$ or does not. If there is a holomorphic extension, it's unique by analytic continuation. Thus, taking the union of all possible extensions, $f$ has a unique maximal connected, open domain on which it's holomorphic. (Right?) What can we say about the behavior of $f$ at the boundary of this domain? Does it necessarily blow up? Or can it be bounded?","If a holomorphic function $f$ is defined on some open set $\Omega$, then any connected open set $U$ containing $\Omega$ either has the property that there exists a holomorphic extension of $f$ on $U$ or does not. If there is a holomorphic extension, it's unique by analytic continuation. Thus, taking the union of all possible extensions, $f$ has a unique maximal connected, open domain on which it's holomorphic. (Right?) What can we say about the behavior of $f$ at the boundary of this domain? Does it necessarily blow up? Or can it be bounded?",,['complex-analysis']
29,Prove that a holomorphic function has a finite limit as $\Im(z)\to\infty$.,Prove that a holomorphic function has a finite limit as .,\Im(z)\to\infty,"The following problem comes from the Graduate Qualifying Exam in Complex analysis from Texas A&M: Let $F$ be a function holomorphic and bounded in the upper half-plane $\mathbb{C}_+$. Suppose that $F$ has period 1, i.e., $F(z+1)=F(z)$ for all $z\in\mathbb{C}_+$. Prove that $F(z)$ has a finite limit as $\Im(z)\to\infty$. So far, I've been able to ascertain the following: $F$ is bounded, which implies that its maximum occurs at its boundary, $\partial\mathbb{C}_+$. If its maximum occurs at $\infty$, then we are done, since then it will be approaching its maximum, a finite number. But if it attains its maximum on the ""$x$-axis"", we might not be able to say as much. If we have a sequence $\{z_n\}\to\infty$ in $\mathbb{C}_+$, it suffices to consider only $z_n$ in the strip $\{z\in\mathbb{C}_+\,\,:\,\,0\leq \Re(z)<1\}$, since $F$ is periodic. Any ideas? Phragmen Lindelof vaguely came to mind.","The following problem comes from the Graduate Qualifying Exam in Complex analysis from Texas A&M: Let $F$ be a function holomorphic and bounded in the upper half-plane $\mathbb{C}_+$. Suppose that $F$ has period 1, i.e., $F(z+1)=F(z)$ for all $z\in\mathbb{C}_+$. Prove that $F(z)$ has a finite limit as $\Im(z)\to\infty$. So far, I've been able to ascertain the following: $F$ is bounded, which implies that its maximum occurs at its boundary, $\partial\mathbb{C}_+$. If its maximum occurs at $\infty$, then we are done, since then it will be approaching its maximum, a finite number. But if it attains its maximum on the ""$x$-axis"", we might not be able to say as much. If we have a sequence $\{z_n\}\to\infty$ in $\mathbb{C}_+$, it suffices to consider only $z_n$ in the strip $\{z\in\mathbb{C}_+\,\,:\,\,0\leq \Re(z)<1\}$, since $F$ is periodic. Any ideas? Phragmen Lindelof vaguely came to mind.",,"['complex-analysis', 'holomorphic-functions']"
30,How to relate the solutions to a Fuchsian type differential equation to the solutions to the hypergeometric differential equation?,How to relate the solutions to a Fuchsian type differential equation to the solutions to the hypergeometric differential equation?,,"Consider a Fuchsian type differential equation written as $$\frac{d^2 y}{dz^2} + \frac{p(z)}{(z - z_1)(z - z_2) \cdots (z - z_m)} \frac{dy}{dz} + \frac{q(z)}{(z - z_1)^2 (z - z_2)^2 \cdots (z - z_m)^2} y = 0, \quad m \geq 2,$$ where $z_1, z_2, \ldots, z_m$ are distinct regular singular points, and $p(z)$ and $q(z)$ are polynomials. How does one relate the solutions to this differential equation to the solutions to the hypergeometric differential equation $$z(1 - z) \frac{d^2 y}{dz^2} + [c - (a + b + 1)z] \frac{dy}{dz} - aby = 0$$ around each regular singular points? The case $m = 2$ essentially reduces to Riemann's differential equation (if $z = \infty$ is a regular singular point) whose solutions can be written in terms of the hypergeometric functions. Can this be done in general, or for at least four or five regular singular points? Update : From what I have gathered so far, all homogeneous linear differential equations of the second order having four regular singularities in the extended complex plane, can be transformed into Heun's differential equation whose solutions are related to the hypergeometric functions.","Consider a Fuchsian type differential equation written as $$\frac{d^2 y}{dz^2} + \frac{p(z)}{(z - z_1)(z - z_2) \cdots (z - z_m)} \frac{dy}{dz} + \frac{q(z)}{(z - z_1)^2 (z - z_2)^2 \cdots (z - z_m)^2} y = 0, \quad m \geq 2,$$ where $z_1, z_2, \ldots, z_m$ are distinct regular singular points, and $p(z)$ and $q(z)$ are polynomials. How does one relate the solutions to this differential equation to the solutions to the hypergeometric differential equation $$z(1 - z) \frac{d^2 y}{dz^2} + [c - (a + b + 1)z] \frac{dy}{dz} - aby = 0$$ around each regular singular points? The case $m = 2$ essentially reduces to Riemann's differential equation (if $z = \infty$ is a regular singular point) whose solutions can be written in terms of the hypergeometric functions. Can this be done in general, or for at least four or five regular singular points? Update : From what I have gathered so far, all homogeneous linear differential equations of the second order having four regular singularities in the extended complex plane, can be transformed into Heun's differential equation whose solutions are related to the hypergeometric functions.",,"['complex-analysis', 'ordinary-differential-equations', 'power-series', 'special-functions', 'hypergeometric-function']"
31,Elliptic integral of the first kind as conformal mapping,Elliptic integral of the first kind as conformal mapping,,"We define the (incomplete) elliptic integral of the first kind with elliptic modulus $0 < k < 1$ as $$ F(z; k) = \int_{0}^{z} \frac{dw}{\sqrt{(1-w^2)(1-k^2w^2)}}, \text{ Im}(z) > 0 $$ It is well-known that $F$ maps the complex upper half-plane conformally onto some rectangle $R(k)$. One method for proving this starts out with showing that $F$ maps the extended real line one-to-one onto the boundary $\delta R(K)$. But I do not quite understand how $F(z; k)$ accomplishes this with respect to the turning angles involved. I can see how 90 degree counterclockwise turns are ""generated"" at $w = -1$ and $w = 1$, but not at $w = -1/k$ and $w = 1/k$, where the root gets real again. Should the denominator in the integrand not be $\sqrt{1-w^2}\sqrt{1-k^2w^2}$ for that to happen? And if so, why is the elliptic integral always shown without this additional separated square root? As it is now it seems not even to be analytic in $\mathbb{H}$. And furthermore, if we wish to have continuity in the closure of the upper half-plane $\overline{\mathbb{H}}$ --- something which is explicitly used in a couple of arguments I have seen ---, do we not really need the even further separated $k\sqrt{1+w}\sqrt{1-w}\sqrt{\frac{1}{k}+w}\sqrt{\frac{1}{k}-w}$ as denominator, like in the Schwarz-Christoffel mapping formula? For me this is all a bit confusing.","We define the (incomplete) elliptic integral of the first kind with elliptic modulus $0 < k < 1$ as $$ F(z; k) = \int_{0}^{z} \frac{dw}{\sqrt{(1-w^2)(1-k^2w^2)}}, \text{ Im}(z) > 0 $$ It is well-known that $F$ maps the complex upper half-plane conformally onto some rectangle $R(k)$. One method for proving this starts out with showing that $F$ maps the extended real line one-to-one onto the boundary $\delta R(K)$. But I do not quite understand how $F(z; k)$ accomplishes this with respect to the turning angles involved. I can see how 90 degree counterclockwise turns are ""generated"" at $w = -1$ and $w = 1$, but not at $w = -1/k$ and $w = 1/k$, where the root gets real again. Should the denominator in the integrand not be $\sqrt{1-w^2}\sqrt{1-k^2w^2}$ for that to happen? And if so, why is the elliptic integral always shown without this additional separated square root? As it is now it seems not even to be analytic in $\mathbb{H}$. And furthermore, if we wish to have continuity in the closure of the upper half-plane $\overline{\mathbb{H}}$ --- something which is explicitly used in a couple of arguments I have seen ---, do we not really need the even further separated $k\sqrt{1+w}\sqrt{1-w}\sqrt{\frac{1}{k}+w}\sqrt{\frac{1}{k}-w}$ as denominator, like in the Schwarz-Christoffel mapping formula? For me this is all a bit confusing.",,"['complex-analysis', 'conformal-geometry', 'elliptic-integrals']"
32,Is absolute value of an analytic function a harmonic function?,Is absolute value of an analytic function a harmonic function?,,"It is well known that if $f(x+i y) = u(x, y) + i v(x, y)$ is an analytic function of variable $z = x + iy$ then both $u$ and $v$ are harmonic functions. Does $|f| = \sqrt{u^2 + v^2}$ have any special properties, in particular is $|f|$ harmonic?","It is well known that if $f(x+i y) = u(x, y) + i v(x, y)$ is an analytic function of variable $z = x + iy$ then both $u$ and $v$ are harmonic functions. Does $|f| = \sqrt{u^2 + v^2}$ have any special properties, in particular is $|f|$ harmonic?",,"['complex-analysis', 'absolute-value', 'harmonic-functions', 'analytic-functions']"
33,Analytic function and the Lagrange interpolating polynomial,Analytic function and the Lagrange interpolating polynomial,,"Let $f(z)$ be analytic in a closed set $A$ and bounded by contour $C$ . Let $z_1,z_2,...,z_n$ be different arbitrary point in the interior of $C$ and let $w_n(z)=(z-z_1)(z-z_2)...(z-z_n) $ . Prove the integral $$P(z)=\frac{1}{2\pi i} \int_C \frac{f(x)}{w_n(x)} \frac{w_n(x)-w_n(z)}{x-z} dx$$ is a polynomial of degree $(n-1)$ that is the same as $f(z)$ at $z_1,z_2,...,z_n$ points. Note: $P(z)$ is the Lagrange interpolating polynomial. I think I have an idea for the proof, but I don't know how to write it formally. Idea I think this formula $$f^n(z_0)=\frac{n!}{2\pi i} \int_J \frac{f(x)}{(x-z_0)^{n+1}} dx $$ will be useful because practically is telling us that P $(z)$ must be 'equal to' $\frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right)$ . Now the rest is trying to proof that $\frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right)$ must be something very similar to the Lagrange polynomial. Is this a good idea? Could be demonstrated in another way? Thanks for any suggestions/hint/tip/help.","Let be analytic in a closed set and bounded by contour . Let be different arbitrary point in the interior of and let . Prove the integral is a polynomial of degree that is the same as at points. Note: is the Lagrange interpolating polynomial. I think I have an idea for the proof, but I don't know how to write it formally. Idea I think this formula will be useful because practically is telling us that P must be 'equal to' . Now the rest is trying to proof that must be something very similar to the Lagrange polynomial. Is this a good idea? Could be demonstrated in another way? Thanks for any suggestions/hint/tip/help.","f(z) A C z_1,z_2,...,z_n C w_n(z)=(z-z_1)(z-z_2)...(z-z_n)  P(z)=\frac{1}{2\pi i} \int_C \frac{f(x)}{w_n(x)} \frac{w_n(x)-w_n(z)}{x-z} dx (n-1) f(z) z_1,z_2,...,z_n P(z) f^n(z_0)=\frac{n!}{2\pi i} \int_J \frac{f(x)}{(x-z_0)^{n+1}} dx  (z) \frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right) \frac{f^n(z_0)}{n!} \left(\frac{w_n(x)-w_n(z)}{x-z} \right)","['complex-analysis', 'complex-integration', 'analytic-functions']"
34,Calculus of a real integral using complex analysis,Calculus of a real integral using complex analysis,,"I'm trying to compute $$I = \int_{-\infty}^{+\infty} \frac{t^{m}}{1+t^{2n}},$$ where $n$ and $m$ are integers such that $2n - m \geq 2$. Let's denote $$F(t) = \frac{t^{m}}{1+t^{2n}}$$ for $t \in \mathbf{R}$. In this case ($2n - m \geq 2$), it is known that if $(a_k)_{k=0}^{n-1}$ is the family of the poles with a positive imaginary part, then $$I = 2i \pi \sum\limits_{k=0}^{n-1}{\text{Res}(F,a_k)}.$$ Here, we know that the poles of $F$ are the $$a_k = e^{i \pi \frac{2k+1}{2n}},$$ where $k \in [\![0,n-1]\!]$. Since these are simple ones, and $F$ is of the form $\frac{g}{h}$, we have, for all $k$, $$\text{Res}(F,a_k) = \frac{g(a_k)}{h'(a_k)}.$$ I know I should find $$\text{Res}(F,a_k) = -\frac{1}{2n}a_k^{m+1}$$ but I can't understand how. I tried the following computation : $$\begin{array}{r c l} \text{Res}(F,a_k) &=& \frac{a_k^m}{2na_k^{2n-1}}\\ &=& \frac{e^{i\frac{m(2k+1)\pi}{2n}}}{2ne^{i(2n-1)\frac{(2k+1)\pi}{2n}}}\\ &=& \frac{1}{2n}e^{i\frac{m(2k+1)\pi - (2n-1)(2k+1)\pi}{2n}}\\ &=& \frac{1}{2n}e^{i\frac{(m-(2n-1))(2k+1)\pi}{2\pi}} \end{array}$$ and I can't see how to simplify... Then the thing is unfortunately not over... We could stop at the expression with the sum of the exponentials (assuming that we managed to simplify this ugly thing I found), but I have been said I should find at the end $$I = \frac{\pi\left[1 - (-1)^{m+1}\right]}{2n \sin \left(\frac{(m+1)\pi}{n}\right)}...,$$ which of course I didn't. Here is what I tried. First I assumed I had the right expression for the $\text{Res}(F,ak)$. Then I computed $$\begin{array}{r c l} I &=& 2i\pi \sum \limits_{k=0}^{n-1}{-\frac{1}{2n} a_k}\\ &=& - \frac{2i\pi}{2n} \sum\limits_{k=0}^{n-1}{\left(e^{\frac{2ik\pi}{2n}}e^{\frac{i\pi}{2n}}\right)^{m+1}}\\ &=& -\frac{2i\pi}{2n} \times e^{i\frac{\pi(m+1)}{2n}} \times \frac{1 - e ^{i\pi}}{1 - e^{i\frac{\pi}{n}}}\\ &=& - \frac{2i\pi}{2n} \times e^{\frac{i\pi(m+1)}{2n}} \times \frac{2}{1 - e^{i\frac{\pi}{n}}} \end{array},$$ which, obviously, is not what I expected... Thank you in advance for your help!","I'm trying to compute $$I = \int_{-\infty}^{+\infty} \frac{t^{m}}{1+t^{2n}},$$ where $n$ and $m$ are integers such that $2n - m \geq 2$. Let's denote $$F(t) = \frac{t^{m}}{1+t^{2n}}$$ for $t \in \mathbf{R}$. In this case ($2n - m \geq 2$), it is known that if $(a_k)_{k=0}^{n-1}$ is the family of the poles with a positive imaginary part, then $$I = 2i \pi \sum\limits_{k=0}^{n-1}{\text{Res}(F,a_k)}.$$ Here, we know that the poles of $F$ are the $$a_k = e^{i \pi \frac{2k+1}{2n}},$$ where $k \in [\![0,n-1]\!]$. Since these are simple ones, and $F$ is of the form $\frac{g}{h}$, we have, for all $k$, $$\text{Res}(F,a_k) = \frac{g(a_k)}{h'(a_k)}.$$ I know I should find $$\text{Res}(F,a_k) = -\frac{1}{2n}a_k^{m+1}$$ but I can't understand how. I tried the following computation : $$\begin{array}{r c l} \text{Res}(F,a_k) &=& \frac{a_k^m}{2na_k^{2n-1}}\\ &=& \frac{e^{i\frac{m(2k+1)\pi}{2n}}}{2ne^{i(2n-1)\frac{(2k+1)\pi}{2n}}}\\ &=& \frac{1}{2n}e^{i\frac{m(2k+1)\pi - (2n-1)(2k+1)\pi}{2n}}\\ &=& \frac{1}{2n}e^{i\frac{(m-(2n-1))(2k+1)\pi}{2\pi}} \end{array}$$ and I can't see how to simplify... Then the thing is unfortunately not over... We could stop at the expression with the sum of the exponentials (assuming that we managed to simplify this ugly thing I found), but I have been said I should find at the end $$I = \frac{\pi\left[1 - (-1)^{m+1}\right]}{2n \sin \left(\frac{(m+1)\pi}{n}\right)}...,$$ which of course I didn't. Here is what I tried. First I assumed I had the right expression for the $\text{Res}(F,ak)$. Then I computed $$\begin{array}{r c l} I &=& 2i\pi \sum \limits_{k=0}^{n-1}{-\frac{1}{2n} a_k}\\ &=& - \frac{2i\pi}{2n} \sum\limits_{k=0}^{n-1}{\left(e^{\frac{2ik\pi}{2n}}e^{\frac{i\pi}{2n}}\right)^{m+1}}\\ &=& -\frac{2i\pi}{2n} \times e^{i\frac{\pi(m+1)}{2n}} \times \frac{1 - e ^{i\pi}}{1 - e^{i\frac{\pi}{n}}}\\ &=& - \frac{2i\pi}{2n} \times e^{\frac{i\pi(m+1)}{2n}} \times \frac{2}{1 - e^{i\frac{\pi}{n}}} \end{array},$$ which, obviously, is not what I expected... Thank you in advance for your help!",,"['calculus', 'integration', 'complex-analysis']"
35,Completed Proof For Incommensurate Lissajous Curves/Bowditch Curves Are Dense In The Rectangle,Completed Proof For Incommensurate Lissajous Curves/Bowditch Curves Are Dense In The Rectangle,,"A Lissajous curve, or a Bowditch curve, is given by the parametric equations $x(t)=Asin(ω_{x}t + \phi)$ $y(t)=Bsin(ω_{y}t+δ)$, Now if $\frac{\omega_{x}}{\omega_{y}}$ is irrational, and $\phi$ and $\delta$ are fixed, then the set $\mathcal{L} = (x(t), y(t) | -\infty < t < \infty)$ is supposedly dense in the rectangle $R =[-A,A]$x$[-B,B]$ I have seen: Show that a Lissajous curve has incommesurate frequencies iff it isdense in a rectangle But a completed proof was not given. This problem is frequently mentioned in the literature, but a reference to a full proof is never given. Does anyone have such a reference, or could someone provide a proof here?","A Lissajous curve, or a Bowditch curve, is given by the parametric equations $x(t)=Asin(ω_{x}t + \phi)$ $y(t)=Bsin(ω_{y}t+δ)$, Now if $\frac{\omega_{x}}{\omega_{y}}$ is irrational, and $\phi$ and $\delta$ are fixed, then the set $\mathcal{L} = (x(t), y(t) | -\infty < t < \infty)$ is supposedly dense in the rectangle $R =[-A,A]$x$[-B,B]$ I have seen: Show that a Lissajous curve has incommesurate frequencies iff it isdense in a rectangle But a completed proof was not given. This problem is frequently mentioned in the literature, but a reference to a full proof is never given. Does anyone have such a reference, or could someone provide a proof here?",,"['real-analysis', 'complex-analysis', 'analysis', 'proof-explanation', 'ergodic-theory']"
36,$\frac{1 - e^{iz}}{z^2} = \frac{-iz}{z^2} + E(z)$ where $E(z)$ is bounded as $z \rightarrow 0?$,where  is bounded as,\frac{1 - e^{iz}}{z^2} = \frac{-iz}{z^2} + E(z) E(z) z \rightarrow 0?,Was reading some notes and it states that $f(z) = \frac{1 - e^{iz}}{z^2}$ can be written as $f(x) = \frac{-iz}{z^2} + E(z)$ where $E(z)$ is bounded as $z \rightarrow 0.$ I don't exactly see why. Help is appreciated.,Was reading some notes and it states that $f(z) = \frac{1 - e^{iz}}{z^2}$ can be written as $f(x) = \frac{-iz}{z^2} + E(z)$ where $E(z)$ is bounded as $z \rightarrow 0.$ I don't exactly see why. Help is appreciated.,,['complex-analysis']
37,Write the function $\frac{1}{(z+1)(3-z)}$ as a Laurent series.,Write the function  as a Laurent series.,\frac{1}{(z+1)(3-z)},"$$f(z)=\frac{1}{(z+1)(3-z)}=\frac{1}{4z+4} + \frac{1}{12-4z}$$ $$\frac{1}{4z+4}=\frac{1}{4z}\frac{1}{1-\frac{-1}{z}}=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k$$ $$\frac{1}{12-4z}=\frac{1}{12}\frac{1}{1-\frac{z}{3}}=\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ $$f(z)=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ I can rewrite that as $$f(z)=\frac{1}{4z}\sum_{k=-\infty}^{0} (-1)^k z^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{1}{3}\right)^k z^k$$. I need to move the $\frac{1}{4z}$ and $\frac{1}{12}$ into the sums but finding a series that will converge to each, but I have no idea what to use for either. Any suggestions? Am I taking a wrong approach or is there an obvious series to use for this? Edit: The center is $0$ and the region in $1 \le |z| \le 3$. I think I can use a geometric sequence to say $\frac{1}{4z}=\sum_{k=0}^{\infty}\frac{1}{2}(\frac{1}{2})^{k-1}\frac{z}{k}$ and $\frac{1}{12}=\sum_{k=0}^{\infty}\frac{1}{36}(\frac{2}{9})^{k-1}\frac{z}{k}$. I'm pretty sure that's true, but it seems like it makes the whole thing a complicated mess.","$$f(z)=\frac{1}{(z+1)(3-z)}=\frac{1}{4z+4} + \frac{1}{12-4z}$$ $$\frac{1}{4z+4}=\frac{1}{4z}\frac{1}{1-\frac{-1}{z}}=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k$$ $$\frac{1}{12-4z}=\frac{1}{12}\frac{1}{1-\frac{z}{3}}=\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ $$f(z)=\frac{1}{4z}\sum_{k=0}^{\infty} \left(\frac{-1}{z}\right)^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{z}{3}\right)^k$$ I can rewrite that as $$f(z)=\frac{1}{4z}\sum_{k=-\infty}^{0} (-1)^k z^k+\frac{1}{12}\sum_{k=0}^{\infty} \left(\frac{1}{3}\right)^k z^k$$. I need to move the $\frac{1}{4z}$ and $\frac{1}{12}$ into the sums but finding a series that will converge to each, but I have no idea what to use for either. Any suggestions? Am I taking a wrong approach or is there an obvious series to use for this? Edit: The center is $0$ and the region in $1 \le |z| \le 3$. I think I can use a geometric sequence to say $\frac{1}{4z}=\sum_{k=0}^{\infty}\frac{1}{2}(\frac{1}{2})^{k-1}\frac{z}{k}$ and $\frac{1}{12}=\sum_{k=0}^{\infty}\frac{1}{36}(\frac{2}{9})^{k-1}\frac{z}{k}$. I'm pretty sure that's true, but it seems like it makes the whole thing a complicated mess.",,"['sequences-and-series', 'complex-analysis', 'laurent-series']"
38,Contour Integration of $\sin(x)/x^{1/2}$,Contour Integration of,\sin(x)/x^{1/2},"Please help me with this contour integration:  $$\int_0^\infty \frac{\sin(x)}{x^{1/2}}\,dx$$ My teacher says we can use ML bound, but I don't know how to do this. It cannot be a pole of order $1/2$, right?","Please help me with this contour integration:  $$\int_0^\infty \frac{\sin(x)}{x^{1/2}}\,dx$$ My teacher says we can use ML bound, but I don't know how to do this. It cannot be a pole of order $1/2$, right?",,"['complex-analysis', 'contour-integration']"
39,$f(z)=\frac 1 {x^2+y^2}+i \frac 1 {x^2+y^2} $ is differentiable and holomorphic,is differentiable and holomorphic,f(z)=\frac 1 {x^2+y^2}+i \frac 1 {x^2+y^2} ,"Is the function  $ f(z)=\dfrac 1 {x^2+y^2} + i \dfrac 1 {x^2+y^2} $ is differentiable and holomorphic somewhere? We have $z=x+iy$ and $f(z)= \dfrac{1+i}{|z|^2}$ . Now, $f(0)= \lim_{\delta z \rightarrow 0} \frac{f(0+\delta z) - f(0)}{\delta z}=$ undefined. So $f(z)$ is not differentiable at origin.  Also since since $ f(z)= |z|^2$ is not differentiable anywhere except origin , so $f(z)$ is not not differentiable and hence it is not holomorphic.   But I am not sure, please help me","Is the function  $ f(z)=\dfrac 1 {x^2+y^2} + i \dfrac 1 {x^2+y^2} $ is differentiable and holomorphic somewhere? We have $z=x+iy$ and $f(z)= \dfrac{1+i}{|z|^2}$ . Now, $f(0)= \lim_{\delta z \rightarrow 0} \frac{f(0+\delta z) - f(0)}{\delta z}=$ undefined. So $f(z)$ is not differentiable at origin.  Also since since $ f(z)= |z|^2$ is not differentiable anywhere except origin , so $f(z)$ is not not differentiable and hence it is not holomorphic.   But I am not sure, please help me",,['complex-analysis']
40,Zeros of complex function,Zeros of complex function,,"Consider the function $f(z)=e^{z}+\varepsilon_1e^{\varepsilon_1 z}+\varepsilon_2e^{\varepsilon_2 z}$ of a complex variable $z=x+i y$, where $\varepsilon_1=-\frac{1}{2}+i\frac{\sqrt{3}}{2}$, $\varepsilon_2=-\frac{1}{2}-i\frac{\sqrt{3}}{2}$. Numerical calculations show that all zeros of the function $f(z)$ are located on the lines $y=0$, $y=\pm \sqrt{3} x$. Are there any ideas how to prove it theoretically?","Consider the function $f(z)=e^{z}+\varepsilon_1e^{\varepsilon_1 z}+\varepsilon_2e^{\varepsilon_2 z}$ of a complex variable $z=x+i y$, where $\varepsilon_1=-\frac{1}{2}+i\frac{\sqrt{3}}{2}$, $\varepsilon_2=-\frac{1}{2}-i\frac{\sqrt{3}}{2}$. Numerical calculations show that all zeros of the function $f(z)$ are located on the lines $y=0$, $y=\pm \sqrt{3} x$. Are there any ideas how to prove it theoretically?",,['complex-analysis']
41,f is analytic mapping of the unit disk into itself such that f(a) = 0. Show $|f(z)| \leq |\frac{z-a}{1-\bar{a}z}|$,f is analytic mapping of the unit disk into itself such that f(a) = 0. Show,|f(z)| \leq |\frac{z-a}{1-\bar{a}z}|,"$f$ is analytic mapping of the unit disk into itself such that $f(a) = 0$. Show $|f(z)| \leq |\frac{z-a}{1-\bar{a}z}|$ I considered $F(z) =f(\phi_{-a}(z))$ where $\phi_a(z) = \frac{z-a}{1-\bar{a}z}$ maps unit disk to unit disk and $\phi_{-a}$ is the inverse of $\phi_a$ I get F is analytic mapping unit disk to unit disk, and $F(0) = 0$, so by Schwarz lemma I get $|F(z)|\leq |z|$ and $|F'(0)|\leq1$. And then I get stuck. I am not sure what I can do to get the final inequality. Or maybe I am thinking about the problem in a wrong way.","$f$ is analytic mapping of the unit disk into itself such that $f(a) = 0$. Show $|f(z)| \leq |\frac{z-a}{1-\bar{a}z}|$ I considered $F(z) =f(\phi_{-a}(z))$ where $\phi_a(z) = \frac{z-a}{1-\bar{a}z}$ maps unit disk to unit disk and $\phi_{-a}$ is the inverse of $\phi_a$ I get F is analytic mapping unit disk to unit disk, and $F(0) = 0$, so by Schwarz lemma I get $|F(z)|\leq |z|$ and $|F'(0)|\leq1$. And then I get stuck. I am not sure what I can do to get the final inequality. Or maybe I am thinking about the problem in a wrong way.",,['complex-analysis']
42,Sequence of non-zero holomorphic functions in the unit disk converges locally to 0,Sequence of non-zero holomorphic functions in the unit disk converges locally to 0,,"I could not solve the following problem: Let $\{f_n\}_n$ be a sequence holomorphic functions in the unit disk $\mathbb{D}$ such that all $f_n$ are zero-free in $\mathbb{D}$, $|f_n|<1$ for all $n\geq1$ and $lim_{n\rightarrow\infty}f_n(0)=0$. Prove that the sequence converges uniformly on compacts of $\mathbb{D}$ to 0. This is what I tried: Since $|f_n|<1$, the sequence $\{f_n\}_n$ is uniformly bounded in any compact of $\mathbb{D}$ and hence by Montel theorem, $\{f_n\}_n$ is a normal family. Then, there is a subsequence $\{f_{n_k}\}_k$ that converges to a function $f$ uniformly over compact subsets of $\mathbb{D}$. Now, the sequence $\{f_{n_k}\}_k$ has no zeros and has limit $0$ in $z=0$ by the hypothesis, so $f(0)=0$. By Hurwitz theorem, $f$ is identically zero. But I cannot prove that $\{f_n\}_n$ converges to $f$ uniformly over compact sets. In fact, if I prove the uniform convergence for $\{f_n\}_n$ instead of a subsequence, then we are done. Can someone help me? PD: I looked for the same question but I did not find it. If it is duplicated, I apologize.","I could not solve the following problem: Let $\{f_n\}_n$ be a sequence holomorphic functions in the unit disk $\mathbb{D}$ such that all $f_n$ are zero-free in $\mathbb{D}$, $|f_n|<1$ for all $n\geq1$ and $lim_{n\rightarrow\infty}f_n(0)=0$. Prove that the sequence converges uniformly on compacts of $\mathbb{D}$ to 0. This is what I tried: Since $|f_n|<1$, the sequence $\{f_n\}_n$ is uniformly bounded in any compact of $\mathbb{D}$ and hence by Montel theorem, $\{f_n\}_n$ is a normal family. Then, there is a subsequence $\{f_{n_k}\}_k$ that converges to a function $f$ uniformly over compact subsets of $\mathbb{D}$. Now, the sequence $\{f_{n_k}\}_k$ has no zeros and has limit $0$ in $z=0$ by the hypothesis, so $f(0)=0$. By Hurwitz theorem, $f$ is identically zero. But I cannot prove that $\{f_n\}_n$ converges to $f$ uniformly over compact sets. In fact, if I prove the uniform convergence for $\{f_n\}_n$ instead of a subsequence, then we are done. Can someone help me? PD: I looked for the same question but I did not find it. If it is duplicated, I apologize.",,"['complex-analysis', 'holomorphic-functions']"
43,Prove the equivalence of norms on the Hardy space $H^2(\mathbb{D})$.,Prove the equivalence of norms on the Hardy space .,H^2(\mathbb{D}),"Let $H^2(\mathbb{D})$ be the space of all functions $f$ holomorphic on the open unit disk $\mathbb{D}$ such that the Hardy norm, given below, is finite: $$||f||_H^2 = \sup_{0<r<1}\frac{1}{2\pi}\int_0^{2\pi} |f(re^{i\theta})|^2 \ \mathrm{d}\theta.$$ I have already shown that the evaluation $f\mapsto f(z) \ (z\in\mathbb{D})$ is continuous with respect to the norm $||\cdot||_H$. Now let $||\cdot||$ be any other norm with respect to which $H^2(\mathbb{D})$ is a Banach space, and for which the evaluations $$f\mapsto f(1/(n+1)) \ (n=1,2,...)$$ are continuous. How do I prove that $||\cdot||$ is equivalent to $||\cdot||_H$? I know that, due to a consequence of the Open Mapping Theorem, one need only show one inequality involving these two norms. Moreover, using the Uniform Boundedness Principle, there is a constant $K$ such that, for all $n\in\mathbb{N}, f\in H^2(\mathbb{D})$, we have $$|f(1/(n+1))|\le K<\infty.$$","Let $H^2(\mathbb{D})$ be the space of all functions $f$ holomorphic on the open unit disk $\mathbb{D}$ such that the Hardy norm, given below, is finite: $$||f||_H^2 = \sup_{0<r<1}\frac{1}{2\pi}\int_0^{2\pi} |f(re^{i\theta})|^2 \ \mathrm{d}\theta.$$ I have already shown that the evaluation $f\mapsto f(z) \ (z\in\mathbb{D})$ is continuous with respect to the norm $||\cdot||_H$. Now let $||\cdot||$ be any other norm with respect to which $H^2(\mathbb{D})$ is a Banach space, and for which the evaluations $$f\mapsto f(1/(n+1)) \ (n=1,2,...)$$ are continuous. How do I prove that $||\cdot||$ is equivalent to $||\cdot||_H$? I know that, due to a consequence of the Open Mapping Theorem, one need only show one inequality involving these two norms. Moreover, using the Uniform Boundedness Principle, there is a constant $K$ such that, for all $n\in\mathbb{N}, f\in H^2(\mathbb{D})$, we have $$|f(1/(n+1))|\le K<\infty.$$",,"['complex-analysis', 'hilbert-spaces', 'hardy-spaces']"
44,Definition of analyticity in complex analysis,Definition of analyticity in complex analysis,,"In my complex analysis class, I learned that a complex function $f(z)$ is said to be analytic at $z_0$ if there is a neighborhood around $z_0$ in which $f$ is differentiable. Then, I learned various properties of analytic functions, but I never quite understood why the notion of pointwise differentiability is not enough and we in fact need differentiability ""in nearby neighborhoods"". What is the importance/role of ""neighborhoods"" in this context? What goes wrong if one replaces analyticity with differentiability? I thought that when one talks about pointwise differentiability, one would like to work in open sets and since analyticity and differentiablity are the same in open sets, I do not see what is important about defining analyticity the way it is defined","In my complex analysis class, I learned that a complex function $f(z)$ is said to be analytic at $z_0$ if there is a neighborhood around $z_0$ in which $f$ is differentiable. Then, I learned various properties of analytic functions, but I never quite understood why the notion of pointwise differentiability is not enough and we in fact need differentiability ""in nearby neighborhoods"". What is the importance/role of ""neighborhoods"" in this context? What goes wrong if one replaces analyticity with differentiability? I thought that when one talks about pointwise differentiability, one would like to work in open sets and since analyticity and differentiablity are the same in open sets, I do not see what is important about defining analyticity the way it is defined",,"['complex-analysis', 'definition', 'analyticity', 'analytic-functions']"
45,Contour integral of $\int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx$,Contour integral of,\int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx,"I'm having a little trouble figuring this one out. So far I've got $$I = \int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx$$ Let  $$I' = \oint_C \frac{e^{2\pi z / 3}}{\cosh{\pi z}}dz$$ Where the contour $C$ is a rectangle extending from $-R$ to $R$ in the limit of $R \rightarrow \infty$ and of height 1, which gives $$\int_{-R}^R \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx + \int_{R}^{-R} \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$ $$=I - \int_{-R}^R \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$ $$=\text{Res}(z = \frac{i}{z})$$ I'm having trouble solving the problem from here, as I'm not sure how to handle the separation of the denominator $\cosh{(\pi x + i)}$. Any help is appreciated!","I'm having a little trouble figuring this one out. So far I've got $$I = \int_{-\infty}^\infty \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx$$ Let  $$I' = \oint_C \frac{e^{2\pi z / 3}}{\cosh{\pi z}}dz$$ Where the contour $C$ is a rectangle extending from $-R$ to $R$ in the limit of $R \rightarrow \infty$ and of height 1, which gives $$\int_{-R}^R \frac{e^{2\pi x / 3}}{\cosh{\pi x}}dx + \int_{R}^{-R} \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$ $$=I - \int_{-R}^R \frac{e^{2\pi x / 3 + i}}{\cosh{(\pi x + i)}}dx$$ $$=\text{Res}(z = \frac{i}{z})$$ I'm having trouble solving the problem from here, as I'm not sure how to handle the separation of the denominator $\cosh{(\pi x + i)}$. Any help is appreciated!",,"['complex-analysis', 'contour-integration']"
46,Detail in the use of the Residue Theorem for $\int\limits_{-\infty}^{\infty}\frac{\cos(2x)-1}{x^2}dx$ [duplicate],Detail in the use of the Residue Theorem for  [duplicate],\int\limits_{-\infty}^{\infty}\frac{\cos(2x)-1}{x^2}dx,"This question already has answers here : Question about evaluating the integral $\int_0^\infty \frac{1-\cos(ax)}{x^2}dx$ using the residue theorem (2 answers) Closed last year . As usual, I have a ridiculously specific question about a tiny detail of a tiny calculation. There is a tremendous amount of context, so fair warning. I don't need a solution to this whole problem. I need a solution to one specific part, and it is a minor detail. I'll show what I've got so far, and point out my concern at the end. Our problem is to use residue calculus to compute: $$\int\limits_{-\infty}^{\infty}\frac{\cos(2x)-1}{x^2}dx.$$ We note that this is equal to the real part of the easier-to-work-with integral: $$\int\limits_{-\infty}^{\infty}\frac{e^{2ix}-1}{x^2}dx,$$ and we use a ""hippo's back"" contour, formed by the positively-oriented half-circle $|z|\leq R$ in the upper half-plane and the line along the real axis from $-R$ to $R$, interrupted from $-\varepsilon$ to $\varepsilon$ by the negatively oriented half-circle in the upper half-plane of radius $\varepsilon$, so as to 'jump' over the simple pole at $z=0$. Since this contour contains no poles or singularities, etc., the integral of our integrand around it is zero by Cauchy's Theorem. It is also a simple matter to show that the large half-circle's contribution is zero in the limit $R\to\infty$. So now we are left with the fact that in the limit $\varepsilon\to 0$, we obtain: $$\int\limits_{-\infty}^{\infty}\frac{e^{2ix}-1}{x^2}dx=\lim\limits_{\varepsilon\to 0}\int\limits_{C_\varepsilon}\frac{e^{2iz}-1}{z^2}dz,$$ where $C_\varepsilon$ is the little negatively-oriented half-circle mentioned above. Now, I know the trick in which the value of the right-hand side happens to give exactly $\pi i \text{Res}(f,0)$ (that is, half of what the full circle would give), and can use it to show that the result is $-2\pi$. Okay, thanks for reading this far. Here is my actual question: Without resorting to tricks like the half-residue thing, how can we get this result from the right-hand side? That is, how do we prove rigorously that: $$\lim\limits_{\varepsilon\to 0}\int\limits_{C_\varepsilon}\frac{e^{2iz}-1}{z^2}dz=-2\pi$$ I have been using the parametrization $z=\varepsilon e^{-it}$ with $t\in[0,\pi]$, where the negative in the exponential deals with the negative orientation, which almost always works in these situations, but not here, since the $\varepsilon$ does not entirely cancel from the denominator then as it usually does in these types of problems. I have confirmed the result with Wolfram-Alpha using the original problem statement, and also noted a few other things, like that the original integrand can be expressed as $\frac{\sin^2(x)}{x^2}$, but gotten nowhere with that. In a pinch, I'll use the 'half-residue' trick, but being able to do this simply from basic principles would be nice.","This question already has answers here : Question about evaluating the integral $\int_0^\infty \frac{1-\cos(ax)}{x^2}dx$ using the residue theorem (2 answers) Closed last year . As usual, I have a ridiculously specific question about a tiny detail of a tiny calculation. There is a tremendous amount of context, so fair warning. I don't need a solution to this whole problem. I need a solution to one specific part, and it is a minor detail. I'll show what I've got so far, and point out my concern at the end. Our problem is to use residue calculus to compute: $$\int\limits_{-\infty}^{\infty}\frac{\cos(2x)-1}{x^2}dx.$$ We note that this is equal to the real part of the easier-to-work-with integral: $$\int\limits_{-\infty}^{\infty}\frac{e^{2ix}-1}{x^2}dx,$$ and we use a ""hippo's back"" contour, formed by the positively-oriented half-circle $|z|\leq R$ in the upper half-plane and the line along the real axis from $-R$ to $R$, interrupted from $-\varepsilon$ to $\varepsilon$ by the negatively oriented half-circle in the upper half-plane of radius $\varepsilon$, so as to 'jump' over the simple pole at $z=0$. Since this contour contains no poles or singularities, etc., the integral of our integrand around it is zero by Cauchy's Theorem. It is also a simple matter to show that the large half-circle's contribution is zero in the limit $R\to\infty$. So now we are left with the fact that in the limit $\varepsilon\to 0$, we obtain: $$\int\limits_{-\infty}^{\infty}\frac{e^{2ix}-1}{x^2}dx=\lim\limits_{\varepsilon\to 0}\int\limits_{C_\varepsilon}\frac{e^{2iz}-1}{z^2}dz,$$ where $C_\varepsilon$ is the little negatively-oriented half-circle mentioned above. Now, I know the trick in which the value of the right-hand side happens to give exactly $\pi i \text{Res}(f,0)$ (that is, half of what the full circle would give), and can use it to show that the result is $-2\pi$. Okay, thanks for reading this far. Here is my actual question: Without resorting to tricks like the half-residue thing, how can we get this result from the right-hand side? That is, how do we prove rigorously that: $$\lim\limits_{\varepsilon\to 0}\int\limits_{C_\varepsilon}\frac{e^{2iz}-1}{z^2}dz=-2\pi$$ I have been using the parametrization $z=\varepsilon e^{-it}$ with $t\in[0,\pi]$, where the negative in the exponential deals with the negative orientation, which almost always works in these situations, but not here, since the $\varepsilon$ does not entirely cancel from the denominator then as it usually does in these types of problems. I have confirmed the result with Wolfram-Alpha using the original problem statement, and also noted a few other things, like that the original integrand can be expressed as $\frac{\sin^2(x)}{x^2}$, but gotten nowhere with that. In a pinch, I'll use the 'half-residue' trick, but being able to do this simply from basic principles would be nice.",,"['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
47,Meromorphic function on projective plane and complex torus,Meromorphic function on projective plane and complex torus,,"I'm attempting to do the following questions from Miranda's Algebraic Curves and Riemann Surfaces. Question II.2.A -  Consider the projective line $\mathbb{P}^1$. Fix a point $p \in \mathbb{P}^1$, and a finite set $S \subset \mathbb{P}^1$ with $p \not \in S$. Show that there exists a meromorphic function $f$ on $\mathbb{P}^1$ with a simple at $p$ and no zeroes or poles at any of the points of $S$. Question II.2.H - Consider the complex torus $X = \mathbb{C}/L$. Fix a point $p \in X$, and a finite set $S \subset X$ with $p \not \in S$. Show that there exists a meromorphic function $f$ on $X$ with a simple zero at $p$ and no zeroes or poles at any of the points of $S$. I've been able to do the other questions, but am unsure of how to prove that there actually exists meromorphic functions with these properties.","I'm attempting to do the following questions from Miranda's Algebraic Curves and Riemann Surfaces. Question II.2.A -  Consider the projective line $\mathbb{P}^1$. Fix a point $p \in \mathbb{P}^1$, and a finite set $S \subset \mathbb{P}^1$ with $p \not \in S$. Show that there exists a meromorphic function $f$ on $\mathbb{P}^1$ with a simple at $p$ and no zeroes or poles at any of the points of $S$. Question II.2.H - Consider the complex torus $X = \mathbb{C}/L$. Fix a point $p \in X$, and a finite set $S \subset X$ with $p \not \in S$. Show that there exists a meromorphic function $f$ on $X$ with a simple zero at $p$ and no zeroes or poles at any of the points of $S$. I've been able to do the other questions, but am unsure of how to prove that there actually exists meromorphic functions with these properties.",,"['abstract-algebra', 'complex-analysis']"
48,Conditions for an entire doubly periodic function to be constant,Conditions for an entire doubly periodic function to be constant,,"I was going through the proof of the fact that an entire doubly periodic function is constant (using Liouville's theorem). My question is, do I have to assume the periods are independent over $\mathbb R$? For example, if I have an entire function $f$ with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for all $z\in\mathbb C$ with the $\lambda_1,\lambda_2$ being independent over, say $\mathbb Q$, but not necessarily over $\mathbb R$, does it still follow that $f$ is constant? I felt the proof I'm reading uses somewhere the fact that the period parallelogram is generated by two complex numbers forming a $\mathbb R$ basis of $\mathbb C$. What happens if I take them to be only independent over $\mathbb Q$? They may no longer form a basis for $\mathbb C$ but it seems that even then if $f$ is entire with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for $\lambda_1,\lambda_2$ independent over $\mathbb Q$, it has to be constant. Why is that true?","I was going through the proof of the fact that an entire doubly periodic function is constant (using Liouville's theorem). My question is, do I have to assume the periods are independent over $\mathbb R$? For example, if I have an entire function $f$ with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for all $z\in\mathbb C$ with the $\lambda_1,\lambda_2$ being independent over, say $\mathbb Q$, but not necessarily over $\mathbb R$, does it still follow that $f$ is constant? I felt the proof I'm reading uses somewhere the fact that the period parallelogram is generated by two complex numbers forming a $\mathbb R$ basis of $\mathbb C$. What happens if I take them to be only independent over $\mathbb Q$? They may no longer form a basis for $\mathbb C$ but it seems that even then if $f$ is entire with $f(z+\lambda_1)=f(z+\lambda_2)=f(z)$ for $\lambda_1,\lambda_2$ independent over $\mathbb Q$, it has to be constant. Why is that true?",,"['complex-analysis', 'elliptic-functions', 'entire-functions']"
49,What is motivation to study Harmonic functions?,What is motivation to study Harmonic functions?,,Recall that a function $f:U (\subset \mathbb R^n) \to \mathbb R$ is called harmonic if $\Delta f=0$ where $\Delta$ is Laplacian operator. What is a good motivation to study harmonic functions?,Recall that a function $f:U (\subset \mathbb R^n) \to \mathbb R$ is called harmonic if $\Delta f=0$ where $\Delta$ is Laplacian operator. What is a good motivation to study harmonic functions?,,"['real-analysis', 'complex-analysis', 'functions', 'harmonic-functions']"
50,Periodicity of Sine from infinite Product Formula: $z\prod_{n=1}^{\infty}\left( 1 - \frac{z^2}{n^2\pi^2}\right)$,Periodicity of Sine from infinite Product Formula:,z\prod_{n=1}^{\infty}\left( 1 - \frac{z^2}{n^2\pi^2}\right),Let $\sin z$ be defined by the following infinite product: $$ \sin (z) = z \prod_{n=1}^{\infty} \left( 1 - \frac{z^2}{n^2\pi^2} \right) $$ How can one derive that $\sin(z + 2\pi) = \sin(z)$?,Let $\sin z$ be defined by the following infinite product: $$ \sin (z) = z \prod_{n=1}^{\infty} \left( 1 - \frac{z^2}{n^2\pi^2} \right) $$ How can one derive that $\sin(z + 2\pi) = \sin(z)$?,,"['complex-analysis', 'periodic-functions', 'infinite-product']"
51,Line Segment Complex Analysis,Line Segment Complex Analysis,,"Let $\alpha, \beta \in \mathbb{C}$. The line segment with end points $\alpha$ and $\beta$ is: \begin{equation} [\alpha,\beta]:=\{(1-t)\alpha+t\beta : 0\leq t\leq 1\} \end{equation} How do we explain this? My book just says it is obvious. I kind of get that it might work, but how does someone goes about finding this expression? Clearly we have that at $t = 0$ we get $\alpha$ and at $t = 1$ we get $\beta$. However for $0\leq t \leq 1$ all I see is some kind of weighted sum, but I can't visualize a segment between $\alpha$ and $\beta$. Any suggestion? I'd like to find a way to understand this cause I don't want to just memorize the formula, I want to be able to work it out. Thank you","Let $\alpha, \beta \in \mathbb{C}$. The line segment with end points $\alpha$ and $\beta$ is: \begin{equation} [\alpha,\beta]:=\{(1-t)\alpha+t\beta : 0\leq t\leq 1\} \end{equation} How do we explain this? My book just says it is obvious. I kind of get that it might work, but how does someone goes about finding this expression? Clearly we have that at $t = 0$ we get $\alpha$ and at $t = 1$ we get $\beta$. However for $0\leq t \leq 1$ all I see is some kind of weighted sum, but I can't visualize a segment between $\alpha$ and $\beta$. Any suggestion? I'd like to find a way to understand this cause I don't want to just memorize the formula, I want to be able to work it out. Thank you",,"['complex-analysis', 'parametrization']"
52,A proof of L'Hopital's rule for complex functions,A proof of L'Hopital's rule for complex functions,,"I haven't seen a proof of this here on Math Stack Exchange, and searching the internet, I couldn't find it clearly stated somewhere. So I'll state the claim and provide a sketch for a proof. If you find that there's some invalid step in the proof, please point it out. Thanks. Claim: Let $a \in \Bbb C$ and $D$ be a domain in $\Bbb C$ such that $ a\in D$ . Let $f,g: D \to \Bbb C$ be analytic non-identically-zero functions such that $f(a) = g(a) = 0$ . On the condition that $\lim_{z \to a }\frac{f'(z)}{g'(z)}$ exists, we have that $\lim_{z \to a}\frac{f(z)}{g(z)}$ exists and: $$L:=\lim_{z \to a}\frac{f(z)}{g(z)} = \lim_{z \to a }\frac{f'(z)}{g'(z)}=:L'$$","I haven't seen a proof of this here on Math Stack Exchange, and searching the internet, I couldn't find it clearly stated somewhere. So I'll state the claim and provide a sketch for a proof. If you find that there's some invalid step in the proof, please point it out. Thanks. Claim: Let and be a domain in such that . Let be analytic non-identically-zero functions such that . On the condition that exists, we have that exists and:","a \in \Bbb C D \Bbb C  a\in D f,g: D \to \Bbb C f(a) = g(a) = 0 \lim_{z \to a }\frac{f'(z)}{g'(z)} \lim_{z \to a}\frac{f(z)}{g(z)} L:=\lim_{z \to a}\frac{f(z)}{g(z)} = \lim_{z \to a }\frac{f'(z)}{g'(z)}=:L'",['complex-analysis']
53,Exam problem on poles and singularity of a complex function,Exam problem on poles and singularity of a complex function,,"I am solving the following Exam question: Question Choose the correct options from the following Consider the function   $\displaystyle{% \,\mathrm{F}\left(\, z\,\right) = \int_{1}^{2}{\mathrm{d}x \over \left(x - z\right)^{2}} \,,\quad \Im\left(\, z\,\right) > 0} $ Then there is a mermorphic function $G(z)$ on $\mathbb{C}$ that agrees with $\,\mathrm{F}(z)$ when  $\Im\left(z\right)>0$, such that $1$, $\infty$ are poles of $G(z)$. $0$, $1$, $\infty$ are poles of $G(z)$. $1$, $2$ are poles of $G(z)$. $1$, $2$ are simple poles of $G(z)$. My approach As question says Meromorphic function $G(z)$ agrees with $\,\mathrm{F}(z)$ on $\Im(z)>0$. We can take $G(z)= \int_{1}^2\frac{1}{\left(\, x - z\,\right)^{\,\, 2}}\,\mathrm{d}x$. If we integrate this function with respect to $x$ assuming $z$ as a constant we will get $G(z) = {1 \over 2 - z} - {1 \over 1-z}$. This shows that given function $G(z)$ has simple poles of order $1$ and $2$. Hence options $3$ and $4$ are correct. My doubt. I am not sure whether my approach is correct as the way question has been projected as an integration of a complex function where variable of integration is $x$ is new to me. Also, whats the logic behind considering $\Im(z)>0$? Thank you for your time.","I am solving the following Exam question: Question Choose the correct options from the following Consider the function   $\displaystyle{% \,\mathrm{F}\left(\, z\,\right) = \int_{1}^{2}{\mathrm{d}x \over \left(x - z\right)^{2}} \,,\quad \Im\left(\, z\,\right) > 0} $ Then there is a mermorphic function $G(z)$ on $\mathbb{C}$ that agrees with $\,\mathrm{F}(z)$ when  $\Im\left(z\right)>0$, such that $1$, $\infty$ are poles of $G(z)$. $0$, $1$, $\infty$ are poles of $G(z)$. $1$, $2$ are poles of $G(z)$. $1$, $2$ are simple poles of $G(z)$. My approach As question says Meromorphic function $G(z)$ agrees with $\,\mathrm{F}(z)$ on $\Im(z)>0$. We can take $G(z)= \int_{1}^2\frac{1}{\left(\, x - z\,\right)^{\,\, 2}}\,\mathrm{d}x$. If we integrate this function with respect to $x$ assuming $z$ as a constant we will get $G(z) = {1 \over 2 - z} - {1 \over 1-z}$. This shows that given function $G(z)$ has simple poles of order $1$ and $2$. Hence options $3$ and $4$ are correct. My doubt. I am not sure whether my approach is correct as the way question has been projected as an integration of a complex function where variable of integration is $x$ is new to me. Also, whats the logic behind considering $\Im(z)>0$? Thank you for your time.",,['complex-analysis']
54,Show that $\sum_{n = 1}^{\infty} \frac{1}{z + n} + \frac{1}{z-n}$ is absolutely convergent for all $z \in \mathbb{H}$,Show that  is absolutely convergent for all,\sum_{n = 1}^{\infty} \frac{1}{z + n} + \frac{1}{z-n} z \in \mathbb{H},"I need to show that the series $$ \sum_{n = 1}^{\infty} \frac{1}{z + n} + \frac{1}{z-n} $$ is absolutely convergent for all $z$ in the complex upper half plane $\mathbb{H} = \{ z \in \mathbb{C} : \Im(z) > 0 \}$. Taking modulus of each term, I get $$ \sum_{n = 1}^{\infty} \left| \frac{1}{z + n} + \frac{1}{z-n} \right| = 2|z| \sum_{n = 1}^{\infty} \frac{1}{| z^2 - n^2 |}. $$ I think I want to be able to compare this to the series $$ \sum_{n = 1}^{\infty} \frac{1}{n^2} $$ which converges, and so conclude that the original series is absolutely convergent, but I don't know how to do that. Could anyone please help me with this?","I need to show that the series $$ \sum_{n = 1}^{\infty} \frac{1}{z + n} + \frac{1}{z-n} $$ is absolutely convergent for all $z$ in the complex upper half plane $\mathbb{H} = \{ z \in \mathbb{C} : \Im(z) > 0 \}$. Taking modulus of each term, I get $$ \sum_{n = 1}^{\infty} \left| \frac{1}{z + n} + \frac{1}{z-n} \right| = 2|z| \sum_{n = 1}^{\infty} \frac{1}{| z^2 - n^2 |}. $$ I think I want to be able to compare this to the series $$ \sum_{n = 1}^{\infty} \frac{1}{n^2} $$ which converges, and so conclude that the original series is absolutely convergent, but I don't know how to do that. Could anyone please help me with this?",,['sequences-and-series']
55,A Riemann surface for the function $f(z) = z^{1/p} + z^{1/q}$,A Riemann surface for the function,f(z) = z^{1/p} + z^{1/q},"When considering the Riemann surface for the function $f(z) = z^{1/p} + z^{1/q}$, where $p,q$ are positive integers, I always thought that it consists of $pq$ branches. However, then I analyzed the function $$f(z) = z^{1/2} + z^{1/4}.$$ It has a single branch cut on the negative real axis. I would expect it to have 8 branches. But, when I start to move on the unit circle around the origin from the point $z=1$, I found that I have to encircle the origin only four times to get back to the original value $f(1) = 2$. Specifically, on the branch, the function changes according to $$\sqrt{z} + \sqrt[4]{z} \to -\sqrt{z} + i \sqrt[4]{z} \to \sqrt{z} - \sqrt[4]{z} \to -\sqrt{z} -i \sqrt[4]{z} \to \sqrt{z} + \sqrt[4]{z}$$ Am I missing some additional branch cuts? What is going on here?","When considering the Riemann surface for the function $f(z) = z^{1/p} + z^{1/q}$, where $p,q$ are positive integers, I always thought that it consists of $pq$ branches. However, then I analyzed the function $$f(z) = z^{1/2} + z^{1/4}.$$ It has a single branch cut on the negative real axis. I would expect it to have 8 branches. But, when I start to move on the unit circle around the origin from the point $z=1$, I found that I have to encircle the origin only four times to get back to the original value $f(1) = 2$. Specifically, on the branch, the function changes according to $$\sqrt{z} + \sqrt[4]{z} \to -\sqrt{z} + i \sqrt[4]{z} \to \sqrt{z} - \sqrt[4]{z} \to -\sqrt{z} -i \sqrt[4]{z} \to \sqrt{z} + \sqrt[4]{z}$$ Am I missing some additional branch cuts? What is going on here?",,[]
56,Find all solutions of $e^{e^z}=1$ in the complex space.,Find all solutions of  in the complex space.,e^{e^z}=1,"Find all solutions of $e^{e^z}=1$ in the complex space. Attempt: $e^{e^z}=1$. Assuming $e^z$ is a complex number, I will start off solving $e^z=e^{x+yi}=1$: $e^x(\cos y+i\sin y)=1\Rightarrow \sin y=0\Rightarrow y=\pi k$. Now, $e^x>0\Rightarrow \cos y =0,\pm 1$. Then $y$ has to be $2\pi k$, and $x$ has to be $0$. Assuming I don't miss solutions (which I really can't tell), I set: $$e^z=2\pi k i$$. $e^x(\cos y+i\sin y)=2\pi k i\Rightarrow y={\pi\over 2}+\pi m, \sin y=\pm 1$. Now $\pm e^x =2\pi k$ (Am I allow to do this?). Now I get $x=\ln (2\pi k)$ but $\ln$ only work with $k\ge 1$ in the Real Numbers, so taking $\pm e^x=2\pi k (k>0)$ instead seems to solve the issue. I get: $z=ln(2\pi k)+i({\pi \over 2}+\pi m), (k,m)\in \Bbb{Z}_+\times \Bbb{Z}$. Checking it gives the required results. My only insecurity is all the branches idea. Would you guide me?","Find all solutions of $e^{e^z}=1$ in the complex space. Attempt: $e^{e^z}=1$. Assuming $e^z$ is a complex number, I will start off solving $e^z=e^{x+yi}=1$: $e^x(\cos y+i\sin y)=1\Rightarrow \sin y=0\Rightarrow y=\pi k$. Now, $e^x>0\Rightarrow \cos y =0,\pm 1$. Then $y$ has to be $2\pi k$, and $x$ has to be $0$. Assuming I don't miss solutions (which I really can't tell), I set: $$e^z=2\pi k i$$. $e^x(\cos y+i\sin y)=2\pi k i\Rightarrow y={\pi\over 2}+\pi m, \sin y=\pm 1$. Now $\pm e^x =2\pi k$ (Am I allow to do this?). Now I get $x=\ln (2\pi k)$ but $\ln$ only work with $k\ge 1$ in the Real Numbers, so taking $\pm e^x=2\pi k (k>0)$ instead seems to solve the issue. I get: $z=ln(2\pi k)+i({\pi \over 2}+\pi m), (k,m)\in \Bbb{Z}_+\times \Bbb{Z}$. Checking it gives the required results. My only insecurity is all the branches idea. Would you guide me?",,"['complex-analysis', 'proof-verification']"
57,"For $f$ analytic on $|z|<1$, $|f|\le M$ with $a_1,\ldots,a_n\in \Bbb{D}$ zeros of $f$ show that $|f(0)|\le M \prod |a_j|$","For  analytic on ,  with  zeros of  show that","f |z|<1 |f|\le M a_1,\ldots,a_n\in \Bbb{D} f |f(0)|\le M \prod |a_j|","For $f$ analytic in unit disk $\Bbb{D}$ where $|f|\le M$ with $a_1,\ldots,a_n\in \Bbb{D}$ such that $f(a_1)=\cdots=f(a_n)=0$ show that $|f(0)|\le M \prod |a_j|$. I have tried many approaches including modifying the function using the Cauchy Formula, ML estimate, Maximum Principle and more. nothing seems to get me forward. I am really clueless here and could use a guidance.","For $f$ analytic in unit disk $\Bbb{D}$ where $|f|\le M$ with $a_1,\ldots,a_n\in \Bbb{D}$ such that $f(a_1)=\cdots=f(a_n)=0$ show that $|f(0)|\le M \prod |a_j|$. I have tried many approaches including modifying the function using the Cauchy Formula, ML estimate, Maximum Principle and more. nothing seems to get me forward. I am really clueless here and could use a guidance.",,['complex-analysis']
58,Show the roots of the quadratic equation $z^2 +bz+ c = 0$ lie in or on the unit circle,Show the roots of the quadratic equation  lie in or on the unit circle,z^2 +bz+ c = 0,"So I need a little help with the following: Considering separately the cases of real and complex roots show that the roots of the quadratic equation  $z^2 +bz+ c = 0$ lie in or on the unit circle (i.e. $|z_{i}|\leq 1$) if and only if $|c|\leq1$ and $|b|\leq 1+c$, where $b$ and $c$ are real coefficients. I showed both sides of the relation for real roots, but now I am stuck on the complex case. Any ideas?","So I need a little help with the following: Considering separately the cases of real and complex roots show that the roots of the quadratic equation  $z^2 +bz+ c = 0$ lie in or on the unit circle (i.e. $|z_{i}|\leq 1$) if and only if $|c|\leq1$ and $|b|\leq 1+c$, where $b$ and $c$ are real coefficients. I showed both sides of the relation for real roots, but now I am stuck on the complex case. Any ideas?",,"['complex-analysis', 'inequality', 'polynomials', 'roots', 'quadratics']"
59,"Biholomorphic $f:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:|z|<1\}$",Biholomorphic,"f:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:|z|<1\}","Is there a bijective holomorphic function $$f:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:|z|<1\}$$ such that $f^{-1}$ is holomorphic? You can give me a composition of functions. For example: If you know a biholomorphic function $$f_0:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:Im(z)>0\}=:H$$ that's enough as the function $$f_1:H\rightarrow\{z\in\mathbb{C}:|z|<1\}$$ is biholomorphic.","Is there a bijective holomorphic function $$f:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:|z|<1\}$$ such that $f^{-1}$ is holomorphic? You can give me a composition of functions. For example: If you know a biholomorphic function $$f_0:\{z\in\mathbb{C}:|z|<1,~Im(z)>0\}\rightarrow\{z\in\mathbb{C}:Im(z)>0\}=:H$$ that's enough as the function $$f_1:H\rightarrow\{z\in\mathbb{C}:|z|<1\}$$ is biholomorphic.",,['complex-analysis']
60,Singularity at $z=0$ for $1-\cos(z)\sin(\frac{1}{z})$,Singularity at  for,z=0 1-\cos(z)\sin(\frac{1}{z}),"Any ideas for solving this problem, mentioned in our last exam, is highly appreciated. What is the residue of $f(z)=(1-\cos z)\sin \frac{1}{z}$ at the isolated point $z=0$ ? Our notes say the answer is: $ - \sum_{n=2}^{\infty} \frac {1}{n!} \frac {1}{(n+1)!}  $ what is the step that reach to above solution?","Any ideas for solving this problem, mentioned in our last exam, is highly appreciated. What is the residue of $f(z)=(1-\cos z)\sin \frac{1}{z}$ at the isolated point $z=0$ ? Our notes say the answer is: $ - \sum_{n=2}^{\infty} \frac {1}{n!} \frac {1}{(n+1)!}  $ what is the step that reach to above solution?",,"['calculus', 'real-analysis', 'linear-algebra', 'complex-analysis', 'contest-math']"
61,"I don't understand why $\oint_\gamma f\, dz=0$ holds for holomorphic functions.",I don't understand why  holds for holomorphic functions.,"\oint_\gamma f\, dz=0","I've recently learned a proof of Cauchy's Integral Theorem, i.e, If $U\subseteq \Bbb C$ is  open and simply connected, $f:U\to\Bbb C$ is holomorphic and $\gamma$ is a closed curve, $\gamma\subseteq U$, then   $$ \oint_\gamma f(z)\,\mathrm dz=0 $$ But I don't understand why this is true, I'm looking for intuition, as just from reading a proof, this still seems a bit magical. I'm not searching for proofs, intuitive arguments are sufficient.","I've recently learned a proof of Cauchy's Integral Theorem, i.e, If $U\subseteq \Bbb C$ is  open and simply connected, $f:U\to\Bbb C$ is holomorphic and $\gamma$ is a closed curve, $\gamma\subseteq U$, then   $$ \oint_\gamma f(z)\,\mathrm dz=0 $$ But I don't understand why this is true, I'm looking for intuition, as just from reading a proof, this still seems a bit magical. I'm not searching for proofs, intuitive arguments are sufficient.",,"['complex-analysis', 'intuition']"
62,Proving recurrence relation with induction: $T(n) = T(n-1) + n$,Proving recurrence relation with induction:,T(n) = T(n-1) + n,"I have to prove that the bound of the following relation is $\theta(n^2)$ by induction- $$T(n) = T(n-1) +  n$$ should i seprate my induction into two sections -  to claim  that $T(n) = O(n^2)$ and $T(n) = \Omega(n^2)$ and prove each case, or should i expand the relation and then formulate my claims ? should my two equations be the same , but with diffrent sign  -->   $\leq$ and $\geq$ Thanks!","I have to prove that the bound of the following relation is $\theta(n^2)$ by induction- $$T(n) = T(n-1) +  n$$ should i seprate my induction into two sections -  to claim  that $T(n) = O(n^2)$ and $T(n) = \Omega(n^2)$ and prove each case, or should i expand the relation and then formulate my claims ? should my two equations be the same , but with diffrent sign  -->   $\leq$ and $\geq$ Thanks!",,"['calculus', 'sequences-and-series', 'complex-analysis', 'asymptotics']"
63,Prove that $ζ(4)=π^4/90$ knowing that $\sin(πz) = πz \prod_{n=1}^∞ \left( 1 - \frac{z^2}{n^2} \right)$,Prove that  knowing that,ζ(4)=π^4/90 \sin(πz) = πz \prod_{n=1}^∞ \left( 1 - \frac{z^2}{n^2} \right),"The question Knowing that: $$\sin(πz) = πz \prod_{n=1}^∞ \left( 1 - \frac{z^2}{n^2} \right) \tag{1}$$ obtain the Taylor series expansion of $\frac{\sin(πz)}{πz}$ to deduce: $$ \sum_{1 ≤ n_1 < n_2 < … < n_k} \frac{1}{n_1^2n_2^2 … n_k^2} = \frac{π^{2k}}{(2k + 1)!} \tag{2}$$ Also deduce that: $$ ζ(4) = \sum_{n=1}^∞ \frac{1}{n^4} = \frac{π^4}{90} \tag{3}$$ What I've obtained For (2) I've done the following (doing what the question suggests): $$ 1 - \frac{z^2π^2}{3!} + \frac{z^4π^4}{5!} - … = (1 - z^2)\left(1 - \frac{z^2}{2^2}\right)\left(1 - \frac{z^2}{3^2}\right)\left(1 - \frac{z^2}{4^2}\right)…= $$ $$ = 1 - z^2\left( 1 + \frac{1}{2^2} + \frac{1}{3^2} + … \right) + z^4 \left( \frac{1}{1^22^2} + \frac{1}{1^23^2} + … + \frac{1}{2^23^2}+…\right) - z^6\left( \frac{1}{1^22^23^2} +\frac{1}{1^22^24^2} + … + \frac{1}{1^23^24^2} + … \right) + … =$$ $$ = 1 - z^2\sum_{1 ≤ n_1}\frac{1}{n_1^2} + z^4 \sum_{1 ≤ n_1 < n_2}\frac{1}{n_1^2n_2^2} + … $$ So one sees that (2) necessarily holds. For (3) I've tried taking $\sum_{1 ≤ n_1<n_2}\frac{1}{n_1^2n_2^2}$ in order to have exponent 4 in the numerator, but according to (2) that gives $π^4/120$. That try is obviously not correct since $n_1≠n_2$ and $90≠120$, but I don't know how how to prove it. Any help?","The question Knowing that: $$\sin(πz) = πz \prod_{n=1}^∞ \left( 1 - \frac{z^2}{n^2} \right) \tag{1}$$ obtain the Taylor series expansion of $\frac{\sin(πz)}{πz}$ to deduce: $$ \sum_{1 ≤ n_1 < n_2 < … < n_k} \frac{1}{n_1^2n_2^2 … n_k^2} = \frac{π^{2k}}{(2k + 1)!} \tag{2}$$ Also deduce that: $$ ζ(4) = \sum_{n=1}^∞ \frac{1}{n^4} = \frac{π^4}{90} \tag{3}$$ What I've obtained For (2) I've done the following (doing what the question suggests): $$ 1 - \frac{z^2π^2}{3!} + \frac{z^4π^4}{5!} - … = (1 - z^2)\left(1 - \frac{z^2}{2^2}\right)\left(1 - \frac{z^2}{3^2}\right)\left(1 - \frac{z^2}{4^2}\right)…= $$ $$ = 1 - z^2\left( 1 + \frac{1}{2^2} + \frac{1}{3^2} + … \right) + z^4 \left( \frac{1}{1^22^2} + \frac{1}{1^23^2} + … + \frac{1}{2^23^2}+…\right) - z^6\left( \frac{1}{1^22^23^2} +\frac{1}{1^22^24^2} + … + \frac{1}{1^23^24^2} + … \right) + … =$$ $$ = 1 - z^2\sum_{1 ≤ n_1}\frac{1}{n_1^2} + z^4 \sum_{1 ≤ n_1 < n_2}\frac{1}{n_1^2n_2^2} + … $$ So one sees that (2) necessarily holds. For (3) I've tried taking $\sum_{1 ≤ n_1<n_2}\frac{1}{n_1^2n_2^2}$ in order to have exponent 4 in the numerator, but according to (2) that gives $π^4/120$. That try is obviously not correct since $n_1≠n_2$ and $90≠120$, but I don't know how how to prove it. Any help?",,"['complex-analysis', 'infinite-product']"
64,Expand the function $f(z)=\frac{1}{(z-a)(z-b)}$ where $0 < |a| < |b|$ in a Laurent series in different annuli,Expand the function  where  in a Laurent series in different annuli,f(z)=\frac{1}{(z-a)(z-b)} 0 < |a| < |b|,"I have to expand the function $f(z) = \frac{1}{(z-a)(z-b)}$ where $a, b \in \mathbb{C}$, $0 < |a| < |b|$ in the following annuli: (a) $0<|z|<|a|$ (b) $|a|<|z|<|b|$ (c) $|b|<|z|$ I made bonafide attempts at $(b)$ and $(c)$, which I'll share below; however, I was not sure what to do about the $0<|z|$ part in (a). I'm kind of teaching these to myself, and the only examples I've seen with a $0$ in them have involved something like $0< |z+2| <|a|$, or something like that where you'd have to make a substitution $w$... Please let me know how to take care of examples like (a). Also, here are my attempts at parts (b) and (c). Please let me know if they're correct, and if not, let me know what I need to do in order to fix them: (b) $\mathbf{|a|<|z|<|b|}$. Using partial fractions, I wrote $\frac{1}{(z-a)(z-b)} = \frac{1}{a-b}\left( \frac{1}{z-a}\right) - \frac{1}{a-b}\left( \frac{1}{z-b}\right)$. Now, if $|z|> |a|$, then $\left\vert \frac{a}{z}\right\vert< 1$, so we write $\frac{1}{(a-b)(z-a)} = \frac{1}{(a-b)z(1-a/z)} = \frac{1}{a-b}\cdot \frac{1}{z} \cdot \sum_{n=0}^{\infty} \left( \frac{a}{z}\right)^{n} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}}$. If $|z|<|b|$, then $\left\vert \frac{z}{b}\right\vert < 1$, so we write $\displaystyle \frac{-1}{(a-b)}\cdot \frac{1}{(z-b)} = \frac{-1}{(a-b)}\cdot \frac{1}{b\left( \frac{z}{b} - 1 \right)} = \frac{1}{b(a-b)}\frac{1}{1-\frac{z}{b}} = \frac{1}{b(a-b)}\sum_{n=0}^{\infty}\left( \frac{z}{b}\right)^{n} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{z^{n}}{b^{n+1}}$ So, the whole expansion is $\displaystyle \frac{1}{z-b} \left( \sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}} + \sum_{n=0}^{\infty}\frac{z^{n}}{b^{n+1}}\right)\\ \displaystyle  = \frac{1}{a-b} \left( \frac{1}{z} + \frac{a}{z^{2}} + \frac{a^{2}}{z^{3}} + \cdots + \frac{1}{b} + \frac{z}{b^{2}}+\frac{z^{2}}{b^{3}}+\cdots\right) \\ \displaystyle =  \frac{1}{z(a-b)} + \frac{a}{z^{2}(a-b)} + \frac{a^{2}}{z^{3}(a-b)} + \cdots + \frac{1}{b(a-b)} + \frac{z}{b^{2}(a-b)}+\frac{z^{2}}{b^{3}(a-b)}+\cdots$ (c) $\mathbf{|b|<|z|}$.  If $|a|<|z|$, we have, as in part (b) $\displaystyle \frac{1}{(a-b)}\frac{1}{(z-a)} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}}$. If $|b|<|z|$, $\displaystyle \frac{1}{(a-b)}\frac{1}{(z-b)} = \frac{1}{(a-b)} \frac{1}{z \left( 1 - \frac{b}{z}\right)}   \\ \displaystyle = \frac{1}{(a-b)}\frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{b}{z}\right)^{n} \\ \displaystyle = \frac{1}{(a-b)}\frac{1}{z}\left( 1 + \frac{b}{z} + \frac{b^{2}}{z^{2}} + \cdots \right) \\ \displaystyle = \frac{1}{(a-b)} \left( \frac{1}{z} + \frac{b}{z^{2}} + \frac{b^{2}}{z^{3}}+ \cdots\right)$ Then, the required Laurent expansion valid for both $|z|>|a|$ and $|z|>|b|$ is found by subtraction: $ \displaystyle  \frac{1}{(a-b)} \left( \frac{1}{z} - \frac{1}{z} + \frac{a}{z^{2}} - \frac{b}{z^{2}} + \frac{a^{2}}{z^{3}} - \frac{b^{2}}{z^{3}} + \cdots \right) \\ \displaystyle = \frac{1}{(a-b)} \left( \frac{a-b}{z^{2}} + \frac{a^{2}-b^{2}}{z^{3}} + \frac{a^{3}-b^{3}}{z^{4}} + \cdots \right) \\ \displaystyle = \left( \frac{1}{z^{2}} + \frac{a^{2}-b^{2}}{z^{3}(a-b)} + \frac{a^{3}-b^{3}}{z^{4}(a-b)} + \cdots \right)$ Again, please let me know how to do part (a), as well as if my parts (b) and (c) are ok. Thanks.","I have to expand the function $f(z) = \frac{1}{(z-a)(z-b)}$ where $a, b \in \mathbb{C}$, $0 < |a| < |b|$ in the following annuli: (a) $0<|z|<|a|$ (b) $|a|<|z|<|b|$ (c) $|b|<|z|$ I made bonafide attempts at $(b)$ and $(c)$, which I'll share below; however, I was not sure what to do about the $0<|z|$ part in (a). I'm kind of teaching these to myself, and the only examples I've seen with a $0$ in them have involved something like $0< |z+2| <|a|$, or something like that where you'd have to make a substitution $w$... Please let me know how to take care of examples like (a). Also, here are my attempts at parts (b) and (c). Please let me know if they're correct, and if not, let me know what I need to do in order to fix them: (b) $\mathbf{|a|<|z|<|b|}$. Using partial fractions, I wrote $\frac{1}{(z-a)(z-b)} = \frac{1}{a-b}\left( \frac{1}{z-a}\right) - \frac{1}{a-b}\left( \frac{1}{z-b}\right)$. Now, if $|z|> |a|$, then $\left\vert \frac{a}{z}\right\vert< 1$, so we write $\frac{1}{(a-b)(z-a)} = \frac{1}{(a-b)z(1-a/z)} = \frac{1}{a-b}\cdot \frac{1}{z} \cdot \sum_{n=0}^{\infty} \left( \frac{a}{z}\right)^{n} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}}$. If $|z|<|b|$, then $\left\vert \frac{z}{b}\right\vert < 1$, so we write $\displaystyle \frac{-1}{(a-b)}\cdot \frac{1}{(z-b)} = \frac{-1}{(a-b)}\cdot \frac{1}{b\left( \frac{z}{b} - 1 \right)} = \frac{1}{b(a-b)}\frac{1}{1-\frac{z}{b}} = \frac{1}{b(a-b)}\sum_{n=0}^{\infty}\left( \frac{z}{b}\right)^{n} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{z^{n}}{b^{n+1}}$ So, the whole expansion is $\displaystyle \frac{1}{z-b} \left( \sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}} + \sum_{n=0}^{\infty}\frac{z^{n}}{b^{n+1}}\right)\\ \displaystyle  = \frac{1}{a-b} \left( \frac{1}{z} + \frac{a}{z^{2}} + \frac{a^{2}}{z^{3}} + \cdots + \frac{1}{b} + \frac{z}{b^{2}}+\frac{z^{2}}{b^{3}}+\cdots\right) \\ \displaystyle =  \frac{1}{z(a-b)} + \frac{a}{z^{2}(a-b)} + \frac{a^{2}}{z^{3}(a-b)} + \cdots + \frac{1}{b(a-b)} + \frac{z}{b^{2}(a-b)}+\frac{z^{2}}{b^{3}(a-b)}+\cdots$ (c) $\mathbf{|b|<|z|}$.  If $|a|<|z|$, we have, as in part (b) $\displaystyle \frac{1}{(a-b)}\frac{1}{(z-a)} = \frac{1}{(a-b)}\sum_{n=0}^{\infty}\frac{a^{n}}{z^{n+1}}$. If $|b|<|z|$, $\displaystyle \frac{1}{(a-b)}\frac{1}{(z-b)} = \frac{1}{(a-b)} \frac{1}{z \left( 1 - \frac{b}{z}\right)}   \\ \displaystyle = \frac{1}{(a-b)}\frac{1}{z} \sum_{n=0}^{\infty} \left( \frac{b}{z}\right)^{n} \\ \displaystyle = \frac{1}{(a-b)}\frac{1}{z}\left( 1 + \frac{b}{z} + \frac{b^{2}}{z^{2}} + \cdots \right) \\ \displaystyle = \frac{1}{(a-b)} \left( \frac{1}{z} + \frac{b}{z^{2}} + \frac{b^{2}}{z^{3}}+ \cdots\right)$ Then, the required Laurent expansion valid for both $|z|>|a|$ and $|z|>|b|$ is found by subtraction: $ \displaystyle  \frac{1}{(a-b)} \left( \frac{1}{z} - \frac{1}{z} + \frac{a}{z^{2}} - \frac{b}{z^{2}} + \frac{a^{2}}{z^{3}} - \frac{b^{2}}{z^{3}} + \cdots \right) \\ \displaystyle = \frac{1}{(a-b)} \left( \frac{a-b}{z^{2}} + \frac{a^{2}-b^{2}}{z^{3}} + \frac{a^{3}-b^{3}}{z^{4}} + \cdots \right) \\ \displaystyle = \left( \frac{1}{z^{2}} + \frac{a^{2}-b^{2}}{z^{3}(a-b)} + \frac{a^{3}-b^{3}}{z^{4}(a-b)} + \cdots \right)$ Again, please let me know how to do part (a), as well as if my parts (b) and (c) are ok. Thanks.",,['complex-analysis']
65,Finding the power series of a complex function,Finding the power series of a complex function,,"So I have the function $$\frac{z^2}{(z+i)(z-i)^2}.$$ I want to determine the power series around $z=0$ of this function. I know that the power series is $\sum_{n=0}^\infty a_n(z-a)^n$, where $a_n=\frac{f^{(n)}(a)}{n!}$. But this gives me coefficients, how can I find a series for this? Edit: maybe we can use partial fractions?","So I have the function $$\frac{z^2}{(z+i)(z-i)^2}.$$ I want to determine the power series around $z=0$ of this function. I know that the power series is $\sum_{n=0}^\infty a_n(z-a)^n$, where $a_n=\frac{f^{(n)}(a)}{n!}$. But this gives me coefficients, how can I find a series for this? Edit: maybe we can use partial fractions?",,"['complex-analysis', 'power-series']"
66,Prove that the limit of the line integral is 0.,Prove that the limit of the line integral is 0.,,"Prove that $$\lim_{\rho\to0}\int_{C_\rho} \frac{z^{1/3}\log z}{z^2+1}dz=0$$ $(|z|>0, -\pi/2<\arg z<3\pi/2)$ where $C_\rho$ is the upper half of the circle with radius $\rho<1$ centered at the origin oriented clockwise. My attempt: Along $C_\rho$, $|z^2+1|\ge||z^2|-|1||=|\rho^2-1|=1-\rho^2$ $\displaystyle\left|\frac{z^{1/3}\log z}{z^2+1}\right|=\frac{\rho^{1/3}|\log z|}{|z^2+1|}\le \frac{\rho^{1/3}|\log z|}{1-\rho^2}$ I need to find an upper bound $M$ for the above expression in terms of $\rho$, so that I can use $\displaystyle\left|\int_{C_\rho} \frac{z^{1/3}\log z}{z^2+1}dz\right|\le M\pi\rho$ and then prove that $$\lim_{\rho\to0}M\pi\rho=0$$","Prove that $$\lim_{\rho\to0}\int_{C_\rho} \frac{z^{1/3}\log z}{z^2+1}dz=0$$ $(|z|>0, -\pi/2<\arg z<3\pi/2)$ where $C_\rho$ is the upper half of the circle with radius $\rho<1$ centered at the origin oriented clockwise. My attempt: Along $C_\rho$, $|z^2+1|\ge||z^2|-|1||=|\rho^2-1|=1-\rho^2$ $\displaystyle\left|\frac{z^{1/3}\log z}{z^2+1}\right|=\frac{\rho^{1/3}|\log z|}{|z^2+1|}\le \frac{\rho^{1/3}|\log z|}{1-\rho^2}$ I need to find an upper bound $M$ for the above expression in terms of $\rho$, so that I can use $\displaystyle\left|\int_{C_\rho} \frac{z^{1/3}\log z}{z^2+1}dz\right|\le M\pi\rho$ and then prove that $$\lim_{\rho\to0}M\pi\rho=0$$",,['complex-analysis']
67,Exercise 16 from chapter 3 of Stein & Shakarchi's complex analysis,Exercise 16 from chapter 3 of Stein & Shakarchi's complex analysis,,"Suppose $f$ and $g$ are holomorphic in a region containing the disc $|z| \le 1$. Suppose that $f$ has a simple zero at $z=0$ and vanishes nowhere else in $|z| \le 1$. Let $f_\epsilon (z) = f(z)+\epsilon g(z)$. Show that if $\epsilon$ is sufficiently small, then (a) $f_\epsilon (z)$ has a unique zero in $|z| \le 1$, and (b) if $z_\epsilon$ is this zero, the mapping $\epsilon \mapsto z_\epsilon$ is continuous. I already solved (a) by applying Rouche's theorem, but (b) is such a nuisance to me. I first tried the classical $\epsilon - \delta$ method, but it didn't work. However, I couldn't find any other ways to prove the continuity. Since $f$ has a simple zero at $z=0$, I found that $f(z)=zh(z)$ for some $h(z)$ that is holomorphic and non-zero in the unit disc and $z_\epsilon h(z_\epsilon) = -\epsilon g(z_\epsilon)$. Am I on the right track? I don't know how to proceed from this.","Suppose $f$ and $g$ are holomorphic in a region containing the disc $|z| \le 1$. Suppose that $f$ has a simple zero at $z=0$ and vanishes nowhere else in $|z| \le 1$. Let $f_\epsilon (z) = f(z)+\epsilon g(z)$. Show that if $\epsilon$ is sufficiently small, then (a) $f_\epsilon (z)$ has a unique zero in $|z| \le 1$, and (b) if $z_\epsilon$ is this zero, the mapping $\epsilon \mapsto z_\epsilon$ is continuous. I already solved (a) by applying Rouche's theorem, but (b) is such a nuisance to me. I first tried the classical $\epsilon - \delta$ method, but it didn't work. However, I couldn't find any other ways to prove the continuity. Since $f$ has a simple zero at $z=0$, I found that $f(z)=zh(z)$ for some $h(z)$ that is holomorphic and non-zero in the unit disc and $z_\epsilon h(z_\epsilon) = -\epsilon g(z_\epsilon)$. Am I on the right track? I don't know how to proceed from this.",,['complex-analysis']
68,Mobius Transformation and Schwarz's Lemma,Mobius Transformation and Schwarz's Lemma,,"My goal is to find a Mobius transformation $g$ that sends $K : |z| < R$ bijectively to itself, and also sends $0$ to $a \in R$. To my knowledge, there is a theorem that says the following: For a disc $K: |z| \leq 1$ and with $f:K \rightarrow K$ being analytic on $|z| <1$, $f$ is of the following form: $$f(z) = e^{i\alpha} \frac {z-a}{1-\overline a z}$$ My idea was that to accomplish what I need to, I have to generalize the proof of this theorem to a disc of radius $R$, rather than the unit disc. How would I be able to do this?","My goal is to find a Mobius transformation $g$ that sends $K : |z| < R$ bijectively to itself, and also sends $0$ to $a \in R$. To my knowledge, there is a theorem that says the following: For a disc $K: |z| \leq 1$ and with $f:K \rightarrow K$ being analytic on $|z| <1$, $f$ is of the following form: $$f(z) = e^{i\alpha} \frac {z-a}{1-\overline a z}$$ My idea was that to accomplish what I need to, I have to generalize the proof of this theorem to a disc of radius $R$, rather than the unit disc. How would I be able to do this?",,"['complex-analysis', 'mobius-transformation']"
69,"Show that if $a>e$, the equation $az^n=e^z$ admit $n$ roots in the unit disk - Rouché theorem","Show that if , the equation  admit  roots in the unit disk - Rouché theorem",a>e az^n=e^z n,"Rouché theorem : Let $D \subset \mathbb{C}$ a domain and $f,g: D \to \mathbb{C}$ two holomorphic functions in $D$ . Let $C$ a closed path contained in the interior of $D$ . If $|f(z)+g(z)| < |f(z)|+|g(z)|$ , $\forall z \in \mathbb{C}$ , then $f$ and $g$ have the same number of zeroes in the interior of $C$ . Question : Show that if $a>e$ , the equation $az^n=e^z$ admit $n$ roots in the unit disk. So I've taken $f(z)=-az^n+e^z$ and $g(z)= az^n$ in using the closed path $C : |z|=1$ . I obtained $|-az^n+e^z+az^n|= |e^z| \leq |-az^n+e^z|+|az^n|$ , $\forall z \in C$ . How could I prove that $|e^z| \not= |-az^n+e^z|+|az^n|$ ?","Rouché theorem : Let a domain and two holomorphic functions in . Let a closed path contained in the interior of . If , , then and have the same number of zeroes in the interior of . Question : Show that if , the equation admit roots in the unit disk. So I've taken and in using the closed path . I obtained , . How could I prove that ?","D \subset \mathbb{C} f,g: D \to \mathbb{C} D C D |f(z)+g(z)| < |f(z)|+|g(z)| \forall z \in \mathbb{C} f g C a>e az^n=e^z n f(z)=-az^n+e^z g(z)= az^n C : |z|=1 |-az^n+e^z+az^n|= |e^z| \leq |-az^n+e^z|+|az^n| \forall z \in C |e^z| \not= |-az^n+e^z|+|az^n|","['complex-analysis', 'roots']"
70,Approximating polynomials over $\mathbb{C}$ with an entire function,Approximating polynomials over  with an entire function,\mathbb{C},"Given a series of polynomials $p_{n}$ and a series of non-intersecting balls $B_{n} \subset \mathbb{C}$ show that there exists some function $f \in \mathcal{O}(\mathbb{C})$ such that $lim_{n \rightarrow \infty} sup_{z \in B_{n}} |f(z)-p_{n}(z)|=0$. Normally approximation is the other way around, so I'm having a little trouble with this.","Given a series of polynomials $p_{n}$ and a series of non-intersecting balls $B_{n} \subset \mathbb{C}$ show that there exists some function $f \in \mathcal{O}(\mathbb{C})$ such that $lim_{n \rightarrow \infty} sup_{z \in B_{n}} |f(z)-p_{n}(z)|=0$. Normally approximation is the other way around, so I'm having a little trouble with this.",,"['complex-analysis', 'analyticity', 'approximation-theory']"
71,Necessary condition for a polynomial of several complex variables to vanish at a point,Necessary condition for a polynomial of several complex variables to vanish at a point,,"For a $1$ -variable polynomial $f(x)\in\Bbb C[x]$ it is well-known that $$f(a)=0\iff f(x)=(x-a)g(x)$$ for some polynomial $g(x)\in\Bbb C[x]$ . Question: Does that principle carries over to multivariable polynomials? That is if $f(x_1,\ldots,x_n)\in\Bbb C[x_1,\ldots,x_n]$ and $f(a_1,\ldots,a_n)=0$ for some $(a_1,\ldots,a_n)\in\Bbb C$ , does it follow that $$f(x_1,\ldots,x_n)=(x_1-a_1)\cdots(x_n-a_n)g(x_1,\ldots,x_n),$$ for some $g\in\Bbb C[x_1,\ldots,x_n]$ ? Attempt: We can fix $x_2,\ldots,x_n$ and consider $f(x_1,\ldots,x_n)$ as a $1$ -variable polynomial in $x_1$ that vanishes at $a_1$ and hence $f(x_1,\ldots,x_n)=(x_1-a_1)g(x_1)$ , but I am not sure why $g(x_1)$ would be a polynomial in $x_2,\ldots,x_n$ .","For a -variable polynomial it is well-known that for some polynomial . Question: Does that principle carries over to multivariable polynomials? That is if and for some , does it follow that for some ? Attempt: We can fix and consider as a -variable polynomial in that vanishes at and hence , but I am not sure why would be a polynomial in .","1 f(x)\in\Bbb C[x] f(a)=0\iff f(x)=(x-a)g(x) g(x)\in\Bbb C[x] f(x_1,\ldots,x_n)\in\Bbb C[x_1,\ldots,x_n] f(a_1,\ldots,a_n)=0 (a_1,\ldots,a_n)\in\Bbb C f(x_1,\ldots,x_n)=(x_1-a_1)\cdots(x_n-a_n)g(x_1,\ldots,x_n), g\in\Bbb C[x_1,\ldots,x_n] x_2,\ldots,x_n f(x_1,\ldots,x_n) 1 x_1 a_1 f(x_1,\ldots,x_n)=(x_1-a_1)g(x_1) g(x_1) x_2,\ldots,x_n","['complex-analysis', 'several-complex-variables']"
72,Uniform convergence in the proof of the Cauchy integral formula in Stein-Shakarchi,Uniform convergence in the proof of the Cauchy integral formula in Stein-Shakarchi,,"The following is the proof of the Cauchy integral formula for derivatives of holomorphic functions in the Complex Analysis by Stein-Shakarchi: Would anybody show me why one has uniform convergence in the integrand as $h\to 0$ (so that one can pass the limit inside the integral)? [Updated:] As a particular case, consider $n=1$. Let  $$ F(\zeta,h;z)=\frac{f(\zeta)}{(\zeta-z-h)(\zeta-z)}. $$ What I want to show is $$ \lim_{h\to 0}\int_CF(\zeta,h;z) d\zeta=\int_CF(\zeta,0;z)\ d\zeta. $$ So I need a uniform bound for $$ |F(\zeta,h;z)-F(\zeta,0;z)|, $$ which is the part I get stuck.","The following is the proof of the Cauchy integral formula for derivatives of holomorphic functions in the Complex Analysis by Stein-Shakarchi: Would anybody show me why one has uniform convergence in the integrand as $h\to 0$ (so that one can pass the limit inside the integral)? [Updated:] As a particular case, consider $n=1$. Let  $$ F(\zeta,h;z)=\frac{f(\zeta)}{(\zeta-z-h)(\zeta-z)}. $$ What I want to show is $$ \lim_{h\to 0}\int_CF(\zeta,h;z) d\zeta=\int_CF(\zeta,0;z)\ d\zeta. $$ So I need a uniform bound for $$ |F(\zeta,h;z)-F(\zeta,0;z)|, $$ which is the part I get stuck.",,['complex-analysis']
73,Trigonometric Expression for $1 + \cos \alpha + \cos 2\alpha + \cdots + \cos n \alpha$ using complex numbers,Trigonometric Expression for  using complex numbers,1 + \cos \alpha + \cos 2\alpha + \cdots + \cos n \alpha,"This question is not a duplicate because I am asked here to use the fact that  $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re (1 + z + z^{2} + \cdots + z^{n})$, where the question this is suspected of being a duplicate of does not use this I am supposed to use the fact that $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re (1 + z + z^{2} + \cdots + z^{n})$, where $z = \cos \alpha + i \sin \alpha$, ro find a trigonometric expression for $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha$. Now, when $z \neq 1$, we have the geometric sum $\displaystyle 1 + z + z^{2} + \cdots + z^{n} = \frac{1-z^{n+1}}{1-z}$. (When $z = 1$, $1 + z + z^{2} + \cdots + z^{n} = n + 1$, so $Re(1 + z + z^{2} + \cdots + z^{n}) = Re(n+1) = n+1$, finished.) So, in the case where $z \neq 1$, $\displaystyle 1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re(1 + z + z^{2} + \cdots + z^{n}) = Re\left(\frac{1-z^{n+1}}{1-z} \right) = Re \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{1-(\cos \alpha + i \sin \alpha)} \right) = Re \left[ \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{(1-\cos \alpha) - i \sin \alpha} \right)\cdot \frac{(1-\cos \alpha) + i \sin \alpha}{(1 - \cos \alpha)+ i \sin \alpha}\right] = Re \left( \frac{(1-\cos \alpha)+i\sin \alpha - ( 1- \cos \alpha)(\cos \alpha + i \sin \alpha)^{n+1}-i \sin \alpha (\cos \alpha + i \sin \alpha)^{n+1}}{(1-\cos \alpha)^{2} + \sin^{2} \alpha}\right)$. Then, to make a long story short, after an application of De Moivre's Theorem to turn the $(\cos \alpha + i \sin \alpha)^{n+1}$'s into $(\cos(n \alpha + \alpha)+ i \sin (n \alpha + \alpha))$'s, usage of the sine and cosine of sum identities, collecting of like terms and cancelling some things, we obtain $\displaystyle Re \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{1-(\cos \alpha + i \sin \alpha)} \right) = Re \left(\frac{(1-\cos \alpha + \cos (n\alpha)) + i(\sin \alpha - \cos (n\alpha)\sin \alpha + \sin (n \alpha))}{2-2\cos \alpha} \right) = \frac{1-\cos \alpha + \cos (n \alpha)}{2-2\cos \alpha}$. At least I think it does. Which brings me to my question: is this correct? If not, where did I go wrong and how do I fix it?","This question is not a duplicate because I am asked here to use the fact that  $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re (1 + z + z^{2} + \cdots + z^{n})$, where the question this is suspected of being a duplicate of does not use this I am supposed to use the fact that $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re (1 + z + z^{2} + \cdots + z^{n})$, where $z = \cos \alpha + i \sin \alpha$, ro find a trigonometric expression for $1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha$. Now, when $z \neq 1$, we have the geometric sum $\displaystyle 1 + z + z^{2} + \cdots + z^{n} = \frac{1-z^{n+1}}{1-z}$. (When $z = 1$, $1 + z + z^{2} + \cdots + z^{n} = n + 1$, so $Re(1 + z + z^{2} + \cdots + z^{n}) = Re(n+1) = n+1$, finished.) So, in the case where $z \neq 1$, $\displaystyle 1 + \cos \alpha + \cos 2 \alpha + \cdots + \cos n \alpha = Re(1 + z + z^{2} + \cdots + z^{n}) = Re\left(\frac{1-z^{n+1}}{1-z} \right) = Re \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{1-(\cos \alpha + i \sin \alpha)} \right) = Re \left[ \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{(1-\cos \alpha) - i \sin \alpha} \right)\cdot \frac{(1-\cos \alpha) + i \sin \alpha}{(1 - \cos \alpha)+ i \sin \alpha}\right] = Re \left( \frac{(1-\cos \alpha)+i\sin \alpha - ( 1- \cos \alpha)(\cos \alpha + i \sin \alpha)^{n+1}-i \sin \alpha (\cos \alpha + i \sin \alpha)^{n+1}}{(1-\cos \alpha)^{2} + \sin^{2} \alpha}\right)$. Then, to make a long story short, after an application of De Moivre's Theorem to turn the $(\cos \alpha + i \sin \alpha)^{n+1}$'s into $(\cos(n \alpha + \alpha)+ i \sin (n \alpha + \alpha))$'s, usage of the sine and cosine of sum identities, collecting of like terms and cancelling some things, we obtain $\displaystyle Re \left(\frac{1-(\cos \alpha + i \sin \alpha)^{n+1}}{1-(\cos \alpha + i \sin \alpha)} \right) = Re \left(\frac{(1-\cos \alpha + \cos (n\alpha)) + i(\sin \alpha - \cos (n\alpha)\sin \alpha + \sin (n \alpha))}{2-2\cos \alpha} \right) = \frac{1-\cos \alpha + \cos (n \alpha)}{2-2\cos \alpha}$. At least I think it does. Which brings me to my question: is this correct? If not, where did I go wrong and how do I fix it?",,['complex-analysis']
74,Show $g(0)=\sup\{ Re(f(0)) : f\in\mathfrak{F}\}$,Show,g(0)=\sup\{ Re(f(0)) : f\in\mathfrak{F}\},"Define a family of functions by  $$\mathfrak{F}:=\left\{ f\in Hol(\mathbb{D}) \ : \ \sum_{n=0}^\infty \left( \frac{|f^{(n)}(0)|}{n!}\right)^2\leq 1 \textrm{ and } f\left(\frac{1}{2}\right)=0\right\}$$. I am trying to show that there exists a $g\in\mathfrak{F}$ s.t.  $$g(0) = \sup\{Re(f(0)) : f\in\mathfrak F\}.$$ Now since f is holomorphic on the disc we know it has a power expansion and that $$a_n = \frac{f^{(n)}(0)}{n!},$$ which means that we know  $$\sum_{n=0}^\infty |a_n|^2\leq 1$$ and so $a_n\in\mathbb{D}$ for $n=0,1,2,\dots.$ The part I am having a issue with is using the assumption that $f\left(\frac{1}{2}\right)=0.$ I've worked similar problems where we had that the functions mapped to the disc, which meant using some conformal maps we could use Schwarz's Lemma. I want to do the same thing here, but I can't see how the $\sum |a_n|^2\leq 1$ means $f:\mathbb{D}\rightarrow\mathbb{D}.$ I appreciate any guidance or hints you can provide. Thanks.","Define a family of functions by  $$\mathfrak{F}:=\left\{ f\in Hol(\mathbb{D}) \ : \ \sum_{n=0}^\infty \left( \frac{|f^{(n)}(0)|}{n!}\right)^2\leq 1 \textrm{ and } f\left(\frac{1}{2}\right)=0\right\}$$. I am trying to show that there exists a $g\in\mathfrak{F}$ s.t.  $$g(0) = \sup\{Re(f(0)) : f\in\mathfrak F\}.$$ Now since f is holomorphic on the disc we know it has a power expansion and that $$a_n = \frac{f^{(n)}(0)}{n!},$$ which means that we know  $$\sum_{n=0}^\infty |a_n|^2\leq 1$$ and so $a_n\in\mathbb{D}$ for $n=0,1,2,\dots.$ The part I am having a issue with is using the assumption that $f\left(\frac{1}{2}\right)=0.$ I've worked similar problems where we had that the functions mapped to the disc, which meant using some conformal maps we could use Schwarz's Lemma. I want to do the same thing here, but I can't see how the $\sum |a_n|^2\leq 1$ means $f:\mathbb{D}\rightarrow\mathbb{D}.$ I appreciate any guidance or hints you can provide. Thanks.",,['complex-analysis']
75,"If $f\in\mathcal{H}(\mathbb{C})$ not constant, then $f(\mathbb{C})$ is dense in $\mathbb{C}$.","If  not constant, then  is dense in .",f\in\mathcal{H}(\mathbb{C}) f(\mathbb{C}) \mathbb{C},"By reductio ad absurdum suppose that $f(\mathbb{C})$ is not dense in $\mathbb{C}$, then there exists $w_0\in\mathbb{C}$ and $\varepsilon_0>0$ such that $|f(\zeta)-w_0|\geq \varepsilon_0$ for all $\zeta\in\mathbb{C}$; this implies: $$|\frac{1}{f-w_0}|\leq \frac{1}{\varepsilon_0} \text{ for all } \zeta\in \mathbb{C}$$ As $f\in\mathcal{H}(\mathbb{C})$ we have that: $$\frac{1}{f-w_0}\in\mathcal{H}(\mathbb{C})$$ So by Liouville's theorem $f$ is constant.","By reductio ad absurdum suppose that $f(\mathbb{C})$ is not dense in $\mathbb{C}$, then there exists $w_0\in\mathbb{C}$ and $\varepsilon_0>0$ such that $|f(\zeta)-w_0|\geq \varepsilon_0$ for all $\zeta\in\mathbb{C}$; this implies: $$|\frac{1}{f-w_0}|\leq \frac{1}{\varepsilon_0} \text{ for all } \zeta\in \mathbb{C}$$ As $f\in\mathcal{H}(\mathbb{C})$ we have that: $$\frac{1}{f-w_0}\in\mathcal{H}(\mathbb{C})$$ So by Liouville's theorem $f$ is constant.",,"['complex-analysis', 'proof-verification']"
76,Singularity of $\sum_{n=0}^\infty \frac{1}{z^{n}n!} $,Singularity of,\sum_{n=0}^\infty \frac{1}{z^{n}n!} ,What kind of singularity does this function have: $$\sum_{n=0}^\infty \frac{1}{z^{n}n!}.$$ It can have pole but its answer is still zero after multiplication by $z^n$ at $n=0$. Therefore the second choice is that it has an essential singularity. Is that correct?,What kind of singularity does this function have: $$\sum_{n=0}^\infty \frac{1}{z^{n}n!}.$$ It can have pole but its answer is still zero after multiplication by $z^n$ at $n=0$. Therefore the second choice is that it has an essential singularity. Is that correct?,,['complex-analysis']
77,Estimation of the n-th derivative of a complex function using Cauchy integral formula.,Estimation of the n-th derivative of a complex function using Cauchy integral formula.,,"I encountered this problem from ""Classical complex analysis"" by L.S. Hahn and B. Epstein, p.133. ""Let $f(z)$ be analytic in the unit disc $D$ and suppose that $$\left|f(z)\right| \leq \dfrac{1}{1-|z|}$$ for all $z \in D$. Show that $$\left|f^{(n)}(0)\right| \leq (n+1)!e.$$ The hint is to use the Cauchy integral formula with a path of integration suitably chosen for each $n$."" My attempt is: By the hypothesis, we have $|f(0)| \leq 1$ . Now let $r \in (0;1)$ and consider the circle $C(0,r)$. By the Cauchy integral formula and taking modulus of both sides, we have $$|f^{(n)}(0)| = \left|\dfrac{n!}{2\pi i} \oint_{C(0,r)} \dfrac{f(z)}{z^{n+1}}\,dz \right| \leq \dfrac{n!}{2\pi } \oint_{C(0,r)} \left|\dfrac{f(z)}{z^{n+1}} \right|\,\left|dz\right|= \dfrac{n!}{(1-r)r^n}.$$ Now we have to choose $r$ (depend on $n$) so that $$\dfrac{1}{(1-r)r^n} \leq (n+1)e$$ and I got stuck at this step. I tried to remove the power $n$ of $r$ in the denumerator by using Bernoulli inequality, $$r^n = (1+(r-1))^n \geq 1+n(r-1)$$ and made the number $e$ appear by using the estimation $$1-r \geq e^{-2r}$$ but still couldn't work things out. Do you have any idea to find $r$ (depend on $n$)? Any help would be highly appreciated. Thanks in advance!","I encountered this problem from ""Classical complex analysis"" by L.S. Hahn and B. Epstein, p.133. ""Let $f(z)$ be analytic in the unit disc $D$ and suppose that $$\left|f(z)\right| \leq \dfrac{1}{1-|z|}$$ for all $z \in D$. Show that $$\left|f^{(n)}(0)\right| \leq (n+1)!e.$$ The hint is to use the Cauchy integral formula with a path of integration suitably chosen for each $n$."" My attempt is: By the hypothesis, we have $|f(0)| \leq 1$ . Now let $r \in (0;1)$ and consider the circle $C(0,r)$. By the Cauchy integral formula and taking modulus of both sides, we have $$|f^{(n)}(0)| = \left|\dfrac{n!}{2\pi i} \oint_{C(0,r)} \dfrac{f(z)}{z^{n+1}}\,dz \right| \leq \dfrac{n!}{2\pi } \oint_{C(0,r)} \left|\dfrac{f(z)}{z^{n+1}} \right|\,\left|dz\right|= \dfrac{n!}{(1-r)r^n}.$$ Now we have to choose $r$ (depend on $n$) so that $$\dfrac{1}{(1-r)r^n} \leq (n+1)e$$ and I got stuck at this step. I tried to remove the power $n$ of $r$ in the denumerator by using Bernoulli inequality, $$r^n = (1+(r-1))^n \geq 1+n(r-1)$$ and made the number $e$ appear by using the estimation $$1-r \geq e^{-2r}$$ but still couldn't work things out. Do you have any idea to find $r$ (depend on $n$)? Any help would be highly appreciated. Thanks in advance!",,"['complex-analysis', 'cauchy-integral-formula']"
78,Evaluate the integral $\int_0^\infty \frac {x^{1/2} dx}{x^2 + 1}$ using method of residues,Evaluate the integral  using method of residues,\int_0^\infty \frac {x^{1/2} dx}{x^2 + 1},"I am trying to evaluate the integral $\int_0^\infty \frac {x^{1/2} dx}{x^2 + 1}$ using method of residues. I can solve this very easily without the $x^{1/2}$ on top, but I do not know what to do when the function on top is not a polynomial where the powers are integers. How do you compute this?","I am trying to evaluate the integral $\int_0^\infty \frac {x^{1/2} dx}{x^2 + 1}$ using method of residues. I can solve this very easily without the $x^{1/2}$ on top, but I do not know what to do when the function on top is not a polynomial where the powers are integers. How do you compute this?",,"['integration', 'complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
79,residue theorem with logarithmic function,residue theorem with logarithmic function,,"I have problem integrating function with logarithm. Problems seems always to be branch cut of $\log$, but here it is different I think. I have task to integrate $$\oint_{|z| = 1} \! dz \log\left(\frac{z - a}{z - b}\right)$$ given $|a| < 1$ and $|b| < 1$ First I think to check branch points of logarithm. I write $$\log\left(\frac{z - a}{z - b}\right) = \log(z - a) - \log(z - b)$$ Going around $a$ in small circle I pick up term $2\pi i$, going around $b$ I pick up term $-2\pi i$, so going around both I pick up nothing. So I make branch cut $a$ to $b$ and contour does not intersect. But now I get stuck! I try to find residue of integral at $a$ and $b$ but I cannot get series of at $a,b$, because logarithm always remains inside. How I can evaluate such integrals?","I have problem integrating function with logarithm. Problems seems always to be branch cut of $\log$, but here it is different I think. I have task to integrate $$\oint_{|z| = 1} \! dz \log\left(\frac{z - a}{z - b}\right)$$ given $|a| < 1$ and $|b| < 1$ First I think to check branch points of logarithm. I write $$\log\left(\frac{z - a}{z - b}\right) = \log(z - a) - \log(z - b)$$ Going around $a$ in small circle I pick up term $2\pi i$, going around $b$ I pick up term $-2\pi i$, so going around both I pick up nothing. So I make branch cut $a$ to $b$ and contour does not intersect. But now I get stuck! I try to find residue of integral at $a$ and $b$ but I cannot get series of at $a,b$, because logarithm always remains inside. How I can evaluate such integrals?",,"['complex-analysis', 'logarithms', 'residue-calculus', 'branch-cuts']"
80,"Gluing together Riemann surfaces, don't see why $Z$ is union of two compact sets.","Gluing together Riemann surfaces, don't see why  is union of two compact sets.",Z,"Consider Lemma 1.7 from page 60-61 of Miranda's Algebraic Curves and Riemann Surfaces . For a link to the book, see here . Lemma 1.7. With the above construction, $Z$ is a compact surface of genus $g$ . The meromorphic function $x$ on $X$ extends to a holomorphic map $\pi: Z \to \mathbb{C}_\infty$ , which has degree $2$ . The branch points of $\pi$ are the roots of $h$ (and the point $\infty$ if $h$ as odd degree). Proof. One checks readily that $Z$ is Hausdorff, and hence is a Riemann surface. $Z$ is compact, since it is the union of two compact sets $$\{(x, y) \in X : \|x\| \le 1\} \text{ and }\{(z, w) \in Y : \|z\| \le 1\}.$$ To me, I don't see why $Z$ is the union of the above two compact sets. Can anyone clarify? Thanks.","Consider Lemma 1.7 from page 60-61 of Miranda's Algebraic Curves and Riemann Surfaces . For a link to the book, see here . Lemma 1.7. With the above construction, is a compact surface of genus . The meromorphic function on extends to a holomorphic map , which has degree . The branch points of are the roots of (and the point if as odd degree). Proof. One checks readily that is Hausdorff, and hence is a Riemann surface. is compact, since it is the union of two compact sets To me, I don't see why is the union of the above two compact sets. Can anyone clarify? Thanks.","Z g x X \pi: Z \to \mathbb{C}_\infty 2 \pi h \infty h Z Z \{(x, y) \in X : \|x\| \le 1\} \text{ and }\{(z, w) \in Y : \|z\| \le 1\}. Z","['complex-analysis', 'algebraic-geometry']"
81,Double integral involving beta functions,Double integral involving beta functions,,"I want to prove the following result: $$\int_0^1 \int_0^1 {f(xy)(1-x)^{p-1}y^p(1-y)^{q-1}} \mathrm{d}x \, \mathrm{d}y=\frac{\Gamma(p) \Gamma(q)}{\Gamma(p+q)} \int_0^1 {f(t)(1-t)^{p+q-1}} \mathrm{d}t.$$ I have tried using the substitution $t=xy$, but am not sure what to use for the other variable. We were given no information about the function $f$. Any help would be appreciated!","I want to prove the following result: $$\int_0^1 \int_0^1 {f(xy)(1-x)^{p-1}y^p(1-y)^{q-1}} \mathrm{d}x \, \mathrm{d}y=\frac{\Gamma(p) \Gamma(q)}{\Gamma(p+q)} \int_0^1 {f(t)(1-t)^{p+q-1}} \mathrm{d}t.$$ I have tried using the substitution $t=xy$, but am not sure what to use for the other variable. We were given no information about the function $f$. Any help would be appreciated!",,"['integration', 'complex-analysis', 'definite-integrals', 'gamma-function', 'beta-function']"
82,Exact value of Gauss Sum,Exact value of Gauss Sum,,"When I was studying quadratic reciprocity, my number theory professor used the following result without proof: $$S(n)=\sum^{n-1}_{x=0}\exp\left(\frac{2\pi ix^2}{n}\right)=\begin{cases} \sqrt{n}+\sqrt{n}i &&\text{if }n\equiv0 \mod 4\\ \sqrt n && \text{if } n\equiv1 \mod4\\ 0 && \text{if } n\equiv2 \mod 4\\ i\sqrt n&&\text{if } n\equiv3 \mod 4 \end{cases} $$ Here $n$ is a positive integer. My professor said it can be done by complex analysis, so I try to prove it. I have read Stein's Complex Analysis so I know about the theory of sum of 2 squares, that $$r_2(n)=4(d_1(n)+d_2(n))$$ I try to compute $S(n)^2$ and there will be an $x^2+y^2$ in the exponential. However, I found a great difficulty on counting. I also try using theta function (essentially Poisson Summation Formula), but the $S(n)$ is a finite sum rather than an infinite sum. So I cannot get rid of the remaining parts. Can someone please prove the formula using complex analysis?","When I was studying quadratic reciprocity, my number theory professor used the following result without proof: Here is a positive integer. My professor said it can be done by complex analysis, so I try to prove it. I have read Stein's Complex Analysis so I know about the theory of sum of 2 squares, that I try to compute and there will be an in the exponential. However, I found a great difficulty on counting. I also try using theta function (essentially Poisson Summation Formula), but the is a finite sum rather than an infinite sum. So I cannot get rid of the remaining parts. Can someone please prove the formula using complex analysis?","S(n)=\sum^{n-1}_{x=0}\exp\left(\frac{2\pi ix^2}{n}\right)=\begin{cases}
\sqrt{n}+\sqrt{n}i &&\text{if }n\equiv0 \mod 4\\
\sqrt n && \text{if } n\equiv1 \mod4\\
0 && \text{if } n\equiv2 \mod 4\\
i\sqrt n&&\text{if } n\equiv3 \mod 4
\end{cases}  n r_2(n)=4(d_1(n)+d_2(n)) S(n)^2 x^2+y^2 S(n)",['complex-analysis']
83,Example of Saddle-Point method,Example of Saddle-Point method,,"I am trying to solve using the saddle point method (large a>0): $$I(\alpha)= \int_{-i\pi/2}^{\pi/2}dz\, (1+z^2)e^{-a\cos(z)}$$ So I find that the point I want to expand about is z=0, because $\partial_z\cos(z)=0\implies z=0,n\pi$  So at $z_0=0$, I get $$I(\alpha)=1\int_{-\epsilon}^\epsilon e^{-a(1-z^2/2+...)}\approx e^{-a}\int_{-\infty}^\infty e^{az^2/2}\, dz\approx i\frac{\sqrt{2\pi}}{\sqrt{a}}e^{-a}$$ My question is if this is a valid approach.  Mostly, did I correctly choose to expand about z=0.  I get confused on which saddle point to select, because I can deform the integral in many ways. And then if I want $a<0$, would I approach it the same way?","I am trying to solve using the saddle point method (large a>0): $$I(\alpha)= \int_{-i\pi/2}^{\pi/2}dz\, (1+z^2)e^{-a\cos(z)}$$ So I find that the point I want to expand about is z=0, because $\partial_z\cos(z)=0\implies z=0,n\pi$  So at $z_0=0$, I get $$I(\alpha)=1\int_{-\epsilon}^\epsilon e^{-a(1-z^2/2+...)}\approx e^{-a}\int_{-\infty}^\infty e^{az^2/2}\, dz\approx i\frac{\sqrt{2\pi}}{\sqrt{a}}e^{-a}$$ My question is if this is a valid approach.  Mostly, did I correctly choose to expand about z=0.  I get confused on which saddle point to select, because I can deform the integral in many ways. And then if I want $a<0$, would I approach it the same way?",,"['complex-analysis', 'asymptotics']"
84,If $|z_1|=|z_2|=|z_3|$ and $\arg z_1\leq \arg z_2 \leq \arg z_3$ prove that $\arg{\frac{z_3-z_2}{z_3-z_1}}=\frac{1}{2}\arg \frac{z_2}{z_1}$,If  and  prove that,|z_1|=|z_2|=|z_3| \arg z_1\leq \arg z_2 \leq \arg z_3 \arg{\frac{z_3-z_2}{z_3-z_1}}=\frac{1}{2}\arg \frac{z_2}{z_1},"If $z_1,z_2,z_2 \in \mathbb{C}$ and $|z_1|=|z_2|=|z_3|$ and $\arg z_1\leq \arg z_2 \leq \arg z_3$ prove that $$\arg{\frac{z_3-z_2}{z_3-z_1}}=\frac{1}{2}\arg \frac{z_2}{z_1}$$ Answer: $\ \arg z_1= \varphi_1,\ \arg z_2= \ \varphi_2, \ \arg z_3=\varphi_3\ldots$ The answer comes to the point where: $$\arg\frac{z_3-z_2}{z_3-z_1}=\arg\left(e^{i \frac{\varphi_1-\varphi_2}{2}}\frac{\sin{\frac{\varphi_3-\varphi_2}{2}}}{\sin{\frac{\varphi_3-\varphi_1}{2}}}\right)= \text{ (this part is not clear)}\\$$ $$ = \arg e^{i \frac{\varphi_1-\varphi_2}{2}}+\arg  \frac{\sin{\frac{\varphi_3-\varphi_2}{2}}}{\sin\frac{\varphi_3-\varphi_1}{2}}=\arg  e^{i \frac{\varphi_1-\varphi_2}{2}}$$ $$=\frac{1}{2}\arg \frac{z_2}{z_1}$$",If and and prove that Answer: The answer comes to the point where:,"z_1,z_2,z_2 \in \mathbb{C} |z_1|=|z_2|=|z_3| \arg z_1\leq \arg z_2 \leq \arg z_3 \arg{\frac{z_3-z_2}{z_3-z_1}}=\frac{1}{2}\arg \frac{z_2}{z_1} \ \arg z_1= \varphi_1,\ \arg z_2= \ \varphi_2, \ \arg z_3=\varphi_3\ldots \arg\frac{z_3-z_2}{z_3-z_1}=\arg\left(e^{i \frac{\varphi_1-\varphi_2}{2}}\frac{\sin{\frac{\varphi_3-\varphi_2}{2}}}{\sin{\frac{\varphi_3-\varphi_1}{2}}}\right)= \text{ (this part is not clear)}\\  = \arg e^{i \frac{\varphi_1-\varphi_2}{2}}+\arg
 \frac{\sin{\frac{\varphi_3-\varphi_2}{2}}}{\sin\frac{\varphi_3-\varphi_1}{2}}=\arg
 e^{i \frac{\varphi_1-\varphi_2}{2}} =\frac{1}{2}\arg \frac{z_2}{z_1}","['complex-analysis', 'analysis', 'inequality']"
85,Find a branch of $\log{(z^2+1)}$,Find a branch of,\log{(z^2+1)},"I have this problem right here: Find a branch of $\log{(z^2+1)}$ that is analytic as $z=0$ and takes the value $2\pi i$ there. If I just plug in  $z=0$ and use the principal branch I would just get $0$, $\log{1}$ is $0$ and the argument is $0$? So what do i do? Can i just cut the plane at the negative real axis and define the branch as $\pi \leq \arg{z} < {3\pi}$ ? If so how do i state that mathematically?","I have this problem right here: Find a branch of $\log{(z^2+1)}$ that is analytic as $z=0$ and takes the value $2\pi i$ there. If I just plug in  $z=0$ and use the principal branch I would just get $0$, $\log{1}$ is $0$ and the argument is $0$? So what do i do? Can i just cut the plane at the negative real axis and define the branch as $\pi \leq \arg{z} < {3\pi}$ ? If so how do i state that mathematically?",,[]
86,Image of the Riemann-sphere,Image of the Riemann-sphere,,"Let $S$ be the Riemann-sphere (the unit sphere in $\mathbb{R}^3$) and $\psi: S \rightarrow \mathbb{C}$ be defined by $$\psi(x_1, x_2, x_3)=\frac{x_1 + ix_2}{1-x_3}.$$ Let $\pi$ be a plane in $\mathbb{R}^3$ such that the intersection with $S$ is not empty. Show that $\psi(\pi \cap S)$ is a line or a circumference in $\mathbb{C}$. It's easy to see that if the plane has normal vector $(0,0,k)$, the image is a circumference. But i can't generalize the result.","Let $S$ be the Riemann-sphere (the unit sphere in $\mathbb{R}^3$) and $\psi: S \rightarrow \mathbb{C}$ be defined by $$\psi(x_1, x_2, x_3)=\frac{x_1 + ix_2}{1-x_3}.$$ Let $\pi$ be a plane in $\mathbb{R}^3$ such that the intersection with $S$ is not empty. Show that $\psi(\pi \cap S)$ is a line or a circumference in $\mathbb{C}$. It's easy to see that if the plane has normal vector $(0,0,k)$, the image is a circumference. But i can't generalize the result.",,"['complex-analysis', 'complex-geometry']"
87,Radius of convergence when multiplying two complex power series?,Radius of convergence when multiplying two complex power series?,,"If $f(z) = \sum_{n=0}^\infty a_n(z-z_0)^n$ and $g(z) = \sum_{n=0}^\infty b_n(z-z_0)^n$ are complex power series whose radii of convergence are $R_1$ and $R_2$ correspondently, then the complex power series of $f(z)g(z)$ has a radius of convergence of what? I believe I have seen before that for two complex power series, the radius of convergence for $f(z)g(z)$ is $R = min({R_1, R_2})$. I have also seen before where the radius of convergence of $f(z)g(z)$ is $R \ge min({R_1,R_2})$. I believe the latter one is correct, but I am unsure. I assume the latter one is correct because of a simple example like this: Let $f(z) = \frac{1-z}{1+z}$ and $g(z) = \frac{1+z}{1-z}$. Both have a radius of convergence of $|z| < 1$. Yet $f(z)g(z) = 1$ and its series expansion has a radius of convergence of $\infty$. So which one is correct? Is one of them correct only in the case of a series expansion in real variables while one is only correct for complex variables? For whichever one is correct, how would you prove the result? (First question asked, so sorry if anything is sloppy or formatted incorrectly)","If $f(z) = \sum_{n=0}^\infty a_n(z-z_0)^n$ and $g(z) = \sum_{n=0}^\infty b_n(z-z_0)^n$ are complex power series whose radii of convergence are $R_1$ and $R_2$ correspondently, then the complex power series of $f(z)g(z)$ has a radius of convergence of what? I believe I have seen before that for two complex power series, the radius of convergence for $f(z)g(z)$ is $R = min({R_1, R_2})$. I have also seen before where the radius of convergence of $f(z)g(z)$ is $R \ge min({R_1,R_2})$. I believe the latter one is correct, but I am unsure. I assume the latter one is correct because of a simple example like this: Let $f(z) = \frac{1-z}{1+z}$ and $g(z) = \frac{1+z}{1-z}$. Both have a radius of convergence of $|z| < 1$. Yet $f(z)g(z) = 1$ and its series expansion has a radius of convergence of $\infty$. So which one is correct? Is one of them correct only in the case of a series expansion in real variables while one is only correct for complex variables? For whichever one is correct, how would you prove the result? (First question asked, so sorry if anything is sloppy or formatted incorrectly)",,"['complex-analysis', 'power-series']"
88,Show that all partial derivatives of $f$ wrt $x$ exist at all points of $\mathbb{R^2}$,Show that all partial derivatives of  wrt  exist at all points of,f x \mathbb{R^2},"Let $\displaystyle f(x,y)=\frac{-2xy}{(x^2+y^2)^2}$ and $f(0)=0$. Show that all partial derivatives of $f$ wrt $x$ exist at all points of $\mathbb{R^2}$ My Try: Regarding $f_x$, it is clear that $f_x$ exists for all $(x,y)\neq 0$. I proved that $f_x$ exists at $(0,0)$ using the limit definition. But this problem asks to show the existence of all other $f_{xx},f_{xxx},...$. How do I show it? It is not possible to calculate all. Is there a general method to show it? Any help is appreciated.","Let $\displaystyle f(x,y)=\frac{-2xy}{(x^2+y^2)^2}$ and $f(0)=0$. Show that all partial derivatives of $f$ wrt $x$ exist at all points of $\mathbb{R^2}$ My Try: Regarding $f_x$, it is clear that $f_x$ exists for all $(x,y)\neq 0$. I proved that $f_x$ exists at $(0,0)$ using the limit definition. But this problem asks to show the existence of all other $f_{xx},f_{xxx},...$. How do I show it? It is not possible to calculate all. Is there a general method to show it? Any help is appreciated.",,"['real-analysis', 'complex-analysis', 'multivariable-calculus', 'partial-derivative']"
89,How to show that $|\exp(z)-1|\le2|z|$ for $|z|\le 1$,How to show that  for,|\exp(z)-1|\le2|z| |z|\le 1,"How to show that $|\exp(z)-1|\le2|z|$ for $|z|\le 1$ $\displaystyle|\exp(z)-1|=\big|\sum\limits_{k=1}^\infty\frac{z^k}{k!}\big|\le\sum\limits_{k=1}^\infty\frac{|z|^k}{k!}=|z|+\sum\limits_{k=2}^\infty\frac{|z|^k}{k!}$ now it remains to prove that the sum, the most right is $\le|z|$ Since $\sum\limits_{k=2}^\infty\frac{|z|^k}{k!}\le\sum\limits_{k=0}^\infty\left(\frac{|z|}{2}\right)^k-\frac{|z|}{2}-1+\frac{|z|^2}{4}$ (geometric series) the RHS is $\displaystyle \frac{1}{1-\frac{|z|}{2}}-\frac{|z|}{2}-1+\frac{|z|^2}{4}=\frac{\frac{|z|}{2}}{\frac{2}{|z|}-1}+\frac{|z|^2}{4}\le|z|$ am I right ?","How to show that $|\exp(z)-1|\le2|z|$ for $|z|\le 1$ $\displaystyle|\exp(z)-1|=\big|\sum\limits_{k=1}^\infty\frac{z^k}{k!}\big|\le\sum\limits_{k=1}^\infty\frac{|z|^k}{k!}=|z|+\sum\limits_{k=2}^\infty\frac{|z|^k}{k!}$ now it remains to prove that the sum, the most right is $\le|z|$ Since $\sum\limits_{k=2}^\infty\frac{|z|^k}{k!}\le\sum\limits_{k=0}^\infty\left(\frac{|z|}{2}\right)^k-\frac{|z|}{2}-1+\frac{|z|^2}{4}$ (geometric series) the RHS is $\displaystyle \frac{1}{1-\frac{|z|}{2}}-\frac{|z|}{2}-1+\frac{|z|^2}{4}=\frac{\frac{|z|}{2}}{\frac{2}{|z|}-1}+\frac{|z|^2}{4}\le|z|$ am I right ?",,"['complex-analysis', 'inequality', 'proof-verification', 'exponential-function']"
90,Geodesics in upper half-plane model of $\mathbb{H}$,Geodesics in upper half-plane model of,\mathbb{H},"On this page in Schlag's book on complex analysis, he is discussing the upper half-plane model of $\mathbb{H}^2$. He says for all $z_0\in \mathbb{H}$ $$\{T'(z_0) \mid T \in PSL(2, \mathbb{R})  \cap \text{Stab}(z_0)\} = SO(2,\mathbb{R}),$$ which means that the   stabilizer subgroup in $PSL(2, \mathbb{R})$ at any point $z_0$ in the   upper half-plane acts on the tangent space at $z_0$ by arbitrary   rotations. Therefore, the geodesics of $\mathbb{H}$ are all circles   that intersect the real line at a right angle. I understand both of these facts in isolation, but could someone explain to me why the first fact implies the second? Thanks","On this page in Schlag's book on complex analysis, he is discussing the upper half-plane model of $\mathbb{H}^2$. He says for all $z_0\in \mathbb{H}$ $$\{T'(z_0) \mid T \in PSL(2, \mathbb{R})  \cap \text{Stab}(z_0)\} = SO(2,\mathbb{R}),$$ which means that the   stabilizer subgroup in $PSL(2, \mathbb{R})$ at any point $z_0$ in the   upper half-plane acts on the tangent space at $z_0$ by arbitrary   rotations. Therefore, the geodesics of $\mathbb{H}$ are all circles   that intersect the real line at a right angle. I understand both of these facts in isolation, but could someone explain to me why the first fact implies the second? Thanks",,"['complex-analysis', 'differential-geometry', 'hyperbolic-geometry']"
91,"$f: \Omega \rightarrow \Omega$ bounded, $f(z_0) = z_0$, show $|f'(z_0)| \leq 1$","bounded, , show",f: \Omega \rightarrow \Omega f(z_0) = z_0 |f'(z_0)| \leq 1,"I'm stuck on the following problem: Let $\Omega$ be a bounded domain, and $f: \Omega \rightarrow \Omega$ analytic such that $f(z_0) = z_0$.  Show that $|f'(z_0)| \leq 1$. What I did so far was suppose that $|f'(z_0)| > 1$, and define $g_n := f \circ \cdots \circ f$ ($n$ times).  Then $g: \Omega \rightarrow \Omega$ is analytic with $g_n(z_0) = z_0$ and $g_n'(z_0) = f'(z_0)^n$.  It follows that $|g_n'(z_0)|$ is large for $n$ large. So now we are reduced to the case where $g: \Omega \rightarrow \Omega$ is analytic, fixes a point $z_0$, and $g'(z_0)$ is very large.  Somehow I want to show that as a result of $g'(z_0)$ being so large, it must map some point in $\Omega$ outside of $\Omega$, contradiction.  Can anyone give a hint?","I'm stuck on the following problem: Let $\Omega$ be a bounded domain, and $f: \Omega \rightarrow \Omega$ analytic such that $f(z_0) = z_0$.  Show that $|f'(z_0)| \leq 1$. What I did so far was suppose that $|f'(z_0)| > 1$, and define $g_n := f \circ \cdots \circ f$ ($n$ times).  Then $g: \Omega \rightarrow \Omega$ is analytic with $g_n(z_0) = z_0$ and $g_n'(z_0) = f'(z_0)^n$.  It follows that $|g_n'(z_0)|$ is large for $n$ large. So now we are reduced to the case where $g: \Omega \rightarrow \Omega$ is analytic, fixes a point $z_0$, and $g'(z_0)$ is very large.  Somehow I want to show that as a result of $g'(z_0)$ being so large, it must map some point in $\Omega$ outside of $\Omega$, contradiction.  Can anyone give a hint?",,['complex-analysis']
92,"Difference between line integrals in complex analysis and real analysis,","Difference between line integrals in complex analysis and real analysis,",,"The formula in complex analysis is $$\int f(\gamma(t))\cdot(\gamma'(t)dt$$ and the formula in the real variable setting, for a gradient field, is: $$\int F\cdot dr$$ $$=\int f_x\,dx + f_y\,dy + f_z\,dz,$$ where the integrand is said to be an ""exact differential"" (or total differential.) Are the formulas essentially the same thing, when we regard the complex function as a ""vector field"" mapping $C^2 \to C^2$? Also, can one compute line integrals of scalar-valued functions in the real-variable setting -- or would this not make any physical sense? Thanks,","The formula in complex analysis is $$\int f(\gamma(t))\cdot(\gamma'(t)dt$$ and the formula in the real variable setting, for a gradient field, is: $$\int F\cdot dr$$ $$=\int f_x\,dx + f_y\,dy + f_z\,dz,$$ where the integrand is said to be an ""exact differential"" (or total differential.) Are the formulas essentially the same thing, when we regard the complex function as a ""vector field"" mapping $C^2 \to C^2$? Also, can one compute line integrals of scalar-valued functions in the real-variable setting -- or would this not make any physical sense? Thanks,",,"['calculus', 'real-analysis', 'integration', 'complex-analysis', 'multivariable-calculus']"
93,Jacobi Elliptic Functions built from Jacobi theta functions,Jacobi Elliptic Functions built from Jacobi theta functions,,"I believe I understand the general theory of elliptic functions to an extent. What I can't seem to find is the distinct method which was used to show that a particular combination of Jacobi Theta functions defined any specific elliptic function. So my question is, how would I go about defining Weierstrass-$\wp$, $\text{sn}, \text{cn}$, or $\text{dn}$ elliptic functions in terms of Jacobi elliptic functions. Reference material or direct answers would help. Thanks","I believe I understand the general theory of elliptic functions to an extent. What I can't seem to find is the distinct method which was used to show that a particular combination of Jacobi Theta functions defined any specific elliptic function. So my question is, how would I go about defining Weierstrass-$\wp$, $\text{sn}, \text{cn}$, or $\text{dn}$ elliptic functions in terms of Jacobi elliptic functions. Reference material or direct answers would help. Thanks",,"['complex-analysis', 'reference-request', 'elliptic-functions', 'theta-functions']"
94,"$f$ continuous on $\overline{D} \setminus \{1\}$, holomorphic and bounded on $D$. Then $f$ attains its supremum on the boundary","continuous on , holomorphic and bounded on . Then  attains its supremum on the boundary",f \overline{D} \setminus \{1\} D f,"Let $D$ be the unit disc, $f$ continuous on $\overline{D} \setminus \{1\}$, holomorphic and bounded on $D$.  The problem is to show that for all $z \in D$, $$|f(z)| \leq \sup\limits_{|\zeta| = 1, \zeta \neq 1} |f(\zeta)|$$ I'm stuck.  Here are two approaches I tried: I .  $f$ is represented by a convergent power series $\sum\limits_{n=0}^{\infty} a_n z^n$, absolutely and uniformly convergent for $|z| \leq r$, where $r < 1$.  I don't know. II .  For each $0 < r < 1$, there is an angle $\theta \in (-\pi/2, \pi/2]$ such that $|f(z)| \leq |f(r e^{i \theta})|$ for all $|z| < r$ (maximal modulus principle).  Pick $\theta_r$ to be such that $|\theta_r|$ is the supremum of all $|\theta|$ satisfying the condition I just mentioned.  $\theta_r$ would be a limit of the $\theta$, so $|f(z_r)| \geq |f(z)|$ for all $|z| < r$ by continuity, where $z_r$ is defined to be $re^{i \theta_r}$.  The idea is I'm trying to get the $\theta_r$ to not be too close to $0$, if possible. Now pick any sequence of radii $r_1 < r_2 < \cdots $ which converges to $1$.  Then $|f(z_{r_1})| \leq |f(z_{r_2})| \leq \cdots$, and we may choose a convergent subsequence of the $z_n$ converging to, say, $z_0 \in \partial D$.  If $z_0 \neq 1$, we're clearly done. To do this, I want to find a subsequence $z_{n_k}$, and a $\delta > 0$, such that $|\theta_{r_{n_{k}}}| > \delta$ for all $k$.  I can then pick a convergent subsequence of this subsequence to do the trick.  If this is not possible, then it's easy to see that $z_n$ has to converge to $1$ as a result.  The numbers $|f(z_n)|$ are nondecreasing and bounded, so $|f(z_n)|$ tends to a limit as $z_n \to 1$.  By the way I picked $z_n$, this shows that if $\theta_{r_n}'$ is another sequence of angles such that the maximum of $f$ on $|z| = r_n$ is attained at $r_ne^{\theta_n'}$, then $r_ne^{\theta_n'}$ also goes to $1$. Not sure if this approach will go anywhere.","Let $D$ be the unit disc, $f$ continuous on $\overline{D} \setminus \{1\}$, holomorphic and bounded on $D$.  The problem is to show that for all $z \in D$, $$|f(z)| \leq \sup\limits_{|\zeta| = 1, \zeta \neq 1} |f(\zeta)|$$ I'm stuck.  Here are two approaches I tried: I .  $f$ is represented by a convergent power series $\sum\limits_{n=0}^{\infty} a_n z^n$, absolutely and uniformly convergent for $|z| \leq r$, where $r < 1$.  I don't know. II .  For each $0 < r < 1$, there is an angle $\theta \in (-\pi/2, \pi/2]$ such that $|f(z)| \leq |f(r e^{i \theta})|$ for all $|z| < r$ (maximal modulus principle).  Pick $\theta_r$ to be such that $|\theta_r|$ is the supremum of all $|\theta|$ satisfying the condition I just mentioned.  $\theta_r$ would be a limit of the $\theta$, so $|f(z_r)| \geq |f(z)|$ for all $|z| < r$ by continuity, where $z_r$ is defined to be $re^{i \theta_r}$.  The idea is I'm trying to get the $\theta_r$ to not be too close to $0$, if possible. Now pick any sequence of radii $r_1 < r_2 < \cdots $ which converges to $1$.  Then $|f(z_{r_1})| \leq |f(z_{r_2})| \leq \cdots$, and we may choose a convergent subsequence of the $z_n$ converging to, say, $z_0 \in \partial D$.  If $z_0 \neq 1$, we're clearly done. To do this, I want to find a subsequence $z_{n_k}$, and a $\delta > 0$, such that $|\theta_{r_{n_{k}}}| > \delta$ for all $k$.  I can then pick a convergent subsequence of this subsequence to do the trick.  If this is not possible, then it's easy to see that $z_n$ has to converge to $1$ as a result.  The numbers $|f(z_n)|$ are nondecreasing and bounded, so $|f(z_n)|$ tends to a limit as $z_n \to 1$.  By the way I picked $z_n$, this shows that if $\theta_{r_n}'$ is another sequence of angles such that the maximum of $f$ on $|z| = r_n$ is attained at $r_ne^{\theta_n'}$, then $r_ne^{\theta_n'}$ also goes to $1$. Not sure if this approach will go anywhere.",,['complex-analysis']
95,Classification of isolated singularity by limit,Classification of isolated singularity by limit,,"Let $z_0$ be an isolated singularity of $f$ so there exist a punctured ball $B'$ centered in the singularity where $f$ is holomorphic. Let $f(z)=\sum_n a_n (z-z_0)^n$ be the Laurent series of $f$ in $B'$. 1. $z_0$ is a removable singularity iff $\lim_{z \to z_0}f(z)$ exists 2. $z_0$ is a pole iff $\lim_{z \to z_0}f(z)=\infty$ 3. $z_0$ is an essential singularity iff $\lim_{z \to z_0}f(z)$ does not exists (either finite or infinite) Proof of 1 . If $z_0$ is a removable singularity then $f(z)=\sum_{n=0}^{+\infty} a_n (z-z_0)^n$ so it follows $\lim_{z \to z_0}f(z)=a_0$. Conversely if the limit exists, putting $f(z_0):=\lim_{z \to z_0}f(z)$ gives an holomorphic extension of $f$. Proof of 2 . If $z_0$ is a pole of order $m$ then $g(z)=f(z)(z-z_0)^m$ is holomorphic and so $\lim_{z \to z_0}f(z)=\lim_{z \to z_0}\frac{g(z)}{(z-z_0)^m}=\infty$. Conversely by hypotesis one has that $\lim_{z \to z_0}g(z)=0$ where $g(z):=1/f(z)$; so $g$ can be extended holomorphic over all the ball and has a zero in $z_0$. It follows that $f$ has a pole in $z_0$. Proof of 3 . Let $z_0$ be an essential singularity. By Casorati-Weierstrass, $f(B')$ is dense in $\mathbb C$ and so $\forall w \in \mathbb C, \forall \epsilon>0, \exists \zeta \in B'$ such that $|f(\zeta)-w|<\epsilon$. Take $w,w' \in \mathbb C$ with $w \neq w'$, then using the previous statement one can construct two sequences $\{z_n\}$ and $\{u_n\}$ such that $f(z_n) \to w$  and $f(u_n) \to w'$. So $ \lim_{z \to z_0}f(z)$ does not exist. Can I use exclusion for the converse? I mean, if the limit of $f$ in $z_0$ does not exist then $z_0$ is not a removable singularity or a pole and so it is an essential singularity.","Let $z_0$ be an isolated singularity of $f$ so there exist a punctured ball $B'$ centered in the singularity where $f$ is holomorphic. Let $f(z)=\sum_n a_n (z-z_0)^n$ be the Laurent series of $f$ in $B'$. 1. $z_0$ is a removable singularity iff $\lim_{z \to z_0}f(z)$ exists 2. $z_0$ is a pole iff $\lim_{z \to z_0}f(z)=\infty$ 3. $z_0$ is an essential singularity iff $\lim_{z \to z_0}f(z)$ does not exists (either finite or infinite) Proof of 1 . If $z_0$ is a removable singularity then $f(z)=\sum_{n=0}^{+\infty} a_n (z-z_0)^n$ so it follows $\lim_{z \to z_0}f(z)=a_0$. Conversely if the limit exists, putting $f(z_0):=\lim_{z \to z_0}f(z)$ gives an holomorphic extension of $f$. Proof of 2 . If $z_0$ is a pole of order $m$ then $g(z)=f(z)(z-z_0)^m$ is holomorphic and so $\lim_{z \to z_0}f(z)=\lim_{z \to z_0}\frac{g(z)}{(z-z_0)^m}=\infty$. Conversely by hypotesis one has that $\lim_{z \to z_0}g(z)=0$ where $g(z):=1/f(z)$; so $g$ can be extended holomorphic over all the ball and has a zero in $z_0$. It follows that $f$ has a pole in $z_0$. Proof of 3 . Let $z_0$ be an essential singularity. By Casorati-Weierstrass, $f(B')$ is dense in $\mathbb C$ and so $\forall w \in \mathbb C, \forall \epsilon>0, \exists \zeta \in B'$ such that $|f(\zeta)-w|<\epsilon$. Take $w,w' \in \mathbb C$ with $w \neq w'$, then using the previous statement one can construct two sequences $\{z_n\}$ and $\{u_n\}$ such that $f(z_n) \to w$  and $f(u_n) \to w'$. So $ \lim_{z \to z_0}f(z)$ does not exist. Can I use exclusion for the converse? I mean, if the limit of $f$ in $z_0$ does not exist then $z_0$ is not a removable singularity or a pole and so it is an essential singularity.",,['complex-analysis']
96,Why are all open subsets not infinite in extent?,Why are all open subsets not infinite in extent?,,"I have been looking at the definition of an open set, for a metric space. I have come across the following definition, a few times: An open set $U$ of the metric space $(X,d)$ is a set given that $\forall x \in U$ there is at least one $\epsilon>0$ such that $\{y|y\in X, d(x,y)\le\epsilon\}\subseteq U$ To me this means is no final point at the edge of the set, since there always has to be one more for the condition above to hold. Hence the set cannot have an 'edge' and thus must be infinite in extent. Why is my reasoning wrong. (I am looking at this from the complex plane, where the definition says something along the lines of 'for an open set of the complex plane' which to me seems like we can't have an open set of the complex plane, unless it is the whole complex plane)","I have been looking at the definition of an open set, for a metric space. I have come across the following definition, a few times: An open set $U$ of the metric space $(X,d)$ is a set given that $\forall x \in U$ there is at least one $\epsilon>0$ such that $\{y|y\in X, d(x,y)\le\epsilon\}\subseteq U$ To me this means is no final point at the edge of the set, since there always has to be one more for the condition above to hold. Hence the set cannot have an 'edge' and thus must be infinite in extent. Why is my reasoning wrong. (I am looking at this from the complex plane, where the definition says something along the lines of 'for an open set of the complex plane' which to me seems like we can't have an open set of the complex plane, unless it is the whole complex plane)",,"['complex-analysis', 'metric-spaces', 'definition']"
97,How can something be proved unsolvable? [duplicate],How can something be proved unsolvable? [duplicate],,"This question already has answers here : How can you prove that a function has no closed form integral? (7 answers) Closed 8 years ago . My question specifically deals with certain real indefinite integrals such as $$\int e^{-x^2} {dx} \ \ \text{and} \ \ \int \sqrt{1+x^3} {dx}$$ Books and articles online have only ever said that these cannot be expressed in terms of elementary functions. I was wondering how this could be proved? I know this is a naive way of thinking, but it seems to me like these are just unsolved problems, not unsolvable ones.","This question already has answers here : How can you prove that a function has no closed form integral? (7 answers) Closed 8 years ago . My question specifically deals with certain real indefinite integrals such as $$\int e^{-x^2} {dx} \ \ \text{and} \ \ \int \sqrt{1+x^3} {dx}$$ Books and articles online have only ever said that these cannot be expressed in terms of elementary functions. I was wondering how this could be proved? I know this is a naive way of thinking, but it seems to me like these are just unsolved problems, not unsolvable ones.",,"['calculus', 'real-analysis', 'complex-analysis', 'analysis']"
98,Why is the function $\operatorname{Log}(G(t))$ Holder continuous?,Why is the function  Holder continuous?,\operatorname{Log}(G(t)),"I was reading the theory about the Riemann-Hilbert problem $\Phi^+(t)=G(t)\Phi^-(t)$ where $G(t)$ is a Holder continuous function on a closed curve $c$ with index $\operatorname{Ind}_cG(t)=0$.  To solve this problem one takes logarithms on the above relation and reduces the problem to the additive R-H problem $\operatorname{Log}\Phi^+(t)-\operatorname{Log}\Phi^-(t)=\operatorname{Log}G(t)$ which using the Plemelj formulae has the solution given by the Cauchy Integral  $$\operatorname{Log}\Phi(z)=\frac{1}{2\pi i}\int_{c} \frac{\operatorname{Log}G(t)}{t-z}\, dz.$$ But to use this formula the potential -here $\operatorname{Log}G(t)$- must satisfiy the Holder condition. The books that I have read about this justify this result using the fact that, since $\operatorname{Ind}_cG(t)=0$, the function $\operatorname{Log}G(t)$ is single-valued (which is true, no problem there) and thus Holder continuous. So thats my question: How can we show that the function $\operatorname{Log}G(t)$ is H-continuous using the fact that $G(t)$ is H-continuous and $\operatorname{Ind}_cG(t)=0$?","I was reading the theory about the Riemann-Hilbert problem $\Phi^+(t)=G(t)\Phi^-(t)$ where $G(t)$ is a Holder continuous function on a closed curve $c$ with index $\operatorname{Ind}_cG(t)=0$.  To solve this problem one takes logarithms on the above relation and reduces the problem to the additive R-H problem $\operatorname{Log}\Phi^+(t)-\operatorname{Log}\Phi^-(t)=\operatorname{Log}G(t)$ which using the Plemelj formulae has the solution given by the Cauchy Integral  $$\operatorname{Log}\Phi(z)=\frac{1}{2\pi i}\int_{c} \frac{\operatorname{Log}G(t)}{t-z}\, dz.$$ But to use this formula the potential -here $\operatorname{Log}G(t)$- must satisfiy the Holder condition. The books that I have read about this justify this result using the fact that, since $\operatorname{Ind}_cG(t)=0$, the function $\operatorname{Log}G(t)$ is single-valued (which is true, no problem there) and thus Holder continuous. So thats my question: How can we show that the function $\operatorname{Log}G(t)$ is H-continuous using the fact that $G(t)$ is H-continuous and $\operatorname{Ind}_cG(t)=0$?",,"['complex-analysis', 'logarithms', 'boundary-value-problem']"
99,$\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=\frac{3\pi}{8a^5}$ for $a>0$,for,\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=\frac{3\pi}{8a^5} a>0,"I've been trying to show that $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=\frac{3\pi}{8a^5}$ for $a>0$ using complex analysis methods. But for some reason I can't get it to come out.  Perhaps someone could figure out where I am going wrong. Since there are no poles on the real axis, I know that $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=2\pi i\cdot\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right).$ To calculate $\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)$ I used the fact that on a small enough disk centered at $ai$, $\frac{1}{(z+ai)^3}=\sum\limits_{k=0}^\infty c_k(z-ai)^k$. Thus $\frac{1}{(z^2+a^2)^3}=\frac{\frac{1}{(z+ai)^3}}{(z-ai)^3}=\sum\limits_{k=0}^\infty c_k(z-ai)^{k-3}$. So $\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)=c_2.$ Where $c_2=\frac{d^2}{dz^2}\frac{1}{(z+ai)^3}\bigg|_{z=ai}=\frac{12}{(2ia)^5}=\frac{3}{8ia^5}.$ But that gives me  $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=2\pi i\cdot\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)=2\pi i\cdot\frac{3}{8ia^5}=\frac{3\pi}{4a^5}.$ Which is off by $\frac{1}{2}$. I must be making a silly mistake somewhere, but I can't seem to find it. Any help would be appreciated.","I've been trying to show that $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=\frac{3\pi}{8a^5}$ for $a>0$ using complex analysis methods. But for some reason I can't get it to come out.  Perhaps someone could figure out where I am going wrong. Since there are no poles on the real axis, I know that $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=2\pi i\cdot\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right).$ To calculate $\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)$ I used the fact that on a small enough disk centered at $ai$, $\frac{1}{(z+ai)^3}=\sum\limits_{k=0}^\infty c_k(z-ai)^k$. Thus $\frac{1}{(z^2+a^2)^3}=\frac{\frac{1}{(z+ai)^3}}{(z-ai)^3}=\sum\limits_{k=0}^\infty c_k(z-ai)^{k-3}$. So $\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)=c_2.$ Where $c_2=\frac{d^2}{dz^2}\frac{1}{(z+ai)^3}\bigg|_{z=ai}=\frac{12}{(2ia)^5}=\frac{3}{8ia^5}.$ But that gives me  $\int_{-\infty}^\infty\frac{1}{(x^2+a^2)^3}dx=2\pi i\cdot\text{Res}\left(\frac{1}{(z^2+a^2)^3},ia\right)=2\pi i\cdot\frac{3}{8ia^5}=\frac{3\pi}{4a^5}.$ Which is off by $\frac{1}{2}$. I must be making a silly mistake somewhere, but I can't seem to find it. Any help would be appreciated.",,['complex-analysis']
