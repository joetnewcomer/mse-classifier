,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Mnemonic for derivative/integral of $\sin x$ and $\cos x$,Mnemonic for derivative/integral of  and,\sin x \cos x,"I'd love to know if anyone has a good mnemonic for answers of the following: $$\frac{\mathrm{d}}{\mathrm{d}x} \, \sin x$$ $$\frac{\mathrm{d}}{\mathrm{d}x} \, \cos x$$ $$\int \sin x \,\mathrm{d}x$$ $$\int \cos x \,\mathrm{d}x$$ I know the first one by heart, and derive the others from it. This sometimes takes me up to five seconds, longer if I'm not really thinking clearly! Does anyone have a good mnemonic for the answers to these common occurrences?","I'd love to know if anyone has a good mnemonic for answers of the following: $$\frac{\mathrm{d}}{\mathrm{d}x} \, \sin x$$ $$\frac{\mathrm{d}}{\mathrm{d}x} \, \cos x$$ $$\int \sin x \,\mathrm{d}x$$ $$\int \cos x \,\mathrm{d}x$$ I know the first one by heart, and derive the others from it. This sometimes takes me up to five seconds, longer if I'm not really thinking clearly! Does anyone have a good mnemonic for the answers to these common occurrences?",,"['trigonometry', 'derivatives', 'soft-question', 'mnemonic']"
1,To find number of real roots,To find number of real roots,,Consider the equation $x^5-5x=c$ where c is a real number. Determine all c such that this equation has exactly 3 real roots. I know that between consecutive real roots of $f$ there is a real root of $f'$ . Now $f'$ in this case is $5x^4-5$ which always has two real roots. So the claim should be true for all c. But I KNOW IT IS NOT TRUE. Where am I messing up?,Consider the equation where c is a real number. Determine all c such that this equation has exactly 3 real roots. I know that between consecutive real roots of there is a real root of . Now in this case is which always has two real roots. So the claim should be true for all c. But I KNOW IT IS NOT TRUE. Where am I messing up?,x^5-5x=c f f' f' 5x^4-5,"['real-analysis', 'calculus', 'derivatives', 'polynomials']"
2,"Prove $\sin(x)\tan(x) > x^2$ for $x \in ( \,0, \frac{\pi}{2}) \,$",Prove  for,"\sin(x)\tan(x) > x^2 x \in ( \,0, \frac{\pi}{2}) \,","Prove $\sin(x)\tan(x) > x^2$ for $x \in ( \,0, \frac{\pi}{2}) \,$ So I did the following: Let $f(x) = \sin(x)\tan(x) - x^2$ . Then of course $f(0) = 0$ and I want to show that for $x \in ( \,0, \frac{\pi}{2}) \,$ $f'(x) > 0$ but I don't really know where to go from here as I can't get anything reasonable done with the derivative. I was thinking of approximating it using the following inequality $\sin(x) < x < \tan(x)$ . Is that a good direction?",Prove for So I did the following: Let . Then of course and I want to show that for but I don't really know where to go from here as I can't get anything reasonable done with the derivative. I was thinking of approximating it using the following inequality . Is that a good direction?,"\sin(x)\tan(x) > x^2 x \in ( \,0, \frac{\pi}{2}) \, f(x) = \sin(x)\tan(x) - x^2 f(0) = 0 x \in ( \,0, \frac{\pi}{2}) \, f'(x) > 0 \sin(x) < x < \tan(x)","['real-analysis', 'calculus', 'derivatives']"
3,Finding the derivative of an absolute value,Finding the derivative of an absolute value,,"This one I just don't know how to derive. $\ln\|x^4\cos x\|$ I know the derivative of $\ln\ x$ , is just $\frac{1}{x}$ . It is the absolute value that throws me off. My question is, does the absolute value stay as is or does it disappear? $\frac{1}{|x^4\cos x|}$ $\frac{1}{x^4\cos x}$ Or is there an extra step that I should preform?","This one I just don't know how to derive. I know the derivative of , is just . It is the absolute value that throws me off. My question is, does the absolute value stay as is or does it disappear? Or is there an extra step that I should preform?",\ln\|x^4\cos x\| \ln\ x \frac{1}{x} \frac{1}{|x^4\cos x|} \frac{1}{x^4\cos x},"['calculus', 'derivatives']"
4,"Find $f'(8.23)$ where $f(x)=23|x|−37\lfloor x\rfloor+58\{x\}+88\arccos(\sin x)−40\max(x,0)$",Find  where,"f'(8.23) f(x)=23|x|−37\lfloor x\rfloor+58\{x\}+88\arccos(\sin x)−40\max(x,0)","Let $$f(x)=23|x|−37\lfloor x\rfloor+58\{x\}+88\arccos(\sin x)−40\max(x,0).$$ Find $f^\prime(8.23)$. Note: For a real number $x$, $\{x\}=x−\lfloor x\rfloor$ denotes the fractional part of x. I don't know the derivatives of the few pieces of this function (like the fractional part).","Let $$f(x)=23|x|−37\lfloor x\rfloor+58\{x\}+88\arccos(\sin x)−40\max(x,0).$$ Find $f^\prime(8.23)$. Note: For a real number $x$, $\{x\}=x−\lfloor x\rfloor$ denotes the fractional part of x. I don't know the derivatives of the few pieces of this function (like the fractional part).",,"['calculus', 'trigonometry']"
5,Using the chain rule to find derivative,Using the chain rule to find derivative,,"Could you help me figure this one out? $$f(x) = 6e^{x\sin x}$$ $$f'(x) = \,?$$","Could you help me figure this one out? $$f(x) = 6e^{x\sin x}$$ $$f'(x) = \,?$$",,"['calculus', 'derivatives']"
6,Derivative of $e^{\ln(1/x)}$,Derivative of,e^{\ln(1/x)},"This question looks so simple, yet it confused me. If $f(x) = e^{\ln(1/x)}$, then $f'(x) =$ ? I got $e^{\ln(1/x)} \cdot \ln(1/x) \cdot (-1/x^2)$. And the correct answer is just the plain $-1/x^2$. But I don't know how I can cancel out the other two function.","This question looks so simple, yet it confused me. If $f(x) = e^{\ln(1/x)}$, then $f'(x) =$ ? I got $e^{\ln(1/x)} \cdot \ln(1/x) \cdot (-1/x^2)$. And the correct answer is just the plain $-1/x^2$. But I don't know how I can cancel out the other two function.",,"['calculus', 'derivatives']"
7,When can I say that $f(x) \gt g(x) \implies f'(x) \gt g'(x)$?,When can I say that ?,f(x) \gt g(x) \implies f'(x) \gt g'(x),"Are there cases when this relation holds? $$f(x) \gt g(x) \implies f'(x) \gt g'(x)$$ I.e. what are the conditions on $f(x)$ and $g(x)$ for that to be true? Is it even possible to determine them? In case it is always valid, how can it be proved?","Are there cases when this relation holds? $$f(x) \gt g(x) \implies f'(x) \gt g'(x)$$ I.e. what are the conditions on $f(x)$ and $g(x)$ for that to be true? Is it even possible to determine them? In case it is always valid, how can it be proved?",,['derivatives']
8,Why does the scalar inside a natural log dissapear when differentiating it? [closed],Why does the scalar inside a natural log dissapear when differentiating it? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 14 days ago . Improve this question For example if I was differentiating $\ln(2x)$ doesn't the chain rule dictate that it should be $2/x$ , not $1/x$ ? Why does the $2$ disappear?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 14 days ago . Improve this question For example if I was differentiating doesn't the chain rule dictate that it should be , not ? Why does the disappear?",\ln(2x) 2/x 1/x 2,"['calculus', 'derivatives']"
9,Understanding rate of change,Understanding rate of change,,"If we are given the function $y=3x+5$ , and were asked to obtain its derivative we would get $y'=3$ , which means that as $x$ increases, the rate at which $y$ changes is always $3$ .. so if $x=1$ , then $y=8$ and if $x=2$ then $y=8+3=11$ and so on.. I was trying to test this concept in a different function, say $y=x^{2}+x$ , the derivative is $y'=2x+1$ , does that mean that the rate at which $y$ changes is always $2x+1$ ? If $x$ increases by $1$ , then we would have $y=1+1=2$ , and when $x$ increases even more by $1$ , we will get $y=2^{2}+2=6$ .. how can I relate $2$ and $6$ to $y'=2x+1$ like how I did with $y=3x+5$ ?","If we are given the function , and were asked to obtain its derivative we would get , which means that as increases, the rate at which changes is always .. so if , then and if then and so on.. I was trying to test this concept in a different function, say , the derivative is , does that mean that the rate at which changes is always ? If increases by , then we would have , and when increases even more by , we will get .. how can I relate and to like how I did with ?",y=3x+5 y'=3 x y 3 x=1 y=8 x=2 y=8+3=11 y=x^{2}+x y'=2x+1 y 2x+1 x 1 y=1+1=2 x 1 y=2^{2}+2=6 2 6 y'=2x+1 y=3x+5,"['calculus', 'derivatives']"
10,Is $ f(x) = \frac{x}{x}$ differentiable?,Is  differentiable?, f(x) = \frac{x}{x},"I know that the function $f(x) = \frac{x}{x}$ is not differentiable at $x = 0$ , but according to the definition of differentiable functions: A differentiable function of one real variable is a function whose derivative exists at each point in its domain since $x = 0$ is not in the domain of $f$ , it doesn't have to be differentiable at that point for the function to be differentiable. This suggests that $f$ is differentiable as every other points in the domain has a derivative of $0$ . However, some say that a function must be continuous if it's differentiable. This disproves the fact that $f$ is differentiable since it's not a continuous function. Then is it really a differentiable function?","I know that the function is not differentiable at , but according to the definition of differentiable functions: A differentiable function of one real variable is a function whose derivative exists at each point in its domain since is not in the domain of , it doesn't have to be differentiable at that point for the function to be differentiable. This suggests that is differentiable as every other points in the domain has a derivative of . However, some say that a function must be continuous if it's differentiable. This disproves the fact that is differentiable since it's not a continuous function. Then is it really a differentiable function?",f(x) = \frac{x}{x} x = 0 x = 0 f f 0 f,"['calculus', 'derivatives']"
11,A short proof of this? $\frac{\phi(x)-\phi(0)}{x}\in\mathcal{C}^\infty(\mathbb{R})$,A short proof of this?,\frac{\phi(x)-\phi(0)}{x}\in\mathcal{C}^\infty(\mathbb{R}),Let $\phi\in C^\infty(\mathbb{R})$ and let $\psi(x)=\frac{\phi(x)-\phi(0)}{x}$ extended to all $\mathbb{R}$ continuously. I know $\psi\in C^\infty(\mathbb{R})$ but I am looking for a short proof of this.,Let $\phi\in C^\infty(\mathbb{R})$ and let $\psi(x)=\frac{\phi(x)-\phi(0)}{x}$ extended to all $\mathbb{R}$ continuously. I know $\psi\in C^\infty(\mathbb{R})$ but I am looking for a short proof of this.,,"['calculus', 'real-analysis', 'derivatives']"
12,"Given $f^{\prime} = g , \, g^{\prime} = f$, Prove $f = \sinh, \, g = \cosh$","Given , Prove","f^{\prime} = g , \, g^{\prime} = f f = \sinh, \, g = \cosh","I'm having some trouble proving these rigorously Given $f, g\,\colon \mathbb{R} \to \mathbb{R}\,$ differentiable with $$f^{\prime} = g \quad \text{and}\quad g^{\prime} = f$$ First, if $f(0) = g(0) = 0$, Prove that $f = g = 0$ Second, if $f(0) = 0$, $\,g(0) = 1$, Prove that $f = \sinh$, $\,g = \cosh$ Any suggestions?","I'm having some trouble proving these rigorously Given $f, g\,\colon \mathbb{R} \to \mathbb{R}\,$ differentiable with $$f^{\prime} = g \quad \text{and}\quad g^{\prime} = f$$ First, if $f(0) = g(0) = 0$, Prove that $f = g = 0$ Second, if $f(0) = 0$, $\,g(0) = 1$, Prove that $f = \sinh$, $\,g = \cosh$ Any suggestions?",,"['real-analysis', 'trigonometry', 'derivatives']"
13,Multiple derivative notation,Multiple derivative notation,,"Official Leibniz notation for double derivative is: $$\frac{\mathrm d^2s}{\mathrm dt^2}$$ This term seems inconsistent. Two considerations: We have infinitesimal change in distance $\mathrm ds$ per infinitesimal change in time $\mathrm dt$ : $\mathrm ds/\mathrm dt$ . Both terms are a tiny value/interval. Because the $\mathrm d$ symbolizes difference , I would as a change of the change of the distance to time intuitively write: $$\frac{\mathrm d(\mathrm ds/\mathrm dt)}{\mathrm dt}=\frac{(\mathrm ds^2/\mathrm dt^2)}{\mathrm dt}=\frac{\mathrm ds^2}{\mathrm dt^3}$$ where the extra $\mathrm d$ says that both terms are now ""double"" infinitesimal differences. Maybe more properly following mathematical logic and not my intuition, the $\mathrm d$ could be considered a ""free"" variable in itself that can be multiplied onto this $\mathrm ds/\mathrm dt$ fraction numerator: $$\frac{\mathrm d(\mathrm ds/\mathrm dt)}{\mathrm dt}=\frac{(\mathrm d^2s/\mathrm dt)}{\mathrm dt}=\frac{\mathrm d^2 s}{\mathrm dt^2}$$ That agrees with the actual notation but doesn't really make physical sense now. $\mathrm d$ means (infinitesimal) difference, so that $\mathrm ds=s_{final}-s_{start}$ , and therefore it makes no physical sense to consider the $\mathrm d$ and the $s$ separate. The $\mathrm ds$ is physically just a ""name""/""symbol"" for one term, which could just as well have been called $x$ or $a$ or anything else. Now, while searching for an explanation, the answers always tend to consider $\frac{\mathrm d}{\mathrm dt}$ as one symbol in itself, so that a double derivative is $\frac{\mathrm d}{\mathrm dt}\frac{\mathrm d}{\mathrm dt}s=\frac{\mathrm d^2}{\mathrm dt^2}s=\frac{\mathrm d^2s}{\mathrm dt^2}$ - which makes even less physical sense, since the $\mathrm dt$ term has to be a separable term before we can treat $\frac{\mathrm ds}{\mathrm dt}$ as a normal fraction (as done in integration e.g.). $\frac{\mathrm d}{\mathrm dt}$ can't possibly be just ""a symbol"". Why is $\frac{\mathrm d^2s}{\mathrm dt^2}$ the correct one in a physical context, where $\mathrm ds$ actually means the infinitesimal difference in $s$ ? Are my considerations in point 2 correct, and I just can't figure out that splitting $\mathrm d$ and $s$ is allowed? Update The answers already given at this time both indicate the use of $\mathrm d/\mathrm dt$ as merely a symbol. So, neither of my two suggestions mentioned above are the case. Sure, I can accept that. But the question still remains of why as well of how come we still treat them as variables then, e.g. in integration ? Let me clarify those two points: Firstly , if it indeed is the case that $\mathrm d/\mathrm dt$ is merely a symbol and should be thought of as just a symbol, then I do not understand the motivation for this symbol. Why did Leibniz choose $\mathrm d/\mathrm dt$ as a symbol, which causes the confusion and inconsistency described in the question above? Why not, say, $\mathrm d/\mathrm d$ , in which case we would get a writing-style that at least looks a bit more ""consistent"": $$\frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm ds}{\mathrm dt}\qquad \frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm d^2s}{\mathrm d^2t}\qquad \frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm d^3s}{\mathrm d^3t}\qquad \cdots$$ Or even better yet, if the two $\mathrm d$ involved in this $\mathrm d/\mathrm dt$ symbol have no meaning as neither a variable nor an indicator of a change in the parameter, then why use this letter at all? Why not stick to, say, the prime-notation throughout and never jump into the Leibniz notation: $$s_t'\qquad s_t''\qquad s_t'''\qquad \cdots$$ And secondly , if the $\mathrm d/\mathrm dt$ really just is a symbol, and that's it, then how come we suddenly can treat it as a fraction again containing a set of variables $\mathrm ds$ and $\mathrm dt$ that we can split apart during for instance integration? Such as here: $$\frac{\mathrm ds}{\mathrm dt}=v\quad\Leftrightarrow\quad \mathrm ds=v\,\mathrm dt\quad\Leftrightarrow\quad \int  1 \,\mathrm ds=\int v\,\mathrm dt \quad\Leftrightarrow\quad s=\int v\,\mathrm dt$$ I hope to get this notion cleared out and appreciate all comments and answers that can help.","Official Leibniz notation for double derivative is: This term seems inconsistent. Two considerations: We have infinitesimal change in distance per infinitesimal change in time : . Both terms are a tiny value/interval. Because the symbolizes difference , I would as a change of the change of the distance to time intuitively write: where the extra says that both terms are now ""double"" infinitesimal differences. Maybe more properly following mathematical logic and not my intuition, the could be considered a ""free"" variable in itself that can be multiplied onto this fraction numerator: That agrees with the actual notation but doesn't really make physical sense now. means (infinitesimal) difference, so that , and therefore it makes no physical sense to consider the and the separate. The is physically just a ""name""/""symbol"" for one term, which could just as well have been called or or anything else. Now, while searching for an explanation, the answers always tend to consider as one symbol in itself, so that a double derivative is - which makes even less physical sense, since the term has to be a separable term before we can treat as a normal fraction (as done in integration e.g.). can't possibly be just ""a symbol"". Why is the correct one in a physical context, where actually means the infinitesimal difference in ? Are my considerations in point 2 correct, and I just can't figure out that splitting and is allowed? Update The answers already given at this time both indicate the use of as merely a symbol. So, neither of my two suggestions mentioned above are the case. Sure, I can accept that. But the question still remains of why as well of how come we still treat them as variables then, e.g. in integration ? Let me clarify those two points: Firstly , if it indeed is the case that is merely a symbol and should be thought of as just a symbol, then I do not understand the motivation for this symbol. Why did Leibniz choose as a symbol, which causes the confusion and inconsistency described in the question above? Why not, say, , in which case we would get a writing-style that at least looks a bit more ""consistent"": Or even better yet, if the two involved in this symbol have no meaning as neither a variable nor an indicator of a change in the parameter, then why use this letter at all? Why not stick to, say, the prime-notation throughout and never jump into the Leibniz notation: And secondly , if the really just is a symbol, and that's it, then how come we suddenly can treat it as a fraction again containing a set of variables and that we can split apart during for instance integration? Such as here: I hope to get this notion cleared out and appreciate all comments and answers that can help.","\frac{\mathrm d^2s}{\mathrm dt^2} \mathrm ds \mathrm dt \mathrm ds/\mathrm dt \mathrm d \frac{\mathrm d(\mathrm ds/\mathrm dt)}{\mathrm dt}=\frac{(\mathrm ds^2/\mathrm dt^2)}{\mathrm dt}=\frac{\mathrm ds^2}{\mathrm dt^3} \mathrm d \mathrm d \mathrm ds/\mathrm dt \frac{\mathrm d(\mathrm ds/\mathrm dt)}{\mathrm dt}=\frac{(\mathrm d^2s/\mathrm dt)}{\mathrm dt}=\frac{\mathrm d^2 s}{\mathrm dt^2} \mathrm d \mathrm ds=s_{final}-s_{start} \mathrm d s \mathrm ds x a \frac{\mathrm d}{\mathrm dt} \frac{\mathrm d}{\mathrm dt}\frac{\mathrm d}{\mathrm dt}s=\frac{\mathrm d^2}{\mathrm dt^2}s=\frac{\mathrm d^2s}{\mathrm dt^2} \mathrm dt \frac{\mathrm ds}{\mathrm dt} \frac{\mathrm d}{\mathrm dt} \frac{\mathrm d^2s}{\mathrm dt^2} \mathrm ds s \mathrm d s \mathrm d/\mathrm dt \mathrm d/\mathrm dt \mathrm d/\mathrm dt \mathrm d/\mathrm d \frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm ds}{\mathrm dt}\qquad \frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm d^2s}{\mathrm d^2t}\qquad \frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac{\mathrm d}{\mathrm d}\frac st=\frac{\mathrm d^3s}{\mathrm d^3t}\qquad \cdots \mathrm d \mathrm d/\mathrm dt s_t'\qquad s_t''\qquad s_t'''\qquad \cdots \mathrm d/\mathrm dt \mathrm ds \mathrm dt \frac{\mathrm ds}{\mathrm dt}=v\quad\Leftrightarrow\quad \mathrm ds=v\,\mathrm dt\quad\Leftrightarrow\quad \int  1 \,\mathrm ds=\int v\,\mathrm dt \quad\Leftrightarrow\quad s=\int v\,\mathrm dt","['derivatives', 'notation']"
14,Minimum distance between the curves $f(x) =e^x$ and $g(x) =\ln x$ [closed],Minimum distance between the curves  and  [closed],f(x) =e^x g(x) =\ln x,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What is the minimum distance between the curves $f(x) =e^x$ and $g(x) = \ln x$? I didn't understand how to solve the problem. Please help me.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question What is the minimum distance between the curves $f(x) =e^x$ and $g(x) = \ln x$? I didn't understand how to solve the problem. Please help me.",,"['calculus', 'derivatives', 'applications', 'curves']"
15,Where did it come from? (derivative of exponential),Where did it come from? (derivative of exponential),,"We all know this rule: $\text{If } y = a^{f(x)} \text{ then } y' = a^{f(x)} \: f'(x)\ln a$ In my book there is the example: Find $\frac{d}{dx}\left((x^{2} + 1)^{\sin x}\right)$ According to the rule, my answer is: $(x^{2} + 1)^{\sin x} \cdot \cos x \cdot \ln(x^{2} + 1)$ But the answer of the book was: $$(x^{2} + 1)^{\sin x}\left(\frac{2x \sin x}{x^{2} + 1} + \cos x \cdot \ln(x^{2} + 1)\right)$$ So, where did $\frac{2x \sin x}{x^{2} + 1}$ come from?","We all know this rule: $\text{If } y = a^{f(x)} \text{ then } y' = a^{f(x)} \: f'(x)\ln a$ In my book there is the example: Find $\frac{d}{dx}\left((x^{2} + 1)^{\sin x}\right)$ According to the rule, my answer is: $(x^{2} + 1)^{\sin x} \cdot \cos x \cdot \ln(x^{2} + 1)$ But the answer of the book was: $$(x^{2} + 1)^{\sin x}\left(\frac{2x \sin x}{x^{2} + 1} + \cos x \cdot \ln(x^{2} + 1)\right)$$ So, where did $\frac{2x \sin x}{x^{2} + 1}$ come from?",,"['derivatives', 'exponential-function']"
16,What functions have the property that $\frac{d}{dx}f(x) = c \cdot f(x+1)$?,What functions have the property that ?,\frac{d}{dx}f(x) = c \cdot f(x+1),"If we are allowed to pick any real-valued constant $c$ that helps, when does $$\frac{d}{dx}f(x) = c \cdot f(x+1)$$ In other words, when does the derivative of a function $f(x)$ equal some constant times $f(x)$? EXAMPLE If we set $f(x) = \sin{ (\frac{\pi}{2}x) }$, then $$\frac{d}{dx} \left( \sin (\frac{\pi}{2}x)  \right) = \frac{\pi}{2}\sin (\frac{\pi}{2}(x+1)) $$ This also works for $f(x) = \cos (\frac{\pi}{2}x) $: $$\frac{d}{dx} \left( \cos (\frac{\pi}{2}x)  \right) =\frac{\pi}{2} \cos (\frac{\pi}{2}(x+1)) $$ WHAT I'M AFTER Is there some way of finding formulas that possess this property? Perhaps there is a way to formalize a method.  I'd like to know if there's an easy way to find formulas that work.","If we are allowed to pick any real-valued constant $c$ that helps, when does $$\frac{d}{dx}f(x) = c \cdot f(x+1)$$ In other words, when does the derivative of a function $f(x)$ equal some constant times $f(x)$? EXAMPLE If we set $f(x) = \sin{ (\frac{\pi}{2}x) }$, then $$\frac{d}{dx} \left( \sin (\frac{\pi}{2}x)  \right) = \frac{\pi}{2}\sin (\frac{\pi}{2}(x+1)) $$ This also works for $f(x) = \cos (\frac{\pi}{2}x) $: $$\frac{d}{dx} \left( \cos (\frac{\pi}{2}x)  \right) =\frac{\pi}{2} \cos (\frac{\pi}{2}(x+1)) $$ WHAT I'M AFTER Is there some way of finding formulas that possess this property? Perhaps there is a way to formalize a method.  I'd like to know if there's an easy way to find formulas that work.",,"['derivatives', 'intuition', 'transformation']"
17,Differentiate $g(t)= {e^t - e^{-t} \over e^t + e^{-t}}$,Differentiate,g(t)= {e^t - e^{-t} \over e^t + e^{-t}},I'm having some trouble trying to differentiate the function $g(t)= \dfrac{e^t - e^{-t}}{e^t + e^{-t}}$ Can someone help me? Thanks a lot!,I'm having some trouble trying to differentiate the function $g(t)= \dfrac{e^t - e^{-t}}{e^t + e^{-t}}$ Can someone help me? Thanks a lot!,,"['calculus', 'derivatives']"
18,Find the $2022$th derivative $f^{(2022)}(0)$ of the function $f(x) = x^{2019}\cos(x)$.,Find the th derivative  of the function .,2022 f^{(2022)}(0) f(x) = x^{2019}\cos(x),"Find $f^{(2022)}(0)$ of the function $$f(x)=x^{2019} \cos x.$$ By Taylor series at the point $x =0$ , my answer was $0$ . But someone who gave this question to me said the answer is like the below picture. Who is correct? Did I something wrong?","Find of the function By Taylor series at the point , my answer was . But someone who gave this question to me said the answer is like the below picture. Who is correct? Did I something wrong?",f^{(2022)}(0) f(x)=x^{2019} \cos x. x =0 0,"['real-analysis', 'derivatives']"
19,What characterizes a tangent line?,What characterizes a tangent line?,,"If the traditional way to define the tangent line to a curve $f(x)$ through the point say $(a , f(a))$ is: ( the tangent line through the point $(a ,f(a))$ is the line that passes through this point with a slope that is equal to the value of the derivative at that point).  From this definition why it follows that in many cases the tangent line touches the curve only once locally? For example take the parabola $f(x)=  x^2 $ the tangent line at the point $(1,1)$ has the equation $g(x)= 2x-1$ . $g$ touches $f$ only at $(1,1)$ .  Why this is true not only for this special case, but for most curves at most points? I have an intuitive feeling for why this is true, so, is there a proof that the tangent line (from the above definition)  will have this property (it touches the curve only once locally) for certain curves like: a circle or a polynomial of degree more than 1?","If the traditional way to define the tangent line to a curve through the point say is: ( the tangent line through the point is the line that passes through this point with a slope that is equal to the value of the derivative at that point).  From this definition why it follows that in many cases the tangent line touches the curve only once locally? For example take the parabola the tangent line at the point has the equation . touches only at .  Why this is true not only for this special case, but for most curves at most points? I have an intuitive feeling for why this is true, so, is there a proof that the tangent line (from the above definition)  will have this property (it touches the curve only once locally) for certain curves like: a circle or a polynomial of degree more than 1?","f(x) (a , f(a)) (a ,f(a)) f(x)=  x^2  (1,1) g(x)= 2x-1 g f (1,1)","['real-analysis', 'calculus', 'derivatives', 'tangent-line', 'slope']"
20,"Longest derivative ""loop""? [duplicate]","Longest derivative ""loop""? [duplicate]",,"This question already has answers here : Functions that are their Own nth Derivatives for Real $n$ (5 answers) Closed 6 years ago . If we keep differentiating $\sin x$ we eventually arrive back at $\sin x$: $$ \begin{align} y &= \sin x \\ \frac{dy}{dx} &= \cos x \\ \frac{d^2y}{dx^2} &= -\sin x \\ \frac{d^3y}{dx^3} &= -\cos x \\ \frac{d^4y}{dx^4} &= \sin x \end{align} $$ It has to be differentiated 4 times before it gets back to itself I was wondering, what function has the longest chain of derivatives before it gets back to itself?","This question already has answers here : Functions that are their Own nth Derivatives for Real $n$ (5 answers) Closed 6 years ago . If we keep differentiating $\sin x$ we eventually arrive back at $\sin x$: $$ \begin{align} y &= \sin x \\ \frac{dy}{dx} &= \cos x \\ \frac{d^2y}{dx^2} &= -\sin x \\ \frac{d^3y}{dx^3} &= -\cos x \\ \frac{d^4y}{dx^4} &= \sin x \end{align} $$ It has to be differentiated 4 times before it gets back to itself I was wondering, what function has the longest chain of derivatives before it gets back to itself?",,['derivatives']
21,Finding the $n^{th}$ derivative of $\frac{x^n}{(1+x)}$,Finding the  derivative of,n^{th} \frac{x^n}{(1+x)},"Find the $n^{th}$ derivative of $\frac{x^n}{(1+x)}$ . I think we have to use Leibnitz's Formula to evaluate this, but I haven't succeeded in it as well. I have already received an answer of $\frac {x^n}{(1+x)}$, that was a bit simpler maybe, but I could not get this one...hope some one can help.","Find the $n^{th}$ derivative of $\frac{x^n}{(1+x)}$ . I think we have to use Leibnitz's Formula to evaluate this, but I haven't succeeded in it as well. I have already received an answer of $\frac {x^n}{(1+x)}$, that was a bit simpler maybe, but I could not get this one...hope some one can help.",,"['calculus', 'derivatives', 'closed-form']"
22,How to learn differentiation?,How to learn differentiation?,,I am having a confusion in learning differentiation. Can you please point me to some video tutorials which explains differentiation basics clearly for beginners?,I am having a confusion in learning differentiation. Can you please point me to some video tutorials which explains differentiation basics clearly for beginners?,,"['calculus', 'derivatives', 'learning']"
23,how to calculate $\frac{d\dot{x}}{dx}$,how to calculate,\frac{d\dot{x}}{dx},Let $x$ depend on $t$. $\dot{x}$ is derivative $x$ over $t$. I want to know if  there are formulas to simplify $\frac{d\dot{x}}{dx}$? Any hint or thought is appreciated. Thank you!,Let $x$ depend on $t$. $\dot{x}$ is derivative $x$ over $t$. I want to know if  there are formulas to simplify $\frac{d\dot{x}}{dx}$? Any hint or thought is appreciated. Thank you!,,['derivatives']
24,The derivative of $\arccos(\cos(x))$,The derivative of,\arccos(\cos(x)),"I was asked to show that $\frac{d}{dx}\arccos(\cos{x}), x \in R$ is equal to $\frac{\sin{x}}{|\sin{x}|}$. What I was able to show is the following: $\frac{d}{dx}\arccos(\cos(x)) = \frac{\sin(x)}{\sqrt{1 - \cos^2{x}}}$ What justifies equating $\sqrt{1 - \cos^2{x}}$ to $|\sin{x}|$? I am aware of the identity $ \sin{x} = \pm\sqrt{1 - \cos^2{x}}$, but I still do not see how that leads to that conclusion.","I was asked to show that $\frac{d}{dx}\arccos(\cos{x}), x \in R$ is equal to $\frac{\sin{x}}{|\sin{x}|}$. What I was able to show is the following: $\frac{d}{dx}\arccos(\cos(x)) = \frac{\sin(x)}{\sqrt{1 - \cos^2{x}}}$ What justifies equating $\sqrt{1 - \cos^2{x}}$ to $|\sin{x}|$? I am aware of the identity $ \sin{x} = \pm\sqrt{1 - \cos^2{x}}$, but I still do not see how that leads to that conclusion.",,['derivatives']
25,Differentiation of inner product with matrices,Differentiation of inner product with matrices,,"Let $n \in \mathbb{N}  (n \neq 0)$ , $A$ a real $\mathbb{nxn}$ square matrix, and $\mathbf{c}$ a vector in $\mathbb{R}^{n}$ . Consider a real function $h: \mathbb{R} \longrightarrow \mathbb{R}, h \in C^{2}(\mathbb{R})$ , and introduce the function $g: \mathbb{R}^{n} \longrightarrow \mathbb{R}$ , defined by $$ g(\mathbf{x})=h\left(\langle A x, A x\rangle\right)- \langle \mathbf{c}, \mathbf{x} \rangle, \quad \forall \mathbf{x} \in \mathbb{R}^{n} . $$ I want to compute $\nabla g$ and $H(g)$ (using only matrices and vector terms) My partial attempt: $$ g^{\prime}(x)=h^{\prime}(\langle A x, A x\rangle) \cdot \text { term }-c $$ Now $ \langle A x, A x\rangle $ is a sum  of terms of the form: $$ \left(\sum_{i=1}^{n} a_{s i} x_{i}\right)\left(\sum_{i=1}^{n} a_{s i} x_{i}\right)=\sum_{k_{1}+k_{2}, \ldots+k_{n}=2}^{n}\left(\begin{array}{c} 2 \\ k_{1}, k_{2}, \ldots, k_{n} \end{array}\right) x^{k_{1}} \cdot \ldots \cdot x^{k_{n}} $$ How to continue? is there any option to avoid using so detailed form? Thank you","Let , a real square matrix, and a vector in . Consider a real function , and introduce the function , defined by I want to compute and (using only matrices and vector terms) My partial attempt: Now is a sum  of terms of the form: How to continue? is there any option to avoid using so detailed form? Thank you","n \in \mathbb{N}  (n \neq 0) A \mathbb{nxn} \mathbf{c} \mathbb{R}^{n} h: \mathbb{R} \longrightarrow \mathbb{R}, h \in C^{2}(\mathbb{R}) g: \mathbb{R}^{n} \longrightarrow \mathbb{R} 
g(\mathbf{x})=h\left(\langle A x, A x\rangle\right)- \langle \mathbf{c}, \mathbf{x} \rangle, \quad \forall \mathbf{x} \in \mathbb{R}^{n} .
 \nabla g H(g) 
g^{\prime}(x)=h^{\prime}(\langle A x, A x\rangle) \cdot \text { term }-c
 
\langle A x, A x\rangle
 
\left(\sum_{i=1}^{n} a_{s i} x_{i}\right)\left(\sum_{i=1}^{n} a_{s i} x_{i}\right)=\sum_{k_{1}+k_{2}, \ldots+k_{n}=2}^{n}\left(\begin{array}{c}
2 \\
k_{1}, k_{2}, \ldots, k_{n}
\end{array}\right) x^{k_{1}} \cdot \ldots \cdot x^{k_{n}}
","['calculus', 'derivatives', 'inner-products', 'matrix-calculus', 'multinomial-coefficients']"
26,Strategy to calculate $ \frac{d}{dx} \left(\frac{x^2-6x-9}{2x^2(x+3)^2}\right) $.,Strategy to calculate ., \frac{d}{dx} \left(\frac{x^2-6x-9}{2x^2(x+3)^2}\right) ,"I am asked to calculate the following: $$ \frac{d}{dx} \left(\frac{x^2-6x-9}{2x^2(x+3)^2}\right). $$ I simplify this a little bit, by moving the constant multiplicator out of the derivative: $$ \left(\frac{1}{2}\right) \frac{d}{dx} \left(\frac{x^2-6x-9}{x^2(x+3)^2}\right) $$ But, using the quotient-rule , the resulting expressions really get unwieldy: $$ \frac{1}{2} \frac{(2x-6)(x^2(x+3)^2) -(x^2-6x-9)(2x(2x^2+9x+9))}{(x^2(x+3)^2)^2} $$ I came up with two approaches (3 maybe): Split the terms up like this: $$ \frac{1}{2}\left( \frac{(2x-6)(x^2(x+3)^2)}{(x^2(x+3)^2)^2} - \frac{(x^2-6x-9)(2x(2x^2+9x+9))}{(x^2(x+3)^2)^2} \right) $$ so that I can simplify the left term to $$ \frac{2x-6}{x^2(x+3)^2}. $$ Taking this approach the right term still doesn't simplify nicely, and I struggle to combine the two terms into one fraction at the end. The brute-force-method. Just expand all the expressions in numerator and denominator, and add/subtract monomials of the same order. This definitely works, but i feel like a stupid robot doing this. The unofficial third-method. Grab a calculator, or computer-algebra-program and let it do the hard work. Is there any strategy apart from my mentioned ones? Am I missing something in my first approach which would make the process go more smoothly? I am looking for general tips to tackle polynomial fractions such as this one, not a plain answer to this specific problem.","I am asked to calculate the following: I simplify this a little bit, by moving the constant multiplicator out of the derivative: But, using the quotient-rule , the resulting expressions really get unwieldy: I came up with two approaches (3 maybe): Split the terms up like this: so that I can simplify the left term to Taking this approach the right term still doesn't simplify nicely, and I struggle to combine the two terms into one fraction at the end. The brute-force-method. Just expand all the expressions in numerator and denominator, and add/subtract monomials of the same order. This definitely works, but i feel like a stupid robot doing this. The unofficial third-method. Grab a calculator, or computer-algebra-program and let it do the hard work. Is there any strategy apart from my mentioned ones? Am I missing something in my first approach which would make the process go more smoothly? I am looking for general tips to tackle polynomial fractions such as this one, not a plain answer to this specific problem.", \frac{d}{dx} \left(\frac{x^2-6x-9}{2x^2(x+3)^2}\right).   \left(\frac{1}{2}\right) \frac{d}{dx} \left(\frac{x^2-6x-9}{x^2(x+3)^2}\right)   \frac{1}{2} \frac{(2x-6)(x^2(x+3)^2) -(x^2-6x-9)(2x(2x^2+9x+9))}{(x^2(x+3)^2)^2}   \frac{1}{2}\left( \frac{(2x-6)(x^2(x+3)^2)}{(x^2(x+3)^2)^2} - \frac{(x^2-6x-9)(2x(2x^2+9x+9))}{(x^2(x+3)^2)^2} \right)   \frac{2x-6}{x^2(x+3)^2}. ,"['calculus', 'derivatives', 'polynomials']"
27,Derivative of $\dfrac{\sqrt{3-x^2}}{3+x}$,Derivative of,\dfrac{\sqrt{3-x^2}}{3+x},"I am trying to find the derivative of this function $f(x)=\dfrac{\sqrt{3-x^2}}{3+x}$ $f'(x)=\dfrac{\dfrac{1}{2}(3-x^2)^{-\frac{1}{2}}\frac{d}{dx}(3-x)(3+x)-\sqrt{3-x^2}}{(3+x)^2}$ $=\dfrac{\dfrac{-2x(3+x)}{2\sqrt{3-x^2}}-\sqrt{3-x^2}}{(3+x)^2}$ $=\dfrac{\dfrac{-x(3+x)}{\sqrt{3-x^2}}-\sqrt{3-x^2}}{(3+x)^2}$ $\dfrac{-x(3+x)}{\sqrt{3-x^2}(3+x)^2}-\dfrac{\sqrt{3-x^2}}{(3+x)^2}$ $\dfrac{-x}{\sqrt{3-x^2}(3+x)}-\dfrac{\sqrt{3-x^2}}{(3+x)^2}$ At this point, I want to transform this derivative into the form of $\dfrac{3(x+1)}{(3+x)^2\sqrt{3-x^2}}$ How do I do this? This form is given by Wolfram: https://www.wolframalpha.com/input/?i=derivative+%283-x%5E2%29%5E%281%2F2%29%2F%283%2Bx%29","I am trying to find the derivative of this function At this point, I want to transform this derivative into the form of How do I do this? This form is given by Wolfram: https://www.wolframalpha.com/input/?i=derivative+%283-x%5E2%29%5E%281%2F2%29%2F%283%2Bx%29",f(x)=\dfrac{\sqrt{3-x^2}}{3+x} f'(x)=\dfrac{\dfrac{1}{2}(3-x^2)^{-\frac{1}{2}}\frac{d}{dx}(3-x)(3+x)-\sqrt{3-x^2}}{(3+x)^2} =\dfrac{\dfrac{-2x(3+x)}{2\sqrt{3-x^2}}-\sqrt{3-x^2}}{(3+x)^2} =\dfrac{\dfrac{-x(3+x)}{\sqrt{3-x^2}}-\sqrt{3-x^2}}{(3+x)^2} \dfrac{-x(3+x)}{\sqrt{3-x^2}(3+x)^2}-\dfrac{\sqrt{3-x^2}}{(3+x)^2} \dfrac{-x}{\sqrt{3-x^2}(3+x)}-\dfrac{\sqrt{3-x^2}}{(3+x)^2} \dfrac{3(x+1)}{(3+x)^2\sqrt{3-x^2}},"['calculus', 'derivatives']"
28,How do I find the absolute maximum and absolute minimum of a function on the given interval?,How do I find the absolute maximum and absolute minimum of a function on the given interval?,,"I am a little confused on how to find the absolute max and min without using a calculator. I know I have to find the derivative of this function and find critical values, but I'm not finding any critical values. I know that the max value of this function in the given interval is $(-5,5)$ , but I cannot find the minimum. Any suggestions?","I am a little confused on how to find the absolute max and min without using a calculator. I know I have to find the derivative of this function and find critical values, but I'm not finding any critical values. I know that the max value of this function in the given interval is , but I cannot find the minimum. Any suggestions?","(-5,5)","['calculus', 'derivatives', 'absolute-value', 'maxima-minima']"
29,Two non-differentiable functions whose product is differentiable.,Two non-differentiable functions whose product is differentiable.,,So I was wondering while studying analysis if there is any case where two functions aren't differential at $0$ (kind of like $1/x$) but is differentiable at 0 when combined (i.e.  $fg$). I mean this for functions that are defined on $\mathbb{R}$.,So I was wondering while studying analysis if there is any case where two functions aren't differential at $0$ (kind of like $1/x$) but is differentiable at 0 when combined (i.e.  $fg$). I mean this for functions that are defined on $\mathbb{R}$.,,"['calculus', 'real-analysis', 'derivatives']"
30,Why's the derivative of $f(x) = x^3-5x-2 $ not $3x^2-7$?,Why's the derivative of  not ?,f(x) = x^3-5x-2  3x^2-7,"I wanted to resolve this problem : $$ f(x) = 3 x^2 - 5 x - 2 $$ to a derivative, and I did it like this : $ \begin{align} f(x) &= x^3-5x-2 \\ f'(x) &= 3x^2-5-2 \\       &= 3x^2-7 \end{align} $ but once I checked the correction, I found this: $$ f'(x) = 3 x^2 - 5 $$ And I really don't know how they manage to get $3x^2 -5$ instead of $3x^2-7$. Thanks for you time","I wanted to resolve this problem : $$ f(x) = 3 x^2 - 5 x - 2 $$ to a derivative, and I did it like this : $ \begin{align} f(x) &= x^3-5x-2 \\ f'(x) &= 3x^2-5-2 \\       &= 3x^2-7 \end{align} $ but once I checked the correction, I found this: $$ f'(x) = 3 x^2 - 5 $$ And I really don't know how they manage to get $3x^2 -5$ instead of $3x^2-7$. Thanks for you time",,['derivatives']
31,Derivative of absolute value of $|x^5|$,Derivative of absolute value of,|x^5|,Differentiate $|x^5|$. I know the formula for the derivative of absolute value but I can't seem to apply it to get $5x|x^3|$.,Differentiate $|x^5|$. I know the formula for the derivative of absolute value but I can't seem to apply it to get $5x|x^3|$.,,"['calculus', 'derivatives', 'absolute-value']"
32,derivative of $y=\frac{x^2\sqrt{x+1}}{(x+2)(x-3)^5}$,derivative of,y=\frac{x^2\sqrt{x+1}}{(x+2)(x-3)^5},$y=\dfrac{x^2\sqrt{x+1}}{(x+2)(x-3)^5}$ The answer is $\dfrac{x^2\sqrt{x+1}}{(x+2)(x-3)^5} \left(\dfrac{2}{x}+\dfrac{1}{2(x+1)}-\dfrac{1}{x+2}-\dfrac{5}{x-3}\right)$ I know that the quotient rule is used but I don't know how to do this problem. Would you multiply together all the terms and then differentiate?,$y=\dfrac{x^2\sqrt{x+1}}{(x+2)(x-3)^5}$ The answer is $\dfrac{x^2\sqrt{x+1}}{(x+2)(x-3)^5} \left(\dfrac{2}{x}+\dfrac{1}{2(x+1)}-\dfrac{1}{x+2}-\dfrac{5}{x-3}\right)$ I know that the quotient rule is used but I don't know how to do this problem. Would you multiply together all the terms and then differentiate?,,"['calculus', 'derivatives']"
33,Shorthand notation for partial?,Shorthand notation for partial?,,"If I am taking a regular derivative, and I want to show the process in detail, I'll do something of the sort $f'(x) = g'(x) + h'(x) - l'(x) ..... $, etc, using that ""prime"" notation. However, what if I wanted to take the partial derivative? Would I still use the prime notation, as long as it's clear what we are treating as a constant? Or is there some other notation for this?","If I am taking a regular derivative, and I want to show the process in detail, I'll do something of the sort $f'(x) = g'(x) + h'(x) - l'(x) ..... $, etc, using that ""prime"" notation. However, what if I wanted to take the partial derivative? Would I still use the prime notation, as long as it's clear what we are treating as a constant? Or is there some other notation for this?",,"['derivatives', 'notation']"
34,Differentiate the following function,Differentiate the following function,,"$$y = \sqrt {\sin x} = (\sin x)^{\frac 12}$$ \begin{aligned} {dy \over dx} & = \frac 12 (\sin x)^{-\frac {1}2}{d\over dx} \sin x  \\ & = \frac 12 (\sin x)^{-\frac 12} \cos x  \\ & = \frac{\cos x}{ 2\sqrt{\sin x}} \end{aligned} Is this correct? Please excuse the poor layout, i'm new :'(","$$y = \sqrt {\sin x} = (\sin x)^{\frac 12}$$ \begin{aligned} {dy \over dx} & = \frac 12 (\sin x)^{-\frac {1}2}{d\over dx} \sin x  \\ & = \frac 12 (\sin x)^{-\frac 12} \cos x  \\ & = \frac{\cos x}{ 2\sqrt{\sin x}} \end{aligned} Is this correct? Please excuse the poor layout, i'm new :'(",,"['calculus', 'derivatives']"
35,Example of uniformly continuous function on R that is not differentiable on all of R,Example of uniformly continuous function on R that is not differentiable on all of R,,"Give an example of a uniformly continuous function $g:\mathbb{R} \rightarrow \mathbb{R}$ that is not differentiable on all of $\mathbb{R}$. Hmm. I can't think creatively enough for one! Would f(x) = |x| on (-1,1) be an example? Certainly not differentiabe, but it if uniformly continuous? Another one: Give an example of a sequence of continuous functions $f_n: \mathbb{R}\rightarrow \mathbb{R}$ whose pointwise limit $f:\mathbb{R} \rightarrow \mathbb{R}$ exists, but is discontinuous.","Give an example of a uniformly continuous function $g:\mathbb{R} \rightarrow \mathbb{R}$ that is not differentiable on all of $\mathbb{R}$. Hmm. I can't think creatively enough for one! Would f(x) = |x| on (-1,1) be an example? Certainly not differentiabe, but it if uniformly continuous? Another one: Give an example of a sequence of continuous functions $f_n: \mathbb{R}\rightarrow \mathbb{R}$ whose pointwise limit $f:\mathbb{R} \rightarrow \mathbb{R}$ exists, but is discontinuous.",,"['real-analysis', 'derivatives', 'continuity', 'uniform-continuity']"
36,How to make a box which has the largest possible volume?,How to make a box which has the largest possible volume?,,"I have sheet metal in form of an equilateral triangle and I want to fold it to make a container for the screws. How should I cut and fold to make the a box with largest volume? Basically I cut the corners and then fold them. There is no ""roof"".  Thank you! This is related to CAD design in Solidworks! $$a=0.15m$$","I have sheet metal in form of an equilateral triangle and I want to fold it to make a container for the screws. How should I cut and fold to make the a box with largest volume? Basically I cut the corners and then fold them. There is no ""roof"".  Thank you! This is related to CAD design in Solidworks! $$a=0.15m$$",,['calculus']
37,Computing derivative $x^{x^x}$,Computing derivative,x^{x^x},"Could you show me how to compute $f'(x)$, where $f(x)=x^{x^x}$. I know that for $g(x)=x^x=e^{x\ln x} \ \ $ $g'(x)=e^{x\ln x}(\ln x+1)$ Now, my problem is this: is $f(x)=x^{x^x}= e^{x^x \ln x}$ or $e^{x\ln x^x}$ ?","Could you show me how to compute $f'(x)$, where $f(x)=x^{x^x}$. I know that for $g(x)=x^x=e^{x\ln x} \ \ $ $g'(x)=e^{x\ln x}(\ln x+1)$ Now, my problem is this: is $f(x)=x^{x^x}= e^{x^x \ln x}$ or $e^{x\ln x^x}$ ?",,['derivatives']
38,Finding the derivative of an exponential function without the chain rule,Finding the derivative of an exponential function without the chain rule,,"Given $f(x) = a^x$ , one can compute the derivative of $f(x)$ using the chain rule quickly by noticing that $f(x) = a^x = \left(e^{ln(a)}\right)^x$ . But how would you go about computing the derivative of $f(x)$ without the chain rule, with just the $f'(x) = \lim_\limits{h \to 0} \frac{f(x + h) - f(x)}{h}$ or the $f'(x) = \lim_\limits{x \to a} \frac{f(x) - f(a)}{x - a}$ definition of a derivative and the fact that $\lim_\limits{h \to 0} \frac{e^h - 1}{h} = 1$ ? $f'(x) = \lim_\limits{h \to 0} \frac{a^{x + h} - a^x}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{a^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{\left(e^{ln(a)}\right)^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{(e^h)^{ln(a)} - 1}{h}$ . How would you proceed from here?","Given , one can compute the derivative of using the chain rule quickly by noticing that . But how would you go about computing the derivative of without the chain rule, with just the or the definition of a derivative and the fact that ? . How would you proceed from here?",f(x) = a^x f(x) f(x) = a^x = \left(e^{ln(a)}\right)^x f(x) f'(x) = \lim_\limits{h \to 0} \frac{f(x + h) - f(x)}{h} f'(x) = \lim_\limits{x \to a} \frac{f(x) - f(a)}{x - a} \lim_\limits{h \to 0} \frac{e^h - 1}{h} = 1 f'(x) = \lim_\limits{h \to 0} \frac{a^{x + h} - a^x}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{a^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{\left(e^{ln(a)}\right)^h - 1}{h} = a^x \cdot \lim_\limits{h \to 0} \frac{(e^h)^{ln(a)} - 1}{h},"['calculus', 'derivatives', 'exponential-function']"
39,$ \cos x\geq 1-\frac{x^2}{2} $ [duplicate],[duplicate], \cos x\geq 1-\frac{x^2}{2} ,"This question already has answers here : Is $\cos(x) \geq 1 - \frac{x^2}{2}$ for all $x$ in $R$? (4 answers) Closed 3 years ago . Prove that for $x\in\mathbb{R}$ $$ \cos x\geq 1-\frac{x^2}{2}. $$ My try: Consider $g(x)=\cos(x)-1+\frac{x^2}{2}.$ If I differentiate $g(x)$ then we get $g'(0)>0$ so locally we get $g(x)>g(0)=0$ and then we can see that the function is increasing for any $x$ the function is increasing and hence we have $g(x)\geq 0$ for any $x \geq 0$ . But I am getting that if $x<0$ then $g(x) \leq 0.$ So this inequality isn't true in general for all $x \in \Bbb R$ . But, if we use Taylor's theorem with Lagrange's remainder then also I am not sure what will be the point $\zeta\in [-x,0]$ where $\cos(x)=1-\frac{x^2}{2}+\frac{x^4}{4}\cos(\zeta).$","This question already has answers here : Is $\cos(x) \geq 1 - \frac{x^2}{2}$ for all $x$ in $R$? (4 answers) Closed 3 years ago . Prove that for My try: Consider If I differentiate then we get so locally we get and then we can see that the function is increasing for any the function is increasing and hence we have for any . But I am getting that if then So this inequality isn't true in general for all . But, if we use Taylor's theorem with Lagrange's remainder then also I am not sure what will be the point where","x\in\mathbb{R} 
\cos x\geq 1-\frac{x^2}{2}.
 g(x)=\cos(x)-1+\frac{x^2}{2}. g(x) g'(0)>0 g(x)>g(0)=0 x g(x)\geq 0 x \geq 0 x<0 g(x) \leq 0. x \in \Bbb R \zeta\in [-x,0] \cos(x)=1-\frac{x^2}{2}+\frac{x^4}{4}\cos(\zeta).","['real-analysis', 'derivatives', 'trigonometry', 'taylor-expansion', 'maxima-minima']"
40,Find the 66th derivative of this integral function.,Find the 66th derivative of this integral function.,,"$$F\left(x\right)=\int _0^x\cos\left(t^3\right)dt$$ . Writing in the form of an infinite series, we get $$\sum _{n\ge 1}\left(\frac{\left(-1\right)^n}{\left(2n\right)!}\cdot \frac{x^{6n+1}}{6n+1}\right)$$ How can we find $F^{\left(66\right)}\left(0\right)$ ? Here's one solution that comes with this exercise, but which I can't comprehend: $$6n+1=66$$ $$n=\frac{65}{6}\notin \mathbb{N}.$$ Therefore $F^{\left(66\right)}\left(0\right)=0$ .",". Writing in the form of an infinite series, we get How can we find ? Here's one solution that comes with this exercise, but which I can't comprehend: Therefore .",F\left(x\right)=\int _0^x\cos\left(t^3\right)dt \sum _{n\ge 1}\left(\frac{\left(-1\right)^n}{\left(2n\right)!}\cdot \frac{x^{6n+1}}{6n+1}\right) F^{\left(66\right)}\left(0\right) 6n+1=66 n=\frac{65}{6}\notin \mathbb{N}. F^{\left(66\right)}\left(0\right)=0,"['real-analysis', 'derivatives']"
41,Problem with this $\frac{d}{dx}(y^3)$,Problem with this,\frac{d}{dx}(y^3),"How do you differentiate this equation with respect to $x$ ? $$x^2=xy^3+2$$ $$\frac{d}{dx}(x^2)=\frac{d}{dx}(xy^3)+\frac{d}{dx}(2)$$ $$2x=x\frac{d}{dx}(y^3)+y^3\frac{d}{dx}(x)+0$$ $$2x=x\frac{d}{dx}(y^3)+y^3$$ Here is the problem I am facing with, $$\frac{d}{dx}(y^3)?$$ this $\frac{d}{dx}(x^3)=3x^2$ it is understandable","How do you differentiate this equation with respect to ? Here is the problem I am facing with, this it is understandable",x x^2=xy^3+2 \frac{d}{dx}(x^2)=\frac{d}{dx}(xy^3)+\frac{d}{dx}(2) 2x=x\frac{d}{dx}(y^3)+y^3\frac{d}{dx}(x)+0 2x=x\frac{d}{dx}(y^3)+y^3 \frac{d}{dx}(y^3)? \frac{d}{dx}(x^3)=3x^2,[]
42,If $f$ is differentiable and $\forall x \in \mathbb R $ and $\forall h >0 ( \mid {f(x+h)-f(x-h)}\mid <h^2 )$ then $f$ is constant?,If  is differentiable and  and  then  is constant?,f \forall x \in \mathbb R  \forall h >0 ( \mid {f(x+h)-f(x-h)}\mid <h^2 ) f,"If $f$ is differentiable ,and $ \forall x \in \mathbb R  $ and $\forall h >0 $ hold $\mid {f(x+h)-f(x-h)}\mid <h^2$.Prove that $f$ is constant.I tried to use Lagrange theorem.","If $f$ is differentiable ,and $ \forall x \in \mathbb R  $ and $\forall h >0 $ hold $\mid {f(x+h)-f(x-h)}\mid <h^2$.Prove that $f$ is constant.I tried to use Lagrange theorem.",,['real-analysis']
43,What is the relation between $\varepsilon$-$\delta$ and $dy$-$dx$ notations?,What is the relation between - and - notations?,\varepsilon \delta dy dx,"For what I know, $dy$-$dx$ aren't real numbers, exist as convenient notations to capture our intuitions about infinitesimal increments, while $\varepsilon$-$\delta$ are real distances, saying that $f$ can be as close as we want to $L$ if $x$ is sufficiently close to $c$. The latter has a formal statement: $$ \lim_{x \to c} f(x) = L  \iff  (\forall \varepsilon > 0)(\exists \ \delta > 0) (\forall x \in D)(0 < |x - c | < \delta \ \Rightarrow \ |f(x) - L| < \varepsilon)$$ While the former denote for $\Delta f$ and $\Delta x$ respectively when we arrive at $\Delta f=A\Delta x+o(\Delta x)$, which comes from the definition of derivative $f'=\lim_{\Delta x\to0}\frac{\Delta f}{\Delta x}$, and a chain of denotations $\varepsilon(\Delta x)=\frac{\Delta f}{\Delta x}-f'$, $o(\Delta x)=\varepsilon(\Delta x)\Delta x$ and $A=f'(x)$, with a note that $\lim_{\Delta x\to0}\varepsilon(\Delta x)=0$. As I understand here $\varepsilon(\Delta x)$ is simply a random unimportant convenient notation and has nothing relates to the infinitesimal above. Yet looking at the graph on Wikipedia: (ε, δ)-definition of limit , I can't help but thinking that they are just one thing: So what is the difference, and more generally, the relation between these two notations? Can I use $\varepsilon$-$\delta$ in a integral? And if $df=A\Delta x,dx=\Delta x$, then they should be real, right?","For what I know, $dy$-$dx$ aren't real numbers, exist as convenient notations to capture our intuitions about infinitesimal increments, while $\varepsilon$-$\delta$ are real distances, saying that $f$ can be as close as we want to $L$ if $x$ is sufficiently close to $c$. The latter has a formal statement: $$ \lim_{x \to c} f(x) = L  \iff  (\forall \varepsilon > 0)(\exists \ \delta > 0) (\forall x \in D)(0 < |x - c | < \delta \ \Rightarrow \ |f(x) - L| < \varepsilon)$$ While the former denote for $\Delta f$ and $\Delta x$ respectively when we arrive at $\Delta f=A\Delta x+o(\Delta x)$, which comes from the definition of derivative $f'=\lim_{\Delta x\to0}\frac{\Delta f}{\Delta x}$, and a chain of denotations $\varepsilon(\Delta x)=\frac{\Delta f}{\Delta x}-f'$, $o(\Delta x)=\varepsilon(\Delta x)\Delta x$ and $A=f'(x)$, with a note that $\lim_{\Delta x\to0}\varepsilon(\Delta x)=0$. As I understand here $\varepsilon(\Delta x)$ is simply a random unimportant convenient notation and has nothing relates to the infinitesimal above. Yet looking at the graph on Wikipedia: (ε, δ)-definition of limit , I can't help but thinking that they are just one thing: So what is the difference, and more generally, the relation between these two notations? Can I use $\varepsilon$-$\delta$ in a integral? And if $df=A\Delta x,dx=\Delta x$, then they should be real, right?",,"['calculus', 'derivatives', 'differential', 'nonstandard-analysis', 'infinitesimals']"
44,How to calculate $ \frac {\mathrm d}{\mathrm dx} {x!} $?,How to calculate ?, \frac {\mathrm d}{\mathrm dx} {x!} ,"I was practising to differentiate various standard functions of $x$, such as $\sin x, \ln x, e^x$, etc. , when I got stuck on $\dfrac {\mathrm d}{\mathrm dx} x!$ . I tried several approachs such as differentiating $x(x-1)(x-2)...1$  .  I tried using $x!=x(x-1)!$  , but for that obviously I had to know the derivative of factorial function, which is essentially I am trying to find. Can anyone help me out?","I was practising to differentiate various standard functions of $x$, such as $\sin x, \ln x, e^x$, etc. , when I got stuck on $\dfrac {\mathrm d}{\mathrm dx} x!$ . I tried several approachs such as differentiating $x(x-1)(x-2)...1$  .  I tried using $x!=x(x-1)!$  , but for that obviously I had to know the derivative of factorial function, which is essentially I am trying to find. Can anyone help me out?",,['calculus']
45,"Use the chain rule to evaluate $\frac{\mathrm{d}}{\mathrm{d}x}\displaystyle\int_{x^2-1}^{\sin(x)} \cos(t) \, \mathrm{d}t $",Use the chain rule to evaluate,"\frac{\mathrm{d}}{\mathrm{d}x}\displaystyle\int_{x^2-1}^{\sin(x)} \cos(t) \, \mathrm{d}t ","Doesn't the derivative of that integral just equal $\cos(x)$? What does it mean to use the Chain Rule? I know for sure it has nothing to do with $u$-substitution. Any help would be appreciated, thanks.","Doesn't the derivative of that integral just equal $\cos(x)$? What does it mean to use the Chain Rule? I know for sure it has nothing to do with $u$-substitution. Any help would be appreciated, thanks.",,"['calculus', 'integration', 'derivatives', 'chain-rule']"
46,Derivative getting different result,Derivative getting different result,,"Studying for a midterm, and one of the problems is: $$\frac{x^3+7}{x}$$ and we have to find the derivative. My professor is getting: $$2x-\frac{7}{x^2}$$ But I got $$3x-\frac{x^3+7}{x^2}$$ I even tried using an online calculator to verify my results, and I indeed it got the same thing. Can someone tell me what I am doing wrong here? Or am I right?","Studying for a midterm, and one of the problems is: $$\frac{x^3+7}{x}$$ and we have to find the derivative. My professor is getting: $$2x-\frac{7}{x^2}$$ But I got $$3x-\frac{x^3+7}{x^2}$$ I even tried using an online calculator to verify my results, and I indeed it got the same thing. Can someone tell me what I am doing wrong here? Or am I right?",,['derivatives']
47,"A function not differentiable exactly two points of $[0,1]$. construction of such a function is possible?",A function not differentiable exactly two points of . construction of such a function is possible?,"[0,1]","Can a continuous function on $[0,1]$ be constructed which is not differentiable exactly at two points on $[0,1]$ ?","Can a continuous function on $[0,1]$ be constructed which is not differentiable exactly at two points on $[0,1]$ ?",,"['real-analysis', 'derivatives', 'examples-counterexamples']"
48,Derivative of $y=x^{\ln x}$?,Derivative of ?,y=x^{\ln x},"I only know how to do one step: $$ \ln\left(\,y\,\right) = \ln\left(\, x^{\ln\left(\, x\,\right)}\,\right) $$ how do i do the derivative of $\ln\left(\, x^{\ln\left(\, x\,\right)}\,\right)$ ?. I know the answer to that is $\ln\left(\,x\,\right)\ln\left(\,x\,\right)$, but how does the $x$ go away ?.","I only know how to do one step: $$ \ln\left(\,y\,\right) = \ln\left(\, x^{\ln\left(\, x\,\right)}\,\right) $$ how do i do the derivative of $\ln\left(\, x^{\ln\left(\, x\,\right)}\,\right)$ ?. I know the answer to that is $\ln\left(\,x\,\right)\ln\left(\,x\,\right)$, but how does the $x$ go away ?.",,"['derivatives', 'implicit-differentiation']"
49,Mean Value Theorem Motivation,Mean Value Theorem Motivation,,"I am currently practicing presenting mathematics to various audiences and am considering the example of the mean value theorem. I was wondering how would I be able to motivate this theorem to a mathematician, to a physicist and to someone who does not have any experience with theoretical mathematics.","I am currently practicing presenting mathematics to various audiences and am considering the example of the mean value theorem. I was wondering how would I be able to motivate this theorem to a mathematician, to a physicist and to someone who does not have any experience with theoretical mathematics.",,"['derivatives', 'intuition', 'education', 'motivation']"
50,Derivative of the $\sin(x)$ when $x$ is measured in degrees,Derivative of the  when  is measured in degrees,\sin(x) x,"So a classic thing to derive in calculus textbooks is something like a statement as follows Is $\frac{d}{dx}\sin(u)$ the same as the derivative of $\frac{d}{dx}\sin(x)$ where $u$ is an angle measured in degrees and $x$ is measured in radians? and of course the answer is no because of the chain rule. Except usually this is ambiguously worded as ""Is the derivative of $\sin(u)$, where $u$ is measured in degrees, equal to the derivative of $\sin(x)$ where $x$ is the same angle but measured in in radians?"" Then the texts go on to say something like ""No and this why we don't work in degrees and instead chose to work in radians, to avoid all the messy constants that come out of taking derivatives."" Am I crazy by thinking this is an odd thing to say that will end up confusing students. If your independent variable was an angle measured in degrees, you are probably more interested in it's derivative with respect to degrees not radians, which would infact be equal at the corresponding degrees and radians of an angle. Is my understanding wrong here. Is what the books say fine? I think at minimum they should at least be clear that we are taking the derivative with respect to radians, no? Note this is not a duplicate of Derivative of the sine function when the argument is measured in degrees Even though it is highly related.","So a classic thing to derive in calculus textbooks is something like a statement as follows Is $\frac{d}{dx}\sin(u)$ the same as the derivative of $\frac{d}{dx}\sin(x)$ where $u$ is an angle measured in degrees and $x$ is measured in radians? and of course the answer is no because of the chain rule. Except usually this is ambiguously worded as ""Is the derivative of $\sin(u)$, where $u$ is measured in degrees, equal to the derivative of $\sin(x)$ where $x$ is the same angle but measured in in radians?"" Then the texts go on to say something like ""No and this why we don't work in degrees and instead chose to work in radians, to avoid all the messy constants that come out of taking derivatives."" Am I crazy by thinking this is an odd thing to say that will end up confusing students. If your independent variable was an angle measured in degrees, you are probably more interested in it's derivative with respect to degrees not radians, which would infact be equal at the corresponding degrees and radians of an angle. Is my understanding wrong here. Is what the books say fine? I think at minimum they should at least be clear that we are taking the derivative with respect to radians, no? Note this is not a duplicate of Derivative of the sine function when the argument is measured in degrees Even though it is highly related.",,"['calculus', 'trigonometry', 'derivatives']"
51,How to use the power series of $e^x$ to find the derivative of $e^x$?,How to use the power series of  to find the derivative of ?,e^x e^x,"I am currently reading Roger Penrose's The Road to Reality and in the book, the author poses various problems with three different levels of difficultly easy, hard and really hard , according to the author this is easy. The problem I am looking at is as follows: Using the power series of $e^x$ show that $de^x = e^x \, dx$ I have no idea as to how to tackle this problem. If someone could provide some key points to solving the problem that would be great. Please do not provide the full steps, just key ideas or things to note. Thanks! EDIT: I believe I understand this now because when you take the derivative of a power series you can do it term by term. The power series for $e^x$ is: $$e^x = \sum_{i=0}^\infty \frac{x^n}{n!}$$ But more expanded it looks like this: $$e^x =  1 + \frac{x}{1!} + \frac{x^2}{2!} + \frac{x^3}{3!} +\ldots $$ If the derivative of each term then I get: $0 + 1 + x + \frac{x^2}{2} + \ldots$ So in essence, I'm coming back to the original series. Therefore, the derivatives are the same.","I am currently reading Roger Penrose's The Road to Reality and in the book, the author poses various problems with three different levels of difficultly easy, hard and really hard , according to the author this is easy. The problem I am looking at is as follows: Using the power series of show that I have no idea as to how to tackle this problem. If someone could provide some key points to solving the problem that would be great. Please do not provide the full steps, just key ideas or things to note. Thanks! EDIT: I believe I understand this now because when you take the derivative of a power series you can do it term by term. The power series for is: But more expanded it looks like this: If the derivative of each term then I get: So in essence, I'm coming back to the original series. Therefore, the derivatives are the same.","e^x de^x = e^x \, dx e^x e^x = \sum_{i=0}^\infty \frac{x^n}{n!} e^x =  1 + \frac{x}{1!} + \frac{x^2}{2!} + \frac{x^3}{3!} +\ldots  0 + 1 + x + \frac{x^2}{2} + \ldots","['calculus', 'derivatives', 'power-series', 'exponential-function']"
52,How to prove that r is a double root if and only if it is a root of a polynomial and of its derivative.,How to prove that r is a double root if and only if it is a root of a polynomial and of its derivative.,,I don't know how to start the question. The title is self explanatory. How to approach and make a formal proof?,I don't know how to start the question. The title is self explanatory. How to approach and make a formal proof?,,"['derivatives', 'roots']"
53,"If $x>0,y>0$ and $4xy=2^{x+y}$ then find the minimum and maximum values of $x+y$.",If  and  then find the minimum and maximum values of .,"x>0,y>0 4xy=2^{x+y} x+y","If $x>0,y>0$ and $4xy=2^{x+y}$ then find the minimum and maximum values of $x+y$ . My Attempt I tried by putting $t=x+y$ $\Rightarrow 4x(t-x)=2^t$ . On differentiation we have $4t-8x=\frac{dt}{dx}(2^tln2-4x)$ . For maximum/minimum put $\frac{dt}{dx}=0$ to obtain $t=2x$ $\Rightarrow x+y=2x$ and thus $y=x$ . Putting in given equation one obtains $4x^2=2^{2x}$ . The obvious solution here is $x=1,2$ . So the value of corresponding $y$ will be $y=1,2$ . So, the extreme values of $x+y$ can be $2$ and $4$ . Is above correct or am I missing something here. Can we solve this using $AM\geq GM$ inequality.","If and then find the minimum and maximum values of . My Attempt I tried by putting . On differentiation we have . For maximum/minimum put to obtain and thus . Putting in given equation one obtains . The obvious solution here is . So the value of corresponding will be . So, the extreme values of can be and . Is above correct or am I missing something here. Can we solve this using inequality.","x>0,y>0 4xy=2^{x+y} x+y t=x+y \Rightarrow 4x(t-x)=2^t 4t-8x=\frac{dt}{dx}(2^tln2-4x) \frac{dt}{dx}=0 t=2x \Rightarrow x+y=2x y=x 4x^2=2^{2x} x=1,2 y y=1,2 x+y 2 4 AM\geq GM","['calculus', 'derivatives', 'inequality', 'maxima-minima', 'a.m.-g.m.-inequality']"
54,Showing a bound of the second derivative using remainder in integral form,Showing a bound of the second derivative using remainder in integral form,,"Let $a,b \in (0,\infty)$ Let $f$ be twice continuously differentiable , $f(0)=f'(0)=f'(a)=0, f(a)=b.$ Show that there exists $c \in (0,a)$ , such that $$\vert f''(c) \vert \geq \frac{4b}{a^2}$$ I have to use the Taylor theorem with integral remainder to prove this.","Let Let be twice continuously differentiable , Show that there exists , such that I have to use the Taylor theorem with integral remainder to prove this.","a,b \in (0,\infty) f f(0)=f'(0)=f'(a)=0, f(a)=b. c \in (0,a) \vert f''(c) \vert \geq \frac{4b}{a^2}","['real-analysis', 'integration', 'derivatives', 'taylor-expansion']"
55,Analytic Properties of $f(x) = x^x$,Analytic Properties of,f(x) = x^x,"The function $f(x) = x^x, x > 0$ can be plotted on graphing software and inspected to see a local minimum around .367. The function is convex, decreasing from 0 to its minimum, and increasing thereafter. The derivative of the function can be found by implicit differentiation to be $f'(x) = x^x(\ln(x)+1)$ . Can the exact value of the local minimum be found? Can someone explain intuitively why the function first decreases and then increases? Is there anything interesting about the class of functions $\{ \, f(x) \, | \, f'(x) = f(x) \cdot g(x) \, \}$ Edit: I forgot, I'll be subject to a firing squad if I don't explain what I have tried! Setting the derivative equal to 0 doesn't do much for me. If this can be solved exactly without optimization algorithms, I suspect something really clever will need to happen. I tried thinking about what is happing for different types of inputs (irrational $x$ , rational $x$ , natural $x$ ). Still didn't get anywhere. Nothing to try really, does this class of functions come up anywhere in math?","The function can be plotted on graphing software and inspected to see a local minimum around .367. The function is convex, decreasing from 0 to its minimum, and increasing thereafter. The derivative of the function can be found by implicit differentiation to be . Can the exact value of the local minimum be found? Can someone explain intuitively why the function first decreases and then increases? Is there anything interesting about the class of functions Edit: I forgot, I'll be subject to a firing squad if I don't explain what I have tried! Setting the derivative equal to 0 doesn't do much for me. If this can be solved exactly without optimization algorithms, I suspect something really clever will need to happen. I tried thinking about what is happing for different types of inputs (irrational , rational , natural ). Still didn't get anywhere. Nothing to try really, does this class of functions come up anywhere in math?","f(x) = x^x, x > 0 f'(x) = x^x(\ln(x)+1) \{ \, f(x) \, | \, f'(x) = f(x) \cdot g(x) \, \} x x x","['calculus', 'derivatives', 'optimization']"
56,Find the $n^{th}$ derivative of $y=\dfrac {x^n}{x-1}$.,Find the  derivative of .,n^{th} y=\dfrac {x^n}{x-1},"Find the $n^{th}$ derivative of $y=\dfrac {x^n}{x-1}$ . My Attempt: $$y=\dfrac {x^n}{x-1}$$ $$y=x^n\cdot(x-1)^{-1}$$ Differentiating both sides, $$y_{1}=x^n\cdot(-1)\cdot(x-1)^{-2}+(x-1)^{-1}\cdot n\cdot x^{(n-1)}$$ $$y_{1}=x^n\cdot(-1)\cdot(x-1)^{-2}+(x-1)^{-1}\cdot n \cdot\dfrac {x^n}{x}$$","Find the derivative of . My Attempt: Differentiating both sides,",n^{th} y=\dfrac {x^n}{x-1} y=\dfrac {x^n}{x-1} y=x^n\cdot(x-1)^{-1} y_{1}=x^n\cdot(-1)\cdot(x-1)^{-2}+(x-1)^{-1}\cdot n\cdot x^{(n-1)} y_{1}=x^n\cdot(-1)\cdot(x-1)^{-2}+(x-1)^{-1}\cdot n \cdot\dfrac {x^n}{x},"['calculus', 'derivatives']"
57,Prove $f$ is decreasing?,Prove  is decreasing?,f,"Let $f:\mathbb{R}\to\mathbb{R}$ be a differentiable function on $[a,+\infty)$ , such that $f^\prime$ is increasing and $\lim_{x\to\infty}f(x)=0$ I have two questions as follows (1) how do you prove that $f$ is decreasing on $[a,+\infty)$ (2) Can the condition ""the sequence $f(n)$ convergent to zero"" work instead of $\lim_{x\to\infty}f(x)=0$ ? I tried to prove this by definition of derivative as follows Since $f^\prime(a)\leq f^\prime(x)$ when $a\leq x_0\;;x_0\in[a,+\infty)$ then we have $$\lim_{x\to a}\frac{f(x)-f(a)}{x-a}\leq\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}$$ but this way can not work.","Let be a differentiable function on , such that is increasing and I have two questions as follows (1) how do you prove that is decreasing on (2) Can the condition ""the sequence convergent to zero"" work instead of ? I tried to prove this by definition of derivative as follows Since when then we have but this way can not work.","f:\mathbb{R}\to\mathbb{R} [a,+\infty) f^\prime \lim_{x\to\infty}f(x)=0 f [a,+\infty) f(n) \lim_{x\to\infty}f(x)=0 f^\prime(a)\leq f^\prime(x) a\leq x_0\;;x_0\in[a,+\infty) \lim_{x\to a}\frac{f(x)-f(a)}{x-a}\leq\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}","['calculus', 'derivatives']"
58,Prove the function $f(x)= \begin{cases}x^2 & x\in\mathbb{Q}\\-x^2 & else\end{cases}$ is differentiable at $x=0$,Prove the function  is differentiable at,f(x)= \begin{cases}x^2 & x\in\mathbb{Q}\\-x^2 & else\end{cases} x=0,"Prove the function $f:\mathbb{R}\rightarrow\mathbb{R}$ defined by $f(x)= \begin{cases}x^2 & x\in\mathbb{Q}\\-x^2 & else\end{cases}$ is differentiable at $x=0$ and that $f'(0)=0$ . Hey everyone, this is a simple calculus problem I've encountered, but I don't really know how to prove this using the definition $lim_{x\to 0} \frac{f(x)-f(0)}{x-0}=f'(x)$ because of the cases. It is trivial that if $x\in\mathbb{Q}$ then $f'(x)=2x$ , else $f'(x)=-2x \Rightarrow$ both limits of these functions are zero when $x$ is approaching zero, but how do I formally prove the function is differentiable at $0$ ? Thanks :)","Prove the function defined by is differentiable at and that . Hey everyone, this is a simple calculus problem I've encountered, but I don't really know how to prove this using the definition because of the cases. It is trivial that if then , else both limits of these functions are zero when is approaching zero, but how do I formally prove the function is differentiable at ? Thanks :)",f:\mathbb{R}\rightarrow\mathbb{R} f(x)= \begin{cases}x^2 & x\in\mathbb{Q}\\-x^2 & else\end{cases} x=0 f'(0)=0 lim_{x\to 0} \frac{f(x)-f(0)}{x-0}=f'(x) x\in\mathbb{Q} f'(x)=2x f'(x)=-2x \Rightarrow x 0,"['calculus', 'real-analysis', 'derivatives']"
59,How to show that $\frac{dy}{dx}=\frac{dy}{d(x-c)}$?,How to show that ?,\frac{dy}{dx}=\frac{dy}{d(x-c)},"It seems intuitive to me that $\frac{dy}{dx}=\frac{dy}{d(x-c)}$ (the derivative of $y$ with respect to $(x-c)$, where $c$ is a constant), since subtracting a constant from $x$ doesn't change the slope of $y$, but how can I show it? Thanks in advance.","It seems intuitive to me that $\frac{dy}{dx}=\frac{dy}{d(x-c)}$ (the derivative of $y$ with respect to $(x-c)$, where $c$ is a constant), since subtracting a constant from $x$ doesn't change the slope of $y$, but how can I show it? Thanks in advance.",,"['calculus', 'derivatives']"
60,Proving Leibniz theorem using induction [duplicate],Proving Leibniz theorem using induction [duplicate],,This question already has answers here : Prove that $(fg)^{(n)} = \sum_{k=0}^n \binom{n}{k}f^{(k)}(x)g^{(n-k)}(x)$ (3 answers) Closed 6 years ago . Let $f$ and $g$ be $n$ times differentiable functions then prove that $$\frac {d^n}{dx^n}(fg)=\sum _{i=0}^n \binom{n}{ i} f^{(i)}g^{(n-i)} $$ where $f^{(k)} $ is $k$-th  derivative with respect to $x $. Now I started with Mathematical Induction. I know its true for $n=1$ so skipped it. Let it be true for $m<n $ thus $$\frac {d^m}{dx^m}(fg)=\sum_{i=0}^{m} \binom {m}{i}f^{(m)}g^{(m-i)} =s .$$ We need to prove this for $m+1$ . Note that $m+1 <n $ is also true. So we see that  $$\frac {d^{m+1}}{dx^{m+1}}(fg)=\frac {d}{dx}(s).$$ But now problem here is that I don't know how to differentiate this whole $s$ as we cant use Leibniz rule to prove Leibniz rule.,This question already has answers here : Prove that $(fg)^{(n)} = \sum_{k=0}^n \binom{n}{k}f^{(k)}(x)g^{(n-k)}(x)$ (3 answers) Closed 6 years ago . Let $f$ and $g$ be $n$ times differentiable functions then prove that $$\frac {d^n}{dx^n}(fg)=\sum _{i=0}^n \binom{n}{ i} f^{(i)}g^{(n-i)} $$ where $f^{(k)} $ is $k$-th  derivative with respect to $x $. Now I started with Mathematical Induction. I know its true for $n=1$ so skipped it. Let it be true for $m<n $ thus $$\frac {d^m}{dx^m}(fg)=\sum_{i=0}^{m} \binom {m}{i}f^{(m)}g^{(m-i)} =s .$$ We need to prove this for $m+1$ . Note that $m+1 <n $ is also true. So we see that  $$\frac {d^{m+1}}{dx^{m+1}}(fg)=\frac {d}{dx}(s).$$ But now problem here is that I don't know how to differentiate this whole $s$ as we cant use Leibniz rule to prove Leibniz rule.,,"['calculus', 'derivatives']"
61,How to show $\frac{2-x}{2+x} \le e^{-x}$ for $x\ge0$?,How to show  for ?,\frac{2-x}{2+x} \le e^{-x} x\ge0,Let $x\geq0$ . Show that: $$\frac{2-x}{2+x} \le e^{-x}.$$ I have some troubles to prove it. Would you give me any hint? [Edit] Adding a graphical illustration to answer a comment on the interest of that inequality and to explain why one answer assumes $0 \leq x \leq 2$ since for $x\geq 2$ it's trivial:,Let . Show that: I have some troubles to prove it. Would you give me any hint? [Edit] Adding a graphical illustration to answer a comment on the interest of that inequality and to explain why one answer assumes since for it's trivial:,x\geq0 \frac{2-x}{2+x} \le e^{-x}. 0 \leq x \leq 2 x\geq 2,"['calculus', 'derivatives', 'inequality', 'exponential-function', 'geometric-progressions']"
62,"Obvious but unprovable: If $f'$ is the zero function on $\mathbb Q$, then $f$ is constant [duplicate]","Obvious but unprovable: If  is the zero function on , then  is constant [duplicate]",f' \mathbb Q f,"This question already has an answer here : Is a function whose derivative vanishes at rationals constant? [duplicate] (1 answer) Closed 7 years ago . Let $f:\mathbb Q\to\mathbb R$ be a uniformly continuous function and assume that $f'(x)=0$ for all $x\in\mathbb Q$. That $f$ is constant is obvious...and, as far as I can tell, unprovable. Please tell me that I'm wrong!","This question already has an answer here : Is a function whose derivative vanishes at rationals constant? [duplicate] (1 answer) Closed 7 years ago . Let $f:\mathbb Q\to\mathbb R$ be a uniformly continuous function and assume that $f'(x)=0$ for all $x\in\mathbb Q$. That $f$ is constant is obvious...and, as far as I can tell, unprovable. Please tell me that I'm wrong!",,"['real-analysis', 'derivatives']"
63,Calculating a derivative of (2015)-th order of function $f(x)$,Calculating a derivative of (2015)-th order of function,f(x),"So I have $\displaystyle{\,\mathrm{f}\left(\, x\, \right) = \frac{x - 1}{\,\sqrt{\, 3 - x\,}\,}}$ And I want to calculate $\,\mathrm{f}^{\mathrm{\left(\, 2015\, \right)}} \,\left(\, 1\,\right)$ So I got the first and second derivative: $$\mathrm{f}'(x)=\frac{-x+5}{2[(-x+3)^{\frac{3}{2}}]}$$ $$ \mathrm{f}''(x)= \frac{-2(-x+3)^{\frac{3}{2}} + (-x+5)\sqrt{-x+3}}{4(-x+3)^3}$$ Perhaps I should look at some of the next derivatives for pattern? or is that not going to help, there is also a formula I know for getting a high order derivative, but it's not going to help if I don't calculate all 2014 of them as well... So any help with this would be appreciated.","So I have $\displaystyle{\,\mathrm{f}\left(\, x\, \right) = \frac{x - 1}{\,\sqrt{\, 3 - x\,}\,}}$ And I want to calculate $\,\mathrm{f}^{\mathrm{\left(\, 2015\, \right)}} \,\left(\, 1\,\right)$ So I got the first and second derivative: $$\mathrm{f}'(x)=\frac{-x+5}{2[(-x+3)^{\frac{3}{2}}]}$$ $$ \mathrm{f}''(x)= \frac{-2(-x+3)^{\frac{3}{2}} + (-x+5)\sqrt{-x+3}}{4(-x+3)^3}$$ Perhaps I should look at some of the next derivatives for pattern? or is that not going to help, there is also a formula I know for getting a high order derivative, but it's not going to help if I don't calculate all 2014 of them as well... So any help with this would be appreciated.",,"['calculus', 'derivatives']"
64,minimum point of $x^2e^{-x}$,minimum point of,x^2e^{-x},I have looking for the minimum point of $$f(x)=x^2e^{-x}$$ I differentiated once and got $f'(x)=-e^{-x}(-2+x)x$ so $x=2$ and $x=0$ can be min/max points. I have differentiated again and got $f''(x)=e^{-x}(2-4x+x^2)$ then I plugged in $x=2$ and got $\frac{-2}{e^2}$ so it is maximum. But in the graph it does not seems like a maximum point. moreover How do I prove that the function is not bounded from above?,I have looking for the minimum point of $$f(x)=x^2e^{-x}$$ I differentiated once and got $f'(x)=-e^{-x}(-2+x)x$ so $x=2$ and $x=0$ can be min/max points. I have differentiated again and got $f''(x)=e^{-x}(2-4x+x^2)$ then I plugged in $x=2$ and got $\frac{-2}{e^2}$ so it is maximum. But in the graph it does not seems like a maximum point. moreover How do I prove that the function is not bounded from above?,,"['calculus', 'derivatives']"
65,How do you find the derivative of the integral $\sin(\ln x)$,How do you find the derivative of the integral,\sin(\ln x),"$$\frac{d}{dx} \;\left[ \int_{a}^{x^2}\sin(\ln(z))\;dz\right]$$ I'm not sure if I'd have to do the chain rule on the natural logarithm and them $x^2$, or if there is no chain rule at all. Any help would be appreciated, thank you!","$$\frac{d}{dx} \;\left[ \int_{a}^{x^2}\sin(\ln(z))\;dz\right]$$ I'm not sure if I'd have to do the chain rule on the natural logarithm and them $x^2$, or if there is no chain rule at all. Any help would be appreciated, thank you!",,"['integration', 'derivatives', 'definite-integrals', 'logarithms']"
66,Differentiate $y^2-2xy+3y=7x$ w.r.t. $x$. Hence show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).$,Differentiate  w.r.t. . Hence show that,y^2-2xy+3y=7x x \frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).,"Differentiate $y^2-2xy+3y=7x$ w.r.t. $x$. Hence show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).$ I differentiated $y^2-2xy+3y=7x$ w.r.t. $x$ and got: $$\frac{dy}{dx}=\frac{7+2y}{2y-2x+3}$$ Differentiating one more time, I get: $$\frac{d^2y}{dx^2}=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)^2}$$ Multiplying by $(2y-2x+3)$ I get: $$\frac{d^2y}{dx^2}(2y-2x+3)=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ Now if I understand correctly the question wants me to show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx})$ So from what I already got, I guess I need to show that $$\frac{dy}{dx}(4-2\frac{dy}{dx})=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ But I don't know how to do this and I'm not sure if I've been following the question correctly. I reckon I might be over-complicating things too. Grateful for any hints/guidance.","Differentiate $y^2-2xy+3y=7x$ w.r.t. $x$. Hence show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx}).$ I differentiated $y^2-2xy+3y=7x$ w.r.t. $x$ and got: $$\frac{dy}{dx}=\frac{7+2y}{2y-2x+3}$$ Differentiating one more time, I get: $$\frac{d^2y}{dx^2}=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)^2}$$ Multiplying by $(2y-2x+3)$ I get: $$\frac{d^2y}{dx^2}(2y-2x+3)=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ Now if I understand correctly the question wants me to show that $\frac{d^2y}{dx^2}(2y-2x+3)=\frac{dy}{dx}(4-2\frac{dy}{dx})$ So from what I already got, I guess I need to show that $$\frac{dy}{dx}(4-2\frac{dy}{dx})=\frac{-4(x+2)\frac{dy}{dx}+4y+14}{(2y-2x+3)}$$ But I don't know how to do this and I'm not sure if I've been following the question correctly. I reckon I might be over-complicating things too. Grateful for any hints/guidance.",,"['calculus', 'derivatives', 'implicit-differentiation']"
67,Differentiate the Function $f(x)= \sqrt{x} \ln x$,Differentiate the Function,f(x)= \sqrt{x} \ln x,Differentiate the Function $f(x)= \sqrt{x} \ln x$,Differentiate the Function $f(x)= \sqrt{x} \ln x$,,"['calculus', 'derivatives']"
68,Why the derivative of $n^{1/n}$ is $n^{1/n} \left( \frac{1}{n^2} - \frac{\log(n)}{n^2}\right)$,Why the derivative of  is,n^{1/n} n^{1/n} \left( \frac{1}{n^2} - \frac{\log(n)}{n^2}\right),"Why the derivative of $n^{1/n} = \sqrt[n]{n}$ is $n^{1/n} \left( \frac{1}{n^2} - \frac{\log(n)}{n^2}\right)$ (according to Maxima and other tools online)? I have tried to applied the chain rule, but it comes something completely different: $$\frac{1}{n} n^{\frac{1}{n} - 1} \cdot 1 = \frac{1}{n} n^\frac{1}{n}n^{-1} = \frac{1}{n^2} n^\frac{1}{n} = \frac{\sqrt[n]{n}}{n^2}$$ Sincerely, I am not seeing where that $\log$ and the rest of the stuff comes from. I have a more difficult problem that is similar and whose solution contains a $\log$ somewhere, but I am not seeing where it comes from.","Why the derivative of $n^{1/n} = \sqrt[n]{n}$ is $n^{1/n} \left( \frac{1}{n^2} - \frac{\log(n)}{n^2}\right)$ (according to Maxima and other tools online)? I have tried to applied the chain rule, but it comes something completely different: $$\frac{1}{n} n^{\frac{1}{n} - 1} \cdot 1 = \frac{1}{n} n^\frac{1}{n}n^{-1} = \frac{1}{n^2} n^\frac{1}{n} = \frac{\sqrt[n]{n}}{n^2}$$ Sincerely, I am not seeing where that $\log$ and the rest of the stuff comes from. I have a more difficult problem that is similar and whose solution contains a $\log$ somewhere, but I am not seeing where it comes from.",,['calculus']
69,”lesser known” rules to calculate the derivative,”lesser known” rules to calculate the derivative,,"I was reading through the online help of WolframAlpha ( link ) and found this statement: Wolfram|Alpha calls Mathematica's $D$ function, which uses a table of   identities much larger than one would find in a standard calculus   textbook. It uses ”well known” rules such as the linearity of the   derivative, product rule, power rule, chain rule, so on. Additionally, $D$   uses ”lesser known” rules to calculate the derivative of a wide array   of special functions. What could these ""lesser known"" rules be?","I was reading through the online help of WolframAlpha ( link ) and found this statement: Wolfram|Alpha calls Mathematica's $D$ function, which uses a table of   identities much larger than one would find in a standard calculus   textbook. It uses ”well known” rules such as the linearity of the   derivative, product rule, power rule, chain rule, so on. Additionally, $D$   uses ”lesser known” rules to calculate the derivative of a wide array   of special functions. What could these ""lesser known"" rules be?",,"['derivatives', 'computer-algebra-systems']"
70,Finding the max of $x^2/(2 + x^2)$,Finding the max of,x^2/(2 + x^2),"I tried to find the maximum value of the following function using the first derivative and equate it to zero : The function :  $y=x^2 /(2+x^2)$ The first derivative: $4x/(x^2 +2)^2 =0 \implies x=0$ which gives an answer $y = 0$. But this is not true. If we make $x = 1$, we get $y= 1/3$, which is bigger than 0! Is there something I misunderstand","I tried to find the maximum value of the following function using the first derivative and equate it to zero : The function :  $y=x^2 /(2+x^2)$ The first derivative: $4x/(x^2 +2)^2 =0 \implies x=0$ which gives an answer $y = 0$. But this is not true. If we make $x = 1$, we get $y= 1/3$, which is bigger than 0! Is there something I misunderstand",,"['calculus', 'derivatives', 'optimization']"
71,Prove that $x+\sin x$ is strictly increasing,Prove that  is strictly increasing,x+\sin x,"I have a function $f(x)=x+\sin x$ and I want to prove that it is strictly increasing. A natural thing to do would be examine $f(x+\epsilon)$ for $\epsilon > 0$, and it is equal to $(x+\epsilon)+\sin(x+\epsilon)=x+\epsilon+\sin x\cos \epsilon + \sin \epsilon \cos x$. Now all I need to prove is that $x+\epsilon+\sin x\cos \epsilon + \sin \epsilon \cos x - \sin x - x$ is always greater than $0$ but it's a dead end for me as I don't know how to proceed. Any hints?","I have a function $f(x)=x+\sin x$ and I want to prove that it is strictly increasing. A natural thing to do would be examine $f(x+\epsilon)$ for $\epsilon > 0$, and it is equal to $(x+\epsilon)+\sin(x+\epsilon)=x+\epsilon+\sin x\cos \epsilon + \sin \epsilon \cos x$. Now all I need to prove is that $x+\epsilon+\sin x\cos \epsilon + \sin \epsilon \cos x - \sin x - x$ is always greater than $0$ but it's a dead end for me as I don't know how to proceed. Any hints?",,"['calculus', 'derivatives']"
72,Derivative of an inverse,Derivative of an inverse,,"Let $f(x)=2x^3+7x−1$, and let $g(x)$ be the inverse of $f(x)$. Then find $g′(191/4)$. I know only one way of doing this. Solving the cubic equation for x and then differentiating it. This is too too long. How to solve it more easily?","Let $f(x)=2x^3+7x−1$, and let $g(x)$ be the inverse of $f(x)$. Then find $g′(191/4)$. I know only one way of doing this. Solving the cubic equation for x and then differentiating it. This is too too long. How to solve it more easily?",,['calculus']
73,Deriving $\frac{8}{\sqrt{x-2}}$,Deriving,\frac{8}{\sqrt{x-2}},"I'm not sure how to derive this: $$\frac{8}{\sqrt{x-2}}$$ I tried $$8 \cdot \frac{1}{\sqrt{x-2}}$$ $$8 \cdot (\sqrt{x-2})^{-1}$$ Differentiating w.r.t. $x$, $$8 \cdot -1 \cdot (\sqrt{x-2})^{-2}$$ $$8 \cdot -1 \cdot \frac{1}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{x-2}$$ But the answer is $$\frac{-4}{(x-2)\sqrt{x-2}}$$ What should I have done?","I'm not sure how to derive this: $$\frac{8}{\sqrt{x-2}}$$ I tried $$8 \cdot \frac{1}{\sqrt{x-2}}$$ $$8 \cdot (\sqrt{x-2})^{-1}$$ Differentiating w.r.t. $x$, $$8 \cdot -1 \cdot (\sqrt{x-2})^{-2}$$ $$8 \cdot -1 \cdot \frac{1}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{(\sqrt{x-2})^{2}}$$ $$\frac{-8}{x-2}$$ But the answer is $$\frac{-4}{(x-2)\sqrt{x-2}}$$ What should I have done?",,"['calculus', 'derivatives']"
74,Derivative of $f(x) = x^2 \sin(1/x)$ using the derivative definition,Derivative of  using the derivative definition,f(x) = x^2 \sin(1/x),"derivative of $f(x) = x^2 \sin(1/x)$ using the derivative definition When not using the derivative definition I get $\cos (1/x) + 2x \sin(1/x)$, which WolframAlpha agrees to. However when I try solving it using the derivative definition: $$\lim_ {h\to 0} = \frac{f(x+h) - f(x)}{h} $$ I get: $$2x \sin \left(\frac{1}{x+h} \right ) + h \sin \left(\frac{1}{x+h}\right)$$ which in return results in, as $h \to 0$: $$2x \sin (1/x)$$ So what am I doing wrong when using the def of derivatives?","derivative of $f(x) = x^2 \sin(1/x)$ using the derivative definition When not using the derivative definition I get $\cos (1/x) + 2x \sin(1/x)$, which WolframAlpha agrees to. However when I try solving it using the derivative definition: $$\lim_ {h\to 0} = \frac{f(x+h) - f(x)}{h} $$ I get: $$2x \sin \left(\frac{1}{x+h} \right ) + h \sin \left(\frac{1}{x+h}\right)$$ which in return results in, as $h \to 0$: $$2x \sin (1/x)$$ So what am I doing wrong when using the def of derivatives?",,['derivatives']
75,Differentiation of the term x^n n times.,Differentiation of the term x^n n times.,,Kindly verify the proof i couldn't find this anywhere. I am fairly new to differentiation so i apologize for mistakes if any...  $$\frac{d}{dx}\left(x^n\right)=nx^{n-1}$$ $$\frac{d}{dx}\left(nx^{n-1}\right)=n\left(n-1\right)x^{n-1-1}=n\left(n-1\right)x^{n-2}$$ Hence if differentiated $n$ times: $$\frac{d^n}{dx^n}\left(x^{n}\right)=n!x^{n-1-1-1-...-1}=n!x^{n-n}$$ $$\frac{d^n}{dx^n}\left(x^{n}\right)=n!$$ Thank you,Kindly verify the proof i couldn't find this anywhere. I am fairly new to differentiation so i apologize for mistakes if any...  $$\frac{d}{dx}\left(x^n\right)=nx^{n-1}$$ $$\frac{d}{dx}\left(nx^{n-1}\right)=n\left(n-1\right)x^{n-1-1}=n\left(n-1\right)x^{n-2}$$ Hence if differentiated $n$ times: $$\frac{d^n}{dx^n}\left(x^{n}\right)=n!x^{n-1-1-1-...-1}=n!x^{n-n}$$ $$\frac{d^n}{dx^n}\left(x^{n}\right)=n!$$ Thank you,,"['calculus', 'derivatives']"
76,Why does f' = 0 gives the min or max?,Why does f' = 0 gives the min or max?,,"I understand how to calculate it, but I am just curious, why actually it works? Do we have a proof that it always works?","I understand how to calculate it, but I am just curious, why actually it works? Do we have a proof that it always works?",,['derivatives']
77,Derivative of $x^a$,Derivative of,x^a,"How to calculate the derivative of function $f$ such, that: $f(x)=x^a$, where $x>0$ and $a\in \Bbb R$. Do you know any formula for $(x+h)^a$?","How to calculate the derivative of function $f$ such, that: $f(x)=x^a$, where $x>0$ and $a\in \Bbb R$. Do you know any formula for $(x+h)^a$?",,"['real-analysis', 'derivatives']"
78,Proving that f'(x) is even if f(x) is odd and differentiable,Proving that f'(x) is even if f(x) is odd and differentiable,,"I've seen some proofs but I don't really get it..I find it hard to understand.. I've done this so far: \begin{eqnarray}  f'(x) &=& \lim_{h \to 0} \frac{f(x) - f(x+h)}{h} \textit{ (since f(x) is odd } f(-x) = -f(x)) \\ &=& \lim_{h \to 0}  \frac{-f(-x) + f(-x-h)}{h} \\ &=& \lim_{h -\to 0} \frac{f(-x-h) - f(-x)}{h} \end{eqnarray} But I don't know how to go from here and make it equal to $f'(-x)$. Any help, please?","I've seen some proofs but I don't really get it..I find it hard to understand.. I've done this so far: \begin{eqnarray}  f'(x) &=& \lim_{h \to 0} \frac{f(x) - f(x+h)}{h} \textit{ (since f(x) is odd } f(-x) = -f(x)) \\ &=& \lim_{h \to 0}  \frac{-f(-x) + f(-x-h)}{h} \\ &=& \lim_{h -\to 0} \frac{f(-x-h) - f(-x)}{h} \end{eqnarray} But I don't know how to go from here and make it equal to $f'(-x)$. Any help, please?",,"['calculus', 'derivatives']"
79,Derivative of an integral $\sqrt{t}\sin t dt$,Derivative of an integral,\sqrt{t}\sin t dt,I need to find the derivative of this function. I know I need to separate the integrals into two and use the chain rule but I am stuck. $$y=\int_\sqrt{x}^{x^3}\sqrt{t}\sin t~dt~.$$ Thanks in advance,I need to find the derivative of this function. I know I need to separate the integrals into two and use the chain rule but I am stuck. $$y=\int_\sqrt{x}^{x^3}\sqrt{t}\sin t~dt~.$$ Thanks in advance,,"['integration', 'derivatives', 'definite-integrals']"
80,Why isn't $\frac{d}{dx} \sin (2x) = \cos (2x)$?,Why isn't ?,\frac{d}{dx} \sin (2x) = \cos (2x),"$g=\sin$, $g'=\cos$ If $g(x)=\sin(x)$, then $g'(x)=\cos(x)$. Then $g(y)=\sin(y)$ and $g'(y)=\cos(y)$. Let $y=2x$. Then $g(y)=\sin(2x)$ and $g'(y)=\cos(2x)$, but if $h(x)=\sin(2x)$, then $h'(x)=2\cos(2x)$, so $h(x)=g(y)$, but $h'(x)$ is not equal to $g'(y)$ if, say, $x = \pi$. This doesn't make sense to me, isn't to say $h(x)=g(y)$ to say that $h(x)$ and $g(y)$ are the same?  and so wouldn't it follow that $h'(x)=g'(y)$? Is my problem that I am looking at individual values, $h(x)$ and $g(y)$, instead of the functions $h$ and $g$ themselves? Edit: Once I thought to think of derivative as slope and realized that the slope of the line tangent to the graph of $h(x)$ at $x=a$ is not necessarily the same as the slope of the line tangent to the graph of $g(x)$ at $x=a$, I understood (satisfactorily) why $g'(x)$ isn't the same as $h'(x)$.","$g=\sin$, $g'=\cos$ If $g(x)=\sin(x)$, then $g'(x)=\cos(x)$. Then $g(y)=\sin(y)$ and $g'(y)=\cos(y)$. Let $y=2x$. Then $g(y)=\sin(2x)$ and $g'(y)=\cos(2x)$, but if $h(x)=\sin(2x)$, then $h'(x)=2\cos(2x)$, so $h(x)=g(y)$, but $h'(x)$ is not equal to $g'(y)$ if, say, $x = \pi$. This doesn't make sense to me, isn't to say $h(x)=g(y)$ to say that $h(x)$ and $g(y)$ are the same?  and so wouldn't it follow that $h'(x)=g'(y)$? Is my problem that I am looking at individual values, $h(x)$ and $g(y)$, instead of the functions $h$ and $g$ themselves? Edit: Once I thought to think of derivative as slope and realized that the slope of the line tangent to the graph of $h(x)$ at $x=a$ is not necessarily the same as the slope of the line tangent to the graph of $g(x)$ at $x=a$, I understood (satisfactorily) why $g'(x)$ isn't the same as $h'(x)$.",,"['calculus', 'trigonometry', 'derivatives']"
81,"Distance between set and point, confused of partial derivatives.","Distance between set and point, confused of partial derivatives.",,"Let $H = \{(x,y,z)\ \in \mathbb{R}^{3}: x^2+y^2 - z^2 + 4 = 0$ Compute the shortest distance between H and point $p=(2,4,0)$ . I am a bit confused because I tried a direct approach. $$ x^2+y^2 + 4 =  z^2$$ Let $D(H,p) = \sqrt{(2-x)^{2}+(4-y)^{2} + x^{2} + y^{2}+4}$ So I tried compute $$\frac{\partial D}{\partial x} = (\sqrt{2} (-1 + x))/\sqrt{12 - 2 x + x^2 - 4 y + y^2}$$ $$\frac{\partial D}{\partial y} = (\sqrt{2} (-2 + y))/\sqrt{12 - 2 x + x^2 - 4 y + y^2}$$ It seems not nice to compare with zero. Do you have another idea?",Let Compute the shortest distance between H and point . I am a bit confused because I tried a direct approach. Let So I tried compute It seems not nice to compare with zero. Do you have another idea?,"H = \{(x,y,z)\ \in \mathbb{R}^{3}: x^2+y^2 - z^2 + 4 = 0 p=(2,4,0)  x^2+y^2 + 4 =  z^2 D(H,p) = \sqrt{(2-x)^{2}+(4-y)^{2} + x^{2} + y^{2}+4} \frac{\partial D}{\partial x} = (\sqrt{2} (-1 + x))/\sqrt{12 - 2 x + x^2 - 4 y + y^2} \frac{\partial D}{\partial y} = (\sqrt{2} (-2 + y))/\sqrt{12 - 2 x + x^2 - 4 y + y^2}","['derivatives', 'maxima-minima']"
82,Is a function differentiable if it has a removable discontinuity,Is a function differentiable if it has a removable discontinuity,,"There are many questions on Math Stack Exchange asking if a function is differentiable if it has a removable discontinuity at $x=a$ .  But, I'm having trouble following the answers. I get the impression, from reading here on Stack Exchange and elsewhere that such a function is not differentiable but I don't understand why. Consider the following equation: $f(x)=\frac{x^3}{x}$ .  The function is undefined at $x=0$ but it is clearly differentiable.  First by simplifying: $\frac{d}{dx}\frac{x^3}{x}=\frac{d}{dx}x^2=2x$ Or, using the quotient rule: $\frac{d}{dx}\frac{x^3}{x}=\frac{3x^2\cdot x-x^3\cdot 1}{x^2}=\frac{3x^3-x^3}{x^2}=\frac{2x^3}{x^2}=2x$ And, finally, my calculator agrees. Therefore, it is established that the function is differentiable and has a derivative at every x-value in its domain, including the troublesome $x=0$ . I conclude that a function is differentiable at $x=a$ if the discontinuity is removable . The only thing I can think of that would make this untrue is the idea that I have changed the original function $f(x)$ by removing the discontinuity with some algebra and I am really differentiating a different function (call it $g(x)$ ) that is not quite the same at the one point of interest.  That argument would be more persuasive if I had simply simplified first and then differentiated.  There I was clearly differentiating a different equation.  But, I did not simplify when applying the quotient rule and I obtained the same answer.  So, the argument seems weak, at best.","There are many questions on Math Stack Exchange asking if a function is differentiable if it has a removable discontinuity at .  But, I'm having trouble following the answers. I get the impression, from reading here on Stack Exchange and elsewhere that such a function is not differentiable but I don't understand why. Consider the following equation: .  The function is undefined at but it is clearly differentiable.  First by simplifying: Or, using the quotient rule: And, finally, my calculator agrees. Therefore, it is established that the function is differentiable and has a derivative at every x-value in its domain, including the troublesome . I conclude that a function is differentiable at if the discontinuity is removable . The only thing I can think of that would make this untrue is the idea that I have changed the original function by removing the discontinuity with some algebra and I am really differentiating a different function (call it ) that is not quite the same at the one point of interest.  That argument would be more persuasive if I had simply simplified first and then differentiated.  There I was clearly differentiating a different equation.  But, I did not simplify when applying the quotient rule and I obtained the same answer.  So, the argument seems weak, at best.",x=a f(x)=\frac{x^3}{x} x=0 \frac{d}{dx}\frac{x^3}{x}=\frac{d}{dx}x^2=2x \frac{d}{dx}\frac{x^3}{x}=\frac{3x^2\cdot x-x^3\cdot 1}{x^2}=\frac{3x^3-x^3}{x^2}=\frac{2x^3}{x^2}=2x x=0 x=a f(x) g(x),"['calculus', 'derivatives', 'continuity']"
83,Why isn't $\bar{z}$ differentiable?,Why isn't  differentiable?,\bar{z},"I understand the process my book took to get there. They used the limit process from the ""real"" direction, and the ""complex direction."" To me, it seems obvious that if $z(x,y)=x-iy$ , $\displaystyle \frac{\partial z}{\partial x}=1$ , and $\displaystyle \frac{\partial z}{\partial (iy)}=-1$ . However, the book uses  this to justify why the function is not differentiable, because it approaches different values from different directions. Clearly then, I am missing something. I am confident that this intuition is correct for multivariable functions, but it doesn't work for $f(z)=\bar{z}$ ? Why can a function not have different derivatives in different directions? I was thinking about this some more and I'm wondering if multivariable functions DO have the ""same"" derivative in any direction. For example, consider the function $f(x,y)=3x^2+6y^2$ ; it's derivative is $6x\,dx+12y\,dy$ in every direction. Does that mean, that $\displaystyle \frac{d\bar{z}}{z}=\,dx-\,d(iy)$ ? Can someone comment on my reasoning or explain the difference between multivariable derivatives and complex derivatives?","I understand the process my book took to get there. They used the limit process from the ""real"" direction, and the ""complex direction."" To me, it seems obvious that if , , and . However, the book uses  this to justify why the function is not differentiable, because it approaches different values from different directions. Clearly then, I am missing something. I am confident that this intuition is correct for multivariable functions, but it doesn't work for ? Why can a function not have different derivatives in different directions? I was thinking about this some more and I'm wondering if multivariable functions DO have the ""same"" derivative in any direction. For example, consider the function ; it's derivative is in every direction. Does that mean, that ? Can someone comment on my reasoning or explain the difference between multivariable derivatives and complex derivatives?","z(x,y)=x-iy \displaystyle \frac{\partial z}{\partial x}=1 \displaystyle \frac{\partial z}{\partial (iy)}=-1 f(z)=\bar{z} f(x,y)=3x^2+6y^2 6x\,dx+12y\,dy \displaystyle \frac{d\bar{z}}{z}=\,dx-\,d(iy)","['derivatives', 'complex-numbers']"
84,Prove all derivatives of $f(x)=\frac{1}{1+x}$ by induction,Prove all derivatives of  by induction,f(x)=\frac{1}{1+x},Problem Prove all derivatives of: $$ f(x)=\frac{1}{1+x} $$ by induction. Attempt to solve I compute few derivatives of $f(x)$ so that i can form general expression for induction hypothesis. I compute all derivatives utilizing formula: $$ \frac{d}{dx}x^n=nx^{n-1} $$ First 4 derivatives are: $$ f'(x)=(-1)\cdot(1+x)^{-2}\cdot 1 = -\frac{1}{(1+x)^2} $$ $$ f''(x)=(-1)(-2)(1+x)^{-3}\cdot 1 = \frac{2}{(1+x)^3} $$ $$ f'''(x)=(-1)(-2)(-3)(1+x)^{-4}\cdot 1 = -\frac{6}{(1+x)^4} $$ $$ f''''(x)=(-1)(-2)(-3)(-4)(1+x)^{-5} \cdot 1 = \frac{24}{(1+x)^5} $$ Observe that $(-1)(-2)(-3)(-4)\dots (-n)$ can be generalized with: $$ (-1)(-2)(-3)(-4)\dots(-n) = (-1)^n\cdot n! $$ Expression follows factorial of $n$ except every other value is positive and every other is negative. If i multiply it by $(-1)^n$ it is positive when $n \mod 2 = 0$ and negative when $n \mod 2 \neq 0$ . Rest of the expression can be generalized as: $$ (1+x)^{-n-1} = (1+x)^{-(n+1)}=\frac{1}{(1+x)^{n+1}} $$ Combining these gives formula in analytic form: $$ f(n)= \frac{(-1)^n \cdot n!}{(1+x)^{n+1}} $$ I can form induction hypothesis such that: $$ \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+1}} $$ Induction proof Base case Base case when $n=0$ : $$ \frac{d^0}{dx^0}\frac{1}{1+x}=\frac{1}{1+x}=\frac{(-1)^0\cdot 0!}{(1+x)^{0+1}} $$ Induction step $$ \frac{d^n}{dx^n}\frac{1}{1+x} =_{\text{ind.hyp}} \frac{(-1)^n\cdot n!}{(1+x)^{n+1+1}} $$ $$ \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+2}} $$ Now the problem is that formula i used for derivation can only be used recursively. I believe this is correct notation for $n$ :th derivative but computing one is only defined recursively with formula i used: $$ \frac{d}{dx} x^n = nx^{n-1} $$ Which is not defined for case: $$ \frac{d^n}{dx^n}x^n = \text{ undefined} $$ The idea is to show that this recursion can be expressed in analytical form and it is valid for all $n\in \mathbb{Z}+$ by induction. Problem is i don't know how do you express this in recursive form and how do you get from recursion formula to the analytical one.,Problem Prove all derivatives of: by induction. Attempt to solve I compute few derivatives of so that i can form general expression for induction hypothesis. I compute all derivatives utilizing formula: First 4 derivatives are: Observe that can be generalized with: Expression follows factorial of except every other value is positive and every other is negative. If i multiply it by it is positive when and negative when . Rest of the expression can be generalized as: Combining these gives formula in analytic form: I can form induction hypothesis such that: Induction proof Base case Base case when : Induction step Now the problem is that formula i used for derivation can only be used recursively. I believe this is correct notation for :th derivative but computing one is only defined recursively with formula i used: Which is not defined for case: The idea is to show that this recursion can be expressed in analytical form and it is valid for all by induction. Problem is i don't know how do you express this in recursive form and how do you get from recursion formula to the analytical one.," f(x)=\frac{1}{1+x}  f(x)  \frac{d}{dx}x^n=nx^{n-1}   f'(x)=(-1)\cdot(1+x)^{-2}\cdot 1 = -\frac{1}{(1+x)^2}   f''(x)=(-1)(-2)(1+x)^{-3}\cdot 1 = \frac{2}{(1+x)^3}   f'''(x)=(-1)(-2)(-3)(1+x)^{-4}\cdot 1 = -\frac{6}{(1+x)^4}   f''''(x)=(-1)(-2)(-3)(-4)(1+x)^{-5} \cdot 1 = \frac{24}{(1+x)^5}  (-1)(-2)(-3)(-4)\dots (-n)  (-1)(-2)(-3)(-4)\dots(-n) = (-1)^n\cdot n!  n (-1)^n n \mod 2 = 0 n \mod 2 \neq 0  (1+x)^{-n-1} = (1+x)^{-(n+1)}=\frac{1}{(1+x)^{n+1}}   f(n)= \frac{(-1)^n \cdot n!}{(1+x)^{n+1}}   \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+1}}  n=0  \frac{d^0}{dx^0}\frac{1}{1+x}=\frac{1}{1+x}=\frac{(-1)^0\cdot 0!}{(1+x)^{0+1}}   \frac{d^n}{dx^n}\frac{1}{1+x} =_{\text{ind.hyp}} \frac{(-1)^n\cdot n!}{(1+x)^{n+1+1}}   \frac{d^n}{dx^n}\frac{1}{1+x} = \frac{(-1)^n\cdot n!}{(1+x)^{n+2}}  n  \frac{d}{dx} x^n = nx^{n-1}   \frac{d^n}{dx^n}x^n = \text{
undefined}  n\in \mathbb{Z}+","['real-analysis', 'derivatives', 'induction']"
85,show that if $f$ is uniformly differentiable then prove that $f'$ is continuous,show that if  is uniformly differentiable then prove that  is continuous,f f',"How would I go about showing that if $f$ is uniformly differentiable then $f'$ is continuous. my attempt: A differentiable function $f:[a,b]\to \Bbb R$ is said to be uniformly differentiable on $[a,b]$ if $\forall \epsilon>0 \exists \delta>0:\forall x,y\in[a,b]$ we have $$0<|x-y|<\delta\implies |\frac{f(x)-f(y)}{x-y}-f'(y)|<\epsilon$$ I don't know where to go from here, any help would be highly appreciated.","How would I go about showing that if $f$ is uniformly differentiable then $f'$ is continuous. my attempt: A differentiable function $f:[a,b]\to \Bbb R$ is said to be uniformly differentiable on $[a,b]$ if $\forall \epsilon>0 \exists \delta>0:\forall x,y\in[a,b]$ we have $$0<|x-y|<\delta\implies |\frac{f(x)-f(y)}{x-y}-f'(y)|<\epsilon$$ I don't know where to go from here, any help would be highly appreciated.",,['real-analysis']
86,Show through chain rule that $(u\cdot v)' = uv' + v'u$,Show through chain rule that,(u\cdot v)' = uv' + v'u,Let function be $f(x)=u\cdot v$ where $u$ and $v$ are in terms of $x$. Then how to make someone understand that $f'(x) = uv' + u'v $ only using chain rule? My attempt: I don't even think it is possible but I may be wrong.,Let function be $f(x)=u\cdot v$ where $u$ and $v$ are in terms of $x$. Then how to make someone understand that $f'(x) = uv' + u'v $ only using chain rule? My attempt: I don't even think it is possible but I may be wrong.,,"['calculus', 'derivatives', 'chain-rule']"
87,Is $\frac{d}{dx}\left(\sum_{n = 0}^\infty x^n\right) = \sum_{n = 0}^\infty\left(\frac{d}{dx} x^n \right)$ true?,Is  true?,\frac{d}{dx}\left(\sum_{n = 0}^\infty x^n\right) = \sum_{n = 0}^\infty\left(\frac{d}{dx} x^n \right),"Almost 3 months ago, I asked this question regarding if it's possible to compute the summation of derivatives, as in the example I've given: $$\sum_{n = 0}^\infty \frac{d}{dx} x^n$$ One answer regarded the interchange between summations and derivatives, which got me thinking: does the interchange between the derivative and the summation succeed in this example? In other words, is $$\frac{d}{dx}\left(\sum_{n = 0}^\infty x^n\right) = \sum_{n = 0}^\infty\left(\frac{d}{dx} x^n \right)$$ true? I believe it is, because the summation of the derivatives of $x^n$ from $n = 0 \to \infty$ was: $$1 + 2x + 3x^2 + 4x^3 + 5x^4 + \cdot \cdot \cdot$$ and to evaluate the summation of a series, you take the derivative of each term , which gets me: $$\frac{d}{dx}\left(\sum_{n=0}^\infty x^n\right) = \frac{d}{dx}(1 + x^2 +x^3 + x^4 + x^5 + \cdot \cdot \cdot) = 1 + 2x + 3x^2 + 4x^3 + 5x^4 + \cdot \cdot \cdot $$ Hence, I believe that the interchange succeeds. Am I right? Does the interchange succeed? Notes I implemented the left hand side of the ""interchange equation"" into WolframAlpha, and I got back something ""useful"", but it doesn't really solve my problem. I found This question and this question , but they have nothing to do with my question. Multiple other questions deal with interchanges with summations and integrals. This is about interchanging summations and derivatives.","Almost 3 months ago, I asked this question regarding if it's possible to compute the summation of derivatives, as in the example I've given: $$\sum_{n = 0}^\infty \frac{d}{dx} x^n$$ One answer regarded the interchange between summations and derivatives, which got me thinking: does the interchange between the derivative and the summation succeed in this example? In other words, is $$\frac{d}{dx}\left(\sum_{n = 0}^\infty x^n\right) = \sum_{n = 0}^\infty\left(\frac{d}{dx} x^n \right)$$ true? I believe it is, because the summation of the derivatives of $x^n$ from $n = 0 \to \infty$ was: $$1 + 2x + 3x^2 + 4x^3 + 5x^4 + \cdot \cdot \cdot$$ and to evaluate the summation of a series, you take the derivative of each term , which gets me: $$\frac{d}{dx}\left(\sum_{n=0}^\infty x^n\right) = \frac{d}{dx}(1 + x^2 +x^3 + x^4 + x^5 + \cdot \cdot \cdot) = 1 + 2x + 3x^2 + 4x^3 + 5x^4 + \cdot \cdot \cdot $$ Hence, I believe that the interchange succeeds. Am I right? Does the interchange succeed? Notes I implemented the left hand side of the ""interchange equation"" into WolframAlpha, and I got back something ""useful"", but it doesn't really solve my problem. I found This question and this question , but they have nothing to do with my question. Multiple other questions deal with interchanges with summations and integrals. This is about interchanging summations and derivatives.",,"['calculus', 'sequences-and-series', 'derivatives', 'summation']"
88,Why can we not just use the chain rule to derive $f(x) = x^x$?,Why can we not just use the chain rule to derive ?,f(x) = x^x,"I know that in order to derive $f(x) = x^x,$ you have to take the log of both sides first and then derive it to get $f'(x) = x^x(ln(x)+1).$ I know that if you take the derivative directly using the chain rule, you get the wrong answer. Why is this? I assume it has something to do with the fact that the definition of the derivative has $h\rightarrow 0$ and we would potentially have $(x+h)^{x+h} \rightarrow 0^0$ somehow (which is indeterminate form), but I'm not immediately seeing this. EDIT: So as has been pointed out, this question has been answered elsewhere. Additionally, I did not provide enough information. Specifically: how am I applying the chain rule to get the wrong answer? (And I suppose 'What wrong answer am I getting?') As it turns out, I couldn't decide which function is the ""outside"" function and which function is the ""inside"" function. Initially, I did the power rule first to get $$f'(x) = x\cdot x^{x-1} \cdot (x^x\cdot \ln(x))= x^{2x}ln(x),$$ which we've seen is wrong.","I know that in order to derive $f(x) = x^x,$ you have to take the log of both sides first and then derive it to get $f'(x) = x^x(ln(x)+1).$ I know that if you take the derivative directly using the chain rule, you get the wrong answer. Why is this? I assume it has something to do with the fact that the definition of the derivative has $h\rightarrow 0$ and we would potentially have $(x+h)^{x+h} \rightarrow 0^0$ somehow (which is indeterminate form), but I'm not immediately seeing this. EDIT: So as has been pointed out, this question has been answered elsewhere. Additionally, I did not provide enough information. Specifically: how am I applying the chain rule to get the wrong answer? (And I suppose 'What wrong answer am I getting?') As it turns out, I couldn't decide which function is the ""outside"" function and which function is the ""inside"" function. Initially, I did the power rule first to get $$f'(x) = x\cdot x^{x-1} \cdot (x^x\cdot \ln(x))= x^{2x}ln(x),$$ which we've seen is wrong.",,"['calculus', 'derivatives']"
89,"Real Analysis question on FTC, Integral","Real Analysis question on FTC, Integral",,"Let $g:[0,1] \rightarrow \mathbb R$ be a continuous function and assume that    $$ \int_{0}^{1} g(x) \phi'(x) dx = 0 $$   for all continuously differentiable functions $\phi: [0,1] \rightarrow \mathbb R$, where $\phi (0) = \phi(1) = 0$. Show that $g(x) = c$ for all $x \in [0,1]$ for some constant $c \in \mathbb R$. My thoughts are applying integration by parts with $G(t) = \int_{0}^{t} g(x) dx $, since now we get  $$ 0 = \int_{0}^{1} G(t) \phi'(t) dt  + \int_{0}^{1} g(t) \phi (t) dt $$  which doesn't really go far. The second thought was applying MVT for definite integrals, which doesn't go far either as the conditions are hardly satisfied. Any hints?","Let $g:[0,1] \rightarrow \mathbb R$ be a continuous function and assume that    $$ \int_{0}^{1} g(x) \phi'(x) dx = 0 $$   for all continuously differentiable functions $\phi: [0,1] \rightarrow \mathbb R$, where $\phi (0) = \phi(1) = 0$. Show that $g(x) = c$ for all $x \in [0,1]$ for some constant $c \in \mathbb R$. My thoughts are applying integration by parts with $G(t) = \int_{0}^{t} g(x) dx $, since now we get  $$ 0 = \int_{0}^{1} G(t) \phi'(t) dt  + \int_{0}^{1} g(t) \phi (t) dt $$  which doesn't really go far. The second thought was applying MVT for definite integrals, which doesn't go far either as the conditions are hardly satisfied. Any hints?",,"['real-analysis', 'integration', 'derivatives', 'definite-integrals', 'continuity']"
90,How to find derivative?,How to find derivative?,,"How can I get from step $3$ to step $4$ in the problem? I've tried this: $6x^2 - 9x + 8x -12 + 2\Delta x - 6x^2 -8x +9x + 12 + 3\Delta x$ It doesn't cancel out to $17\Delta x$, though. I've also tried this: $(3x+4)(2x-3) - (2x-3)(3x+4) = 0$, then the only things left are $2\Delta x$ and $3\Delta x$. That adds up to $5\Delta x$, which isn't the answer. How can I solve this problem? Thanks.","How can I get from step $3$ to step $4$ in the problem? I've tried this: $6x^2 - 9x + 8x -12 + 2\Delta x - 6x^2 -8x +9x + 12 + 3\Delta x$ It doesn't cancel out to $17\Delta x$, though. I've also tried this: $(3x+4)(2x-3) - (2x-3)(3x+4) = 0$, then the only things left are $2\Delta x$ and $3\Delta x$. That adds up to $5\Delta x$, which isn't the answer. How can I solve this problem? Thanks.",,"['calculus', 'derivatives']"
91,What is the derivative of $\log_x(A)$ where $x$ is the base (differentiaition with respect to $x$),What is the derivative of  where  is the base (differentiaition with respect to ),\log_x(A) x x,"I want to find out what $\frac{d}{dx}\log_x A$ is?  I did this so far but I'm not sure.  $y = \log_x A \Longrightarrow x^y = A$ so, $d/dx(x^y) = d/dx(A)$ [differentiating both sides w.r.t $x$] then, $y\cdot x^{y-1}dy/dx = 0$ ....that would imply that $dy/dx = 0$ ..what am i doing wrong? as the graph of $\log_x A$ is a curve.","I want to find out what $\frac{d}{dx}\log_x A$ is?  I did this so far but I'm not sure.  $y = \log_x A \Longrightarrow x^y = A$ so, $d/dx(x^y) = d/dx(A)$ [differentiating both sides w.r.t $x$] then, $y\cdot x^{y-1}dy/dx = 0$ ....that would imply that $dy/dx = 0$ ..what am i doing wrong? as the graph of $\log_x A$ is a curve.",,"['calculus', 'derivatives', 'implicit-differentiation']"
92,"If $f$ is differentiable in $[a,b]$ and $f'(x) \ne 0$ for each $x \in [a,b]$ so $f$ is monotone in $[a,b]$?",If  is differentiable in  and  for each  so  is monotone in ?,"f [a,b] f'(x) \ne 0 x \in [a,b] f [a,b]","If $f$ is differentiable in $[a,b]$ and $f'(x) \ne 0$ for each $x \in [a,b]$ so $f$ is monotone in $[a,b]$. Is this correct? I don't think so. Because the differntial doesn't have to be continuous so it can be positive in one area and negative in other... but I can't find a counter-example... thanks","If $f$ is differentiable in $[a,b]$ and $f'(x) \ne 0$ for each $x \in [a,b]$ so $f$ is monotone in $[a,b]$. Is this correct? I don't think so. Because the differntial doesn't have to be continuous so it can be positive in one area and negative in other... but I can't find a counter-example... thanks",,"['real-analysis', 'derivatives']"
93,derivative of x^x^x... to infinity?,derivative of x^x^x... to infinity?,,"I am a 12th grade student, and I am afraid that in realistic terms this question might not even make sense because of the infinities that have to be dealt with. However, in my attempt to calculate it's derivative, I did the following: $$y=x^{x^{x^{.^{.^.}}}}$$ $$\ln(y)=\ln(x)x^{x^{x^{.^{.^.}}}}$$ $$\ln(y)=y\ln(x)$$ after taking derivative with respect to x on both sides, I obtained the following: $$\frac{\mathrm dy}{\mathrm dx}=\frac{y^2}{x(1-\ln(y))}$$ I am fairly certain that the calculations up to this point are valid. However, to further continue, I analyzed the nature of y in different domains and obtained the values, by observation(that is, by observing how $x$, $x^x$, $x^{x^x}$, $x^{x^{x^x}}$, and so on would behave to draw a conclusion): for $x<1,$ $y$ becomes 0 for $x=1,$ $y$ becomes 1 for $x>1,$ $y$ becomes infinite These 3 points is where the first problem lies. Are these true? If so, how do we reach to the conclusion? Secondly, considering this to be true, I get the derivative at: $x<1$ to be 0. $x=1$ to be 1. for $x>1$, I took $x=2.$ then the derivative $\frac{\mathrm dy}{\mathrm dx} = y^2/[2(1-ln(y))]$ (replacing $x$ by $2$). Now, I applied L hospital's rule to get the value of the expression to be negative infinity. This is the second problem . I have used L Hospital's rule, but limits were not concerned. Is this method valid? If not, how would we calculate it?","I am a 12th grade student, and I am afraid that in realistic terms this question might not even make sense because of the infinities that have to be dealt with. However, in my attempt to calculate it's derivative, I did the following: $$y=x^{x^{x^{.^{.^.}}}}$$ $$\ln(y)=\ln(x)x^{x^{x^{.^{.^.}}}}$$ $$\ln(y)=y\ln(x)$$ after taking derivative with respect to x on both sides, I obtained the following: $$\frac{\mathrm dy}{\mathrm dx}=\frac{y^2}{x(1-\ln(y))}$$ I am fairly certain that the calculations up to this point are valid. However, to further continue, I analyzed the nature of y in different domains and obtained the values, by observation(that is, by observing how $x$, $x^x$, $x^{x^x}$, $x^{x^{x^x}}$, and so on would behave to draw a conclusion): for $x<1,$ $y$ becomes 0 for $x=1,$ $y$ becomes 1 for $x>1,$ $y$ becomes infinite These 3 points is where the first problem lies. Are these true? If so, how do we reach to the conclusion? Secondly, considering this to be true, I get the derivative at: $x<1$ to be 0. $x=1$ to be 1. for $x>1$, I took $x=2.$ then the derivative $\frac{\mathrm dy}{\mathrm dx} = y^2/[2(1-ln(y))]$ (replacing $x$ by $2$). Now, I applied L hospital's rule to get the value of the expression to be negative infinity. This is the second problem . I have used L Hospital's rule, but limits were not concerned. Is this method valid? If not, how would we calculate it?",,"['calculus', 'derivatives', 'infinity']"
94,l'Hospital's rule with trigonometric functions,l'Hospital's rule with trigonometric functions,,$$\lim_{x\to0^+}\frac{1-\cos(x)}{x^2\sin(x)}$$ I keep running in circles using the L'Hospital rule. After the third time applying it I got 0 but this isnt true from the graph. I can see it goes to +ve infinity. Please let me know if anyone has an elegant solution to this lengthy problem.,$$\lim_{x\to0^+}\frac{1-\cos(x)}{x^2\sin(x)}$$ I keep running in circles using the L'Hospital rule. After the third time applying it I got 0 but this isnt true from the graph. I can see it goes to +ve infinity. Please let me know if anyone has an elegant solution to this lengthy problem.,,['derivatives']
95,Easy question : $\int (xdy+ydx)$,Easy question :,\int (xdy+ydx),"I am ashamed to ask such an easy question but, well: Lets say I got a function  $$ f(x,y)=xy $$ Now let's compute the total differential of the function $$ d(f(x,y))=xdy+ydx $$ Now if I do $$  \int d(f(x,y))=\int(xdy+ydx)=\int xdy +\int ydx =x\int dy +y \int dx = 2xy \neq f(x,y) $$ Where is the bias in the reasoning ? Thanks in advance","I am ashamed to ask such an easy question but, well: Lets say I got a function  $$ f(x,y)=xy $$ Now let's compute the total differential of the function $$ d(f(x,y))=xdy+ydx $$ Now if I do $$  \int d(f(x,y))=\int(xdy+ydx)=\int xdy +\int ydx =x\int dy +y \int dx = 2xy \neq f(x,y) $$ Where is the bias in the reasoning ? Thanks in advance",,['derivatives']
96,Prove that a function is constant [duplicate],Prove that a function is constant [duplicate],,"This question already has answers here : Proving a function is constant, under certain conditions? [duplicate] (3 answers) Closed 9 years ago . I'm attempting to prove the following statement: Let $f:\mathbb{R}\to\mathbb{R}$ be a function and suppose that $|f(x)-f(y)|\leq (x-y)^2$ for all $x,y\in\mathbb{R}$, therefore f is constant. I was trying to prove it by a theorem that states that; Let f be a differentiable function in $(a,b)$. Therefore if $f'(x)=0$ for all $x,y\in(a,b)$, then f is constant. But i'm stuck trying to prove that f is differentiable to use the above theorem.","This question already has answers here : Proving a function is constant, under certain conditions? [duplicate] (3 answers) Closed 9 years ago . I'm attempting to prove the following statement: Let $f:\mathbb{R}\to\mathbb{R}$ be a function and suppose that $|f(x)-f(y)|\leq (x-y)^2$ for all $x,y\in\mathbb{R}$, therefore f is constant. I was trying to prove it by a theorem that states that; Let f be a differentiable function in $(a,b)$. Therefore if $f'(x)=0$ for all $x,y\in(a,b)$, then f is constant. But i'm stuck trying to prove that f is differentiable to use the above theorem.",,"['real-analysis', 'derivatives']"
97,Calculus integral evaluation using substitution,Calculus integral evaluation using substitution,,"I have to find this integral: Evaluate the integral using an appropriate substitution $$\int\dfrac{8e^x+7e^{-x}}{8e^x-7e^{-x}}\mathrm dx.$$ I've tried my solution $\ln\Big[15\cdot \sinh(x) + \cosh(x)\Big]$, however, it is wrong. What do I have to do?","I have to find this integral: Evaluate the integral using an appropriate substitution $$\int\dfrac{8e^x+7e^{-x}}{8e^x-7e^{-x}}\mathrm dx.$$ I've tried my solution $\ln\Big[15\cdot \sinh(x) + \cosh(x)\Big]$, however, it is wrong. What do I have to do?",,"['calculus', 'integration', 'derivatives', 'logarithms']"
98,Show that the directional derivative is linear by definition,Show that the directional derivative is linear by definition,,"If $f$ is differentiable at $x$, the map $h\mapsto f(x+h)-f(x)$ should be approximately linear. The scalar multiplicativity can be seen by noting that $$\lim_{h\to 0}\frac{f(x+ch)-f(x)}{h} = \lim_{h\to 0}c\frac{f(x+ch)-f(x)}{ch}= c\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\quad \text{and}\\ \lim_{t\to 0}\frac{f(x+ctv)-f(x)}{t}=\lim_{t\to 0}c\frac{f(x+ctv)-f(x)}{ct}=c\lim_{t\to 0}\frac{f(x+tv)-f(x)}{t},$$ where on the second line, $x$ and $v$ are vectors. The additivity of this map is less easy to see for me. How can we show it? That is, how to show that $$\lim_{t\to 0}\frac{f(x+t(v+w))-f(x)}{t} = \lim_{h\to 0}\frac{f(x+tv)-f(x)}{t}+\lim_{h\to 0}\frac{f(x+tw)-f(x)}{t}?$$","If $f$ is differentiable at $x$, the map $h\mapsto f(x+h)-f(x)$ should be approximately linear. The scalar multiplicativity can be seen by noting that $$\lim_{h\to 0}\frac{f(x+ch)-f(x)}{h} = \lim_{h\to 0}c\frac{f(x+ch)-f(x)}{ch}= c\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}\quad \text{and}\\ \lim_{t\to 0}\frac{f(x+ctv)-f(x)}{t}=\lim_{t\to 0}c\frac{f(x+ctv)-f(x)}{ct}=c\lim_{t\to 0}\frac{f(x+tv)-f(x)}{t},$$ where on the second line, $x$ and $v$ are vectors. The additivity of this map is less easy to see for me. How can we show it? That is, how to show that $$\lim_{t\to 0}\frac{f(x+t(v+w))-f(x)}{t} = \lim_{h\to 0}\frac{f(x+tv)-f(x)}{t}+\lim_{h\to 0}\frac{f(x+tw)-f(x)}{t}?$$",,"['calculus', 'derivatives']"
99,For a differentiable function $f:\mathbb{R} \rightarrow \mathbb{R}$ what does $\lim_{x\rightarrow +\infty} f'(x)=1$ imply? (TIFR GS $2014$),For a differentiable function  what does  imply? (TIFR GS ),f:\mathbb{R} \rightarrow \mathbb{R} \lim_{x\rightarrow +\infty} f'(x)=1 2014,"Question is : For a differentiable function $f:\mathbb{R} \rightarrow \mathbb{R}$ what does $\lim_{x\rightarrow +\infty} f'(x)=1$ imply? Options: $f$ is bounded $f$ is increasing $f$ is unbounded $f'$ is bounded I could not find counter examples but then, I strongly feel $\lim_{x\rightarrow +\infty} f'(x)=1$ would just imply that $f'(x)$ is bounded. I do not have much idea why would other three are false. I would be thankful if someone can suggest me some hints. Thank You.","Question is : For a differentiable function $f:\mathbb{R} \rightarrow \mathbb{R}$ what does $\lim_{x\rightarrow +\infty} f'(x)=1$ imply? Options: $f$ is bounded $f$ is increasing $f$ is unbounded $f'$ is bounded I could not find counter examples but then, I strongly feel $\lim_{x\rightarrow +\infty} f'(x)=1$ would just imply that $f'(x)$ is bounded. I do not have much idea why would other three are false. I would be thankful if someone can suggest me some hints. Thank You.",,['real-analysis']
