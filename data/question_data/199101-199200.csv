,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Proving that a (complex) differential form is of type $(p, q)$ iff its conjugate is of type $(q, p)$ using complex vector fields",Proving that a (complex) differential form is of type  iff its conjugate is of type  using complex vector fields,"(p, q) (q, p)","Let $(M, J)$ be a $n$ -complex manifold and $p+q=k$ where $0\leq k \leq 2n$ . I'm looking for a clean way to prove that $\mu\in \mathcal{A}^k(M, \mathbb{C}):=\Gamma\left(\bigwedge^k T_{\mathbb C}^*M \right)$ is a complex diferrential $k$ -form of type $(p, q)$ iff $\bar{\mu}$ is of type $(q, p)$ . Now, first of all, I want to do everything avoiding real arguments in a coordinate-free fashion using complex vector fields (i.e, smooth sections of the complexified tangent bundle of $M$ ,  which I will denote by $\mathfrak{X}(M, \mathbb C):=\Gamma\left(T_{\mathbb C}M \right)$ ). Ok, so firstly, we define $\bar{\mu}\in \mathcal{A}^k(M, \mathbb{C})$ by $$(1)\qquad\qquad\qquad  \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(\bar{Z_1},\ldots,\bar{Z_k})},\qquad\qquad  Z_1,\ldots,Z_k\in \mathfrak{X}(M, \mathbb C).$$ I'm aware that one can check that a $k$ -form is a $(p,q)$ -form when $\lambda\star \mu= \lambda^p \bar{\lambda}^q \mu$ , with $\lambda \in \mathbb C$ (or more generally, for $\lambda \in \mathcal{C}^\infty(M, \mathbb C)$ ) and where $\lambda\star \mu\in \mathcal{A}^k(M, \mathbb{C}) $ is defined as $$(2)\qquad\qquad\qquad\lambda\star \mu (Z_1,\ldots,Z_k):= \mu(\lambda Z_1,\ldots, \lambda Z_k).$$ Now, the trouble comes here. If we want to check (2) applied to (1), we end up obtaining that $\lambda\star \bar\mu=\lambda^p\bar{\lambda}^q \bar\mu$ , which is definitely NOT what we want. However, if we instead define $\bar \mu$ by $$(3)\qquad\qquad\qquad  \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(Z_1,\ldots,Z_k)},$$ then we arrive at the desired conclusion. Now, in fact I've taken definition $(3)$ for granted for some time, but now I'm convinced it is NOT the right one. If we play with a toy example, let's say $ \mu = dz\wedge d\bar{z}$ and $Z=a\dfrac{\partial}{\partial z}+b\dfrac{\partial}{\partial \bar{z}}, W=\alpha\dfrac{\partial}{\partial z}+\beta\dfrac{\partial}{\partial \bar{z}}$ , we all agree that $\bar\mu= d\bar{z}\wedge dz$ , and we can easily check that $\bar\mu(Z, W)=\overline{\mu(\bar Z, \bar W)}=b\alpha-a\beta$ , whereas $\overline{\mu(Z, W)}=\overline{a\beta - b \alpha}$ , so definition $(1)$ is the right one. So, what am I missing here? I'm certain that the conjugate is given by $(1)$ . Not many authors bother to explain what $\bar\mu$ actually is, or how to compute it, a small portion of them just say that if $\mu=\alpha+i \beta$ , then $\bar\mu=\alpha -i\beta$ (which I agree with, but it is quite dry). In fact, formula $(1)$ appears in Poor's Differential Geometric Structures, a quite venerable and underrated text, and as we saw in the toy example, it is quite the right one. All that being said, we can infer that maybe $(2)$ doesn't work as expected for complex vector fields. If so, what can we do so that $(2)$ works for my desired proof? I guess we can just take the following definition for a $(p, q)$ -form and everything is settled: A complex $k$ -form is of type $(p, q)$ if and only if it vanishes whenever applied to $p+1$ vectors of type $(1, 0)$ or to $q + 1$ vectors of type $(0, 1)$ . The desired conclusion holds trivially using the previous definition, but I'm quite unsatisfied because $(2)$ is a pretty nice way to check if a $k$ -form is a $(p, q)$ -form. Any help or comments are appreciated. Just to be clear, I don't have trouble with the fact that $\mu$ is a $(p, q)$ -form iff $\bar \mu$ is of type $(q, p)$ (for example, using the definition above or local coordinates), rather, I want to see why $(2)$ doesn't hold or what does it need to work correctly in the fashion I want to use it.","Let be a -complex manifold and where . I'm looking for a clean way to prove that is a complex diferrential -form of type iff is of type . Now, first of all, I want to do everything avoiding real arguments in a coordinate-free fashion using complex vector fields (i.e, smooth sections of the complexified tangent bundle of ,  which I will denote by ). Ok, so firstly, we define by I'm aware that one can check that a -form is a -form when , with (or more generally, for ) and where is defined as Now, the trouble comes here. If we want to check (2) applied to (1), we end up obtaining that , which is definitely NOT what we want. However, if we instead define by then we arrive at the desired conclusion. Now, in fact I've taken definition for granted for some time, but now I'm convinced it is NOT the right one. If we play with a toy example, let's say and , we all agree that , and we can easily check that , whereas , so definition is the right one. So, what am I missing here? I'm certain that the conjugate is given by . Not many authors bother to explain what actually is, or how to compute it, a small portion of them just say that if , then (which I agree with, but it is quite dry). In fact, formula appears in Poor's Differential Geometric Structures, a quite venerable and underrated text, and as we saw in the toy example, it is quite the right one. All that being said, we can infer that maybe doesn't work as expected for complex vector fields. If so, what can we do so that works for my desired proof? I guess we can just take the following definition for a -form and everything is settled: A complex -form is of type if and only if it vanishes whenever applied to vectors of type or to vectors of type . The desired conclusion holds trivially using the previous definition, but I'm quite unsatisfied because is a pretty nice way to check if a -form is a -form. Any help or comments are appreciated. Just to be clear, I don't have trouble with the fact that is a -form iff is of type (for example, using the definition above or local coordinates), rather, I want to see why doesn't hold or what does it need to work correctly in the fashion I want to use it.","(M, J) n p+q=k 0\leq k \leq 2n \mu\in \mathcal{A}^k(M, \mathbb{C}):=\Gamma\left(\bigwedge^k T_{\mathbb C}^*M \right) k (p, q) \bar{\mu} (q, p) M \mathfrak{X}(M, \mathbb C):=\Gamma\left(T_{\mathbb C}M \right) \bar{\mu}\in \mathcal{A}^k(M, \mathbb{C}) (1)\qquad\qquad\qquad
 \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(\bar{Z_1},\ldots,\bar{Z_k})},\qquad\qquad  Z_1,\ldots,Z_k\in \mathfrak{X}(M, \mathbb C). k (p,q) \lambda\star \mu= \lambda^p \bar{\lambda}^q \mu \lambda \in \mathbb C \lambda \in \mathcal{C}^\infty(M, \mathbb C) \lambda\star \mu\in \mathcal{A}^k(M, \mathbb{C})  (2)\qquad\qquad\qquad\lambda\star \mu (Z_1,\ldots,Z_k):= \mu(\lambda Z_1,\ldots, \lambda Z_k). \lambda\star \bar\mu=\lambda^p\bar{\lambda}^q \bar\mu \bar \mu (3)\qquad\qquad\qquad
 \bar{\mu}(Z_1,\ldots,Z_k):= \overline{\mu(Z_1,\ldots,Z_k)}, (3)  \mu = dz\wedge d\bar{z} Z=a\dfrac{\partial}{\partial z}+b\dfrac{\partial}{\partial \bar{z}}, W=\alpha\dfrac{\partial}{\partial z}+\beta\dfrac{\partial}{\partial \bar{z}} \bar\mu= d\bar{z}\wedge dz \bar\mu(Z, W)=\overline{\mu(\bar Z, \bar W)}=b\alpha-a\beta \overline{\mu(Z, W)}=\overline{a\beta - b \alpha} (1) (1) \bar\mu \mu=\alpha+i \beta \bar\mu=\alpha -i\beta (1) (2) (2) (p, q) k (p, q) p+1 (1, 0) q + 1 (0, 1) (2) k (p, q) \mu (p, q) \bar \mu (q, p) (2)","['differential-geometry', 'differential-forms', 'complex-geometry', 'multilinear-algebra', 'complex-manifolds']"
1,Understanding the construction and structure of the Grassmannian manifold,Understanding the construction and structure of the Grassmannian manifold,,"I have been reading Differential geometry of smooth manifolds from two different books: one by Jeffrey M Lee and the other by John M Lee. In the first chapter of both books, the authors construct what is called a Grassmannian manifold. Since the proof given in the book is almost complete, there are no ""doubts"" in the proof. However, here, I will be sharing a few concerns while constructing the manifold structure on the Grassmannian. For reference, we will be using the following result which tells us that a set can be given a smooth structure under certain conditions: Theorem: Let $M$ be a set and $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ be a collection of subsets of $M$ together with injective maps $\phi_{\alpha}: U_{\alpha} \to \mathbb{R}^n$ . Assume the following: $\left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta}$ is a smooth atlas for $M$ . There is a countable subcollection $\left\lbrace U_{\alpha_n} \right\rbrace_{n \in \mathbb{N}}$ of $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ which covers $M$ . For distinct points $p, q \in M$ , either there is some $\alpha \in \Delta$ such that $p, q \in U_{\alpha}$ or there are $\alpha, \beta \in \Delta$ with $\alpha \neq \beta$ such that $p \in U_{\alpha}$ , $q \in U_{\beta}$ and $U_{\alpha} \cap U_{\beta} = \emptyset$ . Then, $M$ is a smooth manifold with the topology induced by the atlas. Here, again, when we say a ""smooth atlas"", we mean independently (without assuming a topology on $M$ ). That definition is given as follows. Definition: Let $M$ be a set, $\left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta}$ be a collection of subsets of $M$ , and $\phi_{\alpha}: U_{\alpha} \rightarrow \mathbb{R}^n$ be injective maps onto open sets in $\mathbb{R}^n$ . Then, the collection $\left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta}$ is a smooth chart on $M$ if $\bigcup\limits_{\alpha \in \Delta} U_{\alpha} = M$ . For each $\alpha, \beta \in \Delta$ , the set $\phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right)$ is open in $\mathbb{R}^n$ . For each $\alpha, \beta \in \Delta$ with $U_{\alpha} \cap U_{\beta} \neq \emptyset$ , the map $\phi_{\beta} \circ \phi_{\alpha}^{-1} : \phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right) \rightarrow \phi_{\beta} \left( U_{\alpha} \cap U_{\beta} \right)$ is a (smooth) diffeomorphism. Using this definition and the theorem, the authors try to construct a smooth structure on the Grassmannian. They start with a finite-dimensional real vector space $V$ , say of dimension $n$ , and consider the set of all $k$ -dimensional subspaces of $V$ . We call it $G_{k} \left( V \right)$ . This set will precisely become the Grassmannian manifold. To do so, we would need to construct a suitable atlas on $G_k \left( V \right)$ such that the conditions of the Theorem are satisfied. To achieve this end, we see that for any $k$ -dimensional subspace $P$ of $V$ , there is an $\left( n - k \right)$ -dimensional complementary subspace $Q$ such that $V = P \oplus Q$ . Then, for any linear map $T: P \rightarrow Q$ , if we consider its graph $\Gamma \left( T \right) = \left\lbrace \left( x, Tx \right) | x \in P \right\rbrace$ , then it can be considered as a subspace of $V$ , by identifying $\left( x, Tx \right)$ with $x + Tx$ . Moreover, it is also easy to see that $\Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace$ . In fact, every $k$ -dimensional subspace of $V$ which intersects $Q$ trivially, can be seen as a graph of a linear map from $P$ to $Q$ . To see this, let $W \subseteq V$ be a $k$ -dimensional subspace such that $W \cap Q = \left\lbrace 0 \right\rbrace$ . Then, for each $w \in W$ , there is a unique $p \in P$ and $q \in Q$ such that $w = p + q$ . We define $T: P \rightarrow Q$ as $Tp = q$ . That is, if we consider $U_Q$ to be the set of all $k$ -dimensional subspaces which intersect $Q$ trivially, then we have a bijection $\psi_Q: L \left( P, Q \right) \rightarrow U_Q$ . Here, $L \left( P, Q \right)$ is the space of all linear transformations from $P$ to $Q$ , and can be identified with $R^{k \left( n - k \right)}$ . So, the collection $\left\lbrace \left( U_Q, \phi_Q \right) \right\rbrace$ , where $\phi_Q = \psi_Q^{-1}$ can be the required smooth atlas. Again, to see this, we have to prove point (2) and (3) of the definition. If $\left( P', Q' \right)$ is another pair of complementary subspaces of $V$ , where $P$ is $k$ -dimensional, we first want to prove that $\phi_Q \left( U_Q \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace \text{ and } \Gamma \left( T \right) \cap Q' = \left\lbrace 0 \right\rbrace \right\rbrace$ is empty. However, because $\phi_Q$ is a bijection, we know that $\phi_Q \left( U_{Q} \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q' = \emptyset \right\rbrace$ . What I don't understand is why should this be an open set in $L \left( P, Q \right)$ ?  To understand what is happening, I took a look at the three-dimensional case, when $\Gamma \left( T \right)$ could be $2$ -dimensional. Since there is a one-to-one correspondence between $T$ and $\Gamma \left( T \right)$ , we might as well work with a $2$ -dimensional subspace in $\mathbb{R}^3$ which intersects $Q$ and $Q'$ trivially. To get more of an idea, I have considered that $Q$ is the $X$ -axis, $Q'$ is the $Y$ -axis. Suppose that $T \in \phi_Q \left( U_Q \cap U_{Q'} \right)$ . Then, it corresponds to a plane which does not contain both $X$ - and $Y$ -axes. Now, this plane can be sort of ""rotated"" by a small amount so that the resulting plane(s) do not contain the $X$ - and the $Y$ -axes. See Figure for more intuitive understanding of my thoughts. What I have been stuck on is that how should we use these thoughts to construct open balls around each $T \in \phi_Q \left( U_Q \cap U_{Q'} \right)$ ?","I have been reading Differential geometry of smooth manifolds from two different books: one by Jeffrey M Lee and the other by John M Lee. In the first chapter of both books, the authors construct what is called a Grassmannian manifold. Since the proof given in the book is almost complete, there are no ""doubts"" in the proof. However, here, I will be sharing a few concerns while constructing the manifold structure on the Grassmannian. For reference, we will be using the following result which tells us that a set can be given a smooth structure under certain conditions: Theorem: Let be a set and be a collection of subsets of together with injective maps . Assume the following: is a smooth atlas for . There is a countable subcollection of which covers . For distinct points , either there is some such that or there are with such that , and . Then, is a smooth manifold with the topology induced by the atlas. Here, again, when we say a ""smooth atlas"", we mean independently (without assuming a topology on ). That definition is given as follows. Definition: Let be a set, be a collection of subsets of , and be injective maps onto open sets in . Then, the collection is a smooth chart on if . For each , the set is open in . For each with , the map is a (smooth) diffeomorphism. Using this definition and the theorem, the authors try to construct a smooth structure on the Grassmannian. They start with a finite-dimensional real vector space , say of dimension , and consider the set of all -dimensional subspaces of . We call it . This set will precisely become the Grassmannian manifold. To do so, we would need to construct a suitable atlas on such that the conditions of the Theorem are satisfied. To achieve this end, we see that for any -dimensional subspace of , there is an -dimensional complementary subspace such that . Then, for any linear map , if we consider its graph , then it can be considered as a subspace of , by identifying with . Moreover, it is also easy to see that . In fact, every -dimensional subspace of which intersects trivially, can be seen as a graph of a linear map from to . To see this, let be a -dimensional subspace such that . Then, for each , there is a unique and such that . We define as . That is, if we consider to be the set of all -dimensional subspaces which intersect trivially, then we have a bijection . Here, is the space of all linear transformations from to , and can be identified with . So, the collection , where can be the required smooth atlas. Again, to see this, we have to prove point (2) and (3) of the definition. If is another pair of complementary subspaces of , where is -dimensional, we first want to prove that is empty. However, because is a bijection, we know that . What I don't understand is why should this be an open set in ?  To understand what is happening, I took a look at the three-dimensional case, when could be -dimensional. Since there is a one-to-one correspondence between and , we might as well work with a -dimensional subspace in which intersects and trivially. To get more of an idea, I have considered that is the -axis, is the -axis. Suppose that . Then, it corresponds to a plane which does not contain both - and -axes. Now, this plane can be sort of ""rotated"" by a small amount so that the resulting plane(s) do not contain the - and the -axes. See Figure for more intuitive understanding of my thoughts. What I have been stuck on is that how should we use these thoughts to construct open balls around each ?","M \left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta} M \phi_{\alpha}: U_{\alpha} \to \mathbb{R}^n \left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta} M \left\lbrace U_{\alpha_n} \right\rbrace_{n \in \mathbb{N}} \left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta} M p, q \in M \alpha \in \Delta p, q \in U_{\alpha} \alpha, \beta \in \Delta \alpha \neq \beta p \in U_{\alpha} q \in U_{\beta} U_{\alpha} \cap U_{\beta} = \emptyset M M M \left\lbrace U_{\alpha} \right\rbrace_{\alpha \in \Delta} M \phi_{\alpha}: U_{\alpha} \rightarrow \mathbb{R}^n \mathbb{R}^n \left\lbrace \left( U_{\alpha}, \phi_{\alpha} \right) \right\rbrace_{\alpha \in \Delta} M \bigcup\limits_{\alpha \in \Delta} U_{\alpha} = M \alpha, \beta \in \Delta \phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right) \mathbb{R}^n \alpha, \beta \in \Delta U_{\alpha} \cap U_{\beta} \neq \emptyset \phi_{\beta} \circ \phi_{\alpha}^{-1} : \phi_{\alpha} \left( U_{\alpha} \cap U_{\beta} \right) \rightarrow \phi_{\beta} \left( U_{\alpha} \cap U_{\beta} \right) V n k V G_{k} \left( V \right) G_k \left( V \right) k P V \left( n - k \right) Q V = P \oplus Q T: P \rightarrow Q \Gamma \left( T \right) = \left\lbrace \left( x, Tx \right) | x \in P \right\rbrace V \left( x, Tx \right) x + Tx \Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace k V Q P Q W \subseteq V k W \cap Q = \left\lbrace 0 \right\rbrace w \in W p \in P q \in Q w = p + q T: P \rightarrow Q Tp = q U_Q k Q \psi_Q: L \left( P, Q \right) \rightarrow U_Q L \left( P, Q \right) P Q R^{k \left( n - k \right)} \left\lbrace \left( U_Q, \phi_Q \right) \right\rbrace \phi_Q = \psi_Q^{-1} \left( P', Q' \right) V P k \phi_Q \left( U_Q \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q = \left\lbrace 0 \right\rbrace \text{ and } \Gamma \left( T \right) \cap Q' = \left\lbrace 0 \right\rbrace \right\rbrace \phi_Q \phi_Q \left( U_{Q} \cap U_{Q'} \right) = \left\lbrace T: P \rightarrow Q | \Gamma \left( T \right) \cap Q' = \emptyset \right\rbrace L \left( P, Q \right) \Gamma \left( T \right) 2 T \Gamma \left( T \right) 2 \mathbb{R}^3 Q Q' Q X Q' Y T \in \phi_Q \left( U_Q \cap U_{Q'} \right) X Y X Y T \in \phi_Q \left( U_Q \cap U_{Q'} \right)","['differential-geometry', 'smooth-manifolds', 'grassmannian']"
2,How is the Algebra $C_{p}^{\infty}(U)$ of germs of $C^\infty$ functions in $U$ at $p$ is the Same as $C_{p}^{\infty}(M)$,How is the Algebra  of germs of  functions in  at  is the Same as,C_{p}^{\infty}(U) C^\infty U p C_{p}^{\infty}(M),"Hi i am reading An introduction to manifolds by Loring and have some doubts in remark 8.2. It is written that If $U$ is an open set containing $p$ in $M$ then the algebra $C_{p}^{\infty}(U)$ of germs of $C^\infty$ functions in $U$ at $p$ is the same as $C_{p}^{\infty}(M)$ .Hence, $T_pU=T_pM$ . My first question is: How do we know that the algebra $C_{p}^{\infty}(U)=C_{p}^{\infty}(M)$ . I know that, the equivalence class of $(f,U)$ is called the germ of $f$ at $p$ . I have a second question which is related to the differential of a map. It is written that: The equation $(F_{*}(X_p))f=X_p(f\circ F)$ is independent of the representative of the germ. My second question is that here in the above equation $f$ is the representative of a germ and it is appearing inside the equation then how this equation is independent of the representative $f$ ? For reference i am attaching the screenshots where i have highlighted the part where these two statements are mentioned.","Hi i am reading An introduction to manifolds by Loring and have some doubts in remark 8.2. It is written that If is an open set containing in then the algebra of germs of functions in at is the same as .Hence, . My first question is: How do we know that the algebra . I know that, the equivalence class of is called the germ of at . I have a second question which is related to the differential of a map. It is written that: The equation is independent of the representative of the germ. My second question is that here in the above equation is the representative of a germ and it is appearing inside the equation then how this equation is independent of the representative ? For reference i am attaching the screenshots where i have highlighted the part where these two statements are mentioned.","U p M C_{p}^{\infty}(U) C^\infty U p C_{p}^{\infty}(M) T_pU=T_pM C_{p}^{\infty}(U)=C_{p}^{\infty}(M) (f,U) f p (F_{*}(X_p))f=X_p(f\circ F) f f","['differential-geometry', 'manifolds', 'smooth-manifolds', 'tangent-spaces', 'germs']"
3,Biharmonic functions on closed manifolds?,Biharmonic functions on closed manifolds?,,"Let $(M,g)$ be a closed (compact, $\partial M=\varnothing$ ) smooth connected Riemannian manifold with Laplace–Beltrami operator $\Delta_g$ . As it is well-known, every harmonic function ( $u\in \ker \Delta_g$ ) on $M$ is constant (e.g. Hodge Isomorphism Theorem). Question: What about biharmonic functions ( $u\in \ker \Delta_g^2$ )? In particular, can we say that every (everywhere defined, at least continuous) (distributionally) biharmonic function on $M$ is constant? A few remarks: of course, the answer is negative on non-compact manifolds (think polynomials on $\mathbb R^n$ ), as well as on bounded domains with appropriate boundary conditions. (See e.g. this question ). Equivalently, we may look for smooth solutions to the Poisson equation $\Delta_g u\equiv 1$ . By multiplying on both sides by $u$ and integrating w.r.t. the Riemannian volume $\mu_g$ we get: $$\int u \Delta_g u d\!\mu_g=\int |du|^2 d\!\mu_g=\int u d\!\mu_g$$ If $u$ has mean $0$ , we immediately get that it is constant. If otherwise, we may assume that $\int u d\!\mu_g=1$ , in which case the same holds for $|du|^2$ . In particular if $u$ is a solution to the eikonal equation $|du|^2\equiv\mu_g(M)^{-1}$ , then it is biharmonic. If we allow $du$ to have a singularity at some point $x_0$ in $M$ , then this solution should be (?) the Green kernel for the bi-Laplacian pinned at $x_0$ . If however $du\equiv 1$ everywhere, I do not see why a solution should exist.","Let be a closed (compact, ) smooth connected Riemannian manifold with Laplace–Beltrami operator . As it is well-known, every harmonic function ( ) on is constant (e.g. Hodge Isomorphism Theorem). Question: What about biharmonic functions ( )? In particular, can we say that every (everywhere defined, at least continuous) (distributionally) biharmonic function on is constant? A few remarks: of course, the answer is negative on non-compact manifolds (think polynomials on ), as well as on bounded domains with appropriate boundary conditions. (See e.g. this question ). Equivalently, we may look for smooth solutions to the Poisson equation . By multiplying on both sides by and integrating w.r.t. the Riemannian volume we get: If has mean , we immediately get that it is constant. If otherwise, we may assume that , in which case the same holds for . In particular if is a solution to the eikonal equation , then it is biharmonic. If we allow to have a singularity at some point in , then this solution should be (?) the Green kernel for the bi-Laplacian pinned at . If however everywhere, I do not see why a solution should exist.","(M,g) \partial M=\varnothing \Delta_g u\in \ker \Delta_g M u\in \ker \Delta_g^2 M \mathbb R^n \Delta_g u\equiv 1 u \mu_g \int u \Delta_g u d\!\mu_g=\int |du|^2 d\!\mu_g=\int u d\!\mu_g u 0 \int u d\!\mu_g=1 |du|^2 u |du|^2\equiv\mu_g(M)^{-1} du x_0 M x_0 du\equiv 1","['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'laplacian']"
4,Smoothly extending a metric from a manifold with boundary to an attached cylinder,Smoothly extending a metric from a manifold with boundary to an attached cylinder,,"Let $M$ be a manifold with boundary $\partial M$ . Form the manifold $M'$ by attaching a half-infinite cylinder $\partial M\times[0,\infty)$ to $M$ along its boundary. In other words, $$M'=M\cup_{\partial M}\partial M\times[0,\infty),$$ where we identify $\partial M\sim\partial M\times\{0\}$ . Let $g$ be a Riemannian metric on $M$ . Question: Does there always exist a Riemannian metric $g'$ on $M'$ such that the restriction of $g'$ to $M$ is equal to $g$ ? Comment added later: Now that I think about it, perhaps the required property is built into the definition of smoothness of $g$ at the boundary, namely that it's extendible slightly beyond the boundary of the chart into some open neighborhood; one then uses a partition of unity to get a metric on all of $M'$ .","Let be a manifold with boundary . Form the manifold by attaching a half-infinite cylinder to along its boundary. In other words, where we identify . Let be a Riemannian metric on . Question: Does there always exist a Riemannian metric on such that the restriction of to is equal to ? Comment added later: Now that I think about it, perhaps the required property is built into the definition of smoothness of at the boundary, namely that it's extendible slightly beyond the boundary of the chart into some open neighborhood; one then uses a partition of unity to get a metric on all of .","M \partial M M' \partial M\times[0,\infty) M M'=M\cup_{\partial M}\partial M\times[0,\infty), \partial M\sim\partial M\times\{0\} g M g' M' g' M g g M'","['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds', 'manifolds-with-boundary']"
5,Why is the domain of a parametrised curve given by an open interval?,Why is the domain of a parametrised curve given by an open interval?,,"This is my first question on the math stack exchange. I am currently a second-year undergraduate student taking an elementary course on Curves and Surfaces. My question is as follows. In the parametrization $γ : (−2π, 2π) \to\Bbb R^2$ given by $γ(t) = (\cos t − \sin t, \cos t + \sin t)$ , why is the domain of $t$ given by the open interval $(−2π, 2π)$ and not $[−2π, 2π]$ . Isn't $t$ clearly defined at $−2π$ and $2π?$ In other words why is an open interval taken to describe a parametric curve? Any help would be highly appreciated.","This is my first question on the math stack exchange. I am currently a second-year undergraduate student taking an elementary course on Curves and Surfaces. My question is as follows. In the parametrization given by , why is the domain of given by the open interval and not . Isn't clearly defined at and In other words why is an open interval taken to describe a parametric curve? Any help would be highly appreciated.","γ : (−2π, 2π) \to\Bbb R^2 γ(t) = (\cos t − \sin t, \cos t + \sin t) t (−2π, 2π) [−2π, 2π] t −2π 2π?","['differential-geometry', 'differential-topology', 'curves', 'parametrization']"
6,Dimension of $r$-jets of maps from manifolds $M$ to $N$,Dimension of -jets of maps from manifolds  to,r M N,"Differential Topology Hirsch Chapter 2 Section 4 Problem 11: Compute the Dimension of $J^r(M, N)$ $J^r(M, N)$ is the set of all $r$ -jets from $M$ to $N$ . This is an equivalence class $[x, f, U]_r$ of triples $(x, f, U)$ , where $U \subset M$ is an open set, $x \in U$ , and $f: U \rightarrow N$ is a $C^r$ map; the equivlence relation is: $[x, f, U]_r = [x' f', U']_r$ if $x = x'$ and in some (hence any) pair of charts adapted to $f$ at $x$ , $f$ and $f'$ have the same derivatives up to order $r$ . I wanted to check to see if this was right: $J^r(M, N)$ seems to me to only distinguish among different points and functions whose derivatives differ at order $r+1$ and up. Since $x \in M$ we know that the dimension of $J^r(M, N)\geq dim M$ . Now we just have to figure out the dimension of all functions that differ at order $r+1$ and up and add it to dim $M$ ? I can only think that this is infinite...","Differential Topology Hirsch Chapter 2 Section 4 Problem 11: Compute the Dimension of is the set of all -jets from to . This is an equivalence class of triples , where is an open set, , and is a map; the equivlence relation is: if and in some (hence any) pair of charts adapted to at , and have the same derivatives up to order . I wanted to check to see if this was right: seems to me to only distinguish among different points and functions whose derivatives differ at order and up. Since we know that the dimension of . Now we just have to figure out the dimension of all functions that differ at order and up and add it to dim ? I can only think that this is infinite...","J^r(M, N) J^r(M, N) r M N [x, f, U]_r (x, f, U) U \subset M x \in U f: U \rightarrow N C^r [x, f, U]_r = [x' f', U']_r x = x' f x f f' r J^r(M, N) r+1 x \in M J^r(M, N)\geq dim M r+1 M","['differential-geometry', 'algebraic-topology', 'differential-topology', 'function-spaces']"
7,Is every isometric immersion between surfaces of equal area injective?,Is every isometric immersion between surfaces of equal area injective?,,"Let $M,N$ be smooth connected, compact two-dimensional Riemannian manifolds, such that $M$ has a non-empty Lipschitz boundary. Suppose that $\operatorname{Vol}(M)=\operatorname{Vol}(N)$ . Question: Let $f:M \to N$ be a smooth isometric immersion (i.e $df_p$ is an isometry for every $p \in M$ ). Must $f$ be surjective? This equivalent to $f$ being injective ""a.e. in the image""- i.e. $|f^{-1}(q)| \le 1$ for a.e. $q \in N$ . (see below). The argument given here shows that if $\partial M=\emptyset$ , then $f$ is surjective. Proof of the equivalence: By the area formula $$ \text{Vol}(M) = \int_M 1=\int_M \det df  = \int_N |f^{-1}(y)|=\int_{f(M)} |f^{-1}(y)|. $$ So, if $|f^{-1}(y)| \le 1$ a.e. on $N$ , then $ \text{Vol}(N)=\text{Vol}(M) = \text{Vol}(f(M))$ . On the other hand, if $\text{Vol}(f(M))=\text{Vol}(M)$ , then $$\text{Vol}(f(M))=\text{Vol}(M)= \int_{f(M)} |f^{-1}(y)| \ge \int_{f(M)} 1= \text{Vol}(f(M)),  $$ so $|f^{-1}(y)| \le 1$ a.e. on $f(M)$ , hence also on $N$ . We proved that $|f^{-1}(y)| \le 1$ a.e. on $N$ if and only if $\text{Vol}(f(M))=\text{Vol}(N)$ . Since $f(M) $ is compact, being of full measure in $N$ is equivalent to being equal to $N$ . Comment: Some amount of non-injectivity is clearly possible: Take for example $M=[-1,1]^2$ , and let $N=M/\sim$ be the flat $2$ -torus with $\sim$ the standard equivalence relation. Then the quotient map $\pi:M\to N$ is not everywhere injective.","Let be smooth connected, compact two-dimensional Riemannian manifolds, such that has a non-empty Lipschitz boundary. Suppose that . Question: Let be a smooth isometric immersion (i.e is an isometry for every ). Must be surjective? This equivalent to being injective ""a.e. in the image""- i.e. for a.e. . (see below). The argument given here shows that if , then is surjective. Proof of the equivalence: By the area formula So, if a.e. on , then . On the other hand, if , then so a.e. on , hence also on . We proved that a.e. on if and only if . Since is compact, being of full measure in is equivalent to being equal to . Comment: Some amount of non-injectivity is clearly possible: Take for example , and let be the flat -torus with the standard equivalence relation. Then the quotient map is not everywhere injective.","M,N M \operatorname{Vol}(M)=\operatorname{Vol}(N) f:M \to N df_p p \in M f f |f^{-1}(q)| \le 1 q \in N \partial M=\emptyset f 
\text{Vol}(M) = \int_M 1=\int_M \det df  = \int_N |f^{-1}(y)|=\int_{f(M)} |f^{-1}(y)|.
 |f^{-1}(y)| \le 1 N 
\text{Vol}(N)=\text{Vol}(M) = \text{Vol}(f(M)) \text{Vol}(f(M))=\text{Vol}(M) \text{Vol}(f(M))=\text{Vol}(M)= \int_{f(M)} |f^{-1}(y)| \ge \int_{f(M)} 1= \text{Vol}(f(M)),
  |f^{-1}(y)| \le 1 f(M) N |f^{-1}(y)| \le 1 N \text{Vol}(f(M))=\text{Vol}(N) f(M)  N N M=[-1,1]^2 N=M/\sim 2 \sim \pi:M\to N","['real-analysis', 'differential-geometry', 'riemannian-geometry', 'isometry', 'geometric-measure-theory']"
8,"If $(M,g)$ is a Riemannian manifold and $S$ is a regular level set of $f:M\to \Bbb R$ then $\text{grad}f|_S$ is nowhere vanishing",If  is a Riemannian manifold and  is a regular level set of  then  is nowhere vanishing,"(M,g) S f:M\to \Bbb R \text{grad}f|_S","I have a question reading a proof of the following theorem. Theorem. Let $M$ be an oriented smooth manifold, and suppose $S\subset M$ us a regular level set of a smooth function $f:M\to \Bbb R$ . Then $S$ is orientable. Proof. Choose a Riemannian metric $g$ on $M$ , and let $N=\text{grad}f|_S$ . The hypotheses imply that $N$ is nowhere tangent vector field along $S$ , so the result follows. I know that $N$ is normal to $S$ at each point of $S$ , but how do we know that $N$ does not vanish at each point of $S$ ? If $(U,x^1,\dots,x^n)$ is a chart of $M$ near a point in $S$ , then $g$ can be written as $g=g_{ij}dx^i \otimes dx^j$ where $(g_{ij})$ is a positive definite real symmetric matrix. Then $\text{grad}f|_S$ equals $g^{ij} \dfrac{\partial f}{\partial x^i} \dfrac{\partial }{\partial x^j}$ where $(g^{ij})=(g_{ij})^{-1}$ . Since $S$ is a regular level set, some $\dfrac{\partial f}{\partial x^i}$ does not vanish at each point of $S$ , but how do we know that $g^{ij} \dfrac{\partial f}{\partial x^i}$ does not vanish for some $j$ , at each point of $S$ ?","I have a question reading a proof of the following theorem. Theorem. Let be an oriented smooth manifold, and suppose us a regular level set of a smooth function . Then is orientable. Proof. Choose a Riemannian metric on , and let . The hypotheses imply that is nowhere tangent vector field along , so the result follows. I know that is normal to at each point of , but how do we know that does not vanish at each point of ? If is a chart of near a point in , then can be written as where is a positive definite real symmetric matrix. Then equals where . Since is a regular level set, some does not vanish at each point of , but how do we know that does not vanish for some , at each point of ?","M S\subset M f:M\to \Bbb R S g M N=\text{grad}f|_S N S N S S N S (U,x^1,\dots,x^n) M S g g=g_{ij}dx^i \otimes dx^j (g_{ij}) \text{grad}f|_S g^{ij} \dfrac{\partial f}{\partial x^i} \dfrac{\partial }{\partial x^j} (g^{ij})=(g_{ij})^{-1} S \dfrac{\partial f}{\partial x^i} S g^{ij} \dfrac{\partial f}{\partial x^i} j S","['differential-geometry', 'proof-explanation', 'riemannian-geometry', 'smooth-manifolds', 'orientation']"
9,Curvature Formula Proof By Definition,Curvature Formula Proof By Definition,,"Question : Use Definition 3.2 to prove Theorem 3.4. Definition 3.2 “The signed curvature $k(s)$ of a plane curve $ \alpha: I \rightarrow \mathbb{R^2}, \alpha(u)=(x(u),y(u))$ is defined by $t’(s)=k(s)n(s)$ (where $t(s),n(s)$ are the unit tangent and normal vectors, respectively). Theorem 3.4 “Let $ \alpha: I \rightarrow \mathbb{R^2}, \alpha(u)=(x(u),y(u))$ , be a regular curve (not necessarily parametrised by arc length). Then: $$k(u)=\frac{x’(u)y’’(u)—x’’(u)y’(u)}{(x’(u)^2+y’(u)^2)^{\frac{3}{2}}}$$ Below is my attempt. I’m not sure why my denominator has the incorrect index. Clearly, it must be small faux pas but I can’t find it. I’ve looked at other proofs here relating to the curvature (as many as I could, there are a lot) but none seem to be exactly the same as this. I apologise in advance if this is a duplicate.","Question : Use Definition 3.2 to prove Theorem 3.4. Definition 3.2 “The signed curvature of a plane curve is defined by (where are the unit tangent and normal vectors, respectively). Theorem 3.4 “Let , be a regular curve (not necessarily parametrised by arc length). Then: Below is my attempt. I’m not sure why my denominator has the incorrect index. Clearly, it must be small faux pas but I can’t find it. I’ve looked at other proofs here relating to the curvature (as many as I could, there are a lot) but none seem to be exactly the same as this. I apologise in advance if this is a duplicate.","k(s)  \alpha: I \rightarrow \mathbb{R^2}, \alpha(u)=(x(u),y(u)) t’(s)=k(s)n(s) t(s),n(s)  \alpha: I \rightarrow \mathbb{R^2}, \alpha(u)=(x(u),y(u)) k(u)=\frac{x’(u)y’’(u)—x’’(u)y’(u)}{(x’(u)^2+y’(u)^2)^{\frac{3}{2}}}","['differential-geometry', 'curvature', 'parametrization', 'arc-length']"
10,Lie algebra of a linear algebraic group acts on functions by derivations: what does this mean?,Lie algebra of a linear algebraic group acts on functions by derivations: what does this mean?,,"Let $G$ be a linear algebraic group over an algebraically closed field of characteristic zero.  Let $X$ be an affine variety on which $G$ acts.  Then $G$ naturally acts on the coordinate ring $\mathcal O_X(X)$ by the formula $g.f(x) = f(g^{-1}.x)$ .  I often see the claim ""The Lie algebra $\mathfrak g$ of $G$ also acts on $\mathcal O_X(X)$ by derivations.""  What exactly does this mean? For example, suppose we take $X = G$ , with $G$ acting by conjugation.  If $\xi \in \mathfrak g$ , and $f$ is a regular function on $G$ , what would $\xi.f$ be? I'm a little more familiar with the case of real Lie groups.  If $G$ was a smooth Lie group with an action on a smooth manifold $X$ , and $f$ was a smooth real valued function on $X$ , then I would expect $\xi.f$ would be $$\xi.f(x) = \lim\limits_{t \to 0} \frac{f(\exp(t \xi).x )-f(x)}{t}$$","Let be a linear algebraic group over an algebraically closed field of characteristic zero.  Let be an affine variety on which acts.  Then naturally acts on the coordinate ring by the formula .  I often see the claim ""The Lie algebra of also acts on by derivations.""  What exactly does this mean? For example, suppose we take , with acting by conjugation.  If , and is a regular function on , what would be? I'm a little more familiar with the case of real Lie groups.  If was a smooth Lie group with an action on a smooth manifold , and was a smooth real valued function on , then I would expect would be",G X G G \mathcal O_X(X) g.f(x) = f(g^{-1}.x) \mathfrak g G \mathcal O_X(X) X = G G \xi \in \mathfrak g f G \xi.f G X f X \xi.f \xi.f(x) = \lim\limits_{t \to 0} \frac{f(\exp(t \xi).x )-f(x)}{t},"['differential-geometry', 'algebraic-geometry', 'algebraic-groups']"
11,Well-definedness of the pullback on covectors.,Well-definedness of the pullback on covectors.,,"Basic definitions in question: Let $M,N$ be smooth manifolds, and consider a smooth map $\phi : M \rightarrow N$ . The push-forward map is the map: $$\begin{align} \phi_* : & \ TM \rightarrow TN \\ & \ X \mapsto \phi_*(X) \end{align}$$ $$\text{with} \ \phi_*(X)f = X(f\circ \phi) \ \forall f\in C^{\infty}(N)$$ The pull-back map is the map: $$\begin{align} \phi^* : & \ T^*N \rightarrow T^*M \\ & \ \omega \mapsto \phi^*(\omega) \end{align}$$ $$\text{with} \ \phi^*(\omega)(X) = \omega(\phi_*(X)), \ X \in TM$$ Easy to see that the image of a fibre over $p$ , $T_pM$ , of the tangent bundle $TM$ under the push-forward $\phi_*$ is contained in the fibre over $\phi(p)$ in the corresponding tangent bundle $TN$ : $$\phi_*(T_pM) \subseteq T_{\phi(p)}N.$$ However, it was also claimed that the pull-back of a generic covector $\omega \in T_{\phi(p)}^*N$ will be a covector $\phi^*(\omega) \in T^*_pM$ , where I particularly emphasise the $p$ in $T^*_pM$ . The question: Given that $\phi$ is not known to be injective, isn't it impossible for this definition to guarantee that a covector $\omega$ defined at $x=\phi(p)\in N$ will necessarily be pulled back to a covector at the point $p$ of $M$ ? Patently, if $\phi$ is not injective, there could exist $q\not=p$ with $x=\phi(p)=\phi(q)$ -- so would the pullback of $\omega$ lie in $T^*_pM$ or $T^*_qM$ ? Worse still, what does one do with covectors defined at points in $N$ that don't lie in the image of $\phi$ ? But, if injectivity/surjectivity of $\phi$ is indeed the minimal requirement to have a well-defined pullback of this type, this would consequently impose constraints on the dimensions of $M,N$ . This was certainly not discussed (although I can see this working better in the case of embedding a lower dimensional manifold in one of higher dimension, for example). It's more a question of, what am I missing here? I note that this is a map between cotangent bundles as opposed to the spaces of sections of the cotangent bundles. Perhaps, this is an acceptable definition when acting on forms/covector fields ? I stumbled upon this ( Definition of pullback. ), which states ""This situation with forms is different. For differential forms the pull-back is well-defined even if the function is not injective."" in the top answer.","Basic definitions in question: Let be smooth manifolds, and consider a smooth map . The push-forward map is the map: The pull-back map is the map: Easy to see that the image of a fibre over , , of the tangent bundle under the push-forward is contained in the fibre over in the corresponding tangent bundle : However, it was also claimed that the pull-back of a generic covector will be a covector , where I particularly emphasise the in . The question: Given that is not known to be injective, isn't it impossible for this definition to guarantee that a covector defined at will necessarily be pulled back to a covector at the point of ? Patently, if is not injective, there could exist with -- so would the pullback of lie in or ? Worse still, what does one do with covectors defined at points in that don't lie in the image of ? But, if injectivity/surjectivity of is indeed the minimal requirement to have a well-defined pullback of this type, this would consequently impose constraints on the dimensions of . This was certainly not discussed (although I can see this working better in the case of embedding a lower dimensional manifold in one of higher dimension, for example). It's more a question of, what am I missing here? I note that this is a map between cotangent bundles as opposed to the spaces of sections of the cotangent bundles. Perhaps, this is an acceptable definition when acting on forms/covector fields ? I stumbled upon this ( Definition of pullback. ), which states ""This situation with forms is different. For differential forms the pull-back is well-defined even if the function is not injective."" in the top answer.","M,N \phi : M \rightarrow N \begin{align}
\phi_* : & \ TM \rightarrow TN \\
& \ X \mapsto \phi_*(X)
\end{align} \text{with} \ \phi_*(X)f = X(f\circ \phi) \ \forall f\in C^{\infty}(N) \begin{align}
\phi^* : & \ T^*N \rightarrow T^*M \\
& \ \omega \mapsto \phi^*(\omega)
\end{align} \text{with} \ \phi^*(\omega)(X) = \omega(\phi_*(X)), \ X \in TM p T_pM TM \phi_* \phi(p) TN \phi_*(T_pM) \subseteq T_{\phi(p)}N. \omega \in T_{\phi(p)}^*N \phi^*(\omega) \in T^*_pM p T^*_pM \phi \omega x=\phi(p)\in N p M \phi q\not=p x=\phi(p)=\phi(q) \omega T^*_pM T^*_qM N \phi \phi M,N",['differential-geometry']
12,Existence of a non-compact Riemannian manifold with infinite injective radius,Existence of a non-compact Riemannian manifold with infinite injective radius,,Let $M$ be a complete non-compact Riemannian manifold with non-negative sectional curvature. Please tell is it possible that $M$ has infinite injective radius expect Euclidean space? Thank you,Let be a complete non-compact Riemannian manifold with non-negative sectional curvature. Please tell is it possible that has infinite injective radius expect Euclidean space? Thank you,M M,"['differential-geometry', 'riemannian-geometry']"
13,Curve with constant torsion and no curvature,Curve with constant torsion and no curvature,,"When curvature and torsion are given a curve is fully defined (upto Euclidean motions) in 3-space. $ k=const , \tau = 0 $ represents a circle in a plane ; But what does the space curve $$ k =0 , \tau= const,$$ represent? The center line $ (u=0) $ of a right handed twisted helicoid with parametrization $( u \cos v, u \sin v, c \;v ) $ is a good example. Curvature/Torsion of $u=0$ line of helicoid. Clearly u=0 is a straight line at the helicoid mid with zero curvatures ( both normal (asymptotic $ k_n=0$ ) and geodesic $k_g=0$ ) as valid for a full straight line. Using Enneper-Beltrami theorem torsion of the central parametric line at $\; u=0$ is found constant : Evaluating Gauss curvature K $$ K= \dfrac{-c^2}{(c^2+u^2)^2}, \tau = \sqrt{-K}= \pm \dfrac {1}{c}$$ The sign for the torsion of right helicoid is positive and, for the left handed helicoid it is negative. A physical example is of a long human hair that can be twisted right or left with constant torsion even if the twist is not clearly visible. Other examples include long straight portions of DNA and other polymer molecules which inhabit such a surface. EDIT1: In another example the straight line parameterized by $$(x,y,z)= (a, b t, c t) $$ has zero curvature and non-zero torsion in this example when it becomes asymptotic on certain (arbitrary?) surfaces surfaces of negative Gauss curvature. EDIT2: What I meant by torsion without curvature is shown in the first figure Twist of Helicoid's straight/geodesic Spine . The special asymptotic line intrinsically characterizes how twist occurs during parallel transport in tangent spaces.","When curvature and torsion are given a curve is fully defined (upto Euclidean motions) in 3-space. represents a circle in a plane ; But what does the space curve represent? The center line of a right handed twisted helicoid with parametrization is a good example. Curvature/Torsion of line of helicoid. Clearly u=0 is a straight line at the helicoid mid with zero curvatures ( both normal (asymptotic ) and geodesic ) as valid for a full straight line. Using Enneper-Beltrami theorem torsion of the central parametric line at is found constant : Evaluating Gauss curvature K The sign for the torsion of right helicoid is positive and, for the left handed helicoid it is negative. A physical example is of a long human hair that can be twisted right or left with constant torsion even if the twist is not clearly visible. Other examples include long straight portions of DNA and other polymer molecules which inhabit such a surface. EDIT1: In another example the straight line parameterized by has zero curvature and non-zero torsion in this example when it becomes asymptotic on certain (arbitrary?) surfaces surfaces of negative Gauss curvature. EDIT2: What I meant by torsion without curvature is shown in the first figure Twist of Helicoid's straight/geodesic Spine . The special asymptotic line intrinsically characterizes how twist occurs during parallel transport in tangent spaces."," k=const , \tau = 0   k =0 , \tau= const,  (u=0)  ( u \cos v, u \sin v, c \;v )  u=0  k_n=0 k_g=0 \; u=0  K= \dfrac{-c^2}{(c^2+u^2)^2}, \tau = \sqrt{-K}= \pm \dfrac {1}{c} (x,y,z)= (a, b t, c t) ",['differential-geometry']
14,pullback of Maurer-Cartan form for matrix lie groups,pullback of Maurer-Cartan form for matrix lie groups,,"I want to show that for a manifold $M$ and smooth map $\varphi:M\rightarrow GL(n,\mathbb{R})$ we have $\varphi^*\omega=\varphi^{-1} d\varphi$ . The Maurer-Cartan form is defined as for $X\in T_gG$ we have $\omega(X)=d_g(L_{g^{-1}})(X)$ . My idea to approach this probblem was to first show that for a matrix Lie group the Maurer-Cartan form is given by $g^{-1}dg$ and then statment $\varphi^*\omega=\varphi^{-1} d\varphi$ should somehow follow. First question: To show that $\omega(X)=d_g(L_{g^{-1}})(X)$ agrees with $g^{-1}dg$ . For a matrix group $L_h$ is a linear operaion so $d_g(L_h)=L_h$ and then $\omega(X)=L_{g^{-1}}(X)=g^{-1}(X)$ . But how do we get $dg$ into this? Second question: Does $\varphi^*\omega=\varphi^{-1} d\varphi$ follow from $g^{-1}dg$ and if so how?",I want to show that for a manifold and smooth map we have . The Maurer-Cartan form is defined as for we have . My idea to approach this probblem was to first show that for a matrix Lie group the Maurer-Cartan form is given by and then statment should somehow follow. First question: To show that agrees with . For a matrix group is a linear operaion so and then . But how do we get into this? Second question: Does follow from and if so how?,"M \varphi:M\rightarrow GL(n,\mathbb{R}) \varphi^*\omega=\varphi^{-1} d\varphi X\in T_gG \omega(X)=d_g(L_{g^{-1}})(X) g^{-1}dg \varphi^*\omega=\varphi^{-1} d\varphi \omega(X)=d_g(L_{g^{-1}})(X) g^{-1}dg L_h d_g(L_h)=L_h \omega(X)=L_{g^{-1}}(X)=g^{-1}(X) dg \varphi^*\omega=\varphi^{-1} d\varphi g^{-1}dg","['differential-geometry', 'lie-groups', 'differential-forms']"
15,Can an isometry be thought of as biholomorphism?,Can an isometry be thought of as biholomorphism?,,"I am slightly confused about the interchangeability of the terms isometry and biholomorphism . This confusion is rooted in the following statement, which I have seen more than once in some discussions on equivalent versions of the Uniformization Theorem. Suppose $(M,g)$ is a complete, simply connected, $2$ -dimensional Riemannian manifold with constant curvature. By the Killing-Hopf theorem, it is isometric to either $\mathbb{R}^2$ , $S^2$ , or $\mathbb{H}^2$ . Identify $M$ as a simply connected Riemann surface and identify $\mathbb{R}^2$ , $S^2$ , and $\mathbb{H}^2$ as, respectively, $\mathbb{C}$ , $\hat{\mathbb{C}}$ , and $D_1$ . Then $M$ is biholomorphically equivalent to $\mathbb{C}$ , $\hat{\mathbb{C}}$ , or $D_1$ . To me, an isometry between two Riemannian manifolds $(M,g)$ and $(M',g')$ is a diffeomorphism $f:M\longrightarrow M'$ such that $g=f^*g'$ . Thus, it preserves angles and can be described as a conformal mapping. On the other hand, given two Riemann surfaces $M$ and $N$ , a biholomorphism is a bijective map $f:M \longrightarrow N$ such that both $f$ and $f^{-1}$ are holomorphic. So, in the context of the italicized statement, does it really follow that the isometry turns into a biholomorphism just because we switched from Riemannian manifolds to Riemann surfaces, and because both isometries and biholomorphisms preserve angles? Or is there something more subtle going on here?","I am slightly confused about the interchangeability of the terms isometry and biholomorphism . This confusion is rooted in the following statement, which I have seen more than once in some discussions on equivalent versions of the Uniformization Theorem. Suppose is a complete, simply connected, -dimensional Riemannian manifold with constant curvature. By the Killing-Hopf theorem, it is isometric to either , , or . Identify as a simply connected Riemann surface and identify , , and as, respectively, , , and . Then is biholomorphically equivalent to , , or . To me, an isometry between two Riemannian manifolds and is a diffeomorphism such that . Thus, it preserves angles and can be described as a conformal mapping. On the other hand, given two Riemann surfaces and , a biholomorphism is a bijective map such that both and are holomorphic. So, in the context of the italicized statement, does it really follow that the isometry turns into a biholomorphism just because we switched from Riemannian manifolds to Riemann surfaces, and because both isometries and biholomorphisms preserve angles? Or is there something more subtle going on here?","(M,g) 2 \mathbb{R}^2 S^2 \mathbb{H}^2 M \mathbb{R}^2 S^2 \mathbb{H}^2 \mathbb{C} \hat{\mathbb{C}} D_1 M \mathbb{C} \hat{\mathbb{C}} D_1 (M,g) (M',g') f:M\longrightarrow M' g=f^*g' M N f:M \longrightarrow N f f^{-1}","['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'conformal-geometry']"
16,Why do we need the covariant derivative along a curve - why are linear connections not sufficient?,Why do we need the covariant derivative along a curve - why are linear connections not sufficient?,,"I can't figure out why we need the definition of a 'covariant derivative along a curve', i.e. I can't see why we can't use a 'linear connection' even when the vector fields are not extendible. I'm reading Lee's book on Riemannian manifolds. After he has shown that $\nabla$ depends on X and Y only around an open set, he defines the Christoffel symbols through the expression $\nabla_{E^j}E^i$ , where $E^j,E^i$ are elements of a local frame, i.e. vector fields defined only locally on an open set (and thus not necessarily extendible). Likewise, it is show that $(\nabla_{X}Y)_p$ in fact only depends on $X$ through its value at p and on Y through its values on a curve through p whose tangent at p is $X_p$ . Therefore, if $\gamma$ is a smooth curve, $(\nabla_{\dot{\gamma}}Y)_p$ should be well-defined, even if Y is only defined along $\gamma$ and isn't extendible. Where am I wrong? Thanks a lot.","I can't figure out why we need the definition of a 'covariant derivative along a curve', i.e. I can't see why we can't use a 'linear connection' even when the vector fields are not extendible. I'm reading Lee's book on Riemannian manifolds. After he has shown that depends on X and Y only around an open set, he defines the Christoffel symbols through the expression , where are elements of a local frame, i.e. vector fields defined only locally on an open set (and thus not necessarily extendible). Likewise, it is show that in fact only depends on through its value at p and on Y through its values on a curve through p whose tangent at p is . Therefore, if is a smooth curve, should be well-defined, even if Y is only defined along and isn't extendible. Where am I wrong? Thanks a lot.","\nabla \nabla_{E^j}E^i E^j,E^i (\nabla_{X}Y)_p X X_p \gamma (\nabla_{\dot{\gamma}}Y)_p \gamma","['differential-geometry', 'riemannian-geometry', 'connections']"
17,How do pullback and isothermal transformations of a Riemannian metric change curvature?,How do pullback and isothermal transformations of a Riemannian metric change curvature?,,"Let $(X, g)$ be a (closed) Riemannian surface (or more generally a Riemannian manifold of any dimension). How do the following changes to $g$ change its curvature? Pullback by some diffeomorphism of $X$ ; Multiplication by a scalar function, i.e., replacing $g$ with $\lambda g$ for some $\mathbb R$ -valued function $\lambda$ . More precisely, can we use these two operations to produce a metric with constant curvature?","Let be a (closed) Riemannian surface (or more generally a Riemannian manifold of any dimension). How do the following changes to change its curvature? Pullback by some diffeomorphism of ; Multiplication by a scalar function, i.e., replacing with for some -valued function . More precisely, can we use these two operations to produce a metric with constant curvature?","(X, g) g X g \lambda g \mathbb R \lambda","['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'curvature']"
18,What type of connection is required for the Chern-Gauss-Bonnet Theorem?,What type of connection is required for the Chern-Gauss-Bonnet Theorem?,,"How general a connection on $TM$ can be used in the Chern-Gauss-Bonnet theorem?  Wikipedia only states the theorem for the Levi-Civita connection, but this is probably needlessly restrictive.  (If the theorem can be proven for the LC connection of some metric then it holds for the LC connection for any metric, and so we see already that there is some family of connections for which it holds.   This is also asserted in Q. Yuan's answer here ). What I understand of Chern-Weil theory suggests that the theorem should hold for any connection whatsoever on $TM$ , but perhaps I am missing something.  Chern seems to only consider Levi-Civita connections in A Simple Intrinsic Proof of the Gauss-Bonnet Formula for Closed Riemannian Manifolds .","How general a connection on can be used in the Chern-Gauss-Bonnet theorem?  Wikipedia only states the theorem for the Levi-Civita connection, but this is probably needlessly restrictive.  (If the theorem can be proven for the LC connection of some metric then it holds for the LC connection for any metric, and so we see already that there is some family of connections for which it holds.   This is also asserted in Q. Yuan's answer here ). What I understand of Chern-Weil theory suggests that the theorem should hold for any connection whatsoever on , but perhaps I am missing something.  Chern seems to only consider Levi-Civita connections in A Simple Intrinsic Proof of the Gauss-Bonnet Formula for Closed Riemannian Manifolds .",TM TM,"['differential-geometry', 'riemannian-geometry', 'vector-bundles', 'connections']"
19,Computing the Weingarten map/shape operator,Computing the Weingarten map/shape operator,,"Let $M$ be a surface of revolution of the form $F(t,s)=(r(t)\cos(s),r(t)\sin(s),z(t))$ where $\gamma(t)=(r(t),z(t))$ is a curve with unit speed and $r(t)>0$ . I know the unit normal to $M$ is $\xi(s,t)=(-z'(t)\cos(s),-z'(t)\sin(s),r'(t))$ (or written as $-z'(t)\cos(s) \partial_x -z'(t)\sin(s) \partial_y+  r'(t) \partial_z$ ) and now I want to compute the Weingarten map $S^{\xi}$ . I know that for $X \in \mathfrak{X}(M)$ , $S^{\xi}(X)=-\nabla_X \xi=-X(\xi)$ . $X$ is then of the form $X(s,t)=X_s \partial_s +X_t \partial_t$ . Now I have problems how to plug in $\xi$ in $X$ . Can I somehow compute $\partial_x$ in terms of $\partial_s, \partial_t$ ? I always have big problems doing such computations on concrete examples, so I'm sorry if something I wrote here is complete nonsense..","Let be a surface of revolution of the form where is a curve with unit speed and . I know the unit normal to is (or written as ) and now I want to compute the Weingarten map . I know that for , . is then of the form . Now I have problems how to plug in in . Can I somehow compute in terms of ? I always have big problems doing such computations on concrete examples, so I'm sorry if something I wrote here is complete nonsense..","M F(t,s)=(r(t)\cos(s),r(t)\sin(s),z(t)) \gamma(t)=(r(t),z(t)) r(t)>0 M \xi(s,t)=(-z'(t)\cos(s),-z'(t)\sin(s),r'(t)) -z'(t)\cos(s) \partial_x -z'(t)\sin(s) \partial_y+  r'(t) \partial_z S^{\xi} X \in \mathfrak{X}(M) S^{\xi}(X)=-\nabla_X \xi=-X(\xi) X X(s,t)=X_s \partial_s +X_t \partial_t \xi X \partial_x \partial_s, \partial_t","['differential-geometry', 'riemannian-geometry', 'surfaces']"
20,Inducing almost complex structure in tensor bundle,Inducing almost complex structure in tensor bundle,,"Let $E\to M$ be a (smooth) vector bundle and $J$ be a section of ${\rm End}(E)$ with $J^2= -{\rm Id}$ . Can $J$ induce something in $$\mathscr{T}^{(r,s)}(E)=\bigsqcup_{x\in M} E^{\otimes  r}\otimes (E^*)^{\otimes s},$$ in general? For example, in $E^* = \mathscr{T}^{(0,1)}(E)$ one can set $(J^*\zeta)(\psi)= \zeta(J\psi)$ , this $J^*$ squares to $-{\rm Id}$ and has the nice property that whenever we have a connection $\nabla$ in $E$ , the identity $(\nabla_XJ^*)(\zeta)= \zeta\circ \nabla_XJ$ holds. But if I try to combine these two in the general case and set $$(J\Phi)(\zeta^1,\ldots,\zeta^r,\psi_1,\ldots,\psi_s) = \Phi(\zeta^1\circ J,\ldots ,\zeta^r\circ J,J\psi_1,\ldots, J\psi_s),$$ I get the awkward sign $J^2 = (-1)^{r+s} {\rm Id}$ (which at least is consistent what with I did for $E^*$ ). To summarize my question: I don't like this sign. I wanted $J^2=-{\rm Id}$ always. Is this fixable? If not, are there deeper reasons?","Let be a (smooth) vector bundle and be a section of with . Can induce something in in general? For example, in one can set , this squares to and has the nice property that whenever we have a connection in , the identity holds. But if I try to combine these two in the general case and set I get the awkward sign (which at least is consistent what with I did for ). To summarize my question: I don't like this sign. I wanted always. Is this fixable? If not, are there deeper reasons?","E\to M J {\rm End}(E) J^2= -{\rm Id} J \mathscr{T}^{(r,s)}(E)=\bigsqcup_{x\in M} E^{\otimes  r}\otimes (E^*)^{\otimes s}, E^* = \mathscr{T}^{(0,1)}(E) (J^*\zeta)(\psi)= \zeta(J\psi) J^* -{\rm Id} \nabla E (\nabla_XJ^*)(\zeta)= \zeta\circ \nabla_XJ (J\Phi)(\zeta^1,\ldots,\zeta^r,\psi_1,\ldots,\psi_s) = \Phi(\zeta^1\circ J,\ldots ,\zeta^r\circ J,J\psi_1,\ldots, J\psi_s), J^2 = (-1)^{r+s} {\rm Id} E^* J^2=-{\rm Id}","['differential-geometry', 'complex-geometry', 'vector-bundles', 'almost-complex']"
21,Example of a Manifold which only has Ricci Curvature in One Direction,Example of a Manifold which only has Ricci Curvature in One Direction,,"I was wondering if anyone had a simple example of a manifold which only has Ricci curvature in one direction ie. such that the Ricci tensor only has one non-zero component. Intuitively, I would expect such a thing to be possible somehow just from the definition of Ric but could not think of an example.","I was wondering if anyone had a simple example of a manifold which only has Ricci curvature in one direction ie. such that the Ricci tensor only has one non-zero component. Intuitively, I would expect such a thing to be possible somehow just from the definition of Ric but could not think of an example.",,"['differential-geometry', 'riemannian-geometry']"
22,Taylor expansion of $g^{-1/2}$ where $g$ is riemannian metric in normal coordinates,Taylor expansion of  where  is riemannian metric in normal coordinates,g^{-1/2} g,"Let $(M,g)$ be a riemannian manifold. In normal coordinates for any $q\in M$ , there is a Taylor expansion of $g_q$ given by $$(g_q)_{ij}(x)=\delta_{ij}+\frac{1}{3}R_{kijl}(q)x^k x^l+O(|x|^3)$$ Now here is my question: How does one derive from the above expression, that $$\left(\sqrt{g_q}^{-1}\right)^{ij}(x) =\delta^{ij}-\frac{1}{6}R_{kijl}(q)x^k x^l+O(|x|^3)$$ I know how one derives the Taylor expansion of $g$ , using a geodesic variation. Here $\sqrt{g_q}$ denotes the positive square root of $g$ (as a matrix). I am kinda clueless here, any help would be very much appreciated! I read this in a paper, but there is no further explanation.","Let be a riemannian manifold. In normal coordinates for any , there is a Taylor expansion of given by Now here is my question: How does one derive from the above expression, that I know how one derives the Taylor expansion of , using a geodesic variation. Here denotes the positive square root of (as a matrix). I am kinda clueless here, any help would be very much appreciated! I read this in a paper, but there is no further explanation.","(M,g) q\in M g_q (g_q)_{ij}(x)=\delta_{ij}+\frac{1}{3}R_{kijl}(q)x^k x^l+O(|x|^3) \left(\sqrt{g_q}^{-1}\right)^{ij}(x)
=\delta^{ij}-\frac{1}{6}R_{kijl}(q)x^k x^l+O(|x|^3) g \sqrt{g_q} g","['differential-geometry', 'taylor-expansion', 'riemannian-geometry']"
23,Computing the differential of a Lie group action,Computing the differential of a Lie group action,,"(Ex. 27.4 page 252 Loring Tu) (The differential of an action). Let $\mu: P \times G \rightarrow P$ . For $g \in G$ , the tangent space $T_gG$ may be identified with $l_{g*} \mathfrak{g} $ , where $l_g:G \rightarrow G$ is left multiplication by $g \in G$ and $\mathfrak g = T_eG$ is the Lie algebra of $G$ . An element of the tangent space $T_{(p,g)}P \times G$ is of the form $$(X_P, l_{g*} A)$$ for $X_p \in T_pP$ and $A \in \mathfrak g$ . The differential is given by $$ \mu_*= \mu_{*,(p,g)} :T_{(p,g)}(P \times G) \rightarrow T_{pg} P$$ is given by $$ \mu_*(X_p, l_{g*} A) = r_{g*} (X_p) + \underline{A}_{pg} $$ Definition: $\underline{A}$ is the fundamental vector field on $P$ associated to $A \in \mathfrak{g}$ , $$ \underline{A}_p  = \frac{d}{dt}\Big|_{t=0} p \cdot e^{tA} \in T_pP$$ I am struggling in writing out the proof rigorously and neatly. I would be greatful if someone may spell this out.","(Ex. 27.4 page 252 Loring Tu) (The differential of an action). Let . For , the tangent space may be identified with , where is left multiplication by and is the Lie algebra of . An element of the tangent space is of the form for and . The differential is given by is given by Definition: is the fundamental vector field on associated to , I am struggling in writing out the proof rigorously and neatly. I would be greatful if someone may spell this out.","\mu: P \times G \rightarrow P g \in G T_gG l_{g*} \mathfrak{g}  l_g:G \rightarrow G g \in G \mathfrak g = T_eG G T_{(p,g)}P \times G (X_P, l_{g*} A) X_p \in T_pP A \in \mathfrak g  \mu_*= \mu_{*,(p,g)} :T_{(p,g)}(P \times G) \rightarrow T_{pg} P  \mu_*(X_p, l_{g*} A) = r_{g*} (X_p) + \underline{A}_{pg}  \underline{A} P A \in \mathfrak{g}  \underline{A}_p  = \frac{d}{dt}\Big|_{t=0} p \cdot e^{tA} \in T_pP","['differential-geometry', 'lie-groups', 'lie-algebras', 'differential', 'principal-bundles']"
24,Embedding a compact manifold in $\mathbb{R}^N$,Embedding a compact manifold in,\mathbb{R}^N,"I have an attempt at solving the following problem. This is not so much a question asking for a solution in general, but more on how to complete my own. Let $M^n$ be a compact smooth manifold. Show that there exists an embedding of $M$ into $\mathbb{R}^N$ for some $N$ . (Recall that an embedding of smooth manifolds is a topological embedding such that each differential is injective.) My attempt: Since $M$ is compact, we can cover it by finitely many coordinate neighbourhoods $U_i$ for $i=1,\dotsc,k$ , where $\varphi_i : U_i \to \mathbb{R}^n$ are the corresponding charts. Choose a subordinate (smooth) partition of unity $\psi_i : M \to \mathbb{R}$ . Then the functions $$ f_i := \psi_i \cdot \varphi_i$$ are smooth, where we interpret $\varphi$ as being zero outside of the support of $\psi$ . Now define $$ F : M \to \mathbb{R}^{n\cdot k + k} : x\mapsto (f_1(x),\dotsc,f_k(x),\psi_1(x),\dotsc,\psi_k(x)).$$ My hope was that $F$ is an embedding of smooth manifolds. For this, we verify: Injectivity . This is why the $\psi$ 's were stuck at the end of the map. If all the $\psi(x)$ 's are the same, then all the $\varphi(x)$ 's are the same, but these are local diffeomorphisms, in particular bijections. Smoothness . Trivial. Topological embedding . Immediate since $M$ is compact and $F$ is injective and continuous. Injective differentials . This is my issue. Are all the differentials injective for $F$ as defined above? Or would we need more assumptions on the covering or of the partition of unity for this to work (or for this to work more easily)?","I have an attempt at solving the following problem. This is not so much a question asking for a solution in general, but more on how to complete my own. Let be a compact smooth manifold. Show that there exists an embedding of into for some . (Recall that an embedding of smooth manifolds is a topological embedding such that each differential is injective.) My attempt: Since is compact, we can cover it by finitely many coordinate neighbourhoods for , where are the corresponding charts. Choose a subordinate (smooth) partition of unity . Then the functions are smooth, where we interpret as being zero outside of the support of . Now define My hope was that is an embedding of smooth manifolds. For this, we verify: Injectivity . This is why the 's were stuck at the end of the map. If all the 's are the same, then all the 's are the same, but these are local diffeomorphisms, in particular bijections. Smoothness . Trivial. Topological embedding . Immediate since is compact and is injective and continuous. Injective differentials . This is my issue. Are all the differentials injective for as defined above? Or would we need more assumptions on the covering or of the partition of unity for this to work (or for this to work more easily)?","M^n M \mathbb{R}^N N M U_i i=1,\dotsc,k \varphi_i : U_i \to \mathbb{R}^n \psi_i : M \to \mathbb{R}  f_i := \psi_i \cdot \varphi_i \varphi \psi  F : M \to \mathbb{R}^{n\cdot k + k} : x\mapsto (f_1(x),\dotsc,f_k(x),\psi_1(x),\dotsc,\psi_k(x)). F \psi \psi(x) \varphi(x) M F F","['differential-geometry', 'smooth-manifolds', 'compact-manifolds']"
25,Covariant derivative: QFT vs. Math,Covariant derivative: QFT vs. Math,,"In class, we have seen that the covariant derivative of some form $R$ can be written as: $$DR = dR + [A, R] = dR + A\wedge R - R\wedge A   \tag1$$ Here, $d$ represents the external derivative over forms and $A$ is the local connection defined via the pull-back of a section $S: U_i \in M \rightarrow P(M, G)$ where $P(M, G)$ is the principal bundle  with $M$ the base space and $G$ the Lie group that plays the fiber role. Therefore, $A = S^*\omega$ , with $\omega \in \Omega^1(P)\otimes T_eG$ and $\Omega^1(P)$ the set of 1-forms in $P(M, G)$ . So while $\omega$ is a connection for all $P$ , $A$ is just over $U_i$ So by Eq. (1) we can write: $$D = d + [A,\ ·\ ]  \tag2$$ Eq. (2) is pretty similar to the one used in QFT: $$D_\mu = \partial_\mu + igA_\mu   \tag3$$ $g$ is just the coupling constant of the interaction, so $igA_\mu$ is somehow equivalent to the connection $A$ of the Eq. (1). I understand that the index $\mu$ comes out from the fact that in Eq. (1) we work with forms, so $$A\sim A_\mu dx^\mu \tag4$$ But, what I don't see is how to make the relation between the commutator in Eq. (2) and the simple form $igA_\mu$ .","In class, we have seen that the covariant derivative of some form can be written as: Here, represents the external derivative over forms and is the local connection defined via the pull-back of a section where is the principal bundle  with the base space and the Lie group that plays the fiber role. Therefore, , with and the set of 1-forms in . So while is a connection for all , is just over So by Eq. (1) we can write: Eq. (2) is pretty similar to the one used in QFT: is just the coupling constant of the interaction, so is somehow equivalent to the connection of the Eq. (1). I understand that the index comes out from the fact that in Eq. (1) we work with forms, so But, what I don't see is how to make the relation between the commutator in Eq. (2) and the simple form .","R DR = dR + [A, R] = dR + A\wedge R - R\wedge A   \tag1 d A S: U_i \in M \rightarrow P(M, G) P(M, G) M G A = S^*\omega \omega \in \Omega^1(P)\otimes T_eG \Omega^1(P) P(M, G) \omega P A U_i D = d + [A,\ ·\ ]  \tag2 D_\mu = \partial_\mu + igA_\mu   \tag3 g igA_\mu A \mu A\sim A_\mu dx^\mu \tag4 igA_\mu","['differential-geometry', 'mathematical-physics', 'differential-forms', 'fiber-bundles', 'quantum-field-theory']"
26,Characteristic classes of exotic 4-manifolds,Characteristic classes of exotic 4-manifolds,,"Let $M,M'$ be homeomorphic smooth, closed, simply connected 4-manifolds. Is it necessarily true that $w_2(TM)=w_2(TM')$ and $p_1(TM)=p_1(TM')$ ? If so, the comment on this post , shows that $TM$ and $TM'$ are topologically isomorphic as vector bundles. If the above is false, how does the statement fail, i.e. do we have $w_2(TM)\neq w_2(TM')$ , or $p_1(TM)\neq p_1(TM')$ , or both?","Let be homeomorphic smooth, closed, simply connected 4-manifolds. Is it necessarily true that and ? If so, the comment on this post , shows that and are topologically isomorphic as vector bundles. If the above is false, how does the statement fail, i.e. do we have , or , or both?","M,M' w_2(TM)=w_2(TM') p_1(TM)=p_1(TM') TM TM' w_2(TM)\neq w_2(TM') p_1(TM)\neq p_1(TM')","['differential-geometry', 'algebraic-topology', 'differential-topology', 'smooth-manifolds']"
27,Volume in cone segment bent from rectangle.,Volume in cone segment bent from rectangle.,,"A flexible rectangle sheet size $(a,b),a>b $ is folded half  along side $a$ and glued to make a circular cone cut segment of vertex angle $60^{\circ}$ as shown with three edges $(b,a,b).$ ( $60^{\circ}$ choice for cone apex angle deformation arises due to maximum volume created by internal pressure at $90^{\circ}$ corner obtained by maintaining second order continuity along a line perpendicular to glue line.) After bending distorted edges $(a,b)$ are curved/mapped as conical helices with Clairaut minimal radii nearer to cone vertex as $ (r_a,r_b)= (a/4,b).$ The cone surface is a single boat shaped nappe. Calculate bent area to verify $A= ab $ conserved due to isometry. Calculate volume enclosed by parallel displacement of edge $AB$ (skew perpendicular to cone axis) along the helices. It refers to Jack D'Aurizio A4 paper sheet bent volume problem with two nappes.","A flexible rectangle sheet size $(a,b),a>b $ is folded half  along side $a$ and glued to make a circular cone cut segment of vertex angle $60^{\circ}$ as shown with three edges $(b,a,b).$ ( $60^{\circ}$ choice for cone apex angle deformation arises due to maximum volume created by internal pressure at $90^{\circ}$ corner obtained by maintaining second order continuity along a line perpendicular to glue line.) After bending distorted edges $(a,b)$ are curved/mapped as conical helices with Clairaut minimal radii nearer to cone vertex as $ (r_a,r_b)= (a/4,b).$ The cone surface is a single boat shaped nappe. Calculate bent area to verify $A= ab $ conserved due to isometry. Calculate volume enclosed by parallel displacement of edge $AB$ (skew perpendicular to cone axis) along the helices. It refers to Jack D'Aurizio A4 paper sheet bent volume problem with two nappes.",,"['differential-geometry', 'recreational-mathematics']"
28,Show that a $k$-form $\omega$ is smooth if only if it is smooth as map $\omega : M\rightarrow \Lambda ^k(M)$,Show that a -form  is smooth if only if it is smooth as map,k \omega \omega : M\rightarrow \Lambda ^k(M),Let $M$ be a smooth manifold. Consider $\Lambda ^k(M)=\bigcup_{p\in M}\Lambda ^k(T_{p}M)$ with the natural smooth structure. With this structure I showed that the $\pi :\Lambda ^k(M)\rightarrow M$ projection is smooth. Show that a $k$-form $\omega$ is smooth if only if it is smooth as map $\omega : M\rightarrow \Lambda ^k(M)$.,Let $M$ be a smooth manifold. Consider $\Lambda ^k(M)=\bigcup_{p\in M}\Lambda ^k(T_{p}M)$ with the natural smooth structure. With this structure I showed that the $\pi :\Lambda ^k(M)\rightarrow M$ projection is smooth. Show that a $k$-form $\omega$ is smooth if only if it is smooth as map $\omega : M\rightarrow \Lambda ^k(M)$.,,"['differential-geometry', 'smooth-manifolds', 'differential-forms']"
29,How does the Chern number relate to the Gauss-Bonnet theorem?,How does the Chern number relate to the Gauss-Bonnet theorem?,,"I am a physicist so I am sorry if my question is not rigorous enough. We use the concept of a topological invariant named Chern number, and it is an integer. I have seen people relating it to the Euler characteristic. They say that it has to do with the generalization of the Gauss-Bonnet theorem, namely the Gauss-Bonnet-Chern theorem although I can't see exactly how. How can one go from the Gauss-Bonnet-Chern theorem, if we apply it to a 2D manifold, to the classic Gauss-Bonnet theorem?","I am a physicist so I am sorry if my question is not rigorous enough. We use the concept of a topological invariant named Chern number, and it is an integer. I have seen people relating it to the Euler characteristic. They say that it has to do with the generalization of the Gauss-Bonnet theorem, namely the Gauss-Bonnet-Chern theorem although I can't see exactly how. How can one go from the Gauss-Bonnet-Chern theorem, if we apply it to a 2D manifold, to the classic Gauss-Bonnet theorem?",,"['differential-geometry', 'differential-topology']"
30,soft question - differential geometry and topology book recommendations,soft question - differential geometry and topology book recommendations,,"I just need a few book recommendations for studying on my own. I know the basics (trig, calc, etc.) and on my free time, I studied multivariable and vector calculus, in addition to differential equations.  I am now trying to go into the fields of differential geometry/manifolds/topology, etc. Can you guys recommend me some books on my level? If you need me to tell you further what I already studied, please comment. Thanks in advance.","I just need a few book recommendations for studying on my own. I know the basics (trig, calc, etc.) and on my free time, I studied multivariable and vector calculus, in addition to differential equations.  I am now trying to go into the fields of differential geometry/manifolds/topology, etc. Can you guys recommend me some books on my level? If you need me to tell you further what I already studied, please comment. Thanks in advance.",,"['differential-geometry', 'reference-request', 'soft-question', 'reference-works']"
31,Possible conditions on subsets of Euclidean space to be embedded submanifolds,Possible conditions on subsets of Euclidean space to be embedded submanifolds,,"Consider a locally connected $X\subset \mathbb R^n$. Given a point $p\in X$, consider the following condition: For any $a,b\in X$, if there's a path $a\to p\to b$ in $X$, there is also a smooth path $a\to p \to b$ in $X$ with nonzero derivative at $p$ (at least once). I think this condition may express that $X\subset\mathbb R^n$ is smooth at $p$. Every point $p$ of Euclidean space satisfies this property since e.g the circle going through points $a,b,p$ furnishes a smooth path $a\to p\to b$. Consequently I think every point of an embedded manifold $X\subset\mathbb R^n$ satisfies this condition. Question. Does this characterize manifolds embedded in Euclidean space? That is, if $X\subset \mathbb R^n$ is a locally connected subset whose every point satisfies the above condition, does it follow $X$ is an embedded manifold? Added. Eric Wofsey's answer helped me realize I would like to assume $X$ is additionally locally Euclidean. His comment provides a counterexample to this case, namely the wedge in $\mathbb R^3$ formed by folding a rectangle along a line. This comment outlines the problem with the condition of my question. I have asked a follow-up question here .","Consider a locally connected $X\subset \mathbb R^n$. Given a point $p\in X$, consider the following condition: For any $a,b\in X$, if there's a path $a\to p\to b$ in $X$, there is also a smooth path $a\to p \to b$ in $X$ with nonzero derivative at $p$ (at least once). I think this condition may express that $X\subset\mathbb R^n$ is smooth at $p$. Every point $p$ of Euclidean space satisfies this property since e.g the circle going through points $a,b,p$ furnishes a smooth path $a\to p\to b$. Consequently I think every point of an embedded manifold $X\subset\mathbb R^n$ satisfies this condition. Question. Does this characterize manifolds embedded in Euclidean space? That is, if $X\subset \mathbb R^n$ is a locally connected subset whose every point satisfies the above condition, does it follow $X$ is an embedded manifold? Added. Eric Wofsey's answer helped me realize I would like to assume $X$ is additionally locally Euclidean. His comment provides a counterexample to this case, namely the wedge in $\mathbb R^3$ formed by folding a rectangle along a line. This comment outlines the problem with the condition of my question. I have asked a follow-up question here .",,"['calculus', 'differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
32,First Chern class of the tangent bundle of the sphere starting from a Riemannian metric,First Chern class of the tangent bundle of the sphere starting from a Riemannian metric,,"I'm trying to obtain the first Chern class of the tangent bundle of $S^2$ by starting with its Riemannian metric. So, since we have $$ds^2 = r^2 \left(d \theta^2 + \sin(\theta)^2 d \phi^2    \right)\,,$$ setting $\omega^\theta = r d\theta$, $\omega^\phi = r \sin(\theta) d \phi$ and applying Cartan's structure equations yields $\omega_\theta^\phi = \cos(\theta) d\theta$ and $\Omega_\theta^\phi = - \sin(\theta) d \theta \wedge d \phi = - \Omega_\phi^\theta$. My aim now, if I understand it correctly, is to complexify the connection described by the 1-form $\omega^a_b$ so that I may obtain a new curvature $\widetilde{\Omega}$ which is the one that enters the expression of the Chern class: $$c_1 \left( TS^2\right) = \frac{1}{2\pi i} \left[  \mathrm{tr}\left( \widetilde{\Omega} \right) \right]\,.$$ My issue, however, is that I don't understand how I can determine this complexified connection, therefore any hints on how to proceed would be much appreciated.","I'm trying to obtain the first Chern class of the tangent bundle of $S^2$ by starting with its Riemannian metric. So, since we have $$ds^2 = r^2 \left(d \theta^2 + \sin(\theta)^2 d \phi^2    \right)\,,$$ setting $\omega^\theta = r d\theta$, $\omega^\phi = r \sin(\theta) d \phi$ and applying Cartan's structure equations yields $\omega_\theta^\phi = \cos(\theta) d\theta$ and $\Omega_\theta^\phi = - \sin(\theta) d \theta \wedge d \phi = - \Omega_\phi^\theta$. My aim now, if I understand it correctly, is to complexify the connection described by the 1-form $\omega^a_b$ so that I may obtain a new curvature $\widetilde{\Omega}$ which is the one that enters the expression of the Chern class: $$c_1 \left( TS^2\right) = \frac{1}{2\pi i} \left[  \mathrm{tr}\left( \widetilde{\Omega} \right) \right]\,.$$ My issue, however, is that I don't understand how I can determine this complexified connection, therefore any hints on how to proceed would be much appreciated.",,"['differential-geometry', 'connections', 'characteristic-classes']"
33,Reference request for symplectic geometry.,Reference request for symplectic geometry.,,"I wish to start learning symplectic geometry. I have taken a course in differential geometry of curves and surfaces, another in differentiable manifolds and another in algebraic topology. Please mention some books that one would take up as the first reference to symplectic geometry. Also, please mention any supplementary texts or materials one would need apart from a knowledge of differentiable manifolds to learn symplectic geometry.","I wish to start learning symplectic geometry. I have taken a course in differential geometry of curves and surfaces, another in differentiable manifolds and another in algebraic topology. Please mention some books that one would take up as the first reference to symplectic geometry. Also, please mention any supplementary texts or materials one would need apart from a knowledge of differentiable manifolds to learn symplectic geometry.",,['differential-geometry']
34,Closed geodesic on space diffeomorphic to $S^{2n}$ with positive sectional curvature always contains a conjugate point.,Closed geodesic on space diffeomorphic to  with positive sectional curvature always contains a conjugate point.,S^{2n},"For reference; a closed geodesic is a geodesic that is a closed loop that is smooth at the origin. I have been stuck on this for a few days; the only theorem I have relating to even dimension has to do with orientability, so it doesn't seem like there's anything I will be able to do with that. The fact that it is an even dimensional sphere makes it seem like I may have to use the fact that there is no non-vanishing vector field, but I am not sure how to make this work. Is it possible I can have some hints?","For reference; a closed geodesic is a geodesic that is a closed loop that is smooth at the origin. I have been stuck on this for a few days; the only theorem I have relating to even dimension has to do with orientability, so it doesn't seem like there's anything I will be able to do with that. The fact that it is an even dimensional sphere makes it seem like I may have to use the fact that there is no non-vanishing vector field, but I am not sure how to make this work. Is it possible I can have some hints?",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
35,Reference request for Minimal Surfaces.,Reference request for Minimal Surfaces.,,"I need books or articles based on minimal surfaces. By minimal surface, I mean a surface with 0 mean curvature. More specifically, I wish to explore the Plateau's Problem: There exists a minimal surface with a given boundary. I would also like to see a proof of the fact that a surface of revolution that is minimal is either a plane, helicoid or a catenoid. As a supplementary text, could I also have a reference for calculus of variations? (Unimportant, but why is calculus of variations not taught as a course in universities?) Thank you for your time.","I need books or articles based on minimal surfaces. By minimal surface, I mean a surface with 0 mean curvature. More specifically, I wish to explore the Plateau's Problem: There exists a minimal surface with a given boundary. I would also like to see a proof of the fact that a surface of revolution that is minimal is either a plane, helicoid or a catenoid. As a supplementary text, could I also have a reference for calculus of variations? (Unimportant, but why is calculus of variations not taught as a course in universities?) Thank you for your time.",,"['differential-geometry', 'reference-request']"
36,Pulling back (affine or not) connections,Pulling back (affine or not) connections,,"Suppose that $f:M \to N$ is a smooth map of two manifolds and $E$ is a vector bundle over $N$. Given a connecton $\nabla$ on $E$ one can pull it back to $f^*N$ (which is a bundle over $M$) and obtain a connection $f^* \nabla$. If $E=TN$ is a tangent bundle one can consider the Levi-Civita connection $\nabla$, with respect to the chosen metric $g$ on $N$. It is characterised uniquely as torsion free metric connection. Given a map $f:M \to N$ one can pullback the metric $g$ to $f^*g$. If it happens that $f^*g$ is again a metric (which is the case for example for immersions ) one can consider the Levi Civita connection on $M$ with respect to $f^*g$. I wonder how these two constructions are related, in particular Is there a way to pullback affine connections to get again affine connection (i.e. connections on tangent bundle)? Additionally I would like to know: What is the relation between Christoffels symbols for the connection and for its pullback?","Suppose that $f:M \to N$ is a smooth map of two manifolds and $E$ is a vector bundle over $N$. Given a connecton $\nabla$ on $E$ one can pull it back to $f^*N$ (which is a bundle over $M$) and obtain a connection $f^* \nabla$. If $E=TN$ is a tangent bundle one can consider the Levi-Civita connection $\nabla$, with respect to the chosen metric $g$ on $N$. It is characterised uniquely as torsion free metric connection. Given a map $f:M \to N$ one can pullback the metric $g$ to $f^*g$. If it happens that $f^*g$ is again a metric (which is the case for example for immersions ) one can consider the Levi Civita connection on $M$ with respect to $f^*g$. I wonder how these two constructions are related, in particular Is there a way to pullback affine connections to get again affine connection (i.e. connections on tangent bundle)? Additionally I would like to know: What is the relation between Christoffels symbols for the connection and for its pullback?",,"['differential-geometry', 'riemannian-geometry', 'vector-bundles', 'connections', 'tangent-bundle']"
37,Lorentz Transformations Vs Coordinate Transformations,Lorentz Transformations Vs Coordinate Transformations,,"I'm really confused about Lorentz transformations at the moment. In most books on QFT, Special Relativity or Electrodynamics, people talk about Lorentz transformations as some kind of special coordinate transformation that leaves the metric invariant and then they define what they call the Lorentz scalars. But from my point of view (which is somehow grounded in a background from differential geometry), scalars and the metric, which is a tensor, are invariant under any ""good"" coordinate transformation and that's a lot more than just Lorentz transformations, so I don't see why there's a special role for the Lorentz transformations in special relativity. Saying that the metric is invariant under Lorentz transformations is non-sense to me, because indeed it should be under any type of coordinate transformation if it's a well defined metric on a Minkowski manifold. It seems to me that Lorentz transformations should be relating observers (frames) and not coordinate systems - that would make more sense to me, but usually people mix both concepts as if they were exactly the same. I'd like to understand what it means when one says that some scalar is Lorentz invariant. If someone could clarify me this conceptual confusion, I would be really grateful.","I'm really confused about Lorentz transformations at the moment. In most books on QFT, Special Relativity or Electrodynamics, people talk about Lorentz transformations as some kind of special coordinate transformation that leaves the metric invariant and then they define what they call the Lorentz scalars. But from my point of view (which is somehow grounded in a background from differential geometry), scalars and the metric, which is a tensor, are invariant under any ""good"" coordinate transformation and that's a lot more than just Lorentz transformations, so I don't see why there's a special role for the Lorentz transformations in special relativity. Saying that the metric is invariant under Lorentz transformations is non-sense to me, because indeed it should be under any type of coordinate transformation if it's a well defined metric on a Minkowski manifold. It seems to me that Lorentz transformations should be relating observers (frames) and not coordinate systems - that would make more sense to me, but usually people mix both concepts as if they were exactly the same. I'd like to understand what it means when one says that some scalar is Lorentz invariant. If someone could clarify me this conceptual confusion, I would be really grateful.",,"['differential-geometry', 'coordinate-systems', 'general-relativity', 'semi-riemannian-geometry']"
38,Tangent bundle of a manifold as more than a vector bundle,Tangent bundle of a manifold as more than a vector bundle,,"Let $M$ be a smooth manifold.  The tangent bundle is naturally a smooth vector bundle, but it obviously has more structure than that.  Specifically, there is a natural action of the the diffeomorphism group of $M$ on $TM$.  Unless I am mistaken, this action is what distinguishes $TM$ it from an isomorphic vector bundle (e.g., the cotangent bundle of $M$).  A similar question could be asked for the bundle of $n$-forms and the bundle of densities on an orientable $n$-manifold. Both should be trivial line bundles, but the action should be different. My question is what are good ways to think about this additional structure and does it have a name?  The less category theory the better.","Let $M$ be a smooth manifold.  The tangent bundle is naturally a smooth vector bundle, but it obviously has more structure than that.  Specifically, there is a natural action of the the diffeomorphism group of $M$ on $TM$.  Unless I am mistaken, this action is what distinguishes $TM$ it from an isomorphic vector bundle (e.g., the cotangent bundle of $M$).  A similar question could be asked for the bundle of $n$-forms and the bundle of densities on an orientable $n$-manifold. Both should be trivial line bundles, but the action should be different. My question is what are good ways to think about this additional structure and does it have a name?  The less category theory the better.",,['differential-geometry']
39,Reference Request: Algebraic Topology and Geometry with External Motivation,Reference Request: Algebraic Topology and Geometry with External Motivation,,"Taking a year off before beginning JD/PhD studies.  Planning to review/extend my understanding of modern math.  Despite being able to successfully and contentfully work problems from Rudin, Folland, etc., I have always struggled to learn from the canonical algebra and geometry books (Dummit, Hatcher, etc.). The problem doesnt seem to be ""local:""  there are no specific tricks on particular pages that I can point to that I ""dont get.""  It seems ""global:""  when reading on analytic topics, thoughts on applications -- if even indirect ones (that is, applications of a collection theories to a more applied branch of mathematics) -- are integral to my efforts; I tend to struggle to find direct and indirect applications of apparent import in algebra and topology. I believe one way to remedy that fact in learning about algebra proper is to focus on linear algebra and its generalizations:  books by hoffman, artin, maclane, etc. seem, after only a cursory look though, much more intriguing to me; it is easier for me to get excited about working the exercises therein.  I would like to ask your help in finding suitable perspectives from which to study algebraic topology and geometry, along with reference requests. I have the suspicion that focusing on the differential aspects of things might be the right direction, but it is tough to find comprehensive advice about what such a curriculum would look like.  Based on some cursory reading and comments below, 3 options present themselves so far:  spivaks DG1 then narishmans complex analysis, lees manifolds and geometry, or tus manifolds and forms.  May I ask your help in comparing those 3 options (coverage? exposition quality?  typo quantity?), or recommending additional resources? In a comment I was a bit more succinct/explicit about what I am looking for: a motivated introduction to a bit of modern geometry, whereby motivated I mean either A) something where I can point directly to an area of mainstream physics or economics and say, ""this will be useful here,"" or B) something where I can point indirectly to an area of mathematics where A obviously holds (differential equations, probability theory, etc.). ANSWER: From the answers, comments, and elsewhere, it seems that some mix of John Lee and Loring Tu's books have a sufficient smattering of the algebraic side of things to get a feel for modern geometry, with enough grounding in the differential side of things so that the usefulness of the material in applied math is readily apparent.  Given the time constraints and the level of difficulty of the available suggestions, algebraic geometry will be omitted (this includes even things like several complex variables by Narishman which discuss the topic tangentially) as will traditional graduate algebraic topology (hatcher, rotman, etc.).","Taking a year off before beginning JD/PhD studies.  Planning to review/extend my understanding of modern math.  Despite being able to successfully and contentfully work problems from Rudin, Folland, etc., I have always struggled to learn from the canonical algebra and geometry books (Dummit, Hatcher, etc.). The problem doesnt seem to be ""local:""  there are no specific tricks on particular pages that I can point to that I ""dont get.""  It seems ""global:""  when reading on analytic topics, thoughts on applications -- if even indirect ones (that is, applications of a collection theories to a more applied branch of mathematics) -- are integral to my efforts; I tend to struggle to find direct and indirect applications of apparent import in algebra and topology. I believe one way to remedy that fact in learning about algebra proper is to focus on linear algebra and its generalizations:  books by hoffman, artin, maclane, etc. seem, after only a cursory look though, much more intriguing to me; it is easier for me to get excited about working the exercises therein.  I would like to ask your help in finding suitable perspectives from which to study algebraic topology and geometry, along with reference requests. I have the suspicion that focusing on the differential aspects of things might be the right direction, but it is tough to find comprehensive advice about what such a curriculum would look like.  Based on some cursory reading and comments below, 3 options present themselves so far:  spivaks DG1 then narishmans complex analysis, lees manifolds and geometry, or tus manifolds and forms.  May I ask your help in comparing those 3 options (coverage? exposition quality?  typo quantity?), or recommending additional resources? In a comment I was a bit more succinct/explicit about what I am looking for: a motivated introduction to a bit of modern geometry, whereby motivated I mean either A) something where I can point directly to an area of mainstream physics or economics and say, ""this will be useful here,"" or B) something where I can point indirectly to an area of mathematics where A obviously holds (differential equations, probability theory, etc.). ANSWER: From the answers, comments, and elsewhere, it seems that some mix of John Lee and Loring Tu's books have a sufficient smattering of the algebraic side of things to get a feel for modern geometry, with enough grounding in the differential side of things so that the usefulness of the material in applied math is readily apparent.  Given the time constraints and the level of difficulty of the available suggestions, algebraic geometry will be omitted (this includes even things like several complex variables by Narishman which discuss the topic tangentially) as will traditional graduate algebraic topology (hatcher, rotman, etc.).",,"['differential-geometry', 'algebraic-geometry', 'reference-request', 'algebraic-topology']"
40,About a Morse function on the euclidean $n$-sphere.,About a Morse function on the euclidean -sphere.,n,"If you are in a hurry feel free to jump directly to the emphasized parts. Setup. Let $A$ be a real invertible symmetric square matrix of size $n+1$ whose eigenvalues are: $$\lambda_0>\lambda_1>\cdots>\lambda_n.$$ Let $\{v_0,\ldots,v_n\}$ be an orthonormal basis of $\mathbb{R}^{n+1}$ formed by eigenvectors of $A$ with $v_i$ associated to $\lambda_i$. From now all vectors of $\mathbb{R}^{n+1}$ will be written in this basis, namely, one has: $$(x_0,\ldots,x_n):=x_iv^i.$$ Furthermore, let $F\colon\mathbb{S}^n\rightarrow\mathbb{R}$ defined by: $$F(x):={}^\intercal xAx.$$ Proposition. $F$ defines a Morse function on $\mathbb{S}^n$. I have already computed the critical points of $F$, there set is $\{\pm v_0,\cdots,\pm v_n\}$, namely, one has: $$\textrm{Crit}(F)=\{(\pm 1,0,\ldots,0),(0,\pm 1,0,\ldots,0),\ldots,(0,\ldots,0,\pm 1)\}.$$ Let $x\in\textrm{Crit}(F)$ and let $\varphi$ a chart of $\mathbb{S}^n$ centered at $x$, I am supposed to prove that: $$\textrm{Hess}_0(F\circ\varphi^{-1})\in\textrm{GL}_{n+1}(\mathbb{R}).$$ I have been strongly advised to use the following charts: $$U_p^{\pm}:=\{x\in\mathbb{S}^n;\pm x_p>0\},\varphi_p^{\pm}\colon x\mapsto\left(\frac{x_i}{x_p}\right)_{i\in\{0,\ldots,n\}\setminus\{p\}}.$$ I have computed the inverse of $\varphi_p^{\pm}$ and found that: $$(\varphi_p^{\pm})^{-1}(x):=\frac{\pm 1}{\sqrt{1+\sum\limits_{i=0}^{n-1}{x_i}^2}}(x_0,\cdots,x_{p-1},1,x_p,\ldots,x_{n-1}).$$ Therefore, one has: $$F\circ(\varphi_p^{\pm})^{-1}(x)=\frac{\lambda_p+\sum\limits_{i=0}^{p-1}\lambda_i{x_i}^2+\sum\limits_{j=p}^{n-1}\lambda_{j+1}{x_j}^2}{1+\sum\limits_{i=0}^{n-1}{x_i}^2}.$$ Questions. I do not feel too confident in the above expression, I do not like those $1$ and $\lambda_p$ being apart. Can someone tell me if have made a mistake in my computations? I can see that $\textrm{Hess}_{0}(F\circ{\varphi_p^{\pm}}^{-1})$ will be diagonal and therefore the index of the critical point $\pm v_p$ will be easy to compute, but is there a clever way to conduct the computations? Any help will be greatly appreciated.","If you are in a hurry feel free to jump directly to the emphasized parts. Setup. Let $A$ be a real invertible symmetric square matrix of size $n+1$ whose eigenvalues are: $$\lambda_0>\lambda_1>\cdots>\lambda_n.$$ Let $\{v_0,\ldots,v_n\}$ be an orthonormal basis of $\mathbb{R}^{n+1}$ formed by eigenvectors of $A$ with $v_i$ associated to $\lambda_i$. From now all vectors of $\mathbb{R}^{n+1}$ will be written in this basis, namely, one has: $$(x_0,\ldots,x_n):=x_iv^i.$$ Furthermore, let $F\colon\mathbb{S}^n\rightarrow\mathbb{R}$ defined by: $$F(x):={}^\intercal xAx.$$ Proposition. $F$ defines a Morse function on $\mathbb{S}^n$. I have already computed the critical points of $F$, there set is $\{\pm v_0,\cdots,\pm v_n\}$, namely, one has: $$\textrm{Crit}(F)=\{(\pm 1,0,\ldots,0),(0,\pm 1,0,\ldots,0),\ldots,(0,\ldots,0,\pm 1)\}.$$ Let $x\in\textrm{Crit}(F)$ and let $\varphi$ a chart of $\mathbb{S}^n$ centered at $x$, I am supposed to prove that: $$\textrm{Hess}_0(F\circ\varphi^{-1})\in\textrm{GL}_{n+1}(\mathbb{R}).$$ I have been strongly advised to use the following charts: $$U_p^{\pm}:=\{x\in\mathbb{S}^n;\pm x_p>0\},\varphi_p^{\pm}\colon x\mapsto\left(\frac{x_i}{x_p}\right)_{i\in\{0,\ldots,n\}\setminus\{p\}}.$$ I have computed the inverse of $\varphi_p^{\pm}$ and found that: $$(\varphi_p^{\pm})^{-1}(x):=\frac{\pm 1}{\sqrt{1+\sum\limits_{i=0}^{n-1}{x_i}^2}}(x_0,\cdots,x_{p-1},1,x_p,\ldots,x_{n-1}).$$ Therefore, one has: $$F\circ(\varphi_p^{\pm})^{-1}(x)=\frac{\lambda_p+\sum\limits_{i=0}^{p-1}\lambda_i{x_i}^2+\sum\limits_{j=p}^{n-1}\lambda_{j+1}{x_j}^2}{1+\sum\limits_{i=0}^{n-1}{x_i}^2}.$$ Questions. I do not feel too confident in the above expression, I do not like those $1$ and $\lambda_p$ being apart. Can someone tell me if have made a mistake in my computations? I can see that $\textrm{Hess}_{0}(F\circ{\varphi_p^{\pm}}^{-1})$ will be diagonal and therefore the index of the critical point $\pm v_p$ will be easy to compute, but is there a clever way to conduct the computations? Any help will be greatly appreciated.",,"['differential-geometry', 'spheres', 'morse-theory', 'hessian-matrix']"
41,Realizing smooth curves as geodesics,Realizing smooth curves as geodesics,,"Given a smooth manifold $M$ and any smooth curve $C\subset M$, can we always find a Riemannian metric $g$ on $M$ for which the curve is a geodesic (in the variational sense)? Going further, if not, what is a necessary and sufficient condition for $C$ to be realized as a geodesic in this sense?","Given a smooth manifold $M$ and any smooth curve $C\subset M$, can we always find a Riemannian metric $g$ on $M$ for which the curve is a geodesic (in the variational sense)? Going further, if not, what is a necessary and sufficient condition for $C$ to be realized as a geodesic in this sense?",,"['differential-geometry', 'riemannian-geometry']"
42,"Proof of formula for the the divergence of a totally anti-symmetric rank (2,0) tensor","Proof of formula for the the divergence of a totally anti-symmetric rank (2,0) tensor",,"I would like to prove that $$\nabla_\mu T^{\mu \nu} = \frac{1}{\sqrt{|g|}}\partial_\mu\left(\sqrt{|g|}T^{\mu\nu}\right)$$ Given that $T^{\mu\nu}$ is totally anti-symmetric. I know that $$\nabla_\mu T^{\mu\nu} = \partial_\mu T^{\mu\nu} + \Gamma^{\mu}_{\mu\rho}T^{\rho\nu} + \Gamma^{\nu}_{\mu\rho}T^{\mu\rho}$$ and that $$\Gamma^{\mu}_{\mu\rho} = \partial_\mu \ln\sqrt{|g|}$$. So my idea is to eliminate the term $\Gamma^{\nu}_{\mu\rho}T^{\mu\rho}$ and apply the above formula, however I am having difficulties to do so. I suspect I have to take advantage of the anti-symmetry of $T^{\mu\nu}$. Any help in working this out would be appreciated.","I would like to prove that $$\nabla_\mu T^{\mu \nu} = \frac{1}{\sqrt{|g|}}\partial_\mu\left(\sqrt{|g|}T^{\mu\nu}\right)$$ Given that $T^{\mu\nu}$ is totally anti-symmetric. I know that $$\nabla_\mu T^{\mu\nu} = \partial_\mu T^{\mu\nu} + \Gamma^{\mu}_{\mu\rho}T^{\rho\nu} + \Gamma^{\nu}_{\mu\rho}T^{\mu\rho}$$ and that $$\Gamma^{\mu}_{\mu\rho} = \partial_\mu \ln\sqrt{|g|}$$. So my idea is to eliminate the term $\Gamma^{\nu}_{\mu\rho}T^{\mu\rho}$ and apply the above formula, however I am having difficulties to do so. I suspect I have to take advantage of the anti-symmetry of $T^{\mu\nu}$. Any help in working this out would be appreciated.",,"['differential-geometry', 'tensors']"
43,Understanding the distance metric for a 3D space of uniform positive curvature.,Understanding the distance metric for a 3D space of uniform positive curvature.,,"I am reading a cosmology textbook, and the distance metrics for three dimensional spaces exhibiting various curvatures are being presented. My question is about their treatment of a three dimensional space under unifom positive curvature : In polar coordinates, on the two dimensional surface of a sphere, we can express the distance $d\ell$ between two points as a function in their separation in the radial coordinate $r$, and $d\ell^2 = dr^2 + R^2\sin^2(r/R)d\theta^2$ In three dimensions, this extends to $d\ell^2 = dr^2 + R^2\sin^2(r/R)[d\theta^2 + \sin^2\theta d\phi^2]$. Now, my texbook asserts that when the two points whose separation we are measuring are at antipolar locations, we have $r = \pi R \rightarrow r/R=\pi$, which gives $sin^2(r/R) = 0\rightarrow d\ell^2 = dr^2$. But this makes no sense to me. This isn't how spherical coordinates work at all, right...? If I have two point at antipolar points on a sphere, and I measure each of their $r$ coordinates (the length to the point along a line forming angles $\theta$ and $\phi$ from the $z$ and $x$ axes, respectively) as $r_1$ and $r_2$, then shoudln't their separation $dr = |r_1-r_2|$ simply be $2R$? This would mean that $r/R = 2 \neq \pi$ Claiming that $r/R = \pi$ implies that $r$ refers to the actual path length between the points along the surface of the sphere, which is not how spherical coordinates work. Is my error in applying these spherical coordinates to a two dimensional sphere surface, when I am supposed to be thinking about the three dimensional surface under uniform positive curvature? I.e. the image I have in my head of how spherical coordinates work in this context is all wrong, or at least my placement of the points? I am picturing a ""three dimensional space under uniform positive curvature"" as a sphere, like the Earth. But that isn't right, is it? That is just me imagining a 2D surface being curved into a third dimension, when the more accurate analog is to somehow imagine a 3D space being ""curved"" into a fourth dimension?","I am reading a cosmology textbook, and the distance metrics for three dimensional spaces exhibiting various curvatures are being presented. My question is about their treatment of a three dimensional space under unifom positive curvature : In polar coordinates, on the two dimensional surface of a sphere, we can express the distance $d\ell$ between two points as a function in their separation in the radial coordinate $r$, and $d\ell^2 = dr^2 + R^2\sin^2(r/R)d\theta^2$ In three dimensions, this extends to $d\ell^2 = dr^2 + R^2\sin^2(r/R)[d\theta^2 + \sin^2\theta d\phi^2]$. Now, my texbook asserts that when the two points whose separation we are measuring are at antipolar locations, we have $r = \pi R \rightarrow r/R=\pi$, which gives $sin^2(r/R) = 0\rightarrow d\ell^2 = dr^2$. But this makes no sense to me. This isn't how spherical coordinates work at all, right...? If I have two point at antipolar points on a sphere, and I measure each of their $r$ coordinates (the length to the point along a line forming angles $\theta$ and $\phi$ from the $z$ and $x$ axes, respectively) as $r_1$ and $r_2$, then shoudln't their separation $dr = |r_1-r_2|$ simply be $2R$? This would mean that $r/R = 2 \neq \pi$ Claiming that $r/R = \pi$ implies that $r$ refers to the actual path length between the points along the surface of the sphere, which is not how spherical coordinates work. Is my error in applying these spherical coordinates to a two dimensional sphere surface, when I am supposed to be thinking about the three dimensional surface under uniform positive curvature? I.e. the image I have in my head of how spherical coordinates work in this context is all wrong, or at least my placement of the points? I am picturing a ""three dimensional space under uniform positive curvature"" as a sphere, like the Earth. But that isn't right, is it? That is just me imagining a 2D surface being curved into a third dimension, when the more accurate analog is to somehow imagine a 3D space being ""curved"" into a fourth dimension?",,['differential-geometry']
44,Uniformization of metrics vs. uniformization of Riemann surfaces,Uniformization of metrics vs. uniformization of Riemann surfaces,,"The uniformization theorem in complex analysis says that T1. Any Riemann surface of genus $0$ is conformally equivalent to the unit sphere. The uniformization theorem in differential geometry says that T2. Any smooth Riemannian metric on $S^2$ is conformal to the round metric. T2 implies that any metric $g_{ij}$ on a sphere has the form $e^\sigma (g_0)_{ij}$, where $g_0$ is the standard metric of the unit sphere. In particular, any two metrics are conformal to each other. Here are a few paradoxical statements that seem to follow from this: Cor1. Any diffeomorphism $f:S^2\to S^2$ is a holomorphic map. This is because we can use this map to define a new metric $\,f_\ast g$, but the new metric must be conformal to the old metric, therefore $f$ is a conformal map. As far as I understand, being conformal in the sense of Riemannian geometry is the same as being conformal in the sense of complex analysis (?). Obviously, this is nonsense because the only holomorphic automorphisms of $S^2$ are the Möbius transformations. Cor2. Any coordinate chart on $S^2$ is conformal for any metric. This is because the metric is proportional to some other metric, which is diagonal in these coordinates, therefore is itself diagonal. This is also obviously nonsense because locally the matrix of the metric is an arbitrary symmetric positive $2\times 2$ matrix. What am I missing, and what is the relationship between T1 and T2? If I want to deform Riemannian metrics on the sphere (no complex structure), is it indeed enough to look at just the conformal variations, or are there nontrivial quasiconformal variations?","The uniformization theorem in complex analysis says that T1. Any Riemann surface of genus $0$ is conformally equivalent to the unit sphere. The uniformization theorem in differential geometry says that T2. Any smooth Riemannian metric on $S^2$ is conformal to the round metric. T2 implies that any metric $g_{ij}$ on a sphere has the form $e^\sigma (g_0)_{ij}$, where $g_0$ is the standard metric of the unit sphere. In particular, any two metrics are conformal to each other. Here are a few paradoxical statements that seem to follow from this: Cor1. Any diffeomorphism $f:S^2\to S^2$ is a holomorphic map. This is because we can use this map to define a new metric $\,f_\ast g$, but the new metric must be conformal to the old metric, therefore $f$ is a conformal map. As far as I understand, being conformal in the sense of Riemannian geometry is the same as being conformal in the sense of complex analysis (?). Obviously, this is nonsense because the only holomorphic automorphisms of $S^2$ are the Möbius transformations. Cor2. Any coordinate chart on $S^2$ is conformal for any metric. This is because the metric is proportional to some other metric, which is diagonal in these coordinates, therefore is itself diagonal. This is also obviously nonsense because locally the matrix of the metric is an arbitrary symmetric positive $2\times 2$ matrix. What am I missing, and what is the relationship between T1 and T2? If I want to deform Riemannian metrics on the sphere (no complex structure), is it indeed enough to look at just the conformal variations, or are there nontrivial quasiconformal variations?",,"['differential-geometry', 'riemannian-geometry', 'riemann-surfaces', 'riemann-sphere']"
45,Why does orientability imply SO(n) holonomy?,Why does orientability imply SO(n) holonomy?,,"In each reference I check I am told, without proof, that orientable Riemannian manifolds have holonomy contained in SO$(n)$ by obviousness. I am sure I will feel bad about myself when I hear the answer given its alleged evidency, but this is not so clear to me (in terms of rigorous proof, the intuition is solid). I have a similar confusion for Calabi-Yau manifolds. I see CYs defined (compact) Kählers having SU$(n)$ holonomy or as Kählers having trivial canonical bundle. I see that having trivial canonical bundle implies a non-vanishing global section, but I do not see why the existence of a non-vanishing holomorphic section of the canonical bundle pushes us from U$(n)$ to SU$(n).$","In each reference I check I am told, without proof, that orientable Riemannian manifolds have holonomy contained in SO$(n)$ by obviousness. I am sure I will feel bad about myself when I hear the answer given its alleged evidency, but this is not so clear to me (in terms of rigorous proof, the intuition is solid). I have a similar confusion for Calabi-Yau manifolds. I see CYs defined (compact) Kählers having SU$(n)$ holonomy or as Kählers having trivial canonical bundle. I see that having trivial canonical bundle implies a non-vanishing global section, but I do not see why the existence of a non-vanishing holomorphic section of the canonical bundle pushes us from U$(n)$ to SU$(n).$",,['differential-geometry']
46,Is the complex tangent space closed under conjugation?,Is the complex tangent space closed under conjugation?,,"Let $D$ be a domain in $\mathbb{C}^n$ with $C^2$ boundary and let $\rho$ be a defining function for $D$.  Let $m \in \partial D$.  The complex tangent space to $\partial D$ at $m$ is $\mathcal{T}_m(\partial D) =  \{w \in \mathbb{C^n}: \sum_{i=1}^n \frac{\partial{\rho}}{\partial{z_i}}(m) w_i = 0\}$.  Is this set closed under complex conjugation; that is, if $w \in \mathcal{T}_m(\partial D)$, then is $\overline{w} \in \mathcal{T}_m(\partial D)$? $\textbf{Update}:$ Here are some facts about defining functions. A $C^2$ function $\rho$ is a defining function if $\rho = 0 $ on $\partial D$, $\rho < 0$ in D, $\rho > 0$ in $\bar{D}^c$, and $\nabla{\rho} \neq 0$ on $\partial D$. For example, if $D = B^2(0, 2)$ then a defining function is $\rho(z) = |z|^2 - 2$. It can be shown that the complex tangent space is independent of the choice  of defining function.","Let $D$ be a domain in $\mathbb{C}^n$ with $C^2$ boundary and let $\rho$ be a defining function for $D$.  Let $m \in \partial D$.  The complex tangent space to $\partial D$ at $m$ is $\mathcal{T}_m(\partial D) =  \{w \in \mathbb{C^n}: \sum_{i=1}^n \frac{\partial{\rho}}{\partial{z_i}}(m) w_i = 0\}$.  Is this set closed under complex conjugation; that is, if $w \in \mathcal{T}_m(\partial D)$, then is $\overline{w} \in \mathcal{T}_m(\partial D)$? $\textbf{Update}:$ Here are some facts about defining functions. A $C^2$ function $\rho$ is a defining function if $\rho = 0 $ on $\partial D$, $\rho < 0$ in D, $\rho > 0$ in $\bar{D}^c$, and $\nabla{\rho} \neq 0$ on $\partial D$. For example, if $D = B^2(0, 2)$ then a defining function is $\rho(z) = |z|^2 - 2$. It can be shown that the complex tangent space is independent of the choice  of defining function.",,"['differential-geometry', 'manifolds', 'complex-geometry', 'several-complex-variables', 'complex-manifolds']"
47,The Law of Cosines in Hadamard manifolds,The Law of Cosines in Hadamard manifolds,,"Let $M$ be a Hadamard manifold. Let $\Delta(p_1,p_2,p_3)$ be a geodesic triangle and for $i=1,2,3\pmod 3$ , $\gamma_i:[0,\ell_i]\to M$ be the geodesic joining $p_i$ to $p_{i+1}$ where $\ell_i=\ell(\gamma_i)$. If $\alpha_i$ is the angle between $\dot\gamma_i(0)$ and $-\dot\gamma_{i-1}(\ell_{i-1})$, then how to prove that $$\alpha_1+\alpha_2+\alpha_3\le\pi\tag{1}$$ and $$\ell_i^2+\ell_{i+1}^2-2\ell_i\ell_{i+1}\cos(\alpha_{i+1})\le\ell_{i-1}^2\tag{2}$$ I'm looked some books on Riemannian geometry but did not find a clear proof. Some references introduce this as a result of Rauch's comparison theorem but I don't have enough information and experience on Riemannian geometry, while I can understand Rauch's comparison theorem's statement but I don't know how to obtain $(1)$ and $(2)$ from this theorem, so it would be appropriate if someone here guide me and sketch a proof.","Let $M$ be a Hadamard manifold. Let $\Delta(p_1,p_2,p_3)$ be a geodesic triangle and for $i=1,2,3\pmod 3$ , $\gamma_i:[0,\ell_i]\to M$ be the geodesic joining $p_i$ to $p_{i+1}$ where $\ell_i=\ell(\gamma_i)$. If $\alpha_i$ is the angle between $\dot\gamma_i(0)$ and $-\dot\gamma_{i-1}(\ell_{i-1})$, then how to prove that $$\alpha_1+\alpha_2+\alpha_3\le\pi\tag{1}$$ and $$\ell_i^2+\ell_{i+1}^2-2\ell_i\ell_{i+1}\cos(\alpha_{i+1})\le\ell_{i-1}^2\tag{2}$$ I'm looked some books on Riemannian geometry but did not find a clear proof. Some references introduce this as a result of Rauch's comparison theorem but I don't have enough information and experience on Riemannian geometry, while I can understand Rauch's comparison theorem's statement but I don't know how to obtain $(1)$ and $(2)$ from this theorem, so it would be appropriate if someone here guide me and sketch a proof.",,"['differential-geometry', 'manifolds']"
48,What is the general formula for the Area of a 2-D surface in a 3-D manifold?,What is the general formula for the Area of a 2-D surface in a 3-D manifold?,,"Suppose we have a flat 3-D manifold $ ds^2=\delta_{ab}dx^{a}dx^{b},$ which contains a 2-D surface given by a parametric relationship $r^{a}\left(u,v\right)=x^{a}\left(u,v\right).$ Where $ u $ and $ v $ are two independent parameters. I know that the Area of this surface is the magnitude of a 3-D vector $$ dA_{a}=\varepsilon_{abc}\dfrac{\partial x^{b}}{\partial u}\dfrac{\partial x^{c}}{\partial v} du dv $$ $$dA^2=\delta^{ef}dA_{e}dA_{f}$$ How can I generalize this formula to an arbitrary 3-D manifold given by $ ds^2=g_{ab}dx^{a}dx^{b}$, where: $$ dA^2=g^{ab}dA_{b}dA_{a}? $$ That is, is it possible to write $$ dA_{a}=\kappa_{abc}\dfrac{\partial x^{b}}{\partial u}\dfrac{\partial x^{c}}{\partial v} du dv $$ and, if so, what is $\kappa_{abc}$ ?","Suppose we have a flat 3-D manifold $ ds^2=\delta_{ab}dx^{a}dx^{b},$ which contains a 2-D surface given by a parametric relationship $r^{a}\left(u,v\right)=x^{a}\left(u,v\right).$ Where $ u $ and $ v $ are two independent parameters. I know that the Area of this surface is the magnitude of a 3-D vector $$ dA_{a}=\varepsilon_{abc}\dfrac{\partial x^{b}}{\partial u}\dfrac{\partial x^{c}}{\partial v} du dv $$ $$dA^2=\delta^{ef}dA_{e}dA_{f}$$ How can I generalize this formula to an arbitrary 3-D manifold given by $ ds^2=g_{ab}dx^{a}dx^{b}$, where: $$ dA^2=g^{ab}dA_{b}dA_{a}? $$ That is, is it possible to write $$ dA_{a}=\kappa_{abc}\dfrac{\partial x^{b}}{\partial u}\dfrac{\partial x^{c}}{\partial v} du dv $$ and, if so, what is $\kappa_{abc}$ ?",,"['general-relativity', 'differential-geometry']"
49,Optimization on a Riemannian manifold,Optimization on a Riemannian manifold,,"Consider a Riemannian manifold $(M,g)$, which we assume geodesically complete. Given a smooth function $f : M \to \mathbb{R}^+$. Assume that $f$ has a global minimum on $M$. I am interested in the following optimization problem : $$ \text{Find } p^{\ast} \in \mathop{\mathrm{argmin}} \limits_{p \in M} f(p). $$ Let $\nabla^{g}f$ denote the gradient of $f$ with respect to the Riemannian metric $g$. Let $p \in M$. By definition, the gradient of $f$ at $p$, denoted by $\nabla^{g}f(p)$ is the vector in $\mathrm{T}_{p}M$ which satisfies to : $$ \forall v \in \mathrm{T}_{p}M, \, df_{p}(v) = \left\langle \nabla^{g}f(p),v \right\rangle_{p}$$ The critical points of $f$ are the points $q \in M$ such that $\nabla^{g}f(q)=0$. If $M$ was the Euclidean space $\mathbb{R}^n$, one could start by finding the critical points of $f$ and then check whether a given critical point is a minima or a maxima of $f$. My question is : why can we also proceed like this for Riemannian manifolds ? In other words : what ensures that the extrema of $f$ are among the critical points of $f$ ? Is it based on a Talyor expansion ? This point is not clear to me.","Consider a Riemannian manifold $(M,g)$, which we assume geodesically complete. Given a smooth function $f : M \to \mathbb{R}^+$. Assume that $f$ has a global minimum on $M$. I am interested in the following optimization problem : $$ \text{Find } p^{\ast} \in \mathop{\mathrm{argmin}} \limits_{p \in M} f(p). $$ Let $\nabla^{g}f$ denote the gradient of $f$ with respect to the Riemannian metric $g$. Let $p \in M$. By definition, the gradient of $f$ at $p$, denoted by $\nabla^{g}f(p)$ is the vector in $\mathrm{T}_{p}M$ which satisfies to : $$ \forall v \in \mathrm{T}_{p}M, \, df_{p}(v) = \left\langle \nabla^{g}f(p),v \right\rangle_{p}$$ The critical points of $f$ are the points $q \in M$ such that $\nabla^{g}f(q)=0$. If $M$ was the Euclidean space $\mathbb{R}^n$, one could start by finding the critical points of $f$ and then check whether a given critical point is a minima or a maxima of $f$. My question is : why can we also proceed like this for Riemannian manifolds ? In other words : what ensures that the extrema of $f$ are among the critical points of $f$ ? Is it based on a Talyor expansion ? This point is not clear to me.",,"['differential-geometry', 'optimization', 'riemannian-geometry', 'maxima-minima']"
50,Center of Lie group and Lie algebra,Center of Lie group and Lie algebra,,"Let $G$ be a Lie group and $\mathfrak{g} = T_eG$ its Lie algebra (where $e \in G$ is the neutral element). Denote $Z(\mathfrak{g})$ the center of $\mathfrak{g}$ and $Z(g)$ the center of $G$. I've read the following statement but don't see how to prove it: $$Z(\mathfrak{g}) = 0 \Longleftrightarrow Z(G) \text{ is zero dimensional.}$$ I'm mainly interested in the ""$\Leftarrow$"" direction, as this is used in a corollary of the Bonnet-Myers theorem in the text I'm reading. Now, my knowledge of Lie groups is very basic. For instance, I guess that the dimension of $Z(G)$ means its dimension as a manifold. So I would think that $Z(G)$ is a submanifold of $G$. But how do I even see this in general? According to this question When is the Lie algebra of the center of Lie group the center of its Lie algebra , it seems to be difficult to find conditions when $Z(\mathfrak{g}) = Z(G)$ holds in general, however the statement above looks more simple. Would someone be able to prove the above equivalence?","Let $G$ be a Lie group and $\mathfrak{g} = T_eG$ its Lie algebra (where $e \in G$ is the neutral element). Denote $Z(\mathfrak{g})$ the center of $\mathfrak{g}$ and $Z(g)$ the center of $G$. I've read the following statement but don't see how to prove it: $$Z(\mathfrak{g}) = 0 \Longleftrightarrow Z(G) \text{ is zero dimensional.}$$ I'm mainly interested in the ""$\Leftarrow$"" direction, as this is used in a corollary of the Bonnet-Myers theorem in the text I'm reading. Now, my knowledge of Lie groups is very basic. For instance, I guess that the dimension of $Z(G)$ means its dimension as a manifold. So I would think that $Z(G)$ is a submanifold of $G$. But how do I even see this in general? According to this question When is the Lie algebra of the center of Lie group the center of its Lie algebra , it seems to be difficult to find conditions when $Z(\mathfrak{g}) = Z(G)$ holds in general, however the statement above looks more simple. Would someone be able to prove the above equivalence?",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'riemannian-geometry']"
51,Covariant derivative fullfils Levi-Civita in Euclidean space,Covariant derivative fullfils Levi-Civita in Euclidean space,,"$\newcommand{\Reals}{\mathbf{R}}$In our lecture, when we introduced the Levi-Civita connection, we had as an example the directional derivative of a vector field $X$ in direction of another vectorfield $Y$ in $\Reals^n$ defined by $$ D_XY(p) := \lim_{t \to 0} \frac{Y(p + tX(p))-Y(p)}{t}. $$ We have written down that this definition fullfils the Levi-Civita connection definition, but actually I don't even see why it is a connection. For example why does $D_{f \cdot X}Y = f \cdot D_XY$ for an arbitrary $f \in C^{\infty}(\Reals^n)$ hold? My ideas: Interpreting p as a tangent vector one could use the $\Reals$-linearity of the vectorfield: \begin{align*} D_{f \cdot X}Y(p)   &= \lim_{t \to 0} \frac{Y(p + t(f \cdot X)(p))-Y(p)}{t} \\   &= \lim_{t \to 0} \frac{Y(p + tf(p) \cdot X(p))-Y(p)}{t} \\   &= \lim_{t \to 0} \frac{Y(p) + tf(p)Y(X(p))-Y(p)}{t} \\   &= f(p) \cdot \lim_{t \to 0} \frac{tY(X(p))}{t} \\   &= f(p) \cdot \lim_{t \to 0} \frac{Y(p + tX(p)) - Y(p)}{t} \\   &= f(p) D_X Y. \end{align*} Is that correct? Thank you a lot!","$\newcommand{\Reals}{\mathbf{R}}$In our lecture, when we introduced the Levi-Civita connection, we had as an example the directional derivative of a vector field $X$ in direction of another vectorfield $Y$ in $\Reals^n$ defined by $$ D_XY(p) := \lim_{t \to 0} \frac{Y(p + tX(p))-Y(p)}{t}. $$ We have written down that this definition fullfils the Levi-Civita connection definition, but actually I don't even see why it is a connection. For example why does $D_{f \cdot X}Y = f \cdot D_XY$ for an arbitrary $f \in C^{\infty}(\Reals^n)$ hold? My ideas: Interpreting p as a tangent vector one could use the $\Reals$-linearity of the vectorfield: \begin{align*} D_{f \cdot X}Y(p)   &= \lim_{t \to 0} \frac{Y(p + t(f \cdot X)(p))-Y(p)}{t} \\   &= \lim_{t \to 0} \frac{Y(p + tf(p) \cdot X(p))-Y(p)}{t} \\   &= \lim_{t \to 0} \frac{Y(p) + tf(p)Y(X(p))-Y(p)}{t} \\   &= f(p) \cdot \lim_{t \to 0} \frac{tY(X(p))}{t} \\   &= f(p) \cdot \lim_{t \to 0} \frac{Y(p + tX(p)) - Y(p)}{t} \\   &= f(p) D_X Y. \end{align*} Is that correct? Thank you a lot!",,"['differential-geometry', 'connections']"
52,Show that geodesic equation is given by $\ddot x^k +\Gamma_{ij}^k \dot x^i\dot x^j=0$,Show that geodesic equation is given by,\ddot x^k +\Gamma_{ij}^k \dot x^i\dot x^j=0,"I know that $\gamma $ is a geodesic if and only if $$\nabla _{\dot \gamma}\dot\gamma =0.$$ Using this, I'm trying to re find the equation $$\ddot x^k +\Gamma_{i\ell}^k \dot x^i\dot x^\ell=0,$$ but I don't get it. Let $x^1,...,x^n$ local coordinate. Then $\gamma (t)=(x^1(t),...,x^n(t))$ and $\dot\gamma (t)=\dot x^i(t)\frac{\partial }{\partial x^i}$ (using Einstein convention). Then, $$0=\nabla _{\dot \gamma (t)}\dot \gamma (t)=\nabla _{\dot x^i \frac{\partial }{\partial x^i}}\dot x^\ell \frac{\partial }{\partial x^\ell}=\dot x^i\frac{\partial \dot x^\ell}{\partial x^i}\frac{\partial }{\partial x^\ell}+\dot x^i\dot x^\ell \underbrace{\nabla _{\frac{\partial }{\partial x^i}}\frac{\partial }{\partial x^\ell}}_{=\Gamma_{i\ell}^m\frac{\partial }{\partial x^m}}$$ but I don't get the right equation. Any idea ?","I know that $\gamma $ is a geodesic if and only if $$\nabla _{\dot \gamma}\dot\gamma =0.$$ Using this, I'm trying to re find the equation $$\ddot x^k +\Gamma_{i\ell}^k \dot x^i\dot x^\ell=0,$$ but I don't get it. Let $x^1,...,x^n$ local coordinate. Then $\gamma (t)=(x^1(t),...,x^n(t))$ and $\dot\gamma (t)=\dot x^i(t)\frac{\partial }{\partial x^i}$ (using Einstein convention). Then, $$0=\nabla _{\dot \gamma (t)}\dot \gamma (t)=\nabla _{\dot x^i \frac{\partial }{\partial x^i}}\dot x^\ell \frac{\partial }{\partial x^\ell}=\dot x^i\frac{\partial \dot x^\ell}{\partial x^i}\frac{\partial }{\partial x^\ell}+\dot x^i\dot x^\ell \underbrace{\nabla _{\frac{\partial }{\partial x^i}}\frac{\partial }{\partial x^\ell}}_{=\Gamma_{i\ell}^m\frac{\partial }{\partial x^m}}$$ but I don't get the right equation. Any idea ?",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
53,Left and right invariant vector fields,Left and right invariant vector fields,,"I'm following Woodhouse's book on geometric quantization and I'm stuck with this problem. Let $R_A$ and $L_A$ be right and left invariant vector fields such that $R_A(e)=A=L_A(e)$, where $A$ is an element of Lie algebra. How can I show that $[R_A,R_B]=-R_{[A,B]}$, $[L_A,L_B]=L_{[A,B]}$ and $[R_A, L_B]=0$ ? The hint is to use BCH formula in a form: $\exp(sA) \exp(sB) \approx \exp(st[A,B]) \exp(tB) \exp(sA)$. I can differentiate this expression with respect to s and t but I don't know how to get vector field commutators from this.","I'm following Woodhouse's book on geometric quantization and I'm stuck with this problem. Let $R_A$ and $L_A$ be right and left invariant vector fields such that $R_A(e)=A=L_A(e)$, where $A$ is an element of Lie algebra. How can I show that $[R_A,R_B]=-R_{[A,B]}$, $[L_A,L_B]=L_{[A,B]}$ and $[R_A, L_B]=0$ ? The hint is to use BCH formula in a form: $\exp(sA) \exp(sB) \approx \exp(st[A,B]) \exp(tB) \exp(sA)$. I can differentiate this expression with respect to s and t but I don't know how to get vector field commutators from this.",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
54,Addition of vectors given at different points on a manifold,Addition of vectors given at different points on a manifold,,"Let's say I have a set of tangent vectors given at different points ($\vec{v}_i \in T_{p_i}(M)$) on a riemannian manifold with metric and compatible levi civita connection and I like to calculate e.g. the ""mean"" of all vectors of this set. So I need to add vectors in some sense. Now I have learned that without connection addition of vectors does not make sense since they are all defined in different tangent spaces. How does the concept of parallel transport fix ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) ? Do I understand this correctly that I define a vector addition at one point e.g. $p_1$ ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) as: Find the geodesic between $p_1$ and $p_2$ with tangent vector $\vec{v}_2$ at $p_2$ (solve this set of ODEs) and calculate the tangent vector $\vec{\hat{v}}_2$ of this curve at $p_1$ so that  at $p_1$ ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) := ($\vec{v}_1,p_1$) + ($\vec{\hat{v}}_2,p_1$) = ($\vec{v}_1+\vec{\hat{v}}_2,p_1$) Is this the correct conceptual approach or do I miss a property of the connection which makes it obvious how this should work now?","Let's say I have a set of tangent vectors given at different points ($\vec{v}_i \in T_{p_i}(M)$) on a riemannian manifold with metric and compatible levi civita connection and I like to calculate e.g. the ""mean"" of all vectors of this set. So I need to add vectors in some sense. Now I have learned that without connection addition of vectors does not make sense since they are all defined in different tangent spaces. How does the concept of parallel transport fix ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) ? Do I understand this correctly that I define a vector addition at one point e.g. $p_1$ ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) as: Find the geodesic between $p_1$ and $p_2$ with tangent vector $\vec{v}_2$ at $p_2$ (solve this set of ODEs) and calculate the tangent vector $\vec{\hat{v}}_2$ of this curve at $p_1$ so that  at $p_1$ ($\vec{v}_1,p_1$) + ($\vec{v}_2,p_2$) := ($\vec{v}_1,p_1$) + ($\vec{\hat{v}}_2,p_1$) = ($\vec{v}_1+\vec{\hat{v}}_2,p_1$) Is this the correct conceptual approach or do I miss a property of the connection which makes it obvious how this should work now?",,['differential-geometry']
55,The bundle of spin frames as an associated bundle,The bundle of spin frames as an associated bundle,,"$\DeclareMathOperator{\Spin}{Spin}$Let $X$ be an oriented smooth $n$-manifold with the frame bundle $\pi_{SO} \colon F_{SO} \to X$. Then the bundle of spin frames is a $\Spin(n)$-bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with a $2$-fold equivariant covering $\pi \colon F_{\Spin} \to F_{SO}$ such that $\pi_{\Spin} = \pi_{SO} \circ \pi$. A bundle of spin frames can be considered as a group reduction of the bundle $\pi_{SO} \colon F_{SO} \to X$ along the covering homomorphism $\Spin(n) \to SO(n)$, which is, by definition, a bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with an isomorphism of $SO(n)$-bundles $F_{\Spin} \times_{\Spin(n)} SO(n) \to F_{SO}$. My question is whether the second definition also implies the first one in the sense that any $\Spin(n)$-bundle associated to $F_{SO}$ via the covering projection $\Spin(n) \to SO(n)$ will define a spin structure (a bundle of spin frames)?","$\DeclareMathOperator{\Spin}{Spin}$Let $X$ be an oriented smooth $n$-manifold with the frame bundle $\pi_{SO} \colon F_{SO} \to X$. Then the bundle of spin frames is a $\Spin(n)$-bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with a $2$-fold equivariant covering $\pi \colon F_{\Spin} \to F_{SO}$ such that $\pi_{\Spin} = \pi_{SO} \circ \pi$. A bundle of spin frames can be considered as a group reduction of the bundle $\pi_{SO} \colon F_{SO} \to X$ along the covering homomorphism $\Spin(n) \to SO(n)$, which is, by definition, a bundle $\pi_{\Spin} \colon F_{\Spin} \to X$ together with an isomorphism of $SO(n)$-bundles $F_{\Spin} \times_{\Spin(n)} SO(n) \to F_{SO}$. My question is whether the second definition also implies the first one in the sense that any $\Spin(n)$-bundle associated to $F_{SO}$ via the covering projection $\Spin(n) \to SO(n)$ will define a spin structure (a bundle of spin frames)?",,"['differential-geometry', 'principal-bundles', 'spin-geometry']"
56,"What are the smooth map and the vector field in the Fig. 8.2, page 182 of John Lee's Smooth manifolds, 2nd","What are the smooth map and the vector field in the Fig. 8.2, page 182 of John Lee's Smooth manifolds, 2nd",,"The purpose of this figure is to show that when $F$ is not surjective, then  the differential of $F$ can't decide what vector can be assigned to the points outside of Im$F$ and when $F$ is not injective, then for some points of $N$, there may be several different vectors obtained by applying $dF$ to $X$ at different points of M. But I find it hard to make up a concrete example of such map. I know to many professional geometricians, drawing pictures is enough to give such examples, but a beginner like me is still curious about(or suspect) the existence of such a map. This explains why I want to find an explicit, written-down example. Specifically, are there a smooth vector field on $\mathbb S^1$ and a smooth map from $\mathbb S^1$ to $\mathbb R^2$ taking a unit circle to a ""figure eight"" that make trouble at the cross of ""figure eight""?(Please note that the example I want is a smooth map and a vector field defined on the whole unit circle, not just an open arc of it)","The purpose of this figure is to show that when $F$ is not surjective, then  the differential of $F$ can't decide what vector can be assigned to the points outside of Im$F$ and when $F$ is not injective, then for some points of $N$, there may be several different vectors obtained by applying $dF$ to $X$ at different points of M. But I find it hard to make up a concrete example of such map. I know to many professional geometricians, drawing pictures is enough to give such examples, but a beginner like me is still curious about(or suspect) the existence of such a map. This explains why I want to find an explicit, written-down example. Specifically, are there a smooth vector field on $\mathbb S^1$ and a smooth map from $\mathbb S^1$ to $\mathbb R^2$ taking a unit circle to a ""figure eight"" that make trouble at the cross of ""figure eight""?(Please note that the example I want is a smooth map and a vector field defined on the whole unit circle, not just an open arc of it)",,"['differential-geometry', 'smooth-manifolds']"
57,"Understanding ""trace of map"" in the definition of harmonic maps","Understanding ""trace of map"" in the definition of harmonic maps",,"I have difficulty understanding ""trace of map"" in the definition of harmonic map. Let $\phi: (M,g)\to (N,h)$ is map between two Riemannian manifolds, the energy density is defined as $$e(\phi)=\frac12trace_g\phi^*h$$ From my understanding, the trace of $\phi^*h$ is the trace of its matrix representation with basis $\{ \frac{\partial}{\partial x^i}\}$ , that is $$trace_g\phi^*h=\sum_{i=1}^m\phi^*h(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\phi_*\frac{\partial}{\partial x^i},\phi_*\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial}{\partial y^{\alpha}},\frac{\partial\phi^{\beta}}{\partial x^i}\frac{\partial}{\partial y^{\beta}})=\sum_{i=1}^m\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial\phi^{\beta}}{\partial x^i}h_{\alpha \beta}$$ One can see the reference here , that it explains that in local coordinates, the energy density can be written as: $$e(\phi)=\frac12g^{ij}h_{\alpha \beta}\frac{\partial\phi^{\alpha}}{\partial x^i} \frac{\partial\phi^{\beta}}{\partial x^j}$$ which is different with my understanding! So the trace certainly involves metric $g$ , it seems as the interpretation of $trace_g$ is to raise it up by $g^{ij}$ and regard it as a (1,1)-tensor, instead of a (0,2)-tensor. But why? Any help would be appreciated!","I have difficulty understanding ""trace of map"" in the definition of harmonic map. Let is map between two Riemannian manifolds, the energy density is defined as From my understanding, the trace of is the trace of its matrix representation with basis , that is One can see the reference here , that it explains that in local coordinates, the energy density can be written as: which is different with my understanding! So the trace certainly involves metric , it seems as the interpretation of is to raise it up by and regard it as a (1,1)-tensor, instead of a (0,2)-tensor. But why? Any help would be appreciated!","\phi: (M,g)\to (N,h) e(\phi)=\frac12trace_g\phi^*h \phi^*h \{ \frac{\partial}{\partial x^i}\} trace_g\phi^*h=\sum_{i=1}^m\phi^*h(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\phi_*\frac{\partial}{\partial x^i},\phi_*\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial}{\partial y^{\alpha}},\frac{\partial\phi^{\beta}}{\partial x^i}\frac{\partial}{\partial y^{\beta}})=\sum_{i=1}^m\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial\phi^{\beta}}{\partial x^i}h_{\alpha \beta} e(\phi)=\frac12g^{ij}h_{\alpha \beta}\frac{\partial\phi^{\alpha}}{\partial x^i} \frac{\partial\phi^{\beta}}{\partial x^j} g trace_g g^{ij}","['differential-geometry', 'riemannian-geometry', 'trace']"
58,How can I draw plane distributions in $\mathbb{R}^3$?,How can I draw plane distributions in ?,\mathbb{R}^3,"I see so many nice pictures of contact structures, integrable plane distributions, etc., in manuscripts and online and I have absolutely zero idea how they're made. For example, the following image was posted on Tumblr (source unknown): I was able to gather some information online. For instance, if I go to the Wikipedia page on Contact geometry , there's an image of a contact structure on $\mathbb{R}^3$ , the notes on which say Generated with MetaPost and Inkscape. I have some experience with Inkscape but ideally, I'd like to find a solution that can take a form (e.g. $dz - y dx$ for the Wiki picture) and automate the drawing without me having to draw a hundred little rectangle ""planes"" and manually position them, etc. I also took look through the online Mathematica documentation to see what was available there...I'm sure there's a solution out there, but without asking someone, I just can't seem to find it on my own. Any information would be hugely appreciated!","I see so many nice pictures of contact structures, integrable plane distributions, etc., in manuscripts and online and I have absolutely zero idea how they're made. For example, the following image was posted on Tumblr (source unknown): I was able to gather some information online. For instance, if I go to the Wikipedia page on Contact geometry , there's an image of a contact structure on $\mathbb{R}^3$ , the notes on which say Generated with MetaPost and Inkscape. I have some experience with Inkscape but ideally, I'd like to find a solution that can take a form (e.g. $dz - y dx$ for the Wiki picture) and automate the drawing without me having to draw a hundred little rectangle ""planes"" and manually position them, etc. I also took look through the online Mathematica documentation to see what was available there...I'm sure there's a solution out there, but without asking someone, I just can't seem to find it on my own. Any information would be hugely appreciated!",,"['differential-geometry', 'differential-topology', 'math-software', 'foliations', 'contact-topology']"
59,"Understanding the first fundamental form of a surface, how the parametrization doesn't matter.","Understanding the first fundamental form of a surface, how the parametrization doesn't matter.",,"The following is an excerpt from Pressley's Elementary Differential Geometry on the definition of the first fundamental form. However, there are some parts of this concept that I'm unclear about. It says in the bottom of this excerpt that the coefficients E,F,G and the linear maps du, dv depend on the choice of surface patch for $S$. Here, the patch is $\sigma$. But then, I don't understand how the first fundamental form is an inherent concept of the surface, that is the expression varies under different parametrizations of the same surface and the same point on it. So I can't understand why in the final line, it says ""but the first fundamental form itself depends only on $S$ and $\mathbf{p}$. So to make my question clear, there are theorems that show that the fundamental form determines many properties of different surfaces, such as surfaces that have the same fundamental form are locally isometric etc. But from what I understood from the below definition is that the first fundamental form is an expression, of which is determined by the coefficients $E, F, G$ and the linear maps $du, dv$. But these depend on the parametrization of the surface. So for the same surface and the same point on it, we can have two different expressions,say, $Edu^2+2Fdudv+Gdv^2$ and $\bar{E}d\tilde{u}^2+2\bar{F}d\tilde{u}d\tilde{v}+\bar{G}d\tilde{v}^2$. So the specific choice of parametrization seems to matter, but then how can we use this to talk about inherent properties of different surfaces? I would greatly appreciate any help to understand this.","The following is an excerpt from Pressley's Elementary Differential Geometry on the definition of the first fundamental form. However, there are some parts of this concept that I'm unclear about. It says in the bottom of this excerpt that the coefficients E,F,G and the linear maps du, dv depend on the choice of surface patch for $S$. Here, the patch is $\sigma$. But then, I don't understand how the first fundamental form is an inherent concept of the surface, that is the expression varies under different parametrizations of the same surface and the same point on it. So I can't understand why in the final line, it says ""but the first fundamental form itself depends only on $S$ and $\mathbf{p}$. So to make my question clear, there are theorems that show that the fundamental form determines many properties of different surfaces, such as surfaces that have the same fundamental form are locally isometric etc. But from what I understood from the below definition is that the first fundamental form is an expression, of which is determined by the coefficients $E, F, G$ and the linear maps $du, dv$. But these depend on the parametrization of the surface. So for the same surface and the same point on it, we can have two different expressions,say, $Edu^2+2Fdudv+Gdv^2$ and $\bar{E}d\tilde{u}^2+2\bar{F}d\tilde{u}d\tilde{v}+\bar{G}d\tilde{v}^2$. So the specific choice of parametrization seems to matter, but then how can we use this to talk about inherent properties of different surfaces? I would greatly appreciate any help to understand this.",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'differential-forms']"
60,Exterior derivative of a coordinate function,Exterior derivative of a coordinate function,,"I'm starting to learn about differential forms.  From what I understand the coordinate differential forms $dx^1, \dots, dx^n$ are actually the exterior derivatives of the coordinate functions $x^1, \dots, x^n$ (not necessarily Cartesian coordinates).  How is this shown? The only way I know how to take the exterior derivative of a function ($0$-form) $f$ is to use the formula $df = \frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$, but applying this to a coordinate function $x^1$ would give $$d(x^1) = \frac{\partial x^1}{\partial x^1}dx^1 + \cdots + \frac{\partial x^1}{\partial x^n}dx^n = dx^1$$ which is wholly unconvincing to me.  If someone showed me this proof I'd think that they'd come up with the method just because they knew what the answer should be. I think the problem is that I need a definition of the exterior derivative that doesn't already contain the coordinate functions and then I can confirm that for any arbitrary smooth $f$ the exterior derivative $df$ does in fact equal $\frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$ where $dx^i$ is the exterior derivative of the coordinate function $x^i$. So what is the rigorous way to show that the things that we expand the $1$-form $df$ in ($dx^1, \dots, dx^n$ in the usual notation) are the same things that we get be taking the exterior derivative of each coordinate function ($x^1, \dots, x^n$)?","I'm starting to learn about differential forms.  From what I understand the coordinate differential forms $dx^1, \dots, dx^n$ are actually the exterior derivatives of the coordinate functions $x^1, \dots, x^n$ (not necessarily Cartesian coordinates).  How is this shown? The only way I know how to take the exterior derivative of a function ($0$-form) $f$ is to use the formula $df = \frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$, but applying this to a coordinate function $x^1$ would give $$d(x^1) = \frac{\partial x^1}{\partial x^1}dx^1 + \cdots + \frac{\partial x^1}{\partial x^n}dx^n = dx^1$$ which is wholly unconvincing to me.  If someone showed me this proof I'd think that they'd come up with the method just because they knew what the answer should be. I think the problem is that I need a definition of the exterior derivative that doesn't already contain the coordinate functions and then I can confirm that for any arbitrary smooth $f$ the exterior derivative $df$ does in fact equal $\frac {\partial f}{\partial x^1}dx^1 + \cdots + \frac {\partial f}{\partial x^n}dx^n$ where $dx^i$ is the exterior derivative of the coordinate function $x^i$. So what is the rigorous way to show that the things that we expand the $1$-form $df$ in ($dx^1, \dots, dx^n$ in the usual notation) are the same things that we get be taking the exterior derivative of each coordinate function ($x^1, \dots, x^n$)?",,"['differential-geometry', 'differential-forms']"
61,Vector Field on the $n$-dimensional torus,Vector Field on the -dimensional torus,n,"Give examples  of vector fields on the $n$-dimensional torus. What I have done: on $S^1$ it's easy to give one example with perpendicular vectors of length $1$ rotating in one direction, and another example in the other direction. How many different vector fields are there on $S^1$? I know they are $X =$  $f$ $\cdot$ $d\over dx$ thus they should be an infinite vector space over real numbers. on $T^2$ I think we can draw the square and draw arrows in just 1 direction to get a vector field, for example all the vertical arrows of length $1$. Again, how many different vector field are there on $T^2$? on $T^n$ I think we can use that $T^n = S^1 \times \cdots \times S^1$ for $n$ times, maybe something like $X =$  $f_1$ $\cdot$ $d\over d\theta_1$ $+ \cdots +$ $f_n$ $\cdot$ $d\over d\theta_n$, but I don't know!","Give examples  of vector fields on the $n$-dimensional torus. What I have done: on $S^1$ it's easy to give one example with perpendicular vectors of length $1$ rotating in one direction, and another example in the other direction. How many different vector fields are there on $S^1$? I know they are $X =$  $f$ $\cdot$ $d\over dx$ thus they should be an infinite vector space over real numbers. on $T^2$ I think we can draw the square and draw arrows in just 1 direction to get a vector field, for example all the vertical arrows of length $1$. Again, how many different vector field are there on $T^2$? on $T^n$ I think we can use that $T^n = S^1 \times \cdots \times S^1$ for $n$ times, maybe something like $X =$  $f_1$ $\cdot$ $d\over d\theta_1$ $+ \cdots +$ $f_n$ $\cdot$ $d\over d\theta_n$, but I don't know!",,['differential-geometry']
62,The corner of the squre,The corner of the squre,,"A square is a topological manifold with boundary but not a smooth manifold with boundary because of its corners. But I am confused about it. I think since for a specific corner $p$, there is only one chart to cover $P$ (in order to be compatible), say $(U,f)$ , thus in the NBHD of $P$ the transition maps can only be $ff^{-1},f^{-1}f$, so the charts are compatible, so a square has a smooth structure. I feel confused about it. Could you tell me where I went wrong? Thank you!","A square is a topological manifold with boundary but not a smooth manifold with boundary because of its corners. But I am confused about it. I think since for a specific corner $p$, there is only one chart to cover $P$ (in order to be compatible), say $(U,f)$ , thus in the NBHD of $P$ the transition maps can only be $ff^{-1},f^{-1}f$, so the charts are compatible, so a square has a smooth structure. I feel confused about it. Could you tell me where I went wrong? Thank you!",,"['differential-geometry', 'smooth-manifolds', 'manifolds-with-boundary']"
63,A homological perspective on the Hodge-theorem,A homological perspective on the Hodge-theorem,,"Let $M$ be a smooth oriented manifold of dimension $n$. Let $(\mathcal{A} ^*(M),d)$ be the chain complex of differential forms on $M$. Endowing $M$ with an inner product gives us a hodge star operator which we could use to define the codiferential: $$\delta : \mathcal{A} ^{k}(M) \to \mathcal{A} ^{k-1}(M), \delta: \omega \mapsto (-1)^k \star^{-1}d\star\omega $$ This gives a chain complex $(\mathcal{A} ^*(M),\delta)$. We can now define the laplacian as $\triangle = d \delta + \delta d$. As a chain map, $\triangle : \mathcal{A}^*(M) \to \mathcal{A}^*(M)$ is null homotopic by constrution. By the exterior algebra functor I mean the functor that takes vector bundles over a manifold to their corresponding exterior algebra bundles. 1. Does there exist a map $\varphi: \Gamma(T^*M) \to  \Gamma(T^*M)$ s.t. under the exterior algebra functor the induced map between graded algebras is $\triangle$? To prove the Hodge theorem all we need to do is show that $i: Ker(\triangle) \to \mathcal{A}^*(M)$ is a quasi-isomorphism. From homological algebra we know that the chain map $i$ is a quasi-isomorphism iff its cone $Cone(i)$ is acyclic. 2. What properties should $\varphi: \Gamma (T^*M) \to  \Gamma(T^*M)$ posses to induce a map whose kernel has an acyclic cone? Could the hodge theorem be proved in this way? i.e. by exhibiting some function $\varphi$ satisfying (1) and proving that it posses (2)? (the latter part will no doubt involve some functional anaysis).","Let $M$ be a smooth oriented manifold of dimension $n$. Let $(\mathcal{A} ^*(M),d)$ be the chain complex of differential forms on $M$. Endowing $M$ with an inner product gives us a hodge star operator which we could use to define the codiferential: $$\delta : \mathcal{A} ^{k}(M) \to \mathcal{A} ^{k-1}(M), \delta: \omega \mapsto (-1)^k \star^{-1}d\star\omega $$ This gives a chain complex $(\mathcal{A} ^*(M),\delta)$. We can now define the laplacian as $\triangle = d \delta + \delta d$. As a chain map, $\triangle : \mathcal{A}^*(M) \to \mathcal{A}^*(M)$ is null homotopic by constrution. By the exterior algebra functor I mean the functor that takes vector bundles over a manifold to their corresponding exterior algebra bundles. 1. Does there exist a map $\varphi: \Gamma(T^*M) \to  \Gamma(T^*M)$ s.t. under the exterior algebra functor the induced map between graded algebras is $\triangle$? To prove the Hodge theorem all we need to do is show that $i: Ker(\triangle) \to \mathcal{A}^*(M)$ is a quasi-isomorphism. From homological algebra we know that the chain map $i$ is a quasi-isomorphism iff its cone $Cone(i)$ is acyclic. 2. What properties should $\varphi: \Gamma (T^*M) \to  \Gamma(T^*M)$ posses to induce a map whose kernel has an acyclic cone? Could the hodge theorem be proved in this way? i.e. by exhibiting some function $\varphi$ satisfying (1) and proving that it posses (2)? (the latter part will no doubt involve some functional anaysis).",,"['differential-geometry', 'homological-algebra', 'homology-cohomology', 'hodge-theory']"
64,products of manifolds with boundary,products of manifolds with boundary,,"I am struggling a little bit with the following problem. Let $M$ and $N$ be smooth manifolds of dimension $m$ and $n$, respectively. Show that the product $M\times N$ is a smooth manifold of dimension $m+n$. Is this also true for smooth manifolds with boundary? I am able to do the first part (I just simply considered the product charts), but I am struggling with the part about the manifolds with boundary. My guess is that the answer is no, and most probably the space $[0,1]\times [0,1]$ should do the trick, but I am not quite able to give a rigourous proof that something goes wrong at the corners.","I am struggling a little bit with the following problem. Let $M$ and $N$ be smooth manifolds of dimension $m$ and $n$, respectively. Show that the product $M\times N$ is a smooth manifold of dimension $m+n$. Is this also true for smooth manifolds with boundary? I am able to do the first part (I just simply considered the product charts), but I am struggling with the part about the manifolds with boundary. My guess is that the answer is no, and most probably the space $[0,1]\times [0,1]$ should do the trick, but I am not quite able to give a rigourous proof that something goes wrong at the corners.",,['differential-geometry']
65,Bijective local isometry to global isometry,Bijective local isometry to global isometry,,"Suppose that I have a bijective local isometry $f: X \rightarrow Y$ where $X$ and $Y$ are length spaces. Can I show that $f$ is a global isometry? My thought is to consider a path $\gamma$ from $x$ to $y$ in $X$ and look at a subdivision $(t_1, \ldots, t_n)$ of $\gamma$. Then map the subdivision $(t_1, \ldots t_n)$ to a subdivision of $f(\gamma)$ in $Y$. For a sufficiently fine subdivision each consecutive pair of points should be in the same chart on $Y$. Then the sum of the lengths should be the same in the two spaces so $f$ is an isometry. Can anyone help me formalize this a bit?","Suppose that I have a bijective local isometry $f: X \rightarrow Y$ where $X$ and $Y$ are length spaces. Can I show that $f$ is a global isometry? My thought is to consider a path $\gamma$ from $x$ to $y$ in $X$ and look at a subdivision $(t_1, \ldots, t_n)$ of $\gamma$. Then map the subdivision $(t_1, \ldots t_n)$ to a subdivision of $f(\gamma)$ in $Y$. For a sufficiently fine subdivision each consecutive pair of points should be in the same chart on $Y$. Then the sum of the lengths should be the same in the two spaces so $f$ is an isometry. Can anyone help me formalize this a bit?",,"['differential-geometry', 'metric-spaces', 'differential-topology', 'metric-geometry']"
66,A proof for the Mobius Strip parametrization,A proof for the Mobius Strip parametrization,,"According to Elementary Differential Geometry by A N Pressley, a parameterization for Mobius strip is : $\textit{Example 4.9}$ The Möbius band is the surface obtained by rotating a straight line segment $\cal L$ around its midpoint $P$ at the same time as $P$ moves around a circle $\cal C$, in such a way that as $P$ moves once around $\cal C$, $\cal L$ makes a half-turn about $P$. If we take $\cal C$ to be the circle $x^2+y^2=1$ in the $xy$-plane, and $\cal L$ to be a segment of length $1$ that is initially parallel to the $z$-axis with its midpoint $P$ at $(1,0,0)$, then after $P$ has rotated by an angle $\theta$ around the $z$-axis, $\cal L$ should have rotated by $\theta/2$ around $P$ in the plane containing $P$ and the $z$-axis. The point of $\cal L$ initially at $(1,0,t)$ is then at the point $$\boldsymbol\sigma(t,\theta)=\left(\left(1-t\sin\dfrac\theta2\right)\cos\theta,\left(1-t\sin\dfrac\theta2\right)\sin\theta,t\cos\dfrac\theta2\right).$$ We take the domain of definition of $\boldsymbol\sigma$ to be $$U=\{(t,\theta)\in\mathbf R^2\mid-1/2<t<1/2,\ 0<\theta<2\pi\}.$$ And according to Wiki another parameterization is $x(u,v)= \left(1+\frac{v}{2} \cos \frac{u}{2}\right)\cos u\\ y(u,v)= \left(1+\frac{v}{2} \cos\frac{u}{2}\right)\sin u\\ z(u,v)= \frac{v}{2}\sin \frac{u}{2}.$ My questions are: 1- how these two 'different' parameterizations can be transformed to each other? Supposing the domains remain same ($0 ≤ u < 2π$ and $−1 ≤ v ≤ 1$) is it not possible by changing variables to do the reparameterizations (esp. $x$ and $y$ in $(x,y,z)$). 2- How (at least one of) the mentioned parameterizations be derived? Wiki and the book mentioning with no proof. Thank you.","According to Elementary Differential Geometry by A N Pressley, a parameterization for Mobius strip is : $\textit{Example 4.9}$ The Möbius band is the surface obtained by rotating a straight line segment $\cal L$ around its midpoint $P$ at the same time as $P$ moves around a circle $\cal C$, in such a way that as $P$ moves once around $\cal C$, $\cal L$ makes a half-turn about $P$. If we take $\cal C$ to be the circle $x^2+y^2=1$ in the $xy$-plane, and $\cal L$ to be a segment of length $1$ that is initially parallel to the $z$-axis with its midpoint $P$ at $(1,0,0)$, then after $P$ has rotated by an angle $\theta$ around the $z$-axis, $\cal L$ should have rotated by $\theta/2$ around $P$ in the plane containing $P$ and the $z$-axis. The point of $\cal L$ initially at $(1,0,t)$ is then at the point $$\boldsymbol\sigma(t,\theta)=\left(\left(1-t\sin\dfrac\theta2\right)\cos\theta,\left(1-t\sin\dfrac\theta2\right)\sin\theta,t\cos\dfrac\theta2\right).$$ We take the domain of definition of $\boldsymbol\sigma$ to be $$U=\{(t,\theta)\in\mathbf R^2\mid-1/2<t<1/2,\ 0<\theta<2\pi\}.$$ And according to Wiki another parameterization is $x(u,v)= \left(1+\frac{v}{2} \cos \frac{u}{2}\right)\cos u\\ y(u,v)= \left(1+\frac{v}{2} \cos\frac{u}{2}\right)\sin u\\ z(u,v)= \frac{v}{2}\sin \frac{u}{2}.$ My questions are: 1- how these two 'different' parameterizations can be transformed to each other? Supposing the domains remain same ($0 ≤ u < 2π$ and $−1 ≤ v ≤ 1$) is it not possible by changing variables to do the reparameterizations (esp. $x$ and $y$ in $(x,y,z)$). 2- How (at least one of) the mentioned parameterizations be derived? Wiki and the book mentioning with no proof. Thank you.",,[]
67,Two definitions of conormal bundle,Two definitions of conormal bundle,,"Suppose $X$ is a smooth manifold and $f: Z \to X$ is an immersion with transverse self-intersection. I've seen (e.g. here ) the conormal bundle to $Z$ in $T^* X$ defined as Definition A: $\quad L_Z := \{(x,\alpha) \in T^*X \mid x \in Z, \, \alpha(v) =0 \text{ for all } v \in T_x Z \}\subset T^*X.$ Q1: The space $L_Z$ is an embedded submanifold of $T^* X$. How can you see that it is embedded above self-intersection points of $Z$? (If $x$ is a self-intersection point, $T_x Z$ is not defined, so I assume ""$\alpha( v)=0 \text{ for all } v \in T_x Z$"" means $\alpha \big( df_z (v) \big)=0$ for all $v \in T_z Z$ such that $f(z)=x$. Equivalently, $\alpha(\gamma'(0))=0$ for smooth curves $\gamma: (-\epsilon,\epsilon) \to X$ with image in $f(Z)$. Note that $\alpha$ must be zero if $x$ is a transverse self-intersection point.) The above definition is something of a ""forgetful"" conormal bundle, as it is essentially determined by the image $f(Z)$. If we have access to $f$ itself, it seems more natural to me to define the conormal bundle as a subbundle of the pullback of $T^* X \to X$ by $f$: Definition B: $\quad N^*_f(Z):= \{ (z,\alpha) \in Z \times T^* X \mid \alpha \in T^*_{f(z)} X \text{ such that } \alpha\big( df_z (v)\big)=0 \text{ for all } v \in T_z Z\}.  $ There's an obvious map $F: N^*_f(Z)\to T^*X$ which is an immersion (resp. embedding) if and only if $f$ is an immersion (resp. embedding). And $F(N_f^*(Z))=L_Z$ if $f$ is an embedding, but not if $f$ has transverse self-intersection points. Q2: Which (if either) of these two definitions is the standard definition of the conormal bundle?","Suppose $X$ is a smooth manifold and $f: Z \to X$ is an immersion with transverse self-intersection. I've seen (e.g. here ) the conormal bundle to $Z$ in $T^* X$ defined as Definition A: $\quad L_Z := \{(x,\alpha) \in T^*X \mid x \in Z, \, \alpha(v) =0 \text{ for all } v \in T_x Z \}\subset T^*X.$ Q1: The space $L_Z$ is an embedded submanifold of $T^* X$. How can you see that it is embedded above self-intersection points of $Z$? (If $x$ is a self-intersection point, $T_x Z$ is not defined, so I assume ""$\alpha( v)=0 \text{ for all } v \in T_x Z$"" means $\alpha \big( df_z (v) \big)=0$ for all $v \in T_z Z$ such that $f(z)=x$. Equivalently, $\alpha(\gamma'(0))=0$ for smooth curves $\gamma: (-\epsilon,\epsilon) \to X$ with image in $f(Z)$. Note that $\alpha$ must be zero if $x$ is a transverse self-intersection point.) The above definition is something of a ""forgetful"" conormal bundle, as it is essentially determined by the image $f(Z)$. If we have access to $f$ itself, it seems more natural to me to define the conormal bundle as a subbundle of the pullback of $T^* X \to X$ by $f$: Definition B: $\quad N^*_f(Z):= \{ (z,\alpha) \in Z \times T^* X \mid \alpha \in T^*_{f(z)} X \text{ such that } \alpha\big( df_z (v)\big)=0 \text{ for all } v \in T_z Z\}.  $ There's an obvious map $F: N^*_f(Z)\to T^*X$ which is an immersion (resp. embedding) if and only if $f$ is an immersion (resp. embedding). And $F(N_f^*(Z))=L_Z$ if $f$ is an embedding, but not if $f$ has transverse self-intersection points. Q2: Which (if either) of these two definitions is the standard definition of the conormal bundle?",,"['differential-geometry', 'differential-topology', 'vector-bundles', 'symplectic-geometry']"
68,"In manifold theory, in what sense is the derivative a first-order approximation?","In manifold theory, in what sense is the derivative a first-order approximation?",,"As I move on from the calculus definition of the derivative to the differential geometric definition in terms of tangent spaces, I am wondering how to recover the notion that the derivative of a function represents the first order approximation. Clearly the definitions of the derivative traffic in first order concepts: tangent vectors can be thought of equivalence classes of curves agreeing up to first order; one characterization of the tangent space at $x \in M$ is the dual space to $I/I^2$, where $I$ is the ideal of $C^\infty$ functions that vanish at $x$, and so on. These definitions seem to be well-suited to a characterization of $Df$ as approximating $f$ up to first order at $x \in M$, but I am having trouble putting my finger on it and expressing it precisely. I know that when we're in $\mathbb{R}^n$ the ""approximation"" property of the derivative works very well because we can identify the tangent space at a given point with $\mathbb{R}^n$ itself. But what about in the more general setting? In what sense do we have ""approximation up to first order"" there? What is it exactly that's agreeing with $f$ up to $o(\|h\|)$?","As I move on from the calculus definition of the derivative to the differential geometric definition in terms of tangent spaces, I am wondering how to recover the notion that the derivative of a function represents the first order approximation. Clearly the definitions of the derivative traffic in first order concepts: tangent vectors can be thought of equivalence classes of curves agreeing up to first order; one characterization of the tangent space at $x \in M$ is the dual space to $I/I^2$, where $I$ is the ideal of $C^\infty$ functions that vanish at $x$, and so on. These definitions seem to be well-suited to a characterization of $Df$ as approximating $f$ up to first order at $x \in M$, but I am having trouble putting my finger on it and expressing it precisely. I know that when we're in $\mathbb{R}^n$ the ""approximation"" property of the derivative works very well because we can identify the tangent space at a given point with $\mathbb{R}^n$ itself. But what about in the more general setting? In what sense do we have ""approximation up to first order"" there? What is it exactly that's agreeing with $f$ up to $o(\|h\|)$?",,"['differential-geometry', 'smooth-manifolds']"
69,second fundamental form and connection forms,second fundamental form and connection forms,,"I am reading this paper that has the following: Suppose $M$ is an (n-1) dimensional closed hyper surface immersed in $\mathbb{R}^{n}$. Let $e_1, \cdots, e_n$ be orthonormal frame in $\mathbb{R}^n$ such that $e_1,\cdots, e_{n-1}$ are tangent to $M$ and $e_n$ is the outer normal. Let $\omega_i$ be the corresponding coframes and $\omega_{i,j}$ be the connection forms. And use the same notation for the pull back of the forms through immersion. Then the second fundamental form is defined by the symmetric matrix $\{h_{ij}\}$ with $$\omega_{i,n+1}=h_{ij}\omega_j.$$ I use Boothby's An introduction to differentiable manifolds and Riemannian geometry for reference on differential geometry. In this book, the notations are like this: $e_1,\cdots,e_n$ are the orthonormal frames. $\omega^i$ are the coframes. (so I figured this is equal to $\omega_i$ in the paper.) $\omega_{j}^{k}$ are defined so that $\nabla_{X} e_j = \Sigma_k \omega_{j}^{k}(X)e_k$, where $X$ is a vector field. $\omega_{i,j}=\Sigma_k \omega_{i}^kg_{kj}$. In this case, since this is an orthonormal frame, I guess $\omega_{i,j}=\omega_i^j$. I assume the symmetric matrix is defined by $h_{ij}=\langle e_n,\nabla_{e_i}e_j\rangle$. (Correct me if I am wrong.) Using 3 and 4, I get $h_{ij}=\omega_{j,n+1}(e_i)$. To arrive at the equation in the paper, I will have to justify (note that $\omega_j=\omega^j$) $$\Sigma_j \omega_{j,n+1}(e_i)\omega_j = \omega_{i,n+1}.$$ I am stuck at this step. Can anyone help me?","I am reading this paper that has the following: Suppose $M$ is an (n-1) dimensional closed hyper surface immersed in $\mathbb{R}^{n}$. Let $e_1, \cdots, e_n$ be orthonormal frame in $\mathbb{R}^n$ such that $e_1,\cdots, e_{n-1}$ are tangent to $M$ and $e_n$ is the outer normal. Let $\omega_i$ be the corresponding coframes and $\omega_{i,j}$ be the connection forms. And use the same notation for the pull back of the forms through immersion. Then the second fundamental form is defined by the symmetric matrix $\{h_{ij}\}$ with $$\omega_{i,n+1}=h_{ij}\omega_j.$$ I use Boothby's An introduction to differentiable manifolds and Riemannian geometry for reference on differential geometry. In this book, the notations are like this: $e_1,\cdots,e_n$ are the orthonormal frames. $\omega^i$ are the coframes. (so I figured this is equal to $\omega_i$ in the paper.) $\omega_{j}^{k}$ are defined so that $\nabla_{X} e_j = \Sigma_k \omega_{j}^{k}(X)e_k$, where $X$ is a vector field. $\omega_{i,j}=\Sigma_k \omega_{i}^kg_{kj}$. In this case, since this is an orthonormal frame, I guess $\omega_{i,j}=\omega_i^j$. I assume the symmetric matrix is defined by $h_{ij}=\langle e_n,\nabla_{e_i}e_j\rangle$. (Correct me if I am wrong.) Using 3 and 4, I get $h_{ij}=\omega_{j,n+1}(e_i)$. To arrive at the equation in the paper, I will have to justify (note that $\omega_j=\omega^j$) $$\Sigma_j \omega_{j,n+1}(e_i)\omega_j = \omega_{i,n+1}.$$ I am stuck at this step. Can anyone help me?",,"['differential-geometry', 'riemannian-geometry']"
70,Riemannian geometry vs Hyperbolic geometry,Riemannian geometry vs Hyperbolic geometry,,"I am learning differential geometry in this semester. Concerning the riemannian geometry, if the cross-sectional curvature (riemannian metric ) is negative at every point, the manifold which arises is hyperbolic. At the other hand hyperbolic geometry is another form of non-euclidean geometry just like the riemannian geometry. I am wondering if a manifold with negative curvature in the framework of the riemannian geometry is to be understood as being part of hyperbolic geometry ? If the answer is affirmative, does it mean that hyperbolic geometry is part of the Riemannian geometry ? If the answer is negative, can one study hyperbolic geometry in the framework of differential manifolds ? Thanks for your comment.","I am learning differential geometry in this semester. Concerning the riemannian geometry, if the cross-sectional curvature (riemannian metric ) is negative at every point, the manifold which arises is hyperbolic. At the other hand hyperbolic geometry is another form of non-euclidean geometry just like the riemannian geometry. I am wondering if a manifold with negative curvature in the framework of the riemannian geometry is to be understood as being part of hyperbolic geometry ? If the answer is affirmative, does it mean that hyperbolic geometry is part of the Riemannian geometry ? If the answer is negative, can one study hyperbolic geometry in the framework of differential manifolds ? Thanks for your comment.",,['differential-geometry']
71,Example of orthogonal parametrization of a surface,Example of orthogonal parametrization of a surface,,"I recently came to know about the orthogonal parametrization of a surface, for which $F={\bf X_u}\cdot{\bf X_v}=0$ and $E={\bf X_u}\cdot{\bf X_u}=G={\bf X_v}\cdot{\bf X_v}$. Here, $(E,F,G)$ denote the coefficients of the first fundamental form of a surface $S:={\bf X}(u,v)$. According to the discussion of this thread , it is always possible to parameterize a regular surface $S$ (2 dimensions) via isothermal coordinates that makes the parametrization orthogonal. I went through the wikipedia link suggested in this discussion, but it does not illustrate the principle with a concrete example like: orthogonal parametrization of an ellipsoid/hyperboloid etc. in terms of the isothermal coordinates. If anyone here can refer me to some book/online resources to see such an example, that will be very helpful. The standard parametrization of ellipsoid ($a\sin\theta\cos\phi,b\sin\theta\sin\phi,c\cos\theta$) is not an orthogonal one, that I have checked. So, there must be some parametrization which I did not come across so far. Thanks in advance to anyone who can point me to some direction. P.S. I am sorry if my question sounds stupid; I am an experimental physicists trying to learn few aspects of differential geometry.","I recently came to know about the orthogonal parametrization of a surface, for which $F={\bf X_u}\cdot{\bf X_v}=0$ and $E={\bf X_u}\cdot{\bf X_u}=G={\bf X_v}\cdot{\bf X_v}$. Here, $(E,F,G)$ denote the coefficients of the first fundamental form of a surface $S:={\bf X}(u,v)$. According to the discussion of this thread , it is always possible to parameterize a regular surface $S$ (2 dimensions) via isothermal coordinates that makes the parametrization orthogonal. I went through the wikipedia link suggested in this discussion, but it does not illustrate the principle with a concrete example like: orthogonal parametrization of an ellipsoid/hyperboloid etc. in terms of the isothermal coordinates. If anyone here can refer me to some book/online resources to see such an example, that will be very helpful. The standard parametrization of ellipsoid ($a\sin\theta\cos\phi,b\sin\theta\sin\phi,c\cos\theta$) is not an orthogonal one, that I have checked. So, there must be some parametrization which I did not come across so far. Thanks in advance to anyone who can point me to some direction. P.S. I am sorry if my question sounds stupid; I am an experimental physicists trying to learn few aspects of differential geometry.",,['differential-geometry']
72,Why is $\deg(f)$ well-defined?,Why is  well-defined?,\deg(f),"If $M$ and $N$ are boundaryless, compact, connected, oriented $n$-manifolds, and $f:M\to N$ is smooth, then if $\omega_0$ is a $n$-form on $N$ and $\int_N\omega_0\neq 0$, there is a number $a$ such that $\int_M f^*\omega_0=a\int_N\omega_0$. In fact, if $\omega$ is any $n$-form on $N$, then $\int_M f^*\omega=a\int_N\omega$. How do we know it's the same $a$ for any $\omega$?","If $M$ and $N$ are boundaryless, compact, connected, oriented $n$-manifolds, and $f:M\to N$ is smooth, then if $\omega_0$ is a $n$-form on $N$ and $\int_N\omega_0\neq 0$, there is a number $a$ such that $\int_M f^*\omega_0=a\int_N\omega_0$. In fact, if $\omega$ is any $n$-form on $N$, then $\int_M f^*\omega=a\int_N\omega$. How do we know it's the same $a$ for any $\omega$?",,['differential-geometry']
73,"Hodge star operator and volume form, basic properties","Hodge star operator and volume form, basic properties",,"let $(M,g)$ be an oriented Riemannian manifold. Let $*$ be the hodge operator, I want to prove that $$*\mathrm{vol}_g =1$$ where $\mathrm{vol}_g$ is the associate volume form $\sqrt{g} e^1\wedge \cdots \wedge e^n$ In these notes it's given as a fact, but when I started to prove it, I got confused by the underlying scalar product and how the pairing works, hence can someone show me some hints on how to prove that? I don't want a full solution, only a clarification. In fact using the definition of hodge star I think that it's enough to prove that $g(\mathrm{vol}_g,\mathrm{vol}_g)=1$ but I don't know how to prove it. Given this, then is it true that, for a given top-form ($n$-dim differential form), $w=(*w)\mathrm{vol}_g$? Because I'd argue in this way: $w=\tilde{w}(x)\mathrm{vol}_g$ because we are working in a one dimensional vector space, then $*w={*\tilde{w}}(x)\mathrm{vol}_g=\tilde{w}(x)\,{*\mathrm{vol}}_g=\tilde{w}(x)$. Is it correct? ADDENDUM In this setting, given $\eta \in \Omega^p(M)$, we define $*\eta$ as the unique element such that, for every $w \in \Omega^{p}(M)$ we have $$ w \wedge *\eta = (\bigwedge^p g)(w,\eta) \mathrm{vol}_g$$","let $(M,g)$ be an oriented Riemannian manifold. Let $*$ be the hodge operator, I want to prove that $$*\mathrm{vol}_g =1$$ where $\mathrm{vol}_g$ is the associate volume form $\sqrt{g} e^1\wedge \cdots \wedge e^n$ In these notes it's given as a fact, but when I started to prove it, I got confused by the underlying scalar product and how the pairing works, hence can someone show me some hints on how to prove that? I don't want a full solution, only a clarification. In fact using the definition of hodge star I think that it's enough to prove that $g(\mathrm{vol}_g,\mathrm{vol}_g)=1$ but I don't know how to prove it. Given this, then is it true that, for a given top-form ($n$-dim differential form), $w=(*w)\mathrm{vol}_g$? Because I'd argue in this way: $w=\tilde{w}(x)\mathrm{vol}_g$ because we are working in a one dimensional vector space, then $*w={*\tilde{w}}(x)\mathrm{vol}_g=\tilde{w}(x)\,{*\mathrm{vol}}_g=\tilde{w}(x)$. Is it correct? ADDENDUM In this setting, given $\eta \in \Omega^p(M)$, we define $*\eta$ as the unique element such that, for every $w \in \Omega^{p}(M)$ we have $$ w \wedge *\eta = (\bigwedge^p g)(w,\eta) \mathrm{vol}_g$$",,"['differential-geometry', 'global-analysis']"
74,Does $\omega \wedge \mathrm{d} \omega=0$ (where $\omega$ is a non-vanishing $1$-form) imply $\mathrm{d} \omega \in \langle \omega\rangle$?,Does  (where  is a non-vanishing -form) imply ?,\omega \wedge \mathrm{d} \omega=0 \omega 1 \mathrm{d} \omega \in \langle \omega\rangle,"Let $\omega$ be a non-vanishing (for clarification: nowhere vanishing) smooth $1$-form on a smooth manifold $M$, if $\mathrm{d}\omega \wedge \omega =0$, do we already have $\mathrm{d}\omega= \sum a_i \wedge \omega$ for some $1$-forms $a_i$?","Let $\omega$ be a non-vanishing (for clarification: nowhere vanishing) smooth $1$-form on a smooth manifold $M$, if $\mathrm{d}\omega \wedge \omega =0$, do we already have $\mathrm{d}\omega= \sum a_i \wedge \omega$ for some $1$-forms $a_i$?",,"['differential-geometry', 'differential-forms']"
75,Calculating the pullback of a $2$-form,Calculating the pullback of a -form,2,"I have a $2$-form given by $\omega = dx \wedge dp + dy \wedge dq$ and a map $i : (u,v) \mapsto (u,v,f_u,-f_v)$ for a general smooth map $f : (u,v) \mapsto f(u,v)$. I want to calculate the pullback of this map, i.e. $i^*\omega$. I understand that in this case, \begin{align} i^*\omega &= i^*(dx \wedge dp + dy \wedge dq) \\ &= d(x \circ i)\wedge d(p \circ i) + d(y \circ i)\wedge d(q \circ i). \end{align} Now, calculating each terms gives \begin{align} d(x \circ i) &= d(u) = du, \\ d(y \circ i) &= d(v) = dv, \\ d(p \circ i) &= d(f_u) = f_{uu}du + f_{uv}dv, \\ d(q \circ i) &= d(-f_v) = -f_{vu}du - f_{vv}dv. \end{align} Then, the pullback is given by \begin{align} i^*\omega &= du \wedge (f_{uu}du + f_{uv}dv) - dv \wedge (f_{vu}du + f_{vv}dv) \\ &= du \wedge (f_{uu}du) + du \wedge (f_{uv}dv) - dv \wedge (f_{vu}du) - dv \wedge (f_{vv}dv). \end{align} Could someone verify that it is correct? Can it be further simplified? I tried to follow the steps described in this question. Note. This is not a homework question, I am just trying to teach myself some differential geometry.","I have a $2$-form given by $\omega = dx \wedge dp + dy \wedge dq$ and a map $i : (u,v) \mapsto (u,v,f_u,-f_v)$ for a general smooth map $f : (u,v) \mapsto f(u,v)$. I want to calculate the pullback of this map, i.e. $i^*\omega$. I understand that in this case, \begin{align} i^*\omega &= i^*(dx \wedge dp + dy \wedge dq) \\ &= d(x \circ i)\wedge d(p \circ i) + d(y \circ i)\wedge d(q \circ i). \end{align} Now, calculating each terms gives \begin{align} d(x \circ i) &= d(u) = du, \\ d(y \circ i) &= d(v) = dv, \\ d(p \circ i) &= d(f_u) = f_{uu}du + f_{uv}dv, \\ d(q \circ i) &= d(-f_v) = -f_{vu}du - f_{vv}dv. \end{align} Then, the pullback is given by \begin{align} i^*\omega &= du \wedge (f_{uu}du + f_{uv}dv) - dv \wedge (f_{vu}du + f_{vv}dv) \\ &= du \wedge (f_{uu}du) + du \wedge (f_{uv}dv) - dv \wedge (f_{vu}du) - dv \wedge (f_{vv}dv). \end{align} Could someone verify that it is correct? Can it be further simplified? I tried to follow the steps described in this question. Note. This is not a homework question, I am just trying to teach myself some differential geometry.",,"['differential-geometry', 'solution-verification', 'differential-forms']"
76,Difference between parameterization and embedding of manifolds,Difference between parameterization and embedding of manifolds,,"What is the difference between embedding and parameterization? Why, for example, we say Gauss parameterization of a convex hypersurfaces, and we don't call it an embedding?","What is the difference between embedding and parameterization? Why, for example, we say Gauss parameterization of a convex hypersurfaces, and we don't call it an embedding?",,['differential-geometry']
77,Shape operator and orthogonality of eigenvectors,Shape operator and orthogonality of eigenvectors,,"When studying differential geometry (at a hobby level) I always run into problems when it comes to the varying notations and statements about the shape operator $S_p(\mathbf{x})=I^{-1}_pII_p(\mathbf{x})$.  More specifically, my problems have to do with the orthogonality of the eigenvectors of $S_p$. The cause of some problems might relate to uncertainty ""where"" (in which coordinate space) stuff is happening, so first of all, considering a surface $X:\Omega\rightarrow \mathbb{R}^3$, am I right in thinking that the parameters $\mathbf{x}$ in $S_p(\mathbf{x})$ are ""from"" the parameter domain, that is $\mathbf{x}\in\Omega$? Now, let $\mathbf{u}_1$ and $\mathbf{u}_2$ be the two eigenvectors with $S_p\mathbf{u}_i=k_i\mathbf{u}_i$. Many authors state: ""The eigenvectors of $S_p$ are called principal directions. ...  Recall that it also follows from the Spectral Theorem that the principal directions are orthogonal..."" How can this be? As noted above, in my opinion $S_p$ is ""evaluated"" on $\Omega$. The $S_p$-Matrix is not symmetric. And hence (according to maple) $<\mathbf{u}_1,\mathbf{u}_2>\neq0$. However, it seems that when speaking about orthogonality of the eigenvectors it is always implied that they are first transferred via the Jacobian $J_X$ to the tangent plane: $<J_X\mathbf{u}_1,J_X\mathbf{u}_2>=<\mathbf{u}_1,\mathbf{u}_2>_I=0$. So, my intuition seems to be wrong, can someone point me in the right direction? Finally, I believe prove orthogonality $<\mathbf{u}_1,\mathbf{u}_2>_I=0$ should be easy using simple substitutions, but I seem to be missing some linear algebraic argument... any idea? \begin{equation} <\mathbf{u}_1,\mathbf{u}_2>_I = \mathbf{u}_1^T I_p \mathbf{u}_2 = \\ \textit{using } S_p\mathbf{u}_2=I^{-1}_pII_p\mathbf{u}_2=k_2\mathbf{u}_2 \textit{ we get }\\ \frac{1}{k_2}\mathbf{u}_1^T I_p I^{-1}_pII_p\mathbf{u}_2=\frac{1}{k_2}\mathbf{u}_1^T II_p\mathbf{u}_2\\ \text{ but I cannot see how this is zero } \end{equation} Any pointers?","When studying differential geometry (at a hobby level) I always run into problems when it comes to the varying notations and statements about the shape operator $S_p(\mathbf{x})=I^{-1}_pII_p(\mathbf{x})$.  More specifically, my problems have to do with the orthogonality of the eigenvectors of $S_p$. The cause of some problems might relate to uncertainty ""where"" (in which coordinate space) stuff is happening, so first of all, considering a surface $X:\Omega\rightarrow \mathbb{R}^3$, am I right in thinking that the parameters $\mathbf{x}$ in $S_p(\mathbf{x})$ are ""from"" the parameter domain, that is $\mathbf{x}\in\Omega$? Now, let $\mathbf{u}_1$ and $\mathbf{u}_2$ be the two eigenvectors with $S_p\mathbf{u}_i=k_i\mathbf{u}_i$. Many authors state: ""The eigenvectors of $S_p$ are called principal directions. ...  Recall that it also follows from the Spectral Theorem that the principal directions are orthogonal..."" How can this be? As noted above, in my opinion $S_p$ is ""evaluated"" on $\Omega$. The $S_p$-Matrix is not symmetric. And hence (according to maple) $<\mathbf{u}_1,\mathbf{u}_2>\neq0$. However, it seems that when speaking about orthogonality of the eigenvectors it is always implied that they are first transferred via the Jacobian $J_X$ to the tangent plane: $<J_X\mathbf{u}_1,J_X\mathbf{u}_2>=<\mathbf{u}_1,\mathbf{u}_2>_I=0$. So, my intuition seems to be wrong, can someone point me in the right direction? Finally, I believe prove orthogonality $<\mathbf{u}_1,\mathbf{u}_2>_I=0$ should be easy using simple substitutions, but I seem to be missing some linear algebraic argument... any idea? \begin{equation} <\mathbf{u}_1,\mathbf{u}_2>_I = \mathbf{u}_1^T I_p \mathbf{u}_2 = \\ \textit{using } S_p\mathbf{u}_2=I^{-1}_pII_p\mathbf{u}_2=k_2\mathbf{u}_2 \textit{ we get }\\ \frac{1}{k_2}\mathbf{u}_1^T I_p I^{-1}_pII_p\mathbf{u}_2=\frac{1}{k_2}\mathbf{u}_1^T II_p\mathbf{u}_2\\ \text{ but I cannot see how this is zero } \end{equation} Any pointers?",,"['differential-geometry', 'eigenvalues-eigenvectors', 'curvature']"
78,existence of hemisphere,existence of hemisphere,,"If $ \beta: (a,b)\rightarrow \mathbb{S}^2 $ is a simple closed curve such that $ \int_a^b\Vert\beta^{\prime}(t) \Vert dt<2\pi$ then there is an open hemisphere (or any rotation of this) containing   the image of $\beta $ thanks!","If $ \beta: (a,b)\rightarrow \mathbb{S}^2 $ is a simple closed curve such that $ \int_a^b\Vert\beta^{\prime}(t) \Vert dt<2\pi$ then there is an open hemisphere (or any rotation of this) containing   the image of $\beta $ thanks!",,['differential-geometry']
79,what does it mean for a differential form to be well defined on a manifold?,what does it mean for a differential form to be well defined on a manifold?,,"What does it mean for a differential form to be well defined on some manifold. In particular, why the $2$-form  $\omega=d\psi\wedge d\theta$ is well defined on $S^{2}$? Thank you in advance.","What does it mean for a differential form to be well defined on some manifold. In particular, why the $2$-form  $\omega=d\psi\wedge d\theta$ is well defined on $S^{2}$? Thank you in advance.",,"['differential-geometry', 'differential-forms']"
80,Mean curvature flow - implementation fails for some meshes,Mean curvature flow - implementation fails for some meshes,,"I am working on piece of software to deal with 3D meshes and I need to smooth some meshes. I have implemented MCF by using this formula $\vec{H} = {{t}\over{2}} \sum_{q \in\ link\ p} \vec{Ne} |e| \sin({\theta\over{2}})$ where $\vec{Ne}$ = ${\vec{N1} \vec{N2}}\over{2 \cos{{\theta}\over{2}}}$, $\vec{e} = q - p$ and $N1$ and $N2$ are normals to faces to whom edge belongs. $\theta$ is calculated by cosine similarity between $N1$ and $N2$ And I have tested my implementation with meshes like cube, cone, torus and it works well. But the problem is with more complex meshes, e.g. I tried to smooth Stanford bunny and I got smaller but bumper result instead of smoother! Below you can find examples which present bunny before and after smoothing. My question is if I forgot about something important or this is normal behavior of MFC for some meshes and I should forget about MFC and implement another flow(I will be grateful for any recommendations). I have to add that, for another problematic mesh I calculated some MFC vectors on paper and I got same results(up to floating point errors). At the and I want to add that, as probably some of you know Stanford bunny is not 2-manifold so I removed faces from problematic edges by using MeshLab's filters. Thanks and happy math!","I am working on piece of software to deal with 3D meshes and I need to smooth some meshes. I have implemented MCF by using this formula $\vec{H} = {{t}\over{2}} \sum_{q \in\ link\ p} \vec{Ne} |e| \sin({\theta\over{2}})$ where $\vec{Ne}$ = ${\vec{N1} \vec{N2}}\over{2 \cos{{\theta}\over{2}}}$, $\vec{e} = q - p$ and $N1$ and $N2$ are normals to faces to whom edge belongs. $\theta$ is calculated by cosine similarity between $N1$ and $N2$ And I have tested my implementation with meshes like cube, cone, torus and it works well. But the problem is with more complex meshes, e.g. I tried to smooth Stanford bunny and I got smaller but bumper result instead of smoother! Below you can find examples which present bunny before and after smoothing. My question is if I forgot about something important or this is normal behavior of MFC for some meshes and I should forget about MFC and implement another flow(I will be grateful for any recommendations). I have to add that, for another problematic mesh I calculated some MFC vectors on paper and I got same results(up to floating point errors). At the and I want to add that, as probably some of you know Stanford bunny is not 2-manifold so I removed faces from problematic edges by using MeshLab's filters. Thanks and happy math!",,"['differential-geometry', 'curvature', 'polygons', 'mean-curvature-flows']"
81,The Lie derivative by an infinitesimal action is invertible at an isolated zero point,The Lie derivative by an infinitesimal action is invertible at an isolated zero point,,"Let a compact Lie group $G$ act on a manifold $M$. Fix $X \in \mathfrak g$ and we write $X_M$ for the infinitesimal action of $X$. Assume that $p \in M$ is a zero point of $X_M$. Define a linear map $L_p : T_pM \to T_pM$ by $L_p(v) = \mathcal L(X_M)v$. Here $v$ on the right hand side is an extension of the tangent vector $v$ to a vector field. Since $X_M(p)=0$, $L_p$ is well-defined. I want to show that $L_p$ is invertible if $p$ is an isolated zero point. Here is a proof (Lemma 45). Proof . Pick a $G$-invariant Riemannian metric and suppose that $v \in T_pM-0$ is annihilated by $L_p$. Taking the exponential map with respect to the metric, we see that all the points on the geodesic $\exp_p (tv)$, $t \in \mathbb R$, would be fixed by $\exp(sX) \in G$, $s \in \mathbb R$, contradicting to $p$ being isolated. (I changed the proof slightly due to notation.) Could you tell me why $\exp_p(tv)$ is fixed by $\exp(sX)$?","Let a compact Lie group $G$ act on a manifold $M$. Fix $X \in \mathfrak g$ and we write $X_M$ for the infinitesimal action of $X$. Assume that $p \in M$ is a zero point of $X_M$. Define a linear map $L_p : T_pM \to T_pM$ by $L_p(v) = \mathcal L(X_M)v$. Here $v$ on the right hand side is an extension of the tangent vector $v$ to a vector field. Since $X_M(p)=0$, $L_p$ is well-defined. I want to show that $L_p$ is invertible if $p$ is an isolated zero point. Here is a proof (Lemma 45). Proof . Pick a $G$-invariant Riemannian metric and suppose that $v \in T_pM-0$ is annihilated by $L_p$. Taking the exponential map with respect to the metric, we see that all the points on the geodesic $\exp_p (tv)$, $t \in \mathbb R$, would be fixed by $\exp(sX) \in G$, $s \in \mathbb R$, contradicting to $p$ being isolated. (I changed the proof slightly due to notation.) Could you tell me why $\exp_p(tv)$ is fixed by $\exp(sX)$?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry', 'geodesic']"
82,The principal curvatures of a surface of revolution,The principal curvatures of a surface of revolution,,"The principal curvatures of the surface at a point is defined as the maximal and the minimal curvature among all normal sections. It's claimed (say, on Stillwell's Geometry of Surfaces ) that for a pseudosphere (or generally a surface of revolution) the extremal curvatures are obtained when the normal section coincides or is perpendicular to the plane determined by the longitude and the axis of revolution. It's said that the proposition follows clearly from symmetry. According to that book, there's no differential geometric tool (such as the second fundamental form, etc) introduced, so I need an intuitive and elementary explanation for that fact. After googling, I found an explanation which depends on the knowledge of Dupin indicatrix, which is intuitive and computation-free, though not that elementary. It's really clear that the Dupin indicatrix is reflection-symmetric along the plane determined by the longitude and the axis of revolution, thus one direction of principal curvature is determined. The other one is normal to this. Any help? Thanks!","The principal curvatures of the surface at a point is defined as the maximal and the minimal curvature among all normal sections. It's claimed (say, on Stillwell's Geometry of Surfaces ) that for a pseudosphere (or generally a surface of revolution) the extremal curvatures are obtained when the normal section coincides or is perpendicular to the plane determined by the longitude and the axis of revolution. It's said that the proposition follows clearly from symmetry. According to that book, there's no differential geometric tool (such as the second fundamental form, etc) introduced, so I need an intuitive and elementary explanation for that fact. After googling, I found an explanation which depends on the knowledge of Dupin indicatrix, which is intuitive and computation-free, though not that elementary. It's really clear that the Dupin indicatrix is reflection-symmetric along the plane determined by the longitude and the axis of revolution, thus one direction of principal curvature is determined. The other one is normal to this. Any help? Thanks!",,"['differential-geometry', 'surfaces']"
83,Connection(gauge field) in Fubini-Study metric is pull back of a connection A of line bundle $\mathcal{O}(1)$ on $\mathbb{CP}^{N-1}$,Connection(gauge field) in Fubini-Study metric is pull back of a connection A of line bundle  on,\mathcal{O}(1) \mathbb{CP}^{N-1},"One can describe a  $\mathbb{CP}^{N-1}$ manifold with a Fubini-Study metric $g^{FS}$, and there is a connection one form $v$ on it. A is connection one form(gauge field) of a line bundle($\mathcal{O}(1)$) on $\mathbb{CP}^{N-1}$ whose first Chern class generates the integral cohomology group $H^2(\mathbb{CP}^{N-1},Z)$. I have problem here: 1.Why $v$ is a pull back of $A$? 2.Why A generates cohomology group $H^2(\mathbb{CP}^{N-1},Z)$?","One can describe a  $\mathbb{CP}^{N-1}$ manifold with a Fubini-Study metric $g^{FS}$, and there is a connection one form $v$ on it. A is connection one form(gauge field) of a line bundle($\mathcal{O}(1)$) on $\mathbb{CP}^{N-1}$ whose first Chern class generates the integral cohomology group $H^2(\mathbb{CP}^{N-1},Z)$. I have problem here: 1.Why $v$ is a pull back of $A$? 2.Why A generates cohomology group $H^2(\mathbb{CP}^{N-1},Z)$?",,"['algebraic-geometry', 'differential-geometry', 'mathematical-physics', 'sheaf-theory', 'sheaf-cohomology']"
84,"Given the curvature and torsion, find the curve","Given the curvature and torsion, find the curve",,"I need some help on the following problem: Given that a curve $\mathbf r:I\to \Bbb R ^3$ has constant curvature $k(s)=k$, for all $s$, and constant torsion $\tau(s)=\tau$, for all $s$. Find the curve $\mathbf r$. I only know that, according to the fundamental theorem, this curve exists and is unique. But, how practically find the parametric equation of the curve? Thanks.","I need some help on the following problem: Given that a curve $\mathbf r:I\to \Bbb R ^3$ has constant curvature $k(s)=k$, for all $s$, and constant torsion $\tau(s)=\tau$, for all $s$. Find the curve $\mathbf r$. I only know that, according to the fundamental theorem, this curve exists and is unique. But, how practically find the parametric equation of the curve? Thanks.",,['differential-geometry']
85,integration of differential forms on covering space,integration of differential forms on covering space,,"Let $M_1,M_2$ be $n$-dimensional oriented manifolds. Let $f: M_1\longrightarrow M_2$ be an orientation-preserving diffeomorphism. Then for any $\omega\in \Omega^n_c(M_2)$ we have(page 85 of {Madsen: from calculus to cohomology}) \begin{eqnarray*} \int_{M_2}\omega=\int_{M_1}f^*\omega. \end{eqnarray*} Generally, let $f: M_1\longrightarrow M_2$ be a $n$-sheeted covering map. Then whether is it true or not \begin{eqnarray*} n\int_{M_2}\omega=\int_{M_1}f^*\omega? \end{eqnarray*}","Let $M_1,M_2$ be $n$-dimensional oriented manifolds. Let $f: M_1\longrightarrow M_2$ be an orientation-preserving diffeomorphism. Then for any $\omega\in \Omega^n_c(M_2)$ we have(page 85 of {Madsen: from calculus to cohomology}) \begin{eqnarray*} \int_{M_2}\omega=\int_{M_1}f^*\omega. \end{eqnarray*} Generally, let $f: M_1\longrightarrow M_2$ be a $n$-sheeted covering map. Then whether is it true or not \begin{eqnarray*} n\int_{M_2}\omega=\int_{M_1}f^*\omega? \end{eqnarray*}",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology']"
86,Geodesics Through a Singularity,Geodesics Through a Singularity,,"A singularity on a manifold with metric is defined to be a point at which some geodesic cannot be continued through. For example in Schwarzchild spacetime, $r=0$ defines such a point. Is it the case that any geodesic which hits a singularity cannot be continued past it? This is obviously true for the Schwarzchild solution. However I worry that perhaps that's just an artifact of the symmetry of the situation. There's nothing in the definition of a singularity that refers to an arbitrary geodesic through that point. I've tried to think about this myself, but I'm not sure I have the requisite differential geometry to solve it. I can't see how (say) the Hopf-Rinow theorem, or any related results would help! It would be great to get a mathematician's perspective on this question. Apologies if the solution if obvious and I'm just missing something!","A singularity on a manifold with metric is defined to be a point at which some geodesic cannot be continued through. For example in Schwarzchild spacetime, $r=0$ defines such a point. Is it the case that any geodesic which hits a singularity cannot be continued past it? This is obviously true for the Schwarzchild solution. However I worry that perhaps that's just an artifact of the symmetry of the situation. There's nothing in the definition of a singularity that refers to an arbitrary geodesic through that point. I've tried to think about this myself, but I'm not sure I have the requisite differential geometry to solve it. I can't see how (say) the Hopf-Rinow theorem, or any related results would help! It would be great to get a mathematician's perspective on this question. Apologies if the solution if obvious and I'm just missing something!",,"['differential-geometry', 'mathematical-physics', 'geodesic', 'general-relativity']"
87,Killing vector field of constant length on Riemannian manifolds,Killing vector field of constant length on Riemannian manifolds,,"I would like to solve next problem A Killing vector ﬁeld $X$ on a   Riemannian manifold $(M, g)$ ($g$ is metric) has constant length if and   only if every integral curve of the ﬁeld $X$ is a geodesic   in $(M, g)$. I found here http://arxiv.org/pdf/math/0605371.pdf (Proposition 1) solution, but I don't understand what is $L$, how we define and use that $L$, and how from that (equation in proof) follows statement. Or there is some alternative solutions? My definiton of Killing vector field: Let $X$ be  vector field on a Riemannian manifold $(M,g)$ and $U$ neighbourhood of a point $p \in M$. Let $\varphi: (-\varepsilon, \varepsilon) \times U \to M$ is flow of vector field $X$. Then $X$ is Killing vector field if for every $t_0 \in (-\varepsilon, \varepsilon)$ mapping $\varphi_{t_0}:U \to M$ is isometry.","I would like to solve next problem A Killing vector ﬁeld $X$ on a   Riemannian manifold $(M, g)$ ($g$ is metric) has constant length if and   only if every integral curve of the ﬁeld $X$ is a geodesic   in $(M, g)$. I found here http://arxiv.org/pdf/math/0605371.pdf (Proposition 1) solution, but I don't understand what is $L$, how we define and use that $L$, and how from that (equation in proof) follows statement. Or there is some alternative solutions? My definiton of Killing vector field: Let $X$ be  vector field on a Riemannian manifold $(M,g)$ and $U$ neighbourhood of a point $p \in M$. Let $\varphi: (-\varepsilon, \varepsilon) \times U \to M$ is flow of vector field $X$. Then $X$ is Killing vector field if for every $t_0 \in (-\varepsilon, \varepsilon)$ mapping $\varphi_{t_0}:U \to M$ is isometry.",,['differential-geometry']
88,Does this orbifold embed into $\mathbb{R}^3$?,Does this orbifold embed into ?,\mathbb{R}^3,"Let $X$ be the space obtained by gluing together two congruent equilateral triangles along corresponding edges. Note that $X$ has the structure of a Riemannian manifold except at the three cone points.  In particular, $X$ is a Riemannian orbifold. Is there an isometric embedding of $X$ into $\mathbb{R}^3$?","Let $X$ be the space obtained by gluing together two congruent equilateral triangles along corresponding edges. Note that $X$ has the structure of a Riemannian manifold except at the three cone points.  In particular, $X$ is a Riemannian orbifold. Is there an isometric embedding of $X$ into $\mathbb{R}^3$?",,"['differential-geometry', 'riemannian-geometry', 'orbifolds']"
89,Riemannian Manifolds with $n(n+1)/2$ dimensional symmetry group,Riemannian Manifolds with  dimensional symmetry group,n(n+1)/2,"Given a $n$-dimensional connected Riemannian manifold $(M,g)$, its symmetry group $G$ can be considered as a subbundle of orthonormal frame bundle of $M$ (which I call $F_OM$), yielding: $$\dim G\le \dim F_OM=\dim M +\dim O(n)={n+n(n-1)\over 2}=\frac{n(n+1)}{2}$$ (Here the embedding $\phi:G \hookrightarrow F_OM$ is defined by singling out an arbitrary point $p \in M$ and orthonormal frame $(v_1,...,v_n) \in F_{O,p} M$ and defining $\phi: g \mapsto (gp,g_*v_1,...,g_*v_n)$. However, it takes some work to verify that this map is indeed injective.) These considerations made me wonder which manifolds have a maximally large symmetry group, i.e. which $M$ do satisfy $\dim G= \frac{n(n+1)}{2}$. Of, course $\Bbb R^n,\Bbb S^n$ and $\Bbb H^n$ have got this property, but are there any other exotic examples? (Some thoughts of mine on this problem: One can see that $M$ is homogenuous and isotropic. Each stabiliser of a point has to be isomorphic to either $SO(n)$ or $O(n)$. In particular, $M$ has constant curvature, which implies that $M$ has to be one of $\Bbb R^n,\Bbb S^n$ and $\Bbb H^n$ if $M$ is complete and simply-connected.)","Given a $n$-dimensional connected Riemannian manifold $(M,g)$, its symmetry group $G$ can be considered as a subbundle of orthonormal frame bundle of $M$ (which I call $F_OM$), yielding: $$\dim G\le \dim F_OM=\dim M +\dim O(n)={n+n(n-1)\over 2}=\frac{n(n+1)}{2}$$ (Here the embedding $\phi:G \hookrightarrow F_OM$ is defined by singling out an arbitrary point $p \in M$ and orthonormal frame $(v_1,...,v_n) \in F_{O,p} M$ and defining $\phi: g \mapsto (gp,g_*v_1,...,g_*v_n)$. However, it takes some work to verify that this map is indeed injective.) These considerations made me wonder which manifolds have a maximally large symmetry group, i.e. which $M$ do satisfy $\dim G= \frac{n(n+1)}{2}$. Of, course $\Bbb R^n,\Bbb S^n$ and $\Bbb H^n$ have got this property, but are there any other exotic examples? (Some thoughts of mine on this problem: One can see that $M$ is homogenuous and isotropic. Each stabiliser of a point has to be isomorphic to either $SO(n)$ or $O(n)$. In particular, $M$ has constant curvature, which implies that $M$ has to be one of $\Bbb R^n,\Bbb S^n$ and $\Bbb H^n$ if $M$ is complete and simply-connected.)",,"['differential-geometry', 'manifolds', 'lie-groups', 'riemannian-geometry']"
90,plane of symmetrie leads to geodesic,plane of symmetrie leads to geodesic,,"Any plane of symmetry intersects a surface in a geodesic. I am having a little difficulty with the proof of this one. The proof says: The normal to the surface in such a point must be invariant under reflection in the plane of symmetry and hence lie in that plane. It is orthogonal to the tangent vector of the curve of intersection and so $\vec T'$ points normally. What I don't understand is the conclusion that $T'$ points normally. I know that we can write $k\vec N=\vec T'=k_n \vec n+k_g \vec n\times\vec T$. We already know that $\vec n$ lies in the plane of symmetry and, as I understand it, $\vec T$ has to lie in the plane, too. So $\vec n\times\vec T$ is perpendicular to the plane of symmetry. So why is $\vec T'$ orthogonal to the surface if it's a combination of a vector in the plane and a vector perpendicular to the plane?","Any plane of symmetry intersects a surface in a geodesic. I am having a little difficulty with the proof of this one. The proof says: The normal to the surface in such a point must be invariant under reflection in the plane of symmetry and hence lie in that plane. It is orthogonal to the tangent vector of the curve of intersection and so $\vec T'$ points normally. What I don't understand is the conclusion that $T'$ points normally. I know that we can write $k\vec N=\vec T'=k_n \vec n+k_g \vec n\times\vec T$. We already know that $\vec n$ lies in the plane of symmetry and, as I understand it, $\vec T$ has to lie in the plane, too. So $\vec n\times\vec T$ is perpendicular to the plane of symmetry. So why is $\vec T'$ orthogonal to the surface if it's a combination of a vector in the plane and a vector perpendicular to the plane?",,['differential-geometry']
91,Injectivity of a map between manifolds,Injectivity of a map between manifolds,,"I'm learning the concepts of immersions at the moment. However I'm a bit confused when they define an immersion as a function $f: X\rightarrow Y$ where $X$ and $Y$ are manifolds with dim$X <$ dim$Y$ such that $df_x: T_x(X)\rightarrow T_y(Y)$ is injective. I was wondering why don't we let $f$ be injective and say that's the best case we can get for the condition dim$X <$ dim$Y$(since under this condition we can't apply the inverse function theorem)? Also does injectivity of $df_x$ inply the injectivity of $f$ (it seems that I can't prove it)? How should we picture immersion as (something like the tangent space of $X$ always ""immerses"" into the tangent space of $Y$)? Thanks for everyone's help!","I'm learning the concepts of immersions at the moment. However I'm a bit confused when they define an immersion as a function $f: X\rightarrow Y$ where $X$ and $Y$ are manifolds with dim$X <$ dim$Y$ such that $df_x: T_x(X)\rightarrow T_y(Y)$ is injective. I was wondering why don't we let $f$ be injective and say that's the best case we can get for the condition dim$X <$ dim$Y$(since under this condition we can't apply the inverse function theorem)? Also does injectivity of $df_x$ inply the injectivity of $f$ (it seems that I can't prove it)? How should we picture immersion as (something like the tangent space of $X$ always ""immerses"" into the tangent space of $Y$)? Thanks for everyone's help!",,"['differential-geometry', 'manifolds', 'differential-topology']"
92,Differential Geometry - Computation Help,Differential Geometry - Computation Help,,"I'm trying to learn differential geometry through one of MIT's online courses (lecture notes found here: http://ocw.mit.edu/courses/mathematics/18-950-differential-geometry-fall-2008/lecture-notes/ch1_revised.pdf ) and am stuck with what should be an easy question.  The question asks to show the following:  Suppose $c(s)$ is a regular curve ($c'(s) \ne 0$) in the plane with $|c(s)| \le 1$ and suppose there is a point t with $|c(t)| = 1$.  Then $|\kappa(t)| \ge 1$.  Here, $\kappa$ is defined as $\frac{det(c', c'')}{||c'||^3}.$ It's should be straightforward if we write $c$ as the graph of a function and rotate so that $c(t) = (0,1)$.  However, I feel as if there should be a more elegant solution using only what's found in the first day's notes (found in the link).  I just don't see it.","I'm trying to learn differential geometry through one of MIT's online courses (lecture notes found here: http://ocw.mit.edu/courses/mathematics/18-950-differential-geometry-fall-2008/lecture-notes/ch1_revised.pdf ) and am stuck with what should be an easy question.  The question asks to show the following:  Suppose $c(s)$ is a regular curve ($c'(s) \ne 0$) in the plane with $|c(s)| \le 1$ and suppose there is a point t with $|c(t)| = 1$.  Then $|\kappa(t)| \ge 1$.  Here, $\kappa$ is defined as $\frac{det(c', c'')}{||c'||^3}.$ It's should be straightforward if we write $c$ as the graph of a function and rotate so that $c(t) = (0,1)$.  However, I feel as if there should be a more elegant solution using only what's found in the first day's notes (found in the link).  I just don't see it.",,['differential-geometry']
93,Prove Green formula,Prove Green formula,,"Let $(M^n,g)$ be an oriented Riemannian manifold with boundary $\partial M$.  The orientation on $Μ$ defines an orientation on $\partial M$. Locally, on the boundary, choose a positively oriented frame field $\{e\} ^{n}_{i=1} $ such that $e_1 =\nu$ is the  unit outward normal. Then the frame field $\{e\} ^{n}_{i=2} $ positively oriented on $\partial M$. Let $\{\omega ^i\} ^{n}_{i=1} $ denote the orthonormal coframe field dual to $\{e\} ^{n}_{i=1} $. The volume form of Μ is $$d\mu=\omega^1 \wedge \cdots\wedge\omega^n $$ and the volume form of $\partial M$ is $$d\sigma=\omega^2 \wedge \cdots\wedge\omega^n $$ By using divergence theorem prove that on a compact manifold, $$\int _{M^n}(u\Delta v-v\Delta u)d\mu=\int_{\partial M^n} (u\frac{\partial v}{\partial \nu }-v\frac{\partial u}{\partial \nu })d\sigma .$$ Divergence theorem :Let $(M^n,g)$ be a compact oriented Riemannian manifola.  If $X$ is a vector fiela, then $$\int_M div(X)d\mu=\int_{\partial M^n} \langle X, \nu \rangle d\sigma$$ where $div(X)= \nabla _i X^i.$","Let $(M^n,g)$ be an oriented Riemannian manifold with boundary $\partial M$.  The orientation on $Μ$ defines an orientation on $\partial M$. Locally, on the boundary, choose a positively oriented frame field $\{e\} ^{n}_{i=1} $ such that $e_1 =\nu$ is the  unit outward normal. Then the frame field $\{e\} ^{n}_{i=2} $ positively oriented on $\partial M$. Let $\{\omega ^i\} ^{n}_{i=1} $ denote the orthonormal coframe field dual to $\{e\} ^{n}_{i=1} $. The volume form of Μ is $$d\mu=\omega^1 \wedge \cdots\wedge\omega^n $$ and the volume form of $\partial M$ is $$d\sigma=\omega^2 \wedge \cdots\wedge\omega^n $$ By using divergence theorem prove that on a compact manifold, $$\int _{M^n}(u\Delta v-v\Delta u)d\mu=\int_{\partial M^n} (u\frac{\partial v}{\partial \nu }-v\frac{\partial u}{\partial \nu })d\sigma .$$ Divergence theorem :Let $(M^n,g)$ be a compact oriented Riemannian manifola.  If $X$ is a vector fiela, then $$\int_M div(X)d\mu=\int_{\partial M^n} \langle X, \nu \rangle d\sigma$$ where $div(X)= \nabla _i X^i.$",,"['differential-geometry', 'riemannian-geometry']"
94,Existence of minimizing geodesic in each fixed-end-point homotopy class in a complete manifold?,Existence of minimizing geodesic in each fixed-end-point homotopy class in a complete manifold?,,"This is intuitively clear, but I cannot solve this homework problem: 1) Let $(M,g)$ be a complete Riemannian manifold, let $c:[0,1]\to M$ be a continuous curve in $M$ such that $c(0)=p, c(1)=q$. Then prove that in the fixed-end-point homotopy class of $c$, there is a geodesic $\gamma$, i.e. there exists a geodesic $\gamma$ so that $\gamma$ is homotopic to $c$ with homotopy keeping the end points $p,q$ fixed. 2) My question: Assuming the above is true, is that geodesic $\gamma$ in the answer necessarily minimizing as well? I feel it should be. I was thinking of using Hopf-Rinow theorem stating that geodesically complete is the same as metrically complete and starting with the contrary. But I got stuck.","This is intuitively clear, but I cannot solve this homework problem: 1) Let $(M,g)$ be a complete Riemannian manifold, let $c:[0,1]\to M$ be a continuous curve in $M$ such that $c(0)=p, c(1)=q$. Then prove that in the fixed-end-point homotopy class of $c$, there is a geodesic $\gamma$, i.e. there exists a geodesic $\gamma$ so that $\gamma$ is homotopic to $c$ with homotopy keeping the end points $p,q$ fixed. 2) My question: Assuming the above is true, is that geodesic $\gamma$ in the answer necessarily minimizing as well? I feel it should be. I was thinking of using Hopf-Rinow theorem stating that geodesically complete is the same as metrically complete and starting with the contrary. But I got stuck.",,"['differential-geometry', 'algebraic-topology', 'riemannian-geometry']"
95,Maximum principle for minimal hypersurfaces,Maximum principle for minimal hypersurfaces,,"The well known local version of the maximum principle for minimal hypersurfaces asserts that if two minimal hypersurfaces $ M_1 $ and $ M_2 $ of $ R^n $ has a common point $ x_0 \in M_1 \cap M_2 $ where $ M_1 $ lies (locally) on one side of $ M_2 $ then $ M_1 = M_2 $ in a neighbourod of $ x_0 $. This result can be found for example in 'A course in minimal surfaces' of Colding Minicozzi. Now i want to prove that if one of them is complete, for example $ M_1 $, then $ M_2 \subset M_1 $. It is quite obvious to proceed in this way: if $ f_i:M_i \rightarrow R^n $, $ i=1,2 $, are the immersion maps, for the local version of the maximum principle there exist $ U_i \subset M_i $ such that $ f_i :U_i \rightarrow R^n $ is an embedding and $ f_1(U_1)=f_2(U_2) $. Now it is easy to check that $f_1^{-1} \circ f_2 : U_2 \rightarrow U_1 $ is an isometry. Now the most obviuos thing to do is an application of the unique continuation theorem since $ f_1 $ and $ f_2 $ are harmonic maps on the manifolds (unique continuation is suggested in Colding Minicozzi, but they do not give a proof). My problem is that i don't know how i can apply the unique continuation for elliptic operators? In fact $ f_1 $ and $ f_2 $ are defined on two hypersurfaces of $ R^n $ that a priori can be distinct. Thank you","The well known local version of the maximum principle for minimal hypersurfaces asserts that if two minimal hypersurfaces $ M_1 $ and $ M_2 $ of $ R^n $ has a common point $ x_0 \in M_1 \cap M_2 $ where $ M_1 $ lies (locally) on one side of $ M_2 $ then $ M_1 = M_2 $ in a neighbourod of $ x_0 $. This result can be found for example in 'A course in minimal surfaces' of Colding Minicozzi. Now i want to prove that if one of them is complete, for example $ M_1 $, then $ M_2 \subset M_1 $. It is quite obvious to proceed in this way: if $ f_i:M_i \rightarrow R^n $, $ i=1,2 $, are the immersion maps, for the local version of the maximum principle there exist $ U_i \subset M_i $ such that $ f_i :U_i \rightarrow R^n $ is an embedding and $ f_1(U_1)=f_2(U_2) $. Now it is easy to check that $f_1^{-1} \circ f_2 : U_2 \rightarrow U_1 $ is an isometry. Now the most obviuos thing to do is an application of the unique continuation theorem since $ f_1 $ and $ f_2 $ are harmonic maps on the manifolds (unique continuation is suggested in Colding Minicozzi, but they do not give a proof). My problem is that i don't know how i can apply the unique continuation for elliptic operators? In fact $ f_1 $ and $ f_2 $ are defined on two hypersurfaces of $ R^n $ that a priori can be distinct. Thank you",,['differential-geometry']
96,Differential of the exponential map on the sphere,Differential of the exponential map on the sphere,,"I have a problem understanding how to compute the differential of the exponential map. Concretely I'm struggling with the following concrete case: Let $M$ be the unit sphere and $p=(0,0,1)$ the north pole. Then let $\exp_p : T_pM \cong \mathbb{R}^2 \times \{0\} \to M $ be the exponential map at $p$. How do I now compute: 1) $\mathrm{D}\exp_p|_{(0,0,0)}(1,0,0)$ 2) $\mathrm{D}\exp_p|_{(\frac{\pi}{2},0,0)}(0,1,0)$ 3) $\mathrm{D}\exp_p|_{(\pi,0,0)}(1,0,0)$ 4) $\mathrm{D}\exp_p|_{(2\pi,0,0)}(1,0,0)$ where $\mathrm{D}\exp_p|_vw$ is viewed as a directional derivative.  I really have no clue how to do this. Can anyone show me the technique how to handle that calculation?","I have a problem understanding how to compute the differential of the exponential map. Concretely I'm struggling with the following concrete case: Let $M$ be the unit sphere and $p=(0,0,1)$ the north pole. Then let $\exp_p : T_pM \cong \mathbb{R}^2 \times \{0\} \to M $ be the exponential map at $p$. How do I now compute: 1) $\mathrm{D}\exp_p|_{(0,0,0)}(1,0,0)$ 2) $\mathrm{D}\exp_p|_{(\frac{\pi}{2},0,0)}(0,1,0)$ 3) $\mathrm{D}\exp_p|_{(\pi,0,0)}(1,0,0)$ 4) $\mathrm{D}\exp_p|_{(2\pi,0,0)}(1,0,0)$ where $\mathrm{D}\exp_p|_vw$ is viewed as a directional derivative.  I really have no clue how to do this. Can anyone show me the technique how to handle that calculation?",,['differential-geometry']
97,Tangent space as the dual of an ideal quotient,Tangent space as the dual of an ideal quotient,,"I'm just trying to understand better this way of seeing the tangent space. Given a manifold $M$, it's possible to define the tangent space as $(\mathfrak{I}/\mathfrak{I^2})^*$ , being $\mathfrak{I} = \{f \in C^\infty (M, p); f(p) = 0 \}$ and $C^\infty (M, p)$ the germ of functions on $p$. Or, for a given local ring $R$, the cotangent space is defined analogously as $\mathfrak{m}/\mathfrak{m^2}$, being $\mathfrak{m}$ the unique maximal ideal in this ring . I've already know that $(\mathfrak{I}/\mathfrak{I^2})^*$ is isomorphic to the set of derivations in $C^\infty (M, p)$ by picking the linear functional $l_v(f) = v(f - f(m) + \mathfrak{I^2})$. Furthermore, $\mathfrak{I^2}$ is the zero because always $v(f^2) = 0$. Despite these stuffs, this definition seems very unnatural to me. Is there any intuitive way to see the tangent space via this definition?","I'm just trying to understand better this way of seeing the tangent space. Given a manifold $M$, it's possible to define the tangent space as $(\mathfrak{I}/\mathfrak{I^2})^*$ , being $\mathfrak{I} = \{f \in C^\infty (M, p); f(p) = 0 \}$ and $C^\infty (M, p)$ the germ of functions on $p$. Or, for a given local ring $R$, the cotangent space is defined analogously as $\mathfrak{m}/\mathfrak{m^2}$, being $\mathfrak{m}$ the unique maximal ideal in this ring . I've already know that $(\mathfrak{I}/\mathfrak{I^2})^*$ is isomorphic to the set of derivations in $C^\infty (M, p)$ by picking the linear functional $l_v(f) = v(f - f(m) + \mathfrak{I^2})$. Furthermore, $\mathfrak{I^2}$ is the zero because always $v(f^2) = 0$. Despite these stuffs, this definition seems very unnatural to me. Is there any intuitive way to see the tangent space via this definition?",,"['algebraic-geometry', 'differential-geometry']"
98,Measuring curvature in Flatland,Measuring curvature in Flatland,,"Gauss' Theorema egregium says that the Gaussian curvature of a surface can be   determined entirely by measuring angles, distances and their rates on   the surface itself. A surface looks like $\mathbb{R}^2$ locally  so the angle sum of arbitrarily small triangles tends to $\pi$, doesn't it? Only when one considers bigger triangles - as Gauss did - one will find angle sums deviating from $\pi$. So I wonder how - concretely - an inhabitant of an arbitrarily (but smoothly) curved surface would measure the Gaussian curvature at a given point.","Gauss' Theorema egregium says that the Gaussian curvature of a surface can be   determined entirely by measuring angles, distances and their rates on   the surface itself. A surface looks like $\mathbb{R}^2$ locally  so the angle sum of arbitrarily small triangles tends to $\pi$, doesn't it? Only when one considers bigger triangles - as Gauss did - one will find angle sums deviating from $\pi$. So I wonder how - concretely - an inhabitant of an arbitrarily (but smoothly) curved surface would measure the Gaussian curvature at a given point.",,['differential-geometry']
99,Properties of geodesics on ruled surfaces,Properties of geodesics on ruled surfaces,,"I am trying to solve the following problem: Show that a unit-speed curve $\gamma$ with nowhere vanishing curvature is a geodesic on the ruled surface $\sigma(u,v)=\gamma(u)+v\delta(u)$, where $\gamma$ is a smooth function of $u$, if and only if $\delta$ is perpendicular to the principal normal of $\gamma$ at $\gamma(u)$ for all values of $u$. Edit (rather large): My professor wrote the question down wrong. I fixed it on here. Sadly, even with it right, I can't get either direction. Any help would be appreciated. Thanks!","I am trying to solve the following problem: Show that a unit-speed curve $\gamma$ with nowhere vanishing curvature is a geodesic on the ruled surface $\sigma(u,v)=\gamma(u)+v\delta(u)$, where $\gamma$ is a smooth function of $u$, if and only if $\delta$ is perpendicular to the principal normal of $\gamma$ at $\gamma(u)$ for all values of $u$. Edit (rather large): My professor wrote the question down wrong. I fixed it on here. Sadly, even with it right, I can't get either direction. Any help would be appreciated. Thanks!",,"['differential-geometry', 'curvature', 'geodesic']"
