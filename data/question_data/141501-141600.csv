,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to solve this limit problem?-$\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}}$,How to solve this limit problem?-,\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}},"I need to find the value of- $$\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}}$$ where $m {\in} R$ I don't know how to even start. Would someone explain it step by step, also which type of indeterminate form is this? Is there a simpler to solve this ? i.e. without any high mathematics theorem etc.?","I need to find the value of- $$\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}}$$ where $m {\in} R$ I don't know how to even start. Would someone explain it step by step, also which type of indeterminate form is this? Is there a simpler to solve this ? i.e. without any high mathematics theorem etc.?",,[]
1,application of L'Hopital's rule?,application of L'Hopital's rule?,,"I am trying to evaluate the following  limit:  $$ \lim_{x \to 0} \frac{e^x}{\sum_{n = 1}^\infty n^k e^{-nx}}, $$ where $k$ is a large (but fixed) positive integer. I am unsure how to proceed. Can this be done using L'Hopital's rule? Just started learning calculus, thanks guys!!","I am trying to evaluate the following  limit:  $$ \lim_{x \to 0} \frac{e^x}{\sum_{n = 1}^\infty n^k e^{-nx}}, $$ where $k$ is a large (but fixed) positive integer. I am unsure how to proceed. Can this be done using L'Hopital's rule? Just started learning calculus, thanks guys!!",,"['calculus', 'limits', 'derivatives']"
2,Showing that if $\lim_{x\to\infty}f'(x)=L$ then $\lim_{x\to\infty}\frac{f(x)}{x} = L$. [duplicate],Showing that if  then . [duplicate],\lim_{x\to\infty}f'(x)=L \lim_{x\to\infty}\frac{f(x)}{x} = L,"This question already has an answer here : if $f'(x)\rightarrow L$ as $ x \rightarrow \infty$, $-\infty \leq L \leq \infty $ then $ f(x)/x \rightarrow L $ as $x \rightarrow \infty$ [duplicate] (1 answer) Closed 6 years ago . Let $f:[0,\infty)\to\mathbb{R}$ differentiable and suppose that $$\lim_{x\to\infty}f'(x)=L.$$ How can I prove that $$\lim_{x\to\infty}\frac{f(x)}{x} = L\;?$$ I have solved some similar problems using the Mean Value Theorem, and I am trying to use it again in this one, but nothing works. For example, I tried to apply the MVT in $[x, 2x]$ but it does not work. Some hint?","This question already has an answer here : if $f'(x)\rightarrow L$ as $ x \rightarrow \infty$, $-\infty \leq L \leq \infty $ then $ f(x)/x \rightarrow L $ as $x \rightarrow \infty$ [duplicate] (1 answer) Closed 6 years ago . Let differentiable and suppose that How can I prove that I have solved some similar problems using the Mean Value Theorem, and I am trying to use it again in this one, but nothing works. For example, I tried to apply the MVT in but it does not work. Some hint?","f:[0,\infty)\to\mathbb{R} \lim_{x\to\infty}f'(x)=L. \lim_{x\to\infty}\frac{f(x)}{x} = L\;? [x, 2x]","['real-analysis', 'limits', 'derivatives']"
3,Finding the limit of a fraction: $\lim_{x \to 3} \frac{x^3-27}{x^2-9}$,Finding the limit of a fraction:,\lim_{x \to 3} \frac{x^3-27}{x^2-9},Find $$\lim_{x \to 3} \frac{x^3-27}{x^2-9}$$ What I did is: \begin{align} \lim_{x \to 3} \frac{x^3-27}{x^2-9} &= \lim_{x \to 3} \frac{(x-3)^3+9x-27x}{(x-3)(x+3)} = \lim_{x \to 3} \frac{(x-3)^3+9(x-3)}{(x-3)(x+3)} \\ &= \lim_{x \to 3} \frac{(x-3)^3}{(x-3)(x+3)} + \lim_{x \to 3} \frac{9(x-3)}{(x-3)(x+3)} \\ &= \lim_{x \to 3} \frac{(x-3)^2}{(x+3)} + \lim_{x \to 3} \frac{9}{(x+3)} =0  + \frac{9}{6} \end{align} Wolfram factor the numerator to $(x-3)(x^2+3x+9)$ is there a quick way to find this?,Find What I did is: Wolfram factor the numerator to is there a quick way to find this?,"\lim_{x \to 3} \frac{x^3-27}{x^2-9} \begin{align}
\lim_{x \to 3} \frac{x^3-27}{x^2-9} &= \lim_{x \to 3} \frac{(x-3)^3+9x-27x}{(x-3)(x+3)} = \lim_{x \to 3} \frac{(x-3)^3+9(x-3)}{(x-3)(x+3)} \\
&= \lim_{x \to 3} \frac{(x-3)^3}{(x-3)(x+3)} + \lim_{x \to 3} \frac{9(x-3)}{(x-3)(x+3)} \\
&= \lim_{x \to 3} \frac{(x-3)^2}{(x+3)} + \lim_{x \to 3} \frac{9}{(x+3)} =0  + \frac{9}{6}
\end{align} (x-3)(x^2+3x+9)","['calculus', 'limits']"
4,"The behavior of the graph of $f(x) = \sin (\pi/x)$ as x approaches 0, Why?","The behavior of the graph of  as x approaches 0, Why?",f(x) = \sin (\pi/x),"This is my first post.  I hope it is relevant. for the $\lim_{x\to0}\sin(\pi/x)$ The limit does not exist. I am curious if my logic is appropriate or if there is another way to understand this. So what I believe is the following: As $x\to 0$ we have that $  \pi/x\to\infty$ Therefore,  $\sin(\infty)$, which makes sense by the fact that as x approaches 0, the input of sine will increase to infinity or some large number.  As a result, sine will repeat its periods indefinitely.  It will oscillate between 1 and -1 indefinitely as x approaches 0. I missed one thing and that is this is a two-sided limit, so sine's input is approaching positive and negative infinity","This is my first post.  I hope it is relevant. for the $\lim_{x\to0}\sin(\pi/x)$ The limit does not exist. I am curious if my logic is appropriate or if there is another way to understand this. So what I believe is the following: As $x\to 0$ we have that $  \pi/x\to\infty$ Therefore,  $\sin(\infty)$, which makes sense by the fact that as x approaches 0, the input of sine will increase to infinity or some large number.  As a result, sine will repeat its periods indefinitely.  It will oscillate between 1 and -1 indefinitely as x approaches 0. I missed one thing and that is this is a two-sided limit, so sine's input is approaching positive and negative infinity",,"['limits', 'trigonometry']"
5,Confused about this limit,Confused about this limit,,If $\lim_{x \to \infty} (-1)^x$ is undefined ... Why is $\lim_{x \to \infty} (-1/4)^x$ zero? Couldn't you take out the negative to make it $\lim_{x \to \infty} (-1)^x$ * $\lim_{x \to \infty} (-1/4)^x$ which would make it undefined? Does undefined * 0 = undefined or 0?,If $\lim_{x \to \infty} (-1)^x$ is undefined ... Why is $\lim_{x \to \infty} (-1/4)^x$ zero? Couldn't you take out the negative to make it $\lim_{x \to \infty} (-1)^x$ * $\lim_{x \to \infty} (-1/4)^x$ which would make it undefined? Does undefined * 0 = undefined or 0?,,['limits']
6,Evaluate limit of $(2\sin x\log \cos x + x^{3})/x^{7}$ as $x \to 0$,Evaluate limit of  as,(2\sin x\log \cos x + x^{3})/x^{7} x \to 0,"While trying to solve this question , I came across the following limit $$\lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{6}}\tag{1}$$ Using some algebraic manipulation (and L'Hospital's Rule) I was able to show that $$\lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{5}} = 0\tag{2}$$ From the fact that the numerator in the above limit expression is an odd function, I guessed that the limit in $(1)$ would also be $0$ (it would be great if this guess can be supported by a proof). However I was not able to do this via simple algebraic manipulation. Also note that evaluating $(1)$ is equivalent to solving the linked question (without the assumption of existence of limit). I think it is better to go one step ahead and establish that $$\lim_{x \to 0}\frac{2\sin x \log \cos x + x^{3}}{x^{7}} = -\frac{1}{40}\tag{3}$$ It is possible to evaluate the above limit via Taylor's series very easily, but I would prefer to have a solution of either $(1)$ or $(3)$ without using Taylor's series. Update : I provide an evaluation of limit $(2)$ as an illustration of the kind of answer I would prefer. We have \begin{align} L &= \lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + x^{3}}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x + x^{3} - \sin^{3}x}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x}{x^{5}} + \frac{x^{3} - \sin^{3}x}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x}{\sin^{5}x}\cdot\frac{\sin^{5}x}{x^{5}} + \lim_{x \to 0}\frac{x - \sin x}{x^{3}}\cdot\frac{x^{2} + x\sin x + \sin^{2}x}{x^{2}}\notag\\ &= \lim_{x \to 0}\frac{\log (1 - \sin^{2}x) + \sin^{2}x}{\sin^{4}x}\cdot 1 + \lim_{x \to 0}\frac{1 - \cos x}{3x^{2}}\cdot (1 + 1 + 1)\text{ (via LHR)}\notag\\ &= \lim_{t \to 0}\frac{\log (1 - t) + t}{t^{2}} + \frac{1}{2}\notag\\ &= \lim_{t \to 0}\dfrac{-\dfrac{1}{1 - t} + 1}{2t} + \frac{1}{2}\text{ (via LHR)}\notag\\ &= -\frac{1}{2} + \frac{1}{2} = 0\notag \end{align} Further Update : I have finally found a solution which uses algebraic manipulation and L'Hospital's Rule. The rule has been applied 4 times in total and resulting expressions are simple. See the details in my answer.","While trying to solve this question , I came across the following limit $$\lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{6}}\tag{1}$$ Using some algebraic manipulation (and L'Hospital's Rule) I was able to show that $$\lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{5}} = 0\tag{2}$$ From the fact that the numerator in the above limit expression is an odd function, I guessed that the limit in $(1)$ would also be $0$ (it would be great if this guess can be supported by a proof). However I was not able to do this via simple algebraic manipulation. Also note that evaluating $(1)$ is equivalent to solving the linked question (without the assumption of existence of limit). I think it is better to go one step ahead and establish that $$\lim_{x \to 0}\frac{2\sin x \log \cos x + x^{3}}{x^{7}} = -\frac{1}{40}\tag{3}$$ It is possible to evaluate the above limit via Taylor's series very easily, but I would prefer to have a solution of either $(1)$ or $(3)$ without using Taylor's series. Update : I provide an evaluation of limit $(2)$ as an illustration of the kind of answer I would prefer. We have \begin{align} L &= \lim_{x \to 0}\frac{2\sin x\log \cos x + x^{3}}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + x^{3}}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x + x^{3} - \sin^{3}x}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x}{x^{5}} + \frac{x^{3} - \sin^{3}x}{x^{5}}\notag\\ &= \lim_{x \to 0}\frac{\sin x\log (1 - \sin^{2}x) + \sin^{3}x}{\sin^{5}x}\cdot\frac{\sin^{5}x}{x^{5}} + \lim_{x \to 0}\frac{x - \sin x}{x^{3}}\cdot\frac{x^{2} + x\sin x + \sin^{2}x}{x^{2}}\notag\\ &= \lim_{x \to 0}\frac{\log (1 - \sin^{2}x) + \sin^{2}x}{\sin^{4}x}\cdot 1 + \lim_{x \to 0}\frac{1 - \cos x}{3x^{2}}\cdot (1 + 1 + 1)\text{ (via LHR)}\notag\\ &= \lim_{t \to 0}\frac{\log (1 - t) + t}{t^{2}} + \frac{1}{2}\notag\\ &= \lim_{t \to 0}\dfrac{-\dfrac{1}{1 - t} + 1}{2t} + \frac{1}{2}\text{ (via LHR)}\notag\\ &= -\frac{1}{2} + \frac{1}{2} = 0\notag \end{align} Further Update : I have finally found a solution which uses algebraic manipulation and L'Hospital's Rule. The rule has been applied 4 times in total and resulting expressions are simple. See the details in my answer.",,"['calculus', 'limits']"
7,Under what conditions is $\lim f(x)=e^{\lim \ln(f(x))}$,Under what conditions is,\lim f(x)=e^{\lim \ln(f(x))},"Under what conditions is $\lim_{x\to c} f(x)=e^{\lim_{x \to c} \ln(f(x))}$? I saw this limit in an article used to show that: $$\lim_{\rho \to 0} [\alpha x_{1}^{\rho} + (1-\alpha) x_{2}^{\rho}]^{\frac{1}{\rho}} = x_{1}^{\alpha}x_{2}^{1-\alpha}$$ where the ""trick"" is used to apply l'hopitals rule to: $$\lim_{\rho \to 0} \frac{\ln(\alpha x_{1}^{\rho} + (1-\alpha) x_{2}^{\rho})}{\rho} $$ However I was unaware that this trick existed before today, and I am wondering if there are conditions under which it applies?","Under what conditions is $\lim_{x\to c} f(x)=e^{\lim_{x \to c} \ln(f(x))}$? I saw this limit in an article used to show that: $$\lim_{\rho \to 0} [\alpha x_{1}^{\rho} + (1-\alpha) x_{2}^{\rho}]^{\frac{1}{\rho}} = x_{1}^{\alpha}x_{2}^{1-\alpha}$$ where the ""trick"" is used to apply l'hopitals rule to: $$\lim_{\rho \to 0} \frac{\ln(\alpha x_{1}^{\rho} + (1-\alpha) x_{2}^{\rho})}{\rho} $$ However I was unaware that this trick existed before today, and I am wondering if there are conditions under which it applies?",,['limits']
8,Find $\lim_\limits{x\to 0}{(\sqrt{f^2(x)+2f(x)+3}-f(x))}$,Find,\lim_\limits{x\to 0}{(\sqrt{f^2(x)+2f(x)+3}-f(x))},"Let $f$ be a function such that $x^2f(x)\geq x^2+x+1,\forall x\in\mathbb{R^*}$. Find the value of: $$\lim_\limits{x\to 0}{\left(\sqrt{f^2(x)+2f(x)+3}-f(x)\right)}$$ I think that we may need to apply a sandwich theorem for the limit, so let $g(x)=\sqrt{f^2(x)+2f(x)+3}-f(x)$. It is easy to prove that $g(x)>1$ near/close to 0, since $f(x)>0$ from the original relation. However, I cannot find any function $h$, such that $g(x)<h(x)$ near/close to 0 with $\lim_\limits{x\to 0}{h(x)}=1$. Any hint?","Let $f$ be a function such that $x^2f(x)\geq x^2+x+1,\forall x\in\mathbb{R^*}$. Find the value of: $$\lim_\limits{x\to 0}{\left(\sqrt{f^2(x)+2f(x)+3}-f(x)\right)}$$ I think that we may need to apply a sandwich theorem for the limit, so let $g(x)=\sqrt{f^2(x)+2f(x)+3}-f(x)$. It is easy to prove that $g(x)>1$ near/close to 0, since $f(x)>0$ from the original relation. However, I cannot find any function $h$, such that $g(x)<h(x)$ near/close to 0 with $\lim_\limits{x\to 0}{h(x)}=1$. Any hint?",,['limits']
9,Find $\lim_\limits{x\to -1}{f(x)}$,Find,\lim_\limits{x\to -1}{f(x)},"Let $f:\mathbb{R}\mapsto\mathbb{R}$ be a function such that: $$f(x)=f(1-x), \forall x \in\mathbb{R}$$ $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1$$ Find $\lim_\limits{x\to -1}{f(x)}$. I have tried the following: $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(2+h)+4}{h}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(-h-1)+4}{h}}=1$$ So, I may need to show that $f(-h-1)=f(h+1)$ and I am done. Any hint?","Let $f:\mathbb{R}\mapsto\mathbb{R}$ be a function such that: $$f(x)=f(1-x), \forall x \in\mathbb{R}$$ $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1$$ Find $\lim_\limits{x\to -1}{f(x)}$. I have tried the following: $$\lim_\limits{x\to 2}{\frac{f(x)+4}{x-2}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(2+h)+4}{h}}=1\Leftrightarrow \lim_\limits{h\to 0}{\frac{f(-h-1)+4}{h}}=1$$ So, I may need to show that $f(-h-1)=f(h+1)$ and I am done. Any hint?",,['limits']
10,How prove $\lim_{x\to 0}f(x) = 0\iff\lim_{x\to 0}xf(x) = 0 $? [closed],How prove ? [closed],\lim_{x\to 0}f(x) = 0\iff\lim_{x\to 0}xf(x) = 0 ,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f:R \rightarrow R$ such that  $$| f(x+y)-f(x)-f(y) |\le |x-y|,$$ for all $x, y \in R.$ How can I prove that  $$\lim_{x\to 0}f(x) = 0\iff\lim_{x\to 0}xf(x) = 0? $$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f:R \rightarrow R$ such that  $$| f(x+y)-f(x)-f(y) |\le |x-y|,$$ for all $x, y \in R.$ How can I prove that  $$\lim_{x\to 0}f(x) = 0\iff\lim_{x\to 0}xf(x) = 0? $$",,['limits']
11,Finding $\lim_{x\to +\infty}(\frac{x+\ln x}{ x-\ln x})^{\frac{x}{\ln x}}$,Finding,\lim_{x\to +\infty}(\frac{x+\ln x}{ x-\ln x})^{\frac{x}{\ln x}},Find $\lim_{x\to +\infty}(\frac{x+\ln x}{ x-\ln x})^{\frac{x}{\ln x}}$. I tried using l'Hospital rule with the continuity of $e$ function. Also tried using Taylor expansion with no success. What should I do? Thank you.,Find $\lim_{x\to +\infty}(\frac{x+\ln x}{ x-\ln x})^{\frac{x}{\ln x}}$. I tried using l'Hospital rule with the continuity of $e$ function. Also tried using Taylor expansion with no success. What should I do? Thank you.,,"['calculus', 'real-analysis', 'limits']"
12,Prove that $\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0$ in the $\epsilon$-$\delta$ way [duplicate],Prove that  in the - way [duplicate],\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0 \epsilon \delta,This question already exists : Proving a limit of a trigonometric function: $\lim_{x \to 2/\pi}\lfloor \sin \frac{1}{x} \rfloor=0$ Closed 9 years ago . Given: $$\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0$$ How to prove this limit using the $\epsilon$-$\delta$ way? (the biggest problem is to find $\delta$),This question already exists : Proving a limit of a trigonometric function: $\lim_{x \to 2/\pi}\lfloor \sin \frac{1}{x} \rfloor=0$ Closed 9 years ago . Given: $$\lim_{x \to \frac{2}{\pi}}\lfloor \sin \frac{1}{x} \rfloor=0$$ How to prove this limit using the $\epsilon$-$\delta$ way? (the biggest problem is to find $\delta$),,"['calculus', 'limits', 'trigonometry', 'epsilon-delta', 'ceiling-and-floor-functions']"
13,"Tedious undefined limit without L'Hospital $\mathop {\lim }\limits_{x \to \frac{\pi }{2}} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}$",Tedious undefined limit without L'Hospital,"\mathop {\lim }\limits_{x \to \frac{\pi }{2}} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}","When I try to calculate this limit: $$\mathop {\lim }\limits_{x \to \frac{\pi}{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}$$ I find this: $$\begin{array}{l} L = \mathop {\lim }\limits_{x \to \frac{\pi }{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}\\ \text{variable changing}\\ y = 2x - \pi \\ x \to \frac{\pi }{2}\,\,\,\, \Rightarrow \,\,\,y \to 0\\ \text{so:}\\ L = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{{y + \pi }}{2}} \right)}}{{\ln \,(y)}} = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{y}{2} + \frac{\pi }{2}} \right)}}{{\ln \,(y)}}\\  = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{ - \cot\,\left( {\frac{y}{2}} \right)}}{{\ln \,(y)}} =  - \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\csc (y) + \cot (y)}}{{\ln \,(y)}}\\  = \frac{{ \pm \infty  \pm \infty }}{{ - \infty }} = ?? \end{array}$$ and in the latter part I get stuck, should be obtained using mathematical software $L= \pm \infty$ how I justify without L'Hospital?","When I try to calculate this limit: I find this: and in the latter part I get stuck, should be obtained using mathematical software how I justify without L'Hospital?","\mathop {\lim }\limits_{x \to \frac{\pi}{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}} \begin{array}{l}
L = \mathop {\lim }\limits_{x \to \frac{\pi }{2}^+} \,\,\frac{{\tan \,(x)}}{{\ln \,(2x - \pi )}}\\
\text{variable changing}\\
y = 2x - \pi \\
x \to \frac{\pi }{2}\,\,\,\, \Rightarrow \,\,\,y \to 0\\
\text{so:}\\
L = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{{y + \pi }}{2}} \right)}}{{\ln \,(y)}} = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\tan \,\left( {\frac{y}{2} + \frac{\pi }{2}} \right)}}{{\ln \,(y)}}\\
 = \mathop {\lim }\limits_{y \to 0} \,\,\frac{{ - \cot\,\left( {\frac{y}{2}} \right)}}{{\ln \,(y)}} =  - \mathop {\lim }\limits_{y \to 0} \,\,\frac{{\csc (y) + \cot (y)}}{{\ln \,(y)}}\\
 = \frac{{ \pm \infty  \pm \infty }}{{ - \infty }} = ??
\end{array} L= \pm \infty","['calculus', 'real-analysis', 'analysis', 'limits', 'limits-without-lhopital']"
14,Find the limit of $\sqrt{x^2+x-1} +x$ as $x\to-\infty$,Find the limit of  as,\sqrt{x^2+x-1} +x x\to-\infty,"Find the limit of $\sqrt{x^2+x-1} +x$ as $x\to-\infty$. My solution: multiplying by: $\displaystyle\frac{\sqrt{x^2+x-1}-x}{\sqrt{x^2+x-1}-x}$ Which gives us: $\displaystyle\frac{x-1}{\sqrt{x^2+x-1}-x}$ dividing by $\sqrt{x^2}$ gives: $\displaystyle \frac{1}{\sqrt{1}-1}$ which equals $1/0$ However, I double checked my answers, and this does not seem to be correct, am I making a mistake (perhaps when I take the $\sqrt{1}$ in the denominator of the last step?","Find the limit of $\sqrt{x^2+x-1} +x$ as $x\to-\infty$. My solution: multiplying by: $\displaystyle\frac{\sqrt{x^2+x-1}-x}{\sqrt{x^2+x-1}-x}$ Which gives us: $\displaystyle\frac{x-1}{\sqrt{x^2+x-1}-x}$ dividing by $\sqrt{x^2}$ gives: $\displaystyle \frac{1}{\sqrt{1}-1}$ which equals $1/0$ However, I double checked my answers, and this does not seem to be correct, am I making a mistake (perhaps when I take the $\sqrt{1}$ in the denominator of the last step?",,"['calculus', 'limits', 'radicals']"
15,"Answer Says $\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6} = 0$. I say DNE. What did I do wrong? [duplicate]",Answer Says . I say DNE. What did I do wrong? [duplicate],"\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6} = 0","This question already has answers here : Does the limit $\lim_{(x,y)\to (0,0)} \frac {x^3y^2}{x^4+y^6}$ exist (2 answers) Closed 8 years ago . I was asked to find  $$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6}$$ Observe that setting y=mx results in $$\lim_{(x,mx)\rightarrow(0,0)}\frac{x^3(mx)^2}{x^4+(mx)^6} = 0$$ The textbook solution then proved that the limit is 0 using the squeeze theorem. However, I tried to set y=x^(4/6) and I got: $$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3(x^{\frac{4}{6}})^2}{x^4+(x^{\frac{4}{6}})^6} = \lim_{x\rightarrow0}\frac{x^4}{x^4+x^4} = \frac{1}{2}$$ So I concluded that the limit does not exist.  I am not convinced that my solution is correct, I would really appreciate to know the reason why I am wrong. Thank you","This question already has answers here : Does the limit $\lim_{(x,y)\to (0,0)} \frac {x^3y^2}{x^4+y^6}$ exist (2 answers) Closed 8 years ago . I was asked to find  $$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3y^2}{x^4+y^6}$$ Observe that setting y=mx results in $$\lim_{(x,mx)\rightarrow(0,0)}\frac{x^3(mx)^2}{x^4+(mx)^6} = 0$$ The textbook solution then proved that the limit is 0 using the squeeze theorem. However, I tried to set y=x^(4/6) and I got: $$\lim_{(x,y)\rightarrow(0,0)}\frac{x^3(x^{\frac{4}{6}})^2}{x^4+(x^{\frac{4}{6}})^6} = \lim_{x\rightarrow0}\frac{x^4}{x^4+x^4} = \frac{1}{2}$$ So I concluded that the limit does not exist.  I am not convinced that my solution is correct, I would really appreciate to know the reason why I am wrong. Thank you",,"['calculus', 'limits', 'multivariable-calculus']"
16,Proving that expression is equivalent to the definition of derivative,Proving that expression is equivalent to the definition of derivative,,"Let $f$ be differentiable at $x=a$. Prove that if $x_n \to a^+$ and $y_n \to a^-$ then: $$\lim_{n\to \infty} \frac{f(x_n)-f(y_n)}{x_n-y_n}=f'(a).$$ Every option that I think about seems to my very trivial, so I believe that I am doing something wrong.  Both numerator and denominator approach zero as $n\to\infty$ as the case of the formal definition of derivative, but it isn't guaranteed that the limits are equal (“$\frac{0}{0}$”). Any direction?","Let $f$ be differentiable at $x=a$. Prove that if $x_n \to a^+$ and $y_n \to a^-$ then: $$\lim_{n\to \infty} \frac{f(x_n)-f(y_n)}{x_n-y_n}=f'(a).$$ Every option that I think about seems to my very trivial, so I believe that I am doing something wrong.  Both numerator and denominator approach zero as $n\to\infty$ as the case of the formal definition of derivative, but it isn't guaranteed that the limits are equal (“$\frac{0}{0}$”). Any direction?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
17,Find $\lim_{n\to\infty}$ of this quotient.,Find  of this quotient.,\lim_{n\to\infty},"Find, with proof, the value of this limit $$\lim_{n\to\infty}\frac{\sum^n_{r=0}\binom{2n}{2r}\cdot2^r}{\sum^{n-1}_{r=0}\binom{2n}{2r+1}\cdot2^r}$$ I have tried using binomial identities but two problems occur: Only even binomial coefficients in numerator and only odd in denominator. The binomial coefficient occurs with $2^r$ and not with $2^{2r}$ which would be the binomial identity.","Find, with proof, the value of this limit $$\lim_{n\to\infty}\frac{\sum^n_{r=0}\binom{2n}{2r}\cdot2^r}{\sum^{n-1}_{r=0}\binom{2n}{2r+1}\cdot2^r}$$ I have tried using binomial identities but two problems occur: Only even binomial coefficients in numerator and only odd in denominator. The binomial coefficient occurs with $2^r$ and not with $2^{2r}$ which would be the binomial identity.",,"['limits', 'summation', 'binomial-coefficients', 'contest-math']"
18,How can a point of symmetry have a slope which isn't either $0$ or $±\infty$?,How can a point of symmetry have a slope which isn't either  or ?,0 ±\infty,"I've got a bit of a doubt with a question I'm solving. It goes like this: For $a>0$, let $f:[-4a,4a] \to R$ be an even function such that $f(x) = f(4a - x) \hspace{2 mm}\forall x \in [2a, 4a]$ and    $$\lim_{h\to0} \frac{f(2a + h) - f(2a)}{h} = 4,$$   then   $$\lim_{h\to0} \frac{f(h-2a) - f(-2a)}{2h} = \hspace{2mm}?,$$ Here's my reasoning: It's been given that the function is even , so it's obviously symmetric about the y-axis. Another piece of information which has been give is that $f(x) = f(4a - x) \hspace{2 mm}\forall x\in [2a, 4a]$. So it's gotta be symmetric about the line $x = 2a$ in the interval $ x\in[0,4a]$ too. So the graph would look something like this: Either that, or a cusp or a sharp corner would exist at $x = ±2a$. But, in the question, it's given that $$\lim_{h\to0} \frac{f(2a + h) - f(2a)}{h} = 4,$$ which means that the slope of the graph at $x = 2a$ is $4$. How is this possible, if the only options are: as in the graph, a maxima (or a minima) exists, thus the slope is $0$. a sharp corner exists - which means that the derivative isn't defined at the point. a cusp exists - which means the slope is either $±\infty$! So how is it possible that a portion of the graph be symmetric about a value, but still have a derivative which isn't either $0$ or $±\infty$? Or is it that the question is wrong itself?","I've got a bit of a doubt with a question I'm solving. It goes like this: For $a>0$, let $f:[-4a,4a] \to R$ be an even function such that $f(x) = f(4a - x) \hspace{2 mm}\forall x \in [2a, 4a]$ and    $$\lim_{h\to0} \frac{f(2a + h) - f(2a)}{h} = 4,$$   then   $$\lim_{h\to0} \frac{f(h-2a) - f(-2a)}{2h} = \hspace{2mm}?,$$ Here's my reasoning: It's been given that the function is even , so it's obviously symmetric about the y-axis. Another piece of information which has been give is that $f(x) = f(4a - x) \hspace{2 mm}\forall x\in [2a, 4a]$. So it's gotta be symmetric about the line $x = 2a$ in the interval $ x\in[0,4a]$ too. So the graph would look something like this: Either that, or a cusp or a sharp corner would exist at $x = ±2a$. But, in the question, it's given that $$\lim_{h\to0} \frac{f(2a + h) - f(2a)}{h} = 4,$$ which means that the slope of the graph at $x = 2a$ is $4$. How is this possible, if the only options are: as in the graph, a maxima (or a minima) exists, thus the slope is $0$. a sharp corner exists - which means that the derivative isn't defined at the point. a cusp exists - which means the slope is either $±\infty$! So how is it possible that a portion of the graph be symmetric about a value, but still have a derivative which isn't either $0$ or $±\infty$? Or is it that the question is wrong itself?",,"['calculus', 'limits', 'functions', 'derivatives', 'graphing-functions']"
19,Determine the definite limit,Determine the definite limit,,The following limit $$\lim_{x\to 1}\frac{1}{2(1 - \sqrt{x})} - \frac{1}{3(1 - \sqrt[3]{x})}$$ evaluates to 1/12. This is my progress so far: $$\lim_{x\to 1}\frac{1}{2(1 - \sqrt{x})} - \frac{1}{3(1 - \sqrt[3]{x})}$$ $$\lim_{x\to 1}\frac{1 + \sqrt{x}}{2(1 - x)} - \frac{1 + \sqrt[3]{x} + \sqrt[3]{x^2}}{3(1 - x)}$$ $$\lim_{x\to 1}\frac{3(1 + \sqrt{x})- 2(1 + \sqrt[3]{x} + \sqrt[3]{x^2})}{6(1 - x)}$$ And that's as far as I go.,The following limit $$\lim_{x\to 1}\frac{1}{2(1 - \sqrt{x})} - \frac{1}{3(1 - \sqrt[3]{x})}$$ evaluates to 1/12. This is my progress so far: $$\lim_{x\to 1}\frac{1}{2(1 - \sqrt{x})} - \frac{1}{3(1 - \sqrt[3]{x})}$$ $$\lim_{x\to 1}\frac{1 + \sqrt{x}}{2(1 - x)} - \frac{1 + \sqrt[3]{x} + \sqrt[3]{x^2}}{3(1 - x)}$$ $$\lim_{x\to 1}\frac{3(1 + \sqrt{x})- 2(1 + \sqrt[3]{x} + \sqrt[3]{x^2})}{6(1 - x)}$$ And that's as far as I go.,,"['calculus', 'limits']"
20,Does $\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}}$ exist? [duplicate],Does  exist? [duplicate],\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}},"This question already has answers here : Closed 11 years ago . Possible Duplicate: Explaining $\cos^\infty$ Does the following limit exist? $$\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}}$$ If yes, find the limit. If no, please explain why the limit doesn't exist. I think, the limit exists. So, I tried to use Squeeze theorem but didn't work.","This question already has answers here : Closed 11 years ago . Possible Duplicate: Explaining $\cos^\infty$ Does the following limit exist? $$\lim_{n\to\infty}\underset{n}{\underbrace{\cos(\cos(...\cos x))}}$$ If yes, find the limit. If no, please explain why the limit doesn't exist. I think, the limit exists. So, I tried to use Squeeze theorem but didn't work.",,"['calculus', 'limits', 'trigonometry', 'dynamical-systems']"
21,limits calculus,limits calculus,,"I am having trouble understanding part of the solution to this simple problem. $\lim_{x \to 2} (x^2 + 3x) = 10$ Solution: Let $\epsilon > 0$ $| x - 2 | < \delta$  and $| x^2 +3x -10 | < \epsilon$ since $x^2 +3x -10 = (x - 2)^2 + 7x -14 = (x - 2)^2 + 7x -14 = ( x -2 )^2 +7(x-2)$ $|(x-2)^2 +7(x-2)| \leq |(x-2)|^2 +7|(x-2)|$ $\delta^2 + 7\delta < \epsilon$ let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. then $8\delta < \epsilon$ $\delta < \epsilon/8$. My Question: I worked my way through the question down to $\delta^2 + 7\delta < \epsilon$ I then got confused by the end of this statement Let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. and in particular $\delta^2 \leq \delta$. I see how this allows me to prove the limit but I cannot make sense out of $\delta^2 \leq \delta$. Could anyone explain this to me?","I am having trouble understanding part of the solution to this simple problem. $\lim_{x \to 2} (x^2 + 3x) = 10$ Solution: Let $\epsilon > 0$ $| x - 2 | < \delta$  and $| x^2 +3x -10 | < \epsilon$ since $x^2 +3x -10 = (x - 2)^2 + 7x -14 = (x - 2)^2 + 7x -14 = ( x -2 )^2 +7(x-2)$ $|(x-2)^2 +7(x-2)| \leq |(x-2)|^2 +7|(x-2)|$ $\delta^2 + 7\delta < \epsilon$ let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. then $8\delta < \epsilon$ $\delta < \epsilon/8$. My Question: I worked my way through the question down to $\delta^2 + 7\delta < \epsilon$ I then got confused by the end of this statement Let $\delta$ be the minimum of $1$ and $\epsilon/8$, $\delta^2 \leq \delta$. and in particular $\delta^2 \leq \delta$. I see how this allows me to prove the limit but I cannot make sense out of $\delta^2 \leq \delta$. Could anyone explain this to me?",,['limits']
22,two limit questions related to $\sin$,two limit questions related to,\sin,"I stuck with these 2 limits, can you help me please? $1.\displaystyle\quad \lim_{n \to \infty }\frac{\sin1+2\sin\frac{1}{2}+3\sin\frac{1}{3}+\cdots+n\sin\frac{1}{n}}{n}$ $2.\displaystyle\quad \lim_{n \to \infty }\frac{n}{\frac{1}{\sin1}+\frac{1/2}{\sin1/2}+\frac{1/3}{\sin1/3}+\cdots+\frac{1/n}{\sin1/n}}  $ Thanks in advance.","I stuck with these 2 limits, can you help me please? $1.\displaystyle\quad \lim_{n \to \infty }\frac{\sin1+2\sin\frac{1}{2}+3\sin\frac{1}{3}+\cdots+n\sin\frac{1}{n}}{n}$ $2.\displaystyle\quad \lim_{n \to \infty }\frac{n}{\frac{1}{\sin1}+\frac{1/2}{\sin1/2}+\frac{1/3}{\sin1/3}+\cdots+\frac{1/n}{\sin1/n}}  $ Thanks in advance.",,"['calculus', 'limits']"
23,Compute $\lim_{n\to\infty} (3n)^{1/3} x_n$,Compute,\lim_{n\to\infty} (3n)^{1/3} x_n,Let $(x_{n})_{n \ge 1}$ be a sequence of real numbers with  $$\lim_{n\to\infty} x_n \sum_{k=1}^{n}x^2_{k}=1$$ Compute $$\lim_{n\to\infty} (3n)^{1/3} x_n$$ My guess so far is that $x_{n}$ tends to $0$ and the sum tends to $\infty$. Could you help here? Thanks.,Let $(x_{n})_{n \ge 1}$ be a sequence of real numbers with  $$\lim_{n\to\infty} x_n \sum_{k=1}^{n}x^2_{k}=1$$ Compute $$\lim_{n\to\infty} (3n)^{1/3} x_n$$ My guess so far is that $x_{n}$ tends to $0$ and the sum tends to $\infty$. Could you help here? Thanks.,,"['calculus', 'real-analysis', 'limits']"
24,How to find the limit $\lim \limits_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right]$,How to find the limit,\lim \limits_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right],"Solve $\space \begin{align*} \lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right]   \end{align*}$. I did this way: $$\begin{align*} \lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right] & = 4\lim_ {x \to+\infty} \left [\frac{1}{x} \ln(x+1) \right]= \\\\=4\lim_ {x \to+\infty} \left [ \ln(x+1)^{\frac{1}{x}}\right] &= 4 \ln \left[\lim_ {x \to+\infty}(x+1)^{\frac{1}{x}}\right] =4 \cdot \ln(1)=0 \end{align*}$$ What is the rule behind the shift that I made between the $\ln$ and the $limit$? I'm in the high school.Thanks","Solve $\space \begin{align*} \lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right]   \end{align*}$. I did this way: $$\begin{align*} \lim_ {x \to+\infty} \left [ \frac{4 \ln(x+1)}{x}\right] & = 4\lim_ {x \to+\infty} \left [\frac{1}{x} \ln(x+1) \right]= \\\\=4\lim_ {x \to+\infty} \left [ \ln(x+1)^{\frac{1}{x}}\right] &= 4 \ln \left[\lim_ {x \to+\infty}(x+1)^{\frac{1}{x}}\right] =4 \cdot \ln(1)=0 \end{align*}$$ What is the rule behind the shift that I made between the $\ln$ and the $limit$? I'm in the high school.Thanks",,['calculus']
25,any number raised to the power of infinity [closed],any number raised to the power of infinity [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question 1) I saw in a book that ""the limit as $x$ approaches positive infinity of $e^x$ equals $0$"" I want to ask about this? 2) if the $a$ is a negative number and we take a limit like ""the limit as $x$ approaches positive infinity of $a^x$ equals?"" and if $x$ approaches minus infinity then what happens? Please also tell me what would happen if $a$ is positive number.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question 1) I saw in a book that ""the limit as $x$ approaches positive infinity of $e^x$ equals $0$"" I want to ask about this? 2) if the $a$ is a negative number and we take a limit like ""the limit as $x$ approaches positive infinity of $a^x$ equals?"" and if $x$ approaches minus infinity then what happens? Please also tell me what would happen if $a$ is positive number.",,"['calculus', 'limits']"
26,"Function that grows slower than log, using exponentiation instead of multiplication","Function that grows slower than log, using exponentiation instead of multiplication",,"I'm trying to solve a problem by dividing it into chunks, until each chunk is of size 2 or less, at which point each chunk is easy to solve. I'm having trouble with how to mathematically represent how many such divisions I need to make for some initial problem size n. For most problems I deal with, I break the problem in half continuously until I reach the trivial sizes, so I would say there are log(n) divisions. But with this problem, I'm taking the square root of the problem size in each chunk. So the number of divisions can be represented as ""how many times do I need to take the square root of n for n becomes <=2"", or alternatively, ""how many times do I need to square 2 before it becomes >=n"". This function f(n), whatever it is, obviously grows slower than log(n), but I don't know of a function with this name, nor can I figure out how I would represent it mathematically.","I'm trying to solve a problem by dividing it into chunks, until each chunk is of size 2 or less, at which point each chunk is easy to solve. I'm having trouble with how to mathematically represent how many such divisions I need to make for some initial problem size n. For most problems I deal with, I break the problem in half continuously until I reach the trivial sizes, so I would say there are log(n) divisions. But with this problem, I'm taking the square root of the problem size in each chunk. So the number of divisions can be represented as ""how many times do I need to take the square root of n for n becomes <=2"", or alternatively, ""how many times do I need to square 2 before it becomes >=n"". This function f(n), whatever it is, obviously grows slower than log(n), but I don't know of a function with this name, nor can I figure out how I would represent it mathematically.",,"['functions', 'limits']"
27,What is the standard deviation of the distribution,What is the standard deviation of the distribution,,"Suppose that you have a uniform distribution in the Interval $I_0$ where $$ I_0 \in [0,1] $$ With this as a starting interval, now you take another interval $I_1$ which is a subset of $I_0$ but is exactly half the length. You repeat this multiple times. So if your interval $m = n-1$ , then $$ I_n \subset I_m $$ and the length of interval $n$ is half to that of interval $m$ All the intervals are continuous. Question -> If $n$ tends to infinity, the interval will converge on a point. Now if you repeat this experiment infinitely many times, you will get infinite such points, which will form a distribution. What is the standard deviation of that distribution? Note - Since $I_0$ is of length 1, $I_1$ needs to be of length 0.5. So $I_1$ cannot start from (0.5,1],  as that would mean that $I_1$ will not be subset of $I_0$ . All the possible selections of $I_1$ are equally likely. So, choosing [0.25,0.75], [0.2,0.7],[0,0.5]  etc are all equally likely candidates for $I_1$","Suppose that you have a uniform distribution in the Interval where With this as a starting interval, now you take another interval which is a subset of but is exactly half the length. You repeat this multiple times. So if your interval , then and the length of interval is half to that of interval All the intervals are continuous. Question -> If tends to infinity, the interval will converge on a point. Now if you repeat this experiment infinitely many times, you will get infinite such points, which will form a distribution. What is the standard deviation of that distribution? Note - Since is of length 1, needs to be of length 0.5. So cannot start from (0.5,1],  as that would mean that will not be subset of . All the possible selections of are equally likely. So, choosing [0.25,0.75], [0.2,0.7],[0,0.5]  etc are all equally likely candidates for","I_0  I_0 \in [0,1]  I_1 I_0 m = n-1  I_n \subset I_m  n m n I_0 I_1 I_1 I_1 I_0 I_1 I_1","['limits', 'normal-distribution', 'standard-deviation']"
28,Does there exist a functional definition for a sequential limit? [duplicate],Does there exist a functional definition for a sequential limit? [duplicate],,"This question already has answers here : Is there a ""functional"" definition of a limit? (2 answers) Closed 11 months ago . Consider the sequence $a_n$ . We say that $\lim a_n = c$ if for every $\epsilon > 0$ , there exists a natural number $N$ such that, if $n \geq N$ , then $|a_n - c| < \epsilon$ . This definition suggests that $N$ will always be a function of $\epsilon$ , including a constant function (in which case $N$ is independent of $\epsilon$ ). Therefore, I'm wondering if we can instead define the limit $\lim a_n = c$ as follows: We say that $\lim a_n = c$ if there exists a function $N : (0,\infty) \to \mathbb N$ such that if $|a_n - c| \geq \epsilon$ , then $n < N(\epsilon)$ . This definition does not seem that useful (and is likely missing some conditions), so I'm wondering if a better one can be constructed.","This question already has answers here : Is there a ""functional"" definition of a limit? (2 answers) Closed 11 months ago . Consider the sequence . We say that if for every , there exists a natural number such that, if , then . This definition suggests that will always be a function of , including a constant function (in which case is independent of ). Therefore, I'm wondering if we can instead define the limit as follows: We say that if there exists a function such that if , then . This definition does not seem that useful (and is likely missing some conditions), so I'm wondering if a better one can be constructed.","a_n \lim a_n = c \epsilon > 0 N n \geq N |a_n - c| < \epsilon N \epsilon N \epsilon \lim a_n = c \lim a_n = c N : (0,\infty) \to \mathbb N |a_n - c| \geq \epsilon n < N(\epsilon)",['limits']
29,Function that gives nontrivial limit of $\frac{\exp\left\{ f(x) \right\} }{\sqrt{x} f(x)}$,Function that gives nontrivial limit of,\frac{\exp\left\{ f(x) \right\} }{\sqrt{x} f(x)},"I am looking for a function $f(x): \Re_{>0} \to \Re_{>0}$ that is monotonically increasing such that \begin{equation} \tag{1} \label{lim}  \lim_{x \to \infty } \frac{\exp\left\{ f(x) \right\} }{\sqrt{x} f(x)} = C \,, \end{equation} for some finite, nonzero $C$ . It is easily checked that, $$ \tag{2} \label{cases} \lim_{x \to \infty} \frac{\exp\left\{ \beta \log(x)^\alpha \right\} }{\sqrt{x} \beta \log(x)^\alpha} = \begin{cases} 0 & \text{if } \alpha < 1 \text{or } \alpha =1 \text{ and } \beta \leq 1/2,  \\  \infty & \text{if } \alpha > 1. \end{cases} $$ Hence, my sharpest result so far is $f(x) = \frac{1}{2} \log(x)$ . The question is whether a function that produces a nontrivial limit exists and how it looks like. Alternatively, I would also be very happy with any rate optimal function $f(x)$ such that for any other function $g(x)$ for which the limit in \eqref{lim} is zero, it also holds that $$ \lim_{x \to \infty} \frac{g(x)}{f(x)} = c \,. $$ for some $c\geq 0$ .","I am looking for a function that is monotonically increasing such that for some finite, nonzero . It is easily checked that, Hence, my sharpest result so far is . The question is whether a function that produces a nontrivial limit exists and how it looks like. Alternatively, I would also be very happy with any rate optimal function such that for any other function for which the limit in \eqref{lim} is zero, it also holds that for some .","f(x): \Re_{>0} \to \Re_{>0} \begin{equation} \tag{1} \label{lim} 
\lim_{x \to \infty } \frac{\exp\left\{ f(x) \right\} }{\sqrt{x} f(x)} = C \,, \end{equation} C  \tag{2} \label{cases} \lim_{x \to \infty} \frac{\exp\left\{ \beta \log(x)^\alpha \right\} }{\sqrt{x} \beta \log(x)^\alpha} = \begin{cases} 0 & \text{if } \alpha < 1 \text{or } \alpha =1 \text{ and } \beta \leq 1/2,  \\ 
\infty & \text{if } \alpha > 1. \end{cases}  f(x) = \frac{1}{2} \log(x) f(x) g(x)  \lim_{x \to \infty} \frac{g(x)}{f(x)} = c \,.  c\geq 0","['real-analysis', 'limits', 'functions', 'upper-lower-bounds']"
30,Confusion in limits with trigonometric functions,Confusion in limits with trigonometric functions,,"Evaluate $$L=\lim_{r\to0} \frac{r\cos r}{r\cos r + \sin r}$$ In the solution it is written that as $r\to0$ , $\sin r = r$ and $\cos r = 1$ . Hence, we replace the trigonometric functions with $r$ and $1$ so that we can evaluate the limit easily. Therefore, $L=\lim_{r\to0} \frac{r\cdot1}{r\cdot1 + r}=\frac{1}{2}$ . Now, consider the limit $G =\lim_{r\to0} (\frac{1}{r^{2}}-\frac{1}{\sin^{2}r})$ . If we apply the above logic to this question, we will get $G=0$ , which is wrong. So why is the same logic not applicable in the second case?","Evaluate In the solution it is written that as , and . Hence, we replace the trigonometric functions with and so that we can evaluate the limit easily. Therefore, . Now, consider the limit . If we apply the above logic to this question, we will get , which is wrong. So why is the same logic not applicable in the second case?",L=\lim_{r\to0} \frac{r\cos r}{r\cos r + \sin r} r\to0 \sin r = r \cos r = 1 r 1 L=\lim_{r\to0} \frac{r\cdot1}{r\cdot1 + r}=\frac{1}{2} G =\lim_{r\to0} (\frac{1}{r^{2}}-\frac{1}{\sin^{2}r}) G=0,"['limits', 'trigonometry']"
31,Interpreting $\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{z-x}$,Interpreting,\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{z-x},"I stumbled upon the limit as shown in the title some time ago. Evaluating the limit is not hard -- $\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{z-x}\\ =\lim_{z\to x}\dfrac{f(z)-f(x)-(z-x)f'(x)}{(z-x)^2}\\ \stackrel{\text{L'Hopital's}}{=}\dfrac{1}{2}f''(x)$ . What puzzles me is after I rearrange the equation -- $f''(x)=\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{\dfrac{1}{2}(z-x)}$ , I have a hard time convincing myself of the denominator. The second derivative can be regarded as the difference of the slopes $f'(a),f'(b)$ per the distance between them while $b$ approaches $a$ . In the equation above, we consider the slope at $x$ and another somewhere between $x$ and $z$ (by MVT) but we never know if it is halfway through. So how do we make sense of $\dfrac{1}{2}(z-x)$ ? Why is it not some other fractions or even a varying fraction depending on $z$ , $x$ , and the function itself?","I stumbled upon the limit as shown in the title some time ago. Evaluating the limit is not hard -- . What puzzles me is after I rearrange the equation -- , I have a hard time convincing myself of the denominator. The second derivative can be regarded as the difference of the slopes per the distance between them while approaches . In the equation above, we consider the slope at and another somewhere between and (by MVT) but we never know if it is halfway through. So how do we make sense of ? Why is it not some other fractions or even a varying fraction depending on , , and the function itself?","\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{z-x}\\
=\lim_{z\to x}\dfrac{f(z)-f(x)-(z-x)f'(x)}{(z-x)^2}\\
\stackrel{\text{L'Hopital's}}{=}\dfrac{1}{2}f''(x) f''(x)=\lim_{z\to x}\dfrac{\dfrac{f(z)-f(x)}{z-x}-f'(x)}{\dfrac{1}{2}(z-x)} f'(a),f'(b) b a x x z \dfrac{1}{2}(z-x) z x","['real-analysis', 'calculus', 'limits', 'derivatives']"
32,Did Newton and Leibniz use limits in their derivations of differential calculus?,Did Newton and Leibniz use limits in their derivations of differential calculus?,,"In modern treatments of calculus, limits are used to motivate the derivation of differential calculus. However, when I searched for the history of limits I came across this Wikipedia article , which says: ...the modern idea of the limit of a function goes back to Bolzano who, in 1817... If the modern idea of limits is dated to 1817, what kind of limits did Newton and Leibniz use if any?","In modern treatments of calculus, limits are used to motivate the derivation of differential calculus. However, when I searched for the history of limits I came across this Wikipedia article , which says: ...the modern idea of the limit of a function goes back to Bolzano who, in 1817... If the modern idea of limits is dated to 1817, what kind of limits did Newton and Leibniz use if any?",,"['calculus', 'limits', 'derivatives', 'math-history']"
33,Understanding the counterexamples to L'Hopital's Rule,Understanding the counterexamples to L'Hopital's Rule,,"Wiki provides a counterexample limit that fails with L'Hopital's Rule, because it doesn't satisfy the $g'(x) \ne 0$ rule they provide earlier. Let $f(x)=x+\sin x \cos x$ and $g(x)=f(x)e^{\sin x}.$ Then there is no limit for $f(x)/g(x)$ as $x\to\infty$ However, $$ \begin{align}    \frac{f'(x)}{g'(x)} &= \frac{2\cos^2 x}{(2 \cos^2 x) e^{\sin x} + (x+\sin x \cos x) e^{\sin x} \cos x} \\[4pt]    &= \frac{2\cos x}{2 \cos x +x+\sin x \cos x} e^{-\sin x},  \end{align} $$ which tends to 0 as $x\to\infty$ . My question: is it possible to construct a counterexample where $x$ goes to a real number, rather than infinity? Or does approaching a real number protect you from failing in the $g'(x) = 0$ case.","Wiki provides a counterexample limit that fails with L'Hopital's Rule, because it doesn't satisfy the rule they provide earlier. Let and Then there is no limit for as However, which tends to 0 as . My question: is it possible to construct a counterexample where goes to a real number, rather than infinity? Or does approaching a real number protect you from failing in the case.","g'(x) \ne 0 f(x)=x+\sin x \cos x g(x)=f(x)e^{\sin x}. f(x)/g(x) x\to\infty 
\begin{align}
   \frac{f'(x)}{g'(x)} &= \frac{2\cos^2 x}{(2 \cos^2 x) e^{\sin x} + (x+\sin x \cos x) e^{\sin x} \cos x} \\[4pt]
   &= \frac{2\cos x}{2 \cos x +x+\sin x \cos x} e^{-\sin x},
 \end{align}
 x\to\infty x g'(x) = 0","['calculus', 'limits', 'derivatives']"
34,Why can we use Taylor series for evaluating limits? [duplicate],Why can we use Taylor series for evaluating limits? [duplicate],,"This question already has answers here : Is it okay to ""ignore"" small numbers in limits where $x$ approaches infinity? (6 answers) Closed 2 years ago . I was trying to solve a limit with Taylor series today, which I never had a problem with, but now I suddenly don't understand why it's ok to do it in that way. For example, the limit $$\begin{align} &\lim_{x \to 0} \frac{x - x^3/6 - \sin{x}}{x^5} \\ &= \lim_{x \to 0} \frac{(x-x^3/6) - (x - x^3/6 + x^5/5! - \text{higher order terms} )}{x^5} \\ &= \lim_{x \to 0} \frac{-x^5/5! + \text{higher order terms}}{x^5} \\ &= \lim_{x \to 0} {\frac{-1}{5!} + \text{higher order terms}} = - \frac{1}{120} \end{align}$$ But why can we say that the sum of higher order terms goes to zero? I understand that each of the terms goes to zero, but why does their infinite sum go to zero? How can I justify that? I think that although the summands are small, their infinite sum can hypothetically still be big?","This question already has answers here : Is it okay to ""ignore"" small numbers in limits where $x$ approaches infinity? (6 answers) Closed 2 years ago . I was trying to solve a limit with Taylor series today, which I never had a problem with, but now I suddenly don't understand why it's ok to do it in that way. For example, the limit But why can we say that the sum of higher order terms goes to zero? I understand that each of the terms goes to zero, but why does their infinite sum go to zero? How can I justify that? I think that although the summands are small, their infinite sum can hypothetically still be big?","\begin{align}
&\lim_{x \to 0} \frac{x - x^3/6 - \sin{x}}{x^5} \\
&= \lim_{x \to 0} \frac{(x-x^3/6) - (x - x^3/6 + x^5/5! - \text{higher order terms} )}{x^5} \\
&= \lim_{x \to 0} \frac{-x^5/5! + \text{higher order terms}}{x^5} \\
&= \lim_{x \to 0} {\frac{-1}{5!} + \text{higher order terms}} = - \frac{1}{120}
\end{align}","['calculus', 'limits', 'taylor-expansion']"
35,"Why does $ \lim_{x \rightarrow \pi }\frac{\sin(mx)}{\sin(nx)}=\left ( -1 \right )^{m-n}\;\frac{m}{n}$, for positive naturals $m$ and $n$?","Why does , for positive naturals  and ?", \lim_{x \rightarrow \pi }\frac{\sin(mx)}{\sin(nx)}=\left ( -1 \right )^{m-n}\;\frac{m}{n} m n,"Encountered this in a sample university admission exam. $$ \lim_{x \rightarrow \pi } \frac{\sin(mx)}{\sin(nx)} \quad n,m\in \mathbb N_{> 0} $$ What surprised me was that the answare sheet suggested that the limit was equal to: $$ \left ( -1 \right )^{m-n}\;\frac{m}{n} $$ Graphing the function made it clear for me that this is the correct answer, but i cannot understand why.","Encountered this in a sample university admission exam. What surprised me was that the answare sheet suggested that the limit was equal to: Graphing the function made it clear for me that this is the correct answer, but i cannot understand why.","
\lim_{x \rightarrow \pi } \frac{\sin(mx)}{\sin(nx)} \quad n,m\in \mathbb N_{> 0}
 
\left ( -1 \right )^{m-n}\;\frac{m}{n}
",['limits']
36,Closed form for limit of a sum $\lim\limits_{m\to\infty}(\ln m-4\sum_{n=1}^{m}\frac{(-1)^{n}}{2n+1}\sum_{k=1}^{2n}(-1)^{k}k\ln k)\approx-0.092$,Closed form for limit of a sum,\lim\limits_{m\to\infty}(\ln m-4\sum_{n=1}^{m}\frac{(-1)^{n}}{2n+1}\sum_{k=1}^{2n}(-1)^{k}k\ln k)\approx-0.092,"I'm looking for a closed form of $$\lim\limits_{m\to\infty}\left(\ln m-4\sum_{n=1}^{m}\frac{\left(-1\right)^{n}}{2n+1}\sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k\right)\approx-0.092$$ for even $m$ . ( For context this is a continuation of my ongoing work from this answer .) Here's what I've tried so far. Wolfram alpha gives gives me $$\sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k=-2\zeta^{(1,0)}\left(-1,n+\frac{1}{2}\right)+2\zeta^{(1,0)}\left(-1,n+1\right)+n\ln2+3\ln A-\frac{1}{12}\ln2-\frac{1}{4}$$ From Wolfram's function site I get $$\zeta^{(1,0)}(-1,x)=-\frac{1}{12}\left(-6x^{2}+18x-12\left(x-1\right)\ln\left(x-1\right)+12\ln A+6\left(x-1\right)\ln2\pi-13\right)+\psi^{(-2)}\left(x-1\right)$$ Combining these gets me $$\sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k=-2\psi^{(-2)}\left(n-\frac{1}{2}\right)+2\psi^{(-2)}\left(n\right)-\left(2n-1\right)\ln\left(n-\frac{1}{2}\right)+2n\ln n+n+n\ln2-\frac{1}{2}\ln2\pi+3\ln A-\frac{1}{12}\ln2-1$$ I could keep trying to find more expressions, but it feels like this is making things more complicated and possibly going to bring me back where I started.","I'm looking for a closed form of for even . ( For context this is a continuation of my ongoing work from this answer .) Here's what I've tried so far. Wolfram alpha gives gives me From Wolfram's function site I get Combining these gets me I could keep trying to find more expressions, but it feels like this is making things more complicated and possibly going to bring me back where I started.","\lim\limits_{m\to\infty}\left(\ln m-4\sum_{n=1}^{m}\frac{\left(-1\right)^{n}}{2n+1}\sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k\right)\approx-0.092 m \sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k=-2\zeta^{(1,0)}\left(-1,n+\frac{1}{2}\right)+2\zeta^{(1,0)}\left(-1,n+1\right)+n\ln2+3\ln A-\frac{1}{12}\ln2-\frac{1}{4} \zeta^{(1,0)}(-1,x)=-\frac{1}{12}\left(-6x^{2}+18x-12\left(x-1\right)\ln\left(x-1\right)+12\ln A+6\left(x-1\right)\ln2\pi-13\right)+\psi^{(-2)}\left(x-1\right) \sum_{k=1}^{2n}\left(-1\right)^{k}k\ln k=-2\psi^{(-2)}\left(n-\frac{1}{2}\right)+2\psi^{(-2)}\left(n\right)-\left(2n-1\right)\ln\left(n-\frac{1}{2}\right)+2n\ln n+n+n\ln2-\frac{1}{2}\ln2\pi+3\ln A-\frac{1}{12}\ln2-1","['real-analysis', 'limits', 'summation', 'riemann-zeta']"
37,Limit of a function defined at a single point,Limit of a function defined at a single point,,"Let's suppose we have a function defined at a single point $f : \left\{ 1 \right\} \to \left\{ 1 \right\}$ defined by $f(x) = x$ . Its graph is, therefore, composed of a single point $(1,1)$ . Does the following limit exist? $$\lim_{x \to 1} \ f(x)$$ I've read this post but it addresses the question in a topology perspective. I'd like to answer this considering a typical first semester Calculus course. Any help is highly appreciated.","Let's suppose we have a function defined at a single point defined by . Its graph is, therefore, composed of a single point . Does the following limit exist? I've read this post but it addresses the question in a topology perspective. I'd like to answer this considering a typical first semester Calculus course. Any help is highly appreciated.","f : \left\{ 1 \right\} \to \left\{ 1 \right\} f(x) = x (1,1) \lim_{x \to 1} \ f(x)",['limits']
38,Help finding the limit of $\lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right)$.,Help finding the limit of .,\lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right),"Given that $f:[0,1]\to \Bbb{R}$ is a continuous function, I need to show that $$\lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right)=e^{\int_0^1f(x)dx}$$ Writing $$y=\lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right)$$ and taking the logarithm of both sides and interchanging limit and logarithm(since $f$ is continuous), I get $$\log y = \lim_{n\to \infty}\sum_{k=1}^{n}\log\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right)$$ Now I know that the limit of the Riemann sum $\lim_{n\to \infty}\sum_{k=1}^{n}\frac{b-a}{n}f\left(a+\frac{(b-a)}{n}k\right)=\int_a^bf(x)dx$ . However if I want it to read $\int_0^1f(x)dx$ in the given problem, I would need the term inside the summation to read $\frac{1}{n}f\left(\frac{k}{n}\right)$ . The way to do this it would seem is to take the series expansion of $\log(1+x)$ and ignoring the $x^2$ and higher order terms. Is it justifiable to do so?","Given that is a continuous function, I need to show that Writing and taking the logarithm of both sides and interchanging limit and logarithm(since is continuous), I get Now I know that the limit of the Riemann sum . However if I want it to read in the given problem, I would need the term inside the summation to read . The way to do this it would seem is to take the series expansion of and ignoring the and higher order terms. Is it justifiable to do so?","f:[0,1]\to \Bbb{R} \lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right)=e^{\int_0^1f(x)dx} y=\lim_{n \to \infty}\prod_{k=1}^{n}\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right) f \log y = \lim_{n\to \infty}\sum_{k=1}^{n}\log\left(1+\frac{1}{n}f\left(\frac{k}{n}\right)\right) \lim_{n\to \infty}\sum_{k=1}^{n}\frac{b-a}{n}f\left(a+\frac{(b-a)}{n}k\right)=\int_a^bf(x)dx \int_0^1f(x)dx \frac{1}{n}f\left(\frac{k}{n}\right) \log(1+x) x^2","['calculus', 'limits']"
39,Why define derivative for a function defined on an interval,Why define derivative for a function defined on an interval,,"In the video lectures on real analysis by Professor Su he uses the following definition for the derivative: A function $f: [a,b] \to \mathbb{R}$ is differentiable at $x \in [a,b]$ if the limit $\lim_{t \to x} \frac{f(t)-f(x)}{t-x}$ exists. In this case we say $f'(x)=\lim_{t \to x} \frac{f(t)-f(x)}{t-x}$ is the derivative of $f$ at $x$ . The definition of limit in $\mathbb{R}$ is as follows: Let $f:E \to \mathbb{R}$ where $E \subset \mathbb{R}$ and let $p$ be a limit point of $E$ , then we say $\lim_{x \to p} f(x)=q$ if $\exists q \in \mathbb{R}: \forall \epsilon>0$ $\exists \delta>0$ s.t. $\forall x \in E$ , $0<\lvert x-p \rvert<\delta \implies \lvert f(x)-q \rvert<\epsilon$ . I was wondering why we restrict ourselves to functions with an interval as its domain. Usually the definitions in metric spaces are based on examples in $\mathbb{R}$ and can be generalized to arbitrary metric spaces, e.g. the definition of limit of a function or continuity of a function can be generalized by replacing the absolute value by a distance function. Of course, the derivative defined as a limit of a quotient cannot be generalized to arbitrary metric spaces since division might not be defined, but why would we restrict ourselves to functions defined on an interval? In light of the definition of the limit we can make sense of this limit for any function defined on a subset $E \subset \mathbb{R}$ . Of course in the case where the domain is $\mathbb{R}$ we do not need to specify the condition that $x$ must be a limit point for the derivative at $x$ to exist since every point of $\mathbb{R}$ is a limit point. However, if we generalize this to functions $f:E \to \mathbb{R}$ where $E \subset \mathbb{R}$ , then we require that $x$ is a limit point for the limit to make sense. This definition would also cover the special cases of intervals. For example, we can let $E=[a,b]$ , then every point in this interval is a limit point as long as $a \neq b$ and we can consider the limit at any point without the need to separately introduce one-sided limits. This is because we can consider $[a,b]$ as a metric space in its own right and for the $\delta$ ball of any radius about $a$ or $b$ in $[a,b]$ is simply cut off at one side (because we only consider points in the metric space). To sum up why do most textbooks/lectures on real analysis restrict to open or closed intervals for derivatives?","In the video lectures on real analysis by Professor Su he uses the following definition for the derivative: A function is differentiable at if the limit exists. In this case we say is the derivative of at . The definition of limit in is as follows: Let where and let be a limit point of , then we say if s.t. , . I was wondering why we restrict ourselves to functions with an interval as its domain. Usually the definitions in metric spaces are based on examples in and can be generalized to arbitrary metric spaces, e.g. the definition of limit of a function or continuity of a function can be generalized by replacing the absolute value by a distance function. Of course, the derivative defined as a limit of a quotient cannot be generalized to arbitrary metric spaces since division might not be defined, but why would we restrict ourselves to functions defined on an interval? In light of the definition of the limit we can make sense of this limit for any function defined on a subset . Of course in the case where the domain is we do not need to specify the condition that must be a limit point for the derivative at to exist since every point of is a limit point. However, if we generalize this to functions where , then we require that is a limit point for the limit to make sense. This definition would also cover the special cases of intervals. For example, we can let , then every point in this interval is a limit point as long as and we can consider the limit at any point without the need to separately introduce one-sided limits. This is because we can consider as a metric space in its own right and for the ball of any radius about or in is simply cut off at one side (because we only consider points in the metric space). To sum up why do most textbooks/lectures on real analysis restrict to open or closed intervals for derivatives?","f: [a,b] \to \mathbb{R} x \in [a,b] \lim_{t \to x} \frac{f(t)-f(x)}{t-x} f'(x)=\lim_{t \to x} \frac{f(t)-f(x)}{t-x} f x \mathbb{R} f:E \to \mathbb{R} E \subset \mathbb{R} p E \lim_{x \to p} f(x)=q \exists q \in \mathbb{R}: \forall \epsilon>0 \exists \delta>0 \forall x \in E 0<\lvert x-p \rvert<\delta \implies \lvert f(x)-q \rvert<\epsilon \mathbb{R} E \subset \mathbb{R} \mathbb{R} x x \mathbb{R} f:E \to \mathbb{R} E \subset \mathbb{R} x E=[a,b] a \neq b [a,b] \delta a b [a,b]","['real-analysis', 'limits', 'derivatives', 'metric-spaces', 'definition']"
40,$\lim_{x\rightarrow\infty}\frac{\log f(x^2)}{f(x)}$,,\lim_{x\rightarrow\infty}\frac{\log f(x^2)}{f(x)},"I have a feeling that $\lim_{x\rightarrow\infty}\frac{\log f(x^2)}{f(x)}=0$ for any positive monotone increasing function such that $\lim_{x\rightarrow\infty}f(x)=\infty$ , (in reality I am thinking mostly about super-exponential growth here but I do not think it might make a difference). The idea, intuitively, is that the logarithm takes away more growth than the square in the argument boosts. Though, I am not sure if this is true (maybe adding some more hypotheses) because I find it hard to prove neatly, having $f$ in between mixing these two contributions up. Tried L'Hospital but did not work and standard limit stuff neither, unsuccessfully. Anybody sees which way of approaching this could be productive? Don't need detailed answers, if you have a hunch that'll be enough.","I have a feeling that for any positive monotone increasing function such that , (in reality I am thinking mostly about super-exponential growth here but I do not think it might make a difference). The idea, intuitively, is that the logarithm takes away more growth than the square in the argument boosts. Though, I am not sure if this is true (maybe adding some more hypotheses) because I find it hard to prove neatly, having in between mixing these two contributions up. Tried L'Hospital but did not work and standard limit stuff neither, unsuccessfully. Anybody sees which way of approaching this could be productive? Don't need detailed answers, if you have a hunch that'll be enough.",\lim_{x\rightarrow\infty}\frac{\log f(x^2)}{f(x)}=0 \lim_{x\rightarrow\infty}f(x)=\infty f,"['real-analysis', 'calculus', 'limits', 'logarithms', 'asymptotics']"
41,"Good examples of violations to the ""law of sufficiently large intervals""","Good examples of violations to the ""law of sufficiently large intervals""",,"Tis a common mistake among us mere mortals (laypeople, students, physicists, and the like) to assume that because a function (or sequence) has a certain property over some sufficiently large interval, it must maintain this property as its argument tends to infinity. Some particularly prominent examples are the ""apparent"" asymptote, the ""looks-like"" limit at infinity, and the ""almost"" Cauchy sequence. Well, I was trying to explain why this is not the case when I realised that for every example I could think of, the idea of looking at a ""sufficiently large"" interval did suffice to predict the limiting behaviour of the function. In fact, I've started noticing that even mathematicians will casually use this kind of reasoning when the situation does not require otherwise. The problem is that most ""ordinary"" functions have relatively consistent behaviour over their entire domain. If $f(x)$ is continuous, increasing, $f(x)<3$ for all $x<10,000$ , and $f(10,000)=2.999999978$ , then odds are that $\lim_{x\to\infty}f(x)=3$ . Of course, there might be some absurdly large value where $f$ starts increasing much faster but unless it's being done intentionally there isn't . This brings me to my question. What are some ""natural"" examples of functions (or classes thereof) that appear to obey the ""law of sufficiently large intervals"" but do not? By ""natural"" I  mean something that might appear in a high-school or undergrad textbook and could plausibly fool a TA if they weren't careful; a definable function whose formula does not immediately spoil the reveal. Obviously, something like... $$f(x)=\frac{x}{10^{21}}-\frac 1x$$ ...won't work because anyone who looks at it more than once will realise that $f(x)$ is only ""small"" when $x<10^{21}$ . I'm looking more for examples where, without further work, it still seems reasonable that the limiting behaviour of the function is predicted by its behaviour over a large interval.","Tis a common mistake among us mere mortals (laypeople, students, physicists, and the like) to assume that because a function (or sequence) has a certain property over some sufficiently large interval, it must maintain this property as its argument tends to infinity. Some particularly prominent examples are the ""apparent"" asymptote, the ""looks-like"" limit at infinity, and the ""almost"" Cauchy sequence. Well, I was trying to explain why this is not the case when I realised that for every example I could think of, the idea of looking at a ""sufficiently large"" interval did suffice to predict the limiting behaviour of the function. In fact, I've started noticing that even mathematicians will casually use this kind of reasoning when the situation does not require otherwise. The problem is that most ""ordinary"" functions have relatively consistent behaviour over their entire domain. If is continuous, increasing, for all , and , then odds are that . Of course, there might be some absurdly large value where starts increasing much faster but unless it's being done intentionally there isn't . This brings me to my question. What are some ""natural"" examples of functions (or classes thereof) that appear to obey the ""law of sufficiently large intervals"" but do not? By ""natural"" I  mean something that might appear in a high-school or undergrad textbook and could plausibly fool a TA if they weren't careful; a definable function whose formula does not immediately spoil the reveal. Obviously, something like... ...won't work because anyone who looks at it more than once will realise that is only ""small"" when . I'm looking more for examples where, without further work, it still seems reasonable that the limiting behaviour of the function is predicted by its behaviour over a large interval.","f(x) f(x)<3 x<10,000 f(10,000)=2.999999978 \lim_{x\to\infty}f(x)=3 f f(x)=\frac{x}{10^{21}}-\frac 1x f(x) x<10^{21}","['real-analysis', 'calculus', 'limits', 'soft-question', 'examples-counterexamples']"
42,Proof by epsilon-delta of $\lim \limits_{x \to 1} 3x^2+1=4$,Proof by epsilon-delta of,\lim \limits_{x \to 1} 3x^2+1=4,"I have some doubts proving the following: $$\lim \limits_{x \to 1} 3x^2+1=4$$ My try $(\forall \varepsilon > 0)(\exists \space \delta > 0): (0<|x-1|< \delta \implies |3x^2+1-4| < \varepsilon)$ $\implies 0<|x-1|< \delta \iff -\delta \lt x -1 \lt \delta \iff -\delta +2 \lt x+1 \lt \delta + 2 $ By transitivity: $\implies -(\delta + 2) \lt x+1 \lt \delta + 2 \iff 0 \lt |x+1| \lt \delta + 2$ Now, working with the epsilon part: $|3x^2+1-4| < \varepsilon \iff 3 |x-1||x+1| \lt e$ Using the fact that $|x+1| \lt \delta + 2 \iff 3|x+1| \lt 3(\delta + 2)$ , and $|x-1| \lt \delta$ by transitivity: $3|x-1||x+1| \lt 3(\delta + 2)\delta$ Then, $\varepsilon = 3(\delta + 2) \delta$ should be enough, but, if i solve the quadratic for delta: $\delta = \frac{-6 \pm \sqrt{36 + 12\varepsilon}}{6}$ , a contradiction, because in one of the solutions $\delta \lt 0 \space \forall \varepsilon \gt 0$ . After that i tried using $\delta = 1$ : $\iff |x-1| \lt 1 \implies |3x^2-3| \lt \varepsilon$ $|x-1| \lt 1 \iff  -1 \lt x-1 \lt 1 \iff 1 \lt x+1 \lt 3$ $\implies -3 \lt x+1 \lt 3 \iff |x+1| \lt 3$ With $|x-1| \lt 1$ and $|x+1| \lt 3 \iff 3|x+1| \lt 9: $ $3 |x-1||x+1| \lt \varepsilon \implies 9 |x-1| \lt \varepsilon \iff |x-1| \lt \frac{\varepsilon}{9}$ . So $\delta = \frac{\varepsilon}{9}$ should satisfy, but i used the fact that $\delta = 1.$ How can i proceed here?. I saw that i have to use $\delta = \min\{1, \frac{\varepsilon}{9}\}$ , but i don't know why. Any hints?. Are my steps correct or i did something wrong?. I'm not familiarized with epsilon-delta proofs.","I have some doubts proving the following: My try By transitivity: Now, working with the epsilon part: Using the fact that , and by transitivity: Then, should be enough, but, if i solve the quadratic for delta: , a contradiction, because in one of the solutions . After that i tried using : With and . So should satisfy, but i used the fact that How can i proceed here?. I saw that i have to use , but i don't know why. Any hints?. Are my steps correct or i did something wrong?. I'm not familiarized with epsilon-delta proofs.","\lim \limits_{x \to 1} 3x^2+1=4 (\forall \varepsilon > 0)(\exists \space \delta > 0): (0<|x-1|< \delta \implies |3x^2+1-4| < \varepsilon) \implies 0<|x-1|< \delta \iff -\delta \lt x -1 \lt \delta \iff -\delta +2 \lt x+1 \lt \delta + 2  \implies -(\delta + 2) \lt x+1 \lt \delta + 2 \iff 0 \lt |x+1| \lt \delta + 2 |3x^2+1-4| < \varepsilon \iff 3 |x-1||x+1| \lt e |x+1| \lt \delta + 2 \iff 3|x+1| \lt 3(\delta + 2) |x-1| \lt \delta 3|x-1||x+1| \lt 3(\delta + 2)\delta \varepsilon = 3(\delta + 2) \delta \delta = \frac{-6 \pm \sqrt{36 + 12\varepsilon}}{6} \delta \lt 0 \space \forall \varepsilon \gt 0 \delta = 1 \iff |x-1| \lt 1 \implies |3x^2-3| \lt \varepsilon |x-1| \lt 1 \iff  -1 \lt x-1 \lt 1 \iff 1 \lt x+1 \lt 3 \implies -3 \lt x+1 \lt 3 \iff |x+1| \lt 3 |x-1| \lt 1 |x+1| \lt 3 \iff 3|x+1| \lt 9:  3 |x-1||x+1| \lt \varepsilon \implies 9 |x-1| \lt \varepsilon \iff |x-1| \lt \frac{\varepsilon}{9} \delta = \frac{\varepsilon}{9} \delta = 1. \delta = \min\{1, \frac{\varepsilon}{9}\}","['limits', 'epsilon-delta']"
43,$ \lim_{x\to \frac{1}{{\sqrt 2}^+}} \frac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\frac{1}{\sqrt{2}}}$,, \lim_{x\to \frac{1}{{\sqrt 2}^+}} \frac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\frac{1}{\sqrt{2}}},"$\displaystyle \lim_{x\to {1\over \sqrt{2}^+}} \dfrac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\dfrac{1}{\sqrt{2}}}$ I have tried substituting $x$ for $\sin \theta$ , doing the calculations and ended up with - $2√2$ . But the solution provided was $2√2$ . Then I tried this question again, but this time used $\cos \theta$ instead of $\sin \theta$ and the answer did match. I don't understand why $x$ as $\sin \theta$ doesn't give the correct result. I have checked all my steps but couldn't find any flaw with $\sin \theta$ as substitution. Can anyone tell me whether $\sin \theta $ a wrong substitution for this question or not?","I have tried substituting for , doing the calculations and ended up with - . But the solution provided was . Then I tried this question again, but this time used instead of and the answer did match. I don't understand why as doesn't give the correct result. I have checked all my steps but couldn't find any flaw with as substitution. Can anyone tell me whether a wrong substitution for this question or not?",\displaystyle \lim_{x\to {1\over \sqrt{2}^+}} \dfrac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\dfrac{1}{\sqrt{2}}} x \sin \theta 2√2 2√2 \cos \theta \sin \theta x \sin \theta \sin \theta \sin \theta ,[]
44,Limit of $\lim \limits_{x \to\infty} (\frac{x}{1-x})^{2x}$,Limit of,\lim \limits_{x \to\infty} (\frac{x}{1-x})^{2x},I've been struggling with this term for a while now: $$\lim \limits_{x \to\infty} (\frac{x}{1-x})^{2x}$$ I know it has to do something with $\lim \limits_{x \to\infty} (1+\frac{n}{x})^x=e^n$ but didn't come further than this though: $$\lim \limits_{x \to\infty}  (1+ \frac{2x-1}{1-x})^{2x} = \lim \limits_{x \to\infty} (1+ \frac{2x-1}{1-x})^{1-x})^{\frac{2x}{1-x}} \overset{?}{=} e^{2x-1 {\lim \limits_{x \to\infty} \frac{2x}{1-x}}}  $$,I've been struggling with this term for a while now: I know it has to do something with but didn't come further than this though:,\lim \limits_{x \to\infty} (\frac{x}{1-x})^{2x} \lim \limits_{x \to\infty} (1+\frac{n}{x})^x=e^n \lim \limits_{x \to\infty}  (1+ \frac{2x-1}{1-x})^{2x} = \lim \limits_{x \to\infty} (1+ \frac{2x-1}{1-x})^{1-x})^{\frac{2x}{1-x}} \overset{?}{=} e^{2x-1 {\lim \limits_{x \to\infty} \frac{2x}{1-x}}}  ,"['real-analysis', 'limits', 'limits-without-lhopital']"
45,help with solving a limit with logarithms,help with solving a limit with logarithms,,I am preparing for an exam and I am struggling with the following limit: $$ \lim_{x\to 0}\frac{\ln(1+x^{2018})-\ln^{2018}(1+x)}{x^{2019}}. $$ I tried the L'Hospital rule and i tried to form remarcable limits.,I am preparing for an exam and I am struggling with the following limit: I tried the L'Hospital rule and i tried to form remarcable limits.,"
\lim_{x\to 0}\frac{\ln(1+x^{2018})-\ln^{2018}(1+x)}{x^{2019}}.
","['real-analysis', 'limits', 'polynomials', 'logarithms', 'limits-without-lhopital']"
46,Compute $\lim_{n\to\infty}\frac{\tfrac{n}{1}+\tfrac{n-1}{2}+\dots+\tfrac{2}{n-1}+\tfrac{1}{n}}{\ln(n!)}$ [closed],Compute  [closed],\lim_{n\to\infty}\frac{\tfrac{n}{1}+\tfrac{n-1}{2}+\dots+\tfrac{2}{n-1}+\tfrac{1}{n}}{\ln(n!)},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How can I compute the following limit? $$ \lim_{n\to\infty}\frac{\dfrac{n}{1}+\dfrac{n-1}{2}+\dots+\dfrac{2}{n-1}+\dfrac{1}{n}}{\ln(n!)} $$ I have tried lots of methods, I can't get the answer. Although I think the limit is $0$ , I don't know how to explain it. Please, if someone could help me it would be fantastic.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question How can I compute the following limit? I have tried lots of methods, I can't get the answer. Although I think the limit is , I don't know how to explain it. Please, if someone could help me it would be fantastic.","
\lim_{n\to\infty}\frac{\dfrac{n}{1}+\dfrac{n-1}{2}+\dots+\dfrac{2}{n-1}+\dfrac{1}{n}}{\ln(n!)}
 0",['limits']
47,$\lim _{x\rightarrow c}f(x)=L$ if and only if $\lim_{x\rightarrow0}f(x+c)=L$,if and only if,\lim _{x\rightarrow c}f(x)=L \lim_{x\rightarrow0}f(x+c)=L,"Let $f:= \mathbb{R}\to\mathbb{R}$ and let $c\in\mathbb{R}$ . Show that $\lim _{x\rightarrow c}f(x)=L$ if and only if $\lim_{x\rightarrow0}f(x+c)=L$ . From the definition of limit, we get that it is enough to show: $\forall$ $\varepsilon>0$ $\exists$ $\delta>0$ s.t. if $|x-c|<\delta$ then $|f(x)-L|<\varepsilon$ $\Leftrightarrow$ $\forall$ $\varepsilon_0>0$ $\exists$ $\delta_0>0$ s.t. if $|x|<\delta_0$ then $|f(x+c)-L|<\varepsilon_0$ I can replace $x$ by $x+c$ everywhere in statement for the if $(\Rightarrow)$ part. But, I am not sure this is the correct method. What I need to do is manipulate the inequalities in each to get the other. But, I am not sure how to proceed with that.","Let and let . Show that if and only if . From the definition of limit, we get that it is enough to show: s.t. if then s.t. if then I can replace by everywhere in statement for the if part. But, I am not sure this is the correct method. What I need to do is manipulate the inequalities in each to get the other. But, I am not sure how to proceed with that.",f:= \mathbb{R}\to\mathbb{R} c\in\mathbb{R} \lim _{x\rightarrow c}f(x)=L \lim_{x\rightarrow0}f(x+c)=L \forall \varepsilon>0 \exists \delta>0 |x-c|<\delta |f(x)-L|<\varepsilon \Leftrightarrow \forall \varepsilon_0>0 \exists \delta_0>0 |x|<\delta_0 |f(x+c)-L|<\varepsilon_0 x x+c (\Rightarrow),"['real-analysis', 'limits', 'analysis']"
48,Finding $f$ satisfies $\limsup_{n\to\infty}\frac{\tau(n)}{f(n)}=1$,Finding  satisfies,f \limsup_{n\to\infty}\frac{\tau(n)}{f(n)}=1,"Is there a known result on finding the function $f$ satisfies $$\limsup_{n\to\infty}\frac{\tau(n)}{f(n)}=1?$$   where $\tau(n)$ is the number of factor(s) of $n$. Related: Prove that $d(n)\leq 2\sqrt{n}$ It shows that $f(n)=O(\sqrt n)$. Some Ideas Also, letting $n=2^m,m\in\mathbb Z$ gives $f(n)=\Omega(m)$, or $f(n)=\Omega(\ln n)$. Factorize $n$ into $\prod_ip_i^{\alpha_i}$ gives $\tau(n)=\prod_i(\alpha_i+1)$. So probably the next step to do is to estimate $p_i$. Wikipedia gives $p_n\le n\ln n+n\ln\ln n$ when $n\ge 6$. Can we use this result to give the better bounds for $f$?","Is there a known result on finding the function $f$ satisfies $$\limsup_{n\to\infty}\frac{\tau(n)}{f(n)}=1?$$   where $\tau(n)$ is the number of factor(s) of $n$. Related: Prove that $d(n)\leq 2\sqrt{n}$ It shows that $f(n)=O(\sqrt n)$. Some Ideas Also, letting $n=2^m,m\in\mathbb Z$ gives $f(n)=\Omega(m)$, or $f(n)=\Omega(\ln n)$. Factorize $n$ into $\prod_ip_i^{\alpha_i}$ gives $\tau(n)=\prod_i(\alpha_i+1)$. So probably the next step to do is to estimate $p_i$. Wikipedia gives $p_n\le n\ln n+n\ln\ln n$ when $n\ge 6$. Can we use this result to give the better bounds for $f$?",,"['number-theory', 'limits', 'limsup-and-liminf']"
49,Proving $\lim_{ x\to 0 } \sin \frac{2\pi }{x}$ does not exist,Proving  does not exist,\lim_{ x\to 0 } \sin \frac{2\pi }{x},"Here's my attempt: Suppose there is some $L \in \mathbb{R}$ such that $\lim_{ x\to 0 } \sin \frac{2\pi }{x} = L$. Then, if we let $\varepsilon = 1$, there would exist $\delta > 0$ such that $\left| f(x) - L\right| < 1$ for all $0< |x| < \delta $. Now, by the Archimedean property, there is $n \in \mathbb{N}$ such that $\frac{1}{n} < \delta $. Pick $x_1 = \frac{4}{4n+1}$ and $x_2 = \frac{4}{4n+3}$ and note that $x_1 , x_2 <  \delta $. Now for $x_1$, we have $ \left| f(x_1) - L \right| = \left| \sin \left( (4n+1) \frac{\pi}{2} -L \right) \right| = \left| 1-L \right| < 1 $ And similarly $ \left| f(x_2) - L \right| = \left| \sin \left( (4n+3) \frac{\pi}{2} -L \right) \right| = \left| -1-L \right| < 1 $ Thus, L is within one unit of both $-1$ and $1$. However, there cannot be any such number. A contradiction! Is this proof okay?","Here's my attempt: Suppose there is some $L \in \mathbb{R}$ such that $\lim_{ x\to 0 } \sin \frac{2\pi }{x} = L$. Then, if we let $\varepsilon = 1$, there would exist $\delta > 0$ such that $\left| f(x) - L\right| < 1$ for all $0< |x| < \delta $. Now, by the Archimedean property, there is $n \in \mathbb{N}$ such that $\frac{1}{n} < \delta $. Pick $x_1 = \frac{4}{4n+1}$ and $x_2 = \frac{4}{4n+3}$ and note that $x_1 , x_2 <  \delta $. Now for $x_1$, we have $ \left| f(x_1) - L \right| = \left| \sin \left( (4n+1) \frac{\pi}{2} -L \right) \right| = \left| 1-L \right| < 1 $ And similarly $ \left| f(x_2) - L \right| = \left| \sin \left( (4n+3) \frac{\pi}{2} -L \right) \right| = \left| -1-L \right| < 1 $ Thus, L is within one unit of both $-1$ and $1$. However, there cannot be any such number. A contradiction! Is this proof okay?",,"['real-analysis', 'limits']"
50,Iterated Limits Proof,Iterated Limits Proof,,"If $\lim\limits_{(x,y) \to (a,b)} f(x,y) = L$, and if the one-dimensional limits $~\lim\limits_{x \to a} f(x,y), ~\lim\limits_{y \to b} f(x,y)~$ both exist, prove that $$\lim\limits_{x \to a} \Bigg(\lim\limits_{y \to b} f(x,y)\Bigg) = \lim\limits_{y \to b} \Bigg(\lim\limits_{x \to a} f(x,y)\Bigg) = L$$ Proof. Since  both one-dimensional limits exist, let $~\lim\limits_{x \to a} f(x,y) = L_a, ~ \lim\limits_{y \to b} f(x,y) = L_b$. For every $\epsilon > 0$ there exist $\delta > 0$ such that if the points $(x,y)$ are in the neighborhood $V_\delta (a,b)$, the points $f(x,y)$ are in the neighborhood $V_\epsilon (f(a,b))$, in other words $$0 < |(x,y) - (a,b)| < \delta$$ implies $$|f(x,y) - L| < \epsilon/2$$ Also, for every $\epsilon > 0$ there exist $\delta > 0$ such that if $0 < |x-a| < \delta$, then $|f(x,y) - L_a| < \epsilon/2$ From the properties of inequality, $|x| - |y| \leq |x-y|$, $$|L_a - L| - |L_a - f(x,y)| \leq |f(x,y) - L|$$ $$|L_a - L| \leq |f(x,y) - L| + |L_a - f(x,y)| < \epsilon/2 + \epsilon/2 = \epsilon$$ Thus, for every $\epsilon > 0$ there exist $\delta > 0$ such that if $0 < |y-b| < \delta$, then $|L_a - L| < \epsilon$. This implies that, $$\lim\limits_{x \to a} \Bigg(\lim\limits_{y \to b} f(x,y)\Bigg) = L$$ By appyling the same argument with the other limit, we conclude that $$\lim\limits_{y \to b} \Bigg(\lim\limits_{x \to a} f(x,y)\Bigg) = L$$ Can anyone comment on my work? Have I missed something?","If $\lim\limits_{(x,y) \to (a,b)} f(x,y) = L$, and if the one-dimensional limits $~\lim\limits_{x \to a} f(x,y), ~\lim\limits_{y \to b} f(x,y)~$ both exist, prove that $$\lim\limits_{x \to a} \Bigg(\lim\limits_{y \to b} f(x,y)\Bigg) = \lim\limits_{y \to b} \Bigg(\lim\limits_{x \to a} f(x,y)\Bigg) = L$$ Proof. Since  both one-dimensional limits exist, let $~\lim\limits_{x \to a} f(x,y) = L_a, ~ \lim\limits_{y \to b} f(x,y) = L_b$. For every $\epsilon > 0$ there exist $\delta > 0$ such that if the points $(x,y)$ are in the neighborhood $V_\delta (a,b)$, the points $f(x,y)$ are in the neighborhood $V_\epsilon (f(a,b))$, in other words $$0 < |(x,y) - (a,b)| < \delta$$ implies $$|f(x,y) - L| < \epsilon/2$$ Also, for every $\epsilon > 0$ there exist $\delta > 0$ such that if $0 < |x-a| < \delta$, then $|f(x,y) - L_a| < \epsilon/2$ From the properties of inequality, $|x| - |y| \leq |x-y|$, $$|L_a - L| - |L_a - f(x,y)| \leq |f(x,y) - L|$$ $$|L_a - L| \leq |f(x,y) - L| + |L_a - f(x,y)| < \epsilon/2 + \epsilon/2 = \epsilon$$ Thus, for every $\epsilon > 0$ there exist $\delta > 0$ such that if $0 < |y-b| < \delta$, then $|L_a - L| < \epsilon$. This implies that, $$\lim\limits_{x \to a} \Bigg(\lim\limits_{y \to b} f(x,y)\Bigg) = L$$ By appyling the same argument with the other limit, we conclude that $$\lim\limits_{y \to b} \Bigg(\lim\limits_{x \to a} f(x,y)\Bigg) = L$$ Can anyone comment on my work? Have I missed something?",,"['real-analysis', 'calculus', 'limits']"
51,"Limit as $x\to\infty$ of $(x+3)^x/f_1(x)$, where $f_1(x)=\sum\limits_{n=3}^{x+2}n^x$","Limit as  of , where",x\to\infty (x+3)^x/f_1(x) f_1(x)=\sum\limits_{n=3}^{x+2}n^x,"So take the function $$f_{1}(x)=\sum_{n=3}^{x+2}n^x.$$ This will give results like $3^1$, for $x=1$, $3^2+4^2$, for $x=2$, and $3^3+4^3+5^3$, for $x=3$, and etc. Now, also, take the function $$f_2(x)=(x+3)^x.$$ This will give results like $4^1$, for $x=1$, $5^2$, for $x=2$, and $6^3$, for $x=3$, and etc. Both of these kind of relate to Fermat's last theorem and Euler's related conjecture. What's cool is that $f_1(x)=f_2(x)$, when $x=2,3$. However, both functions separate at higher values, for example: $$f_1(4)=3^4+4^4+5^4+6^4=2258\neq f_2(4)=7^4=2401.$$ What is interesting, though, is that $f_2(x)\ge f_1(x)$, for all non-negative integer $x$ ($f_1$ wouldn't even make sense with any other domain). Even more interesting is the function $\frac{f_2(x)}{f_1(x)}$, which appears to converge, as $x$ approaches infinity. Her is a table of values for $x$, $f_1(x)$, $f_2(x)$, and $\frac{f_2(x)}{f_1(x)}$ (values are 5 digit approximations) $$ \begin{array}{c|lcr} x & f_1(x) & f_2(x) & \frac{f_2(x)}{f_1(x)} \\ \hline 1 & 3 & 4 & 1.3333 \\ 2 & 25 & 25 & 1 \\ 3 & 216 & 216 & 1 \\ 4 & 2258 & 2401 & 1.0633 \\ 5 & 28975 & 32768 & 1.1309 \\ 10 & 1.0277\times 10^{11} & 1.3786\times 10^{11} & 1.3414 \\ 20 & 1.1446\times 10^{27} & 1.7162\times 10^{27} & 1.4994 \\ 30 & 2.2970\times 10^{45} & 3.5927\times 10^{45} & 1.5641 \\ 40 & 1.3640\times 10^{65} & 2.1814\times 10^{65} & 1.5993 \\ 50 & 1.0090\times 10^{86} & 1.6360\times 10^{86} & 1.6214 \\ 100 & 1.1521\times 10^{201} & 1.921\times 10^{201} & 1.6681 \\ 142 & 4.8786\times 10^{306} & 8.2083\times 10^{306} & 1.6825 \\ \end{array} $$ So the question comes down to:$$\text{What is} \lim_{x\to \infty} \frac{(x+3)^x}{\sum_{n=3}^{x+2}n^x}?$$","So take the function $$f_{1}(x)=\sum_{n=3}^{x+2}n^x.$$ This will give results like $3^1$, for $x=1$, $3^2+4^2$, for $x=2$, and $3^3+4^3+5^3$, for $x=3$, and etc. Now, also, take the function $$f_2(x)=(x+3)^x.$$ This will give results like $4^1$, for $x=1$, $5^2$, for $x=2$, and $6^3$, for $x=3$, and etc. Both of these kind of relate to Fermat's last theorem and Euler's related conjecture. What's cool is that $f_1(x)=f_2(x)$, when $x=2,3$. However, both functions separate at higher values, for example: $$f_1(4)=3^4+4^4+5^4+6^4=2258\neq f_2(4)=7^4=2401.$$ What is interesting, though, is that $f_2(x)\ge f_1(x)$, for all non-negative integer $x$ ($f_1$ wouldn't even make sense with any other domain). Even more interesting is the function $\frac{f_2(x)}{f_1(x)}$, which appears to converge, as $x$ approaches infinity. Her is a table of values for $x$, $f_1(x)$, $f_2(x)$, and $\frac{f_2(x)}{f_1(x)}$ (values are 5 digit approximations) $$ \begin{array}{c|lcr} x & f_1(x) & f_2(x) & \frac{f_2(x)}{f_1(x)} \\ \hline 1 & 3 & 4 & 1.3333 \\ 2 & 25 & 25 & 1 \\ 3 & 216 & 216 & 1 \\ 4 & 2258 & 2401 & 1.0633 \\ 5 & 28975 & 32768 & 1.1309 \\ 10 & 1.0277\times 10^{11} & 1.3786\times 10^{11} & 1.3414 \\ 20 & 1.1446\times 10^{27} & 1.7162\times 10^{27} & 1.4994 \\ 30 & 2.2970\times 10^{45} & 3.5927\times 10^{45} & 1.5641 \\ 40 & 1.3640\times 10^{65} & 2.1814\times 10^{65} & 1.5993 \\ 50 & 1.0090\times 10^{86} & 1.6360\times 10^{86} & 1.6214 \\ 100 & 1.1521\times 10^{201} & 1.921\times 10^{201} & 1.6681 \\ 142 & 4.8786\times 10^{306} & 8.2083\times 10^{306} & 1.6825 \\ \end{array} $$ So the question comes down to:$$\text{What is} \lim_{x\to \infty} \frac{(x+3)^x}{\sum_{n=3}^{x+2}n^x}?$$",,"['limits', 'asymptotics']"
52,Statement and proof of the sequential characterization of limits,Statement and proof of the sequential characterization of limits,,So frequently on this site I will use the sequential characterizations of limits and continuity in my answers only to find the OP is unfamiliar with it. It is such a crucial notion that I am going to write the statement and proof here so that I (and others) can link it in answers.,So frequently on this site I will use the sequential characterizations of limits and continuity in my answers only to find the OP is unfamiliar with it. It is such a crucial notion that I am going to write the statement and proof here so that I (and others) can link it in answers.,,"['real-analysis', 'limits']"
53,"Suppose we want to make $|x^2 \sin(1/x)| < \varepsilon$ where $\varepsilon > 1$, why does it not suffice that $|x| < \varepsilon$?","Suppose we want to make  where , why does it not suffice that ?",|x^2 \sin(1/x)| < \varepsilon \varepsilon > 1 |x| < \varepsilon,"I was reading Spivak's Calculus and came across this ( Spivak's Calculus Chapter 5 ) I'm confused because $f(x) = x^2 \sin(\frac{1}{x})$ has the following property: $|f(x)| < |x|$ for all $x ∈ \Bbb{R}$. If we set $|x| < \varepsilon$, then $|f(x)| < |x| < \varepsilon$ therefore $|f(x)| < \varepsilon$. Shouldn't it then suffice to set $|x| < \varepsilon$ if we want to make $|x^2 \sin(\frac{1}{x})| < \varepsilon$?","I was reading Spivak's Calculus and came across this ( Spivak's Calculus Chapter 5 ) I'm confused because $f(x) = x^2 \sin(\frac{1}{x})$ has the following property: $|f(x)| < |x|$ for all $x ∈ \Bbb{R}$. If we set $|x| < \varepsilon$, then $|f(x)| < |x| < \varepsilon$ therefore $|f(x)| < \varepsilon$. Shouldn't it then suffice to set $|x| < \varepsilon$ if we want to make $|x^2 \sin(\frac{1}{x})| < \varepsilon$?",,"['calculus', 'real-analysis', 'limits']"
54,Limit proof by definition,Limit proof by definition,,"I have the following limit: $$\lim_{x \to 6} \frac{x+1}{x-5} = 7$$ How do I prove this equation by the famous definition of the limit? (the one includes delta and epsilon). I know how to prove simple limits like this one: $$\\\lim_{x \to 6} x-5 = 1  \\ |x - x_0| < \delta \implies |x - 6| < \delta  \\ |f(x) -L| < \epsilon \implies |x-5 -1| < \epsilon  \implies |x - 6| < \epsilon   \\ \implies \delta = \epsilon$$ But in the first example I asked about I have: $$|x-6| < \delta$$ $$|\frac{x+1}{x-5} -7| < \epsilon \implies |\frac{36-6x}{x-5}| < \epsilon$$ don't really know how to proceed, thanks in advance :)","I have the following limit: $$\lim_{x \to 6} \frac{x+1}{x-5} = 7$$ How do I prove this equation by the famous definition of the limit? (the one includes delta and epsilon). I know how to prove simple limits like this one: $$\\\lim_{x \to 6} x-5 = 1  \\ |x - x_0| < \delta \implies |x - 6| < \delta  \\ |f(x) -L| < \epsilon \implies |x-5 -1| < \epsilon  \implies |x - 6| < \epsilon   \\ \implies \delta = \epsilon$$ But in the first example I asked about I have: $$|x-6| < \delta$$ $$|\frac{x+1}{x-5} -7| < \epsilon \implies |\frac{36-6x}{x-5}| < \epsilon$$ don't really know how to proceed, thanks in advance :)",,"['calculus', 'limits', 'proof-verification']"
55,"Does L'Hopitals Rule hold for second derivative, third derivative, etc...?","Does L'Hopitals Rule hold for second derivative, third derivative, etc...?",,"Does L'Hopitals Rule hold for second derivative, third derivative, etc...? Assuming the function is differential up to the $k$th derivative, is the following true? $$\lim_{x\to c} \frac{f(x)}{g(x)} = \lim_{x\to c} \frac{f'(x)}{g'(x)} = \lim_{x\to c} \frac{f''(x)}{g''(x)} = \cdots = \lim_{x\to c} \frac{f^{(k)}(x)}{g^{(k)}(x)} = \lim_{x\to c} \frac{f^{(k+1)}(x)}{g^{(k+1)}(x)}$$","Does L'Hopitals Rule hold for second derivative, third derivative, etc...? Assuming the function is differential up to the $k$th derivative, is the following true? $$\lim_{x\to c} \frac{f(x)}{g(x)} = \lim_{x\to c} \frac{f'(x)}{g'(x)} = \lim_{x\to c} \frac{f''(x)}{g''(x)} = \cdots = \lim_{x\to c} \frac{f^{(k)}(x)}{g^{(k)}(x)} = \lim_{x\to c} \frac{f^{(k+1)}(x)}{g^{(k+1)}(x)}$$",,"['calculus', 'limits']"
56,Limit of $\sin 2^n$,Limit of,\sin 2^n,"I am trying to show that $$\lim_{n\to \infty}\sin 2^n$$ diverges for $n \in \mathbb N$ I could show that assuming the limit converges, say to $L$ then $$L=\lim_{n\to \infty}\sin 2^{n+1}$$ $$=2\lim_{n\to \infty}\sin 2^n\lim_{n\to \infty}\cos 2^n$$ $$=2L\lim_{n\to \infty}\cos 2^n$$ It cannot be $$\lim_{n\to \infty}\cos 2^n=\frac{1}{2}$$ since it implies $$\frac{1}{2}=\lim_{n\to \infty}\cos 2^{n+1}$$ $$=2(\lim_{n\to \infty}\cos 2^n)^2-1$$ $$=-\frac{1}{2}$$ So either $$\lim_{n\to \infty}\sin 2^n=0$$ or it diverges. For the sequence to converge, necessarily it must be that $2^n$ gets  arbitrarily close to $m\pi$ for some integer $m(n)$ as $n$ goes to infinity, which seems counterintuitive. But I couldn't prove it, so anyone has some good idea?","I am trying to show that $$\lim_{n\to \infty}\sin 2^n$$ diverges for $n \in \mathbb N$ I could show that assuming the limit converges, say to $L$ then $$L=\lim_{n\to \infty}\sin 2^{n+1}$$ $$=2\lim_{n\to \infty}\sin 2^n\lim_{n\to \infty}\cos 2^n$$ $$=2L\lim_{n\to \infty}\cos 2^n$$ It cannot be $$\lim_{n\to \infty}\cos 2^n=\frac{1}{2}$$ since it implies $$\frac{1}{2}=\lim_{n\to \infty}\cos 2^{n+1}$$ $$=2(\lim_{n\to \infty}\cos 2^n)^2-1$$ $$=-\frac{1}{2}$$ So either $$\lim_{n\to \infty}\sin 2^n=0$$ or it diverges. For the sequence to converge, necessarily it must be that $2^n$ gets  arbitrarily close to $m\pi$ for some integer $m(n)$ as $n$ goes to infinity, which seems counterintuitive. But I couldn't prove it, so anyone has some good idea?",,['limits']
57,Conditions for l'Hôpital's rule,Conditions for l'Hôpital's rule,,"According to l'Hôpital's rule, given functions $f,g$ which are differentiable around $a\in \mathbb R$, such that -- $\lim_{x\to a} f(x)=\lim_{x\to a}g(x)=0$ $g'(x)\neq 0$ on some deleted neighborhood of $a$. $\lim_{x\to a} {\frac {f'(x)}{g'(x)} }$ exists (widely). Then  $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } = \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$. Condition 2 is necessary for the proof, but I can't find a counterexample for the theorem without it. Could you give an example of differentiable functions $f,g$ aroud $a$, such that conditions 1,3 hold, but $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } \neq \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$?","According to l'Hôpital's rule, given functions $f,g$ which are differentiable around $a\in \mathbb R$, such that -- $\lim_{x\to a} f(x)=\lim_{x\to a}g(x)=0$ $g'(x)\neq 0$ on some deleted neighborhood of $a$. $\lim_{x\to a} {\frac {f'(x)}{g'(x)} }$ exists (widely). Then  $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } = \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$. Condition 2 is necessary for the proof, but I can't find a counterexample for the theorem without it. Could you give an example of differentiable functions $f,g$ aroud $a$, such that conditions 1,3 hold, but $\ \ \lim_{x\to a} {\frac {f(x)}{g(x)} } \neq \lim_{x\to a} {\frac {f'(x)}{g'(x)} }$?",,"['calculus', 'limits']"
58,Value of the given limit.,Value of the given limit.,,What is $$\lim _{ x\rightarrow 1 }{ \frac { x\log { \left( x \right) -x+1 }  }{ \left( x-1 \right) \log { \left( x \right)  }  }  } $$   Note I have used $\lim _{ x\rightarrow 0 }{ \frac { \log { \left( 1+x \right)  }  }{ x }  } =1$ . So I wrote $\log(x)=\log(1+x-1)$ and hence I got $\frac{x^2-2x+1}{x-1}$ after cancelling I got the value as $0$. But the correct answer is $\frac{1}{2}$. Where's my mistake? Any hint. I don't want Lhospital rule or Taylor series if they aren't compulsory to work out the answer .,What is $$\lim _{ x\rightarrow 1 }{ \frac { x\log { \left( x \right) -x+1 }  }{ \left( x-1 \right) \log { \left( x \right)  }  }  } $$   Note I have used $\lim _{ x\rightarrow 0 }{ \frac { \log { \left( 1+x \right)  }  }{ x }  } =1$ . So I wrote $\log(x)=\log(1+x-1)$ and hence I got $\frac{x^2-2x+1}{x-1}$ after cancelling I got the value as $0$. But the correct answer is $\frac{1}{2}$. Where's my mistake? Any hint. I don't want Lhospital rule or Taylor series if they aren't compulsory to work out the answer .,,"['limits', 'limits-without-lhopital']"
59,Limits with complex numbers,Limits with complex numbers,,"$$\lim_{z\to 0} \frac{z^*}{z}$$ The way I see it is that it's asking what happens when $z$ approaches $0$. However, I can't just say undefined because $z$ is actually $z=x+iy$. So if I take the complex conjugate of the bottom I remove the $i$ from the denominator and can get it into standard form. The problem then is what does it mean to say that $z$ goes to $0$ when I have $x, y, i$?","$$\lim_{z\to 0} \frac{z^*}{z}$$ The way I see it is that it's asking what happens when $z$ approaches $0$. However, I can't just say undefined because $z$ is actually $z=x+iy$. So if I take the complex conjugate of the bottom I remove the $i$ from the denominator and can get it into standard form. The problem then is what does it mean to say that $z$ goes to $0$ when I have $x, y, i$?",,"['limits', 'complex-numbers']"
60,Prove $\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = 2.25$ knowing that $\lim_{x\to 0}\frac{f(x)}{x} = 3$,Prove  knowing that,\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = 2.25 \lim_{x\to 0}\frac{f(x)}{x} = 3,"$f$ is defined on the neighborhood of $x=0$, $\lim_{x\to 0}\frac{f(x)}{x} = 3$. I need to prove that $\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = 2.25$. I'm kinda stuck. I was thinking: If I define $t = 4x$ then $\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = \lim_{t \to 0}\frac{\frac{f(3 \cdot \frac{t}{4})}{t}}{\frac{\ln(1+t)}{t}}$ and I know that $\lim_{t \to 0}\frac{ln(1+t)}{t} = 1$ but I'm still stuck with $\lim_{t \to 0}\frac{f(3 \cdot \frac{t}{4})}{t}$... Help?","$f$ is defined on the neighborhood of $x=0$, $\lim_{x\to 0}\frac{f(x)}{x} = 3$. I need to prove that $\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = 2.25$. I'm kinda stuck. I was thinking: If I define $t = 4x$ then $\lim_{x \to 0}\frac{f(3x)}{\ln(1+4x)} = \lim_{t \to 0}\frac{\frac{f(3 \cdot \frac{t}{4})}{t}}{\frac{\ln(1+t)}{t}}$ and I know that $\lim_{t \to 0}\frac{ln(1+t)}{t} = 1$ but I'm still stuck with $\lim_{t \to 0}\frac{f(3 \cdot \frac{t}{4})}{t}$... Help?",,"['calculus', 'limits']"
61,How to prove that $x^{\frac{1}{n}}$ is continuous?,How to prove that  is continuous?,x^{\frac{1}{n}},"If there is a function $f$ such that:- $$ f:\mathbb{R}^{+}\rightarrow\mathbb{R}\\ f(x) = x^{\frac{1}{n}}, n\in \mathbb{Z}^{+} $$ How can we prove the continuity of above function using the $\epsilon-\delta$ definition of limits?","If there is a function $f$ such that:- $$ f:\mathbb{R}^{+}\rightarrow\mathbb{R}\\ f(x) = x^{\frac{1}{n}}, n\in \mathbb{Z}^{+} $$ How can we prove the continuity of above function using the $\epsilon-\delta$ definition of limits?",,"['real-analysis', 'limits', 'continuity']"
62,Find the limit as $n$ approaches infinity: $\lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}}$,Find the limit as  approaches infinity:,n \lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}},"$$\lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}}$$ I am taking calculus in university and this is the problem I have been given. I haven't even seen limits involving a variable in the exponent in the textbook, so I am really stuck. I tried graphing and I can guess that the limit will probably be $0$. I've tried laws of exponents, limit laws, but nothing gives me a good answer. Also, sorry about the formatting, but this is the best I could do - it's my first time on this website. The second part of the equation should also be under a square root, so very similar to the first square root, but with the second exponent at $\frac{n}{2}$ instead of $-n$. Thank you so much for help solving this.","$$\lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}}$$ I am taking calculus in university and this is the problem I have been given. I haven't even seen limits involving a variable in the exponent in the textbook, so I am really stuck. I tried graphing and I can guess that the limit will probably be $0$. I've tried laws of exponents, limit laws, but nothing gives me a good answer. Also, sorry about the formatting, but this is the best I could do - it's my first time on this website. The second part of the equation should also be under a square root, so very similar to the first square root, but with the second exponent at $\frac{n}{2}$ instead of $-n$. Thank you so much for help solving this.",,"['calculus', 'limits', 'radicals']"
63,is my argument for $\lim_{n\rightarrow\infty}(a_n) = 0$ given $a_n = \tan(n) (\frac{1}{e})^{n}$ correct?,is my argument for  given  correct?,\lim_{n\rightarrow\infty}(a_n) = 0 a_n = \tan(n) (\frac{1}{e})^{n},"I want to show that $\lim_{n\rightarrow\infty}(a_n) = 0$ where $a_n = \tan(n) (\frac{1}{e})^{n}$ My argument is that: $\tan(n) = \frac{\sin(n)}{\cos(n)} \in \mathbb{R}$ for $n \in \mathbb{N}$ since cos(x) only has roots of the form $x = -\frac{\pi}{2} + \pi k , k \in \mathbb{Z}$. The convergence of the other term is obvious. Is it correct?","I want to show that $\lim_{n\rightarrow\infty}(a_n) = 0$ where $a_n = \tan(n) (\frac{1}{e})^{n}$ My argument is that: $\tan(n) = \frac{\sin(n)}{\cos(n)} \in \mathbb{R}$ for $n \in \mathbb{N}$ since cos(x) only has roots of the form $x = -\frac{\pi}{2} + \pi k , k \in \mathbb{Z}$. The convergence of the other term is obvious. Is it correct?",,"['real-analysis', 'limits']"
64,continuity of a function,continuity of a function,,"I have a task as preparation for my Calculus Exam. $f(x)= \begin{cases} 2^{\frac{1}{x-2}} ,& x\neq 2 \\ 0 ,&x=2 \end{cases}$ Now we have the following solution by one of our tutors: $l_1 = \lim_{x \rightarrow 2^-} f(x) = \lim_{x\rightarrow 2^-}2^{\frac{1}{x-2}} = 2^0 = 1$ $l_2 = \lim_{x \rightarrow 2^+} f(x) = \lim_{x\rightarrow 2^+}2^{\frac{1}{x-2}} = 2^0 = 1$ But I don't understand this specific part:  $\lim_{x\rightarrow 2^+}2^{\frac{1}{x-2}} = 2^0 = 1$ What is she doing between that steps because if I have a fraction with $ \dfrac{1}{\text{number} < 0} $ it is not getting $0$ but larger. So where's the $2^0$ coming from?","I have a task as preparation for my Calculus Exam. $f(x)= \begin{cases} 2^{\frac{1}{x-2}} ,& x\neq 2 \\ 0 ,&x=2 \end{cases}$ Now we have the following solution by one of our tutors: $l_1 = \lim_{x \rightarrow 2^-} f(x) = \lim_{x\rightarrow 2^-}2^{\frac{1}{x-2}} = 2^0 = 1$ $l_2 = \lim_{x \rightarrow 2^+} f(x) = \lim_{x\rightarrow 2^+}2^{\frac{1}{x-2}} = 2^0 = 1$ But I don't understand this specific part:  $\lim_{x\rightarrow 2^+}2^{\frac{1}{x-2}} = 2^0 = 1$ What is she doing between that steps because if I have a fraction with $ \dfrac{1}{\text{number} < 0} $ it is not getting $0$ but larger. So where's the $2^0$ coming from?",,"['calculus', 'limits', 'continuity']"
65,Lebesgue Integration Question,Lebesgue Integration Question,,"Let $f$ be integrable with respect to a Lebesgue measure. Evaluate the limit, $$\lim_{n \to \infty} \int_{-\infty}^{\infty} f(x-n)\left(\frac{1}{1+|x|}\right)\,dx$$ I tried change of variables but I don't know what to do after that.","Let $f$ be integrable with respect to a Lebesgue measure. Evaluate the limit, $$\lim_{n \to \infty} \int_{-\infty}^{\infty} f(x-n)\left(\frac{1}{1+|x|}\right)\,dx$$ I tried change of variables but I don't know what to do after that.",,"['real-analysis', 'limits', 'lebesgue-integral', 'lebesgue-measure']"
66,Prove that a function does not have a limit when $x\rightarrow 0$,Prove that a function does not have a limit when,x\rightarrow 0,"Let $$f(x)=\left\{    \begin{array}{l l}     x+2 & \quad ,x\in\mathbb{Q}\\     6-x & \quad ,x\notin\mathbb{Q}   \end{array} \right.$$ then $$\lim_{x \to 0}f(x)$$ does not exist. By limit definition. I see that I should choose $\varepsilon_0=1$ but I don't see how do I continue.. Thanks","Let $$f(x)=\left\{    \begin{array}{l l}     x+2 & \quad ,x\in\mathbb{Q}\\     6-x & \quad ,x\notin\mathbb{Q}   \end{array} \right.$$ then $$\lim_{x \to 0}f(x)$$ does not exist. By limit definition. I see that I should choose $\varepsilon_0=1$ but I don't see how do I continue.. Thanks",,"['calculus', 'limits']"
67,How often is $x\to\infty$ used to denote ($x\to +\infty$ or $x\to -\infty$)?,How often is  used to denote ( or )?,x\to\infty x\to +\infty x\to -\infty,"How often is $x\to\infty$ used to denote ($x\to +\infty$ or $x\to -\infty$)? Both my textbook and my teacher use $x\to\infty$ as above, so e.g. it's false for us that $\lim_{x\to\infty}\frac{1}{\sqrt{x}}=0$ and the limit does not exist here. But here on M.SE everyone means $x\to +\infty$ when writing $x\to\infty$ and this is how Wikipedia defines it, so I think our notation is unusual. Is it? Do mathematicians ever use it?","How often is $x\to\infty$ used to denote ($x\to +\infty$ or $x\to -\infty$)? Both my textbook and my teacher use $x\to\infty$ as above, so e.g. it's false for us that $\lim_{x\to\infty}\frac{1}{\sqrt{x}}=0$ and the limit does not exist here. But here on M.SE everyone means $x\to +\infty$ when writing $x\to\infty$ and this is how Wikipedia defines it, so I think our notation is unusual. Is it? Do mathematicians ever use it?",,"['calculus', 'limits', 'notation']"
68,Limit of $\sum_{k=1}^{n} \frac{k}{3^k}$,Limit of,\sum_{k=1}^{n} \frac{k}{3^k},"I need to calculate $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{k}{3^k}$$ and I can't really do it. I have a feeling it's simple and that there's a simple catch but I just can't see it. If anyone could provide me with a hint to solve this, I would be grateful. I know this question is classified as homework and that it seems like I haven't tried anything, but I have. I tried expanding this but that doesn't help at all. Geometric progression came to mind at first, but I realized it's not very useful either.  Thanks.","I need to calculate $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{k}{3^k}$$ and I can't really do it. I have a feeling it's simple and that there's a simple catch but I just can't see it. If anyone could provide me with a hint to solve this, I would be grateful. I know this question is classified as homework and that it seems like I haven't tried anything, but I have. I tried expanding this but that doesn't help at all. Geometric progression came to mind at first, but I realized it's not very useful either.  Thanks.",,"['limits', 'convergence-divergence']"
69,How to evaluate $\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}}$,How to evaluate,\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}},"I'd like to know why $\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}} = \max\limits_{1\le i \le n} \left| x_i-y_i\right|$ for $\mathbf{x},\mathbf{y}\in \mathbb{R}^n$. So I started by checking a simpler expression: $\lim\limits_{x\rightarrow \infty} ((6-3)^x+(5-1)^x)^{\frac{1}{x}}=4$ I don't know how to get 4. The expression inside the parenthesis is indeterminate $(\infty + \infty)$ and I don't know of any way to rewrite it so that I can remove the exponents.","I'd like to know why $\lim\limits_{p \rightarrow \infty} \left(\sum_\limits{i=1}^n \left|x_i-y_i\right|^p\right)^{\frac{1}{p}} = \max\limits_{1\le i \le n} \left| x_i-y_i\right|$ for $\mathbf{x},\mathbf{y}\in \mathbb{R}^n$. So I started by checking a simpler expression: $\lim\limits_{x\rightarrow \infty} ((6-3)^x+(5-1)^x)^{\frac{1}{x}}=4$ I don't know how to get 4. The expression inside the parenthesis is indeterminate $(\infty + \infty)$ and I don't know of any way to rewrite it so that I can remove the exponents.",,['limits']
70,the value of $e$ and the method of getting it,the value of  and the method of getting it,e,We define e to be a number which satisfies the following condition $$\lim _{a \to 0} \frac{e^a-1}{a}=1. $$ How did we arrive to the following from above equation $$e=\lim _{n \to \infty} \bigg(1+\frac{1}{n}\bigg)^n ? $$ so that we get the value of n,We define e to be a number which satisfies the following condition $$\lim _{a \to 0} \frac{e^a-1}{a}=1. $$ How did we arrive to the following from above equation $$e=\lim _{n \to \infty} \bigg(1+\frac{1}{n}\bigg)^n ? $$ so that we get the value of n,,"['limits', 'exponential-function']"
71,Limit of Ratio of Chebyshev Polynomials,Limit of Ratio of Chebyshev Polynomials,,"I have been trying to compute the limit $$\lim_{n\to\infty}{{U_n(x)^2}\over{U_{n-1}(x)^2+U_n(x)^2}}$$ where $U_n(x)$ is the $n$-th Chebyshev polynomial of the second kind and $x\ge 1$. Using software I have been able to compute these limits exist when $x$ a half-integer, but I would like to have an explicit formula of the limit as a function of $x$ (at least for $x$ a half-integer).","I have been trying to compute the limit $$\lim_{n\to\infty}{{U_n(x)^2}\over{U_{n-1}(x)^2+U_n(x)^2}}$$ where $U_n(x)$ is the $n$-th Chebyshev polynomial of the second kind and $x\ge 1$. Using software I have been able to compute these limits exist when $x$ a half-integer, but I would like to have an explicit formula of the limit as a function of $x$ (at least for $x$ a half-integer).",,"['limits', 'special-functions', 'chebyshev-polynomials']"
72,Limits using Maclaurins expansion for $\lim_{x\rightarrow 0}\frac{e^{x^2}-\ln(1+x^2)-1}{\cos2x+2x\sin x-1}$,Limits using Maclaurins expansion for,\lim_{x\rightarrow 0}\frac{e^{x^2}-\ln(1+x^2)-1}{\cos2x+2x\sin x-1},"$$\lim_{x\rightarrow 0}\frac{e^{x^2}-\ln(1+x^2)-1}{\cos2x+2x\sin x-1}$$ Using Maclaurin's expansion for the numerator gives: $$\left(1+x^2\cdots\right)-\left(x^2-\frac{x^4}{2}\cdots\right)-1$$ And the denominator: $$\left(1-2x^2\cdots\right) + \left(2x^2-\frac{x^4}{3}\cdots\right)-1$$ $$\therefore \lim_{x\rightarrow 0} f(x) = \frac{-\dfrac{x^4}{2}}{-\dfrac{x^4}{3}} = \frac{3}{2}$$ But Wolfram gives that the limit is $3$. I thought, maybe I used too few terms. What is a thumb rule for how many terms in expansion to use to calculate limits? Using three terms yielded the answer $\lim_{x\rightarrow 0}f(x) = -4$. What did I do wrong?","$$\lim_{x\rightarrow 0}\frac{e^{x^2}-\ln(1+x^2)-1}{\cos2x+2x\sin x-1}$$ Using Maclaurin's expansion for the numerator gives: $$\left(1+x^2\cdots\right)-\left(x^2-\frac{x^4}{2}\cdots\right)-1$$ And the denominator: $$\left(1-2x^2\cdots\right) + \left(2x^2-\frac{x^4}{3}\cdots\right)-1$$ $$\therefore \lim_{x\rightarrow 0} f(x) = \frac{-\dfrac{x^4}{2}}{-\dfrac{x^4}{3}} = \frac{3}{2}$$ But Wolfram gives that the limit is $3$. I thought, maybe I used too few terms. What is a thumb rule for how many terms in expansion to use to calculate limits? Using three terms yielded the answer $\lim_{x\rightarrow 0}f(x) = -4$. What did I do wrong?",,"['calculus', 'limits', 'polynomials', 'taylor-expansion']"
73,Closed formula for the asymptotic limit of a definite integral,Closed formula for the asymptotic limit of a definite integral,,"I would like to solve the following integral: $$ I_0 (a,b)= \int_0^1 dx\int_0^{1-x} dz \frac{1}{a z (z-1)+a x z + x(1-b)}$$ in the limit where $b$ is small ($a$ and $b$ are positive constants). What is the best way to study this asymptotic limit? I have tried to use Mathematica, but it gives some very weird results. Thanks for any help.","I would like to solve the following integral: $$ I_0 (a,b)= \int_0^1 dx\int_0^{1-x} dz \frac{1}{a z (z-1)+a x z + x(1-b)}$$ in the limit where $b$ is small ($a$ and $b$ are positive constants). What is the best way to study this asymptotic limit? I have tried to use Mathematica, but it gives some very weird results. Thanks for any help.",,"['calculus', 'limits', 'definite-integrals', 'taylor-expansion', 'closed-form']"
74,Why does $y = x\sin(\frac{180}{x})$ approach $\pi$?,Why does  approach ?,y = x\sin(\frac{180}{x}) \pi,"A few days ago I was playing on my scientific calculator and I ran over an interesting little equation: $180\sin(1)$ is extremely close to $\pi$. At first I thought it was a coincidence, but then I tried $360\sin\left(\frac{1}{2}\right)$ and it was closer to pi. So then I tried out $90\sin(2)$ and it was farther from $\pi$. So I came up with the equation $y = 180x\sin\left(\frac{1}{x}\right)$, which I then simplified to $y = x\sin\left(\frac{180}{x}\right)$. Although it approaches $\pi$ slower (180 times slower), it is easier to understand what was going on on the desmos graphing calculator. It seems the larger the $x$ value, the closer it gets to $\pi$. I would like to know why exactly this happens. EDIT: (Sine is in degrees not radians, just for clarification)","A few days ago I was playing on my scientific calculator and I ran over an interesting little equation: $180\sin(1)$ is extremely close to $\pi$. At first I thought it was a coincidence, but then I tried $360\sin\left(\frac{1}{2}\right)$ and it was closer to pi. So then I tried out $90\sin(2)$ and it was farther from $\pi$. So I came up with the equation $y = 180x\sin\left(\frac{1}{x}\right)$, which I then simplified to $y = x\sin\left(\frac{180}{x}\right)$. Although it approaches $\pi$ slower (180 times slower), it is easier to understand what was going on on the desmos graphing calculator. It seems the larger the $x$ value, the closer it gets to $\pi$. I would like to know why exactly this happens. EDIT: (Sine is in degrees not radians, just for clarification)",,"['limits', 'trigonometry', 'pi']"
75,I need to understand why the limit of $x\cdot \sin (1/x)$ as $x$ tends to infinity is 1,I need to understand why the limit of  as  tends to infinity is 1,x\cdot \sin (1/x) x,"here's the question, how can I solve this: $$\lim_{x \rightarrow \infty} x\sin (1/x) $$ Now, from textbooks I know it is possible to use the following substitution $x=1/t$, then, the ecuation is reformed in the following way $$\frac{\sin t}{t}$$ then, and this is what I really can´t understand, textbook suggest find the limit as $t\to0^+$ (what gives you 1 as result) Ok, I can't figure out WHY finding that limit as $t$ approaches $0$ from the right gives me the answer of the limit in infinity of the original formula. I think I can't understand what implies the substitution. Better than an answer,  I need an explanation. (Sorry If I wrote something incorrectly, the english is not my original language)               Really thanks!!","here's the question, how can I solve this: $$\lim_{x \rightarrow \infty} x\sin (1/x) $$ Now, from textbooks I know it is possible to use the following substitution $x=1/t$, then, the ecuation is reformed in the following way $$\frac{\sin t}{t}$$ then, and this is what I really can´t understand, textbook suggest find the limit as $t\to0^+$ (what gives you 1 as result) Ok, I can't figure out WHY finding that limit as $t$ approaches $0$ from the right gives me the answer of the limit in infinity of the original formula. I think I can't understand what implies the substitution. Better than an answer,  I need an explanation. (Sorry If I wrote something incorrectly, the english is not my original language)               Really thanks!!",,"['calculus', 'limits', 'infinity']"
76,Evaluating $\lim_{n \rightarrow \infty} \int^{n}_{0} (1+\frac{x}{n})^{-n} \log(2+ \cos(\frac{x}{n})) \> dx$,Evaluating,\lim_{n \rightarrow \infty} \int^{n}_{0} (1+\frac{x}{n})^{-n} \log(2+ \cos(\frac{x}{n})) \> dx,"The problem I am stuck on asks the reader to find the following limit: $$\lim_{n \rightarrow \infty} \int^{n}_{0} \left(1+\frac{x}{n}\right)^{-n} \log\left(2+ \cos\left(\frac{x}{n}\right)\right)\ \mathrm dx.$$ The section I am working on contains all your basic limit theorem in measure theory (Monotone Covergence Theorem, Fatou's Lemma, Dominated Convergence Theorem). I know I am probably overseeing an application of one of them. Help would be greatly appreciated.","The problem I am stuck on asks the reader to find the following limit: $$\lim_{n \rightarrow \infty} \int^{n}_{0} \left(1+\frac{x}{n}\right)^{-n} \log\left(2+ \cos\left(\frac{x}{n}\right)\right)\ \mathrm dx.$$ The section I am working on contains all your basic limit theorem in measure theory (Monotone Covergence Theorem, Fatou's Lemma, Dominated Convergence Theorem). I know I am probably overseeing an application of one of them. Help would be greatly appreciated.",,"['measure-theory', 'limits']"
77,The relation between the number of $0$s which are at the end of $3^{n!}-1$ and that of $n!$,The relation between the number of s which are at the end of  and that of,0 3^{n!}-1 n!,"Let $a_n,b_n$ be the number of $0$ s which are at the end of $3^{n!}-1,n!$ in the decimal system respectively. I found that $a_n=b_n+1$ holds for $n=4,5,\cdots, 10$ . Then, my questions are... Question 1 : Does $a_n=b_n+1$ hold for every $n\ge 4\in\mathbb N$ ? Question 2 : If the answer for question 1 is no , then does $\lim_{n\to\infty}(a_n/b_n)$ exist? We know that $b_n=\sum_{k=1}^{\infty}\lfloor n/5^k\rfloor$ , but I don't have any good idea to treat $3^{n!}-1$ . Can anyone help?","Let be the number of s which are at the end of in the decimal system respectively. I found that holds for . Then, my questions are... Question 1 : Does hold for every ? Question 2 : If the answer for question 1 is no , then does exist? We know that , but I don't have any good idea to treat . Can anyone help?","a_n,b_n 0 3^{n!}-1,n! a_n=b_n+1 n=4,5,\cdots, 10 a_n=b_n+1 n\ge 4\in\mathbb N \lim_{n\to\infty}(a_n/b_n) b_n=\sum_{k=1}^{\infty}\lfloor n/5^k\rfloor 3^{n!}-1","['number-theory', 'limits', 'factorial']"
78,Limit of a sequence $a_1=1;a_{n+1}=(n+1)(1+a_n)$,Limit of a sequence,a_1=1;a_{n+1}=(n+1)(1+a_n),Let a sequence be $a_1=1;a_{n+1}=(n+1)(1+a_n)$ If $P_n=\prod_1^n(1+a_i^{-1})$ then $$\lim_{n\to\infty}P_n $$is ? I did: $$P_n=\prod_1^n\frac{(1+a_i)}{a_i} =\frac{a_{n+1}}{a_1}\prod1^{n-1}\frac{(1+a_i)}{a_{i+1}} =\frac{a_{n+1}}{a_1}\prod_1^{n-1}\frac1{i+1}=\frac{a_{n+1}}{n!}$$ Now how do I find the limit?,Let a sequence be $a_1=1;a_{n+1}=(n+1)(1+a_n)$ If $P_n=\prod_1^n(1+a_i^{-1})$ then $$\lim_{n\to\infty}P_n $$is ? I did: $$P_n=\prod_1^n\frac{(1+a_i)}{a_i} =\frac{a_{n+1}}{a_1}\prod1^{n-1}\frac{(1+a_i)}{a_{i+1}} =\frac{a_{n+1}}{a_1}\prod_1^{n-1}\frac1{i+1}=\frac{a_{n+1}}{n!}$$ Now how do I find the limit?,,['limits']
79,"$\lim_{x\to 2} \, \sqrt{x-2}$",,"\lim_{x\to 2} \, \sqrt{x-2}","$$\lim_{x\to 2} \, \sqrt{x-2}$$ When you take the right hand limit for this expression, you get $0$. However, if you take the left hand side it gives an imaginary number. However, do you consider the imaginary part when taking the limit (in which case both sides would tend to $0$) or do you consider the limit to be undefined because it cannot be approached from the left in the field of real numbers.","$$\lim_{x\to 2} \, \sqrt{x-2}$$ When you take the right hand limit for this expression, you get $0$. However, if you take the left hand side it gives an imaginary number. However, do you consider the imaginary part when taking the limit (in which case both sides would tend to $0$) or do you consider the limit to be undefined because it cannot be approached from the left in the field of real numbers.",,"['real-analysis', 'limits', 'complex-numbers']"
80,$\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}$,,\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}},"$$\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}$$ I need to take this limit. I suceed in proving that: $$\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}>\sqrt[105]{x}$$ I tought this would help me, but in the end, I have: $$\frac{1}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\frac{1}{\sqrt[105]{x}} \implies$$ $$\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\frac{\sqrt[104]{x}}{\sqrt[105]{x}} \implies$$ $$\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[105]{x}}<\lim_{x\to\infty}\sqrt[10920]{x} = \infty$$ Wich does not help me. Is there a way to solve this by comparsion? It would be better to me. If not, is there a way to fator these roots out?","$$\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}$$ I need to take this limit. I suceed in proving that: $$\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}>\sqrt[105]{x}$$ I tought this would help me, but in the end, I have: $$\frac{1}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\frac{1}{\sqrt[105]{x}} \implies$$ $$\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\frac{\sqrt[104]{x}}{\sqrt[105]{x}} \implies$$ $$\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[3]{7+\sqrt[5]{6+\sqrt[7]{x+17}}}}<\lim_{x\to\infty}\frac{\sqrt[104]{x}}{\sqrt[105]{x}}<\lim_{x\to\infty}\sqrt[10920]{x} = \infty$$ Wich does not help me. Is there a way to solve this by comparsion? It would be better to me. If not, is there a way to fator these roots out?",,"['calculus', 'limits']"
81,Limit involving logarithms,Limit involving logarithms,,"I have to solve the limit, $ \displaystyle \lim_{x \to 0} \frac{ \log ((k+x)^{b} - (k-x)^{b} )}{\log x}$ where $k \in (0,1)$ and $b \in (0,1)$ are constant . I have tried using Taylor expansion but it does not work. Thank you.","I have to solve the limit, $ \displaystyle \lim_{x \to 0} \frac{ \log ((k+x)^{b} - (k-x)^{b} )}{\log x}$ where $k \in (0,1)$ and $b \in (0,1)$ are constant . I have tried using Taylor expansion but it does not work. Thank you.",,"['calculus', 'limits']"
82,How can $\lim\limits_{\theta\to0} \theta^{\frac1x -1} \tan(\theta^{\frac1x})$ be evaluated?,How can  be evaluated?,\lim\limits_{\theta\to0} \theta^{\frac1x -1} \tan(\theta^{\frac1x}),"$$ \lim_{\theta\to0} \theta^{\frac1x -1} \tan(\theta^{\frac1x}) \;\;\;\;\; (x > 1) $$ I've tried L'Hôpital's rule with $\theta$ in the denominator, but successive applications seems to only lead to more complex expressions. Interestingly, it seems that each application of L'Hôpital's rule will produce another limit to which L'Hôpital's is applicable. Can I use this fact somehow to analytically evaluate the limit?","$$ \lim_{\theta\to0} \theta^{\frac1x -1} \tan(\theta^{\frac1x}) \;\;\;\;\; (x > 1) $$ I've tried L'Hôpital's rule with $\theta$ in the denominator, but successive applications seems to only lead to more complex expressions. Interestingly, it seems that each application of L'Hôpital's rule will produce another limit to which L'Hôpital's is applicable. Can I use this fact somehow to analytically evaluate the limit?",,['limits']
83,Clarification Regarding evaluation of $\lim_{n\rightarrow \infty} n\sin(2\pi e n!)$- NBHM-$2009$,Clarification Regarding evaluation of - NBHM-,\lim_{n\rightarrow \infty} n\sin(2\pi e n!) 2009,"Question is to evaluate $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)$$ We have $e = 1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots$ $$n!e=n!(1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots)$$ $$=M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots$$  for some integer $M$. Now, for $2\pi e n!$ we have : $$2\pi e n!=2\pi (M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots)$$ $$=(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $\sin(2\pi e n!)$ We have : $$\sin(2\pi e n!)=\sin(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $n\sin(2\pi e n!)$ we have : $$n\sin(2\pi e n!)=n\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For large $n$ we would have $$\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots$$ I hope I can say that for large $n$ $$n\sin(2\pi e n!)=n(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\frac{2\pi}{1+\frac{1}{n}}+\dfrac{2\pi}{(1+\frac{1}{n})(n+2)} + \dfrac{2\pi}{(1+\frac{1}{n})(n+2)(n+3)} + \cdots)$$ As $n\rightarrow \infty$ we would have : $$\frac{2\pi}{1+0}+0+0+0+\dots=2\pi$$ So, $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)=2\pi$$ I would be thankful if some one can check what i have done is reasonably sufficient.... Thank you :)","Question is to evaluate $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)$$ We have $e = 1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots$ $$n!e=n!(1 + \dfrac1{1!} + \dfrac1{2!} + \dfrac1{3!} + \cdots + \dfrac1{n!} + \dfrac1{(n+1)!} + \dfrac1{(n+2)!} + \cdots)$$ $$=M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots$$  for some integer $M$. Now, for $2\pi e n!$ we have : $$2\pi e n!=2\pi (M+\dfrac1{n+1} + \dfrac1{(n+1)(n+2)} + \dfrac1{(n+1)(n+2)(n+3)} + \cdots)$$ $$=(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $\sin(2\pi e n!)$ We have : $$\sin(2\pi e n!)=\sin(2\pi M+\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For $n\sin(2\pi e n!)$ we have : $$n\sin(2\pi e n!)=n\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ For large $n$ we would have $$\sin(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots$$ I hope I can say that for large $n$ $$n\sin(2\pi e n!)=n(\dfrac{2\pi}{n+1} + \dfrac{2\pi}{(n+1)(n+2)} + \dfrac{2\pi}{(n+1)(n+2)(n+3)} + \cdots)$$ $$=\frac{2\pi}{1+\frac{1}{n}}+\dfrac{2\pi}{(1+\frac{1}{n})(n+2)} + \dfrac{2\pi}{(1+\frac{1}{n})(n+2)(n+3)} + \cdots)$$ As $n\rightarrow \infty$ we would have : $$\frac{2\pi}{1+0}+0+0+0+\dots=2\pi$$ So, $$\lim_{n\rightarrow \infty} n\sin(2\pi e n!)=2\pi$$ I would be thankful if some one can check what i have done is reasonably sufficient.... Thank you :)",,['real-analysis']
84,Find the value of : $\lim_{n\to\infty}\sqrt[n]{\frac{|\sin1|}1+\cdots+\frac{|\sin n|}{n}\ }$,Find the value of :,\lim_{n\to\infty}\sqrt[n]{\frac{|\sin1|}1+\cdots+\frac{|\sin n|}{n}\ },"I just read this question, about a limit very similar to that I am asking. I was confused because I was misreading the product dots in that question as plus signs. The provided, excellent answers are easy to follow, and in fact they allow me to realize about my mistake. Now I am curious about the limit $$\lim_{n\to\infty}\sqrt[n]{\frac{|\sin1|}1+\cdots+\frac{|\sin n|}{n}\ }\,.$$ I did not try anything, sorry, my only intuition is that the inner sum probably diverges, so its $n$-th root has indeterminate behavior","I just read this question, about a limit very similar to that I am asking. I was confused because I was misreading the product dots in that question as plus signs. The provided, excellent answers are easy to follow, and in fact they allow me to realize about my mistake. Now I am curious about the limit $$\lim_{n\to\infty}\sqrt[n]{\frac{|\sin1|}1+\cdots+\frac{|\sin n|}{n}\ }\,.$$ I did not try anything, sorry, my only intuition is that the inner sum probably diverges, so its $n$-th root has indeterminate behavior",,['limits']
85,Solution verification: $\lim\limits_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} = -1$,Solution verification:,\lim\limits_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} = -1,"I am trying to find the following limit $$\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2}$$ and I did the following steps: \begin{align} \require{cancel} &\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} \\ &\lim_{x\rightarrow \infty} \frac{x^2\left(\frac{\sqrt{x}}{x^2}+1\right)}{x^2\left(\frac{2x}{x^2}-1\right)} \\ & \lim_{x\rightarrow \infty} \frac{\cancel{x^2}\left(\frac{\sqrt{x}}{x^2}+1\right)}{\cancel{x^2}\left(\frac{2\cancel{x}}{\cancel{x^2}}-1\right)}\\ & \lim_{x\rightarrow \infty} \frac{\left(\frac{\sqrt{x}}{x^2}+1\right)}{\left(\frac{2}{x}-1\right)} \\ \end{align} Now here, the top portion goes to $0$ because the there is a larger power of $x$ in the denominator leaving only a $+1$ on top. On the bottom, the same thing happens, $\frac{2}{x}$ goes to $0$ and we left with $-1$ in the denominator. Therefore $$\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} = -1$$ Is my solution correct and did I take the right steps with the correct logic? Thanks!","I am trying to find the following limit $$\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2}$$ and I did the following steps: \begin{align} \require{cancel} &\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} \\ &\lim_{x\rightarrow \infty} \frac{x^2\left(\frac{\sqrt{x}}{x^2}+1\right)}{x^2\left(\frac{2x}{x^2}-1\right)} \\ & \lim_{x\rightarrow \infty} \frac{\cancel{x^2}\left(\frac{\sqrt{x}}{x^2}+1\right)}{\cancel{x^2}\left(\frac{2\cancel{x}}{\cancel{x^2}}-1\right)}\\ & \lim_{x\rightarrow \infty} \frac{\left(\frac{\sqrt{x}}{x^2}+1\right)}{\left(\frac{2}{x}-1\right)} \\ \end{align} Now here, the top portion goes to $0$ because the there is a larger power of $x$ in the denominator leaving only a $+1$ on top. On the bottom, the same thing happens, $\frac{2}{x}$ goes to $0$ and we left with $-1$ in the denominator. Therefore $$\lim_{x\rightarrow \infty} \frac{\sqrt{x}+x^2}{2x-x^2} = -1$$ Is my solution correct and did I take the right steps with the correct logic? Thanks!",,"['calculus', 'limits', 'solution-verification']"
86,$\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x)$,,\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x),"Let $f(x)=\exp(\sqrt{x})+\exp(-\sqrt{x})=2\cosh(\sqrt{x})$. How to calculate   $\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x)$ Using power series, we have $$f(x)=2\sum\limits_{k=0}^{\infty}\frac{x^k}{(2k)!}$$ so the $n$th derivative is: $$f^{(n)}(x)=2\sum\limits_{k=n}^{\infty}\frac{k!}{(k-n)!(2k)!}x^{k-n}$$ so $$\lim\limits_{x\to 0}f^{(n)}(x)=\frac{2n!}{(2n)!}$$ and hence $$\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x)=0$$ Can one do it by finding a closed form expression for $f^{(n)}(x)$?","Let $f(x)=\exp(\sqrt{x})+\exp(-\sqrt{x})=2\cosh(\sqrt{x})$. How to calculate   $\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x)$ Using power series, we have $$f(x)=2\sum\limits_{k=0}^{\infty}\frac{x^k}{(2k)!}$$ so the $n$th derivative is: $$f^{(n)}(x)=2\sum\limits_{k=n}^{\infty}\frac{k!}{(k-n)!(2k)!}x^{k-n}$$ so $$\lim\limits_{x\to 0}f^{(n)}(x)=\frac{2n!}{(2n)!}$$ and hence $$\lim\limits_{n\to\infty}\lim\limits_{x\to\ 0}f^{(n)}(x)=0$$ Can one do it by finding a closed form expression for $f^{(n)}(x)$?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
87,Find limits of a function with several variables,Find limits of a function with several variables,,"Does this $$\lim_{x,y,z\to(0,0,0)}\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ have a limit? My answer for this is Let f(x,y,z)=$$\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ then, $$\lim_{x\to0}{f(x,0,0)}=\lim_{x\to0}\frac{0}{x^2}=0$$ $$\lim_{x\to0}{f(x,x,0)}=\lim_{x\to0}\frac{x^2}{2x^2}=\frac{1}{2}$$ Since this two limit are not the same,$$\lim_{x,y,z\to(0,0,0)}\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ does not exist. I'm not sure if this justification is enough or correct.","Does this $$\lim_{x,y,z\to(0,0,0)}\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ have a limit? My answer for this is Let f(x,y,z)=$$\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ then, $$\lim_{x\to0}{f(x,0,0)}=\lim_{x\to0}\frac{0}{x^2}=0$$ $$\lim_{x\to0}{f(x,x,0)}=\lim_{x\to0}\frac{x^2}{2x^2}=\frac{1}{2}$$ Since this two limit are not the same,$$\lim_{x,y,z\to(0,0,0)}\frac{xy+2xz+yz}{{x^2+y^2+z^2}}$$ does not exist. I'm not sure if this justification is enough or correct.",,['limits']
88,Find a difficult limit,Find a difficult limit,,How can you prove $\lim_{n \rightarrow \infty} n\sum_{i=1}^{n-1}\frac{i(n-2)!}{(n-1-i)!n^{i+1}} = 1$?  I know that $\sum_{i=1}^{n}\frac{i (n!)}{(n-i)!n^{i}} = n$ but I can't see how to get from one to the other.,How can you prove $\lim_{n \rightarrow \infty} n\sum_{i=1}^{n-1}\frac{i(n-2)!}{(n-1-i)!n^{i+1}} = 1$?  I know that $\sum_{i=1}^{n}\frac{i (n!)}{(n-i)!n^{i}} = n$ but I can't see how to get from one to the other.,,['limits']
89,Is Infinity =Undefined? [closed],Is Infinity =Undefined? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Let's start with the equation $$\begin{equation}y =\frac 1{(x-1)} \end{equation}$$ where the positive and negative limit of $x$ at $1$ both approach $+∞$ , but at $x = 1$ , $y$ is undefined. I know this is because the denominator of the equation resolves to $0$ , but why does $y$ become undefined instead of $+∞$ ?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Let's start with the equation where the positive and negative limit of at both approach , but at , is undefined. I know this is because the denominator of the equation resolves to , but why does become undefined instead of ?",\begin{equation}y =\frac 1{(x-1)} \end{equation} x 1 +∞ x = 1 y 0 y +∞,['calculus']
90,"Limit of $\frac{\sin(x+y)}{x+y}$ as $(x,y) \to (0,0)$",Limit of  as,"\frac{\sin(x+y)}{x+y} (x,y) \to (0,0)","I want to prove that $\lim_{(x,y)\to (0,0)} \frac{\sin(x+y)}{x+y} = 1$ Is it sufficient to say that if $u = x+y$ then as $(x,y) \rightarrow (0,0)$ then $u \rightarrow 0$ and then evaluate $\lim_{u\to 0} \frac{\sin u}{u}$ which is 1 by L'Hôpital's rule? I feel that this is somehow ""cheating"" and I would really like to prove it in a more rigorous way, i.e., by using an $\epsilon$ - $\delta$ argument. I have tried for a long time to use the one variable version and prove that if $0 \lt \sqrt{x^2 + y^2} \lt \delta$ then somehow $0 \lt |x+y| \lt \delta$ and it would follow from the one variable case that $| \frac{\sin(x+y)}{x+y} - 1| \lt \epsilon$. However, because $|x+y| = 0$ when $y = -x$ I am not getting anywhere with this. Any input on this would be helpful :)","I want to prove that $\lim_{(x,y)\to (0,0)} \frac{\sin(x+y)}{x+y} = 1$ Is it sufficient to say that if $u = x+y$ then as $(x,y) \rightarrow (0,0)$ then $u \rightarrow 0$ and then evaluate $\lim_{u\to 0} \frac{\sin u}{u}$ which is 1 by L'Hôpital's rule? I feel that this is somehow ""cheating"" and I would really like to prove it in a more rigorous way, i.e., by using an $\epsilon$ - $\delta$ argument. I have tried for a long time to use the one variable version and prove that if $0 \lt \sqrt{x^2 + y^2} \lt \delta$ then somehow $0 \lt |x+y| \lt \delta$ and it would follow from the one variable case that $| \frac{\sin(x+y)}{x+y} - 1| \lt \epsilon$. However, because $|x+y| = 0$ when $y = -x$ I am not getting anywhere with this. Any input on this would be helpful :)",,"['calculus', 'limits']"
91,"How to find the limit of $\sin(f(x))$, given the graph of $f(x)$","How to find the limit of , given the graph of",\sin(f(x)) f(x),"The full question is uploaded here: https://i.sstatic.net/zwIlv.jpg Basically, given the graph shown in the image above, I thought that the limit of $\sin(f(x))$ would be $\sin(2)$, since the limit of just $f(x)$ is $2$. However, my teacher says that it is $\sin(3)$, since $f(x) = 3$ at that point. Can anyone explain why it is one and not the other? Also, if you could provide a source, that would be great, so I can show my teacher if I am right. Thanks.","The full question is uploaded here: https://i.sstatic.net/zwIlv.jpg Basically, given the graph shown in the image above, I thought that the limit of $\sin(f(x))$ would be $\sin(2)$, since the limit of just $f(x)$ is $2$. However, my teacher says that it is $\sin(3)$, since $f(x) = 3$ at that point. Can anyone explain why it is one and not the other? Also, if you could provide a source, that would be great, so I can show my teacher if I am right. Thanks.",,"['trigonometry', 'limits', 'graphing-functions']"
92,Limit (without series expansion and l'Hôpital's rule),Limit (without series expansion and l'Hôpital's rule),,$$\lim_{x \to \infty}\ln{\frac{x+\sqrt{x^2+1}}{x+\sqrt{x^2-1}}}\cdot \left(\ln{\frac{x+1}{x-1}}\right)^{-2}=\frac{1}{8}$$ Any suggestion to find this limit without series expansion and l'Hôpital's rule? Thanks and regards. Note: WolframAlpha confirms that the result is $\frac{1}{8}$.,$$\lim_{x \to \infty}\ln{\frac{x+\sqrt{x^2+1}}{x+\sqrt{x^2-1}}}\cdot \left(\ln{\frac{x+1}{x-1}}\right)^{-2}=\frac{1}{8}$$ Any suggestion to find this limit without series expansion and l'Hôpital's rule? Thanks and regards. Note: WolframAlpha confirms that the result is $\frac{1}{8}$.,,"['calculus', 'limits', 'logarithms', 'radicals', 'limits-without-lhopital']"
93,How to evaluate $\lim\limits_{x \rightarrow +\infty}{e^x (e - (1+\frac{1}{x} )^x)}$ without L'Hospital?,How to evaluate  without L'Hospital?,\lim\limits_{x \rightarrow +\infty}{e^x (e - (1+\frac{1}{x} )^x)},Using several times L'Hospital Rule I got $$\lim_{x \rightarrow +\infty}{e^x \left (e - \left(1+\dfrac{1}{x}\right )^x\right)} = +\infty.$$ Is it possible find this limit without L'Hospital?,Using several times L'Hospital Rule I got $$\lim_{x \rightarrow +\infty}{e^x \left (e - \left(1+\dfrac{1}{x}\right )^x\right)} = +\infty.$$ Is it possible find this limit without L'Hospital?,,"['calculus', 'limits', 'limits-without-lhopital']"
94,Prove that: $\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' $,Prove that:,\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' ,"I conjecture that in some specific conditions a differentiating function gives the following equality: $$\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' $$ However, I'm not sure yet what exactly those conditions are in order to precisely know where I may apply this rule or not. If you wanna take a look over my posted problem here you'll immediately notice that this rule applies for that case. I really appreciate if you help me clarify this.","I conjecture that in some specific conditions a differentiating function gives the following equality: $$\lim_{n\to\infty} f(n+1) - f(n) = \lim_{x\to\infty} (f(x))' $$ However, I'm not sure yet what exactly those conditions are in order to precisely know where I may apply this rule or not. If you wanna take a look over my posted problem here you'll immediately notice that this rule applies for that case. I really appreciate if you help me clarify this.",,"['calculus', 'real-analysis', 'limits']"
95,Limit $\lim_{x\to \infty} \left(\frac{f(x+1)}{f(x)}\right)^x$,Limit,\lim_{x\to \infty} \left(\frac{f(x+1)}{f(x)}\right)^x,"Can someone please explain to me how to solve this? According to my book the result should be $e^4$, however I cannot understand the proposed solution. Can someone please take the time to walk me through it? $$f : \mathcal R \mapsto \mathbb R, f(x) = (x - 2)(x - 3)(x - 4)(x - 5)$$ $$\lim_{x\to \infty} \left(\frac{f(x+1)}{f(x)}\right)^x$$ Edit: Partial solution. I can get up to the following point. From here onwards however I do not know how to continue in order to get $e^4$. It appears to me that the result is $1^\infty = 1$ at this point (but that's not the case according to my book): $$\lim_{x\to \infty} \left(\frac{x-1}{x-5}\right)^x$$ Edit 2: Solution given by my book. $$\lim_{x\to \infty} \left(1+\frac{4}{x-5}\right)^x$$ $$ = \lim_{x\to \infty} \left(\left(1+\frac{4}{x-5}\right)^\frac{x - 5}{4}\right)^{\frac{4}{x - 5}x}$$ $$ = e^{\lim_{x\to \infty} \frac{4x}{x - 5}} = e^4$$","Can someone please explain to me how to solve this? According to my book the result should be $e^4$, however I cannot understand the proposed solution. Can someone please take the time to walk me through it? $$f : \mathcal R \mapsto \mathbb R, f(x) = (x - 2)(x - 3)(x - 4)(x - 5)$$ $$\lim_{x\to \infty} \left(\frac{f(x+1)}{f(x)}\right)^x$$ Edit: Partial solution. I can get up to the following point. From here onwards however I do not know how to continue in order to get $e^4$. It appears to me that the result is $1^\infty = 1$ at this point (but that's not the case according to my book): $$\lim_{x\to \infty} \left(\frac{x-1}{x-5}\right)^x$$ Edit 2: Solution given by my book. $$\lim_{x\to \infty} \left(1+\frac{4}{x-5}\right)^x$$ $$ = \lim_{x\to \infty} \left(\left(1+\frac{4}{x-5}\right)^\frac{x - 5}{4}\right)^{\frac{4}{x - 5}x}$$ $$ = e^{\lim_{x\to \infty} \frac{4x}{x - 5}} = e^4$$",,"['calculus', 'limits']"
96,Why does $\lim_{x\to0} \left(1+\frac1x\right)^x=1$? [closed],Why does ? [closed],\lim_{x\to0} \left(1+\frac1x\right)^x=1,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 months ago . Improve this question Why does $\lim_{x\to0} \left(1+\frac1x\right)^x=1$ ? Beware that I am NOT asking about $ \lim_{x\to\infty} (1+\frac{1}{x})^x $ , which I know equals to $e$ . When you draw it in GeoGebra or WolframAlpha, it tells us that this is true. But WHY? Any help (or better, proof) is welcome.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 months ago . Improve this question Why does ? Beware that I am NOT asking about , which I know equals to . When you draw it in GeoGebra or WolframAlpha, it tells us that this is true. But WHY? Any help (or better, proof) is welcome.",\lim_{x\to0} \left(1+\frac1x\right)^x=1  \lim_{x\to\infty} (1+\frac{1}{x})^x  e,['limits']
97,Solution-Verification：Evaluate $\lim\limits_{n \to \infty}\left(\sum_{k=1}^n\frac{1}{\sqrt{n^2+n+k}}\right)^n$.,Solution-Verification：Evaluate .,\lim\limits_{n \to \infty}\left(\sum_{k=1}^n\frac{1}{\sqrt{n^2+n+k}}\right)^n,"Here is a proof posted in a Chinese website. Since $f_n(x):=\dfrac{1}{\sqrt{n^2+n+x}}$ is convex on $x\in(0,+\infty),$ by discrete Hadamard inequality , it holds that $$f_n\left(\frac{n+1}{2}\right)\le\frac{1}{n}\sum_{k=1}^nf_n(k)\le \frac{f_n(n)+f_n(1)}{2}.\\$$ Therefore $$\frac{n}{\sqrt{n^2+n+\frac{n+1}{2}}}\le\sum_{k=1}^nf_n(k)\le \frac{n}{\sqrt{n^2+n+\frac{n}{2}}},$$ which implies $$\left(\frac{n}{\sqrt{n^2+n+\frac{n+1}{2}}}\right)^n\le\left(\sum_{k=1}^nf_n(k)\right)^n\le \left(\frac{n}{\sqrt{n^2+n+\frac{n}{2}}}\right)^n.$$ The limits of both sides are $e^{-3/4}$ as $n \to \infty$ . By the squeezing theorem, $$\lim_{n \to \infty}\left(\sum_{k=1}^nf_n(k)\right)^n=e^{-3/4}.$$ This solution is likely to be elegant, but I wonder whether it is correct or not. What is discrete Hadamard inequality?","Here is a proof posted in a Chinese website. Since is convex on by discrete Hadamard inequality , it holds that Therefore which implies The limits of both sides are as . By the squeezing theorem, This solution is likely to be elegant, but I wonder whether it is correct or not. What is discrete Hadamard inequality?","f_n(x):=\dfrac{1}{\sqrt{n^2+n+x}} x\in(0,+\infty), f_n\left(\frac{n+1}{2}\right)\le\frac{1}{n}\sum_{k=1}^nf_n(k)\le \frac{f_n(n)+f_n(1)}{2}.\\ \frac{n}{\sqrt{n^2+n+\frac{n+1}{2}}}\le\sum_{k=1}^nf_n(k)\le \frac{n}{\sqrt{n^2+n+\frac{n}{2}}}, \left(\frac{n}{\sqrt{n^2+n+\frac{n+1}{2}}}\right)^n\le\left(\sum_{k=1}^nf_n(k)\right)^n\le \left(\frac{n}{\sqrt{n^2+n+\frac{n}{2}}}\right)^n. e^{-3/4} n \to \infty \lim_{n \to \infty}\left(\sum_{k=1}^nf_n(k)\right)^n=e^{-3/4}.","['calculus', 'limits', 'solution-verification']"
98,Limit of an integral involving a general $f(x)$,Limit of an integral involving a general,f(x),"Let $f:[0,1]\to\Bbb R$ be a continuous function. Calculate $$\lim_{{n\to\infty}} \frac{\sqrt{n}}{\ln{n}} \int_0^1 \left( \sqrt{n+1+x+x^2+x^3+\ldots+x^{n-1}} - \sqrt{n} \right) f(x) \, dx.$$ I have absolutely no clue how to solve this kind of limit; I tried rationalization, simplifying it using the GP formula and then trying to break it into different integrals, and using Newton Leibniz rule (and L'Hopital's rule) to differentiate the inner term wrt $n.$ Can anyone please help me out with this?","Let be a continuous function. Calculate I have absolutely no clue how to solve this kind of limit; I tried rationalization, simplifying it using the GP formula and then trying to break it into different integrals, and using Newton Leibniz rule (and L'Hopital's rule) to differentiate the inner term wrt Can anyone please help me out with this?","f:[0,1]\to\Bbb R \lim_{{n\to\infty}} \frac{\sqrt{n}}{\ln{n}} \int_0^1 \left( \sqrt{n+1+x+x^2+x^3+\ldots+x^{n-1}} - \sqrt{n} \right) f(x) \, dx. n.","['real-analysis', 'calculus', 'limits', 'definite-integrals']"
99,Can we apply $\dfrac{ \sin ( u ) }{ u } = 1$ when ${ u }$ approaches $0$ even when there are other variables in the sin function?,Can we apply  when  approaches  even when there are other variables in the sin function?,\dfrac{ \sin ( u ) }{ u } = 1 { u } 0,"I have an equation: $$   \displaystyle\lim_{ δx   \rightarrow  0  }   \dfrac{  \sin \left(\left(  x+ \dfrac{ δx  }{ 2  } \right)      δx \right) }{  \left( x+ \dfrac{ δx  }{ 2  }    \right)  δx  }       $$ The solution says that it is equal to $1$ because of the $ \dfrac{  \sin (  u   )    }{ u  }   =  1 $ when ${ u }$ approaches $0$ limit theorem. But I don't understand how that can be applied here, since the equation has both $δx$ and $x$ , so how can the theorem still be applicable?","I have an equation: The solution says that it is equal to because of the when approaches limit theorem. But I don't understand how that can be applied here, since the equation has both and , so how can the theorem still be applicable?","
  \displaystyle\lim_{ δx   \rightarrow  0  }   \dfrac{  \sin \left(\left(  x+ \dfrac{ δx  }{ 2  } \right)      δx \right) }{  \left( x+ \dfrac{ δx  }{ 2  }    \right)  δx  }      
 1  \dfrac{  \sin (  u   )    }{ u  }   =  1  { u } 0 δx x","['calculus', 'limits', 'derivatives', 'trigonometry']"
