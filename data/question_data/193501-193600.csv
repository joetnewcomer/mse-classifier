,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find the derivative of $f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy.$,Find the derivative of,f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy.,"Problem statement: Find the derivative of  $$f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy$$ and find an ordinary differential equation that $f$ solves. Find the solution to this ordinary differential equation to determine an explicit value for $f$. My attempt: Normally, to find $f'(x)$ in this situation, if this was a calculus problem, I would write: $$\frac{d}{dx} f(x) = \frac{d}{dx}\int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy = \frac{d}{dx}\left(\int_{-\infty}^0\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{e^{-xy^2}}{1+y^2}\ dy\right)$$ and then I would differentiate under the integral sign: $$f'(x) = \int_{-\infty}^0\frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy,$$ which leaves me with $$f'(x) = \int_{-\infty}^0 \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy + \int_{0}^\infty \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy.$$ However, this is actually an analysis problem, and as such I am having a really hard time justifying all of these steps. I have already proved that if $F(x) = \int_a^x f(y) \ dy$, then $F$ is absolutely continuous, and therefore the derivative exists a.e. Now, I also know from the FCT that if $f$ is integrable, $F'(x) = f(y)$ a.e. But I still can't quite figure out how to justify moving the derivative in the integral sign, particularly when I have infinite bounds, which I do. Any help would be much appreciated here!","Problem statement: Find the derivative of  $$f(x) = \int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy$$ and find an ordinary differential equation that $f$ solves. Find the solution to this ordinary differential equation to determine an explicit value for $f$. My attempt: Normally, to find $f'(x)$ in this situation, if this was a calculus problem, I would write: $$\frac{d}{dx} f(x) = \frac{d}{dx}\int_{-\infty}^\infty \frac{e^{-xy^2}}{1+y^2}\ dy = \frac{d}{dx}\left(\int_{-\infty}^0\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{e^{-xy^2}}{1+y^2}\ dy\right)$$ and then I would differentiate under the integral sign: $$f'(x) = \int_{-\infty}^0\frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy + \int_0^\infty \frac{\partial}{\partial x}\frac{e^{-xy^2}}{1+y^2}\ dy,$$ which leaves me with $$f'(x) = \int_{-\infty}^0 \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy + \int_{0}^\infty \frac{-y^2e^{-x(y^2+1)}}{1+y^2}\ dy.$$ However, this is actually an analysis problem, and as such I am having a really hard time justifying all of these steps. I have already proved that if $F(x) = \int_a^x f(y) \ dy$, then $F$ is absolutely continuous, and therefore the derivative exists a.e. Now, I also know from the FCT that if $f$ is integrable, $F'(x) = f(y)$ a.e. But I still can't quite figure out how to justify moving the derivative in the integral sign, particularly when I have infinite bounds, which I do. Any help would be much appreciated here!",,"['real-analysis', 'derivatives', 'lebesgue-integral']"
1,Regarding differentiability at $x =0$ [closed],Regarding differentiability at  [closed],x =0,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f : \Bbb R \to \Bbb R$ be defined by $f(x) = \begin{cases} x^2 \text{ if $x$ is rational}\\ x^4 \text{ if $x$ is irrational} \end{cases}$ Is $f$ differentiable at $x = 0$? How do I begin ?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f : \Bbb R \to \Bbb R$ be defined by $f(x) = \begin{cases} x^2 \text{ if $x$ is rational}\\ x^4 \text{ if $x$ is irrational} \end{cases}$ Is $f$ differentiable at $x = 0$? How do I begin ?",,"['real-analysis', 'derivatives']"
2,Constructing Polynomial Function from Set of Points and Slopes,Constructing Polynomial Function from Set of Points and Slopes,,"I only have a basic knowledge of calculus but I would like to know if it's possible to, given a set of points each with their own slopes, construct the simplest (or any) polynomial function that perfectly fits the given information. In other words, a polynomial $P(x)$ would need to take on the value of each given ordinate at each given abscissa, and it's derivative, $P'(x)$ would need to take on the value of each given slope and each given abscissa. I'm thinking that it might not be possible because if there's a series of points  that lie on a straight line among many other, randomly distributed ones, the derivative $P'(x)$ would have a segment of constant value in the middle of the chaotic curvature surrounding it. I don't think that polynomial functions can have this kind of behavior, can they? If it's indeed impossible to do this, is there any other way to construct a curve that fits the given data?","I only have a basic knowledge of calculus but I would like to know if it's possible to, given a set of points each with their own slopes, construct the simplest (or any) polynomial function that perfectly fits the given information. In other words, a polynomial $P(x)$ would need to take on the value of each given ordinate at each given abscissa, and it's derivative, $P'(x)$ would need to take on the value of each given slope and each given abscissa. I'm thinking that it might not be possible because if there's a series of points  that lie on a straight line among many other, randomly distributed ones, the derivative $P'(x)$ would have a segment of constant value in the middle of the chaotic curvature surrounding it. I don't think that polynomial functions can have this kind of behavior, can they? If it's indeed impossible to do this, is there any other way to construct a curve that fits the given data?",,"['calculus', 'derivatives', 'polynomials', 'interpolation', 'taylor-expansion']"
3,Is this Function differentiable and continuous at x=0? [closed],Is this Function differentiable and continuous at x=0? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Is $f(x)$ continuous and differentiable at $x = 0$ ? $$f(x) = x(\sqrt{x} - \sqrt{x+1})$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Is $f(x)$ continuous and differentiable at $x = 0$ ? $$f(x) = x(\sqrt{x} - \sqrt{x+1})$$",,"['calculus', 'derivatives', 'continuity']"
4,Finding the derivative to nth order [closed],Finding the derivative to nth order [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How to find $$\frac{d^ny}{dx^n}$$  of $$y=\frac{x}{lnx-1}$$ Appreciated advance","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How to find $$\frac{d^ny}{dx^n}$$  of $$y=\frac{x}{lnx-1}$$ Appreciated advance",,['derivatives']
5,Derivative of $(\ln x)^e$ [duplicate],Derivative of  [duplicate],(\ln x)^e,"This question already has answers here : ""What if"" math joke: the derivative of $\ln(x)^e$ (5 answers) Closed 9 years ago . In Randall Munroe's What If , he says that ""if you want to be mean to first-year calculus students, you can ask them to take the derivative of $(lnx)^e$"" He says, as I would expect, that the result ""looks like it should be $1$ or something, but it's not."" Why is this? And what's the actual answer?","This question already has answers here : ""What if"" math joke: the derivative of $\ln(x)^e$ (5 answers) Closed 9 years ago . In Randall Munroe's What If , he says that ""if you want to be mean to first-year calculus students, you can ask them to take the derivative of $(lnx)^e$"" He says, as I would expect, that the result ""looks like it should be $1$ or something, but it's not."" Why is this? And what's the actual answer?",,"['derivatives', 'logarithms']"
6,Prove that $\exists \delta>0$ such that $0<|x-y|<\delta \Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon$,Prove that  such that,\exists \delta>0 0<|x-y|<\delta \Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon,"Let $f: I \rightarrow \mathbb R$ be differentiable at $c\in I$. Prove that for every $\varepsilon>, \exists \delta>0$ such that $0<|x-y|<\delta$ and $a\leq x\leq c \leq y\leq b\Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon$ My attempt: $f: I \rightarrow \mathbb R$ is differentiable at $c\in I$, i.e. $f'(c)$ exists. So, $0<|x-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(x)-f(c)}{x-c}-f'(c)\Big|<\varepsilon$ And $0<|y-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(y)-f(c)}{y-c}-f'(c)\Big|<\varepsilon$ I'm stuck here. Please help!","Let $f: I \rightarrow \mathbb R$ be differentiable at $c\in I$. Prove that for every $\varepsilon>, \exists \delta>0$ such that $0<|x-y|<\delta$ and $a\leq x\leq c \leq y\leq b\Rightarrow\Big|\dfrac{f(x)-f(y)}{x-y}-f'(c)\Big|<\varepsilon$ My attempt: $f: I \rightarrow \mathbb R$ is differentiable at $c\in I$, i.e. $f'(c)$ exists. So, $0<|x-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(x)-f(c)}{x-c}-f'(c)\Big|<\varepsilon$ And $0<|y-c|<\dfrac{\delta}{2} \Rightarrow\Big|\dfrac{f(y)-f(c)}{y-c}-f'(c)\Big|<\varepsilon$ I'm stuck here. Please help!",,"['real-analysis', 'derivatives']"
7,Determining the rate of change of a radius as a sphere loses volume,Determining the rate of change of a radius as a sphere loses volume,,"Problem: A spherical balloon leaks $0.2\mathrm m^3 / \mathrm{min}$. How fast does the radius of the balloon decrease the moment the radius is $0.5\mathrm m$? My progress: Since we're dealing with the rate of change of the volume, I set up a function for volume wrt. the radius, which would be $$V(r) = \frac43\pi r^3$$ Then I differentiated it, and got $$V'(r) = 4\pi r^2$$ Now, I don't know quite how to use the first piece of information in the problem. Am I going to need to find a $V(t)$ here? As far as I can tell, we can say that $$V'(t) = -0.2$$ but how do I piece all this together? (Assuming I'm right so far.) Any help appreciated!","Problem: A spherical balloon leaks $0.2\mathrm m^3 / \mathrm{min}$. How fast does the radius of the balloon decrease the moment the radius is $0.5\mathrm m$? My progress: Since we're dealing with the rate of change of the volume, I set up a function for volume wrt. the radius, which would be $$V(r) = \frac43\pi r^3$$ Then I differentiated it, and got $$V'(r) = 4\pi r^2$$ Now, I don't know quite how to use the first piece of information in the problem. Am I going to need to find a $V(t)$ here? As far as I can tell, we can say that $$V'(t) = -0.2$$ but how do I piece all this together? (Assuming I'm right so far.) Any help appreciated!",,"['calculus', 'derivatives', 'volume']"
8,"Prove $f'(0)=0$, if $|f(x)|≤x^2$","Prove , if",f'(0)=0 |f(x)|≤x^2,"Let $f:(-a,a) \longrightarrow R$, $a>0$. Such that  $$ |f(x)|≤x^2 $$ What I did was taking out the module bars so I get $-x^2≤f(x)≤x^2$ and I see that at $x=0$ the function must be zero. I see why f'(0) must equal zero at that point,  but I have no idea on how to prove it.","Let $f:(-a,a) \longrightarrow R$, $a>0$. Such that  $$ |f(x)|≤x^2 $$ What I did was taking out the module bars so I get $-x^2≤f(x)≤x^2$ and I see that at $x=0$ the function must be zero. I see why f'(0) must equal zero at that point,  but I have no idea on how to prove it.",,['derivatives']
9,Differentiate w.r.t a matrix,Differentiate w.r.t a matrix,,"If I define $S=H+ae^T/n$, where $a_i=1$ if $h_{ij}=0$ for all $j$,  $a_i=0$ otherwise and $e$ is a column of 1's. How to do the differentiation w.r.t $h_{ij}$? I know $a$ is somehow related to $h_{ij}$ but I am not sure how to deal with that.","If I define $S=H+ae^T/n$, where $a_i=1$ if $h_{ij}=0$ for all $j$,  $a_i=0$ otherwise and $e$ is a column of 1's. How to do the differentiation w.r.t $h_{ij}$? I know $a$ is somehow related to $h_{ij}$ but I am not sure how to deal with that.",,"['linear-algebra', 'derivatives']"
10,$n$th derivative of $\frac 1{f(x)}$,th derivative of,n \frac 1{f(x)},"Is there a closed-form solution for $\frac {d^n}{dx^n}\frac 1{f(x)}$? I've looked at the first five derivatives in search of some pattern, but I can't identify anything strong enough to give a closed formula.","Is there a closed-form solution for $\frac {d^n}{dx^n}\frac 1{f(x)}$? I've looked at the first five derivatives in search of some pattern, but I can't identify anything strong enough to give a closed formula.",,"['calculus', 'derivatives']"
11,Can this special case happen when working with L'Hopitals rule?,Can this special case happen when working with L'Hopitals rule?,,"I am using this version of L'Hopital's rule Assume that $\lim_{x \rightarrow a}f(x)=\lim_{x \rightarrow a}g(x)=0$, and that the limit-value $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$ exists (could be $\infty$  or $-\infty$). Then the limit  value $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ also exsits, and $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}=\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$. I have two questions: When we have said that $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$, exists, then we have also said that $g'(x)$ is not zero around $a$ , so this does not create a problem? This is my main question: Could there be a special case, where the hypothesis of the rule is satisfied, but for every neighbourhood around $a$ , there is an $x$ such that $g(x)=0$, and so that $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ is not defined, and hence the rule stated as it is, is wrong? Because the rule says that the limit value of $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ exists if the hypothesis is satisfied? (The reason I am suspecting this is what I write below about Cauchy's Mean Value Theorem). On Wikipedia: http://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule they assume that $g'(x)$ is not zero. But they do not say anything about $g(x)$, how do we know that there are not infinitely many points around $a$ , where $g$ is zero? The reason I am asking is that they use Cauchy's mean value theorem in my book for the proof. http://en.wikipedia.org/wiki/Mean_value_theorem#Cauchy.27s_mean_value_theorem But when using the form with fractions, they have to assume that the denominator is not zero? It doesn't say that if $g'(c)$ is non-zero then $g(b)-g(a)$ is nonzero, we are only allowed to go to the fraction part of the theorem if we know that both is non-zero?","I am using this version of L'Hopital's rule Assume that $\lim_{x \rightarrow a}f(x)=\lim_{x \rightarrow a}g(x)=0$, and that the limit-value $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$ exists (could be $\infty$  or $-\infty$). Then the limit  value $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ also exsits, and $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}=\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$. I have two questions: When we have said that $\lim_{x \rightarrow a} \frac{f'(x)}{g'(x)}$, exists, then we have also said that $g'(x)$ is not zero around $a$ , so this does not create a problem? This is my main question: Could there be a special case, where the hypothesis of the rule is satisfied, but for every neighbourhood around $a$ , there is an $x$ such that $g(x)=0$, and so that $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ is not defined, and hence the rule stated as it is, is wrong? Because the rule says that the limit value of $\lim_{x \rightarrow a} \frac{f(x)}{g(x)}$ exists if the hypothesis is satisfied? (The reason I am suspecting this is what I write below about Cauchy's Mean Value Theorem). On Wikipedia: http://en.wikipedia.org/wiki/L%27H%C3%B4pital%27s_rule they assume that $g'(x)$ is not zero. But they do not say anything about $g(x)$, how do we know that there are not infinitely many points around $a$ , where $g$ is zero? The reason I am asking is that they use Cauchy's mean value theorem in my book for the proof. http://en.wikipedia.org/wiki/Mean_value_theorem#Cauchy.27s_mean_value_theorem But when using the form with fractions, they have to assume that the denominator is not zero? It doesn't say that if $g'(c)$ is non-zero then $g(b)-g(a)$ is nonzero, we are only allowed to go to the fraction part of the theorem if we know that both is non-zero?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
12,Integral inequality $\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0$,Integral inequality,\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0,"Let $f(0) = 0$ and $0<f'(x)\leq1$ for all $x \geq0$, then prove: $$\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0$$ The hint I was given was ""differentiate, factor and differentiate again"" but I'm not sure where to start","Let $f(0) = 0$ and $0<f'(x)\leq1$ for all $x \geq0$, then prove: $$\int_0^x{f(t)^3 dt \leq \left( \int_0^x f(t) dt\right)^2} :\forall x>0$$ The hint I was given was ""differentiate, factor and differentiate again"" but I'm not sure where to start",,"['calculus', 'real-analysis', 'integration', 'inequality', 'derivatives']"
13,"Prove that a function diverges to infinity if its derivative has a positive lower bound for all $x$ on a closed ray $\left[ a,\infty \right)$.",Prove that a function diverges to infinity if its derivative has a positive lower bound for all  on a closed ray .,"x \left[ a,\infty \right)","Let $f$ be differentiable on $\left[ a,\infty  \right)$. Prove that if $\exists m>0\,\forall x\in \left[ a,\infty  \right)\,f'\left( x \right)\ge m~$, then $\lim\limits_{x\to\infty}\,f\left( x \right)=\infty $. I began by using the average value theorem (Lagrange's theorem) to prove that $f$ is monotonously increasing, however I still need to prove that $f$ is not bounded, to reach the conclusion that it diverges to infinity, but am not sure how to proceed on that.","Let $f$ be differentiable on $\left[ a,\infty  \right)$. Prove that if $\exists m>0\,\forall x\in \left[ a,\infty  \right)\,f'\left( x \right)\ge m~$, then $\lim\limits_{x\to\infty}\,f\left( x \right)=\infty $. I began by using the average value theorem (Lagrange's theorem) to prove that $f$ is monotonously increasing, however I still need to prove that $f$ is not bounded, to reach the conclusion that it diverges to infinity, but am not sure how to proceed on that.",,['derivatives']
14,Derivative of a continuous function.,Derivative of a continuous function.,,"Let $g:R\to R$ be a continuous function with $g(x+y)=g(x)+g(y), \forall x,y\in R.$ Find $\frac{dg}{dx},$ if it exist.","Let $g:R\to R$ be a continuous function with $g(x+y)=g(x)+g(y), \forall x,y\in R.$ Find $\frac{dg}{dx},$ if it exist.",,"['real-analysis', 'derivatives']"
15,What is the derivative of the integral of a function?,What is the derivative of the integral of a function?,,"Is this correct ? $$ \frac{d}{dt} \left( \int_0^t \phi(t)dt \right) = \phi(t) $$ If not, how can I recover $$ \phi(t) $$ knowing only $$ \int_0^t \phi(t)dt $$ ?","Is this correct ? $$ \frac{d}{dt} \left( \int_0^t \phi(t)dt \right) = \phi(t) $$ If not, how can I recover $$ \phi(t) $$ knowing only $$ \int_0^t \phi(t)dt $$ ?",,"['integration', 'derivatives']"
16,"If a differentiable function approaches $-\infty$ as a limit from the positive side, must its derivative simultaneously approach $\infty$?","If a differentiable function approaches  as a limit from the positive side, must its derivative simultaneously approach ?",-\infty \infty,"Can we say that if $g: (0, \infty)\rightarrow\Bbb{R}$ is a differentiable function and $\lim \limits_{x \to 0+}g(x)= -\infty$, then  $\lim \limits_{x \to 0+}g'(x)= +\infty$ is always true? I think the statement is true, I tried many functions, one of them is $-1/x$ for example, and I always get a true result. if its not true then I need a negative example, and if not, i really need some help to prove this formally.","Can we say that if $g: (0, \infty)\rightarrow\Bbb{R}$ is a differentiable function and $\lim \limits_{x \to 0+}g(x)= -\infty$, then  $\lim \limits_{x \to 0+}g'(x)= +\infty$ is always true? I think the statement is true, I tried many functions, one of them is $-1/x$ for example, and I always get a true result. if its not true then I need a negative example, and if not, i really need some help to prove this formally.",,"['calculus', 'real-analysis', 'derivatives']"
17,12th order derivative using Leibniz,12th order derivative using Leibniz,,I don't fully understand the rule of Leibniz and I'm trying to find the 12th order derivative of: $x\cos  \left(x\right)$ How do I find this using the Leibniz rule?,I don't fully understand the rule of Leibniz and I'm trying to find the 12th order derivative of: How do I find this using the Leibniz rule?,x\cos  \left(x\right),['derivatives']
18,Prove an identity using differential calculus to a problem connected to fluids,Prove an identity using differential calculus to a problem connected to fluids,,"Euler's equation for a incompressible inviscid fluid is $\displaystyle \frac{\partial \textbf{v}_t}{\partial t}+(\textbf{v}_t \cdot \nabla)\textbf{v}_t=-\nabla p_t$ where $\textbf{v}_t=\textbf{v}_t(r)$ is the fluid velocity and $p_t=p_t(r)$ is the pressure. Let $\nu_t(r)$ be the $1$-form associated to $\textbf{v}_t(r)$, ie, $\displaystyle \nu_t=\sum_{i=1}^{3}v_t^idr^i$ Show that $\displaystyle \frac{\partial \nu_t}{\partial t}+L_{\textbf{v}_t}\nu_t=-d(p_t-\frac{1}{2}v_t^2)$ where $v_t^2=\textbf{v}_t \cdot \textbf{v}_t$. HINT: If $\omega=\omega_i dx^i$ is a $1$-form and $\mathbb{X}=X^ie_{(i)}$ a vector field on $\mathbb{R}^n$ then $\displaystyle L_{\mathbb{X}}\omega=(\frac{\partial X^j}{\partial x^i}\omega_j + X^j \frac{\partial \omega^i}{\partial x^j})dx^i$. I am having serious problems attempting this question but I believe once going this question shouldnt be too bad. I believe it is ideal to start with the LHS and try and work to the RHS. I am unsure on how to express the first equation in a more differential form like form and so be able to use it in the question. UPDATE 2: So I get so far $$\begin{align} \frac{\partial \nu_t}{\partial t}+L_{\textbf{v}_t}\nu_t &= \frac{\partial \nu_t}{\partial t}+\left(\frac{\partial v^j}{\partial r^i}v_j + v^j \frac{\partial v_i}{\partial r^j}\right)dr^i. \end{align}  $$ working backwards, $$ \begin{align} \left(-\frac{\partial p}{\partial r^i}+v^j\frac{\partial v^j}{\partial r^i} \right)dr^i &= \frac{\partial}{\partial r^i}(-p_t+\frac{1}{2}v^2)dr^i \\ &=  -d(p_t-\frac{1}{2}v^2) \end{align} $$ Somehow I need to connect the two parts. Please answer if possible using basic differential calculus I am not familiar with using tensors, and Riemmannian manifolds, tangent spaces and bundles... I am only covering a basic course on differential calculus. Sorry for the inconvenience to those who looked at the question earlier. I believe my question should indicate the standard I am working at.","Euler's equation for a incompressible inviscid fluid is $\displaystyle \frac{\partial \textbf{v}_t}{\partial t}+(\textbf{v}_t \cdot \nabla)\textbf{v}_t=-\nabla p_t$ where $\textbf{v}_t=\textbf{v}_t(r)$ is the fluid velocity and $p_t=p_t(r)$ is the pressure. Let $\nu_t(r)$ be the $1$-form associated to $\textbf{v}_t(r)$, ie, $\displaystyle \nu_t=\sum_{i=1}^{3}v_t^idr^i$ Show that $\displaystyle \frac{\partial \nu_t}{\partial t}+L_{\textbf{v}_t}\nu_t=-d(p_t-\frac{1}{2}v_t^2)$ where $v_t^2=\textbf{v}_t \cdot \textbf{v}_t$. HINT: If $\omega=\omega_i dx^i$ is a $1$-form and $\mathbb{X}=X^ie_{(i)}$ a vector field on $\mathbb{R}^n$ then $\displaystyle L_{\mathbb{X}}\omega=(\frac{\partial X^j}{\partial x^i}\omega_j + X^j \frac{\partial \omega^i}{\partial x^j})dx^i$. I am having serious problems attempting this question but I believe once going this question shouldnt be too bad. I believe it is ideal to start with the LHS and try and work to the RHS. I am unsure on how to express the first equation in a more differential form like form and so be able to use it in the question. UPDATE 2: So I get so far $$\begin{align} \frac{\partial \nu_t}{\partial t}+L_{\textbf{v}_t}\nu_t &= \frac{\partial \nu_t}{\partial t}+\left(\frac{\partial v^j}{\partial r^i}v_j + v^j \frac{\partial v_i}{\partial r^j}\right)dr^i. \end{align}  $$ working backwards, $$ \begin{align} \left(-\frac{\partial p}{\partial r^i}+v^j\frac{\partial v^j}{\partial r^i} \right)dr^i &= \frac{\partial}{\partial r^i}(-p_t+\frac{1}{2}v^2)dr^i \\ &=  -d(p_t-\frac{1}{2}v^2) \end{align} $$ Somehow I need to connect the two parts. Please answer if possible using basic differential calculus I am not familiar with using tensors, and Riemmannian manifolds, tangent spaces and bundles... I am only covering a basic course on differential calculus. Sorry for the inconvenience to those who looked at the question earlier. I believe my question should indicate the standard I am working at.",,"['calculus', 'differential-geometry', 'derivatives', 'lie-algebras', 'fluid-dynamics']"
19,Differentiability of a function satisfying a condition on a bounded interval,Differentiability of a function satisfying a condition on a bounded interval,,Let  $\displaystyle f(x)$ satisfies the condition $|f(x)|\leq 1-\cos x$ on the interval $-\frac{\pi}{2}\leq x\leq \frac{\pi}{2}$. Prove that $f(x)$ is differentiable at $x=0$ and find $f^\prime(0)$. My idea: $\lim_{x\to 0} |\frac{f(x)-f(0)}{x}|\leq \lim_{x\to 0} \frac{|f(x)|+|f(0)|}{x}\leq \lim_{x\to 0}\frac{1-\cos x }{x}\leq \lim_{x\to 0}\frac{2 }{x}$ but i m stack in here,Let  $\displaystyle f(x)$ satisfies the condition $|f(x)|\leq 1-\cos x$ on the interval $-\frac{\pi}{2}\leq x\leq \frac{\pi}{2}$. Prove that $f(x)$ is differentiable at $x=0$ and find $f^\prime(0)$. My idea: $\lim_{x\to 0} |\frac{f(x)-f(0)}{x}|\leq \lim_{x\to 0} \frac{|f(x)|+|f(0)|}{x}\leq \lim_{x\to 0}\frac{1-\cos x }{x}\leq \lim_{x\to 0}\frac{2 }{x}$ but i m stack in here,,"['calculus', 'real-analysis', 'derivatives']"
20,Graphing $\frac{x^2-x+1}{2(x-1)}$,Graphing,\frac{x^2-x+1}{2(x-1)},"I need to graph $$\frac{x^2-x+1}{2(x-1)}$$ So I reduced it to make the derivative easy: $$f(x) = \frac{x(x-1)+1}{2(x-1)} = \frac{x}{2} + \frac{1}{2(x-1)}\\f'(x) = \frac{1}{2} - \frac{1}{2(x-1)^2}$$ which has roots $x = 0, x = 2$ But the derivative of the original function and the one I made are different. I can't see why. The two have the same roots, but I can't see what i'm doing wrong. The concavity was easy to find by the derivative I made, but i don't know what's happening","I need to graph So I reduced it to make the derivative easy: which has roots But the derivative of the original function and the one I made are different. I can't see why. The two have the same roots, but I can't see what i'm doing wrong. The concavity was easy to find by the derivative I made, but i don't know what's happening","\frac{x^2-x+1}{2(x-1)} f(x) = \frac{x(x-1)+1}{2(x-1)} = \frac{x}{2} + \frac{1}{2(x-1)}\\f'(x) = \frac{1}{2} - \frac{1}{2(x-1)^2} x = 0, x = 2","['calculus', 'derivatives', 'polynomials']"
21,Differentiability of monotonic functions,Differentiability of monotonic functions,,"If a function is monotonic on set E. Is f differentiable almost everywhere? I have proved for case E closed bounded or open intervals, hence all open sets. But in general I am not able to figure it out. And this I know that derivative of f at isolated points is not defined(or is infinity). But there can be atmost countable no. of isolated points. So what we can say about general E whether it contains isolated points or not.","If a function is monotonic on set E. Is f differentiable almost everywhere? I have proved for case E closed bounded or open intervals, hence all open sets. But in general I am not able to figure it out. And this I know that derivative of f at isolated points is not defined(or is infinity). But there can be atmost countable no. of isolated points. So what we can say about general E whether it contains isolated points or not.",,"['real-analysis', 'derivatives']"
22,Log base 10 not equal to log while differentiating?,Log base 10 not equal to log while differentiating?,,"I was looking at sample questions from my textbook and I came across something interesting that I need a little help understanding The question was to find the derivative of: $\log_{10} (\frac{7}{\sqrt {x+3}})$ My solution was: $\frac{1}{2(x+3)}$ My problem is that when I later tried to check my answer online, it resulted in: $\frac {1}{2(x+3)*\log(10)}$ So this led me to believe that, in the case of deriving with logs, $\log_{10}$ is not the same thing as $\log$, yet in every other scenario it is the same thing. My question is, are these two cases actually different, is one of the results wrong, or are both results the same with the second one being a simple expansion (which I don't think it is but I could be wrong). Any help will be great, this is a really interesting case. Thank you!","I was looking at sample questions from my textbook and I came across something interesting that I need a little help understanding The question was to find the derivative of: $\log_{10} (\frac{7}{\sqrt {x+3}})$ My solution was: $\frac{1}{2(x+3)}$ My problem is that when I later tried to check my answer online, it resulted in: $\frac {1}{2(x+3)*\log(10)}$ So this led me to believe that, in the case of deriving with logs, $\log_{10}$ is not the same thing as $\log$, yet in every other scenario it is the same thing. My question is, are these two cases actually different, is one of the results wrong, or are both results the same with the second one being a simple expansion (which I don't think it is but I could be wrong). Any help will be great, this is a really interesting case. Thank you!",,"['calculus', 'derivatives', 'logarithms']"
23,Maximise the volume of an open triangular prism,Maximise the volume of an open triangular prism,,"An open container is to be constructed out of 200 square centimeters of cardboard. The two end pieces are equilateral triangles. The open top is a horizontal rectangle. Find the lengths of the sides of the triangle for maximum volume of the container. So effectively we have an equilateral triangular prism of length $L$. I first found an equation for $L$:  $$L=\frac{200-\sqrt{3}x^2}{2x}$$ I then used $V = \frac{1}{2}x^2Lsin60$ to get the volume, substituting for $L$ to get the volume in terms of $x$. Differentiating with respect to $x$, setting equal to zero, and solving for $x$ gave me value of $x=6.2$ $$\frac{dv}{dx} = 50\sqrt{0.75} - \frac{9x^2}{8} = 0$$ x=6.204 But this answer was marked wrong by my teacher. Where had I gone wrong?","An open container is to be constructed out of 200 square centimeters of cardboard. The two end pieces are equilateral triangles. The open top is a horizontal rectangle. Find the lengths of the sides of the triangle for maximum volume of the container. So effectively we have an equilateral triangular prism of length $L$. I first found an equation for $L$:  $$L=\frac{200-\sqrt{3}x^2}{2x}$$ I then used $V = \frac{1}{2}x^2Lsin60$ to get the volume, substituting for $L$ to get the volume in terms of $x$. Differentiating with respect to $x$, setting equal to zero, and solving for $x$ gave me value of $x=6.2$ $$\frac{dv}{dx} = 50\sqrt{0.75} - \frac{9x^2}{8} = 0$$ x=6.204 But this answer was marked wrong by my teacher. Where had I gone wrong?",,"['calculus', 'derivatives', 'optimization']"
24,Evaluating $\int x^n e^{x}dx$,Evaluating,\int x^n e^{x}dx,"I consider, for $n=0,1,2,...$,  $$ u_n(x)=\int x^n e^{x}dx.$$ I've performed an integration by parts giving $$ u_n(x)=nx^{n-1} e^{x}-nu_{n-1}(x).$$ I'm looking for a closed form. Thank you.","I consider, for $n=0,1,2,...$,  $$ u_n(x)=\int x^n e^{x}dx.$$ I've performed an integration by parts giving $$ u_n(x)=nx^{n-1} e^{x}-nu_{n-1}(x).$$ I'm looking for a closed form. Thank you.",,"['calculus', 'integration', 'derivatives']"
25,Question about left and right derivative.,Question about left and right derivative.,,Let $f(x):\mathbb{R}\rightarrow\mathbb{R}$ be a function such that $\forall x\in\mathbb{R}$ there exist: $$f'_+(x)=\lim_{\delta\rightarrow 0^+}\frac{f(x+\delta)-f(x)}{\delta}$$ $$f'_-(x)=\lim_{\delta\rightarrow 0^-}\frac{f(x+\delta)-f(x)}{\delta}$$ and $\forall x:f'_-(x)=2f'_+(x)$. How to prove that $f$ is constant. I'm really in nowhere with this kind of problem. EDIT: Actually I'm having an idea of using similar technique as in https://math.stackexchange.com/a/79617/161212 but it's still getting nowhere.,Let $f(x):\mathbb{R}\rightarrow\mathbb{R}$ be a function such that $\forall x\in\mathbb{R}$ there exist: $$f'_+(x)=\lim_{\delta\rightarrow 0^+}\frac{f(x+\delta)-f(x)}{\delta}$$ $$f'_-(x)=\lim_{\delta\rightarrow 0^-}\frac{f(x+\delta)-f(x)}{\delta}$$ and $\forall x:f'_-(x)=2f'_+(x)$. How to prove that $f$ is constant. I'm really in nowhere with this kind of problem. EDIT: Actually I'm having an idea of using similar technique as in https://math.stackexchange.com/a/79617/161212 but it's still getting nowhere.,,"['real-analysis', 'derivatives']"
26,Part of proof that $d^2\omega=0$,Part of proof that,d^2\omega=0,"The following comes from the proof in differentiable manifolds that $d^2\omega=0$. Let $f$ belong to the set of $0$-forms. From definition I have that $\displaystyle df = \frac{\partial f}{\partial x^j}dx^j$ Then from the definition for $d$ of a one-form, apparently we have that $\displaystyle d(df)=d\Big(\frac{\partial f}{\partial x^j}\Big) \wedge dx^j$. I cannot see how this can been derived. I tried $\displaystyle d(df)=d\Big(\frac{\partial f}{\partial x^j} dx^j \Big)$. You then use some kind of product rule? The definition I have been given is if $\displaystyle \omega = \frac{1}{k!} \omega_{i_1 ... i_k} dx^{i_1}\wedge...\wedge dx^{i_k}$ then its derivative is $\displaystyle d\omega = \frac{1}{k!} d\omega_{i_1\cdots i_k} \wedge dx^{i_1}\wedge\cdots\wedge dx^{i_k}$","The following comes from the proof in differentiable manifolds that $d^2\omega=0$. Let $f$ belong to the set of $0$-forms. From definition I have that $\displaystyle df = \frac{\partial f}{\partial x^j}dx^j$ Then from the definition for $d$ of a one-form, apparently we have that $\displaystyle d(df)=d\Big(\frac{\partial f}{\partial x^j}\Big) \wedge dx^j$. I cannot see how this can been derived. I tried $\displaystyle d(df)=d\Big(\frac{\partial f}{\partial x^j} dx^j \Big)$. You then use some kind of product rule? The definition I have been given is if $\displaystyle \omega = \frac{1}{k!} \omega_{i_1 ... i_k} dx^{i_1}\wedge...\wedge dx^{i_k}$ then its derivative is $\displaystyle d\omega = \frac{1}{k!} d\omega_{i_1\cdots i_k} \wedge dx^{i_1}\wedge\cdots\wedge dx^{i_k}$",,"['differential-geometry', 'derivatives', 'manifolds', 'exterior-algebra']"
27,How to check for convexity of function that is not everywhere differentiable?,How to check for convexity of function that is not everywhere differentiable?,,I have a question. I have just been introduced to the subject of convex sets and convex functions.  I read this in wikipedia that a practical test for convexity is -  to check whether the 2nd derivative ( Hessian matrix ) of a continuous differentiable function in the interior of the convex set is non-negative ( positive semi-definite ). So how to check for the convexity of functions like $f(x)=|x|$ which is differentiable at all points except at $x=0$ which coincidentally is actually its global minimum? Thanks all for answering.,I have a question. I have just been introduced to the subject of convex sets and convex functions.  I read this in wikipedia that a practical test for convexity is -  to check whether the 2nd derivative ( Hessian matrix ) of a continuous differentiable function in the interior of the convex set is non-negative ( positive semi-definite ). So how to check for the convexity of functions like $f(x)=|x|$ which is differentiable at all points except at $x=0$ which coincidentally is actually its global minimum? Thanks all for answering.,,"['analysis', 'derivatives', 'convex-optimization']"
28,Finding the second derivative of an infinite series,Finding the second derivative of an infinite series,,"I'm asked to find the 2nd derivative of  $$f(x)=-2x+\frac{2x^3}{3!}-\frac{2x^5}{5!}+\cdots+(-1)^{n+1}\frac{2x^{n+1}}{(2n+1)!}+\cdots=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n+1}2x^{2n+1} }{(2n+1)!}$$ Applying the power rule to $f(x)$, I find I can simplify the coefficient, since $\frac{(2n+1)(2n)}{(2n-1)!}=\frac{1}{(2n-1)!}$. Also, because the first term of $f''(x)$ is positive, the $(-1)^{n+1}$ changes to $(-1)^{n}$, which leaves me with: $$f''(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^n2x^{2n-1} }{(2n-1)!}$$ However, the answer given on the homework solution is $\sum \limits_{n=0}^\infty \frac{(-1)^n2x^{2n+1} }{(2n+1)!}$. I don't see how I can get from my answer to the given solution.","I'm asked to find the 2nd derivative of  $$f(x)=-2x+\frac{2x^3}{3!}-\frac{2x^5}{5!}+\cdots+(-1)^{n+1}\frac{2x^{n+1}}{(2n+1)!}+\cdots=\sum \limits_{n=0}^{\infty} \frac{(-1)^{n+1}2x^{2n+1} }{(2n+1)!}$$ Applying the power rule to $f(x)$, I find I can simplify the coefficient, since $\frac{(2n+1)(2n)}{(2n-1)!}=\frac{1}{(2n-1)!}$. Also, because the first term of $f''(x)$ is positive, the $(-1)^{n+1}$ changes to $(-1)^{n}$, which leaves me with: $$f''(x)=\sum \limits_{n=0}^{\infty} \frac{(-1)^n2x^{2n-1} }{(2n-1)!}$$ However, the answer given on the homework solution is $\sum \limits_{n=0}^\infty \frac{(-1)^n2x^{2n+1} }{(2n+1)!}$. I don't see how I can get from my answer to the given solution.",,"['calculus', 'sequences-and-series', 'derivatives']"
29,Zero point when $f'(x)\gt c$,Zero point when,f'(x)\gt c,"Suppose that the function $f:\mathbb R\to\mathbb R$ is continuously differentiable and that there is a positive number $c$ such that $f'(x)\ge c$ for all points $x$ in $\mathbb R$. Prove that there is exactly one number $x_0$ at which $f(x_0)=0$. This question border me since it seems easy and obvious. I can prove the uniqueness of $x_0$ (since by mean value thm, if there are two zero points, there must be a point such that $f'(x)=0$). However, I cannot prove the existance of such $x_0$.","Suppose that the function $f:\mathbb R\to\mathbb R$ is continuously differentiable and that there is a positive number $c$ such that $f'(x)\ge c$ for all points $x$ in $\mathbb R$. Prove that there is exactly one number $x_0$ at which $f(x_0)=0$. This question border me since it seems easy and obvious. I can prove the uniqueness of $x_0$ (since by mean value thm, if there are two zero points, there must be a point such that $f'(x)=0$). However, I cannot prove the existance of such $x_0$.",,"['analysis', 'derivatives']"
30,Non integer derivative of $1/p(x)$,Non integer derivative of,1/p(x),"I need to find the $k$'th derivative of $1/p(x)$, where $p(x)$ is a polynomial and $k\in\mathbb{R}$ It dosen't have to be an explicit formula, an algorithm which finds a formula for some $k$ is fine.","I need to find the $k$'th derivative of $1/p(x)$, where $p(x)$ is a polynomial and $k\in\mathbb{R}$ It dosen't have to be an explicit formula, an algorithm which finds a formula for some $k$ is fine.",,"['calculus', 'derivatives', 'fractional-calculus']"
31,How to find derivative of an integral of this type,How to find derivative of an integral of this type,,"$$f(x) = \int _x^{e^x}\:\left(\sin t^2\right)\,dt$$ How to find the derivative $f'(x)$ Attempt: $\sin (e^{x^2})  e^x$","$$f(x) = \int _x^{e^x}\:\left(\sin t^2\right)\,dt$$ How to find the derivative $f'(x)$ Attempt: $\sin (e^{x^2})  e^x$",,"['integration', 'derivatives']"
32,Using the Chain Rule to prove trig derivatives,Using the Chain Rule to prove trig derivatives,,"I'm having trouble with this problem, I'm not sure how to tackle it and I was wondering if somebody could set me on the right path. The problem is as follows: Use the Chain Rule to show that if $\theta$ is measured in degrees, then $$\frac{d}{d\theta}(\sin\theta^{\circ}) = \frac{\pi}{180^{\circ}}\cos\theta^{\circ}$$ Thanks!","I'm having trouble with this problem, I'm not sure how to tackle it and I was wondering if somebody could set me on the right path. The problem is as follows: Use the Chain Rule to show that if $\theta$ is measured in degrees, then $$\frac{d}{d\theta}(\sin\theta^{\circ}) = \frac{\pi}{180^{\circ}}\cos\theta^{\circ}$$ Thanks!",,"['calculus', 'algebra-precalculus', 'trigonometry', 'derivatives']"
33,Finding $\dfrac{d^nx}{dy^n}$,Finding,\dfrac{d^nx}{dy^n},"If $y$ is a function of $x$, then what is the relation between $\dfrac{d^nx}{dy^n}$ and $\dfrac{d^ny}{dx^n}$? If we were to talk about $\dfrac{dy}{dx}$ and $\dfrac{dx}{dy}$, then they both are reciprocals of each other. We cannot simply take the reciprocal of $\dfrac{d^ny}{dx^n}$, can we?","If $y$ is a function of $x$, then what is the relation between $\dfrac{d^nx}{dy^n}$ and $\dfrac{d^ny}{dx^n}$? If we were to talk about $\dfrac{dy}{dx}$ and $\dfrac{dx}{dy}$, then they both are reciprocals of each other. We cannot simply take the reciprocal of $\dfrac{d^ny}{dx^n}$, can we?",,"['calculus', 'derivatives']"
34,Derivative and integral of the abs function,Derivative and integral of the abs function,,"I would like to ask about how to find the derivative of the absolute value function for example : $\dfrac{d}{dx}|x-3|$ My try:$$ f(x)=|x-3|\\ f(x) = \begin{cases} x-3, & \text{if }x \geq3 \\ 3-x, & \text{if }x \leq3 \end{cases} $$ So: $$f'(x) = \begin{cases} 1, & \text{if }x \geq3 \\ -1, & \text{if }x \leq3 \end{cases} $$ What is wrong with this approcah?.Please clarify. Also I want also like to find out how to integrate the absolute value function. Thanks","I would like to ask about how to find the derivative of the absolute value function for example : $\dfrac{d}{dx}|x-3|$ My try:$$ f(x)=|x-3|\\ f(x) = \begin{cases} x-3, & \text{if }x \geq3 \\ 3-x, & \text{if }x \leq3 \end{cases} $$ So: $$f'(x) = \begin{cases} 1, & \text{if }x \geq3 \\ -1, & \text{if }x \leq3 \end{cases} $$ What is wrong with this approcah?.Please clarify. Also I want also like to find out how to integrate the absolute value function. Thanks",,"['calculus', 'analysis', 'derivatives', 'absolute-value']"
35,How to resolve multiply differentiation function algorithms?,How to resolve multiply differentiation function algorithms?,,My simple function is  $f(x)=\frac{1}{2}e^{-x}\sin(2x)$; Can I resolve for multiply differentiation  $f^{(n)}=?$ algorithm? Thx for answer.,My simple function is  $f(x)=\frac{1}{2}e^{-x}\sin(2x)$; Can I resolve for multiply differentiation  $f^{(n)}=?$ algorithm? Thx for answer.,,"['trigonometry', 'derivatives']"
36,Local minimum implies local convexity?,Local minimum implies local convexity?,,"Consider a real function $f$, and suppose it has a local minimum at $a\in \mathbb R$. It typically looks like What hypotheses can be added to $f$ so that there is some $\epsilon >0$ such that $f$ is convex over $(a-\epsilon,a+\epsilon)$ ? The motivation for this question is intuition, but I can't find any valid criterion.","Consider a real function $f$, and suppose it has a local minimum at $a\in \mathbb R$. It typically looks like What hypotheses can be added to $f$ so that there is some $\epsilon >0$ such that $f$ is convex over $(a-\epsilon,a+\epsilon)$ ? The motivation for this question is intuition, but I can't find any valid criterion.",,"['real-analysis', 'derivatives', 'optimization']"
37,if $f$ is differentiable at $x_0$ then the limit exists,if  is differentiable at  then the limit exists,f x_0,"Let $f$ differentiable at $x_0$. Show that the following limit exists $$ \lim_{h\rightarrow0} \frac{f(x_0+h)-f(x_0-h)}{h}$$ If $f$ is differetiable at $x_0$ then it's one-sided derivative exists and equal. Hence, $$ \lim_{h\rightarrow0^+} \frac{f(x_0 +h)-f(x_0)}{h} = \lim_{h\rightarrow0^-} \frac{f(x_0  +h)-f(x_0)}{h} $$ Now, technically if I do a simple arithmetic I can get the answer (move the right limit and ""join"" them). Moreover, the limit exists and equals $0$. But, I cannot just join them because they're not the same. What should I do?","Let $f$ differentiable at $x_0$. Show that the following limit exists $$ \lim_{h\rightarrow0} \frac{f(x_0+h)-f(x_0-h)}{h}$$ If $f$ is differetiable at $x_0$ then it's one-sided derivative exists and equal. Hence, $$ \lim_{h\rightarrow0^+} \frac{f(x_0 +h)-f(x_0)}{h} = \lim_{h\rightarrow0^-} \frac{f(x_0  +h)-f(x_0)}{h} $$ Now, technically if I do a simple arithmetic I can get the answer (move the right limit and ""join"" them). Moreover, the limit exists and equals $0$. But, I cannot just join them because they're not the same. What should I do?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
38,Pointwise derivative,Pointwise derivative,,"Please I am struggling to find a proper definition of a pointwise derivative and also what is the difference between a pointwise derivative and the ""classical"" derivative. Can someone please point me to a good reference or define it themselves. Thank you in advance.","Please I am struggling to find a proper definition of a pointwise derivative and also what is the difference between a pointwise derivative and the ""classical"" derivative. Can someone please point me to a good reference or define it themselves. Thank you in advance.",,['real-analysis']
39,prove that a function whose derivative is bounded also bounded,prove that a function whose derivative is bounded also bounded,,"I got this problem: Let $f$ be a differentiable function on an open interval $(a,b)$ such that $f'$ (the derivative of $f$) is bounded on $(a,b)$ (meaning there exist $0<M$ such that $\forall x\in(a,b), |f'(x)|\leq M$), Prove that $f$ is also bounded on $(a,b)$. I tried to prove it but wasn't able to proceed. Thanks.","I got this problem: Let $f$ be a differentiable function on an open interval $(a,b)$ such that $f'$ (the derivative of $f$) is bounded on $(a,b)$ (meaning there exist $0<M$ such that $\forall x\in(a,b), |f'(x)|\leq M$), Prove that $f$ is also bounded on $(a,b)$. I tried to prove it but wasn't able to proceed. Thanks.",,"['calculus', 'derivatives']"
40,Derive an equation for derivative of ln x,Derive an equation for derivative of ln x,,$\frac{d}{dx}e^x = e^x$ use this fact together with the definition of the natural log $\ln x$ as the inverse of the function of $e^x$ to derive an equation for the derivative of $\ln x$.,$\frac{d}{dx}e^x = e^x$ use this fact together with the definition of the natural log $\ln x$ as the inverse of the function of $e^x$ to derive an equation for the derivative of $\ln x$.,,"['calculus', 'derivatives', 'logarithms']"
41,"Show that if $f(x)= \sum\limits_{i=0}^n a_i x^i$ and $a_0+\frac{a_1}{2}+\ldots+\frac{a_n}{n+1}=0$, then there is an $x \in (0,1)$ with $f(x)=0$","Show that if  and , then there is an  with","f(x)= \sum\limits_{i=0}^n a_i x^i a_0+\frac{a_1}{2}+\ldots+\frac{a_n}{n+1}=0 x \in (0,1) f(x)=0","Show that if $f(x)= \sum\limits_{i=0}^n a_i x^i$ and $a_0+\dfrac{a_1}{2}+\ldots+\dfrac{a_n}{n+1}=0$, then there is an $x \in (0,1)$ with $f(x)=0.$","Show that if $f(x)= \sum\limits_{i=0}^n a_i x^i$ and $a_0+\dfrac{a_1}{2}+\ldots+\dfrac{a_n}{n+1}=0$, then there is an $x \in (0,1)$ with $f(x)=0.$",,"['real-analysis', 'derivatives']"
42,Finding the derivative of $f(x) = 2x^2 + x - 3$ at $x = 4$.,Finding the derivative of  at .,f(x) = 2x^2 + x - 3 x = 4,"I am learning about derivatives and differentiating and I came across this; $f(x) = 2x^2 + x - 3$ at $x = 4$ This is as far as I get; $$\frac{2(x + h)^2 + (x + h) - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2(x^2 + 2xh + h^2) + x + h - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2x^2 + 4xh + 2h^2 + x + h - 3 - 2x^2 - x + 3}{ h }$$ The answer I get is $$\frac{4xh + 2h^2 + h}{ h }$$ How can I reduce that further, and am I doing this correctly? Because the answers they show are $f'(x) = 4x+3$ $f '(x) = 2x-3$ $f '(x) = 4x+1$ $f '(x) = 4x-a$ I think I am doing something wrong or not reducing it correctly. I would really appreciate some guidance asap. Thanks!","I am learning about derivatives and differentiating and I came across this; $f(x) = 2x^2 + x - 3$ at $x = 4$ This is as far as I get; $$\frac{2(x + h)^2 + (x + h) - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2(x^2 + 2xh + h^2) + x + h - 3 - (2x^2 - x + 3)}{ h }$$ $$\frac{2x^2 + 4xh + 2h^2 + x + h - 3 - 2x^2 - x + 3}{ h }$$ The answer I get is $$\frac{4xh + 2h^2 + h}{ h }$$ How can I reduce that further, and am I doing this correctly? Because the answers they show are $f'(x) = 4x+3$ $f '(x) = 2x-3$ $f '(x) = 4x+1$ $f '(x) = 4x-a$ I think I am doing something wrong or not reducing it correctly. I would really appreciate some guidance asap. Thanks!",,"['calculus', 'derivatives']"
43,What is the difference between standard derivative and partial derivative?,What is the difference between standard derivative and partial derivative?,,"This is actually a very old question that now I have to face it again and look for answer of it. Suppose $f:\mathbb{R}^n\to \mathbb{R}, f(x_1,x_2,...,x_n)=y$ is a function. What is the difference between: $\frac{\partial f}{\partial x_i}$ $\frac{df}{dx_i}$ if this means anything at all? I am reading this book and the following passage is part of the book: ...it would be appropriate to introduce a scaled time $\tau$ via $$\tau=\epsilon^2 t$$ and regard $u$ as depending both on $t$ and $\tau$, and having no   explicit dependence on $\epsilon$; $t$ and $\tau$ will be treated as   mutually independent. Correspondingly, the time differentiation should   be transformed as $$\frac{d}{dt}\to\frac{\partial}{\partial t}+\epsilon^2  \frac{\partial}{\partial \tau} $$ Where $u=X-X_0$ and $X_0$ is a stable answer for following differential equation: $$\frac{dX}{dt}=F(X)$$","This is actually a very old question that now I have to face it again and look for answer of it. Suppose $f:\mathbb{R}^n\to \mathbb{R}, f(x_1,x_2,...,x_n)=y$ is a function. What is the difference between: $\frac{\partial f}{\partial x_i}$ $\frac{df}{dx_i}$ if this means anything at all? I am reading this book and the following passage is part of the book: ...it would be appropriate to introduce a scaled time $\tau$ via $$\tau=\epsilon^2 t$$ and regard $u$ as depending both on $t$ and $\tau$, and having no   explicit dependence on $\epsilon$; $t$ and $\tau$ will be treated as   mutually independent. Correspondingly, the time differentiation should   be transformed as $$\frac{d}{dt}\to\frac{\partial}{\partial t}+\epsilon^2  \frac{\partial}{\partial \tau} $$ Where $u=X-X_0$ and $X_0$ is a stable answer for following differential equation: $$\frac{dX}{dt}=F(X)$$",,"['calculus', 'derivatives']"
44,evaluate $\int_{0}^{1}\frac{x-1}{\ln x}dx$ [duplicate],evaluate  [duplicate],\int_{0}^{1}\frac{x-1}{\ln x}dx,"This question already has answers here : Showing that $ \int_{0}^{1} \frac{x-1}{\ln(x)} \mathrm dx=\ln2 $ (3 answers) Closed 10 years ago . evaluate $\int_{0}^{1}\frac{x-1}{\ln x}dx$,where x is real. Approach: The suggestion is to differentiate $H(m)=\int_{0}^{1}\frac{x^{m}-1}{\ln x}dx$. This leads to $$H(m)'=m\int_{0}^{1}\frac{x^{m-1}}{\ln x}dx, $$ $$H(m)''=\int_{0}^{1}\frac{x^{m-1}}{\ln x}dx+m(m-1)\int_{0}^{1} \frac{x^{m-2}}{\ln x}dx$$ ...","This question already has answers here : Showing that $ \int_{0}^{1} \frac{x-1}{\ln(x)} \mathrm dx=\ln2 $ (3 answers) Closed 10 years ago . evaluate $\int_{0}^{1}\frac{x-1}{\ln x}dx$,where x is real. Approach: The suggestion is to differentiate $H(m)=\int_{0}^{1}\frac{x^{m}-1}{\ln x}dx$. This leads to $$H(m)'=m\int_{0}^{1}\frac{x^{m-1}}{\ln x}dx, $$ $$H(m)''=\int_{0}^{1}\frac{x^{m-1}}{\ln x}dx+m(m-1)\int_{0}^{1} \frac{x^{m-2}}{\ln x}dx$$ ...",,"['calculus', 'derivatives']"
45,If a function has no critical points then how can I find where the function is increasing or decreasing?,If a function has no critical points then how can I find where the function is increasing or decreasing?,,"Recently, I have discovered some problems that have no critical points i.e. $$f'(x) \not = 0$$ For example, if we have the exponential $e^x$ divided by some other function squared i.e. $(x+2)^2$. Then this function will never equal zero. So how can I find where the function is increasing/decreasing? Thanks!","Recently, I have discovered some problems that have no critical points i.e. $$f'(x) \not = 0$$ For example, if we have the exponential $e^x$ divided by some other function squared i.e. $(x+2)^2$. Then this function will never equal zero. So how can I find where the function is increasing/decreasing? Thanks!",,"['calculus', 'derivatives']"
46,Differential calculus: word problem,Differential calculus: word problem,,The derivation of $$y=xy^2$$ is $$\frac{\mathrm dy}{\mathrm dx} =  y^2 + x\cdot 2y \frac{\mathrm dy}{\mathrm dx}.$$ Why we are are putting $\frac{\mathrm dy}{\mathrm dx}$ if we have already derived $y^2$ and its power becomes its coefficient then why $\frac{\mathrm dy}{\mathrm dx}$? can any one explain it.,The derivation of $$y=xy^2$$ is $$\frac{\mathrm dy}{\mathrm dx} =  y^2 + x\cdot 2y \frac{\mathrm dy}{\mathrm dx}.$$ Why we are are putting $\frac{\mathrm dy}{\mathrm dx}$ if we have already derived $y^2$ and its power becomes its coefficient then why $\frac{\mathrm dy}{\mathrm dx}$? can any one explain it.,,"['calculus', 'derivatives']"
47,"find the derivative $\displaystyle \frac{d}{dx}\int^a_x \tan(\tan(t))\,dt =$ [closed]",find the derivative  [closed],"\displaystyle \frac{d}{dx}\int^a_x \tan(\tan(t))\,dt =","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Find the derivative: $\displaystyle \frac{d}{dx}\int^a_x \tan(\tan(t))\,dt = $ I tried to take the derivative but I am getting the wrong answer every time.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Find the derivative: $\displaystyle \frac{d}{dx}\int^a_x \tan(\tan(t))\,dt = $ I tried to take the derivative but I am getting the wrong answer every time.",,['derivatives']
48,Use the definition of derivative to find $f'(x)$ for $f(x) = x^{1/2}$.,Use the definition of derivative to find  for .,f'(x) f(x) = x^{1/2},"This is an analysis question so we use the definition that the derivative of a function is, $$\lim_{x\to c} \frac{f(x)-f(c)}{x-c}$$ But I'm not really sure if I should just continue to say that $x=c$ for now as the second $x$ perhaps as if $f(x) = \sqrt c$. Obviously if we leave $x$ as is, $(f(x)-f(x)) = 0$ and the lim is $0$, but this is obviously not the case since $f'(x) = \frac{1}{2}\sqrt x$","This is an analysis question so we use the definition that the derivative of a function is, $$\lim_{x\to c} \frac{f(x)-f(c)}{x-c}$$ But I'm not really sure if I should just continue to say that $x=c$ for now as the second $x$ perhaps as if $f(x) = \sqrt c$. Obviously if we leave $x$ as is, $(f(x)-f(x)) = 0$ and the lim is $0$, but this is obviously not the case since $f'(x) = \frac{1}{2}\sqrt x$",,"['real-analysis', 'derivatives', 'radicals']"
49,Proving a 2nd order Mean-Value theorem [closed],Proving a 2nd order Mean-Value theorem [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Let $f\in C^1([a,b])$ have 2nd-order derivative in $(a,b)$. Prove that there exists $c\in (a,b)$ such that   $$f(b)-2 f\left(\frac{a+b}{2}\right)+f(a)=\frac{1}{4} (b-a)^2 f''(c)$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Let $f\in C^1([a,b])$ have 2nd-order derivative in $(a,b)$. Prove that there exists $c\in (a,b)$ such that   $$f(b)-2 f\left(\frac{a+b}{2}\right)+f(a)=\frac{1}{4} (b-a)^2 f''(c)$$",,"['calculus', 'derivatives']"
50,How do they find this derivative?,How do they find this derivative?,,"Given: $\ f(x)= {24 \over x^2+12} $ Their derivative: $\ {dy \over dx} = {-48x \over (x^2+12)^2} $ Yet if I try the quotient rule to solve I get the following: $$  {dy \over dx} = {(x^2+12) - 2x(24) \over (x^2+12)^2} $$ $$  = {(x^2-48x+12) \over (x^2+12)^2} $$ I also tried the product rule and ALSO received a different answer, yet somewhat closer to their solution: $$ f(x)= {24 \over x^2+12} $$ $$  = 24(x^2+12)^{-1} $$ $$  {dy \over dx} = {(x^2+12)^{-1}  - (x^2+12)^{-2}(2x)(24)} $$ $$  = {-48x \over (x^2+12)^3} $$ Am I doing something wrong? Why are my answers different even though I am using the given rules properly(I hope)? Why is their derivative different from what I am getting?","Given: $\ f(x)= {24 \over x^2+12} $ Their derivative: $\ {dy \over dx} = {-48x \over (x^2+12)^2} $ Yet if I try the quotient rule to solve I get the following: $$  {dy \over dx} = {(x^2+12) - 2x(24) \over (x^2+12)^2} $$ $$  = {(x^2-48x+12) \over (x^2+12)^2} $$ I also tried the product rule and ALSO received a different answer, yet somewhat closer to their solution: $$ f(x)= {24 \over x^2+12} $$ $$  = 24(x^2+12)^{-1} $$ $$  {dy \over dx} = {(x^2+12)^{-1}  - (x^2+12)^{-2}(2x)(24)} $$ $$  = {-48x \over (x^2+12)^3} $$ Am I doing something wrong? Why are my answers different even though I am using the given rules properly(I hope)? Why is their derivative different from what I am getting?",,"['calculus', 'derivatives']"
51,How to prove $\frac{\ln x}{\sqrt x}$ is decreasing.,How to prove  is decreasing.,\frac{\ln x}{\sqrt x},"I need to prove this before I can use the Integral Test to determine if the series is is converging or diverging. My series is from [1,infinity). I tried plugging in number and the function seems to increase, so I tried the derivative and now I'm stuck. Thank you, everyone! I've got it now.  The original problem was to determine if the series converges or diverges and why. Series was from n=1 to infinity: (ln n)/(sqrt n)","I need to prove this before I can use the Integral Test to determine if the series is is converging or diverging. My series is from [1,infinity). I tried plugging in number and the function seems to increase, so I tried the derivative and now I'm stuck. Thank you, everyone! I've got it now.  The original problem was to determine if the series converges or diverges and why. Series was from n=1 to infinity: (ln n)/(sqrt n)",,"['calculus', 'sequences-and-series', 'derivatives']"
52,Are one of these directions true $ \lim_{x\to\infty} f'(x)=0 $ $\Longleftrightarrow$ $ \lim_{x\to\infty} f(x)=L $ (L is finite),Are one of these directions true    (L is finite), \lim_{x\to\infty} f'(x)=0  \Longleftrightarrow  \lim_{x\to\infty} f(x)=L ,"Is the following true? ( I can't find counter example for it ) $ \lim_{x\to\infty} f'(x)=0 $ $\Longrightarrow$ $ \lim_{x\to\infty} f(x)=L $ (L is finite) if so, how do I prove it? How about the other way around: $ \lim_{x\to\infty} f(x)=L $ (L is finite)  $\Longrightarrow$  $ \lim_{x\to\infty} f'(x)=0 $","Is the following true? ( I can't find counter example for it ) $ \lim_{x\to\infty} f'(x)=0 $ $\Longrightarrow$ $ \lim_{x\to\infty} f(x)=L $ (L is finite) if so, how do I prove it? How about the other way around: $ \lim_{x\to\infty} f(x)=L $ (L is finite)  $\Longrightarrow$  $ \lim_{x\to\infty} f'(x)=0 $",,"['calculus', 'limits', 'derivatives']"
53,Does differentiation symbol need parentheses or?,Does differentiation symbol need parentheses or?,,Suppose I have this expression: $$\frac{d}{dx}(e^{x})^2 + 6$$ Does it mean to differentiate $6$ too or just the first term? This is an exercise on a calculus course that I'm doing on Coursera. Unfortunately anything printed has a weight greater than the onlooker's intelligence. It's beyond me how people on the course forum including the two professors who happen to be doctors can't understand the basic and obvious meaning of parentheses.,Suppose I have this expression: $$\frac{d}{dx}(e^{x})^2 + 6$$ Does it mean to differentiate $6$ too or just the first term? This is an exercise on a calculus course that I'm doing on Coursera. Unfortunately anything printed has a weight greater than the onlooker's intelligence. It's beyond me how people on the course forum including the two professors who happen to be doctors can't understand the basic and obvious meaning of parentheses.,,"['calculus', 'derivatives', 'notation']"
54,Find the derivative of $f(x)=(15\sqrt{x}+5)^2$,Find the derivative of,f(x)=(15\sqrt{x}+5)^2,Find the derivative of $f(x)=(15\sqrt{x}+5)^2$ and determine $f'(9)$ So far I factor it so I got $f(x) = 225x+150\sqrt{x}+25$. Now I did some of the derivatives rules where $\frac{d}{dx}225x$=225 and $\frac{d}{dx}25=0$ So I have $225+\frac{d}{dx}150\sqrt{x}+0$ So to is there a derivative rule for the square root or do I just plug in 9 or did I do something wrong. Please Help!!!,Find the derivative of $f(x)=(15\sqrt{x}+5)^2$ and determine $f'(9)$ So far I factor it so I got $f(x) = 225x+150\sqrt{x}+25$. Now I did some of the derivatives rules where $\frac{d}{dx}225x$=225 and $\frac{d}{dx}25=0$ So I have $225+\frac{d}{dx}150\sqrt{x}+0$ So to is there a derivative rule for the square root or do I just plug in 9 or did I do something wrong. Please Help!!!,,"['calculus', 'derivatives']"
55,The $n$-th derivative of the product of three functions,The -th derivative of the product of three functions,n,"I would like to ask what are the general formula for the the $n$-th derivative of the product of three functions? For the product of two functions, we have the Leibniz's rule for the general formula, how about three functions? Example may be like$\ y=\ x^2\cdot x\cdot \ln x$","I would like to ask what are the general formula for the the $n$-th derivative of the product of three functions? For the product of two functions, we have the Leibniz's rule for the general formula, how about three functions? Example may be like$\ y=\ x^2\cdot x\cdot \ln x$",,['derivatives']
56,Does $\frac{\mathrm d}{\mathrm dx} \ln(x)=\frac{\mathrm d}{\mathrm dx} \ln|x|$?,Does ?,\frac{\mathrm d}{\mathrm dx} \ln(x)=\frac{\mathrm d}{\mathrm dx} \ln|x|,"For some time, I've seen different solutions for the same problems. Let $f$ be any continuous function, differenciable on its domain such that, $$\int \frac{\mathrm d f}{f}=\ln(f)$$ but some authors say, $$\int \frac{\mathrm d f}{f}=\ln|f|$$ I know that, $$\displaystyle \frac{\mathrm d}{\mathrm dx}\ln |x|=\frac{\mathrm d}{\mathrm dx}\ln \sqrt(x^2)=$$ $$\displaystyle \frac{\mathrm d}{\mathrm dx}\ln (x^2)^{\frac{1}{2}}=\frac{\mathrm d}{\mathrm dx}\frac{1}{2}\ln (x^2)=$$ $$\frac{\mathrm d}{\mathrm dx}\ln (x)$$ And so I concluded that: $$\frac{\mathrm d}{\mathrm dx} \ln|x|=\frac{\mathrm d}{\mathrm dx} \ln(x)$$ Can I generalizate that, $$\int \frac{\mathrm d f}{f}=\ln(f)= \ln|f|$$","For some time, I've seen different solutions for the same problems. Let $f$ be any continuous function, differenciable on its domain such that, $$\int \frac{\mathrm d f}{f}=\ln(f)$$ but some authors say, $$\int \frac{\mathrm d f}{f}=\ln|f|$$ I know that, $$\displaystyle \frac{\mathrm d}{\mathrm dx}\ln |x|=\frac{\mathrm d}{\mathrm dx}\ln \sqrt(x^2)=$$ $$\displaystyle \frac{\mathrm d}{\mathrm dx}\ln (x^2)^{\frac{1}{2}}=\frac{\mathrm d}{\mathrm dx}\frac{1}{2}\ln (x^2)=$$ $$\frac{\mathrm d}{\mathrm dx}\ln (x)$$ And so I concluded that: $$\frac{\mathrm d}{\mathrm dx} \ln|x|=\frac{\mathrm d}{\mathrm dx} \ln(x)$$ Can I generalizate that, $$\int \frac{\mathrm d f}{f}=\ln(f)= \ln|f|$$",,['integration']
57,Can somebody provide an explanation to the formula of a one elementary integral?,Can somebody provide an explanation to the formula of a one elementary integral?,,"Here is the formula: $$ \int{\frac{dx}{x}} = \ln{|x|} + C $$ In my textbook it is given without proof, so I have a little confusion here. From the definition of integral this equality must be true: $$ (\ln|x| + C)` = \frac{1}{x} $$ But I failed to derive it. Cause according to the rule of differentiation of a complex funtion $(f_1(f_2(x)))` = f_1`(f_2(x))*f_2`(x) $ (if I understand it right) the derivative of $\ln|x| + C$ is: $$ (\ln|x| + C)` = (\ln|x|)` + C` = \frac{1}{|x|} * |x|` + 0 $$ And this is confirmed by the Wolfram Mathematica: So this is obviously not $\frac{1}{x}$. Can somebody provide an explanation for this problem? My appreciation.","Here is the formula: $$ \int{\frac{dx}{x}} = \ln{|x|} + C $$ In my textbook it is given without proof, so I have a little confusion here. From the definition of integral this equality must be true: $$ (\ln|x| + C)` = \frac{1}{x} $$ But I failed to derive it. Cause according to the rule of differentiation of a complex funtion $(f_1(f_2(x)))` = f_1`(f_2(x))*f_2`(x) $ (if I understand it right) the derivative of $\ln|x| + C$ is: $$ (\ln|x| + C)` = (\ln|x|)` + C` = \frac{1}{|x|} * |x|` + 0 $$ And this is confirmed by the Wolfram Mathematica: So this is obviously not $\frac{1}{x}$. Can somebody provide an explanation for this problem? My appreciation.",,"['integration', 'derivatives', 'self-learning']"
58,Cheapest can problem,Cheapest can problem,,"A cylindrical can which must hold 1000 mL is set to be designed so the least amount of material is necessary to make the can. What should the radius be? What is the height of the can? What is the minimum surface area? I'm not really sure how or where to start...please help! Thanks, Bill","A cylindrical can which must hold 1000 mL is set to be designed so the least amount of material is necessary to make the can. What should the radius be? What is the height of the can? What is the minimum surface area? I'm not really sure how or where to start...please help! Thanks, Bill",,"['calculus', 'geometry', 'derivatives']"
59,Transpose of matrix inverse: $(AA^T)^{-1}A^Tb \stackrel{?}{=} (A^TA)^{-1}A^Tb$,Transpose of matrix inverse:,(AA^T)^{-1}A^Tb \stackrel{?}{=} (A^TA)^{-1}A^Tb,Given the matrix equation: $$ x^TA^TA = b^TA $$ I'm trying to find the least squares solution (i.e.; trying to minimize $r=||Ax-b||$). The matrix $A$ is not necessarily symmetric. When I solve it in following way I find $x$ as: $$ \begin{array}{rcl} x^TA^TA &=& b^TA \\ x^T &=& b^TA(A^TA)^{-1} \\ x &=& (AA^T)^{-1}A^Tb \end{array} $$ But I find a different solution for $x$ when I solve it this way: $$ \begin{array}{rcl} x^TA^TA &=& b^TA \\ A^TAx &=& A^Tb \\ x &=& (A^TA)^{-1}A^Tb \end{array} $$ Apparently the latter one is the correct solution. But what is wrong with the first one? What am I doing wrong?,Given the matrix equation: $$ x^TA^TA = b^TA $$ I'm trying to find the least squares solution (i.e.; trying to minimize $r=||Ax-b||$). The matrix $A$ is not necessarily symmetric. When I solve it in following way I find $x$ as: $$ \begin{array}{rcl} x^TA^TA &=& b^TA \\ x^T &=& b^TA(A^TA)^{-1} \\ x &=& (AA^T)^{-1}A^Tb \end{array} $$ But I find a different solution for $x$ when I solve it this way: $$ \begin{array}{rcl} x^TA^TA &=& b^TA \\ A^TAx &=& A^Tb \\ x &=& (A^TA)^{-1}A^Tb \end{array} $$ Apparently the latter one is the correct solution. But what is wrong with the first one? What am I doing wrong?,,"['matrices', 'optimization', 'derivatives', 'inverse']"
60,Using integration and differentiation to solve for deceleration?,Using integration and differentiation to solve for deceleration?,,"PROBLEM STATES: The landing velocity of an airplane (at which it touches the ground) is 100mi/hr. It decelerates at a constant rate and comes to a stop after traveling .25miles along a straight landing strip. Find the deceleration or the negative acceleration. MY CONCERN/QUESTIONS: I have worked to long on this problem and just can't find out how to approach this. I feel like i'm missing some important data or physical law that I need to apply. Usually we take the anti-derivative of acceleration make it equal the velocity in working backwards. However, I cannot approach this problem like this. I do not have acceleration and only have velocity. To define initial conditions I would say at time (0) distance is (0). However, for some intuitive reason I'm wanting to say at time (0) distance is (.25). Can anyone help me out in solving this problem. I feel like I'm not given a sufficient amount of information to solve this problem.","PROBLEM STATES: The landing velocity of an airplane (at which it touches the ground) is 100mi/hr. It decelerates at a constant rate and comes to a stop after traveling .25miles along a straight landing strip. Find the deceleration or the negative acceleration. MY CONCERN/QUESTIONS: I have worked to long on this problem and just can't find out how to approach this. I feel like i'm missing some important data or physical law that I need to apply. Usually we take the anti-derivative of acceleration make it equal the velocity in working backwards. However, I cannot approach this problem like this. I do not have acceleration and only have velocity. To define initial conditions I would say at time (0) distance is (0). However, for some intuitive reason I'm wanting to say at time (0) distance is (.25). Can anyone help me out in solving this problem. I feel like I'm not given a sufficient amount of information to solve this problem.",,"['integration', 'derivatives']"
61,Derivative of $\sec^{-1}(x)$,Derivative of,\sec^{-1}(x),"I'm struggling with problem below which I eagerly want to solve. Let me know from where this problem is, if possible (the origin source of textbook). your answers might really helpful to get through the struggles with which I confront. Question One way of defining $\sec^{-1}(x)$ that is sometimes used is to say that $y=\sec^{-1}(x)$ $\iff$ $\sec(y)=x$ and $y \in (0,\pi]$ (alternatively, y is between 0 and pi and is the same 0 and pi, y not 0) show that, with this definition. $\frac{d}{dx}\sec^{-1}(x)=\frac{1}{|x|\sqrt{x^2-1}}$","I'm struggling with problem below which I eagerly want to solve. Let me know from where this problem is, if possible (the origin source of textbook). your answers might really helpful to get through the struggles with which I confront. Question One way of defining $\sec^{-1}(x)$ that is sometimes used is to say that $y=\sec^{-1}(x)$ $\iff$ $\sec(y)=x$ and $y \in (0,\pi]$ (alternatively, y is between 0 and pi and is the same 0 and pi, y not 0) show that, with this definition. $\frac{d}{dx}\sec^{-1}(x)=\frac{1}{|x|\sqrt{x^2-1}}$",,"['calculus', 'derivatives']"
62,Finding an inflection point,Finding an inflection point,,Can anyone help me find an inflection point for the following function without using graphing calculator. Determine the intervals of concavity and points of inflection for the function $f(x)=x\sqrt{25-x^2}$ for my first derivative I did $f'(x)=1\sqrt{25-x^2}+(x)\frac{1}{2\sqrt{25-x^2}}(-2x)$ for my common denominator I got $\frac{50-4x^2}{2\sqrt{25-x^2}}$ for my second derivative I got $f''(x)=\frac{(-4x)\sqrt{25-x^2}-(25-2x^2)(1/2)\sqrt{25-x^2}(-2x)}{\sqrt{(25-x^2)^2}}$ But I am having trobule finding the inflection point.,Can anyone help me find an inflection point for the following function without using graphing calculator. Determine the intervals of concavity and points of inflection for the function $f(x)=x\sqrt{25-x^2}$ for my first derivative I did $f'(x)=1\sqrt{25-x^2}+(x)\frac{1}{2\sqrt{25-x^2}}(-2x)$ for my common denominator I got $\frac{50-4x^2}{2\sqrt{25-x^2}}$ for my second derivative I got $f''(x)=\frac{(-4x)\sqrt{25-x^2}-(25-2x^2)(1/2)\sqrt{25-x^2}(-2x)}{\sqrt{(25-x^2)^2}}$ But I am having trobule finding the inflection point.,,"['calculus', 'derivatives']"
63,"Applied mathematics, when to leave out delta function?","Applied mathematics, when to leave out delta function?",,I cant figure out when I´m supposed to ignore the $\delta(t)$ function in the answer. $\theta(t)$ is The Heaviside function I have three examples: 1. Let $f(t) = e^t\theta(t)$ and find $f'$ Answer: $(e^t\theta(t))' = (e^t)'\theta(t) + e^t(\theta(t))' = e^t\theta(t) + e^t\delta(t) = e^t\theta(t) + \delta(t)$ Hence $\delta$(t) stay. 2. Let $f(t) = e^{2t}\theta(t)$ and find $f'$ Answer: $(e^{2t}\theta(t))' = (e^{2t})'\theta(t) + e^{2t}(\theta(t))' = 2e^{2t}\theta(t) + e^{2t}\delta(t) = 2e^{2t}\theta(t) + \delta(t)$ Again $\delta(t)$ stays. 3. Let $f(t) = t\theta(t)$ and find $f'$ Answer: $(t\theta(t))' = t'\theta(t) + t(\theta(t))' = \theta(t) + t\delta(t) = \theta(t)$ Here $\delta(t)$ is just removed in the last step? Why is it okay to remove it? (These writings are from an previous exam and I've just entered the answers from the key),I cant figure out when I´m supposed to ignore the $\delta(t)$ function in the answer. $\theta(t)$ is The Heaviside function I have three examples: 1. Let $f(t) = e^t\theta(t)$ and find $f'$ Answer: $(e^t\theta(t))' = (e^t)'\theta(t) + e^t(\theta(t))' = e^t\theta(t) + e^t\delta(t) = e^t\theta(t) + \delta(t)$ Hence $\delta$(t) stay. 2. Let $f(t) = e^{2t}\theta(t)$ and find $f'$ Answer: $(e^{2t}\theta(t))' = (e^{2t})'\theta(t) + e^{2t}(\theta(t))' = 2e^{2t}\theta(t) + e^{2t}\delta(t) = 2e^{2t}\theta(t) + \delta(t)$ Again $\delta(t)$ stays. 3. Let $f(t) = t\theta(t)$ and find $f'$ Answer: $(t\theta(t))' = t'\theta(t) + t(\theta(t))' = \theta(t) + t\delta(t) = \theta(t)$ Here $\delta(t)$ is just removed in the last step? Why is it okay to remove it? (These writings are from an previous exam and I've just entered the answers from the key),,['derivatives']
64,On the meaning of the second derivative,On the meaning of the second derivative,,"When we want to find the velocity of an object we use the derivative to find this. However, I just learned that when you find the acceleration of the object you find the second derivative. I'm confused on what is being defined as the parameters of acceleration. I always thought acceleration of an object is it's velocity (d/t). Furthermore, in the second derivative are we using the x value or the y value of interest. In the first derivative we were only concerned with the x value. Does this still hold true with the second derivative? I would post pictures but apparently I'm still lacking 4 points.","When we want to find the velocity of an object we use the derivative to find this. However, I just learned that when you find the acceleration of the object you find the second derivative. I'm confused on what is being defined as the parameters of acceleration. I always thought acceleration of an object is it's velocity (d/t). Furthermore, in the second derivative are we using the x value or the y value of interest. In the first derivative we were only concerned with the x value. Does this still hold true with the second derivative? I would post pictures but apparently I'm still lacking 4 points.",,['derivatives']
65,Convexity and minimum of a vector function,Convexity and minimum of a vector function,,"Prove that the function $f:\mathbb{R}^n\to \mathbb{R}$ given by $f(x)=x^T \cdot x$ is strictly convex. Use this result to find the absolute minimum by equating the derivative to zero. I am not sure how to prove that a vector function is convex. Is there a general method to do this? Also, I tried differentiating the function and I got $2x^T$dx as a result for the differential, which would mean that $2x^T$ is the derivative. However, does this give me the absolute minimum? Or did I make a mistake in differentiating? Thanks in advance.","Prove that the function $f:\mathbb{R}^n\to \mathbb{R}$ given by $f(x)=x^T \cdot x$ is strictly convex. Use this result to find the absolute minimum by equating the derivative to zero. I am not sure how to prove that a vector function is convex. Is there a general method to do this? Also, I tried differentiating the function and I got $2x^T$dx as a result for the differential, which would mean that $2x^T$ is the derivative. However, does this give me the absolute minimum? Or did I make a mistake in differentiating? Thanks in advance.",,"['derivatives', 'vector-spaces', 'convex-analysis']"
66,Calculus chain rule question?,Calculus chain rule question?,,How would I figure out the following $f(x)=(x^2-9)^2$ determine the values for which $f'(x)<0$ I know the derivative is using the chain rule is $2(x^2-9)(2x)$ but how would I figure out the rest.,How would I figure out the following $f(x)=(x^2-9)^2$ determine the values for which $f'(x)<0$ I know the derivative is using the chain rule is $2(x^2-9)(2x)$ but how would I figure out the rest.,,"['calculus', 'derivatives']"
67,How to use Rolle's Theorem to prove this statement?,How to use Rolle's Theorem to prove this statement?,,"If $f$ is a polynomial with $n$ distinct zeros, then $f'$ has at least   $n-1$ zeros.","If $f$ is a polynomial with $n$ distinct zeros, then $f'$ has at least   $n-1$ zeros.",,"['real-analysis', 'derivatives']"
68,Derivative of $\cos nx$,Derivative of,\cos nx,How to calculate derivative of $ \cos ax$? Do I need any formula for $ \cos ax$? The answer in my exercise book says it is $-a \sin ax$. But I don't know how to come to this result. Could you maybe explain it to me?,How to calculate derivative of $ \cos ax$? Do I need any formula for $ \cos ax$? The answer in my exercise book says it is $-a \sin ax$. But I don't know how to come to this result. Could you maybe explain it to me?,,"['trigonometry', 'derivatives']"
69,Identifying inflection points and critical points,Identifying inflection points and critical points,,"I'm given an equation and asked to find the following: Domain Critical points Inflection points Asymptotes The function is: $y = 2 + 9x + 3x^2 -x^3$ It has been quite awhile since I have done this sort of problem so I'm a bit rusty. Can someone check my work and explain the missing parts? Domain All Real Critical Points: Find derivative: $ y' = -3x^2 + 6x + 9$ Set equal to 0: $ 3x^2 - 6x - 9 = 0 $ $ (3x + 3)(x - 3) = 0$ $ x = -1, x = 3$ Corresponding points: (-1, -3) & (3,30) Inflection Points: Take second derivative: $ y'' = 6x - 6$ Set it to 0: edit (fix typo) $ x = 1 $ Corresponding point: (1, 13) Asymptotes None","I'm given an equation and asked to find the following: Domain Critical points Inflection points Asymptotes The function is: $y = 2 + 9x + 3x^2 -x^3$ It has been quite awhile since I have done this sort of problem so I'm a bit rusty. Can someone check my work and explain the missing parts? Domain All Real Critical Points: Find derivative: $ y' = -3x^2 + 6x + 9$ Set equal to 0: $ 3x^2 - 6x - 9 = 0 $ $ (3x + 3)(x - 3) = 0$ $ x = -1, x = 3$ Corresponding points: (-1, -3) & (3,30) Inflection Points: Take second derivative: $ y'' = 6x - 6$ Set it to 0: edit (fix typo) $ x = 1 $ Corresponding point: (1, 13) Asymptotes None",,"['calculus', 'derivatives']"
70,How to find the critical points of a polynomial? [closed],How to find the critical points of a polynomial? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need help finding the critical points of the function $x^5+x^4-2x^2$, I don't understand, can someone help show me how to find the critical points please","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I need help finding the critical points of the function $x^5+x^4-2x^2$, I don't understand, can someone help show me how to find the critical points please",,"['calculus', 'derivatives']"
71,derivative at a given point,derivative at a given point,,"I often see the following: $$ \left. \frac{\partial q}{\partial \alpha} \right|_{\alpha = 0} $$ Where $q$ is a function $q(q', t, \alpha)$. Is that just the same as that? $$ \frac{\partial}{\partial \alpha} q(\alpha=0) $$ If they are the same, why do people write the first one? I find the second easier.","I often see the following: $$ \left. \frac{\partial q}{\partial \alpha} \right|_{\alpha = 0} $$ Where $q$ is a function $q(q', t, \alpha)$. Is that just the same as that? $$ \frac{\partial}{\partial \alpha} q(\alpha=0) $$ If they are the same, why do people write the first one? I find the second easier.",,"['calculus', 'notation', 'derivatives']"
72,"Given the rate of which a circular area grows, find the radius and its rate of change","Given the rate of which a circular area grows, find the radius and its rate of change",,"A viscous liquid is poured on to a flat surface. It forms a circular patch whose area grows at a steady rate of $5 \text{ cm}^2/s$. Find in terms of $π$, (a) the radius of the patch 20 seconds after pouring has commenced (b) the rate of increase of the radius at this instant.","A viscous liquid is poured on to a flat surface. It forms a circular patch whose area grows at a steady rate of $5 \text{ cm}^2/s$. Find in terms of $π$, (a) the radius of the patch 20 seconds after pouring has commenced (b) the rate of increase of the radius at this instant.",,"['calculus', 'derivatives']"
73,"How to find $h'(x)$, if $h(x) = f(g(x))$.","How to find , if .",h'(x) h(x) = f(g(x)),"Let $f'(x) = \sqrt{3x + 4}$ and $g(x)=x^2-1$. Find $h'(x)$, if $h(x) = f(g(x))$. I know that $g'(x) = 2x$, but I don't know how to do further. The answer is $h'(x) = 2x \sqrt{3x^2 + 1}$.","Let $f'(x) = \sqrt{3x + 4}$ and $g(x)=x^2-1$. Find $h'(x)$, if $h(x) = f(g(x))$. I know that $g'(x) = 2x$, but I don't know how to do further. The answer is $h'(x) = 2x \sqrt{3x^2 + 1}$.",,"['calculus', 'derivatives']"
74,Need help understanding $\frac {dx}{\cos^2(\frac{x}{2})} = 2d(\operatorname{tg}(\frac{x}{2})) $,Need help understanding,\frac {dx}{\cos^2(\frac{x}{2})} = 2d(\operatorname{tg}(\frac{x}{2})) ,"I have found this statement somewhere, however, I dont really understand it. Could someone explain me where does $2$ before $\operatorname{tg}(x/2)$ come from? $$\frac {dx}{\cos^2(\frac{x}{2})} = 2d(\operatorname{tg}(\frac{x}{2})) $$","I have found this statement somewhere, however, I dont really understand it. Could someone explain me where does $2$ before $\operatorname{tg}(x/2)$ come from? $$\frac {dx}{\cos^2(\frac{x}{2})} = 2d(\operatorname{tg}(\frac{x}{2})) $$",,"['calculus', 'trigonometry', 'derivatives']"
75,Convergence and Differentiability of a Sequence of Functions,Convergence and Differentiability of a Sequence of Functions,,"Question: I'm studying a sequence of functions $$f_n(x) = \sqrt{x^2 + \frac{1}{n}}$$ defined on the domain $[-1,1]$ and I'm trying to understand their behavior as $n$ approaches infinity. Context and Motivation: This problem came up while I was studying real analysis and the concept of uniform convergence. I understand that for a sequence of functions to converge uniformly to a limiting function, the speed of convergence must be independent of the choice of $x$ in the domain. I'm interested in seeing how this plays out for the given sequence of functions, especially since they involve a square root, which can often lead to interesting behavior. My Attempts: I've tried to find the pointwise limit of the sequence by taking the limit as $n$ goes to infinity, which gives me the function $$f(x) = |x|$$ . However, I'm unsure if the convergence is uniform. I've also noticed that each $f_n$ is differentiable, but I'm not sure if the limiting function $f$ is differentiable on $[-1,1]$ due to the absolute value. Specific Questions: Does the sequence $f_n(x)$ converge uniformly to $f(x)$ on $[-1,1]$ ? Is the limiting function $f(x)$ differentiable on $[-1,1]$ ?","Question: I'm studying a sequence of functions defined on the domain and I'm trying to understand their behavior as approaches infinity. Context and Motivation: This problem came up while I was studying real analysis and the concept of uniform convergence. I understand that for a sequence of functions to converge uniformly to a limiting function, the speed of convergence must be independent of the choice of in the domain. I'm interested in seeing how this plays out for the given sequence of functions, especially since they involve a square root, which can often lead to interesting behavior. My Attempts: I've tried to find the pointwise limit of the sequence by taking the limit as goes to infinity, which gives me the function . However, I'm unsure if the convergence is uniform. I've also noticed that each is differentiable, but I'm not sure if the limiting function is differentiable on due to the absolute value. Specific Questions: Does the sequence converge uniformly to on ? Is the limiting function differentiable on ?","f_n(x) = \sqrt{x^2 + \frac{1}{n}} [-1,1] n x n f(x) = |x| f_n f [-1,1] f_n(x) f(x) [-1,1] f(x) [-1,1]","['real-analysis', 'sequences-and-series', 'derivatives', 'convergence-divergence', 'uniform-convergence']"
76,"Is a measure, whose distributional derivative is a measure, absolutely continuous wrt Lebesgue?","Is a measure, whose distributional derivative is a measure, absolutely continuous wrt Lebesgue?",,Suppose $\mu$ is a finite Borel measure on $\mathbb{R}^n$ with the property that it's distributional gradient $\nabla\mu$ is a vector-valued finite Borel measure. Does it follows then that $\mu$ itself is absolutely continuous with respect to Lebesgue measure?,Suppose is a finite Borel measure on with the property that it's distributional gradient is a vector-valued finite Borel measure. Does it follows then that itself is absolutely continuous with respect to Lebesgue measure?,\mu \mathbb{R}^n \nabla\mu \mu,"['derivatives', 'lebesgue-measure', 'distribution-theory', 'bounded-variation', 'borel-measures']"
77,"If $(f(x)-x)f''(x)>0$ , then $f(x)=f^{-1}(x)$ has no solution.","If  , then  has no solution.",(f(x)-x)f''(x)>0 f(x)=f^{-1}(x),"If $f:\mathbb{R}\to\mathbb{R}$ is a double differentiable bijective function, then which of the following statements may be true ? (A) $(f(x)-x)f''(x)\leq 0$ for all $x\in\mathbb{R}$ (B) $(f(x)-x)f''(x)\geq 0$ for all $x\in\mathbb{R}$ (C) If $(f(x)-x)f''(x)>0$ , then $f(x)=f^{-1}(x)$ has no solution. (D) If $(f(x)-x)f''(x)>0$ , then $f(x)=f^{-1}(x)$ has at least one real solution. My Attempt Clearly if $f(x)=e^{-x}$ then both (A) and (B) are NOT true. If I take $f(x)=e^x$ then (C) appears to be true. But is there a general explanation","If is a double differentiable bijective function, then which of the following statements may be true ? (A) for all (B) for all (C) If , then has no solution. (D) If , then has at least one real solution. My Attempt Clearly if then both (A) and (B) are NOT true. If I take then (C) appears to be true. But is there a general explanation",f:\mathbb{R}\to\mathbb{R} (f(x)-x)f''(x)\leq 0 x\in\mathbb{R} (f(x)-x)f''(x)\geq 0 x\in\mathbb{R} (f(x)-x)f''(x)>0 f(x)=f^{-1}(x) (f(x)-x)f''(x)>0 f(x)=f^{-1}(x) f(x)=e^{-x} f(x)=e^x,"['real-analysis', 'calculus', 'derivatives', 'inverse-function']"
78,Does differentiation change the units of measurement in mathematical equations?,Does differentiation change the units of measurement in mathematical equations?,,"While i'm doing the math homework, I find something very strange. I am confused by a textbook's answer. The Question The textbook's answer So, Does differentiation change the units of measurement in mathematical equations?","While i'm doing the math homework, I find something very strange. I am confused by a textbook's answer. The Question The textbook's answer So, Does differentiation change the units of measurement in mathematical equations?",,['derivatives']
79,How to prove that the local minimum for $f(x)=\left|x\right|$ occurs at $x=0$?,How to prove that the local minimum for  occurs at ?,f(x)=\left|x\right| x=0,"The first and second derivative tests don't work as $f\left(x\right)$ is not differentiable at $x=0$ . So, critical points can't be obtained to check for local maxima or minima or inflection. Plotting the graph for $f\left(x\right)=\left|x\right|$ does show that $f'\left(x\right)$ or $\frac{df\left(x\right)}{dx}$ goes from decreasing to increasing as $f\left(x\right)$ passes $x=0$ . Thus, $x=0$ can be termed as the point of local minimum. However, can this be done through another method in addition to curve sketching just like the first and second derivative tests?","The first and second derivative tests don't work as is not differentiable at . So, critical points can't be obtained to check for local maxima or minima or inflection. Plotting the graph for does show that or goes from decreasing to increasing as passes . Thus, can be termed as the point of local minimum. However, can this be done through another method in addition to curve sketching just like the first and second derivative tests?",f\left(x\right) x=0 f\left(x\right)=\left|x\right| f'\left(x\right) \frac{df\left(x\right)}{dx} f\left(x\right) x=0 x=0,"['derivatives', 'maxima-minima']"
80,Matrix multiplication seen as derivative or integral,Matrix multiplication seen as derivative or integral,,"I'm reading the book ""Introduction to Linear Algebra 5th edition"" page 24 about Inverse Matrix, below is the background info. $$ \mathbf{A} = \begin{bmatrix} 1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 1 \end{bmatrix}, \qquad \mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}, \qquad \mathbf{b} = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix}. $$ In which the author mentioned ""The differences $\mathbf{A}\mathbf{x}$ become the derivative $\frac{\mathrm{d}x}{\mathrm{d}t} = b(t)$ . In the inverse direction, the sums $\mathbf{A}^{-1}\mathbf{b}$ become the integral of $b(t)$ ."" I'm so confused about these statements, I'm thinking he meant vector $\mathbf{x}$ as a function, which applied to matrix $\mathbf{A}$ , so $\mathbf{x}(t)$ is the $\mathbf{A}\mathbf{x}$ .  Then how could: "" $\mathbf{A}\mathbf{x}$ become the derivative $\frac{\mathrm{d}x}{\mathrm{d}t} = b(t)$ ""? As I cant imagine the derivative of $\mathbf{A}\mathbf{x}$ or $x(t)$ here. $$ \mathbf{A}\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 - x_1 \\ x_3 - x_2 \end{bmatrix} $$","I'm reading the book ""Introduction to Linear Algebra 5th edition"" page 24 about Inverse Matrix, below is the background info. In which the author mentioned ""The differences become the derivative . In the inverse direction, the sums become the integral of ."" I'm so confused about these statements, I'm thinking he meant vector as a function, which applied to matrix , so is the .  Then how could: "" become the derivative ""? As I cant imagine the derivative of or here."," \mathbf{A} = \begin{bmatrix} 1 & 0 & 0 \\ -1 & 1 & 0 \\ 0 & -1 & 1 \end{bmatrix}, \qquad
\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}, \qquad
\mathbf{b} = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix}.
 \mathbf{A}\mathbf{x} \frac{\mathrm{d}x}{\mathrm{d}t} = b(t) \mathbf{A}^{-1}\mathbf{b} b(t) \mathbf{x} \mathbf{A} \mathbf{x}(t) \mathbf{A}\mathbf{x} \mathbf{A}\mathbf{x} \frac{\mathrm{d}x}{\mathrm{d}t} = b(t) \mathbf{A}\mathbf{x} x(t)  \mathbf{A}\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 - x_1 \\ x_3 - x_2 \end{bmatrix} ","['calculus', 'linear-algebra', 'integration', 'derivatives']"
81,Can you get an infinite number of derivatives from $\frac{d}{dx}\sin(x)$? [closed],Can you get an infinite number of derivatives from ? [closed],\frac{d}{dx}\sin(x),"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last year . Improve this question I know that the first derivative of sine of $x$ is cosine of $x$ , but I'm really facing a problem trying to understand the other derivatives of the sine function. The following $2$ statements are both true: $$\frac{d}{dx}\sin(x) = \cos(x)$$ $$\frac{d}{dx}\cos(x) = -\sin(x)$$ And then, according to the constant multiple rule, we can see that the following is also true: $$\frac{d}{dx}-\sin(x) = -1 \cdot \frac{d}{dx}\sin(x) = -1 \cdot \cos(x) = -\cos(x)$$ Hence: $$\frac{d}{dx}-\cos(x) = -1\cdot\frac{d}{dx}\cos(x) = -1\cdot(-\sin(x)) = \sin(x) \ \dots$$ Can we keep repeating this process to infinity? And what does it really mean that the fourth derivative of $\sin(x)$ is $\sin(x)$ ? I've seen a visualisation that explains why the derivative of $\sin(x)$ is $\cos(x)$ , so I know why the first derivative of $\sin(x)$ is $\cos(x)$ , at least intuitively, but I can't really get the idea of the rest of the derivatives of $\sin(x)$ , or why they are repeating, and can we really keep repeating this with no problems?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last year . Improve this question I know that the first derivative of sine of is cosine of , but I'm really facing a problem trying to understand the other derivatives of the sine function. The following statements are both true: And then, according to the constant multiple rule, we can see that the following is also true: Hence: Can we keep repeating this process to infinity? And what does it really mean that the fourth derivative of is ? I've seen a visualisation that explains why the derivative of is , so I know why the first derivative of is , at least intuitively, but I can't really get the idea of the rest of the derivatives of , or why they are repeating, and can we really keep repeating this with no problems?",x x 2 \frac{d}{dx}\sin(x) = \cos(x) \frac{d}{dx}\cos(x) = -\sin(x) \frac{d}{dx}-\sin(x) = -1 \cdot \frac{d}{dx}\sin(x) = -1 \cdot \cos(x) = -\cos(x) \frac{d}{dx}-\cos(x) = -1\cdot\frac{d}{dx}\cos(x) = -1\cdot(-\sin(x)) = \sin(x) \ \dots \sin(x) \sin(x) \sin(x) \cos(x) \sin(x) \cos(x) \sin(x),"['calculus', 'derivatives', 'trigonometry', 'solution-verification']"
82,Derivative of numerator greater than denominator implies quotient is increasing.,Derivative of numerator greater than denominator implies quotient is increasing.,,"Let $u, v$ be two non-negative functions satisfying $u'>v'>0$ . Then I would like to show $$\left(\frac{u}{v}\right)'>0.$$ I'm not sure if this is actually even true, although it is intuitive and has worked for every example that I've tried. Here is my work so far: \begin{align} \left(\frac{u}{v}\right)'=\frac{u'v-uv'}{v^2}, \end{align} so it remains to show that $u'v-uv'>0$ . We can naively substitute the inequality $u'v-uv'>v'(v-u)$ , but I believe $v-u>0$ is not required. If someone can fill in what I'm missing then I would appreciate it.","Let be two non-negative functions satisfying . Then I would like to show I'm not sure if this is actually even true, although it is intuitive and has worked for every example that I've tried. Here is my work so far: so it remains to show that . We can naively substitute the inequality , but I believe is not required. If someone can fill in what I'm missing then I would appreciate it.","u, v u'>v'>0 \left(\frac{u}{v}\right)'>0. \begin{align}
\left(\frac{u}{v}\right)'=\frac{u'v-uv'}{v^2},
\end{align} u'v-uv'>0 u'v-uv'>v'(v-u) v-u>0","['calculus', 'derivatives', 'power-series', 'fractions']"
83,Derivative of $(2x^2+3)^2(x^3-2x)^4$,Derivative of,(2x^2+3)^2(x^3-2x)^4,I want to know if there's another method in shorter way. I came up to this problem Find the $f'(x)$ $$ f(x) = (2x^2+3)^2\cdot(x^3-2x)^4 $$ Applying product rules $$ \frac{d}{dx}f(x)g(x) = f(x)\frac{d}{dx}g'(x) + g'(x)\frac{d}{dx}f(x) $$ Solve: $$ f = (2x^2+3)^2 $$ $$ g = (x^3-2x)^4$$ $$ \frac{d}{dx}(2x^2+3)^2(x^3+2x)^4 + \frac{d}{dx}(x^3-2x)^4(2x^2+3)^2 $$ $$ 2(2x^2+3) 4x(x^3-2x)^4 + 4(x^3-2x)^3(3x^2-2)(2x^2+3)^2 $$ $$ 8x(2x^2+3)(x^3-2x)^4 + 4(x^3-2x)^3(3x^2-2)(2x^2+3)^2 $$ $$ 8x(2x^2+3)(x^3-2x)^4 + (x^3-2x)^3(12x^2-8)(2x^2+3)^2 $$ Answer: $$ f'(x) =8x(2x+3)(x^3-2x)^4 + (x^3-2x)^3(12x^2-8)(2x^2+3)^2 $$ Is this correct way or are there other methods? Thanks in advance.,I want to know if there's another method in shorter way. I came up to this problem Find the Applying product rules Solve: Answer: Is this correct way or are there other methods? Thanks in advance.,"f'(x) 
f(x) = (2x^2+3)^2\cdot(x^3-2x)^4
 
\frac{d}{dx}f(x)g(x) = f(x)\frac{d}{dx}g'(x) + g'(x)\frac{d}{dx}f(x)
  f = (2x^2+3)^2   g = (x^3-2x)^4 
\frac{d}{dx}(2x^2+3)^2(x^3+2x)^4 + \frac{d}{dx}(x^3-2x)^4(2x^2+3)^2
 
2(2x^2+3) 4x(x^3-2x)^4 + 4(x^3-2x)^3(3x^2-2)(2x^2+3)^2
 
8x(2x^2+3)(x^3-2x)^4 + 4(x^3-2x)^3(3x^2-2)(2x^2+3)^2
 
8x(2x^2+3)(x^3-2x)^4 + (x^3-2x)^3(12x^2-8)(2x^2+3)^2
 
f'(x) =8x(2x+3)(x^3-2x)^4 + (x^3-2x)^3(12x^2-8)(2x^2+3)^2
","['calculus', 'derivatives']"
84,Can we always assume that a function is differentiable?,Can we always assume that a function is differentiable?,,"I know how to solve the following problem assuming a supplementary condition(that a function is differentiable). The problem: Let $a$ and $b$ be real numbers in the interval $(0, +\infty)$ and $f : [a, b] \to [0, b]$ a bijective and continuous function and $f(0)=0$ . Show that $$\int_0^a f(x)dx+\int_0^b f^{-1}(x)dx=ab$$ where $f^{-1}$ is the inverse function of $f$ . This is my approach. $f$ is a continuous function therefore it has the intermediate value property. The function is bijective and it is continuous so, in particular, it is injective. Therefore, the function is monotone. The function is increasing because the codomain has positive values. What I mean is that if we take $x \in [0, a] \implies f(x) \in [0, b] \implies 0 \le f(x)$ . Since $0 \le x \implies f(0) \le f(x)$ it means that f has to be increasing. $f$ is continuous and increasing therefore, the extreme value theorem says that $f(a)=b$ . Now, I would assume that $f$ is differentiable, so I can use the substitution $u=f^{-1}(x)$ on the second integral. Therefore, $x=f(u) \implies dx=f'(u)du$ . So, $$\int_0^b f^{-1}(x)dx=\int_0^a uf'(u)du=uf(u)\biggr \rvert_{0}^{a}-\int_0^a f(u)du$$ Therefore, the sum of the two integrals is $ab$ . However, I don't know how to deal with the case where $f$ is not differentiable. Can we assume this? Because I have found counterexamples, like $f(x)=x$ for $x \in [0, 1]$ and $f(x)=2x-1$ for $x \in (1, 2]$ . This function is not differentiable at $x=1$ , but is both continuous and bijective. And with the same reasoning we can create a function that has a countable set of points where the function is not differentiable, like $f(x)=\frac{1}{n}x+c_n$ for $x \in [\frac{1}{n}, \frac{1}{n+1}]$ and we find $c_n$ such that the function is continuous. Is it safe to assume that the function is differentiable, and if yes why? Edit: I wrote some ambiguous things and I corrected them","I know how to solve the following problem assuming a supplementary condition(that a function is differentiable). The problem: Let and be real numbers in the interval and a bijective and continuous function and . Show that where is the inverse function of . This is my approach. is a continuous function therefore it has the intermediate value property. The function is bijective and it is continuous so, in particular, it is injective. Therefore, the function is monotone. The function is increasing because the codomain has positive values. What I mean is that if we take . Since it means that f has to be increasing. is continuous and increasing therefore, the extreme value theorem says that . Now, I would assume that is differentiable, so I can use the substitution on the second integral. Therefore, . So, Therefore, the sum of the two integrals is . However, I don't know how to deal with the case where is not differentiable. Can we assume this? Because I have found counterexamples, like for and for . This function is not differentiable at , but is both continuous and bijective. And with the same reasoning we can create a function that has a countable set of points where the function is not differentiable, like for and we find such that the function is continuous. Is it safe to assume that the function is differentiable, and if yes why? Edit: I wrote some ambiguous things and I corrected them","a b (0, +\infty) f : [a, b] \to [0, b] f(0)=0 \int_0^a f(x)dx+\int_0^b f^{-1}(x)dx=ab f^{-1} f f x \in [0, a] \implies f(x) \in [0, b] \implies 0 \le f(x) 0 \le x \implies f(0) \le f(x) f f(a)=b f u=f^{-1}(x) x=f(u) \implies dx=f'(u)du \int_0^b f^{-1}(x)dx=\int_0^a uf'(u)du=uf(u)\biggr \rvert_{0}^{a}-\int_0^a f(u)du ab f f(x)=x x \in [0, 1] f(x)=2x-1 x \in (1, 2] x=1 f(x)=\frac{1}{n}x+c_n x \in [\frac{1}{n}, \frac{1}{n+1}] c_n","['real-analysis', 'calculus', 'integration', 'derivatives', 'definite-integrals']"
85,can a bounded ratio of two polynomials have unbounded derivative?,can a bounded ratio of two polynomials have unbounded derivative?,,"Let $P(x_1,\cdots,x_m)$ and $Q(x_1,\cdots,x_m)$ be two polynomials and assume that $$f(x_1,\cdots,x_m)=\frac{Q(x_1,\cdots,x_m)}{P(x_1,\cdots,x_m)}$$ is bounded over some region $D\subseteq \mathbb{R}^m$ . Can $f$ have an unbounded derivative over $D$ ? By unbounded I mean that $|\nabla f|\rightarrow \infty$ somewhere in $D$ .",Let and be two polynomials and assume that is bounded over some region . Can have an unbounded derivative over ? By unbounded I mean that somewhere in .,"P(x_1,\cdots,x_m) Q(x_1,\cdots,x_m) f(x_1,\cdots,x_m)=\frac{Q(x_1,\cdots,x_m)}{P(x_1,\cdots,x_m)} D\subseteq \mathbb{R}^m f D |\nabla f|\rightarrow \infty D","['derivatives', 'polynomials']"
86,What is the $n^{th}$ derivative of $f(x)=\sin^2x$?,What is the  derivative of ?,n^{th} f(x)=\sin^2x,"What is the $n^{th}$ derivative of $f(x)=\sin^2x$ ? I am not allowed to use anything fancy, just the process of mathematical induction and the basic rules for calculating derivatives. (I haven't studied the Leibniz rule for example) So we have $$f'(x)=2\sin x(\sin x)'=2\sin x\cos x=\sin2x\\f''(x)=(\sin2x)'=\cos2x(2x)'=2\cos2x\\f'''(x)=(2\cos 2x)'=2(\cos2x)'=-4\sin 2x\\f^{(4)}(x)=-8\cos2x$$ Is it possible to make an assumption for the n-th derivate (that we will of course prove using induction) that doesn't include looking at different cases (I mean when $n$ is even and odd and etc)? In other words, I want to find a single formula parametrized with $n$ for the n-th derivative. Thanks!","What is the derivative of ? I am not allowed to use anything fancy, just the process of mathematical induction and the basic rules for calculating derivatives. (I haven't studied the Leibniz rule for example) So we have Is it possible to make an assumption for the n-th derivate (that we will of course prove using induction) that doesn't include looking at different cases (I mean when is even and odd and etc)? In other words, I want to find a single formula parametrized with for the n-th derivative. Thanks!",n^{th} f(x)=\sin^2x f'(x)=2\sin x(\sin x)'=2\sin x\cos x=\sin2x\\f''(x)=(\sin2x)'=\cos2x(2x)'=2\cos2x\\f'''(x)=(2\cos 2x)'=2(\cos2x)'=-4\sin 2x\\f^{(4)}(x)=-8\cos2x n n,"['calculus', 'derivatives']"
87,Solution verification and how to prove a function isn't integrable,Solution verification and how to prove a function isn't integrable,,"Let $H(x)=x^2\sin(\pi/x^2)$ if $x\in]0,1]$ and $H(0)=0$ . Show that $H'(x)=h(x)$ exists for all $x\in[0,1]$ . Also, show that $H'$ is not Riemann integrable in $[0,1]$ . This way, $h$ has an anti derivative in $[0,1]$ but it isn't Riemann integrable in said interval. Finally, show that $\lim_{a\to 0+}\int_{a}^{1}h(x)dx$ exists. I think I was able to prove $H'(x)=h(x)$ exists for all $x\in[0,1]$ . My attempt: If $x=0$ $$\lim_{a\to 0}\frac{H(0+a)-H(0)}{a}$$ $$=\lim_{a\to 0} a\sin(\pi/a^2)=0,$$ using $|\sin(\beta)|\leq 1$ and squeeze theorem. So, $H'(0)=0$ Now, for $x\in(0,1]$ we have that $$\frac{d}{dx}\left(x^2\sin(\pi/x^2)\right)$$ $$=2x\sin(\pi/x^2)-\frac{2\pi\cos(\pi/x^2)}{x}.$$ Is my attempt correct? Does it prove what I was asked? Also, how can I do the rest of the exercise? I honestly don't know how to prove that $H'$ isn't integrable in $[0,1]$ or that $\lim_{a\to 0+}\int_{a}^{1}h(x)dx$ exists. Isn't the function $$h(x)=H'(x)=2x\sin(\pi/x^2)-\frac{2\pi\cos(\pi/x^2)}{x}$$ if $x\in(0,1],$ $$H'(0)=0$$ bounded? Thanks in advance.","Let if and . Show that exists for all . Also, show that is not Riemann integrable in . This way, has an anti derivative in but it isn't Riemann integrable in said interval. Finally, show that exists. I think I was able to prove exists for all . My attempt: If using and squeeze theorem. So, Now, for we have that Is my attempt correct? Does it prove what I was asked? Also, how can I do the rest of the exercise? I honestly don't know how to prove that isn't integrable in or that exists. Isn't the function if bounded? Thanks in advance.","H(x)=x^2\sin(\pi/x^2) x\in]0,1] H(0)=0 H'(x)=h(x) x\in[0,1] H' [0,1] h [0,1] \lim_{a\to 0+}\int_{a}^{1}h(x)dx H'(x)=h(x) x\in[0,1] x=0 \lim_{a\to 0}\frac{H(0+a)-H(0)}{a} =\lim_{a\to 0} a\sin(\pi/a^2)=0, |\sin(\beta)|\leq 1 H'(0)=0 x\in(0,1] \frac{d}{dx}\left(x^2\sin(\pi/x^2)\right) =2x\sin(\pi/x^2)-\frac{2\pi\cos(\pi/x^2)}{x}. H' [0,1] \lim_{a\to 0+}\int_{a}^{1}h(x)dx h(x)=H'(x)=2x\sin(\pi/x^2)-\frac{2\pi\cos(\pi/x^2)}{x} x\in(0,1], H'(0)=0","['real-analysis', 'calculus', 'derivatives', 'solution-verification', 'riemann-integration']"
88,Geometric proof for derivative of $f(x)=\sqrt{x}$,Geometric proof for derivative of,f(x)=\sqrt{x},"Using a square of  area $x$ , we obtain $$dx = (2\sqrt{x})d\sqrt{x}+(d\sqrt{x})^2$$ $$\frac{d\sqrt{x}}{dx} = \frac{1}{2 \sqrt{x}} - \frac{(d\sqrt{x})^2}{2\sqrt{x}dx}$$ How do I show that $\frac{(d\sqrt{x})^2}{2\sqrt{x}dx} \rightarrow 0$ as $dx\rightarrow0$ ?","Using a square of  area , we obtain How do I show that as ?",x dx = (2\sqrt{x})d\sqrt{x}+(d\sqrt{x})^2 \frac{d\sqrt{x}}{dx} = \frac{1}{2 \sqrt{x}} - \frac{(d\sqrt{x})^2}{2\sqrt{x}dx} \frac{(d\sqrt{x})^2}{2\sqrt{x}dx} \rightarrow 0 dx\rightarrow0,"['calculus', 'derivatives']"
89,Derivative of an implicit trigonometric function,Derivative of an implicit trigonometric function,,"I was doing my homework which included finding the derivative of implicit function. One of them was $$3\sin(xy)+ 4\cos(xy) = 5$$ On first attempt I did this as follows $$\frac{d}{dx}(3\sin(xy)+ 4\cos(xy)) = \frac{d}{dx}(5)$$ $$[3\cos(xy)-4\sin(xy)][y+x\frac{dy}{dx}] = 0$$ $$\frac{dy}{dx}= \frac{-y}{x}$$ It matched the answer and I was happy. I don't know why but I wrote the original expression as this $$\frac{3}{5}\sin(xy)+ \frac{4}{5}\cos(xy) = 1$$ $$\cos(\alpha)\sin(xy)+ \sin(\alpha)\cos(xy) = 1$$ $$\sin(xy +\alpha)=1 \quad \quad \textrm{where} \quad\alpha = \arccos(\frac{3}{5})$$ Again from step 2 of finding derivative, $$[3\cos(xy)-4\sin(xy)][y+x\frac{dy}{dx}] = 0$$ $$[\frac{3}{5}\cos(xy)-\frac{4}{5}\sin(xy)][y+x\frac{dy}{dx}] = 0$$ $$[\cos(\alpha)\cos(xy)-\sin(\alpha)\sin(xy)][y+x\frac{dy}{dx}] = 0$$ $$[\cos(xy +\alpha)][y+x\frac{dy}{dx}] = 0$$ Since $\sin(xy +\alpha) =1 \implies \cos(xy+\alpha)=0$ what did in finding the derivate while going from step 2 to 3 was diving by zero which is not valid. So I cannot actually conclude that the derivative is $\frac{-y}{x}$ . But then why is the answer right(wolfram alpha says this too)? Is there any other way of finding this derivate? Thank you in advance.","I was doing my homework which included finding the derivative of implicit function. One of them was On first attempt I did this as follows It matched the answer and I was happy. I don't know why but I wrote the original expression as this Again from step 2 of finding derivative, Since what did in finding the derivate while going from step 2 to 3 was diving by zero which is not valid. So I cannot actually conclude that the derivative is . But then why is the answer right(wolfram alpha says this too)? Is there any other way of finding this derivate? Thank you in advance.",3\sin(xy)+ 4\cos(xy) = 5 \frac{d}{dx}(3\sin(xy)+ 4\cos(xy)) = \frac{d}{dx}(5) [3\cos(xy)-4\sin(xy)][y+x\frac{dy}{dx}] = 0 \frac{dy}{dx}= \frac{-y}{x} \frac{3}{5}\sin(xy)+ \frac{4}{5}\cos(xy) = 1 \cos(\alpha)\sin(xy)+ \sin(\alpha)\cos(xy) = 1 \sin(xy +\alpha)=1 \quad \quad \textrm{where} \quad\alpha = \arccos(\frac{3}{5}) [3\cos(xy)-4\sin(xy)][y+x\frac{dy}{dx}] = 0 [\frac{3}{5}\cos(xy)-\frac{4}{5}\sin(xy)][y+x\frac{dy}{dx}] = 0 [\cos(\alpha)\cos(xy)-\sin(\alpha)\sin(xy)][y+x\frac{dy}{dx}] = 0 [\cos(xy +\alpha)][y+x\frac{dy}{dx}] = 0 \sin(xy +\alpha) =1 \implies \cos(xy+\alpha)=0 \frac{-y}{x},"['calculus', 'derivatives', 'implicit-differentiation']"
90,Determining if a function is uniform continuous based on information of the limit of its derivative,Determining if a function is uniform continuous based on information of the limit of its derivative,,"I'm studying real analysis more specifically derivative functions from $\mathbb{R}$ to $\mathbb{R}$ . I'm struggling a bit between the relation of the derivative of a function and the function itself. For example let's say we have a function $$f:\mathbb{R}^+ \rightarrow \mathbb{R}$$ which is derivable and for which $\lim_{x \to \infty}f'(x) = 1$ . Can we using this info determine if the function is uniformly continuous on $\mathbb{R}$ ? I started of by noticing that for such function the $\lim_{x \to \infty}f(x) = \infty$ and also that if I can somehow show the derivative function is bounded that we can easily conclude that the function is indeed uniformly continuous. Now I don't now how to proceed with this. I could maybe say that if the derivative function is also continuous that is should be bounded? Or maybe because of the fact that we don't know if the derivative function is continuous we can't really say it is bounded and thus we can't conclude if f is uniformly continuous, but in this case and in general I can't find a counter-example. Any tips on how to furthur proceed with this problem would be greatly appreciated :)) P.S: $\mathbb{R}^+ = [0,\infty)$","I'm studying real analysis more specifically derivative functions from to . I'm struggling a bit between the relation of the derivative of a function and the function itself. For example let's say we have a function which is derivable and for which . Can we using this info determine if the function is uniformly continuous on ? I started of by noticing that for such function the and also that if I can somehow show the derivative function is bounded that we can easily conclude that the function is indeed uniformly continuous. Now I don't now how to proceed with this. I could maybe say that if the derivative function is also continuous that is should be bounded? Or maybe because of the fact that we don't know if the derivative function is continuous we can't really say it is bounded and thus we can't conclude if f is uniformly continuous, but in this case and in general I can't find a counter-example. Any tips on how to furthur proceed with this problem would be greatly appreciated :)) P.S:","\mathbb{R} \mathbb{R} f:\mathbb{R}^+ \rightarrow \mathbb{R} \lim_{x \to \infty}f'(x) = 1 \mathbb{R} \lim_{x \to \infty}f(x) = \infty \mathbb{R}^+ = [0,\infty)","['real-analysis', 'derivatives', 'uniform-continuity']"
91,"Spivak, Ch. 15, Trigonometric Functions"", Proof of $\arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha \sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}$.","Spivak, Ch. 15, Trigonometric Functions"", Proof of .",\arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha \sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})},"The following problem is from Chapter 15 ""Trigonometric Functions"" from Spivak's Calculus Prove that $$\arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha  \sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}$$ indicating any restrictions on $\alpha$ and $\beta$ . My question is about the restrictions on $\alpha$ and $\beta$ . I will show the solution from the solution manual first, and then specify my question. Here is the solution manual solution From the addition formula for $\sin$ we obtain, for $|\alpha|\leq 1$ and $|\beta|\leq 1$ , $$\sin{(\arcsin{\alpha}+\arcsin{\beta})}=\sin{(\arcsin{\alpha})\cos{(\arcsin{\beta})}}+\cos{(\arcsin{\alpha})\sin{(\arcsin{\beta})}}$$ $$=\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2}$$ Note that though it is not mentioned a significant step is taken in showing that $$\cos{(\arcsin{x})}=\sqrt{1-x^2}$$ This is done by computing the derivative of $\sin(x)$ as the reciprocal of the derivative of $\arcsin$ at $\sin{x}$ . Consequently $$\arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}\tag{1}$$ provided that $-\pi/2\leq\arcsin{\alpha}+\arcsin{\beta}\leq\pi/2$ . [If $\pi/2<\arcsin{\alpha}+\arcsin{\beta}\leq \pi$ , the right side must be replaced with $\pi-\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}$ , and if $-\pi\leq \arcsin{\alpha}+\arcsin{\beta}\leq -\pi/2$ , replaced with $-\pi-\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}$ .] My question is about the last paragraph. Let's start at the point where we have $$\sin{(\arcsin{\alpha}+\arcsin{\beta})}=\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2}$$ and we want to take the $\arcsin$ of each side to obtain $(1)$ . Now, $\arcsin{\alpha}$ and $\arcsin{\beta}$ are each in $(-\pi/2, \pi/2)$ . Their sum is in $(-\pi, \pi)$ , and the whole left expression is thus in $[-1,1]$ . $\pm 1$ occur when $\arcsin{\alpha}+\arcsin{\beta}=\pm \frac{\pi}{2}$ . If one of these two cases occurs, then $\arcsin$ isn't defined for $\sin{(\arcsin{\alpha}+\arcsin{\beta})}=\pm 1$ . EDIT: the sentence above is is incorrect. I confused $\arcsin$ with its derivative $\arcsin'$ . So my first question is about the following snippet of the solution manual solution provided that $-\pi/2\leq\arcsin{\alpha}+\arcsin{\beta}\leq\pi/2$ where the values $\pi/2$ and $-\pi/2$ are included in the possibilities. Are these values really allowed? EDIT: given the first edit above, yes, these values are allowed. My second question is about the discussion when $\pi/2<\arcsin{\alpha}+\arcsin{\beta}\leq \pi$ or $-\pi\leq \arcsin{\alpha}+\arcsin{\beta}\leq -\pi/2$ . What is happening in these cases, I don't know what Spivak's solution manual did there.","The following problem is from Chapter 15 ""Trigonometric Functions"" from Spivak's Calculus Prove that indicating any restrictions on and . My question is about the restrictions on and . I will show the solution from the solution manual first, and then specify my question. Here is the solution manual solution From the addition formula for we obtain, for and , Note that though it is not mentioned a significant step is taken in showing that This is done by computing the derivative of as the reciprocal of the derivative of at . Consequently provided that . [If , the right side must be replaced with , and if , replaced with .] My question is about the last paragraph. Let's start at the point where we have and we want to take the of each side to obtain . Now, and are each in . Their sum is in , and the whole left expression is thus in . occur when . If one of these two cases occurs, then isn't defined for . EDIT: the sentence above is is incorrect. I confused with its derivative . So my first question is about the following snippet of the solution manual solution provided that where the values and are included in the possibilities. Are these values really allowed? EDIT: given the first edit above, yes, these values are allowed. My second question is about the discussion when or . What is happening in these cases, I don't know what Spivak's solution manual did there.","\arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha
 \sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})} \alpha \beta \alpha \beta \sin |\alpha|\leq 1 |\beta|\leq 1 \sin{(\arcsin{\alpha}+\arcsin{\beta})}=\sin{(\arcsin{\alpha})\cos{(\arcsin{\beta})}}+\cos{(\arcsin{\alpha})\sin{(\arcsin{\beta})}} =\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2} \cos{(\arcsin{x})}=\sqrt{1-x^2} \sin(x) \arcsin \sin{x} \arcsin{\alpha}+\arcsin{\beta}=\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})}\tag{1} -\pi/2\leq\arcsin{\alpha}+\arcsin{\beta}\leq\pi/2 \pi/2<\arcsin{\alpha}+\arcsin{\beta}\leq \pi \pi-\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})} -\pi\leq \arcsin{\alpha}+\arcsin{\beta}\leq -\pi/2 -\pi-\arcsin{(\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2})} \sin{(\arcsin{\alpha}+\arcsin{\beta})}=\alpha\sqrt{1-\beta^2}+\beta\sqrt{1-\alpha^2} \arcsin (1) \arcsin{\alpha} \arcsin{\beta} (-\pi/2, \pi/2) (-\pi, \pi) [-1,1] \pm 1 \arcsin{\alpha}+\arcsin{\beta}=\pm \frac{\pi}{2} \arcsin \sin{(\arcsin{\alpha}+\arcsin{\beta})}=\pm 1 \arcsin \arcsin' -\pi/2\leq\arcsin{\alpha}+\arcsin{\beta}\leq\pi/2 \pi/2 -\pi/2 \pi/2<\arcsin{\alpha}+\arcsin{\beta}\leq \pi -\pi\leq \arcsin{\alpha}+\arcsin{\beta}\leq -\pi/2","['calculus', 'integration', 'derivatives', 'proof-explanation', 'inverse-function']"
92,how do you calculate a derivative with respect to another derivative,how do you calculate a derivative with respect to another derivative,,I just learned some basics principles in Lagrangian mechanics and theres this equation $$\frac{d}{dt}\left(\frac{dL}{d(\frac{dx}{dt})}\right)=\frac{dl}{dx}$$ where $l$ is kinetic energy-potential energy and therefore is a function of $x$ and $t$ . What I don't get is how you solve and simplify the $\frac{d}{d(\frac{dx}{dt})}$ part because  it has a derivative at the bottom instead of a variable. When doing some expamples for the lagrangian equation I came across some examples that said that $\frac{d{x}}{d(\frac{dx}{dt})}=0$ . Shouldn't that equal to $0$ only if $x$ is independant of $\frac{dx}{dt}$ ? I feel like I'm missing something significant here... so any help would be much appreciated. Thanks in advance,I just learned some basics principles in Lagrangian mechanics and theres this equation where is kinetic energy-potential energy and therefore is a function of and . What I don't get is how you solve and simplify the part because  it has a derivative at the bottom instead of a variable. When doing some expamples for the lagrangian equation I came across some examples that said that . Shouldn't that equal to only if is independant of ? I feel like I'm missing something significant here... so any help would be much appreciated. Thanks in advance,\frac{d}{dt}\left(\frac{dL}{d(\frac{dx}{dt})}\right)=\frac{dl}{dx} l x t \frac{d}{d(\frac{dx}{dt})} \frac{d{x}}{d(\frac{dx}{dt})}=0 0 x \frac{dx}{dt},"['derivatives', 'partial-differential-equations', 'partial-derivative', 'euler-lagrange-equation']"
93,Norm of vector in directional derivate,Norm of vector in directional derivate,,"Reading about the derivatives according to a direction, I found a definition saying that the norm of the vector v in the formula $\nabla_{\mathbf{v}}{f}(\mathbf{x}) = \lim_{h \to 0}{\frac{f(\mathbf{x} + h\mathbf{v}) - f(\mathbf{x})}{h}}$ must necessarily be 1. Why is this needed? If the vector norm is different, what happens?","Reading about the derivatives according to a direction, I found a definition saying that the norm of the vector v in the formula must necessarily be 1. Why is this needed? If the vector norm is different, what happens?",\nabla_{\mathbf{v}}{f}(\mathbf{x}) = \lim_{h \to 0}{\frac{f(\mathbf{x} + h\mathbf{v}) - f(\mathbf{x})}{h}},"['derivatives', 'partial-derivative']"
94,How to compute the limit $\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}$?,How to compute the limit ?,\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}},"My question is simply how do we compute the limit $\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}$ ? For context on where this came from, consider the following problem. Spivak, Chapter 11, problem 18: Ecological Ed must cross a circular lake of radius 1 mile. He can row across at 2mph or walk around at 4mph, or he can row part way and walk the rest. What route should he take so as to i) see as much scenery as possible i) seems to be asking what the longest path is. The solution manual says that this is obviously the going around the semicircle, ie walking around. I'd like to prove this. $$a^2=c^2+d^2$$ $$d=\sqrt{a^2-c^2}$$ $$r^2=c^2+(a+d)^2$$ $$=2a^2+2a\sqrt{a^2-c^2}$$ $$\sin{\alpha}=\frac{c}{a} \implies c =a\sin{\alpha}$$ Therefore $$r^2(\alpha)=2a^2+2a\sqrt{a^2-a^2\sin^2{\alpha}}$$ $$=2a^2(1+\sqrt{1-\sin^2{\alpha}})$$ $$=2a^2(1+\cos{\alpha})$$ Also $$w(\alpha)=\alpha a$$ The total distance is therefore $$l(\alpha)=r(\alpha)+w(\alpha)$$ $$=a\sqrt{2(1+\cos{\alpha}} +a\alpha$$ $$=a(\alpha+\sqrt{2(1+\cos{\alpha}})$$ Taking the derivative $$l'(\alpha)=a(1+\frac{-2\sin{\alpha}}{2\sqrt{2(1+\cos{\alpha}})}), \alpha \neq \pi$$ $$=a(1-\frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}), \alpha \neq \pi$$ $$l'(\alpha)=0 \implies \sin{\alpha}=\sqrt{2(1+\cos{\alpha})}, \alpha \neq \pi$$ If we square both sides $$\sin^2{\alpha}=2(1+\cos{\alpha}$$ $$1-\cos^2{\alpha}=2(1+\cos{\alpha})$$ $$\cos^2{\alpha}+2\cos{\alpha}+1=0$$ $$\Delta=4-4=0$$ $$\cos{\alpha}=\frac{-2}{2}=-1$$ $$\alpha=\pi$$ Therefore, since $l'$ isn't defined at $\pi$ , this isn't a critical point. In fact we can see that for $\alpha \in [0,\pi)$ , $l'>0$ . This would seem to indicate that the longest trajectory is at $\pi$ , one of the endpoints of the domain of $l$ . $$l(\pi)=\pi a = \frac{2\pi a}{2}$$ which makes sense. (note that $l(0)=2a$ ). I am curious about what happens to $l'$ when $\alpha$ approaches $\pi$ . To that end, I need to compute the limit $$\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}$$ But how? L'Hopital doesn't seem to work. EDIT: My calculations, based on the hint given by Christophe Leuridan: $$1+\cos{\alpha}=2\cos^2{\alpha/2}$$ $$\sin{\alpha}=2\sin{\alpha/2}\cos{\alpha/2}$$ $$\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}$$ $$=\lim\limits_{\alpha \to \pi} \frac{2\sin{\alpha/2}\cos{\alpha/2}}{\sqrt{2 \cdot 2\cos^2{\alpha/2}}}$$ $$=\lim\limits_{\alpha \to \pi} \sin{\alpha/2}$$ $$\sin{\pi/2}$$ $$=1$$ EDIT: The above calculations are incorrect, since I incorrectly cancelled $\cos{\alpha/2}$ with $|\cos{\alpha/2}|$ . See comment below for correct version, the result of which is that the limit doesn't exist.","My question is simply how do we compute the limit ? For context on where this came from, consider the following problem. Spivak, Chapter 11, problem 18: Ecological Ed must cross a circular lake of radius 1 mile. He can row across at 2mph or walk around at 4mph, or he can row part way and walk the rest. What route should he take so as to i) see as much scenery as possible i) seems to be asking what the longest path is. The solution manual says that this is obviously the going around the semicircle, ie walking around. I'd like to prove this. Therefore Also The total distance is therefore Taking the derivative If we square both sides Therefore, since isn't defined at , this isn't a critical point. In fact we can see that for , . This would seem to indicate that the longest trajectory is at , one of the endpoints of the domain of . which makes sense. (note that ). I am curious about what happens to when approaches . To that end, I need to compute the limit But how? L'Hopital doesn't seem to work. EDIT: My calculations, based on the hint given by Christophe Leuridan: EDIT: The above calculations are incorrect, since I incorrectly cancelled with . See comment below for correct version, the result of which is that the limit doesn't exist.","\lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}} a^2=c^2+d^2 d=\sqrt{a^2-c^2} r^2=c^2+(a+d)^2 =2a^2+2a\sqrt{a^2-c^2} \sin{\alpha}=\frac{c}{a} \implies c =a\sin{\alpha} r^2(\alpha)=2a^2+2a\sqrt{a^2-a^2\sin^2{\alpha}} =2a^2(1+\sqrt{1-\sin^2{\alpha}}) =2a^2(1+\cos{\alpha}) w(\alpha)=\alpha a l(\alpha)=r(\alpha)+w(\alpha) =a\sqrt{2(1+\cos{\alpha}} +a\alpha =a(\alpha+\sqrt{2(1+\cos{\alpha}}) l'(\alpha)=a(1+\frac{-2\sin{\alpha}}{2\sqrt{2(1+\cos{\alpha}})}), \alpha \neq \pi =a(1-\frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}}), \alpha \neq \pi l'(\alpha)=0 \implies \sin{\alpha}=\sqrt{2(1+\cos{\alpha})}, \alpha \neq \pi \sin^2{\alpha}=2(1+\cos{\alpha} 1-\cos^2{\alpha}=2(1+\cos{\alpha}) \cos^2{\alpha}+2\cos{\alpha}+1=0 \Delta=4-4=0 \cos{\alpha}=\frac{-2}{2}=-1 \alpha=\pi l' \pi \alpha \in [0,\pi) l'>0 \pi l l(\pi)=\pi a = \frac{2\pi a}{2} l(0)=2a l' \alpha \pi \lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}} 1+\cos{\alpha}=2\cos^2{\alpha/2} \sin{\alpha}=2\sin{\alpha/2}\cos{\alpha/2} \lim\limits_{\alpha \to \pi} \frac{\sin{\alpha}}{\sqrt{2(1+\cos{\alpha})}} =\lim\limits_{\alpha \to \pi} \frac{2\sin{\alpha/2}\cos{\alpha/2}}{\sqrt{2 \cdot 2\cos^2{\alpha/2}}} =\lim\limits_{\alpha \to \pi} \sin{\alpha/2} \sin{\pi/2} =1 \cos{\alpha/2} |\cos{\alpha/2}|","['calculus', 'limits', 'derivatives']"
95,Question regarding complex differentiability,Question regarding complex differentiability,,"I have been introduced to a new understanding of the differentiability of a complex function, which is: $f$ is $C$ -differentiable at $z_0$ iff we canfind a complex number $\alpha$ and a continuous function $R:\mathbb{D}\to\mathbb{C}$ , where $D\subset C$ is a suitably small neighborhood of $0$ such that $R(0)=0$ and $f(a+h)=f(a)+\alpha h+hR(h)$ . I want to prove this claim. I can prove that if $f$ is differentiable, it will meet the above condition, but I have trouble proving the converse. Any help or guidance you could give would be greatly appreciated.","I have been introduced to a new understanding of the differentiability of a complex function, which is: is -differentiable at iff we canfind a complex number and a continuous function , where is a suitably small neighborhood of such that and . I want to prove this claim. I can prove that if is differentiable, it will meet the above condition, but I have trouble proving the converse. Any help or guidance you could give would be greatly appreciated.",f C z_0 \alpha R:\mathbb{D}\to\mathbb{C} D\subset C 0 R(0)=0 f(a+h)=f(a)+\alpha h+hR(h) f,"['complex-analysis', 'derivatives']"
96,"For an arbitrary continuous $\mathbb{R}\to\mathbb{R}$, how to show that a certain Borel set is contained in the set of finite differentiability?","For an arbitrary continuous , how to show that a certain Borel set is contained in the set of finite differentiability?",\mathbb{R}\to\mathbb{R},"I am working on a more detailed version of a proof that has appeared on Math Stack before. Requests for a proof of the following theorem have been posted several times, but I am asking about the specific strategy suggested in (1) below. Theorem. Let $f$ be any real-valued, continuous function with domain $\mathbb{R}$ . Then $\Delta(f) := \{x\in \mathbb{R}: f'(x) \in \mathbb{R}\}$ is Borel measurable. In other words, the set of points of finite differentiability belongs to the sigma-algebra generated by the closed sets. I am trying to flesh out the proof given in (1) Show that $\Delta(f)$ is a $F_{\sigma\delta}$ -set , where it is suggested that $\Delta(f)$ is exactly $$S\,=\,\bigcap_{k=1}^{\infty} \;\bigcup_{n=1}^{\infty} \;\; \bigcap_{0 < |\eta| < \frac{1}{n}} \;\; \bigcap_{0 < |\delta| < \frac{1}{n}} \; \left\{x:\;\; \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right| \; \leq \frac{1}{k}\right\}.$$ I have showed that $\Delta(f)$ is a subset of the above set; I outline the reasoning below. For any fixed and non-zero $\eta$ and $\delta$ , the function $$x \mapsto \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right|$$ is continuous, so that the set $\{x: \cdots\}$ appearing above is closed, being a continuous pre-image of a closed set. So if $S=\Delta(f)$ the theorem is proved. What I am stuck on is showing $S\subset \Delta(f)$ . Set $S$ doesn't ""know"" about the value of the derivative, which is why I think it is harder. It seems (from looking at other approaches posted) that we need to pass to the rationals ( maybe something like this: https://math.stackexchange.com/a/1395360 ), or build a Cauchy sequence, or a sequence of nested compacts. It makes me wonder, more generally, about sufficient conditions for differentiability at $x_0$ that do not involve pre-knowledge of $f'(x_0)$ . What is a good way to rigorously show the inclusion $S\subset \Delta(f)\,$ ? Sketch of proof that $\Delta(f)\subset S$ : Let $x \in \Delta(f)$ , and let $k\geqslant 1$ be fixed. Let $\epsilon = 1/k>0.$ Let $t=f'(x)$ . $\exists n\geqslant 1,$ $$\left| \frac{f(x + \eta) - f(x)}{\eta} -t \right| \; \leqslant \; \frac{\epsilon}{2} \;\text{ whenever }\; 0 \lt |\eta|\lt \frac1n.$$ From here it is just a matter of applying the triangle inequality: $$\left| \frac{f(x + \eta) - f(x)}{\eta} -  \frac{f(x + \delta) - f(x)}{\delta} \right|  $$ $$\leqslant \left| \frac{f(x + \eta) - f(x)}{\eta} - t\right| + \left| \frac{f(x + \delta) - f(x)}{\delta} -t \right|  \leqslant \epsilon=\frac{1}{k}.$$","I am working on a more detailed version of a proof that has appeared on Math Stack before. Requests for a proof of the following theorem have been posted several times, but I am asking about the specific strategy suggested in (1) below. Theorem. Let be any real-valued, continuous function with domain . Then is Borel measurable. In other words, the set of points of finite differentiability belongs to the sigma-algebra generated by the closed sets. I am trying to flesh out the proof given in (1) Show that is a -set , where it is suggested that is exactly I have showed that is a subset of the above set; I outline the reasoning below. For any fixed and non-zero and , the function is continuous, so that the set appearing above is closed, being a continuous pre-image of a closed set. So if the theorem is proved. What I am stuck on is showing . Set doesn't ""know"" about the value of the derivative, which is why I think it is harder. It seems (from looking at other approaches posted) that we need to pass to the rationals ( maybe something like this: https://math.stackexchange.com/a/1395360 ), or build a Cauchy sequence, or a sequence of nested compacts. It makes me wonder, more generally, about sufficient conditions for differentiability at that do not involve pre-knowledge of . What is a good way to rigorously show the inclusion ? Sketch of proof that : Let , and let be fixed. Let Let . From here it is just a matter of applying the triangle inequality:","f \mathbb{R} \Delta(f) := \{x\in \mathbb{R}: f'(x) \in \mathbb{R}\} \Delta(f) F_{\sigma\delta} \Delta(f) S\,=\,\bigcap_{k=1}^{\infty} \;\bigcup_{n=1}^{\infty} \;\; \bigcap_{0 < |\eta| < \frac{1}{n}} \;\; \bigcap_{0 < |\delta| < \frac{1}{n}} \; \left\{x:\;\; \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right| \; \leq \frac{1}{k}\right\}. \Delta(f) \eta \delta x \mapsto \left| \frac{f(x + \eta) - f(x)}{\eta} \; - \;  \frac{f(x + \delta) - f(x)}{\delta} \right| \{x: \cdots\} S=\Delta(f) S\subset \Delta(f) S x_0 f'(x_0) S\subset \Delta(f)\, \Delta(f)\subset S x \in \Delta(f) k\geqslant 1 \epsilon = 1/k>0. t=f'(x) \exists n\geqslant 1, \left| \frac{f(x + \eta) - f(x)}{\eta} -t \right| \; \leqslant \; \frac{\epsilon}{2} \;\text{ whenever }\; 0 \lt |\eta|\lt \frac1n. \left| \frac{f(x + \eta) - f(x)}{\eta} -  \frac{f(x + \delta) - f(x)}{\delta} \right|   \leqslant \left| \frac{f(x + \eta) - f(x)}{\eta} - t\right| + \left| \frac{f(x + \delta) - f(x)}{\delta} -t \right|  \leqslant \epsilon=\frac{1}{k}.","['real-analysis', 'derivatives', 'continuity', 'borel-sets']"
97,Partial Derivative of Hadamard Root (elements-wise square root),Partial Derivative of Hadamard Root (elements-wise square root),,"Given $\mathbf{X} \in \mathbb{R}^{n \times 1}$ , $\mathbf{A} \in \mathbb{R}^{n \times n}$ , the function is $\mathbf{f}=\sqrt{\mathbf{A} \mathbf{X} \odot \mathbf{A} \mathbf{X}}$ , where $\sqrt{(\cdot)}$ is Hadamard root (elements-wise square root), and $(\cdot) \odot (\cdot)$ is the Hadamard Product . How to compute $\frac{\partial \mathbf{f}}{\partial \mathbf{X}}$ ? I have tried to follow this similar question and answer to solve my problem, but the function of that question is Frobenius inner product, which is different with mine so can not solve in that way. Thanks in advance!","Given , , the function is , where is Hadamard root (elements-wise square root), and is the Hadamard Product . How to compute ? I have tried to follow this similar question and answer to solve my problem, but the function of that question is Frobenius inner product, which is different with mine so can not solve in that way. Thanks in advance!",\mathbf{X} \in \mathbb{R}^{n \times 1} \mathbf{A} \in \mathbb{R}^{n \times n} \mathbf{f}=\sqrt{\mathbf{A} \mathbf{X} \odot \mathbf{A} \mathbf{X}} \sqrt{(\cdot)} (\cdot) \odot (\cdot) \frac{\partial \mathbf{f}}{\partial \mathbf{X}},"['linear-algebra', 'matrices', 'derivatives', 'partial-derivative', 'matrix-calculus']"
98,Differentiability on $\mathbb{R}^n$ under an equivalence relation.,Differentiability on  under an equivalence relation.,\mathbb{R}^n,"Let $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ be differentiable. Given an equivalence relation $\sim$ on $\mathbb{R}^n$ , is $f:\mathbb{R}^n/\sim \rightarrow \mathbb{R}^n/\sim$ also differentiable? The question that made me consider this is as follows: Given the 2-sphere $\mathbb{S}^2$ (as a manifold), consider the stereographic projection defined in the usual way, e.g. from the 'South pole' as \begin{align} P_S:\mathbb{S}^2\setminus (0,0,-1) &\longrightarrow \mathbb{R}^2 \\ (x, y, z) &\longmapsto (\frac{x}{1+z}, \frac{y}{1+z}). \end{align} With a similarly defined maps $P_N$ for the 'North pole', this gives us an atlas on $\mathbb{S}^2$ (they are smoothly compatible charts), and so we can talk about differentiability. Now define the equivalence relation for $x, x'\in \mathbb{S}^2$ \begin{align} x\sim x' \iff x = -x. \end{align} Now we can define \begin{align} P_S':\mathbb{S}^2\setminus (0,0,-1)/\sim &\longrightarrow \mathbb{R}^2/\sim' \\ [(x, y, z)] &\longmapsto [(\frac{x}{1+z}, \frac{y}{1+z})], \end{align} where given $(\frac{x}{1+z}, \frac{y}{1+z}), a\in \mathbb{R}^2$ , define \begin{align} (\frac{x}{1+z}, \frac{y}{1+z}) \sim' a \iff a = (-\frac{x}{1-z}, -\frac{y}{1-z}). \end{align} Together with the analogous $P_N'$ (although I don't know if this is necessary any longer, since $(0,0,-1)\sim(0,0,1)$ ), this provides charts for $\mathbb{S}^2/\sim$ . Assuming there is a function $f\in C^{\infty}(\mathbb{S}^2)$ , then if $f(x) = f(-x) \forall x\in \mathbb{S}^2$ , then it seems to me that this function would be well defined on $\mathbb{S}^2/\sim$ . i.e. define $f'\in C^{\infty}(\mathbb{S}^2/\sim):[(x, y, z)] \mapsto f(x, y, z)$ . Is this correct? And if $f$ is differentiable on $\mathbb{S}^2$ , will it be differentiable on $\mathbb{S}^2/\sim$ ?","Let be differentiable. Given an equivalence relation on , is also differentiable? The question that made me consider this is as follows: Given the 2-sphere (as a manifold), consider the stereographic projection defined in the usual way, e.g. from the 'South pole' as With a similarly defined maps for the 'North pole', this gives us an atlas on (they are smoothly compatible charts), and so we can talk about differentiability. Now define the equivalence relation for Now we can define where given , define Together with the analogous (although I don't know if this is necessary any longer, since ), this provides charts for . Assuming there is a function , then if , then it seems to me that this function would be well defined on . i.e. define . Is this correct? And if is differentiable on , will it be differentiable on ?","f:\mathbb{R}^n \rightarrow \mathbb{R}^n \sim \mathbb{R}^n f:\mathbb{R}^n/\sim \rightarrow \mathbb{R}^n/\sim \mathbb{S}^2 \begin{align}
P_S:\mathbb{S}^2\setminus (0,0,-1) &\longrightarrow \mathbb{R}^2
\\ (x, y, z) &\longmapsto (\frac{x}{1+z}, \frac{y}{1+z}).
\end{align} P_N \mathbb{S}^2 x, x'\in \mathbb{S}^2 \begin{align}
x\sim x' \iff x = -x.
\end{align} \begin{align}
P_S':\mathbb{S}^2\setminus (0,0,-1)/\sim &\longrightarrow \mathbb{R}^2/\sim'
\\ [(x, y, z)] &\longmapsto [(\frac{x}{1+z}, \frac{y}{1+z})],
\end{align} (\frac{x}{1+z}, \frac{y}{1+z}), a\in \mathbb{R}^2 \begin{align}
(\frac{x}{1+z}, \frac{y}{1+z}) \sim' a \iff a = (-\frac{x}{1-z}, -\frac{y}{1-z}).
\end{align} P_N' (0,0,-1)\sim(0,0,1) \mathbb{S}^2/\sim f\in C^{\infty}(\mathbb{S}^2) f(x) = f(-x) \forall x\in \mathbb{S}^2 \mathbb{S}^2/\sim f'\in C^{\infty}(\mathbb{S}^2/\sim):[(x, y, z)] \mapsto f(x, y, z) f \mathbb{S}^2 \mathbb{S}^2/\sim","['calculus', 'derivatives', 'continuity', 'real-numbers']"
99,Differentiability of $f(|x|)$,Differentiability of,f(|x|),"What are the rules for the differentiability of $f(|x|)$ ? In hindsight, and upon inspecting $\sin(|x|)$ and $\cos(|x|)$ , the only rule I can deduce is that $f(x)$ should not be zero at $x=0$ . But I couldn't get any polynomials for which my rule applies. So is $\cos(|x|)$ , the only possible function where $f(x)$ is differentiable at $x=0$ or are there any other polynomials too?","What are the rules for the differentiability of ? In hindsight, and upon inspecting and , the only rule I can deduce is that should not be zero at . But I couldn't get any polynomials for which my rule applies. So is , the only possible function where is differentiable at or are there any other polynomials too?",f(|x|) \sin(|x|) \cos(|x|) f(x) x=0 \cos(|x|) f(x) x=0,"['derivatives', 'trigonometry', 'polynomials']"
