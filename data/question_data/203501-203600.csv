,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How would one differentiate the exponential map?,How would one differentiate the exponential map?,,"In General Relativity if $(M,g,\nabla)$ is spacetime being $\nabla$ the Levi-Civita connection, then we can define on a geodesically convex set $U\subset M$ the map $\sigma : U\times U\to \mathbb{R}$ $$\sigma(x,y)=\dfrac{1}{2}g_x(\exp_x^{-1}(y),\exp_x^{-1}(y))$$ in other words, $\sigma(x,y)$ is a half of the geodesic distance squared between two points $x,y\in U$. Given a chart $(x,V)$ (here we are thinking that $U\subset V$), we can then consider the covariant derivative $\nabla_\mu$ with respect to $\frac{\partial}{\partial x^\mu}$. I want to compute objects like $$\nabla_\mu \sigma(x,y)$$ $$\nabla_\mu \nabla_\nu \sigma(x,y)$$ with the understanding that the derivative keeps $x$ fixed. So $x$ is a parameter here. The first derivative is obviously the partial, since $\nabla_X$ is $X$ itself on $C^\infty(M)$. The issue is that we need to differentiate $\exp_x^{-1}$ and this doesn't seem trivial. All I know about $\exp_x$ is that it is a map $\exp_x : T_x M\to U$ which given $X\in T_xM$, if $\gamma_{x,X} : I\subset\mathbb{R}\to U$ is the unique geodesic with $\gamma_{x,X}(0)=x$ and $\gamma_{x,X}'(0)=X$ then $\exp_x(X)=\gamma_{x,X}(1)$. I have no idea on how to differentiate this map, let alone its inverse. So how do we compute $\nabla_\mu \sigma(x,y)$ with $x$ fixed? How the exponential map is differentiated?","In General Relativity if $(M,g,\nabla)$ is spacetime being $\nabla$ the Levi-Civita connection, then we can define on a geodesically convex set $U\subset M$ the map $\sigma : U\times U\to \mathbb{R}$ $$\sigma(x,y)=\dfrac{1}{2}g_x(\exp_x^{-1}(y),\exp_x^{-1}(y))$$ in other words, $\sigma(x,y)$ is a half of the geodesic distance squared between two points $x,y\in U$. Given a chart $(x,V)$ (here we are thinking that $U\subset V$), we can then consider the covariant derivative $\nabla_\mu$ with respect to $\frac{\partial}{\partial x^\mu}$. I want to compute objects like $$\nabla_\mu \sigma(x,y)$$ $$\nabla_\mu \nabla_\nu \sigma(x,y)$$ with the understanding that the derivative keeps $x$ fixed. So $x$ is a parameter here. The first derivative is obviously the partial, since $\nabla_X$ is $X$ itself on $C^\infty(M)$. The issue is that we need to differentiate $\exp_x^{-1}$ and this doesn't seem trivial. All I know about $\exp_x$ is that it is a map $\exp_x : T_x M\to U$ which given $X\in T_xM$, if $\gamma_{x,X} : I\subset\mathbb{R}\to U$ is the unique geodesic with $\gamma_{x,X}(0)=x$ and $\gamma_{x,X}'(0)=X$ then $\exp_x(X)=\gamma_{x,X}(1)$. I have no idea on how to differentiate this map, let alone its inverse. So how do we compute $\nabla_\mu \sigma(x,y)$ with $x$ fixed? How the exponential map is differentiated?",,"['differential-geometry', 'riemannian-geometry', 'mathematical-physics', 'general-relativity']"
1,Relative homology group of a translation surface,Relative homology group of a translation surface,,"Let $X$ be a Riemann surface of genus $g\ge 2$, $\omega$ an holomorphic differential on $X$ and $\Sigma(\omega)$ the set of zeroes of $\omega$. We can equip $X$ with the singular flat metric $\omega\overline{\omega}$: the couple $(X,\omega\overline{\omega})$ is often called a translation surface. Consider the relative homology group $H_1(X,\Sigma(\omega),\mathbb{C})$. Let $\gamma$ be a saddle connection on $X$: by definition it is a geodesic segment for $\omega\overline{\omega}$ which encounters the points of $\Sigma(\omega)$ only at its initial and terminal points. Consider $[\gamma]\in H_1(X,\Sigma(\omega),\mathbb{C})$ (the class of $\gamma$ in the relative homology group); I know that, since the metric $\omega\overline{\omega}$ is negatively curved, $\gamma$ is the only geodesic representative of $[\gamma]$. My question is: what is the geodesic representative of $k[\gamma]$ for $k\in \mathbb{R}$?","Let $X$ be a Riemann surface of genus $g\ge 2$, $\omega$ an holomorphic differential on $X$ and $\Sigma(\omega)$ the set of zeroes of $\omega$. We can equip $X$ with the singular flat metric $\omega\overline{\omega}$: the couple $(X,\omega\overline{\omega})$ is often called a translation surface. Consider the relative homology group $H_1(X,\Sigma(\omega),\mathbb{C})$. Let $\gamma$ be a saddle connection on $X$: by definition it is a geodesic segment for $\omega\overline{\omega}$ which encounters the points of $\Sigma(\omega)$ only at its initial and terminal points. Consider $[\gamma]\in H_1(X,\Sigma(\omega),\mathbb{C})$ (the class of $\gamma$ in the relative homology group); I know that, since the metric $\omega\overline{\omega}$ is negatively curved, $\gamma$ is the only geodesic representative of $[\gamma]$. My question is: what is the geodesic representative of $k[\gamma]$ for $k\in \mathbb{R}$?",,"['general-topology', 'differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'differential-topology']"
2,Basis vectors in information geometry,Basis vectors in information geometry,,"A basis vector in the tangent space at a point of a smooth manifold is given by a differential operator such as $\partial_{i}=\cfrac{\partial }{\partial \xi^{i}}$. On the other hand, in a statistical manifold consisting of probability distributions $p(x; \pmb{\xi})$ the basis vectors can be considered to be $\partial_{i} \log{p}$ which are not differential operators. Vector fields are defined to be linear maps that satisfy the product rule. How come $X^{i}\partial_{i}\log{p}$ is considered to be a vector field on a statistical manifold? How do we reconcile the defining properties of a vector field with the choice of $\partial_{i} \log{p}$ as basis vectors?","A basis vector in the tangent space at a point of a smooth manifold is given by a differential operator such as $\partial_{i}=\cfrac{\partial }{\partial \xi^{i}}$. On the other hand, in a statistical manifold consisting of probability distributions $p(x; \pmb{\xi})$ the basis vectors can be considered to be $\partial_{i} \log{p}$ which are not differential operators. Vector fields are defined to be linear maps that satisfy the product rule. How come $X^{i}\partial_{i}\log{p}$ is considered to be a vector field on a statistical manifold? How do we reconcile the defining properties of a vector field with the choice of $\partial_{i} \log{p}$ as basis vectors?",,"['differential-geometry', 'vector-fields', 'information-geometry']"
3,Minimal surface having two plane curves as its boundary,Minimal surface having two plane curves as its boundary,,"Let $\alpha$ and $\beta$ be closed, simple plane curves contained in $\mathbb{R}^2\times\{0\}$ . For $d>0$ , define $\beta_d(t):=\beta(t)+d(0,0,1)$ , the translation of $\beta$ along the $z$ -axis. Define $$S:=\{d\in\mathbb{R}_+\mid\exists\text{ a minimal surface }\Sigma\subset\mathbb{R}^3\text{ such that }\partial\Sigma=\alpha\cup\beta_d\}$$ Prove that $\sup S<\infty$ [ hint : compare $\Sigma$ with an appropriate catenoid and use the maximum principle] I probably don't know what this hint means. I know that minimal surfaces with isothermal parametrization have harmonic coordinate functions. Is the hint suggesting to use the maximum principle for harmonic functions? How would I do that?","Let and be closed, simple plane curves contained in . For , define , the translation of along the -axis. Define Prove that [ hint : compare with an appropriate catenoid and use the maximum principle] I probably don't know what this hint means. I know that minimal surfaces with isothermal parametrization have harmonic coordinate functions. Is the hint suggesting to use the maximum principle for harmonic functions? How would I do that?","\alpha \beta \mathbb{R}^2\times\{0\} d>0 \beta_d(t):=\beta(t)+d(0,0,1) \beta z S:=\{d\in\mathbb{R}_+\mid\exists\text{ a minimal surface }\Sigma\subset\mathbb{R}^3\text{ such that }\partial\Sigma=\alpha\cup\beta_d\} \sup S<\infty \Sigma","['differential-geometry', 'surfaces', 'plane-curves', 'minimal-surfaces']"
4,When is a ruled parametrisation an actual parametrisation?,When is a ruled parametrisation an actual parametrisation?,,"I'm trying to get an answer to the following question: When is a ruled parametrization $ r(s, t) = c(s) + tv(s) : \mathbb{R}^2 \to \mathbb{R}^3 $ a parametrization? What constraints must $ c, v $ satisfy? This altogether is a vague question, so to clarify, I will assume the following definition"" A smooth map $ r : \mathbb{R}^2 \to \mathbb{R}^3 $ is called a parametrization if its derivative has rank $ 2 $ at every point This leads to the obvious observation that, in case of ruled surfaces, the following vectors: $$ \dot{c}(s) + t\dot{v}(s) \text{ and } v(s)$$ need be linearly independent. However, I am wondering if there is any deeper sense to it? How do I interpret this? I would love some feedback on it. Is this definition of parametrization the standard one?","I'm trying to get an answer to the following question: When is a ruled parametrization $ r(s, t) = c(s) + tv(s) : \mathbb{R}^2 \to \mathbb{R}^3 $ a parametrization? What constraints must $ c, v $ satisfy? This altogether is a vague question, so to clarify, I will assume the following definition"" A smooth map $ r : \mathbb{R}^2 \to \mathbb{R}^3 $ is called a parametrization if its derivative has rank $ 2 $ at every point This leads to the obvious observation that, in case of ruled surfaces, the following vectors: $$ \dot{c}(s) + t\dot{v}(s) \text{ and } v(s)$$ need be linearly independent. However, I am wondering if there is any deeper sense to it? How do I interpret this? I would love some feedback on it. Is this definition of parametrization the standard one?",,"['differential-geometry', 'surfaces', 'parametrization']"
5,Lift of symplectic form to the cotangent bundle,Lift of symplectic form to the cotangent bundle,,"Consider a symplectic manifold $(M,\omega)$ on which a Hamiltonian group action $G\curvearrowright M$ is defined. Then we have the usual canonical induced action of $G$ on $X:=T^*M$, that also preserves the fibration $\pi:X\to M$. My question is: Is there any symplectic form on $X:=T^*M$ that coincides with $\omega$ on the zero-section of $X$, that is also preserved by the induced action $G\curvearrowright X$ ? I realize that the question may seem too broad or vague, but I would very much appreciate any reference to articles or books addressing the question. Feel free to assume additional regularity on the manifold, like compactness or being Kähler.","Consider a symplectic manifold $(M,\omega)$ on which a Hamiltonian group action $G\curvearrowright M$ is defined. Then we have the usual canonical induced action of $G$ on $X:=T^*M$, that also preserves the fibration $\pi:X\to M$. My question is: Is there any symplectic form on $X:=T^*M$ that coincides with $\omega$ on the zero-section of $X$, that is also preserved by the induced action $G\curvearrowright X$ ? I realize that the question may seem too broad or vague, but I would very much appreciate any reference to articles or books addressing the question. Feel free to assume additional regularity on the manifold, like compactness or being Kähler.",,"['differential-geometry', 'reference-request', 'group-actions', 'symplectic-geometry', 'kahler-manifolds']"
6,Critical Curves of the Energy Functional are Geodesics,Critical Curves of the Energy Functional are Geodesics,,"I'd like to prove that E-critical curves of the energy functional: $$ E(\eta) = \frac 12 \int_I g(\eta'(t), \eta'(t))dt$$ satisfy the geodesic equation: $$\nabla_{\eta'} \eta' = 0$$ So the geodesic equation is as follows: $$\nabla_{v} u = \nabla_{v^{i}e_{i}} u^{j}e_{j} = v^{i}\nabla_{e_{i}} u^{j}e_{j} = v^{i}u^{j}\nabla_{e_{i}} e_{j} + v^{i}e_{j}\nabla_{e_{i}} u^{j} = v^{i}u^{j}\Gamma^{k}_{ij}e_{k} + v^{i}\frac{du^{j}}{dx^{i}}e_{j}$$ Which I've also seen as: $$\frac{d^{2}x^{k}}{ds^{2}} + \Gamma^{k}_{ij} \frac{dx^{i}}{ds} \frac{dx^{j}}{ds^{2}}$$ with: $\Gamma^{k}_{ij} = \frac 12 g^{kl}(\frac{dg_{jl}}{dx^{i}} + \frac{dg_{il}}{dx^{j}} - \frac{dg_{ij}}{dx^{l}})$ My intuition tells me that... I. First we need to show the curves, $\eta$ , satisfy the Euler-Lagrange equation and thus are critical curves II. Then we show that those curves satisfy the geodesic equation. Correct? If this is correct then I just need some help with... i.) When we say $\eta$ is a critical curve what does that tell us about $\eta$ that is useful in solving the geodesic equation? I mean we can just say $\eta$ is an arbitrary function that solves the EL equations but since we're doing this in general we need not give an explicit form for $\eta$ . I'm just confused on how to proceed. ii. I actually solving the geodesic equation I could use a little assistance too. Since we are on an arbitrary (wrt dimension specifically) manifold we can't say how many components of $\eta$ there are or how many basis vectors there are so there must be other properties endowed to $\eta$ (perhaps based on being a critical curve of the energy functional) which suggest to us that say it's 2nd deriv is equal to zero for all components or the connection on the manifold (cristoffel symbols) are always zero for this reason or that reason. Any help is greatly appreciated.","I'd like to prove that E-critical curves of the energy functional: satisfy the geodesic equation: So the geodesic equation is as follows: Which I've also seen as: with: My intuition tells me that... I. First we need to show the curves, , satisfy the Euler-Lagrange equation and thus are critical curves II. Then we show that those curves satisfy the geodesic equation. Correct? If this is correct then I just need some help with... i.) When we say is a critical curve what does that tell us about that is useful in solving the geodesic equation? I mean we can just say is an arbitrary function that solves the EL equations but since we're doing this in general we need not give an explicit form for . I'm just confused on how to proceed. ii. I actually solving the geodesic equation I could use a little assistance too. Since we are on an arbitrary (wrt dimension specifically) manifold we can't say how many components of there are or how many basis vectors there are so there must be other properties endowed to (perhaps based on being a critical curve of the energy functional) which suggest to us that say it's 2nd deriv is equal to zero for all components or the connection on the manifold (cristoffel symbols) are always zero for this reason or that reason. Any help is greatly appreciated."," E(\eta) = \frac 12 \int_I g(\eta'(t), \eta'(t))dt \nabla_{\eta'} \eta' = 0 \nabla_{v} u = \nabla_{v^{i}e_{i}} u^{j}e_{j} = v^{i}\nabla_{e_{i}} u^{j}e_{j} = v^{i}u^{j}\nabla_{e_{i}} e_{j} + v^{i}e_{j}\nabla_{e_{i}} u^{j} = v^{i}u^{j}\Gamma^{k}_{ij}e_{k} + v^{i}\frac{du^{j}}{dx^{i}}e_{j} \frac{d^{2}x^{k}}{ds^{2}} + \Gamma^{k}_{ij} \frac{dx^{i}}{ds} \frac{dx^{j}}{ds^{2}} \Gamma^{k}_{ij} = \frac 12 g^{kl}(\frac{dg_{jl}}{dx^{i}} + \frac{dg_{il}}{dx^{j}} - \frac{dg_{ij}}{dx^{l}}) \eta \eta \eta \eta \eta \eta \eta","['differential-geometry', 'manifolds', 'riemannian-geometry', 'calculus-of-variations', 'geodesic']"
7,Determining parametrization of curve from its acceleration,Determining parametrization of curve from its acceleration,,"I am doing a project in which I have an object experiencing acceleration in a direction changing with time. I know the along-track and transverse acceleration components $a_{||}(t)$ and $a_{\perp}(t)$ in the comoving frame of the object, but not in an inertial reference frame. As time passes $a_{\perp}(t)$ increases while $a_{||}(t)$ decreases, so I expect the motion of the object to be a spiral in an inertial reference frame, and it is a parametrization of this spiral I am looking for. I have attempted to describe the curvature by $\kappa(t) = \frac{v(t)^{2}}{a_{\perp}(t)}$, where $v(t) = \sqrt{a_{\perp}(t)^{2} + a_{||}(t)^{2}} \ t$, and as expected I find the curvature to be increasing in time. Now how do I find a parametrization for the resulting motion in an inertial frame? I have looked into frenet-serret basis but the only thing resembling a solution I have not been able to find a solution. The closes I have found is this parametrization for an arc-length parametrized curvature: $\eta(t) = \int_0^t\cos\left( \int_0^t \kappa(s)ds\right)ds$ But I get curve that spirals outwards in time from origo, not inwards. Any help is appreciated, am I going about this the wrong way?","I am doing a project in which I have an object experiencing acceleration in a direction changing with time. I know the along-track and transverse acceleration components $a_{||}(t)$ and $a_{\perp}(t)$ in the comoving frame of the object, but not in an inertial reference frame. As time passes $a_{\perp}(t)$ increases while $a_{||}(t)$ decreases, so I expect the motion of the object to be a spiral in an inertial reference frame, and it is a parametrization of this spiral I am looking for. I have attempted to describe the curvature by $\kappa(t) = \frac{v(t)^{2}}{a_{\perp}(t)}$, where $v(t) = \sqrt{a_{\perp}(t)^{2} + a_{||}(t)^{2}} \ t$, and as expected I find the curvature to be increasing in time. Now how do I find a parametrization for the resulting motion in an inertial frame? I have looked into frenet-serret basis but the only thing resembling a solution I have not been able to find a solution. The closes I have found is this parametrization for an arc-length parametrized curvature: $\eta(t) = \int_0^t\cos\left( \int_0^t \kappa(s)ds\right)ds$ But I get curve that spirals outwards in time from origo, not inwards. Any help is appreciated, am I going about this the wrong way?",,"['differential-geometry', 'curves', 'curvature']"
8,Construction of the cotangent bundle involves a non-canonical choice(?),Construction of the cotangent bundle involves a non-canonical choice(?),,"In the book that I am reading (Introduction to Differential Manifolds by Barden and Thomas), they note that, for each chart $(U,\phi)$ in the atlas of some smooth $m$-manifold and each $p \in U,$ we have a bijection $\phi_*(p):T_p(M)\to \mathbb{R}^m$ given by $$\phi_*(p):[\gamma]_p \mapsto (\phi\circ\gamma)'(0).$$ Transporting the linear structure from $\mathbb{R}^m$ onto $T_p(M)$ makes each $\phi_*(p)$ into a linear isomorphism. They then say that, by taking the dual map of $(\phi_*(p))^{-1}\!,$ we have, for each $p \in U,$ a linear isomorphism $T_p^*(M)\to(\mathbb{R}^m)^*$ and so taking these maps all together we obtain a bijection $$\phi^*:T^*(U)=\coprod_{p \in U} T_p^*(M) \to \phi(U)\times (\mathbb{R}^m)^*$$ The next step is to view $\phi(U)\times (\mathbb{R}^m)^*$ as an open subspace of $\mathbb{R}^{2m}$ and then transport the topological structure of this onto $T^*(U)$ via the map $\phi^*.$ BUT... Surely this last step surely requires us to choose an identification of $(\mathbb{R}^m)^*$ with $\mathbb{R}^m$ and so, since this cannot be done canonically, I'm a bit confused... Any explanations or advice is very welcome. Thanks!","In the book that I am reading (Introduction to Differential Manifolds by Barden and Thomas), they note that, for each chart $(U,\phi)$ in the atlas of some smooth $m$-manifold and each $p \in U,$ we have a bijection $\phi_*(p):T_p(M)\to \mathbb{R}^m$ given by $$\phi_*(p):[\gamma]_p \mapsto (\phi\circ\gamma)'(0).$$ Transporting the linear structure from $\mathbb{R}^m$ onto $T_p(M)$ makes each $\phi_*(p)$ into a linear isomorphism. They then say that, by taking the dual map of $(\phi_*(p))^{-1}\!,$ we have, for each $p \in U,$ a linear isomorphism $T_p^*(M)\to(\mathbb{R}^m)^*$ and so taking these maps all together we obtain a bijection $$\phi^*:T^*(U)=\coprod_{p \in U} T_p^*(M) \to \phi(U)\times (\mathbb{R}^m)^*$$ The next step is to view $\phi(U)\times (\mathbb{R}^m)^*$ as an open subspace of $\mathbb{R}^{2m}$ and then transport the topological structure of this onto $T^*(U)$ via the map $\phi^*.$ BUT... Surely this last step surely requires us to choose an identification of $(\mathbb{R}^m)^*$ with $\mathbb{R}^m$ and so, since this cannot be done canonically, I'm a bit confused... Any explanations or advice is very welcome. Thanks!",,"['differential-geometry', 'smooth-manifolds', 'tangent-bundle']"
9,What is the relationship between Lie bracket and exterior derivative?,What is the relationship between Lie bracket and exterior derivative?,,"Let $\omega$ be a 1-form and $X$ and $Y$ the vector fields on $M$, a smooth manifold. I know that there is a well-known identity: $d\omega(X,Y)= X(\omega(Y))-Y(\omega(X))-\omega[X,Y]$ which illustrates the relationship between exterior derivative and Lie bracket. The proof of this follows from taking co-ordinates of $X$ and $Y$ and running some computations, which is not difficult. However, I don't get the intuitive meaning behind this. Is it simply meant to be seen as things like Leibniz rule, where the result, although computational, is quite fundamental that we are to take it as theoretical building-blocks? Indeed, this identity is key in showing that given a connection $\nabla$ with connection 1-form matrix $\Omega$ and curvature tensor $R$, $R(X,Y)(Z)=\nabla^2(Z)(X,Y)$(or the curvature matrix of $R$ is indeed $d\Omega-\Omega \wedge \Omega$). Since Lie bracket $[X,Y]$ measures(in some sense) how far the vector fields $X$ and $Y$ are off from forming local co-ordinates, we can think of the term $\omega[X,Y]$ as making 'adjustments', but I wonder whether there are better interpretations of this identity. The cases where $X=\partial/\partial x^i$ and $Y=\partial/\partial x^j$ do return what is expected- that is, $d\omega(x,y)=\partial \omega^j/\partial x^i-\partial \omega^i/\partial x^j$, but it doesn't really contribute to explaining the $\omega[X,Y]$ term.","Let $\omega$ be a 1-form and $X$ and $Y$ the vector fields on $M$, a smooth manifold. I know that there is a well-known identity: $d\omega(X,Y)= X(\omega(Y))-Y(\omega(X))-\omega[X,Y]$ which illustrates the relationship between exterior derivative and Lie bracket. The proof of this follows from taking co-ordinates of $X$ and $Y$ and running some computations, which is not difficult. However, I don't get the intuitive meaning behind this. Is it simply meant to be seen as things like Leibniz rule, where the result, although computational, is quite fundamental that we are to take it as theoretical building-blocks? Indeed, this identity is key in showing that given a connection $\nabla$ with connection 1-form matrix $\Omega$ and curvature tensor $R$, $R(X,Y)(Z)=\nabla^2(Z)(X,Y)$(or the curvature matrix of $R$ is indeed $d\Omega-\Omega \wedge \Omega$). Since Lie bracket $[X,Y]$ measures(in some sense) how far the vector fields $X$ and $Y$ are off from forming local co-ordinates, we can think of the term $\omega[X,Y]$ as making 'adjustments', but I wonder whether there are better interpretations of this identity. The cases where $X=\partial/\partial x^i$ and $Y=\partial/\partial x^j$ do return what is expected- that is, $d\omega(x,y)=\partial \omega^j/\partial x^i-\partial \omega^i/\partial x^j$, but it doesn't really contribute to explaining the $\omega[X,Y]$ term.",,['differential-geometry']
10,Planar curves and number of intersection,Planar curves and number of intersection,,"I am looking for an example. 1)Find Two planar, smooth (C^2) and strictly convex curves such that their intersection counts an infinite number of points in the plane. By strictly convex I mean a curve whose curvature is strictly positive or strictly negative. In addition the curves need to be simple and not loops. 2) (Relaxed version of the problem) If you can't find the example as above, try to relax the hypothesis slightly more. Then you can take the following hypothesis. The two curves are convex. But when the curvature is 0, then you can't have a curvature locally 0 around that point. For sure this is a relaxing condition because you allow for the curvatures being zero. The rest of hypotheses are the same. Also in this case you should have an infinite number of intersections. I am very happy if anyone finds this counterexample especially for the case 1). I am not sure if this example exists. Even you have a partial answer or you know why such curves cannot exist, please let me know.. Thanks. Francesco","I am looking for an example. 1)Find Two planar, smooth (C^2) and strictly convex curves such that their intersection counts an infinite number of points in the plane. By strictly convex I mean a curve whose curvature is strictly positive or strictly negative. In addition the curves need to be simple and not loops. 2) (Relaxed version of the problem) If you can't find the example as above, try to relax the hypothesis slightly more. Then you can take the following hypothesis. The two curves are convex. But when the curvature is 0, then you can't have a curvature locally 0 around that point. For sure this is a relaxing condition because you allow for the curvatures being zero. The rest of hypotheses are the same. Also in this case you should have an infinite number of intersections. I am very happy if anyone finds this counterexample especially for the case 1). I am not sure if this example exists. Even you have a partial answer or you know why such curves cannot exist, please let me know.. Thanks. Francesco",,"['differential-geometry', 'algebraic-geometry', 'differential-topology', 'euclidean-geometry', 'riemannian-geometry']"
11,Current being a differential form with distribution coefficients,Current being a differential form with distribution coefficients,,"It is a standard result that on a domain $\Omega$ in $\mathbb{R}^n$, $T=\sum_{|I|=q}T_{I}dx_{I}$ for any $q$-current $T$, where $T_{I}$ is a $0$ current or a distribution on $\Omega$ for each multi-index $I$. Now, for an $r$-current $T$ and an $s$-form $\alpha$ on $\Omega$, define an $r+s$-current as $(T\wedge\alpha)(\beta)=T(\alpha\wedge\beta)$ for any $n-r-s$-form $\beta$ on $\Omega$. Then, in the above we have $T=\sum_{|I|=q}T_{I}\wedge dx_{I}$ on $\Omega$. At this stage, if we start with a general smooth manifold $M$(orientable) and a $q$-current $T$ on $M$, can we write $T=\sum_{\alpha}T_{\alpha}\wedge\omega_{\alpha}$ on $M~?$ (Here $T_{\alpha}$ and $\omega_{\alpha}$ are distributions and $q$-forms on $M$ for each $\alpha$).","It is a standard result that on a domain $\Omega$ in $\mathbb{R}^n$, $T=\sum_{|I|=q}T_{I}dx_{I}$ for any $q$-current $T$, where $T_{I}$ is a $0$ current or a distribution on $\Omega$ for each multi-index $I$. Now, for an $r$-current $T$ and an $s$-form $\alpha$ on $\Omega$, define an $r+s$-current as $(T\wedge\alpha)(\beta)=T(\alpha\wedge\beta)$ for any $n-r-s$-form $\beta$ on $\Omega$. Then, in the above we have $T=\sum_{|I|=q}T_{I}\wedge dx_{I}$ on $\Omega$. At this stage, if we start with a general smooth manifold $M$(orientable) and a $q$-current $T$ on $M$, can we write $T=\sum_{\alpha}T_{\alpha}\wedge\omega_{\alpha}$ on $M~?$ (Here $T_{\alpha}$ and $\omega_{\alpha}$ are distributions and $q$-forms on $M$ for each $\alpha$).",,"['differential-geometry', 'distribution-theory', 'differential-forms']"
12,Why do these intersections of surfaces give a line not a point?,Why do these intersections of surfaces give a line not a point?,,"Given a pair of functions $f(x,y,z)$ and $g(x,y,z)$. Now make the three equations: $$ \nabla f(x,y,z) \times \nabla g(x,y,z) = 0 $$ This gives equations for three 2D surfaces. At first inspection this seems like the intersection of all three should be a point. But playing around it seems they all intersect on a 1D curve. Why? For example try: $$f(x,y,z) = x^2+(y-5)^2+z^2$$ $$g(x,y,z) = (x+3)^2+y^2+(z-1)^2$$ this gives three planes which cross each other on a single line between the points $(0,5,0)$ and $(-3,0,1)$. Is this always the case? Or in what circumstances does this happen? Edit: Another question is, can you direct me to a book (Fluid Mechanics?) that has this equation? Also apparently it implies there is a function $h(f,g)=0$ how to find this function $h$?","Given a pair of functions $f(x,y,z)$ and $g(x,y,z)$. Now make the three equations: $$ \nabla f(x,y,z) \times \nabla g(x,y,z) = 0 $$ This gives equations for three 2D surfaces. At first inspection this seems like the intersection of all three should be a point. But playing around it seems they all intersect on a 1D curve. Why? For example try: $$f(x,y,z) = x^2+(y-5)^2+z^2$$ $$g(x,y,z) = (x+3)^2+y^2+(z-1)^2$$ this gives three planes which cross each other on a single line between the points $(0,5,0)$ and $(-3,0,1)$. Is this always the case? Or in what circumstances does this happen? Edit: Another question is, can you direct me to a book (Fluid Mechanics?) that has this equation? Also apparently it implies there is a function $h(f,g)=0$ how to find this function $h$?",,"['differential-geometry', 'vector-analysis']"
13,Local/Global isometries of the torus,Local/Global isometries of the torus,,"I am looking at isometries of the two-torus with the flat metric. From a local perspective, $T^2 = S^1 \times S^1$ has coordinates $(x,y)$, with metric: $$ds^2 = dx^2 + dy^2$$ The difference between $T^2$ and $\mathbb{R}^2$ is in the topology, and comes from imposing the periodicity of the coordinates $x \sim x+1$ and  $y \sim y+1$. I know that $\mathbb{R}^2$ has three Killing vectors: $\{ \partial_x,\partial_y, x\partial_y - y\partial_x \}$, which are simply the translations, and rotation of the plane. These are also local Killing vectors for the torus, but on the other hand I know that $T^2$ has only two global Killing vectors, the translations. How, explicitly, do I see that the rotation Killing vector is not a global Killing   vector for the two-torus?","I am looking at isometries of the two-torus with the flat metric. From a local perspective, $T^2 = S^1 \times S^1$ has coordinates $(x,y)$, with metric: $$ds^2 = dx^2 + dy^2$$ The difference between $T^2$ and $\mathbb{R}^2$ is in the topology, and comes from imposing the periodicity of the coordinates $x \sim x+1$ and  $y \sim y+1$. I know that $\mathbb{R}^2$ has three Killing vectors: $\{ \partial_x,\partial_y, x\partial_y - y\partial_x \}$, which are simply the translations, and rotation of the plane. These are also local Killing vectors for the torus, but on the other hand I know that $T^2$ has only two global Killing vectors, the translations. How, explicitly, do I see that the rotation Killing vector is not a global Killing   vector for the two-torus?",,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'symmetry']"
14,Calculating the curvature of a surface,Calculating the curvature of a surface,,"From https://en.wikipedia.org/wiki/Curvature#Local_expressions : For a plane curve given parametrically in Cartesian coordinates as $f(t)=(x(t), y(t))$, the curvature is $$\kappa = \frac{|x'y''-y'x''|}{\left(x'^2+y'^2\right)^\frac32}$$ What is the general expression for a 3 or higher dimensional surface, e.g. the curvature of $f(t) = (x(t), y(t), z(t))$?","From https://en.wikipedia.org/wiki/Curvature#Local_expressions : For a plane curve given parametrically in Cartesian coordinates as $f(t)=(x(t), y(t))$, the curvature is $$\kappa = \frac{|x'y''-y'x''|}{\left(x'^2+y'^2\right)^\frac32}$$ What is the general expression for a 3 or higher dimensional surface, e.g. the curvature of $f(t) = (x(t), y(t), z(t))$?",,"['geometry', 'differential-geometry', 'analytic-geometry', 'curvature']"
15,Finding the variation field,Finding the variation field,,"Let $M$ be a complete connected Riemannian manifold and $r\in M$ and $p,q\in B(r;R)$ where $R$ is the convexity radius at point $r$. Let $u\in T_pM$ and $v\in T_qM$ and $\epsilon>0$ be such that $\exp_psu,\exp_qsv\in B(r;R)$ and $\Gamma:(-\epsilon,\epsilon)\times[0,1]\to M$ be defined by $$\Gamma(s,t)=\exp_{\exp_psu}(t\exp^{-1}_{\exp_psu}\exp_qsv)$$ I want to calculate the variation field $V(t)=\partial_s\Gamma(0,t)$ at $t=0$ and $t=1$, that is $$\partial_s\Gamma(0,t)=\frac d{ds}\Gamma(s,t)|_{s=0}$$ If $\gamma(s)=t\exp^{-1}_{\exp_psu}\exp_qsv$ ,then $$\frac d{ds}\Gamma(s,t)|_{s=0}=(\exp_{\exp_psu})_{*t\exp^{-1}_pq}(\dot\gamma(0))$$ if $\mu=\exp_qsv$, then $$\dot\gamma(0)=(t\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0))$$ So,  $$V(0)=(\exp_{\exp_psu})_{*0}((0)_{*q}(\dot\mu(0)))$$ and $$V(1)=(\exp_{\exp_psu})_{*\exp^{-1}_pq}((\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0)))$$ but I don't know how continue from here. In this paper is claimed that $V(0)=u$ and $V(1)=v$ without any explanation. Can anyone give me some hint for calculating of $V(0)$ and $V(1)$, please?","Let $M$ be a complete connected Riemannian manifold and $r\in M$ and $p,q\in B(r;R)$ where $R$ is the convexity radius at point $r$. Let $u\in T_pM$ and $v\in T_qM$ and $\epsilon>0$ be such that $\exp_psu,\exp_qsv\in B(r;R)$ and $\Gamma:(-\epsilon,\epsilon)\times[0,1]\to M$ be defined by $$\Gamma(s,t)=\exp_{\exp_psu}(t\exp^{-1}_{\exp_psu}\exp_qsv)$$ I want to calculate the variation field $V(t)=\partial_s\Gamma(0,t)$ at $t=0$ and $t=1$, that is $$\partial_s\Gamma(0,t)=\frac d{ds}\Gamma(s,t)|_{s=0}$$ If $\gamma(s)=t\exp^{-1}_{\exp_psu}\exp_qsv$ ,then $$\frac d{ds}\Gamma(s,t)|_{s=0}=(\exp_{\exp_psu})_{*t\exp^{-1}_pq}(\dot\gamma(0))$$ if $\mu=\exp_qsv$, then $$\dot\gamma(0)=(t\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0))$$ So,  $$V(0)=(\exp_{\exp_psu})_{*0}((0)_{*q}(\dot\mu(0)))$$ and $$V(1)=(\exp_{\exp_psu})_{*\exp^{-1}_pq}((\exp^{-1}_{\exp_psu})_{*q}(\dot\mu(0)))$$ but I don't know how continue from here. In this paper is claimed that $V(0)=u$ and $V(1)=v$ without any explanation. Can anyone give me some hint for calculating of $V(0)$ and $V(1)$, please?",,"['differential-geometry', 'manifolds']"
16,tom Dieck's universal definition of a tangent space,tom Dieck's universal definition of a tangent space,,"In page 362 of tom Dieck's Algebraic Topology , the author gives a definition for the tangent space of a premanifold (locally ringed space locally isomorphic to open subset of Euclidean space) which I understand as follows: Let $(X,\mathcal O _X)$ be a premanifold. A tangent space at $p$ consists of a pair $(\mathrm T_pX,\jmath)$ satisfying the following data. $\mathrm T_pX$ is a vector space. For each chart $\bf x$ of $X$ about $p$, $\jmath_\mathbf{x}:\mathrm T_pX\to \mathbb R ^n$ is a linear isomorphism. $\jmath_\mathbf{y}\circ \jmath_{\mathbf{x}}^{-1}=\mathrm d_{\mathbf x p}(\mathbf y\circ \mathbf x^{-1}):\mathbb R ^n \cong \mathbb R^n$. These properties imply that if $(\mathrm T_pX,\jmath)$ and $(\mathrm T_p^\prime  X,\jmath ^\prime)$ are two tangent spaces of $X$ at $p$ then the composite $\jmath_\mathbf{x}^{-1}\circ \jmath_\mathbf{x}^\prime:\mathrm T^\prime_pX\cong \mathrm T_pX$ does not depend on the chart $\mathbf x$. From this the author concludes the tangent space is unique up to unique isomorphism ""by the universal property"". What are the categories involved and in what precise sense is the tangent space an initial/terminal object?","In page 362 of tom Dieck's Algebraic Topology , the author gives a definition for the tangent space of a premanifold (locally ringed space locally isomorphic to open subset of Euclidean space) which I understand as follows: Let $(X,\mathcal O _X)$ be a premanifold. A tangent space at $p$ consists of a pair $(\mathrm T_pX,\jmath)$ satisfying the following data. $\mathrm T_pX$ is a vector space. For each chart $\bf x$ of $X$ about $p$, $\jmath_\mathbf{x}:\mathrm T_pX\to \mathbb R ^n$ is a linear isomorphism. $\jmath_\mathbf{y}\circ \jmath_{\mathbf{x}}^{-1}=\mathrm d_{\mathbf x p}(\mathbf y\circ \mathbf x^{-1}):\mathbb R ^n \cong \mathbb R^n$. These properties imply that if $(\mathrm T_pX,\jmath)$ and $(\mathrm T_p^\prime  X,\jmath ^\prime)$ are two tangent spaces of $X$ at $p$ then the composite $\jmath_\mathbf{x}^{-1}\circ \jmath_\mathbf{x}^\prime:\mathrm T^\prime_pX\cong \mathrm T_pX$ does not depend on the chart $\mathbf x$. From this the author concludes the tangent space is unique up to unique isomorphism ""by the universal property"". What are the categories involved and in what precise sense is the tangent space an initial/terminal object?",,"['differential-geometry', 'category-theory', 'manifolds', 'definition', 'limits-colimits']"
17,Terminology: what is a spun manifold,Terminology: what is a spun manifold,,"I have been reading this paper and encountered the words ""spun manifold"". Now, I know what a spin structure is. I just want to check that ""spun manifold"" is indeed just a grammatically correct form of ""spin manifold"" and not ""a spin manifold with extra structure"".","I have been reading this paper and encountered the words ""spun manifold"". Now, I know what a spin structure is. I just want to check that ""spun manifold"" is indeed just a grammatically correct form of ""spin manifold"" and not ""a spin manifold with extra structure"".",,"['differential-geometry', 'terminology']"
18,Nonlinear PDE related to zero Hessian,Nonlinear PDE related to zero Hessian,,"Consider $$f_{xx}f_{yy}-f_{xy}^2 =0$$ where $f=f(x,y)$ is a well behaved function. This PDE is the determinant of the Hessian. Solutions for $f$ are the trivial solution, $f=$constant and $f=ax+by$ for $a,b$ constant. However, $f=f(x-cy)$ for $c$ a constant also satisfies this equation. This implies there are lines of constant value along $\xi = x-cy$. That is, the curvature alongs these lines is zero which agrees with my intuition as the determinant is proportional to the Gaussian curvature. Are there more general solutions?","Consider $$f_{xx}f_{yy}-f_{xy}^2 =0$$ where $f=f(x,y)$ is a well behaved function. This PDE is the determinant of the Hessian. Solutions for $f$ are the trivial solution, $f=$constant and $f=ax+by$ for $a,b$ constant. However, $f=f(x-cy)$ for $c$ a constant also satisfies this equation. This implies there are lines of constant value along $\xi = x-cy$. That is, the curvature alongs these lines is zero which agrees with my intuition as the determinant is proportional to the Gaussian curvature. Are there more general solutions?",,"['differential-geometry', 'partial-differential-equations']"
19,Invariant forms on a Lie group - are these equal?,Invariant forms on a Lie group - are these equal?,,"Motivation: This is a follow-up question to this question that I asked a few minutes ago. (my question there actually doesn't even make sense (apparently I did not pay close enough attention) - see levap's answer. I've tried to modify that question so that it actually does make sense and here is what I've come up with: Background: Let $L$ be a Lie group, and $g$ a left-invariant riemannian metric on $L$. With respect to $g$, choose an orthonormal basis $v_e = v_e^1, \cdots v_e^n$ for the tangent space at the identity $T_e L$, and let $w_e = w_e^1, \cdots, w_e^n$ denote the dual basis to $v_e$ in $T^*_eL$. As $g$ is left-invariant this orthonormal basis at the identity induces a global an orthonormal frame field $v$ on all of $L$ by using Lie group structure. See here for details. Now, we can construct global 1- forms from this basis in two obvious ways, and I'm wondering if the result is the same. Take $w_e$, the dual basis to $v_e$, and using the Lie group structure define a global basis of invariant 1-forms. Again, see here for details. Call this $\phi =\phi^1, \cdots, \phi^n$. Take the global frame field $v$ and at each point $p \in L$ take the dual coframe to produce a global coframe field. Call this $w= w^1, \cdots, w^n$. Question: Does $$\phi = w?$$  i.e  does $\phi^1 = w^1, \cdots, \phi^n = w^n$? Attempt: I think I may have figured this out. We have by construction that at any point $g\in L$  $$w_g^i (v_g^j) = \delta_{ij}.$$ So for equality of $\phi$ and $w$ we would need $$ \phi_g^i (v_g^j) = \delta_{ij}. $$ However,  $$ \phi_g^i (v_g^j)= (w_e^i \circ dg^{-1}) \circ (dg \circ v_e^j) = w_e^i(v_e^j) = \delta_{ij}.   $$ So by uniqueness of the dual basis $\phi$ and $w$ are equal.","Motivation: This is a follow-up question to this question that I asked a few minutes ago. (my question there actually doesn't even make sense (apparently I did not pay close enough attention) - see levap's answer. I've tried to modify that question so that it actually does make sense and here is what I've come up with: Background: Let $L$ be a Lie group, and $g$ a left-invariant riemannian metric on $L$. With respect to $g$, choose an orthonormal basis $v_e = v_e^1, \cdots v_e^n$ for the tangent space at the identity $T_e L$, and let $w_e = w_e^1, \cdots, w_e^n$ denote the dual basis to $v_e$ in $T^*_eL$. As $g$ is left-invariant this orthonormal basis at the identity induces a global an orthonormal frame field $v$ on all of $L$ by using Lie group structure. See here for details. Now, we can construct global 1- forms from this basis in two obvious ways, and I'm wondering if the result is the same. Take $w_e$, the dual basis to $v_e$, and using the Lie group structure define a global basis of invariant 1-forms. Again, see here for details. Call this $\phi =\phi^1, \cdots, \phi^n$. Take the global frame field $v$ and at each point $p \in L$ take the dual coframe to produce a global coframe field. Call this $w= w^1, \cdots, w^n$. Question: Does $$\phi = w?$$  i.e  does $\phi^1 = w^1, \cdots, \phi^n = w^n$? Attempt: I think I may have figured this out. We have by construction that at any point $g\in L$  $$w_g^i (v_g^j) = \delta_{ij}.$$ So for equality of $\phi$ and $w$ we would need $$ \phi_g^i (v_g^j) = \delta_{ij}. $$ However,  $$ \phi_g^i (v_g^j)= (w_e^i \circ dg^{-1}) \circ (dg \circ v_e^j) = w_e^i(v_e^j) = \delta_{ij}.   $$ So by uniqueness of the dual basis $\phi$ and $w$ are equal.",,"['linear-algebra', 'differential-geometry', 'lie-groups']"
20,Problem regarding mean value theorem,Problem regarding mean value theorem,,"Let $f:\mathbb R\to \mathbb R$ be a continuous function, and let $S=$ set of all slopes of secant of the graph of the function $f$ $T=$ set of all slopes of the tangent  of the graph of the function Question : (true or false with reason) If $S=T=\mathbb R$ where $\mathbb R$ is the set of all real number, then the function is differentiable everywhere. I think the answer is false because though $S=T=\mathbb R$, there may exist a point at which $f$ is not differentiable. Please anyone give an example of this. added :there may exists points on the graph which is sharp or has vertical tangent.here tangent and secant are geomertric objects and not trigonometric ratios.","Let $f:\mathbb R\to \mathbb R$ be a continuous function, and let $S=$ set of all slopes of secant of the graph of the function $f$ $T=$ set of all slopes of the tangent  of the graph of the function Question : (true or false with reason) If $S=T=\mathbb R$ where $\mathbb R$ is the set of all real number, then the function is differentiable everywhere. I think the answer is false because though $S=T=\mathbb R$, there may exist a point at which $f$ is not differentiable. Please anyone give an example of this. added :there may exists points on the graph which is sharp or has vertical tangent.here tangent and secant are geomertric objects and not trigonometric ratios.",,"['calculus', 'real-analysis', 'differential-geometry']"
21,"For any smooth manifold $M$, does there exist some coordinate chart $(U,(x^i))$ such that $M\setminus U$ has measure zero? [duplicate]","For any smooth manifold , does there exist some coordinate chart  such that  has measure zero? [duplicate]","M (U,(x^i)) M\setminus U","This question already has an answer here : How much of an $n$-dimensional manifold can we embed into $\mathbb{R}^n$? (1 answer) Closed 7 years ago . Assume that $M$ is connected. Ideally, I would like $U$ to be connected, though that's not strictly necessary. If this were true, it would instantly make integration on compact oriented manifolds much easier, since we can simply pass to Euclidean space $\mathbb{R}^n$ in order to evaluate the integral. Intuitively, it seems like it must be true. Consider the following examples: $\mathbb{S}^n$ – we use the stereographic projection $\mathbb{T}^n \cong (\mathbb{R}/\mathbb{Z})^n$ – we consider $U=(0,1)^n$ $\mathbb{RP}^n$ – we consider $U_0=\{[1:x^1:\cdots:x^n]\, \big\vert\, x^1,\ldots,x^n\in\mathbb{R}^n\}$ If $M$ and $N$ have smooth charts $(U,(x^i)$ and $(V,(y^j))$ defined almost everywhere, respectively, then $M\times N$ has smooth chart $(U\times V, (x^1,\ldots,x^n,y^1,\ldots,y^m))$ defined almost everywhere. However, I have no clue about how to prove a statement like this, and I suspect that any counterexample would be very difficult to find.","This question already has an answer here : How much of an $n$-dimensional manifold can we embed into $\mathbb{R}^n$? (1 answer) Closed 7 years ago . Assume that $M$ is connected. Ideally, I would like $U$ to be connected, though that's not strictly necessary. If this were true, it would instantly make integration on compact oriented manifolds much easier, since we can simply pass to Euclidean space $\mathbb{R}^n$ in order to evaluate the integral. Intuitively, it seems like it must be true. Consider the following examples: $\mathbb{S}^n$ – we use the stereographic projection $\mathbb{T}^n \cong (\mathbb{R}/\mathbb{Z})^n$ – we consider $U=(0,1)^n$ $\mathbb{RP}^n$ – we consider $U_0=\{[1:x^1:\cdots:x^n]\, \big\vert\, x^1,\ldots,x^n\in\mathbb{R}^n\}$ If $M$ and $N$ have smooth charts $(U,(x^i)$ and $(V,(y^j))$ defined almost everywhere, respectively, then $M\times N$ has smooth chart $(U\times V, (x^1,\ldots,x^n,y^1,\ldots,y^m))$ defined almost everywhere. However, I have no clue about how to prove a statement like this, and I suspect that any counterexample would be very difficult to find.",,"['general-topology', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
22,Can we see the symplectic nature of cotangent bundles through classifying maps.,Can we see the symplectic nature of cotangent bundles through classifying maps.,,"Background As is well known cotangent bundles are ( `the' ) examples of symplectic manifolds. In particular they are examples of almost symplectic manifolds (there one merely requires the symplectic form to be non-degenerate, not necessarily closed). On the other hand -if we phrase things in the language of classifying spaces- the existence of an almost symplectic structure on $T^*M$ means we can reduce the structure group from $GL_{2n}$ to $Sp_{2n}$. Here dim$(T^*M) = 2n$. Differently said, there exists a lift $\tilde{\tau}$ of the classifying map $\tau$ as follows: The Question Is there a simple (topological) argument, why such lifts always exist for cotangent bundles? Further Comment I would also be interested in other non-constructive proofs of cotangent bundles being symplectic manifolds, so feel free to interpret the question slightly differently and answer that.","Background As is well known cotangent bundles are ( `the' ) examples of symplectic manifolds. In particular they are examples of almost symplectic manifolds (there one merely requires the symplectic form to be non-degenerate, not necessarily closed). On the other hand -if we phrase things in the language of classifying spaces- the existence of an almost symplectic structure on $T^*M$ means we can reduce the structure group from $GL_{2n}$ to $Sp_{2n}$. Here dim$(T^*M) = 2n$. Differently said, there exists a lift $\tilde{\tau}$ of the classifying map $\tau$ as follows: The Question Is there a simple (topological) argument, why such lifts always exist for cotangent bundles? Further Comment I would also be interested in other non-constructive proofs of cotangent bundles being symplectic manifolds, so feel free to interpret the question slightly differently and answer that.",,"['differential-geometry', 'algebraic-topology', 'symplectic-geometry', 'classifying-spaces']"
23,Doubts on definition of the Lie derivative,Doubts on definition of the Lie derivative,,"I have some difficulties to see why the definition of the lie derivative makes sense. I'm going to use the notations of Lee's book. Let $M$ manifold and $W$ a smooth vector field on $M$. Let $\eta$ the flow of another smooth vector field $V$ $$(L_VW)_p=d/dt(d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})=\lim_t (d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})-W_p)/t $$ where the derivative and the limit are computed in $0$ Now: 1) Is the second equality a definition ? 2) I don't understand what a derivative or a limit of these objects means. I would like to find a function $F$ depending on $t$ such that $(L_VW)_p=d/dt F(t)$ computed in $0$. My problem is that if I take $F(t)=d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})$ I have a function with values not in $\mathbb R $ (I think they are in $T_pM$, right?) So how can I derive a such $F:\mathbb R\to T_pM$ ? Is this problem just that I do not know what a derivative in a topological vector space is or something like this? Same problem with the Lie derivative of a tensor field. P.S. Moreover, the symbol $d/dt$ in the definition of the Lie derivative should be interpreted as the velocity of a curve or as the limit of the difference quotient? Or, more in general, the velocity of a curve into $T_pM$ is actually equals to the limit of the different quotient?","I have some difficulties to see why the definition of the lie derivative makes sense. I'm going to use the notations of Lee's book. Let $M$ manifold and $W$ a smooth vector field on $M$. Let $\eta$ the flow of another smooth vector field $V$ $$(L_VW)_p=d/dt(d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})=\lim_t (d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})-W_p)/t $$ where the derivative and the limit are computed in $0$ Now: 1) Is the second equality a definition ? 2) I don't understand what a derivative or a limit of these objects means. I would like to find a function $F$ depending on $t$ such that $(L_VW)_p=d/dt F(t)$ computed in $0$. My problem is that if I take $F(t)=d(\eta_{-t})_{\eta_t(p)}(W_{\eta_t(p)})$ I have a function with values not in $\mathbb R $ (I think they are in $T_pM$, right?) So how can I derive a such $F:\mathbb R\to T_pM$ ? Is this problem just that I do not know what a derivative in a topological vector space is or something like this? Same problem with the Lie derivative of a tensor field. P.S. Moreover, the symbol $d/dt$ in the definition of the Lie derivative should be interpreted as the velocity of a curve or as the limit of the difference quotient? Or, more in general, the velocity of a curve into $T_pM$ is actually equals to the limit of the different quotient?",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'lie-derivative']"
24,Elliptic operator $d+d^*$,Elliptic operator,d+d^*,"We consider a Riemannian manifold $(M,g)$ and the metric can induce the dual $d^*$ of $d$ by the formula: $$ \int_M \langle\alpha, d\beta\rangle d{\text vol}_g = \int_M \langle d^*\alpha, \beta\rangle d{\text vol}_g $$ I am a new graduate student, and one of my teacher mentioned in a class that $$d+d^*$$ is an elliptic operator. I am curious about this. I know elliptic operators in Euclidean spaces, but how to understand this? Could you tell me some references about this issue? Thanks.","We consider a Riemannian manifold $(M,g)$ and the metric can induce the dual $d^*$ of $d$ by the formula: $$ \int_M \langle\alpha, d\beta\rangle d{\text vol}_g = \int_M \langle d^*\alpha, \beta\rangle d{\text vol}_g $$ I am a new graduate student, and one of my teacher mentioned in a class that $$d+d^*$$ is an elliptic operator. I am curious about this. I know elliptic operators in Euclidean spaces, but how to understand this? Could you tell me some references about this issue? Thanks.",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'differential-operators']"
25,How to prove this is homeomorphism?,How to prove this is homeomorphism?,,"Let $\Bbb R^n \cup\{\infty\} $ be the Alexandroff compactification of  $\Bbb R^n$. Prove that the function $\phi:\Bbb R^n \cup\{\infty\}\rightarrow\Bbb R^n \cup\{\infty\}, \ $ $\phi(x)=x/|x|^2$ if $ x\neq0,\infty$, $\phi(0)=\infty$ and $\phi(\infty)=0$ is an homeomorphism. It's clear in case $x\neq0,\infty,$ but I don't know how to prove the continuity in the zero and infinity points. I also know if $\phi$ is continuous, then it's an homeomorphism because $\phi=\phi^{-1}$.","Let $\Bbb R^n \cup\{\infty\} $ be the Alexandroff compactification of  $\Bbb R^n$. Prove that the function $\phi:\Bbb R^n \cup\{\infty\}\rightarrow\Bbb R^n \cup\{\infty\}, \ $ $\phi(x)=x/|x|^2$ if $ x\neq0,\infty$, $\phi(0)=\infty$ and $\phi(\infty)=0$ is an homeomorphism. It's clear in case $x\neq0,\infty,$ but I don't know how to prove the continuity in the zero and infinity points. I also know if $\phi$ is continuous, then it's an homeomorphism because $\phi=\phi^{-1}$.",,"['general-topology', 'differential-geometry']"
26,Show that for any arc length parameterized curve there is a vector $ω(s)$ that satisfies the following equations,Show that for any arc length parameterized curve there is a vector  that satisfies the following equations,ω(s),"I'm trying to solve the following question Show that for any arc length parameterized curve there is a vector   $ω(s)$ that satisfies $$T'(s) = ω(s) × T (s)$$ $$N'(s) = ω(s) × N(s)$$ $$B'(s) = ω(s) × > B(s)$$ HINT: Consider $ω(s) = a(s)T (s) +b(s)N(s) +c(s)B(s)$ (where $T$, $N$,   $B$ are the unit tangent, normal and binormal vectors) and find the   coefficients $a$, $b$, $c$ that work. I managed to get  $$a(s) = T(s) \cdot ω(s)$$ $$b(s) = N(s) \cdot ω(s)$$ $$c(s) = B(s) \cdot ω(s)$$ But I don't know how to proceed from this. What direction should I be going in.","I'm trying to solve the following question Show that for any arc length parameterized curve there is a vector   $ω(s)$ that satisfies $$T'(s) = ω(s) × T (s)$$ $$N'(s) = ω(s) × N(s)$$ $$B'(s) = ω(s) × > B(s)$$ HINT: Consider $ω(s) = a(s)T (s) +b(s)N(s) +c(s)B(s)$ (where $T$, $N$,   $B$ are the unit tangent, normal and binormal vectors) and find the   coefficients $a$, $b$, $c$ that work. I managed to get  $$a(s) = T(s) \cdot ω(s)$$ $$b(s) = N(s) \cdot ω(s)$$ $$c(s) = B(s) \cdot ω(s)$$ But I don't know how to proceed from this. What direction should I be going in.",,"['differential-geometry', 'vectors', 'vector-analysis']"
27,"Some confusion about normal vector, curvature and normal curvature in Do Carmo's textbook.","Some confusion about normal vector, curvature and normal curvature in Do Carmo's textbook.",,"There is this part of a text from Do Carmo's Differential Geometry that I don't quite understand. I understand the definitions of curvature, normal curvature, normal section etc. But what I am confused at is the part that says ""In a neighbourhood of $p$, a normal section of $S$ at $p$ is a regular plane curve on $S$ whose normal vector $n$ at $p$ is $\pm N(p)$ or zero; its curvature is therefore equal to the absolute value of the normal curvature along $v$ at $p$."" First, is the neighbourhood of $p$ a part a curve $C$, a surface $S$ or a neighbourhood of $p$ on the normal section? It is not that clear. Especially when it mentioned the curvature it seems that it refers to the curve $C$. Another thing that confuses me is why is the normal vector either $N(p)$ or zero? And why is the curvature equal the absolute value of the normal curvature? Here is how I worked it out: $k_n=k\cos\theta$ and $\theta=0$, so $k_n=k$, where $k_n$ is the normal curvature. Am I correct? Or should I reason as follows: $n=0$, so $\cos\theta=<0,N>=0$, so $k_n=0$? I have been looking back and forth for the definitions and tried to work it out myself but still couldn't really understand the text. Could someone please help clarify the confusion? Thanks.","There is this part of a text from Do Carmo's Differential Geometry that I don't quite understand. I understand the definitions of curvature, normal curvature, normal section etc. But what I am confused at is the part that says ""In a neighbourhood of $p$, a normal section of $S$ at $p$ is a regular plane curve on $S$ whose normal vector $n$ at $p$ is $\pm N(p)$ or zero; its curvature is therefore equal to the absolute value of the normal curvature along $v$ at $p$."" First, is the neighbourhood of $p$ a part a curve $C$, a surface $S$ or a neighbourhood of $p$ on the normal section? It is not that clear. Especially when it mentioned the curvature it seems that it refers to the curve $C$. Another thing that confuses me is why is the normal vector either $N(p)$ or zero? And why is the curvature equal the absolute value of the normal curvature? Here is how I worked it out: $k_n=k\cos\theta$ and $\theta=0$, so $k_n=k$, where $k_n$ is the normal curvature. Am I correct? Or should I reason as follows: $n=0$, so $\cos\theta=<0,N>=0$, so $k_n=0$? I have been looking back and forth for the definitions and tried to work it out myself but still couldn't really understand the text. Could someone please help clarify the confusion? Thanks.",,['differential-geometry']
28,Geometric structures which always exist,Geometric structures which always exist,,"It is well known fact that Riemannian metric always exist on any manifold. Another way to say that is that any manifold always admit $O(n)$ structure i.e. $O(n)$ reduction of structure group of frame bundle $L(M)$. One way to see that (next to the classical argument with partition of unity) is that $Gl(n)/O(n)$ is contactible, existance of a $G$ structure is equivalent to the existance of section of a fibre bundle $L(M)/G$ and fibre bundles with contractible fibre always possess one. My questions are: $\bullet$ What are another closed subgroups $G \subset Gl(n)$ with $Gl(n)/G$ contractible ? $\bullet$ What are another closed subgroups $G \subset Gl(n)$ such that any manifold admits $G$ structure?","It is well known fact that Riemannian metric always exist on any manifold. Another way to say that is that any manifold always admit $O(n)$ structure i.e. $O(n)$ reduction of structure group of frame bundle $L(M)$. One way to see that (next to the classical argument with partition of unity) is that $Gl(n)/O(n)$ is contactible, existance of a $G$ structure is equivalent to the existance of section of a fibre bundle $L(M)/G$ and fibre bundles with contractible fibre always possess one. My questions are: $\bullet$ What are another closed subgroups $G \subset Gl(n)$ with $Gl(n)/G$ contractible ? $\bullet$ What are another closed subgroups $G \subset Gl(n)$ such that any manifold admits $G$ structure?",,"['differential-geometry', 'lie-groups']"
29,Lie derivative on $\mathbb{R}^n$,Lie derivative on,\mathbb{R}^n,"This is an exercise left for homework, taken from the textbook which we follow in class, Lee's book ''Introduction to Smooth Manifolds'' Second Edition. Definition: $D_vW(p)=\frac{\mathrm{d} }{\mathrm{d} t}|_{t=0} W_{p+tv}=\lim_{t\rightarrow 0}\frac{1}{t}(W_{p+tv}-W_p)$ (*) Suppose $v\in \mathbb{R}^n$ and $W$ is a smooth vector field on an open subset of $\mathbb{R}^n$. Show that the directional derivative $D_vW(p)$ defined by (*) is equal to $(L_VW)_p$, where $V$ is the vector field $V=v^i\frac{\partial }{\partial x^i}$ with constant coefficients in standard coordinates. Any thoughts? Am i supposed to use the theorem which states $L_VW=[V,W]$, or is there a simpler way to show this equality? Thanks in advance for your answers!","This is an exercise left for homework, taken from the textbook which we follow in class, Lee's book ''Introduction to Smooth Manifolds'' Second Edition. Definition: $D_vW(p)=\frac{\mathrm{d} }{\mathrm{d} t}|_{t=0} W_{p+tv}=\lim_{t\rightarrow 0}\frac{1}{t}(W_{p+tv}-W_p)$ (*) Suppose $v\in \mathbb{R}^n$ and $W$ is a smooth vector field on an open subset of $\mathbb{R}^n$. Show that the directional derivative $D_vW(p)$ defined by (*) is equal to $(L_VW)_p$, where $V$ is the vector field $V=v^i\frac{\partial }{\partial x^i}$ with constant coefficients in standard coordinates. Any thoughts? Am i supposed to use the theorem which states $L_VW=[V,W]$, or is there a simpler way to show this equality? Thanks in advance for your answers!",,"['differential-geometry', 'lie-derivative']"
30,Can we have infinitely many conjugacy classes of stabilizer subgroups?,Can we have infinitely many conjugacy classes of stabilizer subgroups?,,"Let $G$ be a compact connected Lie group acting smoothly on a smooth connected manifold $M$. Say that $p,q\in M$ have the same orbit type if their stabilizer subgroups $G_p$ and $G_q$ are conjugate in $G$. Can there be infinitely many orbit types? In other words, if $[G_p]$ denotes the conjugacy class of $G_p$ in $G$, is it possible that the set $$\{[G_p]:p\in M\}$$ is infinite?","Let $G$ be a compact connected Lie group acting smoothly on a smooth connected manifold $M$. Say that $p,q\in M$ have the same orbit type if their stabilizer subgroups $G_p$ and $G_q$ are conjugate in $G$. Can there be infinitely many orbit types? In other words, if $[G_p]$ denotes the conjugacy class of $G_p$ in $G$, is it possible that the set $$\{[G_p]:p\in M\}$$ is infinite?",,"['differential-geometry', 'manifolds', 'lie-groups', 'smooth-manifolds', 'group-actions']"
31,Tangent space to a differentiable manifold,Tangent space to a differentiable manifold,,"I was trying to write the kinetic energy by following, step by step, the construction of tangent vectors and then inducing the scalar product from $\mathbb{R}^3$. Theorically, all the construction is quite clear to me, but I find myself in trouble when trying to apply it (I guess it is not that clear).  Let's take, for example, a Paraboloid. I can define a chart (which also is an atlas): $\phi(\rho,\theta)=(\rho\cos\theta,\rho\sin\theta, \rho^2+1)$ Now, I could also think that $\rho=\rho(t)$ and $\theta=\theta(t)$. In this case, i have a curve on the manifold. I can now define a derivation: $X_{p,\phi}f=(f\circ \phi(t))'(0)$ with $\phi(0)=p$. Now, it is easy to express this tangent vector thinking of it as immersed in $\mathbb{R}^3$, but I was trying to espress it in the basis $\bigg\{\frac{\partial}{\partial\rho},\frac{\partial}{\partial\theta}\bigg\}$. Frankly, and this makes me feel really stupid, i can't. The thing is that taking the vector I found and feeding it (two times, since it is a quadratic form) to the induced scalar product: $S=(S_{11},S_{12},S_{21},S_{22})=(1,0,0,\rho^2)$ does not reproduce the kinetic energy I wanted, which is: $T=\dot\rho^2(1+4\rho^2)+\rho^2\dot\theta^2$ I'm grateful for any help you can give me, because I really need to deeply understand these basic concepts!","I was trying to write the kinetic energy by following, step by step, the construction of tangent vectors and then inducing the scalar product from $\mathbb{R}^3$. Theorically, all the construction is quite clear to me, but I find myself in trouble when trying to apply it (I guess it is not that clear).  Let's take, for example, a Paraboloid. I can define a chart (which also is an atlas): $\phi(\rho,\theta)=(\rho\cos\theta,\rho\sin\theta, \rho^2+1)$ Now, I could also think that $\rho=\rho(t)$ and $\theta=\theta(t)$. In this case, i have a curve on the manifold. I can now define a derivation: $X_{p,\phi}f=(f\circ \phi(t))'(0)$ with $\phi(0)=p$. Now, it is easy to express this tangent vector thinking of it as immersed in $\mathbb{R}^3$, but I was trying to espress it in the basis $\bigg\{\frac{\partial}{\partial\rho},\frac{\partial}{\partial\theta}\bigg\}$. Frankly, and this makes me feel really stupid, i can't. The thing is that taking the vector I found and feeding it (two times, since it is a quadratic form) to the induced scalar product: $S=(S_{11},S_{12},S_{21},S_{22})=(1,0,0,\rho^2)$ does not reproduce the kinetic energy I wanted, which is: $T=\dot\rho^2(1+4\rho^2)+\rho^2\dot\theta^2$ I'm grateful for any help you can give me, because I really need to deeply understand these basic concepts!",,"['differential-geometry', 'mathematical-physics']"
32,"Consider $f: S^1 \to$ Figure Eight. $f$ is an immersion, but how?","Consider  Figure Eight.  is an immersion, but how?",f: S^1 \to f,"I am reading Guillemin and Pollack. The definition of an immersion they give is: $f: X \to Y$ is an immersion at $x \in X$ if $df_x : T_x(X) \to T_y(Y)$ is injective. If $f$ is an immersion $\forall x \in X$, then we say that $f$ is an immersion. So apparently the map from the circle to the figure 8 is an immersion, as they state on the next page. But what about the critical point in the mapping $f$? There is no tangent space defined here, correct? So then how could $f$ possibly be an immersion? Also, is there a simple example of something that isn't an immersion that will help me remember this definition? Thank you.","I am reading Guillemin and Pollack. The definition of an immersion they give is: $f: X \to Y$ is an immersion at $x \in X$ if $df_x : T_x(X) \to T_y(Y)$ is injective. If $f$ is an immersion $\forall x \in X$, then we say that $f$ is an immersion. So apparently the map from the circle to the figure 8 is an immersion, as they state on the next page. But what about the critical point in the mapping $f$? There is no tangent space defined here, correct? So then how could $f$ possibly be an immersion? Also, is there a simple example of something that isn't an immersion that will help me remember this definition? Thank you.",,"['differential-geometry', 'differential-topology']"
33,An orientable two plane bundle is trivial over a surface with boundary,An orientable two plane bundle is trivial over a surface with boundary,,"Why an orientable two plane bundle is trivial over a surface with boundary? When, I read a lecture notes ""Legendrian and transversal knots by Jhon B Etnyre"", I seen this result(he just state it). I don't know how the problem will go. Can any one fix it??? Thanks advance.","Why an orientable two plane bundle is trivial over a surface with boundary? When, I read a lecture notes ""Legendrian and transversal knots by Jhon B Etnyre"", I seen this result(he just state it). I don't know how the problem will go. Can any one fix it??? Thanks advance.",,"['differential-geometry', 'differential-topology', 'vector-bundles', 'fiber-bundles']"
34,Show that a particular mapping of an open ball in $\mathbb{R}^k$ onto $\mathbb{R}^k$ is a diffeomorphism.,Show that a particular mapping of an open ball in  onto  is a diffeomorphism.,\mathbb{R}^k \mathbb{R}^k,"This is a problem from Guilleman and Pollack: Page 5, question 4. Let $B_a$ be the open ball $\{ x: |x|^2 < a \}$ in $\mathbb{R}^k$, where $|x|^2 = \sum_i x_i^2$. Show that the map \begin{equation} x \mapsto \frac{ax}{\sqrt{a^2 - |x|^2}} \end{equation} is a diffeomorphism of $B_a$ onto $\mathbb{R}^k$. My question is mostly about the language of this problem. The author says show that this is a map ${\bf onto}$ $\mathbb{R}^k$. Does this mean it is supposed to be a ${\bf surjective}$ map? If so, shouldn't the definition of the ball be such that $\{ x: |x|^2 < a^2 \}$, so that it is a ball of radius $a$, and points near the boundary get sent to infinity in $\mathbb{R}^k$?","This is a problem from Guilleman and Pollack: Page 5, question 4. Let $B_a$ be the open ball $\{ x: |x|^2 < a \}$ in $\mathbb{R}^k$, where $|x|^2 = \sum_i x_i^2$. Show that the map \begin{equation} x \mapsto \frac{ax}{\sqrt{a^2 - |x|^2}} \end{equation} is a diffeomorphism of $B_a$ onto $\mathbb{R}^k$. My question is mostly about the language of this problem. The author says show that this is a map ${\bf onto}$ $\mathbb{R}^k$. Does this mean it is supposed to be a ${\bf surjective}$ map? If so, shouldn't the definition of the ball be such that $\{ x: |x|^2 < a^2 \}$, so that it is a ball of radius $a$, and points near the boundary get sent to infinity in $\mathbb{R}^k$?",,"['general-topology', 'differential-geometry', 'differential-topology']"
35,How to prove the Bonnesen's Inequality?,How to prove the Bonnesen's Inequality?,,"The Bonnesen's Inequality states that for a convex plane curve, which has length $L$ and encloses an area $A$, $$rL \ge A+ \pi r^2 \text{ for all } R_\text{in} \le r \le R_\text{out}$$ where $R_\text{in}$ is the inradius of the curve, and $R_\text{out}$ is the circumradius. I've seen some papers show that it comes from $2A + 2Lr + 2 \pi r^2 \le 4rL$, but still I don't have any idea about this.","The Bonnesen's Inequality states that for a convex plane curve, which has length $L$ and encloses an area $A$, $$rL \ge A+ \pi r^2 \text{ for all } R_\text{in} \le r \le R_\text{out}$$ where $R_\text{in}$ is the inradius of the curve, and $R_\text{out}$ is the circumradius. I've seen some papers show that it comes from $2A + 2Lr + 2 \pi r^2 \le 4rL$, but still I don't have any idea about this.",,"['differential-geometry', 'inequality']"
36,How to understand immersed submanifold?,How to understand immersed submanifold?,,"I read this from Loring Tu's book: I am so confused what ""the topology and differentiable structure inherited from $f$"" really means. This one doesn't stuck me when I first went here. But in the following chapter of Lie groups, I run through this again: I wonder if there is a given smooth structure on $H$ itself. I can hardly understand ""an immersed submanifold via the inclusion map"". If here we can define ""immersion"", we must first give $H$ a smooth structure. I am so confused. Any help will be appreciated.","I read this from Loring Tu's book: I am so confused what ""the topology and differentiable structure inherited from $f$"" really means. This one doesn't stuck me when I first went here. But in the following chapter of Lie groups, I run through this again: I wonder if there is a given smooth structure on $H$ itself. I can hardly understand ""an immersed submanifold via the inclusion map"". If here we can define ""immersion"", we must first give $H$ a smooth structure. I am so confused. Any help will be appreciated.",,"['differential-geometry', 'manifolds', 'differential-topology', 'lie-groups', 'smooth-manifolds']"
37,Line in product mainifold,Line in product mainifold,,"Let $(M_1, g_1)$ and $(M_2, g_2)$  be two complete Riemannian manifolds and consider the product $(M, g) = (M_1 \times M_2, g_1 + g_2)$. Let $\gamma : \mathbb{R} \to (M,g )$ be a line. I can write $t \mapsto \gamma(t) = ( \gamma_1(t), \gamma_2(t))$, where $\gamma_1(t) \in M_1$ and $\gamma_2(t) \in M_2$. I know that if $\gamma$ is a geodesic then also $\gamma_1$ and $\gamma_2$ are geodesics in $(M_1, g_1)$ and $(M_2, g_2)$  respectively. My question is If $\gamma$ is a line , how can I prove that $\gamma_1$ and $\gamma_2$ are lines (assuming that they are not constant and up to a scaling factor)? Thanks! EDIT : Let $(N, g_N)$ be a Riemannian manifold. A geodesic $l : \mathbb{R} \to (N, g_N)$ is said to be a line if  $$ dist\big(l(s), l(t)\big) = |t-s| $$ for every $t, s \in \mathbb{R}$.","Let $(M_1, g_1)$ and $(M_2, g_2)$  be two complete Riemannian manifolds and consider the product $(M, g) = (M_1 \times M_2, g_1 + g_2)$. Let $\gamma : \mathbb{R} \to (M,g )$ be a line. I can write $t \mapsto \gamma(t) = ( \gamma_1(t), \gamma_2(t))$, where $\gamma_1(t) \in M_1$ and $\gamma_2(t) \in M_2$. I know that if $\gamma$ is a geodesic then also $\gamma_1$ and $\gamma_2$ are geodesics in $(M_1, g_1)$ and $(M_2, g_2)$  respectively. My question is If $\gamma$ is a line , how can I prove that $\gamma_1$ and $\gamma_2$ are lines (assuming that they are not constant and up to a scaling factor)? Thanks! EDIT : Let $(N, g_N)$ be a Riemannian manifold. A geodesic $l : \mathbb{R} \to (N, g_N)$ is said to be a line if  $$ dist\big(l(s), l(t)\big) = |t-s| $$ for every $t, s \in \mathbb{R}$.",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
38,computational insight behind why connections fix the shape of surface,computational insight behind why connections fix the shape of surface,,"Based on a video lecture, I had some queries. If we just have a manifold [M-set,O-topology,A-atlas] say $S^2$, this manifold represents a football or a potato equally. But once we choose a connection $\nabla$ on it, it will only represent say an ellipsoid and nothing else. It's shape is now fixed. No stretching or deformation is now allowed. Can you explicitly define a connection on $S^2$ and show why it is fixing the shape of the manifold computationally (Even the example of a spherical connection will do)? Conversely, given a shape of the manifold, how can its connection be written down explicitly from that piece of information? Maybe the latter question makes more sense than the former question! It seems clear to me in respect of real functions $f:\mathbb{R}\rightarrow \mathbb{R}$ that if $f'$ is given and some initial conditions, the shape of curve $""f(x)\,\,vs\,\,x""$ is fixed. But how does this generalize in terms of manifold and connection? What is the underlying physical idea/intuition behind this relationship of an abstract concept viz. connection and the physical shape? This must have to do with the very early days when connection was defined. But modern expositions of connection don't go into all that and it difficult to find those ideas. EDIT: Based on Lee Mosher's comment i shortened the question and will ask other queries later in other questions.","Based on a video lecture, I had some queries. If we just have a manifold [M-set,O-topology,A-atlas] say $S^2$, this manifold represents a football or a potato equally. But once we choose a connection $\nabla$ on it, it will only represent say an ellipsoid and nothing else. It's shape is now fixed. No stretching or deformation is now allowed. Can you explicitly define a connection on $S^2$ and show why it is fixing the shape of the manifold computationally (Even the example of a spherical connection will do)? Conversely, given a shape of the manifold, how can its connection be written down explicitly from that piece of information? Maybe the latter question makes more sense than the former question! It seems clear to me in respect of real functions $f:\mathbb{R}\rightarrow \mathbb{R}$ that if $f'$ is given and some initial conditions, the shape of curve $""f(x)\,\,vs\,\,x""$ is fixed. But how does this generalize in terms of manifold and connection? What is the underlying physical idea/intuition behind this relationship of an abstract concept viz. connection and the physical shape? This must have to do with the very early days when connection was defined. But modern expositions of connection don't go into all that and it difficult to find those ideas. EDIT: Based on Lee Mosher's comment i shortened the question and will ask other queries later in other questions.",,"['differential-geometry', 'reference-request', 'manifolds', 'connections']"
39,Defining a Riemannian metric,Defining a Riemannian metric,,"Let $M$ be a smooth manifold. I have seen a Riemannian metric be defined in many ways: A smooth choice of an inner product $g_p:T_pM\times T_pM\to\mathbb{R}$ which is symmetric and positive-definite, at each point $p\in M$. An element of $\Gamma(T^\ast M\otimes T^\ast M)$ (which is positive-definite, symmetric) An element of $\Gamma(\mathrm{Hom}(TM\otimes TM,\mathbb{R}))$ (positive-definite, symmetric) Are these all equivalent? The reason why I wonder is that if $TM$ is not parallelisable, then $\Gamma(TM)$ is not a free module, so we don't have the isomorphism $\Gamma(T^\ast M)\otimes\Gamma(T^\ast M))\cong\mathrm{Hom}(\Gamma(TM)\otimes\Gamma(TM),C^\infty(M))$. EDIT Can we equivalently define a Riemannian metric as an element of $\Gamma(T^\ast M)\otimes\Gamma(T^\ast M)$, or is this just utterly wrong?","Let $M$ be a smooth manifold. I have seen a Riemannian metric be defined in many ways: A smooth choice of an inner product $g_p:T_pM\times T_pM\to\mathbb{R}$ which is symmetric and positive-definite, at each point $p\in M$. An element of $\Gamma(T^\ast M\otimes T^\ast M)$ (which is positive-definite, symmetric) An element of $\Gamma(\mathrm{Hom}(TM\otimes TM,\mathbb{R}))$ (positive-definite, symmetric) Are these all equivalent? The reason why I wonder is that if $TM$ is not parallelisable, then $\Gamma(TM)$ is not a free module, so we don't have the isomorphism $\Gamma(T^\ast M)\otimes\Gamma(T^\ast M))\cong\mathrm{Hom}(\Gamma(TM)\otimes\Gamma(TM),C^\infty(M))$. EDIT Can we equivalently define a Riemannian metric as an element of $\Gamma(T^\ast M)\otimes\Gamma(T^\ast M)$, or is this just utterly wrong?",,"['differential-geometry', 'smooth-manifolds', 'tensors', 'vector-bundles']"
40,Connection after a metric rescaling and compatibility,Connection after a metric rescaling and compatibility,,"It's known (see here for example) that after a rescaling of the metric $\tilde{g}=e^{2\omega}g$, we can find a new connection $\tilde\nabla$ associated to the new metric: $ \tilde\nabla _X Y = \nabla _X Y + (X \omega )Y + (Y \omega )X - g(X,Y) \operatorname{grad}\omega \tag{1}, $ where $\nabla$ is the Levi-Civita connection of $(M,g)$. In coordinates: $ \tilde\Gamma^{k}_{ij}=\Gamma^{k}_{ij} + \delta_{i}^{k} \partial_j \omega  + \delta_{j}^{k} \partial_i \omega - g_{i j} g^{k l} \partial_{l} \omega. \tag{2} $ My question is: is the new connection $\tilde\nabla$ compatible with the new metric $\tilde g$? I am using Equation (1) together with the property $ X[\tilde g(Y,Z)] = (\tilde\nabla_X\tilde g)(Y,Z)+\tilde g(\tilde\nabla_XY,Z)+\tilde g(Y,\tilde\nabla_XZ)\tag{3}, $ but I am not getting $\tilde\nabla\tilde g = 0$. Instead $\tilde\nabla\tilde g$ is proportional to the new metric. Is this right?","It's known (see here for example) that after a rescaling of the metric $\tilde{g}=e^{2\omega}g$, we can find a new connection $\tilde\nabla$ associated to the new metric: $ \tilde\nabla _X Y = \nabla _X Y + (X \omega )Y + (Y \omega )X - g(X,Y) \operatorname{grad}\omega \tag{1}, $ where $\nabla$ is the Levi-Civita connection of $(M,g)$. In coordinates: $ \tilde\Gamma^{k}_{ij}=\Gamma^{k}_{ij} + \delta_{i}^{k} \partial_j \omega  + \delta_{j}^{k} \partial_i \omega - g_{i j} g^{k l} \partial_{l} \omega. \tag{2} $ My question is: is the new connection $\tilde\nabla$ compatible with the new metric $\tilde g$? I am using Equation (1) together with the property $ X[\tilde g(Y,Z)] = (\tilde\nabla_X\tilde g)(Y,Z)+\tilde g(\tilde\nabla_XY,Z)+\tilde g(Y,\tilde\nabla_XZ)\tag{3}, $ but I am not getting $\tilde\nabla\tilde g = 0$. Instead $\tilde\nabla\tilde g$ is proportional to the new metric. Is this right?",,['differential-geometry']
41,Gauge condition equivalent to condition that coordinate functions satisfy wave equation to first order,Gauge condition equivalent to condition that coordinate functions satisfy wave equation to first order,,"Let $\eta_{ab}$ be the metric of special relativity and let $x^\mu$ be global inertial coordinates of $\eta_{ab}$. Let $\gamma_{ab}$ be a small perturbation of $\eta_{ab}$. How do I see that the gauge condition$$0 = \partial^a \overline{\gamma}_{ab} = \partial^a \gamma_{ab} - {1\over2}\partial_b \gamma$$is equivalent to the condition that the coordinate functions $x^\mu$ satisfy the wave equation $\nabla^a \nabla_a x^\mu = 0$ to first order in $\gamma_{ab}$, where $\nabla_a$ is the derivative operator associated with $g_{ab} = \eta_{ab} + \gamma_{ab}$?","Let $\eta_{ab}$ be the metric of special relativity and let $x^\mu$ be global inertial coordinates of $\eta_{ab}$. Let $\gamma_{ab}$ be a small perturbation of $\eta_{ab}$. How do I see that the gauge condition$$0 = \partial^a \overline{\gamma}_{ab} = \partial^a \gamma_{ab} - {1\over2}\partial_b \gamma$$is equivalent to the condition that the coordinate functions $x^\mu$ satisfy the wave equation $\nabla^a \nabla_a x^\mu = 0$ to first order in $\gamma_{ab}$, where $\nabla_a$ is the derivative operator associated with $g_{ab} = \eta_{ab} + \gamma_{ab}$?",,"['differential-geometry', 'riemannian-geometry']"
42,"Rotor of a vector field in coordinates $x^1,x^2,x^3$",Rotor of a vector field in coordinates,"x^1,x^2,x^3","Let $U\subset \mathbb{R}^3$ be an open subset endowed with a triple orthogonal coordinate system $\{x^1,x^2,x^3\}$ and let $X$ be a smooth vector field on $U$. The vector field rot$X$ (or curl$X$) which is called a rotor (or curl) of a vector field $X$ can be defined in coordinates $x^1,x^2,x^3$ by means of the forms $\omega_X,\theta_X$, which are defined as  $$(\omega_X)_p(v_p)=\langle X_p,v_p\rangle,$$ $$(\theta_X)_p(v_p,w_p)=\langle X_p,v_p\times w_p\rangle,$$ in a following way $$d\omega_X=\theta_{\text{rot}X}$$ where $d$ is the exterior derivative. Find the rotor of the vector field $X$ in coordinates $x^1,x^2,x^3$ and then in particular cases of Cartesian cylindrical and spherical coordinates. Should I first prove that $\omega$ is a 1-form and $\theta$ is a 2-form? Any ideas on how to approach this problem?","Let $U\subset \mathbb{R}^3$ be an open subset endowed with a triple orthogonal coordinate system $\{x^1,x^2,x^3\}$ and let $X$ be a smooth vector field on $U$. The vector field rot$X$ (or curl$X$) which is called a rotor (or curl) of a vector field $X$ can be defined in coordinates $x^1,x^2,x^3$ by means of the forms $\omega_X,\theta_X$, which are defined as  $$(\omega_X)_p(v_p)=\langle X_p,v_p\rangle,$$ $$(\theta_X)_p(v_p,w_p)=\langle X_p,v_p\times w_p\rangle,$$ in a following way $$d\omega_X=\theta_{\text{rot}X}$$ where $d$ is the exterior derivative. Find the rotor of the vector field $X$ in coordinates $x^1,x^2,x^3$ and then in particular cases of Cartesian cylindrical and spherical coordinates. Should I first prove that $\omega$ is a 1-form and $\theta$ is a 2-form? Any ideas on how to approach this problem?",,['differential-geometry']
43,The tangent map of multiplication - Maurer-Cartan form,The tangent map of multiplication - Maurer-Cartan form,,"Question: Consider the multiplication map $\mu : G \times G \to G$ of a Lie group. So on the tangent level we have a map $T(G \times G) \to TG$. Making the proper identification $T(G\times G) \simeq TG \times TG$ and also identifying $TG$ with $G \times \mathfrak g$ through $\mathrm{triv}_L v_x \mapsto (x, \omega_G(v_x)) = (x , TL_{x^{-1}}\cdot v_x)$. Show that the map ""$T\mu$"" defined so that the following diagram commute is given by $$((x,v),(y,w))\mapsto (xy, TR_y \cdot v + TL_x \cdot w )$$   where the diagram is $$\require{AMScd}\begin{CD}T(G \times G) \simeq TG \times TG @>{T\mu}>> TG\\@VVV@VVV\\(G \times \mathfrak g)\times(G \times \mathfrak g)@>{""T\mu""}>> G \times \mathfrak g\end{CD}$$ Attempt: The idea was to simply find $T\mu = \mathrm{triv}_L \circ T\mu \circ (\mathrm{triv}_L \times \mathrm{triv}_L)^{-1}$ and this is what I have so far $$(\mathrm{triv}_L \times \mathrm{triv}_L)^{-1}  ((x,v),(y,w)) = (L_x ^ v, L_y^w) $$ then $$T\mu (L_x ^ v, L_y^w) = L_x ^ v +  L_y^w \implies \mathrm{triv}_L (L_x ^ v +  L_y^w) = (xy, TL_{(xy)^{-1}} (L_x^v + L_y^w))$$ Now working on the second coordinate of the last equation we obtain $$\begin{align}TL_{(xy)^{-1}} (L_x^v + L_y^w) &= TL_{(xy)^{-1}} TL_{x}\cdot v_x + TL_{(xy)^{-1}}TL_{y}\cdot w_y\\&= TL_{y^{-1}x^{-1}}TL_{x}\cdot v_x + TL_{y^{-1}x^{-1}}TL_{y}\cdot w_y\\&=TL_{y^{-1}}\cdot v_x +TL_{y^{-1}}TL_{x^{-1}}TL_{y}\cdot w_y \end{align}$$ and I couldn't get past this. Any ideas on how I should go on? Note1: This is the Exercise 5.94 of Jeffrey Lee's Manifolds and Differential Geometry. Note2: $L_x^v = T_e L_x \cdot v_x$ is the left-invariant vector field corresponding to $v_x \in TG$.","Question: Consider the multiplication map $\mu : G \times G \to G$ of a Lie group. So on the tangent level we have a map $T(G \times G) \to TG$. Making the proper identification $T(G\times G) \simeq TG \times TG$ and also identifying $TG$ with $G \times \mathfrak g$ through $\mathrm{triv}_L v_x \mapsto (x, \omega_G(v_x)) = (x , TL_{x^{-1}}\cdot v_x)$. Show that the map ""$T\mu$"" defined so that the following diagram commute is given by $$((x,v),(y,w))\mapsto (xy, TR_y \cdot v + TL_x \cdot w )$$   where the diagram is $$\require{AMScd}\begin{CD}T(G \times G) \simeq TG \times TG @>{T\mu}>> TG\\@VVV@VVV\\(G \times \mathfrak g)\times(G \times \mathfrak g)@>{""T\mu""}>> G \times \mathfrak g\end{CD}$$ Attempt: The idea was to simply find $T\mu = \mathrm{triv}_L \circ T\mu \circ (\mathrm{triv}_L \times \mathrm{triv}_L)^{-1}$ and this is what I have so far $$(\mathrm{triv}_L \times \mathrm{triv}_L)^{-1}  ((x,v),(y,w)) = (L_x ^ v, L_y^w) $$ then $$T\mu (L_x ^ v, L_y^w) = L_x ^ v +  L_y^w \implies \mathrm{triv}_L (L_x ^ v +  L_y^w) = (xy, TL_{(xy)^{-1}} (L_x^v + L_y^w))$$ Now working on the second coordinate of the last equation we obtain $$\begin{align}TL_{(xy)^{-1}} (L_x^v + L_y^w) &= TL_{(xy)^{-1}} TL_{x}\cdot v_x + TL_{(xy)^{-1}}TL_{y}\cdot w_y\\&= TL_{y^{-1}x^{-1}}TL_{x}\cdot v_x + TL_{y^{-1}x^{-1}}TL_{y}\cdot w_y\\&=TL_{y^{-1}}\cdot v_x +TL_{y^{-1}}TL_{x^{-1}}TL_{y}\cdot w_y \end{align}$$ and I couldn't get past this. Any ideas on how I should go on? Note1: This is the Exercise 5.94 of Jeffrey Lee's Manifolds and Differential Geometry. Note2: $L_x^v = T_e L_x \cdot v_x$ is the left-invariant vector field corresponding to $v_x \in TG$.",,"['differential-geometry', 'proof-verification', 'lie-groups']"
44,Product of inexact differential forms is inexact,Product of inexact differential forms is inexact,,"Suppose we have a product manifold $M = M_1 \times M_2$. Let $\omega$ be a closed but inexact form on $M_1$ and $\eta$ a closed but inexact form on $M_2$. Then the claim is that $$\omega \wedge \eta$$ is inexact on the manifold $M$. I $\require{enclose}\enclose{horizontalstrike}{\mathrm{suspect}}$ know that the general statement ""a product of inexact forms is inexact"" is false, but I don't know how to go about proving the above claim. The context of this question is in de Rham cohomology: I'm trying to prove Künneth's formula, and as a prelude I want to show that differential forms of the form above correspond to non-trivial elements of the cohomology groups of $M$.","Suppose we have a product manifold $M = M_1 \times M_2$. Let $\omega$ be a closed but inexact form on $M_1$ and $\eta$ a closed but inexact form on $M_2$. Then the claim is that $$\omega \wedge \eta$$ is inexact on the manifold $M$. I $\require{enclose}\enclose{horizontalstrike}{\mathrm{suspect}}$ know that the general statement ""a product of inexact forms is inexact"" is false, but I don't know how to go about proving the above claim. The context of this question is in de Rham cohomology: I'm trying to prove Künneth's formula, and as a prelude I want to show that differential forms of the form above correspond to non-trivial elements of the cohomology groups of $M$.",,"['differential-geometry', 'homology-cohomology']"
45,Dirichlet problem for a ball in a Riemannian Manifold,Dirichlet problem for a ball in a Riemannian Manifold,,"I'm trying to work through the 2nd chapter ""Volume comparison"" of Jeff Cheeger's ""Degeneration of Riemannian Metrics under Ricci Curvature Bounds"". But with the last section I have some problems. First some notation: Let $ M^n $ be a Riemannian Manifold, $ p\in M^n $. $ \mathcal A(r) $ denotes the area element of $ \partial B_r(p) $ in geodesic polar coordinates. Symbols, that are underlined, are in the complete simply connected space with constant curvature $ H $ ($H$ is a real constant). For $h\geq 0$ a nonnegative function, we define $$ \mathcal F_h(x_1,x_2)=\inf_{\gamma} \int_0^l \! h(\gamma(s)) \, ds $$ (here the infimum is taken over all minimal geodesics from $x_1$ to $x_2$, $s$ denotes arclength. Cheeger is proving the segment inequality: Let $ \operatorname{Ric}_{M^n}\geq -(n-1) $ and $ A_1, A_2\subseteq B_r(p) $ with $ r\leq R $. Then $$ \int_{A_1\times A_2}\! \mathcal F_h(x_1,x_2) \, d(x_1,x_2)\leq c(n,R) r (\operatorname{vol}(A_1)+\operatorname{vol}(A_2))\cdot \int_{B_{2R}(p)}\! h(x) \, dx, $$ where $$ c(n,R)=\sup_{0<\frac s2\leq u\leq s} \frac{\underline{\mathcal A}(s)}{\underline{\mathcal A}(u)}. $$ Now to my problems: In the next section about the  Poincaré inequality, Cheeger writes: If $h=|\nabla f|$, then $|f(x_1)-f(x_2)|\leq \mathcal F_h(x_1, x_2)\quad (*)$. Has anyone some hints, how to show this? In the next paragraph, he shows a lower bound for the Dirichlet problem for $B_r(p)$: Let $\operatorname{Ric}_{M^n}\geq (n-1)H$ and $\partial B_{3r}(p)\neq \emptyset$. If $f: B_r(p)\to\mathbb R$ with $f|_{\partial B_r(p)}=0$, we can extend $f$ to $B_{3r}(p)$ by setting $f=0$ in $B_{3r}(p)\setminus B_r(p)$. If we choose $h=|\nabla f^2|$, a straightforward application of the segment inequality and relative volume comparison shows, that there exists $x_1\in B_{\frac 32 r}(p)\setminus B_r(p)$, such that $$ \int_{B_{\frac 32 r(p)}}\! |f^2(x_2)|\, dx_2\leq \int_{B_{\frac 32 r(p)}}\! |\mathcal F_{|\nabla f^2|}(x_1, x_2)|\, dx_2\leq c(n,R)r \int_{B_{\frac 32 r(p)}}\! |\nabla f^2(x_2)|\, dx_2. $$ Here is my next problem: The first inequality follows from $(*)$. But I have no idea, how to show the second inequality. And this should ""easily imply"", that $ \lambda_1\geq c(n,R)r^2>0 $ (where $\lambda_1$ is the smallest eigenvalue for the Dirichlet problem for $B_r(p)$). Same here: Some hints to show this? (I think, ""easily imply"" is too difficult for me ;-)) Thank you very much for some help. (And I hope my English is not too bad ;-))","I'm trying to work through the 2nd chapter ""Volume comparison"" of Jeff Cheeger's ""Degeneration of Riemannian Metrics under Ricci Curvature Bounds"". But with the last section I have some problems. First some notation: Let $ M^n $ be a Riemannian Manifold, $ p\in M^n $. $ \mathcal A(r) $ denotes the area element of $ \partial B_r(p) $ in geodesic polar coordinates. Symbols, that are underlined, are in the complete simply connected space with constant curvature $ H $ ($H$ is a real constant). For $h\geq 0$ a nonnegative function, we define $$ \mathcal F_h(x_1,x_2)=\inf_{\gamma} \int_0^l \! h(\gamma(s)) \, ds $$ (here the infimum is taken over all minimal geodesics from $x_1$ to $x_2$, $s$ denotes arclength. Cheeger is proving the segment inequality: Let $ \operatorname{Ric}_{M^n}\geq -(n-1) $ and $ A_1, A_2\subseteq B_r(p) $ with $ r\leq R $. Then $$ \int_{A_1\times A_2}\! \mathcal F_h(x_1,x_2) \, d(x_1,x_2)\leq c(n,R) r (\operatorname{vol}(A_1)+\operatorname{vol}(A_2))\cdot \int_{B_{2R}(p)}\! h(x) \, dx, $$ where $$ c(n,R)=\sup_{0<\frac s2\leq u\leq s} \frac{\underline{\mathcal A}(s)}{\underline{\mathcal A}(u)}. $$ Now to my problems: In the next section about the  Poincaré inequality, Cheeger writes: If $h=|\nabla f|$, then $|f(x_1)-f(x_2)|\leq \mathcal F_h(x_1, x_2)\quad (*)$. Has anyone some hints, how to show this? In the next paragraph, he shows a lower bound for the Dirichlet problem for $B_r(p)$: Let $\operatorname{Ric}_{M^n}\geq (n-1)H$ and $\partial B_{3r}(p)\neq \emptyset$. If $f: B_r(p)\to\mathbb R$ with $f|_{\partial B_r(p)}=0$, we can extend $f$ to $B_{3r}(p)$ by setting $f=0$ in $B_{3r}(p)\setminus B_r(p)$. If we choose $h=|\nabla f^2|$, a straightforward application of the segment inequality and relative volume comparison shows, that there exists $x_1\in B_{\frac 32 r}(p)\setminus B_r(p)$, such that $$ \int_{B_{\frac 32 r(p)}}\! |f^2(x_2)|\, dx_2\leq \int_{B_{\frac 32 r(p)}}\! |\mathcal F_{|\nabla f^2|}(x_1, x_2)|\, dx_2\leq c(n,R)r \int_{B_{\frac 32 r(p)}}\! |\nabla f^2(x_2)|\, dx_2. $$ Here is my next problem: The first inequality follows from $(*)$. But I have no idea, how to show the second inequality. And this should ""easily imply"", that $ \lambda_1\geq c(n,R)r^2>0 $ (where $\lambda_1$ is the smallest eigenvalue for the Dirichlet problem for $B_r(p)$). Same here: Some hints to show this? (I think, ""easily imply"" is too difficult for me ;-)) Thank you very much for some help. (And I hope my English is not too bad ;-))",,"['differential-geometry', 'riemannian-geometry']"
46,A semisimple Lie group has no character; Am I right?,A semisimple Lie group has no character; Am I right?,,"Let $G$ be a compact connected Lie group with semisimple Lie algebra ${\frak g}$. With the following reasoning, I show that there is no non-trivial Lie group homomorphism $$\chi:G\to S^1.$$ Is that true? Proof. Let $\chi:G\to S^1\subseteq\Bbb C$ be a character. Then, $d\chi:{\frak g}\to i\Bbb R$ so $id\chi:{\frak g}\to \Bbb R$, i.e. $id\chi\in{\frak g}^*$. But since $\chi$ is a homomorphism, and $S^1$ is abelian, we have for all $g\in G$ and $X\in{\frak g}$ that $$({\operatorname{Ad}}_g^*id\chi)(X)=i\frac{d}{dt}\Big|_{t=0}\chi(\exp(t\operatorname{Ad}_{g^{-1}}(X)))=i\frac{d}{dt}\Big|_{t=0}\chi(g^{-1}\exp(tX)g)=i\frac{d}{dt}\chi(\exp(tX))=id\chi(X).$$ Thus, $\operatorname{Ad}_g^*id\chi=id\chi$ for all $g\in G$. Using the Killing form to identify $id\chi\in{\frak g}^*$ with an element $X_{\chi}\in{\frak g}$, we find $\operatorname{Ad}_g(X_{\chi})=X_{\chi}$ for all $g\in G$. Thus, $X_{\chi}\in\operatorname{Lie}(Z_G)=Z_{{\frak g}}$ (where $Z$ means ""center""). But a semisimple Lie algebra has zero center and hence $X_{\chi}=0$. Thus, $id\chi=0$ and hence $\chi=1$. $$\tag{Q.E.D.}$$","Let $G$ be a compact connected Lie group with semisimple Lie algebra ${\frak g}$. With the following reasoning, I show that there is no non-trivial Lie group homomorphism $$\chi:G\to S^1.$$ Is that true? Proof. Let $\chi:G\to S^1\subseteq\Bbb C$ be a character. Then, $d\chi:{\frak g}\to i\Bbb R$ so $id\chi:{\frak g}\to \Bbb R$, i.e. $id\chi\in{\frak g}^*$. But since $\chi$ is a homomorphism, and $S^1$ is abelian, we have for all $g\in G$ and $X\in{\frak g}$ that $$({\operatorname{Ad}}_g^*id\chi)(X)=i\frac{d}{dt}\Big|_{t=0}\chi(\exp(t\operatorname{Ad}_{g^{-1}}(X)))=i\frac{d}{dt}\Big|_{t=0}\chi(g^{-1}\exp(tX)g)=i\frac{d}{dt}\chi(\exp(tX))=id\chi(X).$$ Thus, $\operatorname{Ad}_g^*id\chi=id\chi$ for all $g\in G$. Using the Killing form to identify $id\chi\in{\frak g}^*$ with an element $X_{\chi}\in{\frak g}$, we find $\operatorname{Ad}_g(X_{\chi})=X_{\chi}$ for all $g\in G$. Thus, $X_{\chi}\in\operatorname{Lie}(Z_G)=Z_{{\frak g}}$ (where $Z$ means ""center""). But a semisimple Lie algebra has zero center and hence $X_{\chi}=0$. Thus, $id\chi=0$ and hence $\chi=1$. $$\tag{Q.E.D.}$$",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
47,Question about two ways to induce an inner product on $S^2V$,Question about two ways to induce an inner product on,S^2V,"$\newcommand{\til}{\tilde}$ Let $(V,g)$ be an $n$-dimensional inner product space, and let $S^2V^*$ be the symmetric algebra. I am familiar with a natural way to endow $S^2V^*$ with an inner product via $g$. In the paper The Riemannian Manifold of all Riemannian Metrics (by Gil-Medrano, Michor) a different way of endowing $S^2V^*$ with a product is described and I suspect it amounts to the same product I am familiar with. Question: Are these inner products identical (maybe up to a scalar multiple)?  (I will now describe the two approaches) Approach 1: We can think of $S^2V^*$ as the vector space of symmetric bilinear maps $V \times V \to \mathbb{R}$. As such, it is a subspace of $W:=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear} \}  \cong V^* \otimes V^*$ (The isomorphism is canonical). The inner ptoduct $g$ induces an inner product on $V^*$ which in turn induces a product on $W$. Now $S^2V^*$ inherits the inner product from $W$. Approach 2 (from the paper): Let $B \in S^2V^*=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear and symmetric} \}$. $B$ induces a (linear) map $T_B:V \to V^*$ via $T_B(v)(\til v)=B(v,\til v)$. If $B$ is non-degenerate then $T_B$ is invertible. (In particular this is true for $T_g$). Now, given $h,k \in S^2V^*$ , we define $\langle h,k \rangle_g =\operatorname{tr}(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ Note that $(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ is a linear map $V \to V$ so its trace is defined.","$\newcommand{\til}{\tilde}$ Let $(V,g)$ be an $n$-dimensional inner product space, and let $S^2V^*$ be the symmetric algebra. I am familiar with a natural way to endow $S^2V^*$ with an inner product via $g$. In the paper The Riemannian Manifold of all Riemannian Metrics (by Gil-Medrano, Michor) a different way of endowing $S^2V^*$ with a product is described and I suspect it amounts to the same product I am familiar with. Question: Are these inner products identical (maybe up to a scalar multiple)?  (I will now describe the two approaches) Approach 1: We can think of $S^2V^*$ as the vector space of symmetric bilinear maps $V \times V \to \mathbb{R}$. As such, it is a subspace of $W:=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear} \}  \cong V^* \otimes V^*$ (The isomorphism is canonical). The inner ptoduct $g$ induces an inner product on $V^*$ which in turn induces a product on $W$. Now $S^2V^*$ inherits the inner product from $W$. Approach 2 (from the paper): Let $B \in S^2V^*=\{T:V \times V \to \mathbb{R}| \, T \text{ is bilinear and symmetric} \}$. $B$ induces a (linear) map $T_B:V \to V^*$ via $T_B(v)(\til v)=B(v,\til v)$. If $B$ is non-degenerate then $T_B$ is invertible. (In particular this is true for $T_g$). Now, given $h,k \in S^2V^*$ , we define $\langle h,k \rangle_g =\operatorname{tr}(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ Note that $(T_g^{-1}\circ T_h \circ T_g^{-1} \circ T_k)$ is a linear map $V \to V$ so its trace is defined.",,"['linear-algebra', 'differential-geometry', 'riemannian-geometry', 'inner-products', 'tensor-products']"
48,Calculating the differential of the inverse of matrix exp?,Calculating the differential of the inverse of matrix exp?,,"Let $A(t)$ and $B(t)$ be two matrix-valued smooth function satisfying the equation, $B(t) = e^{A(t)}$. I need to express $\frac{dA(t)}{dt}$ in terms of $B(t)$. I know that there is a formula of Wilcox, namely $$ \frac{d}{dt} e^{A(t)} = \int_0^1 e^{s A(t) } \frac{dA(t)}{dt}  e^{(1-s) A(t) } ds.$$ But I need something of the opposite direction. Does anyone know if there is such a formula or a general method to calculate that?","Let $A(t)$ and $B(t)$ be two matrix-valued smooth function satisfying the equation, $B(t) = e^{A(t)}$. I need to express $\frac{dA(t)}{dt}$ in terms of $B(t)$. I know that there is a formula of Wilcox, namely $$ \frac{d}{dt} e^{A(t)} = \int_0^1 e^{s A(t) } \frac{dA(t)}{dt}  e^{(1-s) A(t) } ds.$$ But I need something of the opposite direction. Does anyone know if there is such a formula or a general method to calculate that?",,"['matrices', 'differential-geometry', 'lie-groups', 'matrix-calculus']"
49,Differentiability of an action of the group of invertible elements of a $C^{*}$-algebra $\mathcal{A}$ on the dual of $\mathcal{A}$,Differentiability of an action of the group of invertible elements of a -algebra  on the dual of,C^{*} \mathcal{A} \mathcal{A},"I am studying the actions of Banach-Lie groups on Banach manifolds, and I am not able to concretely evaluate the differentiability properties of a specific action. Let $\mathcal{A}$ be a unital $C^{*}$-algebra, and $\mathcal{A}^{*}$ its topological dual, which is a complex Banach space with norm: $$ \left|\left|\omega\right|\right|:=\sup\left\{|\omega(\mathbf{A})|\,;\mathbf{A}\in\mathcal{A}\colon||\mathbf{A}||=1\right\} $$ Let us denote with $\mathcal{G}(\mathcal{A})$ the set of all invertible elements in $\mathcal{A}$. This set is a Banach-Lie group with respect to the multiplication operation inherited from $\mathcal{A}$. This group naturally acts on $\mathcal{A}$ as follows: $$ \mathbf{A}\mapsto c_{\mathbf{G}}(\mathbf{A}):=\mathbf{G}\,\mathbf{A}\,\mathbf{G}^{\dagger}\,. $$ By means of this action, an action on $\mathcal{A}^{*}$ is obtained: $$ \omega\mapsto \alpha_{\mathbf{G}}(\omega) $$ $$ \left(\alpha_{\mathbf{G}}(\omega)\right)(\mathbf{A}):=\omega\left(c_{\mathbf{G}}(\mathbf{A})\right)=\omega\left(\mathbf{G}\,\mathbf{A}\,\mathbf{G}^{\dagger}\right)\,. $$ It is easy to see that this action is linear and preserves hermiticity. I am interested in the differentiability properties of this action. By definition, the action is differentiable if the map: $$ \mathcal{G}(\mathcal{A})\times\mathcal{A}^{*}\rightarrow\mathcal{A}^{*} $$  $$ (\mathbf{G}\,;\omega)\mapsto \alpha_{G}\omega $$ is differentiable. I know the abstract definition of differentiability (Frechet derivative) of a map between Banach manifolds, however, I do not know how to concretely proceed to investigate the subject. Specifically, a map $f:V\rightarrow W$ between Banach space is differentiable at $x_{0}\in V$ if, for all $\epsilon>0$ there exist $\delta_{\epsilon}>0$ and a bounded linear map $Df_{x_{0}}:V\rightarrow W$ such that: $$ ||f(x-x_{0}) - f(x_{0}) - Df_{x_{0}}(x-x_{0})||<\epsilon $$ whenever $||x-x_{0}||<\delta_{\epsilon}$. Since $\mathcal{G}(\mathcal{A})$ is only a Banach manifold, I need a coordinates system in order to use the definition of Frechet derivative, and I do not know what kind of coordinates system I should use. Furthermore, even if I knew it, I would need an ""educated guess"" of the explicit face of the derivative $Df_{x_{0}}$ to actually calculate the limit in the definition of the Frechet derivative. Are there other, more smart ways to proceed? Thank You in advance. EDIT With a little effort, I was able to prove that the linear map $\alpha_{\mathbf{G}}:\mathcal{A}^{*}\rightarrow\mathcal{A}^{*}$ is bounded, and thus continuous, for all $\mathbf{G}\in\mathcal{G}(\mathcal{A})$. This means that $\alpha_{\mathbf{G}}$ is analytic for all $\mathbf{G}$ (it is a continuous 1-homogeneous polynomial), but I do not know if it is of some relevance. EDIT 2 According to Andreas Cap's answer, I tried to work out the details without using the $t$ parameter. Let $U_{\mathbf{G}}\subset\mathcal{G}(\mathcal{A})$ be a neighbourhood of $\mathbf{G}$ such that $\mathbf{G}+\mathbf{H}\in U$ for all $\mathbf{H}\in U$. Then we can write: $$ \alpha(\mathbf{G}+\mathbf{H}\,;\omega + \tau)(\mathbf{A}) - \alpha(\mathbf{G}\,;\omega)(\mathbf{A})=\omega(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger}) + \omega(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) + \tau(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) + \tau(\mathbf{G}\mathbf{A}\mathbf{G}^{\dagger}) $$ The linear functional introduced by Andreas Cap is: $$ D\alpha_{\mathbf{G}\,;\omega}(\mathbf{H}\,;\tau)(\mathbf{A})=\omega(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger}) + \tau(\mathbf{G}\mathbf{A}\mathbf{G}^{\dagger}) $$ and thus: $$ \alpha(\mathbf{G}+\mathbf{H}\,;\omega + \tau)(\mathbf{A}) - \alpha(\mathbf{G}\,;\omega)(\mathbf{A}) - D\alpha_{\mathbf{G}\,;\omega}(\mathbf{H}\,;\tau)(\mathbf{A})= \tau(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger})+ (\omega+\tau)(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) $$ Let us call this functional $\gamma$. The norm of $\gamma$ is: $$ ||\gamma||=\sup_{\mathbf{A}\neq\mathbf{0}}\frac{|\gamma(\mathbf{A})|}{||\mathbf{A}||} $$ Then: $$ |\gamma(\mathbf{A})|\leq|\tau(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger})| + |(\omega+\tau)(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger})|\leq $$ $$ \leq2||\tau||\,||\mathbf{G}||\,||\mathbf{A}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2}\,||\mathbf{A}|| + ||\tau||\,||\mathbf{H}||^{2} \,||\mathbf{A}|| $$ which means: $$ ||\gamma||=2||\tau||\,||\mathbf{G}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2} + ||\tau||\,||\mathbf{H}||^{2} $$ The action $\alpha$ is differentiable at $(\mathbf{G}\,;\omega)$ if, for all $\epsilon>0$ there exists $\delta_{\epsilon}>0$ such that: $$ \frac{||\gamma||}{||(\mathbf{H}\,;\tau)||}<\epsilon $$ whenever $||(\mathbf{H}\,;\tau)||<\delta_{\epsilon}$. However, we have: $$ \frac{||\gamma||}{||(\mathbf{H}\,;\tau)||}=\frac{2||\tau||\,||\mathbf{G}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2} + ||\tau||\,||\mathbf{H}||^{2}}{||\mathbf{H}|| +||\tau||} $$ and I am not sure that this is less than $\epsilon$.","I am studying the actions of Banach-Lie groups on Banach manifolds, and I am not able to concretely evaluate the differentiability properties of a specific action. Let $\mathcal{A}$ be a unital $C^{*}$-algebra, and $\mathcal{A}^{*}$ its topological dual, which is a complex Banach space with norm: $$ \left|\left|\omega\right|\right|:=\sup\left\{|\omega(\mathbf{A})|\,;\mathbf{A}\in\mathcal{A}\colon||\mathbf{A}||=1\right\} $$ Let us denote with $\mathcal{G}(\mathcal{A})$ the set of all invertible elements in $\mathcal{A}$. This set is a Banach-Lie group with respect to the multiplication operation inherited from $\mathcal{A}$. This group naturally acts on $\mathcal{A}$ as follows: $$ \mathbf{A}\mapsto c_{\mathbf{G}}(\mathbf{A}):=\mathbf{G}\,\mathbf{A}\,\mathbf{G}^{\dagger}\,. $$ By means of this action, an action on $\mathcal{A}^{*}$ is obtained: $$ \omega\mapsto \alpha_{\mathbf{G}}(\omega) $$ $$ \left(\alpha_{\mathbf{G}}(\omega)\right)(\mathbf{A}):=\omega\left(c_{\mathbf{G}}(\mathbf{A})\right)=\omega\left(\mathbf{G}\,\mathbf{A}\,\mathbf{G}^{\dagger}\right)\,. $$ It is easy to see that this action is linear and preserves hermiticity. I am interested in the differentiability properties of this action. By definition, the action is differentiable if the map: $$ \mathcal{G}(\mathcal{A})\times\mathcal{A}^{*}\rightarrow\mathcal{A}^{*} $$  $$ (\mathbf{G}\,;\omega)\mapsto \alpha_{G}\omega $$ is differentiable. I know the abstract definition of differentiability (Frechet derivative) of a map between Banach manifolds, however, I do not know how to concretely proceed to investigate the subject. Specifically, a map $f:V\rightarrow W$ between Banach space is differentiable at $x_{0}\in V$ if, for all $\epsilon>0$ there exist $\delta_{\epsilon}>0$ and a bounded linear map $Df_{x_{0}}:V\rightarrow W$ such that: $$ ||f(x-x_{0}) - f(x_{0}) - Df_{x_{0}}(x-x_{0})||<\epsilon $$ whenever $||x-x_{0}||<\delta_{\epsilon}$. Since $\mathcal{G}(\mathcal{A})$ is only a Banach manifold, I need a coordinates system in order to use the definition of Frechet derivative, and I do not know what kind of coordinates system I should use. Furthermore, even if I knew it, I would need an ""educated guess"" of the explicit face of the derivative $Df_{x_{0}}$ to actually calculate the limit in the definition of the Frechet derivative. Are there other, more smart ways to proceed? Thank You in advance. EDIT With a little effort, I was able to prove that the linear map $\alpha_{\mathbf{G}}:\mathcal{A}^{*}\rightarrow\mathcal{A}^{*}$ is bounded, and thus continuous, for all $\mathbf{G}\in\mathcal{G}(\mathcal{A})$. This means that $\alpha_{\mathbf{G}}$ is analytic for all $\mathbf{G}$ (it is a continuous 1-homogeneous polynomial), but I do not know if it is of some relevance. EDIT 2 According to Andreas Cap's answer, I tried to work out the details without using the $t$ parameter. Let $U_{\mathbf{G}}\subset\mathcal{G}(\mathcal{A})$ be a neighbourhood of $\mathbf{G}$ such that $\mathbf{G}+\mathbf{H}\in U$ for all $\mathbf{H}\in U$. Then we can write: $$ \alpha(\mathbf{G}+\mathbf{H}\,;\omega + \tau)(\mathbf{A}) - \alpha(\mathbf{G}\,;\omega)(\mathbf{A})=\omega(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger}) + \omega(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) + \tau(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) + \tau(\mathbf{G}\mathbf{A}\mathbf{G}^{\dagger}) $$ The linear functional introduced by Andreas Cap is: $$ D\alpha_{\mathbf{G}\,;\omega}(\mathbf{H}\,;\tau)(\mathbf{A})=\omega(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger}) + \tau(\mathbf{G}\mathbf{A}\mathbf{G}^{\dagger}) $$ and thus: $$ \alpha(\mathbf{G}+\mathbf{H}\,;\omega + \tau)(\mathbf{A}) - \alpha(\mathbf{G}\,;\omega)(\mathbf{A}) - D\alpha_{\mathbf{G}\,;\omega}(\mathbf{H}\,;\tau)(\mathbf{A})= \tau(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger})+ (\omega+\tau)(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger}) $$ Let us call this functional $\gamma$. The norm of $\gamma$ is: $$ ||\gamma||=\sup_{\mathbf{A}\neq\mathbf{0}}\frac{|\gamma(\mathbf{A})|}{||\mathbf{A}||} $$ Then: $$ |\gamma(\mathbf{A})|\leq|\tau(\mathbf{G}\mathbf{A}\mathbf{H}^{\dagger} + \mathbf{H}\mathbf{A}\mathbf{G}^{\dagger})| + |(\omega+\tau)(\mathbf{H}\mathbf{A}\mathbf{H}^{\dagger})|\leq $$ $$ \leq2||\tau||\,||\mathbf{G}||\,||\mathbf{A}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2}\,||\mathbf{A}|| + ||\tau||\,||\mathbf{H}||^{2} \,||\mathbf{A}|| $$ which means: $$ ||\gamma||=2||\tau||\,||\mathbf{G}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2} + ||\tau||\,||\mathbf{H}||^{2} $$ The action $\alpha$ is differentiable at $(\mathbf{G}\,;\omega)$ if, for all $\epsilon>0$ there exists $\delta_{\epsilon}>0$ such that: $$ \frac{||\gamma||}{||(\mathbf{H}\,;\tau)||}<\epsilon $$ whenever $||(\mathbf{H}\,;\tau)||<\delta_{\epsilon}$. However, we have: $$ \frac{||\gamma||}{||(\mathbf{H}\,;\tau)||}=\frac{2||\tau||\,||\mathbf{G}||\,||\mathbf{H}|| + ||\omega||\,||\mathbf{H}||^{2} + ||\tau||\,||\mathbf{H}||^{2}}{||\mathbf{H}|| +||\tau||} $$ and I am not sure that this is less than $\epsilon$.",,"['functional-analysis', 'differential-geometry', 'banach-spaces', 'lie-groups']"
50,Laplacian of a distance function on a Riemann manifold,Laplacian of a distance function on a Riemann manifold,,"For some reasons I need to  show the following fact. Let $(M, g)$ be a Riemannian manifold. Let $U \subset M$ be an open set and $r: M \to \mathbb{R}$ a smooth distance function.     Let us assume also that $Ric \ge (n - 1) k$. Then    $$ \Big(\frac{\Delta r}{n-1}\Big)^2 + k \ge 0.$$ I can't see how to prove it. EDIT: I am studying the proof of the Lemma34 (Ricci Comparison Result) at page 268 of the book ""Riemannian Geometry"" (second edition) by Petersen. I can't understand why the third inequality in the proof does hold. If I can prove what I wrote above, then everything would be clear.","For some reasons I need to  show the following fact. Let $(M, g)$ be a Riemannian manifold. Let $U \subset M$ be an open set and $r: M \to \mathbb{R}$ a smooth distance function.     Let us assume also that $Ric \ge (n - 1) k$. Then    $$ \Big(\frac{\Delta r}{n-1}\Big)^2 + k \ge 0.$$ I can't see how to prove it. EDIT: I am studying the proof of the Lemma34 (Ricci Comparison Result) at page 268 of the book ""Riemannian Geometry"" (second edition) by Petersen. I can't understand why the third inequality in the proof does hold. If I can prove what I wrote above, then everything would be clear.",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'laplacian']"
51,Intrinsic definition of differential k-form on smooth manifold,Intrinsic definition of differential k-form on smooth manifold,,"Suppose I have a $k$-dimensional manifold embedded in $\mathbb{R}^n$. Munkres defines a $k$-form on $M$ as a a function $\omega$ that assigns an alternating tensor at each point $p \in M$ that acts on $k$-tuples of tangent vectors in $T_pM$. He says that, for simplicity, we will just work with $k$-forms that are defined on open sets (of $\mathbb{R}^n$) which contain $M$, as we can restrict this $k$-form to $M$. So if we have a $k$-form $\omega$ defined on an open set of $\mathbb{R}^n$, then we can write $\omega = \sum f_I dx^I$ where $I$ represents an ascending $k$-tuple of integers from the set $\{1, \dots, n\}$ and the $f_I$ are smooth functions. However, I would like to think (and I may be wrong here) that if we really want a $k$-form $\omega$ defined on just $M$, then because $\dim(M) = k$, we ought to be able to write $\omega = f dz^1 \wedge \cdots \wedge dz^k$, where the $z^i$ are standard coordinates on the tangent space at each point. Being able to write a form in that manner seems much more desirable to me. I was told however, that in general, the tangent spaces of the manifold will be in different directions, so I cannot just declare $z^i$ for $1 \leq i \leq k$ to be standard coordinates on the tangent space, for the $z^i$ will, in general, be different for each tangent space. This makes sense to me. However, this also bothers me because why should a $k$-form be dependent on the space that the manifold is embedded in? By writing $\omega = \sum f_I dx^I$ we are implicitly making reference to the ambient space. There ought to be an intrinsic way to define a $k$-form on a $k$-manifold. Also, since $\omega$ acts on $k$-tuples of tangent vectors, and the tangent space can be defined via derivations without reference to an ambient space, then $\omega$ ought to take on the same values, regardless of what space $M$ is embedded in. At least these properties seem reasonable to me. On the Wikipedia page, there is an intrinsic definition: https://en.wikipedia.org/wiki/Differential_form#Intrinsic_definitions But I don't know enough smooth manifold theory yet to understand that definition. My only workings with smooth manifold theory so far have come from Munkres and the first three chapters of Lee's ""Introduction to smooth manifolds"" (which covers smooth manifolds, smooth maps between smooth manifolds, tangent spacces). So I was hoping that someone would be able to explain it in an intelligible way to me. Also, please correct anything that I may have gotten wrong, and definitely correct me if my list of ""reasonable properties"" is wrong as well. Thanks.","Suppose I have a $k$-dimensional manifold embedded in $\mathbb{R}^n$. Munkres defines a $k$-form on $M$ as a a function $\omega$ that assigns an alternating tensor at each point $p \in M$ that acts on $k$-tuples of tangent vectors in $T_pM$. He says that, for simplicity, we will just work with $k$-forms that are defined on open sets (of $\mathbb{R}^n$) which contain $M$, as we can restrict this $k$-form to $M$. So if we have a $k$-form $\omega$ defined on an open set of $\mathbb{R}^n$, then we can write $\omega = \sum f_I dx^I$ where $I$ represents an ascending $k$-tuple of integers from the set $\{1, \dots, n\}$ and the $f_I$ are smooth functions. However, I would like to think (and I may be wrong here) that if we really want a $k$-form $\omega$ defined on just $M$, then because $\dim(M) = k$, we ought to be able to write $\omega = f dz^1 \wedge \cdots \wedge dz^k$, where the $z^i$ are standard coordinates on the tangent space at each point. Being able to write a form in that manner seems much more desirable to me. I was told however, that in general, the tangent spaces of the manifold will be in different directions, so I cannot just declare $z^i$ for $1 \leq i \leq k$ to be standard coordinates on the tangent space, for the $z^i$ will, in general, be different for each tangent space. This makes sense to me. However, this also bothers me because why should a $k$-form be dependent on the space that the manifold is embedded in? By writing $\omega = \sum f_I dx^I$ we are implicitly making reference to the ambient space. There ought to be an intrinsic way to define a $k$-form on a $k$-manifold. Also, since $\omega$ acts on $k$-tuples of tangent vectors, and the tangent space can be defined via derivations without reference to an ambient space, then $\omega$ ought to take on the same values, regardless of what space $M$ is embedded in. At least these properties seem reasonable to me. On the Wikipedia page, there is an intrinsic definition: https://en.wikipedia.org/wiki/Differential_form#Intrinsic_definitions But I don't know enough smooth manifold theory yet to understand that definition. My only workings with smooth manifold theory so far have come from Munkres and the first three chapters of Lee's ""Introduction to smooth manifolds"" (which covers smooth manifolds, smooth maps between smooth manifolds, tangent spacces). So I was hoping that someone would be able to explain it in an intelligible way to me. Also, please correct anything that I may have gotten wrong, and definitely correct me if my list of ""reasonable properties"" is wrong as well. Thanks.",,"['differential-geometry', 'differential-topology', 'differential-forms', 'smooth-manifolds']"
52,Bases and wedge product,Bases and wedge product,,"Let $\{v_1,\dots, v_r\}$ and $\{w_1,\dots, w_r\}$ be linearly independent sets of a vector space $V$. If $v_1 \wedge \dots \wedge v_r =c w_1 \wedge \dots \wedge w_r   $ for some nonzero number $c$, then $\{v_1,\dots, v_r\}$ and $\{w_1,\dots, w_r\}$ are two bases of the same $r-$dimensional subspace. To approach this problem, I first extend two sets to bases of $V$, say $\{v_1,\dots, v_d\}$ and $\{w_1,\dots, w_d\}$ where $d$ is the dimension of the vector space $V$. Then each $v_i$ can be expressed into a linear combination of $w_1,\dots,w_d$. But how to show that each $v_i$ can be expressed into a linear combination of $w_1,\dots,w_r$? Thanks in advance!","Let $\{v_1,\dots, v_r\}$ and $\{w_1,\dots, w_r\}$ be linearly independent sets of a vector space $V$. If $v_1 \wedge \dots \wedge v_r =c w_1 \wedge \dots \wedge w_r   $ for some nonzero number $c$, then $\{v_1,\dots, v_r\}$ and $\{w_1,\dots, w_r\}$ are two bases of the same $r-$dimensional subspace. To approach this problem, I first extend two sets to bases of $V$, say $\{v_1,\dots, v_d\}$ and $\{w_1,\dots, w_d\}$ where $d$ is the dimension of the vector space $V$. Then each $v_i$ can be expressed into a linear combination of $w_1,\dots,w_d$. But how to show that each $v_i$ can be expressed into a linear combination of $w_1,\dots,w_r$? Thanks in advance!",,"['differential-geometry', 'exterior-algebra']"
53,Gauss formula for a 3-sphere embedded in $\mathbb{R}^4$,Gauss formula for a 3-sphere embedded in,\mathbb{R}^4,"Given connections $\nabla$ and $\bar{\nabla}$ as connections on $\mathbb{R}^4$ and the 3-sphere of radius $r$: $\mathbb{S}^3(r)$, the vector fields $X,Y$ tangent to $\mathbb{S^3}(r)$, how do I obtain the expression: $$\nabla_{X} Y = \bar\nabla_{X} Y - \dfrac{1}{r^2}<X,Y>p,$$ where $p : \mathbb{S}^3 \to \mathbb{R}^4$ represents the position vector. I came across this expression in a paper which mentions it as a standard result. However I was unable to derive it from my own limited knowledge.","Given connections $\nabla$ and $\bar{\nabla}$ as connections on $\mathbb{R}^4$ and the 3-sphere of radius $r$: $\mathbb{S}^3(r)$, the vector fields $X,Y$ tangent to $\mathbb{S^3}(r)$, how do I obtain the expression: $$\nabla_{X} Y = \bar\nabla_{X} Y - \dfrac{1}{r^2}<X,Y>p,$$ where $p : \mathbb{S}^3 \to \mathbb{R}^4$ represents the position vector. I came across this expression in a paper which mentions it as a standard result. However I was unable to derive it from my own limited knowledge.",,"['differential-geometry', 'riemannian-geometry', 'connections']"
54,Calculating Christoffel symbols using variational geodesic equation,Calculating Christoffel symbols using variational geodesic equation,,Given the line element $$ds^2 = e^v dt^2 - e^{\lambda} dr^2 - r^2 d \theta^2 - r^2 \sin^2 \theta d \phi^2$$ we wish to compute the Christoffel symbols $\Gamma^{a}_{bc}$ using the geodesic equation. Our Lagrangian is $$L = g_{ab} {\dot{x}}^a {\dot{x}}^b = e^v \dot{t}^2 - e^{\lambda} \dot{r}^2 - r^2 \dot{\theta}^2 - r^2 \sin^2 \theta \dot{\phi}^2.$$ Applying the Euler-Lagrange equations and dividing by $-2e^v$ yields $$\ddot{t} - \frac{1}{2} \dot{v} \dot{t}^2 + v' \dot{t} \dot{r} + \frac{1}{2} \dot{\lambda} e^{\lambda - v} \dot{r}^2 = 0.$$ I incorrectly conclude that $\Gamma^{0}_{00} = - \frac{1}{2} \dot{v}$. Why? I have a feeling this has something to do with the difference between the geodesic equations for space-like and time-like geodesics.,Given the line element $$ds^2 = e^v dt^2 - e^{\lambda} dr^2 - r^2 d \theta^2 - r^2 \sin^2 \theta d \phi^2$$ we wish to compute the Christoffel symbols $\Gamma^{a}_{bc}$ using the geodesic equation. Our Lagrangian is $$L = g_{ab} {\dot{x}}^a {\dot{x}}^b = e^v \dot{t}^2 - e^{\lambda} \dot{r}^2 - r^2 \dot{\theta}^2 - r^2 \sin^2 \theta \dot{\phi}^2.$$ Applying the Euler-Lagrange equations and dividing by $-2e^v$ yields $$\ddot{t} - \frac{1}{2} \dot{v} \dot{t}^2 + v' \dot{t} \dot{r} + \frac{1}{2} \dot{\lambda} e^{\lambda - v} \dot{r}^2 = 0.$$ I incorrectly conclude that $\Gamma^{0}_{00} = - \frac{1}{2} \dot{v}$. Why? I have a feeling this has something to do with the difference between the geodesic equations for space-like and time-like geodesics.,,"['differential-geometry', 'tensors', 'general-relativity', 'semi-riemannian-geometry']"
55,"Smooth representative $f: S^{2n - 1} \to S^n$, do we have $f^*\omega = d\alpha$?","Smooth representative , do we have ?",f: S^{2n - 1} \to S^n f^*\omega = d\alpha,Let $[f] \in \pi_{2n - 1}(S^n)$. Choose a smooth representative $f: S^{2n - 1} \to S^n$. Let $\omega$ be a smooth $n$-form on $S^n$ with$$\int_{S^n} \omega = 1.$$Do we have that$$f^*\omega = d\alpha$$for some $(n -1 )$-form $\alpha$ on $S^{2n - 1}$?,Let $[f] \in \pi_{2n - 1}(S^n)$. Choose a smooth representative $f: S^{2n - 1} \to S^n$. Let $\omega$ be a smooth $n$-form on $S^n$ with$$\int_{S^n} \omega = 1.$$Do we have that$$f^*\omega = d\alpha$$for some $(n -1 )$-form $\alpha$ on $S^{2n - 1}$?,,"['differential-geometry', 'algebraic-topology']"
56,Wedge product of closed form each with integral periods has integral period?,Wedge product of closed form each with integral periods has integral period?,,"Suppose $\alpha$ and $\beta$ are closed forms on $M$ which have integral periods, i.e. for all $[A] \in H_*(M, \mathbb{Z})$ represented by a smooth cycle $A$, we have $\int_A \alpha \in \mathbb{Z}$, and similarly for $\beta$. Does $\alpha \wedge \beta$ have integral period?","Suppose $\alpha$ and $\beta$ are closed forms on $M$ which have integral periods, i.e. for all $[A] \in H_*(M, \mathbb{Z})$ represented by a smooth cycle $A$, we have $\int_A \alpha \in \mathbb{Z}$, and similarly for $\beta$. Does $\alpha \wedge \beta$ have integral period?",,"['differential-geometry', 'algebraic-topology']"
57,When does contractible space of almost complex structures taming a given symplectic form $\omega$ contain an integrable compatible one?,When does contractible space of almost complex structures taming a given symplectic form  contain an integrable compatible one?,\omega,"Given a symplectic form $\omega$ on a compact symplectic manifold $X$, we know there is a contractible homotopy class $\mathcal{J}_{\omega}$ of almost complex structures that tame $\omega$.  A subset of these is also compatible with $\omega$, in that $\omega(\cdot, J\cdot \cdot)$ defines a Riemannian metric on the manifold.  How do know, other than things like odd Betti numbers being even, if $\omega$ has an integrable member $J_{\omega, int}$ of $\mathcal{J}_{\omega}$, so that $(X,\omega, J_{\omega, int}, \omega(\cdot, J_{\omega, int}\cdot \cdot))$ is a Kaehler manifold?","Given a symplectic form $\omega$ on a compact symplectic manifold $X$, we know there is a contractible homotopy class $\mathcal{J}_{\omega}$ of almost complex structures that tame $\omega$.  A subset of these is also compatible with $\omega$, in that $\omega(\cdot, J\cdot \cdot)$ defines a Riemannian metric on the manifold.  How do know, other than things like odd Betti numbers being even, if $\omega$ has an integrable member $J_{\omega, int}$ of $\mathcal{J}_{\omega}$, so that $(X,\omega, J_{\omega, int}, \omega(\cdot, J_{\omega, int}\cdot \cdot))$ is a Kaehler manifold?",,"['general-topology', 'differential-geometry', 'symplectic-geometry', 'kahler-manifolds', 'almost-complex']"
58,How to find the tangent space of a general submanifold?,How to find the tangent space of a general submanifold?,,"Given a submanifold $(S,\phi)$ of a manifold $M$, how do we find the subspace of $T_pM$ that is equal to $T_pS$ for $p\in \phi(S)$. I know how to do it for level sets. Is there a way for general submanifolds?","Given a submanifold $(S,\phi)$ of a manifold $M$, how do we find the subspace of $T_pM$ that is equal to $T_pS$ for $p\in \phi(S)$. I know how to do it for level sets. Is there a way for general submanifolds?",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
59,Polyakov action in complex coordinates,Polyakov action in complex coordinates,,"Let $\Sigma$ be a compact $2$-manifold with riemannian metric $g$ and $f:\Sigma \to \mathbf{R}^n$ given locally by $f_1(x_1,x_2),\dots,f_n(x_1,x_2)$. Define $$   S(f,g) = -\frac{1}{2\pi\alpha'}\int_{\Sigma}\left(\sum_{i=1}^n\sum_{k,j=1}^2g^{jk}(x)\frac{\partial f_i}{\partial x_j}\frac{\partial f_i}{\partial x_k}\right)\Phi, $$ where $\Phi$ is the volume form. Suppose that $g$ is the euclidean metric. If $f:\Sigma \to \mathbf{C}^n$ is given locally by $\phi_1(z),\dots,\phi_n(z)$ (using a single complex coordinate for $\Sigma$), the source I'm following says the above changes to $$   S(f,g) = -\frac{i}{2\pi\alpha'}\int \sum_{j=1}^n\left(\frac{\partial \phi_j}{\partial z}\frac{\partial \overline{\phi_j}}{\partial \bar z} + \frac{\partial \overline{\phi_j}}{\partial z}\frac{\partial \phi_j}{\partial \bar z}\right) dz \wedge d\bar z. $$ I get that in complex coordinates $\Phi = \frac{i}{2}dz \wedge d\bar z$ and $g^{jk} = 2$ if $j \neq k$ and $0$ otherwise, but I'm not sure how the $\overline{\phi_j}$ came up in the expression, and trying different guesses for what it should be didn't get me anywhere. What is going on here?","Let $\Sigma$ be a compact $2$-manifold with riemannian metric $g$ and $f:\Sigma \to \mathbf{R}^n$ given locally by $f_1(x_1,x_2),\dots,f_n(x_1,x_2)$. Define $$   S(f,g) = -\frac{1}{2\pi\alpha'}\int_{\Sigma}\left(\sum_{i=1}^n\sum_{k,j=1}^2g^{jk}(x)\frac{\partial f_i}{\partial x_j}\frac{\partial f_i}{\partial x_k}\right)\Phi, $$ where $\Phi$ is the volume form. Suppose that $g$ is the euclidean metric. If $f:\Sigma \to \mathbf{C}^n$ is given locally by $\phi_1(z),\dots,\phi_n(z)$ (using a single complex coordinate for $\Sigma$), the source I'm following says the above changes to $$   S(f,g) = -\frac{i}{2\pi\alpha'}\int \sum_{j=1}^n\left(\frac{\partial \phi_j}{\partial z}\frac{\partial \overline{\phi_j}}{\partial \bar z} + \frac{\partial \overline{\phi_j}}{\partial z}\frac{\partial \phi_j}{\partial \bar z}\right) dz \wedge d\bar z. $$ I get that in complex coordinates $\Phi = \frac{i}{2}dz \wedge d\bar z$ and $g^{jk} = 2$ if $j \neq k$ and $0$ otherwise, but I'm not sure how the $\overline{\phi_j}$ came up in the expression, and trying different guesses for what it should be didn't get me anywhere. What is going on here?",,"['differential-geometry', 'complex-geometry', 'string-theory']"
60,Inward/Outward-pointing tangent vector is well-defined,Inward/Outward-pointing tangent vector is well-defined,,"Let $M$ be a smooth manifold with boundary and $p\in \partial M$. We say a tangent vector $v\in T_pM$ is inward-pointing if in a chart $x$ with $v=v^i\partial/\partial x^i$ (using the summation convention) one has $v^1>0$. Why is this well-defined? I.e. if $y$ is another chart around $p$ with $v=w^j \partial/\partial y^j$, how can we conclude that $w^1>0$? I tried looking at the change of coordinates formula which says that $$w^1=\frac{\partial (y^1\circ x^{-1})}{\partial x^i}(x(p))v^i$$ but why should that be positive when $v^1>0$? What am I missing?","Let $M$ be a smooth manifold with boundary and $p\in \partial M$. We say a tangent vector $v\in T_pM$ is inward-pointing if in a chart $x$ with $v=v^i\partial/\partial x^i$ (using the summation convention) one has $v^1>0$. Why is this well-defined? I.e. if $y$ is another chart around $p$ with $v=w^j \partial/\partial y^j$, how can we conclude that $w^1>0$? I tried looking at the change of coordinates formula which says that $$w^1=\frac{\partial (y^1\circ x^{-1})}{\partial x^i}(x(p))v^i$$ but why should that be positive when $v^1>0$? What am I missing?",,"['differential-geometry', 'differential-topology']"
61,Kähler differential and higher derivations (geometric interpretation of diagonal here),Kähler differential and higher derivations (geometric interpretation of diagonal here),,"I am studing Kähler differentials and I tried to understand the geometric motivation behind these settings. What I do not understand is the role which plays the diagonal in all these theory. The cotangent sheaf is later defined in terms of the diagonal map. Why is this geometrically interesting? I tried to write a short introduction to Kähler differential to make the geometric nature more available, but I do not now if it make sense. Here it is: Differential $ 1 $-forms are linear transformations $ \omega_{p}:T_p X\mapsto K $  assigning an element in $ K $ to a tangent vector of the tangent space $ T_p X $ of a point $ p\in X $ in some differential manifold $ X $. Differential $ 1 $-forms can be viewed as \textit{infinitesimal} direction vectors $ \triangle p $. This means in physical terms, that the scalar $ \omega_p(\triangle t)\in K $ with $ \triangle t $ a tangent vector represents the \textit{work} required to move from $ x_i $ to $ x_{i+1} $ with $ p\in (x_i,x_{i+1}) $ along some curve. In other words, differential forms are cotangent vectors over some field $ K $, which give information about the work which is locally required to move along some curve. However, they can be generalized and captured by sheaf theory. For this attempt, we observe first that $ \triangle p $ is related to Taylor expansions. Indeed, let $ f $ be a smooth function, that is $ f\in C^{\infty}(\mathbb{C}) $, on a differential manifold $ X$ and let $\mathfrak{J}$ be the ideal of smooth functions vanishing at the point $p\in X$. The zero order part of the Taylor series of a smooth function $f$ is the value of $f$ at the point $ p $, let us say, $ f(p)=c $, so that $ f-c\in\mathfrak{J}$. Now the first order derivatives of $f-c$ correspond to the first order terms in the Taylor series and these are given by the image of $f$ in $\mathfrak{J}/\mathfrak{J}^2$. Let us denote this map by $ d(f) $ with $ d: \mathcal{O}_X\rightarrow \mathfrak{J}/\mathfrak{J}^2 $ and where $ \mathcal{O}_X $ denotes the ring of smooth functions on $ X $. Moreover, if $ f $ is constant, this means a fixed vector, then $ d(f)=0 $. Another important input is that $ \triangle p$ is required to be non zero, as there is no direction available for the zero vector. But $ \triangle p=0 $ is satisfied if and only if the two endpoints of the tangent vector $ \triangle p $ are choosen to be the same, which happens if and only if the point $ p\in X $ correspond to an element on the diagonal of $ X\times X $. So we demand that we just consider elements in $ X\times X $ vanishing on the diagonal (or in the complement of the diagonal). Summarizing up, my two questions are the following: 1) which geoemtric interpretation have the diagonal in these context? 2) Higher derivations seemed to me a generalization of Kähler differentials, but what is their motivation or geometric nature (analogy to differential geometry), since I cannot see any connection between Kähler differentials and higher derivations ?","I am studing Kähler differentials and I tried to understand the geometric motivation behind these settings. What I do not understand is the role which plays the diagonal in all these theory. The cotangent sheaf is later defined in terms of the diagonal map. Why is this geometrically interesting? I tried to write a short introduction to Kähler differential to make the geometric nature more available, but I do not now if it make sense. Here it is: Differential $ 1 $-forms are linear transformations $ \omega_{p}:T_p X\mapsto K $  assigning an element in $ K $ to a tangent vector of the tangent space $ T_p X $ of a point $ p\in X $ in some differential manifold $ X $. Differential $ 1 $-forms can be viewed as \textit{infinitesimal} direction vectors $ \triangle p $. This means in physical terms, that the scalar $ \omega_p(\triangle t)\in K $ with $ \triangle t $ a tangent vector represents the \textit{work} required to move from $ x_i $ to $ x_{i+1} $ with $ p\in (x_i,x_{i+1}) $ along some curve. In other words, differential forms are cotangent vectors over some field $ K $, which give information about the work which is locally required to move along some curve. However, they can be generalized and captured by sheaf theory. For this attempt, we observe first that $ \triangle p $ is related to Taylor expansions. Indeed, let $ f $ be a smooth function, that is $ f\in C^{\infty}(\mathbb{C}) $, on a differential manifold $ X$ and let $\mathfrak{J}$ be the ideal of smooth functions vanishing at the point $p\in X$. The zero order part of the Taylor series of a smooth function $f$ is the value of $f$ at the point $ p $, let us say, $ f(p)=c $, so that $ f-c\in\mathfrak{J}$. Now the first order derivatives of $f-c$ correspond to the first order terms in the Taylor series and these are given by the image of $f$ in $\mathfrak{J}/\mathfrak{J}^2$. Let us denote this map by $ d(f) $ with $ d: \mathcal{O}_X\rightarrow \mathfrak{J}/\mathfrak{J}^2 $ and where $ \mathcal{O}_X $ denotes the ring of smooth functions on $ X $. Moreover, if $ f $ is constant, this means a fixed vector, then $ d(f)=0 $. Another important input is that $ \triangle p$ is required to be non zero, as there is no direction available for the zero vector. But $ \triangle p=0 $ is satisfied if and only if the two endpoints of the tangent vector $ \triangle p $ are choosen to be the same, which happens if and only if the point $ p\in X $ correspond to an element on the diagonal of $ X\times X $. So we demand that we just consider elements in $ X\times X $ vanishing on the diagonal (or in the complement of the diagonal). Summarizing up, my two questions are the following: 1) which geoemtric interpretation have the diagonal in these context? 2) Higher derivations seemed to me a generalization of Kähler differentials, but what is their motivation or geometric nature (analogy to differential geometry), since I cannot see any connection between Kähler differentials and higher derivations ?",,"['algebraic-geometry', 'differential-geometry', 'sheaf-theory', 'complex-geometry']"
62,Examples of four dimensional tensors satisfying the Bianchi identity,Examples of four dimensional tensors satisfying the Bianchi identity,,"Is there an example of a $(4, 0)$-tensor field $T(X, Y, Z, W)$ that has the following properties: (1) $T(X, Y, Z, W) = -T(Y, X, Z, W)$ (2) $T(X, Y, Z, W) + T(Y, Z, X, W) + T(Z, X, Y, W) = 0$ and (3) $T(X, Y, X, Y) = T(Y, X, Y, X)$, but these properties do not imply that (4) $T(X, Y, Z, W) = -T(X, Y, W, Z)$ I could not prove whether this holds. On the other hand, if (1), (2) and (4) hold then (3) is valid (this is easy to prove). Thank you!","Is there an example of a $(4, 0)$-tensor field $T(X, Y, Z, W)$ that has the following properties: (1) $T(X, Y, Z, W) = -T(Y, X, Z, W)$ (2) $T(X, Y, Z, W) + T(Y, Z, X, W) + T(Z, X, Y, W) = 0$ and (3) $T(X, Y, X, Y) = T(Y, X, Y, X)$, but these properties do not imply that (4) $T(X, Y, Z, W) = -T(X, Y, W, Z)$ I could not prove whether this holds. On the other hand, if (1), (2) and (4) hold then (3) is valid (this is easy to prove). Thank you!",,"['linear-algebra', 'differential-geometry']"
63,Why is L the derivative of L? I have a very vague understanding about the very step needed to show $dL=L$.,Why is L the derivative of L? I have a very vague understanding about the very step needed to show .,dL=L,"I have a bits-and-pieces understanding on how to solve this problem and just a very rough intuition of the path to solve the problem but very much struggling to get to show $dL=L$. This is part of a question if Do Carmo's book that reads as follows: Prove that if $L:R^3\to R^3$ is a linear map and $S\subset R^3$ is a regular surface invariant under $L$, i.e., $L(S)\subset S$, then the restriction $L|S$ is a differentiable map and $$dL_p(w)=L(w), \text{ }p\in S, w\in T_p(S).$$ I could show that the restriction $L|S$ is a differentiable map but I am struggling to show that $dL_p(w)=L(w)$. So let's try this: Let $p$ be a point on the surface $S$, $x:U\subset \mathbb R^2\rightarrow S$ be a parametrization s.t. $x(0)=p$ and $y:V\subset \mathbb R^2\rightarrow S$ be another parametrization s.t. $L(p)=y(0)$. Let $f(u,v)=y^{-1}\circ L \circ x(u,v)$. By using chain rule, we get $df_0=d(y^{-1})_{L(p)}\circ dL \circ dx_0$. My question is: 1. What the map does is $\mathbb R^2 \underset{dx}{\longrightarrow} T_pS \underset{dL}{\longrightarrow} T_{L(p)}S\underset{dy^{-1}}{\longrightarrow} \mathbb R^2$. From here, how can we conclude that $dL=L$? I have seen some similar problems from some other sources, but I am still very much struggling to connect all the dots, everything for me is still bits and pieces. Helps are greatly appreciated! Hopefully after making those points clear I can finish the problem by myself. Thanks.","I have a bits-and-pieces understanding on how to solve this problem and just a very rough intuition of the path to solve the problem but very much struggling to get to show $dL=L$. This is part of a question if Do Carmo's book that reads as follows: Prove that if $L:R^3\to R^3$ is a linear map and $S\subset R^3$ is a regular surface invariant under $L$, i.e., $L(S)\subset S$, then the restriction $L|S$ is a differentiable map and $$dL_p(w)=L(w), \text{ }p\in S, w\in T_p(S).$$ I could show that the restriction $L|S$ is a differentiable map but I am struggling to show that $dL_p(w)=L(w)$. So let's try this: Let $p$ be a point on the surface $S$, $x:U\subset \mathbb R^2\rightarrow S$ be a parametrization s.t. $x(0)=p$ and $y:V\subset \mathbb R^2\rightarrow S$ be another parametrization s.t. $L(p)=y(0)$. Let $f(u,v)=y^{-1}\circ L \circ x(u,v)$. By using chain rule, we get $df_0=d(y^{-1})_{L(p)}\circ dL \circ dx_0$. My question is: 1. What the map does is $\mathbb R^2 \underset{dx}{\longrightarrow} T_pS \underset{dL}{\longrightarrow} T_{L(p)}S\underset{dy^{-1}}{\longrightarrow} \mathbb R^2$. From here, how can we conclude that $dL=L$? I have seen some similar problems from some other sources, but I am still very much struggling to connect all the dots, everything for me is still bits and pieces. Helps are greatly appreciated! Hopefully after making those points clear I can finish the problem by myself. Thanks.",,['differential-geometry']
64,Where does the minus sign come from in this expression?,Where does the minus sign come from in this expression?,,"I'm trying to solve a problem from a course on General Relativity. Consider the change of coordinates $x^\mu \to x'^\mu  = x^\mu + \varepsilon \xi^{\mu} (x)$ and for a tensor $T$ define $\delta T(x) = T'(x) - T(x)$. I want to show that for a vector $V^\mu$ $$\delta V^\mu = - \varepsilon \left[ \xi^a \partial_a V^\mu - V^a\partial_a \xi^\mu \right] + O(\varepsilon^2)$$ I understand that this is to gain insight in the concept of Lie derivative but I don't understand where the minus sign inside the parenthesis comes from. I've performed the calculations and I always get the same expression but with a plus sign. $$\delta V^\mu = - \varepsilon \left[ \xi^a \partial_a V^\mu + V^a\partial_a \xi^\mu \right] + O(\varepsilon^2)$$ Am I wrong? In case that I am, where does the sign come from?","I'm trying to solve a problem from a course on General Relativity. Consider the change of coordinates $x^\mu \to x'^\mu  = x^\mu + \varepsilon \xi^{\mu} (x)$ and for a tensor $T$ define $\delta T(x) = T'(x) - T(x)$. I want to show that for a vector $V^\mu$ $$\delta V^\mu = - \varepsilon \left[ \xi^a \partial_a V^\mu - V^a\partial_a \xi^\mu \right] + O(\varepsilon^2)$$ I understand that this is to gain insight in the concept of Lie derivative but I don't understand where the minus sign inside the parenthesis comes from. I've performed the calculations and I always get the same expression but with a plus sign. $$\delta V^\mu = - \varepsilon \left[ \xi^a \partial_a V^\mu + V^a\partial_a \xi^\mu \right] + O(\varepsilon^2)$$ Am I wrong? In case that I am, where does the sign come from?",,"['differential-geometry', 'general-relativity', 'lie-derivative']"
65,what does Whitney sum of vector bundles correspond to in the k-theory KO?,what does Whitney sum of vector bundles correspond to in the k-theory KO?,,"Let $X$ be a $CW$-complex and $\text{Vect}^n(X)$  the collection of $n$-dimensional real vector bundles over $X$. Let  $$ \text{Vect}^*(X)=\bigoplus_{n=0}^\infty \text{Vect}^n(X) $$ with addition \begin{eqnarray*} \oplus:  \text{Vect}^m(X)\times\text{Vect}^n(X)&\longrightarrow& \text{Vect}^{m+n}(X),\\ (\xi,\eta)&\longmapsto&\xi\oplus\eta \end{eqnarray*} and multiplication \begin{eqnarray*} \otimes:  \text{Vect}^m(X)\times\text{Vect}^n(X)&\longrightarrow& \text{Vect}^{mn}(X),\\ (\xi,\eta)&\longmapsto&\xi\otimes\eta \end{eqnarray*} where $\oplus$ denotes the Whitney sum and $\otimes$ the tensor product. Then $KO(X)$, the K-theory of $X$, can be identified with the group completion of $(\text{Vect}(X),\oplus)$. On the other hand, by the Atiyah-Hirzebruch spectral sequence,  $$ E_2^{p,q}=H^p(X;KO^q(*)) $$  converges to the generalized cohomology theory $KO(X)=\oplus_{n\in\mathbb{Z}}KO^n(X)$. The generalized cohomology theory has addition $+$ and cup-product $\smile$. Question. (1). What does $\text{Vect}^1(X)$ correspond to in $KO(X)$? Does $\text{Vect}^n(X)$ correspond to $KO^n(X)$? (2).  What does $\oplus$ correspond to in $KO(X)$? With the addition $\oplus$, does the monoid $(\text{Vect}^*(X),\oplus)$ isomorphic  to $(KO^n(X)\mid _{n\geq 0},+)$? (3).  With the addition $\oplus$ and multiplication $\otimes$, does the monoid with multiplication $(\text{Vect}^*(X),\oplus,\otimes)$ isomorphic to $(KO^n(X)\mid _{n\geq 0},+,\smile)$ (I think it is wrong)?","Let $X$ be a $CW$-complex and $\text{Vect}^n(X)$  the collection of $n$-dimensional real vector bundles over $X$. Let  $$ \text{Vect}^*(X)=\bigoplus_{n=0}^\infty \text{Vect}^n(X) $$ with addition \begin{eqnarray*} \oplus:  \text{Vect}^m(X)\times\text{Vect}^n(X)&\longrightarrow& \text{Vect}^{m+n}(X),\\ (\xi,\eta)&\longmapsto&\xi\oplus\eta \end{eqnarray*} and multiplication \begin{eqnarray*} \otimes:  \text{Vect}^m(X)\times\text{Vect}^n(X)&\longrightarrow& \text{Vect}^{mn}(X),\\ (\xi,\eta)&\longmapsto&\xi\otimes\eta \end{eqnarray*} where $\oplus$ denotes the Whitney sum and $\otimes$ the tensor product. Then $KO(X)$, the K-theory of $X$, can be identified with the group completion of $(\text{Vect}(X),\oplus)$. On the other hand, by the Atiyah-Hirzebruch spectral sequence,  $$ E_2^{p,q}=H^p(X;KO^q(*)) $$  converges to the generalized cohomology theory $KO(X)=\oplus_{n\in\mathbb{Z}}KO^n(X)$. The generalized cohomology theory has addition $+$ and cup-product $\smile$. Question. (1). What does $\text{Vect}^1(X)$ correspond to in $KO(X)$? Does $\text{Vect}^n(X)$ correspond to $KO^n(X)$? (2).  What does $\oplus$ correspond to in $KO(X)$? With the addition $\oplus$, does the monoid $(\text{Vect}^*(X),\oplus)$ isomorphic  to $(KO^n(X)\mid _{n\geq 0},+)$? (3).  With the addition $\oplus$ and multiplication $\otimes$, does the monoid with multiplication $(\text{Vect}^*(X),\oplus,\otimes)$ isomorphic to $(KO^n(X)\mid _{n\geq 0},+,\smile)$ (I think it is wrong)?",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'geometric-topology', 'topological-k-theory']"
66,Compute using the define of Lie derivative.,Compute using the define of Lie derivative.,,"The Lie derivative is defined as picture below.$X,Y,Z$ is vector fields,and $g$ is Riemannian metric. I try to compute  $$ \mathcal L_Xg(Y,Z)=X(g(Y,Z))-g(\mathcal L_XY,Z)-g(Y,\mathcal L_XZ) $$ Firstly, \begin{align} \mathcal L_Xg(Y,Z) &=(\frac{d}{dt}(*\varphi_t)g(Y,Z))|_{t=0}\\ &=\frac{d}{dt}|_{t=0}g_{\varphi_t}(\varphi_t^*(Y),\varphi^*_t(Z)) \end{align} Then, I don't know how to do it.","The Lie derivative is defined as picture below.$X,Y,Z$ is vector fields,and $g$ is Riemannian metric. I try to compute  $$ \mathcal L_Xg(Y,Z)=X(g(Y,Z))-g(\mathcal L_XY,Z)-g(Y,\mathcal L_XZ) $$ Firstly, \begin{align} \mathcal L_Xg(Y,Z) &=(\frac{d}{dt}(*\varphi_t)g(Y,Z))|_{t=0}\\ &=\frac{d}{dt}|_{t=0}g_{\varphi_t}(\varphi_t^*(Y),\varphi^*_t(Z)) \end{align} Then, I don't know how to do it.",,"['differential-geometry', 'riemannian-geometry']"
67,$d(\iota_v\rho)=0 \implies d(\phi\iota_v\rho)=d\phi(v)\rho$?,?,d(\iota_v\rho)=0 \implies d(\phi\iota_v\rho)=d\phi(v)\rho,"My motivation is physical, but my question is purely mathematical. Everybody knows, that the power of the electric current in a piece of wire is $$P=UI$$ where the wire is regular domain $V$ in a 3-dimensional orientable differentiable manifold M: it is a flow tube between two level set pieces $A$ and $B$ of a function $\phi: M\to \mathbb R$, $U = \phi(B)-\phi(A)$. $I = \int_B\iota_v\rho$, where $v$ is a vector field: ths is the velocity field of the moving charges. $\rho$ is a 3-form: this is the charge density 3-form, so $\iota_v\rho$ is the current density 2-form. We suppose that the current is stationary, i.e. $d(\iota_v\rho) = 0$ the velocity field $v$ of the moving charges in the wire is everywhere tangent to the side wall of the tube. Because of these assumptions $$0=\int_V d(\iota_v\rho) =\int_{\partial V}\iota_v\rho=\int_B\iota_v\rho+\int_A\iota_v\rho = 0$$ hence $\int_A\iota_v\rho = -I$. Because of assumption 2.  $$\int_{\partial V}\phi\iota_v\rho=\int_B\phi\iota_v\rho+\int_A\phi\iota_v\rho = \phi(B)\int_B\iota_v\rho+\phi(A)\int_A\iota_v\rho = (\phi(B)-\phi(A))I=UI=P$$ By applying Stokes theorem, this means that $$ P = \int_Vd(\phi\iota_v\rho)$$ On the other hand, we know also, that the power of the electric field $E=d\phi$ is $$ P = \int_V E(v)\rho = \int_V d\phi(v)\rho$$  That's why I suspect that for any vector field $v$ and 3-form $\rho$ having $d(\iota_v\rho)=0$ and for any function $\phi$ $$d(\phi\iota_v\rho)=d\phi(v)\rho$$ Is this really true?","My motivation is physical, but my question is purely mathematical. Everybody knows, that the power of the electric current in a piece of wire is $$P=UI$$ where the wire is regular domain $V$ in a 3-dimensional orientable differentiable manifold M: it is a flow tube between two level set pieces $A$ and $B$ of a function $\phi: M\to \mathbb R$, $U = \phi(B)-\phi(A)$. $I = \int_B\iota_v\rho$, where $v$ is a vector field: ths is the velocity field of the moving charges. $\rho$ is a 3-form: this is the charge density 3-form, so $\iota_v\rho$ is the current density 2-form. We suppose that the current is stationary, i.e. $d(\iota_v\rho) = 0$ the velocity field $v$ of the moving charges in the wire is everywhere tangent to the side wall of the tube. Because of these assumptions $$0=\int_V d(\iota_v\rho) =\int_{\partial V}\iota_v\rho=\int_B\iota_v\rho+\int_A\iota_v\rho = 0$$ hence $\int_A\iota_v\rho = -I$. Because of assumption 2.  $$\int_{\partial V}\phi\iota_v\rho=\int_B\phi\iota_v\rho+\int_A\phi\iota_v\rho = \phi(B)\int_B\iota_v\rho+\phi(A)\int_A\iota_v\rho = (\phi(B)-\phi(A))I=UI=P$$ By applying Stokes theorem, this means that $$ P = \int_Vd(\phi\iota_v\rho)$$ On the other hand, we know also, that the power of the electric field $E=d\phi$ is $$ P = \int_V E(v)\rho = \int_V d\phi(v)\rho$$  That's why I suspect that for any vector field $v$ and 3-form $\rho$ having $d(\iota_v\rho)=0$ and for any function $\phi$ $$d(\phi\iota_v\rho)=d\phi(v)\rho$$ Is this really true?",,"['differential-geometry', 'differential-forms']"
68,Complement of the zero section in degree $k$ line bundle over $\mathbb{P}^n$,Complement of the zero section in degree  line bundle over,k \mathbb{P}^n,"Consider the tautological line bundle $\mathcal{O}(-1)$ over $\mathbb{P}^n$. Let $L^{-k}$ denote the total space of $\mathcal{O}(-k)$ with $k \in \mathbb{N}$. Then it is claimed that the complement of the zero section in $L^{-k}$ is biholomorphic to the quotient $(\mathbb{C}^{n+1} \!-\! \{0\})/\mathbb{Z}_k$. Where $\mathbb{Z}_k = \{0, ..., k-1 \}$ acts as follows: \begin{equation}  z \mapsto e^{\frac{2 \pi i m}{k}}, \;\;\; m \in \mathbb{Z}_k.  \end{equation} I think that this will follow from considering the transition functions of $\mathcal{O}(-k)$ which with respect to the standard open cover $U_i$ of $\mathbb{P}^n$ are given by: \begin{equation} g_{ij}(l) = \bigg(\frac{z_i}{z_j} \bigg)^k, \;\;\; l=[z_o: ... : z_n] \in \mathbb{P}^n. \end{equation} But I just can't come up with a concrete way to realise this biholomorphism, any help would be greatly appreciated. Is it helpful to consider the line bunle $E$ that is constructed from $g_{ij}$ in the standard way, that is, we let define the total space by: \begin{equation} E = (U_i \times \mathbb{C})/\sim \end{equation} where $(l,w) \sim (l, \bigg(\frac{z_i}{z_j} \bigg)^k w)$ for all $l \in U_i \cap U_j$ and $w \in \mathbb{C}$.","Consider the tautological line bundle $\mathcal{O}(-1)$ over $\mathbb{P}^n$. Let $L^{-k}$ denote the total space of $\mathcal{O}(-k)$ with $k \in \mathbb{N}$. Then it is claimed that the complement of the zero section in $L^{-k}$ is biholomorphic to the quotient $(\mathbb{C}^{n+1} \!-\! \{0\})/\mathbb{Z}_k$. Where $\mathbb{Z}_k = \{0, ..., k-1 \}$ acts as follows: \begin{equation}  z \mapsto e^{\frac{2 \pi i m}{k}}, \;\;\; m \in \mathbb{Z}_k.  \end{equation} I think that this will follow from considering the transition functions of $\mathcal{O}(-k)$ which with respect to the standard open cover $U_i$ of $\mathbb{P}^n$ are given by: \begin{equation} g_{ij}(l) = \bigg(\frac{z_i}{z_j} \bigg)^k, \;\;\; l=[z_o: ... : z_n] \in \mathbb{P}^n. \end{equation} But I just can't come up with a concrete way to realise this biholomorphism, any help would be greatly appreciated. Is it helpful to consider the line bunle $E$ that is constructed from $g_{ij}$ in the standard way, that is, we let define the total space by: \begin{equation} E = (U_i \times \mathbb{C})/\sim \end{equation} where $(l,w) \sim (l, \bigg(\frac{z_i}{z_j} \bigg)^k w)$ for all $l \in U_i \cap U_j$ and $w \in \mathbb{C}$.",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
69,How to prove this sum being a real number related to unitary matrices?,How to prove this sum being a real number related to unitary matrices?,,"Based on my recent study on  non-Abelian gauge theory in physics, I encounter an identity that should be correct physically but I don't know how to prove it mathematically. Consider a $n\times n$ unitary matrix $U(x,y)\in U(n)$ smoothly depending on two real parameters $x,y$, let $u_{ij}$ be its entities, then does the following relation $$\sum_{i,j=1}^n (\partial_xu_{ij}^*)(\partial_yu_{ij})=\sum_{i,j=1}^n (\partial_xu_{ij})(\partial_yu_{ij}^*)$$ hold ? Which means the sum is a real number (where $u^*$ means the complex conjugate). And how to prove this ? Thank you very much.","Based on my recent study on  non-Abelian gauge theory in physics, I encounter an identity that should be correct physically but I don't know how to prove it mathematically. Consider a $n\times n$ unitary matrix $U(x,y)\in U(n)$ smoothly depending on two real parameters $x,y$, let $u_{ij}$ be its entities, then does the following relation $$\sum_{i,j=1}^n (\partial_xu_{ij}^*)(\partial_yu_{ij})=\sum_{i,j=1}^n (\partial_xu_{ij})(\partial_yu_{ij}^*)$$ hold ? Which means the sum is a real number (where $u^*$ means the complex conjugate). And how to prove this ? Thank you very much.",,"['calculus', 'differential-geometry', 'lie-groups', 'vector-bundles', 'fiber-bundles']"
70,Generally compute Gauss curvature,Generally compute Gauss curvature,,"For a surface $F(x,y,z)=0$, we want to compute its Gauss curvature. I tried to suppose $z=f(x,y)$ locally and get a complicated expression. Is there any direct way to compute this? Thanks for your help.","For a surface $F(x,y,z)=0$, we want to compute its Gauss curvature. I tried to suppose $z=f(x,y)$ locally and get a complicated expression. Is there any direct way to compute this? Thanks for your help.",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
71,Conformal iff $E=G$ and $F=0$,Conformal iff  and,E=G F=0,"Prove that a parametrization $x(u,v)$ is conformal (angle-preserving) if and only if the coefficients of the first fundamental form satisfy $E=G$ and $F = 0$. My attempt: It suffices to consider $e_1$ and $e_2$ in $\mathbb{R}^2$. It is easy to show that the differential $dx(e_1)=x_u$ and $dx(e_2)=x_v$. Note that $e_1$ and $e_2$ are orthogonal to each other, while $x_u$ and $x_v$ are also orthogonal to each other in the corresponding tangent space. Now, note that, by assumption, $$\cos \theta = \frac{\langle e_1,e_2\rangle}{\|e_1\|\cdot \|e_2\|} = \frac{\langle x_u,x_v\rangle}{\|x_u\|\cdot\|x_v\|} = \frac{F}{\sqrt{EG}}.$$ However, $\langle e_1,e_2 \rangle=0$ implies $F=0$. What about $E$ and $G$? I appreciate any hints here. Thanks in advance.","Prove that a parametrization $x(u,v)$ is conformal (angle-preserving) if and only if the coefficients of the first fundamental form satisfy $E=G$ and $F = 0$. My attempt: It suffices to consider $e_1$ and $e_2$ in $\mathbb{R}^2$. It is easy to show that the differential $dx(e_1)=x_u$ and $dx(e_2)=x_v$. Note that $e_1$ and $e_2$ are orthogonal to each other, while $x_u$ and $x_v$ are also orthogonal to each other in the corresponding tangent space. Now, note that, by assumption, $$\cos \theta = \frac{\langle e_1,e_2\rangle}{\|e_1\|\cdot \|e_2\|} = \frac{\langle x_u,x_v\rangle}{\|x_u\|\cdot\|x_v\|} = \frac{F}{\sqrt{EG}}.$$ However, $\langle e_1,e_2 \rangle=0$ implies $F=0$. What about $E$ and $G$? I appreciate any hints here. Thanks in advance.",,['differential-geometry']
72,There is no 2-form on $\mathbb R^3$ whose restriction to every surface gives its volume form,There is no 2-form on  whose restriction to every surface gives its volume form,\mathbb R^3,"Prove that there isn't such a 2-form $\omega$ on $\mathbb{R}^3$ that $\omega$ restricted to any surface $\Sigma$ gives its volume form. Suppose that there is such a form: $$\omega=f_3(x,y,z)dx \wedge dy + f_1(x,y,z)dy \wedge dz+ f_2(x,y,z) dz \wedge dx$$ Consider plane (x,y,c) for any $c$. Then $\omega$ restricted to this plane is: $$f_3(x,y,c) dx \wedge dy$$ Volume form of plane (x,y,c) is $dx \wedge dy$, so we have: $$f_3(x,y,c)=1$$ for any $x,y,c$, so $f_3 \equiv 1$. We can do the same with $f_1$ and $f_2$. So: $$\omega=dx \wedge dy + dy \wedge dz+ dz \wedge dx$$ Now let's consider plane: $(x,y,x)$, $\omega$ restricted to this plane is: $$dx \wedge dy + dy \wedge dx+ dx \wedge dx=0$$ But volume form of this plane is not $0$. My question: is it correct? Is there any simplier way to prove that?","Prove that there isn't such a 2-form $\omega$ on $\mathbb{R}^3$ that $\omega$ restricted to any surface $\Sigma$ gives its volume form. Suppose that there is such a form: $$\omega=f_3(x,y,z)dx \wedge dy + f_1(x,y,z)dy \wedge dz+ f_2(x,y,z) dz \wedge dx$$ Consider plane (x,y,c) for any $c$. Then $\omega$ restricted to this plane is: $$f_3(x,y,c) dx \wedge dy$$ Volume form of plane (x,y,c) is $dx \wedge dy$, so we have: $$f_3(x,y,c)=1$$ for any $x,y,c$, so $f_3 \equiv 1$. We can do the same with $f_1$ and $f_2$. So: $$\omega=dx \wedge dy + dy \wedge dz+ dz \wedge dx$$ Now let's consider plane: $(x,y,x)$, $\omega$ restricted to this plane is: $$dx \wedge dy + dy \wedge dx+ dx \wedge dx=0$$ But volume form of this plane is not $0$. My question: is it correct? Is there any simplier way to prove that?",,"['differential-geometry', 'proof-verification', 'differential-forms']"
73,Conformal immersions from surfaces into 3-manifolds,Conformal immersions from surfaces into 3-manifolds,,"Let $f:(S,g) \to (M,h) $ be a smooth immersion of a compact surface into a 3 - manifold. Is it true that there exists a diffeomorphism $\phi: S \to S$, such that the metric $(f \circ \phi)^*(h)$ is conformal to $g$ ? To explain the motivation behind ths question, consider first the following set-up. Let $D_2 \subset \mathbb R^2$ be the standard 2-disk and $f: (S,g_{eukl}) \to (M,g)$ an immersion into a Riemannian manifold. It is well-known that the area of $f$ is defined as $A(f) = \int_{D_2} \sqrt{||f_1||_g \cdot ||f_2||_g - g(f_1,f_2)^2 } dx_1dx_2$, where $f_i := \partial f/\partial x_i$. On the other hand, the Dirichlet energy is defined as $E(f) = \frac{1}{2}\int_{D_2} ||f_1||_g + ||f_2||_g dx_1dx_2$, and by simply comparing the integrants, one sees that $A(f) \leq E(f)$ with equality holding if and only if $||f_1||_g = ||f_2||_g$ and $g(f_1,f_2) = 0$ everywhere. Immersions with that property are called conformal and it is well known that for any given immersion, there exists a parameter transformation $\psi:D_2 \to D_2$ such that $f \circ \psi$ is a conformal immersion. In other words, an immersion $f$ is conformal if and only if $f^*(g) = e^{\phi} \cdot g_{eukl}$ for some smooth function $\phi$ on $D_2$, which means precisely that $f^*(g)$ and $g_{eukl}$ are conformal as metrics on $D_2$. I have some trouble understanding why this is still possible when $f:(S,h) \to (M,g)$ is an immersion of any compact Riemannian 2-manifold. I know that the area of $f$ is in general defined by $A(g) := \int_S \omega_{f^*(g)}$, whereas the Dirichlet energy depends on $h$ and is defined by $E_h(f) := \frac{1}{2} \int_S |df|^2 \omega_h$. I have shown that we always have $A(f) \leq E_h(f)$ (regardless of $h$), where $f$ is said to be conformal if equality holds. One can show that this is equivalent to the metrics $f^*(g)$ and $h$ being conformal, i.e $f^*(g) = e^\phi \cdot h$. Is it still true that there exists a diffeomorphism $\psi: S \to S$ such that $f \circ \psi$ is conformal ? I ask because I only find papers that assert the existence of isothermal coordinates on any Riemannian 2-manifold, which essentially seems to only imply the case from the first paragraph.","Let $f:(S,g) \to (M,h) $ be a smooth immersion of a compact surface into a 3 - manifold. Is it true that there exists a diffeomorphism $\phi: S \to S$, such that the metric $(f \circ \phi)^*(h)$ is conformal to $g$ ? To explain the motivation behind ths question, consider first the following set-up. Let $D_2 \subset \mathbb R^2$ be the standard 2-disk and $f: (S,g_{eukl}) \to (M,g)$ an immersion into a Riemannian manifold. It is well-known that the area of $f$ is defined as $A(f) = \int_{D_2} \sqrt{||f_1||_g \cdot ||f_2||_g - g(f_1,f_2)^2 } dx_1dx_2$, where $f_i := \partial f/\partial x_i$. On the other hand, the Dirichlet energy is defined as $E(f) = \frac{1}{2}\int_{D_2} ||f_1||_g + ||f_2||_g dx_1dx_2$, and by simply comparing the integrants, one sees that $A(f) \leq E(f)$ with equality holding if and only if $||f_1||_g = ||f_2||_g$ and $g(f_1,f_2) = 0$ everywhere. Immersions with that property are called conformal and it is well known that for any given immersion, there exists a parameter transformation $\psi:D_2 \to D_2$ such that $f \circ \psi$ is a conformal immersion. In other words, an immersion $f$ is conformal if and only if $f^*(g) = e^{\phi} \cdot g_{eukl}$ for some smooth function $\phi$ on $D_2$, which means precisely that $f^*(g)$ and $g_{eukl}$ are conformal as metrics on $D_2$. I have some trouble understanding why this is still possible when $f:(S,h) \to (M,g)$ is an immersion of any compact Riemannian 2-manifold. I know that the area of $f$ is in general defined by $A(g) := \int_S \omega_{f^*(g)}$, whereas the Dirichlet energy depends on $h$ and is defined by $E_h(f) := \frac{1}{2} \int_S |df|^2 \omega_h$. I have shown that we always have $A(f) \leq E_h(f)$ (regardless of $h$), where $f$ is said to be conformal if equality holds. One can show that this is equivalent to the metrics $f^*(g)$ and $h$ being conformal, i.e $f^*(g) = e^\phi \cdot h$. Is it still true that there exists a diffeomorphism $\psi: S \to S$ such that $f \circ \psi$ is conformal ? I ask because I only find papers that assert the existence of isothermal coordinates on any Riemannian 2-manifold, which essentially seems to only imply the case from the first paragraph.",,"['differential-geometry', 'riemannian-geometry', 'surfaces', 'minimal-surfaces']"
74,Are flat manifolds affine?,Are flat manifolds affine?,,"I try to understand an article where it is stated that some results regarding affine manifolds apply to the case of the manifold being a flat, compact Lorentzian manifold. The definition of affine, in this context, is that the manifold has a maximal atlas of charts whose transitions maps extend to affine mappings on ${R}^n$. My questions: Is a flat manifold affine? Especially, is a flat Lorentzian manifold affine? Is a compact, flat Lorentzian manifold affine?","I try to understand an article where it is stated that some results regarding affine manifolds apply to the case of the manifold being a flat, compact Lorentzian manifold. The definition of affine, in this context, is that the manifold has a maximal atlas of charts whose transitions maps extend to affine mappings on ${R}^n$. My questions: Is a flat manifold affine? Especially, is a flat Lorentzian manifold affine? Is a compact, flat Lorentzian manifold affine?",,['differential-geometry']
75,Geodesic Lines on Covering Maps,Geodesic Lines on Covering Maps,,"So I'm not sure how deck transformations work into this problem. I've established the following so far. Let $\pi:\tilde{M}\rightarrow M$ be the universal covering map. We may suppose that $M$ is compact and complete, and we endow the pullback metric on $\tilde{M}$. We also know that the fundamental group of $M$ has infinitely many elements, so this tells us that $\tilde{M}$ is non-compact. Knowing this we can form a geodesic ray $\gamma:[0,\infty)\rightarrow \tilde{M}$ situated at $\gamma(0)=p\in\tilde{M}$. By completeness we can complete $\gamma$ to be a geodesic on $\mathbb{R}$. I want to show that $\gamma$ is a geodesic line. Here is where I don't know how deck transformations come into play. I've messed around with it a little bit and I haven't gotten anywhere. Any advice on what I might need to show to get on the right track? Definition: (Geodesic ray)A geodesic ray is a map $\gamma:[0,\infty)\rightarrow M$ such that $\gamma\mid_{[0,t]}$ is a minimizing geodesic for all $t>0$. Definition: (Geodesic line)A geodesic line is a map $\gamma:\mathbb{R}\rightarrow M$ such that $\gamma\mid_{[a,b]}$ is a minimizing geodesic for all $a,b\in\mathbb{R}$.","So I'm not sure how deck transformations work into this problem. I've established the following so far. Let $\pi:\tilde{M}\rightarrow M$ be the universal covering map. We may suppose that $M$ is compact and complete, and we endow the pullback metric on $\tilde{M}$. We also know that the fundamental group of $M$ has infinitely many elements, so this tells us that $\tilde{M}$ is non-compact. Knowing this we can form a geodesic ray $\gamma:[0,\infty)\rightarrow \tilde{M}$ situated at $\gamma(0)=p\in\tilde{M}$. By completeness we can complete $\gamma$ to be a geodesic on $\mathbb{R}$. I want to show that $\gamma$ is a geodesic line. Here is where I don't know how deck transformations come into play. I've messed around with it a little bit and I haven't gotten anywhere. Any advice on what I might need to show to get on the right track? Definition: (Geodesic ray)A geodesic ray is a map $\gamma:[0,\infty)\rightarrow M$ such that $\gamma\mid_{[0,t]}$ is a minimizing geodesic for all $t>0$. Definition: (Geodesic line)A geodesic line is a map $\gamma:\mathbb{R}\rightarrow M$ such that $\gamma\mid_{[a,b]}$ is a minimizing geodesic for all $a,b\in\mathbb{R}$.",,"['differential-geometry', 'riemannian-geometry', 'covering-spaces']"
76,How do we conclude that the determinant is $1$ ?,How do we conclude that the determinant is  ?,1,"I am looking at the following exercise of the book of Andrew Pressley: Let $P$ be an $n \times n$ orthogonal matrix and let $a \in \mathbb{R}^n$, so that $M(v) =Pv + a$ is an isometry of $\mathbb{R}^3$ (see Appendix 1). Show that, if $\gamma$ is a unit-speed curve in $\mathbb{R}^n$, the curve $\Gamma = M(\gamma )$ is also unit-speed. Show also that, if $t, n, b$ and $T, N, B$ are the tangent vector, principal normal and binormal of $\gamma$ and $\Gamma$, respectively, then $T = Pt$, $N = Pn$ and $B = Pb$. $$$$ The only point I get stuck is at showing that $B = Pb$. I did this: We have $$B T \times N=Pt \times Pn=\det (P) P( t \times n)$$ Since $P$ is an orthogonal matrix, we have $\det (P)=\pm 1$. How do we get $\det (P)=1$ so that $B=P(t \times n)=Pb$ ? $$$$ Edit: How do we conclude that in this case $P$ is orientation preserving? Do we assume that the isometry is direct?","I am looking at the following exercise of the book of Andrew Pressley: Let $P$ be an $n \times n$ orthogonal matrix and let $a \in \mathbb{R}^n$, so that $M(v) =Pv + a$ is an isometry of $\mathbb{R}^3$ (see Appendix 1). Show that, if $\gamma$ is a unit-speed curve in $\mathbb{R}^n$, the curve $\Gamma = M(\gamma )$ is also unit-speed. Show also that, if $t, n, b$ and $T, N, B$ are the tangent vector, principal normal and binormal of $\gamma$ and $\Gamma$, respectively, then $T = Pt$, $N = Pn$ and $B = Pb$. $$$$ The only point I get stuck is at showing that $B = Pb$. I did this: We have $$B T \times N=Pt \times Pn=\det (P) P( t \times n)$$ Since $P$ is an orthogonal matrix, we have $\det (P)=\pm 1$. How do we get $\det (P)=1$ so that $B=P(t \times n)=Pb$ ? $$$$ Edit: How do we conclude that in this case $P$ is orientation preserving? Do we assume that the isometry is direct?",,['differential-geometry']
77,proving a given curve is a geodesic,proving a given curve is a geodesic,,"I am trying to solve the following problem from Lee's Riemannian Manifolds : where the curve $\gamma : I \to \mathbb{R}^2$ is given by $\gamma(t) = (a(t),b(t))$ so that $M$ is parametrized as $\varphi(\theta,t) = (a(t) \cos \theta, a(t) \sin \theta, b(t))$. I completed part (a), and got the following: $$\begin{array}{cccc} \Gamma_{\theta \theta}^{\theta} = 0, & \Gamma_{\theta \theta}^t = - a(t) \dot{a}(t), & \Gamma_{\theta t}^{\theta} = \dfrac{\dot{a}(t)}{a(t)}, & \Gamma_{\theta t}^t = 0, \\  \Gamma_{t \theta}^{\theta} = \dfrac{\dot{a}(t)}{a(t)}, & \Gamma_{t \theta}^t = 0, & \Gamma_{tt}^{\theta} = 0, & \text{and } \Gamma_{tt}^t = 0. \end{array}$$ For part (b), I think I should be showing that the curve $\alpha : I \to M$ defined by $\alpha(t) = \varphi(\theta_0,t) = (a(t) \cos \theta_0, a(t) \sin \theta_0,b(t))$ satisfies the geodesic equation $$\ddot{\alpha}^k(t) + \dot{\alpha}^i(t) \dot{\alpha}^j(t) \Gamma_{ij}^k (\alpha(t)) = 0.$$  However, I'm confused as to how to perform the calculation when my curve is in standard coordinates and my Christoffel symbols are in $(\theta,t)$ coordinates.  Can anyone tell me where I'm going wrong in trying to do the calculation and what I should be doing instead? Also, I'm assuming that for part (c), I should again be using the geodesic equation, but that I should be able to derive a condition on the ""latitude circle"" after performing the calculation.","I am trying to solve the following problem from Lee's Riemannian Manifolds : where the curve $\gamma : I \to \mathbb{R}^2$ is given by $\gamma(t) = (a(t),b(t))$ so that $M$ is parametrized as $\varphi(\theta,t) = (a(t) \cos \theta, a(t) \sin \theta, b(t))$. I completed part (a), and got the following: $$\begin{array}{cccc} \Gamma_{\theta \theta}^{\theta} = 0, & \Gamma_{\theta \theta}^t = - a(t) \dot{a}(t), & \Gamma_{\theta t}^{\theta} = \dfrac{\dot{a}(t)}{a(t)}, & \Gamma_{\theta t}^t = 0, \\  \Gamma_{t \theta}^{\theta} = \dfrac{\dot{a}(t)}{a(t)}, & \Gamma_{t \theta}^t = 0, & \Gamma_{tt}^{\theta} = 0, & \text{and } \Gamma_{tt}^t = 0. \end{array}$$ For part (b), I think I should be showing that the curve $\alpha : I \to M$ defined by $\alpha(t) = \varphi(\theta_0,t) = (a(t) \cos \theta_0, a(t) \sin \theta_0,b(t))$ satisfies the geodesic equation $$\ddot{\alpha}^k(t) + \dot{\alpha}^i(t) \dot{\alpha}^j(t) \Gamma_{ij}^k (\alpha(t)) = 0.$$  However, I'm confused as to how to perform the calculation when my curve is in standard coordinates and my Christoffel symbols are in $(\theta,t)$ coordinates.  Can anyone tell me where I'm going wrong in trying to do the calculation and what I should be doing instead? Also, I'm assuming that for part (c), I should again be using the geodesic equation, but that I should be able to derive a condition on the ""latitude circle"" after performing the calculation.",,"['geometry', 'differential-geometry', 'riemannian-geometry']"
78,Exterior Derivative in overlapping charts,Exterior Derivative in overlapping charts,,"Given a smooth manifold $M$, say of dimension $n$ and two charts $ (U,x)$ & $ (V,y)$, I want to prove that if $U \cap V \neq \emptyset $, then the exterior derivatives $d_x$ and $d_y$ coincide in $ U \cap V$. For this, there is a Lemma (8.36) in Jeffrey Lee's Manifolds and Differential Geometry that says that if I have two natural graded derivations of the same degree defined on the same set (such as $d_x$ and $d_y$ in $ U \cap V$), and they coincide when applied to smooth functions and exact forms, then they are equal. If $\alpha$ is an exact form, then $\alpha = d\beta$ for some differential form $\beta$. The exterior derivative $d$ satisfies that $d \circ d = 0$, so $d_x\alpha = d_y\alpha = d \circ d \beta = 0 $. Now, given a smooth function $f \in C^\infty(U \cap V)$, I want to show that $d_xf = \sum_i \partial f/\partial x^i dx^i = \sum_i \partial f/\partial y^i dy^i = d_yf$, but I don't know how. I only know that $\partial f/\partial x^i = \sum_k \partial f/\partial y^k \cdot \partial y^k/\partial x^i$.","Given a smooth manifold $M$, say of dimension $n$ and two charts $ (U,x)$ & $ (V,y)$, I want to prove that if $U \cap V \neq \emptyset $, then the exterior derivatives $d_x$ and $d_y$ coincide in $ U \cap V$. For this, there is a Lemma (8.36) in Jeffrey Lee's Manifolds and Differential Geometry that says that if I have two natural graded derivations of the same degree defined on the same set (such as $d_x$ and $d_y$ in $ U \cap V$), and they coincide when applied to smooth functions and exact forms, then they are equal. If $\alpha$ is an exact form, then $\alpha = d\beta$ for some differential form $\beta$. The exterior derivative $d$ satisfies that $d \circ d = 0$, so $d_x\alpha = d_y\alpha = d \circ d \beta = 0 $. Now, given a smooth function $f \in C^\infty(U \cap V)$, I want to show that $d_xf = \sum_i \partial f/\partial x^i dx^i = \sum_i \partial f/\partial y^i dy^i = d_yf$, but I don't know how. I only know that $\partial f/\partial x^i = \sum_k \partial f/\partial y^k \cdot \partial y^k/\partial x^i$.",,"['differential-geometry', 'differential-forms', 'smooth-manifolds']"
79,Easy derivation to show that the curvature is $k(t)=\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3}$?,Easy derivation to show that the curvature is ?,k(t)=\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3},"This is an exercise from Do Carmo's Differential Geometry which I doubt whether or not my working is correct. Let $\alpha: I\to R^3$ be a regular parametrized curve (not necessarily by arc length) and let $\beta:J\to R^3$ be a reparametrization of $\alpha(I)$ by the arc length $s=s(t)$, measured from $t_0\in I$. Let $t=t(s)$ be the inverse function of $s$ and set $d\alpha/dt=\alpha'$, $d^2\alpha/dt^2=\alpha''$, etc. Prove that the curvature of $\alpha$ at $t\in I$ is $$k(t)=\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3}$$ My attempt: We first simplify the RHS: $\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3}=\frac{|\alpha'||\alpha''|}{{|\alpha'|}^3}=\frac{|\alpha''|}{{|\alpha'|}^2}$, where I used the definition $|a\wedge b|=|a||b|\cos\theta$. Then we find the unit tangent vector of $\alpha$: $T(t)=\frac{\alpha'}{|\alpha'|}$. So $\frac{dT}{ds}=\frac{dT}{dt}\frac{dt}{ds}=T'(t)\frac{1}{|\alpha'|}$. Now it is very tempting to write $T'(t)=\frac{\alpha''}{|\alpha'|}$, then we have $\frac{dT}{ds}=\frac{\alpha''}{{|\alpha'|}^2}$ and since $\frac{dT}{ds}=kn$ where $n$ is the unit normal vector, so $k=\frac{|\alpha''|}{{|\alpha'|}^2}$. I really doubt my correctness, the part that I found it hard is to find $T'(t)$. And I think my working $T'(t)=\frac{\alpha''}{|\alpha'|}$ is wrong since the denominator might also be a function of $t$. But I am not sure how to fix it. Helps are really greatly appreciated! Thanks.","This is an exercise from Do Carmo's Differential Geometry which I doubt whether or not my working is correct. Let $\alpha: I\to R^3$ be a regular parametrized curve (not necessarily by arc length) and let $\beta:J\to R^3$ be a reparametrization of $\alpha(I)$ by the arc length $s=s(t)$, measured from $t_0\in I$. Let $t=t(s)$ be the inverse function of $s$ and set $d\alpha/dt=\alpha'$, $d^2\alpha/dt^2=\alpha''$, etc. Prove that the curvature of $\alpha$ at $t\in I$ is $$k(t)=\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3}$$ My attempt: We first simplify the RHS: $\frac{|\alpha'\wedge\alpha''|}{{|\alpha'|}^3}=\frac{|\alpha'||\alpha''|}{{|\alpha'|}^3}=\frac{|\alpha''|}{{|\alpha'|}^2}$, where I used the definition $|a\wedge b|=|a||b|\cos\theta$. Then we find the unit tangent vector of $\alpha$: $T(t)=\frac{\alpha'}{|\alpha'|}$. So $\frac{dT}{ds}=\frac{dT}{dt}\frac{dt}{ds}=T'(t)\frac{1}{|\alpha'|}$. Now it is very tempting to write $T'(t)=\frac{\alpha''}{|\alpha'|}$, then we have $\frac{dT}{ds}=\frac{\alpha''}{{|\alpha'|}^2}$ and since $\frac{dT}{ds}=kn$ where $n$ is the unit normal vector, so $k=\frac{|\alpha''|}{{|\alpha'|}^2}$. I really doubt my correctness, the part that I found it hard is to find $T'(t)$. And I think my working $T'(t)=\frac{\alpha''}{|\alpha'|}$ is wrong since the denominator might also be a function of $t$. But I am not sure how to fix it. Helps are really greatly appreciated! Thanks.",,"['differential-geometry', 'curves', 'curvature']"
80,Asymptotic behaviour of the length of a curve .,Asymptotic behaviour of the length of a curve .,,"Let $(M, g)$ be a Riemannian manifold and $\gamma :[0, \delta] \to M$ a $C^1$-curve, $\gamma(0) = y$ and $\dot\gamma(0) \neq 0$. Then we have $$\lim_{t\to 0} \frac{d_M(y, \gamma(t))}{\int_0^t |\dot \gamma|} = 1.$$ The proof suggested below uses the Taylor expansion of metric in a normal coordinate . I post this question and answer here since it helps complete a proof I wrote here , and this result has some independent interest (I think), and Would someone please check if the answer is correct, I am bit unfamiliar with the big $O$ argument. On the other hand, it would be great if someone points me to a reference where this is proved.","Let $(M, g)$ be a Riemannian manifold and $\gamma :[0, \delta] \to M$ a $C^1$-curve, $\gamma(0) = y$ and $\dot\gamma(0) \neq 0$. Then we have $$\lim_{t\to 0} \frac{d_M(y, \gamma(t))}{\int_0^t |\dot \gamma|} = 1.$$ The proof suggested below uses the Taylor expansion of metric in a normal coordinate . I post this question and answer here since it helps complete a proof I wrote here , and this result has some independent interest (I think), and Would someone please check if the answer is correct, I am bit unfamiliar with the big $O$ argument. On the other hand, it would be great if someone points me to a reference where this is proved.",,['differential-geometry']
81,Ratio of Eigenfunctions,Ratio of Eigenfunctions,,"Suppose we have the first two eigenfunctions $\phi_1, \phi_2$ of the Laplace Operator on a bounded domain with smooth boundary with Dirichlet condition. The first eigenfunction is positive in the interior, and hence by Hopf Boundary Lemma, has non-zero gradient on the boundary. Both the first and second eigenfunction are zero on the boundary. Apparently the ratio $\phi_2/\phi_1$ remains smooth on the closure of the domain. Why is this so? Reading some papers that use Malgrange's theorem, but I don't understand how we can apply Malgrange to $\phi_2$. I would also like to find a proof that doesn't use such a powerful theorem. These papers: http://homepages.math.uic.edu/~yau/35%20publications/An.pdf","Suppose we have the first two eigenfunctions $\phi_1, \phi_2$ of the Laplace Operator on a bounded domain with smooth boundary with Dirichlet condition. The first eigenfunction is positive in the interior, and hence by Hopf Boundary Lemma, has non-zero gradient on the boundary. Both the first and second eigenfunction are zero on the boundary. Apparently the ratio $\phi_2/\phi_1$ remains smooth on the closure of the domain. Why is this so? Reading some papers that use Malgrange's theorem, but I don't understand how we can apply Malgrange to $\phi_2$. I would also like to find a proof that doesn't use such a powerful theorem. These papers: http://homepages.math.uic.edu/~yau/35%20publications/An.pdf",,"['real-analysis', 'differential-geometry', 'partial-differential-equations']"
82,Clarification in the way I have to do derivatives in this problem of Riemannian geometry (Euler-Lagrange equations),Clarification in the way I have to do derivatives in this problem of Riemannian geometry (Euler-Lagrange equations),,"Let be $X$ a Riemannian manifold. I fix a local chart $(U,\varphi)$ If $ \phi : [a,b] \rightarrow U$ is $C^\infty$ I consider $$H(\phi )= \int_a^b k(\phi (t),\dot{\phi(t)})\; dt$$ where $$ k(\phi(t),\dot{\phi(t)})= \sum_{\alpha, \beta} g_{\alpha,\beta}(\phi(t)) \:\dot{\phi}(t)^\alpha\: \dot{\phi}(t)^\beta$$ and $\phi^1(t),\dots, \phi^n(t)$ are the local coordinates of $\phi(t)$ (i.e. $\varphi \circ \phi=(\phi^1, \dots \phi^n)$) I have that $k$ satisfies the Euler-Lagrange equations: $$ \frac{d}{dt}\big(\frac{\partial k}{\partial \dot{x}^\gamma}\big)-\frac{\partial k}{\partial x^\gamma}=0.$$ I don't understand why I have that: $$ \frac{\partial k}{\partial x^\gamma}= \sum_{\alpha, \beta} \frac{\partial g_{\alpha,\beta}} {\partial x^ \gamma} \:\dot{\phi}^\alpha\: \dot{\phi}^\beta$$  and $$ \frac{\partial k}{\partial \dot{x}^\gamma}=2 \sum_{\alpha}  g_{\alpha,\gamma}\dot{\phi}^\alpha.$$ Why, when I do these derivatives, have I to consider  $\phi^j$ as  $x^j$ and the $\dot{\phi}^j$ as $\dot{x}^j$ ? Thanks for the clarification.","Let be $X$ a Riemannian manifold. I fix a local chart $(U,\varphi)$ If $ \phi : [a,b] \rightarrow U$ is $C^\infty$ I consider $$H(\phi )= \int_a^b k(\phi (t),\dot{\phi(t)})\; dt$$ where $$ k(\phi(t),\dot{\phi(t)})= \sum_{\alpha, \beta} g_{\alpha,\beta}(\phi(t)) \:\dot{\phi}(t)^\alpha\: \dot{\phi}(t)^\beta$$ and $\phi^1(t),\dots, \phi^n(t)$ are the local coordinates of $\phi(t)$ (i.e. $\varphi \circ \phi=(\phi^1, \dots \phi^n)$) I have that $k$ satisfies the Euler-Lagrange equations: $$ \frac{d}{dt}\big(\frac{\partial k}{\partial \dot{x}^\gamma}\big)-\frac{\partial k}{\partial x^\gamma}=0.$$ I don't understand why I have that: $$ \frac{\partial k}{\partial x^\gamma}= \sum_{\alpha, \beta} \frac{\partial g_{\alpha,\beta}} {\partial x^ \gamma} \:\dot{\phi}^\alpha\: \dot{\phi}^\beta$$  and $$ \frac{\partial k}{\partial \dot{x}^\gamma}=2 \sum_{\alpha}  g_{\alpha,\gamma}\dot{\phi}^\alpha.$$ Why, when I do these derivatives, have I to consider  $\phi^j$ as  $x^j$ and the $\dot{\phi}^j$ as $\dot{x}^j$ ? Thanks for the clarification.",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
83,Geometric\Graphical verification of $ads=vdv$?,Geometric\Graphical verification of ?,ads=vdv,"In my Engineering Dynamics class, I've encountered this equation $ads=vdv$.  I could not wrap my head around why it was true, but I was able to come up with a verification of it as such: $\mathrm{ds}=s'(t)\mathrm{dt}=v\mathrm{dt}$ and $dv=v'(t)\mathrm{dt}=a\mathrm{dt}$.  This yields $a*v\mathrm{dt}=v*a\mathrm{dt}$, ""proof"" (such as it is) complete.  However, I still have some issues.  I assume if I have $a(b\mathrm{dt})$, it is equal to $b(a\mathrm{dt})$ because either they are constants or to be evaluated $t$ must be taken consistently, but I can't prove it formally. Also, I can't really see intuitively why this is true.  I can see why $\frac{dy}{dx}$ is the derivative, and graphically so.  Simply draw the graph where we take a value of $f'(x)$ and multiply it by $\Delta x$ to get $\Delta y$ (of course, $dy$ only equals an arbitrarily chosen $\Delta y$ if $f(x)$ is linear.)  But I can't even figure out how to derive the first relationship. So I suppose the meat of my question is if someone would be so kind as to give a better (preferably graphical) description of why $ads=vdv$?","In my Engineering Dynamics class, I've encountered this equation $ads=vdv$.  I could not wrap my head around why it was true, but I was able to come up with a verification of it as such: $\mathrm{ds}=s'(t)\mathrm{dt}=v\mathrm{dt}$ and $dv=v'(t)\mathrm{dt}=a\mathrm{dt}$.  This yields $a*v\mathrm{dt}=v*a\mathrm{dt}$, ""proof"" (such as it is) complete.  However, I still have some issues.  I assume if I have $a(b\mathrm{dt})$, it is equal to $b(a\mathrm{dt})$ because either they are constants or to be evaluated $t$ must be taken consistently, but I can't prove it formally. Also, I can't really see intuitively why this is true.  I can see why $\frac{dy}{dx}$ is the derivative, and graphically so.  Simply draw the graph where we take a value of $f'(x)$ and multiply it by $\Delta x$ to get $\Delta y$ (of course, $dy$ only equals an arbitrarily chosen $\Delta y$ if $f(x)$ is linear.)  But I can't even figure out how to derive the first relationship. So I suppose the meat of my question is if someone would be so kind as to give a better (preferably graphical) description of why $ads=vdv$?",,"['calculus', 'differential-geometry']"
84,Surface with all tangent plane pass through one common point is a cone surface,Surface with all tangent plane pass through one common point is a cone surface,,"I want to prove that a surface with all tangent plane pass through one common point is a cone surface (a surface like this $\mathbf{r}(u,v)=\mathbf{a}_0+v\mathbf{b}(u)$, here $\mathbf{a}_0$ is a constant vector). Hints1: use natural coodintates; Hints2: use the orthonormal frame and exterior differential forms. For both methods, up to now, I can only prove that the Gauss curvature of the surface is zero. I do not know how to proceed? Any ideas or comments will be helpful.","I want to prove that a surface with all tangent plane pass through one common point is a cone surface (a surface like this $\mathbf{r}(u,v)=\mathbf{a}_0+v\mathbf{b}(u)$, here $\mathbf{a}_0$ is a constant vector). Hints1: use natural coodintates; Hints2: use the orthonormal frame and exterior differential forms. For both methods, up to now, I can only prove that the Gauss curvature of the surface is zero. I do not know how to proceed? Any ideas or comments will be helpful.",,"['differential-geometry', 'surfaces']"
85,smooth manifolds and preimage of momentum mappings,smooth manifolds and preimage of momentum mappings,,"Let $G$ be a Lie group acting on itself as $\phi(h)(g)= L_h(g)$ as a left translation. Then we can consider the cotangent lift of this action, namely $\Phi: G \times T^*G \rightarrow T^*G$  as $\Phi(h)(g,p) = (hg,(dL_{h^{-1}}(hg))^*p).$ It can now be shown that such a map induces a canonical Hamilton function with moment map on the cotangent bundle $H_{\xi}(g,p) =  J(q,p)(\xi):=(dR_g)^*(e)(p)(\xi)$ for some $\xi \in \mathfrak{g}.$ This is now my motivation for the question: If we consider $J^{-1}(x)$ for $x \in \mathfrak{g}^*$ then this set is given by $$J^{-1}(x) = \{ (g , (dR_{g^{-1}})^*(g)(x));g \in G \}.$$ My question is: Why is it a manifold? (I admit that it looks very much like an application of the regular value theorem, but I don't see why it applies) If there is anything unclear about my question, please let me know.","Let $G$ be a Lie group acting on itself as $\phi(h)(g)= L_h(g)$ as a left translation. Then we can consider the cotangent lift of this action, namely $\Phi: G \times T^*G \rightarrow T^*G$  as $\Phi(h)(g,p) = (hg,(dL_{h^{-1}}(hg))^*p).$ It can now be shown that such a map induces a canonical Hamilton function with moment map on the cotangent bundle $H_{\xi}(g,p) =  J(q,p)(\xi):=(dR_g)^*(e)(p)(\xi)$ for some $\xi \in \mathfrak{g}.$ This is now my motivation for the question: If we consider $J^{-1}(x)$ for $x \in \mathfrak{g}^*$ then this set is given by $$J^{-1}(x) = \{ (g , (dR_{g^{-1}})^*(g)(x));g \in G \}.$$ My question is: Why is it a manifold? (I admit that it looks very much like an application of the regular value theorem, but I don't see why it applies) If there is anything unclear about my question, please let me know.",,"['differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras', 'symplectic-geometry']"
86,A question on Stokes theorem for Lipschitz functions,A question on Stokes theorem for Lipschitz functions,,"Let $M$ be an oriented compact Riemannian manifold. Let $f$ be a Lipschitz function on $M$, denote $M'\subset M$ be the set on which $f$ is differentiable. On one hand, Stokes theorem works for Lipschitz functions, so we have $$0=\int_M \Delta f.$$ On the other hand I was wondering do we have $$\int_M\Delta f=\int_{M'}\Delta f\ \ ?$$ In other words, if $f$ is Lipschitz on $M$, and $\Delta f\geq 0$ on $M'$, could we conclude that $f$ has to be a constant?","Let $M$ be an oriented compact Riemannian manifold. Let $f$ be a Lipschitz function on $M$, denote $M'\subset M$ be the set on which $f$ is differentiable. On one hand, Stokes theorem works for Lipschitz functions, so we have $$0=\int_M \Delta f.$$ On the other hand I was wondering do we have $$\int_M\Delta f=\int_{M'}\Delta f\ \ ?$$ In other words, if $f$ is Lipschitz on $M$, and $\Delta f\geq 0$ on $M'$, could we conclude that $f$ has to be a constant?",,"['differential-geometry', 'riemannian-geometry']"
87,Mean Curvature flow: Evolution equation of any invariant symmetric homogeneous polynomial with input the Weingarten map.,Mean Curvature flow: Evolution equation of any invariant symmetric homogeneous polynomial with input the Weingarten map.,,"I have the following evolution equations realted to mean curavture flow, with the induced metric $g=\{g_{ij}\}$, measure $d\mu$ and second fundamental form $A=\{h_{ij}\}$: 1)$\frac{\partial}{\partial t}g_{ij}=-2Hh_{ij}$ 2)$\frac{\partial}{\partial t}d\mu=-H^2d\mu$ 3)$\frac{\partial}{\partial t}h_{ij}=\Delta h_{ij}-2Hh_{il}h^l_j+|A|^2h_{ij}$ Now we consider the Weingarten map $W:T_pM\to T_pM$ associated with $A$ and $g$, given by the matrix $\{h^i_j\}=\{g^{il}h_{lj}\}$, and let $P$ be any invariant symmetric homogeneous polynomial. Then I wish to prove the result. If  $W=\{h^i_j\}$ is the Weingarten map and $P(W)$ is an invariant polynomial of degree $\alpha$, i.e. $P(\rho W)=\rho^{\alpha}P(W)$, then 1) $\frac{\partial}{\partial t}h^i_j=\Delta h_j^i+|A|^2h_j^i$ 2)$\frac{\partial}{\partial t}P=\Delta P- \frac{\partial^2 P}{\partial h_{ij}\partial h_{pq}}\nabla_lh_{ij}\nabla_lh_{pq}+\alpha|A|^2P$ I'm able to prove the first part as follows, $\frac{\partial}{\partial t}h^i_j=\frac{\partial}{\partial t}(g^{ik}h_{jk}) =\frac{\partial}{\partial t}(g^{ik})h_{jk}+\frac{\partial}{\partial t}(h_{jk})g^{ik}$ $=2Hg^{is}h_{sl}g^{lk}h_{jk}+(\nabla h_{jk}-2Hh_{jl}h^l_k+|A|^2h_{jk})g^{ik}$ $=\Delta h_j^i+|A|^2H_j^i$. To work out $\frac{\partial}{\partial t}g^{ij}$ you just need to use the fact that $g^{ij}g_{ij}=1$ I think I'm missing a simple useful result to get part 2) out?","I have the following evolution equations realted to mean curavture flow, with the induced metric $g=\{g_{ij}\}$, measure $d\mu$ and second fundamental form $A=\{h_{ij}\}$: 1)$\frac{\partial}{\partial t}g_{ij}=-2Hh_{ij}$ 2)$\frac{\partial}{\partial t}d\mu=-H^2d\mu$ 3)$\frac{\partial}{\partial t}h_{ij}=\Delta h_{ij}-2Hh_{il}h^l_j+|A|^2h_{ij}$ Now we consider the Weingarten map $W:T_pM\to T_pM$ associated with $A$ and $g$, given by the matrix $\{h^i_j\}=\{g^{il}h_{lj}\}$, and let $P$ be any invariant symmetric homogeneous polynomial. Then I wish to prove the result. If  $W=\{h^i_j\}$ is the Weingarten map and $P(W)$ is an invariant polynomial of degree $\alpha$, i.e. $P(\rho W)=\rho^{\alpha}P(W)$, then 1) $\frac{\partial}{\partial t}h^i_j=\Delta h_j^i+|A|^2h_j^i$ 2)$\frac{\partial}{\partial t}P=\Delta P- \frac{\partial^2 P}{\partial h_{ij}\partial h_{pq}}\nabla_lh_{ij}\nabla_lh_{pq}+\alpha|A|^2P$ I'm able to prove the first part as follows, $\frac{\partial}{\partial t}h^i_j=\frac{\partial}{\partial t}(g^{ik}h_{jk}) =\frac{\partial}{\partial t}(g^{ik})h_{jk}+\frac{\partial}{\partial t}(h_{jk})g^{ik}$ $=2Hg^{is}h_{sl}g^{lk}h_{jk}+(\nabla h_{jk}-2Hh_{jl}h^l_k+|A|^2h_{jk})g^{ik}$ $=\Delta h_j^i+|A|^2H_j^i$. To work out $\frac{\partial}{\partial t}g^{ij}$ you just need to use the fact that $g^{ij}g_{ij}=1$ I think I'm missing a simple useful result to get part 2) out?",,"['differential-geometry', 'riemannian-geometry', 'mean-curvature-flows']"
88,Pulling back a connection to a curve,Pulling back a connection to a curve,,"What does it mean to pull a connection back to a curve? For example, if I take the connection $\nabla s = ds$ on the trivial bundle $\mathbb R^2 \times \mathbb R^2$ over $\mathbb R^2$, and the curve $\gamma=(a(t),b(t))$, what would pullback connection look like in coordinates? I tried to say $(\gamma^*d)(f(t))=d(\gamma(f(t))$, but I don't think this is right. The second object is $d$ of a function to $\mathbb R^2$, not $\mathbb R$, so we end up with a vector of $1$-forms instead of a single $1$-form.","What does it mean to pull a connection back to a curve? For example, if I take the connection $\nabla s = ds$ on the trivial bundle $\mathbb R^2 \times \mathbb R^2$ over $\mathbb R^2$, and the curve $\gamma=(a(t),b(t))$, what would pullback connection look like in coordinates? I tried to say $(\gamma^*d)(f(t))=d(\gamma(f(t))$, but I don't think this is right. The second object is $d$ of a function to $\mathbb R^2$, not $\mathbb R$, so we end up with a vector of $1$-forms instead of a single $1$-form.",,"['differential-geometry', 'definition', 'riemannian-geometry']"
89,Am I right about this definition of submanifold?,Am I right about this definition of submanifold?,,"Consider the following definition of submanifold : 1.5.  $\ \bf Definition.\ $ A subset $M\subset\mathbf R^{n}$ is called a $\underline{\text{differentiable submanifold}}$ of $\mathbf R^n$ of $\underline{\text{dimension}}$ $m\leqslant n$, if to each $x\in M$ there corresponds an invertible germ $\widetilde{\phi}\colon (\mathbf R^n,x)\to(\mathbf R^n,0)$, such that $\widetilde{\phi}(M,x)=(\mathbf R^m,x)\subset(\mathbf R^n,x)$ ($\mathbf R^m$ linearly imbedded in $\mathbf R^n$ for $m\leqslant n$) It seems to me that this is not equivalent to the usual definition of a submanifold: the usual definition is that $M$ is a submanifold of $N$ if there is a map $f: M \to N$ such that $f$ is a smooth injective embedding that is a homeomorphism onto its image. As far as I can tell the definition above merely says that $M$ comes with an atlas consisting of smooth diffeomorphisms $\phi$. But then any subset $M$ of $\mathbb R^n$ that can be endowed with such an atlas would be a submanifold of $\mathbb R^n$. Am I missing something? Please could someone clarify this to me?","Consider the following definition of submanifold : 1.5.  $\ \bf Definition.\ $ A subset $M\subset\mathbf R^{n}$ is called a $\underline{\text{differentiable submanifold}}$ of $\mathbf R^n$ of $\underline{\text{dimension}}$ $m\leqslant n$, if to each $x\in M$ there corresponds an invertible germ $\widetilde{\phi}\colon (\mathbf R^n,x)\to(\mathbf R^n,0)$, such that $\widetilde{\phi}(M,x)=(\mathbf R^m,x)\subset(\mathbf R^n,x)$ ($\mathbf R^m$ linearly imbedded in $\mathbf R^n$ for $m\leqslant n$) It seems to me that this is not equivalent to the usual definition of a submanifold: the usual definition is that $M$ is a submanifold of $N$ if there is a map $f: M \to N$ such that $f$ is a smooth injective embedding that is a homeomorphism onto its image. As far as I can tell the definition above merely says that $M$ comes with an atlas consisting of smooth diffeomorphisms $\phi$. But then any subset $M$ of $\mathbb R^n$ that can be endowed with such an atlas would be a submanifold of $\mathbb R^n$. Am I missing something? Please could someone clarify this to me?",,"['differential-geometry', 'differential-topology', 'definition']"
90,Proving this result on tangent spaces to foliations,Proving this result on tangent spaces to foliations,,"Reading through Lee's introduction to smooth manifold, I bumped into this result: $\textbf{Lemma 14.12.}$ Let $\cal F$ be a foliation of a smooth manifold $M$ . The collection of tangent spaces to the leaves of $\cal F$ forms an involutive distribution on $M$ . I've tried to prove it, but have gotten stuck. A foliation is basically slicing $M$ into $k$ -dimensional submanifolds (immersed submanifolds), called leaves, so that each $p\in M$ has a neighborhood $(U,\phi)$ which intersects each leaf either in the empty set or in a coutable union of ""slices"", i.e. connected pieces where the final $\dim M-k$ coordinates of $\phi$ are constant. This type of chart is called flat chart . I have to prove the tangent spaces to the foliation give a $k$ -dimensional distribution on $M$ . A distribution is assigning to each point a linear subspace $\Delta_p$ of dimension the distribution's dimension, in this case $k$ , of the tangent space $T_pM$ , in such a way that each $p\in M$ has a neighborhood $U$ with $k$ linearly independent fields $X_1,\dotsc,X_k$ on $U$ which are smooth and span $\Delta_q$ for all $q\in U$ , i.e. $\Delta_q=\mathrm{span}(X_1(q),\dotsc,X_k(q))$ for all $q\in U$ . That we have a subspace of the tangent space per point of $M$ is easy: take the tangent spaces to the leaves. The $k$ fields are the first problem. How do I construct them? I'm sure I must use the flat charts somehow. Perhaps the coordinate fields of the flat chart? Those may not span the subspaces though. So how do I find these fields? Involutiveness means that those $k$ fields have Lie brackets which stay in the distribution. If I can't show the fields exist, I certainly cannot show they fulfill this condition, so I am stuck here. How do I proceed?","Reading through Lee's introduction to smooth manifold, I bumped into this result: Let be a foliation of a smooth manifold . The collection of tangent spaces to the leaves of forms an involutive distribution on . I've tried to prove it, but have gotten stuck. A foliation is basically slicing into -dimensional submanifolds (immersed submanifolds), called leaves, so that each has a neighborhood which intersects each leaf either in the empty set or in a coutable union of ""slices"", i.e. connected pieces where the final coordinates of are constant. This type of chart is called flat chart . I have to prove the tangent spaces to the foliation give a -dimensional distribution on . A distribution is assigning to each point a linear subspace of dimension the distribution's dimension, in this case , of the tangent space , in such a way that each has a neighborhood with linearly independent fields on which are smooth and span for all , i.e. for all . That we have a subspace of the tangent space per point of is easy: take the tangent spaces to the leaves. The fields are the first problem. How do I construct them? I'm sure I must use the flat charts somehow. Perhaps the coordinate fields of the flat chart? Those may not span the subspaces though. So how do I find these fields? Involutiveness means that those fields have Lie brackets which stay in the distribution. If I can't show the fields exist, I certainly cannot show they fulfill this condition, so I am stuck here. How do I proceed?","\textbf{Lemma 14.12.} \cal F M \cal F M M k p\in M (U,\phi) \dim M-k \phi k M \Delta_p k T_pM p\in M U k X_1,\dotsc,X_k U \Delta_q q\in U \Delta_q=\mathrm{span}(X_1(q),\dotsc,X_k(q)) q\in U M k k","['differential-geometry', 'smooth-manifolds', 'foliations']"
91,Holonomy computation in a sphere,Holonomy computation in a sphere,,"Let $S^1$ be the unit sphere in $\mathbb R^3$, and let $$C=\{(r\cos t, r\sin t, h)\colon t\in \mathbb R\}$$ with $r^2+h^2=1$ be a circle in $S^2$. I want to compute the holonomy around this circle. I know that if $(\theta, \phi)$ are spherical coordinates, where $\theta$ measures the angle from the $x$-axis (as in polar coordinates) and $\phi$ measures the angle from the $z$-axis, we can pull back the Euclidean metric to find $$ds^2=d\phi^2 + \sin^2 \phi \ d\theta^2.$$ Then traveling around the circle means fixing $\phi$ and moving theta from $0$ to $2\pi$. However, actually computing parallel transport along this curve in coordinates seems really messy. Is there a way to do it in the ambient coordinates that would make the calculation easier? I tried to do the computation in coordinates and it didn't go so well. We are looking to parallel transport vectors along $\gamma(t)=(t,\phi_0)$, with $t\in[0,2\pi]$. We have $\gamma'(t)=(1,0)$. Any vector field $V(\theta)$ along the curve extends in the obvious way: $\tilde V(\theta, \phi)=V(\theta)$, so it suffices to look at extensions that are just a function of $\theta$. Note $D_t=\nabla_\theta$. If $$V=a(\theta)\partial_\theta + b(\theta)\partial_\phi,$$ we need  $$D_tV=0,$$ or $$\nabla_\theta(a(\theta)\partial_\theta + b(\theta)\partial_\phi)=0.$$ Writing everything out and noting that a few of the Christoffel symbols vanish, I get the following system. $$a'(\theta)+b(\theta)\Gamma^\theta_{\theta \phi}=0.$$ $$b'(\theta) + a(\theta)\Gamma^\phi_{\theta\phi}=0.$$ I get $$\Gamma^\theta_{\theta \phi} = \frac{\cos \phi}{\sin \phi},$$ $$\Gamma^\phi_{\theta\phi}=-\cos \phi \sin \phi.$$ We get solutions  $$a(\theta)=\cos(\theta \cos \phi),$$ $$b(\theta)=\sin (\phi) \sin(\theta \cos \phi).$$ At $\theta=0$, we have $X=(1,0)$. At $\theta=2\pi$, we have $$Y=(\cos(2\pi \cos \phi), \sin\phi \cdot \sin(2\pi \cos \phi).$$ These are both norm $\sin^2 \phi$ vectors. We can compute the angle  $$\cos \alpha = \frac{\langle X, Y \rangle_g}{|X||Y|}.$$ Then $\alpha = 2\pi \cos\phi$, or $2\phi h$.","Let $S^1$ be the unit sphere in $\mathbb R^3$, and let $$C=\{(r\cos t, r\sin t, h)\colon t\in \mathbb R\}$$ with $r^2+h^2=1$ be a circle in $S^2$. I want to compute the holonomy around this circle. I know that if $(\theta, \phi)$ are spherical coordinates, where $\theta$ measures the angle from the $x$-axis (as in polar coordinates) and $\phi$ measures the angle from the $z$-axis, we can pull back the Euclidean metric to find $$ds^2=d\phi^2 + \sin^2 \phi \ d\theta^2.$$ Then traveling around the circle means fixing $\phi$ and moving theta from $0$ to $2\pi$. However, actually computing parallel transport along this curve in coordinates seems really messy. Is there a way to do it in the ambient coordinates that would make the calculation easier? I tried to do the computation in coordinates and it didn't go so well. We are looking to parallel transport vectors along $\gamma(t)=(t,\phi_0)$, with $t\in[0,2\pi]$. We have $\gamma'(t)=(1,0)$. Any vector field $V(\theta)$ along the curve extends in the obvious way: $\tilde V(\theta, \phi)=V(\theta)$, so it suffices to look at extensions that are just a function of $\theta$. Note $D_t=\nabla_\theta$. If $$V=a(\theta)\partial_\theta + b(\theta)\partial_\phi,$$ we need  $$D_tV=0,$$ or $$\nabla_\theta(a(\theta)\partial_\theta + b(\theta)\partial_\phi)=0.$$ Writing everything out and noting that a few of the Christoffel symbols vanish, I get the following system. $$a'(\theta)+b(\theta)\Gamma^\theta_{\theta \phi}=0.$$ $$b'(\theta) + a(\theta)\Gamma^\phi_{\theta\phi}=0.$$ I get $$\Gamma^\theta_{\theta \phi} = \frac{\cos \phi}{\sin \phi},$$ $$\Gamma^\phi_{\theta\phi}=-\cos \phi \sin \phi.$$ We get solutions  $$a(\theta)=\cos(\theta \cos \phi),$$ $$b(\theta)=\sin (\phi) \sin(\theta \cos \phi).$$ At $\theta=0$, we have $X=(1,0)$. At $\theta=2\pi$, we have $$Y=(\cos(2\pi \cos \phi), \sin\phi \cdot \sin(2\pi \cos \phi).$$ These are both norm $\sin^2 \phi$ vectors. We can compute the angle  $$\cos \alpha = \frac{\langle X, Y \rangle_g}{|X||Y|}.$$ Then $\alpha = 2\pi \cos\phi$, or $2\phi h$.",,"['differential-geometry', 'riemannian-geometry']"
92,Huisken's distance comparison principle and type II singularities.,Huisken's distance comparison principle and type II singularities.,,"I've been reading Huisken's paper on his distance comparison principle and he remarked that in particular his theorem rules out the formation of type II singularities. These are singularities where in particular cusps form. Why is this true? For reference I will include his principle below Huisken's Distance Comparison Principle Let $F:\Gamma\times[0,T]\rightarrow\mathbb{R}^2$ be a smooth embedded solution of the curve shortening flow (1.1). Let $\Gamma\neq S^1$, such that $l$ is smoothly defined on $\Gamma\times \Gamma$. Suppose $d/l$ attains a local minimum at (p,q) in the interior of $\gamma\times\gamma$ at time $t_0\in[0,T]$. Then$$\frac{d}{dt}(d/l)(p,q,t_0)\geq0$$ with equality if and only if $\Gamma$ is a straight line. Note: $$d(p,q,t)=|F(p,t)-F(q,t)|$$ and $$l(p,q,t)=|\int_p^qds_t|$$ Reference: A Distance Comparison Principle for Evolving Curves by Huisken","I've been reading Huisken's paper on his distance comparison principle and he remarked that in particular his theorem rules out the formation of type II singularities. These are singularities where in particular cusps form. Why is this true? For reference I will include his principle below Huisken's Distance Comparison Principle Let $F:\Gamma\times[0,T]\rightarrow\mathbb{R}^2$ be a smooth embedded solution of the curve shortening flow (1.1). Let $\Gamma\neq S^1$, such that $l$ is smoothly defined on $\Gamma\times \Gamma$. Suppose $d/l$ attains a local minimum at (p,q) in the interior of $\gamma\times\gamma$ at time $t_0\in[0,T]$. Then$$\frac{d}{dt}(d/l)(p,q,t_0)\geq0$$ with equality if and only if $\Gamma$ is a straight line. Note: $$d(p,q,t)=|F(p,t)-F(q,t)|$$ and $$l(p,q,t)=|\int_p^qds_t|$$ Reference: A Distance Comparison Principle for Evolving Curves by Huisken",,"['differential-geometry', 'differential-topology']"
93,Star operator in the simplest form,Star operator in the simplest form,,"Let $E$ together with $g$ be a inner product space(over field $\mathbb R$) , $\text{dim}E=n<\infty$ and $\{e_1,\cdots,e_n\}$ is orthonormal basis of $E$ that $\{e^1,\cdots,e^n\}$ is its dual basis(for $E^*$). Now we define  $\omega:=e^1\wedge\cdots\wedge e^n$ as an element of volume of $E$. I prove that $g^{\flat}: E\rightarrow E^*$ with rule  $(g^{\flat}(u))(v)=g(u,v)$, is an isomorphism ($ \forall u,v\in E$). Convention: $u\stackrel{g^{\flat}}\mapsto \tilde{u} $ i.e. $\tilde{u}:=g^{\flat}(u)$. I wish to prove that for any p-form $\theta\in \Lambda^p(E)$,  There exist a unique element $\eta\in\Lambda^{(n-p)}(E)$ such that $\eta(u_1,\cdots, u_{n-p})\omega=\theta\wedge\tilde{u}_1\cdots\wedge \tilde{u}_{n-p}\qquad \forall u_1,\cdots, u_{n-p}\in E$ . How can I do this? Of course I guess that should be defined an inner product $g_{\Lambda^k(E)}$ on $\Lambda^k(E)$ for any $0<k<n$ and then use $g^{\flat}_{\Lambda^k(E)}$. what is your method ? and How?","Let $E$ together with $g$ be a inner product space(over field $\mathbb R$) , $\text{dim}E=n<\infty$ and $\{e_1,\cdots,e_n\}$ is orthonormal basis of $E$ that $\{e^1,\cdots,e^n\}$ is its dual basis(for $E^*$). Now we define  $\omega:=e^1\wedge\cdots\wedge e^n$ as an element of volume of $E$. I prove that $g^{\flat}: E\rightarrow E^*$ with rule  $(g^{\flat}(u))(v)=g(u,v)$, is an isomorphism ($ \forall u,v\in E$). Convention: $u\stackrel{g^{\flat}}\mapsto \tilde{u} $ i.e. $\tilde{u}:=g^{\flat}(u)$. I wish to prove that for any p-form $\theta\in \Lambda^p(E)$,  There exist a unique element $\eta\in\Lambda^{(n-p)}(E)$ such that $\eta(u_1,\cdots, u_{n-p})\omega=\theta\wedge\tilde{u}_1\cdots\wedge \tilde{u}_{n-p}\qquad \forall u_1,\cdots, u_{n-p}\in E$ . How can I do this? Of course I guess that should be defined an inner product $g_{\Lambda^k(E)}$ on $\Lambda^k(E)$ for any $0<k<n$ and then use $g^{\flat}_{\Lambda^k(E)}$. what is your method ? and How?",,"['differential-geometry', 'tensor-products', 'tensors', 'multilinear-algebra', 'exterior-algebra']"
94,Curvature flow for convex planes curves,Curvature flow for convex planes curves,,"Tentative translation of the original question. I've read several articles on the curvature flow for convex plane curves (the curve remains convex during evolution, and eventually shrinks to a point). I found this result interesting but couldn't relate it to a real life phenomenon. Does anyone know of a real phenomenon which could shed some light on this result? Original question. Bonsoir mes amis, j'ai lu plusieurs articles sur le flot de courbure pour le cas des courbes convexes planes (pendant l’évolution la courbe reste convexe et tend vers un point à la limite), je l'ai trouvé très intéressant mais je n'ai pas pu appliquer un exemple dans notre vie pratique ou un certain phénomène déroulant dans la nature qui explique ce flot et cette évolution. Est-ce que quelqu'un a une idée d'un certain exemple ou phénomène réel qui explique ce résultat ??","Tentative translation of the original question. I've read several articles on the curvature flow for convex plane curves (the curve remains convex during evolution, and eventually shrinks to a point). I found this result interesting but couldn't relate it to a real life phenomenon. Does anyone know of a real phenomenon which could shed some light on this result? Original question. Bonsoir mes amis, j'ai lu plusieurs articles sur le flot de courbure pour le cas des courbes convexes planes (pendant l’évolution la courbe reste convexe et tend vers un point à la limite), je l'ai trouvé très intéressant mais je n'ai pas pu appliquer un exemple dans notre vie pratique ou un certain phénomène déroulant dans la nature qui explique ce flot et cette évolution. Est-ce que quelqu'un a une idée d'un certain exemple ou phénomène réel qui explique ce résultat ??",,"['geometry', 'differential-geometry', 'euclidean-geometry', 'riemannian-geometry']"
95,"Let $p=(5,0,-4)$ and $v \in T_{(5,0,-4)}M$. Compute $(F^{*}\omega)_p(v)$.",Let  and . Compute .,"p=(5,0,-4) v \in T_{(5,0,-4)}M (F^{*}\omega)_p(v)","Let me show my work before presenting the problem itself. Let $M=\{(x,y,z) \in \mathbb{R}^3 : x+y=5, x+z=cos^2y\}$ . We can easily see that $M$ is a submanifold of $\mathbb{R}^3$ of dimension $1$ . We can also see that we can construct a global atlas for $M$ , say $\{(M,\varphi)\}$ , where $\varphi:M\rightarrow\mathbb{R}$ is given by $(x,y,z) \mapsto y$ . If $P=(p_1,p_2,p_3) \in M$ , then $T_PM=\langle (-1,1,1-2sin(p_2)cos(p_2)) \rangle$ . In particular, for $P=(5,0,-4) \in M$ , $T_{(5,0,-4)}M = \langle (-1,1,1) \rangle$ . Consider the morphism (smooth map) $F:M \rightarrow S^1$ given by $(x,y,z) \mapsto (\frac{x}{\sqrt{x^2+y^2}},\frac{y}{\sqrt{x^2+y^2}})$ . Remember that $S^1=\{(x,y) \in \mathbb{R}^2 : x^2+y^2=1\}$ , so the given morphism is well defined. Expressing $F$ in the atlas of $M$ , we get $$F(x,y,z)=F(\varphi^{-1}(y))=(\frac{5-y}{\sqrt{2y^2-10y+25}},\frac{y}{\sqrt{2y^2-10y+25}})$$ We can see that $F(5,0,-4)=(1,0)$ . Now we choose a coordinate chart $\psi$ of $S^1$ in a neighborhood of $(1,0)$ . For example, $\psi:U=\{(x,y) \in S^1 : x > 0\} \longrightarrow ]-1,1[$ given by $(x,y) \mapsto y$ . We have also that $\omega=-\frac{1}{x}dy$ is one $1$ -form which is an orientation of $S^1$ in a neighborhood of the point $(1,0)$ . Let $P=(5,0,-4)$ and $v \in T_{(5,0,-4)}M$ . I want to compute $(F^{*}\omega)_P(v)$ . I'll show my attempt: We put $x:=\frac{u}{\sqrt{u^2+v^2}}$ and $y:=\frac{v}{\sqrt{u^2+v^2}}$ . So $-\frac{1}{x}dy=\frac{v}{u^2+v^2}du-\frac{u}{u^2+v^2}dv$ (I don't present the calculations because they're somewhat boring). So $F^*\omega = \frac{y}{x^2+y^2}dx -\frac{x}{x^2+y^2}dy$ and $(F^*\omega)_p=-\frac{1}{5}dy$ , so $(F^*\omega)_p(v)=-\frac{1}{5}C$ , where $v=(-C,C,C) \in T_{(5,0,-4)}M = \langle (-1,1,1) \rangle$ . Is this right? Some help would be appreciated. Thanks in advance.","Let me show my work before presenting the problem itself. Let . We can easily see that is a submanifold of of dimension . We can also see that we can construct a global atlas for , say , where is given by . If , then . In particular, for , . Consider the morphism (smooth map) given by . Remember that , so the given morphism is well defined. Expressing in the atlas of , we get We can see that . Now we choose a coordinate chart of in a neighborhood of . For example, given by . We have also that is one -form which is an orientation of in a neighborhood of the point . Let and . I want to compute . I'll show my attempt: We put and . So (I don't present the calculations because they're somewhat boring). So and , so , where . Is this right? Some help would be appreciated. Thanks in advance.","M=\{(x,y,z) \in \mathbb{R}^3 : x+y=5, x+z=cos^2y\} M \mathbb{R}^3 1 M \{(M,\varphi)\} \varphi:M\rightarrow\mathbb{R} (x,y,z) \mapsto y P=(p_1,p_2,p_3) \in M T_PM=\langle (-1,1,1-2sin(p_2)cos(p_2)) \rangle P=(5,0,-4) \in M T_{(5,0,-4)}M = \langle (-1,1,1) \rangle F:M \rightarrow S^1 (x,y,z) \mapsto (\frac{x}{\sqrt{x^2+y^2}},\frac{y}{\sqrt{x^2+y^2}}) S^1=\{(x,y) \in \mathbb{R}^2 : x^2+y^2=1\} F M F(x,y,z)=F(\varphi^{-1}(y))=(\frac{5-y}{\sqrt{2y^2-10y+25}},\frac{y}{\sqrt{2y^2-10y+25}}) F(5,0,-4)=(1,0) \psi S^1 (1,0) \psi:U=\{(x,y) \in S^1 : x > 0\} \longrightarrow ]-1,1[ (x,y) \mapsto y \omega=-\frac{1}{x}dy 1 S^1 (1,0) P=(5,0,-4) v \in T_{(5,0,-4)}M (F^{*}\omega)_P(v) x:=\frac{u}{\sqrt{u^2+v^2}} y:=\frac{v}{\sqrt{u^2+v^2}} -\frac{1}{x}dy=\frac{v}{u^2+v^2}du-\frac{u}{u^2+v^2}dv F^*\omega = \frac{y}{x^2+y^2}dx -\frac{x}{x^2+y^2}dy (F^*\omega)_p=-\frac{1}{5}dy (F^*\omega)_p(v)=-\frac{1}{5}C v=(-C,C,C) \in T_{(5,0,-4)}M = \langle (-1,1,1) \rangle","['differential-geometry', 'manifolds', 'orientation']"
96,Symplectic group action,Symplectic group action,,"Let $(M,\omega)$ be a symplectic manifold. We say that a group action $\phi: G \times M \rightarrow M$ is symplectic if each $\phi(g,.)$ is a symplectomorphism. Now, I am going through some lecture notes that are not available online, where I have difficulties to understand some details. So we define the vector field $\psi$ on the Lie Algebra ($\eta \in \mathfrak{g},p \in M$) such that $$\psi(\eta)(p) = \frac{d}{dt}|_{t=0} (\phi(e^{t \eta},p)) \in T_pM$$ So far so good. Now the author says: Assume that for each $\psi(\eta)$ there is a global Hamilton function $H_{\eta}: M \rightarrow \mathbb{R}$ such that $dH_{\eta} = \omega(\psi_{\eta},.).$ (So $\psi_\eta$ is the Hamiltonian vector field to $dH_{\eta}.)$ So far so good: Now the author wants to show that $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ for all $g \in G$ and $\xi \in \mathfrak{g}.$ In order to do this he claims that it is sufficient to prove this for all $1-$parameter subgroups $g(t) = e^{t \eta}, \eta \in \mathfrak{g}.$ I have no idea why this is sufficient cause I don't see that the exponential map is surjective in general (despite, he may refer here to a special case. at least, this is what I suspect, maybe you can help me identifying this one.) Then he writes $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ if and only if $H_{\xi} ( \phi(e^{t \eta},p)) = H_{Ad_{e^{-t\eta}}(\xi)}(p).$ and after that he again claims that it is sufficient (I have not the slightest idea why) to show this for $\frac{d}{dt}|_{t=0}$ so he differentiates both sides and gets for the right hand-side $$\frac{d}{dt}|_{t=0}H_{Ad_{e^{-t\eta}}(\xi)}(p) = H_{ad_{-\eta}(\xi)}(p).$$ Actually, I have even difficulties to understand why you can differentiate this function and leave $H$ as it is (no chain rule). Later on, he claims that any $T_p(orb_G(p))$ can be written as $\psi_{\eta}(p)$ for some $\eta \in \mathfrak{g}$ where $orb_G(p)$ is the orbit of $p$ under the group action $g$. I think this is similar to the previous issues. Either he likes to proof only special cases or I am missing a point here, but I don't see where all his sufficiency arguments come from? Is there anybody who looks through this or could comment on this? I can talk to the author soon, but I don't want to contact him without being sure that there is really something missing here.","Let $(M,\omega)$ be a symplectic manifold. We say that a group action $\phi: G \times M \rightarrow M$ is symplectic if each $\phi(g,.)$ is a symplectomorphism. Now, I am going through some lecture notes that are not available online, where I have difficulties to understand some details. So we define the vector field $\psi$ on the Lie Algebra ($\eta \in \mathfrak{g},p \in M$) such that $$\psi(\eta)(p) = \frac{d}{dt}|_{t=0} (\phi(e^{t \eta},p)) \in T_pM$$ So far so good. Now the author says: Assume that for each $\psi(\eta)$ there is a global Hamilton function $H_{\eta}: M \rightarrow \mathbb{R}$ such that $dH_{\eta} = \omega(\psi_{\eta},.).$ (So $\psi_\eta$ is the Hamiltonian vector field to $dH_{\eta}.)$ So far so good: Now the author wants to show that $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ for all $g \in G$ and $\xi \in \mathfrak{g}.$ In order to do this he claims that it is sufficient to prove this for all $1-$parameter subgroups $g(t) = e^{t \eta}, \eta \in \mathfrak{g}.$ I have no idea why this is sufficient cause I don't see that the exponential map is surjective in general (despite, he may refer here to a special case. at least, this is what I suspect, maybe you can help me identifying this one.) Then he writes $H_{\xi} ( \phi(g,p)) = H_{Ad_{g^{-1}}(\xi)}(p)$ if and only if $H_{\xi} ( \phi(e^{t \eta},p)) = H_{Ad_{e^{-t\eta}}(\xi)}(p).$ and after that he again claims that it is sufficient (I have not the slightest idea why) to show this for $\frac{d}{dt}|_{t=0}$ so he differentiates both sides and gets for the right hand-side $$\frac{d}{dt}|_{t=0}H_{Ad_{e^{-t\eta}}(\xi)}(p) = H_{ad_{-\eta}(\xi)}(p).$$ Actually, I have even difficulties to understand why you can differentiate this function and leave $H$ as it is (no chain rule). Later on, he claims that any $T_p(orb_G(p))$ can be written as $\psi_{\eta}(p)$ for some $\eta \in \mathfrak{g}$ where $orb_G(p)$ is the orbit of $p$ under the group action $g$. I think this is similar to the previous issues. Either he likes to proof only special cases or I am missing a point here, but I don't see where all his sufficiency arguments come from? Is there anybody who looks through this or could comment on this? I can talk to the author soon, but I don't want to contact him without being sure that there is really something missing here.",,['differential-geometry']
97,"How To Formalize the Fact that $(g, h)\mapsto dL_g|_h$ is smooth where $g, h\in G$ a Lie Group",How To Formalize the Fact that  is smooth where  a Lie Group,"(g, h)\mapsto dL_g|_h g, h\in G","Let $G$ be a Lie group. I am wondering if there is a way to say that the map $(g, h)\mapsto dL_g|_h$ defined on $G\times G$ is a smooth map (Here $L_g$ is the left translation map from $G$ to $G$ and by $dL_g|_h$ I mean the differential of $L_g$ at $h$). The challenge here is to make the set $\bigsqcup_{g, h\in G}\mathcal L(T_hG, T_{gh}G)$ into a smooth manifold in a fruitful way since $dL_g|_h\in \mathcal L(T_gG, T_{gh}G)$. I was reading the proof of the fact that the Lie algebra of a Lie group is finite dimensional from where the above question is motivated. In the proof there was this fact used that the map $g\mapsto dL_g|_ev:G\to TG$ is a smooth map, where $v$ is a fixed vector in $T_eG$. Thank you.","Let $G$ be a Lie group. I am wondering if there is a way to say that the map $(g, h)\mapsto dL_g|_h$ defined on $G\times G$ is a smooth map (Here $L_g$ is the left translation map from $G$ to $G$ and by $dL_g|_h$ I mean the differential of $L_g$ at $h$). The challenge here is to make the set $\bigsqcup_{g, h\in G}\mathcal L(T_hG, T_{gh}G)$ into a smooth manifold in a fruitful way since $dL_g|_h\in \mathcal L(T_gG, T_{gh}G)$. I was reading the proof of the fact that the Lie algebra of a Lie group is finite dimensional from where the above question is motivated. In the proof there was this fact used that the map $g\mapsto dL_g|_ev:G\to TG$ is a smooth map, where $v$ is a fixed vector in $T_eG$. Thank you.",,"['differential-geometry', 'lie-groups', 'smooth-manifolds']"
98,Congruence of two curves with an arbitrary speed?,Congruence of two curves with an arbitrary speed?,,"I'm studying the book ""elementary differential geometry"" by o'neil. There is a collorary which states that if two curves a(t), b(t) which is defined in the same real line interval has the same speed, curvature, torsion(torsion may differ by sign), then they are congruent. The preceding theorem says that two unit speed curve defined on the same real line interval are congruent if their curvature and torsion are equal(torsion may differ by sign) So i would like to prove the collorary as follows: since the speeds of the two curves are the same, the arc length parametrizations are the same( with the same lower limit of integration), say t=t(s) So the unit speed parametrization of the two curves has the same curvature and torsion since the original curve has the same curvature and torsion and arc length paramerization. So the two unit speed parametrization of two curves are congruent. And substituting s=s(t), the original two curves are congruent. Is there any fallacy in my reasoning? Any help will be greatly appreciated. Thank you for reading","I'm studying the book ""elementary differential geometry"" by o'neil. There is a collorary which states that if two curves a(t), b(t) which is defined in the same real line interval has the same speed, curvature, torsion(torsion may differ by sign), then they are congruent. The preceding theorem says that two unit speed curve defined on the same real line interval are congruent if their curvature and torsion are equal(torsion may differ by sign) So i would like to prove the collorary as follows: since the speeds of the two curves are the same, the arc length parametrizations are the same( with the same lower limit of integration), say t=t(s) So the unit speed parametrization of the two curves has the same curvature and torsion since the original curve has the same curvature and torsion and arc length paramerization. So the two unit speed parametrization of two curves are congruent. And substituting s=s(t), the original two curves are congruent. Is there any fallacy in my reasoning? Any help will be greatly appreciated. Thank you for reading",,['differential-geometry']
99,Covariant derivative of a constant inner product and how it decomposes into local coordinates,Covariant derivative of a constant inner product and how it decomposes into local coordinates,,"I wanted to confirm that my explicit (symbolic) computations of the covariant derivative of a constant inner product is (carefully) done right and correct. For the physicists (includes me), this is useful when thinking about 4-velocities. The defining property of a 4-velocity $u$ is this: $ u\cdot u \equiv u^{\flat}(u) \equiv g(u,u) = u_{\mu} u^{\mu} = g_{\mu \nu}u^{\mu} u^{\nu} = -1 $ For $f \in C^{\infty}(M)$ (smooth function on manifold $M$), $\nabla_u f = u(f) = u_i\frac{ \partial f}{ \partial x^i} \, \text{(locally)}$.  So clearly $\nabla_u (-1) =0$. Then is the chain rule or Leibnitz rule still valid for the so-called inner product $u\cdot u = u_{\mu} u^{\mu}$ so that $ \nabla_v (u_{\gamma} u^{\gamma} ) = u_{\gamma} \nabla_v u^{\gamma} + u^{\gamma} \nabla_v u_{\gamma} = 0  $ ? For the special case of $v=u$ (taking the covariant derivative with respect to $u$, or however it's called), and for a Levi Civita connection $\nabla$, so that one (of 2) of its defining properties being $\nabla g = 0$, so that  $\nabla_{\gamma} g_{\mu \nu}=0$ Then  $ u^{\gamma} \nabla_u u_{\gamma} = u^{\gamma}\nabla_u g_{\gamma \nu} u^{\nu} = u^{\gamma} g_{\gamma \nu} u^{\sigma} \nabla_{\sigma}u^{\nu} = u_{\nu} \nabla_u u^{\nu}$ So then $\nabla_u (u_{\gamma} u^{\gamma}) = 2 u_{\gamma} \nabla_u u^{\gamma} = 0 $. Then I can conclude that, assuming a Levi-Civita connection $\nabla$, $u\cdot u =-1$ also means that $u_{\nu} \nabla_u u^{\nu} =0$ Is this all correct? Update: EY 20150530 Yvonne Choquet-Bruhat, General Relativity and the Einstein Equations : Oxford Mathematical Monographs, Oxford University Press, 2009. ISBN-13: 978-0199230723 Chapter 13 Singularities, the 3rd section, Equation (3.6), confirms that $u^{\beta} \nabla_{\alpha} u_{\beta}=0$ is true, since $u^{\beta}u_{\beta}=-1$ I just want to know if I did the steps correctly.","I wanted to confirm that my explicit (symbolic) computations of the covariant derivative of a constant inner product is (carefully) done right and correct. For the physicists (includes me), this is useful when thinking about 4-velocities. The defining property of a 4-velocity $u$ is this: $ u\cdot u \equiv u^{\flat}(u) \equiv g(u,u) = u_{\mu} u^{\mu} = g_{\mu \nu}u^{\mu} u^{\nu} = -1 $ For $f \in C^{\infty}(M)$ (smooth function on manifold $M$), $\nabla_u f = u(f) = u_i\frac{ \partial f}{ \partial x^i} \, \text{(locally)}$.  So clearly $\nabla_u (-1) =0$. Then is the chain rule or Leibnitz rule still valid for the so-called inner product $u\cdot u = u_{\mu} u^{\mu}$ so that $ \nabla_v (u_{\gamma} u^{\gamma} ) = u_{\gamma} \nabla_v u^{\gamma} + u^{\gamma} \nabla_v u_{\gamma} = 0  $ ? For the special case of $v=u$ (taking the covariant derivative with respect to $u$, or however it's called), and for a Levi Civita connection $\nabla$, so that one (of 2) of its defining properties being $\nabla g = 0$, so that  $\nabla_{\gamma} g_{\mu \nu}=0$ Then  $ u^{\gamma} \nabla_u u_{\gamma} = u^{\gamma}\nabla_u g_{\gamma \nu} u^{\nu} = u^{\gamma} g_{\gamma \nu} u^{\sigma} \nabla_{\sigma}u^{\nu} = u_{\nu} \nabla_u u^{\nu}$ So then $\nabla_u (u_{\gamma} u^{\gamma}) = 2 u_{\gamma} \nabla_u u^{\gamma} = 0 $. Then I can conclude that, assuming a Levi-Civita connection $\nabla$, $u\cdot u =-1$ also means that $u_{\nu} \nabla_u u^{\nu} =0$ Is this all correct? Update: EY 20150530 Yvonne Choquet-Bruhat, General Relativity and the Einstein Equations : Oxford Mathematical Monographs, Oxford University Press, 2009. ISBN-13: 978-0199230723 Chapter 13 Singularities, the 3rd section, Equation (3.6), confirms that $u^{\beta} \nabla_{\alpha} u_{\beta}=0$ is true, since $u^{\beta}u_{\beta}=-1$ I just want to know if I did the steps correctly.",,"['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
