,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability of $n$ times a $\frac1n$ event,Probability of  times a  event,n \frac1n,"I never studied probability at school and this problem has been bothering me for a long time: Let's say I have a perfectly fair die. If I roll it, the odds of it landing on $6$ are $\frac{1}{6}$. If I roll two dice, the odds of at least one of them landing on 6 are $\frac{1}{6}\times 2 =\frac{1}{3}$. But what about if I roll six dice? What are the odds that one will land on $6$? Based on the previous reasoning, it should be: $$\frac{1}{6}\times 6 = 1$$ But that can't be true. It's actually possible that I roll six dice and none of them land on 6. What about if I roll $100$ dice? It's still possible that none of the land on 6. So what are the odds that at least one will?","I never studied probability at school and this problem has been bothering me for a long time: Let's say I have a perfectly fair die. If I roll it, the odds of it landing on $6$ are $\frac{1}{6}$. If I roll two dice, the odds of at least one of them landing on 6 are $\frac{1}{6}\times 2 =\frac{1}{3}$. But what about if I roll six dice? What are the odds that one will land on $6$? Based on the previous reasoning, it should be: $$\frac{1}{6}\times 6 = 1$$ But that can't be true. It's actually possible that I roll six dice and none of them land on 6. What about if I roll $100$ dice? It's still possible that none of the land on 6. So what are the odds that at least one will?",,['probability']
1,Price of Option in Betting Game,Price of Option in Betting Game,,"We both put 20 USD into a box. Then, we each generate a number in the interval (0,1) with uniform distribution. The person with the higher number wins and takes 40 USD, whilst the loser is left with 0 USD. I offer to sell you an option that allows you to regenerate your number after you see both of our numbers. What is the price of the option? This is my approach. After we get our number, there is a 50% chance that yours is higher than mine. If this is the case, I choose to regenerate my number to try and win, which gives me another 50% chance of winning. However, if my number is initially higher than yours (50% chance), then I do not use the option. This gives the expected probability P of winning of: P = 0.5(1) + 0.5(0.5) = 0.75 Hence price of option would be (0.75*40) - 0.5(40) = $10 However, the answer is 20/3. May someone please explain where I am going wrong?","We both put 20 USD into a box. Then, we each generate a number in the interval (0,1) with uniform distribution. The person with the higher number wins and takes 40 USD, whilst the loser is left with 0 USD. I offer to sell you an option that allows you to regenerate your number after you see both of our numbers. What is the price of the option? This is my approach. After we get our number, there is a 50% chance that yours is higher than mine. If this is the case, I choose to regenerate my number to try and win, which gives me another 50% chance of winning. However, if my number is initially higher than yours (50% chance), then I do not use the option. This gives the expected probability P of winning of: P = 0.5(1) + 0.5(0.5) = 0.75 Hence price of option would be (0.75*40) - 0.5(40) = $10 However, the answer is 20/3. May someone please explain where I am going wrong?",,"['probability', 'statistics', 'expected-value', 'game-theory', 'gambling']"
2,Calculate the probability of getting a total of 6 in three throws of a die,Calculate the probability of getting a total of 6 in three throws of a die,,"I am working on the following problem: In three throws of a die, what is the probability of a total score of $6$? My solution: We can get $6$ by the combination $(4,1,1)$ which has $3$ permutations and $(3,2,1)$ which has $6$ permutations. Therefore the probability is  $$\frac{3 + 6}{6^3} = \frac{9}{216} = \frac{1}{24}$$  But the solution that is mentioned as correct in my notes is: $$\frac{5}{108}$$ What am I doing wrong here?","I am working on the following problem: In three throws of a die, what is the probability of a total score of $6$? My solution: We can get $6$ by the combination $(4,1,1)$ which has $3$ permutations and $(3,2,1)$ which has $6$ permutations. Therefore the probability is  $$\frac{3 + 6}{6^3} = \frac{9}{216} = \frac{1}{24}$$  But the solution that is mentioned as correct in my notes is: $$\frac{5}{108}$$ What am I doing wrong here?",,"['probability', 'combinatorics', 'probability-theory', 'dice']"
3,Help with understanding point from Kahneman's book “Thinking Fast and Slow”,Help with understanding point from Kahneman's book “Thinking Fast and Slow”,,"My question: How did Kahneman arrive at the 60% number in the last sentence (""60% of the pairs"")? From Daniel Kahneman, Thinking Fast and Slow (Chapter 19, Illusion of Understanding): Update: from your answers, it appears that the number should have actually been 65%, so it was wrong in the book. A very generous estimate of the correlation between the success of the   firm and the quality of its CEO might be as high as .30, indicating   30% overlap. To appreciate the significance of this number, consider   the following question: Suppose you consider many pairs of firms. The two firms in each pair   are generally similar, but the CEO of one of them is better than the   other. How often will you find that the firm with the stronger CEO is   the more successful of the two? In a well-ordered and predictable world, the correlation would be   perfect, and the stronger CEO would be found to lead the more   successful firm in 100% of the pairs. If the relative success of   similar firms was determined entirely by factors that the CEO does not   control (call them luck, if you wish), you would find the more   successful firm led by the weaker CEO 50% of the time. A correlation   of .30 implies that you would find the stronger CEO leading the   stronger firm in about 60% of the pairs—an improvement of a mere 10   percentage points over random guessing, hardly grist for the hero   worship of CEOs we so often witness.","My question: How did Kahneman arrive at the 60% number in the last sentence (""60% of the pairs"")? From Daniel Kahneman, Thinking Fast and Slow (Chapter 19, Illusion of Understanding): Update: from your answers, it appears that the number should have actually been 65%, so it was wrong in the book. A very generous estimate of the correlation between the success of the   firm and the quality of its CEO might be as high as .30, indicating   30% overlap. To appreciate the significance of this number, consider   the following question: Suppose you consider many pairs of firms. The two firms in each pair   are generally similar, but the CEO of one of them is better than the   other. How often will you find that the firm with the stronger CEO is   the more successful of the two? In a well-ordered and predictable world, the correlation would be   perfect, and the stronger CEO would be found to lead the more   successful firm in 100% of the pairs. If the relative success of   similar firms was determined entirely by factors that the CEO does not   control (call them luck, if you wish), you would find the more   successful firm led by the weaker CEO 50% of the time. A correlation   of .30 implies that you would find the stronger CEO leading the   stronger firm in about 60% of the pairs—an improvement of a mere 10   percentage points over random guessing, hardly grist for the hero   worship of CEOs we so often witness.",,"['probability', 'correlation']"
4,The expected area of a triangle formed by three points randomly chosen from the unit square,The expected area of a triangle formed by three points randomly chosen from the unit square,,"""Three points are chosen uniformly and at random from a unit square. What is the expected value of the area of the resulting triangle?"" I need to do a research about that problem and i found this suggested solution: here . Now, I understand almost everything except anecdote (2) when he computes the expected value of $b$ and $v$.  I can't understand how he reaches those calculations. If someone can explain to me this that would be great. Thanks.","""Three points are chosen uniformly and at random from a unit square. What is the expected value of the area of the resulting triangle?"" I need to do a research about that problem and i found this suggested solution: here . Now, I understand almost everything except anecdote (2) when he computes the expected value of $b$ and $v$.  I can't understand how he reaches those calculations. If someone can explain to me this that would be great. Thanks.",,['probability']
5,Probability Density Function of Scaled Gamma Random Variable,Probability Density Function of Scaled Gamma Random Variable,,"Assume we have a Gamma Random Variable $X$ with the following pdf $$ \frac{m^mx^{m-1}}{\Gamma(m)}\text{exp}(-mx)$$ If I am asked to find the distribution of the following  $$Y= aX$$  where a is non-negative constant, how will the distribution change? Thanks","Assume we have a Gamma Random Variable $X$ with the following pdf $$ \frac{m^mx^{m-1}}{\Gamma(m)}\text{exp}(-mx)$$ If I am asked to find the distribution of the following  $$Y= aX$$  where a is non-negative constant, how will the distribution change? Thanks",,"['probability', 'probability-theory', 'probability-distributions']"
6,What does conditional probability $P(A|B)$ mean when $P(B)=0$?,What does conditional probability  mean when ?,P(A|B) P(B)=0,"Does anyone ever ascribe a value to $P(A|B)$ when $P(B)=0$? I realize that it being undefined makes sense, but I also feel like there should be a sensible definition.","Does anyone ever ascribe a value to $P(A|B)$ when $P(B)=0$? I realize that it being undefined makes sense, but I also feel like there should be a sensible definition.",,['probability']
7,How to calculate the $4$th central moment of binomial distribution?,How to calculate the th central moment of binomial distribution?,4,"I just derived it by using the generation function to first get raw moments. The result is $(-1+3np^2-6p^2-3np+6p)n(p-1)p$. It was merely brutal force calculation, nothing interesting.  So I was wondering, if there any one knows tricks that could simplify the process a bit.","I just derived it by using the generation function to first get raw moments. The result is $(-1+3np^2-6p^2-3np+6p)n(p-1)p$. It was merely brutal force calculation, nothing interesting.  So I was wondering, if there any one knows tricks that could simplify the process a bit.",,['probability']
8,What is expected number of turns to play this children's game?,What is expected number of turns to play this children's game?,,"I'm playing this game with children and I'm ready to stab my eyes with an ice pick. It seems like it never ends, but I know I expect it to end. What is my expected number of spins to remove all the fruit from the tree? Goal: To remove 14 cherries from tree by executing one of following seven directions at random per turn. 1. Remove 1 cherry.  2. Remove 2 cherries.  3. Remove 3 cherries.  4. Remove 4 cherries.  5. Return 1 cherry to tree.  6. Return 2 cherries to tree.  7. Return all your cherries to tree. Once I realized I have a 1/7 chance each turn of playing this game in perpetuity, I started reaching for the kitchen drawer.","I'm playing this game with children and I'm ready to stab my eyes with an ice pick. It seems like it never ends, but I know I expect it to end. What is my expected number of spins to remove all the fruit from the tree? Goal: To remove 14 cherries from tree by executing one of following seven directions at random per turn. 1. Remove 1 cherry.  2. Remove 2 cherries.  3. Remove 3 cherries.  4. Remove 4 cherries.  5. Return 1 cherry to tree.  6. Return 2 cherries to tree.  7. Return all your cherries to tree. Once I realized I have a 1/7 chance each turn of playing this game in perpetuity, I started reaching for the kitchen drawer.",,"['probability', 'game-theory']"
9,Probability question: optimal strategy,Probability question: optimal strategy,,"I am really confused about how to think about this question. It was presented as a challenge by a peer. Two people seek to kill a duck at a location $Y$ meters from their origin. They walk from $x=0$ to $x=Y$ together. At any time, one of the two may pull out their gun and shoot at the duck, however, the probability that person A hits is $P_{A}(x)$ and the probability that person B hits is $P_{B}(x)$. It is also known that $P_A(0)=P_B(0)=0$ and $P_A(Y)=P_B(Y)=1$ and both functions are increasing functions. What is the optimal strategy for each player?","I am really confused about how to think about this question. It was presented as a challenge by a peer. Two people seek to kill a duck at a location $Y$ meters from their origin. They walk from $x=0$ to $x=Y$ together. At any time, one of the two may pull out their gun and shoot at the duck, however, the probability that person A hits is $P_{A}(x)$ and the probability that person B hits is $P_{B}(x)$. It is also known that $P_A(0)=P_B(0)=0$ and $P_A(Y)=P_B(Y)=1$ and both functions are increasing functions. What is the optimal strategy for each player?",,"['probability', 'game-theory']"
10,Problem with Gambler's ruin,Problem with Gambler's ruin,,"Consider a gambler who has $k$ coins when he enters a casino. The gambler plays a game in which he wins $1$ coin if he wins a round and loses $1$ coin if he loses a round. He wins a round with probability $\displaystyle \frac{1}{2}$ and loses a round with probability $\displaystyle \frac{1}{2}$ . The gambler is considered to win the game if he ends with $n$ coins ( $n \gt k$ ) at some point of time and is considered to lose a game if he ends with $0$ coins. What is the probability that the gambler wins the game on the $m^{th}$ round(where $m\gt n-k$ and $m=n-k+2r $ for some $r\in\Bbb{N}$ ) such that he does not end with $0$ coins or $n$ coins in any of the earlier $m-1$ rounds. $\color{green}{\text{My try:}}$ Due to a lot of restrictions on the parameters and the event, I tried to work out the problems for some small values of $n,m,k$ to get an idea on how the probability might be. On obtaining some sequences of numbers I tried searching the sequence on OEIS to get an idea over the explicit form for the probability. But even after trying a lot of values for $n,m,k$ I couldn't conjecture an explicit form for the probability. If we denote the probability that the gambler wins in the $m^{th} $ round by $p_m$ then I could only conjecture that $$p_m=\displaystyle f_{n,k,m} \left(\frac{1}{2}\right)^{m}$$ For some natural numbers $f_{n,k,m}$ which depend on the values of $n,k,m$ . It is quite easily noticeable that $$f_{n,k,n-k}=1$$ but other than this I couldn't find a general pattern for the $f_{n,k,m}$ 's. Any help would be greatly appreciated. Also if it would be possible to create a generating function for $f_{n,k,m}$ then that generating function would also suffice to solve the problem ( I tried to form a generating function for the $f_{n,k,m}$ 's but failed miserably). * Edit * Some values I tried are (""assuming I have counted them correctly""): $$f_{6,2,4}=f_{6,3,3}=f_{5,2,3}=f_{6,4,2}=f_{5,1,4}=1$$ $$f_{6,2,6}=4$$ $$f_{6,2,8}=13$$ $$f_{6,3,5}=3$$ $$f_{6,3,7}=9$$ $$f_{6,3,9}=27$$ $$f_{5,2,5}=3$$ $$f_{5,2,7}=8$$ $$f_{5,2,9}=21$$ $$f_{5,2,11}=55$$ $$f_{6,4,4}=2$$ $$f_{6,4,6}=5$$ $$f_{6,4,8}=14$$ $$f_{5,1,6}=3$$ $$f_{5,1,8}=8$$ $$f_{5,1,10}=21$$ $$f_{5,1,12}=55$$","Consider a gambler who has coins when he enters a casino. The gambler plays a game in which he wins coin if he wins a round and loses coin if he loses a round. He wins a round with probability and loses a round with probability . The gambler is considered to win the game if he ends with coins ( ) at some point of time and is considered to lose a game if he ends with coins. What is the probability that the gambler wins the game on the round(where and for some ) such that he does not end with coins or coins in any of the earlier rounds. Due to a lot of restrictions on the parameters and the event, I tried to work out the problems for some small values of to get an idea on how the probability might be. On obtaining some sequences of numbers I tried searching the sequence on OEIS to get an idea over the explicit form for the probability. But even after trying a lot of values for I couldn't conjecture an explicit form for the probability. If we denote the probability that the gambler wins in the round by then I could only conjecture that For some natural numbers which depend on the values of . It is quite easily noticeable that but other than this I couldn't find a general pattern for the 's. Any help would be greatly appreciated. Also if it would be possible to create a generating function for then that generating function would also suffice to solve the problem ( I tried to form a generating function for the 's but failed miserably). * Edit * Some values I tried are (""assuming I have counted them correctly""):","k 1 1 \displaystyle \frac{1}{2} \displaystyle \frac{1}{2} n n \gt k 0 m^{th} m\gt n-k m=n-k+2r  r\in\Bbb{N} 0 n m-1 \color{green}{\text{My try:}} n,m,k n,m,k m^{th}  p_m p_m=\displaystyle f_{n,k,m} \left(\frac{1}{2}\right)^{m} f_{n,k,m} n,k,m f_{n,k,n-k}=1 f_{n,k,m} f_{n,k,m} f_{n,k,m} f_{6,2,4}=f_{6,3,3}=f_{5,2,3}=f_{6,4,2}=f_{5,1,4}=1 f_{6,2,6}=4 f_{6,2,8}=13 f_{6,3,5}=3 f_{6,3,7}=9 f_{6,3,9}=27 f_{5,2,5}=3 f_{5,2,7}=8 f_{5,2,9}=21 f_{5,2,11}=55 f_{6,4,4}=2 f_{6,4,6}=5 f_{6,4,8}=14 f_{5,1,6}=3 f_{5,1,8}=8 f_{5,1,10}=21 f_{5,1,12}=55","['probability', 'combinatorics', 'probability-theory', 'markov-chains', 'random-walk']"
11,"Do you ""sample"" a random number generator? If not, what's the correct word?","Do you ""sample"" a random number generator? If not, what's the correct word?",,"This is basically an English language question, but since it pertains to mathematics and programming quite directly, I'll post it here. Let $D$ denote a random number generator. More precisely, assume that $D$ is a probability measure on the real line. Maybe it's the standard normal distribution or something. Imagine we've implemented $D$ on a computer, and we decide to ""sample"" it 10 times and put the values thereby obtained the variables $x_0,\ldots,x_9$. Question. What's the correct word for what I'm refer to as ""sampling""?","This is basically an English language question, but since it pertains to mathematics and programming quite directly, I'll post it here. Let $D$ denote a random number generator. More precisely, assume that $D$ is a probability measure on the real line. Maybe it's the standard normal distribution or something. Imagine we've implemented $D$ on a computer, and we decide to ""sample"" it 10 times and put the values thereby obtained the variables $x_0,\ldots,x_9$. Question. What's the correct word for what I'm refer to as ""sampling""?",,"['probability', 'terminology', 'computer-science']"
12,Borel $\sigma$-Algebra definition.,Borel -Algebra definition.,\sigma,"Definition : The Borel $\sigma$ -algebra on $\mathbb R$ is the $\sigma$ -algebra B( $\mathbb R$ ) generated by the $\pi$ -system $\mathcal J$ of intervals $\ (a, b]$ , where $\ a<b$ in $\mathbb R$ (We also allow the possibility that $\ a=-\infty\ or \ b=\infty$ ) Its elements are called Borel sets . For A $\in$ B( $\mathbb R$ ), the $\sigma$ -algebra $$B(A)= \{B \subseteq A: B \in B(\mathbb R)\}$$ of Borel subsets of A is termed the Borel $\sigma$ -algebra on A. I struggle with this part especially ""generated by the $\pi$ -system $\mathcal J$ of intervals (a, b]"" In addition could someone please provide an example of a Borel set, preferably some numerical interval :) Also is $\mathbb R$ the type of numbers that the $\sigma$ -algebra  is acting on?","Definition : The Borel -algebra on is the -algebra B( ) generated by the -system of intervals , where in (We also allow the possibility that ) Its elements are called Borel sets . For A B( ), the -algebra of Borel subsets of A is termed the Borel -algebra on A. I struggle with this part especially ""generated by the -system of intervals (a, b]"" In addition could someone please provide an example of a Borel set, preferably some numerical interval :) Also is the type of numbers that the -algebra  is acting on?","\sigma \mathbb R \sigma \mathbb R \pi \mathcal J \ (a, b] \ a<b \mathbb R \ a=-\infty\ or \ b=\infty \in \mathbb R \sigma B(A)= \{B \subseteq A: B \in B(\mathbb R)\} \sigma \pi \mathcal J \mathbb R \sigma","['probability', 'measure-theory', 'probability-theory']"
13,"$P(X^2+Y^2<1)$ of two independent n(0,1) random variables","of two independent n(0,1) random variables",P(X^2+Y^2<1),"Suppose that X and Y are independent n(0,1) random variables. a) Find $P(X^2+Y^2<1)$ Attempt: a) Let $U = X^2 + Y^2$, $V = Y$. Then $X = \sqrt{V^2 -U}$, $Y = V$. $J  = \left| \begin{array}{ccc} \frac{-1}{\sqrt{V^2-U}} & \frac{V}{V^2-U} \\ 0 & 1\\ \end{array} \right| $ Then the joint distribution of $f_{u,v}(u,v)$ is: $$f_{u,v}(u,v)= \frac{1}{2\pi}e^{\frac{-\sqrt{v^2-u}}{2}}e^{\frac{-u^2}{2}}\frac{1}{\sqrt{v^2-u}}$$ Then $P(X^2 +Y^2 <1)$ is: $$\int_0^\infty \int_0^{v^2-u} \frac{1}{2\pi}e^{\frac{-\sqrt{v^2-u}}{2}}e^{\frac{-u^2}{2}}\frac{1}{\sqrt{v^2-u}}dudv$$ However, at this point I simply do not know how any tricks to complete this integration.","Suppose that X and Y are independent n(0,1) random variables. a) Find $P(X^2+Y^2<1)$ Attempt: a) Let $U = X^2 + Y^2$, $V = Y$. Then $X = \sqrt{V^2 -U}$, $Y = V$. $J  = \left| \begin{array}{ccc} \frac{-1}{\sqrt{V^2-U}} & \frac{V}{V^2-U} \\ 0 & 1\\ \end{array} \right| $ Then the joint distribution of $f_{u,v}(u,v)$ is: $$f_{u,v}(u,v)= \frac{1}{2\pi}e^{\frac{-\sqrt{v^2-u}}{2}}e^{\frac{-u^2}{2}}\frac{1}{\sqrt{v^2-u}}$$ Then $P(X^2 +Y^2 <1)$ is: $$\int_0^\infty \int_0^{v^2-u} \frac{1}{2\pi}e^{\frac{-\sqrt{v^2-u}}{2}}e^{\frac{-u^2}{2}}\frac{1}{\sqrt{v^2-u}}dudv$$ However, at this point I simply do not know how any tricks to complete this integration.",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution']"
14,Calculate the probability of an event occurring AT LEAST x times over n trials?,Calculate the probability of an event occurring AT LEAST x times over n trials?,,"Forgive me if this is simple, but I've been twisting around this problem for a bit. I know how to calculate if a given event happens exactly $x$ times over $n$ trials (where $p$ is the probability of the event occurring during a single trial): $$p^x (1-p)^{n-x}$$ It seems like I could get the result of it occurring at least $x$ times by doing a sum... $$\sum_{q=0}^{n-x} p^{x+q}  (1-p)^{n-(x+q)}$$ ... But I'm assuming there's a simpler way, mathematically, to go about calculating this.  Can anyone enlighten me?","Forgive me if this is simple, but I've been twisting around this problem for a bit. I know how to calculate if a given event happens exactly $x$ times over $n$ trials (where $p$ is the probability of the event occurring during a single trial): $$p^x (1-p)^{n-x}$$ It seems like I could get the result of it occurring at least $x$ times by doing a sum... $$\sum_{q=0}^{n-x} p^{x+q}  (1-p)^{n-(x+q)}$$ ... But I'm assuming there's a simpler way, mathematically, to go about calculating this.  Can anyone enlighten me?",,"['probability', 'statistics']"
15,"Are any linear combination of normal random variables, normally distributed?","Are any linear combination of normal random variables, normally distributed?",,"It is easy to show that if we have n independent normally distributed random variables, then a linear combination fo them ar normally distributed. It is also said that if (x1,x2,..,xn) is multivariate normally distributed, but not nececarrily independent, then any linear combination is also normally distributed. This is stated here: http://en.wikipedia.org/wiki/Multivariate_normal_distribution#Definition But does this mean that any linear combination of normally distributed random variables are normally distributed, even if they are not independent? This will follow from the definition if the joint distribution of set of normally distributed random variables(not nececarrily independent) are jointly multivarite distributed?","It is easy to show that if we have n independent normally distributed random variables, then a linear combination fo them ar normally distributed. It is also said that if (x1,x2,..,xn) is multivariate normally distributed, but not nececarrily independent, then any linear combination is also normally distributed. This is stated here: http://en.wikipedia.org/wiki/Multivariate_normal_distribution#Definition But does this mean that any linear combination of normally distributed random variables are normally distributed, even if they are not independent? This will follow from the definition if the joint distribution of set of normally distributed random variables(not nececarrily independent) are jointly multivarite distributed?",,"['probability', 'statistics', 'probability-theory', 'random-variables', 'normal-distribution']"
16,Probability that the last ball is white?,Probability that the last ball is white?,,"A jar contains $m=90$ white balls and $n=10$ red balls, the balls are drawn under the following constraints: the ball is thrown away if it is white; the ball is put back if it is red and another ball is drawn; this time, the ball is thrown away no matter what color it is. The question is, what is the probability to exhaust all balls and have the last one in white color? My guess is $\frac{1}{2}$ but I might be wrong. Please show how you deduce the answer. Thanks! EDIT: Thanks for posting the solution and simulation, which are all appreciated. B. E. Oakley and R. L. Perry discussed a very similar problem in their A Sampling Process paper published on The Mathematical Gazette, Vol. 49, No. 367 (Feb., 1965), pp. 42-44 . The problem presented in the paper is: A bag contains m > 0 black balls and n > 0 white balls. A sequence of balls from the bag is discarded in the following manner: (i) A ball is chosen at random and discarded. (ii) Another ball is chosen at random from the remainder. If its colour is different from the last it is replaced in the bag and the process repeated from the beginning (i.e. (i)). If the second ball is the same colour as the first it is discarded and we proceed from (ii). Thus the balls are sampled and discarded until a change in colour occurs, at which point the last ball is replaced and the process starts afresh. The question is: what is the probability that the final ball should be black? Their induction gives $\frac{1}{2}$ which is what I have here. Apparently having no constraint on colors like what's in the paper changes the situation significantly. But the story hasn't ended. At the end of their paper, they proposed a seemingly more interesting problem: What is the solution if there are balls of 3 different colours and the sampling process is as before?","A jar contains $m=90$ white balls and $n=10$ red balls, the balls are drawn under the following constraints: the ball is thrown away if it is white; the ball is put back if it is red and another ball is drawn; this time, the ball is thrown away no matter what color it is. The question is, what is the probability to exhaust all balls and have the last one in white color? My guess is $\frac{1}{2}$ but I might be wrong. Please show how you deduce the answer. Thanks! EDIT: Thanks for posting the solution and simulation, which are all appreciated. B. E. Oakley and R. L. Perry discussed a very similar problem in their A Sampling Process paper published on The Mathematical Gazette, Vol. 49, No. 367 (Feb., 1965), pp. 42-44 . The problem presented in the paper is: A bag contains m > 0 black balls and n > 0 white balls. A sequence of balls from the bag is discarded in the following manner: (i) A ball is chosen at random and discarded. (ii) Another ball is chosen at random from the remainder. If its colour is different from the last it is replaced in the bag and the process repeated from the beginning (i.e. (i)). If the second ball is the same colour as the first it is discarded and we proceed from (ii). Thus the balls are sampled and discarded until a change in colour occurs, at which point the last ball is replaced and the process starts afresh. The question is: what is the probability that the final ball should be black? Their induction gives $\frac{1}{2}$ which is what I have here. Apparently having no constraint on colors like what's in the paper changes the situation significantly. But the story hasn't ended. At the end of their paper, they proposed a seemingly more interesting problem: What is the solution if there are balls of 3 different colours and the sampling process is as before?",,['probability']
17,"X,Y ~ Unif(0,1) not necessarily independent, can P(X+Y>1)>1/2?","X,Y ~ Unif(0,1) not necessarily independent, can P(X+Y>1)>1/2?",,"My set up is the following: $X,Y \sim \text{Unif}(0,1)$ but their joint distribution is not constrained. My question is whether there exists a joint dependence between them (that preserves the marginals) such that $\operatorname{Prob}(X+Y>1)>1/2$ . I can show it is = 1/2 for independence (via integrating the joint PDF), but am wondering whether there is a simple argument or counterexample either way for the cases where the joint distribution is not constrained. I have tried conditioning on one of the variables but couldn't make progress. All the simiulation evidence I have suggests it is = 1/2 for a variety of dependencies. Thanks!","My set up is the following: but their joint distribution is not constrained. My question is whether there exists a joint dependence between them (that preserves the marginals) such that . I can show it is = 1/2 for independence (via integrating the joint PDF), but am wondering whether there is a simple argument or counterexample either way for the cases where the joint distribution is not constrained. I have tried conditioning on one of the variables but couldn't make progress. All the simiulation evidence I have suggests it is = 1/2 for a variety of dependencies. Thanks!","X,Y \sim \text{Unif}(0,1) \operatorname{Prob}(X+Y>1)>1/2","['probability', 'random-variables', 'uniform-distribution']"
18,Combination notation vs. Binomial Coefficient Formula,Combination notation vs. Binomial Coefficient Formula,,"I'm studying probability and statistics and had a question regarding notation. I noticed that combinations and the binomial coefficient are essentially the same thing, that is: $$\binom{n}{k}\ =\ _nC_k\ =\ \frac{n!}{(n-k)!k!}$$ But I was wondering, is there a particular difference between the two that people should be aware of? For example, are there certain use cases where one is preferred over the other? Thank you.","I'm studying probability and statistics and had a question regarding notation. I noticed that combinations and the binomial coefficient are essentially the same thing, that is: $$\binom{n}{k}\ =\ _nC_k\ =\ \frac{n!}{(n-k)!k!}$$ But I was wondering, is there a particular difference between the two that people should be aware of? For example, are there certain use cases where one is preferred over the other? Thank you.",,"['probability', 'statistics', 'binomial-coefficients', 'combinations']"
19,What is the expected number of flips of an unfair coin until you have 2 more heads than tails?,What is the expected number of flips of an unfair coin until you have 2 more heads than tails?,,"$p$ is the probability of heads. Note if $p \le 0.5$, the answer is infinity, so assume $p > 0.5$. What is the expected number of flips of the coin where we have 2 more heads than tails? Note you would stop flipping the coin when you first encounter the situation where you have 2 more heads than tails.","$p$ is the probability of heads. Note if $p \le 0.5$, the answer is infinity, so assume $p > 0.5$. What is the expected number of flips of the coin where we have 2 more heads than tails? Note you would stop flipping the coin when you first encounter the situation where you have 2 more heads than tails.",,"['probability', 'combinatorics']"
20,The birthday paradox [duplicate],The birthday paradox [duplicate],,"This question already has answers here : Explain the Birthday Paradox (4 answers) Closed 8 years ago . I would like a better understanding of the famous birthday paradox.  ""What is the probability that, in a set of n randomly chosen people, some pair of them will have the same birthday?"" I understood the first part, where the probability reaches 100% when the number of people reaches 367 by the pigeonhole principle. But I am not understanding the explanation beyond that. How do they say that the probability is 99.9% with 70 people and 50% with 23 people? And how do you further generalize the answer? And why is it a ""paradox""?","This question already has answers here : Explain the Birthday Paradox (4 answers) Closed 8 years ago . I would like a better understanding of the famous birthday paradox.  ""What is the probability that, in a set of n randomly chosen people, some pair of them will have the same birthday?"" I understood the first part, where the probability reaches 100% when the number of people reaches 367 by the pigeonhole principle. But I am not understanding the explanation beyond that. How do they say that the probability is 99.9% with 70 people and 50% with 23 people? And how do you further generalize the answer? And why is it a ""paradox""?",,"['probability', 'statistics', 'birthday']"
21,Probability of an event occuring at least once in 50 tries,Probability of an event occuring at least once in 50 tries,,"Probability of an event is $.116$. In $50$ tries, what are the chances at least one event occurs? I see that the probability that it wouldn't happen in one try is $.884$ and the probability that it wouldn't happen in two tries is $(.884)^2$.","Probability of an event is $.116$. In $50$ tries, what are the chances at least one event occurs? I see that the probability that it wouldn't happen in one try is $.884$ and the probability that it wouldn't happen in two tries is $(.884)^2$.",,['probability']
22,Expected value of the minimum of a non-negative random variable and a constant,Expected value of the minimum of a non-negative random variable and a constant,,"X is a non-negative random variable. Define Y = MIN(X, c) where c is a constant. What is E[Y]? I am modeling the constant as another random variable whose pdf is Dirac Delta function: $f_{c}(x) := \delta(x-c)$ . The mean and variance of this ""constant random variable""(!) comes out as $c$ and $0$ , but does this approach have enough mathematical rigor?","X is a non-negative random variable. Define Y = MIN(X, c) where c is a constant. What is E[Y]? I am modeling the constant as another random variable whose pdf is Dirac Delta function: . The mean and variance of this ""constant random variable""(!) comes out as and , but does this approach have enough mathematical rigor?",f_{c}(x) := \delta(x-c) c 0,"['probability', 'random-variables']"
23,What is the probability that no letter is in its proper envelope?,What is the probability that no letter is in its proper envelope?,,Five letters are addressed to five different persons and the corresponding envelopes are prepared. The letters are put into the envelopes at random. What is the probability that no letter is in its proper envelope?,Five letters are addressed to five different persons and the corresponding envelopes are prepared. The letters are put into the envelopes at random. What is the probability that no letter is in its proper envelope?,,"['probability', 'derangements']"
24,Probability of rolling three dice without getting a 6,Probability of rolling three dice without getting a 6,,I am having trouble understanding how you get $91/216$ as the answer to this question. say a die is rolled three times what is the probability that at least one roll is 6?,I am having trouble understanding how you get $91/216$ as the answer to this question. say a die is rolled three times what is the probability that at least one roll is 6?,,"['probability', 'combinatorics', 'dice']"
25,Derive the expected value for a Pareto distribution?,Derive the expected value for a Pareto distribution?,,"X is a random value that is Pareto distributed with parameter $a>0$, if $\Pr(X>x)=x^{-a}$ for all $x≥1$. Show that $EX=a/(a-1)$  if $a>1$ and $E(X)=∞$ if $0< a \le1$. I can derive the latter using the fact that the expected value is the integral between $0$ and $\infty$ of $\Pr(X>x)$ but I'm not sure how to go about showing the first case (i.e. when $a>1$)? Any help would be appreciated.","X is a random value that is Pareto distributed with parameter $a>0$, if $\Pr(X>x)=x^{-a}$ for all $x≥1$. Show that $EX=a/(a-1)$  if $a>1$ and $E(X)=∞$ if $0< a \le1$. I can derive the latter using the fact that the expected value is the integral between $0$ and $\infty$ of $\Pr(X>x)$ but I'm not sure how to go about showing the first case (i.e. when $a>1$)? Any help would be appreciated.",,"['probability', 'probability-distributions']"
26,Ratio of Boys and Girls,Ratio of Boys and Girls,,"In a country where everyone wants a boy, each family continues having babies till they have a boy. After some time, what is the proportion of boys to girls in the country? (Assuming probability of having a boy or a girl is the same)","In a country where everyone wants a boy, each family continues having babies till they have a boy. After some time, what is the proportion of boys to girls in the country? (Assuming probability of having a boy or a girl is the same)",,['probability']
27,Understanding counting using multinomial coefficients,Understanding counting using multinomial coefficients,,"I'm studying Chapter 1 of Ross A First Course in Probability Theory (8th Edition) and I'm grappling with multinomial coefficients. All given examples come from this chapter. Specifically $${n \choose n_1 ... n_r}=\frac{n!}{n_1! ... n_r!}$$ gives the number of ways to choose groups of objects of sizes $n_1, ..., n_r$ where $\sum_{i=1}^{i=r} n_i = n$ . Then we have the following 3 examples: 10 officers are to be divided as follows. 5 on patrol, 2 at the station and 3 in reserve. In how many ways can this be done? The answer is of course $$\frac{10!}{5!2!3!}$$ 10 kids are to be divided into two teams A and B of size 5 each where each team will play in a separate division. In how many ways can this be done? Again, the answer is similar to what we'd expect $$\frac{10!}{5!5!}$$ 10 kids divide themselves up into two teams of 5 to play basketball at the playground. In how many ways can this be done. This is where my confusion begins . The example says the answer is $$(\frac{10!}{5!5!})/2!$$ because even though this looks like the previous problem, it is different since the order doesn't matter here. Firstly, it looks exactly the same. I do not see why order matters in EITHER of examples # $2$ and # $3$ . Secondly, example # $1$ looks exactly like the situation of example # $2$ except with $3$ groups instead of $2$ so, if order mattered in example # $2$ , then it should have mattered in example # $1$ , no?. So, my question : What am I missing here? Any feedback is much appreciated.","I'm studying Chapter 1 of Ross A First Course in Probability Theory (8th Edition) and I'm grappling with multinomial coefficients. All given examples come from this chapter. Specifically gives the number of ways to choose groups of objects of sizes where . Then we have the following 3 examples: 10 officers are to be divided as follows. 5 on patrol, 2 at the station and 3 in reserve. In how many ways can this be done? The answer is of course 10 kids are to be divided into two teams A and B of size 5 each where each team will play in a separate division. In how many ways can this be done? Again, the answer is similar to what we'd expect 10 kids divide themselves up into two teams of 5 to play basketball at the playground. In how many ways can this be done. This is where my confusion begins . The example says the answer is because even though this looks like the previous problem, it is different since the order doesn't matter here. Firstly, it looks exactly the same. I do not see why order matters in EITHER of examples # and # . Secondly, example # looks exactly like the situation of example # except with groups instead of so, if order mattered in example # , then it should have mattered in example # , no?. So, my question : What am I missing here? Any feedback is much appreciated.","{n \choose n_1 ... n_r}=\frac{n!}{n_1! ... n_r!} n_1, ..., n_r \sum_{i=1}^{i=r} n_i = n \frac{10!}{5!2!3!} \frac{10!}{5!5!} (\frac{10!}{5!5!})/2! 2 3 1 2 3 2 2 1","['probability', 'combinatorics', 'multinomial-coefficients']"
28,How many ways can you arrange nothing?,How many ways can you arrange nothing?,,"I have heard that you can arrange nothing in only $~0! = 1$ way. That is, leave it like that, nothing. Is that reasoning correct? I want to understand why there's one way to arrange nothing when there's nothing to be arranged in the first place. You can't arrange something that doesn't exist, right? I hope you help me understand this concept.","I have heard that you can arrange nothing in only way. That is, leave it like that, nothing. Is that reasoning correct? I want to understand why there's one way to arrange nothing when there's nothing to be arranged in the first place. You can't arrange something that doesn't exist, right? I hope you help me understand this concept.",~0! = 1,"['probability', 'combinatorics', 'probability-theory']"
29,Expectation of product of independent random variables,Expectation of product of independent random variables,,"I'm stuck trying to show $E(XY) = E(X)E(Y)$ for $X, Y$ nonnegative bounded independent random variables on a probability space. The definition of independence is that $P(\{ X \in B\} \cap \{ Y \in C\}) = P(X \in B) P(Y \in C)$ for Borel sets $B$ and $C$. I'm not assuming $X$ or $Y$ have probability density functions so I cannot use them. Nor can I use conditional expectation.","I'm stuck trying to show $E(XY) = E(X)E(Y)$ for $X, Y$ nonnegative bounded independent random variables on a probability space. The definition of independence is that $P(\{ X \in B\} \cap \{ Y \in C\}) = P(X \in B) P(Y \in C)$ for Borel sets $B$ and $C$. I'm not assuming $X$ or $Y$ have probability density functions so I cannot use them. Nor can I use conditional expectation.",,"['probability', 'probability-distributions', 'random-variables', 'expectation']"
30,Mean of squared $ L_2 $ norm of Gaussian random vector,Mean of squared  norm of Gaussian random vector, L_2 ,"In my studies of probability, I have recently came across the following task: Let us assume we have an $N$ dimensional Gaussian random vector $ X $ with zero mean and known (not necessarily diagonal) covariance matrix $ \Sigma $. I am interested in the mean of the following random variable $ \lvert \lvert X \rvert \rvert _2 ^2 $. In simple words, is there an expression for the mean of the squared $ L_2 $ norm of an $ N $ dimensional Gaussian random vector with general covariance matrix? I certainly appreciate all help on this.","In my studies of probability, I have recently came across the following task: Let us assume we have an $N$ dimensional Gaussian random vector $ X $ with zero mean and known (not necessarily diagonal) covariance matrix $ \Sigma $. I am interested in the mean of the following random variable $ \lvert \lvert X \rvert \rvert _2 ^2 $. In simple words, is there an expression for the mean of the squared $ L_2 $ norm of an $ N $ dimensional Gaussian random vector with general covariance matrix? I certainly appreciate all help on this.",,"['probability', 'probability-theory', 'normal-distribution', 'normed-spaces']"
31,notation for two random variables with the same distribution,notation for two random variables with the same distribution,,"Suppose $X$ and $Y$ have the same distribution, can I write $X \sim Y$ or is there some other notation for this? Using tilde feels a bit strange since usually you have $X \sim N(0, 1)$.","Suppose $X$ and $Y$ have the same distribution, can I write $X \sim Y$ or is there some other notation for this? Using tilde feels a bit strange since usually you have $X \sim N(0, 1)$.",,"['probability', 'notation']"
32,Events $A_n\uparrow A$ meaning. $A_n\downarrow A$ meaning.,Events  meaning.  meaning.,A_n\uparrow A A_n\downarrow A,i simply do not understand the arrows in this context! :\,i simply do not understand the arrows in this context! :\,,"['probability', 'measure-theory', 'probability-theory', 'notation']"
33,Calculating expected value and variance of a probability density function,Calculating expected value and variance of a probability density function,,"If I was given a probability density function: $$f(y) = \left\{\begin{array}{ll}\frac{3y^2(4-y)}{64} & \textrm{for }  0 \leq y \leq 4\\            0 & \textrm{elsewhere} \end{array}\right.$$ for expected value would that just be the following integral?  $$\int_{0}^{4} yf(y)\,\textrm{d}y$$ I do not know how I would calculate the variance though. Any tips? Thanks","If I was given a probability density function: $$f(y) = \left\{\begin{array}{ll}\frac{3y^2(4-y)}{64} & \textrm{for }  0 \leq y \leq 4\\            0 & \textrm{elsewhere} \end{array}\right.$$ for expected value would that just be the following integral?  $$\int_{0}^{4} yf(y)\,\textrm{d}y$$ I do not know how I would calculate the variance though. Any tips? Thanks",,['probability']
34,Infinite Sum of Normals,Infinite Sum of Normals,,"If we sum a finite number of Normals, $\displaystyle \sum^n_{k=1} X_k \sim N(\sum^n_{k=1}\mu_k,\sum^n_{k=1}\sigma_k^2)$. Is this valid when we do an infinite sum, as long as $\sum^\infty_{k=1}\mu_k \text{ and }\sum^\infty_{k=1}\sigma_k^2$ converge, or do we need some extra conditions? Many thanks.","If we sum a finite number of Normals, $\displaystyle \sum^n_{k=1} X_k \sim N(\sum^n_{k=1}\mu_k,\sum^n_{k=1}\sigma_k^2)$. Is this valid when we do an infinite sum, as long as $\sum^\infty_{k=1}\mu_k \text{ and }\sum^\infty_{k=1}\sigma_k^2$ converge, or do we need some extra conditions? Many thanks.",,"['probability', 'probability-theory', 'probability-distributions']"
35,"3 trams are coming every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come?","3 trams are coming every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come?",,"3 trams are coming to the stop every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come? It's a practical problem, not some kind of a riddle for which I have a surprising magic trick or an answer. I really don't know. I was waiting for a tram when this question come to my mind. So, if you ask me for example ""how the trams are driving?"" my answer will be I don't know, I have the same (or lesser) tram knowledge as you. Assume some accurate (probably probabilistic;) model and present the answer, for example ""5 minutes"" + showing how you obtain this result. Perfect answer will generalize the problem, answering how long do we have to wait when the trams come every $x_1, x_2, x_3...$ minutes. But even the basic problem is not as easy as it is looking, so feel warned.","3 trams are coming to the stop every 10, 15 and 15 minutes. On average, how long do I have to wait for any tram to come? It's a practical problem, not some kind of a riddle for which I have a surprising magic trick or an answer. I really don't know. I was waiting for a tram when this question come to my mind. So, if you ask me for example ""how the trams are driving?"" my answer will be I don't know, I have the same (or lesser) tram knowledge as you. Assume some accurate (probably probabilistic;) model and present the answer, for example ""5 minutes"" + showing how you obtain this result. Perfect answer will generalize the problem, answering how long do we have to wait when the trams come every $x_1, x_2, x_3...$ minutes. But even the basic problem is not as easy as it is looking, so feel warned.",,"['probability', 'puzzle', 'average']"
36,Sum of exponential random variable with different means,Sum of exponential random variable with different means,,"Suppose that $X$ and $Y$ are independent exponential random variables with pdf's $f(x)=\lambda e^{-\lambda x}$ and $f(y) = \mu e^{- \mu y}$. What is $\;P \{ X+Y <t \}$ ie what is the cdf of the sum? I know that the distribution is gamma when the parameter is the same, but I'm not sure of a closed form when the parameters are different.","Suppose that $X$ and $Y$ are independent exponential random variables with pdf's $f(x)=\lambda e^{-\lambda x}$ and $f(y) = \mu e^{- \mu y}$. What is $\;P \{ X+Y <t \}$ ie what is the cdf of the sum? I know that the distribution is gamma when the parameter is the same, but I'm not sure of a closed form when the parameters are different.",,"['probability', 'random-variables']"
37,Does adding or/and dividing a random variable by a constant change its probability distribution?,Does adding or/and dividing a random variable by a constant change its probability distribution?,,"Suppose that we have a random variable X with probability distribution $PDF_X(\mu_x,\sigma_x)$ Consider random variable $Y=\frac {X-a}b$ , I  know that mean and variance of Y would be: $$\mu_y=\frac {\mu_x-a}b, \sigma_y=\sqrt{ \frac {\sigma_x^2} {b^2}  }$$ Would X and Y have the same type of probability distribution (Of course with different mean and variance)? For example I know that if X is a Normal random variable, Y would be again a Normal random variable. Is this true for all the other probability distribution? Thank you.","Suppose that we have a random variable X with probability distribution $PDF_X(\mu_x,\sigma_x)$ Consider random variable $Y=\frac {X-a}b$ , I  know that mean and variance of Y would be: $$\mu_y=\frac {\mu_x-a}b, \sigma_y=\sqrt{ \frac {\sigma_x^2} {b^2}  }$$ Would X and Y have the same type of probability distribution (Of course with different mean and variance)? For example I know that if X is a Normal random variable, Y would be again a Normal random variable. Is this true for all the other probability distribution? Thank you.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
38,"Given three integers in $\{0,\ldots,100\}$ which sum up to $100$. What is the probabilty that two of them are the same?",Given three integers in  which sum up to . What is the probabilty that two of them are the same?,"\{0,\ldots,100\} 100","We pick $3$ numbers (one by one) from set $\{0,1,...,100\}$. What is probabilty that two numbers are the same if sum of those $3$ numbers is $100$? My solution: Which two are the same we can pick in $\binom {3}{2}$ ways. Suggest $x_2=x_3$- we need to find compositon $x_1+x_2+x_2=100 \implies x_1+2x_2=100$ which implies that $x_1$ is even so we can divide this by $2$. Now we get $y_1+y_2=50$ , and using formula there are $$\binom{50+2-1}{2-1}=51$$ compositions. So, probability is $$\frac{51*3}{\binom{100+3-1}{3-1}}$$ Is this right answer? P.S.$\binom{100+3-1}{3-1}$ is number of compositions of 100 into 3 parts (allowing $0$)","We pick $3$ numbers (one by one) from set $\{0,1,...,100\}$. What is probabilty that two numbers are the same if sum of those $3$ numbers is $100$? My solution: Which two are the same we can pick in $\binom {3}{2}$ ways. Suggest $x_2=x_3$- we need to find compositon $x_1+x_2+x_2=100 \implies x_1+2x_2=100$ which implies that $x_1$ is even so we can divide this by $2$. Now we get $y_1+y_2=50$ , and using formula there are $$\binom{50+2-1}{2-1}=51$$ compositions. So, probability is $$\frac{51*3}{\binom{100+3-1}{3-1}}$$ Is this right answer? P.S.$\binom{100+3-1}{3-1}$ is number of compositions of 100 into 3 parts (allowing $0$)",,"['probability', 'combinatorics', 'elementary-number-theory', 'discrete-mathematics', 'solution-verification']"
39,Show that ${-n \choose i} = (-1)^i{n+i-1 \choose i} $,Show that,{-n \choose i} = (-1)^i{n+i-1 \choose i} ,Show that ${-n \choose i} = (-1)^i{n+i-1 \choose i} $. This is a homework exercise I have to make and I just cant get started on it. The problem lies with the $-n$. Using the definition I get: $${-n \choose i} = \frac{ (-n)!}{i!(-n-i)!}$$ But how do I calculate $(-n)!$ in this expression? I know the Gamma function could be used but I am sure that is not what is required from us. Does anyone know how this works? Maybe it's just a question of definitions? Thanks in advance!,Show that ${-n \choose i} = (-1)^i{n+i-1 \choose i} $. This is a homework exercise I have to make and I just cant get started on it. The problem lies with the $-n$. Using the definition I get: $${-n \choose i} = \frac{ (-n)!}{i!(-n-i)!}$$ But how do I calculate $(-n)!$ in this expression? I know the Gamma function could be used but I am sure that is not what is required from us. Does anyone know how this works? Maybe it's just a question of definitions? Thanks in advance!,,"['probability', 'combinatorics', 'binomial-coefficients']"
40,Obtain the conditional distribution of $X$ given $X^2=t$,Obtain the conditional distribution of  given,X X^2=t,"Consider the model $X \sim N(\theta, 1)$ for $\theta \in \mathbb R$ . Obtain the conditional distribution of $X$ given $X^2=t$ for $t\ge 0$ . Hint: This is a discrete distribution. Current work: $f(X=x|X^2=t)=\displaystyle \frac{f(X=x, X^2=t)}{f(X^2=t)}=\frac{f(X=x, X^2=t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{f(X=\sqrt t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{\frac{1}{\sqrt {2\pi}}e^{-(\sqrt t-\theta)^2/2}}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}$ ? But this can't be right because there's no $x$ in the answer. What does one do here?",Consider the model for . Obtain the conditional distribution of given for . Hint: This is a discrete distribution. Current work: ? But this can't be right because there's no in the answer. What does one do here?,"X \sim N(\theta, 1) \theta \in \mathbb R X X^2=t t\ge 0 f(X=x|X^2=t)=\displaystyle \frac{f(X=x, X^2=t)}{f(X^2=t)}=\frac{f(X=x, X^2=t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{f(X=\sqrt t)}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})}=\frac{\frac{1}{\sqrt {2\pi}}e^{-(\sqrt t-\theta)^2/2}}{\frac{1}{2\sqrt{2\pi t}}(e^{(\sqrt t-\theta)^2/2}+e^{(\sqrt t + \theta)^2/2})} x","['probability', 'probability-distributions', 'normal-distribution', 'conditional-probability']"
41,Exploding (a.k.a open-ended) dice pool,Exploding (a.k.a open-ended) dice pool,,"Say we role $n$ identical, fair dice, each with $d$ sides (every side comes up with the same probability $\frac{1}{d}$ ). On each die, the sides are numbered from $1$ to $d$ with no repeating number, as you would expect. So an ordinary $d$ sided die pool. Every dice in the outcome that shows a number equal or higher than the threshold number $t$ is said to show a hit. Every die that shows the maximum result of $d$ is rolled again, which we call ""exploding"". If the re-rolled dice show hits, the number of hits is added to the hit count. Dice that show the maximum after re-rolling are rolled again and their hits counted until none show a maximum result. Given the values of $$ d\ ...\ \text{Number of sides on each die}\ \ d>0 $$ $$ n\ ...\ \text{Number of dies rolled}\ \ n\ge 0$$ $$ h\ ...\ \text{Number of hits, we want the probability for}$$ $$ t\ ...\ \text{Threshold value for a die to roll a hit}\ \ 0 < t \le d$$ what is the probability to get exactly exactly $h$ hits? Lets call it: $$p^\text{exploding}(d,n,t,h) = p_{d,n,t,h}$$ Can you derive a formula for this probability? Example roll: We roll 7 six-sided dice and count those as hits that show a 5 or a 6 . In this example, $d=6$ , $n=7$ , $t=5$ . The outcome of such a roll may be 6 , 5 , 1 , 2 , 3 , 6 , 1 . That's three hits so far, but we have to roll the two sixes again (they explode). This time it's 6 , 2 . One more hit, and one more die to roll. We are at four hits at this point. The last die to be re-rolled shows 6 again, we re-roll it yet another time. On the last re-roll it shows a 4 - no more hits. That gives five hits in total and the roll is complete. So, for this roll $h=5$ . Simple case for just one die $n=1$ : If we roll only one die with the same threshold as above, so ( $d=6$ , $n=1$ , $t=5$ ), the probabilities can be easily calculated: $$ p_{6,1,5,0} = \frac{4}{6} \quad \text{(Probability for exactly 0 hits - roll 1-4 on the first roll, no explosion here)} $$ $$ p_{6,1,5,1} = \frac{1}{6} + \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 1 hit - roll either a 5 or a result of 1-4 after a 6)} $$ $$ p_{6,1,5,2} = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 2 hits - either a 6 and 5 or two sixes and 1-4)} $$ $$ p_{d,1,t,h\ge 1} = \left(\frac{1}{d}\right)^{h-1}\frac{d-t}{d}  + \left( \frac{1}{d} \right)^h \cdot \frac{t-1}{d} \quad \text{(Probability for exactly $h\ge 1$ hits - either $h-1$ maximum rolls and non-maximal success or $h$ maximum rolls and a non-success )} $$ Without Explosion: For none-exploding dice the probability would just be binomially distributed : $$ p^\text{non-exploding}_{d,n,t,h} = \binom{n}{h} \left( \frac{d-t+1}{d} \right)^h \left( 1 - \frac{d-t+1}{d} \right)^{n-h} $$ $$ E^\text{non-exploding}_{d,n,t} = n \frac{d-t+1}{d}; \qquad V^\text{non-exploding}_{d,n,t} = n \frac{(d-1)(d-t+1))}{d^2} $$ Where $E_{d,n,t}$ is the expected number of hits, and $V_{d,n,t}$ its variance. Edit1: In the mean time I found Probability of rolling $n$ successes on an open-ended/exploding dice roll . However I'm afraid, I don't fully get the answer there. E.g. the author says $s = n^k + r$ , which does not hold for his examples. Also I'm not sure how to get $s$ , $k$ and $r$ from my input values stated above (which are $d$ , $n$ , $h$ and $s$ ). Edit2: If one had the probability for $b$ successes via explosions, given that the initial role had $l$ successes prior to the explosions, one could just subtract all those probabilities for all values of $b$ from the value for the pure binomial distributions with $l$ successes and add the respective value to the pure binomial probability of $b+l$ successes. Just an idea. I suppose this should be something like a combination of geometric and binomial distribution. Edit3: I accepted Brian Tung 's excellent answer, giving the formula: $$ p^\text{exploding}_{d,n,t,h} = \frac{(t-1)^n}{d^{n+h}}              \sum_{k=0}^{\max\{h, n\}} \binom{n}{k} \binom{n+h-k-1}{h-k}              \left[ \frac{d(d-t)}{t-1} \right]^k $$ $$ E^\text{exploding}_{d,n,t} = n\frac{d+1-t}{d-1}; \qquad V^\text{exploding}_{d,n,t} = E_{d,n,t} - n\frac{(d-t)^2-1}{(d-1)^2} $$ Here is a graph from a simulation ( html ) that illustrates the whole thing:","Say we role identical, fair dice, each with sides (every side comes up with the same probability ). On each die, the sides are numbered from to with no repeating number, as you would expect. So an ordinary sided die pool. Every dice in the outcome that shows a number equal or higher than the threshold number is said to show a hit. Every die that shows the maximum result of is rolled again, which we call ""exploding"". If the re-rolled dice show hits, the number of hits is added to the hit count. Dice that show the maximum after re-rolling are rolled again and their hits counted until none show a maximum result. Given the values of what is the probability to get exactly exactly hits? Lets call it: Can you derive a formula for this probability? Example roll: We roll 7 six-sided dice and count those as hits that show a 5 or a 6 . In this example, , , . The outcome of such a roll may be 6 , 5 , 1 , 2 , 3 , 6 , 1 . That's three hits so far, but we have to roll the two sixes again (they explode). This time it's 6 , 2 . One more hit, and one more die to roll. We are at four hits at this point. The last die to be re-rolled shows 6 again, we re-roll it yet another time. On the last re-roll it shows a 4 - no more hits. That gives five hits in total and the roll is complete. So, for this roll . Simple case for just one die : If we roll only one die with the same threshold as above, so ( , , ), the probabilities can be easily calculated: Without Explosion: For none-exploding dice the probability would just be binomially distributed : Where is the expected number of hits, and its variance. Edit1: In the mean time I found Probability of rolling $n$ successes on an open-ended/exploding dice roll . However I'm afraid, I don't fully get the answer there. E.g. the author says , which does not hold for his examples. Also I'm not sure how to get , and from my input values stated above (which are , , and ). Edit2: If one had the probability for successes via explosions, given that the initial role had successes prior to the explosions, one could just subtract all those probabilities for all values of from the value for the pure binomial distributions with successes and add the respective value to the pure binomial probability of successes. Just an idea. I suppose this should be something like a combination of geometric and binomial distribution. Edit3: I accepted Brian Tung 's excellent answer, giving the formula: Here is a graph from a simulation ( html ) that illustrates the whole thing:","n d \frac{1}{d} 1 d d t d  d\ ...\ \text{Number of sides on each die}\ \ d>0   n\ ...\ \text{Number of dies rolled}\ \ n\ge 0  h\ ...\ \text{Number of hits, we want the probability for}  t\ ...\ \text{Threshold value for a die to roll a hit}\ \ 0 < t \le d h p^\text{exploding}(d,n,t,h) = p_{d,n,t,h} d=6 n=7 t=5 h=5 n=1 d=6 n=1 t=5  p_{6,1,5,0} = \frac{4}{6} \quad \text{(Probability for exactly 0 hits - roll 1-4 on the first roll, no explosion here)}   p_{6,1,5,1} = \frac{1}{6} + \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 1 hit - roll either a 5 or a result of 1-4 after a 6)}   p_{6,1,5,2} = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} \cdot \frac{4}{6} \quad \text{(Probability for exactly 2 hits - either a 6 and 5 or two sixes and 1-4)}   p_{d,1,t,h\ge 1} = \left(\frac{1}{d}\right)^{h-1}\frac{d-t}{d}  + \left( \frac{1}{d} \right)^h \cdot \frac{t-1}{d} \quad \text{(Probability for exactly h\ge 1 hits - either h-1 maximum rolls and non-maximal success or h maximum rolls and a non-success )}   p^\text{non-exploding}_{d,n,t,h} = \binom{n}{h} \left( \frac{d-t+1}{d} \right)^h \left( 1 - \frac{d-t+1}{d} \right)^{n-h}   E^\text{non-exploding}_{d,n,t} = n \frac{d-t+1}{d}; \qquad V^\text{non-exploding}_{d,n,t} = n \frac{(d-1)(d-t+1))}{d^2}  E_{d,n,t} V_{d,n,t} s = n^k + r s k r d n h s b l b l b+l  p^\text{exploding}_{d,n,t,h} = \frac{(t-1)^n}{d^{n+h}}
             \sum_{k=0}^{\max\{h, n\}} \binom{n}{k} \binom{n+h-k-1}{h-k}
             \left[ \frac{d(d-t)}{t-1} \right]^k   E^\text{exploding}_{d,n,t} = n\frac{d+1-t}{d-1}; \qquad V^\text{exploding}_{d,n,t} = E_{d,n,t} - n\frac{(d-t)^2-1}{(d-1)^2} ","['probability', 'dice']"
42,Probability of getting 3 cards in the same suit from a deck,Probability of getting 3 cards in the same suit from a deck,,"When three cards are randomly selected at a time from a standard deck   of 52 playing  cards, what is the probability that all of these three   cards are in the same suit (heart,  diamond, spade, or club)? I'm mortified to ask for help again about probability math. If you look at my profile you probably can see that I've asked several questions about probability. When I thought I can wrap my head around this kind of math, then I had this question and I knew I did not. Can you please give me some hints on this question and advice me some useful tips for learning to solve this kind of math? P/s : I already had the answer for this, but I don't know how to solve it!!!","When three cards are randomly selected at a time from a standard deck   of 52 playing  cards, what is the probability that all of these three   cards are in the same suit (heart,  diamond, spade, or club)? I'm mortified to ask for help again about probability math. If you look at my profile you probably can see that I've asked several questions about probability. When I thought I can wrap my head around this kind of math, then I had this question and I knew I did not. Can you please give me some hints on this question and advice me some useful tips for learning to solve this kind of math? P/s : I already had the answer for this, but I don't know how to solve it!!!",,"['probability', 'card-games']"
43,Mill's Inequality on normal distribution,Mill's Inequality on normal distribution,,"Given that $Z \sim N(0,1)$. Prove Mill's Inequality: $$P(|Z|>t) \leq  \sqrt{\frac{2}{\pi}}\frac{e^ {\frac{-t^2}{2}}}{t} ~\forall t > 0$$","Given that $Z \sim N(0,1)$. Prove Mill's Inequality: $$P(|Z|>t) \leq  \sqrt{\frac{2}{\pi}}\frac{e^ {\frac{-t^2}{2}}}{t} ~\forall t > 0$$",,"['probability', 'normal-distribution']"
44,Expected number of times random substring occurs inside of larger random string,Expected number of times random substring occurs inside of larger random string,,"I have a four-letter alphabet containing A, B, C, and D. What is the expected number of times a string of length $m$ occurs inside of larger random substring of length $n$, both generated from the same alphabet? I think I've got it so far for an even distribution, where each letter has a probability of $0.25$: $$(n-m)\cdot\left(\frac 1 4\right)^m$$ What if the letters are not evenly distributed? What if A and B had probabilities of $0.115$, and C and D had probabilities of $0.385$? How does that change the problem?","I have a four-letter alphabet containing A, B, C, and D. What is the expected number of times a string of length $m$ occurs inside of larger random substring of length $n$, both generated from the same alphabet? I think I've got it so far for an even distribution, where each letter has a probability of $0.25$: $$(n-m)\cdot\left(\frac 1 4\right)^m$$ What if the letters are not evenly distributed? What if A and B had probabilities of $0.115$, and C and D had probabilities of $0.385$? How does that change the problem?",,['probability']
45,Looking for intuition behind coin-flipping pattern expectation,Looking for intuition behind coin-flipping pattern expectation,,"I was discussing the following problem with my son: Suppose we start flipping a (fair) coin, and write down the sequence; for example it might come out HTTHTHHTTTTH... .  I am interested in the expected number of flips to obtain a given pattern.  For example, it takes an expected 30 flips to get HHHH .  But here's the (somewhat surprising) thing: it takes only 20 expected flips to get HTHT . The tempting intuition is to think that any pattern XXXX is equiprobable since, in batches of 4 isolated flips, this is true.  But when we are looking for embedded patterns like this, things change.  My son wanted to know why HTHT was so much more likely to occur before HHHH but I could not articulate any kind of satisfying explanation.  Can you?","I was discussing the following problem with my son: Suppose we start flipping a (fair) coin, and write down the sequence; for example it might come out HTTHTHHTTTTH... .  I am interested in the expected number of flips to obtain a given pattern.  For example, it takes an expected 30 flips to get HHHH .  But here's the (somewhat surprising) thing: it takes only 20 expected flips to get HTHT . The tempting intuition is to think that any pattern XXXX is equiprobable since, in batches of 4 isolated flips, this is true.  But when we are looking for embedded patterns like this, things change.  My son wanted to know why HTHT was so much more likely to occur before HHHH but I could not articulate any kind of satisfying explanation.  Can you?",,['probability']
46,About joint probability divided by the product of the probabilities,About joint probability divided by the product of the probabilities,,"Let $X$ and $Y$ be two events. So $P(X)$ is the probability of $X$ happens, and $P(Y)$ is the probability of $Y$ happens. So $P(X,Y)$ is probability of both $X$ and $Y$ happen. So what is the meaning of the following function: $h(X,Y)=\frac{P(X,Y)}{P(X)P(Y)}?$ I know that when $h=1$, it means $X$ and $Y$ are independent. So what is the situation when $h>1$ or $h<1$?","Let $X$ and $Y$ be two events. So $P(X)$ is the probability of $X$ happens, and $P(Y)$ is the probability of $Y$ happens. So $P(X,Y)$ is probability of both $X$ and $Y$ happen. So what is the meaning of the following function: $h(X,Y)=\frac{P(X,Y)}{P(X)P(Y)}?$ I know that when $h=1$, it means $X$ and $Y$ are independent. So what is the situation when $h>1$ or $h<1$?",,"['probability', 'statistics']"
47,Probability question on dice,Probability question on dice,,A fair die is rolled. Each time the value is noted and a running sum is maintained. What is the expected number of runs needed so that the sum is even?,A fair die is rolled. Each time the value is noted and a running sum is maintained. What is the expected number of runs needed so that the sum is even?,,['probability']
48,average number of moves needed to complete a game of FreeCell,average number of moves needed to complete a game of FreeCell,,"Sometimes finishing a game of FreeCell takes me 10 minutes, other times just one minute. I know that all but one of the FreeCell deals in windows can be won, but I'm not sure if they are random or not [yet that is irreverent]. Assume: ALL GAMES POSSIBLE. Random deal. NO Automation. IE.  The minimum number of clicks is 52, not 0. What is the average minimum number of moves necessary to complete a game of Freecell?","Sometimes finishing a game of FreeCell takes me 10 minutes, other times just one minute. I know that all but one of the FreeCell deals in windows can be won, but I'm not sure if they are random or not [yet that is irreverent]. Assume: ALL GAMES POSSIBLE. Random deal. NO Automation. IE.  The minimum number of clicks is 52, not 0. What is the average minimum number of moves necessary to complete a game of Freecell?",,"['probability', 'combinatorics', 'card-games', 'combinatorial-game-theory']"
49,Rolling a dice until the average of the outcome hits a specific value.,Rolling a dice until the average of the outcome hits a specific value.,,"I roll the dice until the average of the outcomes is $2.5$ . Once the average is $2.5$ , I will stop rolling. For example, if I get a sequence of 2, 6, 4, 1, 1, 1 outcomes, I will stop rolling the dice at the sixth trial. Let $E$ be the event of stopping rolling the dice and $E_n$ be the event of getting the average $2.5$ after rolling the dice exactly $n$ times. Then, $E = E_1 \cup E_2 \cup E_3 \cup E_4 \cup \cdots$ . Since it will not end with odd trials, I can rewrite it as $E = E_2 \cup E_4 \cup \cdots$ . Since ${E_{2n}}^\complement \supseteq \bigcup_{k=2n}^{\infty} E_{2k}$ , $E_{2k}$ 's are disjoint. Thus, $Pr(E) = \sum_{k=1}^{\infty} Pr(E_{2k})$ . However, I am stuck with calculating the exact probability of each event $E_{2k}$ for large $k$ . How can I calculate the probability of each event $E_{2k}$ ( $Pr(E_{2k})$ for $k>1$ ) and finally the probability of stopping rolling the dice $Pr(E)$ ? It seems that $Pr(E_{2k})$ goes to zero as $k\rightarrow \infty$ . Then, would the $Pr(E)<1$ ? Or, is the probability of stopping rolling the dice eventually one? Also, I wonder if there is any related theorem that I can use to calculate such events.","I roll the dice until the average of the outcomes is . Once the average is , I will stop rolling. For example, if I get a sequence of 2, 6, 4, 1, 1, 1 outcomes, I will stop rolling the dice at the sixth trial. Let be the event of stopping rolling the dice and be the event of getting the average after rolling the dice exactly times. Then, . Since it will not end with odd trials, I can rewrite it as . Since , 's are disjoint. Thus, . However, I am stuck with calculating the exact probability of each event for large . How can I calculate the probability of each event ( for ) and finally the probability of stopping rolling the dice ? It seems that goes to zero as . Then, would the ? Or, is the probability of stopping rolling the dice eventually one? Also, I wonder if there is any related theorem that I can use to calculate such events.",2.5 2.5 E E_n 2.5 n E = E_1 \cup E_2 \cup E_3 \cup E_4 \cup \cdots E = E_2 \cup E_4 \cup \cdots {E_{2n}}^\complement \supseteq \bigcup_{k=2n}^{\infty} E_{2k} E_{2k} Pr(E) = \sum_{k=1}^{\infty} Pr(E_{2k}) E_{2k} k E_{2k} Pr(E_{2k}) k>1 Pr(E) Pr(E_{2k}) k\rightarrow \infty Pr(E)<1,"['probability', 'statistics', 'dice']"
50,What is the probability that both children are boys if at least one is a boy born on a Tuesday?,What is the probability that both children are boys if at least one is a boy born on a Tuesday?,,"A family has two children. Given that at least one of the children is a boy who was born on a Tuesday, what is the probability that both children are boys? The day of birth is independent of the gender P(both are boys $\mid $ at least one boy) = P(both are boys) / P(at least one boy) $= P(\text {both are boys}) / [1 - P(\text{both are girls}$)] $= 0.5^2/(1-0.5^2)$ $= 0.25/0.75$ $= 0.3333$","A family has two children. Given that at least one of the children is a boy who was born on a Tuesday, what is the probability that both children are boys? The day of birth is independent of the gender P(both are boys $\mid $ at least one boy) = P(both are boys) / P(at least one boy) $= P(\text {both are boys}) / [1 - P(\text{both are girls}$)] $= 0.5^2/(1-0.5^2)$ $= 0.25/0.75$ $= 0.3333$",,['probability']
51,What is the probability that $\min\limits_{i}\max\limits_{j} M_{ij}\gt \max\limits_{j}\min\limits_{i} M_{ij}$,What is the probability that,\min\limits_{i}\max\limits_{j} M_{ij}\gt \max\limits_{j}\min\limits_{i} M_{ij},"Assume you have a $n\times n$ matrix $M$, each entry is filled with a number from $1$ to $n^2$ randomly, and no two entries are the same. There are $n$ rows, select the max number of each row, so there are $n$ numbers. $A$ is defined as the minimum number of these $n$ numbers. To clarify: $$ A:= \min_{i}\max_{j} M_{ij}\\ B:= \max_{j}\min_{i} M_{ij}. $$ What is $\Pr[A>B]$? Edit 1: The computer run has the following result: $$ 0.332877, 0.698953, 0.886191, 0.960409, 0.986796, 0.995996, 0.99876, 0.999604, 0.999892 $$ This is from $n=2$ to $n=10$ Edit 2: More hint: Computer check for $\Pr[A\ge B]$ $$ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 $$ Code: import numpy as np N = 1000000 ratio = [] for n in range(2,11):     count = 0     for j in range(N):         m = np.random.permutation(n**2).reshape(n,n)         a = min([max(m[i,:]) for i in range(n)])         b = max([min(m[:,i]) for i in range(n)])         if(a>b):             count += 1     ratio.append(count/N)  print(ratio)","Assume you have a $n\times n$ matrix $M$, each entry is filled with a number from $1$ to $n^2$ randomly, and no two entries are the same. There are $n$ rows, select the max number of each row, so there are $n$ numbers. $A$ is defined as the minimum number of these $n$ numbers. To clarify: $$ A:= \min_{i}\max_{j} M_{ij}\\ B:= \max_{j}\min_{i} M_{ij}. $$ What is $\Pr[A>B]$? Edit 1: The computer run has the following result: $$ 0.332877, 0.698953, 0.886191, 0.960409, 0.986796, 0.995996, 0.99876, 0.999604, 0.999892 $$ This is from $n=2$ to $n=10$ Edit 2: More hint: Computer check for $\Pr[A\ge B]$ $$ 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 $$ Code: import numpy as np N = 1000000 ratio = [] for n in range(2,11):     count = 0     for j in range(N):         m = np.random.permutation(n**2).reshape(n,n)         a = min([max(m[i,:]) for i in range(n)])         b = max([min(m[:,i]) for i in range(n)])         if(a>b):             count += 1     ratio.append(count/N)  print(ratio)",,['probability']
52,Is there an intuitive way of viewing the Law of Total Expectation $\mathbb{E}\big[\mathbb{E}[X|Y]\big]=\mathbb{E}[X]?$,Is there an intuitive way of viewing the Law of Total Expectation,\mathbb{E}\big[\mathbb{E}[X|Y]\big]=\mathbb{E}[X]?,"Law of total expectation If $\mathbb{E}\big[|X|\big]$ finite then for any $Y,\;\mathbb{E}\big[\mathbb{E}[X\mid Y]\big]=\mathbb{E}[X]$ I remember reading this for the first time and thinking... hold up, what? The proof is simple, but I am wondering whether there is an intuitive reason why we might expect this result?","Law of total expectation If finite then for any I remember reading this for the first time and thinking... hold up, what? The proof is simple, but I am wondering whether there is an intuitive reason why we might expect this result?","\mathbb{E}\big[|X|\big] Y,\;\mathbb{E}\big[\mathbb{E}[X\mid Y]\big]=\mathbb{E}[X]","['probability', 'intuition', 'expectation', 'conditional-expectation']"
53,The birthday problem when the order is not important,The birthday problem when the order is not important,,"Suppose that we are interested in the probability that in a set of $n$ randomly chosen people at least two people share the same birthday. We make the assumption that each day of the year (except February 29) is equally probable for a birthday. Such problem is called the birthday problem . It seems that there are two ways to obtain this probability: $$ p(n)=1-\frac{365\cdot364\cdot\ldots\cdot(365-n+1)}{365^n} $$ and $$ q(n)=1-{365\choose n}\biggl/{365+n-1\choose n} $$ using stars and bars . When we calculate $p(n)$, the order of people is important. However, when we calculate $q(n)$, the order is not important, we can only tell how many people have a birthday on a particular day. Usually only the probability $p(n)$ is calculated. The probability $p(n)$ is lower than the probability $q(n)$ as we see in the graph. Does it make sense to calculate probability $q(n)$? How can I intuitively understand why these probabilities are different (it might seem that the importance of order should not affect the final answer)? Which one is the right way to calculate the probability in the birthday problem? Any help is much appreciated!","Suppose that we are interested in the probability that in a set of $n$ randomly chosen people at least two people share the same birthday. We make the assumption that each day of the year (except February 29) is equally probable for a birthday. Such problem is called the birthday problem . It seems that there are two ways to obtain this probability: $$ p(n)=1-\frac{365\cdot364\cdot\ldots\cdot(365-n+1)}{365^n} $$ and $$ q(n)=1-{365\choose n}\biggl/{365+n-1\choose n} $$ using stars and bars . When we calculate $p(n)$, the order of people is important. However, when we calculate $q(n)$, the order is not important, we can only tell how many people have a birthday on a particular day. Usually only the probability $p(n)$ is calculated. The probability $p(n)$ is lower than the probability $q(n)$ as we see in the graph. Does it make sense to calculate probability $q(n)$? How can I intuitively understand why these probabilities are different (it might seem that the importance of order should not affect the final answer)? Which one is the right way to calculate the probability in the birthday problem? Any help is much appreciated!",,"['probability', 'combinatorics', 'combinations', 'birthday']"
54,Joint density problem. Two uniform distributions,Joint density problem. Two uniform distributions,,"This is the problem: An insurer estimates that Smith's time until death is uniformly distributed on the interval [0,5], and Jone's time until death also uniformly distributed on the interval [0,10]. The insurer assumes the two times of death are independent of one another. Find the probability that Smith is the first of the two to die. The solution manual first multiplies them by one another and does this: $$\int_0^{5}\int_s^{10}\frac{1}{50}\ dj\ ds$$ I don't get how this integral describes smith's time of death happening faster. They have a rectangle they drew with a shaded reason that I don't quite understand how describes this problem either. Can someone help me out here. I feel like I'm missing something obvious","This is the problem: An insurer estimates that Smith's time until death is uniformly distributed on the interval [0,5], and Jone's time until death also uniformly distributed on the interval [0,10]. The insurer assumes the two times of death are independent of one another. Find the probability that Smith is the first of the two to die. The solution manual first multiplies them by one another and does this: $$\int_0^{5}\int_s^{10}\frac{1}{50}\ dj\ ds$$ I don't get how this integral describes smith's time of death happening faster. They have a rectangle they drew with a shaded reason that I don't quite understand how describes this problem either. Can someone help me out here. I feel like I'm missing something obvious",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
55,Why does probability change as you change perspective?,Why does probability change as you change perspective?,,"I was trying to solve the following question: Out of 2 Boys and 2 Girls, two students are chosen to advance to the next level. What is the probability that two girls advance to the next level However, because the question was ambiguous I calculated the probabilities considering all four cases of whether they were distinguishable or indistinguishable, and whether order mattered or didn't matter and got different probabilities for each case. However, I want to know why this happens. All you are doing is simply picking two students and seeing if they are both girls. You keep doing this and after infinite trials, divide the number of times they were both girls by the number of total trials. How does this outcome depend upon whether you view them as distinguishable, indistinguishable, ordered, or non-ordered? Cases: Indistinguishable, order matters: $\frac{1}{2\cdot 2}=\frac{1}{4}$ (Cases are BB, BG, GB, GG) Indistinguishable, order does not matter: $\frac{1}{3}$ (Cases are BB, B+G, GG) Distinguishable, order matters: $\frac{2}{\text{Permutation}(4,2)} = \frac{1}{6}$ Distinguishable, order does not matter: $\frac{1}{\binom{4}{2}}=\frac{1}{6}$","I was trying to solve the following question: Out of 2 Boys and 2 Girls, two students are chosen to advance to the next level. What is the probability that two girls advance to the next level However, because the question was ambiguous I calculated the probabilities considering all four cases of whether they were distinguishable or indistinguishable, and whether order mattered or didn't matter and got different probabilities for each case. However, I want to know why this happens. All you are doing is simply picking two students and seeing if they are both girls. You keep doing this and after infinite trials, divide the number of times they were both girls by the number of total trials. How does this outcome depend upon whether you view them as distinguishable, indistinguishable, ordered, or non-ordered? Cases: Indistinguishable, order matters: $\frac{1}{2\cdot 2}=\frac{1}{4}$ (Cases are BB, BG, GB, GG) Indistinguishable, order does not matter: $\frac{1}{3}$ (Cases are BB, B+G, GG) Distinguishable, order matters: $\frac{2}{\text{Permutation}(4,2)} = \frac{1}{6}$ Distinguishable, order does not matter: $\frac{1}{\binom{4}{2}}=\frac{1}{6}$",,"['probability', 'soft-question']"
56,distribution of $X^2 + Y^2$,distribution of,X^2 + Y^2,"Suppose $X$ and $Y$ are independent uniform distributions between $(0,1)$. What is the distribution of $X^2 + Y^2$? I derived that the pdf of $X^2$ is $\frac{1}{2\sqrt{x}}$ for $0\leq x \leq 1$. How can I continue from here?","Suppose $X$ and $Y$ are independent uniform distributions between $(0,1)$. What is the distribution of $X^2 + Y^2$? I derived that the pdf of $X^2$ is $\frac{1}{2\sqrt{x}}$ for $0\leq x \leq 1$. How can I continue from here?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
57,Variance of number of runs of consecutive heads in $n$ biased coin flips,Variance of number of runs of consecutive heads in  biased coin flips,n,"Suppose we have a sequence of $n$ coin flips of a biased coin with probability $p$ of being heads. Let $X_n$ be the random variable that records the number of runs of consecutive heads, e.g. THHTHTHH has 3 runs of heads. By linearity of expectation, $E(X_n)$ is the sum of $n$ probabilities of getting a run of heads starting at coin flip $j$ for $1 \leq j \leq n$. For $j = 1$ this probability is $p$, and for $j > 1$ we must have flip $j-1$ is tails and flip $j$ is heads, which has probability $p(1-p)$. So $E(X_n) = p + (n-1)p(1-p)$. What about Var$(X_n)$? Is there any way to compute a formula for it? Or if not, at least get asymptotics for it?","Suppose we have a sequence of $n$ coin flips of a biased coin with probability $p$ of being heads. Let $X_n$ be the random variable that records the number of runs of consecutive heads, e.g. THHTHTHH has 3 runs of heads. By linearity of expectation, $E(X_n)$ is the sum of $n$ probabilities of getting a run of heads starting at coin flip $j$ for $1 \leq j \leq n$. For $j = 1$ this probability is $p$, and for $j > 1$ we must have flip $j-1$ is tails and flip $j$ is heads, which has probability $p(1-p)$. So $E(X_n) = p + (n-1)p(1-p)$. What about Var$(X_n)$? Is there any way to compute a formula for it? Or if not, at least get asymptotics for it?",,['probability']
58,If $X$ and $Y$ are independent. How about $X^2$ and $Y$? And how about $f(X)$ and $g(Y)$? [duplicate],If  and  are independent. How about  and ? And how about  and ? [duplicate],X Y X^2 Y f(X) g(Y),"This question already has an answer here : Are squares of independent random variables independent? (1 answer) Closed 10 years ago . If $X$ and $Y$ are independent. How about $X^2$ and $Y$? And how about $f(X)$ and $g(Y)$? I always have confusion about it. I feel ... yeah of course $f(X)$ and $g(Y)$ are independent, because $X$ and $Y$ are. But .. is it right?? Then how can I prove it?","This question already has an answer here : Are squares of independent random variables independent? (1 answer) Closed 10 years ago . If $X$ and $Y$ are independent. How about $X^2$ and $Y$? And how about $f(X)$ and $g(Y)$? I always have confusion about it. I feel ... yeah of course $f(X)$ and $g(Y)$ are independent, because $X$ and $Y$ are. But .. is it right?? Then how can I prove it?",,"['probability', 'probability-theory']"
59,How many random samples needed to pick all elements of set? [duplicate],How many random samples needed to pick all elements of set? [duplicate],,"This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . If repeatedly picking a random element from a set, what is the expected number of times I'd have to pick before seeing all the elements of the set? Edit: when picking an element, it is simply counted and not removed from the set, so it can be picked again.","This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . If repeatedly picking a random element from a set, what is the expected number of times I'd have to pick before seeing all the elements of the set? Edit: when picking an element, it is simply counted and not removed from the set, so it can be picked again.",,"['probability', 'random', 'coupon-collector']"
60,Moments and non-negative random variables?,Moments and non-negative random variables?,,"I want to prove that for non-negative random variables with distribution F: $$E(X^{n}) = \int_0^\infty n x^{n-1} P(\{X≥x\}) dx$$ Is the following proof correct? $$R.H.S = \int_0^\infty n x^{n-1} P(\{X≥x\}) dx = \int_0^\infty n x^{n-1} (1-F(x)) dx$$ using integration by parts: $$R.H.S = [x^{n}(1-F(x))]_0^\infty + \int_0^\infty x^{n} f(x) dx = 0 + \int_0^\infty x^{n} f(x) dx = E(X^{n})$$ If not correct, then how to prove it?","I want to prove that for non-negative random variables with distribution F: $$E(X^{n}) = \int_0^\infty n x^{n-1} P(\{X≥x\}) dx$$ Is the following proof correct? $$R.H.S = \int_0^\infty n x^{n-1} P(\{X≥x\}) dx = \int_0^\infty n x^{n-1} (1-F(x)) dx$$ using integration by parts: $$R.H.S = [x^{n}(1-F(x))]_0^\infty + \int_0^\infty x^{n} f(x) dx = 0 + \int_0^\infty x^{n} f(x) dx = E(X^{n})$$ If not correct, then how to prove it?",,['probability']
61,Is there a known explanation for the Feynman point?,Is there a known explanation for the Feynman point?,,"The Feynman point is a mathematical coincidence . It states that from position 762, there are six consecutive nines in the decimal expansion of pi. Some mathematical coincidences have an explanation, like Ramanujan's constant being close to an integer . Is there a known explanation for the Feynman point? Update: the ‘special thing’ about this string of six 9s is that is occurs so early. According to Wikipedia: For a normal number sampled uniformly at random, the probability of a specific sequence of six digits occurring this early in the decimal representation is about 0.08%. The early string of six 9's is also the first occurrence of four and five consecutive identical digits. If we regard the strings 000000, 111111, until 999999 ‘equally important’, then we should immediately multiply this probability by 10. As with every mathematical coincidence, it could be an ‘actual coincidence’, meaning that there is no ‘explanation’. However, maybe there is in fact an ‘explanation’. This question gives an example of a similar, but more extreme situation. In that case, there is a clear explanation.","The Feynman point is a mathematical coincidence . It states that from position 762, there are six consecutive nines in the decimal expansion of pi. Some mathematical coincidences have an explanation, like Ramanujan's constant being close to an integer . Is there a known explanation for the Feynman point? Update: the ‘special thing’ about this string of six 9s is that is occurs so early. According to Wikipedia: For a normal number sampled uniformly at random, the probability of a specific sequence of six digits occurring this early in the decimal representation is about 0.08%. The early string of six 9's is also the first occurrence of four and five consecutive identical digits. If we regard the strings 000000, 111111, until 999999 ‘equally important’, then we should immediately multiply this probability by 10. As with every mathematical coincidence, it could be an ‘actual coincidence’, meaning that there is no ‘explanation’. However, maybe there is in fact an ‘explanation’. This question gives an example of a similar, but more extreme situation. In that case, there is a clear explanation.",,"['probability', 'pi', 'decimal-expansion']"
62,"Break a stick at $n$ random points. What is the probability that the three shortest pieces can form a triangle, as $n\to\infty$?","Break a stick at  random points. What is the probability that the three shortest pieces can form a triangle, as ?",n n\to\infty,"Question : On a stick, choose $n$ uniformly random points, and break the stick at those points. What is the limit of the probability that the three shortest pieces can form a triangle, as $n\to\infty$ ? Context : I'm currently interested in questions about broken sticks. They often have nice answers . My attempt : I don't know how to find the exact probability, so I ran a simulation on Excel. For each of $n=10,n=100,n=1000$ , the probability seems to be roughly $0.45$ . So it seems that the probability quickly converges... but to what?","Question : On a stick, choose uniformly random points, and break the stick at those points. What is the limit of the probability that the three shortest pieces can form a triangle, as ? Context : I'm currently interested in questions about broken sticks. They often have nice answers . My attempt : I don't know how to find the exact probability, so I ran a simulation on Excel. For each of , the probability seems to be roughly . So it seems that the probability quickly converges... but to what?","n n\to\infty n=10,n=100,n=1000 0.45","['probability', 'limits', 'triangles', 'geometric-probability']"
63,Two artists want to paint all sand grains in 2 colors. They stop if one artist picks a grain already painted by the other. In mean how many picks?,Two artists want to paint all sand grains in 2 colors. They stop if one artist picks a grain already painted by the other. In mean how many picks?,,"Let $N$ be the (big) number of sand grains. Artist $B$ want to paint them blue. Artist $R$ want to paint them red. We start with all sand grains unpainted. They decide $B$ can start. $B$ picks a random sand grain (all always chance $\frac{1}{N}$ ) and paint it blue. After this it's $R$ turn. $R$ picks a random sand grain and paints it red (if not already blue). If an artist picks a sand grain which is: not painted yet the artists paints it with the own color and place it back afterwards. After this it's the other artist turn again. already colored in the own color the same artist will pick a new sand grain (this can repeat multiple times). already colored but not the own color the drawing session will end for both artists. (That means they do fair share. They have either the same amount of colored sand grains or $R$ has just $1$ more.) What is the expected/mean count of picks required for this experiment in relation to $N$ ? We assume $N$ can grow as big we want (but not $\infty$ ). Does it converge to a equation $f(N)$ ? The expected number of picks $n$ could be written as: $$\mathbb{E}[n,N] = \sum_{i=2}^{\infty} i\cdot p_i$$ Can we approximate it for large $N$ . Does it converge to something?",Let be the (big) number of sand grains. Artist want to paint them blue. Artist want to paint them red. We start with all sand grains unpainted. They decide can start. picks a random sand grain (all always chance ) and paint it blue. After this it's turn. picks a random sand grain and paints it red (if not already blue). If an artist picks a sand grain which is: not painted yet the artists paints it with the own color and place it back afterwards. After this it's the other artist turn again. already colored in the own color the same artist will pick a new sand grain (this can repeat multiple times). already colored but not the own color the drawing session will end for both artists. (That means they do fair share. They have either the same amount of colored sand grains or has just more.) What is the expected/mean count of picks required for this experiment in relation to ? We assume can grow as big we want (but not ). Does it converge to a equation ? The expected number of picks could be written as: Can we approximate it for large . Does it converge to something?,"N B R B B \frac{1}{N} R R R 1 N N \infty f(N) n \mathbb{E}[n,N] = \sum_{i=2}^{\infty} i\cdot p_i N","['probability', 'statistics', 'expected-value', 'card-games', 'coupon-collector']"
64,Compute $E(\sin X)$ if $X$ is normally distributed,Compute  if  is normally distributed,E(\sin X) X,If $X$ is normally distributed with mean $\mu$ and standard deviation $\sigma$ what is the expected value $E[\sin(x)]$? I think this has something to do with the characteristic function...,If $X$ is normally distributed with mean $\mu$ and standard deviation $\sigma$ what is the expected value $E[\sin(x)]$? I think this has something to do with the characteristic function...,,"['probability', 'statistics', 'normal-distribution']"
65,What is the chance of rolling a specific number after a certain amount of rolls?,What is the chance of rolling a specific number after a certain amount of rolls?,,"Say I roll a $6$ sided dice and I want to roll a $6$. what is the probability that I will have rolled the number I want after $6$ rolls? I have been using this: $\displaystyle1-\left(1-\frac{1}{x}\right)^y$ where $x$ is the number of sides and $y$ is the amount of rolls, so it would be $\displaystyle1-\left(1-\frac{1}{6}\right)^6$ for rolling a specific number in $6$ rolls, which is $\approx66.5\%$ is this the correct way of calculating the probability of something like this, if not what is the proper way? i'm not really sure why that formula works(if it does) so some elaboration on that would be nice. sorry for lack of technical language thanks in advance","Say I roll a $6$ sided dice and I want to roll a $6$. what is the probability that I will have rolled the number I want after $6$ rolls? I have been using this: $\displaystyle1-\left(1-\frac{1}{x}\right)^y$ where $x$ is the number of sides and $y$ is the amount of rolls, so it would be $\displaystyle1-\left(1-\frac{1}{6}\right)^6$ for rolling a specific number in $6$ rolls, which is $\approx66.5\%$ is this the correct way of calculating the probability of something like this, if not what is the proper way? i'm not really sure why that formula works(if it does) so some elaboration on that would be nice. sorry for lack of technical language thanks in advance",,['probability']
66,Stochastic processes book suggestions.,Stochastic processes book suggestions.,,"I would like to find a book that introduces me gently to the subject of stochastic processes without sacrificing mathematical rigor. It would be great if the book has lots of examples and that the book is designed for undergraduates. Just like how there are rigorous undergraduate abstract algebra books (I am thinking of GAllian's contemporary modern algebra here). I already studied measure theory, and prob. theory. Thank you.","I would like to find a book that introduces me gently to the subject of stochastic processes without sacrificing mathematical rigor. It would be great if the book has lots of examples and that the book is designed for undergraduates. Just like how there are rigorous undergraduate abstract algebra books (I am thinking of GAllian's contemporary modern algebra here). I already studied measure theory, and prob. theory. Thank you.",,"['probability', 'stochastic-processes', 'book-recommendation', 'advice']"
67,Probability of winning a game in tennis?,Probability of winning a game in tennis?,,"Suppose there is a tennis singles match, where Player A plays a single game against Player B. The probability that player A will win a single point is $x$, and thus $1-x$ is the probability that Player B will win a point. The scoring system in tennis goes 15, 30, 40, then game.  However a score of 40-40 is known as deuce and the winner of the next point gains an ""advantage"".  If this player wins again, he then wins the game, but if he loses the score returns to 40-40, or deuce. So given the probability player A will win a single point is $x$, what is the probabilty that player A will win the entire game?","Suppose there is a tennis singles match, where Player A plays a single game against Player B. The probability that player A will win a single point is $x$, and thus $1-x$ is the probability that Player B will win a point. The scoring system in tennis goes 15, 30, 40, then game.  However a score of 40-40 is known as deuce and the winner of the next point gains an ""advantage"".  If this player wins again, he then wins the game, but if he loses the score returns to 40-40, or deuce. So given the probability player A will win a single point is $x$, what is the probabilty that player A will win the entire game?",,['probability']
68,Deal or No Deal: Monty Hall?,Deal or No Deal: Monty Hall?,,"This question was inspired by another question posted today: Monty Hall Problem Extended . So I thought that the comments an answers brought up a great point about increasing the doors to 100 or something much larger, and using that as a way to help visualize why switching is always the best choice when trying to explain the problem to others. And then I was thinking about the game show, Deal or No Deal. For those unfamiliar with Deal or No Deal: there are 26 cases, each containing amounts of money ranging from \$0.01 to one million dollars. You choose one case, and it's ""yours"" and out-of-play (this is analogous to choosing the first door in the Monty Hall problem). Throughout the game you open 24 of the remaining cases, and you see how much money was in each case. In the end, you are left with 2 cases: ""your"" case, that you chose in the beginning, and the only other case you didn't open. This is where it becomes Monty Hall: you can either choose to keep your case, or switch cases and get the other one. So what I'm wondering is, does the Monty Hall logic of ""always switch doors/cases"" apply here? The differences: 1) It's not a case of there being simply 1 car and a bunch of goats. All the money values are different in each case. You aren't always going to end up with a choice between a million dollars or something small... The two remaining cases might end up being \$10,000 and \$250,000. Or it might be \$10 and a million dollars. Or \$10 and $100. 2) I think part of what makes Monty Hall work is that the car always remains in play. Your first choice is a 1/26 probability of selecting the car/million dollar case. But in Deal or No Deal, the car/million dollar case can be eliminated partway through the game. So I'm thinking that probably changes things. My first vague thoughts are... If you make it to the end and the million dollar case still is in play, Monty Hall applies and you should switch cases. Because it's the same idea; I had a 1/26 shot at the million. 24 have been eliminated. It's much more likely that the other case has the million. But if the million is eliminated while you're playing, what then? Can Monty Hall not help us, because you can't compare the probability of selecting the million dollar case because now it's zero? I'm trying to think of a way to figure out whether or not you should switch, in an attempt to get the case with the most money in it . We know that \$1,000,000 is no longer available. But is there anything we can do to decide which case is likely to be more valuable? Or is this outside Monty Hall's bounds?","This question was inspired by another question posted today: Monty Hall Problem Extended . So I thought that the comments an answers brought up a great point about increasing the doors to 100 or something much larger, and using that as a way to help visualize why switching is always the best choice when trying to explain the problem to others. And then I was thinking about the game show, Deal or No Deal. For those unfamiliar with Deal or No Deal: there are 26 cases, each containing amounts of money ranging from \$0.01 to one million dollars. You choose one case, and it's ""yours"" and out-of-play (this is analogous to choosing the first door in the Monty Hall problem). Throughout the game you open 24 of the remaining cases, and you see how much money was in each case. In the end, you are left with 2 cases: ""your"" case, that you chose in the beginning, and the only other case you didn't open. This is where it becomes Monty Hall: you can either choose to keep your case, or switch cases and get the other one. So what I'm wondering is, does the Monty Hall logic of ""always switch doors/cases"" apply here? The differences: 1) It's not a case of there being simply 1 car and a bunch of goats. All the money values are different in each case. You aren't always going to end up with a choice between a million dollars or something small... The two remaining cases might end up being \$10,000 and \$250,000. Or it might be \$10 and a million dollars. Or \$10 and $100. 2) I think part of what makes Monty Hall work is that the car always remains in play. Your first choice is a 1/26 probability of selecting the car/million dollar case. But in Deal or No Deal, the car/million dollar case can be eliminated partway through the game. So I'm thinking that probably changes things. My first vague thoughts are... If you make it to the end and the million dollar case still is in play, Monty Hall applies and you should switch cases. Because it's the same idea; I had a 1/26 shot at the million. 24 have been eliminated. It's much more likely that the other case has the million. But if the million is eliminated while you're playing, what then? Can Monty Hall not help us, because you can't compare the probability of selecting the million dollar case because now it's zero? I'm trying to think of a way to figure out whether or not you should switch, in an attempt to get the case with the most money in it . We know that \$1,000,000 is no longer available. But is there anything we can do to decide which case is likely to be more valuable? Or is this outside Monty Hall's bounds?",,"['probability', 'game-theory', 'monty-hall']"
69,non-exponential family probability distributions and their uses,non-exponential family probability distributions and their uses,,"I was actually trying to find information on non-exponential family probability distributions. So many of the distributions that we study in statistics are members of an exponential family of distributions. But this leads to the natural question of whether there exist sets of distributions that are not members of an exponential family? I could not find any references to these. Does anyone know of distributions that are not members of an exponential family? Also, what are the applications for these types of distributions? Where are they used? Thanks.","I was actually trying to find information on non-exponential family probability distributions. So many of the distributions that we study in statistics are members of an exponential family of distributions. But this leads to the natural question of whether there exist sets of distributions that are not members of an exponential family? I could not find any references to these. Does anyone know of distributions that are not members of an exponential family? Also, what are the applications for these types of distributions? Where are they used? Thanks.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
70,Conditional distributions of the multivariate normal,Conditional distributions of the multivariate normal,,"Wikipedia gives details on the conditional distribution of the multivariate normal: If $\mu$ and $\Sigma$ are partitioned as follows $\boldsymbol\mu = \begin{bmatrix}  \boldsymbol\mu_1 \\  \boldsymbol\mu_2 \end{bmatrix}$ $\boldsymbol\Sigma = \begin{bmatrix}  \boldsymbol\Sigma_{11} & \boldsymbol\Sigma_{12} \\  \boldsymbol\Sigma_{21} & \boldsymbol\Sigma_{22} \end{bmatrix} \quad$ then, the distribution of $x_1$ conditional on $x_2= a$ is   multivariate normal $(x_1|x_2=a) \sim N(\bar{\mu}, \bar{\Sigma})$   where $\bar{\boldsymbol\mu} = \boldsymbol\mu_1 + \boldsymbol\Sigma_{12} \boldsymbol\Sigma_{22}^{-1} \left(  \mathbf{a} - \boldsymbol\mu_2 \right) $ and covariance matrix $\overline{\boldsymbol\Sigma} = \boldsymbol\Sigma_{11} - \boldsymbol\Sigma_{12} \boldsymbol\Sigma_{22}^{-1} \boldsymbol\Sigma_{21}.  $ How can I prove this result? Wikipedia cites Eaton, Morris L. (1983). Multivariate Statistics: a Vector Space Approach. John Wiley and Sons. pp. 116–117., but I don't have this book handy...","Wikipedia gives details on the conditional distribution of the multivariate normal: If $\mu$ and $\Sigma$ are partitioned as follows $\boldsymbol\mu = \begin{bmatrix}  \boldsymbol\mu_1 \\  \boldsymbol\mu_2 \end{bmatrix}$ $\boldsymbol\Sigma = \begin{bmatrix}  \boldsymbol\Sigma_{11} & \boldsymbol\Sigma_{12} \\  \boldsymbol\Sigma_{21} & \boldsymbol\Sigma_{22} \end{bmatrix} \quad$ then, the distribution of $x_1$ conditional on $x_2= a$ is   multivariate normal $(x_1|x_2=a) \sim N(\bar{\mu}, \bar{\Sigma})$   where $\bar{\boldsymbol\mu} = \boldsymbol\mu_1 + \boldsymbol\Sigma_{12} \boldsymbol\Sigma_{22}^{-1} \left(  \mathbf{a} - \boldsymbol\mu_2 \right) $ and covariance matrix $\overline{\boldsymbol\Sigma} = \boldsymbol\Sigma_{11} - \boldsymbol\Sigma_{12} \boldsymbol\Sigma_{22}^{-1} \boldsymbol\Sigma_{21}.  $ How can I prove this result? Wikipedia cites Eaton, Morris L. (1983). Multivariate Statistics: a Vector Space Approach. John Wiley and Sons. pp. 116–117., but I don't have this book handy...",,"['probability', 'normal-distribution']"
71,$X$ is a Geometric random variable find the expectation of $1/X$,is a Geometric random variable find the expectation of,X 1/X,"Let $X$ be a geometric random variable with parameter $p$, find the expectation of $E[1/X]$. I need help simplifying the series.","Let $X$ be a geometric random variable with parameter $p$, find the expectation of $E[1/X]$. I need help simplifying the series.",,"['probability', 'sequences-and-series', 'probability-theory', 'stochastic-processes']"
72,What is linearity of Expectations?,What is linearity of Expectations?,,In reading about the average case analysis of randomized quick sort I came across linearity of expectations of indicator random variable  I know indicator random variable and expectation. What does linearity of Expectation mean  ?,In reading about the average case analysis of randomized quick sort I came across linearity of expectations of indicator random variable  I know indicator random variable and expectation. What does linearity of Expectation mean  ?,,"['probability', 'sequences-and-series', 'probability-theory']"
73,In Lotto what is the minimum number of tickets you would need to buy to guarantee at least one 3 number match?,In Lotto what is the minimum number of tickets you would need to buy to guarantee at least one 3 number match?,,"In Lotto (the UK lottery), you pick 6 numbers from a pool of 49. How many tickets would you need to guarantee at least one match of 3 numbers? Wikipedia shows the probability of matching 3 numbers at 55:1. Does that mean if you buy 55 tickets you are guaranteed to get at least one match? (P.S. I did search here and find another lottery question, possibly asking the same thing - but obviously didn't understand that.) cheers","In Lotto (the UK lottery), you pick 6 numbers from a pool of 49. How many tickets would you need to guarantee at least one match of 3 numbers? Wikipedia shows the probability of matching 3 numbers at 55:1. Does that mean if you buy 55 tickets you are guaranteed to get at least one match? (P.S. I did search here and find another lottery question, possibly asking the same thing - but obviously didn't understand that.) cheers",,['probability']
74,Probability I have another pack of sweetener,Probability I have another pack of sweetener,,"I drove my motorcycle to a fast food restaurant the other day.  As I was waiting for my lunch, I noticed they still had their coffee condiments out.  Not having any at home, I decided I'd grab a small handful and toss them into my motorcycle bag for later. I always put two sweeteners in my coffee, but one day I pulled a sweetener out of my motorcycle bag and I didn't see a second. I thought to myself, ""I should keep looking; there's a 50/50 chance there's another one in here."" I'm a math novice so I asked some of my friends if they thought I was right.  They weren't willing to assert either way, so I thought I'd ask here.  Was I statistically sound in my conclusion? EDIT: I haven't accepted an answer on this question yet, but I will be reviewing the answers soon.  Part of the reason I haven't is because I feel like a lot of the answers are a smidgen pedantic (and I don't mean that in a negative way at all). While I recognize that it's impossible to predict the distribution of a handful of sweeter packets because the universe is or is not random (whatever the case), I feel like a lot of people would fail a statistics course if they were to tell the professor a coin flip isn't 50/50 because, ""nobody shuffles cards completely randomly, no die is unbiased, and you impart bias in a coin flip."" I was really hoping to get answers to this question based on the same simple model of the universe that allows statistics professors to teach and allows casinos to make fortunes based on the knowledge that a six sided die has, ceteris paribus, 6 equally likely outcomes. I'm by no means saying that my original conclusion was correct, however, I'm not prepared to accept that it was wrong because of the ""orientation of the hairs on my skin, the amount of blood distending my vessels, or the imperfections in my skin.""","I drove my motorcycle to a fast food restaurant the other day.  As I was waiting for my lunch, I noticed they still had their coffee condiments out.  Not having any at home, I decided I'd grab a small handful and toss them into my motorcycle bag for later. I always put two sweeteners in my coffee, but one day I pulled a sweetener out of my motorcycle bag and I didn't see a second. I thought to myself, ""I should keep looking; there's a 50/50 chance there's another one in here."" I'm a math novice so I asked some of my friends if they thought I was right.  They weren't willing to assert either way, so I thought I'd ask here.  Was I statistically sound in my conclusion? EDIT: I haven't accepted an answer on this question yet, but I will be reviewing the answers soon.  Part of the reason I haven't is because I feel like a lot of the answers are a smidgen pedantic (and I don't mean that in a negative way at all). While I recognize that it's impossible to predict the distribution of a handful of sweeter packets because the universe is or is not random (whatever the case), I feel like a lot of people would fail a statistics course if they were to tell the professor a coin flip isn't 50/50 because, ""nobody shuffles cards completely randomly, no die is unbiased, and you impart bias in a coin flip."" I was really hoping to get answers to this question based on the same simple model of the universe that allows statistics professors to teach and allows casinos to make fortunes based on the knowledge that a six sided die has, ceteris paribus, 6 equally likely outcomes. I'm by no means saying that my original conclusion was correct, however, I'm not prepared to accept that it was wrong because of the ""orientation of the hairs on my skin, the amount of blood distending my vessels, or the imperfections in my skin.""",,['probability']
75,Probability of 3 of a kind with 7 dice,Probability of 3 of a kind with 7 dice,,"Similar questions: Chance of 7 of a kind with 10 dice Probability of getting exactly $k$ of a kind in $n$ rolls of $m$-sided dice, where $k\leq n/2$ Probability was never my thing, so please bear with me. I've reviewed the threads above to the best of my ability, but I still wonder how to go about finding a match of 3 from 7 dice. At least three match, but no more (two sets of three is okay, a set of three and a set of four is not): (a) : $ \frac{6  \binom{7}{3} 5^4}{6^7}  $ In the other discussions, this wasn't desired since it would allow for a second triple to occur, or even a quadruple.  Odds of a quadruple with the remaining 4 dice: (b) : $(1/5)^4 $ Then, the probability that from rolling 7 dice that there is at least three that match, and no more than three, would be: (c) : $ \frac{6  \binom{7}{3} * 5^4}{6^7}- (1/5)^4 $ Exactly two sets of three: (d) : $ \frac{6  \binom{7}{3}  \binom{4}{3} \binom{1}{1}}{ 6^7} $ Maybe?  My thought process was that if $\binom{7}{3}$ will give me a set of three, then with the remaining 4, I could pick 3 yielding $\binom{4}{3}$ with 1 leftover.  I realize this is probably wrong.  Why? What would be the proper way to go about this? Exactly one set of three: Then to find the probability that there is one and only one set of three from 7 dice, we could take the probability of one or more sets of three (c) and subtract the probability of exactly two sets (d), for: $ \frac{6  \binom{7}{3}  5^4}{ 6^7} - (1/5)^4 - \frac{6  \binom{7}{3}  \binom{4}{3} \binom{1}{1} }{ 6^7} $ (e) : $  \left(\frac{6  \binom{7}{3}}{ 6^7}\right) \left( 5^4 -  \binom{4}{3} \binom{1}{1} \right) - (1/5)^4 $ Is this at all on the right path? Thank you! PS. Sorry about the syntax, but I couldn't figure out how to make the standard nCr() symbol with MathJaX.","Similar questions: Chance of 7 of a kind with 10 dice Probability of getting exactly $k$ of a kind in $n$ rolls of $m$-sided dice, where $k\leq n/2$ Probability was never my thing, so please bear with me. I've reviewed the threads above to the best of my ability, but I still wonder how to go about finding a match of 3 from 7 dice. At least three match, but no more (two sets of three is okay, a set of three and a set of four is not): (a) : $ \frac{6  \binom{7}{3} 5^4}{6^7}  $ In the other discussions, this wasn't desired since it would allow for a second triple to occur, or even a quadruple.  Odds of a quadruple with the remaining 4 dice: (b) : $(1/5)^4 $ Then, the probability that from rolling 7 dice that there is at least three that match, and no more than three, would be: (c) : $ \frac{6  \binom{7}{3} * 5^4}{6^7}- (1/5)^4 $ Exactly two sets of three: (d) : $ \frac{6  \binom{7}{3}  \binom{4}{3} \binom{1}{1}}{ 6^7} $ Maybe?  My thought process was that if $\binom{7}{3}$ will give me a set of three, then with the remaining 4, I could pick 3 yielding $\binom{4}{3}$ with 1 leftover.  I realize this is probably wrong.  Why? What would be the proper way to go about this? Exactly one set of three: Then to find the probability that there is one and only one set of three from 7 dice, we could take the probability of one or more sets of three (c) and subtract the probability of exactly two sets (d), for: $ \frac{6  \binom{7}{3}  5^4}{ 6^7} - (1/5)^4 - \frac{6  \binom{7}{3}  \binom{4}{3} \binom{1}{1} }{ 6^7} $ (e) : $  \left(\frac{6  \binom{7}{3}}{ 6^7}\right) \left( 5^4 -  \binom{4}{3} \binom{1}{1} \right) - (1/5)^4 $ Is this at all on the right path? Thank you! PS. Sorry about the syntax, but I couldn't figure out how to make the standard nCr() symbol with MathJaX.",,"['probability', 'combinatorics', 'dice']"
76,Closed form of integral: $\displaystyle\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x$,Closed form of integral:,\displaystyle\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x,"Context I was trying to calculate the entropy in the Benktander distribution of the second kind, where: $$f_X(x)=\exp\left(\frac{a}{b}(1-x^b)\right)\cdot x^{b-2}\cdot(ax^b-b+1)\qquad x\geq 1$$ Where $a>0$ and $b\in(0,1]$ In this case the entropy is defined as: $$H[X]=-\int_1^\infty f(x)\cdot\ln(f(x))\mathrm{d}x$$ And after several steps I arrived at this point: $$H[X]=1+\frac{e^{\frac{a}{b}}}{b}\left(E_{\frac{1}{b}}\left(\frac{a}{b}\right)-\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x\right)$$ Where $E_s(z)$ is the generalized exponential integral What is the closed form of this integral? $$\displaystyle\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x$$ I think it might be useful to consider the following function: $$E_s(z):=z^{s-1}\int_{z}^{\infty}e^{-t}t^{-s}\mathrm{d}t$$ Is integral representation of the exponential integral function, so we can define this other function: $$E^{(1,0)}_s(z):=\frac{\mathrm{d}}{\mathrm{d}s}E_s(z)=z^{s-1}\int_{z}^{\infty}e^{-t}t^{-s}\ln\left(\frac{z}{t}\right)\mathrm{dt}$$ My approach is this: $$\int_{1}^{\infty}\frac{ax+b-1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax+b-1\right)\mathrm{d}x=\left.\frac{\partial}{\partial s}\int_{1}^{\infty}\frac{(ax+b-1)^s}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\mathrm{d}x\right|_{s=1}$$ Then I try to solve $$\int_{1}^{\infty}\frac{(ax+b-1)^s}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\mathrm{d}x=\frac{\left(b-1\right)^{s+1-\frac{1}{b}}}{a^{1-\frac{1}{b}}}\int_{\frac{a}{b-1}}^{\infty}\frac{\left(x+1\right)^{s}}{x^{\frac{1}{b}}}e^{-\frac{b-1}{b}x}dx$$ Then I get stuck","Context I was trying to calculate the entropy in the Benktander distribution of the second kind, where: Where and In this case the entropy is defined as: And after several steps I arrived at this point: Where is the generalized exponential integral What is the closed form of this integral? I think it might be useful to consider the following function: Is integral representation of the exponential integral function, so we can define this other function: My approach is this: Then I try to solve Then I get stuck","f_X(x)=\exp\left(\frac{a}{b}(1-x^b)\right)\cdot x^{b-2}\cdot(ax^b-b+1)\qquad x\geq 1 a>0 b\in(0,1] H[X]=-\int_1^\infty f(x)\cdot\ln(f(x))\mathrm{d}x H[X]=1+\frac{e^{\frac{a}{b}}}{b}\left(E_{\frac{1}{b}}\left(\frac{a}{b}\right)-\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x\right) E_s(z) \displaystyle\int_{1}^{\infty}\frac{ax-b+1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax-b+1\right)\mathrm{d}x E_s(z):=z^{s-1}\int_{z}^{\infty}e^{-t}t^{-s}\mathrm{d}t E^{(1,0)}_s(z):=\frac{\mathrm{d}}{\mathrm{d}s}E_s(z)=z^{s-1}\int_{z}^{\infty}e^{-t}t^{-s}\ln\left(\frac{z}{t}\right)\mathrm{dt} \int_{1}^{\infty}\frac{ax+b-1}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\ln\left(ax+b-1\right)\mathrm{d}x=\left.\frac{\partial}{\partial s}\int_{1}^{\infty}\frac{(ax+b-1)^s}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\mathrm{d}x\right|_{s=1} \int_{1}^{\infty}\frac{(ax+b-1)^s}{x^{\frac{1}{b}}}e^{-\frac{a}{b}x}\mathrm{d}x=\frac{\left(b-1\right)^{s+1-\frac{1}{b}}}{a^{1-\frac{1}{b}}}\int_{\frac{a}{b-1}}^{\infty}\frac{\left(x+1\right)^{s}}{x^{\frac{1}{b}}}e^{-\frac{b-1}{b}x}dx","['probability', 'integration', 'statistics', 'definite-integrals', 'improper-integrals']"
77,Simplifying $10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 2\binom{37}{8} + 1\binom{38}{9}$,Simplifying,10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 2\binom{37}{8} + 1\binom{38}{9},"In trying to solve a probability problem from an old math contest: https://artofproblemsolving.com/wiki/index.php/1987_AIME_Problems/Problem_13 I had reduced the crux of the problem to calculating/simplifying $$10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots +  2\binom{37}{8} + 1\binom{38}{9},$$ which I'm not sure how to simplify further. Could anyone give me a hint? Thanks in advance. EDIT: Calvin Lin asks me to explain how I got my expression. The total number of ways to order $40$ distinct numbers is $40!$ , so that will be our denominator. So let's calculate the numerator. Without loss of generality let our numbers in some order be $1$ , $2$ , $\ldots$ , $39$ , $40$ . We are counting the total number of configurations where: $r_{20}$ is greater than the other first $29$ numbers i.e. $r_1$ , $r_2$ , $\ldots$ , $r_{18}$ , $r_{19}$ , $r_{21}$ , $r_{22}$ , $\ldots$ , $r_{29}$ , $r_{30}$ . $r_{20}$ is less than $r_{31}$ . So $r_{20}$ has to be at least $30$ and is at most $39$ . Let's go case by case: $r_{20} = 30$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $28$ , $29$ , hence $29!$ ways to select and order. Then there's $10$ choices for $r_{31}$ , and then $9!$ choices for the last $9$ numbers. $r_{20} = 31$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $28$ , $29$ , $30$ , hence $30 \cdot 29 \cdots 3 \cdot 2$ ways to select and order. Then there's $9$ choices for $r_{31}$ , and then $9!$ choices for the last $9$ numbers. And so forth $\ldots$ $r_{20} = 39$ : The first $29$ numbers (where is $r_{20}$ omitted) have to be selected from $1$ , $2$ , $\ldots$ , $37$ , $38$ , hence $38 \cdot 37 \cdots 11 \cdot 10$ ways to select and order. There's only $1$ choice for $r_{31}$ and that's $r_{31} = 40$ , and again there's $9!$ choices for the last $9$ numbers. So our numerator is $$(29!)(10)(9!) + (30 \cdot 29 \cdots 3 \cdot 2)(9)(9!) + \ldots + (37 \cdot 36 \cdots 10 \cdot 9)(2)(9!) + (38 \cdot 37 \cdots 11 \cdot 10)(1)(9!) = (29!)(9!)\left(10 + 9{{30}\over{1}} + 8{{31 \cdot 20}\over{2 \cdot 1}} + 7{{32 \cdot 31 \cdot 30}\over{3 \cdot 2 \cdot 1}}  + \ldots + 1{{38 \cdots 30}\over{9 \cdots 1}}\right) = (29!)(9!)\left(10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}\right).$$ So the expression we want to calculate/simplify is $$10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}.$$ Again, any help would be well-appreciated.","In trying to solve a probability problem from an old math contest: https://artofproblemsolving.com/wiki/index.php/1987_AIME_Problems/Problem_13 I had reduced the crux of the problem to calculating/simplifying which I'm not sure how to simplify further. Could anyone give me a hint? Thanks in advance. EDIT: Calvin Lin asks me to explain how I got my expression. The total number of ways to order distinct numbers is , so that will be our denominator. So let's calculate the numerator. Without loss of generality let our numbers in some order be , , , , . We are counting the total number of configurations where: is greater than the other first numbers i.e. , , , , , , , , , . is less than . So has to be at least and is at most . Let's go case by case: : The first numbers (where is omitted) have to be selected from , , , , , hence ways to select and order. Then there's choices for , and then choices for the last numbers. : The first numbers (where is omitted) have to be selected from , , , , , , hence ways to select and order. Then there's choices for , and then choices for the last numbers. And so forth : The first numbers (where is omitted) have to be selected from , , , , , hence ways to select and order. There's only choice for and that's , and again there's choices for the last numbers. So our numerator is So the expression we want to calculate/simplify is Again, any help would be well-appreciated.","10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 
2\binom{37}{8} + 1\binom{38}{9}, 40 40! 1 2 \ldots 39 40 r_{20} 29 r_1 r_2 \ldots r_{18} r_{19} r_{21} r_{22} \ldots r_{29} r_{30} r_{20} r_{31} r_{20} 30 39 r_{20} = 30 29 r_{20} 1 2 \ldots 28 29 29! 10 r_{31} 9! 9 r_{20} = 31 29 r_{20} 1 2 \ldots 28 29 30 30 \cdot 29 \cdots 3 \cdot 2 9 r_{31} 9! 9 \ldots r_{20} = 39 29 r_{20} 1 2 \ldots 37 38 38 \cdot 37 \cdots 11 \cdot 10 1 r_{31} r_{31} = 40 9! 9 (29!)(10)(9!) + (30 \cdot 29 \cdots 3 \cdot 2)(9)(9!) + \ldots + (37 \cdot 36 \cdots 10 \cdot 9)(2)(9!) + (38 \cdot 37 \cdots 11 \cdot 10)(1)(9!) = (29!)(9!)\left(10 + 9{{30}\over{1}} + 8{{31 \cdot 20}\over{2 \cdot 1}} + 7{{32 \cdot 31 \cdot 30}\over{3 \cdot 2 \cdot 1}}  + \ldots + 1{{38 \cdots 30}\over{9 \cdots 1}}\right) = (29!)(9!)\left(10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}\right). 10 \binom{29}{0} + 9\binom{30}{1} + 8 \binom{31}{2} + \ldots + 1\binom{38}{9}.","['probability', 'combinatorics', 'summation', 'contest-math', 'binomial-coefficients']"
78,"I've clicked XKCD's ""random"" button k times and I've already seen all of them. What's the expected number of XKCD's I've seen?","I've clicked XKCD's ""random"" button k times and I've already seen all of them. What's the expected number of XKCD's I've seen?",,"This seems like a modification of the coupon collector's problem which can be stated as follows: There are $n$ coupons total to collect. Given that the past $k$ coupons seen I've already collected (coupons are collected with replacement), what's the expected number of coupon's I've collected so far? I'm also unsure if this problem depends on an underlying prior probability distribution on the number of coupons I've collected; if it does, can this be solved with an arbitrary distribution? One additional part to this question: let's say after the $k$ th one I collect a new coupon; what would the expected number of coupon's I've collected be then?","This seems like a modification of the coupon collector's problem which can be stated as follows: There are coupons total to collect. Given that the past coupons seen I've already collected (coupons are collected with replacement), what's the expected number of coupon's I've collected so far? I'm also unsure if this problem depends on an underlying prior probability distribution on the number of coupons I've collected; if it does, can this be solved with an arbitrary distribution? One additional part to this question: let's say after the th one I collect a new coupon; what would the expected number of coupon's I've collected be then?",n k k,"['probability', 'expected-value', 'bayesian', 'balls-in-bins', 'coupon-collector']"
79,Questions about definition of Quantile function,Questions about definition of Quantile function,,"Let $F$ be a distribution function. For $0<p<1$ , the $p$ -th quantile or fractile of $F$ is defined by $$\xi_p = F^{\leftarrow}(p) = \inf\{x:F(x)\geq p\}$$ my questions are following: Why we take $\inf$ ? If we take $\min$ then what kind of problem arise? Why we can not take $\sup$ ? If we take $\sup$ then which portion of the definition of the $F$ we have to modify? And what kind of problem arise when we take $\sup$ ? Suppose we want to study empirical quantile function using $\sup$ in the definition then what kind of problem arise? Any kind of help appreciable. Thanks in advance","Let be a distribution function. For , the -th quantile or fractile of is defined by my questions are following: Why we take ? If we take then what kind of problem arise? Why we can not take ? If we take then which portion of the definition of the we have to modify? And what kind of problem arise when we take ? Suppose we want to study empirical quantile function using in the definition then what kind of problem arise? Any kind of help appreciable. Thanks in advance",F 0<p<1 p F \xi_p = F^{\leftarrow}(p) = \inf\{x:F(x)\geq p\} \inf \min \sup \sup F \sup \sup,"['probability', 'probability-theory', 'random-variables', 'cumulative-distribution-functions', 'quantile-function']"
80,How do I know when to use the Law of total probability?,How do I know when to use the Law of total probability?,,"I am studying Probability Theory 1, and we have learned the Law of total probability and proved it. I know the theoretical intuition behind it and I know why it makes sense from it's proof. But when I see a new problem (that they solved it using this method) I just can't relate it to this law. Can you guide me of how and when should I use it, and what kind of problems can be solved using this theorem? I would like some simple example illustrating it's usage.","I am studying Probability Theory 1, and we have learned the Law of total probability and proved it. I know the theoretical intuition behind it and I know why it makes sense from it's proof. But when I see a new problem (that they solved it using this method) I just can't relate it to this law. Can you guide me of how and when should I use it, and what kind of problems can be solved using this theorem? I would like some simple example illustrating it's usage.",,['probability']
81,What is the likelihood of two line segments crossing?,What is the likelihood of two line segments crossing?,,Consider a square space. Randomly select 4 points. Randomly connect two sets of two to each other with line segments. What is the chance of the line segments intersecting? (I will maybe try and solve this with a little Monte-Carlo simulation but would be very interested in an analytic solution.),Consider a square space. Randomly select 4 points. Randomly connect two sets of two to each other with line segments. What is the chance of the line segments intersecting? (I will maybe try and solve this with a little Monte-Carlo simulation but would be very interested in an analytic solution.),,"['probability', 'geometry']"
82,"Show that Cov(X,Y)=Cov(X,E(Y|X)).","Show that Cov(X,Y)=Cov(X,E(Y|X)).",,"Let X, Y be independent random variables.  I've been working on this for a while and I think this question just requires skillful manipulation of the expectations E(X) and E(Y|X).  At one point I got that Cov(X,Y) is 0... which is incorrect.  Since then I have started over and here's what I have: Cov(X, E(Y|X))=E((X-E(X)(E(Y|X)-E(E(Y|X))) =E(X E(Y|X))-X E(E(Y|X))-E(X)E(Y|X)+E(X) E(E(Y|X)) =E(E(XY|X))-E(E(XY|X)) And I'm not so sure what to do from there.  Did I just make things more complicated?","Let X, Y be independent random variables.  I've been working on this for a while and I think this question just requires skillful manipulation of the expectations E(X) and E(Y|X).  At one point I got that Cov(X,Y) is 0... which is incorrect.  Since then I have started over and here's what I have: Cov(X, E(Y|X))=E((X-E(X)(E(Y|X)-E(E(Y|X))) =E(X E(Y|X))-X E(E(Y|X))-E(X)E(Y|X)+E(X) E(E(Y|X)) =E(E(XY|X))-E(E(XY|X)) And I'm not so sure what to do from there.  Did I just make things more complicated?",,"['probability', 'probability-theory', 'statistics']"
83,How to sample a binomial random variable?,How to sample a binomial random variable?,,"Rather than using mathematical libraries, how would you sample from a binomial random variable efficiently? Given the binomial random variable X, where $k$ are the number of successes in $n$ trials with a success probability of $p$ $$     P(X=k|n, p) = \binom{n}{k} p^k(1-p)^{n-k}, $$ how could I obtain $N$ number of samples of $X$? The naïve approach is to decompose $X$ into $X = Y_1 + Y_2 + ... + Y_n$, where $Y$ are the bernoulli experiments  $$ Y_i = P(Y_i = 1) = p. $$ Or, in other words, I can test $n$ times if some random value is above $p$ and count how many times this was a success. This is, however, terribly inefficient when $n$ is large. It is possible to sample a continuous random variable by finding the inverse CDF ($F^{-1}(x)$), sampling from the uniform distribution $ u = U(0,1)$ and calculating the value of the sample in the inverse CDF $F^{-1}(u)$. Given that this is a discrete distribution, how could I apply this? Which other methods are available?","Rather than using mathematical libraries, how would you sample from a binomial random variable efficiently? Given the binomial random variable X, where $k$ are the number of successes in $n$ trials with a success probability of $p$ $$     P(X=k|n, p) = \binom{n}{k} p^k(1-p)^{n-k}, $$ how could I obtain $N$ number of samples of $X$? The naïve approach is to decompose $X$ into $X = Y_1 + Y_2 + ... + Y_n$, where $Y$ are the bernoulli experiments  $$ Y_i = P(Y_i = 1) = p. $$ Or, in other words, I can test $n$ times if some random value is above $p$ and count how many times this was a success. This is, however, terribly inefficient when $n$ is large. It is possible to sample a continuous random variable by finding the inverse CDF ($F^{-1}(x)$), sampling from the uniform distribution $ u = U(0,1)$ and calculating the value of the sample in the inverse CDF $F^{-1}(u)$. Given that this is a discrete distribution, how could I apply this? Which other methods are available?",,"['probability', 'binomial-distribution']"
84,Random ants probability question,Random ants probability question,,"500 ants are randomly put on a 1-foot string (independent uniform distribution for each ant between 0 and 1). Each ant randomly moves toward on end of the string (equal probability to the left or the right) at constant speed of 1 foot/minute until it falls of a t one end of the string. Also assume that the size of the ant is infinitely small. When two ants collide head-on, they both immediately change directions and keep on moving at 1 foot/min. What is the expected time for all ants to fall off the string? I realize this question has been asked here . However, I am trying to understand the answer that is given for this question in my book: It says the ants labels are randomly assigned and hence the labels of the ants can be changed with no difference to the result. So when the ants collide, they effectively continue in the same direction. This makes sense. However, I am unclear about this part: If an ant is put on the x-th foot, the expected value for it to fall off is just x min. If it goes in the other direction, simply set it to 1-x. So, the original problem just becomes what is the expected value of the maximum of 500 IID random variables with a Uniform Distribution between 0 and 1. I don't understand how the difference in direction that it goes in is being accounted for.","500 ants are randomly put on a 1-foot string (independent uniform distribution for each ant between 0 and 1). Each ant randomly moves toward on end of the string (equal probability to the left or the right) at constant speed of 1 foot/minute until it falls of a t one end of the string. Also assume that the size of the ant is infinitely small. When two ants collide head-on, they both immediately change directions and keep on moving at 1 foot/min. What is the expected time for all ants to fall off the string? I realize this question has been asked here . However, I am trying to understand the answer that is given for this question in my book: It says the ants labels are randomly assigned and hence the labels of the ants can be changed with no difference to the result. So when the ants collide, they effectively continue in the same direction. This makes sense. However, I am unclear about this part: If an ant is put on the x-th foot, the expected value for it to fall off is just x min. If it goes in the other direction, simply set it to 1-x. So, the original problem just becomes what is the expected value of the maximum of 500 IID random variables with a Uniform Distribution between 0 and 1. I don't understand how the difference in direction that it goes in is being accounted for.",,['probability']
85,A fair die is rolled n times. What is the probability that at least 1 of the 6 values never appears?,A fair die is rolled n times. What is the probability that at least 1 of the 6 values never appears?,,"A fair die is rolled $n$ times. What is the probability that at least $1$ of the $6$ values never appears? I went about calculating the complement of this, because it seemed to be easier. However, I am having trouble with it. I was able to calculate the complement for $n=6$ and $n=7$ using a formula for putting $n$ items into $6$ boxes and requiring that each box had one item. For $n=7$ one box had to have two items and there are six ways to do that, so I accounted for this in the formula: $$\frac{6\times(7!/2!)}{6^7}$$ It seems that it will be quite complicated to apply this method for $n>7$, but I can't seem to figure out any other way. I thought to use a combination to choose the 6 from n which have to be the values $1$ through $6$: $${n\choose 6}6!/6^n$$ but this seems to undercount by quite a bit. Would the answer be something like this? This is not homework, just self-study. Thanks!","A fair die is rolled $n$ times. What is the probability that at least $1$ of the $6$ values never appears? I went about calculating the complement of this, because it seemed to be easier. However, I am having trouble with it. I was able to calculate the complement for $n=6$ and $n=7$ using a formula for putting $n$ items into $6$ boxes and requiring that each box had one item. For $n=7$ one box had to have two items and there are six ways to do that, so I accounted for this in the formula: $$\frac{6\times(7!/2!)}{6^7}$$ It seems that it will be quite complicated to apply this method for $n>7$, but I can't seem to figure out any other way. I thought to use a combination to choose the 6 from n which have to be the values $1$ through $6$: $${n\choose 6}6!/6^n$$ but this seems to undercount by quite a bit. Would the answer be something like this? This is not homework, just self-study. Thanks!",,"['probability', 'combinatorics']"
86,Limit of Gaussian random variables is Gaussian?,Limit of Gaussian random variables is Gaussian?,,"Consider a sequence $X_n$ of Gaussian random variables with mean $\mu_n$ and variance $\sigma_n^2$, which converges in distribution (to some limiting distribution). Can I then conclude that $\mu_n$ converges to some $\mu$ and $\sigma_n^2$ converges to some $\sigma^2$, with the limiting distribution being $N(\mu, \sigma^2)$? Here, I think I'd allow the degenerate Gaussian distribution with zero variance. I've tried looking this up elsewhere on this site, but all those I've found assume almost sure/L2 convergence. I was thinking this should be true, and was trying to do this by characteristic functions but without assuming the convergence of the two parameters, I can't seem to conclude anything.","Consider a sequence $X_n$ of Gaussian random variables with mean $\mu_n$ and variance $\sigma_n^2$, which converges in distribution (to some limiting distribution). Can I then conclude that $\mu_n$ converges to some $\mu$ and $\sigma_n^2$ converges to some $\sigma^2$, with the limiting distribution being $N(\mu, \sigma^2)$? Here, I think I'd allow the degenerate Gaussian distribution with zero variance. I've tried looking this up elsewhere on this site, but all those I've found assume almost sure/L2 convergence. I was thinking this should be true, and was trying to do this by characteristic functions but without assuming the convergence of the two parameters, I can't seem to conclude anything.",,"['probability', 'convergence-divergence', 'normal-distribution']"
87,Are subsets of independent events independent,Are subsets of independent events independent,,"Intuitively, if events A and B are independent, then any subset of A should also be independent of B, that is, let $C \subset A$, then is it true that $P(C \cap B) = P(C) P(B)$? Here is my attempt to prove this statement: We have $P(A \cap B) = P(C \cap B) + P((A \setminus C) \cap B)$ and $P(A)P(B) = P(A \setminus C)P(B) + P(C)P(B)$. The independence of A and B implies that $P(C \cap B) = P(C) P(B)$ if and only if $P((A \setminus C) \cap B) = P(A \setminus C)P(B)$. In words, if A and B are independent, then any subset of A is independent of B if and only if its complement in A is independent of B. So if my original statement is wrong, can anybody give a counter example?","Intuitively, if events A and B are independent, then any subset of A should also be independent of B, that is, let $C \subset A$, then is it true that $P(C \cap B) = P(C) P(B)$? Here is my attempt to prove this statement: We have $P(A \cap B) = P(C \cap B) + P((A \setminus C) \cap B)$ and $P(A)P(B) = P(A \setminus C)P(B) + P(C)P(B)$. The independence of A and B implies that $P(C \cap B) = P(C) P(B)$ if and only if $P((A \setminus C) \cap B) = P(A \setminus C)P(B)$. In words, if A and B are independent, then any subset of A is independent of B if and only if its complement in A is independent of B. So if my original statement is wrong, can anybody give a counter example?",,"['probability', 'elementary-set-theory']"
88,Mutual or pairwise independence needed? Variance of a sum.,Mutual or pairwise independence needed? Variance of a sum.,,"This is a simple question: Do we need mutual independence or only pairwise independence in order to state that $$\mathrm{Var}\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \mathrm{Var}\left[X_i\right]?$$ As I do not know what uncorrelated means (I know that this is the actual condition), I am not sure whether it is enough for each pair to be independent. Thanks for your help.","This is a simple question: Do we need mutual independence or only pairwise independence in order to state that $$\mathrm{Var}\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \mathrm{Var}\left[X_i\right]?$$ As I do not know what uncorrelated means (I know that this is the actual condition), I am not sure whether it is enough for each pair to be independent. Thanks for your help.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'covariance']"
89,What does $\mathbb{P}(d\omega)=dw$ actually mean?,What does  actually mean?,\mathbb{P}(d\omega)=dw,"I am currently reading S. Shreve's book Stochastic Calculus II, and I have a question regarding Example 1.6.4 (p.35-36) which describes a change of measure, but I am puzzled by the notation. $\Omega=[0,1], \mathbb{P}$ is the uniform measure and  $$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\omega=b^2-a^2$$ for $0\le a\le b \le 1$. The first step is: We may use the fact that $\mathbb{P}(d\omega) = d\omega$ to rewrite the equation above as   $$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\mathbb{P}(\omega).$$ I have several questions regarding this statement: $\mathbb{P}$ is a probability measure from $\mathcal{F}\rightarrow\mathbb{R}$, I cannot find a clear definition in the book what $\mathbb{P}(d\omega)$ actually means. Is $d\omega$ actually an event? Why does this $\mathbb{P}(d\omega) = d\omega$ help in rewriting, shouldn't we need $d\mathbb{P}(\omega) = d\omega$? What does $\mathbb{P}(d\omega) = d\omega$ even mean, and why is this true?","I am currently reading S. Shreve's book Stochastic Calculus II, and I have a question regarding Example 1.6.4 (p.35-36) which describes a change of measure, but I am puzzled by the notation. $\Omega=[0,1], \mathbb{P}$ is the uniform measure and  $$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\omega=b^2-a^2$$ for $0\le a\le b \le 1$. The first step is: We may use the fact that $\mathbb{P}(d\omega) = d\omega$ to rewrite the equation above as   $$\tilde{\mathbb{P}}[a,b]=\int_a^b 2\omega d\mathbb{P}(\omega).$$ I have several questions regarding this statement: $\mathbb{P}$ is a probability measure from $\mathcal{F}\rightarrow\mathbb{R}$, I cannot find a clear definition in the book what $\mathbb{P}(d\omega)$ actually means. Is $d\omega$ actually an event? Why does this $\mathbb{P}(d\omega) = d\omega$ help in rewriting, shouldn't we need $d\mathbb{P}(\omega) = d\omega$? What does $\mathbb{P}(d\omega) = d\omega$ even mean, and why is this true?",,"['probability', 'measure-theory', 'notation']"
90,Deep Understanding of Independence of Probabilities,Deep Understanding of Independence of Probabilities,,"I really want to have a deep understanding of the independent probabilities of two events. That means to me that I just do not want to use and know the definition. I want to fully understand the why. Definition 3.1. (a) Two events $A$ and $B$ are independent if $\text{P}(A \cap B) = \text{P}(A)P(B)$. (b) $A$ (possibly infinite) collection of events $(A_i)_{i \in I}$ is an independent collection if for every finite subset $J$ of $I$, one has   $$\text{P}\left(\bigcap_{i \in J} A_i\right) = \prod_{i \in J}\text{P}(A_i).$$   The collection $(A_i)_{i\in I}$ is often said to be mutually independent. Therefore my question: Let's consider two events of two train crashes $A$ and $B$. $A$ is in London and $B$ is in New York. If the intersection of the two trains is a multiple of the probabilities of the two events then these two events are independent.(In my opinion this should be $0$ for independent events) If not they are dependent. If we just know this kind of information, logically these two events should not be dependent, because a train crash in London should not have anything to two with one in New York. (Could I also say shares the same information?) However, if I get that these two events are dependent is my equation wrong? AND is this value the probability of their dependency? I appreciate your answer!","I really want to have a deep understanding of the independent probabilities of two events. That means to me that I just do not want to use and know the definition. I want to fully understand the why. Definition 3.1. (a) Two events $A$ and $B$ are independent if $\text{P}(A \cap B) = \text{P}(A)P(B)$. (b) $A$ (possibly infinite) collection of events $(A_i)_{i \in I}$ is an independent collection if for every finite subset $J$ of $I$, one has   $$\text{P}\left(\bigcap_{i \in J} A_i\right) = \prod_{i \in J}\text{P}(A_i).$$   The collection $(A_i)_{i\in I}$ is often said to be mutually independent. Therefore my question: Let's consider two events of two train crashes $A$ and $B$. $A$ is in London and $B$ is in New York. If the intersection of the two trains is a multiple of the probabilities of the two events then these two events are independent.(In my opinion this should be $0$ for independent events) If not they are dependent. If we just know this kind of information, logically these two events should not be dependent, because a train crash in London should not have anything to two with one in New York. (Could I also say shares the same information?) However, if I get that these two events are dependent is my equation wrong? AND is this value the probability of their dependency? I appreciate your answer!",,"['probability', 'probability-theory', 'intuition']"
91,Probability generating function,Probability generating function,,"What is the probability generating function of the couple of random variables $(X,Y)$? For a variable $X$, it is $G_X(t)=E[t^X]$ but I can't figure out what it is for two variables. Also, how can I deduce the expected values $E[XY]$, $\text E[X]$, $\text E[Y]$ and  the covariance $\text {Cov}[X,Y]$ from this function?","What is the probability generating function of the couple of random variables $(X,Y)$? For a variable $X$, it is $G_X(t)=E[t^X]$ but I can't figure out what it is for two variables. Also, how can I deduce the expected values $E[XY]$, $\text E[X]$, $\text E[Y]$ and  the covariance $\text {Cov}[X,Y]$ from this function?",,['probability']
92,"Question about random walk with fixed endpoint, and a reference request","Question about random walk with fixed endpoint, and a reference request",,"We have a random walk of length $n$, starting at $0$ and ending at $-6\,\sqrt{n}$. Can we give any sort of high probability bound on the number of steps before we first reach the value $-2\, \sqrt{n}$? I'm really looking for anything related to the random variable defined by the first time we reach the value $-2\,\sqrt{n}$, like probability distribution, expected value, etc. As for the reference request, are there any books which discuss random walks with a given endpoint in more detail? The unfortunate thing is that knowing the endpoint loses the martingale property, so I don't really know of many ways to analyze this type of walk.","We have a random walk of length $n$, starting at $0$ and ending at $-6\,\sqrt{n}$. Can we give any sort of high probability bound on the number of steps before we first reach the value $-2\, \sqrt{n}$? I'm really looking for anything related to the random variable defined by the first time we reach the value $-2\,\sqrt{n}$, like probability distribution, expected value, etc. As for the reference request, are there any books which discuss random walks with a given endpoint in more detail? The unfortunate thing is that knowing the endpoint loses the martingale property, so I don't really know of many ways to analyze this type of walk.",,"['probability', 'reference-request', 'random-walk']"
93,Finding joint probability distribution of two dependent random variables?,Finding joint probability distribution of two dependent random variables?,,"If I have two dependent continuous random variables $X$ and $Y$ with known pdf's $f(x)$ and $f(y)$. How to calculate their join probability distribution $f(x, y)$? For example if $Y = \sin{X}$ and I want to calculate the pdf of $Z$ where $Z = \frac{X}{Y}$ or $Z = X - Y$. So, how to find out $f(x, y)$ first?","If I have two dependent continuous random variables $X$ and $Y$ with known pdf's $f(x)$ and $f(y)$. How to calculate their join probability distribution $f(x, y)$? For example if $Y = \sin{X}$ and I want to calculate the pdf of $Z$ where $Z = \frac{X}{Y}$ or $Z = X - Y$. So, how to find out $f(x, y)$ first?",,"['probability', 'probability-theory']"
94,How safe is it to ignore low probability events?,How safe is it to ignore low probability events?,,"See this question on applying probability theory principles in software design. The question is generally the following: you design some system (say software) and rely on some well-known mathematical concept (say hash function). You know that when this concept is used without caution your system can sometimes fail, however the probability of such failure is extremely low. You need to evaluate whether you want to alter the design or can just ignore that drawback. Consequences of a failure are usually taken into account when such evaluations are done. For example if a failure leads to a person being mildly offended then it is not that of a problem but if a failure leads to a nuclear power explosion that it is a serious problem. Now the accepted answer goes like this (all numbers here are exaggerated for better perception): probability of Earth colliding with a space rock is 10E-50 and probability of that drawback causing a problem is 10E-100. You see - Earth colliding with a space rock is a gazillion times more likely. So relax, that design is good enough. Is that reasoning correct? Can it be accepted at all times?","See this question on applying probability theory principles in software design. The question is generally the following: you design some system (say software) and rely on some well-known mathematical concept (say hash function). You know that when this concept is used without caution your system can sometimes fail, however the probability of such failure is extremely low. You need to evaluate whether you want to alter the design or can just ignore that drawback. Consequences of a failure are usually taken into account when such evaluations are done. For example if a failure leads to a person being mildly offended then it is not that of a problem but if a failure leads to a nuclear power explosion that it is a serious problem. Now the accepted answer goes like this (all numbers here are exaggerated for better perception): probability of Earth colliding with a space rock is 10E-50 and probability of that drawback causing a problem is 10E-100. You see - Earth colliding with a space rock is a gazillion times more likely. So relax, that design is good enough. Is that reasoning correct? Can it be accepted at all times?",,"['probability', 'probability-theory']"
95,Why is estimating the proportion of Democrats the same as estimating the bias of a coin?,Why is estimating the proportion of Democrats the same as estimating the bias of a coin?,,"My textbook is talking about how estimating the proportion of Democrats in the population reduces to estimating the bias of a coin, which I wasn't seeing. Here is the paragraph I was reading: Consider the problem of estimating the proportion $p$ of Democrats in the US population, by taking a small random sample. We can model this as the problem of estimating the bias of a coin above, where each coin toss corresponds to a person that we select randomly from the entire population. And the coin tosses are independent: we are assuming here that the sampling is done “with replacement”; i.e., we select each person in the sample from the entire population, including those we have already picked. So there is a small chance that we will pick the same person twice. I am not seeing how the problem of estimating the proportion of Democrats is equivalent to estimating the bias of a coin. There are 2 things I am confused with here: When we have a bunch of coin tosses from the same coin, each toss has an equal propensity to be heads; but people in a population don't have an equal propensity to be Democrat. And modelling this example as estimating the bias of a coin  assumes that the probability of every person being a Democrat is the same, it seems- are we treating the proportion of people which are Democrat as an equivalent notion to the propensity of a particular person to be Democrat? How is flipping a coin the same thing as sampling a person from the population? I see that while we could classify things into 2 possibilities in both cases, with Democrat and non-Democrat corresponding to heads and tails, there are an amount of possible outcomes equal to the amount of people in the population for sampling a person, making me feel that this is somehow different from when there are only 2 outcomes from flipping a coin. I would be very grateful if anyone could explain how these situations are similar in a way which resolves my confusions.","My textbook is talking about how estimating the proportion of Democrats in the population reduces to estimating the bias of a coin, which I wasn't seeing. Here is the paragraph I was reading: Consider the problem of estimating the proportion of Democrats in the US population, by taking a small random sample. We can model this as the problem of estimating the bias of a coin above, where each coin toss corresponds to a person that we select randomly from the entire population. And the coin tosses are independent: we are assuming here that the sampling is done “with replacement”; i.e., we select each person in the sample from the entire population, including those we have already picked. So there is a small chance that we will pick the same person twice. I am not seeing how the problem of estimating the proportion of Democrats is equivalent to estimating the bias of a coin. There are 2 things I am confused with here: When we have a bunch of coin tosses from the same coin, each toss has an equal propensity to be heads; but people in a population don't have an equal propensity to be Democrat. And modelling this example as estimating the bias of a coin  assumes that the probability of every person being a Democrat is the same, it seems- are we treating the proportion of people which are Democrat as an equivalent notion to the propensity of a particular person to be Democrat? How is flipping a coin the same thing as sampling a person from the population? I see that while we could classify things into 2 possibilities in both cases, with Democrat and non-Democrat corresponding to heads and tails, there are an amount of possible outcomes equal to the amount of people in the population for sampling a person, making me feel that this is somehow different from when there are only 2 outcomes from flipping a coin. I would be very grateful if anyone could explain how these situations are similar in a way which resolves my confusions.",p,"['probability', 'statistics', 'statistical-inference']"
96,A Weighted Gaussian Inequality: $E[\frac{\sigma_n^2 x_n^2}{\sum_{i=1}^n \sigma_i^2x_i^2} ] \ge \frac{\sigma_n^2}{\sum_{i=1}^n \sigma_i^2}$,A Weighted Gaussian Inequality:,E[\frac{\sigma_n^2 x_n^2}{\sum_{i=1}^n \sigma_i^2x_i^2} ] \ge \frac{\sigma_n^2}{\sum_{i=1}^n \sigma_i^2},"Given $\sigma_1 \ge \dots \ge \sigma_n \ge 0$ , and independent random gaussian variables $x_1, \dots, x_n \sim \mathcal N(0,1)$ , I want to show: $$ \mathbb E\left[ \frac{\sigma_n^2 x_n^2}{\sum_{i=1}^n \sigma_i^2 x_i^2} \right] \ge \frac{\sigma_n^2}{\sum_{i=1}^n \sigma_i^2}. $$ Note that this corresponds to taking the expectation of the numerator and denominator individually. Using Jensen's inequality I can show \begin{align} \mathbb E\left[ \frac{x^2}{x^2 + z} \right] &= \mathbb E\left[ \mathbb E\left[ \frac{x^2}{x^2 + z} \mid x \right] \right] \\&\ge \mathbb E\left[ \frac{x^2}{x^2 + \mathbb E[z]} \right] \\&\approx \frac{1}{1 + \sqrt{\mathbb E[z]} + \mathbb E[z]}. \end{align} However, what I would need to be true is $ \mathbb E\left[ \frac{x^2}{x^2 + z} \right] \ge \frac{1}{1 + \mathbb E[z]} $ , and that certainly doesn't hold in general. In particular it seems I need to somehow use that it's the smallest $\sigma_n$ that's in the numerator. The equivalent result with an arbitrary $\sigma_i$ doesn't seem to be true in general. It's also interesting to notice that in the simple case $n=2$ we get $$ \mathbb E\left[ \frac{\sigma_2^2 x_2^2}{\sigma_1^2 x_1^2 + \sigma_2^2 x_2^2} \right] = \frac{\sigma_2}{\sigma_1 + \sigma_2}. $$ (At least Mathematica says this is true, I'd be interested in knowing a proof.) Though that definitely doesn't hold for $n > 2$ . I suppose the equation $\sum_{i=1}^n \sigma_i^2 x_i^2 = 1$ corresponds to integrating over an ellipse, but I haven't found a nice geometric way to make use of that. I tried something else. In the case $\sigma_1 = 1$ and $\sigma_2=\sigma_3$ , Mathematica can evaluate the expectation as $$ \frac{x_1^2}{x_1^2 + \sigma_2^2 (x_2^2 + x_3^2)} = \frac{1}{1-\sigma_2^2}+\frac{\sigma_2 \sinh ^{-1}\left(\sqrt{\sigma_2^2-1}\right)}{\left(\sigma_2^2-1\right)^{3/2}}. $$ As expected this is below $1/(1+2\sigma_2^2)$ for $\sigma_2 > 1$ : Mathematica even finds an expression for the general case $E[\frac{x_n^2}{x_n^2+a \chi^2}]$ where $\chi^2$ is Chi-squared distributed with $n-1$ degrees of freedom. So maybe there's a proof works by ""evening out"" the larger $\sigma$ values... The bound with chi-squared isn't particularly pretty though... A statement equivalent to my inequality is that $$ \mathbb E\left[ \frac{x_n^2}{\sum_{i=1}^n p_i x_i^2} \right] \ge E\left[ \frac{x_n^2}{\frac{1}{n} \sum_{i=1}^n x_i^2} \right], $$ where $\sum_i p_i=1$ , and $p_1 \ge p_2 \ge \dots \ge p_n \ge 0$ . Since $E\left[ \frac{x_n^2}{\sum_{i=1}^n x_i^2} \right]=\frac1n$ by symmetry. It might even be that all of this is true independent of $x_i$ being Gaussian, as long as they are IID.","Given , and independent random gaussian variables , I want to show: Note that this corresponds to taking the expectation of the numerator and denominator individually. Using Jensen's inequality I can show However, what I would need to be true is , and that certainly doesn't hold in general. In particular it seems I need to somehow use that it's the smallest that's in the numerator. The equivalent result with an arbitrary doesn't seem to be true in general. It's also interesting to notice that in the simple case we get (At least Mathematica says this is true, I'd be interested in knowing a proof.) Though that definitely doesn't hold for . I suppose the equation corresponds to integrating over an ellipse, but I haven't found a nice geometric way to make use of that. I tried something else. In the case and , Mathematica can evaluate the expectation as As expected this is below for : Mathematica even finds an expression for the general case where is Chi-squared distributed with degrees of freedom. So maybe there's a proof works by ""evening out"" the larger values... The bound with chi-squared isn't particularly pretty though... A statement equivalent to my inequality is that where , and . Since by symmetry. It might even be that all of this is true independent of being Gaussian, as long as they are IID.","\sigma_1 \ge \dots \ge \sigma_n \ge 0 x_1, \dots, x_n \sim \mathcal N(0,1) 
\mathbb E\left[
\frac{\sigma_n^2 x_n^2}{\sum_{i=1}^n \sigma_i^2 x_i^2}
\right]
\ge \frac{\sigma_n^2}{\sum_{i=1}^n \sigma_i^2}.
 \begin{align}
\mathbb E\left[
\frac{x^2}{x^2 + z}
\right]
&=
\mathbb E\left[
\mathbb E\left[
\frac{x^2}{x^2 + z}
\mid x
\right]
\right]
\\&\ge
\mathbb E\left[
\frac{x^2}{x^2 + \mathbb E[z]}
\right]
\\&\approx
\frac{1}{1 + \sqrt{\mathbb E[z]} + \mathbb E[z]}.
\end{align} 
\mathbb E\left[
\frac{x^2}{x^2 + z}
\right] \ge \frac{1}{1 + \mathbb E[z]}
 \sigma_n \sigma_i n=2 
\mathbb E\left[
\frac{\sigma_2^2 x_2^2}{\sigma_1^2 x_1^2 + \sigma_2^2 x_2^2}
\right]
= \frac{\sigma_2}{\sigma_1 + \sigma_2}.
 n > 2 \sum_{i=1}^n \sigma_i^2 x_i^2 = 1 \sigma_1 = 1 \sigma_2=\sigma_3 
\frac{x_1^2}{x_1^2 + \sigma_2^2 (x_2^2 + x_3^2)}
=
\frac{1}{1-\sigma_2^2}+\frac{\sigma_2 \sinh ^{-1}\left(\sqrt{\sigma_2^2-1}\right)}{\left(\sigma_2^2-1\right)^{3/2}}.
 1/(1+2\sigma_2^2) \sigma_2 > 1 E[\frac{x_n^2}{x_n^2+a \chi^2}] \chi^2 n-1 \sigma 
\mathbb E\left[
\frac{x_n^2}{\sum_{i=1}^n p_i x_i^2}
\right]
\ge E\left[
\frac{x_n^2}{\frac{1}{n} \sum_{i=1}^n x_i^2}
\right],
 \sum_i p_i=1 p_1 \ge p_2 \ge \dots \ge p_n \ge 0 E\left[
\frac{x_n^2}{\sum_{i=1}^n x_i^2}
\right]=\frac1n x_i","['probability', 'inequality', 'normal-distribution', 'conic-sections', 'geometric-probability']"
97,"average length of ""harmonic walk"" mod $n$ is $\ln(n)$ -- why?","average length of ""harmonic walk"" mod  is  -- why?",n \ln(n),"Let a harmonic walk be a stochastic process where at turn $t \ge 2$ the probability of ending the walk is $\frac{1}{t}$ and the first turn never ends the walk. A harmonic walk can be viewed as a distribution over $\mathbb{N}_{\ge 1}$ without finite mean. Empirically, it seems to be the case that the average length of a harmonic walk mod $n$ is $\ln\left(n\right)$ . I'm wondering why this should be the case. The definition of the harmonic series (1) looks similar to the integral definition of the natural log, $\ln(x) \stackrel{\text{def}}{=} \int_{1}^{x} 1/s \;\text{ds} $ , so there might be reason to suspect that a relationship might exist, but that resemblance isn't remotely convincing. The harmonic series $H$ is given below (1) with the symbol "" $H$ "" referring to the formal sum, not the value. $$ H \stackrel{\text{def}}{=} \sum_{k=1}^{\infty} \frac{1}{k} \;\;\;\;\;\;\;\;\text{and $H$ diverges} \tag{1} $$ We can write an equivalent formal sum of partial products $H'$ (2a). I don't know the exact term for the relationship between $H$ and $H'$ as formal expressions, but $\frac{1}{k}$ is finite and definitely equal to $\prod_{l=2}^{k} \frac{l-1}{l} $ . $$ H' \stackrel{\text{def}}{=} \sum_{k=1}^{\infty} \prod_{l=2}^{k} \frac{l-1}{l} \tag{2a} $$ $$ H' = 1 + \left(\frac{1}{2}\right) + \left(\frac{1}{2} \times \frac{2}{3} \right) \dots \tag{2b} $$ Squinting at the definition of $H'$ , we can come up with a stochastic process $\Psi$ . At every turn in $\Psi$ , we either stop immediately or add 1 to $t$ . If $t = 1$ , then advance to the next turn with probability $1$ . If $t \ne 1$ , then stop with probability $\frac{1}{t}$ and continue to the next turn with probability $\frac{t-1}{t}$ . If we take the output of $\Psi \;\;\text{mod}\;\; n$ for various values of $n$ , it seems to match $\ln\left(n\right)$ . n        Ψ mod n     ln(n) 2          0.693     0.693 3          1.099     1.099 4          1.386     1.386 5          1.609     1.609 6          1.793     1.792 7          1.947     1.946 Why should this be the case? Here is the python code used to produce samples: import random import math import os  STOP = ""STOP"" GO   = ""GO""  def step(n):     assert (n > 1)     if random.randint(1, n) == 1:         return STOP     else:         return GO   def walk_length():     n = 2     len_ = 1     while GO == step(n):         len_ += 1         n += 1     return len_   for x in range(1000000):     print(walk_length() % int(os.getenv(""MODULUS""))) and the summary script from here : #! /bin/sh  Rscript -e 'summary (as.numeric (readLines (""stdin"")));' A sample run. > env MODULUS=7 python process_steps.py | summary     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    0.000   1.000   1.000   1.947   3.000   6.000","Let a harmonic walk be a stochastic process where at turn the probability of ending the walk is and the first turn never ends the walk. A harmonic walk can be viewed as a distribution over without finite mean. Empirically, it seems to be the case that the average length of a harmonic walk mod is . I'm wondering why this should be the case. The definition of the harmonic series (1) looks similar to the integral definition of the natural log, , so there might be reason to suspect that a relationship might exist, but that resemblance isn't remotely convincing. The harmonic series is given below (1) with the symbol "" "" referring to the formal sum, not the value. We can write an equivalent formal sum of partial products (2a). I don't know the exact term for the relationship between and as formal expressions, but is finite and definitely equal to . Squinting at the definition of , we can come up with a stochastic process . At every turn in , we either stop immediately or add 1 to . If , then advance to the next turn with probability . If , then stop with probability and continue to the next turn with probability . If we take the output of for various values of , it seems to match . n        Ψ mod n     ln(n) 2          0.693     0.693 3          1.099     1.099 4          1.386     1.386 5          1.609     1.609 6          1.793     1.792 7          1.947     1.946 Why should this be the case? Here is the python code used to produce samples: import random import math import os  STOP = ""STOP"" GO   = ""GO""  def step(n):     assert (n > 1)     if random.randint(1, n) == 1:         return STOP     else:         return GO   def walk_length():     n = 2     len_ = 1     while GO == step(n):         len_ += 1         n += 1     return len_   for x in range(1000000):     print(walk_length() % int(os.getenv(""MODULUS""))) and the summary script from here : #! /bin/sh  Rscript -e 'summary (as.numeric (readLines (""stdin"")));' A sample run. > env MODULUS=7 python process_steps.py | summary     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    0.000   1.000   1.000   1.947   3.000   6.000",t \ge 2 \frac{1}{t} \mathbb{N}_{\ge 1} n \ln\left(n\right) \ln(x) \stackrel{\text{def}}{=} \int_{1}^{x} 1/s \;\text{ds}  H H  H \stackrel{\text{def}}{=} \sum_{k=1}^{\infty} \frac{1}{k} \;\;\;\;\;\;\;\;\text{and H diverges} \tag{1}  H' H H' \frac{1}{k} \prod_{l=2}^{k} \frac{l-1}{l}   H' \stackrel{\text{def}}{=} \sum_{k=1}^{\infty} \prod_{l=2}^{k} \frac{l-1}{l} \tag{2a}   H' = 1 + \left(\frac{1}{2}\right) + \left(\frac{1}{2} \times \frac{2}{3} \right) \dots \tag{2b}  H' \Psi \Psi t t = 1 1 t \ne 1 \frac{1}{t} \frac{t-1}{t} \Psi \;\;\text{mod}\;\; n n \ln\left(n\right),"['probability', 'sequences-and-series']"
98,"A box has three coins. One has two heads, another two tails and the last is a fair coin.","A box has three coins. One has two heads, another two tails and the last is a fair coin.",,"I am stuck on this question: A box has three coins. One has two heads, one has two tails, and the other is a fair coin with one head and one tail.  A coin is chosen at random, and comes up head. a) What is the probability that the coin chosen is the two headed coin b) What is the probability that if it is thrown another time it will come up heads c) What is the probability that the coin chosen is the two headed coin, supposing that the coin is thrown a second time and comes up heads again I have solved part a, and the answer is $\frac 23$ . However I am stuck on parts b and c.  This is my thought process: part b: P(Heads on the second throw) = P( $H_2$ | $H_1$ ) $\cdot$ P(fair coin) + P( $H_2$ | $H_1$ ) $\cdot$ P(coin with two heads) = $\frac 12$ $\cdot$ $\frac 13$ + 1 $\cdot$ $\frac 13$ = $\frac 12$ , and I'm not sure how to even start with part c. The answer to part b should be $\frac 56$ , but can anyone explain why?  Thanks.","I am stuck on this question: A box has three coins. One has two heads, one has two tails, and the other is a fair coin with one head and one tail.  A coin is chosen at random, and comes up head. a) What is the probability that the coin chosen is the two headed coin b) What is the probability that if it is thrown another time it will come up heads c) What is the probability that the coin chosen is the two headed coin, supposing that the coin is thrown a second time and comes up heads again I have solved part a, and the answer is . However I am stuck on parts b and c.  This is my thought process: part b: P(Heads on the second throw) = P( | ) P(fair coin) + P( | ) P(coin with two heads) = + 1 = , and I'm not sure how to even start with part c. The answer to part b should be , but can anyone explain why?  Thanks.",\frac 23 H_2 H_1 \cdot H_2 H_1 \cdot \frac 12 \cdot \frac 13 \cdot \frac 13 \frac 12 \frac 56,"['probability', 'statistics']"
99,Probability that a random triangle with vertices on a circle contains an arbitrary point inside said circle,Probability that a random triangle with vertices on a circle contains an arbitrary point inside said circle,,"What is the probability that a triangle with vertices uniformly randomly distributed on a circle contains the circle's centre ? This is already done (similar to Putnam 1992 A6). The answer is $\frac14$. Now, instead of generalising it to higher dimensions (where the answer is $\frac1{2^n}$ in $n$ dimensions), I wonder what the answer is when the point is not the centre of the circle: Given the unit circle and a point $P$ inside it with distance $d$ from the centre, what is the probability that when three points are randomly chosen on the circle, the triangle formed by those three points will contain $P$? I want to ask: is there a formula for the probability when $d$ changes? For example, the formula should give probability equal to $0$ when $d=1$ and give $\frac14$ when $d=0$. My attempt: Rotate the circle such that the point lies on the $x$-axis. Let $P=(d,0)$ and mark the three points on the circle $P_1,P_2$ and $P_3$. Then, given fixed $P_1$ and $P_2$, $P_3$ must lie in the arc formed by the intersection of $PP_1$ and $PP_2$ with the circle. I tried using clines to solve this problem, but it turns out to be very complicated and I don't think it's very suitable for me to use coordinates. Is this related to barycentric coordinates or complex numbers? Or is there even a non-geometric way to solve this? Please help :(","What is the probability that a triangle with vertices uniformly randomly distributed on a circle contains the circle's centre ? This is already done (similar to Putnam 1992 A6). The answer is $\frac14$. Now, instead of generalising it to higher dimensions (where the answer is $\frac1{2^n}$ in $n$ dimensions), I wonder what the answer is when the point is not the centre of the circle: Given the unit circle and a point $P$ inside it with distance $d$ from the centre, what is the probability that when three points are randomly chosen on the circle, the triangle formed by those three points will contain $P$? I want to ask: is there a formula for the probability when $d$ changes? For example, the formula should give probability equal to $0$ when $d=1$ and give $\frac14$ when $d=0$. My attempt: Rotate the circle such that the point lies on the $x$-axis. Let $P=(d,0)$ and mark the three points on the circle $P_1,P_2$ and $P_3$. Then, given fixed $P_1$ and $P_2$, $P_3$ must lie in the arc formed by the intersection of $PP_1$ and $PP_2$ with the circle. I tried using clines to solve this problem, but it turns out to be very complicated and I don't think it's very suitable for me to use coordinates. Is this related to barycentric coordinates or complex numbers? Or is there even a non-geometric way to solve this? Please help :(",,"['probability', 'geometry', 'circles', 'triangles', 'geometric-probability']"
