,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove that if $f$ is a diffeomorphism than its differential $D_{f}$ is an isomorphism,Prove that if  is a diffeomorphism than its differential  is an isomorphism,f D_{f},"I want to prove that if $f : U \to V$ , when $U,V \subset R^n$ , is a diffeomorphism than its differential $D_{f}$ is an isomorphism. Since $D_{f}$ is a linear transformation, isomorphism means that it's both injective and surjective. Moreover, $D_{f}$ is between two vector spaces with the same dimension (both are $R^{n*n}$ ) then we can use the dimension theorem for vector spaces. So we really need to prove only that $D_{f}$ is injective (or surjective). However, I don't really see how to do it. I know that $f$ is $C^1$ (continuously differential) and also $f^{-1}$ is $C^1$ . Maybe, because the inverse of $D_f$ is $D_{f^{-1}}$ . So if $D_f$ is not injective then it doesn't have an inverse - contradiction. I'm not really sure if I'm right here. Help would be appreciated.","I want to prove that if , when , is a diffeomorphism than its differential is an isomorphism. Since is a linear transformation, isomorphism means that it's both injective and surjective. Moreover, is between two vector spaces with the same dimension (both are ) then we can use the dimension theorem for vector spaces. So we really need to prove only that is injective (or surjective). However, I don't really see how to do it. I know that is (continuously differential) and also is . Maybe, because the inverse of is . So if is not injective then it doesn't have an inverse - contradiction. I'm not really sure if I'm right here. Help would be appreciated.","f : U \to V U,V \subset R^n D_{f} D_{f} D_{f} R^{n*n} D_{f} f C^1 f^{-1} C^1 D_f D_{f^{-1}} D_f","['multivariable-calculus', 'linear-transformations', 'vector-space-isomorphism', 'diffeomorphism']"
1,Product Rule for vector output functions,Product Rule for vector output functions,,"In Spivak's calculus of manifolds there is a product rule given as below. if $f,g:\mathbb{R}^n \rightarrow \mathbb{R}$ are differentiable at a, then $D(f*g)(a)=g(a)Df(a)+f(a)Dg(a).$ My question is, if this condition of  ' $f,g:\mathbb{R}^n \rightarrow \mathbb{R}$ ' is always necessary? What if we have vector valued output for each of the functions? Is there a generalized product rule? If not, how is this answer valid because $x^T$ and $Ax$ are surely not satisfying above condition.","In Spivak's calculus of manifolds there is a product rule given as below. if are differentiable at a, then My question is, if this condition of  ' ' is always necessary? What if we have vector valued output for each of the functions? Is there a generalized product rule? If not, how is this answer valid because and are surely not satisfying above condition.","f,g:\mathbb{R}^n \rightarrow \mathbb{R} D(f*g)(a)=g(a)Df(a)+f(a)Dg(a). f,g:\mathbb{R}^n \rightarrow \mathbb{R} x^T Ax","['multivariable-calculus', 'derivatives']"
2,"How to solve the integral $\int_{B(0,1)} xy(x+z)(y+z)dxdydz$?",How to solve the integral ?,"\int_{B(0,1)} xy(x+z)(y+z)dxdydz","How to solve the integral $$\int_{B(0,1)} xy(x+z)(y+z)dxdydz$$ where $B(0,1)=\{ (x,y,z) | x^2 + y^2 + z^2 < 1\}$ ? I tried using spherical coordinates, but it turned out ugly. I then tried solving without any substitution but it wasn't so pleasant as well. I think to use the substitution $u=xy, v = x+z, w = y+z$ but I can't determine the range. I also am not sure if it is a diffeomorphism. Any suggestions? Help would be appreciated","How to solve the integral where ? I tried using spherical coordinates, but it turned out ugly. I then tried solving without any substitution but it wasn't so pleasant as well. I think to use the substitution but I can't determine the range. I also am not sure if it is a diffeomorphism. Any suggestions? Help would be appreciated","\int_{B(0,1)} xy(x+z)(y+z)dxdydz B(0,1)=\{ (x,y,z) | x^2 + y^2 + z^2 < 1\} u=xy, v = x+z, w = y+z","['calculus', 'integration', 'multivariable-calculus']"
3,Sufficient condition for continuity of function of two variables,Sufficient condition for continuity of function of two variables,,"For a function of two variables to be continous, a sufficient condition is said to be that one of the partial derivatives exists and is bounded near the required point and the other partial derivative just exists at that point I cant understand how the bounded partial derivative helps in the proof.Please explain this to me Thanks in advance","For a function of two variables to be continous, a sufficient condition is said to be that one of the partial derivatives exists and is bounded near the required point and the other partial derivative just exists at that point I cant understand how the bounded partial derivative helps in the proof.Please explain this to me Thanks in advance",,"['multivariable-calculus', 'continuity']"
4,Principal curvatures of surface of revolution,Principal curvatures of surface of revolution,,"Consider the following surface of revolution: $$S(t,\theta)=(t,f(t)\cos\theta,f(t)\sin\theta)$$ To calculate its principal curvatures, first we calculate the coordinate tangent vectors, then normalize their cross product to get the unit normal vector $N$ . Finally, we calculate the shape operator using $S\partial_i=-D_{\partial_i}N$ . This is how I find principal curvatures for two dimensional, parameterized surfaces. But if I revolve the graph $(t,f(t))$ along $x$ -axis in $R^{n+1}$ , giving the surface, $$S(t,w)=(t,f(t)w)=(t,f(t)\cos\theta_1,f(t)\sin\theta_1\cos\theta_2,\cdots)$$ where $w$ is a direction in $S^n$ , how do I calculate its shape operator ? In particular, I am interested in its sectional and mean curvatures. My intuition says that the principal curvatures should be the same in all angular directions.","Consider the following surface of revolution: To calculate its principal curvatures, first we calculate the coordinate tangent vectors, then normalize their cross product to get the unit normal vector . Finally, we calculate the shape operator using . This is how I find principal curvatures for two dimensional, parameterized surfaces. But if I revolve the graph along -axis in , giving the surface, where is a direction in , how do I calculate its shape operator ? In particular, I am interested in its sectional and mean curvatures. My intuition says that the principal curvatures should be the same in all angular directions.","S(t,\theta)=(t,f(t)\cos\theta,f(t)\sin\theta) N S\partial_i=-D_{\partial_i}N (t,f(t)) x R^{n+1} S(t,w)=(t,f(t)w)=(t,f(t)\cos\theta_1,f(t)\sin\theta_1\cos\theta_2,\cdots) w S^n","['multivariable-calculus', 'differential-geometry', 'riemannian-geometry']"
5,Area of Cardioid $r=1+\sin(\theta)$ Using Green's Theorem,Area of Cardioid  Using Green's Theorem,r=1+\sin(\theta),"Find the area enclosed by $r=1+\sin \theta$ using Green's theorem. What I have is $\gamma(t)=(t,1+\sin t)$ $\gamma'(t)=(1,\cos t)$ Then $\frac{1}{2}\int_{0}^{2\pi}(-1-\sin t+t\cos t)dt=-\pi$ Is it correct?","Find the area enclosed by $r=1+\sin \theta$ using Green's theorem. What I have is $\gamma(t)=(t,1+\sin t)$ $\gamma'(t)=(1,\cos t)$ Then $\frac{1}{2}\int_{0}^{2\pi}(-1-\sin t+t\cos t)dt=-\pi$ Is it correct?",,"['calculus', 'multivariable-calculus']"
6,Surface integral - cone below plane,Surface integral - cone below plane,,"After several years I suddenly need to brush up on surface integrals. Looking through my old Calculus book I have been attempting to solve some problems, but the following problem has really made me hit a wall, even though it probably is quite easy to solve: Find $\int \int_S y dS$, where $S$ is part of the cone $z=\sqrt{2(x^2 + y^2)}$ that lies below the plane $z=1+y$. So far I have found that $dS = \sqrt{3}$, which then means I have to solve the integral: $$\sqrt{3}\int \int_S y dx dy$$. However, I am really stuck on how to proceed from here. I have tried looking at the intersection between the cone and the plane, and transforming the integral to polar coordinates, but can't seem to get anywhere. If someone can help me out a bit here, then I would greatly appreciate it!","After several years I suddenly need to brush up on surface integrals. Looking through my old Calculus book I have been attempting to solve some problems, but the following problem has really made me hit a wall, even though it probably is quite easy to solve: Find $\int \int_S y dS$, where $S$ is part of the cone $z=\sqrt{2(x^2 + y^2)}$ that lies below the plane $z=1+y$. So far I have found that $dS = \sqrt{3}$, which then means I have to solve the integral: $$\sqrt{3}\int \int_S y dx dy$$. However, I am really stuck on how to proceed from here. I have tried looking at the intersection between the cone and the plane, and transforming the integral to polar coordinates, but can't seem to get anywhere. If someone can help me out a bit here, then I would greatly appreciate it!",,"['multivariable-calculus', 'surface-integrals']"
7,evalute $\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx$ by polar coordinates,evalute  by polar coordinates,\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx,"$$\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx$$ After I sketch the area required, it is a right angle triangle with vertices $(0,0), (3,0), (3,3)$. Now I have to change it to polar coordinates to solve it. So, I know that $ dA = dx \ dy = r\ dr\ d{\theta}$ by solving the jacobian. the new integral should be something like $$ \iint_{D*}^{} 1\ dr\ d{\theta}$$ but I am having trouble determining the limits of $r$ and $\theta$. I think it should be $$0\le \theta \le \frac{\pi}{4}$$ and $$0\le r\le3.$$ Though I'm not sure about $r$.","$$\int_{0}^{3} \int_{0}^{x} \frac{1}{\sqrt{x^2+y^2}} dy \ dx$$ After I sketch the area required, it is a right angle triangle with vertices $(0,0), (3,0), (3,3)$. Now I have to change it to polar coordinates to solve it. So, I know that $ dA = dx \ dy = r\ dr\ d{\theta}$ by solving the jacobian. the new integral should be something like $$ \iint_{D*}^{} 1\ dr\ d{\theta}$$ but I am having trouble determining the limits of $r$ and $\theta$. I think it should be $$0\le \theta \le \frac{\pi}{4}$$ and $$0\le r\le3.$$ Though I'm not sure about $r$.",,"['integration', 'multivariable-calculus']"
8,Differentiability of $f$ if $f = \sum f_k$ and $f_k$ are differentiable at one point,Differentiability of  if  and  are differentiable at one point,f f = \sum f_k f_k,"Let $f:U\rightarrow \mathbb{R}^n$ be a function, where $U\subset \mathbb{R}^m$ is open. Suppose there exist functions $f_k:U\rightarrow \mathbb{R}^n,$ $k\in\mathbb{N}$, such that for all $x\in U$: $$f(x)=\sum_{k=1}^{\infty}f_k(x).$$ Moreover, suppose that each $f_k$ is differentiable at some point $x_0\in U$. Does this imply that $f$ is differentiable at $x_0$? Unfortunately, I do not know the answer. I checked some examples, and it seems to be correct. I would be thankful, if someone can help me.","Let $f:U\rightarrow \mathbb{R}^n$ be a function, where $U\subset \mathbb{R}^m$ is open. Suppose there exist functions $f_k:U\rightarrow \mathbb{R}^n,$ $k\in\mathbb{N}$, such that for all $x\in U$: $$f(x)=\sum_{k=1}^{\infty}f_k(x).$$ Moreover, suppose that each $f_k$ is differentiable at some point $x_0\in U$. Does this imply that $f$ is differentiable at $x_0$? Unfortunately, I do not know the answer. I checked some examples, and it seems to be correct. I would be thankful, if someone can help me.",,"['real-analysis', 'multivariable-calculus']"
9,What conditions would guarantee $\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2$ to be non-zero in a small neighbourhood?,What conditions would guarantee  to be non-zero in a small neighbourhood?,\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2,Suppose I have $\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2$ where  $\Psi(\mathbf{0}) = \mathbf{0}$. I would like to show that there exists a small open set $U$ around $\mathbf{0}$ such that it is non-zero for all points in $U \backslash \{ \mathbf{0} \}$. I am wondering what kind of conditions on $\Psi$ would ensure this is satisfied? Any comments are appreciated. Thank you.,Suppose I have $\Psi: \mathbb{R}^n \rightarrow \mathbb{R}^2$ where  $\Psi(\mathbf{0}) = \mathbf{0}$. I would like to show that there exists a small open set $U$ around $\mathbf{0}$ such that it is non-zero for all points in $U \backslash \{ \mathbf{0} \}$. I am wondering what kind of conditions on $\Psi$ would ensure this is satisfied? Any comments are appreciated. Thank you.,,"['multivariable-calculus', 'differential-geometry', 'maxima-minima']"
10,Finding critical points of a triple variable function,Finding critical points of a triple variable function,,"What are the critical points of the function: $f(x,y,z)=\frac{1}{z^2+x^2+1+y^2}$? Identify as a local minima, maxima, or saddle points. So I know you have to take the gradient and set it equal to $(0,0,0)$. That will get you all your critical points. How do I identify it as a local minima, maxima, or a saddle point?","What are the critical points of the function: $f(x,y,z)=\frac{1}{z^2+x^2+1+y^2}$? Identify as a local minima, maxima, or saddle points. So I know you have to take the gradient and set it equal to $(0,0,0)$. That will get you all your critical points. How do I identify it as a local minima, maxima, or a saddle point?",,"['multivariable-calculus', 'maxima-minima']"
11,"Integrate $e^{xy}$ over a hyperbolic ""rectangle""","Integrate  over a hyperbolic ""rectangle""",e^{xy},"While reviewing multivariate calculus with a student, I encountered this exercise: Evaluate the integral $\displaystyle\iint_We^{xy}\,\mathrm dx\,\mathrm dy$, where $W$ is the region bounded by $1\le xy\le4$ and $1\le\dfrac xy\le2$. I made the change of coordinates $$\begin{cases}u(x,y)=xy\\[1ex]v(x,y)=\dfrac xy\end{cases}$$ for which the Jacobian and its determinant are $$\mathbf J=\begin{bmatrix}y&x\\[1ex]\dfrac1y&-\dfrac x{y^2}\end{bmatrix},\quad\det\mathbf J=-\dfrac{2x}y=-2v$$ So the integral is $$\iint_We^{xy}\,\mathrm dx\,\mathrm dy=2\int_{v=1}^{v=2}\int_{u=1}^{u=4}ve^u\,\mathrm du\,\mathrm dv=3e^4-3e$$ I check my answer with Mathematica to find out the answer instead appears to be Integrate[     E^(x y) Boole[1 <= x y <= 4 && 1 <= x/y <= 2],     {x, 0, Infinity}, {y, 0, Infinity} ] which returns a different answer of $\dfrac{(e^4-e)\log2}2$. Is there a mistake in my work? Or is Mathematica correct? Or is the integral I'm computing with Integrate not equivalent to the one I'm supposed to compute?","While reviewing multivariate calculus with a student, I encountered this exercise: Evaluate the integral $\displaystyle\iint_We^{xy}\,\mathrm dx\,\mathrm dy$, where $W$ is the region bounded by $1\le xy\le4$ and $1\le\dfrac xy\le2$. I made the change of coordinates $$\begin{cases}u(x,y)=xy\\[1ex]v(x,y)=\dfrac xy\end{cases}$$ for which the Jacobian and its determinant are $$\mathbf J=\begin{bmatrix}y&x\\[1ex]\dfrac1y&-\dfrac x{y^2}\end{bmatrix},\quad\det\mathbf J=-\dfrac{2x}y=-2v$$ So the integral is $$\iint_We^{xy}\,\mathrm dx\,\mathrm dy=2\int_{v=1}^{v=2}\int_{u=1}^{u=4}ve^u\,\mathrm du\,\mathrm dv=3e^4-3e$$ I check my answer with Mathematica to find out the answer instead appears to be Integrate[     E^(x y) Boole[1 <= x y <= 4 && 1 <= x/y <= 2],     {x, 0, Infinity}, {y, 0, Infinity} ] which returns a different answer of $\dfrac{(e^4-e)\log2}2$. Is there a mistake in my work? Or is Mathematica correct? Or is the integral I'm computing with Integrate not equivalent to the one I'm supposed to compute?",,"['multivariable-calculus', 'definite-integrals', 'math-software']"
12,"Why can't a parameterization $c(t) = ( x(t), y(t) )$ describe a 2-dimensional surface in the plane?",Why can't a parameterization  describe a 2-dimensional surface in the plane?,"c(t) = ( x(t), y(t) )","Consider a parameterization  $$c(t) = (x(t), y(t)) $$ For every $t$, you have some $(x,y)$ output. This will be some curve in the plane. My textbook seems to imply that only a single parameter is needed for a curve because curves are 1-dimensional. Now consider a parametrization $$ g(u,v) = (x(u,v), y(u,v))$$ For every $(u,v)$ you have some $(x,y)$ output. This will be some surface in the plane. My textbook seems to imply that 2 parameters are needed for a surface because surfaces are 2-dimensional. So my question is, does a single parameter always result in a curve? Why can't the curve fold up on itself to form a 2-dimensional surface in the plane? And if we go beyond the plane, why can't a parameterization $c(t)$ give you a surface in 3-space (adding in a $z(t)$)or a volume in 3-space? If I just scribble my pen on a sheet of paper, I create a bunch of lines. But couldn't my scribbling form a surface if it was fine enough? I feel like this is getting into the ""philosophy of continuous mathematics."" Limits, continuous number lines, and whatnot as opposed to ""discrete mathematics"". Likewise, why can't $g(u,v)$ describe a volume? Does a single parameter always give a curve, 2 a surface, and 3 a volume?","Consider a parameterization  $$c(t) = (x(t), y(t)) $$ For every $t$, you have some $(x,y)$ output. This will be some curve in the plane. My textbook seems to imply that only a single parameter is needed for a curve because curves are 1-dimensional. Now consider a parametrization $$ g(u,v) = (x(u,v), y(u,v))$$ For every $(u,v)$ you have some $(x,y)$ output. This will be some surface in the plane. My textbook seems to imply that 2 parameters are needed for a surface because surfaces are 2-dimensional. So my question is, does a single parameter always result in a curve? Why can't the curve fold up on itself to form a 2-dimensional surface in the plane? And if we go beyond the plane, why can't a parameterization $c(t)$ give you a surface in 3-space (adding in a $z(t)$)or a volume in 3-space? If I just scribble my pen on a sheet of paper, I create a bunch of lines. But couldn't my scribbling form a surface if it was fine enough? I feel like this is getting into the ""philosophy of continuous mathematics."" Limits, continuous number lines, and whatnot as opposed to ""discrete mathematics"". Likewise, why can't $g(u,v)$ describe a volume? Does a single parameter always give a curve, 2 a surface, and 3 a volume?",,"['multivariable-calculus', 'surfaces', 'curves']"
13,"Does the curve $(t^2, t^5)$ have a tangent at the origin?",Does the curve  have a tangent at the origin?,"(t^2, t^5)","My question is whether or not the curve $x(t) = t^{2}, \ y(t) = t^{5}$ has a tangent at $(x, y) = (0, 0)$. I don't really know what to do if both $dy = dx = 0$, so I tried to take the limit $\lim_{t \to 0} \frac{dy}{dx} = \lim_{t \to 0}\frac{5t^{4}}{2t}$ which is zero. But does this mean the curve has a tangent, with slope $0$? My book is very unclear with this situation. Thanks!","My question is whether or not the curve $x(t) = t^{2}, \ y(t) = t^{5}$ has a tangent at $(x, y) = (0, 0)$. I don't really know what to do if both $dy = dx = 0$, so I tried to take the limit $\lim_{t \to 0} \frac{dy}{dx} = \lim_{t \to 0}\frac{5t^{4}}{2t}$ which is zero. But does this mean the curve has a tangent, with slope $0$? My book is very unclear with this situation. Thanks!",,"['multivariable-calculus', 'derivatives', 'tangent-line']"
14,Extremepoints of function with two variables,Extremepoints of function with two variables,,"$f(x,y)=x\cdot y(ax+by+c)\quad x,y>0\quad abc\neq 0\\ $ Partial Derivatives: ${ f }_{ x }=y(ax+by+c)+axy\\ { f }_{ y }=x(ax+by+c)+byx$ How do I find the critical Points out of The system of equations beneath, aren't they depended on the behaviour of a,b,c $y(ax+by+c)+axy=0$ $x(ax+by+c)+byx=0$","$f(x,y)=x\cdot y(ax+by+c)\quad x,y>0\quad abc\neq 0\\ $ Partial Derivatives: ${ f }_{ x }=y(ax+by+c)+axy\\ { f }_{ y }=x(ax+by+c)+byx$ How do I find the critical Points out of The system of equations beneath, aren't they depended on the behaviour of a,b,c $y(ax+by+c)+axy=0$ $x(ax+by+c)+byx=0$",,"['real-analysis', 'multivariable-calculus']"
15,"Computing a double integral by method of change of variables. I am having trouble determining a valid diffeomorphism that ""works"".","Computing a double integral by method of change of variables. I am having trouble determining a valid diffeomorphism that ""works"".",,"I am trying to compute the integral $$\iint_{R} sin(9x^2 + 4y^2) dA$$ where R is bounded by the region $9x^2 + 4y^2 = 36$, by the change of variables method. I am having trouble determining the proper transformation $G: \mathbb{R^2} \to R$ so that I can perform my change of variables. I have tried expressing the ellipsoid by transforming it into a circle (with radius 1) but that did not get me anywhere and hence I am really stuck. I'd appreciate any hints or ideas on how to approach these problems. More so, any general advice that you may have for finding a good transformation/diffeomorphism that works for the change of variables. Thanks!","I am trying to compute the integral $$\iint_{R} sin(9x^2 + 4y^2) dA$$ where R is bounded by the region $9x^2 + 4y^2 = 36$, by the change of variables method. I am having trouble determining the proper transformation $G: \mathbb{R^2} \to R$ so that I can perform my change of variables. I have tried expressing the ellipsoid by transforming it into a circle (with radius 1) but that did not get me anywhere and hence I am really stuck. I'd appreciate any hints or ideas on how to approach these problems. More so, any general advice that you may have for finding a good transformation/diffeomorphism that works for the change of variables. Thanks!",,['multivariable-calculus']
16,Computing flow of vectors fields with partial derivatives,Computing flow of vectors fields with partial derivatives,,"Define vector fields $X$ and $Y$ on the plane by $$ X = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y}, \qquad Y = x \dfrac{\partial}{\partial y} + y \dfrac{\partial}{\partial x}.$$ Compute the flows $\theta , \psi$ of $X$ and $Y$ , and verify that the flows do not commute by finding explicit open intervals $J$ and $K$ containing $0$ such that $\theta_s \circ \psi_t$ and $\psi_t \circ \theta_s$ are both defined for all $(s,t) \in J \times K$ , but they are unequal for some $(s,t)$ . To solve for the flow I need to solve the PDE. Every example I've encountered dealt with a simple ODE that could be solved via separation of variables. This makes for a dumb question but I've never taken a PDE course, so how do I solve the PDE? For the second part of the question, once I figure out how to solve the PDE, I think I'll be able to show they don't commute, just figured I'd post the full question.","Define vector fields and on the plane by Compute the flows of and , and verify that the flows do not commute by finding explicit open intervals and containing such that and are both defined for all , but they are unequal for some . To solve for the flow I need to solve the PDE. Every example I've encountered dealt with a simple ODE that could be solved via separation of variables. This makes for a dumb question but I've never taken a PDE course, so how do I solve the PDE? For the second part of the question, once I figure out how to solve the PDE, I think I'll be able to show they don't commute, just figured I'd post the full question.","X Y  X = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y}, \qquad Y = x \dfrac{\partial}{\partial y} + y \dfrac{\partial}{\partial x}. \theta , \psi X Y J K 0 \theta_s \circ \psi_t \psi_t \circ \theta_s (s,t) \in J \times K (s,t)","['multivariable-calculus', 'differential-geometry', 'partial-differential-equations', 'partial-derivative', 'vector-fields']"
17,How to find the point on the sphere that is closest to a plane?,How to find the point on the sphere that is closest to a plane?,,"Consider the plane $x+2y+2z=4$, how to find the point on the sphere $x^2+y^2+z^2=1$ that is closest to the plane? I could find the distance from the plane to the origin using the formula $D=\frac{|1\cdot 0+2\cdot 0+2\cdot 0-4|}{\sqrt{1^2+2^2+2^2}}=\frac43$, and then I can find the distance between the plane and sphere by subtracting the radius of sphere from plane-origin distance:$\frac43-1=\frac13$. But then I am stuck here because I don't know how to convert this distance into a direction vector, so I could subtract it from the plane to find the sphere point. Any help would be appreciated.","Consider the plane $x+2y+2z=4$, how to find the point on the sphere $x^2+y^2+z^2=1$ that is closest to the plane? I could find the distance from the plane to the origin using the formula $D=\frac{|1\cdot 0+2\cdot 0+2\cdot 0-4|}{\sqrt{1^2+2^2+2^2}}=\frac43$, and then I can find the distance between the plane and sphere by subtracting the radius of sphere from plane-origin distance:$\frac43-1=\frac13$. But then I am stuck here because I don't know how to convert this distance into a direction vector, so I could subtract it from the plane to find the sphere point. Any help would be appreciated.",,"['calculus', 'multivariable-calculus', 'vectors', 'spheres']"
18,Showing that a function is differentiable,Showing that a function is differentiable,,"So. I have to show that this functiun is differentiable outside of $(0,0)$ and also to calculate  its differentiation. $$f(x,y)=xy\frac{x^2-y^2}{x^2+y^2}$$ when $(x,y)$ is not equal to $(0,0)$ and $$f(x,y)=0$$ when $(x,y)$ is equal to $(0,0)$. Also we have to show that the function is differentiable on $(0,0)$ too. $$$$ Firstly I wanted to see if the functiun is continuous e.g: $$\lim_{(x,y)\to (0,0)}{xy\frac{x^2-y^2}{x^2+y^2}}=0$$ so it is countinous.$$$$ Than I wanted to see if it is differentiable but I don't know how to continue, all I got is: $$\lim_{(x,y)\to (0,0)} \frac{f(x,y)-f(0,0)}{(x,y)-(0,0)}=\lim_{(x,y)\to (0,0)}\frac{xy\frac{x^2-y^2}{x^2+y^2}}{\sqrt{x^2+y^2}}$$ Can someone put me on the right track? And explain me what am I doing wrong? I don't know how to continue it..","So. I have to show that this functiun is differentiable outside of $(0,0)$ and also to calculate  its differentiation. $$f(x,y)=xy\frac{x^2-y^2}{x^2+y^2}$$ when $(x,y)$ is not equal to $(0,0)$ and $$f(x,y)=0$$ when $(x,y)$ is equal to $(0,0)$. Also we have to show that the function is differentiable on $(0,0)$ too. $$$$ Firstly I wanted to see if the functiun is continuous e.g: $$\lim_{(x,y)\to (0,0)}{xy\frac{x^2-y^2}{x^2+y^2}}=0$$ so it is countinous.$$$$ Than I wanted to see if it is differentiable but I don't know how to continue, all I got is: $$\lim_{(x,y)\to (0,0)} \frac{f(x,y)-f(0,0)}{(x,y)-(0,0)}=\lim_{(x,y)\to (0,0)}\frac{xy\frac{x^2-y^2}{x^2+y^2}}{\sqrt{x^2+y^2}}$$ Can someone put me on the right track? And explain me what am I doing wrong? I don't know how to continue it..",,"['calculus', 'multivariable-calculus', 'differential-topology']"
19,Distance between surfaces,Distance between surfaces,,"I'm trying to find the minimal distance between the surfaces described by $z=x^2+y^2$ and $x+y-2z=8$. I would imagine there are several approaches including the use of Lagrange multipliers. I attempted to find the spot when their normal vectors are parallel ( since i believe if these vectors are not parallel there is a direction that will bring the distance lower). So if $U(x,y,z)=x^2+y^2$ and $V(x,y,z)=x+y-2z$ are functions describing these surfaces then their normal vectors are $(2x,2y,-1)$ and $(1,1-2)$ respectively. Then I want their cross product to be zero; this is at $(1/4,1/4,z)$. But when i solve for $z$ and I cannot simultaneously satisfy both equations. What gives?! Am I along the right line of thinking?","I'm trying to find the minimal distance between the surfaces described by $z=x^2+y^2$ and $x+y-2z=8$. I would imagine there are several approaches including the use of Lagrange multipliers. I attempted to find the spot when their normal vectors are parallel ( since i believe if these vectors are not parallel there is a direction that will bring the distance lower). So if $U(x,y,z)=x^2+y^2$ and $V(x,y,z)=x+y-2z$ are functions describing these surfaces then their normal vectors are $(2x,2y,-1)$ and $(1,1-2)$ respectively. Then I want their cross product to be zero; this is at $(1/4,1/4,z)$. But when i solve for $z$ and I cannot simultaneously satisfy both equations. What gives?! Am I along the right line of thinking?",,['multivariable-calculus']
20,"For which $a\in \mathbb{R}$ is $f(x,y) = \frac{xy^a}{x^2+y^2}$ with $f(0,0)=0$ continuous? [duplicate]",For which  is  with  continuous? [duplicate],"a\in \mathbb{R} f(x,y) = \frac{xy^a}{x^2+y^2} f(0,0)=0","This question already has answers here : Prove that $g(x,y) = \frac{x^3y}{x^2+y^2}$ with $g(0,0)=0$ is continuous (4 answers) Closed 7 years ago . My function is defined as: $$f(x,y) =  \begin{cases}        \dfrac{xy^a}{x^2+y^2}&(x,y) \neq (0,0)\\      \ 0&(x,y) = (0,0)    \end{cases} $$ I want to find out for which $a\in \mathbb{R}$ the function is continuous. I am not quite sure how to solve something like this. I know that for $a=1$ the function is definitely not continuous, which can be checked, since $(\frac1n,\frac1n)$ converges to $(0,0)$ but $f(\frac1n,\frac1n)$ does not. Now if I want $f$ to be steady in $(0,0)$, I figured that this is the case if $a>1$. But this is where I get stuck. How to I prove or check, if for $a>1$ the rest of the function is continuous as well? Any help is greatly appreciated!","This question already has answers here : Prove that $g(x,y) = \frac{x^3y}{x^2+y^2}$ with $g(0,0)=0$ is continuous (4 answers) Closed 7 years ago . My function is defined as: $$f(x,y) =  \begin{cases}        \dfrac{xy^a}{x^2+y^2}&(x,y) \neq (0,0)\\      \ 0&(x,y) = (0,0)    \end{cases} $$ I want to find out for which $a\in \mathbb{R}$ the function is continuous. I am not quite sure how to solve something like this. I know that for $a=1$ the function is definitely not continuous, which can be checked, since $(\frac1n,\frac1n)$ converges to $(0,0)$ but $f(\frac1n,\frac1n)$ does not. Now if I want $f$ to be steady in $(0,0)$, I figured that this is the case if $a>1$. But this is where I get stuck. How to I prove or check, if for $a>1$ the rest of the function is continuous as well? Any help is greatly appreciated!",,"['real-analysis', 'multivariable-calculus', 'continuity']"
21,Does there exist any continuous function whose partials doesn't exist?,Does there exist any continuous function whose partials doesn't exist?,,"Does there exist a continuous function of $f : \mathbb R^2 \longrightarrow \mathbb R$ such that it is continuous whose both the partial derivatives don't exist. I think the function $f : \mathbb R^2 \longrightarrow \mathbb R$ defined by $f(x,y) = |x|(1 + y)$, where $(x,y) \in \mathbb R^2$ has the above property at $(0,0)$. But I can't prove that $f$ is continuous at $(0,0)$ by $\epsilon-\delta$ method. Please help me. Thank you in advance.","Does there exist a continuous function of $f : \mathbb R^2 \longrightarrow \mathbb R$ such that it is continuous whose both the partial derivatives don't exist. I think the function $f : \mathbb R^2 \longrightarrow \mathbb R$ defined by $f(x,y) = |x|(1 + y)$, where $(x,y) \in \mathbb R^2$ has the above property at $(0,0)$. But I can't prove that $f$ is continuous at $(0,0)$ by $\epsilon-\delta$ method. Please help me. Thank you in advance.",,"['real-analysis', 'multivariable-calculus', 'continuity']"
22,limit of $\frac{x^2}{x^2+y^2}$,limit of,\frac{x^2}{x^2+y^2},"To prove $\frac{x^2}{x^2+y^2}$ has no limit at $(0,0)$ we can take $y=kx$ and therefore: $$\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2+y^2}=\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2+k^2x^2}=\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2(1+k^2)}=\lim_{(x,kx)\to (0,0)}\frac{1}{(1+k^2)}$$ For different $k$ we will get different limits, so there is no limit at $(0,0)$ But what about the limit at $(3,3)$ intuitively there is a limit which is $\frac{1}{2}$ but if we look at: $$\lim_{(x,kx)\to (3,3)}\frac{x^2}{x^2+y^2}$$ we get $$\lim_{(x,kx)\to (3,3)}\frac{1}{(1+k^2)}=?$$ Where am I getting it wrong?","To prove $\frac{x^2}{x^2+y^2}$ has no limit at $(0,0)$ we can take $y=kx$ and therefore: $$\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2+y^2}=\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2+k^2x^2}=\lim_{(x,kx)\to (0,0)}\frac{x^2}{x^2(1+k^2)}=\lim_{(x,kx)\to (0,0)}\frac{1}{(1+k^2)}$$ For different $k$ we will get different limits, so there is no limit at $(0,0)$ But what about the limit at $(3,3)$ intuitively there is a limit which is $\frac{1}{2}$ but if we look at: $$\lim_{(x,kx)\to (3,3)}\frac{x^2}{x^2+y^2}$$ we get $$\lim_{(x,kx)\to (3,3)}\frac{1}{(1+k^2)}=?$$ Where am I getting it wrong?",,"['real-analysis', 'multivariable-calculus']"
23,Maximizing the line integral over a line segment,Maximizing the line integral over a line segment,,"Let $f(x,y) = 8x + 6y$. Take $C$ to be the line segment with length $10$ starting at the point $(2,2)$. At what point should the line segment end for $$\int_C \nabla f\cdot d{\bf r}$$ to be maximized? I think I have an idea of how to approach the problem, but I wanted to know if there are any special properties that are immediate from the given problem that make this problem ""nice"". Here's my attempt : We want ${\bf r}(t) = \langle 2, 2\rangle + t\langle a-2, b-2\rangle$ such that $\|{\bf r}\| = 10$, for some point $(a,b)$ and $t\in[0,1]$. We know that $${\bf r}(1) = (a,b),$$ so we have that $a^2 + b^2 = 100$ implies that $b = \pm\sqrt{100 - a^2}$. Well, using the fundamental theorem of line integrals, we have that $$\begin{align}\int_C\nabla f\cdot{\bf r} & = f(a,b) - f(2,2)\\& = 8a + 6b - 28 \\ &= 8a + 6\pm\sqrt{100-a^2} - 28\end{align},$$ which considering the positive root, we have a maximum of $10\sqrt{65} - 22 \approx 58.6$ at $a = 16\sqrt{5\over13}$, and the negative root has a maximum of $58$ at $a = 10$. Obviously $58.6 > 58$, so we only worry about the positive root. Therefore, when $a = 16\sqrt{5\over13}$, $b = 2\sqrt{5\over13}$. This seems to be correct (I haven't checked the answer and can't unfortunately), but I don't know if this is even the way you're expected to do this problem. Would anyone happen to know of a better way?","Let $f(x,y) = 8x + 6y$. Take $C$ to be the line segment with length $10$ starting at the point $(2,2)$. At what point should the line segment end for $$\int_C \nabla f\cdot d{\bf r}$$ to be maximized? I think I have an idea of how to approach the problem, but I wanted to know if there are any special properties that are immediate from the given problem that make this problem ""nice"". Here's my attempt : We want ${\bf r}(t) = \langle 2, 2\rangle + t\langle a-2, b-2\rangle$ such that $\|{\bf r}\| = 10$, for some point $(a,b)$ and $t\in[0,1]$. We know that $${\bf r}(1) = (a,b),$$ so we have that $a^2 + b^2 = 100$ implies that $b = \pm\sqrt{100 - a^2}$. Well, using the fundamental theorem of line integrals, we have that $$\begin{align}\int_C\nabla f\cdot{\bf r} & = f(a,b) - f(2,2)\\& = 8a + 6b - 28 \\ &= 8a + 6\pm\sqrt{100-a^2} - 28\end{align},$$ which considering the positive root, we have a maximum of $10\sqrt{65} - 22 \approx 58.6$ at $a = 16\sqrt{5\over13}$, and the negative root has a maximum of $58$ at $a = 10$. Obviously $58.6 > 58$, so we only worry about the positive root. Therefore, when $a = 16\sqrt{5\over13}$, $b = 2\sqrt{5\over13}$. This seems to be correct (I haven't checked the answer and can't unfortunately), but I don't know if this is even the way you're expected to do this problem. Would anyone happen to know of a better way?",,"['integration', 'multivariable-calculus', 'proof-verification', 'vectors']"
24,How can I mathematically model a pringle as a function?,How can I mathematically model a pringle as a function?,,I need to translate the dimensions of a pringle chip into a mathematical function to calculate the surface area of hyperbolic paraboloids. How can I do this?,I need to translate the dimensions of a pringle chip into a mathematical function to calculate the surface area of hyperbolic paraboloids. How can I do this?,,"['multivariable-calculus', 'quadrics']"
25,Taylor Expansion of log determinant of a matrix,Taylor Expansion of log determinant of a matrix,,"I came across this matrix expansion based on Taylor expansion, which I could not derive: let $A=(\Sigma(\theta^{'})-\Sigma(\theta))\Sigma^{-1}(\theta)$, $$\log\det(I+A)=tr(A)-R_3$$ with $$R_3\le c_3\sum_{i=1}^p\lambda_i^2$$ where $p$ is the dimension of $A$,$c_3$ is some constant, and $\lambda$s are the eigenvalues of $A$. Could anyone provide any hint on how to derive this equality for expansion or at least the inequality for bounding the $\log\det(I+A)$? Is this a problem on Taylor expansion of a function of single variable $\theta$? I can understand this result is reasonable, since first term is first order ($\sum_i\lambda_i$), the second term is bounded by second order terms. However, I cannot find a direct formula to derive this. Maybe relevant: in Anderson Intro to multivariate statistics, it has a Theorem A.4.8 states that: $$\det(I+xC)=1+xtr(C)+O(x^2),$$ could be useful?","I came across this matrix expansion based on Taylor expansion, which I could not derive: let $A=(\Sigma(\theta^{'})-\Sigma(\theta))\Sigma^{-1}(\theta)$, $$\log\det(I+A)=tr(A)-R_3$$ with $$R_3\le c_3\sum_{i=1}^p\lambda_i^2$$ where $p$ is the dimension of $A$,$c_3$ is some constant, and $\lambda$s are the eigenvalues of $A$. Could anyone provide any hint on how to derive this equality for expansion or at least the inequality for bounding the $\log\det(I+A)$? Is this a problem on Taylor expansion of a function of single variable $\theta$? I can understand this result is reasonable, since first term is first order ($\sum_i\lambda_i$), the second term is bounded by second order terms. However, I cannot find a direct formula to derive this. Maybe relevant: in Anderson Intro to multivariate statistics, it has a Theorem A.4.8 states that: $$\det(I+xC)=1+xtr(C)+O(x^2),$$ could be useful?",,"['linear-algebra', 'multivariable-calculus']"
26,"Proving a function is not differentiable, when its partials are not continuous","Proving a function is not differentiable, when its partials are not continuous",,"Let $$f(x,y)=\frac{y \sin (3 x)}{\sqrt{x^2+y^2}},$$ and $f(0,0)=0$. I'm trying to prove that it's not differentiable in $(0,0)$. Some my plan was to compute the limit of the definition of differentiability, and check that it doesn't exist. However, when I try to calculate the partial derivatives, I get $$\frac{\partial f}{\partial x}=\frac{3 y \cos (3 x)}{\sqrt{x^2+y^2}}-\frac{x y \sin (3 x)}{\left(x^2+y^2\right)^{3/2}}.$$ Should I just assume that this partial derivative can be extended by continuity, or should I prove it? If I convert to spherical coordinates, I get zero as the limit. I'm not sure if the teacher had this in mind, or I'm doing some mistake... Any help would be appreciated.","Let $$f(x,y)=\frac{y \sin (3 x)}{\sqrt{x^2+y^2}},$$ and $f(0,0)=0$. I'm trying to prove that it's not differentiable in $(0,0)$. Some my plan was to compute the limit of the definition of differentiability, and check that it doesn't exist. However, when I try to calculate the partial derivatives, I get $$\frac{\partial f}{\partial x}=\frac{3 y \cos (3 x)}{\sqrt{x^2+y^2}}-\frac{x y \sin (3 x)}{\left(x^2+y^2\right)^{3/2}}.$$ Should I just assume that this partial derivative can be extended by continuity, or should I prove it? If I convert to spherical coordinates, I get zero as the limit. I'm not sure if the teacher had this in mind, or I'm doing some mistake... Any help would be appreciated.",,"['multivariable-calculus', 'derivatives']"
27,Distance in 3-space between two parallel vectors,Distance in 3-space between two parallel vectors,,"I know these two lines are parallel, but I don't know how to find the distance between them. Any suggestions? Line 1: (3, 4, 7) + {6, 2, 4}t Line 2: (-1, 5, -1) + {3, 1, 2}t I tried creating a triangle composed of an orthogonal line to both lines (the shortest distance between the lines), a hypotenuse that connects the two known points (3, 4, 7) and (-1, 5, -1), and a leg that connects (-1, 5, -1) to the intersection of the orthogonal line on line 2. On line 1, the point (3, 4, 7) was the intersection of the orthogonal line and the hypotenuse. I'm sorry if that doesn't make any sense, I did my best. I have no idea how to include pictures on this website, this is my first post. And this is not a homework assignment, it's a practice problem for a Multivariable Calculus class. I'm studying for a test we have next week. Any and all help is appreciated!","I know these two lines are parallel, but I don't know how to find the distance between them. Any suggestions? Line 1: (3, 4, 7) + {6, 2, 4}t Line 2: (-1, 5, -1) + {3, 1, 2}t I tried creating a triangle composed of an orthogonal line to both lines (the shortest distance between the lines), a hypotenuse that connects the two known points (3, 4, 7) and (-1, 5, -1), and a leg that connects (-1, 5, -1) to the intersection of the orthogonal line on line 2. On line 1, the point (3, 4, 7) was the intersection of the orthogonal line and the hypotenuse. I'm sorry if that doesn't make any sense, I did my best. I have no idea how to include pictures on this website, this is my first post. And this is not a homework assignment, it's a practice problem for a Multivariable Calculus class. I'm studying for a test we have next week. Any and all help is appreciated!",,"['calculus', 'multivariable-calculus']"
28,How to solve this double integral involving trig substitution (using tangent function)?,How to solve this double integral involving trig substitution (using tangent function)?,,"This is a question I came across and I cannot find the answer. By using a substitution involving the tangent function, show that $$\int_0^1\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy\,dx=\frac{\pi}{4}$$ My attempt I use trig substitution, by saying $$\tan(\theta)=\frac{y}{x}$$ which means  $$x\sec^2(\theta)\,d\theta=dy$$ Also, it should be noted that because of this  $$x\sec(\theta)=\sqrt{x^2+y^2}$$ $$x^4\sec^4(\theta)=(x^2+y^2)^2 $$ Thus, when I substitute this information into the integral, I get $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2-(x^2\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)} \, d\theta \,dx$$ Then, this simplifies to $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2(1-\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx$$ $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2\sec^2(\theta)}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx=\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})}{\frac{1}{x}}\,d\theta \,dx$$ which leads to $$\int_0^1 \left[\frac \theta x \right]_0^{\arctan\left(\frac{1}{x}\right)} \,dx = \int_0^1 \frac{\arctan\left(\frac{1}{x}\right)}{x}                   \, dx_{(3)} $$ At this point I am stuck.  How do I evaluate this integral.  Am I on the right path?  Wolfram Alpha gives an answer other than $\frac{\pi}{4}$ for (3), so I am not sure where I am wrong.","This is a question I came across and I cannot find the answer. By using a substitution involving the tangent function, show that $$\int_0^1\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}\,dy\,dx=\frac{\pi}{4}$$ My attempt I use trig substitution, by saying $$\tan(\theta)=\frac{y}{x}$$ which means  $$x\sec^2(\theta)\,d\theta=dy$$ Also, it should be noted that because of this  $$x\sec(\theta)=\sqrt{x^2+y^2}$$ $$x^4\sec^4(\theta)=(x^2+y^2)^2 $$ Thus, when I substitute this information into the integral, I get $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2-(x^2\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)} \, d\theta \,dx$$ Then, this simplifies to $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2(1-\tan^2(\theta))}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx$$ $$\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})} \frac{x^2\sec^2(\theta)}{x^4\sec^4(\theta)}{x\sec^2(\theta)}\,d\theta \,dx=\int_0^1\int_{\theta=0}^{\arctan(\frac{1}{x})}{\frac{1}{x}}\,d\theta \,dx$$ which leads to $$\int_0^1 \left[\frac \theta x \right]_0^{\arctan\left(\frac{1}{x}\right)} \,dx = \int_0^1 \frac{\arctan\left(\frac{1}{x}\right)}{x}                   \, dx_{(3)} $$ At this point I am stuck.  How do I evaluate this integral.  Am I on the right path?  Wolfram Alpha gives an answer other than $\frac{\pi}{4}$ for (3), so I am not sure where I am wrong.",,"['integration', 'multivariable-calculus']"
29,"Finding extrema of $f(x,y) = sin(xy)$",Finding extrema of,"f(x,y) = sin(xy)","I did calculate $f_{xy}(x,y)$ and $f_{yx}(x,y)$ and equating them gives the expression $$\tan(xy)=-\frac{xy}{2}$$ and equating $f_x(x,y)=0$ and $f_y(x,y)=0$ gives $$xy=(2m+1)\frac{\pi}{2}$$ These are the expressions I got: $$f_x(x,y) = y\cos(xy)$$ $$f_y(x,y) = x\cos(xy)$$ $$f_{xx}(x,y) = -y^2\sin(xy)$$ $$f_{yy}(x,y) = -x^2\sin(xy)$$ $$f_{xy}(x,y) = -2y\sin(xy)-xy^2\cos(xy)$$ $$f_{yy}(x,y) = -2x\sin(xy)-x^2y\cos(xy)$$ How do I move from here?",I did calculate and and equating them gives the expression and equating and gives These are the expressions I got: How do I move from here?,"f_{xy}(x,y) f_{yx}(x,y) \tan(xy)=-\frac{xy}{2} f_x(x,y)=0 f_y(x,y)=0 xy=(2m+1)\frac{\pi}{2} f_x(x,y) = y\cos(xy) f_y(x,y) = x\cos(xy) f_{xx}(x,y) = -y^2\sin(xy) f_{yy}(x,y) = -x^2\sin(xy) f_{xy}(x,y) = -2y\sin(xy)-xy^2\cos(xy) f_{yy}(x,y) = -2x\sin(xy)-x^2y\cos(xy)",['multivariable-calculus']
30,Quotient of multivariable differentiable functions,Quotient of multivariable differentiable functions,,"Let $E$ be an open subset of $\mathbb{R}^n$ and $f,g:E\to \mathbb{R}^1$ be differentiable functions with $g\neq 0$ on $E$. How to prove that $\dfrac{f}{g}$ is also differentiable? I can't prove this rigorously. Can anyone show the full proof? I would be very thankful!","Let $E$ be an open subset of $\mathbb{R}^n$ and $f,g:E\to \mathbb{R}^1$ be differentiable functions with $g\neq 0$ on $E$. How to prove that $\dfrac{f}{g}$ is also differentiable? I can't prove this rigorously. Can anyone show the full proof? I would be very thankful!",,['multivariable-calculus']
31,The Relation Between Kronecker's Delta and the Permutation Symbol,The Relation Between Kronecker's Delta and the Permutation Symbol,,"The Kronecker's Delta is defined as $$\delta_{ij}= \begin{cases} 1 & i=j \\ 0 & i \ne j \end{cases}$$ Also, the Permuation Symbol known as Levi Cevita 's Symbol is introduced as $$\varepsilon_{ijk}= \begin{cases} 1 & \text{$ijk$ is an even permutation of $123$} \\ -1 & \text{$ijk$ is an odd permutation of $123$} \\ 0 & \text{$ijk$ has two same indices} \end{cases}$$ where $i$, $j$, and $k$ are natural numbers $1,2,3$. These symbols are widely used in vector and tensor analysis and in differential geometry. There is a relation between them as the following theorem states. Theorem. The following relation holds between the Kronecker's Delta and permutation symbol   $$\varepsilon_{ijk}\varepsilon_{pqr}= \begin{vmatrix} \delta_{ip} & \delta_{iq} & \delta_{ir} \\ \delta_{jp} & \delta_{jq} & \delta_{jr} \\ \delta_{kp} & \delta_{kq} & \delta_{kr} \\ \end {vmatrix}$$   where $|\cdot|$ denotes the determinant. I am looking for different proofs of this theorem.  Also, I don't want to prove it by just investigating that the equality holds for different choices of the indices one by one! I don't have any idea to take a first step. Any hint or help is appreciated. :)","The Kronecker's Delta is defined as $$\delta_{ij}= \begin{cases} 1 & i=j \\ 0 & i \ne j \end{cases}$$ Also, the Permuation Symbol known as Levi Cevita 's Symbol is introduced as $$\varepsilon_{ijk}= \begin{cases} 1 & \text{$ijk$ is an even permutation of $123$} \\ -1 & \text{$ijk$ is an odd permutation of $123$} \\ 0 & \text{$ijk$ has two same indices} \end{cases}$$ where $i$, $j$, and $k$ are natural numbers $1,2,3$. These symbols are widely used in vector and tensor analysis and in differential geometry. There is a relation between them as the following theorem states. Theorem. The following relation holds between the Kronecker's Delta and permutation symbol   $$\varepsilon_{ijk}\varepsilon_{pqr}= \begin{vmatrix} \delta_{ip} & \delta_{iq} & \delta_{ir} \\ \delta_{jp} & \delta_{jq} & \delta_{jr} \\ \delta_{kp} & \delta_{kq} & \delta_{kr} \\ \end {vmatrix}$$   where $|\cdot|$ denotes the determinant. I am looking for different proofs of this theorem.  Also, I don't want to prove it by just investigating that the equality holds for different choices of the indices one by one! I don't have any idea to take a first step. Any hint or help is appreciated. :)",,"['multivariable-calculus', 'differential-geometry', 'permutations', 'tensors', 'kronecker-symbol']"
32,Does the Divergence Theorem hold for arbitrary tensor fields?,Does the Divergence Theorem hold for arbitrary tensor fields?,,"So, a heads up, this is my first post and I'm a fairly new user.  Additionally, my math knowledge tops out at vector calculus and ODEs, but don't shy away from answering beyond my understanding should it be necessary. Anyway, my question is simply whether the divergence theorem holds for fields other than general 3-vector fields, and if so, what changes.  I imagine the dot product would be become an inner product and the gradient operator would have to evolve somehow, but I have no idea how. For simplicity, I think it can be assumed that I'm asking whether the divergence theorem holds for rank-2 tensors. Thanks in advance for any insight.","So, a heads up, this is my first post and I'm a fairly new user.  Additionally, my math knowledge tops out at vector calculus and ODEs, but don't shy away from answering beyond my understanding should it be necessary. Anyway, my question is simply whether the divergence theorem holds for fields other than general 3-vector fields, and if so, what changes.  I imagine the dot product would be become an inner product and the gradient operator would have to evolve somehow, but I have no idea how. For simplicity, I think it can be assumed that I'm asking whether the divergence theorem holds for rank-2 tensors. Thanks in advance for any insight.",,"['multivariable-calculus', 'tensors']"
33,Divergence $0$ everywhere implies Flux $0$?,Divergence  everywhere implies Flux ?,0 0,"I was told this by a college mate, and I was pretty unsure as to why/if this is true. Consider the vectorfield $F=(1,1,1)$, it clearly has divergence $0$ at every point, but, picturing it in my head, I think the flux should not be $0$ for at least some surfaces (a plane normal to the vectors, for example). I'm saying this because of my intuition about these concepts: consider said vector field representing some liquid moving, then If I place a grid (plane said above) I clearly have some liquid flowing through it, thus the flux should not be 0... Where am I wrong?","I was told this by a college mate, and I was pretty unsure as to why/if this is true. Consider the vectorfield $F=(1,1,1)$, it clearly has divergence $0$ at every point, but, picturing it in my head, I think the flux should not be $0$ for at least some surfaces (a plane normal to the vectors, for example). I'm saying this because of my intuition about these concepts: consider said vector field representing some liquid moving, then If I place a grid (plane said above) I clearly have some liquid flowing through it, thus the flux should not be 0... Where am I wrong?",,"['multivariable-calculus', 'vectors']"
34,"$f:\mathbb R^{2} \rightarrow \mathbb R$ s.t ${f(x,y)}={{xy}\over {x^{2}+y}}$ is not continuous at the origin",s.t  is not continuous at the origin,"f:\mathbb R^{2} \rightarrow \mathbb R {f(x,y)}={{xy}\over {x^{2}+y}}","$f:\mathbb R^{2} \rightarrow  \mathbb R$  is  defined  as $${f(x,y)}={{xy}\over {x^{2}+y}}$$; when  $x^{2}+y\neq 0$ and $$f(x,y)=0$$  otherwise. To  show  this  is  not  continuous  at  the  origin .  A  hint  is  given  as  to  go  along  the  line $y=mx$ . So  along  that  line  $$f(x,y)=f(x,mx)={{mx^{2}}\over {x^{2}+mx}}$$  $$={{mx}\over {x+m}}$$ Taking  limit  tending  to  $0$ , we  have  $$\lim_{x\rightarrow 0 }f(x,y) =0=f(0,0)$$ Then  where  is  the  contradiction  to  continuity  by  moving  along  $y=mx$ $?$","$f:\mathbb R^{2} \rightarrow  \mathbb R$  is  defined  as $${f(x,y)}={{xy}\over {x^{2}+y}}$$; when  $x^{2}+y\neq 0$ and $$f(x,y)=0$$  otherwise. To  show  this  is  not  continuous  at  the  origin .  A  hint  is  given  as  to  go  along  the  line $y=mx$ . So  along  that  line  $$f(x,y)=f(x,mx)={{mx^{2}}\over {x^{2}+mx}}$$  $$={{mx}\over {x+m}}$$ Taking  limit  tending  to  $0$ , we  have  $$\lim_{x\rightarrow 0 }f(x,y) =0=f(0,0)$$ Then  where  is  the  contradiction  to  continuity  by  moving  along  $y=mx$ $?$",,"['real-analysis', 'multivariable-calculus', 'continuity']"
35,What is an example of Gâteaux differentiable but not Fréchet differentiable at a point in a finite-dimensional space?,What is an example of Gâteaux differentiable but not Fréchet differentiable at a point in a finite-dimensional space?,,"Let $V,W$ be nonzero normed spaces over $\mathbb{K}$ such that $V$ is finite-dimensional. Let $E$ open in $\mathbb{K}$ and $p\in E$. Let $f:E\rightarrow W$ be Gâteaux-differentiable at $p$. Is $f$ necessarily Fréchet-differentiable at $p$ in this case? I think this is not true in general, but cannot find a counterexample. What would be a counterexample?","Let $V,W$ be nonzero normed spaces over $\mathbb{K}$ such that $V$ is finite-dimensional. Let $E$ open in $\mathbb{K}$ and $p\in E$. Let $f:E\rightarrow W$ be Gâteaux-differentiable at $p$. Is $f$ necessarily Fréchet-differentiable at $p$ in this case? I think this is not true in general, but cannot find a counterexample. What would be a counterexample?",,"['multivariable-calculus', 'examples-counterexamples', 'gateaux-derivative']"
36,"Is the set of all $(x,y,z)$ such that $z^2-x^2-y^2-1 = 0$ open or closed?",Is the set of all  such that  open or closed?,"(x,y,z) z^2-x^2-y^2-1 = 0","As the title says, is the set of all $(x,y,z)$ such that $z^2-x^2-y^2-1 = 0$ open or closed? Moreover, how can I prove it? I understand the definition of open and closed sets, but I don't get this exercise yet. I've been trying this for days. Thanks for all help you can give me. Regards!","As the title says, is the set of all $(x,y,z)$ such that $z^2-x^2-y^2-1 = 0$ open or closed? Moreover, how can I prove it? I understand the definition of open and closed sets, but I don't get this exercise yet. I've been trying this for days. Thanks for all help you can give me. Regards!",,"['real-analysis', 'multivariable-calculus']"
37,Multivariable Calculus: Line Integral,Multivariable Calculus: Line Integral,,"I have this math problem. It states: Calculate the given line integral $\oint _c {M dx+Ndy}$ where $C$ is   the triangle with vertices $P_0=(0, 1)$, $P_1=(2, 1)$, $P_2=(3, 4)$   with counterclockwise rotation. Here is the problem:  $\oint _c {x dx+ dy}$ I'm not sure as to what the ""counterclockwise rotation"" means. I'm assuming I have to start by finding 3 different line integrals. So I find three parametric lines... $\vec{P_0} + \vec{P_0P_1}t=<0, 1> + <2t, 0> = <2t, 1>$ $\vec{P_1} + \vec{P_1P_2}t=<2, 1> + <t, 3t> = <2+t, 1+3t>$ $\vec{P_2} + \vec{P_2P_0}t=<3, 4> + <-3t, -3t> = <3-3t, 4-3t>$ That's pretty much where I got. Thanks for the help.","I have this math problem. It states: Calculate the given line integral $\oint _c {M dx+Ndy}$ where $C$ is   the triangle with vertices $P_0=(0, 1)$, $P_1=(2, 1)$, $P_2=(3, 4)$   with counterclockwise rotation. Here is the problem:  $\oint _c {x dx+ dy}$ I'm not sure as to what the ""counterclockwise rotation"" means. I'm assuming I have to start by finding 3 different line integrals. So I find three parametric lines... $\vec{P_0} + \vec{P_0P_1}t=<0, 1> + <2t, 0> = <2t, 1>$ $\vec{P_1} + \vec{P_1P_2}t=<2, 1> + <t, 3t> = <2+t, 1+3t>$ $\vec{P_2} + \vec{P_2P_0}t=<3, 4> + <-3t, -3t> = <3-3t, 4-3t>$ That's pretty much where I got. Thanks for the help.",,"['multivariable-calculus', 'vector-fields', 'line-integrals']"
38,Let $\alpha(s)$ be a unit speed curve in $R^2$. Show $\kappa=|\frac{d\theta}{ds}|$,Let  be a unit speed curve in . Show,\alpha(s) R^2 \kappa=|\frac{d\theta}{ds}|,"I'm lost on solving the following problem. Let $\alpha(s)$ be a unit speed curve in $R^2$. Show $\kappa=|\frac{d\theta}{ds}|$, where $\theta$ is the angle between the positive $x$-axis and the tangent line to the curve $\alpha$ measured in the counterclockwise sense. I'm used to curves in $R^3$ and I'm not sure how to tackle this problem, which is restricted to $R^2$. I don't know what property of curvature I should be using. I would greatly appreciate any solutions, hints or suggestions.","I'm lost on solving the following problem. Let $\alpha(s)$ be a unit speed curve in $R^2$. Show $\kappa=|\frac{d\theta}{ds}|$, where $\theta$ is the angle between the positive $x$-axis and the tangent line to the curve $\alpha$ measured in the counterclockwise sense. I'm used to curves in $R^3$ and I'm not sure how to tackle this problem, which is restricted to $R^2$. I don't know what property of curvature I should be using. I would greatly appreciate any solutions, hints or suggestions.",,"['multivariable-calculus', 'differential-geometry', 'vector-analysis']"
39,Multivariable taylor polynomial,Multivariable taylor polynomial,,"$$f(x, y) = e^{2x+xy+y^2}$$ Find the 2nd order taylor polynomial to the above function about (0,0) The formula is: $$P(x,y)=f(a,b)+f_x(a,b)(x-a)+f_y(a,b)(y-b)+\frac 12[f_{xx}(x-a)^2+2f_{xy}(x-a)(y-b)+f_{yy}(y-b)^2]$$ $$f_x=e^{2x+xy+y^2}(2+y)$$ $$f_y=e^{2x+xy+y^2}(x+2y)$$ $$f_{xx}=e^{2x+xy+y^2}(2+y)^2$$ $$f_{yy}=e^{2x+xy+y^2}(x+2y)^2+2e^{2x+xy+y^2}$$ $$f_{xy}=e^{2x+xy+y^2}(2+y)(x+2y)+e^{2x+xy+y^2}$$ But I still get the wrong answer. What I am doing wrong?","$$f(x, y) = e^{2x+xy+y^2}$$ Find the 2nd order taylor polynomial to the above function about (0,0) The formula is: $$P(x,y)=f(a,b)+f_x(a,b)(x-a)+f_y(a,b)(y-b)+\frac 12[f_{xx}(x-a)^2+2f_{xy}(x-a)(y-b)+f_{yy}(y-b)^2]$$ $$f_x=e^{2x+xy+y^2}(2+y)$$ $$f_y=e^{2x+xy+y^2}(x+2y)$$ $$f_{xx}=e^{2x+xy+y^2}(2+y)^2$$ $$f_{yy}=e^{2x+xy+y^2}(x+2y)^2+2e^{2x+xy+y^2}$$ $$f_{xy}=e^{2x+xy+y^2}(2+y)(x+2y)+e^{2x+xy+y^2}$$ But I still get the wrong answer. What I am doing wrong?",,['multivariable-calculus']
40,Integral over the unit ball,Integral over the unit ball,,"This question has been asked before, but I did not understand it, so I worked on it on my own and got stuck. Any help would be appreciated. Let $A$ be the region in $\Bbb R^2$ bounded by the curve $x^2-xy+2y^2=1$. Express the integral $\int _A xy$ as an integral over the unit ball in $\Bbb R^2$ centered at $0$. Hint: Complete the square. This is how far I could go and stuck: $x^2-xy-2y^2=\frac 78 x^2+(\frac18 x^2-xy+2y^2)=(\sqrt \frac 78 x)^2+(\frac1{2\sqrt2 x}-\sqrt 2 y)^2$ Then, I set $u=\frac 78 x, v=\frac1{2\sqrt2 x}-\sqrt 2 y$ I do not know how from this I can proceed to use the change of variables theorem. Thanks in advance!","This question has been asked before, but I did not understand it, so I worked on it on my own and got stuck. Any help would be appreciated. Let $A$ be the region in $\Bbb R^2$ bounded by the curve $x^2-xy+2y^2=1$. Express the integral $\int _A xy$ as an integral over the unit ball in $\Bbb R^2$ centered at $0$. Hint: Complete the square. This is how far I could go and stuck: $x^2-xy-2y^2=\frac 78 x^2+(\frac18 x^2-xy+2y^2)=(\sqrt \frac 78 x)^2+(\frac1{2\sqrt2 x}-\sqrt 2 y)^2$ Then, I set $u=\frac 78 x, v=\frac1{2\sqrt2 x}-\sqrt 2 y$ I do not know how from this I can proceed to use the change of variables theorem. Thanks in advance!",,"['calculus', 'real-analysis', 'integration', 'multivariable-calculus']"
41,"Find $\mathbf{F}$ such that $\nabla \times \mathbf{F} = (-3xz^2, 0, z^3)$",Find  such that,"\mathbf{F} \nabla \times \mathbf{F} = (-3xz^2, 0, z^3)","Let $S$ be the surface defined by $z = x^{2} + y^{2}$ for $z \leq 4$, oriented   with upward-pointing normal. Use Stokes' theorem to evaluate   $\iint_{S}\left(\, -3xz^{2}\ ,\ 0\ ,\ z^{3}\,\right)\cdot{\rm d}\mathbf{S}$. Hint: You may look for a vector field   $ \mathbf{F} = M\left(\,x,y,z\,\right)\mathbf{i} + N\left(\,x,y,z\,\right)\mathbf{j} $   such that $\nabla \times \mathbf{F} = (-3xz^2, 0, z^3)$. The question itself is straightforward except the fact that we need to find out $\mathbf{F}$. Upon expanding $\nabla \times \mathbf{F}$, we get $$(-\frac{dN}{dz}, \frac{dM}{dz}, \frac{dN}{dx}-\frac{dM}{dy})=(-3xz^2, 0, z^3).$$ Problem arises as I try to find out $M$ and $N$. First, I have $$N = xz^3 + g(x,y)$$for some function $g$.It then gives $$\frac{dM}{dy}=g_x$$ which I cannot proceed. Is it even possible to find out $M$ and $N$ explicitly? Or do I need to solve the above question without finding $M$ and $N$?","Let $S$ be the surface defined by $z = x^{2} + y^{2}$ for $z \leq 4$, oriented   with upward-pointing normal. Use Stokes' theorem to evaluate   $\iint_{S}\left(\, -3xz^{2}\ ,\ 0\ ,\ z^{3}\,\right)\cdot{\rm d}\mathbf{S}$. Hint: You may look for a vector field   $ \mathbf{F} = M\left(\,x,y,z\,\right)\mathbf{i} + N\left(\,x,y,z\,\right)\mathbf{j} $   such that $\nabla \times \mathbf{F} = (-3xz^2, 0, z^3)$. The question itself is straightforward except the fact that we need to find out $\mathbf{F}$. Upon expanding $\nabla \times \mathbf{F}$, we get $$(-\frac{dN}{dz}, \frac{dM}{dz}, \frac{dN}{dx}-\frac{dM}{dy})=(-3xz^2, 0, z^3).$$ Problem arises as I try to find out $M$ and $N$. First, I have $$N = xz^3 + g(x,y)$$for some function $g$.It then gives $$\frac{dM}{dy}=g_x$$ which I cannot proceed. Is it even possible to find out $M$ and $N$ explicitly? Or do I need to solve the above question without finding $M$ and $N$?",,['multivariable-calculus']
42,What quantity does a line integral represent?,What quantity does a line integral represent?,,"I'm currently trying to wrap my head around line integrals, Green's theorem, and vector fields and I'm having a bit of difficulty understanding what a line integral represents geometrically. Is it basically the arc length of a curve, for a scalar field? And then when you bring the concept into a vector field, then what does it represent?","I'm currently trying to wrap my head around line integrals, Green's theorem, and vector fields and I'm having a bit of difficulty understanding what a line integral represents geometrically. Is it basically the arc length of a curve, for a scalar field? And then when you bring the concept into a vector field, then what does it represent?",,"['multivariable-calculus', 'vector-analysis', 'vectors']"
43,Evaluating a double integral from zero to infinity,Evaluating a double integral from zero to infinity,,"How do I evaluate this integral? I don't understand at which point the limit notation should set in? And my method yields $0$ in the end. The integral is: $$ \int_0^{\infty} \int_0^{\infty} c\,x\,y\,e^{-(x+y)} \;\mathrm{d}y\;\mathrm{d}x $$","How do I evaluate this integral? I don't understand at which point the limit notation should set in? And my method yields $0$ in the end. The integral is: $$ \int_0^{\infty} \int_0^{\infty} c\,x\,y\,e^{-(x+y)} \;\mathrm{d}y\;\mathrm{d}x $$",,"['calculus', 'integration', 'multivariable-calculus', 'probability-distributions', 'improper-integrals']"
44,Absolute Max/Min of a function of two variables on a set?,Absolute Max/Min of a function of two variables on a set?,,"How do you find the absolute maximum/minimum values of the function $f(x,y) = x^2 + y^2 - 8y + 16$ on the given set R where $R = {(x,y): x^2 + y^2 ≤ 25}$ I know the absolute maximum is 81 and minimum is 0. How exactly does this work? I have seen something about converting the inequality in the set into an equality and then plugging it back into the equation. Every way I do this seems to be wrong and my book skips way too many steps to help. Thanks.","How do you find the absolute maximum/minimum values of the function $f(x,y) = x^2 + y^2 - 8y + 16$ on the given set R where $R = {(x,y): x^2 + y^2 ≤ 25}$ I know the absolute maximum is 81 and minimum is 0. How exactly does this work? I have seen something about converting the inequality in the set into an equality and then plugging it back into the equation. Every way I do this seems to be wrong and my book skips way too many steps to help. Thanks.",,['multivariable-calculus']
45,Finding the Limits of the Triple Integral (Spherical Coordinates),Finding the Limits of the Triple Integral (Spherical Coordinates),,"Let $D$ be the region in $\mathbb{R}^3$ below $z=-\sqrt{x^2 + y^2}$ and above $z=-\sqrt{4-x^2 -y^2}$. Rewrite \begin{align*}\iiint \limits_D z^2 dV\end{align*} using Spherical Coordinates. I rewrote the integral in spherical coordinates, and now know that it is as follows:  \begin{align*}\iiint \limits_D z^2 dV &= \int\limits_{\theta_0}^{\theta_1}\int \limits_{\phi_1}^{\phi_2}\int\limits_{\rho_1}^{\rho_2}(\rho^4\cos^2{\phi}sin{\phi})d\rho d\phi d\theta \end{align*} My problem, however, is finding the limits for $\rho, \phi$ and $\theta$ in the triple integral. I am having some trouble finding these limits. Can somebody please assist me, as I honestly have no idea how to go about doing so for this question. EDIT: $\textbf{I have to draw a sketch of the region $D$ in the given question (but I am struggling to do so)}$ and use that to find the limits.","Let $D$ be the region in $\mathbb{R}^3$ below $z=-\sqrt{x^2 + y^2}$ and above $z=-\sqrt{4-x^2 -y^2}$. Rewrite \begin{align*}\iiint \limits_D z^2 dV\end{align*} using Spherical Coordinates. I rewrote the integral in spherical coordinates, and now know that it is as follows:  \begin{align*}\iiint \limits_D z^2 dV &= \int\limits_{\theta_0}^{\theta_1}\int \limits_{\phi_1}^{\phi_2}\int\limits_{\rho_1}^{\rho_2}(\rho^4\cos^2{\phi}sin{\phi})d\rho d\phi d\theta \end{align*} My problem, however, is finding the limits for $\rho, \phi$ and $\theta$ in the triple integral. I am having some trouble finding these limits. Can somebody please assist me, as I honestly have no idea how to go about doing so for this question. EDIT: $\textbf{I have to draw a sketch of the region $D$ in the given question (but I am struggling to do so)}$ and use that to find the limits.",,"['integration', 'multivariable-calculus', 'spherical-coordinates']"
46,Stokes' Theorem - Stuck with a non-elementary integral,Stokes' Theorem - Stuck with a non-elementary integral,,"The following is an old exam problem (Calc III). It looks simple and technical, but I end up with a difficult integral and I guess I have a mistake somewhere. We are given the vector field $F(x,y,z)=(4z+2xy,x^2+z^2,2yz+x)$. We are asked to calculate the line integral $\int_{C} \vec{F} \cdot d\vec{r}$, where $C$ is the intersection of the conic $z=\sqrt{x^2+y^2}$ and the cylinder $x^2+(y-1)^2=1$. Stokes' Theorem allows us to replace the required integral with $\int_{S} \text{Curl}\vec{F} \cdot \hat{n} dS$, where $S$ is a surface bounded by $C$, and $\hat{n}$ is a normal to that surface. The curl is $\text{Curl}\vec{F}=(0,3,0)$, so the integral simplifies to $3 \int_{S} (0,1,0) \cdot \hat{n} dS$. I choose the surface to be $(x,y,\sqrt{x^2+y^2})$ with $x^2+(y-1)^2 \le 1$. I choose the parametrization $x=r\cos\theta, y=1+r\sin\theta$, and ended up with the integral $\int_{0}^{1} \int_{0}^{2\pi} \frac{r^2 \sin\theta +r}{\sqrt{r^2+1+2r\sin\theta}} dr d\theta$. I know how to solve similar integrals but this specific one seems non-elementary. What am I doing wrong?","The following is an old exam problem (Calc III). It looks simple and technical, but I end up with a difficult integral and I guess I have a mistake somewhere. We are given the vector field $F(x,y,z)=(4z+2xy,x^2+z^2,2yz+x)$. We are asked to calculate the line integral $\int_{C} \vec{F} \cdot d\vec{r}$, where $C$ is the intersection of the conic $z=\sqrt{x^2+y^2}$ and the cylinder $x^2+(y-1)^2=1$. Stokes' Theorem allows us to replace the required integral with $\int_{S} \text{Curl}\vec{F} \cdot \hat{n} dS$, where $S$ is a surface bounded by $C$, and $\hat{n}$ is a normal to that surface. The curl is $\text{Curl}\vec{F}=(0,3,0)$, so the integral simplifies to $3 \int_{S} (0,1,0) \cdot \hat{n} dS$. I choose the surface to be $(x,y,\sqrt{x^2+y^2})$ with $x^2+(y-1)^2 \le 1$. I choose the parametrization $x=r\cos\theta, y=1+r\sin\theta$, and ended up with the integral $\int_{0}^{1} \int_{0}^{2\pi} \frac{r^2 \sin\theta +r}{\sqrt{r^2+1+2r\sin\theta}} dr d\theta$. I know how to solve similar integrals but this specific one seems non-elementary. What am I doing wrong?",,['multivariable-calculus']
47,no diffeomorphism from $\mathbb{R}^2 \to \mathbb{R}^3$,no diffeomorphism from,\mathbb{R}^2 \to \mathbb{R}^3,"Show there is exist no diffeomorphism from $\mathbb{R}^2 \to \mathbb{R}^3$ PS: Don't say $\mathbb{R}^2,\mathbb{R}^3$ aren't homeomorphic, I need explanation without using topology","Show there is exist no diffeomorphism from $\mathbb{R}^2 \to \mathbb{R}^3$ PS: Don't say $\mathbb{R}^2,\mathbb{R}^3$ aren't homeomorphic, I need explanation without using topology",,['multivariable-calculus']
48,"Double integration:$ \int_0^a \int_0^b e^{max(b^2x^2,a^2y^2)}dydx $",Double integration:," \int_0^a \int_0^b e^{max(b^2x^2,a^2y^2)}dydx ","I would be grateful for a little help if someone could help me solve a problem in my textbook. The question is, evaluate $ \int_0^a  \int_0^b e^{max(b^2x^2,a^2y^2)}dydx  $, where $a,b$ are positive numbers and $max(b^2x^2,a^2y^2)=b^2x^2$ if $b^2x^2 \geq a^2y^2$ and $a^2y^2$ if $b^2x^2 < a^2y^2$. I've studied double integrals, but I'm not sure how to solve this question. I've looked at the answer sheet, and it says $\int_0^a  \int_0^{bx/a} e^{b^2x^2}dydx + \int_0^b  \int_0^{ay/b} e^{a^2y^2}dxdy$ but I don't really understand the meaning of this. Could someone lend me a hand?","I would be grateful for a little help if someone could help me solve a problem in my textbook. The question is, evaluate $ \int_0^a  \int_0^b e^{max(b^2x^2,a^2y^2)}dydx  $, where $a,b$ are positive numbers and $max(b^2x^2,a^2y^2)=b^2x^2$ if $b^2x^2 \geq a^2y^2$ and $a^2y^2$ if $b^2x^2 < a^2y^2$. I've studied double integrals, but I'm not sure how to solve this question. I've looked at the answer sheet, and it says $\int_0^a  \int_0^{bx/a} e^{b^2x^2}dydx + \int_0^b  \int_0^{ay/b} e^{a^2y^2}dxdy$ but I don't really understand the meaning of this. Could someone lend me a hand?",,"['calculus', 'multivariable-calculus']"
49,Mass of ellipsoid,Mass of ellipsoid,,"We are given the elipsoid $$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2} \leq 1$$ with density function $$p(x,y,z)=x^2+y^2+z^2$$ Find the mass of the elipsoid. I used the transformation $x=ar\sin\theta \cos\phi$ , $y=br\sin \theta \sin \phi$ and $z=cr\cos\theta$ . Spherical coordinates but I multiplied $x,y,z$ by $a,b,c$ respectively. I calculate the jacobian of this transformation, it is $abcr^2\sin\theta$ . So the mass is $$\int_{0}^{2\pi} \int_{0}^{\pi}\int_{0}^{1}(a^2r^2\sin^2\theta \cos^2\phi+b^2r^2\sin^2 \theta \sin ^2\phi+c^2r^2\cos^2 \theta)abcr^2\sin\theta drd\theta d\phi$$ But I'm having trouble calculating this integral. I thought maybe we can use that $$\sin^2x+\cos^2x=1$$ but because the coefficients are different it's difficult to use that here. How would I calculate this integral?","We are given the elipsoid with density function Find the mass of the elipsoid. I used the transformation , and . Spherical coordinates but I multiplied by respectively. I calculate the jacobian of this transformation, it is . So the mass is But I'm having trouble calculating this integral. I thought maybe we can use that but because the coefficients are different it's difficult to use that here. How would I calculate this integral?","\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2} \leq 1 p(x,y,z)=x^2+y^2+z^2 x=ar\sin\theta \cos\phi y=br\sin \theta \sin \phi z=cr\cos\theta x,y,z a,b,c abcr^2\sin\theta \int_{0}^{2\pi} \int_{0}^{\pi}\int_{0}^{1}(a^2r^2\sin^2\theta \cos^2\phi+b^2r^2\sin^2 \theta \sin ^2\phi+c^2r^2\cos^2 \theta)abcr^2\sin\theta drd\theta d\phi \sin^2x+\cos^2x=1","['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'ellipsoids']"
50,"Find the area of the surface of revolution generated by revolving about the $x$-axis the hypocycloid $x=a\cos^3\theta$, $y=a\sin^3\theta$","Find the area of the surface of revolution generated by revolving about the -axis the hypocycloid ,",x x=a\cos^3\theta y=a\sin^3\theta,"Find the area of the surface of revolution generated by revolving about the $x$-axis the hypocycloid $x=a\cos^3\theta$, $y=a\sin^3\theta$ ($0 \leq \theta \leq \pi$) I know you have to integrate $2\pi y ds$ for the limits $0$ to $\pi$ and I know that $ds$ is the square root of the sum of each derivative squared but I'm stuck on the integration, how do we do it? Please help!","Find the area of the surface of revolution generated by revolving about the $x$-axis the hypocycloid $x=a\cos^3\theta$, $y=a\sin^3\theta$ ($0 \leq \theta \leq \pi$) I know you have to integrate $2\pi y ds$ for the limits $0$ to $\pi$ and I know that $ds$ is the square root of the sum of each derivative squared but I'm stuck on the integration, how do we do it? Please help!",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
51,Does the existence of partial derivatives imply Frechet differentiability?,Does the existence of partial derivatives imply Frechet differentiability?,,"Let $f : \mathbb R^n \rightarrow \mathbb R^m$ and $a \in \mathbb R^n$such that $\forall i \in [1,n], \large \frac{\partial f}{\partial x_i}(a)$ exists. Is $f$ Frechet differentiable ? I'd say no, but I don't know any counter-examples...","Let $f : \mathbb R^n \rightarrow \mathbb R^m$ and $a \in \mathbb R^n$such that $\forall i \in [1,n], \large \frac{\partial f}{\partial x_i}(a)$ exists. Is $f$ Frechet differentiable ? I'd say no, but I don't know any counter-examples...",,"['multivariable-calculus', 'derivatives']"
52,Show that $f$ is constant on each sphere in $\mathbb{R}^3$ centered at the origin,Show that  is constant on each sphere in  centered at the origin,f \mathbb{R}^3,"Hi everyone this is a past exam question that I am studying as I go through my class that I am having trouble with, the full question is this: Let $f:\mathbb{R}^3 \rightarrow \mathbb{R}$ be a differentiable function and suppose that $$ \nabla f(\textbf{x}) = g(\textbf{x})\textbf{x} $$ for all $\textbf{x} \in \mathbb{R}^3$ where $g: \mathbb{R}^3 \rightarrow \mathbb{R}$  is a function. Show that $f$ is constant on each sphere in $\mathbb{R}^3$ centered at $(0,0,0)$. i.e. show that if $\textbf{a}$, $\textbf{b}$ $\in \mathbb{R}^3$ and $\|\textbf{a}\| = \|\textbf{b}\|$ then $f(\textbf{a}) = f(\textbf{b})$. I'm stuck on this question and not sure which direction to take. I'm really just throwing ideas around. I do know that the gradient vector at $\textbf{a}$ is perpendicular to all the tangent lines to the level set $f^{-1}(c)$ at $\textbf{a}$. Then letting $\textbf{x} = h(t) = (h_{1}(t), h_{2}(t), h_{3}(t))$ with $h(0)= \textbf{a}$. I have $f(h(\textbf{0}))=c$. Then taking derivatives: $$\frac{d}{dt}f(h(\textbf{0})) = \frac{d}{dt} c = 0$$ $$h'(0) \cdot \bigtriangledown f(h(\textbf{0})) = 0$$ Substituting in for $f(h(\textbf{0}))$ yields $$h'(0) \cdot g(\textbf{a})\textbf{a} = 0$$ Now i'm really not sure where to go from here, how relate the magnitude of $\textbf{a}$ or $\textbf{b}$ to the question (do i need to parametrise?) I would really appreciate some guidance with this question.","Hi everyone this is a past exam question that I am studying as I go through my class that I am having trouble with, the full question is this: Let $f:\mathbb{R}^3 \rightarrow \mathbb{R}$ be a differentiable function and suppose that $$ \nabla f(\textbf{x}) = g(\textbf{x})\textbf{x} $$ for all $\textbf{x} \in \mathbb{R}^3$ where $g: \mathbb{R}^3 \rightarrow \mathbb{R}$  is a function. Show that $f$ is constant on each sphere in $\mathbb{R}^3$ centered at $(0,0,0)$. i.e. show that if $\textbf{a}$, $\textbf{b}$ $\in \mathbb{R}^3$ and $\|\textbf{a}\| = \|\textbf{b}\|$ then $f(\textbf{a}) = f(\textbf{b})$. I'm stuck on this question and not sure which direction to take. I'm really just throwing ideas around. I do know that the gradient vector at $\textbf{a}$ is perpendicular to all the tangent lines to the level set $f^{-1}(c)$ at $\textbf{a}$. Then letting $\textbf{x} = h(t) = (h_{1}(t), h_{2}(t), h_{3}(t))$ with $h(0)= \textbf{a}$. I have $f(h(\textbf{0}))=c$. Then taking derivatives: $$\frac{d}{dt}f(h(\textbf{0})) = \frac{d}{dt} c = 0$$ $$h'(0) \cdot \bigtriangledown f(h(\textbf{0})) = 0$$ Substituting in for $f(h(\textbf{0}))$ yields $$h'(0) \cdot g(\textbf{a})\textbf{a} = 0$$ Now i'm really not sure where to go from here, how relate the magnitude of $\textbf{a}$ or $\textbf{b}$ to the question (do i need to parametrise?) I would really appreciate some guidance with this question.",,['multivariable-calculus']
53,How is the entropy of the multivariate normal distribution with mean 0 calculated?,How is the entropy of the multivariate normal distribution with mean 0 calculated?,,"Here is what I have so far: $$\begin{align} h(x) &= - \int \frac{1}{(2\pi)^{\frac{D}{2}}\det\Sigma^{\frac{1}{2}}} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) \ln \frac{1}{(2\pi)^{\frac{D}{2}}\det\Sigma^{\frac{1}{2}}} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) dx \\ &= \frac{1}{2} \ln ((2\pi)^D\det\Sigma) + \frac{1}{2}\int \frac{x^T \Sigma^{-1} x}{(2\pi)^{\frac{D}{2}}\det \Sigma} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) \end{align}$$ Having solved the 1D case, I assume the trick is to show that the remaining integral is similar to $\Sigma$, but I'm not good with multidimensional calculus.","Here is what I have so far: $$\begin{align} h(x) &= - \int \frac{1}{(2\pi)^{\frac{D}{2}}\det\Sigma^{\frac{1}{2}}} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) \ln \frac{1}{(2\pi)^{\frac{D}{2}}\det\Sigma^{\frac{1}{2}}} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) dx \\ &= \frac{1}{2} \ln ((2\pi)^D\det\Sigma) + \frac{1}{2}\int \frac{x^T \Sigma^{-1} x}{(2\pi)^{\frac{D}{2}}\det \Sigma} \exp(-\frac{1}{2} x^T\Sigma^{-1}x) \end{align}$$ Having solved the 1D case, I assume the trick is to show that the remaining integral is similar to $\Sigma$, but I'm not good with multidimensional calculus.",,"['multivariable-calculus', 'normal-distribution', 'entropy']"
54,Explain the equation of the tangent plane?,Explain the equation of the tangent plane?,,"So I'm doing my assignment to calculate the equation of a tangent plane at some point. I stumble upon a page on the web that says that an equation of a tangent plane to the surface $z=f(x, y)$ at the point $(x_0, y_0, z_0)$ is $$z-z_0 = f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0)$$ My professor also used this equation at some point. My question is, how was this equation derived? Can you explain to me the parts of this equation and why it works? Thanks.","So I'm doing my assignment to calculate the equation of a tangent plane at some point. I stumble upon a page on the web that says that an equation of a tangent plane to the surface $z=f(x, y)$ at the point $(x_0, y_0, z_0)$ is $$z-z_0 = f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0)$$ My professor also used this equation at some point. My question is, how was this equation derived? Can you explain to me the parts of this equation and why it works? Thanks.",,"['calculus', 'multivariable-calculus', 'differential-geometry']"
55,"Conflicting answers, chain rule","Conflicting answers, chain rule",,"Let: $g:\mathbb{R}^2\rightarrow\mathbb{R}^2$ and $g(x,y) = (x^2-y^2,2xy)$ $f:\mathbb{R}^2\rightarrow\mathbb{R}$ and $f(u,v) = u^2+v^2$ first compute the 2x2 matrix $(Dg)(x,y)$ (don't know why it's written like that, compute the total derivative of g at (x,y) Easy, $\frac{\partial{g}}{\partial{x}}=(2x,2y)$ and $\frac{\partial{g}}{\partial{y}}=(-2y,2x)$ $$\begin{pmatrix}2x&&-2y\\2y&&2x\end{pmatrix}$$ second Calculate $\nabla f(u,v) = (2u,2v)$ third Use thee chain rule to calculate $D(f$ composed $g)(x,y)$ $D_a(f(g))=D_{g(a)}f$ composed $D_ag$ (total derivative at a point a=(x,y)) $D_{g(a)}f = \nabla f(x^2-y^2,2xy) = (2x^2-2y^2,4xy)$ Which is: $$\begin{pmatrix}2x&&-2y\\2y&&2x\end{pmatrix}*\begin{pmatrix}2x^2-2y^2\\4xy\end{pmatrix}$$ That gives the vector: $(2x(2x^2-2y^2-4y^2),2y(2x^2+2y^2))$ which I believe contains a sign error at the -4. $f(g(x,y))=f(x^2-y^2,2xy)=(x^2-y^2)^2+4x^2y^2=x^4-2x^2y^2+y^4+4x^2y^2=x^2+2x^2y^2+y^4=(x^2+y^2)^2$ So $\nabla(f(g(x,y)) = (2(x^2+y^2)2x,2(x^2+y^2)2y)$ (I haven't said any more in my workings, I have just checked over and over again, you an see that, without that potential sign error, this'd work) My notation is particularly weak here, so any help (defining what things mean) would be gratefully received for example $\nabla(f(g(x,y))$ Invites one to use the chain rule, although it denotes that I substituted.","Let: $g:\mathbb{R}^2\rightarrow\mathbb{R}^2$ and $g(x,y) = (x^2-y^2,2xy)$ $f:\mathbb{R}^2\rightarrow\mathbb{R}$ and $f(u,v) = u^2+v^2$ first compute the 2x2 matrix $(Dg)(x,y)$ (don't know why it's written like that, compute the total derivative of g at (x,y) Easy, $\frac{\partial{g}}{\partial{x}}=(2x,2y)$ and $\frac{\partial{g}}{\partial{y}}=(-2y,2x)$ $$\begin{pmatrix}2x&&-2y\\2y&&2x\end{pmatrix}$$ second Calculate $\nabla f(u,v) = (2u,2v)$ third Use thee chain rule to calculate $D(f$ composed $g)(x,y)$ $D_a(f(g))=D_{g(a)}f$ composed $D_ag$ (total derivative at a point a=(x,y)) $D_{g(a)}f = \nabla f(x^2-y^2,2xy) = (2x^2-2y^2,4xy)$ Which is: $$\begin{pmatrix}2x&&-2y\\2y&&2x\end{pmatrix}*\begin{pmatrix}2x^2-2y^2\\4xy\end{pmatrix}$$ That gives the vector: $(2x(2x^2-2y^2-4y^2),2y(2x^2+2y^2))$ which I believe contains a sign error at the -4. $f(g(x,y))=f(x^2-y^2,2xy)=(x^2-y^2)^2+4x^2y^2=x^4-2x^2y^2+y^4+4x^2y^2=x^2+2x^2y^2+y^4=(x^2+y^2)^2$ So $\nabla(f(g(x,y)) = (2(x^2+y^2)2x,2(x^2+y^2)2y)$ (I haven't said any more in my workings, I have just checked over and over again, you an see that, without that potential sign error, this'd work) My notation is particularly weak here, so any help (defining what things mean) would be gratefully received for example $\nabla(f(g(x,y))$ Invites one to use the chain rule, although it denotes that I substituted.",,"['multivariable-calculus', 'partial-derivative']"
56,Triple Integral $ \iiint\limits_S\frac1{\sqrt{\left(x-a\right)^{2}+\left(y-b\right)^{2}+\left(z-c\right)^{2}}}\;dx\;dy\;dz $,Triple Integral, \iiint\limits_S\frac1{\sqrt{\left(x-a\right)^{2}+\left(y-b\right)^{2}+\left(z-c\right)^{2}}}\;dx\;dy\;dz ,"I used spherical coordinates and couldn't calculate this triple integral. $$ \iiint_S\frac1{\sqrt{\left(x-a\right)^{2}+\left(y-b\right)^{2}+\left(z-c\right)^{2}}}\;dx\;dy\;dz $$ where $S$ is a solid sphere of radius $R$ and center at the origin, and $\left ( a,b,c \right )$ is a fixed point outside this sphere.","I used spherical coordinates and couldn't calculate this triple integral. $$ \iiint_S\frac1{\sqrt{\left(x-a\right)^{2}+\left(y-b\right)^{2}+\left(z-c\right)^{2}}}\;dx\;dy\;dz $$ where $S$ is a solid sphere of radius $R$ and center at the origin, and $\left ( a,b,c \right )$ is a fixed point outside this sphere.",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
57,"How to calculate $f'(t)$, where $f:I\to\mathbb{R}^{n^2}$ is given by $f(t)=X(t)^k$?","How to calculate , where  is given by ?",f'(t) f:I\to\mathbb{R}^{n^2} f(t)=X(t)^k,"Let $I$ be a interval, $\mathbb{R}^{n^2}$ be the set of all $n\times n$ matrices and $X:I \to\mathbb{R}^{n^2}$ be a differentiable function. Given $k\in\mathbb{N}$, define $f:I\to\mathbb{R}^{n^2}$ by $f(t)=X(t)^k$. How to calculate $f'(t)$ for all $t\in I$? Thanks.","Let $I$ be a interval, $\mathbb{R}^{n^2}$ be the set of all $n\times n$ matrices and $X:I \to\mathbb{R}^{n^2}$ be a differentiable function. Given $k\in\mathbb{N}$, define $f:I\to\mathbb{R}^{n^2}$ by $f(t)=X(t)^k$. How to calculate $f'(t)$ for all $t\in I$? Thanks.",,['multivariable-calculus']
58,"Stereographic projection when the ""North/South Pole"" is not given by $(0,...,\pm 1)$?","Stereographic projection when the ""North/South Pole"" is not given by ?","(0,...,\pm 1)","Straight forward enough...  what if  My point is arbitrary, how can I get a new stereographic projection?","Straight forward enough...  what if  My point is arbitrary, how can I get a new stereographic projection?",,"['multivariable-calculus', 'transformation']"
59,Divergence transforms as scalar under rotation in 2D + intuition,Divergence transforms as scalar under rotation in 2D + intuition,,"Problem is as follows: In two dimensions, show that the divergence transforms as a scalar under rotations. Aim is to determine $\bar{v}_{y}$ and $\bar{v}_{z}$, and show that $\frac{\partial\bar{v}_{y}}{\partial\bar{y}}$ + $\frac{\partial\bar{v}_{z}}{\partial\bar{z}} = \frac{\partial v_{y}}{\partial y} + \frac{\partial v_{y}}{\partial z}$ I'm not sure at all why the above shows that divergence transforms as a scalar under rotations. It was a part of the question (given as a hint) so I was just trying to solve it without really understanding what I was doing. Any help on clarifying why I do need to show that would be appreciated. Since this is a rotation in two dimensions (in the $y$ and $z$ axis), $ \left( {\begin{array}{cc} \bar{v}_{y}  \\ \bar{v}_{z} \end{array} } \right) $ =  $ \left( {\begin{array}{cc} \cos\phi & \sin\phi  \\ -\sin\phi & \cos\phi \end{array} } \right) $ $ \left( {\begin{array}{cc} {v}_{y}  \\ v_{z} \end{array} } \right) $. Expanding this out, I found that $\bar{v}_{y} = v_{y}.\cos\phi + v_{z}.\sin\phi$ and $\bar{v}_{z} = -v_{y}.\sin\phi + v_{z}.\cos\phi$. Solving for $v_{y}$ and $v_{z}$, by multiplying $\bar{v}_{y}$ and $\bar{v}_{z}$ by $\sin\phi$ and $\cos\phi$, I was able to use the $\sin^{2}\phi + \cos^{2}\phi = 1$ identity to get $v_{z} = \bar{v}_{y}.\sin\phi + \bar{v}_{z}.\cos\phi$ and $v_{y} = \bar{v}_{y}.\cos\phi - \bar{v}_{z}.\sin\phi$. Next, I found the components of the original equation: The first partial derivative in the equation was determined as $\frac{\partial \bar{v}_{y}}{\partial \bar{y}} = (\frac{\partial \bar{v}_{y}}{\partial y})(\frac{\partial y}{\partial \bar{y}}) + (\frac{\partial \bar{v}_{y}}{\partial z})(\frac{\partial z}{\partial \bar{y}})$ and the second as $\frac{\partial \bar{v}_{z}}{\partial \bar{z}} = (\frac{\partial \bar{v}_{z}}{\partial y})(\frac{\partial y}{\partial \bar{z}}) + (\frac{\partial \bar{v}_{z}}{\partial z})(\frac{\partial z}{\partial \bar{z}})$. At this point, I become stuck because I cannot seem to be able to find $\partial \bar{v}_{y}$ and $\partial \bar{v}_{z}$ with respect to $\partial y$ and $\partial z$. How to I continue? Thanks in advance.","Problem is as follows: In two dimensions, show that the divergence transforms as a scalar under rotations. Aim is to determine $\bar{v}_{y}$ and $\bar{v}_{z}$, and show that $\frac{\partial\bar{v}_{y}}{\partial\bar{y}}$ + $\frac{\partial\bar{v}_{z}}{\partial\bar{z}} = \frac{\partial v_{y}}{\partial y} + \frac{\partial v_{y}}{\partial z}$ I'm not sure at all why the above shows that divergence transforms as a scalar under rotations. It was a part of the question (given as a hint) so I was just trying to solve it without really understanding what I was doing. Any help on clarifying why I do need to show that would be appreciated. Since this is a rotation in two dimensions (in the $y$ and $z$ axis), $ \left( {\begin{array}{cc} \bar{v}_{y}  \\ \bar{v}_{z} \end{array} } \right) $ =  $ \left( {\begin{array}{cc} \cos\phi & \sin\phi  \\ -\sin\phi & \cos\phi \end{array} } \right) $ $ \left( {\begin{array}{cc} {v}_{y}  \\ v_{z} \end{array} } \right) $. Expanding this out, I found that $\bar{v}_{y} = v_{y}.\cos\phi + v_{z}.\sin\phi$ and $\bar{v}_{z} = -v_{y}.\sin\phi + v_{z}.\cos\phi$. Solving for $v_{y}$ and $v_{z}$, by multiplying $\bar{v}_{y}$ and $\bar{v}_{z}$ by $\sin\phi$ and $\cos\phi$, I was able to use the $\sin^{2}\phi + \cos^{2}\phi = 1$ identity to get $v_{z} = \bar{v}_{y}.\sin\phi + \bar{v}_{z}.\cos\phi$ and $v_{y} = \bar{v}_{y}.\cos\phi - \bar{v}_{z}.\sin\phi$. Next, I found the components of the original equation: The first partial derivative in the equation was determined as $\frac{\partial \bar{v}_{y}}{\partial \bar{y}} = (\frac{\partial \bar{v}_{y}}{\partial y})(\frac{\partial y}{\partial \bar{y}}) + (\frac{\partial \bar{v}_{y}}{\partial z})(\frac{\partial z}{\partial \bar{y}})$ and the second as $\frac{\partial \bar{v}_{z}}{\partial \bar{z}} = (\frac{\partial \bar{v}_{z}}{\partial y})(\frac{\partial y}{\partial \bar{z}}) + (\frac{\partial \bar{v}_{z}}{\partial z})(\frac{\partial z}{\partial \bar{z}})$. At this point, I become stuck because I cannot seem to be able to find $\partial \bar{v}_{y}$ and $\partial \bar{v}_{z}$ with respect to $\partial y$ and $\partial z$. How to I continue? Thanks in advance.",,"['multivariable-calculus', 'vector-analysis']"
60,"What does $\frac{\partial}{\partial x}(\frac{\partial f}{\partial u})$ mean when $f(x,t), u=x+ct, v=x-ct $?",What does  mean when ?,"\frac{\partial}{\partial x}(\frac{\partial f}{\partial u}) f(x,t), u=x+ct, v=x-ct ","I'm trying to transform the wave equation $\frac{\partial^2f}{\partial t^2}-c^2\frac{\partial^2f}{\partial x^2}$ using the substitution: $ \\u=x+ct \\v=x-ct $ and using the chain rule for the partial derivatives $\frac{\partial f}{\partial x}$ and$\frac{\partial f}{\partial t}$ I get: $ \frac{\partial f}{\partial x}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial x}=\frac{\partial f}{\partial u}*1+\frac{\partial f}{\partial v}*1 $ and similarly: $: \frac{\partial f}{\partial t}=\frac{\partial f}{\partial u}*c+\frac{\partial f}{\partial v}*(-c) $ To express the second partial derivative $\frac{\partial^2f}{\partial x^2}$: $ \frac{\partial^2f}{\partial x^2}=\frac{\partial}{\partial x}(\frac{\partial f}{\partial x})=\frac{\partial}{\partial x}(\frac{\partial f}{\partial u})+\frac{\partial}{\partial x}(\frac{\partial f}{\partial v}) $ Now the notation says I should take the derivative with respect to $x$ of $\frac{\partial f}{\partial u}$, but what then is $\frac{\partial f}{\partial u}$? If $f$ is a function of $x$ and $t$, which both are in expressed in both $u$ and $v$, how does the chain rule apply here (as compared to the first step above, which I can handle)? Thanks! Alexander","I'm trying to transform the wave equation $\frac{\partial^2f}{\partial t^2}-c^2\frac{\partial^2f}{\partial x^2}$ using the substitution: $ \\u=x+ct \\v=x-ct $ and using the chain rule for the partial derivatives $\frac{\partial f}{\partial x}$ and$\frac{\partial f}{\partial t}$ I get: $ \frac{\partial f}{\partial x}=\frac{\partial f}{\partial u}\frac{\partial u}{\partial x}+\frac{\partial f}{\partial v}\frac{\partial v}{\partial x}=\frac{\partial f}{\partial u}*1+\frac{\partial f}{\partial v}*1 $ and similarly: $: \frac{\partial f}{\partial t}=\frac{\partial f}{\partial u}*c+\frac{\partial f}{\partial v}*(-c) $ To express the second partial derivative $\frac{\partial^2f}{\partial x^2}$: $ \frac{\partial^2f}{\partial x^2}=\frac{\partial}{\partial x}(\frac{\partial f}{\partial x})=\frac{\partial}{\partial x}(\frac{\partial f}{\partial u})+\frac{\partial}{\partial x}(\frac{\partial f}{\partial v}) $ Now the notation says I should take the derivative with respect to $x$ of $\frac{\partial f}{\partial u}$, but what then is $\frac{\partial f}{\partial u}$? If $f$ is a function of $x$ and $t$, which both are in expressed in both $u$ and $v$, how does the chain rule apply here (as compared to the first step above, which I can handle)? Thanks! Alexander",,"['multivariable-calculus', 'partial-differential-equations']"
61,Euclidean Metric and Convexity,Euclidean Metric and Convexity,,"Question: Consider the Euclidean metric space $(\mathbb{R}^n , \Vert\cdot \Vert)$. Let $X\subset \mathbb{R}^n$ and $f\colon X \to \mathbb{R}$. $X$ is said to be a convex set if for every $x,y \in X$ and $t \in (0,1)$, we have $tx+(1-t)y \in X$. $f$ is said to be a convex function at $x\in X$ if for every $y \in X$ and $t\in(0,1)$, $tx+(1-t)y\in X$ implies $f(tx+(1-t)y) \le tf(x) +(1-y)f(y)$. $f$ is said to be a convex function if it is a convex function at every $x \in X$. Prove the following statements: If X is a convex set, then $f\colon X \in \mathbb{R}$ is a convex function iff $\{ (x,y) \in X \times \mathbb{R} \mid f(x) \le y \}$ is a convex set. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and differentiable at $x \in X$, then $$f(y)-f(x) \ge Df(x)\cdot (y-x)$$ for every $y\in X$, where $Df(x)$ is the derivative of $f(x)$ at $x$. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and twice differentiable at $x \in X$, then $D^2f(x)$ is positive semidefinite. EDIT : I am deleting how I tried Part 1 as I got my mistake and now it is solved. Part 2 and Part 3 are still unsolved","Question: Consider the Euclidean metric space $(\mathbb{R}^n , \Vert\cdot \Vert)$. Let $X\subset \mathbb{R}^n$ and $f\colon X \to \mathbb{R}$. $X$ is said to be a convex set if for every $x,y \in X$ and $t \in (0,1)$, we have $tx+(1-t)y \in X$. $f$ is said to be a convex function at $x\in X$ if for every $y \in X$ and $t\in(0,1)$, $tx+(1-t)y\in X$ implies $f(tx+(1-t)y) \le tf(x) +(1-y)f(y)$. $f$ is said to be a convex function if it is a convex function at every $x \in X$. Prove the following statements: If X is a convex set, then $f\colon X \in \mathbb{R}$ is a convex function iff $\{ (x,y) \in X \times \mathbb{R} \mid f(x) \le y \}$ is a convex set. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and differentiable at $x \in X$, then $$f(y)-f(x) \ge Df(x)\cdot (y-x)$$ for every $y\in X$, where $Df(x)$ is the derivative of $f(x)$ at $x$. If $X$ is open in $\mathbb{R}^n$ and $f$ is convex and twice differentiable at $x \in X$, then $D^2f(x)$ is positive semidefinite. EDIT : I am deleting how I tried Part 1 as I got my mistake and now it is solved. Part 2 and Part 3 are still unsolved",,"['multivariable-calculus', 'convex-analysis', 'inner-products']"
62,How do you formally prove that a function in several variable is really a function,How do you formally prove that a function in several variable is really a function,,"Let say for example that we define $f:\mathbb{R}^{3}\longrightarrow \mathbb{R}^{3}$ such that $f(x,y,z)=(y^{2},xz,xy^{2})$. My informal argument would be just that there is only one object  that can be defined having three real numbers, but I'm just saying this intuitively. How do you prove it formally?","Let say for example that we define $f:\mathbb{R}^{3}\longrightarrow \mathbb{R}^{3}$ such that $f(x,y,z)=(y^{2},xz,xy^{2})$. My informal argument would be just that there is only one object  that can be defined having three real numbers, but I'm just saying this intuitively. How do you prove it formally?",,"['elementary-set-theory', 'multivariable-calculus']"
63,Differential manipulation,Differential manipulation,,"Let $v \equiv F(y, z)$. The partial derivatives of $F$ are $$F_1 \equiv \frac{\partial F(y,z)}{\partial y} = \frac{H(v)}{H(y)},$$ $$F_2 \equiv \frac{\partial F(y,z)}{\partial z} = r\frac{H(v)}{H(z)},$$ where $H$ is an arbitrary function. This is taken from the book Probability Theory by E.T. Jaynes. The author goes on saying that the relation $ \mathrm{d}v = \mathrm{d}F(y, z) = F_1\mathrm{d}y + F_2\mathrm{d}z$ takes the form of  $$\frac{\mathrm{d}v}{H(v)} = \frac{\mathrm{d}y}{H(y)} + r\frac{\mathrm{d}z}{H(z)}$$ or, on integration $$w[F(y, z)] = w(v) = w(y)w^r(z),$$ where $$w(x) \equiv exp\left\{\int^x \frac{\mathrm{d}x}{H(x)}\right\}.$$ I did undergraduate calculus; however, we didn't do this kind of differential manipulation (expansion of $\mathrm{d}v$) and I find it quite confusing. Is there a way to arrive at the same result using ""standard"" steps like integration by substitution etc.?","Let $v \equiv F(y, z)$. The partial derivatives of $F$ are $$F_1 \equiv \frac{\partial F(y,z)}{\partial y} = \frac{H(v)}{H(y)},$$ $$F_2 \equiv \frac{\partial F(y,z)}{\partial z} = r\frac{H(v)}{H(z)},$$ where $H$ is an arbitrary function. This is taken from the book Probability Theory by E.T. Jaynes. The author goes on saying that the relation $ \mathrm{d}v = \mathrm{d}F(y, z) = F_1\mathrm{d}y + F_2\mathrm{d}z$ takes the form of  $$\frac{\mathrm{d}v}{H(v)} = \frac{\mathrm{d}y}{H(y)} + r\frac{\mathrm{d}z}{H(z)}$$ or, on integration $$w[F(y, z)] = w(v) = w(y)w^r(z),$$ where $$w(x) \equiv exp\left\{\int^x \frac{\mathrm{d}x}{H(x)}\right\}.$$ I did undergraduate calculus; however, we didn't do this kind of differential manipulation (expansion of $\mathrm{d}v$) and I find it quite confusing. Is there a way to arrive at the same result using ""standard"" steps like integration by substitution etc.?",,"['calculus', 'integration', 'multivariable-calculus']"
64,How do you find and classify the critical points of the function?,How do you find and classify the critical points of the function?,,"Find and classify the critical points of the function  $$ f(x,y) = 5x^2 + 2xy + 5y^2. $$ Use the second derivative test to justify your answer. For critical points I got $(0,0)$. Is that the only critical point?","Find and classify the critical points of the function  $$ f(x,y) = 5x^2 + 2xy + 5y^2. $$ Use the second derivative test to justify your answer. For critical points I got $(0,0)$. Is that the only critical point?",,['multivariable-calculus']
65,Solving problem 3-29 in Spivak´s Calculus on Manifolds without using change of variables,Solving problem 3-29 in Spivak´s Calculus on Manifolds without using change of variables,,"Problem 3-29 (p. 61) in the section treating Fubini´s theorem reads: Use Fubini´s theorem to derive an expression for the volume of a set of $\mathbb{R}^{3}$ obtained by revolving a Jordan-measurable set in the $yz$-plane about the $z$-axis . By making some simplying assumptions about the plane region and changing variables to cylindrical coordinates we can obtain an expression for the volume. However, the material on the change of variables is treated two sections later (p. 66). Thus, is there is a way to solve the problem without using change of variables? The definition of Jordan-measurable can be found on p. 56 (See also Theorem 3-9, p.55), but I sumarize it here: Spivak defines a bounded subset $C$ of $\mathbb{R}^{n}$ to be Jordan measurable if the topological boundary of $C$ has measure $0$, i.e. if for any $\varepsilon>0$ there is a cover $\{U_{i}\}$ of $\mathrm{Bd}(C)$ by closed $n$-cubes such that $\sum_{i}v(U_{i})<\varepsilon$ (where $v(U_{i})$ denotes the $n$-dimensional volume of the rectangle $U_{i}$). If $C$ is Jordan measurable it is contained inside some closed $n$-cube $A$ and the characteristic function $\chi_{C}$ is integrable on $A$. The integral $\int_{A}\chi_{C}$ is called the $n$-dimensional volume of $C$.","Problem 3-29 (p. 61) in the section treating Fubini´s theorem reads: Use Fubini´s theorem to derive an expression for the volume of a set of $\mathbb{R}^{3}$ obtained by revolving a Jordan-measurable set in the $yz$-plane about the $z$-axis . By making some simplying assumptions about the plane region and changing variables to cylindrical coordinates we can obtain an expression for the volume. However, the material on the change of variables is treated two sections later (p. 66). Thus, is there is a way to solve the problem without using change of variables? The definition of Jordan-measurable can be found on p. 56 (See also Theorem 3-9, p.55), but I sumarize it here: Spivak defines a bounded subset $C$ of $\mathbb{R}^{n}$ to be Jordan measurable if the topological boundary of $C$ has measure $0$, i.e. if for any $\varepsilon>0$ there is a cover $\{U_{i}\}$ of $\mathrm{Bd}(C)$ by closed $n$-cubes such that $\sum_{i}v(U_{i})<\varepsilon$ (where $v(U_{i})$ denotes the $n$-dimensional volume of the rectangle $U_{i}$). If $C$ is Jordan measurable it is contained inside some closed $n$-cube $A$ and the characteristic function $\chi_{C}$ is integrable on $A$. The integral $\int_{A}\chi_{C}$ is called the $n$-dimensional volume of $C$.",,"['integration', 'multivariable-calculus', 'differential-topology']"
66,Vector Taylor series,Vector Taylor series,,"From pg. 35 of Classical Electrodynamics 3rd edition, Jackson, $$\begin{aligned} \nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{4 \pi \epsilon_{0}} \int \rho\left(\mathbf{x}^{\prime}\right)\left[\frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\right] d^{3} x^{\prime} \end{aligned}$$ ""Choose R such that $\rho(\mathbf{x'})$ changes little over the interior of the sphere... With a Taylor series expansion of the well-behaved $\rho (\mathbf{x'})$ around $\mathbf{x'} = \mathbf{x}$ one finds ..."" \begin{align} \nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{\epsilon_{0}} \int_{0}^{R} \frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\left[\rho(\mathbf{x})+\frac{r^{2}}{6} \nabla^{2} \rho+\cdots\right] r^{2} d r+O\left(a^{2}\right), \end{align} where $r = |\mathbf{x'} -\mathbf{x}|$ . Could someone explain how to derive this Taylor series for a function of a vector? I've never seen this before and am at a loss.","From pg. 35 of Classical Electrodynamics 3rd edition, Jackson, ""Choose R such that changes little over the interior of the sphere... With a Taylor series expansion of the well-behaved around one finds ..."" where . Could someone explain how to derive this Taylor series for a function of a vector? I've never seen this before and am at a loss.","\begin{aligned} \nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{4 \pi \epsilon_{0}} \int \rho\left(\mathbf{x}^{\prime}\right)\left[\frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\right] d^{3} x^{\prime} \end{aligned} \rho(\mathbf{x'}) \rho (\mathbf{x'}) \mathbf{x'} = \mathbf{x} \begin{align}
\nabla^{2} \Phi_{a}(\mathbf{x}) &=-\frac{1}{\epsilon_{0}} \int_{0}^{R} \frac{3 a^{2}}{\left(r^{2}+a^{2}\right)^{5 / 2}}\left[\rho(\mathbf{x})+\frac{r^{2}}{6} \nabla^{2} \rho+\cdots\right] r^{2} d r+O\left(a^{2}\right),
\end{align} r = |\mathbf{x'} -\mathbf{x}|","['multivariable-calculus', 'taylor-expansion']"
67,Using nabla with partial derivatives and the Laplace operation $\partial_x^2+\partial_y^2+\partial_z^2$,Using nabla with partial derivatives and the Laplace operation,\partial_x^2+\partial_y^2+\partial_z^2,"Source of the problem p.812 here . Suppose $$\bar{F}(x,y,z)=(xy-z^2)\bar{i}+(xyz)\bar{j}+(x-y^2-z^2)\bar{k}.$$ I am concerned where I need to nabla an unit vector for example with $$\triangledown \times F.$$ I am particularly uncertain with $\partial_{x}\bar{k}$ (where $\bar{k}$ is an unit vector) -- is it zero or $\bar{k}\partial_{x}$? This scan reuses the same logic and if the latter is wrong, it will have many errors (particularly in the middle section)","Source of the problem p.812 here . Suppose $$\bar{F}(x,y,z)=(xy-z^2)\bar{i}+(xyz)\bar{j}+(x-y^2-z^2)\bar{k}.$$ I am concerned where I need to nabla an unit vector for example with $$\triangledown \times F.$$ I am particularly uncertain with $\partial_{x}\bar{k}$ (where $\bar{k}$ is an unit vector) -- is it zero or $\bar{k}\partial_{x}$? This scan reuses the same logic and if the latter is wrong, it will have many errors (particularly in the middle section)",,"['multivariable-calculus', 'notation']"
68,Notation for some integrals,Notation for some integrals,,"I've seen some problems where the OP writes integrals in this form $$\int {dt} f\left( t \right)$$ or for double integrals $$\int {dx} \int {dtf\left( {t,x} \right)} $$ Do they represent another kind of integrals, or is it just notation?","I've seen some problems where the OP writes integrals in this form $$\int {dt} f\left( t \right)$$ or for double integrals $$\int {dx} \int {dtf\left( {t,x} \right)} $$ Do they represent another kind of integrals, or is it just notation?",,"['integration', 'multivariable-calculus', 'notation']"
69,Wronskian is independent to the choice of a basis,Wronskian is independent to the choice of a basis,,"How to show that the Wronskian is independent to the choice of a basis of $V$? Let $f_1(x), \ldots, f_n(x)$ be a basis of a vector space $V$. Then the Wronskian is the determinant of a matrix whose i-th row is $f_1^{(i-1)}, \ldots, f_n^{(i-1)}$. Here $f_j^{(i)}$ is the i-th derivative of $f_j$. Thank you very much.","How to show that the Wronskian is independent to the choice of a basis of $V$? Let $f_1(x), \ldots, f_n(x)$ be a basis of a vector space $V$. Then the Wronskian is the determinant of a matrix whose i-th row is $f_1^{(i-1)}, \ldots, f_n^{(i-1)}$. Here $f_j^{(i)}$ is the i-th derivative of $f_j$. Thank you very much.",,"['linear-algebra', 'multivariable-calculus']"
70,Calculus of an integral,Calculus of an integral,,"I'm trying to calculate the following integral $$\int\limits_S \exp\left\{\sum_{i=1}^n \lambda _ix_i\right\} \, d\sigma$$ where the $\lambda_i$ are constant real parameters, $S$ is a surface in $\mathbb{R}^n$ determined by the conditions $$\sum _{i=1}^n x_i=1$$ and $$\forall _i0\leq x_i\leq 1,$$ and $d\sigma$ is the element of area on this surface. I have the feeling that a relatively simple expression can be found. Thanks.","I'm trying to calculate the following integral $$\int\limits_S \exp\left\{\sum_{i=1}^n \lambda _ix_i\right\} \, d\sigma$$ where the $\lambda_i$ are constant real parameters, $S$ is a surface in $\mathbb{R}^n$ determined by the conditions $$\sum _{i=1}^n x_i=1$$ and $$\forall _i0\leq x_i\leq 1,$$ and $d\sigma$ is the element of area on this surface. I have the feeling that a relatively simple expression can be found. Thanks.",,['multivariable-calculus']
71,Level curves and functions of three variables,Level curves and functions of three variables,,"I would like to ask just a quick question. Say for example I give you a function of two variables $z = f(x,y)$ = $x^2 + y^2$ which represents a paraboloid. If I want the level curves $f(x,y) = c$, then these now represent concentric circles in the $x-y$ plane centered at the origin of radius $\sqrt{c}$. Now here's my question. Say I have $w = f(x,y,z)$ now a function of three variables, i.e. it is a hypersurface in $\mathbb{R}^4$. If I have a level ""curve"" say $w = f(x,y,z) = 0$, does this then represent now a level ""surface"" in $\mathbb{R}^3$? Thanks, Ben","I would like to ask just a quick question. Say for example I give you a function of two variables $z = f(x,y)$ = $x^2 + y^2$ which represents a paraboloid. If I want the level curves $f(x,y) = c$, then these now represent concentric circles in the $x-y$ plane centered at the origin of radius $\sqrt{c}$. Now here's my question. Say I have $w = f(x,y,z)$ now a function of three variables, i.e. it is a hypersurface in $\mathbb{R}^4$. If I have a level ""curve"" say $w = f(x,y,z) = 0$, does this then represent now a level ""surface"" in $\mathbb{R}^3$? Thanks, Ben",,[]
72,Find area of figure and volume of body,Find area of figure and volume of body,,"Problem Find area: $$\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2=\frac{xy}{c^2},\qquad a,b,c > 0$$ My solution: The figure encloses area under itself so we're looking at: $$\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2},\qquad a,b,c > 0$$ The function is symmetric in first and third quadrant, therefore if $S_D$ is the total area under the function defined in domain $D$ and $D1$ is the domain only for $x\geq0$ , $y\geq0$ (first quadrant): $S_D=2S_{D1}$ $D1$ : $$(\frac{x^2}{a^2}+\frac{y^2}{b^2})^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0$$ And by chekcing $(x,y)=(0,0)$ $$0\leq\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0$$ (But $\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2$ is always positive for every $x$ and $y$ ) And from here I don't really know how to continue to get the double integral that calculates the area for the figure. I'm pretty sure I have to express $y$ or $x$ as a function of the other, but I don't know how to form the function which has 4th, 2nd and 1st degree terms. I also tried polar coordinates change of variables, but to no avail (but I did know it wouldn't work since there's also terms of first degree on the right side of the equation): $$S_D = 2\int \int_{D1} \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2 - \frac{xy}{c^2}\, dx\, dy$$","Problem Find area: My solution: The figure encloses area under itself so we're looking at: The function is symmetric in first and third quadrant, therefore if is the total area under the function defined in domain and is the domain only for , (first quadrant): : And by chekcing (But is always positive for every and ) And from here I don't really know how to continue to get the double integral that calculates the area for the figure. I'm pretty sure I have to express or as a function of the other, but I don't know how to form the function which has 4th, 2nd and 1st degree terms. I also tried polar coordinates change of variables, but to no avail (but I did know it wouldn't work since there's also terms of first degree on the right side of the equation):","\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2=\frac{xy}{c^2},\qquad a,b,c > 0 \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2},\qquad a,b,c > 0 S_D D D1 x\geq0 y\geq0 S_D=2S_{D1} D1 (\frac{x^2}{a^2}+\frac{y^2}{b^2})^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0 (x,y)=(0,0) 0\leq\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0 \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2 x y y x S_D = 2\int \int_{D1} \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2 - \frac{xy}{c^2}\, dx\, dy","['calculus', 'integration', 'multivariable-calculus', 'area']"
73,Partial derivatives and functions,Partial derivatives and functions,,"If I have $y=x^2$ and I have a function of $x$ and $y$ i.e. $f(x,y)=x+y$ , then why is it that the partial derivative of this function with respect to $x$ is 1 whereas the partial derivative of $g(x)=x+x^2$ is $1+2x$ , despite the fact that $f(x,y)=g(x)$ ?","If I have and I have a function of and i.e. , then why is it that the partial derivative of this function with respect to is 1 whereas the partial derivative of is , despite the fact that ?","y=x^2 x y f(x,y)=x+y x g(x)=x+x^2 1+2x f(x,y)=g(x)","['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
74,Computing an integral using differential under the integral sign,Computing an integral using differential under the integral sign,,"The following integral is in question. $$I(x) =\int_0^x \frac{\ln(1+tx)}{1+t^2}\,dt$$ My attempt is finding $I’(x)$ which is $$I’(x) = \int_0^x \frac{t}{(1+t^2)(1+tx)}\,dt + \frac{\ln(1+x^2)}{1+x^2} $$ Now we can use partial fraction decompostion for the first integral. $$\frac{t}{(1+t^2)(1+tx)} = \frac{At +B}{1+t^2}+\frac{C}{1+tx}$$ Solving this gives the following values: $$A = \frac{1}{1+x^2}$$ $$B = \frac{x}{1+x^2}$$ $$C = \frac{-x}{1+x^2}$$ Now we can solve the first integral and we obtain that $$I’(x) = \frac{1}{2}\frac{\ln(1+x^2)}{1+x^2} + \frac{x\arctan(x)}{1+x^2}$$ Here Intuitively I would get something that is easy to integrate and find the constant by limits or some other obvious way but I get a function that I cannot integrate, can someone help me and give me a hint of what I am doing wrong ? Thanks!!","The following integral is in question. My attempt is finding which is Now we can use partial fraction decompostion for the first integral. Solving this gives the following values: Now we can solve the first integral and we obtain that Here Intuitively I would get something that is easy to integrate and find the constant by limits or some other obvious way but I get a function that I cannot integrate, can someone help me and give me a hint of what I am doing wrong ? Thanks!!","I(x) =\int_0^x \frac{\ln(1+tx)}{1+t^2}\,dt I’(x) I’(x) = \int_0^x \frac{t}{(1+t^2)(1+tx)}\,dt + \frac{\ln(1+x^2)}{1+x^2}  \frac{t}{(1+t^2)(1+tx)} = \frac{At +B}{1+t^2}+\frac{C}{1+tx} A = \frac{1}{1+x^2} B = \frac{x}{1+x^2} C = \frac{-x}{1+x^2} I’(x) = \frac{1}{2}\frac{\ln(1+x^2)}{1+x^2} + \frac{x\arctan(x)}{1+x^2}","['real-analysis', 'calculus', 'integration', 'multivariable-calculus', 'derivatives']"
75,Why is $\iiint_B(12x^2+2z)dxdydz=\iiint_B4(x^2+y^2+z^2)dxdydz$?,Why is ?,\iiint_B(12x^2+2z)dxdydz=\iiint_B4(x^2+y^2+z^2)dxdydz,"According to my teacher $$\iiint_B (12x^2+2z) \, dx \, dy \, dz = \iiint_B 4(x^2+y^2+z^2) \, dx\, dy\, dz$$ where $B=\{(x,y,z)\mid x^2+y^2+z^2\le 1\}$ . I have absolutely no clue why the triple integrals should be equal.",According to my teacher where . I have absolutely no clue why the triple integrals should be equal.,"\iiint_B (12x^2+2z) \, dx \, dy \, dz = \iiint_B 4(x^2+y^2+z^2) \, dx\, dy\, dz B=\{(x,y,z)\mid x^2+y^2+z^2\le 1\}","['integration', 'multivariable-calculus']"
76,Multivariate chain rule (again) for differential forms,Multivariate chain rule (again) for differential forms,,"I know there has been many questions on multivariate chain rules already, but I read through a few of them and I'm still confused how to correctly do my case, so I will ask again. I'm trying to prove that for an exact $1$ -form $\alpha = \sum_i f_i dx_i$ , the $0$ -form $g(\mathbf{x}) = \sum_j x_j\left(\int_0^1 f_j(t\mathbf{x})dt\right)$ is an antiderivative i.e. $dg = \alpha$ . By definition, it suffices to prove that $\frac{\partial g}{\partial x_i} = f_i$ . So I get \begin{align*} \frac{\partial g}{\partial x_i} &= \left(\int_0^1 f_i(t\mathbf{x})dt\right) + \left(\sum_j x_j \left(\int_0^1 \frac{\partial(f_j(t\mathbf{x}))}{\partial x_i} \right)\right) \\ &= \left(\int_0^1 f_i(t\mathbf{x})dt\right) + \left(\sum_j x_j \left(\int_0^1 \color{red}{\sum_k \frac{\partial f_j}{\partial x_k} \cdot \frac{\partial (tx_k)}{\partial x_i} } \right)\right) \\ &= \int_0^1 f_i(t\mathbf{x})dt + \sum_j x_j \int_0^1 \frac{\partial f_j}{\partial x_i}(t\mathbf{x}) \cdot tdt \end{align*} First question is whether the chain rule application at the red part is correct. The second question is how do I proceed from here? Numerical example I worked through: take $\alpha = x^2y dx + x dy$ . Then, \begin{align*} \frac{\partial g}{\partial x} &= \int_0^1 (x^2y)\big|_{x=tx,y=ty} dt + x\int_0^1 \left(\frac{\partial(x^2y)}{\partial x}\right)\big|_{x=tx,y=ty} \cdot tdt + y\int_0^1 \left(\frac{\partial(x^2y)}{\partial y}\right)\big|_{x=tx,y=ty} \cdot tdt \\ &= \int_0^1 t^3x^2y dt + x \int_0^1 (2t^2xy) \cdot tdt + y \int_0^1 (t^2x^2) \cdot tdt \end{align*} But I don't get much insight on how to simplify this in general. I guess when $f_i$ is polynomial this is easier but about in general..","I know there has been many questions on multivariate chain rules already, but I read through a few of them and I'm still confused how to correctly do my case, so I will ask again. I'm trying to prove that for an exact -form , the -form is an antiderivative i.e. . By definition, it suffices to prove that . So I get First question is whether the chain rule application at the red part is correct. The second question is how do I proceed from here? Numerical example I worked through: take . Then, But I don't get much insight on how to simplify this in general. I guess when is polynomial this is easier but about in general..","1 \alpha = \sum_i f_i dx_i 0 g(\mathbf{x}) = \sum_j x_j\left(\int_0^1 f_j(t\mathbf{x})dt\right) dg = \alpha \frac{\partial g}{\partial x_i} = f_i \begin{align*}
\frac{\partial g}{\partial x_i}
&= \left(\int_0^1 f_i(t\mathbf{x})dt\right) + \left(\sum_j x_j \left(\int_0^1 \frac{\partial(f_j(t\mathbf{x}))}{\partial x_i} \right)\right) \\
&= \left(\int_0^1 f_i(t\mathbf{x})dt\right) + \left(\sum_j x_j \left(\int_0^1 \color{red}{\sum_k \frac{\partial f_j}{\partial x_k} \cdot \frac{\partial (tx_k)}{\partial x_i} } \right)\right) \\
&= \int_0^1 f_i(t\mathbf{x})dt + \sum_j x_j \int_0^1 \frac{\partial f_j}{\partial x_i}(t\mathbf{x}) \cdot tdt
\end{align*} \alpha = x^2y dx + x dy \begin{align*}
\frac{\partial g}{\partial x}
&= \int_0^1 (x^2y)\big|_{x=tx,y=ty} dt + x\int_0^1 \left(\frac{\partial(x^2y)}{\partial x}\right)\big|_{x=tx,y=ty} \cdot tdt + y\int_0^1 \left(\frac{\partial(x^2y)}{\partial y}\right)\big|_{x=tx,y=ty} \cdot tdt \\
&= \int_0^1 t^3x^2y dt + x \int_0^1 (2t^2xy) \cdot tdt + y \int_0^1 (t^2x^2) \cdot tdt
\end{align*} f_i","['multivariable-calculus', 'differential-forms']"
77,Finding the Volume of Region in Three-Dimensional Space.,Finding the Volume of Region in Three-Dimensional Space.,,"I am currently working on calculating the volume of the region $W$ in $\mathbb{R}^3$ , defined by the constraints: $$W=\{ (x,y,z)\in\mathbb{R}^3 ∣ z≥2,  x^2+y^2≤6−z,  y≥x \} .$$ My approach involves using triple integration, and the volume integral I have formulated is as follows: $$V = \int_{2}^{4} \int_{x}^{\sqrt{6-x^2}} \int_{2}^{6-x^2-y^2} \, dz \, dy \, dx .$$ However, I find myself at a stage where I need assistance confirming if my approach is correct. Could you provide guidance on how to tackle this analytical development? Are there any suggestions for simplifying the integration or considerations I should be aware of? I appreciate any help or insights you can offer. Thank you!","I am currently working on calculating the volume of the region in , defined by the constraints: My approach involves using triple integration, and the volume integral I have formulated is as follows: However, I find myself at a stage where I need assistance confirming if my approach is correct. Could you provide guidance on how to tackle this analytical development? Are there any suggestions for simplifying the integration or considerations I should be aware of? I appreciate any help or insights you can offer. Thank you!","W \mathbb{R}^3 W=\{ (x,y,z)\in\mathbb{R}^3 ∣ z≥2,  x^2+y^2≤6−z,  y≥x \} . V = \int_{2}^{4} \int_{x}^{\sqrt{6-x^2}} \int_{2}^{6-x^2-y^2} \, dz \, dy \, dx .","['real-analysis', 'calculus', 'integration', 'multivariable-calculus', 'volume']"
78,Is a smooth simple closed curve the union of finitely many arcs?,Is a smooth simple closed curve the union of finitely many arcs?,,"This is a problem from Pugh's Real Mathematical Analysis [Chapter 5]. If $C$ is a smooth simple closed curve in the plane, show that it is the union of finitely many arcs $C_l$ , each of which is the graph of a smooth function $y = h(x)$ or $x = h(y)$ , and the arcs $C_l$ meet only at common endpoints. Attempt : Let $C$ be parametrized by $t$ , that is, $(x(t),y(t))$ be its coordinates, where $t$ changes in $[0,1]$ . We can start by letting $t_0$ = $0$ and continue traversing the curve (either clockwise or counter-clockwise) until one of the coordinates of the derivate changes sign. Let's call this point $t_1$ . With continuing the same algorithm, we have partitioned $C$ into a (not necessarily finite) number of arcs with their domain $[t_i,t_{i+1}]$ . But here two things remain to be proved: First : How to revise the algorithm so that the sign-changing points are finite? Or how to show that they are finite, if it is the case? Second : It is easy to show that in each arc either $x$ is a function of $y$ or vice versa. The question is why one of them is an smooth function of the other. Thanks for your suggestions in advance. Note that I'm taking an Advanced Calculus course and I'm not familiar with manifolds or algebraic topology. So keep your answers as simple as possible.","This is a problem from Pugh's Real Mathematical Analysis [Chapter 5]. If is a smooth simple closed curve in the plane, show that it is the union of finitely many arcs , each of which is the graph of a smooth function or , and the arcs meet only at common endpoints. Attempt : Let be parametrized by , that is, be its coordinates, where changes in . We can start by letting = and continue traversing the curve (either clockwise or counter-clockwise) until one of the coordinates of the derivate changes sign. Let's call this point . With continuing the same algorithm, we have partitioned into a (not necessarily finite) number of arcs with their domain . But here two things remain to be proved: First : How to revise the algorithm so that the sign-changing points are finite? Or how to show that they are finite, if it is the case? Second : It is easy to show that in each arc either is a function of or vice versa. The question is why one of them is an smooth function of the other. Thanks for your suggestions in advance. Note that I'm taking an Advanced Calculus course and I'm not familiar with manifolds or algebraic topology. So keep your answers as simple as possible.","C C_l y = h(x) x = h(y) C_l C t (x(t),y(t)) t [0,1] t_0 0 t_1 C [t_i,t_{i+1}] x y","['real-analysis', 'multivariable-calculus']"
79,Differentiable function: where am I wrong?,Differentiable function: where am I wrong?,,"Consider the function $$f(x, y) = \frac{x^4y^3}{x^8 + y^4}$$ not at the origin, but $0$ at the origin. I already provd the continuity of the function at the origin. I have to show if it's differentiable. Considering some paths, I keep getting $$\lim_{(x, y) \to (0, 0)} \frac{1}{\sqrt{x^2+y^2}} \frac{x^4y^3}{x^8 + y^4} =0$$ Yet when proving in serious way the differentiability, I get stuck. Here is what I did: \begin{equation} \begin{split} \vert \frac{x^4y^3}{(x^8+y^4)\sqrt{x^2+y^2}} \vert & \leq \frac{x^4y^2|y|}{(x^8+y^4)\sqrt{x^2+y^2}}\\\\ & \leq \frac{x^4y^2|y|}{\sqrt{x^2+y^2}2x^4y^2} \\\\ & = \frac{|y|}{\sqrt{x^2+y^2}} \\\\ & \leq \frac{\sqrt{y^2}}{\sqrt{x^2+y^2}} \\\\ & \leq \frac{\sqrt{x^2+y^2}}{\sqrt{x^2+y^2}} \\\\ & = 1 \end{split} \end{equation} From line two to line three I used AM/GM: $x^8 + y^4 \geq 2\sqrt{x^8y^4} = 2x^4y^2$ and I reversed So, am I wrong or is the function not differentiable at zero?","Consider the function not at the origin, but at the origin. I already provd the continuity of the function at the origin. I have to show if it's differentiable. Considering some paths, I keep getting Yet when proving in serious way the differentiability, I get stuck. Here is what I did: From line two to line three I used AM/GM: and I reversed So, am I wrong or is the function not differentiable at zero?","f(x, y) = \frac{x^4y^3}{x^8 + y^4} 0 \lim_{(x, y) \to (0, 0)} \frac{1}{\sqrt{x^2+y^2}} \frac{x^4y^3}{x^8 + y^4} =0 \begin{equation}
\begin{split}
\vert \frac{x^4y^3}{(x^8+y^4)\sqrt{x^2+y^2}} \vert & \leq \frac{x^4y^2|y|}{(x^8+y^4)\sqrt{x^2+y^2}}\\\\
& \leq \frac{x^4y^2|y|}{\sqrt{x^2+y^2}2x^4y^2}
\\\\
& = \frac{|y|}{\sqrt{x^2+y^2}}
\\\\
& \leq \frac{\sqrt{y^2}}{\sqrt{x^2+y^2}}
\\\\
& \leq \frac{\sqrt{x^2+y^2}}{\sqrt{x^2+y^2}}
\\\\
& = 1
\end{split}
\end{equation} x^8 + y^4 \geq 2\sqrt{x^8y^4} = 2x^4y^2","['real-analysis', 'multivariable-calculus', 'derivatives', 'solution-verification']"
80,Maximizing volume of a cylinder with $2$ cones given surface area $A$,Maximizing volume of a cylinder with  cones given surface area,2 A,"A cylinder with a cone on either side of it. The cones have the same radius as the cylinder. Cylinder area without the sides: $$A_{cyl}=2\pi r h_1$$ Cone area without the base: $$A_{cone}=\pi r \sqrt{h_2^2+r^2}$$ Total area of body: $$A_{tot}=2\pi r h_1 + 2\pi r \sqrt{h_2^2+r^2}$$ Volume: $$V_{tot}=\pi r^2 h_1 +\frac{2\pi r^2 h_2}{3}=\pi r^2 (h_1 + \frac{2}{3}h_2)$$ I have managed to calculate the maximum volume given surface area for the cone and the cylinder separately but together there are three variables. How would I go about calculating $r,h_1,h_2$ to maximize the volume?",A cylinder with a cone on either side of it. The cones have the same radius as the cylinder. Cylinder area without the sides: Cone area without the base: Total area of body: Volume: I have managed to calculate the maximum volume given surface area for the cone and the cylinder separately but together there are three variables. How would I go about calculating to maximize the volume?,"A_{cyl}=2\pi r h_1 A_{cone}=\pi r \sqrt{h_2^2+r^2} A_{tot}=2\pi r h_1 + 2\pi r \sqrt{h_2^2+r^2} V_{tot}=\pi r^2 h_1 +\frac{2\pi r^2 h_2}{3}=\pi r^2 (h_1 + \frac{2}{3}h_2) r,h_1,h_2","['multivariable-calculus', 'optimization']"
81,Connection between the linear algebra and calculus explanation of linearity of the derivative operator,Connection between the linear algebra and calculus explanation of linearity of the derivative operator,,"This is too-embarrassing-to-ask question that keeps bothering me in the back of my mind: It's clear that $$D(f + g) = D(f) + D(g)$$ and that $$ D(c f)= c D(f)$$ for $f, g$ differentiable functions and $c$ a scalar. On the other hand we can construct the Jacobian matrix of partial derivatives, or a gradient and multiply it times a directional vector. Or we can talk about the best linear approximation of a function, or the affine approximation, and it all makes sense independently. But it bothers me that an operator that transforms nonlinear functions to other nonlinear functions (e.f. polynomials of grade $3$ to $2$ ) can be called linear. How are all the arguments reconciled with each other, and with the nonlinearity of the input functions being modified?","This is too-embarrassing-to-ask question that keeps bothering me in the back of my mind: It's clear that and that for differentiable functions and a scalar. On the other hand we can construct the Jacobian matrix of partial derivatives, or a gradient and multiply it times a directional vector. Or we can talk about the best linear approximation of a function, or the affine approximation, and it all makes sense independently. But it bothers me that an operator that transforms nonlinear functions to other nonlinear functions (e.f. polynomials of grade to ) can be called linear. How are all the arguments reconciled with each other, and with the nonlinearity of the input functions being modified?","D(f + g) = D(f) + D(g)  D(c f)= c D(f) f, g c 3 2","['linear-algebra', 'multivariable-calculus', 'linear-transformations']"
82,Why does $z$-axis have to point out of the page for a typical orientation of the $y$-axis and $x$-axis?,Why does -axis have to point out of the page for a typical orientation of the -axis and -axis?,z y x,"In class, when I constructed my plot of a $3$ D solid, I thought that it was arbitrary which directions I chose as my positive $x$ -, $y$ -, and $z$ - axes. But when I got the paper back, I was told that the $z$ -axis must be the cross product of the $x$ - and $y$ axes (in that order of course, because cross product is not commutative). Why is this? What does it affect if this rule is not followed?","In class, when I constructed my plot of a D solid, I thought that it was arbitrary which directions I chose as my positive -, -, and - axes. But when I got the paper back, I was told that the -axis must be the cross product of the - and axes (in that order of course, because cross product is not commutative). Why is this? What does it affect if this rule is not followed?",3 x y z z x y,"['multivariable-calculus', 'vector-analysis']"
83,How to plot the graph of this given set in $\mathbb{R}^2$,How to plot the graph of this given set in,\mathbb{R}^2,"Can anyone help me plot the graph of the set $$B=\{(a_1+a_2, a_1a_2):a_1,a_2\in\mathbb{R},|a_1|<1,|a_2|<1\}.$$ Ok so I can shade the region $|x|<2$ and $|y|<1$ . But do not know how to proceed after that. And above sets is real roots of the equation $x^2-\alpha x+\beta$ whose modulus is less than 1. Will it be the intersection of the shaded area above and the parabola $x^2-4y>0$ ?",Can anyone help me plot the graph of the set Ok so I can shade the region and . But do not know how to proceed after that. And above sets is real roots of the equation whose modulus is less than 1. Will it be the intersection of the shaded area above and the parabola ?,"B=\{(a_1+a_2, a_1a_2):a_1,a_2\in\mathbb{R},|a_1|<1,|a_2|<1\}. |x|<2 |y|<1 x^2-\alpha x+\beta x^2-4y>0","['real-analysis', 'multivariable-calculus', 'graphing-functions']"
84,Volume of a body bounded by a surface.,Volume of a body bounded by a surface.,,"I want to find a volume of a body, bounded by: $$(x^2+y^2+z^2)^2 = az(x^2+y^2)$$ for some $a > 0$ . As I understood I am supposed to say that for аor a fixed value of z, it looks like a circle, which means that we just need to take the integral of the resulting function. But I'm having a little trouble getting the radius $(x ^ 2 + y ^ 2)$ of a circle at fixed z and reducing that to an integral. Maybe there are simpler ways to get the volume of a given shape?","I want to find a volume of a body, bounded by: for some . As I understood I am supposed to say that for аor a fixed value of z, it looks like a circle, which means that we just need to take the integral of the resulting function. But I'm having a little trouble getting the radius of a circle at fixed z and reducing that to an integral. Maybe there are simpler ways to get the volume of a given shape?",(x^2+y^2+z^2)^2 = az(x^2+y^2) a > 0 (x ^ 2 + y ^ 2),"['real-analysis', 'integration', 'multivariable-calculus', 'volume', 'multiple-integral']"
85,A set with volume zero can be covered by finitely many open boxes,A set with volume zero can be covered by finitely many open boxes,,"A set $X\subseteq\mathbb{R}^n$ is said to have $n$ -dimensional volume zero iff for any $\epsilon>0$ , there exist finitely many closed $n$ -boxes $R_1,\cdots,R_s$ such that $X\subseteq \bigcup_i R_i$ and $\sum_{i} \text{vol}(R_i)<\epsilon$ . Given a set $X$ with volume zero, I would like to show that for any $\epsilon>0$ , there exists such a cover where each point in $X$ is an interior point of the cover and its volume is less than $\epsilon$ . In other words, is it possible to cover $X$ with open boxes instead (with total volume less than $\epsilon$ )? I encountered this problem in the proof of Proposition 7.1.8 in Multivariable Mathematics: Linear Algebra, Multivariable Calculus, and Manifolds by T. Shifrin. The proposition asserts that if the set $X$ of discontinuities of a bounded function $f:R\to\mathbb{R}$ has volume zero, then $f$ is integrable on $R$ . In the proof, $X$ is covered in the manner mentioned in the previous paragraph so that the closure of the complement of the covered portion does not contain any discontinuity point. However, the author did not provide a proof for why such a cover exists. This is intuitive to me, but I struggle to produce a rigorous proof.","A set is said to have -dimensional volume zero iff for any , there exist finitely many closed -boxes such that and . Given a set with volume zero, I would like to show that for any , there exists such a cover where each point in is an interior point of the cover and its volume is less than . In other words, is it possible to cover with open boxes instead (with total volume less than )? I encountered this problem in the proof of Proposition 7.1.8 in Multivariable Mathematics: Linear Algebra, Multivariable Calculus, and Manifolds by T. Shifrin. The proposition asserts that if the set of discontinuities of a bounded function has volume zero, then is integrable on . In the proof, is covered in the manner mentioned in the previous paragraph so that the closure of the complement of the covered portion does not contain any discontinuity point. However, the author did not provide a proof for why such a cover exists. This is intuitive to me, but I struggle to produce a rigorous proof.","X\subseteq\mathbb{R}^n n \epsilon>0 n R_1,\cdots,R_s X\subseteq \bigcup_i R_i \sum_{i} \text{vol}(R_i)<\epsilon X \epsilon>0 X \epsilon X \epsilon X f:R\to\mathbb{R} f R X","['general-topology', 'multivariable-calculus', 'riemann-integration']"
86,Prove a inequality property of convex function,Prove a inequality property of convex function,,"Problem: Let $f: \mathbb{R}^n \to \overline{\mathbb{R}}$ be the convex function. Let $x_1,x_3 \in E$ (Euclidean space in $\mathbb{R}^n$ ) and $x_2 \in (x_1,x_3)$ . Prove that $$\dfrac{f(x_3) -f(x_2)}{\Vert x_3-x_2 \Vert} \ge\dfrac{f(x_2)-f(x_1)}{\Vert x_2-x_1\Vert}.$$ My attempt: Since $x_2 \in (x_1,x_3)$ then there exists $t \in (0,1)$ such that $x_2 = tx_1 + (1-t)x_3$ . Thus we have $$f(x_3) - f(x_2)  \ge f(x_3)-tf(x_1)-(1-t)f(x_3) = tf(x_3)-tf(x_1).$$ Therefore $$\dfrac{f(x_3)-f(x_2)}{\Vert x_3-x_2\Vert} \ge \dfrac{t}{\vert t \vert}\dfrac{f(x_3)-f(x_1)}{\Vert x_3-x_1\Vert} \ge -\dfrac{f(x_3)-f(x_1)}{\Vert x_3-x_1\Vert} = \dfrac{f(x_1)-f(x_3)}{\Vert x_1-x_3\Vert}.$$ I have tried many different ways to have a result like the solution above but I failed. I wonder that the problem is right or not?",Problem: Let be the convex function. Let (Euclidean space in ) and . Prove that My attempt: Since then there exists such that . Thus we have Therefore I have tried many different ways to have a result like the solution above but I failed. I wonder that the problem is right or not?,"f: \mathbb{R}^n \to \overline{\mathbb{R}} x_1,x_3
\in E \mathbb{R}^n x_2 \in (x_1,x_3) \dfrac{f(x_3) -f(x_2)}{\Vert x_3-x_2 \Vert} \ge\dfrac{f(x_2)-f(x_1)}{\Vert x_2-x_1\Vert}. x_2 \in (x_1,x_3) t \in (0,1) x_2 = tx_1 + (1-t)x_3 f(x_3) - f(x_2)  \ge f(x_3)-tf(x_1)-(1-t)f(x_3) = tf(x_3)-tf(x_1). \dfrac{f(x_3)-f(x_2)}{\Vert x_3-x_2\Vert} \ge \dfrac{t}{\vert t \vert}\dfrac{f(x_3)-f(x_1)}{\Vert x_3-x_1\Vert} \ge -\dfrac{f(x_3)-f(x_1)}{\Vert x_3-x_1\Vert} = \dfrac{f(x_1)-f(x_3)}{\Vert x_1-x_3\Vert}.","['multivariable-calculus', 'inequality', 'convex-analysis']"
87,Characterization of Lipschitz derivative,Characterization of Lipschitz derivative,,"Let $f \colon O \to \mathbb R$ be continuously differentiable, where $O \subset \mathbb R^n$ is open and convex. Then, the following two assertions are equivalent: $\nabla f$ is Lipschitz-continuous with constant $1$ , i.e., $$ \| \nabla f(y) - \nabla f(x) \| \le \| y - x \| \qquad \forall x,y \in O.$$ we have $$ \bigl| (\nabla f(y) - \nabla f(x) )^\top (y - x) \bigr| \le \|y - x\|^2 \qquad\forall x,y \in O.$$ I am looking for a concise proof or a reference for this equivalence. The direction $1 \Rightarrow 2$ is just an application of the Cauchy-Schwarz inequality. The other direction is slightly harder. Let me outline a proof. If we assume additionally $f \in C^2$ , then by using $y = x + t h$ , with fixed $h \in \mathbb R^n$ in 2, we obtain $$ |h^\top \nabla^2f(x) h| \le \| h \|^2 \qquad\forall x \in O, h \in \mathbb R^n$$ by passing to the limit $t \to 0$ . Since $\nabla^2 f(x)$ is symmetric, this yields $\| \nabla^2 f(x) \| \le 1$ and the Lipschitz continuity of $\nabla f$ follows. In the general case, one can apply this argument to the mollification $f_\epsilon = f \mathbin\star \psi_\epsilon$ , where $\psi_\epsilon$ is a standard mollifier. Is it possible give a direct proof of $2 \Rightarrow 1$ without the 'detour' to $C^2$ -functions? By the way: Although the statements 1 and 2 only depend on $\nabla f$ , the equivalence no longer holds if $\nabla f$ is replaced by an arbitrary, continuous function $g \colon O \to \mathbb R^n$ : Use, e.g., $g(x) = A x$ , where $A \in \mathbb R^{n \times n}$ is skew symmetric.","Let be continuously differentiable, where is open and convex. Then, the following two assertions are equivalent: is Lipschitz-continuous with constant , i.e., we have I am looking for a concise proof or a reference for this equivalence. The direction is just an application of the Cauchy-Schwarz inequality. The other direction is slightly harder. Let me outline a proof. If we assume additionally , then by using , with fixed in 2, we obtain by passing to the limit . Since is symmetric, this yields and the Lipschitz continuity of follows. In the general case, one can apply this argument to the mollification , where is a standard mollifier. Is it possible give a direct proof of without the 'detour' to -functions? By the way: Although the statements 1 and 2 only depend on , the equivalence no longer holds if is replaced by an arbitrary, continuous function : Use, e.g., , where is skew symmetric.","f \colon O \to \mathbb R O \subset \mathbb R^n \nabla f 1  \| \nabla f(y) - \nabla f(x) \| \le \| y - x \| \qquad \forall x,y \in O.  \bigl| (\nabla f(y) - \nabla f(x) )^\top (y - x) \bigr| \le \|y - x\|^2 \qquad\forall x,y \in O. 1 \Rightarrow 2 f \in C^2 y = x + t h h \in \mathbb R^n  |h^\top \nabla^2f(x) h| \le \| h \|^2 \qquad\forall x \in O, h \in \mathbb R^n t \to 0 \nabla^2 f(x) \| \nabla^2 f(x) \| \le 1 \nabla f f_\epsilon = f \mathbin\star \psi_\epsilon \psi_\epsilon 2 \Rightarrow 1 C^2 \nabla f \nabla f g \colon O \to \mathbb R^n g(x) = A x A \in \mathbb R^{n \times n}","['calculus', 'multivariable-calculus', 'lipschitz-functions']"
88,Find max/min value of a multivariable function,Find max/min value of a multivariable function,,"Determine the maximum and minimum value of: $$x^2+5y^2-4x$$ in the region: $$x^2+y^2<=1 $$ and $$y>=0$$ I was trying to do this question. Firstly I found the gradient and put it equal to 0 and found the point (2,0). However, this point is not in the region and could not be used. So from here, I'm not quite sure how to continue. I do know it has something to do with the edges of the region, to find the corner points and maybe somehow continue from there, but I'm not quite sure. Thanks","Determine the maximum and minimum value of: in the region: and I was trying to do this question. Firstly I found the gradient and put it equal to 0 and found the point (2,0). However, this point is not in the region and could not be used. So from here, I'm not quite sure how to continue. I do know it has something to do with the edges of the region, to find the corner points and maybe somehow continue from there, but I'm not quite sure. Thanks",x^2+5y^2-4x x^2+y^2<=1  y>=0,"['calculus', 'multivariable-calculus']"
89,Using Stokes theorem to find the line integral over the boundary of a paraboloid in the first octant opening downward the z-axis,Using Stokes theorem to find the line integral over the boundary of a paraboloid in the first octant opening downward the z-axis,,"I've been trying at this problem on my homework, but I think I am going about it the wrong way. I tried breaking it down into the line integrals of the boundaries of the surface, but I think I might have the wrong idea about how Stokes' Theorem works. Can someone please give me a step by step solution to this problem? Edit I will include my work here: I tried several different things and none of them turned out right.","I've been trying at this problem on my homework, but I think I am going about it the wrong way. I tried breaking it down into the line integrals of the boundaries of the surface, but I think I might have the wrong idea about how Stokes' Theorem works. Can someone please give me a step by step solution to this problem? Edit I will include my work here: I tried several different things and none of them turned out right.",,"['calculus', 'multivariable-calculus', 'multiple-integral', 'stokes-theorem', 'curl']"
90,Continuity of function in $\mathbb{R}^2$,Continuity of function in,\mathbb{R}^2,"Where should I start if I want to study the continuity of a function in $\mathbb{R}^2$ ? Like this one: $$f(x,y)=   \begin{cases}        \frac{x^2y}{x^2+\sqrt{y}} & \quad\text{if } y>0,\\       0 & \quad\text{otherwise.}\\    \end{cases} $$ I think $f$ is continuous except at $(0,0)$ , so I have to take the limit to see if it's continuous, right? But I'm confused about the piecewise function, which would be $0$ at that point... Could someone help me?","Where should I start if I want to study the continuity of a function in ? Like this one: I think is continuous except at , so I have to take the limit to see if it's continuous, right? But I'm confused about the piecewise function, which would be at that point... Could someone help me?","\mathbb{R}^2 f(x,y)=  
\begin{cases} 
      \frac{x^2y}{x^2+\sqrt{y}} & \quad\text{if } y>0,\\
      0 & \quad\text{otherwise.}\\
   \end{cases}
 f (0,0) 0","['multivariable-calculus', 'continuity']"
91,Evaluate the I?,Evaluate the I?,,This  is question is inspired from this find the value   of $$I=\int_{0}^{2\pi} \int_{0}^{\sqrt 2 a}\sqrt{ \frac{u^4}{a^2} +u^2} du dv$$ My attempt : $$I=\int_{0}^{2\pi} \int_{0}^{\sqrt 2 a}u\sqrt{ \frac{u^2}{a^2} +1} du dv$$ after that im not able to solved this,This  is question is inspired from this find the value   of My attempt : after that im not able to solved this,I=\int_{0}^{2\pi} \int_{0}^{\sqrt 2 a}\sqrt{ \frac{u^4}{a^2} +u^2} du dv I=\int_{0}^{2\pi} \int_{0}^{\sqrt 2 a}u\sqrt{ \frac{u^2}{a^2} +1} du dv,"['multivariable-calculus', 'multiple-integral']"
92,Derivative of integral with varying domain? Fundamental theorem of calculus?,Derivative of integral with varying domain? Fundamental theorem of calculus?,,"Say I want to find the $n^{th}$ derivative of $$\int_{V_x} F{(x_1,...,x_k)}dV$$ where $V_x$ is some $k$ -dimensional volume dependent on $x$ . In the $1$ -dimensional case this is the fundamental theorem of calculus for $n=1$ and we can take higher derivatives after applying the fundamental theorem. To be concrete, say $V_x$ is the cube $[0,x]^k$ . What can I do in general? Is this Stokes theorem?","Say I want to find the derivative of where is some -dimensional volume dependent on . In the -dimensional case this is the fundamental theorem of calculus for and we can take higher derivatives after applying the fundamental theorem. To be concrete, say is the cube . What can I do in general? Is this Stokes theorem?","n^{th} \int_{V_x} F{(x_1,...,x_k)}dV V_x k x 1 n=1 V_x [0,x]^k","['calculus', 'integration', 'multivariable-calculus']"
93,How to check continuity of this multivariable function,How to check continuity of this multivariable function,,"Here's the function: $$f(x,y)=\begin{cases}{y+{1\over y}\arctan({x^2y})} & y\neq 0\\ 0 & y=0\end{cases}$$ I need to study it's continuity and I've got a hard time understanding exactly how to rigorously formulate my findings (because I don't understand everything that well), so I would like to know if my reasoning is correct. Firstly what I found was that in $f(x,y)=(0,0)$ the function is continuous in $(0,0)$ because the limit of this function for $(x,y)\to(0,0)$ is indeed $0$ . Secondly, the function isn't continuous in $f(x,y)=(x,0)$ if $x$ isn't zero because the limit of f when $y\to 0 $ and $x$ is ""fixed"" is $1$ . Is this reasoning correct and complete ?","Here's the function: I need to study it's continuity and I've got a hard time understanding exactly how to rigorously formulate my findings (because I don't understand everything that well), so I would like to know if my reasoning is correct. Firstly what I found was that in the function is continuous in because the limit of this function for is indeed . Secondly, the function isn't continuous in if isn't zero because the limit of f when and is ""fixed"" is . Is this reasoning correct and complete ?","f(x,y)=\begin{cases}{y+{1\over y}\arctan({x^2y})} & y\neq 0\\ 0 & y=0\end{cases} f(x,y)=(0,0) (0,0) (x,y)\to(0,0) 0 f(x,y)=(x,0) x y\to 0  x 1","['calculus', 'multivariable-calculus', 'continuity']"
94,Volume with spherical polar coordinates,Volume with spherical polar coordinates,,"Determine the volume between the surface $z=\sqrt{4-x^2-y^2}$ and the area of the xy plane determined by $x^2+y^2\le 1,\ x+y>0,\ y\ge 0$ . I convert to spherical polar coordinates. $$K=0\le r\le 1,\ 0\le \phi \le \frac{3\pi}{4},\ 0\le \theta \le 2\pi$$ $$\iiint_{K} (\sqrt {4-r^2\sin^2\phi \cos^2\theta-r^2\sin^2\phi \sin^2\theta)}r^2\sin\phi drd\phi d\theta$$ I can't figure out how to take $\int_{K} (\sqrt {4-r^2\sin^2\phi \cos^2\theta-r^2\sin^2\phi \sin^2\theta)}r^2\sin\phi dr$ , which makes me think I made a mistake somewhere. EDIT: Thanks for all the answers. Now I understand how the limits of $\theta ,r,z$ works. I don't fully understand where the function ""disappear"". $\sqrt {4-x^2-y^2} =\sqrt {4-r^2}$ Why isn't it then: $\int \int \int _{K} {\sqrt {4-r^2}rdzdrd\theta }$","Determine the volume between the surface and the area of the xy plane determined by . I convert to spherical polar coordinates. I can't figure out how to take , which makes me think I made a mistake somewhere. EDIT: Thanks for all the answers. Now I understand how the limits of works. I don't fully understand where the function ""disappear"". Why isn't it then:","z=\sqrt{4-x^2-y^2} x^2+y^2\le 1,\ x+y>0,\ y\ge 0 K=0\le r\le 1,\ 0\le \phi \le \frac{3\pi}{4},\ 0\le \theta \le 2\pi \iiint_{K} (\sqrt {4-r^2\sin^2\phi \cos^2\theta-r^2\sin^2\phi \sin^2\theta)}r^2\sin\phi drd\phi d\theta \int_{K} (\sqrt {4-r^2\sin^2\phi \cos^2\theta-r^2\sin^2\phi \sin^2\theta)}r^2\sin\phi dr \theta ,r,z \sqrt {4-x^2-y^2} =\sqrt {4-r^2} \int \int \int _{K} {\sqrt {4-r^2}rdzdrd\theta }","['calculus', 'integration', 'multivariable-calculus', 'spherical-coordinates']"
95,"Evaluating $\int_{-4} ^4\int _0 ^{\sqrt{16-x^2}} \int _0 ^{16-x^2-y^2} \sqrt{x^2 + y^2}\,dz\,dy\,dx$",Evaluating,"\int_{-4} ^4\int _0 ^{\sqrt{16-x^2}} \int _0 ^{16-x^2-y^2} \sqrt{x^2 + y^2}\,dz\,dy\,dx","Question : Evaluate the given triple integral with cylindrical coordinates: $$\int_{-4} ^4\int _0 ^{\sqrt{16-x^2}} \int _0 ^{16-x^2-y^2} \sqrt{x^2 + y^2}\,dz\,dy\,dx$$ My solution (attempt): Upon converting the triple integral into cylindrical coordinates, I got: $$\int_{0} ^{\pi/2}\int _0 ^{4} \int _0 ^{16-r^2\cos^2\theta-r^2\sin^2\theta} r^2\,dz\,dr\,d\theta$$ After solving for the solution, I got $1024\pi/15$ as the answer. Apparently, this is incorrect. Could someone please show me where integral conversion is wrong? Thanks in advance!","Question : Evaluate the given triple integral with cylindrical coordinates: My solution (attempt): Upon converting the triple integral into cylindrical coordinates, I got: After solving for the solution, I got as the answer. Apparently, this is incorrect. Could someone please show me where integral conversion is wrong? Thanks in advance!","\int_{-4} ^4\int _0 ^{\sqrt{16-x^2}} \int _0 ^{16-x^2-y^2} \sqrt{x^2 + y^2}\,dz\,dy\,dx \int_{0} ^{\pi/2}\int _0 ^{4} \int _0 ^{16-r^2\cos^2\theta-r^2\sin^2\theta} r^2\,dz\,dr\,d\theta 1024\pi/15","['multivariable-calculus', 'multiple-integral']"
96,Meaning of directional derivative of a vector field,Meaning of directional derivative of a vector field,,"Suppose I have a vector field $ \vec{B} (x,y,z)$ then do $ \frac{ \partial B}{ \partial n}$ where n is the direction vector of a line denote the directional derivative of the vector in the direction of $n$ ? The reason I ask is that I recently encountered this in a physics textbook but all the gradients and directional derivatives that I've seen till now were defined for scalar fields. Edit: The real quantity that I started with was the one from this mse post : $$ (\nabla B_i) n_i $$ I thought this would be the directional derivative since it looked like one but then I later realized this is actually a vector field. A picture from the book: Page-158, I.e irodov basic laws of electromagnetism","Suppose I have a vector field then do where n is the direction vector of a line denote the directional derivative of the vector in the direction of ? The reason I ask is that I recently encountered this in a physics textbook but all the gradients and directional derivatives that I've seen till now were defined for scalar fields. Edit: The real quantity that I started with was the one from this mse post : I thought this would be the directional derivative since it looked like one but then I later realized this is actually a vector field. A picture from the book: Page-158, I.e irodov basic laws of electromagnetism"," \vec{B} (x,y,z)  \frac{ \partial B}{ \partial n} n  (\nabla B_i) n_i ",['multivariable-calculus']
97,"Proving the differentiablity of a function at the point (0,0)","Proving the differentiablity of a function at the point (0,0)",,"Let $\mathbb{R}^n$ be endowed with a norm $|| \ ||$ and let $f:\mathbb{R}^n\to\mathbb{R}$ be a function satisfying $|f(x)|\leq||x||^2$ for any $x\in\mathbb{R}^n$ . Show that $f$ is differentiable at the point $0\in\mathbb{R}^n$ . Honestly I have problem with the definition of the derivative of a function of many variables. The definition that I have is the following: The map $f$ is said to be differentible at the point $p\in U\subset\mathbb{R}^n$ if exist a linear map $L:\mathbb{R}^n\to\mathbb{R}^n$ such that $$ \underset{h\to0}{\textrm{Lim}}\dfrac{||{f(a+h)=f(a)-L.h}||}{||h||}=0 $$ From the hypothesis I can see that $f(0)=0$ and so we reduce our limit to $$ \underset{h\to0}{\textrm{Lim}}\dfrac{||{f(h)-L.h}||}{||h||}=0 $$ I can see also that if I choose $L$ to be the zero map, the last limit is true. Now my problem is if I can choose the map $L$ to be zero at the point $0\in\mathbb{R}^n$ or if there is something I'm not seeing in the definition that allows me to prove that $f$ is differentiable at $0\in\mathbb{R}^n$","Let be endowed with a norm and let be a function satisfying for any . Show that is differentiable at the point . Honestly I have problem with the definition of the derivative of a function of many variables. The definition that I have is the following: The map is said to be differentible at the point if exist a linear map such that From the hypothesis I can see that and so we reduce our limit to I can see also that if I choose to be the zero map, the last limit is true. Now my problem is if I can choose the map to be zero at the point or if there is something I'm not seeing in the definition that allows me to prove that is differentiable at","\mathbb{R}^n || \ || f:\mathbb{R}^n\to\mathbb{R} |f(x)|\leq||x||^2 x\in\mathbb{R}^n f 0\in\mathbb{R}^n f p\in U\subset\mathbb{R}^n L:\mathbb{R}^n\to\mathbb{R}^n 
\underset{h\to0}{\textrm{Lim}}\dfrac{||{f(a+h)=f(a)-L.h}||}{||h||}=0
 f(0)=0 
\underset{h\to0}{\textrm{Lim}}\dfrac{||{f(h)-L.h}||}{||h||}=0
 L L 0\in\mathbb{R}^n f 0\in\mathbb{R}^n","['real-analysis', 'multivariable-calculus']"
98,A Laplacian identity from Evans,A Laplacian identity from Evans,,"In Theorem 1 (Solving Poisson's equation) on page 24 of Partial Differential Equations (2e) by Evans comparing equation (11) and (13) there appears to be the equality of $$ \int_{\mathbb{R}^n \setminus  B(0,\epsilon)} \Phi(y)\Delta_x f(x-y) \,dy  = \int_{\mathbb{R}^n \setminus B(0,\epsilon)} \Phi(y)\Delta_y f(x-y) \,dy.$$ For context: $\Phi$ is the fundamental solution to the Laplace equation, $-\Delta u = f$ in $\mathbb{R}^n$ , and $B(0,\epsilon)$ is the ball of radius $\epsilon$ centered on zero. Where does the equality with respect to the Laplacians come from? That is why does $$ \Delta_xf(x-y) = \Delta_yf(x-y) $$ hold? I have seen this in another reference (page 149 of Partial Differential Equations in Action (3e) - Salsa). Is this a general property of convolution or is it something more subtle? In terms of level of understanding, explanations without reliance on measure theory would be preferred.","In Theorem 1 (Solving Poisson's equation) on page 24 of Partial Differential Equations (2e) by Evans comparing equation (11) and (13) there appears to be the equality of For context: is the fundamental solution to the Laplace equation, in , and is the ball of radius centered on zero. Where does the equality with respect to the Laplacians come from? That is why does hold? I have seen this in another reference (page 149 of Partial Differential Equations in Action (3e) - Salsa). Is this a general property of convolution or is it something more subtle? In terms of level of understanding, explanations without reliance on measure theory would be preferred."," \int_{\mathbb{R}^n \setminus  B(0,\epsilon)} \Phi(y)\Delta_x f(x-y) \,dy  = \int_{\mathbb{R}^n \setminus B(0,\epsilon)} \Phi(y)\Delta_y f(x-y) \,dy. \Phi -\Delta u = f \mathbb{R}^n B(0,\epsilon) \epsilon  \Delta_xf(x-y) = \Delta_yf(x-y) ","['multivariable-calculus', 'partial-differential-equations', 'convolution', 'laplacian']"
99,"Evaluating $\frac{dg}{dθ}$ at $(r,θ)=(2\sqrt{2},\frac{π}{4})$ where $g(x,y)=\frac1{x+y^2}$ using chain rule?",Evaluating  at  where  using chain rule?,"\frac{dg}{dθ} (r,θ)=(2\sqrt{2},\frac{π}{4}) g(x,y)=\frac1{x+y^2}",Okay so my first step is to find the partial derivatives: $$\frac{\partial \:}{\partial \:x}\left(\frac{1}{x+y^2}\right)=-\frac{1}{\left(x+y^2\right)^2}$$ $$\frac{\partial \:}{\partial \:y}\left(\frac{1}{x+y^2}\right)=-\frac{2y}{\left(x+y^2\right)^2}$$ Then I multiply each partial derivative with its respective equal and add it together: $$(fx)(32r\cos(\theta)) + (fy)(3r(\sin(\theta))$$ Then I sub in X and Y in the partial derivatives. And then plug in $r$ and $\theta$ : $$-\left(\frac{1}{\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:}{4}\right)+\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi }{4}\right)\right)^2\right)^2}\right)\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:}{4}\right)\right)+-\left(\frac{2\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right)}{\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:\:}{4}\right)+\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right)^2\right)^2}\right)\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right)$$ And I show my answer in the screenshot above. But for some reason the software is telling me it's wrong. I've also tried not multiplying the partial derivatives by the $32rcos(\theta)$ thing but it's still giving me the wrong answer. What am I doing wrong? Thank you.,Okay so my first step is to find the partial derivatives: Then I multiply each partial derivative with its respective equal and add it together: Then I sub in X and Y in the partial derivatives. And then plug in and : And I show my answer in the screenshot above. But for some reason the software is telling me it's wrong. I've also tried not multiplying the partial derivatives by the thing but it's still giving me the wrong answer. What am I doing wrong? Thank you.,\frac{\partial \:}{\partial \:x}\left(\frac{1}{x+y^2}\right)=-\frac{1}{\left(x+y^2\right)^2} \frac{\partial \:}{\partial \:y}\left(\frac{1}{x+y^2}\right)=-\frac{2y}{\left(x+y^2\right)^2} (fx)(32r\cos(\theta)) + (fy)(3r(\sin(\theta)) r \theta -\left(\frac{1}{\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:}{4}\right)+\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi }{4}\right)\right)^2\right)^2}\right)\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:}{4}\right)\right)+-\left(\frac{2\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right)}{\left(32\left(2\sqrt{2}\right)cos\left(\frac{\pi \:\:}{4}\right)+\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right)^2\right)^2}\right)\left(3\left(2\sqrt{2}\right)sin\left(\frac{\pi \:}{4}\right)\right) 32rcos(\theta),"['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
