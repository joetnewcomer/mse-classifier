,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Norm of the operator $T:\ell^2 \to \ell^2$ defined as $(Tx)_1=0, (Tx)_n=-x_n+\alpha x_{n+1}$",Norm of the operator  defined as,"T:\ell^2 \to \ell^2 (Tx)_1=0, (Tx)_n=-x_n+\alpha x_{n+1}","Consider the operator $T: \ell^2 \to \ell^2$ defined as $$\begin{cases}   (Tx)_1 = 0, \\   (Tx)_n = -x_n + \alpha x_{n+1}, \quad n\ge 2 \end{cases} $$ where $\alpha \in \mathbb{C}$. I want to find the norm $\|T\|$. The best constraint I found is $$ \sqrt{1+|\alpha|^2} \le \|T\| \le 1+|\alpha|. $$ To do this I considered that $$\|T\|^2=\sum_{n=2}^\infty |-x_n + \alpha x_{n+1}|^2 \le 2 \sum_{n=2}^\infty (|x_n|^2+|\alpha|^2 |x_n|^2) \le 2(1+|\alpha|^2) \|x\|^2$$ hence $\|T\| \le \sqrt{2(1+|\alpha|^2)}$. This is actually worst that the bound found below so not very useful. $$x=(0,0,1+\alpha,0,...) \Longrightarrow Tx=(1+\alpha)(0,\alpha,-1,0,...)$$ hence $\|T\| \ge \sqrt{1+|\alpha|^2}$. Thinking of $T$ as sum of $T_1$ and $T_2$ defined respectively as $$\begin{cases}   (T_1 x)_1 = 0, \\   (T_1 x)_n = -x_n, \quad n \ge 2, \end{cases}$$ and $$\begin{cases}   (T_2 x)_1 = 0, \\   (T_2 x)_n = \alpha x_n, \quad n \ge 2, \end{cases}$$ noting that $\|T_1\|=1$ and $\|T_2\|=|\alpha|$, we conclude from the triangle inequality that $$\|T\| \le 1 + |\alpha|.$$ This constraint is better than the above as is easily seen in the plot below (where $x=|\alpha|$): What can I use to obtain the exact result?","Consider the operator $T: \ell^2 \to \ell^2$ defined as $$\begin{cases}   (Tx)_1 = 0, \\   (Tx)_n = -x_n + \alpha x_{n+1}, \quad n\ge 2 \end{cases} $$ where $\alpha \in \mathbb{C}$. I want to find the norm $\|T\|$. The best constraint I found is $$ \sqrt{1+|\alpha|^2} \le \|T\| \le 1+|\alpha|. $$ To do this I considered that $$\|T\|^2=\sum_{n=2}^\infty |-x_n + \alpha x_{n+1}|^2 \le 2 \sum_{n=2}^\infty (|x_n|^2+|\alpha|^2 |x_n|^2) \le 2(1+|\alpha|^2) \|x\|^2$$ hence $\|T\| \le \sqrt{2(1+|\alpha|^2)}$. This is actually worst that the bound found below so not very useful. $$x=(0,0,1+\alpha,0,...) \Longrightarrow Tx=(1+\alpha)(0,\alpha,-1,0,...)$$ hence $\|T\| \ge \sqrt{1+|\alpha|^2}$. Thinking of $T$ as sum of $T_1$ and $T_2$ defined respectively as $$\begin{cases}   (T_1 x)_1 = 0, \\   (T_1 x)_n = -x_n, \quad n \ge 2, \end{cases}$$ and $$\begin{cases}   (T_2 x)_1 = 0, \\   (T_2 x)_n = \alpha x_n, \quad n \ge 2, \end{cases}$$ noting that $\|T_1\|=1$ and $\|T_2\|=|\alpha|$, we conclude from the triangle inequality that $$\|T\| \le 1 + |\alpha|.$$ This constraint is better than the above as is easily seen in the plot below (where $x=|\alpha|$): What can I use to obtain the exact result?",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
1,The Mountain Pass theorem,The Mountain Pass theorem,,"I cam across the Mountain Pass Theorem, mentioned for example at http://en.wikipedia.org/wiki/Mountain_pass_theorem . In (very) loose terms, it somewhat reminds me of Rolle's theorem.  Trying to understand it better in the infinte-dimensional setting, I came across a multiple variables Mountain Pass Theorem in finite dimensional spaces, due to Courant. In this case the critical value $c$ is attained for a certain curve $g$ (using Wikipedia's notation). What surprises me is that in the Mountain Pass Theorem proper the critical value $c$ is defined as an $\inf \max$. While I am trying to work out the details, I am sure it would have been defined as a  $\min \max$ if it were possible. I cannot get around this point. The critical value $c$ is never attained by any curve $g$, and yet is a stationary point of the functional. the theorem proves there is a saddle, and yet in general no curve crosses it at the lowest height possible?? This totally defies my understanding. Has anybody got a word of wisdom? Thanks","I cam across the Mountain Pass Theorem, mentioned for example at http://en.wikipedia.org/wiki/Mountain_pass_theorem . In (very) loose terms, it somewhat reminds me of Rolle's theorem.  Trying to understand it better in the infinte-dimensional setting, I came across a multiple variables Mountain Pass Theorem in finite dimensional spaces, due to Courant. In this case the critical value $c$ is attained for a certain curve $g$ (using Wikipedia's notation). What surprises me is that in the Mountain Pass Theorem proper the critical value $c$ is defined as an $\inf \max$. While I am trying to work out the details, I am sure it would have been defined as a  $\min \max$ if it were possible. I cannot get around this point. The critical value $c$ is never attained by any curve $g$, and yet is a stationary point of the functional. the theorem proves there is a saddle, and yet in general no curve crosses it at the lowest height possible?? This totally defies my understanding. Has anybody got a word of wisdom? Thanks",,['functional-analysis']
2,Is the norm on $\ell^\infty$ induced by an inner product?,Is the norm on  induced by an inner product?,\ell^\infty,"Let $\ell^\infty$ be the normed space of all bounded sequences $x \colon= \left(\xi_n \right)_{n \in \mathbb{N} }$ of complex numbers, with the norm defined by $$\lVert x \rVert_{\ell^\infty} \colon= \sup_{n \in \mathbb{N}} \lvert \xi_n \rvert.$$ Is this norm induced by an inner product? That is, can we show that $$\lVert x + y \rVert_{\ell^\infty}^2 + \lVert x - y \rVert_{\ell^\infty}^2 \ = \ 2\left( \lVert x \rVert_{\ell^\infty}^2 + \lVert y \rVert_{\ell^\infty}^2 \right) \ \ \ \mbox{ for all } \ x, y \in \ell^\infty?$$ Or can we find any bounded sequences $x \colon= \left( \xi_n \right)_{n \in \mathbb{N} }$ and $y \colon= \left( \eta_n \right)_{ n \in \mathbb{N} }$ of complex numbers for which the above equality fails?","Let be the normed space of all bounded sequences of complex numbers, with the norm defined by Is this norm induced by an inner product? That is, can we show that Or can we find any bounded sequences and of complex numbers for which the above equality fails?","\ell^\infty x \colon= \left(\xi_n \right)_{n \in \mathbb{N} } \lVert x \rVert_{\ell^\infty} \colon= \sup_{n \in \mathbb{N}} \lvert \xi_n \rvert. \lVert x + y \rVert_{\ell^\infty}^2 + \lVert x - y \rVert_{\ell^\infty}^2 \ = \ 2\left( \lVert x \rVert_{\ell^\infty}^2 + \lVert y \rVert_{\ell^\infty}^2 \right) \ \ \ \mbox{ for all } \ x, y \in \ell^\infty? x \colon= \left( \xi_n \right)_{n \in \mathbb{N} } y \colon= \left( \eta_n \right)_{ n \in \mathbb{N} }","['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces', 'inner-products']"
3,Sufficient conditions on integration kernel for continuity of the integral operator,Sufficient conditions on integration kernel for continuity of the integral operator,,"Suppose that we have a measure $d\mu(v)=e^{-|v|^2}dv$ on $\Bbb R^d$. We define a linear operator  $$T[f](u)=\int_{\Bbb R^d} |u-v|^\beta f(v) d\mu(v).$$ I want to establish conditons on $\beta\in\Bbb R$ so the operator $T$ is continuous on $L^2(d\mu)$. Constant functions belong to $L^2(d\mu)$; for $\beta\le -d $ the operator $T$ is not defined for constant functions, hence, necessarily we need $\beta>-d$. If $\beta>-d/2$, then the integration kernel $k(u,v)=|u-v|^\beta \in L^2(d\mu(u)\,d\mu(v))$, and hence by Hilbert-Schmidt criterion the operator $T$ is compact and continuous. I'm interested in the case $\beta\in(-d,d/2]$. Is there a criterion that allows to show continuity/compactness of the operator $T$? I'll be glad to hear all suggestions.","Suppose that we have a measure $d\mu(v)=e^{-|v|^2}dv$ on $\Bbb R^d$. We define a linear operator  $$T[f](u)=\int_{\Bbb R^d} |u-v|^\beta f(v) d\mu(v).$$ I want to establish conditons on $\beta\in\Bbb R$ so the operator $T$ is continuous on $L^2(d\mu)$. Constant functions belong to $L^2(d\mu)$; for $\beta\le -d $ the operator $T$ is not defined for constant functions, hence, necessarily we need $\beta>-d$. If $\beta>-d/2$, then the integration kernel $k(u,v)=|u-v|^\beta \in L^2(d\mu(u)\,d\mu(v))$, and hence by Hilbert-Schmidt criterion the operator $T$ is compact and continuous. I'm interested in the case $\beta\in(-d,d/2]$. Is there a criterion that allows to show continuity/compactness of the operator $T$? I'll be glad to hear all suggestions.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators', 'integral-operators']"
4,"If $u, u'' \in L^2(0,1)$, is it true that $u' \in L^2(0,1)$?","If , is it true that ?","u, u'' \in L^2(0,1) u' \in L^2(0,1)","Let $u \in L^2(0,1)$. If $$u'' \in L^2(0,1)$$ is it true that $$u' \in L^2(0,1)?$$  Why yes/not? If $u, u'' \in L^2(0, 1)$ do not imply that $u' \in L^2(0,1)$, how can I show that $u' \in L^2(0,1)$? Thank you!","Let $u \in L^2(0,1)$. If $$u'' \in L^2(0,1)$$ is it true that $$u' \in L^2(0,1)?$$  Why yes/not? If $u, u'' \in L^2(0, 1)$ do not imply that $u' \in L^2(0,1)$, how can I show that $u' \in L^2(0,1)$? Thank you!",,"['functional-analysis', 'measure-theory', 'derivatives']"
5,Approximate Identities,Approximate Identities,,"Statement : Let $U$ be a C* algebra and$\lambda=\left\{A\in U:A\geq 0, ||A||<1\right\}$. If $B\in \lambda$ then if $X\in U$ $$||X^*(I-B)^2X||\leq ||X^*(I-B)X||$$ For reference this is from Davidson's $C^*$ Algebras by Example, where he proves that every $C^*$ algebra has an approximate identity. Question how do they arrive at that inequality?","Statement : Let $U$ be a C* algebra and$\lambda=\left\{A\in U:A\geq 0, ||A||<1\right\}$. If $B\in \lambda$ then if $X\in U$ $$||X^*(I-B)^2X||\leq ||X^*(I-B)X||$$ For reference this is from Davidson's $C^*$ Algebras by Example, where he proves that every $C^*$ algebra has an approximate identity. Question how do they arrive at that inequality?",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'c-star-algebras', 'banach-algebras']"
6,Is the 3d Schwartz space isomorphic to a subspace of the 1d Schwartz space?,Is the 3d Schwartz space isomorphic to a subspace of the 1d Schwartz space?,,"Are the Schwartz-spaces $\mathscr{S}(\mathbb{R})$ and $\mathscr{S}(\mathbb{R}^3)$ isomorphic (as topological vector spaces)? Is $\mathscr{S}(\mathbb{R}^3)$ at least isomorphic to a subspace of $\mathscr{S}(\mathbb{R})$? (These are simplified versions of item 3. and 4. from this question . Sorry for reposting them here...) I think that $\mathscr{S}(\mathbb{R})$ is isomorphic to a subspace of $\mathscr{S}(\mathbb{R}^3)$, for example to the subspace of functions of the form $f(x)\exp(-y^2-z^2)$. Is this correct? One hint that $\mathscr{S}(\mathbb{R}^3)$ might indeed be isomorphic to a subspace of $\mathscr{S}(\mathbb{R})$ can be found in the Encyclopedia of Mathematics article Nuclear space : Every nuclear space of type Fréchet is isomorphic to a subspace of the space $\mathscr{E}(\mathbb R)$ of infinitely-differentiable functions on the real line, that is, $\mathscr{E}(\mathbb R)$ is a universal space for the nuclear spaces of type Fréchet (see [10]). [10]    T. Komura, Y. Komura, ""Ueber die Einbettung der nuklearen Räume in $(s)^A$"" Math. Ann. , 162 (1965–1966) pp. 284–288","Are the Schwartz-spaces $\mathscr{S}(\mathbb{R})$ and $\mathscr{S}(\mathbb{R}^3)$ isomorphic (as topological vector spaces)? Is $\mathscr{S}(\mathbb{R}^3)$ at least isomorphic to a subspace of $\mathscr{S}(\mathbb{R})$? (These are simplified versions of item 3. and 4. from this question . Sorry for reposting them here...) I think that $\mathscr{S}(\mathbb{R})$ is isomorphic to a subspace of $\mathscr{S}(\mathbb{R}^3)$, for example to the subspace of functions of the form $f(x)\exp(-y^2-z^2)$. Is this correct? One hint that $\mathscr{S}(\mathbb{R}^3)$ might indeed be isomorphic to a subspace of $\mathscr{S}(\mathbb{R})$ can be found in the Encyclopedia of Mathematics article Nuclear space : Every nuclear space of type Fréchet is isomorphic to a subspace of the space $\mathscr{E}(\mathbb R)$ of infinitely-differentiable functions on the real line, that is, $\mathscr{E}(\mathbb R)$ is a universal space for the nuclear spaces of type Fréchet (see [10]). [10]    T. Komura, Y. Komura, ""Ueber die Einbettung der nuklearen Räume in $(s)^A$"" Math. Ann. , 162 (1965–1966) pp. 284–288",,"['functional-analysis', 'topological-vector-spaces', 'schwartz-space']"
7,Dense subset in sequence space,Dense subset in sequence space,,"I'm trying to prove that $F=\{x=\{x_n\}_{n\in \mathbb{N}}\in l^2(\mathbb{N}):\sum_{n=1}^{\infty} x_n=0\}$ is dense in the sequence space $l^2(\mathbb{N})$. I think it should be an easy exercise, but I don't see why an arbitrary sequence $x \in l^2(\mathbb{N})$ is the limit of one in F. Any hint would be of help, thanks!","I'm trying to prove that $F=\{x=\{x_n\}_{n\in \mathbb{N}}\in l^2(\mathbb{N}):\sum_{n=1}^{\infty} x_n=0\}$ is dense in the sequence space $l^2(\mathbb{N})$. I think it should be an easy exercise, but I don't see why an arbitrary sequence $x \in l^2(\mathbb{N})$ is the limit of one in F. Any hint would be of help, thanks!",,"['functional-analysis', 'lp-spaces']"
8,Properties of solutions to the associated Legendre ODE,Properties of solutions to the associated Legendre ODE,,"The associated Legendre ODE is given by $$  \left( (1-x^2) f'(x) \right)' - \frac{m^2}{1-x^2} f(x) = \lambda f(x)$$ The eigenfunctions have certain properties that I would like to understand by looking NOT at the eigenfunctions and eigenvalues but only by referring to the ODE itself. So please pretend that you are not aware of the fact that you can construct the two things analytically. Then, we have that the eigenfunctions are all $C^{\infty}$ if we exclude the Legendre-polynomials of the second kind, can we see this directly from the differential equation? Probably this follows for the Legendre polynomials somehow if we require boundedness of the solutions at the end of the interval to exclude the Legendre polynomials of the second kind. But how does this follow for the associated Legendre polynomials, i.e. then the ODE has an additional singular term that could cause additional trouble? Despite, all the solutions are proper well-behaved functions, so we should somehow see this out of the ODE itself. Furthermore, if we increase $m$, then the ground-state solutions get higher. I mean, if we start with $m=0$, then the ground-state is $\lambda=0$, for $m=1$ we have $\lambda= 1(1+1)=2$ and for $m=2$ we have $\lambda = 2(2+1)=6$. Can we see this directly out of the differential equations that this is the case?","The associated Legendre ODE is given by $$  \left( (1-x^2) f'(x) \right)' - \frac{m^2}{1-x^2} f(x) = \lambda f(x)$$ The eigenfunctions have certain properties that I would like to understand by looking NOT at the eigenfunctions and eigenvalues but only by referring to the ODE itself. So please pretend that you are not aware of the fact that you can construct the two things analytically. Then, we have that the eigenfunctions are all $C^{\infty}$ if we exclude the Legendre-polynomials of the second kind, can we see this directly from the differential equation? Probably this follows for the Legendre polynomials somehow if we require boundedness of the solutions at the end of the interval to exclude the Legendre polynomials of the second kind. But how does this follow for the associated Legendre polynomials, i.e. then the ODE has an additional singular term that could cause additional trouble? Despite, all the solutions are proper well-behaved functions, so we should somehow see this out of the ODE itself. Furthermore, if we increase $m$, then the ground-state solutions get higher. I mean, if we start with $m=0$, then the ground-state is $\lambda=0$, for $m=1$ we have $\lambda= 1(1+1)=2$ and for $m=2$ we have $\lambda = 2(2+1)=6$. Can we see this directly out of the differential equations that this is the case?",,"['real-analysis', 'analysis']"
9,Metrizability of the unit ball $B_{X^*}$.,Metrizability of the unit ball .,B_{X^*},"I am trying to prove the assertion: If $X$ is a separable normed space, then the unit ball in $X^*$ with   the weak* topology,  $(B_{X^*},\sigma(X^*,X))$, is metrizable. Firstly, I took $D=(x_n)\subset X$, $\overline{D}=X$. If $\sigma(X^*,D)$ is the topology in $X^*$ with countable local basis for $0$: $$U_n= \{x^* \in X^*: \sup\limits_{1\leq j\leq n}|x^*(x_j)|< \varepsilon_n \}$$ How can I prove that $(X^*, \sigma(X^*,D))$ is a Hausdorff TVS? If I could prove this, than I should conclude that $(X^*, \sigma(X^*,D))$ is metrizable. Then I have another problem: How can I use Alaoglu's Theorem to show that $\sigma(X^*,D)=\sigma(X^*,X)$ in $B_{X^*}$ ?","I am trying to prove the assertion: If $X$ is a separable normed space, then the unit ball in $X^*$ with   the weak* topology,  $(B_{X^*},\sigma(X^*,X))$, is metrizable. Firstly, I took $D=(x_n)\subset X$, $\overline{D}=X$. If $\sigma(X^*,D)$ is the topology in $X^*$ with countable local basis for $0$: $$U_n= \{x^* \in X^*: \sup\limits_{1\leq j\leq n}|x^*(x_j)|< \varepsilon_n \}$$ How can I prove that $(X^*, \sigma(X^*,D))$ is a Hausdorff TVS? If I could prove this, than I should conclude that $(X^*, \sigma(X^*,D))$ is metrizable. Then I have another problem: How can I use Alaoglu's Theorem to show that $\sigma(X^*,D)=\sigma(X^*,X)$ in $B_{X^*}$ ?",,"['functional-analysis', 'normed-spaces', 'topological-vector-spaces']"
10,Direct sum of kernel and image of the adjoint operator,Direct sum of kernel and image of the adjoint operator,,"Let $H$ be a separable Hilbert space and $T:=I-A$, where $A:H\to H$ is a compac t operator. If $T^\ast$ is the adjoint operator of $T$ it can be proved that $\ker T$ and $\text{im } T^\ast:=T^\ast (H)$ are closed thanks to the compactness of $A$ (pp. 469-70 here ; I can translate for anybody interested). It is clear, from the very definition of adjoint operator, that $\ker T\perp \text{im } T^\ast$. Therefore, as Kolmgorov-Fomin's says, in order to prove that $H=\ker T\oplus \text{im } T^\ast$, it is enough to show that no non-null vector can be orthogonal to both $\ker T$ and $\text{im } T^\ast$. Why? I suppose it is a trivial thing, but the book does not explain such a fact in the chapter on linear operators and I know nothing analogous from finite dimension linear algebra cases. Thank you so much!","Let $H$ be a separable Hilbert space and $T:=I-A$, where $A:H\to H$ is a compac t operator. If $T^\ast$ is the adjoint operator of $T$ it can be proved that $\ker T$ and $\text{im } T^\ast:=T^\ast (H)$ are closed thanks to the compactness of $A$ (pp. 469-70 here ; I can translate for anybody interested). It is clear, from the very definition of adjoint operator, that $\ker T\perp \text{im } T^\ast$. Therefore, as Kolmgorov-Fomin's says, in order to prove that $H=\ker T\oplus \text{im } T^\ast$, it is enough to show that no non-null vector can be orthogonal to both $\ker T$ and $\text{im } T^\ast$. Why? I suppose it is a trivial thing, but the book does not explain such a fact in the chapter on linear operators and I know nothing analogous from finite dimension linear algebra cases. Thank you so much!",,"['linear-algebra', 'functional-analysis', 'hilbert-spaces']"
11,A Counter Example about Closed Graph Theorem,A Counter Example about Closed Graph Theorem,,"This is an example I read around closed graph theorem. Let $Y=C[0, 1]$ and $X$ be its subset $C^\infty[0, 1]$. Equip both with uniform norm. Define $D: X \to Y$ by $f \mapsto f'$. Suppose $(f_n, f_n') \to (g, h)$ in $X \times Y$. Thus, $f_n \to g, f_n' \to h$ both uniformly on $[0, 1]$. It is well known that $g' = h$. Thus, the graph of $D$ is closed. But since $D(t^n) = nt^{n-1}$, $D$ is not continuous. I have three questions about this example. Why $f_n \to g, f_n' \to h$ both uniformly on $[0, 1]$? Why $g' = h$ even though it is well known ? Why $D$ is not continuous because $D(t^n) = nt^{n-1}$? Could anyone explain these questions to me, please? Thank you!","This is an example I read around closed graph theorem. Let $Y=C[0, 1]$ and $X$ be its subset $C^\infty[0, 1]$. Equip both with uniform norm. Define $D: X \to Y$ by $f \mapsto f'$. Suppose $(f_n, f_n') \to (g, h)$ in $X \times Y$. Thus, $f_n \to g, f_n' \to h$ both uniformly on $[0, 1]$. It is well known that $g' = h$. Thus, the graph of $D$ is closed. But since $D(t^n) = nt^{n-1}$, $D$ is not continuous. I have three questions about this example. Why $f_n \to g, f_n' \to h$ both uniformly on $[0, 1]$? Why $g' = h$ even though it is well known ? Why $D$ is not continuous because $D(t^n) = nt^{n-1}$? Could anyone explain these questions to me, please? Thank you!",,"['real-analysis', 'analysis', 'functional-analysis', 'self-learning', 'banach-spaces']"
12,"Is c, the Banach space of convergent sequences with the sup norm, separable?","Is c, the Banach space of convergent sequences with the sup norm, separable?",,"Is $c$, the Banach space of convergent sequences with the sup norm, separable? Let $X$ be the set of all sequences which are rational numbers, that converge to some rational number $x$. As the rationals are countably infinite, we need to only show that $X$ is dense in $c$. That is what I am a bit unsure how to show... help would be appreciated.","Is $c$, the Banach space of convergent sequences with the sup norm, separable? Let $X$ be the set of all sequences which are rational numbers, that converge to some rational number $x$. As the rationals are countably infinite, we need to only show that $X$ is dense in $c$. That is what I am a bit unsure how to show... help would be appreciated.",,['functional-analysis']
13,Bochner Integral: Integrability,Bochner Integral: Integrability,,"Attention This question has been slightly modified!! Reference It is related to: Bochner Integral: Axioms Problem Given a measure space $\Omega$ and a Banach space $E$. Consider Bochner measurable functions $F\in\mathcal{B}$. Then integrability is given by: $$\int\|F-S_n\|\mathrm{d}\mu\to0\iff\int\|F\|\mathrm{d}\mu<\infty$$ On the one hand it holds: $$\int\|F\|\mathrm{d}\mu\leq\int\|F-S_N\|\mathrm{d}\mu+\int\|S_N\|\mathrm{d}\mu<1+\infty$$ What about the converse? Addendum There's another didactic definition of integrability: $$F\in\mathcal{L}:\iff\int\|S_m-S_n\|\mathrm{d}\mu\to0\quad(S_n\to F)$$ Certainly, one has for a suitable approximation: $$S_n\to F:\quad\int\|S_m-S_n\|\mathrm{d}\mu\leq\int\|F-S_m\|\mathrm{d}\mu+\int\|F-S_n\|\mathrm{d}\mu\to0$$ But what about the converse here? Caution Although an integral gives the impression of measurability one should keep in mind that: $$\int\|F-S_n\|\mathrm{d}\mu\to0\quad\nRightarrow\quad F\in\mathcal{B}$$ (For a counterexample see: Bochner Integral: Approximability )","Attention This question has been slightly modified!! Reference It is related to: Bochner Integral: Axioms Problem Given a measure space $\Omega$ and a Banach space $E$. Consider Bochner measurable functions $F\in\mathcal{B}$. Then integrability is given by: $$\int\|F-S_n\|\mathrm{d}\mu\to0\iff\int\|F\|\mathrm{d}\mu<\infty$$ On the one hand it holds: $$\int\|F\|\mathrm{d}\mu\leq\int\|F-S_N\|\mathrm{d}\mu+\int\|S_N\|\mathrm{d}\mu<1+\infty$$ What about the converse? Addendum There's another didactic definition of integrability: $$F\in\mathcal{L}:\iff\int\|S_m-S_n\|\mathrm{d}\mu\to0\quad(S_n\to F)$$ Certainly, one has for a suitable approximation: $$S_n\to F:\quad\int\|S_m-S_n\|\mathrm{d}\mu\leq\int\|F-S_m\|\mathrm{d}\mu+\int\|F-S_n\|\mathrm{d}\mu\to0$$ But what about the converse here? Caution Although an integral gives the impression of measurability one should keep in mind that: $$\int\|F-S_n\|\mathrm{d}\mu\to0\quad\nRightarrow\quad F\in\mathcal{B}$$ (For a counterexample see: Bochner Integral: Approximability )",,"['integration', 'functional-analysis', 'measure-theory']"
14,Nontrivial solutions of $\sum\limits_{-\infty}^\infty\overline{a_n}a_{n+k}=\delta_{k0}$,Nontrivial solutions of,\sum\limits_{-\infty}^\infty\overline{a_n}a_{n+k}=\delta_{k0},"Let $a=(a_n)$ with $a_n\in\mathbb{C}$ be a vector indexed over all $n\in\mathbb{Z}$, and consider the system of equations $\sum\limits_{-\infty}^\infty\overline{a_n}a_{n+k}=\delta_{k0}$ for all $k\in\mathbb{Z}$. One may verify this has a family of trivial solutions given by $a_n=\delta_{nm}$ for some nonzero integer $m$. Assuming $a_0=0$, are there any other solutions? This problem is inspired by (unsuccessful) attempts to find a tractable solution to an earlier question of mine. What I wanted was a closed curve $z(s)\in\mathbb{C}$ whose Fourier series was arc-length parametrized i.e. $z(s)=\sum\limits_{n=-\infty}^\infty c_n e^{i n s}$ with $|z'(s)|^2=\sum\limits_{nm}(n\overline{c_n})(m c_m)e^{i (m-n)s}=1$ for all $s\in\mathbb{R}$. This requires $\sum\limits_{-\infty}^\infty nm\overline{c_n}c_{m}=\delta_{nm}$ for all $m$, which upon identifying $m=n+k$ and $a_n=n c_n$ yields the system of equations above. Unfortunately, the only solutions which are obvious to me are the trivial ones given above (i.e. a single mode $e^{i m s}$). Any nontrivial solutions appear to involve all frequencies; a construction of such would clarify my questions greatly.","Let $a=(a_n)$ with $a_n\in\mathbb{C}$ be a vector indexed over all $n\in\mathbb{Z}$, and consider the system of equations $\sum\limits_{-\infty}^\infty\overline{a_n}a_{n+k}=\delta_{k0}$ for all $k\in\mathbb{Z}$. One may verify this has a family of trivial solutions given by $a_n=\delta_{nm}$ for some nonzero integer $m$. Assuming $a_0=0$, are there any other solutions? This problem is inspired by (unsuccessful) attempts to find a tractable solution to an earlier question of mine. What I wanted was a closed curve $z(s)\in\mathbb{C}$ whose Fourier series was arc-length parametrized i.e. $z(s)=\sum\limits_{n=-\infty}^\infty c_n e^{i n s}$ with $|z'(s)|^2=\sum\limits_{nm}(n\overline{c_n})(m c_m)e^{i (m-n)s}=1$ for all $s\in\mathbb{R}$. This requires $\sum\limits_{-\infty}^\infty nm\overline{c_n}c_{m}=\delta_{nm}$ for all $m$, which upon identifying $m=n+k$ and $a_n=n c_n$ yields the system of equations above. Unfortunately, the only solutions which are obvious to me are the trivial ones given above (i.e. a single mode $e^{i m s}$). Any nontrivial solutions appear to involve all frequencies; a construction of such would clarify my questions greatly.",,"['linear-algebra', 'functional-analysis', 'fourier-series', 'plane-curves']"
15,Spectral theory,Spectral theory,,"I have absolutely no idea about Spectral theory and want to ask some fundamental questions. 1.) What does it mean that the resolvent of an operator is Hilbert-Schmidt? (Cause I saw a theorem that was like: The resolvent of our self-adjoint operator is Hilbert-Schmidt, hence all eigenvalues are purely discrete and the eigenfunctions are simple and form an orthonormal basis). I don't see how this Hilbert-Schmidt is related to any of the other things. 2.) Can we always represent the resolvent of a self-adjoint operator with a Hilbert-Schmidt integral operator and is the Hilbert Schmidt integral kernel the same as the Green's function? If anything is unclear, please let me know.","I have absolutely no idea about Spectral theory and want to ask some fundamental questions. 1.) What does it mean that the resolvent of an operator is Hilbert-Schmidt? (Cause I saw a theorem that was like: The resolvent of our self-adjoint operator is Hilbert-Schmidt, hence all eigenvalues are purely discrete and the eigenfunctions are simple and form an orthonormal basis). I don't see how this Hilbert-Schmidt is related to any of the other things. 2.) Can we always represent the resolvent of a self-adjoint operator with a Hilbert-Schmidt integral operator and is the Hilbert Schmidt integral kernel the same as the Green's function? If anything is unclear, please let me know.",,"['real-analysis', 'analysis']"
16,Cartesian product of reflexive spaces is reflexive,Cartesian product of reflexive spaces is reflexive,,"Given $(E,\|\|_E),(F,\|\|_F)$ reflexive normed vector spaces. I have to prove that also $(E\times F,\|\|_{E\times F})$ is reflexive where $\|\|_{E\times F}$ is the product norm. What I know is that $(E\times F)'$ is algebrically and topologically isomorphic to $E'\times F'$.","Given $(E,\|\|_E),(F,\|\|_F)$ reflexive normed vector spaces. I have to prove that also $(E\times F,\|\|_{E\times F})$ is reflexive where $\|\|_{E\times F}$ is the product norm. What I know is that $(E\times F)'$ is algebrically and topologically isomorphic to $E'\times F'$.",,"['functional-analysis', 'normed-spaces']"
17,"Is a non-compact Riemannian manifold a ""measure space""?","Is a non-compact Riemannian manifold a ""measure space""?",,"One can define $L^p$ spaces for measure spaces with a given measure. Is a non-compact (i.e., it has a boundary) bounded Riemannian manifold a measure space? I am thinking of the manifold $(0,T) \times S$ where $S$ is a $n-1$ dimensional hypersurface embedded in $\mathbb{R}^n$. I want to know so I can use the $L^p$ theory already available. Are there any technicalities I need to worry about?  Basically I want density of continuous functions on a manifold that I have in mind. Thanks.","One can define $L^p$ spaces for measure spaces with a given measure. Is a non-compact (i.e., it has a boundary) bounded Riemannian manifold a measure space? I am thinking of the manifold $(0,T) \times S$ where $S$ is a $n-1$ dimensional hypersurface embedded in $\mathbb{R}^n$. I want to know so I can use the $L^p$ theory already available. Are there any technicalities I need to worry about?  Basically I want density of continuous functions on a manifold that I have in mind. Thanks.",,"['functional-analysis', 'manifolds', 'lp-spaces']"
18,The Levi-Civita connection in infinite dimensions,The Levi-Civita connection in infinite dimensions,,Is there an analogue of the Fundamental Theorem of Riemannian Geometry for (some subclass of) infinite-dimensional manifolds?,Is there an analogue of the Fundamental Theorem of Riemannian Geometry for (some subclass of) infinite-dimensional manifolds?,,"['functional-analysis', 'differential-geometry', 'riemannian-geometry']"
19,Counterexample about non Hausdorff topological vector spaces,Counterexample about non Hausdorff topological vector spaces,,"I have some troubles with Hausdorffness in TVS: Question 1. Is there any topological vector space $X$ which is not Hausdorff? Question 2. Give an explicit example of a topological vector space $X$ (Hausdorff / non Hausdorff) such that $(X, \tau_w)$ is not Hausdorff? Question 3. Prove that, for any topological vector space $X$, $(X^*, \tau_{w^*})$ always Hausdorff. Thanks in advance!","I have some troubles with Hausdorffness in TVS: Question 1. Is there any topological vector space $X$ which is not Hausdorff? Question 2. Give an explicit example of a topological vector space $X$ (Hausdorff / non Hausdorff) such that $(X, \tau_w)$ is not Hausdorff? Question 3. Prove that, for any topological vector space $X$, $(X^*, \tau_{w^*})$ always Hausdorff. Thanks in advance!",,"['functional-analysis', 'topological-vector-spaces']"
20,Why is the set of all $\infty$-tuples with finitely many non-zero rational terms dense in $\ell_2$?,Why is the set of all -tuples with finitely many non-zero rational terms dense in ?,\infty \ell_2,"This statement has been given as an example in the book ""Introductory real analysis"" written by Kolmogorov and Fomin: The set of all points $x=(x_1,x_2,\cdots,x_n,\cdots)$ with only   finitely many non-zero coordinates, each a rational number, is dense   in the space $\ell_2$. and $\ell_2$ is defined this way: $$\ell_2 = \{ (x_1,x_2, \cdots, x_n, \cdots): \sum_{n=1}^\infty x_n^2 <\infty  \text{ and } x_n \in \mathbb{R} \} $$ Analysis is one of my weak subjects in math. So, please bear with me. I know what I need to show. Suppose that I define: $$A = \{ (x_1,x_2, \cdots, x_n, \cdots): \text{only finitely many terms are non-zero and }  x_i \in \mathbb{Q} \}$$ I need to show that if $(x_n)_{n \in\mathbb{N}}$ is in $l_2$ then one can find a ""sequence of sequences in $A$"" such that the limit approaches to $(x_n)_{n \in \mathbb{N}}$. So, if I was allowed to use sequences like $(x_1,x_2, \cdots, x_n, \cdots)$ where only finitely many terms are non-zero but the terms were allowed to be in $\mathbb{R}$ I was done because for any sequence $(x_n)$ the sequence $(y_k)$ where $y_k = (x_1, x_2, \cdots, x_k, 0, 0, 0, \cdots, 0, \cdots)$ works. Am I right? Now the problem is that I should find a sequence like $y_k$ where this time all terms must be chosen from rational numbers. This is my solution for this: Since $\mathbb{Q}$ is dense in $\mathbb{R}$ I can find a sequence of rational numbers that approaches any given real number $x_i$. therefore: $$x_1 = \lim (q_{11},q_{12},q_{13}, \cdots, q_{1n}, \cdots)$$ $$x_2 = \lim (q_{21},q_{22},q_{23}, \cdots, q_{2n}, \cdots)$$ $$\vdots$$ $$x_i = \lim (q_{i1},q_{i2},q_{i3}, \cdots, q_{in}, \cdots)$$ $$\vdots$$ Now I create my new sequence this way: $$y_1 = (q_{11},0,0,0,0,0,0,\cdots)$$ $$y_2 = (q_{12},q_{22},0,0,0,0,\cdots)$$ $$y_3 = (q_{13},q_{23},q_{33},0,0,\cdots)$$ and $y_k$ is formed the similar way. I mean you go the $k$-th column and choose $q_{1k},q_{2k},\cdots,q_{kk}$ on the rows and put zero for all other entries beyond the $k$-th coordinate. I want to claim that given any $x=(x_1,x_2, \cdots, x_n, \cdots)$ in $\ell_2$, the sequence $(y_k)_{n \in \mathbb{N}}$ constructed in the way just explained approaches $x \in \ell_2$. I think it is obvious that this is true because: $$\lim_{k \to \infty} y_k = (\lim_{k \to \infty} q_{nk})_{n \in \mathbb{N}} = (x_n)_{n \in \mathbb{N}}$$ Does what I'm saying makes sense? Is my solution correct or it needs to be modified?","This statement has been given as an example in the book ""Introductory real analysis"" written by Kolmogorov and Fomin: The set of all points $x=(x_1,x_2,\cdots,x_n,\cdots)$ with only   finitely many non-zero coordinates, each a rational number, is dense   in the space $\ell_2$. and $\ell_2$ is defined this way: $$\ell_2 = \{ (x_1,x_2, \cdots, x_n, \cdots): \sum_{n=1}^\infty x_n^2 <\infty  \text{ and } x_n \in \mathbb{R} \} $$ Analysis is one of my weak subjects in math. So, please bear with me. I know what I need to show. Suppose that I define: $$A = \{ (x_1,x_2, \cdots, x_n, \cdots): \text{only finitely many terms are non-zero and }  x_i \in \mathbb{Q} \}$$ I need to show that if $(x_n)_{n \in\mathbb{N}}$ is in $l_2$ then one can find a ""sequence of sequences in $A$"" such that the limit approaches to $(x_n)_{n \in \mathbb{N}}$. So, if I was allowed to use sequences like $(x_1,x_2, \cdots, x_n, \cdots)$ where only finitely many terms are non-zero but the terms were allowed to be in $\mathbb{R}$ I was done because for any sequence $(x_n)$ the sequence $(y_k)$ where $y_k = (x_1, x_2, \cdots, x_k, 0, 0, 0, \cdots, 0, \cdots)$ works. Am I right? Now the problem is that I should find a sequence like $y_k$ where this time all terms must be chosen from rational numbers. This is my solution for this: Since $\mathbb{Q}$ is dense in $\mathbb{R}$ I can find a sequence of rational numbers that approaches any given real number $x_i$. therefore: $$x_1 = \lim (q_{11},q_{12},q_{13}, \cdots, q_{1n}, \cdots)$$ $$x_2 = \lim (q_{21},q_{22},q_{23}, \cdots, q_{2n}, \cdots)$$ $$\vdots$$ $$x_i = \lim (q_{i1},q_{i2},q_{i3}, \cdots, q_{in}, \cdots)$$ $$\vdots$$ Now I create my new sequence this way: $$y_1 = (q_{11},0,0,0,0,0,0,\cdots)$$ $$y_2 = (q_{12},q_{22},0,0,0,0,\cdots)$$ $$y_3 = (q_{13},q_{23},q_{33},0,0,\cdots)$$ and $y_k$ is formed the similar way. I mean you go the $k$-th column and choose $q_{1k},q_{2k},\cdots,q_{kk}$ on the rows and put zero for all other entries beyond the $k$-th coordinate. I want to claim that given any $x=(x_1,x_2, \cdots, x_n, \cdots)$ in $\ell_2$, the sequence $(y_k)_{n \in \mathbb{N}}$ constructed in the way just explained approaches $x \in \ell_2$. I think it is obvious that this is true because: $$\lim_{k \to \infty} y_k = (\lim_{k \to \infty} q_{nk})_{n \in \mathbb{N}} = (x_n)_{n \in \mathbb{N}}$$ Does what I'm saying makes sense? Is my solution correct or it needs to be modified?",,"['real-analysis', 'analysis', 'functional-analysis', 'proof-verification', 'lp-spaces']"
21,Dense subspace in a Hilbert space,Dense subspace in a Hilbert space,,Let $H$ be a Hilbert Space and $\{e_n\}_{n\in\mathbb{N}}$ an orthonormal basis. Now let $(x_n)$ be a sequence in $H$ satisfying $$\sum_{n=1}^{\infty}||x_n-e_n||^2<1.$$ Prove that $\operatorname{lin}\{x_n:n\in\mathbb{N}\}$ is dense in $H$. I don't know even how to start this problem...,Let $H$ be a Hilbert Space and $\{e_n\}_{n\in\mathbb{N}}$ an orthonormal basis. Now let $(x_n)$ be a sequence in $H$ satisfying $$\sum_{n=1}^{\infty}||x_n-e_n||^2<1.$$ Prove that $\operatorname{lin}\{x_n:n\in\mathbb{N}\}$ is dense in $H$. I don't know even how to start this problem...,,"['functional-analysis', 'hilbert-spaces']"
22,Showing a linear map has a unique extension from a Sobolev space to an Lp space,Showing a linear map has a unique extension from a Sobolev space to an Lp space,,"This is related to another question I asked: Directional derivative in a Sobolev-like inequality Suppose that $u \in C_{0}^{\infty}(\Omega)$. Show that the linear map $u \to u(x,0) \in C^{\infty}(\mathbb{R}^{n})$ has a unique continuous extension as a map from $W^{1,p}_{0}(\Omega)$ to $L^{p}(\partial \Omega_{+})$, where $\partial \Omega_{+} \equiv \{x;(x,0)\in\Omega\}$. I know that you can define extensions from one Sobolev space to another. Is the reason why we can do it here from a Sobolev space to an $L^{p}$ space because $L^{p}$ spaces are contained inside Sobolev spaces? Also, I was thinking about using the BLT Theorem, but do I know that the map from $u$ to $u(x,0)$ is bounded? I'm very confused, and not as well-versed in functional analysis as I should be, so any assistance/hints you could give me for this proof would be much appreciated!","This is related to another question I asked: Directional derivative in a Sobolev-like inequality Suppose that $u \in C_{0}^{\infty}(\Omega)$. Show that the linear map $u \to u(x,0) \in C^{\infty}(\mathbb{R}^{n})$ has a unique continuous extension as a map from $W^{1,p}_{0}(\Omega)$ to $L^{p}(\partial \Omega_{+})$, where $\partial \Omega_{+} \equiv \{x;(x,0)\in\Omega\}$. I know that you can define extensions from one Sobolev space to another. Is the reason why we can do it here from a Sobolev space to an $L^{p}$ space because $L^{p}$ spaces are contained inside Sobolev spaces? Also, I was thinking about using the BLT Theorem, but do I know that the map from $u$ to $u(x,0)$ is bounded? I'm very confused, and not as well-versed in functional analysis as I should be, so any assistance/hints you could give me for this proof would be much appreciated!",,['functional-analysis']
23,Do the homomorphisms really have to be continuous?,Do the homomorphisms really have to be continuous?,,"I read that If $\varphi, \psi$ are continuous homomorphisms from a normed algebra $A$ to a normed algebra $B$ then $\varphi = \psi$ if $\varphi$ and $\psi$ are equal on a set $S$ that generates the algebra $A$. Do they really have to be continuous? As far as I can tell even if they are not but agree on $S$ and $S$ generates $A$ then they still have to be equal. The equality seems to follow from the properties of homomorphisms.","I read that If $\varphi, \psi$ are continuous homomorphisms from a normed algebra $A$ to a normed algebra $B$ then $\varphi = \psi$ if $\varphi$ and $\psi$ are equal on a set $S$ that generates the algebra $A$. Do they really have to be continuous? As far as I can tell even if they are not but agree on $S$ and $S$ generates $A$ then they still have to be equal. The equality seems to follow from the properties of homomorphisms.",,"['functional-analysis', 'banach-algebras']"
24,Orthogonal complement examples,Orthogonal complement examples,,"I am looking for an example such that in a pre-Hilbert space $H$ we have for a subspace $U$ that (i) $\bar{U} \oplus U^\perp \neq H$ (ii) $ \bar{U} \neq U^{\perp \perp}$  Since finite and closed subspaces will probably not do it, I am not good at inventing nice examples. Does anybody here have a few at hand?","I am looking for an example such that in a pre-Hilbert space $H$ we have for a subspace $U$ that (i) $\bar{U} \oplus U^\perp \neq H$ (ii) $ \bar{U} \neq U^{\perp \perp}$  Since finite and closed subspaces will probably not do it, I am not good at inventing nice examples. Does anybody here have a few at hand?",,"['calculus', 'real-analysis']"
25,"Extending continuous, densely-defined linear maps between locally convex spaces","Extending continuous, densely-defined linear maps between locally convex spaces",,"Let $X$ and $Y$ be locally convex topological vector spaces, say over $\mathbb{C}$. To set the stage a bit, I'll say that the topology on $X$ is given by a separating family of semi-norms $(p_i)_{i \in I}$ and, similarly, the topology on $Y$ is given by a family $(q_j)_{j \in J}$. Now, suppose that $V \subset X$ is a dense subspace of $X$ and $T : V \to Y$ is a continuous linear map. Does there exist, then, a (unique) continuous extension $\overline T : X \to Y$ of $T$? The answer is yes for Banach spaces, and this is an incredibly useful fact. The norm seems pretty crucial to the proof though. Any easy counterexamples?","Let $X$ and $Y$ be locally convex topological vector spaces, say over $\mathbb{C}$. To set the stage a bit, I'll say that the topology on $X$ is given by a separating family of semi-norms $(p_i)_{i \in I}$ and, similarly, the topology on $Y$ is given by a family $(q_j)_{j \in J}$. Now, suppose that $V \subset X$ is a dense subspace of $X$ and $T : V \to Y$ is a continuous linear map. Does there exist, then, a (unique) continuous extension $\overline T : X \to Y$ of $T$? The answer is yes for Banach spaces, and this is an incredibly useful fact. The norm seems pretty crucial to the proof though. Any easy counterexamples?",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
26,Relationship between a finite codimensional subspace of dual space and the annihilator,Relationship between a finite codimensional subspace of dual space and the annihilator,,"Notation: $X$ is a banach space, $X'$ is the dual space to $X$. When $V \subset X'$, we write $\ker V = \cap_{l \in V} \ker l$, and when $W \subset X$, we write $ann \; W = \{l \in X' \mid l(w) = 0 \text{ for all } w \in W \}$. When $V$ is a finite-dimensional subspace of $X'$, it is well-known (at least to math.stackexchange, where it's been asked about 3,000 times) that $$ V = ann \; (\ker V) $$ My question: is this true when $V$ is a closed, finite CO-dimensional subspace? For me, this means that there is a complement $W \subset X'$ of finite dimension to $V$ in $W$, such that the splitting $X' = W \oplus V$ is topological.","Notation: $X$ is a banach space, $X'$ is the dual space to $X$. When $V \subset X'$, we write $\ker V = \cap_{l \in V} \ker l$, and when $W \subset X$, we write $ann \; W = \{l \in X' \mid l(w) = 0 \text{ for all } w \in W \}$. When $V$ is a finite-dimensional subspace of $X'$, it is well-known (at least to math.stackexchange, where it's been asked about 3,000 times) that $$ V = ann \; (\ker V) $$ My question: is this true when $V$ is a closed, finite CO-dimensional subspace? For me, this means that there is a complement $W \subset X'$ of finite dimension to $V$ in $W$, such that the splitting $X' = W \oplus V$ is topological.",,"['linear-algebra', 'functional-analysis', 'banach-spaces']"
27,"If $\sum_n \|x\|< \infty$, how to show that $\sum x_n$ is convergent in the Hilbert space $H$. [duplicate]","If , how to show that  is convergent in the Hilbert space . [duplicate]",\sum_n \|x\|< \infty \sum x_n H,"This question already has answers here : Converging series in Banach space (2 answers) Closed 10 years ago . Let $\{x_n\}$ be a sequence in a Hilbert space $H$. If $\sum_n \|x\|< \infty$, how to show that $\sum x_n$ is convergent in $H$? There is no doubt that $x_n \rightarrow 0$ as $n \rightarrow \infty$ (right?) since we have that \begin{align*} \sum_n \|x\|< \infty &\iff \|x_n\|\rightarrow 0 \text{ as } n \rightarrow \infty \\ &\iff \langle x_n,x_n\rangle \rightarrow 0 \text{ as } n \rightarrow \infty \\ &\iff x_n \rightarrow 0 \text{ as } n\rightarrow \infty \end{align*} (it is a property of the inner product that $\langle x,x\rangle=0 \implies x=0$) What to do next? Can I use the completeness of $H$ somehow?","This question already has answers here : Converging series in Banach space (2 answers) Closed 10 years ago . Let $\{x_n\}$ be a sequence in a Hilbert space $H$. If $\sum_n \|x\|< \infty$, how to show that $\sum x_n$ is convergent in $H$? There is no doubt that $x_n \rightarrow 0$ as $n \rightarrow \infty$ (right?) since we have that \begin{align*} \sum_n \|x\|< \infty &\iff \|x_n\|\rightarrow 0 \text{ as } n \rightarrow \infty \\ &\iff \langle x_n,x_n\rangle \rightarrow 0 \text{ as } n \rightarrow \infty \\ &\iff x_n \rightarrow 0 \text{ as } n\rightarrow \infty \end{align*} (it is a property of the inner product that $\langle x,x\rangle=0 \implies x=0$) What to do next? Can I use the completeness of $H$ somehow?",,['functional-analysis']
28,When do inner products of weakly convergent subsequences converge?,When do inner products of weakly convergent subsequences converge?,,"If we have 2 weakly convergent subsequences in $L^2(U)$ (for $U$ some bounded open domain with smooth boundary), $u_k\rightharpoonup u$ and $v_k\rightharpoonup v$, under which conditions do we have $$\langle u_k,v_k \rangle \to \langle u, v \rangle?$$ I can see that if $u_k \to u$ strongly and $\{v_k\}_{k=1}^{\infty}$ is bounded then the result follows but I don't know when it would be true if both convergences are only weak. Thanks!","If we have 2 weakly convergent subsequences in $L^2(U)$ (for $U$ some bounded open domain with smooth boundary), $u_k\rightharpoonup u$ and $v_k\rightharpoonup v$, under which conditions do we have $$\langle u_k,v_k \rangle \to \langle u, v \rangle?$$ I can see that if $u_k \to u$ strongly and $\{v_k\}_{k=1}^{\infty}$ is bounded then the result follows but I don't know when it would be true if both convergences are only weak. Thanks!",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'weak-convergence']"
29,Convolution of distributions is not associative,Convolution of distributions is not associative,,"I need some help with this exercise: It proposes to show that convolution of distributions is not associative: If $T=T_1$ (distribution given by f=1), $S=\delta'$, and $R=T_H$ (we denote as $H$ the Heaviside function, in $\mathbb{R}$), then: $$T\ast(S\ast R)\neq(T\ast S)\ast R$$ I'm not very familiarized with convolutions of distributions, so any help will be very useful. Thanks in advance.","I need some help with this exercise: It proposes to show that convolution of distributions is not associative: If $T=T_1$ (distribution given by f=1), $S=\delta'$, and $R=T_H$ (we denote as $H$ the Heaviside function, in $\mathbb{R}$), then: $$T\ast(S\ast R)\neq(T\ast S)\ast R$$ I'm not very familiarized with convolutions of distributions, so any help will be very useful. Thanks in advance.",,"['functional-analysis', 'distribution-theory', 'convolution']"
30,"Reflexive, separable containing all finite dimensional spaces almost isometrically","Reflexive, separable containing all finite dimensional spaces almost isometrically",,"Is there a separable, reflexive Banach space $Z$ such that for every finite dimensional space $X$ and every $a>0$, there is a $1+a$-embedding of $X$ into $Z$? I can do the question without the 'reflexive' (in which case it's true), but I'm totally stuck on how to find a reflexive space with this property. Please help? Thanks.","Is there a separable, reflexive Banach space $Z$ such that for every finite dimensional space $X$ and every $a>0$, there is a $1+a$-embedding of $X$ into $Z$? I can do the question without the 'reflexive' (in which case it's true), but I'm totally stuck on how to find a reflexive space with this property. Please help? Thanks.",,"['functional-analysis', 'banach-spaces']"
31,In banach algebra: Show there exists $x$ s.t. $x^2+bx+xb+c=0$,In banach algebra: Show there exists  s.t.,x x^2+bx+xb+c=0,"Let $A$ be a banach algebra with unit $e$ and $b,c\in A$ be such that $\sigma(b^2-c)\subset \mathbb{R}^+$ Then there exists $x\in A$ such that $$x^2+bx+xb+c=0$$ I want to show this, but lack the insight to proceed The only thing we got is $(b^2-c-\lambda e )$ is invertible for some $\lambda < 0$ so any suggestions are greatly appreciated.","Let $A$ be a banach algebra with unit $e$ and $b,c\in A$ be such that $\sigma(b^2-c)\subset \mathbb{R}^+$ Then there exists $x\in A$ such that $$x^2+bx+xb+c=0$$ I want to show this, but lack the insight to proceed The only thing we got is $(b^2-c-\lambda e )$ is invertible for some $\lambda < 0$ so any suggestions are greatly appreciated.",,"['functional-analysis', 'banach-algebras']"
32,"How to show that the dual of $(\mathbb{R}^n,\|{\cdot}\|_p)$ is $(\mathbb{R}^n,\|{\cdot}\|_q)$?",How to show that the dual of  is ?,"(\mathbb{R}^n,\|{\cdot}\|_p) (\mathbb{R}^n,\|{\cdot}\|_q)","I am trying to brush up on my functional analysis and I learn some $L_p$ spaces since I was never formally intrduced to them through courses. I wanted to know if anyone could offer me a proof or give me a resouce that that would have the proof of the fact that the dual space of $(\mathbb{R}^n,\|{\cdot}\|_p)$ is isometrically isomorphic to $(\mathbb{R}^n,\|{\cdot}\|_q)$ whenever $\frac{1}{p}+\frac{1}{q}=1$.","I am trying to brush up on my functional analysis and I learn some $L_p$ spaces since I was never formally intrduced to them through courses. I wanted to know if anyone could offer me a proof or give me a resouce that that would have the proof of the fact that the dual space of $(\mathbb{R}^n,\|{\cdot}\|_p)$ is isometrically isomorphic to $(\mathbb{R}^n,\|{\cdot}\|_q)$ whenever $\frac{1}{p}+\frac{1}{q}=1$.",,"['real-analysis', 'linear-algebra', 'functional-analysis', 'banach-spaces']"
33,Show that an operator is bounded (from Reed and Simon),Show that an operator is bounded (from Reed and Simon),,"I am currently reading Reed and Simon's IV: Analysis of Operators, Volume 4 (Methods of Modern Mathematical Physics). I don't understand something they do in Theorem XIII.64. The problem is: Let $A$ be a self-adjoint operator that is bounded from below, and let $P_{\Omega}$ be the family of spectral projections corresponding to $A$. Then $AP_{(-\infty, \lambda)}$ is a bounded operator. What I have thought so far: $A$ can be thought of as the identity on its spectrum and since the spectrum is bounded from below, and since $P_{(-\infty, \lambda)}$ corresponds to the characteristic function of $(-\infty, \lambda)$, $AP_{(-\infty, \lambda)}$ corresponds to the identity on a bounded set, and is then a bounded operator. I have no idea on how to give a rigorous proof of this. Edit: Here $P_{\Omega} = \chi_{\Omega}(A)$ for a Borel set $\Omega$, and where $\chi$ is the characteristic function. $AP_{\Omega}$ is composition of the operators $A$ and $P_{\Omega}$. Edit: spectral theorem (multiplication form) : Let $A$ be a self-adjoint operator on a separable Hilbert space $H$. Then there is a finite measure space $(M, \mu)$, and a unitary operator $U: H \rightarrow L^2(M, \mu)$ and a real-valued function $f$ which is finite a. e. such that $UAU^{-1}\phi(m) = f(m)\phi(m)$. spectral theorem (projection valued measure form) There is a one-to-one correspondence between self-adjoint operators $A$ and projection-valued measures $\{P_{\Omega}\}$, the correspondence is given by $$ A = \int_{-\infty}^{\infty}\lambda dP_{\lambda}, $$ where $P_{\lambda} = P_{(-\infty, \lambda)}$ Thank you for your help!","I am currently reading Reed and Simon's IV: Analysis of Operators, Volume 4 (Methods of Modern Mathematical Physics). I don't understand something they do in Theorem XIII.64. The problem is: Let $A$ be a self-adjoint operator that is bounded from below, and let $P_{\Omega}$ be the family of spectral projections corresponding to $A$. Then $AP_{(-\infty, \lambda)}$ is a bounded operator. What I have thought so far: $A$ can be thought of as the identity on its spectrum and since the spectrum is bounded from below, and since $P_{(-\infty, \lambda)}$ corresponds to the characteristic function of $(-\infty, \lambda)$, $AP_{(-\infty, \lambda)}$ corresponds to the identity on a bounded set, and is then a bounded operator. I have no idea on how to give a rigorous proof of this. Edit: Here $P_{\Omega} = \chi_{\Omega}(A)$ for a Borel set $\Omega$, and where $\chi$ is the characteristic function. $AP_{\Omega}$ is composition of the operators $A$ and $P_{\Omega}$. Edit: spectral theorem (multiplication form) : Let $A$ be a self-adjoint operator on a separable Hilbert space $H$. Then there is a finite measure space $(M, \mu)$, and a unitary operator $U: H \rightarrow L^2(M, \mu)$ and a real-valued function $f$ which is finite a. e. such that $UAU^{-1}\phi(m) = f(m)\phi(m)$. spectral theorem (projection valued measure form) There is a one-to-one correspondence between self-adjoint operators $A$ and projection-valued measures $\{P_{\Omega}\}$, the correspondence is given by $$ A = \int_{-\infty}^{\infty}\lambda dP_{\lambda}, $$ where $P_{\lambda} = P_{(-\infty, \lambda)}$ Thank you for your help!",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
34,Bounded operators with prescribed range,Bounded operators with prescribed range,,"If $X$ is a seaparable Banach space and $Y$ is a subspace of $X$, not necessarily closed, can one always find an bounded operator with range $Y$? It is easy when $Y$ is closed and complemented, what if it's not? Edit 1: I modified the question to add that $X$ is separable. It seems that the general case is open. https://mathoverflow.net/questions/101253/surjectivity-of-operators-on-linfty Edit 2: If $Y$ is not closed, Jonas Meyer answer below shows that the answer is 'No'. What about when $Y$ is closed? Edit 3: A followup question has been posted about the case when $Y$ is closed: Bounded operators with prescribed range - part II","If $X$ is a seaparable Banach space and $Y$ is a subspace of $X$, not necessarily closed, can one always find an bounded operator with range $Y$? It is easy when $Y$ is closed and complemented, what if it's not? Edit 1: I modified the question to add that $X$ is separable. It seems that the general case is open. https://mathoverflow.net/questions/101253/surjectivity-of-operators-on-linfty Edit 2: If $Y$ is not closed, Jonas Meyer answer below shows that the answer is 'No'. What about when $Y$ is closed? Edit 3: A followup question has been posted about the case when $Y$ is closed: Bounded operators with prescribed range - part II",,"['functional-analysis', 'operator-theory']"
35,Kernel of the closure of an unbounded operator,Kernel of the closure of an unbounded operator,,"Let $T:\mathcal{D}(T)\subset X\to Y$ be a densely defined closable operator. Define $\text{ker}\,T=\{(x,0)\in \text{graph}\,T\}$ where $\text{graph}\,T\subset X\times Y$. My question is $\overline{\text{ker}\,T}=\text{ker}\,\overline{T}$? I recall that $\overline{T}$ is the closure of $T$. I know that $\overline{\text{ker}\,T}\subset\text{ker}\,\overline{T}$, what about the reverse inclusion? So far I have proved that $\text{ker}\,T^{\perp}\subset R(T^*)$ implies the inclusion $\overline{\text{ker}\,T}\supset\text{ker}\,\overline{T}$, but this inclusion seems to be false in general. Someone has any clue about the kernel of the closure of an operator? Thanks in advance. Remarks: $M^{\perp}=\{x'\in X'\mid x'(x)=0 \text{ for every } x\in M\}$ where $X'$ is the dual space and $T^*:\mathcal{D}(T^*)\subset Y'\to X'$ is the adjoint. The norm in $X\times Y$ is $||(x,y)||=||x||+||y||$.","Let $T:\mathcal{D}(T)\subset X\to Y$ be a densely defined closable operator. Define $\text{ker}\,T=\{(x,0)\in \text{graph}\,T\}$ where $\text{graph}\,T\subset X\times Y$. My question is $\overline{\text{ker}\,T}=\text{ker}\,\overline{T}$? I recall that $\overline{T}$ is the closure of $T$. I know that $\overline{\text{ker}\,T}\subset\text{ker}\,\overline{T}$, what about the reverse inclusion? So far I have proved that $\text{ker}\,T^{\perp}\subset R(T^*)$ implies the inclusion $\overline{\text{ker}\,T}\supset\text{ker}\,\overline{T}$, but this inclusion seems to be false in general. Someone has any clue about the kernel of the closure of an operator? Thanks in advance. Remarks: $M^{\perp}=\{x'\in X'\mid x'(x)=0 \text{ for every } x\in M\}$ where $X'$ is the dual space and $T^*:\mathcal{D}(T^*)\subset Y'\to X'$ is the adjoint. The norm in $X\times Y$ is $||(x,y)||=||x||+||y||$.",,['functional-analysis']
36,Core for the Laplace operator in a bounded domain,Core for the Laplace operator in a bounded domain,,Let $X$ be a bounded connected open subset of the $n$-dimensional real Euclidean space. Consider the Laplace operator defined on the space of infinitely differentiable functions with compact support in $X$. Does the closure of this operator generate a strongly continuous semigroup on $C_0(X)$ endowed with the supremum norm? I think it is equivalent to the following question: Is the space of infinitely differentiable functions with compact support in $X$ a core for the Dirichlet Laplacian on $X$?,Let $X$ be a bounded connected open subset of the $n$-dimensional real Euclidean space. Consider the Laplace operator defined on the space of infinitely differentiable functions with compact support in $X$. Does the closure of this operator generate a strongly continuous semigroup on $C_0(X)$ endowed with the supremum norm? I think it is equivalent to the following question: Is the space of infinitely differentiable functions with compact support in $X$ a core for the Dirichlet Laplacian on $X$?,,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'partial-derivative']"
37,Does every absorbing set of a Banach space contain a neighborhood of origin?,Does every absorbing set of a Banach space contain a neighborhood of origin?,,Let $X$ be a Banach space and $A$ be any absorbing subset of $X$. Does $A$ contain a neighborhood of the origin?,Let $X$ be a Banach space and $A$ be any absorbing subset of $X$. Does $A$ contain a neighborhood of the origin?,,['functional-analysis']
38,A non-separable strictly convex space with a separable pre-dual,A non-separable strictly convex space with a separable pre-dual,,I am asked to find an example of a non-separable strictly convex space with a separable pre-dual. So please give me some hints or some references about such problems. Thanks in advance.,I am asked to find an example of a non-separable strictly convex space with a separable pre-dual. So please give me some hints or some references about such problems. Thanks in advance.,,"['functional-analysis', 'normed-spaces']"
39,Projection operator for non-orthonormal basis,Projection operator for non-orthonormal basis,,"Let $V \subset H$ be Hilbert spaces. Let $\{v_j\}_{j=1}^\infty$ be a basis for $V$ and $H$. Define $V_N$ to be the span of $\{v_j\}_{j=1}^N$. We can define a projection operator $P:H \to V_N$ by $$P(h) = \sum_{j=1}^N(h,v_j)_Hv_j$$ which is bounded from $H$ to $H$. I can show that $P^2(h) = P(h)$ if the $v_j$ are orthonormal in $H$. If they are not (say they are just a basis, not orthonormal and not orthogonal), then how can I show this identity? Should I define the projection differently?","Let $V \subset H$ be Hilbert spaces. Let $\{v_j\}_{j=1}^\infty$ be a basis for $V$ and $H$. Define $V_N$ to be the span of $\{v_j\}_{j=1}^N$. We can define a projection operator $P:H \to V_N$ by $$P(h) = \sum_{j=1}^N(h,v_j)_Hv_j$$ which is bounded from $H$ to $H$. I can show that $P^2(h) = P(h)$ if the $v_j$ are orthonormal in $H$. If they are not (say they are just a basis, not orthonormal and not orthogonal), then how can I show this identity? Should I define the projection differently?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'inner-products']"
40,Why $\mbox{Ker }T^{*}\oplus\overline{\mbox{Im }{T}}=X$?,Why ?,\mbox{Ker }T^{*}\oplus\overline{\mbox{Im }{T}}=X,"Can you explain me or indicate where can I find a proof, please why: $$\mbox{Ker }T^{*}\oplus\overline{\mbox{Im }{T}}=X \mbox{ ? }$$ $X$ is a complex Hilbert space. thanks :)","Can you explain me or indicate where can I find a proof, please why: $$\mbox{Ker }T^{*}\oplus\overline{\mbox{Im }{T}}=X \mbox{ ? }$$ $X$ is a complex Hilbert space. thanks :)",,['functional-analysis']
41,a trace class operator problem,a trace class operator problem,,"Could someone help me with this Prove that If $A$ and $B$ are positive trace class operators on a Hilbert space, then so is $A^zB^{(1-z)}$ for a complex number $z$ such that $0 <Re(z)< 1$. An operator $A$ is called trace class if $\sum_{n=1}^{\infty}\langle |A|e_n,e_n\rangle < \infty  $ |A| is positive square root of $ A^*A$","Could someone help me with this Prove that If $A$ and $B$ are positive trace class operators on a Hilbert space, then so is $A^zB^{(1-z)}$ for a complex number $z$ such that $0 <Re(z)< 1$. An operator $A$ is called trace class if $\sum_{n=1}^{\infty}\langle |A|e_n,e_n\rangle < \infty  $ |A| is positive square root of $ A^*A$",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras']"
42,Every function in $D'(\Omega)$ is the limit of a sequence in $D'(\Omega)$ with compact support.,Every function in  is the limit of a sequence in  with compact support.,D'(\Omega) D'(\Omega),How will we prove that for every $f\in D'(\Omega)$ there exists a sequence $(f_j)$ in $D'(\Omega)$ with compact support such that $f$ is the limit of $(f_j)$?,How will we prove that for every $f\in D'(\Omega)$ there exists a sequence $(f_j)$ in $D'(\Omega)$ with compact support such that $f$ is the limit of $(f_j)$?,,"['functional-analysis', 'fourier-analysis', 'weak-convergence']"
43,What is the functional inverse (with respect to $h$ (!)) of $f^{\circ h}(x)={F(h) +x F(h-1) \over F(1+h) +x F(h) }$?,What is the functional inverse (with respect to  (!)) of ?,h f^{\circ h}(x)={F(h) +x F(h-1) \over F(1+h) +x F(h) },"I've considered the fractional iteration of $f(x) = {1 \over 1+x} $ for which the general expression depending on the iteration-height parameter $h$ might be assumed by the formula  $$ f^{\circ h}(x) = f(x,h)={F(h) +x \cdot F(h-1) \over F(1+h) +x \cdot F(h)  }$$  where $ \displaystyle \qquad \small F(h)=\operatorname{fibonacci}(h) = {\varphi^h - (1-\varphi)^h \over \sqrt5 }$ and $ \displaystyle \qquad \small \varphi = {1+\sqrt5 \over 2} \sim 1.618... $ (Note, that for fractional iterates we need $x \in \mathbb C$) Today I tried to find a formulation for the functional inverse with respect to h , but don't find a good starting point so: Q: How would look a function $ h = \operatorname{hgh}(x_0,x_h) $ which would indicate the required iteration-height $h$ given $x_0$ and $x_h = f(x_0,h)$ ? Is there even a closed form for it (I'd call it still closed-form  if it possibly includes e.g. the Lambert-W function) [update]: for more background see the older exercise of mine","I've considered the fractional iteration of $f(x) = {1 \over 1+x} $ for which the general expression depending on the iteration-height parameter $h$ might be assumed by the formula  $$ f^{\circ h}(x) = f(x,h)={F(h) +x \cdot F(h-1) \over F(1+h) +x \cdot F(h)  }$$  where $ \displaystyle \qquad \small F(h)=\operatorname{fibonacci}(h) = {\varphi^h - (1-\varphi)^h \over \sqrt5 }$ and $ \displaystyle \qquad \small \varphi = {1+\sqrt5 \over 2} \sim 1.618... $ (Note, that for fractional iterates we need $x \in \mathbb C$) Today I tried to find a formulation for the functional inverse with respect to h , but don't find a good starting point so: Q: How would look a function $ h = \operatorname{hgh}(x_0,x_h) $ which would indicate the required iteration-height $h$ given $x_0$ and $x_h = f(x_0,h)$ ? Is there even a closed form for it (I'd call it still closed-form  if it possibly includes e.g. the Lambert-W function) [update]: for more background see the older exercise of mine",,"['functional-analysis', 'special-functions', 'fibonacci-numbers', 'function-and-relation-composition', 'complex-dynamics']"
44,$C_c^0(\Omega)$ is not Banach!?! Also density requires completeness?,is not Banach!?! Also density requires completeness?,C_c^0(\Omega),"Today I was very surprised to learn that $C_c^0(\Omega)$ is not a Banach space with the supremum norm. Why is that, when $C^\infty_c(\Omega)$ is? Also (from here , bottom of page 18), I learn that even though we can approximate any function in $C_c^0(\Omega)$ by a $C_c^\infty(\Omega)$ function as closely as we want, there is no dense inclusion since the space is not Banach. Is it really necessary for ""density"" that being complete is required? If completeness is required for density, then the statement I read somewhere $C_c^\infty(0,T;V)$ ($V$ is Hilbert) is dense in $W(0,T)$ (some space) does not make sense either. Or is it different because $[0,T]$ is compact?","Today I was very surprised to learn that $C_c^0(\Omega)$ is not a Banach space with the supremum norm. Why is that, when $C^\infty_c(\Omega)$ is? Also (from here , bottom of page 18), I learn that even though we can approximate any function in $C_c^0(\Omega)$ by a $C_c^\infty(\Omega)$ function as closely as we want, there is no dense inclusion since the space is not Banach. Is it really necessary for ""density"" that being complete is required? If completeness is required for density, then the statement I read somewhere $C_c^\infty(0,T;V)$ ($V$ is Hilbert) is dense in $W(0,T)$ (some space) does not make sense either. Or is it different because $[0,T]$ is compact?",,"['functional-analysis', 'banach-spaces']"
45,self-adjoint operator proof,self-adjoint operator proof,,"Let $T$ be a densely defined closed unbounded operator on a Hilbert space $H$. A number $\lambda \in C$ is called an approximate eigenvalue of T if there is a sequence ${X_n} \subset D(T)$, with $\|X_n\|=1, n=1,2,... $ s.t. $(T-\lambda I)X_n \rightarrow 0$ as $n \rightarrow \infty$. Then how to prove that if $T$ is self adjoint then any $\lambda \in \sigma(T)$ is an approximate eigenvalue? Was thinking about using spectral theorem, first assume there doesn't exist the sequence $X_n$ and try to induce the contradiction.","Let $T$ be a densely defined closed unbounded operator on a Hilbert space $H$. A number $\lambda \in C$ is called an approximate eigenvalue of T if there is a sequence ${X_n} \subset D(T)$, with $\|X_n\|=1, n=1,2,... $ s.t. $(T-\lambda I)X_n \rightarrow 0$ as $n \rightarrow \infty$. Then how to prove that if $T$ is self adjoint then any $\lambda \in \sigma(T)$ is an approximate eigenvalue? Was thinking about using spectral theorem, first assume there doesn't exist the sequence $X_n$ and try to induce the contradiction.",,"['functional-analysis', 'hilbert-spaces']"
46,Name for this simple inequality,Name for this simple inequality,,"Let $x,y$ vectors in $\mathbb{R}^3$. From $$\Vert x+y\Vert^2\geq 0$$ it follows that $$2x\cdot y\geq -\Vert x\Vert^2-\Vert y\Vert^2$$ Has this inequality a name?","Let $x,y$ vectors in $\mathbb{R}^3$. From $$\Vert x+y\Vert^2\geq 0$$ it follows that $$2x\cdot y\geq -\Vert x\Vert^2-\Vert y\Vert^2$$ Has this inequality a name?",,"['linear-algebra', 'geometry', 'functional-analysis']"
47,Polar decomposition of invertible elements in a unital C$ ^{*} $-algebra.,Polar decomposition of invertible elements in a unital C-algebra., ^{*} ,"If $ A $ is a unital C$ ^{*} $-algebra and $ a $ is invertible, then $ a = u|a| $ for a unique unitary element $ u $ of $ A $. If $ \| a \| = \| a^{-1} \| = 1 $, what can you say about $ |a| $? I don’t know how to start!","If $ A $ is a unital C$ ^{*} $-algebra and $ a $ is invertible, then $ a = u|a| $ for a unique unitary element $ u $ of $ A $. If $ \| a \| = \| a^{-1} \| = 1 $, what can you say about $ |a| $? I don’t know how to start!",,"['functional-analysis', 'operator-algebras']"
48,Is it possible for a Strongly Convex function to be unbounded below?,Is it possible for a Strongly Convex function to be unbounded below?,,"Let $X$ be a non-reflexive Banach space and $f:X\rightarrow\mathbb{R}$ a $C^1$ function that is Strongly Convex, i.e. $$f(u)-f(v)\geq\langle f'(v),u-v\rangle+c\|u-v\|^2$$ where $c>0$ is constant. Is it possible for $f$ to be unbounded below?","Let $X$ be a non-reflexive Banach space and $f:X\rightarrow\mathbb{R}$ a $C^1$ function that is Strongly Convex, i.e. $$f(u)-f(v)\geq\langle f'(v),u-v\rangle+c\|u-v\|^2$$ where $c>0$ is constant. Is it possible for $f$ to be unbounded below?",,"['functional-analysis', 'banach-spaces', 'convex-analysis']"
49,"The vector space formed on C[0,1] and the norm $(\int_{0}^{1}|f(t)|^2 dt)^{1/2} $","The vector space formed on C[0,1] and the norm",(\int_{0}^{1}|f(t)|^2 dt)^{1/2} ,"How does one show that $(C[0,1], ||.||_{2})$ where $||.||_2=(\int_{0}^{1}|f(t)|^2dt)^{1/2}$ and $C[0,1]$ is the space of all continous function which are mapped from $[0,1]\rightarrow \mathbb{R}$, is not complete? First to show that $(C[0,1], ||.||_{2})$ is a normed vector space: $||.||_2$ fulfills $||f(t)||=0 \Rightarrow f(t)=0$ $||.||_2$ fulfills the  scalar multiplication property: $$||\lambda f(t)||_{2} = (\int_{0}^{1}|\lambda f(t)|^2dt)^{1/2}=|\lambda|(\int_{0}^{1}| f(t)|^2dt)^{1/2}=|\lambda|||f(t)||_2$$ Thirdly, it also fulfills the triangle inequality:$$||x(t)+y(t)||_2^2 = \int_{0}^{1}|x(t)+y(t)|^2dt \le \int_{0}^{1}|x(t)|^2dt + 2\int_{0}^{1}|x(t)y(t)|dt +\int_{0}^{1}|y(t)|^2dt \le ||x(t)||_2^2 + 2||x(t)||_2||y(t)||_2+||y(t)||_2^2 = (||x(t)||_2+||(y(t)||_2)^2$$ this also shows the closure under addition in $C[0,1]$ so , $(C[0,1],||.||_2)$ is a normed vector space , but how can we show that it is not complete?","How does one show that $(C[0,1], ||.||_{2})$ where $||.||_2=(\int_{0}^{1}|f(t)|^2dt)^{1/2}$ and $C[0,1]$ is the space of all continous function which are mapped from $[0,1]\rightarrow \mathbb{R}$, is not complete? First to show that $(C[0,1], ||.||_{2})$ is a normed vector space: $||.||_2$ fulfills $||f(t)||=0 \Rightarrow f(t)=0$ $||.||_2$ fulfills the  scalar multiplication property: $$||\lambda f(t)||_{2} = (\int_{0}^{1}|\lambda f(t)|^2dt)^{1/2}=|\lambda|(\int_{0}^{1}| f(t)|^2dt)^{1/2}=|\lambda|||f(t)||_2$$ Thirdly, it also fulfills the triangle inequality:$$||x(t)+y(t)||_2^2 = \int_{0}^{1}|x(t)+y(t)|^2dt \le \int_{0}^{1}|x(t)|^2dt + 2\int_{0}^{1}|x(t)y(t)|dt +\int_{0}^{1}|y(t)|^2dt \le ||x(t)||_2^2 + 2||x(t)||_2||y(t)||_2+||y(t)||_2^2 = (||x(t)||_2+||(y(t)||_2)^2$$ this also shows the closure under addition in $C[0,1]$ so , $(C[0,1],||.||_2)$ is a normed vector space , but how can we show that it is not complete?",,"['calculus', 'real-analysis', 'functional-analysis', 'normed-spaces']"
50,Why is the laplacian positive-definite,Why is the laplacian positive-definite,,"Let (M,g) be compact Riemannian manifold (possibly $\partial M\neq\emptyset)$ Now I have read, that ""the laplace-beltrami operator is a positive definite operator"". I have shown, if M is a closed manifold or if we consider dirichlet boundary conditions, $\Delta:=-\nabla^2$ is positive definite, i.e. $(\Delta f,f)_{L^2}\geq 0$. Which setting does the author mean by: ""the laplace-beltrami operator is a positive definite operator""?? Is $\Delta$ always positive definite independent of the boundary conditions? Thank you!","Let (M,g) be compact Riemannian manifold (possibly $\partial M\neq\emptyset)$ Now I have read, that ""the laplace-beltrami operator is a positive definite operator"". I have shown, if M is a closed manifold or if we consider dirichlet boundary conditions, $\Delta:=-\nabla^2$ is positive definite, i.e. $(\Delta f,f)_{L^2}\geq 0$. Which setting does the author mean by: ""the laplace-beltrami operator is a positive definite operator""?? Is $\Delta$ always positive definite independent of the boundary conditions? Thank you!",,"['functional-analysis', 'manifolds']"
51,Separation in dual space,Separation in dual space,,"Let $X$ be a real Banach space and $X^*$ its dual space. Let $C^*$ be a weak$^*$ closed and convex subset in $X^*$  and $x^*\notin C^*$. Then there exists $x\in X$ such that $$ \langle x^*, x\rangle > \sup_{f\in C^*}\langle f, x\rangle. $$ I would like to ask whether the statement is true? How can we prove?","Let $X$ be a real Banach space and $X^*$ its dual space. Let $C^*$ be a weak$^*$ closed and convex subset in $X^*$  and $x^*\notin C^*$. Then there exists $x\in X$ such that $$ \langle x^*, x\rangle > \sup_{f\in C^*}\langle f, x\rangle. $$ I would like to ask whether the statement is true? How can we prove?",,['functional-analysis']
52,Functions of bounded variation and $L^\infty$ functions,Functions of bounded variation and  functions,L^\infty,Here are my questions. Are $L^\infty$ functions of bounded variation? Is the composition of two BV functions still of bounded variation? Is $x\mapsto \frac 1{f(x)}$ of bounded variation when $f$ is of bounded variation? Cheers.,Here are my questions. Are $L^\infty$ functions of bounded variation? Is the composition of two BV functions still of bounded variation? Is $x\mapsto \frac 1{f(x)}$ of bounded variation when $f$ is of bounded variation? Cheers.,,"['real-analysis', 'functional-analysis', 'bounded-variation']"
53,Frechet Differentiability versus Strict Differentiability,Frechet Differentiability versus Strict Differentiability,,"We recall two concepts of differentiability of a mapping. Let $X, Y$ be real Banach spaces and $f: X\rightarrow Y$ be a mapping. $f$ is said to be Frechet differentiable at $\bar{x}$ if there exists a linear continuous operator $\nabla f(\bar{x}): X\rightarrow Y$ such that $$ \lim_{x\rightarrow \bar{x}}\frac{f(x)-f(\bar{x})-\nabla f(\bar{x})(x-\bar{x})}{\|x-\bar{x}\|}=0. $$ $f$ is said to be strictly differentiable at $\bar{x}$ if $f$ is Frechet differentiable at $\bar{x}$ and  $$ \lim_{\substack{x\rightarrow \bar{x}\\ u\rightarrow \bar{x}}}\frac{f(x)-f(u)-\nabla f(\bar{x})(x-u)}{\|x-u\|}=0. $$ It is known that if $f$ is continuously Frechet differentiable in a neighborhooh of $\bar{x}$  then $f$ is strictly differentiable at this point but not vice versa. I would like to find a mapping $f$ such that $f$ is strictly differentiable at $\bar{x}$ but it is not differentiable at points near $\bar{x}$.","We recall two concepts of differentiability of a mapping. Let $X, Y$ be real Banach spaces and $f: X\rightarrow Y$ be a mapping. $f$ is said to be Frechet differentiable at $\bar{x}$ if there exists a linear continuous operator $\nabla f(\bar{x}): X\rightarrow Y$ such that $$ \lim_{x\rightarrow \bar{x}}\frac{f(x)-f(\bar{x})-\nabla f(\bar{x})(x-\bar{x})}{\|x-\bar{x}\|}=0. $$ $f$ is said to be strictly differentiable at $\bar{x}$ if $f$ is Frechet differentiable at $\bar{x}$ and  $$ \lim_{\substack{x\rightarrow \bar{x}\\ u\rightarrow \bar{x}}}\frac{f(x)-f(u)-\nabla f(\bar{x})(x-u)}{\|x-u\|}=0. $$ It is known that if $f$ is continuously Frechet differentiable in a neighborhooh of $\bar{x}$  then $f$ is strictly differentiable at this point but not vice versa. I would like to find a mapping $f$ such that $f$ is strictly differentiable at $\bar{x}$ but it is not differentiable at points near $\bar{x}$.",,"['real-analysis', 'functional-analysis']"
54,Converse to Inverse Function Theorem?,Converse to Inverse Function Theorem?,,"A fairly general form of the Inverse Function Theorem is: Suppose $X, Y$ are Banach spaces, $U \subset X$ is open and $f:U \to Y$ is continuously differentiable. If for some $x \in U$ the derivative $Df(x)$ is invertible, then there exists a neighborhood $V \subset f(U)$ such that $f(x) \in V$ and a continuously differentiable function $g: V \to U$ such that $f(g(x)) = x$ for all $x \in V$. A question I have had is whether there are any sufficient conditions such that the converse holds, i.e., if $Df(x)$ is not invertible then $f$ is locally not invertible.? Thanks in advance.","A fairly general form of the Inverse Function Theorem is: Suppose $X, Y$ are Banach spaces, $U \subset X$ is open and $f:U \to Y$ is continuously differentiable. If for some $x \in U$ the derivative $Df(x)$ is invertible, then there exists a neighborhood $V \subset f(U)$ such that $f(x) \in V$ and a continuously differentiable function $g: V \to U$ such that $f(g(x)) = x$ for all $x \in V$. A question I have had is whether there are any sufficient conditions such that the converse holds, i.e., if $Df(x)$ is not invertible then $f$ is locally not invertible.? Thanks in advance.",,['real-analysis']
55,Nearest point projection in uniformly convex Banach spaces,Nearest point projection in uniformly convex Banach spaces,,"Let $X$ be a uniformly convex Banach space , $x\in X$ and $C\subset X$ closed and convex, then there is a unique $y\in C$ with $$\lVert x-y\rVert=\inf_{z\in C}\lVert x-z \rVert.$$ Is there a good book where I can find a proof of this theorem?","Let $X$ be a uniformly convex Banach space , $x\in X$ and $C\subset X$ closed and convex, then there is a unique $y\in C$ with $$\lVert x-y\rVert=\inf_{z\in C}\lVert x-z \rVert.$$ Is there a good book where I can find a proof of this theorem?",,"['reference-request', 'functional-analysis', 'banach-spaces']"
56,"$\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty}$ for functions in $C([0,1])$?",for functions in ?,"\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty} C([0,1])","Why does the following hold for continuous functions on $[0,1]$? $\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty}$","Why does the following hold for continuous functions on $[0,1]$? $\|\cdot\|_1 \leq \|\cdot\|_2 \leq \|\cdot\|_{\infty}$",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'normed-spaces']"
57,Inner product for vector - valued functions,Inner product for vector - valued functions,,"I understand that, for example the inner product space $L^2(X)$ of complex - valued functions defined on $X$ has the inner product \begin{equation} (f,g) = \int f \, \overline{g\,}. \end{equation} Now I am reading a text where the elements of my inner product space are vector - valued functions, and it is assumed the reader knows how to adjust the inner product so that it works in this case. I am not sure how to do this, here is a guess and it would be great if I could get feedback on whether this is the right way to generalize to vector - valued functions: \begin{equation} (f,g) = \sum_{i = 1}^n \int f_i \, \overline{g_i}  \end{equation} (here, $n$ is the dimension of the range, and $f_i$ is the $i^{th}$ component of the function $f$). Many thanks !","I understand that, for example the inner product space $L^2(X)$ of complex - valued functions defined on $X$ has the inner product \begin{equation} (f,g) = \int f \, \overline{g\,}. \end{equation} Now I am reading a text where the elements of my inner product space are vector - valued functions, and it is assumed the reader knows how to adjust the inner product so that it works in this case. I am not sure how to do this, here is a guess and it would be great if I could get feedback on whether this is the right way to generalize to vector - valued functions: \begin{equation} (f,g) = \sum_{i = 1}^n \int f_i \, \overline{g_i}  \end{equation} (here, $n$ is the dimension of the range, and $f_i$ is the $i^{th}$ component of the function $f$). Many thanks !",,"['measure-theory', 'functional-analysis', 'inner-products']"
58,Bounded inverse operator,Bounded inverse operator,,"Let $X$ and $Y$ be Banach spaces. Suppose $T$ is a linear operator from $X$ onto $Y$ with $\operatorname{Dom}(T)\subset X$. Show that $\exists T^{-1}\in L(Y,X)\Leftrightarrow\exists M>0:\ \left\Vert x\right\Vert \leq M\left\Vert Tx\right\Vert ,\forall x\in \operatorname{Dom}(T)$ . This problem seems to be closely related to the following theorems. But I also noticed some differences. For example, it is possible that $\operatorname{Dom}(T)\neq X$. Also, we don't know $T\in L(X,Y)$. Thank you! $T\in L(X,Y)$, $\operatorname{Dom}(T)=X$. Then, $\operatorname{Ker}(T)=\{0\}$ (one-to-one) and $\operatorname{Im}(T)$ is closed in $Y$ iff $\left\Vert Tx\right\Vert _{Y}\geq C\left\Vert x\right\Vert _{X}$ $\forall x\in X$ for some $C>0$. $T\in L(X,Y)$ is bijective $\Rightarrow$$T$ is invertible. $\exists T^{-1}\in L(Y,X)$ .","Let $X$ and $Y$ be Banach spaces. Suppose $T$ is a linear operator from $X$ onto $Y$ with $\operatorname{Dom}(T)\subset X$. Show that $\exists T^{-1}\in L(Y,X)\Leftrightarrow\exists M>0:\ \left\Vert x\right\Vert \leq M\left\Vert Tx\right\Vert ,\forall x\in \operatorname{Dom}(T)$ . This problem seems to be closely related to the following theorems. But I also noticed some differences. For example, it is possible that $\operatorname{Dom}(T)\neq X$. Also, we don't know $T\in L(X,Y)$. Thank you! $T\in L(X,Y)$, $\operatorname{Dom}(T)=X$. Then, $\operatorname{Ker}(T)=\{0\}$ (one-to-one) and $\operatorname{Im}(T)$ is closed in $Y$ iff $\left\Vert Tx\right\Vert _{Y}\geq C\left\Vert x\right\Vert _{X}$ $\forall x\in X$ for some $C>0$. $T\in L(X,Y)$ is bijective $\Rightarrow$$T$ is invertible. $\exists T^{-1}\in L(Y,X)$ .",,['functional-analysis']
59,Hoelder functions with power $>1$,Hoelder functions with power,>1,Do there exist in Banach space any  nonconstant functions satisfying Hoelder condition with power $>1$ defined on open connected set with values in $\mathbb{R}$? Thanks.,Do there exist in Banach space any  nonconstant functions satisfying Hoelder condition with power $>1$ defined on open connected set with values in $\mathbb{R}$? Thanks.,,"['real-analysis', 'functional-analysis']"
60,Hahn-Banach. Extend the functional by continuity,Hahn-Banach. Extend the functional by continuity,,"Let $E$ be a dense linear subspace of a normed vector space $X$, and let $Y$ be a Banach space. Suppose $T_{0}\in\mathcal{L}(E,Y)$ is a bounded linear operator from $E$ to $Y$. Show that $T_{0}$ can be extended to $T\in\mathcal{L}(X,Y)$ (by continuity) without increasing its norm. I have a dumb question: Given the Hahn-Banach theorem, what's to prove here? It seems to be the immediate consequence of that theorem. If I am wrong, please show me how to prove this. Thank you!","Let $E$ be a dense linear subspace of a normed vector space $X$, and let $Y$ be a Banach space. Suppose $T_{0}\in\mathcal{L}(E,Y)$ is a bounded linear operator from $E$ to $Y$. Show that $T_{0}$ can be extended to $T\in\mathcal{L}(X,Y)$ (by continuity) without increasing its norm. I have a dumb question: Given the Hahn-Banach theorem, what's to prove here? It seems to be the immediate consequence of that theorem. If I am wrong, please show me how to prove this. Thank you!",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
61,A non weakly convergent sequence in $L^p(\mathbb{N})$,A non weakly convergent sequence in,L^p(\mathbb{N}),Can anyone provide an example of a sequence $(x_{k}) \in L^p(\mathbb{N})$ with $1<p<\infty$ such that $x_{k}(n)\rightarrow 0$ as $k\rightarrow \infty$ such $x_{k}$ doesn't converges weakly to zero. The sequence has to be unbounded because if the sequence is bounded with this the sequence is weakly convergent.,Can anyone provide an example of a sequence $(x_{k}) \in L^p(\mathbb{N})$ with $1<p<\infty$ such that $x_{k}(n)\rightarrow 0$ as $k\rightarrow \infty$ such $x_{k}$ doesn't converges weakly to zero. The sequence has to be unbounded because if the sequence is bounded with this the sequence is weakly convergent.,,"['real-analysis', 'functional-analysis', 'measure-theory']"
62,An integral operator inequality,An integral operator inequality,,"This problem is from exercise 30 on page 196 of Folland's ""Real Analysis"". Let $K$ be a non-negative measurable function on $[0,\infty)$ and let $\phi(s) = \displaystyle\int_0 ^\infty K(x)x^{s-1} dx$. I am trying to prove that if $f$ and $g$ are non-negative measurable functions and $p$ and $q$ are conjugate exponents, then $\displaystyle\int_0 ^\infty \int_0 ^\infty K(xy)f(x)g(y) dxdy \leq \phi(1/p) \left(\int_0 ^\infty x^{p-2} f(x)^p dx\right)^{1/p} \left(\int_0 ^\infty g(x)^q dx\right)^{1/q}$. So far, I have been attempting various combinations of Hölder's inequality and the theorem given in the text for a function $K$ on $\mathbb R^2$ which is homogenous of degree $-1$, but have not met with much success. Any suggestions?","This problem is from exercise 30 on page 196 of Folland's ""Real Analysis"". Let $K$ be a non-negative measurable function on $[0,\infty)$ and let $\phi(s) = \displaystyle\int_0 ^\infty K(x)x^{s-1} dx$. I am trying to prove that if $f$ and $g$ are non-negative measurable functions and $p$ and $q$ are conjugate exponents, then $\displaystyle\int_0 ^\infty \int_0 ^\infty K(xy)f(x)g(y) dxdy \leq \phi(1/p) \left(\int_0 ^\infty x^{p-2} f(x)^p dx\right)^{1/p} \left(\int_0 ^\infty g(x)^q dx\right)^{1/q}$. So far, I have been attempting various combinations of Hölder's inequality and the theorem given in the text for a function $K$ on $\mathbb R^2$ which is homogenous of degree $-1$, but have not met with much success. Any suggestions?",,"['real-analysis', 'functional-analysis', 'inequality']"
63,Dimension of Continuous functions,Dimension of Continuous functions,,"I think that $\{\text{continuous functions on } [0,1]\}$ has a different dimension from $\{\text{continuous functions on } [0,1]:F(0)=0, F\in C^1(0,1)\}$ due to the constraints in the latter. But how do I prove this? (I realize that this question may be similar to the question Bases of spaces of continuous functions I asked previously, but this is hopefully more concise and I have thought about @Florian's enlightenment that the dimension of the set of continuous functions on a closed interval is infinite.) Thanks loads!","I think that $\{\text{continuous functions on } [0,1]\}$ has a different dimension from $\{\text{continuous functions on } [0,1]:F(0)=0, F\in C^1(0,1)\}$ due to the constraints in the latter. But how do I prove this? (I realize that this question may be similar to the question Bases of spaces of continuous functions I asked previously, but this is hopefully more concise and I have thought about @Florian's enlightenment that the dimension of the set of continuous functions on a closed interval is infinite.) Thanks loads!",,"['linear-algebra', 'functional-analysis']"
64,A closed subspace of $c_0$,A closed subspace of,c_0,"Does anyone know an example of an infinite dimensional closed linear subspace $S$ of $X=c_0$ (with the sup norm) which is not isomorphic to $X$, i.e. there does not exist a linear one-to-one map $T$ from $X$ onto $S$ such that both $T$ and its inverse are continuous?","Does anyone know an example of an infinite dimensional closed linear subspace $S$ of $X=c_0$ (with the sup norm) which is not isomorphic to $X$, i.e. there does not exist a linear one-to-one map $T$ from $X$ onto $S$ such that both $T$ and its inverse are continuous?",,"['analysis', 'functional-analysis', 'banach-spaces']"
65,spectrum of right shift operator on $\ell^2(\mathbb{Z})$,spectrum of right shift operator on,\ell^2(\mathbb{Z}),"Consider the right shift operator on $\ell^2(\mathbb{Z})$. Is there a way of calculating (well, showing what it is since I already know it's $z$ s.t $|z| = 1$) its spectrum without reference to it being unitary and with just basic linear operator and spectral theory? How about if I assume that it exists and use the vector with zero everywhere except the 0th position, where it is 1? (If you don't understand that, ignore it)","Consider the right shift operator on $\ell^2(\mathbb{Z})$. Is there a way of calculating (well, showing what it is since I already know it's $z$ s.t $|z| = 1$) its spectrum without reference to it being unitary and with just basic linear operator and spectral theory? How about if I assume that it exists and use the vector with zero everywhere except the 0th position, where it is 1? (If you don't understand that, ignore it)",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
66,Infimum of the support of a convolution product,Infimum of the support of a convolution product,,"Let $f$ and $g$ be distributions on $\mathbb{R}$ with compact support. Do we have $\inf (\textrm{supp}(f*g)) = \inf (\textrm{supp}(f)) + \inf (\textrm{supp}(g))$ Where 'supp' denotes de the support of a distribution ? The left term is obviously greater than the right one. But the other inequality seems trickier to me (I guess it's always easier to prove that things are equal to zero). Any help in finding either a counterexample, proof, or reference for that statement would be appreciated. Thanks.","Let $f$ and $g$ be distributions on $\mathbb{R}$ with compact support. Do we have $\inf (\textrm{supp}(f*g)) = \inf (\textrm{supp}(f)) + \inf (\textrm{supp}(g))$ Where 'supp' denotes de the support of a distribution ? The left term is obviously greater than the right one. But the other inequality seems trickier to me (I guess it's always easier to prove that things are equal to zero). Any help in finding either a counterexample, proof, or reference for that statement would be appreciated. Thanks.",,"['real-analysis', 'functional-analysis']"
67,Rebuilding of bounded linear operator between Banach spaces,Rebuilding of bounded linear operator between Banach spaces,,"It is possible to rebuild a bounded linear operator between Banach spaces knowing the image only through the dual elements? Maybe we need some other hypothesis but the statement could be something like: Let $Y, X$ be Banach spaces on $\mathbb{K}\in \{\mathbb{R}, \mathbb{C}\}$ , let $X$ be endowed with weak topology, $\sigma(X, X^*)$ , let $f_{x^*} \in \mathcal{L}(Y, \mathbb{K})$ (i.e linear and bounded) $\forall x^* \in X^*$ , Then $\exists !$ (or $\exists$ ) $f\in \mathcal{L}(Y, X)$ such that $f_{x^*}=x^* \circ f, \forall x^* \in X^*$","It is possible to rebuild a bounded linear operator between Banach spaces knowing the image only through the dual elements? Maybe we need some other hypothesis but the statement could be something like: Let be Banach spaces on , let be endowed with weak topology, , let (i.e linear and bounded) , Then (or ) such that","Y, X \mathbb{K}\in \{\mathbb{R}, \mathbb{C}\} X \sigma(X, X^*) f_{x^*} \in \mathcal{L}(Y, \mathbb{K}) \forall x^* \in X^* \exists ! \exists f\in \mathcal{L}(Y, X) f_{x^*}=x^* \circ f, \forall x^* \in X^*","['functional-analysis', 'operator-theory', 'banach-spaces', 'weak-convergence']"
68,Non-trivial closed maps on Banach spaces,Non-trivial closed maps on Banach spaces,,"Let's call a map closed if it takes any closed subset to a closed subset. I'm wondering if there are some ""standard"" examples of closed (in this sense) linear maps on a Banach space, other than the zero map or a linear homeomorphism. More precisely: Question: What is an example of a bounded linear map $T\colon X\to X$ , where $X$ is a Banach space, that takes closed sets to closed sets, other than $T=0$ or a homeomorphism?","Let's call a map closed if it takes any closed subset to a closed subset. I'm wondering if there are some ""standard"" examples of closed (in this sense) linear maps on a Banach space, other than the zero map or a linear homeomorphism. More precisely: Question: What is an example of a bounded linear map , where is a Banach space, that takes closed sets to closed sets, other than or a homeomorphism?",T\colon X\to X X T=0,"['functional-analysis', 'linear-transformations', 'operator-theory', 'banach-spaces']"
69,Confusion about spectral measure of operator in tracial von Neumann algebra,Confusion about spectral measure of operator in tracial von Neumann algebra,,"The setting is that $(M, \tau)$ is a tracial von Neumann algebra ( $\tau$ is a faithful, normal tracial state) that is a subset of the bounded operators on a Hilbert space $H$ . Let $x \in M$ be a self-adjoint operator. Let $\mu_x$ be the spectral measure of $x$ (with respect to $\tau$ ). I am a bit confused about where the wrong step in the following ""proof"" that if $x$ is not invertible (i.e. $0 \in \sigma(x)$ ) then $\mu_x(\{0\}) > 0$ . If this is true, then by considering $x - \lambda$ for $\lambda \in \sigma(x)$ , it seems we would get that $\sigma(x)$ could only contain countably many points, which is false in general. Suppose that $x$ does not have a bounded inverse in $M$ , or equivalently that $x$ is not bijective. For a self adjoint $x \in M$ , it is a fact that $\chi_{\mathbb{R} \setminus \{0\}}(x)$ is equal to the projection onto the closure of the image of $x$ (or, equivalently the orthogonal complement to the kernel of $x$ ). Hence, for $x$ to not be invertible, $\chi_{\mathbb{R} \setminus \{0 \}}(x) \neq 1$ . As $\chi_{\mathbb{R} \setminus \{0\}}(x) + \chi_{\{0\}}(x) = 1$ , this means that $\chi_{ \{0\}}(x)$ is a non-zero projection. From faithfulness of $\tau$ , then $\tau(\chi_{ \{0\}}(x)) > 0$ and hence $\mu_x(\{0\}) > 0$ .","The setting is that is a tracial von Neumann algebra ( is a faithful, normal tracial state) that is a subset of the bounded operators on a Hilbert space . Let be a self-adjoint operator. Let be the spectral measure of (with respect to ). I am a bit confused about where the wrong step in the following ""proof"" that if is not invertible (i.e. ) then . If this is true, then by considering for , it seems we would get that could only contain countably many points, which is false in general. Suppose that does not have a bounded inverse in , or equivalently that is not bijective. For a self adjoint , it is a fact that is equal to the projection onto the closure of the image of (or, equivalently the orthogonal complement to the kernel of ). Hence, for to not be invertible, . As , this means that is a non-zero projection. From faithfulness of , then and hence .","(M, \tau) \tau H x \in M \mu_x x \tau x 0 \in \sigma(x) \mu_x(\{0\}) > 0 x - \lambda \lambda \in \sigma(x) \sigma(x) x M x x \in M \chi_{\mathbb{R} \setminus \{0\}}(x) x x x \chi_{\mathbb{R} \setminus \{0 \}}(x) \neq 1 \chi_{\mathbb{R} \setminus \{0\}}(x) + \chi_{\{0\}}(x) = 1 \chi_{ \{0\}}(x) \tau \tau(\chi_{ \{0\}}(x)) > 0 \mu_x(\{0\}) > 0","['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
70,Counting measure and integrability condition,Counting measure and integrability condition,,"Let $\mathcal{A}$ be the $\sigma$ -field on $[0,1]$ that consists of all subsets of $[0,1]$ that are (at most) countable or whose complement is (at most) countable. Let $\mu$ be the counting measure on $([0,1], \mathcal{A})$ . (1) Verify that a function $f:[0,1] \longrightarrow \mathbb{R}$ is in $L^1([0,1], \mathcal{A}, \mu)$ if and only if the set $E_f=\{x \in[0,1]: f(x) \neq 0\}$ is at most countable, and $$ \sum_{x \in E_f}|f(x)|<\infty $$ Furthermore, we have $\|f\|_1=\sum_{x \in E_f}|f(x)|<\infty$ in that case. (2) For every $f \in L^1([0,1], \mathcal{A}, \mu)$ , set $$ \Phi(f)=\sum_{x \in E_f} x f(x) . $$ Prove that $\Phi$ is a continuous linear form on $L^1([0,1], \mathcal{A}, \mu)$ . (3) Show that there exists no function $g \in L^{\infty}([0,1], \mathcal{A}, \mu)$ such that $\Phi(f)=$ $\int f g \mathrm{~d} \mu$ for every $f \in L^1([0,1], \mathcal{A}, \mu)$ . Can someone give me idea on how to solve it, main problem of mine is how to use counting measure on real line and do manipulation with it. Thank you. In case, I start with Indicator function of $A$ , we know it $f$ will be integrable if $A$ is finite and in that case, $\{ x \in [0, 1]: f(x) \neq 0 \}$ is countable.","Let be the -field on that consists of all subsets of that are (at most) countable or whose complement is (at most) countable. Let be the counting measure on . (1) Verify that a function is in if and only if the set is at most countable, and Furthermore, we have in that case. (2) For every , set Prove that is a continuous linear form on . (3) Show that there exists no function such that for every . Can someone give me idea on how to solve it, main problem of mine is how to use counting measure on real line and do manipulation with it. Thank you. In case, I start with Indicator function of , we know it will be integrable if is finite and in that case, is countable.","\mathcal{A} \sigma [0,1] [0,1] \mu ([0,1], \mathcal{A}) f:[0,1] \longrightarrow \mathbb{R} L^1([0,1], \mathcal{A}, \mu) E_f=\{x \in[0,1]: f(x) \neq 0\} 
\sum_{x \in E_f}|f(x)|<\infty
 \|f\|_1=\sum_{x \in E_f}|f(x)|<\infty f \in L^1([0,1], \mathcal{A}, \mu) 
\Phi(f)=\sum_{x \in E_f} x f(x) .
 \Phi L^1([0,1], \mathcal{A}, \mu) g \in L^{\infty}([0,1], \mathcal{A}, \mu) \Phi(f)= \int f g \mathrm{~d} \mu f \in L^1([0,1], \mathcal{A}, \mu) A f A \{ x \in [0, 1]: f(x) \neq 0 \}","['integration', 'functional-analysis', 'measure-theory', 'lp-spaces']"
71,"is $\min\{\|f\|_\infty , \|f\|_1\}$ a norm on $C[0,1]$ ? proof [duplicate]",is  a norm on  ? proof [duplicate],"\min\{\|f\|_\infty , \|f\|_1\} C[0,1]","This question already has an answer here : If $a>1$ then $\|f||=\min \left\{\max\{|f(t)| : t \in [0,1]\}, a \int_{0}^{1} |f(t)|dt \right\}$ is not a norm in $C[0,1]$ (1 answer) Closed 7 months ago . I have the following question: For $a>0$ and $\|f\|_\infty=\sup_{t \in [0,1]} |f(t)|$ $\|f\|_1 =a\cdot \int_0^1 |f(t)|dt$ Show that $\|f\|:=\min\{\|f\|_1,\|f\|_\infty\}$ is a norm on $C[0,1]$ only iff $a\le1$ I tried to go through the all $3$ characteristics of a norm but i never used the fact that a hast to lower $1$ ... i supsect that for $a>1$ we may get a problem with the triangle-equation... but i dont't see where this problem might come from??","This question already has an answer here : If $a>1$ then $\|f||=\min \left\{\max\{|f(t)| : t \in [0,1]\}, a \int_{0}^{1} |f(t)|dt \right\}$ is not a norm in $C[0,1]$ (1 answer) Closed 7 months ago . I have the following question: For and Show that is a norm on only iff I tried to go through the all characteristics of a norm but i never used the fact that a hast to lower ... i supsect that for we may get a problem with the triangle-equation... but i dont't see where this problem might come from??","a>0 \|f\|_\infty=\sup_{t \in [0,1]} |f(t)| \|f\|_1 =a\cdot \int_0^1 |f(t)|dt \|f\|:=\min\{\|f\|_1,\|f\|_\infty\} C[0,1] a\le1 3 1 a>1","['functional-analysis', 'normed-spaces']"
72,Dividing a tempered distribution by a polynomial,Dividing a tempered distribution by a polynomial,,"Let $p=p(x_1,...,x_N)$ be a non-zero polynomial in $N$ variables (real coefficients). Let $\mathscr{S}$ be the Schwartz space on $\mathbb{R}^N$ and let $\mathscr{S}'$ be its topological dual (i.e. the space of tempered distributions). I know that the map $\mathscr{S}'\to \mathscr{S}', \ \ \ T\mapsto pT$ (where $\langle pT,\psi \rangle:=\langle T, p\psi \rangle$ ) is linear and continous. My class notes affirm that this map has also a continous inverse given by $\mathscr{S}'\to \mathscr{S}', \ \ \ T\mapsto T/p$ and I don't understand this. This works if $p$ hasn't any real zeroes, but otherwise $T/p$ shouldn't be well-defined. I understand that the zeroes of $p$ form a null measure set so maybe there is some way of solving this issue. But I don't know how. Can you help me?","Let be a non-zero polynomial in variables (real coefficients). Let be the Schwartz space on and let be its topological dual (i.e. the space of tempered distributions). I know that the map (where ) is linear and continous. My class notes affirm that this map has also a continous inverse given by and I don't understand this. This works if hasn't any real zeroes, but otherwise shouldn't be well-defined. I understand that the zeroes of form a null measure set so maybe there is some way of solving this issue. But I don't know how. Can you help me?","p=p(x_1,...,x_N) N \mathscr{S} \mathbb{R}^N \mathscr{S}' \mathscr{S}'\to \mathscr{S}', \ \ \ T\mapsto pT \langle pT,\psi \rangle:=\langle T, p\psi \rangle \mathscr{S}'\to \mathscr{S}', \ \ \ T\mapsto T/p p T/p p","['functional-analysis', 'distribution-theory', 'schwartz-space']"
73,Show that a nonlocal operator with symmetric kernel is well defined,Show that a nonlocal operator with symmetric kernel is well defined,,"Assume that $J:\mathbb{R}^N\backslash \{0\}  \to (0, \infty)$ is a symmetric function; that is, $J(x)=J(-x)$ for any $x \in\mathbb{R}^N$ . Moreover, we assume that there is a constant $J_0 > 0$ and $0 < s < 1$ such that \begin{equation}\label{CondJ1}   J_0 \leqslant J(x)|x|^{N + 2s}, \end{equation} almost everywere in $\mathbb{R}^N$ . We also assume that \begin{equation}\label{CondJ2}   Jm \in L^1(\mathbb{R}^N), \end{equation} where $m(x) = \min\{1, |x|^2\}$ . Now, consider the nonlocal operador $$\mathcal{L}_Ju(x)= 2\int_{\mathbb{R}^N} J(x - y)(u(x)-u(y))dy.$$ I need to show that $\mathcal{L}_J u \in L^2(\mathbb{R}^N)$ if $u \in C^{\infty}_0(\mathbb{R}^N)$ .This indeed should happen, as mentioned on page 4 of the paper: https://arxiv.org/pdf/1612.05696.pdf . Attempt: If $u \in C^{\infty}_0(\mathbb{R}^N)$ , then $|u(x) - u(y)| \leqslant C|x - y|$ , for some $C > 0$ and $|u(x) - u(y)| \leqslant 2\|u\|_{L^{\infty}(\Omega)}$ . Thus $$|u(x) - u(y)| \leqslant K\sqrt{m(x - y)},$$ for some $K > 0$ . Consequently \begin{split}     \int_{\mathbb{R}^N}\Big|2\int_{\mathbb{R}^N}J(x - y)(u(x) - u(y))dy\Big|^2dx &\leqslant 4K^2\int_{\mathbb{R}^N}\Big|\int_{\mathbb{R}^N}J(x - y)\sqrt{m(x - y)}dy\Big|^2dx.\\ \end{split} But I only know that $Jm \in L^1(\mathbb{R}^N)$ .","Assume that is a symmetric function; that is, for any . Moreover, we assume that there is a constant and such that almost everywere in . We also assume that where . Now, consider the nonlocal operador I need to show that if .This indeed should happen, as mentioned on page 4 of the paper: https://arxiv.org/pdf/1612.05696.pdf . Attempt: If , then , for some and . Thus for some . Consequently But I only know that .","J:\mathbb{R}^N\backslash \{0\}  \to (0, \infty) J(x)=J(-x) x \in\mathbb{R}^N J_0 > 0 0 < s < 1 \begin{equation}\label{CondJ1}  
J_0 \leqslant J(x)|x|^{N + 2s},
\end{equation} \mathbb{R}^N \begin{equation}\label{CondJ2}  
Jm \in L^1(\mathbb{R}^N),
\end{equation} m(x) = \min\{1, |x|^2\} \mathcal{L}_Ju(x)= 2\int_{\mathbb{R}^N} J(x - y)(u(x)-u(y))dy. \mathcal{L}_J u \in L^2(\mathbb{R}^N) u \in C^{\infty}_0(\mathbb{R}^N) u \in C^{\infty}_0(\mathbb{R}^N) |u(x) - u(y)| \leqslant C|x - y| C > 0 |u(x) - u(y)| \leqslant 2\|u\|_{L^{\infty}(\Omega)} |u(x) - u(y)| \leqslant K\sqrt{m(x - y)}, K > 0 \begin{split}
    \int_{\mathbb{R}^N}\Big|2\int_{\mathbb{R}^N}J(x - y)(u(x) - u(y))dy\Big|^2dx &\leqslant 4K^2\int_{\mathbb{R}^N}\Big|\int_{\mathbb{R}^N}J(x - y)\sqrt{m(x - y)}dy\Big|^2dx.\\
\end{split} Jm \in L^1(\mathbb{R}^N)","['functional-analysis', 'multivariable-calculus', 'smooth-functions', 'fractional-sobolev-spaces']"
74,Separability of $B(X)$.,Separability of .,B(X),"Assume $X$ is a separable space, or even a countable one. Is then the space of bounded complex-valued functions on $X$ with the supremum norm, $\|f\|_{\infty}=\sup_{x\in X} |f(x)|$ , separable as well? Edit: Assume that $X$ is a countable set. Is the answer still no? All the counterexamples seem to consider $X$ as uncountable.","Assume is a separable space, or even a countable one. Is then the space of bounded complex-valued functions on with the supremum norm, , separable as well? Edit: Assume that is a countable set. Is the answer still no? All the counterexamples seem to consider as uncountable.",X X \|f\|_{\infty}=\sup_{x\in X} |f(x)| X X,"['real-analysis', 'functional-analysis']"
75,Every compact subset of real line is spectrum of self-adjoint operator,Every compact subset of real line is spectrum of self-adjoint operator,,"It is known that if $H$ is Hilbert space and $T$ is self-adjoint operator on $H$ , then the spectrum is real and closed. But is every closed or compact subset of real numbers a spectrum of some self-adjoint operator on some $H?$ For interval I think we can find the construction but how if the set is a mess, for example, Cantor set?","It is known that if is Hilbert space and is self-adjoint operator on , then the spectrum is real and closed. But is every closed or compact subset of real numbers a spectrum of some self-adjoint operator on some For interval I think we can find the construction but how if the set is a mess, for example, Cantor set?",H T H H?,"['functional-analysis', 'operator-theory']"
76,(Frechet) Differentiability of Implicit function in Banach spaces,(Frechet) Differentiability of Implicit function in Banach spaces,,"I'm looking at the classical implicit function theorem in Banach spaces. So $X,Y,Z$ are Banach spaces and $F: U_{x_0}\times V_{y_0} \to Z$ continuous and continuously differentiable with respect to y. And the inverse linear operator of the Frechet partial derivative is bounded linear operator. Also $F(x_0,y_0)=O.$ Then locally there is unique implicit function $T$ which $F(x,Tx)=O.$ This $T$ is continuous. However if we assume additional smoothness  condition for $F,$ then $T$ also has it. Ofcouse formal differentiation of $F(x,Tx) = O$ gets us that if $T$ is Frechet differentiable, then $T'x = - F'_y(x,Tx)^{-1} F'_{x}(x,Tx)$ possibly on smaller ball. So If I assume additionally that $F$ is continuously differentiable, then im trying to prove that indeed $T$ is differentiable by trying to see that $||\omega(x,h)||:=||T(x+h)-Tx+F'_y(x,Tx)^{-1} F'_{x}(x,Tx)h|| = o(||h||)$ as $h \to O.$ And so trying to get to $||\omega(x,h)||\leqq c \varepsilon ||h||.$ But the bound I'm currently getting is something along those lines: ( $\overline{x}:=x+h, y:=Tx, \overline{y}:=T(x+h))$ \begin{align*} ||\omega(x,h)||&= ||-F'_y (x,y)^{-1}||_{L(Z,Y)}.||-F'_y(x,y)(\overline{y}-y)-F'_x(x,y)h|| \\  &\leq c_1 ||F(x,y)-F(x,\overline{y})+\nu(x,\overline{y}-y)+F(x,y)-F(\overline{x},y)+\mu(h,x)|| \\ &\leq c_1 ( \varepsilon ||\overline{y}-y|| + \varepsilon ||h|| + ||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)||), \end{align*} provided that $||h|| < \delta(\varepsilon), ||\overline{y}-\overline{y}|| < \delta(\varepsilon).$ Where $c_1:=||-F'_y (x,y)^{-1}||_{L(Z,Y)}.$ Now the last term in the norm I evaluate the same way with the partial Frechet derivatives \begin{align*} ||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)|| \leqq ||F'_y(x,y)||. ||\overline{y} - y|| +\varepsilon ||\overline{y}-y|| +||F'_x(x,y)||.||h||+\varepsilon .||h||. \end{align*} Denoting $c_2:=||F'_y(x,y)||_{L(Y,Z)}$ and $c_3:=||F'_x(x,y)||_{L(X,Z)}.$ This then reads $||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)|| \leqq (c_2 + \varepsilon)||\overline{y}-y|| + (c_3 +\varepsilon)||h||$ and in substituing in the inequality for $||\omega(x,h)||$ we get $$ || \omega(x,h)|| \leqq c_1 (2\varepsilon+c_2)||\overline{y}-y||+(2\varepsilon+c_3)||h||. $$ Bound for $||\overline{y}-y||$ will get with this inequality and combined with reversed triangle inequality for the definition of omega : $$ | ||\overline{y}-y|| - ||-F'_y(x,y)^{-1}F'_x(x,y)||.||h|| | \leq ||\omega(x,h)||\leqq c_1 [(2\varepsilon+c_2)||\overline{y}-y||+(2\varepsilon+c_3)||h||]. $$ Therefore denoting $c_4:=||-F'_y(x,y)^{-1}F'_x(x,y)||=c_1.c_3$ we get $(1-c_1(2\varepsilon+c_2))||\overline{y}-y|| \leq (c_1 c_3 +c_1 (2\varepsilon +c_2))||h||.$ Thus getting the following absurd (useless)bound $$ ||\omega(x,h)|| \leqq \left[ (2\varepsilon+c_3) + \frac{c_1(2\varepsilon+c_2)}{1-c_1(2\varepsilon+c_2)} [c_1 c_3 + c_1(2\varepsilon + c_2)] \right] ||h||. $$ The problem with this bound is that it must be multiple of $\varepsilon$ and $||h||$ in order to get $o(||h||).$ Any suggestions on how to get a better bound will be much appreciated. For reference: I tried to escape the argument in Deimling's book, where implicit function theorem was proven (without the assertion for differentiability of the implicit function) and then inverse function theorem was proven, and differentiability of the inverse function was established quoite easy. After that Mr. Deimling proves differentiability of the implicit function using the inverse function theorem; There he assumes $F is C^m$ and considers the following map: $G(x,y):=(x, F'_y(x_0,y_0)^{-1}F(x,y)).$ And claims that since $$ G'(x_0,y_0)(h,k) = (h, k+ F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0)h), $$ $G'(x_0,y_0)$ must be a homeomorphism (which i dont see how its automatically true) And then $G^{-1}(x,O)=(x,Tx)$ with $T$ exactly the implicit function we are discussing. And  now its clear how differentiability (and $C^m$ ) in inverse function theorem establishes it in the implicit function theorem. So additional question : Is it obvious that $G'(x_0,y_0) = (Id_X, Id_Y +F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0))$ is homeomorphism? Update It is obvious... since the right coordinate is translation with linear bounded operator the inverse will be sign-conjugated one: $$G'(x_0,y_0)^{-1}=(Id_X, Id_Y - F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0)).$$ Now it's clear how the rest follows.","I'm looking at the classical implicit function theorem in Banach spaces. So are Banach spaces and continuous and continuously differentiable with respect to y. And the inverse linear operator of the Frechet partial derivative is bounded linear operator. Also Then locally there is unique implicit function which This is continuous. However if we assume additional smoothness  condition for then also has it. Ofcouse formal differentiation of gets us that if is Frechet differentiable, then possibly on smaller ball. So If I assume additionally that is continuously differentiable, then im trying to prove that indeed is differentiable by trying to see that as And so trying to get to But the bound I'm currently getting is something along those lines: ( provided that Where Now the last term in the norm I evaluate the same way with the partial Frechet derivatives Denoting and This then reads and in substituing in the inequality for we get Bound for will get with this inequality and combined with reversed triangle inequality for the definition of omega : Therefore denoting we get Thus getting the following absurd (useless)bound The problem with this bound is that it must be multiple of and in order to get Any suggestions on how to get a better bound will be much appreciated. For reference: I tried to escape the argument in Deimling's book, where implicit function theorem was proven (without the assertion for differentiability of the implicit function) and then inverse function theorem was proven, and differentiability of the inverse function was established quoite easy. After that Mr. Deimling proves differentiability of the implicit function using the inverse function theorem; There he assumes and considers the following map: And claims that since must be a homeomorphism (which i dont see how its automatically true) And then with exactly the implicit function we are discussing. And  now its clear how differentiability (and ) in inverse function theorem establishes it in the implicit function theorem. So additional question : Is it obvious that is homeomorphism? Update It is obvious... since the right coordinate is translation with linear bounded operator the inverse will be sign-conjugated one: Now it's clear how the rest follows.","X,Y,Z F: U_{x_0}\times V_{y_0} \to Z F(x_0,y_0)=O. T F(x,Tx)=O. T F, T F(x,Tx) = O T T'x = - F'_y(x,Tx)^{-1} F'_{x}(x,Tx) F T ||\omega(x,h)||:=||T(x+h)-Tx+F'_y(x,Tx)^{-1} F'_{x}(x,Tx)h|| = o(||h||) h \to O. ||\omega(x,h)||\leqq c \varepsilon ||h||. \overline{x}:=x+h, y:=Tx, \overline{y}:=T(x+h)) \begin{align*}
||\omega(x,h)||&= ||-F'_y (x,y)^{-1}||_{L(Z,Y)}.||-F'_y(x,y)(\overline{y}-y)-F'_x(x,y)h|| \\ 
&\leq c_1 ||F(x,y)-F(x,\overline{y})+\nu(x,\overline{y}-y)+F(x,y)-F(\overline{x},y)+\mu(h,x)|| \\
&\leq c_1 ( \varepsilon ||\overline{y}-y|| + \varepsilon ||h|| + ||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)||),
\end{align*} ||h|| < \delta(\varepsilon), ||\overline{y}-\overline{y}|| < \delta(\varepsilon). c_1:=||-F'_y (x,y)^{-1}||_{L(Z,Y)}. \begin{align*}
||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)|| \leqq ||F'_y(x,y)||. ||\overline{y} - y|| +\varepsilon ||\overline{y}-y|| +||F'_x(x,y)||.||h||+\varepsilon .||h||.
\end{align*} c_2:=||F'_y(x,y)||_{L(Y,Z)} c_3:=||F'_x(x,y)||_{L(X,Z)}. ||F(x,\overline{y})-F(x,y)+F(\overline{x},y)-F(x,y)|| \leqq (c_2 + \varepsilon)||\overline{y}-y|| + (c_3 +\varepsilon)||h|| ||\omega(x,h)|| 
|| \omega(x,h)|| \leqq c_1 (2\varepsilon+c_2)||\overline{y}-y||+(2\varepsilon+c_3)||h||.
 ||\overline{y}-y|| 
| ||\overline{y}-y|| - ||-F'_y(x,y)^{-1}F'_x(x,y)||.||h|| | \leq ||\omega(x,h)||\leqq c_1 [(2\varepsilon+c_2)||\overline{y}-y||+(2\varepsilon+c_3)||h||].
 c_4:=||-F'_y(x,y)^{-1}F'_x(x,y)||=c_1.c_3 (1-c_1(2\varepsilon+c_2))||\overline{y}-y|| \leq (c_1 c_3 +c_1 (2\varepsilon +c_2))||h||. 
||\omega(x,h)|| \leqq \left[ (2\varepsilon+c_3) + \frac{c_1(2\varepsilon+c_2)}{1-c_1(2\varepsilon+c_2)} [c_1 c_3 + c_1(2\varepsilon + c_2)] \right] ||h||.
 \varepsilon ||h|| o(||h||). F is C^m G(x,y):=(x, F'_y(x_0,y_0)^{-1}F(x,y)). 
G'(x_0,y_0)(h,k) = (h, k+ F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0)h),
 G'(x_0,y_0) G^{-1}(x,O)=(x,Tx) T C^m G'(x_0,y_0) = (Id_X, Id_Y +F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0)) G'(x_0,y_0)^{-1}=(Id_X, Id_Y - F'_y(x_0,y_0)^{-1}F'_x(x_0,y_0)).","['functional-analysis', 'analysis', 'implicit-function-theorem', 'nonlinear-analysis']"
77,span of maximal orthonormal sets in a Hilbert space,span of maximal orthonormal sets in a Hilbert space,,"I am working through Walter Rudin's Real and Complex Analysis and I'm having trouble understanding something about Theorem 4.18: I understand the proof of the theorem, but I'm confused about the relationship between conditions (i) and (ii).  If $ \{u_\alpha\}$ is a maximal orthonormal set in H, that means that there are no extra vectors in H that we can add to $ \{u_\alpha\}$ which is orthogonoal to every vector in $ \{u_\alpha\}$ . For example, $R^3$ equipped with the dot product is a Hilbert space, and $\{u_\alpha\}=\{(1,0,0),(0,1,0),(0,0,1)\}$ would be a maximal orthonormal set in $R^3$ .  But in this case, the set of all finite linear combinations of members of $\{u_\alpha\}$ would not just be dense in H, but is equal to H.  My question is, wouldn't this be the case for every Hilbert space, and if not, could someone provide a good example to help build intuition as to how that works?","I am working through Walter Rudin's Real and Complex Analysis and I'm having trouble understanding something about Theorem 4.18: I understand the proof of the theorem, but I'm confused about the relationship between conditions (i) and (ii).  If is a maximal orthonormal set in H, that means that there are no extra vectors in H that we can add to which is orthogonoal to every vector in . For example, equipped with the dot product is a Hilbert space, and would be a maximal orthonormal set in .  But in this case, the set of all finite linear combinations of members of would not just be dense in H, but is equal to H.  My question is, wouldn't this be the case for every Hilbert space, and if not, could someone provide a good example to help build intuition as to how that works?"," \{u_\alpha\}  \{u_\alpha\}  \{u_\alpha\} R^3 \{u_\alpha\}=\{(1,0,0),(0,1,0),(0,0,1)\} R^3 \{u_\alpha\}","['functional-analysis', 'hilbert-spaces', 'orthonormal']"
78,"If $u,v\in \dot H^{1/4}(\mathbb R)$, where does the product $uv$ lie?","If , where does the product  lie?","u,v\in \dot H^{1/4}(\mathbb R) uv","Let $u,v\in\dot H^{1/4}(\mathbb R)$ . Since by Sobolev embedding $\dot H^{1/4}(\mathbb R)\hookrightarrow L^4(\mathbb R)$ , I know that the product $uv$ lies in $L^2(\mathbb R)$ , that is, it holds the estimate $$ \|uv\|_{L^2}\leq C\|u\|_{\dot H^{1/4}}\|v\|_{\dot H^{1/4}}. $$ My question is, is it possible to find a better estimate on $uv$ ? Does the product lie in some Besov space of positive regularity, or any normed space that is strictly contained in $L^2$ ? The Sobolev space $\dot H^s(\mathbb R)$ is the space of tempered distributions such that the Fourier transform is locally integrable and the following norm is finite: $$ \|u\|^2_{\dot H^s}=\left|\int_{\mathbb R}|\xi|^{2s}|\widehat u(\xi)|^2\,d\xi\right|, $$ where $\widehat u$ is the Fourier transform of $u$ .","Let . Since by Sobolev embedding , I know that the product lies in , that is, it holds the estimate My question is, is it possible to find a better estimate on ? Does the product lie in some Besov space of positive regularity, or any normed space that is strictly contained in ? The Sobolev space is the space of tempered distributions such that the Fourier transform is locally integrable and the following norm is finite: where is the Fourier transform of .","u,v\in\dot H^{1/4}(\mathbb R) \dot H^{1/4}(\mathbb R)\hookrightarrow L^4(\mathbb R) uv L^2(\mathbb R)  \|uv\|_{L^2}\leq C\|u\|_{\dot H^{1/4}}\|v\|_{\dot H^{1/4}}.  uv L^2 \dot H^s(\mathbb R)  \|u\|^2_{\dot H^s}=\left|\int_{\mathbb R}|\xi|^{2s}|\widehat u(\xi)|^2\,d\xi\right|,  \widehat u u","['real-analysis', 'functional-analysis', 'fourier-analysis', 'sobolev-spaces']"
79,A hint in Brezis' exercise 4.16.1,A hint in Brezis' exercise 4.16.1,,"Let $(\Omega, \mathcal F, \mu)$ be a $\sigma$ -finite measure space. I'm trying to prove below hint in Brezis' Functional Analysis , i.e., Let $p \in [1, \infty)$ and $p'$ its Hölder conjugate. Let $f_n,f,g:\Omega \to \mathbb R$ be measurable functions such that $f_n,f \in L^p(\Omega)$ for all $n$ . Assume $f_n \to f$ in the weak topology $\sigma(L^p, L^{p'})$ and $f_n \to g$ $\mu$ -a.e. Then $f=g$ $\mu$ -a.e. Could you confirm if my attempt is fine? Is there a way to bypass the use of exercise 3.4.1? Proof First, we need the following result, i.e., Brezis' exercise 3.4.1 Let $E$ be a Banach space and $(x_n) \subset E$ such that $x_n \to x$ in $\sigma(E, E^*)$ . Then there exists a sequence $(y_n) \subset E$ such that $y_n \in \operatorname{conv} (\{x_n, x_{n+1}, \ldots\})$ for all $n$ and $y_n \rightarrow x$ in norm. Let $(g_n)$ be a sequence given by above result for the pair $((f_n)_n, f)$ . Then $g_n \in \operatorname{conv} (\{f_n, f_{n+1}, \ldots\})$ and $g_n \to f$ in $L^p$ . There is a sub-sequence $\varphi$ of $\mathbb N$ such that $g_{\varphi (n)} \to f$ $\mu$ -a.e. Fix $\omega \in \Omega$ such that $f_n (\omega) \to g (\omega)$ and $g_{\varphi (n)} (\omega) \to f (\omega)$ . Fix $\varepsilon >0$ . There is $N$ such that for every $n >N$ $$ \begin{align} |f_n(\omega) - g (\omega)| &< \varepsilon. \end{align} $$ Fix $n>N$ . There is $\psi (n) > \varphi (n)$ and a probability vector $(t_i)_{i=\varphi (n)}^{\psi (n)}$ such that $$ g_{\varphi (n)} = \sum_{i=\varphi (n)}^{\psi (n)} t_i f_i \quad \mu \text{-a.e.} $$ Then $$ |g_{\varphi (n)} (\omega) - g (\omega)| \le \sum_{i=\varphi (n)}^{\psi (n)} t_i |f_i (\omega) - g(\omega)| < \varepsilon. $$ Hence $g_{\varphi (n)} (\omega) \to g (\omega)$ . It follows that $g(\omega) = f(\omega)$ . This completes the proof.","Let be a -finite measure space. I'm trying to prove below hint in Brezis' Functional Analysis , i.e., Let and its Hölder conjugate. Let be measurable functions such that for all . Assume in the weak topology and -a.e. Then -a.e. Could you confirm if my attempt is fine? Is there a way to bypass the use of exercise 3.4.1? Proof First, we need the following result, i.e., Brezis' exercise 3.4.1 Let be a Banach space and such that in . Then there exists a sequence such that for all and in norm. Let be a sequence given by above result for the pair . Then and in . There is a sub-sequence of such that -a.e. Fix such that and . Fix . There is such that for every Fix . There is and a probability vector such that Then Hence . It follows that . This completes the proof.","(\Omega, \mathcal F, \mu) \sigma p \in [1, \infty) p' f_n,f,g:\Omega \to \mathbb R f_n,f \in L^p(\Omega) n f_n \to f \sigma(L^p, L^{p'}) f_n \to g \mu f=g \mu E (x_n) \subset E x_n \to x \sigma(E, E^*) (y_n) \subset E y_n \in \operatorname{conv} (\{x_n, x_{n+1}, \ldots\}) n y_n \rightarrow x (g_n) ((f_n)_n, f) g_n \in \operatorname{conv} (\{f_n, f_{n+1}, \ldots\}) g_n \to f L^p \varphi \mathbb N g_{\varphi (n)} \to f \mu \omega \in \Omega f_n (\omega) \to g (\omega) g_{\varphi (n)} (\omega) \to f (\omega) \varepsilon >0 N n >N 
\begin{align}
|f_n(\omega) - g (\omega)| &< \varepsilon.
\end{align}
 n>N \psi (n) > \varphi (n) (t_i)_{i=\varphi (n)}^{\psi (n)} 
g_{\varphi (n)} = \sum_{i=\varphi (n)}^{\psi (n)} t_i f_i
\quad \mu \text{-a.e.}
 
|g_{\varphi (n)} (\omega) - g (\omega)| \le \sum_{i=\varphi (n)}^{\psi (n)} t_i |f_i (\omega) - g(\omega)| < \varepsilon.
 g_{\varphi (n)} (\omega) \to g (\omega) g(\omega) = f(\omega)","['real-analysis', 'functional-analysis', 'lebesgue-integral', 'banach-spaces', 'lp-spaces']"
80,Question on showing that $\frac{1}{n}\sum_{k=0}^{n-1}U^kf$ converges in norm to the orthogonal projection $Pf$ to the space $\{f\in H: Uf = f\}$,Question on showing that  converges in norm to the orthogonal projection  to the space,\frac{1}{n}\sum_{k=0}^{n-1}U^kf Pf \{f\in H: Uf = f\},"Edit: The reference I am reading is Yves Coudène's Ergodic Theory and Dynamical Systems , chapter 1, proof of theorem 1.1 on page 5. Let $H$ be a Hilbert space and $U:H\to H$ a bounded linear operator with $\|U\|\leq 1$ . Define $\mathrm{Inv} = \{f\in H\mid Uf = f\}$ . I am currently trying to understand a proof that $\lim_{n\to\infty}\frac{1}{n}\sum_{k=0}^{n-1}U^k f = Pf$ where $P:H\to \mathrm{Inv}$ is an orthogonal projection. Denote $S_nf := \sum_{k=0}^{n-1}U^kf$ . If $f\in \mathrm{Inv}$ the claim is clear. The proof I am reading says that since $$\big\|\tfrac{1}{n}S_n(f)\big\|^2 = \left<f, \tfrac1nS_n^*\tfrac1n S_nf\right>$$ it suffices to show that for every $f\in \mathrm{Inv}^\perp$ , the sequence $f_n := \frac{1}{n}S_n^*\frac{1}{n}S_n(f)$ converges weakly to $0$ , or that all accumulation points of the sequence $f_n$ are $0$ . Up to this point I am fully with the proof, since if what is said about the limit points of $f_n$ is true then $\left<f, f_n\right>\to 0, n\to \infty$ by e.g. Cauchy-Schwarz. ( Questions: ) But then the mystery begins with the following claim made in the proof: Because they [(the accumulation points)] are in $\mathrm{Inv}^\perp$ , it suffices to prove that they are invariant under $U$ or $U^*$ . 1.) I don't really follow why the accumulation points of $f_n$ are necessarily in $\mathrm{Inv}^\perp$ given everything that has been said so far. But this is potentially only a minor issue if the weak convergence can be concluded without really considering where the limit points are. With this in mind, the following (bold marked part later in this post) confuses me even more: It is quite simple to conclude that for every $h\in H:(I - U^*)\frac{1}{n}S_n^*h = \frac{1}{n}(I - U^*)h$ . The author uses this fact to choose $h = \frac{1}{n}S_nf$ and writes $$\big\|(I - U*)\tfrac1n S_n^*\tfrac1n S_nf\big\|\leq \tfrac1n \|I - U^{*n}\|\big\|\tfrac1n S_nf\big\|\leq \tfrac2n\|f\|\to 0,n\to\infty$$ ( Confusing part: ) and states Convergence in norm implies weak convergence. 2.) I don't understand why this shows what we want, that $f_n$ tends weakly to zero. The norm inequality shows precisely that $\lim_{n\to\infty}(I - U^*)\left(f_n\right) = 0$ . My current understanding is that this would be great if we would know that $\frac{1}{n}S_n^*\frac{1}{n}S_nf$ converges to something, as then we could say that the limit of $\frac{1}{n}S_n^*\frac{1}{n}S_nf$ is invariant under $U^*$ and consequently under $U$ . How can the weak convergence be deduced?","Edit: The reference I am reading is Yves Coudène's Ergodic Theory and Dynamical Systems , chapter 1, proof of theorem 1.1 on page 5. Let be a Hilbert space and a bounded linear operator with . Define . I am currently trying to understand a proof that where is an orthogonal projection. Denote . If the claim is clear. The proof I am reading says that since it suffices to show that for every , the sequence converges weakly to , or that all accumulation points of the sequence are . Up to this point I am fully with the proof, since if what is said about the limit points of is true then by e.g. Cauchy-Schwarz. ( Questions: ) But then the mystery begins with the following claim made in the proof: Because they [(the accumulation points)] are in , it suffices to prove that they are invariant under or . 1.) I don't really follow why the accumulation points of are necessarily in given everything that has been said so far. But this is potentially only a minor issue if the weak convergence can be concluded without really considering where the limit points are. With this in mind, the following (bold marked part later in this post) confuses me even more: It is quite simple to conclude that for every . The author uses this fact to choose and writes ( Confusing part: ) and states Convergence in norm implies weak convergence. 2.) I don't understand why this shows what we want, that tends weakly to zero. The norm inequality shows precisely that . My current understanding is that this would be great if we would know that converges to something, as then we could say that the limit of is invariant under and consequently under . How can the weak convergence be deduced?","H U:H\to H \|U\|\leq 1 \mathrm{Inv} = \{f\in H\mid Uf = f\} \lim_{n\to\infty}\frac{1}{n}\sum_{k=0}^{n-1}U^k f = Pf P:H\to \mathrm{Inv} S_nf := \sum_{k=0}^{n-1}U^kf f\in \mathrm{Inv} \big\|\tfrac{1}{n}S_n(f)\big\|^2 = \left<f, \tfrac1nS_n^*\tfrac1n S_nf\right> f\in \mathrm{Inv}^\perp f_n := \frac{1}{n}S_n^*\frac{1}{n}S_n(f) 0 f_n 0 f_n \left<f, f_n\right>\to 0, n\to \infty \mathrm{Inv}^\perp U U^* f_n \mathrm{Inv}^\perp h\in H:(I - U^*)\frac{1}{n}S_n^*h = \frac{1}{n}(I - U^*)h h = \frac{1}{n}S_nf \big\|(I - U*)\tfrac1n S_n^*\tfrac1n S_nf\big\|\leq \tfrac1n \|I - U^{*n}\|\big\|\tfrac1n S_nf\big\|\leq \tfrac2n\|f\|\to 0,n\to\infty f_n \lim_{n\to\infty}(I - U^*)\left(f_n\right) = 0 \frac{1}{n}S_n^*\frac{1}{n}S_nf \frac{1}{n}S_n^*\frac{1}{n}S_nf U^* U","['linear-algebra', 'functional-analysis', 'hilbert-spaces', 'orthogonality', 'projection']"
81,Definition of ground state?,Definition of ground state?,,"In quantum mechanics, a ground state is an eigenstate of the hamiltonian with the minimal eigenvalue and its existence is guaranteed by appropriate theorems. At least that's how it's defined in undergraduate courses. In the formalism of operator algebras, the definition of ground state is equally clear but so different that I cannot relate it to the classic definition. Given a suitable operator algebra $U$ and a continuous group of automorphisms $\tau$ defineing a dynamical system on $U$ , and calling $\tau$ the infinitesimal generator of the system (for a quantum system this would be the Hamiltonian) a ground state $\omega$ is one that for every operator $A$ of the algebra with adjoint $A*$ satisfies $$- i \omega(A^* \delta(A)) \geq 0 \ \ \ \ \ (1) $$ Eq. (1) follows from the KMS condition, I will paste a screenshot from one source here: I wonder if anybody has an intuition on how to bridge this definition to the classic one.","In quantum mechanics, a ground state is an eigenstate of the hamiltonian with the minimal eigenvalue and its existence is guaranteed by appropriate theorems. At least that's how it's defined in undergraduate courses. In the formalism of operator algebras, the definition of ground state is equally clear but so different that I cannot relate it to the classic definition. Given a suitable operator algebra and a continuous group of automorphisms defineing a dynamical system on , and calling the infinitesimal generator of the system (for a quantum system this would be the Hamiltonian) a ground state is one that for every operator of the algebra with adjoint satisfies Eq. (1) follows from the KMS condition, I will paste a screenshot from one source here: I wonder if anybody has an intuition on how to bridge this definition to the classic one.",U \tau U \tau \omega A A* - i \omega(A^* \delta(A)) \geq 0 \ \ \ \ \ (1) ,"['functional-analysis', 'operator-theory', 'c-star-algebras', 'quantum-mechanics', 'quantum-information']"
82,If $f_n$ converges to $f$ in $L^p$ then does $f_n^2$ converge to $f^2$?,If  converges to  in  then does  converge to ?,f_n f L^p f_n^2 f^2,"I want to say no, but what is a counterexample? More generally, does $L^p$ convergence of a sequence of functions imply any sort of convergence (i.e. in some different $L^{p'}$ space) of a function of that sequence of functions?","I want to say no, but what is a counterexample? More generally, does convergence of a sequence of functions imply any sort of convergence (i.e. in some different space) of a function of that sequence of functions?",L^p L^{p'},"['functional-analysis', 'lp-spaces']"
83,Convergent sequence of real numbers inside spectrum of operator,Convergent sequence of real numbers inside spectrum of operator,,"I'm trying to solve the following. Let $T$ be a compact and self-adjoint operator on a prehilbertian space. Determine wether the spectrum of T contains a sequence of real numbers that converge to zero. Some context: By a prehilbertian space, we're referring to a vector space over a field $\mathbb{K}$ , generally $\mathbb{R}$ or $\mathbb{C}$ , that has an inner product. Every inner product naturally induces a norm so every prehilbertian space is also a normed vector space. The resolvent of an operator $T$ is defined as $\rho(T) = \{\lambda\in\mathbb{C}:(\lambda Id-T) \ \text{has an inverse}\}$ and therefore the spectrum is $\sigma(T) = \mathbb{C}-\rho(T)$ . Finally, an operator $T:X\longrightarrow Y$ between normed spaces is compact if $T(B_X)$ is a relatively compact set in $Y$ (i.e. its closure is compact in $Y$ ), where $B_X$ is the unit ball in $X$ . My attempt at the proof I'm having issues understanding what the restriction of not being a Hilbert space implies. Is the completeness of the space necessary to prove the claim? I mean, if we were on a Hilbert space, then by the spectral theorem there exists a Hilbert base and sequence of real (since $T$ is self-adjoint) numbers such that $Te_k = \lambda_ke_k$ , with $\lambda_k\to 0$ as $k\to\infty$ , therefore those real numbers are indeed eigenvalues, which are obviusly a subset of the spectrum. But what happens if it's not a Hilbert space? As far as I've been told, the result is true, but I don't know what results to use to come up with the answer.","I'm trying to solve the following. Let be a compact and self-adjoint operator on a prehilbertian space. Determine wether the spectrum of T contains a sequence of real numbers that converge to zero. Some context: By a prehilbertian space, we're referring to a vector space over a field , generally or , that has an inner product. Every inner product naturally induces a norm so every prehilbertian space is also a normed vector space. The resolvent of an operator is defined as and therefore the spectrum is . Finally, an operator between normed spaces is compact if is a relatively compact set in (i.e. its closure is compact in ), where is the unit ball in . My attempt at the proof I'm having issues understanding what the restriction of not being a Hilbert space implies. Is the completeness of the space necessary to prove the claim? I mean, if we were on a Hilbert space, then by the spectral theorem there exists a Hilbert base and sequence of real (since is self-adjoint) numbers such that , with as , therefore those real numbers are indeed eigenvalues, which are obviusly a subset of the spectrum. But what happens if it's not a Hilbert space? As far as I've been told, the result is true, but I don't know what results to use to come up with the answer.",T \mathbb{K} \mathbb{R} \mathbb{C} T \rho(T) = \{\lambda\in\mathbb{C}:(\lambda Id-T) \ \text{has an inverse}\} \sigma(T) = \mathbb{C}-\rho(T) T:X\longrightarrow Y T(B_X) Y Y B_X X T Te_k = \lambda_ke_k \lambda_k\to 0 k\to\infty,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
84,Understanding notation of norm with three vertical lines,Understanding notation of norm with three vertical lines,,"We usually denote a norm with the notation $||\cdot ||$ . However I've seen someone write $|||\cdot|||$ . Is this the same as $||\cdot||$ ? For instance, I have readed a note regarding functional analysis. A lemma states: Lemma: Let $A$ be a Banach algebra with identity $I$ . Then there is a norm $|||\cdot|||$ on $A$ , equivalent to the original norm, such that $(A,|||\cdot|||)$ is a unital Banach algebra with $|||I|||=1$ . I am just curious. Could we just write the lemma as e.g. Lemma: Let $A$ be a Banach algebra with identity $I$ . Then there is a norm $||\cdot||$ on $A$ , equivalent to the original norm, such that $(A,||\cdot||)$ is a unital Banach algebra with $||I||=1$ .","We usually denote a norm with the notation . However I've seen someone write . Is this the same as ? For instance, I have readed a note regarding functional analysis. A lemma states: Lemma: Let be a Banach algebra with identity . Then there is a norm on , equivalent to the original norm, such that is a unital Banach algebra with . I am just curious. Could we just write the lemma as e.g. Lemma: Let be a Banach algebra with identity . Then there is a norm on , equivalent to the original norm, such that is a unital Banach algebra with .","||\cdot || |||\cdot||| ||\cdot|| A I |||\cdot||| A (A,|||\cdot|||) |||I|||=1 A I ||\cdot|| A (A,||\cdot||) ||I||=1","['functional-analysis', 'notation', 'normed-spaces', 'operator-theory', 'banach-spaces']"
85,The admissible exponents of Strichartz estimate,The admissible exponents of Strichartz estimate,,"The Strichartz estimate for the Schrodinger equation is well-known: $$ \|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^2_x}, $$ where the exponent $p,q \in [2,\infty]$ satisfy $$ \frac{2}{p}+\frac{d}{q} = \frac{d}{2}, \quad (p,q,d) \neq (2,\infty,2). $$ I wonder whether we can replace $L^2$ -norm of the R.H.S. to $L^r$ -norm. More precisely, I would like to know if we get an estimate like the following: $$ \|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^r_x}. $$ The above estimate is invariant with respect to the scaling when $(p,q,r)$ satisfies $$ \frac{2}{p}+\frac{d}{q} = \frac{d}{r}. $$","The Strichartz estimate for the Schrodinger equation is well-known: where the exponent satisfy I wonder whether we can replace -norm of the R.H.S. to -norm. More precisely, I would like to know if we get an estimate like the following: The above estimate is invariant with respect to the scaling when satisfies","
\|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^2_x},
 p,q \in [2,\infty] 
\frac{2}{p}+\frac{d}{q} = \frac{d}{2}, \quad (p,q,d) \neq (2,\infty,2).
 L^2 L^r 
\|e^{it\Delta} u_0\|_{L^p_t L^q_x} \le C \|u_0\|_{L^r_x}.
 (p,q,r) 
\frac{2}{p}+\frac{d}{q} = \frac{d}{r}.
","['real-analysis', 'calculus', 'functional-analysis', 'partial-differential-equations', 'harmonic-analysis']"
86,Why do we prefer the Schauder basis over the Hamel basis in functional analysis?,Why do we prefer the Schauder basis over the Hamel basis in functional analysis?,,"Our functional analysis instructor mentioned in the class that the Hamel basis is not so important in the context of Banach spaces. Instead, we prefer the Schauder basis. However, he did not specify the reason why it is so. I tried to think about it myself, but could not find a satisfactory answer. Can someone illustrate why the Hamel basis is not important in the context of Banach spaces, and what motivated mathematicians to work with the Schauder basis?","Our functional analysis instructor mentioned in the class that the Hamel basis is not so important in the context of Banach spaces. Instead, we prefer the Schauder basis. However, he did not specify the reason why it is so. I tried to think about it myself, but could not find a satisfactory answer. Can someone illustrate why the Hamel basis is not important in the context of Banach spaces, and what motivated mathematicians to work with the Schauder basis?",,"['functional-analysis', 'banach-spaces', 'hamel-basis', 'schauder-basis']"
87,Does every incomplete real inner product space admit a closed subspace of countable dimension?,Does every incomplete real inner product space admit a closed subspace of countable dimension?,,"Suppose $X$ is an incomplete real inner product space. Does there exist a sequence $(y_n)_n \in X$ such that $Y = \operatorname{span}\{y_n\}_n$ is closed? This question cropped up as part of my research. It cannot be the case, by the Baire category theorem, that $Y$ is complete, hence admitting such a closed subspace would imply $X$ is incomplete, but is the converse true? My instinct is to take $(y_n)_n$ to be a non-convergent Cauchy sequence, and apply Gram-Schmidt (removing $0$ vectors as they come) to form orthonormal $(z_n)_n$ . This would produce a new basis for $Y$ whose coordinate maps are all continuous. So, if $(x_n)_n \in Y$ converges to $x \in X$ , then the coordinates $\langle x_n, z_i \rangle$ converge to $\langle x, z_i\rangle$ as $n \to \infty$ . If all but finitely many of these coordinates are $0$ , then $x \in Y$ . If not, then I'd like to find a way to parlay this into constructing a limit for $(y_n)_n$ , but I'm not sure how to do it. Does anyone have an idea? I don't even know if this result is true.","Suppose is an incomplete real inner product space. Does there exist a sequence such that is closed? This question cropped up as part of my research. It cannot be the case, by the Baire category theorem, that is complete, hence admitting such a closed subspace would imply is incomplete, but is the converse true? My instinct is to take to be a non-convergent Cauchy sequence, and apply Gram-Schmidt (removing vectors as they come) to form orthonormal . This would produce a new basis for whose coordinate maps are all continuous. So, if converges to , then the coordinates converge to as . If all but finitely many of these coordinates are , then . If not, then I'd like to find a way to parlay this into constructing a limit for , but I'm not sure how to do it. Does anyone have an idea? I don't even know if this result is true.","X (y_n)_n \in X Y = \operatorname{span}\{y_n\}_n Y X (y_n)_n 0 (z_n)_n Y (x_n)_n \in Y x \in X \langle x_n, z_i \rangle \langle x, z_i\rangle n \to \infty 0 x \in Y (y_n)_n","['functional-analysis', 'inner-products', 'complete-spaces']"
88,"Is $p(x) = \max(p_1(x), p_2(x))$ a seminorm when $p_1, p_2$ are seminorms?",Is  a seminorm when  are seminorms?,"p(x) = \max(p_1(x), p_2(x)) p_1, p_2","To start: I've shown that yes, $p(x) = \max(p_1(x), p_2(x))$ is a seminorm if $p_1, p_2$ are seminorms. But I did that by proving absolute homogeneity and the triangle inequality directly. What I'd like to know: Is there some broader theoretical result that could be used instead? By way of comparison: if $\pi_i(x_1, x_2) = x_i$ are projection operators and $T$ is a linear transformation, then I know that $q(x) = p_1(\pi_1(Tx)) + p_2(\pi_2(Tx)))$ is a seminorm without directly proving the seminorm axioms because each $p_i(\pi_1(Tx))$ is a seminorm (as the composition of a seminorm and a linear operator), so that $q$ is the sum of seminorms. Is there some similar theorem(s) I could use for $p$ ?","To start: I've shown that yes, is a seminorm if are seminorms. But I did that by proving absolute homogeneity and the triangle inequality directly. What I'd like to know: Is there some broader theoretical result that could be used instead? By way of comparison: if are projection operators and is a linear transformation, then I know that is a seminorm without directly proving the seminorm axioms because each is a seminorm (as the composition of a seminorm and a linear operator), so that is the sum of seminorms. Is there some similar theorem(s) I could use for ?","p(x) = \max(p_1(x), p_2(x)) p_1, p_2 \pi_i(x_1, x_2) = x_i T q(x) = p_1(\pi_1(Tx)) + p_2(\pi_2(Tx))) p_i(\pi_1(Tx)) q p","['functional-analysis', 'normed-spaces', 'hilbert-spaces']"
89,Why the norm is $>1$ for one projection operator?,Why the norm is  for one projection operator?,>1,"Let $P: c \to c$ be a projection operator onto $c_0 \subseteq c$ . That is, $P$ is a bounded operator such that $P^2=P$ and $\operatorname{Im} P=c_0$ . We are asked to show that $\lVert P\rVert > 1$ . My attempt was: For any $w\in c$ we have that $$\lVert Pw \rVert= \lVert P^2 w\rVert \leq \lVert P\rVert^2 \lVert w\rVert$$ this implies that $\frac{\lVert Pw \rVert}{\lVert w\rVert}\leq \lVert P\rVert^2$ or equivalently $1\leq \lVert P\rVert$ . I do know why the inequality is strict. Hence, the other side we know that for all $w\in c $ then $w=w-P(w)+P(w)$ where $w-P(w)\in \ker P$ and $P(w)\in c_0= \operatorname{Im} P$ , so $\lvert c \rvert = \lvert \ker P \rvert + \lvert c_0 \rvert > \lvert c_0\rvert$ where i mean $\lvert c \rvert := \operatorname{dim}c$ . I guess that I need to find some particular element in the domain for attach the grater dimension or something like that. I am not sure if $c_0$ are the sequence that converge to $0$ for this reason i did no try other thing with sequences. I will appreciate any hint please. Best","Let be a projection operator onto . That is, is a bounded operator such that and . We are asked to show that . My attempt was: For any we have that this implies that or equivalently . I do know why the inequality is strict. Hence, the other side we know that for all then where and , so where i mean . I guess that I need to find some particular element in the domain for attach the grater dimension or something like that. I am not sure if are the sequence that converge to for this reason i did no try other thing with sequences. I will appreciate any hint please. Best",P: c \to c c_0 \subseteq c P P^2=P \operatorname{Im} P=c_0 \lVert P\rVert > 1 w\in c \lVert Pw \rVert= \lVert P^2 w\rVert \leq \lVert P\rVert^2 \lVert w\rVert \frac{\lVert Pw \rVert}{\lVert w\rVert}\leq \lVert P\rVert^2 1\leq \lVert P\rVert w\in c  w=w-P(w)+P(w) w-P(w)\in \ker P P(w)\in c_0= \operatorname{Im} P \lvert c \rvert = \lvert \ker P \rvert + \lvert c_0 \rvert > \lvert c_0\rvert \lvert c \rvert := \operatorname{dim}c c_0 0,"['functional-analysis', 'operator-theory', 'operator-algebras']"
90,Understanding the weak* topology on the space of distributions,Understanding the weak* topology on the space of distributions,,"I am studying distributions from Folland's book on real analysis. In this text he says A distribution on $U$ is a continuous linear functional on $C_C^\infty(U)$ (where $U$ is an open subset of $\mathbb{R}^n$ ). The space of all distributions on $U$ is denoted by $\mathcal{D}$ '(U). We impose the weak* topology on $\mathcal{D}'(U)$ , that is, the topology of pointwise convergence on $C_C^\infty(U)$ . I have been trying to better understand this topology and why we would impose this in the first place. Part of my troubles could be that I have not used the weak* topology much and so I am not too comfortable/experienced with it. To my knowledge, for a topological vector space $X$ , we look at the maps $\mathscr{X}_x \in X^{**}$ that are associated to some $x \in X$ defined as $\mathscr{X}_x(f) = f(x)$ for all $f \in X^*$ , and require all these maps to be continuous. This is the weak* topology. If this picture is correct, what interest is this topology in the context of distributions? Is it simply because it is weak enough to allow certain convergence results? Is there some better picture to have in mind?","I am studying distributions from Folland's book on real analysis. In this text he says A distribution on is a continuous linear functional on (where is an open subset of ). The space of all distributions on is denoted by '(U). We impose the weak* topology on , that is, the topology of pointwise convergence on . I have been trying to better understand this topology and why we would impose this in the first place. Part of my troubles could be that I have not used the weak* topology much and so I am not too comfortable/experienced with it. To my knowledge, for a topological vector space , we look at the maps that are associated to some defined as for all , and require all these maps to be continuous. This is the weak* topology. If this picture is correct, what interest is this topology in the context of distributions? Is it simply because it is weak enough to allow certain convergence results? Is there some better picture to have in mind?",U C_C^\infty(U) U \mathbb{R}^n U \mathcal{D} \mathcal{D}'(U) C_C^\infty(U) X \mathscr{X}_x \in X^{**} x \in X \mathscr{X}_x(f) = f(x) f \in X^*,"['real-analysis', 'functional-analysis', 'distribution-theory', 'topological-vector-spaces', 'duality-theorems']"
91,"Let $E$ be a Banach space, $p \in (1, \infty)$, and $L_p := L_{p}(X, \mu, E)$. Is $(L_p)^* \cong L_{p'}$ where $\frac{1}{p} + \frac{1}{p'} = 1$?","Let  be a Banach space, , and . Is  where ?","E p \in (1, \infty) L_p := L_{p}(X, \mu, E) (L_p)^* \cong L_{p'} \frac{1}{p} + \frac{1}{p'} = 1","Let $(X, \Sigma, \mu)$ be a $\sigma$ -finite measure space and $(E, |\cdot|)$ a Banach space. Here we use Bochner integral .  The space $L_p := L_{p}(X, \mu, E)$ consists of (equivalence classes of) all Bochner measurable functions $f$ with values in $E$ whose norm $|f|$ lies in the standard $L_{p}(X, \mu, \mathbb R_{\ge 0})$ space. A standard result is that if $E = \mathbb R$ and $p \in (1, \infty)$ then the continuous dual space $(L_p)^*$ of $L_p$ is indeed $L_{p'}$ where $\frac{1}{p} + \frac{1}{p'} = 1$ . One of the proof relies on the continuous linear operator $T:L_{p'} \to (L_p)^*$ defined by $$ \langle T u, f\rangle := \int_X u(x)f(x)\mathrm d \mu(x) \quad \forall u \in L_{p'}, \forall f \in L_{p}.  $$ Then $T$ is indeed a linear surjective isometry. However, I could not see how to use the same approach for a general Banach space $E$ . Is there such a linear surjective isometry $T$ in case $E$ is a general Banach space?","Let be a -finite measure space and a Banach space. Here we use Bochner integral .  The space consists of (equivalence classes of) all Bochner measurable functions with values in whose norm lies in the standard space. A standard result is that if and then the continuous dual space of is indeed where . One of the proof relies on the continuous linear operator defined by Then is indeed a linear surjective isometry. However, I could not see how to use the same approach for a general Banach space . Is there such a linear surjective isometry in case is a general Banach space?","(X, \Sigma, \mu) \sigma (E, |\cdot|) L_p := L_{p}(X, \mu, E) f E |f| L_{p}(X, \mu, \mathbb R_{\ge 0}) E = \mathbb R p \in (1, \infty) (L_p)^* L_p L_{p'} \frac{1}{p} + \frac{1}{p'} = 1 T:L_{p'} \to (L_p)^* 
\langle T u, f\rangle := \int_X u(x)f(x)\mathrm d \mu(x) \quad \forall u \in L_{p'}, \forall f \in L_{p}. 
 T E T E","['functional-analysis', 'banach-spaces', 'lp-spaces', 'dual-spaces', 'bochner-spaces']"
92,"What is the continuous version of ""diagonal matrix""?","What is the continuous version of ""diagonal matrix""?",,"A diagonal matrix has the nice property that its eigenvectors span the space it acts on. What if the space is infinite-dimensional? What would you call a diagonal operator? Does the space have to be a Hilbert space? Banach space? How can we think about a diagonal operator on, say, $L^2[0,1]$ ?","A diagonal matrix has the nice property that its eigenvectors span the space it acts on. What if the space is infinite-dimensional? What would you call a diagonal operator? Does the space have to be a Hilbert space? Banach space? How can we think about a diagonal operator on, say, ?","L^2[0,1]","['functional-analysis', 'functions', 'linear-transformations', 'operator-theory']"
93,"Why is ""isometric"" not part of ""isomorphism""?","Why is ""isometric"" not part of ""isomorphism""?",,"Suppose we have two normed/metric spaces $X$ and $Y$ and suppose $X$ and $Y$ are isometrically isomorphic meaning there exists an isomorphism $T: X \rightarrow Y$ which is also an isometry. This is the ""nicest"" map possible between these spaces. However, if one should think of an isomorphism in general as something that ""preserves structure"", why is isometry property not just contained in the definition of an isomorphism? Wouldn't one expect that distances is part of the structure of a set (with a distance function)? In Rudin's ""Functional Analysis"", he also writes ""isometric isomorphism"" when appropriate. So from I can tell this in the general notion? Can anyone help shed some light on this?","Suppose we have two normed/metric spaces and and suppose and are isometrically isomorphic meaning there exists an isomorphism which is also an isometry. This is the ""nicest"" map possible between these spaces. However, if one should think of an isomorphism in general as something that ""preserves structure"", why is isometry property not just contained in the definition of an isomorphism? Wouldn't one expect that distances is part of the structure of a set (with a distance function)? In Rudin's ""Functional Analysis"", he also writes ""isometric isomorphism"" when appropriate. So from I can tell this in the general notion? Can anyone help shed some light on this?",X Y X Y T: X \rightarrow Y,"['functional-analysis', 'terminology', 'isometry']"
94,Compact subset of banach space is dentable,Compact subset of banach space is dentable,,"Let $X$ be a real Banach Space and $K\subset X$ be compact. We've to show that $K$ is dentable. A bounded set $B$ of $X$ is said to be dentable if $\forall \epsilon>0$ , there exists $x_{\epsilon}\in B$ such that $x_{\epsilon}\not\in \overline{co}(B\setminus B(x_{\epsilon},\epsilon))$ I know two results- For compact $K$ , $\overline{co}(K)$ is compact. If $\overline{co}(B)$ is dentable implies $B$ is dentable. Using these two we can WLOG assume $K$ is compact and CONVEX . Then by Krein Milman Theorem , $\text{Ext}(K)\neq\emptyset$ and $K=\overline{co}(\text{Ext}(K))$ . (Here $\text{Ext}(K)$ denotes the set of all extreme points of $K$ ) So I pick $x_0\in\text{Ext}(K)$ . My intuition is this $x_0$ will serve our purpose for all $\epsilon>0$ i.e. $x_0\not\in \overline{co}(K\setminus B(x_0,\epsilon))$ . But I cannot prove that. Can anyone help me finish the argument? Thanks for your help in advance.","Let be a real Banach Space and be compact. We've to show that is dentable. A bounded set of is said to be dentable if , there exists such that I know two results- For compact , is compact. If is dentable implies is dentable. Using these two we can WLOG assume is compact and CONVEX . Then by Krein Milman Theorem , and . (Here denotes the set of all extreme points of ) So I pick . My intuition is this will serve our purpose for all i.e. . But I cannot prove that. Can anyone help me finish the argument? Thanks for your help in advance.","X K\subset X K B X \forall \epsilon>0 x_{\epsilon}\in B x_{\epsilon}\not\in \overline{co}(B\setminus B(x_{\epsilon},\epsilon)) K \overline{co}(K) \overline{co}(B) B K \text{Ext}(K)\neq\emptyset K=\overline{co}(\text{Ext}(K)) \text{Ext}(K) K x_0\in\text{Ext}(K) x_0 \epsilon>0 x_0\not\in \overline{co}(K\setminus B(x_0,\epsilon))","['functional-analysis', 'normed-spaces', 'banach-spaces', 'convex-hulls']"
95,How to show the norm of the difference of two pure state is 2?,How to show the norm of the difference of two pure state is 2?,,"Given two distinct pure state $\phi_1$ and $\phi_2$ in a commutative unital C $^*$ -algebra, how do we show $\|\phi_1-\phi_2\|=2$ ? Of course, we know the norm must be $\leq 2$ by the triangle inequality, so all we need to do is to find an element $a$ where $\|\phi_1(a)-\phi_2(a)\|=2$ . I tried doing this but unfortunately, we don't have much information on the norm of $\|\phi_1(a)-\phi_2(a)\|$ given some arbitrary $a$ . Most of the theorems I can currently use are for the converse: given some normal element $b$ , we know there exists a state $\omega$ where $\omega(b)=\|b\|$ . I could not find much of a way to use this though. Now I have previously proven that states are in fact multiplicative in a commutative unital C $^*$ -algebra, but I can't think of a good way to apply that. Another approach is just proof by contradiction and assumes as element $a$ where $||\phi_1(a)-\phi_2(a)||=2$ does not exist and show that either $\phi_1$ or $\phi_2$ is not a pure state which would imply their corresponding GNS representation is not irreducible so I tried to find an invariant subspace in their GNS representation. Now that also seemed too hard to do so I am still stuck.","Given two distinct pure state and in a commutative unital C -algebra, how do we show ? Of course, we know the norm must be by the triangle inequality, so all we need to do is to find an element where . I tried doing this but unfortunately, we don't have much information on the norm of given some arbitrary . Most of the theorems I can currently use are for the converse: given some normal element , we know there exists a state where . I could not find much of a way to use this though. Now I have previously proven that states are in fact multiplicative in a commutative unital C -algebra, but I can't think of a good way to apply that. Another approach is just proof by contradiction and assumes as element where does not exist and show that either or is not a pure state which would imply their corresponding GNS representation is not irreducible so I tried to find an invariant subspace in their GNS representation. Now that also seemed too hard to do so I am still stuck.",\phi_1 \phi_2 ^* \|\phi_1-\phi_2\|=2 \leq 2 a \|\phi_1(a)-\phi_2(a)\|=2 \|\phi_1(a)-\phi_2(a)\| a b \omega \omega(b)=\|b\| ^* a ||\phi_1(a)-\phi_2(a)||=2 \phi_1 \phi_2,"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
96,Continuity of polar decomposition,Continuity of polar decomposition,,"This question is about a step in the proof of this answer , which is not directly clear to me. Consider the following scenario: $H$ is a Hilbert space, $A\in GL(H)$ a positive self-adjoint operator. We surround the spectrum $\sigma(A)$ by a contour $\gamma$ which does not intersect $]-\infty, 0]$ . This allows to use the holomorphic functional calculus to define $\sqrt{A}$ . I would like to see that $\sqrt{\cdot}$ is continuous at $A$ . My problem is the following: If $B$ is sufficiently close to $A$ wrt $\|\cdot\|_{op}$ , how do we see that $\sigma(B)$ is still enclosed by $\gamma$ ? If we know this, we get the desired result simply by continuity of parameter integrals. I can't quite put the argument together. Intuitively it should be right, as the spectrum is compact, $\gamma$ encloses an open set, $GL(H)\subseteq (\mathcal L(H), \|\cdot\|_{op})$ is open, so everything seems nice and fitting. However, I struggle with pinning down the exact argument. Any suggestions?","This question is about a step in the proof of this answer , which is not directly clear to me. Consider the following scenario: is a Hilbert space, a positive self-adjoint operator. We surround the spectrum by a contour which does not intersect . This allows to use the holomorphic functional calculus to define . I would like to see that is continuous at . My problem is the following: If is sufficiently close to wrt , how do we see that is still enclosed by ? If we know this, we get the desired result simply by continuity of parameter integrals. I can't quite put the argument together. Intuitively it should be right, as the spectrum is compact, encloses an open set, is open, so everything seems nice and fitting. However, I struggle with pinning down the exact argument. Any suggestions?","H A\in GL(H) \sigma(A) \gamma ]-\infty, 0] \sqrt{A} \sqrt{\cdot} A B A \|\cdot\|_{op} \sigma(B) \gamma \gamma GL(H)\subseteq (\mathcal L(H), \|\cdot\|_{op})","['functional-analysis', 'continuity', 'spectral-theory', 'functional-calculus']"
97,The trace theorem for functions in $H^{1/2}(\Omega)$,The trace theorem for functions in,H^{1/2}(\Omega),"In my textbook, it said that we have the trace operator on Sobolev space like this: (Suppose $\Omega$ is a nice domain in $R^d$ ) \begin{equation*}    H^{s}(\Omega) \hookrightarrow H^{s-\frac{1}{2}}(\partial \Omega), \forall s > \frac{1}{2} \end{equation*} I'm wondering if it is still valid in the case $s = \frac{1}{2}$ , where we consider $H^0(\Omega)$ as $L^2(\Omega)$ . I think it will have counterexample for this one, while I can not find any. And I'm also looking for a proof of the following problem: \begin{equation*} \text{ There exists $C>0$ s.t. for any $f \in H^1(\Omega)$,we have }  \|f\|_{L^2(\partial \Omega)}^2 \leq C \|f\|_{L^2(\Omega)} \|f\|_{H^1(\Omega)} \end{equation*} This problem is related to the previous problem in the following sense: suppose the trace theorem holds for $s = \frac{1}{2}$ , then the left hand side is controlled by the $H^{1/2}$ norm, and the results can be proved by interpolation inequality on Sobolev Space.","In my textbook, it said that we have the trace operator on Sobolev space like this: (Suppose is a nice domain in ) I'm wondering if it is still valid in the case , where we consider as . I think it will have counterexample for this one, while I can not find any. And I'm also looking for a proof of the following problem: This problem is related to the previous problem in the following sense: suppose the trace theorem holds for , then the left hand side is controlled by the norm, and the results can be proved by interpolation inequality on Sobolev Space.","\Omega R^d \begin{equation*}
   H^{s}(\Omega) \hookrightarrow H^{s-\frac{1}{2}}(\partial \Omega), \forall s > \frac{1}{2}
\end{equation*} s = \frac{1}{2} H^0(\Omega) L^2(\Omega) \begin{equation*}
\text{
There exists C>0 s.t. for any f \in H^1(\Omega),we have }
 \|f\|_{L^2(\partial \Omega)}^2 \leq C \|f\|_{L^2(\Omega)} \|f\|_{H^1(\Omega)} \end{equation*} s = \frac{1}{2} H^{1/2}","['functional-analysis', 'inequality', 'sobolev-spaces', 'fractional-sobolev-spaces', 'trace-map']"
98,Why is this element invertible?,Why is this element invertible?,,"I'm reading through C* Algebras by Murphy, and the following theorem and proof is presented. Theorem: suppose that $a,b \in A^{+}$ (are positive elements) of a C* algebra A.  Then $a \leq b$ implies $a^{\frac{1}{2}} \leq b^{\frac{1}{2}}$ . Proof: we may suppose wlog that A is unital.  If we show that $a^2 \leq b^2$ implies $a \leq b$ then we're done. Let $t>0$ and Let $c,d $ be the real and imaginary hermitian parts of $(tI+b+a)(tI+b-a)$ for $I$ the unit of $A$ . It can be verified that $c \geq t^2I$ implying that $c$ is invertible and positive. Then $I+ic^{-\frac{1}{2}}dc^{-\frac{1}{2}}$ is invertible implying that $c+id$ is invertable. Hence $(tI+b-a)$ is left invertable and hence invertible since it's hermitian. Hence $t \notin \sigma(b-a)$ , implying that $a \leq b$ . My question, why is $I+ic^{-\frac{1}{2}}dc^{-\frac{1}{2}}$ invertible? I don't see how this follows from $c$ being positive and invertible whatsoever. If someone could explain that'd be great.","I'm reading through C* Algebras by Murphy, and the following theorem and proof is presented. Theorem: suppose that (are positive elements) of a C* algebra A.  Then implies . Proof: we may suppose wlog that A is unital.  If we show that implies then we're done. Let and Let be the real and imaginary hermitian parts of for the unit of . It can be verified that implying that is invertible and positive. Then is invertible implying that is invertable. Hence is left invertable and hence invertible since it's hermitian. Hence , implying that . My question, why is invertible? I don't see how this follows from being positive and invertible whatsoever. If someone could explain that'd be great.","a,b \in A^{+} a \leq b a^{\frac{1}{2}} \leq b^{\frac{1}{2}} a^2 \leq b^2 a \leq b t>0 c,d  (tI+b+a)(tI+b-a) I A c \geq t^2I c I+ic^{-\frac{1}{2}}dc^{-\frac{1}{2}} c+id (tI+b-a) t \notin \sigma(b-a) a \leq b I+ic^{-\frac{1}{2}}dc^{-\frac{1}{2}} c","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
99,Boundedness of an operator composed with a sequence of pseudo inverses,Boundedness of an operator composed with a sequence of pseudo inverses,,"I'm reading a paper and the following fact is given without proof, and I was hoping one of you smart folks could shed some light on it or provide a counter example: Consider an infinite dimensional separable Hilbert space $\mathcal{H}$ , and let $A$ and $L$ denote two linear, compact operators. Suppose further that $L$ is symmetric and positive definite, so that the spectral theorem gives $$ L(\cdot) = \sum_{\ell=1}^\infty \lambda_\ell \langle \phi_\ell,\cdot\rangle \phi_\ell.  $$ We define a pseudo-inverse of $L$ as $$ L^{-1}\pi_n(\cdot) = \sum_{\ell=1}^n \frac{ \langle \phi_\ell,\cdot\rangle}{\lambda_\ell} \phi_\ell. $$ ( $\pi_n$ is the projection onto the span of $\phi_1,...,\phi_n$ ). The claim in the paper is that if it is assumed that $$ \sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell} < \infty, $$ then $$ \sup_{n\ge 1} \|AL^{-1}\pi_n\|_{op} < \infty.  $$ $\|\cdot \|_{op}$ is the usual operator norm. I cannot see why this is true! The assumption seems to imply something about some sort of Trace norm of $AL^{-1}\pi_n$ , but if I try to work out what the Trace or Hilbert-Schmidt norms are of $AL^{-1}\pi_n$ , I get something like $$ \sum_{\ell=1}^n \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell^2}, $$ and assuming $\sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell^2} < \infty$ is evidently a much stronger condition. Am I missing something simple as to why the condition implies the operator norms are uniformly bounded?","I'm reading a paper and the following fact is given without proof, and I was hoping one of you smart folks could shed some light on it or provide a counter example: Consider an infinite dimensional separable Hilbert space , and let and denote two linear, compact operators. Suppose further that is symmetric and positive definite, so that the spectral theorem gives We define a pseudo-inverse of as ( is the projection onto the span of ). The claim in the paper is that if it is assumed that then is the usual operator norm. I cannot see why this is true! The assumption seems to imply something about some sort of Trace norm of , but if I try to work out what the Trace or Hilbert-Schmidt norms are of , I get something like and assuming is evidently a much stronger condition. Am I missing something simple as to why the condition implies the operator norms are uniformly bounded?","\mathcal{H} A L L 
L(\cdot) = \sum_{\ell=1}^\infty \lambda_\ell \langle \phi_\ell,\cdot\rangle \phi_\ell. 
 L 
L^{-1}\pi_n(\cdot) = \sum_{\ell=1}^n \frac{ \langle \phi_\ell,\cdot\rangle}{\lambda_\ell} \phi_\ell.
 \pi_n \phi_1,...,\phi_n 
\sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell} < \infty,
 
\sup_{n\ge 1} \|AL^{-1}\pi_n\|_{op} < \infty. 
 \|\cdot \|_{op} AL^{-1}\pi_n AL^{-1}\pi_n 
\sum_{\ell=1}^n \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell^2},
 \sum_{\ell=1}^\infty \frac{ \|A(\phi_{\ell})\|^2}{\lambda_\ell^2} < \infty","['real-analysis', 'linear-algebra', 'functional-analysis', 'operator-theory']"
