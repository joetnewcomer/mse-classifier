,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to determine whether or not a specified set is a smooth surface?,How to determine whether or not a specified set is a smooth surface?,,"I know that a given set $M$ is a smooth surface of dimension $k$ in $\mathbb{R}^n$ iff there's a map $r:U\rightarrow\mathbb{R}^n, U\subset \mathbb{R}^k$ is open such that $\forall a\in U, \text{rank}(D_r(a))=k$. How can I determine that a given set is a smooth surface if I am given the set as a level set of a function $\Phi:\mathbb{R}^n\rightarrow\mathbb{R}^{n-k}$? Must I find a parametrization of the set? For example, how can I tell if $M=\{(x,y,z)\in\mathbb{R}^3|z>y\geq0, x^2-y^2=0\}$ is a smooth surface? I was already given an answer to this one, but it remains unclear how to solve for a more general case. Specifically I would like to know how to tell if a given set is a smooth surface and if it's not a surface how can I prove otherwise, by which tools / theorems? Edited Progress I have gathered so far that in order to determine that a given set is a $k$-dimensional surface I must either: (a) find a parametrization of it (b) it's a graph of a function (c) it's a level set of a function. Furthermore, there is no algorithm to prove that a set is not a surface, I'd have to evaluate the set by the definition of a surface. Am I correct in this?","I know that a given set $M$ is a smooth surface of dimension $k$ in $\mathbb{R}^n$ iff there's a map $r:U\rightarrow\mathbb{R}^n, U\subset \mathbb{R}^k$ is open such that $\forall a\in U, \text{rank}(D_r(a))=k$. How can I determine that a given set is a smooth surface if I am given the set as a level set of a function $\Phi:\mathbb{R}^n\rightarrow\mathbb{R}^{n-k}$? Must I find a parametrization of the set? For example, how can I tell if $M=\{(x,y,z)\in\mathbb{R}^3|z>y\geq0, x^2-y^2=0\}$ is a smooth surface? I was already given an answer to this one, but it remains unclear how to solve for a more general case. Specifically I would like to know how to tell if a given set is a smooth surface and if it's not a surface how can I prove otherwise, by which tools / theorems? Edited Progress I have gathered so far that in order to determine that a given set is a $k$-dimensional surface I must either: (a) find a parametrization of it (b) it's a graph of a function (c) it's a level set of a function. Furthermore, there is no algorithm to prove that a set is not a surface, I'd have to evaluate the set by the definition of a surface. Am I correct in this?",,"['multivariable-calculus', 'surfaces']"
1,How to make a uniform grid of points in a curved space?,How to make a uniform grid of points in a curved space?,,"If a space has a differential volume element defined by: $d\Omega=\sin^2(\alpha)\sin(\theta)d\alpha d\theta d\phi$ And $\alpha \in [0,\pi/2]$, $\theta \in [0,\pi]$, and $\phi \in [0,2\pi]$ How can I make a regular grid of points over the space that is uniform with respect to the the differential volume element? I imagine a solution where I reparameterize the space in terms of, e.g., $u,v,w$, which are sampled uniformly. Then to get $\alpha,\theta,\phi$ I apply some transformation: $\alpha = f(u)$ $\theta = g(v)$ $\phi = h(w)$ or something like that.  How would I do this (i.e. find f, g, and h)?","If a space has a differential volume element defined by: $d\Omega=\sin^2(\alpha)\sin(\theta)d\alpha d\theta d\phi$ And $\alpha \in [0,\pi/2]$, $\theta \in [0,\pi]$, and $\phi \in [0,2\pi]$ How can I make a regular grid of points over the space that is uniform with respect to the the differential volume element? I imagine a solution where I reparameterize the space in terms of, e.g., $u,v,w$, which are sampled uniformly. Then to get $\alpha,\theta,\phi$ I apply some transformation: $\alpha = f(u)$ $\theta = g(v)$ $\phi = h(w)$ or something like that.  How would I do this (i.e. find f, g, and h)?",,"['differential-geometry', 'multivariable-calculus']"
2,gradient vector of composition of functions,gradient vector of composition of functions,,Let $U \subset \mathbb{R}^n$ be open and let $f:U \to \mathbb{R}$ and $h:\mathbb{R}\to \mathbb{R}$ be differentiable functions. How can I prove the following equation? $$\nabla{(h\circ f)}(P)=h'(f(P))\nabla f(P)$$,Let $U \subset \mathbb{R}^n$ be open and let $f:U \to \mathbb{R}$ and $h:\mathbb{R}\to \mathbb{R}$ be differentiable functions. How can I prove the following equation? $$\nabla{(h\circ f)}(P)=h'(f(P))\nabla f(P)$$,,['multivariable-calculus']
3,Notation for a certain kind of discrete measure,Notation for a certain kind of discrete measure,,"Suppose $\phi:\mathbb{R}^n \rightarrow \mathbb{R}$ is smooth, $Z=\{x: \phi(x)=0\}$ and $D\phi\neq0$ on $Z$. Is anyone familiar with use of the notation $dZ$ for the measure   $$\sum_{x \in Z} |D\phi(x)|\delta_x,$$ where $\delta_x$ is the Dirac measure at $x$? If so, can you explain it?","Suppose $\phi:\mathbb{R}^n \rightarrow \mathbb{R}$ is smooth, $Z=\{x: \phi(x)=0\}$ and $D\phi\neq0$ on $Z$. Is anyone familiar with use of the notation $dZ$ for the measure   $$\sum_{x \in Z} |D\phi(x)|\delta_x,$$ where $\delta_x$ is the Dirac measure at $x$? If so, can you explain it?",,"['calculus', 'measure-theory', 'multivariable-calculus']"
4,How to construct a vector space and compute basis?,How to construct a vector space and compute basis?,,"My professor demonstrated that in vector calculus that you can construct basis vectors for one, two, and three forms using the vectors $dx$, $dx$ and $dy$, as well as $dx \wedge dy$, $dy \wedge dz$, and $dx \wedge dz$...but he never explained the process thoroughly. I need help constructing a real vector space, but I don't know how. From his assignment: Define the real vector space $\bigwedge^p {\bf R}^n$ for all integers $p\geq 0$. Check that your definition agrees  for the cases $p=1, 2, 3$.  - 1 form, 2 form, and 3 forms in vector space. Compute the dimension of the vector space $\bigwedge^p {\bf R}^n$. For a set $E\subseteq {\bf R}^n$, define the set $\Omega^p (E)$ of $p$-forms defined on $E$. The problem is that I do not know what the omega sign and the bigwedge sign is. Could anyone please give me some hints so that I can do this by myself? I'm not hounding orders to anyone, I just need help from a different perspective.","My professor demonstrated that in vector calculus that you can construct basis vectors for one, two, and three forms using the vectors $dx$, $dx$ and $dy$, as well as $dx \wedge dy$, $dy \wedge dz$, and $dx \wedge dz$...but he never explained the process thoroughly. I need help constructing a real vector space, but I don't know how. From his assignment: Define the real vector space $\bigwedge^p {\bf R}^n$ for all integers $p\geq 0$. Check that your definition agrees  for the cases $p=1, 2, 3$.  - 1 form, 2 form, and 3 forms in vector space. Compute the dimension of the vector space $\bigwedge^p {\bf R}^n$. For a set $E\subseteq {\bf R}^n$, define the set $\Omega^p (E)$ of $p$-forms defined on $E$. The problem is that I do not know what the omega sign and the bigwedge sign is. Could anyone please give me some hints so that I can do this by myself? I'm not hounding orders to anyone, I just need help from a different perspective.",,"['linear-algebra', 'real-analysis', 'multivariable-calculus']"
5,"Vector identity $ (b \wedge a) = -(a \wedge b)$, when $a,b \in \mathbb{R}^3$","Vector identity , when"," (b \wedge a) = -(a \wedge b) a,b \in \mathbb{R}^3","I'm completely new with the sum notation and Levi-Civita-Symbols. Can somebody tell me if what I did was correct? Let $a,b \in \mathbb{R}^3$ . I want to prove $$ (b \wedge a) = -(a \wedge b), $$ so I did $$(b \wedge a)_i = \epsilon_{ijk}b_ja_k = - \epsilon_{ikj}b_ja_k = -\epsilon_{ikj}a_kb_j = - (a \wedge b)_i.$$",I'm completely new with the sum notation and Levi-Civita-Symbols. Can somebody tell me if what I did was correct? Let . I want to prove so I did,"a,b \in \mathbb{R}^3  (b \wedge a) = -(a \wedge b),  (b \wedge a)_i = \epsilon_{ijk}b_ja_k = - \epsilon_{ikj}b_ja_k = -\epsilon_{ikj}a_kb_j = - (a \wedge b)_i.","['multivariable-calculus', 'tensors']"
6,"Scale-agnostic, differentiable, co-planarity measure","Scale-agnostic, differentiable, co-planarity measure",,"I am looking for an (almost everywhere) differentiable function $f(p_1,p_2,p_3,p_4)$ that given four points will give me a scale-agnostic measure for co-planarity. It is zero if the four points lie on the same plane and positive otherwise. Scale-agnostic means that, when I uniformly scale all points the planarity measure will return the same. I came up with something that is quite complex and not easy to optimize. Define $u=p_2-p_1$, $v=p_3-p_1$, $w=p_4-p_1$. Then the planarity measure is: $$\frac{\left[(u \times v) \cdot w \right]^{2}}{\left(||u \times v||^{2} ||w||^{2} \right)}$$ The numerator is simply (the square of) the volume of the tetrahedron defined by the four points, and the denominator is a normalizing factor that makes this measure become simply the cosine of an angle. Because angles do not changed under uniform scale, this function satisfies all my requirements. Does anybody know of something simpler? Alex.","I am looking for an (almost everywhere) differentiable function $f(p_1,p_2,p_3,p_4)$ that given four points will give me a scale-agnostic measure for co-planarity. It is zero if the four points lie on the same plane and positive otherwise. Scale-agnostic means that, when I uniformly scale all points the planarity measure will return the same. I came up with something that is quite complex and not easy to optimize. Define $u=p_2-p_1$, $v=p_3-p_1$, $w=p_4-p_1$. Then the planarity measure is: $$\frac{\left[(u \times v) \cdot w \right]^{2}}{\left(||u \times v||^{2} ||w||^{2} \right)}$$ The numerator is simply (the square of) the volume of the tetrahedron defined by the four points, and the denominator is a normalizing factor that makes this measure become simply the cosine of an angle. Because angles do not changed under uniform scale, this function satisfies all my requirements. Does anybody know of something simpler? Alex.",,"['multivariable-calculus', '3d']"
7,"What do $âˆ‚ð‘§,âˆ‚ð‘¥$ and $âˆ‚ð‘¦$ individually mean?",What do  and  individually mean?,"âˆ‚ð‘§,âˆ‚ð‘¥ âˆ‚ð‘¦","So, I came up with this (weird) warning paragraph in my calc textbook : The symbol $âˆ‚z$ , unlike the differential $dz$ , has no meaning of it's own. For example if we were to ""cancel"" partial symbols in the chain-rule formula $\frac{\partial z}{\partial u}=\frac{\partial z}{\partial x}\frac{\partial x}{\partial u}+\frac{\partial z}{\partial y}\frac{\partial y}{\partial u}$ we would obtain: $\frac{\partial z}{\partial u}=\frac{\partial z}{\partial u}+\frac{\partial z}{\partial u}$ which is false in cases $\frac{\partial z}{\partial u}â‰ 0$ . I know that for variable $y$ dependent on $x$ in such a way that $y=f(x)$ we can say: $dx=âˆ†x$ and $dy=\lim_{âˆ†x\rightarrow0}âˆ†y$ . Analogously for the variable $z$ dependent on $x$ and $y$ in such a way that $z=f(x,y)$ can we say: $dx=âˆ†x,dy=âˆ†y$ and $dz=\lim_{(âˆ†x,âˆ†y)\rightarrow(0,0)}âˆ†z$ $??$ Are $âˆ‚x=dx,âˆ‚y=dy$ and $âˆ‚z=dz$ $??$ If they are not, what do $âˆ‚z,âˆ‚x$ and $âˆ‚y$ individually mean $?$ And what does the differential $dz$ expresses? [I am probably sounding like a dumb econ undergrad (which I am) so mind my lack of mathematical knowledge.]","So, I came up with this (weird) warning paragraph in my calc textbook : The symbol , unlike the differential , has no meaning of it's own. For example if we were to ""cancel"" partial symbols in the chain-rule formula we would obtain: which is false in cases . I know that for variable dependent on in such a way that we can say: and . Analogously for the variable dependent on and in such a way that can we say: and Are and If they are not, what do and individually mean And what does the differential expresses? [I am probably sounding like a dumb econ undergrad (which I am) so mind my lack of mathematical knowledge.]","âˆ‚z dz \frac{\partial z}{\partial u}=\frac{\partial z}{\partial x}\frac{\partial x}{\partial u}+\frac{\partial z}{\partial y}\frac{\partial y}{\partial u} \frac{\partial z}{\partial u}=\frac{\partial z}{\partial u}+\frac{\partial z}{\partial u} \frac{\partial z}{\partial u}â‰ 0 y x y=f(x) dx=âˆ†x dy=\lim_{âˆ†x\rightarrow0}âˆ†y z x y z=f(x,y) dx=âˆ†x,dy=âˆ†y dz=\lim_{(âˆ†x,âˆ†y)\rightarrow(0,0)}âˆ†z ?? âˆ‚x=dx,âˆ‚y=dy âˆ‚z=dz ?? âˆ‚z,âˆ‚x âˆ‚y ? dz","['multivariable-calculus', 'partial-differential-equations', 'partial-derivative']"
8,Find the volume of the region inside both the sphere $x^2+y^2+z^2=4$ and the cylinder $x^2+y^2=1$,Find the volume of the region inside both the sphere  and the cylinder,x^2+y^2+z^2=4 x^2+y^2=1,Find the volume of the region inside both the sphere $x^2+y^2+z^2=4$ and the cylinder $x^2+y^2=1$ $$2\int_0^{2\pi}\int_0^{\frac{\pi} 6}\int_0^{2}1.r^2\sin \varphi dr d\varphi d\theta + \int_0^{2\pi}\int_{\frac{\pi} 6}^{\frac{5\pi} 6}\int_0^{\frac 1 {\sin \varphi}}1.r^2\sin \varphi dr d\varphi d\theta $$ This question is in the lecture notes but I didn't understand how the answer is obtained. Could someone help?,Find the volume of the region inside both the sphere $x^2+y^2+z^2=4$ and the cylinder $x^2+y^2=1$ $$2\int_0^{2\pi}\int_0^{\frac{\pi} 6}\int_0^{2}1.r^2\sin \varphi dr d\varphi d\theta + \int_0^{2\pi}\int_{\frac{\pi} 6}^{\frac{5\pi} 6}\int_0^{\frac 1 {\sin \varphi}}1.r^2\sin \varphi dr d\varphi d\theta $$ This question is in the lecture notes but I didn't understand how the answer is obtained. Could someone help?,,"['integration', 'multivariable-calculus', 'volume', 'spherical-coordinates']"
9,How to solve trigonometric equations in 2 variables?,How to solve trigonometric equations in 2 variables?,,"Find out both $x$ and $y$ , $$\cos(x)=-\cos(x+y)$$ I come up with this equation when I was finding out maxima and minima of a two variable function $$f(x,y)=\sin x+\sin y+\sin (x+y);$$ however I get a solution by hit and trial approach, that is $$x=y={\pi\over 3}$$ will satisfy this equation, but how to solve it, as I have many other problems of the same kind and this hit and trial is time consuming.","Find out both and , I come up with this equation when I was finding out maxima and minima of a two variable function however I get a solution by hit and trial approach, that is will satisfy this equation, but how to solve it, as I have many other problems of the same kind and this hit and trial is time consuming.","x y \cos(x)=-\cos(x+y) f(x,y)=\sin x+\sin y+\sin (x+y); x=y={\pi\over 3}","['multivariable-calculus', 'differential']"
10,Show the locus of all points such that $x^2+y^2+z^2=1$ and $x^2-y^2-z=0$ is smooth (Implicit Function Theorem),Show the locus of all points such that  and  is smooth (Implicit Function Theorem),x^2+y^2+z^2=1 x^2-y^2-z=0,"Let $\mathcal C$ be the locus of all point $(x,y,z) \in \mathbb R^3$ with    $$x^2+y^2+z^2=1 \text{ and } x^2-y^2-z=0.$$   Show that $\mathcal C$ is a smooth curve in the following sense: For each point $p \in \mathcal C$, there exist open sets $U \subset \mathbb R$, $W \subset \mathbb R^3$ and a $\mathcal C^1$ map $f:U \to W$ such that $p \in W$ and $f(U)= \mathcal C \cap W$. My idea was to define a function $\Phi:\mathbb R^3 \to \mathbb R^2$ by $\Phi(x,y,z)=(x^2+y^2+z^2-1, x^2-y^2-z)$. Then $\Phi^{-1}(0)=\mathcal C$. Now I want to apply the Implicit Function Theorem but I run into a problem: Let $\phi_1$ and $\phi_2$ denote the coordinate functions of $\Phi$. Then $$\det \begin{bmatrix} \frac{\partial \phi_1}{\partial y} & \frac{\partial \phi_1}{\partial z} \\ \frac{\partial \phi_2}{\partial y} & \frac{\partial \phi_2}{\partial z} \end{bmatrix} = \det \begin{bmatrix} 2y & 2z \\ -2y & -1 \end{bmatrix} = 4yz-2y = 2y(2z-1). $$ So my determinant is zero when $y=0$ and when $z=\frac{1}{2}$ and I can't apply the Implicit Function Theorem at those points. I think there might be a way to use the Implicit Function Theorem twice to get two functions $g,h: \mathbb R \to \mathbb R$ such that $\Phi(x,g(x),h(x)) = 0$. Then I would be able to define $f:\mathbb R \to \mathbb R^3$ by $f(x) = (x, g(x), h(x))$. Is this possible? Or do I need to change my function $\Phi$?","Let $\mathcal C$ be the locus of all point $(x,y,z) \in \mathbb R^3$ with    $$x^2+y^2+z^2=1 \text{ and } x^2-y^2-z=0.$$   Show that $\mathcal C$ is a smooth curve in the following sense: For each point $p \in \mathcal C$, there exist open sets $U \subset \mathbb R$, $W \subset \mathbb R^3$ and a $\mathcal C^1$ map $f:U \to W$ such that $p \in W$ and $f(U)= \mathcal C \cap W$. My idea was to define a function $\Phi:\mathbb R^3 \to \mathbb R^2$ by $\Phi(x,y,z)=(x^2+y^2+z^2-1, x^2-y^2-z)$. Then $\Phi^{-1}(0)=\mathcal C$. Now I want to apply the Implicit Function Theorem but I run into a problem: Let $\phi_1$ and $\phi_2$ denote the coordinate functions of $\Phi$. Then $$\det \begin{bmatrix} \frac{\partial \phi_1}{\partial y} & \frac{\partial \phi_1}{\partial z} \\ \frac{\partial \phi_2}{\partial y} & \frac{\partial \phi_2}{\partial z} \end{bmatrix} = \det \begin{bmatrix} 2y & 2z \\ -2y & -1 \end{bmatrix} = 4yz-2y = 2y(2z-1). $$ So my determinant is zero when $y=0$ and when $z=\frac{1}{2}$ and I can't apply the Implicit Function Theorem at those points. I think there might be a way to use the Implicit Function Theorem twice to get two functions $g,h: \mathbb R \to \mathbb R$ such that $\Phi(x,g(x),h(x)) = 0$. Then I would be able to define $f:\mathbb R \to \mathbb R^3$ by $f(x) = (x, g(x), h(x))$. Is this possible? Or do I need to change my function $\Phi$?",,"['real-analysis', 'multivariable-calculus', 'implicit-function-theorem']"
11,Mean Value Theorem for Several Variables,Mean Value Theorem for Several Variables,,"Please see the mean value theorem stated here: MVT . Note that the MVT stated there requires that the segment connecting $x$ and $y$ lies in $G$. So clearly, MVT works for any pair of points if $G$ is made a convex open set. Here are my questions: What happens if $G$ is not convex, but connected? Looking at the proof of MVT, I think the MVT will still work as long as there is a path (a continuous map) from $x$ to $y$. And this is the case in a connected set. Am I right in thinking this? Suppose the answer to (1) is yes. (Of course, if I am wrong in (1), please ignore this question.)Assume that $G$ is open and connected and let $x,y \in G$. Then there is some path (not necessarily a line segment) connecting $x$ and $y$ in $G$. MVT guarantees that there is a $z$ on this path such that  $$f(x) - f(y) = \nabla f(z) \cdot (x - y).$$ Can we say something about the distance between $z$ and the points $x$,$y$? If the path is a line segment, then certainly, $$|x-z|\leq |x-y| \quad \text{and} \quad |y-z| \leq |x-y|.$$ If the path is not a line segment, what happens?","Please see the mean value theorem stated here: MVT . Note that the MVT stated there requires that the segment connecting $x$ and $y$ lies in $G$. So clearly, MVT works for any pair of points if $G$ is made a convex open set. Here are my questions: What happens if $G$ is not convex, but connected? Looking at the proof of MVT, I think the MVT will still work as long as there is a path (a continuous map) from $x$ to $y$. And this is the case in a connected set. Am I right in thinking this? Suppose the answer to (1) is yes. (Of course, if I am wrong in (1), please ignore this question.)Assume that $G$ is open and connected and let $x,y \in G$. Then there is some path (not necessarily a line segment) connecting $x$ and $y$ in $G$. MVT guarantees that there is a $z$ on this path such that  $$f(x) - f(y) = \nabla f(z) \cdot (x - y).$$ Can we say something about the distance between $z$ and the points $x$,$y$? If the path is a line segment, then certainly, $$|x-z|\leq |x-y| \quad \text{and} \quad |y-z| \leq |x-y|.$$ If the path is not a line segment, what happens?",,"['calculus', 'multivariable-calculus', 'connectedness']"
12,"help with $\lim\limits_{(x,y) \to (0,0)} f(x,y) = {\cos(x) -1 - {x^2/2} \over x^4 + y^4}$",help with,"\lim\limits_{(x,y) \to (0,0)} f(x,y) = {\cos(x) -1 - {x^2/2} \over x^4 + y^4}","$\lim\limits_{(x,y) \to (0,0)} f(x,y) = \dfrac{\cos(x) -1 - {x^2 \over 2}}{x^4 + y^4}$ Is the following approach correct? If we approach the origin from $y$ , that is $x = 0$: $\lim\limits_{(x=0,y) \to (0,0)} f(0,y) = {0 \over y^4} = 0$ Now we approach the origin from $x$ and use $\cos(x) \sim_{0} 1 - {x^2\over 2}$ $\lim\limits_{(x,y=0) \to (0,0)} f(0,y) = { -x^2 \over x^4} =- {1 \over x^2}=-\infty$ Then we can conclude that the limit does not exist. My teacher took another approach where he uses the $\cos (2x)$ formula and ends up using $\lim\limits_{u\to0}\dfrac{\sin u}{u}=1$ so I'm wondering if my solution is OK or not.","$\lim\limits_{(x,y) \to (0,0)} f(x,y) = \dfrac{\cos(x) -1 - {x^2 \over 2}}{x^4 + y^4}$ Is the following approach correct? If we approach the origin from $y$ , that is $x = 0$: $\lim\limits_{(x=0,y) \to (0,0)} f(0,y) = {0 \over y^4} = 0$ Now we approach the origin from $x$ and use $\cos(x) \sim_{0} 1 - {x^2\over 2}$ $\lim\limits_{(x,y=0) \to (0,0)} f(0,y) = { -x^2 \over x^4} =- {1 \over x^2}=-\infty$ Then we can conclude that the limit does not exist. My teacher took another approach where he uses the $\cos (2x)$ formula and ends up using $\lim\limits_{u\to0}\dfrac{\sin u}{u}=1$ so I'm wondering if my solution is OK or not.",,"['limits', 'multivariable-calculus']"
13,How to solve $\frac{\partial^2\Psi}{\partial x^2} + \frac{x^2}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t}$?,How to solve ?,\frac{\partial^2\Psi}{\partial x^2} + \frac{x^2}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t},"Is there a solution using $\Psi(x,t)$ such that $$\frac{\partial^2\Psi}{\partial x^2} + \frac{x^2}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t}$$ ? This is a follow-up question to this question which solves $\frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t}$ using separation of variables method $\Psi = X(x)T(t)$ . Unfortunately, the separation of variables method does not seem to work for solving this modified form of $\frac{x^2}{1+t^2}\Psi$ ?","Is there a solution using such that ? This is a follow-up question to this question which solves using separation of variables method . Unfortunately, the separation of variables method does not seem to work for solving this modified form of ?","\Psi(x,t) \frac{\partial^2\Psi}{\partial x^2} + \frac{x^2}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t} \frac{\partial^2\Psi}{\partial x^2} + \frac{1}{1+t^2}\Psi = \frac{\partial \Psi}{\partial t} \Psi = X(x)T(t) \frac{x^2}{1+t^2}\Psi","['multivariable-calculus', 'partial-differential-equations', 'quantum-mechanics']"
14,Partial derivative of $\sin(xz)$: Is this making sense and is it a proper use of notation?,Partial derivative of : Is this making sense and is it a proper use of notation?,\sin(xz),"The exercise here is to calculate $\dfrac{\partial}{\partial x} \sin(xz)$ The usual way is just considering $z$ as a constant and deriving, so it would be $z\cos(xz)$ . However, I want to solve it this way: Define $a=xz$ , then $\sin(a) = \sin(xz)$ $\dfrac{\partial}{\partial x} \sin(a) = \dfrac{\partial}{\partial a} \sin(a) \dfrac{\partial}{\partial x} xz = z\cos(a) = z\cos(xz)$ . Is this second way correct? My friend said it is not making sense and not a proper use of notation. But I do not understant why...","The exercise here is to calculate The usual way is just considering as a constant and deriving, so it would be . However, I want to solve it this way: Define , then . Is this second way correct? My friend said it is not making sense and not a proper use of notation. But I do not understant why...",\dfrac{\partial}{\partial x} \sin(xz) z z\cos(xz) a=xz \sin(a) = \sin(xz) \dfrac{\partial}{\partial x} \sin(a) = \dfrac{\partial}{\partial a} \sin(a) \dfrac{\partial}{\partial x} xz = z\cos(a) = z\cos(xz),['calculus']
15,Calculating the max and min of $\sin(x)+\sin(y)+\sin(z)$,Calculating the max and min of,\sin(x)+\sin(y)+\sin(z),"I took the partial derivatives of $\sin(x)+\sin(y)+\sin(z)$ and it didn't work out, so I am trying to use Lagrange's method (with the constraint: $x+y+z=\pi$)... I am not sure how to set this up. EDIT: while I appreciate other approaches, if someone could direct me towards using the Lagrange's method it would help me learn how to use that method as well :)","I took the partial derivatives of $\sin(x)+\sin(y)+\sin(z)$ and it didn't work out, so I am trying to use Lagrange's method (with the constraint: $x+y+z=\pi$)... I am not sure how to set this up. EDIT: while I appreciate other approaches, if someone could direct me towards using the Lagrange's method it would help me learn how to use that method as well :)",,"['multivariable-calculus', 'optimization']"
16,Can we determine the injectivity of a map $\mathbb{R}^n \rightarrow \mathbb{R}^n$ on subset of $\mathbb{R}^n$ by looking at the Jacobian?,Can we determine the injectivity of a map  on subset of  by looking at the Jacobian?,\mathbb{R}^n \rightarrow \mathbb{R}^n \mathbb{R}^n,"Specifically, I'm looking for an analogue of the following theorem in the case of real functions: Let $f: A \subset \mathbb{R} \rightarrow \mathbb{R}$ be monotone on $A$, then $f$ is injective on $A$. My question is, given a differentiable function $F : \mathbb{R}^n \rightarrow \mathbb{R}^n$, is there a similar theorem we could state in terms of the sign of the Jacobian, and possibly some other simple topological restrictions on the set $A$? The inverse function theorem doesn't work for me, as I am wondering about the injectivity on a specific set $A$, not just on some neighborhood of a point.","Specifically, I'm looking for an analogue of the following theorem in the case of real functions: Let $f: A \subset \mathbb{R} \rightarrow \mathbb{R}$ be monotone on $A$, then $f$ is injective on $A$. My question is, given a differentiable function $F : \mathbb{R}^n \rightarrow \mathbb{R}^n$, is there a similar theorem we could state in terms of the sign of the Jacobian, and possibly some other simple topological restrictions on the set $A$? The inverse function theorem doesn't work for me, as I am wondering about the injectivity on a specific set $A$, not just on some neighborhood of a point.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
17,inequality $\frac{2(x + y)^2}{2x^2 + y^2} \leq 3$,inequality,\frac{2(x + y)^2}{2x^2 + y^2} \leq 3,"I'm looking for a ""nice"" way to show that the following inequality holds, i.e. without differentiating and determining the maximum: $$ \frac{2(x + y)^2}{2x^2+ y^2} \leq 3 \quad \forall x,y \in \mathbb{R} $$ It's rather easy to show $$ \frac{4xy}{x^2 + y^2} \le 2 $$ and obviously $$ \frac{2x^2 + 2y^2}{2x^2+y^2} \le 2 $$ but combining these two does not give me a sufficient low bound.","I'm looking for a ""nice"" way to show that the following inequality holds, i.e. without differentiating and determining the maximum: It's rather easy to show and obviously but combining these two does not give me a sufficient low bound.","
\frac{2(x + y)^2}{2x^2+ y^2} \leq 3 \quad \forall x,y \in \mathbb{R}
 
\frac{4xy}{x^2 + y^2} \le 2
 
\frac{2x^2 + 2y^2}{2x^2+y^2} \le 2
","['calculus', 'algebra-precalculus', 'multivariable-calculus', 'inequality']"
18,"Proving $ \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0$",Proving," \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0","I'm unable to prove that $$ \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0$$ I tried with polar coordinates but I'm unable to reach a function that depends only on $\rho$ $$0\le\frac{\rho^3\cos^3(\theta)\sin(\theta)}{\rho^2\cos^2(\theta)+|\rho\sin(\theta)|}=\frac{\rho^2\cos^3(\theta)\sin(\theta)}{\rho\cos^2(\theta)+|\sin(\theta)|}\leq \dots ?$$",I'm unable to prove that I tried with polar coordinates but I'm unable to reach a function that depends only on," \lim_{(x,y) \to (0,0)} \frac{x^2y}{x^2+|y|}=0 \rho 0\le\frac{\rho^3\cos^3(\theta)\sin(\theta)}{\rho^2\cos^2(\theta)+|\rho\sin(\theta)|}=\frac{\rho^2\cos^3(\theta)\sin(\theta)}{\rho\cos^2(\theta)+|\sin(\theta)|}\leq \dots ?","['calculus', 'limits', 'multivariable-calculus', 'proof-verification']"
19,"Evaluate $\int_0^{\infty}\int_0^{\infty}e^{-x^2-2xy-y^2}\,dx\,dy$",Evaluate,"\int_0^{\infty}\int_0^{\infty}e^{-x^2-2xy-y^2}\,dx\,dy","I would like to compute the following, $$ \int_0^{\infty}\int_0^{\infty}e^{-x^2-2xy-y^2}\ dx\,dy $$ It is obvious that we can rewrite the integral above to, $$ \int_0^{\infty}\int_0^{\infty}e^{-(x+y)^2}\ dx\,dy $$ so we are ending up with something looking like a gaussian integral. I think that a smart substitution would help but all I tried ended up to be something I am not able to compute... I really would appreciate any hint. Thanks in advance!","I would like to compute the following, $$ \int_0^{\infty}\int_0^{\infty}e^{-x^2-2xy-y^2}\ dx\,dy $$ It is obvious that we can rewrite the integral above to, $$ \int_0^{\infty}\int_0^{\infty}e^{-(x+y)^2}\ dx\,dy $$ so we are ending up with something looking like a gaussian integral. I think that a smart substitution would help but all I tried ended up to be something I am not able to compute... I really would appreciate any hint. Thanks in advance!",,"['real-analysis', 'integration', 'multivariable-calculus', 'definite-integrals', 'improper-integrals']"
20,"Any solution for $\iiint\frac{x^2+2y^2}{x^2+4y^2+z^2}\,dv$",Any solution for,"\iiint\frac{x^2+2y^2}{x^2+4y^2+z^2}\,dv","I tried to solve this triple integral but couldn't integrate the result. $$\iiint\frac{x^2+2y^2}{x^2+4y^2+z^2}\,dv$$ and the surface to integrate in is $$x^2+y^2+z^2\le1$$ Is there any way to transform the integral into polar coordinates?",I tried to solve this triple integral but couldn't integrate the result. and the surface to integrate in is Is there any way to transform the integral into polar coordinates?,"\iiint\frac{x^2+2y^2}{x^2+4y^2+z^2}\,dv x^2+y^2+z^2\le1","['integration', 'multivariable-calculus', 'multiple-integral']"
21,Derivation of divergence in spherical coordinates from the divergence theorem,Derivation of divergence in spherical coordinates from the divergence theorem,,"I'm trying to find the expression of the divergence of a vector field $\vec{E}$ in spherical coordinates from the theorem : $$\iint_{S(V)}(\vec{E}.\vec{n})dS = \iiint_{V}div(\vec{E})dV$$ but if I write $\vec{E}$ in spherical coordinates: $$\vec{E} = E_r\vec{e_r}+E_{\phi}\vec{e_{\phi}}+E_{\theta}\vec{e_{\theta}}$$ and if I consider a spherical volume and its surface, I find that $\vec{n} = \vec{e_r}$ since $\vec{n}$ is orthogonal to the spherical surface at any point... So I'm left with $(\vec{E}.\vec{n})  = E_r$ and $$\iint_{S(V)}E_rdS = \iiint_{V}div(\vec{E})dV$$ I don't understand how I'm supposed to get to  $$div(\vec{E}) = \frac{1}{r^2}\frac{\partial (r^2 E_r)}{\partial r} + \frac{1}{r sin\theta}\frac{\partial E_\phi}{\partial\phi}+\frac{1}{r sin\theta}\frac{\partial(sin\theta E_{\theta})}{\partial \theta}$$","I'm trying to find the expression of the divergence of a vector field $\vec{E}$ in spherical coordinates from the theorem : $$\iint_{S(V)}(\vec{E}.\vec{n})dS = \iiint_{V}div(\vec{E})dV$$ but if I write $\vec{E}$ in spherical coordinates: $$\vec{E} = E_r\vec{e_r}+E_{\phi}\vec{e_{\phi}}+E_{\theta}\vec{e_{\theta}}$$ and if I consider a spherical volume and its surface, I find that $\vec{n} = \vec{e_r}$ since $\vec{n}$ is orthogonal to the spherical surface at any point... So I'm left with $(\vec{E}.\vec{n})  = E_r$ and $$\iint_{S(V)}E_rdS = \iiint_{V}div(\vec{E})dV$$ I don't understand how I'm supposed to get to  $$div(\vec{E}) = \frac{1}{r^2}\frac{\partial (r^2 E_r)}{\partial r} + \frac{1}{r sin\theta}\frac{\partial E_\phi}{\partial\phi}+\frac{1}{r sin\theta}\frac{\partial(sin\theta E_{\theta})}{\partial \theta}$$",,"['multivariable-calculus', 'vector-analysis']"
22,Prove that the product of sines of angles of a triangle is min if it is equilateral,Prove that the product of sines of angles of a triangle is min if it is equilateral,,"I was solving problems about extreme values and conditional extrema , I encounter this problem : Prove that the product of the sines of the three angles in a triangle is  minimum if the triangle is equilateral . I started by writing the objective function and differentiating it to find the critical points but I do not know how to complete the solution. $$F(x,y,z)=sin(x)sin(y)sin(z)$$ then  $$F_x= cos(x)sin(y)sin(z)=0$$ hence $$x=(2n+1)\pi/2 \ \ ,\ \  y=n\pi \ \ ,\ \  z=n\pi$$ where $$n=0,\pm1,\pm2,...$$ Similarly $$F_y=0$$ gives $$x=n\pi\ \ ,\ \  y=(2n+1)\pi/2  \ \ ,\ \  z=n\pi$$ Finally $$F_z=0$$ gives $$x=n\pi \ \ ,\ \  y=n\pi \ \ ,\ \  z=(2n+1)\pi/2 $$","I was solving problems about extreme values and conditional extrema , I encounter this problem : Prove that the product of the sines of the three angles in a triangle is  minimum if the triangle is equilateral . I started by writing the objective function and differentiating it to find the critical points but I do not know how to complete the solution. $$F(x,y,z)=sin(x)sin(y)sin(z)$$ then  $$F_x= cos(x)sin(y)sin(z)=0$$ hence $$x=(2n+1)\pi/2 \ \ ,\ \  y=n\pi \ \ ,\ \  z=n\pi$$ where $$n=0,\pm1,\pm2,...$$ Similarly $$F_y=0$$ gives $$x=n\pi\ \ ,\ \  y=(2n+1)\pi/2  \ \ ,\ \  z=n\pi$$ Finally $$F_z=0$$ gives $$x=n\pi \ \ ,\ \  y=n\pi \ \ ,\ \  z=(2n+1)\pi/2 $$",,"['multivariable-calculus', 'triangles', 'lagrange-multiplier']"
23,Maxima of $\sin(nx)/\sin(x)$,Maxima of,\sin(nx)/\sin(x),"I was wondering if there is an analytical solution to find the maxima of the following function in terms of $x$: $$ f(x) = \frac{\sin(nx)}{\sin(x)} $$ where $n$ is any positive integer greater than $0$ I tried equating the partial derivative of $f(x)$ with respect to $x$ to $0$, but I can't seem to find any other solution than $x = \pi k$ to the resulting trigonometric equation. I was also not able to find a solution in existing posts.","I was wondering if there is an analytical solution to find the maxima of the following function in terms of $x$: $$ f(x) = \frac{\sin(nx)}{\sin(x)} $$ where $n$ is any positive integer greater than $0$ I tried equating the partial derivative of $f(x)$ with respect to $x$ to $0$, but I can't seem to find any other solution than $x = \pi k$ to the resulting trigonometric equation. I was also not able to find a solution in existing posts.",,"['calculus', 'multivariable-calculus']"
24,Evaluating $\int_{\Omega}\frac{e^{x^2}}{e^{x^2} + e^{y^2}}dxdy $,Evaluating,\int_{\Omega}\frac{e^{x^2}}{e^{x^2} + e^{y^2}}dxdy ,"Title says it all. I want to calculate $\int_{\Omega}\frac{e^{x^2}}{e^{x^2} + e^{y^2}}dxdy$ where $\Omega = [-1, 1]^2$. It seems to defy all integration techniques. The function $e^{x^2}$ does not have a standard anti-derivative, so how do we calculate this integral?","Title says it all. I want to calculate $\int_{\Omega}\frac{e^{x^2}}{e^{x^2} + e^{y^2}}dxdy$ where $\Omega = [-1, 1]^2$. It seems to defy all integration techniques. The function $e^{x^2}$ does not have a standard anti-derivative, so how do we calculate this integral?",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
25,"Show that limit of $\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0$ as $(x,y) \to (0,0)$",Show that limit of  as,"\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0 (x,y) \to (0,0)","I'm asked to show that the limit of $\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0$ as $(x,y) \to (0,0)$. I guess the easiest way to do this would be by converting to polar form, so this is what I did: $$\frac{\sin(xy)}{\sqrt{x^2+y^2}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2\cos^2\theta+r^2\sin^2\theta}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2(\cos^2\theta+\sin^2\theta)}} = \frac{\sin(r^2\cos\theta \sin\theta)}{r}$$ from here I guess I should try to prove using the definition, so I did the following: since we know L is $0$ $$\left|\frac{\sin(r^2\cos\theta \sin\theta)}{r} - 0\right| = \left|\frac{\sin(r^2\cos\theta \sin\theta)}{r}\right| \leq \left| \frac{1}{r} \right| = \frac{1}{r}$$ which is true because $sin$ is bounded by $0$ and $1$, and $r$ is always a positive value.  I also know that, since we are using polar coordinates, the distance between $(0,0)$ and $(x,y)$ is $r$. But I'm stuck here, I don't really know where to go from this. I guess I'm not getting the strategy behind the definition? I think I'm pretty close to the answer, so feel free to give me the last steps if there's little to be done, it won't spoil the fun for me :)","I'm asked to show that the limit of $\frac{\sin(xy)}{\sqrt{x^2+y^2}} = 0$ as $(x,y) \to (0,0)$. I guess the easiest way to do this would be by converting to polar form, so this is what I did: $$\frac{\sin(xy)}{\sqrt{x^2+y^2}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2\cos^2\theta+r^2\sin^2\theta}} = \frac{\sin(r^2\cos\theta \sin\theta)}{\sqrt{r^2(\cos^2\theta+\sin^2\theta)}} = \frac{\sin(r^2\cos\theta \sin\theta)}{r}$$ from here I guess I should try to prove using the definition, so I did the following: since we know L is $0$ $$\left|\frac{\sin(r^2\cos\theta \sin\theta)}{r} - 0\right| = \left|\frac{\sin(r^2\cos\theta \sin\theta)}{r}\right| \leq \left| \frac{1}{r} \right| = \frac{1}{r}$$ which is true because $sin$ is bounded by $0$ and $1$, and $r$ is always a positive value.  I also know that, since we are using polar coordinates, the distance between $(0,0)$ and $(x,y)$ is $r$. But I'm stuck here, I don't really know where to go from this. I guess I'm not getting the strategy behind the definition? I think I'm pretty close to the answer, so feel free to give me the last steps if there's little to be done, it won't spoil the fun for me :)",,"['calculus', 'limits', 'multivariable-calculus']"
26,"How do I calculate an integral like $\oint \vec{E}^{\,} \cdot \vec{dA}^{\,}$?",How do I calculate an integral like ?,"\oint \vec{E}^{\,} \cdot \vec{dA}^{\,}","$$\oint \vec{E}^{\,} \cdot \vec{dA}^{\,}$$ This is Gauss' law from physics but my question is more maths related. Say I have $\vec{E}^{\,}=3.5\times 10^3N/C\times e_x$ and $A = 0,35\times0,70m^2$ . The plane that has that area, where the electric field $E$ is applied, is parallel to $YZ$ . So it has a coordinate in $e_x$ . Right? What does the circle in the integral mean in practice? What is the value of $dA$ ? Why is it a vector? How do I solve this integral?","This is Gauss' law from physics but my question is more maths related. Say I have and . The plane that has that area, where the electric field is applied, is parallel to . So it has a coordinate in . Right? What does the circle in the integral mean in practice? What is the value of ? Why is it a vector? How do I solve this integral?","\oint \vec{E}^{\,} \cdot \vec{dA}^{\,} \vec{E}^{\,}=3.5\times 10^3N/C\times e_x A = 0,35\times0,70m^2 E YZ e_x dA","['integration', 'multivariable-calculus', 'vector-analysis', 'physics', 'multiple-integral']"
27,"Does the function $d(x,y)= \frac{\lvert x-y\rvert} {1+{\lvert x-y\rvert}}$ define a metric on $\mathbb{R}^n?$",Does the function  define a metric on,"d(x,y)= \frac{\lvert x-y\rvert} {1+{\lvert x-y\rvert}} \mathbb{R}^n?","Does the function $d: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ given by:  $$d(x,y)= \frac{\lvert x-y\rvert} {1+{\lvert x-y\rvert}}$$ define a metric on $\mathbb{R}^n?$ How do you go about proving this? Do I need to just show that it satisfies the three conditions to be a metric? If so how do I show them?","Does the function $d: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$ given by:  $$d(x,y)= \frac{\lvert x-y\rvert} {1+{\lvert x-y\rvert}}$$ define a metric on $\mathbb{R}^n?$ How do you go about proving this? Do I need to just show that it satisfies the three conditions to be a metric? If so how do I show them?",,"['real-analysis', 'multivariable-calculus', 'metric-spaces']"
28,Nowhere $0$ form on the sphere?,Nowhere  form on the sphere?,0,"Consider the differential form on $\mathbb R^3$ given by $ x dy \wedge dz + y dz \wedge dx + z dx \wedge dy$. I converted this to spherical coordinates using a laborious calculation, and when I'm done, by some miracle (which would be cool if someone could explain exactly how that works), I get something really compact and elegant: $\rho^3 \sin \phi d\phi \wedge d\theta$. If we call this form $\Omega$, my task is to compute $i^*\Omega,$ where $i$ represents the inclusion from $\mathbb S^2 \rightarrow \mathbb R^3$, which seems to be pretty easy also - on the unit sphere we just have $\rho = 1$. Now why is this nowhere $0$ on the sphere? It looks like it's $0$ along the half plane where $\phi = 0$!","Consider the differential form on $\mathbb R^3$ given by $ x dy \wedge dz + y dz \wedge dx + z dx \wedge dy$. I converted this to spherical coordinates using a laborious calculation, and when I'm done, by some miracle (which would be cool if someone could explain exactly how that works), I get something really compact and elegant: $\rho^3 \sin \phi d\phi \wedge d\theta$. If we call this form $\Omega$, my task is to compute $i^*\Omega,$ where $i$ represents the inclusion from $\mathbb S^2 \rightarrow \mathbb R^3$, which seems to be pretty easy also - on the unit sphere we just have $\rho = 1$. Now why is this nowhere $0$ on the sphere? It looks like it's $0$ along the half plane where $\phi = 0$!",,"['multivariable-calculus', 'differential-geometry', 'differential-forms']"
29,Finding multivariable limits for the function $\frac{3x^2y}{x^2+y^2}$,Finding multivariable limits for the function,\frac{3x^2y}{x^2+y^2},"Could anyone help me with this Find $$\lim_{(x,y) \to (0,0)} \frac{3x^2y}{x^2+y^2}$$ if this limit exists I tried using the squeeze theorem, but I could not find a suitable expression for the squeeze theorem as I could not find any number that allow me to squeeze the limit in between and cancel the denominator","Could anyone help me with this Find $$\lim_{(x,y) \to (0,0)} \frac{3x^2y}{x^2+y^2}$$ if this limit exists I tried using the squeeze theorem, but I could not find a suitable expression for the squeeze theorem as I could not find any number that allow me to squeeze the limit in between and cancel the denominator",,"['limits', 'multivariable-calculus']"
30,Prove that the gradient of a unit vector equals 2/magnitude of the vector,Prove that the gradient of a unit vector equals 2/magnitude of the vector,,"Let $\vec r=(x,y,z)$ Firstly find $\vec \nabla (\frac 1 r)$ where r is the magnitude of $\vec r$. I think I've done this correctly to get $-x(x^2+y^2+z^2)^{-\frac32} \hat i-y(x^2+y^2+z^2)^{-\frac32} \hat j-z(x^2+y^2+z^2)^{-\frac32} \hat k$ Secondly prove that $\vec \nabla. \frac{\vec r}{r}=\frac2r$ I've really got no idea for the second part.","Let $\vec r=(x,y,z)$ Firstly find $\vec \nabla (\frac 1 r)$ where r is the magnitude of $\vec r$. I think I've done this correctly to get $-x(x^2+y^2+z^2)^{-\frac32} \hat i-y(x^2+y^2+z^2)^{-\frac32} \hat j-z(x^2+y^2+z^2)^{-\frac32} \hat k$ Secondly prove that $\vec \nabla. \frac{\vec r}{r}=\frac2r$ I've really got no idea for the second part.",,"['multivariable-calculus', 'vector-analysis']"
31,The derivative of Multivariate function,The derivative of Multivariate function,,"For Multivariate function $$f(x,y)=x^3+y^3$$ How to express $$f''(x,y)$$","For Multivariate function $$f(x,y)=x^3+y^3$$ How to express $$f''(x,y)$$",,"['calculus', 'real-analysis', 'multivariable-calculus', 'derivatives']"
32,Higher order Derivatives.,Higher order Derivatives.,,"Now we know that given two Banach spaces $E$ and $F$ and a function $\ f:E \to F $ , the derivative $ Df(x) $ is a linear map from $E$ to $F$ at some point $ x $ in $E$. Briefly $ \ Df: E \to L(E,F) $  where $ L(E,F) $ is space of all linear mappings from $E$ to $F$. Now my question is how would a second order derivative look like. Since the derivative map of a linear map is linear map itself does this mean $ \ D^2(f(x))=D(f(x)) $ which doesn't seem likely to me. Or is it something else? Also, is the following right? $$D^2(f): E \to L(L(E,F),F) $$","Now we know that given two Banach spaces $E$ and $F$ and a function $\ f:E \to F $ , the derivative $ Df(x) $ is a linear map from $E$ to $F$ at some point $ x $ in $E$. Briefly $ \ Df: E \to L(E,F) $  where $ L(E,F) $ is space of all linear mappings from $E$ to $F$. Now my question is how would a second order derivative look like. Since the derivative map of a linear map is linear map itself does this mean $ \ D^2(f(x))=D(f(x)) $ which doesn't seem likely to me. Or is it something else? Also, is the following right? $$D^2(f): E \to L(L(E,F),F) $$",,['multivariable-calculus']
33,How to check if the limit exists in multivariable calculus,How to check if the limit exists in multivariable calculus,,"$$\lim_{(x,y ) \to (0,0)} ye^{\frac{âˆ’1}{\sqrt{x^2+y^2}}}$$ I have tried many ways so far and I keep getting the limit to be $0$ . So far I have set x equal to zero and then y and I got the limit to be $0$ . I tried setting $y=x$ and $y=x^2$ and still got zero. What else can I do? My idea is that when both x and y go to zero, the fraction $\frac{-1}{0.00\ldots1}$ becomes negative infinity and when I raise $e$ to negative infinity it will go to zero. And zero times zero is zero. Is this correct? If yes what about my explanation?","I have tried many ways so far and I keep getting the limit to be . So far I have set x equal to zero and then y and I got the limit to be . I tried setting and and still got zero. What else can I do? My idea is that when both x and y go to zero, the fraction becomes negative infinity and when I raise to negative infinity it will go to zero. And zero times zero is zero. Is this correct? If yes what about my explanation?","\lim_{(x,y ) \to (0,0)} ye^{\frac{âˆ’1}{\sqrt{x^2+y^2}}} 0 0 y=x y=x^2 \frac{-1}{0.00\ldots1} e","['calculus', 'limits', 'multivariable-calculus', 'continuity', 'limits-without-lhopital']"
34,"$\iint_D(x^2-y^2)dxdy$ with D enclosed by $y=\frac2x$, $y=\frac4x$, $y=x$, $y=x-3$?","with D enclosed by , , , ?",\iint_D(x^2-y^2)dxdy y=\frac2x y=\frac4x y=x y=x-3,"I have been presented with the following problem: Calculate the double integral $$\iint_D(x^2-y^2)dxdy$$ where D is the area enclosed by the curves $y=\frac2x$ , $y=\frac4x$ , $y=x$ , and $y=x-3$ . Here's a visualisation of the area D: https://i.sstatic.net/Y7ewp.png I've been trying to use various substitutions, but I always fail in finding the new area or what x and y should be substituted with. I'm kind of stuck and would like a pointer in what I should substitute (or if I should even you substitution to begin with). Thanks in advance!","I have been presented with the following problem: Calculate the double integral where D is the area enclosed by the curves , , , and . Here's a visualisation of the area D: https://i.sstatic.net/Y7ewp.png I've been trying to use various substitutions, but I always fail in finding the new area or what x and y should be substituted with. I'm kind of stuck and would like a pointer in what I should substitute (or if I should even you substitution to begin with). Thanks in advance!",\iint_D(x^2-y^2)dxdy y=\frac2x y=\frac4x y=x y=x-3,"['integration', 'multivariable-calculus', 'definite-integrals', 'multiple-integral']"
35,How to prove $\frac{a^{n+1}+b^{n+1}+c^{n+1}}{a^n+b^n+c^n} \ge \sqrt[3]{abc}$?,How to prove ?,\frac{a^{n+1}+b^{n+1}+c^{n+1}}{a^n+b^n+c^n} \ge \sqrt[3]{abc},"Give $a,b,c>0$ . Prove that: $$\dfrac{a^{n+1}+b^{n+1}+c^{n+1}}{a^n+b^n+c^n} \ge \sqrt[3]{abc}.$$ My direction: (we have the equation if and only if $a=b=c$ ) $a^{n+1}+a^nb+a^nc \ge 3a^n\sqrt[3]{abc}$ $b^{n+1}+b^na+b^nc \ge 3b^n\sqrt[3]{abc}$ $c^{n+1}+c^na+c^nb \ge 3c^n\sqrt[3]{abc}$ But from these things, i can't prove the problem.","Give . Prove that: My direction: (we have the equation if and only if ) But from these things, i can't prove the problem.","a,b,c>0 \dfrac{a^{n+1}+b^{n+1}+c^{n+1}}{a^n+b^n+c^n} \ge \sqrt[3]{abc}. a=b=c a^{n+1}+a^nb+a^nc \ge 3a^n\sqrt[3]{abc} b^{n+1}+b^na+b^nc \ge 3b^n\sqrt[3]{abc} c^{n+1}+c^na+c^nb \ge 3c^n\sqrt[3]{abc}","['multivariable-calculus', 'inequality', 'summation', 'a.m.-g.m.-inequality', 'muirhead-inequality']"
36,Wedge product of $\beta \wedge dx$,Wedge product of,\beta \wedge dx,"I'm still struggling to understand the wedge product (and also differential forms in general) and am therefore trying to find / come up with actual examples. Say I have differential forms $\alpha = dx + dy + dz$ and $\beta = 2dx - dy + dz$ , how would I wedge $\alpha \wedge \beta \wedge dz$ . Sorry if this is not a good question, I'm just really lacking good intuition, yet.","I'm still struggling to understand the wedge product (and also differential forms in general) and am therefore trying to find / come up with actual examples. Say I have differential forms and , how would I wedge . Sorry if this is not a good question, I'm just really lacking good intuition, yet.",\alpha = dx + dy + dz \beta = 2dx - dy + dz \alpha \wedge \beta \wedge dz,"['multivariable-calculus', 'differential-geometry', 'intuition', 'differential-forms', 'exterior-algebra']"
37,Transform the partial differential equation with new independent variables,Transform the partial differential equation with new independent variables,,"Transform the following equation to new independent variables $u = x$ , $v = x^2+y^2$ $$ y\frac{\partial z}{\partial x} - x \frac{\partial z}{\partial y} = 0  $$ Notce you don't have to actually solve the pde, the problem is to transform it. The official answer is $ \frac{\partial z}{\partial u} = 0 $ My work: $$ y\frac{\partial z}{\partial x} = x\frac{\partial z}{\partial y} \longrightarrow \frac{1}{x}\frac{\partial z}{\partial x} = \frac{1}{y}\frac{\partial z}{\partial y}  $$ $$ \frac{\partial z}{\partial y} = \frac{\partial z}{\partial v}\frac{\partial v}{\partial y} \longrightarrow \frac{\partial z}{\partial y} = \frac{\partial z}{\partial v}2y $$ Substituting, you get $$ \frac{1}{x} \frac{\partial z}{\partial x}  = 2\frac{\partial z}{\partial v}    $$ By the same procedure you can get $$ \frac{\partial z}{\partial x} = \frac{\partial z}{\partial u} $$ Finally, I got $$ \frac{1}{u}\frac{\partial z}{\partial u} = 2\frac{\partial z}{\partial v} $$ Which is obviously not the official answer. Am I doing something wrong and if not, how do I finish the problem? Thanks.","Transform the following equation to new independent variables , Notce you don't have to actually solve the pde, the problem is to transform it. The official answer is My work: Substituting, you get By the same procedure you can get Finally, I got Which is obviously not the official answer. Am I doing something wrong and if not, how do I finish the problem? Thanks.",u = x v = x^2+y^2  y\frac{\partial z}{\partial x} - x \frac{\partial z}{\partial y} = 0    \frac{\partial z}{\partial u} = 0   y\frac{\partial z}{\partial x} = x\frac{\partial z}{\partial y} \longrightarrow \frac{1}{x}\frac{\partial z}{\partial x} = \frac{1}{y}\frac{\partial z}{\partial y}    \frac{\partial z}{\partial y} = \frac{\partial z}{\partial v}\frac{\partial v}{\partial y} \longrightarrow \frac{\partial z}{\partial y} = \frac{\partial z}{\partial v}2y   \frac{1}{x} \frac{\partial z}{\partial x}  = 2\frac{\partial z}{\partial v}      \frac{\partial z}{\partial x} = \frac{\partial z}{\partial u}   \frac{1}{u}\frac{\partial z}{\partial u} = 2\frac{\partial z}{\partial v} ,"['multivariable-calculus', 'partial-differential-equations']"
38,Domain of multivariable function,Domain of multivariable function,,"I have a function of two real variables which is given by the transformation rule $$f(x,y)=\frac{y}{1+x^2+y^2}.$$ I have to find the domain of $f$ which consists of all points $(x,y)$. When I examine the function I would say the domain is $$|x,y \in \Bbb{R}^2:y\neq0, x \text{ are real numbers|}$$, but looking at the results-list it says that both $x$ and $y$ are real numbers. How come that is? This might be straightforward for some of you, but I can't seem to wrap my head around this on my own and hope some of you can help. Thanks in advance","I have a function of two real variables which is given by the transformation rule $$f(x,y)=\frac{y}{1+x^2+y^2}.$$ I have to find the domain of $f$ which consists of all points $(x,y)$. When I examine the function I would say the domain is $$|x,y \in \Bbb{R}^2:y\neq0, x \text{ are real numbers|}$$, but looking at the results-list it says that both $x$ and $y$ are real numbers. How come that is? This might be straightforward for some of you, but I can't seem to wrap my head around this on my own and hope some of you can help. Thanks in advance",,"['multivariable-calculus', 'functions']"
39,If $a^2+b^2+c^2+d^2=4$ what is the range of $a^3+b^3+c^3+d^3$?,If  what is the range of ?,a^2+b^2+c^2+d^2=4 a^3+b^3+c^3+d^3,"I tried to used AM-GM but could not do.Setting any one as $2$ or $-2$ and the others $0$ we get the range  as $[-8,8]$ but what is the formal way to do this?","I tried to used AM-GM but could not do.Setting any one as $2$ or $-2$ and the others $0$ we get the range  as $[-8,8]$ but what is the formal way to do this?",,"['multivariable-calculus', 'maxima-minima', 'karamata-inequality']"
40,"Compute $\lim_{ (x,y)\to (0,0)}\frac{x^ny^m}{x^2+y^2}$ [duplicate]",Compute  [duplicate],"\lim_{ (x,y)\to (0,0)}\frac{x^ny^m}{x^2+y^2}","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 4 years ago . Compute $\displaystyle\lim_{ (x,y)\to (0,0)}\dfrac{x^ny^m}{x^2+y^2}$ Determine with the conditions on $n$ and $m$ for which this limit exists and conditions for which this limit does not exist. I found that when $x$ approaches $0$ the limit approaches $0$ and as $y$ approaches $0$ the limit also approaches $0$. As $x$ and $y$ approaches $x$ it seems like there are no conditions for $m$ and $n$ which will make the limit exist.","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 4 years ago . Compute $\displaystyle\lim_{ (x,y)\to (0,0)}\dfrac{x^ny^m}{x^2+y^2}$ Determine with the conditions on $n$ and $m$ for which this limit exists and conditions for which this limit does not exist. I found that when $x$ approaches $0$ the limit approaches $0$ and as $y$ approaches $0$ the limit also approaches $0$. As $x$ and $y$ approaches $x$ it seems like there are no conditions for $m$ and $n$ which will make the limit exist.",,"['limits', 'multivariable-calculus']"
41,Evaluation of the integral of $e^{-(x^2+y^2)}$ over a disk,Evaluation of the integral of  over a disk,e^{-(x^2+y^2)},"Show that   $$\renewcommand{\intd}{\,\mathrm{d}}     \iint_{D(R)} e^{-(x^2+y^2)} \intd x \intd y = \pi \left(1 - e^{-R^2}\right)$$   where $D(R)$ is the disc of radius $R$ with center $(0,0).$ I have never been asked to calculate a double integral without a defined region, so I don't even know where to start. I don't know the boundaries. This is my guess: $$0 < r < R\\ 0 < \theta < 2\pi $$ Is this correct?","Show that   $$\renewcommand{\intd}{\,\mathrm{d}}     \iint_{D(R)} e^{-(x^2+y^2)} \intd x \intd y = \pi \left(1 - e^{-R^2}\right)$$   where $D(R)$ is the disc of radius $R$ with center $(0,0).$ I have never been asked to calculate a double integral without a defined region, so I don't even know where to start. I don't know the boundaries. This is my guess: $$0 < r < R\\ 0 < \theta < 2\pi $$ Is this correct?",,"['calculus', 'integration', 'multivariable-calculus', 'exponential-function', 'polar-coordinates']"
42,a question about double integral,a question about double integral,,"Let $a,b$ be positive real numbers, and let $R$ be the region in $\Bbb R^2$ bounded by $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$. Calculate the integral  $$ \int\int_R\left(1-\frac{x^2}{a^2}-\frac{y^2}{b^2}\right)^{3/2}dx\,dy $$ my question is I don't know anything about $R$, the function $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ is not the function of $R$, so then how can I get the answer? Could somebody give me some hints.","Let $a,b$ be positive real numbers, and let $R$ be the region in $\Bbb R^2$ bounded by $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$. Calculate the integral  $$ \int\int_R\left(1-\frac{x^2}{a^2}-\frac{y^2}{b^2}\right)^{3/2}dx\,dy $$ my question is I don't know anything about $R$, the function $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ is not the function of $R$, so then how can I get the answer? Could somebody give me some hints.",,"['calculus', 'integration', 'multivariable-calculus']"
43,Finding the $x$ and $y$ values such that the partial derivatives are zero simultaneously,Finding the  and  values such that the partial derivatives are zero simultaneously,x y,"$f(x,y) = x^2 + 4xy + y^2 -4x + 16y + 3$ So, I proceeded with taking the partial derivatives: $f(x,y)_x = 2x + 4y - 4$ and $f(x,y)_y = 4x + 2y + 16$ and $f(x,y)_x = f(x,y)_y = 0$ $2x + 4y - 4 = 4x + 2y + 16$. This leads to a linear equation. However, they came out with a specific ordered pair, $(-6, 4)$ What did I do wrong?","$f(x,y) = x^2 + 4xy + y^2 -4x + 16y + 3$ So, I proceeded with taking the partial derivatives: $f(x,y)_x = 2x + 4y - 4$ and $f(x,y)_y = 4x + 2y + 16$ and $f(x,y)_x = f(x,y)_y = 0$ $2x + 4y - 4 = 4x + 2y + 16$. This leads to a linear equation. However, they came out with a specific ordered pair, $(-6, 4)$ What did I do wrong?",,"['algebra-precalculus', 'multivariable-calculus']"
44,A limit which exists in polar coordinates but not in Cartesian coordinates?,A limit which exists in polar coordinates but not in Cartesian coordinates?,,"Let's have look at the function $$ f(x,y) \begin{cases} \frac{y(x^2+y^2)}{y^2+(x^2+y^2)^2} & (x,y)\neq(0,0) \\0 & (x,y)=(0,0)\end{cases}.$$ Switching to polar coordinates gives $$ f(r,\theta)=\begin{cases} \frac{r^3 \sin \theta}{r^2\sin^2\theta+r^4} & r\neq0 \\0 & r=0\end{cases}.$$ We'd like to investigate the existence of a limit for $f$ at the origin. In Cartesian coordinates ( $f(x,y)$ ) one can immeidately see that the limit doesn't exist because for example on the path $y=0$ we have $\lim_{x\rightarrow 0,y=0} f(x,y)=0$ and on the path $y=x^2$ we have $\lim_{x\rightarrow 0,y=x^2} f(x,y)=\frac{1}{2}$ . However, in polar coordinates we have $$ f(r,\theta)=\begin{cases} \frac{r \sin \theta}{\sin^2\theta+r^2} & r\neq0 \\0 & r=0\end{cases} $$ so that $$ \lim_{r\rightarrow 0}f(r,\theta) = \begin{cases} 0 & \sin\theta = 0\\ 0 & \sin\theta \neq 0 \end{cases}$$ so the limit exists and is zero regardless of $\theta$ . Why does it look the limit doesn't exist in Cartesian coordinates but exists in polar coordinates? Edit: Thanks to the insightful comments on this page and other similar questions in the site, the unboundedness of the expression with $\sin^2 \theta$ is the key to the failure of the limit existence. $\sin\theta$ can get arbitrarily small, making the whole expression arbitrarily large, effectively counteracting $r\rightarrow 0$ .","Let's have look at the function Switching to polar coordinates gives We'd like to investigate the existence of a limit for at the origin. In Cartesian coordinates ( ) one can immeidately see that the limit doesn't exist because for example on the path we have and on the path we have . However, in polar coordinates we have so that so the limit exists and is zero regardless of . Why does it look the limit doesn't exist in Cartesian coordinates but exists in polar coordinates? Edit: Thanks to the insightful comments on this page and other similar questions in the site, the unboundedness of the expression with is the key to the failure of the limit existence. can get arbitrarily small, making the whole expression arbitrarily large, effectively counteracting ."," f(x,y) \begin{cases}
\frac{y(x^2+y^2)}{y^2+(x^2+y^2)^2} & (x,y)\neq(0,0)
\\0 & (x,y)=(0,0)\end{cases}.  f(r,\theta)=\begin{cases}
\frac{r^3 \sin \theta}{r^2\sin^2\theta+r^4} & r\neq0
\\0 & r=0\end{cases}. f f(x,y) y=0 \lim_{x\rightarrow 0,y=0} f(x,y)=0 y=x^2 \lim_{x\rightarrow 0,y=x^2} f(x,y)=\frac{1}{2}  f(r,\theta)=\begin{cases}
\frac{r \sin \theta}{\sin^2\theta+r^2} & r\neq0
\\0 & r=0\end{cases}   \lim_{r\rightarrow 0}f(r,\theta) = \begin{cases}
0 & \sin\theta = 0\\
0 & \sin\theta \neq 0
\end{cases} \theta \sin^2 \theta \sin\theta r\rightarrow 0","['calculus', 'limits', 'multivariable-calculus', 'limits-without-lhopital']"
45,"In this textbook explanation of needing partial derivatives, how is this partial derivative not an indeterminate form?","In this textbook explanation of needing partial derivatives, how is this partial derivative not an indeterminate form?",,"$$  f(x,y) = x^\frac{1}{3}y^\frac{1}{3} $$ $$\frac{\partial f}{\partial x}(0,0) = \lim_{x \to 0} \frac{f(h,0)-f(0,0)}{h}= \lim_{x \to 0} \frac{0-0}{h} = 0$$ ""and, similarly, $\frac{\partial f}{\partial y}(0,0) =0$ (these are not indeterminate forms!). It is necessary to use the original definition of partial derivatives, because the functions $x^\frac{1}{3}$ and $y^\frac{1}{3}$ are not themselves differentiable at 0."" This is a portion of textbook explaning why a simple definition of a partial derivative does not work but a linear approximation definition of a partial derivative must be used. However, I'm confused at this part where they seem to be trying to use a counterexample to prove why a simple definition of partial derivatives does not work. Isn't this limit an indeterminate form? Yet, as you can see, the textbook claims this limit is not an indeterminate form to make their case. I would greatly appreciate your help in making sense of this textbook. Reference textbook: Vector Calculus by Marsden and Tromba 5th edition.","""and, similarly, (these are not indeterminate forms!). It is necessary to use the original definition of partial derivatives, because the functions and are not themselves differentiable at 0."" This is a portion of textbook explaning why a simple definition of a partial derivative does not work but a linear approximation definition of a partial derivative must be used. However, I'm confused at this part where they seem to be trying to use a counterexample to prove why a simple definition of partial derivatives does not work. Isn't this limit an indeterminate form? Yet, as you can see, the textbook claims this limit is not an indeterminate form to make their case. I would greatly appreciate your help in making sense of this textbook. Reference textbook: Vector Calculus by Marsden and Tromba 5th edition.","  f(x,y) = x^\frac{1}{3}y^\frac{1}{3}  \frac{\partial f}{\partial x}(0,0) = \lim_{x \to 0} \frac{f(h,0)-f(0,0)}{h}= \lim_{x \to 0} \frac{0-0}{h} = 0 \frac{\partial f}{\partial y}(0,0) =0 x^\frac{1}{3} y^\frac{1}{3}","['limits', 'multivariable-calculus', 'partial-derivative', 'indeterminate-forms', 'linear-approximation']"
46,$ \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} dx dy $,, \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} dx dy ,Question : The integral $$ \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} \mathop{dx}\mathop{dy} $$ is (a) infinite (b) finite but can not be evaluated in closed form (c) 1 (d) 2 . I tried substituting $u=x+y$ and $v=y$ that led me no where . I'm not even sure about convergence of integral .Any help would be greatly appreciated .,Question : The integral $$ \int_{0}^{ \infty} \int_{0}^{ \infty} \frac { e^{-(x+y)}}{x+y} \mathop{dx}\mathop{dy} $$ is (a) infinite (b) finite but can not be evaluated in closed form (c) 1 (d) 2 . I tried substituting $u=x+y$ and $v=y$ that led me no where . I'm not even sure about convergence of integral .Any help would be greatly appreciated .,,"['calculus', 'real-analysis', 'multivariable-calculus']"
47,Are curves in a level set continuous?,Are curves in a level set continuous?,,"Wikipedia defines a level set as a level set of a real-valued function of $n$ real variables $f$ is a set of the form $$L_c(f) = \left\{ (x_1, \cdots, x_n) \, \mid \, f(x_1, \cdots, x_n) = c \right\}$$ I often seen level sets drawn as curves in $\Bbb{R}^2$ like this My Question: Why do we assume a level set is continuous? Why couldn't it be just a collection of random points all with the same value instead of curves?","Wikipedia defines a level set as a level set of a real-valued function of $n$ real variables $f$ is a set of the form $$L_c(f) = \left\{ (x_1, \cdots, x_n) \, \mid \, f(x_1, \cdots, x_n) = c \right\}$$ I often seen level sets drawn as curves in $\Bbb{R}^2$ like this My Question: Why do we assume a level set is continuous? Why couldn't it be just a collection of random points all with the same value instead of curves?",,"['calculus', 'multivariable-calculus']"
48,"Why Lagrange multipliers don't help to find the minimum of $f(x,y)=x^2+y^2$ with the constraint $y=1$?",Why Lagrange multipliers don't help to find the minimum of  with the constraint ?,"f(x,y)=x^2+y^2 y=1","Please help me understand why the following doesn't work. Say I want to find the minimum of the function $f(x,y)=x^2+y^2$ with the constraint $y=1$. So I declare the helper function $g(x,y)=(y-1)^2=0$. And by using the Lagrange multipliers method, what I get is $F=x^2+y^2+\lambda(y-1)^2, F_x=2x, F_y=2y+2\lambda(y-1)$ and \begin{cases} 2x=0\\ 2y+2\lambda(y-1)=0\\ (y-1)^2=0. \end{cases} The above has no solutions, although obviously $(0, 1)$ is a minimum value.","Please help me understand why the following doesn't work. Say I want to find the minimum of the function $f(x,y)=x^2+y^2$ with the constraint $y=1$. So I declare the helper function $g(x,y)=(y-1)^2=0$. And by using the Lagrange multipliers method, what I get is $F=x^2+y^2+\lambda(y-1)^2, F_x=2x, F_y=2y+2\lambda(y-1)$ and \begin{cases} 2x=0\\ 2y+2\lambda(y-1)=0\\ (y-1)^2=0. \end{cases} The above has no solutions, although obviously $(0, 1)$ is a minimum value.",,"['multivariable-calculus', 'lagrange-multiplier']"
49,Line Integral Around a Triangle,Line Integral Around a Triangle,,"Let $R$ be the interior of the triangle with vertices $(0,0), (4,2),$ and $(0,2)$. Let $C$ be the boundary of $R$, oriented counterclockwise. Now evaluate the integral below. $$\int_C(y+e^\sqrt{x}) dx + (xe^{y^2}) dy$$ I know this has to be parametrized somehow, but I'm not sure where to start. Could someone show me how to set up the integral so it can be evaluated? Thanks.","Let $R$ be the interior of the triangle with vertices $(0,0), (4,2),$ and $(0,2)$. Let $C$ be the boundary of $R$, oriented counterclockwise. Now evaluate the integral below. $$\int_C(y+e^\sqrt{x}) dx + (xe^{y^2}) dy$$ I know this has to be parametrized somehow, but I'm not sure where to start. Could someone show me how to set up the integral so it can be evaluated? Thanks.",,['multivariable-calculus']
50,"What is $ \lim_{(x,y)\to(2,2)}\frac{x^4-y^4}{x^2 - y^2} $?",What is ?," \lim_{(x,y)\to(2,2)}\frac{x^4-y^4}{x^2 - y^2} ","I have limit: $$ \lim_{(x,y)\to(2,2)}\frac{x^4-y^4}{x^2 - y^2} $$ Why is the result $8$ ?","I have limit: $$ \lim_{(x,y)\to(2,2)}\frac{x^4-y^4}{x^2 - y^2} $$ Why is the result $8$ ?",,"['calculus', 'limits', 'multivariable-calculus']"
51,Integral with cross product,Integral with cross product,,"Given a function $\vec{r}(t)$, is there a way to simplify: $$\int_0^u \frac{\vec{r}}{\vec{r} \cdot \vec{r}} \times \frac{d\vec{r}}{dt}~dt$$ With an abuse of notation, it's a line integral like this: $$ \int_\gamma \frac{\vec{r}}{\vec{r} \cdot \vec{r}} \times d\vec{r}$$ but I've only seen dot products used with the $d\vec{r}$, never cross. No idea if it makes sense. I know that it's path-dependent (consider $\vec{r}$ going in a circle), but in two dimensions, it turns out to be the winding number around $0$ times $2\pi$. Is there a way to extend this correlation to three dimensions? (My motivation here is: I like angular velocities to be vectors, so I define $\vec{\omega}$ not as $\frac{d\theta}{dt}$, but as $\frac{\vec{r} \times \vec{v}}{|\vec{r}|^2}$. It points along the instantaneous axis of rotation, and gives the angular velocity around that point. But I couldn't come up with a physical interpretation for $\theta$ as a vector, so I'm curious to see what comes out of this integral)","Given a function $\vec{r}(t)$, is there a way to simplify: $$\int_0^u \frac{\vec{r}}{\vec{r} \cdot \vec{r}} \times \frac{d\vec{r}}{dt}~dt$$ With an abuse of notation, it's a line integral like this: $$ \int_\gamma \frac{\vec{r}}{\vec{r} \cdot \vec{r}} \times d\vec{r}$$ but I've only seen dot products used with the $d\vec{r}$, never cross. No idea if it makes sense. I know that it's path-dependent (consider $\vec{r}$ going in a circle), but in two dimensions, it turns out to be the winding number around $0$ times $2\pi$. Is there a way to extend this correlation to three dimensions? (My motivation here is: I like angular velocities to be vectors, so I define $\vec{\omega}$ not as $\frac{d\theta}{dt}$, but as $\frac{\vec{r} \times \vec{v}}{|\vec{r}|^2}$. It points along the instantaneous axis of rotation, and gives the angular velocity around that point. But I couldn't come up with a physical interpretation for $\theta$ as a vector, so I'm curious to see what comes out of this integral)",,"['multivariable-calculus', 'physics']"
52,Prove that $\frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2$.,Prove that .,\frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2,"Given: $x,y,z\geq0$ $xy+yz+zx=1$ Prove that $\displaystyle \frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2$ . I tried using Cauchy's inequality LHS $\geq\frac 9 {2a+2b+2c}$ , but failed. Please give me some ideas. Thank you.","Given: Prove that . I tried using Cauchy's inequality LHS , but failed. Please give me some ideas. Thank you.","x,y,z\geq0 xy+yz+zx=1 \displaystyle \frac 1 {x+y}+\frac 1 {y+z}+\frac 1 {z+x}\geq \frac 5 2 \geq\frac 9 {2a+2b+2c}","['multivariable-calculus', 'inequality', 'substitution', 'symmetric-polynomials', 'uvw']"
53,What the implicit function theorem is actually showing,What the implicit function theorem is actually showing,,"Theorem : Let $F: X\subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ be of class of $C^1$ and let $a$ be a point of the level set $S=\{x\in\mathbb{R}^n \mid F(x)=c\}$. If $F_{x_n}(a)\neq 0$ then there is a neighborhood $U$ of $(a_1,a_1\dots a_{n-1}) \in \mathbb{R}^{n-1}$, a neighborhood $V$ for of $a_n\in\mathbb{R}$ and a function $f:U\subseteq\mathbb{R}^{n-1} \rightarrow V$ of class $C^1$ such that if $(x_1,x_2,\ldots,x_{n-1})\in U$ and $x_n \in V$ satisfy $F(x_1,x_2,\ldots,x_n)=c$ ,then $x_n = f(x_1,x_2,\ldots,x_{n-1})$ is representable as a function of $(x_1,\ldots,x_{n-1})$ . I don't quite get what the theorem is trying to show. Can someone explain it? Is it just as simple as we just consider different part of the function?","Theorem : Let $F: X\subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ be of class of $C^1$ and let $a$ be a point of the level set $S=\{x\in\mathbb{R}^n \mid F(x)=c\}$. If $F_{x_n}(a)\neq 0$ then there is a neighborhood $U$ of $(a_1,a_1\dots a_{n-1}) \in \mathbb{R}^{n-1}$, a neighborhood $V$ for of $a_n\in\mathbb{R}$ and a function $f:U\subseteq\mathbb{R}^{n-1} \rightarrow V$ of class $C^1$ such that if $(x_1,x_2,\ldots,x_{n-1})\in U$ and $x_n \in V$ satisfy $F(x_1,x_2,\ldots,x_n)=c$ ,then $x_n = f(x_1,x_2,\ldots,x_{n-1})$ is representable as a function of $(x_1,\ldots,x_{n-1})$ . I don't quite get what the theorem is trying to show. Can someone explain it? Is it just as simple as we just consider different part of the function?",,['multivariable-calculus']
54,"Evaluating $\int_0^4 \int_{\sqrt {x}}^2 \frac{x^2 e^{y^2}}{y^5}\mathrm dy\,\mathrm dx$",Evaluating,"\int_0^4 \int_{\sqrt {x}}^2 \frac{x^2 e^{y^2}}{y^5}\mathrm dy\,\mathrm dx","I need help starting with this. I can't find an example like this anywhere in my book $$\int_0^4 \int_{\sqrt {x}}^2 \frac{x^2 e^{y^2}}{y^5}\mathrm dy\,\mathrm dx$$","I need help starting with this. I can't find an example like this anywhere in my book $$\int_0^4 \int_{\sqrt {x}}^2 \frac{x^2 e^{y^2}}{y^5}\mathrm dy\,\mathrm dx$$",,"['integration', 'multivariable-calculus']"
55,Electric Field by integral method is not the same as for Gauss's Law,Electric Field by integral method is not the same as for Gauss's Law,,"I'm trying to calculate the Electric Field over a thick spherical sphere with charge density $\rho = \frac{k}{r^2}$ for $a < r < b$ , where $a$ is the radius of the inner surface and $b$ the radius of the outer surface. From Gauss's Law I've got it to be $\vec{E} = \frac{k}{\epsilon_0}\frac{r-a}{r^2}$ . But also tried to integrate the charge over the surface and I was hoping to get the same result but didn't. My attempt was, in spherical coordinates: $$ \begin{equation} \begin{aligned} \vec{E} &= \frac{1}{4 \pi \epsilon_0}\int_a^r \int_0^\pi \int_0^{2\pi} \frac{\rho r^2 \sin \phi}{r^2} d\theta d\phi dr \vec{e_r}\\ &= \frac{1}{4 \pi \epsilon_0}\int_a^r \int_0^\pi \int_0^{2\pi} \frac{k \sin \phi}{r^2} d\theta d\phi dr \vec{e_r}\\ \\ &= -\frac{k}{\epsilon_0}(\frac{1}{r} - \frac{1}{a})\\ &= \frac{k}{\epsilon}\frac{r-a}{ra}\vec{e_r} \end{aligned} \end{equation} $$ Which are not the same. But they should be! I know that my Gauss method gave me the right expression, but I can't figure out why the integral method didn't.","I'm trying to calculate the Electric Field over a thick spherical sphere with charge density for , where is the radius of the inner surface and the radius of the outer surface. From Gauss's Law I've got it to be . But also tried to integrate the charge over the surface and I was hoping to get the same result but didn't. My attempt was, in spherical coordinates: Which are not the same. But they should be! I know that my Gauss method gave me the right expression, but I can't figure out why the integral method didn't.","\rho = \frac{k}{r^2} a < r < b a b \vec{E} = \frac{k}{\epsilon_0}\frac{r-a}{r^2} 
\begin{equation}
\begin{aligned}
\vec{E} &= \frac{1}{4 \pi \epsilon_0}\int_a^r \int_0^\pi \int_0^{2\pi} \frac{\rho r^2 \sin \phi}{r^2} d\theta d\phi dr \vec{e_r}\\ &= \frac{1}{4 \pi \epsilon_0}\int_a^r \int_0^\pi \int_0^{2\pi} \frac{k \sin \phi}{r^2} d\theta d\phi dr \vec{e_r}\\ \\ &= -\frac{k}{\epsilon_0}(\frac{1}{r} - \frac{1}{a})\\ &= \frac{k}{\epsilon}\frac{r-a}{ra}\vec{e_r}
\end{aligned}
\end{equation}
","['integration', 'multivariable-calculus', 'vector-analysis', 'vector-fields', 'electromagnetism']"
56,Understanding an intuitive explanation of the derivative of $x^x$,Understanding an intuitive explanation of the derivative of,x^x,"This question is related to this question here Can't argue with success? Looking for ""bad math"" that ""gets away with it"" The question is about ways to get the right answer with incorrect logic/methods. One of the answers with $104$ score by Hans Engler reads like this Here's another classical freshman calculus example: Find $\frac{d}{dx} x^x$ . Alice says ""this is like $\frac{d}{dx} x^n = nx^{nâˆ’1}$ , so the answer is $xx^{xâˆ’1}=x^x$ ."" Bob says ""no, this is like $\frac{d}{dx} a^x = \log{a}â‹…a^x$ , so the answer is $\log{x}â‹…x^x$ ."" Charlie says ""if you're not sure, just add the two terms, so you'll get partial credit"". The answer $\frac{d}{dx} x^x= (1+\log x)x^x$ turns out to be correct. Joriki in the comments of this answer states that That's not wrong; that's a perfectly valid method. You get the derivative of any expression with respect to x as the sums of all the derivatives with respect to the individual instances of x while holding all other instances constant. I am having trouble making sense of his comment, this is what I think it means. Imagine that the $x$ s in $x^x$ were different. Let's call them $x_1$ and $x_2$ . Thus, our expression becomes ${x_1}^{x_2}$ . I believe his comment is saying that the rate of change of ${x_1}^{x_2} = \frac{\partial}{\partial x_1} {x_1}^{x_2} + \frac{\partial}{\partial x_2} {x_1}^{x_2}$ . Each partial derivative evaluates the change in the quantity with respect to a different $x$ and sums them up while keeping the other $x$ constant, just like the comment says. However, I am not sure why this equality is true.","This question is related to this question here Can't argue with success? Looking for ""bad math"" that ""gets away with it"" The question is about ways to get the right answer with incorrect logic/methods. One of the answers with score by Hans Engler reads like this Here's another classical freshman calculus example: Find . Alice says ""this is like , so the answer is ."" Bob says ""no, this is like , so the answer is ."" Charlie says ""if you're not sure, just add the two terms, so you'll get partial credit"". The answer turns out to be correct. Joriki in the comments of this answer states that That's not wrong; that's a perfectly valid method. You get the derivative of any expression with respect to x as the sums of all the derivatives with respect to the individual instances of x while holding all other instances constant. I am having trouble making sense of his comment, this is what I think it means. Imagine that the s in were different. Let's call them and . Thus, our expression becomes . I believe his comment is saying that the rate of change of . Each partial derivative evaluates the change in the quantity with respect to a different and sums them up while keeping the other constant, just like the comment says. However, I am not sure why this equality is true.",104 \frac{d}{dx} x^x \frac{d}{dx} x^n = nx^{nâˆ’1} xx^{xâˆ’1}=x^x \frac{d}{dx} a^x = \log{a}â‹…a^x \log{x}â‹…x^x \frac{d}{dx} x^x= (1+\log x)x^x x x^x x_1 x_2 {x_1}^{x_2} {x_1}^{x_2} = \frac{\partial}{\partial x_1} {x_1}^{x_2} + \frac{\partial}{\partial x_2} {x_1}^{x_2} x x,"['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
57,"Show that $f(x,y) = \sin( x )|y|$ is differentible at $(0,0)$.",Show that  is differentible at .,"f(x,y) = \sin( x )|y| (0,0)","Show that $$f(x,y) = \sin( x )|y|$$ is differentible at $(0,0)$ . Trying to find the partial derivatives, I found out that $$f'_y = \sin(x)\frac{|y|}{y}$$ is not defined at $(0,0)$ . However, if the partial derivative does not exist then we cannot say $f$ is differentible since the function is differentible at some point iff all partial derivatives exist and are continuous. Any help is appreciated.","Show that is differentible at . Trying to find the partial derivatives, I found out that is not defined at . However, if the partial derivative does not exist then we cannot say is differentible since the function is differentible at some point iff all partial derivatives exist and are continuous. Any help is appreciated.","f(x,y) = \sin( x )|y| (0,0) f'_y = \sin(x)\frac{|y|}{y} (0,0) f","['real-analysis', 'calculus', 'multivariable-calculus']"
58,"Optimization $\max\{xy:(x,y) \in M \}$",Optimization,"\max\{xy:(x,y) \in M \}","Consider $\max\{xy:(x,y) \in M \}$ with the set $M := \left \{ (x,y) \in \mathbb{R}^2: x^2+y^2 \leq 4\right \} $ How or where do I have to sketch the level sets $N_c = \{(x,y) : xy = c \}$ for $c =0$ , $c=1$ , $c=4$ and $M$ ? When I write $x^2+y^2 = c$ in Desmos I get this for $c=1$ and this for $c=4$ For $c=0$ I get nothing and regarding $M$ I don't know how it's done. Is $M$ just a circle $<= 4$ ?","Consider with the set How or where do I have to sketch the level sets for , , and ? When I write in Desmos I get this for and this for For I get nothing and regarding I don't know how it's done. Is just a circle ?","\max\{xy:(x,y) \in M \} M := \left \{ (x,y) \in \mathbb{R}^2: x^2+y^2 \leq 4\right \}  N_c = \{(x,y) : xy = c \} c =0 c=1 c=4 M x^2+y^2 = c c=1 c=4 c=0 M M <= 4","['calculus', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
59,"Limit of $f(x, y)$ at $(0, 0)$",Limit of  at,"f(x, y) (0, 0)","I need to show $$\lim_{(x, y) \rightarrow (0,0)} \frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} = 0 $$ Not really sure how to go about this without using the epsilon delta definition, which I would prefer not to. Any sort of help is appreciated. Edit: I do have the inequality: $$\frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} \le \frac{xy(x^2+y^2)}{(x^2+y^2)^{3/2}} = \frac{xy}{(x^2+y^2)} $$","I need to show Not really sure how to go about this without using the epsilon delta definition, which I would prefer not to. Any sort of help is appreciated. Edit: I do have the inequality:","\lim_{(x, y) \rightarrow (0,0)} \frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} = 0
 \frac{xy(x^2-y^2)}{(x^2+y^2)^{3/2}} \le \frac{xy(x^2+y^2)}{(x^2+y^2)^{3/2}} = \frac{xy}{(x^2+y^2)} ","['limits', 'multivariable-calculus']"
60,Why should I care about the symmetric equation of a line?,Why should I care about the symmetric equation of a line?,,"I'm currently TAing for a multivariable calculus course. When I think of a line, I think of the span of a single vector, potentially shifted away from the origin. In this way, the most natural representation of a line (to me) is its vector form : $$P + tv$$ where I first move to a point $P$ on my line, and then move in the direction of some vector $v$ . And if I'm in $\mathbb{R}^3$ where $P = \langle x_0,y_0,z_0\rangle$ and $v = \langle v_1, v_2,v_3\rangle$ , I can understand writing the line in parametric form : $$\begin{cases}x = x_0 + tv_1 \\ y = y_0 + tv_2 \\ z = z_0 + tv_3\end{cases}$$ because we're just being explicit about components. However, if each $v_i$ is nonzero, there's the symmetric equation of a line $$\frac{x-x_0}{v_1} = \frac{y-y_0}{v_2} = \frac{z-z_0}{v_3}.$$ Why would I (or my students) ever use this format to describe a line? I see geometry in the vector equation, but I see no geometry in the symmetric equation. Why not just use vector equations or parametric equations?","I'm currently TAing for a multivariable calculus course. When I think of a line, I think of the span of a single vector, potentially shifted away from the origin. In this way, the most natural representation of a line (to me) is its vector form : where I first move to a point on my line, and then move in the direction of some vector . And if I'm in where and , I can understand writing the line in parametric form : because we're just being explicit about components. However, if each is nonzero, there's the symmetric equation of a line Why would I (or my students) ever use this format to describe a line? I see geometry in the vector equation, but I see no geometry in the symmetric equation. Why not just use vector equations or parametric equations?","P + tv P v \mathbb{R}^3 P = \langle x_0,y_0,z_0\rangle v = \langle v_1, v_2,v_3\rangle \begin{cases}x = x_0 + tv_1 \\ y = y_0 + tv_2 \\ z = z_0 + tv_3\end{cases} v_i \frac{x-x_0}{v_1} = \frac{y-y_0}{v_2} = \frac{z-z_0}{v_3}.","['multivariable-calculus', 'education']"
61,Laplace equation: What is the difference between divergence operator and gradient operator both represented by $\nabla$? (in wikipedia article),Laplace equation: What is the difference between divergence operator and gradient operator both represented by ? (in wikipedia article),\nabla,"Here is the beginning of the article of Laplace equation of wikipedia Laplace's equation is a second-order partial differential equation named after Pierre-Simon Laplace who first studied its properties. This is often written as $$ \nabla^2f = 0\quad\text{or}\quad\Delta f = 0 $$ where $\Delta= \nabla \cdot \nabla = \nabla^2$ is the Laplace operator and $\nabla$ is divergence operator (also symbolized ""div""), $\nabla$ is the gradient operator (also symbolized ""grad""), and $f(x,y,z)$ is a twice-differentiable real-valued function. The Laplace operator therefore maps a scalar function to another scalar function My question: In this definition, what is the difference between divergence operator and gradient operator both represented by $\nabla$ ?","Here is the beginning of the article of Laplace equation of wikipedia Laplace's equation is a second-order partial differential equation named after Pierre-Simon Laplace who first studied its properties. This is often written as where is the Laplace operator and is divergence operator (also symbolized ""div""), is the gradient operator (also symbolized ""grad""), and is a twice-differentiable real-valued function. The Laplace operator therefore maps a scalar function to another scalar function My question: In this definition, what is the difference between divergence operator and gradient operator both represented by ?","
\nabla^2f = 0\quad\text{or}\quad\Delta f = 0
 \Delta= \nabla \cdot \nabla = \nabla^2 \nabla \nabla f(x,y,z) \nabla","['multivariable-calculus', 'harmonic-functions']"
62,How do I find the distance from a point to a plane?,How do I find the distance from a point to a plane?,,"I am trying to find the distance from point $(8, 0, -6)$ and plane $x+y+z = 6$ . I tried solving it but I am still getting it wrong. Can anyone help me on this? Any help I would very much appreciate. The following is my work: $$d = \sqrt{(x-8)^2 + (y-0)^2 + (z+6)^2}$$ since $x+y+z = 6$ , $z = 6-x-y$ , so \begin{align*} d &= \sqrt{(x-8)^2 + (y-0)^2 + (-x-y+12)^2} \\ d^2 &= (x-8)^2 + (y-0)^2 + (-x-y)^2 \end{align*} Find partial derivative $f_x$ and $f_y$ and critical points \begin{align*} f_x &= 2(x-8) + 2(-x-y+12) \\ &= 24-2y \quad (\text{set }= 0) \\ &= \text{critical point }y = 4 \\ f_y &= 2y + 2(-x-y+12) \\ &= 24 - 2x \quad (\text{set }= 0) \\ &= \text{critical point }x = 12 \\ \end{align*} Plug in $x = 12$ and $y = 4$ to original equation $$d = \sqrt{(x - 8)^2 + (4)^2 + (-12-4+12)^2} = \sqrt{48}$$","I am trying to find the distance from point and plane . I tried solving it but I am still getting it wrong. Can anyone help me on this? Any help I would very much appreciate. The following is my work: since , , so Find partial derivative and and critical points Plug in and to original equation","(8, 0, -6) x+y+z = 6 d = \sqrt{(x-8)^2 + (y-0)^2 + (z+6)^2} x+y+z = 6 z = 6-x-y \begin{align*}
d &= \sqrt{(x-8)^2 + (y-0)^2 + (-x-y+12)^2} \\
d^2 &= (x-8)^2 + (y-0)^2 + (-x-y)^2
\end{align*} f_x f_y \begin{align*}
f_x &= 2(x-8) + 2(-x-y+12) \\
&= 24-2y \quad (\text{set }= 0) \\
&= \text{critical point }y = 4 \\
f_y &= 2y + 2(-x-y+12) \\
&= 24 - 2x \quad (\text{set }= 0) \\
&= \text{critical point }x = 12 \\
\end{align*} x = 12 y = 4 d = \sqrt{(x - 8)^2 + (4)^2 + (-12-4+12)^2} = \sqrt{48}","['multivariable-calculus', 'optimization', 'cauchy-schwarz-inequality']"
63,Does There exist a bijection between $\mathbb{R}^2$ and $ \mathbb{R}$ such that it is differentiable,Does There exist a bijection between  and  such that it is differentiable,\mathbb{R}^2  \mathbb{R},"I was thinking recently about Louville's Theorem and the fact that there exist a bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Since $\mathbb{C}$ is nothing but $\mathbb{R}^2$ via the construction of $\mathbb{C}$ we can use those terms interchangeably. I thought of the following tho transformations. First $$f_1:\mathbb{R}^2 \to \mathbb{R}$$ which we know exists and then  $$f_2:\mathbb{R} \to S^1 $$ witch is a well known bijection and is differentiable (as far as I know). the composition of the functions $f_1$ and $f_2$ (let's call it $f_c$) should hence be a bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Louville's theorem states that any function such that $|f(z)|<M$ and $f\in H(\mathbb{C})$ must be equal to a constant function. aka $f(z)=c, c\in\mathbb{C}$ Our function $f_c$ is not a constant function because it ascribes a unique number in $S^1$ for each number in $\mathbb{C}$ and also $f_c$ is bounded $(f_c(z)<2$ for every $z\in \mathbb{C})$. The only thing that could make Louville's theorem not work in this case would be the fact that $f_1$ is not a holomorphic function. Which would mean that there is no holomorphic bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Is this argument true? If it is, does anyone know any restraints when it comes to differentiability of bijections between $\mathbb{R}^2$ and $ \mathbb{R}$? Thank you in advance.","I was thinking recently about Louville's Theorem and the fact that there exist a bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Since $\mathbb{C}$ is nothing but $\mathbb{R}^2$ via the construction of $\mathbb{C}$ we can use those terms interchangeably. I thought of the following tho transformations. First $$f_1:\mathbb{R}^2 \to \mathbb{R}$$ which we know exists and then  $$f_2:\mathbb{R} \to S^1 $$ witch is a well known bijection and is differentiable (as far as I know). the composition of the functions $f_1$ and $f_2$ (let's call it $f_c$) should hence be a bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Louville's theorem states that any function such that $|f(z)|<M$ and $f\in H(\mathbb{C})$ must be equal to a constant function. aka $f(z)=c, c\in\mathbb{C}$ Our function $f_c$ is not a constant function because it ascribes a unique number in $S^1$ for each number in $\mathbb{C}$ and also $f_c$ is bounded $(f_c(z)<2$ for every $z\in \mathbb{C})$. The only thing that could make Louville's theorem not work in this case would be the fact that $f_1$ is not a holomorphic function. Which would mean that there is no holomorphic bijection between $\mathbb{R}^2$ and $ \mathbb{R}$. Is this argument true? If it is, does anyone know any restraints when it comes to differentiability of bijections between $\mathbb{R}^2$ and $ \mathbb{R}$? Thank you in advance.",,"['real-analysis', 'complex-analysis', 'functions', 'multivariable-calculus']"
64,Flux through sphere,Flux through sphere,,"I wish to find the flux of $\mathbf{F}=(x^2,y^2,z^2)$ through $S: (x-1)^2+(y-3)^2+(z+1)^2$ Here is what I tried: I ""moved"" the sphere to $(0,0)$ by changing the variables to: $u=x-1$ , $v=y-3$ , $w=z+1$ so now we have $F=((u+1)^2,(v+3)^2,(w-1)^2)$ and $S$ is the unit sphere. So my calculation is (after switching to polar): $$\int_0^{2\pi}\int_0^1\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}}{\rm div}\,\mathbf{F}\,r\,{\rm d}z\,{\rm d}r\,{\rm d}\theta=\int_0^{2\pi}\int_0^1\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}}(2r\cos\theta +2r\sin\theta +2z+6)r\,{\rm d}z\,{\rm d}r\,{\rm d}\theta$$ but I got $0$ instead $8\pi$ What did I do wrong?","I wish to find the flux of $\mathbf{F}=(x^2,y^2,z^2)$ through $S: (x-1)^2+(y-3)^2+(z+1)^2$ Here is what I tried: I ""moved"" the sphere to $(0,0)$ by changing the variables to: $u=x-1$ , $v=y-3$ , $w=z+1$ so now we have $F=((u+1)^2,(v+3)^2,(w-1)^2)$ and $S$ is the unit sphere. So my calculation is (after switching to polar): $$\int_0^{2\pi}\int_0^1\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}}{\rm div}\,\mathbf{F}\,r\,{\rm d}z\,{\rm d}r\,{\rm d}\theta=\int_0^{2\pi}\int_0^1\int_{-\sqrt{1-r^2}}^{\sqrt{1-r^2}}(2r\cos\theta +2r\sin\theta +2z+6)r\,{\rm d}z\,{\rm d}r\,{\rm d}\theta$$ but I got $0$ instead $8\pi$ What did I do wrong?",,"['integration', 'multivariable-calculus', 'divergence-operator']"
65,Is the L2 norm always positive?,Is the L2 norm always positive?,,"Is $$\int_{a}^{b} u^2(x,t) \, dx \, , \,\, 0\le t \le T$$ defined as the $L^2$-norm: $$|| u^2||_{2,[a,b]}^{2} $$ Always positive (or equal to zero)? If not what restrictions do I need to make it so? Or does that just depend on the function $u$","Is $$\int_{a}^{b} u^2(x,t) \, dx \, , \,\, 0\le t \le T$$ defined as the $L^2$-norm: $$|| u^2||_{2,[a,b]}^{2} $$ Always positive (or equal to zero)? If not what restrictions do I need to make it so? Or does that just depend on the function $u$",,"['real-analysis', 'multivariable-calculus', 'normed-spaces', 'fluid-dynamics']"
66,Mistake in Apostol's Calculus Volume II regarding inner products?,Mistake in Apostol's Calculus Volume II regarding inner products?,,"It looks like there is a completely miswritten formula in Apostol's Calculus, Volume II, regarding inner products. The formula states that:  ""If $x=(x_1,x_2)$ and $y=(y_1,y_2)$ are any two vectors in $V_2$, define $(x,y)$ by the formula $(x,y)=2x_1y_1+x_1y_2+x_2y_1+x_2y_2$. Through online research and consulting with a friend, it looks like $(x,y)=x_1y_1+x_2y_2$ is in fact the correct formula for inner products, but I wanted to make sure the book's version was not also correct, because this is more than a minute typo. Is there any validity to the book's definition?","It looks like there is a completely miswritten formula in Apostol's Calculus, Volume II, regarding inner products. The formula states that:  ""If $x=(x_1,x_2)$ and $y=(y_1,y_2)$ are any two vectors in $V_2$, define $(x,y)$ by the formula $(x,y)=2x_1y_1+x_1y_2+x_2y_1+x_2y_2$. Through online research and consulting with a friend, it looks like $(x,y)=x_1y_1+x_2y_2$ is in fact the correct formula for inner products, but I wanted to make sure the book's version was not also correct, because this is more than a minute typo. Is there any validity to the book's definition?",,['real-analysis']
67,"If $f$ is differentiable in $B(a)$ and $f(x) \leq f(a)$ for all $x$ in $B(a)$, then $\nabla f(a) = 0$","If  is differentiable in  and  for all  in , then",f B(a) f(x) \leq f(a) x B(a) \nabla f(a) = 0,"Assume $f$ is differentiable at each point of an n-ball $B(a)$. Prove that if $f(x) \leq f(a)$ for all $x$ in $B(a)$, then $\nabla {f(a)} = 0.$ I had my proof, but I'm not sure it is correct. Proof: Since f is differentiable at each point of the n-ball B(a), meaning $$\lim_{h \to 0} \frac{f(a+hy)-f(a)}{h} = \nabla f(a) \cdot y$$ , where y is an arbitrary unit vector. From the mean value theorem, we know that $$\lim_{h \to 0} \frac{f(a+hy)-f(a-hy)}{h} = \nabla f(c) \cdot y$$ for some c where $||c|| < r$. Since $$\lim_{h \to 0} \frac{f(a+hy)-f(a)}{h} = \nabla f(c) \cdot y = - \lim_{h \to 0} \frac{f(a)-f(a-hy)}{h}$$ Since the RHS of the the first equation is 0, we have $\nabla f(a) = 0$. So, is there any mistake of any suggestion about the point that I can improve mathematically or about the way that I wrote ?","Assume $f$ is differentiable at each point of an n-ball $B(a)$. Prove that if $f(x) \leq f(a)$ for all $x$ in $B(a)$, then $\nabla {f(a)} = 0.$ I had my proof, but I'm not sure it is correct. Proof: Since f is differentiable at each point of the n-ball B(a), meaning $$\lim_{h \to 0} \frac{f(a+hy)-f(a)}{h} = \nabla f(a) \cdot y$$ , where y is an arbitrary unit vector. From the mean value theorem, we know that $$\lim_{h \to 0} \frac{f(a+hy)-f(a-hy)}{h} = \nabla f(c) \cdot y$$ for some c where $||c|| < r$. Since $$\lim_{h \to 0} \frac{f(a+hy)-f(a)}{h} = \nabla f(c) \cdot y = - \lim_{h \to 0} \frac{f(a)-f(a-hy)}{h}$$ Since the RHS of the the first equation is 0, we have $\nabla f(a) = 0$. So, is there any mistake of any suggestion about the point that I can improve mathematically or about the way that I wrote ?",,"['multivariable-calculus', 'derivatives', 'proof-verification', 'proof-writing', 'vector-analysis']"
68,"Prove $f(x,y) = \frac{x^2+y^2}{x+y}$ is not continuous at $(0,0)$.",Prove  is not continuous at .,"f(x,y) = \frac{x^2+y^2}{x+y} (0,0)","Let $f(x,y) = \frac{x^2+y^2}{x+y}$ when $x+y \neq 0$ and $f(x,y) = 0$ when $x+y=0$. Prove $f$ is not continuous at $(0,0)$ in the $R^2$ norm. Is this as easy as noticing that the function is undefined on the line $y=-x$ and hence $$\lim_{x \to 0} f(x,-x) = \frac{2x^2}{x-x}$$ does not exist? Should this not be true in any norm then (even though the question specifically asks for the case of the $R^2$ norm)?","Let $f(x,y) = \frac{x^2+y^2}{x+y}$ when $x+y \neq 0$ and $f(x,y) = 0$ when $x+y=0$. Prove $f$ is not continuous at $(0,0)$ in the $R^2$ norm. Is this as easy as noticing that the function is undefined on the line $y=-x$ and hence $$\lim_{x \to 0} f(x,-x) = \frac{2x^2}{x-x}$$ does not exist? Should this not be true in any norm then (even though the question specifically asks for the case of the $R^2$ norm)?",,"['limits', 'multivariable-calculus', 'continuity']"
69,proving gradient of a function is always perpendicular to the contour lines,proving gradient of a function is always perpendicular to the contour lines,,"Can someone give an explanation of how such a proof would go, given a function example:   $y = f(x)$","Can someone give an explanation of how such a proof would go, given a function example:   $y = f(x)$",,['multivariable-calculus']
70,Is my understanding of space correct?,Is my understanding of space correct?,,"I'm learning more about dimensions in multivariable calc, and have been able to make connections by studying level curves and level surfaces.  I've learned that a function of 2 variables is really a 2 dimensional object and we can view and perceive it as 3D by looking at it in 3 space. A function of 3 variables is a 3 dimensional object but we cannot perceive this because it would require us to view it in 4 dimensions, but we can view special cases by drawing level surfaces.","I'm learning more about dimensions in multivariable calc, and have been able to make connections by studying level curves and level surfaces.  I've learned that a function of 2 variables is really a 2 dimensional object and we can view and perceive it as 3D by looking at it in 3 space. A function of 3 variables is a 3 dimensional object but we cannot perceive this because it would require us to view it in 4 dimensions, but we can view special cases by drawing level surfaces.",,"['multivariable-calculus', 'soft-question', 'low-dimensional-topology']"
71,"How to find the derivative of $F(t) = \int_0^t f(t, x) \, dx$?",How to find the derivative of ?,"F(t) = \int_0^t f(t, x) \, dx","Let $f: \mathbb{R}^2 \to \mathbb{R}$ be a continuous function. Define $F: \mathbb{R} \to \mathbb{R}$ by, $$ F(t) = \int_0^t f(t, x) \, dx $$ Then, I'm not sure how to get $F'$. If, there are functions $g$ and $h$ such that $f(t, x) = g(t)h(x)$, then of course we have $$ F(t) = \int_0^t f(t, x) \, dx = \int_0^t g(t)h(x) \, dx = g(t)\int_0^t h(x) \, dx $$ which can then be differentiated using the product rule. But apart from this special case, I don't know how to get $F'$.","Let $f: \mathbb{R}^2 \to \mathbb{R}$ be a continuous function. Define $F: \mathbb{R} \to \mathbb{R}$ by, $$ F(t) = \int_0^t f(t, x) \, dx $$ Then, I'm not sure how to get $F'$. If, there are functions $g$ and $h$ such that $f(t, x) = g(t)h(x)$, then of course we have $$ F(t) = \int_0^t f(t, x) \, dx = \int_0^t g(t)h(x) \, dx = g(t)\int_0^t h(x) \, dx $$ which can then be differentiated using the product rule. But apart from this special case, I don't know how to get $F'$.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
72,Using Spherical coordinates find the volume:,Using Spherical coordinates find the volume:,,"Inside the surfaces $z=x^2+y^2$ and $z=\sqrt{2-x^2-y^2}$ I integrated over the ranges: $0 \leq \theta \leq 2\pi$ $ 0 \leq \phi \leq \frac{\pi}{2}$ $0 \leq r \leq \sqrt{2}$ I get $\frac{\pi}{2}(4\sqrt{2} -4).$ There answer is the same except a $-\frac{7}{2}$ instead of the 4 at the end. Obviously I'm missing a 1\2 but I seems, I can not find it.","Inside the surfaces $z=x^2+y^2$ and $z=\sqrt{2-x^2-y^2}$ I integrated over the ranges: $0 \leq \theta \leq 2\pi$ $ 0 \leq \phi \leq \frac{\pi}{2}$ $0 \leq r \leq \sqrt{2}$ I get $\frac{\pi}{2}(4\sqrt{2} -4).$ There answer is the same except a $-\frac{7}{2}$ instead of the 4 at the end. Obviously I'm missing a 1\2 but I seems, I can not find it.",,"['multivariable-calculus', 'integration']"
73,"Finding critical points of f(x,y)","Finding critical points of f(x,y)",,"Find the critical point of $$ f(x,y) = 3x^3 + 3y^3 + x^3y^3 $$ To do this, I know that I need to set $$f_y = 0, f_x = 0 $$ So $$f_x= 9x^2 + 3x^2y^3$$ $$f_y = 9y^2 + 3y^2x^3$$ Then you solve for x,  but substituting these two equations into each other. But somehow I ended up with $$x = y$$ and thats not very helpful. Is there something I did wrong or misunderstood?","Find the critical point of $$ f(x,y) = 3x^3 + 3y^3 + x^3y^3 $$ To do this, I know that I need to set $$f_y = 0, f_x = 0 $$ So $$f_x= 9x^2 + 3x^2y^3$$ $$f_y = 9y^2 + 3y^2x^3$$ Then you solve for x,  but substituting these two equations into each other. But somehow I ended up with $$x = y$$ and thats not very helpful. Is there something I did wrong or misunderstood?",,['multivariable-calculus']
74,Changing order of integration,Changing order of integration,,"Change the order of integration of the following and evaluate the integral: $$\int_{-1}^{0} \int_{-1}^y y\sqrt{x^2 + y^2} \, dx \, dy$$ I know I have to draw out the graph but im having a hard time with that... any pointers?","Change the order of integration of the following and evaluate the integral: $$\int_{-1}^{0} \int_{-1}^y y\sqrt{x^2 + y^2} \, dx \, dy$$ I know I have to draw out the graph but im having a hard time with that... any pointers?",,"['integration', 'multivariable-calculus']"
75,Issue with textbook exercise on vectors,Issue with textbook exercise on vectors,,"the following is a question from my textbook on vectors: EDIT: Added text, so that the post is self-contained even without the picture. The points $A$ and $B$ have position vectors $\begin{pmatrix}2\\9\\t\end{pmatrix}$ and $\begin{pmatrix}2t\\5\\3t\end{pmatrix}$ respectively. a. Find $\vec{AB}$. b. Find, in terms of $t$, $|\vec{AB}|$. c. Find the value of $t$ which makes $|\vec{AB}|$ a minimum. d. Find the minimum value of $|\vec{AB}|$. My issue is with part C. I accept the textbook's solution, as mine gives an incorrect answer but do not understand why their method is acceptable. Since the exercise is to find the value of t that makes vector AB a minimum, why is it acceptable to square vector AB and then differentiate, rather than just differentiating vector AB as it is, using the chain rule? I see how this leads to the problem of two t values, rather than one, but I didn't feel that it would be acceptable to just ignore one by squaring, and changing the original formula. What am I misunderstanding here? EDIT: Added text. (a) $\vec{AB}=\mathbf{b}-\mathbf{a}=\begin{pmatrix}2\\9\\t\end{pmatrix}-\begin{pmatrix}2t\\5\\3t\end{pmatrix} =\begin{pmatrix}2-2t\\-4\\2t\end{pmatrix}$ (b) $\begin{align}|\vec{AB}|&=\sqrt{(2-2t)^2+(-4)^2+{2t}^2}\\ &=\sqrt{4t^2-8t+4+16+4t^2}\\ &=\sqrt{8t^2-8t+20} \end{align}$ (c) Let $|\vec{AB}|^2=p$, then $p=8t^2-8t+20$ and $\frac{\mathrm{d}p}{\mathrm{d}t}=16t-8$ Thanks!","the following is a question from my textbook on vectors: EDIT: Added text, so that the post is self-contained even without the picture. The points $A$ and $B$ have position vectors $\begin{pmatrix}2\\9\\t\end{pmatrix}$ and $\begin{pmatrix}2t\\5\\3t\end{pmatrix}$ respectively. a. Find $\vec{AB}$. b. Find, in terms of $t$, $|\vec{AB}|$. c. Find the value of $t$ which makes $|\vec{AB}|$ a minimum. d. Find the minimum value of $|\vec{AB}|$. My issue is with part C. I accept the textbook's solution, as mine gives an incorrect answer but do not understand why their method is acceptable. Since the exercise is to find the value of t that makes vector AB a minimum, why is it acceptable to square vector AB and then differentiate, rather than just differentiating vector AB as it is, using the chain rule? I see how this leads to the problem of two t values, rather than one, but I didn't feel that it would be acceptable to just ignore one by squaring, and changing the original formula. What am I misunderstanding here? EDIT: Added text. (a) $\vec{AB}=\mathbf{b}-\mathbf{a}=\begin{pmatrix}2\\9\\t\end{pmatrix}-\begin{pmatrix}2t\\5\\3t\end{pmatrix} =\begin{pmatrix}2-2t\\-4\\2t\end{pmatrix}$ (b) $\begin{align}|\vec{AB}|&=\sqrt{(2-2t)^2+(-4)^2+{2t}^2}\\ &=\sqrt{4t^2-8t+4+16+4t^2}\\ &=\sqrt{8t^2-8t+20} \end{align}$ (c) Let $|\vec{AB}|^2=p$, then $p=8t^2-8t+20$ and $\frac{\mathrm{d}p}{\mathrm{d}t}=16t-8$ Thanks!",,"['calculus', 'multivariable-calculus', 'optimization']"
76,A manifold admits a non-vanishing top form iff it has an oriented atlas. Do we need connectedness here?,A manifold admits a non-vanishing top form iff it has an oriented atlas. Do we need connectedness here?,,"I appreciate anyone who can provide help. This is a theorem in sec. 20.4 of Loring Tu's book ""An introduction to manifolds"" The theorem is the following, A manifold admits a non-vanishing top form iff it has an oriented atlas. I manage to show one direction. The part that confuses me is that if we assume the top form, we want to show there is an oriented atlas. Say we have a top form $\omega$ , then pick a chart $(U,x)$ , we know that $$\omega=fdx^1\wedge...\wedge dx^n$$ on the coordinate open set $U$ . But then the book say either $f>0$ or $f<0$ . I cannot see why this is the case without connectedness assumed.","I appreciate anyone who can provide help. This is a theorem in sec. 20.4 of Loring Tu's book ""An introduction to manifolds"" The theorem is the following, A manifold admits a non-vanishing top form iff it has an oriented atlas. I manage to show one direction. The part that confuses me is that if we assume the top form, we want to show there is an oriented atlas. Say we have a top form , then pick a chart , we know that on the coordinate open set . But then the book say either or . I cannot see why this is the case without connectedness assumed.","\omega (U,x) \omega=fdx^1\wedge...\wedge dx^n U f>0 f<0","['multivariable-calculus', 'differential-geometry', 'differential-topology']"
77,"What is $\lim_{(x,y) \to (0,0)} \dfrac{1 - \cos x}{x+y}$?",What is ?,"\lim_{(x,y) \to (0,0)} \dfrac{1 - \cos x}{x+y}","I want to understand this multivariate limit. WolframAlpha says $\lim_{(x,y) \to (0,0)} \dfrac{1 - \cos x}{x+y} = 0$ But what if I take a curve $y = -x$ , then the limit doesn't exist, right? Wouldn't this make the limit inexistent? I tried to prove using sandwich theorem and definition, but didn't get anything good. Any help would be appreciated.","I want to understand this multivariate limit. WolframAlpha says But what if I take a curve , then the limit doesn't exist, right? Wouldn't this make the limit inexistent? I tried to prove using sandwich theorem and definition, but didn't get anything good. Any help would be appreciated.","\lim_{(x,y) \to (0,0)} \dfrac{1 - \cos x}{x+y} = 0 y = -x",['calculus']
78,Does a Line Integral that sums to a vector exist ? And is it useful?,Does a Line Integral that sums to a vector exist ? And is it useful?,,We know that we can integrate a vector field on a curve to get a scalar sum: this is how the line integral is defined. Is there a use for another sort of integral whose sum is a vector ? I can't seem to find that defined anywhere.,We know that we can integrate a vector field on a curve to get a scalar sum: this is how the line integral is defined. Is there a use for another sort of integral whose sum is a vector ? I can't seem to find that defined anywhere.,,"['multivariable-calculus', 'vector-analysis', 'vector-fields']"
79,Integral of a two dimensional function,Integral of a two dimensional function,,"A function is defined by $$f(x,y) = \int_{x^2}^{xy} e^{t^2} \,dt$$ We are to decide the partial derivatives of the function. I am quite unsure whether this is a trick question because we could do an approximation of the integrand with the Taylor series, but I can't see how that would simplify the work. Could I just get a direction to as how I should approach this problem? I would very much not like to just get the solution. Note that this is one of the easiest questions on the paper.","A function is defined by We are to decide the partial derivatives of the function. I am quite unsure whether this is a trick question because we could do an approximation of the integrand with the Taylor series, but I can't see how that would simplify the work. Could I just get a direction to as how I should approach this problem? I would very much not like to just get the solution. Note that this is one of the easiest questions on the paper.","f(x,y) = \int_{x^2}^{xy} e^{t^2} \,dt",['multivariable-calculus']
80,"How to find the equation of plane given 3 points: $(a,0,0), (0,b,0),(0,0,c)$?",How to find the equation of plane given 3 points: ?,"(a,0,0), (0,b,0),(0,0,c)","Find the equation of plane given 3 points: $(a,0,0), (0,b,0), (0,0,c)$. The way I would go about this is first finding two vectors: $$ \overrightarrow{AB}=(0,b,0)-(a,0,0)=\langle -a,b,0\rangle\\ \overrightarrow{AC}=(0,0,c)-(a,0,0)=\langle -a,0,c\rangle $$ Then we can get the normal vector by doing a cross product: $$ \overrightarrow{AB}\times\overrightarrow{AC}=\langle -bc,-ac,-ab\rangle $$ so the plane equation is something like: $$ -bcx-acy-abz+d=0 $$ plug in one of the points for example $(a,0,0)$ to find $d$: $$ -bcx-acy-abz+abc=0 $$ What I came across is another plane equation for these points: $$ \frac{x}{a}+\frac{y}{b}+\frac{z}{c}=1 $$ which is inarguably much simpler. How does one arrive to this representation?","Find the equation of plane given 3 points: $(a,0,0), (0,b,0), (0,0,c)$. The way I would go about this is first finding two vectors: $$ \overrightarrow{AB}=(0,b,0)-(a,0,0)=\langle -a,b,0\rangle\\ \overrightarrow{AC}=(0,0,c)-(a,0,0)=\langle -a,0,c\rangle $$ Then we can get the normal vector by doing a cross product: $$ \overrightarrow{AB}\times\overrightarrow{AC}=\langle -bc,-ac,-ab\rangle $$ so the plane equation is something like: $$ -bcx-acy-abz+d=0 $$ plug in one of the points for example $(a,0,0)$ to find $d$: $$ -bcx-acy-abz+abc=0 $$ What I came across is another plane equation for these points: $$ \frac{x}{a}+\frac{y}{b}+\frac{z}{c}=1 $$ which is inarguably much simpler. How does one arrive to this representation?",,"['multivariable-calculus', 'proof-explanation']"
81,Why is my solution incorrect?,Why is my solution incorrect?,,I was trying to compute this limit: $$\lim_{x \to 0}\lim_{y \to 0} (x+y)\sin{\frac{x}{y}}$$ And this is my solution: $$\lim_{x \to 0}\lim_{y \to 0}|(x+y)\sin{\frac{x}{y}}|\leq\lim_{x \to 0}\lim_{y \to 0} |(x+y)|=0$$ So I got the limit 0. The answer was different. I have no idea what is wrong with my solution?,I was trying to compute this limit: $$\lim_{x \to 0}\lim_{y \to 0} (x+y)\sin{\frac{x}{y}}$$ And this is my solution: $$\lim_{x \to 0}\lim_{y \to 0}|(x+y)\sin{\frac{x}{y}}|\leq\lim_{x \to 0}\lim_{y \to 0} |(x+y)|=0$$ So I got the limit 0. The answer was different. I have no idea what is wrong with my solution?,,"['calculus', 'real-analysis', 'limits', 'multivariable-calculus']"
82,Prove that $\int_0^1\frac{x^y-1}{\log x}\mathrm dx=\log(1+y)$,Prove that,\int_0^1\frac{x^y-1}{\log x}\mathrm dx=\log(1+y),"The title says it all - I currently can't find a good way to start. Tried rewriting it into a line integral, but I really don't see a way to solve this right now. I'd appreciate any hints.","The title says it all - I currently can't find a good way to start. Tried rewriting it into a line integral, but I really don't see a way to solve this right now. I'd appreciate any hints.",,"['integration', 'analysis', 'multivariable-calculus', 'logarithms']"
83,"Find $\lim_{(x,y) \to (0,0)} \frac{\sin(x^3y^2)}{(x^2+y^2)^2}$",Find,"\lim_{(x,y) \to (0,0)} \frac{\sin(x^3y^2)}{(x^2+y^2)^2}","Find $$\lim_{(x,y) \to (0,0)}  \frac{\sin(x^3y^2)}{(x^2+y^2)^2}$$ I tried multiplying $x^3y^3$ the nominator and denominator, didn't work. I tried the polar way too, $x = r \cos\phi$, $y=r \sin\phi$,$x^2 + y^2 = r^2$ too. which gives me $\frac{""0""}{""0""}$ I tried proving that this limit doesn't exist but wolfram shows that its limit is zero. Can anyone give me a hint on how to approach this?","Find $$\lim_{(x,y) \to (0,0)}  \frac{\sin(x^3y^2)}{(x^2+y^2)^2}$$ I tried multiplying $x^3y^3$ the nominator and denominator, didn't work. I tried the polar way too, $x = r \cos\phi$, $y=r \sin\phi$,$x^2 + y^2 = r^2$ too. which gives me $\frac{""0""}{""0""}$ I tried proving that this limit doesn't exist but wolfram shows that its limit is zero. Can anyone give me a hint on how to approach this?",,"['limits', 'multivariable-calculus']"
84,Prove that the area of a region is $\int _{C} x dy = -\int _C ydx$ using Green's Theorem,Prove that the area of a region is  using Green's Theorem,\int _{C} x dy = -\int _C ydx,"If $\mathbf{c}$ is a simple closed plane curve whose image bounds a region R, and which is traversed counterclockwise, then the area of R is $\int _{c} x dy = -\int _c ydx$, where x and y are the coordinates of the plane. Prove this using Green's Theorem. Attempt: Area = $\int\int_R 1dA$. If we take some P(x,y) and Q(x,y) such that ($\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}$) = 1, then $\int\int_R (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y})$ dA. By Green's Theorem $\int\int_R (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y})$ dA = $\int_c Pdx + Qdy$. Now since ($\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}$) = 1 there are different possibilities for P(x,y) and Q(x,y), but I don't know how to find all of the different possibilities. Any help is appreciated.","If $\mathbf{c}$ is a simple closed plane curve whose image bounds a region R, and which is traversed counterclockwise, then the area of R is $\int _{c} x dy = -\int _c ydx$, where x and y are the coordinates of the plane. Prove this using Green's Theorem. Attempt: Area = $\int\int_R 1dA$. If we take some P(x,y) and Q(x,y) such that ($\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}$) = 1, then $\int\int_R (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y})$ dA. By Green's Theorem $\int\int_R (\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y})$ dA = $\int_c Pdx + Qdy$. Now since ($\frac{\partial Q}{\partial x} - \frac{\partial P}{\partial y}$) = 1 there are different possibilities for P(x,y) and Q(x,y), but I don't know how to find all of the different possibilities. Any help is appreciated.",,"['multivariable-calculus', 'differential-geometry', 'greens-theorem']"
85,Maximum value of $ x^2 + y^2 $ given $4 x^4 + 9 y^4 = 64$ [closed],Maximum value of  given  [closed], x^2 + y^2  4 x^4 + 9 y^4 = 64,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question It is given that $4 x^4 + 9 y^4 = 64$. Then what will be the maximum value of $x^2 + y^2$? I have done it using the sides of a right-angled triangle be $2x , 3y $ and hypotenuse as 8 .","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question It is given that $4 x^4 + 9 y^4 = 64$. Then what will be the maximum value of $x^2 + y^2$? I have done it using the sides of a right-angled triangle be $2x , 3y $ and hypotenuse as 8 .",,"['calculus', 'multivariable-calculus', 'optimization']"
86,Very Tricky Double Integral Problem,Very Tricky Double Integral Problem,,"Evaluate the Integral: \begin{align} \int_{0}^{4}\int_{\sqrt{x}}^{2}{\mathrm{d} y\,\mathrm{d}x \over 1 + y^{3}} \end{align} I can't understand how this would be possible. There IS a formula for evaluating $1/\left(1+y^{3}\right)$ , but it becomes an extremely complicated mess that I can't imagine could be re-integrated. Is there a simplification technique that I'm missing here $?$ .","Evaluate the Integral: I can't understand how this would be possible. There IS a formula for evaluating , but it becomes an extremely complicated mess that I can't imagine could be re-integrated. Is there a simplification technique that I'm missing here .","\begin{align}
\int_{0}^{4}\int_{\sqrt{x}}^{2}{\mathrm{d} y\,\mathrm{d}x \over 1 + y^{3}}
\end{align} 1/\left(1+y^{3}\right) ?","['integration', 'multivariable-calculus', 'definite-integrals']"
87,"Prove that $\lim \limits_{(x,y,z) \to (0,0,0)} \frac{{xyz}}{{x+y+z}}=0$",Prove that,"\lim \limits_{(x,y,z) \to (0,0,0)} \frac{{xyz}}{{x+y+z}}=0","I have a strong feeling that the following limit is zero, can anybody help me prove it. $ \lim\limits_{(x,y,z) \to (0,0,0)} \frac{{xyz}}{{x+y+z}}$ Thanks!","I have a strong feeling that the following limit is zero, can anybody help me prove it. $ \lim\limits_{(x,y,z) \to (0,0,0)} \frac{{xyz}}{{x+y+z}}$ Thanks!",,"['limits', 'multivariable-calculus']"
88,"$\lim _{(x,y)\to(0,0)}\frac{x(x-y)}{x^4+y^4}$ does not exists",does not exists,"\lim _{(x,y)\to(0,0)}\frac{x(x-y)}{x^4+y^4}","Show that $$\lim_{(x,y)\to(0,0)} \frac{xy(x-y)}{x^4+y^4}$$ does not exists. I've tried the ""traditional"" paths, with $(x,x)$, $(0,x)$, $(0,-x)$, but I only get $0$ as answer. Any hint? Thanks!","Show that $$\lim_{(x,y)\to(0,0)} \frac{xy(x-y)}{x^4+y^4}$$ does not exists. I've tried the ""traditional"" paths, with $(x,x)$, $(0,x)$, $(0,-x)$, but I only get $0$ as answer. Any hint? Thanks!",,"['limits', 'multivariable-calculus']"
89,Multivariable limit of rational function,Multivariable limit of rational function,,"Does the following limit exist? $$\lim_{(x,y) \to (0,0)}\frac{x^2y^3}{x^4+(x^2+y^3)^2}$$ I tried to solve this problem using polar coordinates, but I can't simplify it. I tried the squeeze theorem, I got $0.5$, but I think this is incorrect.","Does the following limit exist? $$\lim_{(x,y) \to (0,0)}\frac{x^2y^3}{x^4+(x^2+y^3)^2}$$ I tried to solve this problem using polar coordinates, but I can't simplify it. I tried the squeeze theorem, I got $0.5$, but I think this is incorrect.",,"['limits', 'multivariable-calculus']"
90,"Finding $\lim_{(x,y) \to 0} \frac{x^2}{ x - y}$",Finding,"\lim_{(x,y) \to 0} \frac{x^2}{ x - y}","This is not help with homework. I just had this question on our final exam and was wondering what the answer was. $$\lim_{x,y \to 0} \frac{x^2}{x-y}$$ I tried to use polar coordinates. So, $$\lim_{r\to0^+} \frac{r^2\cos^2\theta}{r(\cos \theta - \sin \theta)}$$ $$= \lim_{r\to0^+} \frac{r\cos^2\theta}{\cos \theta - \sin \theta}$$ I get stuck here. Wolfram alpha says it does not exist. Could somebody provide insight as to where I went wrong?","This is not help with homework. I just had this question on our final exam and was wondering what the answer was. $$\lim_{x,y \to 0} \frac{x^2}{x-y}$$ I tried to use polar coordinates. So, $$\lim_{r\to0^+} \frac{r^2\cos^2\theta}{r(\cos \theta - \sin \theta)}$$ $$= \lim_{r\to0^+} \frac{r\cos^2\theta}{\cos \theta - \sin \theta}$$ I get stuck here. Wolfram alpha says it does not exist. Could somebody provide insight as to where I went wrong?",,"['limits', 'multivariable-calculus']"
91,Shortest distance between ellipse and a line,Shortest distance between ellipse and a line,,"I was trying to find the shortest distance between the ellipse $$\frac{x^2}{4} + y^2 = 1$$ and the line $x+y=4$. We have to find the point on the ellipse where  its tangent line is parallel to $x+y=4$ and find the distance between those two points.  However, when I used the implicit differentiation, I get $$\frac{x}{2} + 2y\frac{dy}{dx} = 0$$ $$\frac{dy}{dx} = \frac{-x}{4y}$$ If it's parallel to $x+y=4$, then we need $x=4y$. Do I just plug it into ellipse equation and solve for it and calculate the distance between the point and a line or am I doing it wrong? I just wanted to clarify. Any help would be appreciated. Thanks!","I was trying to find the shortest distance between the ellipse $$\frac{x^2}{4} + y^2 = 1$$ and the line $x+y=4$. We have to find the point on the ellipse where  its tangent line is parallel to $x+y=4$ and find the distance between those two points.  However, when I used the implicit differentiation, I get $$\frac{x}{2} + 2y\frac{dy}{dx} = 0$$ $$\frac{dy}{dx} = \frac{-x}{4y}$$ If it's parallel to $x+y=4$, then we need $x=4y$. Do I just plug it into ellipse equation and solve for it and calculate the distance between the point and a line or am I doing it wrong? I just wanted to clarify. Any help would be appreciated. Thanks!",,"['calculus', 'multivariable-calculus']"
92,Demonstrate that the limit of a function of two variables does not exist,Demonstrate that the limit of a function of two variables does not exist,,"From my multivariable textbook: $$\lim_{|x,y|\to|0,0|}\frac{y^2\sin^2 x}{x^4+y^4}$$ (original screenshot) Wolfram indicates that the limit DNE, but does not list the steps used to solve. Is there a particular substitution that I'm overlooking?","From my multivariable textbook: $$\lim_{|x,y|\to|0,0|}\frac{y^2\sin^2 x}{x^4+y^4}$$ (original screenshot) Wolfram indicates that the limit DNE, but does not list the steps used to solve. Is there a particular substitution that I'm overlooking?",,"['limits', 'functions', 'multivariable-calculus']"
93,Evaluate an iterated integral by reversing the order of integration,Evaluate an iterated integral by reversing the order of integration,,"I'm not sure if I am doing something wrong or if the question has a typo... $$\int\limits_{0}^{3}\!\!\int\limits_{x^{2}}^{9}xe^{y^{2}}\mathsf{d}y\ \mathsf{d}x$$ I notice that $0\leq x\leq 3$ and $x^{2}\leq y\leq 9$. Given these bounds, when I reverse the order I'm coming up with $0\leq y\leq 9$ and $\sqrt{y}\leq x\leq 3$... $$\int\limits_{0}^{9}\!\!\int\limits_{\sqrt{y}}^{3}xe^{y^{2}}\mathsf{d}x\ \mathsf{d}y$$ So now I can easily integrate with respect to x, but I get stuck on the next step... $$\int\limits_{0}^{9}\frac{1}{2}\left[9e^{y^{2}}-ye^{y^{2}}\right]\mathsf{d}y$$ I can integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}ye^{y^{2}}\mathsf{d}y$ with no problem, but I don't see how I can easily integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}9e^{y^{2}}\mathsf{d}y$.","I'm not sure if I am doing something wrong or if the question has a typo... $$\int\limits_{0}^{3}\!\!\int\limits_{x^{2}}^{9}xe^{y^{2}}\mathsf{d}y\ \mathsf{d}x$$ I notice that $0\leq x\leq 3$ and $x^{2}\leq y\leq 9$. Given these bounds, when I reverse the order I'm coming up with $0\leq y\leq 9$ and $\sqrt{y}\leq x\leq 3$... $$\int\limits_{0}^{9}\!\!\int\limits_{\sqrt{y}}^{3}xe^{y^{2}}\mathsf{d}x\ \mathsf{d}y$$ So now I can easily integrate with respect to x, but I get stuck on the next step... $$\int\limits_{0}^{9}\frac{1}{2}\left[9e^{y^{2}}-ye^{y^{2}}\right]\mathsf{d}y$$ I can integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}ye^{y^{2}}\mathsf{d}y$ with no problem, but I don't see how I can easily integrate $\displaystyle\frac{1}{2}\int\limits_{0}^{9}9e^{y^{2}}\mathsf{d}y$.",,['multivariable-calculus']
94,"Evaluating $\int_{0}^1\int_{0}^1 xy\sqrt{x^2+y^2}\,dy\,dx$",Evaluating,"\int_{0}^1\int_{0}^1 xy\sqrt{x^2+y^2}\,dy\,dx","Calculate the iterated integral: $$\int_{0}^1\int_{0}^1 xy\sqrt{x^2+y^2}\,dy\,dx$$ I'm stumped with this problem. Should I do integration by parts with both variables or is there another way to do this? If someone could help me out, that would grand!","Calculate the iterated integral: $$\int_{0}^1\int_{0}^1 xy\sqrt{x^2+y^2}\,dy\,dx$$ I'm stumped with this problem. Should I do integration by parts with both variables or is there another way to do this? If someone could help me out, that would grand!",,"['multivariable-calculus', 'integration']"
95,$x^4+y^4 \geq \frac{(x^2+y^2)^2}{2}$,,x^4+y^4 \geq \frac{(x^2+y^2)^2}{2},"I'm doing some exercise to prepare for my multivariable analysis exam. I didn't understand the second part of this question. Given the function $$f(x,y)=(x^2+y^2+1)^2 - 2(x^2+y^2) +4\cos(xy)$$ Prove that the taylor polynomial of degree $4$ of $f$ is equal to   $5+x^4+y^4$. First, $4\cos(xy) = 4 - 2(xy)^2 + 4R_3 $ $(x^2+y^2+1)^2=x^4+2 x^2 y^2+2 x^2+y^4+2 y^2+1$ Therefore: $(x^2+y^2+1)^2 - 2(x^2+y^2)=x^4+2 x^2 y^2+y^4+1$ Therefore: $f(x,y)=x^4+y^4+5+4R_3$ I don't know exactly why I can now conclude that Taylor Polynomial of degree 4 must be $5+x^4+y^4$, but I don't know exactly why. Now the second question is: $x^4+y^4 \geq \frac{(x^2+y^2)^2}{2}$ New edit I understand this now thanks to hint of Hagen von Eitzen, thanks ! The third question is: Determine what kind of stationary point you have in $(0,0)$.","I'm doing some exercise to prepare for my multivariable analysis exam. I didn't understand the second part of this question. Given the function $$f(x,y)=(x^2+y^2+1)^2 - 2(x^2+y^2) +4\cos(xy)$$ Prove that the taylor polynomial of degree $4$ of $f$ is equal to   $5+x^4+y^4$. First, $4\cos(xy) = 4 - 2(xy)^2 + 4R_3 $ $(x^2+y^2+1)^2=x^4+2 x^2 y^2+2 x^2+y^4+2 y^2+1$ Therefore: $(x^2+y^2+1)^2 - 2(x^2+y^2)=x^4+2 x^2 y^2+y^4+1$ Therefore: $f(x,y)=x^4+y^4+5+4R_3$ I don't know exactly why I can now conclude that Taylor Polynomial of degree 4 must be $5+x^4+y^4$, but I don't know exactly why. Now the second question is: $x^4+y^4 \geq \frac{(x^2+y^2)^2}{2}$ New edit I understand this now thanks to hint of Hagen von Eitzen, thanks ! The third question is: Determine what kind of stationary point you have in $(0,0)$.",,"['real-analysis', 'multivariable-calculus']"
96,Evaluating $ \int_0^1 \int_y^1 \sqrt{1+x^2} dx dy $,Evaluating, \int_0^1 \int_y^1 \sqrt{1+x^2} dx dy ,$$   \int_0^1 \int_y^1 \sqrt{1+x^2} dx dy $$ I've tried switching the order as per fubini theorem to $\int_y^1 \int_0^1 \sqrt{(1+x^2)} dy dx$ and managed to get $\int_y^1 \sqrt{(1+x^2)} dx$ but am stuck there. How do i continue integrating?,$$   \int_0^1 \int_y^1 \sqrt{1+x^2} dx dy $$ I've tried switching the order as per fubini theorem to $\int_y^1 \int_0^1 \sqrt{(1+x^2)} dy dx$ and managed to get $\int_y^1 \sqrt{(1+x^2)} dx$ but am stuck there. How do i continue integrating?,,['multivariable-calculus']
97,Continuity of a function involving dot product,Continuity of a function involving dot product,,"Let $\lambda \in \mathbb{R}$ and Let $A$ be a linear operator on $\mathbb{R}^3$. Define $f:\mathbb{R}^3 \to \mathbb{R}$ by $f(x):=\langle A(x),x\rangle- \lambda \langle x,x\rangle $ where $\langle,\rangle$ is the usual dot product on $\mathbb{R}^3$. Does $\lim_{x\rightarrow0}\frac{f(x)}{|x|}$ exist? My computation:  $$\begin{align*} \lim_{x\rightarrow0}\frac{f(x)}{|x|} &=\lim_{x\rightarrow0}\frac{\langle A(x)-\lambda x,x\rangle}{|x|} \\ &=\lim_{x\rightarrow0}\frac{|A(x)-\lambda x||x|\cos \theta_{x}}{|x|} \\ &=\lim_{x\rightarrow0}|A(x)-\lambda x|\cos \theta_{x}=0\end{align*}$$ where $\theta_{x}$ is the angle between $A(x)-\lambda x$ and $x$. I wonder whether $\theta_{x}$ is continuous? If yes, then my computation is ok.","Let $\lambda \in \mathbb{R}$ and Let $A$ be a linear operator on $\mathbb{R}^3$. Define $f:\mathbb{R}^3 \to \mathbb{R}$ by $f(x):=\langle A(x),x\rangle- \lambda \langle x,x\rangle $ where $\langle,\rangle$ is the usual dot product on $\mathbb{R}^3$. Does $\lim_{x\rightarrow0}\frac{f(x)}{|x|}$ exist? My computation:  $$\begin{align*} \lim_{x\rightarrow0}\frac{f(x)}{|x|} &=\lim_{x\rightarrow0}\frac{\langle A(x)-\lambda x,x\rangle}{|x|} \\ &=\lim_{x\rightarrow0}\frac{|A(x)-\lambda x||x|\cos \theta_{x}}{|x|} \\ &=\lim_{x\rightarrow0}|A(x)-\lambda x|\cos \theta_{x}=0\end{align*}$$ where $\theta_{x}$ is the angle between $A(x)-\lambda x$ and $x$. I wonder whether $\theta_{x}$ is continuous? If yes, then my computation is ok.",,"['real-analysis', 'limits', 'multivariable-calculus']"
98,"Multivariable limit $\lim\limits_{(x,y,z) \rightarrow (0,0,0)} \frac{xy+2yz+3xz}{x^2+4y^2+9z^2}$",Multivariable limit,"\lim\limits_{(x,y,z) \rightarrow (0,0,0)} \frac{xy+2yz+3xz}{x^2+4y^2+9z^2}","The problem is: $$\displaystyle \lim_{(x,y,z) \rightarrow (0,0,0)} \frac{xy+2yz+3xz}{x^2+4y^2+9z^2}.$$ The tutor guessed it didn't exist, and he was correct. However, I'd like to understand why it doesn't exist. I think I have to turn it into spherical coordinates and then see if the end result depends on an angle, like I've done for two variables with polar coordinates. I don't know how though. I know $\rho = \sqrt{x^2+y^2+z^2}$ and $\theta = \arctan \left(\frac{y}{x} \right)$ and $\phi = \arccos \left( \frac{z}{\rho} \right)$, but how on earth do I break this thing up?","The problem is: $$\displaystyle \lim_{(x,y,z) \rightarrow (0,0,0)} \frac{xy+2yz+3xz}{x^2+4y^2+9z^2}.$$ The tutor guessed it didn't exist, and he was correct. However, I'd like to understand why it doesn't exist. I think I have to turn it into spherical coordinates and then see if the end result depends on an angle, like I've done for two variables with polar coordinates. I don't know how though. I know $\rho = \sqrt{x^2+y^2+z^2}$ and $\theta = \arctan \left(\frac{y}{x} \right)$ and $\phi = \arccos \left( \frac{z}{\rho} \right)$, but how on earth do I break this thing up?",,['multivariable-calculus']
99,Why a vector function to $\mathbb{R}^n$ can be regarded as $n$ different functions?,Why a vector function to  can be regarded as  different functions?,\mathbb{R}^n n,"I am taking advanced calculus, and the professor said the following: we can regard $f: U \rightarrow \mathbb{R}^n$ as $n$ different functions, and write $f = (f_1,...,f_n)$ ."" I am not sure what the rigorous justification for representing the vector-valued function as $f = (f_1,...,f_n)$ (i.e. why we can write $f$ as $f = (f_1,...,f_n)$ ). How do we know that each component of the vector is a function of $p \in U$ ? I thought of the following: Since $f: U \rightarrow \mathbb{R}^n$ , then we know that $f(p)\in\mathbb{R}^n$ , and thus we can write $f(p)$ as $f = (f_1,...,f_n)$ , where $f_i$ are the components of $f(p)$ . we can say that $f$ is comprised of $n$ different functions because when writing $f_i = \langle f, \mathbf{e}_i \rangle$ , we have $n$ different functions from $U$ to $\mathbb{R}^n$ , so (I hope so) this answers why we can think of $f$ as being made of $n$ functions. but why $f_i$ is function? how do we know that each component of $f$ is a function on its own? I think that we have already established this on the previous point - since $f_i = (f,\mathbf{e}_i)$ , it is a composition of two functions ( $(*,\mathbf{e}_i): U \rightarrow \mathbb{R}$ composed over $f$ ), and thus is a function (or alternatively, say that $f_i = \pi_i \circ f$ which is again a function since it is the composition of the projection function over $f$ ). But I feel like I lack the ""intuitive"" understanding of why this is true... the only intuitive (and contorted) explanation I came close to is the following: Since $f$ is a vector-valued function, we know that $f(p) \in \mathbb{R}^n$ , and since it is a vector, we know that the vector and its components are equivalent. Since we know that $p$ determines $f(p)$ and that it is equivalent to its components because it is a vector, we can say that each of its components is also a function of $p$ . I would be grateful if you could make these points clearer (and maybe provide a formal definition, as I think that the cause for my misunderstanding is the lack of a formal definition. I looked for formal definitions in the literature (Ruding for example, but since it is very basic I wasn't able to find any rigid and rigorous definitions there).","I am taking advanced calculus, and the professor said the following: we can regard as different functions, and write ."" I am not sure what the rigorous justification for representing the vector-valued function as (i.e. why we can write as ). How do we know that each component of the vector is a function of ? I thought of the following: Since , then we know that , and thus we can write as , where are the components of . we can say that is comprised of different functions because when writing , we have different functions from to , so (I hope so) this answers why we can think of as being made of functions. but why is function? how do we know that each component of is a function on its own? I think that we have already established this on the previous point - since , it is a composition of two functions ( composed over ), and thus is a function (or alternatively, say that which is again a function since it is the composition of the projection function over ). But I feel like I lack the ""intuitive"" understanding of why this is true... the only intuitive (and contorted) explanation I came close to is the following: Since is a vector-valued function, we know that , and since it is a vector, we know that the vector and its components are equivalent. Since we know that determines and that it is equivalent to its components because it is a vector, we can say that each of its components is also a function of . I would be grateful if you could make these points clearer (and maybe provide a formal definition, as I think that the cause for my misunderstanding is the lack of a formal definition. I looked for formal definitions in the literature (Ruding for example, but since it is very basic I wasn't able to find any rigid and rigorous definitions there).","f: U \rightarrow \mathbb{R}^n n f = (f_1,...,f_n) f = (f_1,...,f_n) f f = (f_1,...,f_n) p \in U f: U \rightarrow \mathbb{R}^n f(p)\in\mathbb{R}^n f(p) f = (f_1,...,f_n) f_i f(p) f n f_i = \langle f, \mathbf{e}_i \rangle n U \mathbb{R}^n f n f_i f f_i = (f,\mathbf{e}_i) (*,\mathbf{e}_i): U \rightarrow \mathbb{R} f f_i = \pi_i \circ f f f f(p) \in \mathbb{R}^n p f(p) p","['calculus', 'multivariable-calculus', 'elementary-set-theory', 'intuition']"
