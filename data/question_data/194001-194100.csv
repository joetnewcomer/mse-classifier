,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Differentials as linear maps,Differentials as linear maps,,"I found the following on the Differential (infinitesimal) Wikipedia page. First they take a function $f(x)$ and define $x$ as the identity map of $\mathbb{R},$ such that $f(x(p))=f(p).$ The differential $\mathrm{d}f$ (which of course depends on $f$ ) is then a function whose value at $p$ (usually denoted $df_p$ ) is not a number, but a linear map from $\mathbb{R}$ to $\mathbb{R}$ ... There is more to the quote, but that's easily found on the Wikipedia page. Anyway, let's say $f(x)=x^2.$ Then for some real $p,$ $df_p=2xdx_p.$ But I'm confused as to how this is a linear map. In particular, what is $dx_p$ here? The Wikipedia page mentioned it's ""again just the identity map from $\mathbb{R}$ to $\mathbb{R}$ (a $1\times1$ matrix with entry $1$ ). But it can't be saying $dx_p=\begin{bmatrix}1\end{bmatrix}$ , can it? So, what exactly is $df_p$ as the Wikipedia page describes?","I found the following on the Differential (infinitesimal) Wikipedia page. First they take a function and define as the identity map of such that The differential (which of course depends on ) is then a function whose value at (usually denoted ) is not a number, but a linear map from to ... There is more to the quote, but that's easily found on the Wikipedia page. Anyway, let's say Then for some real But I'm confused as to how this is a linear map. In particular, what is here? The Wikipedia page mentioned it's ""again just the identity map from to (a matrix with entry ). But it can't be saying , can it? So, what exactly is as the Wikipedia page describes?","f(x) x \mathbb{R}, f(x(p))=f(p). \mathrm{d}f f p df_p \mathbb{R} \mathbb{R} f(x)=x^2. p, df_p=2xdx_p. dx_p \mathbb{R} \mathbb{R} 1\times1 1 dx_p=\begin{bmatrix}1\end{bmatrix} df_p","['linear-algebra', 'derivatives', 'differential-geometry']"
1,Ordinary Derivative of a Function of a Polynomial,Ordinary Derivative of a Function of a Polynomial,,"I want to find higher order derivatives of: $$ f(x)=\frac{1}{4}(x^2-1)^2+K; \quad\quad K=\text{constant} $$ However, I want to find the derivatives with respect to the variable $y$ where we are given the relationship that $x=2y-1$ . My confusion is that following two approaches I am getting slightly different answers. Approach $1$ was to substitute from the start and then calculate the derivatives which gave (after expanding): $$ f(2y-1) = 4y^4-8y^3+4y^2+K  $$ Differentiating and applying the chain rule to the RHS, gives: $$ \frac{df}{dy}(2)=16y^3-24y^2+8y \implies \frac{df}{dy}=8y^3-12y^2+4y $$ My other approach was to calculate the derivatives with respect to $x$ and then use substitution afterwards: $$ f(x)=\frac{1}{4}x^4-\frac{1}{2}x^2+\frac{1}{4} +K $$ $$ \frac{df}{dx} = x^3-x $$ Using the chain rule, we have $\frac{df}{dx}=\frac{df}{dy}\frac{dy}{dx}=\frac{df}{dy}\cdot\frac{1}{2}$ . But this would imply: $$ \frac{df}{dy} = 2\frac{df}{dx}=2(x^3-x)=2[(2y-1)^3-(2y-1)]=16y^3-24y^2+8y $$ I believe I should get the same thing with either approach but I can't tell why they disagree by a factor of $2$ . For reference, what I'm actually interested in is the second and third derivatives of this function. Help would be much appreciated in resolving my mistake.","I want to find higher order derivatives of: However, I want to find the derivatives with respect to the variable where we are given the relationship that . My confusion is that following two approaches I am getting slightly different answers. Approach was to substitute from the start and then calculate the derivatives which gave (after expanding): Differentiating and applying the chain rule to the RHS, gives: My other approach was to calculate the derivatives with respect to and then use substitution afterwards: Using the chain rule, we have . But this would imply: I believe I should get the same thing with either approach but I can't tell why they disagree by a factor of . For reference, what I'm actually interested in is the second and third derivatives of this function. Help would be much appreciated in resolving my mistake.", f(x)=\frac{1}{4}(x^2-1)^2+K; \quad\quad K=\text{constant}  y x=2y-1 1  f(2y-1) = 4y^4-8y^3+4y^2+K    \frac{df}{dy}(2)=16y^3-24y^2+8y \implies \frac{df}{dy}=8y^3-12y^2+4y  x  f(x)=\frac{1}{4}x^4-\frac{1}{2}x^2+\frac{1}{4} +K   \frac{df}{dx} = x^3-x  \frac{df}{dx}=\frac{df}{dy}\frac{dy}{dx}=\frac{df}{dy}\cdot\frac{1}{2}  \frac{df}{dy} = 2\frac{df}{dx}=2(x^3-x)=2[(2y-1)^3-(2y-1)]=16y^3-24y^2+8y  2,"['calculus', 'derivatives', 'substitution', 'chain-rule']"
2,"Why does 3blue1brown use the ""around a point"" to describe a derivative?","Why does 3blue1brown use the ""around a point"" to describe a derivative?",,"In this article (which includes a link to the video version of the article as well), Grant Sanderson aka 3blue1brown describes a derivative. He says at the end of the passage headed ""The Paradox"" , ""Since change in an instant still makes no sense, rather than interpreting the slope of this tangent line as an “instantaneous rate of change”, an alternate notion is to think of it as the best constant approximation for rate of change around a point"". However, I'll be the devil's advocate and disagree with him. I particularly take issue with his usage of the word ""around a point"". I think that the slope of the tangent line is the slope of the curve at that exact point, not around that point. I'll present two quotations in favor of my case: To partially quote myself from my most recent question , Let us consider 2 different points $A$ & $B$ of the above graph. Now, if we find the slope of the secant line $AB$ , it'll be an approximation of the slope of $A$ . If we pick a point that is closer to $A$ than $B$ , $C$ , the slope of $AC$ will be a better approximation of $A$ 's slope. Now, if we know what the value is that the slopes of the secant lines are approaching as the points are getting closer and closer to $A$ , we will be able to find the best approximation and the most correct answer of the slope of that point: the approached value. It is the best approximation because we know that the approximations are getting better and better as the approximations are getting closer and closer to the approached value, so the approached value is the most accurate approximation, and it is the slope of the curve at that exact point , not around that point. We can calculate this approached value by taking the limit: $$f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$$ $f'(x)$ is the approached valued, and it is known as the derivative of $f$ at $x$ . To quote @Javier's comment to this question , ""Maybe you should try not thinking of limits as movement, because then, as you say, you never ""get there"". Rather, when you see a limit like the derivative, imagine that there is a number that you cannot calculate, but that you can approximate with arbitrarily high precision. This is not some fuzzy thinking that cheats by evading the concept of instantaneous rate of change; if you can approximate a number arbitrarily well, then you know exactly what it is, even if you cannot calculate it ""directly"". With this point of view, the limit is not a process that will never end. Instead, it's an indirect way of specifying (without ambiguity) a number that you couldn't otherwise calculate. Maybe this will help."" In short, I think a derivative is the slope of a graph/curve at an exact point, not near that point or around that point. I think 3blue1brown's reasoning can lead to problems. In the passage titled ""The Paradox at Time Zero"" , he essentially argues that at time zero, the car is not static even though the derivative gives us $0$ at that point. He says, ""For smaller and smaller nudges in time, this ratio of the change in distance over change in time approaches $0$ , though in this case it never actually hits it"". However, I'd argue that as we can see that as our approximations approach $0$ we are getting more accurate. As we get arbitrarily close to zero, our approximations become arbitrarily accurate. So, we can understand that the most accurate approximation is the approached value as our approximations are getting better and better as we are getting closer and closer to the approached value. See @Javier's comment above. Questions: Am I correct or is 3blue1brown correct?","In this article (which includes a link to the video version of the article as well), Grant Sanderson aka 3blue1brown describes a derivative. He says at the end of the passage headed ""The Paradox"" , ""Since change in an instant still makes no sense, rather than interpreting the slope of this tangent line as an “instantaneous rate of change”, an alternate notion is to think of it as the best constant approximation for rate of change around a point"". However, I'll be the devil's advocate and disagree with him. I particularly take issue with his usage of the word ""around a point"". I think that the slope of the tangent line is the slope of the curve at that exact point, not around that point. I'll present two quotations in favor of my case: To partially quote myself from my most recent question , Let us consider 2 different points & of the above graph. Now, if we find the slope of the secant line , it'll be an approximation of the slope of . If we pick a point that is closer to than , , the slope of will be a better approximation of 's slope. Now, if we know what the value is that the slopes of the secant lines are approaching as the points are getting closer and closer to , we will be able to find the best approximation and the most correct answer of the slope of that point: the approached value. It is the best approximation because we know that the approximations are getting better and better as the approximations are getting closer and closer to the approached value, so the approached value is the most accurate approximation, and it is the slope of the curve at that exact point , not around that point. We can calculate this approached value by taking the limit: is the approached valued, and it is known as the derivative of at . To quote @Javier's comment to this question , ""Maybe you should try not thinking of limits as movement, because then, as you say, you never ""get there"". Rather, when you see a limit like the derivative, imagine that there is a number that you cannot calculate, but that you can approximate with arbitrarily high precision. This is not some fuzzy thinking that cheats by evading the concept of instantaneous rate of change; if you can approximate a number arbitrarily well, then you know exactly what it is, even if you cannot calculate it ""directly"". With this point of view, the limit is not a process that will never end. Instead, it's an indirect way of specifying (without ambiguity) a number that you couldn't otherwise calculate. Maybe this will help."" In short, I think a derivative is the slope of a graph/curve at an exact point, not near that point or around that point. I think 3blue1brown's reasoning can lead to problems. In the passage titled ""The Paradox at Time Zero"" , he essentially argues that at time zero, the car is not static even though the derivative gives us at that point. He says, ""For smaller and smaller nudges in time, this ratio of the change in distance over change in time approaches , though in this case it never actually hits it"". However, I'd argue that as we can see that as our approximations approach we are getting more accurate. As we get arbitrarily close to zero, our approximations become arbitrarily accurate. So, we can understand that the most accurate approximation is the approached value as our approximations are getting better and better as we are getting closer and closer to the approached value. See @Javier's comment above. Questions: Am I correct or is 3blue1brown correct?",A B AB A A B C AC A A f'(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h} f'(x) f x 0 0 0,"['calculus', 'derivatives', 'soft-question']"
3,Relation between polynomial division and derivative,Relation between polynomial division and derivative,,"$P(x)$ is a polynomial and it is equal to $2x^3 + 2ax^2 +bx +c$ . It is given that $P(x)$ can be divided by $(x-1)^3$ with zero remainder. Then , what is $c$ ? This is a basic polynomials question, to reach the solution we use derivative for shortcut. For example, we find $P(1) ,P'(1),P''(1)$ respectively. Then answer is $2$ .. My question is why we use derivative, I could not conceive the reason behind the usage of derivative. In first thought, I thought that if $(x-1)^3$ divides $P(x)$ , then $(x-1)^2$ and $(x-1)$ divides $P(x)$ , as well. However, I could not see any relation with derivative. Can you enlighten me?","is a polynomial and it is equal to . It is given that can be divided by with zero remainder. Then , what is ? This is a basic polynomials question, to reach the solution we use derivative for shortcut. For example, we find respectively. Then answer is .. My question is why we use derivative, I could not conceive the reason behind the usage of derivative. In first thought, I thought that if divides , then and divides , as well. However, I could not see any relation with derivative. Can you enlighten me?","P(x) 2x^3 + 2ax^2 +bx +c P(x) (x-1)^3 c P(1) ,P'(1),P''(1) 2 (x-1)^3 P(x) (x-1)^2 (x-1) P(x)","['real-analysis', 'algebra-precalculus']"
4,How to prove the derivative of $\ln{f(x)}$?,How to prove the derivative of ?,\ln{f(x)},I've been trying to demonstrate the derivative formulas for a few functions. I could demonstrate that $\ln [x^{n}]=\frac{n}{x}$ . But when I tried to derive $f(x)=\ln[u(x)]$ I couldn't. I just started it and couldn't go foreward. What I did was: $$ \begin{align}  f'(x)&=\lim_{h \to 0}\frac{\ln u(x+h)-\ln u(x)}{h}\\&=\lim_{h \to 0}\frac{\ln\frac{u(x+h)}{u(x)}}{h}\\ &=\lim_{h \to 0} \frac{1}{h}\ln\frac{u(x+h)}{u(x)}\\ &=\lim_{h \to 0} \ln\left(\frac{u(x+h)}{u(x)}\right)^{\frac{1}{h}} \end{align}  $$ What do I do next?,I've been trying to demonstrate the derivative formulas for a few functions. I could demonstrate that . But when I tried to derive I couldn't. I just started it and couldn't go foreward. What I did was: What do I do next?,"\ln [x^{n}]=\frac{n}{x} f(x)=\ln[u(x)] 
\begin{align} 
f'(x)&=\lim_{h \to 0}\frac{\ln u(x+h)-\ln u(x)}{h}\\&=\lim_{h \to 0}\frac{\ln\frac{u(x+h)}{u(x)}}{h}\\
&=\lim_{h \to 0} \frac{1}{h}\ln\frac{u(x+h)}{u(x)}\\
&=\lim_{h \to 0} \ln\left(\frac{u(x+h)}{u(x)}\right)^{\frac{1}{h}}
\end{align}  ","['calculus', 'limits', 'derivatives']"
5,Derivative of $Y \mapsto Y^T Y$,Derivative of,Y \mapsto Y^T Y,"Is this derivative done correctly? I've did not find the solution in the matrix cookbook, but followed the similar examples: $$\frac{\delta Y^TY}{\delta Y} =  ?$$ $$X=Y^TY$$ $$\delta X=(\delta Y^T)Y + Y^T(\delta Y)$$ $$\mathrm{vec}(\delta X)=\mathrm{vec}(\delta Y^TY) + \mathrm{vec}(Y^T\delta Y)$$ $$\mathrm{vec}(\delta X)=(I\otimes Y)\,\mathrm{vec}(\delta Y^T) + (I \otimes Y^T)\,\mathrm{vec}(\delta Y)$$ $$\frac{\delta X}{\delta Y} =  2(I \otimes Y^T)$$","Is this derivative done correctly? I've did not find the solution in the matrix cookbook, but followed the similar examples:","\frac{\delta Y^TY}{\delta Y} =  ? X=Y^TY \delta X=(\delta Y^T)Y + Y^T(\delta Y) \mathrm{vec}(\delta X)=\mathrm{vec}(\delta Y^TY) + \mathrm{vec}(Y^T\delta Y) \mathrm{vec}(\delta X)=(I\otimes Y)\,\mathrm{vec}(\delta Y^T) + (I \otimes Y^T)\,\mathrm{vec}(\delta Y) \frac{\delta X}{\delta Y} =  2(I \otimes Y^T)","['matrices', 'derivatives', 'matrix-calculus']"
6,"Using logarithmic differentiation or otherwise, differentiate $y = (x −1) (x − 2) (x − 3$)? And show that $y' = 3x^2-12x+11$","Using logarithmic differentiation or otherwise, differentiate )? And show that",y = (x −1) (x − 2) (x − 3 y' = 3x^2-12x+11,So far this is my method: \begin{align*} y = (x-1)(x-2)(x-3) & \Longleftrightarrow \ln(y) = \ln(x-1) + \ln(x-2) + \ln(x-3)\\\\ & \Longleftrightarrow \frac{y'}{y} = \frac{1}{x-1} + \frac{1}{x-2} + \frac{1}{x-3}\\\\ & \Longleftrightarrow  y' = y\left(\frac{1}{x-1} + \frac{1}{x-2} + \frac{1}{x-3}\right) \end{align*},So far this is my method:,"\begin{align*}
y = (x-1)(x-2)(x-3) & \Longleftrightarrow \ln(y) = \ln(x-1) + \ln(x-2) + \ln(x-3)\\\\
& \Longleftrightarrow \frac{y'}{y} = \frac{1}{x-1} + \frac{1}{x-2} + \frac{1}{x-3}\\\\
& \Longleftrightarrow 
y' = y\left(\frac{1}{x-1} + \frac{1}{x-2} + \frac{1}{x-3}\right)
\end{align*}",['calculus']
7,"Let $f(x)=ax^3+bx^2+cx+5$. If $|f(x)|\le|e^x-e^2|$ for all $x\ge0$ and if the maximum value of $|12a+4b+c|$ is $m$, then find $[m]$","Let . If  for all  and if the maximum value of  is , then find",f(x)=ax^3+bx^2+cx+5 |f(x)|\le|e^x-e^2| x\ge0 |12a+4b+c| m [m],"Let $f(x)=ax^3+bx^2+cx+5$ . If $|f(x)|\le|e^x-e^2|$ for all $x\ge0$ and if the maximum value of $|12a+4b+c|$ is $m$ , then find $[m]$ (where $[.]$ represents the greatest integer function.) I first thought $|f(x)|\le|e^x-e^2|$ represents the boundedness of $f(x)$ but then realized a cubic function is unbounded. Also, the RHS of the inequality is not constant. On observing $|12a+4b+c|$ , I figured it is $f'(2)$ . I don't think we can find its maximum value by finding the critical points of $f''(x)=0$ because that would give the extremum of $f'(x)$ , not $f'(2)$ . If $|f(x)|\le|e^x-e^2|$ , can we say anything about $f'(x)$ ?","Let . If for all and if the maximum value of is , then find (where represents the greatest integer function.) I first thought represents the boundedness of but then realized a cubic function is unbounded. Also, the RHS of the inequality is not constant. On observing , I figured it is . I don't think we can find its maximum value by finding the critical points of because that would give the extremum of , not . If , can we say anything about ?",f(x)=ax^3+bx^2+cx+5 |f(x)|\le|e^x-e^2| x\ge0 |12a+4b+c| m [m] [.] |f(x)|\le|e^x-e^2| f(x) |12a+4b+c| f'(2) f''(x)=0 f'(x) f'(2) |f(x)|\le|e^x-e^2| f'(x),"['calculus', 'derivatives', 'functional-inequalities']"
8,What is the notation $f¢(x)$ stands for in context of derivatives?,What is the notation  stands for in context of derivatives?,f¢(x),"Consider the remark given here in the chapter 6 named APPLICATION OF DERIVATIVES from NCERT class 12 book There is a more generalised theorem , which states that if $\mathbf{f¢(x) > 0}$ for $x$ in an interval excluding the end points and $f$ is continuous in the interval, then $f$ is increasing. Similarly, if $\mathbf{f¢(x) < 0}$ for $x$ in an interval excluding the end points and $f$ is continuous in the interval, then $f$ is decreasing. I am facing two issues in understanding it, What is the notation $f¢(x)$ ? Is it $f'(x)$ ? How is it a generalisation of the following theorem as told? (I can see no difference in both, if 1 is true) Let $f$ be continuous on $[a, b]$ and differentiable on the open interval $(a,b)$ . Then (a) $f$ is increasing in $[a,b]$ if $f ′(x) > 0$ for each $x \in (a,  b)$ (b) $f$ is decreasing in $[a,b]$ if $f ′(x) < 0$ for each $x \in (a,  b)$ (c) $f$ is a constant function in $[a,b]$ if $f ′(x) = 0$ for each $x  \in (a, b)$","Consider the remark given here in the chapter 6 named APPLICATION OF DERIVATIVES from NCERT class 12 book There is a more generalised theorem , which states that if for in an interval excluding the end points and is continuous in the interval, then is increasing. Similarly, if for in an interval excluding the end points and is continuous in the interval, then is decreasing. I am facing two issues in understanding it, What is the notation ? Is it ? How is it a generalisation of the following theorem as told? (I can see no difference in both, if 1 is true) Let be continuous on and differentiable on the open interval . Then (a) is increasing in if for each (b) is decreasing in if for each (c) is a constant function in if for each","\mathbf{f¢(x) > 0} x f f \mathbf{f¢(x) < 0} x f f f¢(x) f'(x) f [a, b] (a,b) f [a,b] f ′(x) > 0 x \in (a,
 b) f [a,b] f ′(x) < 0 x \in (a,
 b) f [a,b] f ′(x) = 0 x
 \in (a, b)","['derivatives', 'notation']"
9,Derivative of $\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right)$.,Derivative of .,\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right),"Find the derivative of $\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right)$ . I'm learning differentiation and this is an exercise problem from my book. I used chain rule and got the following: $\begin{align} \dfrac d{dx}\left[\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan\frac x2\right)\right] &= \dfrac{1}{1+\frac{a-b}{a+b}\tan^2\frac x 2}\cdot\dfrac{d}{dx}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right)\\ &= \dfrac{1}{1+\frac{a-b}{a+b}\tan^2\frac x 2}\cdot\frac 1 2\sqrt{\frac{a-b}{a+b}}\sec^2\frac x 2 \end{align}$ But this doesn't match the answer in the book. The given answer is $\frac{\sqrt{a^2-b^2}}{2(a+b\cos x)}$ . So, where did I go wrong and what is the correct solution?","Find the derivative of . I'm learning differentiation and this is an exercise problem from my book. I used chain rule and got the following: But this doesn't match the answer in the book. The given answer is . So, where did I go wrong and what is the correct solution?","\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right) \begin{align}
\dfrac d{dx}\left[\tan^{-1}\left(\sqrt{\frac{a-b}{a+b}}\tan\frac x2\right)\right] &= \dfrac{1}{1+\frac{a-b}{a+b}\tan^2\frac x 2}\cdot\dfrac{d}{dx}\left(\sqrt{\frac{a-b}{a+b}}\tan \frac x2\right)\\ &= \dfrac{1}{1+\frac{a-b}{a+b}\tan^2\frac x 2}\cdot\frac 1 2\sqrt{\frac{a-b}{a+b}}\sec^2\frac x 2
\end{align} \frac{\sqrt{a^2-b^2}}{2(a+b\cos x)}","['calculus', 'derivatives', 'inverse-function', 'chain-rule']"
10,Why does the derivative of the magnitude of a vector yield a different result to the magnitude of the derivative of a vector?,Why does the derivative of the magnitude of a vector yield a different result to the magnitude of the derivative of a vector?,,"The problem The time derivative of the posistion vector is the velocity vector, then we can take the magnitude of the posistion. Thats what part a doesand the magnitude is given to be 1953.3 But when you first take the magnitude of the posistion vector then divide that by the time derivative of the expression it gives 1935.5 So knowing this the magnitude of the velocity vector is not the same as the magnitude of the first time derivative of the posistion vector. Can someone please explain why that is the case?","The problem The time derivative of the posistion vector is the velocity vector, then we can take the magnitude of the posistion. Thats what part a doesand the magnitude is given to be 1953.3 But when you first take the magnitude of the posistion vector then divide that by the time derivative of the expression it gives 1935.5 So knowing this the magnitude of the velocity vector is not the same as the magnitude of the first time derivative of the posistion vector. Can someone please explain why that is the case?",,"['derivatives', 'vectors']"
11,How to decompose $\frac{1+x}{\sqrt{(1-x)}}$ into partial fractions?,How to decompose  into partial fractions?,\frac{1+x}{\sqrt{(1-x)}},"Basically homework help. The question ( Problems of Calculus in One Variable , IA Maron, number 2.3.9(b) ) is to find the derivative of the 100th order of the function $$ y = \frac{1+x}{\sqrt{(1-x)}} $$ by 'expansion into a linear combination of simpler functions'. I can't find any help online. There is a hint at the back, which says that $y$ can be written as $2(\sqrt{1-x})^{-1} - \sqrt{1-x}$ , but how we get that, I have no idea. How am I supposed to decompose $y$ ?","Basically homework help. The question ( Problems of Calculus in One Variable , IA Maron, number 2.3.9(b) ) is to find the derivative of the 100th order of the function by 'expansion into a linear combination of simpler functions'. I can't find any help online. There is a hint at the back, which says that can be written as , but how we get that, I have no idea. How am I supposed to decompose ?","
y = \frac{1+x}{\sqrt{(1-x)}}
 y 2(\sqrt{1-x})^{-1} - \sqrt{1-x} y","['calculus', 'derivatives', 'problem-solving', 'partial-fractions']"
12,Prove Directional Derivative Exists For All Unit Vectors,Prove Directional Derivative Exists For All Unit Vectors,,"I'm pretty stuck on the following problem. Define $f: R^2 \rightarrow R$ by $$f(x,y) = \frac{xy^2}{x^2+y^2} \quad\text{ if }\quad (x,y) \neq (0,0),$$ $$f(x,y) = 0 \quad\quad\quad\text{ if }\quad\quad (x,y) =(0,0).$$ Prove $D_uf$ exists for all $u$ . So I know that this is the directional derivative, and that $u$ can be any unit vector. But there are infinite possibilities for $u$ , so how can I show the derivative exists for all of them?","I'm pretty stuck on the following problem. Define by Prove exists for all . So I know that this is the directional derivative, and that can be any unit vector. But there are infinite possibilities for , so how can I show the derivative exists for all of them?","f: R^2 \rightarrow R f(x,y) = \frac{xy^2}{x^2+y^2} \quad\text{ if }\quad (x,y) \neq (0,0), f(x,y) = 0 \quad\quad\quad\text{ if }\quad\quad (x,y) =(0,0). D_uf u u u","['real-analysis', 'derivatives', 'partial-derivative']"
13,"Real analysis uniform convergence: Suppose that $f_n : (a,b) \to \mathbb R $ is a sequence of differentiable functions such that there is ...",Real analysis uniform convergence: Suppose that  is a sequence of differentiable functions such that there is ...,"f_n : (a,b) \to \mathbb R ","Suppose that $f_n : (a,b)\to \mathbb R $ is a sequence of differentiable functions such that there is $c \in (a, b)$ satisfying $\lim_{n \to \infty} f_n(c) = L \in \mathbb R$ . Suppose further that given $[\alpha, \beta] \subset (a, b)$ , the sequence $(f'_n)$ converges uniformly to the null function in $[\alpha, \beta]$ . Show that in each $[\alpha, \beta] \subset (a, b)$ the function $f_n$ converges uniformly to the constant function equal to $L$ . What I've managed to do so far is this Fix $\epsilon \gt 0$ ,and choose $N$ such that $m, n \ge N$ implies $|f_n(x_0) − f_m(x_0)| \lt \frac{\epsilon}{2}$ and $|f'_n(t) − f'_m(t)| \lt \frac{\epsilon}{2(b-a)}$ for all $t \in [a, b]$ . So lets say $g = f_n −f_m$ is small on the entire interval $[a, b]$ , now applying the Mean Value Theorem to $g$ , we get $$|g(x) − g(t)| = |x − t||f'(c)| \le |x − t| \frac{\epsilon}{2(b − a)} \le \frac{\epsilon}{2}$$ valid for all $x$ , $t \in[a, b]$ and all $m$ , $n \ge N$ . Now for all $x \in [a, b]$ $$|g(x)| \le |g(x) − g(x_0)| + |g(x_0)| \lt \epsilon$$ This shows that the sequence $f_n$ is uniformly Cauchy, hence uniformly converges to some function, $f$ on $[a, b]$ I'm in the right way? Thanks in advance for any help.","Suppose that is a sequence of differentiable functions such that there is satisfying . Suppose further that given , the sequence converges uniformly to the null function in . Show that in each the function converges uniformly to the constant function equal to . What I've managed to do so far is this Fix ,and choose such that implies and for all . So lets say is small on the entire interval , now applying the Mean Value Theorem to , we get valid for all , and all , . Now for all This shows that the sequence is uniformly Cauchy, hence uniformly converges to some function, on I'm in the right way? Thanks in advance for any help.","f_n : (a,b)\to \mathbb R  c \in (a, b) \lim_{n \to \infty} f_n(c) = L \in \mathbb R [\alpha, \beta] \subset (a, b) (f'_n) [\alpha, \beta] [\alpha, \beta] \subset (a, b) f_n L \epsilon \gt 0 N m, n \ge N |f_n(x_0) − f_m(x_0)| \lt \frac{\epsilon}{2} |f'_n(t) − f'_m(t)| \lt \frac{\epsilon}{2(b-a)} t \in [a, b] g = f_n −f_m [a, b] g |g(x) − g(t)| = |x − t||f'(c)| \le |x − t| \frac{\epsilon}{2(b − a)} \le \frac{\epsilon}{2} x t \in[a, b] m n \ge N x \in [a, b] |g(x)| \le |g(x) − g(x_0)| + |g(x_0)| \lt \epsilon f_n f [a, b]","['real-analysis', 'derivatives', 'solution-verification', 'uniform-convergence']"
14,"Finding a polynomial $P\in\Bbb R[x]$ such that $|\sqrt[3]x-P(x)|\le\frac1{100}, \forall x\in[0,1]$",Finding a polynomial  such that,"P\in\Bbb R[x] |\sqrt[3]x-P(x)|\le\frac1{100}, \forall x\in[0,1]","A very similar question has already been asked before, but here the cubic root appears: Find a polynomial $P\in\Bbb R[x]$ such that $|\sqrt[3]x-P(x)|\le\frac1{100},\forall x\in[0,1]$ From what I understand, $P$ should be a Taylor polynomial $T_n$ (which, I know, is the $n^{\mathrm{th}}$ partial sum of the corresponding Taylor series) around $c\in[0,1]$ of the function $f(x)=\sqrt[3]x$ of a suitable degree and $\sqrt[3]x-P(x)=R_n(x)=\frac{f^{(n+1)}(c_x)}{(n+1)!}(x-c)^{n+1}$ for some $c_x$ between $c$ and $x$ . Since there is $1/3$ in the exponent, I didn't try applying the Stirling's approximation. Instead, I have the Taylor expansion of $\sqrt[3]x$ around $x=1$ : $$\begin{aligned}\sqrt[3]x&=\sqrt[3]{1+(x-1)}\\&=\sum_{n=0}^\infty\binom{1/3}n(x-1)^n\\&=\sum_{n=0}^\infty\frac{\frac13\left(\frac13-1\right)\left(\frac13-2\right)\cdots\left(\frac13-(n-1)\right)}{3^nn!}(x-1)^n\\&=\sum_{n=0}^\infty\frac{(-1)^n(3n-4)!!!}{(3n)!!!}(x-1)^n,\end{aligned}$$ however, I'm not sure how to proceed. I also considered Lagrange interpolation polynomial, but $\sqrt[3] x$ has an infinite slope at $x=0$ . I also tried using the hint from the thread, which is, the Taylor series of $\sqrt[3]{x+\varepsilon}$ around $x=1:$ $$\begin{aligned}\sqrt[3]{x+\varepsilon}&=\sqrt[3]{x-1+\varepsilon+1}\\&=\sqrt[3]{1+\varepsilon}\sqrt[3]{1+\frac{x-1}{1+\varepsilon}}\\&=\sqrt[3]{1+\varepsilon}\sum_{n=0}^\infty\frac{(-1)^n(3n-4)!!!}{(3n)!!!(1+\varepsilon)^n}(x-1)^n.\end{aligned}$$ I believe I'm either missing something or that I made a mistake. What is step should I take next? How to find the large enough $\deg(P)=n$ so that the approximation is correct up two $2$ decimal digits? EDIT: As advised in the comments, I developed $f(x)=\sqrt[3]x$ around $c=\frac12$ : $\begin{aligned}\sqrt[3]x&=\left(\frac12+\left(x-\frac12\right)\right)^\frac13\\&=\frac1{2^3}\left(1+2\left(x-\frac12\right)\right)^\frac13\\&=\sum_{n=0}^\infty\binom{1/3}n2^{n-1/3}\left(x-\frac12\right)^n,\end{aligned}$ but I'm still a bit confused as to how to determine which is the least degree of the Taylor polynomial that suits us. Thank you very much!","A very similar question has already been asked before, but here the cubic root appears: Find a polynomial such that From what I understand, should be a Taylor polynomial (which, I know, is the partial sum of the corresponding Taylor series) around of the function of a suitable degree and for some between and . Since there is in the exponent, I didn't try applying the Stirling's approximation. Instead, I have the Taylor expansion of around : however, I'm not sure how to proceed. I also considered Lagrange interpolation polynomial, but has an infinite slope at . I also tried using the hint from the thread, which is, the Taylor series of around I believe I'm either missing something or that I made a mistake. What is step should I take next? How to find the large enough so that the approximation is correct up two decimal digits? EDIT: As advised in the comments, I developed around : but I'm still a bit confused as to how to determine which is the least degree of the Taylor polynomial that suits us. Thank you very much!","P\in\Bbb R[x] |\sqrt[3]x-P(x)|\le\frac1{100},\forall x\in[0,1] P T_n n^{\mathrm{th}} c\in[0,1] f(x)=\sqrt[3]x \sqrt[3]x-P(x)=R_n(x)=\frac{f^{(n+1)}(c_x)}{(n+1)!}(x-c)^{n+1} c_x c x 1/3 \sqrt[3]x x=1 \begin{aligned}\sqrt[3]x&=\sqrt[3]{1+(x-1)}\\&=\sum_{n=0}^\infty\binom{1/3}n(x-1)^n\\&=\sum_{n=0}^\infty\frac{\frac13\left(\frac13-1\right)\left(\frac13-2\right)\cdots\left(\frac13-(n-1)\right)}{3^nn!}(x-1)^n\\&=\sum_{n=0}^\infty\frac{(-1)^n(3n-4)!!!}{(3n)!!!}(x-1)^n,\end{aligned} \sqrt[3] x x=0 \sqrt[3]{x+\varepsilon} x=1: \begin{aligned}\sqrt[3]{x+\varepsilon}&=\sqrt[3]{x-1+\varepsilon+1}\\&=\sqrt[3]{1+\varepsilon}\sqrt[3]{1+\frac{x-1}{1+\varepsilon}}\\&=\sqrt[3]{1+\varepsilon}\sum_{n=0}^\infty\frac{(-1)^n(3n-4)!!!}{(3n)!!!(1+\varepsilon)^n}(x-1)^n.\end{aligned} \deg(P)=n 2 f(x)=\sqrt[3]x c=\frac12 \begin{aligned}\sqrt[3]x&=\left(\frac12+\left(x-\frac12\right)\right)^\frac13\\&=\frac1{2^3}\left(1+2\left(x-\frac12\right)\right)^\frac13\\&=\sum_{n=0}^\infty\binom{1/3}n2^{n-1/3}\left(x-\frac12\right)^n,\end{aligned}","['real-analysis', 'calculus', 'derivatives', 'taylor-expansion']"
15,Use the chain rule to compute the derivative of an inverse function.,Use the chain rule to compute the derivative of an inverse function.,,"Given a function $f(x)$ , let $g=f^{-1}(x)$ . Then define the composite function $f(g(x))$ . Then, by the Chain Rule, $(f(g(x)))'=f'(g(x)) g'(x)$ . However, since $f(x)$ and $g(x)$ are inverses, $f(g(x))=x$ and $(f(g(x)))'=(x)'=1$ . So $1=f'(g(x)) g'(x)$ . If you solve for $g'(x)$ , you get $$\frac{1}{f'(g(x))}$$ which is the derivative of an inverse function. QED Is the above proof correct and if so, can it be considered mathematically rigorous?","Given a function , let . Then define the composite function . Then, by the Chain Rule, . However, since and are inverses, and . So . If you solve for , you get which is the derivative of an inverse function. QED Is the above proof correct and if so, can it be considered mathematically rigorous?",f(x) g=f^{-1}(x) f(g(x)) (f(g(x)))'=f'(g(x)) g'(x) f(x) g(x) f(g(x))=x (f(g(x)))'=(x)'=1 1=f'(g(x)) g'(x) g'(x) \frac{1}{f'(g(x))},"['real-analysis', 'calculus', 'derivatives', 'solution-verification']"
16,Notation of the partial derivative,Notation of the partial derivative,,What does in simple word this notation means: $$\left(\frac{\partial u}{\partial x} \right) dx $$ I understand it this way: the rate of change of $u$ with respect to $x$ . But what we achieve by multiplying partial derivative by $dx$ afterwards?,What does in simple word this notation means: I understand it this way: the rate of change of with respect to . But what we achieve by multiplying partial derivative by afterwards?,\left(\frac{\partial u}{\partial x} \right) dx  u x dx,['derivatives']
17,Polynomial Graph Question Whose Solution Does Not Make Sense,Polynomial Graph Question Whose Solution Does Not Make Sense,,"The question is: How many roots of the equation $3x^4 +6x^3 + x^2 +6x +3$ are real? The textbook's solution is: Let $f(x) = 3x^4 +6x^3 + x^2 +6x +3$ . Now $$f'(x) =12x^3 +18x^2 +2x +6\\     \implies f''(x) = 36x^2 +36x +2 ≠ 0 \; \forall x \in \mathbb{R} $$ So, graph of $f'(x)$ intersects $x$ -axis only once. Hence, $f(x)$ has only one turning point. So $f(x)=0$ has maximum two real roots. Now $f(0)=3>0$ and $f(-1)=-5<0$ So graph cuts $x$ -axis between $-1$ and $1$ . Hence $f(x)=0$ has two real roots. My Question: How on earth does $f''(x)$ have no real solutions? Using the quadratic formula I get $2$ real negative roots. Am I missing something here? Also how does the fact that the graph cuts the $x$ -axis between $1$ and $-1$ imply that there are $2$ real roots? I just started reading the portion in the textbook on Graphs Of Polynomial Functions and I am in $12$ th grade so if you could, please explain in a little simple way thank you. Also sorry if the formatting is weird this is the first time I have asked a question here :) .","The question is: How many roots of the equation are real? The textbook's solution is: Let . Now So, graph of intersects -axis only once. Hence, has only one turning point. So has maximum two real roots. Now and So graph cuts -axis between and . Hence has two real roots. My Question: How on earth does have no real solutions? Using the quadratic formula I get real negative roots. Am I missing something here? Also how does the fact that the graph cuts the -axis between and imply that there are real roots? I just started reading the portion in the textbook on Graphs Of Polynomial Functions and I am in th grade so if you could, please explain in a little simple way thank you. Also sorry if the formatting is weird this is the first time I have asked a question here :) .","3x^4 +6x^3 + x^2 +6x +3 f(x) = 3x^4 +6x^3 + x^2 +6x +3 f'(x) =12x^3 +18x^2 +2x +6\\
    \implies f''(x) = 36x^2 +36x +2 ≠ 0 \; \forall x \in \mathbb{R}  f'(x) x f(x) f(x)=0 f(0)=3>0 f(-1)=-5<0 x -1 1 f(x)=0 f''(x) 2 x 1 -1 2 12","['algebra-precalculus', 'derivatives', 'polynomials', 'graphing-functions']"
18,Mean value theorem for sums,Mean value theorem for sums,,"I need to prove that if $f$ is continuous in $[x_1,x_2]$ and $a_1$ and $a_2$ are both greater than $0$ then there exists one $y \in [x_1,x_2]$ s.t. $$a_1\cdot f(x_1) + a_2\cdot f(x_2) = (a_1+a_2)f(y)$$ I have tried using the MVT but I got nowhere. Note that there are no derivatives or integrations in the equation.",I need to prove that if is continuous in and and are both greater than then there exists one s.t. I have tried using the MVT but I got nowhere. Note that there are no derivatives or integrations in the equation.,"f [x_1,x_2] a_1 a_2 0 y \in [x_1,x_2] a_1\cdot f(x_1) + a_2\cdot f(x_2) = (a_1+a_2)f(y)","['real-analysis', 'calculus', 'derivatives']"
19,Let $h$ be the function defined by $h(x)=\int_{0}^{x^2}e^{x+t}dt$ for all real numbers $x$. Then $h'(1)=\dots$,Let  be the function defined by  for all real numbers . Then,h h(x)=\int_{0}^{x^2}e^{x+t}dt x h'(1)=\dots,"This question appeared in the GRE MATH SUBJECT TEST (GR $0568$ ) - Question# $24$ : Let $h$ be the function defined by $h(x)=\int_{0}^{x^2}e^{x+t}dt$ for all real numbers $x$ . Then $h'(1)=$ (A) $e-1$ (B) $e^2$ (C) $e^2-e$ (D) $2e^2$ (E) $3e^2-e$ Now I have two approaches; FIRST APPROACH: (TRUE and I understand it very well): $h(x)=\int_{0}^{x^2}e^{x+t}dt=e^{x+t}|_{t=0}^{t=x^2}=e^{x+x^2}-e^x$ Differentiating, we get $h'(x)=(1+2x)e^{x+x^2}-e^x$ So $h'(1)=(1+2(1))e^{1+1^2}-e^1=3e^2-e$ Hence E is the correct answer. SECOND APPROACH: (FALSE and I do not know where is the mistake): Note that $$A(x)=\int_{B(x)}^{C(x)}a(t)dt \implies A'(x)=a(C(x))C'(x)-a(B(x))B'(x)$$ So, $h'(x)=(e^{x+x^2})(2x)$ Therefore $h'(1)=(e^{1+1^2})(2(1))=2e^2$ (which is the incorrect option D). Please clarify my mistake in the second approach. Your help would be appreciated. THANKS.","This question appeared in the GRE MATH SUBJECT TEST (GR ) - Question# : Let be the function defined by for all real numbers . Then (A) (B) (C) (D) (E) Now I have two approaches; FIRST APPROACH: (TRUE and I understand it very well): Differentiating, we get So Hence E is the correct answer. SECOND APPROACH: (FALSE and I do not know where is the mistake): Note that So, Therefore (which is the incorrect option D). Please clarify my mistake in the second approach. Your help would be appreciated. THANKS.",0568 24 h h(x)=\int_{0}^{x^2}e^{x+t}dt x h'(1)= e-1 e^2 e^2-e 2e^2 3e^2-e h(x)=\int_{0}^{x^2}e^{x+t}dt=e^{x+t}|_{t=0}^{t=x^2}=e^{x+x^2}-e^x h'(x)=(1+2x)e^{x+x^2}-e^x h'(1)=(1+2(1))e^{1+1^2}-e^1=3e^2-e A(x)=\int_{B(x)}^{C(x)}a(t)dt \implies A'(x)=a(C(x))C'(x)-a(B(x))B'(x) h'(x)=(e^{x+x^2})(2x) h'(1)=(e^{1+1^2})(2(1))=2e^2,"['calculus', 'integration', 'derivatives', 'exponential-function', 'gre-exam']"
20,Find a rectangular parallelepiped of total area 'A' having the maximum volume.,Find a rectangular parallelepiped of total area 'A' having the maximum volume.,,"Find a rectangular parallelepiped of total area 'A' having the maximum volume. Using Lagrange multipliers, Determine: Function to optimize. Condition or constraint. The dimensions of 'x', 'y', 'z'. $g(x,y,z) = xyz=V$ $f(x,y,z)=2(xy+yz+zx)$ By lagrange multipliers, we get the following relations $$2(z+y) = \lambda yz \tag{1}$$ $$ 2(z+x) = \lambda xz \tag{2}$$ $$ 2(y+x)= \lambda xy \tag{3}$$ From (1) and (2),: $$ \frac{z+y}{z+x} = \frac{y}{x}$$ $$ xz + xy = zy + yx$$ Hence, $$ x=z$$ Similarly , by solving the system, we get $x=y=z$ , plugging $xyz$ into the expression for $g$ : $$ x^3 = S$$ $$ x = S^{\frac13}$$ Finally, I have reached the point where $x$ = $\sqrt[3]{s}$ , I am not very sure if the procedures I have performed are correct because of this result; I am not sure how to proceed to find the variables $x, y, z$ . Can anyone help me with this, please?","Find a rectangular parallelepiped of total area 'A' having the maximum volume. Using Lagrange multipliers, Determine: Function to optimize. Condition or constraint. The dimensions of 'x', 'y', 'z'. By lagrange multipliers, we get the following relations From (1) and (2),: Hence, Similarly , by solving the system, we get , plugging into the expression for : Finally, I have reached the point where = , I am not very sure if the procedures I have performed are correct because of this result; I am not sure how to proceed to find the variables . Can anyone help me with this, please?","g(x,y,z) = xyz=V f(x,y,z)=2(xy+yz+zx) 2(z+y) = \lambda yz \tag{1}  2(z+x) = \lambda xz \tag{2}  2(y+x)= \lambda xy \tag{3}  \frac{z+y}{z+x} = \frac{y}{x}  xz + xy = zy + yx  x=z x=y=z xyz g  x^3 = S  x = S^{\frac13} x \sqrt[3]{s} x, y, z","['calculus', 'derivatives', 'lagrange-multiplier']"
21,Finding maximal length of a log (calculus),Finding maximal length of a log (calculus),,"Let the width of a river be $a$ and the width of a canal be $b$ . Canal is perpendicular to the river. What is the maximum length of a log that can be send from river to canal? The result given in a book is $(a^{2/3} + b^{2/3})^{3/2}$ . I have found this exercise in the book of exercises by Boris Demidovič. It is known in eastern Europe to be the one of the best collections of problems. edit: changed word to perpendicular, thanks Henry Lee.","Let the width of a river be and the width of a canal be . Canal is perpendicular to the river. What is the maximum length of a log that can be send from river to canal? The result given in a book is . I have found this exercise in the book of exercises by Boris Demidovič. It is known in eastern Europe to be the one of the best collections of problems. edit: changed word to perpendicular, thanks Henry Lee.",a b (a^{2/3} + b^{2/3})^{3/2},"['calculus', 'derivatives', 'optimization', 'maxima-minima']"
22,Approximate $\sin 29^\circ$ using differentials,Approximate  using differentials,\sin 29^\circ,Using differential find approximate value of $\sqrt[3]{1.02}$ I did this. We know $f(x_0+\Delta x)-f(x_0)=\frac{df}{dx}(x_0)\cdot\Delta x$ $$f(x)=\sqrt[3]{1+x}$$ $$f(0.02)-f(0)=\frac{df}{dx}(0)\cdot0.02$$ And after calculation I solved. But the problem I don't know how to solve is approximate using differential $\sin29^\circ$ .,Using differential find approximate value of I did this. We know And after calculation I solved. But the problem I don't know how to solve is approximate using differential .,\sqrt[3]{1.02} f(x_0+\Delta x)-f(x_0)=\frac{df}{dx}(x_0)\cdot\Delta x f(x)=\sqrt[3]{1+x} f(0.02)-f(0)=\frac{df}{dx}(0)\cdot0.02 \sin29^\circ,"['real-analysis', 'calculus']"
23,Modification of Lagrange’s Remainder Theorem to calculate $\ln 2$,Modification of Lagrange’s Remainder Theorem to calculate,\ln 2,"The following question is from Stephen Abbott's ""Understanding Analysis."" Question: Explain how Lagrange’s Remainder Theorem can be modified to prove $$ 1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4} \cdots = \ln2. $$ A question close to mine was asked here but does not address my concern. The usual procedure used to solve such problems is to first show that the power series $f(x) = \sum_{k=1}^\infty \frac{(-1)^{k-1}x^{k}}{k}$ can be derived from that of $1/(1+x)$ so that the region of convergence for $f(x)$ would be $(-1,1)$ , then to show that $f(x)$ converges at $x=1$ (using alternating series test in this case).  Abel's theorem would imply that $f(x)$ converges uniformly on $[0,1]$ and continuous limit theorem would imply that $f(x)$ is continuous at $x=1$ . Finally, as $f(x) = \ln(1+x)$ on $(-1,1)$ , we can conclude that $\ln(2) = 1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4} \cdots$ The question however asks us to modify Lagrange’s Remainder Theorem. Following are two statements, the first of which is Lagrange’s Remainder Theorem as given in the text, and the second is the one that I have modified. Please let me know if second statement is correct and if not, please give me a hint as to where I am going wrong. Lagrange’s Remainder Theorem (as given in the text): Let $f$ be differentiable $N + 1$ times on $(−R,R)$ . Define $a_n = f^{(n)}(0)/n!$ for $n = 0,1,\cdots,N$ , and let $$ S_N(x) = a_0 +a_1x+a_2x^2 +\cdots+a_Nx^N. $$ Given $x\neq 0$ in $(−R,R)$ , there exists a point $c$ satisfying $|c| < |x|$ where the error function $E_N(x) = f(x) − S_N(x)$ satisfies $$ E_N(x) = \frac{f^{(N+1)}(c)x^{N+1}}{(N + 1)!}. $$ Modified Lagrange’s Remainder Theorem: Let $f$ be differentiable $N + 1$ times on $(−R,R)$ , be continuous at $x=R$ , and let the Taylor series of $f$ be convergent at $x=R$ ( $R>0$ ). Define $a_n = f^{(n)}(0)/n!$ for $n = 0,1,\cdots,N$ , and let $$S_N(x) = a_0 +a_1x+a_2x^2 +\cdots+a_Nx^N.$$ There exists a point $c$ satisfying $|c| < R$ where the error function $E_N(x) = f(x) − S_N(x)$ satisfies $$ E_N(R) = \frac{f^{(N+1)}(c)R^{N+1}}{(N + 1)!}. $$ The proof basically runs along the same lines as the first approach that I have outlined above which uses Abel's Theorem, along with the standard proof for Lagrange’s Remainder Theorem.","The following question is from Stephen Abbott's ""Understanding Analysis."" Question: Explain how Lagrange’s Remainder Theorem can be modified to prove A question close to mine was asked here but does not address my concern. The usual procedure used to solve such problems is to first show that the power series can be derived from that of so that the region of convergence for would be , then to show that converges at (using alternating series test in this case).  Abel's theorem would imply that converges uniformly on and continuous limit theorem would imply that is continuous at . Finally, as on , we can conclude that The question however asks us to modify Lagrange’s Remainder Theorem. Following are two statements, the first of which is Lagrange’s Remainder Theorem as given in the text, and the second is the one that I have modified. Please let me know if second statement is correct and if not, please give me a hint as to where I am going wrong. Lagrange’s Remainder Theorem (as given in the text): Let be differentiable times on . Define for , and let Given in , there exists a point satisfying where the error function satisfies Modified Lagrange’s Remainder Theorem: Let be differentiable times on , be continuous at , and let the Taylor series of be convergent at ( ). Define for , and let There exists a point satisfying where the error function satisfies The proof basically runs along the same lines as the first approach that I have outlined above which uses Abel's Theorem, along with the standard proof for Lagrange’s Remainder Theorem.","
1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4} \cdots = \ln2.
 f(x) = \sum_{k=1}^\infty \frac{(-1)^{k-1}x^{k}}{k} 1/(1+x) f(x) (-1,1) f(x) x=1 f(x) [0,1] f(x) x=1 f(x) = \ln(1+x) (-1,1) \ln(2) = 1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4} \cdots f N + 1 (−R,R) a_n = f^{(n)}(0)/n! n = 0,1,\cdots,N 
S_N(x) = a_0 +a_1x+a_2x^2 +\cdots+a_Nx^N.
 x\neq 0 (−R,R) c |c| < |x| E_N(x) = f(x) − S_N(x) 
E_N(x) = \frac{f^{(N+1)}(c)x^{N+1}}{(N + 1)!}.
 f N + 1 (−R,R) x=R f x=R R>0 a_n = f^{(n)}(0)/n! n = 0,1,\cdots,N S_N(x) = a_0 +a_1x+a_2x^2 +\cdots+a_Nx^N. c |c| < R E_N(x) = f(x) − S_N(x) 
E_N(R) = \frac{f^{(N+1)}(c)R^{N+1}}{(N + 1)!}.
","['real-analysis', 'derivatives', 'continuity', 'taylor-expansion']"
24,Gateaux derivative of the following operator,Gateaux derivative of the following operator,,"Let $f \colon \mathbb{R}  \to \mathbb{R}$ be $\mathcal{C}^1[a,b]$ with bounded derivative. Let $H=L^2[a,b]$ and consider the Nemytskii operator $F\colon H \to H$ defined by $$F(x)(\psi)=f(x(\psi))$$ for $\psi \in [a,b]$ . Then I need to show that the Gateaux derivative $DF \colon H \to \mathcal{L}(H)$ of F is $$DF(x) h =\frac{\partial f}{\partial x} (x) h$$ for $h \in H$ being the direction. With the last inequality i mean that $$DF(x) h (\psi) =\frac{\partial f}{\partial x} (x(\psi)) h(\psi)$$ for every $\psi \in [a,b]$ so that $DF(x)h$ is the Nemystkii operator associated with the derivative of $f$ . I take $\psi \in [a,b]$ fixed and I compute $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} (\psi)=\lim_{\alpha \to 0}\frac{f(x(\psi)+\alpha h(\psi)) - f(x(\psi))}{\alpha}= \frac{\partial f}{\partial x} (x(\psi))h(\psi)$$ for every $\psi$ . Then can I conclude that if I define a Nemitskii operator $DF(x)h$ by $DF(x) h (\psi)=\frac{\partial f}{\partial x} (x(\psi))$ this is the Gateaux derivative of $F$ in direction $h$ ? I mean by the previous equality the following $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} $$ is a Nemistkii operator and its action on $\psi$ is the same as $DF(x)h$ so that $$\lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} =DF(x)h$$ and then $DF(x)h$ is the Gateaux derivative.",Let be with bounded derivative. Let and consider the Nemytskii operator defined by for . Then I need to show that the Gateaux derivative of F is for being the direction. With the last inequality i mean that for every so that is the Nemystkii operator associated with the derivative of . I take fixed and I compute for every . Then can I conclude that if I define a Nemitskii operator by this is the Gateaux derivative of in direction ? I mean by the previous equality the following is a Nemistkii operator and its action on is the same as so that and then is the Gateaux derivative.,"f \colon \mathbb{R}  \to \mathbb{R} \mathcal{C}^1[a,b] H=L^2[a,b] F\colon H \to H F(x)(\psi)=f(x(\psi)) \psi \in [a,b] DF \colon H \to \mathcal{L}(H) DF(x) h =\frac{\partial f}{\partial x} (x) h h \in H DF(x) h (\psi) =\frac{\partial f}{\partial x} (x(\psi)) h(\psi) \psi \in [a,b] DF(x)h f \psi \in [a,b] \lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} (\psi)=\lim_{\alpha \to 0}\frac{f(x(\psi)+\alpha h(\psi)) - f(x(\psi))}{\alpha}= \frac{\partial f}{\partial x} (x(\psi))h(\psi) \psi DF(x)h DF(x) h (\psi)=\frac{\partial f}{\partial x} (x(\psi)) F h \lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha}  \psi DF(x)h \lim_{\alpha \to 0}\frac{F(x+\alpha h) - F(x)}{\alpha} =DF(x)h DF(x)h","['functional-analysis', 'derivatives', 'solution-verification', 'gateaux-derivative']"
25,Why does the lower right derivative of a Brownian motion at a fixed $t \ge 0$ is $ - \infty$?,Why does the lower right derivative of a Brownian motion at a fixed  is ?,t \ge 0  - \infty,"I am reading Peter Morters and Yuval Peres's book Brownian Motion. In theorem 1.27, it is proved that for a fixed $t \ge 0,$ almost surely, the Brownian motion $B(t)$ is not differentiable at $t$ and that $D^*B(t)=+ \infty$ and $D_*B(t)=-\infty.$ First we consider the Brownian motion $X(t) := tB(1/t)$ obtained from the time inversion of $B(t).$ Then $$D^*X(0) = \limsup_{h \downarrow 0} \frac {X(0 + h)-X(0)}{h} \ge \limsup_{n \to \infty} \frac {X(1/n)-X(0)}{1/n} \ge \limsup_{n \to \infty} \sqrt n X(1/n) = \limsup_{n \to \infty} B(n)/\sqrt n=+\infty.$$ (It is already stated before in the book that $\limsup_{n \to \infty} B(n)/ \sqrt n = + \infty$ and $\liminf_{n \to \infty} B(n)/ \sqrt n = - \infty.$ ) If I employ the same strategy for $D_*X(0)$ , then I want the inequalities as obtained above to be reversed for $\liminf$ . But it can be seen that the second inequality doesn't reverse! (it is only based on  the inequality $n \gt \sqrt n$ ). So in this way I can't show that $D_*X(0) = \liminf_{h \downarrow 0} \frac {X(0 + h)-X(0)}{h} \le \liminf_{n \to \infty} B(n)/ \sqrt n.$ So what it is it that I am missing here? Moreover, we want $D_*X(0) = D_*B(t).$ In the book, for a fixed $t \ge 0$ , we define $X(s)=B(t+s)-B(t)$ . But how is that possible? Isn't $X(s) := sB(1/s)?$ (I have this very same doubt for showing $D^*X(0)=D^*B(t).$ )","I am reading Peter Morters and Yuval Peres's book Brownian Motion. In theorem 1.27, it is proved that for a fixed almost surely, the Brownian motion is not differentiable at and that and First we consider the Brownian motion obtained from the time inversion of Then (It is already stated before in the book that and ) If I employ the same strategy for , then I want the inequalities as obtained above to be reversed for . But it can be seen that the second inequality doesn't reverse! (it is only based on  the inequality ). So in this way I can't show that So what it is it that I am missing here? Moreover, we want In the book, for a fixed , we define . But how is that possible? Isn't (I have this very same doubt for showing )","t \ge 0, B(t) t D^*B(t)=+ \infty D_*B(t)=-\infty. X(t) := tB(1/t) B(t). D^*X(0) = \limsup_{h \downarrow 0} \frac {X(0 + h)-X(0)}{h} \ge \limsup_{n \to \infty} \frac {X(1/n)-X(0)}{1/n} \ge \limsup_{n \to \infty} \sqrt n X(1/n) = \limsup_{n \to \infty} B(n)/\sqrt n=+\infty. \limsup_{n \to \infty} B(n)/ \sqrt n = + \infty \liminf_{n \to \infty} B(n)/ \sqrt n = - \infty. D_*X(0) \liminf n \gt \sqrt n D_*X(0) = \liminf_{h \downarrow 0} \frac {X(0 + h)-X(0)}{h} \le \liminf_{n \to \infty} B(n)/ \sqrt n. D_*X(0) = D_*B(t). t \ge 0 X(s)=B(t+s)-B(t) X(s) := sB(1/s)? D^*X(0)=D^*B(t).","['probability-theory', 'derivatives', 'proof-explanation', 'brownian-motion', 'limsup-and-liminf']"
26,Ambiguity when finding an Inverse trigonometric derivative [duplicate],Ambiguity when finding an Inverse trigonometric derivative [duplicate],,"This question already has an answer here : What is wrong with this substitution? (1 answer) Closed 3 years ago . The question I was solving was to find the derivative of $y = \arcsin(2x\sqrt{1-x^2}), -\frac{1}{\sqrt{2} } <x< \frac{1}{\sqrt{2}}$ Substituting $x = \cos\theta \Rightarrow \theta = \arccos (x)$ , I got $y = \arcsin(\sin2\theta) = 2\theta$ Differentiating, I got $\frac{-2}{\sqrt{1-x^2}}$ However, substituting $x=\sin\theta$ , simplifying and then differentiating, I got $y' = \frac{2}{\sqrt{1-x^2}}$ , which is the negative of what I'd gotten earlier. Also, this is the correct answer according to my textbook. Both substitutions lead to $2x\sqrt{1-x^2}$ turning into $\sin2\theta$ , so why is the substitution $x = \sin\theta $ more valid than the substitution $x = \cos\theta$ ?","This question already has an answer here : What is wrong with this substitution? (1 answer) Closed 3 years ago . The question I was solving was to find the derivative of Substituting , I got Differentiating, I got However, substituting , simplifying and then differentiating, I got , which is the negative of what I'd gotten earlier. Also, this is the correct answer according to my textbook. Both substitutions lead to turning into , so why is the substitution more valid than the substitution ?","y = \arcsin(2x\sqrt{1-x^2}), -\frac{1}{\sqrt{2} } <x< \frac{1}{\sqrt{2}} x = \cos\theta \Rightarrow \theta = \arccos (x) y = \arcsin(\sin2\theta) = 2\theta \frac{-2}{\sqrt{1-x^2}} x=\sin\theta y' = \frac{2}{\sqrt{1-x^2}} 2x\sqrt{1-x^2} \sin2\theta x = \sin\theta  x = \cos\theta","['calculus', 'derivatives', 'trigonometry', 'substitution']"
27,Functions agree in first $n$ derivatives and differ in the $n+1$-th derivative,Functions agree in first  derivatives and differ in the -th derivative,n n+1,"Let $f:(a,b)\to \mathbb{R}$ and $g:(a,b)\to \mathbb{R}$ such that there exists $x_0\in (a,b)$ verifying $f(x_0)=g(x_0)$ and $$\frac{d^k}{dx^k}f(x_0)=\frac{d^k}{dx^k}g(x_0)$$ for $k=1,\ldots ,n$ and $$\frac{d^{n+1}}{dx^{n+1}}f(x_0)\neq \frac{d^{n+1}}{dx^{n+1}}g(x_0).$$ Prove that: If $n$ is odd then there exists $\delta >0$ such that $f(x)-g(x)$ does not change sign for $x\in (x_0-\delta ,x_0+\delta )$ . If $n$ is even then for every $\delta >0$ there exists $x_1,x_2\in (x_0-\delta ,x_0+\delta )$ such that $f(x_1)-g(x_1)<0<f(x_2)-g(x_2)$ . It is true for $f(x)=x^m$ and $g(x)=x^{m+1}$ with $x_0=0$ , so I have the feeling this should be true for every function verifying the hypothesis, but I don't know how to prove it in general.","Let and such that there exists verifying and for and Prove that: If is odd then there exists such that does not change sign for . If is even then for every there exists such that . It is true for and with , so I have the feeling this should be true for every function verifying the hypothesis, but I don't know how to prove it in general.","f:(a,b)\to \mathbb{R} g:(a,b)\to \mathbb{R} x_0\in (a,b) f(x_0)=g(x_0) \frac{d^k}{dx^k}f(x_0)=\frac{d^k}{dx^k}g(x_0) k=1,\ldots ,n \frac{d^{n+1}}{dx^{n+1}}f(x_0)\neq \frac{d^{n+1}}{dx^{n+1}}g(x_0). n \delta >0 f(x)-g(x) x\in (x_0-\delta ,x_0+\delta ) n \delta >0 x_1,x_2\in (x_0-\delta ,x_0+\delta ) f(x_1)-g(x_1)<0<f(x_2)-g(x_2) f(x)=x^m g(x)=x^{m+1} x_0=0",['real-analysis']
28,Failing to understand some basic idea behind differentiation,Failing to understand some basic idea behind differentiation,,"I just discovered I must have some big holes in my knowledge of basic calculus, and this is scary honestly. I have to compute some derivatives of the solution of a dynamical system: \begin{equation*} \frac{\text d y(t)}{\text dt} = f(t,y(t)),\quad y(t_0) = y_0,\quad t_0\leq t\leq T. \end{equation*} Say that I have to compute derivatives with respect to $t$ . Clearly, $\dfrac{\text d y(t)}{\text dt}$ is given. I want to compute $\dfrac{\text d y(t)}{\text du}$ with $u<t$ . I write: \begin{equation*} y(t) = y(u) +\int_u^t f(\tau,y(\tau))\text d \tau\therefore\dfrac{\text d y(t)}{\text du}=\dfrac{\text d y(u)}{\text du}+\dfrac{\text d}{\text du}\int_u^t f(\tau,y(\tau))\text d \tau=f(u,y(u))+? \end{equation*} The question mark stays for the fact that I have some uncertainties in how to compute the derivative of the integral by Leibniz rule. I will not report here all my doubts, I could fill pages. I assume $\dfrac{\text d y(t)}{\text du}=0$ with $u>t$ for physical reasons (how can future influence past?), but is it actually true? If I unwind all the computation I will get by chain rule some terms like $\dfrac{\text d t}{\text du}$ . Intuitively, it should be zero, but since $\dfrac{\text d t}{\text du}=\left(\dfrac{\text d u}{\text dt}\right)^{-1}$ , then I would set it to 1. the specific case $\dfrac{\text d y(t)}{\text d t_0}$ is the funniest. I get different results when computing it as \begin{equation*} \dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d}{\text d t_0}\left(y_0+\int_{t_0}^t f(\tau,y(\tau))\text d\tau\right) = -f(t_0,y_0) \end{equation*} or \begin{equation*} \dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d y(t)}{\text d t}\dfrac{\text d t}{\text d t_0} = f(t,y(t)) \end{equation*} what about $\dfrac{\text d y(u)}{\text d y(t)}$ with $t<u$ , by Leibniz rule? I obtain different results writing $y(u)=y(t)+\int_t^u f(\tau,y(\tau))\text d\tau$ or $y(u)=y_0+\int_0^u f(\tau,y(\tau))\text d\tau$ $\dfrac{\text d y(u)}{\text d y(t)}$ with $t>u$ would be 0 for physical reasons, or the inverse of what results in point 4, by algebra of differentials. How would you solve these doubts? I think I don't get completely the meaning of derivative ..","I just discovered I must have some big holes in my knowledge of basic calculus, and this is scary honestly. I have to compute some derivatives of the solution of a dynamical system: Say that I have to compute derivatives with respect to . Clearly, is given. I want to compute with . I write: The question mark stays for the fact that I have some uncertainties in how to compute the derivative of the integral by Leibniz rule. I will not report here all my doubts, I could fill pages. I assume with for physical reasons (how can future influence past?), but is it actually true? If I unwind all the computation I will get by chain rule some terms like . Intuitively, it should be zero, but since , then I would set it to 1. the specific case is the funniest. I get different results when computing it as or what about with , by Leibniz rule? I obtain different results writing or with would be 0 for physical reasons, or the inverse of what results in point 4, by algebra of differentials. How would you solve these doubts? I think I don't get completely the meaning of derivative ..","\begin{equation*}
\frac{\text d y(t)}{\text dt} = f(t,y(t)),\quad y(t_0) = y_0,\quad t_0\leq t\leq T.
\end{equation*} t \dfrac{\text d y(t)}{\text dt} \dfrac{\text d y(t)}{\text du} u<t \begin{equation*}
y(t) = y(u) +\int_u^t f(\tau,y(\tau))\text d \tau\therefore\dfrac{\text d y(t)}{\text du}=\dfrac{\text d y(u)}{\text du}+\dfrac{\text d}{\text du}\int_u^t f(\tau,y(\tau))\text d \tau=f(u,y(u))+?
\end{equation*} \dfrac{\text d y(t)}{\text du}=0 u>t \dfrac{\text d t}{\text du} \dfrac{\text d t}{\text du}=\left(\dfrac{\text d u}{\text dt}\right)^{-1} \dfrac{\text d y(t)}{\text d t_0} \begin{equation*}
\dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d}{\text d t_0}\left(y_0+\int_{t_0}^t f(\tau,y(\tau))\text d\tau\right) = -f(t_0,y_0)
\end{equation*} \begin{equation*}
\dfrac{\text d y(t)}{\text d t_0} = \dfrac{\text d y(t)}{\text d t}\dfrac{\text d t}{\text d t_0} = f(t,y(t))
\end{equation*} \dfrac{\text d y(u)}{\text d y(t)} t<u y(u)=y(t)+\int_t^u f(\tau,y(\tau))\text d\tau y(u)=y_0+\int_0^u f(\tau,y(\tau))\text d\tau \dfrac{\text d y(u)}{\text d y(t)} t>u","['calculus', 'integration', 'derivatives', 'chain-rule', 'leibniz-integral-rule']"
29,How to use MVT to prove the following problem,How to use MVT to prove the following problem,,"Let $f(x)$ be continuous on $[a,b]$ , differentiable on $(a,b)$ , and $f(a)=f(b),|f'(x)|\leqslant1$ . prove that for any $x_1,x_2\in[a,b]$ establish $$|f(x_1)-f(x_2)|\leqslant\frac{b-a}{2}.$$ I want to use MVT.But I don't know how did the $\frac{1}{2}$ .","Let be continuous on , differentiable on , and . prove that for any establish I want to use MVT.But I don't know how did the .","f(x) [a,b] (a,b) f(a)=f(b),|f'(x)|\leqslant1 x_1,x_2\in[a,b] |f(x_1)-f(x_2)|\leqslant\frac{b-a}{2}. \frac{1}{2}","['real-analysis', 'derivatives']"
30,Understating the acceleration equation in terms of velocity,Understating the acceleration equation in terms of velocity,,"Sorry if this is considered a ‘basic’ question, but I’ve been stuck on this for a while now and can’t find much help. I know $\frac{d}{dx} \left(\frac{1}{2} v^2\right) =$ acceleration. But I do not understand what is wrong with my working out. $$\left(\frac{d}{dt}\right)\left(\frac{dx}{dt}\right) = \left(\frac{d}{dx}\right)\left(\frac{dx}{dt}\right)\left(\frac{dx}{dt}\right) = \frac{d}{dx} (v^2)$$ I don’t know why I am missing the half that is in the original equation. I have seen the proof for it, but I do not exactly know what wrong assumption I am making. Thank you.","Sorry if this is considered a ‘basic’ question, but I’ve been stuck on this for a while now and can’t find much help. I know acceleration. But I do not understand what is wrong with my working out. I don’t know why I am missing the half that is in the original equation. I have seen the proof for it, but I do not exactly know what wrong assumption I am making. Thank you.",\frac{d}{dx} \left(\frac{1}{2} v^2\right) = \left(\frac{d}{dt}\right)\left(\frac{dx}{dt}\right) = \left(\frac{d}{dx}\right)\left(\frac{dx}{dt}\right)\left(\frac{dx}{dt}\right) = \frac{d}{dx} (v^2),"['calculus', 'derivatives', 'chain-rule']"
31,Property of a covariant derivative of a vector field along a curve,Property of a covariant derivative of a vector field along a curve,,"I am studying the covariant derivative of a vector field $X$ along a curve $\gamma$ ( $\nabla_{\dot \gamma}X:=\frac{\nabla X}{dt}$ ) and I have read the following property: $$\nabla_{\dot \gamma}X=\Big(\frac{d \xi^k}{dt}+\Gamma_{ij}^k\frac{dx^i}{dt}\xi^j\Big)\frac{\partial}{\partial_k}$$ In order to prove this above I have thought that if $X=\xi^j \frac{\partial}{\partial x^j}$ and $\dot \gamma= \frac{dx^i}{dt} \frac{\partial}{\partial x^i}$ , we have that: since $\nabla X=\Big(\frac{\partial \xi^k}{\partial x^j}+\Gamma_{ji}^k\xi^j\Big)\frac{\partial}{\partial_k}$ we obtain: $$\nabla_{\dot \gamma}X=\nabla_{\frac{dx^i}{dt}\frac{\partial}{\partial x^i}}(\xi^j \frac{\partial}{\partial x^j})=\frac{dx^i}{dt}\Big(\nabla_{\frac{\partial}{\partial x^k}}(\xi^j \frac{\partial}{\partial x^j})\Big)=\frac{dx^i}{dt}\Big(\xi^j\nabla_{\frac{\partial}{\partial x^i}}( \frac{\partial}{\partial x^j})\Big)+\frac{dx^i}{dt}\Big(\xi^j\frac{\partial}{\partial x^i}\Big)\frac{\partial}{\partial x^j}=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{dx^i}{dt}(\frac{\partial}{\partial x^i})}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{d\xi^j}{dt}}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k+{\frac{d\xi^k}{dt}}\Big)\frac{\partial}{\partial x^k}$$ where the last equality is obtained considering the index $j$ in the second term as $k$ . $\textbf{My question:}$ do you think that the passages that I have done are correct? In particular it is valid the equality that involves the red quantities (I am not sure that is mathematically rigorous)?","I am studying the covariant derivative of a vector field along a curve ( ) and I have read the following property: In order to prove this above I have thought that if and , we have that: since we obtain: where the last equality is obtained considering the index in the second term as . do you think that the passages that I have done are correct? In particular it is valid the equality that involves the red quantities (I am not sure that is mathematically rigorous)?",X \gamma \nabla_{\dot \gamma}X:=\frac{\nabla X}{dt} \nabla_{\dot \gamma}X=\Big(\frac{d \xi^k}{dt}+\Gamma_{ij}^k\frac{dx^i}{dt}\xi^j\Big)\frac{\partial}{\partial_k} X=\xi^j \frac{\partial}{\partial x^j} \dot \gamma= \frac{dx^i}{dt} \frac{\partial}{\partial x^i} \nabla X=\Big(\frac{\partial \xi^k}{\partial x^j}+\Gamma_{ji}^k\xi^j\Big)\frac{\partial}{\partial_k} \nabla_{\dot \gamma}X=\nabla_{\frac{dx^i}{dt}\frac{\partial}{\partial x^i}}(\xi^j \frac{\partial}{\partial x^j})=\frac{dx^i}{dt}\Big(\nabla_{\frac{\partial}{\partial x^k}}(\xi^j \frac{\partial}{\partial x^j})\Big)=\frac{dx^i}{dt}\Big(\xi^j\nabla_{\frac{\partial}{\partial x^i}}( \frac{\partial}{\partial x^j})\Big)+\frac{dx^i}{dt}\Big(\xi^j\frac{\partial}{\partial x^i}\Big)\frac{\partial}{\partial x^j}=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{dx^i}{dt}(\frac{\partial}{\partial x^i})}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k\frac{\partial}{\partial x^k}+\color{red}{\frac{d\xi^j}{dt}}\frac{\partial}{\partial x^j}\Big)=\Big(\frac{dx^i}{dt}\xi^j\Gamma_{ij}^k+{\frac{d\xi^k}{dt}}\Big)\frac{\partial}{\partial x^k} j k \textbf{My question:},"['derivatives', 'differential-geometry', 'vector-fields']"
32,Determine the partial derivative of $\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}$.,Determine the partial derivative of .,\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)},"Determine the partial derivative of $f(x)$ : $$f(x,y)=\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}$$ Here's what I have so far: \begin{align} \frac{\partial \:}{\partial \:x}\left(\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}\right) &= \frac{\frac{\partial \:}{\partial \:x}\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)\cos ^2\left(x^2y^2\right)-\frac{\partial \:}{\partial \:x}\left(\cos ^2\left(x^2y^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\ &= \frac{\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(y^2x^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)\cos ^2\left(x^2y^2\right)-\left(-2y^2x\sin \left(2y^2x^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\ &= \frac{\cos ^2\left(x^2y^2\right)\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(x^2y^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)+2xy^2\sin \left(2x^2y^2\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\cos ^4\left(x^2y^2\right)} \end{align} However, I am not sure if this answer is correct since I get a different answer on emathhelp website.","Determine the partial derivative of : Here's what I have so far: However, I am not sure if this answer is correct since I get a different answer on emathhelp website.","f(x) f(x,y)=\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)} \begin{align}
\frac{\partial \:}{\partial \:x}\left(\frac{\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}}{\cos ^2\left(x^2y^2\right)}\right) &= \frac{\frac{\partial \:}{\partial \:x}\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)\cos ^2\left(x^2y^2\right)-\frac{\partial \:}{\partial \:x}\left(\cos ^2\left(x^2y^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\
&= \frac{\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(y^2x^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)\cos ^2\left(x^2y^2\right)-\left(-2y^2x\sin \left(2y^2x^2\right)\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\left(\cos ^2\left(x^2y^2\right)\right)^2} \\
&= \frac{\cos ^2\left(x^2y^2\right)\left(\frac{2\tan \left(\frac{1}{x^2+1}\right)}{x}-\frac{2x\ln \left(x^2y^2\right)\sec ^2\left(\frac{1}{x^2+1}\right)}{\left(x^2+1\right)^2}+\frac{2x}{3\left(x^2+y^2\right)^{\frac{2}{3}}}\right)+2xy^2\sin \left(2x^2y^2\right)\left(\ln \left(x^2y^2\right)\tan \left(\frac{1}{x^2+1}\right)+\sqrt[3]{x^2+y^2}\right)}{\cos ^4\left(x^2y^2\right)}
\end{align}","['real-analysis', 'calculus', 'complex-analysis', 'derivatives', 'partial-derivative']"
33,Continuity of Functions with Vertical Tangents,Continuity of Functions with Vertical Tangents,,"I'm running into some confusion regarding properties of continuous functions. I'm comfortable with the epsilon-delta definition of limits and the basic definition of continuity at a point $a$ ( $\lim_{x\rightarrow a}f(x)$ must exist, $f(a)$ must exist, and the two must equal one another), but I'm frequently encountering the statement that a function is continuous if and only if ""a small change in $x$ produces a small change in $f(x)$ "". This seems reasonable enough, but continuous functions with vertical tangents seem to present a contradiction to this assertion. For example, the function $f(x)=\sqrt[3]{x}$ is continuous at $x=0$ by the definition of continuity, but its derivative at $x=0$ is undefined because the line tangent to the curve $y=f(x)$ is vertical. Shouldn't this mean, then, that at $x=0$ a small change in $x$ produces an infinite change in $y$ ? I'm not sure if $\left.\frac{dy}{dx}\right|_{x=0}=\infty$ constitutes an abuse of notation, but certainly it is true that $f^\prime(0)$ is undefined and $$\lim_{x\rightarrow 0}f^\prime(x)=\infty\text{.}$$ So I'm not sure how this ""small change in $x$ /small change in $f(x)$ "" description of continuity holds in this particular case.  Can anyone help resolve this confusion for me?","I'm running into some confusion regarding properties of continuous functions. I'm comfortable with the epsilon-delta definition of limits and the basic definition of continuity at a point ( must exist, must exist, and the two must equal one another), but I'm frequently encountering the statement that a function is continuous if and only if ""a small change in produces a small change in "". This seems reasonable enough, but continuous functions with vertical tangents seem to present a contradiction to this assertion. For example, the function is continuous at by the definition of continuity, but its derivative at is undefined because the line tangent to the curve is vertical. Shouldn't this mean, then, that at a small change in produces an infinite change in ? I'm not sure if constitutes an abuse of notation, but certainly it is true that is undefined and So I'm not sure how this ""small change in /small change in "" description of continuity holds in this particular case.  Can anyone help resolve this confusion for me?",a \lim_{x\rightarrow a}f(x) f(a) x f(x) f(x)=\sqrt[3]{x} x=0 x=0 y=f(x) x=0 x y \left.\frac{dy}{dx}\right|_{x=0}=\infty f^\prime(0) \lim_{x\rightarrow 0}f^\prime(x)=\infty\text{.} x f(x),"['calculus', 'limits', 'derivatives', 'continuity', 'infinitesimals']"
34,"Meaning of the space $W_0^{1,p}$",Meaning of the space,"W_0^{1,p}","I don't understand why the space $W_0^{1,p}(\Omega)$ is defined like the closure of $C^{\infty}_c(\Omega)$ functions and not like the space of $W^{1,p}(\Omega)$ functions with compact support in $\Omega$ . I don't understand if this is a useful definition, and in this case, why this is a useful definition? Or if there is another reason for this definition.","I don't understand why the space is defined like the closure of functions and not like the space of functions with compact support in . I don't understand if this is a useful definition, and in this case, why this is a useful definition? Or if there is another reason for this definition.","W_0^{1,p}(\Omega) C^{\infty}_c(\Omega) W^{1,p}(\Omega) \Omega","['real-analysis', 'derivatives', 'compactness', 'sobolev-spaces', 'calculus-of-variations']"
35,A matrix differentiation with trace and kronecker product,A matrix differentiation with trace and kronecker product,,"I'm new to matrix calculus and want to differentiate the following function w.r.t $X$ , $Y$ $$\phi(X,Y) = Y^TA^T(L\otimes X):Y^TA^T(L\otimes X) =tr((L\otimes X)^TAYY^TA^T(L\otimes X)) $$ I know the derivative w.r.t $Y$ , but have no idea how to start it w.r.t $X$ I have checked some related questions and solutions, but I still have no idea how the 'differential' $d\phi$ are derived. Is there any reference about calculating the differential of a matrix? Any help will be appreciated!!","I'm new to matrix calculus and want to differentiate the following function w.r.t , I know the derivative w.r.t , but have no idea how to start it w.r.t I have checked some related questions and solutions, but I still have no idea how the 'differential' are derived. Is there any reference about calculating the differential of a matrix? Any help will be appreciated!!","X Y \phi(X,Y) = Y^TA^T(L\otimes X):Y^TA^T(L\otimes X)
=tr((L\otimes X)^TAYY^TA^T(L\otimes X))  Y X d\phi","['matrices', 'derivatives', 'matrix-calculus']"
36,Why do we say limits which go to infinity are not defined?,Why do we say limits which go to infinity are not defined?,,I recently saw this article by oregonstate.edu about the differentiability of the function $y=\sqrt{X}$ at $x=0$ they claim that the derivative at $x=0$ does not exist.i understand the concept of one-sided differentiability and how the $\lim_{h \to 0-} \frac{\sqrt{x+h}-\sqrt{x}}{h} $ does not exist but for values of greater than 0 and approaching from the right they say that the limit does not exist as it is positive infinity. my question is why isn't this limit defined surely we know it is approaching infinity so why can't we say it has an infinite slope,I recently saw this article by oregonstate.edu about the differentiability of the function at they claim that the derivative at does not exist.i understand the concept of one-sided differentiability and how the does not exist but for values of greater than 0 and approaching from the right they say that the limit does not exist as it is positive infinity. my question is why isn't this limit defined surely we know it is approaching infinity so why can't we say it has an infinite slope,y=\sqrt{X} x=0 x=0 \lim_{h \to 0-} \frac{\sqrt{x+h}-\sqrt{x}}{h} ,"['real-analysis', 'derivatives', 'self-learning']"
37,Confused: using Taylor series to find derivative,Confused: using Taylor series to find derivative,,"TL;DR: read bolded parts Lets say I have f(x) = sin(x^2) and I want the f''''''(0) (6th derivative). Using taylor series, this is really simple. We plug in x^2 into the taylor polynomial of sin(x), and get this: Then the 6th derivative is 1/3! * 6! = 120. I am confused because taylor series seems really unrelated; there should be an equally easy way to do this just with derivatives and chain rule (no detour to taylor series) . But when I bash it out, I don't get a simple solution. (120 on the last line, typo) Why does taylor series come up in finding derivatives?","TL;DR: read bolded parts Lets say I have f(x) = sin(x^2) and I want the f''''''(0) (6th derivative). Using taylor series, this is really simple. We plug in x^2 into the taylor polynomial of sin(x), and get this: Then the 6th derivative is 1/3! * 6! = 120. I am confused because taylor series seems really unrelated; there should be an equally easy way to do this just with derivatives and chain rule (no detour to taylor series) . But when I bash it out, I don't get a simple solution. (120 on the last line, typo) Why does taylor series come up in finding derivatives?",,"['calculus', 'derivatives', 'taylor-expansion']"
38,Limit of a simple Integral,Limit of a simple Integral,,"Need to show that $$\lim_{t\to 1^-}(1-t)\int_0^t\frac{g(s)}{(1-s)^2}ds=g(1)$$ for any continuous function $g(s)$ . I tried a variable change $u=1/(1-s)$ which gives $du=ds/(1-s)^2$ with $$(1-t)\int_1^{\frac{1}{1-t}}g(1-\frac{1}{u})du$$ I cannot seem to figure out how to get to the limit, given that thus far it's correct.","Need to show that for any continuous function . I tried a variable change which gives with I cannot seem to figure out how to get to the limit, given that thus far it's correct.",\lim_{t\to 1^-}(1-t)\int_0^t\frac{g(s)}{(1-s)^2}ds=g(1) g(s) u=1/(1-s) du=ds/(1-s)^2 (1-t)\int_1^{\frac{1}{1-t}}g(1-\frac{1}{u})du,"['calculus', 'integration', 'limits', 'derivatives', 'improper-integrals']"
39,How many times is $f^{-1}$ differentbable if $f$ is differentiable $m$ times at $x$?,How many times is  differentbable if  is differentiable  times at ?,f^{-1} f m x,Let $f$ be continuously differentiable $m$ times at $x \in \mathbb{R}$ . Does it then follow that $f^{-1}$ (assuming it exists) is also continuously differentiable $m$ times at $f(x)$ ? This is true for $m=1$ but does it hold for any $m$ ? Thank you!,Let be continuously differentiable times at . Does it then follow that (assuming it exists) is also continuously differentiable times at ? This is true for but does it hold for any ? Thank you!,f m x \in \mathbb{R} f^{-1} m f(x) m=1 m,"['calculus', 'derivatives']"
40,Derivative of trace-based linear scalar field,Derivative of trace-based linear scalar field,,"I'm just getting into matrix calculus, so this question might be really easy for you guys out there. I'm trying to understand some of the simpler derivations in The Matrix Cookbook. I've been looking at derivatives of the trace predominantly. The following formulas are given: $$ \frac{\delta}{\delta X} {\rm Tr}(XA) = A^T $$ $$ \frac{\delta}{\delta X} {\rm Tr}(AX^T) = A $$ I can't completely reproduce these example though. When I try to take the derivative with a small example manually, I always get $A$ . \begin{align} \frac{\delta}{\delta X} {\rm Tr}\left( \begin{bmatrix} x_1 & x_2 \\ x_3 & x_4 \end{bmatrix} \begin{bmatrix} a_1 & a_2 \\ a_3 & a_4 \end{bmatrix} \right) &= \frac{\delta}{\delta X} {\rm Tr}\left( \begin{bmatrix} a_1x_1 + a_3x_2 & a_2x_1 + a_4x_2 \\ a_1x_3 + a_3x_4 & a_2x_3 + a_4x_4 \end{bmatrix}\right) \\ &= {\rm Tr}\left( \begin{bmatrix} \begin{bmatrix} a_1 & a_2 \\ 0 & 0 \end{bmatrix} & \begin{bmatrix} a_3 & a_4 \\ 0 & 0 \end{bmatrix} \\ \begin{bmatrix} 0 & 0\\ a_1 & a_2 \end{bmatrix} & \begin{bmatrix} 0 & 0 \\ a_3 & a_4  \end{bmatrix}  \end{bmatrix} \right)\\ &= \begin{bmatrix} a_1 & a_2 \\ a_3 & a_4 \end{bmatrix} \end{align} \begin{align} \frac{\delta}{\delta X} {\rm Tr}\left( \begin{bmatrix} a_1 & a_2 \\ a_3 & a_4 \end{bmatrix} \begin{bmatrix} x_1 & x_3 \\ x_2 & x_4 \end{bmatrix} \right) &= \frac{\delta}{\delta X} {\rm Tr}\left( \begin{bmatrix} a_1x_1 + a_2x_2 & a_1x_3 + a_2x_4 \\ a_3x_1 + a_4x_2 & a_3x_3 + a_4x_4 \end{bmatrix}\right) \\ &= {\rm Tr}\left( \begin{bmatrix} \begin{bmatrix} a_1 & 0 \\ a_3 & 0 \end{bmatrix} & \begin{bmatrix} 0 & a_2 \\ 0 & a_4 \end{bmatrix} \\ \begin{bmatrix} a_1 & 0\\ a_3 & 0 \end{bmatrix} & \begin{bmatrix} 0 & a_2 \\ 0 & a_4  \end{bmatrix}  \end{bmatrix} \right)\\ &= \begin{bmatrix} a_1 & a_2 \\ a_3 & a_4 \end{bmatrix} \end{align} I'm sorry if the notation is wrong and thanks for your help.","I'm just getting into matrix calculus, so this question might be really easy for you guys out there. I'm trying to understand some of the simpler derivations in The Matrix Cookbook. I've been looking at derivatives of the trace predominantly. The following formulas are given: I can't completely reproduce these example though. When I try to take the derivative with a small example manually, I always get . I'm sorry if the notation is wrong and thanks for your help.","
\frac{\delta}{\delta X} {\rm Tr}(XA) = A^T
 
\frac{\delta}{\delta X} {\rm Tr}(AX^T) = A
 A \begin{align}
\frac{\delta}{\delta X}
{\rm Tr}\left(
\begin{bmatrix}
x_1 & x_2 \\
x_3 & x_4
\end{bmatrix}
\begin{bmatrix}
a_1 & a_2 \\
a_3 & a_4
\end{bmatrix}
\right) &=
\frac{\delta}{\delta X}
{\rm Tr}\left(
\begin{bmatrix}
a_1x_1 + a_3x_2 & a_2x_1 + a_4x_2 \\
a_1x_3 + a_3x_4 & a_2x_3 + a_4x_4
\end{bmatrix}\right)
\\
&=
{\rm Tr}\left(
\begin{bmatrix}
\begin{bmatrix}
a_1 & a_2 \\
0 & 0
\end{bmatrix} &
\begin{bmatrix}
a_3 & a_4 \\
0 & 0
\end{bmatrix} \\
\begin{bmatrix}
0 & 0\\
a_1 & a_2
\end{bmatrix} &
\begin{bmatrix}
0 & 0 \\
a_3 & a_4 
\end{bmatrix} 
\end{bmatrix}
\right)\\
&=
\begin{bmatrix}
a_1 & a_2 \\
a_3 & a_4
\end{bmatrix}
\end{align} \begin{align}
\frac{\delta}{\delta X}
{\rm Tr}\left(
\begin{bmatrix}
a_1 & a_2 \\
a_3 & a_4
\end{bmatrix}
\begin{bmatrix}
x_1 & x_3 \\
x_2 & x_4
\end{bmatrix}
\right) &=
\frac{\delta}{\delta X}
{\rm Tr}\left(
\begin{bmatrix}
a_1x_1 + a_2x_2 & a_1x_3 + a_2x_4 \\
a_3x_1 + a_4x_2 & a_3x_3 + a_4x_4
\end{bmatrix}\right)
\\
&=
{\rm Tr}\left(
\begin{bmatrix}
\begin{bmatrix}
a_1 & 0 \\
a_3 & 0
\end{bmatrix} &
\begin{bmatrix}
0 & a_2 \\
0 & a_4
\end{bmatrix} \\
\begin{bmatrix}
a_1 & 0\\
a_3 & 0
\end{bmatrix} &
\begin{bmatrix}
0 & a_2 \\
0 & a_4 
\end{bmatrix} 
\end{bmatrix}
\right)\\
&=
\begin{bmatrix}
a_1 & a_2 \\
a_3 & a_4
\end{bmatrix}
\end{align}","['matrices', 'derivatives', 'matrix-calculus', 'trace', 'scalar-fields']"
41,Derivative of a smooth function as an equivalence class,Derivative of a smooth function as an equivalence class,,"In my differential manifolds class, the derivative of a function $f \in C^\infty (M)$ , where $M$ is a manifold, at $p \in M$ was defined as the image of the linear map $$(df)_p := C^\infty (M) \mapsto C^\infty (M)/Z_p$$ where $Z_p$ is the set of all smooth functions that have zero derivative at $p$ . In other words, the derivative is an equivalence class of $C^\infty (M)$ defined by the relation that two functions are related if their derivative vanishes at $p$ , the derivative of a function at a point is an equivalence class. I'm struggling to wrap my head around this. How can a derivative become an equivalence class? Does this hold in elementary calculus too?","In my differential manifolds class, the derivative of a function , where is a manifold, at was defined as the image of the linear map where is the set of all smooth functions that have zero derivative at . In other words, the derivative is an equivalence class of defined by the relation that two functions are related if their derivative vanishes at , the derivative of a function at a point is an equivalence class. I'm struggling to wrap my head around this. How can a derivative become an equivalence class? Does this hold in elementary calculus too?",f \in C^\infty (M) M p \in M (df)_p := C^\infty (M) \mapsto C^\infty (M)/Z_p Z_p p C^\infty (M) p,"['derivatives', 'differential-geometry', 'manifolds']"
42,"Derivative of a function of the form $f=f(x,g(x))$",Derivative of a function of the form,"f=f(x,g(x))","Consider a function of the following form $f=f(x,g(x))$ . For the derivative of this function, we do the following. $$ \frac{df}{dx} = \frac{df}{dx} \bigg\rvert_{g}+\frac{df}{dg} \frac{dg}{dx} $$ I have the following question about the above equation. Since $g$ itself is a function of $x$ , does it even make sense to say "" $f$ is a function of $x$ and $g$ ""? Does the first term of the equation read ""derivative of $f$ with respect to $x$ at a fixed $g$ ""? If so, how does this make sense since if $x$ is changed, $g$ also changes and the derivative is no longer calculated at a fixed $g$ . Please let me know if you need me to make myself more clearer. Thank you for answering.","Consider a function of the following form . For the derivative of this function, we do the following. I have the following question about the above equation. Since itself is a function of , does it even make sense to say "" is a function of and ""? Does the first term of the equation read ""derivative of with respect to at a fixed ""? If so, how does this make sense since if is changed, also changes and the derivative is no longer calculated at a fixed . Please let me know if you need me to make myself more clearer. Thank you for answering.","f=f(x,g(x)) 
\frac{df}{dx} = \frac{df}{dx} \bigg\rvert_{g}+\frac{df}{dg} \frac{dg}{dx}
 g x f x g f x g x g g",['derivatives']
43,What is the Name of this Point?,What is the Name of this Point?,,"I am trying to find the name of the point at which the derivative of a function at that point is zero but it is not a local max or min within any interval. For instance, take the function $y=(x+1)(x-1)^3$ . The roots of the first derivative are -0.5, one, and one but the function at $x=1$ is neither a local max or a local min. What is the name of this point? Is it just a Point of Inflection or is there another name? $y=(x+1)(x-1)^3$ "" />","I am trying to find the name of the point at which the derivative of a function at that point is zero but it is not a local max or min within any interval. For instance, take the function . The roots of the first derivative are -0.5, one, and one but the function at is neither a local max or a local min. What is the name of this point? Is it just a Point of Inflection or is there another name? $y=(x+1)(x-1)^3$ "" />",y=(x+1)(x-1)^3 x=1,"['calculus', 'derivatives', 'terminology', 'roots', 'graphing-functions']"
44,On tangents of parabolas,On tangents of parabolas,,"Question Let $a > 0$ and $b > 0$ be constants. Suppose that the parabolas $$C_1 : y^2 = 4a(a - x)\ \mathrm {and}\ C_2 : y^2 = 4b(b + x)$$ intersect at a point $P$ . Prove that the tangent line to $C_1$ at $P$ and the tangent line to $C_2$ at $P$ are perpendicular. My Working From $C_1$ , $$2y\frac {dy} {dx} = -4a$$ $$\implies \frac {dy} {dx} = -\frac {2a} {y}$$ From $C_2$ , $$2y\frac {dy} {dx} = 4b$$ $$\implies \frac {dy} {dx} = \frac {2b} {y}$$ Then, from elementary geometry, I know that for two lines to be perpendicular to each other, the product of their gradients must be $-1$ . Thus, working backwards, $$(-\frac {2a} {y})(\frac {2b} {y}) = -1$$ $$\implies y^2 = 4ab$$ so the problem reduces to showing that $$y^2 = 4ab$$ and we are done. However, this is where I am stuck. How do I show the above relation given only the equations of the two curves? Any suggestions to how I may proceed or even alternatives to solving this problem will be nice :)","Question Let and be constants. Suppose that the parabolas intersect at a point . Prove that the tangent line to at and the tangent line to at are perpendicular. My Working From , From , Then, from elementary geometry, I know that for two lines to be perpendicular to each other, the product of their gradients must be . Thus, working backwards, so the problem reduces to showing that and we are done. However, this is where I am stuck. How do I show the above relation given only the equations of the two curves? Any suggestions to how I may proceed or even alternatives to solving this problem will be nice :)",a > 0 b > 0 C_1 : y^2 = 4a(a - x)\ \mathrm {and}\ C_2 : y^2 = 4b(b + x) P C_1 P C_2 P C_1 2y\frac {dy} {dx} = -4a \implies \frac {dy} {dx} = -\frac {2a} {y} C_2 2y\frac {dy} {dx} = 4b \implies \frac {dy} {dx} = \frac {2b} {y} -1 (-\frac {2a} {y})(\frac {2b} {y}) = -1 \implies y^2 = 4ab y^2 = 4ab,"['real-analysis', 'calculus', 'derivatives']"
45,L'Hospital rule to find limit on indeterminate form.,L'Hospital rule to find limit on indeterminate form.,,"I have the following limit to compute: $$\lim_{x\to 0}{\left(\cos x -1\over {5 x^2}\right)}$$ I need to find the limit as $x \to 0$ .  I tried using L'Hospital rule , so I found the derivative of the numerator, which is: $${-\sin x}$$ The derivative of the denominator is: $${10x}$$ Now I have the following: $${-\sin x \over {10x}}$$ What should I do now? , I'm not sure on how I could apply direct substitution to this problem?","I have the following limit to compute: I need to find the limit as .  I tried using L'Hospital rule , so I found the derivative of the numerator, which is: The derivative of the denominator is: Now I have the following: What should I do now? , I'm not sure on how I could apply direct substitution to this problem?",\lim_{x\to 0}{\left(\cos x -1\over {5 x^2}\right)} x \to 0 {-\sin x} {10x} {-\sin x \over {10x}},"['limits', 'derivatives', 'substitution']"
46,Find solutions for $f'(\sin x) f(\cos x)=\sin x$,Find solutions for,f'(\sin x) f(\cos x)=\sin x,"We are given $$f'(\sin x) f(\cos x)=\sin x$$ and we need to find out the function which respects this condition. The answer is $$f(x)=\sqrt{c}e^{\frac{1}{2c}(x^2-\frac{1}{2})}$$ I tried to expand the initial condition just as on the other problems, but I can't seem to be getting anywhere, and having trigonometrical functions doesn't make it better. The closest I've gotten to the answer is through an integration after which nothing else works.","We are given and we need to find out the function which respects this condition. The answer is I tried to expand the initial condition just as on the other problems, but I can't seem to be getting anywhere, and having trigonometrical functions doesn't make it better. The closest I've gotten to the answer is through an integration after which nothing else works.",f'(\sin x) f(\cos x)=\sin x f(x)=\sqrt{c}e^{\frac{1}{2c}(x^2-\frac{1}{2})},"['integration', 'complex-analysis', 'derivatives', 'trigonometry']"
47,Number of solutions of $\ln(|a-x|)=x$,Number of solutions of,\ln(|a-x|)=x,"I don't want to duplicate this question: which is too similar to post it again but could you explain to me, how do we determine the number of root in the interval, using the derivative? I have tried substitution with: $$ y=a-x\\x=a-y~~for~x>0\\x=y-a~~for~x<0\\x>0\\f(y)=\ln(y)+y-a\\f'(y)=\frac{1}{y}+1\\f'(y)=0~~~y=-1\\\\f'(y)>0~~~y<-1\\\\f'(y)<0~~~y>-1\\min=0$$ Then I substitute: $$\ f(-1)=a+1$$ Thus $f(-1)=0$ for $a=1$ . Similarly I construct the answers for $x<0$ . However, how to determine the number of roots for every interval of a?","I don't want to duplicate this question: which is too similar to post it again but could you explain to me, how do we determine the number of root in the interval, using the derivative? I have tried substitution with: Then I substitute: Thus for . Similarly I construct the answers for . However, how to determine the number of roots for every interval of a?", y=a-x\\x=a-y~~for~x>0\\x=y-a~~for~x<0\\x>0\\f(y)=\ln(y)+y-a\\f'(y)=\frac{1}{y}+1\\f'(y)=0~~~y=-1\\\\f'(y)>0~~~y<-1\\\\f'(y)<0~~~y>-1\\min=0 \ f(-1)=a+1 f(-1)=0 a=1 x<0,"['real-analysis', 'derivatives']"
48,Derivative of matrix-valued function with respect to scalar,Derivative of matrix-valued function with respect to scalar,,"Given vector $\mu \in \Bbb R^n$ and $n \times n$ matrices $A$ and $\Sigma$ , let matrix-valued function $F : \Bbb R \to \Bbb R^{n \times n}$ be defined by $$F(t) := |(I-2tA\Sigma)|^{1/2} \exp \left(\frac{1}{2}\mu'[I-(I-2tA\Sigma)^{-1})\Sigma^{-1}\mu \right)$$ How can I get the second derivative of $F$ with respect to $t$ ? Could someone please give me a hint?","Given vector and matrices and , let matrix-valued function be defined by How can I get the second derivative of with respect to ? Could someone please give me a hint?",\mu \in \Bbb R^n n \times n A \Sigma F : \Bbb R \to \Bbb R^{n \times n} F(t) := |(I-2tA\Sigma)|^{1/2} \exp \left(\frac{1}{2}\mu'[I-(I-2tA\Sigma)^{-1})\Sigma^{-1}\mu \right) F t,"['calculus', 'linear-algebra', 'matrices', 'derivatives', 'matrix-calculus']"
49,An easy Real Analysis Problem,An easy Real Analysis Problem,,"I found this Real Analysis problem from the MTRP book published by ISI for class 11. I . Suppose the function $f:[a,b]\to \Bbb R$ is differentiable on $(a,b)$ , where $b-a\geq 4$ . Prove that there is $x_0\in (a,b)$ such that $$f'(x_0)<1+\big(f(x_0)\big)^2.$$ My ideas of solving : When I first saw the problem I just tracked it from reverse and got idea that this problem involves $\arctan(x)$ . So I considered a function $g(x) = \arctan(f(x))$ . This get's the problem to be transformed to showing that for some real number $c$ we have $g(c) < c$ . For this I considered another function $h(x) = g(x) - x$ . But at this point Iam struck and have no idea where to go about.","I found this Real Analysis problem from the MTRP book published by ISI for class 11. I . Suppose the function is differentiable on , where . Prove that there is such that My ideas of solving : When I first saw the problem I just tracked it from reverse and got idea that this problem involves . So I considered a function . This get's the problem to be transformed to showing that for some real number we have . For this I considered another function . But at this point Iam struck and have no idea where to go about.","f:[a,b]\to \Bbb R (a,b) b-a\geq 4 x_0\in (a,b) f'(x_0)<1+\big(f(x_0)\big)^2. \arctan(x) g(x) = \arctan(f(x)) c g(c) < c h(x) = g(x) - x","['real-analysis', 'derivatives', 'continuity']"
50,Evaluating $\int_{-1/2}^{1} \cos^{-1} \frac{1-x^2}{1+x^2} dx$,Evaluating,\int_{-1/2}^{1} \cos^{-1} \frac{1-x^2}{1+x^2} dx,Let us do the integration by parts $$I=\int_{-1/2}^{1} ~\cos^{-1} \frac{1-x^2}{1+x^2}. 1~ dx =\left.x \cos^{-1} \frac{1-x^2}{1+x^2}\right|_{-1/2}^{1}-\int_{-1/2}^{1} \frac{2x}{1+x^2} dx$$ $$=\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\left .\ln(1+x^2)\right|_{-1/2}^{1}=\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\ln\frac{8}{5}.$$ The question is whether something is amiss here and whether the answer is right. EDit The correct answer is $$I=\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\ln\frac{5}{2}.$$,Let us do the integration by parts The question is whether something is amiss here and whether the answer is right. EDit The correct answer is,I=\int_{-1/2}^{1} ~\cos^{-1} \frac{1-x^2}{1+x^2}. 1~ dx =\left.x \cos^{-1} \frac{1-x^2}{1+x^2}\right|_{-1/2}^{1}-\int_{-1/2}^{1} \frac{2x}{1+x^2} dx =\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\left .\ln(1+x^2)\right|_{-1/2}^{1}=\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\ln\frac{8}{5}. I=\frac{\pi}{2}+\frac{1}{2}\cos^{-1} \frac{3}{5}-\ln\frac{5}{2}.,"['integration', 'derivatives', 'definite-integrals']"
51,Differentiability in zero,Differentiability in zero,,"Consider the function given by, $$f(x)=\begin{cases}        x^2+kx+m & -\frac{\pi}{2}<x< 0 \\       \tan(x)+\cos(x) & 0\leq x< \frac{\pi}{2}    \end{cases}$$ I now want to determine $k$ and $m$ such that $f$ is differentiable in $x=0$ . Furthermore, I want to determine $k$ such that the line $k=y-36x$ is perpendicular to the following curve given by, $$y=\frac{1}{|x-7|}$$ For the first task I concluded $m=1$ and $k\in \mathbb{R}$ . Is this correct, for the second task, I have not made any progress","Consider the function given by, I now want to determine and such that is differentiable in . Furthermore, I want to determine such that the line is perpendicular to the following curve given by, For the first task I concluded and . Is this correct, for the second task, I have not made any progress","f(x)=\begin{cases} 
      x^2+kx+m & -\frac{\pi}{2}<x< 0 \\
      \tan(x)+\cos(x) & 0\leq x< \frac{\pi}{2}
   \end{cases} k m f x=0 k k=y-36x y=\frac{1}{|x-7|} m=1 k\in \mathbb{R}","['calculus', 'derivatives']"
52,Showing for $g\in C^\infty$ that $g^{(n)}(0)=0$ given a vanishing property [duplicate],Showing for  that  given a vanishing property [duplicate],g\in C^\infty g^{(n)}(0)=0,"This question already has an answer here : Show $g^{(n)}(0)=0$ for all $n$ (1 answer) Closed 3 years ago . Given an infinitely differentiable function $g: \mathbb{R} \rightarrow \mathbb{R}$ with the property that for every index $n$ there are positive numbers $c_{n}$ and $\delta_{n}$ such that $$|g(x)| \leq c_{n}|x|^{n} \quad      \text{if}     \quad |x|< \delta_{n}$$ Show that for each natural number $n,g^{(n)}(0)=0$ My attempt: By taking $x=\frac{1}{k}$ itself, we obtain $$\left|\frac{g(\frac{1}{k})}{\frac{1}{k}}\right| \leq  \frac{c_n}{k^{n-1}}$$ whenever $1/k < \delta_n,~n \geq2$ . Now Let $k \rightarrow \infty $ to get $g'(0)=0$ . But what about higher derivatives of $g$ at $0$ ?","This question already has an answer here : Show $g^{(n)}(0)=0$ for all $n$ (1 answer) Closed 3 years ago . Given an infinitely differentiable function with the property that for every index there are positive numbers and such that Show that for each natural number My attempt: By taking itself, we obtain whenever . Now Let to get . But what about higher derivatives of at ?","g: \mathbb{R} \rightarrow \mathbb{R} n c_{n} \delta_{n} |g(x)| \leq c_{n}|x|^{n} \quad      \text{if}     \quad |x|< \delta_{n} n,g^{(n)}(0)=0 x=\frac{1}{k} \left|\frac{g(\frac{1}{k})}{\frac{1}{k}}\right| \leq  \frac{c_n}{k^{n-1}} 1/k < \delta_n,~n \geq2 k \rightarrow \infty  g'(0)=0 g 0","['real-analysis', 'calculus', 'derivatives']"
53,Simple question concerning integrals and derivatives,Simple question concerning integrals and derivatives,,"I have a question about integrals and derivatives. It concerns the proof of the formula of the energy stored in a capacitor. The formula is $E = \frac{1}{2}C.V^2$ where $E$ is the energy stored, $C$ the capacitance (a scalar constant), and $V$ is the voltage applied on the capacitor. Here is the proof, as presented in many physics textbook: we charge the capacitor during a time $t$ , leading its voltage to go from $0$ to $V$ . We note $P(t)$ the power, $U(t)$ the voltage accross the capacitor (going from $0$ at time = 0 to $V$ at time = $t$ ), and $I(t)$ the current flowing through the capacitor. We have the capacitor formula: $I(t) = C.\frac{dU}{dt}(t)$ , where $C$ is a scalar constant. \begin{align*} P(t) &= U(t)\cdot I(t) \\ &= C\cdot U(t)\cdot\frac{dU}{dt} \\ \rightarrow dE &= C\cdot U(t)\cdot dU \\ \rightarrow \int_{0}^{t}{dE} &= \int_{0}^{V}{C\cdot U(t)\cdot dU} \\ \rightarrow E &= \frac{1}{2}C\cdot V^2 \end{align*} I do not understand two things. The first is: why do we write $\frac{dU}{dt}$ instead of $\frac{dU}{dt}(t)$ , because $\frac{dU}{dt}$ is the derivative of $U$ hence it is also a function of the variable $t$ ? The second is: we have $P(t) = C.U(t).\frac{dU}{dt}(t)$ hence $E = \int_{0}^{t}{P(t).dt} = \int_{0}^{t}{C.U(t).\frac{dU}{dt}(t).dt}$ . I thought we could not have the same $t$ as an integral bound and as the variable $dt$ ? Is it also legal to multiply by $dt$ and to simplify $\frac{dU}{dt}(t).dt$ by $dU(t)$ ? But what will be the meaning of $dU(t)$ ? It is not a derivative anymore, so what is it? If we do this simplification, we end up with $E = \int_{0}^{t}{C.U(t).dU(t)}$ , what is the meaning of such an integral, we now integrate with $dU(t)$ and not a simple $dU$ , it seems weird. By the way, how can we exchange $\int_{0}^{t}$ by $\int_{0}^{V}$ ? Thank you very much for your help. How can we write a rigorous proof of this formula?","I have a question about integrals and derivatives. It concerns the proof of the formula of the energy stored in a capacitor. The formula is where is the energy stored, the capacitance (a scalar constant), and is the voltage applied on the capacitor. Here is the proof, as presented in many physics textbook: we charge the capacitor during a time , leading its voltage to go from to . We note the power, the voltage accross the capacitor (going from at time = 0 to at time = ), and the current flowing through the capacitor. We have the capacitor formula: , where is a scalar constant. I do not understand two things. The first is: why do we write instead of , because is the derivative of hence it is also a function of the variable ? The second is: we have hence . I thought we could not have the same as an integral bound and as the variable ? Is it also legal to multiply by and to simplify by ? But what will be the meaning of ? It is not a derivative anymore, so what is it? If we do this simplification, we end up with , what is the meaning of such an integral, we now integrate with and not a simple , it seems weird. By the way, how can we exchange by ? Thank you very much for your help. How can we write a rigorous proof of this formula?","E = \frac{1}{2}C.V^2 E C V t 0 V P(t) U(t) 0 V t I(t) I(t) = C.\frac{dU}{dt}(t) C \begin{align*}
P(t) &= U(t)\cdot I(t) \\
&= C\cdot U(t)\cdot\frac{dU}{dt} \\
\rightarrow dE &= C\cdot U(t)\cdot dU \\
\rightarrow \int_{0}^{t}{dE} &= \int_{0}^{V}{C\cdot U(t)\cdot dU} \\
\rightarrow E &= \frac{1}{2}C\cdot V^2
\end{align*} \frac{dU}{dt} \frac{dU}{dt}(t) \frac{dU}{dt} U t P(t) = C.U(t).\frac{dU}{dt}(t) E = \int_{0}^{t}{P(t).dt} = \int_{0}^{t}{C.U(t).\frac{dU}{dt}(t).dt} t dt dt \frac{dU}{dt}(t).dt dU(t) dU(t) E = \int_{0}^{t}{C.U(t).dU(t)} dU(t) dU \int_{0}^{t} \int_{0}^{V}","['integration', 'derivatives']"
54,Derivation of an integral function in $L^p$,Derivation of an integral function in,L^p,"I know that for any continuous function $f:[0,1]\to\mathbb{R}$ $$\frac{d}{dx} \int_0^x f(y)dy = f(x).$$ Let's say that $f\in L^p$ for $p>1$ . Can I say that the equality still holds almost everywhere? If not, what is the largest subset of $L^p$ such that the equality holds almost everywhere?","I know that for any continuous function Let's say that for . Can I say that the equality still holds almost everywhere? If not, what is the largest subset of such that the equality holds almost everywhere?","f:[0,1]\to\mathbb{R} \frac{d}{dx} \int_0^x f(y)dy = f(x). f\in L^p p>1 L^p","['real-analysis', 'integration', 'derivatives']"
55,Derivative of resultant axis-angle with respect to two consecutive axis-angle rotations,Derivative of resultant axis-angle with respect to two consecutive axis-angle rotations,,"I am recently stuck in a problem about derivative of axis angle rotations. I came up with a simplified problem description as below: We perform two consecutive rotations described in axis-angles as $\mathbf{\theta}^a, \mathbf{\theta}^b$ . Note that the rotations are of the magnitude of $||\mathbf{\theta}^a||$ and $||\mathbf{\theta}^b||$ around axes of $\bar{\mathbf{\theta}^a}=\frac{\mathbf{\theta}^a}{||\mathbf{\theta}^a||}$ and $\bar{\mathbf{\theta}^b}=\frac{\mathbf{\theta}^b}{||\mathbf{\theta}^b||}$ . We can result in a third rotation representing the two consecutive rotations above as $\mathbf{\theta}^c$ . The question is: how do we calculate the following derivatives? $$\frac{\partial \theta ^c _i}{\partial \theta ^a _j}, \frac{\partial \theta ^c _i}{\partial \theta ^b _j}$$ My original thought was to use rotation matrices and chain rules, because two consecutive rotations are simply matrix multiplication $\mathbf{R}^c=\mathbf{R}^b \mathbf{R}^a$ . However, this would require two derivatives: $$\frac{\partial R _{ij}}{\partial \theta _k}$$ $$\frac{\partial \theta _k}{\partial R _{ij}}$$ The top one from matrix to exponential coordinates are easy based on this paper: https://arxiv.org/abs/1312.0788 But the bottom one is much more trickier and I got stuck. Could anyone please help? Thank you! Best, Shawn","I am recently stuck in a problem about derivative of axis angle rotations. I came up with a simplified problem description as below: We perform two consecutive rotations described in axis-angles as . Note that the rotations are of the magnitude of and around axes of and . We can result in a third rotation representing the two consecutive rotations above as . The question is: how do we calculate the following derivatives? My original thought was to use rotation matrices and chain rules, because two consecutive rotations are simply matrix multiplication . However, this would require two derivatives: The top one from matrix to exponential coordinates are easy based on this paper: https://arxiv.org/abs/1312.0788 But the bottom one is much more trickier and I got stuck. Could anyone please help? Thank you! Best, Shawn","\mathbf{\theta}^a, \mathbf{\theta}^b ||\mathbf{\theta}^a|| ||\mathbf{\theta}^b|| \bar{\mathbf{\theta}^a}=\frac{\mathbf{\theta}^a}{||\mathbf{\theta}^a||} \bar{\mathbf{\theta}^b}=\frac{\mathbf{\theta}^b}{||\mathbf{\theta}^b||} \mathbf{\theta}^c \frac{\partial \theta ^c _i}{\partial \theta ^a _j}, \frac{\partial \theta ^c _i}{\partial \theta ^b _j} \mathbf{R}^c=\mathbf{R}^b \mathbf{R}^a \frac{\partial R _{ij}}{\partial \theta _k} \frac{\partial \theta _k}{\partial R _{ij}}","['derivatives', 'differential-geometry', 'partial-derivative', 'rotations']"
56,differentiate integral in t by x,differentiate integral in t by x,,can somebody explain to me why the derivative of $ h(x) = \int_1^x \ln\lvert \cos(e^\sqrt{t}) + 2 \rvert dt $ is: $ h(x)' = \ln\lvert \cos(e^\sqrt{x}) + 2 \rvert $ Why does only the variable change? Thanks,can somebody explain to me why the derivative of is: Why does only the variable change? Thanks, h(x) = \int_1^x \ln\lvert \cos(e^\sqrt{t}) + 2 \rvert dt   h(x)' = \ln\lvert \cos(e^\sqrt{x}) + 2 \rvert ,"['derivatives', 'definite-integrals']"
57,Derivative of vector with vectorization,Derivative of vector with vectorization,,"I have these constraints on a cost function $$ c = A+Bx=A+B\text{vec}\ (q^*q^\top), $$ where $(c,A)\in\mathbb{R}^{100}$ , $B\in\mathbb{C}^{100\times 81}$ , $x\in\mathbb{C}^{81}$ and $q\in\mathbb{C}^9$ . So $x=\text{vec}\ (q^*q^\top)$ , which is the vectorization operator. I want to speed up my optimizer and therefore i require the gradient of the constraints (with respect to $q$ ). This is how far i have come: $$ \begin{aligned} dc = Bdx &= Bd\text{vec}\ (q^*q^\top)\\ &=B\text{vec}\ (q^*dq^\top+dq^*q^\top) \\ &=B\text{vec}\ (q^H:dq)+B\text{vec}\ (q^\top:dq^*) \end{aligned} $$ However, i cannot seem to get rid of the $\text{vec}$ operator. If i ""matricize"" the left side to remove the vectorization at the right side, i cannot get to $\frac{\partial c}{\partial q}$ anymore. Anyone got some brilliance for me? Update : The last line of my derivation is incorrect i think. $q^H\in\mathbb{C}^{12}$ while $dq\in\mathbb{C}^{1\times 12}$ , so you cannot use the Frobenius product here.","I have these constraints on a cost function where , , and . So , which is the vectorization operator. I want to speed up my optimizer and therefore i require the gradient of the constraints (with respect to ). This is how far i have come: However, i cannot seem to get rid of the operator. If i ""matricize"" the left side to remove the vectorization at the right side, i cannot get to anymore. Anyone got some brilliance for me? Update : The last line of my derivation is incorrect i think. while , so you cannot use the Frobenius product here.","
c = A+Bx=A+B\text{vec}\ (q^*q^\top),
 (c,A)\in\mathbb{R}^{100} B\in\mathbb{C}^{100\times 81} x\in\mathbb{C}^{81} q\in\mathbb{C}^9 x=\text{vec}\ (q^*q^\top) q 
\begin{aligned}
dc = Bdx &= Bd\text{vec}\ (q^*q^\top)\\
&=B\text{vec}\ (q^*dq^\top+dq^*q^\top) \\
&=B\text{vec}\ (q^H:dq)+B\text{vec}\ (q^\top:dq^*)
\end{aligned}
 \text{vec} \frac{\partial c}{\partial q} q^H\in\mathbb{C}^{12} dq\in\mathbb{C}^{1\times 12}","['linear-algebra', 'derivatives', 'optimization', 'vector-analysis', 'matrix-calculus']"
58,What is the difference between average slope and Instant slope(Instantaneous Rate of Change),What is the difference between average slope and Instant slope(Instantaneous Rate of Change),,"I'm starting to learn calculus, and I'm getting confused about what average slope and instant slope(instantaneous rate of change)do and what they're differences are after looking at several sources on the internet. I know that average slope is $\frac{Δy}{Δx }$ and instant slope is $\frac{dy}{dx}$ . Are these formulas correct? And if they are, what difference is there between Δy and dy?","I'm starting to learn calculus, and I'm getting confused about what average slope and instant slope(instantaneous rate of change)do and what they're differences are after looking at several sources on the internet. I know that average slope is and instant slope is . Are these formulas correct? And if they are, what difference is there between Δy and dy?","\frac{Δy}{Δx
} \frac{dy}{dx}","['calculus', 'derivatives', 'slope']"
59,How to differentiate $f(r\cos\theta) = r$ with respect to $r\cos\theta$?,How to differentiate  with respect to ?,f(r\cos\theta) = r r\cos\theta,"Let $r,\theta \in \mathbb{R}$ . As stated in the title, how do I differentiate $f(r\cos\theta) = r$ with respect to $r\cos\theta$ ? I have never encountered a question or concept like this, and am not sure where to start. My first thought is to start from the fundamentals: perhaps I should try differentiating $x$ with respect to $2x$ . Perhaps I can use change of variables with $u$ = $2x$ . Then the problem would be equivalent to differentiating $\frac{x}{2}$ with respect to $x$ , which is easy. However, evaluating either $\frac{d}{d(2x)} x$ or $\frac{d}{d(r\cos\theta)} r$ in various software produces error messages, so I'm not sure that the change of variables idea is even valid. How should I proceed? Any advice is deeply appreciated.","Let . As stated in the title, how do I differentiate with respect to ? I have never encountered a question or concept like this, and am not sure where to start. My first thought is to start from the fundamentals: perhaps I should try differentiating with respect to . Perhaps I can use change of variables with = . Then the problem would be equivalent to differentiating with respect to , which is easy. However, evaluating either or in various software produces error messages, so I'm not sure that the change of variables idea is even valid. How should I proceed? Any advice is deeply appreciated.","r,\theta \in \mathbb{R} f(r\cos\theta) = r r\cos\theta x 2x u 2x \frac{x}{2} x \frac{d}{d(2x)} x \frac{d}{d(r\cos\theta)} r","['derivatives', 'trigonometry']"
60,How to prove that $\wp''$'s zeros are not at half-periods?,How to prove that 's zeros are not at half-periods?,\wp'',"This is an exercise adapted from Apostol. The problem is stated as Prove that $$\wp''\left(\frac{\omega_1}{2}\right)=2(e_1-e_2)(e_1-e_3)$$ where $\omega_1,\omega_2$ generates the lattice for $\wp$ . I could see that by Weierstrass' differential equation, we have $$2\wp''\wp'=4\wp'((\wp-e_1)(\wp-e_2)+(\wp-e_2)(\wp-e_3)+(\wp-e_3)(\wp-e_1))$$ and $$2\wp'''\wp'+2\wp''^2=4\wp''(\cdots)+4\wp'(\cdots)$$ At $z=\frac{\omega_1}{2}$ we have $\wp'''=\wp'=0$ since they are odd elliptic functions. Therefore, $$2\wp''^2\left(\frac{\omega_1}{2}\right)=4(e_1-e_2)(e_1-e_3)\wp''$$ Now if $\wp''\left(\frac{\omega_1}{2}\right)\neq0$ we are done. However, I find it very difficult to prove the claim. I tried the following steps: first, we assume $\wp'(z)\neq 0$ . Then by the expanded differential equation, $$\wp''=6\wp^2-\frac{1}{2}g_2=6\left(\wp-\sqrt{\frac{g_2}{12}}\right)\left(\wp+\sqrt{\frac{g_2}{12}}\right)$$ Since $\wp(z)\pm\sqrt{\frac{g_2}{12}}$ are double zeros of $\wp''$ and the order of $\wp''$ is $4$ , if I could prove that $\pm\sqrt{\frac{g_2}{12}}\neq e_i$ , $i=1,2,3$ then we are done. I tried to use the fact that $g_2=2(e_1^2+e_2^2+e_3^2)$ , but it left me with the problem of proving $$\frac{e_1^2+e_2^2+e_3^2}{6}\neq e_i^2$$ for all $i$ . How can I proceed? or is there a simpler argument that applies? I must have missed something. Please help me. Thanks in advance.","This is an exercise adapted from Apostol. The problem is stated as Prove that where generates the lattice for . I could see that by Weierstrass' differential equation, we have and At we have since they are odd elliptic functions. Therefore, Now if we are done. However, I find it very difficult to prove the claim. I tried the following steps: first, we assume . Then by the expanded differential equation, Since are double zeros of and the order of is , if I could prove that , then we are done. I tried to use the fact that , but it left me with the problem of proving for all . How can I proceed? or is there a simpler argument that applies? I must have missed something. Please help me. Thanks in advance.","\wp''\left(\frac{\omega_1}{2}\right)=2(e_1-e_2)(e_1-e_3) \omega_1,\omega_2 \wp 2\wp''\wp'=4\wp'((\wp-e_1)(\wp-e_2)+(\wp-e_2)(\wp-e_3)+(\wp-e_3)(\wp-e_1)) 2\wp'''\wp'+2\wp''^2=4\wp''(\cdots)+4\wp'(\cdots) z=\frac{\omega_1}{2} \wp'''=\wp'=0 2\wp''^2\left(\frac{\omega_1}{2}\right)=4(e_1-e_2)(e_1-e_3)\wp'' \wp''\left(\frac{\omega_1}{2}\right)\neq0 \wp'(z)\neq 0 \wp''=6\wp^2-\frac{1}{2}g_2=6\left(\wp-\sqrt{\frac{g_2}{12}}\right)\left(\wp+\sqrt{\frac{g_2}{12}}\right) \wp(z)\pm\sqrt{\frac{g_2}{12}} \wp'' \wp'' 4 \pm\sqrt{\frac{g_2}{12}}\neq e_i i=1,2,3 g_2=2(e_1^2+e_2^2+e_3^2) \frac{e_1^2+e_2^2+e_3^2}{6}\neq e_i^2 i","['number-theory', 'derivatives', 'roots', 'elliptic-functions']"
61,Find $x(t)$ given $\frac{dx}{dt}$ and $\frac{dy}{dt}$,Find  given  and,x(t) \frac{dx}{dt} \frac{dy}{dt},"For $0 \leq t \leq 1$ , a particle is moving along a curve so that its position at time $t$ is $(x(t),y(t))$ . At time $t=0$ , the particle is at position $(0,0)$ . We are given that $$\frac{dx}{dt} = \frac{t}{\sqrt {1+t^2}}$$ $$\frac{dy}{dt} = \sqrt {\frac{1-t^2}{1+t^2}}$$ Find $x(t)$ Here is my work: $$x(t)=\int \frac{dx}{dt}= \int \frac{t}{\sqrt{1+t^2}}dt$$ Substituting: $$u=t^2+1 \implies du= 2t dt$$ We get; $$x(t) = \int \frac{t}{\sqrt{1+t^2}}dt = \sqrt{t^2+1}+C$$ Since it is asking for $x(t)$ and not $y(t)$ I believe I'm ok","For , a particle is moving along a curve so that its position at time is . At time , the particle is at position . We are given that Find Here is my work: Substituting: We get; Since it is asking for and not I believe I'm ok","0 \leq t \leq 1 t (x(t),y(t)) t=0 (0,0) \frac{dx}{dt} = \frac{t}{\sqrt {1+t^2}} \frac{dy}{dt} = \sqrt {\frac{1-t^2}{1+t^2}} x(t) x(t)=\int \frac{dx}{dt}= \int \frac{t}{\sqrt{1+t^2}}dt u=t^2+1 \implies du= 2t dt x(t) = \int \frac{t}{\sqrt{1+t^2}}dt = \sqrt{t^2+1}+C x(t) y(t)","['calculus', 'integration']"
62,derivative of hypergeometric function,derivative of hypergeometric function,,"I am doing an integral in Mathematica and I find the solution contains derivatives of hypergeometric functions. I would like (ideally) a simple analytic form for these. I have tried HypExp mathematica package but there is no derivative capability. I would like to know how to simplify the following functions: $\text{Hypergeometric2F1}^{(0,0,1,0)}\left(1,1,2,-\frac{2}{a-2}\right)$ $\text{Hypergeometric2F1}^{(0,1,0,0)}\left(1,1,2,-\frac{2}{a-2}\right)$ Thanks",I am doing an integral in Mathematica and I find the solution contains derivatives of hypergeometric functions. I would like (ideally) a simple analytic form for these. I have tried HypExp mathematica package but there is no derivative capability. I would like to know how to simplify the following functions: Thanks,"\text{Hypergeometric2F1}^{(0,0,1,0)}\left(1,1,2,-\frac{2}{a-2}\right) \text{Hypergeometric2F1}^{(0,1,0,0)}\left(1,1,2,-\frac{2}{a-2}\right)","['derivatives', 'hypergeometric-function', 'analytic-functions']"
63,Derivative of L1 norm of Hadamard product,Derivative of L1 norm of Hadamard product,,"I am trying to find the derivative of $f(B)=\lambda\Vert W \bigodot B \Vert_1 + \frac{\rho}{2}\Vert A-B \Vert_F^2 + tr(\Delta^T(A-B))$ with respect to B. where B is (n×n）matrix, W is (n×n）constant matrix, A is (n×n）constant matrix. $\lambda$ and $\rho$ are scalars. $tr$ is the trace of the matrix. $W \bigodot B$ is the Hadamard product of W and B. I am troubled in finding the derivative involving Hadamard product and L-1 norm. Therefore, I first replaced $W \bigodot B$ with T. $$T=W \bigodot B$$ $$B=W^{-1} \bigodot T$$ where $W^{-1}$ is the element-wise inverse. $W \bigodot W^{-1}=I$ . $$f(T)=\lambda\Vert T \Vert_1 + \frac{\rho}{2}\Vert A-W^{-1} \bigodot T  \Vert_F^2 + tr(\Delta^T(A-W^{-1} \bigodot T))$$ I do not konw what to do next. Thank you in advance for any help you can provide.","I am trying to find the derivative of with respect to B. where B is (n×n）matrix, W is (n×n）constant matrix, A is (n×n）constant matrix. and are scalars. is the trace of the matrix. is the Hadamard product of W and B. I am troubled in finding the derivative involving Hadamard product and L-1 norm. Therefore, I first replaced with T. where is the element-wise inverse. . I do not konw what to do next. Thank you in advance for any help you can provide.",f(B)=\lambda\Vert W \bigodot B \Vert_1 + \frac{\rho}{2}\Vert A-B \Vert_F^2 + tr(\Delta^T(A-B)) \lambda \rho tr W \bigodot B W \bigodot B T=W \bigodot B B=W^{-1} \bigodot T W^{-1} W \bigodot W^{-1}=I f(T)=\lambda\Vert T \Vert_1 + \frac{\rho}{2}\Vert A-W^{-1} \bigodot T  \Vert_F^2 + tr(\Delta^T(A-W^{-1} \bigodot T)),"['matrices', 'derivatives', 'matrix-calculus', 'regularization', 'hadamard-product']"
64,derivative manipulation,derivative manipulation,,I was reading a book and was hoping to get clarification. here is the image from the book And here it is again: $$ M{d^2x\over dt^2} = f(x)  $$ they claim can be written as $${M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = f(x)$$ Is the factor $\frac 1 2$ incorrect? I find: $${M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = {\frac M 2}{d \over dx}{dx \over dt}{dx \over dt} = {\frac M 2}{d \over dt}{dx \over dt}={\frac M 2}{d^2x \over dt^2}$$,I was reading a book and was hoping to get clarification. here is the image from the book And here it is again: they claim can be written as Is the factor incorrect? I find:, M{d^2x\over dt^2} = f(x)   {M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = f(x) \frac 1 2 {M \over 2}{d \over dx}\left({dx \over dt}\right)^2 = {\frac M 2}{d \over dx}{dx \over dt}{dx \over dt} = {\frac M 2}{d \over dt}{dx \over dt}={\frac M 2}{d^2x \over dt^2},"['calculus', 'derivatives']"
65,"If $f(x)=x^3+x^2+ax+4\sin x$ is increasing for all real values of $x$, find the interval in which the variable $a$ lies.","If  is increasing for all real values of , find the interval in which the variable  lies.",f(x)=x^3+x^2+ax+4\sin x x a,"I have this problem If $f(x)=x^3+x^2+ax+4\sin x$ is increasing for all real values of $x$ , then $a$ lies in the interval So what I did was to first differentiate the function and equate it to greater than equal to zero ie $f'(x)=3x^2+2x+a+4\cos x \geq 0$ I also know that the determinant of this value should be less than 0. But I don't know what to do after this. I asked my teacher and some other sources and they just substituted $\cos x=-1$ and wrote the equation as : $f'(x)=3x^2+2x+a-4 \geq 0$ I don't know what to do after this and why did my teacher do so. If you can guide me then it would be great.","I have this problem If is increasing for all real values of , then lies in the interval So what I did was to first differentiate the function and equate it to greater than equal to zero ie I also know that the determinant of this value should be less than 0. But I don't know what to do after this. I asked my teacher and some other sources and they just substituted and wrote the equation as : I don't know what to do after this and why did my teacher do so. If you can guide me then it would be great.",f(x)=x^3+x^2+ax+4\sin x x a f'(x)=3x^2+2x+a+4\cos x \geq 0 \cos x=-1 f'(x)=3x^2+2x+a-4 \geq 0,"['calculus', 'derivatives', 'trigonometry', 'maxima-minima']"
66,Integration by parts with a gradient operator,Integration by parts with a gradient operator,,"I know that integration of parts can be used on a single integral: $$\int \frac{df}{dx} g   \,dx = fg - \int f\frac{dg}{dx}  \,dx$$ For a triple integral with a gradient operator, is the following operation legitimate? $$\iiint_V \nabla(f)g \,dV \,=?\, fg - \iiint_V f\nabla(g) \,dV$$ If not, how would one simplify the expression on the left? Please explain.","I know that integration of parts can be used on a single integral: For a triple integral with a gradient operator, is the following operation legitimate? If not, how would one simplify the expression on the left? Please explain.","\int \frac{df}{dx} g   \,dx = fg - \int f\frac{dg}{dx}  \,dx \iiint_V \nabla(f)g \,dV \,=?\, fg - \iiint_V f\nabla(g) \,dV","['integration', 'derivatives', 'vector-analysis']"
67,Polynomials and the Generalized Mean Value Theorem,Polynomials and the Generalized Mean Value Theorem,,"I want to prove the following proposition: Proposition. There exist real polynomials $f$ and $g$ such that $g(0)\neq g(1)$ and $$ \frac{f(1)-f(0)}{g(1)-g(0)}\neq \frac{f^{'}(\xi)}{ g^{'}(\xi)}$$ for all $\xi\in (0,1)$ . It seems directly related to the generalized mean value theorem (MVT) but am not sure how to prove it. The negation of the statement is: For all real polynomials $f$ and $g$ such that $g(0)\neq g(1)$ there exist $\xi\in (0,1)$ such that $$ \frac{f(1)-f(0)}{g(1)-g(0)}= \frac{f^{'}(\xi)}{ g^{'}(\xi)}$$ which is true if $g^{'}(\xi)\neq 0$ by the generalized MVT. Any help is greatly appreciated.",I want to prove the following proposition: Proposition. There exist real polynomials and such that and for all . It seems directly related to the generalized mean value theorem (MVT) but am not sure how to prove it. The negation of the statement is: For all real polynomials and such that there exist such that which is true if by the generalized MVT. Any help is greatly appreciated.,"f g g(0)\neq g(1)  \frac{f(1)-f(0)}{g(1)-g(0)}\neq \frac{f^{'}(\xi)}{ g^{'}(\xi)} \xi\in (0,1) f g g(0)\neq g(1) \xi\in (0,1)  \frac{f(1)-f(0)}{g(1)-g(0)}= \frac{f^{'}(\xi)}{ g^{'}(\xi)} g^{'}(\xi)\neq 0","['real-analysis', 'calculus', 'derivatives']"
68,Derivatives of $G(x)=\int^{e^x}_1(\log(t))^2dt$ and $H(x)=\int^{x^2}_{-x^2}e^{-t^5}dt$,Derivatives of  and,G(x)=\int^{e^x}_1(\log(t))^2dt H(x)=\int^{x^2}_{-x^2}e^{-t^5}dt,"I have $2$ tasks: To evaluate $G(x)=\int^{e^x}_1(\log(t))^2dt$ for $x\gt 0$ and $H(x)=\int^{x^2}_{-x^2}e^{-t^5}dt$ for $x \in \Bbb R$ So by the fundamental theorem of calculus: If $F(x)=\int^x_af$ is differentiable at $c$ , then $F'(c)=f(c)$ And by Newton's FTC: $\int^b_af(x)dx=F(b)-F(a)$ So, what I do is : $G'(x)=(\log(e^x))^2-(\log(1))^2=x^2$ And $H'(x)=e^{-x^{10}}-e^{x^{10}}=\frac{1-e^{2x^{10}}}{e^{x^{10}}}$ But , in the answer sheet, the result is: $G'(x)=\log^2(e^x)e^x=x^2e^x$ And $H'(x)=2x(e^{-x^{10}}+e^{-x^{10}})=4xe^{-x^{10}}$ What am I doing/interpreting wrong? Any help is appreciated!","I have tasks: To evaluate for and for So by the fundamental theorem of calculus: If is differentiable at , then And by Newton's FTC: So, what I do is : And But , in the answer sheet, the result is: And What am I doing/interpreting wrong? Any help is appreciated!",2 G(x)=\int^{e^x}_1(\log(t))^2dt x\gt 0 H(x)=\int^{x^2}_{-x^2}e^{-t^5}dt x \in \Bbb R F(x)=\int^x_af c F'(c)=f(c) \int^b_af(x)dx=F(b)-F(a) G'(x)=(\log(e^x))^2-(\log(1))^2=x^2 H'(x)=e^{-x^{10}}-e^{x^{10}}=\frac{1-e^{2x^{10}}}{e^{x^{10}}} G'(x)=\log^2(e^x)e^x=x^2e^x H'(x)=2x(e^{-x^{10}}+e^{-x^{10}})=4xe^{-x^{10}},['real-analysis']
69,How can I solve this limit using L'Hospital's rule somewhere?,How can I solve this limit using L'Hospital's rule somewhere?,,I have to solve this limit $\lim _{x\to 0+}\left(\left(\left(1+x\right)^x-1\right)^x\right)$ as $x$ approaches $0$ from the positive numbers. I have tried to change it to e to the limit of the exponent and apply L'Hospital's on it but to no avail. Can someone help me?,I have to solve this limit as approaches from the positive numbers. I have tried to change it to e to the limit of the exponent and apply L'Hospital's on it but to no avail. Can someone help me?,\lim _{x\to 0+}\left(\left(\left(1+x\right)^x-1\right)^x\right) x 0,"['calculus', 'limits', 'derivatives']"
70,"Assuming that "" slope of the tangent at $x=a$ "" and "" $f'(a)$"" are not identical by definition , how can their identity be shown algebraically?","Assuming that "" slope of the tangent at  "" and "" "" are not identical by definition , how can their identity be shown algebraically?",x=a f'(a),"When the concept of the "" derivative number"" of a function $f$ for some $x-$ value , say $x=a$ is introduced - this number is simply $f'(a)$ -  the motivation is often that this number is identical to the slope of the tangent to the graph of $f$ at point $(a, f(a)$ . This is shown visually, by allowing a line passing through point $A =(a, f(a))$ and through some point $B$ on the curve to move gradually ( while $B$ also moves) until this line becomes identical to the tangent ( the slope of which we are supposed to look for). My question is : how to show analytically that the number $\lim_{h\rightarrow0}\frac {f(a+h) - f(a)}{h}$ and the number $\frac{y_{D} - y_C} {x_{D} - x_C}$ (with $C$ and $D$ two arbitrary distinct points on the tangent line) are actually one and the same number? To put it more briefly: assuming there is at least a conceptual difference between "" derivative number"" and "" slope of the tangent"" , how to show that the two expressions denote, in fact, one and the same object ( namely, the same number) ? PS : here I use the expression "" derivative number"" that is common in french mathematics to denote the image of an x-value under the derivative function.","When the concept of the "" derivative number"" of a function for some value , say is introduced - this number is simply -  the motivation is often that this number is identical to the slope of the tangent to the graph of at point . This is shown visually, by allowing a line passing through point and through some point on the curve to move gradually ( while also moves) until this line becomes identical to the tangent ( the slope of which we are supposed to look for). My question is : how to show analytically that the number and the number (with and two arbitrary distinct points on the tangent line) are actually one and the same number? To put it more briefly: assuming there is at least a conceptual difference between "" derivative number"" and "" slope of the tangent"" , how to show that the two expressions denote, in fact, one and the same object ( namely, the same number) ? PS : here I use the expression "" derivative number"" that is common in french mathematics to denote the image of an x-value under the derivative function.","f x- x=a f'(a) f (a, f(a) A =(a, f(a)) B B \lim_{h\rightarrow0}\frac {f(a+h) - f(a)}{h} \frac{y_{D} - y_C} {x_{D} - x_C} C D","['calculus', 'derivatives']"
71,Implicit Differentiation of logarithm,Implicit Differentiation of logarithm,,"Differentiate $y=\log_a(x)$ with respect to $x$ I see that $a^y=x$ . My textbook says implicit differentiation gets us \begin{align*}a'(\ln a)\frac{dy}{dx}&=1 \\\implies \frac{dy}{dx}&=\frac{1}{a'\ln a} \\ \frac{dy}{dx}&=\frac{1}{x\ln a}\end{align*} What I don't understand is why $\frac{d}{dx}[a^y]=a'(\ln a)\cfrac{dy}{dx}$ and why $a'=x$ When I try this using a base of $e$ with the chain rule, I get \begin{align*}\frac{d}{dx}[e^{y\ln a}]&=\frac{d}{dx}[x] \\ &\boxed{u=y\ln a, du=\frac{dy}{dx}\ln a+\frac1ay; \\ f=e^u, df=e^u \\ df/du*du/dx=e^{y\ln a}\frac{dy}{dx}\ln a+\frac1ay} \\ \implies x\frac{dy}{dx}\ln a+\frac1ay&=1 \\ \frac{dy}{dx}&=\frac{1}{\ln a}\biggr(\frac1x-\frac{y}{a}\biggr)\end{align*} I see here that if I distribute, I get $\cfrac{1}{x\ln a}-\cfrac{y}{a\ln a}$ which implies $y$ must be zero! But I don't know how to show that, either. Can someone fill the gaps I'm missing in my textbooks solution? UPDATE: I just realized the mistake I made in my differentiation was forgetting that ln (a) is a constant! Once I took out the constant or allowed the constant to be differentiated to $0$ I got the correct answer.  I will mark the best answer correct soon enough, though, thanks everyone","Differentiate with respect to I see that . My textbook says implicit differentiation gets us What I don't understand is why and why When I try this using a base of with the chain rule, I get I see here that if I distribute, I get which implies must be zero! But I don't know how to show that, either. Can someone fill the gaps I'm missing in my textbooks solution? UPDATE: I just realized the mistake I made in my differentiation was forgetting that ln (a) is a constant! Once I took out the constant or allowed the constant to be differentiated to I got the correct answer.  I will mark the best answer correct soon enough, though, thanks everyone","y=\log_a(x) x a^y=x \begin{align*}a'(\ln a)\frac{dy}{dx}&=1 \\\implies \frac{dy}{dx}&=\frac{1}{a'\ln a} \\ \frac{dy}{dx}&=\frac{1}{x\ln a}\end{align*} \frac{d}{dx}[a^y]=a'(\ln a)\cfrac{dy}{dx} a'=x e \begin{align*}\frac{d}{dx}[e^{y\ln a}]&=\frac{d}{dx}[x] \\ &\boxed{u=y\ln a, du=\frac{dy}{dx}\ln a+\frac1ay; \\ f=e^u, df=e^u \\ df/du*du/dx=e^{y\ln a}\frac{dy}{dx}\ln a+\frac1ay} \\ \implies x\frac{dy}{dx}\ln a+\frac1ay&=1 \\ \frac{dy}{dx}&=\frac{1}{\ln a}\biggr(\frac1x-\frac{y}{a}\biggr)\end{align*} \cfrac{1}{x\ln a}-\cfrac{y}{a\ln a} y 0","['calculus', 'derivatives', 'logarithms', 'implicit-differentiation']"
72,Differentials of a Lagrangian in Fluid Mechanics,Differentials of a Lagrangian in Fluid Mechanics,,"My question relates to the paper by Foures et al. The paper presents a Lagrangian approach to finding an adjoint Poiseuille flow equation. It also defines the notion of an inner product (equation (3.10) in the paper) and proceeds to outline the method in which differentials are taken with respect to the componentwise velocity, $u_i$ . In the second term on the right-hand side of equation (A.5) below, how was the differential constructed? In particular, where do terms such as $\partial_t \delta u_i$ and $\delta u_j\partial_j U_i$ come from? I'm struggling to see how these terms were derived, so if anyone could offer an explanation (as to how the differential was computed), I'd be very grateful. EDIT: Using the Gateaux derivative on the terms $U_j\partial_j u_i$ and $u_j\partial_j\bar{u}_i = u_j\partial_j(U_i - u_i)$ gives $U_j\partial_j\delta u_i + \delta u_j \partial_j(U_i-u_i-\epsilon \delta u_i) + (u_j + \epsilon \delta u_j)\partial_j(-\delta u_i)\vert_{\epsilon=0}$ . Clearly something has gone wrong here, but I'm not sure what...","My question relates to the paper by Foures et al. The paper presents a Lagrangian approach to finding an adjoint Poiseuille flow equation. It also defines the notion of an inner product (equation (3.10) in the paper) and proceeds to outline the method in which differentials are taken with respect to the componentwise velocity, . In the second term on the right-hand side of equation (A.5) below, how was the differential constructed? In particular, where do terms such as and come from? I'm struggling to see how these terms were derived, so if anyone could offer an explanation (as to how the differential was computed), I'd be very grateful. EDIT: Using the Gateaux derivative on the terms and gives . Clearly something has gone wrong here, but I'm not sure what...",u_i \partial_t \delta u_i \delta u_j\partial_j U_i U_j\partial_j u_i u_j\partial_j\bar{u}_i = u_j\partial_j(U_i - u_i) U_j\partial_j\delta u_i + \delta u_j \partial_j(U_i-u_i-\epsilon \delta u_i) + (u_j + \epsilon \delta u_j)\partial_j(-\delta u_i)\vert_{\epsilon=0},"['calculus', 'derivatives', 'inner-products', 'lagrange-multiplier', 'fluid-dynamics']"
73,The value of the series: $\sum_{p=1}^{n} \sin(\frac{p}{n^2})$,The value of the series:,\sum_{p=1}^{n} \sin(\frac{p}{n^2}),"Find the limit as $n\rightarrow \infty$ of: $$\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right)$$ This question seems odd to me because it was included in my differentiability problems set . My Attempt: We have: $\sin(x) \le x $ , Thus clearly: $$\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right) \le \sum_{p=1}^{n} \frac{p}{n^2}$$ I have to prove that: $$\sum_{p=1}^{n} \frac{p}{n^2} \rightarrow \frac12$$ And: $$\frac{1}{2}\le\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right)$$ To conclude that the series converges to $\frac12$ . Though, I think there exists another solution that uses derivative or something similar. Update: I proved by double summation that: $$\sum_{p=1}^{n} \frac{p}{n^2} = \frac{1+\frac1n}{2}$$ So it clearly goes to $\frac12$","Find the limit as of: This question seems odd to me because it was included in my differentiability problems set . My Attempt: We have: , Thus clearly: I have to prove that: And: To conclude that the series converges to . Though, I think there exists another solution that uses derivative or something similar. Update: I proved by double summation that: So it clearly goes to",n\rightarrow \infty \sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right) \sin(x) \le x  \sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right) \le \sum_{p=1}^{n} \frac{p}{n^2} \sum_{p=1}^{n} \frac{p}{n^2} \rightarrow \frac12 \frac{1}{2}\le\sum_{p=1}^{n} \sin\left(\frac{p}{n^2}\right) \frac12 \sum_{p=1}^{n} \frac{p}{n^2} = \frac{1+\frac1n}{2} \frac12,"['sequences-and-series', 'derivatives']"
74,Why does the derivative equation of the unit semicircle equation intersect the semicircle at $x=-\frac{1}{\phi}$?,Why does the derivative equation of the unit semicircle equation intersect the semicircle at ?,x=-\frac{1}{\phi},"I was playing around in desmos and I discovered something interesting, but I am nowhere near advanced enough to tackle this. The circle equation $f(x)=\sqrt{1-x^2}$ and its derivative (I don't know how to find the equation - if possible could you explain this as well?) intersect at or extremely close to (as in I zoomed in as far as I could in desmos) the point where x is equal to $\frac{-1}{\phi}$ where $\phi$ is 1.6180339... I don't know whether all 3 lines actually cross at this point, but it seems like it's too perfect to be false. Is anybody able to come up with a reason why this happens?","I was playing around in desmos and I discovered something interesting, but I am nowhere near advanced enough to tackle this. The circle equation and its derivative (I don't know how to find the equation - if possible could you explain this as well?) intersect at or extremely close to (as in I zoomed in as far as I could in desmos) the point where x is equal to where is 1.6180339... I don't know whether all 3 lines actually cross at this point, but it seems like it's too perfect to be false. Is anybody able to come up with a reason why this happens?",f(x)=\sqrt{1-x^2} \frac{-1}{\phi} \phi,"['derivatives', 'circles', 'graphing-functions', 'golden-ratio']"
75,Second derivative statement,Second derivative statement,,"I have to prove the following: $$f''(x)=\lim_{h\rightarrow0} \frac{f(x+h)+f(x-h)-2f(x)}{h^2}$$ I tried to just apply the definition of derivative, namely: $$f'(x)=\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h}$$ Then this: $$f''(x)=\lim_{h\rightarrow0} \frac{f'(x+h)-f'(x)}{h}$$ $$f''(x)=\lim_{h\rightarrow0} \frac{\lim_{h\rightarrow0} \frac{f(x+2h)-f(x+h)}{h}-\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h}}{h}$$ $$f''(x)=\lim_{h\rightarrow0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2}$$ But what now? I came to the conclusion that this is true for $f''(x-h)$ , but not for $f''(x)$ . How can I solve this problem?","I have to prove the following: I tried to just apply the definition of derivative, namely: Then this: But what now? I came to the conclusion that this is true for , but not for . How can I solve this problem?",f''(x)=\lim_{h\rightarrow0} \frac{f(x+h)+f(x-h)-2f(x)}{h^2} f'(x)=\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h} f''(x)=\lim_{h\rightarrow0} \frac{f'(x+h)-f'(x)}{h} f''(x)=\lim_{h\rightarrow0} \frac{\lim_{h\rightarrow0} \frac{f(x+2h)-f(x+h)}{h}-\lim_{h\rightarrow0} \frac{f(x+h)-f(x)}{h}}{h} f''(x)=\lim_{h\rightarrow0}\frac{f(x+2h)-2f(x+h)+f(x)}{h^2} f''(x-h) f''(x),"['calculus', 'derivatives']"
76,How does using limits to find the derivative of a function avoid dividing by $0$?,How does using limits to find the derivative of a function avoid dividing by ?,0,"What is wrong with this argument that differentiation using the First Principle leads to division by $0$ : $$ f'(x)=\lim_\limits{h \to 0} \frac{f(x+h)-f(x)}{h} \\ $$ Using the quotient limit law: $$ \lim_\limits{h \to 0} \frac{f(x+h)-f(x)}{h}=\frac{\lim_\limits{h \to 0}f(x+h)-f(x)}{\lim_\limits{h \to 0}h} $$ $$ \lim_\limits{h \to 0}h = 0 $$ Therefore, there the top half of the fraction is divided by $0$ . Here is my reasoning for why $\lim_\limits{h \to 0}h = 0$ : As $h$ approaches $0$ , its value becomes smaller (and will become smaller than any number strictly greater than $0$ ). For example, you cannot evaluate the limit as equalling $0.001$ , because at some point $h$ will be lower than this. $0$ is the largest number that does not have this problem. Therefore, the limit expression is equal to $0$ . Thank you for reading.","What is wrong with this argument that differentiation using the First Principle leads to division by : Using the quotient limit law: Therefore, there the top half of the fraction is divided by . Here is my reasoning for why : As approaches , its value becomes smaller (and will become smaller than any number strictly greater than ). For example, you cannot evaluate the limit as equalling , because at some point will be lower than this. is the largest number that does not have this problem. Therefore, the limit expression is equal to . Thank you for reading.","0 
f'(x)=\lim_\limits{h \to 0} \frac{f(x+h)-f(x)}{h} \\
 
\lim_\limits{h \to 0} \frac{f(x+h)-f(x)}{h}=\frac{\lim_\limits{h \to 0}f(x+h)-f(x)}{\lim_\limits{h \to 0}h}
 
\lim_\limits{h \to 0}h = 0
 0 \lim_\limits{h \to 0}h = 0 h 0 0 0.001 h 0 0","['calculus', 'derivatives', 'intuition']"
77,How can I find the smoothest transition between two straight lines?,How can I find the smoothest transition between two straight lines?,,"Let's say I have the function $$f(x)=\begin{Bmatrix} x & \textrm{,} & \textrm{if } x\leqslant 1.5\\  \frac{x}{3}+1 & \textrm{,} & \textrm{otherwise} \end{Bmatrix}$$ which has a sharp edge at 1.5, i.e. a discontinuity in the first derivative. I would like to smooth that transition with some other function. In practice I would like to set a window around the sharp edge in which the transition happens: $$f(x)=\begin{Bmatrix} x & \textrm{, } & \textrm{if } x\leqslant 1.5-t\\ s(x) & \textrm{, } & \textrm{if } 1.5-t\leqslant x\leqslant 1.5+t\\ \frac{x}{3}+1 & \textrm{, } & \textrm{otherwise} \end{Bmatrix}$$ with s(x) being my transition function and t being half the window width. I could choose a quadratic but that would create a sharp edge in the first derivative (i.e. a discontinuity in the second derivative). I'd like a function f(x) that ends up with no discontinuities in any of the derivatives and is monotonically nondecreasing. If anyone can point me in the right direction of what I'm looking for, I'd be thankful.","Let's say I have the function which has a sharp edge at 1.5, i.e. a discontinuity in the first derivative. I would like to smooth that transition with some other function. In practice I would like to set a window around the sharp edge in which the transition happens: with s(x) being my transition function and t being half the window width. I could choose a quadratic but that would create a sharp edge in the first derivative (i.e. a discontinuity in the second derivative). I'd like a function f(x) that ends up with no discontinuities in any of the derivatives and is monotonically nondecreasing. If anyone can point me in the right direction of what I'm looking for, I'd be thankful.","f(x)=\begin{Bmatrix}
x & \textrm{,} & \textrm{if } x\leqslant 1.5\\ 
\frac{x}{3}+1 & \textrm{,} & \textrm{otherwise}
\end{Bmatrix} f(x)=\begin{Bmatrix}
x & \textrm{, } & \textrm{if } x\leqslant 1.5-t\\
s(x) & \textrm{, } & \textrm{if } 1.5-t\leqslant x\leqslant 1.5+t\\
\frac{x}{3}+1 & \textrm{, } & \textrm{otherwise}
\end{Bmatrix}",['derivatives']
78,Volume of decreasing diameter,Volume of decreasing diameter,,"A sphere's volume decreases at a rate of $1$ cm $^3$ /min. Find the instantaneous rate of which diameter decreases with respect to time when diameter is 10 units. First, I know radius is $d/2$ , so $v=\cfrac{\pi d^3}{6}$ . I also know that $\cfrac{dv}{dt}=-1$ . Finding the derivative of $v$ I get $$\cfrac{\pi d^2}{2}$$ And at this point is where I'm confused. The expressions here are all in terms of $d$ , but I'm taking the derivative with respect to $t$ (time) even though $t$ is nowhere to be found here, so it's throwing me off. I would prefer your solution to be written with Leibniz's notation.","A sphere's volume decreases at a rate of cm /min. Find the instantaneous rate of which diameter decreases with respect to time when diameter is 10 units. First, I know radius is , so . I also know that . Finding the derivative of I get And at this point is where I'm confused. The expressions here are all in terms of , but I'm taking the derivative with respect to (time) even though is nowhere to be found here, so it's throwing me off. I would prefer your solution to be written with Leibniz's notation.",1 ^3 d/2 v=\cfrac{\pi d^3}{6} \cfrac{dv}{dt}=-1 v \cfrac{\pi d^2}{2} d t t,"['calculus', 'derivatives', 'volume', 'spheres', 'related-rates']"
79,"$\tan x>x+\frac {x^3}3$ for $x\in(0,\frac\pi2)$",for,"\tan x>x+\frac {x^3}3 x\in(0,\frac\pi2)","$$\tan x>x+\frac {x^3}3~\text{ for }~x\in\left(0,\frac\pi2\right)$$ My solution: Both functions are monotone, increasing, equal at $x=0$ . If i could show that the derivative of the first is greater than then derivative of second function that would be it. Taking the derivatives: $$\frac1{\cos^2 x}>1+x^2$$ Applying the same reasoning on the derivatives  and taking their derivatives we get $$\frac{\tan x}{\cos^2 x}>x$$ Doing the same thing (it is possible to stop here if we use $\tan x>x$ ) $$\frac{1+\tan x\sin 2x}{\cos^4 x}>1$$ It is easy to see that last inequality is true therefore all previous are also true. Is my solution correct, i would be very disappointed if it weren't. Are there different ways to solve this ?","My solution: Both functions are monotone, increasing, equal at . If i could show that the derivative of the first is greater than then derivative of second function that would be it. Taking the derivatives: Applying the same reasoning on the derivatives  and taking their derivatives we get Doing the same thing (it is possible to stop here if we use ) It is easy to see that last inequality is true therefore all previous are also true. Is my solution correct, i would be very disappointed if it weren't. Are there different ways to solve this ?","\tan x>x+\frac {x^3}3~\text{ for }~x\in\left(0,\frac\pi2\right) x=0 \frac1{\cos^2 x}>1+x^2 \frac{\tan x}{\cos^2 x}>x \tan x>x \frac{1+\tan x\sin 2x}{\cos^4 x}>1","['real-analysis', 'derivatives', 'inequality']"
80,"Let $f(x)$ be a differentiable function at $x=0$ & $f\left(\frac{x+y}{k}\right)=\frac{f(x)+f(y)}k \left(k\in R, k\ne 0,2\right)$. Show following",Let  be a differentiable function at  & . Show following,"f(x) x=0 f\left(\frac{x+y}{k}\right)=\frac{f(x)+f(y)}k \left(k\in R, k\ne 0,2\right)","Let $f(x)$ be a derivable function at $x=0$ & $f\left(\dfrac{x+y}{k}\right)=\dfrac{f(x)+f(y)}{k} \left(k\in R, k\ne 0,2\right)$ . Show that $f(x)$ is either a zero or odd linear function. My attempt is as follows:- Putting $x=0,y=0$ in the functional equation $$f(0)=\dfrac{2f(0)}{k}$$ $$f(0)(k-2)=0$$ $$f(0)=0 \text { as it is given $k \ne 2$ }$$ Replace $y=-x$ in the functional equation. $$f(0)=\dfrac{f(x)+f(-x)}{k}$$ $$f(x)+f(-x)=0$$ $$f(-x)=-f(x)$$ Thus $f(x)$ is definitely an odd function. As $f(x)$ is a derivable function at $x=0$ then following limit should exist:- $$\lim_{h\to 0}\dfrac{f(h)-f(0)}{h}$$ $$\lim_{h\to 0}\dfrac{f(h)}{h}$$ Assuming $f(x)$ to be polynomial function. If $f(x)$ is a linear function, then limit should be non-zero because if its a polynomial of degree greater than $1$ , then limit would be zero. Like if $f(x)=ax^2+bx+c$ Applying L' Hospital rule:- $$\lim_{h\to 0}(2ah+b)=0$$ If $f(x)$ is a constant function other than $0$ , then $f(x)=-f(x)$ will not hold. So we just have to prove that $$\lim_{h\to 0}\dfrac{f(h)}{h} \ne 0$$ Applying L' Hospital rule as we have $\dfrac{0}{0}$ form and function is derivable at $x=0$ $$\lim_{h\to 0}f'(h)=f'(0)$$ If we can just prove that $f'(0) \ne 0$ , then we will be done. I am not getting how to prove this fact.Any hints?","Let be a derivable function at & . Show that is either a zero or odd linear function. My attempt is as follows:- Putting in the functional equation Replace in the functional equation. Thus is definitely an odd function. As is a derivable function at then following limit should exist:- Assuming to be polynomial function. If is a linear function, then limit should be non-zero because if its a polynomial of degree greater than , then limit would be zero. Like if Applying L' Hospital rule:- If is a constant function other than , then will not hold. So we just have to prove that Applying L' Hospital rule as we have form and function is derivable at If we can just prove that , then we will be done. I am not getting how to prove this fact.Any hints?","f(x) x=0 f\left(\dfrac{x+y}{k}\right)=\dfrac{f(x)+f(y)}{k} \left(k\in R, k\ne 0,2\right) f(x) x=0,y=0 f(0)=\dfrac{2f(0)}{k} f(0)(k-2)=0 f(0)=0 \text { as it is given k \ne 2 } y=-x f(0)=\dfrac{f(x)+f(-x)}{k} f(x)+f(-x)=0 f(-x)=-f(x) f(x) f(x) x=0 \lim_{h\to 0}\dfrac{f(h)-f(0)}{h} \lim_{h\to 0}\dfrac{f(h)}{h} f(x) f(x) 1 f(x)=ax^2+bx+c \lim_{h\to 0}(2ah+b)=0 f(x) 0 f(x)=-f(x) \lim_{h\to 0}\dfrac{f(h)}{h} \ne 0 \dfrac{0}{0} x=0 \lim_{h\to 0}f'(h)=f'(0) f'(0) \ne 0","['real-analysis', 'calculus', 'limits', 'derivatives']"
81,How to detailed derivation of multiplicative update rules for Nonnegative Matrix Factorization?,How to detailed derivation of multiplicative update rules for Nonnegative Matrix Factorization?,,"How to detailed derivation of multiplicative update rules for Nonnegative Matrix Factorization? Minimize $\left \| V - WH \right \|^2$ with respect to $W$ and $H$ , subject to the constraints $W,H \geq 0.$ The multiplicative update rules are as follows: \begin{equation} W_{i,j} \leftarrow W_{ij}   \frac{(VH^T)_{ij}}{(WHH^T)_{ij}} \end{equation} \begin{equation} H_{i,j} \leftarrow H_{ij}  \frac{(W^TV)_{ij}}{(W^TWH)_{ij}} \end{equation} the Lagrange $\mathcal{L}$ is: $$\mathcal{L}(W,H) =\left \| V - WH \right \|^2-Tr(\Psi W^T)-Tr(\Phi H^T)$$ The derivatives with respect to H can computed similarly. Thus, $$\nabla_W f(W,H) = -2VH^T + 2WHH^T-\Psi$$ $$\nabla_H f(W,H) = -2W^TV + 2W^TWH- \Phi$$ According to KKT conditions, $\Psi_{ij}W_{ij}=0$ and $\Phi_{ij}H_{ij}=0$ : $$(-2VH^T + 2WHH^T)\circ W=0$$ $$(-2W^TV + 2W^TWH)\circ H=0$$ The question is: Why the results are as follows: \begin{equation} W_{i,j} \leftarrow W_{ij}   \frac{(VH^T)_{ij}}{(WHH^T)_{ij}} \end{equation} \begin{equation} H_{i,j} \leftarrow H_{ij}  \frac{(W^TV)_{ij}}{(W^TWH)_{ij}} \end{equation} Not are as follows: \begin{equation} W_{i,j} \leftarrow W_{ij}   \frac{(WHH^T)_{ij} }{(VH^T)_{ij}} \end{equation} \begin{equation} H_{i,j} \leftarrow H_{ij}  \frac{(W^TWH)_{ij}}{(W^TV)_{ij}} \end{equation} In addition, Why should the learning rate be set like as follows: $\eta_W = \frac{W}{WHH^T}$ and $\eta_H = \frac{H}{W^TWH}$ Click here , you can see this paper.","How to detailed derivation of multiplicative update rules for Nonnegative Matrix Factorization? Minimize with respect to and , subject to the constraints The multiplicative update rules are as follows: the Lagrange is: The derivatives with respect to H can computed similarly. Thus, According to KKT conditions, and : The question is: Why the results are as follows: Not are as follows: In addition, Why should the learning rate be set like as follows: and Click here , you can see this paper.","\left \| V - WH \right \|^2 W H W,H \geq 0. \begin{equation}
W_{i,j} \leftarrow W_{ij}   \frac{(VH^T)_{ij}}{(WHH^T)_{ij}}
\end{equation} \begin{equation}
H_{i,j} \leftarrow H_{ij}  \frac{(W^TV)_{ij}}{(W^TWH)_{ij}}
\end{equation} \mathcal{L} \mathcal{L}(W,H) =\left \| V - WH \right \|^2-Tr(\Psi W^T)-Tr(\Phi H^T) \nabla_W f(W,H) = -2VH^T + 2WHH^T-\Psi \nabla_H f(W,H) = -2W^TV + 2W^TWH- \Phi \Psi_{ij}W_{ij}=0 \Phi_{ij}H_{ij}=0 (-2VH^T + 2WHH^T)\circ W=0 (-2W^TV + 2W^TWH)\circ H=0 \begin{equation}
W_{i,j} \leftarrow W_{ij}   \frac{(VH^T)_{ij}}{(WHH^T)_{ij}}
\end{equation} \begin{equation}
H_{i,j} \leftarrow H_{ij}  \frac{(W^TV)_{ij}}{(W^TWH)_{ij}}
\end{equation} \begin{equation}
W_{i,j} \leftarrow W_{ij}   \frac{(WHH^T)_{ij} }{(VH^T)_{ij}}
\end{equation} \begin{equation}
H_{i,j} \leftarrow H_{ij}  \frac{(W^TWH)_{ij}}{(W^TV)_{ij}}
\end{equation} \eta_W = \frac{W}{WHH^T} \eta_H = \frac{H}{W^TWH}","['real-analysis', 'matrices', 'derivatives', 'optimization', 'matrix-calculus']"
82,About differentiability and continuity $A(x) = \int_{0}^{x} f(t) dt$,About differentiability and continuity,A(x) = \int_{0}^{x} f(t) dt,"For some $f:\mathbb{R} \to \mathbb{R}$ integrable in every interval $[a, b]$ of $\mathbb{R}$ , consider $A(x) = \int_{0}^{x} f(t) dt$ . (i) Is it true that $A$ is differentiable? I don't know how to connect the fact that $f$ is integrable with this preposition... is that possible? (ii) Is it true that if $f$ is differentiable in some $c$ then $A'$ is continuous in c? I was thinking that if $f$ is differentiable in $c$ , then $f$ is continuous in $c$ . So by the fundamental theorem of calculus $A$ is differentiable in $c$ , then continuous. Am I right?","For some integrable in every interval of , consider . (i) Is it true that is differentiable? I don't know how to connect the fact that is integrable with this preposition... is that possible? (ii) Is it true that if is differentiable in some then is continuous in c? I was thinking that if is differentiable in , then is continuous in . So by the fundamental theorem of calculus is differentiable in , then continuous. Am I right?","f:\mathbb{R} \to \mathbb{R} [a, b] \mathbb{R} A(x) = \int_{0}^{x} f(t) dt A f f c A' f c f c A c","['calculus', 'integration', 'derivatives', 'continuity']"
83,Why is this derivative of an integral calculated in this way?,Why is this derivative of an integral calculated in this way?,,"Could anyone please give me an insight as to why the following derivative is correct? The function to derivate is $$f(x) = -ax +b\int_{-\infty}^xF(\xi)d\xi$$ The result is $$f'(x) = -a + bF(x)$$ Particularly, I do not understand how the integral is resolved to $bF(x)$ . What rule am I missing?","Could anyone please give me an insight as to why the following derivative is correct? The function to derivate is The result is Particularly, I do not understand how the integral is resolved to . What rule am I missing?",f(x) = -ax +b\int_{-\infty}^xF(\xi)d\xi f'(x) = -a + bF(x) bF(x),"['calculus', 'integration', 'derivatives', 'definite-integrals']"
84,Integrating $\frac{\mathrm d}{\mathrm dx}f(x)$ from $0$ to $t$,Integrating  from  to,\frac{\mathrm d}{\mathrm dx}f(x) 0 t,"I need help for solving the integral $$\int_0^t\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx.$$ I think that the indefinite integral $$\int\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx$$ will be equal to $f(x) + C$ . Then, when I apply the boundaries to that result, I should get $$\int_0^t\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx = (f(t) + C) - (f(0) + C) = f(t) -f(0).$$ But I have some doubts if the indefinite integral I found is correct or not. Can you verify my result?","I need help for solving the integral I think that the indefinite integral will be equal to . Then, when I apply the boundaries to that result, I should get But I have some doubts if the indefinite integral I found is correct or not. Can you verify my result?",\int_0^t\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx. \int\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx f(x) + C \int_0^t\left(\frac{\mathrm d}{\mathrm dx}f(x)\right)\mathrm dx = (f(t) + C) - (f(0) + C) = f(t) -f(0).,"['real-analysis', 'calculus', 'integration', 'derivatives']"
85,Evaluating $\int_0^\infty e^{-ax}\frac{\sin{(bx)}}{x}dx $,Evaluating,\int_0^\infty e^{-ax}\frac{\sin{(bx)}}{x}dx ,"From the formula $\displaystyle\int_0^\infty e^{-tx}\frac{\sin{(x)}}{x}dx=\frac{\pi}{2}-\arctan{(t)}$ for $t>0$ , how to use change of variables to obtain a formula for $\displaystyle\int_0^\infty e^{-ax}\frac{\sin{(bx)}}{x}dx$ , when $a$ and $b$ are positive? Then how to use differentiation under integral sign with respect to b to find a formula for $\displaystyle\int_0^\infty e^{-ax}\cos{(bx)}dx$ when a and b are positive. My attempt:  I know the result $\displaystyle\int_0^\infty e^{ax}\cos{(bx)}dx= \frac{e^{ax}}{a^2+b^2}(a\cos{(bx)}+b\sin{(bx)})$ . Is this result useful here? Secondly integral calculator gives me this answer $$-\frac{i(Ei((ib-a)x)-Ei(-(ib+a)x))}{2}.$$ How to evaluate this answer  involving exponential integrals if a=4 and b=5? Note=It was assumed that $(ib+a)\not=0$","From the formula for , how to use change of variables to obtain a formula for , when and are positive? Then how to use differentiation under integral sign with respect to b to find a formula for when a and b are positive. My attempt:  I know the result . Is this result useful here? Secondly integral calculator gives me this answer How to evaluate this answer  involving exponential integrals if a=4 and b=5? Note=It was assumed that",\displaystyle\int_0^\infty e^{-tx}\frac{\sin{(x)}}{x}dx=\frac{\pi}{2}-\arctan{(t)} t>0 \displaystyle\int_0^\infty e^{-ax}\frac{\sin{(bx)}}{x}dx a b \displaystyle\int_0^\infty e^{-ax}\cos{(bx)}dx \displaystyle\int_0^\infty e^{ax}\cos{(bx)}dx= \frac{e^{ax}}{a^2+b^2}(a\cos{(bx)}+b\sin{(bx)}) -\frac{i(Ei((ib-a)x)-Ei(-(ib+a)x))}{2}. (ib+a)\not=0,"['integration', 'derivatives', 'exponential-function', 'improper-integrals', 'trigonometric-integrals']"
86,Proving a Function is Strictly Greater than Another Using the Derivative,Proving a Function is Strictly Greater than Another Using the Derivative,,"Let $f:[0,1]→\mathbb R$ and $g:[0,1]→\mathbb R$ be differentiable with $f(0)=g(0)$ and $f'(x)>g'(x)$ for all $x\in [0,1]$ . Prove $f(x)>g(x)$ for all $x\in (0,1]$ There only seems to be a related theorem, but only applies if $f'(x)=g'(x)$ . I think it might be modifiable to fit this case. The theorem states: Suppose that $f$ and $g$ are continuous on $[a,b]$ and differentiable on $(a,b)$ and that $f'(x)=g'(x)$ for all $x\in (a,b)$ . Then there is a real number $k$ such that $f(x)=g(x)+k$ for all $x\in [a,b]$ . So, we want the case that $f'(x)>g'(x)$ . Although, I'm not sure if I would use this theorem for this problem. Do I have to use IVT or construct a new function?","Let and be differentiable with and for all . Prove for all There only seems to be a related theorem, but only applies if . I think it might be modifiable to fit this case. The theorem states: Suppose that and are continuous on and differentiable on and that for all . Then there is a real number such that for all . So, we want the case that . Although, I'm not sure if I would use this theorem for this problem. Do I have to use IVT or construct a new function?","f:[0,1]→\mathbb R g:[0,1]→\mathbb R f(0)=g(0) f'(x)>g'(x) x\in [0,1] f(x)>g(x) x\in (0,1] f'(x)=g'(x) f g [a,b] (a,b) f'(x)=g'(x) x\in (a,b) k f(x)=g(x)+k x\in [a,b] f'(x)>g'(x)","['real-analysis', 'analysis', 'derivatives']"
87,Why is $y''(x)=f''(u)\cdot [g'(x)]^2$ not correct?,Why is  not correct?,y''(x)=f''(u)\cdot [g'(x)]^2,"Denote the 2-oder difference of $y=f(x)$ as $\Delta^2 y$ , namely \begin{align*} \Delta^2y&=\Delta(\Delta y)\\&=\Delta (f(x+\Delta x)-f(x))\\ &=f(x+\Delta x+\Delta x)-f(x+\Delta x)-(f(x+\Delta x)-f(x))\\ &=f(x+2\Delta x)-2f(x+\Delta x)+f(x).\\ \end{align*} If $f(x)$ is twice differentiable , then we can prove that \begin{align*} \lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}&=\lim_{\Delta x \to 0}\frac{f(x+2\Delta x)-2f(x+\Delta x)+f(x)}{(\Delta x)^2}\\ &=\lim_{\Delta x \to 0}\frac{2f'(x+2\Delta x)-2f'(x+\Delta x)}{2\Delta x}\\ &=\lim_{\Delta x \to 0}\frac{f'(x+2\Delta x)-f'(x+\Delta x)}{\Delta x}\\ &=f''(x),\end{align*} which shows that $$\lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}=\frac{{\rm d}^2 y}{({\rm d}x)^2}.$$ But, if we construct a composite function $y=y(x)$ with $y=f(u),u=g(x)$ ，where $f,g$ are also twice differentiable . Then $$\lim_{\Delta x \to 0}\frac{\Delta^2 y}{\Delta x^2}=\lim_{\Delta x \to 0}\left(\frac{\Delta^2 y}{(\Delta u)^2}\cdot \frac{(\Delta u)^2}{(\Delta x)^2}\right),$$ which seems to imply $$y''(x)=f''(u)\cdot [g'(x)]^2.$$ Of course, this is obviously not correct. But where does the misitake occur?","Denote the 2-oder difference of as , namely If is twice differentiable , then we can prove that which shows that But, if we construct a composite function with ，where are also twice differentiable . Then which seems to imply Of course, this is obviously not correct. But where does the misitake occur?","y=f(x) \Delta^2 y \begin{align*} \Delta^2y&=\Delta(\Delta y)\\&=\Delta (f(x+\Delta x)-f(x))\\ &=f(x+\Delta x+\Delta x)-f(x+\Delta x)-(f(x+\Delta x)-f(x))\\ &=f(x+2\Delta x)-2f(x+\Delta x)+f(x).\\ \end{align*} f(x) \begin{align*} \lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}&=\lim_{\Delta x \to 0}\frac{f(x+2\Delta x)-2f(x+\Delta x)+f(x)}{(\Delta x)^2}\\ &=\lim_{\Delta x \to 0}\frac{2f'(x+2\Delta x)-2f'(x+\Delta x)}{2\Delta x}\\ &=\lim_{\Delta x \to 0}\frac{f'(x+2\Delta x)-f'(x+\Delta x)}{\Delta x}\\
&=f''(x),\end{align*} \lim_{\Delta x \to 0}\frac{\Delta^2 y}{(\Delta x)^2}=\frac{{\rm d}^2 y}{({\rm d}x)^2}. y=y(x) y=f(u),u=g(x) f,g \lim_{\Delta x \to 0}\frac{\Delta^2 y}{\Delta x^2}=\lim_{\Delta x \to 0}\left(\frac{\Delta^2 y}{(\Delta u)^2}\cdot \frac{(\Delta u)^2}{(\Delta x)^2}\right), y''(x)=f''(u)\cdot [g'(x)]^2.","['calculus', 'derivatives']"
88,Disagreement with calculus teacher on a recent test,Disagreement with calculus teacher on a recent test,,"I had a calculus quiz recently and there was a specific Yes/No question that keeps confusing me and I don't understand my teacher's point. The question goes: A point on the graph f where f ' is not defined, extreme values can occur on that point.  (Yes  /  No) I gave examples of functions such as f(x)=x^(1/3) to show that the answer was ""No"" because in such a function where the derivative is undefined an extreme value is not present (even though a critical point is present), Is this a flaw in my logic and understanding or is the case I'm coming up with just a deviance from the norm. Would really appreciate if someone could clear my concept and help me with this. Thanks in advance :)","I had a calculus quiz recently and there was a specific Yes/No question that keeps confusing me and I don't understand my teacher's point. The question goes: A point on the graph f where f ' is not defined, extreme values can occur on that point.  (Yes  /  No) I gave examples of functions such as f(x)=x^(1/3) to show that the answer was ""No"" because in such a function where the derivative is undefined an extreme value is not present (even though a critical point is present), Is this a flaw in my logic and understanding or is the case I'm coming up with just a deviance from the norm. Would really appreciate if someone could clear my concept and help me with this. Thanks in advance :)",,"['calculus', 'derivatives', 'maxima-minima']"
89,How should we interpret $\frac {d}{dt}$?,How should we interpret ?,\frac {d}{dt},"I've been using derivatives and integrals mechanically for years without really questioning the symbols.  I recently watched some YouTube videos and came to understand that: $$\frac {dx}{dt}$$ basically means, for some function, $f(t)=x$ , an infinitesimal change in $t$ , or $dt$ , results in an infinitesimal change in $x$ , or $dx$ .  The ratio of those two numbers is the derivative, or the instantaneous tangent line of $f(t)$ at $t$ .  So far, so good. So could someone explain how to interpret this: $$\frac {d}{dt}$$ I get that the bottom part is an infinitesimal change in $t$ , but what is the top part?  And how should I read an expression like $$\frac {d^2x}{dt^2}$$ My main confusion is the $d$ part seems to have an existence on it's own without the dimension.","I've been using derivatives and integrals mechanically for years without really questioning the symbols.  I recently watched some YouTube videos and came to understand that: basically means, for some function, , an infinitesimal change in , or , results in an infinitesimal change in , or .  The ratio of those two numbers is the derivative, or the instantaneous tangent line of at .  So far, so good. So could someone explain how to interpret this: I get that the bottom part is an infinitesimal change in , but what is the top part?  And how should I read an expression like My main confusion is the part seems to have an existence on it's own without the dimension.",\frac {dx}{dt} f(t)=x t dt x dx f(t) t \frac {d}{dt} t \frac {d^2x}{dt^2} d,['derivatives']
90,Rate of change of volume of cylinder with respect to surface area,Rate of change of volume of cylinder with respect to surface area,,"The surface area of a cylinder is increasing at a rate of 9π m^2/hr.  The height of the cylinder is fixed at 3 meters.  At a certain instant, the surface area is 36π m^2.  What is the rate of change of the volume of the cylinder at the instant (in cubic meters per hour) My daughter got stuck and asked me for help. I spent an hour trying to figure it out and I'm stuck too! Thanks! Here is the answer, thanks to Rishi. Looks like there are a few other ways to solve. Thanks to everyone!! Formulas: S = 2πrh + 2πr^2 V = πr^2h Steps: dS/dt = 9π     <-- given d/dt (2πrh + 2πr^2) = 9π dr/dt (2πh + 4πr) = 9π (2r + 3) dr/dt = 9/2    <-- divide by 2π Equation: dV/dt = 2πrh dr/dt = 6πr dr/dt Solve for r at the instant: 6πr + 2πr^2 = 36π r = 3 Use r to find dr/dt in above equation: (2x3 + 3) dr/dt = 9/2 dr/dt = 1/2 Put values into equation: dV/dt = 6π(3) (1/2) dV/dt = 9π","The surface area of a cylinder is increasing at a rate of 9π m^2/hr.  The height of the cylinder is fixed at 3 meters.  At a certain instant, the surface area is 36π m^2.  What is the rate of change of the volume of the cylinder at the instant (in cubic meters per hour) My daughter got stuck and asked me for help. I spent an hour trying to figure it out and I'm stuck too! Thanks! Here is the answer, thanks to Rishi. Looks like there are a few other ways to solve. Thanks to everyone!! Formulas: S = 2πrh + 2πr^2 V = πr^2h Steps: dS/dt = 9π     <-- given d/dt (2πrh + 2πr^2) = 9π dr/dt (2πh + 4πr) = 9π (2r + 3) dr/dt = 9/2    <-- divide by 2π Equation: dV/dt = 2πrh dr/dt = 6πr dr/dt Solve for r at the instant: 6πr + 2πr^2 = 36π r = 3 Use r to find dr/dt in above equation: (2x3 + 3) dr/dt = 9/2 dr/dt = 1/2 Put values into equation: dV/dt = 6π(3) (1/2) dV/dt = 9π",,"['calculus', 'derivatives']"
91,Errors and approximations,Errors and approximations,,I needed help with this question: The diameter and altitude of a can in the shape of a right circular cylinder are measured 4cm and 6cm respectively. The possible error in each measurement is 0.1cm.Find approximately the maximum possible error in values computer for the  volume. My try: $V=24π$ $$ V= \pi r^2 h $$ $$ dV= \frac {dV}{dr} dr + \frac {dV}{dh} dh$$ $$ = (2\pi rh) dr + (\pi r^2)dh$$ $$ \frac {dV}{V} = 2(dr/r)+ (dh/h) = 2(0.1)+ (0.1) = 0.3 $$ $dV=0.3X 24π=7.2π cc$ But the answer is $1.6πcc$ . What I did wrong?,I needed help with this question: The diameter and altitude of a can in the shape of a right circular cylinder are measured 4cm and 6cm respectively. The possible error in each measurement is 0.1cm.Find approximately the maximum possible error in values computer for the  volume. My try: But the answer is . What I did wrong?,V=24π  V= \pi r^2 h   dV= \frac {dV}{dr} dr + \frac {dV}{dh} dh  = (2\pi rh) dr + (\pi r^2)dh  \frac {dV}{V} = 2(dr/r)+ (dh/h) = 2(0.1)+ (0.1) = 0.3  dV=0.3X 24π=7.2π cc 1.6πcc,['derivatives']
92,Cylindrical tank rate of change,Cylindrical tank rate of change,,Water is pouring into a cylinder with a radius of 5m and height of 20m at a rate of  3 cubic metres a minute. Find the rate of change of height when the tank is half full. Now the Volume V = $πr^2h$ and I can determine the rate of change in Volume is $dV/dt = πr^2dh/dt$ and the rate of change of height is $dh/dt = 1/πr^2\times dV/dt$ Using that formula I can determine that the water is rising at a rate of $3/25π$ m/min. But I cannot seem to figure out how to factor in height so that it is half full. Or is this wrong?,Water is pouring into a cylinder with a radius of 5m and height of 20m at a rate of  3 cubic metres a minute. Find the rate of change of height when the tank is half full. Now the Volume V = and I can determine the rate of change in Volume is and the rate of change of height is Using that formula I can determine that the water is rising at a rate of m/min. But I cannot seem to figure out how to factor in height so that it is half full. Or is this wrong?,πr^2h dV/dt = πr^2dh/dt dh/dt = 1/πr^2\times dV/dt 3/25π,"['derivatives', 'related-rates']"
93,"If $f(x) = e^{x^a}$, what is $f^{(n)}(x)$, the $n$-th derivative of $f$ and what is $\lim_{x \to 0^+} f^{(n)}(x)/x^{a-n}$.","If , what is , the -th derivative of  and what is .",f(x) = e^{x^a} f^{(n)}(x) n f \lim_{x \to 0^+} f^{(n)}(x)/x^{a-n},"This is inspired by Finding the $18th$ Derivative of a Particular Product at $x = 0$ If $f(x) = e^{x^a}$ , what is $f^{(n)}(x)$ , the $n$ -th derivative of $f$ and what is $\lim_{x \to 0^+} f^{(n)}(x)/x^{a-n}$ . I'm sure that this is a duplicate, but I haven't been able to find it. My conjecture is that $f^{(n)}(x) =f(x)ax^{a-n}g_n(x, a) $ where $g_n(x, a) =a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka} $ , the $c(a, n, k) $ are polynomials in $a$ of degree $n-1$ , and $g_n(0,a) =c(a, n, 0) =\prod_{k=1}^{n-1} (a-k) =\dfrac{(a-1)!}{(a-n)!} $ . Note:  I just added my derivation of the recurrence for the $c(a, n, k)$ . It's messy, so there is a fair chance of error(s). Here is what I've done. The following was done with Wolfy and https://www.derivative-calculator.net $\begin{array}\\ f'(x) &=ax^{a-1}f(x)\\ f''(x) &=a x^{a - 2} (a x^a + a - 1)f(x)\\ f'''(x) &=f(x) (a^3 x^{3 a - 3} + (a - 1) a^2 x^{2 a - 3} + a^2 (2 a - 2) x^{2 a - 3} + (a - 2) (a - 1) a x^{a - 3})\\ &=f(x)x^{a-3} (a^3 x^{2 a} + (a - 1) a^2 x^{ a} + a^2 (2 a - 2) x^{ a} + (a - 2) (a - 1)a)\\ &=f(x)ax^{a-3} (a^2 x^{2 a} + ((a - 1) a+a (2 a - 2) ) x^{ a} + (a - 2) (a - 1))\\ &=f(x)ax^{a-3} (a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1))\\ f''''(x) &=ax^{a-4}f(x)\left(a^3x^{3a}+\left(6a^3-6a^2\right)x^{2a}+\left(7a^3-18a^2+11a\right)x^a+a^3-6a^2+11a-6\right)\\ &=ax^{a-4}f(x)\left(a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\right)\\ ...\\ f^{(n)}(x) &=f(x)ax^{a-n}g_n(x, a)\\ g_1(x, a) &= 1\\ g_2(x, a) &= ax^a+a-1\\ g_3(x, a) &= a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1)\\ g_4(x) &=a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\\ ...\\ g_n(x, a) &=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka}\\  \end{array} $ It looks like $g_n(0, a) =c(a, n, 0) =\prod_{k=1}^{n-1} (a-k) =\dfrac{(a-1)!}{(a-n)!} $ (the last for integer $a$ ). I'm quite sure that the existence of the $g_n(x, a)$ can be confirmed by induction, but finding the form of the recurrence, though probably straightforward, would take more work than I am willing to do right now. Maybe later. And here it is. If $f(x) =\prod_{k=1}^m f_k(x) $ , then, removing the "" $(x)$ "", $\ln f =\sum_{k=1}^m f_k $ so, differentiating, $\dfrac{f'}{f} =\sum_{k=1}^m \dfrac{f_k'}{f_k} $ so that $f' =\sum_{k=1}^m f_k'\prod_{j=1, j\ne k}^m f_j $ . Since $\begin{array}\\ f^{(n)}(x) &=f(x)ax^{a-n}g_n(x, a),\\ f^{(n+1)}(x) &=(f(x)ax^{a-n}g_n(x, a))'\\ &=f'(x)ax^{a-n}g_n(x, a)+f(x)a(x^{a-n})'g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\ &=ax^{a-1}f(x)ax^{a-n}g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\ &=a^2x^{2a-n-1}f(x)g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\ &=f(x)ax^{a-n-1}(ax^{a}g_n(x, a)+(a-n)g_n(x, a)+xg_n'(x, a))\\ &=f(x)ax^{a-n-1}((ax^{a}+a-n)g_n(x, a)+xg_n'(x, a))\\ \text{so}\\ g_{n+1}(x, a) &=(ax^{a}+a-n)g_n(x, a)+xg_n'(x, a)\\ \text{Since}\\ g_n(x, a) &=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\  g_n'(x, a) &=a^{n-1}a(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\  &=a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\  \text{so}\\ g_{n+1}(x, a) &=(ax^{a}+a-n)(a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\ &+x(a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1})\\ &=(ax^{a}+a-n)a^{n-1}x^{a(n-1)}+(ax^{a}+a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\ &+a^{n}(n-1)x^{a(n-1)}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka}\\ &=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)}+ax^{a}\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ &+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ &+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\ &=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)} +a\sum_{k=0}^{n-2}c(a, n, k)x^{(k+1)a}\\ &+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ &+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\ &=ax^{a}a^{n-1}x^{a(n-1)}+((a-n)a^{n-1}+a^{n}(n-1))x^{a(n-2)}\\ &+\sum_{k=1}^{n-1}ac(a, n, k-1)x^{ka}\\ &+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ &+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\ &=ax^{a}a^{n-1}x^{a(n-1)}+(a^n-na^{n-1}+na^{n}-a^n)x^{a(n-2)}\\ &+\sum_{k=1}^{n-2}ac(a, n, k-1)x^{ka} +ac(a, n, n-2)x^{(n-1)a}\\ &+(a-n)c(a, n, 0)+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ &+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\ &=a^{n}x^{an}+ac(a, n, n-2)x^{(n-1)a}+na^{n-1}(a-1)x^{a(n-2)}\\ &+(a-n)c(a, n, 0)\\ &+\sum_{k=1}^{n-2}(ac(a, n, k-1)+(a-n)+kac(a, n, k))x^{ka}\\ \text{Matching}\\ g_{n+1}(x, a) &=a^{n}x^{an}+\sum_{k=0}^{n-1}c(a, n+1, k)x^{ka}\\ c(a, n+1, n-1)  &=ac(a, n, n-2)\\ c(a, n+1, n-2)  &=na^{n-1}(a-1)+ac(a, n, n-3)+(a-n)+(n-2)ac(a, n, n-2)\\ c(a, n+1, 0)  &=(a-n)c(a, n, 0)\\ c(a, n+1, k) &=ac(a, n, k-1)+(a-n)+kac(a, n, k) \quad\text{for }k=1..n-3\\ \end{array} $","This is inspired by Finding the $18th$ Derivative of a Particular Product at $x = 0$ If , what is , the -th derivative of and what is . I'm sure that this is a duplicate, but I haven't been able to find it. My conjecture is that where , the are polynomials in of degree , and . Note:  I just added my derivation of the recurrence for the . It's messy, so there is a fair chance of error(s). Here is what I've done. The following was done with Wolfy and https://www.derivative-calculator.net It looks like (the last for integer ). I'm quite sure that the existence of the can be confirmed by induction, but finding the form of the recurrence, though probably straightforward, would take more work than I am willing to do right now. Maybe later. And here it is. If , then, removing the "" "", so, differentiating, so that . Since","f(x) = e^{x^a} f^{(n)}(x) n f \lim_{x \to 0^+} f^{(n)}(x)/x^{a-n} f^{(n)}(x)
=f(x)ax^{a-n}g_n(x, a)
 g_n(x, a)
=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka}
 c(a, n, k)
 a n-1 g_n(0,a)
=c(a, n, 0)
=\prod_{k=1}^{n-1} (a-k)
=\dfrac{(a-1)!}{(a-n)!}
 c(a, n, k) \begin{array}\\
f'(x)
&=ax^{a-1}f(x)\\
f''(x)
&=a x^{a - 2} (a x^a + a - 1)f(x)\\
f'''(x)
&=f(x) (a^3 x^{3 a - 3} + (a - 1) a^2 x^{2 a - 3} + a^2 (2 a - 2) x^{2 a - 3} + (a - 2) (a - 1) a x^{a - 3})\\
&=f(x)x^{a-3} (a^3 x^{2 a} + (a - 1) a^2 x^{ a} + a^2 (2 a - 2) x^{ a} + (a - 2) (a - 1)a)\\
&=f(x)ax^{a-3} (a^2 x^{2 a} + ((a - 1) a+a (2 a - 2) ) x^{ a} + (a - 2) (a - 1))\\
&=f(x)ax^{a-3} (a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1))\\
f''''(x)
&=ax^{a-4}f(x)\left(a^3x^{3a}+\left(6a^3-6a^2\right)x^{2a}+\left(7a^3-18a^2+11a\right)x^a+a^3-6a^2+11a-6\right)\\
&=ax^{a-4}f(x)\left(a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\right)\\
...\\
f^{(n)}(x)
&=f(x)ax^{a-n}g_n(x, a)\\
g_1(x, a)
&= 1\\
g_2(x, a)
&= ax^a+a-1\\
g_3(x, a)
&= a^2 x^{2 a} + 3(a - 1) a x^{ a} + (a - 2) (a - 1)\\
g_4(x)
&=a^3x^{3a}+6a^2(a-1)x^{2a}+a (a - 1) (7 a - 11)x^a+(a - 1) (a - 2) (a - 3)\\
...\\
g_n(x, a)
&=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-1}c(a, n, k)x^{ka}\\ 
\end{array}
 g_n(0, a)
=c(a, n, 0)
=\prod_{k=1}^{n-1} (a-k)
=\dfrac{(a-1)!}{(a-n)!}
 a g_n(x, a) f(x)
=\prod_{k=1}^m f_k(x)
 (x) \ln f
=\sum_{k=1}^m f_k
 \dfrac{f'}{f}
=\sum_{k=1}^m \dfrac{f_k'}{f_k}
 f'
=\sum_{k=1}^m f_k'\prod_{j=1, j\ne k}^m f_j
 \begin{array}\\
f^{(n)}(x)
&=f(x)ax^{a-n}g_n(x, a),\\
f^{(n+1)}(x)
&=(f(x)ax^{a-n}g_n(x, a))'\\
&=f'(x)ax^{a-n}g_n(x, a)+f(x)a(x^{a-n})'g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=ax^{a-1}f(x)ax^{a-n}g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=a^2x^{2a-n-1}f(x)g_n(x, a)+f(x)a(a-n)x^{a-n-1}g_n(x, a)+f(x)ax^{a-n}g_n'(x, a)\\
&=f(x)ax^{a-n-1}(ax^{a}g_n(x, a)+(a-n)g_n(x, a)+xg_n'(x, a))\\
&=f(x)ax^{a-n-1}((ax^{a}+a-n)g_n(x, a)+xg_n'(x, a))\\
\text{so}\\
g_{n+1}(x, a)
&=(ax^{a}+a-n)g_n(x, a)+xg_n'(x, a)\\
\text{Since}\\
g_n(x, a)
&=a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\ 
g_n'(x, a)
&=a^{n-1}a(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\ 
&=a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1}\\ 
\text{so}\\
g_{n+1}(x, a)
&=(ax^{a}+a-n)(a^{n-1}x^{a(n-1)}+\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\
&+x(a^{n}(n-1)x^{a(n-1)-1}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka-1})\\
&=(ax^{a}+a-n)a^{n-1}x^{a(n-1)}+(ax^{a}+a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka})\\
&+a^{n}(n-1)x^{a(n-1)}+\sum_{k=0}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)}+ax^{a}\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a-n)a^{n-1}x^{a(n-2)}
+a\sum_{k=0}^{n-2}c(a, n, k)x^{(k+1)a}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+a^{n}(n-1)x^{a(n-2)}+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+((a-n)a^{n-1}+a^{n}(n-1))x^{a(n-2)}\\
&+\sum_{k=1}^{n-1}ac(a, n, k-1)x^{ka}\\
&+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=ax^{a}a^{n-1}x^{a(n-1)}+(a^n-na^{n-1}+na^{n}-a^n)x^{a(n-2)}\\
&+\sum_{k=1}^{n-2}ac(a, n, k-1)x^{ka}
+ac(a, n, n-2)x^{(n-1)a}\\
&+(a-n)c(a, n, 0)+(a-n)\sum_{k=0}^{n-2}c(a, n, k)x^{ka}\\
&+\sum_{k=1}^{n-2}kac(a, n, k)x^{ka}\\
&=a^{n}x^{an}+ac(a, n, n-2)x^{(n-1)a}+na^{n-1}(a-1)x^{a(n-2)}\\
&+(a-n)c(a, n, 0)\\
&+\sum_{k=1}^{n-2}(ac(a, n, k-1)+(a-n)+kac(a, n, k))x^{ka}\\
\text{Matching}\\
g_{n+1}(x, a)
&=a^{n}x^{an}+\sum_{k=0}^{n-1}c(a, n+1, k)x^{ka}\\
c(a, n+1, n-1) 
&=ac(a, n, n-2)\\
c(a, n+1, n-2) 
&=na^{n-1}(a-1)+ac(a, n, n-3)+(a-n)+(n-2)ac(a, n, n-2)\\
c(a, n+1, 0) 
&=(a-n)c(a, n, 0)\\
c(a, n+1, k)
&=ac(a, n, k-1)+(a-n)+kac(a, n, k)
\quad\text{for }k=1..n-3\\
\end{array}
","['derivatives', 'induction', 'recurrence-relations', 'exponential-function']"
94,"Calculus for the Practical Man: Chapter 4, Problem 10 (Solve problem without trigonometry possible?)","Calculus for the Practical Man: Chapter 4, Problem 10 (Solve problem without trigonometry possible?)",,"My issue is that I am trying to avoid trigonometry as a means to solve this problem, because he goes into the calculus of trigonometric functions in the subsequent chapter, and, therefore, I think he intends the problem to be solved without trigonometry. Two automobiles are moving along straight level roads which cross at an angle of sixty degrees, one approaching the crossing at 25 miles an hour and the other leaving it at 30 miles an hour on the same side. How fast are they approaching or separating form each other at the moment when each is ten miles from the crossing. How do I relate the quantities given that I cannot use trigonometry and the right triangle relation $x^2 + y^2 = h^2$ ?""","My issue is that I am trying to avoid trigonometry as a means to solve this problem, because he goes into the calculus of trigonometric functions in the subsequent chapter, and, therefore, I think he intends the problem to be solved without trigonometry. Two automobiles are moving along straight level roads which cross at an angle of sixty degrees, one approaching the crossing at 25 miles an hour and the other leaving it at 30 miles an hour on the same side. How fast are they approaching or separating form each other at the moment when each is ten miles from the crossing. How do I relate the quantities given that I cannot use trigonometry and the right triangle relation ?""",x^2 + y^2 = h^2,"['calculus', 'derivatives', 'related-rates']"
95,Approximations using derivatives,Approximations using derivatives,,"I came across the following definitions in my textbook: The differential of $x$ , denoted by $dx$ , is defined by $dx = \Delta x$ The differential of $y$ , denoted by $dy$ , is defined by $dy=f'(x) dx$ or $dy = (\frac{dy}{dx})\Delta x$ I understood the first part. However, the second part doesn't make intuitive sense to me. What is the intuitive explanation for the second definition?","I came across the following definitions in my textbook: The differential of , denoted by , is defined by The differential of , denoted by , is defined by or I understood the first part. However, the second part doesn't make intuitive sense to me. What is the intuitive explanation for the second definition?",x dx dx = \Delta x y dy dy=f'(x) dx dy = (\frac{dy}{dx})\Delta x,"['calculus', 'derivatives', 'approximation']"
96,Let $f(z)=\frac{\bar z^2}{z}$ when $z\neq 0$ and $f(0)=0$. Show that $f'(0)$ does not exist.,Let  when  and . Show that  does not exist.,f(z)=\frac{\bar z^2}{z} z\neq 0 f(0)=0 f'(0),"Let $f(z)=\frac{\bar z^2}{z}$ when $z\neq 0$ and $f(0)=0$ . Show that $f'(0)$ does not exist. $$f'(0)=\lim_{z \to 0} \frac{f(z)-f(0)}{z-0}=\lim_{z \to 0} \left( \frac{x-iy}{x+iy}\right)^2$$ Reaching the origin along the line $y=mx$ , we get $$f'(0)=\lim_{x \to 0} \left( \frac{x-imx}{x+imx}\right)^2=\left( \frac{1-im}{1+im}\right)^2$$ Since this value depends on $m$ , the derivative takes different values along different paths and hence does not exist. Is this right and what are other ways to do this?","Let when and . Show that does not exist. Reaching the origin along the line , we get Since this value depends on , the derivative takes different values along different paths and hence does not exist. Is this right and what are other ways to do this?",f(z)=\frac{\bar z^2}{z} z\neq 0 f(0)=0 f'(0) f'(0)=\lim_{z \to 0} \frac{f(z)-f(0)}{z-0}=\lim_{z \to 0} \left( \frac{x-iy}{x+iy}\right)^2 y=mx f'(0)=\lim_{x \to 0} \left( \frac{x-imx}{x+imx}\right)^2=\left( \frac{1-im}{1+im}\right)^2 m,"['complex-analysis', 'limits', 'proof-verification', 'derivatives', 'complex-numbers']"
97,The differential of $\lVert D^{1-\lambda} U^* D^{2\lambda}\ UD^{1-\lambda} \rVert_F^2$ with respect to $\lambda$,The differential of  with respect to,\lVert D^{1-\lambda} U^* D^{2\lambda}\ UD^{1-\lambda} \rVert_F^2 \lambda,"Let a square matrix $A=WDV^*$ by the SVD where $D$ is diagonal with positive entries, $U=V^*W$ is unitary, and $0<\lambda<1$ .  let $$ f_{(\lambda)} = \lVert D^{1-\lambda} U^* D^{2\lambda}\  UD^{1-\lambda} \rVert_F^2 = \operatorname{tr}\Big(D^{2-2\lambda} U^* D^{2\lambda}\ U \ D^{2-2\lambda} U^* D^{2\lambda}\ U\Big) $$ Please help with the differential $\frac{\partial}{\partial\lambda} f_{(\lambda)}$ . I'm thinking in the Frobenius product direction, but I'm not able to get it done. Thanks in advance. Post-edit: Thanks to @greg for pointing my attention to $\operatorname{tr}(M^*M)\ne\operatorname{tr}(M^2)$ since $M=D^{2-2\lambda} U^* D^{2\lambda}\ U$ is not normal. Again, the Frobenius norm is a real-valued function. Therefore, to ensure real-valued trace, will the following be correct? (I implemented some test cases in MATLAB to check the equality) . $$ \begin{align} f_{(\lambda)} & \ne \operatorname{tr}\Big((D^{2-2\lambda} U^* D^{2\lambda}\ U)^2\Big) \\ &=\operatorname{tr}\Big((D^{2-2\lambda} U^* D^{2\lambda}\ U)\ (D^{2-2\lambda} U^* D^{2\lambda}\ U)^*\Big) \\ &=\operatorname{tr}\big(D^{4-4\lambda} U^* D^{4\lambda}\ U\big) \end{align} $$ If it's the right way to state it, please help with the differential $\frac{\partial}{\partial\lambda} f_{(\lambda)}$ with respect to this $f_{(\lambda)}$ version.","Let a square matrix by the SVD where is diagonal with positive entries, is unitary, and .  let Please help with the differential . I'm thinking in the Frobenius product direction, but I'm not able to get it done. Thanks in advance. Post-edit: Thanks to @greg for pointing my attention to since is not normal. Again, the Frobenius norm is a real-valued function. Therefore, to ensure real-valued trace, will the following be correct? (I implemented some test cases in MATLAB to check the equality) . If it's the right way to state it, please help with the differential with respect to this version.","A=WDV^* D U=V^*W 0<\lambda<1  f_{(\lambda)} = \lVert D^{1-\lambda} U^* D^{2\lambda}\  UD^{1-\lambda} \rVert_F^2 = \operatorname{tr}\Big(D^{2-2\lambda} U^* D^{2\lambda}\ U \ D^{2-2\lambda} U^* D^{2\lambda}\ U\Big)  \frac{\partial}{\partial\lambda} f_{(\lambda)} \operatorname{tr}(M^*M)\ne\operatorname{tr}(M^2) M=D^{2-2\lambda} U^* D^{2\lambda}\ U  \begin{align} f_{(\lambda)} & \ne \operatorname{tr}\Big((D^{2-2\lambda} U^* D^{2\lambda}\ U)^2\Big) \\
&=\operatorname{tr}\Big((D^{2-2\lambda} U^* D^{2\lambda}\ U)\ (D^{2-2\lambda} U^* D^{2\lambda}\ U)^*\Big) \\
&=\operatorname{tr}\big(D^{4-4\lambda} U^* D^{4\lambda}\ U\big) \end{align}  \frac{\partial}{\partial\lambda} f_{(\lambda)} f_{(\lambda)}","['linear-algebra', 'matrices', 'derivatives', 'trace', 'frobenius-method']"
98,Derivative of sum of matrix-vector product,Derivative of sum of matrix-vector product,,"I would like to take the derivative of the following expression w.r.t. the matrix $A \in \mathbb{R}^{m \times n}$ , i.e., $$ \frac{\partial \big( \sum_{i=1}^m (Ax)_i \big)}{\partial A}, $$ where $x \in \mathbb{R}^n$ . The second answer here gives the derivative of the matrix-vector product w.r.t. the matrix, but, I wasn't sure how it changes with the summation? Though I think that it should work out cleanly since derivative and summation are linear operators and can be interchanged? I am not sure about how the indices would change so any advice regarding that would be much appreciated.","I would like to take the derivative of the following expression w.r.t. the matrix , i.e., where . The second answer here gives the derivative of the matrix-vector product w.r.t. the matrix, but, I wasn't sure how it changes with the summation? Though I think that it should work out cleanly since derivative and summation are linear operators and can be interchanged? I am not sure about how the indices would change so any advice regarding that would be much appreciated.","A \in \mathbb{R}^{m \times n}  \frac{\partial \big( \sum_{i=1}^m (Ax)_i \big)}{\partial A},  x \in \mathbb{R}^n","['linear-algebra', 'derivatives', 'matrix-calculus']"
99,"Find formula for $f''(0)$ using $f(0), f(h), f(2h), f'(h)$",Find formula for  using,"f''(0) f(0), f(h), f(2h), f'(h)","I want to find an approximation for $f''(0)$ using the values of: $f(0), f(h), f(2h), f'(h)$ Usually I would use unknown coefficients and work the formula $$Af(0) + Bf(h) +Cf(2h)+Df'(h)$$ using taylor's expansion constraints. The problem here, that in the expansion of $f'(h)$ , there is a difference in the multiplication by $h$ : $f'(h) = f'(0) + hf''(0) + ...$ unlike $f(h) = f(0) + hf'(0) + \frac{h^2}{2}f''(0) + ...$ Moreover, I don't know the value of $f'(0)$ Help would be appreciated","I want to find an approximation for using the values of: Usually I would use unknown coefficients and work the formula using taylor's expansion constraints. The problem here, that in the expansion of , there is a difference in the multiplication by : unlike Moreover, I don't know the value of Help would be appreciated","f''(0) f(0), f(h), f(2h), f'(h) Af(0) + Bf(h) +Cf(2h)+Df'(h) f'(h) h f'(h) = f'(0) + hf''(0) + ... f(h) = f(0) + hf'(0) + \frac{h^2}{2}f''(0) + ... f'(0)","['derivatives', 'numerical-methods', 'numerical-calculus']"
