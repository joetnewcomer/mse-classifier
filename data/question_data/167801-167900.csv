,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Moment Generating Functions of Normal/Gaussian Random Variable: 3rd, 4th,..,kth Moment","Moment Generating Functions of Normal/Gaussian Random Variable: 3rd, 4th,..,kth Moment",,"Derivation of Normal Random MGF: I'm having trouble deriving the answers for $E\,[X^3]$ and $E\,[X^4]$ given the information from the image I've posted. In the image I understand how they setup the equation for normal random distribution $X$ : given as $G(\theta)$ . What I am not understanding is how you can go from simply completing the square to finding the 4th moment. Am I simply misinterpreting the equation given in the image or do I need to complete more steps that are not stated in the image?",Derivation of Normal Random MGF: I'm having trouble deriving the answers for and given the information from the image I've posted. In the image I understand how they setup the equation for normal random distribution : given as . What I am not understanding is how you can go from simply completing the square to finding the 4th moment. Am I simply misinterpreting the equation given in the image or do I need to complete more steps that are not stated in the image?,"E\,[X^3] E\,[X^4] X G(\theta)","['probability', 'statistics', 'stochastic-processes']"
1,Binomial testing,Binomial testing,,"Suppose in any given year, the probability of getting a success is $0.8$. Suppose we have $10$ years of data and we have observed $3$ failures. How can I test if these three failures are statistically significant at say the 90% confidence interval? I have vague memories of high school hypothesis testing but cannot seem to recall it!","Suppose in any given year, the probability of getting a success is $0.8$. Suppose we have $10$ years of data and we have observed $3$ failures. How can I test if these three failures are statistically significant at say the 90% confidence interval? I have vague memories of high school hypothesis testing but cannot seem to recall it!",,"['probability', 'statistics']"
2,probability of concordance and discordance,probability of concordance and discordance,,"Define the probability of concordance $(\pi_c)$ and probability of discordance $(\pi_d)$. Obtain an unbiased estimate of $\tau = \pi_c-\pi_d$ I know what is concordance and discordance (usually use it to find Kendall's tau). Knowing that, I guessed that probability of concordance is $P(X_1>X_2, Y_1>Y_2)$ or something like this. But I don't really rely on guess. What I want is a article/book where it is documented or if someone gives answer of this specific question here (that will be very helpful), so that I ca answer the question clearly. Anyway, thanks for any help.","Define the probability of concordance $(\pi_c)$ and probability of discordance $(\pi_d)$. Obtain an unbiased estimate of $\tau = \pi_c-\pi_d$ I know what is concordance and discordance (usually use it to find Kendall's tau). Knowing that, I guessed that probability of concordance is $P(X_1>X_2, Y_1>Y_2)$ or something like this. But I don't really rely on guess. What I want is a article/book where it is documented or if someone gives answer of this specific question here (that will be very helpful), so that I ca answer the question clearly. Anyway, thanks for any help.",,"['probability', 'statistics', 'reference-request', 'statistical-inference']"
3,How to find the MLE of the parameters of an inverse Gaussian distribution?,How to find the MLE of the parameters of an inverse Gaussian distribution?,,The pdf is $(\frac{\lambda}{2\pi x^3})^\frac{1}{2}$exp$(\frac{-\lambda (x-\mu)^2}{2 \mu^2 x})$ I believe $\hat\mu$=$\bar X$ but I can't seem to find $\hat \lambda$,The pdf is $(\frac{\lambda}{2\pi x^3})^\frac{1}{2}$exp$(\frac{-\lambda (x-\mu)^2}{2 \mu^2 x})$ I believe $\hat\mu$=$\bar X$ but I can't seem to find $\hat \lambda$,,"['statistics', 'maximum-likelihood']"
4,Covariance of polynomials of random normal variables,Covariance of polynomials of random normal variables,,"$\newcommand{\Cov}{\operatorname{Cov}}$If $X$ and $Y$ are random variables with a bivariate normal distribution and: $X\sim\mathcal{N}(\mu_X,\sigma_X^2)$ $Y\sim\mathcal{N}(\mu_Y,\sigma_Y^2)$ $\Cov(X,Y)\neq0$ May I compute $\Cov(X^m,Y^n)$ for arbitrary positive integers $m$ and $n$?","$\newcommand{\Cov}{\operatorname{Cov}}$If $X$ and $Y$ are random variables with a bivariate normal distribution and: $X\sim\mathcal{N}(\mu_X,\sigma_X^2)$ $Y\sim\mathcal{N}(\mu_Y,\sigma_Y^2)$ $\Cov(X,Y)\neq0$ May I compute $\Cov(X^m,Y^n)$ for arbitrary positive integers $m$ and $n$?",,"['probability', 'statistics', 'random-variables', 'normal-distribution', 'covariance']"
5,Derivation of derivative of multivariate Gaussian w.r.t. covariance matrix,Derivation of derivative of multivariate Gaussian w.r.t. covariance matrix,,"I'm reading a paper, probabilistic CCA , in which the authors state derivatives without showing derivations. I would like step-by-step derivations to convince myself. Consider a $d$-dimensional multivariate Gaussian random variable: $$ \textbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma) $$ In probabilistic CCA, we define $\Sigma = W W^{\top} + \Psi$, where $W \in \mathbb{R}^{d \times q}$ and $\Psi \in \mathbb{R}^{d \times d}$. I'd like to compute the derivative w.r.t. $\boldsymbol{\mu}$, $W$, and $\Psi$ for the negative log-likelihood. The stationary point for $\boldsymbol{\mu}$ is just the empirical mean (shown below*) or $\hat{\boldsymbol{\mu}}$. Plugging in the minimum for the parameter $\boldsymbol{\mu}$ into the negative log-likelihood, we get: $$ \frac{\partial \mathcal{L}}{\partial W} = \frac{\partial}{\partial W} \Big\{ \overbrace{     \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \hat{\boldsymbol{\mu}})^{\top} \Sigma^{-1} (\textbf{x}_i - \hat{\boldsymbol{\mu}}) }^{A} + \overbrace{\frac{n}{2} \ln |\Sigma|}^{B} + \overbrace{\text{const}}^{C} \Big\} $$ Clearly, $C = 0$. But I'm not sure how to handle $A$ and $B$, particularly since $\Sigma = W W^{\top} + \Psi$. *Derivative w.r.t. $\boldsymbol{\mu}$ The negative log-likelihood is: $$ \mathcal{L} = \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) + \frac{n}{2} \ln |\Sigma| + \text{const} $$ The derivative of the two rightmost terms with respect to $\boldsymbol{\mu}$ is $0$, meaning we just need to compute: $$ \frac{\partial}{\partial \boldsymbol{\mu}} \Big\{ \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ By the linearity of differentiation, we have: $$ \frac{1}{2} \sum_{i=1}^{n} \frac{\partial}{\partial \boldsymbol{\mu}} \Big\{ (\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ Using Equation ($86$) from the Matrix Cookbox , we get: $$ \frac{1}{2} \sum_{i=1}^{n} \Big\{ -2 \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ Finally, solve for $\boldsymbol{\mu}$, we get: $$ \begin{align} 0 &= \frac{1}{2} \sum_{i=1}^{n} \Big\{ -2 \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} \\ &= - \sum_{i=1}^{n} \Big\{ \Sigma^{-1} \textbf{x}_i - \Sigma^{-1} \boldsymbol{\mu} \Big\} \\ &= - \sum_{i=1}^{n} \Big\{ \Sigma^{-1} \textbf{x}_i \Big\} + n \Sigma^{-1} \boldsymbol{\mu} \\ - n \Sigma^{-1} \boldsymbol{\mu} &= - \Sigma^{-1} \sum_{i=1}^{n} \textbf{x}_i \\ \boldsymbol{\mu} &= \frac{1}{n} \sum_{i=1}^{n} \textbf{x}_i \end{align} $$ And we're done.","I'm reading a paper, probabilistic CCA , in which the authors state derivatives without showing derivations. I would like step-by-step derivations to convince myself. Consider a $d$-dimensional multivariate Gaussian random variable: $$ \textbf{x} \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma) $$ In probabilistic CCA, we define $\Sigma = W W^{\top} + \Psi$, where $W \in \mathbb{R}^{d \times q}$ and $\Psi \in \mathbb{R}^{d \times d}$. I'd like to compute the derivative w.r.t. $\boldsymbol{\mu}$, $W$, and $\Psi$ for the negative log-likelihood. The stationary point for $\boldsymbol{\mu}$ is just the empirical mean (shown below*) or $\hat{\boldsymbol{\mu}}$. Plugging in the minimum for the parameter $\boldsymbol{\mu}$ into the negative log-likelihood, we get: $$ \frac{\partial \mathcal{L}}{\partial W} = \frac{\partial}{\partial W} \Big\{ \overbrace{     \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \hat{\boldsymbol{\mu}})^{\top} \Sigma^{-1} (\textbf{x}_i - \hat{\boldsymbol{\mu}}) }^{A} + \overbrace{\frac{n}{2} \ln |\Sigma|}^{B} + \overbrace{\text{const}}^{C} \Big\} $$ Clearly, $C = 0$. But I'm not sure how to handle $A$ and $B$, particularly since $\Sigma = W W^{\top} + \Psi$. *Derivative w.r.t. $\boldsymbol{\mu}$ The negative log-likelihood is: $$ \mathcal{L} = \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) + \frac{n}{2} \ln |\Sigma| + \text{const} $$ The derivative of the two rightmost terms with respect to $\boldsymbol{\mu}$ is $0$, meaning we just need to compute: $$ \frac{\partial}{\partial \boldsymbol{\mu}} \Big\{ \frac{1}{2} \sum_{i=1}^{n}(\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ By the linearity of differentiation, we have: $$ \frac{1}{2} \sum_{i=1}^{n} \frac{\partial}{\partial \boldsymbol{\mu}} \Big\{ (\textbf{x}_i - \boldsymbol{\mu})^{\top} \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ Using Equation ($86$) from the Matrix Cookbox , we get: $$ \frac{1}{2} \sum_{i=1}^{n} \Big\{ -2 \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} = 0 $$ Finally, solve for $\boldsymbol{\mu}$, we get: $$ \begin{align} 0 &= \frac{1}{2} \sum_{i=1}^{n} \Big\{ -2 \Sigma^{-1} (\textbf{x}_i - \boldsymbol{\mu}) \Big\} \\ &= - \sum_{i=1}^{n} \Big\{ \Sigma^{-1} \textbf{x}_i - \Sigma^{-1} \boldsymbol{\mu} \Big\} \\ &= - \sum_{i=1}^{n} \Big\{ \Sigma^{-1} \textbf{x}_i \Big\} + n \Sigma^{-1} \boldsymbol{\mu} \\ - n \Sigma^{-1} \boldsymbol{\mu} &= - \Sigma^{-1} \sum_{i=1}^{n} \textbf{x}_i \\ \boldsymbol{\mu} &= \frac{1}{n} \sum_{i=1}^{n} \textbf{x}_i \end{align} $$ And we're done.",,"['statistics', 'derivatives', 'partial-derivative', 'matrix-calculus']"
6,First-Order Stochastic Dominance,First-Order Stochastic Dominance,,"Consider two cumulative distribution functions $F(x)$ and $G(x)$ for $x\in[a,b]$ where $G(x)$ has the first-order stochastic dominance over $F(x)$. That is, $F(x)>G(x)$ for all $x\in(a,b)$. We assume $a<0$ and $b>0$. Let $f(x)$ and $g(x)$ be the probability density function of $F(x)$ and $G(x)$ respectively. Suppose the expected value of $x$ under $F(x)$ is positive: $$ \int_{a}^{b}xf(x)dx=\int_{a}^{0}xf(x)dx+\int_{0}^{b}xf(x)dx>0. $$ Under this condition, does $f(x)-g(x)>0$ always hold in any interval of $0<x<b$? Graphical Expression of the Question is Here.","Consider two cumulative distribution functions $F(x)$ and $G(x)$ for $x\in[a,b]$ where $G(x)$ has the first-order stochastic dominance over $F(x)$. That is, $F(x)>G(x)$ for all $x\in(a,b)$. We assume $a<0$ and $b>0$. Let $f(x)$ and $g(x)$ be the probability density function of $F(x)$ and $G(x)$ respectively. Suppose the expected value of $x$ under $F(x)$ is positive: $$ \int_{a}^{b}xf(x)dx=\int_{a}^{0}xf(x)dx+\int_{0}^{b}xf(x)dx>0. $$ Under this condition, does $f(x)-g(x)>0$ always hold in any interval of $0<x<b$? Graphical Expression of the Question is Here.",,"['calculus', 'statistics', 'probability-distributions', 'economics']"
7,Mean and root mean square of a random variable,Mean and root mean square of a random variable,,"Given a positive random variable $x$ with continuous probability density $f(x)$. What is the main difference between the ordinary mean value $$\bar{x} = \int_0^\infty\,x\,f(x)\ dx$$ and the root mean squared expression $$\tilde{x}= \sqrt{\int_0^\infty\,x^2\,f(x)\ dx}.$$ Are there any relations or inequalities between both of them?","Given a positive random variable $x$ with continuous probability density $f(x)$. What is the main difference between the ordinary mean value $$\bar{x} = \int_0^\infty\,x\,f(x)\ dx$$ and the root mean squared expression $$\tilde{x}= \sqrt{\int_0^\infty\,x^2\,f(x)\ dx}.$$ Are there any relations or inequalities between both of them?",,['real-analysis']
8,Bootstrap for Mean with 95% Confidence Interval,Bootstrap for Mean with 95% Confidence Interval,,"I've been working through a book Modern Data Science with R and I have a conceptual question about bootstrapping and confidence intervals. Say you do a bootstrap for a mean 1000 times.  How do you get the 95% confidence interval?  According to the demonstration in the book, you simply calculate the .025, .975 quantile. Can anybody explain why this is so? I'm wondering why this process doesn't include the familiar steps of calculating a confidence interval like you'd do in a t-test. Just in case there are any R users that want a reference to a specific example of the book exercise I am working with, it is here: https://mdsr-book.github.io/instructor/foundations-ex.html I am using R and the data for the 2nd exercise is the Gestation dataset available in the MosaicData package. This question was prompted by the difference between the 1st exercise and the 2nd one. The 1st exercise simply asked to calculate a confidence interval which I solved simply with the t.test function. The 2nd exercise I first solved with the Mosaic package (following book demonstration) but didn't really know ""why"" the answer works. (Book showed the procedure but didn't explain) So I'm basically wondering WHY the 95% confidence interval can be obtained by getting 1,000 or so means with resampling (e.g. bootstrap) and then getting the appropriate quantile.","I've been working through a book Modern Data Science with R and I have a conceptual question about bootstrapping and confidence intervals. Say you do a bootstrap for a mean 1000 times.  How do you get the 95% confidence interval?  According to the demonstration in the book, you simply calculate the .025, .975 quantile. Can anybody explain why this is so? I'm wondering why this process doesn't include the familiar steps of calculating a confidence interval like you'd do in a t-test. Just in case there are any R users that want a reference to a specific example of the book exercise I am working with, it is here: https://mdsr-book.github.io/instructor/foundations-ex.html I am using R and the data for the 2nd exercise is the Gestation dataset available in the MosaicData package. This question was prompted by the difference between the 1st exercise and the 2nd one. The 1st exercise simply asked to calculate a confidence interval which I solved simply with the t.test function. The 2nd exercise I first solved with the Mosaic package (following book demonstration) but didn't really know ""why"" the answer works. (Book showed the procedure but didn't explain) So I'm basically wondering WHY the 95% confidence interval can be obtained by getting 1,000 or so means with resampling (e.g. bootstrap) and then getting the appropriate quantile.",,['statistics']
9,One-sided confidence interval for variance,One-sided confidence interval for variance,,"I am little bit confused about how we get the upper bound for CI for variance: We have $\frac{(n-1) s^2}{\sigma^{2}}\sim X^2(n-1)$ $$P\left(\frac{(n-1)s^2}{\sigma^{2}}>X^2_{1-\alpha,n-1}\right)=1-\alpha$$ and if we solve for $\sigma^{2}$ then we should get $$P\left(\frac{1}{\sigma^{2}}>\frac{X^2_{1-\alpha,n-1}}{(n-1)s^2}\right)=1-α\Longrightarrow P\left(\sigma^{2}>\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right)=1-α\\\Longrightarrow CI=\left[\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}},+\infty\right].$$ But I do not know how the upper bound CI come out to be  $\left[0,\dfrac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right]$???","I am little bit confused about how we get the upper bound for CI for variance: We have $\frac{(n-1) s^2}{\sigma^{2}}\sim X^2(n-1)$ $$P\left(\frac{(n-1)s^2}{\sigma^{2}}>X^2_{1-\alpha,n-1}\right)=1-\alpha$$ and if we solve for $\sigma^{2}$ then we should get $$P\left(\frac{1}{\sigma^{2}}>\frac{X^2_{1-\alpha,n-1}}{(n-1)s^2}\right)=1-α\Longrightarrow P\left(\sigma^{2}>\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right)=1-α\\\Longrightarrow CI=\left[\frac{(n-1)s^2}{X^2_{1-\alpha,n-1}},+\infty\right].$$ But I do not know how the upper bound CI come out to be  $\left[0,\dfrac{(n-1)s^2}{X^2_{1-\alpha,n-1}}\right]$???",,['statistics']
10,Using variance properties to find the standard deviation of a sample,Using variance properties to find the standard deviation of a sample,,"The question is: The standard deviation of the mean mass of a sample of 2 aubergines is 20 g smaller than the standard deviation in the mass of a single aubergine. Find the standard deviation of the mass of an aubergine. So, I chose X as the mass of an aubergine, and set up an equation: $\sqrt{Var(X_1 + X_2)+20}=\sqrt{Var(X)}$ $Var(X_1 + X_2)+20=Var(X)$ $2Var(X)+20=Var(X)$ But then I get a negative value of $Var(X)$. What did I do wrong? Edit: I realized that since it's a sample, it should be $Var(\frac{X_1 + X_2}{2})$. So I did make an equation like that, assuming $X_1+X_2=2X$. But then again I don't have the answer for some reason. $\frac{1}{4}(2)Var(X)+20=Var(X)$ $\frac{1}{2}Var(X)+20=Var(X)$ $\frac{1}{2}Var(X)=20$ $Var(X)=40$ And so the standard deviation would be $\sqrt{40}$. But apparently the answer is 68.3g. Anybody know what I did wrong?","The question is: The standard deviation of the mean mass of a sample of 2 aubergines is 20 g smaller than the standard deviation in the mass of a single aubergine. Find the standard deviation of the mass of an aubergine. So, I chose X as the mass of an aubergine, and set up an equation: $\sqrt{Var(X_1 + X_2)+20}=\sqrt{Var(X)}$ $Var(X_1 + X_2)+20=Var(X)$ $2Var(X)+20=Var(X)$ But then I get a negative value of $Var(X)$. What did I do wrong? Edit: I realized that since it's a sample, it should be $Var(\frac{X_1 + X_2}{2})$. So I did make an equation like that, assuming $X_1+X_2=2X$. But then again I don't have the answer for some reason. $\frac{1}{4}(2)Var(X)+20=Var(X)$ $\frac{1}{2}Var(X)+20=Var(X)$ $\frac{1}{2}Var(X)=20$ $Var(X)=40$ And so the standard deviation would be $\sqrt{40}$. But apparently the answer is 68.3g. Anybody know what I did wrong?",,['statistics']
11,hypothesis testing using conditional distribution,hypothesis testing using conditional distribution,,"Let $X_1 \sim \operatorname{Geo}(p_1)$ and $X_2 \sim \operatorname{Geo}(p_2)$ be independent random variables, where $\operatorname{Geo}(p)$ refers to the Geometric distribution whose p.m.f. $f$ is given by $$f(k) = p(1−p)^k,\qquad\qquad k = 0,1,\ldots$$ What is the conditional distribution of $X_1\mid X_1+X_2=y$, assuming $p_1=p_2$ Here is how I proceeded :- $$P(X_1=t\mid X_1+X_2=y) \Rightarrow \frac{P(X_1=t \cap X_1+X_2=y)}{P(X_1+X_2=y)} \Rightarrow \frac{P(X_1+X_2=y\mid X_1=t)\cdot P(X_1=t)}{P(X_1 + X_2=y)}$$ $$\Rightarrow \frac{P(X_2=y-t)\cdot P(X_1=t)}{P( X_1+X_2=y)}$$ Now we know that $X_1+X_2 \sim \operatorname{NegativeBinomial}(y,2)= {y+2-1 \choose {2-1}} p^2(1-p)^y = (y+1)p^2(1-p)^y$ $$\therefore\quad \Rightarrow \frac{P(X_2=y-t)\cdot P(X_1=t)}{P( X_1+X_2=y)} \Rightarrow \frac{p^2(1-p)^y}{(y+1)p^2(1-p)^y}=\frac 1 {y+1}$$ To test $H_0 : p_1 = p_2 \text{ against the alternative } H_1 : p_1 < p_2. $ Based on the result obtained in (a), derive a level 0.05 test for $H_0$ against $H_1$ that rejects $H_0$ when $X_1$ is large. Any idea about how to do this problem. I know how to use likelihood ratios to derive test statistic , but in this case the test statistic does not depend on either $p_1 \text{ or } p_2$.","Let $X_1 \sim \operatorname{Geo}(p_1)$ and $X_2 \sim \operatorname{Geo}(p_2)$ be independent random variables, where $\operatorname{Geo}(p)$ refers to the Geometric distribution whose p.m.f. $f$ is given by $$f(k) = p(1−p)^k,\qquad\qquad k = 0,1,\ldots$$ What is the conditional distribution of $X_1\mid X_1+X_2=y$, assuming $p_1=p_2$ Here is how I proceeded :- $$P(X_1=t\mid X_1+X_2=y) \Rightarrow \frac{P(X_1=t \cap X_1+X_2=y)}{P(X_1+X_2=y)} \Rightarrow \frac{P(X_1+X_2=y\mid X_1=t)\cdot P(X_1=t)}{P(X_1 + X_2=y)}$$ $$\Rightarrow \frac{P(X_2=y-t)\cdot P(X_1=t)}{P( X_1+X_2=y)}$$ Now we know that $X_1+X_2 \sim \operatorname{NegativeBinomial}(y,2)= {y+2-1 \choose {2-1}} p^2(1-p)^y = (y+1)p^2(1-p)^y$ $$\therefore\quad \Rightarrow \frac{P(X_2=y-t)\cdot P(X_1=t)}{P( X_1+X_2=y)} \Rightarrow \frac{p^2(1-p)^y}{(y+1)p^2(1-p)^y}=\frac 1 {y+1}$$ To test $H_0 : p_1 = p_2 \text{ against the alternative } H_1 : p_1 < p_2. $ Based on the result obtained in (a), derive a level 0.05 test for $H_0$ against $H_1$ that rejects $H_0$ when $X_1$ is large. Any idea about how to do this problem. I know how to use likelihood ratios to derive test statistic , but in this case the test statistic does not depend on either $p_1 \text{ or } p_2$.",,"['probability', 'statistics']"
12,Break down Simple Moving Average formula,Break down Simple Moving Average formula,,"I am new to Mathematics and understanding formulas - I'm currently trying to break down the Simple Moving Average formula  from  Wikipedia but struggling. I understand in practice how to calculate it, but I am struggling to really grasp an understanding of the formula below: $\displaystyle\overline p_{\displaystyle{SM}}=\frac{p_{\displaystyle{M}}+p_{\displaystyle{M}-1}+\cdots+p_{\displaystyle{M}-\displaystyle(n-1)}}{n}=\frac{1}{n}\sum_{i=0}^{n-1}p_{\displaystyle{M}}-i$ Could somebody break this formula  down for me and explain it piece by piece?  Preferably in both English and Math so I can piece the two together.","I am new to Mathematics and understanding formulas - I'm currently trying to break down the Simple Moving Average formula  from  Wikipedia but struggling. I understand in practice how to calculate it, but I am struggling to really grasp an understanding of the formula below: Could somebody break this formula  down for me and explain it piece by piece?  Preferably in both English and Math so I can piece the two together.",\displaystyle\overline p_{\displaystyle{SM}}=\frac{p_{\displaystyle{M}}+p_{\displaystyle{M}-1}+\cdots+p_{\displaystyle{M}-\displaystyle(n-1)}}{n}=\frac{1}{n}\sum_{i=0}^{n-1}p_{\displaystyle{M}}-i,['statistics']
13,moment of iid sums,moment of iid sums,,"Let Let $X_1,X_2,X_3,X_4$ be a sequence of independent, identically distributed random variables with: $$ E(X) = 0 $$ $$ E(X^2)=1$$ $$E(X^3) = 1$$ $$E(X^4) = 6 $$ Let: $$S_1 =X_1$$ $$S_2 =X_1+X_2$$ $$S_3 = X_1+X_2+X_3$$ and so on. Show that  $$\sum_{r=1}^{n} \frac{E(S_r^4)}{r^2(r+1)^2} = \frac{3n}{n+1}$$ Using central moments of iids I have found the 4th central moment of $S_n$ to be $$E(S_n^4) = n(6-3n^2)$$ putting this into the sum i have $$\sum_{r=1}^{n}\frac{r(6-3r^2)}{r^2(r+1)^2}$$ not really sure where to go from here in order to get the expression needed","Let Let $X_1,X_2,X_3,X_4$ be a sequence of independent, identically distributed random variables with: $$ E(X) = 0 $$ $$ E(X^2)=1$$ $$E(X^3) = 1$$ $$E(X^4) = 6 $$ Let: $$S_1 =X_1$$ $$S_2 =X_1+X_2$$ $$S_3 = X_1+X_2+X_3$$ and so on. Show that  $$\sum_{r=1}^{n} \frac{E(S_r^4)}{r^2(r+1)^2} = \frac{3n}{n+1}$$ Using central moments of iids I have found the 4th central moment of $S_n$ to be $$E(S_n^4) = n(6-3n^2)$$ putting this into the sum i have $$\sum_{r=1}^{n}\frac{r(6-3r^2)}{r^2(r+1)^2}$$ not really sure where to go from here in order to get the expression needed",,['statistics']
14,Maximum Likelihood Estimate with Multiple Parameters,Maximum Likelihood Estimate with Multiple Parameters,,"I am not very familiar with multivariable calculus, but something tells me that I don't need to be in order to solve this problem; take a look: Suppose that $X_1,...,X_m$ and $Y_1,...,Y_n$ are independent exponential random variables with $X_i\sim EXP(\lambda)$ and $Y_j\sim EXP(\theta \lambda)$ . Find the $MLE$ of $\lambda$ and $\theta$ . Finding the MLE of $\lambda$ is simple; by ignoring the $Y_j$ altogether and just looking at the $X_i$ , it turns out to be $\sum x_i/m$ .  However, for $\theta$ , I am no longer sure since the distribution of $Y_j$ is also dependent on $\lambda$ .  I don't know if I need to go as far as finding the gradient or if I can somehow use my previous result, but either way, I honestly don't know how to do it. Any advice would be appreciated.","I am not very familiar with multivariable calculus, but something tells me that I don't need to be in order to solve this problem; take a look: Suppose that and are independent exponential random variables with and . Find the of and . Finding the MLE of is simple; by ignoring the altogether and just looking at the , it turns out to be .  However, for , I am no longer sure since the distribution of is also dependent on .  I don't know if I need to go as far as finding the gradient or if I can somehow use my previous result, but either way, I honestly don't know how to do it. Any advice would be appreciated.","X_1,...,X_m Y_1,...,Y_n X_i\sim EXP(\lambda) Y_j\sim EXP(\theta \lambda) MLE \lambda \theta \lambda Y_j X_i \sum x_i/m \theta Y_j \lambda","['statistics', 'probability-distributions', 'statistical-inference', 'maximum-likelihood', 'parameter-estimation']"
15,Intuition behind the conditional distribution of sum of two Poisson random variables,Intuition behind the conditional distribution of sum of two Poisson random variables,,"Let $X$ and $Y$ be two independent random variables, where $X\sim \operatorname{Pois}(\lambda_1)$ and $Y\sim \operatorname{Pois}(\lambda_2)$. It's fairly straightforward to show mathematically that $$P(X=x\mid X+Y=n) = \binom n x \left(\frac{\lambda_1}{\lambda_1+\lambda_2}\right)^x \left(\frac{\lambda_2}{\lambda_1+\lambda_2}\right)^{n-x},$$ which shows that given $X+Y=n$, $X\sim \operatorname{Binom}\left(\frac{\lambda_1}{\lambda_1+\lambda_2},n\right)$. Is there any intuitive way to understand this result in terms of Poisson point processes, or is this simply a convenient mathematical property?","Let $X$ and $Y$ be two independent random variables, where $X\sim \operatorname{Pois}(\lambda_1)$ and $Y\sim \operatorname{Pois}(\lambda_2)$. It's fairly straightforward to show mathematically that $$P(X=x\mid X+Y=n) = \binom n x \left(\frac{\lambda_1}{\lambda_1+\lambda_2}\right)^x \left(\frac{\lambda_2}{\lambda_1+\lambda_2}\right)^{n-x},$$ which shows that given $X+Y=n$, $X\sim \operatorname{Binom}\left(\frac{\lambda_1}{\lambda_1+\lambda_2},n\right)$. Is there any intuitive way to understand this result in terms of Poisson point processes, or is this simply a convenient mathematical property?",,"['probability', 'statistics', 'probability-distributions']"
16,Odds of winning a superlottery,Odds of winning a superlottery,,"The problem: There's a lottery (or a ""superlottery"", I'm not really sure how that's different). In order to play, I select 8 numbers from the first 90 positive integers (so, 1-90 inclusive). Also, a computer selects 12 numbers from the first 90 positive integers. If all of my 8 numbers are in the set of 12 selected by the computer, I win. Assuming all numbers are randomly selected, what are the odds of winning? My solution: Once the computer has chosen its 12 numbers, there are $\binom{12}{8}$ ways for me to pick a winning set of numbers, and $\binom{90}{8}$ ways to pick a set of 8 numbers overall. So, the odds of winning are $\frac{\binom{12}{8}}{\binom{90}{8}}=\frac{1}{156597013}\approx6.38*10^{-9}$. My friend's solution: There are $\binom{12}{8}$ ways to choose winning numbers. The odds of the first number matching are $\frac{12}{90}$, the odds of the second number matching are $\frac{11}{89}$, and so on. So the odds of all the numbers matching are $\binom{12}{8}*\frac{12}{90}*...*\frac{5}{83}=\frac{495}{156597013}\approx2.107*10^{-6}$. Which of us is right (if either), and what mistake is the other person making?","The problem: There's a lottery (or a ""superlottery"", I'm not really sure how that's different). In order to play, I select 8 numbers from the first 90 positive integers (so, 1-90 inclusive). Also, a computer selects 12 numbers from the first 90 positive integers. If all of my 8 numbers are in the set of 12 selected by the computer, I win. Assuming all numbers are randomly selected, what are the odds of winning? My solution: Once the computer has chosen its 12 numbers, there are $\binom{12}{8}$ ways for me to pick a winning set of numbers, and $\binom{90}{8}$ ways to pick a set of 8 numbers overall. So, the odds of winning are $\frac{\binom{12}{8}}{\binom{90}{8}}=\frac{1}{156597013}\approx6.38*10^{-9}$. My friend's solution: There are $\binom{12}{8}$ ways to choose winning numbers. The odds of the first number matching are $\frac{12}{90}$, the odds of the second number matching are $\frac{11}{89}$, and so on. So the odds of all the numbers matching are $\binom{12}{8}*\frac{12}{90}*...*\frac{5}{83}=\frac{495}{156597013}\approx2.107*10^{-6}$. Which of us is right (if either), and what mistake is the other person making?",,"['probability', 'statistics', 'discrete-mathematics', 'combinations']"
17,Determine if an Estimator is Biased (Unusual Expectation Expression),Determine if an Estimator is Biased (Unusual Expectation Expression),,"Let $X_1, X_2, \ldots, X_n$ be i.i.d. with a common density function: $$f(x;\theta)=\theta x^{\theta-1}$$ for $0<x<1$ and $\theta>0$.  So this is $\operatorname{BETA}(\theta,1)$ distribution. Given this Maximum Likelihood Estimator (MLE) for $\theta$:  $$\hat \theta=\frac{-n}{\sum_{i=1}^n \ln(X_i)}$$ Determine if $\hat\theta$ is biased.  If it is biased, could you redefine it to make it unbiased? Unfortunately, this is where I get stuck; I have no idea how to evaluate the expectation of $\hat\theta$. $$\operatorname E\left( \frac{-n}{\sum_{i=1}^n \ln(X_i)} \right)$$ How does one calculate this?","Let $X_1, X_2, \ldots, X_n$ be i.i.d. with a common density function: $$f(x;\theta)=\theta x^{\theta-1}$$ for $0<x<1$ and $\theta>0$.  So this is $\operatorname{BETA}(\theta,1)$ distribution. Given this Maximum Likelihood Estimator (MLE) for $\theta$:  $$\hat \theta=\frac{-n}{\sum_{i=1}^n \ln(X_i)}$$ Determine if $\hat\theta$ is biased.  If it is biased, could you redefine it to make it unbiased? Unfortunately, this is where I get stuck; I have no idea how to evaluate the expectation of $\hat\theta$. $$\operatorname E\left( \frac{-n}{\sum_{i=1}^n \ln(X_i)} \right)$$ How does one calculate this?",,"['probability', 'statistics', 'probability-distributions', 'expected-value']"
18,"Compute a measure of ""near multiplicity"" from a list of noisy values","Compute a measure of ""near multiplicity"" from a list of noisy values",,"Question I posted this question on StackOverflow before but someone advised me to ask it there because it looks like a numerical algorithm problem. Let us say I've got a list of values which have a common multiple greater than 1. For example, let us take the multiple to be 3 and form a collection of multiples of this value: harmonicList = [3,6,6,3,3,9,27,3,15,18,9] Now I add some noise: harmonicList = [ v + (random() * 2 - 1 ) * 0.1 for v in harmonicList] I'm searching for an algorithm that will return a number near 1.0 when the items in the list are near to being multiples of a common value but near 0.0 when the numbers are not near to being multiples -- such as, for example when the list is a collection of prime numbers. Is there such a measure of ""near multiplicity""? Why I want to solve this problem I'm currently trying to detect Chessboard in a screenshot using Hough Transform. Sometimes the case is ideal, and it works very well : But sometimes not : I would like to detect the cases where there is a lot of aberrations. Thus, my idea is to compute the intersections of the lines detected, and create a collection of length  (only if the lines where horizontal or vertical). If the detection was good, I know that there will be a great ""harmonicity"" inside this collection I can then use that algorithm and a threshold.","Question I posted this question on StackOverflow before but someone advised me to ask it there because it looks like a numerical algorithm problem. Let us say I've got a list of values which have a common multiple greater than 1. For example, let us take the multiple to be 3 and form a collection of multiples of this value: harmonicList = [3,6,6,3,3,9,27,3,15,18,9] Now I add some noise: harmonicList = [ v + (random() * 2 - 1 ) * 0.1 for v in harmonicList] I'm searching for an algorithm that will return a number near 1.0 when the items in the list are near to being multiples of a common value but near 0.0 when the numbers are not near to being multiples -- such as, for example when the list is a collection of prime numbers. Is there such a measure of ""near multiplicity""? Why I want to solve this problem I'm currently trying to detect Chessboard in a screenshot using Hough Transform. Sometimes the case is ideal, and it works very well : But sometimes not : I would like to detect the cases where there is a lot of aberrations. Thus, my idea is to compute the intersections of the lines detected, and create a collection of length  (only if the lines where horizontal or vertical). If the detection was good, I know that there will be a great ""harmonicity"" inside this collection I can then use that algorithm and a threshold.",,['statistics']
19,Limit of chi square distribution.,Limit of chi square distribution.,,Question in my exercise is written as $$\lim_{n \to \infty}\bigg(\dfrac{1}{2^{\frac{n}{2}}\Gamma{\frac{n}{2}}}\int_{n+\sqrt{2n}}^{\infty}e^{\frac{-t}{2}}t^{\frac{n}{2}-1}dt\bigg)$$ equals : $(A)=.5$ $(B)=0$ $(C)=.0228$ $(D)=.1587$ As sample size increase chi square approaches normal distribution.(I am not sure if i wrote this statement correct so please correct me and give me little explanation on that). Using this fact i calculated $P(X>n-\sqrt{2n}) = \Phi(-1) = .1587$. Did i do everything correct using this intuition ?,Question in my exercise is written as $$\lim_{n \to \infty}\bigg(\dfrac{1}{2^{\frac{n}{2}}\Gamma{\frac{n}{2}}}\int_{n+\sqrt{2n}}^{\infty}e^{\frac{-t}{2}}t^{\frac{n}{2}-1}dt\bigg)$$ equals : $(A)=.5$ $(B)=0$ $(C)=.0228$ $(D)=.1587$ As sample size increase chi square approaches normal distribution.(I am not sure if i wrote this statement correct so please correct me and give me little explanation on that). Using this fact i calculated $P(X>n-\sqrt{2n}) = \Phi(-1) = .1587$. Did i do everything correct using this intuition ?,,"['statistics', 'probability-distributions', 'statistical-inference', 'sampling', 'chi-squared']"
20,Derive a sufficient statistic for $\theta$.,Derive a sufficient statistic for .,\theta,"Exercise: Suppose that $X = X_1,\ldots,X_n$ are i.i.d. random variables with the $\operatorname{Ber}(\theta)$ distribution. Derive a sufficient statistic for $\theta$. What I've tried: I know that by the Factorisation theorem $T(X)$ is a sufficient statistic if the likelihood function of $X$ can be written as $$f_X(X\mid\theta) = g_\theta(T(X))h(X)$$ where $h$ and $g_\theta$ are nonnegative Borel functions. So I've chosen to rewrite the likelihood function in the form of the factorisation theorem: $$f_X(X\mid\theta) = \prod_{i = 1}^n\theta^{x_i}(1-\theta)^{1-x_i} = \theta^{\sum_{i =1}^nx_i}(1-\theta)^{\sum_{i = 1}^n(1-x_i)}$$ However, I don't know how to proceed from here, as I can't see how this would been rewritten to the form used in the factorisation theorem. Question: How do I solve this exercise? (Preferably with the factorisation theorem) Thanks!","Exercise: Suppose that $X = X_1,\ldots,X_n$ are i.i.d. random variables with the $\operatorname{Ber}(\theta)$ distribution. Derive a sufficient statistic for $\theta$. What I've tried: I know that by the Factorisation theorem $T(X)$ is a sufficient statistic if the likelihood function of $X$ can be written as $$f_X(X\mid\theta) = g_\theta(T(X))h(X)$$ where $h$ and $g_\theta$ are nonnegative Borel functions. So I've chosen to rewrite the likelihood function in the form of the factorisation theorem: $$f_X(X\mid\theta) = \prod_{i = 1}^n\theta^{x_i}(1-\theta)^{1-x_i} = \theta^{\sum_{i =1}^nx_i}(1-\theta)^{\sum_{i = 1}^n(1-x_i)}$$ However, I don't know how to proceed from here, as I can't see how this would been rewritten to the form used in the factorisation theorem. Question: How do I solve this exercise? (Preferably with the factorisation theorem) Thanks!",,"['statistics', 'probability-distributions', 'statistical-inference']"
21,Probability that two random numbers have a Sørensen-Dice coefficient over a given threshold,Probability that two random numbers have a Sørensen-Dice coefficient over a given threshold,,"The following problem came up at work and my probability knowledge isn't up to the task. Let $a, b \in \mathbb{Z}_{2^n}$ be two $n$ bit integers. Their Sørensen-Dice coefficient is the quantity $$ DS(a, b) = \frac{2|a \wedge b|}{|a| + |b|} $$ where $|a|$ denotes the population count of $a$ (number of 1 bits) and $a\wedge b$ is bitwise AND. I would like to know: Given $t \in [0, 1]$, what is the probability that $DS(a, b) \ge t$ for $a, b$ drawn uniformly at random from $\mathbb{Z}_{2^n}$? Call this probability $P_n(t)$.  Experimentally this probability appears to have the form $$P_n(t) = \frac{1}{1 + 2^{\alpha(t - 1/2)}}$$ where $\alpha$ is some function of $n$. I expect this to be the form of the final answer, albeit with a more precise description of $\alpha$. Edit: In practice $n$ is 1024 or, more generally, some even power of 512 (I expect the result to hold for general $n$, but maybe that case is easier to handle as a first step). I would like to be better at solving these kinds of problems, so I will gratefully accept any recommendations for further reading too.","The following problem came up at work and my probability knowledge isn't up to the task. Let $a, b \in \mathbb{Z}_{2^n}$ be two $n$ bit integers. Their Sørensen-Dice coefficient is the quantity $$ DS(a, b) = \frac{2|a \wedge b|}{|a| + |b|} $$ where $|a|$ denotes the population count of $a$ (number of 1 bits) and $a\wedge b$ is bitwise AND. I would like to know: Given $t \in [0, 1]$, what is the probability that $DS(a, b) \ge t$ for $a, b$ drawn uniformly at random from $\mathbb{Z}_{2^n}$? Call this probability $P_n(t)$.  Experimentally this probability appears to have the form $$P_n(t) = \frac{1}{1 + 2^{\alpha(t - 1/2)}}$$ where $\alpha$ is some function of $n$. I expect this to be the form of the final answer, albeit with a more precise description of $\alpha$. Edit: In practice $n$ is 1024 or, more generally, some even power of 512 (I expect the result to hold for general $n$, but maybe that case is easier to handle as a first step). I would like to be better at solving these kinds of problems, so I will gratefully accept any recommendations for further reading too.",,"['probability', 'statistics', 'book-recommendation', 'elementary-probability']"
22,The sequence $\{X_n\}$ obeys weak law of large numbers if,The sequence  obeys weak law of large numbers if,\{X_n\},"Let $\{X_n\}$ is a sequence of independent random variables with  $P\{X_n=\pm n^\alpha\}=\frac{1}{2}$, $n=1,2,\cdots$. The sequence $\{X_n\}$ obeys weak law of large numbers if 1) $\alpha <1/2$ 2) $\alpha =1/2$ 3) $1/2<\alpha \leq 1$ 4) $\alpha >1$ I find $E(S_n)=0, Var(X_n)=n^{2 \alpha}$ and I have to show $\frac{E(S_n^2)}{n^2}$ tend to zero as $n \rightarrow \infty$ for satisfying WLLN. So $\frac{E(S_n^2)}{n^2}=\frac{Var(S_n)}{n^2}=\frac{1}{n^2}\sum_{i=1} ^n Var(X_i)$ after that how to handle to find the condition on $\alpha$, Please help.","Let $\{X_n\}$ is a sequence of independent random variables with  $P\{X_n=\pm n^\alpha\}=\frac{1}{2}$, $n=1,2,\cdots$. The sequence $\{X_n\}$ obeys weak law of large numbers if 1) $\alpha <1/2$ 2) $\alpha =1/2$ 3) $1/2<\alpha \leq 1$ 4) $\alpha >1$ I find $E(S_n)=0, Var(X_n)=n^{2 \alpha}$ and I have to show $\frac{E(S_n^2)}{n^2}$ tend to zero as $n \rightarrow \infty$ for satisfying WLLN. So $\frac{E(S_n^2)}{n^2}=\frac{Var(S_n)}{n^2}=\frac{1}{n^2}\sum_{i=1} ^n Var(X_i)$ after that how to handle to find the condition on $\alpha$, Please help.",,"['probability', 'statistics', 'law-of-large-numbers']"
23,Concentration inequality for i.i.d. negative multinomial variables,Concentration inequality for i.i.d. negative multinomial variables,,"Let $\mathbf p=(p_0,p_1,\cdots,p_m)$ be a probability vector, such that $p_0+p_1+\cdots+p_m=1$. Let $X_1,X_2,\cdots$ be i.i.d. random variables distributed according to the categorical distribution parameterized by $\mathbf p$, meaning that $\Pr[X_i=j] = p_j$ for $j=1,\cdots,m$. Let $k$ be the first $X_k$ such that $X_k=0$. I'm interested in the random variable $Z := \sum_{i=1}^k{\mathbb I[X_i]=1}$. Namely, this is the number of occurreces of item 1 until $X_k=0$. It follows a negative multinomial distribution : https://en.wikipedia.org/wiki/Negative_multinomial_distribution What I'm interested is the following question: Let $Z_1,\cdots,Z_n$ be i.i.d. random variables defined in the above manner. How can we derive an upper bound of the tail probability   $$ \Pr\left[\left|\frac{1}{n}\sum_{i=1}^n{Z_i} - \mathbb EZ\right| > t\right]? $$","Let $\mathbf p=(p_0,p_1,\cdots,p_m)$ be a probability vector, such that $p_0+p_1+\cdots+p_m=1$. Let $X_1,X_2,\cdots$ be i.i.d. random variables distributed according to the categorical distribution parameterized by $\mathbf p$, meaning that $\Pr[X_i=j] = p_j$ for $j=1,\cdots,m$. Let $k$ be the first $X_k$ such that $X_k=0$. I'm interested in the random variable $Z := \sum_{i=1}^k{\mathbb I[X_i]=1}$. Namely, this is the number of occurreces of item 1 until $X_k=0$. It follows a negative multinomial distribution : https://en.wikipedia.org/wiki/Negative_multinomial_distribution What I'm interested is the following question: Let $Z_1,\cdots,Z_n$ be i.i.d. random variables defined in the above manner. How can we derive an upper bound of the tail probability   $$ \Pr\left[\left|\frac{1}{n}\sum_{i=1}^n{Z_i} - \mathbb EZ\right| > t\right]? $$",,"['probability', 'statistics', 'negative-binomial', 'concentration-of-measure', 'distribution-tails']"
24,How to find the closed form formula for $\hat{\beta}$ while using ordinary least squares estimation?,How to find the closed form formula for  while using ordinary least squares estimation?,\hat{\beta},"According to Wikipedia's article on Linear Regression : Given a data set $\{y_i,x_{i1},\ldots,x_{ip}\}_{i=1}^{i=n}$ of $n$   statistical units, a regression model assumes that the relationship   between the dependent variable $y_i$ and the $p-\text{vector}$ or   regressors $x_i$ is linear. This relationship is modelled through a   disturbance term or error variable $\varepsilon_i$-an unobserved random   variable that adds random noise to the to the linear relationship   between the dependent variables and regressors. The model takes the   form   $y_i=\beta_0(1)+\beta_1x_{i1}+\cdots+\beta_px_{ip}+\epsilon_i=x_i^T \beta + \varepsilon_i$ These equations can be written in vector form as $$y=\mathbf{X\beta+\epsilon}$$ For the Ordinary Least Square estimation they say that the closed form expression for the estimated value of the unknown parameter $\beta$ is $$\hat{\mathbf{\beta}}=(\mathbf{X^{T}X})^{-1}\mathbf{X}^{T}y$$ I'm not sure how they get this formula for $\hat{\beta}$. It would be very nice if someone can explain me the derivation.","According to Wikipedia's article on Linear Regression : Given a data set $\{y_i,x_{i1},\ldots,x_{ip}\}_{i=1}^{i=n}$ of $n$   statistical units, a regression model assumes that the relationship   between the dependent variable $y_i$ and the $p-\text{vector}$ or   regressors $x_i$ is linear. This relationship is modelled through a   disturbance term or error variable $\varepsilon_i$-an unobserved random   variable that adds random noise to the to the linear relationship   between the dependent variables and regressors. The model takes the   form   $y_i=\beta_0(1)+\beta_1x_{i1}+\cdots+\beta_px_{ip}+\epsilon_i=x_i^T \beta + \varepsilon_i$ These equations can be written in vector form as $$y=\mathbf{X\beta+\epsilon}$$ For the Ordinary Least Square estimation they say that the closed form expression for the estimated value of the unknown parameter $\beta$ is $$\hat{\mathbf{\beta}}=(\mathbf{X^{T}X})^{-1}\mathbf{X}^{T}y$$ I'm not sure how they get this formula for $\hat{\beta}$. It would be very nice if someone can explain me the derivation.",,"['calculus', 'linear-algebra']"
25,Is my understanding of Likelihood Ratio Tests and Likelihood Functions correct?,Is my understanding of Likelihood Ratio Tests and Likelihood Functions correct?,,"I'm trying to understand Likelihood Ratio Tests, Likelihood Functions and Hypotheses Tests, which makes up a significant amount of what we're supposed to learn in my statistics for beginners course. But I'm very new to this level of maths, so a lot of the rigorous knowledge and intuitive understanding is unfortunately missing for me; my apologies then for the length of the post from my over explaining some things. I was wondering if you could tell me from my summation if my understanding of these processes is correct/where I've gone wrong? My understanding so far: Imagine you have collected a sample of data from some population; say you know the type of distribution that models the population, but you are unsure of the value of one of the parameters. So you construct a Likelihood Function, and work out the value of your parameter $\theta$ that maximises the probability of your sample data under that distribution. And you do this by taking the (Log) Likelihood Function, differentiating and setting equal to zero, then solving for $\theta$. I.e. if you were to graph 'Probability of your sample occurring' on the Y-axis vs the potential values of your parameter $\theta$ on X-axis, you would be finding the $\theta$ that maximises this function on your graph. So now comes Likelihood Ratio Tests. As I understand it so far, the purpose of an LRT is to workout whether the parameter you've identified as maximising is better than some null-hypothesis parameter, by a statistically significant level. Otherwise without doing an LRT, it might be that your proposed maximising $\theta$ was only marginally better, and maybe only for this sample, than the null value due to something like sampling error, yet you thought it was definitively better. Now if I understand Null Hypotheses Tests right, in the case where your null hyp is rejected, the test doesn't then specifically tell you which other hyp is the actual true one, a hypothesis test just tells you whether or not the null-hyp is true or not (if it's not true though, you know the true hypothesis will be a member of the null's complement). Then, let: $H_0 = {}$'$\theta_\text{Null-Hyp}$ is the value of the parameter that maximises your Likelihood Function.' $H_1 = {}$'$\theta_\text{Null-Hyp}$ is not the maximising value (and thus the max value $\theta \in \Theta_\text{Alt-Hyp}$, where $\Theta_\text{Alt-Hyp} = \theta_\text{Null-Hyp}^c)$.' $L(\theta) = {}$Likelihood Function with $\theta$ as your maximising parameter. The Likelihood Ratio is then: $$\frac{L(\theta_\text{Null-Hyp})}{L(\Theta_\text{Alt-Hyp})} \leqslant K$$ So, constructing your LRT: when setting up your LRT you first pick the confidence lvl (say 95%) you want. Then you work out the K that corresponds to this confidence lvl (more on this later). Now for every $\theta$ $\in$ $\Theta_\text{Alt-Hyp}$, s.t. the ratio is $\leqslant K$, you can say with 95% confidence that these $\theta$ output, by a statistically significant amount, a higher value for the Likelihood Function than $\theta_\text{Null-Hyp}$. So you reject the null hypothesis. And of course, you already knew the $\theta \in \Theta_\text{Alt-Hyp}$ that maximises the Likelihood Function, but now you're very confident this value wasn't produced from your sample erroneously, e.g. from things like sampling error, etc. That's my summation of the process, which I thought was approximately right - though please let me know where I've gone wrong. However, it's in the the process of the below example that I am most confused. In this example about honey pots, https://onlinecourses.science.psu.edu/stat414/node/309 the author is trying to find the mean weight of the population from a sample of pots. They construct an LRT with an (as far as I understand it) arbitrarily chosen value for the $H_0$ pop mean of $\theta_\text{Null-Hyp} = 10,$ and Sig Lvl of $\alpha = 0.05.$ Their variable for $\theta_\text{Alt-Hyp}$ is $\bar X$. The author takes the Likelihood Ratio, manipulates the algebra, and arrives at the equation: $$Z= \frac{\bar X-10}{\sigma / \sqrt n} = f(K) $$ From this they look up the Z statistic for $\alpha = 0.05$ to say that $f(K) = 1.96.$ They then find the inverse of $f(K)$ to find their value of $K.$ Here's why I'm confused. If in the end they use the Z-Statistic to calculate their value of K, why don't they just skip straight to calculating the Z-stat in the first place, instead of doing the LRT? If they work to make sure they can input $\bar X$ into the Z-stat to be able to decide whether to reject $H_0$, why do they then continue with the LRT, or use it in the first place? On top of this, what determines what value you should choose for the null hypothesis? Clearly I'm missing something in my understanding (as well as any holes in my explanations above), so if anyone could fill in my knowledge gaps I'd really appreciate it. I apologise that this is such a long post, thanks for your time so far. Any help you could offer would be greatly appreciated. Cheers","I'm trying to understand Likelihood Ratio Tests, Likelihood Functions and Hypotheses Tests, which makes up a significant amount of what we're supposed to learn in my statistics for beginners course. But I'm very new to this level of maths, so a lot of the rigorous knowledge and intuitive understanding is unfortunately missing for me; my apologies then for the length of the post from my over explaining some things. I was wondering if you could tell me from my summation if my understanding of these processes is correct/where I've gone wrong? My understanding so far: Imagine you have collected a sample of data from some population; say you know the type of distribution that models the population, but you are unsure of the value of one of the parameters. So you construct a Likelihood Function, and work out the value of your parameter $\theta$ that maximises the probability of your sample data under that distribution. And you do this by taking the (Log) Likelihood Function, differentiating and setting equal to zero, then solving for $\theta$. I.e. if you were to graph 'Probability of your sample occurring' on the Y-axis vs the potential values of your parameter $\theta$ on X-axis, you would be finding the $\theta$ that maximises this function on your graph. So now comes Likelihood Ratio Tests. As I understand it so far, the purpose of an LRT is to workout whether the parameter you've identified as maximising is better than some null-hypothesis parameter, by a statistically significant level. Otherwise without doing an LRT, it might be that your proposed maximising $\theta$ was only marginally better, and maybe only for this sample, than the null value due to something like sampling error, yet you thought it was definitively better. Now if I understand Null Hypotheses Tests right, in the case where your null hyp is rejected, the test doesn't then specifically tell you which other hyp is the actual true one, a hypothesis test just tells you whether or not the null-hyp is true or not (if it's not true though, you know the true hypothesis will be a member of the null's complement). Then, let: $H_0 = {}$'$\theta_\text{Null-Hyp}$ is the value of the parameter that maximises your Likelihood Function.' $H_1 = {}$'$\theta_\text{Null-Hyp}$ is not the maximising value (and thus the max value $\theta \in \Theta_\text{Alt-Hyp}$, where $\Theta_\text{Alt-Hyp} = \theta_\text{Null-Hyp}^c)$.' $L(\theta) = {}$Likelihood Function with $\theta$ as your maximising parameter. The Likelihood Ratio is then: $$\frac{L(\theta_\text{Null-Hyp})}{L(\Theta_\text{Alt-Hyp})} \leqslant K$$ So, constructing your LRT: when setting up your LRT you first pick the confidence lvl (say 95%) you want. Then you work out the K that corresponds to this confidence lvl (more on this later). Now for every $\theta$ $\in$ $\Theta_\text{Alt-Hyp}$, s.t. the ratio is $\leqslant K$, you can say with 95% confidence that these $\theta$ output, by a statistically significant amount, a higher value for the Likelihood Function than $\theta_\text{Null-Hyp}$. So you reject the null hypothesis. And of course, you already knew the $\theta \in \Theta_\text{Alt-Hyp}$ that maximises the Likelihood Function, but now you're very confident this value wasn't produced from your sample erroneously, e.g. from things like sampling error, etc. That's my summation of the process, which I thought was approximately right - though please let me know where I've gone wrong. However, it's in the the process of the below example that I am most confused. In this example about honey pots, https://onlinecourses.science.psu.edu/stat414/node/309 the author is trying to find the mean weight of the population from a sample of pots. They construct an LRT with an (as far as I understand it) arbitrarily chosen value for the $H_0$ pop mean of $\theta_\text{Null-Hyp} = 10,$ and Sig Lvl of $\alpha = 0.05.$ Their variable for $\theta_\text{Alt-Hyp}$ is $\bar X$. The author takes the Likelihood Ratio, manipulates the algebra, and arrives at the equation: $$Z= \frac{\bar X-10}{\sigma / \sqrt n} = f(K) $$ From this they look up the Z statistic for $\alpha = 0.05$ to say that $f(K) = 1.96.$ They then find the inverse of $f(K)$ to find their value of $K.$ Here's why I'm confused. If in the end they use the Z-Statistic to calculate their value of K, why don't they just skip straight to calculating the Z-stat in the first place, instead of doing the LRT? If they work to make sure they can input $\bar X$ into the Z-stat to be able to decide whether to reject $H_0$, why do they then continue with the LRT, or use it in the first place? On top of this, what determines what value you should choose for the null hypothesis? Clearly I'm missing something in my understanding (as well as any holes in my explanations above), so if anyone could fill in my knowledge gaps I'd really appreciate it. I apologise that this is such a long post, thanks for your time so far. Any help you could offer would be greatly appreciated. Cheers",,"['statistics', 'order-statistics', 'descriptive-statistics']"
26,Regression Analysis (Line of Best Fit) for Categorical Variables,Regression Analysis (Line of Best Fit) for Categorical Variables,,"Brief Background/Motivation: I am looking at an Income vs. Education table that is adapted from a dissertation and was used in developing a curriculum in a social justice mathematics program. In the dissertation, the author discusses using these data (income vs. education level, broken down by gender) to have students create a line of best fit , but does not explain how the categorical variable is treated or transformed into an ordinal variable. The issue, as I see it, is that education level is categorical and not continuous; I have been unable to find a ""standard"" or even suggested approach regarding how to treat the categorical variable. I see two different ways: Starting at 1, label each category 1-7. This assumes a uniform/linear step size (i.e., the difference between some high school and completing high school is the same as the difference between a master's degree and a doctorate) which is clearly problematic, but one possibility. Approximate the number of years of schooling for each category. For example, ""high school completion"" would be 13, bachelor's degree would be 17, masters would be anything from 18 to 19, etc. Then you have to make some decisions about categories such as ""some high school"": is this a 10, 11 or 12? Also, how should you count the category of ""no high school""?  Is this a 7 or 8 or 9?  This is also clearly subjective and has its own problematics, but is actually roughly the same as (1). Question: Do either of the two approaches suggested above work? Or is there another, better way to treat these data? Pointers to relevant papers or resources would be welcome, too.","Brief Background/Motivation: I am looking at an Income vs. Education table that is adapted from a dissertation and was used in developing a curriculum in a social justice mathematics program. In the dissertation, the author discusses using these data (income vs. education level, broken down by gender) to have students create a line of best fit , but does not explain how the categorical variable is treated or transformed into an ordinal variable. The issue, as I see it, is that education level is categorical and not continuous; I have been unable to find a ""standard"" or even suggested approach regarding how to treat the categorical variable. I see two different ways: Starting at 1, label each category 1-7. This assumes a uniform/linear step size (i.e., the difference between some high school and completing high school is the same as the difference between a master's degree and a doctorate) which is clearly problematic, but one possibility. Approximate the number of years of schooling for each category. For example, ""high school completion"" would be 13, bachelor's degree would be 17, masters would be anything from 18 to 19, etc. Then you have to make some decisions about categories such as ""some high school"": is this a 10, 11 or 12? Also, how should you count the category of ""no high school""?  Is this a 7 or 8 or 9?  This is also clearly subjective and has its own problematics, but is actually roughly the same as (1). Question: Do either of the two approaches suggested above work? Or is there another, better way to treat these data? Pointers to relevant papers or resources would be welcome, too.",,"['statistics', 'reference-request', 'regression', 'linear-regression']"
27,Normal approximation of a mixture of normal distributions,Normal approximation of a mixture of normal distributions,,"I have noticed that sometimes mixtures of normal distributions can be approximated very well by a simple normal distribution. For instance, the mixture of the normal distributions $\mathcal{N}(0,1)$ and $\mathcal{N}(1,1)$ (with both distributions having a weight $w_i$ of 0.5) is well approximated by $\mathcal{N}(0.5,1.2544)$; the density functions of both distributions differ by about 0.004 or less over the whole continuum. My question is, under which conditions is such a normal approximation of a mixture of normal distributions possible?","I have noticed that sometimes mixtures of normal distributions can be approximated very well by a simple normal distribution. For instance, the mixture of the normal distributions $\mathcal{N}(0,1)$ and $\mathcal{N}(1,1)$ (with both distributions having a weight $w_i$ of 0.5) is well approximated by $\mathcal{N}(0.5,1.2544)$; the density functions of both distributions differ by about 0.004 or less over the whole continuum. My question is, under which conditions is such a normal approximation of a mixture of normal distributions possible?",,"['statistics', 'probability-distributions']"
28,Type I and II Errors,Type I and II Errors,,"Good evening, I am a little confused about type I errors. If you are given a population of students doing hypothesis tests for a certain condition at a certain significance level, is it possible to calculate: (a) how many students will fail to reject the null hypothesis given that the null hypothesis is false (b) how many students will reject the null hypothesis given that the null hypothesis is true. I have tried searching online but so far all sites only show how to calculate the probability that at least one type I error will be made. Any assistance will be greatly appreciated. Thanks!","Good evening, I am a little confused about type I errors. If you are given a population of students doing hypothesis tests for a certain condition at a certain significance level, is it possible to calculate: (a) how many students will fail to reject the null hypothesis given that the null hypothesis is false (b) how many students will reject the null hypothesis given that the null hypothesis is true. I have tried searching online but so far all sites only show how to calculate the probability that at least one type I error will be made. Any assistance will be greatly appreciated. Thanks!",,['statistics']
29,An Intuitive Understanding of Covariance,An Intuitive Understanding of Covariance,,"I'm trying to intuitively understand what it means for two random variables to have non-zero covariance. At the moment, I imagine that the two random variables (which have non-zero covariance) both depend (at least in part) on a common random variable, and this is why they have non-zero covariance. E.g., if $U$, $V$, $Z$ and $W$ are independent random variables, and $X_1 = \frac{U + V}{Z}$ and $X_2 = W + Z$, then since both $X_1$ and $X_2$ depend on $Z$, the two variables will have non-zero covariance. Is this a good way of intuitively thinking about covariance? If not, is there a better way which might help?","I'm trying to intuitively understand what it means for two random variables to have non-zero covariance. At the moment, I imagine that the two random variables (which have non-zero covariance) both depend (at least in part) on a common random variable, and this is why they have non-zero covariance. E.g., if $U$, $V$, $Z$ and $W$ are independent random variables, and $X_1 = \frac{U + V}{Z}$ and $X_2 = W + Z$, then since both $X_1$ and $X_2$ depend on $Z$, the two variables will have non-zero covariance. Is this a good way of intuitively thinking about covariance? If not, is there a better way which might help?",,"['statistics', 'intuition', 'covariance', 'correlation']"
30,Linear Fit when Data has Uncertainty,Linear Fit when Data has Uncertainty,,"I am attempting to find the slope and y-intercept (along with their uncertainty) from a set of data. In this case, I am graphing Gamma Energy (MeV) vs. Peak Centroid (Channel). Here is my data: Gamma Energy (MeV): 1.17, 1.33, 0.032, 0.662, 0.511, 1.275, 0.088 Peak Centroid (Channel): 622.65, 712, 21, 360.38, 280.64, 676.85, 18.68 Peak Centroid Uncertainty: 0.0342, 0.0347, 2, 0.0155, 0.0231, 0.0288, 0.1346 As can be seen, one Centroid Uncertainty value is significantly higher than the rest, so I cannot use a normal non-weighted least squares fit. I researched this a bit and found that I can use the formula $\left ( X^TWX \right )\hat{\beta }=X^TWy$ to solve for $\hat{\beta}$. Now, I know $y_{i}$ is simply each of my Gamma Energies. I also know $W_{ii}=\frac{1}{\sigma_{i}^2}$ where $\sigma_{i}$ corresponds to each of my Centroid Uncertainties. All other elements in $W$ are $0$. My issue is, I do not know how to contruct $X$. I have looked at various sources, and none of them really made sense to me. What exactly does each element correspond to, and how do I implement that in my case. When I find $\hat{\beta}$, won't this simply correspond to the $m$ and $b$ values in $y=mx+b$? How can I find the uncertainty in $m$ and $b$? Also, in my case, the uncertainties are in the x-values where (I think) the formula I am using assumes them to be in the y-values. Will this affect my results? As an aside, if I had errors in both x and y-values, how would I solve that?","I am attempting to find the slope and y-intercept (along with their uncertainty) from a set of data. In this case, I am graphing Gamma Energy (MeV) vs. Peak Centroid (Channel). Here is my data: Gamma Energy (MeV): 1.17, 1.33, 0.032, 0.662, 0.511, 1.275, 0.088 Peak Centroid (Channel): 622.65, 712, 21, 360.38, 280.64, 676.85, 18.68 Peak Centroid Uncertainty: 0.0342, 0.0347, 2, 0.0155, 0.0231, 0.0288, 0.1346 As can be seen, one Centroid Uncertainty value is significantly higher than the rest, so I cannot use a normal non-weighted least squares fit. I researched this a bit and found that I can use the formula $\left ( X^TWX \right )\hat{\beta }=X^TWy$ to solve for $\hat{\beta}$. Now, I know $y_{i}$ is simply each of my Gamma Energies. I also know $W_{ii}=\frac{1}{\sigma_{i}^2}$ where $\sigma_{i}$ corresponds to each of my Centroid Uncertainties. All other elements in $W$ are $0$. My issue is, I do not know how to contruct $X$. I have looked at various sources, and none of them really made sense to me. What exactly does each element correspond to, and how do I implement that in my case. When I find $\hat{\beta}$, won't this simply correspond to the $m$ and $b$ values in $y=mx+b$? How can I find the uncertainty in $m$ and $b$? Also, in my case, the uncertainties are in the x-values where (I think) the formula I am using assumes them to be in the y-values. Will this affect my results? As an aside, if I had errors in both x and y-values, how would I solve that?",,"['linear-algebra', 'statistics', 'linear-regression', 'weighted-least-squares']"
31,How do I find the expected return on a ticket?,How do I find the expected return on a ticket?,,"A lottery has a grand prize of 400,000 dollars, five runner up prizes of 50,000 dollars each, nine third-place prizes of 10000 dollars each, and twenty-five consolation prizes of 1000 dollars each. If 2,000,000 tickets are sold for 1 dollar each and the probability of any one ticket winning is the same as that of any other ticket winning, find the expected return on a $1 ticket. (Round your answer to two decimal places.) I tried  $$(400,000\times \frac {1}{2,000,000}) + (50,000\times \frac {5}{2,000,000}) + (10,000\times \frac {9}{2,000,000}) + (1,000\times \frac{25}{2,000,000})$$ and so on with each of the other prizes, getting .3825 then round it to .38 which was wrong. Please explain what I may have done wrong or show me what I would need to do instead. Thanks.","A lottery has a grand prize of 400,000 dollars, five runner up prizes of 50,000 dollars each, nine third-place prizes of 10000 dollars each, and twenty-five consolation prizes of 1000 dollars each. If 2,000,000 tickets are sold for 1 dollar each and the probability of any one ticket winning is the same as that of any other ticket winning, find the expected return on a $1 ticket. (Round your answer to two decimal places.) I tried  $$(400,000\times \frac {1}{2,000,000}) + (50,000\times \frac {5}{2,000,000}) + (10,000\times \frac {9}{2,000,000}) + (1,000\times \frac{25}{2,000,000})$$ and so on with each of the other prizes, getting .3825 then round it to .38 which was wrong. Please explain what I may have done wrong or show me what I would need to do instead. Thanks.",,"['statistics', 'central-tendency']"
32,Applying Karlin-Rubin,Applying Karlin-Rubin,,"I have trouble understanding how to apply Karlin-Rubin My situation: $X_1 ... X_5\sim Poisson(\lambda)$ independent. My hypothesis test is $$H_0: \lambda \leq 3$$ $$H_1: \lambda > 3$$ I checked that $\sum_i x_i$ is a sufficient MLR statistic for Poisson. Find a UMP level $\alpha = 0.05$ test. Complementary data: \begin{matrix} Observation: & 1 & 2 & 3 & 4 & 5 \\ Count:& 2 & 5 & 4 & 7 & 5 \end{matrix} Theorem: Consider testing $H_0:\theta \leq \theta_0$ vs. $H_1:\theta > \theta_0$ and consider $T$ to be a sufficient statistic for $\theta$ with MLR property on $\theta$. Then for any $t_0$, the test that rejects $H_0$ iff $T>t_0$ is a UMP level $\alpha$ test, where $\alpha = P_{\theta_0}(T>t_0)$ My attempt: I know $\sum x_i \sim Poisson(5\lambda)$ so I can write $$\alpha = 0.05  = \Pr_{\lambda = 3}\left(\sum x_i > t_0\right)$$ $$ = 1 - CDF_{poisson(15)}(t_0)$$ I don't really understand what $t_0$ is in the definition and how to arrive to the test. I know the CDF of poisson so that's not a problem. I just don't really understand what the last sentence of the theorem is saying and how to apply it. EDIT: From looking through some examples it seems like the test is just $I(\sum_i > t_0)$ where $1$ means to rejects $H_0$. And you just solve for $t_0$ above. Is that it?","I have trouble understanding how to apply Karlin-Rubin My situation: $X_1 ... X_5\sim Poisson(\lambda)$ independent. My hypothesis test is $$H_0: \lambda \leq 3$$ $$H_1: \lambda > 3$$ I checked that $\sum_i x_i$ is a sufficient MLR statistic for Poisson. Find a UMP level $\alpha = 0.05$ test. Complementary data: \begin{matrix} Observation: & 1 & 2 & 3 & 4 & 5 \\ Count:& 2 & 5 & 4 & 7 & 5 \end{matrix} Theorem: Consider testing $H_0:\theta \leq \theta_0$ vs. $H_1:\theta > \theta_0$ and consider $T$ to be a sufficient statistic for $\theta$ with MLR property on $\theta$. Then for any $t_0$, the test that rejects $H_0$ iff $T>t_0$ is a UMP level $\alpha$ test, where $\alpha = P_{\theta_0}(T>t_0)$ My attempt: I know $\sum x_i \sim Poisson(5\lambda)$ so I can write $$\alpha = 0.05  = \Pr_{\lambda = 3}\left(\sum x_i > t_0\right)$$ $$ = 1 - CDF_{poisson(15)}(t_0)$$ I don't really understand what $t_0$ is in the definition and how to arrive to the test. I know the CDF of poisson so that's not a problem. I just don't really understand what the last sentence of the theorem is saying and how to apply it. EDIT: From looking through some examples it seems like the test is just $I(\sum_i > t_0)$ where $1$ means to rejects $H_0$. And you just solve for $t_0$ above. Is that it?",,"['statistics', 'poisson-distribution', 'hypothesis-testing', 'order-statistics', 'maximum-likelihood']"
33,Transformation of Expectation of Summation,Transformation of Expectation of Summation,,"Can I perform that $$E\left[\sum_{i=1}^{n}X_i\right] = \sum_{i=1}^{n}E[X_i]$$ if $X_i$ is not i.i.d.? In other words, can I move the summation inside expectation out in any situation? Also, what about variance $Var(\sum_{i=1}^{n}X_i)$? Is it the same as expectation?","Can I perform that $$E\left[\sum_{i=1}^{n}X_i\right] = \sum_{i=1}^{n}E[X_i]$$ if $X_i$ is not i.i.d.? In other words, can I move the summation inside expectation out in any situation? Also, what about variance $Var(\sum_{i=1}^{n}X_i)$? Is it the same as expectation?",,"['probability', 'statistics']"
34,Why does the sum of the residuals not equal to 0 when there is no intercept of SLR [closed],Why does the sum of the residuals not equal to 0 when there is no intercept of SLR [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question As we all know that the residuals sum to 0 when there is an intercept. But why the residuals do not sum to 0 when we don't have the intercept in simple linear regression?,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question As we all know that the residuals sum to 0 when there is an intercept. But why the residuals do not sum to 0 when we don't have the intercept in simple linear regression?,,['statistics']
35,Independence of X̄ for IID random variables,Independence of X̄ for IID random variables,,"My question is that: Is $\overline X$ independent of $X_1 - \overline X$, given that $X_1,\ldots,X_n$ are IID random variables? I was thinking that it is independent, but i don't know the logic behind it.","My question is that: Is $\overline X$ independent of $X_1 - \overline X$, given that $X_1,\ldots,X_n$ are IID random variables? I was thinking that it is independent, but i don't know the logic behind it.",,['statistics']
36,Why does Hoeffding's Lemma do taylor expansion in the exponent?,Why does Hoeffding's Lemma do taylor expansion in the exponent?,,"While reading through the proof, I realized that one part of the proof I took for granted was that Hoeffding's lemma expanded on the exponent portion of the inequality after the reparametrization of the bounds: Note, I will use different variable names. $a$ is the $\theta$, and $x$ is the $u$: https://en.wikipedia.org/wiki/Hoeffding%27s_lemma They took the function $e^{-ax}(1-a+ae^x)$, and redefined it in terms of $e^{f(x)}$ where $f(x) = -ax + log(1-a+ae^x)$, and did a taylor expansion on the top, around $x = 0$, to get $e^{1/2(a(1-a))x^2}$, which translated to the final result after some trivial observations. However, I don't understand what prompted the expansion on $f(x)$, rather than the entire function itself. Can someone elaborate on this?","While reading through the proof, I realized that one part of the proof I took for granted was that Hoeffding's lemma expanded on the exponent portion of the inequality after the reparametrization of the bounds: Note, I will use different variable names. $a$ is the $\theta$, and $x$ is the $u$: https://en.wikipedia.org/wiki/Hoeffding%27s_lemma They took the function $e^{-ax}(1-a+ae^x)$, and redefined it in terms of $e^{f(x)}$ where $f(x) = -ax + log(1-a+ae^x)$, and did a taylor expansion on the top, around $x = 0$, to get $e^{1/2(a(1-a))x^2}$, which translated to the final result after some trivial observations. However, I don't understand what prompted the expansion on $f(x)$, rather than the entire function itself. Can someone elaborate on this?",,"['statistics', 'convergence-divergence', 'taylor-expansion', 'machine-learning']"
37,What is the entropy of binomial decay?,What is the entropy of binomial decay?,,"Let's play a game. I start with $N$ tokens, and I wait $T$ turns. Every turn, each token has probability $p$ of disappearing. I want an analytic formula for the entropy of this process, as a function of $N$, $T$, and $p$ . The calculation is straightforward for $N=1$ and $T=\infty$. The probability $p_i$ that our (only) token disappears at turn $i$ is $(1-p)^{i}p$, and the entropy $E$ is given by: $E(N=1, T=\infty, p=p) = \sum_{i}^{\infty}p_i\ln(p_i)$ $=\sum_{i}^{\infty}(1-p)^{i}p\ln((1-p)^{i}p)$ $=p\ln(1-p)\sum_{i}^{\infty}i(1-p)^{i} + p\ln(p)\sum_{i}^{\infty}(1-p)^{i}$ $=p\ln(1-p)\frac{1-p}{p^2} + p\ln(p)\frac{1}{p}$ $=\frac{1-p}{p}\ln(1-p) + \ln(p)$ For $N=2$ and $T=\infty$, my calculation (not shown) is a lot uglier, but simplifies down to: $E(N=2, T=\infty, p=p) = \frac{2-2p}{2-p}\ln(2) + 2\ln(p) + \frac{2-2p}{p} \ln(1-p)$ I'm about to calculate the $N=3$, $T=\infty$ case, but I've got the feeling I'm reinventing the wheel. Is the formula for $E(N, T, p)$ known? I'm particularly interested in the $T=\infty$ case. A good approximation is almost as useful to me as an exact formula, but I'm interested in both small and large values of $N$. As a sanity check, we can compare against a Python simulation: #!/usr/bin/python3 import numpy as np from scipy.stats import binom  def entropy(n_initial, p, n_steps, n_trials):     # Simulate many stochastic binomial decays, return the average of     # the log of their binomial ""penalty""     log_penalty = np.zeros(n_trials, dtype=np.float64)     n = n_initial * np.ones(n_trials, dtype=np.int64)     for i in range(n_steps):         num_losses = np.random.binomial(n, p)         log_penalty += binom.logpmf(k=num_losses, n=n, p=p)         n -= num_losses     return log_penalty.mean()  p=0.1 print(entropy(n_initial=1, p=p, n_steps=1000, n_trials=10000)) print(((1-p)/p)*np.log(1-p) + np.log(p))  print(entropy(n_initial=2, p=p, n_steps=1000, n_trials=10000)) print((2-2*p)/(2-p)*np.log(2) + 2*np.log(p) + ((2-2*p)/p) * np.log(1-p)) Please forgive/correct me if I've made errors in my math or I'm using the wrong terms; I'm an experimental physicist, not a mathematician, and my formal math is rusty.","Let's play a game. I start with $N$ tokens, and I wait $T$ turns. Every turn, each token has probability $p$ of disappearing. I want an analytic formula for the entropy of this process, as a function of $N$, $T$, and $p$ . The calculation is straightforward for $N=1$ and $T=\infty$. The probability $p_i$ that our (only) token disappears at turn $i$ is $(1-p)^{i}p$, and the entropy $E$ is given by: $E(N=1, T=\infty, p=p) = \sum_{i}^{\infty}p_i\ln(p_i)$ $=\sum_{i}^{\infty}(1-p)^{i}p\ln((1-p)^{i}p)$ $=p\ln(1-p)\sum_{i}^{\infty}i(1-p)^{i} + p\ln(p)\sum_{i}^{\infty}(1-p)^{i}$ $=p\ln(1-p)\frac{1-p}{p^2} + p\ln(p)\frac{1}{p}$ $=\frac{1-p}{p}\ln(1-p) + \ln(p)$ For $N=2$ and $T=\infty$, my calculation (not shown) is a lot uglier, but simplifies down to: $E(N=2, T=\infty, p=p) = \frac{2-2p}{2-p}\ln(2) + 2\ln(p) + \frac{2-2p}{p} \ln(1-p)$ I'm about to calculate the $N=3$, $T=\infty$ case, but I've got the feeling I'm reinventing the wheel. Is the formula for $E(N, T, p)$ known? I'm particularly interested in the $T=\infty$ case. A good approximation is almost as useful to me as an exact formula, but I'm interested in both small and large values of $N$. As a sanity check, we can compare against a Python simulation: #!/usr/bin/python3 import numpy as np from scipy.stats import binom  def entropy(n_initial, p, n_steps, n_trials):     # Simulate many stochastic binomial decays, return the average of     # the log of their binomial ""penalty""     log_penalty = np.zeros(n_trials, dtype=np.float64)     n = n_initial * np.ones(n_trials, dtype=np.int64)     for i in range(n_steps):         num_losses = np.random.binomial(n, p)         log_penalty += binom.logpmf(k=num_losses, n=n, p=p)         n -= num_losses     return log_penalty.mean()  p=0.1 print(entropy(n_initial=1, p=p, n_steps=1000, n_trials=10000)) print(((1-p)/p)*np.log(1-p) + np.log(p))  print(entropy(n_initial=2, p=p, n_steps=1000, n_trials=10000)) print((2-2*p)/(2-p)*np.log(2) + 2*np.log(p) + ((2-2*p)/p) * np.log(1-p)) Please forgive/correct me if I've made errors in my math or I'm using the wrong terms; I'm an experimental physicist, not a mathematician, and my formal math is rusty.",,"['probability', 'statistics', 'binomial-coefficients', 'binomial-distribution', 'entropy']"
38,"What is the origin of the term ""moments"" in the study of random variables?","What is the origin of the term ""moments"" in the study of random variables?",,"I understand what the moments are, I just want to know who picked the term ""moment"" and why? How is the word ""moment"" related to different but related ways to describe the shape of a random variable?","I understand what the moments are, I just want to know who picked the term ""moment"" and why? How is the word ""moment"" related to different but related ways to describe the shape of a random variable?",,"['statistics', 'math-history', 'moment-generating-functions']"
39,Formal underpinnings of cross-validation?,Formal underpinnings of cross-validation?,,"In the past, I've used cross-validation in a purely instrumental way--namely, to ensure that models have decent predictive ability. I know that cross-validation works, but I don't know why it works on a formal mathematical level. Is there a formal derivation showing that cross-validation of any form (leave one out, exhaustive, or other) maximizes predictive validity, or is cross-validation an ad hoc tool that we use because it intuitively makes sense?","In the past, I've used cross-validation in a purely instrumental way--namely, to ensure that models have decent predictive ability. I know that cross-validation works, but I don't know why it works on a formal mathematical level. Is there a formal derivation showing that cross-validation of any form (leave one out, exhaustive, or other) maximizes predictive validity, or is cross-validation an ad hoc tool that we use because it intuitively makes sense?",,"['statistics', 'statistical-inference']"
40,Is there an unbiased estimator of the reciprocal of the slope in linear regression?,Is there an unbiased estimator of the reciprocal of the slope in linear regression?,,"I have a situation which can be handled well through a simple linear regression model. That is, I have data points with known x values, y values with a given amount of error, and an ideal fit of the form $y = \alpha + \beta x$. It's easily possible to get unbiased (but correlated) estimators for $\alpha$ and $\beta$ through linear regression, but I have a case where it would be useful to have an unbiased estimator of $\beta^{-1}$, and I haven't been able to figure out if this is possible. Some things I've tried which don't work: Using the inverse of the estimator, $\hat{\beta}^{-1}$. This can be shown through Taylor expansion to be biased. Eg. if $\beta > 0$, then this will be biased high proportional to $\sigma^2 (\hat{\beta})$ to lowest order. Performing the inverse linear regression, instead trying to fit $x = -\alpha/\beta + y/\beta$ for $-\alpha/\beta$ and $\beta^{-1}$. The problem here is that this breaks the assumption going into the linear regression model, that error is on the dependent variable only. Instead of getting an unbiased estimator of $\beta^{-1}$, you end up getting an unbiased estimator of $\beta\sigma^2(x)/\sigma^2(y)$. So, is there any known way to do this?","I have a situation which can be handled well through a simple linear regression model. That is, I have data points with known x values, y values with a given amount of error, and an ideal fit of the form $y = \alpha + \beta x$. It's easily possible to get unbiased (but correlated) estimators for $\alpha$ and $\beta$ through linear regression, but I have a case where it would be useful to have an unbiased estimator of $\beta^{-1}$, and I haven't been able to figure out if this is possible. Some things I've tried which don't work: Using the inverse of the estimator, $\hat{\beta}^{-1}$. This can be shown through Taylor expansion to be biased. Eg. if $\beta > 0$, then this will be biased high proportional to $\sigma^2 (\hat{\beta})$ to lowest order. Performing the inverse linear regression, instead trying to fit $x = -\alpha/\beta + y/\beta$ for $-\alpha/\beta$ and $\beta^{-1}$. The problem here is that this breaks the assumption going into the linear regression model, that error is on the dependent variable only. Instead of getting an unbiased estimator of $\beta^{-1}$, you end up getting an unbiased estimator of $\beta\sigma^2(x)/\sigma^2(y)$. So, is there any known way to do this?",,"['statistics', 'regression', 'linear-regression']"
41,Ratio of sum of squares of Normal Distributions,Ratio of sum of squares of Normal Distributions,,"Find $$E[\frac{\sum_{i=1}^{51} X_i^2}{\sum_{i=51}^{101} X_i^2}], $$if $X_1,X_2,...,X_{51}$ are independent and are distributed as N(0,1). This question appeared in my final exam of probability and stochastic processes, that occurred today .I couldn't answer this in the exam and would love to find out more. I did simplify this a bit though. Here's what I did: $Y = \sum_{i=1}^{50} X_i^2$, $Z = \sum_{i=52}^{101} X_i^2,X = X_{51}$. Then,  $X \sim \gamma(1/2,1/2), Y \sim \gamma(25,1/2), Z \sim\gamma(25,1/2). $ Then we wish to find $E[\frac{X+Y}{X+Z}]$, where X,Y,Z are independent random variables. I was stuck after this, as there was this integral of $$\frac{x^{-1/2}}{x+z}e^{-25x}, 0\leq x < \infty$$ Any help will be appreciated.","Find $$E[\frac{\sum_{i=1}^{51} X_i^2}{\sum_{i=51}^{101} X_i^2}], $$if $X_1,X_2,...,X_{51}$ are independent and are distributed as N(0,1). This question appeared in my final exam of probability and stochastic processes, that occurred today .I couldn't answer this in the exam and would love to find out more. I did simplify this a bit though. Here's what I did: $Y = \sum_{i=1}^{50} X_i^2$, $Z = \sum_{i=52}^{101} X_i^2,X = X_{51}$. Then,  $X \sim \gamma(1/2,1/2), Y \sim \gamma(25,1/2), Z \sim\gamma(25,1/2). $ Then we wish to find $E[\frac{X+Y}{X+Z}]$, where X,Y,Z are independent random variables. I was stuck after this, as there was this integral of $$\frac{x^{-1/2}}{x+z}e^{-25x}, 0\leq x < \infty$$ Any help will be appreciated.",,"['statistics', 'probability-distributions', 'random-variables', 'normal-distribution']"
42,Cramer-Rao Casella Berger 7.38 for exponential family,Cramer-Rao Casella Berger 7.38 for exponential family,,"The question states  ''let $X_{1}, \dots, X_{n}$ be random sample from $f(x \mid \theta) = \theta\cdot x^{\theta-1}$ for $0 < x< 1 ; \theta > 0$ . Is there a function of $\theta, g(\theta)$ for which there exists an unbiased estimator of $\theta$ whose variance $\textbf{attains}$ the Cramèr-Rao lower bound ? if so find it!"". so we have an exponential family, and we can interchange differentiation and integration, so the fisher information term, denominator of the Cramér-Rao lower bound, I calculated as $E \left(\dfrac{\partial}{\partial \theta}[\ln(\theta \cdot x^{\theta-1})] \right)^{2} = -n E \left(\dfrac{\partial^{2}}{\partial \theta^{2}}(\ln(\theta x^{\theta-1}\right) \implies \dfrac{\theta^{2}}{n}$ taking $\dfrac{1}{I(\theta)}$ Now just taking a stab the statistic I've used is $W(X)= \overline{X}$ which I calculate to be UBE since $E[X] = \dfrac{\theta}{\theta + 1}$ and thus E $[\overline{X}] = \frac{\theta}{\theta + 1}$ from my calculations (hopefully right). similarly, if I calculate the variance I get $\dfrac{\theta}{(\theta + 1)^{2}(\theta + 2)} \geq \dfrac{\theta^{2}}{n}$ satisfies the lower bound. If I examine the MLE I find: $\dfrac{n}{\theta} + \sum_{i}\ln(x_{i}) = 0 \implies \hat{\theta_{MLE}} = \dfrac{-n}{\sum \ln(x_{i})}$ . the attainment theory states \begin{equation} \begin{split} \frac{n}{\theta} + \sum_{i}\ln(x_{i}) &= a(\theta)[W(\vec{x})-\tau(\theta)]\\  &= n [\frac{ \sum \ln(x_{i})}{n} - \dfrac{-1}{\theta}] \end{split} \end{equation} where if W(x) satisfies the above, then it is the best estimate for $\tau$ . We need to use Rao-Blackwell theorem for W in the above equation to show that $\dfrac{1}{\hat{\theta_{MLE}}}$ is the best. Consider Y = \log(X) now applying the transformation with the Jacobian we have \begin{equation} \begin{split} f_{X}(e^{y}) = \theta e^{y(\theta-1)}\cdot e^{y} = \theta e^{y\theta} = f_{Y}(y) \end{split} \end{equation} where E[Y] = $\frac{1}{\theta}$ (Which I think is an unbiased estimator ?) Using the Rao-Blackwell theorem, let $\theta^{\star} = E[Y_{i} \mid \sum y_{i} = t]$ where since $f_{Y}(y)$ is an exponential family then $\sum y_{i}$ can be shown to be sufficient statistic. then \begin{equation} \begin{split}  E[\theta^{\star}] &= E \left[ E[Y_{i} \mid \sum y_{i} = t] \right] \\  &= E\left[ \theta^{\star} \right] \\  &= \frac{1}{\theta^{\star}} \end{split} \end{equation} which really fits into the attainment equation written above! so my guess is to let $W(\vec{x}) = \dfrac{1}{\theta_{\text{MLE}}^{\star}}$ be the best UBE (?)","The question states  ''let be random sample from for . Is there a function of for which there exists an unbiased estimator of whose variance the Cramèr-Rao lower bound ? if so find it!"". so we have an exponential family, and we can interchange differentiation and integration, so the fisher information term, denominator of the Cramér-Rao lower bound, I calculated as taking Now just taking a stab the statistic I've used is which I calculate to be UBE since and thus E from my calculations (hopefully right). similarly, if I calculate the variance I get satisfies the lower bound. If I examine the MLE I find: . the attainment theory states where if W(x) satisfies the above, then it is the best estimate for . We need to use Rao-Blackwell theorem for W in the above equation to show that is the best. Consider Y = \log(X) now applying the transformation with the Jacobian we have where E[Y] = (Which I think is an unbiased estimator ?) Using the Rao-Blackwell theorem, let where since is an exponential family then can be shown to be sufficient statistic. then which really fits into the attainment equation written above! so my guess is to let be the best UBE (?)","X_{1}, \dots, X_{n} f(x \mid \theta) = \theta\cdot x^{\theta-1} 0 < x< 1 ; \theta > 0 \theta, g(\theta) \theta \textbf{attains} E \left(\dfrac{\partial}{\partial \theta}[\ln(\theta \cdot x^{\theta-1})] \right)^{2} = -n E \left(\dfrac{\partial^{2}}{\partial \theta^{2}}(\ln(\theta x^{\theta-1}\right) \implies \dfrac{\theta^{2}}{n} \dfrac{1}{I(\theta)} W(X)= \overline{X} E[X] = \dfrac{\theta}{\theta + 1} [\overline{X}] = \frac{\theta}{\theta + 1} \dfrac{\theta}{(\theta + 1)^{2}(\theta + 2)} \geq \dfrac{\theta^{2}}{n} \dfrac{n}{\theta} + \sum_{i}\ln(x_{i}) = 0 \implies \hat{\theta_{MLE}} = \dfrac{-n}{\sum \ln(x_{i})} \begin{equation}
\begin{split}
\frac{n}{\theta} + \sum_{i}\ln(x_{i}) &= a(\theta)[W(\vec{x})-\tau(\theta)]\\
 &= n [\frac{ \sum \ln(x_{i})}{n} - \dfrac{-1}{\theta}]
\end{split}
\end{equation} \tau \dfrac{1}{\hat{\theta_{MLE}}} \begin{equation}
\begin{split}
f_{X}(e^{y}) = \theta e^{y(\theta-1)}\cdot e^{y} = \theta e^{y\theta} = f_{Y}(y)
\end{split}
\end{equation} \frac{1}{\theta} \theta^{\star} = E[Y_{i} \mid \sum y_{i} = t] f_{Y}(y) \sum y_{i} \begin{equation}
\begin{split}
 E[\theta^{\star}] &= E \left[ E[Y_{i} \mid \sum y_{i} = t] \right] \\
 &= E\left[ \theta^{\star} \right] \\
 &= \frac{1}{\theta^{\star}}
\end{split}
\end{equation} W(\vec{x}) = \dfrac{1}{\theta_{\text{MLE}}^{\star}}","['statistics', 'estimation', 'variance', 'upper-lower-bounds']"
43,"If $P(A) = 1/3, P(B|A) = 3/5$, then $A$ and $B$ cannot be disjoint","If , then  and  cannot be disjoint","P(A) = 1/3, P(B|A) = 3/5 A B","Show that if $P(A) = 1/3, P(B|A) = 3/5$, then $A$ and $B$ cannot be   disjoint The expression $P(B|A) = 3/5$ means that, given that $A$ happened, the probability of $B$ happening is $3/5$. However, it does not force $B$ to have or not a relation to $A$. What I know to be a universal rule is: $$P(A\cap B) = P(A|B) P(B)$$ When $A$ is independent from $B$, we have $P(A|B) = P(A)$. So in the two cases: they're dependent or not dependent, their product isn't $0$, right? So $A$ and $B$ cannot be disjoint. Even though I understand this proof, I cannot understand why this is true. Suppose that the probability of an event $A$ is $1/3$, and of the event $B$ is $3/5$, as stated in the question. Why cannot $A$ and $B$ be disjoint? $P(A\cap B)$ is just the probability that $A$ and $B$ occur together, right? Why this isn't possible?","Show that if $P(A) = 1/3, P(B|A) = 3/5$, then $A$ and $B$ cannot be   disjoint The expression $P(B|A) = 3/5$ means that, given that $A$ happened, the probability of $B$ happening is $3/5$. However, it does not force $B$ to have or not a relation to $A$. What I know to be a universal rule is: $$P(A\cap B) = P(A|B) P(B)$$ When $A$ is independent from $B$, we have $P(A|B) = P(A)$. So in the two cases: they're dependent or not dependent, their product isn't $0$, right? So $A$ and $B$ cannot be disjoint. Even though I understand this proof, I cannot understand why this is true. Suppose that the probability of an event $A$ is $1/3$, and of the event $B$ is $3/5$, as stated in the question. Why cannot $A$ and $B$ be disjoint? $P(A\cap B)$ is just the probability that $A$ and $B$ occur together, right? Why this isn't possible?",,"['probability', 'statistics', 'elementary-set-theory']"
44,Probability using Bayes rule,Probability using Bayes rule,,"Suppose that in answering a question on a true/false test, an examinee either knows the answer with probability $p$ or s/he guesses with probability $1-p$. Assume that if the examinee knows the answer to a question, the probability that s/he gives the correct answer is $1$, and if s/he guesses then s/he only gives the correct answer with probability $0.5$. Use Bayes rule to compute the probability that an examinee knew the answer to a question given that s/he has correctly answered it. First I wrote out all the probabilities from the question. $$ P(\text{Wrong}) = 0.5 \\ P(\text{Correct}) = 0.5 \\ P(\text{Correct} \mid \text{Known}) = 1 \\ P(\text{Wrong} \mid \text{Known}) = 0 \\ P(\text{Correct} \mid \text{Guess}) = 0.5 \\ P(\text{Wrong} \mid \text{Guess}) = 0.5 \\ $$ I tried creating two equations with two unknowns to get a value of $p$ shown below: $$ (1)\quad 0.5 = \frac{P(\text{Guess} \mid \text{Correct})\cdot0.5}{1 - p} $$ $$ (2)\quad 1 = \frac{P(\text{Known} \mid \text{Correct})\cdot0.5}{p} $$ Then rearranged $(2)$ to get the following: $$ P(\text{Known} \mid \text{Correct}) = 2p $$ And $P(\text{Guesses} \mid \text{Correct})$ is equal to $1 - P(\text{Knows} \mid \text{Correct})$ so I substituted that back into $(1)$ $$ (1)\quad 0.5 = \frac{(1 - 2p)\cdot0.5}{1 - p}\\ (1)\quad 0.5 = \frac{0.5 - p}{1 - p}\\ (1)\quad 0.5 - 0.5p = 0.5 - p\\ 0.5p = 0\\ p = 0 $$ But this is can't be right, the question is only 5% so doesn't seem like it would be this much work, am I missing something simple here? The main equation that needs to be solved: $$ P(\text{Known} \mid \text{Correct}) = \frac{P(\text{Correct} \mid \text{Known}) P(\text{Known})}{P(\text{Correct})} $$","Suppose that in answering a question on a true/false test, an examinee either knows the answer with probability $p$ or s/he guesses with probability $1-p$. Assume that if the examinee knows the answer to a question, the probability that s/he gives the correct answer is $1$, and if s/he guesses then s/he only gives the correct answer with probability $0.5$. Use Bayes rule to compute the probability that an examinee knew the answer to a question given that s/he has correctly answered it. First I wrote out all the probabilities from the question. $$ P(\text{Wrong}) = 0.5 \\ P(\text{Correct}) = 0.5 \\ P(\text{Correct} \mid \text{Known}) = 1 \\ P(\text{Wrong} \mid \text{Known}) = 0 \\ P(\text{Correct} \mid \text{Guess}) = 0.5 \\ P(\text{Wrong} \mid \text{Guess}) = 0.5 \\ $$ I tried creating two equations with two unknowns to get a value of $p$ shown below: $$ (1)\quad 0.5 = \frac{P(\text{Guess} \mid \text{Correct})\cdot0.5}{1 - p} $$ $$ (2)\quad 1 = \frac{P(\text{Known} \mid \text{Correct})\cdot0.5}{p} $$ Then rearranged $(2)$ to get the following: $$ P(\text{Known} \mid \text{Correct}) = 2p $$ And $P(\text{Guesses} \mid \text{Correct})$ is equal to $1 - P(\text{Knows} \mid \text{Correct})$ so I substituted that back into $(1)$ $$ (1)\quad 0.5 = \frac{(1 - 2p)\cdot0.5}{1 - p}\\ (1)\quad 0.5 = \frac{0.5 - p}{1 - p}\\ (1)\quad 0.5 - 0.5p = 0.5 - p\\ 0.5p = 0\\ p = 0 $$ But this is can't be right, the question is only 5% so doesn't seem like it would be this much work, am I missing something simple here? The main equation that needs to be solved: $$ P(\text{Known} \mid \text{Correct}) = \frac{P(\text{Correct} \mid \text{Known}) P(\text{Known})}{P(\text{Correct})} $$",,"['probability', 'statistics', 'bayes-theorem']"
45,Rolling a die 1000 times. Estimate the probability $ℙ( \prod^{1000}_{n=1} X_n ≤ z^{1000})$ for real $1 < z < 6$,Rolling a die 1000 times. Estimate the probability  for real,ℙ( \prod^{1000}_{n=1} X_n ≤ z^{1000}) 1 < z < 6,"Rolling a die 1000 times, denoting the outcome of roll by $X_n$. Estimate the probability  $ℙ( \displaystyle\prod^{1000}_{n=1} X_n ≤ z^{1000})$ for real $1 < z < 6$ I've taken the natural log of both sides to change the product into a sum and I've subtracted $1000*𝔼[ln(X_n)]$ and divided by $\sqrt{1000*Var(ln(X_n))}$ on both sides so that it has standard normal distribution. I was going to use the Central Limit Theorem but as $z$ is an unknown real I think the Law of Large Numbers would be more useful but I am unsure how to go about it. I know that with a low $z$ the value will be closer to $0$ and a high $z$ it will be closer to $1$. Any help would be greatly appreciated!","Rolling a die 1000 times, denoting the outcome of roll by $X_n$. Estimate the probability  $ℙ( \displaystyle\prod^{1000}_{n=1} X_n ≤ z^{1000})$ for real $1 < z < 6$ I've taken the natural log of both sides to change the product into a sum and I've subtracted $1000*𝔼[ln(X_n)]$ and divided by $\sqrt{1000*Var(ln(X_n))}$ on both sides so that it has standard normal distribution. I was going to use the Central Limit Theorem but as $z$ is an unknown real I think the Law of Large Numbers would be more useful but I am unsure how to go about it. I know that with a low $z$ the value will be closer to $0$ and a high $z$ it will be closer to $1$. Any help would be greatly appreciated!",,"['probability', 'statistics']"
46,Question on lines of regression,Question on lines of regression,,I know how to find the line of regression when given the set of values of x and y. But in this question i don't have any idea what to do. I am a beginner . I will really appreciate the help.,I know how to find the line of regression when given the set of values of x and y. But in this question i don't have any idea what to do. I am a beginner . I will really appreciate the help.,,"['probability', 'statistics', 'regression', 'linear-regression', 'regression-analysis']"
47,Information theory applied to a dice (intuition about information theory),Information theory applied to a dice (intuition about information theory),,"Let's say I have a die that has the values 1 to 6 written on it, and I don't know the probability to get each value, I only know that when I throw the die many times I get an average value of 3.5, just like a fair die. According to information theory, I can guess the most unbiased probability to get a certain value by maximizing the uncertainty under the constraints, where the uncertainty is: $$H=−K\sum_{i} p_i\ln(p_i)$$ and the constraints are: $$\sum_{i}p_i=1$$ and $$\sum_{i}p_i⋅v_i=3.5$$ where $v_i$ are the values of the dice between 1 to 6. If I maximize $H$ under the constrains I get: $$p_i∝\exp(−v_iμ/K)$$ Where μ is the Lagrange multiplier corresponding to the second condition. My question is : Is this really the most unbiased probability we can find under the constraints? The possibility of equal probabilities ($p_i=1/6$) fulfills the constraints, and according to Occam's razor principle, it should be more likely than exponential probability. What am I missing?","Let's say I have a die that has the values 1 to 6 written on it, and I don't know the probability to get each value, I only know that when I throw the die many times I get an average value of 3.5, just like a fair die. According to information theory, I can guess the most unbiased probability to get a certain value by maximizing the uncertainty under the constraints, where the uncertainty is: $$H=−K\sum_{i} p_i\ln(p_i)$$ and the constraints are: $$\sum_{i}p_i=1$$ and $$\sum_{i}p_i⋅v_i=3.5$$ where $v_i$ are the values of the dice between 1 to 6. If I maximize $H$ under the constrains I get: $$p_i∝\exp(−v_iμ/K)$$ Where μ is the Lagrange multiplier corresponding to the second condition. My question is : Is this really the most unbiased probability we can find under the constraints? The possibility of equal probabilities ($p_i=1/6$) fulfills the constraints, and according to Occam's razor principle, it should be more likely than exponential probability. What am I missing?",,"['statistics', 'information-theory', 'entropy']"
48,How to prove the estimator of $\sigma^2$ in generalized least squares is unbiased?,How to prove the estimator of  in generalized least squares is unbiased?,\sigma^2,"The model is as follow: $$y = X\beta + \epsilon, \epsilon \sim (0,\sigma^2 V)$$ where $X$ is $n \times (p+1)$ and $V$ is a known positive definite matrix. Using spectral decomposition, it can be established that $V$ is positive definite if and only if there exists a nonsingular matrix $P$ such that $V = PP^T$. Multiplying $P^{-1}$ on both sides yields that $$P^{-1}y = P^{-1} X \beta + P^{-1} \epsilon$$ I managed to derive that $\hat{\beta} = (X^T V^{-1}X)^{-1}X^TV^{-1}y$. The estimator for $\sigma^2$ is as follow $$\hat{\sigma^2}= \frac{(y-X\hat{\beta})^T V^{-1}(y-X\hat{\beta})}{n-(p+1)}  $$ $$= \frac{y^T(V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1})y}{n-(p+1)}$$ But I failed to show that the estimator of $\sigma^2$ is unbiased My attempt is to take expectation of $\hat{\sigma^2}$ and then use trace to show that $$E(\hat{\sigma^2})= \frac{tr(V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1})) E(yy^T)}{n-(p+1)}$$ Then I got stuck. I do not know how to continue. Can someone kindly help me here please?","The model is as follow: $$y = X\beta + \epsilon, \epsilon \sim (0,\sigma^2 V)$$ where $X$ is $n \times (p+1)$ and $V$ is a known positive definite matrix. Using spectral decomposition, it can be established that $V$ is positive definite if and only if there exists a nonsingular matrix $P$ such that $V = PP^T$. Multiplying $P^{-1}$ on both sides yields that $$P^{-1}y = P^{-1} X \beta + P^{-1} \epsilon$$ I managed to derive that $\hat{\beta} = (X^T V^{-1}X)^{-1}X^TV^{-1}y$. The estimator for $\sigma^2$ is as follow $$\hat{\sigma^2}= \frac{(y-X\hat{\beta})^T V^{-1}(y-X\hat{\beta})}{n-(p+1)}  $$ $$= \frac{y^T(V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1})y}{n-(p+1)}$$ But I failed to show that the estimator of $\sigma^2$ is unbiased My attempt is to take expectation of $\hat{\sigma^2}$ and then use trace to show that $$E(\hat{\sigma^2})= \frac{tr(V^{-1}-V^{-1}X(X^TV^{-1}X)^{-1}X^TV^{-1})) E(yy^T)}{n-(p+1)}$$ Then I got stuck. I do not know how to continue. Can someone kindly help me here please?",,"['linear-algebra', 'statistics']"
49,"30% pizza to 10% people, 70% pizza to 90% people, what is the difference?","30% pizza to 10% people, 70% pizza to 90% people, what is the difference?",,"Yesterday I was reading an article, which had a statistic exposing a certain disproportion in different groups of people. I will now reformulate this problem in a more ""neutral"" way. If 10% of people get 30% of pizza, then how many times more pizza does an average person in the 10% group get than the average person in the 90% group? I know we can solve this problem the following way: EDIT: $$x/(x+1) = .3$$   so $x=0.428571$, which means that the 10% group gets $x=0.428571$ pizzas every time the other group gets one pizza. But how can we solve this in a different way? I seem to have always had some issue with percentages, despite doing well in much more complicated math or physics problems. Here's what I've tried: $30/10 = 70x/90$, so $x\approx 3.8571$, which is obviously false, and we can easily verify this. Can someone please clarify why exactly my second equation is incorrect, and what a correct equation should look like? I mean an equation with proportions, but not like the first equation, which is easy to come up with, but I want a more ""direct"" approach.","Yesterday I was reading an article, which had a statistic exposing a certain disproportion in different groups of people. I will now reformulate this problem in a more ""neutral"" way. If 10% of people get 30% of pizza, then how many times more pizza does an average person in the 10% group get than the average person in the 90% group? I know we can solve this problem the following way: EDIT: $$x/(x+1) = .3$$   so $x=0.428571$, which means that the 10% group gets $x=0.428571$ pizzas every time the other group gets one pizza. But how can we solve this in a different way? I seem to have always had some issue with percentages, despite doing well in much more complicated math or physics problems. Here's what I've tried: $30/10 = 70x/90$, so $x\approx 3.8571$, which is obviously false, and we can easily verify this. Can someone please clarify why exactly my second equation is incorrect, and what a correct equation should look like? I mean an equation with proportions, but not like the first equation, which is easy to come up with, but I want a more ""direct"" approach.",,"['algebra-precalculus', 'statistics', 'percentages']"
50,Is it possible to compute Pearson correlation coefficient in parallel?,Is it possible to compute Pearson correlation coefficient in parallel?,,"Let be $X = \{x_1, ..., x_n\}$ and $Y = \{y_1, ..., y_n\}$ two vectors of the same length $n$. Is it possible to compute the Pearson correlation coefficient between $X$ and $Y$ in parallel? More precisely, is it possible to compute $\rho = \operatorname{corr}(X,Y)$ by computing $\rho_1 = \operatorname{corr}(X_1,Y)$ and $\rho_2 = \operatorname{corr}(X_2,Y)$ separately where $X_1 = \{x_1, ..., x_{n/2}\}$ and $X_2 = \{x_{n/2 + 1}, ..., x_{n}\}$?","Let be $X = \{x_1, ..., x_n\}$ and $Y = \{y_1, ..., y_n\}$ two vectors of the same length $n$. Is it possible to compute the Pearson correlation coefficient between $X$ and $Y$ in parallel? More precisely, is it possible to compute $\rho = \operatorname{corr}(X,Y)$ by computing $\rho_1 = \operatorname{corr}(X_1,Y)$ and $\rho_2 = \operatorname{corr}(X_2,Y)$ separately where $X_1 = \{x_1, ..., x_{n/2}\}$ and $X_2 = \{x_{n/2 + 1}, ..., x_{n}\}$?",,"['probability', 'statistics', 'correlation']"
51,Is the coin fair?,Is the coin fair?,,"A coin was tossed n 1000 times, and the proportion of heads observed was 0.51. Do we have evidence to conclude that the coin is unfair? My approach: expected value for the number of heads is 1000*0.15=510 in theory, the probability will be 0.5 and that means 500 out of 1000 coins would show head so this is fair","A coin was tossed n 1000 times, and the proportion of heads observed was 0.51. Do we have evidence to conclude that the coin is unfair? My approach: expected value for the number of heads is 1000*0.15=510 in theory, the probability will be 0.5 and that means 500 out of 1000 coins would show head so this is fair",,"['probability', 'statistics', 'statistical-inference']"
52,Confidence Interval and Variance of Coefficient of Variation,Confidence Interval and Variance of Coefficient of Variation,,"I'm currently struggling to find the confidence interval of a statistic. I'm calculating the coefficient of variation for a specific sample. The coefficient of variation is $$\frac{\sigma}{\mu}$$ I would like to construct a normal confidence interval around the estimator. I'm stuck trying to get the variance of my estimator. $$ \operatorname{Var}\left[\frac{\sigma}{\mu}\right] = \operatorname{Var}\left[\frac{\sum(x_i-\bar{x})^2}{\sum(x_i)}\right] $$ I start expanding it and a lot of it resolves by itself. However, I'm very confused about the following quantities: $$ \operatorname{Var}\left[\frac{\sum(x_i)^2}{\sum(x_i)}\right] $$ and $$ \operatorname{Cov}\left[\frac{\sum(x_i)^2}{\sum(x_i)},X\right] $$ Can anyone lend me a hand here?","I'm currently struggling to find the confidence interval of a statistic. I'm calculating the coefficient of variation for a specific sample. The coefficient of variation is I would like to construct a normal confidence interval around the estimator. I'm stuck trying to get the variance of my estimator. I start expanding it and a lot of it resolves by itself. However, I'm very confused about the following quantities: and Can anyone lend me a hand here?","\frac{\sigma}{\mu}  \operatorname{Var}\left[\frac{\sigma}{\mu}\right] = \operatorname{Var}\left[\frac{\sum(x_i-\bar{x})^2}{\sum(x_i)}\right]   \operatorname{Var}\left[\frac{\sum(x_i)^2}{\sum(x_i)}\right]   \operatorname{Cov}\left[\frac{\sum(x_i)^2}{\sum(x_i)},X\right] ","['statistics', 'variance', 'confidence-interval']"
53,Show that $\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$ under the least squares optimality criterion.,Show that  under the least squares optimality criterion.,\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2},"I need to prove that $\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$. I have not seen this as a definition for $\hat{β}_1$ before and am having trouble even starting this proof, but it must have something to do with the least-squares normal equations and the least-squares estimators. Any thoughts?","I need to prove that $\hat{β}_1 = \dfrac{\sum_{i=1}^nx_iy_i}{\sum_{i=1}^nx_i^2}$. I have not seen this as a definition for $\hat{β}_1$ before and am having trouble even starting this proof, but it must have something to do with the least-squares normal equations and the least-squares estimators. Any thoughts?",,"['statistics', 'proof-writing', 'least-squares', 'regression-analysis']"
54,Is independence preserved under transformation?,Is independence preserved under transformation?,,"Is independence preserved under transformation? If not, assume linear/continuous? This problem comes from proving $X_n$ and $s_n^2$ are independent given iid sample from $N(\theta,\sigma^2)$ The argument goes $s_n^2$ is a function of $X_i-\bar{X}$ which is uncorrelated to $\bar{X}$ by Basu's theorem.","Is independence preserved under transformation? If not, assume linear/continuous? This problem comes from proving $X_n$ and $s_n^2$ are independent given iid sample from $N(\theta,\sigma^2)$ The argument goes $s_n^2$ is a function of $X_i-\bar{X}$ which is uncorrelated to $\bar{X}$ by Basu's theorem.",,"['probability', 'statistics']"
55,M Balls in N Bins: Expectation,M Balls in N Bins: Expectation,,"Question : I have a typical $m$ balls in $n$ bins question, where I'm trying to find the expected number of balls in each bin.  Each ball is independently placed into one of the n bins, so there is a $\frac1n$ chance for each bin. My Guess : I believe that the expected value should be something like $\frac mn$, but I'm not sure how to prove it. I started by using an indicator random variable $X_i$ = the event in which the $i$-th ball is in a bin. $X_i = 1$ with probability $\frac 1n$ OR $0$ with probability $1-\frac 1n$. E(number of balls in each bin) = $E(X_1)+E(X_2)+ ... + E(X_m) = m\cdot E(X_i) = \frac mn$ But I think that the proof doesn't seem correct, can anyone explain where I went wrong (if I did go wrong)? Thanks!","Question : I have a typical $m$ balls in $n$ bins question, where I'm trying to find the expected number of balls in each bin.  Each ball is independently placed into one of the n bins, so there is a $\frac1n$ chance for each bin. My Guess : I believe that the expected value should be something like $\frac mn$, but I'm not sure how to prove it. I started by using an indicator random variable $X_i$ = the event in which the $i$-th ball is in a bin. $X_i = 1$ with probability $\frac 1n$ OR $0$ with probability $1-\frac 1n$. E(number of balls in each bin) = $E(X_1)+E(X_2)+ ... + E(X_m) = m\cdot E(X_i) = \frac mn$ But I think that the proof doesn't seem correct, can anyone explain where I went wrong (if I did go wrong)? Thanks!",,"['probability', 'statistics', 'balls-in-bins']"
56,"For the distribution $f_\theta (x) = \theta x^{\theta-1}$, what is the sufficient statistic corresponding to the Monotone Likelihood Ratio?","For the distribution , what is the sufficient statistic corresponding to the Monotone Likelihood Ratio?",f_\theta (x) = \theta x^{\theta-1},"Suppose I have a sequence of iid random variables $X_1, \ldots, X_n$ following the pdf: $$ f_\theta (x) = \theta x^{\theta-1} $$ for $\theta >0$ and $0 <x<1$. I would like to find a sufficient statistic $T(X)$, such that the family $f_\theta (x)$ has a monotone likelihood ratio (MLR) in $T(X)$. I do this by having: $$ \frac{f(x|\theta_1)}{f(x|\theta_2)} = \frac{\prod_{i=1}^{n}\theta_1x_i^{\theta_1-1}}{\prod_{i=1}^{n}\theta_2x_i^{\theta_2-1}} = \left(\frac{\theta_1}{\theta_2}\right)^n \prod_{i=1}^n\left(x_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2} $$ At this point, is the sufficient statistic corresponding to the MLR, $T(X) = \prod_{i=1}^nx_i$? Or would it be: $$ \frac{f(x|\theta_1)}{f(x|\theta_2)}  = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(e^{\sum_{i=1}^n \log(x_i)}\right)^{\theta_1-\theta_2} $$ and hence the sufficient statistic is $\sum_{i=1}^n \log(x_i)$? I understand that sufficient statistics are not unique, but which one of the above is the right answer? Is it $T(X) = \prod_{i=1}^nx_i$ or $T(X) =\sum_{i=1}^n \log(x_i)$ ?","Suppose I have a sequence of iid random variables $X_1, \ldots, X_n$ following the pdf: $$ f_\theta (x) = \theta x^{\theta-1} $$ for $\theta >0$ and $0 <x<1$. I would like to find a sufficient statistic $T(X)$, such that the family $f_\theta (x)$ has a monotone likelihood ratio (MLR) in $T(X)$. I do this by having: $$ \frac{f(x|\theta_1)}{f(x|\theta_2)} = \frac{\prod_{i=1}^{n}\theta_1x_i^{\theta_1-1}}{\prod_{i=1}^{n}\theta_2x_i^{\theta_2-1}} = \left(\frac{\theta_1}{\theta_2}\right)^n \prod_{i=1}^n\left(x_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2} $$ At this point, is the sufficient statistic corresponding to the MLR, $T(X) = \prod_{i=1}^nx_i$? Or would it be: $$ \frac{f(x|\theta_1)}{f(x|\theta_2)}  = \left(\frac{\theta_1}{\theta_2}\right)^n \left(\prod_{i=1}^nx_i\right)^{\theta_1-\theta_2} = \left(\frac{\theta_1}{\theta_2}\right)^n \left(e^{\sum_{i=1}^n \log(x_i)}\right)^{\theta_1-\theta_2} $$ and hence the sufficient statistic is $\sum_{i=1}^n \log(x_i)$? I understand that sufficient statistics are not unique, but which one of the above is the right answer? Is it $T(X) = \prod_{i=1}^nx_i$ or $T(X) =\sum_{i=1}^n \log(x_i)$ ?",,"['probability', 'statistics', 'statistical-inference']"
57,Random but even distribution of AB v. BA,Random but even distribution of AB v. BA,,"I'm a software developer not a statistician, so use small words. :) I'm looking for an algorithm to generate a sequence of AB tests that are randomly distributed to users, but ensures an equal distribution. The sequence must be reproducible using a seed value. (I'll get around to actually finding a software algorithm, but first I need to understand/clarify what I'm trying to do.) So: 6 subjects or 50 or 500 (always an even number). Exactly half the subjects must get test A then test B, the other half must get B then A. The profile cannot be simply AAABBB, since the subject list is not necessarily randomized. It needs to be reproducible. So, a ""seed"" number will ensure I can get that exact same distribution again. The seed also ensures I can guarantee a different sequence if that's what I want. My first shot at this involves a random profile where the second half is ""flipped"", ensuring it's symmetrical. So: 20 subjects, Seed = 314 My simple algorithm just runs through the seed, toggling A to B until it hits the halfway point, then reverses the sequence: 3     1 4       3...       A A A B A A A A B B (flip) A A B B B B A B B B B B B A B B B B A A        B B A A A A B A A A                           ...3 4       1 3 One of the things I've run up against is that, for a small number such as 6, a seed number must be highly constrained, or several different seeds will result in the same profile. So: 6 subjects, Seed = 523 5... A A A (flip) B B B B B B        A A A               ...5 but seed 427 does the same thing: 4... A A A (flip) B B B B B B        A A A               ...5 (In fact, there are so few possible permutations of profiles, the seed itself must be constrained to no more than about 24 or so possible values. Not really a seed anymore. More like 'pick a number from 1 to 24')","I'm a software developer not a statistician, so use small words. :) I'm looking for an algorithm to generate a sequence of AB tests that are randomly distributed to users, but ensures an equal distribution. The sequence must be reproducible using a seed value. (I'll get around to actually finding a software algorithm, but first I need to understand/clarify what I'm trying to do.) So: 6 subjects or 50 or 500 (always an even number). Exactly half the subjects must get test A then test B, the other half must get B then A. The profile cannot be simply AAABBB, since the subject list is not necessarily randomized. It needs to be reproducible. So, a ""seed"" number will ensure I can get that exact same distribution again. The seed also ensures I can guarantee a different sequence if that's what I want. My first shot at this involves a random profile where the second half is ""flipped"", ensuring it's symmetrical. So: 20 subjects, Seed = 314 My simple algorithm just runs through the seed, toggling A to B until it hits the halfway point, then reverses the sequence: 3     1 4       3...       A A A B A A A A B B (flip) A A B B B B A B B B B B B A B B B B A A        B B A A A A B A A A                           ...3 4       1 3 One of the things I've run up against is that, for a small number such as 6, a seed number must be highly constrained, or several different seeds will result in the same profile. So: 6 subjects, Seed = 523 5... A A A (flip) B B B B B B        A A A               ...5 but seed 427 does the same thing: 4... A A A (flip) B B B B B B        A A A               ...5 (In fact, there are so few possible permutations of profiles, the seed itself must be constrained to no more than about 24 or so possible values. Not really a seed anymore. More like 'pick a number from 1 to 24')",,['statistics']
58,Simplifying $\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n)$,Simplifying,\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n),"I would like to show $$\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n) = \dfrac{1}{n}\sum_{i=1}^{n}U_iV_i+\bar{U}_n\bar{V}_n$$ where $\bar{X}_n = \dfrac{1}{n}\sum_{i=1}^{n}X_i$ and similarly for $\bar{Y}_n$, $\bar{U}_n$, and $\bar{V}_n$; $U_i = X_i - \mu_x$, $V_i = Y_i - \mu_y$, where $\mu_x$ and $\mu_y$ are constants. My attempt: $$\begin{align} \frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n) &= \dfrac{1}{n}\sum_{i=1}^{n}[(X_i-\mu_x)-(\bar{X}_n-\mu_x)][(Y_i-\mu_y)-(\bar{Y}_n-\mu_y)] \\ &= \dfrac{1}{n}\sum_{i=1}^{n}(X_i-\mu_x)(Y_i-\mu_y)-\dfrac{2}{n}(\bar{X}_n-\mu_x)(\bar{Y}_n-\mu_y)\\ &+(\bar{X}_n-\mu_x)(\bar{Y}_n-\mu_y)\text{.} \end{align}$$ This doesn't quite match what I'm looking for. Is my desired equation wrong, or is my work wrong?","I would like to show $$\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n) = \dfrac{1}{n}\sum_{i=1}^{n}U_iV_i+\bar{U}_n\bar{V}_n$$ where $\bar{X}_n = \dfrac{1}{n}\sum_{i=1}^{n}X_i$ and similarly for $\bar{Y}_n$, $\bar{U}_n$, and $\bar{V}_n$; $U_i = X_i - \mu_x$, $V_i = Y_i - \mu_y$, where $\mu_x$ and $\mu_y$ are constants. My attempt: $$\begin{align} \frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X}_n)(Y_i - \bar{Y}_n) &= \dfrac{1}{n}\sum_{i=1}^{n}[(X_i-\mu_x)-(\bar{X}_n-\mu_x)][(Y_i-\mu_y)-(\bar{Y}_n-\mu_y)] \\ &= \dfrac{1}{n}\sum_{i=1}^{n}(X_i-\mu_x)(Y_i-\mu_y)-\dfrac{2}{n}(\bar{X}_n-\mu_x)(\bar{Y}_n-\mu_y)\\ &+(\bar{X}_n-\mu_x)(\bar{Y}_n-\mu_y)\text{.} \end{align}$$ This doesn't quite match what I'm looking for. Is my desired equation wrong, or is my work wrong?",,"['statistics', 'summation']"
59,Optimal $\mathbf{W}$'s columns are the generalized eigenvectors in $\mathbf{S}_\text{B}\mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i$,Optimal 's columns are the generalized eigenvectors in,\mathbf{W} \mathbf{S}_\text{B}\mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i,"I am trying to understand Linear Discriminant Analysis (a.k.a. Fisher's discriminant analysis). I am reading this technical report and Christopher Bishop's Pattern Recognition and Machine Learning (section 4.1.4, p.187). Some definitions first: A data point $\mathbf{x}_n$ is defined as a column vector with $M$ components. $\mathbf{X}$ is defined as a $(M, N)$ matrix where columns are the data points $\mathbf{x}_n$ . $K$ is the number of classes. $\mathbf{S}_\text{B}$ : between-class covariance of the data before projection. $\mathbf{S}_\text{W}$ : within-class covariance of the data before projection. $\mathbf{s}_\text{B}$ : between-class covariance of the projected data. $\mathbf{s}_\text{W}$ : within-class covariance of the projected data. The general idea in Fisher's discriminant analysis is to project the data points in $\mathbf{X}$ to a $K - 1$ space that maximizes $\mathbf{s}_\text{B}$ and minimizes $\mathbf{s}_\text{W}$ . In the technical report, the discrimination criterion is defined as $$J(\mathbf{W}) = \frac{|\mathbf{s}_\text{B}|}{|\mathbf{s}_\text{W}|} = \frac{|\mathbf{W}^\mathsf{T}\mathbf{S}_\text{B}\mathbf{W}|}{|\mathbf{W}^\mathsf{T}\mathbf{S}_\text{W}\mathbf{W}|} = \frac{\text{det}(\mathbf{W}^\mathsf{T}\mathbf{S}_\text{B}\mathbf{W})}{\text{det}(\mathbf{W}^\mathsf{T}\mathbf{S}_\text{W}\mathbf{W})}$$ Question $(1)$ arises here: why does maximizing the ratio of the discriminants is a good criterion for maximizing $\mathbf{s}_\text{B}$ and minimizing $\mathbf{s}_\text{W}$ ? (there seems to be a basic linear algebra notion I am missing) Now, right after defining this criterion, they say that the columns of an optimal $\mathbf{W}$ are the generalized eigenvectors $\mathbf{v}_i$ that correspond to the nonzero eigenvalues $\lambda_i$ in $$\mathbf{S}_\text{B} \mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i,$$ subject to the normalization constraint $$\mathbf{v}_i^\mathsf{T}\mathbf{S}_\text{W}\mathbf{v}_i = 1.$$ Now arises question $(2)$ : why is this true? To find the optimal $\mathbf{W}$ , I guess we need to solve $\frac{\partial J(\mathbf{W})}{\partial\mathbf{W}} = 0$ for $\mathbf{W}$ . I started by first noting (from the Matrix Cookbook) that $$\frac{\partial\text{det}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})}{\partial \mathbf{W}} = 2 \text{det}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})\mathbf{A}\mathbf{W}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})^{-1}$$ for any symmetric matrix $\mathbf{A}$ ( $\mathbf{S}_\text{B}$ and $\mathbf{S}_\text{W}$ do are symmetric, since they are covariance matrices). This leads me to the following $$\frac{\partial J(\mathbf{W})}{\partial\mathbf{W}} = \frac{2|\mathbf{W}^\mathsf{T} \mathbf{S}_\text{B}\mathbf{W}|\{ \mathbf{S}_\text{B}\mathbf{W}(\mathbf{W}^\mathsf{T} \mathbf{S}_\text{B}\mathbf{W})^{-1} -  \mathbf{S}_\text{W}\mathbf{W}(\mathbf{W}^\mathsf{T} \mathbf{S}_\text{W}\mathbf{W})^{-1} \}} {|\mathbf{W}^\mathsf{T} \mathbf{S}_\text{W}\mathbf{W}|}$$ But then I'm not sure where I am going and would have liked some insight!","I am trying to understand Linear Discriminant Analysis (a.k.a. Fisher's discriminant analysis). I am reading this technical report and Christopher Bishop's Pattern Recognition and Machine Learning (section 4.1.4, p.187). Some definitions first: A data point is defined as a column vector with components. is defined as a matrix where columns are the data points . is the number of classes. : between-class covariance of the data before projection. : within-class covariance of the data before projection. : between-class covariance of the projected data. : within-class covariance of the projected data. The general idea in Fisher's discriminant analysis is to project the data points in to a space that maximizes and minimizes . In the technical report, the discrimination criterion is defined as Question arises here: why does maximizing the ratio of the discriminants is a good criterion for maximizing and minimizing ? (there seems to be a basic linear algebra notion I am missing) Now, right after defining this criterion, they say that the columns of an optimal are the generalized eigenvectors that correspond to the nonzero eigenvalues in subject to the normalization constraint Now arises question : why is this true? To find the optimal , I guess we need to solve for . I started by first noting (from the Matrix Cookbook) that for any symmetric matrix ( and do are symmetric, since they are covariance matrices). This leads me to the following But then I'm not sure where I am going and would have liked some insight!","\mathbf{x}_n M \mathbf{X} (M, N) \mathbf{x}_n K \mathbf{S}_\text{B} \mathbf{S}_\text{W} \mathbf{s}_\text{B} \mathbf{s}_\text{W} \mathbf{X} K - 1 \mathbf{s}_\text{B} \mathbf{s}_\text{W} J(\mathbf{W}) = \frac{|\mathbf{s}_\text{B}|}{|\mathbf{s}_\text{W}|} = \frac{|\mathbf{W}^\mathsf{T}\mathbf{S}_\text{B}\mathbf{W}|}{|\mathbf{W}^\mathsf{T}\mathbf{S}_\text{W}\mathbf{W}|} = \frac{\text{det}(\mathbf{W}^\mathsf{T}\mathbf{S}_\text{B}\mathbf{W})}{\text{det}(\mathbf{W}^\mathsf{T}\mathbf{S}_\text{W}\mathbf{W})} (1) \mathbf{s}_\text{B} \mathbf{s}_\text{W} \mathbf{W} \mathbf{v}_i \lambda_i \mathbf{S}_\text{B} \mathbf{v}_i = \lambda_i \mathbf{S}_\text{W} \mathbf{v}_i, \mathbf{v}_i^\mathsf{T}\mathbf{S}_\text{W}\mathbf{v}_i = 1. (2) \mathbf{W} \frac{\partial J(\mathbf{W})}{\partial\mathbf{W}} = 0 \mathbf{W} \frac{\partial\text{det}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})}{\partial \mathbf{W}} = 2 \text{det}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})\mathbf{A}\mathbf{W}(\mathbf{W}^\mathsf{T}\mathbf{A}\mathbf{W})^{-1} \mathbf{A} \mathbf{S}_\text{B} \mathbf{S}_\text{W} \frac{\partial J(\mathbf{W})}{\partial\mathbf{W}} = \frac{2|\mathbf{W}^\mathsf{T} \mathbf{S}_\text{B}\mathbf{W}|\{ \mathbf{S}_\text{B}\mathbf{W}(\mathbf{W}^\mathsf{T} \mathbf{S}_\text{B}\mathbf{W})^{-1} - 
\mathbf{S}_\text{W}\mathbf{W}(\mathbf{W}^\mathsf{T} \mathbf{S}_\text{W}\mathbf{W})^{-1}
\}}
{|\mathbf{W}^\mathsf{T} \mathbf{S}_\text{W}\mathbf{W}|}","['linear-algebra', 'statistics', 'machine-learning', 'discriminant']"
60,"In expectation, does conditioning reduce moments beyond the second?","In expectation, does conditioning reduce moments beyond the second?",,"I know that conditioning on a random variable, in expectation, reduces variance. This is a consequence of the law of total variance. Formally, I refer to the following: $$E[Var(x|y)]=Var(x)-Var[E(x|y)]\le Var(x)$$ where equivalence holds only in the case of independence.  My question is whether this type of argumentation extends to higher moments. In particular, is it the case that: $$E[(x-E(x|y))^k]\le E[(x-E(x))^k]$$ for $k>2$ and arbitrary distributions of $x$ and $y$? Intuitively, I believe it must hold for $k$ even, but haven't thought of a suitable proof technique. I'm not sure whether or not it will hold for $k$ odd.","I know that conditioning on a random variable, in expectation, reduces variance. This is a consequence of the law of total variance. Formally, I refer to the following: $$E[Var(x|y)]=Var(x)-Var[E(x|y)]\le Var(x)$$ where equivalence holds only in the case of independence.  My question is whether this type of argumentation extends to higher moments. In particular, is it the case that: $$E[(x-E(x|y))^k]\le E[(x-E(x))^k]$$ for $k>2$ and arbitrary distributions of $x$ and $y$? Intuitively, I believe it must hold for $k$ even, but haven't thought of a suitable proof technique. I'm not sure whether or not it will hold for $k$ odd.",,"['probability', 'statistics', 'probability-distributions']"
61,Expectation of log of linear function of the Dirichlet distribution [closed],Expectation of log of linear function of the Dirichlet distribution [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given $\mathbf{X}\sim\mathsf{Dir}(\alpha_1,\cdots,\alpha_k)$, is there an expression for the expectation $$ \mathbb{E}\left[ \log \left(\mathbf{c}^\top \mathbf{X} \right)\right] $$ where $\mathbf{c}\in\mathbb{R}_+^k$ is a vector of positive constants?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Given $\mathbf{X}\sim\mathsf{Dir}(\alpha_1,\cdots,\alpha_k)$, is there an expression for the expectation $$ \mathbb{E}\left[ \log \left(\mathbf{c}^\top \mathbf{X} \right)\right] $$ where $\mathbf{c}\in\mathbb{R}_+^k$ is a vector of positive constants?",,"['probability', 'integration', 'statistics', 'expectation']"
62,"$95$% confidence interval for $\theta_2-\theta_1$ from $\text{uniform}\left(\theta_1,\theta_2\right)$",% confidence interval for  from,"95 \theta_2-\theta_1 \text{uniform}\left(\theta_1,\theta_2\right)","I want to find a $95$ % confidence interval for $\theta_2-\theta_1$ where $X_1,...,X_n$ are the random sample from $U(\theta_1,\theta_2)$ , the uniform distribution with two parameters $\theta_1, \theta_2$ . I have the maximum likelihood estimators $\hat\theta_1=X_{(1)}$ , the minimum order statistic, and $\hat\theta_2=X_{(n)}$ , the maximum order statistic. But I don't know how to compute the confidence interval of $\theta_2-\theta_1$ . Is there anyone can help me? Thanks for your help","I want to find a % confidence interval for where are the random sample from , the uniform distribution with two parameters . I have the maximum likelihood estimators , the minimum order statistic, and , the maximum order statistic. But I don't know how to compute the confidence interval of . Is there anyone can help me? Thanks for your help","95 \theta_2-\theta_1 X_1,...,X_n U(\theta_1,\theta_2) \theta_1, \theta_2 \hat\theta_1=X_{(1)} \hat\theta_2=X_{(n)} \theta_2-\theta_1","['statistics', 'statistical-inference', 'uniform-distribution', 'parameter-estimation', 'confidence-interval']"
63,standard deviation probability of a poission distribution,standard deviation probability of a poission distribution,,"Just looking for a bit of help on the topic. The question is basically this: Number of drivers who travel between a particular origin and destination during a designated time period has a Poisson distribution with parameter µ = 20. What is the probability that the number of drivers will be within two standard deviations of the mean value? Because it's a Poisson distribution, the expected value and the variance are the same, so mean value = µ = 20. Because the variance is 20, the standard deviation is the squareroot of 20 = 4.47. Two standard deviations is then 4.47*2 = 8.9 Two standard deviations from the mean is (20-8.9 <= x <= 20+8.9) So we're looking for P(11 <= x <= 29). I put it in matlab like so poisscdf(29,20) - poisscdf(11,20) and I get 0.9568 .... the answer however is .945 . I'm just wondering where I went wrong!","Just looking for a bit of help on the topic. The question is basically this: Number of drivers who travel between a particular origin and destination during a designated time period has a Poisson distribution with parameter µ = 20. What is the probability that the number of drivers will be within two standard deviations of the mean value? Because it's a Poisson distribution, the expected value and the variance are the same, so mean value = µ = 20. Because the variance is 20, the standard deviation is the squareroot of 20 = 4.47. Two standard deviations is then 4.47*2 = 8.9 Two standard deviations from the mean is (20-8.9 <= x <= 20+8.9) So we're looking for P(11 <= x <= 29). I put it in matlab like so poisscdf(29,20) - poisscdf(11,20) and I get 0.9568 .... the answer however is .945 . I'm just wondering where I went wrong!",,"['probability', 'statistics', 'poisson-distribution']"
64,Card probability problem: Five cards will be dealt from a well-shuffled deck. Find the chance of getting an ace or a king among the 5 cards.,Card probability problem: Five cards will be dealt from a well-shuffled deck. Find the chance of getting an ace or a king among the 5 cards.,,"Five cards will be dealt from a well-shuffled deck. Find the chance of getting an ace or a king among the 5 cards. I think question means getting at least a king or an ace, and here is my procedure: $p$(an ace or a king among 5 cards)=$p$(at least an ace)+$p$(at least an king)-$p$(ace and king at the same time) $p$(at least an ace)=$1-\frac{48}{52}\times\frac{47}{52}\times\frac{46}{52}\times\frac{45}{52}\times\frac{44}{52}$ $p$(at least an king)=$1-\frac{48}{52}\times\frac{47}{52}\times\frac{46}{52}\times\frac{45}{52}\times\frac{44}{52}$ $p$(ace and king at the same time)=... Here I am stuck because there are many combination that ace and king are together. I feel like I misintepreted the question. Could someone give an insight?","Five cards will be dealt from a well-shuffled deck. Find the chance of getting an ace or a king among the 5 cards. I think question means getting at least a king or an ace, and here is my procedure: $p$(an ace or a king among 5 cards)=$p$(at least an ace)+$p$(at least an king)-$p$(ace and king at the same time) $p$(at least an ace)=$1-\frac{48}{52}\times\frac{47}{52}\times\frac{46}{52}\times\frac{45}{52}\times\frac{44}{52}$ $p$(at least an king)=$1-\frac{48}{52}\times\frac{47}{52}\times\frac{46}{52}\times\frac{45}{52}\times\frac{44}{52}$ $p$(ace and king at the same time)=... Here I am stuck because there are many combination that ace and king are together. I feel like I misintepreted the question. Could someone give an insight?",,"['probability', 'statistics', 'combinations', 'card-games']"
65,"Within a unit square, given n random uniform points, what is the average distance to the nearest k points?","Within a unit square, given n random uniform points, what is the average distance to the nearest k points?",,"Within a unit square, given n random uniform points, what is the average distance to the nearest k points?  To be precise: if k=2 we are averaging the distances of the 1st and 2nd nearest neighbors to point i. Here is a reference for the n=2 k=1 solution. Average distance between two randomly chosen points in unit square (without calculus) (for this question I assume calculus is needed) However, if you rather had n points and were interested in the average distance to the k nearest neighbors is this something that can be solved with an exact answer? I have produced results empirically for 10,000 iterations: n=2, k=1: 0.52 n=3, k=2: 0.52 <- intuitively identical to n=2,k=1 n=5, k=4: 0.52 <- intuitively identical to n=2,k=1 n=3, k=1: 0.39 n=5, k=1: 0.28 n=10, k=1: 0.18 n=10, k=2: 0.24 n=10, k=3: 0.28 n=100, k=5: 0.097","Within a unit square, given n random uniform points, what is the average distance to the nearest k points?  To be precise: if k=2 we are averaging the distances of the 1st and 2nd nearest neighbors to point i. Here is a reference for the n=2 k=1 solution. Average distance between two randomly chosen points in unit square (without calculus) (for this question I assume calculus is needed) However, if you rather had n points and were interested in the average distance to the k nearest neighbors is this something that can be solved with an exact answer? I have produced results empirically for 10,000 iterations: n=2, k=1: 0.52 n=3, k=2: 0.52 <- intuitively identical to n=2,k=1 n=5, k=4: 0.52 <- intuitively identical to n=2,k=1 n=3, k=1: 0.39 n=5, k=1: 0.28 n=10, k=1: 0.18 n=10, k=2: 0.24 n=10, k=3: 0.28 n=100, k=5: 0.097",,"['calculus', 'probability', 'geometry', 'statistics']"
66,Ant is on a vertex of a triangle. What is the expected number of seconds to get back to the original vertex?,Ant is on a vertex of a triangle. What is the expected number of seconds to get back to the original vertex?,,"An Ant is on a vertex of a triangle. Each second, it moves randomly to an adjacent vertex. What is the expected number of seconds before it arrives back at the original vertex? My solution: I dont know how to use markov chains yet, but Im guessing that could be a way to do this. I was wondering if there was an intuitive way to solve this problem. I would have guessed 3 seconds as an answer. I'm assuming that if it is at Vertex A, there is a 1/2 chance of going to Vertex B or C. So minimum number of seconds is 2 seconds. Max number could be infinite if it keeps bouncing back between B and C without returning to A. I'm still not sure how to do this puzzle.","An Ant is on a vertex of a triangle. Each second, it moves randomly to an adjacent vertex. What is the expected number of seconds before it arrives back at the original vertex? My solution: I dont know how to use markov chains yet, but Im guessing that could be a way to do this. I was wondering if there was an intuitive way to solve this problem. I would have guessed 3 seconds as an answer. I'm assuming that if it is at Vertex A, there is a 1/2 chance of going to Vertex B or C. So minimum number of seconds is 2 seconds. Max number could be infinite if it keeps bouncing back between B and C without returning to A. I'm still not sure how to do this puzzle.",,"['probability', 'statistics', 'markov-chains']"
67,Why does this hacky derivation for least-squares regression work?,Why does this hacky derivation for least-squares regression work?,,"Consider the regression problem where we have $m$ measurements of the dependent variable and a model with $n$ degrees of freedom, where $m>n$. We can write the dependent variable measurements in a vector $\mathbf{y}$ (size $m\times 1$) and the model parameters in a vector $\mathbf{x}$ (size $n\times 1$), and arrange the independent measurements appropriately in a matrix $\mathbf{A}$ (size $m\times n$). The problem is now to choose $\mathbf{x}$ such that $\mathbf{y}$ is represented as closely as possible by $\mathbf{A}\mathbf{x}$. The most common way of quantifying ""as closely as possible"" is in the least-squares sense. We write: $$ E = \left(\mathbf{y} - \mathbf{A}\mathbf{x}\right)^T\left(\mathbf{y} - \mathbf{A}\mathbf{x}\right) \tag{1} $$ By taking the derivative of $E$ wrt $\mathbf{x}$ and setting it to zero, we end up with the least-squares solution: $$ \mathbf{x}=\left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y} \tag{2} $$ I once had a professor show me a hacky way to have to neither remember this formula, nor do the tedious derivation in an exam situation. He was very clear that it was a hack and that I should never use it as a serious derivation. It goes as follows - start out by writing: $$ \mathbf{A}\mathbf{x} = \mathbf{y} \tag{3} $$ Observe that we cannot solve this equation by taking the inverse of $\mathbf{A}$ because this is not a square matrix. No problem! - multiply each side by $A^T$ (size $n\times m$) to get: $$ \left(\mathbf{A}^T\mathbf{A}\right) \mathbf{x} = \mathbf{A}^T \mathbf{y} \tag{4} $$ Now $A^T A$ is a square matrix (size $n\times n$), which means it's (potentially) invertible. Multiply each side by $\left(\mathbf{A}^T \mathbf{A}\right)^{-1}$ to get: $$ \mathbf{x} = \left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y} \tag{5} $$ We get the right result, in the least-squares sense! Of course the hack is that, in general, Eq. (3) is not true to begin with; it is an inconsistent equation with no solution. My question is: Is it just pure coincidence that this hack works in this particular case? Or is there perhaps a deeper reason? Maybe an insight as to why it leads to the least-squares solution as opposed to other one? Thank you!","Consider the regression problem where we have $m$ measurements of the dependent variable and a model with $n$ degrees of freedom, where $m>n$. We can write the dependent variable measurements in a vector $\mathbf{y}$ (size $m\times 1$) and the model parameters in a vector $\mathbf{x}$ (size $n\times 1$), and arrange the independent measurements appropriately in a matrix $\mathbf{A}$ (size $m\times n$). The problem is now to choose $\mathbf{x}$ such that $\mathbf{y}$ is represented as closely as possible by $\mathbf{A}\mathbf{x}$. The most common way of quantifying ""as closely as possible"" is in the least-squares sense. We write: $$ E = \left(\mathbf{y} - \mathbf{A}\mathbf{x}\right)^T\left(\mathbf{y} - \mathbf{A}\mathbf{x}\right) \tag{1} $$ By taking the derivative of $E$ wrt $\mathbf{x}$ and setting it to zero, we end up with the least-squares solution: $$ \mathbf{x}=\left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y} \tag{2} $$ I once had a professor show me a hacky way to have to neither remember this formula, nor do the tedious derivation in an exam situation. He was very clear that it was a hack and that I should never use it as a serious derivation. It goes as follows - start out by writing: $$ \mathbf{A}\mathbf{x} = \mathbf{y} \tag{3} $$ Observe that we cannot solve this equation by taking the inverse of $\mathbf{A}$ because this is not a square matrix. No problem! - multiply each side by $A^T$ (size $n\times m$) to get: $$ \left(\mathbf{A}^T\mathbf{A}\right) \mathbf{x} = \mathbf{A}^T \mathbf{y} \tag{4} $$ Now $A^T A$ is a square matrix (size $n\times n$), which means it's (potentially) invertible. Multiply each side by $\left(\mathbf{A}^T \mathbf{A}\right)^{-1}$ to get: $$ \mathbf{x} = \left(\mathbf{A}^T \mathbf{A}\right)^{-1} \mathbf{A} \mathbf{y} \tag{5} $$ We get the right result, in the least-squares sense! Of course the hack is that, in general, Eq. (3) is not true to begin with; it is an inconsistent equation with no solution. My question is: Is it just pure coincidence that this hack works in this particular case? Or is there perhaps a deeper reason? Maybe an insight as to why it leads to the least-squares solution as opposed to other one? Thank you!",,"['matrices', 'statistics', 'regression', 'matrix-calculus', 'least-squares']"
68,"Why $\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^n Cov(X_i,X_j)=\frac{1}{n^2}\sum_{i-j=-n}^n (n-|i-j|)\gamma(i-j)$",Why,"\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^n Cov(X_i,X_j)=\frac{1}{n^2}\sum_{i-j=-n}^n (n-|i-j|)\gamma(i-j)","I'm having trouble to understand a passage in the mean square error of an estimator. Let $\{X_t\}$ be a stationary process of a time series with mean $\mu$, thus the sample mean estimator is $$\overline{X}_n=\frac{1}{n}(X_1+X_2+\dots +X_n)$$ The mean squared error of this estimator is $$E[\overline{X}_n-\mu]^2=Var(\overline{X}_n)$$ since that $\overline{X}_n$ is a unbiased estimator of $\mu$. Then $$Var(\overline{X}_n)=\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^n Cov(X_i,X_j)\qquad (1)$$ $$=\frac{1}{n^2}\sum_{i-j=-n}^n (n-|i-j|)\gamma(i-j)\qquad (2)$$ $$=\frac{1}{n}\sum_{h=-n}^n \Big(1-\frac{|h|}{n}\Big)\gamma (h)$$ where $\gamma (i-j)=Cov(X_{t+(i-j)},X_t)$ and $\gamma(h)=Cov(X_{t+h},X_t)$ (autocovariance function). I can't figure out what they make from (1) to (2). I make a test with $n=1$ and it works, but I don't understand what they did, since in (1) I have a sum with $n^2$ terms and in (2) I have just $2n+1$ terms.","I'm having trouble to understand a passage in the mean square error of an estimator. Let $\{X_t\}$ be a stationary process of a time series with mean $\mu$, thus the sample mean estimator is $$\overline{X}_n=\frac{1}{n}(X_1+X_2+\dots +X_n)$$ The mean squared error of this estimator is $$E[\overline{X}_n-\mu]^2=Var(\overline{X}_n)$$ since that $\overline{X}_n$ is a unbiased estimator of $\mu$. Then $$Var(\overline{X}_n)=\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^n Cov(X_i,X_j)\qquad (1)$$ $$=\frac{1}{n^2}\sum_{i-j=-n}^n (n-|i-j|)\gamma(i-j)\qquad (2)$$ $$=\frac{1}{n}\sum_{h=-n}^n \Big(1-\frac{|h|}{n}\Big)\gamma (h)$$ where $\gamma (i-j)=Cov(X_{t+(i-j)},X_t)$ and $\gamma(h)=Cov(X_{t+h},X_t)$ (autocovariance function). I can't figure out what they make from (1) to (2). I make a test with $n=1$ and it works, but I don't understand what they did, since in (1) I have a sum with $n^2$ terms and in (2) I have just $2n+1$ terms.",,"['sequences-and-series', 'statistics', 'stochastic-processes', 'time-series']"
69,"What is the odd that a data set is distributed according to a Uniform 0,1?","What is the odd that a data set is distributed according to a Uniform 0,1?",,"I have a data set consisting of values in between 0 and 1 and I would like to have a statistic that help me understand if the data is really uniformly (evenly) distributed. I can't find anything so i'm actually using some custom tests -  Given a dataset of n points,  I'm calculating the 'expected distance' between 2 subsequent point (100/n) and I compute the square of the difference between the effective distance of two subsequent ordered point and the expected distance. it's calibrated using my own perception of what's uniformly distributed and what's not. Anybody has something better?","I have a data set consisting of values in between 0 and 1 and I would like to have a statistic that help me understand if the data is really uniformly (evenly) distributed. I can't find anything so i'm actually using some custom tests -  Given a dataset of n points,  I'm calculating the 'expected distance' between 2 subsequent point (100/n) and I compute the square of the difference between the effective distance of two subsequent ordered point and the expected distance. it's calibrated using my own perception of what's uniformly distributed and what's not. Anybody has something better?",,"['probability', 'statistics']"
70,Use moment generating function to show that $f_Y(y)$ has chi squared distrubution,Use moment generating function to show that  has chi squared distrubution,f_Y(y),"Problem in my Stat class Let $Y_1, Y_2,\ldots, Y_n$ be arandom sample of size $n$ from $$f_Y(y)= \frac{1}{\theta } e^{-y/\theta}, \qquad y> 0,\theta > 0$$ Use moment-generating functions to show that the ratio $2n\bar{y}/\theta$ has a chi square distribution with $2n$ degrees of freedom. First question do they mean that $2n\bar{y}$ is the $y$ variable and $\theta$ is the $\theta$ variable? secondly how do you show that anything has a chi squared distribution? Small hints to guide me in the right direction would also be helpful.","Problem in my Stat class Let $Y_1, Y_2,\ldots, Y_n$ be arandom sample of size $n$ from $$f_Y(y)= \frac{1}{\theta } e^{-y/\theta}, \qquad y> 0,\theta > 0$$ Use moment-generating functions to show that the ratio $2n\bar{y}/\theta$ has a chi square distribution with $2n$ degrees of freedom. First question do they mean that $2n\bar{y}$ is the $y$ variable and $\theta$ is the $\theta$ variable? secondly how do you show that anything has a chi squared distribution? Small hints to guide me in the right direction would also be helpful.",,['statistics']
71,How mean change standard deviation?,How mean change standard deviation?,,"A college statistics class conducted a survey of how students spend their money. They asked 25 students to estimate how much money they typically spend each week on fast food. They determined that the mean amount spent on fast food is $31.52$ with a standard deviation of $21.60$. Later they realized that a value entered as $3$ should have been $30$. They recalculate the mean and standard deviation. The mean is now $32.60$. Which of the following is true about the standard deviation? The standard deviation will increase, because we have increased the value of a data point. The standard deviation will stay the same, because the standard deviation is not affected by a change in a single measurement. The standard deviation will decrease, because this change moved a data point closer to the mean.","A college statistics class conducted a survey of how students spend their money. They asked 25 students to estimate how much money they typically spend each week on fast food. They determined that the mean amount spent on fast food is $31.52$ with a standard deviation of $21.60$. Later they realized that a value entered as $3$ should have been $30$. They recalculate the mean and standard deviation. The mean is now $32.60$. Which of the following is true about the standard deviation? The standard deviation will increase, because we have increased the value of a data point. The standard deviation will stay the same, because the standard deviation is not affected by a change in a single measurement. The standard deviation will decrease, because this change moved a data point closer to the mean.",,['statistics']
72,Finding the expectation of the Gamma density function,Finding the expectation of the Gamma density function,,I am confused on how to solve this problem. I understand that there is some relationship along the lines of: $$ \Gamma(\alpha) = \int e^{(-t)}t^{\alpha -1} $$  $$ \Gamma(\alpha) = \int e^{-x/\beta}(x/\beta)^{\alpha -1} $$  $$ \Gamma(\alpha) = 1/(\beta)^{(\alpha-1)}\int e^{-x/\beta}(x)^{\alpha-1} $$  $$ (\beta)^{(\alpha-1)}\Gamma(\alpha) = \int e^{-x/\beta}(x)^{\alpha-1} $$ So the function then simplifies to: $$ 1/\beta $$ Which would be the expectation. However the answer given is $$\alpha\beta $$  So I am not entirely sure what I am doing wrong. Thanks!,I am confused on how to solve this problem. I understand that there is some relationship along the lines of: $$ \Gamma(\alpha) = \int e^{(-t)}t^{\alpha -1} $$  $$ \Gamma(\alpha) = \int e^{-x/\beta}(x/\beta)^{\alpha -1} $$  $$ \Gamma(\alpha) = 1/(\beta)^{(\alpha-1)}\int e^{-x/\beta}(x)^{\alpha-1} $$  $$ (\beta)^{(\alpha-1)}\Gamma(\alpha) = \int e^{-x/\beta}(x)^{\alpha-1} $$ So the function then simplifies to: $$ 1/\beta $$ Which would be the expectation. However the answer given is $$\alpha\beta $$  So I am not entirely sure what I am doing wrong. Thanks!,,"['statistics', 'expectation', 'gamma-distribution']"
73,"Number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots","Number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots",,"From the picture above I have five slots and a bag of balls (three) of color -red, blue and green... Question Now whenever I choose a ball, I note the colour and replace it in the bag, then I randomly keep choosing balls (independent event) until all five slots are filled and put them back in the bag.. How can I derive a formula to find all possible repetitive arrangements (exhaustive approach) with the condition that a MAXIMUM of THREE balls of the same color are in the five slots. Note: I have ask a similar question at Finding the Total number of permutation using a selective formula In the accepted answer, there were five slots and five letters and all arrangements with a maximum of three letters were found using a pattern $3-1-1: \binom5{1,2,2}\binom5{3,1,1}$ $2-2-1: \binom5{2,1,2}\binom5{2,2,1}$ $2-1-1-1: \binom5{1,3,1}\binom5{2,1,1,1}$ $1-1-1-1-1:\binom55\binom5{1,1,1,1,1}$ Now in this question the number of balls and slots varies I would like to build from the pattern above answer using multinomials (since I don't want to write a  new algorithm again)","From the picture above I have five slots and a bag of balls (three) of color -red, blue and green... Question Now whenever I choose a ball, I note the colour and replace it in the bag, then I randomly keep choosing balls (independent event) until all five slots are filled and put them back in the bag.. How can I derive a formula to find all possible repetitive arrangements (exhaustive approach) with the condition that a MAXIMUM of THREE balls of the same color are in the five slots. Note: I have ask a similar question at Finding the Total number of permutation using a selective formula In the accepted answer, there were five slots and five letters and all arrangements with a maximum of three letters were found using a pattern $3-1-1: \binom5{1,2,2}\binom5{3,1,1}$ $2-2-1: \binom5{2,1,2}\binom5{2,2,1}$ $2-1-1-1: \binom5{1,3,1}\binom5{2,1,1,1}$ $1-1-1-1-1:\binom55\binom5{1,1,1,1,1}$ Now in this question the number of balls and slots varies I would like to build from the pattern above answer using multinomials (since I don't want to write a  new algorithm again)",,"['combinatorics', 'statistics', 'combinations']"
74,How high can a Kurtosis value be?,How high can a Kurtosis value be?,,"I am working on computing some summary statistics for a bank that nearly failed during the 2008 crisis. The time series I have is the stock price and returns for this particular bank, spanning 9 years. However, for a period of 5 months in my time series, I have the same daily stock price (the bank had its shares suspended from trading). I am computing some summary statistics on the returns of this particular bank, and I obtained a very high Kurtosis of 374 (I expected a high Kurtosis, but not that high). As such, how high can a Kurtosis value be? And if I keep the 374, does it make my computations seem dodgy? Sorry for this very trivial question, but I am quite interested to know whether it is too high for a bank that nearly failed.","I am working on computing some summary statistics for a bank that nearly failed during the 2008 crisis. The time series I have is the stock price and returns for this particular bank, spanning 9 years. However, for a period of 5 months in my time series, I have the same daily stock price (the bank had its shares suspended from trading). I am computing some summary statistics on the returns of this particular bank, and I obtained a very high Kurtosis of 374 (I expected a high Kurtosis, but not that high). As such, how high can a Kurtosis value be? And if I keep the 374, does it make my computations seem dodgy? Sorry for this very trivial question, but I am quite interested to know whether it is too high for a bank that nearly failed.",,['statistics']
75,Sufficient statistic of one parameter,Sufficient statistic of one parameter,,"If $Y_1,\ldots,Y_n$ independent each having pdf: $$ f(y\mid \beta,\theta, x)=\theta e^{-\theta(y-\beta x)},~~ y>\beta x$$ where $x_1,\ldots,x_n$ are given, the parameters $\beta$ and $\theta$ are unknown. I know the joint sufficent statistics for $\beta$ and $\theta$ are $\overline{Y}$ and $\min\{Y_i/X_i\}$. But can I say that the sufficient statistic for $\beta$ is $\min\{Y_i/X_i\}$? I don't know why, but I feel strange calculating sufficient statistics for only part of the parameters.","If $Y_1,\ldots,Y_n$ independent each having pdf: $$ f(y\mid \beta,\theta, x)=\theta e^{-\theta(y-\beta x)},~~ y>\beta x$$ where $x_1,\ldots,x_n$ are given, the parameters $\beta$ and $\theta$ are unknown. I know the joint sufficent statistics for $\beta$ and $\theta$ are $\overline{Y}$ and $\min\{Y_i/X_i\}$. But can I say that the sufficient statistic for $\beta$ is $\min\{Y_i/X_i\}$? I don't know why, but I feel strange calculating sufficient statistics for only part of the parameters.",,"['probability', 'statistics']"
76,An estimator whose variance attains Cramer-Rao lower bound is consistent,An estimator whose variance attains Cramer-Rao lower bound is consistent,,If the variance of an estimator attains the Cramer-Rao lower bound   then the estimator is $(A)$ most efficient $(B)$ sufficient $(C)$ consistent $(D)$ admissible I can show that the the variance is most efficient. But I'm unable to test whether it is consistent or NOT. Please help me.,If the variance of an estimator attains the Cramer-Rao lower bound   then the estimator is $(A)$ most efficient $(B)$ sufficient $(C)$ consistent $(D)$ admissible I can show that the the variance is most efficient. But I'm unable to test whether it is consistent or NOT. Please help me.,,"['probability', 'statistics', 'statistical-inference']"
77,Suggestions for Constructing a Random Variables from Correlated Observations,Suggestions for Constructing a Random Variables from Correlated Observations,,"Let $\mathcal{X} \neq \phi $ be a finite set. Let $P_{XY_1Y_2}$ be a fixed  joint distribution over $\mathcal{X}\times\mathcal{X}\times\mathcal{X}\ $ and that a random sample $(X,Y_1,Y_2 )$ is drawn using $P_{XY_1Y_2}$. Suppose there are two parties, $A$ and $B$ such that $A$ gets to observes $Y_1$ and $B$ gets to observes $Y_2$. Additionally $A$ knows the conditional distribution $P_{Y_1|X}$ and similarly $B$ knows the distribution $P_{Y_2|X}$. I'm interested in finding a method which makes party $A$ construct $\hat{X}_1$ using the information $P_{Y_1|X}$ and $Y_1$ and similarly $B$ construct $\hat{X}_2$ using the information $P_{Y_2|X}$ and $Y_2$ such that $P(\hat{X}_1 \neq \hat{X}_2)$ is 'small' and $P(\hat{X}_1\neq X)$ is 'small'. In other words I am interested in constructing a random variable based on correlated observations. I do agree that the problem is not well posed. I look for only informal suggestions. Any relevant literature would also be really helpful. Thanks in advance for your help.","Let $\mathcal{X} \neq \phi $ be a finite set. Let $P_{XY_1Y_2}$ be a fixed  joint distribution over $\mathcal{X}\times\mathcal{X}\times\mathcal{X}\ $ and that a random sample $(X,Y_1,Y_2 )$ is drawn using $P_{XY_1Y_2}$. Suppose there are two parties, $A$ and $B$ such that $A$ gets to observes $Y_1$ and $B$ gets to observes $Y_2$. Additionally $A$ knows the conditional distribution $P_{Y_1|X}$ and similarly $B$ knows the distribution $P_{Y_2|X}$. I'm interested in finding a method which makes party $A$ construct $\hat{X}_1$ using the information $P_{Y_1|X}$ and $Y_1$ and similarly $B$ construct $\hat{X}_2$ using the information $P_{Y_2|X}$ and $Y_2$ such that $P(\hat{X}_1 \neq \hat{X}_2)$ is 'small' and $P(\hat{X}_1\neq X)$ is 'small'. In other words I am interested in constructing a random variable based on correlated observations. I do agree that the problem is not well posed. I look for only informal suggestions. Any relevant literature would also be really helpful. Thanks in advance for your help.",,"['probability', 'statistics', 'stochastic-processes', 'statistical-inference']"
78,What does it mean for a pdf to have this property?,What does it mean for a pdf to have this property?,,"What does it mean for a probability density function $f(x)$ to have the following property?   $$1+\int_{x=0}^{\infty}x^2 \left(\frac{f'(x)^2}{f(x)}-f''(x)\right)dx>0$$ I have tried a lot to simplify this condition and see what it means (in terms of moments of $f(x)$, etc), but no luck yet. Do you have any idea?","What does it mean for a probability density function $f(x)$ to have the following property?   $$1+\int_{x=0}^{\infty}x^2 \left(\frac{f'(x)^2}{f(x)}-f''(x)\right)dx>0$$ I have tried a lot to simplify this condition and see what it means (in terms of moments of $f(x)$, etc), but no luck yet. Do you have any idea?",,"['probability', 'statistics', 'probability-distributions', 'stochastic-processes', 'stochastic-calculus']"
79,Find the PMF for number of heads following the first tail on a four consecutive coin toss expriment,Find the PMF for number of heads following the first tail on a four consecutive coin toss expriment,,"Suppose a fair coin is toss four times consecutively. Find the PMF for random variable of number of heads following the first tail. My take: Let random variable $X$ be the number of heads in this experiment. Then $X\sim Binomial(4, 0.5)$. Hence, $P(X=k) = \binom{4}{k}{0.5}^{k}{0.5}^{4-k}$, for $k = 0, 1, 2, 3, 4$. Let A denote the event which the first toss is tail in this experiment. Then we know that $P(A)=0.5$. Let random variable $Y$ be number of heads following the first tail. Then $P(Y=y)=P(X=k\mid A)$, for $y = 0, 1, 2, 3$. However, I think my reasoning is not valid since $k=4$ is impossible, but it's my only intuition. Can someone please enlighten me on this question or this type of question in general? Many thanks, Sebastian","Suppose a fair coin is toss four times consecutively. Find the PMF for random variable of number of heads following the first tail. My take: Let random variable $X$ be the number of heads in this experiment. Then $X\sim Binomial(4, 0.5)$. Hence, $P(X=k) = \binom{4}{k}{0.5}^{k}{0.5}^{4-k}$, for $k = 0, 1, 2, 3, 4$. Let A denote the event which the first toss is tail in this experiment. Then we know that $P(A)=0.5$. Let random variable $Y$ be number of heads following the first tail. Then $P(Y=y)=P(X=k\mid A)$, for $y = 0, 1, 2, 3$. However, I think my reasoning is not valid since $k=4$ is impossible, but it's my only intuition. Can someone please enlighten me on this question or this type of question in general? Many thanks, Sebastian",,"['probability', 'statistics', 'probability-distributions', 'random-variables']"
80,The standard deviation is more stable than the mean?,The standard deviation is more stable than the mean?,,"In an introduction to the subject of hypothesis testing, a book on probability and statistics for engineering students has a statement asserting that ""the standard deviation is more stable than the mean' (paraphrased). The context is paraphrased as follows: A machine packs packages of powered sugar. If the machine works properly, then the weight of each package is normally distributed with a mean 0.5kg and a standard deviation 0.015kg. One day, a worker randomly selected 9 bags of powered sugar packed by the machine, with the following weights: 0.497kg, 0.506kg, 0.518kg, 0.524kg, 0.498kg, 0.511kg, 0.520kg, 0.515kg, 0.512kg Use this to decide whether the machine was working properly. In order the derive a solution, the books does the following (still paraphrased): Let the random variable $X$ denote the weight of a package of powered sugar on this particular day, and let $\mu$ and $\sigma$ denote the mean and the standard deviation of $X$ respectively. Experience suggests that the standard deviation is more stable than the mean. So we may suppose that $\sigma=0.015$ . Thus $X\sim \mathcal{N}(\mu, 0.015^2)$ , with $\mu$ unknown. With this in mind, we propose two hypotheses: $$H_0: \mu = 0.5, \qquad H_1: \mu\neq 0.5.$$ We want to use the data available to decide which one to accept. The book then proceeds to introduce the statistic $$ \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$$ to do the hypothesis testing. The questionable assumption about the standard deviation being equal to 0.015 aside, I want to know whether it is true that 'experience suggests that the standard deviation is more stable than the mean'. And if this is true, do we have a theoretical explanation? I was thinking that perhaps we could interpret it this way: Denote the weight of a package produced by the machine when it is working properly by the random variable $Y$ , then $Y\sim \mathcal{N}(\lambda, \theta^2)$ , for some $\lambda$ and $\theta>0$ . Then taking all possible factors into account, maybe we could view the weight of a package produced by the machine in each possible state (broken or not) as a new variable $Y_i\sim \mathcal{N}(\lambda, \theta^2)$ , with all the $Y_i$ independent and indentically distributed. Then the statement is saying that for an $n$ large enough $$ D(\bar{Y}) \geq D(S), \tag{1}$$ where $\bar{Y}$ is the sample mean $\bar{Y}=\frac{1}{n}\sum_{i=1}^n Y_i$ , and $S$ is the sample standard deviation, with $S^2=\frac{1}{n-1}\sum_{i=1}^n (Y_i-\bar{Y})^2$ . But it is not very difficult to see that Inequality $(1)$ is not always true. Failing to find any reference about this statement, I ask for your help!","In an introduction to the subject of hypothesis testing, a book on probability and statistics for engineering students has a statement asserting that ""the standard deviation is more stable than the mean' (paraphrased). The context is paraphrased as follows: A machine packs packages of powered sugar. If the machine works properly, then the weight of each package is normally distributed with a mean 0.5kg and a standard deviation 0.015kg. One day, a worker randomly selected 9 bags of powered sugar packed by the machine, with the following weights: 0.497kg, 0.506kg, 0.518kg, 0.524kg, 0.498kg, 0.511kg, 0.520kg, 0.515kg, 0.512kg Use this to decide whether the machine was working properly. In order the derive a solution, the books does the following (still paraphrased): Let the random variable denote the weight of a package of powered sugar on this particular day, and let and denote the mean and the standard deviation of respectively. Experience suggests that the standard deviation is more stable than the mean. So we may suppose that . Thus , with unknown. With this in mind, we propose two hypotheses: We want to use the data available to decide which one to accept. The book then proceeds to introduce the statistic to do the hypothesis testing. The questionable assumption about the standard deviation being equal to 0.015 aside, I want to know whether it is true that 'experience suggests that the standard deviation is more stable than the mean'. And if this is true, do we have a theoretical explanation? I was thinking that perhaps we could interpret it this way: Denote the weight of a package produced by the machine when it is working properly by the random variable , then , for some and . Then taking all possible factors into account, maybe we could view the weight of a package produced by the machine in each possible state (broken or not) as a new variable , with all the independent and indentically distributed. Then the statement is saying that for an large enough where is the sample mean , and is the sample standard deviation, with . But it is not very difficult to see that Inequality is not always true. Failing to find any reference about this statement, I ask for your help!","X \mu \sigma X \sigma=0.015 X\sim \mathcal{N}(\mu, 0.015^2) \mu H_0: \mu = 0.5, \qquad H_1: \mu\neq 0.5.  \frac{\bar{X}-\mu}{\sigma/\sqrt{n}} Y Y\sim \mathcal{N}(\lambda, \theta^2) \lambda \theta>0 Y_i\sim \mathcal{N}(\lambda, \theta^2) Y_i n  D(\bar{Y}) \geq D(S), \tag{1} \bar{Y} \bar{Y}=\frac{1}{n}\sum_{i=1}^n Y_i S S^2=\frac{1}{n-1}\sum_{i=1}^n (Y_i-\bar{Y})^2 (1)","['probability', 'statistics', 'normal-distribution', 'standard-deviation', 'means']"
81,Variance of Least Squares Estimator for Affine Model,Variance of Least Squares Estimator for Affine Model,,"Suppose a fit a line using the method of least squares to $n$ points, all the standard statistical assumptions hold, and I want to estimate that line at a new point, $x_0$. Denoting that value by $\hat{y_0}$, the estimate is given by: $$\hat{y_0} = \hat{\beta_0} + \hat{\beta_1}x_0$$ Where $$\hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}$$ and $$\hat{\beta_1} = \frac{\sum_{i=1}^n (x_i-\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}$$ I now want an expression for the variance of $\hat{y_0}$. I tried to do it as follows: $$V(\hat{y_0}) = V(\hat{\beta_0}) + V(\hat{\beta_1}x_0) + 2Cov(\hat{\beta_0},\hat\beta_1x_0)$$ Where $V(\hat{\beta_0}) = 0$ since $\beta_0$ is constant by definition (depending on the sample means). I also think that the covariance term should be zero because $E(\hat{\beta_0}\hat{\beta_1x_0}) = E(\hat\beta_0)(\hat\beta_1x_0)$ intuitively, but I haven't proven this. I'm not sure what to do about the middle term -- do I just hammer out the computation? Advice/Solution would be appreciated. Note: this is a review question for a test I have tomorrow, not homework. I need to understand this.","Suppose a fit a line using the method of least squares to $n$ points, all the standard statistical assumptions hold, and I want to estimate that line at a new point, $x_0$. Denoting that value by $\hat{y_0}$, the estimate is given by: $$\hat{y_0} = \hat{\beta_0} + \hat{\beta_1}x_0$$ Where $$\hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}$$ and $$\hat{\beta_1} = \frac{\sum_{i=1}^n (x_i-\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2}$$ I now want an expression for the variance of $\hat{y_0}$. I tried to do it as follows: $$V(\hat{y_0}) = V(\hat{\beta_0}) + V(\hat{\beta_1}x_0) + 2Cov(\hat{\beta_0},\hat\beta_1x_0)$$ Where $V(\hat{\beta_0}) = 0$ since $\beta_0$ is constant by definition (depending on the sample means). I also think that the covariance term should be zero because $E(\hat{\beta_0}\hat{\beta_1x_0}) = E(\hat\beta_0)(\hat\beta_1x_0)$ intuitively, but I haven't proven this. I'm not sure what to do about the middle term -- do I just hammer out the computation? Advice/Solution would be appreciated. Note: this is a review question for a test I have tomorrow, not homework. I need to understand this.",,"['statistics', 'regression', 'estimation', 'least-squares', 'variance']"
82,GMM with full and diagonal covariances,GMM with full and diagonal covariances,,"I have Gaussian Mixture Model-- distribution  with probability density function, that is a weighted sum of Gaussian probability density functions: \begin{equation} p(X)=\sum_{i=1}^k \omega_i\mathcal{N}(X,\mu_i,\Sigma_i)=\sum_{i=1}^k \omega_ip_i(X), \end{equation} where $k$ is the number of components, $\mathcal{N}(X,\mu_i,\Sigma_i), i=1,...,k$ are Gaussian densities with expectations (vectors) $\mu_i,i=1,...,k$ and covariance matrices $\Sigma_i,i=1,...,k$, $\omega_i,i=1,...,k$ are weights: $\sum_{i=1}^k \omega_i=1.$ Covariance matrices $\Sigma_i,i=1,...,k$,are full -- have correlation elements (non-zero non-diagonal elements). How I can approximate this GMM via GMM with components with diagonal covariances. It is understood, that it will be more components in the weighted sum, but they will be diagonal.  Here on page 2 in is written, that it is possible (but without proof) : https://www.ll.mit.edu/mission/cybersec/publications/publication-files/full_papers/0802_Reynolds_Biometrics-GMM.pdf ""It is also important to note that because the component Gaussian are  acting together to model the overall feature density, full covariance  matrices are not necessary even if the features are not statistically  independent. The linear combination of diagonal covariance basis Gaussians  is capable of modeling the correlations between feature vector elements.  The effect of using a set of M full covariance matrix Gaussians can be  equally obtained by using a larger set of diagonal covariance Gaussians. "" But how it can be done and what can be say if to compare cost of calculations for these 2 cases? Is it faster to use in calculations more components, but diagonal? Thank you.","I have Gaussian Mixture Model-- distribution  with probability density function, that is a weighted sum of Gaussian probability density functions: \begin{equation} p(X)=\sum_{i=1}^k \omega_i\mathcal{N}(X,\mu_i,\Sigma_i)=\sum_{i=1}^k \omega_ip_i(X), \end{equation} where $k$ is the number of components, $\mathcal{N}(X,\mu_i,\Sigma_i), i=1,...,k$ are Gaussian densities with expectations (vectors) $\mu_i,i=1,...,k$ and covariance matrices $\Sigma_i,i=1,...,k$, $\omega_i,i=1,...,k$ are weights: $\sum_{i=1}^k \omega_i=1.$ Covariance matrices $\Sigma_i,i=1,...,k$,are full -- have correlation elements (non-zero non-diagonal elements). How I can approximate this GMM via GMM with components with diagonal covariances. It is understood, that it will be more components in the weighted sum, but they will be diagonal.  Here on page 2 in is written, that it is possible (but without proof) : https://www.ll.mit.edu/mission/cybersec/publications/publication-files/full_papers/0802_Reynolds_Biometrics-GMM.pdf ""It is also important to note that because the component Gaussian are  acting together to model the overall feature density, full covariance  matrices are not necessary even if the features are not statistically  independent. The linear combination of diagonal covariance basis Gaussians  is capable of modeling the correlations between feature vector elements.  The effect of using a set of M full covariance matrix Gaussians can be  equally obtained by using a larger set of diagonal covariance Gaussians. "" But how it can be done and what can be say if to compare cost of calculations for these 2 cases? Is it faster to use in calculations more components, but diagonal? Thank you.",,"['matrices', 'statistics', 'probability-distributions', 'stochastic-calculus', 'stochastic-analysis']"
83,Average volume of set of cubes using the mean and variance of its side lengths.,Average volume of set of cubes using the mean and variance of its side lengths.,,"First, i tried this question: The side lengths of a set of squares have an average of 5 and variance of 4. What is their average area? Let X = The Side Length From this question , I knew we had to calculate $E(X^2)$. i.e. $$Var(X) = E(X^2) - E(X)^2$$ and as, $$Var(X) = 4, E(X) = 5$$ The average area of the set of squares is therefore $E(X^2) = 29$. However, if the question were talking about a set of cubes, how would you work out their average volume? Is it possible from just the information given? (Does it involve $E(X^3)$ by any chance too?)","First, i tried this question: The side lengths of a set of squares have an average of 5 and variance of 4. What is their average area? Let X = The Side Length From this question , I knew we had to calculate $E(X^2)$. i.e. $$Var(X) = E(X^2) - E(X)^2$$ and as, $$Var(X) = 4, E(X) = 5$$ The average area of the set of squares is therefore $E(X^2) = 29$. However, if the question were talking about a set of cubes, how would you work out their average volume? Is it possible from just the information given? (Does it involve $E(X^3)$ by any chance too?)",,['statistics']
84,Help Understanding Difference in P-Value & Critical Value Results,Help Understanding Difference in P-Value & Critical Value Results,,"I'd appreciate help in understanding how changing the significance level effects the results of the t-test. I have conducted an experiment where a group of 15 participants took a test, played a game, and took the original test again. The data set follows: Round 1 (Before Game) Scores: 6,  4, 7,  8, 12,  6,  7,  5, 11,  4,  7,  1,  6, 10,  4 Round 2 (After Game) Scores: 2,  3,  7, 11, 11,  9,  7, 12,  5, 15, 11, 11,  7,  4,  7 mean test score before game play: 6.53 mean test score after game play: 8.13 Accordingly I formulated a null hypothesis that game play does not effect test scores and an alternative hypothesis that game play increases scores (see below). Using the data and R I calculated the t-statistic, critical value, and p-value $H_0: \mu_0 = 6.53$ and $H_1: \mu_1 > 6.53$ $\alpha = 0.05, \mu_0 = 6.53, \overline x = 8.13, \sigma = 3.70, n = 15$ $$ t = \frac{8.13 - 6.53}{\frac{3.70}{\sqrt 15}} = 1.67 $$ Critical value = 1.76 and p-value = 0.94 T-value < Critical Value $ \to $ $1.67 < 1.76 \therefore$ accept $H_0$ $p-value > \alpha$ $\to 0.94 > 0.5 \therefore$ accept $H_0$ But when I re-calculate with a  $\alpha$ of 0.1 the critical value changes to 1.35, while the p-value stays the same at 0.94. At this point, accepting/rejecting diverges based on which value comparison is made. Did I make a mistake in the calculation or am I misunderstanding some other factor(s)? Thanks.","I'd appreciate help in understanding how changing the significance level effects the results of the t-test. I have conducted an experiment where a group of 15 participants took a test, played a game, and took the original test again. The data set follows: Round 1 (Before Game) Scores: 6,  4, 7,  8, 12,  6,  7,  5, 11,  4,  7,  1,  6, 10,  4 Round 2 (After Game) Scores: 2,  3,  7, 11, 11,  9,  7, 12,  5, 15, 11, 11,  7,  4,  7 mean test score before game play: 6.53 mean test score after game play: 8.13 Accordingly I formulated a null hypothesis that game play does not effect test scores and an alternative hypothesis that game play increases scores (see below). Using the data and R I calculated the t-statistic, critical value, and p-value $H_0: \mu_0 = 6.53$ and $H_1: \mu_1 > 6.53$ $\alpha = 0.05, \mu_0 = 6.53, \overline x = 8.13, \sigma = 3.70, n = 15$ $$ t = \frac{8.13 - 6.53}{\frac{3.70}{\sqrt 15}} = 1.67 $$ Critical value = 1.76 and p-value = 0.94 T-value < Critical Value $ \to $ $1.67 < 1.76 \therefore$ accept $H_0$ $p-value > \alpha$ $\to 0.94 > 0.5 \therefore$ accept $H_0$ But when I re-calculate with a  $\alpha$ of 0.1 the critical value changes to 1.35, while the p-value stays the same at 0.94. At this point, accepting/rejecting diverges based on which value comparison is made. Did I make a mistake in the calculation or am I misunderstanding some other factor(s)? Thanks.",,"['statistics', 'hypothesis-testing']"
85,What's the probability to win (or lose) this solitaire? [duplicate],What's the probability to win (or lose) this solitaire? [duplicate],,"This question already has answers here : Combinatorial card game [duplicate] (3 answers) Closed 8 years ago . Me and my friends used to play a ""solitaire"" and always asked ourselves which are the odds to win, or lose. I studied Maths and many of them did as well, but nobody could find a good answer to this question. The solitaire goes as follows: get a regular deck of 52 cards and start flipping cards one at a time. When you flip the first card, you say ""one"": if the card is actually a ""one"", that is, an ace, then you lose the game. If not, you move on flipping another card and saying ""two"": as above, you lose if the flipped card is actually a two. You do the same for the number $3$ and then you switch back to one, that is, you say ""one"" by flipping the fourth card (supposing you haven't lost the game yet). My questions are: What are the the odds of going through the whole deck of cards without saying the number of the card you are flipping, i.e. the odds of winning this game? Does the number of cards in the deck make a difference? For example, would it be more or less likely to win if I had a deck of $48$ cards, from which I took out the queens? Does the numbers you say make a difference? For example, would it been more or less likely to win if I said ""one, two, three, four , one, two, ..."" while flipping the cards, instead of ""one, two, three, one, ...""? The only information I got is that it is extremely hard to win this game. Anyway, it is not impossible (so far, I have seen me or my friends win about $5$ times). My attempts to directly calculate probabilities, using combinatorics techniques, failed utterly. Thanks!","This question already has answers here : Combinatorial card game [duplicate] (3 answers) Closed 8 years ago . Me and my friends used to play a ""solitaire"" and always asked ourselves which are the odds to win, or lose. I studied Maths and many of them did as well, but nobody could find a good answer to this question. The solitaire goes as follows: get a regular deck of 52 cards and start flipping cards one at a time. When you flip the first card, you say ""one"": if the card is actually a ""one"", that is, an ace, then you lose the game. If not, you move on flipping another card and saying ""two"": as above, you lose if the flipped card is actually a two. You do the same for the number $3$ and then you switch back to one, that is, you say ""one"" by flipping the fourth card (supposing you haven't lost the game yet). My questions are: What are the the odds of going through the whole deck of cards without saying the number of the card you are flipping, i.e. the odds of winning this game? Does the number of cards in the deck make a difference? For example, would it be more or less likely to win if I had a deck of $48$ cards, from which I took out the queens? Does the numbers you say make a difference? For example, would it been more or less likely to win if I said ""one, two, three, four , one, two, ..."" while flipping the cards, instead of ""one, two, three, one, ...""? The only information I got is that it is extremely hard to win this game. Anyway, it is not impossible (so far, I have seen me or my friends win about $5$ times). My attempts to directly calculate probabilities, using combinatorics techniques, failed utterly. Thanks!",,"['probability', 'combinatorics', 'statistics', 'recreational-mathematics']"
86,The expression of the sum of infinite gaussian functions,The expression of the sum of infinite gaussian functions,,"Let $f(x|\mu,\sigma^2)$ be the gaussian function (normal distribution): $$f(x|\mu,\sigma^2)=\frac{1}{\sigma\sqrt{2\pi}}e^{ -\frac{(x-\mu)^2}{2\sigma^2} }$$ We know its integral over $\mathbb{R}$ is 1. Now we divide the interval $[0,1]$ into $n$ subintervals, each with an equal length of $1/n$. For each subinterval $[\frac{i-1}{n},\frac{i}{n}], (i=1,2,\cdots,n)$, there is a function $g_i(x)$: $$g_i(x)=\frac{1}{n}f(x|\frac{i-0.5}{n},\sigma^2)$$ Namely, a rescaled gaussian function whose mean is the center of the subinterval and integral over $\mathbb{R}$ is $1/n$. Add them together: $$G(x) = \sum_{i=1}^n g_i(x)$$ Problem: What's the expression of $G(x)$ when $n\rightarrow \infty$ ? I simulated the result in Matlab by setting $n=10, \sigma=0.08$: ($g_i(x)$ in blue and $G(x)$ in red) By the way, I plan to use $G(x)$ in image processing, so an analytical expression that can be computed directly may be more useful than a mathematical strict yet confusing solution (such as a series). Common special functions like Bessel function are also OK. And necessary approximation will also be acceptable. Thank you in advance.","Let $f(x|\mu,\sigma^2)$ be the gaussian function (normal distribution): $$f(x|\mu,\sigma^2)=\frac{1}{\sigma\sqrt{2\pi}}e^{ -\frac{(x-\mu)^2}{2\sigma^2} }$$ We know its integral over $\mathbb{R}$ is 1. Now we divide the interval $[0,1]$ into $n$ subintervals, each with an equal length of $1/n$. For each subinterval $[\frac{i-1}{n},\frac{i}{n}], (i=1,2,\cdots,n)$, there is a function $g_i(x)$: $$g_i(x)=\frac{1}{n}f(x|\frac{i-0.5}{n},\sigma^2)$$ Namely, a rescaled gaussian function whose mean is the center of the subinterval and integral over $\mathbb{R}$ is $1/n$. Add them together: $$G(x) = \sum_{i=1}^n g_i(x)$$ Problem: What's the expression of $G(x)$ when $n\rightarrow \infty$ ? I simulated the result in Matlab by setting $n=10, \sigma=0.08$: ($g_i(x)$ in blue and $G(x)$ in red) By the way, I plan to use $G(x)$ in image processing, so an analytical expression that can be computed directly may be more useful than a mathematical strict yet confusing solution (such as a series). Common special functions like Bessel function are also OK. And necessary approximation will also be acceptable. Thank you in advance.",,"['calculus', 'statistics', 'special-functions']"
87,What is the standard deviation of the sample distribution for the sample standard deviation?,What is the standard deviation of the sample distribution for the sample standard deviation?,,"I know that for the sample distribution for the sample mean given a large sample or a normal underlying distribution, the mean of the sample distribution is the population mean of the underlying population and the standard deviation of the sample distribution is the standard deviation of the underlying population divided by the square root of the sample size. I also know that in general, the mean of a sample distribution for an unbiased estimator is the population parameter that is estimated. Assuming that the sample size is large, what is the standard deviation of the sample distribution of a sample statistic, say, the sample standard deviation?","I know that for the sample distribution for the sample mean given a large sample or a normal underlying distribution, the mean of the sample distribution is the population mean of the underlying population and the standard deviation of the sample distribution is the standard deviation of the underlying population divided by the square root of the sample size. I also know that in general, the mean of a sample distribution for an unbiased estimator is the population parameter that is estimated. Assuming that the sample size is large, what is the standard deviation of the sample distribution of a sample statistic, say, the sample standard deviation?",,"['statistics', 'statistical-inference']"
88,"Using the normal approximation, what is the $z$-value of a sample difference of $\hat p_1−\hat p_2=−0.18$? [closed]","Using the normal approximation, what is the -value of a sample difference of ? [closed]",z \hat p_1−\hat p_2=−0.18,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question A few concepts from my textbook that I do not understand: If the Random, Normal, and Independent conditions are met, then is it true that $\hat p_1+2\hat p_2$ is approximately normally distributed? My instinct is that it would remain normal, since both the mean and standard deviation of $\hat p_2$, which is itself normal, would be multiplied by a constant $-2$? When Anne and Carl play tennis, Anne has a $50\%$ chance of winning each game, and when Billy and Carl play, Billy has a $40\%$ chance of winning each game. Anne and Billy each play Carl $25$ times. If $\hat p_1$ is Anne's sample proportion of wins and $\hat p_2$ is Billy's sample proportion of wins, then $\hat p_1−\hat p_2$ may be approximated by a normal distribution. Using this approximation, what is the $z$-value of a sample difference of $\hat p_1−\hat p_2=−0.18$? I'm not sure how to approach this; should I use the probabilities in the two-sample Z formula and use the result of approximately $-1.286$? Thanks!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question A few concepts from my textbook that I do not understand: If the Random, Normal, and Independent conditions are met, then is it true that $\hat p_1+2\hat p_2$ is approximately normally distributed? My instinct is that it would remain normal, since both the mean and standard deviation of $\hat p_2$, which is itself normal, would be multiplied by a constant $-2$? When Anne and Carl play tennis, Anne has a $50\%$ chance of winning each game, and when Billy and Carl play, Billy has a $40\%$ chance of winning each game. Anne and Billy each play Carl $25$ times. If $\hat p_1$ is Anne's sample proportion of wins and $\hat p_2$ is Billy's sample proportion of wins, then $\hat p_1−\hat p_2$ may be approximated by a normal distribution. Using this approximation, what is the $z$-value of a sample difference of $\hat p_1−\hat p_2=−0.18$? I'm not sure how to approach this; should I use the probabilities in the two-sample Z formula and use the result of approximately $-1.286$? Thanks!",,"['probability', 'statistics', 'normal-distribution', 'statistical-inference']"
89,Bayesian probability on Bernoulli distribution,Bayesian probability on Bernoulli distribution,,"Let $D$ be a Bernoulli distribution with $P[X=1] = \theta$ (and so $P[X=0]=1-\theta$). Let $\chi = \{0,1\}$ be an iid sample drawn from $D$. Assume a prior distribution on $\theta$, with $\theta$ uniformly distributed between 0 and .25. What is the value of $p(\theta)$ for $\theta=\frac{1}{8}$?What is the value of $p(\theta \vert \chi)$ for $\theta=\frac{1}{8}$? I'm confused by what the question is asking for, and how everything ties together. There are other parts, but I think if I can grasp what's happening here I will be able to figure out the rest. I think I am supposed to be finding the probability that the random variable $\theta$ takes on the value of $\frac{1}{8}$ given that it is uniformly distributed over the interval [0,$\frac{1}{4}$], but isn't this probability 0 because the probability of choosing any given point in an interval is 0? I know I must be thinking about this incorrectly because I should use Bayes' rule for the second part, and $p(\theta)$ should be interpreted as the prior probability of $\theta$, which definitely should not be 0. This is a homework question, so I'm not looking for an explicit answer, but any hints would be very appreciated.","Let $D$ be a Bernoulli distribution with $P[X=1] = \theta$ (and so $P[X=0]=1-\theta$). Let $\chi = \{0,1\}$ be an iid sample drawn from $D$. Assume a prior distribution on $\theta$, with $\theta$ uniformly distributed between 0 and .25. What is the value of $p(\theta)$ for $\theta=\frac{1}{8}$?What is the value of $p(\theta \vert \chi)$ for $\theta=\frac{1}{8}$? I'm confused by what the question is asking for, and how everything ties together. There are other parts, but I think if I can grasp what's happening here I will be able to figure out the rest. I think I am supposed to be finding the probability that the random variable $\theta$ takes on the value of $\frac{1}{8}$ given that it is uniformly distributed over the interval [0,$\frac{1}{4}$], but isn't this probability 0 because the probability of choosing any given point in an interval is 0? I know I must be thinking about this incorrectly because I should use Bayes' rule for the second part, and $p(\theta)$ should be interpreted as the prior probability of $\theta$, which definitely should not be 0. This is a homework question, so I'm not looking for an explicit answer, but any hints would be very appreciated.",,"['statistics', 'bayes-theorem']"
90,Ball Permutations without replacement,Ball Permutations without replacement,,"This is a question from a sample stat midterm. A box has 60 balls - 15 are Yellow; 15 are red; 15 are white; 15 are   green. 14 Balls are selected without replacement and are put in 4   boxes, one for each ball. a) Compute the probability that box 1 has 5 balls, box 2 has 4 balls,   box 3 has 3 balls, and box 4 has 2 balls. b) Compute the probability that 2 boxes have 5 balls, 1 box has 3   balls, and one box has 1 ball. I was a bit confused on how to approach this. I was thinking that the total number of ways to distribute the balls should be $4^{14}\binom{60}{14}$, so the probability for part a should be something like $\frac{w}{4^{14}\binom{60}{14}}$ where $w$ is the number of ways to fulfill the above requirements. But I'm not sure if that is the correct approach, or where to go from there. What is the correct way to solve this?","This is a question from a sample stat midterm. A box has 60 balls - 15 are Yellow; 15 are red; 15 are white; 15 are   green. 14 Balls are selected without replacement and are put in 4   boxes, one for each ball. a) Compute the probability that box 1 has 5 balls, box 2 has 4 balls,   box 3 has 3 balls, and box 4 has 2 balls. b) Compute the probability that 2 boxes have 5 balls, 1 box has 3   balls, and one box has 1 ball. I was a bit confused on how to approach this. I was thinking that the total number of ways to distribute the balls should be $4^{14}\binom{60}{14}$, so the probability for part a should be something like $\frac{w}{4^{14}\binom{60}{14}}$ where $w$ is the number of ways to fulfill the above requirements. But I'm not sure if that is the correct approach, or where to go from there. What is the correct way to solve this?",,"['combinatorics', 'statistics']"
91,How to show that $E[E[X\mid Y]\mid Y] = E[X\mid Y]$,How to show that,E[E[X\mid Y]\mid Y] = E[X\mid Y],"I'm reading a little proof about how the estimation error (based on the conditional expectation estimator, $E[X\mid Y]$) has zero expectation, and at one point the author used the equality that the conditional expectation of the estimator on $Y$ == the estimator itself, i.e. $E[E[X\mid Y]|Y] = E[X\mid Y]$. Can somebody show me how that's derived? I'm pretty sure it has to do with the law of iterated expectation... See textbook screenshot:","I'm reading a little proof about how the estimation error (based on the conditional expectation estimator, $E[X\mid Y]$) has zero expectation, and at one point the author used the equality that the conditional expectation of the estimator on $Y$ == the estimator itself, i.e. $E[E[X\mid Y]|Y] = E[X\mid Y]$. Can somebody show me how that's derived? I'm pretty sure it has to do with the law of iterated expectation... See textbook screenshot:",,"['probability', 'statistics', 'expectation', 'conditional-expectation', 'estimation']"
92,What is the third quartile when there are no data above the median?,What is the third quartile when there are no data above the median?,,"I'm a programmer, so apologies if this is a bad question.  I'm writing some code that needs to detect outliers.  I am currently calculating first and third quartiles.  In a sample set of data, I have the following numbers: 179,179,179,178,177 The median comes out to 179 and the first quartile 178, but since there is no number above the median what should I do?  Or what if all the numbers were the same?  Is the quartile the median? This is my reference.","I'm a programmer, so apologies if this is a bad question.  I'm writing some code that needs to detect outliers.  I am currently calculating first and third quartiles.  In a sample set of data, I have the following numbers: 179,179,179,178,177 The median comes out to 179 and the first quartile 178, but since there is no number above the median what should I do?  Or what if all the numbers were the same?  Is the quartile the median? This is my reference.",,"['statistics', 'median']"
93,"is this natural probability, statistics, or fraud","is this natural probability, statistics, or fraud",,"I think I may have uncovered a corrupt box draw practice in greyhound  racing. Can someone please help me find the truth using math? It is rumored that one trainer is being given preferential box draw  treatment for greyhound racing. Does the following numbers fall outside  the accepted deviation of what would/ could/ should happen in a ""blind""  box draw. There are $8$ runners in every race, box $-1-$ has a massive advantage in  greyhound racing, and box $-5-$ a massive disadvantage One trainer draws box $-1-$ $232$ from $1621$ runners and box $-5-$ $163$ from  $1621$. Is he being given preferential treatment, does the statistics  prove that this is not a random draw? Another trainer for example draws box $-1-$ $ 272$ from $2183$  and box $-5-$ $309$ from $2183$ starters, is he being given a disadvantage? I would appreciate any help from someone who knows about this type of  randomness,probability, statistics, or whatever expert field this is.Is there a pattern or proof of something not quite right? Or is all this just the way the cookie crumbles?","I think I may have uncovered a corrupt box draw practice in greyhound  racing. Can someone please help me find the truth using math? It is rumored that one trainer is being given preferential box draw  treatment for greyhound racing. Does the following numbers fall outside  the accepted deviation of what would/ could/ should happen in a ""blind""  box draw. There are $8$ runners in every race, box $-1-$ has a massive advantage in  greyhound racing, and box $-5-$ a massive disadvantage One trainer draws box $-1-$ $232$ from $1621$ runners and box $-5-$ $163$ from  $1621$. Is he being given preferential treatment, does the statistics  prove that this is not a random draw? Another trainer for example draws box $-1-$ $ 272$ from $2183$  and box $-5-$ $309$ from $2183$ starters, is he being given a disadvantage? I would appreciate any help from someone who knows about this type of  randomness,probability, statistics, or whatever expert field this is.Is there a pattern or proof of something not quite right? Or is all this just the way the cookie crumbles?",,"['probability', 'statistics', 'applications', 'hypothesis-testing']"
94,"Central limit theorem, when do we know if n isn't large enough","Central limit theorem, when do we know if n isn't large enough",,"I'm working on a statistics question, and I'm stumped on how to answer it. Here is the question According to a survey conducted by the American Bar Association, 1 in every 410 Americans is a lawyer, but 1 in every 64 residents of Washington, D.C., is a lawyer.   (a) Use the Central Limit Theorem to approximate the probability that there is at least one lawyer in a random sample of 1500 Americans. Is n = 1500 large enough for the approximation to work well? Using the CLT, I found that the answer was approximately .95, but I don't know how to determine if the sample size is large enough for the approximation? What do you look for in this case?","I'm working on a statistics question, and I'm stumped on how to answer it. Here is the question According to a survey conducted by the American Bar Association, 1 in every 410 Americans is a lawyer, but 1 in every 64 residents of Washington, D.C., is a lawyer.   (a) Use the Central Limit Theorem to approximate the probability that there is at least one lawyer in a random sample of 1500 Americans. Is n = 1500 large enough for the approximation to work well? Using the CLT, I found that the answer was approximately .95, but I don't know how to determine if the sample size is large enough for the approximation? What do you look for in this case?",,['statistics']
95,Urn probability replacement problem,Urn probability replacement problem,,"An urn contains $10$ red and $10$ white balls. They are taken out at random one at a time. Find the probability that the fourth white ball is the fourth, fifth, sixth or seventh ball drawn if the sampling is done A. with replacement B. without replacement For A I got that it is $(\frac{1}{2})^4$ but I don't see how the rest of the spaces could be done. For B I got for the first part $.043$ but once again for the fifth position I try using the conditional probability $\frac{10C_1 \times 10C_3}{20C_4}$ but my answer is not the same answer as the solution. Any help would be appreciated.","An urn contains $10$ red and $10$ white balls. They are taken out at random one at a time. Find the probability that the fourth white ball is the fourth, fifth, sixth or seventh ball drawn if the sampling is done A. with replacement B. without replacement For A I got that it is $(\frac{1}{2})^4$ but I don't see how the rest of the spaces could be done. For B I got for the first part $.043$ but once again for the fifth position I try using the conditional probability $\frac{10C_1 \times 10C_3}{20C_4}$ but my answer is not the same answer as the solution. Any help would be appreciated.",,"['probability', 'statistics']"
96,How to put my knowledge of probability and statistics to practice,How to put my knowledge of probability and statistics to practice,,"Background: I am a masters student in stochastic analysis. My course is very theoretical, which in general is fine by me, it is what I enjoy the most. From the more data-friendly subjects, I have (or will obtain/deepen) knowledge in stochastic processes of all kinds, time series, statistics, linear regression. Apart from those my course focuses on stochastic analysis, stochastic differential equations, spatial modelling and point processes. I can work with R, Mathematica and a bit of Python and Javascript. And of course, one shouldn't forget: Excel. Motivation: The final impetus that lead me to write this question is quite simple: recently I stumbled upon a data-analysis student competition in my city and thought about entering. I quickly realized I have literally zero idea what to do with data. Not that I am not good at it - I literally have no actual knowledge, apart from being able to answer narrow questions in statistics and regression from classes, possibly model the simples processes if I try very hard. But more generally, I simply feel that since I am a mathematician, having data analysis skills is the sort of low-hanging fruit and it would be a great shame not to learn anything about it. Goals: Here lies the problem. While I have a vague idea, my lack of knowledge is such that I do not know what is it I want. I understand this does not make for a well-posed question, but I am hoping shaping my goals is what Math.SE will help with, too. I think I'd like to stick with R, since it's a free software that I'll always be able to use (unlike Mathematica), but software choice is secondary. Vaguely, I'd like to: 1) Have the knowledge necessary to be able to theoretically compete in such a competition (doing badly is fine, but currently I am wondering about entering a marathon having only read about ""legs"" and ""running"" on wikipedia) 2) Be able to most utilise my knowledge of mathematics and make it my strength - if I competed against other people I'd probably be stomped into ground by even those who have just basic statistics and time series knowledge, but are good at working with data. Moreover, if I could somehow incorporate actual stochastics/spatial modelling, that would also be an interesting option. 3) I'll take a stab at guessing my goals - be able to do basic statistics/regression in R, model different processes, do experiments with random variables from different probability distributions, have the basic toolset for time series. Beyond that I'd really be completely guessing. Questions : 1) What do I study? Are there topics/books considered to be the basics ? 2) How can I best utilize my strengths - i.e. deeper understanding of mathematics? Say if I somehow had to compare data using an interesting metric that requires good deal of knowledge of metric spaces to be understood (yeah, I don't know what I am talking about). Then again, it's very likely that the simpler, the better. I'd simple like to be aware of possible strengths, but I really do want to be able to walk/crawl properly first. 3) The main question: what resources would you recommend for me, i.e. someone who isn't afraid of (or even welcomes) complicated mathematics? That is not to say a simple book may not be far more important, but I am not limited to them. This is primarily a reference-request question (also to make it easier to answer, I suppose), but any answer consisting of general tips and thoughts on this matter will be very welcomed, too. Btw, I wouldn't want to make it sound like a competition is the main motivation for me, as it really isn't. It's just that I think it's a useful benchmark for the ""real-life"" data skills I learned. Thanks for any help!","Background: I am a masters student in stochastic analysis. My course is very theoretical, which in general is fine by me, it is what I enjoy the most. From the more data-friendly subjects, I have (or will obtain/deepen) knowledge in stochastic processes of all kinds, time series, statistics, linear regression. Apart from those my course focuses on stochastic analysis, stochastic differential equations, spatial modelling and point processes. I can work with R, Mathematica and a bit of Python and Javascript. And of course, one shouldn't forget: Excel. Motivation: The final impetus that lead me to write this question is quite simple: recently I stumbled upon a data-analysis student competition in my city and thought about entering. I quickly realized I have literally zero idea what to do with data. Not that I am not good at it - I literally have no actual knowledge, apart from being able to answer narrow questions in statistics and regression from classes, possibly model the simples processes if I try very hard. But more generally, I simply feel that since I am a mathematician, having data analysis skills is the sort of low-hanging fruit and it would be a great shame not to learn anything about it. Goals: Here lies the problem. While I have a vague idea, my lack of knowledge is such that I do not know what is it I want. I understand this does not make for a well-posed question, but I am hoping shaping my goals is what Math.SE will help with, too. I think I'd like to stick with R, since it's a free software that I'll always be able to use (unlike Mathematica), but software choice is secondary. Vaguely, I'd like to: 1) Have the knowledge necessary to be able to theoretically compete in such a competition (doing badly is fine, but currently I am wondering about entering a marathon having only read about ""legs"" and ""running"" on wikipedia) 2) Be able to most utilise my knowledge of mathematics and make it my strength - if I competed against other people I'd probably be stomped into ground by even those who have just basic statistics and time series knowledge, but are good at working with data. Moreover, if I could somehow incorporate actual stochastics/spatial modelling, that would also be an interesting option. 3) I'll take a stab at guessing my goals - be able to do basic statistics/regression in R, model different processes, do experiments with random variables from different probability distributions, have the basic toolset for time series. Beyond that I'd really be completely guessing. Questions : 1) What do I study? Are there topics/books considered to be the basics ? 2) How can I best utilize my strengths - i.e. deeper understanding of mathematics? Say if I somehow had to compare data using an interesting metric that requires good deal of knowledge of metric spaces to be understood (yeah, I don't know what I am talking about). Then again, it's very likely that the simpler, the better. I'd simple like to be aware of possible strengths, but I really do want to be able to walk/crawl properly first. 3) The main question: what resources would you recommend for me, i.e. someone who isn't afraid of (or even welcomes) complicated mathematics? That is not to say a simple book may not be far more important, but I am not limited to them. This is primarily a reference-request question (also to make it easier to answer, I suppose), but any answer consisting of general tips and thoughts on this matter will be very welcomed, too. Btw, I wouldn't want to make it sound like a competition is the main motivation for me, as it really isn't. It's just that I think it's a useful benchmark for the ""real-life"" data skills I learned. Thanks for any help!",,"['statistics', 'reference-request', 'stochastic-processes', 'career-development']"
97,What is the probability that the loser has won exactly $k$ games when the match is over?,What is the probability that the loser has won exactly  games when the match is over?,k,"Adam and Eve play a series of games of tennis, stopping as soon as one as them has won $n$ games. Suppose that they are evenly matched and that Adam wins each game with probability $1/2$, independently of the other games. What is the probability that the loser has won exactly $k$ games when the match is over? The answer I get is $$\dbinom{k+n-1}{k}(1/2)^{k+n}$$ [here 1 ]. Is it correct?","Adam and Eve play a series of games of tennis, stopping as soon as one as them has won $n$ games. Suppose that they are evenly matched and that Adam wins each game with probability $1/2$, independently of the other games. What is the probability that the loser has won exactly $k$ games when the match is over? The answer I get is $$\dbinom{k+n-1}{k}(1/2)^{k+n}$$ [here 1 ]. Is it correct?",,"['probability', 'statistics', 'game-theory']"
98,How to calculate expected number of trials of this geometric distribution,How to calculate expected number of trials of this geometric distribution,,"I understand why the expected number of trials until there is a success is given by $$ \sum_{i=0}^{\infty} i p q^{i-1} \ = \ E[\text{number of trials until} \ X=1] = \frac{1}{p}  $$ where $p$ is the probability of success and $X=1$ denotes the first success. However, I have different problem. In my setting, after the $n$th trial there will be success with probability 1. The probability of a success happening at the $i$th period [before n periods] is $p(1-p)^{i-1}$. I suspect that the expected amount of trials until success is given by $$ p + 2p(1-p) + 3p(1-p)^2 + ...+ np(1-p)^{n-1} $$ I am not sure if the correct answer is either $$  \frac{1-(1-p)^n}{p}   $$ or $$  \frac{1-(1-p)^n}{p} -n(1-p)^n  $$ I have tried using a few partial sum tricks and forcing the addition of probabilities equal to one in the following way: $$ \sum_{i=0}^{n}  p (1-p)^{i-1} + (1-p)^{n-1} \ = 1 $$ But I am not sure if this is the right way to even approach the question. How can I calculate the expected value of trials until the first success when I know that at a some $n$th period there will be success with probability 1?","I understand why the expected number of trials until there is a success is given by $$ \sum_{i=0}^{\infty} i p q^{i-1} \ = \ E[\text{number of trials until} \ X=1] = \frac{1}{p}  $$ where $p$ is the probability of success and $X=1$ denotes the first success. However, I have different problem. In my setting, after the $n$th trial there will be success with probability 1. The probability of a success happening at the $i$th period [before n periods] is $p(1-p)^{i-1}$. I suspect that the expected amount of trials until success is given by $$ p + 2p(1-p) + 3p(1-p)^2 + ...+ np(1-p)^{n-1} $$ I am not sure if the correct answer is either $$  \frac{1-(1-p)^n}{p}   $$ or $$  \frac{1-(1-p)^n}{p} -n(1-p)^n  $$ I have tried using a few partial sum tricks and forcing the addition of probabilities equal to one in the following way: $$ \sum_{i=0}^{n}  p (1-p)^{i-1} + (1-p)^{n-1} \ = 1 $$ But I am not sure if this is the right way to even approach the question. How can I calculate the expected value of trials until the first success when I know that at a some $n$th period there will be success with probability 1?",,"['probability', 'statistics', 'probability-distributions', 'expectation']"
99,When is the bootstrap sampling method not applicable?,When is the bootstrap sampling method not applicable?,,"I have used once the bootstrap sampling method to obtain a confidence interval for the expected daily returns that I had calculated using some data given. As far as I have understood, this method can be used even when the distribution of the random variable, in this case of the expected value of the daily returns, hasn't a ""nice"" distribution, but I would like to have a precise explanation of when should this method be used and why. Should for example the sample, in my case it was the daily returns, be Gaussian (or normally) distributed? My intuition is of course to say no, but again, a precise explanation would be more helpful. In general, when is the bootstrap sampling method not applicable? And when is it applicable?","I have used once the bootstrap sampling method to obtain a confidence interval for the expected daily returns that I had calculated using some data given. As far as I have understood, this method can be used even when the distribution of the random variable, in this case of the expected value of the daily returns, hasn't a ""nice"" distribution, but I would like to have a precise explanation of when should this method be used and why. Should for example the sample, in my case it was the daily returns, be Gaussian (or normally) distributed? My intuition is of course to say no, but again, a precise explanation would be more helpful. In general, when is the bootstrap sampling method not applicable? And when is it applicable?",,['statistics']
