,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"How to handle the differential of a vector field, ${\rm d}X:TM\to TTM$, in terms of (equivalence classes of) curves?","How to handle the differential of a vector field, , in terms of (equivalence classes of) curves?",{\rm d}X:TM\to TTM,"Given a generic smooth function $f:M\to N$ , we know that its differential is a smooth function $\mathrm df:TM\to TN$ such that $$\mathrm df(p,[\gamma'(0)])\equiv (f(p),\underbrace{\big[\partial_t\big|_0 f(\gamma(t))\big]}_{\in \eta\circ T_{f(p)}N}),$$ for any path $\gamma:I\to M$ with $\gamma(0)=p$ and $\gamma\in[\gamma'(0)]$ , and denoting with $[\gamma'(0)]$ the equivalence class of paths identified by their first derivative in some chart, and similarly denoting with $\partial_t\big|_0 [f(\gamma(t))]$ the corresponding equivalence class of paths $I\to N$ . I'm also denoting with $\eta$ the map sending an element in $TN$ into its second component, to clarify that the second element in the expression above is an equivalence class of curves (the notation is from Tao's notes I believe). On the other hand, a vector field is also a smooth function $X:M\to TM$ , and it should therefore make sense to talk about its differential, which is then a map $\mathrm dX:TM\to TTM$ , with $TTM$ tangent bundle of the tangent bundle of $M$ . If I try to unravel the same definition used above in this case I get a bit lost in the notation, however. In particular, we should have $$\mathrm dX(p,[\gamma'(0)]) = \big(\underbrace{X(p)}_{\in T_pM}, \underbrace{\big[\partial_t\big|_0X(\gamma(t))\big]}_{\in \eta\circ (T_{X(p)}TM)} \big).$$ So far, so good. But then we also know that $X(p)=(p,[\partial_t\big|_0\Phi_X^t(p)])$ , where $t\mapsto \Phi_X^t(p)$ is a curve representing the tangent curve corresponding to $X(p)$ (there might be a better notation for this, I'm not sure). Using this, I'd get $$\mathrm dX(p,[\gamma'(0)]) = \big( \underbrace{(p,\,\,[\partial_t|_0 \Phi_X^t(p)])}_{\in T_pM}, \,\, \big[\partial_t\big|_0\big\{\underbrace{(\gamma(t),\,\,[\partial_s|_0 \Phi_X^s(\gamma(t))])}_{X(\gamma(t))}\big\}\big] \big).$$ On the RHS we are now dealing with equivalence classes of paths in $TM$ . My question is, is there a way to simplify this expression to have just a tuple of four numbers? Naively, I would be tempted to just rewrite this as $$\mathrm dX(p,[\gamma'(0)]) = \big(   p,\,\,   [\partial_t|_0 \Phi_X^t(p)],\,\,   [\gamma'(0)],\,\,   \Big[\partial_t|_0\big[\partial_s|_0 \Phi_X^s(\gamma(t))\big]\Big] \big),$$ but I'm not sure whether this is legit, as I'm pretending that I can simply add pointwise the components of the tangent bundle. I'm sort of taking a curve $\tilde\gamma:I\to TM$ and writing it as $\tilde\gamma(t)=(\gamma_1(t),\gamma_2(t))$ for some pair of curves $\gamma_1:I\to M$ and $\gamma_2:I\to\eta\circ TM$ . Locally, we can do this via the trivialisation of the bundle, but is it legit to write this sort of expression more in general? Furthermore, is there a way to further rewrite the last bit of this expression, the one with the multiple derivatives, more explicitly? Addendum: Perhaps a more expressive, if less standard, notation for the above equations would be as follows. Given any curve $\gamma:I\to M$ , define the map $D_t$ as sending smooth curves defined at $t\in\mathbb R$ to the corresponding equivalence class of curves defined by their slope at $t$ , so that $D_t[\gamma]\subset\mathrm{Curves}(M)$ for any $\gamma\in\mathrm{Curves}(M)$ . With this, we can write for any $f:M\to N$ , $$\mathrm df(p,D_0[\gamma]) = (f(p), D_0[f\circ\gamma]).$$ For vector fields, we then have $$X(p)=(p,D_0[\Phi_X(p,\cdot)]), \qquad X(\gamma(t)) = (\gamma(t), D_0[\Phi_X(\gamma(t),\cdot)]), $$ and thus $$\mathrm dX(p,D_0[\gamma]) = (     X(p),     D_0[X\circ\gamma] ) \\ = (     p, D_0[\Phi_X(p,\cdot)], \,\,     D_{t=0}\big[(\gamma(t), D_{s=0}[\Phi_X(\gamma(t),s)])\big] \,\, ),$$ where I also had to write $D_{t=0}$ and $D_{s=0}$ to remark which curve/functional relation ought to be used as input to the map $D_0$ .","Given a generic smooth function , we know that its differential is a smooth function such that for any path with and , and denoting with the equivalence class of paths identified by their first derivative in some chart, and similarly denoting with the corresponding equivalence class of paths . I'm also denoting with the map sending an element in into its second component, to clarify that the second element in the expression above is an equivalence class of curves (the notation is from Tao's notes I believe). On the other hand, a vector field is also a smooth function , and it should therefore make sense to talk about its differential, which is then a map , with tangent bundle of the tangent bundle of . If I try to unravel the same definition used above in this case I get a bit lost in the notation, however. In particular, we should have So far, so good. But then we also know that , where is a curve representing the tangent curve corresponding to (there might be a better notation for this, I'm not sure). Using this, I'd get On the RHS we are now dealing with equivalence classes of paths in . My question is, is there a way to simplify this expression to have just a tuple of four numbers? Naively, I would be tempted to just rewrite this as but I'm not sure whether this is legit, as I'm pretending that I can simply add pointwise the components of the tangent bundle. I'm sort of taking a curve and writing it as for some pair of curves and . Locally, we can do this via the trivialisation of the bundle, but is it legit to write this sort of expression more in general? Furthermore, is there a way to further rewrite the last bit of this expression, the one with the multiple derivatives, more explicitly? Addendum: Perhaps a more expressive, if less standard, notation for the above equations would be as follows. Given any curve , define the map as sending smooth curves defined at to the corresponding equivalence class of curves defined by their slope at , so that for any . With this, we can write for any , For vector fields, we then have and thus where I also had to write and to remark which curve/functional relation ought to be used as input to the map .","f:M\to N \mathrm df:TM\to TN \mathrm df(p,[\gamma'(0)])\equiv (f(p),\underbrace{\big[\partial_t\big|_0 f(\gamma(t))\big]}_{\in \eta\circ T_{f(p)}N}), \gamma:I\to M \gamma(0)=p \gamma\in[\gamma'(0)] [\gamma'(0)] \partial_t\big|_0 [f(\gamma(t))] I\to N \eta TN X:M\to TM \mathrm dX:TM\to TTM TTM M \mathrm dX(p,[\gamma'(0)]) = \big(\underbrace{X(p)}_{\in T_pM}, \underbrace{\big[\partial_t\big|_0X(\gamma(t))\big]}_{\in \eta\circ (T_{X(p)}TM)}
\big). X(p)=(p,[\partial_t\big|_0\Phi_X^t(p)]) t\mapsto \Phi_X^t(p) X(p) \mathrm dX(p,[\gamma'(0)]) = \big(
\underbrace{(p,\,\,[\partial_t|_0 \Phi_X^t(p)])}_{\in T_pM}, \,\,
\big[\partial_t\big|_0\big\{\underbrace{(\gamma(t),\,\,[\partial_s|_0 \Phi_X^s(\gamma(t))])}_{X(\gamma(t))}\big\}\big]
\big). TM \mathrm dX(p,[\gamma'(0)]) = \big(
  p,\,\,
  [\partial_t|_0 \Phi_X^t(p)],\,\,
  [\gamma'(0)],\,\,
  \Big[\partial_t|_0\big[\partial_s|_0 \Phi_X^s(\gamma(t))\big]\Big]
\big), \tilde\gamma:I\to TM \tilde\gamma(t)=(\gamma_1(t),\gamma_2(t)) \gamma_1:I\to M \gamma_2:I\to\eta\circ TM \gamma:I\to M D_t t\in\mathbb R t D_t[\gamma]\subset\mathrm{Curves}(M) \gamma\in\mathrm{Curves}(M) f:M\to N \mathrm df(p,D_0[\gamma]) = (f(p), D_0[f\circ\gamma]). X(p)=(p,D_0[\Phi_X(p,\cdot)]),
\qquad
X(\gamma(t)) = (\gamma(t), D_0[\Phi_X(\gamma(t),\cdot)]),
 \mathrm dX(p,D_0[\gamma])
= (
    X(p),
    D_0[X\circ\gamma]
) \\
= (
    p, D_0[\Phi_X(p,\cdot)], \,\,
    D_{t=0}\big[(\gamma(t), D_{s=0}[\Phi_X(\gamma(t),s)])\big] \,\,
), D_{t=0} D_{s=0} D_0","['differential-geometry', 'vector-bundles', 'vector-fields', 'differential', 'tangent-bundle']"
1,Pullbacks and isomorphisms of vector bundles,Pullbacks and isomorphisms of vector bundles,,"I want to clarify certain details regarding pullbacks of vector bundles. I suspect my question will be equivalent in every possible setting: topological, differentiable and holomorphic vector bundles. Setting Let $X$ be a manifold and $E$ a vector bundle over $X$ . We consider automorphisms of $X$ , namely those isomorphisms in the appropriate category (homeomorphisms, diffeomorphisms, biholomorphisms...). Let $g:X\rightarrow X$ be one such automorphism. I can construct the pullback bundle by either declaring transition functions from those of $E$ $$ E \equiv \{U_i, \psi_{ij}\} \implies g^*E \equiv \{g^{-1}(U_i), \psi_{ij}\circ g\} $$ or even more explicitly by $$ g^*E = \{ (x,e)\in X\times E| g(x)=\pi(e)\} $$ I already know that there is a commutative diagram involving these bundles $$\begin{array} *g^*E & \stackrel{\hat{g}}{\longrightarrow} & E \\ \downarrow{p_1} & & \downarrow{\pi} \\ X & \stackrel{g}{\longrightarrow} & X   \end{array} $$ and $g(x,e)=e$ covers the automorphism $g$ . Question I want to clarify if it is possible that $g^*E$ is isomorphic to the original bundle, meaning there is a commutative diagram as above covering the identity on X . I know this is a stronger condition, but as I have $g$ an automorphism of $X$ , I suspect this could be possible in some situations. For example, from the classification of line bundles over $\mathbb{P}_\mathbb{C}^1$ , I can use the pullback of a connection and show that the degree/first Chern number is invariant under the action of $g\in SL(2,C)\subset Aut(\mathbb{P}_\mathbb{C}^1)$ , and thus $g^*L\simeq L$ for every line bundle over the projective line. I am trying to come up with a proof that either implements explicitly an identity-covering-vector-bundle-map or a proof involving Cech cohomology, but I would really prefer the former. If this is false, I would like to build an explicit counterexample.","I want to clarify certain details regarding pullbacks of vector bundles. I suspect my question will be equivalent in every possible setting: topological, differentiable and holomorphic vector bundles. Setting Let be a manifold and a vector bundle over . We consider automorphisms of , namely those isomorphisms in the appropriate category (homeomorphisms, diffeomorphisms, biholomorphisms...). Let be one such automorphism. I can construct the pullback bundle by either declaring transition functions from those of or even more explicitly by I already know that there is a commutative diagram involving these bundles and covers the automorphism . Question I want to clarify if it is possible that is isomorphic to the original bundle, meaning there is a commutative diagram as above covering the identity on X . I know this is a stronger condition, but as I have an automorphism of , I suspect this could be possible in some situations. For example, from the classification of line bundles over , I can use the pullback of a connection and show that the degree/first Chern number is invariant under the action of , and thus for every line bundle over the projective line. I am trying to come up with a proof that either implements explicitly an identity-covering-vector-bundle-map or a proof involving Cech cohomology, but I would really prefer the former. If this is false, I would like to build an explicit counterexample.","X E X X g:X\rightarrow X E 
E \equiv \{U_i, \psi_{ij}\} \implies g^*E \equiv \{g^{-1}(U_i), \psi_{ij}\circ g\}
 
g^*E = \{ (x,e)\in X\times E| g(x)=\pi(e)\}
 \begin{array}
*g^*E & \stackrel{\hat{g}}{\longrightarrow} & E \\
\downarrow{p_1} & & \downarrow{\pi} \\
X & \stackrel{g}{\longrightarrow} & X  
\end{array}
 g(x,e)=e g g^*E g X \mathbb{P}_\mathbb{C}^1 g\in SL(2,C)\subset Aut(\mathbb{P}_\mathbb{C}^1) g^*L\simeq L","['differential-geometry', 'algebraic-geometry', 'vector-bundles']"
2,How to deal with products of “shifted” Kronecker deltas?,How to deal with products of “shifted” Kronecker deltas?,,"How does one deal with expressions like $$ \sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} \quad \text{ or } \quad \sum_\mu a_\mu\delta_{2\mu,j} \delta_{2\mu -1,k} \quad ? $$ The usual rules would tell me set $\mu=\frac{j+1}{2}$ so that the first expression would be equal to $$ \sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} \stackrel{?}{=} s_{\frac{j+1}{2}}\delta_{j+1,k} $$ but it should be $$ \sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} = s_{(j+1)/2}\delta_{j+1,k}\delta_{j\in \mathbb{O}\ } $$ where $\mathbb{O}$ here denotes the set of (positive) odd numbers. So, what are the rules to tackle these problems fast?","How does one deal with expressions like The usual rules would tell me set so that the first expression would be equal to but it should be where here denotes the set of (positive) odd numbers. So, what are the rules to tackle these problems fast?","
\sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} \quad \text{ or } \quad \sum_\mu a_\mu\delta_{2\mu,j} \delta_{2\mu -1,k} \quad ?
 \mu=\frac{j+1}{2} 
\sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} \stackrel{?}{=} s_{\frac{j+1}{2}}\delta_{j+1,k}
 
\sum_\mu s_\mu \delta_{2 \mu-1,j} \delta_{2\mu,k} = s_{(j+1)/2}\delta_{j+1,k}\delta_{j\in \mathbb{O}\
}
 \mathbb{O}","['linear-algebra', 'differential-geometry', 'notation', 'tensors', 'index-notation']"
3,Short exact sequences of holomorphic vector bundles,Short exact sequences of holomorphic vector bundles,,"Consider a holomorphic bundle $F$ over a complex manifold $M$ . I have read on a comment here on mathstack that given a holomorphic subbundle $E$ of $F$ there are many non-isomorphic holomorphic bundles $G$ that complete the sort exact sequence $$0\to E \xrightarrow{h} F \to G \to 0\,.$$ I really can not understand how is this possible. By defintion of the short exact sequence it should be $F/im(h) = G$ , where $im(h) =E$ . Hence any two holomorphic bundles $G_1$ , $G_2$ that complete the short exact sequnce above should be isomorphic to $F/E$ . Note that by convention $h$ should have constant rank along the fibers.","Consider a holomorphic bundle over a complex manifold . I have read on a comment here on mathstack that given a holomorphic subbundle of there are many non-isomorphic holomorphic bundles that complete the sort exact sequence I really can not understand how is this possible. By defintion of the short exact sequence it should be , where . Hence any two holomorphic bundles , that complete the short exact sequnce above should be isomorphic to . Note that by convention should have constant rank along the fibers.","F M E F G 0\to E \xrightarrow{h} F \to G \to 0\,. F/im(h) = G im(h) =E G_1 G_2 F/E h","['differential-geometry', 'complex-geometry', 'vector-bundles', 'exact-sequence']"
4,Curves and smooth functions on manifolds derivative,Curves and smooth functions on manifolds derivative,,"Let $f: M\rightarrow \mathbb{R} $ be a smooth map at $p\in M$ and let $\gamma:(-\epsilon,\epsilon)\rightarrow M$ be a smooth curve with $\gamma(0)=p$ . Let $(U,\phi)$ be a chart at $p$ . Set, $(\phi \circ \gamma)(t)=(x_1(t),......,x_n(t))$ We claim: $\frac{d}{dt}|_{t=0}(f\circ \gamma)=\sum_i\frac{\partial{f\circ \phi^{-1}}}{\partial{x}_i}|_{\phi(p)}\frac{d{x_i}}{dt}|_{t=0} $ Is this because, $\frac{d}{dt}|_{t=0}(f\circ \gamma)=\frac{d}{dt}|_{t=0}((f\circ \phi^{-1})\circ (\phi \circ \gamma)).$ and then the chain rule in euclidean space implies what we claim?","Let be a smooth map at and let be a smooth curve with . Let be a chart at . Set, We claim: Is this because, and then the chain rule in euclidean space implies what we claim?","f: M\rightarrow \mathbb{R}  p\in M \gamma:(-\epsilon,\epsilon)\rightarrow M \gamma(0)=p (U,\phi) p (\phi \circ \gamma)(t)=(x_1(t),......,x_n(t)) \frac{d}{dt}|_{t=0}(f\circ \gamma)=\sum_i\frac{\partial{f\circ \phi^{-1}}}{\partial{x}_i}|_{\phi(p)}\frac{d{x_i}}{dt}|_{t=0}  \frac{d}{dt}|_{t=0}(f\circ \gamma)=\frac{d}{dt}|_{t=0}((f\circ \phi^{-1})\circ (\phi \circ \gamma)).",['differential-geometry']
5,Taylor expansion of length of image of circle by Riemannian exponential map,Taylor expansion of length of image of circle by Riemannian exponential map,,"Let $(M, g)$ be a Riemannian manifold (without boundary) and let $p \in M$ . Consider a linear $2$ -plane $P$ in $T_p M$ and let $C_r$ be a circle in $P$ , of radius $r$ and centered at $0$ (for $r$ small enough). How can we prove that $$\mathrm{Length}(\mathrm{exp}_p(C_r)) = 2 \pi \left(r - \frac{\mathrm{sec}(P)}{6} r^3 + O(r^4) \right), $$ where $\mathrm{exp}_p$ is the Riemannian exponential map at $p$ and $\mathrm{sec}(P)$ is the sectional curvature of the plane $P$ ? I tried using the definition of length: the curve $\mathrm{exp}_p(C_r)$ can be parametrized as $$\gamma : [0,2\pi] \to M, \quad \gamma(t) = \mathrm{exp}_p (r\cos(t) v + r\sin(t) w), $$ where $\{v, w\}$ is an orthonormal basis for $P$ . Then, we know that $$\mathrm{sec}(P) = R_p(v, w, w, v), $$ where $R$ is the $(0, 4)$ version of the Riemann curvature tensor, and we have that, \begin{align} \mathrm{Length} (\gamma) &= \int_0^{2\pi} |\dot{\gamma}(t)|dt \\ &= \int_0^{2\pi} \left| \left( d \left(\mathrm{exp}_p \right) \right)_{r\cos(t) v + r\sin(t) w} \left( -r\sin(t)v + r\cos(t)w \right)  \right| dt, \end{align} but I am not sure how to continue further, as I do not exactly know how to compute the differential of the exponential map at those particular points. I thought about using the fact that, since $r$ is small enough, the image of $\gamma$ is contained in a chart of Riemannian normal coordinates, call them $(x^1, \cdots, x^n)$ . Then, in these coordinates, the components of the Riemannian metric satisfy $$g_{ij} = \delta_{ij} - \frac{1}{3} \sum_{k, l} R_{iklj}(p)x^k x^l + O(|x|^3), $$ where $R_{ikjl}$ are the components of the $(0,4)$ version of the Riemann curvature tensor (this is Exercise 10.1 in Lee's Introduction to Riemannian manifolds, 2nd edition). However, I do not know how to use this.","Let be a Riemannian manifold (without boundary) and let . Consider a linear -plane in and let be a circle in , of radius and centered at (for small enough). How can we prove that where is the Riemannian exponential map at and is the sectional curvature of the plane ? I tried using the definition of length: the curve can be parametrized as where is an orthonormal basis for . Then, we know that where is the version of the Riemann curvature tensor, and we have that, but I am not sure how to continue further, as I do not exactly know how to compute the differential of the exponential map at those particular points. I thought about using the fact that, since is small enough, the image of is contained in a chart of Riemannian normal coordinates, call them . Then, in these coordinates, the components of the Riemannian metric satisfy where are the components of the version of the Riemann curvature tensor (this is Exercise 10.1 in Lee's Introduction to Riemannian manifolds, 2nd edition). However, I do not know how to use this.","(M, g) p \in M 2 P T_p M C_r P r 0 r \mathrm{Length}(\mathrm{exp}_p(C_r)) = 2 \pi \left(r - \frac{\mathrm{sec}(P)}{6} r^3 + O(r^4) \right),  \mathrm{exp}_p p \mathrm{sec}(P) P \mathrm{exp}_p(C_r) \gamma : [0,2\pi] \to M, \quad \gamma(t) = \mathrm{exp}_p (r\cos(t) v + r\sin(t) w),  \{v, w\} P \mathrm{sec}(P) = R_p(v, w, w, v),  R (0, 4) \begin{align}
\mathrm{Length} (\gamma) &= \int_0^{2\pi} |\dot{\gamma}(t)|dt \\
&= \int_0^{2\pi} \left| \left( d \left(\mathrm{exp}_p \right) \right)_{r\cos(t) v + r\sin(t) w} \left( -r\sin(t)v + r\cos(t)w \right)  \right| dt,
\end{align} r \gamma (x^1, \cdots, x^n) g_{ij} = \delta_{ij} - \frac{1}{3} \sum_{k, l} R_{iklj}(p)x^k x^l + O(|x|^3),  R_{ikjl} (0,4)","['differential-geometry', 'riemannian-geometry', 'curvature']"
6,Convergence of the image of the derivative map,Convergence of the image of the derivative map,,"Let $g\colon \Bbb R^2\to \Bbb R^2$ be a smooth map and $x_n\to x$ in $\Bbb R^2$ with $r_n:=|g(x_n)|\to 1$ . Write $S_r:=\{z\in \Bbb  R^2:|z|=r\}$ and assume $\text{im}(dg_{x_n})=T_{g(x_n)}(S_{r_n})$ for all $n$ . Then $\text{im}(dg_x)\subseteq T_{g(x)}(S_1)$ . My attempt: Without loss of generality, assume $dg_x\neq 0$ . So, we need to show, $\text{im}(dg_x)= T_{g(x)}(S_1)$ . Since $x_n\to x$ we have $g(x_n)\to g(x)$ . So, we can write, $g(x)=(\cos\theta,\sin\theta)$ and $g(x_n)=(r_n\cos\theta_n, r_n\sin \theta_n)$ so that $\theta_n\to \theta$ . Let $v_n=(-\sin\theta_n,\cos\theta_n)$ be a generator of $T_{g(x_n)}(S_{r_n})$ and $v=(-\sin\theta,\cos\theta)$ be a generator of $T_{g(x)}(S_1)$ . The derivative map $dg\colon \Bbb R^2\to L(\Bbb R^2,\Bbb R^2)$ is continuous implies $dg_{x_n}\to dg_x$ , and this convergence an be thought as convergence of $2\times 2$ -matrices. As $\text{rank}(dg_{x_n})=1$ , we have $\text{rank}(dg_x)$ is either $0$ or $1$ . From the assumption, $\text{rank}(dg_x)=1$ . Let $\widehat i,\widehat j\in \Bbb R^2\cong T_{x_n}\Bbb R^2$ be two perpendicular unit vectors. So, $dg_{x_n}(\widehat i)\to dg_x(\widehat i)$ and $dg_{x_n}(\widehat j)\to dg_x(\widehat j)$ . Since, $dg_{x_n}(\bullet)\parallel v_n$ we have $\big\langle dg_{x_n}(\widehat i), g(x_n)\big\rangle=0=\big\langle dg_{x_n}(\widehat j), g(x_n)\big\rangle$ , hence convergence of inner-product gives $$\big\langle dg_{x}(\widehat i), g(x)\big\rangle=0=\big\langle dg_{x}(\widehat j), g(x)\big\rangle,$$ i.e., $\text{im}(dg_x)=T_{g(x)}(S_1)$ . Is my attempt correct? Is there any other way of doing this?","Let be a smooth map and in with . Write and assume for all . Then . My attempt: Without loss of generality, assume . So, we need to show, . Since we have . So, we can write, and so that . Let be a generator of and be a generator of . The derivative map is continuous implies , and this convergence an be thought as convergence of -matrices. As , we have is either or . From the assumption, . Let be two perpendicular unit vectors. So, and . Since, we have , hence convergence of inner-product gives i.e., . Is my attempt correct? Is there any other way of doing this?","g\colon \Bbb R^2\to \Bbb R^2 x_n\to x \Bbb R^2 r_n:=|g(x_n)|\to 1 S_r:=\{z\in \Bbb
 R^2:|z|=r\} \text{im}(dg_{x_n})=T_{g(x_n)}(S_{r_n}) n \text{im}(dg_x)\subseteq T_{g(x)}(S_1) dg_x\neq 0 \text{im}(dg_x)= T_{g(x)}(S_1) x_n\to x g(x_n)\to g(x) g(x)=(\cos\theta,\sin\theta) g(x_n)=(r_n\cos\theta_n, r_n\sin \theta_n) \theta_n\to \theta v_n=(-\sin\theta_n,\cos\theta_n) T_{g(x_n)}(S_{r_n}) v=(-\sin\theta,\cos\theta) T_{g(x)}(S_1) dg\colon \Bbb R^2\to L(\Bbb R^2,\Bbb R^2) dg_{x_n}\to dg_x 2\times 2 \text{rank}(dg_{x_n})=1 \text{rank}(dg_x) 0 1 \text{rank}(dg_x)=1 \widehat i,\widehat j\in \Bbb R^2\cong T_{x_n}\Bbb R^2 dg_{x_n}(\widehat i)\to dg_x(\widehat i) dg_{x_n}(\widehat j)\to dg_x(\widehat j) dg_{x_n}(\bullet)\parallel v_n \big\langle dg_{x_n}(\widehat i), g(x_n)\big\rangle=0=\big\langle dg_{x_n}(\widehat j), g(x_n)\big\rangle \big\langle dg_{x}(\widehat i), g(x)\big\rangle=0=\big\langle dg_{x}(\widehat j), g(x)\big\rangle, \text{im}(dg_x)=T_{g(x)}(S_1)","['differential-geometry', 'solution-verification', 'differential-topology', 'smooth-manifolds']"
7,"Topology of $\mathbb{R}^{n+1}$ versus $\mathbb{R}^{n,1}$",Topology of  versus,"\mathbb{R}^{n+1} \mathbb{R}^{n,1}","What are the topology of these two noncompact manifolds $M_1=\mathbb{R}^{n+1}$ versus $M_2=\mathbb{R}^{n,1}$ , their differences? The inner product of the vectors for $M_1$ relies on the Euclidean metric: $$ g_{ab}=\delta_{ab}, \quad a,b \in 1,2,...,n+1. $$ The inner product of the vectors for $M_2$ relies on the (pseudo) Minkowski metric: $$ g_{1,1}=-1, \quad g_{ab}=+\delta_{mn}, \quad a,b \in 2,...,n+1. $$ All off diagonal components are zeros. Homotopy group: I believe both have the $\pi_0(M_1)=\pi_0(M_2)=0$ . So only one piece. I believe both have the $\pi_1(M_1)=\pi_1(M_2)=0$ . So only contractible cycles. how about higher homotopy groups $\pi_k(M_1)$ , or $\pi_k(M_2)$ ? Homology groups: how about higher homotopy groups $H_k(M_1)$ , or $H_k(M_2)$ ? Are there some topology ways to distinguish $\mathbb{R}^{n+1}$ versus $\mathbb{R}^{n,1}$ ? What are those topological differences between the $M_1=\mathbb{R}^{n+1}$ versus $M_2=\mathbb{R}^{n,1}$ ?","What are the topology of these two noncompact manifolds versus , their differences? The inner product of the vectors for relies on the Euclidean metric: The inner product of the vectors for relies on the (pseudo) Minkowski metric: All off diagonal components are zeros. Homotopy group: I believe both have the . So only one piece. I believe both have the . So only contractible cycles. how about higher homotopy groups , or ? Homology groups: how about higher homotopy groups , or ? Are there some topology ways to distinguish versus ? What are those topological differences between the versus ?","M_1=\mathbb{R}^{n+1} M_2=\mathbb{R}^{n,1} M_1 
g_{ab}=\delta_{ab}, \quad a,b \in 1,2,...,n+1.
 M_2 
g_{1,1}=-1, \quad g_{ab}=+\delta_{mn}, \quad a,b \in 2,...,n+1.
 \pi_0(M_1)=\pi_0(M_2)=0 \pi_1(M_1)=\pi_1(M_2)=0 \pi_k(M_1) \pi_k(M_2) H_k(M_1) H_k(M_2) \mathbb{R}^{n+1} \mathbb{R}^{n,1} M_1=\mathbb{R}^{n+1} M_2=\mathbb{R}^{n,1}","['differential-geometry', 'algebraic-topology', 'differential-topology', 'homology-cohomology', 'homotopy-theory']"
8,Composition of flow maps of Hamiltonian systems,Composition of flow maps of Hamiltonian systems,,"Given a pair of autonomous Hamiltonian vector fields $X_H,X_K\in\mathfrak{X}(M)$ , with flow maps which are respectively $\Phi^t,\Psi^s$ , is $\Phi^t\circ \Psi^s$ the $(t+s)-$ flow map of some Hamiltonian system? I think this is the case, possibly with the final map being the flow of a time-dependent Hamiltonian system. I know that the composition map is a symplectomorphism. However, since not all the functions in this space are flows of Hamiltonian systems, I am not sure of the answer to this question. Here is an additional explanation of what I am interested in. I do not mean that for any $t$ and $s$ , the Hamiltonian of the resulting vector field remains unchanged. More precisely, here are some settings which, for my interest, are not counterexamples: $$ \Phi^t\circ \Psi^s = \varphi_{X_L}^{t+s} $$ $$ \Psi^t\circ \Phi^s = \alpha_{X_R}^{t+s} $$ $$ \Phi^u\circ \Psi^v = \varphi_{X_W}^{u+v}, $$ where $L,R,W$ are three Hamiltonian functions which possibly do not coincide. This means that, when we fix $t$ and $s$ , there is a Hamiltonian vector field $X_{U}$ so that its $(t+s)-$ flow is the same map as $\Phi^t\circ \Psi^s$ .","Given a pair of autonomous Hamiltonian vector fields , with flow maps which are respectively , is the flow map of some Hamiltonian system? I think this is the case, possibly with the final map being the flow of a time-dependent Hamiltonian system. I know that the composition map is a symplectomorphism. However, since not all the functions in this space are flows of Hamiltonian systems, I am not sure of the answer to this question. Here is an additional explanation of what I am interested in. I do not mean that for any and , the Hamiltonian of the resulting vector field remains unchanged. More precisely, here are some settings which, for my interest, are not counterexamples: where are three Hamiltonian functions which possibly do not coincide. This means that, when we fix and , there is a Hamiltonian vector field so that its flow is the same map as .","X_H,X_K\in\mathfrak{X}(M) \Phi^t,\Psi^s \Phi^t\circ \Psi^s (t+s)- t s  \Phi^t\circ \Psi^s = \varphi_{X_L}^{t+s}   \Psi^t\circ \Phi^s = \alpha_{X_R}^{t+s}   \Phi^u\circ \Psi^v = \varphi_{X_W}^{u+v},  L,R,W t s X_{U} (t+s)- \Phi^t\circ \Psi^s","['differential-geometry', 'dynamical-systems', 'vector-fields', 'hamilton-equations']"
9,Cauchy surface for sphere,Cauchy surface for sphere,,"If we have a Lorentzian manifold $\mathbb{R} \times S^n$ with metric $g= -dt^2 + ds^n$ where $ds^n$ is just the standard round metric for spheres. Does this manifold have a Cauchy surface, i.e. is it globally hyperbolic? And if so what is the Cauchy surface? Basically that would mean that the Cauchy surface is homeomorphic to $S^n$ . I think that means that there exists no Cauchy surface but I am not sure.","If we have a Lorentzian manifold with metric where is just the standard round metric for spheres. Does this manifold have a Cauchy surface, i.e. is it globally hyperbolic? And if so what is the Cauchy surface? Basically that would mean that the Cauchy surface is homeomorphic to . I think that means that there exists no Cauchy surface but I am not sure.",\mathbb{R} \times S^n g= -dt^2 + ds^n ds^n S^n,"['differential-geometry', 'semi-riemannian-geometry']"
10,Existence of Complex Frames on a Complex Vector Bundle,Existence of Complex Frames on a Complex Vector Bundle,,"$E \rightarrow M $ be a complex vector bundle (of real rank $2r$ ) with almost complex structure $J:E\rightarrow E \space\space\space(J^2 =-1)$ on it. $U\subset M$ be a trivial neighbourhood. Does there exist a complex frame for $E \rightarrow M$ over U? By a complex frame, I mean a set of $r$ (real) linearly independent $E_U$ -sections $\{X_1, ... , X_r\}$ , such that $\{X_1, ... , X_r, JX_1, ... , JX_r\}$ forms a complete $E_U$ -frame. (By ""linearly independent"", I mean they are linearly independent in the fibre above every point $x\in U$ ). It seems like such frames do exist as I recall seeing such frames in definition of complex connection and curvature matrices on complex vector bundles, which then lead to construction of Chern forms and classes. I need such a frame to prove that existence of a $J$ map for $E \rightarrow M $ implies a reduction of structure group of E to $GL(r,C)$ . I am stuck with this, even though I can prove the converse by explicitly constructing a complex frame using the reduction. Edit: I am using the following definition for 'complex vector bundle': A real even ranked vector bundle with a J-map. Sorry for the confusion.","be a complex vector bundle (of real rank ) with almost complex structure on it. be a trivial neighbourhood. Does there exist a complex frame for over U? By a complex frame, I mean a set of (real) linearly independent -sections , such that forms a complete -frame. (By ""linearly independent"", I mean they are linearly independent in the fibre above every point ). It seems like such frames do exist as I recall seeing such frames in definition of complex connection and curvature matrices on complex vector bundles, which then lead to construction of Chern forms and classes. I need such a frame to prove that existence of a map for implies a reduction of structure group of E to . I am stuck with this, even though I can prove the converse by explicitly constructing a complex frame using the reduction. Edit: I am using the following definition for 'complex vector bundle': A real even ranked vector bundle with a J-map. Sorry for the confusion.","E \rightarrow M  2r J:E\rightarrow E \space\space\space(J^2 =-1) U\subset M E \rightarrow M r E_U \{X_1, ... , X_r\} \{X_1, ... , X_r, JX_1, ... , JX_r\} E_U x\in U J E \rightarrow M  GL(r,C)","['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'vector-bundles', 'almost-complex']"
11,Linear PDE in n+1 dimension given t=0 condition,Linear PDE in n+1 dimension given t=0 condition,,"Given the following PDE: $$\frac{\partial}{\partial t} f(x,y,t) = x \frac{\partial f}{\partial y} - y \frac{\partial f}{\partial x}$$ And initial condition: $$f(x,y,0) = g(x,y) = x^2+y^2$$ How do we determine $f$ for all time? My thinking is as follows: the initial function (paraboloid) is being modified by a certain vector field defined by the RHS of the equation, and it determines the shape of the function for $t > 0$ So suppose we have a vector field $v(x,y) = (-y,x)$ then the vector field $v$ represents the movement of the function through time. And the local flow of any particle starting at $(x, y)$ is $p(t) = (-yt + x, xt+y)$ . So in this case $p$ represents a curve in $R^2$ going through time, starting at $(x,y)$ and being moved by the said vector field. So the solution of the PDE is obtained by composing $g$ with $p$ , that is: $$f(x,y,t) = g(p(t)) = (-yt+x)^2 + (xt+y)^2 = (x^2+y^2)(t^2+1)$$ So at first glance it does satisfy the initial condition, but it does not satisfy the main PDE itself. $$\frac{\partial f}{\partial t} = 2t(x^2+y^2)$$ But $$\frac{\partial f}{\partial x} = 2x(t^2+1)$$ $$\frac{\partial f}{\partial y} = 2y(t^2+1)$$ So the RHS of the equation is zero What did I do wrong here?","Given the following PDE: And initial condition: How do we determine for all time? My thinking is as follows: the initial function (paraboloid) is being modified by a certain vector field defined by the RHS of the equation, and it determines the shape of the function for So suppose we have a vector field then the vector field represents the movement of the function through time. And the local flow of any particle starting at is . So in this case represents a curve in going through time, starting at and being moved by the said vector field. So the solution of the PDE is obtained by composing with , that is: So at first glance it does satisfy the initial condition, but it does not satisfy the main PDE itself. But So the RHS of the equation is zero What did I do wrong here?","\frac{\partial}{\partial t} f(x,y,t) = x \frac{\partial f}{\partial y} - y \frac{\partial f}{\partial x} f(x,y,0) = g(x,y) = x^2+y^2 f t > 0 v(x,y) = (-y,x) v (x, y) p(t) = (-yt + x, xt+y) p R^2 (x,y) g p f(x,y,t) = g(p(t)) = (-yt+x)^2 + (xt+y)^2 = (x^2+y^2)(t^2+1) \frac{\partial f}{\partial t} = 2t(x^2+y^2) \frac{\partial f}{\partial x} = 2x(t^2+1) \frac{\partial f}{\partial y} = 2y(t^2+1)","['differential-geometry', 'partial-differential-equations', 'initial-value-problems']"
12,Is the boundary of a $k$-manifold with corners a $(k-1)$-manifold with corners too?,Is the boundary of a -manifold with corners a -manifold with corners too?,k (k-1),"First of all  we remember some elementary definitions and results about manifolds with corners. Definition A function $f$ defined in a subset $S$ of $\Bbb R^k$ is said of class $C^r$ if it can be extended to a function $\phi$ (said $C^r$ -extension) that is of class $C^r$ in a open neighborhood of $S$ . Lemma If $f$ is a function defined in a subset $S$ of $\Bbb R^n$ such that for any $x\in S$ there exists a function $f_x$ defined in a neighborhood of $x$ that is of class $C^r$ and compatible with $f$ on $U_x\cap S$ then $f$ is of class $C^r$ . Lemma If $U$ is an open set of $H^n_k:=\Bbb R^{n-k}\times[0,+\infty)^k$ for any $k\le n$ then the derivatives of two different extensions $\phi$ and $\varphi$ of a $C^r$ -function $f$ agree in $U$ . Definition A $k$ -manifold with corners in $\Bbb R^n$ of class $C^r$ is a subspace $M$ of $\Bbb R^n$ whose points have a neighborhood $V$ in $M$ that is the immage of a homeomorphism $\phi$ of calss $C^r$ defined an open set $U$ of $\Bbb R^k$ or of $H^k_m$ and whose derivative has rank $k$ . Definition A point $y$ of a $k$ -manifold with corners $M$ is said interior point or boundary point if there exist a coordinate patch about $y$ defined in an open set of $\Bbb R^k$ or in an open set of $H^k_l$ respectively. Theorem Let be $M$ a $k$ -manifold with corners in $\Bbb R^n$ . So if $\phi:U\rightarrow V$ is a coordinate patch about any point boundary point $y$ of $M$ then necessarily $$ y=\phi(x) $$ for any $x\in U\cap\operatorname{bd}H^k_l$ . So with the previous definitions and efforts I ask to explain ( rigorously ) why the boundary points set $\partial M$ of a $k$ -manifolds with corners is or is not a $(k-1)$ -manifolds with corners too: indeed at the page $253$ of the text Introduction to Smooth Manifolds by John M. Lee it is explicitely said that generally the boudary of a smooth manifolds with corners is not a smooth manifolds with corners although it is not said that it is not a ( not smooth ) manifold with corners and so this confunsed me. Moreover I do not know if my definition of manifold with corners is effectively compatible with John M. Lee definition although it seemed to me it is. So provided that the result is true I arranged a proof that I show to follow: I point out that the proposed solution is imperfect because I did not able to prove a little but important thing as me myself I am showing. So could someone help me, please? MY PROOF ATTEMPT Well by the preceding theorem we know that if $y$ is an element of $\partial M$ then there exist a coordinate patch $\phi:U\rightarrow V$ defined in an open set of $H^k_l$ such that $$ y=\phi(x) $$ for any $x\in\operatorname{bd}H^k_l$ and thus without loss of generality we can assume that $x^k$ is zero: indeed if $x\in\operatorname{bd}H^k_l$ then  it must be $$ x^i=0 $$ for any $i=(k-l)+1,\dots,k$ so that if $\psi$ is the diffeomorphism that interchanges the $i$ -th coordinate with the last (observe that $\psi$ is an involution that maps $H^k_l$ onto $H^k_l$ ) then $\phi\circ\psi$ is a coordinate patch about $y$ having the desired property. So we remember (click here for details) that if $W$ is an open set of $\Bbb R^k$ then $$ W\cap\big(\Bbb R^{k-1}\times\{0\}\big)=A_W\times\{0\} $$ for any open set $A_W$ of $\Bbb R^{k-1}$ . Now we first assuem that it is $l=1$ . So in this case the restriction of $\phi$ to $U\cap\operatorname{bd}H^k_1$ carries this set in a one to one fashion onto the open set $V\cap\partial M$ of $\partial M$ . Now if $U$ is open in $H^k_1$ then there must exist an open set $W$ of $\Bbb R^k$ whose intersection with $H^k_1$ is equal to $U$ and thus putting $$ \varphi(x):=\phi(x,0) $$ for any $x\in A_W$ then we prove that $\varphi$ is a coordinate patch about $y$ . So clearly $\varphi$ is of class $C^r$ because $\phi$ is; moreover the derivative of $\phi$ has rank $(k-1)$ because $D\varphi(x)$ consists simply of the first $(k-1)$ columns of the matrix $D\phi(x,0)$ ; finally $\phi$ is injective and its immage $V\cap\partial M$ is open in $M$ and the inverse function $\varphi^{-1}$ is continuous because it is equal to the function $\phi^{-1}$ followed by the projection of $\Bbb R^k$ onto its first $(k-1)$ coordinates. So we conclude that $\varphi$ is a coordinate patch about $y$ defined in an open set of $\Bbb R^{k-1}$ . Now we let assume that $l>1$ . So since $U$ is open in $H^k_l$ then $$ U=W\cap H^k_l $$ for any open set $W$ of $\Bbb R^k$ and thus $$ U\cap\operatorname{bd}H^k_1=(W\cap H^k_l)\cap\operatorname{bd}H^k_1=(W\cap\operatorname{bd}H^k_1)\cap H^k_l=\\\big(W\cap(\Bbb R^{k-1}\times\{0\})\big)\cap(H^{k-1}_{l-1}\times[0,+\infty))=(A_W\times\{0\})\cap(H^{k-1}_{l-1}\times[0,+\infty))=(A_W\cap H^{k-1}_{l-1})\times\{0\} $$ so that we let to prove that the function $\varphi$ defined in $A_W\cap H^{k-1}_{l-1}$ through the equation $$ \varphi(x):=\phi(x,0) $$ for any $x\in A_W\cap H^{k-1}_{l-1}$ is a coordinate patch about $y$ . So clearly $A_W\cap H^{k-1}_{l-1}$ is open in $H^{k-1}_{l-1}$ and by analogous arguments applied above $\varphi$ is a $C^r$ injective function whose derivative has maximum rank and whose inverse is continuous but unfortunately I did not able to show that the immage of $\varphi$ is effectively open in $\partial M$ so that I can not claim that $\varphi$ is a coordinate patch about $y$ .","First of all  we remember some elementary definitions and results about manifolds with corners. Definition A function defined in a subset of is said of class if it can be extended to a function (said -extension) that is of class in a open neighborhood of . Lemma If is a function defined in a subset of such that for any there exists a function defined in a neighborhood of that is of class and compatible with on then is of class . Lemma If is an open set of for any then the derivatives of two different extensions and of a -function agree in . Definition A -manifold with corners in of class is a subspace of whose points have a neighborhood in that is the immage of a homeomorphism of calss defined an open set of or of and whose derivative has rank . Definition A point of a -manifold with corners is said interior point or boundary point if there exist a coordinate patch about defined in an open set of or in an open set of respectively. Theorem Let be a -manifold with corners in . So if is a coordinate patch about any point boundary point of then necessarily for any . So with the previous definitions and efforts I ask to explain ( rigorously ) why the boundary points set of a -manifolds with corners is or is not a -manifolds with corners too: indeed at the page of the text Introduction to Smooth Manifolds by John M. Lee it is explicitely said that generally the boudary of a smooth manifolds with corners is not a smooth manifolds with corners although it is not said that it is not a ( not smooth ) manifold with corners and so this confunsed me. Moreover I do not know if my definition of manifold with corners is effectively compatible with John M. Lee definition although it seemed to me it is. So provided that the result is true I arranged a proof that I show to follow: I point out that the proposed solution is imperfect because I did not able to prove a little but important thing as me myself I am showing. So could someone help me, please? MY PROOF ATTEMPT Well by the preceding theorem we know that if is an element of then there exist a coordinate patch defined in an open set of such that for any and thus without loss of generality we can assume that is zero: indeed if then  it must be for any so that if is the diffeomorphism that interchanges the -th coordinate with the last (observe that is an involution that maps onto ) then is a coordinate patch about having the desired property. So we remember (click here for details) that if is an open set of then for any open set of . Now we first assuem that it is . So in this case the restriction of to carries this set in a one to one fashion onto the open set of . Now if is open in then there must exist an open set of whose intersection with is equal to and thus putting for any then we prove that is a coordinate patch about . So clearly is of class because is; moreover the derivative of has rank because consists simply of the first columns of the matrix ; finally is injective and its immage is open in and the inverse function is continuous because it is equal to the function followed by the projection of onto its first coordinates. So we conclude that is a coordinate patch about defined in an open set of . Now we let assume that . So since is open in then for any open set of and thus so that we let to prove that the function defined in through the equation for any is a coordinate patch about . So clearly is open in and by analogous arguments applied above is a injective function whose derivative has maximum rank and whose inverse is continuous but unfortunately I did not able to show that the immage of is effectively open in so that I can not claim that is a coordinate patch about .","f S \Bbb R^k C^r \phi C^r C^r S f S \Bbb R^n x\in S f_x x C^r f U_x\cap S f C^r U H^n_k:=\Bbb R^{n-k}\times[0,+\infty)^k k\le n \phi \varphi C^r f U k \Bbb R^n C^r M \Bbb R^n V M \phi C^r U \Bbb R^k H^k_m k y k M y \Bbb R^k H^k_l M k \Bbb R^n \phi:U\rightarrow V y M 
y=\phi(x)
 x\in U\cap\operatorname{bd}H^k_l \partial M k (k-1) 253 y \partial M \phi:U\rightarrow V H^k_l 
y=\phi(x)
 x\in\operatorname{bd}H^k_l x^k x\in\operatorname{bd}H^k_l 
x^i=0
 i=(k-l)+1,\dots,k \psi i \psi H^k_l H^k_l \phi\circ\psi y W \Bbb R^k 
W\cap\big(\Bbb R^{k-1}\times\{0\}\big)=A_W\times\{0\}
 A_W \Bbb R^{k-1} l=1 \phi U\cap\operatorname{bd}H^k_1 V\cap\partial M \partial M U H^k_1 W \Bbb R^k H^k_1 U 
\varphi(x):=\phi(x,0)
 x\in A_W \varphi y \varphi C^r \phi \phi (k-1) D\varphi(x) (k-1) D\phi(x,0) \phi V\cap\partial M M \varphi^{-1} \phi^{-1} \Bbb R^k (k-1) \varphi y \Bbb R^{k-1} l>1 U H^k_l 
U=W\cap H^k_l
 W \Bbb R^k 
U\cap\operatorname{bd}H^k_1=(W\cap H^k_l)\cap\operatorname{bd}H^k_1=(W\cap\operatorname{bd}H^k_1)\cap H^k_l=\\\big(W\cap(\Bbb R^{k-1}\times\{0\})\big)\cap(H^{k-1}_{l-1}\times[0,+\infty))=(A_W\times\{0\})\cap(H^{k-1}_{l-1}\times[0,+\infty))=(A_W\cap H^{k-1}_{l-1})\times\{0\}
 \varphi A_W\cap H^{k-1}_{l-1} 
\varphi(x):=\phi(x,0)
 x\in A_W\cap H^{k-1}_{l-1} y A_W\cap H^{k-1}_{l-1} H^{k-1}_{l-1} \varphi C^r \varphi \partial M \varphi y","['differential-geometry', 'manifolds', 'examples-counterexamples', 'smooth-functions', 'manifolds-with-boundary']"
13,What is the meaning of the exterior derivative of a nonholonomic constraint?,What is the meaning of the exterior derivative of a nonholonomic constraint?,,"Suppose we have a nonholonomic mechanical system, say Lagrangian, for example the Chaplygin sleigh is a model of a knife in the plane. Its configuation space is $Q = S^1\times \mathbb{R}^2$ with local coordinates $q = (\theta,x,y)$ . The nonholonomic constraint is ""no admissible velocities are perpendicular to the blade"" which is specified by a one-form $$\omega_q = \sin\theta\,\mathrm dx + \cos\theta\,\mathrm dy.$$ When evaulating on a velocity $\dot{q}$ we specify the velocity constraint $$v = \omega_q\cdot \dot{q} = -\dot{x}\sin\theta + \dot{y}\cos\theta = 0.$$ What is the mathematical/physical meaning of the exterior derivative of the constraint one-form? Since $\omega_q$ is a one-form, in physics, we typically interpret it as a force. Mathematically, we integrate this form over a 'line' to get the work due to the force over the 'line'. The exterior derivative is a 2-form, (does this have any physical significance??) $$\mathrm d\omega = -\cos\theta\,\mathrm d\theta \wedge\,\mathrm dx - \sin\theta\,\mathrm d\theta \wedge\,\mathrm dy$$ If we evaluate this 2-form along a tangent (velocity) vector $\dot{q}$ , we find the 'force' $$\alpha_q = \mathrm d\omega(\dot{q},.) = \left(\dot{x}\cos\theta + \dot{y}\sin\theta \right)\,\mathrm d\theta - \cos\theta\dot{\theta}\,\mathrm dx - \sin\theta \dot{\theta}\,\mathrm dy.$$ Does this 'force', $\alpha_q \in T^*Q$ , have any direct/obvious physical/mathematical physics/differential geometric  interpretation?? Thanks.","Suppose we have a nonholonomic mechanical system, say Lagrangian, for example the Chaplygin sleigh is a model of a knife in the plane. Its configuation space is with local coordinates . The nonholonomic constraint is ""no admissible velocities are perpendicular to the blade"" which is specified by a one-form When evaulating on a velocity we specify the velocity constraint What is the mathematical/physical meaning of the exterior derivative of the constraint one-form? Since is a one-form, in physics, we typically interpret it as a force. Mathematically, we integrate this form over a 'line' to get the work due to the force over the 'line'. The exterior derivative is a 2-form, (does this have any physical significance??) If we evaluate this 2-form along a tangent (velocity) vector , we find the 'force' Does this 'force', , have any direct/obvious physical/mathematical physics/differential geometric  interpretation?? Thanks.","Q = S^1\times \mathbb{R}^2 q = (\theta,x,y) \omega_q = \sin\theta\,\mathrm dx + \cos\theta\,\mathrm dy. \dot{q} v = \omega_q\cdot \dot{q} = -\dot{x}\sin\theta + \dot{y}\cos\theta = 0. \omega_q \mathrm d\omega = -\cos\theta\,\mathrm d\theta \wedge\,\mathrm dx - \sin\theta\,\mathrm d\theta \wedge\,\mathrm dy \dot{q} \alpha_q = \mathrm d\omega(\dot{q},.) = \left(\dot{x}\cos\theta + \dot{y}\sin\theta \right)\,\mathrm d\theta - \cos\theta\dot{\theta}\,\mathrm dx - \sin\theta \dot{\theta}\,\mathrm dy. \alpha_q \in T^*Q","['differential-geometry', 'differential-forms', 'classical-mechanics']"
14,Help pulling back the tautological one-form on the cotangent bundle $T^*M$ to the tangent bundle $TM$ using a Riemannian metric on $M$,Help pulling back the tautological one-form on the cotangent bundle  to the tangent bundle  using a Riemannian metric on,T^*M TM M,"I am struggling with exercise 5 page 304 in Global Aspects of Classical Integrable Systems ,Cushman and Bates Let $g$ be a Riemannian metric on a smooth manifold $M$ . In local coordinates $x = (x_1,... x_n)$ the metric may be written as $g = \sum g_{ij} dx^i \otimes dx^j$ Let $v = (x, \nu) = (x^1,..., x^n, \nu^1,... \nu^n)$ be natural coordinates on TM. Show that the pullback $\theta_g$ by the map $g^\#$ to $TM$ of the canonical 1-form $\theta$ on $T^*M$ may be written as $\theta_g(\nu) = \sum g_{i j}\nu^i dx^j$ Setting the problem: Take coordinates on $T^*M$ to be $m = (x, p)$ Canonical 1-form $\theta$ on $T^*M$ \begin{equation}     \begin{aligned}     \theta\in \chi ^*(T^*M)\\     \theta: \chi (T^*M) \rightarrow C^\infty(\mathbb{R})\\\theta_m: T_m(T^*M) \rightarrow \mathbb{R}     \\     \theta_{m=(x, p)} = \sum_i p_i dx^i     \end{aligned} \end{equation} $\;\;\;\;\;$ * Let $w \in T_m(T^*M), \quad w = \sum_i^n w_i \dfrac{\partial}{\partial x^i} + \sum_{i=1}^{n} w'_{i} \dfrac{\partial}{\partial p^i}$ $\;\;\;\;\;$ * Then $\theta_m(w) = \sum_i w_ip_i$ . The map $g(x)^\#$ on $T_xM$ is the isomorphism induced by $g(x)$ between $T_xM$ and $T^*_xM$ \begin{equation} \begin{aligned} &g^\#(v) = g(x)^\#(\nu) \text{ is such that } [g(x)^\#(\nu)](\mu) = g_x(\nu, \mu), \quad \mu \in T_xM \end{aligned} \end{equation} Pullback of a 1-form (Wikipedia): Let $\phi:M \rightarrow N$ be a smooth map between smooth manifolds, and let $\alpha$ be a 1-form on $N$ . \newline Then the pullback of $\alpha$ by $\phi$ is the 1-form $\phi^*\alpha$ on $M$ defined by: \begin{equation} (\phi^*\alpha)_x(X) = \alpha_{\phi(x)}(d\phi_x(x)) \end{equation} for $x \in M$ and $X \in T_xM$ Property of the tautological one-form from Wikipedia: The tautological one-form is the unique one-form that ""cancels"" the pullback. The tautological one-form $\theta$ is the only form with the property that $\beta^*\theta = \beta$ , for every 1-form $\beta$ on $Q$ My confusion and my attempt While $\theta$ is a one-form on $T^*M$ , it seems to me that $g^\#$ maps to $T^*_xM$ . (Indeed once we feed the metric a tangent vector we have decided on an attachment point $x$ of the manifold) My solution was instead to define $g^\#:TM \rightarrow T^*M$ \begin{equation} g^\#(x, \nu) = (x, g^2(x)^\#(\nu)) \end{equation} where $[g^2(x)^\#(\nu)](\mu) = g(x)(\nu, \mu)$ Attempt component-wise \begin{equation} \begin{aligned} \theta_g(v) = [(g^\#)^*\theta] (v) &= \theta ( g^\#(v))\circ dg^\#_v \\ &= \theta ( g^\#(x^i, \nu^i))\circ dg^\#_v\\ &= \theta(\sum g_{ij}(x) \nu^i dx^j) \circ dg^\#_v\\ &= (\sum g_{ij}(x) \nu^i dx^j) \circ dg^\#_v  \end{aligned} \end{equation} Is this a valid method ? Can I show $dg^\#_v$ acts as the identity map on $\dfrac{\partial}{\partial x^i}$ components ? I have also been attempting a solution using the ""tautological one form cancels pullback"" identity My ""solution"" has been to fix $\nu$ while varying $x$ thus defining the one-form: $$g^\#_\nu: M \rightarrow T^*M $$ $$g^\#_\nu(x) \text{ is such that: }$$ $$g^\#_\nu(x)(\mu) = g_x(\nu, \mu) $$ Pulling $\theta$ back by $g^\#_\nu$ : $$\theta_g = (g^\#_\nu)^*\theta = g^\#_\nu = \iota_\nu g = \sum g_{ij} \nu^i dx^j $$ There are obviously several problems with this solution, $\theta_g$ acts in $M$ instead of $TM$ and it is odd to fix a covector $\nu$ in this way. I am unsure how to define $g^\#$ to get spaces to properly match up, I am unsure how to deal with the fact the tautological form on $T^*M$ ""looks"" like a one-form on $M$ Any help with this exercise, or suggestions on simpler exercises to tackle that migh help would be very welcome.","I am struggling with exercise 5 page 304 in Global Aspects of Classical Integrable Systems ,Cushman and Bates Let be a Riemannian metric on a smooth manifold . In local coordinates the metric may be written as Let be natural coordinates on TM. Show that the pullback by the map to of the canonical 1-form on may be written as Setting the problem: Take coordinates on to be Canonical 1-form on * Let * Then . The map on is the isomorphism induced by between and Pullback of a 1-form (Wikipedia): Let be a smooth map between smooth manifolds, and let be a 1-form on . \newline Then the pullback of by is the 1-form on defined by: for and Property of the tautological one-form from Wikipedia: The tautological one-form is the unique one-form that ""cancels"" the pullback. The tautological one-form is the only form with the property that , for every 1-form on My confusion and my attempt While is a one-form on , it seems to me that maps to . (Indeed once we feed the metric a tangent vector we have decided on an attachment point of the manifold) My solution was instead to define where Attempt component-wise Is this a valid method ? Can I show acts as the identity map on components ? I have also been attempting a solution using the ""tautological one form cancels pullback"" identity My ""solution"" has been to fix while varying thus defining the one-form: Pulling back by : There are obviously several problems with this solution, acts in instead of and it is odd to fix a covector in this way. I am unsure how to define to get spaces to properly match up, I am unsure how to deal with the fact the tautological form on ""looks"" like a one-form on Any help with this exercise, or suggestions on simpler exercises to tackle that migh help would be very welcome.","g M x = (x_1,... x_n) g = \sum g_{ij} dx^i \otimes dx^j v = (x, \nu) = (x^1,..., x^n, \nu^1,... \nu^n) \theta_g g^\# TM \theta T^*M \theta_g(\nu) = \sum g_{i j}\nu^i dx^j T^*M m = (x, p) \theta T^*M \begin{equation}
    \begin{aligned}
    \theta\in \chi ^*(T^*M)\\
    \theta: \chi (T^*M) \rightarrow C^\infty(\mathbb{R})\\\theta_m: T_m(T^*M) \rightarrow \mathbb{R}
    \\
    \theta_{m=(x, p)} = \sum_i p_i dx^i
    \end{aligned}
\end{equation} \;\;\;\;\; w \in T_m(T^*M), \quad w = \sum_i^n w_i \dfrac{\partial}{\partial x^i} + \sum_{i=1}^{n} w'_{i} \dfrac{\partial}{\partial p^i} \;\;\;\;\; \theta_m(w) = \sum_i w_ip_i g(x)^\# T_xM g(x) T_xM T^*_xM \begin{equation}
\begin{aligned}
&g^\#(v) = g(x)^\#(\nu) \text{ is such that }
[g(x)^\#(\nu)](\mu) = g_x(\nu, \mu), \quad \mu \in T_xM
\end{aligned}
\end{equation} \phi:M \rightarrow N \alpha N \alpha \phi \phi^*\alpha M \begin{equation}
(\phi^*\alpha)_x(X) = \alpha_{\phi(x)}(d\phi_x(x))
\end{equation} x \in M X \in T_xM \theta \beta^*\theta = \beta \beta Q \theta T^*M g^\# T^*_xM x g^\#:TM \rightarrow T^*M \begin{equation}
g^\#(x, \nu) = (x, g^2(x)^\#(\nu))
\end{equation} [g^2(x)^\#(\nu)](\mu) = g(x)(\nu, \mu) \begin{equation}
\begin{aligned}
\theta_g(v) = [(g^\#)^*\theta] (v) &= \theta ( g^\#(v))\circ dg^\#_v \\
&= \theta ( g^\#(x^i, \nu^i))\circ dg^\#_v\\
&= \theta(\sum g_{ij}(x) \nu^i dx^j) \circ dg^\#_v\\
&= (\sum g_{ij}(x) \nu^i dx^j) \circ dg^\#_v 
\end{aligned}
\end{equation} dg^\#_v \dfrac{\partial}{\partial x^i} \nu x g^\#_\nu: M \rightarrow T^*M
 g^\#_\nu(x) \text{ is such that: } g^\#_\nu(x)(\mu) = g_x(\nu, \mu)
 \theta g^\#_\nu \theta_g = (g^\#_\nu)^*\theta = g^\#_\nu = \iota_\nu g = \sum g_{ij} \nu^i dx^j
 \theta_g M TM \nu g^\# T^*M M","['differential-geometry', 'differential-forms', 'symplectic-geometry']"
15,Inverse of left-invariant metric is left-invariant,Inverse of left-invariant metric is left-invariant,,"Given a Lie group $G$ of dimension $n$ with a left-invariant metric $g$ . Is it true that $g^{-1}$ , that is, the metric in the cotangent bundle (whose matrix form is the inverse of that of $g$ ) is also left-invariant? The reason that I think this is not true is that for a particular example, I have $n$ left-invariant 1-forms, and if my computations are correct, some of the inner products (via $g^{-1}$ ) of these forms are not constants.","Given a Lie group of dimension with a left-invariant metric . Is it true that , that is, the metric in the cotangent bundle (whose matrix form is the inverse of that of ) is also left-invariant? The reason that I think this is not true is that for a particular example, I have left-invariant 1-forms, and if my computations are correct, some of the inner products (via ) of these forms are not constants.",G n g g^{-1} g n g^{-1},"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
16,Kodaira-Thurston example,Kodaira-Thurston example,,"I am trying to understand the Kodaira-Thurston example as it's done in the book ""Lectures on Symplectic Geometry"" by Ana Cannas. Let's take $\mathbb{R}^{4}$ , with local coordinates $\{x_1,x_2,y_1,y_2\}$ , and following sympletic form $\omega = dx_{1}\wedge dy_{1} + dx_{2}\wedge dy_{2}$ . Now one can consider the following discrete group $\Gamma$ which is generated by the following symplectomorphisms: \begin{align*}     &\gamma_{1}: (x_1,x_2,y_1,y_2) \longrightarrow (x_1,x_2+1,y_1,y_2)\\     &\gamma_{2}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1,x_2,y_1,y_2+1)\\     &\gamma_{3}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1+1,x_2,y_1,y_2)\\     &\gamma_{4}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1,x_2,y_1+1,y_2) \end{align*} and take $M=\mathbb{R}^4/\Gamma$ . Now we know that $\pi_1(M)\cong \Gamma$ , but I am having some trouble understanding why this will have rank $3$ . Also I am not sure how one can define a symplectic structure on this manifold $M$ . Any help is appreciated, thanks in advance.","I am trying to understand the Kodaira-Thurston example as it's done in the book ""Lectures on Symplectic Geometry"" by Ana Cannas. Let's take , with local coordinates , and following sympletic form . Now one can consider the following discrete group which is generated by the following symplectomorphisms: and take . Now we know that , but I am having some trouble understanding why this will have rank . Also I am not sure how one can define a symplectic structure on this manifold . Any help is appreciated, thanks in advance.","\mathbb{R}^{4} \{x_1,x_2,y_1,y_2\} \omega = dx_{1}\wedge dy_{1} + dx_{2}\wedge dy_{2} \Gamma \begin{align*}
    &\gamma_{1}: (x_1,x_2,y_1,y_2) \longrightarrow (x_1,x_2+1,y_1,y_2)\\
    &\gamma_{2}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1,x_2,y_1,y_2+1)\\
    &\gamma_{3}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1+1,x_2,y_1,y_2)\\
    &\gamma_{4}: (x_1,x_2,y_1,y_2)\longrightarrow (x_1,x_2,y_1+1,y_2)
\end{align*} M=\mathbb{R}^4/\Gamma \pi_1(M)\cong \Gamma 3 M","['differential-geometry', 'complex-geometry', 'symplectic-geometry']"
17,$H: \mathbb{R^2 } \rightarrow \mathbb{R^2}$ be a homeomorphism such that $H(\partial B_1)= \partial B_2$. Show that $H(B_2)=B_1$.,be a homeomorphism such that . Show that .,H: \mathbb{R^2 } \rightarrow \mathbb{R^2} H(\partial B_1)= \partial B_2 H(B_2)=B_1,"Let $B_1,\ B_2 \subset  \mathbb{R^2}$ be disks, and let $H:  \mathbb{R^2 } \rightarrow  \mathbb{R^2}$ be a homeomorhism such that $H(\partial B_1)= \partial B_2$ . Show that $H(B_2)=B_1$ . My attempt: Since $\partial B_1$ , and $\partial B_2$ are 1-spheres, by Schönflies Theorem there exist homeomorphisms $H_1,H_2: \mathbb{R^2} \rightarrow \mathbb{R^2}$ such that $H_1(S^1)= \partial B_1$ , and $H_2(S^1)= \partial B_2$ . So, $S^1 = H_i^{-1}(\partial B_i)$ for $i=1,2$ . $$H_1^{-1}(\partial B_1)=H_2^{-1}(\partial B_2)$$ $$H_2 \circ H_1^{-1}(\partial B_1) = \partial B_2$$ It is clear that $H_2 \circ H_1^{-1}$ is a homemorphism. Now, I wish to prove the following claim. Claim: $H_2 \circ H_1^{-1}(B_1)=B_2$ . This is all I have done so far. Am I on the right track? I am open to any help. Additionally, even though it seems a bit irrelevant I have another question. If we have a homeomorphism $H: \mathbb{R^n} \rightarrow \mathbb{R^n}$ , and we have two homeomorphic subsets of $\mathbb{R^n}$ , say $B$ and $D^2$ ,(unit disk), can we say directly that $H: B \rightarrow D^2$ is also a homeomorphism?","Let be disks, and let be a homeomorhism such that . Show that . My attempt: Since , and are 1-spheres, by Schönflies Theorem there exist homeomorphisms such that , and . So, for . It is clear that is a homemorphism. Now, I wish to prove the following claim. Claim: . This is all I have done so far. Am I on the right track? I am open to any help. Additionally, even though it seems a bit irrelevant I have another question. If we have a homeomorphism , and we have two homeomorphic subsets of , say and ,(unit disk), can we say directly that is also a homeomorphism?","B_1,\ B_2 \subset  \mathbb{R^2} H:  \mathbb{R^2 } \rightarrow  \mathbb{R^2} H(\partial B_1)= \partial B_2 H(B_2)=B_1 \partial B_1 \partial B_2 H_1,H_2: \mathbb{R^2} \rightarrow \mathbb{R^2} H_1(S^1)= \partial B_1 H_2(S^1)= \partial B_2 S^1 = H_i^{-1}(\partial B_i) i=1,2 H_1^{-1}(\partial B_1)=H_2^{-1}(\partial B_2) H_2 \circ H_1^{-1}(\partial B_1) = \partial B_2 H_2 \circ H_1^{-1} H_2 \circ H_1^{-1}(B_1)=B_2 H: \mathbb{R^n} \rightarrow \mathbb{R^n} \mathbb{R^n} B D^2 H: B \rightarrow D^2","['general-topology', 'differential-geometry', 'geometric-topology']"
18,Sphere is a symplectic submanifold of Lie algebra $S0(3)^*$,Sphere is a symplectic submanifold of Lie algebra,S0(3)^*,"I'm working through this example in Peter Olver's textbook Application of Lie Groups to Differential equations and I am having some trouble and was wondering if somebody could point out where I went wrong. So in the first highlighted section, I am trying to understand why this coincides with the tangent space of the sphere. I know that the Hamiltonian vectors are not linearly independent but atleast of them are so they span a $2D$ subspace in the tangent space, however, when we look at the tangent space to the sphere using spherical coordinates I get that it is spanned by $$\frac{d}{d\theta} = -p\sin\theta\sin\phi \frac{d}{du^1} + p \cos\theta\sin\phi \frac{d}{du^2} = -u^2 \frac{d}{du^1} + u^1 \frac{d}{du^2}$$ $$\frac{d}{d\phi} = p\cos\theta\cos\phi \frac{d}{du^1} + p \sin\theta\cos\phi \frac{d}{du^2} - p\sin\phi \frac{d}{du^3}$$ Now the first one coincides with one of the Hamiltonian vectors however the second one I cannot seem to simplify or rewrite so that it looks like any of the other hamiltonian vectors or a linear combination of them. As for the second highlited piece I wrote $ \phi = \arccos(\frac{u^3}{p})$ and $ \theta = \arctan(\frac{u^2}{u^1})$ by solving the spherical coordinates formulas and got the following by computing the gradient with respect to the coordinates $u = (u^1,u^2,u^3)$ $$\nabla_u(\theta) = (\frac{-u^2}{(u^1)^2 +(u^2)^2}, \frac{u^1}{(u^1)^2+(u^2)^2}, 0)$$ $$ \nabla_u(\phi) = (0,0,\frac{-1}{\sqrt{(u^1)^2+ (u^2)^2}}) $$ $$\nabla_u(\theta) \times \nabla_u(\phi) = (\frac{-u^1}{((u^1)^2 + (u^2)^2)^{3/2}}, \frac{-u^2}{((u^1)^2 + (u^2)^2)^{3/2}}, 0)$$ $$ u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = (u^1,u^2,u^3) \cdot (\frac{-u^1}{((u^1)^2 + (u^2)^2)^{3/2}}, \frac{-u^2}{((u^1)^2 + (u^2)^2)^{3/2}}, 0) = \frac{-1}{\sqrt{(u^1)^2+(u^2)^2}}$$ Now changing that back into spherical coordinates I get $$   u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = \frac{-1}{p\sin\phi}$$ $$ \implies - u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = \frac{1}{p\sin\phi} $$ So I am off by a negative sign, I've done the calculations over and I still get the same thing I am not sure where I am going wrong unless this whole process of doing the gradient was wrong.","I'm working through this example in Peter Olver's textbook Application of Lie Groups to Differential equations and I am having some trouble and was wondering if somebody could point out where I went wrong. So in the first highlighted section, I am trying to understand why this coincides with the tangent space of the sphere. I know that the Hamiltonian vectors are not linearly independent but atleast of them are so they span a subspace in the tangent space, however, when we look at the tangent space to the sphere using spherical coordinates I get that it is spanned by Now the first one coincides with one of the Hamiltonian vectors however the second one I cannot seem to simplify or rewrite so that it looks like any of the other hamiltonian vectors or a linear combination of them. As for the second highlited piece I wrote and by solving the spherical coordinates formulas and got the following by computing the gradient with respect to the coordinates Now changing that back into spherical coordinates I get So I am off by a negative sign, I've done the calculations over and I still get the same thing I am not sure where I am going wrong unless this whole process of doing the gradient was wrong.","2D \frac{d}{d\theta} = -p\sin\theta\sin\phi \frac{d}{du^1} + p \cos\theta\sin\phi \frac{d}{du^2} = -u^2 \frac{d}{du^1} + u^1 \frac{d}{du^2} \frac{d}{d\phi} = p\cos\theta\cos\phi \frac{d}{du^1} + p \sin\theta\cos\phi \frac{d}{du^2} - p\sin\phi \frac{d}{du^3}  \phi = \arccos(\frac{u^3}{p})  \theta = \arctan(\frac{u^2}{u^1}) u = (u^1,u^2,u^3) \nabla_u(\theta) = (\frac{-u^2}{(u^1)^2 +(u^2)^2}, \frac{u^1}{(u^1)^2+(u^2)^2}, 0)  \nabla_u(\phi) = (0,0,\frac{-1}{\sqrt{(u^1)^2+ (u^2)^2}})  \nabla_u(\theta) \times \nabla_u(\phi) = (\frac{-u^1}{((u^1)^2 + (u^2)^2)^{3/2}}, \frac{-u^2}{((u^1)^2 + (u^2)^2)^{3/2}}, 0)  u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = (u^1,u^2,u^3) \cdot (\frac{-u^1}{((u^1)^2 + (u^2)^2)^{3/2}}, \frac{-u^2}{((u^1)^2 + (u^2)^2)^{3/2}}, 0) = \frac{-1}{\sqrt{(u^1)^2+(u^2)^2}}    u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = \frac{-1}{p\sin\phi}  \implies - u \cdot (\nabla_u(\theta) \times \nabla_u(\phi)) = \frac{1}{p\sin\phi} ","['differential-geometry', 'symplectic-geometry', 'symplectic-linear-algebra', 'hamilton-equations', 'poisson-geometry']"
19,Finding isometries of a manifold $M$ which has Euclidean geometry,Finding isometries of a manifold  which has Euclidean geometry,M,"How do you find the isometries of a manifold $M$ with metric $ds^2=\frac{du^2}{u^2}+\frac{dv^2}{v^2}?$ Observe that $ds^2$ is of the form $ds^2=g(u)du^2+f(v)dv^2.$ This means that the metric must describe a Euclidean geometry. In fact with more work we can show that $ds^2$ is a transported metric from the familiar $\Bbb R^2$ to $M:=\Bbb R^2_+$ via $\exp.$ I calculated the pullback via an immersion here: \begin{align}  (f^{-1})^* (dx^2 + dy^2) &=( d((f^{-1})^*x))^2 + ( d((f^{-1})^*y))^2 \\ &= (d (x\circ f^{-1}))^2 +(d (y\circ f^{-1}))^2 \\ &= (d \log u)^2 +(d\log v)^2 \\ &= \left( \frac{1}{u} du\right)^2 +  \left( \frac{1}{v} dv\right)^2 \\ &= \frac{1}{u^2} du^2 + \frac{1}{v^2} dv^2. \end{align} Now I know that the isometries of $M$ are basically the isometries of $\Bbb R^2$ in disguise. I figured out that translation in $\Bbb R^2 \implies (x+a,y+b)$ has analogue in $M \implies (ax,by).$ Rotation in $\Bbb R^2 \implies \begin{bmatrix} \cos \theta & -\sin \theta \\   \sin \theta & \cos \theta \\ \end{bmatrix}(x,y)$ has what analogue in $M?$ I couldn't figure this one out.",How do you find the isometries of a manifold with metric Observe that is of the form This means that the metric must describe a Euclidean geometry. In fact with more work we can show that is a transported metric from the familiar to via I calculated the pullback via an immersion here: Now I know that the isometries of are basically the isometries of in disguise. I figured out that translation in has analogue in Rotation in has what analogue in I couldn't figure this one out.,"M ds^2=\frac{du^2}{u^2}+\frac{dv^2}{v^2}? ds^2 ds^2=g(u)du^2+f(v)dv^2. ds^2 \Bbb R^2 M:=\Bbb R^2_+ \exp. \begin{align}
 (f^{-1})^* (dx^2 + dy^2) &=( d((f^{-1})^*x))^2 + ( d((f^{-1})^*y))^2 \\
&= (d (x\circ f^{-1}))^2 +(d (y\circ f^{-1}))^2 \\
&= (d \log u)^2 +(d\log v)^2 \\
&= \left( \frac{1}{u} du\right)^2 +  \left( \frac{1}{v} dv\right)^2 \\
&= \frac{1}{u^2} du^2 + \frac{1}{v^2} dv^2.
\end{align} M \Bbb R^2 \Bbb R^2 \implies (x+a,y+b) M \implies (ax,by). \Bbb R^2 \implies
\begin{bmatrix}
\cos \theta & -\sin \theta \\  
\sin \theta & \cos \theta \\
\end{bmatrix}(x,y) M?","['differential-geometry', 'euclidean-geometry', 'analytic-geometry', 'isometry']"
20,Flows commute if and only if poisson bracket is identically zero,Flows commute if and only if poisson bracket is identically zero,,"I tried the following symplectic geometry exercise and wanted to make sure it was correct Let (M,ω) be a closed symplectic manifold, $f,g ∈ C∞(M)$ two smooth functions and $\phi_t,\psi_t ∈ Ham(M,ω)$ the (autonomous) Hamiltonian flows generated by $X_f$ and $X_g$ . Then  the flows commute, ∀t ∈ [0,1], if and only of the Poisson bracket ${f, g} ≡ ω(Xf , Xg) ∈ C^∞(M)$ is identically zero. Let's first suppose that the poisson bracket is identically zero. Then we will have that $H:=\omega(X_g,X_f)=-\omega(X_f,X_g)=0$ . Then using the fact that $ i([X_f,X_g]) \omega = dH = 0$ we get that $i([X_f,X_g]) \omega =0$ and since $\omega$ is non-degenerate we will get that $[X_f,X_g]=0$ , and now using a standard differential geometry fact we get that the flows commute Now let's assume that $\phi_t \circ \psi_t = \psi_t \circ \phi_t, \forall t\in [0,1]$ .It's a well know fact of geometry that this implies that $[X_f,X_g]=0$ . Then we know that $i([X_f,X_g]) \omega = dH$ where $H=\omega(X_g,X_f)$ . And so this tells us that $d\omega(X_f,X_g)=0$ . Now another way to see this is that in each connected component $U$ the function will be constant,i.e. , $\omega(X_f,X_g)=a_U$ for some $a_U\in \mathbb{R}$ and so this tells us that $df(X_g)=a_U$ and so we get that for any $p\in U, \frac{d}{dt}f(\psi_t(p))=a_U*t+b$ for some $b\in \mathbb{R}$ . Now if we assume that $a_U \neq 0$ we will get a contradiction with the fact that $M$ is compact. Take the sequence $\{\psi_{n}(p)\}_{n=-\infty}^{n=\infty}$ , since $M$ is compact we can take a convergent subsequence $\psi_{n_k}(p)\rightarrow a$ with $n_k\rightarrow \infty$ .Now since the functions involved are continuous we must have that $f(\psi_{n_k}(p))=a_U*(n_k)+b\rightarrow f(a)$ , but the left side is going to infinity while the right side is a finite number and so we obtain a contradiction,and we must have that $a_U=0$ . Since the choice of $U$ was arbitrary we get the desired result. Any input is appreciated. Thanks in advance.","I tried the following symplectic geometry exercise and wanted to make sure it was correct Let (M,ω) be a closed symplectic manifold, two smooth functions and the (autonomous) Hamiltonian flows generated by and . Then  the flows commute, ∀t ∈ [0,1], if and only of the Poisson bracket is identically zero. Let's first suppose that the poisson bracket is identically zero. Then we will have that . Then using the fact that we get that and since is non-degenerate we will get that , and now using a standard differential geometry fact we get that the flows commute Now let's assume that .It's a well know fact of geometry that this implies that . Then we know that where . And so this tells us that . Now another way to see this is that in each connected component the function will be constant,i.e. , for some and so this tells us that and so we get that for any for some . Now if we assume that we will get a contradiction with the fact that is compact. Take the sequence , since is compact we can take a convergent subsequence with .Now since the functions involved are continuous we must have that , but the left side is going to infinity while the right side is a finite number and so we obtain a contradiction,and we must have that . Since the choice of was arbitrary we get the desired result. Any input is appreciated. Thanks in advance.","f,g ∈ C∞(M) \phi_t,\psi_t ∈ Ham(M,ω) X_f X_g {f, g} ≡ ω(Xf , Xg) ∈ C^∞(M) H:=\omega(X_g,X_f)=-\omega(X_f,X_g)=0  i([X_f,X_g]) \omega = dH = 0 i([X_f,X_g]) \omega =0 \omega [X_f,X_g]=0 \phi_t \circ \psi_t = \psi_t \circ \phi_t, \forall t\in [0,1] [X_f,X_g]=0 i([X_f,X_g]) \omega = dH H=\omega(X_g,X_f) d\omega(X_f,X_g)=0 U \omega(X_f,X_g)=a_U a_U\in \mathbb{R} df(X_g)=a_U p\in U, \frac{d}{dt}f(\psi_t(p))=a_U*t+b b\in \mathbb{R} a_U \neq 0 M \{\psi_{n}(p)\}_{n=-\infty}^{n=\infty} M \psi_{n_k}(p)\rightarrow a n_k\rightarrow \infty f(\psi_{n_k}(p))=a_U*(n_k)+b\rightarrow f(a) a_U=0 U","['differential-geometry', 'solution-verification', 'symplectic-geometry']"
21,On the proof about the dimension of the conformal group of a manifold,On the proof about the dimension of the conformal group of a manifold,,"I have been reading the book ""Transformation Groups in Differential Geometry"" by S. Kobayashi. More concretely, I am trying to understand the proof of the Theorem 6.1 of Chapter IV. Theorem 6.1 (S. Kobayashi, 1954) : Let $M$ be a manifold of dimension $n \geq 3$ , and $P$ a conformal structure on $M$ . Then, the conformal transformation group  Conf $(M)$ of $M$ is a Lie group with dimension $\leq \frac{1}{2}(n+1)(n+2)$ . I think I understood the essence of the proof, which is the following: a conformal structure $P$ on $M$ is determinated by a (unique) Cartan connection on $P$ that ""comes from"" the restriction of the canonical form of second frame bundle $P^2(M)$ to $P$ (that connection is constructed in the section 5 of the same chapter and extended to a Cartan connection on $P$ thanks to Theorem 4.2). The uniqueness of that Cartan connection holds since $n\geq 3$ . Now, by using the Theorem 3.1 (of the same book), that states that the group $U(P,\omega)$ of automorphisms of $P$ that preserve the Cartan connection $\omega$ , is a Lie group and has dimension $\leq \dim P = \frac{1}{2}(n+1)(n+2)$ , we obtain the result. Unfortunately, there are two details that I cannot understand. That is why I am posting this question. (1) In the page 143, it is written ""Assume that $n\geq 3$ , so that the normal Cartan connection is unique . Then, for each automorphism $f$ of $P$ , $f_*$ (restricted to $P$ ), preserves the normal connection."" I suppose that this means that for any conformal transformation $f$ on $M$ , the induced map $f_*: P^2(M) \rightarrow P^2(M)$ that sends $P$ into $P$ preserves the Cartan connection $\omega$ on $P$ . Thus, we have that any conformal transformation is an automorphism of $U(P,\omega)$ and then Conf $(M) \subset U(P, \omega)$ . However this affirmation is not clear for me. In other words, how do we know that if the Cartan connection is unique, then any automorphism of $P$ preserves that connection? (2) The other detail that intrigues me is the following: Do we have the equality Conf $(M) = U(P, \omega)$ in general or just Conf $(M) \subset U(P, \omega)$ ? By reading the book it seems that the equality holds; that should justify the fact that Conf $(M)$ is a Lie group by using Theorem 3.1, but I still can't see how to prove this fact. Any comment is highly appreciated.","I have been reading the book ""Transformation Groups in Differential Geometry"" by S. Kobayashi. More concretely, I am trying to understand the proof of the Theorem 6.1 of Chapter IV. Theorem 6.1 (S. Kobayashi, 1954) : Let be a manifold of dimension , and a conformal structure on . Then, the conformal transformation group  Conf of is a Lie group with dimension . I think I understood the essence of the proof, which is the following: a conformal structure on is determinated by a (unique) Cartan connection on that ""comes from"" the restriction of the canonical form of second frame bundle to (that connection is constructed in the section 5 of the same chapter and extended to a Cartan connection on thanks to Theorem 4.2). The uniqueness of that Cartan connection holds since . Now, by using the Theorem 3.1 (of the same book), that states that the group of automorphisms of that preserve the Cartan connection , is a Lie group and has dimension , we obtain the result. Unfortunately, there are two details that I cannot understand. That is why I am posting this question. (1) In the page 143, it is written ""Assume that , so that the normal Cartan connection is unique . Then, for each automorphism of , (restricted to ), preserves the normal connection."" I suppose that this means that for any conformal transformation on , the induced map that sends into preserves the Cartan connection on . Thus, we have that any conformal transformation is an automorphism of and then Conf . However this affirmation is not clear for me. In other words, how do we know that if the Cartan connection is unique, then any automorphism of preserves that connection? (2) The other detail that intrigues me is the following: Do we have the equality Conf in general or just Conf ? By reading the book it seems that the equality holds; that should justify the fact that Conf is a Lie group by using Theorem 3.1, but I still can't see how to prove this fact. Any comment is highly appreciated.","M n \geq 3 P M (M) M \leq \frac{1}{2}(n+1)(n+2) P M P P^2(M) P P n\geq 3 U(P,\omega) P \omega \leq \dim P = \frac{1}{2}(n+1)(n+2) n\geq 3 f P f_* P f M f_*: P^2(M) \rightarrow P^2(M) P P \omega P U(P,\omega) (M) \subset U(P, \omega) P (M) = U(P, \omega) (M) \subset U(P, \omega) (M)","['differential-geometry', 'conformal-geometry', 'fiber-bundles', 'connections', 'geometric-transformation']"
22,Representing $\mathbb{C} P^3$ as $Sp(2) / (SU(2)U(1))$?,Representing  as ?,\mathbb{C} P^3 Sp(2) / (SU(2)U(1)),"I have a question regarding some representations of the three-dimensional complex projective space $\mathbb{C} P^3$ . I am reading the article 'Homogeneous Nearly Kähler manifolds' by Jean-Baptiste Butruille. In it, he claims that $\mathbb{C} P^3 = G/H$ , where $G = Sp(2)$ and $H = SU(2)U(1)$ . Question: I was wondering: what does $SU(2)U(1)$ mean? What group is it? It is clearly not the Cartesian product $SU(2) \times U(1)$ (for it is not a typo in the article). Also, he writes the homogeneous space $\mathbb{C} P^3 \cong Sp(2)/ U(1)Sp(1)$ . Again, I don't understand what the denominator means.","I have a question regarding some representations of the three-dimensional complex projective space . I am reading the article 'Homogeneous Nearly Kähler manifolds' by Jean-Baptiste Butruille. In it, he claims that , where and . Question: I was wondering: what does mean? What group is it? It is clearly not the Cartesian product (for it is not a typo in the article). Also, he writes the homogeneous space . Again, I don't understand what the denominator means.",\mathbb{C} P^3 \mathbb{C} P^3 = G/H G = Sp(2) H = SU(2)U(1) SU(2)U(1) SU(2) \times U(1) \mathbb{C} P^3 \cong Sp(2)/ U(1)Sp(1),"['differential-geometry', 'homogeneous-spaces']"
23,Corollary 11.46 of John Lee's introduction to smooth manifold.,Corollary 11.46 of John Lee's introduction to smooth manifold.,,"The original satatement is that Suppose that $F : M → N$ is a $\textbf{local diffeomorphism}$ . Then the pullback $F^∗:\mathfrak{X}^*(N)\to \mathfrak{X}^*(M)$ takes closed covector fields to closed covector fields, and exact ones to exact ones. The proof of $F^*$ sends exact one to exact one does not use the condition $F$ is a local diffeomorphism. It's used in the proof for the case of closed covector fields. And now my professor said that we can drop the local diffeomorphism condition if $M := U\subset\Bbb R^n$ and $N:=V\subset\Bbb R^m$ . I don't understand why is true in that case. Could anyone explain this?","The original satatement is that Suppose that is a . Then the pullback takes closed covector fields to closed covector fields, and exact ones to exact ones. The proof of sends exact one to exact one does not use the condition is a local diffeomorphism. It's used in the proof for the case of closed covector fields. And now my professor said that we can drop the local diffeomorphism condition if and . I don't understand why is true in that case. Could anyone explain this?",F : M → N \textbf{local diffeomorphism} F^∗:\mathfrak{X}^*(N)\to \mathfrak{X}^*(M) F^* F M := U\subset\Bbb R^n N:=V\subset\Bbb R^m,"['differential-geometry', 'smooth-manifolds']"
24,Normal bundle $\oplus$ tangent bundle is a trivial bundle,Normal bundle  tangent bundle is a trivial bundle,\oplus,I have the same question as in this post Sum of normal bundle and tangent bundle. I'm wondering how to prove that the sum of the normal bundle and the tangent of a submanifold $M \subset \mathbb{R}^n$ is trivial. The answer to this post didn't contain an explanation to the fact that their  direct sum is equal to the pullback of tangent bundle over $\mathbb{R}^n$ ? Could someone please explain why this is true or give another proof ? Thanks,I have the same question as in this post Sum of normal bundle and tangent bundle. I'm wondering how to prove that the sum of the normal bundle and the tangent of a submanifold is trivial. The answer to this post didn't contain an explanation to the fact that their  direct sum is equal to the pullback of tangent bundle over ? Could someone please explain why this is true or give another proof ? Thanks,M \subset \mathbb{R}^n \mathbb{R}^n,"['differential-geometry', 'vector-bundles']"
25,How is the pullback of a Riemannian metric defined?,How is the pullback of a Riemannian metric defined?,,"Let $M, N$ are two manifolds. Now I am interested in defining the pullback of an arbitrary tensor field of type $(r,s)$ under the diffeomorphism $\phi : M \rightarrow N$ as follows: $\phi^* T(\eta_1,\dots, \eta_r, X_1, \dots, X_s) = T( (\phi^{-1})^*(\eta_1), \dots, (\phi^{-1})^*(\eta_r), \phi_* X_1, \dots, \phi_* X_s)$ . where $\eta_i \in T_p^*(M)$ is a covector and $X_j \in T_p(M)$ is a vector. Actually I am interested in pullback of a metric tensor. We know that it is a $(0, 2)$ tensor. Therefore, the above formula becomes $$\phi^*g(X,Y) = g(\phi_*X, \phi_*Y)$$ . Now consider $g_{\alpha \beta}$ is a $(0, 2)$ tensor on $N$ . Now my question is can one write the formula as follows $$(\phi^*g)_{\mu \nu} = \frac{\partial y^{\alpha} }{\partial x^{\mu}} \frac{\partial y^{\beta} }{\partial x^{\nu}} g_{\alpha \beta}$$ . Please help me. Thanking in advanced.","Let are two manifolds. Now I am interested in defining the pullback of an arbitrary tensor field of type under the diffeomorphism as follows: . where is a covector and is a vector. Actually I am interested in pullback of a metric tensor. We know that it is a tensor. Therefore, the above formula becomes . Now consider is a tensor on . Now my question is can one write the formula as follows . Please help me. Thanking in advanced.","M, N (r,s) \phi : M \rightarrow N \phi^* T(\eta_1,\dots, \eta_r, X_1, \dots, X_s) = T( (\phi^{-1})^*(\eta_1), \dots, (\phi^{-1})^*(\eta_r), \phi_* X_1, \dots, \phi_* X_s) \eta_i \in T_p^*(M) X_j \in T_p(M) (0, 2) \phi^*g(X,Y) = g(\phi_*X, \phi_*Y) g_{\alpha \beta} (0, 2) N (\phi^*g)_{\mu \nu} = \frac{\partial y^{\alpha} }{\partial x^{\mu}} \frac{\partial y^{\beta} }{\partial x^{\nu}} g_{\alpha \beta}","['differential-geometry', 'manifolds']"
26,How is the inclusion map both an Immersion and Submersion between Manifolds,How is the inclusion map both an Immersion and Submersion between Manifolds,,"Hi i am trying to figure out why an inclusion map is both and immersion and submersion. This is what i have tried so far.Let $S$ be an open subset of a manifold $M$ . Now the inclusion mapping  is $\iota:S\to M$ . Now to prove immersion/submersion we have to show that each of its differentials $\iota_{*,p}$ , for $p \in S$ , is, resp, injective/surjective. By definition of differential of a smooth map $F$ ,we have $(F_{*,p}(X_p))f=X_p(f\circ F)$ where $F_{*,p}:T_pM\to T_{F(p)}N$ where $M$ and $N$ are manifolds.Now, taking $F$ as the inclusion map $\iota$ , we get $(\iota_{*,p}(X_p))f=X_p(f\circ \iota)=X_p(f)$ where $\iota_{*,p}:T_pS\to T_{\iota(p)=p}M$ . My questions are as follows: How do we know from this that each $\iota_{*,p}$ is injective and surjective so that $\iota$ is both an immersion and a submersion?","Hi i am trying to figure out why an inclusion map is both and immersion and submersion. This is what i have tried so far.Let be an open subset of a manifold . Now the inclusion mapping  is . Now to prove immersion/submersion we have to show that each of its differentials , for , is, resp, injective/surjective. By definition of differential of a smooth map ,we have where where and are manifolds.Now, taking as the inclusion map , we get where . My questions are as follows: How do we know from this that each is injective and surjective so that is both an immersion and a submersion?","S M \iota:S\to M \iota_{*,p} p \in S F (F_{*,p}(X_p))f=X_p(f\circ F) F_{*,p}:T_pM\to T_{F(p)}N M N F \iota (\iota_{*,p}(X_p))f=X_p(f\circ \iota)=X_p(f) \iota_{*,p}:T_pS\to T_{\iota(p)=p}M \iota_{*,p} \iota","['differential-geometry', 'manifolds', 'smooth-manifolds', 'inclusion-exclusion', 'tangent-spaces']"
27,The differential complex of smooth forms,The differential complex of smooth forms,,"I'm  learning my self  about differential forms from the book by Loring Tu, and I've come across this sentence which seems important by I didn't understand it: "" The differential complex of smooth forms on a manifold can be pulled back under a smooth map, making the complex into a contravariant functor called the de Rham complex of the manifold"" I was thinking that the de Rham complex is the same as the complex of differential forms ! Could you please enlight the difference between de Rham complex and the complex of differential forms and what it is meant by ""contravariant functor"" and say more about the above sentence . Thanks a lot!","I'm  learning my self  about differential forms from the book by Loring Tu, and I've come across this sentence which seems important by I didn't understand it: "" The differential complex of smooth forms on a manifold can be pulled back under a smooth map, making the complex into a contravariant functor called the de Rham complex of the manifold"" I was thinking that the de Rham complex is the same as the complex of differential forms ! Could you please enlight the difference between de Rham complex and the complex of differential forms and what it is meant by ""contravariant functor"" and say more about the above sentence . Thanks a lot!",,"['differential-geometry', 'algebraic-topology', 'differential-forms', 'de-rham-cohomology']"
28,Adjoint of the differential in Morse-Novikov cohomology,Adjoint of the differential in Morse-Novikov cohomology,,"Let $M^n$ be a smooth manifold and we can define the Morse-Novikov cohomology group $H^k (M^n,\theta)$ with co-boundary differential operator $d_\theta (w) = dw + \theta \wedge w$ where $0\neq[\theta]∈ H_{dR}^1(M^n)$ . This cohomology shares many properties with the ordinary de Rham cohomology and only depend on $[\theta]$ . As it has been shown that the Hodge theory works nicely on this cohomology by defining the adjoint operator $d_\theta^*$ ( I suppose it defines as usual adjoint $\delta$ of de Rham operator $d$ ) and defining the corresponding Laplacian of these operators. I have the following question: It seems to me that the Stokes’ theorem does not work well with this operator $d_\theta$ because we will have an extra  term which is $\int_M[\theta \wedge w]$ and this implies that the Green formula will not work (i.e. $d_\theta^*$ will no longer be adjoint of $d_\theta$ ). Am I right?",Let be a smooth manifold and we can define the Morse-Novikov cohomology group with co-boundary differential operator where . This cohomology shares many properties with the ordinary de Rham cohomology and only depend on . As it has been shown that the Hodge theory works nicely on this cohomology by defining the adjoint operator ( I suppose it defines as usual adjoint of de Rham operator ) and defining the corresponding Laplacian of these operators. I have the following question: It seems to me that the Stokes’ theorem does not work well with this operator because we will have an extra  term which is and this implies that the Green formula will not work (i.e. will no longer be adjoint of ). Am I right?,"M^n H^k (M^n,\theta) d_\theta (w) = dw + \theta \wedge w 0\neq[\theta]∈ H_{dR}^1(M^n) [\theta] d_\theta^* \delta d d_\theta \int_M[\theta \wedge w] d_\theta^* d_\theta","['differential-geometry', 'homology-cohomology', 'adjoint-operators', 'de-rham-cohomology']"
29,Local isometry which is not covering map,Local isometry which is not covering map,,"The theorem of Ambrose establishes that given a local isometry between two connected Riemannian manifolds $(M, g)$ and $(N,h)$ if $M$ is complete then $f$ is a covering. I was wondering why completeness is necessary and I was trying to construct a local isometry which is not a covering until I realized that I do not know of many examples of local isometries, particularly on non complete manifolds such as the punctured plane. Does anyone know of a few examples? Any help would be welcome, thanks in advance.","The theorem of Ambrose establishes that given a local isometry between two connected Riemannian manifolds and if is complete then is a covering. I was wondering why completeness is necessary and I was trying to construct a local isometry which is not a covering until I realized that I do not know of many examples of local isometries, particularly on non complete manifolds such as the punctured plane. Does anyone know of a few examples? Any help would be welcome, thanks in advance.","(M, g) (N,h) M f","['differential-geometry', 'manifolds', 'isometry']"
30,Immersion and Submersion between Manifolds,Immersion and Submersion between Manifolds,,"I am reading ""An introduction to Manifolds"" by Loring Tu. There they've first defined immersion and submersion between manifolds and then gave an example. In the last line of the example they've written This example shows in particular that a submersion need not be onto. And i am unable to understand that statement. For reference the following is the way they've defined immersion and submersion: A $C^\infty$ map $F:N\to M$ is said to be an immersion at $p\in N$ if its differential $F_{*,p}:T_pN\to T_{F(p)M}$ is injective and a submersion at p if $F_{*,p}$ is surjective.We call F an immersion if it is an immersion at every $p\in N$ and a submersion if it is a submersion at every $p\in N$ . I am attaching the screenshot of the example they've given and there i have highlighted the statement that i could not understand. My doubt is that surjective by definition means onto so how can a submersion need not be onto?","I am reading ""An introduction to Manifolds"" by Loring Tu. There they've first defined immersion and submersion between manifolds and then gave an example. In the last line of the example they've written This example shows in particular that a submersion need not be onto. And i am unable to understand that statement. For reference the following is the way they've defined immersion and submersion: A map is said to be an immersion at if its differential is injective and a submersion at p if is surjective.We call F an immersion if it is an immersion at every and a submersion if it is a submersion at every . I am attaching the screenshot of the example they've given and there i have highlighted the statement that i could not understand. My doubt is that surjective by definition means onto so how can a submersion need not be onto?","C^\infty F:N\to M p\in N F_{*,p}:T_pN\to T_{F(p)M} F_{*,p} p\in N p\in N","['general-topology', 'differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
31,Stereographic projection and complex polynomial. (Do Carmo 2-3-16),Stereographic projection and complex polynomial. (Do Carmo 2-3-16),,"$\newcommand{\set}[1]{\left\lbrace #1 \right\rbrace} \newcommand{\suchthat}{\;\big\vert\;}$ Let $ \mathbb{R}^{2} = \set{(x,y,z)\in\mathbb{R}^{3} \suchthat z=-1} $ be identified with the complex plane $ \mathbb{C} $ by setting $(x,y,-1)=x+iy=\zeta\in\mathbb{C}$ . Let $ P: \mathbb{C}\to\mathbb{C} $ be the complex polynomial \begin{equation*} P(\zeta) = a_{0}\zeta^{n} + a_{1}\zeta^{n-1} + \cdots + a_{n}, \quad a_{0}\neq 0,\, a_{i}\in\mathbb{C},\, i=0,\dots,n. \end{equation*} Denote by $ \pi_{N} $ the stereographic projection of $ S^{2}=\set{(x,y,z)\in\mathbb{R}^{3} \suchthat x^{2}+y^{2}+z^{2}=1 } $ from the North pole $ N=(0,0,1) $ onto $ \mathbb{R}^{2} $ . Prove that the map $ F: S^{2}\to S^{2} $ given by \begin{align*} F(p) &= \pi_{N}^{-1}\circ P \circ \pi_{N}(p), \quad \text{if } p\in S^{2}-\set{N}, \\ F(N) &= N \end{align*} is differentiable. My attempt By using Do Carmo's hint, $ F $ is differentiable in $ S^{2}-\set{N} $ as a composition of differentiable maps. To prove that $ F $ is differentiable at $ N $ , consider the stereographic projection $ \pi_{S} $ from the South pole $ S=(0,0,-1) $ and set $ Q=\pi_{S} \circ F \circ \pi_{S}^{-1}: U \subset \mathbb{C}\to\mathbb{C} $ (of course, we are identifying the plane $ z=1 $ with $ \mathbb{C} $ ) Now, I will show that $ \pi_{N}\circ\pi_{S}^{-1}: \mathbb{C}-\set{0}\to\mathbb{C} $ is given by $ \pi_{N}\circ\pi_{S}^{-1}(\zeta) = 1/\overline{\zeta} $ . Let $ \mathbf{u}=(u,v,1) $ be a point in plane $ z=1 $ (i.e., $ \mathbb{C} $ ); $ \ell_{S}(t) $ be the line through $ S $ with director vector $ \mathbf{u}-S=(u,v,2) $ , then the parametrization of $ \ell_{S} $ is \begin{equation*} \ell_{S}(t) = (0,0,-1) + t(u,v,2) = (tu,tv,2t-1) \end{equation*} and the intersection point $ (x,y,z) $ between $ \ell_{S} $ and $ S^{2} $ (distinct of $ S $ , i.e., $ t \neq 0 $ ) is given by the value of $t$ that satisfies \begin{equation*} (tu)^{2} + (tv)^{2} + (2t-1)^{2}= 1 \quad \implies \quad t^{2}u^{2} + t^{2}v^{2} + 4t^{2} - 4t + 1 = 1 \quad \implies \quad tu^{2} + tv^{2} + 4t = 4 \end{equation*} then \begin{equation*} t=\dfrac{4}{u^{2} + v^{2} + 4} \end{equation*} yields \begin{equation*} (x,y,z) = \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right) \end{equation*} therefore \begin{equation} \pi_{S}^{-1}(u,v) = \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right) \tag{1} \end{equation} Now, to calculate $ \pi_{N}\circ\pi_{S}^{-1} $ , take (1) as a point in $ S^{2} $ and let $ \ell_{N}(t) $ be the line trough $ N $ with director vector $ \pi_{S}^{-1}-N $ , then \begin{align*} \ell_{N}(t) &= (0,0,1) + t\left[ \pi_{S}^{-1} - (0,0,1) \right] \\[2ex]  &= (0,0,1) + t\left[ \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right) - (0,0,1) \right] \\[2ex]  &= (0,0,1) + t\left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{-2(u^{2}+v^{2})}{u^{2} + v^{2} + 4} \right) \end{align*} And for this point to belong to the plane $ z=-1 $ (i.e., $ \mathbb{C} $ ) clearly we need that \begin{equation*} \dfrac{-2(u^{2}+v^{2})}{u^{2} + v^{2} + 4}t+1=-1 \quad \implies \quad t=\dfrac{u^{2} + v^{2} + 4}{u^{2} + v^{2}} \end{equation*} thus \begin{equation*} (x,y,-1) = \left( \dfrac{4u}{u^{2}+v^{2}}, \dfrac{4v}{u^{2}+v^{2}}, -1 \right) \end{equation*} therefore \begin{equation} \pi_{N}\circ\pi_{S}^{-1}(u,v) = \left( \dfrac{4u}{u^{2}+v^{2}}, \dfrac{4v}{u^{2}+v^{2}}, -1 \right) \tag{2} \end{equation} where $ (u,v-1) = u + iv = \zeta $ . \ But the inverse of conjugate of $ \zeta $ should be \begin{equation} 1/\overline{\zeta} = \left( \dfrac{u}{u^{2}+v^{2}}, \dfrac{v}{u^{2}+v^{2}}, -1 \right) \tag{3} \end{equation} My Question . Where is my mistake? Do Carmo's book says the equation should be like (3). I'm confused. Next step is conclude that \begin{equation*}  Q(\zeta) = \dfrac{\zeta^{n}}{\overline{a_{0}} + \overline{a_{1}}\zeta + \cdots + \overline{a_{n}}\zeta^{n}}    \end{equation*} We have the next relations (if $ F \neq N $ ) \begin{align*} Q(\zeta) &= \left( \pi_{S}\circ F \circ\pi_{S}^{-1} \right) (\zeta) = \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \circ\pi_{N} \circ\pi_{S}^{-1} \right) (\zeta) \\ &= \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \right) \circ \left( \pi_{N}\circ\pi_{S}^{-1}(\zeta) \right) \\ &= \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \right) (1/\overline{\zeta}) \\ &= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \circ P(1/\overline{\zeta}) \\ &= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left( a_{0}\left(1/\overline{\zeta}^{n}\right) + a_{1}\left(1/\overline{\zeta}^{n-1}\right) + \cdots + a_{n} \right) \\ &= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left(  \left( 1/\overline{\zeta}^{n} \right)\left( a_{0}+a_{1}\overline{\zeta} + \cdots + a_{n}\overline{\zeta}^{n} \right) \right) \end{align*} Since $ \pi_{S}\circ \pi_{N}^{-1} = \left( \pi_{N}\circ\pi_{S}^{-1} \right)^{-1} $ should be $ \pi_{S}\circ \pi_{N}^{-1} = 1/\overline{\zeta} $ as well. Thus \begin{align*} Q(\zeta) &= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left(  \left( 1/\overline{\zeta}^{n} \right)\left( a_{0}+a_{1}\overline{\zeta} + \cdots + a_{n}\overline{\zeta}^{n} \right) \right) \\  &= \dfrac{\zeta^{n}}{\overline{a_{0}} + \overline{a_{1}}\zeta + \cdots + \overline{a_{n}}\zeta^{n}}    \end{align*} Hence, $ Q $ is differentiable at $ \zeta=0 $ . Thus, $ F = \pi_{S}^{-1}\circ Q \circ\pi_{S} $ is differentiable at $ N $ .","Let be identified with the complex plane by setting . Let be the complex polynomial Denote by the stereographic projection of from the North pole onto . Prove that the map given by is differentiable. My attempt By using Do Carmo's hint, is differentiable in as a composition of differentiable maps. To prove that is differentiable at , consider the stereographic projection from the South pole and set (of course, we are identifying the plane with ) Now, I will show that is given by . Let be a point in plane (i.e., ); be the line through with director vector , then the parametrization of is and the intersection point between and (distinct of , i.e., ) is given by the value of that satisfies then yields therefore Now, to calculate , take (1) as a point in and let be the line trough with director vector , then And for this point to belong to the plane (i.e., ) clearly we need that thus therefore where . \ But the inverse of conjugate of should be My Question . Where is my mistake? Do Carmo's book says the equation should be like (3). I'm confused. Next step is conclude that We have the next relations (if ) Since should be as well. Thus Hence, is differentiable at . Thus, is differentiable at .","\newcommand{\set}[1]{\left\lbrace #1 \right\rbrace} \newcommand{\suchthat}{\;\big\vert\;}  \mathbb{R}^{2} = \set{(x,y,z)\in\mathbb{R}^{3} \suchthat z=-1}   \mathbb{C}  (x,y,-1)=x+iy=\zeta\in\mathbb{C}  P: \mathbb{C}\to\mathbb{C}  \begin{equation*}
P(\zeta) = a_{0}\zeta^{n} + a_{1}\zeta^{n-1} + \cdots + a_{n}, \quad a_{0}\neq 0,\, a_{i}\in\mathbb{C},\, i=0,\dots,n.
\end{equation*}  \pi_{N}   S^{2}=\set{(x,y,z)\in\mathbb{R}^{3} \suchthat x^{2}+y^{2}+z^{2}=1 }   N=(0,0,1)   \mathbb{R}^{2}   F: S^{2}\to S^{2}  \begin{align*}
F(p) &= \pi_{N}^{-1}\circ P \circ \pi_{N}(p), \quad \text{if } p\in S^{2}-\set{N}, \\
F(N) &= N
\end{align*}  F   S^{2}-\set{N}   F   N   \pi_{S}   S=(0,0,-1)   Q=\pi_{S} \circ F \circ \pi_{S}^{-1}: U \subset \mathbb{C}\to\mathbb{C}   z=1   \mathbb{C}   \pi_{N}\circ\pi_{S}^{-1}: \mathbb{C}-\set{0}\to\mathbb{C}   \pi_{N}\circ\pi_{S}^{-1}(\zeta) = 1/\overline{\zeta}   \mathbf{u}=(u,v,1)   z=1   \mathbb{C}   \ell_{S}(t)   S   \mathbf{u}-S=(u,v,2)   \ell_{S}  \begin{equation*}
\ell_{S}(t) = (0,0,-1) + t(u,v,2) = (tu,tv,2t-1)
\end{equation*}  (x,y,z)   \ell_{S}   S^{2}   S   t \neq 0  t \begin{equation*}
(tu)^{2} + (tv)^{2} + (2t-1)^{2}= 1 \quad \implies \quad t^{2}u^{2} + t^{2}v^{2} + 4t^{2} - 4t + 1 = 1 \quad \implies \quad tu^{2} + tv^{2} + 4t = 4
\end{equation*} \begin{equation*}
t=\dfrac{4}{u^{2} + v^{2} + 4}
\end{equation*} \begin{equation*}
(x,y,z) = \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right)
\end{equation*} \begin{equation}
\pi_{S}^{-1}(u,v) = \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right)
\tag{1}
\end{equation}  \pi_{N}\circ\pi_{S}^{-1}   S^{2}   \ell_{N}(t)   N   \pi_{S}^{-1}-N  \begin{align*}
\ell_{N}(t) &= (0,0,1) + t\left[ \pi_{S}^{-1} - (0,0,1) \right] \\[2ex]
 &= (0,0,1) + t\left[ \left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{4-u^{2}-v^{2}}{u^{2} + v^{2} + 4} \right) - (0,0,1) \right] \\[2ex]
 &= (0,0,1) + t\left( \dfrac{4u}{u^{2} + v^{2} + 4}, \dfrac{4v}{u^{2} + v^{2} + 4}, \dfrac{-2(u^{2}+v^{2})}{u^{2} + v^{2} + 4} \right)
\end{align*}  z=-1   \mathbb{C}  \begin{equation*}
\dfrac{-2(u^{2}+v^{2})}{u^{2} + v^{2} + 4}t+1=-1 \quad \implies \quad t=\dfrac{u^{2} + v^{2} + 4}{u^{2} + v^{2}}
\end{equation*} \begin{equation*}
(x,y,-1) = \left( \dfrac{4u}{u^{2}+v^{2}}, \dfrac{4v}{u^{2}+v^{2}}, -1 \right)
\end{equation*} \begin{equation}
\pi_{N}\circ\pi_{S}^{-1}(u,v) = \left( \dfrac{4u}{u^{2}+v^{2}}, \dfrac{4v}{u^{2}+v^{2}}, -1 \right)
\tag{2}
\end{equation}  (u,v-1) = u + iv = \zeta   \zeta  \begin{equation}
1/\overline{\zeta} = \left( \dfrac{u}{u^{2}+v^{2}}, \dfrac{v}{u^{2}+v^{2}}, -1 \right)
\tag{3}
\end{equation} \begin{equation*}
 Q(\zeta) = \dfrac{\zeta^{n}}{\overline{a_{0}} + \overline{a_{1}}\zeta + \cdots + \overline{a_{n}}\zeta^{n}}   
\end{equation*}  F \neq N  \begin{align*}
Q(\zeta) &= \left( \pi_{S}\circ F \circ\pi_{S}^{-1} \right) (\zeta) = \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \circ\pi_{N} \circ\pi_{S}^{-1} \right) (\zeta) \\
&= \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \right) \circ \left( \pi_{N}\circ\pi_{S}^{-1}(\zeta) \right) \\
&= \left( \pi_{S}\circ \pi_{N}^{-1} \circ P \right) (1/\overline{\zeta}) \\
&= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \circ P(1/\overline{\zeta}) \\
&= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left( a_{0}\left(1/\overline{\zeta}^{n}\right) + a_{1}\left(1/\overline{\zeta}^{n-1}\right) + \cdots + a_{n} \right) \\
&= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left(  \left( 1/\overline{\zeta}^{n} \right)\left( a_{0}+a_{1}\overline{\zeta} + \cdots + a_{n}\overline{\zeta}^{n} \right) \right)
\end{align*}  \pi_{S}\circ \pi_{N}^{-1} = \left( \pi_{N}\circ\pi_{S}^{-1} \right)^{-1}   \pi_{S}\circ \pi_{N}^{-1} = 1/\overline{\zeta}  \begin{align*}
Q(\zeta) &= \left( \pi_{S}\circ \pi_{N}^{-1} \right) \left(  \left( 1/\overline{\zeta}^{n} \right)\left( a_{0}+a_{1}\overline{\zeta} + \cdots + a_{n}\overline{\zeta}^{n} \right) \right) \\
 &= \dfrac{\zeta^{n}}{\overline{a_{0}} + \overline{a_{1}}\zeta + \cdots + \overline{a_{n}}\zeta^{n}}   
\end{align*}  Q   \zeta=0   F = \pi_{S}^{-1}\circ Q \circ\pi_{S}   N ","['differential-geometry', 'stereographic-projections']"
32,How to find a path tangent to a distribution,How to find a path tangent to a distribution,,"Let $D$ be the smooth distribution on $\mathbb{R}^3$ such that $$ D_{(a,b,c)}=\{\,(x,y,z)\in\mathbb{R}^3\,:\,z-bx=0\,\}. $$ How to show that for any $p,\,q\in\mathbb{R}^3$ , there exists a path $\alpha$ from $p$ to $q$ tangent to $D$ ?","Let be the smooth distribution on such that How to show that for any , there exists a path from to tangent to ?","D \mathbb{R}^3 
D_{(a,b,c)}=\{\,(x,y,z)\in\mathbb{R}^3\,:\,z-bx=0\,\}.
 p,\,q\in\mathbb{R}^3 \alpha p q D",['differential-geometry']
33,Definition of integration of a differential form (John Lee),Definition of integration of a differential form (John Lee),,"In Chapter 16 of John Lee's book Introduction to Smooth Manifolds , he defines integrals over subspaces of $\mathbb R^n$ as follows: If $D\subseteq\mathbb R^n$ is a bounded subset whose boundary has measure zero, and if $\omega$ is a continuous $n$ -form on $\overline D$ , then write $\omega=fdx^1\wedge\dots\wedge dx^n$ for some continuous function $f:\overline D\to\mathbb R$ . Then the integral of $\omega$ over $D$ is $$\int_D\omega=\int_DfdV.$$ My (possibly dumb) question is: Why does $\omega$ have to be defined on $\overline D$ ? Shouldn't it be enough for $\omega$ to be a continuous $n$ -form defined on $D$ ?","In Chapter 16 of John Lee's book Introduction to Smooth Manifolds , he defines integrals over subspaces of as follows: If is a bounded subset whose boundary has measure zero, and if is a continuous -form on , then write for some continuous function . Then the integral of over is My (possibly dumb) question is: Why does have to be defined on ? Shouldn't it be enough for to be a continuous -form defined on ?",\mathbb R^n D\subseteq\mathbb R^n \omega n \overline D \omega=fdx^1\wedge\dots\wedge dx^n f:\overline D\to\mathbb R \omega D \int_D\omega=\int_DfdV. \omega \overline D \omega n D,"['differential-geometry', 'definition', 'smooth-manifolds', 'differential-forms']"
34,Proving the map $\Psi: \mathcal{V}_pM\to T_pM$ defined by $\Psi[\gamma] = \gamma'(0)$ is well defined and bijective.,Proving the map  defined by  is well defined and bijective.,\Psi: \mathcal{V}_pM\to T_pM \Psi[\gamma] = \gamma'(0),I am reading Professor Lee's Intro to Smooth Manifolds book and one of the problems asks the following. How would you approach a proof to this? Also do I need to prove it is well defined? Or is that just a byproduct? Thank you for your time and help! Let $M$ be a smooth manifold with or without boundary and $p\in M.$ Let $\mathcal{V}_pM$ denote the set of equivalence classes of smooth curves starting at $p$ under the relation $\gamma_1 \sim \gamma_2$ if $(f\circ \gamma_1)'(0) = (f\circ \gamma_2)'(0)$ for every smooth real-valued function $f$ defined in a neighborhood of $p.$ Show that the map $\Psi: \mathcal{V}_pM\to T_pM$ defined by $\Psi[\gamma] = \gamma'(0)$ is well defined and bijective.,I am reading Professor Lee's Intro to Smooth Manifolds book and one of the problems asks the following. How would you approach a proof to this? Also do I need to prove it is well defined? Or is that just a byproduct? Thank you for your time and help! Let be a smooth manifold with or without boundary and Let denote the set of equivalence classes of smooth curves starting at under the relation if for every smooth real-valued function defined in a neighborhood of Show that the map defined by is well defined and bijective.,M p\in M. \mathcal{V}_pM p \gamma_1 \sim \gamma_2 (f\circ \gamma_1)'(0) = (f\circ \gamma_2)'(0) f p. \Psi: \mathcal{V}_pM\to T_pM \Psi[\gamma] = \gamma'(0),"['differential-geometry', 'smooth-manifolds', 'tangent-bundle']"
35,Why is the blow up of a submanifold of $\mathbb{P}^n$ again projective,Why is the blow up of a submanifold of  again projective,\mathbb{P}^n,"I saw somewhere that the blow up (at any point) of a submanifold of $\mathbb{P}^n$ is still projective. I have the feeling that this is a consequence of the Kodaira embedding theorem, any thoughts?","I saw somewhere that the blow up (at any point) of a submanifold of is still projective. I have the feeling that this is a consequence of the Kodaira embedding theorem, any thoughts?",\mathbb{P}^n,"['differential-geometry', 'manifolds', 'complex-geometry', 'projective-space', 'blowup']"
36,Reparametrization theorem,Reparametrization theorem,,"The reparametrization theorem says the following: If $α:I\to\mathbb{R}^n$ is a regular curve in $\mathbb{R}^n$ , then there exists a reparametrization $\beta$ of $\alpha$ such that $β$ has unit speed. My question is this: If the curve is not regular, then is there no arc length parameterization?. What I tried was to get the following example $t\mapsto (|t|t,t^2)$ for $t\in[-1,1]$ whose graph would approximate this: It is understood that when reaching point $(0,0)$ the particle that follows this route stops instantly and then he continues its journey, but if there were a parameterization $\beta$ by arc length, it means that when reaching that point it would continue with $||\beta'||=1$ , is there such a possibility? How would it be explained if it existed. Thanks.","The reparametrization theorem says the following: If is a regular curve in , then there exists a reparametrization of such that has unit speed. My question is this: If the curve is not regular, then is there no arc length parameterization?. What I tried was to get the following example for whose graph would approximate this: It is understood that when reaching point the particle that follows this route stops instantly and then he continues its journey, but if there were a parameterization by arc length, it means that when reaching that point it would continue with , is there such a possibility? How would it be explained if it existed. Thanks.","α:I\to\mathbb{R}^n \mathbb{R}^n \beta \alpha β t\mapsto (|t|t,t^2) t\in[-1,1] (0,0) \beta ||\beta'||=1","['differential-geometry', 'curves', 'arc-length']"
37,"Is the set $\{x \in \mathbb R^n : d(x, M) = c\}$ a smooth manifold for a small constant $c$ when $M$ is a smooth manifold embedded in $\mathbb R^n$?",Is the set  a smooth manifold for a small constant  when  is a smooth manifold embedded in ?,"\{x \in \mathbb R^n : d(x, M) = c\} c M \mathbb R^n","I am a beginner of differential geometry. Let $M$ be a smooth manifold embedded in $\mathbb R^n$ and consider the subset $$       S = \{x \in \mathbb R^n : d(x, M) = c \}, $$ where $d(x, M)$ denotes the distance between a point $x$ and the manifold $M$ . I would like to know if $S$ is a smooth (at least $C^1$ ) manifold for sufficiently small $c > 0$ . In one of the simplest cases, that $M$ is a (finite) line segment in $\mathbb R^3$ , I think $S$ is the union of a cylinder of radius $c$ with its center line $M$ and two half spheres attached to the both ends of the cylinder, and $S$ is smooth.","I am a beginner of differential geometry. Let be a smooth manifold embedded in and consider the subset where denotes the distance between a point and the manifold . I would like to know if is a smooth (at least ) manifold for sufficiently small . In one of the simplest cases, that is a (finite) line segment in , I think is the union of a cylinder of radius with its center line and two half spheres attached to the both ends of the cylinder, and is smooth.","M \mathbb R^n 
      S = \{x \in \mathbb R^n : d(x, M) = c \},
 d(x, M) x M S C^1 c > 0 M \mathbb R^3 S c M S",[]
38,Relations between two definitions of Lie algebra,Relations between two definitions of Lie algebra,,"This post follows from another post What is exponential map in differential geometry about two kinds of exponential maps (of Riemannian groups and of Lie groups, separately) and Lie algebra. It is inspired by discussions following the answer, which are not repeated here. It’s said there are two definitions of Lie algebra (tangent space, left invariant vector field). (Edited to add:) (The question is originally stated as ‘ Relations between two two definitions of exponential maps’, that’s something I’m also interested in, I may put another post for that if necessary.) (Edited to add:) By far I guess Lie algebra is a bit like a collection $G$ of left invariant (well behaved) vector field such that from a vector at a point we can infer or generate vectors at all other points, (i.e. a well behaved vector field), for these vectors are somehow the same or homogeneous; the homogeneity and generalizability is what the invariant means. [It's, as explained below, invariant of vector fields $X$ or phase space... w.r.t. the operation $+$ of Lie group. e.g. $X_{p+q} = X_q$ for all $p, q$ in the Lie group.](Probably right invariant works too) So there is a one one correspondence between a left invariant vector field in $G$ and a vector in a tangent space $T_qM$ (it seems, according to some other posts, $q$ can be any point and we prefer identity for it’s convenient.) and so $G$ of these vector fields and $T_qM$ are isomorphic or have at least some kind of one one correspondence and so the two definitions are consistent. The definition of Lie algebra also includes the consideration of commutability of two left invariant vector fields. For that purpose we define an unusual multiplication [,]. Why we particularly need to take care of that commutability? I guess it’s for the the expansion of log (exp(X)exp(Y)), as mentioned in the comment of the origin post. (Btw, in the tangent space definition do we need to consider commutability?) Why we do such expansion? It’s because the idea of exponential maps of Lie groups originates from exponent of matrix? In a word, the left invariant definition seems to justify the tangent space definition (I guess there is a related proof) and if we consider tangent space at all points and carefully pick up a vector of invariant property (like of certain length and direction) from each tangent space we may well visualize ANY left invariant vector field. And it is isomorphic to a vector of tangent space at ONE point. (The following continues discussion, in comments on an answer, on notations in Lie group) About notations, using Lie group $M$ as an example, $\ell_q:M\to M$ (or in Spivak's notation, $L_a$ ) is adding a point $q$ to any point in $M$ (such addition is possible since we impose a Lie group structure to a manifold ), while $\ell_{q*} $ (or $\ L_{a*}$ ) is the derived operation for the tangent space of Lie group $M$ (NOT the Lie group itself) at a point $q$ , e.g. $T_pM$ or $M_p$ (it confuses me since the two denote the same thing), adding q to p (NOT adding elements in tangent space) to get tangent space $T_{q+p}M$ . Using Lie group $SO(2)$ (~ $S^1$ ) as an example $\ell_A:SO(2)\to SO(2)$ is multiplying a matrix $A$ to any matrix in $SO(2)$ , while $\ell_{A*}$ is the derived operation for the tangent space of Lie group $SO(2)$ at a point $p$ , e.g. $T_pS^1$ , adding q to p to get tangent space $T_{q+p}S^1$ . Left invariant means a vector field (or a collection of vector fields, or all tangent vectors at all points or in phsical context the phase space, or in symplectic geometry and the Hamiltonian mechanics (which I know little) the similar pair of position and velocity), each element of it for any 'distance' (any element in Lie group) being transferred or moving to another point and we still get the same vector field (or vector fields, or phase space...). (Complement: considering Lie derivative of a vector field, this seems to somehow the same as saying $L_XX=0$ , which in terms of Lie algebra, just $[X,X]=0$ in the definition; by seeing [ , ] as 'derivative' it seems the meaning is clearer. Put that view in the context of matrix Lie group, e.g. $SO(2)$ where $[A, A]=0, [A, B]=0$ , it's like saying the two vector fields corresponding to two tangent vectors at a same point differentiated against themselves and, sometimes, even against each other equals zero.) And Lie group basically enables us to to interpret a point at a manifold as a distance, similar to that we can treat a vector (position) in Euclidean space as a displacement (by setting the 'original point' $O$ , which 'becomes' in Lie group the unit $e$ ). With Lie group we 'geometrify' the non-geometrical objects like a matrix set, and 'numerify' the non numerical objects like a manifold. And exponential maps basically links (though not necessarily one one) a tangent vector to a point at a manifold (geometrical manifolds like surface or more abstract manifold like a matrix set, the two corresponding to the two kinds of exponential maps I guess) interpreted as a 'distance'/displacement. With exponential maps we link tangent space (a vector space) to the manifold (now made a Lie group). But here comes another question, which I states in another post: why we need to, with exponential maps, make a link between a tangent space and the manifold?","This post follows from another post What is exponential map in differential geometry about two kinds of exponential maps (of Riemannian groups and of Lie groups, separately) and Lie algebra. It is inspired by discussions following the answer, which are not repeated here. It’s said there are two definitions of Lie algebra (tangent space, left invariant vector field). (Edited to add:) (The question is originally stated as ‘ Relations between two two definitions of exponential maps’, that’s something I’m also interested in, I may put another post for that if necessary.) (Edited to add:) By far I guess Lie algebra is a bit like a collection of left invariant (well behaved) vector field such that from a vector at a point we can infer or generate vectors at all other points, (i.e. a well behaved vector field), for these vectors are somehow the same or homogeneous; the homogeneity and generalizability is what the invariant means. [It's, as explained below, invariant of vector fields or phase space... w.r.t. the operation of Lie group. e.g. for all in the Lie group.](Probably right invariant works too) So there is a one one correspondence between a left invariant vector field in and a vector in a tangent space (it seems, according to some other posts, can be any point and we prefer identity for it’s convenient.) and so of these vector fields and are isomorphic or have at least some kind of one one correspondence and so the two definitions are consistent. The definition of Lie algebra also includes the consideration of commutability of two left invariant vector fields. For that purpose we define an unusual multiplication [,]. Why we particularly need to take care of that commutability? I guess it’s for the the expansion of log (exp(X)exp(Y)), as mentioned in the comment of the origin post. (Btw, in the tangent space definition do we need to consider commutability?) Why we do such expansion? It’s because the idea of exponential maps of Lie groups originates from exponent of matrix? In a word, the left invariant definition seems to justify the tangent space definition (I guess there is a related proof) and if we consider tangent space at all points and carefully pick up a vector of invariant property (like of certain length and direction) from each tangent space we may well visualize ANY left invariant vector field. And it is isomorphic to a vector of tangent space at ONE point. (The following continues discussion, in comments on an answer, on notations in Lie group) About notations, using Lie group as an example, (or in Spivak's notation, ) is adding a point to any point in (such addition is possible since we impose a Lie group structure to a manifold ), while (or ) is the derived operation for the tangent space of Lie group (NOT the Lie group itself) at a point , e.g. or (it confuses me since the two denote the same thing), adding q to p (NOT adding elements in tangent space) to get tangent space . Using Lie group (~ ) as an example is multiplying a matrix to any matrix in , while is the derived operation for the tangent space of Lie group at a point , e.g. , adding q to p to get tangent space . Left invariant means a vector field (or a collection of vector fields, or all tangent vectors at all points or in phsical context the phase space, or in symplectic geometry and the Hamiltonian mechanics (which I know little) the similar pair of position and velocity), each element of it for any 'distance' (any element in Lie group) being transferred or moving to another point and we still get the same vector field (or vector fields, or phase space...). (Complement: considering Lie derivative of a vector field, this seems to somehow the same as saying , which in terms of Lie algebra, just in the definition; by seeing [ , ] as 'derivative' it seems the meaning is clearer. Put that view in the context of matrix Lie group, e.g. where , it's like saying the two vector fields corresponding to two tangent vectors at a same point differentiated against themselves and, sometimes, even against each other equals zero.) And Lie group basically enables us to to interpret a point at a manifold as a distance, similar to that we can treat a vector (position) in Euclidean space as a displacement (by setting the 'original point' , which 'becomes' in Lie group the unit ). With Lie group we 'geometrify' the non-geometrical objects like a matrix set, and 'numerify' the non numerical objects like a manifold. And exponential maps basically links (though not necessarily one one) a tangent vector to a point at a manifold (geometrical manifolds like surface or more abstract manifold like a matrix set, the two corresponding to the two kinds of exponential maps I guess) interpreted as a 'distance'/displacement. With exponential maps we link tangent space (a vector space) to the manifold (now made a Lie group). But here comes another question, which I states in another post: why we need to, with exponential maps, make a link between a tangent space and the manifold?","G X + X_{p+q} = X_q p, q G T_qM q G T_qM M \ell_q:M\to M L_a q M \ell_{q*}  \ L_{a*} M q T_pM M_p T_{q+p}M SO(2) S^1 \ell_A:SO(2)\to SO(2) A SO(2) \ell_{A*} SO(2) p T_pS^1 T_{q+p}S^1 L_XX=0 [X,X]=0 SO(2) [A, A]=0, [A, B]=0 O e","['differential-geometry', 'lie-groups', 'lie-algebras']"
39,Differential of gradient on submanifold of Euclidean space,Differential of gradient on submanifold of Euclidean space,,"I'm currently selfstudying (and new to) differential geometry and I came across something, that I can't make sense of at the moment. Let $M$ be a submanifold of $\mathbb{R}^{n}$ and let $u,f:M\longrightarrow\mathbb{R}$ be a function. The gradient $\nabla^{M}$ of $f$ is defined by the property, that $g_{p}(\nabla^{M}f,X)=d_{p}f(X)$ , where $p\in M$ , $X\in TM$ satisfying $X(p)\in T_{p}M$ and $d_{p}f:T_{p}M\longrightarrow T_{f(p)}\mathbb{R}=\mathbb{R}$ . Since the defining property holds for all vector fields $X$ , we get that $\nabla^{M}f(p)=g^{ij}d_{p}f$ , where $g^{ij}$ is inverse matrix of the matrix representing the first fundamental form. Now, let $u(x)=\nabla^{M}f(x)$ . My questions are: What is the differential $d_{p}u$ of $u$ ? Is there, consequently, a meaningful object for something like the ""second derivative"" aka. the Hessian of $f$ ? Thanks in advance.","I'm currently selfstudying (and new to) differential geometry and I came across something, that I can't make sense of at the moment. Let be a submanifold of and let be a function. The gradient of is defined by the property, that , where , satisfying and . Since the defining property holds for all vector fields , we get that , where is inverse matrix of the matrix representing the first fundamental form. Now, let . My questions are: What is the differential of ? Is there, consequently, a meaningful object for something like the ""second derivative"" aka. the Hessian of ? Thanks in advance.","M \mathbb{R}^{n} u,f:M\longrightarrow\mathbb{R} \nabla^{M} f g_{p}(\nabla^{M}f,X)=d_{p}f(X) p\in M X\in TM X(p)\in T_{p}M d_{p}f:T_{p}M\longrightarrow T_{f(p)}\mathbb{R}=\mathbb{R} X \nabla^{M}f(p)=g^{ij}d_{p}f g^{ij} u(x)=\nabla^{M}f(x) d_{p}u u f","['differential-geometry', 'riemannian-geometry', 'submanifold']"
40,What is an example of a non-Riemannian manifold?,What is an example of a non-Riemannian manifold?,,"A Riemannian manifold $(M,g)$ is a manifold equipped with a metric tensor ( $g$ ) that is both symmetric and positive definite. Now if the metric tensor is symmetric but not positive definite, then it's a pseudo-Riemannian manifold. But what the case of a manifold equipped with a metric tensor $(M,g)$ such that $g$ is not symmetric(regardless of whether it is or is not positive definite)? That is, $\forall (x,y) \ such \ that (\ x \neq  y \ )  \in T_{p}(M) \ g(x,y)\neq g(y,x)$ at any point p in M.","A Riemannian manifold is a manifold equipped with a metric tensor ( ) that is both symmetric and positive definite. Now if the metric tensor is symmetric but not positive definite, then it's a pseudo-Riemannian manifold. But what the case of a manifold equipped with a metric tensor such that is not symmetric(regardless of whether it is or is not positive definite)? That is, at any point p in M.","(M,g) g (M,g) g \forall (x,y) \ such \ that (\ x \neq  y \ )  \in T_{p}(M) \ g(x,y)\neq g(y,x)","['differential-geometry', 'manifolds', 'riemannian-geometry']"
41,Smooth maps between manifolds are continuous,Smooth maps between manifolds are continuous,,"The comments in this question Smooth maps (between manifolds) are continuous (comment in Barrett O'Neill's textbook) seem to suggest that a smooth map ""in charts"", id est satisfying the definition A mapping $\phi:M\rightarrow N$ is smooth provided that for every coordinate system $\xi$ in M and $\eta$ in N the coordinate expression $\eta\circ\phi\circ\xi^{-1}$ is Euclidean smooth. might not be continuous. Here, I'm thinking every meaning every coordinate system in the maximal atlas. I am not sure if O'Neil uses maximal atlases but I would like to know the answer for maximal atlases all the same. The definition of maximal atlas can be found here: https://en.wikipedia.org/wiki/Smooth_structure . Since in this definition, I am not guaranteed that the domain of $\eta\circ\phi\circ\xi^{-1}$ is open let's say that here smooth means that it is the restriction of a smooth map defined on an open set. Does there exist a counterexample of a map satisfying this property that is not continuous?","The comments in this question Smooth maps (between manifolds) are continuous (comment in Barrett O'Neill's textbook) seem to suggest that a smooth map ""in charts"", id est satisfying the definition A mapping is smooth provided that for every coordinate system in M and in N the coordinate expression is Euclidean smooth. might not be continuous. Here, I'm thinking every meaning every coordinate system in the maximal atlas. I am not sure if O'Neil uses maximal atlases but I would like to know the answer for maximal atlases all the same. The definition of maximal atlas can be found here: https://en.wikipedia.org/wiki/Smooth_structure . Since in this definition, I am not guaranteed that the domain of is open let's say that here smooth means that it is the restriction of a smooth map defined on an open set. Does there exist a counterexample of a map satisfying this property that is not continuous?",\phi:M\rightarrow N \xi \eta \eta\circ\phi\circ\xi^{-1} \eta\circ\phi\circ\xi^{-1},"['differential-geometry', 'smooth-manifolds']"
42,"What are Minkowski space and Lorentzian manifolds, formally speaking?","What are Minkowski space and Lorentzian manifolds, formally speaking?",,"I am in general confused about what Minkowski space is . I'll write down what I know and what I believe Minkowski space is. I'd appreciate any corrections. A Riemannian manifold is a manifold (so it locally looks like $\mathbb R^n$ ) equipped with a non-negative positive symmetric bilinear form (the metric). Hyperbolic space is a type of Riemannian manifold, where it locally looks like $\mathbb R^n$ , but globally the space has negative curvature. This gives it all of the weird properties we know and love [geodesics getting exponentially farther away, thin triangles, etc.] 'Minkowski space' naively speaking is some space $\mathbb  M \equiv \mathbb (\mathbb R^4, d)$ equipped with the metric $d(p, q) = p_0 q_0 - p_1 q_1 - p_2 q_2 - p_3 q_3$ . This looks exactly like the hyperboloid model of hyperbolic space . So it far to say that Minkowski space is literally the hyperboloid model of hyperbolic space? Next, a 'Lorentzian manifold' is a pseudo-riemannian manifold which locally looks like Minkowski space $\mathbb M$ [contrast with the Riemannian manifold which locally looks like $\mathbb R^n$ ]. Globally, it is is given by a manifold which is equipped with a non-degenerate symmetric bilinear form: note that here, the metric can be negative definite . When we talk about a 'flat Lorentzian manifold', we are talking about how the different 'local Minkowski spaces' fit together. A flat Lorentzian manifold is still hyperbolic , because minkowski space is hyperbolic. Rather, the flat here refers to the fact that there is no curvature across the local Minkowski spaces fitting together. So we are to imagine many copies of Minkowski space, each of which fit together 'perfectly', and hence there is no curvature. But locally, the manifold is Minkowski, and thus has constant negative curvature 'at each local point'. Wikipedia talks about the phrase [locally flat Is this correct? am I completely off? I find this very confusing, because Wikipedia keeps talking about float Lorentzian manifolds. To quote: Just as Euclidean space $\mathbb {R} ^{n}$ can be thought of as the model Riemannian manifold, Minkowski space $\mathbb {R} ^{n-1,1}$ with the flat Minkowski metric is the model Lorentzian manifold. My understanding of the situation is that because in a Pseudo-Riemannian manifold we can have the metric be negative , we can simply set the metric to $diag(1, -1, -1, -1)$ and get hyperbolic space. This is flat because the second derivatives vanish (indeed, the first derivatives vanish), and hence the space cannot have curvature. On the other hand, in the Riemannian case, we need to setup the hyperbolicity through curvature by assembling copies of $\mathbb R^n$ . Is what I have written sane, or am I completely off the mark? I'm looking for clarifications and spotting mistakes in my mental model of the physics I am studying with the math that I know.","I am in general confused about what Minkowski space is . I'll write down what I know and what I believe Minkowski space is. I'd appreciate any corrections. A Riemannian manifold is a manifold (so it locally looks like ) equipped with a non-negative positive symmetric bilinear form (the metric). Hyperbolic space is a type of Riemannian manifold, where it locally looks like , but globally the space has negative curvature. This gives it all of the weird properties we know and love [geodesics getting exponentially farther away, thin triangles, etc.] 'Minkowski space' naively speaking is some space equipped with the metric . This looks exactly like the hyperboloid model of hyperbolic space . So it far to say that Minkowski space is literally the hyperboloid model of hyperbolic space? Next, a 'Lorentzian manifold' is a pseudo-riemannian manifold which locally looks like Minkowski space [contrast with the Riemannian manifold which locally looks like ]. Globally, it is is given by a manifold which is equipped with a non-degenerate symmetric bilinear form: note that here, the metric can be negative definite . When we talk about a 'flat Lorentzian manifold', we are talking about how the different 'local Minkowski spaces' fit together. A flat Lorentzian manifold is still hyperbolic , because minkowski space is hyperbolic. Rather, the flat here refers to the fact that there is no curvature across the local Minkowski spaces fitting together. So we are to imagine many copies of Minkowski space, each of which fit together 'perfectly', and hence there is no curvature. But locally, the manifold is Minkowski, and thus has constant negative curvature 'at each local point'. Wikipedia talks about the phrase [locally flat Is this correct? am I completely off? I find this very confusing, because Wikipedia keeps talking about float Lorentzian manifolds. To quote: Just as Euclidean space can be thought of as the model Riemannian manifold, Minkowski space with the flat Minkowski metric is the model Lorentzian manifold. My understanding of the situation is that because in a Pseudo-Riemannian manifold we can have the metric be negative , we can simply set the metric to and get hyperbolic space. This is flat because the second derivatives vanish (indeed, the first derivatives vanish), and hence the space cannot have curvature. On the other hand, in the Riemannian case, we need to setup the hyperbolicity through curvature by assembling copies of . Is what I have written sane, or am I completely off the mark? I'm looking for clarifications and spotting mistakes in my mental model of the physics I am studying with the math that I know.","\mathbb R^n \mathbb R^n \mathbb  M \equiv \mathbb (\mathbb R^4, d) d(p, q) = p_0 q_0 - p_1 q_1 - p_2 q_2 - p_3 q_3 \mathbb M \mathbb R^n \mathbb {R} ^{n} \mathbb {R} ^{n-1,1} diag(1, -1, -1, -1) \mathbb R^n","['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry', 'general-relativity', 'semi-riemannian-geometry']"
43,One nappe of the hyperbola is an embedding. Pollack 1.3.8,One nappe of the hyperbola is an embedding. Pollack 1.3.8,,"The problem asks to check that the map $f:\mathbb{R}^1\to \mathbb{R}^2$ given by $t\mapsto(\cosh(t),\sinh(t))$ is a closed embedding. I tried two different approaches to solve this problem. First , we can use the fact that $$f \text{ is a closed embedding if and only if } f(\mathbb{R}^1) \text{ is closed in }\mathbb{R}^2$$ and $f$ is a homeomorphism onto its image. We can see that $f(\mathbb{R}^1)$ is closed since its complement is open. Next, we want to show that $f$ is a homeomorphism. If we are going to look at it geometrically, then it is obvious as we can see that the image/preimage of open sets is going to be open. My first question: how to show this more precisely? I was thinking to define a function $g:f(\mathbb{R}^1)\to \mathbb{R}^1$ given by $g(x,y)=\ln(x+y)$ since $$(x,y)=(\cosh(t),\sinh(t))\text{, so } x+y=e^t\text{ i.e. }t=\ln(x+y)$$ So, we can see that $f$ and $g$ are continuous functions and inverses of each other i.e. $f$ is a homeomorphism. Does it work? (1) Second approach is to use the direct definition of the closed embedding. In other words, $$f\text{ is a closed embedding if and only if } f\text{ is an immersion and the preimage of every compact set is compact.}$$ $f$ is an immersion if the differential $df_a$ is injective for all $a\in\mathbb{R}^1$ i.e. the tangent vector is never zero. But, we can see that $df_a=\begin{bmatrix}\sinh(a)\\ \cosh(a)\end{bmatrix}$ , so $|df_a|\neq0$ To show that the preimage of a compact set is compact, I used the following. If we take any compact set $A$ in $\mathbb{R}^2$ , then we always can find a closed ball center at the origin that will contain $A$ . That closed ball will intersect $f(\mathbb{R}^1)$ at some point $(x_0,y_0)$ i.e. at some point $t_0\in \mathbb{R}^1$ as $(x_0,y_0)\in f(\mathbb{R}^1)$ . Then we can see that $$f^{-1}(A\cap f(\mathbb{R}^1))\subset[-t_0,t_0]$$ Since $A\cap f(\mathbb{R}^1)$ is closed, $f$ is continuous, and $[-t_0,t_0]$ is compact, then $f^{-1}(A\cap f(\mathbb{R}^1))$ is compact as the closed subset of the compact set. Does it work? (2)","The problem asks to check that the map given by is a closed embedding. I tried two different approaches to solve this problem. First , we can use the fact that and is a homeomorphism onto its image. We can see that is closed since its complement is open. Next, we want to show that is a homeomorphism. If we are going to look at it geometrically, then it is obvious as we can see that the image/preimage of open sets is going to be open. My first question: how to show this more precisely? I was thinking to define a function given by since So, we can see that and are continuous functions and inverses of each other i.e. is a homeomorphism. Does it work? (1) Second approach is to use the direct definition of the closed embedding. In other words, is an immersion if the differential is injective for all i.e. the tangent vector is never zero. But, we can see that , so To show that the preimage of a compact set is compact, I used the following. If we take any compact set in , then we always can find a closed ball center at the origin that will contain . That closed ball will intersect at some point i.e. at some point as . Then we can see that Since is closed, is continuous, and is compact, then is compact as the closed subset of the compact set. Does it work? (2)","f:\mathbb{R}^1\to \mathbb{R}^2 t\mapsto(\cosh(t),\sinh(t)) f \text{ is a closed embedding if and only if } f(\mathbb{R}^1) \text{ is closed in }\mathbb{R}^2 f f(\mathbb{R}^1) f g:f(\mathbb{R}^1)\to \mathbb{R}^1 g(x,y)=\ln(x+y) (x,y)=(\cosh(t),\sinh(t))\text{, so } x+y=e^t\text{ i.e. }t=\ln(x+y) f g f f\text{ is a closed embedding if and only if } f\text{ is an immersion and the preimage of every compact set is compact.} f df_a a\in\mathbb{R}^1 df_a=\begin{bmatrix}\sinh(a)\\ \cosh(a)\end{bmatrix} |df_a|\neq0 A \mathbb{R}^2 A f(\mathbb{R}^1) (x_0,y_0) t_0\in \mathbb{R}^1 (x_0,y_0)\in f(\mathbb{R}^1) f^{-1}(A\cap f(\mathbb{R}^1))\subset[-t_0,t_0] A\cap f(\mathbb{R}^1) f [-t_0,t_0] f^{-1}(A\cap f(\mathbb{R}^1))","['differential-geometry', 'solution-verification']"
44,"Why is the vector $(u_x, u_y, - 1)$ normal to the surface $u=u(x, y) $?",Why is the vector  normal to the surface ?,"(u_x, u_y, - 1) u=u(x, y) ","Studying the method of characteristics, the argument goes as follows: We are interested in the equation: $a(x, y)u_x+b(x, y) u_y=f(x, y, u)$ ; $(a(x, y), b(x, y), f(x, y, u))(u_x, u_y, - 1) =(a,b,f)\nabla{F}=0$ , where $F =u(x, y) - u=0$ . Hence, $(a, b, f)$ is orthogonal to $\nabla F$ . Then, they say that $\nabla F$ is orthogonal to the solution surface, and so we get that $(a, b, f) $ lies in the tangential plane to the solution surface. Therefore, we can build a characteristic curve, starting from a point on the boundary. We parametrise our unknown characteristic curve as ${x(t), y(t), z(t)} $ , and find the tangent vector to it at every point - $v=(x_t (t), y_t (t), z_t (t)) $ . Then, we find $x, y, z$ from the condition $v=c(a, b, f)$ . This is a system of ODEs, comprising the method of Characteristics. However, I don't understand why they say that $\nabla F=(u_x, u_y, - 1)$ is orthogonal to the solution surface.","Studying the method of characteristics, the argument goes as follows: We are interested in the equation: ; , where . Hence, is orthogonal to . Then, they say that is orthogonal to the solution surface, and so we get that lies in the tangential plane to the solution surface. Therefore, we can build a characteristic curve, starting from a point on the boundary. We parametrise our unknown characteristic curve as , and find the tangent vector to it at every point - . Then, we find from the condition . This is a system of ODEs, comprising the method of Characteristics. However, I don't understand why they say that is orthogonal to the solution surface.","a(x, y)u_x+b(x, y) u_y=f(x, y, u) (a(x, y), b(x, y), f(x, y, u))(u_x, u_y, - 1) =(a,b,f)\nabla{F}=0 F =u(x, y) - u=0 (a, b, f) \nabla F \nabla F (a, b, f)  {x(t), y(t), z(t)}  v=(x_t (t), y_t (t), z_t (t))  x, y, z v=c(a, b, f) \nabla F=(u_x, u_y, - 1)","['differential-geometry', 'partial-differential-equations', 'vector-analysis']"
45,Gradient in level-set coordinates.,Gradient in level-set coordinates.,,"If f: $\mathbb{R}^n \to \mathbb{R}$ is a smooth function and $x_0$ is a regular point, we know there is a diffeomorphism $\phi:U \to \phi(U)\subset \mathbb{R}^n$ , with $x_0 \in \phi(U)$ such that $$f(\phi(x)) = x_n, \quad \text{for } x=(x_1,\ldots,x_n) \in U.$$ Using Riemannian Geometry notation, can we say that that the coordinate frame induced by the local chart $(U,\phi)$ satisfies $\partial_n = \text{grad} f$ ? It seems to me that this should be the case, since the composition with $\phi$ depends only on the last variable.","If f: is a smooth function and is a regular point, we know there is a diffeomorphism , with such that Using Riemannian Geometry notation, can we say that that the coordinate frame induced by the local chart satisfies ? It seems to me that this should be the case, since the composition with depends only on the last variable.","\mathbb{R}^n \to \mathbb{R} x_0 \phi:U \to \phi(U)\subset \mathbb{R}^n x_0 \in \phi(U) f(\phi(x)) = x_n, \quad \text{for } x=(x_1,\ldots,x_n) \in U. (U,\phi) \partial_n = \text{grad} f \phi","['calculus', 'differential-geometry', 'differential-topology', 'smooth-manifolds']"
46,Haar integral invariance against inversion,Haar integral invariance against inversion,,"Suppose $G$ is a compact Lie group, and $\omega$ is a left-invariant volume form over $G$ such that. $$\int_{G}\omega = 1$$ with respect to the orientation determined by $\omega$ . If I define $$\int_{G}f(g)dg:=\int_{G}f\omega$$ for every continuous real-valued function $f\colon G\to \mathbb{R}$ , the map $f\mapsto\int_{G}f(g)dg$ is called the Haar integral. I need to prove that $$\int_{G}f(g^{-1})dg=\int_{G}f(g)dg$$ for any continuous function $f$ . I have made some attempts without success. First, I tried to use the modular function $c\colon G\to \mathbb{R}$ given by $R_{g}^{*}\omega = c(g)\omega$ for every $g\in G$ . I've seen that, calling the inversion map $\beta$ , we have $$L_{g}^{*}\beta^{*}(\omega)=(\beta \circ L_{g})^{*}\omega=(R_{g^{-1}} \circ \beta)^{*}\omega=\beta^{*}(c(g^{-1})\omega)=c(g^{-1})\beta^{*}\omega$$ so $\beta^{*}\omega$ might not be necessarily left invariant (for example. if $G$ is not connected). With a similar argument, I managed to prove that $\beta^{*}\omega$ is right invariant (but didn't see how to use that to my advantage). Another idea I had was to use the fact that the Haar integral is left and right invariant (which I was able to prove beforehand). Again, I don't see a clear way to get from that to the desired equality. Are any of my ideas on the right track? The book I'm reading on the subject (''Compact Lie groups"", by M. R. Sepanski) says that the argument used to prove the equation is similar to that of proving $$\int_{G}f(gh)dg=\int_{G}f(g)dg$$ for any $h\in G$ . EDIT: I've seen written that this result can be used by proving uniqueness of the integral, i.e., that if the Haar integral can be determined by the properties I already proved, and the functional $$J(f)=\int_{G}f(g^{-1})dg$$ verifies those properties, then $J$ is the Haar integral. I don't know how to prove either of those claims though. Thank you in advance!","Suppose is a compact Lie group, and is a left-invariant volume form over such that. with respect to the orientation determined by . If I define for every continuous real-valued function , the map is called the Haar integral. I need to prove that for any continuous function . I have made some attempts without success. First, I tried to use the modular function given by for every . I've seen that, calling the inversion map , we have so might not be necessarily left invariant (for example. if is not connected). With a similar argument, I managed to prove that is right invariant (but didn't see how to use that to my advantage). Another idea I had was to use the fact that the Haar integral is left and right invariant (which I was able to prove beforehand). Again, I don't see a clear way to get from that to the desired equality. Are any of my ideas on the right track? The book I'm reading on the subject (''Compact Lie groups"", by M. R. Sepanski) says that the argument used to prove the equation is similar to that of proving for any . EDIT: I've seen written that this result can be used by proving uniqueness of the integral, i.e., that if the Haar integral can be determined by the properties I already proved, and the functional verifies those properties, then is the Haar integral. I don't know how to prove either of those claims though. Thank you in advance!",G \omega G \int_{G}\omega = 1 \omega \int_{G}f(g)dg:=\int_{G}f\omega f\colon G\to \mathbb{R} f\mapsto\int_{G}f(g)dg \int_{G}f(g^{-1})dg=\int_{G}f(g)dg f c\colon G\to \mathbb{R} R_{g}^{*}\omega = c(g)\omega g\in G \beta L_{g}^{*}\beta^{*}(\omega)=(\beta \circ L_{g})^{*}\omega=(R_{g^{-1}} \circ \beta)^{*}\omega=\beta^{*}(c(g^{-1})\omega)=c(g^{-1})\beta^{*}\omega \beta^{*}\omega G \beta^{*}\omega \int_{G}f(gh)dg=\int_{G}f(g)dg h\in G J(f)=\int_{G}f(g^{-1})dg J,"['integration', 'differential-geometry', 'lie-groups']"
47,Pushforward and Pullback Applied to Composition of Maps,Pushforward and Pullback Applied to Composition of Maps,,"I'm working through Frankel's ""The Geometry of Physics"" this summer, and I'm stuck on a problem concerning the pushforward and pullback operations.  The problem is stated as follows: Let $F:M^n \rightarrow W^r$ and $G:W^r \rightarrow V^s$ be smooth maps. Let x, y, and z be local coordinates near $p \epsilon M$ . $F(p) \epsilon W$ and $G(F(p)) \epsilon V$ , respectively.  We may consider the composite map $G \circ F: M \rightarrow V$ . (i) Show, by using bases $\frac{\partial}{\partial x}$ , $\frac{\partial}{\partial y}$ $\frac{\partial}{\partial z}$ , that $$(G \circ F)_* = G_* \circ F_*$$ (ii) Show, by using bases $dx$ , $dy$ , $dz$ , that $$(G \circ F)^* = G^* \circ F^*$$ So far I've started with the fact that: $$(G \circ F)_* = (G_* \circ F) \cdot F_*$$ by the chain rule, but I'm not sure how to proceed.  I feel like if I can get help with the first one the second one shouldn't be much of an issue. Thank you.","I'm working through Frankel's ""The Geometry of Physics"" this summer, and I'm stuck on a problem concerning the pushforward and pullback operations.  The problem is stated as follows: Let and be smooth maps. Let x, y, and z be local coordinates near . and , respectively.  We may consider the composite map . (i) Show, by using bases , , that (ii) Show, by using bases , , , that So far I've started with the fact that: by the chain rule, but I'm not sure how to proceed.  I feel like if I can get help with the first one the second one shouldn't be much of an issue. Thank you.",F:M^n \rightarrow W^r G:W^r \rightarrow V^s p \epsilon M F(p) \epsilon W G(F(p)) \epsilon V G \circ F: M \rightarrow V \frac{\partial}{\partial x} \frac{\partial}{\partial y} \frac{\partial}{\partial z} (G \circ F)_* = G_* \circ F_* dx dy dz (G \circ F)^* = G^* \circ F^* (G \circ F)_* = (G_* \circ F) \cdot F_*,"['differential-geometry', 'physics', 'pullback', 'pushforward']"
48,Injective morphisms of locally free sheaves and fiberwise injectivity of vector bundles,Injective morphisms of locally free sheaves and fiberwise injectivity of vector bundles,,"Let's fix a smooth integral algebraic variety $X$ over $\mathbb C$ . If $\mathscr E$ is a locally free sheaf on $X$ , then at each closed point $x\in X$ we have a complex vector space $E_x:=\mathscr E_x\otimes\mathbb C$ and $E:=\bigsqcup_x E_x$ can be endowed with a structure of smooth vector bundle. The transition between locally free sheaves and vector bundles is functorial and it is actually an equivalence of categories. Now assume that $\varphi:\mathscr E\to\mathscr H$ is an injective morphism between locally free sheaves. It means that for any $x\in X$ we have an injective morphisms of $\mathscr O_{X,x}$ -modules $\varphi_x:\mathscr E_x\to\mathscr H_x$ . It is well known that the induced map at the level of vector spaces (fibres of vector bundles) $\Phi_x:E_x\to H_x$ is in general not injective . This because the operation $-\otimes\mathbb C$ doesn't preserve left exactness. Finally the question: Let's keep the above hypotheses and notation. Is it true or false that there is always a Zariski open subset $U\subset X$ such that $\{\Phi_x\}_{x\in U}$ are injective (as homomorphism of vector spaces)? Are we able to describe such a subset? Is it characterized by some ""nice"" property?","Let's fix a smooth integral algebraic variety over . If is a locally free sheaf on , then at each closed point we have a complex vector space and can be endowed with a structure of smooth vector bundle. The transition between locally free sheaves and vector bundles is functorial and it is actually an equivalence of categories. Now assume that is an injective morphism between locally free sheaves. It means that for any we have an injective morphisms of -modules . It is well known that the induced map at the level of vector spaces (fibres of vector bundles) is in general not injective . This because the operation doesn't preserve left exactness. Finally the question: Let's keep the above hypotheses and notation. Is it true or false that there is always a Zariski open subset such that are injective (as homomorphism of vector spaces)? Are we able to describe such a subset? Is it characterized by some ""nice"" property?","X \mathbb C \mathscr E X x\in X E_x:=\mathscr E_x\otimes\mathbb C E:=\bigsqcup_x E_x \varphi:\mathscr E\to\mathscr H x\in X \mathscr O_{X,x} \varphi_x:\mathscr E_x\to\mathscr H_x \Phi_x:E_x\to H_x -\otimes\mathbb C U\subset X \{\Phi_x\}_{x\in U}","['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'sheaf-theory', 'vector-bundles']"
49,Is it true that $\Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M))$?,Is it true that ?,\Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M)),"Well, the question is in the title. Is it true, that given a smooth manifold $M$ , the following isomorphism holds: $$ \Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M)) $$ $\Gamma$ - smooth sections functor, $\Lambda$ - exterior algebra functor. Base ring for both - $C^\infty(M)$ . Motivation: I'm kind of confused, because some sources define differential forms as sections of exterior bundle, others define forms as elements of exerior algebra of sections: For example: Wikipedia uses first definition https://en.wikipedia.org/wiki/Differential_form nLab uses second definition https://ncatlab.org/nlab/show/exterior+algebra (at the bottom) Are those equivalent?","Well, the question is in the title. Is it true, that given a smooth manifold , the following isomorphism holds: - smooth sections functor, - exterior algebra functor. Base ring for both - . Motivation: I'm kind of confused, because some sources define differential forms as sections of exterior bundle, others define forms as elements of exerior algebra of sections: For example: Wikipedia uses first definition https://en.wikipedia.org/wiki/Differential_form nLab uses second definition https://ncatlab.org/nlab/show/exterior+algebra (at the bottom) Are those equivalent?","M 
\Gamma(\Lambda(T^*M)) \cong \Lambda(\Gamma(T^*M))
 \Gamma \Lambda C^\infty(M)","['differential-geometry', 'differential-forms', 'vector-bundles', 'exterior-algebra']"
50,$C^\infty(M)$-linear maps are local,-linear maps are local,C^\infty(M),"Very often in mathematical physics literature I've heard a fact that probably (if I've understood it correctly) translates as follows. Let $M$ be a differentiable manifold, and denote by $C^\infty(M)$ the   ring of smooth real functions $M\to\Bbb{R}$ . Let now $E$ and $F$ be   vector bundles on $M$ , and notice that the spaces of smooth sections $\Gamma(E)$ and $\Gamma(F)$ are modules over $C^\infty(M)$ .  Let now $f:\Gamma(E)\to\Gamma(F)$ be a smooth, $\Bbb{R}$ -linear function. The following are   equivalent. $f$ is $C^\infty(M)$ -linear; $f$ is ""local"", meaning that given sections $\phi,\psi$ which agree at the point $p\in M$ ,   then $f(\phi)$ and $f(\psi)$ agree at $p$ too. First of all, is the above correct? If not, what is the correct statement? Also, where can I find a reference and a proof?","Very often in mathematical physics literature I've heard a fact that probably (if I've understood it correctly) translates as follows. Let be a differentiable manifold, and denote by the   ring of smooth real functions . Let now and be   vector bundles on , and notice that the spaces of smooth sections and are modules over .  Let now be a smooth, -linear function. The following are   equivalent. is -linear; is ""local"", meaning that given sections which agree at the point ,   then and agree at too. First of all, is the above correct? If not, what is the correct statement? Also, where can I find a reference and a proof?","M C^\infty(M) M\to\Bbb{R} E F M \Gamma(E) \Gamma(F) C^\infty(M) f:\Gamma(E)\to\Gamma(F) \Bbb{R} f C^\infty(M) f \phi,\psi p\in M f(\phi) f(\psi) p","['differential-geometry', 'algebraic-geometry', 'reference-request', 'commutative-algebra', 'vector-bundles']"
51,Vector bundle is Manifold,Vector bundle is Manifold,,I want to show that the total space of a vector bundle $E \overset{\pi}{\rightarrow} M$ is itself a manifold. It is easy to construct charts by just composing the bundle maps $\pi^{-1}(U_{\alpha}) \rightarrow U_{\alpha} \times \mathbb{R}^k$ with the charts for $M$ . It now remains to show the Hausdorff property and that $E$ is second countable. Can someone help me with that?,I want to show that the total space of a vector bundle is itself a manifold. It is easy to construct charts by just composing the bundle maps with the charts for . It now remains to show the Hausdorff property and that is second countable. Can someone help me with that?,E \overset{\pi}{\rightarrow} M \pi^{-1}(U_{\alpha}) \rightarrow U_{\alpha} \times \mathbb{R}^k M E,"['general-topology', 'differential-geometry', 'smooth-manifolds', 'vector-bundles']"
52,$\mathbb{R}$-bundle,-bundle,\mathbb{R},"Why a principal $\mathbb{R}$ -bundle is always trivial? I know that a principal bundle of the form $(E,B,\pi,G)$ is trivial if and only if it admits a global section $f:B\to E$ . So which section should I take? Is there a simpler way to prove this property?",Why a principal -bundle is always trivial? I know that a principal bundle of the form is trivial if and only if it admits a global section . So which section should I take? Is there a simpler way to prove this property?,"\mathbb{R} (E,B,\pi,G) f:B\to E","['differential-geometry', 'principal-bundles']"
53,The Hodge diamond of a Calabi-Yau Fourfold,The Hodge diamond of a Calabi-Yau Fourfold,,"I am studying the String Theory book by Becker, Becker, and Schwarz, and I decided to verify the Hodge diamonds for a CY3 and a CY4. These can be found on page 365 and they are eq.(9.14) and (9.16). It was very easy for me to derive the precise form of the Hodge diamond following what they mention in the book. A problem arose when I tried to repeat the computation for the case of a CY4. Let me first state the problem/question. Why for a CY4 the Hodge number $h^{2,0}$ is equal to zero? This is not obvious to me from the relations they give in the book. Allow me to show you how I have worked out the rest of the elements of the Hodge diamond. Let me write here the properties the book gives for the Hodge numbers. For a Calabi-Yau n-fold we have that -these are eq.(9.10)-(9.12) in the book $\begin{equation} \begin{split} h^{p,0} &= h^{n-p,0} \\ h^{p,q} &= h^{q,p} \\ h^{p,q} &= h^{n-q,n-p} \end{split} \end{equation}$ and we know that for a simply connected manifold $h^{1,0}=h^{0,1}=0$ and that a compact connected Kahler manifold has $h^{0,0}=1$ . From the first of the above properties, we have the following relations $\begin{equation} \begin{split} &h^{4,3} = h^{3,4}, \qquad h^{4,2} = h^{2,4}, \qquad h^{4,1} = h^{1,4}, \qquad h^{4,0} = h^{0,4}, \qquad \qquad h^{3,2} = h^{2,3}, \qquad h^{3,1} = h^{1,3}, \\ &h^{3,0} = h^{0,3}, \qquad h^{2,1} = h^{1,2}, \qquad h^{2,0} = h^{0,2}, \qquad h^{1,0} = h^{0,1} \end{split} \end{equation}$ From the second property we have $\begin{equation} h^{4,0} = h^{0,0} \qquad h^{3,0} = h^{1,0} \end{equation}$ And finally, from the third one we obtain $\begin{equation}  h^{4,4} = h^{0,0}, \qquad h^{4,3} = h^{1,0}, \qquad h^{4,2} = h^{2,0}, \qquad h^{4,1} = h^{1,0}, \qquad h^{3,3} = h^{1,1}, \qquad h^{3,2} = h^{2,1}. \end{equation}$ The undetermined $h^{2,2}$ is given by -see eq.(9.17) $\begin{equation} h^{2,2} = 2 (22+2h^{1,1}+2h^{1,3}-h^{1,2}) \end{equation}$ If we impose all of the above to the Hodge diamond we get precisely what is shown in the book with the only difference that in the book they seem to have that $h^{2,0}=0$ which I cannot obtain.","I am studying the String Theory book by Becker, Becker, and Schwarz, and I decided to verify the Hodge diamonds for a CY3 and a CY4. These can be found on page 365 and they are eq.(9.14) and (9.16). It was very easy for me to derive the precise form of the Hodge diamond following what they mention in the book. A problem arose when I tried to repeat the computation for the case of a CY4. Let me first state the problem/question. Why for a CY4 the Hodge number is equal to zero? This is not obvious to me from the relations they give in the book. Allow me to show you how I have worked out the rest of the elements of the Hodge diamond. Let me write here the properties the book gives for the Hodge numbers. For a Calabi-Yau n-fold we have that -these are eq.(9.10)-(9.12) in the book and we know that for a simply connected manifold and that a compact connected Kahler manifold has . From the first of the above properties, we have the following relations From the second property we have And finally, from the third one we obtain The undetermined is given by -see eq.(9.17) If we impose all of the above to the Hodge diamond we get precisely what is shown in the book with the only difference that in the book they seem to have that which I cannot obtain.","h^{2,0} \begin{equation}
\begin{split}
h^{p,0} &= h^{n-p,0} \\
h^{p,q} &= h^{q,p} \\
h^{p,q} &= h^{n-q,n-p}
\end{split}
\end{equation} h^{1,0}=h^{0,1}=0 h^{0,0}=1 \begin{equation}
\begin{split}
&h^{4,3} = h^{3,4}, \qquad h^{4,2} = h^{2,4}, \qquad h^{4,1} = h^{1,4}, \qquad h^{4,0} = h^{0,4}, \qquad \qquad h^{3,2} = h^{2,3}, \qquad h^{3,1} = h^{1,3}, \\
&h^{3,0} = h^{0,3}, \qquad h^{2,1} = h^{1,2}, \qquad h^{2,0} = h^{0,2}, \qquad h^{1,0} = h^{0,1}
\end{split}
\end{equation} \begin{equation}
h^{4,0} = h^{0,0} \qquad h^{3,0} = h^{1,0}
\end{equation} \begin{equation} 
h^{4,4} = h^{0,0}, \qquad h^{4,3} = h^{1,0}, \qquad h^{4,2} = h^{2,0}, \qquad h^{4,1} = h^{1,0}, \qquad h^{3,3} = h^{1,1}, \qquad h^{3,2} = h^{2,1}.
\end{equation} h^{2,2} \begin{equation}
h^{2,2} = 2 (22+2h^{1,1}+2h^{1,3}-h^{1,2})
\end{equation} h^{2,0}=0","['differential-geometry', 'algebraic-geometry']"
54,How both definitions of a lie group are equivalent,How both definitions of a lie group are equivalent,,"I can't proof that these definitions of lie groups are equivalent. Can anyone prove it directly?. A Lie group is a set which carries the algebraic structure of a group and the differentiable structure of a smooth manifold such that the mapping $$ G\times G \rightarrow G \hspace{1cm} (a,b) \mapsto ab^{-1}$$ is smooth A Lie group is a set which carries the algebraic structure of a group and the differentiable structure of a smooth manifold such that the mappings $$ G\times G \rightarrow G \hspace{1cm} (a,b) \mapsto ab$$ and $$ G \rightarrow G \hspace{1cm} g \mapsto g^{-1}$$ are smooth",I can't proof that these definitions of lie groups are equivalent. Can anyone prove it directly?. A Lie group is a set which carries the algebraic structure of a group and the differentiable structure of a smooth manifold such that the mapping is smooth A Lie group is a set which carries the algebraic structure of a group and the differentiable structure of a smooth manifold such that the mappings and are smooth," G\times G \rightarrow G \hspace{1cm} (a,b) \mapsto ab^{-1}  G\times G \rightarrow G \hspace{1cm} (a,b) \mapsto ab  G \rightarrow G \hspace{1cm} g \mapsto g^{-1}","['differential-geometry', 'smooth-manifolds']"
55,"Showing there is a symplectomorphism of $(T^{*} M, \omega_{T^{*}M})$ satisfying this property",Showing there is a symplectomorphism of  satisfying this property,"(T^{*} M, \omega_{T^{*}M})","Problem: Let $M$ be a manifold, and let $\alpha$ be a closed $1$ -form on $M$ . Show that there exists a symplectomorphism of $(T^{*} M, \omega_{T^{*} M})$ that maps the zero section to the submanifold $\text{Im}(\alpha) := \left\{ \alpha_x: x \in M \right\} $ of $T^{*} M$ . Attempt: The zero section of $T^{*} M$ is $$M_{0} = \left\{ (x, \xi) \in T^{*} M \mid \xi = 0 \ \text{in} \ T_x^{*} M \right\}. $$ My idea was to define the symplectomorphism $\phi$ as $\phi := \alpha \circ \pi$ , where $\pi : T^{*} M \rightarrow M$ is the projection. I have to show that $\phi$ is a diffeomorphism and that $\phi^{*} (\omega_{T^{*} M}) = \omega_{T^{*} M}$ ? However, this is where I am stuck. Also, I'm not sure where I need the closedness of $\alpha$ . Help is appreciated.","Problem: Let be a manifold, and let be a closed -form on . Show that there exists a symplectomorphism of that maps the zero section to the submanifold of . Attempt: The zero section of is My idea was to define the symplectomorphism as , where is the projection. I have to show that is a diffeomorphism and that ? However, this is where I am stuck. Also, I'm not sure where I need the closedness of . Help is appreciated.","M \alpha 1 M (T^{*} M, \omega_{T^{*} M}) \text{Im}(\alpha) := \left\{ \alpha_x: x \in M \right\}  T^{*} M T^{*} M M_{0} = \left\{ (x, \xi) \in T^{*} M \mid \xi = 0 \ \text{in} \ T_x^{*} M \right\}.  \phi \phi := \alpha \circ \pi \pi : T^{*} M \rightarrow M \phi \phi^{*} (\omega_{T^{*} M}) = \omega_{T^{*} M} \alpha","['differential-geometry', 'differential-topology', 'symplectic-geometry']"
56,Line bundles have flat connections,Line bundles have flat connections,,"Let $M$ be a manifold of $L \to M$ a line bundle (say over $\mathbb{C}$ , ie complex line bundle). Is it true & why that for every such line bundle there exist a flat connection $\nabla_L : \Gamma(X,E)\to \Gamma(X, \Omega_X^1\otimes L)$ , i.e. a connection which curvature $\nabla_L^2= \Omega_L \in \Omega ^{2}({\mathrm  {End}}\,L)=\Gamma ({\mathrm  {End}}\,L\otimes \Lambda ^{2}T^{*}M)$ is zero. Thus an existence problem. Sure, I not see any reason why all connections on $L$ should be flat, nevertheless I'm asking if on the other hand there always exist a flat one. If yes, is the claim independ of the field (so we can replace $\mathbb{C}$ by any other)?","Let be a manifold of a line bundle (say over , ie complex line bundle). Is it true & why that for every such line bundle there exist a flat connection , i.e. a connection which curvature is zero. Thus an existence problem. Sure, I not see any reason why all connections on should be flat, nevertheless I'm asking if on the other hand there always exist a flat one. If yes, is the claim independ of the field (so we can replace by any other)?","M L \to M \mathbb{C} \nabla_L : \Gamma(X,E)\to \Gamma(X, \Omega_X^1\otimes L) \nabla_L^2= \Omega_L \in \Omega ^{2}({\mathrm  {End}}\,L)=\Gamma ({\mathrm  {End}}\,L\otimes \Lambda ^{2}T^{*}M) L \mathbb{C}","['differential-geometry', 'vector-bundles']"
57,Is there a connection between the construction of $\mathbb{Q}$ and exotic $\mathbb{R}^4$'s,Is there a connection between the construction of  and exotic 's,\mathbb{Q} \mathbb{R}^4,"I learned that there exist so-called ""exotic"" $\mathbb{R}^4$ 's. That is, there exist topological spaces which are homeomorphic but not diffeomorphic to $\mathbb{R}^4$ . Quite remarkably, it has been proven that $4$ is the only value of $n$ for which there exists an exotic $\mathbb{R}^n$ . Moreover, it has also been shown that there are uncountably many exotic $\mathbb{R}^4$ 's. https://en.wikipedia.org/wiki/Exotic_R4 I admit that I do not at all understand the existence proof of an exotic $\mathbb{R}^4$ , but it seems to be quite non-constructive. It rests upon the existence of a non-trivial smooth 5 dimensional $h$ -cobordism which must exist by some other theorem. https://projecteuclid.org/download/pdf_1/euclid.jdg/1214437666 However I had an idea of where these things could be coming from (or at least something interesting if not related to exotic $\mathbb{R}^4$ 's). Recall the standard construction of $\mathbb{Q}$ from $\mathbb{Z}$ : on the set $\mathbb{Z}\times(\mathbb{Z}-\{0\})$ we define a relation by $$(a,b)\sim(c,d)\Longleftrightarrow ad=bc$$ Then you show it's an equivalence relation and on the set of equivalence classes, you define addtion, multiplication, show that they're well-defined, etc. However, recall from elementary set theory the definition of a relation: A relation on $X$ is nothing more than a subset of $X\times X$ . So from this perspective, $\mathbb{Q}$ can be identified with a particular subset of $\big(\mathbb{Z}\times(\mathbb{Z}-\{0\})\big)^2\subseteq \mathbb{Z}^4$ . But $\mathbb{Z}^4\subseteq \mathbb{R}^4$ , so that means that $\mathbb{Q}$ is sitting inside of $\mathbb{R}^4$ . Clearly, we already know that $\mathbb{Q}\subseteq \mathbb{R}^4$ by inclusion into any one of the coordinates. However, these are quite different than the $\mathbb{Q}$ coming from the set contruction, which I will call $\tilde{\mathbb{Q}}$ to distingtuish from the ""ordinary"" $\mathbb{Q}$ 's sitting inside $\mathbb{R}^4$ . Of course, $\tilde{\mathbb{Q}}$ has it's natural metric. However, it doesn't coincide with the standard metric as a subset of $\mathbb{R}^4$ . So perhaps the completion of $\tilde{\mathbb{Q}}$ with respect to the $\mathbb{R}^4$ metric is what leads to these exotic $\mathbb{R}^4$ 's. Obviously, this is all conjecture but I would appreciate any comments or insight.","I learned that there exist so-called ""exotic"" 's. That is, there exist topological spaces which are homeomorphic but not diffeomorphic to . Quite remarkably, it has been proven that is the only value of for which there exists an exotic . Moreover, it has also been shown that there are uncountably many exotic 's. https://en.wikipedia.org/wiki/Exotic_R4 I admit that I do not at all understand the existence proof of an exotic , but it seems to be quite non-constructive. It rests upon the existence of a non-trivial smooth 5 dimensional -cobordism which must exist by some other theorem. https://projecteuclid.org/download/pdf_1/euclid.jdg/1214437666 However I had an idea of where these things could be coming from (or at least something interesting if not related to exotic 's). Recall the standard construction of from : on the set we define a relation by Then you show it's an equivalence relation and on the set of equivalence classes, you define addtion, multiplication, show that they're well-defined, etc. However, recall from elementary set theory the definition of a relation: A relation on is nothing more than a subset of . So from this perspective, can be identified with a particular subset of . But , so that means that is sitting inside of . Clearly, we already know that by inclusion into any one of the coordinates. However, these are quite different than the coming from the set contruction, which I will call to distingtuish from the ""ordinary"" 's sitting inside . Of course, has it's natural metric. However, it doesn't coincide with the standard metric as a subset of . So perhaps the completion of with respect to the metric is what leads to these exotic 's. Obviously, this is all conjecture but I would appreciate any comments or insight.","\mathbb{R}^4 \mathbb{R}^4 4 n \mathbb{R}^n \mathbb{R}^4 \mathbb{R}^4 h \mathbb{R}^4 \mathbb{Q} \mathbb{Z} \mathbb{Z}\times(\mathbb{Z}-\{0\}) (a,b)\sim(c,d)\Longleftrightarrow ad=bc X X\times X \mathbb{Q} \big(\mathbb{Z}\times(\mathbb{Z}-\{0\})\big)^2\subseteq \mathbb{Z}^4 \mathbb{Z}^4\subseteq \mathbb{R}^4 \mathbb{Q} \mathbb{R}^4 \mathbb{Q}\subseteq \mathbb{R}^4 \mathbb{Q} \tilde{\mathbb{Q}} \mathbb{Q} \mathbb{R}^4 \tilde{\mathbb{Q}} \mathbb{R}^4 \tilde{\mathbb{Q}} \mathbb{R}^4 \mathbb{R}^4",['differential-geometry']
58,Contact vector field,Contact vector field,,"I am not sure if I understand the definition of a contact vector field: Let $(W, \xi)$ be a contact manifold. A vector field $Y$ is called a contact vector field, if the flow of $Y$ preserves $\xi$ . If $\lambda$ is a defining contact form, then this means that $\mathcal{L}_Y \lambda= p \lambda$ where $p: W \rightarrow \mathbb{R}$ . Now what exactly does ""the flow of $Y$ preserves $\xi$ "" mean? As far as I understand, it is the following: Let $\varphi_t(x)$ be the flow of $Y$ . Then for each $t$ , it holds: $\varphi_t^{*} \xi = \xi $ so for each tangent vector $v \in \xi_p$ , it holds that the tangent vector $f \mapsto v(f \circ \varphi_t)$ is in $\xi_{\varphi_t(p)}$ Is that correct? And if yes, how does it correspond to $\mathcal{L}_Y \lambda= p \lambda$ where $p: W \rightarrow \mathbb{R}$ Locally, $\xi= \ker\{\lambda\}$ . $\mathcal{L}_Y \lambda = d(\iota_Y \lambda)+ \iota_Y(d \lambda)$ But why is that equivalent?","I am not sure if I understand the definition of a contact vector field: Let be a contact manifold. A vector field is called a contact vector field, if the flow of preserves . If is a defining contact form, then this means that where . Now what exactly does ""the flow of preserves "" mean? As far as I understand, it is the following: Let be the flow of . Then for each , it holds: so for each tangent vector , it holds that the tangent vector is in Is that correct? And if yes, how does it correspond to where Locally, . But why is that equivalent?","(W, \xi) Y Y \xi \lambda \mathcal{L}_Y \lambda= p \lambda p: W \rightarrow \mathbb{R} Y \xi \varphi_t(x) Y t \varphi_t^{*} \xi = \xi  v \in \xi_p f \mapsto v(f \circ \varphi_t) \xi_{\varphi_t(p)} \mathcal{L}_Y \lambda= p \lambda p: W \rightarrow \mathbb{R} \xi= \ker\{\lambda\} \mathcal{L}_Y \lambda = d(\iota_Y \lambda)+ \iota_Y(d \lambda)","['differential-geometry', 'manifolds', 'vector-fields', 'contact-topology']"
59,When does $U\subset V$ induce maps on homology of finite rank?,When does  induce maps on homology of finite rank?,U\subset V,"Question 1. Let $X$ be a topological manifold, $U\subset V\subset X$ open subsets. The inclusion $\iota:U\to V$ induces corresponding maps on homology $\iota_*:H_\bullet(U)\to H_\bullet(V)$ . We take the coefficients to lie in some fixed field. Under what conditions can we conclude that $\iota_*$ has finite rank (as a linear map)? In particular, I am interested in whether the following is sufficient: $\overline{U}\subset V$ and $\overline{U}$ is compact. I encountered this problem when reading Gromov's paper Curvature, diameter and Betti numbers . The setting is on a complete Riemannian manifold $(M,g)$ where we may consider balls $B(p,r):=\{x\in M:d(p,x)<r\}$ . The content of such a ball is defined by $$\operatorname{cont}B(p,r):=\operatorname{rank}(B(p,r/5)\subset B(p,r)),$$ where the rank refers to the rank of the induced map on homology. I need to know that this number is always finite. I encountered the second question when reading the proof of the results in the aforementioned paper of Gromov in the book Riemannian Geometry by Peter Petersen. The author remarks without proof the following: Question 2. Notation as above. For $r$ large enough, $$\operatorname{cont}B(p,r)=\sum b_i(M)$$ where $b_i:=\dim H_i(M)$ is the Betti number of $M$ . Now this is obvious if $M$ is compact. But why is it true for noncompact complete manifolds? I'm a bit rusty on algebraic topology, but I really don't see why these should hold. Any help is highly appreciated!","Question 1. Let be a topological manifold, open subsets. The inclusion induces corresponding maps on homology . We take the coefficients to lie in some fixed field. Under what conditions can we conclude that has finite rank (as a linear map)? In particular, I am interested in whether the following is sufficient: and is compact. I encountered this problem when reading Gromov's paper Curvature, diameter and Betti numbers . The setting is on a complete Riemannian manifold where we may consider balls . The content of such a ball is defined by where the rank refers to the rank of the induced map on homology. I need to know that this number is always finite. I encountered the second question when reading the proof of the results in the aforementioned paper of Gromov in the book Riemannian Geometry by Peter Petersen. The author remarks without proof the following: Question 2. Notation as above. For large enough, where is the Betti number of . Now this is obvious if is compact. But why is it true for noncompact complete manifolds? I'm a bit rusty on algebraic topology, but I really don't see why these should hold. Any help is highly appreciated!","X U\subset V\subset X \iota:U\to V \iota_*:H_\bullet(U)\to H_\bullet(V) \iota_* \overline{U}\subset V \overline{U} (M,g) B(p,r):=\{x\in M:d(p,x)<r\} \operatorname{cont}B(p,r):=\operatorname{rank}(B(p,r/5)\subset B(p,r)), r \operatorname{cont}B(p,r)=\sum b_i(M) b_i:=\dim H_i(M) M M","['differential-geometry', 'algebraic-topology', 'riemannian-geometry', 'homology-cohomology']"
60,Proving that $k(t)=\frac{|\alpha'\wedge\alpha''|}{|\alpha'|^3}.$,Proving that,k(t)=\frac{|\alpha'\wedge\alpha''|}{|\alpha'|^3}.,"I understand this question has already been asked, but I don't exactly follow that answer. I saw I had a similar process but I got lost in their explanation. Following do Carmo, Section 1.5-Exercise 12 Let $α:I→R^3$ be a regular parametrized curve (not necessarily by arc length) and let $β:J→R^3$ be a reparametrization of $α(I)$ by the arc length $s=s(t)$ , measured from $t_0∈I$ . Let $t=t(s)$ be the inverse function of $s$ and set $dα/dt=α′$ , $d^2α/dt^2=α′′$ , etc. Prove that the curvature of $\alpha$ at $t\in I$ is $$k(t)=\frac{|\alpha'\wedge\alpha''|}{|\alpha'|^3}.$$ So, my first thought it to start with what we already know $$s=s(t)=\int_{t_0}^t|\alpha'(t)|dt\implies s'(t)=|\alpha'(t)|.$$ If we rewrite this is a differentiable form, we get $$s'(t)=\frac{\alpha'(t)\cdot\alpha'(t)}{|\alpha'(t)|}.$$ Differentiating both sides of the equation we get $$s''(t)=\frac{2\alpha'(t)\cdot\alpha''(t)}{|\alpha'(t)|}\frac{dt}{ds}\implies s'''(t)=2\frac{\alpha'(t)\cdot\alpha''(t)}{|\alpha'(t)|}.$$ But now, I have no idea what I'm supposed to do? I don't know how I'm supposed to get the $k(t)$ from this equation.","I understand this question has already been asked, but I don't exactly follow that answer. I saw I had a similar process but I got lost in their explanation. Following do Carmo, Section 1.5-Exercise 12 Let be a regular parametrized curve (not necessarily by arc length) and let be a reparametrization of by the arc length , measured from . Let be the inverse function of and set , , etc. Prove that the curvature of at is So, my first thought it to start with what we already know If we rewrite this is a differentiable form, we get Differentiating both sides of the equation we get But now, I have no idea what I'm supposed to do? I don't know how I'm supposed to get the from this equation.",α:I→R^3 β:J→R^3 α(I) s=s(t) t_0∈I t=t(s) s dα/dt=α′ d^2α/dt^2=α′′ \alpha t\in I k(t)=\frac{|\alpha'\wedge\alpha''|}{|\alpha'|^3}. s=s(t)=\int_{t_0}^t|\alpha'(t)|dt\implies s'(t)=|\alpha'(t)|. s'(t)=\frac{\alpha'(t)\cdot\alpha'(t)}{|\alpha'(t)|}. s''(t)=\frac{2\alpha'(t)\cdot\alpha''(t)}{|\alpha'(t)|}\frac{dt}{ds}\implies s'''(t)=2\frac{\alpha'(t)\cdot\alpha''(t)}{|\alpha'(t)|}. k(t),"['differential-geometry', 'curves', 'curvature']"
61,Definition of Higgs bundle,Definition of Higgs bundle,,"I currently try to deal with the definition of a Higgs bundle: The definition is: $(E, \varphi)$ is called a Higgs bundle, if $E$ is a holomorphic vector bundle and $\varphi$ is a holomorphic 1-form with values in $End(E)$ , s.t. $\varphi \wedge \varphi=0$ Now I am not sure what holomorphic 1-form with values in $End(E)$ . Is it a section of $T^{*}M \otimes End(E)$ ? Since the definition of a 1-form in general is that it is a section in $T^{*}M$ . Also, I am reading a paper where it says 'Because $\varphi$ takes values in the adjoint representation, we can think of it locally as an $n \times n$ matrix of holomorphic one-forms – which we can take to act on the fiber of $E$ .' I don't understand what 'takes values in the adjoint representation' means here and how it is related to the above definition. Thanks in advance for any help!","I currently try to deal with the definition of a Higgs bundle: The definition is: is called a Higgs bundle, if is a holomorphic vector bundle and is a holomorphic 1-form with values in , s.t. Now I am not sure what holomorphic 1-form with values in . Is it a section of ? Since the definition of a 1-form in general is that it is a section in . Also, I am reading a paper where it says 'Because takes values in the adjoint representation, we can think of it locally as an matrix of holomorphic one-forms – which we can take to act on the fiber of .' I don't understand what 'takes values in the adjoint representation' means here and how it is related to the above definition. Thanks in advance for any help!","(E, \varphi) E \varphi End(E) \varphi \wedge \varphi=0 End(E) T^{*}M \otimes End(E) T^{*}M \varphi n \times n E","['differential-geometry', 'differential-forms', 'vector-bundles', 'holomorphic-bundles']"
62,vertical component of Lie bracket,vertical component of Lie bracket,,"Let $f:X\to Y$ be a submersion equipped with a connection given by a vertical projection $\mathrm V$ . Let $\vec v_1,\vec v_2$ be vector fields on $Y$ with unique horizontal lifts $\vec u_1,\vec u_2$ . I have read the vertical component $\mathrm V([\vec u_1,\vec u_2](x))$ of the Lie bracket at a point $x\in X$ depends only on $\vec u_1(x),\vec u_2(x)$ , i.e $\vec v_1(fx),\vec v_2(fx)$ . Question. What is the intuition behind this fact and how can I prove it?","Let be a submersion equipped with a connection given by a vertical projection . Let be vector fields on with unique horizontal lifts . I have read the vertical component of the Lie bracket at a point depends only on , i.e . Question. What is the intuition behind this fact and how can I prove it?","f:X\to Y \mathrm V \vec v_1,\vec v_2 Y \vec u_1,\vec u_2 \mathrm V([\vec u_1,\vec u_2](x)) x\in X \vec u_1(x),\vec u_2(x) \vec v_1(fx),\vec v_2(fx)","['differential-geometry', 'connections', 'lie-derivative']"
63,Understanding components and vector derivative in general curvilinear coordinates,Understanding components and vector derivative in general curvilinear coordinates,,"I'm studying introductory vector calculus and need to confirm/clarify my concepts. The definition of the derivative of a vector (for example in $\mathbb{R}^2$ ) if the unit vectors are constant throughout the 2D space is in terms of its components: if we have $\mathbb{r}(t)=(x(t), y(t))$ in the standard Cartesian basis , then $$\frac{d\mathbb{r}}{dt}=\frac{dx}{dt}\mathbb{e}_x+\frac{dy}{dt}\mathbb{e}_y$$ Now if we move to polar coordinates $\rho, \phi$ , then the unit basis vectors $\mathbb{e}_{\rho},\mathbb{e}_{\phi}$ will change direction depending on the location in 2D space. To define the derivative in this case, the book that I'm studying gives the following quick method: we see that $\mathbb{r}=\rho \mathbb{e}_{\rho}$ (where $\rho$ is the distance of the vector's endpoint from the origin), which means $$\frac{d\mathbb{r}}{dt}=\frac{d\rho}{dt}\mathbb{e}_{\rho}+\rho\frac{d\mathbb{e}_{\rho}}{dt}$$ So far, so good: $\frac{d\rho}{dt}$ can be calculated since we can express $\rho$ in terms of $x(t)$ and $y(t)$ , and differentiate that expression w.r.t. $t$ . In this specific case, we can also express $\mathbb{e}_{\rho}=(\cos\phi)\mathbb{e}_x + (\sin\phi)\mathbb{e}_y$ . It turns out that $$\frac{d\mathbb{e}_{\rho}}{dt}=\frac{d\phi}{dt}\mathbb{e}_{\phi}$$ because of the specific way $\mathbb{e}_{\rho}$ and $\mathbb{e}_{\phi}$ are defined in terms of $\mathbb{e}_x$ and $\mathbb{e}_y$ . Expressing the same vector $\mathbb{r}$ in a general curvilinear coordinate system $u,v$ , To even start differentiating $\mathbb{r}$ , we need to find the components of $\mathbb{r}$ in the new system. I'm assuming the way to identify $\mathbb{r}$ is to identify it as the intersection of two coordinate curves $u=c_1$ and $v=c_2$ - in this case, $u=5$ and $v=4$ . Is my understanding correct? Is this the way to identify the components of a vector in a curvilinear system? So if we have some differentiable functions $f,g$ such that $u=f(x,y)$ and $v=g(x,y)$ and $\mathbb{r}=u\mathbb{e}_u+v\mathbb{e}_v$ , then $$\frac{d\mathbb{r}}{dt}=\frac{du}{dt}\mathbb{e}_u+u\frac{d\mathbb{e}_u}{dt}+\frac{dv}{dt}\mathbb{e}_v+v\frac{d\mathbb{e}_v}{dt}$$ $\frac{du}{dt}$ can be identified as $\frac{df(x(t),y(t))}{dt}$ and can be evaluated. How does one, in general, express basis vectors $\mathbb{e}_u$ and $\mathbb{e}_v$ in terms of $\mathbb{e}_x$ and $\mathbb{e}_y$ ? And even if we do manage to define curvilinear basis vectors in terms of $\mathbb{e}_x,\mathbb{e}_y$ , it's not necessary that we'll get a nice expression for $\frac{d\mathbb{e}_u}{dt}$ and $\frac{d\mathbb{e}_v}{dt}$ in terms of $\mathbb{e}_u$ and $\mathbb{e}_v$ . How do we get the curvilinear components of $\frac{d\mathbb{r}}{dt}$ in that case?","I'm studying introductory vector calculus and need to confirm/clarify my concepts. The definition of the derivative of a vector (for example in ) if the unit vectors are constant throughout the 2D space is in terms of its components: if we have in the standard Cartesian basis , then Now if we move to polar coordinates , then the unit basis vectors will change direction depending on the location in 2D space. To define the derivative in this case, the book that I'm studying gives the following quick method: we see that (where is the distance of the vector's endpoint from the origin), which means So far, so good: can be calculated since we can express in terms of and , and differentiate that expression w.r.t. . In this specific case, we can also express . It turns out that because of the specific way and are defined in terms of and . Expressing the same vector in a general curvilinear coordinate system , To even start differentiating , we need to find the components of in the new system. I'm assuming the way to identify is to identify it as the intersection of two coordinate curves and - in this case, and . Is my understanding correct? Is this the way to identify the components of a vector in a curvilinear system? So if we have some differentiable functions such that and and , then can be identified as and can be evaluated. How does one, in general, express basis vectors and in terms of and ? And even if we do manage to define curvilinear basis vectors in terms of , it's not necessary that we'll get a nice expression for and in terms of and . How do we get the curvilinear components of in that case?","\mathbb{R}^2 \mathbb{r}(t)=(x(t), y(t)) \frac{d\mathbb{r}}{dt}=\frac{dx}{dt}\mathbb{e}_x+\frac{dy}{dt}\mathbb{e}_y \rho, \phi \mathbb{e}_{\rho},\mathbb{e}_{\phi} \mathbb{r}=\rho \mathbb{e}_{\rho} \rho \frac{d\mathbb{r}}{dt}=\frac{d\rho}{dt}\mathbb{e}_{\rho}+\rho\frac{d\mathbb{e}_{\rho}}{dt} \frac{d\rho}{dt} \rho x(t) y(t) t \mathbb{e}_{\rho}=(\cos\phi)\mathbb{e}_x + (\sin\phi)\mathbb{e}_y \frac{d\mathbb{e}_{\rho}}{dt}=\frac{d\phi}{dt}\mathbb{e}_{\phi} \mathbb{e}_{\rho} \mathbb{e}_{\phi} \mathbb{e}_x \mathbb{e}_y \mathbb{r} u,v \mathbb{r} \mathbb{r} \mathbb{r} u=c_1 v=c_2 u=5 v=4 f,g u=f(x,y) v=g(x,y) \mathbb{r}=u\mathbb{e}_u+v\mathbb{e}_v \frac{d\mathbb{r}}{dt}=\frac{du}{dt}\mathbb{e}_u+u\frac{d\mathbb{e}_u}{dt}+\frac{dv}{dt}\mathbb{e}_v+v\frac{d\mathbb{e}_v}{dt} \frac{du}{dt} \frac{df(x(t),y(t))}{dt} \mathbb{e}_u \mathbb{e}_v \mathbb{e}_x \mathbb{e}_y \mathbb{e}_x,\mathbb{e}_y \frac{d\mathbb{e}_u}{dt} \frac{d\mathbb{e}_v}{dt} \mathbb{e}_u \mathbb{e}_v \frac{d\mathbb{r}}{dt}","['differential-geometry', 'vector-fields']"
64,Some good books on application of Gauss-Bonnet-Chern Theorem in general relativity,Some good books on application of Gauss-Bonnet-Chern Theorem in general relativity,,I am currently doing an undergraduate project about Gauss-Bonnet-Chern Theorem. Is there any particular book suggestions regarding the application of the theorem in the theory of general relativity? Edit: I should ask more specifically. Is there any good reference on the application of Gauss-Bonnet-Chern Theorem for four-dimensional manifold on general relativity?,I am currently doing an undergraduate project about Gauss-Bonnet-Chern Theorem. Is there any particular book suggestions regarding the application of the theorem in the theory of general relativity? Edit: I should ask more specifically. Is there any good reference on the application of Gauss-Bonnet-Chern Theorem for four-dimensional manifold on general relativity?,,"['differential-geometry', 'reference-request', 'manifolds', 'riemannian-geometry', 'general-relativity']"
65,Isomorphisms of vector bundles preserve orientability,Isomorphisms of vector bundles preserve orientability,,"Let $E$ and $\tilde{E}$ be vector bundles of rank $k$ over $M$ , and assume they can be trivialized over the same cover $\{U_\alpha\}$ . Suppose $E$ is orientable. The definition of orientable that I know is that the transition maps of $E$ , say $t_{\alpha\beta}: U_\beta \cap U_\alpha \to GL(k, \mathbf{R})$ always has positive determinant. It's unclear to me why $\tilde{E}$ must also be orientable if there is a vector bundle isomorphism $\varphi: E \to \tilde{E}$ . For example such a vector bundle isomorphism is given by the data of smooth maps $h_\alpha: U_\alpha \to GL(k, \mathbf{R})$ such that $\tilde{t}_{\alpha\beta} = h_\alpha t_{\alpha\beta} h_\beta^{-1}$ . In fact, I think you might as well take the $h_\alpha$ 's to be arbitrary and define $\tilde{E}$ to be the vector bundle over $M$ with transition maps given by the above formula. But in general it doesn't seem like there's any guarantee that $\tilde{t}_{\alpha\beta}$ has positive determinant, as $h_\alpha$ and $h_\beta$ might have determinants of different signs. Even if you can fix this locally by flipping a sign in a chart, it isn't clear to me that this can be done without causing problems in intersections with other charts.","Let and be vector bundles of rank over , and assume they can be trivialized over the same cover . Suppose is orientable. The definition of orientable that I know is that the transition maps of , say always has positive determinant. It's unclear to me why must also be orientable if there is a vector bundle isomorphism . For example such a vector bundle isomorphism is given by the data of smooth maps such that . In fact, I think you might as well take the 's to be arbitrary and define to be the vector bundle over with transition maps given by the above formula. But in general it doesn't seem like there's any guarantee that has positive determinant, as and might have determinants of different signs. Even if you can fix this locally by flipping a sign in a chart, it isn't clear to me that this can be done without causing problems in intersections with other charts.","E \tilde{E} k M \{U_\alpha\} E E t_{\alpha\beta}: U_\beta \cap U_\alpha \to GL(k, \mathbf{R}) \tilde{E} \varphi: E \to \tilde{E} h_\alpha: U_\alpha \to GL(k, \mathbf{R}) \tilde{t}_{\alpha\beta} = h_\alpha t_{\alpha\beta} h_\beta^{-1} h_\alpha \tilde{E} M \tilde{t}_{\alpha\beta} h_\alpha h_\beta","['differential-geometry', 'differential-topology', 'vector-bundles']"
66,What's an example where the inclusion map $\iota: A \to B$ is smooth and a topological embedding but not an immersion?,What's an example where the inclusion map  is smooth and a topological embedding but not an immersion?,\iota: A \to B,"Context: 1. Are manifold subsets submanifolds? 2. Can manifold subsets always be made into submanifolds? 3. Why is the inclusion from a submanifold smooth? Let $A,B$ be topological spaces with $A \subseteq B$ and $A$ a topological subspace of $B$ . Suppose $A$ and $B$ become smooth manifolds $(A,\mathscr A)$ and $(B,\mathscr B)$ with respectively with dimensions $a$ and $b$ . What's an example where the inclusion map $\iota: (A,\mathscr A) \to (B,\mathscr B)$ is smooth and a topological embedding but not an immersion? There are a lot of examples of smooth immersions that are not topological embeddings (and thus not smooth embeddings) like this . There are also examples of smooth topological embeddings that are not immersions (and thus, again, not smooth embeddings) like this . In some of the questions linked above, there were examples that where $\iota$ wasn't smooth or even continuous. The purpose of this question is to ask specifically about the inclusion map and the case that the inclusion map is smooth. If such examples exists, then this tells me there's nothing particularly different about the inclusion map. What's an example where the inclusion map $\iota: (A,\mathscr A) \to (B,\mathscr B)$ is smooth but not a topological embedding? Just checking my understanding. If there are no such examples, then (1) could simply ask ""smooth but not immersion"".","Context: 1. Are manifold subsets submanifolds? 2. Can manifold subsets always be made into submanifolds? 3. Why is the inclusion from a submanifold smooth? Let be topological spaces with and a topological subspace of . Suppose and become smooth manifolds and with respectively with dimensions and . What's an example where the inclusion map is smooth and a topological embedding but not an immersion? There are a lot of examples of smooth immersions that are not topological embeddings (and thus not smooth embeddings) like this . There are also examples of smooth topological embeddings that are not immersions (and thus, again, not smooth embeddings) like this . In some of the questions linked above, there were examples that where wasn't smooth or even continuous. The purpose of this question is to ask specifically about the inclusion map and the case that the inclusion map is smooth. If such examples exists, then this tells me there's nothing particularly different about the inclusion map. What's an example where the inclusion map is smooth but not a topological embedding? Just checking my understanding. If there are no such examples, then (1) could simply ask ""smooth but not immersion"".","A,B A \subseteq B A B A B (A,\mathscr A) (B,\mathscr B) a b \iota: (A,\mathscr A) \to (B,\mathscr B) \iota \iota: (A,\mathscr A) \to (B,\mathscr B)","['general-topology', 'differential-geometry']"
67,Computing the curvature of a connection,Computing the curvature of a connection,,"I'm trying to compute the curvature of a connection $\nabla$ on a 2-dimensional real vector bundle $E$ over a 2-dimensional manifold $M$ . I'm using the definition $$F_{\nabla}(X,Y,s)= \nabla_X\nabla_Yf-\nabla_Y\nabla_Xf -\nabla_{[X,Y]}f$$ where $X,Y$ are vector field over $M$ and $s$ is a section of $E$ . I know that $F_{\nabla}$ is $C^{\infty}(M)$ -linear in all components, hence my idea is to compute the curvature just for vector field of the form $\frac{\partial}{\partial x}$ and $\frac{\partial}{\partial y}$ , since they locally give a basis for the $C^{\infty}$ -module of vector fields. Now, I'm not really familiar with Lie derivative, so I'm thinking of $[X,Y]$ just as an operator, but I think $[\frac{\partial}{\partial x},\frac{\partial}{\partial x}]$ , $[\frac{\partial}{\partial x},\frac{\partial}{\partial y}]$ , $[\frac{\partial}{\partial y},\frac{\partial}{\partial x}]$ and $[\frac{\partial}{\partial y},\frac{\partial}{\partial y}]$ should all be zero. It follows that in my computation $\nabla_{[X,Y]}f$ always vanishes. Is it possible? Am I allowed to work locally like that?","I'm trying to compute the curvature of a connection on a 2-dimensional real vector bundle over a 2-dimensional manifold . I'm using the definition where are vector field over and is a section of . I know that is -linear in all components, hence my idea is to compute the curvature just for vector field of the form and , since they locally give a basis for the -module of vector fields. Now, I'm not really familiar with Lie derivative, so I'm thinking of just as an operator, but I think , , and should all be zero. It follows that in my computation always vanishes. Is it possible? Am I allowed to work locally like that?","\nabla E M F_{\nabla}(X,Y,s)= \nabla_X\nabla_Yf-\nabla_Y\nabla_Xf -\nabla_{[X,Y]}f X,Y M s E F_{\nabla} C^{\infty}(M) \frac{\partial}{\partial x} \frac{\partial}{\partial y} C^{\infty} [X,Y] [\frac{\partial}{\partial x},\frac{\partial}{\partial x}] [\frac{\partial}{\partial x},\frac{\partial}{\partial y}] [\frac{\partial}{\partial y},\frac{\partial}{\partial x}] [\frac{\partial}{\partial y},\frac{\partial}{\partial y}] \nabla_{[X,Y]}f","['differential-geometry', 'vector-bundles', 'curvature', 'connections']"
68,How to calculate the Tangent space of a line in $\mathbb{R}^2$?,How to calculate the Tangent space of a line in ?,\mathbb{R}^2,"Calculate the Tangent Space of a line $y=mx; m\in \mathbb{R}$ in a point $p=(x,y)$ I know that a line that passes through the origin is a manifold $M$ and the chart is $(M,\varphi); \varphi(x)=(x,mx)$ . I know that $T_pM$ is generated by one element, but i don't know how to find the element $d/dx^i$ I appreciate your help.","Calculate the Tangent Space of a line in a point I know that a line that passes through the origin is a manifold and the chart is . I know that is generated by one element, but i don't know how to find the element I appreciate your help.","y=mx; m\in \mathbb{R} p=(x,y) M (M,\varphi); \varphi(x)=(x,mx) T_pM d/dx^i",['differential-geometry']
69,Why do we need charts to define a submersion/immersion?,Why do we need charts to define a submersion/immersion?,,"I am learning the theory of smooth manifolds and have a question on the definitions of a submersion/immersion and its dependency on given charts. Given a smooth map $f:M\mapsto N$ between two smooth manifolds of finite dimension. If I am correct this means that given any chart $\chi$ of $M$ and chart $\chi^\prime$ on $N$ , $$f_{\chi^\prime}^{\chi}=\chi^\prime\circ f\circ\chi^{-1}$$ is smooth in the usual sense of analysis. Now to prove if $f$ is a submersion (or similar an immersion) at $p\in M$ one checks that, $$(df_{\chi^\prime}^{\chi})_{\chi(p)}$$ is surjective\injective. By the chainrule, $$\big(d(\chi^\prime\circ f\circ\chi^{-1})\big)_{\chi(p)}=(d\chi^\prime)_{\chi(p)}\circ(df)_p\circ(d\chi^{-1})_{\chi^{-1}(p)}.$$ But since all charts a homeomorphisms their differentials are isomorfisms. Now my question is, why bother looking at $f_{\chi^\prime}^{\chi}$ if you can just look at whether or not the differential of $f$ is surjective/injecitive? The differentials of the charts are after all isomorfisms. Am i looking at it the right way? Beside that, in the practical situation of having to check wheter or not a map is a submersion/immersion one has to do this for all combination of charts contained in the two atlases which induce the smooth structures, thats a bit cumbersome... Is there a trick/theorem one can use?","I am learning the theory of smooth manifolds and have a question on the definitions of a submersion/immersion and its dependency on given charts. Given a smooth map between two smooth manifolds of finite dimension. If I am correct this means that given any chart of and chart on , is smooth in the usual sense of analysis. Now to prove if is a submersion (or similar an immersion) at one checks that, is surjective\injective. By the chainrule, But since all charts a homeomorphisms their differentials are isomorfisms. Now my question is, why bother looking at if you can just look at whether or not the differential of is surjective/injecitive? The differentials of the charts are after all isomorfisms. Am i looking at it the right way? Beside that, in the practical situation of having to check wheter or not a map is a submersion/immersion one has to do this for all combination of charts contained in the two atlases which induce the smooth structures, thats a bit cumbersome... Is there a trick/theorem one can use?",f:M\mapsto N \chi M \chi^\prime N f_{\chi^\prime}^{\chi}=\chi^\prime\circ f\circ\chi^{-1} f p\in M (df_{\chi^\prime}^{\chi})_{\chi(p)} \big(d(\chi^\prime\circ f\circ\chi^{-1})\big)_{\chi(p)}=(d\chi^\prime)_{\chi(p)}\circ(df)_p\circ(d\chi^{-1})_{\chi^{-1}(p)}. f_{\chi^\prime}^{\chi} f,['differential-geometry']
70,How can I find an approximation of a smooth function $R^2 \to R^4$ such that when restricted to $S^1$ it is an immersion?,How can I find an approximation of a smooth function  such that when restricted to  it is an immersion?,R^2 \to R^4 S^1,"I am having trouble with the following exercise: Given a smooth function $f: R^2 \to R^4$ and $S^{1}$ embedded in $R^2$ , then $\forall \epsilon >0$ there exists a smooth function $f_{1}$ such that $sup|f(x)-f_{1}(x)|< \epsilon$ , which is an immersion when restricted to $S^1$ .","I am having trouble with the following exercise: Given a smooth function and embedded in , then there exists a smooth function such that , which is an immersion when restricted to .",f: R^2 \to R^4 S^{1} R^2 \forall \epsilon >0 f_{1} sup|f(x)-f_{1}(x)|< \epsilon S^1,"['differential-geometry', 'manifolds']"
71,Paraboloid is diffeomorphic to a plane,Paraboloid is diffeomorphic to a plane,,"Consider the paraboloid $x^2+y^2=z$ . I need to show that this paraboloid is diffeomorphic to a plane. Let $P$ be this paraboloid and $S$ be the plane that I will use. So, by definition, I need to show that a function $\phi:P\rightarrow S$ satisfies the following. Let $\alpha:U_{1}\subset\mathbb{R}^{2}\rightarrow P$ a local parametrization of $P$ , with $p\in\alpha (U_1);\beta:U_{2}\rightarrow S$ a local parametrization of $S$ with $\phi(\alpha(U_{1}))\subset\beta(U_{2})$ . We have $\beta^{-1}\, \circ\,\phi\,\circ\,\alpha:U_{1}\rightarrow U_{2}$ differentiable at $q=\alpha^{-1}(p),$ and $\phi$ has a differentiable inverse $\phi^{-1}:S\rightarrow P.$ I take the parametrization of $P$ given by $$\alpha(u,v)=(v\cos(u),v\sin(u), v^2)\quad u\in[0,2\pi),v\in\mathbb{R}.$$ For $S$ , I think that I can take an arbitrary plane to be diffeomorphic to $P$ , so, consider the plane $xy$ , that is, the set of points with form $(x,y,0), x,y\in\mathbb{R}$ . Take the parametrization of $S$ given by $$\beta(u,v)=(u,v,0),\quad u,v\in\mathbb{R}$$ So, I can define a $\phi:S\rightarrow P$ by $\phi(u,v,0)=(v\cos(u),v\sin(u),v^2)$ . Is this $\phi$ a diffeomorphism?","Consider the paraboloid . I need to show that this paraboloid is diffeomorphic to a plane. Let be this paraboloid and be the plane that I will use. So, by definition, I need to show that a function satisfies the following. Let a local parametrization of , with a local parametrization of with . We have differentiable at and has a differentiable inverse I take the parametrization of given by For , I think that I can take an arbitrary plane to be diffeomorphic to , so, consider the plane , that is, the set of points with form . Take the parametrization of given by So, I can define a by . Is this a diffeomorphism?","x^2+y^2=z P S \phi:P\rightarrow S \alpha:U_{1}\subset\mathbb{R}^{2}\rightarrow P P p\in\alpha (U_1);\beta:U_{2}\rightarrow S S \phi(\alpha(U_{1}))\subset\beta(U_{2}) \beta^{-1}\, \circ\,\phi\,\circ\,\alpha:U_{1}\rightarrow U_{2} q=\alpha^{-1}(p), \phi \phi^{-1}:S\rightarrow P. P \alpha(u,v)=(v\cos(u),v\sin(u), v^2)\quad u\in[0,2\pi),v\in\mathbb{R}. S P xy (x,y,0), x,y\in\mathbb{R} S \beta(u,v)=(u,v,0),\quad u,v\in\mathbb{R} \phi:S\rightarrow P \phi(u,v,0)=(v\cos(u),v\sin(u),v^2) \phi","['differential-geometry', 'parametrization', 'diffeomorphism']"
72,Induced map on $T(X)$ the Tangent bundle,Induced map on  the Tangent bundle,T(X),"If $ f:X\to Y$ is an Immersion\ Submersion\ Diffeomorphism then what can we say about the induced map $ df: T(X)\to T(Y) $ defined as $df(x,v)= (f(x),df_x(v))$ .  Will it also have the same properties? I don't know how to start, kindly help. Thanks & regards","If is an Immersion\ Submersion\ Diffeomorphism then what can we say about the induced map defined as .  Will it also have the same properties? I don't know how to start, kindly help. Thanks & regards"," f:X\to Y  df: T(X)\to T(Y)  df(x,v)= (f(x),df_x(v))","['differential-geometry', 'differential-topology']"
73,Expression in D.J Saunders 's book (The geometry of jet bundles),Expression in D.J Saunders 's book (The geometry of jet bundles),,"Lemma 4.1.1 in D.J Saunders 's book (The geometry of jet bundles) says: Let $(E,\pi,M)$ be a bundle, and let $p$ $\in M$ . Suppose that $\phi$ and $\psi$ are section that satisfy $\phi(p)=\psi(p)$ . Let $(x^i,u^\alpha)$ and $(y^i,v^\beta)$ be two adapted coordinate systems around $\phi(p)$ , and suppose also that $$\frac{\partial(   u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial(   u^\alpha \circ \psi)}{\partial x^i}\bigg|_{p}$$ for $1 \leq i\leq m$ and $1 \leq \alpha \leq n$ then $$\frac{\partial(   v^\beta \circ \phi)}{\partial y^i}\bigg|_{p}=\frac{\partial(   v^\beta \circ \psi)}{\partial y^i}\bigg|_{p}$$ for $1 \leq j\leq m$ and $1 \leq \beta \leq n$ To proof this he uses the relation $$\frac{\partial(   v^\beta \circ \phi)}{\partial y^j}\bigg|_{p}=\frac{\partial(   v^\beta \circ \phi)}{\partial x^i}\bigg|_{p} \frac{\partial   x^i }{\partial y^j}\bigg|_{p}=\left (\frac{\partial   v^\beta }{\partial x^i}\bigg|_{\phi(p)}+\frac{\partial   v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial(   u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p} \right)\frac{\partial   x^i }{\partial y^j}\bigg|_{p} $$ My problem  here is why $$\frac{\partial(   v^\beta \circ \phi)}{\partial x^i}\bigg|_{p} =\left (\frac{\partial   v^\beta }{\partial x^i}\bigg|_{\phi(p)}+\frac{\partial   v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial(   u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p} \right)$$ Shouldn't it be $$ \frac{\partial(   v^\beta \circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial(   v^\beta \circ u^{-1} \circ u\circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial   v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial(   u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p} $$ ? So why the extra factor $$\frac{\partial   v^\beta }{\partial x^i}\bigg|_{\phi(p)}$$ appears?","Lemma 4.1.1 in D.J Saunders 's book (The geometry of jet bundles) says: Let be a bundle, and let . Suppose that and are section that satisfy . Let and be two adapted coordinate systems around , and suppose also that for and then for and To proof this he uses the relation My problem  here is why Shouldn't it be ? So why the extra factor appears?","(E,\pi,M) p \in M \phi \psi \phi(p)=\psi(p) (x^i,u^\alpha) (y^i,v^\beta) \phi(p) \frac{\partial( 
 u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial( 
 u^\alpha \circ \psi)}{\partial x^i}\bigg|_{p} 1 \leq i\leq m 1 \leq \alpha \leq n \frac{\partial( 
 v^\beta \circ \phi)}{\partial y^i}\bigg|_{p}=\frac{\partial( 
 v^\beta \circ \psi)}{\partial y^i}\bigg|_{p} 1 \leq j\leq m 1 \leq \beta \leq n \frac{\partial( 
 v^\beta \circ \phi)}{\partial y^j}\bigg|_{p}=\frac{\partial( 
 v^\beta \circ \phi)}{\partial x^i}\bigg|_{p} \frac{\partial 
 x^i }{\partial y^j}\bigg|_{p}=\left (\frac{\partial 
 v^\beta }{\partial x^i}\bigg|_{\phi(p)}+\frac{\partial 
 v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial( 
 u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p} \right)\frac{\partial 
 x^i }{\partial y^j}\bigg|_{p}  \frac{\partial( 
 v^\beta \circ \phi)}{\partial x^i}\bigg|_{p} =\left (\frac{\partial 
 v^\beta }{\partial x^i}\bigg|_{\phi(p)}+\frac{\partial 
 v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial( 
 u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p} \right)  \frac{\partial( 
 v^\beta \circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial( 
 v^\beta \circ u^{-1} \circ u\circ \phi)}{\partial x^i}\bigg|_{p}=\frac{\partial 
 v^\beta }{\partial u^{\alpha}}\bigg|_{\phi(p)} \frac{\partial( 
 u^\alpha \circ \phi)}{\partial x^i}\bigg|_{p}  \frac{\partial 
 v^\beta }{\partial x^i}\bigg|_{\phi(p)}","['differential-geometry', 'coordinate-systems', 'fiber-bundles', 'jet-bundles']"
74,"Do non-product metrics on product spaces still satisfy a ""sectional inequality""?","Do non-product metrics on product spaces still satisfy a ""sectional inequality""?",,"Let $X, Y$ be connected manifolds and $g$ a Riemannian metric on $X\times Y$ inducing a metric $d$ . Is it true that for $x_1,x_2\in X, y_1,y_2\in Y$ one has: $$\inf_{x\in X}d[(x,y_1),(x,y_2)]≤d[(x_1,y_1), (x_2,y_2)].$$ Some additional (not very useful) remarks: The conditions of $X,Y$ being manifolds and $d$ coming from a Riemannian metric are likely overkill. If the statement is true it is likely already true for much less stringent conditions, I would guess something like path connected + locally path connected + locally compact is enough. For product metrics of the form $d[(x_1,y_2), (x_2,y_2)] = d_X(x_1,x_2)+ d_Y(y_1,y_2)$ or $d=\max(d_X, d_Y)$ the statement is trivial.","Let be connected manifolds and a Riemannian metric on inducing a metric . Is it true that for one has: Some additional (not very useful) remarks: The conditions of being manifolds and coming from a Riemannian metric are likely overkill. If the statement is true it is likely already true for much less stringent conditions, I would guess something like path connected + locally path connected + locally compact is enough. For product metrics of the form or the statement is trivial.","X, Y g X\times Y d x_1,x_2\in X, y_1,y_2\in Y \inf_{x\in X}d[(x,y_1),(x,y_2)]≤d[(x_1,y_1), (x_2,y_2)]. X,Y d d[(x_1,y_2), (x_2,y_2)] = d_X(x_1,x_2)+ d_Y(y_1,y_2) d=\max(d_X, d_Y)","['general-topology', 'differential-geometry', 'metric-spaces']"
75,Rauch comparison theorem with other initial conditions?,Rauch comparison theorem with other initial conditions?,,"The statement of the Rauch comparison theorem (see e.g. https://en.wikipedia.org/wiki/Rauch_comparison_theorem ) involves two normal Jacobi fields $J$ and $\tilde{J}$ along two unit speed geodesics $\gamma$ and $\tilde{\gamma}$ in their respective manifolds $M$ and $\tilde{M}$ . As a hypothesis, $J(0)=\tilde{J}(0)=0$ and $\|D_tJ(0)\|=\|\tilde{D}_t\tilde{J}(0)\|$ . Also, conjugate points must be avoided in $\tilde{\gamma}$ . I've been looking for an identical statement but taking a non-zero initial condition (EDIT): $\|J(0)\|=\|\tilde{J}(0)\|=a\neq0$ . Nevertheless, I didn't find anything and I don't even know if it's possible. The only similar thing I found is on the page 149 of the Sakai's book Riemannian geometry (1996). Here, an extended result to Rauch is given but it involves an hypersurface $N$ , $N$ -Jacobi fields and focal points. I also found somewhere Rauch as a corollary of the Sturm's theorem on differential equations, but the version I'm looking for was not deduced from there (I don't know if it's possible just by taking another initial condition in the differential equation problem). To sum up, I just want the same statement as above but with a non-zero initial condition (maybe with some change on the condition of avoiding conjugate points also, I don't know). Any reference is welcome! Thank you in advance!","The statement of the Rauch comparison theorem (see e.g. https://en.wikipedia.org/wiki/Rauch_comparison_theorem ) involves two normal Jacobi fields and along two unit speed geodesics and in their respective manifolds and . As a hypothesis, and . Also, conjugate points must be avoided in . I've been looking for an identical statement but taking a non-zero initial condition (EDIT): . Nevertheless, I didn't find anything and I don't even know if it's possible. The only similar thing I found is on the page 149 of the Sakai's book Riemannian geometry (1996). Here, an extended result to Rauch is given but it involves an hypersurface , -Jacobi fields and focal points. I also found somewhere Rauch as a corollary of the Sturm's theorem on differential equations, but the version I'm looking for was not deduced from there (I don't know if it's possible just by taking another initial condition in the differential equation problem). To sum up, I just want the same statement as above but with a non-zero initial condition (maybe with some change on the condition of avoiding conjugate points also, I don't know). Any reference is welcome! Thank you in advance!",J \tilde{J} \gamma \tilde{\gamma} M \tilde{M} J(0)=\tilde{J}(0)=0 \|D_tJ(0)\|=\|\tilde{D}_t\tilde{J}(0)\| \tilde{\gamma} \|J(0)\|=\|\tilde{J}(0)\|=a\neq0 N N,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
76,A particular confusion in showing $M_m$ is naturally isomorphic with $(F_m/F_m^2)^*$,A particular confusion in showing  is naturally isomorphic with,M_m (F_m/F_m^2)^*,"I am working through the proof of a lemma in Frank Warner's Foundations of Differentiable Manifolds. I am trying to show that the maps he defines in the proof of this lemma are in fact inverses. Here $F_m^k$ is defined to be the set of k-fold products of germs at m, $M_m$ is the set of tangent vectors at $m$ . Attempt: Let $w\in M_m$ , this is mapped to the functional in $(F_m/F_m^2)^*$ that sends $f$ to $m(f)=m^i\frac{\partial f}{\partial x^i}$ . We want to show that $v_w(f)=w$ . $$v_w(f)=l(\{w(f)-w(f)(m)\})=l(\{w(f)\})-l(\{w(f)(m)\})$$ But I am not sure how to continue.","I am working through the proof of a lemma in Frank Warner's Foundations of Differentiable Manifolds. I am trying to show that the maps he defines in the proof of this lemma are in fact inverses. Here is defined to be the set of k-fold products of germs at m, is the set of tangent vectors at . Attempt: Let , this is mapped to the functional in that sends to . We want to show that . But I am not sure how to continue.",F_m^k M_m m w\in M_m (F_m/F_m^2)^* f m(f)=m^i\frac{\partial f}{\partial x^i} v_w(f)=w v_w(f)=l(\{w(f)-w(f)(m)\})=l(\{w(f)\})-l(\{w(f)(m)\}),"['differential-geometry', 'smooth-manifolds']"
77,Proving that the Yamabe invariant is indeed conformally invariant,Proving that the Yamabe invariant is indeed conformally invariant,,"In Aubin's book, $\textit{Some Nonlinear Problems in Riemannian Geometry}$ , the following proof is given to show that $\mu$ (the Yamabe invariant) is conformally invariant. The Equation (1) that is being referred to is: I have encountered two difficulties with this proof. First: When I evaluate $\nabla^i(\varphi\psi)\nabla_i(\varphi\psi)$ , I get \begin{equation*} \nabla^i(\varphi\psi)\nabla_i(\varphi\psi) = \varphi^2 \nabla^i\psi\nabla_i\psi + \psi^2\nabla^i\varphi\nabla_i\varphi + \varphi\psi(\nabla^i\varphi\nabla_i\psi + \nabla^i\psi\nabla_i\varphi). \end{equation*} How do the last three terms in the above turn into $\varphi\psi^2\Delta\varphi$ ? Second: After using equation (1), I get, \begin{equation*} J(\varphi\psi)=\frac{4\frac{n-1}{n-2}\big[\int_M \varphi^2 \nabla^i\psi\nabla_i\psi \, dV\big] + \int_M R' \psi^2 dV'}{\big[\int_M \psi^N dV'\big]^{2/N}}. \end{equation*} In the first integral on the numerator, I'm not sure how $\varphi^2$ is used to transform $dV$ into $dV'$ . Apologies if the answers to my difficulties are trivial (I'm still rather new to this type of material). Any help would be greatly appreciated. Thank you.","In Aubin's book, , the following proof is given to show that (the Yamabe invariant) is conformally invariant. The Equation (1) that is being referred to is: I have encountered two difficulties with this proof. First: When I evaluate , I get How do the last three terms in the above turn into ? Second: After using equation (1), I get, In the first integral on the numerator, I'm not sure how is used to transform into . Apologies if the answers to my difficulties are trivial (I'm still rather new to this type of material). Any help would be greatly appreciated. Thank you.","\textit{Some Nonlinear Problems in Riemannian Geometry} \mu \nabla^i(\varphi\psi)\nabla_i(\varphi\psi) \begin{equation*}
\nabla^i(\varphi\psi)\nabla_i(\varphi\psi) = \varphi^2 \nabla^i\psi\nabla_i\psi + \psi^2\nabla^i\varphi\nabla_i\varphi + \varphi\psi(\nabla^i\varphi\nabla_i\psi + \nabla^i\psi\nabla_i\varphi).
\end{equation*} \varphi\psi^2\Delta\varphi \begin{equation*}
J(\varphi\psi)=\frac{4\frac{n-1}{n-2}\big[\int_M \varphi^2 \nabla^i\psi\nabla_i\psi \, dV\big] + \int_M R' \psi^2 dV'}{\big[\int_M \psi^N dV'\big]^{2/N}}.
\end{equation*} \varphi^2 dV dV'","['differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
78,Riemannian curvature tensor of hyperbolic space $\mathbb H^3$,Riemannian curvature tensor of hyperbolic space,\mathbb H^3,"Question : Given metric $g=\frac{4}{(1-\rho^2)^2}(d\rho^2+\rho^2d\theta^2+\rho^2\cos^2\theta d\varphi^2)$ and unit orthogonal vector fields $X_1=\frac{1-\rho^2}{2}\frac{\partial}{\partial \rho}, X_2=\frac{1-\rho^2}{2\rho}\frac{\partial}{\partial \theta}, X_3=\frac{1-\rho^2}{2\rho\cos\theta}\frac{\partial}{\partial \varphi}.$ In order to check $\langle R(X_i,X_j)X_k,X_l\rangle=-(\delta_{ik}\delta_{jl}-\delta_{il}\delta_{jk})\ (i,j,k,l=1,2,3)$ , is it necessary to calculate explicitly it's ture for every component? Or is there an abstract way to derive this? Background : I'm going to check hyperbolic space $\Bbb H^n:=(B^n,g)$ has constant sectional curvature $-1$ , where $B^n=\{x\in \Bbb R^n ,|x|<1\}$ is unit ball and $g=\frac{4}{(1-\sum_i (x^i)^2)^2}\sum_i dx^i\otimes dx^i$ is hyperbolic metric. By using a trick in Riemannian Geometry, it remains to show $\Bbb H^3$ has constant sectional curvature $-1$ . In spherical coordinate $\{\rho, \varphi, \theta\}$ on $\Bbb R^3-\{0\}, $ hyperbolic metric can be written as $\frac{4}{(1-\rho^2)^2}(d\rho^2+\rho^2d\theta^2+\rho^2\cos^2\theta d\varphi^2)$ . Vector fields $X_1=\frac{1-\rho^2}{2}\frac{\partial}{\partial \rho}, X_2=\frac{1-\rho^2}{2\rho}\frac{\partial}{\partial \theta}, X_3=\frac{1-\rho^2}{2\rho\cos\theta}\frac{\partial}{\partial \varphi}$ are unit orthogonal vector fields under hyoerbolic metric. $$[X_1,X_2]=-\frac{1+\rho^2}{2\rho}X_2,\ [X_2,X_3]=\frac{1-\rho^2}{2\rho}\tan \theta\cdot X_3,\ [X_1,X_3]=-\frac{1+\rho^2}{2\rho} X_3.$$ For unit orthogonal vector fields, Koszul formula becomes $$2\langle\nabla_XY,Z\rangle =\langle[X,Y],Z\rangle-\langle[X,Z],Y\rangle-\langle[Y,Z],X\rangle$$ and we have $$\nabla_{X_1}X_1=\nabla_{X_1}X_2=\nabla_{X_1}X_3=0.$$ $$\nabla_{X_2}X_2=-\frac{1+\rho^2}{2\rho} X_1,\nabla_{X_2}X_3=0,\nabla_{X_3}X_3=-\frac{1+\rho^2}{2\rho} X_1+\frac{1-\rho^2}{2\rho}\tan \theta\cdot X_2.$$ Sectional curvature is determined by all its 2-dim subspace, and by torsion-free property and calculation, $$K(X_1,X_2):=\langle R(X_1,X_2)X_2,X_1\rangle=-1,$$ $$K(X_2,X_3):=\langle R(X_2,X_3)X_3,X_2\rangle=-1,$$ $$K(X_1,X_3):=\langle R(X_1,X_3)X_3,X_1\rangle=-1.$$ So $\Bbb H^3$ has constant sectional curvature $-1$ . My textbook also says $\langle R(X_i,X_j)X_k,X_l\rangle=-(\delta_{ik}\delta_{jl}-\delta_{il}\delta_{jk})\ (i,j,k,l=1,2,3)$ , it's an abstract equation while calculating sectional curvature requires a lot of explicit calculation, so is there an abstract way(without calculating all its components) to derive this equation for Riemmanian curvature? Thanks for your time and patience.","Question : Given metric and unit orthogonal vector fields In order to check , is it necessary to calculate explicitly it's ture for every component? Or is there an abstract way to derive this? Background : I'm going to check hyperbolic space has constant sectional curvature , where is unit ball and is hyperbolic metric. By using a trick in Riemannian Geometry, it remains to show has constant sectional curvature . In spherical coordinate on hyperbolic metric can be written as . Vector fields are unit orthogonal vector fields under hyoerbolic metric. For unit orthogonal vector fields, Koszul formula becomes and we have Sectional curvature is determined by all its 2-dim subspace, and by torsion-free property and calculation, So has constant sectional curvature . My textbook also says , it's an abstract equation while calculating sectional curvature requires a lot of explicit calculation, so is there an abstract way(without calculating all its components) to derive this equation for Riemmanian curvature? Thanks for your time and patience.","g=\frac{4}{(1-\rho^2)^2}(d\rho^2+\rho^2d\theta^2+\rho^2\cos^2\theta d\varphi^2) X_1=\frac{1-\rho^2}{2}\frac{\partial}{\partial \rho}, X_2=\frac{1-\rho^2}{2\rho}\frac{\partial}{\partial \theta}, X_3=\frac{1-\rho^2}{2\rho\cos\theta}\frac{\partial}{\partial \varphi}. \langle R(X_i,X_j)X_k,X_l\rangle=-(\delta_{ik}\delta_{jl}-\delta_{il}\delta_{jk})\ (i,j,k,l=1,2,3) \Bbb H^n:=(B^n,g) -1 B^n=\{x\in \Bbb R^n ,|x|<1\} g=\frac{4}{(1-\sum_i (x^i)^2)^2}\sum_i dx^i\otimes dx^i \Bbb H^3 -1 \{\rho, \varphi, \theta\} \Bbb R^3-\{0\},  \frac{4}{(1-\rho^2)^2}(d\rho^2+\rho^2d\theta^2+\rho^2\cos^2\theta d\varphi^2) X_1=\frac{1-\rho^2}{2}\frac{\partial}{\partial \rho}, X_2=\frac{1-\rho^2}{2\rho}\frac{\partial}{\partial \theta}, X_3=\frac{1-\rho^2}{2\rho\cos\theta}\frac{\partial}{\partial \varphi} [X_1,X_2]=-\frac{1+\rho^2}{2\rho}X_2,\ [X_2,X_3]=\frac{1-\rho^2}{2\rho}\tan \theta\cdot X_3,\ [X_1,X_3]=-\frac{1+\rho^2}{2\rho} X_3. 2\langle\nabla_XY,Z\rangle =\langle[X,Y],Z\rangle-\langle[X,Z],Y\rangle-\langle[Y,Z],X\rangle \nabla_{X_1}X_1=\nabla_{X_1}X_2=\nabla_{X_1}X_3=0. \nabla_{X_2}X_2=-\frac{1+\rho^2}{2\rho} X_1,\nabla_{X_2}X_3=0,\nabla_{X_3}X_3=-\frac{1+\rho^2}{2\rho} X_1+\frac{1-\rho^2}{2\rho}\tan \theta\cdot X_2. K(X_1,X_2):=\langle R(X_1,X_2)X_2,X_1\rangle=-1, K(X_2,X_3):=\langle R(X_2,X_3)X_3,X_2\rangle=-1, K(X_1,X_3):=\langle R(X_1,X_3)X_3,X_1\rangle=-1. \Bbb H^3 -1 \langle R(X_i,X_j)X_k,X_l\rangle=-(\delta_{ik}\delta_{jl}-\delta_{il}\delta_{jk})\ (i,j,k,l=1,2,3)","['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry', 'curvature']"
79,About a condition for an immersion to be an embedding,About a condition for an immersion to be an embedding,,"I was trying to work on immersions embeddings in the case of smooth manifolds, and one sentence I read in a book seemed to imply that an immersion $f:X \rightarrow Y$ (in the sense of smooth manifolds) is an embedding if and only if for every point $y$ in $Y$ there exist arbitrarily small open neighborhoods of $y$ in $Y$ such that $f^{-1}(U)$ is connected. Is that true?","I was trying to work on immersions embeddings in the case of smooth manifolds, and one sentence I read in a book seemed to imply that an immersion (in the sense of smooth manifolds) is an embedding if and only if for every point in there exist arbitrarily small open neighborhoods of in such that is connected. Is that true?",f:X \rightarrow Y y Y y Y f^{-1}(U),"['differential-geometry', 'differential-topology']"
80,Sphere with given tangent space,Sphere with given tangent space,,"Let $S^n$ be the unit $n$ -sphere equipped with its standard metric inherited from $\mathbb{R}^{n+1}$ , let $p \in S^n$ , and let $V \subset T_pS^n$ be an $m$ -dimensional subspace of the tangent space at $p$ , where $m < n$ . Is it possible to isometrically embed $S^m$ into $S^n$ so that $T_pS^m = V$ ? This seems like it should be true, especially if one considers the case $n=2$ and $m=1$ , since given a tangent of $S^2$ at $p$ , it is easy to find a great circle through $p$ with the same tangent. For the general case I was thinking of taking an orthonormal basis of $V$ , and somehow parametrizing an $m$ -sphere using it, but this seems like an overkill. Could someone give me a hint on how to see this?","Let be the unit -sphere equipped with its standard metric inherited from , let , and let be an -dimensional subspace of the tangent space at , where . Is it possible to isometrically embed into so that ? This seems like it should be true, especially if one considers the case and , since given a tangent of at , it is easy to find a great circle through with the same tangent. For the general case I was thinking of taking an orthonormal basis of , and somehow parametrizing an -sphere using it, but this seems like an overkill. Could someone give me a hint on how to see this?",S^n n \mathbb{R}^{n+1} p \in S^n V \subset T_pS^n m p m < n S^m S^n T_pS^m = V n=2 m=1 S^2 p p V m,"['differential-geometry', 'riemannian-geometry', 'spheres']"
81,Simple closed curves have the same trace if and only if they are equivalent,Simple closed curves have the same trace if and only if they are equivalent,,"I'm very stuck on Exercise 1.35 (4) in Kristopher Tapp's Differential Geometry of Curves and Surfaces which reads: Show that two parametrized simple closed curves have the same trace if and only if they are equivalent (that is, one is a reparametrization of the other). Note that this text defines curves to be smooth and closed curves to be regular. Further, it is meant to only have the prerequisites of multivariable calculus, linear algebra, and real analysis (not necessarily including multivariable content), does not introduce the idea of a diffeomorphism until talking about surfaces, and does not define the derivative of a curve as a linear function between tangent spaces (but rather as another curve, differeniated componentwise). I am looking for a solution that reflects this. The ""if"" direction is clear from the definitions, but I'm stuck on the ""only if"". I've tried doing it directly by supposing two simple closed curves $\boldsymbol\gamma: [a, b] \to \mathbb R^n$ and $\boldsymbol\beta: [c, d] \to \mathbb R^n$ have the same trace and constructing a bijection $\phi: [a, b] \to [c, d]$ such that $\boldsymbol\gamma = \boldsymbol\beta \circ \phi$ , but I get stuck trying to show that $\phi$ is smooth, let alone that its derivative is never zero and that its derivatives all match at $a$ and $b$ . Update: I've been reviewing the differential geometry exercises I was working on when I wrote this problem and made some progress, but I'm still not quite sure how to put everything together. Here's what I have so far. Let $\boldsymbol\gamma: [a, b] \to \mathbb R^n, \boldsymbol\beta: [c, d] \to \mathbb R^n$ be two parametrized simple closed curves with the same trace $\Gamma$ and components $\boldsymbol\gamma(t) = (\gamma_1(t), \ldots, \gamma_n(t)), \boldsymbol\beta(t) = (\beta_1(t), \ldots, \beta_n(t))$ , and assume without loss of generality that $\boldsymbol\gamma(a) = \boldsymbol\beta(c)$ . For every $s \in [c, d]$ , there is a $k(s) \in \{1, \ldots, n\}$ such that $\beta_{k(s)}'(s) \neq 0$ , and hence there are neighbourhoods $U_s$ of $s$ in $[c, d]$ and $V_s$ of $\beta_{k(s)}(s)$ in $\mathbb R$ such that $\beta_{k(s)}$ has a smooth local inverse $\psi_s: V_s \to U_s$ . I then want to define $\phi(t) = \psi_s(\gamma_{k(s)}(t))$ , where $\boldsymbol\beta(s) = \boldsymbol\gamma(t)$ , but I'm getting caught up in writing out the details showing that this is well-defined (and I'm not sure it is well-defined for $t \in \{a, b\}$ ). Once I have that, it is clear that (a) $\phi$ is smooth, (b) $\phi$ has nonzero derivative, and (c) all derivatives of $\phi$ match at $a$ and $b$ .","I'm very stuck on Exercise 1.35 (4) in Kristopher Tapp's Differential Geometry of Curves and Surfaces which reads: Show that two parametrized simple closed curves have the same trace if and only if they are equivalent (that is, one is a reparametrization of the other). Note that this text defines curves to be smooth and closed curves to be regular. Further, it is meant to only have the prerequisites of multivariable calculus, linear algebra, and real analysis (not necessarily including multivariable content), does not introduce the idea of a diffeomorphism until talking about surfaces, and does not define the derivative of a curve as a linear function between tangent spaces (but rather as another curve, differeniated componentwise). I am looking for a solution that reflects this. The ""if"" direction is clear from the definitions, but I'm stuck on the ""only if"". I've tried doing it directly by supposing two simple closed curves and have the same trace and constructing a bijection such that , but I get stuck trying to show that is smooth, let alone that its derivative is never zero and that its derivatives all match at and . Update: I've been reviewing the differential geometry exercises I was working on when I wrote this problem and made some progress, but I'm still not quite sure how to put everything together. Here's what I have so far. Let be two parametrized simple closed curves with the same trace and components , and assume without loss of generality that . For every , there is a such that , and hence there are neighbourhoods of in and of in such that has a smooth local inverse . I then want to define , where , but I'm getting caught up in writing out the details showing that this is well-defined (and I'm not sure it is well-defined for ). Once I have that, it is clear that (a) is smooth, (b) has nonzero derivative, and (c) all derivatives of match at and .","\boldsymbol\gamma: [a, b] \to \mathbb R^n \boldsymbol\beta: [c, d] \to \mathbb R^n \phi: [a, b] \to [c, d] \boldsymbol\gamma = \boldsymbol\beta \circ \phi \phi a b \boldsymbol\gamma: [a, b] \to \mathbb R^n, \boldsymbol\beta: [c, d] \to \mathbb R^n \Gamma \boldsymbol\gamma(t) = (\gamma_1(t), \ldots, \gamma_n(t)), \boldsymbol\beta(t) = (\beta_1(t), \ldots, \beta_n(t)) \boldsymbol\gamma(a) = \boldsymbol\beta(c) s \in [c, d] k(s) \in \{1, \ldots, n\} \beta_{k(s)}'(s) \neq 0 U_s s [c, d] V_s \beta_{k(s)}(s) \mathbb R \beta_{k(s)} \psi_s: V_s \to U_s \phi(t) = \psi_s(\gamma_{k(s)}(t)) \boldsymbol\beta(s) = \boldsymbol\gamma(t) t \in \{a, b\} \phi \phi \phi a b","['differential-geometry', 'curves', 'parametrization']"
82,why the curvature of a spiral in its origin is not infinity?,why the curvature of a spiral in its origin is not infinity?,,"It can be shown that the curvature of a spiral $\bf{r}(\rm t)=t(\cos t, \sin t)$ is given by \begin{eqnarray}     \kappa(t) = \frac{t^2 + 2}{(\sqrt{1+ t^2})^3} \end{eqnarray} Given that the radius at $t=0$ is $0$ , I would think that the curvature is infinity. Still $\lim_{t \to 0} \kappa(t) = 2$ .","It can be shown that the curvature of a spiral is given by Given that the radius at is , I would think that the curvature is infinity. Still .","\bf{r}(\rm t)=t(\cos t, \sin t) \begin{eqnarray}
    \kappa(t) = \frac{t^2 + 2}{(\sqrt{1+ t^2})^3}
\end{eqnarray} t=0 0 \lim_{t \to 0} \kappa(t) = 2","['calculus', 'differential-geometry']"
83,"Asymptotic curve with negative Gauss curvature, show $|\tau(P)|=\sqrt{-K(P)}$","Asymptotic curve with negative Gauss curvature, show",|\tau(P)|=\sqrt{-K(P)},"Suppose $K(P) < 0$ where $K(P)$ is the Gauss curvature at $P$ , where $K(P) = \det|S_p|$ , the determinant of the shape operator at $P$ . If $C$ is an asymptotic curve with $\kappa(P) \neq 0$ , prove that its torsion satisfies $|\tau(P)|=\sqrt{-K(P)}$ . Hint: If we choose an orthonormal basis $\{U,V\}$ for $T_p(M)$ with $U$ tangent to $C$ , what is the matrix for $S_p$ ? The answer to this hint is that the matrix for $S_p$ will be symmetric, and furthermore the matrix representation of the first fundamental form will be a scalar multiple of the identity matrix. Well, first of all, since $C$ is an asymptotic curve, we have $\kappa N \cdot n=0$ where $N$ is the unit normal vector of the curve and $n$ is the unit normal vector of the surface. I'm having trouble seeing the connection to torsion here, or how the fact that the matrix for $S_p$ is symmetric is going to be useful. Insights greatly appreciated!!","Suppose where is the Gauss curvature at , where , the determinant of the shape operator at . If is an asymptotic curve with , prove that its torsion satisfies . Hint: If we choose an orthonormal basis for with tangent to , what is the matrix for ? The answer to this hint is that the matrix for will be symmetric, and furthermore the matrix representation of the first fundamental form will be a scalar multiple of the identity matrix. Well, first of all, since is an asymptotic curve, we have where is the unit normal vector of the curve and is the unit normal vector of the surface. I'm having trouble seeing the connection to torsion here, or how the fact that the matrix for is symmetric is going to be useful. Insights greatly appreciated!!","K(P) < 0 K(P) P K(P) = \det|S_p| P C \kappa(P) \neq 0 |\tau(P)|=\sqrt{-K(P)} \{U,V\} T_p(M) U C S_p S_p C \kappa N \cdot n=0 N n S_p",[]
84,Embedded surface in simply connected manifold is two sided?,Embedded surface in simply connected manifold is two sided?,,"Suppose M is embedded surface(compact without boundary) in N^3 which is a simply connected three dimensional manifold, then why does M have to be two sided? Is there any example for this? I found a paper named ""orientability of hypersurface in $R^n$ "", but I  don't quite understand the short argument. Thanks for you help.","Suppose M is embedded surface(compact without boundary) in N^3 which is a simply connected three dimensional manifold, then why does M have to be two sided? Is there any example for this? I found a paper named ""orientability of hypersurface in "", but I  don't quite understand the short argument. Thanks for you help.",R^n,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
85,Uniqueness of geodesics that join two points in exponential neighbourhoods,Uniqueness of geodesics that join two points in exponential neighbourhoods,,"I'm currently working through some notes on surfaces in $\mathbb{R}^3$ and their geodesics, with the following definitions (it's kind of lengthy, I will highlight the key parts): For a sufficiently smooth surface $S$ parametrized by $\varphi  : D \to \mathbb{R}^3$ , a geodesic is a curve $\alpha : I \to S$ to have acceleration orthogonal to the tangent spaces, i.e. $\alpha$ is a geodesic if and only if $$ \alpha''(t) \perp T_{\alpha(t)}S \quad (\forall t \in I). $$ It is proven that fixing $p \in S$ and $v \in T_pS$ there is a unique geodesic $\gamma_{p,v} : I_{p,v} \to S$ such that $\gamma(0) = p$ and $\gamma'(0) = v$ , with $I_{p,v}$ the maximal interval of definition. That is, geodesics that stem from $p$ with velocity $v$ are (locally) unique, because two different ones give the same solution to an ODE in a sufficiently small interval of $p$ . It is also claimed that, since these curves and their definition intervals depend smoothly on $p$ and $v$ and $\gamma_{p,0}$ is defined on $\mathbb{R}$ , by continuity there exists some open ball $B_R(0_p) \subset T_pS$ where $1 \in I_{p,v}$ for $v \in B_R(0_p)$ . Hence it is possible to define the Riemannian exponential as $$ \begin{align} \exp_p : &B_R(0_p) \to S \\ & v \longmapsto \gamma_{p,v}(1)  \end{align} $$ Shortly after it is proved that $\exp_p$ sends lines through $0$ to geodesics , since $\gamma_{s,v}(t) = \gamma_{s,tv}(1)$ , and that $D(\exp_p)_0 = Id$ which says that in a neighbourhood of $0$ , the exponential is a diffeomorphism . We assume from now on that $R$ is small enough for this to hold. From the previous definitions and results, it is then claimed that one can see that if $q = \exp_p(v) \in \exp(B_R(0_p))$ then there is a unique geodesic that joins $p$ and $q$ , namely $$ \gamma(t) := \exp_p(tv) $$ with $[0,1] \subset Dom(\gamma)$ . I do not see why local uniqueness is derived just from the previous results. How can this be proven? I am aware that (given sufficient regularity hypotheses), any curve $\alpha \subset S$ in $\exp_p(B_R(0_p))$ is a lift $\alpha(t) = \exp_p(\beta(t))$ with $\beta$ a curve in $B_R(0_p)$ (that is, in it's identification with a ball of the plane) but I haven't been able to prove much with that. I also presume a strong usage of locality is needed, as for example in the sphere any two points there are two geodesics joining them.","I'm currently working through some notes on surfaces in and their geodesics, with the following definitions (it's kind of lengthy, I will highlight the key parts): For a sufficiently smooth surface parametrized by , a geodesic is a curve to have acceleration orthogonal to the tangent spaces, i.e. is a geodesic if and only if It is proven that fixing and there is a unique geodesic such that and , with the maximal interval of definition. That is, geodesics that stem from with velocity are (locally) unique, because two different ones give the same solution to an ODE in a sufficiently small interval of . It is also claimed that, since these curves and their definition intervals depend smoothly on and and is defined on , by continuity there exists some open ball where for . Hence it is possible to define the Riemannian exponential as Shortly after it is proved that sends lines through to geodesics , since , and that which says that in a neighbourhood of , the exponential is a diffeomorphism . We assume from now on that is small enough for this to hold. From the previous definitions and results, it is then claimed that one can see that if then there is a unique geodesic that joins and , namely with . I do not see why local uniqueness is derived just from the previous results. How can this be proven? I am aware that (given sufficient regularity hypotheses), any curve in is a lift with a curve in (that is, in it's identification with a ball of the plane) but I haven't been able to prove much with that. I also presume a strong usage of locality is needed, as for example in the sphere any two points there are two geodesics joining them.","\mathbb{R}^3 S \varphi  : D \to \mathbb{R}^3 \alpha : I \to S \alpha 
\alpha''(t) \perp T_{\alpha(t)}S \quad (\forall t \in I).
 p \in S v \in T_pS \gamma_{p,v} : I_{p,v} \to S \gamma(0) = p \gamma'(0) = v I_{p,v} p v p p v \gamma_{p,0} \mathbb{R} B_R(0_p) \subset T_pS 1 \in I_{p,v} v \in B_R(0_p) 
\begin{align}
\exp_p : &B_R(0_p) \to S \\
& v \longmapsto \gamma_{p,v}(1) 
\end{align}
 \exp_p 0 \gamma_{s,v}(t) = \gamma_{s,tv}(1) D(\exp_p)_0 = Id 0 R q = \exp_p(v) \in \exp(B_R(0_p)) p q 
\gamma(t) := \exp_p(tv)
 [0,1] \subset Dom(\gamma) \alpha \subset S \exp_p(B_R(0_p)) \alpha(t) = \exp_p(\beta(t)) \beta B_R(0_p)","['differential-geometry', 'surfaces', 'geodesic']"
86,Tangent vector field to a smooth curve over a smooth manifold,Tangent vector field to a smooth curve over a smooth manifold,,"I am teaching myself some elementary differential geometry and am stuck on the concept of the tangent vector field of a smooth curve. I have searched the web for an hour or so but cannot find anything pertaining specifically to my issue here. For a smooth curve $\gamma:(0,1)\rightarrow M$ , where $M$ is a manifold with a connection $\nabla$ , we can define the notion of autoparallel transport. We say the curve is autoparallely transported if $\nabla_{\dot{\gamma}}\dot{\gamma} = 0$ on the curve, where $\dot{\gamma}$ is the tangent vector field to $\gamma$ . My question is, how do we define this guy in terms of an element in the section of the tangent bundle? This is my initial guess, sort of with an abuse of notation: \begin{equation} \dot{\gamma}(\bullet) := \dot{\gamma}(\gamma(\bullet)) = \dot{\gamma}\circ \gamma : (0,1)\to TM ,\end{equation} which I think would make the latter $\dot{\gamma}\in\Gamma(TM)$ , i.e. a vector field sort of sending $M\lvert_{\gamma}\to TM$ . But something feels off, is this enough to be able to continue?","I am teaching myself some elementary differential geometry and am stuck on the concept of the tangent vector field of a smooth curve. I have searched the web for an hour or so but cannot find anything pertaining specifically to my issue here. For a smooth curve , where is a manifold with a connection , we can define the notion of autoparallel transport. We say the curve is autoparallely transported if on the curve, where is the tangent vector field to . My question is, how do we define this guy in terms of an element in the section of the tangent bundle? This is my initial guess, sort of with an abuse of notation: which I think would make the latter , i.e. a vector field sort of sending . But something feels off, is this enough to be able to continue?","\gamma:(0,1)\rightarrow M M \nabla \nabla_{\dot{\gamma}}\dot{\gamma} = 0 \dot{\gamma} \gamma \begin{equation} \dot{\gamma}(\bullet) := \dot{\gamma}(\gamma(\bullet)) = \dot{\gamma}\circ \gamma : (0,1)\to TM ,\end{equation} \dot{\gamma}\in\Gamma(TM) M\lvert_{\gamma}\to TM","['differential-geometry', 'vector-spaces', 'vectors', 'riemannian-geometry']"
87,Showing that the Cayley Transform is an involution.,Showing that the Cayley Transform is an involution.,,"For a finite dimensional vector space V the Cayley Transform is a function $T: Gl(V) \to End(V)$ such that $T(f) = (I-f)(I+f)^{-1}$ . I am asked to show that the Cayley Transformation is an involution, which means that $T(T(f)) = f$ . I tried to do this by evaluating the function and I get that $T(T(f)) = (I-(I-f)(1+f)^{-1})(I+(I-f)(I+f)^{-1})^{-1}$ , I don't really know what to do from here.","For a finite dimensional vector space V the Cayley Transform is a function such that . I am asked to show that the Cayley Transformation is an involution, which means that . I tried to do this by evaluating the function and I get that , I don't really know what to do from here.",T: Gl(V) \to End(V) T(f) = (I-f)(I+f)^{-1} T(T(f)) = f T(T(f)) = (I-(I-f)(1+f)^{-1})(I+(I-f)(I+f)^{-1})^{-1},"['linear-algebra', 'differential-geometry']"
88,Defining a pseudo-gradient field for a $1$-form,Defining a pseudo-gradient field for a -form,1,"I'm reading Audin and Damian's Morse Theory and Floer Homology ; they say there is an analogous way to define nondegenerate critical points for 1-forms as well as pseudo-gradient fields but don't discuss how. The goal is to define such a vector field for a 1-form $\alpha$ and then lift it to a pseudo-gradient field for a function on a covering space. Here's the context. Suppose I have a smooth closed 1-form $\alpha$ on a manifold $M$ . If I consider a map $\phi:\pi_1(M) \to \mathbb{R}$ which is simply integrating $\alpha$ along a loop in $M$ , then it is in fact a homomorphism. I can then consider $\ker \phi \subset \pi_1(M)$ and find a smooth covering space $p: \hat{M} \to M$ such that $p_*(\pi_1(\hat{M}))=\ker \phi$ . This means that for all loops $\hat{\gamma} \in \pi_1(\hat{M})$ , $$\int_{\hat{\gamma}}p^* \alpha = 0 $$ by construction. Thus, $p^* \alpha$ is exact ( $= df$ ) for some function $f$ . We also observe that $(df)_y = 0 \Leftrightarrow \alpha_{p(y)}=0$ . Thus, they say that $f$ and $p^* \alpha$ share the same critical points which themselves share properties such as nondegeneracy and index. It seems a critical point for $\alpha$ is simply where it vanishes. My questions: How are the notions of critical points, nondegeneracy, and pseudogradients defined for a 1-form? Can this be done for $k$ -forms? This paper by Latour is referenced but I can't read French: http://www.numdam.org/article/PMIHES_1994__80__135_0.pdf","I'm reading Audin and Damian's Morse Theory and Floer Homology ; they say there is an analogous way to define nondegenerate critical points for 1-forms as well as pseudo-gradient fields but don't discuss how. The goal is to define such a vector field for a 1-form and then lift it to a pseudo-gradient field for a function on a covering space. Here's the context. Suppose I have a smooth closed 1-form on a manifold . If I consider a map which is simply integrating along a loop in , then it is in fact a homomorphism. I can then consider and find a smooth covering space such that . This means that for all loops , by construction. Thus, is exact ( ) for some function . We also observe that . Thus, they say that and share the same critical points which themselves share properties such as nondegeneracy and index. It seems a critical point for is simply where it vanishes. My questions: How are the notions of critical points, nondegeneracy, and pseudogradients defined for a 1-form? Can this be done for -forms? This paper by Latour is referenced but I can't read French: http://www.numdam.org/article/PMIHES_1994__80__135_0.pdf","\alpha \alpha M \phi:\pi_1(M) \to \mathbb{R} \alpha M \ker \phi \subset \pi_1(M) p: \hat{M} \to M p_*(\pi_1(\hat{M}))=\ker \phi \hat{\gamma} \in \pi_1(\hat{M}) \int_{\hat{\gamma}}p^* \alpha = 0
 p^* \alpha = df f (df)_y = 0 \Leftrightarrow \alpha_{p(y)}=0 f p^* \alpha \alpha k","['differential-geometry', 'morse-theory']"
89,"Given a differential form $\omega$, is there a differential form $\phi$ such that $\omega\wedge\phi$ is closed?","Given a differential form , is there a differential form  such that  is closed?",\omega \phi \omega\wedge\phi,"Let $M$ be a differential manifold and $\Omega^p(M)$ the vector bundle of $p$ -forms. My question is: Given a differential $p$ -form $\omega$ , is there a differential $q$ -form $\phi$ such that $d(\omega\wedge\phi)=0$ ? I am excluding the trivial cases when $\omega$ is already closed or when $(q+p)$ is larger or equal to the dimension of the cotangent space at a point. My question is a generalization of the integrating factor problem, where $\omega$ is a 1-form, $\phi$ is a function and $d(f\omega)$ should be exact and not only closed as I am requiring. In this question about the existence of integrating factor for 1-forms in two variables the answers say that the problem is difficult and still open, even in this simpler case. I was unable to find any reference who could be of some help in answer my question, then I would really appreciate if someone can give me some directions in the literature and, if possible, discuss some special cases where a solution is or is not possible.","Let be a differential manifold and the vector bundle of -forms. My question is: Given a differential -form , is there a differential -form such that ? I am excluding the trivial cases when is already closed or when is larger or equal to the dimension of the cotangent space at a point. My question is a generalization of the integrating factor problem, where is a 1-form, is a function and should be exact and not only closed as I am requiring. In this question about the existence of integrating factor for 1-forms in two variables the answers say that the problem is difficult and still open, even in this simpler case. I was unable to find any reference who could be of some help in answer my question, then I would really appreciate if someone can give me some directions in the literature and, if possible, discuss some special cases where a solution is or is not possible.",M \Omega^p(M) p p \omega q \phi d(\omega\wedge\phi)=0 \omega (q+p) \omega \phi d(f\omega),"['differential-geometry', 'smooth-manifolds', 'closed-form', 'vector-bundles', 'exterior-derivative']"
90,Isotropy group of connection is isomorphic to centraliser of holonomy group,Isotropy group of connection is isomorphic to centraliser of holonomy group,,"I am asking for a proof of Lemma (4.2.8) of Donaldson, Kronheimer: The Geometry of Four-Manifolds . Let $P \rightarrow X$ be a principal bundle with structure group $G$ . Denote by $\mathcal{G}$ the gauge group. Let $A$ be a connection on $P$ and $H_A \subset G$ its holonomy. Denote by $$ \Gamma_A= \{u \in \mathcal{G} | u(A)=A \} $$ the isotropy group of $A$ in $\mathcal{G}$ . Then the claim of the lemma is: For any connection $A$ over a connected base $X$ , $\Gamma_A$ is isomorphic to the centraliser of $H_A$ in $G$ . My attempt to prove it: Now if the bundle was trivial, i.e. $P=X \times G$ , we could take $g \in G$ in the centraliser of $H_A$ and get a unique element $u_g \in \mathcal{G}$ satisfying $u_g(x,e)=(x,g)$ . If the connection $A$ is the trivial connection then it is easy to check that this satisfies $u_g \in \Gamma_A$ . In matrix notation we have $u(A)=u^{-1}Au+u^{-1} du$ . Plugging in an $A$ -horizontal vector field to this formula shows that any $u \in \Gamma_A$ needs to be constant on $X \times \{e\}$ , i.e. $u=u_g$ for some $g \in G$ . Plugging in a vertical vector field shows that $g$ must be in the centraliser of $H_A$ in $G$ , because $u^{-1} du$ vanishes on vertical vector fields. I believe I can make this argument work for non-trivial connections $A$ . But no matter if I can or cannot: all of this assumed that the bundle was trivial. If the bundle isn't trivial I don't even know how to write down a map from the centraliser of $H_A$ to $\Gamma_A$ .","I am asking for a proof of Lemma (4.2.8) of Donaldson, Kronheimer: The Geometry of Four-Manifolds . Let be a principal bundle with structure group . Denote by the gauge group. Let be a connection on and its holonomy. Denote by the isotropy group of in . Then the claim of the lemma is: For any connection over a connected base , is isomorphic to the centraliser of in . My attempt to prove it: Now if the bundle was trivial, i.e. , we could take in the centraliser of and get a unique element satisfying . If the connection is the trivial connection then it is easy to check that this satisfies . In matrix notation we have . Plugging in an -horizontal vector field to this formula shows that any needs to be constant on , i.e. for some . Plugging in a vertical vector field shows that must be in the centraliser of in , because vanishes on vertical vector fields. I believe I can make this argument work for non-trivial connections . But no matter if I can or cannot: all of this assumed that the bundle was trivial. If the bundle isn't trivial I don't even know how to write down a map from the centraliser of to .","P \rightarrow X G \mathcal{G} A P H_A \subset G 
\Gamma_A=
\{u \in \mathcal{G} | u(A)=A \}
 A \mathcal{G} A X \Gamma_A H_A G P=X \times G g \in G H_A u_g \in \mathcal{G} u_g(x,e)=(x,g) A u_g \in \Gamma_A u(A)=u^{-1}Au+u^{-1} du A u \in \Gamma_A X \times \{e\} u=u_g g \in G g H_A G u^{-1} du A H_A \Gamma_A","['differential-geometry', 'principal-bundles', 'gauge-theory']"
91,Group of orientation preserving homeomorphisms of circle $S^1$ acts transitively on the set of closed intervals of $S^1.$,Group of orientation preserving homeomorphisms of circle  acts transitively on the set of closed intervals of,S^1 S^1.,"The closed intervals here mean the arcs including endpoints on the circle. I tried to do it by taking the inverse image of those two closed intervals from $S^1$ to its covering space $\mathbb{R}$ and then constructed a homeomorphism of $\mathbb{R}$ that takes these closed intervals to each other. But the issue is that while projecting it back to $S^1$ , I am unable to ensure that this will result in a homeomorphism. Any other approach is also welcome.","The closed intervals here mean the arcs including endpoints on the circle. I tried to do it by taking the inverse image of those two closed intervals from to its covering space and then constructed a homeomorphism of that takes these closed intervals to each other. But the issue is that while projecting it back to , I am unable to ensure that this will result in a homeomorphism. Any other approach is also welcome.",S^1 \mathbb{R} \mathbb{R} S^1,"['general-topology', 'differential-geometry', 'geometric-topology']"
92,First de Rham Cohomology group of the 2-torus,First de Rham Cohomology group of the 2-torus,,"Show that for the de Rham cohomology, $H^{1}_{dR}({T^{2}})$ is isomorphic to $\mathbb{R}^{2}$ by showing that the following map: $[\alpha] \to (\int_{S^{1}}f^{*}_{1}\alpha,\int_{S^{1}}f^{*}_{1}\alpha)$ , where $f_{1}=(\theta,c_{1}), f_{2}=(c_{2},\theta)$ for $c_{1},c_{2}$ constants (seen as maps $S^{1} \to S^{1} \times S^{1}$ )  is an isomorphism. I have shown that the map is well-defined, linear and independent of the constants chosen. However, I'm having trouble with showing that it is surjective and injective. Surjectivity seems to be easy to show, but I'm not sure on how to go about it. For injectivity, it suffices to show that if the integrals are $0$ , then $\alpha$ is an exact form, yet I'm having troubles with it as well. What would be a good way to tackle this problem?","Show that for the de Rham cohomology, is isomorphic to by showing that the following map: , where for constants (seen as maps )  is an isomorphism. I have shown that the map is well-defined, linear and independent of the constants chosen. However, I'm having trouble with showing that it is surjective and injective. Surjectivity seems to be easy to show, but I'm not sure on how to go about it. For injectivity, it suffices to show that if the integrals are , then is an exact form, yet I'm having troubles with it as well. What would be a good way to tackle this problem?","H^{1}_{dR}({T^{2}}) \mathbb{R}^{2} [\alpha] \to (\int_{S^{1}}f^{*}_{1}\alpha,\int_{S^{1}}f^{*}_{1}\alpha) f_{1}=(\theta,c_{1}), f_{2}=(c_{2},\theta) c_{1},c_{2} S^{1} \to S^{1} \times S^{1} 0 \alpha","['differential-geometry', 'algebraic-topology', 'smooth-manifolds', 'differential-forms']"
93,Why does this vector field approach zero near the north pole?,Why does this vector field approach zero near the north pole?,,"In this question, Raziel's answer builds a vector field over $S^2$ . The vector field is built from the push forward of the stereographic projection on $N$ . Let $p \in S^2 \setminus \{N\}$ , and let's say that $X_p = U_p \partial_u + V_p \partial_v$ . I understant that as $p$ approaches the north pole, by the change of coordinates given in the other post, it can be seen that $X_p$ approaches zero (and thus can be extended at $N$ with zero). However, I don't understand it at an intuitive level. (I want to understand why this happens.) If we fix $f \in C^{\infty}(S^2)$ , should I understand that $X_p f$ approaches zero as $p \to N$ because you are deriving $f$ respect to a larger vector, or is that nonsense? I think that expressing $X_p$ in function of $\partial_x$ and $\partial_y$ would help me, but I'm not sure how to compute that.","In this question, Raziel's answer builds a vector field over . The vector field is built from the push forward of the stereographic projection on . Let , and let's say that . I understant that as approaches the north pole, by the change of coordinates given in the other post, it can be seen that approaches zero (and thus can be extended at with zero). However, I don't understand it at an intuitive level. (I want to understand why this happens.) If we fix , should I understand that approaches zero as because you are deriving respect to a larger vector, or is that nonsense? I think that expressing in function of and would help me, but I'm not sure how to compute that.",S^2 N p \in S^2 \setminus \{N\} X_p = U_p \partial_u + V_p \partial_v p X_p N f \in C^{\infty}(S^2) X_p f p \to N f X_p \partial_x \partial_y,"['differential-geometry', 'manifolds', 'vector-fields', 'spheres']"
94,the line with two origins and the related equivalence relation,the line with two origins and the related equivalence relation,,"I'm trying to prove that the line with two origin is not Hausdorff but I'm having trouble understanding the problem statement. $\textbf{I'm not asking for a solution}$ , I just need a clarification of what the problem means. Here is the problem: (Problem 3-16 from LeeTM): Let $X$ be the subset $(\mathbb{R} \times \{0\}) \cup (\mathbb{R} \times \{1\}) \subseteq \mathbb{R}^2$ . Define an equivalence relation on $X$ by declaring $(x,0) \sim (x,1)$ if $x \neq 0$ . Show that the quotient space $X/ \sim$ is locally Euclidean and second countable, but not Hausdorff. where LeeTM:=Introduction to Topological Manifolds by John Lee. $\textbf{My question:}$ what does ""declaring $(x,0) \sim (x,1)$ if $x \neq 0$ "" mean? I have two guesses. (Guess 1) Let $(x_1,y_1),(x_2,y_2) \in X$ , we say $(x_1,y_1) \sim (x_2,y_2)$ if and only if $x_1,x_2$ are non-zero with $x_1=x_2$ and $\{y_1,y_2\}=\{0,1\}$ But if this is what he meant, then the equivalence class of $(0,0) \in X$ is the empty set because its $x$ -coordinate is zero : no point in $X$ can have the same non-zero $x$ -coordinate as $(0,0)$ . However, equivalence classes can't be the empty set because of the reflexivity. Therefore, I had a second guess (Guess 2) $(x_1,y_1) \sim (x_2,y_2)$ if and only if $x_1=x_2$ and $\{y_1,y_2\}=\{0,1\}$ . In this case, we have $$(0,0) \notin [(0,0)] = \{(0,1)\} $$ which contradicts the reflexivity of equivalence relation. So my second guess is also wrong. $\textbf{What does he mean really? what is the equivalence relation he's trying to define?}$ In example 3.48 of LeeTM, he used the similar wording: "" let $\sim$ be the equivalence relation on $\bar{\mathbb{B}}^2$ ( the closed unit disk in $\mathbb{R}^2$ ) generated by $(x,y) \sim (x,-y)$ for all $(x,y) \in \partial \mathbb{B}^2$ "". He defined the equivalence relation for the points on the boundary but what about those on the interior? (Likewise, in problem 3-16, he defined the equivalence relation for $x \neq 0$ but what about $x=0$ ?) He uses this ""description"" more than one time so I think it may be a terminology that everyone knows (except me). $\textbf{Can someone explain to me what does this wording/description of equivalence relation mean?}$","I'm trying to prove that the line with two origin is not Hausdorff but I'm having trouble understanding the problem statement. , I just need a clarification of what the problem means. Here is the problem: (Problem 3-16 from LeeTM): Let be the subset . Define an equivalence relation on by declaring if . Show that the quotient space is locally Euclidean and second countable, but not Hausdorff. where LeeTM:=Introduction to Topological Manifolds by John Lee. what does ""declaring if "" mean? I have two guesses. (Guess 1) Let , we say if and only if are non-zero with and But if this is what he meant, then the equivalence class of is the empty set because its -coordinate is zero : no point in can have the same non-zero -coordinate as . However, equivalence classes can't be the empty set because of the reflexivity. Therefore, I had a second guess (Guess 2) if and only if and . In this case, we have which contradicts the reflexivity of equivalence relation. So my second guess is also wrong. In example 3.48 of LeeTM, he used the similar wording: "" let be the equivalence relation on ( the closed unit disk in ) generated by for all "". He defined the equivalence relation for the points on the boundary but what about those on the interior? (Likewise, in problem 3-16, he defined the equivalence relation for but what about ?) He uses this ""description"" more than one time so I think it may be a terminology that everyone knows (except me).","\textbf{I'm not asking for a solution} X (\mathbb{R} \times \{0\}) \cup (\mathbb{R} \times \{1\}) \subseteq \mathbb{R}^2 X (x,0) \sim (x,1) x \neq 0 X/ \sim \textbf{My question:} (x,0) \sim (x,1) x \neq 0 (x_1,y_1),(x_2,y_2) \in X (x_1,y_1) \sim (x_2,y_2) x_1,x_2 x_1=x_2 \{y_1,y_2\}=\{0,1\} (0,0) \in X x X x (0,0) (x_1,y_1) \sim (x_2,y_2) x_1=x_2 \{y_1,y_2\}=\{0,1\} (0,0) \notin [(0,0)] = \{(0,1)\}  \textbf{What does he mean really? what is the equivalence relation he's trying to define?} \sim \bar{\mathbb{B}}^2 \mathbb{R}^2 (x,y) \sim (x,-y) (x,y) \in \partial \mathbb{B}^2 x \neq 0 x=0 \textbf{Can someone explain to me what does this wording/description of equivalence relation mean?}","['general-topology', 'differential-geometry', 'equivalence-relations']"
95,Infinitesimal generator of a smooth $S^1$-action over $\mathbb C$,Infinitesimal generator of a smooth -action over,S^1 \mathbb C,"Question : Consider the symplectic manifold $(\mathbb C, \omega_0 = \frac{i}{2} {\rm d}z \wedge {\rm d}\bar z)$ and a smooth $\Bbb S^1$ -action over $\mathbb C$ given by $$(t,z) \mapsto t^kz$$ for some fixed $k \in \mathbb Z$ , with moment map $\mu: \mathbb C \to \frak {g}^* \cong i\mathbb R$ given by $$\mu (z) = -\frac{i}{2}k|z|^2$$ What is the infinitesimal generator of this action $(X^\#)_{z_0} = \displaystyle \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0$ ? Attempt: I tried to use polar coordinates $z = r e^{i\theta}$ . Then the symplectic 2-form is $\omega_0 = r {\rm d}r \wedge {\rm d}\theta$ and the moment map should be $$\mu (re^{i\theta}) = -\frac{i}{2}kr^2$$ if we consider the global flow $\exp : \mathfrak g = \text{Lie} (S^1) \cong i\mathbb R \to S^1$ , $\exp (is) = e^{is}$ then $$\begin{align}(X^\#)_{z_0} &= \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0 = \frac{d}{dt}\bigg|_{t=0} e^{its}\cdot z_0 \\&= \frac{d}{dt}\bigg|_{t=0} e^{itks} z_0 = iksz_0 \\&= iksr_0 e^{i\theta_0} = -ksr_0 \sin \theta_0 + i ksr_0 \cos \theta_0\end{align}$$ I can't see how this is a vector field written in coordinates $\frac{\partial}{\partial r}$ and $\frac{\partial}{\partial \theta}$ . Any help?","Question : Consider the symplectic manifold and a smooth -action over given by for some fixed , with moment map given by What is the infinitesimal generator of this action ? Attempt: I tried to use polar coordinates . Then the symplectic 2-form is and the moment map should be if we consider the global flow , then I can't see how this is a vector field written in coordinates and . Any help?","(\mathbb C, \omega_0 = \frac{i}{2} {\rm d}z \wedge {\rm d}\bar z) \Bbb S^1 \mathbb C (t,z) \mapsto t^kz k \in \mathbb Z \mu: \mathbb C \to \frak {g}^* \cong i\mathbb R \mu (z) = -\frac{i}{2}k|z|^2 (X^\#)_{z_0} = \displaystyle \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0 z = r e^{i\theta} \omega_0 = r {\rm d}r \wedge {\rm d}\theta \mu (re^{i\theta}) = -\frac{i}{2}kr^2 \exp : \mathfrak g = \text{Lie} (S^1) \cong i\mathbb R \to S^1 \exp (is) = e^{is} \begin{align}(X^\#)_{z_0} &= \frac{d}{dt}\bigg|_{t=0} \exp(tX)\cdot z_0 = \frac{d}{dt}\bigg|_{t=0} e^{its}\cdot z_0 \\&= \frac{d}{dt}\bigg|_{t=0} e^{itks} z_0 = iksz_0 \\&= iksr_0 e^{i\theta_0} = -ksr_0 \sin \theta_0 + i ksr_0 \cos \theta_0\end{align} \frac{\partial}{\partial r} \frac{\partial}{\partial \theta}","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'symplectic-geometry']"
96,Horizontal Subbundles and Connection Maps,Horizontal Subbundles and Connection Maps,,"I'm trying to see the equivalence between the Ehresmann connection and the connection map, and having trouble getting the setup to be correct. Suppose $M$ is a smooth manifold.  Let $\pi:TM\to M$ denote tangent bundle, with differential $d\pi:TTM\to TM$ .  Then one has the canonical vertical subbundle $V=\ker{d\pi}$ . A horizontal subbundle $H$ is any subbundle which is complementary to $V$ , that is, $TTM=H\oplus V$ .  Such an $H$ is equivalent to the existence of some $(0,2)$ -tensor $\sigma$ on $TM$ ( $\sigma:TTM\to TTM$ ) such that $\sigma^2=\sigma$ and $\sigma(TTM)=V$ , and then letting $H=\ker{\sigma}$ . However, if $(M,g)$ is Riemannian with Levi-Civita connection $\nabla$ , from what I've found in the literature, one typically defines a connection map $K:TTM\to TM$ by taking some $(\theta,\xi)\in TTM$ , letting $\gamma(t)=(\alpha(t),\beta(t))\in TM$ with $\gamma(0)=\theta$ , $\gamma'(0)=\xi$ and giving $$(\theta,\xi)\mapsto K_\theta(\xi)=\left(\nabla_{\alpha'(t)}\beta(t)\right)_{t=0}.$$ Then you define $H=\ker{K}$ . What's the correlation between $\sigma$ and $K$ ? Also, if anyone has any references on the above that would be helpful.  I seem to have only found a small section Sakai's Riemannian Geometry text, and a bit more in-depth section in Paternain's Geodesic Flows text.  My interest in the topic is geared towards understanding the Sasakian metric on $TM$ better.","I'm trying to see the equivalence between the Ehresmann connection and the connection map, and having trouble getting the setup to be correct. Suppose is a smooth manifold.  Let denote tangent bundle, with differential .  Then one has the canonical vertical subbundle . A horizontal subbundle is any subbundle which is complementary to , that is, .  Such an is equivalent to the existence of some -tensor on ( ) such that and , and then letting . However, if is Riemannian with Levi-Civita connection , from what I've found in the literature, one typically defines a connection map by taking some , letting with , and giving Then you define . What's the correlation between and ? Also, if anyone has any references on the above that would be helpful.  I seem to have only found a small section Sakai's Riemannian Geometry text, and a bit more in-depth section in Paternain's Geodesic Flows text.  My interest in the topic is geared towards understanding the Sasakian metric on better.","M \pi:TM\to M d\pi:TTM\to TM V=\ker{d\pi} H V TTM=H\oplus V H (0,2) \sigma TM \sigma:TTM\to TTM \sigma^2=\sigma \sigma(TTM)=V H=\ker{\sigma} (M,g) \nabla K:TTM\to TM (\theta,\xi)\in TTM \gamma(t)=(\alpha(t),\beta(t))\in TM \gamma(0)=\theta \gamma'(0)=\xi (\theta,\xi)\mapsto K_\theta(\xi)=\left(\nabla_{\alpha'(t)}\beta(t)\right)_{t=0}. H=\ker{K} \sigma K TM","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'vector-bundles', 'connections']"
97,Prove curvature of sphere curve $\geq R^{-1}$,Prove curvature of sphere curve,\geq R^{-1},"Let $\bf x(s)$ be a sphere curve lying on the surface of a sphere with center $\bf{p}$ and radius $R$ satisfying $$|\bf{x}(s)-p|^2=R^2.$$ I want to prove that the curvature $\kappa \geq R^{-1}$ . I assumed the center is the origin as this does not affect the curvature. Differentiating I have \begin{equation}  \bf x'\cdot x=0, x''\cdot x=0. \end{equation} I know I need to invoke the structure equations and that $\bf T,N,B$ form an orthonormal basis. I tried to write $$\bf x=\lambda T+\mu N+\nu. $$ Using the structure equations and $T=x'$ I found $$\mu'-\mu\kappa=1,\mu'-v\tau+\mu\kappa=0,v'=-\mu\tau$$ Using $\bf x' \cdot x=0$ I got $\bf\lambda^2+\mu^2+\nu^2=R^2$ and $\bf \lambda'\lambda+\mu\mu'+\nu\nu'=0$ . So I want to establish $$\kappa^2\geq \frac{1}{\lambda^2+\mu^2+\nu^2}.$$ I have some relations between $\kappa,\tau,\lambda,\mu$ and $\nu$ and I get more if I look at $\bf x''\cdot x=0$ . However, the equations become very long and I'm not sure how to show the inequality. Do I have the right approach?","Let be a sphere curve lying on the surface of a sphere with center and radius satisfying I want to prove that the curvature . I assumed the center is the origin as this does not affect the curvature. Differentiating I have I know I need to invoke the structure equations and that form an orthonormal basis. I tried to write Using the structure equations and I found Using I got and . So I want to establish I have some relations between and and I get more if I look at . However, the equations become very long and I'm not sure how to show the inequality. Do I have the right approach?","\bf x(s) \bf{p} R |\bf{x}(s)-p|^2=R^2. \kappa \geq R^{-1} \begin{equation}  \bf x'\cdot x=0, x''\cdot x=0. \end{equation} \bf T,N,B \bf x=\lambda T+\mu N+\nu.  T=x' \mu'-\mu\kappa=1,\mu'-v\tau+\mu\kappa=0,v'=-\mu\tau \bf x' \cdot x=0 \bf\lambda^2+\mu^2+\nu^2=R^2 \bf \lambda'\lambda+\mu\mu'+\nu\nu'=0 \kappa^2\geq \frac{1}{\lambda^2+\mu^2+\nu^2}. \kappa,\tau,\lambda,\mu \nu \bf x''\cdot x=0",['differential-geometry']
98,First generalization of the inverse function theorem Q.10 section 1.3 in Allan Pollack and Guillemin(1).,First generalization of the inverse function theorem Q.10 section 1.3 in Allan Pollack and Guillemin(1).,,"Part of Q.10 section 1.3 in  Allan Pollack and Guillemin is the following: ""Generalization of the inverse function theorem.let $f:X \rightarrow Y$ be a smooth map that is 1-1 on a compact submanifold Z of X. Suppose that for all $x \in Z$ , $$df_{x}: T_{x}(X) \rightarrow T_{f(x)}(Y) ,$$ is an isomorphism. then $f$ maps $Z$ diffeomorphically onto $f(Z)$ . why?"" The inverse function theorem that is stated in Allan Pollack differential Topology before this question is: Suppose that $f:X \rightarrow Y$ is a smooth map whose derivative $df_{x}$ at the point $x$ is an isomorphism. Then $f$ is a local diffeomorphism at $x$ . Does the answer is ""by the inverse function theorm""? am I correct?","Part of Q.10 section 1.3 in  Allan Pollack and Guillemin is the following: ""Generalization of the inverse function theorem.let be a smooth map that is 1-1 on a compact submanifold Z of X. Suppose that for all , is an isomorphism. then maps diffeomorphically onto . why?"" The inverse function theorem that is stated in Allan Pollack differential Topology before this question is: Suppose that is a smooth map whose derivative at the point is an isomorphism. Then is a local diffeomorphism at . Does the answer is ""by the inverse function theorm""? am I correct?","f:X \rightarrow Y x \in Z df_{x}: T_{x}(X) \rightarrow T_{f(x)}(Y) , f Z f(Z) f:X \rightarrow Y df_{x} x f x","['general-topology', 'differential-geometry', 'differential-topology']"
99,Curvature of a curve projected on its osculator plan,Curvature of a curve projected on its osculator plan,,"I have to prove that for any regular curve in $\mathbb{R^3}$ it's curvature $k(t)$ is the same as the curvature of its projection on the osculator plane at $t$ Basically what i did was writting on the canonical local form, and projecting on the First two coordinates, deriving twice and taking the norm, but it lead me nowhere I get $\sqrt{({ks^2})^2+(k+sk')^2}$ if i dont carry the aproximation errors.","I have to prove that for any regular curve in $\mathbb{R^3}$ it's curvature $k(t)$ is the same as the curvature of its projection on the osculator plane at $t$ Basically what i did was writting on the canonical local form, and projecting on the First two coordinates, deriving twice and taking the norm, but it lead me nowhere I get $\sqrt{({ks^2})^2+(k+sk')^2}$ if i dont carry the aproximation errors.",,"['differential-geometry', 'curves', 'curvature']"
