,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is there a hypergeometric function form of the quadratic formula that converges for all a,b,c?","Is there a hypergeometric function form of the quadratic formula that converges for all a,b,c?",,"After reading this question about a general formula for roots, I was curious about the simple case of $N=2$ . As is well known to school children, if $ ax^2 + bx + c = 0 $ , then the roots are $ \frac{-b \pm \sqrt{b^2-4ac}}{2a} $ Shuffling the binomial series around yields $$  -\frac{c}{b} \sum_{k=0}^{\infty} \binom{-\frac{1}{2}+k}{k} \left( \frac{4ac}{b^2} \right)^k \frac{1}{(k+1)} = -\frac{b}{2a} +  \frac{ \sqrt{b^2-4ac}}{2a} $$ but this doesn't converge for simple cases such as $ a=1,b=1,c=-1 $ since the radius of convergence is $<\frac{1}{4}$ . Is there a hypergeometric series that converges for all $a,b,c$ (where there are roots of course)?","After reading this question about a general formula for roots, I was curious about the simple case of . As is well known to school children, if , then the roots are Shuffling the binomial series around yields but this doesn't converge for simple cases such as since the radius of convergence is . Is there a hypergeometric series that converges for all (where there are roots of course)?","N=2  ax^2 + bx + c = 0   \frac{-b \pm \sqrt{b^2-4ac}}{2a}    -\frac{c}{b} \sum_{k=0}^{\infty} \binom{-\frac{1}{2}+k}{k} \left( \frac{4ac}{b^2} \right)^k \frac{1}{(k+1)} = -\frac{b}{2a} +  \frac{ \sqrt{b^2-4ac}}{2a}   a=1,b=1,c=-1  <\frac{1}{4} a,b,c","['sequences-and-series', 'algebra-precalculus', 'roots']"
1,"How do we prove that the simple continued fraction for $e^{2/n}=[1;\frac{n-1}{2},6n,\frac{5n-1}{2},1,1,...]$?",How do we prove that the simple continued fraction for ?,"e^{2/n}=[1;\frac{n-1}{2},6n,\frac{5n-1}{2},1,1,...]","Motivation: remarkably, the simple continued fraction - which is unique - for $e^{1/n},e^{2/n}$ is known for every $n\in\Bbb N$ . The expansions for $e^{3/n}$ , or even $e^{p/q}$ , are not known in general, and it is a strange miracle that we can figure out any of them at all... Euler first derived the continued fraction for $e$ and $e^{1/n}$ . The expansion for $e^{2/n}$ is viewable on the web, but I have not been able to find a proof of this beautiful fact. This original text from Euler proves that, for real $s$ : $$\begin{align}\tag{1}e^{2/s}&=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s+}\cdots\\e^{1/s}&=1+\frac{1}{s-1+}\frac{1}{1+}\frac{1}{1+}\frac{1}{3s-1+}\cdots\end{align}$$ It derives the expansion for $e^{1/s}$ from that for $e^{2/s}$ by means of his ""interpolation"" formulae: $$\begin{align}a+\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\frac{1}{m+}\frac{1}{n+}\frac{1}{c+}\cdots&=\frac{1}{mn+1}\left((mn+1)a+n+\frac{1}{(mn+1)b+m+n+}\frac{1}{(mn+1)c+m+n+}\cdots\right)\\A+\frac{1}{a+}\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\cdots&=A+\frac{mn+1}{(mn+1)a+n+}\frac{1}{(mn+1)b+m+n+}\cdots\\a+\frac{1}{b+}\frac{1}{c+}\cdots&=a-n+\frac{mn+1}{m+}\frac{1}{n+}\frac{1}{\frac{b-m-n}{mn+1}+}\frac{1}{m+}\frac{1}{n+}\frac{1}{\frac{c-m-n}{mn+1}+}\cdots\end{align}$$ Which all have nice special cases for $m=n=1$ . Wikipedia claims that in fact: $$\tag{$\ast$}e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{6s+}\frac{1}{\frac{5s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{7s-1}{2}+}\frac{1}{18s+}\frac{1}{\frac{11s-1}{2}+}\frac{1}{1+}\cdots$$ Which I'd like to understand. First note that, by equivalence transformation (multiply by $2,1/2,2,1/2,\cdots$ ) the a first try might be to convert $(\ast)$ into: $$e^{2/s}=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s-1+}\frac{1}{\frac{1}{2}+}\frac{1}{2+}\frac{1}{\frac{7s-1}{4}+}\cdots$$ Which unfortunately doesn't work out. Also, although two $1s$ have clearly been interpolated somehow to get $(\ast)$ , we can't directly employ any of the standard results shown above, since, instead of $a,1,1,b,1,1,...$ it is of the form $a,b,c,1,1,d,e,f,1,1,...$ . If we try to realise $(1)$ as an interpolation, using the middle formula, we need to solve $2a+1=s-1\implies a=\frac{s-1}{2}$ , $2b+2=3s\implies b=\frac{3s-2}{2}$ , etc., to get: $$e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{3s-2}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{5s-2}{2}+}\cdots$$ Which seems better, but is still not quite right. I'm convinced the answer is going to be a simple transformation: the denominators of $(\ast)$ are of the form $\frac{x-1}{2},2x$ for $x$ the denominator in $(1)$ . The presence of a $2$ -multiplier and a $1/2$ -multiplier suggests some simple cancellation. However, the two interpolating $1s$ are causing me a headache. Does anyone know how we get $(\ast)$ ?","Motivation: remarkably, the simple continued fraction - which is unique - for is known for every . The expansions for , or even , are not known in general, and it is a strange miracle that we can figure out any of them at all... Euler first derived the continued fraction for and . The expansion for is viewable on the web, but I have not been able to find a proof of this beautiful fact. This original text from Euler proves that, for real : It derives the expansion for from that for by means of his ""interpolation"" formulae: Which all have nice special cases for . Wikipedia claims that in fact: Which I'd like to understand. First note that, by equivalence transformation (multiply by ) the a first try might be to convert into: Which unfortunately doesn't work out. Also, although two have clearly been interpolated somehow to get , we can't directly employ any of the standard results shown above, since, instead of it is of the form . If we try to realise as an interpolation, using the middle formula, we need to solve , , etc., to get: Which seems better, but is still not quite right. I'm convinced the answer is going to be a simple transformation: the denominators of are of the form for the denominator in . The presence of a -multiplier and a -multiplier suggests some simple cancellation. However, the two interpolating are causing me a headache. Does anyone know how we get ?","e^{1/n},e^{2/n} n\in\Bbb N e^{3/n} e^{p/q} e e^{1/n} e^{2/n} s \begin{align}\tag{1}e^{2/s}&=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s+}\cdots\\e^{1/s}&=1+\frac{1}{s-1+}\frac{1}{1+}\frac{1}{1+}\frac{1}{3s-1+}\cdots\end{align} e^{1/s} e^{2/s} \begin{align}a+\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\frac{1}{m+}\frac{1}{n+}\frac{1}{c+}\cdots&=\frac{1}{mn+1}\left((mn+1)a+n+\frac{1}{(mn+1)b+m+n+}\frac{1}{(mn+1)c+m+n+}\cdots\right)\\A+\frac{1}{a+}\frac{1}{m+}\frac{1}{n+}\frac{1}{b+}\cdots&=A+\frac{mn+1}{(mn+1)a+n+}\frac{1}{(mn+1)b+m+n+}\cdots\\a+\frac{1}{b+}\frac{1}{c+}\cdots&=a-n+\frac{mn+1}{m+}\frac{1}{n+}\frac{1}{\frac{b-m-n}{mn+1}+}\frac{1}{m+}\frac{1}{n+}\frac{1}{\frac{c-m-n}{mn+1}+}\cdots\end{align} m=n=1 \tag{\ast}e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{6s+}\frac{1}{\frac{5s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{7s-1}{2}+}\frac{1}{18s+}\frac{1}{\frac{11s-1}{2}+}\frac{1}{1+}\cdots 2,1/2,2,1/2,\cdots (\ast) e^{2/s}=1+\frac{2}{s-1+}\frac{1}{3s+}\frac{1}{5s-1+}\frac{1}{\frac{1}{2}+}\frac{1}{2+}\frac{1}{\frac{7s-1}{4}+}\cdots 1s (\ast) a,1,1,b,1,1,... a,b,c,1,1,d,e,f,1,1,... (1) 2a+1=s-1\implies a=\frac{s-1}{2} 2b+2=3s\implies b=\frac{3s-2}{2} e^{2/s}=1+\frac{1}{\frac{s-1}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{3s-2}{2}+}\frac{1}{1+}\frac{1}{1+}\frac{1}{\frac{5s-2}{2}+}\cdots (\ast) \frac{x-1}{2},2x x (1) 2 1/2 1s (\ast)","['real-analysis', 'sequences-and-series', 'number-theory', 'reference-request', 'continued-fractions']"
2,Periodic sequences of integers generated by $a_{n+1}=\operatorname{rad}(a_{n})+\operatorname{rad}(a_{n-1})$,Periodic sequences of integers generated by,a_{n+1}=\operatorname{rad}(a_{n})+\operatorname{rad}(a_{n-1}),"Let's define the radical of the positive integer $n$ as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\ p\text{ prime}}}p$$ and consider the following Fibonacci-like sequence $$a_{n+1}=\operatorname{rad}(a_{n})+\operatorname{rad}(a_{n-1})$$ If $a_1=1,\,a_2=1$ the sequence coincides with OEIS A121369 $$1, 1, 2, 3, 5, 8, 7, 9, 10, 13, 23, 36, 29, 35, 64, 37, 39, 76, 77, ...$$ If $a_1=2,\,a_2=2$ the sequence becomes $$2, 2, 4, 4, 4, ...$$ If $a_1=3,\,a_2=3$ the sequence becomes $$3, 3, 6, 9, 9, 6, 9, ...$$ If $a_1=5,\,a_2=5$ the sequence becomes $$5, 5, 10, 15, 25, 20, 15, 25, ...$$ If $a_1=7,\,a_2=7$ the sequence becomes $$7, 7, 14, 21, 35, 56, 49, 21, 28, 35, 49, 42, 49, 49, 14, 21, ...$$ The above sequences, except for the first, are all periodic. Continuing with the successive prime numbers , we obtain: for $\,p=11,\,$ a sequence with a period length of $\,9$ , for $\,p=13,\,$ a sequence with a period length of $\,81$ , but for $\,p=17\,$ and $\,p=19\,$ two apparently divergent sequences. Other primes that generate periodic sequences are (the respective period lengths in brackets): $$23 (9), 29 (12), 31 (207), 37 (27), 41 (36), 47 (39), 73 (198), 79 (60)$$ Some questions arise from the previous experimental observations: is the period length always a multiple of $3$ (not considering the case $p=2$ )? also in the doubtful cases mentioned above, does the sequence become periodic at some point? given the starting prime number, is it possible to predict the length of the period of the generated sequence or, at least, to identify some pattern? I have posted a more general question of the same nature here . Edit For the calculation of $\,\operatorname{rad}(n)\,$ I used the sympy.primefactors() method inside Python: from sympy import primefactors  def rad(num):     primes = primefactors(num)     value = 1     for p in primes:         value *= p     return value  (a0, a1) = (17, 17) for n in range(2, 10001):     a2 = rad(a1) + rad(a0)     print(n, a2)     a0 = a1     a1 = a2","Let's define the radical of the positive integer as and consider the following Fibonacci-like sequence If the sequence coincides with OEIS A121369 If the sequence becomes If the sequence becomes If the sequence becomes If the sequence becomes The above sequences, except for the first, are all periodic. Continuing with the successive prime numbers , we obtain: for a sequence with a period length of , for a sequence with a period length of , but for and two apparently divergent sequences. Other primes that generate periodic sequences are (the respective period lengths in brackets): Some questions arise from the previous experimental observations: is the period length always a multiple of (not considering the case )? also in the doubtful cases mentioned above, does the sequence become periodic at some point? given the starting prime number, is it possible to predict the length of the period of the generated sequence or, at least, to identify some pattern? I have posted a more general question of the same nature here . Edit For the calculation of I used the sympy.primefactors() method inside Python: from sympy import primefactors  def rad(num):     primes = primefactors(num)     value = 1     for p in primes:         value *= p     return value  (a0, a1) = (17, 17) for n in range(2, 10001):     a2 = rad(a1) + rad(a0)     print(n, a2)     a0 = a1     a1 = a2","n \operatorname{rad}(n)=\prod_{\substack{p\mid n\\ p\text{ prime}}}p a_{n+1}=\operatorname{rad}(a_{n})+\operatorname{rad}(a_{n-1}) a_1=1,\,a_2=1 1, 1, 2, 3, 5, 8, 7, 9, 10, 13, 23, 36, 29, 35, 64, 37, 39, 76, 77, ... a_1=2,\,a_2=2 2, 2, 4, 4, 4, ... a_1=3,\,a_2=3 3, 3, 6, 9, 9, 6, 9, ... a_1=5,\,a_2=5 5, 5, 10, 15, 25, 20, 15, 25, ... a_1=7,\,a_2=7 7, 7, 14, 21, 35, 56, 49, 21, 28, 35, 49, 42, 49, 49, 14, 21, ... \,p=11,\, \,9 \,p=13,\, \,81 \,p=17\, \,p=19\, 23 (9), 29 (12), 31 (207), 37 (27), 41 (36), 47 (39), 73 (198), 79 (60) 3 p=2 \,\operatorname{rad}(n)\,","['sequences-and-series', 'number-theory', 'prime-numbers', 'prime-factorization', 'experimental-mathematics']"
3,"Let $\left\vert\frac{a_{n+1}}{a_n}\right\vert\to 1,$ define $f:(-1,1)\to\mathbb{R};\ f(x)=\sum_{n=0}^{\infty}a_n x^n.$ Is $f$ continuous?",Let  define  Is  continuous?,"\left\vert\frac{a_{n+1}}{a_n}\right\vert\to 1, f:(-1,1)\to\mathbb{R};\ f(x)=\sum_{n=0}^{\infty}a_n x^n. f","Suppose $(a_n)_n$ is a real sequence with $\displaystyle\lim_{n\to\infty}\left\vert \frac{a_{n+1}}{a_n} \right\vert=1.\ $ Define $f:(-1,1)\to\mathbb{R};\ f(x)=\displaystyle\sum_{n=0}^{\infty}a_n x^n.$ By application of the Limit comparison test and comparing this sum to a geometric series (i.e. using the ratio test also), $f(x)$ converges for all $x\in (-1,1),\ $ and so we see that $f$ is well-defined. But can we prove that $f(x)$ is: Continuous, differentiable etc? I have tried to show that $f(x)$ is continuous i.e. showing that $\displaystyle\lim_{h\to 0}\left(f(a+h)-f(a)\right)=0$ via the following method: $$f(a+h)-f(a) = (a_0 - a_0) + a_1(a+h-a) + a_2((a+h)^2-a^2) + a_3((a+h)^3-a^3) + \ldots$$ $$ = 0 + a_1 h + a_2 h (2a+h) + a_3 h (3a^2 + 3ah + h^2) + \ldots $$ $$ = h\left[ a_1 + a_2 (2a+h) + a_3 (3a^2 + 3ah + h^2) + \ldots \right]. $$ Using also the fact that $\vert a \vert < 1,$ can it be proven that the sum inside the square bracket is bounded as $h\to 0\ ?$ It would then follow that $\displaystyle\lim_{h\to 0}\left(f(a+h)-f(a)\right)=0.$ Or is there some other method to prove continuity of $f$ ?","Suppose is a real sequence with Define By application of the Limit comparison test and comparing this sum to a geometric series (i.e. using the ratio test also), converges for all and so we see that is well-defined. But can we prove that is: Continuous, differentiable etc? I have tried to show that is continuous i.e. showing that via the following method: Using also the fact that can it be proven that the sum inside the square bracket is bounded as It would then follow that Or is there some other method to prove continuity of ?","(a_n)_n \displaystyle\lim_{n\to\infty}\left\vert \frac{a_{n+1}}{a_n} \right\vert=1.\  f:(-1,1)\to\mathbb{R};\ f(x)=\displaystyle\sum_{n=0}^{\infty}a_n x^n. f(x) x\in (-1,1),\  f f(x) f(x) \displaystyle\lim_{h\to 0}\left(f(a+h)-f(a)\right)=0 f(a+h)-f(a) = (a_0 - a_0) + a_1(a+h-a) + a_2((a+h)^2-a^2) + a_3((a+h)^3-a^3) + \ldots  = 0 + a_1 h + a_2 h (2a+h) + a_3 h (3a^2 + 3ah + h^2) + \ldots   = h\left[ a_1 + a_2 (2a+h) + a_3 (3a^2 + 3ah + h^2) + \ldots \right].  \vert a \vert < 1, h\to 0\ ? \displaystyle\lim_{h\to 0}\left(f(a+h)-f(a)\right)=0. f","['real-analysis', 'sequences-and-series', 'power-series']"
4,How does this sequence of expressions continue?,How does this sequence of expressions continue?,,"I have the following sequence of expressions (question marks denote unknown numbers): $1^k x$ $2^k x² − (1 × 1^k +  1 × 2^k) x$ $3^k x³ − (2 × 2^k +  3 × 3^k) x² + ( 2 × 1^k +  2 × 2^k +  2 × 3^k) x$ $4^k x⁴ − (3 × 3^k +  6 × 4^k) x³ + ( 6 × 2^k +  9 × 3^k + 11 × 4^k) x² − (6 × 1^k + 6 × 2^k + 6 × 3^k + 6 × 4^k) x$ $5^k x⁵ − (4 × 4^k + 10 × 5^k) x⁴ + (12 × 3^k + 24 × 4^k + 35 × 5^k) x³ − (24 × 2^k + 36 × 3^k + 44 × 4^k + 50 × 5^k) x² + (24 × 1^k + 24 × 2^k + 24 × 3^k + 24 × 4^k + 24 × 5^k) x$ $6^k x⁶ − (5 × 5^k + 15 × 6^k) x⁵ + (20 × 4^k + 50 × 5^k + 85 × 6^k) x⁴ − (60 × 3^k + 120 × 4^k + 175 × 5^k + 225 × 6^k) x³ + (120 × 2^k + 180 × 3^k + 220 × 4^k + 250 × 5^k + 274 × 6^k) x² − (120 × 1^k + 120 × 2^k + 120 × 3^k + 120 × 4^k + 120 × 5^k + 120 × 6^k) x$ $7^k x⁷ − (6 × 6^k + 21 × 7^k) x⁶ + (30 × 5^k + 90 × 6^k + 175 × 7^k) x⁵ − (120 × 4^k + 300 × 5^k + 510 × 6^k + 735 × 7^k) x⁴ + (360 × 3^k + 720 × 4^k + 1050 × 5^k + 1350 × 6^k + 1624 × 7^k) x³ − ( ? × 2^k +  ? × 3^k +  ? × 4^k +  ? × 5^k +  ? × 6^k +  ? × 7^k) x² + (720 × 1^k + 720 × 2^k + 720 × 3^k + 720 × 4^k + 720 × 5^k + 720 × 6^k + 720 × 7^k) x$ The Problem I want to know how to continue this sequence. That is, how to fill in the missing numbers in the seventh expression in the sequence, and how to construct the eighth and ninth and twelfth and so on expressions in the sequence. Some patterns immediately stand out: The expressions are polynomials in terms of $x$ , with coefficients composed of sums of numbers in the form in the form $(a × b^k)$ , where $a$ and $b$ are positive integers The coefficient for the $m$ th term in all expressions is a sum of $(m + 1)$ numbers in the form $(a × b^k)$ The $n$ th expression is $n$ terms long, with highest degree $n$ and containing terms of all lower degrees down to and including 1, with zero constant term The zeroth term in the $n$ th expression is $n^k × x^n$ The first term in the $n$ th expression is $−\left((n − 1) × (n − 1)^k + \frac{n² − n}{2} × n^k\right) × x^{n − 1}$ The second term in the $n$ th expression is $\left((n² − 3 n + 2) × (n − 2)^k + \frac{n³ − 4 n² + 5 n − 2}{2} × (n − 1)^k + \frac{3 n⁴ − 10 n³ + 9 n² − 2 n}{24} × n^k\right) × x^{n − 2}$ The third term in the $n$ th expression is $−\left((n³ - 6 n² + 11 n - 6) × (n − 3)^k + \frac{n⁴ - 8 n³ + 23 n² - 28 n + 12}{2} × (n − 2)^k + \frac{3 n⁵ - 25 n⁴ + 79 n³ - 119 n² + 86 n - 24}{8} × (n − 1)^k + \frac{n⁶ - 7 n⁵ + 17 n⁴ - 17 n³ + 6 n²}{48} × n^k\right) × x^{n − 3}$ The $(n − 1)$ th term (the last non-zero term) in the $n$ th expression is $(−1)^{n − 1} × (n − 1)! × (1^k + 2^k + 3^k + \, ... + (n − 1)^k + n^k) × x$ The terms alternate positive and negative — the zeroth is always positive, the first is always negative, the second is always positive, and so on The bases $b$ of the exponential numbers $(a × b^k)$ in the $m$ th term in the $n$ th expression are one higher than the bases of the corresponding numbers in the $m$ th term of the $(n − 1)$ th expression To break it down, here are the coefficients of the zeroth terms in all the expressions: $1^k$ $2^k$ $3^k$ $4^k$ $5^k$ $6^k$ $7^k$ $n^k$ Here are the coefficients of the first terms in all the expressions: $0 × 0^k +  0 × 1^k$ $1 × 1^k +  1 × 2^k$ $2 × 2^k +  3 × 3^k$ $3 × 3^k +  6 × 4^k$ $4 × 4^k + 10 × 5^k$ $5 × 5^k + 15 × 6^k$ $6 × 6^k + 21 × 7^k$ $(n − 1) × (n − 1)^k + \frac{n² − n}{2} × n^k$ Here are the coefficients of the second terms in all the expressions: $ 0 × −1^k +  0 × 0^k +   0 × 1^k$ $ 0 ×  0^k +  0 × 1^k +   0 × 2^k$ $ 2 ×  1^k +  2 × 2^k +   2 × 3^k$ $ 6 ×  2^k +  9 × 3^k +  11 × 4^k$ $12 ×  3^k + 24 × 4^k +  35 × 5^k$ $20 ×  4^k + 50 × 5^k +  85 × 6^k$ $30 ×  5^k + 90 × 6^k + 175 × 7^k$ $(n² − 3 n + 2) × (n − 2)^k + \frac{n³ − 4 n² + 5 n − 2}{2} × (n − 1)^k + \frac{3 n⁴ − 10 n³ + 9 n² − 2 n}{24} × n^k$ Here are the coefficients of the third terms in all the expressions: $  0 × −2^k +   0 × −1^k +   0 × 0^k +   0 × 1^k$ $  0 × −1^k +   0 ×  0^k +   0 × 1^k +   0 × 2^k$ $  0 ×  0^k +   0 ×  1^k +   0 × 2^k +   0 × 3^k$ $  6 ×  1^k +   6 ×  2^k +   6 × 3^k +   6 × 4^k$ $ 24 ×  2^k +  36 ×  3^k +  44 × 4^k +  50 × 5^k$ $ 60 ×  3^k + 120 ×  4^k + 175 × 5^k + 225 × 6^k$ $120 ×  4^k + 300 ×  5^k + 510 × 6^k + 735 × 7^k$ $(n³ − 6 n² + 11 n − 6) × (n − 3)^k + \frac{n⁴ − 8 n³ + 23 n² − 28 n + 12}{2} × (n − 2)^k + \frac{3 n⁵ − 25 n⁴ + 79 n³ − 119 n² + 86 n − 24}{24} × (n − 1)^k + \frac{n⁶ − 7 n⁵ + 17 n⁴ − 17 n³ + 6 n²}{48} × n^k$ Here are the coefficients of the fourth terms in all the expressions (note that I don't know the pattern for the last number in each coefficient): $  0 × −3^k +   0 × −2^k +    0 × −1^k +    0 × 0^k +    0 × 1^k$ $  0 × −2^k +   0 × −1^k +    0 ×  0^k +    0 × 1^k +    0 × 2^k$ $  0 × −1^k +   0 ×  0^k +    0 ×  1^k +    0 × 2^k +    0 × 3^k$ $  0 ×  0^k +   0 ×  1^k +    0 ×  2^k +    0 × 3^k +    0 × 4^k$ $ 24 ×  1^k +  24 ×  2^k +   24 ×  3^k +   24 × 4^k +   24 × 5^k$ $120 ×  2^k + 180 ×  3^k +  220 ×  4^k +  250 × 5^k +  274 × 6^k$ $360 ×  3^k + 720 ×  4^k + 1050 ×  5^k + 1350 × 6^k + 1624 × 7^k$ $(n⁴ − 10 n³ + 35 n² − 50 n + 24) × (n − 4)^k + \frac{n⁵ − 13 n⁴ + 65 n³ − 155 n² + 174 n − 72}{2} × (n − 3)^k + \frac{3 n⁶ − 43 n⁵ + 249 n⁴ − 745 n³ + 1212 n² − 1012 n + 336}{24} × (n − 2)^k + \frac{n⁷ − 14 n⁶ + 80 n⁵ − 242 n⁴ + 419 n³ − 416 n² + 220 n − 48}{48} × (n − 1)^k + ??? × n^k$ However, I have been unable to figure out patterns for constructing the terms that fall between the third and last terms in the expressions. Where the Expressions Come From The expressions generate numbers to be added as constants when developing the piecewise equations for an Irwin-Hall distribution (IHD), a probability distribution of a number $n$ of independent uniformly-distributed random variables. The probability density function (PDF) of an IHD of $n$ variables is a piecewise polynomial function consisting of $n$ segments of degree $(n − 1)$ . The Cumulative Distribution Function (CDF) of an IHD of $n$ variables is a piecewise polynomial function consisting of $n$ segments of degree $n$ . Wikipedia gives this expression for the PDF of an IHD of $n$ variables: $$f_X(x; n) = \frac{1}{2(n − 1)!} \sum_{k = 0}^n {\left((−1)^k {n \choose k} (x − k)^{n − 1} \operatorname{sgn}(x − k)\right)}$$ However, this does not directly give the piecewise polynomial form of the PDF. I want to find a way to generate the piecewise polynomial directly. This question is part of my efforts to do so. The $(n − 1)$ th derivative of the $m$ th segment in the PDF (and the $n$ th derivative of the $m$ th segment in the CDF) of an IHD of $n$ variables is a constant term of the form $\frac{(−1)^m (n − 1)!}{m! (n − 1 − m)!}$ . For example, in the case of four variables, the 3rd derivatives of the four segments of the PDF are: $\frac{ (4 − 1)!}{0! (4 − 1 − 0)!} = \frac{ 3!}{0! 3!} =  1$ $\frac{−(4 − 1)!}{1! (4 − 1 − 1)!} = \frac{−3!}{1! 2!} = −3$ $\frac{ (4 − 1)!}{2! (4 − 1 − 2)!} = \frac{ 3!}{2! 1!} =  3$ $\frac{−(4 − 1)!}{3! (4 − 1 − 3)!} = \frac{−3!}{3! 0!} = −1$ In the case of five variables, the 4th derivatives of the five segments of the PDF are: $\frac{ (5 − 1)!}{0! (5 − 1 − 0)!} = \frac{ 4!}{0! 4!} =  1$ $\frac{−(5 − 1)!}{1! (5 − 1 − 1)!} = \frac{−4!}{1! 3!} = −4$ $\frac{ (5 − 1)!}{2! (5 − 1 − 2)!} = \frac{ 4!}{2! 2!} =  6$ $\frac{−(5 − 1)!}{3! (5 − 1 − 3)!} = \frac{−4!}{3! 1!} = −4$ $\frac{ (5 − 1)!}{4! (5 − 1 − 4)!} = \frac{ 4!}{4! 0!} =  1$ The full PDF of an IHD of $n$ variables can be obtained by integrating these base numbers $(n − 1)$ times, adding a new constant term each time. The full CDF of an IHD of $n$ variables can be obtained by continuing the process one additional time. The constant terms to be added follow a specific pattern for each segment. I obtained the sequences of constant terms for each segment by trial and error, making a guess and then refining it until it lined up with the previous segment. I then used WolframAlpha to find the expressions that produce those constant terms for a given number $n$ of variables after $k$ integrations, giving rise to the sequence of equations that is the topic of this question. The constant we add to the integrations of the zeroth segment is always zero The constant we add to the integrations of the first segment is given by the sequence of expressions $\{n, \frac{−n}{2}, \frac{n}{6}, \frac{−n}{24}, \frac{n}{120}, \frac{−n}{720}, \, … \} = \frac{(−1)^k n}{0! × (k + 1)!}$ The constant we add to the integrations of the second segment is given by the sequence of expressions $\{−(n² − 2n), \frac{2n² − 3n}{2}, \frac{−(4n² − 5n)}{6}, \frac{8n² − 9n}{24}, \frac{−(16n² − 17n)}{120}, \frac{32n² − 33n}{720}, \, … \} = \frac{(−1)^{k + 1} (2^k n² − (1 + 2^k) n)}{1! × (k + 1)!}$ The constant we add to the integrations of the third segment is given by the sequence of expressions $\{\frac{n³ − 5n² + 6n}{2}, \frac{−(3n³ − 13n² + 12n)}{4}, \frac{9n³ − 35n² + 28n}{12}, \frac{−(27n³ − 97n² + 72n)}{48}, \frac{81n³ − 275n² + 196n}{240}, \frac{−(243n³ − 793n² + 552n)}{1440}, \, … \} = \frac{(−1)^k (3^k n³ − (2 × 2^k +  3 × 3^k) n² + 2! (1 + 2^k + 3^k) n)}{2! × (k + 1)!}$ The constant we add to the integrations of the fourth segment is given by the sequence of expressions $\{\frac{n⁴ − 9n³ + 26n² − 24n}{6}, \frac{−(4n⁴ − 33n³ + 83n² − 60n)}{12}, \frac{16n⁴ − 123n³ + 281n² − 180n}{36}, \frac{−(64n⁴ − 465n³ + 995n² − 600n)}{144}, \frac{256n⁴ − 1779n³ + 3641n² − 2124n}{720}, \frac{−(1024n⁴ − 6873n³ + 13643n² − 7800n)}{4320}, \, … \} = \frac{(−1)^k (4^k n⁴ − (3 × 3^k + 6 × 4^k) n³ + (6 × 2^k + 9 × 3^k + 11 × 4^k) n² − 3! (1 + 2^k + 3^k + 4^k) n)}{3! × (k + 1)!}$ An Example of the Process The equation for the third segment ( $m = 3$ ) after three integrations ( $k = 3$ ) is: $$\int \left( \int \left( \int \left( \frac{(−1)^3 (n − 1)!}{3! (n − 1 − 3)!} \right) + \frac{n³ − 5n² + 6n}{2! × 1!} \right) − \frac{3n³ − 13n² + 12n}{2! × 2!} \right) + \frac{9n³ − 35n² + 28n}{2! × 3!}$$ In the case of four variables ( $n = 4$ ), that simplifies to: $$\int \left( \int \left( \int \left( −1 \right)  + 4 \right) − 8 \right) + \frac{32}{3}$$ Which expands into: $$\frac{−x³}{6} + 2x² − 8x + \frac{32}{3}$$ Which can be re-written as: $$\frac{−x³ + 12x² − 48x + 64}{3!}$$ Doing this for the other three segments in the PDF of the IHD of four variables gives the piecewise polynomial: $$f_X(x; 4) = \begin{cases} \frac{x³}{3!} & : 0 ≤ x ≤ 1 \\ \frac{−3x³ + 12x² − 12x + 4}{3!} & : 1 ≤ x ≤ 2 \\ \frac{3x³ − 24x² + 60x − 44}{3!} & :  2 ≤ x ≤ 3 \\ \frac{−x³ + 12x² − 48x + 64}{3!} & :  3 ≤ x ≤ 4 \\ 0 & : \text{otherwise} \end{cases}$$ Back to the Problem The expressions for the $m$ th segment are all divided by $((m − 1)! × (k + 1)!)$ . When $m$ is even, the expressions are multiplied by $(−1)^{k + 1}$ . When $m$ is odd, the expressions are multiplied by $(−1)^k$ . Removing these known factors and replacing the $n$ s with $x$ s leaves the polynomials that are the basis of this question. Here are the numbers I've worked out for the seventh expression in the sequence, which is as far as I can get with WolframAlpha: $1 x⁷ −  27 x⁶ +  295 x⁵ −  1665 x⁴ +  5104 x³ −  8028 x² +  5040 x$ 1, 0, 0, 0, 0, 0, 0, 8, 63, 280, 924, 2520, 6006, 12936, 25740, ... $7 x⁷ − 183 x⁶ + 1915 x⁵ − 10185 x⁴ + 28678 x³ − 39672 x² + 20160 x$ 1, −2, 0, 0, 0, 0, 0, 64, 495, 2170, 7084, 19152, 45318, 97020, 192060, ... …","I have the following sequence of expressions (question marks denote unknown numbers): The Problem I want to know how to continue this sequence. That is, how to fill in the missing numbers in the seventh expression in the sequence, and how to construct the eighth and ninth and twelfth and so on expressions in the sequence. Some patterns immediately stand out: The expressions are polynomials in terms of , with coefficients composed of sums of numbers in the form in the form , where and are positive integers The coefficient for the th term in all expressions is a sum of numbers in the form The th expression is terms long, with highest degree and containing terms of all lower degrees down to and including 1, with zero constant term The zeroth term in the th expression is The first term in the th expression is The second term in the th expression is The third term in the th expression is The th term (the last non-zero term) in the th expression is The terms alternate positive and negative — the zeroth is always positive, the first is always negative, the second is always positive, and so on The bases of the exponential numbers in the th term in the th expression are one higher than the bases of the corresponding numbers in the th term of the th expression To break it down, here are the coefficients of the zeroth terms in all the expressions: Here are the coefficients of the first terms in all the expressions: Here are the coefficients of the second terms in all the expressions: Here are the coefficients of the third terms in all the expressions: Here are the coefficients of the fourth terms in all the expressions (note that I don't know the pattern for the last number in each coefficient): However, I have been unable to figure out patterns for constructing the terms that fall between the third and last terms in the expressions. Where the Expressions Come From The expressions generate numbers to be added as constants when developing the piecewise equations for an Irwin-Hall distribution (IHD), a probability distribution of a number of independent uniformly-distributed random variables. The probability density function (PDF) of an IHD of variables is a piecewise polynomial function consisting of segments of degree . The Cumulative Distribution Function (CDF) of an IHD of variables is a piecewise polynomial function consisting of segments of degree . Wikipedia gives this expression for the PDF of an IHD of variables: However, this does not directly give the piecewise polynomial form of the PDF. I want to find a way to generate the piecewise polynomial directly. This question is part of my efforts to do so. The th derivative of the th segment in the PDF (and the th derivative of the th segment in the CDF) of an IHD of variables is a constant term of the form . For example, in the case of four variables, the 3rd derivatives of the four segments of the PDF are: In the case of five variables, the 4th derivatives of the five segments of the PDF are: The full PDF of an IHD of variables can be obtained by integrating these base numbers times, adding a new constant term each time. The full CDF of an IHD of variables can be obtained by continuing the process one additional time. The constant terms to be added follow a specific pattern for each segment. I obtained the sequences of constant terms for each segment by trial and error, making a guess and then refining it until it lined up with the previous segment. I then used WolframAlpha to find the expressions that produce those constant terms for a given number of variables after integrations, giving rise to the sequence of equations that is the topic of this question. The constant we add to the integrations of the zeroth segment is always zero The constant we add to the integrations of the first segment is given by the sequence of expressions The constant we add to the integrations of the second segment is given by the sequence of expressions The constant we add to the integrations of the third segment is given by the sequence of expressions The constant we add to the integrations of the fourth segment is given by the sequence of expressions An Example of the Process The equation for the third segment ( ) after three integrations ( ) is: In the case of four variables ( ), that simplifies to: Which expands into: Which can be re-written as: Doing this for the other three segments in the PDF of the IHD of four variables gives the piecewise polynomial: Back to the Problem The expressions for the th segment are all divided by . When is even, the expressions are multiplied by . When is odd, the expressions are multiplied by . Removing these known factors and replacing the s with s leaves the polynomials that are the basis of this question. Here are the numbers I've worked out for the seventh expression in the sequence, which is as far as I can get with WolframAlpha: 1, 0, 0, 0, 0, 0, 0, 8, 63, 280, 924, 2520, 6006, 12936, 25740, ... 1, −2, 0, 0, 0, 0, 0, 64, 495, 2170, 7084, 19152, 45318, 97020, 192060, ... …","1^k x 2^k x² − (1 × 1^k +  1 × 2^k) x 3^k x³ − (2 × 2^k +  3 × 3^k) x² + ( 2 × 1^k +  2 × 2^k +  2 × 3^k) x 4^k x⁴ − (3 × 3^k +  6 × 4^k) x³ + ( 6 × 2^k +  9 × 3^k + 11 × 4^k) x² − (6 × 1^k + 6 × 2^k + 6 × 3^k + 6 × 4^k) x 5^k x⁵ − (4 × 4^k + 10 × 5^k) x⁴ + (12 × 3^k + 24 × 4^k + 35 × 5^k) x³ − (24 × 2^k + 36 × 3^k + 44 × 4^k + 50 × 5^k) x² + (24 × 1^k + 24 × 2^k + 24 × 3^k + 24 × 4^k + 24 × 5^k) x 6^k x⁶ − (5 × 5^k + 15 × 6^k) x⁵ + (20 × 4^k + 50 × 5^k + 85 × 6^k) x⁴ − (60 × 3^k + 120 × 4^k + 175 × 5^k + 225 × 6^k) x³ + (120 × 2^k + 180 × 3^k + 220 × 4^k + 250 × 5^k + 274 × 6^k) x² − (120 × 1^k + 120 × 2^k + 120 × 3^k + 120 × 4^k + 120 × 5^k + 120 × 6^k) x 7^k x⁷ − (6 × 6^k + 21 × 7^k) x⁶ + (30 × 5^k + 90 × 6^k + 175 × 7^k) x⁵ − (120 × 4^k + 300 × 5^k + 510 × 6^k + 735 × 7^k) x⁴ + (360 × 3^k + 720 × 4^k + 1050 × 5^k + 1350 × 6^k + 1624 × 7^k) x³ − ( ? × 2^k +  ? × 3^k +  ? × 4^k +  ? × 5^k +  ? × 6^k +  ? × 7^k) x² + (720 × 1^k + 720 × 2^k + 720 × 3^k + 720 × 4^k + 720 × 5^k + 720 × 6^k + 720 × 7^k) x x (a × b^k) a b m (m + 1) (a × b^k) n n n n n^k × x^n n −\left((n − 1) × (n − 1)^k + \frac{n² − n}{2} × n^k\right) × x^{n − 1} n \left((n² − 3 n + 2) × (n − 2)^k + \frac{n³ − 4 n² + 5 n − 2}{2} × (n − 1)^k + \frac{3 n⁴ − 10 n³ + 9 n² − 2 n}{24} × n^k\right) × x^{n − 2} n −\left((n³ - 6 n² + 11 n - 6) × (n − 3)^k + \frac{n⁴ - 8 n³ + 23 n² - 28 n + 12}{2} × (n − 2)^k + \frac{3 n⁵ - 25 n⁴ + 79 n³ - 119 n² + 86 n - 24}{8} × (n − 1)^k + \frac{n⁶ - 7 n⁵ + 17 n⁴ - 17 n³ + 6 n²}{48} × n^k\right) × x^{n − 3} (n − 1) n (−1)^{n − 1} × (n − 1)! × (1^k + 2^k + 3^k + \, ... + (n − 1)^k + n^k) × x b (a × b^k) m n m (n − 1) 1^k 2^k 3^k 4^k 5^k 6^k 7^k n^k 0 × 0^k +  0 × 1^k 1 × 1^k +  1 × 2^k 2 × 2^k +  3 × 3^k 3 × 3^k +  6 × 4^k 4 × 4^k + 10 × 5^k 5 × 5^k + 15 × 6^k 6 × 6^k + 21 × 7^k (n − 1) × (n − 1)^k + \frac{n² − n}{2} × n^k  0 × −1^k +  0 × 0^k +   0 × 1^k  0 ×  0^k +  0 × 1^k +   0 × 2^k  2 ×  1^k +  2 × 2^k +   2 × 3^k  6 ×  2^k +  9 × 3^k +  11 × 4^k 12 ×  3^k + 24 × 4^k +  35 × 5^k 20 ×  4^k + 50 × 5^k +  85 × 6^k 30 ×  5^k + 90 × 6^k + 175 × 7^k (n² − 3 n + 2) × (n − 2)^k + \frac{n³ − 4 n² + 5 n − 2}{2} × (n − 1)^k + \frac{3 n⁴ − 10 n³ + 9 n² − 2 n}{24} × n^k   0 × −2^k +   0 × −1^k +   0 × 0^k +   0 × 1^k   0 × −1^k +   0 ×  0^k +   0 × 1^k +   0 × 2^k   0 ×  0^k +   0 ×  1^k +   0 × 2^k +   0 × 3^k   6 ×  1^k +   6 ×  2^k +   6 × 3^k +   6 × 4^k  24 ×  2^k +  36 ×  3^k +  44 × 4^k +  50 × 5^k  60 ×  3^k + 120 ×  4^k + 175 × 5^k + 225 × 6^k 120 ×  4^k + 300 ×  5^k + 510 × 6^k + 735 × 7^k (n³ − 6 n² + 11 n − 6) × (n − 3)^k + \frac{n⁴ − 8 n³ + 23 n² − 28 n + 12}{2} × (n − 2)^k + \frac{3 n⁵ − 25 n⁴ + 79 n³ − 119 n² + 86 n − 24}{24} × (n − 1)^k + \frac{n⁶ − 7 n⁵ + 17 n⁴ − 17 n³ + 6 n²}{48} × n^k   0 × −3^k +   0 × −2^k +    0 × −1^k +    0 × 0^k +    0 × 1^k   0 × −2^k +   0 × −1^k +    0 ×  0^k +    0 × 1^k +    0 × 2^k   0 × −1^k +   0 ×  0^k +    0 ×  1^k +    0 × 2^k +    0 × 3^k   0 ×  0^k +   0 ×  1^k +    0 ×  2^k +    0 × 3^k +    0 × 4^k  24 ×  1^k +  24 ×  2^k +   24 ×  3^k +   24 × 4^k +   24 × 5^k 120 ×  2^k + 180 ×  3^k +  220 ×  4^k +  250 × 5^k +  274 × 6^k 360 ×  3^k + 720 ×  4^k + 1050 ×  5^k + 1350 × 6^k + 1624 × 7^k (n⁴ − 10 n³ + 35 n² − 50 n + 24) × (n − 4)^k + \frac{n⁵ − 13 n⁴ + 65 n³ − 155 n² + 174 n − 72}{2} × (n − 3)^k + \frac{3 n⁶ − 43 n⁵ + 249 n⁴ − 745 n³ + 1212 n² − 1012 n + 336}{24} × (n − 2)^k + \frac{n⁷ − 14 n⁶ + 80 n⁵ − 242 n⁴ + 419 n³ − 416 n² + 220 n − 48}{48} × (n − 1)^k + ??? × n^k n n n (n − 1) n n n n f_X(x; n) = \frac{1}{2(n − 1)!} \sum_{k = 0}^n {\left((−1)^k {n \choose k} (x − k)^{n − 1} \operatorname{sgn}(x − k)\right)} (n − 1) m n m n \frac{(−1)^m (n − 1)!}{m! (n − 1 − m)!} \frac{ (4 − 1)!}{0! (4 − 1 − 0)!} = \frac{ 3!}{0! 3!} =  1 \frac{−(4 − 1)!}{1! (4 − 1 − 1)!} = \frac{−3!}{1! 2!} = −3 \frac{ (4 − 1)!}{2! (4 − 1 − 2)!} = \frac{ 3!}{2! 1!} =  3 \frac{−(4 − 1)!}{3! (4 − 1 − 3)!} = \frac{−3!}{3! 0!} = −1 \frac{ (5 − 1)!}{0! (5 − 1 − 0)!} = \frac{ 4!}{0! 4!} =  1 \frac{−(5 − 1)!}{1! (5 − 1 − 1)!} = \frac{−4!}{1! 3!} = −4 \frac{ (5 − 1)!}{2! (5 − 1 − 2)!} = \frac{ 4!}{2! 2!} =  6 \frac{−(5 − 1)!}{3! (5 − 1 − 3)!} = \frac{−4!}{3! 1!} = −4 \frac{ (5 − 1)!}{4! (5 − 1 − 4)!} = \frac{ 4!}{4! 0!} =  1 n (n − 1) n n k \{n, \frac{−n}{2}, \frac{n}{6}, \frac{−n}{24}, \frac{n}{120}, \frac{−n}{720}, \, … \} = \frac{(−1)^k n}{0! × (k + 1)!} \{−(n² − 2n), \frac{2n² − 3n}{2}, \frac{−(4n² − 5n)}{6}, \frac{8n² − 9n}{24}, \frac{−(16n² − 17n)}{120}, \frac{32n² − 33n}{720}, \, … \} = \frac{(−1)^{k + 1} (2^k n² − (1 + 2^k) n)}{1! × (k + 1)!} \{\frac{n³ − 5n² + 6n}{2}, \frac{−(3n³ − 13n² + 12n)}{4}, \frac{9n³ − 35n² + 28n}{12}, \frac{−(27n³ − 97n² + 72n)}{48}, \frac{81n³ − 275n² + 196n}{240}, \frac{−(243n³ − 793n² + 552n)}{1440}, \, … \} = \frac{(−1)^k (3^k n³ − (2 × 2^k +  3 × 3^k) n² + 2! (1 + 2^k + 3^k) n)}{2! × (k + 1)!} \{\frac{n⁴ − 9n³ + 26n² − 24n}{6}, \frac{−(4n⁴ − 33n³ + 83n² − 60n)}{12}, \frac{16n⁴ − 123n³ + 281n² − 180n}{36}, \frac{−(64n⁴ − 465n³ + 995n² − 600n)}{144}, \frac{256n⁴ − 1779n³ + 3641n² − 2124n}{720}, \frac{−(1024n⁴ − 6873n³ + 13643n² − 7800n)}{4320}, \, … \} = \frac{(−1)^k (4^k n⁴ − (3 × 3^k + 6 × 4^k) n³ + (6 × 2^k + 9 × 3^k + 11 × 4^k) n² − 3! (1 + 2^k + 3^k + 4^k) n)}{3! × (k + 1)!} m = 3 k = 3 \int \left( \int \left( \int \left( \frac{(−1)^3 (n − 1)!}{3! (n − 1 − 3)!} \right) + \frac{n³ − 5n² + 6n}{2! × 1!} \right) − \frac{3n³ − 13n² + 12n}{2! × 2!} \right) + \frac{9n³ − 35n² + 28n}{2! × 3!} n = 4 \int \left( \int \left( \int \left( −1 \right)  + 4 \right) − 8 \right) + \frac{32}{3} \frac{−x³}{6} + 2x² − 8x + \frac{32}{3} \frac{−x³ + 12x² − 48x + 64}{3!} f_X(x; 4) = \begin{cases}
\frac{x³}{3!} & : 0 ≤ x ≤ 1 \\
\frac{−3x³ + 12x² − 12x + 4}{3!} & : 1 ≤ x ≤ 2 \\
\frac{3x³ − 24x² + 60x − 44}{3!} & :  2 ≤ x ≤ 3 \\
\frac{−x³ + 12x² − 48x + 64}{3!} & :  3 ≤ x ≤ 4 \\
0 & : \text{otherwise}
\end{cases} m ((m − 1)! × (k + 1)!) m (−1)^{k + 1} m (−1)^k n x 1 x⁷ −  27 x⁶ +  295 x⁵ −  1665 x⁴ +  5104 x³ −  8028 x² +  5040 x 7 x⁷ − 183 x⁶ + 1915 x⁵ − 10185 x⁴ + 28678 x³ − 39672 x² + 20160 x","['sequences-and-series', 'recurrence-relations', 'recreational-mathematics', 'generating-functions']"
5,Find $x_1=a$ such that $x_{n+1}=x_n(x_n-1)$ converges,Find  such that  converges,x_1=a x_{n+1}=x_n(x_n-1),"Given $x_1=a$ , and $x_{n+1}=x_n(x_n-1). \forall n\in\mathbb{N*}$ Find the conditions of a such that $x_n$ converges. My attempts Now apparently if we assume $L$ is the limit with the correct $a$ then $L \in \{0,2\}$ . I also guess that $a \in [0,2]$ because otherwise $|x_n-1| >1 \forall n\in\mathbb{Z}$ which means $\lim x_n = +\infty$ . I may try to prove harder that $a = L \in \{0,2\}$ So I first tried to quadrupled both sides, and got $4x_{n+1}+1=(2x_n-1)^2$ . Then I substitute $2x_n-1=y_n$ and got: $2y_{n+1}+3=y_n^2$ At this point I think I may have complicated things up Any way to do otherwise? Please help!","Given , and Find the conditions of a such that converges. My attempts Now apparently if we assume is the limit with the correct then . I also guess that because otherwise which means . I may try to prove harder that So I first tried to quadrupled both sides, and got . Then I substitute and got: At this point I think I may have complicated things up Any way to do otherwise? Please help!","x_1=a x_{n+1}=x_n(x_n-1). \forall n\in\mathbb{N*} x_n L a L \in \{0,2\} a \in [0,2] |x_n-1| >1 \forall n\in\mathbb{Z} \lim x_n = +\infty a = L \in \{0,2\} 4x_{n+1}+1=(2x_n-1)^2 2x_n-1=y_n 2y_{n+1}+3=y_n^2","['sequences-and-series', 'algebra-precalculus', 'limits']"
6,Maximize equation involving sum over subsets,Maximize equation involving sum over subsets,,"I am trying to find the function $f(x)$ the maximizes the following equation. $$\sum_{S\subseteq \{1,\dots,n\}}(-1)^{n-|S|} \left(\sum_{i\in S}\int_{\frac{i-1}{n}}^{\frac{i}{n}}f(x)dx\right)^t$$ Where $t$ is a real constant greater than $1$ , $0\leq f(x)\forall x\in\left[0,1\right]$ and $\int_0^1f(x)dx=1$ . From trying out different functions I've come to believe $f(x)=1$ is the answer, however I haven't been able to proof this result.","I am trying to find the function the maximizes the following equation. Where is a real constant greater than , and . From trying out different functions I've come to believe is the answer, however I haven't been able to proof this result.","f(x) \sum_{S\subseteq \{1,\dots,n\}}(-1)^{n-|S|} \left(\sum_{i\in S}\int_{\frac{i-1}{n}}^{\frac{i}{n}}f(x)dx\right)^t t 1 0\leq f(x)\forall x\in\left[0,1\right] \int_0^1f(x)dx=1 f(x)=1","['calculus', 'sequences-and-series', 'functions', 'optimization']"
7,Conditions for a dynamical system to be input-commutative?,Conditions for a dynamical system to be input-commutative?,,"Consider an explicit discrete-time dynamical system (recurrence relation), $$ x_{t+1} = f(x_t, u_t)\ \ \ \ \forall t \in \mathbb{N} $$ where $u$ is an exogenous sequence of ""inputs."" I am intrigued by systems for which the value of $x_t$ is invariant to permutations of the input sequence up to time $t-1$ . That is, if we write the ""solution"" to the system as, $$ x_t = g(x_0,u_0,u_1,\ldots,u_{t-1}) $$ then I define the property ""input-commutativity"" as when $g$ is commutative in the arguments $u_0,u_1,...,u_{t-1}$ . Put simply, it means that the system ends up in the same state regardless of the order that the inputs are provided in. Here are some simple examples on $\mathbb{R}$ : \begin{align*} x_{t+1} = x_t u_t\ \  &\implies\ \ x_t = x_0\prod_{\tau=0}^{t-1}u_\tau \tag{1}\\[6pt] x_{t+1} = \max\{x_t,u_t\}\ \  &\implies\ \ x_t = \max\{x_0,u_0,u_1,\ldots,u_{t-1}\} \tag{2}\\[6pt] x_{t+1} = x_t + 2u_t\ \  &\implies\ \ x_t = x_0 + 2\sum_{\tau=0}^{t-1}u_\tau \tag{3} \end{align*} The first two examples show that $f$ need not be linear and the third example shows that $f$ need not itself be commutative. Meanwhile, $x_{t+1} = 2x_t + 2u_t$ is an example of a linear and commutative $f$ that does not yield an input-commutative solution. It seems that linearity and/or commutativity of $f$ have no bearing on whether the solution will be input-commutative. A perhaps motivating example is the recursive application of Bayes rule from probability theory. If $u$ is a sequence of independent random variables then we can define the ""belief state"" for some random variable $\theta$ as $\ x_t = p(\theta|u_0,u_1,\ldots,u_{t-1})\ $ and have, $$ x_{t+1} = \frac{p(u_t|\theta) x_t}{p(u_t)}\ \  \implies\ \ x_t = x_0\prod_{\tau=0}^{t-1}\frac{p(u_\tau|\theta)}{p(u_\tau)} $$ Though this is just a glorified version of the $x_t u_t$ example (1), it provides the nice physical interpretation that one's belief about an unknown parameter should end up the same no matter what order the evidence is provided in. (For what it's worth, the $\max(x_t,u_t)$ example (2) also has an interpretation as a ""peak detector"" device, and the additive example (3) could represent work/transactions performed on a storage of energy/money). Anyway, the only general form for a solution $g$ in terms of the dynamic $f$ is, $$ g(x_0,u_0,u_1,\ldots,u_{t-1}) = f(f(f(f(x_0,u_0),u_1),\ldots),u_{t-1}) $$ from which it is not so obvious to see what about $f$ is necessary and/or sufficient to make $g$ commutative in $u_0,u_1,\ldots,u_{t-1}$ . My questions are: Can this property of the solution $g$ be deduced by any properties of the dynamic $f$ ? Does this property have an official name? Any references for its study? Is there a formalization of this concept for continuous-time? Thanks in advance!","Consider an explicit discrete-time dynamical system (recurrence relation), where is an exogenous sequence of ""inputs."" I am intrigued by systems for which the value of is invariant to permutations of the input sequence up to time . That is, if we write the ""solution"" to the system as, then I define the property ""input-commutativity"" as when is commutative in the arguments . Put simply, it means that the system ends up in the same state regardless of the order that the inputs are provided in. Here are some simple examples on : The first two examples show that need not be linear and the third example shows that need not itself be commutative. Meanwhile, is an example of a linear and commutative that does not yield an input-commutative solution. It seems that linearity and/or commutativity of have no bearing on whether the solution will be input-commutative. A perhaps motivating example is the recursive application of Bayes rule from probability theory. If is a sequence of independent random variables then we can define the ""belief state"" for some random variable as and have, Though this is just a glorified version of the example (1), it provides the nice physical interpretation that one's belief about an unknown parameter should end up the same no matter what order the evidence is provided in. (For what it's worth, the example (2) also has an interpretation as a ""peak detector"" device, and the additive example (3) could represent work/transactions performed on a storage of energy/money). Anyway, the only general form for a solution in terms of the dynamic is, from which it is not so obvious to see what about is necessary and/or sufficient to make commutative in . My questions are: Can this property of the solution be deduced by any properties of the dynamic ? Does this property have an official name? Any references for its study? Is there a formalization of this concept for continuous-time? Thanks in advance!","
x_{t+1} = f(x_t, u_t)\ \ \ \ \forall t \in \mathbb{N}
 u x_t t-1 
x_t = g(x_0,u_0,u_1,\ldots,u_{t-1})
 g u_0,u_1,...,u_{t-1} \mathbb{R} \begin{align*}
x_{t+1} = x_t u_t\ \  &\implies\ \ x_t = x_0\prod_{\tau=0}^{t-1}u_\tau \tag{1}\\[6pt]
x_{t+1} = \max\{x_t,u_t\}\ \  &\implies\ \ x_t = \max\{x_0,u_0,u_1,\ldots,u_{t-1}\} \tag{2}\\[6pt]
x_{t+1} = x_t + 2u_t\ \  &\implies\ \ x_t = x_0 + 2\sum_{\tau=0}^{t-1}u_\tau \tag{3}
\end{align*} f f x_{t+1} = 2x_t + 2u_t f f u \theta \ x_t = p(\theta|u_0,u_1,\ldots,u_{t-1})\  
x_{t+1} = \frac{p(u_t|\theta) x_t}{p(u_t)}\ \  \implies\ \ x_t = x_0\prod_{\tau=0}^{t-1}\frac{p(u_\tau|\theta)}{p(u_\tau)}
 x_t u_t \max(x_t,u_t) g f 
g(x_0,u_0,u_1,\ldots,u_{t-1}) = f(f(f(f(x_0,u_0),u_1),\ldots),u_{t-1})
 f g u_0,u_1,\ldots,u_{t-1} g f","['sequences-and-series', 'recurrence-relations', 'dynamical-systems']"
8,Chances to go infinite in Magic: The Gathering using Dungeons & Dragons set dice rolling,Chances to go infinite in Magic: The Gathering using Dungeons & Dragons set dice rolling,,"So Wizards of the Coast recently released a Dungeons & Dragons -themed Magic: The Gathering set. In this set they have the following two creatures: Pixie Guide and Delina . With those two cards attacking, a funny thing happens: A 20-sided dice is rolled for each Pixie Guide on the field + 1. If at least one of those dice rolls 15 or greater, a copy of Pixie Guide is made, then the process is repeated starting from 1. Question: What are the chances that this goes infinite? Partial solution: Given $i$ dice, the probability of low-rolling all rolls is $p^i$ , where $p=14/20$ . The probability of high-rolling at least one dice is thus $1-p^i$ , and the probability of going infinite is thus $$P=\prod_{i=2}^{\infty}(1-p^i)$$ Note that the product starts at $i=2$ , because the very first time we roll two dice. Does $P$ have a closed expression for $0 < p < 1$ ? A simulation suggests it converges to 0.14105299 for 100 terms.","So Wizards of the Coast recently released a Dungeons & Dragons -themed Magic: The Gathering set. In this set they have the following two creatures: Pixie Guide and Delina . With those two cards attacking, a funny thing happens: A 20-sided dice is rolled for each Pixie Guide on the field + 1. If at least one of those dice rolls 15 or greater, a copy of Pixie Guide is made, then the process is repeated starting from 1. Question: What are the chances that this goes infinite? Partial solution: Given dice, the probability of low-rolling all rolls is , where . The probability of high-rolling at least one dice is thus , and the probability of going infinite is thus Note that the product starts at , because the very first time we roll two dice. Does have a closed expression for ? A simulation suggests it converges to 0.14105299 for 100 terms.",i p^i p=14/20 1-p^i P=\prod_{i=2}^{\infty}(1-p^i) i=2 P 0 < p < 1,"['sequences-and-series', 'limits']"
9,"Test for convergence for all $\alpha \in [0, 1)$ series $\sum_{n=1}^{\infty} \frac{(-1)^{\lfloor\sqrt{n}\rfloor}}{n^{\alpha}}$",Test for convergence for all  series,"\alpha \in [0, 1) \sum_{n=1}^{\infty} \frac{(-1)^{\lfloor\sqrt{n}\rfloor}}{n^{\alpha}}","$ %Define large versions of lfloor and rfloor (big enough to handle sqrt).  \newcommand{\lf}{\large \lfloor \normalsize}  \newcommand{\rf}{\large \rfloor \normalsize} $ Note: $\lf\sqrt{n}\rf$ denotes integer part of $\sqrt{n}$ (floor rounding). So, I have such series $$A :=\sum_{n=1}^{\infty} a_n$$ where $$a_n = \frac{(-1)^{\lf\sqrt{n}\rf}}{n^{\alpha}}$$ This is what I tried to do: Let's group our $a_n$ such way that by doing that all elements in group will have same sign. If series that we get after grouping sequence such way converges, initial series will converge also. Let's denote by $t$ minimal $n$ such that $\lf \sqrt{n} \rf = t$ .  But that means that $n = t^2$ . Now let's find other elements of that group. $ \lf\sqrt{n}\rf = \lf\sqrt{t^2}\rf = \lf\sqrt{t^2 + 1}\rf = \lf\sqrt{t^2 + 2}\rf = \cdots = \lf\sqrt{t^2 + 2t}\rf$ . We have $2t + 1$ elements in each group. So we can see how our series would look like $$\large\sum_{t = 1}^{\infty}\normalsize \sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}}$$ Now we can see that $$(2t + 1) \cdot \frac{1}{(t^2 + 2t)^{\alpha}} \le \sum_{n = t^2}^{t^2 + 2t}\frac{1}{n^{\alpha}} \le (2t + 1) \cdot \frac{1}{(t^2)^{\alpha}}$$ So, is it accurate to say that for $\alpha \in (\frac{1}{2}, 1)$ we have convergence here? For instance, by applying Leibniz criterion. I have doubts since I apply it not to my sequence $a_n$ but to the sequence that I was able to use to evaluate it from right side (however, I believe that the one on the left is also such that $b_n \searrow 0$ and $b_n \ge 0$ if $\alpha \in \big(\frac{1}{2}, 1)$ ). And of course for $\alpha = 0$ it diverges. But what about case of $\alpha \in (0, \frac{1}{2}\big]$ ? How to see what happens there? And did I show everything right in case of $\alpha \in \big(\frac{1}{2}, 1)$ ? Idea: may be we can use evaluation of sum of each of block using definite integral? At least it’s absolute value. $|\sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}} - (-1)^t\int_{t^2}^{t^2 + 2t + 1} x^{-\alpha} dx| \le (t^2)^{-\alpha} - (t^2+2t + 1)^{-\alpha}$ . I tried to use it but it did not help much. All help will be appreciated!","Note: denotes integer part of (floor rounding). So, I have such series where This is what I tried to do: Let's group our such way that by doing that all elements in group will have same sign. If series that we get after grouping sequence such way converges, initial series will converge also. Let's denote by minimal such that .  But that means that . Now let's find other elements of that group. . We have elements in each group. So we can see how our series would look like Now we can see that So, is it accurate to say that for we have convergence here? For instance, by applying Leibniz criterion. I have doubts since I apply it not to my sequence but to the sequence that I was able to use to evaluate it from right side (however, I believe that the one on the left is also such that and if ). And of course for it diverges. But what about case of ? How to see what happens there? And did I show everything right in case of ? Idea: may be we can use evaluation of sum of each of block using definite integral? At least it’s absolute value. . I tried to use it but it did not help much. All help will be appreciated!","
%Define large versions of lfloor and rfloor (big enough to handle sqrt).
 \newcommand{\lf}{\large \lfloor \normalsize}
 \newcommand{\rf}{\large \rfloor \normalsize}
 \lf\sqrt{n}\rf \sqrt{n} A :=\sum_{n=1}^{\infty} a_n a_n = \frac{(-1)^{\lf\sqrt{n}\rf}}{n^{\alpha}} a_n t n \lf \sqrt{n} \rf = t n = t^2  \lf\sqrt{n}\rf
= \lf\sqrt{t^2}\rf
= \lf\sqrt{t^2 + 1}\rf
= \lf\sqrt{t^2 + 2}\rf = \cdots
= \lf\sqrt{t^2 + 2t}\rf 2t + 1 \large\sum_{t = 1}^{\infty}\normalsize
\sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}} (2t + 1) \cdot \frac{1}{(t^2 + 2t)^{\alpha}} \le \sum_{n = t^2}^{t^2 + 2t}\frac{1}{n^{\alpha}} \le (2t + 1) \cdot \frac{1}{(t^2)^{\alpha}} \alpha \in (\frac{1}{2}, 1) a_n b_n \searrow 0 b_n \ge 0 \alpha \in \big(\frac{1}{2}, 1) \alpha = 0 \alpha \in (0, \frac{1}{2}\big] \alpha \in \big(\frac{1}{2}, 1) |\sum_{n = t^2}^{t^2 + 2t}\frac{(-1)^t}{n^{\alpha}} - (-1)^t\int_{t^2}^{t^2 + 2t + 1} x^{-\alpha} dx| \le (t^2)^{-\alpha} - (t^2+2t + 1)^{-\alpha}","['calculus', 'sequences-and-series', 'convergence-divergence']"
10,"What's the sequence $3,9,24,21,36,30,75,120,270,462,837,1320,2085,\ldots$?",What's the sequence ?,"3,9,24,21,36,30,75,120,270,462,837,1320,2085,\ldots","In order to find a formula of the partition of an integer into 5 parts (see $(6)$ below), I find the sequence $$S_1: 3,9,24,21,36,30,75,120,270,462,837,1320,2085,\ldots \tag1$$ It's clear that $S_1$ is divisible by $3$ , so I got the sequence $$S_2: 1,3,8,7,12,10,25,40,90,154,279,440,695,\ldots \tag2$$ I can't figure out what's this sequence. I tried to divide the sequence into two other sequences: The odd sequence $$S_3: 3,7,10,40,154,440,\ldots\tag3$$ and the even sequence $$S_4: 1,8,12,25,90,279,695,\ldots\tag4$$ but yet I can't find any answer. More details: For example, the formula of the partition of an integer into 3 parts is A069905 $$p_3(n)=\begin{cases} \frac1{12}n^2 &\text{if}\; n=6k \\[4pt] \frac1{12}(n^2-1) &\text{if}\; n=6k+1 \;\text{or}\; n=6k+5 \\[4pt]  \frac1{12}(n^2-4) &\text{if}\; n=6k+2 \;\text{or}\; n=6k+4 \\[4pt] \frac1{12}(n^2+3) &\text{if}\; n=6k+3 \end{cases}\tag5$$ $p_3(n)$ is a mod $6$ formula. I managed to find also $p_4(n)$ , and it's a mod $12$ formula, A026810 . I suspect that $p_5(n)$ is a mod $15$ formula. While working in the case $n=15k+5$ , I found $$\begin{align} p_5(5) &=\frac13((\phantom{9}5 \cdot\phantom{99}0)+\phantom{9}\color{red}{3})+0 &&=1 \\[4pt] p_5(20)&=\frac13((20\cdot\phantom{9}12)+\phantom{9}\color{red}{9})+1 &&=84 \\[4pt] p_5(35)&=\frac13((35\cdot\phantom{9}57)+\color{red}{24})+1 &&=674 \\[4pt] p_5(50)&=\frac13((50\cdot156)+\color{red}{21})+4 &&=2611 \\[4pt] p_5(65)&=\frac13((65\cdot330)+\color{red}{36})+4 &&=7166 \\[4pt] p_5(80)&=\frac13((80\cdot600)+\color{red}{30})+9 &&=16019 \\[4pt] p_5(95)&=\frac13((95\cdot987)+\color{red}{75})+9 &&=31289\\[4pt] \cdots &= \cdots \end{align} \tag6$$ The sequence of multipliers: $0,12,57,156,330,600,987,\ldots$ is the sequence $3a(n)$ , with $a(n) = \frac16n(n + 1)(7n + 5)$ . The sequence: $0,1,1,4,4,9,9,\ldots$ is the squares sequence ( $0$ for $0$ ). Then the sequence $S_1$ appears highlighted in red. Any answer please?","In order to find a formula of the partition of an integer into 5 parts (see below), I find the sequence It's clear that is divisible by , so I got the sequence I can't figure out what's this sequence. I tried to divide the sequence into two other sequences: The odd sequence and the even sequence but yet I can't find any answer. More details: For example, the formula of the partition of an integer into 3 parts is A069905 is a mod formula. I managed to find also , and it's a mod formula, A026810 . I suspect that is a mod formula. While working in the case , I found The sequence of multipliers: is the sequence , with . The sequence: is the squares sequence ( for ). Then the sequence appears highlighted in red. Any answer please?","(6) S_1: 3,9,24,21,36,30,75,120,270,462,837,1320,2085,\ldots \tag1 S_1 3 S_2: 1,3,8,7,12,10,25,40,90,154,279,440,695,\ldots \tag2 S_3: 3,7,10,40,154,440,\ldots\tag3 S_4: 1,8,12,25,90,279,695,\ldots\tag4 p_3(n)=\begin{cases}
\frac1{12}n^2 &\text{if}\; n=6k \\[4pt]
\frac1{12}(n^2-1) &\text{if}\; n=6k+1 \;\text{or}\; n=6k+5 \\[4pt] 
\frac1{12}(n^2-4) &\text{if}\; n=6k+2 \;\text{or}\; n=6k+4 \\[4pt]
\frac1{12}(n^2+3) &\text{if}\; n=6k+3
\end{cases}\tag5 p_3(n) 6 p_4(n) 12 p_5(n) 15 n=15k+5 \begin{align}
p_5(5) &=\frac13((\phantom{9}5 \cdot\phantom{99}0)+\phantom{9}\color{red}{3})+0 &&=1 \\[4pt]
p_5(20)&=\frac13((20\cdot\phantom{9}12)+\phantom{9}\color{red}{9})+1 &&=84 \\[4pt]
p_5(35)&=\frac13((35\cdot\phantom{9}57)+\color{red}{24})+1 &&=674 \\[4pt]
p_5(50)&=\frac13((50\cdot156)+\color{red}{21})+4 &&=2611 \\[4pt]
p_5(65)&=\frac13((65\cdot330)+\color{red}{36})+4 &&=7166 \\[4pt]
p_5(80)&=\frac13((80\cdot600)+\color{red}{30})+9 &&=16019 \\[4pt]
p_5(95)&=\frac13((95\cdot987)+\color{red}{75})+9 &&=31289\\[4pt]
\cdots &= \cdots
\end{align} \tag6 0,12,57,156,330,600,987,\ldots 3a(n) a(n) = \frac16n(n + 1)(7n + 5) 0,1,1,4,4,9,9,\ldots 0 0 S_1","['sequences-and-series', 'integer-partitions']"
11,Variation of fat Cantor Sets -- Help needed with the sum of a sequence with relationship between $a_n$ and $S_{n-1}$,Variation of fat Cantor Sets -- Help needed with the sum of a sequence with relationship between  and,a_n S_{n-1},"I am having trouble with finding the infinite sum of the sequence $\{a_n\}$ with the relationship $$ a_1 = r, \; a_n = r^n(1-S_{n-1})$$ where $$ S_{n-1} = \sum_{k=1}^{n-1} a_k, \; 0<r<1$$ I tried to subtract $$S_{n-1} = 1- \frac{a_n}{r^n}$$ from $$S_{n} = 1- \frac{a_{n+1}}{r^{n+1}}$$ and after some simplification I got $$\frac{a_{n+1}}{a_n} = r(1-r^n)$$ Could anyone help me to calculate $\sum_{n=1}^\infty a_n$ based on the relationships above? Many thanks!! Edit: I thought this is a rather technical question so I didn't provide the background of why I am doing this in the first place. Now I see why it might help. I am considering a variation of 'fat Cantor sets' which is obtained by varying the ratio removed at each step. To be precise, starting from the unit interval $K_0 = [0,1]$ , we remove the middle open subinterval $G^1_1$ such that $\ell(G^1_1)/\ell(K_0) = r$ , for some $r \in (0,1)$ . Call the remaining intervals $K_1$ . Next, we remove the middle open subintervals $G^2_1$ and $G^2_2$ such that $\mu(G^2_1 \cup G^2_2)/\mu(K_1) = r^2$ . Continuing in this fashion such that the measure of intervals removed at step $n$ is of proportion $r^n$ to the measure of the original intervals. Denote $\mu(\bigcup_{m=1}^{2^{n-1}}G_m^n) = a_n$ the length of intervals removed at step $n$ , $n \geq 1$ . We therefore have the relation $a_n = r^n(1-S_{n-1})$ . In other words, the length of the subintervals removed at each step is of proportion $r^n$ to the original interval, which equals r^n*(1 - sum of the length of intervals removed in previous steps). I am interested in finding $\sum_{n=1}^\infty a_n$ , which is the total length removed in this construction.","I am having trouble with finding the infinite sum of the sequence with the relationship where I tried to subtract from and after some simplification I got Could anyone help me to calculate based on the relationships above? Many thanks!! Edit: I thought this is a rather technical question so I didn't provide the background of why I am doing this in the first place. Now I see why it might help. I am considering a variation of 'fat Cantor sets' which is obtained by varying the ratio removed at each step. To be precise, starting from the unit interval , we remove the middle open subinterval such that , for some . Call the remaining intervals . Next, we remove the middle open subintervals and such that . Continuing in this fashion such that the measure of intervals removed at step is of proportion to the measure of the original intervals. Denote the length of intervals removed at step , . We therefore have the relation . In other words, the length of the subintervals removed at each step is of proportion to the original interval, which equals r^n*(1 - sum of the length of intervals removed in previous steps). I am interested in finding , which is the total length removed in this construction.","\{a_n\}  a_1 = r, \; a_n = r^n(1-S_{n-1})  S_{n-1} = \sum_{k=1}^{n-1} a_k, \; 0<r<1 S_{n-1} = 1- \frac{a_n}{r^n} S_{n} = 1- \frac{a_{n+1}}{r^{n+1}} \frac{a_{n+1}}{a_n} = r(1-r^n) \sum_{n=1}^\infty a_n K_0 = [0,1] G^1_1 \ell(G^1_1)/\ell(K_0) = r r \in (0,1) K_1 G^2_1 G^2_2 \mu(G^2_1 \cup G^2_2)/\mu(K_1) = r^2 n r^n \mu(\bigcup_{m=1}^{2^{n-1}}G_m^n) = a_n n n \geq 1 a_n = r^n(1-S_{n-1}) r^n \sum_{n=1}^\infty a_n","['real-analysis', 'sequences-and-series', 'general-topology']"
12,Proving if $a_{k}\ge a_{k-1}+1$ then $1+\frac{1}{a_{0}}(1+\frac{1}{a_{1}-a_{0}})...(1+\frac{1}{a_{n}-a_{0}})\le \prod_{k=0}^{n}(1+\frac{1}{a_{k}})$,Proving if  then,a_{k}\ge a_{k-1}+1 1+\frac{1}{a_{0}}(1+\frac{1}{a_{1}-a_{0}})...(1+\frac{1}{a_{n}-a_{0}})\le \prod_{k=0}^{n}(1+\frac{1}{a_{k}}),"I've worked on this problem with the sequence $a_{k}$ being the natural numbers, that is $a_{k}=a_{k-1}+1$ and $a_{0}=1$ . Over the naturals, $\prod_{k=0}^{n}(1+\frac{1}{a_{k}})$ can be proven to be $n+1$ . I've been able to recognize the obvious pattern in $\prod_{k=2}^{n}(1+\frac{1}{k-1})$ to be equal to $n$ , but I do not know how to prove this rigorously. That said, over the naturals, the inequality reduces to $n+1 \le n+1$ . That got me thinking if the sequence in question could be expanded with the condition $a_{k}\ge a_{k-1}+1$ and specifically if this would not lead to the situation corresponding with RHS being greater than LHS. Thank you for your help.","I've worked on this problem with the sequence being the natural numbers, that is and . Over the naturals, can be proven to be . I've been able to recognize the obvious pattern in to be equal to , but I do not know how to prove this rigorously. That said, over the naturals, the inequality reduces to . That got me thinking if the sequence in question could be expanded with the condition and specifically if this would not lead to the situation corresponding with RHS being greater than LHS. Thank you for your help.",a_{k} a_{k}=a_{k-1}+1 a_{0}=1 \prod_{k=0}^{n}(1+\frac{1}{a_{k}}) n+1 \prod_{k=2}^{n}(1+\frac{1}{k-1}) n n+1 \le n+1 a_{k}\ge a_{k-1}+1,"['sequences-and-series', 'inequality', 'products']"
13,Evaluate $\lim\limits_{n\to\infty} \frac{\sin(1)+\sin^2(\frac{1}{2})+\ldots+\sin^n(\frac{1}{n})}{\frac{1}{1!}+\frac{1}{2!}+\ldots+\frac{1}{n!}}$,Evaluate,\lim\limits_{n\to\infty} \frac{\sin(1)+\sin^2(\frac{1}{2})+\ldots+\sin^n(\frac{1}{n})}{\frac{1}{1!}+\frac{1}{2!}+\ldots+\frac{1}{n!}},"This was a recent problem on the Awesome Math Problem Column. The solution is given as follows: We shall use Stolz-Cesaro Lemma . We have: $$\lim_{n\to\infty} \frac{\sin(1)+\sin^2(\frac{1}{2})+\ldots+\sin^n(\frac{1}{n})}{\frac{1}{1!}+\frac{1}{2!}+\ldots+\frac{1}{n!}}$$ $$=\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n!}}=\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n^n}}\cdot\lim_{n\to\infty} \frac{n!}{n^n}.$$ Since $$\frac{n!}{n^n}<\frac{1}{n}$$ we have $$\lim_{n\to\infty}\frac{n!}{n^n}=0$$ So, the required limit is $0$ . I have two problems with the given proof that I can’t wrap my head around. Firstly, from everything I have read so far the Stolz-Cesaro limit only applies to cases where the limit is of the form $\frac{0}{0}$ and the form $\frac{\cdot}{\infty}$ . However, just from the wording of the theorem and the way the author presented this solution both seem to imply the following: $$a_n=\sum_{k=1}^n \sin^k\Big(\frac{1}{k}\Big), \ \ \  \text{and} \ \ \ b_n=\sum_{k=1}^n \frac{1}{k!}$$ Then when “applying” the Stolz-Cesaro theorem you would have: $$\lim_{n\to\infty} \frac{a_n-a_{n-1}}{b_n-b_{n-1}}=\lim_{n\to\infty} \frac{\sum\limits_{k=1}^{n} \sin^k(\frac{1}{k})-\sum\limits_{k=1}^{n-1} \sin^k(\frac{1}{k})}{\sum\limits_{k=1}^n \frac{1}{k!}-\sum\limits_{k=1}^{n-1} \frac{1}{k!}}=\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n!}}$$ The problem that I see is when $n\to\infty$ we know that $a_n$ converges by the root test, and $b_n$ converges to $e-1$ . So by basic limit rules this would converge also. So it seems that $b_n$ does not satisfy either of the sequence requirements of the Stolz-Cesaro Theorem. Secondly, according to wolfram $\displaystyle\sum_{n=1}^\infty \sin^n\Big(\frac{1}{n}\Big)\approx 1.11043$ . So intuitively it seems to me that this limit would be approximately $\frac{1.11043}{e-1}\approx 0.646244$ . Does anyone know what is going on here?","This was a recent problem on the Awesome Math Problem Column. The solution is given as follows: We shall use Stolz-Cesaro Lemma . We have: Since we have So, the required limit is . I have two problems with the given proof that I can’t wrap my head around. Firstly, from everything I have read so far the Stolz-Cesaro limit only applies to cases where the limit is of the form and the form . However, just from the wording of the theorem and the way the author presented this solution both seem to imply the following: Then when “applying” the Stolz-Cesaro theorem you would have: The problem that I see is when we know that converges by the root test, and converges to . So by basic limit rules this would converge also. So it seems that does not satisfy either of the sequence requirements of the Stolz-Cesaro Theorem. Secondly, according to wolfram . So intuitively it seems to me that this limit would be approximately . Does anyone know what is going on here?","\lim_{n\to\infty} \frac{\sin(1)+\sin^2(\frac{1}{2})+\ldots+\sin^n(\frac{1}{n})}{\frac{1}{1!}+\frac{1}{2!}+\ldots+\frac{1}{n!}} =\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n!}}=\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n^n}}\cdot\lim_{n\to\infty} \frac{n!}{n^n}. \frac{n!}{n^n}<\frac{1}{n} \lim_{n\to\infty}\frac{n!}{n^n}=0 0 \frac{0}{0} \frac{\cdot}{\infty} a_n=\sum_{k=1}^n \sin^k\Big(\frac{1}{k}\Big), \ \ \  \text{and} \ \ \ b_n=\sum_{k=1}^n \frac{1}{k!} \lim_{n\to\infty} \frac{a_n-a_{n-1}}{b_n-b_{n-1}}=\lim_{n\to\infty} \frac{\sum\limits_{k=1}^{n} \sin^k(\frac{1}{k})-\sum\limits_{k=1}^{n-1} \sin^k(\frac{1}{k})}{\sum\limits_{k=1}^n \frac{1}{k!}-\sum\limits_{k=1}^{n-1} \frac{1}{k!}}=\lim_{n\to\infty}\frac{\sin^n(\frac{1}{n})}{\frac{1}{n!}} n\to\infty a_n b_n e-1 b_n \displaystyle\sum_{n=1}^\infty \sin^n\Big(\frac{1}{n}\Big)\approx 1.11043 \frac{1.11043}{e-1}\approx 0.646244","['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence', 'closed-form']"
14,$\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}}$ [duplicate],[duplicate],\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}},"This question already has answers here : Infinite Series $\sum\limits_{n=1}^{\infty}\frac{1}{4^n\cos^2\frac{x}{2^n}}$ (3 answers) Closed 3 years ago . $\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}}$ How can I calculate this? Since there are $4^n$ and $\cos^2x$ , I tried: $$\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}} = 4\sum_{n=1}^{\infty}{\frac{\sin^2{\frac{\pi}{4 \cdot 2^n}}}{4^{n}\sin^2{\frac{\pi}{4\cdot2^{n-1}}}}}$$ to use $2\sin x \cos x = \sin2x$","This question already has answers here : Infinite Series $\sum\limits_{n=1}^{\infty}\frac{1}{4^n\cos^2\frac{x}{2^n}}$ (3 answers) Closed 3 years ago . How can I calculate this? Since there are and , I tried: to use",\sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}} 4^n \cos^2x \sum_{n=1}^{\infty} {\frac{1}{4^n \cos^2 (\frac{\pi}{2^{n+2}})}} = 4\sum_{n=1}^{\infty}{\frac{\sin^2{\frac{\pi}{4 \cdot 2^n}}}{4^{n}\sin^2{\frac{\pi}{4\cdot2^{n-1}}}}} 2\sin x \cos x = \sin2x,"['sequences-and-series', 'algebra-precalculus', 'trigonometry', 'summation']"
15,Infinite positive integer sequence with distinctive sum of digits,Infinite positive integer sequence with distinctive sum of digits,,"I am looking at this problem. Interestingly most problems on that site has solutions except this one, thus I am asking here. https://www.komal.hu/feladat?a=feladat&f=A728&l=en Essentially, for question (a), we are asked to construct an infinite positive integer sequence $\{ a_i \}$ such that $a_{i+1} \leq 2a_i$ , and the sums of decimal digits of each item in the integer sequence are distinct.  For question (b), we are ask to prove if this is possible for binary digits . I am not even sure if question (a) is feasible at all. We will probably want to guarantee that the sum of digits is ascending as well, because otherwise we will run of of numbers eventually. Since if we ever had digit $9$ as the last digit, say $99$ , then from 99 to $2*99$ , there is no number with sum of digits greater than $18$ . But it seems like I will always hit a number with last digit = 9 however I construct my series","I am looking at this problem. Interestingly most problems on that site has solutions except this one, thus I am asking here. https://www.komal.hu/feladat?a=feladat&f=A728&l=en Essentially, for question (a), we are asked to construct an infinite positive integer sequence such that , and the sums of decimal digits of each item in the integer sequence are distinct.  For question (b), we are ask to prove if this is possible for binary digits . I am not even sure if question (a) is feasible at all. We will probably want to guarantee that the sum of digits is ascending as well, because otherwise we will run of of numbers eventually. Since if we ever had digit as the last digit, say , then from 99 to , there is no number with sum of digits greater than . But it seems like I will always hit a number with last digit = 9 however I construct my series",\{ a_i \} a_{i+1} \leq 2a_i 9 99 2*99 18,"['sequences-and-series', 'elementary-number-theory', 'contest-math']"
16,Consistency of summation methods,Consistency of summation methods,,"Two summation methods $\Sigma_1, \Sigma_2 : (\mathbb{N} \rightarrow \mathbb{C}) \rightharpoonup \mathbb{C}$ are consistent iff $\Sigma_1 \cup \Sigma_2$ is functional (right-unique), i.e. $$ \forall x \in (\operatorname{dom} \Sigma_1 \cap \operatorname{dom} \Sigma_2) : \Sigma_1(x) = \Sigma_2(x) $$ Many of the well-known summation methods (Cesàro summation, Abel summation, Borel summation, Euler summation, etc.) turn out to be consistent with each other. Are there any examples of mutually inconsistent summation methods that are not ad hoc , i.e. motivated by or constructed for the purpose of being mutually inconsistent? If not, is there some explanation behind this fact? Is it possible there's some kind of ideal ""general summation"" that all these methods are approaching? Note that this is different from the question of non-constructive extensions such as those given by the Hahn-Banach theorem .","Two summation methods are consistent iff is functional (right-unique), i.e. Many of the well-known summation methods (Cesàro summation, Abel summation, Borel summation, Euler summation, etc.) turn out to be consistent with each other. Are there any examples of mutually inconsistent summation methods that are not ad hoc , i.e. motivated by or constructed for the purpose of being mutually inconsistent? If not, is there some explanation behind this fact? Is it possible there's some kind of ideal ""general summation"" that all these methods are approaching? Note that this is different from the question of non-constructive extensions such as those given by the Hahn-Banach theorem .","\Sigma_1, \Sigma_2 : (\mathbb{N} \rightarrow \mathbb{C}) \rightharpoonup \mathbb{C} \Sigma_1 \cup \Sigma_2  \forall x \in (\operatorname{dom} \Sigma_1 \cap \operatorname{dom} \Sigma_2) : \Sigma_1(x) = \Sigma_2(x) ","['sequences-and-series', 'summation', 'divergent-series', 'summation-method']"
17,Arithmetic Progression Question (involving modulus inequalities and equations),Arithmetic Progression Question (involving modulus inequalities and equations),,OPTIONS: A) 10 B) 15 C) 25 D) None of the above,OPTIONS: A) 10 B) 15 C) 25 D) None of the above,,"['sequences-and-series', 'algebra-precalculus', 'elementary-set-theory', 'inequality', 'arithmetic-progressions']"
18,Question about decreasing sequence.,Question about decreasing sequence.,,"Problem : Imagine an infinite chessboard that contains a positive integer in each square. If the value of each square is equal to the average of its four neighbors to the north, south, west, and east, prove that the values in all the squares are equal. I understood the problem can be proved by using the decreasing sequence. I think it is false when 'positive integer' changed to 'positive real number', but I can't prove it. Question : Is it still true when 'positive integer' changed to 'positive real number'? Thank you for your advice.","Problem : Imagine an infinite chessboard that contains a positive integer in each square. If the value of each square is equal to the average of its four neighbors to the north, south, west, and east, prove that the values in all the squares are equal. I understood the problem can be proved by using the decreasing sequence. I think it is false when 'positive integer' changed to 'positive real number', but I can't prove it. Question : Is it still true when 'positive integer' changed to 'positive real number'? Thank you for your advice.",,['sequences-and-series']
19,Prove $ \sum\limits_{k = 1}^{n} ( - 1)^{\lfloor k\alpha \rfloor}$ is unbounded where $\alpha$ is irrational.,Prove  is unbounded where  is irrational., \sum\limits_{k = 1}^{n} ( - 1)^{\lfloor k\alpha \rfloor} \alpha,"Obviously, value of $ ( - 1)^{\lfloor k\alpha \rfloor}$ depends on $ \{k\alpha\}$ . This sequence is uniformly distrubuted $ \mod 1$ . We have $ \sum\limits_{k = 1}^{n} ( - 1)^{\lfloor k\alpha \rfloor} = \sum\limits_{k = 1}^{n} f\left(k\frac {\alpha}{2} \right)$ , where $ f$ is defined by $ f(x) = \left\{\begin{array}{cc} 1 & 0\leqslant x < \frac {1}{2} \\ -1 & \frac {1}{2}\leqslant x < 1 \end{array} \right.$ How to go on with this?","Obviously, value of depends on . This sequence is uniformly distrubuted . We have , where is defined by How to go on with this?"," ( - 1)^{\lfloor k\alpha \rfloor}  \{k\alpha\}  \mod 1  \sum\limits_{k = 1}^{n} ( - 1)^{\lfloor k\alpha \rfloor} = \sum\limits_{k = 1}^{n} f\left(k\frac {\alpha}{2} \right)  f  f(x) = \left\{\begin{array}{cc} 1 & 0\leqslant x < \frac {1}{2} \\
-1 & \frac {1}{2}\leqslant x < 1 \end{array} \right.","['calculus', 'sequences-and-series', 'limits']"
20,Calculus 2: Series Integration,Calculus 2: Series Integration,,I do not understand how $\int \sum_{n=0}^\infty (-1)^nx^{2n}dx = \sum_{n=0}^\infty  (\frac{(-1)^nx^{2n+1}}{2n+1})+C$ . Here are my steps: $$\int \sum_{n=0}^\infty  (-1)^nx^{2n}dx$$ $$=\sum_{n=0}^\infty  (-1)^n\int x^{2n}dx$$ $$=\sum_{n=0}^\infty  (-1)^n(\frac{x^{2n+1}}{2n+1}+K)$$ $$=\sum_{n=0}^\infty  (\frac{(-1)^nx^{2n+1}}{2n+1}+C)$$ The constant $C$ cannot be separated from the series. It is a part of the sequence that makes up the series.,I do not understand how . Here are my steps: The constant cannot be separated from the series. It is a part of the sequence that makes up the series.,\int \sum_{n=0}^\infty (-1)^nx^{2n}dx = \sum_{n=0}^\infty  (\frac{(-1)^nx^{2n+1}}{2n+1})+C \int \sum_{n=0}^\infty  (-1)^nx^{2n}dx =\sum_{n=0}^\infty  (-1)^n\int x^{2n}dx =\sum_{n=0}^\infty  (-1)^n(\frac{x^{2n+1}}{2n+1}+K) =\sum_{n=0}^\infty  (\frac{(-1)^nx^{2n+1}}{2n+1}+C) C,[]
21,Determining the value of $\sum_{n=2}^\infty \frac{1}{n^n-1}$,Determining the value of,\sum_{n=2}^\infty \frac{1}{n^n-1},"$$\displaystyle\sum_{n=1}^\infty\sum_{m=2}^\infty \frac{1}{m^{mn}}=\sum_{n=1}^\infty\left(\frac{1}{2^{2n}}+\frac{1}{3^{3n}}+\frac{1}{4^{4n}}+\cdots\right) \tag{$\star$}$$ I have a strong suspicion that the above summation converges, although I'm not sure how to prove it. But I'm more interested in the precise value of $(\star)$ , especially a nice representation (if possible). Here's what I have so far: \begin{align} \sum_{n=1}^\infty\left(\frac{1}{2^{2n}}+\frac{1}{3^{3n}}+\frac{1}{4^{4n}}+\cdots\right) & = \sum_{n=1}^\infty\frac{1}{2^{2n}}+\sum_{n=1}^\infty\frac{1}{3^{3n}}+\sum_{n=1}^\infty\frac{1}{4^{4n}}+\cdots \\ & = \sum_{n=1}^\infty\frac{1}{\left(2^{2}\right)^n}+\sum_{n=1}^\infty\frac{1}{\left(3^{3}\right)^n}+\sum_{n=1}^\infty\frac{1}{\left(4^{4}\right)^n}+\cdots \\ & = \frac{1}{2^2-1}+\frac{1}{3^3-1}+\frac{1}{4^4-1}+\cdots\\ & =\sum_{n=2}^\infty \frac{1}{n^n-1}  \end{align} So $(\star)=\displaystyle\sum_{n=2}^\infty \frac{1}{n^n-1}$ . From here, all I know how to do is get an approximate value of the solution. How would you go about finding its exact value?","I have a strong suspicion that the above summation converges, although I'm not sure how to prove it. But I'm more interested in the precise value of , especially a nice representation (if possible). Here's what I have so far: So . From here, all I know how to do is get an approximate value of the solution. How would you go about finding its exact value?","\displaystyle\sum_{n=1}^\infty\sum_{m=2}^\infty \frac{1}{m^{mn}}=\sum_{n=1}^\infty\left(\frac{1}{2^{2n}}+\frac{1}{3^{3n}}+\frac{1}{4^{4n}}+\cdots\right) \tag{\star} (\star) \begin{align}
\sum_{n=1}^\infty\left(\frac{1}{2^{2n}}+\frac{1}{3^{3n}}+\frac{1}{4^{4n}}+\cdots\right) & = \sum_{n=1}^\infty\frac{1}{2^{2n}}+\sum_{n=1}^\infty\frac{1}{3^{3n}}+\sum_{n=1}^\infty\frac{1}{4^{4n}}+\cdots \\ & = \sum_{n=1}^\infty\frac{1}{\left(2^{2}\right)^n}+\sum_{n=1}^\infty\frac{1}{\left(3^{3}\right)^n}+\sum_{n=1}^\infty\frac{1}{\left(4^{4}\right)^n}+\cdots \\ & = \frac{1}{2^2-1}+\frac{1}{3^3-1}+\frac{1}{4^4-1}+\cdots\\ & =\sum_{n=2}^\infty \frac{1}{n^n-1} 
\end{align} (\star)=\displaystyle\sum_{n=2}^\infty \frac{1}{n^n-1}",['sequences-and-series']
22,Does there exist a sequence of continuous functions converging to $f$?,Does there exist a sequence of continuous functions converging to ?,f,"Let $g:\mathbb{N}\to\mathbb{Q}$ be a bijection. Let $f:\mathbb{R}\to\mathbb{R}$ be defined in the following way: $$f(x)=\begin{cases} 1/g^{-1}(x) & x\in\mathbb{Q}\\ 0 &x\not\in\mathbb{Q} \end{cases}$$ I have shown that $f$ is continuous at each $x\not\in\mathbb{Q}$ and not continuous at each $x\in\mathbb{Q}$ . However, I am wondering if there is a sequence $\{f_n\}$ of continuous functions which converges pointwise to $f$ . I would imagine that if there was, it would be similar to the construction in this question , concerning Thomae's function, but I cannot make that work because Thomae's function is constructed differently. A hint would be appreciated.","Let be a bijection. Let be defined in the following way: I have shown that is continuous at each and not continuous at each . However, I am wondering if there is a sequence of continuous functions which converges pointwise to . I would imagine that if there was, it would be similar to the construction in this question , concerning Thomae's function, but I cannot make that work because Thomae's function is constructed differently. A hint would be appreciated.","g:\mathbb{N}\to\mathbb{Q} f:\mathbb{R}\to\mathbb{R} f(x)=\begin{cases}
1/g^{-1}(x) & x\in\mathbb{Q}\\
0 &x\not\in\mathbb{Q}
\end{cases} f x\not\in\mathbb{Q} x\in\mathbb{Q} \{f_n\} f",['real-analysis']
23,Family indexed by $\mathbb{N}$ vs sequence,Family indexed by  vs sequence,\mathbb{N},"Possibly a trivial question, but no harm in asking: I am reading around and some notes mention a ""family of random variables $\{X_n\}$ where $n\in \mathbb{N}$ "". Is this the same as the sequence of random variables $(X_n)_{n\ge 1}$ ? The curly brackets and use of the word family seem to indicate that there is no specific order (since in other sections he talks about sequences of random variables), but this seems to not make much sense because in the end the author ends up proving limiting results like the central limit theorem etc. Thanks!","Possibly a trivial question, but no harm in asking: I am reading around and some notes mention a ""family of random variables where "". Is this the same as the sequence of random variables ? The curly brackets and use of the word family seem to indicate that there is no specific order (since in other sections he talks about sequences of random variables), but this seems to not make much sense because in the end the author ends up proving limiting results like the central limit theorem etc. Thanks!",\{X_n\} n\in \mathbb{N} (X_n)_{n\ge 1},"['sequences-and-series', 'probability-theory', 'notation', 'random-variables', 'nets']"
24,if such $(2n+4)x_{n+2}=b(2n+3)x_{n+1}+2a(n+1)x_{n}$ show $x_{n}\in Z$,if such  show,(2n+4)x_{n+2}=b(2n+3)x_{n+1}+2a(n+1)x_{n} x_{n}\in Z,"let $a,b$ be  integer,and such $a\equiv 0,b\equiv 0\pmod 4$ ,and sequece $x_{n}$ ,such $x_{0}=1,x_{1}=\dfrac{b}{2}$ and such $$(2n+4)x_{n+2}=b(2n+3)x_{n+1}+2\cdot a\cdot(n+1)x_{n}$$ show that $$x_{n}\in Z$$ I'm not sure I was wrong： I try let $$f(t)=\sum_{n=0}^{+\infty}x_{n}t^n$$ ,then $$f'(t)=\sum_{n=0}^{+\infty}nx_{n}t^{n-1}=\sum_{n=0}^{+\infty}(n+1)x_{n+1}t^n$$ ,so we have $$\sum_{n=0}^{+\infty}2(n+2)t^{n+2}=2(tf'(t)-\dfrac{b}{2}t)$$ other hand we have $$\sum_{n=0}^{+\infty}2(n+2)t^{n+2}=\sum_{n=0}^{+\infty}[b(2n+3)x_{n+1}+2a(n+1)x_{n}]t^{n+2}=2bt^2f'(t)+bt(f(t)-1)+2a(tf'(t)+tf(t))$$ so we have $$2tf'(t)-bt=2bt^2f'(t)+btf(t)-bt+2atf'(t)+2atf(t)$$ so we have $$(2-2bt-2a)f'(t)=(b+2a)f(t)$$ so we have $$(ln(f(t)))'=\dfrac{b+2a}{2-2bt-2a}$$ I fell I have wrong","let be  integer,and such ,and sequece ,such and such show that I'm not sure I was wrong： I try let ,then ,so we have other hand we have so we have so we have so we have I fell I have wrong","a,b a\equiv 0,b\equiv 0\pmod 4 x_{n} x_{0}=1,x_{1}=\dfrac{b}{2} (2n+4)x_{n+2}=b(2n+3)x_{n+1}+2\cdot a\cdot(n+1)x_{n} x_{n}\in Z f(t)=\sum_{n=0}^{+\infty}x_{n}t^n f'(t)=\sum_{n=0}^{+\infty}nx_{n}t^{n-1}=\sum_{n=0}^{+\infty}(n+1)x_{n+1}t^n \sum_{n=0}^{+\infty}2(n+2)t^{n+2}=2(tf'(t)-\dfrac{b}{2}t) \sum_{n=0}^{+\infty}2(n+2)t^{n+2}=\sum_{n=0}^{+\infty}[b(2n+3)x_{n+1}+2a(n+1)x_{n}]t^{n+2}=2bt^2f'(t)+bt(f(t)-1)+2a(tf'(t)+tf(t)) 2tf'(t)-bt=2bt^2f'(t)+btf(t)-bt+2atf'(t)+2atf(t) (2-2bt-2a)f'(t)=(b+2a)f(t) (ln(f(t)))'=\dfrac{b+2a}{2-2bt-2a}",['sequences-and-series']
25,"Determine all sequences $a_1, a_2, a_3, . . . $ of nonnegative integers such that $a_1 \lt a_2 \lt a_3 \lt · · ·$",Determine all sequences  of nonnegative integers such that,"a_1, a_2, a_3, . . .  a_1 \lt a_2 \lt a_3 \lt · · ·","Determine all sequences $a_1, a_2, a_3, . . . $ of nonnegative integers such that $a_1 \lt a_2 \lt a_3 \lt · · ·$ and $a_n$ divides $a_{n-1}+n$ for all $n\ge2$ . I know that one obvious possible sequence is $a_n=a_{n-1}+n$ but I don't know how to prove this is the only one or if there is more from the 2018 SAMO senior round 3 http://www.samf.ac.za/content/files/QuestionPapers/s3q2018.pdf",Determine all sequences of nonnegative integers such that and divides for all . I know that one obvious possible sequence is but I don't know how to prove this is the only one or if there is more from the 2018 SAMO senior round 3 http://www.samf.ac.za/content/files/QuestionPapers/s3q2018.pdf,"a_1, a_2, a_3, . . .  a_1 \lt a_2 \lt a_3 \lt · · · a_n a_{n-1}+n n\ge2 a_n=a_{n-1}+n","['sequences-and-series', 'number-theory', 'problem-solving']"
26,Summation Involving Product Of Two Identical Polynomials.,Summation Involving Product Of Two Identical Polynomials.,,"Recently I stuck, to a problem. However I rarely think that there is some proper formula for this problem, but here I am in search of algorithm's or theorem that relate to this problem or can solve this problem. We have three integers  positive integers $a, b, n$ and we need to compute this summation: $$\sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)(k^b - {(k - 1)}^b)}$$ It looks simple, if we try to solve it using computer, but real problem lies in it's constraints: $$n < 10^{12}$$ $$a < 10^4$$ $$b < 10^4$$ Clearly, we cannot iterate from $k = 1$ to $k = n$ , thus we need to think of an algorithm that solve it in constant time or in complexity in terms of $a$ and $b$ One can easily find relation like this $\sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)} = n^a$ but the problem has product of two such terms. So, Please give me some suggestion to solve this problem.","Recently I stuck, to a problem. However I rarely think that there is some proper formula for this problem, but here I am in search of algorithm's or theorem that relate to this problem or can solve this problem. We have three integers  positive integers and we need to compute this summation: It looks simple, if we try to solve it using computer, but real problem lies in it's constraints: Clearly, we cannot iterate from to , thus we need to think of an algorithm that solve it in constant time or in complexity in terms of and One can easily find relation like this but the problem has product of two such terms. So, Please give me some suggestion to solve this problem.","a, b, n \sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)(k^b - {(k - 1)}^b)} n < 10^{12} a < 10^4 b < 10^4 k = 1 k = n a b \sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)} = n^a","['calculus', 'sequences-and-series', 'combinatorics', 'algorithms', 'summation-method']"
27,How long does it take for this sequence to obtain this loop?,How long does it take for this sequence to obtain this loop?,,"For positive integers $m,n$ , define a sequence $S_m(n)$ so that $S_m(1)=m$ , $S_m(n+1)=S_m(n)^2-1$ if $S_m(n)$ is prime, and $S_m(n+1)$ is the greatest prime factor of $S_m(n)$ otherwise. It is clear that, regardless of $m$ , this sequence always gets caught in the infinite loop $2,3,8,2,3,\dots$ , because for any prime $p$ , $p^2-1=(p+1)(p-1)$ and if $p\neq 2$ then the greatest prime factor of this term is at most $\lceil p/2\rceil<p$ . What is less clear, is the rate at which the sequence becomes stuck into that loop. If we define $t(m)$ to be the smallest integer $n$ so that $S_m(n)=2$ , then how does $t(m)$ grow? By some numerical testing I've found that $t(m)<20$ for all $m<10000$ , which seems to suggest a logarithmic growth speed. In particular, for any positive integer $N$ , is it always true that there exists an $m$ so that $t(m)>N$ ? Any thoughts are appreciated!","For positive integers , define a sequence so that , if is prime, and is the greatest prime factor of otherwise. It is clear that, regardless of , this sequence always gets caught in the infinite loop , because for any prime , and if then the greatest prime factor of this term is at most . What is less clear, is the rate at which the sequence becomes stuck into that loop. If we define to be the smallest integer so that , then how does grow? By some numerical testing I've found that for all , which seems to suggest a logarithmic growth speed. In particular, for any positive integer , is it always true that there exists an so that ? Any thoughts are appreciated!","m,n S_m(n) S_m(1)=m S_m(n+1)=S_m(n)^2-1 S_m(n) S_m(n+1) S_m(n) m 2,3,8,2,3,\dots p p^2-1=(p+1)(p-1) p\neq 2 \lceil p/2\rceil<p t(m) n S_m(n)=2 t(m) t(m)<20 m<10000 N m t(m)>N","['sequences-and-series', 'elementary-number-theory']"
28,Calculating $S=\sum\limits_{n=1}^\infty\left(\frac{1}{\Gamma^2(n+1)}\right)^{{1}/{n}}$,Calculating,S=\sum\limits_{n=1}^\infty\left(\frac{1}{\Gamma^2(n+1)}\right)^{{1}/{n}},I tried to find the answer for the question: Numerical evaluation of $\sum_{N=1}^\infty\left(\frac{1}{\Gamma(N+1)^2}\right)^{\frac{1}{N}}$ . I think my result is $4$ times than the expected value. Is this accidental and my solution is not correct? Does my solution have theoretical or some inattention fault? The solution is: $S=\sum\limits_{n=1}^\infty\left(\frac{1}{\Gamma^2(n+1)}\right)^{{1}/{n}}=\sum\limits_{n=1}^\infty\left(\frac{1}{n!^2)}\right)^{{1}/{n}}=\sum\limits_{n=1}^\infty \prod\limits_{k=1}^n k^{-2/n}$ $S=\sum\limits_{n=1}^\infty e^{\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{1}{k})} $ From the exponent we get: ${\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{1}{k})}={\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{n}{k} \frac{1}{n})}=\frac{2}{n}\sum\limits_{k=1}^n \ln\frac{n}{k}+\frac{2}{n}\sum\limits_{k=1}^n \ln \frac{1}{n}$ The first term of the exponent is Riemann sum so we get: $2\int\limits _0^1\ln\frac{1}{x} dx= 2$ Put back into the sum: $S=\sum\limits_{n=1}^\infty e^{2-\frac{2}{n} n \ln{n}}=\sum\limits_{n=1}^\infty \frac {e^{2}}{n^2}=\zeta(2)e^2 $,I tried to find the answer for the question: Numerical evaluation of . I think my result is times than the expected value. Is this accidental and my solution is not correct? Does my solution have theoretical or some inattention fault? The solution is: From the exponent we get: The first term of the exponent is Riemann sum so we get: Put back into the sum:,\sum_{N=1}^\infty\left(\frac{1}{\Gamma(N+1)^2}\right)^{\frac{1}{N}} 4 S=\sum\limits_{n=1}^\infty\left(\frac{1}{\Gamma^2(n+1)}\right)^{{1}/{n}}=\sum\limits_{n=1}^\infty\left(\frac{1}{n!^2)}\right)^{{1}/{n}}=\sum\limits_{n=1}^\infty \prod\limits_{k=1}^n k^{-2/n} S=\sum\limits_{n=1}^\infty e^{\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{1}{k})}  {\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{1}{k})}={\frac{2}{n}\sum\limits_{k=1}^n \ln(\frac{n}{k} \frac{1}{n})}=\frac{2}{n}\sum\limits_{k=1}^n \ln\frac{n}{k}+\frac{2}{n}\sum\limits_{k=1}^n \ln \frac{1}{n} 2\int\limits _0^1\ln\frac{1}{x} dx= 2 S=\sum\limits_{n=1}^\infty e^{2-\frac{2}{n} n \ln{n}}=\sum\limits_{n=1}^\infty \frac {e^{2}}{n^2}=\zeta(2)e^2 ,"['sequences-and-series', 'summation', 'gamma-function', 'riemann-integration', 'zeta-functions']"
29,On convergence of sums of the form $\sum_{n=1}^{\infty}\frac{1}{n^{1+f(n)}}$,On convergence of sums of the form,\sum_{n=1}^{\infty}\frac{1}{n^{1+f(n)}},"The p-series convergence test is a classic and well-known result for sums of the form $\sum_{n=1}^{\infty}\frac{1}{n^p}$ for a real number $p$ . It is known that $\sum_{n=1}^{\infty}\frac{1}{n}$ diverges, but for every $\epsilon>0$ , $\sum_{n=1}^{\infty}\frac{1}{n^{1+\epsilon}}$ converges. It can be shown that series with terms asymptotically smaller than this will also converge, such as $$\sum_{n=2}^{\infty}\frac{1}{n\log^2n}\text{ and even }\sum_{n=2}^{\infty}\frac{1}{n\log^{1+\epsilon}n}\text{ for }\epsilon>0$$ I was introduced to a related series by a coworker of mine, which is the following: $$\sum_{n=1}^{\infty}\frac{1}{n^{1+\sin n}}$$ Supposedly, he was able to prove that this diverged. A natural generalization is to look at series of the form $$\sum_{n=1}^{\infty}\frac{1}{n^{c+\sin n}}$$ for some $c>0$ . It is not hard to show that the series diverges when $c\leq0$ and converges when $c\geq2$ . What I want is to find the smallest value of $c$ such that the series converges, or a tight lower bound. Formally, I want to find $$\inf\left\{c\,:\,\sum_{n=1}^{\infty}\frac{1}{n^{c+\sin n}}<\infty\right\}$$ Any progress on finding this number is appreciated. I would assume that it is greater than 1, but I haven't been able to prove much else.","The p-series convergence test is a classic and well-known result for sums of the form for a real number . It is known that diverges, but for every , converges. It can be shown that series with terms asymptotically smaller than this will also converge, such as I was introduced to a related series by a coworker of mine, which is the following: Supposedly, he was able to prove that this diverged. A natural generalization is to look at series of the form for some . It is not hard to show that the series diverges when and converges when . What I want is to find the smallest value of such that the series converges, or a tight lower bound. Formally, I want to find Any progress on finding this number is appreciated. I would assume that it is greater than 1, but I haven't been able to prove much else.","\sum_{n=1}^{\infty}\frac{1}{n^p} p \sum_{n=1}^{\infty}\frac{1}{n} \epsilon>0 \sum_{n=1}^{\infty}\frac{1}{n^{1+\epsilon}} \sum_{n=2}^{\infty}\frac{1}{n\log^2n}\text{ and even }\sum_{n=2}^{\infty}\frac{1}{n\log^{1+\epsilon}n}\text{ for }\epsilon>0 \sum_{n=1}^{\infty}\frac{1}{n^{1+\sin n}} \sum_{n=1}^{\infty}\frac{1}{n^{c+\sin n}} c>0 c\leq0 c\geq2 c \inf\left\{c\,:\,\sum_{n=1}^{\infty}\frac{1}{n^{c+\sin n}}<\infty\right\}","['calculus', 'real-analysis', 'sequences-and-series', 'divergent-series']"
30,Computing Airy functions through their Taylor series,Computing Airy functions through their Taylor series,,"I've been trying to find good methods for numerically computing Airy functions, and I found that for small arguments it's convenient to use their Taylor series expansions: $$\text{Ai} (z)=\frac{1}{3^{2/3} \pi} \sum_{n=0}^{\infty} \frac{\Gamma(1/3(n+1))}{n!}(3^{1/3}z)^n \sin[(2(n+1)\pi)/3]$$ $$\text{Bi} (z)=\frac{1}{3^{1/6} \pi} \sum_{n=0}^{\infty} \frac{\Gamma(1/3(n+1))}{n!}(3^{1/3}z)^n |\sin[(2(n+1)\pi)/3]|$$ While these expansions are inconvenient for direct implementation, I've modified them in the following way. Let's define some quantities: $$C_0=\frac{\Gamma(1/3)}{3^{1/3}} \\ D_0=\Gamma(2/3)$$ And recurrence relations: $$C_k=\frac{C_{k-1}}{3k(3k-1)} \\ D_k=\frac{D_{k-1}}{3k(3k-2)}$$ Then the general terms will be: $$A_k=z^{3k} \left(C_k-\frac{z}{3k+1}D_k \right) \\ B_k=z^{3k} \left(C_k+\frac{z}{3k+1}D_k \right)$$ And finally: $$\text{Ai}(z)= \frac{3^{1/6}}{2 \pi}\sum_{k=0}^\infty A_k$$ $$\text{Bi}(z)= \frac{3^{2/3}}{2 \pi}\sum_{k=0}^\infty B_k$$ This seems to work great for (approximately) $|z|<7$ (including complex values) using around $20-25$ terms of the recurrence, for the larger arguments there seem to be some numerical issues. My questions are as follows: Can this algorithm be improved in some obvious way for better convergence/stability, taking into account possible rounding/cancellation errors? And what is the best way to compute these functions for larger arguments? Can I already use the asymptotic expansions listed in some sources for $|z|>7$ ? The R code I made for this algorithm: #Airy functions using series AiBi <- function(z){ g13 <- 2.678938534707747633655693; #Gamma(1/3) g23 <- 1.354117939426400416945288; #Gamma(2/3) Km <- 25; #Number of terms used C <- 1:Km; D <- C; A <- C; B <- C; C[1] <- g13/3^(1/3); D[1] <- g23; A[1] <- C[1]-D[1]*z; B[1] <- C[1]+D[1]*z; k <- 1; while (k < Km) {k <- k+1;         C[k] <- C[k-1]/(3*k-3)/(3*k-4);         D[k] <- D[k-1]/(3*k-3)/(3*k-5);         A[k] <- z^(3*k-3)*(C[k]-D[k]*z/(3*k-2));         B[k] <- z^(3*k-3)*(C[k]+D[k]*z/(3*k-2)) }; c(sum(A)*3^(1/6),sum(B)*3^(2/3))/2/pi}; AiBi(pi/exp(1)) Update: Wanted to point out an obvious improvement. Instead of computing the coefficients, it's much better to use backwards recurrence. For example, for the first part of the series: $$f(z) =  \sum_{k=0}^\infty C_k z^{3k}$$ Pick some $K_m$ large enough, then define (for the sake of simplicity I changed $C_0=1$ ): $$f_0=1 \\ f_{k'}=1+\frac{z^3}{3(K_m-k')(3(K_m-k')-1)}f_{k'-1}, \qquad k'=0,1,2,\dots,K_m-1$$ This should make the numerical computation faster and more stable (obviously, $z^3$ should be precomputed).","I've been trying to find good methods for numerically computing Airy functions, and I found that for small arguments it's convenient to use their Taylor series expansions: While these expansions are inconvenient for direct implementation, I've modified them in the following way. Let's define some quantities: And recurrence relations: Then the general terms will be: And finally: This seems to work great for (approximately) (including complex values) using around terms of the recurrence, for the larger arguments there seem to be some numerical issues. My questions are as follows: Can this algorithm be improved in some obvious way for better convergence/stability, taking into account possible rounding/cancellation errors? And what is the best way to compute these functions for larger arguments? Can I already use the asymptotic expansions listed in some sources for ? The R code I made for this algorithm: #Airy functions using series AiBi <- function(z){ g13 <- 2.678938534707747633655693; #Gamma(1/3) g23 <- 1.354117939426400416945288; #Gamma(2/3) Km <- 25; #Number of terms used C <- 1:Km; D <- C; A <- C; B <- C; C[1] <- g13/3^(1/3); D[1] <- g23; A[1] <- C[1]-D[1]*z; B[1] <- C[1]+D[1]*z; k <- 1; while (k < Km) {k <- k+1;         C[k] <- C[k-1]/(3*k-3)/(3*k-4);         D[k] <- D[k-1]/(3*k-3)/(3*k-5);         A[k] <- z^(3*k-3)*(C[k]-D[k]*z/(3*k-2));         B[k] <- z^(3*k-3)*(C[k]+D[k]*z/(3*k-2)) }; c(sum(A)*3^(1/6),sum(B)*3^(2/3))/2/pi}; AiBi(pi/exp(1)) Update: Wanted to point out an obvious improvement. Instead of computing the coefficients, it's much better to use backwards recurrence. For example, for the first part of the series: Pick some large enough, then define (for the sake of simplicity I changed ): This should make the numerical computation faster and more stable (obviously, should be precomputed).","\text{Ai} (z)=\frac{1}{3^{2/3} \pi} \sum_{n=0}^{\infty} \frac{\Gamma(1/3(n+1))}{n!}(3^{1/3}z)^n \sin[(2(n+1)\pi)/3] \text{Bi} (z)=\frac{1}{3^{1/6} \pi} \sum_{n=0}^{\infty} \frac{\Gamma(1/3(n+1))}{n!}(3^{1/3}z)^n |\sin[(2(n+1)\pi)/3]| C_0=\frac{\Gamma(1/3)}{3^{1/3}} \\ D_0=\Gamma(2/3) C_k=\frac{C_{k-1}}{3k(3k-1)} \\ D_k=\frac{D_{k-1}}{3k(3k-2)} A_k=z^{3k} \left(C_k-\frac{z}{3k+1}D_k \right) \\ B_k=z^{3k} \left(C_k+\frac{z}{3k+1}D_k \right) \text{Ai}(z)= \frac{3^{1/6}}{2 \pi}\sum_{k=0}^\infty A_k \text{Bi}(z)= \frac{3^{2/3}}{2 \pi}\sum_{k=0}^\infty B_k |z|<7 20-25 |z|>7 f(z) =  \sum_{k=0}^\infty C_k z^{3k} K_m C_0=1 f_0=1 \\ f_{k'}=1+\frac{z^3}{3(K_m-k')(3(K_m-k')-1)}f_{k'-1}, \qquad k'=0,1,2,\dots,K_m-1 z^3","['sequences-and-series', 'numerical-methods', 'airy-functions']"
31,An integer sequence related to Penrose tessellation,An integer sequence related to Penrose tessellation,,"Consider covering the plane by means of the classical Penrose tiles (i.e. the ""fat"" and ""thin"" rhombi) in a spiraling fashion, adding step by step a new tile around a given one, as introduced in this post . At each step, we need one of the two tiles (and only one), as illustrated in the following picture: The starting tile is the pink one. The segments connecting the centers of the tiles represent the consecutive steps of the spiral walk around the starting tile. The numbers inside the tiles (1, fat rhombus; $\color{red} 0$, thin rhombus), highlight the alternation of the two kinds of tiles as a function of the walk step. Displaying these numbers in a sequence, we find: $s(n)=1$,$1$,$1$,$1$,$\color{red}0$,$1$,$1$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$1\ldots$ My question is: Is there a closed formula for $s(n)$? Thanks for your suggestions!","Consider covering the plane by means of the classical Penrose tiles (i.e. the ""fat"" and ""thin"" rhombi) in a spiraling fashion, adding step by step a new tile around a given one, as introduced in this post . At each step, we need one of the two tiles (and only one), as illustrated in the following picture: The starting tile is the pink one. The segments connecting the centers of the tiles represent the consecutive steps of the spiral walk around the starting tile. The numbers inside the tiles (1, fat rhombus; $\color{red} 0$, thin rhombus), highlight the alternation of the two kinds of tiles as a function of the walk step. Displaying these numbers in a sequence, we find: $s(n)=1$,$1$,$1$,$1$,$\color{red}0$,$1$,$1$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$\color{red}0$,$\color{red}0$,$1$,$1\ldots$ My question is: Is there a closed formula for $s(n)$? Thanks for your suggestions!",,"['sequences-and-series', 'geometry']"
32,Recursive definition of this sequence,Recursive definition of this sequence,,"I'm having some trouble finding a recursive definition for the following sequence: $x_0 = \sqrt{1+n}$ $x_1 = \sqrt{1+n\sqrt{1+(n+1)}}$ $x_2 = \sqrt{1+n\sqrt{1+(n+1)\sqrt{1+(n+2)}}}$ $x_3 = \sqrt{1+n\sqrt{1+(n+1)\sqrt{1+(n+2)\sqrt{1+(n+3)}}}}$ and so on (where $n \in \mathbb{N}$). I tried using something like $x_{i+1} = \sqrt{1 + n f(x_i)}$ where $f$ would be a function that sends $n$ to $n+1$ wherever $n$ appears in $x_i$. So for instance $f(x_0) = \sqrt{1 + (n+1)}$ and $f(x_1) = \sqrt{1+(n+1)\sqrt{1+(n+2)}}$. My problem is that I can't figure out an explicit form for $f$. If it's any help, the limit of the sequence is $n+1$.","I'm having some trouble finding a recursive definition for the following sequence: $x_0 = \sqrt{1+n}$ $x_1 = \sqrt{1+n\sqrt{1+(n+1)}}$ $x_2 = \sqrt{1+n\sqrt{1+(n+1)\sqrt{1+(n+2)}}}$ $x_3 = \sqrt{1+n\sqrt{1+(n+1)\sqrt{1+(n+2)\sqrt{1+(n+3)}}}}$ and so on (where $n \in \mathbb{N}$). I tried using something like $x_{i+1} = \sqrt{1 + n f(x_i)}$ where $f$ would be a function that sends $n$ to $n+1$ wherever $n$ appears in $x_i$. So for instance $f(x_0) = \sqrt{1 + (n+1)}$ and $f(x_1) = \sqrt{1+(n+1)\sqrt{1+(n+2)}}$. My problem is that I can't figure out an explicit form for $f$. If it's any help, the limit of the sequence is $n+1$.",,"['real-analysis', 'sequences-and-series']"
33,Intuition of error in Taylor appoximation and finding error in approximation of a function by a constant function,Intuition of error in Taylor appoximation and finding error in approximation of a function by a constant function,,"I am reading up on Taylor approximation of a function and I'm trying to develop the intuition for the remainder, when approximating a function with $n^{th}$ degree polynomial which has a continuous $(n+1)^{th}$ derivate, given by      $\frac{1}{n!}\int_{a}^{x} (x - t)^nf^{(n+1)}(t)dt$ My intuition of linear approximation is this: We used a constant first derivate to evaluate at x (since we approximate f at a). Hence, we have to use the information about rate of rate of change from the any point $ t \in (a,x)$ to compensate for this error. Specifically, the second derivative gives the difference between the first derivatives at two successive points and scales it over unit interval. Therefore, f''(t) corrects for error at t but introduces new error from (t, x) which is corrected with the same logic at the next point. Thus, the integral given above. Is this correct? My reasoning is because if I begin the approximation using a constant function and reason that by using the rate of change at every point, a function can be reconstructed starting from any point. But if I try to use the above integral to compute the error in estimates for the constant function, it doesn't work because of the $(-t)$. Is there a formula to estimate the error including the constant case? I understand the proof of the integral using integration by parts (and requirement of the continuity of $f^{(n+1)}(x)$ is to be able to use the first fundamental theorem). Can you please help me fix my intuition of the integral?","I am reading up on Taylor approximation of a function and I'm trying to develop the intuition for the remainder, when approximating a function with $n^{th}$ degree polynomial which has a continuous $(n+1)^{th}$ derivate, given by      $\frac{1}{n!}\int_{a}^{x} (x - t)^nf^{(n+1)}(t)dt$ My intuition of linear approximation is this: We used a constant first derivate to evaluate at x (since we approximate f at a). Hence, we have to use the information about rate of rate of change from the any point $ t \in (a,x)$ to compensate for this error. Specifically, the second derivative gives the difference between the first derivatives at two successive points and scales it over unit interval. Therefore, f''(t) corrects for error at t but introduces new error from (t, x) which is corrected with the same logic at the next point. Thus, the integral given above. Is this correct? My reasoning is because if I begin the approximation using a constant function and reason that by using the rate of change at every point, a function can be reconstructed starting from any point. But if I try to use the above integral to compute the error in estimates for the constant function, it doesn't work because of the $(-t)$. Is there a formula to estimate the error including the constant case? I understand the proof of the integral using integration by parts (and requirement of the continuity of $f^{(n+1)}(x)$ is to be able to use the first fundamental theorem). Can you please help me fix my intuition of the integral?",,"['calculus', 'sequences-and-series', 'taylor-expansion', 'approximation', 'linear-approximation']"
34,Get approximations of series involving Cauchy numbers of the first kind and the Möbius function,Get approximations of series involving Cauchy numbers of the first kind and the Möbius function,,"We denote for integers $n\geq 1$ the $n$th Gregory coefficient as $G_n$, and the Möbius function as $\mu(n)$. You've here the Wikipedia's article dedicated to the Gregory coefficients. Using an argument of absolute convergence, and the information of previous Wikipedia for the first related series to the Gregory coefficients and the result due to Candelperger, Coppo and Young,  it is obvious to prove that $$\sum_{n=1}^\infty\mu(n)|G_n|\tag{1}$$ and $$\sum_{n=1}^\infty\frac{|G_n|\cdot m(n)}{n}\tag{2}$$ are convergent series, where $m(x)$ denotes the function $$m(x)=\sum_{1\leq k\leq x}\frac{\mu(k)}{k}.\tag{3}$$ Question. Have you an idea/hint to get a good approximation (the first four or six digits) of $(1)$ and $(2)$? Many thanks. I know that there are upper bounds for the absolute value of $(3)$ for large values of $x$.","We denote for integers $n\geq 1$ the $n$th Gregory coefficient as $G_n$, and the Möbius function as $\mu(n)$. You've here the Wikipedia's article dedicated to the Gregory coefficients. Using an argument of absolute convergence, and the information of previous Wikipedia for the first related series to the Gregory coefficients and the result due to Candelperger, Coppo and Young,  it is obvious to prove that $$\sum_{n=1}^\infty\mu(n)|G_n|\tag{1}$$ and $$\sum_{n=1}^\infty\frac{|G_n|\cdot m(n)}{n}\tag{2}$$ are convergent series, where $m(x)$ denotes the function $$m(x)=\sum_{1\leq k\leq x}\frac{\mu(k)}{k}.\tag{3}$$ Question. Have you an idea/hint to get a good approximation (the first four or six digits) of $(1)$ and $(2)$? Many thanks. I know that there are upper bounds for the absolute value of $(3)$ for large values of $x$.",,"['real-analysis', 'sequences-and-series']"
35,"What about sequences $\{\sum_{k=1}^n (\operatorname{rad}(k))^p\}_{n\geq 1}$ containing an infinitude of prime numbers, where $p\geq 1$ is integer?","What about sequences  containing an infinitude of prime numbers, where  is integer?",\{\sum_{k=1}^n (\operatorname{rad}(k))^p\}_{n\geq 1} p\geq 1,"We denote the radical of the integer $n> 1$ as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\ p\text{ prime}}}p,$$ taking $\operatorname{rad}(1)=1$ that is this definition from Wikipedia . In this post we do a comparison with the so-called Faulhaber polynomials (their factorization), see this Wikipedia in the way that I am going to define sequences using the arithmetic function $a(k)=\operatorname{rad}(n)$ instead of the arithmetic function $a(k)=k$ inside the finite sums $$\sum_{k=1}^n (a(k))^p$$ where $p\geq 1$ is a fixed integer. The comparison that we evoke is ask us when (for a fixed integer $p\geq 1$) the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p\tag{1}$$ reaches/contains infinitely many prime numbers, this is that our sequence $(1)$ has infinitely many terms being prime numbers for a fixed choice of $p$. I think that this conjecture is wild, since I did few experiments (and I hope that these were rights) and by the mentioned comparison. Any case I would like to know feedback about our question from this MSE. Question. Can you find an integer (or what do you think about it) $p\geq 1$ such that the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p$$ contains only a finite number of prime numbers in its terms as $n$ runs over the positive integers $\geq 1$? Or well, what are your heuristic or reasoning to elucidate if this kind of sequences $(1)$ should have finitely many or infinitely many prime numbers for a choice of $p$, when $n\geq 1$? Many thanks. I think that this question can be very difficult. I should to choice some answer that provide good feedback about it, thus isn't required solve all minor questions. I did this variation since the radical of an integer $\operatorname{rad}(n)$ is an important arithmetic function (related to the so-called abc conjecture) in analytic number theory, is a multiplicative function and it's like a substitute of the function $a(n)=n$.","We denote the radical of the integer $n> 1$ as $$\operatorname{rad}(n)=\prod_{\substack{p\mid n\\ p\text{ prime}}}p,$$ taking $\operatorname{rad}(1)=1$ that is this definition from Wikipedia . In this post we do a comparison with the so-called Faulhaber polynomials (their factorization), see this Wikipedia in the way that I am going to define sequences using the arithmetic function $a(k)=\operatorname{rad}(n)$ instead of the arithmetic function $a(k)=k$ inside the finite sums $$\sum_{k=1}^n (a(k))^p$$ where $p\geq 1$ is a fixed integer. The comparison that we evoke is ask us when (for a fixed integer $p\geq 1$) the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p\tag{1}$$ reaches/contains infinitely many prime numbers, this is that our sequence $(1)$ has infinitely many terms being prime numbers for a fixed choice of $p$. I think that this conjecture is wild, since I did few experiments (and I hope that these were rights) and by the mentioned comparison. Any case I would like to know feedback about our question from this MSE. Question. Can you find an integer (or what do you think about it) $p\geq 1$ such that the sequence $$\sum_{k=1}^n (\operatorname{rad}(k))^p$$ contains only a finite number of prime numbers in its terms as $n$ runs over the positive integers $\geq 1$? Or well, what are your heuristic or reasoning to elucidate if this kind of sequences $(1)$ should have finitely many or infinitely many prime numbers for a choice of $p$, when $n\geq 1$? Many thanks. I think that this question can be very difficult. I should to choice some answer that provide good feedback about it, thus isn't required solve all minor questions. I did this variation since the radical of an integer $\operatorname{rad}(n)$ is an important arithmetic function (related to the so-called abc conjecture) in analytic number theory, is a multiplicative function and it's like a substitute of the function $a(n)=n$.",,"['sequences-and-series', 'prime-numbers']"
36,Example where Ermakoff's convergence test is inconclusive,Example where Ermakoff's convergence test is inconclusive,,"Ermakoff's test states that for a nonincreasing function $f(x)$, $\sum f(n)$ converges if $$\limsup_{x \to \infty} \frac{e^x f(e^x)}{f(x)} < 1$$ and diverges if $$\liminf_{x \to \infty} \frac{e^x f(e^x)}{f(x)} > 1.$$ This test seems to be very powerful in that any example I try gives a limit of $0$ or $\infty$. Question: Is there an example where Ermakoff's test is inconclusive, i.e. is there an $f(x)$ that gives a limit of 1? More generally, is there an $f(x)$ that gives a finite positive limit? My approach was to toe the line between slowly diverging summands like $\frac{1}{n}, \frac{1}{n \log n}, \frac{1}{n \log n \log\log n}, \ldots$ I tried throwing in special functions that grow differently than a power of a nested logarithm, such as $li(x)$ and $W(x)$ . This didn't get me very far as I ended up wandering aimlessly through examples. By taking the logarithm of the limit and performing substitutions, it's equivalent to look for a nondecreasing function $g(x)$ where $\lim_{x \to \infty} (x - g(x) + g(\log x)) = 0$. This form makes working with series at $x = \infty$ a bit easier. The test can be generalized by looking at $\phi'(x) f(\phi(x))/f(x)$ for any increasing $\phi(x) > x$. Letting $\phi(x) = e^x$ gives Ermakoff's test and letting $\phi(x) = x + 1$ gives d'Alembert's ratio test. Bonus question: Is there a way to find an inconclusive example for any $\phi(x)$? I imagine the faster $\phi(x)$ grows, the harder it becomes.","Ermakoff's test states that for a nonincreasing function $f(x)$, $\sum f(n)$ converges if $$\limsup_{x \to \infty} \frac{e^x f(e^x)}{f(x)} < 1$$ and diverges if $$\liminf_{x \to \infty} \frac{e^x f(e^x)}{f(x)} > 1.$$ This test seems to be very powerful in that any example I try gives a limit of $0$ or $\infty$. Question: Is there an example where Ermakoff's test is inconclusive, i.e. is there an $f(x)$ that gives a limit of 1? More generally, is there an $f(x)$ that gives a finite positive limit? My approach was to toe the line between slowly diverging summands like $\frac{1}{n}, \frac{1}{n \log n}, \frac{1}{n \log n \log\log n}, \ldots$ I tried throwing in special functions that grow differently than a power of a nested logarithm, such as $li(x)$ and $W(x)$ . This didn't get me very far as I ended up wandering aimlessly through examples. By taking the logarithm of the limit and performing substitutions, it's equivalent to look for a nondecreasing function $g(x)$ where $\lim_{x \to \infty} (x - g(x) + g(\log x)) = 0$. This form makes working with series at $x = \infty$ a bit easier. The test can be generalized by looking at $\phi'(x) f(\phi(x))/f(x)$ for any increasing $\phi(x) > x$. Letting $\phi(x) = e^x$ gives Ermakoff's test and letting $\phi(x) = x + 1$ gives d'Alembert's ratio test. Bonus question: Is there a way to find an inconclusive example for any $\phi(x)$? I imagine the faster $\phi(x)$ grows, the harder it becomes.",,"['sequences-and-series', 'convergence-divergence']"
37,"$n$th Term of the sequence $1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots$ [duplicate]",th Term of the sequence  [duplicate],"n 1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots","This question already has answers here : Formula for the $n$th term of $1, 2, 2, 3, 3, 3, 4, 4 ,4, 4, 5, ...$ (4 answers) Closed 6 years ago . Prove that $n$th Term of the sequence $1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots$ is given by $$T_n =\left[\sqrt{2n+\frac{1}{2}}\right]$$ where $[.]$ is Floor function My Try: Its clear that $1$st Term is $1$, $3$rd Term is $2$, $6$th term is $3$ and so on We have Triangular numbers as $1,3,6,10,...$ whose $m$th term is given by $\frac{m(m+1)}{2}$ Hence for the given sequence $$T_{\frac{m(m+1)}{2}}=m$$ Letting $$\frac{m(m+1)}{2}=n$$ we get Quadratic in $m$ as $$m^2+m-2n=0$$ So $m$ takes $\frac{-1\pm \sqrt{1+8n}}{2}$ and since $m$ is a positive integer we have $$m=\frac{-1+\sqrt{1+8n}}{2}$$ hence $$T_n=\frac{-1+\sqrt{1+8n}}{2}$$ how to proceed further?","This question already has answers here : Formula for the $n$th term of $1, 2, 2, 3, 3, 3, 4, 4 ,4, 4, 5, ...$ (4 answers) Closed 6 years ago . Prove that $n$th Term of the sequence $1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,\cdots$ is given by $$T_n =\left[\sqrt{2n+\frac{1}{2}}\right]$$ where $[.]$ is Floor function My Try: Its clear that $1$st Term is $1$, $3$rd Term is $2$, $6$th term is $3$ and so on We have Triangular numbers as $1,3,6,10,...$ whose $m$th term is given by $\frac{m(m+1)}{2}$ Hence for the given sequence $$T_{\frac{m(m+1)}{2}}=m$$ Letting $$\frac{m(m+1)}{2}=n$$ we get Quadratic in $m$ as $$m^2+m-2n=0$$ So $m$ takes $\frac{-1\pm \sqrt{1+8n}}{2}$ and since $m$ is a positive integer we have $$m=\frac{-1+\sqrt{1+8n}}{2}$$ hence $$T_n=\frac{-1+\sqrt{1+8n}}{2}$$ how to proceed further?",,"['sequences-and-series', 'algebra-precalculus', 'radicals', 'ceiling-and-floor-functions']"
38,Sequence notation where a has a subscript and a superscript,Sequence notation where a has a subscript and a superscript,,"So from what I've seen of sequences a common format would be something like $a_{n+1} = 2a_n + 5 $ I was doing some review for sequences and come across a format that looks something like $a_{n+1}=a_n^2-1$ given $a_1=1$ According to my solution manual, $a_1=1,a_2=0,a_3=-1,a_4=0$ I initially thought that maybe it was just a weird notation and I could write it as $a_n$ but that would just make is a continually decreasing sequences so $a_1=1,a_2=0,a_3=-1,a_4=-2,a_5=-3$ and so on. So this doesnt fit the answer. I'd like to know how this $a_n^c$ where c is just some number actually works in case it comes up on a test. Any example at all or just an explanation would be great, I can't actually find this notation in the section before the question. For reference, this is in Briggs, Cochran Calculus Early Transcendentals 2nd edition, 8.1 #20 Edit: Thanks to u/Rob Arthan for this Since  $a_n^2 = a_n \times a_n=(a_n)^2$ this makes the answers from above as $a_2=(a_1)^2-1=1^2-1=0$ $a_3=(a_2)^2-1=0^2-1=-1$ $a_4=(a_3)^2-1=(-1)^2-1=1-1=0$ and so on and so forth","So from what I've seen of sequences a common format would be something like $a_{n+1} = 2a_n + 5 $ I was doing some review for sequences and come across a format that looks something like $a_{n+1}=a_n^2-1$ given $a_1=1$ According to my solution manual, $a_1=1,a_2=0,a_3=-1,a_4=0$ I initially thought that maybe it was just a weird notation and I could write it as $a_n$ but that would just make is a continually decreasing sequences so $a_1=1,a_2=0,a_3=-1,a_4=-2,a_5=-3$ and so on. So this doesnt fit the answer. I'd like to know how this $a_n^c$ where c is just some number actually works in case it comes up on a test. Any example at all or just an explanation would be great, I can't actually find this notation in the section before the question. For reference, this is in Briggs, Cochran Calculus Early Transcendentals 2nd edition, 8.1 #20 Edit: Thanks to u/Rob Arthan for this Since  $a_n^2 = a_n \times a_n=(a_n)^2$ this makes the answers from above as $a_2=(a_1)^2-1=1^2-1=0$ $a_3=(a_2)^2-1=0^2-1=-1$ $a_4=(a_3)^2-1=(-1)^2-1=1-1=0$ and so on and so forth",,"['sequences-and-series', 'notation']"
39,Divergence of a series involving an operator,Divergence of a series involving an operator,,"Let $T$ be an operator on an infinite-dimensional Hilbert space $H$, $r$ be its spectral radius. Let $\phi$ be a positive linear functional on the algebra $B(H)$ of bounded operators on $H$ such that $\phi(I_H)=1$ and $\phi(S^*S)=0$ implies $S=0$. I wonder if $$\sum_{n=1}^\infty\dfrac{\phi(T^n)}{nr^n}$$ diverges? Informally we can have $\phi(\log|T-rI|)$ which seems to diverge, but how should I prove it formally? Jonas provided a nice counterexmaple where the series converges. But I think it is because he constructed an operator which has $i,-i$ as its spectrum, then the series is reduced to $\sum i^n/n$ and $\sum (-i)^n/n$ which both converge. I wonder what if I assume $T$ has an eigenvalue which equals to $r$? Jonas gave another counterexmaple. Please see the answer below. I admit that my intuition is for when $\phi$ is a trace and $T$ is a matrix, then $\phi(T^n)$ will be $\sum_i \lambda_i^n$, where $\lambda_i$ are eigenvalues. Then it will diverge. But what about a general operator with a general tracial positive linear functional? This part can be found here","Let $T$ be an operator on an infinite-dimensional Hilbert space $H$, $r$ be its spectral radius. Let $\phi$ be a positive linear functional on the algebra $B(H)$ of bounded operators on $H$ such that $\phi(I_H)=1$ and $\phi(S^*S)=0$ implies $S=0$. I wonder if $$\sum_{n=1}^\infty\dfrac{\phi(T^n)}{nr^n}$$ diverges? Informally we can have $\phi(\log|T-rI|)$ which seems to diverge, but how should I prove it formally? Jonas provided a nice counterexmaple where the series converges. But I think it is because he constructed an operator which has $i,-i$ as its spectrum, then the series is reduced to $\sum i^n/n$ and $\sum (-i)^n/n$ which both converge. I wonder what if I assume $T$ has an eigenvalue which equals to $r$? Jonas gave another counterexmaple. Please see the answer below. I admit that my intuition is for when $\phi$ is a trace and $T$ is a matrix, then $\phi(T^n)$ will be $\sum_i \lambda_i^n$, where $\lambda_i$ are eigenvalues. Then it will diverge. But what about a general operator with a general tracial positive linear functional? This part can be found here",,"['sequences-and-series', 'functional-analysis', 'operator-theory', 'operator-algebras']"
40,Lacunary functions and sums of reciprocals,Lacunary functions and sums of reciprocals,,"Let $\Lambda=\left\{ \lambda_{n}\right\} _{n=0}^{\infty}$ be an infinite, strictly increasing sequence of non-negative integers. I say that $\Lambda$ is reciprocal-summable if: $$\sum_{\lambda\in\Lambda\backslash\left\{ 0\right\} }\frac{1}{\lambda}<\infty$$ Now, in a slight abuse of terminology, I'm going to use the term “lacunary” to refer only to those holomorphic functions on $\mathbb{D}$ for which the unit circle is a natural boundary (such as $\sum_{n=0}^{\infty}z^{2^{n}}$). The only functions I'm concerned with are those for which the power series coefficients are $0$s and $1$s. I've been reading up on the known criteria (and converses) for when a function is lacunary (results of Fabry, Hadamard, Pólya, etc.). However, many (if not most) of them try to go from the most general point of view they can find, and so, I can't seem to find the exact details / answers that I'm looking for. The claims which I would like to have answered (either partially or entirely) and/or be pointed toward a counterexample of are as follows: I. If $\Lambda$   is reciprocal summable, then $\sum_{n=0}^{\infty}z^{\lambda_{n}}$   is lacunary. II. If $\Lambda$   is not reciprocal-summable, then $\sum_{n=0}^{\infty}z^{\lambda_{n}}$   is not lacunary. If any of the results (or predecessors thereof) of Hadamard, Fabry, Pólya (etc.) imply one or more of these claims, an explanation of how they do so would be much appreciated. Thanks in advance!","Let $\Lambda=\left\{ \lambda_{n}\right\} _{n=0}^{\infty}$ be an infinite, strictly increasing sequence of non-negative integers. I say that $\Lambda$ is reciprocal-summable if: $$\sum_{\lambda\in\Lambda\backslash\left\{ 0\right\} }\frac{1}{\lambda}<\infty$$ Now, in a slight abuse of terminology, I'm going to use the term “lacunary” to refer only to those holomorphic functions on $\mathbb{D}$ for which the unit circle is a natural boundary (such as $\sum_{n=0}^{\infty}z^{2^{n}}$). The only functions I'm concerned with are those for which the power series coefficients are $0$s and $1$s. I've been reading up on the known criteria (and converses) for when a function is lacunary (results of Fabry, Hadamard, Pólya, etc.). However, many (if not most) of them try to go from the most general point of view they can find, and so, I can't seem to find the exact details / answers that I'm looking for. The claims which I would like to have answered (either partially or entirely) and/or be pointed toward a counterexample of are as follows: I. If $\Lambda$   is reciprocal summable, then $\sum_{n=0}^{\infty}z^{\lambda_{n}}$   is lacunary. II. If $\Lambda$   is not reciprocal-summable, then $\sum_{n=0}^{\infty}z^{\lambda_{n}}$   is not lacunary. If any of the results (or predecessors thereof) of Hadamard, Fabry, Pólya (etc.) imply one or more of these claims, an explanation of how they do so would be much appreciated. Thanks in advance!",,"['sequences-and-series', 'complex-analysis', 'lacunary-series']"
41,Compute $\sum\limits_n(-1)^{n-1}\frac{2^{n+1}}{2^{2n}-1}$ in terms of $\sum\limits_n\frac1{2^n-1}$ and $\sum\limits_n\frac1{2^n+1}$,Compute  in terms of  and,\sum\limits_n(-1)^{n-1}\frac{2^{n+1}}{2^{2n}-1} \sum\limits_n\frac1{2^n-1} \sum\limits_n\frac1{2^n+1},"Question : let  $$\sum_{n=1}^{+\infty}\dfrac{1}{2^n-1}=E,\sum_{n=1}^{+\infty}\dfrac{1}{2^n+1}=F$$ where $E,F$ are constant,(in fact,$E$ is Erdős-Borwein Constant ),Find the sum   $$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\dfrac{2^{n+1}}{2^{2n}-1}$$ I tried this which I found in my texbook which seems relative, but Im not sure how to apply it to the problem: $$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\left(\dfrac{1}{2^n+1}+\dfrac{1}{2^n-1}\right)=\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n-1}+\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n+1}$$ following can't try","Question : let  $$\sum_{n=1}^{+\infty}\dfrac{1}{2^n-1}=E,\sum_{n=1}^{+\infty}\dfrac{1}{2^n+1}=F$$ where $E,F$ are constant,(in fact,$E$ is Erdős-Borwein Constant ),Find the sum   $$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\dfrac{2^{n+1}}{2^{2n}-1}$$ I tried this which I found in my texbook which seems relative, but Im not sure how to apply it to the problem: $$f=\sum_{n=1}^{+\infty}(-1)^{n-1}\left(\dfrac{1}{2^n+1}+\dfrac{1}{2^n-1}\right)=\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n-1}+\sum_{n=1}^{+\infty}\dfrac{(-1)^{n-1}}{2^n+1}$$ following can't try",,"['sequences-and-series', 'summation']"
42,"If $\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty$, then $\frac{1}{n} \sum_{k = 1}^n a_k \to 0$ [duplicate]","If , then  [duplicate]",\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty \frac{1}{n} \sum_{k = 1}^n a_k \to 0,"This question already has an answer here : Slick proofs that if $\sum\limits_{k=1}^\infty \frac{a_k}{k}$ converges then $\lim\limits_{n\to\infty} \frac{1}{n}\sum\limits_{k=1}^n a_k=0$ (1 answer) Closed 7 years ago . I'm currently reading a paper, where they assert that for a nonnegative sequence $a_k$ of real numbers with $\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty$, we have $\lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n a_k = 0$. My attempt to prove this was using the following idea: If $a_k > \varepsilon > 0$ for all $k \geq k_0$, then $$ \sum_{k = 1}^\infty \frac{a_k}{k} > \varepsilon \sum_{k = k_0}^\infty \frac{1}{k} = + \infty.$$ So we should have some decay condition on the $a_k$. However, we could have $a_k$ to be the characteristic function of $\{ n^2 : n \geq 1 \}$ for instance; then we can't compare the series $\sum_{k = 1}^\infty \frac{a_k}{k}$ to the harmonic numbers; but then we can equally deduce the fact since square numbers have density zero. I know that this is very vague. The reason for this is, that I couldn't get the idea to work. How can I prove the fact? Thanks!","This question already has an answer here : Slick proofs that if $\sum\limits_{k=1}^\infty \frac{a_k}{k}$ converges then $\lim\limits_{n\to\infty} \frac{1}{n}\sum\limits_{k=1}^n a_k=0$ (1 answer) Closed 7 years ago . I'm currently reading a paper, where they assert that for a nonnegative sequence $a_k$ of real numbers with $\sum_{k = 1}^\infty \frac{a_k}{k} < + \infty$, we have $\lim_{n \to \infty} \frac{1}{n} \sum_{k = 1}^n a_k = 0$. My attempt to prove this was using the following idea: If $a_k > \varepsilon > 0$ for all $k \geq k_0$, then $$ \sum_{k = 1}^\infty \frac{a_k}{k} > \varepsilon \sum_{k = k_0}^\infty \frac{1}{k} = + \infty.$$ So we should have some decay condition on the $a_k$. However, we could have $a_k$ to be the characteristic function of $\{ n^2 : n \geq 1 \}$ for instance; then we can't compare the series $\sum_{k = 1}^\infty \frac{a_k}{k}$ to the harmonic numbers; but then we can equally deduce the fact since square numbers have density zero. I know that this is very vague. The reason for this is, that I couldn't get the idea to work. How can I prove the fact? Thanks!",,"['calculus', 'real-analysis', 'sequences-and-series']"
43,Verifying a Series Solution to Dirichlet's Problem via separation of variables,Verifying a Series Solution to Dirichlet's Problem via separation of variables,,"In Stein's Fourier Analysis i'm having trouble attempting to verify the series solution given in the problem in $(1.)$ $(1.)$ The Dirchlet problem is the annulus defined by ${{(r, \theta): p < r < 1}}$, where $0 \leq p \leq 1$ in the inner radius. The problem to solve: $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = 0$$ subject to the boundary conditions: $${      \begin{align}         u(1,\theta) = f(\theta) \\        u(p,\theta) = g(\theta).       \end{align}  }$$ Stein's intial argument was to write solutions for the Dirchlet Problem as he did previously in the following form: $$u(r,\theta)= \sum_{}^{}c_{n}(r)e^{in\theta}$$ with $c_{n}(r) = A_{n}r^{n} + B_{n}r^{-n}, n \neq 0$ Set:  $$f(\theta) \sim \sum_{}^{} a_{n}e^{in\theta}$$ and $$g(\theta) \sim \sum_{}^{}b_{n}e^{in\theta}$$ This leads to the solution $$u(r,\theta) = \sum_{n \leq 0} (\frac{1}{p^{n}-p^{-n}})((p/r)^{n} - (r/p)^{n})a_{n} + (r^{n} - r^{-n})b_{n}]e^{in\theta} + a_{o} + (b_{o} - a_{o}\frac{logr}{logp}$$ From looking what was done in Chapter 1 as a prior example,  and comparing the problem in $(1.)$the series the solution was obtained via Sepration of Variables. My initial attack can be followed in $(2.)$ $(2.)$ $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = \Delta{u}$$ $$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}} +  r\frac{\partial{u}}{\partial{r}} = -\frac{\partial^{2}u}{\partial{\theta}^{2}}$$ Plugging in our solution product: $(u(r,\theta))=F(r)G(\theta))$ $$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) +  r\frac{\partial{u}}{\partial{r}}F(r)G(\theta)= -\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)$$ Now dividing by our Solution Product:  $$\frac{r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) + r\frac{\partial{u}}{\partial{r}}F(r)G(\theta) } {F{(r)}} = \frac{-\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)}{G{(\theta)}} $$ Finally one can observe in a more convenient form  that we have the following: $$\frac{r^{2}F(r)G''(\theta)+r(G(\theta))F'(r)}{F(r)} = \frac{F(r)-G''(\theta)}{G(\theta)}$$ $$   \left\{      \begin{align}          r^2G''(\theta) + r(G(\theta)F'(r)) = 0 \\          F(r) - \dfrac{F(r) - G''(\theta)}{G(\theta)} = 0      \end{align}    \right.  $$ $$   \left\{      \begin{align}         r^{2}G''(\theta)+r(G(\theta))F'(r)\lambda F(r)=0 \\         F(r) - \lambda \frac{G''(\theta)}{G''(\theta)} = 0      \end{align}    \right.  $$ From the previous result above I'm stuck on working out a series solution to the above ODE's is their any fundamental observations I'm missing towards the problem ?","In Stein's Fourier Analysis i'm having trouble attempting to verify the series solution given in the problem in $(1.)$ $(1.)$ The Dirchlet problem is the annulus defined by ${{(r, \theta): p < r < 1}}$, where $0 \leq p \leq 1$ in the inner radius. The problem to solve: $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = 0$$ subject to the boundary conditions: $${      \begin{align}         u(1,\theta) = f(\theta) \\        u(p,\theta) = g(\theta).       \end{align}  }$$ Stein's intial argument was to write solutions for the Dirchlet Problem as he did previously in the following form: $$u(r,\theta)= \sum_{}^{}c_{n}(r)e^{in\theta}$$ with $c_{n}(r) = A_{n}r^{n} + B_{n}r^{-n}, n \neq 0$ Set:  $$f(\theta) \sim \sum_{}^{} a_{n}e^{in\theta}$$ and $$g(\theta) \sim \sum_{}^{}b_{n}e^{in\theta}$$ This leads to the solution $$u(r,\theta) = \sum_{n \leq 0} (\frac{1}{p^{n}-p^{-n}})((p/r)^{n} - (r/p)^{n})a_{n} + (r^{n} - r^{-n})b_{n}]e^{in\theta} + a_{o} + (b_{o} - a_{o}\frac{logr}{logp}$$ From looking what was done in Chapter 1 as a prior example,  and comparing the problem in $(1.)$the series the solution was obtained via Sepration of Variables. My initial attack can be followed in $(2.)$ $(2.)$ $$\frac{\partial^{2}u}{\partial{r}^{2}} + \frac{1}{r} \frac{\partial{u}}{\partial{r}}+ \frac{1}{r^{2}}\frac{\partial^{2}u}{\partial{\theta}^{2}} = \Delta{u}$$ $$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}} +  r\frac{\partial{u}}{\partial{r}} = -\frac{\partial^{2}u}{\partial{\theta}^{2}}$$ Plugging in our solution product: $(u(r,\theta))=F(r)G(\theta))$ $$r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) +  r\frac{\partial{u}}{\partial{r}}F(r)G(\theta)= -\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)$$ Now dividing by our Solution Product:  $$\frac{r^{2}\frac{\partial^{2}u}{\partial{r}^{2}}F(r)G(\theta) + r\frac{\partial{u}}{\partial{r}}F(r)G(\theta) } {F{(r)}} = \frac{-\frac{\partial^{2}u}{\partial{\theta}^{2}}F(r)G(\theta)}{G{(\theta)}} $$ Finally one can observe in a more convenient form  that we have the following: $$\frac{r^{2}F(r)G''(\theta)+r(G(\theta))F'(r)}{F(r)} = \frac{F(r)-G''(\theta)}{G(\theta)}$$ $$   \left\{      \begin{align}          r^2G''(\theta) + r(G(\theta)F'(r)) = 0 \\          F(r) - \dfrac{F(r) - G''(\theta)}{G(\theta)} = 0      \end{align}    \right.  $$ $$   \left\{      \begin{align}         r^{2}G''(\theta)+r(G(\theta))F'(r)\lambda F(r)=0 \\         F(r) - \lambda \frac{G''(\theta)}{G''(\theta)} = 0      \end{align}    \right.  $$ From the previous result above I'm stuck on working out a series solution to the above ODE's is their any fundamental observations I'm missing towards the problem ?",,"['sequences-and-series', 'ordinary-differential-equations', 'partial-differential-equations', 'proof-explanation']"
44,A series for $\frac{355}{113}-\pi$,A series for,\frac{355}{113}-\pi,"Series for sums $\pi+\dfrac{p_n}{q_n}$ Lehmer's interesting series relating $\pi$ to its early convergents $3$, $\dfrac{22}{7}$ and $\dfrac{355}{113}$ may be written as follows. $$\begin{align} \sum_{n=1}^\infty \dfrac{n2^n}{\dbinom{2 n}{n}}&=\pi+3\tag{A.1}\\ \dfrac{2}{7}\sum_{n=1}^\infty \dfrac{n^22^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.2}\\ \dfrac{2}{35}\sum_{n=1}^\infty \dfrac{n^32^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.3}\\ \dfrac{1}{113}\sum_{n=1}^\infty \dfrac{n^42^n}{\dbinom{2 n}{n}}&=\pi+\frac{355}{113}\tag{A.4}\\ \end{align}$$ Series for differences $\pi-\dfrac{p_n}{q_n}$ or $\dfrac{p_n}{q_n}-\pi$ Series that prove the sign of the error when approximating $\pi$ by its convergents include: $$\begin{align} \pi-3&=4·24\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{B.1}\\ \frac{22}{7}-\pi&=4^2·240\sum_{k=0}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{B.2}\\ \frac{22}{7}-\pi&=4^3·285120\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{B.3}\\ \end{align}$$ A series to prove $\frac{22}{7}-\pi>0$ Series and integrals for inequalities and approximations to $\pi$ Changing the initial value for summations leads to results as in A.1, A.2 and A.3. $$\begin{align} \pi+3&=4·24\sum_{k=-1}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{C.1}\\ \frac{22}{7}+\pi&=-4^2·240\sum_{k=-3}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{C.2}\\ \frac{22}{7}+\pi&=-4^3·285120\sum_{k=-3}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{C.3}\\ \end{align}$$ Let us assume there is a series for the fourth convergent $$\sum_{k=0}^\infty \frac{q}{\Pi_{i}(4k+d_i)}=\frac{355}{113}-\pi\tag{B.4}$$ for some positive rational $q$ and positive integers $d_i$. Question: Is there a technique to obtain the difference series (B.1, B.2, B.3) from their sum counterparts (A.1, A.2, A.3) that allows to determine B.4 from A.4?","Series for sums $\pi+\dfrac{p_n}{q_n}$ Lehmer's interesting series relating $\pi$ to its early convergents $3$, $\dfrac{22}{7}$ and $\dfrac{355}{113}$ may be written as follows. $$\begin{align} \sum_{n=1}^\infty \dfrac{n2^n}{\dbinom{2 n}{n}}&=\pi+3\tag{A.1}\\ \dfrac{2}{7}\sum_{n=1}^\infty \dfrac{n^22^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.2}\\ \dfrac{2}{35}\sum_{n=1}^\infty \dfrac{n^32^n}{\dbinom{2 n}{n}}&=\pi+\dfrac{22}{7}\tag{A.3}\\ \dfrac{1}{113}\sum_{n=1}^\infty \dfrac{n^42^n}{\dbinom{2 n}{n}}&=\pi+\frac{355}{113}\tag{A.4}\\ \end{align}$$ Series for differences $\pi-\dfrac{p_n}{q_n}$ or $\dfrac{p_n}{q_n}-\pi$ Series that prove the sign of the error when approximating $\pi$ by its convergents include: $$\begin{align} \pi-3&=4·24\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{B.1}\\ \frac{22}{7}-\pi&=4^2·240\sum_{k=0}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{B.2}\\ \frac{22}{7}-\pi&=4^3·285120\sum_{k=0}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{B.3}\\ \end{align}$$ A series to prove $\frac{22}{7}-\pi>0$ Series and integrals for inequalities and approximations to $\pi$ Changing the initial value for summations leads to results as in A.1, A.2 and A.3. $$\begin{align} \pi+3&=4·24\sum_{k=-1}^\infty \frac{(4k+1)!}{(4k+6)!}(k+1)\tag{C.1}\\ \frac{22}{7}+\pi&=-4^2·240\sum_{k=-3}^\infty \frac{(4k+3)!}{(4k+11)!}(k+1)(k+2)\tag{C.2}\\ \frac{22}{7}+\pi&=-4^3·285120\sum_{k=-3}^\infty \frac{(4k+1)!}{(4k+14)!}(k+1)(k+2)(k+3)\tag{C.3}\\ \end{align}$$ Let us assume there is a series for the fourth convergent $$\sum_{k=0}^\infty \frac{q}{\Pi_{i}(4k+d_i)}=\frac{355}{113}-\pi\tag{B.4}$$ for some positive rational $q$ and positive integers $d_i$. Question: Is there a technique to obtain the difference series (B.1, B.2, B.3) from their sum counterparts (A.1, A.2, A.3) that allows to determine B.4 from A.4?",,"['sequences-and-series', 'approximation', 'pi', 'diophantine-approximation']"
45,Binomial expansion of negative exponents.,Binomial expansion of negative exponents.,,"Let's say I have to expand $(1+x)^{-1}$ using binomial expansion. Using the theorem, I get: $$(1+x)^{-1} = 1-x+x^2-x^3+x^4-x^5+x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{2}= 1-1+1-1+1-1+1+....+{\infty}$$ A similar result arises with higher power of the exponent For $(1+x)^{-2}$ we get: $$(1+x)^{-2} = 1-2x+3x^2-4x^3+5x^4-6x^5+7x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{4}= 1-2+3-4+5-6+7+....+{\infty}$$ How does this makes sense? Help please!","Let's say I have to expand $(1+x)^{-1}$ using binomial expansion. Using the theorem, I get: $$(1+x)^{-1} = 1-x+x^2-x^3+x^4-x^5+x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{2}= 1-1+1-1+1-1+1+....+{\infty}$$ A similar result arises with higher power of the exponent For $(1+x)^{-2}$ we get: $$(1+x)^{-2} = 1-2x+3x^2-4x^3+5x^4-6x^5+7x^6+....+{\infty}$$ Substituting $x$ for $1$, I get: $$\frac{1}{4}= 1-2+3-4+5-6+7+....+{\infty}$$ How does this makes sense? Help please!",,"['sequences-and-series', 'binomial-theorem', 'negative-binomial']"
46,"Find all $n$ such that $n \mid x_n$ where $x_n = x_{n-1} + \lfloor n^2 / 4 \rfloor$, $x_0 = 0$","Find all  such that  where ,",n n \mid x_n x_n = x_{n-1} + \lfloor n^2 / 4 \rfloor x_0 = 0,$X_n$ is sequence such that $x_n=x_{n-1}+[\frac{n^2}{4}]$ and $x_0=0$. Find all positve integers $n$ for which $x_n$ is divisible by $n$.  [X] means integer part.,$X_n$ is sequence such that $x_n=x_{n-1}+[\frac{n^2}{4}]$ and $x_0=0$. Find all positve integers $n$ for which $x_n$ is divisible by $n$.  [X] means integer part.,,"['sequences-and-series', 'elementary-number-theory', 'divisibility']"
47,On the fractional derivatives of the Riemann zeta function and the derivatives of the derivatives,On the fractional derivatives of the Riemann zeta function and the derivatives of the derivatives,,"It's been a while since the last fractional-calculus question, so here's my question for all of you. It can be found from the Riemann-Liouville definition of the fractional derivative that whenever $\Re(s)>1$, $$\begin{align}I_x^\alpha\zeta(x)&={\frac  {1}{\Gamma (\alpha )}}\int _{a}^{x}\zeta(t)(x-t)^{\alpha -1}\ dt\\&=\frac1{\Gamma(\alpha)}\int_a^x\sum_{n=1}^\infty\frac{(x-t)^{\alpha-1}}{n^t}\ dt\\&=\frac1{\Gamma(\alpha)}\sum_{n=1}^\infty\int_a^x\frac{(x-t)^{\alpha-1}}{n^t}\ dt\\&=\sum_{n=1}^\infty\frac{(-\ln n)^{-\alpha}}{n^x}\end{align}$$ Thanks to WolframAlpha for that last step.  I imagine the interchange between integral and sum can be made with rigor, but I can't see how at the moment.  Setting this into it's derivative form, I end up with $$D_x^\alpha\zeta(x)=\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ which shall be my fractional derivative of the Riemann zeta function. I then wish to take the following: (is differentiation with respect to the fractional derivative nonsensical?) $$D_\alpha^\beta D_x^\alpha\zeta(x)=D_\alpha^\beta\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ Again, using the Riemann-Liouville definition, I end up with $$D_\alpha^\beta\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}=\sum_{n=1}^\infty\frac{(\ln(-\ln n))^\beta(-\ln n)^\alpha}{n^x}$$ Which is a little weird since the summand is undefined at $n=1$.  What should I do about this? Also, my end goal is to get some crazy derivative of derivatives of the zeta function into $$\sum_{n=1?}^\infty\frac{\prod_{k=0}^p(\ \overbrace{\ln\ln\dots\ln\ln}^k\ n\ )^{a_k}}{n^x}$$ Any ideas? Simple idea: Rewriting the zeta function as $$\zeta(x)=1+\sum_{n=2}^\infty\frac1{n^x}$$ now removes the problem, and with linearity, should give us $$D_x^\alpha\zeta(x)=\frac1{\Gamma(1-\alpha)x^\alpha}+\sum_{n=2}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ $$D_\alpha^\beta D_x^\alpha\zeta(x)=\left(D_\alpha^\beta\frac1{\Gamma(1-\alpha)x^\alpha}\right)+\sum_{n=2}^\infty\frac{(\ln(-\ln n))^\beta(-\ln n)^\alpha}{n^x}$$ Though this feels a tad bit unsafe.","It's been a while since the last fractional-calculus question, so here's my question for all of you. It can be found from the Riemann-Liouville definition of the fractional derivative that whenever $\Re(s)>1$, $$\begin{align}I_x^\alpha\zeta(x)&={\frac  {1}{\Gamma (\alpha )}}\int _{a}^{x}\zeta(t)(x-t)^{\alpha -1}\ dt\\&=\frac1{\Gamma(\alpha)}\int_a^x\sum_{n=1}^\infty\frac{(x-t)^{\alpha-1}}{n^t}\ dt\\&=\frac1{\Gamma(\alpha)}\sum_{n=1}^\infty\int_a^x\frac{(x-t)^{\alpha-1}}{n^t}\ dt\\&=\sum_{n=1}^\infty\frac{(-\ln n)^{-\alpha}}{n^x}\end{align}$$ Thanks to WolframAlpha for that last step.  I imagine the interchange between integral and sum can be made with rigor, but I can't see how at the moment.  Setting this into it's derivative form, I end up with $$D_x^\alpha\zeta(x)=\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ which shall be my fractional derivative of the Riemann zeta function. I then wish to take the following: (is differentiation with respect to the fractional derivative nonsensical?) $$D_\alpha^\beta D_x^\alpha\zeta(x)=D_\alpha^\beta\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ Again, using the Riemann-Liouville definition, I end up with $$D_\alpha^\beta\sum_{n=1}^\infty\frac{(-\ln n)^\alpha}{n^x}=\sum_{n=1}^\infty\frac{(\ln(-\ln n))^\beta(-\ln n)^\alpha}{n^x}$$ Which is a little weird since the summand is undefined at $n=1$.  What should I do about this? Also, my end goal is to get some crazy derivative of derivatives of the zeta function into $$\sum_{n=1?}^\infty\frac{\prod_{k=0}^p(\ \overbrace{\ln\ln\dots\ln\ln}^k\ n\ )^{a_k}}{n^x}$$ Any ideas? Simple idea: Rewriting the zeta function as $$\zeta(x)=1+\sum_{n=2}^\infty\frac1{n^x}$$ now removes the problem, and with linearity, should give us $$D_x^\alpha\zeta(x)=\frac1{\Gamma(1-\alpha)x^\alpha}+\sum_{n=2}^\infty\frac{(-\ln n)^\alpha}{n^x}$$ $$D_\alpha^\beta D_x^\alpha\zeta(x)=\left(D_\alpha^\beta\frac1{\Gamma(1-\alpha)x^\alpha}\right)+\sum_{n=2}^\infty\frac{(\ln(-\ln n))^\beta(-\ln n)^\alpha}{n^x}$$ Though this feels a tad bit unsafe.",,"['sequences-and-series', 'riemann-zeta', 'fractional-calculus']"
48,Series of non negative terms diverges then does $\frac{\sum a_i^2}{(\sum a_i)^2} \to 0$?,Series of non negative terms diverges then does ?,\frac{\sum a_i^2}{(\sum a_i)^2} \to 0,"Suppose $\{a_n\}_{n\ge 1}$ be a sequence of nonnegative numbers such that $\displaystyle \sum_{i=1}^n a_i \to \infty$. Suppose that there exist a distribution function $F$ (non decreasing, right continuous, $\displaystyle \lim_{x\to-\infty} F(x)=0$ and $\displaystyle \lim_{x\to \infty} F(x)=1$) with $F(0)=0$ such that for all $x\in \mathbb{R}$   $$\lim_{n\to\infty} \frac1n\sum_{i=1}^n \mathbb{I}_{(a_i \le x)}=F(x)$$    Then is it true that   $$\frac{\sum\limits_{i=1}^n a_i^2}{\left(\sum\limits_{i=1}^n a_i\right)^2} \to 0 \ \ ?$$ My try: Note that without the distribution condition the above limit is not true. Just take $a_n$ such that it dominates $a_1+a_2+\cdots+a_{n-1}$ for example we can take $a_n=n^{2n}$. Then $a_1+a_2+\cdots+a_{n-1}= \mathcal{O}(n^{2n-1})$ and the limit goes to 1. Suppose we define $x_{n}^2=\sum\limits_{i=1}^n a_i^2$ and $y_n=\sum\limits_{i=1}^n a_i$. and let $z_n^2=\frac{x_n^2}{y_n^2}$. Then $$\begin{aligned} z_{n+1}^2 & =\frac{x_{n}^2+a_{n+1}^2}{(y_n+a_{n+1})^2} \\ & = \frac{z_n^2+t_n^2}{(1+t_n)^2}\end{aligned}$$ where $t_n:= \frac{a_{n+1}}{a_1+a_2+\cdots+a_n}$. I am stuck here. Any help/suggestions?","Suppose $\{a_n\}_{n\ge 1}$ be a sequence of nonnegative numbers such that $\displaystyle \sum_{i=1}^n a_i \to \infty$. Suppose that there exist a distribution function $F$ (non decreasing, right continuous, $\displaystyle \lim_{x\to-\infty} F(x)=0$ and $\displaystyle \lim_{x\to \infty} F(x)=1$) with $F(0)=0$ such that for all $x\in \mathbb{R}$   $$\lim_{n\to\infty} \frac1n\sum_{i=1}^n \mathbb{I}_{(a_i \le x)}=F(x)$$    Then is it true that   $$\frac{\sum\limits_{i=1}^n a_i^2}{\left(\sum\limits_{i=1}^n a_i\right)^2} \to 0 \ \ ?$$ My try: Note that without the distribution condition the above limit is not true. Just take $a_n$ such that it dominates $a_1+a_2+\cdots+a_{n-1}$ for example we can take $a_n=n^{2n}$. Then $a_1+a_2+\cdots+a_{n-1}= \mathcal{O}(n^{2n-1})$ and the limit goes to 1. Suppose we define $x_{n}^2=\sum\limits_{i=1}^n a_i^2$ and $y_n=\sum\limits_{i=1}^n a_i$. and let $z_n^2=\frac{x_n^2}{y_n^2}$. Then $$\begin{aligned} z_{n+1}^2 & =\frac{x_{n}^2+a_{n+1}^2}{(y_n+a_{n+1})^2} \\ & = \frac{z_n^2+t_n^2}{(1+t_n)^2}\end{aligned}$$ where $t_n:= \frac{a_{n+1}}{a_1+a_2+\cdots+a_n}$. I am stuck here. Any help/suggestions?",,"['real-analysis', 'sequences-and-series', 'limits', 'probability-theory', 'probability-distributions']"
49,"$(a_n)$ is a sequence that converges to a>0. Prove that $\exists \delta \gt 0$ and $M \in \mathbb N$ such that $\forall n \ge M, a_n \ge \delta$.",is a sequence that converges to a>0. Prove that  and  such that .,"(a_n) \exists \delta \gt 0 M \in \mathbb N \forall n \ge M, a_n \ge \delta","$(a_n)$ is a sequence and $a_n \rightarrow a$, $a \gt 0$. Prove that $\exists \delta \gt 0$ and $M \in \mathbb N$ such that $\forall n \ge M, a_n \ge \delta$. Hello, everyone. This is my first post to the site, and I look forward to hearing your suggestions and feedback. I have attempted a proof, but something tells me that it is incorrect, and I am unsure of how to proceed. Here is what I have written: By the definition of convergence, $\forall \epsilon \gt 0$, $\exists N \in \mathbb N$ such that $n \ge N \rightarrow |a_n-a| \lt \epsilon$. This implies that $\forall \epsilon \gt 0, \exists N \in \mathbb N$ such that $\forall n \ge N, a_n \gt a- \epsilon$. Since $\epsilon$ is arbitrary, let $\epsilon \lt a$, so that $a-\epsilon \gt 0$. Let $\delta = a-\epsilon$, and let $M \ge N$. Then, $\forall n \ge M, a_n \ge \delta$.","$(a_n)$ is a sequence and $a_n \rightarrow a$, $a \gt 0$. Prove that $\exists \delta \gt 0$ and $M \in \mathbb N$ such that $\forall n \ge M, a_n \ge \delta$. Hello, everyone. This is my first post to the site, and I look forward to hearing your suggestions and feedback. I have attempted a proof, but something tells me that it is incorrect, and I am unsure of how to proceed. Here is what I have written: By the definition of convergence, $\forall \epsilon \gt 0$, $\exists N \in \mathbb N$ such that $n \ge N \rightarrow |a_n-a| \lt \epsilon$. This implies that $\forall \epsilon \gt 0, \exists N \in \mathbb N$ such that $\forall n \ge N, a_n \gt a- \epsilon$. Since $\epsilon$ is arbitrary, let $\epsilon \lt a$, so that $a-\epsilon \gt 0$. Let $\delta = a-\epsilon$, and let $M \ge N$. Then, $\forall n \ge M, a_n \ge \delta$.",,"['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
50,Find the limit of this function as $x\to\infty$,Find the limit of this function as,x\to\infty,"Prove that if a sequence of real numbers $(a_n)$ converges to $g$, then $\text{lim}_{x\to\infty}e^{-x}\sum_{n=0}^{\infty}a_n\frac{x^n}{n!}=g$. I'm not exactly sure how to do this. I tried looking at the partial sums firs $\sum_{n=0}^ka_n\frac{x^n}{n!}$. For a fixed $x$, I'm guessing that this converges to a function $g\cdot l(x)$ where $\frac{l(x)}{e^x}\to 0$ as $x\to\infty$. I'm not sure how to show this though. I tried to bound $|(a_1x+a_2x^2/2+...+a_kx^k/k!)-kx^kg|$, but wasn't getting anywhere. Does anyone have advice on how I should get started?","Prove that if a sequence of real numbers $(a_n)$ converges to $g$, then $\text{lim}_{x\to\infty}e^{-x}\sum_{n=0}^{\infty}a_n\frac{x^n}{n!}=g$. I'm not exactly sure how to do this. I tried looking at the partial sums firs $\sum_{n=0}^ka_n\frac{x^n}{n!}$. For a fixed $x$, I'm guessing that this converges to a function $g\cdot l(x)$ where $\frac{l(x)}{e^x}\to 0$ as $x\to\infty$. I'm not sure how to show this though. I tried to bound $|(a_1x+a_2x^2/2+...+a_kx^k/k!)-kx^kg|$, but wasn't getting anywhere. Does anyone have advice on how I should get started?",,"['calculus', 'sequences-and-series']"
51,Approximation the sum $\sum\limits_{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}}$,Approximation the sum,\sum\limits_{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}},"I would like to find lower and upper bounds on the following sum \begin{align} \sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \end{align} where $c,a>0$ and $k>1$. Note that if we could approximate this sum with an integral then  \begin{align} \sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \approx \int _{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} dn=  -\frac{2 a}{k} e^{-\frac{(c+n)^k}{2*a}} |_0^\infty=\frac{2 a}{k} e^{-\frac{c^k}{2*a}} \end{align} then one might guess that the bounds are  \begin{align} \frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_1 \le\sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \le \frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_2 \end{align} My question is how can this be done or is there a better method  to give lower and upper bounds? I also know that there are bounds of the form \begin{align} \int_0^\infty f(x) dx \le \sum_{n=0}^\infty f(n) \le f(0) + \int_0^\infty f(x) dx \end{align} but they only hold if $f(x)$ is monotone decreasing which is not the case here. Thanks.","I would like to find lower and upper bounds on the following sum \begin{align} \sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \end{align} where $c,a>0$ and $k>1$. Note that if we could approximate this sum with an integral then  \begin{align} \sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \approx \int _{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} dn=  -\frac{2 a}{k} e^{-\frac{(c+n)^k}{2*a}} |_0^\infty=\frac{2 a}{k} e^{-\frac{c^k}{2*a}} \end{align} then one might guess that the bounds are  \begin{align} \frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_1 \le\sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \le \frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_2 \end{align} My question is how can this be done or is there a better method  to give lower and upper bounds? I also know that there are bounds of the form \begin{align} \int_0^\infty f(x) dx \le \sum_{n=0}^\infty f(n) \le f(0) + \int_0^\infty f(x) dx \end{align} but they only hold if $f(x)$ is monotone decreasing which is not the case here. Thanks.",,"['calculus', 'real-analysis', 'sequences-and-series', 'approximation']"
52,"Limits of $a_n, b_n, c_n$",Limits of,"a_n, b_n, c_n","Three given positive $a_1, b_1, c_1$, such that $a_1+b_1+c_1=1, \forall\ n,$     $$a_{n+1}=a_n^2+2b_nc_n, b_{n+1}=b_n^2+2a_nc_n, c_{n+1}=c_n^2+2a_nb_n$$     Prove $\{a_n\},\{b_n\}$ and $ \{c_n\} $ are convergent. I have noticed that if I add three equalities together, then get  $$a_{n+1}+b_{n+1}+c_{n+1}=(a_n+b_n+c_n)^2$$ This means $\forall \ n, a_n+b_n+c_n=1$. Also, I get  $$a_{n+1}-b_{n+1}=(a_1-b_1)\prod_{i=1}^n(1-3c_i).$$ But I don't know how to continue proving they are convergent? Sincerely thanks for our help.","Three given positive $a_1, b_1, c_1$, such that $a_1+b_1+c_1=1, \forall\ n,$     $$a_{n+1}=a_n^2+2b_nc_n, b_{n+1}=b_n^2+2a_nc_n, c_{n+1}=c_n^2+2a_nb_n$$     Prove $\{a_n\},\{b_n\}$ and $ \{c_n\} $ are convergent. I have noticed that if I add three equalities together, then get  $$a_{n+1}+b_{n+1}+c_{n+1}=(a_n+b_n+c_n)^2$$ This means $\forall \ n, a_n+b_n+c_n=1$. Also, I get  $$a_{n+1}-b_{n+1}=(a_1-b_1)\prod_{i=1}^n(1-3c_i).$$ But I don't know how to continue proving they are convergent? Sincerely thanks for our help.",,"['sequences-and-series', 'limits', 'limits-without-lhopital']"
53,How to prove this continued fraction connection between $\gamma$ and $e$?,How to prove this continued fraction connection between  and ?,\gamma e,"There is apparently a curious connection between Euler-Mascheroni constant $\gamma$ and $e$ in the form of an infinite series and continued fraction: $$e \gamma=e \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n!~n}-\cfrac{1}{2-\cfrac{1}{4-\cfrac{4}{6-\cfrac{9}{8-\cfrac{16}{10-\cdots}}}}}$$ As can be seen, the partial denominators and numerators have the form $2n$ and $-n^2$ respectively. How can we prove this? Might it be a useful method to compute $\gamma$?","There is apparently a curious connection between Euler-Mascheroni constant $\gamma$ and $e$ in the form of an infinite series and continued fraction: $$e \gamma=e \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n!~n}-\cfrac{1}{2-\cfrac{1}{4-\cfrac{4}{6-\cfrac{9}{8-\cfrac{16}{10-\cdots}}}}}$$ As can be seen, the partial denominators and numerators have the form $2n$ and $-n^2$ respectively. How can we prove this? Might it be a useful method to compute $\gamma$?",,"['sequences-and-series', 'special-functions', 'continued-fractions', 'euler-mascheroni-constant']"
54,Prove that for $k>1$ $a_n$ is a perfect square,Prove that for   is a perfect square,k>1 a_n,"I'm having problems with this exercise. Let $k > 1$ be an integer. We define $(a_n)_{n \in \Bbb N_0}$ as: $$a_0 = 1$$ $$a_1 = 1$$ $$a_{n+2} = (k^2-2)a_{n+1}-a_n-2(k-2)$$ Prove that $\forall n \in \Bbb N_0, a_n$ is a perfect square. I'm not sure how to tackle this problem. I want to prove that $a_n=(a+b)^2$ in some way. I was going to attempt with induction, $P(0)$ and $P(1)$ are true, $P(2)=(k-1)^2$... but how should I pick $P(n)$ and $P(n+1)$. Or should I try other method? I've also tried finding the roots so I could have the closed formula for the sequence but I've ended up with a rather disappointing looking expression: $\frac{(k^2-2) \pm \sqrt{k^4-4k^2-8k+16}}{2}$ Any ideas or suggestions? Thanks!","I'm having problems with this exercise. Let $k > 1$ be an integer. We define $(a_n)_{n \in \Bbb N_0}$ as: $$a_0 = 1$$ $$a_1 = 1$$ $$a_{n+2} = (k^2-2)a_{n+1}-a_n-2(k-2)$$ Prove that $\forall n \in \Bbb N_0, a_n$ is a perfect square. I'm not sure how to tackle this problem. I want to prove that $a_n=(a+b)^2$ in some way. I was going to attempt with induction, $P(0)$ and $P(1)$ are true, $P(2)=(k-1)^2$... but how should I pick $P(n)$ and $P(n+1)$. Or should I try other method? I've also tried finding the roots so I could have the closed formula for the sequence but I've ended up with a rather disappointing looking expression: $\frac{(k^2-2) \pm \sqrt{k^4-4k^2-8k+16}}{2}$ Any ideas or suggestions? Thanks!",,"['sequences-and-series', 'number-theory', 'recursion', 'square-numbers']"
55,Theorem 3.37 in Baby Rudin: $\lim\inf\frac{c_{n+1}}{c_n}\leq\lim\inf\sqrt[n]{c_n}\leq\lim\sup\sqrt[n]{c_n}\leq \lim\sup\frac{c_{n+1}}{c_n}$,Theorem 3.37 in Baby Rudin:,\lim\inf\frac{c_{n+1}}{c_n}\leq\lim\inf\sqrt[n]{c_n}\leq\lim\sup\sqrt[n]{c_n}\leq \lim\sup\frac{c_{n+1}}{c_n},"Here's Theorem 3.37 in the book Principles of Mathematical Analysis by Walter Rudin, third edition: For any sequence $\{c_n\}$ of positive numbers, $$\lim_{n\to\infty} \inf \frac{c_{n+1}}{c_n} \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$ $$ \lim_{n\to\infty} \sup \sqrt[n]{c_n} \leq \lim_{n\to\infty} \sup \frac{c_{n+1}}{c_n}.$$ Now Rudin has given a proof of the second inequality. Here's my proof of the first. Let $$\alpha = \lim_{n\to\infty} \inf \frac{c_{n+1}}{c_n}.$$ Then $\alpha \geq 0$. If $\alpha = 0$, then we're done since $$\lim_{n\to\infty} \sqrt[n]{c_n} \geq 0.$$ So we suppose that $\alpha > 0$ and choose a real number $\beta$ such that $0 < \beta < \alpha$. Then by the result analogous to Theorem 3.17 (b), there is an integer $N$ such that $n \geq N$ implies $$ \frac{c_{n+1}}{c_n} > \beta,$$ which in turn implies $$c_{n+1} > \beta c_n.$$   So for each $n \geq N$, we have    $$c_n \geq  \left( c_N \cdot \beta^{-N} \right) \cdot \beta^n. $$   Thus, for $n \geq N$, we have $$\sqrt[n]{c_n} \geq \beta \sqrt[n]{  c_N \cdot \beta^{-N}  }.$$ Then taking the limit inferior of both sides, we get    $$\lim_{n\to\infty}\inf \sqrt[n]{c_n} \geq \lim_{n\to\infty} \inf \left( \beta \sqrt[n]{ c_N \beta^N} \right) = \lim_{n\to\infty} \left( \beta \sqrt[n]{ c_N \beta^N} \right) = \beta \cdot 1 = \beta$$   by Theorem 3.20 (b). Thus we have shown that for any (positive) real number $\beta$ such that $\beta < \alpha$, we have $$\beta \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$    which implies that $$\alpha \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$ as required. Is the above proof correct? If so, then is my presentation good enough? If not, then where does the problem lie?","Here's Theorem 3.37 in the book Principles of Mathematical Analysis by Walter Rudin, third edition: For any sequence $\{c_n\}$ of positive numbers, $$\lim_{n\to\infty} \inf \frac{c_{n+1}}{c_n} \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$ $$ \lim_{n\to\infty} \sup \sqrt[n]{c_n} \leq \lim_{n\to\infty} \sup \frac{c_{n+1}}{c_n}.$$ Now Rudin has given a proof of the second inequality. Here's my proof of the first. Let $$\alpha = \lim_{n\to\infty} \inf \frac{c_{n+1}}{c_n}.$$ Then $\alpha \geq 0$. If $\alpha = 0$, then we're done since $$\lim_{n\to\infty} \sqrt[n]{c_n} \geq 0.$$ So we suppose that $\alpha > 0$ and choose a real number $\beta$ such that $0 < \beta < \alpha$. Then by the result analogous to Theorem 3.17 (b), there is an integer $N$ such that $n \geq N$ implies $$ \frac{c_{n+1}}{c_n} > \beta,$$ which in turn implies $$c_{n+1} > \beta c_n.$$   So for each $n \geq N$, we have    $$c_n \geq  \left( c_N \cdot \beta^{-N} \right) \cdot \beta^n. $$   Thus, for $n \geq N$, we have $$\sqrt[n]{c_n} \geq \beta \sqrt[n]{  c_N \cdot \beta^{-N}  }.$$ Then taking the limit inferior of both sides, we get    $$\lim_{n\to\infty}\inf \sqrt[n]{c_n} \geq \lim_{n\to\infty} \inf \left( \beta \sqrt[n]{ c_N \beta^N} \right) = \lim_{n\to\infty} \left( \beta \sqrt[n]{ c_N \beta^N} \right) = \beta \cdot 1 = \beta$$   by Theorem 3.20 (b). Thus we have shown that for any (positive) real number $\beta$ such that $\beta < \alpha$, we have $$\beta \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$    which implies that $$\alpha \leq \lim_{n\to\infty} \inf \sqrt[n]{c_n},$$ as required. Is the above proof correct? If so, then is my presentation good enough? If not, then where does the problem lie?",,"['real-analysis', 'sequences-and-series', 'analysis', 'proof-verification', 'limsup-and-liminf']"
56,How to determine if this musical exercise is valid: will the pattern complete?,How to determine if this musical exercise is valid: will the pattern complete?,,"I'm hoping that math has an answer to a question arising out of a musical exercise. In music terms, the exercise is: Choose two arpeggios (sets of notes) of equal (or roughly equal) span (number of notes and distance between them) Start at the bottom of one, and play N notes going upwards until the top, then back down again After N, chose the very next note from the ""other"" arpeggio in the same direction you are going and repeat (play N notes) until you have done ""every possible transition from one arpeggio to the other"" I am trying to figure out what characteristics of the arpeggios determine whether: you will in fact go through every possible transition from one arpeggio to the other? Whether this also means inherently that you arrive back where you started. That, in a nutshell, is the question. The exercise was given with arpeggios of length 10 and N=8 Here is my attempt to cast it in a "" mathemetical way "", escaping the musical context. We have a an ordered set of nodes (aka notes :) ). In this case 30 of them.  Their ordinality can be represented by a number - they are numbered, and ""higher"" means... higher in the numerical sense. (N1, N2, ..., N30) We take two subsets, call them 'A' and 'D'.   These have equal size (in this case 10). A: (N1, N5, N8, N11, N13, N17, N20, N23, N25, N29)  D: (N1, N4, N6, N10, N13, N16, N18, N22, N25, N28) An ""up"" transition means ""find the next highest number in the target set to the current one"".   Inversely for a down transition. We can transition inside the current set or to the ""other"" set. The exercise is: Start in the direction 'up"", at the lowest node in set A and make N transitions in set A If at any point there are no remaining notes upwards, reverse direction Having made N transitions in set A, transition in the same direction to set D Make N transitions in Set D, then transition to set A ... repeat until all transitions have been made. The question is: what characteristics of the sets (A and D) determine whether you will take every possible transition? (and thus arrive back at ""the beginning"") With N=8, the sequence starts like this: start in A : N1, N5, N8, N11, N13, N17, N20, N23,   trans to D : N25, N28, N25, N22, N18, N16, N13, N10,   trans to A : N8, N5, N1, N5, N8, N11 ... and the question is ""do we 'trans to X: NY' for all X in A,D and Y in nodes-in-A-and-D ?"""" (And a simpler question - ""do we ever arrive back at 'trans to A: N1'?"") I tried to represent this graphically.   I laid out the initial set of 30 notes, then illustrated the subsets A and D.   Then I drew in all the possible transitions. In doing so I discovered that the specific sets (A and D) from the exercise have some interesting properties: they have some nodes in common, which result in one-way transitions, which I have highlighted. (Edit: deleted detailed discussion of how I simulated this for guitar - I think it was a distraction). I wrote a simulation of this.   When I run it for N=3, what I see is that I do get back to the beginning and thus will repeat from here, but not every transition was covered. A:N1 -> A:N5 -> A:N8 -> D:N10 -> D:N13 -> D:N16 -> A:N17 -> A:N20 -> A:N23 ->  D:N25 -> D:N28 -> D:N25 -> A:N23 -> A:N20 -> A:N17 -> D:N16 -> D:N13 ->  D:N10 -> A:N8 -> A:N5 -> A:N1 -> D:N4 -> D:N6 -> D:N10 -> A:N11 -> A:N13 -> A:N17 ->  D:N18 -> D:N22 -> D:N25 -> A:N29 -> A:N25 -> A:N23 -> D:N22 -> D:N18 -> D:N16 ->  A:N13 -> A:N11 -> A:N8 -> D:N6 -> D:N4 -> D:N1 -> A:N5 -> A:N8 -> A:N11 ->  D:N13 -> D:N16 -> D:N18 -> A:N20 -> A:N23 -> A:N25 -> D:N28 -> D:N25 -> D:N22 ->  A:N20 -> A:N17 -> A:N13 -> D:N10 -> D:N6 -> D:N4 -> A:N1 The missing two that this sequence does not transition to are A:N25 and D:N1. With N=8 the sequence is much longer before it repeats, but also ""worse"".   Worse in the sense that it does not arrive back at the beginning before repeating, and it leaves more ""holes"". Is there some way to look at this, or represent the problem, such that you could deduce this outcome without simulating it? Update : for those who can relate better to musical notation, here are the figures in musical notation. The A arpeggio: The D arpeggio The simulation of N=3 run of the exercise - 3 notes per bar, alternating A7 arpeggio and D7 arpeggio (note that the generator does not carry accidentals over bars):","I'm hoping that math has an answer to a question arising out of a musical exercise. In music terms, the exercise is: Choose two arpeggios (sets of notes) of equal (or roughly equal) span (number of notes and distance between them) Start at the bottom of one, and play N notes going upwards until the top, then back down again After N, chose the very next note from the ""other"" arpeggio in the same direction you are going and repeat (play N notes) until you have done ""every possible transition from one arpeggio to the other"" I am trying to figure out what characteristics of the arpeggios determine whether: you will in fact go through every possible transition from one arpeggio to the other? Whether this also means inherently that you arrive back where you started. That, in a nutshell, is the question. The exercise was given with arpeggios of length 10 and N=8 Here is my attempt to cast it in a "" mathemetical way "", escaping the musical context. We have a an ordered set of nodes (aka notes :) ). In this case 30 of them.  Their ordinality can be represented by a number - they are numbered, and ""higher"" means... higher in the numerical sense. (N1, N2, ..., N30) We take two subsets, call them 'A' and 'D'.   These have equal size (in this case 10). A: (N1, N5, N8, N11, N13, N17, N20, N23, N25, N29)  D: (N1, N4, N6, N10, N13, N16, N18, N22, N25, N28) An ""up"" transition means ""find the next highest number in the target set to the current one"".   Inversely for a down transition. We can transition inside the current set or to the ""other"" set. The exercise is: Start in the direction 'up"", at the lowest node in set A and make N transitions in set A If at any point there are no remaining notes upwards, reverse direction Having made N transitions in set A, transition in the same direction to set D Make N transitions in Set D, then transition to set A ... repeat until all transitions have been made. The question is: what characteristics of the sets (A and D) determine whether you will take every possible transition? (and thus arrive back at ""the beginning"") With N=8, the sequence starts like this: start in A : N1, N5, N8, N11, N13, N17, N20, N23,   trans to D : N25, N28, N25, N22, N18, N16, N13, N10,   trans to A : N8, N5, N1, N5, N8, N11 ... and the question is ""do we 'trans to X: NY' for all X in A,D and Y in nodes-in-A-and-D ?"""" (And a simpler question - ""do we ever arrive back at 'trans to A: N1'?"") I tried to represent this graphically.   I laid out the initial set of 30 notes, then illustrated the subsets A and D.   Then I drew in all the possible transitions. In doing so I discovered that the specific sets (A and D) from the exercise have some interesting properties: they have some nodes in common, which result in one-way transitions, which I have highlighted. (Edit: deleted detailed discussion of how I simulated this for guitar - I think it was a distraction). I wrote a simulation of this.   When I run it for N=3, what I see is that I do get back to the beginning and thus will repeat from here, but not every transition was covered. A:N1 -> A:N5 -> A:N8 -> D:N10 -> D:N13 -> D:N16 -> A:N17 -> A:N20 -> A:N23 ->  D:N25 -> D:N28 -> D:N25 -> A:N23 -> A:N20 -> A:N17 -> D:N16 -> D:N13 ->  D:N10 -> A:N8 -> A:N5 -> A:N1 -> D:N4 -> D:N6 -> D:N10 -> A:N11 -> A:N13 -> A:N17 ->  D:N18 -> D:N22 -> D:N25 -> A:N29 -> A:N25 -> A:N23 -> D:N22 -> D:N18 -> D:N16 ->  A:N13 -> A:N11 -> A:N8 -> D:N6 -> D:N4 -> D:N1 -> A:N5 -> A:N8 -> A:N11 ->  D:N13 -> D:N16 -> D:N18 -> A:N20 -> A:N23 -> A:N25 -> D:N28 -> D:N25 -> D:N22 ->  A:N20 -> A:N17 -> A:N13 -> D:N10 -> D:N6 -> D:N4 -> A:N1 The missing two that this sequence does not transition to are A:N25 and D:N1. With N=8 the sequence is much longer before it repeats, but also ""worse"".   Worse in the sense that it does not arrive back at the beginning before repeating, and it leaves more ""holes"". Is there some way to look at this, or represent the problem, such that you could deduce this outcome without simulating it? Update : for those who can relate better to musical notation, here are the figures in musical notation. The A arpeggio: The D arpeggio The simulation of N=3 run of the exercise - 3 notes per bar, alternating A7 arpeggio and D7 arpeggio (note that the generator does not carry accidentals over bars):",,"['sequences-and-series', 'music-theory']"
57,Express a real number as a product,Express a real number as a product,,"Hi guys if I have a number $x \in [1,2)$ is it possible to express such number as: $$x = \prod_{j=0}^{+\infty} (1 + \alpha_j 2^{-j})$$ where each $\alpha_j \in \left\{-1,0,1\right\}$? If yes, how could it be proven? Also assuming such sequence exists, is the sequence $\left\{ \alpha_j \right\}_{j\in \mathbb{N}}$ unique? I tried by starting with the representation $$x = 1 + \sum_{j=1}^{+\infty} x_j 2^{-j}, x_j \in \left\{0,1\right\}$$ but I didn't end up with anything...","Hi guys if I have a number $x \in [1,2)$ is it possible to express such number as: $$x = \prod_{j=0}^{+\infty} (1 + \alpha_j 2^{-j})$$ where each $\alpha_j \in \left\{-1,0,1\right\}$? If yes, how could it be proven? Also assuming such sequence exists, is the sequence $\left\{ \alpha_j \right\}_{j\in \mathbb{N}}$ unique? I tried by starting with the representation $$x = 1 + \sum_{j=1}^{+\infty} x_j 2^{-j}, x_j \in \left\{0,1\right\}$$ but I didn't end up with anything...",,"['real-analysis', 'sequences-and-series', 'number-theory']"
58,Show that a sequence of functions convergent pointwise to $\chi_{\mathbb Q}$ does not exist [duplicate],Show that a sequence of functions convergent pointwise to  does not exist [duplicate],\chi_{\mathbb Q},"This question already has answers here : Existence of a sequence of continuous functions convergent pointwise to the indicator function of irrational numbers (2 answers) Closed 8 years ago . Prove that there isn't a sequence of continuous function on $[0,1]$ that converges pointwise to the function $f$ on $[0,1]$ defined by $f(x)=0$ if $x$ is rational and $f(x)=1$ if $x$ is irrational. What I've tried: By contradiction: Suppose that indeed exists one(say $f_n$) and let's take $a$ in $[0,1]\cap \mathbb{Q}$, then $f_n(a)$ approaches to $0$ when $n$ is sufficiently large, say $n\ge N$. Let's take in particular $n=N$. Since $f_N$ is continuous, there exists a neighborhood of $a$, $(a-d,a+d)$, in which $f_N(x)$ is near $f_N(a)$, and thus is near to $0$. Let's take now $b$ irrational in that neighborhood. Then, for $n$ sufficiently large,say $n\ge K$, $f_n(b)$ is near $1$. This should be the contradiction, since $b$ would be at the same time near $0$ and $1$ (suppose I've chosen the right epsilons). The problem is that the $K$ may be larger than the $N$, and so there is no contradiction. If I then try to make the $N$ larger, then I modify the $d$, which modifies the $b$, and therefore there's no sense in taking that particular $b$. I've also tried to apply continuity to $f_k(x)$, but the neighborhood in which $f_k(x)$ is near $f_k(b)$ (which is near $1$) may not have anything in common with the previous neighborhood... I wish you could help me.  Thanks in advance.","This question already has answers here : Existence of a sequence of continuous functions convergent pointwise to the indicator function of irrational numbers (2 answers) Closed 8 years ago . Prove that there isn't a sequence of continuous function on $[0,1]$ that converges pointwise to the function $f$ on $[0,1]$ defined by $f(x)=0$ if $x$ is rational and $f(x)=1$ if $x$ is irrational. What I've tried: By contradiction: Suppose that indeed exists one(say $f_n$) and let's take $a$ in $[0,1]\cap \mathbb{Q}$, then $f_n(a)$ approaches to $0$ when $n$ is sufficiently large, say $n\ge N$. Let's take in particular $n=N$. Since $f_N$ is continuous, there exists a neighborhood of $a$, $(a-d,a+d)$, in which $f_N(x)$ is near $f_N(a)$, and thus is near to $0$. Let's take now $b$ irrational in that neighborhood. Then, for $n$ sufficiently large,say $n\ge K$, $f_n(b)$ is near $1$. This should be the contradiction, since $b$ would be at the same time near $0$ and $1$ (suppose I've chosen the right epsilons). The problem is that the $K$ may be larger than the $N$, and so there is no contradiction. If I then try to make the $N$ larger, then I modify the $d$, which modifies the $b$, and therefore there's no sense in taking that particular $b$. I've also tried to apply continuity to $f_k(x)$, but the neighborhood in which $f_k(x)$ is near $f_k(b)$ (which is near $1$) may not have anything in common with the previous neighborhood... I wish you could help me.  Thanks in advance.",,['sequences-and-series']
59,A conjecture about prime numbers based on $\sigma_1(n)$ and the Highly Abundant Numbers,A conjecture about prime numbers based on  and the Highly Abundant Numbers,\sigma_1(n),"I am trying to find the smallest expression $E(n)$ , whose distances between the value of the expression and the next prime closer to the expression, $\mathcal{N}(E(n))$ , and from the expression to the previous closer prime, $\mathcal{P}(E(n))$ , are both prime numbers or $1$ . (1) $\mathcal{N}(E(n))-E(n)\ \in \{1,\Bbb P\}$ . (2) $E(n)-\mathcal{P}(E(n))\ \in \{1,\Bbb P\}$ . It is based in the same idea as the Fortunate Numbers , to know more about the reasons why I did the test please check here (longer explanation). I tried several combinations, but the following one seems to work properly so far and is not related with factorials or primorials, so I believe it would be easier to test: $E(n)$ ={ $m$ whose $\sigma_1(m)$ value is the $n^{th}$ element of the Record value sequence of $\sigma_1(m)$ (sum of divisors of m) ( A034885 )}$ ""Record values"" are defined as the subset of values $\sigma_1(m)$ of the set of sum of divisors of $m \in \Bbb N$ who are bigger than any previous values of the set, up to that value $m$ , so it provides a strictly increasing set of values of $\sigma_1(m)$ . Those are exactly the values of OEIS A034885 $(1,3,4,7,12,15,18,28,31,39,42...)$ . And they are exactly (thanks to @Ivan Neretin for the suggestion in the answers!) the Highly Abundant Numbers sequence (OEIS A002093 ): $\{1,2,3,4,6,8,10,12,16,18,20,24,30,36,42,48...\}$ The point is that tested almost up to $10^{27}$ both the distances of those elements $E(n)$ to the previous and following closer primes (when there is a previous positive prime) is also a prime number or $1$ . Here is a sample PARI/GP code able to check easily up to $10^9$ : testlimit = 10^9;n=1;exitval=0;prevsumdiv=0;while((n<testlimit) && (exitval==0),dj=divisors(n);sum_div=0;for(t=1,length(dj),sum_div=sum_div+dj[t]);while(sum_div<=prevsumdiv,sum_div=0;n=n+1;dj=divisors(n);for(t=1,length(dj),sum_div=sum_div+dj[t]));prevsumdiv = sum_div;np=nextprime(n+1);npmn=np-n;pp=precprime(n-1);nmpp=n-pp;if((nmpp==1 || isprime(nmpp)) && (npmn==1 || isprime(npmn)), print(""n= "",n,"" sigma1(n)= "",sum_div,"" N(n)= "",np,"" N(n)-n= "", npmn ,"" P(n)= "",pp,"" n-P(n)= "", nmpp);,exitval=1;)); After that point, I have been able to reduce the expression. It is possible to use instead of $\sigma_1(m)$ a reduced version of the sum of divisors, I will call it $\sigma_e(m)$ defined as the sum of the even composite divisors of $m$ not including $m$ itself in case of being even. In other words, it is the sum of divisors not including the sum of the prime numbers that are divisors, odd divisors, $1$ and $m$ itself. $E(n)$ is: $E(n)$ ={ $m$ whose $\sigma_e(m)$ value is the $n^{th}$ element of the Record value sequence of $\sigma_e(m)$ (sum of composite even divisors of m not including m in case of being even)}$ So it is not required to use A034885 anymore. Apart from this expression, I tried also using the sum of the prime divisors of $m$ , and other combinations of partial sums of the divisors of $m$ , including $1$ and $m$ itself, but those ones did not work. The even divisors seem to be the key. This is an example including the interval [1,99]. Please I would like to ask the following questions: Why does it happen? I can not imagine which possible reason is behind that property. Some insights would be very welcomed! Are there similar expressions based on other non-factorial functions? so far I have tried using the totient function and some sums of divisors of even numbers instead of $\sigma_e(n)$ , all of them unsuccessfully. I did not find any reference to this property, if it was already tested please I would like to know about it. Thank you! Last update 2016/01/05 : amazingly $\forall h \in $ {Highly Abundant Numbers}, $h\gt3$ ,tested up to $10^{27}$ no counterexamples found, the closest prime number $p \lt h$ located to a distance $d=(h-p) \gt 1$ is also always at a prime distance, so $d \in \Bbb P$ . If the test is not wrong, these would mean that the even Highly Abundant Numbers greater than $2$ have always at least a Goldbach pair of primes. $h=p+d, p,d\in\Bbb P$","I am trying to find the smallest expression , whose distances between the value of the expression and the next prime closer to the expression, , and from the expression to the previous closer prime, , are both prime numbers or . (1) . (2) . It is based in the same idea as the Fortunate Numbers , to know more about the reasons why I did the test please check here (longer explanation). I tried several combinations, but the following one seems to work properly so far and is not related with factorials or primorials, so I believe it would be easier to test: ={ whose value is the element of the Record value sequence of (sum of divisors of m) ( A034885 )}$ ""Record values"" are defined as the subset of values of the set of sum of divisors of who are bigger than any previous values of the set, up to that value , so it provides a strictly increasing set of values of . Those are exactly the values of OEIS A034885 . And they are exactly (thanks to @Ivan Neretin for the suggestion in the answers!) the Highly Abundant Numbers sequence (OEIS A002093 ): The point is that tested almost up to both the distances of those elements to the previous and following closer primes (when there is a previous positive prime) is also a prime number or . Here is a sample PARI/GP code able to check easily up to : testlimit = 10^9;n=1;exitval=0;prevsumdiv=0;while((n<testlimit) && (exitval==0),dj=divisors(n);sum_div=0;for(t=1,length(dj),sum_div=sum_div+dj[t]);while(sum_div<=prevsumdiv,sum_div=0;n=n+1;dj=divisors(n);for(t=1,length(dj),sum_div=sum_div+dj[t]));prevsumdiv = sum_div;np=nextprime(n+1);npmn=np-n;pp=precprime(n-1);nmpp=n-pp;if((nmpp==1 || isprime(nmpp)) && (npmn==1 || isprime(npmn)), print(""n= "",n,"" sigma1(n)= "",sum_div,"" N(n)= "",np,"" N(n)-n= "", npmn ,"" P(n)= "",pp,"" n-P(n)= "", nmpp);,exitval=1;)); After that point, I have been able to reduce the expression. It is possible to use instead of a reduced version of the sum of divisors, I will call it defined as the sum of the even composite divisors of not including itself in case of being even. In other words, it is the sum of divisors not including the sum of the prime numbers that are divisors, odd divisors, and itself. is: ={ whose value is the element of the Record value sequence of (sum of composite even divisors of m not including m in case of being even)}$ So it is not required to use A034885 anymore. Apart from this expression, I tried also using the sum of the prime divisors of , and other combinations of partial sums of the divisors of , including and itself, but those ones did not work. The even divisors seem to be the key. This is an example including the interval [1,99]. Please I would like to ask the following questions: Why does it happen? I can not imagine which possible reason is behind that property. Some insights would be very welcomed! Are there similar expressions based on other non-factorial functions? so far I have tried using the totient function and some sums of divisors of even numbers instead of , all of them unsuccessfully. I did not find any reference to this property, if it was already tested please I would like to know about it. Thank you! Last update 2016/01/05 : amazingly {Highly Abundant Numbers}, ,tested up to no counterexamples found, the closest prime number located to a distance is also always at a prime distance, so . If the test is not wrong, these would mean that the even Highly Abundant Numbers greater than have always at least a Goldbach pair of primes.","E(n) \mathcal{N}(E(n)) \mathcal{P}(E(n)) 1 \mathcal{N}(E(n))-E(n)\ \in \{1,\Bbb P\} E(n)-\mathcal{P}(E(n))\ \in \{1,\Bbb P\} E(n) m \sigma_1(m) n^{th} \sigma_1(m) \sigma_1(m) m \in \Bbb N m \sigma_1(m) (1,3,4,7,12,15,18,28,31,39,42...) \{1,2,3,4,6,8,10,12,16,18,20,24,30,36,42,48...\} 10^{27} E(n) 1 10^9 \sigma_1(m) \sigma_e(m) m m 1 m E(n) E(n) m \sigma_e(m) n^{th} \sigma_e(m) m m 1 m \sigma_e(n) \forall h \in  h\gt3 10^{27} p \lt h d=(h-p) \gt 1 d \in \Bbb P 2 h=p+d, p,d\in\Bbb P","['sequences-and-series', 'elementary-number-theory', 'prime-numbers', 'conjectures', 'divisor-sum']"
60,Uniform convergence of $\sum_{n \ge 0} (-1)^n(1-x)x^n$,Uniform convergence of,\sum_{n \ge 0} (-1)^n(1-x)x^n,"Let $f_n: [0,1] \to \mathbb{R}$, $f_n(x)=(-1)^n (1-x)x^n, \forall x\in [0,1], n \ge 0$. Prove that $\sum\limits_{n \ge 0} f_n(x)$ convergenes uniformly. Let $S_n(x) = \sum\limits_{k = 0}^n f_k(x), \forall x \in [0,1], n \ge 0$. Then, $S_n(x)=1-x-x+x^2+x^2-x^3-x^3+x^4+...+(-1)^{n-1}x^{n-1}+(-1)^nx^n+(-1)^nx^n+(-1)^{n+1}x^{n+1}$ so $S_n(x)=1-2x+2x^2-...+(-1)^n\cdot 2x^n+(-1)^{n+1}x^{n+1}, \forall x\in [0,1], n \ge 0$. We know that $1+x^{2p+1}=(1+x)(x^{2p}-x^{2p-1}+x^{2p-2}-....+x^2-x+1)$, so, for $n=2p$, $p \ge 0$, we may write: $$ S_{2p}= 2(1-x+x^2-...+x^{2p})-1-x^{2p+1}=2 \cdot \frac{1+x^{2p+1}}{1+x}-1-x^{2p+1}$$ Now, it's easy to see that $\lim\limits_{p \to \infty}S_{2p}(x)=\frac{1-x}{1+x}, \forall x\in [0,1]$. For $n=2p+1$, $p \ge 0$, we have: $$ S_{2p+1}(x)=2(1-x+x^2-...+x^{2p+2})-1-x^{2p+2}=2\cdot \frac{1+x^{2p+3}}{1+x} -1 -x^{2p+2} $$ In this case we have: $\lim\limits_{p \to \infty} S_{2p+1}(x) = \frac{1-x}{1+x}, \forall x\in [0,1]$. So, $\lim\limits_{n \to \infty} S_n(x) =\frac{1-x}{1+x}, \forall x\in [0,1]$. Now, it remains to prove that $\lim\limits_{n\to \infty} \sup\limits_{x \in [0,1]} |S_n(x)-\frac{1-x}{1+x}|=0$. It's easy to see that $g_n(x)=|S_n(x)-\frac{1-x}{1+x}|=x^{n+1} \cdot \frac{1-x}{1+x}$. How can I continue?","Let $f_n: [0,1] \to \mathbb{R}$, $f_n(x)=(-1)^n (1-x)x^n, \forall x\in [0,1], n \ge 0$. Prove that $\sum\limits_{n \ge 0} f_n(x)$ convergenes uniformly. Let $S_n(x) = \sum\limits_{k = 0}^n f_k(x), \forall x \in [0,1], n \ge 0$. Then, $S_n(x)=1-x-x+x^2+x^2-x^3-x^3+x^4+...+(-1)^{n-1}x^{n-1}+(-1)^nx^n+(-1)^nx^n+(-1)^{n+1}x^{n+1}$ so $S_n(x)=1-2x+2x^2-...+(-1)^n\cdot 2x^n+(-1)^{n+1}x^{n+1}, \forall x\in [0,1], n \ge 0$. We know that $1+x^{2p+1}=(1+x)(x^{2p}-x^{2p-1}+x^{2p-2}-....+x^2-x+1)$, so, for $n=2p$, $p \ge 0$, we may write: $$ S_{2p}= 2(1-x+x^2-...+x^{2p})-1-x^{2p+1}=2 \cdot \frac{1+x^{2p+1}}{1+x}-1-x^{2p+1}$$ Now, it's easy to see that $\lim\limits_{p \to \infty}S_{2p}(x)=\frac{1-x}{1+x}, \forall x\in [0,1]$. For $n=2p+1$, $p \ge 0$, we have: $$ S_{2p+1}(x)=2(1-x+x^2-...+x^{2p+2})-1-x^{2p+2}=2\cdot \frac{1+x^{2p+3}}{1+x} -1 -x^{2p+2} $$ In this case we have: $\lim\limits_{p \to \infty} S_{2p+1}(x) = \frac{1-x}{1+x}, \forall x\in [0,1]$. So, $\lim\limits_{n \to \infty} S_n(x) =\frac{1-x}{1+x}, \forall x\in [0,1]$. Now, it remains to prove that $\lim\limits_{n\to \infty} \sup\limits_{x \in [0,1]} |S_n(x)-\frac{1-x}{1+x}|=0$. It's easy to see that $g_n(x)=|S_n(x)-\frac{1-x}{1+x}|=x^{n+1} \cdot \frac{1-x}{1+x}$. How can I continue?",,['sequences-and-series']
61,Given Sequence of Numbers find number of combinations,Given Sequence of Numbers find number of combinations,,"I have the sequence of numbers $1,2,4,8,16,\ldots$. This is an infinite sequence. So my problem is that if I have any positive integer value, $x$, what are the possible ways that I can write $x$ as the sum of the sequence that I noted above. For example, if $x=7$, then I would have the possible ways to be $1+1+1+1+1+1+1$ $1+1+1+1+1+2$ $1+1+1+2+2$ $1+1+1+4$ $1+2+2+2$ $1+2+4$ So in this when $x=7$ we have $6$ possible ways. So basically, my question is that is there a way to generalize this for any value of $x$? If it is necessary to note, when $x=10$ there are $14$ possible ways.","I have the sequence of numbers $1,2,4,8,16,\ldots$. This is an infinite sequence. So my problem is that if I have any positive integer value, $x$, what are the possible ways that I can write $x$ as the sum of the sequence that I noted above. For example, if $x=7$, then I would have the possible ways to be $1+1+1+1+1+1+1$ $1+1+1+1+1+2$ $1+1+1+2+2$ $1+1+1+4$ $1+2+2+2$ $1+2+4$ So in this when $x=7$ we have $6$ possible ways. So basically, my question is that is there a way to generalize this for any value of $x$? If it is necessary to note, when $x=10$ there are $14$ possible ways.",,"['sequences-and-series', 'combinatorics']"
62,Giving a sense to the formal equation $\sin x=-\pi\sum_{n=1}^{+\infty}\frac{\mu(n)}n\left\{\frac{nx}{2\pi}\right\}$,Giving a sense to the formal equation,\sin x=-\pi\sum_{n=1}^{+\infty}\frac{\mu(n)}n\left\{\frac{nx}{2\pi}\right\},"Does there exist a formula giving a sense to the formal equation $$ \sin x=-\pi\sum_{n=1}^{+\infty}\frac{\mu(n)}{n}\left\{\frac{nx}{2\pi}\right\}, $$ where $\mu$ is the Möbius function, $\{\cdot\}$ stands for the fractional part of a real number? Namely, the series on the right hand side does not converge , but can it be made convergent to $\sin x$ after applying some ""natural"" summation method?","Does there exist a formula giving a sense to the formal equation $$ \sin x=-\pi\sum_{n=1}^{+\infty}\frac{\mu(n)}{n}\left\{\frac{nx}{2\pi}\right\}, $$ where $\mu$ is the Möbius function, $\{\cdot\}$ stands for the fractional part of a real number? Namely, the series on the right hand side does not converge , but can it be made convergent to $\sin x$ after applying some ""natural"" summation method?",,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'reference-request', 'fractional-part']"
63,How to evaluate this double infinite sum (Catalan number),How to evaluate this double infinite sum (Catalan number),,"Let  $C_n = \dfrac{1}{n+1}\binom{2n}{n}$. Is it possible to find the exact value of this infinite sum ? $$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{4^{n+k}}$$ In general, is it possible to evaluate  $$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{x^{n+k}}$$ in term of $x$? Thanks in advances.","Let  $C_n = \dfrac{1}{n+1}\binom{2n}{n}$. Is it possible to find the exact value of this infinite sum ? $$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{4^{n+k}}$$ In general, is it possible to evaluate  $$\sum_{n=1}^\infty \sum_{k=n}^\infty \frac{\left(C_{n+1}-2C_n\right)\left(C_{k+1}-C_k\right)}{x^{n+k}}$$ in term of $x$? Thanks in advances.",,"['sequences-and-series', 'combinatorics', 'generating-functions']"
64,Determine all real $x$ for which the series $\sum\limits_{k=1}^\infty\frac{k^k}{k!}x^k$ converges.,Determine all real  for which the series  converges.,x \sum\limits_{k=1}^\infty\frac{k^k}{k!}x^k,"Determine all real $x$ for which the following series converges:   $$\sum_{k=1}^\infty\frac{k^k}{k!}x^k.$$   You may use the fact that   $$\lim_{k\to\infty}\frac{k!}{\sqrt{2\pi k}(k/e)^k}=1.$$ ( original image ) I found that the radius of convergence is $\displaystyle \frac{1}{e}$.Next considered end points. When $\displaystyle x=-\frac{1}{e}$, the series converges by alternating series test. But I was fail to determine it for the case where $\displaystyle x=\frac{1}{e}$. I tried to use comparison test by using the given fact. I guess in this case the series diverges. Can anybody please give me a hint to complete the proof?","Determine all real $x$ for which the following series converges:   $$\sum_{k=1}^\infty\frac{k^k}{k!}x^k.$$   You may use the fact that   $$\lim_{k\to\infty}\frac{k!}{\sqrt{2\pi k}(k/e)^k}=1.$$ ( original image ) I found that the radius of convergence is $\displaystyle \frac{1}{e}$.Next considered end points. When $\displaystyle x=-\frac{1}{e}$, the series converges by alternating series test. But I was fail to determine it for the case where $\displaystyle x=\frac{1}{e}$. I tried to use comparison test by using the given fact. I guess in this case the series diverges. Can anybody please give me a hint to complete the proof?",,"['sequences-and-series', 'exponential-function']"
65,The irrationality of rapidly converging series,The irrationality of rapidly converging series,,"I recently saw a pretty elegant proof of the irrationality of $e$, namely: Let $s_n:=\sum_{k=0}^{n}{\frac{1}{k!}}$ such that $e=\lim_{n\to\infty} s_n$. We obviously have $s_n<e$ and furthermore $e=s_n+\frac{1}{(n+1)!}+\frac{1}{(n+2)!}+...=s_n+\frac{1}{n!}\left(\frac{1}{(n+1)}+\frac{1}{(n+1)(n+2)}+...\right)<s_n+\frac{1}{n!}\left(\frac{1}{(n+1)}+\frac{1}{(n+1)^2}+...\right)=s_n+\frac{1}{n!n}$. Therefore, we have $n!s_n<n!e<n!s_n+\frac{1}{n}$. If $e$ was rational, then $e=\frac p q$ for $p,q\in\mathbb N$. But since we can choose $n$ arbitrarily high we can assume $n>q$. Then the numbers $n!s_n$ and $n!e$ are clearly integers and we get $n!s_n<n!e<n!s_n+\frac{1}{n}≤n!s_n+1$, contradiction. I adapted this proof to show the irrationality of numbers like $\sum_{k=0}^{\infty} \frac{1}{2^{n^2}}$ which for me raised the following question: This kind of proof seems to be working well with rapidly converging series. Can there be said anything rigorous about the irrationality of such series in order to justify this observation?","I recently saw a pretty elegant proof of the irrationality of $e$, namely: Let $s_n:=\sum_{k=0}^{n}{\frac{1}{k!}}$ such that $e=\lim_{n\to\infty} s_n$. We obviously have $s_n<e$ and furthermore $e=s_n+\frac{1}{(n+1)!}+\frac{1}{(n+2)!}+...=s_n+\frac{1}{n!}\left(\frac{1}{(n+1)}+\frac{1}{(n+1)(n+2)}+...\right)<s_n+\frac{1}{n!}\left(\frac{1}{(n+1)}+\frac{1}{(n+1)^2}+...\right)=s_n+\frac{1}{n!n}$. Therefore, we have $n!s_n<n!e<n!s_n+\frac{1}{n}$. If $e$ was rational, then $e=\frac p q$ for $p,q\in\mathbb N$. But since we can choose $n$ arbitrarily high we can assume $n>q$. Then the numbers $n!s_n$ and $n!e$ are clearly integers and we get $n!s_n<n!e<n!s_n+\frac{1}{n}≤n!s_n+1$, contradiction. I adapted this proof to show the irrationality of numbers like $\sum_{k=0}^{\infty} \frac{1}{2^{n^2}}$ which for me raised the following question: This kind of proof seems to be working well with rapidly converging series. Can there be said anything rigorous about the irrationality of such series in order to justify this observation?",,"['sequences-and-series', 'irrational-numbers']"
66,How to solve this multiple summation?,How to solve this multiple summation?,,"How to solve this summation ? $$\sum_{0\le x_1\le x_2...\le x_n \le n}^{}\binom{k+x_1-1}{x_1}\binom{k+x_2-1}{x_2}...\binom{k+x_n-1}{x_n}$$ where $k$ , $n$ are known. Due to hockey-stick identity , $$\sum_{i=0}^n\binom{i+k-1}{i}=\binom{n+k}{k}$$","How to solve this summation ? $$\sum_{0\le x_1\le x_2...\le x_n \le n}^{}\binom{k+x_1-1}{x_1}\binom{k+x_2-1}{x_2}...\binom{k+x_n-1}{x_n}$$ where $k$ , $n$ are known. Due to hockey-stick identity , $$\sum_{i=0}^n\binom{i+k-1}{i}=\binom{n+k}{k}$$",,"['sequences-and-series', 'combinatorics', 'summation']"
67,A Limit of a Geometric Average,A Limit of a Geometric Average,,"I have a problem calculating the following limit: $\lim\limits_{n \to \infty}{ (1-2/3)^{3/n}*(1-2/4)^{4/n}...(1-2/(n+2))^\frac{n+2}{n}}$ I thought this is a geometric average of the first n items of a series and so I figured the limit should be the same as the limit of the infinity series: $$a_n=(1-2/(n+2))^{n+2}$$ which I though should be zero as n approaches infinity, since $(1-2/(n+2))<1$. I would greatly appreciate if anyone could help me understand this limit.","I have a problem calculating the following limit: $\lim\limits_{n \to \infty}{ (1-2/3)^{3/n}*(1-2/4)^{4/n}...(1-2/(n+2))^\frac{n+2}{n}}$ I thought this is a geometric average of the first n items of a series and so I figured the limit should be the same as the limit of the infinity series: $$a_n=(1-2/(n+2))^{n+2}$$ which I though should be zero as n approaches infinity, since $(1-2/(n+2))<1$. I would greatly appreciate if anyone could help me understand this limit.",,"['sequences-and-series', 'limits']"
68,"Show that if $b_k\uparrow \infty$ and $\Sigma_{k = 1}^\infty a_kb_k$ converges, then $b_m \Sigma_{k = m}^\infty a_k → 0$ as $m → \infty$.","Show that if  and  converges, then  as .",b_k\uparrow \infty \Sigma_{k = 1}^\infty a_kb_k b_m \Sigma_{k = m}^\infty a_k → 0 m → \infty,"Suppose that $\Sigma_{k=1}^\infty a_k$ converges. Prove that if $b_k\uparrow \infty$ and $\Sigma_{k = 1}^\infty a_kb_k$ converges, then $b_m \Sigma_{k = m}^\infty a_k → 0$ as $m → \infty$. Attemtp: Suppose $\Sigma_{k=1}^\infty a_k$ converges, and $\Sigma_{k = 1}^\infty a_kb_k$ also.Then we know by Abel's Formula that the sequences converge only iff its partial sums converge. If we let $\Sigma a_k = \Sigma \frac{a_kb_k}{b_k}$, then because $b_k$ is increasing we have $\frac{1}{b_k}$ is decreasing to zero. So we almost have a telescoping series. Then let $c_k = \Sigma_{ j = k}^{\infty} a_jb_j$. Then $\Sigma_{k = n}^m a_k = \Sigma \frac{a_kb_k}{b_k}= \Sigma_{k = n}^m \frac{c_k - c_{k+1}}{b_k}$ I don't know how to continue. I am having trouble applying Abel's Formula and the subscripts are confusing. Can someone please help me? I am suppose to use Abel's Formula.  Thank you very much. Abel's Formula: Let $a_k,b_k$ be real sequences, and for each pair of integers $n \geq m \geq 1$ set $A_{n,m} = \Sigma_{k =m}^n a_k$ $\Sigma_{k = n}^m a_kb_k = A_{n,m}b_n - \Sigma_{k = m}^{n-1} A_{k,m}(b_{k+1} -b_k)$","Suppose that $\Sigma_{k=1}^\infty a_k$ converges. Prove that if $b_k\uparrow \infty$ and $\Sigma_{k = 1}^\infty a_kb_k$ converges, then $b_m \Sigma_{k = m}^\infty a_k → 0$ as $m → \infty$. Attemtp: Suppose $\Sigma_{k=1}^\infty a_k$ converges, and $\Sigma_{k = 1}^\infty a_kb_k$ also.Then we know by Abel's Formula that the sequences converge only iff its partial sums converge. If we let $\Sigma a_k = \Sigma \frac{a_kb_k}{b_k}$, then because $b_k$ is increasing we have $\frac{1}{b_k}$ is decreasing to zero. So we almost have a telescoping series. Then let $c_k = \Sigma_{ j = k}^{\infty} a_jb_j$. Then $\Sigma_{k = n}^m a_k = \Sigma \frac{a_kb_k}{b_k}= \Sigma_{k = n}^m \frac{c_k - c_{k+1}}{b_k}$ I don't know how to continue. I am having trouble applying Abel's Formula and the subscripts are confusing. Can someone please help me? I am suppose to use Abel's Formula.  Thank you very much. Abel's Formula: Let $a_k,b_k$ be real sequences, and for each pair of integers $n \geq m \geq 1$ set $A_{n,m} = \Sigma_{k =m}^n a_k$ $\Sigma_{k = n}^m a_kb_k = A_{n,m}b_n - \Sigma_{k = m}^{n-1} A_{k,m}(b_{k+1} -b_k)$",,"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence']"
69,Is this solution on series convergence correct?,Is this solution on series convergence correct?,,"I want to calculate the sum of the following series $$\sum_{n=0}^\infty \frac{(2^n+(-1)^n)^2}{11^n}$$ My solution. 1) First of all $(2^n + (-1)^n)^2=2^{2n}+2^{n+1}(-1)^n+1$. 2) Then the original series becomes: $$\sum_{n=0}^\infty \frac{(2^n+(-1)^n)^2}{11^n}= \sum_{n=0}^\infty \frac{2^{2n}}{11^n}+\sum_{n=0}^\infty \frac{2^{n+1}(-1)^n}{11^n}+\sum_{n=0}^\infty \frac{1}{11^n}$$ 3) Then I want to apply formula for the sum of geometric series. 4) Finally, I simply want to add three sums. Is this a correct way to go?","I want to calculate the sum of the following series $$\sum_{n=0}^\infty \frac{(2^n+(-1)^n)^2}{11^n}$$ My solution. 1) First of all $(2^n + (-1)^n)^2=2^{2n}+2^{n+1}(-1)^n+1$. 2) Then the original series becomes: $$\sum_{n=0}^\infty \frac{(2^n+(-1)^n)^2}{11^n}= \sum_{n=0}^\infty \frac{2^{2n}}{11^n}+\sum_{n=0}^\infty \frac{2^{n+1}(-1)^n}{11^n}+\sum_{n=0}^\infty \frac{1}{11^n}$$ 3) Then I want to apply formula for the sum of geometric series. 4) Finally, I simply want to add three sums. Is this a correct way to go?",,"['real-analysis', 'sequences-and-series', 'analysis']"
70,Prove that $ \frac{1}{2!} + \frac{2}{3!} + \frac{3}{4!}+\cdots + \frac{n}{(n+1)!} = 1 - \frac{1}{(n+1)!}$ for $n\in \mathbb N$,Prove that  for, \frac{1}{2!} + \frac{2}{3!} + \frac{3}{4!}+\cdots + \frac{n}{(n+1)!} = 1 - \frac{1}{(n+1)!} n\in \mathbb N,"I want to prove that if $n \in \mathbb N$ then $$\frac{1}{2!} + \frac{2}{3!} + \frac{3}{4!}+ \cdots+ \frac{n}{(n+1)!} = 1 - \frac{1}{(n+1)!}.$$ I think I am stuck on two fronts. First, I don't know how to express the leading terms on the left hand side before the $\dfrac{n}{(n+1)!}$ (or if doing so is even necessary to solve the problem). I am also assuming that the right high side should initially be expressed $1 - \dfrac{1}{(n+2)!}$. But where to go from there. I'm actually not sure if I'm even thinking about it the right way.","I want to prove that if $n \in \mathbb N$ then $$\frac{1}{2!} + \frac{2}{3!} + \frac{3}{4!}+ \cdots+ \frac{n}{(n+1)!} = 1 - \frac{1}{(n+1)!}.$$ I think I am stuck on two fronts. First, I don't know how to express the leading terms on the left hand side before the $\dfrac{n}{(n+1)!}$ (or if doing so is even necessary to solve the problem). I am also assuming that the right high side should initially be expressed $1 - \dfrac{1}{(n+2)!}$. But where to go from there. I'm actually not sure if I'm even thinking about it the right way.",,"['sequences-and-series', 'induction']"
71,Hard limit: $\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n$,Hard limit:,\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n,"I've stumbled on a particularly hard limit problem: Evaluate the following limit:   $$\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n\text{, with $n, k \in \mathbb{N}$ and $x \in \mathbb{R}$}$$   You will find a sequence $a_k(x)$. Then evaluate the limit   $$\lim_{k \to +\infty} a_k(x)$$   finding a function $f(x)$. Side question: does something change if the $2$ inside the sine is dropped? Now, I've already seen something similar to this, but instead of the sine function it had the cosine. That is the Dirichlet function, giving $1$ for the rationals and $0$ otherwise. The problem is that here we have a sine, which is $0$ at multiples of $2\pi$. So my intuition is that the limit is $0$, but that does not make sense with respect to the problem statement!","I've stumbled on a particularly hard limit problem: Evaluate the following limit:   $$\lim_{n \to +\infty} \left(\sin\left(2\pi(k!)x\right)\right)^n\text{, with $n, k \in \mathbb{N}$ and $x \in \mathbb{R}$}$$   You will find a sequence $a_k(x)$. Then evaluate the limit   $$\lim_{k \to +\infty} a_k(x)$$   finding a function $f(x)$. Side question: does something change if the $2$ inside the sine is dropped? Now, I've already seen something similar to this, but instead of the sine function it had the cosine. That is the Dirichlet function, giving $1$ for the rationals and $0$ otherwise. The problem is that here we have a sine, which is $0$ at multiples of $2\pi$. So my intuition is that the limit is $0$, but that does not make sense with respect to the problem statement!",,"['calculus', 'sequences-and-series', 'limits']"
72,Examine limit of sequence,Examine limit of sequence,,I have to examine limit of following sequence $\{a_n\}_{ n \ge 1}$ $a_n = \sqrt[n]{\sum_{k=1}^{n}{(2 -\frac{1}{k})^k}}$. We know that $\lim_{n \to \infty} \sqrt[n]{a} = 1$ for $a > 0$ and we know that $\sqrt[n]{\sum_{k=1}^{n}{(2 -\frac{1}{k})^k}} > 0$ but sequence $a_n$ is increasing (I cannot prove it but I checked it in wolframalpha) so we cannot use the squeeze theorem. Any hints?,I have to examine limit of following sequence $\{a_n\}_{ n \ge 1}$ $a_n = \sqrt[n]{\sum_{k=1}^{n}{(2 -\frac{1}{k})^k}}$. We know that $\lim_{n \to \infty} \sqrt[n]{a} = 1$ for $a > 0$ and we know that $\sqrt[n]{\sum_{k=1}^{n}{(2 -\frac{1}{k})^k}} > 0$ but sequence $a_n$ is increasing (I cannot prove it but I checked it in wolframalpha) so we cannot use the squeeze theorem. Any hints?,,"['sequences-and-series', 'limits']"
73,"Closed form of a ""harmonic"" alternating dilogarithm sum","Closed form of a ""harmonic"" alternating dilogarithm sum",,"Does the following sum $$ S = \sum_{n\geq 2}(-1)^n \mathrm{Li}_2(2/n) = 1.14434\ 42096\ 91982\ 23727\ 39852\ 45805\ldots $$ have a closed form in terms of known constants? Neither the inverse symbolic calculator nor wolfram alpha could suggest anything for it. There is also the related sum $$ S_2 = \sum_{n\geq 2}\left(\mathrm{Li}_2(2/n) - 2/n\right) = 1.14135\ 80945\ 90055\ 78983\ 33729\ 08670\ldots $$ to which I would like to know a closed form. Also, this one: $$ S_3 = \sum_{n\geq 2}(-1)^n\mathrm{Li}_2(4/n^2) = 1.30537\ 19631\ 37203\ 80215\ 02160\ 56689\ldots $$","Does the following sum $$ S = \sum_{n\geq 2}(-1)^n \mathrm{Li}_2(2/n) = 1.14434\ 42096\ 91982\ 23727\ 39852\ 45805\ldots $$ have a closed form in terms of known constants? Neither the inverse symbolic calculator nor wolfram alpha could suggest anything for it. There is also the related sum $$ S_2 = \sum_{n\geq 2}\left(\mathrm{Li}_2(2/n) - 2/n\right) = 1.14135\ 80945\ 90055\ 78983\ 33729\ 08670\ldots $$ to which I would like to know a closed form. Also, this one: $$ S_3 = \sum_{n\geq 2}(-1)^n\mathrm{Li}_2(4/n^2) = 1.30537\ 19631\ 37203\ 80215\ 02160\ 56689\ldots $$",,"['sequences-and-series', 'special-functions', 'closed-form']"
74,Summation of the series$\sum_{n=1}^\infty\frac{1}{n^2+4}$,Summation of the series,\sum_{n=1}^\infty\frac{1}{n^2+4},Evaluate the sum of the following series $$\sum_{n=1}^\infty\frac{1}{n^2+4}$$ I saw a video in youtube where it is solved using complex analysis. What other method can be used to solve this?,Evaluate the sum of the following series $$\sum_{n=1}^\infty\frac{1}{n^2+4}$$ I saw a video in youtube where it is solved using complex analysis. What other method can be used to solve this?,,"['sequences-and-series', 'complex-analysis']"
75,Control ratio of geometric series through its sum,Control ratio of geometric series through its sum,,"A geometric series $S_n$ is the sum of the $n$ first elements of a geometric sequence $u_n$: $$u_n = ar^n \space \forall n \in \mathbb{N}^*$$ with $u_0$ defined, and: $$S_n = \sum_{k = 0}^{k = n - 1}u_k=a\frac{1 - r^n}{1 - r}$$ Then, is there a way to determine the ratio $r$ analytically through a given finite $n$ and finite sum $S_n$?","A geometric series $S_n$ is the sum of the $n$ first elements of a geometric sequence $u_n$: $$u_n = ar^n \space \forall n \in \mathbb{N}^*$$ with $u_0$ defined, and: $$S_n = \sum_{k = 0}^{k = n - 1}u_k=a\frac{1 - r^n}{1 - r}$$ Then, is there a way to determine the ratio $r$ analytically through a given finite $n$ and finite sum $S_n$?",,"['sequences-and-series', 'summation']"
76,Frobenius method differ by integer,Frobenius method differ by integer,,"When the roots of the indicial equation differ by an integer the equation is of the form: $$y_2 (z)=cy_1 (z) \ln(z)+z^{\sigma_2 } \sum_{n=0 }^\infty(b_n z^n )$$ Here is what is bothering me. The last term on the RHS (namely $z^{\sigma_2 } ∑_{n=0 }^\infty(b_n z^n )$) is the Frobenius series that we would usually (if the roots did not differ by an integer) substitute into the original ODE. But the reason that we did not do this in the first place is because it leads to something going wrong (such as dividing by 0 for one of the terms). Thus when we sub $y_2$ into the ODE since derivatives are like linear operators we will get exactly the same problem as we had before hand i.e. for one of the terms we will need to divide by 0, say. So how do we get around this problem? To demensionstrate my point consider example 7 in this document http://www.most.gov.mm/techuni/media/EM_03011_p2chap34.pdf The ODE is $(x^2-x)y''-xy'+y=0$   The roots to the indicial equation are $r_1=1$ and $r_2=0$. And it can be easly shown that for a given root $r$ the reccurence relationship is:   $$a_{s+1}=\frac{a_n(n+r-1)^2}{(n+1+r)(n+r)}$$   when $r=0$ when have   $$a_{s+1}=\frac{a_n(n-1)^2}{(n+1)(n)}$$   Thus when $n=0$ we end up dividing by 0 and we can not use this method.   When $r=1$ this can be solved to get $y_1=a_0 x$.   Thus using $$y_2 (x)=cx \ln(x)+x^{r_2 } \sum_{n=0 }^\infty(b_n x^n )$$   and differentiating it twice and subbing it back into the ODE we get:   $$-xc+\sum (n(n-1)b_n+(n+1)nb_{n+1}-b_nn+b_n)x^n=0$$   so when equating coefficients of $x^n$ in an effort to find $b_n$ we will get exactly the same recurrence relationship as before and thus not be able to find $b_1$ since it will involve dividing by 0","When the roots of the indicial equation differ by an integer the equation is of the form: $$y_2 (z)=cy_1 (z) \ln(z)+z^{\sigma_2 } \sum_{n=0 }^\infty(b_n z^n )$$ Here is what is bothering me. The last term on the RHS (namely $z^{\sigma_2 } ∑_{n=0 }^\infty(b_n z^n )$) is the Frobenius series that we would usually (if the roots did not differ by an integer) substitute into the original ODE. But the reason that we did not do this in the first place is because it leads to something going wrong (such as dividing by 0 for one of the terms). Thus when we sub $y_2$ into the ODE since derivatives are like linear operators we will get exactly the same problem as we had before hand i.e. for one of the terms we will need to divide by 0, say. So how do we get around this problem? To demensionstrate my point consider example 7 in this document http://www.most.gov.mm/techuni/media/EM_03011_p2chap34.pdf The ODE is $(x^2-x)y''-xy'+y=0$   The roots to the indicial equation are $r_1=1$ and $r_2=0$. And it can be easly shown that for a given root $r$ the reccurence relationship is:   $$a_{s+1}=\frac{a_n(n+r-1)^2}{(n+1+r)(n+r)}$$   when $r=0$ when have   $$a_{s+1}=\frac{a_n(n-1)^2}{(n+1)(n)}$$   Thus when $n=0$ we end up dividing by 0 and we can not use this method.   When $r=1$ this can be solved to get $y_1=a_0 x$.   Thus using $$y_2 (x)=cx \ln(x)+x^{r_2 } \sum_{n=0 }^\infty(b_n x^n )$$   and differentiating it twice and subbing it back into the ODE we get:   $$-xc+\sum (n(n-1)b_n+(n+1)nb_{n+1}-b_nn+b_n)x^n=0$$   so when equating coefficients of $x^n$ in an effort to find $b_n$ we will get exactly the same recurrence relationship as before and thus not be able to find $b_1$ since it will involve dividing by 0",,['sequences-and-series']
77,Algebraic manipulation of floors and ceilings,Algebraic manipulation of floors and ceilings,,"I am trying to solve the summation $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \sum_{i=3}^{n} \left\lceil\frac{i-2}{2}\right\rceil $$ I will list some of the simplifications that I've found so far, and then get around to asking my question. Please feel free to point out any logical errors that I have (in all likelihood) made. $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \sum_{i=1}^{n-2} \left\lceil\frac{i}{2}\right\rceil $$ $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \left(\sum_{i=1}^{\left\lceil\frac{n-2}{2}\right\rceil} i+ \sum_{i=1}^{\left\lfloor\frac{n-2}{2}\right\rfloor} i\right) $$ Since the upper bound in both of the inner summations will be an integer, I have: $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \left(\frac{\left\lceil\frac{n-2}{2}\right\rceil\left(\left\lceil\frac{n-2}{2}\right\rceil + 1\right)}{2}+\frac{\left\lfloor\frac{n-2}{2}\right\rfloor\left(\left\lfloor\frac{n-2}{2}\right\rfloor + 1\right)}{2}\right) $$ How do I simplify a floor times a floor and a ceiling times a ceiling algebraically? I'm thinking that the identity $$ n = \left\lceil\frac{n}{2}\right\rceil + \left\lfloor\frac{n}{2}\right\rfloor $$ might come in handy, but I have very little experience manipulating floors and ceilings algebraically. Let me be clear: I'm not looking for an answer to the summation, just guidance in simplifying this current step.","I am trying to solve the summation $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \sum_{i=3}^{n} \left\lceil\frac{i-2}{2}\right\rceil $$ I will list some of the simplifications that I've found so far, and then get around to asking my question. Please feel free to point out any logical errors that I have (in all likelihood) made. $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \sum_{i=1}^{n-2} \left\lceil\frac{i}{2}\right\rceil $$ $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \left(\sum_{i=1}^{\left\lceil\frac{n-2}{2}\right\rceil} i+ \sum_{i=1}^{\left\lfloor\frac{n-2}{2}\right\rfloor} i\right) $$ Since the upper bound in both of the inner summations will be an integer, I have: $$ \sum_{n=3}^{\infty} \frac{1}{2^n} \left(\frac{\left\lceil\frac{n-2}{2}\right\rceil\left(\left\lceil\frac{n-2}{2}\right\rceil + 1\right)}{2}+\frac{\left\lfloor\frac{n-2}{2}\right\rfloor\left(\left\lfloor\frac{n-2}{2}\right\rfloor + 1\right)}{2}\right) $$ How do I simplify a floor times a floor and a ceiling times a ceiling algebraically? I'm thinking that the identity $$ n = \left\lceil\frac{n}{2}\right\rceil + \left\lfloor\frac{n}{2}\right\rfloor $$ might come in handy, but I have very little experience manipulating floors and ceilings algebraically. Let me be clear: I'm not looking for an answer to the summation, just guidance in simplifying this current step.",,"['sequences-and-series', 'summation', 'ceiling-and-floor-functions']"
78,Apparent paradox for the bird traveling between two trains puzzle,Apparent paradox for the bird traveling between two trains puzzle,,"Trying the ""hard solution"" for the puzzle below (which has been discussed, with a different angle, elsewhere on this forum) I got to a point where I have three seemingly valid solutions, and two do not match. I have checked the procedure several times, both by hand and with Maxima, and it appears correct - but I am obviously missing something.I cannot sort this out, maybe someone here can. (Sorry for the ASCII math, I am not MathJax-enabled) The story and the puzzle: A colleague approached one day John Von Neumann with a puzzle that had two paths to a solution, a laborious, complicated calculation and an elegant, Aha!-type solution. This colleague had a theory: in such a case, mathematicians work out the laborious solution while the (lazier, but smarter) physicists pause and find the quick-and-easy solution. Which solution would von Neumann find? You know the sort of puzzle: Two trains, 100 miles apart, are approaching each other on the same track, one going 30 miles per hour, the other going 20 miles per hour. A bird flying 120 miles per hour starts at train A (when they are 100 miles apart), flies to train B, turns around and flies back to the approaching train A, and so forth, until the two trains collide. How far has the bird flown when the collision occurs? “Two hundred and forty miles,” von Neumann answered almost instantly. “Darn,” replied his colleague, “I predicted you’d do it the hard way, summing the infinite series.” “Ay!” von Neumann cried in embarrassment, smiting his forehead. “There’s an easy way!” Solution 1  - Easy: The trains will collide in $T_t=\frac{D_0}{V_1+V_2}$ . Hence $D_b=V_b\cdot\frac{D_0}{V_1+V_2}=120\cdot\frac{100}{50}=240$ Hard Solution preliminary: On the first leg, the bird travels the distance $D_0$ in time $T_0=\frac{D_0}{V_b+V_2}$ ; On the second leg, distance and duration amount to: $D_1 = D_0-T_0 \cdot (V_1+V_2) = D_0 \cdot \frac{V_b-V_1}{V_b+V_2}; T_1=D_0 \cdot \frac{V_1-V_b}{V_1+V_b}*(V_2+V_b))=T_0 \cdot \frac{V_b-V_1}{V_b+V_1}$ On the third leg,  a recurrence emerges: $D_2 = D_0 \cdot \frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)} ; T_2 = T_0 \cdot \frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)}$ The same recurrence is found to hold between $D_3$ and $D_1$ and $T_3$ and $T_1$ . If we set: $$R=\frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)}$$ We see that both the total duration and the total distance traveled by the bird can be computed summing a geometrical series  with coefficient $R$ and respective first terms $(T_0+T_1)$ and $(D_0+D_1)$ . $R< 1$ holds, so convergence is assured. Therefore we have. Solution 2: $$T_t= \sum (T_0+T_1)R^n = \frac{D_0}{V_1+V_2}; D_b= V_b\cdot\frac{D_0}{V_1+V_2}$$ This matches solution (1) as it should. Solution 3: $$D_b= \sum(D_0+D_1)R^n ) = D_0 \cdot \frac{(V_1+V_b)\cdot(V_2-V_1+2 V_b)}{2 V_b\cdot(V_2+V_1)}$$ I am stymied.","Trying the ""hard solution"" for the puzzle below (which has been discussed, with a different angle, elsewhere on this forum) I got to a point where I have three seemingly valid solutions, and two do not match. I have checked the procedure several times, both by hand and with Maxima, and it appears correct - but I am obviously missing something.I cannot sort this out, maybe someone here can. (Sorry for the ASCII math, I am not MathJax-enabled) The story and the puzzle: A colleague approached one day John Von Neumann with a puzzle that had two paths to a solution, a laborious, complicated calculation and an elegant, Aha!-type solution. This colleague had a theory: in such a case, mathematicians work out the laborious solution while the (lazier, but smarter) physicists pause and find the quick-and-easy solution. Which solution would von Neumann find? You know the sort of puzzle: Two trains, 100 miles apart, are approaching each other on the same track, one going 30 miles per hour, the other going 20 miles per hour. A bird flying 120 miles per hour starts at train A (when they are 100 miles apart), flies to train B, turns around and flies back to the approaching train A, and so forth, until the two trains collide. How far has the bird flown when the collision occurs? “Two hundred and forty miles,” von Neumann answered almost instantly. “Darn,” replied his colleague, “I predicted you’d do it the hard way, summing the infinite series.” “Ay!” von Neumann cried in embarrassment, smiting his forehead. “There’s an easy way!” Solution 1  - Easy: The trains will collide in . Hence Hard Solution preliminary: On the first leg, the bird travels the distance in time ; On the second leg, distance and duration amount to: On the third leg,  a recurrence emerges: The same recurrence is found to hold between and and and . If we set: We see that both the total duration and the total distance traveled by the bird can be computed summing a geometrical series  with coefficient and respective first terms and . holds, so convergence is assured. Therefore we have. Solution 2: This matches solution (1) as it should. Solution 3: I am stymied.",T_t=\frac{D_0}{V_1+V_2} D_b=V_b\cdot\frac{D_0}{V_1+V_2}=120\cdot\frac{100}{50}=240 D_0 T_0=\frac{D_0}{V_b+V_2} D_1 = D_0-T_0 \cdot (V_1+V_2) = D_0 \cdot \frac{V_b-V_1}{V_b+V_2}; T_1=D_0 \cdot \frac{V_1-V_b}{V_1+V_b}*(V_2+V_b))=T_0 \cdot \frac{V_b-V_1}{V_b+V_1} D_2 = D_0 \cdot \frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)} ; T_2 = T_0 \cdot \frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)} D_3 D_1 T_3 T_1 R=\frac{(V_1-V_b)\cdot(V_2-V_b)}{(V_1+V_b)\cdot(V_2+V_b)} R (T_0+T_1) (D_0+D_1) R< 1 T_t= \sum (T_0+T_1)R^n = \frac{D_0}{V_1+V_2}; D_b= V_b\cdot\frac{D_0}{V_1+V_2} D_b= \sum(D_0+D_1)R^n ) = D_0 \cdot \frac{(V_1+V_b)\cdot(V_2-V_1+2 V_b)}{2 V_b\cdot(V_2+V_1)},"['sequences-and-series', 'puzzle']"
79,Number of palindromic numbers less than a power of $10$,Number of palindromic numbers less than a power of,10,"I noticed that every $10^{n}$ there is a certain number of palindromic numbers that I collected in this sequence: $$S=\{a_n,a_{n+1},a_{n+2}...\}=\{10,9,90,90,900,900...\}$$ where every number $a_n$ is the number of palindromic numbers between $10^{n}$ and $10^{n+1}$ starting with $n=0$. Now I wanted to know the number of palindromic numbers less than $10^p$ and I came up with this formula:  \begin{cases} 1+\sum^{\lfloor{\frac{p}{2}\rfloor}}_{k=0} 18 \cdot10^k & {\text{if $p$ is even}}\\ 1+\left(\sum^{\lfloor{\frac{p}{2}+1}\rfloor-1}_{k=0} 18 \cdot10^k\right)- \left(9 \cdot 10^{\lfloor{\frac{p}{2}+1}\rfloor-1} \right) & {\text{if $p$ is odd}} \end{cases} Is this right? Thanks! :)","I noticed that every $10^{n}$ there is a certain number of palindromic numbers that I collected in this sequence: $$S=\{a_n,a_{n+1},a_{n+2}...\}=\{10,9,90,90,900,900...\}$$ where every number $a_n$ is the number of palindromic numbers between $10^{n}$ and $10^{n+1}$ starting with $n=0$. Now I wanted to know the number of palindromic numbers less than $10^p$ and I came up with this formula:  \begin{cases} 1+\sum^{\lfloor{\frac{p}{2}\rfloor}}_{k=0} 18 \cdot10^k & {\text{if $p$ is even}}\\ 1+\left(\sum^{\lfloor{\frac{p}{2}+1}\rfloor-1}_{k=0} 18 \cdot10^k\right)- \left(9 \cdot 10^{\lfloor{\frac{p}{2}+1}\rfloor-1} \right) & {\text{if $p$ is odd}} \end{cases} Is this right? Thanks! :)",,"['sequences-and-series', 'elementary-number-theory', 'summation', 'palindrome']"
80,Show that $\sum_n \frac{1}{a_n}\lt90$ [duplicate],Show that  [duplicate],\sum_n \frac{1}{a_n}\lt90,"This question already has answers here : Sum of reciprocals of numbers with certain terms omitted (2 answers) Closed 10 years ago . Let $1,2,3,4,5,6,7,8,9,11,12,\cdots$ be the sequence of all the positive integers which do not contain the digit zero. Write $\{a_n\}$ for this sequence. By comparing with a geometric series, show that $$\sum_n \frac{1}{a_n}\lt90$$ I would try to start this but summing the geometric series is trivial, so the point lies in finding such a series(or a set of series) This looks really amazing to me since this is just the harmonic series, with (apparently) a small fraction of the terms removed, and yet it converges.","This question already has answers here : Sum of reciprocals of numbers with certain terms omitted (2 answers) Closed 10 years ago . Let $1,2,3,4,5,6,7,8,9,11,12,\cdots$ be the sequence of all the positive integers which do not contain the digit zero. Write $\{a_n\}$ for this sequence. By comparing with a geometric series, show that $$\sum_n \frac{1}{a_n}\lt90$$ I would try to start this but summing the geometric series is trivial, so the point lies in finding such a series(or a set of series) This looks really amazing to me since this is just the harmonic series, with (apparently) a small fraction of the terms removed, and yet it converges.",,['sequences-and-series']
81,Comparison between infinite products and series,Comparison between infinite products and series,,I need examples of the following facts: 1) $\prod_{j=0}^{+\infty}(1+a_{j})$ converges $\nRightarrow  \prod_{j=0}^{+\infty}(1+|a_{j}|)$ converges 2) $\prod_{j=0}^{+\infty}(1+a_{j})$ converges $\nRightarrow  \sum_{j=0}^{+\infty}a_{j}$ converges 3) $\sum_{j=0}^{+\infty}a_{j}$ converges $\nRightarrow \prod_{j=0}^{+\infty}(1+a_{j})$ converges where $a_{j} \in \mathbb{C}$. Any hint ?,I need examples of the following facts: 1) $\prod_{j=0}^{+\infty}(1+a_{j})$ converges $\nRightarrow  \prod_{j=0}^{+\infty}(1+|a_{j}|)$ converges 2) $\prod_{j=0}^{+\infty}(1+a_{j})$ converges $\nRightarrow  \sum_{j=0}^{+\infty}a_{j}$ converges 3) $\sum_{j=0}^{+\infty}a_{j}$ converges $\nRightarrow \prod_{j=0}^{+\infty}(1+a_{j})$ converges where $a_{j} \in \mathbb{C}$. Any hint ?,,"['sequences-and-series', 'complex-analysis', 'analysis', 'convergence-divergence', 'infinite-product']"
82,How find this sum $\sum_{k=1}^{n}\frac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3}$,How find this sum,\sum_{k=1}^{n}\frac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3},"let sequence $\{a_{n}\},\{b_{n}\}$ such $$a_{1}=2,b_{1}=1$$ and $$a_{n+1}=\dfrac{a_{n}+1}{a_{n}+b_{n}+3},b_{n+1}=\dfrac{b_{n}+1}{a_{n}+b_{n}+3}$$ find the  $$\sum_{k=1}^{n}\dfrac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3}$$ my idea: since $$a_{n+1}+b_{n+1}=\dfrac{a_{n}+b_{n}+2}{a_{n}+b_{n}+3}$$ $$\dfrac{a_{n+1}}{b_{n+1}}=\dfrac{a_{n}+1}{b_{n}+1}$$ maybe  we can note this  $$a+b+ab+1=(a+1)(b+1)?$$ then I can't ,Thank you","let sequence $\{a_{n}\},\{b_{n}\}$ such $$a_{1}=2,b_{1}=1$$ and $$a_{n+1}=\dfrac{a_{n}+1}{a_{n}+b_{n}+3},b_{n+1}=\dfrac{b_{n}+1}{a_{n}+b_{n}+3}$$ find the  $$\sum_{k=1}^{n}\dfrac{(a_{k}+1)(b_{k}+1)}{a_{k}+b_{k}+3}$$ my idea: since $$a_{n+1}+b_{n+1}=\dfrac{a_{n}+b_{n}+2}{a_{n}+b_{n}+3}$$ $$\dfrac{a_{n+1}}{b_{n+1}}=\dfrac{a_{n}+1}{b_{n}+1}$$ maybe  we can note this  $$a+b+ab+1=(a+1)(b+1)?$$ then I can't ,Thank you",,"['sequences-and-series', 'summation']"
83,How to prove that $b_{2008}\neq 0$,How to prove that,b_{2008}\neq 0,"Let the polynomial $f$ be defined as $$f(x)=a_{m}x^m+a_{m-1}x^{m-1}+\cdots+a_{1}x+a_{0}, \qquad a_{i}\in \Bbb Z \ (i=0,1,2,\cdots,m), \ a_{i}\neq 0.$$ Define the sequence $\{b_{n}\}$ as  $$b_{1}=0,b_{n+1}=f(b_{n}).$$ Show that $$b_{2008}\neq 0.$$ My try: let $x_{i},i=1,2,\dots,m$ be the complex roots of the polynomial $f(x)$, then $$f(x)=a_{m}(x-x_{1})(x-x_{2})\cdots(x-x_{m})$$ Maybe this is Olympic math exam question, this is a problem my frend asked me.","Let the polynomial $f$ be defined as $$f(x)=a_{m}x^m+a_{m-1}x^{m-1}+\cdots+a_{1}x+a_{0}, \qquad a_{i}\in \Bbb Z \ (i=0,1,2,\cdots,m), \ a_{i}\neq 0.$$ Define the sequence $\{b_{n}\}$ as  $$b_{1}=0,b_{n+1}=f(b_{n}).$$ Show that $$b_{2008}\neq 0.$$ My try: let $x_{i},i=1,2,\dots,m$ be the complex roots of the polynomial $f(x)$, then $$f(x)=a_{m}(x-x_{1})(x-x_{2})\cdots(x-x_{m})$$ Maybe this is Olympic math exam question, this is a problem my frend asked me.",,"['sequences-and-series', 'polynomials']"
84,Find the limit of $(u_n)$ when $n \rightarrow +\infty $,Find the limit of  when,(u_n) n \rightarrow +\infty ,"Let $$(u_n) :  \begin{cases} u_1=0\\u_2=1  \\ u_{n+1}=\dfrac{3u_{n-1}+2}{10u_n+2u_{n-1}+2}, \forall n \in \mathbb{N}\end{cases} $$ Find the limit of $(u_n)$ when $n \rightarrow +\infty $ I can prove that  $0 <u_n<1 ,\forall n \in \mathbb{N}$ but it 's all i can do, $(u_n)$ is not the decreasing or inscreasing sequence by calculate by computer i can see it.","Let $$(u_n) :  \begin{cases} u_1=0\\u_2=1  \\ u_{n+1}=\dfrac{3u_{n-1}+2}{10u_n+2u_{n-1}+2}, \forall n \in \mathbb{N}\end{cases} $$ Find the limit of $(u_n)$ when $n \rightarrow +\infty $ I can prove that  $0 <u_n<1 ,\forall n \in \mathbb{N}$ but it 's all i can do, $(u_n)$ is not the decreasing or inscreasing sequence by calculate by computer i can see it.",,"['sequences-and-series', 'limits']"
85,Find a power series for the following function $\frac{x^2}{1+x^3}$,Find a power series for the following function,\frac{x^2}{1+x^3},"I'm not sure if I solved this correctly, but here is the problem: Find a power series for the following function $\frac{x^2}{1+x^3}$ And here is what I did: $$x^2\frac{1}{1-(-x^3)}$$ Here is where I took some educated guesses as to how to setup the power series: $$x^2\sum_{n=0}^{\infty}(-x^3)^n$$ I then factored out the $-1$ like this: $$x^2\sum_{n=0}^{\infty}(-1)^{n+1}x^{3n}$$ Lastly I multiplied the $x^2$ through and got this: $$\sum_{n=0}^{\infty}(-1)^{n+1}x^{3n+2}$$ Is this correct?","I'm not sure if I solved this correctly, but here is the problem: Find a power series for the following function $\frac{x^2}{1+x^3}$ And here is what I did: $$x^2\frac{1}{1-(-x^3)}$$ Here is where I took some educated guesses as to how to setup the power series: $$x^2\sum_{n=0}^{\infty}(-x^3)^n$$ I then factored out the $-1$ like this: $$x^2\sum_{n=0}^{\infty}(-1)^{n+1}x^{3n}$$ Lastly I multiplied the $x^2$ through and got this: $$\sum_{n=0}^{\infty}(-1)^{n+1}x^{3n+2}$$ Is this correct?",,"['calculus', 'sequences-and-series', 'power-series']"
86,Evaluating $\sum^\infty_{n=0}\sum^n_{k=1}\frac{1}{e^{n-1}(n-k)!(n-1)^{k-1}}$,Evaluating,\sum^\infty_{n=0}\sum^n_{k=1}\frac{1}{e^{n-1}(n-k)!(n-1)^{k-1}},"Major Update There has been a major error in one of my calculations, helpfully pointed out by   doraemonpaul. The lower limit for the second summation has been changed to $k=0$ rather than $k=1$. This has mostly deleted all my work on this summation so I am starting from scratch once more. This may however reveal a better summation to evaluate. Who knows. The series is as follows $$\sum^\infty_{n=0}\sum^n_{k=0}\frac{1}{e^{n-1}(n-k)!(n-1)^{k-1}}$$","Major Update There has been a major error in one of my calculations, helpfully pointed out by   doraemonpaul. The lower limit for the second summation has been changed to $k=0$ rather than $k=1$. This has mostly deleted all my work on this summation so I am starting from scratch once more. This may however reveal a better summation to evaluate. Who knows. The series is as follows $$\sum^\infty_{n=0}\sum^n_{k=0}\frac{1}{e^{n-1}(n-k)!(n-1)^{k-1}}$$",,"['sequences-and-series', 'summation']"
87,"Bounded, divergent series with terms approaching zero","Bounded, divergent series with terms approaching zero",,"Is there an example, or proof that one cannot exist, of a sequence of real numbers $a_n$ such that (1) $a_n\rightarrow 0$ (perhaps non-monotonically), and (2) the sequence of partial sums $\sum_1^N a_n$ are uniformly bounded, but the sum $\sum_1^\infty a_n$ diverges? Condition (1) prevents things like $a_n = (-1)^n$, while condition (2) prevents things like $a_n = 1/n$.","Is there an example, or proof that one cannot exist, of a sequence of real numbers $a_n$ such that (1) $a_n\rightarrow 0$ (perhaps non-monotonically), and (2) the sequence of partial sums $\sum_1^N a_n$ are uniformly bounded, but the sum $\sum_1^\infty a_n$ diverges? Condition (1) prevents things like $a_n = (-1)^n$, while condition (2) prevents things like $a_n = 1/n$.",,"['real-analysis', 'sequences-and-series']"
88,MRB constant proofs wanted,MRB constant proofs wanted,,"This article has been edited for a bounty. $C$ MRB, the MRB constant, is defined at http://mathworld.wolfram.com/MRBConstant.html . There is an excellent 56 page paper whose author has passed away. You can find it in Google Scholar ""MRB constant,"" Better yet, use the following link http://web.archive.org/web/20130430193005/http://www.perfscipress.com/papers/UniversalTOC25.pdf . You find a cached copy there. Just before the author, Richerd Crandall, died I wrote him about a possible small error. What I'm worried about is formula 44 on page 29 and below. When I naively worked formula 44 it needed a negative sign in front of it. Crandall did write me back admitting to a typo, but he died before he had a chance to correct it.    Is there anyone out there competent enough to check, correct and prove the corrected  formulas for me? Thank you. I will use the proofs often and try to get the formulas published more. Here is how I worked formula 44 and got -B: (*define the Dirichlet eta function*) eta[s_] := (1 - 2^(1 - s)) Zeta[s]; (*define the higher derivatives of the eta(0)*) a[i_] := Derivative[i][eta][0]; (*Define c:*) c[j_] := Sum[Binomial[j, d] (-1)^d d^(j - d), {d, 1, j}] (*formula (44)*) N[Sum[c[m]/m!*a[m], {m, 1, 40}], 100]","This article has been edited for a bounty. MRB, the MRB constant, is defined at http://mathworld.wolfram.com/MRBConstant.html . There is an excellent 56 page paper whose author has passed away. You can find it in Google Scholar ""MRB constant,"" Better yet, use the following link http://web.archive.org/web/20130430193005/http://www.perfscipress.com/papers/UniversalTOC25.pdf . You find a cached copy there. Just before the author, Richerd Crandall, died I wrote him about a possible small error. What I'm worried about is formula 44 on page 29 and below. When I naively worked formula 44 it needed a negative sign in front of it. Crandall did write me back admitting to a typo, but he died before he had a chance to correct it.    Is there anyone out there competent enough to check, correct and prove the corrected  formulas for me? Thank you. I will use the proofs often and try to get the formulas published more. Here is how I worked formula 44 and got -B: (*define the Dirichlet eta function*) eta[s_] := (1 - 2^(1 - s)) Zeta[s]; (*define the higher derivatives of the eta(0)*) a[i_] := Derivative[i][eta][0]; (*Define c:*) c[j_] := Sum[Binomial[j, d] (-1)^d d^(j - d), {d, 1, j}] (*formula (44)*) N[Sum[c[m]/m!*a[m], {m, 1, 40}], 100]",C,"['sequences-and-series', 'recreational-mathematics', 'constants']"
89,How to prove series expansion for incomplete gamma function?,How to prove series expansion for incomplete gamma function?,,"Wolfram MathWorld (citing Abramowitz and Stegun) gives the following result: $$E_1(x)\equiv\int_x^\infty \frac{e^{-u}}{u}du=-\gamma-\ln x-\sum_{n=1}^\infty\frac{(-1)^nx^n}{n\cdot n!}$$ I am wondering if anybody could supply some details on the proof of this result? In particular, if we Taylor expand $e^{-u}$ , we get: $$E_1(x)=\int_x^\infty \frac{1-u+u^2/2!-u^3/3!+\ldots}{u}du=\left(\ln u+\sum_{n=1}^\infty\frac{(-1)^nu^n}{n\cdot n!}\right)\Bigg|^\infty_x$$ The last two terms of $E_1(x)$ from above (i.e. $-\ln x-\sum_{n=1}^\infty\frac{(-1)^nx^n}{n\cdot n!}$ ) follow very easily from the lower bound, but I'm not sure how to argue that the upper bound evaluates to the negative Euler-Mascheroni constant $-\gamma$ . Thank you very much for your help!","Wolfram MathWorld (citing Abramowitz and Stegun) gives the following result: I am wondering if anybody could supply some details on the proof of this result? In particular, if we Taylor expand , we get: The last two terms of from above (i.e. ) follow very easily from the lower bound, but I'm not sure how to argue that the upper bound evaluates to the negative Euler-Mascheroni constant . Thank you very much for your help!",E_1(x)\equiv\int_x^\infty \frac{e^{-u}}{u}du=-\gamma-\ln x-\sum_{n=1}^\infty\frac{(-1)^nx^n}{n\cdot n!} e^{-u} E_1(x)=\int_x^\infty \frac{1-u+u^2/2!-u^3/3!+\ldots}{u}du=\left(\ln u+\sum_{n=1}^\infty\frac{(-1)^nu^n}{n\cdot n!}\right)\Bigg|^\infty_x E_1(x) -\ln x-\sum_{n=1}^\infty\frac{(-1)^nx^n}{n\cdot n!} -\gamma,"['sequences-and-series', 'gamma-function']"
90,"Let $\lim_{n\to\infty}a_n$ = a, $\lim_{n\to\infty}b_n$ = b. We need to find $\lim_{n\to\infty}\frac{a_nb_1+a_{n-1}b_2+...+a_1b_1}{n}$. [duplicate]","Let  = a,  = b. We need to find . [duplicate]",\lim_{n\to\infty}a_n \lim_{n\to\infty}b_n \lim_{n\to\infty}\frac{a_nb_1+a_{n-1}b_2+...+a_1b_1}{n},"This question already has answers here : Find the limit $\lim_{n\to\infty} \frac{x_1 y_n + x_2 y_{n-1} + \cdots + x_n y_1}{n}$ (5 answers) Closed 8 years ago . Let $\lim_{n\to\infty}a_n$ = a, $\lim_{n\to\infty}b_n$ = b. We need to find $\lim_{n\to\infty}\frac{a_nb_1+a_{n-1}b_2+...+a_1b_1}{n}$. As far as I get it, the answer is $ab$. I've tried this to prove it: as both $a_n$ and $b_n$ have a limit, they also both have a supremum. Let $C_1$ and $C_2$ be the supremua. Then by the properties of supremum for any given $е$ there are $k, l$ such that  $$\frac{a_nb_1+a_{n-1}b_2+...+a_1b_n}{n}<C_1C_2<(a_k+e)(b_l+e)$$ And I feel like there is some tiny step from here to the solution as the above is more or less $ab$, but I just can't get there. Would you mind giving some hints?","This question already has answers here : Find the limit $\lim_{n\to\infty} \frac{x_1 y_n + x_2 y_{n-1} + \cdots + x_n y_1}{n}$ (5 answers) Closed 8 years ago . Let $\lim_{n\to\infty}a_n$ = a, $\lim_{n\to\infty}b_n$ = b. We need to find $\lim_{n\to\infty}\frac{a_nb_1+a_{n-1}b_2+...+a_1b_1}{n}$. As far as I get it, the answer is $ab$. I've tried this to prove it: as both $a_n$ and $b_n$ have a limit, they also both have a supremum. Let $C_1$ and $C_2$ be the supremua. Then by the properties of supremum for any given $е$ there are $k, l$ such that  $$\frac{a_nb_1+a_{n-1}b_2+...+a_1b_n}{n}<C_1C_2<(a_k+e)(b_l+e)$$ And I feel like there is some tiny step from here to the solution as the above is more or less $ab$, but I just can't get there. Would you mind giving some hints?",,"['sequences-and-series', 'limits']"
91,How to prove this inequality for $a_{n}<5$,How to prove this inequality for,a_{n}<5,"Let $a_{1}=1,a_{2}=2$ and be related by the recurrence $$a_{n+2}=\dfrac{a^2_{n+1}(1+a_{n})+(1+2a_{n})a_{n+1}-a^2_{n}}{a_{n+1}+a^2_{n}+a_{n}+1}$$ for $n\in N.$ How can I show that $a_{n}<5,n\in N$? my idea: I think we have  $$a_{n+2}=pa_{n+1}+qa_{n}$$ because we have $$a_{n+2}a_{n+1}+a_{n+2}a^2_{n}+a_{n+2}a_{n}+a_{n+2}=a^2_{n+1}+a^2_{n+1}a_{n}+a_{n+1}+2a_{n}a_{n+1}-a^2_{n}\cdots (1)$$ then  $$a_{n+1}a_{n}+a_{n+1}a^2_{n-1}+a_{n+1}a_{n-1}+a_{n+1}=a^2_{n}+a^2_{n}a_{n-1}+a_{n}+2a_{n-1}a_{n}-a^2_{n-1}\cdots (2)$$ (1)+(2)","Let $a_{1}=1,a_{2}=2$ and be related by the recurrence $$a_{n+2}=\dfrac{a^2_{n+1}(1+a_{n})+(1+2a_{n})a_{n+1}-a^2_{n}}{a_{n+1}+a^2_{n}+a_{n}+1}$$ for $n\in N.$ How can I show that $a_{n}<5,n\in N$? my idea: I think we have  $$a_{n+2}=pa_{n+1}+qa_{n}$$ because we have $$a_{n+2}a_{n+1}+a_{n+2}a^2_{n}+a_{n+2}a_{n}+a_{n+2}=a^2_{n+1}+a^2_{n+1}a_{n}+a_{n+1}+2a_{n}a_{n+1}-a^2_{n}\cdots (1)$$ then  $$a_{n+1}a_{n}+a_{n+1}a^2_{n-1}+a_{n+1}a_{n-1}+a_{n+1}=a^2_{n}+a^2_{n}a_{n-1}+a_{n}+2a_{n-1}a_{n}-a^2_{n-1}\cdots (2)$$ (1)+(2)",,"['sequences-and-series', 'inequality']"
92,Sylvester's sequence: is there an exact closed form?,Sylvester's sequence: is there an exact closed form?,,"I'm afraid this is one of those ""amateur mathematician with no journal access"" questions. Anyhow, Wikipedia ( here ) and OEIS give this closed form for the terms Sylvester's sequence: $S_n = \lfloor E^{2^{n+1}} + \frac12\rfloor$ (where $E \approx 1.264$). Is this the best we can do for a closed form, or is there an exact formula known? Is it known that there is no such formula?","I'm afraid this is one of those ""amateur mathematician with no journal access"" questions. Anyhow, Wikipedia ( here ) and OEIS give this closed form for the terms Sylvester's sequence: $S_n = \lfloor E^{2^{n+1}} + \frac12\rfloor$ (where $E \approx 1.264$). Is this the best we can do for a closed form, or is there an exact formula known? Is it known that there is no such formula?",,"['sequences-and-series', 'closed-form']"
93,Show that sequence approaches fixed point of a function,Show that sequence approaches fixed point of a function,,"Problem Let $f(x)$ be a differentiable function on $\Bbb R$ with $\left|\,f ' (x)\right| \leq r < 1$, where $r$ is constant.  Then consider the sequence $\{x_n\}$ such that $x_1 = 0$, $x_{n+1} = f(x_n)$, $n\geq1$.  Show that $x_n \to x^*$ as $n$ approaches infinity.  Moreover, $x^* = f(x^*)$. Attempt I tried showing that when $f ' (x) = r$, then eventually you end up with $x_{n+1} = \sum_{n=1}^{\infty}r^n$.  That sum converges by the $p$ test, so then $f(x)$ should converge to some number $x^*$.  Then for $\epsilon>0$ there exists $N$ such that $n\geq N$ such that $$ \left|\,f(x^*)-x^*\right| \leq \left|x_{n+1} - x_n\right| \leq \epsilon. $$ Then to show for $f ' (x) < r$ use direct comparison test to say the bigger series converges so the smaller one must converge as well. I'm not sure if I can just do this or not, can someone let me know if I'm using the correct method or not?","Problem Let $f(x)$ be a differentiable function on $\Bbb R$ with $\left|\,f ' (x)\right| \leq r < 1$, where $r$ is constant.  Then consider the sequence $\{x_n\}$ such that $x_1 = 0$, $x_{n+1} = f(x_n)$, $n\geq1$.  Show that $x_n \to x^*$ as $n$ approaches infinity.  Moreover, $x^* = f(x^*)$. Attempt I tried showing that when $f ' (x) = r$, then eventually you end up with $x_{n+1} = \sum_{n=1}^{\infty}r^n$.  That sum converges by the $p$ test, so then $f(x)$ should converge to some number $x^*$.  Then for $\epsilon>0$ there exists $N$ such that $n\geq N$ such that $$ \left|\,f(x^*)-x^*\right| \leq \left|x_{n+1} - x_n\right| \leq \epsilon. $$ Then to show for $f ' (x) < r$ use direct comparison test to say the bigger series converges so the smaller one must converge as well. I'm not sure if I can just do this or not, can someone let me know if I'm using the correct method or not?",,"['sequences-and-series', 'analysis', 'limits', 'convergence-divergence', 'fixed-point-theorems']"
94,how compute $a_n$ respect to b?,how compute  respect to b?,a_n,"Assume sequence ${a_n}$ ,$a_n\in \Bbb R\,$ is defined by : $$a_0=0\quad a_1=b\quad a_{n+1}=a_n\sqrt{1+a^2_{n-1}} +\sqrt{1+a^2_n} \quad,\;n\ge1$$ how calculate $a_n$ respect to b? thanks in advance","Assume sequence ${a_n}$ ,$a_n\in \Bbb R\,$ is defined by : $$a_0=0\quad a_1=b\quad a_{n+1}=a_n\sqrt{1+a^2_{n-1}} +\sqrt{1+a^2_n} \quad,\;n\ge1$$ how calculate $a_n$ respect to b? thanks in advance",,"['sequences-and-series', 'analysis']"
95,Sum of increasing power,Sum of increasing power,,"What are the results of this: $$\sum_{i = 1}^{n}a^{i^{2}}$$ and this: $$\sum_{i = 1}^{n}a^{i^{3}}$$ expressed in terms of $n$, with $a$ being a predefined constant? Is there any general rule to calculating the sums of series like these for an arbitrary power of $i$?","What are the results of this: $$\sum_{i = 1}^{n}a^{i^{2}}$$ and this: $$\sum_{i = 1}^{n}a^{i^{3}}$$ expressed in terms of $n$, with $a$ being a predefined constant? Is there any general rule to calculating the sums of series like these for an arbitrary power of $i$?",,"['sequences-and-series', 'summation']"
96,Series of quotients with perturbed denominator,Series of quotients with perturbed denominator,,"Let $a_n>0$ and $b_n>0$ be two strictly declining sequences such that the series $$\sum_{n=1}^\infty \frac{a_n}{b_n}$$ is convergent. For $\sigma>0$ define $$f^N(\sigma) = \sum_{n=1}^N \frac{a_n}{b_n + \sigma/N}$$ Is it generally true that $\lim_{N \to \infty} f^N(\sigma)$ is independent of $\sigma$ or are there counterexamples? Remarks: The answer is trivially true if $\sum \frac{a_n}{b_n^2}$ is convergent as well. In this case $$\left|\frac{d}{d\sigma} f^N(\sigma)\right| = \frac{1}{N}\sum_{n=1}^{N} \frac{a_n}{(b_n+\sigma/N)^2} \leq \frac{1}{N}\sum_{n=1}^N \frac{a_n}{b_n^2} \to 0$$ More interesting is the case of divergent $\sum \frac{a_n}{b_n^2}$, e.g. $a_n = c^{-2n}$ and $b_n = c^{-n}$, or $a_n = 1/n^4$ and $b_n = 1/n^2$. In both these cases $$ \frac{d}{d\sigma} \left.f^N(\sigma)\right|_{\sigma=0} \to 1, $$ but from playing around with Maple and Mathematica I have the suspicion that $\frac{d}{d{\sigma}}f^N(\sigma)$ converges to $0$ for every $\sigma>0$, i.e. $f^N(\sigma)$ becomes non-differentiable in the limit. If that is true it would still allow for the possibility of $f^N(\sigma)$ converging pointwise to a constant. Eventually I am interested in the case $a_n = n^2I_n(K)^2$ and $b_n=I_n(K)$, where $I_n(K)$ is the modified Bessel function of the first kind. Any help or pointer to relevant literature is very much appreciated!","Let $a_n>0$ and $b_n>0$ be two strictly declining sequences such that the series $$\sum_{n=1}^\infty \frac{a_n}{b_n}$$ is convergent. For $\sigma>0$ define $$f^N(\sigma) = \sum_{n=1}^N \frac{a_n}{b_n + \sigma/N}$$ Is it generally true that $\lim_{N \to \infty} f^N(\sigma)$ is independent of $\sigma$ or are there counterexamples? Remarks: The answer is trivially true if $\sum \frac{a_n}{b_n^2}$ is convergent as well. In this case $$\left|\frac{d}{d\sigma} f^N(\sigma)\right| = \frac{1}{N}\sum_{n=1}^{N} \frac{a_n}{(b_n+\sigma/N)^2} \leq \frac{1}{N}\sum_{n=1}^N \frac{a_n}{b_n^2} \to 0$$ More interesting is the case of divergent $\sum \frac{a_n}{b_n^2}$, e.g. $a_n = c^{-2n}$ and $b_n = c^{-n}$, or $a_n = 1/n^4$ and $b_n = 1/n^2$. In both these cases $$ \frac{d}{d\sigma} \left.f^N(\sigma)\right|_{\sigma=0} \to 1, $$ but from playing around with Maple and Mathematica I have the suspicion that $\frac{d}{d{\sigma}}f^N(\sigma)$ converges to $0$ for every $\sigma>0$, i.e. $f^N(\sigma)$ becomes non-differentiable in the limit. If that is true it would still allow for the possibility of $f^N(\sigma)$ converging pointwise to a constant. Eventually I am interested in the case $a_n = n^2I_n(K)^2$ and $b_n=I_n(K)$, where $I_n(K)$ is the modified Bessel function of the first kind. Any help or pointer to relevant literature is very much appreciated!",,"['sequences-and-series', 'limits']"
97,How fast does $\sum_{k=1}^n \frac{1}{k^\alpha}$ ( $\alpha\leq1$) diverge?,How fast does  ( ) diverge?,\sum_{k=1}^n \frac{1}{k^\alpha} \alpha\leq1,"The series $\sum_{k=1}^\infty \frac{1}{k^\alpha}$ diverges if $\alpha\leq 1$. How can I estimate the divergent rate when $\alpha$ is given. For example, if $\alpha=1$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(\log n)$; if $\alpha=0$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(n)$.","The series $\sum_{k=1}^\infty \frac{1}{k^\alpha}$ diverges if $\alpha\leq 1$. How can I estimate the divergent rate when $\alpha$ is given. For example, if $\alpha=1$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(\log n)$; if $\alpha=0$, $\sum_{k=1}^n \frac{1}{k^\alpha}=O(n)$.",,['sequences-and-series']
98,Test the convergence of: $1+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}+\cdots$,Test the convergence of:,1+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}+\frac{1}{5}-\frac{1}{6}+\cdots,"My Solution Let the subscript begin at 1. Group the terms three by three. The partial sum $S_{n}$ satisfies $$S_{3n}-S_{3(n-1)}=\frac{1}{3n-2}+\frac{1}{3n-1}-\frac{1}{3n} > \frac{1}{3n}+\frac{1}{3n}-\frac{1}{3n}=\frac{1}{3n},\quad(n\ge1),$$ where $S_0=0$. Thus $S_{3n}>\sum\limits_{i=1}^n \frac{1}{3i}$ and $S_{3n}$ diverges as $n\to+\infty$. As $\{S_{3n}\}$ is a divergent subseries (?) of $\{S_n\}$, so the original series must be divergent. Questions Is the word ""subseries"" correct? [ Edit : Yeah, I find ""subsequence"" a better word.] Is my solution a rigorous proof? [ Edit : It is a proof. It has no flaw. It is rigorous.] Are there other different / elegant / interesting solutions? [ Edit: Seems that my solution is succinct enough.] What is a rigorous proof ? [ Edit : A proof that has no flaw is rigorous.] Thank you all!","My Solution Let the subscript begin at 1. Group the terms three by three. The partial sum $S_{n}$ satisfies $$S_{3n}-S_{3(n-1)}=\frac{1}{3n-2}+\frac{1}{3n-1}-\frac{1}{3n} > \frac{1}{3n}+\frac{1}{3n}-\frac{1}{3n}=\frac{1}{3n},\quad(n\ge1),$$ where $S_0=0$. Thus $S_{3n}>\sum\limits_{i=1}^n \frac{1}{3i}$ and $S_{3n}$ diverges as $n\to+\infty$. As $\{S_{3n}\}$ is a divergent subseries (?) of $\{S_n\}$, so the original series must be divergent. Questions Is the word ""subseries"" correct? [ Edit : Yeah, I find ""subsequence"" a better word.] Is my solution a rigorous proof? [ Edit : It is a proof. It has no flaw. It is rigorous.] Are there other different / elegant / interesting solutions? [ Edit: Seems that my solution is succinct enough.] What is a rigorous proof ? [ Edit : A proof that has no flaw is rigorous.] Thank you all!",,['sequences-and-series']
99,Radius of Convergence of this Series,Radius of Convergence of this Series,,"This is a question from a GRE math subject test practice material. $$ \sum^{\infty}_{n=1} \frac{n!x^{2n}}{n^n(1+x^{2n})}  $$ The set of real numbers $x$ for which the series converges is: $\{0\}$, $\{-1 \leq x \leq 1\}$, $\{-1 < x < 1\}$, $\{-\sqrt{e} \leq x \leq \sqrt{e}\}$ or $\mathbb{R}$? Attempt: $\frac{n!}{n^n} = \frac{1}{n} \frac{2}{n} \frac{3(4)(5)...(n-1)(n)}{n^{n-2}} < (2/n^2)$ So by comparison test to $(2/n^2)$, $\frac{n!}{n^n}$ converges. Furthermore, $0 < \frac{x^{2n}}{(1+x^{2n})} < 1$  for all $x \in \mathbb{R}$. So this series converges for all real number $x$? The answer is $\mathbb{R}$? Questions: Is my logic and answer correct? Is there an easier way?","This is a question from a GRE math subject test practice material. $$ \sum^{\infty}_{n=1} \frac{n!x^{2n}}{n^n(1+x^{2n})}  $$ The set of real numbers $x$ for which the series converges is: $\{0\}$, $\{-1 \leq x \leq 1\}$, $\{-1 < x < 1\}$, $\{-\sqrt{e} \leq x \leq \sqrt{e}\}$ or $\mathbb{R}$? Attempt: $\frac{n!}{n^n} = \frac{1}{n} \frac{2}{n} \frac{3(4)(5)...(n-1)(n)}{n^{n-2}} < (2/n^2)$ So by comparison test to $(2/n^2)$, $\frac{n!}{n^n}$ converges. Furthermore, $0 < \frac{x^{2n}}{(1+x^{2n})} < 1$  for all $x \in \mathbb{R}$. So this series converges for all real number $x$? The answer is $\mathbb{R}$? Questions: Is my logic and answer correct? Is there an easier way?",,['sequences-and-series']
