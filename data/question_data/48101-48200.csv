,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Brownian bridge sde,Brownian bridge sde,,"The SDE for the Brownian bridge is the following: $$dX_t = \dfrac{b-X_t}{1-t} \, dt+dB_t$$ with the solution $$X_t = a(1-t)+bt+(1-t)\int_{0}^t \dfrac{dB_s}{1-s}.$$ The expectation and covariance are: $$\mathbb{E}(X_t) = a+(b-a)t$$ $$\operatorname{Cov}(X_s,X_t) = \min(s,t)-st$$ Now I want to have a look at what happens as $t\rightarrow 1$ . For the expectation and covariance I get $$\mathbb{E}(X_1) = b,$$ $$\operatorname{Cov}(X_s,X_1) = \min(s,1)-s$$ But I'm having trouble to see what happens with $X_t$ . The first two summands clearly go to b, and the last summand should go to 0 as Brownian bridge expression for a Brownian motion suggests. The prove in the last comment using Doob's maximal inequality and Borel-Cantelli is quite short and I don't understand, what's exactly happening there, especially not, where the last equation comes from. Would be great if someone could explain it more exact how I get $$\lim_{t \rightarrow 1} (1-t)\int_0^t \frac{dB_s}{1-s} = 0 \text{ a.s.} $$ Thanks in advance!","The SDE for the Brownian bridge is the following: with the solution The expectation and covariance are: Now I want to have a look at what happens as . For the expectation and covariance I get But I'm having trouble to see what happens with . The first two summands clearly go to b, and the last summand should go to 0 as Brownian bridge expression for a Brownian motion suggests. The prove in the last comment using Doob's maximal inequality and Borel-Cantelli is quite short and I don't understand, what's exactly happening there, especially not, where the last equation comes from. Would be great if someone could explain it more exact how I get Thanks in advance!","dX_t = \dfrac{b-X_t}{1-t} \, dt+dB_t X_t = a(1-t)+bt+(1-t)\int_{0}^t \dfrac{dB_s}{1-s}. \mathbb{E}(X_t) = a+(b-a)t \operatorname{Cov}(X_s,X_t) = \min(s,t)-st t\rightarrow 1 \mathbb{E}(X_1) = b, \operatorname{Cov}(X_s,X_1) = \min(s,1)-s X_t \lim_{t \rightarrow 1} (1-t)\int_0^t \frac{dB_s}{1-s} = 0 \text{ a.s.} ","['integration', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
1,Non-integrable function that has an antiderivative,Non-integrable function that has an antiderivative,,"The wikipedia article on antiderivatives states: Non-continuous functions can have antiderivatives. [...] In some cases, the antiderivatives of such pathological functions may be found by Riemann integration, while in other cases these   functions are not Riemann integrable. I'm looking for an example of such a function - a bounded function $f : [a, b] \to [m, M]$ that has an antiderivative $F$ such that $F' = f$ on its domain, while $f$ is not Riemann-integrable.","The wikipedia article on antiderivatives states: Non-continuous functions can have antiderivatives. [...] In some cases, the antiderivatives of such pathological functions may be found by Riemann integration, while in other cases these   functions are not Riemann integrable. I'm looking for an example of such a function - a bounded function $f : [a, b] \to [m, M]$ that has an antiderivative $F$ such that $F' = f$ on its domain, while $f$ is not Riemann-integrable.",,['integration']
2,Evaluate $\int(x^{91}+x^{327})\cos(x)\mathrm{d}x \quad .$,Evaluate,\int(x^{91}+x^{327})\cos(x)\mathrm{d}x \quad .,"Evaluate  $$\int\left(x^{91}+x^{327}\right)\cos(x)\mathrm{d}x \quad .$$ It's my first time to face integration like that. I just need a clue to start because I tried, but it's not working Thanks in advance","Evaluate  $$\int\left(x^{91}+x^{327}\right)\cos(x)\mathrm{d}x \quad .$$ It's my first time to face integration like that. I just need a clue to start because I tried, but it's not working Thanks in advance",,"['integration', 'indefinite-integrals']"
3,Evaluating $\int_0^L\int_0^L \cos^{-1}\left(\frac{x^2+y^2-a^2}{2xy}\right)xy~dx~dy$,Evaluating,\int_0^L\int_0^L \cos^{-1}\left(\frac{x^2+y^2-a^2}{2xy}\right)xy~dx~dy,"I have the following integral to evaluate. $$\displaystyle\int\int_{x,y\in\Omega}\cos^{-1}\left(\frac{x^2+y^2-a^2}{2xy}\right)xy~dx~dy,$$   where $0\le a\le L$ and $\Omega=\{(x,y)\in (0,L]\times(0,L]: |x-y|<a,  (x+y)>a\}$. I used the transformation of variable as below: $$\begin{align}x&=\frac{a\sin(\theta+\phi)}{\sin \theta},\\ \\ y&=\frac{a\sin\phi}{\sin \theta}.\end{align}$$ It seems that the integral can be evaluated by this technique but I'm not sure because the calculations are getting quite messy. I was wondering is there any better method to find it? Thanks in advance.","I have the following integral to evaluate. $$\displaystyle\int\int_{x,y\in\Omega}\cos^{-1}\left(\frac{x^2+y^2-a^2}{2xy}\right)xy~dx~dy,$$   where $0\le a\le L$ and $\Omega=\{(x,y)\in (0,L]\times(0,L]: |x-y|<a,  (x+y)>a\}$. I used the transformation of variable as below: $$\begin{align}x&=\frac{a\sin(\theta+\phi)}{\sin \theta},\\ \\ y&=\frac{a\sin\phi}{\sin \theta}.\end{align}$$ It seems that the integral can be evaluated by this technique but I'm not sure because the calculations are getting quite messy. I was wondering is there any better method to find it? Thanks in advance.",,"['integration', 'definite-integrals']"
4,$f(x)=\int_{0}^{+\infty} e^{-(t+\frac{1}{t})x}dt$ how to find $f(x)$?,how to find ?,f(x)=\int_{0}^{+\infty} e^{-(t+\frac{1}{t})x}dt f(x),"$$f(x)=\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt$$ if while  $ x>0 $ ,  $ f(x) $  has values I noticed some interesting relations for $f(x)$ as shown below: $$ \begin{align} t & =\frac{1}{z} \\ f(x) & =\int_0^{+\infty} \frac{1}{z^2} e^{-(z+\frac{1}{z})x}dz=\int_0^{+\infty} \frac{1}{t^{2}} e^{-(t+\frac{1}{t})x} \; dt \\ f'(x) & =-\int_{0}^{+\infty} (t+\frac{1}{t}) e^{-(t+\frac{1}{t})x}\;dt \\ f''(x) & = \int_0^{+\infty} (t^2+2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}\;dt=\int_0^{+\infty} (t^{2}+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}dt+2\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt \\ f''(x) & =\int_0^{+\infty} (t^2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}\;dt+2f(x) \\ f''(x)-2f(x) & =\int_0^{+\infty} (t^2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x} \; dt=\int_0^{+\infty} t^2 e^{-(t+\frac{1}{t})x}\;dt+\int_0^{+\infty} \frac{1}{t^2} e^{-(t+\frac{1}{t})x}\;dt \\ f''(x)-2f(x) & =\int_0^{+\infty} t^2 e^{-(t+\frac{1}{t})x}dt+f(x) \\ f''(x)-3f(x) & =\int_{0}^{+\infty} t^{2} e^{-(t+\frac{1}{t})x}dt \end{align} $$ and also another relation $$f(x)=\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}dt=\int_0^1 e^{-(t+\frac{1}{t})x}\;dt+\int_1^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt$$ $$=\int_0^1 e^{-(t+\frac{1}{t})x}\;dt+\int_0^1 \frac{1}{z^2}e^{-(z+\frac{1}{z})x}\;dz=\int_0^1(1+\frac{1}{z^2})e^{-(z+\frac{1}{z})x}\;dz$$ I can write many relation that related to that function However I havent expressed it yet as a known function relation. How can I find $f(x)$? Thanks a lot for answers","$$f(x)=\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt$$ if while  $ x>0 $ ,  $ f(x) $  has values I noticed some interesting relations for $f(x)$ as shown below: $$ \begin{align} t & =\frac{1}{z} \\ f(x) & =\int_0^{+\infty} \frac{1}{z^2} e^{-(z+\frac{1}{z})x}dz=\int_0^{+\infty} \frac{1}{t^{2}} e^{-(t+\frac{1}{t})x} \; dt \\ f'(x) & =-\int_{0}^{+\infty} (t+\frac{1}{t}) e^{-(t+\frac{1}{t})x}\;dt \\ f''(x) & = \int_0^{+\infty} (t^2+2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}\;dt=\int_0^{+\infty} (t^{2}+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}dt+2\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt \\ f''(x) & =\int_0^{+\infty} (t^2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x}\;dt+2f(x) \\ f''(x)-2f(x) & =\int_0^{+\infty} (t^2+\frac{1}{t^2}) e^{-(t+\frac{1}{t})x} \; dt=\int_0^{+\infty} t^2 e^{-(t+\frac{1}{t})x}\;dt+\int_0^{+\infty} \frac{1}{t^2} e^{-(t+\frac{1}{t})x}\;dt \\ f''(x)-2f(x) & =\int_0^{+\infty} t^2 e^{-(t+\frac{1}{t})x}dt+f(x) \\ f''(x)-3f(x) & =\int_{0}^{+\infty} t^{2} e^{-(t+\frac{1}{t})x}dt \end{align} $$ and also another relation $$f(x)=\int_0^{+\infty}  e^{-(t+\frac{1}{t})x}dt=\int_0^1 e^{-(t+\frac{1}{t})x}\;dt+\int_1^{+\infty}  e^{-(t+\frac{1}{t})x}\;dt$$ $$=\int_0^1 e^{-(t+\frac{1}{t})x}\;dt+\int_0^1 \frac{1}{z^2}e^{-(z+\frac{1}{z})x}\;dz=\int_0^1(1+\frac{1}{z^2})e^{-(z+\frac{1}{z})x}\;dz$$ I can write many relation that related to that function However I havent expressed it yet as a known function relation. How can I find $f(x)$? Thanks a lot for answers",,"['integration', 'ordinary-differential-equations', 'special-functions']"
5,Generalized integrals for Bessel Moments $\int_{0}^{\infty} x^4K_0(x)K_1(x)^3 \ln(xK_1(x))^2\text{d}x=\frac{1}{32}$,Generalized integrals for Bessel Moments,\int_{0}^{\infty} x^4K_0(x)K_1(x)^3 \ln(xK_1(x))^2\text{d}x=\frac{1}{32},"Let $I_\nu(x)$ be the modified Bessel functions of first kind with order $\text{ }\nu$ , $K_\nu(x)$ be the modified Bessel functions of second kind with order $\text{ }\nu$ . Prerequisite Information: The integral $$\int_{0}^{\infty} x^4K_0(x)K_1(x)^3 \ln(xK_1(x))^2\text{d}x=\frac{1}{32}$$ can be shown as follows: Note that $$\frac{\text{d}}{\mathrm{d}x}\left ( -\frac{x^\alpha}{\alpha} K_1(x)^\alpha  \right )  =x^\alpha K_0(x)K_1(x)^{\alpha-1}.$$ Therefore, $$\int_{0}^{\infty}x^\alpha K_0(x)K_1(x)^{\alpha-1}\text{d}x =\frac{1}{\alpha},\qquad{\Re(\alpha)>0} .$$ And the equality immediately follows by differentiating the expression. There are also some integral identities involving Bessel functions , but not (quite) trivial. These integrals had studied in arXiv:0801.0891 . For example, $$\begin{aligned} &\int_{0}^{\infty}K_0(x)^3\text{d}x=\frac{3\Gamma\left ( \frac{1}{3}  \right )^6 }{32\pi\cdot2^{2/3}}  ,\\ &\int_{0}^{\infty}xK_0(x)^4\text{d}x=\frac{7}{8}\zeta(3) ,\\ &\int_{0}^{\infty}xI_0(x)K_0(x)^2\text{d}x= \frac{\pi}{3\sqrt{3} },\\ &\int_{0}^{\infty}xI_0(x)K_0(x)^3\text{d}x=\frac{\pi^2}{16} . \end{aligned}$$ In this paper, the authors determine some relations among the moments. For example, $$ \int_{0}^{\infty}K_0(x)^4\text{d}x =\pi^2\int_{0}^{\infty}K_0(x)^2I_0(x)^2\mathrm{d}x. $$ These relations can be generalized in many ways. Using contour integration , we conclude that $$ \int_{0}^{\infty}  x^3 K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right )  \text{d}x=\frac{\pi^4}{128}. $$ (Only one example.) Moreover, $$ \int_{0}^{\infty}  x^{2k+1} K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right )  \text{d}x= \begin{cases}   0 & k=0, \\  a_k\cdot\pi^4 & k\in\mathbb{Z}^{+}. \end{cases} $$ Where $a_k$ is always a rational number. And we are able to compute $$ \int_{0}^{\infty}  xI_0(\alpha x) K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right )  \text{d}x $$ by expanding the $I_0(\alpha x)$ into Maclaurin series . Another simple identity is given by $$ \int_{0}^{\infty}x^7K_0(x)K_1(x)^2K_2(x)\text{d}x =\frac{1}{3}. $$ Problem: I am trying to find more results but failed. Can we find the closed-forms of other moments such as $\int_{0}^{\infty}K_0(x)^5\text{d}x, \int_{0}^{\infty}K_0(x)I_0(x)J_0(x)Y_0(x)\text{d}x$ ? Any idea would be much appreciated. Maybe interests: Two integrals (both are easy to check): $$\begin{aligned} &\int_{0}^{\infty} \frac{x^2}{\alpha^2+x^2}K_0(x)^2\text{d}x =\frac{\pi^2}{4}-\frac{\pi^3}{8}\alpha \left ( J_0(\alpha)^2+Y_0(\alpha)^2 \right ), \\  &\int_{0}^{\infty}K_0(x)^2\cos(\alpha x)\mathrm{d}x =\frac{\pi}{\sqrt{4+\alpha^2} }K\left ( \frac{\alpha}{\sqrt{4+\alpha^2} }  \right ).  \end{aligned}$$ Where $K(x)=\frac\pi2{}_2F_1\left(\frac12,\frac12;1;x^2\right)$ and ${}_2F_1$ is Gauss hypergeometric function .","Let be the modified Bessel functions of first kind with order , be the modified Bessel functions of second kind with order . Prerequisite Information: The integral can be shown as follows: Note that Therefore, And the equality immediately follows by differentiating the expression. There are also some integral identities involving Bessel functions , but not (quite) trivial. These integrals had studied in arXiv:0801.0891 . For example, In this paper, the authors determine some relations among the moments. For example, These relations can be generalized in many ways. Using contour integration , we conclude that (Only one example.) Moreover, Where is always a rational number. And we are able to compute by expanding the into Maclaurin series . Another simple identity is given by Problem: I am trying to find more results but failed. Can we find the closed-forms of other moments such as ? Any idea would be much appreciated. Maybe interests: Two integrals (both are easy to check): Where and is Gauss hypergeometric function .","I_\nu(x) \text{ }\nu K_\nu(x) \text{ }\nu \int_{0}^{\infty} x^4K_0(x)K_1(x)^3
\ln(xK_1(x))^2\text{d}x=\frac{1}{32} \frac{\text{d}}{\mathrm{d}x}\left ( -\frac{x^\alpha}{\alpha}
K_1(x)^\alpha  \right ) 
=x^\alpha K_0(x)K_1(x)^{\alpha-1}. \int_{0}^{\infty}x^\alpha K_0(x)K_1(x)^{\alpha-1}\text{d}x
=\frac{1}{\alpha},\qquad{\Re(\alpha)>0} . \begin{aligned}
&\int_{0}^{\infty}K_0(x)^3\text{d}x=\frac{3\Gamma\left ( \frac{1}{3}  \right )^6 }{32\pi\cdot2^{2/3}}  ,\\
&\int_{0}^{\infty}xK_0(x)^4\text{d}x=\frac{7}{8}\zeta(3) ,\\
&\int_{0}^{\infty}xI_0(x)K_0(x)^2\text{d}x= \frac{\pi}{3\sqrt{3} },\\
&\int_{0}^{\infty}xI_0(x)K_0(x)^3\text{d}x=\frac{\pi^2}{16} .
\end{aligned} 
\int_{0}^{\infty}K_0(x)^4\text{d}x
=\pi^2\int_{0}^{\infty}K_0(x)^2I_0(x)^2\mathrm{d}x.
 
\int_{0}^{\infty} 
x^3 K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right ) 
\text{d}x=\frac{\pi^4}{128}.
 
\int_{0}^{\infty} 
x^{2k+1} K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right ) 
\text{d}x=
\begin{cases}
  0 & k=0, \\
 a_k\cdot\pi^4 & k\in\mathbb{Z}^{+}.
\end{cases}
 a_k 
\int_{0}^{\infty} 
xI_0(\alpha x) K_0(x)^5I_0(x)\left ( \pi^2I_0(x)^2-K_0(x)^2 \right ) 
\text{d}x
 I_0(\alpha x) 
\int_{0}^{\infty}x^7K_0(x)K_1(x)^2K_2(x)\text{d}x
=\frac{1}{3}.
 \int_{0}^{\infty}K_0(x)^5\text{d}x,
\int_{0}^{\infty}K_0(x)I_0(x)J_0(x)Y_0(x)\text{d}x \begin{aligned}
&\int_{0}^{\infty} \frac{x^2}{\alpha^2+x^2}K_0(x)^2\text{d}x
=\frac{\pi^2}{4}-\frac{\pi^3}{8}\alpha \left ( J_0(\alpha)^2+Y_0(\alpha)^2 \right ),
\\ 
&\int_{0}^{\infty}K_0(x)^2\cos(\alpha x)\mathrm{d}x
=\frac{\pi}{\sqrt{4+\alpha^2} }K\left ( \frac{\alpha}{\sqrt{4+\alpha^2} }  \right ). 
\end{aligned} K(x)=\frac\pi2{}_2F_1\left(\frac12,\frac12;1;x^2\right) {}_2F_1","['integration', 'definite-integrals', 'contour-integration', 'closed-form', 'bessel-functions']"
6,Behavior of inverse of $f(s)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i}$,Behavior of inverse of,f(s)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i},"Take a function $f$ defined as follows with $H_n$ referring to Harmonic number $$f(s,n)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i}$$ Suppose $g(\epsilon,n)$ is the inverse of this function, ie $f(g(\epsilon,n),n)=\epsilon$ . I'm interested in behavior of $g(\epsilon,n)$ for fixed small $\epsilon>0$ as $n\to \infty$ . Plotting various values, it seems $g(10^{-6},n)\lesssim 10n$ . Can someone see a way to explain this analytically? Edit following Sal's suggestion, problem above can be rewritten as integral for large $n$ , and the inverse in $s$ seems to grow (sub)linearly as well $$f(s,n)\approx \frac{1}{\log n}\int_{i=1}^n \left(1-\frac{1}{i}\right)^{s} \frac{1}{i}$$ notebook Edit Trying to match Katsurda approximate expression, it seems to give good results for x<25 after which it diverges rapidly $$\sum_{j=2}^\infty \frac{(-x)^j}{j!}\zeta(j) \approx x(\log x + 2 \gamma -1)$$ After differentiating expression I get $$\sum_{j=1}^\infty -\frac{(-x)^j}{j!} \approx \log x+2\gamma$$","Take a function defined as follows with referring to Harmonic number Suppose is the inverse of this function, ie . I'm interested in behavior of for fixed small as . Plotting various values, it seems . Can someone see a way to explain this analytically? Edit following Sal's suggestion, problem above can be rewritten as integral for large , and the inverse in seems to grow (sub)linearly as well notebook Edit Trying to match Katsurda approximate expression, it seems to give good results for x<25 after which it diverges rapidly After differentiating expression I get","f H_n f(s,n)=\frac{1}{H_n}\sum_{i=1}^n \left(1-\frac{1}{i}\right)^s\frac{1}{i} g(\epsilon,n) f(g(\epsilon,n),n)=\epsilon g(\epsilon,n) \epsilon>0 n\to \infty g(10^{-6},n)\lesssim 10n n s f(s,n)\approx \frac{1}{\log n}\int_{i=1}^n \left(1-\frac{1}{i}\right)^{s} \frac{1}{i} \sum_{j=2}^\infty \frac{(-x)^j}{j!}\zeta(j) \approx x(\log x + 2 \gamma -1) \sum_{j=1}^\infty -\frac{(-x)^j}{j!} \approx \log x+2\gamma","['integration', 'sequences-and-series', 'limits', 'summation', 'hypergeometric-function']"
7,Trouble with Poisson integral,Trouble with Poisson integral,,"I'm continuing my studies about the space $\mathbb{T}$ and I reach the point in which are introduced the Harmonic functions. Well up to now I have a little trouble with understanding the Poisson's integral. I know that this particular integral is defined as: DEF: If $\mu\in\ M(\mathbb{T})$ we define the Poisson integral of $\mu$ by the expression for $z= re^{i\theta}$ : $P(\mu)(z)=\int_{-\pi}^{\pi}P(ze^{-it})d\mu (t)$ . Now to understand better how to use it, I am trying doing some exercise about this Poisson integral. In particular, I'm trying to calculate $P(\mu)$ for this two cases: For $\mu=\delta_{0}-\delta_{\pi/2}$ where $\delta_{x}$ is the Dirac measure for the points $d\mu=D_{N}(t)dm(t)$ where $D_{N}$ is the kernel of Dirichelet. I've tried to apply directly my definition but something goes wrong! Can someone help me?","I'm continuing my studies about the space and I reach the point in which are introduced the Harmonic functions. Well up to now I have a little trouble with understanding the Poisson's integral. I know that this particular integral is defined as: DEF: If we define the Poisson integral of by the expression for : . Now to understand better how to use it, I am trying doing some exercise about this Poisson integral. In particular, I'm trying to calculate for this two cases: For where is the Dirac measure for the points where is the kernel of Dirichelet. I've tried to apply directly my definition but something goes wrong! Can someone help me?",\mathbb{T} \mu\in\ M(\mathbb{T}) \mu z= re^{i\theta} P(\mu)(z)=\int_{-\pi}^{\pi}P(ze^{-it})d\mu (t) P(\mu) \mu=\delta_{0}-\delta_{\pi/2} \delta_{x} d\mu=D_{N}(t)dm(t) D_{N},"['integration', 'complex-analysis', 'harmonic-analysis', 'harmonic-functions', 'poisson-integrals']"
8,Volume of a ball in hyperbolic space,Volume of a ball in hyperbolic space,,"I'm trying to derive the volume of the $n$ -dimensional R-ball in hyperbolic space, $\mathcal{B}_\mathbb{H}(y; R) = \{x \in \mathbb{H}^n : \lVert x \rVert_y \le R\}$ , using the Riemannian volume formula and integrating in the exponential chart at $y \in \mathbb{H}^n$ : $$\mathcal{Vol}(\mathcal{B}_\mathbb{H}) = \int_\mathcal{X} d\mathcal{M} = \int_{B_y} \sqrt{\det g(\exp_y(u))} du,$$ where $B_y = \log_y \mathcal{B}_\mathbb{H}$ , $g(x)$ is the metric tensor expressed in some orthonormal frame, and $\exp_y(\cdot)$ denotes the exponential map. I'm using [1, Sec 3.1] as a reference for this approach. However, I'm getting a different result than what I expect, which is $\propto \int_0^R \sinh^{n-1}(r) dr$ ( wiki ), and I wonder what I'm doing wrong. I assume it's something that has to do with how I'm handling the metric tensor, but I couldn't pinpoint it precisely. Do I misinterpret the volume formula from above? My approach is to use the Poincaré ball model because that's the model I'm familiar with where the metric tensor has a nice expression: $g(x) = \Big(\frac{2}{1 - \lVert x \rVert^2}\Big)^2 I_n$ .  Because it only depends on $x$ via its extrinsic norm, the integral above separates per angular coordinates and radial distance. I want to compute the latter which amounts to computing $\sqrt{\det g(x)}$ for $x$ with $d(0, x) = r$ and then integrating over $r$ from $0$ to $R$ . We have, $$d(0, x) = \cosh^{-1}\Big(1 + 2 \frac{\lVert x \rVert^2}{1 - \lVert x \rVert^2}\Big) = r \implies \lVert x \rVert^2 = \frac{\cosh(r) - 1}{\cosh(r) + 1},$$ and $$\sqrt{\det g(x)} = \Big(\frac{2}{1 - \lVert x \rVert^2}\Big)^n.$$ Finally, substituting the former into the latter gives $\sqrt{\det g(x)} = \big(\cosh(r) + 1\big)^n$ which is different than the expected $\sinh^{n-1}(r)$ . [1]: Pennec, Xavier. ""Intrinsic statistics on Riemannian manifolds: Basic tools for geometric measurements."" Journal of Mathematical Imaging and Vision 25.1 (2006): 127.","I'm trying to derive the volume of the -dimensional R-ball in hyperbolic space, , using the Riemannian volume formula and integrating in the exponential chart at : where , is the metric tensor expressed in some orthonormal frame, and denotes the exponential map. I'm using [1, Sec 3.1] as a reference for this approach. However, I'm getting a different result than what I expect, which is ( wiki ), and I wonder what I'm doing wrong. I assume it's something that has to do with how I'm handling the metric tensor, but I couldn't pinpoint it precisely. Do I misinterpret the volume formula from above? My approach is to use the Poincaré ball model because that's the model I'm familiar with where the metric tensor has a nice expression: .  Because it only depends on via its extrinsic norm, the integral above separates per angular coordinates and radial distance. I want to compute the latter which amounts to computing for with and then integrating over from to . We have, and Finally, substituting the former into the latter gives which is different than the expected . [1]: Pennec, Xavier. ""Intrinsic statistics on Riemannian manifolds: Basic tools for geometric measurements."" Journal of Mathematical Imaging and Vision 25.1 (2006): 127.","n \mathcal{B}_\mathbb{H}(y; R) = \{x \in \mathbb{H}^n : \lVert x \rVert_y \le R\} y \in \mathbb{H}^n \mathcal{Vol}(\mathcal{B}_\mathbb{H}) = \int_\mathcal{X} d\mathcal{M} = \int_{B_y} \sqrt{\det g(\exp_y(u))} du, B_y = \log_y \mathcal{B}_\mathbb{H} g(x) \exp_y(\cdot) \propto \int_0^R \sinh^{n-1}(r) dr g(x) = \Big(\frac{2}{1 - \lVert x \rVert^2}\Big)^2 I_n x \sqrt{\det g(x)} x d(0, x) = r r 0 R d(0, x) = \cosh^{-1}\Big(1 + 2 \frac{\lVert x \rVert^2}{1 - \lVert x \rVert^2}\Big) = r \implies \lVert x \rVert^2 = \frac{\cosh(r) - 1}{\cosh(r) + 1}, \sqrt{\det g(x)} = \Big(\frac{2}{1 - \lVert x \rVert^2}\Big)^n. \sqrt{\det g(x)} = \big(\cosh(r) + 1\big)^n \sinh^{n-1}(r)","['integration', 'differential-geometry', 'volume', 'hyperbolic-geometry']"
9,Bounds for $\int_0^1 x^{\cos x+\sin x} dx$,Bounds for,\int_0^1 x^{\cos x+\sin x} dx,"Hello I am trying to show that $\frac{2}{5} \le \int_0^1 x^{\cos x+\sin x}dx \le \frac{1}{2}$ or to get better bounds. Here is my try:$$I=\int_0^1 x^{\cos x}\cdot x^{\sin x} \,dx$$ By Cauchy inequality $$I^2\le \int_0^1 x^{\cos x} \,dx \cdot \int_0^1 x^{\sin x} \,dx$$ for $x\in [0,1]\,$ $$ 0\le \cos x \le 1$$ $$\,0\le \sin x \le 1$$ thus $$x^{\cos x} \le x$$ $$x^{\sin x} \le x$$ so $$\int_0^1 x^{\cos x} \,dx \le \frac{1}{2}$$ $$\int_0^1 x^{\sin x} \,dx \le \frac{1}{2}$$  Therefore $$I\le \sqrt{\frac{1}{2}\cdot \frac{1}{2}} \le \frac{1}{2}$$ Is this correct? And what about the lower bound?","Hello I am trying to show that $\frac{2}{5} \le \int_0^1 x^{\cos x+\sin x}dx \le \frac{1}{2}$ or to get better bounds. Here is my try:$$I=\int_0^1 x^{\cos x}\cdot x^{\sin x} \,dx$$ By Cauchy inequality $$I^2\le \int_0^1 x^{\cos x} \,dx \cdot \int_0^1 x^{\sin x} \,dx$$ for $x\in [0,1]\,$ $$ 0\le \cos x \le 1$$ $$\,0\le \sin x \le 1$$ thus $$x^{\cos x} \le x$$ $$x^{\sin x} \le x$$ so $$\int_0^1 x^{\cos x} \,dx \le \frac{1}{2}$$ $$\int_0^1 x^{\sin x} \,dx \le \frac{1}{2}$$  Therefore $$I\le \sqrt{\frac{1}{2}\cdot \frac{1}{2}} \le \frac{1}{2}$$ Is this correct? And what about the lower bound?",,"['integration', 'upper-lower-bounds']"
10,Is the regularization of a Fourier transform unique?,Is the regularization of a Fourier transform unique?,,"The Fourier transform of the Coulomb potential $1/\vert \mathbf r \vert$   of an electric charge doesn't converge because one obtains $$F(k)=\frac {4\pi}{k} \int_0^\infty \sin(kr) dr.$$ The standard way to obtain a sensible value is to multiple the integrand by $f(\alpha,r)=e^{-\alpha r}$ and after doing the integral, taking the limit $\alpha\to 0$ (which has a nice physical reason). So one gets  $$F(k)=\frac{4\pi}{k^2}.$$ Would any other function $f(\alpha,r)$ that makes the integral converge and that satisfies $\lim_{\alpha\to\alpha_0}f(\alpha,r)=1$ give the same result?  For example $$F(k)=\lim_{\alpha\to 0}\frac {4\pi}{k} \int_0^\infty \frac{\sin(kr)}{\Gamma(\alpha r)} dr\stackrel{?}{=}\frac{4\pi}{k^2}.$$ In this case, Cesàro integration gives the same result. What would be the sufficient condition for uniqueness of regularization (maybe the theory of tempered distributions can answer this).","The Fourier transform of the Coulomb potential $1/\vert \mathbf r \vert$   of an electric charge doesn't converge because one obtains $$F(k)=\frac {4\pi}{k} \int_0^\infty \sin(kr) dr.$$ The standard way to obtain a sensible value is to multiple the integrand by $f(\alpha,r)=e^{-\alpha r}$ and after doing the integral, taking the limit $\alpha\to 0$ (which has a nice physical reason). So one gets  $$F(k)=\frac{4\pi}{k^2}.$$ Would any other function $f(\alpha,r)$ that makes the integral converge and that satisfies $\lim_{\alpha\to\alpha_0}f(\alpha,r)=1$ give the same result?  For example $$F(k)=\lim_{\alpha\to 0}\frac {4\pi}{k} \int_0^\infty \frac{\sin(kr)}{\Gamma(\alpha r)} dr\stackrel{?}{=}\frac{4\pi}{k^2}.$$ In this case, Cesàro integration gives the same result. What would be the sufficient condition for uniqueness of regularization (maybe the theory of tempered distributions can answer this).",,"['integration', 'fourier-analysis', 'physics']"
11,Does $\operatorname{div}\left(\nabla G +xG\right)=0\Longleftrightarrow \nabla G +xG=0$?,Does ?,\operatorname{div}\left(\nabla G +xG\right)=0\Longleftrightarrow \nabla G +xG=0,Let $G$ be a smooth function defined on $\textbf{R}^d$. What are the assumptions I should use to assume that $$\operatorname{div}\left(\nabla G(x) +xG(x)\right)=0 \quad (\forall x\in \textbf{R}^d)$$ implies that $G$ is a Gaussian? (Several answers are possible I guess...) Many thanks !,Let $G$ be a smooth function defined on $\textbf{R}^d$. What are the assumptions I should use to assume that $$\operatorname{div}\left(\nabla G(x) +xG(x)\right)=0 \quad (\forall x\in \textbf{R}^d)$$ implies that $G$ is a Gaussian? (Several answers are possible I guess...) Many thanks !,,"['integration', 'partial-differential-equations', 'entropy', 'gaussian-integral']"
12,How do I evaluate the integral $\int \frac{1}{x^3 -1}dx$,How do I evaluate the integral,\int \frac{1}{x^3 -1}dx,"this is my first question here so I hope I did everything right. Still really new to LaTeX as well$$\int \frac{1}{x^3 -1}dx $$ I first used partial fractions to decompose this integral into two parts$$\int \frac{1}{3(x-1)}dx -\frac{1}{3} \int \frac{x+2}{x^2 + x + 1}dx$$ I definitely can solve the first part as $\frac{\ln(x-1)}{3}$ but I'm stuck with the second part as I don't know what to do since the denominator is not easily factor-able. Thanks in advance to anybody taking the time to read this. Edit: I do know that you can complete the square to make the integral prettier, but I don't know how to cancel the numerator or seperate it to relate the integral to $\int \frac{1}{x^2 + 1}$ to get some value of arctan(x) +c","this is my first question here so I hope I did everything right. Still really new to LaTeX as well$$\int \frac{1}{x^3 -1}dx $$ I first used partial fractions to decompose this integral into two parts$$\int \frac{1}{3(x-1)}dx -\frac{1}{3} \int \frac{x+2}{x^2 + x + 1}dx$$ I definitely can solve the first part as $\frac{\ln(x-1)}{3}$ but I'm stuck with the second part as I don't know what to do since the denominator is not easily factor-able. Thanks in advance to anybody taking the time to read this. Edit: I do know that you can complete the square to make the integral prettier, but I don't know how to cancel the numerator or seperate it to relate the integral to $\int \frac{1}{x^2 + 1}$ to get some value of arctan(x) +c",,"['integration', 'partial-fractions']"
13,Calculation of Radon–Nikodym derivative,Calculation of Radon–Nikodym derivative,,"Suppose the function $X \colon \mathbb{R} \longrightarrow \mathbb{R} \colon x \longmapsto X(x) : = x^2$. I want to calculate the Radon–Nikodym derivative $\frac{\text{d}\lambda_X}{\text{d}\lambda}$, where $\lambda$ denotes the Lebesgue measure and $\lambda_X$ is the Pushforward measure of $X$ with respect to $\lambda$. To calculate $\frac{\text{d}\lambda_X}{\text{d}\lambda}$ I first need to show that $\lambda_X \ll \lambda$. Now we have $$ \lambda(X^{-1}(a,b))=\lambda(\sqrt{a},\sqrt{b})=\sqrt{b}-\sqrt{a}$$ and $$ \lambda(a,b)=0 \Longrightarrow \lambda_X(a,b)=\lambda(\sqrt{a},\sqrt{b})=0$$ and hence $\lambda_X \ll \lambda$. Now my questions are: Is there a way to write the measure $\lambda_X$ explicitly down? How can I finally calculate $\frac{\text{d}\lambda_X}{\text{d}\lambda}$? Calculating $\frac{\text{d}\lambda_X}{\text{d}\lambda}$ means, finding a measurable function $\varphi \geq 0$ with $$\lambda_X(A) = \int_{A} \varphi \, \text{d} \lambda. $$ EDIT: By trying I found out that $\varphi(x)=2 \frac{1}{\sqrt{x}}$. Is this correct?","Suppose the function $X \colon \mathbb{R} \longrightarrow \mathbb{R} \colon x \longmapsto X(x) : = x^2$. I want to calculate the Radon–Nikodym derivative $\frac{\text{d}\lambda_X}{\text{d}\lambda}$, where $\lambda$ denotes the Lebesgue measure and $\lambda_X$ is the Pushforward measure of $X$ with respect to $\lambda$. To calculate $\frac{\text{d}\lambda_X}{\text{d}\lambda}$ I first need to show that $\lambda_X \ll \lambda$. Now we have $$ \lambda(X^{-1}(a,b))=\lambda(\sqrt{a},\sqrt{b})=\sqrt{b}-\sqrt{a}$$ and $$ \lambda(a,b)=0 \Longrightarrow \lambda_X(a,b)=\lambda(\sqrt{a},\sqrt{b})=0$$ and hence $\lambda_X \ll \lambda$. Now my questions are: Is there a way to write the measure $\lambda_X$ explicitly down? How can I finally calculate $\frac{\text{d}\lambda_X}{\text{d}\lambda}$? Calculating $\frac{\text{d}\lambda_X}{\text{d}\lambda}$ means, finding a measurable function $\varphi \geq 0$ with $$\lambda_X(A) = \int_{A} \varphi \, \text{d} \lambda. $$ EDIT: By trying I found out that $\varphi(x)=2 \frac{1}{\sqrt{x}}$. Is this correct?",,"['integration', 'measure-theory', 'stochastic-calculus', 'lebesgue-measure', 'stochastic-integrals']"
14,"Show that $u(x)=\ln\left(\ln\left(1+\frac{1}{|x|}\right)\right)$ is in $W^{1,n}(U)$, where $U=B(0,1)\subset\mathbb{R}^n$.","Show that  is in , where .","u(x)=\ln\left(\ln\left(1+\frac{1}{|x|}\right)\right) W^{1,n}(U) U=B(0,1)\subset\mathbb{R}^n","The entire problem statement is: Let $n>1$ and let $U=B(0,1)\subset\mathbb{R}^n$. Show that $u:U\to\mathbb{R}$ given by  $$u(x)=\ln\left(\ln\left(1+\frac{1}{|x|}\right)\right)$$ is in $W^{1,n}(U).$ My attempt at the proof is as follows: To show that $u\in W^{1,n}(U)$ it suffices to show that $|Du|\in L^{n}(U)$. Consider $$u_{x_i}=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}|x|^{-2}\frac{x_i}{|x|},$$ which simplifies to, $$u_{x_i}=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}\frac{x_i}{|x|^3}.$$ Thus, $$|Du|=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}\frac{1}{|x|^2}$$ which can be manipulated to, $$|Du|=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+|x|}\frac{1}{|x|}.$$ Moreover, since $U=B(0,1)$ we can bound the second term from above which gives, $$|Du|\leq\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{|x|}$$ Thus, we can instead show that $$\int_U\left(\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{|x|}\right)^n<\infty.$$ Converting this into polar coordinates we have with $r=|x|$, $$\int_0^R\int_{\partial B(0,r)}\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^n\,dSdr=\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^n\int_{\partial B(0,r)}dSdr$$ Note that $\int_{\partial B(0,r)}\,dS=n\alpha(n)r^{n-1}$, which is the surface area of $B(0,r)$. Thus, we have then $$n\alpha(n)\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^nr^{n-1}\,dr=n\alpha(n)\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\right)^n\frac{1}{r}\,dr$$ And so this is where I get stuck in the problem, since I don't how I can evaluate that last integral to show it's finite. Thank you for any help or feedback!","The entire problem statement is: Let $n>1$ and let $U=B(0,1)\subset\mathbb{R}^n$. Show that $u:U\to\mathbb{R}$ given by  $$u(x)=\ln\left(\ln\left(1+\frac{1}{|x|}\right)\right)$$ is in $W^{1,n}(U).$ My attempt at the proof is as follows: To show that $u\in W^{1,n}(U)$ it suffices to show that $|Du|\in L^{n}(U)$. Consider $$u_{x_i}=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}|x|^{-2}\frac{x_i}{|x|},$$ which simplifies to, $$u_{x_i}=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}\frac{x_i}{|x|^3}.$$ Thus, $$|Du|=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+\frac{1}{|x|}}\frac{1}{|x|^2}$$ which can be manipulated to, $$|Du|=\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{1+|x|}\frac{1}{|x|}.$$ Moreover, since $U=B(0,1)$ we can bound the second term from above which gives, $$|Du|\leq\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{|x|}$$ Thus, we can instead show that $$\int_U\left(\frac{1}{\ln\left(1+\frac{1}{|x|}\right)}\frac{1}{|x|}\right)^n<\infty.$$ Converting this into polar coordinates we have with $r=|x|$, $$\int_0^R\int_{\partial B(0,r)}\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^n\,dSdr=\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^n\int_{\partial B(0,r)}dSdr$$ Note that $\int_{\partial B(0,r)}\,dS=n\alpha(n)r^{n-1}$, which is the surface area of $B(0,r)$. Thus, we have then $$n\alpha(n)\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\frac{1}{r}\right)^nr^{n-1}\,dr=n\alpha(n)\int_0^R\left(\frac{1}{\ln\left(1+\frac{1}{r}\right)}\right)^n\frac{1}{r}\,dr$$ And so this is where I get stuck in the problem, since I don't how I can evaluate that last integral to show it's finite. Thank you for any help or feedback!",,"['integration', 'functional-analysis', 'sobolev-spaces', 'polar-coordinates']"
15,Integration by parts for multidimensional Lebesgue-Stieltjes Integrals,Integration by parts for multidimensional Lebesgue-Stieltjes Integrals,,"I am concerned with the following problem: I am wondering if there exists any sort of integration by parts formula for a multidimensional Lebesgue-Stieltjes integral. In my case the integral is given by (1) and its domain is a multidimensional subset of $\mathbb{R}^n$. I suspect that this would involve the function $f$ instead of the corresponding measure $\mu$ according to Theorem 2 below. I am looking for a result similar to the well known result in the case of $n=1$, i.e.: $$\int\limits_a^b g(t) \, df(t) = g(b)f(b)-g(a)f(a)-\int\limits_a^b f(t) dg(t)$$ I'd be greatful for any hint on literature that contains relevant information on such multidimensional scenarios. So far I found plenty of literature on the one-dimensional case, i.e. $\Omega \subset \mathbb{R}$, but nothing definitive on $\Omega \subset \mathbb{R}^n$ for $n>1$. Let's consider the following well known result from duality theory in Analysis: Theorem 1 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 14.14) Let $\Omega \subset \mathbb{R}^n$ and $\Phi: C_c(\Omega) \rightarrow \mathbb{R}$ be a continuous linear functional, where $C_c(\Omega)$ is the set of all real valued continous functions on $\Omega$ with compact support. Then $\Phi$ can be expressed the follwing way: $$\Phi(g) = \int\limits_{\Omega} g(x) \, d\mu(x) \mspace{1in} \forall g \in C_c(\Omega)\tag{1}$$ where $\mu$ is a regular signed Borel measures of bounded variation, which is uniquely determined. To further work with this measure $\mu$ I found the following interesting fact: Let's define $$\Delta_h f(x) := \sum\limits_\delta (-1)^{\sum_{i=1}^n \delta_i} f(x-h(\delta)) \tag{2}$$ with $\delta_i$ being either $0$ or $1$, $h = (h_1,\dots,h_n)$ and $h(\delta) = (h_1 \delta_1, \dots, h_n \delta_n)$ and the sum over $delta$ meaning the sum over all possible binary vectors with length $n$. Then the following theorem holds Theorem 2 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 10.50) If $f : \mathbb{R}^n \rightarrow \mathbb{R}$ is continuous from above and satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, then there exists a unique Borel measure $\mu$ on $\mathbb{R}^n$ satisfying (2). Conversely, if $\mu$ is Borel measure on $\mathbb{R}^n$, then there exists a function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ (unique up to translation) that is continuous from above, satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, and satisfies (2).","I am concerned with the following problem: I am wondering if there exists any sort of integration by parts formula for a multidimensional Lebesgue-Stieltjes integral. In my case the integral is given by (1) and its domain is a multidimensional subset of $\mathbb{R}^n$. I suspect that this would involve the function $f$ instead of the corresponding measure $\mu$ according to Theorem 2 below. I am looking for a result similar to the well known result in the case of $n=1$, i.e.: $$\int\limits_a^b g(t) \, df(t) = g(b)f(b)-g(a)f(a)-\int\limits_a^b f(t) dg(t)$$ I'd be greatful for any hint on literature that contains relevant information on such multidimensional scenarios. So far I found plenty of literature on the one-dimensional case, i.e. $\Omega \subset \mathbb{R}$, but nothing definitive on $\Omega \subset \mathbb{R}^n$ for $n>1$. Let's consider the following well known result from duality theory in Analysis: Theorem 1 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 14.14) Let $\Omega \subset \mathbb{R}^n$ and $\Phi: C_c(\Omega) \rightarrow \mathbb{R}$ be a continuous linear functional, where $C_c(\Omega)$ is the set of all real valued continous functions on $\Omega$ with compact support. Then $\Phi$ can be expressed the follwing way: $$\Phi(g) = \int\limits_{\Omega} g(x) \, d\mu(x) \mspace{1in} \forall g \in C_c(\Omega)\tag{1}$$ where $\mu$ is a regular signed Borel measures of bounded variation, which is uniquely determined. To further work with this measure $\mu$ I found the following interesting fact: Let's define $$\Delta_h f(x) := \sum\limits_\delta (-1)^{\sum_{i=1}^n \delta_i} f(x-h(\delta)) \tag{2}$$ with $\delta_i$ being either $0$ or $1$, $h = (h_1,\dots,h_n)$ and $h(\delta) = (h_1 \delta_1, \dots, h_n \delta_n)$ and the sum over $delta$ meaning the sum over all possible binary vectors with length $n$. Then the following theorem holds Theorem 2 (cf. Aliprantis Border, Infinite-Dimensional Analysis Theorem 10.50) If $f : \mathbb{R}^n \rightarrow \mathbb{R}$ is continuous from above and satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, then there exists a unique Borel measure $\mu$ on $\mathbb{R}^n$ satisfying (2). Conversely, if $\mu$ is Borel measure on $\mathbb{R}^n$, then there exists a function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ (unique up to translation) that is continuous from above, satisfies $\Delta_h f(x) \geq 0$ for all $x \in \mathbb{R}^n$ and all $h \in \mathbb{R}_+^n$, and satisfies (2).",,"['integration', 'measure-theory', 'lebesgue-measure']"
16,A difficult integral: $\int_0^{\pi/2} (\log \sin x)^2 \ dx $ [duplicate],A difficult integral:  [duplicate],\int_0^{\pi/2} (\log \sin x)^2 \ dx ,"This question already has answers here : Integrate square of the log-sine integral: $\int_0^{\frac{\pi}{2}}\ln^{2}(\sin(x))dx$ (8 answers) Closed 10 years ago . $$ \int_{0}^{\frac{\pi}{2}} (\log \sin x)^2 \, dx = \int_{0}^{\frac{\pi}{2}} (\log \cos x)^2 \, dx = \frac{\pi}{2}\left\{ \frac{\pi^2}{12} + (\log 2)^2 \right\} $$ I tried integration by parts, but I ended up with $$ \int_{0}^{\frac{\pi}{2}} (\log \sin x)(\log \cos x) \, dx. $$ I tried to use exponential form for integration but I couldn't integrate further. Original image: Link","This question already has answers here : Integrate square of the log-sine integral: $\int_0^{\frac{\pi}{2}}\ln^{2}(\sin(x))dx$ (8 answers) Closed 10 years ago . I tried integration by parts, but I ended up with I tried to use exponential form for integration but I couldn't integrate further. Original image: Link"," \int_{0}^{\frac{\pi}{2}} (\log \sin x)^2 \, dx = \int_{0}^{\frac{\pi}{2}} (\log \cos x)^2 \, dx = \frac{\pi}{2}\left\{ \frac{\pi^2}{12} + (\log 2)^2 \right\}   \int_{0}^{\frac{\pi}{2}} (\log \sin x)(\log \cos x) \, dx. ",['integration']
17,What is a cyclic integral?,What is a cyclic integral?,,Can anyone explain what a cyclic integral is? My professor used it in his Thermodynamics lecture. One of the equations was $$\oint\:dv=0$$ where $v$ is Volume. Isn't the integral of $dv$ equal to $v$? Can anyone explain in simple terms?,Can anyone explain what a cyclic integral is? My professor used it in his Thermodynamics lecture. One of the equations was $$\oint\:dv=0$$ where $v$ is Volume. Isn't the integral of $dv$ equal to $v$? Can anyone explain in simple terms?,,"['integration', 'physics']"
18,"What is $E[1/\|x\|^4]$ where $x\sim$ Gaussian($0,C\cdot $diag($1,1/2,1/3,1/4,\ldots$))?",What is  where  Gaussian(diag())?,"E[1/\|x\|^4] x\sim 0,C\cdot  1,1/2,1/3,1/4,\ldots","Let $\Sigma_d$ be a diagonal matrix with diagonal $1,1/2,1/3,\ldots,1/d$ Let $E_d$ denote expectation w.r.t normally distributed $x$ which is centered at 0 with covariance matrix $\frac{\Sigma_d}{\operatorname{Tr}\Sigma_d}$ What is the value of the following limit? $$\lim_{d\to \infty} E_d\left[\frac{1}{\|x\|^4}\right]$$ You can show that $\lim_{d\to\infty} E_d[\|x\|^4]=1$ by using Gaussian fourth-moment formula $E[\|x\|^4]=(\operatorname{Tr}\Sigma)^2+2\operatorname{Tr}(\Sigma^2)$ Numerical simulation suggests the limit in question might be equal to $1$ , any tips? notebook Closely related issue was discussed on stats.SE and on Mathoverflow in the last month. Question is still open.","Let be a diagonal matrix with diagonal Let denote expectation w.r.t normally distributed which is centered at 0 with covariance matrix What is the value of the following limit? You can show that by using Gaussian fourth-moment formula Numerical simulation suggests the limit in question might be equal to , any tips? notebook Closely related issue was discussed on stats.SE and on Mathoverflow in the last month. Question is still open.","\Sigma_d 1,1/2,1/3,\ldots,1/d E_d x \frac{\Sigma_d}{\operatorname{Tr}\Sigma_d} \lim_{d\to \infty} E_d\left[\frac{1}{\|x\|^4}\right] \lim_{d\to\infty} E_d[\|x\|^4]=1 E[\|x\|^4]=(\operatorname{Tr}\Sigma)^2+2\operatorname{Tr}(\Sigma^2) 1","['integration', 'probability-theory', 'statistics', 'normal-distribution']"
19,Different ways to evaluate $\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)}$,Different ways to evaluate,\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)},"The following question: How to compute the harmonic series $$\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)}$$ where $H_n=\sum_{k=1}^n\frac{1}{k}$ and $H_n^{(2)}=\sum_{k=1}^n\frac{1}{k^2}$ , was proposed by @Tolaso (The original question had been closed and deleted). My friend Cornel and I managed to compute it in different ways and would like to see other solutions if possible . Cornel's solution : We start with the following key identity presented in the book (Almost) Impossible Integrals, Sums, and Series ) , Sect. $4.19$ , pages $290-291$ , $$\varphi(n)=\sum_{k=1}^{\infty} \frac{H_k H_k^{(2)}}{(k+1)(k+n+1)}$$ $$\small =2\zeta(3)\frac{H_n}{n}+\frac{\zeta(2)}{2}\frac{H_n^2}{n}-\frac{\zeta(2)}{2}\frac{H_n^{(2)}}{n}-\frac{H_n^{(4)}}{4n}-\frac{(H_n^{(2)})^2}{4n}-\frac{H_n}{n}\sum_{i=1}^n \frac{H_i}{i^2}+\frac{1}{2n}\sum_{i=1}^{n} \frac{H_i^2}{i^2}.\tag1$$ Then, based on $(1)$ we obtain that $$\sum_{k=1}^{\infty} \frac{H_k H_k^{(2)}}{(k+1)(k+2)(k+3)}=\varphi(1)-\varphi(2)=\frac{1}{2}\zeta(3)-\frac{1}{4}\zeta(2)-\frac{1}{32}.$$ End of story A note: the whole process is completed by using series manipulations only, with no use of integrals. My solution : Replace $x$ by $xyz$ in the generating function : $$\sum_{n=1}^\infty H_nH_n^{(2)}x^n= \frac{\operatorname{Li}_3(x)+\operatorname{Li}_3(1-x)+\frac12\ln x\ln^2(1-x)-\zeta(2)\ln(1-x)-\zeta(3)}{1-x}=f(x),$$ we get $$\sum_{n=1}^\infty H_nH_n^{(2)}(xyz)^n=f(xyz).$$ Multiply both sides by $yz^2$ then integrate w.r.t $x$ , $y$ and $z$ using the fact $$\int_0^1\int_0^1\int_0^1 x^n y^{n+1}z^{n+2}dxdydz=\frac{1}{(n+1)(n+2)(n+3)}$$ we obtain $$\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)}=\int_0^1\int_0^1\int_0^1 yz^2f(xyz)dxdydz$$ $$\overset{x=t/y}{=}\int_0^1\left[\int_0^1\int_0^y z^2f(zt)dtdy\right]dz=\int_0^1\left[\int_0^1\int_t^1 z^2f(zt)dydt\right]dz$$ $$=\int_0^1\left[\int_0^1 z^2f(zt)(1-t)dt\right]dz\overset{t=u/z}{=}\int_0^1\int_0^z zf(u)\left(1-\frac{u}{z}\right)dudz$$ $$=\int_0^1\int_u^1 f(u)(z-u)dzdu=\frac12\int_0^1(1-u)^2f(u)du=\frac12\int_0^1 u^2f(1-u)du$$ $$=\frac12\underbrace{\int_0^1 u\operatorname{Li}_3(1-u)du}_{1-u\to u}+\frac12\int_0^1 u\operatorname{Li}_3(u)du$$ $$+\frac12\int_0^1 u\left[\frac12\ln(1-u)\ln^2(u)-\zeta(2)\ln(u)-\zeta(3)\right]du$$ $$=\frac12\int_0^1 \operatorname{Li}_3(u)du+\frac12\int_0^1 u\left[\frac12\ln(1-u)\ln^2(u)-\zeta(2)\ln(u)-\zeta(3)\right]du$$ $$=\frac12\left(\zeta(3)-\zeta(2)+1\right)+\frac12\left(\frac12\zeta(2)-\frac{17}{16}\right)$$ $$=\frac12\zeta(3)-\frac14\zeta(2)-\frac1{32}.$$","The following question: How to compute the harmonic series where and , was proposed by @Tolaso (The original question had been closed and deleted). My friend Cornel and I managed to compute it in different ways and would like to see other solutions if possible . Cornel's solution : We start with the following key identity presented in the book (Almost) Impossible Integrals, Sums, and Series ) , Sect. , pages , Then, based on we obtain that End of story A note: the whole process is completed by using series manipulations only, with no use of integrals. My solution : Replace by in the generating function : we get Multiply both sides by then integrate w.r.t , and using the fact we obtain","\sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)} H_n=\sum_{k=1}^n\frac{1}{k} H_n^{(2)}=\sum_{k=1}^n\frac{1}{k^2} 4.19 290-291 \varphi(n)=\sum_{k=1}^{\infty} \frac{H_k H_k^{(2)}}{(k+1)(k+n+1)} \small =2\zeta(3)\frac{H_n}{n}+\frac{\zeta(2)}{2}\frac{H_n^2}{n}-\frac{\zeta(2)}{2}\frac{H_n^{(2)}}{n}-\frac{H_n^{(4)}}{4n}-\frac{(H_n^{(2)})^2}{4n}-\frac{H_n}{n}\sum_{i=1}^n \frac{H_i}{i^2}+\frac{1}{2n}\sum_{i=1}^{n} \frac{H_i^2}{i^2}.\tag1 (1) \sum_{k=1}^{\infty} \frac{H_k H_k^{(2)}}{(k+1)(k+2)(k+3)}=\varphi(1)-\varphi(2)=\frac{1}{2}\zeta(3)-\frac{1}{4}\zeta(2)-\frac{1}{32}. x xyz \sum_{n=1}^\infty H_nH_n^{(2)}x^n=
\frac{\operatorname{Li}_3(x)+\operatorname{Li}_3(1-x)+\frac12\ln x\ln^2(1-x)-\zeta(2)\ln(1-x)-\zeta(3)}{1-x}=f(x), \sum_{n=1}^\infty H_nH_n^{(2)}(xyz)^n=f(xyz). yz^2 x y z \int_0^1\int_0^1\int_0^1 x^n y^{n+1}z^{n+2}dxdydz=\frac{1}{(n+1)(n+2)(n+3)} \sum_{n=1}^\infty\frac{H_nH_n^{(2)}}{(n+1)(n+2)(n+3)}=\int_0^1\int_0^1\int_0^1 yz^2f(xyz)dxdydz \overset{x=t/y}{=}\int_0^1\left[\int_0^1\int_0^y z^2f(zt)dtdy\right]dz=\int_0^1\left[\int_0^1\int_t^1 z^2f(zt)dydt\right]dz =\int_0^1\left[\int_0^1 z^2f(zt)(1-t)dt\right]dz\overset{t=u/z}{=}\int_0^1\int_0^z zf(u)\left(1-\frac{u}{z}\right)dudz =\int_0^1\int_u^1 f(u)(z-u)dzdu=\frac12\int_0^1(1-u)^2f(u)du=\frac12\int_0^1 u^2f(1-u)du =\frac12\underbrace{\int_0^1 u\operatorname{Li}_3(1-u)du}_{1-u\to u}+\frac12\int_0^1 u\operatorname{Li}_3(u)du +\frac12\int_0^1 u\left[\frac12\ln(1-u)\ln^2(u)-\zeta(2)\ln(u)-\zeta(3)\right]du =\frac12\int_0^1 \operatorname{Li}_3(u)du+\frac12\int_0^1 u\left[\frac12\ln(1-u)\ln^2(u)-\zeta(2)\ln(u)-\zeta(3)\right]du =\frac12\left(\zeta(3)-\zeta(2)+1\right)+\frac12\left(\frac12\zeta(2)-\frac{17}{16}\right) =\frac12\zeta(3)-\frac14\zeta(2)-\frac1{32}.","['integration', 'sequences-and-series', 'alternative-proof', 'harmonic-numbers', 'polylogarithm']"
20,Help for $\int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z$,Help for,\int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z,"With the help of programs I have been able to conjecture $$\int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z=\frac{\pi }{8}G-\frac{7}{32}\zeta \left(3\right)$$ But is there a simple way to prove this? What I have got thus far is: $$\int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z=-\frac{1}{2}\int _0^1\frac{1}{1+z^2}\int _0^z\frac{\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\:\mathrm{d}y\:\mathrm{d}z$$ $$=-\frac{1}{2}\int _0^1\frac{\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\int _y^1\frac{1}{1+z^2}\:\mathrm{d}z\:\mathrm{d}y=-\frac{1}{2}\int _0^1\frac{\left(\frac{\pi }{4}-\arctan \left(y\right)\right)\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\:\mathrm{d}y$$ But I'm not sure how to advance from here, is the current path I'm taking correct?","With the help of programs I have been able to conjecture But is there a simple way to prove this? What I have got thus far is: But I'm not sure how to advance from here, is the current path I'm taking correct?",\int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z=\frac{\pi }{8}G-\frac{7}{32}\zeta \left(3\right) \int _0^1\int _0^z\int _0^y\frac{1}{\left(1-x^2\right)\left(1+y^2\right)\left(1+z^2\right)}\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z=-\frac{1}{2}\int _0^1\frac{1}{1+z^2}\int _0^z\frac{\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\:\mathrm{d}y\:\mathrm{d}z =-\frac{1}{2}\int _0^1\frac{\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\int _y^1\frac{1}{1+z^2}\:\mathrm{d}z\:\mathrm{d}y=-\frac{1}{2}\int _0^1\frac{\left(\frac{\pi }{4}-\arctan \left(y\right)\right)\ln \left(\frac{1-y}{1+y}\right)}{1+y^2}\:\mathrm{d}y,"['integration', 'definite-integrals']"
21,Double integration with Indicator function,Double integration with Indicator function,,"The integral of interest is: $$Q = \int_{\mathbb{R}^2}\int_{\mathbb{R}^2} I\left(\frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1} \in [0,1]\right) \nonumber \\ \times I\left(2\arcsin\left(\frac{\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}}{2\sqrt{y_1^2 + \left(x_1 - \frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1}\right)^2}}\right) > \theta\right) \\ \times \exp\left(-C\left(y_1^2 + \left(x_1 - \frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1}\right)^2\right)\right)\mathrm{d}Z_1\mathrm{d}Z_2,$$ where $C > 0$ , $Z_1 = (x_1, y_1)$ , $Z_2 = (x_2,y_2)$ , $I(\cdot)$ is an indicator function, and $\theta \in (0, \pi]$ .","The integral of interest is: where , , , is an indicator function, and .","Q = \int_{\mathbb{R}^2}\int_{\mathbb{R}^2} I\left(\frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1} \in [0,1]\right) \nonumber \\
\times I\left(2\arcsin\left(\frac{\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}}{2\sqrt{y_1^2 + \left(x_1 - \frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1}\right)^2}}\right) > \theta\right) \\ \times \exp\left(-C\left(y_1^2 + \left(x_1 - \frac{1}{2}\frac{x_2^2 - x_1^2 + y_2^2 - y_1^2}{x_2-x_1}\right)^2\right)\right)\mathrm{d}Z_1\mathrm{d}Z_2, C > 0 Z_1 = (x_1, y_1) Z_2 = (x_2,y_2) I(\cdot) \theta \in (0, \pi]",['integration']
22,Need help with an integral in quantum mechanics,Need help with an integral in quantum mechanics,,"I'm studying many-electron atoms without e-e repulsion, in particular, an atom with two electrons and Z protons. Once we get the wave function for the ground state, which (in atomic units) is $$\psi (r_1,r_2)= {Z^3 \over \pi } e^{-Z(r_1+r_2)},$$ we want to approximate how much the e-e interaction would contribute to the energy. For that purpuse, we calculate the expected value of the potential energy $ ~  U_{ee} ={1 \over | \bf r _1 -  r_2 |} $ (again in atomic units), in the state given by the previous wave function. The integral to be calculated is: $$ \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ \psi ^* (r_1,r_2) {1 \over | \bf r _1 -  r_2 |} \psi  (r_1,r_2) = {Z^6 \over \pi^2} \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ { e^{-2Z(r_1+r_2)} \over | \bf r _1 -  r_2 |} $$ Now, it's been a while since I took a course in multivariable calculus, but I gave it a try... and couldn't do it. I know that the integral in cartesian coordinates is $${Z^6 \over \pi^2} \int _{-\infty} ^\infty \int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty  { e^{-2Z \left(\sqrt{x_1^2+y_1^2+z_1^2}+\sqrt{x_2^2+y_2^2+z_2^2} \right) } \over \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}}dx_1dy_1dz_1dx_2dy_2dz_2 ,  $$ and that, in order to compute it, you'd need to do the six iterated integrals. Mathematica can't do that in a reasonable time, and neither can I (I doubt there is a closed form for most of them). So instead I tried two sets of spherical coordinates: $$ x_1=r_1 \sin \theta _1 \cos \phi _1 ~~~~~~~~ x_2=r_2 \sin \theta _2 \cos \phi _2  \\ y_1=r_1 \sin \theta _1 \sin \phi _1 ~~~~~~~~~ y_2=r_2 \sin \theta _2 \sin \phi _2 \\ z_1=r_1 \cos \theta _1 ~~~~~~~~~ z_2=r_2 \cos \theta _2 $$ I used mathematica to calculate the Jacobian determinant and it turns out it's just the product of the two individual Jacobians (which should have been obvious but I'm a bit dumb). After calculating that denominator, the integral that needs to be done is: $$ {Z^6 \over \pi ^2} \int ^{2\pi} _0 \int ^{2\pi} _0 \int ^\pi _0 \int ^\pi _0 \int ^\infty _0 \int ^\infty _0 {e^{-2Z(r_1+r_2)} r_1^2r_2^2 \sin \theta _1 \sin \theta _2 \over \sqrt{r_1^2+r_2^2-2r_1r_2 (\sin \theta _1 \sin \theta _2 \cos (\phi _1 - \phi _2)+\cos \theta _1 \cos \theta _2)}} dr_1dr_2d\theta_1d\theta_2d\phi_1d\phi_2$$ ...which looks... better? Mathematica still hangs up if I try to do the whole integral. Integrating first in $r_1$ or $r_2$ seems impossible analytically. Trying to integrate first in the rest of variables gives a closed answer, but it's in terms of hypergeometric functions or elliptic integrals (and it's absurdly complicated). And the thing is: the answer to this integral is suposedly ${5 \over 8}Z$ . Is it really necessary to do six integrals involving hypergeometric functions and elliptic integrals to get such a simple answer? I wouldn't know how to continue anyways, because well... I don't know how to integrate eliptic integrals composed with other complicated functions and it seems mathematica doesn't know either. What should I do here? Edit: I swear the integrals fit in one line when I was writing.","I'm studying many-electron atoms without e-e repulsion, in particular, an atom with two electrons and Z protons. Once we get the wave function for the ground state, which (in atomic units) is we want to approximate how much the e-e interaction would contribute to the energy. For that purpuse, we calculate the expected value of the potential energy (again in atomic units), in the state given by the previous wave function. The integral to be calculated is: Now, it's been a while since I took a course in multivariable calculus, but I gave it a try... and couldn't do it. I know that the integral in cartesian coordinates is and that, in order to compute it, you'd need to do the six iterated integrals. Mathematica can't do that in a reasonable time, and neither can I (I doubt there is a closed form for most of them). So instead I tried two sets of spherical coordinates: I used mathematica to calculate the Jacobian determinant and it turns out it's just the product of the two individual Jacobians (which should have been obvious but I'm a bit dumb). After calculating that denominator, the integral that needs to be done is: ...which looks... better? Mathematica still hangs up if I try to do the whole integral. Integrating first in or seems impossible analytically. Trying to integrate first in the rest of variables gives a closed answer, but it's in terms of hypergeometric functions or elliptic integrals (and it's absurdly complicated). And the thing is: the answer to this integral is suposedly . Is it really necessary to do six integrals involving hypergeometric functions and elliptic integrals to get such a simple answer? I wouldn't know how to continue anyways, because well... I don't know how to integrate eliptic integrals composed with other complicated functions and it seems mathematica doesn't know either. What should I do here? Edit: I swear the integrals fit in one line when I was writing.","\psi (r_1,r_2)= {Z^3 \over \pi } e^{-Z(r_1+r_2)},  ~  U_{ee} ={1 \over | \bf r _1 -  r_2 |}   \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ \psi ^* (r_1,r_2) {1 \over | \bf r _1 -  r_2 |} \psi  (r_1,r_2) = {Z^6 \over \pi^2} \int d ^3 {\bf r } _1 d ^3 {\bf r } _2 ~ { e^{-2Z(r_1+r_2)} \over | \bf r _1 -  r_2 |}  {Z^6 \over \pi^2} \int _{-\infty} ^\infty \int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty\int _{-\infty} ^\infty  { e^{-2Z \left(\sqrt{x_1^2+y_1^2+z_1^2}+\sqrt{x_2^2+y_2^2+z_2^2} \right) } \over \sqrt{(x_1-x_2)^2+(y_1-y_2)^2+(z_1-z_2)^2}}dx_1dy_1dz_1dx_2dy_2dz_2 ,    x_1=r_1 \sin \theta _1 \cos \phi _1 ~~~~~~~~ x_2=r_2 \sin \theta _2 \cos \phi _2  \\ y_1=r_1 \sin \theta _1 \sin \phi _1 ~~~~~~~~~ y_2=r_2 \sin \theta _2 \sin \phi _2 \\ z_1=r_1 \cos \theta _1 ~~~~~~~~~ z_2=r_2 \cos \theta _2   {Z^6 \over \pi ^2} \int ^{2\pi} _0 \int ^{2\pi} _0 \int ^\pi _0 \int ^\pi _0 \int ^\infty _0 \int ^\infty _0 {e^{-2Z(r_1+r_2)} r_1^2r_2^2 \sin \theta _1 \sin \theta _2 \over \sqrt{r_1^2+r_2^2-2r_1r_2 (\sin \theta _1 \sin \theta _2 \cos (\phi _1 - \phi _2)+\cos \theta _1 \cos \theta _2)}} dr_1dr_2d\theta_1d\theta_2d\phi_1d\phi_2 r_1 r_2 {5 \over 8}Z","['integration', 'quantum-mechanics']"
23,Residue Theorem if Pole is on Contour,Residue Theorem if Pole is on Contour,,"This is  a question on contour integration. The particular problem has a (simple) pole on the contour which prohibits a direct application of Cauchy's Residue Theorem. Daniel Fischer commented as follows Not really. [...] if the contour is smooth at the pole, it's as if half of the pole lies inside the contour and half outside. If the contour has a corner at the pole, with (inner) angle $\alpha$ , the fraction is $\frac{\alpha}{2\pi}$ , so you get $\alpha i$ times the residue of the pole instead of $2\pi i$ times as for singularities properly enclosed by the contour. The same result is mentioned in this question . Unfortunately, Daniel didn't know a reference for this (generalised) result. Can anyone point me to a book/paper/recourse which covers this result? I'd like to see a proof and some maths underlying this intuition. Thank you very much!","This is  a question on contour integration. The particular problem has a (simple) pole on the contour which prohibits a direct application of Cauchy's Residue Theorem. Daniel Fischer commented as follows Not really. [...] if the contour is smooth at the pole, it's as if half of the pole lies inside the contour and half outside. If the contour has a corner at the pole, with (inner) angle , the fraction is , so you get times the residue of the pole instead of times as for singularities properly enclosed by the contour. The same result is mentioned in this question . Unfortunately, Daniel didn't know a reference for this (generalised) result. Can anyone point me to a book/paper/recourse which covers this result? I'd like to see a proof and some maths underlying this intuition. Thank you very much!",\alpha \frac{\alpha}{2\pi} \alpha i 2\pi i,"['integration', 'complex-analysis', 'reference-request', 'contour-integration', 'residue-calculus']"
24,Two Euler sums each containing the reciprocal of the central binomial coefficient,Two Euler sums each containing the reciprocal of the central binomial coefficient,,"Is it possible to find closed-form expressions for the following two Euler sums containing the reciprocal of the central binomial coefficient? $$1. \sum_{n = 0}^\infty \frac{(-1)^n H_n}{(2n + 1) \binom{2n}{n}} \qquad \text{and} \qquad 2. \sum_{n = 0}^\infty \frac{(-1)^n H_{2n + 1}}{(2n + 1) \binom{2n}{n}}$$ Here $H_n$ is the $n$ th harmonic number . The reason I am interested in these two sums is as follows. It arose while considering alternative ways to evaluate the integral given here $$\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \frac{\pi^2}{5 \sqrt{5}}.$$ One way, very similar to the answer given, is to use the dilogarithm machinery and is relatively simple. A second way is as follows: \begin{align} \int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx &= - \int_0^1 \frac{\ln x}{1 + (x - x^2)} \, dx\\ &= - \int_0^1 \ln x \sum_{n = 0}^\infty (-1)^n (x - x^2)^n \, dx \tag1 \\ &= - \sum_{n = 0}^\infty (-1)^n \int_0^1 \ln x \, x^n (1 - x)^n \, dx\tag2. \end{align} In (1) a geometric expansion has been used and is valid since $|x - x^2| < 1$ for $0 < x < 1$ . In (2) the summation and integration has been interchanged and is valid due to the dominated convergence theorem. Consider $$J(a) = \int_0^1 x^a (1 - x)^n \, dx, \quad a > 0.$$ Differentiating with respect to $a$ we have $$J'(a) = \int_0^1 \ln x \, x^a (1 - x)^n \, dx,$$ and we observe that $$J'(n) = \int_0^1 \ln x \, x^n (1 - x)^n \, dx.$$ Now $$J(a) = \operatorname{B} (a + 1, n + 1) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)}.$$ Thus $$J' (a) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)} \left [\psi (a + 1) - \psi (a + n + 2) \right ].$$ Here $\psi (z)$ is the digamma function . Setting $a = n$ then gives $$J'(n) = \frac{1}{(2n + 1) \binom{2n}{n}} \left [\psi (n + 1) - \psi (2n + 2) \right ] = \frac{1}{(2n + 1) \binom{2n}{n}} (H_n - H_{2n + 1}),$$ where we have used the result : $\psi(x) = H_{n - 1} - \gamma$ , with $\gamma$ corresponding the the Euler–Mascheroni constant. So on returning to our integral we see that $$\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1) \binom{2n}{n}} (H_{2n + 1} - H_n) = \frac{\pi^2}{5 \sqrt{5}},$$ and brings me to the two Euler sums. Thoughts on finding the sums One thought is to somehow massage the result $$\sum_{n = 0}^\infty \frac{x^{2n + 2}}{(n + 1)(2n + 1) \binom{2n}{n}} = 4 \arcsin^2 \left (\frac{x}{2} \right ),$$ in conjunction with perhaps the result $$H_n = - n \int_0^1 x^{n - 1} \ln (1 - x) \, dx,$$ into a suitable form but the presence of the alternating term $(-1)^n$ is proving difficult.","Is it possible to find closed-form expressions for the following two Euler sums containing the reciprocal of the central binomial coefficient? Here is the th harmonic number . The reason I am interested in these two sums is as follows. It arose while considering alternative ways to evaluate the integral given here One way, very similar to the answer given, is to use the dilogarithm machinery and is relatively simple. A second way is as follows: In (1) a geometric expansion has been used and is valid since for . In (2) the summation and integration has been interchanged and is valid due to the dominated convergence theorem. Consider Differentiating with respect to we have and we observe that Now Thus Here is the digamma function . Setting then gives where we have used the result : , with corresponding the the Euler–Mascheroni constant. So on returning to our integral we see that and brings me to the two Euler sums. Thoughts on finding the sums One thought is to somehow massage the result in conjunction with perhaps the result into a suitable form but the presence of the alternating term is proving difficult.","1. \sum_{n = 0}^\infty \frac{(-1)^n H_n}{(2n + 1) \binom{2n}{n}} \qquad \text{and} \qquad 2. \sum_{n = 0}^\infty \frac{(-1)^n H_{2n + 1}}{(2n + 1) \binom{2n}{n}} H_n n \int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \frac{\pi^2}{5 \sqrt{5}}. \begin{align}
\int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx &= - \int_0^1 \frac{\ln x}{1 + (x - x^2)} \, dx\\
&= - \int_0^1 \ln x \sum_{n = 0}^\infty (-1)^n (x - x^2)^n \, dx \tag1 \\
&= - \sum_{n = 0}^\infty (-1)^n \int_0^1 \ln x \, x^n (1 - x)^n \, dx\tag2.
\end{align} |x - x^2| < 1 0 < x < 1 J(a) = \int_0^1 x^a (1 - x)^n \, dx, \quad a > 0. a J'(a) = \int_0^1 \ln x \, x^a (1 - x)^n \, dx, J'(n) = \int_0^1 \ln x \, x^n (1 - x)^n \, dx. J(a) = \operatorname{B} (a + 1, n + 1) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)}. J' (a) = \frac{\Gamma (n + 1) \Gamma (a + 1)}{\Gamma (a + n + 2)} \left [\psi (a + 1) - \psi (a + n + 2) \right ]. \psi (z) a = n J'(n) = \frac{1}{(2n + 1) \binom{2n}{n}} \left [\psi (n + 1) - \psi (2n + 2) \right ] = \frac{1}{(2n + 1) \binom{2n}{n}} (H_n - H_{2n + 1}), \psi(x) = H_{n - 1} - \gamma \gamma \int_0^1 \frac{\ln x}{x^2 - x - 1} \, dx = \sum_{n = 0}^\infty \frac{(-1)^n}{(2n + 1) \binom{2n}{n}} (H_{2n + 1} - H_n) = \frac{\pi^2}{5 \sqrt{5}}, \sum_{n = 0}^\infty \frac{x^{2n + 2}}{(n + 1)(2n + 1) \binom{2n}{n}} = 4 \arcsin^2 \left (\frac{x}{2} \right ), H_n = - n \int_0^1 x^{n - 1} \ln (1 - x) \, dx, (-1)^n","['integration', 'definite-integrals', 'improper-integrals', 'harmonic-numbers', 'euler-sums']"
25,The gauss map $ N$ is surjective if the surface is compact,The gauss map  is surjective if the surface is compact, N,"I'm having trouble in solving this (classical - I think) exercise. I have to adjust some detail. Let M be a compact and orientable surface in $\mathbb{R}^3$ with genus $g \gt 0$ and Gaussian curvature K. 1) Let $M_{+} = \{p \in M | K(p) \geq 0\}$. Show that the Gauss map $N: M_{+} \to \mathbb{S}^2$ is surjective. 2) Show that $\int_{M} |K|dA \geq 8\pi$ My attempt is: 1) Pick $\vec{v} \in \mathbb{S}^2$. Define the function $F: M \to \mathbb{R}$ with $F(p) = \vec{p} \cdot \vec{v}$. Since S is compact, F has a max $p_{0}$. Now take $\vec{v_{0}} \in T_{p_{0}}M$. So it exists a curve $\sigma: (-\epsilon, \epsilon) \to M$ with $\sigma(0) = p_{0}$ and $\sigma'(0) = \vec{v_{0}}$. Define the function $f: (-\epsilon, \epsilon) \to \mathbb{R}$ with $f(t) = \sigma(t) \cdot \vec{v}$. It has a max in 0, fo $f'(0) = 0$ and $f''(0) \leq 0$, Now, $f'(0) = \sigma'(0)\cdot\vec{v} = \vec{v_{0}}\cdot\vec{v} = 0$. So $\vec{v} \in (T_{p_{0}}M)^{\bot} = N_{p_{0}}$. So, $N_{p_{0}} = \pm\vec{v}$. (*) Then $f''(0) = \sigma''(0)\cdot\vec{v} = II_{p_{0}}(\vec{v_{0}})\cdot\pm N_{p_{0}}$, that is always negative or positive, so Gaussian curvature is positive. My problem is (*). If I use Jordan-Brouwer theorem, I can choose a priori the normal vector pointing outside and I'm done, it will be positive. But I suppose I can conclude even without this strong theorem. My idea, but probably I'm wrong, is that if $N_{p_{0}} = -\vec{v}$ then $N_{p_{1}} = \vec{v}$ where $p_{1}$ is the minimum of F, but I don't know how to prove it. 2) Here I have simply to prove that $\int_{M_{+}} |K|dA \geq 4\pi$, then it will follow from Gauss-Bonnet. The idea is clear: use the change of variable theorem. $\int_{M_{+}} |K|dA = \int_{N^{-1}(\mathbb{S}^2)}|\det dN|dA \geq \int_{\mathbb{S}^2}dA = 4\pi$ My problem is: can I do that? N will not be in general injective nor a diffeomorphism, so I cannot use the ""real"" change of variable theorem. I put ""$\geq$"" because intuitively I restrict the integral on a domain that makes N bijective, but I don't know if this is correct. Thanks in advance","I'm having trouble in solving this (classical - I think) exercise. I have to adjust some detail. Let M be a compact and orientable surface in $\mathbb{R}^3$ with genus $g \gt 0$ and Gaussian curvature K. 1) Let $M_{+} = \{p \in M | K(p) \geq 0\}$. Show that the Gauss map $N: M_{+} \to \mathbb{S}^2$ is surjective. 2) Show that $\int_{M} |K|dA \geq 8\pi$ My attempt is: 1) Pick $\vec{v} \in \mathbb{S}^2$. Define the function $F: M \to \mathbb{R}$ with $F(p) = \vec{p} \cdot \vec{v}$. Since S is compact, F has a max $p_{0}$. Now take $\vec{v_{0}} \in T_{p_{0}}M$. So it exists a curve $\sigma: (-\epsilon, \epsilon) \to M$ with $\sigma(0) = p_{0}$ and $\sigma'(0) = \vec{v_{0}}$. Define the function $f: (-\epsilon, \epsilon) \to \mathbb{R}$ with $f(t) = \sigma(t) \cdot \vec{v}$. It has a max in 0, fo $f'(0) = 0$ and $f''(0) \leq 0$, Now, $f'(0) = \sigma'(0)\cdot\vec{v} = \vec{v_{0}}\cdot\vec{v} = 0$. So $\vec{v} \in (T_{p_{0}}M)^{\bot} = N_{p_{0}}$. So, $N_{p_{0}} = \pm\vec{v}$. (*) Then $f''(0) = \sigma''(0)\cdot\vec{v} = II_{p_{0}}(\vec{v_{0}})\cdot\pm N_{p_{0}}$, that is always negative or positive, so Gaussian curvature is positive. My problem is (*). If I use Jordan-Brouwer theorem, I can choose a priori the normal vector pointing outside and I'm done, it will be positive. But I suppose I can conclude even without this strong theorem. My idea, but probably I'm wrong, is that if $N_{p_{0}} = -\vec{v}$ then $N_{p_{1}} = \vec{v}$ where $p_{1}$ is the minimum of F, but I don't know how to prove it. 2) Here I have simply to prove that $\int_{M_{+}} |K|dA \geq 4\pi$, then it will follow from Gauss-Bonnet. The idea is clear: use the change of variable theorem. $\int_{M_{+}} |K|dA = \int_{N^{-1}(\mathbb{S}^2)}|\det dN|dA \geq \int_{\mathbb{S}^2}dA = 4\pi$ My problem is: can I do that? N will not be in general injective nor a diffeomorphism, so I cannot use the ""real"" change of variable theorem. I put ""$\geq$"" because intuitively I restrict the integral on a domain that makes N bijective, but I don't know if this is correct. Thanks in advance",,"['integration', 'differential-geometry', 'surfaces', 'curvature']"
26,"Intuition behind Cauchy's theorem, simply-connected domain, and $\oint_C 1/z^2 dz = 0$","Intuition behind Cauchy's theorem, simply-connected domain, and",\oint_C 1/z^2 dz = 0,"I am trying to develop an intuition for the difference between $\oint_C 1/z^2 dz = 0$ and $\oint_C 1/z \,dz = 2\pi i$. The classical proof of Cauchy's integral theorem seems to be to use Green's theorem along with the Cauchy-Riemann equations. This however, requires a simply connected domain, which $1/z^2$ doesn't have. So if $1/z$ and $1/z^2$ both have a pole at $0$, why do they behave differently when integrating around a closed curve? I know how to compute the integrals by parameterizing a circle of radius $1$ around $0$, so this is not what I am looking for. Terence Tao has an interesting explanation which I have a hard time wrapping my head around, so perhaps someone could explain starting from here? Another way to view Cauchy’s theorem is an assertion that every (continuously) differentiable function has an antiderivative. This is true infinitesimally (because $f(z_0)+f'(z_0)(z-z_0)$ has an antiderivative of $f(z_0)(z-z_0) + \frac{1}{2} f'(z_0) (z-z_0)^2)$, and it propagates to be true locally (by summing up and estimating the errors), and then (assuming no topological obstructions, such as poles) it is true globally. In one dimension, the corresponding statement is that every continuous function has an antiderivative (i.e. the fundamental theorem of calculus). In two dimensions, one needs an extra order of control on the function (continuous differentiability rather than just continuity) because one needs one better order of control on the error term to compensate for the extra dimension (dividing a non-infinitesimal two-dimensional region into infinitesimal ones requires many more pieces than for a one-dimensional region, thus allowing many more errors to accumulate.)","I am trying to develop an intuition for the difference between $\oint_C 1/z^2 dz = 0$ and $\oint_C 1/z \,dz = 2\pi i$. The classical proof of Cauchy's integral theorem seems to be to use Green's theorem along with the Cauchy-Riemann equations. This however, requires a simply connected domain, which $1/z^2$ doesn't have. So if $1/z$ and $1/z^2$ both have a pole at $0$, why do they behave differently when integrating around a closed curve? I know how to compute the integrals by parameterizing a circle of radius $1$ around $0$, so this is not what I am looking for. Terence Tao has an interesting explanation which I have a hard time wrapping my head around, so perhaps someone could explain starting from here? Another way to view Cauchy’s theorem is an assertion that every (continuously) differentiable function has an antiderivative. This is true infinitesimally (because $f(z_0)+f'(z_0)(z-z_0)$ has an antiderivative of $f(z_0)(z-z_0) + \frac{1}{2} f'(z_0) (z-z_0)^2)$, and it propagates to be true locally (by summing up and estimating the errors), and then (assuming no topological obstructions, such as poles) it is true globally. In one dimension, the corresponding statement is that every continuous function has an antiderivative (i.e. the fundamental theorem of calculus). In two dimensions, one needs an extra order of control on the function (continuous differentiability rather than just continuity) because one needs one better order of control on the error term to compensate for the extra dimension (dividing a non-infinitesimal two-dimensional region into infinitesimal ones requires many more pieces than for a one-dimensional region, thus allowing many more errors to accumulate.)",,"['integration', 'complex-analysis']"
27,Integration training? [duplicate],Integration training? [duplicate],,"This question already has answers here : Some users are mind bogglingly skilled at integration. How did they get there? (4 answers) Closed 7 years ago . I've been pretty frustrated lately with my poor integration skills. A lot of times I find that in my math or physics classes I understand the concepts behind a question, reduce it to an integral, and then find myself unable to solve it. Yet some people both on this board and at my university are deft hands at solving complicated integrals with a variety of tricks. I'd really like to get better at integrals and start approaching their level. I was hoping that there might be suggestions of workbooks or textbooks that are designed purely on increasing the reader's ability to solve difficult integrals, and also suggestions on a good general philosophy to take to get better at this as well. Also, I'm unsure if this is the wrong place to ask this question. If so, I apologize and I'll remove the question.","This question already has answers here : Some users are mind bogglingly skilled at integration. How did they get there? (4 answers) Closed 7 years ago . I've been pretty frustrated lately with my poor integration skills. A lot of times I find that in my math or physics classes I understand the concepts behind a question, reduce it to an integral, and then find myself unable to solve it. Yet some people both on this board and at my university are deft hands at solving complicated integrals with a variety of tricks. I'd really like to get better at integrals and start approaching their level. I was hoping that there might be suggestions of workbooks or textbooks that are designed purely on increasing the reader's ability to solve difficult integrals, and also suggestions on a good general philosophy to take to get better at this as well. Also, I'm unsure if this is the wrong place to ask this question. If so, I apologize and I'll remove the question.",,"['integration', 'soft-question']"
28,In what sense does analyticity guarantee the following equality?,In what sense does analyticity guarantee the following equality?,,"I was reading a paper$^1$ on particle physics, and at some point it is stated that, provided $f(x)$ is analitic, we have $$ f(x)-f(0)=\frac{x}{\pi}\int_0^\infty \frac{\text{Im}\;f(y)}{y(y-x-i\varepsilon)} \;\mathrm dy\tag{1} $$ where the $i\varepsilon$ is supposed to be taken $\varepsilon\to 0^+$ after integrating. This looks very similar to (what we physicists) call the Kramers-Kronig relations , though I believe in mathematics it is called the Sokhotski-Plemelj theorem : $$ \int_a^b\frac{f(x)}{x-i\varepsilon}\mathrm dx=i\pi f(0)+\mathcal P\!\int_a^b\frac{f(x)}{x}\mathrm dx \tag{2} $$ where $\mathcal P$ means Cauchy principal value. My questions : is the relation $(1)$ true in general? under what circumstances? is it possible to prove $(1)$ from $(2)$? or is $(2)$ irrelevant here? $^1$ The Muon g-2 , by F. Jegerlehner and A. Nyffelerpage, arXiv:0902.3360v1 , page 39.","I was reading a paper$^1$ on particle physics, and at some point it is stated that, provided $f(x)$ is analitic, we have $$ f(x)-f(0)=\frac{x}{\pi}\int_0^\infty \frac{\text{Im}\;f(y)}{y(y-x-i\varepsilon)} \;\mathrm dy\tag{1} $$ where the $i\varepsilon$ is supposed to be taken $\varepsilon\to 0^+$ after integrating. This looks very similar to (what we physicists) call the Kramers-Kronig relations , though I believe in mathematics it is called the Sokhotski-Plemelj theorem : $$ \int_a^b\frac{f(x)}{x-i\varepsilon}\mathrm dx=i\pi f(0)+\mathcal P\!\int_a^b\frac{f(x)}{x}\mathrm dx \tag{2} $$ where $\mathcal P$ means Cauchy principal value. My questions : is the relation $(1)$ true in general? under what circumstances? is it possible to prove $(1)$ from $(2)$? or is $(2)$ irrelevant here? $^1$ The Muon g-2 , by F. Jegerlehner and A. Nyffelerpage, arXiv:0902.3360v1 , page 39.",,"['integration', 'complex-analysis', 'mathematical-physics', 'cauchy-principal-value']"
29,Connection between integral expression and the factorial of infinity,Connection between integral expression and the factorial of infinity,,"Does the fact that $$\int_{-\infty}^{\infty}\exp\left(-\frac{1}{2}x^2\right)\mathrm{d}x=\sqrt{2\pi}$$ Have something to do with the fact that the regularized factorial of infinity is also $\sqrt{2\pi}$? $$\infty!=\prod_{n=1}^\infty n=\exp\left(\sum_{n=1}^\infty\log n\right)=\exp(-\zeta'(0))=\exp\left(\frac{1}{2}\log2\pi\right)=\sqrt{2\pi}$$ If so, what is the connection between them?","Does the fact that $$\int_{-\infty}^{\infty}\exp\left(-\frac{1}{2}x^2\right)\mathrm{d}x=\sqrt{2\pi}$$ Have something to do with the fact that the regularized factorial of infinity is also $\sqrt{2\pi}$? $$\infty!=\prod_{n=1}^\infty n=\exp\left(\sum_{n=1}^\infty\log n\right)=\exp(-\zeta'(0))=\exp\left(\frac{1}{2}\log2\pi\right)=\sqrt{2\pi}$$ If so, what is the connection between them?",,"['integration', 'riemann-zeta', 'divergent-series', 'infinite-product', 'regularization']"
30,Evaluation of $\lim_{n\rightarrow\infty} \int_{-\pi}^\pi x^2 \frac{\sin(2nx)}{\sin x} dx$,Evaluation of,\lim_{n\rightarrow\infty} \int_{-\pi}^\pi x^2 \frac{\sin(2nx)}{\sin x} dx,"I need an approach to analytically evaluating this limit: $$\lim_{n\rightarrow\infty} \int_{-\pi}^\pi x^2 \frac{\sin(2nx)}{\sin x} dx$$ Numerically, I see that the answer is $-\pi^3$.  Similarly, if I replace $x^2$ with $x^4$, I get $-\pi^5$.  I vaguely recall seeing this result obtained analytically and not necessarily using advanced ideas, but I just can't remember any details.  I know the fraction in the integrand relates to Chebyshev polynomials of the second kind.  Thoughts anyone?  Thanks!","I need an approach to analytically evaluating this limit: $$\lim_{n\rightarrow\infty} \int_{-\pi}^\pi x^2 \frac{\sin(2nx)}{\sin x} dx$$ Numerically, I see that the answer is $-\pi^3$.  Similarly, if I replace $x^2$ with $x^4$, I get $-\pi^5$.  I vaguely recall seeing this result obtained analytically and not necessarily using advanced ideas, but I just can't remember any details.  I know the fraction in the integrand relates to Chebyshev polynomials of the second kind.  Thoughts anyone?  Thanks!",,['integration']
31,"An attempt at generalizing a family of integrals $\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\, dx$",An attempt at generalizing a family of integrals,"\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\, dx","Main question $$ \int_0^1{\frac{\sin \left( \pi x \right)}{x^x\left( 1-x \right) ^{1-x}}}\mathrm{d}x $$ This is a famous integral. It can be evaluated by contour integration, and it equals to $\pi/e$ . I tried to generalized it, and I wrote $$ I_{\alpha}=\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x $$ here $\alpha\in\left(0,\infty\right)$ . By substituting $x=\frac{\alpha}{e^t+1}$ , $I_{\alpha}$ becomes $$ \alpha ^{1-\alpha}\int_{-\infty}^{\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\sin \left( \frac{\alpha \pi}{e^t+1} \right) \exp \left( \frac{\alpha t}{e^t+1} \right)}\mathrm{d}x $$ Or equivalently $$ \alpha ^{1-\alpha}\int_{\infty}^{-\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\sin \left( \frac{-\alpha \pi}{e^t+1} \right) \exp \left( \frac{\alpha t}{e^t+1} \right)}\mathrm{d}x $$ This implies \begin{align*} I_{\alpha}&=\alpha ^{1-\alpha}\Im \left\{ \int_{-\infty}^{\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\exp \left( \frac{\alpha \left( t+i\pi \right)}{e^t+1} \right)}\mathrm{d}x \right\}  \\& =\alpha ^{1-\alpha}\Im \left\{ \int_{\infty}^{-\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\exp \left( \frac{\alpha \left( t-i\pi \right)}{e^t+1} \right)}\mathrm{d}x \right\}  \end{align*} Then I tried to apply contour integration here. $$ f\left( z \right) =\frac{e^{z\left( 1-\alpha \right)}}{\left( 1-e^z \right) ^{2-\alpha}}\exp \left( \frac{\alpha z}{1-e^z} \right)  $$ The contour I used I integrate this contour clockwise. By residue theorem $$ \oint_C{f\left( z \right) \mathrm{d}z}=\int_{\psi _-}{+\int_{\psi _+}{+}\int_{\phi _-}{+}\int_{\phi _+}{f\left( z \right) \mathrm{d}z}}=2\pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right]  $$ The vertical parts actually vanish when $R$ approaches infinity. As for the horizontal part, since $$ f\left( x+i\pi \right) =\frac{e^{x\left( 1-\alpha \right)}e^{i\pi \left( 1-\alpha \right)}}{\left( 1+e^x \right) ^{2-\alpha}}\exp \left( \frac{x+i\pi}{1+e^x} \right)  \\ f\left( x-i\pi \right) =\frac{e^{x\left( 1-\alpha \right)}e^{i\pi \left( \alpha -1 \right)}}{\left( 1+e^x \right) ^{2-\alpha}}\exp \left( \frac{x-i\pi}{1+e^x} \right)  $$ therefore, by adding the horizontal part together, there is $$ \Im \left\{\int_{\psi _-}{+\int_{\psi _+}{f\left( z \right) \mathrm{d}z}}\right\} = \frac{2\cos \left( \pi \left( \alpha -1 \right) \right)}{\alpha ^{1-\alpha}} I_{\alpha}  $$ So I have $$ I_{\alpha}=\alpha ^{1-\alpha}\Im \left\{ \frac{\pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right]}{\cos \left( \pi \left( \alpha -1 \right) \right)} \right\}  $$ Then I was stuck. How do I calculate this residue? It's somehow very difficult for me... Have I done anything worng? Addendum 1 There are few questions stemmed form this question. Such as $$ J_{\alpha}=\int_0^{\alpha}{\frac{\sin \left( \pi x/\alpha \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x \\ K_{\alpha ,\beta}=\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^{x+\beta}\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x \\ L_{\alpha ,\beta}=\int_0^{\alpha}{\frac{\sin \left( \pi x/\alpha \right)}{x^{x+\beta}\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x $$ which I doubt a closed form even exist. Another interesting thing, it seems that $$ K_{1,1}=\int_0^1{\frac{\sin \left( \pi x \right)}{x^{1+x}\left( 1-x \right) ^{1-x}}}\mathrm{d}x=\pi  $$ Addendum 2 For $\alpha=n\in\mathbb{N}$ , $e^{i\pi\left(1-\alpha\right)}$ and $e^{i\pi\left(\alpha-1\right)}$ actually evaluates in the same sign so the expression simplifies to $$I_n=n ^{1-n}\Im \left\{ \pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right]\right\} $$ and this actually evaluates to $$I_n=\frac{\pi}{e}\delta_{n,1}$$ Given by what desmos graphed this seems to be truth Plus, I was noted by the comment that my previous method has a branch cut problem. So I might want to modify contour $C$ a little bit to exclude the branch cut. I took a look at $f(z)$ and it seems that there're branch points in $i2\mathbb{Z}\pi$ . My thought currently is to aim the brach of the ones bigger than $0$ upward and the rest of it downward and make a little ""key hole branch"" from below. Don't know if that works tho.","Main question This is a famous integral. It can be evaluated by contour integration, and it equals to . I tried to generalized it, and I wrote here . By substituting , becomes Or equivalently This implies Then I tried to apply contour integration here. The contour I used I integrate this contour clockwise. By residue theorem The vertical parts actually vanish when approaches infinity. As for the horizontal part, since therefore, by adding the horizontal part together, there is So I have Then I was stuck. How do I calculate this residue? It's somehow very difficult for me... Have I done anything worng? Addendum 1 There are few questions stemmed form this question. Such as which I doubt a closed form even exist. Another interesting thing, it seems that Addendum 2 For , and actually evaluates in the same sign so the expression simplifies to and this actually evaluates to Given by what desmos graphed this seems to be truth Plus, I was noted by the comment that my previous method has a branch cut problem. So I might want to modify contour a little bit to exclude the branch cut. I took a look at and it seems that there're branch points in . My thought currently is to aim the brach of the ones bigger than upward and the rest of it downward and make a little ""key hole branch"" from below. Don't know if that works tho.","
\int_0^1{\frac{\sin \left( \pi x \right)}{x^x\left( 1-x \right) ^{1-x}}}\mathrm{d}x
 \pi/e 
I_{\alpha}=\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x
 \alpha\in\left(0,\infty\right) x=\frac{\alpha}{e^t+1} I_{\alpha} 
\alpha ^{1-\alpha}\int_{-\infty}^{\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\sin \left( \frac{\alpha \pi}{e^t+1} \right) \exp \left( \frac{\alpha t}{e^t+1} \right)}\mathrm{d}x
 
\alpha ^{1-\alpha}\int_{\infty}^{-\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\sin \left( \frac{-\alpha \pi}{e^t+1} \right) \exp \left( \frac{\alpha t}{e^t+1} \right)}\mathrm{d}x
 \begin{align*}
I_{\alpha}&=\alpha ^{1-\alpha}\Im \left\{ \int_{-\infty}^{\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\exp \left( \frac{\alpha \left( t+i\pi \right)}{e^t+1} \right)}\mathrm{d}x \right\} 
\\&
=\alpha ^{1-\alpha}\Im \left\{ \int_{\infty}^{-\infty}{\frac{e^{t\left( 1-\alpha \right)}}{\left( 1+e^t \right) ^{2-\alpha}}\exp \left( \frac{\alpha \left( t-i\pi \right)}{e^t+1} \right)}\mathrm{d}x \right\} 
\end{align*} 
f\left( z \right) =\frac{e^{z\left( 1-\alpha \right)}}{\left( 1-e^z \right) ^{2-\alpha}}\exp \left( \frac{\alpha z}{1-e^z} \right) 
 
\oint_C{f\left( z \right) \mathrm{d}z}=\int_{\psi _-}{+\int_{\psi _+}{+}\int_{\phi _-}{+}\int_{\phi _+}{f\left( z \right) \mathrm{d}z}}=2\pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right] 
 R 
f\left( x+i\pi \right) =\frac{e^{x\left( 1-\alpha \right)}e^{i\pi \left( 1-\alpha \right)}}{\left( 1+e^x \right) ^{2-\alpha}}\exp \left( \frac{x+i\pi}{1+e^x} \right) 
\\
f\left( x-i\pi \right) =\frac{e^{x\left( 1-\alpha \right)}e^{i\pi \left( \alpha -1 \right)}}{\left( 1+e^x \right) ^{2-\alpha}}\exp \left( \frac{x-i\pi}{1+e^x} \right) 
 
\Im \left\{\int_{\psi _-}{+\int_{\psi _+}{f\left( z \right) \mathrm{d}z}}\right\} = \frac{2\cos \left( \pi \left( \alpha -1 \right) \right)}{\alpha ^{1-\alpha}} I_{\alpha} 
 
I_{\alpha}=\alpha ^{1-\alpha}\Im \left\{ \frac{\pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right]}{\cos \left( \pi \left( \alpha -1 \right) \right)} \right\} 
 
J_{\alpha}=\int_0^{\alpha}{\frac{\sin \left( \pi x/\alpha \right)}{x^x\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x
\\
K_{\alpha ,\beta}=\int_0^{\alpha}{\frac{\sin \left( \pi x \right)}{x^{x+\beta}\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x
\\
L_{\alpha ,\beta}=\int_0^{\alpha}{\frac{\sin \left( \pi x/\alpha \right)}{x^{x+\beta}\left( \alpha -x \right) ^{\alpha -x}}}\mathrm{d}x
 
K_{1,1}=\int_0^1{\frac{\sin \left( \pi x \right)}{x^{1+x}\left( 1-x \right) ^{1-x}}}\mathrm{d}x=\pi 
 \alpha=n\in\mathbb{N} e^{i\pi\left(1-\alpha\right)} e^{i\pi\left(\alpha-1\right)} I_n=n ^{1-n}\Im \left\{ \pi i\mathrm{Res}\left[ f\left( z \right) ,0 \right]\right\}  I_n=\frac{\pi}{e}\delta_{n,1} C f(z) i2\mathbb{Z}\pi 0","['integration', 'complex-analysis', 'definite-integrals', 'contour-integration']"
32,Conditions for the summation theorem for functions with infinitely many poles,Conditions for the summation theorem for functions with infinitely many poles,,"It is widely know the summation theorem via residues: Suppose $f(z)$ analytic on $\mathbb{C}$ except for a finite number of poles. And let $f(z)$ be such that along the path $C_{N}$ , the square with vertices at $\left(N+\frac{1}{2}\right)(-1+i), \left(N+\frac{1}{2}\right)(-1-i), \left(N+\frac{1}{2}\right)(1-i), \left(N+\frac{1}{2}\right)(1+i)$ . $$|f(z)|\leq\frac{M}{|z|^k}$$ where $k>1$ and $M$ are constants independent of $N$ we have $$\sum_{n=-\infty}^{\infty} f(n) = -\sum \left\{\textrm{ residues of } \pi\cot(\pi z)f(z) \textrm{ at the poles of } f(z) \right\}$$ We can extend this theorem for functions with infinitely many poles: Consider the path $C_{N}$ . Let $f(z)$ with infinitely many poles with the conditions: $$|f(z) |\leq \frac{M}{|z|^{k}} \tag{*}$$ along the path $C_{N}$ where $k>1$ and $M$ are constants independent of $N$ and $$\lim_{N \to \infty} \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right)<\infty$$ where $$A_{N} = \left\{ \textrm{poles of } f(z) \textrm{ inside } C_{N} \right\}$$ then: $$\sum_{n=-\infty}^{\infty} f(n) = \lim_{N \to \infty} \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right)$$ the set of $C_{N}$ is called ""Big squares"". Can we weaken the condition $(*)$ ? For example, $f(z)$ to be $\mathcal{O}(z^{-2})$ at infinity? $$|f(z)| \leq \frac{M}{|z|^{2}} \quad z \to \infty$$ or there are even weaker conditions? What is a good reference for the summation theorem for functions with infinitely many poles? Here is my try for question 1: Given that $f(z)$ is $\mathcal{O}(z^{-2})$ : $\exists \delta,M>0$ so that whenever $|z|>\delta$ $$|f(z)|\leq\frac{M}{|z|^2}$$ If we choose our first square $C_{N}$ for $N$ sufficiently large such that $|z|>\delta$ then $$\oint_{C_{N}} \pi \cot(\pi z)f(z) dz = \sum_{n=-N}^{N} f(n) + \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right) $$ We just have to prove that $$\oint_{C_{N}} \pi \cot(\pi z)f(z) dz  \to 0 \quad N \to \infty$$ But it can be proven that $$|\cot(\pi z)|$$ is bounded in $C_{N}$ : $$|\cot(\pi z)|\leq A$$ Then $$\left| \oint_{C_{N}} \pi \cot(\pi z) f(z) dz\right| \leq \frac{\pi A M}{N^2}(8N+4)$$ since the lenght of the path $C_{N}$ is $8N+4$ . Hence, the integral vanishes as $N \to \infty$ .","It is widely know the summation theorem via residues: Suppose analytic on except for a finite number of poles. And let be such that along the path , the square with vertices at . where and are constants independent of we have We can extend this theorem for functions with infinitely many poles: Consider the path . Let with infinitely many poles with the conditions: along the path where and are constants independent of and where then: the set of is called ""Big squares"". Can we weaken the condition ? For example, to be at infinity? or there are even weaker conditions? What is a good reference for the summation theorem for functions with infinitely many poles? Here is my try for question 1: Given that is : so that whenever If we choose our first square for sufficiently large such that then We just have to prove that But it can be proven that is bounded in : Then since the lenght of the path is . Hence, the integral vanishes as .","f(z) \mathbb{C} f(z) C_{N} \left(N+\frac{1}{2}\right)(-1+i), \left(N+\frac{1}{2}\right)(-1-i), \left(N+\frac{1}{2}\right)(1-i), \left(N+\frac{1}{2}\right)(1+i) |f(z)|\leq\frac{M}{|z|^k} k>1 M N \sum_{n=-\infty}^{\infty} f(n) = -\sum \left\{\textrm{ residues of } \pi\cot(\pi z)f(z) \textrm{ at the poles of } f(z) \right\} C_{N} f(z) |f(z) |\leq \frac{M}{|z|^{k}} \tag{*} C_{N} k>1 M N \lim_{N \to \infty} \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right)<\infty A_{N} = \left\{ \textrm{poles of } f(z) \textrm{ inside } C_{N} \right\} \sum_{n=-\infty}^{\infty} f(n) = \lim_{N \to \infty} \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right) C_{N} (*) f(z) \mathcal{O}(z^{-2}) |f(z)| \leq \frac{M}{|z|^{2}} \quad z \to \infty f(z) \mathcal{O}(z^{-2}) \exists \delta,M>0 |z|>\delta |f(z)|\leq\frac{M}{|z|^2} C_{N} N |z|>\delta \oint_{C_{N}} \pi \cot(\pi z)f(z) dz = \sum_{n=-N}^{N} f(n) + \sum_{a\in A_{N}} \operatorname{Res}\left(\pi\cot(\pi z)f(z),a\right)
 \oint_{C_{N}} \pi \cot(\pi z)f(z) dz  \to 0 \quad N \to \infty |\cot(\pi z)| C_{N} |\cot(\pi z)|\leq A \left| \oint_{C_{N}} \pi \cot(\pi z) f(z) dz\right| \leq \frac{\pi A M}{N^2}(8N+4) C_{N} 8N+4 N \to \infty","['integration', 'sequences-and-series', 'complex-analysis', 'residue-calculus']"
33,Is there a formula for $\int_0^\pi\frac{\sin(nx)}{\cos(\theta)-cos(x)}dx$?,Is there a formula for ?,\int_0^\pi\frac{\sin(nx)}{\cos(\theta)-cos(x)}dx,"I'm working on a school project about the aerodynamics of an helicopter blade. I'm trying to adapt my aerodynamics class ( centered around planes wings mostly ) to this case. In our class, we used what we called the integrals of Glauert and more specifically, this integral : $$ \int_{0}^{\pi}\frac{\cos\left(nx\right)} {\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x = -\pi\,\frac{\sin\left(n\theta\right)}{\sin\left(\theta\right)} $$ In the helicopter case, I need to evaluate a similar integral but with $\sin\left(nx\right)$ instead of $\cos\left(nx\right)$ . I found a beautiful proof of the first result in the book Inside Interesting Integrals by Paul Nahin ( page $60$ ) which uses recursivity. I tried to adapt it to the other integral using the formula $$\sin\left(\left(n + 1\right)x\right) + \sin\left(\left(n - 1\right)x\right) = 2\sin\left(nx\right)\cos\left(x\right)$$ $$ \mbox{Calling}\quad I_{n} = \int_0^\pi\frac{\sin\left(nx\right)}{\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x, $$ I find that $$ I_{n+1} - 2\cos\left(\theta\right)I_{n} + I_{n - 1} = \int_{0}^{\pi}2\sin\left(nx\right)\,{\rm d}x $$ but I then have a problem to solve the recursive equation be the result is $0$ or $\frac{4}{n}$ depending on the parity of n. I decoupled the system to get two recursive equations for the different parities : For $a_n=I_{2n}$ , I get $a_{n+1}-2\cos(2\theta)a_n+a_{n-1}=8\cos\theta(\frac{1}{2n+1}+\frac{1}{2n-1}$ ) And for $b_n=I_{2n+1}$ , I get $b_n-2\cos(2\theta)b_{n-1}+b_{n-2}=\frac{8}{2n-1}\cos(\theta)$ I entered these formula on Wolfram Alpha and got some really ugly results. I was thus wondering if a more simple formula could exist for my integral. I also quickly looked at the wikipedia proof which uses residual theorems but I got lost quite fast... Do you know some other way to evaluate this integral or maybe if it's possible to solve the recursive equations to get to a simpler result than the one from Wolfram ? Thank you very much !","I'm working on a school project about the aerodynamics of an helicopter blade. I'm trying to adapt my aerodynamics class ( centered around planes wings mostly ) to this case. In our class, we used what we called the integrals of Glauert and more specifically, this integral : In the helicopter case, I need to evaluate a similar integral but with instead of . I found a beautiful proof of the first result in the book Inside Interesting Integrals by Paul Nahin ( page ) which uses recursivity. I tried to adapt it to the other integral using the formula I find that but I then have a problem to solve the recursive equation be the result is or depending on the parity of n. I decoupled the system to get two recursive equations for the different parities : For , I get ) And for , I get I entered these formula on Wolfram Alpha and got some really ugly results. I was thus wondering if a more simple formula could exist for my integral. I also quickly looked at the wikipedia proof which uses residual theorems but I got lost quite fast... Do you know some other way to evaluate this integral or maybe if it's possible to solve the recursive equations to get to a simpler result than the one from Wolfram ? Thank you very much !","
\int_{0}^{\pi}\frac{\cos\left(nx\right)}
{\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x = -\pi\,\frac{\sin\left(n\theta\right)}{\sin\left(\theta\right)}
 \sin\left(nx\right) \cos\left(nx\right) 60 \sin\left(\left(n + 1\right)x\right) +
\sin\left(\left(n - 1\right)x\right)
= 2\sin\left(nx\right)\cos\left(x\right) 
\mbox{Calling}\quad
I_{n} =
\int_0^\pi\frac{\sin\left(nx\right)}{\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x,
 
I_{n+1} - 2\cos\left(\theta\right)I_{n} +
I_{n - 1} = \int_{0}^{\pi}2\sin\left(nx\right)\,{\rm d}x
 0 \frac{4}{n} a_n=I_{2n} a_{n+1}-2\cos(2\theta)a_n+a_{n-1}=8\cos\theta(\frac{1}{2n+1}+\frac{1}{2n-1} b_n=I_{2n+1} b_n-2\cos(2\theta)b_{n-1}+b_{n-2}=\frac{8}{2n-1}\cos(\theta)","['integration', 'recurrence-relations', 'physics', 'cauchy-principal-value']"
34,How to show that the integral $\frac{1}{2\pi i} \int_{\gamma} \frac{dz}{z - a}$ is integer-valued when the curve $\gamma$ is not piecewise smooth?,How to show that the integral  is integer-valued when the curve  is not piecewise smooth?,\frac{1}{2\pi i} \int_{\gamma} \frac{dz}{z - a} \gamma,"In Conway's Functions of One Complex Variable , there is a proposition which is as follows: 5.1 Proposition. If $\gamma\colon [0,1] \to \mathbb{C}$ is a closed rectifiable curve and $a \notin \{\gamma\}$ then    $$\frac{1}{2\pi i} \int_{\gamma}\frac{dz}{z - a}$$   is an integer. Proof. This is only proved under the hypothesis that $\gamma$ is differentiable. For those unfamiliar with Conway's book, $\{\gamma\}$ is his notation for the image set of the curve $\gamma$ and differentiable (when referring to curves) means $\gamma'$ exists and is continuous. I know the latter as smooth. The proposition is meant to motivate his definition of the winding number. From Conway's proof, it's trivial to generalize to closed piecewise smooth curves. This leads me to my first question: how can one prove the proposition in its full generality for closed rectifiable curves? In general, the integral is a Riemann-Stieltjes integral $$\frac{1}{2\pi i} \int_{0}^{1}\frac{1}{\gamma(t) - a}\,d\gamma(t)$$ whose existence follows from the fact that $1/(\gamma(t) - a)$ is continuous and $\gamma(t)$ is of bounded variation. Seeing as how the winding number about $a$ can be defined using a continuous choice of argument for all closed curves not passing through $a$, my second question is: if the hypothesis is relaxed to include all closed curves, does the integral necessarily exist and is it still integer-valued?","In Conway's Functions of One Complex Variable , there is a proposition which is as follows: 5.1 Proposition. If $\gamma\colon [0,1] \to \mathbb{C}$ is a closed rectifiable curve and $a \notin \{\gamma\}$ then    $$\frac{1}{2\pi i} \int_{\gamma}\frac{dz}{z - a}$$   is an integer. Proof. This is only proved under the hypothesis that $\gamma$ is differentiable. For those unfamiliar with Conway's book, $\{\gamma\}$ is his notation for the image set of the curve $\gamma$ and differentiable (when referring to curves) means $\gamma'$ exists and is continuous. I know the latter as smooth. The proposition is meant to motivate his definition of the winding number. From Conway's proof, it's trivial to generalize to closed piecewise smooth curves. This leads me to my first question: how can one prove the proposition in its full generality for closed rectifiable curves? In general, the integral is a Riemann-Stieltjes integral $$\frac{1}{2\pi i} \int_{0}^{1}\frac{1}{\gamma(t) - a}\,d\gamma(t)$$ whose existence follows from the fact that $1/(\gamma(t) - a)$ is continuous and $\gamma(t)$ is of bounded variation. Seeing as how the winding number about $a$ can be defined using a continuous choice of argument for all closed curves not passing through $a$, my second question is: if the hypothesis is relaxed to include all closed curves, does the integral necessarily exist and is it still integer-valued?",,"['integration', 'complex-analysis', 'winding-number']"
35,Can you integrate on a scheme?,Can you integrate on a scheme?,,"As the question suggests, can you integrate on a scheme? How? I don't even know if this is even a well-posed question...","As the question suggests, can you integrate on a scheme? How? I don't even know if this is even a well-posed question...",,['integration']
36,Computing the Gaussian integral with step functions,Computing the Gaussian integral with step functions,,"Say, we are interested in deriving $$\int_{-\infty}^{\infty}e^{-x^2}=\sqrt{\pi}\tag{1}$$ There are many well known ways to do it , for example: by polar coordinates via the gamma function, etc. After coming across this limit $$\lim\limits_{n\to\infty} \frac{\sqrt{\pi n}}{2^{2n}}  \binom {2n} {n+\lfloor x\sqrt{n} \rfloor} = e^{-x^2}\tag{2}$$ I wonder how can we derive $(1)$ by using $(2)$ as an approximation via step functions. Here is a picture of $n=4$:","Say, we are interested in deriving $$\int_{-\infty}^{\infty}e^{-x^2}=\sqrt{\pi}\tag{1}$$ There are many well known ways to do it , for example: by polar coordinates via the gamma function, etc. After coming across this limit $$\lim\limits_{n\to\infty} \frac{\sqrt{\pi n}}{2^{2n}}  \binom {2n} {n+\lfloor x\sqrt{n} \rfloor} = e^{-x^2}\tag{2}$$ I wonder how can we derive $(1)$ by using $(2)$ as an approximation via step functions. Here is a picture of $n=4$:",,"['integration', 'limits', 'improper-integrals', 'normal-distribution']"
37,Computing $ \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2}$,Computing, \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2},I would like to show that $$ \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2}=\frac{\pi^2}{15}-\ln^2(\phi) $$ where $$ \phi = \frac{1+\sqrt{5}}{2}$$ How can this result be derived from the integral representation $$  \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2} = -\int_0^{1/\phi^2}\frac{\ln(1-x)}{x} \mathrm dx $$ ?,I would like to show that $$ \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2}=\frac{\pi^2}{15}-\ln^2(\phi) $$ where $$ \phi = \frac{1+\sqrt{5}}{2}$$ How can this result be derived from the integral representation $$  \sum_{n=1}^{\infty} \frac{1}{\phi^{2n}n^2} = -\int_0^{1/\phi^2}\frac{\ln(1-x)}{x} \mathrm dx $$ ?,,"['sequences-and-series', 'integration']"
38,Gaussian matrix integration,Gaussian matrix integration,,"Consider a random hermitian matrix $B$ of size $N\times N$ with Gaussian probability measure given by $$ dx(B) = e^{-\frac{N}{2}Tr(B^2)}\prod_{i=1}^N dB_{ii} \prod_{i<j} d\Re(dB_{ij})d\Im(dB_{ij}) $$ where $B_{ii}, \Re(B_{ij}), \Im(B_{ij})$ are independent Gaussian random variables. How can we prove the following integral?  I am looking for a detailed proof that involves reducing it to the usual Gaussian Matrix integral that we can do, thanks. $$ \int dx(B) = 2^N \left(\frac{\pi }{N}\right)^{\frac{N^2}{2}} $$","Consider a random hermitian matrix of size with Gaussian probability measure given by where are independent Gaussian random variables. How can we prove the following integral?  I am looking for a detailed proof that involves reducing it to the usual Gaussian Matrix integral that we can do, thanks.","B N\times N 
dx(B) = e^{-\frac{N}{2}Tr(B^2)}\prod_{i=1}^N dB_{ii} \prod_{i<j} d\Re(dB_{ij})d\Im(dB_{ij})
 B_{ii}, \Re(B_{ij}), \Im(B_{ij}) 
\int dx(B) = 2^N \left(\frac{\pi }{N}\right)^{\frac{N^2}{2}}
","['integration', 'matrices', 'complex-analysis', 'measure-theory', 'gaussian-integral']"
39,Why is $\int \frac{f'(x)}{f(x)}=\ln |f(x)|$ ignored in differential equations?,Why is  ignored in differential equations?,\int \frac{f'(x)}{f(x)}=\ln |f(x)|,"I've noticed that whenever $\int \frac{f'(x)}{f(x)}$ comes up in a differential equation the answer is always given as $\ln f(x)$ rather than $\ln |f(x)|$ as I was taught it should be. Is it because of the arbitrary constant? In other words, since $$\int \frac{f'(x)}{f(x)}=\ln |f(x)|+\ln A$$ for some constant $A$, then the answer is $\ln A|f(x)|$ and because $A$ can be positive or negative it follows that there is no point including the absolute signs? Hence the answer is given as $\ln f(x)+C$ for some constant $C$ rather than $\ln |f(x)|+C$. Is this why?","I've noticed that whenever $\int \frac{f'(x)}{f(x)}$ comes up in a differential equation the answer is always given as $\ln f(x)$ rather than $\ln |f(x)|$ as I was taught it should be. Is it because of the arbitrary constant? In other words, since $$\int \frac{f'(x)}{f(x)}=\ln |f(x)|+\ln A$$ for some constant $A$, then the answer is $\ln A|f(x)|$ and because $A$ can be positive or negative it follows that there is no point including the absolute signs? Hence the answer is given as $\ln f(x)+C$ for some constant $C$ rather than $\ln |f(x)|+C$. Is this why?",,"['integration', 'ordinary-differential-equations', 'indefinite-integrals']"
40,"Help in calculating the following integral $\int_0^{2\pi}\! \frac{(1+2\cos x)^n \cos (nx)}{3+2\cos x} \, \mathrm{d}x. $",Help in calculating the following integral,"\int_0^{2\pi}\! \frac{(1+2\cos x)^n \cos (nx)}{3+2\cos x} \, \mathrm{d}x. ","I was asked to calculate this: $$\int_0^{2\pi}\! \frac{(1+2\cos x)^n \cos (nx)}{3+2\cos x} \, \mathrm{d}x. $$ My idea was to change the integration limits to $|z|=1$ in the complex plane and to use the residue theorem: $$\int\limits_{|z|=1}\!\frac{(1+z+z^{-1})^n\frac{1}{2}(z^n+z^{-n})}{3+z+z^{-1}} \,\frac{\mathrm{d}z}{iz} = -\frac{i}{2} \int\limits_{|z|=1}\!\frac{(z^2+z+1)^n(z^{2n}+1)}{z^{2n}(z^2+3z+1)} \,\mathrm{d}z$$ but this requires me to calculate $$\lim_{z \to 0}\frac{d^{2n-1}}{dz^{2n-1}}\left[\frac{(z^2+z+1)^n(z^{2n}+1)}{z^2+3z+1}\right]$$ in order to get the residue at $z=0$. Is there any other way of doing this?","I was asked to calculate this: $$\int_0^{2\pi}\! \frac{(1+2\cos x)^n \cos (nx)}{3+2\cos x} \, \mathrm{d}x. $$ My idea was to change the integration limits to $|z|=1$ in the complex plane and to use the residue theorem: $$\int\limits_{|z|=1}\!\frac{(1+z+z^{-1})^n\frac{1}{2}(z^n+z^{-n})}{3+z+z^{-1}} \,\frac{\mathrm{d}z}{iz} = -\frac{i}{2} \int\limits_{|z|=1}\!\frac{(z^2+z+1)^n(z^{2n}+1)}{z^{2n}(z^2+3z+1)} \,\mathrm{d}z$$ but this requires me to calculate $$\lim_{z \to 0}\frac{d^{2n-1}}{dz^{2n-1}}\left[\frac{(z^2+z+1)^n(z^{2n}+1)}{z^2+3z+1}\right]$$ in order to get the residue at $z=0$. Is there any other way of doing this?",,"['complex-analysis', 'integration', 'residue-calculus']"
41,Evaluate $\int_{0}^{1} \operatorname{Li}_3\left [ \left ( \frac{x(1-x)}{1+x} \right ) ^2 \right ] \text{d}x$,Evaluate,\int_{0}^{1} \operatorname{Li}_3\left [ \left ( \frac{x(1-x)}{1+x} \right ) ^2 \right ] \text{d}x,"Possibly evaluate the integral? $$ \int_{0}^{1} \operatorname{Li}_3\left [  \left (  \frac{x(1-x)}{1+x} \right ) ^2 \right ]  \text{d}x. $$ I came across this when playing with Legendre polynomials, and I am curious about the existence of this closed-form of the simple-looking integral. The relevant functional equations are much easier to arrive at, but leaving a massive calculation to reform the integral, out of my reach. I am appreciated for your help. I somehow believe its existence, as I have derived the following expression: Denoting $\chi_2(x)=\sum_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)^2}$ and defining $$ f(x)=\operatorname{Li}_3(x^2) +4\ln\left ( 1-x^2 \right )  +8\left ( \frac{\text{artanh}(x)+\chi_2(x)}{x} -1 \right ), $$ one have $$ \int_{0}^{1} f\left ( \frac{x(1-x)}{1+x}  \right ) \text{d}x =\frac{21}{2}\zeta(3)-4\ln(2)^2-16+\pi^2-\frac{2\pi^2}3\ln(2). $$ The idea is to find a function, whose Legendre-Fourier coefficients consisting of $$ \int_{0}^{1} \left ( \frac{x\left ( 1-x \right ) }{1+x}  \right )^n \text{d} x, $$ and therefore it's an obvious task.","Possibly evaluate the integral? I came across this when playing with Legendre polynomials, and I am curious about the existence of this closed-form of the simple-looking integral. The relevant functional equations are much easier to arrive at, but leaving a massive calculation to reform the integral, out of my reach. I am appreciated for your help. I somehow believe its existence, as I have derived the following expression: Denoting and defining one have The idea is to find a function, whose Legendre-Fourier coefficients consisting of and therefore it's an obvious task.","
\int_{0}^{1} \operatorname{Li}_3\left [ 
\left (  \frac{x(1-x)}{1+x} \right ) ^2 \right ] 
\text{d}x.
 \chi_2(x)=\sum_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)^2} 
f(x)=\operatorname{Li}_3(x^2)
+4\ln\left ( 1-x^2 \right ) 
+8\left ( \frac{\text{artanh}(x)+\chi_2(x)}{x} -1 \right ),
 
\int_{0}^{1} f\left ( \frac{x(1-x)}{1+x}  \right ) \text{d}x
=\frac{21}{2}\zeta(3)-4\ln(2)^2-16+\pi^2-\frac{2\pi^2}3\ln(2).
 
\int_{0}^{1} \left ( \frac{x\left ( 1-x \right ) }{1+x}  \right )^n
\text{d} x,
","['integration', 'definite-integrals', 'legendre-polynomials', 'polylogarithm']"
42,When does the infinite recursive fraction integral $\int_a^b \frac{g(x_1)dx_1}{\int_a^{x_1}\frac{g(x_2)dx_2}{\int_a^{x_2}\cdots}}$ converge?,When does the infinite recursive fraction integral  converge?,\int_a^b \frac{g(x_1)dx_1}{\int_a^{x_1}\frac{g(x_2)dx_2}{\int_a^{x_2}\cdots}},"I write problems for integration bees, and I am considering problems of the form in the title, i.e. $$\int_a^b \frac{g(x_1)dx_1}{\int_a^{x_1}\frac{g(x_2)dx_2}{\int_a^{x_2}\frac{g(x_3)dx_3}{\int_a^{x_3}\cdots}}}$$ where $g$ is of the special form $$\begin{cases}g(x) = f(x)f'(x) \\ f(a) = 0 \\ f(x)\geq 0\end{cases}$$ Or more formally, consider the sequence $$F_{n+1}(x) = \int_a^x \frac{g(t)dt}{F_n(t)} \hspace{20 pt}F_0(t) =  1$$ If $g$ is of the special form above, in the limit we get $$F'(x) = \frac{f(x)f'(x)}{F(x)} \implies F(x) = |f(x)|$$ by L'Hopital's rule. I think a necessary condition for convergence might be $f'(x) \geq 0$ as taking $f(x) = \sin x$ it looks like the sequence diverges if $b > \frac{\pi}{2}$ when $a=0$ , but I am not sure if this is a sufficient condition. This gives a solution $$\int_0^{\frac{\pi}{2}}\frac{\sin x_1\cos x_1\:dx_1}{\int_0^{x_1}\frac{\sin x_2 \cos x_2 \:dx_2}{\int_0^{x_3}\frac{\sin x_3 \cos x_3 \:dx_3}{\int_0^{x_3}\cdots}}} = 1$$ $\textbf{My Question}$ : Is $f'(x)\geq 0$ is a sufficient (or even necessary) condition for convergence? If not, what other conditions would I need on the kernel $g$ to get limit convergence? Thanks in advance for your help!","I write problems for integration bees, and I am considering problems of the form in the title, i.e. where is of the special form Or more formally, consider the sequence If is of the special form above, in the limit we get by L'Hopital's rule. I think a necessary condition for convergence might be as taking it looks like the sequence diverges if when , but I am not sure if this is a sufficient condition. This gives a solution : Is is a sufficient (or even necessary) condition for convergence? If not, what other conditions would I need on the kernel to get limit convergence? Thanks in advance for your help!",\int_a^b \frac{g(x_1)dx_1}{\int_a^{x_1}\frac{g(x_2)dx_2}{\int_a^{x_2}\frac{g(x_3)dx_3}{\int_a^{x_3}\cdots}}} g \begin{cases}g(x) = f(x)f'(x) \\ f(a) = 0 \\ f(x)\geq 0\end{cases} F_{n+1}(x) = \int_a^x \frac{g(t)dt}{F_n(t)} \hspace{20 pt}F_0(t) =  1 g F'(x) = \frac{f(x)f'(x)}{F(x)} \implies F(x) = |f(x)| f'(x) \geq 0 f(x) = \sin x b > \frac{\pi}{2} a=0 \int_0^{\frac{\pi}{2}}\frac{\sin x_1\cos x_1\:dx_1}{\int_0^{x_1}\frac{\sin x_2 \cos x_2 \:dx_2}{\int_0^{x_3}\frac{\sin x_3 \cos x_3 \:dx_3}{\int_0^{x_3}\cdots}}} = 1 \textbf{My Question} f'(x)\geq 0 g,"['integration', 'sequences-and-series', 'limits', 'definite-integrals']"
43,How should I integrate this function?,How should I integrate this function?,,"Thank you for your precious time! Here is the integration I want to calculate: $$\int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j 2 \pi\left[ \cos \theta- \cos \varphi+ \cos \left(\theta-\varphi\right)\right]} e^{j \theta} e^{-j \varphi} d \theta \, d \varphi$$ I think this integration is related to Bessel functions of the first kind, when we remove the term $\cos(\theta-\varphi)$ above : $$\int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j 2 \pi\left[ \cos \theta- \cos \varphi\right]} e^{j \theta} e^{-j \varphi}\, d \theta d \varphi=\int_{0}^{2 \pi}e^{j (2 \pi \cos \theta+\theta)} d\theta \int_{0}^{2 \pi}e^{-j (2 \pi \cos \varphi+\varphi)}\, d\varphi$$ With the bessel integration: $$ J_{n}(x)=\dfrac{1}{2 \pi} \int_{-\pi}^{\pi} e^{j(n \tau-x \sin \tau)}\, d \tau $$ The integration would be easy to get. But due to the $\cos(\theta-\varphi)$ term in the desired integration, I still can't find a good method. Could you give me any advice? Any help would be appreciated! -----------------------------------------2023/3/11------------------------------------------ According to @Semiclasical's suggestion, I tried: $$e^{j c \cos \left(\theta-\varphi\right)}=\sum_{n=-\infty}^{\infty} j^{n} J_{n}\left(c\right) e^{i n\left(\theta-\varphi\right)}$$ So the integration would be: $$\sum_{i=-\infty}^{\infty}J_n(c)j^n\int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j\left(a \cos \theta-b \cos \varphi\right)} e^{j\left(1+n\right) \theta} e^{-j\left(1+n\right) \varphi} d \theta d \varphi$$ And then it becomes: $$\sum_{i=-\infty}^{\infty} \dfrac{4 \pi^{2}}{j^{-n}} J_{n}\left(c\right) J_{1+n}\left(a\right) J_{-\left(1+n\right)}\left(b\right)$$ I think this is useful. But the integration becomes the summation of series. To be more specific, the integration becomes the summation of Bessel functions. It's still hard to get an analytical formula. I tried to truncate this series, but the accuracy severely degraded. So for now, I think I should try something else. And currently, I'm planning to give Meijer-G function a try. Could you give me more suggestions? Any help is appreciated! -----------------------------------------2023/3/12------------------------------------------ I can't find useful Meijer-G functions for me. But I find that the equation below is actually very accurate(even after truncation): $$\sum_{i=-\infty}^{\infty} \dfrac{4 \pi^{2}}{j^{-n}} J_{n}\left(c\right) J_{1+n}\left(a\right) J_{-\left(1+n\right)}\left(b\right)$$ So I decide to stick on the sum of bessel functions. Since it's hard to get the bessel function summation directly. I used the asymptotic form of bessel functions: $$ J_{\alpha}(z) \sim \frac{1}{\Gamma(\alpha+1)}\left(\frac{z}{2}\right)^{\alpha} $$ Then we can transform bessel series into power series. The summation might be easier. This should work only when $z$ is very small since this asymptotic form of bessel function only works when $z$ is very small. Could you give me any advice? Any help would be appreciated!","Thank you for your precious time! Here is the integration I want to calculate: I think this integration is related to Bessel functions of the first kind, when we remove the term above : With the bessel integration: The integration would be easy to get. But due to the term in the desired integration, I still can't find a good method. Could you give me any advice? Any help would be appreciated! -----------------------------------------2023/3/11------------------------------------------ According to @Semiclasical's suggestion, I tried: So the integration would be: And then it becomes: I think this is useful. But the integration becomes the summation of series. To be more specific, the integration becomes the summation of Bessel functions. It's still hard to get an analytical formula. I tried to truncate this series, but the accuracy severely degraded. So for now, I think I should try something else. And currently, I'm planning to give Meijer-G function a try. Could you give me more suggestions? Any help is appreciated! -----------------------------------------2023/3/12------------------------------------------ I can't find useful Meijer-G functions for me. But I find that the equation below is actually very accurate(even after truncation): So I decide to stick on the sum of bessel functions. Since it's hard to get the bessel function summation directly. I used the asymptotic form of bessel functions: Then we can transform bessel series into power series. The summation might be easier. This should work only when is very small since this asymptotic form of bessel function only works when is very small. Could you give me any advice? Any help would be appreciated!","\int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j 2 \pi\left[ \cos \theta- \cos \varphi+ \cos \left(\theta-\varphi\right)\right]} e^{j \theta} e^{-j \varphi} d \theta \, d \varphi \cos(\theta-\varphi) \int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j 2 \pi\left[ \cos \theta- \cos \varphi\right]} e^{j \theta} e^{-j \varphi}\, d \theta d \varphi=\int_{0}^{2 \pi}e^{j (2 \pi \cos \theta+\theta)} d\theta \int_{0}^{2 \pi}e^{-j (2 \pi \cos \varphi+\varphi)}\, d\varphi 
J_{n}(x)=\dfrac{1}{2 \pi} \int_{-\pi}^{\pi} e^{j(n \tau-x \sin \tau)}\, d \tau
 \cos(\theta-\varphi) e^{j c \cos \left(\theta-\varphi\right)}=\sum_{n=-\infty}^{\infty} j^{n} J_{n}\left(c\right) e^{i n\left(\theta-\varphi\right)} \sum_{i=-\infty}^{\infty}J_n(c)j^n\int_{0}^{2 \pi} \int_{0}^{2 \pi} e^{j\left(a \cos \theta-b \cos \varphi\right)} e^{j\left(1+n\right) \theta} e^{-j\left(1+n\right) \varphi} d \theta d \varphi \sum_{i=-\infty}^{\infty} \dfrac{4 \pi^{2}}{j^{-n}} J_{n}\left(c\right) J_{1+n}\left(a\right) J_{-\left(1+n\right)}\left(b\right) \sum_{i=-\infty}^{\infty} \dfrac{4 \pi^{2}}{j^{-n}} J_{n}\left(c\right) J_{1+n}\left(a\right) J_{-\left(1+n\right)}\left(b\right) 
J_{\alpha}(z) \sim \frac{1}{\Gamma(\alpha+1)}\left(\frac{z}{2}\right)^{\alpha}
 z z","['integration', 'complex-analysis', 'complex-numbers', 'special-functions', 'bessel-functions']"
44,How to show that $f'(x)<2f(x)$ [closed],How to show that  [closed],f'(x)<2f(x),"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . The community reviewed whether to reopen this question 1 year ago and left it closed: Original close reason(s) were not resolved Improve this question This is question B4 in 1999 Putnam Exam. I would appreciate if somebody could help me with this. Let $f(x),f'(x),f''(x),f'''(x)>0$ , $f'''(x)$ is a continuous function and $f'''(x)<f(x)$ on $\mathbb{R}$. Then show that   $$f'(x)<2f(x),~ \forall x\in \mathbb{R}.$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . The community reviewed whether to reopen this question 1 year ago and left it closed: Original close reason(s) were not resolved Improve this question This is question B4 in 1999 Putnam Exam. I would appreciate if somebody could help me with this. Let $f(x),f'(x),f''(x),f'''(x)>0$ , $f'''(x)$ is a continuous function and $f'''(x)<f(x)$ on $\mathbb{R}$. Then show that   $$f'(x)<2f(x),~ \forall x\in \mathbb{R}.$$",,"['real-analysis', 'derivatives', 'inequality']"
45,Integration on manifolds vs. integration on chains,Integration on manifolds vs. integration on chains,,"Motivation/Background: I wish to understand the more practical/computable aspects of integration of differential forms on manifolds. In this question I shall usually implicitly include ""manifolds with boundary"" and ""manifolds with corners"" into the term ""manifold"". Most textbooks on differential geometry introduce two related but a priori seemingly distinct theories of integration, integration on manifolds (with boundary/corners) , and integration on chains . The exact relationship between the two is unclear to me. Usually integration on manifolds is defined by assuming that the differential form has compact support (to avoid convergence issues), but on manifolds with boundary/corners this does mean that the support can intersect the boundary. The integral is defined in terms of coordinates, and is globalized by using a locally finite cover by coordinate neighborhoods and a partition of unity subordinate to this cover. In practice, this does not provide a method amenable to calculations because constructing partitions of unity explicitly can be difficult/impossible. By contrast, the integration on chains goes as follows. I will use cubic chains in this question as opposed to simplicical chains, as I find it is easier to do calculations with cubes. As far as I am aware, the two theories are equivalent. An elementary $r$ -cube is defined to be $I^r\subset\mathbb R^r$ , where $I=[0,1]$ . As a subspace of $\mathbb R^r$ , the elementary $r$ -cube is a manifold with corners. An $r$ -cube in an ( $n$ dimensional) manifold $M$ is defined to be a smooth map $\sigma:I^r\rightarrow M$ . This map does not need to be an immersion or injective or anything, it might be quite degenerate. An $r$ -chain $C$ on $M$ is defined to be a formal finite linear combination of $r$ -cubes: $$ C=\sum_i \alpha_i\sigma_i.$$ If $\omega\in \Omega^r(M)$ is a (smooth) $r$ -form, the integral of $\omega$ over an $r$ -cube $\sigma$ is defined as $$ \int_\sigma\omega=\int_{I^r}\sigma^\ast\omega, $$ where in the last integral the standard orientation of $\mathbb R^r$ is used. In other words, we may write $\sigma^\ast\omega=\rho(u^1,...,u^r)\mathrm du^1\wedge...\wedge\mathrm du^r$ , where $u^1,...,u^r$ are the standard coordinates on $\mathbb R^r$ , and the integral is $$ \int_\sigma\omega=\int_0^1...\int_0^1\rho(u^1,...,u^r)\mathrm du^1...\mathrm du^r. $$ For a general $r$ -chain $C=\sum_i\alpha_i\sigma_i$ , we have $$ \int_C\omega=\sum_i\alpha_i\int_{\sigma_i}\omega. $$ For the elementary $r$ -cube $I^r$ , the $i$ th positive boundary is defined as $$ \partial_i^+I^r=\{u\in I^r:\  u^i=1 \}, $$ while the $i$ th negative boundary is defined as $$ \partial_i^- I^r=\{ u\in I^r:\ u^i=0\}, $$ and the boundary of $I^r$ is $$ \partial I^r=\sum_{i=1}^r\partial_i^+ I^r-\sum_{i=1}^r\partial_i^- I^r. $$ If $\sigma:I^r\rightarrow M$ is a general $r$ -cube, then $$ \partial_i^+\sigma=\sigma|_{\partial_i^+ I^r},\quad\partial_i^-\sigma=\sigma|_{\partial^-_i I^r} $$ and $$ \partial\sigma=\sum_{i=1}^r\partial_i^+\sigma -\sum_{i=1}^r\partial^-_i\sigma. $$ The boundary of a general $r$ -chain is defined by linearity. When one integrates over curves, since every 1 dimensional manifold is diffeomorphic to either $\mathbb R$ , $S^1$ , or a closed interval, one may always effectively parametrize the curve using a single coordinate system, which might be degenerate at a single point (in case of $S^1$ ), which is of measure zero, so this degeneracy does not affect the integral. It seems to me that chains realize this ideal for higher dimensional manifolds, since integration over a chain is always a linear combination of integrals over a cube, which is calculatable in principle (I mean this in the sense that the parametrization itself is not a part of the problem  - the integrals of course might be impossible to explicitly compute), and when we integrate over surfaces in physics and vector calculus, we usually actually integrate on chains, rather than manifolds. To give an explicit example, a sphere of radius $r_0$ in $\mathbb R^3$ is a submanifold, which cannot be described using a single chart. However if we consider the map $$ \sigma:I^2\rightarrow \mathbb R^3,\ \sigma(u^1,u^2)=\left(\begin{matrix} r_0\sin(\pi u^1)\cos(2\pi u^2) \\ r_0\sin(\pi u^1)\sin(2\pi u^2) \\ r_0\cos(\pi u^1)\end{matrix}\right), $$ this map fails to be an immersion at $u^1=0$ and $u^1=1$ , but it does cover the entire sphere as point sets. The set of points where this map fails to be an immersion is a set of zero measure, thus the entire sphere can be described for the purposes of integration using a single $2$ -cube. Moreover, this also describes the boundary, since the $u^1=1$ and $u^1=0$ boundaries are single points, so they are sets of measure zero as $1$ -manifolds, and the $u^2=1$ and $u^2=0$ boundaries are the same line segments but with the opposite orientation, so $1$ -integrals over these $1$ -cubes cancel. Hence, the boundary of the sphere is zero even from the chain point of view. Questions: For the practical parametrization of submanifolds and the explicit computability of integrals, it would be very beneficial if the situation outlined with the sphere embedded in $\mathbb R^3$ would be general. In other words, a theorem of the following form should exist: Hopefully existing theorem: Given an $r$ dimensional ""submanifold with boundary/corners"" $S$ in $M$ , there is an $r$ -chain $C$ in $M$ that is ""equivalent"" to $S\ \blacksquare$ . I have put ""submanifold"" into quotes because there are multiple inequivalent possible definitions (injective immersion, embedding etc.) and I do not know which one should be used, and I have put ""equivalent"" into quotes because I do not know what definition should such an equivalence satisfy. I would assume that as point sets the image of $S$ and $C$ should agree and it should be true that for any $\omega\in\Omega^r(M)$ $r$ -form we should have $$ \int_S\omega=\int_C\omega, $$ where the first expression is integration of $\omega$ in the sense of manifolds and the second expression is integration of $\omega$ in the sense of chains. The manifolds in question are orientable and oriented whenever necessary. So... Does such a result exist? In other words, given a submanifold, is it always possible to replace the submanifold with a chain for the purposes of integration? I would be terribly appreciative if references (papers and/or textbooks) would be given to me where such results are treated/proven. If the answer to 1) is affirmative, then the proofs/treatment of that result, and if the answer to 1) is negative, then for example sources that treat/explain when exactly can integration over manifolds be replaced with integration over chains.","Motivation/Background: I wish to understand the more practical/computable aspects of integration of differential forms on manifolds. In this question I shall usually implicitly include ""manifolds with boundary"" and ""manifolds with corners"" into the term ""manifold"". Most textbooks on differential geometry introduce two related but a priori seemingly distinct theories of integration, integration on manifolds (with boundary/corners) , and integration on chains . The exact relationship between the two is unclear to me. Usually integration on manifolds is defined by assuming that the differential form has compact support (to avoid convergence issues), but on manifolds with boundary/corners this does mean that the support can intersect the boundary. The integral is defined in terms of coordinates, and is globalized by using a locally finite cover by coordinate neighborhoods and a partition of unity subordinate to this cover. In practice, this does not provide a method amenable to calculations because constructing partitions of unity explicitly can be difficult/impossible. By contrast, the integration on chains goes as follows. I will use cubic chains in this question as opposed to simplicical chains, as I find it is easier to do calculations with cubes. As far as I am aware, the two theories are equivalent. An elementary -cube is defined to be , where . As a subspace of , the elementary -cube is a manifold with corners. An -cube in an ( dimensional) manifold is defined to be a smooth map . This map does not need to be an immersion or injective or anything, it might be quite degenerate. An -chain on is defined to be a formal finite linear combination of -cubes: If is a (smooth) -form, the integral of over an -cube is defined as where in the last integral the standard orientation of is used. In other words, we may write , where are the standard coordinates on , and the integral is For a general -chain , we have For the elementary -cube , the th positive boundary is defined as while the th negative boundary is defined as and the boundary of is If is a general -cube, then and The boundary of a general -chain is defined by linearity. When one integrates over curves, since every 1 dimensional manifold is diffeomorphic to either , , or a closed interval, one may always effectively parametrize the curve using a single coordinate system, which might be degenerate at a single point (in case of ), which is of measure zero, so this degeneracy does not affect the integral. It seems to me that chains realize this ideal for higher dimensional manifolds, since integration over a chain is always a linear combination of integrals over a cube, which is calculatable in principle (I mean this in the sense that the parametrization itself is not a part of the problem  - the integrals of course might be impossible to explicitly compute), and when we integrate over surfaces in physics and vector calculus, we usually actually integrate on chains, rather than manifolds. To give an explicit example, a sphere of radius in is a submanifold, which cannot be described using a single chart. However if we consider the map this map fails to be an immersion at and , but it does cover the entire sphere as point sets. The set of points where this map fails to be an immersion is a set of zero measure, thus the entire sphere can be described for the purposes of integration using a single -cube. Moreover, this also describes the boundary, since the and boundaries are single points, so they are sets of measure zero as -manifolds, and the and boundaries are the same line segments but with the opposite orientation, so -integrals over these -cubes cancel. Hence, the boundary of the sphere is zero even from the chain point of view. Questions: For the practical parametrization of submanifolds and the explicit computability of integrals, it would be very beneficial if the situation outlined with the sphere embedded in would be general. In other words, a theorem of the following form should exist: Hopefully existing theorem: Given an dimensional ""submanifold with boundary/corners"" in , there is an -chain in that is ""equivalent"" to . I have put ""submanifold"" into quotes because there are multiple inequivalent possible definitions (injective immersion, embedding etc.) and I do not know which one should be used, and I have put ""equivalent"" into quotes because I do not know what definition should such an equivalence satisfy. I would assume that as point sets the image of and should agree and it should be true that for any -form we should have where the first expression is integration of in the sense of manifolds and the second expression is integration of in the sense of chains. The manifolds in question are orientable and oriented whenever necessary. So... Does such a result exist? In other words, given a submanifold, is it always possible to replace the submanifold with a chain for the purposes of integration? I would be terribly appreciative if references (papers and/or textbooks) would be given to me where such results are treated/proven. If the answer to 1) is affirmative, then the proofs/treatment of that result, and if the answer to 1) is negative, then for example sources that treat/explain when exactly can integration over manifolds be replaced with integration over chains.","r I^r\subset\mathbb R^r I=[0,1] \mathbb R^r r r n M \sigma:I^r\rightarrow M r C M r  C=\sum_i \alpha_i\sigma_i. \omega\in \Omega^r(M) r \omega r \sigma  \int_\sigma\omega=\int_{I^r}\sigma^\ast\omega,  \mathbb R^r \sigma^\ast\omega=\rho(u^1,...,u^r)\mathrm du^1\wedge...\wedge\mathrm du^r u^1,...,u^r \mathbb R^r  \int_\sigma\omega=\int_0^1...\int_0^1\rho(u^1,...,u^r)\mathrm du^1...\mathrm du^r.  r C=\sum_i\alpha_i\sigma_i  \int_C\omega=\sum_i\alpha_i\int_{\sigma_i}\omega.  r I^r i  \partial_i^+I^r=\{u\in I^r:\  u^i=1 \},  i  \partial_i^- I^r=\{ u\in I^r:\ u^i=0\},  I^r  \partial I^r=\sum_{i=1}^r\partial_i^+ I^r-\sum_{i=1}^r\partial_i^- I^r.  \sigma:I^r\rightarrow M r  \partial_i^+\sigma=\sigma|_{\partial_i^+ I^r},\quad\partial_i^-\sigma=\sigma|_{\partial^-_i I^r}   \partial\sigma=\sum_{i=1}^r\partial_i^+\sigma -\sum_{i=1}^r\partial^-_i\sigma.  r \mathbb R S^1 S^1 r_0 \mathbb R^3  \sigma:I^2\rightarrow \mathbb R^3,\ \sigma(u^1,u^2)=\left(\begin{matrix} r_0\sin(\pi u^1)\cos(2\pi u^2) \\ r_0\sin(\pi u^1)\sin(2\pi u^2) \\ r_0\cos(\pi u^1)\end{matrix}\right),  u^1=0 u^1=1 2 u^1=1 u^1=0 1 u^2=1 u^2=0 1 1 \mathbb R^3 r S M r C M S\ \blacksquare S C \omega\in\Omega^r(M) r  \int_S\omega=\int_C\omega,  \omega \omega","['integration', 'differential-geometry', 'differential-topology', 'vector-analysis', 'differential-forms']"
46,Average value of $\ln(1+e^x)$ when $x$ is normally distributed,Average value of  when  is normally distributed,\ln(1+e^x) x,"Does the following integral admit a closed form answer: $$\int_{-\infty}^\infty\mathrm d x \exp\left(-\frac{(x-\mu)^2}{2\nu}\right) \ln(1+e^x)$$ where $\nu>0$ and $\mu$ are finite real parameters. This is just the average value of $\ln(1+e^x)$ , when $x$ is normally distributed with mean $\mu$ and variance $\nu$ (forgetting the normalization constant). I tried with symbolic processing software (Mathematica and WolframAlpha), and both return the input expression unevaluated, suggesting that a closed form solution does not exist, or at least it is not obvious.","Does the following integral admit a closed form answer: where and are finite real parameters. This is just the average value of , when is normally distributed with mean and variance (forgetting the normalization constant). I tried with symbolic processing software (Mathematica and WolframAlpha), and both return the input expression unevaluated, suggesting that a closed form solution does not exist, or at least it is not obvious.",\int_{-\infty}^\infty\mathrm d x \exp\left(-\frac{(x-\mu)^2}{2\nu}\right) \ln(1+e^x) \nu>0 \mu \ln(1+e^x) x \mu \nu,"['integration', 'definite-integrals', 'normal-distribution']"
47,Methods to solve $\int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}\:dx$,Methods to solve,\int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}\:dx,"Spurred on by this question, I decided to investigate for different functions on the numerator. Here, I went from $\exp(..)$ to $\sin(..) / \cos(..)$ . I initially thought I could modify the result from $\exp(..)$ but got stuck . So I decided on another approach which here is a combination of Feynman's Trick, Laplace Transforms and coupled ODE Systems. I would love for a qualified eye to have a look over to see if what I've done is correct and/or another method (Not using Complex Analysis) to solve. Here I've included more of my algebra to aid in those who wish to go over. Consider the following two definite integrals \begin{align}     I_{n,a,k} &= \int_{0}^{\infty} \frac{\sin\left(kx^n\right)}{x^n + a}\:dx \\     J_{n,a,k} &= \int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}:dx \end{align} For $a,k \in \mathbb{R}^+$ and $n \in \mathbb{R}^{+}, n > 1$ . Here we define: \begin{align}     I_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\sin\left(tkx^n\right)}{x^n + a}:dx \\     J_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}:dx \end{align} Here we observe that: \begin{align}     I_{n,a,k}(1) &= I_{n,a,k} & I_{n,a,k}(0) &= 0   \\     J_{n,a,k}(1) &= J_{n,a,k} & J_{n,a,k}(0) &= a^{\frac{1}{n} - 1} \frac{\Gamma\left(1 -\frac{1}{n}\right)\Gamma\left(\frac{1}{n} \right)}{n} = \theta_{a,n} \end{align} Here we will address each integral individually. For $I_{n,a,k}$ we take the derivative with respect to ' $t$ ': \begin{align}     I_{n,a,k}'(t) &= \int_{0}^{\infty} \frac{kx^n\cos\left(tkx^n\right)}{x^n + a}\:dx = k\left[\int_{0}^{\infty} \cos\left(tkx^n\right)\:dx - a\int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}\:dx \right] \\     \frac{1}{k}I_{n,a,k}'(t) &= \frac{1}{k^{\frac{1}{n}}t^{\frac{1}{n}}}\int_{0}^{\infty} \cos\left(u^n\right)\:du - aJ_{n,a,k}(t) \end{align} Thus, \begin{equation}     \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) = \frac{1}{k^{\frac{1}{n}}t^{\frac{1}{n}}}\int_{0}^{\infty} \cos\left(u^n\right)\:du \end{equation} From Section X, we arrive at: \begin{equation}     \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) =  \frac{\Gamma\left(\frac{1}{n}\right)\cos\left(\frac{\pi}{2n} \right)}{nk^{\frac{1}{n}}t^{\frac{1}{n}}} \end{equation} Applying the same method to $J_{n,a,k}\left(t\right)$ we arrive at: \begin{equation}     -\frac{1}{k}J_{n,a,k}'(t) + aI_{n,a,k}(t) = \ \frac{\Gamma\left(\frac{1}{n}\right)\sin\left(\frac{\pi}{2n} \right)}{nk^{\frac{1}{n}}t^{\frac{1}{n}}} \end{equation} And thus, we arrive at the couple ordinary differential equation system: \begin{align}     \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)t^{-\frac{1}{n}}\\     aI_{n,a,k}(t) -\frac{1}{k}J_{n,a,k}'(t)  &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)t^{-\frac{1}{n}} \end{align} Where $\Psi_{k,n} = \frac{\Gamma\left(\frac{1}{n}\right)}{n}k^{-\frac{1}{n}}$ . Although there are many approaches to solving this system, here I will employ Laplace Transforms: \begin{align}     \frac{1}{k}\mathscr{L}\left[I_{n,a,k}'(t)\right] + a\mathscr{L}\left[J_{n,a,k}(t)\right] &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\mathscr{L}\left[t^{-\frac{1}{n}}\right]\\     a\mathscr{L}\left[I_{n,a,k}(t)\right] -\frac{1}{k}\mathscr{L}\left[J_{n,a,k}'(t)\right]  &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\mathscr{L}\left[t^{-\frac{1}{n}}\right] \end{align} Which becomes: \begin{align}     \frac{s}{k}\bar{I}_{n,a,k}(s)  + a\bar{J}_{n,a,k}(s) &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\kappa(s)\\     a\bar{I}_{n,a,k}(s) -\frac{s}{k}\bar{J}_{n,a,k}(s)   &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\kappa(s) + \frac{1}{k}\theta_{a,n} \end{align} Where \begin{equation}     \kappa(s) = \mathscr{L}\left[t^{-\frac{1}{n}}\right] = \Gamma\left(1 - \frac{1}{n}\right)s^{1 - \frac{1}{n}} \end{equation} Solving for $\bar{J}_{n,a,k}(s)$ we find: \begin{align}     \bar{J}_{n,a,k}(s) &= \frac{1}{s^2 + a^2k^2}\left[ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\kappa(s) -k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)s\kappa(s) - s\theta_{a,n}\right] \\     &=ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\frac{1}{s^2 + a^2k^2}\kappa(s)-k\Psi_{k,n}\frac{s}{s^2 + a^2k^2}\kappa(s)\\     &\qquad- \theta_{a,n}\frac{s}{s^2 + a^2k^2} \end{align} Taking the Inverse Laplace Transform, we arrive at: \begin{align}     &J_{n,a,k}(t) = \mathscr{L}^{-1}\left[ \bar{J}_{n,a,k}(s) \right] = ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\mathscr{L}^{-1}\left[\frac{1}{s^2 + a^2k^2}\kappa(s)\right]\\     &\qquad-ak\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\mathscr{L}^{-1}\left[\frac{s}{s^2 + a^2k^2}\kappa(s)\right]- \theta_{a,n}\mathscr{L}^{-1}\left[\frac{s}{s^2 + a^2k^2}\right] \\     &= ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\int_{0}^{t} \frac{1}{ak}\sin\left(ak\left(t - \tau\right)\right) \tau^{-\frac{1}{n}}\:d tau\\     &\qquad-ak\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\int_{0}^{t} \cos\left(ak\left(t - \tau\right)\right) \tau^{-\frac{1}{n}}\:d tau -\theta_{a,n}\cos\left(akt \right) \\     &= k\Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\int_{0}^{t} \left[\sin\left(akt\right)\cos\left(ak\tau\right)  - \sin\left(ak\tau\right)\cos\left(akt\right) \right]\tau^{-\frac{1}{n}}\:d\tau\\     &\qquad-k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\int_{0}^{t} \left[\cos\left(akt\right)\cos\left(ak\tau\right)  +\sin\left(ak\tau\right)\sin\left(akt\right) \right] \tau^{-\frac{1}{n}}\:d\tau \\     &\qquad-\theta_{a,n}\cos\left(akt \right) \\     &= k\Psi_{k,n}\cos\left(\frac{\pi}{2n} \right) \left[\sin\left(akt\right)\int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau - \cos\left(akt\right)\int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau \right]  \\     &\qquad-k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\left[\cos\left(akt\right)\int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau+ \sin\left(akt\right)\int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau  \right] \\      &\qquad-\theta_{a,n}\cos\left(akt \right) \\      &= k \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau-\cos\left(akt + \frac{\pi}{2n}\right) \int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau \right] \\      &\qquad-\theta_{a,n}\cos\left(akt \right) \\      &= k \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1}\int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1} \int_{0}^{t} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\      &\qquad-\theta_{a,n}\cos\left(akt \right) \\           &= k k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1} \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)\int_{0}^{akt} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\      &\qquad-\theta_{a,n}\cos\left(akt \right) \end{align} Hence, \begin{align}     J_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}\:dx \\           &=a^{\frac{1}{n} - 1}\frac{\Gamma\left(\frac{1}{n} \right)}{n} \left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)\int_{0}^{akt} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] -\theta_{a,n}\cos\left(akt \right)  \end{align} And finally, \begin{align}     J_{n,a,k} &= J_{n,a,k}(1) = \int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}\:dx \\           &=a^{\frac{1}{n} - 1}\frac{\Gamma\left(\frac{1}{n} \right)}{n} \left[\sin\left(ak + \frac{\pi}{2n}\right) \int_{0}^{ak} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(ak + \frac{\pi}{2n}\right)\int_{0}^{ak} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\           &\qquad-\cos\left(ak \right) a^{\frac{1}{n} - 1} \frac{\Gamma\left(1 -\frac{1}{n}\right)\Gamma\left(\frac{1}{n} \right)}{n}  \end{align}","Spurred on by this question, I decided to investigate for different functions on the numerator. Here, I went from to . I initially thought I could modify the result from but got stuck . So I decided on another approach which here is a combination of Feynman's Trick, Laplace Transforms and coupled ODE Systems. I would love for a qualified eye to have a look over to see if what I've done is correct and/or another method (Not using Complex Analysis) to solve. Here I've included more of my algebra to aid in those who wish to go over. Consider the following two definite integrals For and . Here we define: Here we observe that: Here we will address each integral individually. For we take the derivative with respect to ' ': Thus, From Section X, we arrive at: Applying the same method to we arrive at: And thus, we arrive at the couple ordinary differential equation system: Where . Although there are many approaches to solving this system, here I will employ Laplace Transforms: Which becomes: Where Solving for we find: Taking the Inverse Laplace Transform, we arrive at: Hence, And finally,","\exp(..) \sin(..) / \cos(..) \exp(..) \begin{align}
    I_{n,a,k} &= \int_{0}^{\infty} \frac{\sin\left(kx^n\right)}{x^n + a}\:dx \\
    J_{n,a,k} &= \int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}:dx
\end{align} a,k \in \mathbb{R}^+ n \in \mathbb{R}^{+}, n > 1 \begin{align}
    I_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\sin\left(tkx^n\right)}{x^n + a}:dx \\
    J_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}:dx
\end{align} \begin{align}
    I_{n,a,k}(1) &= I_{n,a,k} & I_{n,a,k}(0) &= 0   \\
    J_{n,a,k}(1) &= J_{n,a,k} & J_{n,a,k}(0) &= a^{\frac{1}{n} - 1} \frac{\Gamma\left(1 -\frac{1}{n}\right)\Gamma\left(\frac{1}{n} \right)}{n} = \theta_{a,n}
\end{align} I_{n,a,k} t \begin{align}
    I_{n,a,k}'(t) &= \int_{0}^{\infty} \frac{kx^n\cos\left(tkx^n\right)}{x^n + a}\:dx = k\left[\int_{0}^{\infty} \cos\left(tkx^n\right)\:dx - a\int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}\:dx \right] \\
    \frac{1}{k}I_{n,a,k}'(t) &= \frac{1}{k^{\frac{1}{n}}t^{\frac{1}{n}}}\int_{0}^{\infty} \cos\left(u^n\right)\:du - aJ_{n,a,k}(t)
\end{align} \begin{equation}
    \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) = \frac{1}{k^{\frac{1}{n}}t^{\frac{1}{n}}}\int_{0}^{\infty} \cos\left(u^n\right)\:du
\end{equation} \begin{equation}
    \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) =  \frac{\Gamma\left(\frac{1}{n}\right)\cos\left(\frac{\pi}{2n} \right)}{nk^{\frac{1}{n}}t^{\frac{1}{n}}}
\end{equation} J_{n,a,k}\left(t\right) \begin{equation}
    -\frac{1}{k}J_{n,a,k}'(t) + aI_{n,a,k}(t) = \ \frac{\Gamma\left(\frac{1}{n}\right)\sin\left(\frac{\pi}{2n} \right)}{nk^{\frac{1}{n}}t^{\frac{1}{n}}}
\end{equation} \begin{align}
    \frac{1}{k}I_{n,a,k}'(t) + aJ_{n,a,k}(t) &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)t^{-\frac{1}{n}}\\
    aI_{n,a,k}(t) -\frac{1}{k}J_{n,a,k}'(t)  &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)t^{-\frac{1}{n}}
\end{align} \Psi_{k,n} = \frac{\Gamma\left(\frac{1}{n}\right)}{n}k^{-\frac{1}{n}} \begin{align}
    \frac{1}{k}\mathscr{L}\left[I_{n,a,k}'(t)\right] + a\mathscr{L}\left[J_{n,a,k}(t)\right] &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\mathscr{L}\left[t^{-\frac{1}{n}}\right]\\
    a\mathscr{L}\left[I_{n,a,k}(t)\right] -\frac{1}{k}\mathscr{L}\left[J_{n,a,k}'(t)\right]  &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\mathscr{L}\left[t^{-\frac{1}{n}}\right]
\end{align} \begin{align}
    \frac{s}{k}\bar{I}_{n,a,k}(s)  + a\bar{J}_{n,a,k}(s) &=  \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\kappa(s)\\
    a\bar{I}_{n,a,k}(s) -\frac{s}{k}\bar{J}_{n,a,k}(s)   &=  \Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\kappa(s) + \frac{1}{k}\theta_{a,n}
\end{align} \begin{equation}
    \kappa(s) = \mathscr{L}\left[t^{-\frac{1}{n}}\right] = \Gamma\left(1 - \frac{1}{n}\right)s^{1 - \frac{1}{n}}
\end{equation} \bar{J}_{n,a,k}(s) \begin{align}
    \bar{J}_{n,a,k}(s) &= \frac{1}{s^2 + a^2k^2}\left[ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\kappa(s) -k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)s\kappa(s) - s\theta_{a,n}\right] \\
    &=ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\frac{1}{s^2 + a^2k^2}\kappa(s)-k\Psi_{k,n}\frac{s}{s^2 + a^2k^2}\kappa(s)\\
    &\qquad- \theta_{a,n}\frac{s}{s^2 + a^2k^2}
\end{align} \begin{align}
    &J_{n,a,k}(t) = \mathscr{L}^{-1}\left[ \bar{J}_{n,a,k}(s) \right] = ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\mathscr{L}^{-1}\left[\frac{1}{s^2 + a^2k^2}\kappa(s)\right]\\
    &\qquad-ak\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\mathscr{L}^{-1}\left[\frac{s}{s^2 + a^2k^2}\kappa(s)\right]- \theta_{a,n}\mathscr{L}^{-1}\left[\frac{s}{s^2 + a^2k^2}\right] \\
    &= ak^2 \Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\int_{0}^{t} \frac{1}{ak}\sin\left(ak\left(t - \tau\right)\right) \tau^{-\frac{1}{n}}\:d
tau\\
    &\qquad-ak\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\int_{0}^{t} \cos\left(ak\left(t - \tau\right)\right) \tau^{-\frac{1}{n}}\:d
tau -\theta_{a,n}\cos\left(akt \right) \\
    &= k\Psi_{k,n}\cos\left(\frac{\pi}{2n} \right)\int_{0}^{t} \left[\sin\left(akt\right)\cos\left(ak\tau\right)  - \sin\left(ak\tau\right)\cos\left(akt\right) \right]\tau^{-\frac{1}{n}}\:d\tau\\
    &\qquad-k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\int_{0}^{t} \left[\cos\left(akt\right)\cos\left(ak\tau\right)  +\sin\left(ak\tau\right)\sin\left(akt\right) \right] \tau^{-\frac{1}{n}}\:d\tau \\
    &\qquad-\theta_{a,n}\cos\left(akt \right) \\
    &= k\Psi_{k,n}\cos\left(\frac{\pi}{2n} \right) \left[\sin\left(akt\right)\int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau - \cos\left(akt\right)\int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau \right]  \\
    &\qquad-k\Psi_{k,n}\sin\left(\frac{\pi}{2n} \right)\left[\cos\left(akt\right)\int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau+ \sin\left(akt\right)\int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau  \right] \\
     &\qquad-\theta_{a,n}\cos\left(akt \right) \\
     &= k \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{t} \frac{\cos\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau-\cos\left(akt + \frac{\pi}{2n}\right) \int_{0}^{t} \frac{\sin\left(ak\tau\right) }{\tau^{\frac{1}{n}}}\:d\tau \right] \\
     &\qquad-\theta_{a,n}\cos\left(akt \right) \\
     &= k \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1}\int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1} \int_{0}^{t} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\
     &\qquad-\theta_{a,n}\cos\left(akt \right) \\
          &= k k^{\frac{1}{n} - 1} a^{\frac{1}{n} - 1} \Psi_{k,n}\left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)\int_{0}^{akt} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\
     &\qquad-\theta_{a,n}\cos\left(akt \right)
\end{align} \begin{align}
    J_{n,a,k}(t) &= \int_{0}^{\infty} \frac{\cos\left(tkx^n\right)}{x^n + a}\:dx \\
          &=a^{\frac{1}{n} - 1}\frac{\Gamma\left(\frac{1}{n} \right)}{n} \left[\sin\left(akt + \frac{\pi}{2n}\right) \int_{0}^{akt} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(akt + \frac{\pi}{2n}\right)\int_{0}^{akt} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] -\theta_{a,n}\cos\left(akt \right) 
\end{align} \begin{align}
    J_{n,a,k} &= J_{n,a,k}(1) = \int_{0}^{\infty} \frac{\cos\left(kx^n\right)}{x^n + a}\:dx \\
          &=a^{\frac{1}{n} - 1}\frac{\Gamma\left(\frac{1}{n} \right)}{n} \left[\sin\left(ak + \frac{\pi}{2n}\right) \int_{0}^{ak} \frac{\cos\left(u\right) }{u^{\frac{1}{n}}}\:du-\cos\left(ak + \frac{\pi}{2n}\right)\int_{0}^{ak} \frac{\sin\left(u\right) }{u^{\frac{1}{n}}}\:du \right] \\
          &\qquad-\cos\left(ak \right) a^{\frac{1}{n} - 1} \frac{\Gamma\left(1 -\frac{1}{n}\right)\Gamma\left(\frac{1}{n} \right)}{n} 
\end{align}","['integration', 'ordinary-differential-equations']"
48,Using Laplace transforms to evaluate$\int_{0}^{\infty}\frac{\sin^2(x)}{x^2(x^2 + 1)} dx$,Using Laplace transforms to evaluate,\int_{0}^{\infty}\frac{\sin^2(x)}{x^2(x^2 + 1)} dx,"Recently I've been playing around with Feynman's Trick to evaluate integrals. Obviously, one of it's many great features is that it allows derivatives to make expressions simpler. I was wondering whether Laplace Transforms could equally be applied. I'm not qualified to say the following is proper or rigorous, it was just an experiment. Consider $$I = \int_{0}^{\infty}\frac{\sin^2(x)}{x^2(x^2 + 1)}\, \mathrm dx.$$ Let $$I(t) = \int_{0}^{\infty}\frac{\sin^2(tx)}{x^2(x^2 + 1)} \,\mathrm dx$$ Take the Laplace Transform to yield \begin{align*} \mathscr L[I(t)] &= \int_{0}^{\infty}\frac{\mathscr L[\sin^2(tx)]}{x^2(x^2 + 1)}\,\mathrm dx\\  &= \int_{0}^{\infty}\frac{\mathscr 1}{x^2(x^2 + 1)}\frac{2x^2}{s(s^2 + 4x^2)}\,\mathrm dx\\  &= \frac{2}{s}\int_{0}^{\infty}\frac{1}{(x^2 + 1)(4x^2 + s^2)}\,\mathrm dx. \end{align*} Splitting via Partial Fraction Decomposition we arrive at \begin{align*} \mathscr L[I(t)] &= \frac{2}{s(s^2 - 4)}\int_{0}^{\infty}\left[ \frac{1}{x^{2} + 1} - \frac{4}{4x^{2} + s^2}\right] \,\mathrm dx\\ &= \frac{2}{s(s^2 - 4)}\left[\arctan(x) - \frac{2}{s}\arctan\left(\frac{2x}{s}\right)\right]_{0}^{\infty}\\ &= \frac{2}{s(s^2 - 4)}\left[\frac{\pi}{2} - \frac{2}{s}\frac{\pi}{2} \right]\\ &= \frac{\pi}{s^2(s + 2)} \end{align*} And so $$I(t) = \mathscr L^{-1}\left[\frac{\pi}{s^2(s + 2)}\right] = \pi\left[\frac{t}{2} + \frac{e^{-2t}}{4} - \frac{1}{4}\right]$$ Hence, $$I(1) = \pi\left[\frac{1}{2} + \frac{e^{-2}}{4} - \frac{1}{4} \right] = \frac{\pi}{4}\left[1 + e^{-2}\right]$$ which is correct. I'm unsure if this is mere luck or whether this is a viable method. Has anyone used this method before?","Recently I've been playing around with Feynman's Trick to evaluate integrals. Obviously, one of it's many great features is that it allows derivatives to make expressions simpler. I was wondering whether Laplace Transforms could equally be applied. I'm not qualified to say the following is proper or rigorous, it was just an experiment. Consider Let Take the Laplace Transform to yield Splitting via Partial Fraction Decomposition we arrive at And so Hence, which is correct. I'm unsure if this is mere luck or whether this is a viable method. Has anyone used this method before?","I = \int_{0}^{\infty}\frac{\sin^2(x)}{x^2(x^2 + 1)}\, \mathrm dx. I(t) = \int_{0}^{\infty}\frac{\sin^2(tx)}{x^2(x^2 + 1)} \,\mathrm dx \begin{align*}
\mathscr L[I(t)] &= \int_{0}^{\infty}\frac{\mathscr L[\sin^2(tx)]}{x^2(x^2 + 1)}\,\mathrm dx\\ 
&= \int_{0}^{\infty}\frac{\mathscr 1}{x^2(x^2 + 1)}\frac{2x^2}{s(s^2 + 4x^2)}\,\mathrm dx\\ 
&= \frac{2}{s}\int_{0}^{\infty}\frac{1}{(x^2 + 1)(4x^2 + s^2)}\,\mathrm dx.
\end{align*} \begin{align*}
\mathscr L[I(t)] &= \frac{2}{s(s^2 - 4)}\int_{0}^{\infty}\left[ \frac{1}{x^{2} + 1} - \frac{4}{4x^{2} + s^2}\right] \,\mathrm dx\\
&= \frac{2}{s(s^2 - 4)}\left[\arctan(x) - \frac{2}{s}\arctan\left(\frac{2x}{s}\right)\right]_{0}^{\infty}\\
&= \frac{2}{s(s^2 - 4)}\left[\frac{\pi}{2} - \frac{2}{s}\frac{\pi}{2} \right]\\
&= \frac{\pi}{s^2(s + 2)}
\end{align*} I(t) = \mathscr L^{-1}\left[\frac{\pi}{s^2(s + 2)}\right] = \pi\left[\frac{t}{2} + \frac{e^{-2t}}{4} - \frac{1}{4}\right] I(1) = \pi\left[\frac{1}{2} + \frac{e^{-2}}{4} - \frac{1}{4}
\right] = \frac{\pi}{4}\left[1 + e^{-2}\right]","['integration', 'proof-verification']"
49,Geometric meaning of an integral on a compact Riemann surface,Geometric meaning of an integral on a compact Riemann surface,,"Let $X$ be a compact Riemann surface and fix a volume form $\Omega$ on $X$ such that $\int_X\Omega=1$. Now let's fix a function $g:U\subset X\to\mathbb R$ on $X$ with the following properties: $U=X\setminus\{x_1,\ldots,x_r\}$ for $r\in\mathbb N$. $g$ is a $C^\infty$ function on $U$. For any point $x\in X$ there exist a real number $a\in\mathbb R$ and a $C^\infty$ function $u$ on an open neighborhood of $x$ such that the equality:  $$g=a\log|z|^2+u\quad (\ast)$$ holds in an open (punctured)     neighborhood of $x$ contained in a holomorphic chart $(V,z)$ centred     in $x$ $\Delta_{\bar\partial}(g)$ is constant In other words $g$ is smooth almost everywhere, on singular point it has logarithmic behaviour and its $\bar{\partial}$-Laplacian is constant. Now consider the integral  $$\int_X g\Omega$$ (note that the form is integrable cause the singularities are integrable). What is its geometric/intuitive meaning? What are we measuring with such integral? Is it related to the numbers $a$ of equation $(\ast)$ (just finitely many of them are nonzero)? Many thanks in advance","Let $X$ be a compact Riemann surface and fix a volume form $\Omega$ on $X$ such that $\int_X\Omega=1$. Now let's fix a function $g:U\subset X\to\mathbb R$ on $X$ with the following properties: $U=X\setminus\{x_1,\ldots,x_r\}$ for $r\in\mathbb N$. $g$ is a $C^\infty$ function on $U$. For any point $x\in X$ there exist a real number $a\in\mathbb R$ and a $C^\infty$ function $u$ on an open neighborhood of $x$ such that the equality:  $$g=a\log|z|^2+u\quad (\ast)$$ holds in an open (punctured)     neighborhood of $x$ contained in a holomorphic chart $(V,z)$ centred     in $x$ $\Delta_{\bar\partial}(g)$ is constant In other words $g$ is smooth almost everywhere, on singular point it has logarithmic behaviour and its $\bar{\partial}$-Laplacian is constant. Now consider the integral  $$\int_X g\Omega$$ (note that the form is integrable cause the singularities are integrable). What is its geometric/intuitive meaning? What are we measuring with such integral? Is it related to the numbers $a$ of equation $(\ast)$ (just finitely many of them are nonzero)? Many thanks in advance",,"['integration', 'differential-forms', 'complex-geometry', 'riemann-surfaces']"
50,"Dilogarithmic fashion: the case $(p,q)=(3,4)$ of $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$",Dilogarithmic fashion: the case  of,"(p,q)=(3,4) \int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx","Today I met on Facebook the following integral $$\int_{0}^{1}\frac{\text{Li}_3(x)\,\text{Li}_4(x)}{x^2}\,dx$$ which I proved to be equal to $$\frac{10 \pi ^2}{3}-\frac{17 \pi ^4}{180}-\frac{\pi ^6}{540}-10\, \zeta(3)-\frac{\pi^2}{3}\,\zeta(3)-\frac{\pi^4}{90}\,\zeta(3)-\zeta(3)^2-2\,\zeta(5).$$ The trick I used is pretty nice: by integration by parts, the computation of $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$ boils down to the computation of $\int_{0}^{1}\frac{\text{Li}_{p-1}(x)\,\text{Li}_q(x)}{x^2}\,dx$ and $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_{q-1}(x)}{x^2}\,dx$. It follows that through many steps of integration by parts the evaluation of the generalized $(p,q)$-integral boils down to the evaluation of $$ \int_{0}^{1}\frac{-\log(1-x)\,\text{Li}_r(x)}{x^2}\,dx =\zeta(2)+\sum_{n\geq 2}\frac{H_{n-1}}{(n-1)n^r},$$ where by partial fraction decomposition the RHS only depends on standard Euler sums $\sum_{n\geq 1}\frac{H_n}{n^s}$, always expressible in terms of values of the $\zeta$ function. See, for instance, Flajolet and Salvy , Theorem 2.2. I would use this question for collecting alternative/shorter/slicker solutions, both for the starting integral or for the generalized one $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$.","Today I met on Facebook the following integral $$\int_{0}^{1}\frac{\text{Li}_3(x)\,\text{Li}_4(x)}{x^2}\,dx$$ which I proved to be equal to $$\frac{10 \pi ^2}{3}-\frac{17 \pi ^4}{180}-\frac{\pi ^6}{540}-10\, \zeta(3)-\frac{\pi^2}{3}\,\zeta(3)-\frac{\pi^4}{90}\,\zeta(3)-\zeta(3)^2-2\,\zeta(5).$$ The trick I used is pretty nice: by integration by parts, the computation of $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$ boils down to the computation of $\int_{0}^{1}\frac{\text{Li}_{p-1}(x)\,\text{Li}_q(x)}{x^2}\,dx$ and $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_{q-1}(x)}{x^2}\,dx$. It follows that through many steps of integration by parts the evaluation of the generalized $(p,q)$-integral boils down to the evaluation of $$ \int_{0}^{1}\frac{-\log(1-x)\,\text{Li}_r(x)}{x^2}\,dx =\zeta(2)+\sum_{n\geq 2}\frac{H_{n-1}}{(n-1)n^r},$$ where by partial fraction decomposition the RHS only depends on standard Euler sums $\sum_{n\geq 1}\frac{H_n}{n^s}$, always expressible in terms of values of the $\zeta$ function. See, for instance, Flajolet and Salvy , Theorem 2.2. I would use this question for collecting alternative/shorter/slicker solutions, both for the starting integral or for the generalized one $\int_{0}^{1}\frac{\text{Li}_p(x)\,\text{Li}_q(x)}{x^2}\,dx$.",,"['integration', 'special-functions', 'alternative-proof']"
51,Question about $\int_{0}^{\infty} \sin x dx = 1$,Question about,\int_{0}^{\infty} \sin x dx = 1,"I saw that physicists use the following integral  $$ \int_{0}^{\infty} \sin x dx = 1 $$ in a distribution sense, i.e.  $$ \int_{0}^{\infty} \sin x dx := \lim_{a\to 0} \int_{0}^{\infty} e^{-ax}\sin x dx = \lim_{a\to 0} \frac{1}{a^{2}+1} = 1 $$ However, I wonder we get the same value when we change the distribution part. For example, we have the following result (according to Wolfram alpha) $$ \lim_{a\to 0} \int_{0}^{\infty} e^{-ax^{2}}\sin x dx = \lim_{a\to 0}\frac{F\left(\frac{1}{2\sqrt{a}}\right)}{\sqrt{a}} = \lim_{a\to 0 }\frac{e^{-1/4a}}{\sqrt{a}}\int_{0}^{\frac{1}{2\sqrt{a}}}e^{y^{2}}dy =1  $$ where $F(x):=e^{-x^{2}}\int_{0}^{x}e^{y^{2}}dy$ is a Dawson's integral. To show this, we have to show the following : suppose a function $f:\mathbb{R}_{\geq 0}\times \mathbb{R}_{\geq 0}\to \mathbb{R}$ is continuous and the integral  $$ \int_{0}^{\infty} f(a, x)\sin x dx $$ converges for any $a\geq 0$. If $f(0, x)=0$ for all $x\geq 0$, we have $$ \lim_{a\to 0} \int_{0}^{\infty} f(a, x)\sin x dx = 0 $$ It seems that we cannot use dominated convergence theorem since $\sin x\not\in L^{1}$. If the above statement is true, is there any other function than $\sin x$ which satisfies the property and can define the improper integral in this way?","I saw that physicists use the following integral  $$ \int_{0}^{\infty} \sin x dx = 1 $$ in a distribution sense, i.e.  $$ \int_{0}^{\infty} \sin x dx := \lim_{a\to 0} \int_{0}^{\infty} e^{-ax}\sin x dx = \lim_{a\to 0} \frac{1}{a^{2}+1} = 1 $$ However, I wonder we get the same value when we change the distribution part. For example, we have the following result (according to Wolfram alpha) $$ \lim_{a\to 0} \int_{0}^{\infty} e^{-ax^{2}}\sin x dx = \lim_{a\to 0}\frac{F\left(\frac{1}{2\sqrt{a}}\right)}{\sqrt{a}} = \lim_{a\to 0 }\frac{e^{-1/4a}}{\sqrt{a}}\int_{0}^{\frac{1}{2\sqrt{a}}}e^{y^{2}}dy =1  $$ where $F(x):=e^{-x^{2}}\int_{0}^{x}e^{y^{2}}dy$ is a Dawson's integral. To show this, we have to show the following : suppose a function $f:\mathbb{R}_{\geq 0}\times \mathbb{R}_{\geq 0}\to \mathbb{R}$ is continuous and the integral  $$ \int_{0}^{\infty} f(a, x)\sin x dx $$ converges for any $a\geq 0$. If $f(0, x)=0$ for all $x\geq 0$, we have $$ \lim_{a\to 0} \int_{0}^{\infty} f(a, x)\sin x dx = 0 $$ It seems that we cannot use dominated convergence theorem since $\sin x\not\in L^{1}$. If the above statement is true, is there any other function than $\sin x$ which satisfies the property and can define the improper integral in this way?",,"['integration', 'improper-integrals', 'distribution-theory']"
52,Generalizations of Integrals,Generalizations of Integrals,,"I've been studying dimensional regularization recently and found that some people view the divergent integrals, which are replaced by certain finite expressions in the regularization procedure, as existent because ""the regularization process provides the correct understanding what the integral really is"". Thus they see those expressions no longer as Lebesgue integrals but as objects of a kind for which they don't have a rigorous mathematical definition. I'm looking for such definitions. This has parallels in the study of divergent series, which may be Cesàro-summable for example. On the other hand, if one views series as special cases of Lebesgue integrals with (counting measure), only absolutely convergent series exist in Lebesgue sense. We thus have a vast theory of generalizations to Lebesgue integrals with counting measure. An often quoted reference seems to be Hardy's book ""Divergent Series"" although I'd be interested in more modern sources, as well as for asymptotic analysis! Apart from looking for such references,the question is: Are there generalizations of integrals over, say, $\mathbb{R}^n $ that (for example) do not require the absolute value of the integrand to be integrable as well? Generalizations in the style of Cesàro? Do such generalizations have something to do with regularization schemes? Are there connections to topics like distribution theory?","I've been studying dimensional regularization recently and found that some people view the divergent integrals, which are replaced by certain finite expressions in the regularization procedure, as existent because ""the regularization process provides the correct understanding what the integral really is"". Thus they see those expressions no longer as Lebesgue integrals but as objects of a kind for which they don't have a rigorous mathematical definition. I'm looking for such definitions. This has parallels in the study of divergent series, which may be Cesàro-summable for example. On the other hand, if one views series as special cases of Lebesgue integrals with (counting measure), only absolutely convergent series exist in Lebesgue sense. We thus have a vast theory of generalizations to Lebesgue integrals with counting measure. An often quoted reference seems to be Hardy's book ""Divergent Series"" although I'd be interested in more modern sources, as well as for asymptotic analysis! Apart from looking for such references,the question is: Are there generalizations of integrals over, say, $\mathbb{R}^n $ that (for example) do not require the absolute value of the integrand to be integrable as well? Generalizations in the style of Cesàro? Do such generalizations have something to do with regularization schemes? Are there connections to topics like distribution theory?",,"['integration', 'analysis', 'improper-integrals']"
53,What are the mathematical foundations of the renormalisation group?,What are the mathematical foundations of the renormalisation group?,,"Briefly, RG refers to mathematical tools that allows systematic investigation of the changes of a physical system as viewed at different distance scales. These methods are very important in quantum field theory and statistical mechanics. I'm currently taking a statistical physics course so I'm very curious about this. Sarada Rajeev , a physicist at the University of Rochester, says that 'a new integral calculus of functions of an infinite number of variables is needed' in order to give these methods a rigorous mathematical foundation. Update : In a correspondence where I was discussing how this would be different from variational calculus, I got the following reply from Professor Rajeev, Variational calculus is the differential calculus of an infinite   number of variables: paths. The corresponding integral calculus is the   ""path integral"" one pioneered by Weiner and Feynman. Although we have   the theory of integration over paths ( the space of functions of one   variable  (good enough for Stochastic ODEs and Quantum Mechanics) we   do not have it for for fields (functions of several variables).   Renormalization theory gives us hints on when such a theory is likely   to exist. Constructing it would be at least as important as the   discovery of Lebesgue integration. This statement by professor Rajeev is very interesting as it highlights the importance of such mathematical foundations(to him and many other mathematical physicists).","Briefly, RG refers to mathematical tools that allows systematic investigation of the changes of a physical system as viewed at different distance scales. These methods are very important in quantum field theory and statistical mechanics. I'm currently taking a statistical physics course so I'm very curious about this. Sarada Rajeev , a physicist at the University of Rochester, says that 'a new integral calculus of functions of an infinite number of variables is needed' in order to give these methods a rigorous mathematical foundation. Update : In a correspondence where I was discussing how this would be different from variational calculus, I got the following reply from Professor Rajeev, Variational calculus is the differential calculus of an infinite   number of variables: paths. The corresponding integral calculus is the   ""path integral"" one pioneered by Weiner and Feynman. Although we have   the theory of integration over paths ( the space of functions of one   variable  (good enough for Stochastic ODEs and Quantum Mechanics) we   do not have it for for fields (functions of several variables).   Renormalization theory gives us hints on when such a theory is likely   to exist. Constructing it would be at least as important as the   discovery of Lebesgue integration. This statement by professor Rajeev is very interesting as it highlights the importance of such mathematical foundations(to him and many other mathematical physicists).",,"['integration', 'reference-request']"
54,Integral of rational function over $\mathbb{H}^4$,Integral of rational function over,\mathbb{H}^4,"Suppose I have a rational function of $8$ coordinates $a,b,c,d,e,f,g,h$ that I want to integrate over $\mathbb{H}^4$: (256*b*d*f*(a^5 + b^4*(c - 2*e) - a^4*(3*c + 2*e) - c*(c^2 + d^2)*(e^2 + f^2) + a^3*(2*b^2 + 3*c^2 + d^2 + 6*c*e + e^2 + f^2) +      b^2*(c^3 - 2*c^2*e + 2*d^2*e + c*(d^2 - e^2 - f^2)) + a*(b^4 + 2*c^3*e + 2*c*d^2*e + 3*c^2*(e^2 + f^2) + d^2*(e^2 + f^2) +        b^2*(-c^2 - 3*d^2 + 6*c*e + e^2 + f^2)) - a^2*(c^3 + 6*c^2*e + 2*d^2*e + 2*b^2*(c + 2*e) + c*(d^2 + 3*(e^2 + f^2))))*(e - g)*h*    (c^5 + d^4*(e - 2*g) - c^4*(3*e + 2*g) - e*(e^2 + f^2)*(g^2 + h^2) + c^3*(2*d^2 + 3*e^2 + f^2 + 6*e*g + g^2 + h^2) +      d^2*(e^3 - 2*e^2*g + 2*f^2*g + e*(f^2 - g^2 - h^2)) + c*(d^4 + 2*e^3*g + 2*e*f^2*g + 3*e^2*(g^2 + h^2) + f^2*(g^2 + h^2) +        d^2*(-e^2 - 3*f^2 + 6*e*g + g^2 + h^2)) - c^2*(e^3 + 6*e^2*g + 2*f^2*g + 2*d^2*(e + 2*g) + e*(f^2 + 3*(g^2 + h^2)))))/   ((a^2 + b^2)*((-1 + c)^2 + d^2)*((b + d)^2 + (a - c)^2)*((b - d)^2 + (a - c)^2)*((b + f)^2 + (a - e)^2)*((b - f)^2 + (a - e)^2)*((d + f)^2 + (c - e)^2)*((d - f)^2 + (c - e)^2)*((d + h)^2 + (c - g)^2)*((d - h)^2 + (c - g)^2)*((f + h)^2 + (e - g)^2)*((f - h)^2 + (e - g)^2)) Here $\mathbb{H}^4$ is the Cartesian product of four copies of the upper half plane $\mathbb{H} = \mathbb{R} \times \mathbb{R}_{>0}$. That is, the integration bounds are given by $a \in (-\infty,\infty), b \in (0, \infty), \ldots, g\in (-\infty,\infty), h\in(0,\infty)$. I'd like to know the exact value of the integral, but accurate numerical approximations would also be appreciated. Since I have 9 more integrals of this type, general advice is also welcome. I tried some of Mathematica's methods, but I didn't succeed. The denominator factors as a product of $12$ quadratics of the form $x^2+y^2$: $$(a^2 + b^2)((c - 1)^2 + d^2)((b + d)^2 + (a - c)^2)((b - d)^2 + (a - c)^2)((b + f)^2 + (a - e)^2)((b - f)^2 + (a - e)^2)((d + f)^2 + (c - e)^2)((d - f)^2 + (c - e)^2)((d + h)^2 + (c - g)^2)((d - h)^2 + (c - g)^2)((f + h)^2 + (e - g)^2)((f - h)^2 + (e - g)^2)$$ If $x^2+y^2 = 0$ then $x=y=0$, so the set of singularities is a union of (restrictions of) strict linear subspaces. Also, we have that $x$ involves only $a,c,e,g \in (-\infty,\infty)$ and $y$ involves only $b,d,f,h \in (0, \infty)$. The numerator factors as $256bdfh(e-g)$ times $$a^5 + 2 a^3 b^2 + a b^4 - 3 a^4 c - 2 a^2 b^2 c + b^4 c + 3 a^3 c^2 -   a b^2 c^2 - a^2 c^3 + b^2 c^3 + a^3 d^2 - 3 a b^2 d^2 - a^2 c d^2 +   b^2 c d^2 - 2 a^4 e - 4 a^2 b^2 e - 2 b^4 e + 6 a^3 c e +   6 a b^2 c e - 6 a^2 c^2 e - 2 b^2 c^2 e + 2 a c^3 e - 2 a^2 d^2 e +   2 b^2 d^2 e + 2 a c d^2 e + a^3 e^2 + a b^2 e^2 - 3 a^2 c e^2 -   b^2 c e^2 + 3 a c^2 e^2 - c^3 e^2 + a d^2 e^2 - c d^2 e^2 + a^3 f^2 +   a b^2 f^2 - 3 a^2 c f^2 - b^2 c f^2 + 3 a c^2 f^2 - c^3 f^2 +   a d^2 f^2 - c d^2 f^2$$ times $$c^5 + 2 c^3 d^2 + c d^4 - 3 c^4 e - 2 c^2 d^2 e + d^4 e + 3 c^3 e^2 -   c d^2 e^2 - c^2 e^3 + d^2 e^3 + c^3 f^2 - 3 c d^2 f^2 - c^2 e f^2 +   d^2 e f^2 - 2 c^4 g - 4 c^2 d^2 g - 2 d^4 g + 6 c^3 e g +   6 c d^2 e g - 6 c^2 e^2 g - 2 d^2 e^2 g + 2 c e^3 g - 2 c^2 f^2 g +   2 d^2 f^2 g + 2 c e f^2 g + c^3 g^2 + c d^2 g^2 - 3 c^2 e g^2 -   d^2 e g^2 + 3 c e^2 g^2 - e^3 g^2 + c f^2 g^2 - e f^2 g^2 + c^3 h^2 +   c d^2 h^2 - 3 c^2 e h^2 - d^2 e h^2 + 3 c e^2 h^2 - e^3 h^2 +   c f^2 h^2 - e f^2 h^2,$$ and the latter two factors are both irreducible over $\mathbb{Q}$ according to Mathematica. The two factors have the same shape: the first is mapped to the second by $$a \mapsto c, \quad b \mapsto d,\quad c \mapsto e,\quad d \mapsto f,\quad e \mapsto g,\quad f \mapsto h.$$","Suppose I have a rational function of $8$ coordinates $a,b,c,d,e,f,g,h$ that I want to integrate over $\mathbb{H}^4$: (256*b*d*f*(a^5 + b^4*(c - 2*e) - a^4*(3*c + 2*e) - c*(c^2 + d^2)*(e^2 + f^2) + a^3*(2*b^2 + 3*c^2 + d^2 + 6*c*e + e^2 + f^2) +      b^2*(c^3 - 2*c^2*e + 2*d^2*e + c*(d^2 - e^2 - f^2)) + a*(b^4 + 2*c^3*e + 2*c*d^2*e + 3*c^2*(e^2 + f^2) + d^2*(e^2 + f^2) +        b^2*(-c^2 - 3*d^2 + 6*c*e + e^2 + f^2)) - a^2*(c^3 + 6*c^2*e + 2*d^2*e + 2*b^2*(c + 2*e) + c*(d^2 + 3*(e^2 + f^2))))*(e - g)*h*    (c^5 + d^4*(e - 2*g) - c^4*(3*e + 2*g) - e*(e^2 + f^2)*(g^2 + h^2) + c^3*(2*d^2 + 3*e^2 + f^2 + 6*e*g + g^2 + h^2) +      d^2*(e^3 - 2*e^2*g + 2*f^2*g + e*(f^2 - g^2 - h^2)) + c*(d^4 + 2*e^3*g + 2*e*f^2*g + 3*e^2*(g^2 + h^2) + f^2*(g^2 + h^2) +        d^2*(-e^2 - 3*f^2 + 6*e*g + g^2 + h^2)) - c^2*(e^3 + 6*e^2*g + 2*f^2*g + 2*d^2*(e + 2*g) + e*(f^2 + 3*(g^2 + h^2)))))/   ((a^2 + b^2)*((-1 + c)^2 + d^2)*((b + d)^2 + (a - c)^2)*((b - d)^2 + (a - c)^2)*((b + f)^2 + (a - e)^2)*((b - f)^2 + (a - e)^2)*((d + f)^2 + (c - e)^2)*((d - f)^2 + (c - e)^2)*((d + h)^2 + (c - g)^2)*((d - h)^2 + (c - g)^2)*((f + h)^2 + (e - g)^2)*((f - h)^2 + (e - g)^2)) Here $\mathbb{H}^4$ is the Cartesian product of four copies of the upper half plane $\mathbb{H} = \mathbb{R} \times \mathbb{R}_{>0}$. That is, the integration bounds are given by $a \in (-\infty,\infty), b \in (0, \infty), \ldots, g\in (-\infty,\infty), h\in(0,\infty)$. I'd like to know the exact value of the integral, but accurate numerical approximations would also be appreciated. Since I have 9 more integrals of this type, general advice is also welcome. I tried some of Mathematica's methods, but I didn't succeed. The denominator factors as a product of $12$ quadratics of the form $x^2+y^2$: $$(a^2 + b^2)((c - 1)^2 + d^2)((b + d)^2 + (a - c)^2)((b - d)^2 + (a - c)^2)((b + f)^2 + (a - e)^2)((b - f)^2 + (a - e)^2)((d + f)^2 + (c - e)^2)((d - f)^2 + (c - e)^2)((d + h)^2 + (c - g)^2)((d - h)^2 + (c - g)^2)((f + h)^2 + (e - g)^2)((f - h)^2 + (e - g)^2)$$ If $x^2+y^2 = 0$ then $x=y=0$, so the set of singularities is a union of (restrictions of) strict linear subspaces. Also, we have that $x$ involves only $a,c,e,g \in (-\infty,\infty)$ and $y$ involves only $b,d,f,h \in (0, \infty)$. The numerator factors as $256bdfh(e-g)$ times $$a^5 + 2 a^3 b^2 + a b^4 - 3 a^4 c - 2 a^2 b^2 c + b^4 c + 3 a^3 c^2 -   a b^2 c^2 - a^2 c^3 + b^2 c^3 + a^3 d^2 - 3 a b^2 d^2 - a^2 c d^2 +   b^2 c d^2 - 2 a^4 e - 4 a^2 b^2 e - 2 b^4 e + 6 a^3 c e +   6 a b^2 c e - 6 a^2 c^2 e - 2 b^2 c^2 e + 2 a c^3 e - 2 a^2 d^2 e +   2 b^2 d^2 e + 2 a c d^2 e + a^3 e^2 + a b^2 e^2 - 3 a^2 c e^2 -   b^2 c e^2 + 3 a c^2 e^2 - c^3 e^2 + a d^2 e^2 - c d^2 e^2 + a^3 f^2 +   a b^2 f^2 - 3 a^2 c f^2 - b^2 c f^2 + 3 a c^2 f^2 - c^3 f^2 +   a d^2 f^2 - c d^2 f^2$$ times $$c^5 + 2 c^3 d^2 + c d^4 - 3 c^4 e - 2 c^2 d^2 e + d^4 e + 3 c^3 e^2 -   c d^2 e^2 - c^2 e^3 + d^2 e^3 + c^3 f^2 - 3 c d^2 f^2 - c^2 e f^2 +   d^2 e f^2 - 2 c^4 g - 4 c^2 d^2 g - 2 d^4 g + 6 c^3 e g +   6 c d^2 e g - 6 c^2 e^2 g - 2 d^2 e^2 g + 2 c e^3 g - 2 c^2 f^2 g +   2 d^2 f^2 g + 2 c e f^2 g + c^3 g^2 + c d^2 g^2 - 3 c^2 e g^2 -   d^2 e g^2 + 3 c e^2 g^2 - e^3 g^2 + c f^2 g^2 - e f^2 g^2 + c^3 h^2 +   c d^2 h^2 - 3 c^2 e h^2 - d^2 e h^2 + 3 c e^2 h^2 - e^3 h^2 +   c f^2 h^2 - e f^2 h^2,$$ and the latter two factors are both irreducible over $\mathbb{Q}$ according to Mathematica. The two factors have the same shape: the first is mapped to the second by $$a \mapsto c, \quad b \mapsto d,\quad c \mapsto e,\quad d \mapsto f,\quad e \mapsto g,\quad f \mapsto h.$$",,"['integration', 'definite-integrals', 'numerical-methods', 'improper-integrals', 'contour-integration']"
55,Equivalence class of definite integrals,Equivalence class of definite integrals,,"Let's assume we have a smooth function $f(x):[a,b]\to \mathbb{R}$ so that the integral $$\int_a^b f(x) dx$$ is finite. By performing various changes of variables, we can derive a large (infinite?) number of different definite integrals which evaluate to the same value as the original integral. We could even introduce the concept of an equivalence class of definite integrals connected by a change of variables. Do such equivalence classes exist? Are they even remotely useful?","Let's assume we have a smooth function $f(x):[a,b]\to \mathbb{R}$ so that the integral $$\int_a^b f(x) dx$$ is finite. By performing various changes of variables, we can derive a large (infinite?) number of different definite integrals which evaluate to the same value as the original integral. We could even introduce the concept of an equivalence class of definite integrals connected by a change of variables. Do such equivalence classes exist? Are they even remotely useful?",,['integration']
56,Interesting Integral with Parameters,Interesting Integral with Parameters,,"I would like to compute the following integral: $$\int\frac{d^{2}\overrightarrow{q}}{2\pi}\int\frac{d^{2}\overrightarrow{k}}{2\pi}e^{i\overrightarrow{q}\cdot\overrightarrow{r}}\left(e^{i\overrightarrow{k}\cdot\overrightarrow{\rho_{1}}}-e^{i\overrightarrow{k}\cdot\overrightarrow{\rho_{2}}}\right)\frac{\overrightarrow{q}\cdot\overrightarrow{k}}{q^{2}k^{2}}\log^{2}\left(\frac{k^{2}}{q^{2}}\right)  $$ Where $q$ is the length of a two component vector. This integral appears in http://arxiv.org/pdf/0705.1885.pdf as eq (80) in the appendix. As I'm stuck for quite a long time, I recently talked to one of the authors of this paper and the sent me an explanation how to reproduce it: You represent $\log ^2$ as the second derivative w.r.t. $\nu$ at $\nu = 0$ according to  $\log ^2 (a) =\frac {\partial ^2} {\partial \nu ^2} \Big| _{\nu = 0} a^\nu$. Exponentiate all the denominators according to (74). Make full squares and Gauss-integrate out $q_1$ and $q_2$. Substitute $a_1=u z, a_2 = u (1-z), a_3= u z \frac {1-z} {\frac 1 t-1}$ and Gauss-integrate w.r.t. $u$. Decompose the result into simple fractions and drop the $\frac 1 t$ pole as it will not contribute after the differentiation. Integrate the rest w.r.t. $t$. Subtract the bare divergent at $\nu=0$ term $~ z^{-1+\nu}$ or something like that and add it. Integrate the term you added w.r.t. $z$ and then take its second derivative in $\nu$ and set $\nu =0$. Take the second derivative in $\nu$ of the rest and set $\nu =0$. It should not have divergences in $z$. You will have a dilogarithm   integral. Take it. In the sum of 8 and 9 you should get (80). Unfortunately, all the steps after step 5 are not clear to me. Can someone help me with that please? Your help is appreciated!","I would like to compute the following integral: $$\int\frac{d^{2}\overrightarrow{q}}{2\pi}\int\frac{d^{2}\overrightarrow{k}}{2\pi}e^{i\overrightarrow{q}\cdot\overrightarrow{r}}\left(e^{i\overrightarrow{k}\cdot\overrightarrow{\rho_{1}}}-e^{i\overrightarrow{k}\cdot\overrightarrow{\rho_{2}}}\right)\frac{\overrightarrow{q}\cdot\overrightarrow{k}}{q^{2}k^{2}}\log^{2}\left(\frac{k^{2}}{q^{2}}\right)  $$ Where $q$ is the length of a two component vector. This integral appears in http://arxiv.org/pdf/0705.1885.pdf as eq (80) in the appendix. As I'm stuck for quite a long time, I recently talked to one of the authors of this paper and the sent me an explanation how to reproduce it: You represent $\log ^2$ as the second derivative w.r.t. $\nu$ at $\nu = 0$ according to  $\log ^2 (a) =\frac {\partial ^2} {\partial \nu ^2} \Big| _{\nu = 0} a^\nu$. Exponentiate all the denominators according to (74). Make full squares and Gauss-integrate out $q_1$ and $q_2$. Substitute $a_1=u z, a_2 = u (1-z), a_3= u z \frac {1-z} {\frac 1 t-1}$ and Gauss-integrate w.r.t. $u$. Decompose the result into simple fractions and drop the $\frac 1 t$ pole as it will not contribute after the differentiation. Integrate the rest w.r.t. $t$. Subtract the bare divergent at $\nu=0$ term $~ z^{-1+\nu}$ or something like that and add it. Integrate the term you added w.r.t. $z$ and then take its second derivative in $\nu$ and set $\nu =0$. Take the second derivative in $\nu$ of the rest and set $\nu =0$. It should not have divergences in $z$. You will have a dilogarithm   integral. Take it. In the sum of 8 and 9 you should get (80). Unfortunately, all the steps after step 5 are not clear to me. Can someone help me with that please? Your help is appreciated!",,"['integration', 'fourier-series']"
57,A p-adic integral,A p-adic integral,,"Let $(K,||)$ be a finite extension of $\mathbb{Q}_p$ of degree $d$ such that the restriction of $||$ to $\mathbb{Q}_p$ is the usual p-adic absolute value. Endow $GL_n(K)$ with the unique Haar measure $d^{\times} \mu$ which gives mass $1$ to the compact subgroup $K = GL_n(\mathcal{O}_K) = SL_n(K) \cap M_n( \mathcal{O}_K )$. My question is the following : does the integral $$ I(s) = \int_{GL_n(K)} \mathrm{1}_{\psi \in M_n( \mathcal{O}_K )} |\det \psi|^{ds} d^{\times} \mu(\psi) $$ have an ""explicit"" expression ? The case $n=1$ is easy (if $q$ is the cardinality of the residue field of $K$, then $I = (1-q^{-s})^{-1}$) and I didn't succeeded in calculating $I(s)$ for general $n$.","Let $(K,||)$ be a finite extension of $\mathbb{Q}_p$ of degree $d$ such that the restriction of $||$ to $\mathbb{Q}_p$ is the usual p-adic absolute value. Endow $GL_n(K)$ with the unique Haar measure $d^{\times} \mu$ which gives mass $1$ to the compact subgroup $K = GL_n(\mathcal{O}_K) = SL_n(K) \cap M_n( \mathcal{O}_K )$. My question is the following : does the integral $$ I(s) = \int_{GL_n(K)} \mathrm{1}_{\psi \in M_n( \mathcal{O}_K )} |\det \psi|^{ds} d^{\times} \mu(\psi) $$ have an ""explicit"" expression ? The case $n=1$ is easy (if $q$ is the cardinality of the residue field of $K$, then $I = (1-q^{-s})^{-1}$) and I didn't succeeded in calculating $I(s)$ for general $n$.",,"['integration', 'p-adic-number-theory']"
58,Reinventing The Wheel - Part 1: The Riemann Integral [closed],Reinventing The Wheel - Part 1: The Riemann Integral [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Preface The core of any notion of integral is some sort of weighted sum: $$\sum b\mu(A)$$ Depending on wether the domain or range is decomposed these split into Riemann and Lebesgue type ones: $$\{A_i\}_{I \in I}: b_i\in fA_i$$ $$\{b_i\}_{I \in I}:A_i=f^{-1}\{b_i\}$$ In order to handle kinds of infinite sums one can introduce a notion of convergence: $$\lim_{\leq}$$ The crucial ingredient for uniqueness is a directed order together with a Hausdorff space: $$\leq\text{ directed}\\ \mathcal{T}\text{ Hausdorff}$$ (For more details see Hausdorffness vs Uniqueness .) (Besides, these two first facts, namely summation and convergence, are the ones that weak notions of integral exploit.) For Lebesgue type ones the natural notion of convergence fails; that is plain summation gives: $$f:[0,1]\to\mathbb{R}:f(x):=x:\quad\{\sum_{b\in B}b\mu(f^{-1}\{b\})\}_{\# B_0<\infty}=0\qquad B_0\leq B_0':\iff B_0\subseteq B_0'$$ For Riemann type ones this subtlety does not arise since it foots on collections of sets rather than elements. That will be the starting point of this article! Strategy & Goal The basic strategy of this article is to study a notion of integral of Riemann type under a suitable notion of convergence with: Hausdorff topological vector space: $V$ Measure space of possible infinite size: $\mu(\Omega)\leq\infty$ Integral of Riemann type: $I(f)=\lim_{\leq}\sum_{A\in\mathcal{A}}f(b)\mu(A)$ The primary goal will be to entail functions with poles and oscillations while retaining uniformly continuous functionsof the following form: Uniformly continuous: $I(f)\text{ exists}$ Poles: $f:(0,1]\to\mathbb{R}: f(x):=x^{\alpha>-1}$ Oscillation: $g:[1,\infty)\to\mathbb{R}: g(x):=\frac{1}{x}\sin(x)$ Definition Consider a sigma-finite complete measure space and a Banach space as well as Banach space valued functions: $$(\Omega,\Sigma,\mu)\text{ and }(E,\|\cdot\|) \text{ and }(\mathcal{F},\ldots)$$ Define the integral if it exists by: $$\int f\mathrm{d}\mu:=\lim_{(\Sigma_0,\leq)}\left\{\sum_{(A,a)\in\Sigma_0}\mu(A)f(a)\right\}_{\Sigma_0}$$ with the finite collections of disjoint measurable subsets of finite size: $$\Sigma_0\subseteq\Sigma: \qquad \#\Sigma_0<\infty\text{ as well as }\mu(A)<\infty\text{ and }A\cap B=\varnothing\text{ for }A\neq B,A,B\in\Sigma_0$$ being ordered by refinement and expansion: $$\Sigma_0\leq\Sigma_0':\iff\Sigma_0\dashv\Sigma_0',\Sigma_0\prec\Sigma_0'$$ where refinement and expansion are defined as: $$\Sigma_0\dashv\Sigma_0':\iff\forall A\in\Sigma_0\exists A'\in\Sigma_0':A\supseteq A'$$ $$\Sigma_0\prec\Sigma_0':\iff\cup_{A\in\Sigma_0}A\subseteq\cup_{A'\in\Sigma_0'}A'$$ In fact, these are considered as tagged collections but for better reading this is masked: $(A,a)\in\Sigma_0$ Note also that the collections are not required to actually cover the measure space: $\cup_{A\in\Sigma_0}A\subseteq\Omega$ The ordering of collections is chosen so to give the right result: $\int s\mathrm{d}\mu=\sum_{e\in \mathrm{im}s}\mu(s^{-1}\{e\})e$ Interpretation: This can be interpreted as the net of simple functions: $$s_{\Sigma_0}:=\sum_{(A,a)\in\Sigma_0}f(a)\chi_A$$ Then the above read: $$\int s_{\Sigma_0}\mathrm{d}\mu\to\int f\mathrm{d}\mu$$ Moreover for integrable functions the net of simple functions converges pointwise (proof?): $$\left(\int s_{\Sigma_0}\mathrm{d}\mu \to \int f\mathrm{d}\mu\right) \Rightarrow \left(s_{\Sigma_0}(\omega)\to f(\omega)\right)$$ (Note that it is claimed pointwise convergence everywhere rather than almost everywhere.) So the question arises how this Riemann type integral relates to the Lebesgue type integral by Bochner. (The crucial difference is that this approach considers the net of simple functions related to the function under consideration while the approach by Bochner considers some sequence of simple functions not necessarily related to the function under consideration.) Discussion: It turns out that this notion of integrability is very restrictive. A necessary condition on integrability is: $$\exists\mu(N)=0: \|f(\Omega\setminus N)\|<\infty$$ So though the first critical example won't be dissolved by this notion: $$f:(0,1]\to\mathbb{R}:x\mapsto \frac{1}{\sqrt{x}}$$ the second will be dissolved however: $$g:[1,\infty)\to\mathbb{R}:x\mapsto\frac{1}{x}\sin(x)$$ Especially no Lebesgue type integrability does imply this Riemann type integrability. However, a positive result is achieved on finite measure spaces. A sufficient condition on integrability is: $$\ldots$$ Absolute integrability does not imply integrability (example?). Regarding convergence theorems the uniform convergence theorem holds (proof?) but the dominated, monotone and Fatou convergence theorem fail (example?). Summary: $$\ldots$$","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Preface The core of any notion of integral is some sort of weighted sum: $$\sum b\mu(A)$$ Depending on wether the domain or range is decomposed these split into Riemann and Lebesgue type ones: $$\{A_i\}_{I \in I}: b_i\in fA_i$$ $$\{b_i\}_{I \in I}:A_i=f^{-1}\{b_i\}$$ In order to handle kinds of infinite sums one can introduce a notion of convergence: $$\lim_{\leq}$$ The crucial ingredient for uniqueness is a directed order together with a Hausdorff space: $$\leq\text{ directed}\\ \mathcal{T}\text{ Hausdorff}$$ (For more details see Hausdorffness vs Uniqueness .) (Besides, these two first facts, namely summation and convergence, are the ones that weak notions of integral exploit.) For Lebesgue type ones the natural notion of convergence fails; that is plain summation gives: $$f:[0,1]\to\mathbb{R}:f(x):=x:\quad\{\sum_{b\in B}b\mu(f^{-1}\{b\})\}_{\# B_0<\infty}=0\qquad B_0\leq B_0':\iff B_0\subseteq B_0'$$ For Riemann type ones this subtlety does not arise since it foots on collections of sets rather than elements. That will be the starting point of this article! Strategy & Goal The basic strategy of this article is to study a notion of integral of Riemann type under a suitable notion of convergence with: Hausdorff topological vector space: $V$ Measure space of possible infinite size: $\mu(\Omega)\leq\infty$ Integral of Riemann type: $I(f)=\lim_{\leq}\sum_{A\in\mathcal{A}}f(b)\mu(A)$ The primary goal will be to entail functions with poles and oscillations while retaining uniformly continuous functionsof the following form: Uniformly continuous: $I(f)\text{ exists}$ Poles: $f:(0,1]\to\mathbb{R}: f(x):=x^{\alpha>-1}$ Oscillation: $g:[1,\infty)\to\mathbb{R}: g(x):=\frac{1}{x}\sin(x)$ Definition Consider a sigma-finite complete measure space and a Banach space as well as Banach space valued functions: $$(\Omega,\Sigma,\mu)\text{ and }(E,\|\cdot\|) \text{ and }(\mathcal{F},\ldots)$$ Define the integral if it exists by: $$\int f\mathrm{d}\mu:=\lim_{(\Sigma_0,\leq)}\left\{\sum_{(A,a)\in\Sigma_0}\mu(A)f(a)\right\}_{\Sigma_0}$$ with the finite collections of disjoint measurable subsets of finite size: $$\Sigma_0\subseteq\Sigma: \qquad \#\Sigma_0<\infty\text{ as well as }\mu(A)<\infty\text{ and }A\cap B=\varnothing\text{ for }A\neq B,A,B\in\Sigma_0$$ being ordered by refinement and expansion: $$\Sigma_0\leq\Sigma_0':\iff\Sigma_0\dashv\Sigma_0',\Sigma_0\prec\Sigma_0'$$ where refinement and expansion are defined as: $$\Sigma_0\dashv\Sigma_0':\iff\forall A\in\Sigma_0\exists A'\in\Sigma_0':A\supseteq A'$$ $$\Sigma_0\prec\Sigma_0':\iff\cup_{A\in\Sigma_0}A\subseteq\cup_{A'\in\Sigma_0'}A'$$ In fact, these are considered as tagged collections but for better reading this is masked: $(A,a)\in\Sigma_0$ Note also that the collections are not required to actually cover the measure space: $\cup_{A\in\Sigma_0}A\subseteq\Omega$ The ordering of collections is chosen so to give the right result: $\int s\mathrm{d}\mu=\sum_{e\in \mathrm{im}s}\mu(s^{-1}\{e\})e$ Interpretation: This can be interpreted as the net of simple functions: $$s_{\Sigma_0}:=\sum_{(A,a)\in\Sigma_0}f(a)\chi_A$$ Then the above read: $$\int s_{\Sigma_0}\mathrm{d}\mu\to\int f\mathrm{d}\mu$$ Moreover for integrable functions the net of simple functions converges pointwise (proof?): $$\left(\int s_{\Sigma_0}\mathrm{d}\mu \to \int f\mathrm{d}\mu\right) \Rightarrow \left(s_{\Sigma_0}(\omega)\to f(\omega)\right)$$ (Note that it is claimed pointwise convergence everywhere rather than almost everywhere.) So the question arises how this Riemann type integral relates to the Lebesgue type integral by Bochner. (The crucial difference is that this approach considers the net of simple functions related to the function under consideration while the approach by Bochner considers some sequence of simple functions not necessarily related to the function under consideration.) Discussion: It turns out that this notion of integrability is very restrictive. A necessary condition on integrability is: $$\exists\mu(N)=0: \|f(\Omega\setminus N)\|<\infty$$ So though the first critical example won't be dissolved by this notion: $$f:(0,1]\to\mathbb{R}:x\mapsto \frac{1}{\sqrt{x}}$$ the second will be dissolved however: $$g:[1,\infty)\to\mathbb{R}:x\mapsto\frac{1}{x}\sin(x)$$ Especially no Lebesgue type integrability does imply this Riemann type integrability. However, a positive result is achieved on finite measure spaces. A sufficient condition on integrability is: $$\ldots$$ Absolute integrability does not imply integrability (example?). Regarding convergence theorems the uniform convergence theorem holds (proof?) but the dominated, monotone and Fatou convergence theorem fail (example?). Summary: $$\ldots$$",,"['integration', 'general-topology', 'functional-analysis', 'banach-spaces', 'lebesgue-integral']"
59,How do I evaluate this integral $\int_0^\pi{\frac{{{x^2}}}{{\sqrt 5-2\cos x}}}\operatorname d\!x$?,How do I evaluate this integral ?,\int_0^\pi{\frac{{{x^2}}}{{\sqrt 5-2\cos x}}}\operatorname d\!x,"Show that $$\int\limits_0^\pi{\frac{{{x^2}}}{{\sqrt 5-2\cos x}}}\operatorname d\!x =\frac{{{\pi^3}}}{{15}}+2\pi \ln^2 \left({\frac{{1+\sqrt 5 }}{2}}\right).$$ I don't have any idea how to start, but maybe I could use the Polylogarithm .","Show that $$\int\limits_0^\pi{\frac{{{x^2}}}{{\sqrt 5-2\cos x}}}\operatorname d\!x =\frac{{{\pi^3}}}{{15}}+2\pi \ln^2 \left({\frac{{1+\sqrt 5 }}{2}}\right).$$ I don't have any idea how to start, but maybe I could use the Polylogarithm .",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
60,What is the easiest way to integrate $\left(\frac{1-x}{1+x}\right)^{1/2}?$,What is the easiest way to integrate,\left(\frac{1-x}{1+x}\right)^{1/2}?,"This is an indefinite integral that's supposed to be very easy: $$I=\int\sqrt{\frac{1-x}{1+x}}\,dx$$ I can only think of one way of calculating it, and it's a bit complicated, that is: substitute $x=\sin u$, and obtain $dx=(\cos u)\,du$ and $$I=\int\sqrt{\frac{1-\sin u}{1+\sin u}}(\cos u) \,du=\int\frac{1-\tan\frac{u}{2}}{1+\tan\frac{u}{2}}(\cos u)\,du.$$ substitute $t=\tan \dfrac u2$, obtaining $du=\dfrac{2\,dt}{1+t^2},$ $\cos u=\dfrac{1-t^2}{1+t^2}$ and $$I=\int \frac{1-t}{1+t}\frac{1-t^2}{1+t^2}\frac2{1+t^2}\,dt=2\int\left(\frac{1-t}{1+t}\right)^2\,dt,$$ which can be calculated. I'm not even sure if this is correct though. But even if it is, I think this way is too difficult for the place in which I found this integral, which is a set of indefinite integrals where obvious substitutions work and no knowledge is necessary beyond how substitution works in general. I think there must be an easy way to do it that I don't see.","This is an indefinite integral that's supposed to be very easy: $$I=\int\sqrt{\frac{1-x}{1+x}}\,dx$$ I can only think of one way of calculating it, and it's a bit complicated, that is: substitute $x=\sin u$, and obtain $dx=(\cos u)\,du$ and $$I=\int\sqrt{\frac{1-\sin u}{1+\sin u}}(\cos u) \,du=\int\frac{1-\tan\frac{u}{2}}{1+\tan\frac{u}{2}}(\cos u)\,du.$$ substitute $t=\tan \dfrac u2$, obtaining $du=\dfrac{2\,dt}{1+t^2},$ $\cos u=\dfrac{1-t^2}{1+t^2}$ and $$I=\int \frac{1-t}{1+t}\frac{1-t^2}{1+t^2}\frac2{1+t^2}\,dt=2\int\left(\frac{1-t}{1+t}\right)^2\,dt,$$ which can be calculated. I'm not even sure if this is correct though. But even if it is, I think this way is too difficult for the place in which I found this integral, which is a set of indefinite integrals where obvious substitutions work and no knowledge is necessary beyond how substitution works in general. I think there must be an easy way to do it that I don't see.",,['integration']
61,Example where $\int |f(x)| dx$ is infinite and $\int |f(x)|^2 dx$ is finite,Example where  is infinite and  is finite,\int |f(x)| dx \int |f(x)|^2 dx,"I read in a book that the condition $\int |f(x)|^2 dx <\infty$ is less restrictive than $\int |f(x)| dx <\infty$. That means whenever $\int |f(x)| dx$ is finite, $\int |f(x)|^2 dx$ is also finite, right? My understanding is that $|f(x)|$ may have a thick tail to make the integral blow up, but $|f(x)|^2$ may decay quickly enough to have a finite integral. Can someone give me an example that $\int |f(x)| dx=\infty$ but $\int |f(x)|^2 dx <\infty$. Suppose $f(x)$ is an absolutely continous function and bounded on $(-\infty, \infty)$.","I read in a book that the condition $\int |f(x)|^2 dx <\infty$ is less restrictive than $\int |f(x)| dx <\infty$. That means whenever $\int |f(x)| dx$ is finite, $\int |f(x)|^2 dx$ is also finite, right? My understanding is that $|f(x)|$ may have a thick tail to make the integral blow up, but $|f(x)|^2$ may decay quickly enough to have a finite integral. Can someone give me an example that $\int |f(x)| dx=\infty$ but $\int |f(x)|^2 dx <\infty$. Suppose $f(x)$ is an absolutely continous function and bounded on $(-\infty, \infty)$.",,['integration']
62,How to evaluate $\frac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta $?,How to evaluate ?,\frac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta ,How to evaluate the integral given below? $$\dfrac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta $$,How to evaluate the integral given below? $$\dfrac{1}{2\pi }\int_{-\pi }^{\pi }\dfrac{\sin n\theta }{\sin\theta }d\theta $$,,"['integration', 'definite-integrals']"
63,"Computing the indefinite integral $\int x^n \sin x\,dx$",Computing the indefinite integral,"\int x^n \sin x\,dx","$\newcommand{\term}[3]{   \sum_{k=0}^{\lfloor #1/2 \rfloor} (-1)^{#2} x^{#3} \frac{n!}{(#3)!} }$ I am trying to prove that for $n \in\mathbb N$, $$ \int x^n \sin x \, dx = \cos x \term{n}{k+1}{n-2k} + \sin x \term{(n-1)}{k}{n-2k-1} $$ I started with differentiation, and this is what I got: If we define $f(x)$ as $$ f(x) = \cos x \term{n}{k+1}{n-2k} + \sin x \term{n-1}{k}{n-2k-1} $$ then we have $$ \begin{align*} f’(x) &= \cos x \term{n}{k+1}{n-2k-1}  - \sin x \term{n}{k+1}{n-2k} \\ &\qquad  + \sin x \term{(n-1)}{k}{n-2k-2}  + \cos x \term{(n-1)}{k}{n-2k-1} \\[8pt] &= \cos x \left[    \term{n}{k+1}{n-2k-1}  + \term{(n-1)}{k}{n-2k-1} \right] \\ &\qquad  + \sin x \left[    \term{(n-1)}{k}{n-2k-2}  - \term{n}{k+1}{n-2k} \right] \end{align*} $$ I don't know how to go on, because of the different limits of the sum with $\lfloor{n/2}\rfloor$ and $\lfloor{(n-1)/2}\rfloor$.","$\newcommand{\term}[3]{   \sum_{k=0}^{\lfloor #1/2 \rfloor} (-1)^{#2} x^{#3} \frac{n!}{(#3)!} }$ I am trying to prove that for $n \in\mathbb N$, $$ \int x^n \sin x \, dx = \cos x \term{n}{k+1}{n-2k} + \sin x \term{(n-1)}{k}{n-2k-1} $$ I started with differentiation, and this is what I got: If we define $f(x)$ as $$ f(x) = \cos x \term{n}{k+1}{n-2k} + \sin x \term{n-1}{k}{n-2k-1} $$ then we have $$ \begin{align*} f’(x) &= \cos x \term{n}{k+1}{n-2k-1}  - \sin x \term{n}{k+1}{n-2k} \\ &\qquad  + \sin x \term{(n-1)}{k}{n-2k-2}  + \cos x \term{(n-1)}{k}{n-2k-1} \\[8pt] &= \cos x \left[    \term{n}{k+1}{n-2k-1}  + \term{(n-1)}{k}{n-2k-1} \right] \\ &\qquad  + \sin x \left[    \term{(n-1)}{k}{n-2k-2}  - \term{n}{k+1}{n-2k} \right] \end{align*} $$ I don't know how to go on, because of the different limits of the sum with $\lfloor{n/2}\rfloor$ and $\lfloor{(n-1)/2}\rfloor$.",,['integration']
64,Evaluate an absolute monster integral $\int\limits_{0}^{1} \frac{\log(1-x+x^2)}{\sqrt{x}(1+x)}\mathrm{d}x.$,Evaluate an absolute monster integral,\int\limits_{0}^{1} \frac{\log(1-x+x^2)}{\sqrt{x}(1+x)}\mathrm{d}x.,"I want to figure out a way to evaluate $$\int\limits_{0}^{1} \frac{\log(1-x+x^2)}{\sqrt{x}(1+x)}\mathrm{d}x.$$ I tried to substitute $x = u^2$ and cancel the square root in the denominator, getting $$2\int\limits_{0}^{1} \frac{\log(1-u^2+u^4)}{1+u^2}\mathrm{d}u.$$ But now I am stuck again.","I want to figure out a way to evaluate I tried to substitute and cancel the square root in the denominator, getting But now I am stuck again.",\int\limits_{0}^{1} \frac{\log(1-x+x^2)}{\sqrt{x}(1+x)}\mathrm{d}x. x = u^2 2\int\limits_{0}^{1} \frac{\log(1-u^2+u^4)}{1+u^2}\mathrm{d}u.,"['integration', 'improper-integrals']"
65,About an integral of the MIT Integration Bee Finals (2023),About an integral of the MIT Integration Bee Finals (2023),,"I would like to solve the first problem of the MIT Integration Bee Finals, which is the following integral : $$\int_0^{\frac{\pi}{2}} \frac{\sqrt[3]{\tan(x)}}{(\cos(x) + \sin(x))^2}dx$$ I tried substitution $u=\tan(x)$ , King Property, but nothing leads me to the solution which is apparently $\frac{2\sqrt{3}}{9} \pi$ . If anybody knows how to solve it I would be grateful.","I would like to solve the first problem of the MIT Integration Bee Finals, which is the following integral : I tried substitution , King Property, but nothing leads me to the solution which is apparently . If anybody knows how to solve it I would be grateful.",\int_0^{\frac{\pi}{2}} \frac{\sqrt[3]{\tan(x)}}{(\cos(x) + \sin(x))^2}dx u=\tan(x) \frac{2\sqrt{3}}{9} \pi,"['integration', 'trigonometry']"
66,How to evaluate integral: $ \int_{0}^{\infty} e^{-x}\left|\sin{x}\right| \ dx $,How to evaluate integral:, \int_{0}^{\infty} e^{-x}\left|\sin{x}\right| \ dx ,I try to evaluate integral below.I solved indefinite integral but after evaluating limit I get wrong result.I don't know where can be problem.Maybe I just use the wrong method? $$ \int_{0}^{\infty} e^{-x}\left|\sin{x}\right| \ dx= $$ $$=  \left[ -\frac{1}{2}e^{-x}\operatorname{sgn}\left(\sin{x}\right)\left(\sin{x}+\cos{x}\right)\right]_0^\infty $$,I try to evaluate integral below.I solved indefinite integral but after evaluating limit I get wrong result.I don't know where can be problem.Maybe I just use the wrong method?, \int_{0}^{\infty} e^{-x}\left|\sin{x}\right| \ dx=  =  \left[ -\frac{1}{2}e^{-x}\operatorname{sgn}\left(\sin{x}\right)\left(\sin{x}+\cos{x}\right)\right]_0^\infty ,"['integration', 'definite-integrals', 'improper-integrals']"
67,Improper integral of natural log over a quadratic,Improper integral of natural log over a quadratic,,"I need to evaluate  $$\int\limits_0^{+\infty}\frac{\ln{x}}{x^2+x+1}\,\mathrm{d}x\,.$$ I don't know how to integrate this, and for the most part, I don't even think it is expressible as elementary functions. In that case, how would I even manipulate the integral using some $u$-substitution to transform this into some integrable function? Or can this all be done without actual integration , and just some clever substitution to somehow find a multiple of this integral's value?","I need to evaluate  $$\int\limits_0^{+\infty}\frac{\ln{x}}{x^2+x+1}\,\mathrm{d}x\,.$$ I don't know how to integrate this, and for the most part, I don't even think it is expressible as elementary functions. In that case, how would I even manipulate the integral using some $u$-substitution to transform this into some integrable function? Or can this all be done without actual integration , and just some clever substitution to somehow find a multiple of this integral's value?",,"['integration', 'improper-integrals']"
68,Finding volumes — when to use double integrals and triple integrals?,Finding volumes — when to use double integrals and triple integrals?,,"This is not a technical question at all, but I'm quite confused about what should I use to compute volumes in $\mathbb{R}^3$ with integration. I've read somewhere that a double integral gets the volume swapping across the $x$ and $y$ axis while a triple integral just integrate the whole thing at once, how accurate is this? Can a volume expressed by a double integral be expressed by a triple integral?, And can a triple always be expressed by a double? This one doesn't seem true, but I don't have a good answer to why. I also found this comments while reading openstudy.com made by someone named  KingGeorge one year ago: For a double integral you have to integrate some function, for a triple integral, you integrate 1. Does this mean that using an integral to get a volume always should look like $\iiint  dxdydz$ without any function? Geometrically, there are a few things you can be looking at. One, you're finding a 4-volume. That is, the 4-dimensional equivalent of volume. Two, if the volume in the region you're integrating in has a changing density, you could be finding the total mass. I'm not sure if I understand correctly, but this means that a triple integral does not compute exactly the volume I want but a 4-D equivalent?.","This is not a technical question at all, but I'm quite confused about what should I use to compute volumes in with integration. I've read somewhere that a double integral gets the volume swapping across the and axis while a triple integral just integrate the whole thing at once, how accurate is this? Can a volume expressed by a double integral be expressed by a triple integral?, And can a triple always be expressed by a double? This one doesn't seem true, but I don't have a good answer to why. I also found this comments while reading openstudy.com made by someone named  KingGeorge one year ago: For a double integral you have to integrate some function, for a triple integral, you integrate 1. Does this mean that using an integral to get a volume always should look like without any function? Geometrically, there are a few things you can be looking at. One, you're finding a 4-volume. That is, the 4-dimensional equivalent of volume. Two, if the volume in the region you're integrating in has a changing density, you could be finding the total mass. I'm not sure if I understand correctly, but this means that a triple integral does not compute exactly the volume I want but a 4-D equivalent?.",\mathbb{R}^3 x y \iiint  dxdydz,"['integration', 'multivariable-calculus', 'volume', 'multiple-integral']"
69,"How to evaluate $\int\limits^1_0 \sqrt{1+\frac{1}{x}}\, \text{d}x$",How to evaluate,"\int\limits^1_0 \sqrt{1+\frac{1}{x}}\, \text{d}x","I need to calculate the length of a curve $y=2\sqrt{x}$ from $x=0$ to $x=1$. So I started by taking $\int\limits^1_0 \sqrt{1+\frac{1}{x}}\, \text{d}x$, and then doing substitution: $\left[u = 1+\frac{1}{x}, \text{d}u = \frac{-1}{x^2}\text{d}x \Rightarrow -\text{d}u = \frac{1}{x^2}\text{d}x \right]^1_0 = -\int\limits^1_0 \sqrt{u} \,\text{d}u$ but this obviously will not lead to the correct answer, since $\frac{1}{x^2}$ isn't in the original formula. Wolfram Alpha is doing a lot of steps for this integration, but I don't think that many steps are needed. How would I start with this integration?","I need to calculate the length of a curve $y=2\sqrt{x}$ from $x=0$ to $x=1$. So I started by taking $\int\limits^1_0 \sqrt{1+\frac{1}{x}}\, \text{d}x$, and then doing substitution: $\left[u = 1+\frac{1}{x}, \text{d}u = \frac{-1}{x^2}\text{d}x \Rightarrow -\text{d}u = \frac{1}{x^2}\text{d}x \right]^1_0 = -\int\limits^1_0 \sqrt{u} \,\text{d}u$ but this obviously will not lead to the correct answer, since $\frac{1}{x^2}$ isn't in the original formula. Wolfram Alpha is doing a lot of steps for this integration, but I don't think that many steps are needed. How would I start with this integration?",,"['integration', 'definite-integrals']"
70,"Find $\int_1^\infty \frac{\{x\}}{x(x+1)}dx,$ where $\{x\}$ means $x - \lfloor x \rfloor$.",Find  where  means .,"\int_1^\infty \frac{\{x\}}{x(x+1)}dx, \{x\} x - \lfloor x \rfloor","Question: Find $\int_1^\infty \frac{\{x\}}{x(x+1)}dx,$ where $\{x\}$ means $x - \lfloor x \rfloor$ . I have attempted to split this into two integrals, namely $$\int_1^\infty \frac{x}{x(x+1)}dx - \int_1^\infty \frac{\lfloor x \rfloor}{x(x+1)}dx,$$ however did not get anywhere. I have also considered that the average value of $\{x\}$ is $\frac{1}{2}$ (I think). With mostly just instincts and jotting down a few numbers, I obtained an answer of $\ln{\sqrt{2}}$ , which seems reasonable since Desmos approximated the answer (when the upper limit is large) as 0.30… I am only 17 so try to keep notation at my level, though this shouldn't really involve anything too complicated.","Question: Find where means . I have attempted to split this into two integrals, namely however did not get anywhere. I have also considered that the average value of is (I think). With mostly just instincts and jotting down a few numbers, I obtained an answer of , which seems reasonable since Desmos approximated the answer (when the upper limit is large) as 0.30… I am only 17 so try to keep notation at my level, though this shouldn't really involve anything too complicated.","\int_1^\infty \frac{\{x\}}{x(x+1)}dx, \{x\} x - \lfloor x \rfloor \int_1^\infty \frac{x}{x(x+1)}dx - \int_1^\infty \frac{\lfloor x \rfloor}{x(x+1)}dx, \{x\} \frac{1}{2} \ln{\sqrt{2}}","['integration', 'definite-integrals', 'ceiling-and-floor-functions', 'fractional-part']"
71,"Solve $ \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx $",Solve," \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx ","I haven't seen this question, but if someone has, it would be very appreciated if you could send a link! I've been very interested in the MIT Integration Bee, and one question that stood out to me was: $$ \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx $$ I tried rewriting a couple of ways to simplify it, but nothing seemed to help. According to the official MIT Integration Bee website, the answer is $$ \frac{19}{6} $$ Thanks!","I haven't seen this question, but if someone has, it would be very appreciated if you could send a link! I've been very interested in the MIT Integration Bee, and one question that stood out to me was: I tried rewriting a couple of ways to simplify it, but nothing seemed to help. According to the official MIT Integration Bee website, the answer is Thanks!"," \int_0^2 \sqrt{x+\sqrt{x+\sqrt{x+\dotsb}}}\,dx   \frac{19}{6} ","['integration', 'definite-integrals', 'nested-radicals']"
72,Two apparently different antiderivatives of $\frac{1}{2 x}$ [duplicate],Two apparently different antiderivatives of  [duplicate],\frac{1}{2 x},"This question already has answers here : Two different solutions to integral (3 answers) Closed 5 years ago . What is right way to calculate this integral and why? $$ \int\frac{1}{2x}\text dx $$ I thought, that this substitution is right: $$ t = 2x $$ $$ \text dt = 2\text dx $$ $$ \frac{\text dt}{2} = \text dx $$ $$ \int\frac{1}{2x}\text dx=\int\frac{1}{t}\frac{\text dt}{2}=\frac{1}{2}\ln|2x| + C . $$ But it's not right, because this is the correct answer: $$ \int\frac{1}{2x}\text dx=\frac{1}{2}\int\frac{1}{x}\text dx=\frac{1}{2}\ln|x| + C . $$ Can someone explain me, why is the first way wrong? When I derive both results, I get the same result.","This question already has answers here : Two different solutions to integral (3 answers) Closed 5 years ago . What is right way to calculate this integral and why? $$ \int\frac{1}{2x}\text dx $$ I thought, that this substitution is right: $$ t = 2x $$ $$ \text dt = 2\text dx $$ $$ \frac{\text dt}{2} = \text dx $$ $$ \int\frac{1}{2x}\text dx=\int\frac{1}{t}\frac{\text dt}{2}=\frac{1}{2}\ln|2x| + C . $$ But it's not right, because this is the correct answer: $$ \int\frac{1}{2x}\text dx=\frac{1}{2}\int\frac{1}{x}\text dx=\frac{1}{2}\ln|x| + C . $$ Can someone explain me, why is the first way wrong? When I derive both results, I get the same result.",,"['integration', 'indefinite-integrals']"
73,Integrals inequality,Integrals inequality,,I have $$A=\int_1^5{\frac{e^x}{e^x+x^2}dx}$$ $$B=\int_1^5{\frac{x^2}{e^x+x^2}dx}$$ I have already found that $A+B=4$ but now I want to prove that $AB\le4$. I don't know how. I am thinking of using the properties of integrals but nothing seems to work out for me. Any ideas?,I have $$A=\int_1^5{\frac{e^x}{e^x+x^2}dx}$$ $$B=\int_1^5{\frac{x^2}{e^x+x^2}dx}$$ I have already found that $A+B=4$ but now I want to prove that $AB\le4$. I don't know how. I am thinking of using the properties of integrals but nothing seems to work out for me. Any ideas?,,"['integration', 'inequality', 'definite-integrals']"
74,Help for evaluating complicated integral $\int \frac 1 {x^n-x} dx$,Help for evaluating complicated integral,\int \frac 1 {x^n-x} dx,"I have this complicated integral to evaluate : $$\int \dfrac 1 {x^n-x} dx$$ I'm struggling to evaluate this. My attempt : $$\int \dfrac1x \cdot \dfrac 1 {x^{n-1}-1} dx$$  Now, I try to apply integration by parts. For that, I use : $V=\large\dfrac1x$ and $U=\large\dfrac 1 {x^{n-1}-1}$ But, that doesnt take me anywhere. It just gives me an even more complicated expression to evaluate.. Help would be appreciated.. Thank you..","I have this complicated integral to evaluate : $$\int \dfrac 1 {x^n-x} dx$$ I'm struggling to evaluate this. My attempt : $$\int \dfrac1x \cdot \dfrac 1 {x^{n-1}-1} dx$$  Now, I try to apply integration by parts. For that, I use : $V=\large\dfrac1x$ and $U=\large\dfrac 1 {x^{n-1}-1}$ But, that doesnt take me anywhere. It just gives me an even more complicated expression to evaluate.. Help would be appreciated.. Thank you..",,['integration']
75,"Use of the word ""solve""?","Use of the word ""solve""?",,"This is not a mathematical question, but just a matter of terminology. I don't understand why so many people (especially on MSE) want to solve integrals. It makes sense for me (linguistically speaking) to solve an equation or to solve a problem, but definitely not to solve an integral: instead, I would just say compute . So, I would like to know if ""to solve an integral"" is correct English. Needless to say, English is not my native language...","This is not a mathematical question, but just a matter of terminology. I don't understand why so many people (especially on MSE) want to solve integrals. It makes sense for me (linguistically speaking) to solve an equation or to solve a problem, but definitely not to solve an integral: instead, I would just say compute . So, I would like to know if ""to solve an integral"" is correct English. Needless to say, English is not my native language...",,"['integration', 'terminology']"
76,How can we evaluate $\int_{0}^{\infty}e^{-xt}\sin(t)dt$ without using Laplace transforms?,How can we evaluate  without using Laplace transforms?,\int_{0}^{\infty}e^{-xt}\sin(t)dt,"Without using Laplace transforms, how do I show that for every positive number $x$ the following equation is valid? $$\int_{0}^{\infty}e^{-xt}\sin(t)dt=\frac{1}{x^2+1}. $$","Without using Laplace transforms, how do I show that for every positive number $x$ the following equation is valid? $$\int_{0}^{\infty}e^{-xt}\sin(t)dt=\frac{1}{x^2+1}. $$",,"['complex-analysis', 'integration']"
77,Calculate $ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n+1} H_n$ [duplicate],Calculate  [duplicate], \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n+1} H_n,"This question already exists : On a series involving harmonic numbers Closed 3 years ago . Define $$ H_n = \sum_{k=1}^n \frac{1}{k} $$ I need to calculate the sum $$ S = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n+1} H_n $$ Using the following integral representation of $ H_n$ $$ H_n = -n \int_0^1 x^{n-1}\ln(1-x) dx $$ and exchanging the order of summation, I obtained $$ S = -\int_0^1 \left(\frac{1}{1+x}+\frac{\ln(1+x)-x}{x^2}\right) \ln(1-x) dx $$ Using Wolfram Alpha, I got $$ S \approx 0.240227 $$ so I guess $$ S = \frac{(\ln 2)^2}{2} $$ But I don't know how to calculate the integral. Any idea?","This question already exists : On a series involving harmonic numbers Closed 3 years ago . Define I need to calculate the sum Using the following integral representation of and exchanging the order of summation, I obtained Using Wolfram Alpha, I got so I guess But I don't know how to calculate the integral. Any idea?","
H_n = \sum_{k=1}^n \frac{1}{k}
 
S = \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n+1} H_n
  H_n 
H_n = -n \int_0^1 x^{n-1}\ln(1-x) dx
 
S = -\int_0^1 \left(\frac{1}{1+x}+\frac{\ln(1+x)-x}{x^2}\right) \ln(1-x) dx
 
S \approx 0.240227
 
S = \frac{(\ln 2)^2}{2}
","['integration', 'sequences-and-series', 'limits']"
78,Prove $\int_{0}^{\infty}\frac{|\sin x|\sin x}{x}dx=1$,Prove,\int_{0}^{\infty}\frac{|\sin x|\sin x}{x}dx=1,"Prove $$\int_{0}^{\infty}\frac{|\sin x|\sin x}{x}dx=1.$$ I know how to calculate $\int_{0}^{\infty}\frac{\sin x}{x}dx=\frac{\pi}{2}$ , but the method cannot be applied here. So I am thinking $$\sum_{k=0}^n(-1)^k\int_{k\pi}^{(k+1)\pi}\frac{\sin^2 x}{x}dx$$ but I don't know how to proceed.","Prove I know how to calculate , but the method cannot be applied here. So I am thinking but I don't know how to proceed.",\int_{0}^{\infty}\frac{|\sin x|\sin x}{x}dx=1. \int_{0}^{\infty}\frac{\sin x}{x}dx=\frac{\pi}{2} \sum_{k=0}^n(-1)^k\int_{k\pi}^{(k+1)\pi}\frac{\sin^2 x}{x}dx,['integration']
79,Why do I get two different answers when solving for arclength?,Why do I get two different answers when solving for arclength?,,"I am given that $\frac{dx}{dt}=8t\cos(t)$ and $\frac{dy}{dt}=8t\sin(t)$ . I tried solving for the arclength from $t=0$ to $t=1.$ Method 1: $$\text{Arclength} = \int_{0}^{1} \sqrt{\left(\frac{dx}{dt}\right)^2+\left(\frac{dy}{dt}\right)^2} dx = 4.$$ Method 2: $$\text{Arclength} = \int_{0}^{1} \sqrt{1+\left(\frac{dy}{dx}\right)^2} dx.$$ However, when I solve using method 2, I get $1.22619,$ when the answer should be $4.$ What is causing this difference?","I am given that and . I tried solving for the arclength from to Method 1: Method 2: However, when I solve using method 2, I get when the answer should be What is causing this difference?","\frac{dx}{dt}=8t\cos(t) \frac{dy}{dt}=8t\sin(t) t=0 t=1. \text{Arclength} = \int_{0}^{1} \sqrt{\left(\frac{dx}{dt}\right)^2+\left(\frac{dy}{dt}\right)^2} dx = 4. \text{Arclength} = \int_{0}^{1} \sqrt{1+\left(\frac{dy}{dx}\right)^2} dx. 1.22619, 4.","['integration', 'arc-length']"
80,"Prove $\int_{\frac{\pi}{20}}^{\frac{3\pi}{20}} \ln \tan x\,\,dx= - \frac{2G}{5}$",Prove,"\int_{\frac{\pi}{20}}^{\frac{3\pi}{20}} \ln \tan x\,\,dx= - \frac{2G}{5}","Context: This question asks to calculate a definite integral which turns out to be equal to $$\displaystyle 4 \, \text{Ti}_2\left( \tan \frac{3\pi}{20} \right) - 4 \, \text{Ti}_2\left( \tan \frac{\pi}{20} \right),$$ where $\text{Ti}_2(x) = \operatorname{Im}\text{Li}_2( i\, x)$ is the Inverse Tangent Integral function. The source for this integral is this question on brilliant.org. In a comment , the OP claims that the closed form can be further simplified to $-\dfrac\pi5 \ln\left( 124 - 55\sqrt5 + 2\sqrt{7625 - 3410\sqrt5} \right) + \dfrac85 G$ . How can we prove that? I have thought about using the formula $$\text{Ti}_2(\tan x) = x \ln \tan x+ \sum_{n=0}^{\infty} \frac{\sin(2x(2n+1))}{(2n+1)^2}. \tag{1}$$ but that only mildly simplifies the problem. Equivalent formulations include: $$\, \text{Ti}_2\left( \tan \frac{3\pi}{20} \right) -  \, \text{Ti}_2\left( \tan \frac{\pi}{20} \right) \stackrel?= \frac{ \pi}{20} \ln \frac{  \tan^3( 3\pi/20)}{\tan ( \pi/20)}   + \frac{2 G}{5} \tag{2}$$ $$ \sum_{n=0}^{\infty} \frac{\sin \left(\frac{3\pi}{10}(2n+1) \right)- \sin \left(\frac{\pi}{10}(2n+1)\right)}{(2n+1)^2} \stackrel?=\ \frac{2G}{5} \tag{3}$$ $$\int_{\pi/20}^{3\pi/20} \ln \tan x\,\,dx \stackrel?= - \frac{2G}{5} \tag{4}$$ A related similar question is this one.","Context: This question asks to calculate a definite integral which turns out to be equal to where is the Inverse Tangent Integral function. The source for this integral is this question on brilliant.org. In a comment , the OP claims that the closed form can be further simplified to . How can we prove that? I have thought about using the formula but that only mildly simplifies the problem. Equivalent formulations include: A related similar question is this one.","\displaystyle 4 \, \text{Ti}_2\left( \tan \frac{3\pi}{20} \right) -
4 \, \text{Ti}_2\left( \tan \frac{\pi}{20} \right), \text{Ti}_2(x) = \operatorname{Im}\text{Li}_2( i\, x) -\dfrac\pi5 \ln\left( 124 - 55\sqrt5 + 2\sqrt{7625 - 3410\sqrt5} \right) + \dfrac85 G \text{Ti}_2(\tan x) = x \ln \tan x+ \sum_{n=0}^{\infty} \frac{\sin(2x(2n+1))}{(2n+1)^2}. \tag{1} \, \text{Ti}_2\left( \tan \frac{3\pi}{20} \right) -
 \, \text{Ti}_2\left( \tan \frac{\pi}{20} \right) \stackrel?= \frac{ \pi}{20} \ln \frac{  \tan^3( 3\pi/20)}{\tan ( \pi/20)}   + \frac{2 G}{5} \tag{2}  \sum_{n=0}^{\infty} \frac{\sin \left(\frac{3\pi}{10}(2n+1) \right)- \sin \left(\frac{\pi}{10}(2n+1)\right)}{(2n+1)^2} \stackrel?=\
\frac{2G}{5} \tag{3} \int_{\pi/20}^{3\pi/20} \ln \tan x\,\,dx \stackrel?= - \frac{2G}{5} \tag{4}","['integration', 'sequences-and-series', 'definite-integrals', 'trigonometric-integrals', 'polylogarithm']"
81,"$\int_0^\infty \frac{1}{1+x^ 9} \, dx$",,"\int_0^\infty \frac{1}{1+x^ 9} \, dx","$\int_0^\infty \frac{1}{1+x^9} \, dx$ I tried taking the integral of $\Gamma_R = [0,R] \cup \gamma_R \cup I_R$, where we see that \gamma_R is the circle parametrized by $z = Re^{it}$ with $t\in[0,\frac{\pi}{2}]$. And $I_R$ is the line form $iR$ to $0$ one can note the following three things: 1) $\int_0^\infty \frac{1}{1+x^ 9}\,dz$ = $\int_0^\infty \frac{1}{1+z^ 9}\,dz$. (Note that $z$ is on the $x$-axis) 2) $\int_{\gamma_R}\frac{1}{1+z^ 9} = 0$. (By the ML inequality) the main problem is when i parametrize $I^{-}_{R}$ with $z(x) = xi$ and $x \in [0,R]$. The main problem is that i get that: 3) $\int_{I_R}\frac{1}{1+z^9} = -\int_{I_R^-}\frac{1}{1+z^9} = -\int_{0}^{R} \frac{i}{ix^9 + 1}$. note that i want to work towards taking $R$ to infinity eventually and then equal the sum of the integrals to the sum of the residuals of $\Gamma_R$ times $2\pi i$. The main problem here is that my term in 3), does not look like the form $c \cdot \int_{0}^{\infty}\frac{1}{1+x^ 9}$ with c a constant value. If i can get this done i think i'm finished. PS: The singular points i got where $e^{\frac{\pi i}{9}},e^{\frac{3 \pi i}{9}}$.","$\int_0^\infty \frac{1}{1+x^9} \, dx$ I tried taking the integral of $\Gamma_R = [0,R] \cup \gamma_R \cup I_R$, where we see that \gamma_R is the circle parametrized by $z = Re^{it}$ with $t\in[0,\frac{\pi}{2}]$. And $I_R$ is the line form $iR$ to $0$ one can note the following three things: 1) $\int_0^\infty \frac{1}{1+x^ 9}\,dz$ = $\int_0^\infty \frac{1}{1+z^ 9}\,dz$. (Note that $z$ is on the $x$-axis) 2) $\int_{\gamma_R}\frac{1}{1+z^ 9} = 0$. (By the ML inequality) the main problem is when i parametrize $I^{-}_{R}$ with $z(x) = xi$ and $x \in [0,R]$. The main problem is that i get that: 3) $\int_{I_R}\frac{1}{1+z^9} = -\int_{I_R^-}\frac{1}{1+z^9} = -\int_{0}^{R} \frac{i}{ix^9 + 1}$. note that i want to work towards taking $R$ to infinity eventually and then equal the sum of the integrals to the sum of the residuals of $\Gamma_R$ times $2\pi i$. The main problem here is that my term in 3), does not look like the form $c \cdot \int_{0}^{\infty}\frac{1}{1+x^ 9}$ with c a constant value. If i can get this done i think i'm finished. PS: The singular points i got where $e^{\frac{\pi i}{9}},e^{\frac{3 \pi i}{9}}$.",,"['integration', 'residue-calculus']"
82,Derivative of Integral with variable bounds,Derivative of Integral with variable bounds,,I was testing my calculus knowledge when I found an example final exam from UCIrvine: http://www.math.uci.edu/sites/math.uci.edu/files/2B_final_samp1.pdf Number 2.) a.) asks to evaluate: $$ {d\over dx}\int_{sin(x)}^{x^2}t^3tan(t)dt $$ This is what I did: $\begin{aligned}  {d\over dx}\int_{\sin(x)}^{x^2}t^3\tan(t)dt  &={d\over dx}\left(\int_{\sin(x)}^{a}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right)  \\ &= {d\over dx}\left(-\int_{a}^{\sin(x)}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right)  \\ &= -{d\over dx}\int_{a}^{\sin(x)}t^3\tan(t)dt+{d\over dx}\int_{a}^{x^2}t^3\tan(t)dt  \\ &= -\sin^3(x)\tan(\sin(x))\cos(x)+{x^2}^3\tan(x^2)2x \\ &= 2x^7\tan(x^2)-\sin^3(x)\cos(x)\tan(\sin(x))  \end{aligned}$ Is this correct?,I was testing my calculus knowledge when I found an example final exam from UCIrvine: http://www.math.uci.edu/sites/math.uci.edu/files/2B_final_samp1.pdf Number 2.) a.) asks to evaluate: This is what I did: Is this correct?," {d\over dx}\int_{sin(x)}^{x^2}t^3tan(t)dt  \begin{aligned} 
{d\over dx}\int_{\sin(x)}^{x^2}t^3\tan(t)dt 
&={d\over dx}\left(\int_{\sin(x)}^{a}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right) 
\\
&= {d\over dx}\left(-\int_{a}^{\sin(x)}t^3\tan(t)dt+\int_{a}^{x^2}t^3\tan(t)dt\right) 
\\
&= -{d\over dx}\int_{a}^{\sin(x)}t^3\tan(t)dt+{d\over dx}\int_{a}^{x^2}t^3\tan(t)dt 
\\
&= -\sin^3(x)\tan(\sin(x))\cos(x)+{x^2}^3\tan(x^2)2x \\
&= 2x^7\tan(x^2)-\sin^3(x)\cos(x)\tan(\sin(x)) 
\end{aligned}","['integration', 'derivatives']"
83,How do I solve this definite integral: $\int_0^{2\pi} \frac{dx}{\sin^{4}x + \cos^{4}x}$?,How do I solve this definite integral: ?,\int_0^{2\pi} \frac{dx}{\sin^{4}x + \cos^{4}x},"$$\int_0^{2\pi} \frac{dx}{\sin^{4}x + \cos^{4}x}$$ I have already solved the indefinite integral by transforming $\sin^{4}x + \cos^{4}x$ as follows: $\sin^{4}x + \cos^{4}x = (\sin^{2}x + \cos^{2}x)^{2} - 2\cdot\sin^{2}x\cdot\cos^{2}x = 1 - \frac{1}{2}\cdot\sin^{2}(2x) = \frac{1 + \cos^{2}(2x)}{2}$, and then using the $\tan(2x) = t$ substitution. But if I do the same with the definite integral, both bounds of the integral become $0$.","$$\int_0^{2\pi} \frac{dx}{\sin^{4}x + \cos^{4}x}$$ I have already solved the indefinite integral by transforming $\sin^{4}x + \cos^{4}x$ as follows: $\sin^{4}x + \cos^{4}x = (\sin^{2}x + \cos^{2}x)^{2} - 2\cdot\sin^{2}x\cdot\cos^{2}x = 1 - \frac{1}{2}\cdot\sin^{2}(2x) = \frac{1 + \cos^{2}(2x)}{2}$, and then using the $\tan(2x) = t$ substitution. But if I do the same with the definite integral, both bounds of the integral become $0$.",,"['integration', 'analysis', 'definite-integrals']"
84,If $f(x) = e^{-x}+2e^{-2x}+3e^{-3x}+\cdots$ then find $\int_{\ln2}^{\ln3}f(x)dx$,If  then find,f(x) = e^{-x}+2e^{-2x}+3e^{-3x}+\cdots \int_{\ln2}^{\ln3}f(x)dx,Solve the following If $f(x) = e^{-x}+2e^{-2x}+3e^{-3x}+\cdots $ Then find $\int_{\ln2}^{\ln3}f(x)dx$ I don't have any idea.,Solve the following If $f(x) = e^{-x}+2e^{-2x}+3e^{-3x}+\cdots $ Then find $\int_{\ln2}^{\ln3}f(x)dx$ I don't have any idea.,,['integration']
85,Show $\int_0^\infty \frac{\tan^{-1}x^2}{1+x^2} dx= \int_0^\infty \frac{\tan^{-1}x^{1/2} }{1+x^2}dx$,Show,\int_0^\infty \frac{\tan^{-1}x^2}{1+x^2} dx= \int_0^\infty \frac{\tan^{-1}x^{1/2} }{1+x^2}dx,"I accidentally found out that the two integrals below $$I_1=\int_0^\infty \frac{\tan^{-1}x^2}{1+x^2} dx,\>\>\>\>\>\>\>I_2=\int_0^\infty \frac{\tan^{-1}x^{1/2} }{1+x^2}dx$$ are equal in value. In fact, they can be evaluated explicitly. For example, the first one can be carried out via double integration,  as sketched below. \begin{align} I_1&=\int_0^\infty \left(\int_0^1 \frac{x^2}{1+y^2x^4}dy\right)\frac{1}{1+x^2}dx\\ &= \frac\pi2\int_0^1 \left( \sqrt{\frac y2}+ \frac1{\sqrt{2y} }-1\right)\frac{1}{1+y^2}dy=\frac{\pi^2}8 \end{align} Similarly, the second one yields $I_2=\frac{\pi^2}8$ as well. The evaluations are a bit involved, though, and it seems an overreach to prove their equality this way, if only the following needs to be shown $$\int_0^\infty \frac{\tan^{-1}x^2-\tan^{-1}x^{1/2} }{1+x^2}dx=0$$ The question, then, is whether there is a shortcut to show that the above integral vanishes.","I accidentally found out that the two integrals below are equal in value. In fact, they can be evaluated explicitly. For example, the first one can be carried out via double integration,  as sketched below. Similarly, the second one yields as well. The evaluations are a bit involved, though, and it seems an overreach to prove their equality this way, if only the following needs to be shown The question, then, is whether there is a shortcut to show that the above integral vanishes.","I_1=\int_0^\infty \frac{\tan^{-1}x^2}{1+x^2} dx,\>\>\>\>\>\>\>I_2=\int_0^\infty \frac{\tan^{-1}x^{1/2} }{1+x^2}dx \begin{align}
I_1&=\int_0^\infty \left(\int_0^1 \frac{x^2}{1+y^2x^4}dy\right)\frac{1}{1+x^2}dx\\
&= \frac\pi2\int_0^1 \left( \sqrt{\frac y2}+ \frac1{\sqrt{2y} }-1\right)\frac{1}{1+y^2}dy=\frac{\pi^2}8
\end{align} I_2=\frac{\pi^2}8 \int_0^\infty \frac{\tan^{-1}x^2-\tan^{-1}x^{1/2} }{1+x^2}dx=0","['integration', 'improper-integrals']"
86,How to integrate $|x| \cdot x$,How to integrate,|x| \cdot x,"How to integrate this manually? $$ \int |x|\cdot x ~dx  $$ My tries so far: $$ \int |x|\cdot x ~dx = (x^2/2)\cdot|x| - \int (x²/2)\cdot \mathop{\mathrm{sign}}(x) ~dx  $$ Trying it again, but using sign(x) as first parameter, because sign(x) is not derivable further. $$  \int \mathop{\mathrm{sign}}(x)\cdot(x²/2) ~dx =|x|\cdot (x^2/2) - \int |x|\cdot x ~dx  $$ Great, as nothing would have been done. Next try, using the signum function $$ |x|\cdot x = \mathop{\mathrm{sign}}(x)\cdot x^2 $$ $$  \int \mathop{\mathrm{sign}}(x)\cdot |x| ~dx = x^2-\int|x|\cdot x^2~dx $$ $$  \int |x|\cdot x^2 ~dx =x²\cdot \mathop{\mathrm{sign}}(x)\cdot x^2-\int x^2\cdot \mathop{\mathrm{sign}}(x)\cdot 2x ~dx $$ which seems to be a never ending chain again. Any ideas?","How to integrate this manually? $$ \int |x|\cdot x ~dx  $$ My tries so far: $$ \int |x|\cdot x ~dx = (x^2/2)\cdot|x| - \int (x²/2)\cdot \mathop{\mathrm{sign}}(x) ~dx  $$ Trying it again, but using sign(x) as first parameter, because sign(x) is not derivable further. $$  \int \mathop{\mathrm{sign}}(x)\cdot(x²/2) ~dx =|x|\cdot (x^2/2) - \int |x|\cdot x ~dx  $$ Great, as nothing would have been done. Next try, using the signum function $$ |x|\cdot x = \mathop{\mathrm{sign}}(x)\cdot x^2 $$ $$  \int \mathop{\mathrm{sign}}(x)\cdot |x| ~dx = x^2-\int|x|\cdot x^2~dx $$ $$  \int |x|\cdot x^2 ~dx =x²\cdot \mathop{\mathrm{sign}}(x)\cdot x^2-\int x^2\cdot \mathop{\mathrm{sign}}(x)\cdot 2x ~dx $$ which seems to be a never ending chain again. Any ideas?",,['integration']
87,How to integrate $\displaystyle 1-e^{-1/x^2}$?,How to integrate ?,\displaystyle 1-e^{-1/x^2},"How to integrate $\displaystyle 1-e^{-1/x^2}$ ? as hint is given: $\displaystyle\int_{\mathbb R}e^{-x^2/2}=\sqrt{2\pi}$ If i substitute $u=\dfrac{1}{x}$ , it doesn't bring anything: $\,\displaystyle\int\limits_{-\infty}^{\infty}\left(1-e^{-1/x^2}\right)dx=\int\limits_{-\infty}^{0}\left(1-e^{-1/x^2}\right)dx+\int\limits_{0}^{\infty}\left(1-e^{-1/x^2}\right)dx\overset{?}=2\int\limits_{0}^{\infty}\left(1-\frac{e^{-u^2}}{-u^2}\right)du$ $2\displaystyle\int\limits_{0}^{\infty}\left(1-\frac{e^{-u^2}}{-u^2}\right)du=?$ How to continue ? $\textbf{The original exercise was}$ : If a probability has a density $f(x)=C(1-e^{-1/x^2})$ then determine the value of constant $C$ Since $\displaystyle\int f\overset{!}=1$ , i thought first to calculate the expression above. ( $\textbf{ATTENTION:}$ Question edited from integrating $e^{-1/x^2}$ to integrating $1-e^{-1/x^2}$ )","How to integrate ? as hint is given: If i substitute , it doesn't bring anything: How to continue ? : If a probability has a density then determine the value of constant Since , i thought first to calculate the expression above. ( Question edited from integrating to integrating )","\displaystyle 1-e^{-1/x^2} \displaystyle\int_{\mathbb R}e^{-x^2/2}=\sqrt{2\pi} u=\dfrac{1}{x} \,\displaystyle\int\limits_{-\infty}^{\infty}\left(1-e^{-1/x^2}\right)dx=\int\limits_{-\infty}^{0}\left(1-e^{-1/x^2}\right)dx+\int\limits_{0}^{\infty}\left(1-e^{-1/x^2}\right)dx\overset{?}=2\int\limits_{0}^{\infty}\left(1-\frac{e^{-u^2}}{-u^2}\right)du 2\displaystyle\int\limits_{0}^{\infty}\left(1-\frac{e^{-u^2}}{-u^2}\right)du=? \textbf{The original exercise was} f(x)=C(1-e^{-1/x^2}) C \displaystyle\int f\overset{!}=1 \textbf{ATTENTION:} e^{-1/x^2} 1-e^{-1/x^2}","['integration', 'probability-distributions', 'definite-integrals', 'improper-integrals', 'indefinite-integrals']"
88,Proving an estimate for this integral,Proving an estimate for this integral,,How can I show that$$\sqrt[3]6>\int_1^\infty\frac{(1+x)^{1/3}}{x^2}\mathrm dx?$$,How can I show that$$\sqrt[3]6>\int_1^\infty\frac{(1+x)^{1/3}}{x^2}\mathrm dx?$$,,"['integration', 'measure-theory', 'inequality']"
89,"Show by substitution that $\int_0^{\pi} \frac{x\sin x}{1+\cos^2 x} \,\mathrm dx = \frac{\pi}{2}\int_0^{\pi} \frac{\sin x}{1+\cos^2 x}  \,\mathrm dx$",Show by substitution that,"\int_0^{\pi} \frac{x\sin x}{1+\cos^2 x} \,\mathrm dx = \frac{\pi}{2}\int_0^{\pi} \frac{\sin x}{1+\cos^2 x}  \,\mathrm dx","How do you show $$\int_0^{\pi} \frac{x\sin x}{1+\cos^2 x} \,\mathrm{d}x = \frac{\pi}{2}\int_0^{\pi} \frac{\sin x}{1+\cos^2 x} \,\mathrm{d}x$$ without integrating by parts, but only using substitution?","How do you show $$\int_0^{\pi} \frac{x\sin x}{1+\cos^2 x} \,\mathrm{d}x = \frac{\pi}{2}\int_0^{\pi} \frac{\sin x}{1+\cos^2 x} \,\mathrm{d}x$$ without integrating by parts, but only using substitution?",,['integration']
90,"Different ways to evaluate $\int_0^\infty xI_0(2x)e^{-x^2}\,dx$",Different ways to evaluate,"\int_0^\infty xI_0(2x)e^{-x^2}\,dx","Evaluate $$\int_0^\infty xI_0(2x)e^{-x^2}\,dx$$ where $$I_0(x) = \frac 1\pi \int_0^\pi e^{x\cos\theta}\,d\theta$$ is a Bessel Function. Source: Berkeley Math Tournament This question was on a math contest for high school students, so I am looking for other methods that preferably do not involve higher mathematics than Calc II. However, I am also interested in other ways to solve this problem that goes beyond the normal calculus curriculum. My solution is posted below as an answer.","Evaluate $$\int_0^\infty xI_0(2x)e^{-x^2}\,dx$$ where $$I_0(x) = \frac 1\pi \int_0^\pi e^{x\cos\theta}\,d\theta$$ is a Bessel Function. Source: Berkeley Math Tournament This question was on a math contest for high school students, so I am looking for other methods that preferably do not involve higher mathematics than Calc II. However, I am also interested in other ways to solve this problem that goes beyond the normal calculus curriculum. My solution is posted below as an answer.",,"['integration', 'definite-integrals', 'contest-math', 'improper-integrals', 'bessel-functions']"
91,In which senses can an integral exist?,In which senses can an integral exist?,,I asked about the value of an integral here: Hard integral that standard CAS get totally wrong The question got downvoted and voted to close because I didn't understand (and wasn't able to answer) the following question: In which sense is the integral supposed to exist? So in what senses can integrals exist? What are the options here?,I asked about the value of an integral here: Hard integral that standard CAS get totally wrong The question got downvoted and voted to close because I didn't understand (and wasn't able to answer) the following question: In which sense is the integral supposed to exist? So in what senses can integrals exist? What are the options here?,,['integration']
92,How to evaluate $\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^5\left(1+x\right)}{1+x}\:dx$,How to evaluate,\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^5\left(1+x\right)}{1+x}\:dx,"Before you think I haven't tried anything, please read. I've been trying to evaluate $$\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^5\left(1+x\right)}{1+x}\:dx$$ But I can't find a way to simplify it. Integration by parts is not valid since we face convergence issues. Subbing the $1-x$ term is also not quite helpful here. I also tried to use the sub $\frac{1}{1+x}$ but this is not useful either. Using algebraic identities isn't that useful either, since we run into similar difficulty integrals. Since these attempts do not lead to anything, how can I approach it?","Before you think I haven't tried anything, please read. I've been trying to evaluate But I can't find a way to simplify it. Integration by parts is not valid since we face convergence issues. Subbing the term is also not quite helpful here. I also tried to use the sub but this is not useful either. Using algebraic identities isn't that useful either, since we run into similar difficulty integrals. Since these attempts do not lead to anything, how can I approach it?",\int _0^1\frac{\ln ^2\left(1-x\right)\ln ^5\left(1+x\right)}{1+x}\:dx 1-x \frac{1}{1+x},"['integration', 'definite-integrals']"
93,"Integral $-\int_{0}^{a}{at^{3}\,{\rm d}t\over\,\sqrt{\,\left(a^{2} -t^{2}\right)\left(b^{2}t^{2} +a^{4}-a^{2}t^{2}\right)\,}\,}$",Integral,"-\int_{0}^{a}{at^{3}\,{\rm d}t\over\,\sqrt{\,\left(a^{2} -t^{2}\right)\left(b^{2}t^{2} +a^{4}-a^{2}t^{2}\right)\,}\,}","This problem's taking me a lot longer than I like (probably doing things the hard way...).  I have 9 different terms to integrate, some of which are messier than others.  This one, though, is messier than most. $$-{\Large\int}_{\!0}^{a} \!\raise 0.8ex {at^{3}\,{\rm d}t \over \,\sqrt{\,\left(a^{2} -t^{2}\right)\left(b^{2}t^{2} +a^{4}-a^{2}t^{2}\right)\,}\,} $$ I tried a whole series of substitutions on this.  First $t=a\sin\left(u\right)$, then $v=\cos\left(u\right)$ and split the resulting integral into two, only to find (after substitution number three) that the first half diverged (haven't tried the second half).  In any case, I'm assuming there has to be a better way to attempt this.  Any suggestions appreciated.","This problem's taking me a lot longer than I like (probably doing things the hard way...).  I have 9 different terms to integrate, some of which are messier than others.  This one, though, is messier than most. $$-{\Large\int}_{\!0}^{a} \!\raise 0.8ex {at^{3}\,{\rm d}t \over \,\sqrt{\,\left(a^{2} -t^{2}\right)\left(b^{2}t^{2} +a^{4}-a^{2}t^{2}\right)\,}\,} $$ I tried a whole series of substitutions on this.  First $t=a\sin\left(u\right)$, then $v=\cos\left(u\right)$ and split the resulting integral into two, only to find (after substitution number three) that the first half diverged (haven't tried the second half).  In any case, I'm assuming there has to be a better way to attempt this.  Any suggestions appreciated.",,"['integration', 'definite-integrals', 'improper-integrals']"
94,What does integration do?,What does integration do?,,"I know that integrals are used to compute the area under a curve. Let's say I have $y = x^2$. It creates smaller rectangles and then add up the sum (assuming that rectangles are going infinitely in number and is like going to a limit). But I recently encountered a problem in my mind. Suppose we have a function, $y = x^2$. If we integrated it, we simply get the anti derivative of it which is $x^3/3$, assuming that the area is not of concern. What is the correlation of $x^3/3$ to $x^2$? I mean, it simply likes transforms a function into another function, but I can't get a clearer picture. When we graph $x^2$ and $x^3/3$, there is no connection visually. They are simply different graphs. Thanks and I hope your comments can clear up my mind.","I know that integrals are used to compute the area under a curve. Let's say I have $y = x^2$. It creates smaller rectangles and then add up the sum (assuming that rectangles are going infinitely in number and is like going to a limit). But I recently encountered a problem in my mind. Suppose we have a function, $y = x^2$. If we integrated it, we simply get the anti derivative of it which is $x^3/3$, assuming that the area is not of concern. What is the correlation of $x^3/3$ to $x^2$? I mean, it simply likes transforms a function into another function, but I can't get a clearer picture. When we graph $x^2$ and $x^3/3$, there is no connection visually. They are simply different graphs. Thanks and I hope your comments can clear up my mind.",,['integration']
95,How do I apply the product (capital pi) symbol here?,How do I apply the product (capital pi) symbol here?,,"I know $\prod$ is the product symbol but I'm not sure how to apply it in the result shown below.  The $a$, $b$, and $d$ are constants. $$\frac{\prod\left(\frac{(b - a)(b + a)}{d^2 + b^2}\,;x\,\middle|\,\frac{(b - a)(b + a)}{d^2 + b^2}\right)}{(d^2 + b^2)^\frac{3}{2}}$$ Any help appreciated.  By the way, this result above came from the integration of this: $1/(d^2 + b^2\cos^2x+a^2\sin^2x)^\frac{3}{2}$ EDIT:  How do I evaluate that result to a numerical result? (e.g. With integration limits $0$ to $2\pi$)","I know $\prod$ is the product symbol but I'm not sure how to apply it in the result shown below.  The $a$, $b$, and $d$ are constants. $$\frac{\prod\left(\frac{(b - a)(b + a)}{d^2 + b^2}\,;x\,\middle|\,\frac{(b - a)(b + a)}{d^2 + b^2}\right)}{(d^2 + b^2)^\frac{3}{2}}$$ Any help appreciated.  By the way, this result above came from the integration of this: $1/(d^2 + b^2\cos^2x+a^2\sin^2x)^\frac{3}{2}$ EDIT:  How do I evaluate that result to a numerical result? (e.g. With integration limits $0$ to $2\pi$)",,"['integration', 'notation', 'special-functions']"
96,"Convergence of $\int_{0}^{+\infty} \frac{x}{1+e^x}\,dx$",Convergence of,"\int_{0}^{+\infty} \frac{x}{1+e^x}\,dx","Does this integral converge to any particular value? $$\int_{0}^{+\infty} \frac{x}{1+e^x}\,dx$$ If the answer is yes, how should I calculate its value? I tried to use convergence tests but I failed due to the complexity of the integral itself.","Does this integral converge to any particular value? $$\int_{0}^{+\infty} \frac{x}{1+e^x}\,dx$$ If the answer is yes, how should I calculate its value? I tried to use convergence tests but I failed due to the complexity of the integral itself.",,"['integration', 'improper-integrals']"
97,"Proof that $\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0$",Proof that,"\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0","Prove that $\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0$ for all integers $n \neq 0$. I think I'm encouraged to prove this by induction (but a simpler method would probably work, too). Here's what I've attempted: $$\text{1.}\int_0^{2\pi}\sin x\,dx=\int_0^{2\pi}\cos x\,dx=0.\;\checkmark\\\text{2. Assume}\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0.\;\checkmark\\\text{3. Prove}\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\cos (nx+x)\,dx=0.\\\text{[From here, I'm lost. I've tried applying a trig identity, but I'm not sure how to proceed.]}\\\text{For the}\sin\text{integral},\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\sin nx\cos x\,dx+\int_0^{2\pi}\cos nx\sin x\,dx.$$ I hope I'm on the right track. In the last step, I have $\sin nx$ and $\cos nx$ in the integrals, but I'm not sure if that helps me. I would appreciate any help with this. Thanks :) As I indicated above, it'd be great to find a way to complete this induction proof—probably by, as Arkamis said, ""working it like the transcontinental railroad"" with trig identities (if that's possible). I think my instructor discouraged a simple $u$-substitution, because we've recently been focused on manipulating trig identities.","Prove that $\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0$ for all integers $n \neq 0$. I think I'm encouraged to prove this by induction (but a simpler method would probably work, too). Here's what I've attempted: $$\text{1.}\int_0^{2\pi}\sin x\,dx=\int_0^{2\pi}\cos x\,dx=0.\;\checkmark\\\text{2. Assume}\int_0^{2\pi}\sin nx\,dx=\int_0^{2\pi}\cos nx\,dx=0.\;\checkmark\\\text{3. Prove}\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\cos (nx+x)\,dx=0.\\\text{[From here, I'm lost. I've tried applying a trig identity, but I'm not sure how to proceed.]}\\\text{For the}\sin\text{integral},\int_0^{2\pi}\sin (nx+x)\,dx=\int_0^{2\pi}\sin nx\cos x\,dx+\int_0^{2\pi}\cos nx\sin x\,dx.$$ I hope I'm on the right track. In the last step, I have $\sin nx$ and $\cos nx$ in the integrals, but I'm not sure if that helps me. I would appreciate any help with this. Thanks :) As I indicated above, it'd be great to find a way to complete this induction proof—probably by, as Arkamis said, ""working it like the transcontinental railroad"" with trig identities (if that's possible). I think my instructor discouraged a simple $u$-substitution, because we've recently been focused on manipulating trig identities.",,"['integration', 'trigonometry', 'definite-integrals', 'induction']"
98,Why is $\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx?$,Why is,\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx?,"I don't know why these two integrals yield the same results. $$\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx$$ Any hints, clues and ideas how to go about dealing these integrals(showing that they are the same and determine the closed form)? $$\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx$$I know it is similar to the sophere's dream integral.  I think you can possible use integration by parts. Because there are three functions are involved applying by parts it would be very long. I try to make a substitution of $u=1-x$ $$-\int_{0}^{1}u^{1+u}(1-u)^{1-u}\sin((u+1)\pi)du$$ Q: show that they are the same and evaluate its closed form. Edited $$\int_{0}^{1}u^{1+u}(1-u)^{1-u}\sin(u\pi)du$$ Let try and applying by parts $u=x^x(1-x)^{2-x}$ $du=x^x(1-x)^{2-x}\ln{x\over 2-x}dx$ $v=-{\cos{(x\pi)}\over \pi}$ $$=-{1\over \pi}x^x(1-x)^{2-x}\cos{(x\pi)}+{1\over \pi}\int_{0}^{1}x^x(1-x)^{2-x}\cos{(x\pi)}\ln{x\over 2-x}dx$$ This looked more complicate than before, so ideally, no, it is not a good way of tackling this problem.","I don't know why these two integrals yield the same results. $$\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx$$ Any hints, clues and ideas how to go about dealing these integrals(showing that they are the same and determine the closed form)? $$\int_{0}^{1}x^x(1-x)^{2-x}\sin(x\pi)dx=\int_{0}^{1}x^{1+x}(1-x)^{1-x}\sin(x\pi)dx$$I know it is similar to the sophere's dream integral.  I think you can possible use integration by parts. Because there are three functions are involved applying by parts it would be very long. I try to make a substitution of $u=1-x$ $$-\int_{0}^{1}u^{1+u}(1-u)^{1-u}\sin((u+1)\pi)du$$ Q: show that they are the same and evaluate its closed form. Edited $$\int_{0}^{1}u^{1+u}(1-u)^{1-u}\sin(u\pi)du$$ Let try and applying by parts $u=x^x(1-x)^{2-x}$ $du=x^x(1-x)^{2-x}\ln{x\over 2-x}dx$ $v=-{\cos{(x\pi)}\over \pi}$ $$=-{1\over \pi}x^x(1-x)^{2-x}\cos{(x\pi)}+{1\over \pi}\int_{0}^{1}x^x(1-x)^{2-x}\cos{(x\pi)}\ln{x\over 2-x}dx$$ This looked more complicate than before, so ideally, no, it is not a good way of tackling this problem.",,[]
99,Integrating over the naturals. What does it mean?,Integrating over the naturals. What does it mean?,,"Let $F$ be the power set of $\Bbb{N}$ and consider the measurable space $(\Bbb{N}, F)$.  Then what does it mean to take the integral with respect to the measure $\mu(A) = \sum_{a \in A} \frac{1}{a}$.  What would $\int f \ d\mu$ represent, where $f$ is some function $f: \Bbb{N} \to \Bbb{R}$? My attempt. Take the simplest integrand which is usually $1$ and integrate to get $\int 1  \ d\mu = 1 \mu(\Bbb{N}) = \infty$.  This means what ?","Let $F$ be the power set of $\Bbb{N}$ and consider the measurable space $(\Bbb{N}, F)$.  Then what does it mean to take the integral with respect to the measure $\mu(A) = \sum_{a \in A} \frac{1}{a}$.  What would $\int f \ d\mu$ represent, where $f$ is some function $f: \Bbb{N} \to \Bbb{R}$? My attempt. Take the simplest integrand which is usually $1$ and integrate to get $\int 1  \ d\mu = 1 \mu(\Bbb{N}) = \infty$.  This means what ?",,"['integration', 'sequences-and-series', 'summation', 'lebesgue-integral']"
