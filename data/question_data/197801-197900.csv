,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What ways are there to comb a torus?,What ways are there to comb a torus?,,"Modulo diffeomorphisms, what are all possible nonvanishing vector fields on the two-torus?","Modulo diffeomorphisms, what are all possible nonvanishing vector fields on the two-torus?",,"['differential-geometry', 'moduli-space']"
1,Parallel transport along a 2-sphere.,Parallel transport along a 2-sphere.,,"I'm currently learning about parallel transport and connections and we were considering the parallel transport of a tangent vector along a sphere as given in the picture below. From my understanding, by defining a connection on your manifold, you provide a way to identify vectors at one point of the manifold with vectors at another point on the manifold via parallel transporting the vector. So in the given example, when the initial vector is parallely transported along the closed curve it returns to the same spot as a different vector. Is this because there has not been defined a correct connection on the sphere (that takes into account the curvature of the 2-sphere)? In which case, when a connection is defined on the sphere, (i.e. by the covariant derivative) parallel transport of any vector along a closed curve back to its initial position will result in the same vector? So this is in fact an example of the need for a connection, and not just the standard derivative? Thanks in advance!","I'm currently learning about parallel transport and connections and we were considering the parallel transport of a tangent vector along a sphere as given in the picture below. From my understanding, by defining a connection on your manifold, you provide a way to identify vectors at one point of the manifold with vectors at another point on the manifold via parallel transporting the vector. So in the given example, when the initial vector is parallely transported along the closed curve it returns to the same spot as a different vector. Is this because there has not been defined a correct connection on the sphere (that takes into account the curvature of the 2-sphere)? In which case, when a connection is defined on the sphere, (i.e. by the covariant derivative) parallel transport of any vector along a closed curve back to its initial position will result in the same vector? So this is in fact an example of the need for a connection, and not just the standard derivative? Thanks in advance!",,"['differential-geometry', 'connections']"
2,Taylor Expansion of tensor moved by a flow.,Taylor Expansion of tensor moved by a flow.,,"I am reading Peter Petersen's notes on manifold theory and he introduces Lie Derivatives in the following way. ""Let $X$ be a vector field and $F^t$ the corresponding locally defined flow on a smooth manifold $M$. Thus $F^t (p)$ is defined for small $t$ and the curve $t \to F^t (p)$ is the integral curve for X that goes through $p$ at $t = 0$. The Lie derivative of a tensor in the direction of $X$ is defined as the first order term in a suitable Taylor expansion of the tensor when it is moved by the flow of $X$."" I am uncertain of what he means when he refers to the ""Taylor expansion of the tensor as it is moved by the flow of $X$"". I am only aware of Taylor expansions for functions and I was hoping that somebody can help clarify this.","I am reading Peter Petersen's notes on manifold theory and he introduces Lie Derivatives in the following way. ""Let $X$ be a vector field and $F^t$ the corresponding locally defined flow on a smooth manifold $M$. Thus $F^t (p)$ is defined for small $t$ and the curve $t \to F^t (p)$ is the integral curve for X that goes through $p$ at $t = 0$. The Lie derivative of a tensor in the direction of $X$ is defined as the first order term in a suitable Taylor expansion of the tensor when it is moved by the flow of $X$."" I am uncertain of what he means when he refers to the ""Taylor expansion of the tensor as it is moved by the flow of $X$"". I am only aware of Taylor expansions for functions and I was hoping that somebody can help clarify this.",,"['differential-geometry', 'differential-topology', 'taylor-expansion', 'tensors', 'smooth-manifolds']"
3,Gradient in local coordinates on a manifold with Riemannian metric,Gradient in local coordinates on a manifold with Riemannian metric,,"Let $M$ be a smooth manifold with a Riemannian metric g : $TM\otimes TM$ -> R If f is a smooth function from M to R , the gradient of f with respect to g is the vector field $\nabla f$ defined by $df$=$g(\nabla f, *)$ (1) In local coordinates {$x^i$}, compute $\nabla f $ in terms of local coordinates. (2) Now consider $p \in M$. Show that if $V \in T_p M$ satisfies $df_p(V)>0$, then there exists a Riemannian metric $g$ on $M$ with $\nabla f(p)$=$V$ I'm having trouble with how to represent $g(\nabla f, *)$ in terms of local coordinates. Any help would be appreciated. Thanks.","Let $M$ be a smooth manifold with a Riemannian metric g : $TM\otimes TM$ -> R If f is a smooth function from M to R , the gradient of f with respect to g is the vector field $\nabla f$ defined by $df$=$g(\nabla f, *)$ (1) In local coordinates {$x^i$}, compute $\nabla f $ in terms of local coordinates. (2) Now consider $p \in M$. Show that if $V \in T_p M$ satisfies $df_p(V)>0$, then there exists a Riemannian metric $g$ on $M$ with $\nabla f(p)$=$V$ I'm having trouble with how to represent $g(\nabla f, *)$ in terms of local coordinates. Any help would be appreciated. Thanks.",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'coordinate-systems']"
4,A differentiable map doesn't depend on the parametrization,A differentiable map doesn't depend on the parametrization,,"In Do Carmo's Differential Geometry of Curves and Surfaces there's an excercise in section 2-3 that says: Prove that the definition of a differentiable map between surfaces does not depend on the parametrization chosen. According to the book, the definition of a differentiable map is, if $\varphi:S_1\to S_2$ is a continuous map, where both $S_1,S_2$ are regular surfaces. then $\varphi$ is differentiable at $p\in S_1$ if given parametrizations: $f:U \subset\Bbb R^2\to S_1$ and $g:W \subset\Bbb R^2\to S_2$, with $p\in f(U)$ and $\varphi(f(U))\subset g(W)$, the map $g^{-1}\circ\varphi\circ f: U\to W$ is differentiable at $q=f^{-1}(p)$. I'm getting a little bit confused on how to prove this without making a mess. I'm relying on the following diagram: Where $f_1,f_2$ are two diferent parametrizations for $S_1$, and $g_1,g_2$ are two diferent parametrizations for $S_2$. And my guess is that we have to prove that $g_1^{-1}\circ\varphi\circ f_1=g_2^{-1}\circ\varphi\circ f_2$, althought would it be also necesary to prove $g_1^{-1}\circ\varphi\circ f_2=g_2^{-1}\circ\varphi\circ f_1$? Am I considering this wrong? An attempt to do this: We know that $f_1=f_2\circ f_2^{-1}\circ f_1$ and $g_1^{-1}=(g_2\circ g_2^{-1}\circ g_1)^{-1}=g_1^{-1}\circ g_2\circ g_2^{-1}$, hence  $$g_1^{-1}\circ\varphi\circ f_1=(g_1^{-1}\circ g_2\circ g_2^{-1}) \circ\varphi\circ (f_2\circ f_2^{-1}\circ f_1) \\=g_1^{-1}\circ g_2\circ (g_2^{-1} \circ\varphi\circ f_2)\circ f_2^{-1}\circ f_1 \\=G \circ (g_2^{-1} \circ\varphi\circ f_2)\circ F$$ because $S_1,S_2$ are regular, then  $F,G$ are diff. but I'm not sure what to do from here, can we conclude that $g_1^{-1}\circ\varphi\circ f_1\subseteq g_2^{-1}\circ\varphi\circ f_2$?","In Do Carmo's Differential Geometry of Curves and Surfaces there's an excercise in section 2-3 that says: Prove that the definition of a differentiable map between surfaces does not depend on the parametrization chosen. According to the book, the definition of a differentiable map is, if $\varphi:S_1\to S_2$ is a continuous map, where both $S_1,S_2$ are regular surfaces. then $\varphi$ is differentiable at $p\in S_1$ if given parametrizations: $f:U \subset\Bbb R^2\to S_1$ and $g:W \subset\Bbb R^2\to S_2$, with $p\in f(U)$ and $\varphi(f(U))\subset g(W)$, the map $g^{-1}\circ\varphi\circ f: U\to W$ is differentiable at $q=f^{-1}(p)$. I'm getting a little bit confused on how to prove this without making a mess. I'm relying on the following diagram: Where $f_1,f_2$ are two diferent parametrizations for $S_1$, and $g_1,g_2$ are two diferent parametrizations for $S_2$. And my guess is that we have to prove that $g_1^{-1}\circ\varphi\circ f_1=g_2^{-1}\circ\varphi\circ f_2$, althought would it be also necesary to prove $g_1^{-1}\circ\varphi\circ f_2=g_2^{-1}\circ\varphi\circ f_1$? Am I considering this wrong? An attempt to do this: We know that $f_1=f_2\circ f_2^{-1}\circ f_1$ and $g_1^{-1}=(g_2\circ g_2^{-1}\circ g_1)^{-1}=g_1^{-1}\circ g_2\circ g_2^{-1}$, hence  $$g_1^{-1}\circ\varphi\circ f_1=(g_1^{-1}\circ g_2\circ g_2^{-1}) \circ\varphi\circ (f_2\circ f_2^{-1}\circ f_1) \\=g_1^{-1}\circ g_2\circ (g_2^{-1} \circ\varphi\circ f_2)\circ f_2^{-1}\circ f_1 \\=G \circ (g_2^{-1} \circ\varphi\circ f_2)\circ F$$ because $S_1,S_2$ are regular, then  $F,G$ are diff. but I'm not sure what to do from here, can we conclude that $g_1^{-1}\circ\varphi\circ f_1\subseteq g_2^{-1}\circ\varphi\circ f_2$?",,['differential-geometry']
5,Affine connection on a Lie group.,Affine connection on a Lie group.,,"Let $G$ be a Lie group. For $g \in G$, we can define a diffeomorphism $l_g: G \to G$ by $l_g(x)=gx$, and a bundle map ${l_g}_*:TG \to TG$. Then, I guess that we can obtain the affine connection on $G$ by reverse thinking that we could make a parallel transportation from a connection. Now, ${l_g}_*$ is the 'parallel transportation', and we would like to make the 'affine connection' from this. Is it true? If so, what is the name of this affine connection on $G$? Thanks for your help!!","Let $G$ be a Lie group. For $g \in G$, we can define a diffeomorphism $l_g: G \to G$ by $l_g(x)=gx$, and a bundle map ${l_g}_*:TG \to TG$. Then, I guess that we can obtain the affine connection on $G$ by reverse thinking that we could make a parallel transportation from a connection. Now, ${l_g}_*$ is the 'parallel transportation', and we would like to make the 'affine connection' from this. Is it true? If so, what is the name of this affine connection on $G$? Thanks for your help!!",,"['differential-geometry', 'differential-topology']"
6,Application of Riemann Roch,Application of Riemann Roch,,"I have read that thanks to Riemann Roch theorem, if get $\Sigma$ a compact Riemann Surface of genus $g$ there exists a conformal branch covering $\phi: \Sigma \rightarrow S^2$ of degree less than $g+1$. Unfortunately I have found only very abstract references which not clearly implies this fact. does any one can explain this to me? Ideally with a basic reference.","I have read that thanks to Riemann Roch theorem, if get $\Sigma$ a compact Riemann Surface of genus $g$ there exists a conformal branch covering $\phi: \Sigma \rightarrow S^2$ of degree less than $g+1$. Unfortunately I have found only very abstract references which not clearly implies this fact. does any one can explain this to me? Ideally with a basic reference.",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
7,Looking for a good book on Morse-Bott functions.,Looking for a good book on Morse-Bott functions.,,"I am looking for a book to study for the first time Morse-Bott functions. Does anyone know one that is easy to follow and detailed? If there is one connecting this subject with symplectic geometry, it would be useful too. Thanks!","I am looking for a book to study for the first time Morse-Bott functions. Does anyone know one that is easy to follow and detailed? If there is one connecting this subject with symplectic geometry, it would be useful too. Thanks!",,"['differential-geometry', 'differential-topology', 'symplectic-geometry', 'morse-theory']"
8,Metric Tensor and Curvature,Metric Tensor and Curvature,,"I have a doubt about the metric tensor and curvature. My point is: last year I was talking to a mathematician that I know and he said to me that the metric tensor is something that we define on a manifold like an inner product is defined on a vector space. What he said is: given a vector space $V$ we can define any inner product that we want, it just must comply with the axioms. The same happens with the metric tensor: given a manifold $M$ we can define any metric tensor, it just needs to assign to each point a valid inner product on the tangent space. But hat brought me some doubts: the $2$-sphere is a manifold $S^2$, and it has curvature. This is obvious geometrically: we can see that $S^2$ cannot be considered flat in any way. However, the curvature tensor which gives the curvature, is defined in terms of the metric. If we can define any metric that we want, then how we're going to recover the "" true "" curvature of the sphere ? In other words, I think that there wouldn't be a problem to assign to the $S^2$ as a metric tensor the tensor field that at each point assign just the euclidean inner product. I thought that the metric tensor was derived from the charts, but this mathematician said that it's not, it's just defined at our will, having to satisfy the inner product properties at any point. Can someone point out a good reference for me to read more about how to obtain the metric and so on ? Or even give some example ? Thanks in advance. And sorry if the question is silly. Also, if it's not well explained, just tell me and I'll rewrite it.","I have a doubt about the metric tensor and curvature. My point is: last year I was talking to a mathematician that I know and he said to me that the metric tensor is something that we define on a manifold like an inner product is defined on a vector space. What he said is: given a vector space $V$ we can define any inner product that we want, it just must comply with the axioms. The same happens with the metric tensor: given a manifold $M$ we can define any metric tensor, it just needs to assign to each point a valid inner product on the tangent space. But hat brought me some doubts: the $2$-sphere is a manifold $S^2$, and it has curvature. This is obvious geometrically: we can see that $S^2$ cannot be considered flat in any way. However, the curvature tensor which gives the curvature, is defined in terms of the metric. If we can define any metric that we want, then how we're going to recover the "" true "" curvature of the sphere ? In other words, I think that there wouldn't be a problem to assign to the $S^2$ as a metric tensor the tensor field that at each point assign just the euclidean inner product. I thought that the metric tensor was derived from the charts, but this mathematician said that it's not, it's just defined at our will, having to satisfy the inner product properties at any point. Can someone point out a good reference for me to read more about how to obtain the metric and so on ? Or even give some example ? Thanks in advance. And sorry if the question is silly. Also, if it's not well explained, just tell me and I'll rewrite it.",,"['differential-geometry', 'manifolds']"
9,"In the symplectic 2-sphere $(S^2,d\theta\wedge dz)$, is the vector field $X=\partial_\theta$ Hamiltonian?","In the symplectic 2-sphere , is the vector field  Hamiltonian?","(S^2,d\theta\wedge dz) X=\partial_\theta","Consider the sphere $S^2\subset\mathbb{R}^3$ in cylindrical coordinates $(\theta, z)$ (away from poles $z=\pm 1$) with symplectic structure $\omega=d\theta\wedge dz$. I want to show that the vector field $X=\partial_\theta$ is hamiltonian. That is, the contraction of $\omega$ by $X$, denoted $i_X\omega$ is exact. One way is straightforward: since the first de Rham group of the sphere is trivial the 1-form $i_X\omega$, being closed, has to be exact. Question 1 -- why is $i_X\omega$ closed? Question 2 -- Suppose I don't want to use my knowledge about de Rham groups and I want to show directly (""by hands"") that $i_X\omega$ is exact. How to do this properly? Here is my work: Since $X=\partial_\theta$ we get $$ i_X\omega(\partial_\theta)=\omega(X,\partial_\theta)=0 \\ i_X\omega(\partial_z)=\omega(X,\partial_z)=1 $$ Hence $i_X\omega=dz$ and so it is exact, at least locally on $U=S^2\setminus\{z=\pm 1\}$. Now, to show the global exactness I would have to find a suitable change of charts and check that the transformed $\omega$ is exact around z=1 and z=-1. If all I said is correct, then what would be a suitable change of charts? Or, is there an easier way?","Consider the sphere $S^2\subset\mathbb{R}^3$ in cylindrical coordinates $(\theta, z)$ (away from poles $z=\pm 1$) with symplectic structure $\omega=d\theta\wedge dz$. I want to show that the vector field $X=\partial_\theta$ is hamiltonian. That is, the contraction of $\omega$ by $X$, denoted $i_X\omega$ is exact. One way is straightforward: since the first de Rham group of the sphere is trivial the 1-form $i_X\omega$, being closed, has to be exact. Question 1 -- why is $i_X\omega$ closed? Question 2 -- Suppose I don't want to use my knowledge about de Rham groups and I want to show directly (""by hands"") that $i_X\omega$ is exact. How to do this properly? Here is my work: Since $X=\partial_\theta$ we get $$ i_X\omega(\partial_\theta)=\omega(X,\partial_\theta)=0 \\ i_X\omega(\partial_z)=\omega(X,\partial_z)=1 $$ Hence $i_X\omega=dz$ and so it is exact, at least locally on $U=S^2\setminus\{z=\pm 1\}$. Now, to show the global exactness I would have to find a suitable change of charts and check that the transformed $\omega$ is exact around z=1 and z=-1. If all I said is correct, then what would be a suitable change of charts? Or, is there an easier way?",,"['differential-geometry', 'vector-fields', 'spheres', 'symplectic-geometry']"
10,Gauss-Bonnet theorem for spheres that almost look like a torus,Gauss-Bonnet theorem for spheres that almost look like a torus,,"[Corrected due to Jason's answer.] Imagine a torus and a flat disk fitting in the middle of its ""hole"" (a doughnut with a membrane in the middle). Cut the torus at its inner equator, duplicate the disk, move the two copies away from each other slightly, widen the cut appropriately and join the two flat disks with the sliced torus (anyway you like). You get a surface $M$ homeomorphic to the sphere - thus with integral curvature $\int_S\kappa = 4\pi$ - , but with integral curvature equal to that of the torus $\int_T\kappa = 0$ plus a contribution from the ""regions of agglutination"" where the two disks and the sliced torus are glued together (the disks by themselves having zero curvature). Is it simply a consequence of the Gauss-Bonnet theorem that however smoothly or abruptly you glue the two disks and the sliced torus together the integral curvature in the ""region of agglutination"" has to be $4\pi$? Or is there a mistake in my description of the surface or in my understanding of the Gauss-Bonnet theorem?","[Corrected due to Jason's answer.] Imagine a torus and a flat disk fitting in the middle of its ""hole"" (a doughnut with a membrane in the middle). Cut the torus at its inner equator, duplicate the disk, move the two copies away from each other slightly, widen the cut appropriately and join the two flat disks with the sliced torus (anyway you like). You get a surface $M$ homeomorphic to the sphere - thus with integral curvature $\int_S\kappa = 4\pi$ - , but with integral curvature equal to that of the torus $\int_T\kappa = 0$ plus a contribution from the ""regions of agglutination"" where the two disks and the sliced torus are glued together (the disks by themselves having zero curvature). Is it simply a consequence of the Gauss-Bonnet theorem that however smoothly or abruptly you glue the two disks and the sliced torus together the integral curvature in the ""region of agglutination"" has to be $4\pi$? Or is there a mistake in my description of the surface or in my understanding of the Gauss-Bonnet theorem?",,['differential-geometry']
11,Second fundamental form proportional to the Hessian,Second fundamental form proportional to the Hessian,,"Let $(M^n,g)$ be a Riemannian manifold and $f:M\to\mathbb{R}$ a smooth function. Then the graph $S=\{(p,f(p))\mid p\in M\}$ is a submanifold of $(M\times\mathbb{R},g+g_{\mathbb{R}})$ and carries the induced metric $\tilde{g}=g+\nabla f\otimes \nabla f$. Now I want to know, how to calculate the second fundamental form $h$ of $S$. In my intuition at every point $h_{(p,f(p))}(df_p(\cdot),df_p(\cdot)):T_pM\times T_pM\to \mathbb{R}$ has to be proportional to the Hessian $\operatorname{hess}(f)_p(\cdot,\cdot):T_pM\times T_pM\to \mathbb{R}$. Does anyone know the exact relation between those? EDIT : The idea is: Define $\tilde{f}:M\times\mathbb{R}\to \mathbb{R}; (p,r)\mapsto f(p)-r$. Then $\tilde{f}^{-1}(0)=S$ and following Sun Park Joe's comment the second fundamental form at $\tilde{p}=(p,r)$ is given by $h_{\tilde{p}}(v,w)=\frac{hess(\tilde{f})_{\tilde{p}}(v,w)}{\left|\nabla \tilde{f}_{\tilde{p}}\right|}=\frac{hess(f)_p(d(f^{-1})_\tilde{p}~v~~,~~d(f^{-1})_{\tilde{p}}~w)}{\sqrt{1+\left|\nabla f_p\right|}}$. I hope, I got everything right..","Let $(M^n,g)$ be a Riemannian manifold and $f:M\to\mathbb{R}$ a smooth function. Then the graph $S=\{(p,f(p))\mid p\in M\}$ is a submanifold of $(M\times\mathbb{R},g+g_{\mathbb{R}})$ and carries the induced metric $\tilde{g}=g+\nabla f\otimes \nabla f$. Now I want to know, how to calculate the second fundamental form $h$ of $S$. In my intuition at every point $h_{(p,f(p))}(df_p(\cdot),df_p(\cdot)):T_pM\times T_pM\to \mathbb{R}$ has to be proportional to the Hessian $\operatorname{hess}(f)_p(\cdot,\cdot):T_pM\times T_pM\to \mathbb{R}$. Does anyone know the exact relation between those? EDIT : The idea is: Define $\tilde{f}:M\times\mathbb{R}\to \mathbb{R}; (p,r)\mapsto f(p)-r$. Then $\tilde{f}^{-1}(0)=S$ and following Sun Park Joe's comment the second fundamental form at $\tilde{p}=(p,r)$ is given by $h_{\tilde{p}}(v,w)=\frac{hess(\tilde{f})_{\tilde{p}}(v,w)}{\left|\nabla \tilde{f}_{\tilde{p}}\right|}=\frac{hess(f)_p(d(f^{-1})_\tilde{p}~v~~,~~d(f^{-1})_{\tilde{p}}~w)}{\sqrt{1+\left|\nabla f_p\right|}}$. I hope, I got everything right..",,"['differential-geometry', 'riemannian-geometry']"
12,Why would we expect the pushforward to encode the total derivative of a smooth map?,Why would we expect the pushforward to encode the total derivative of a smooth map?,,"According to Lee, the pushforward was invented to give a coordinate independent definition of the total derivative of a smooth function between two smooth manifolds.  To each smooth map $F:M \to N$ and each point $p \in M$ we associate a linear map $F_*:T_pM\to T_{F(p)}N$ defined by $F_*X(f) = X(f \circ F)$ where $X$ is any derivation in $T_pM$ and $f:N \to \mathbb{R}$ is any smooth function.  Given a smooth chart $\phi:M \to \mathbb{R}^m$ near $p$ we have a basis for $T_pM$ given by $\frac{\partial}{\partial x^i}|_{p} = ({\phi ^{-1}}_*)\frac{\partial}{\partial x^i}|_{\phi(p)}$.  Similarly given a smooth chart $\psi$ near $F(p)$ we have a basis for $T_{F(p)}N$ given by $\frac{\partial}{\partial y^i}|_{F(p)} = ({\psi ^{-1}}_*)\frac{\partial}{\partial y^i}|_{\psi(p)}$.  A calculation in Lee shows that the matrix representation of $F_*$ with respect to these bases is the total derivative of the coordinate representation $\hat{F} = \psi \circ F \circ \phi ^{-1}$ evaluated at $\phi(p)$. My question is, is there some intuitive reason why we would expect this to be true?  This all seems very abstract to me.  I can't tell if it is supposed to be obvious that this definition should be a coordinate independent way of encoding the total derivative of $F$ and I am just missing something, or if it is just difficult to understand.  How should I think about the pushforward?","According to Lee, the pushforward was invented to give a coordinate independent definition of the total derivative of a smooth function between two smooth manifolds.  To each smooth map $F:M \to N$ and each point $p \in M$ we associate a linear map $F_*:T_pM\to T_{F(p)}N$ defined by $F_*X(f) = X(f \circ F)$ where $X$ is any derivation in $T_pM$ and $f:N \to \mathbb{R}$ is any smooth function.  Given a smooth chart $\phi:M \to \mathbb{R}^m$ near $p$ we have a basis for $T_pM$ given by $\frac{\partial}{\partial x^i}|_{p} = ({\phi ^{-1}}_*)\frac{\partial}{\partial x^i}|_{\phi(p)}$.  Similarly given a smooth chart $\psi$ near $F(p)$ we have a basis for $T_{F(p)}N$ given by $\frac{\partial}{\partial y^i}|_{F(p)} = ({\psi ^{-1}}_*)\frac{\partial}{\partial y^i}|_{\psi(p)}$.  A calculation in Lee shows that the matrix representation of $F_*$ with respect to these bases is the total derivative of the coordinate representation $\hat{F} = \psi \circ F \circ \phi ^{-1}$ evaluated at $\phi(p)$. My question is, is there some intuitive reason why we would expect this to be true?  This all seems very abstract to me.  I can't tell if it is supposed to be obvious that this definition should be a coordinate independent way of encoding the total derivative of $F$ and I am just missing something, or if it is just difficult to understand.  How should I think about the pushforward?",,"['differential-geometry', 'manifolds']"
13,Geodesic flows and Curvature,Geodesic flows and Curvature,,"I have some conceptual questions related to geodesic flows and cuvature. Suppose you have one parameter group of isometries from your manifold to itself. Since isometry preserves metric then it preserves Levi-Civita connection and curvature. How would one tie this to geodesic flows*. Is there a way to understand whether if a manifold has constant curvature by its geodesics (besides the criteria I gave below). For instance given a point $p$ on $M$ , if $p$ can be connected to any other point on the manifold by a geodesic (as in sphere) then does the manifold have constant curvature? I would assume that if you have a ""neighbourhood of geodesic flows"" then its pullback preserves metric on that nbd. However it is not a global isometry. *-I know one theorem where if every geodesic circle has constant curvature then the manifold has constant curvature. My second question is where can I get some information about the set of all isometries of a manifold as a space itself? Is there a good geometry book on this topic as a reference?","I have some conceptual questions related to geodesic flows and cuvature. Suppose you have one parameter group of isometries from your manifold to itself. Since isometry preserves metric then it preserves Levi-Civita connection and curvature. How would one tie this to geodesic flows*. Is there a way to understand whether if a manifold has constant curvature by its geodesics (besides the criteria I gave below). For instance given a point on , if can be connected to any other point on the manifold by a geodesic (as in sphere) then does the manifold have constant curvature? I would assume that if you have a ""neighbourhood of geodesic flows"" then its pullback preserves metric on that nbd. However it is not a global isometry. *-I know one theorem where if every geodesic circle has constant curvature then the manifold has constant curvature. My second question is where can I get some information about the set of all isometries of a manifold as a space itself? Is there a good geometry book on this topic as a reference?",p M p,"['differential-geometry', 'curvature']"
14,"Morse functions are dense in $\mathcal{C}^\infty(X,\mathbb{R})$.",Morse functions are dense in .,"\mathcal{C}^\infty(X,\mathbb{R})","In Shastri's Elements of Differential Topology, p.210-211, there is written: Why do we get a Morse function $f_u$ on $X$? We know that for any $f\!\in\!\mathcal{C}^\infty(X,\mathbb{R})$, there is some $a\!\in\!\mathbb{R}^N$, such that $f_a(x)=f(x)\!+\!\langle x,a\rangle$ is a Morse function on $X$. Since $X$ is compact, the function $|\langle\_,a\rangle|$ attains its maximal value on $X$. Then, we define $$b := \frac{a\varepsilon}{\max_{x\in X}|\langle x,a\rangle|},$$ and we have $\sup_{x\in X}|f\!-\!f_b|=\sup_{x\in X}|\langle x,b\rangle|=\frac{\sup_{x\in X}|\langle x,a\rangle|}{\max_{x\in X}|\langle x,a\rangle|}\varepsilon=\varepsilon$. But why is this $f_b$ a Morse function on $X$? Its differential is $D(f_b)_p=D(f)_p+b$, so $p\!\in\!X$ is a critical point iff $D(f)_p\!=\!-b\!=\!-\frac{a}{\ldots}$. On the other hand, the critical points of $f_a$ are those for which $D(f)_p\!=\!-a$. I do not see how to make a conclusion here.","In Shastri's Elements of Differential Topology, p.210-211, there is written: Why do we get a Morse function $f_u$ on $X$? We know that for any $f\!\in\!\mathcal{C}^\infty(X,\mathbb{R})$, there is some $a\!\in\!\mathbb{R}^N$, such that $f_a(x)=f(x)\!+\!\langle x,a\rangle$ is a Morse function on $X$. Since $X$ is compact, the function $|\langle\_,a\rangle|$ attains its maximal value on $X$. Then, we define $$b := \frac{a\varepsilon}{\max_{x\in X}|\langle x,a\rangle|},$$ and we have $\sup_{x\in X}|f\!-\!f_b|=\sup_{x\in X}|\langle x,b\rangle|=\frac{\sup_{x\in X}|\langle x,a\rangle|}{\max_{x\in X}|\langle x,a\rangle|}\varepsilon=\varepsilon$. But why is this $f_b$ a Morse function on $X$? Its differential is $D(f_b)_p=D(f)_p+b$, so $p\!\in\!X$ is a critical point iff $D(f)_p\!=\!-b\!=\!-\frac{a}{\ldots}$. On the other hand, the critical points of $f_a$ are those for which $D(f)_p\!=\!-a$. I do not see how to make a conclusion here.",,"['differential-geometry', 'differential-topology']"
15,Covector field on the sphere $S^2$ vanishing?,Covector field on the sphere  vanishing?,S^2,"Covector field on the sphere $S^2$ vanishing? There exists a smooth vector field $X$ on $S^2$ that vanishes at exactly one point, for example at the north pole. My idea is the following: Let $\beta:=\{Y_1:=X, Y_2, Y_3\}$ be a basis for $\mathbb{R}^3$. Now, take $\beta^*:=\{\phi^1,\phi^2,\phi^3\}$, the dual basis of $\beta$.","Covector field on the sphere $S^2$ vanishing? There exists a smooth vector field $X$ on $S^2$ that vanishes at exactly one point, for example at the north pole. My idea is the following: Let $\beta:=\{Y_1:=X, Y_2, Y_3\}$ be a basis for $\mathbb{R}^3$. Now, take $\beta^*:=\{\phi^1,\phi^2,\phi^3\}$, the dual basis of $\beta$.",,[]
16,Deformation of the Kähler structure on $CP^n$,Deformation of the Kähler structure on,CP^n,"Using the homogeneous coordinate on $CP^n$, we consider the open set $U_0:=\{[1, \ldots, z_n]\}$. Then the standard Kähler form of $CP^n$ can be written as $$ \omega_0=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+|z_1|^2+\cdots+|z_n|^2) $$ The compatability of this form can be easily checked for other chart $U_i$. My question is, if I want to deform this Kähler form, an easy way to do this is introducing a function say $\rho: \mathbb R\to \mathbb R$ and write the new Kähler form on $U_0$ as $$ \omega_\rho=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+\rho(|z_1|^2+\cdots+|z_n|^2)) $$ Then what are the restrictions on $\rho$ and how to write the form $\omega_\rho$ in other coordinate charts, say $U_1$?","Using the homogeneous coordinate on $CP^n$, we consider the open set $U_0:=\{[1, \ldots, z_n]\}$. Then the standard Kähler form of $CP^n$ can be written as $$ \omega_0=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+|z_1|^2+\cdots+|z_n|^2) $$ The compatability of this form can be easily checked for other chart $U_i$. My question is, if I want to deform this Kähler form, an easy way to do this is introducing a function say $\rho: \mathbb R\to \mathbb R$ and write the new Kähler form on $U_0$ as $$ \omega_\rho=\frac{\sqrt{-1}}{2}\partial\bar{\partial}\log(1+\rho(|z_1|^2+\cdots+|z_n|^2)) $$ Then what are the restrictions on $\rho$ and how to write the form $\omega_\rho$ in other coordinate charts, say $U_1$?",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
17,Universal Definition for Pullback,Universal Definition for Pullback,,"The concept of ""pullback"" has several definitions depending on the context in which it is applied, e.g., smooth functions on manifolds, differential forms, multilinear forms and so forth. See, for example, the Wikipedia Page for an enumeration of these definitions. Is there a ""universal definition"" of pullback from which these various specialized definitions can be derived or should these definitions be viewed as intrinsic and independent? I am aware of the categorical representation as discussed here , but I don't believe (perhaps I'm mistaken) that these various specialized definitions can be derived from the categorical one. Also, is it a coincidence that the adjoint of an operator and the pullback operation both share the exponentiated $*$ as an indicator or is it reflective of a deeper relationship?","The concept of ""pullback"" has several definitions depending on the context in which it is applied, e.g., smooth functions on manifolds, differential forms, multilinear forms and so forth. See, for example, the Wikipedia Page for an enumeration of these definitions. Is there a ""universal definition"" of pullback from which these various specialized definitions can be derived or should these definitions be viewed as intrinsic and independent? I am aware of the categorical representation as discussed here , but I don't believe (perhaps I'm mistaken) that these various specialized definitions can be derived from the categorical one. Also, is it a coincidence that the adjoint of an operator and the pullback operation both share the exponentiated $*$ as an indicator or is it reflective of a deeper relationship?",,"['differential-geometry', 'multilinear-algebra']"
18,Adding handles to a sphere,Adding handles to a sphere,,"I am trying to work through Boothby's An Introduction to Differentiable Manifolds on my own and, embarassingly, have got stuck at the very first chapter. At the end of section 4, chapter 1 (called: Further examples of manifolds: cutting and pasting), there's this question: Prove that adding a handle to a 2-manifolds in the fashion described above for $S^2$ and $T^2$ actually does give a 2 manifold Unfortunately, Boothby gives no formal definitions for cutting and pasting so I have no idea about how to show that a sphere with a handle will be locally euclidean. For example, what if the handle is attached to the surface such that at the joint (a circle) the two surfaces meet sharply, so that for points on the joint we cannot find a normal. So, my questions are: Where can I find the operations of cutting formalised (I realise that pasting is connected to quotient topology, so I am studying that now). And, how does one answer this question rigorously? Edit Upon further thought, 'cutting' could be this: since a manifold $M$ is metrizable, we can remove an open disk (open so that I get a boundary in the resulting manifold) around a point, i.e., we consider $M - B(p,\epsilon)$. So, given two dissimilar points, we remove two non-intersecting open disks (we can do this because a manifold is hausdorff). Now, how do I 'paste' the ends of the cylinder 'smoothly'?","I am trying to work through Boothby's An Introduction to Differentiable Manifolds on my own and, embarassingly, have got stuck at the very first chapter. At the end of section 4, chapter 1 (called: Further examples of manifolds: cutting and pasting), there's this question: Prove that adding a handle to a 2-manifolds in the fashion described above for $S^2$ and $T^2$ actually does give a 2 manifold Unfortunately, Boothby gives no formal definitions for cutting and pasting so I have no idea about how to show that a sphere with a handle will be locally euclidean. For example, what if the handle is attached to the surface such that at the joint (a circle) the two surfaces meet sharply, so that for points on the joint we cannot find a normal. So, my questions are: Where can I find the operations of cutting formalised (I realise that pasting is connected to quotient topology, so I am studying that now). And, how does one answer this question rigorously? Edit Upon further thought, 'cutting' could be this: since a manifold $M$ is metrizable, we can remove an open disk (open so that I get a boundary in the resulting manifold) around a point, i.e., we consider $M - B(p,\epsilon)$. So, given two dissimilar points, we remove two non-intersecting open disks (we can do this because a manifold is hausdorff). Now, how do I 'paste' the ends of the cylinder 'smoothly'?",,['differential-geometry']
19,Differential Geometry's lecture notes by professor Will Merry,Differential Geometry's lecture notes by professor Will Merry,,"I have recently got to know these notes from this answer, i.e., Will Merry, Differential Geometry : beautifully written notes (with problems sheets!), where lectures 1-27 cover pretty much the same stuff as the above book of Jeffrey Lee. Lectures 28-53 also center around metrics and connections, but the notion of parallel transport is worked out much more thoroughly than in Jeffrey Lee's book. It's unfortunate that the author passed away and the link (to the notes given in that answer) does not work anymore. I would like to ask if someone keeps these notes and can share them. Thank you so much!","I have recently got to know these notes from this answer, i.e., Will Merry, Differential Geometry : beautifully written notes (with problems sheets!), where lectures 1-27 cover pretty much the same stuff as the above book of Jeffrey Lee. Lectures 28-53 also center around metrics and connections, but the notion of parallel transport is worked out much more thoroughly than in Jeffrey Lee's book. It's unfortunate that the author passed away and the link (to the notes given in that answer) does not work anymore. I would like to ask if someone keeps these notes and can share them. Thank you so much!",,"['differential-geometry', 'reference-request']"
20,Hodge star duality and the metric,Hodge star duality and the metric,,"Let $X$ be a smooth compact Riemannian manifold of even dimension $2n$ . Using the Hodge star $*: \Omega^r(X) \to \Omega^{2n-r}(X)$ one can define self-dual and anti-self-dual $n$ -forms on $X$ , $$ \omega = * \omega \,, \quad \eta = - * \eta \,. $$ A property of a non-trivial (anti-)self-dual form $\xi$ is that it must have positive (negative) square-integral $\int_X \xi \wedge \xi$ , \begin{align} \int_X \omega \wedge \omega &\,=\, ~~\int_X \omega \wedge * \omega \,\equiv ~~(\omega , \omega ) > 0 \\ \int_X \eta \wedge \eta ~&\,=\, - \int_X \eta \wedge * \eta ~\, \equiv - (\eta , \eta) \,< 0 . \end{align} My question is whether the converse statement holds: Can any smooth $n$ -form with positive (negative) square-integral be made (anti-)self-dual by a choice of smooth metric?","Let be a smooth compact Riemannian manifold of even dimension . Using the Hodge star one can define self-dual and anti-self-dual -forms on , A property of a non-trivial (anti-)self-dual form is that it must have positive (negative) square-integral , My question is whether the converse statement holds: Can any smooth -form with positive (negative) square-integral be made (anti-)self-dual by a choice of smooth metric?","X 2n *: \Omega^r(X) \to \Omega^{2n-r}(X) n X 
\omega = * \omega \,, \quad \eta = - * \eta \,.
 \xi \int_X \xi \wedge \xi \begin{align}
\int_X \omega \wedge \omega &\,=\, ~~\int_X \omega \wedge * \omega \,\equiv ~~(\omega , \omega ) > 0 \\
\int_X \eta \wedge \eta ~&\,=\, - \int_X \eta \wedge * \eta ~\, \equiv - (\eta , \eta) \,< 0 .
\end{align} n","['differential-geometry', 'differential-forms', 'de-rham-cohomology', 'hodge-theory']"
21,Shortest paths on a manifold with boundary are composed solely of geodesics and boundary sections?,Shortest paths on a manifold with boundary are composed solely of geodesics and boundary sections?,,"Is the following true? Proposition : Let $M$ be a manifold with boundary $\partial M$ . For any $p, q \in M$ let $P$ be a shortest path from $p$ to $q$ . Then $P = \bigcup_{k=1}^n P_k$ where: $P_k$ is a geodesic if $k$ is odd $P_k \subseteq \partial M$ if $k$ is even My intuition is that the proposition (or something like it with suitable corrections) is well known ... but I haven't been able to find a reference. Why I am asking When $M$ is the Euclidean plane and $\partial M$ arises from removing simple polygons, the following Visibility Graph Method can be used to find a shortest path from $p$ to $q$ : Locate the vertices $V$ of the polygons Construct the visibility graph $G$ on $V \cup \{ p, q \}$ : $x, y$ are adjacent in $G$ if the line segment $xy$ is contained by $M$ Search $G$ for a shortest path $P$ from $p$ to $q$ A graph search algorithm (eg Dijkstra's algorithm or A*) will find $P$ as a shortest path in $G$ . The Proposition then ensures that $P$ is a shortest path in $M$ from $p$ to $q$ . It is natural to ask about the following generalizations of the Visibility Graph Method: $M$ is a 2-manifold and $\partial M$ arises from removing simple polygons where the polygons' edges are geodesics. Here, ""line segment $xy$ "" is replaced with ""geodesic $xy$ "". See for example this question about using visibility graphs to find shortest paths on spheres . $M$ is a 2-manifold and $\partial M$ arises from removing simple regions. (see for example this question about algorithms for finding shortest paths in manifolds ). What I have found so far The Visibility Graph Method for polyline paths in the plane amidst polygon obstacles is studied in introductions to computational geometry and path planning. See for example de Berg et al (2008) who prove the following: Lemma 15.1 (de Berg et al, 2008). Any shortest path between a start point and a goal point among a set of $S$ of disjoint polygonal obstacles is a polygonal path whose inner vertices are vertices of $S$ .  (An inner vertex is a vertex that is neither the begin- nor end-point of the path) The proof of Lemma 15.1 is that if a path $P$ can be locally shortened then it isn't a shortest path. Hence non-polygonal paths get shortened into polygonal paths, and then they get shortened until the interior vertices are vertices of the polygons. Outwardly, the proof of Lemma 15.1 resembles the preamble discussion in Pressley (2010, Section 9.4) in which it is established that the shortest path in a surface between two points is always a geodesic. The similarity is in applying local shortening until the path becomes a geodesic. Consequently for the Proposition, we can at least get to a handwaving proof that (conjecture) the portions of $P$ that are contained in $M - \partial M$ are geodesics . de Berg et al (2008) then set a exercise for extending to obstacles other than polygons. Exercise 15.3 (de Berg et al, 2008). Let $S$ be a set of $n$ disjoint disc-shaped obstacles, not necessarily of equal radius. Prove that the shortest path between two points not seeing each other consists of parts of boundaries of the discs, and/or common tangents of discs, and/or tangents from the start or goal point to the discs. This led me to think that in general (conjecture) shortest paths are composed of geodesics or boundary points . Alexander & Alexander (1981) proved Theorem (Alexander & Alexander, 1981). Let $M$ be a Reimannian $C^3$ -manifold-with- $C^1$ -boundary. A) Any shortest path of $M$ is $C^1$ . B) At any point where it touches the boundary, a shortest path of $M$ possesses an osculating plane which is normal to the boundary. They also commented If $M$ is a Euclidean space with an open convex body removed, then it is easy to see that a shortest path joining parts of the boundary $\partial M$ must lie in $\partial M$ . The Visibility Graph Method is otherwise not in the mainstream of methods for finding shortest paths on surfaces. See for example Bose et al (2011), Crane et al (2020). There appear to be two reasons: the geodesics are not easy to obtain (except in special cases such as the Euclidean plane or the sphere - see for example this question on the kind of computations that are needed generally ), and the feeling that the visibility graph is too large to work with. References de Berg, Mark; van Kreveld, Marc; Overmars, Mark; Schwarzkopf, Otfried. (2008). Computational geometry. Algorithms and applications: Third Edition. , Berlin: Springer. Pressley, Andrew. (2010). Elementary Differential Geometry: Second Edition , Springer Undergraduate Mathematics Series. London: Springer-Verlag. DOI 10.1007/978-1-84882-891-9_9 Alexander, Ralph; Alexander, S. (1981) Geodesics in Riemannian manifolds-with-boundary , Indiana Univ. Math. J. 30, 481-488. ZBL0469.53039 . Bose, Prosenjit; Maheshwari, Anil; Shu, Chang; Wuhrer, Stefanie. (2011) A survey of geodesic paths on 3D surfaces , Comput. Geom. 44, No. 9, 486-498 ZBL1231.65038 . Crane, Keenan; Livesu, Marco; Puppo, Enrico; Qin, Yipeng. (2020) A Survey of Algorithms for Geodesic Paths and Distance Maps . ArXiV 2007.10430","Is the following true? Proposition : Let be a manifold with boundary . For any let be a shortest path from to . Then where: is a geodesic if is odd if is even My intuition is that the proposition (or something like it with suitable corrections) is well known ... but I haven't been able to find a reference. Why I am asking When is the Euclidean plane and arises from removing simple polygons, the following Visibility Graph Method can be used to find a shortest path from to : Locate the vertices of the polygons Construct the visibility graph on : are adjacent in if the line segment is contained by Search for a shortest path from to A graph search algorithm (eg Dijkstra's algorithm or A*) will find as a shortest path in . The Proposition then ensures that is a shortest path in from to . It is natural to ask about the following generalizations of the Visibility Graph Method: is a 2-manifold and arises from removing simple polygons where the polygons' edges are geodesics. Here, ""line segment "" is replaced with ""geodesic "". See for example this question about using visibility graphs to find shortest paths on spheres . is a 2-manifold and arises from removing simple regions. (see for example this question about algorithms for finding shortest paths in manifolds ). What I have found so far The Visibility Graph Method for polyline paths in the plane amidst polygon obstacles is studied in introductions to computational geometry and path planning. See for example de Berg et al (2008) who prove the following: Lemma 15.1 (de Berg et al, 2008). Any shortest path between a start point and a goal point among a set of of disjoint polygonal obstacles is a polygonal path whose inner vertices are vertices of .  (An inner vertex is a vertex that is neither the begin- nor end-point of the path) The proof of Lemma 15.1 is that if a path can be locally shortened then it isn't a shortest path. Hence non-polygonal paths get shortened into polygonal paths, and then they get shortened until the interior vertices are vertices of the polygons. Outwardly, the proof of Lemma 15.1 resembles the preamble discussion in Pressley (2010, Section 9.4) in which it is established that the shortest path in a surface between two points is always a geodesic. The similarity is in applying local shortening until the path becomes a geodesic. Consequently for the Proposition, we can at least get to a handwaving proof that (conjecture) the portions of that are contained in are geodesics . de Berg et al (2008) then set a exercise for extending to obstacles other than polygons. Exercise 15.3 (de Berg et al, 2008). Let be a set of disjoint disc-shaped obstacles, not necessarily of equal radius. Prove that the shortest path between two points not seeing each other consists of parts of boundaries of the discs, and/or common tangents of discs, and/or tangents from the start or goal point to the discs. This led me to think that in general (conjecture) shortest paths are composed of geodesics or boundary points . Alexander & Alexander (1981) proved Theorem (Alexander & Alexander, 1981). Let be a Reimannian -manifold-with- -boundary. A) Any shortest path of is . B) At any point where it touches the boundary, a shortest path of possesses an osculating plane which is normal to the boundary. They also commented If is a Euclidean space with an open convex body removed, then it is easy to see that a shortest path joining parts of the boundary must lie in . The Visibility Graph Method is otherwise not in the mainstream of methods for finding shortest paths on surfaces. See for example Bose et al (2011), Crane et al (2020). There appear to be two reasons: the geodesics are not easy to obtain (except in special cases such as the Euclidean plane or the sphere - see for example this question on the kind of computations that are needed generally ), and the feeling that the visibility graph is too large to work with. References de Berg, Mark; van Kreveld, Marc; Overmars, Mark; Schwarzkopf, Otfried. (2008). Computational geometry. Algorithms and applications: Third Edition. , Berlin: Springer. Pressley, Andrew. (2010). Elementary Differential Geometry: Second Edition , Springer Undergraduate Mathematics Series. London: Springer-Verlag. DOI 10.1007/978-1-84882-891-9_9 Alexander, Ralph; Alexander, S. (1981) Geodesics in Riemannian manifolds-with-boundary , Indiana Univ. Math. J. 30, 481-488. ZBL0469.53039 . Bose, Prosenjit; Maheshwari, Anil; Shu, Chang; Wuhrer, Stefanie. (2011) A survey of geodesic paths on 3D surfaces , Comput. Geom. 44, No. 9, 486-498 ZBL1231.65038 . Crane, Keenan; Livesu, Marco; Puppo, Enrico; Qin, Yipeng. (2020) A Survey of Algorithms for Geodesic Paths and Distance Maps . ArXiV 2007.10430","M \partial M p, q \in M P p q P = \bigcup_{k=1}^n P_k P_k k P_k \subseteq \partial M k M \partial M p q V G V \cup \{ p, q \} x, y G xy M G P p q P G P M p q M \partial M xy xy M \partial M S S P P M - \partial M S n M C^3 C^1 M C^1 M M \partial M \partial M","['differential-geometry', 'reference-request', 'metric-spaces', 'riemannian-geometry', 'manifolds-with-boundary']"
22,"Is there a relationship between the multiplicity of an index and the ""algebraic"" multiplicity of a zero of a section from a (complex) vector bundle?","Is there a relationship between the multiplicity of an index and the ""algebraic"" multiplicity of a zero of a section from a (complex) vector bundle?",,"I'm a physicist who is trying to make sense of the relationship between the number of zeros of a section from an associated vector bundle and the Euler characteristic. My interest lies in applications to gauge theories in which finite energy solutions can be classified according to a topological charge (which is a Chern number/topological degree in the cases I know, and can be related to the Euler characteristic). More precisely, let us consider theorem 11.17 in the book Differential forms ins algebraic Topology from Bott-Tu: Let $\pi:E\to M$ be an oriented rank k vector bundle over a compact oriented manifold of dimension k. Let s be a section of E with a finite number of zeros. The Euler class of E is Poincare dual to the zeros of s, counted with the appropriate multiplicities. I have sometimes found it stated that the topological degree counts the number of zeros of a section, with multiplicity. I believe the above theorem is the mathematical justification for this (do correct me if I am wrong, please). But the multiplicity this theorem is talking about is ""the local degree of x as a singularity of the section $s/||s||$ of the unit sphere bundle of E relative to some Riemannian structure on E"", according to the authors. I wanna know when (if ever) there exists a relationship between this meaning of multiplicity and that found in, say, complex analysis (that's what I called algebraic multiplicity in the title). I will assume the zeros are isolated. My question was motivated by the behavior of axially symmetric magnetic vortices in the static case of the Nielsen-Olesen/Ginzburg-Landau theory. Here we have a scalar field $\varphi:\mathbb{R^2}\to\mathbb{C}$ , seen as a section of the line bundle. Axially symmetric solutions can be taken in the form $\varphi=f(r)e^{in\theta}$ , where $n$ is the (integer) topological degree. This field is coupled to a connection $A_{\theta}=A_{\theta}(r)$ . The boundary conditions ensure those fields are nonsingular and that the magnetic flux is proportional to $n$ . $\varphi$ must have a zero at the origin (and nowhere else). The multiplicity of this zero, in the sense described by Bott-Tu, is indeed $n$ , and it may be verified that $f(r)\propto r^n$ to leading order in its power series expansion, so $f(r)$ has a zero of multiplicity $n$ . This sounds a lot like the Argument Principle, with the difference that $\varphi$ does not have a complex domain. If $r$ and $\theta$ could be seen as polar coordinates in the complex plane, then this would be a zero of multiplicity $n$ in $\mathbb{C}$ . The exact same $r^n$ behavior appears in all vortex theories I know, like [Maxwell or pure] Chern-Simons and many other generalized models, some very different from Nielsen-Olesen. I'm interested in developing models in gauge theories such as the aforementioned ones (with the exact same topology, bundle and covariant derivative, but different equations of motion), and would like to know if I should expect such a behavior to occur in the solutions to such theories. Could I find a solution where, for example, $f(r)\propto r^m$ , where $m\neq n$ or would that somehow lead to a problem in my theory? Can the degree be used to predict anything about the multiplicity of the zeros of $f(r)$ ? Edit (because I accidentally pressed enter before finishing the current bounty description, and didn't find a way to edit that description): While a very good answer has been provided, I still haven't been able to figure out (even after reading some of the references) if something like $f(r)\propto r^m$ could be obtained as a leading order approximation near the origin, with $m\neq n$ . The answer to that might be implicit from the current answer, but I can't see it. A definite answer to the last paragraph preceding this edit is sufficient for the reward (although any information concerning sections with a form more general than the proposed $f(r) e^{in\theta}$ will be greatly appreciated as well).","I'm a physicist who is trying to make sense of the relationship between the number of zeros of a section from an associated vector bundle and the Euler characteristic. My interest lies in applications to gauge theories in which finite energy solutions can be classified according to a topological charge (which is a Chern number/topological degree in the cases I know, and can be related to the Euler characteristic). More precisely, let us consider theorem 11.17 in the book Differential forms ins algebraic Topology from Bott-Tu: Let be an oriented rank k vector bundle over a compact oriented manifold of dimension k. Let s be a section of E with a finite number of zeros. The Euler class of E is Poincare dual to the zeros of s, counted with the appropriate multiplicities. I have sometimes found it stated that the topological degree counts the number of zeros of a section, with multiplicity. I believe the above theorem is the mathematical justification for this (do correct me if I am wrong, please). But the multiplicity this theorem is talking about is ""the local degree of x as a singularity of the section of the unit sphere bundle of E relative to some Riemannian structure on E"", according to the authors. I wanna know when (if ever) there exists a relationship between this meaning of multiplicity and that found in, say, complex analysis (that's what I called algebraic multiplicity in the title). I will assume the zeros are isolated. My question was motivated by the behavior of axially symmetric magnetic vortices in the static case of the Nielsen-Olesen/Ginzburg-Landau theory. Here we have a scalar field , seen as a section of the line bundle. Axially symmetric solutions can be taken in the form , where is the (integer) topological degree. This field is coupled to a connection . The boundary conditions ensure those fields are nonsingular and that the magnetic flux is proportional to . must have a zero at the origin (and nowhere else). The multiplicity of this zero, in the sense described by Bott-Tu, is indeed , and it may be verified that to leading order in its power series expansion, so has a zero of multiplicity . This sounds a lot like the Argument Principle, with the difference that does not have a complex domain. If and could be seen as polar coordinates in the complex plane, then this would be a zero of multiplicity in . The exact same behavior appears in all vortex theories I know, like [Maxwell or pure] Chern-Simons and many other generalized models, some very different from Nielsen-Olesen. I'm interested in developing models in gauge theories such as the aforementioned ones (with the exact same topology, bundle and covariant derivative, but different equations of motion), and would like to know if I should expect such a behavior to occur in the solutions to such theories. Could I find a solution where, for example, , where or would that somehow lead to a problem in my theory? Can the degree be used to predict anything about the multiplicity of the zeros of ? Edit (because I accidentally pressed enter before finishing the current bounty description, and didn't find a way to edit that description): While a very good answer has been provided, I still haven't been able to figure out (even after reading some of the references) if something like could be obtained as a leading order approximation near the origin, with . The answer to that might be implicit from the current answer, but I can't see it. A definite answer to the last paragraph preceding this edit is sufficient for the reward (although any information concerning sections with a form more general than the proposed will be greatly appreciated as well).",\pi:E\to M s/||s|| \varphi:\mathbb{R^2}\to\mathbb{C} \varphi=f(r)e^{in\theta} n A_{\theta}=A_{\theta}(r) n \varphi n f(r)\propto r^n f(r) n \varphi r \theta n \mathbb{C} r^n f(r)\propto r^m m\neq n f(r) f(r)\propto r^m m\neq n f(r) e^{in\theta},"['differential-geometry', 'differential-topology', 'mathematical-physics', 'fiber-bundles', 'characteristic-classes']"
23,Section 4.2 in Loring Tu's Differential Geometry,Section 4.2 in Loring Tu's Differential Geometry,,"Section 4.2 in Loring Tu's Differential Geometry : My Question: Since $D_XY −D_YX = [X,Y]$ , then why define the quantity $T(X,Y)=D_XY −D_YX - [X,Y]$ ? Isn't $T$ always equal to $0$ ? I got very confused, and I want to know whether I have got anything wrong.","Section 4.2 in Loring Tu's Differential Geometry : My Question: Since , then why define the quantity ? Isn't always equal to ? I got very confused, and I want to know whether I have got anything wrong.","D_XY −D_YX = [X,Y] T(X,Y)=D_XY −D_YX - [X,Y] T 0","['differential-geometry', 'smooth-manifolds', 'connections']"
24,Is there an analogue of the moduli space of the torus in semi-Riemannian signature?,Is there an analogue of the moduli space of the torus in semi-Riemannian signature?,,"I'm starting to study Riemann surfaces and already met the fact that Riemann surfaces have both a complex structure and a conformal structure that are, in fact, very closely related. If we consider a Riemann surface one can classify the different conformal structures and if I correctly understand the space whose points label these different conformal structures is the so-called Riemann moduli space. For the torus the moduli space is $${\cal M}={\cal H}/{\rm PSL(2,\mathbb{Z}})$$ where ${\cal H}$ is the upper half plane in $\mathbb{C}$ and ${\rm PSL}(2,\mathbb{Z})={\rm SL}(2,\mathbb{Z})/\mathbb{Z}_2$ . So the distinct conformal structures of the torus are identified by a complex number $\tau$ with ${\rm Re}(\tau)\leq 1/2$ , ${\rm Im}(\tau)>0$ and $|\tau|>1$ . Now, all of this is in the context of Riemann surfaces which are equipped with a conformal structure and hence with an equivalence class of Riemannian metrics. But I would say nothing stops us from picking the manifold $\mathbb{T}^2=S^1\times S^1$ and endowing it with a Lorentzian metric, like $$g=-d\phi\otimes d\phi+d\psi\otimes d\psi,$$ where $\phi$ and $\psi$ are angle coordinate functions on $S^1$ and $(\phi,\psi)$ is the product chart. Question : Is there an analogue of the moduli space and of the modular parameter for such a Lorentzian torus? My intuition says that there should be because we can still consider two Lorentzian metrics conformally equivalent if they are a Weyl rescaling of one another, and we can still talk about a conformal structure as an equivalence class of such metrics.","I'm starting to study Riemann surfaces and already met the fact that Riemann surfaces have both a complex structure and a conformal structure that are, in fact, very closely related. If we consider a Riemann surface one can classify the different conformal structures and if I correctly understand the space whose points label these different conformal structures is the so-called Riemann moduli space. For the torus the moduli space is where is the upper half plane in and . So the distinct conformal structures of the torus are identified by a complex number with , and . Now, all of this is in the context of Riemann surfaces which are equipped with a conformal structure and hence with an equivalence class of Riemannian metrics. But I would say nothing stops us from picking the manifold and endowing it with a Lorentzian metric, like where and are angle coordinate functions on and is the product chart. Question : Is there an analogue of the moduli space and of the modular parameter for such a Lorentzian torus? My intuition says that there should be because we can still consider two Lorentzian metrics conformally equivalent if they are a Weyl rescaling of one another, and we can still talk about a conformal structure as an equivalence class of such metrics.","{\cal M}={\cal H}/{\rm PSL(2,\mathbb{Z}}) {\cal H} \mathbb{C} {\rm PSL}(2,\mathbb{Z})={\rm SL}(2,\mathbb{Z})/\mathbb{Z}_2 \tau {\rm Re}(\tau)\leq 1/2 {\rm Im}(\tau)>0 |\tau|>1 \mathbb{T}^2=S^1\times S^1 g=-d\phi\otimes d\phi+d\psi\otimes d\psi, \phi \psi S^1 (\phi,\psi)","['differential-geometry', 'riemann-surfaces', 'conformal-geometry', 'semi-riemannian-geometry']"
25,What are the research areas in differential geometry involving Lie Groups action?,What are the research areas in differential geometry involving Lie Groups action?,,"I love Lie groups actions! My contact with this topic occurred in the context of differentiable manifolds and riemannian geometry courses, and while studying Klein geometries. My knowledge is still very limited, though. I would like to specialize on a research area in which I could work a lot with Lie groups action from a geometric point of view. It would be very nice if I could find some suggestions/possibilities here. I'm not connected to the university now and I couldn't find pithy information on the internet. Thank you all, in advance.","I love Lie groups actions! My contact with this topic occurred in the context of differentiable manifolds and riemannian geometry courses, and while studying Klein geometries. My knowledge is still very limited, though. I would like to specialize on a research area in which I could work a lot with Lie groups action from a geometric point of view. It would be very nice if I could find some suggestions/possibilities here. I'm not connected to the university now and I couldn't find pithy information on the internet. Thank you all, in advance.",,"['differential-geometry', 'lie-groups']"
26,$M\setminus \mathrm{Cut}(L)$ deforms to $L$,deforms to,M\setminus \mathrm{Cut}(L) L,"Let $M$ be a connected complete Riemannian manifold, $p\in M$ and $\mathrm{Cu}(p)$ denotes the cut locus of a point . This is a standard result that $M\setminus\mathrm{Cu}(p)$ deforms to $p$ . Now if $L$ is a compact submanifold of $M$ and $\mathrm{C}u(L)$ denotes the cut locus of $L$ then is it true that $M\setminus \mathrm{Cu}(L)$ deforms to $L$ . I checked some of the examples and it worked. But I am unable to prove this fact. Any reference or proof will be appreciated. Edit We say $q\in \mathrm{Cu}(L)$ if any distance minimal geodesic joining $L$ to $q$ is no longer distance minimal beyond $q$ . By deformation, I mean to find $$H:M\setminus \mathrm{Cu}(L)\times [0,1]\to M\setminus \mathrm{Cu}(L)$$ such that $H(x,0)= x,~ H(q,1)\in L$ and $H(q,t)=q$ (if $q\in L$ ). Thanks!","Let be a connected complete Riemannian manifold, and denotes the cut locus of a point . This is a standard result that deforms to . Now if is a compact submanifold of and denotes the cut locus of then is it true that deforms to . I checked some of the examples and it worked. But I am unable to prove this fact. Any reference or proof will be appreciated. Edit We say if any distance minimal geodesic joining to is no longer distance minimal beyond . By deformation, I mean to find such that and (if ). Thanks!","M p\in M \mathrm{Cu}(p) M\setminus\mathrm{Cu}(p) p L M \mathrm{C}u(L) L M\setminus \mathrm{Cu}(L) L q\in \mathrm{Cu}(L) L q q H:M\setminus \mathrm{Cu}(L)\times [0,1]\to M\setminus \mathrm{Cu}(L) H(x,0)= x,~ H(q,1)\in L H(q,t)=q q\in L","['differential-geometry', 'riemannian-geometry']"
27,"Every connected orientable smooth manifold has exactly two orientations, Lee Proposition 15.9","Every connected orientable smooth manifold has exactly two orientations, Lee Proposition 15.9",,"The proof of Proposition 15.9 from John Lee's book ""Introduction to Smooth Manifolds"" is left as an exercise. Here is the statement: Let $M$ be a connected, orientable, smooth manifold with or without boundary. Then $M$ has exactly two orientations. If two orientations of $M$ agree at one point, they are equal. Here is my argument Let $\mathcal{O}=\{\mathcal{O}_p:p\in M\}$ and $\tilde{\mathcal{O}}=\{\tilde{\mathcal{O}}_p:p\in M\}$ be orientations for $M$ . Let $\mathcal {C}=\{p\in M:\mathcal O_p=\tilde{\mathcal O}_p\}$ , and let $p\in \mathcal C$ . By definition there exist $(E_i:U\to TM)$ and $(\tilde E_i:\tilde U\to TM)$ (continuous) local frames such that $p\in U\cap \tilde U$ and $(E_i)$ is positively oriented with respect to $\mathcal O$ and $(\tilde E_i)$ is positively oriented with respect to $\tilde {\mathcal O}$ . We can suppose $U\subseteq \tilde U$ and $U$ connected. Since $\mathcal O_p=\tilde{\mathcal O}_p$ we have that the ordered basis $(E_1|_p,\dots,E_n|_p)$ and $(\tilde E_1|_p,\dots,\tilde E_n|_p)$ are consistently oriented, meaning that the transition matrix $A(p)=(A_i^j(p))$ has positive determinant. The map det $_A:U\to \mathbb{R}, q \mapsto$ det $A(q)$ is continuous (where $A(q)$ is the transition matrix between the ordered basis $(E_1|_q,\dots,E_n|_q)$ and $(\tilde E_1|_q,\dots,\tilde E_n|_q)$ ) and since $U$ is connected and det $A(p)>0$ we have that det $_A$ is always positive on $U$ . This implies that $U\subseteq \mathcal C$ , and thus $\mathcal C$ is open in $M$ . Analogously we show that $M-\mathcal C$ is open in $M$ . Since $M$ is connected we have $\mathcal C=\emptyset$ or $\mathcal C=M$ . In the second case we have $\mathcal O=\tilde{\mathcal O}$ . In the first case $\mathcal O$ and $\tilde{\mathcal O}$ are two distinct orientations of $M$ and any other orientation $\hat{\mathcal O}$ of $M$ would have $\hat{\mathcal O_p}=\mathcal O_p$ or $\hat{\mathcal O_p}=\tilde{\mathcal O_p}$ , and thus we would have $\hat{\mathcal O}=\mathcal O$ or $\hat{\mathcal O}=\tilde{\mathcal O}$ . $\qquad\square$ To be precise I should also prove the existence of two distinct orientations. But if $\mathcal O$ is the orientation which exists by hypothesis, then $-\mathcal O$ is another orientation. So we have at least two (distinct) orientations of $M$ . Please let me know if my proof is correct and if it can be shortened/ simplified.","The proof of Proposition 15.9 from John Lee's book ""Introduction to Smooth Manifolds"" is left as an exercise. Here is the statement: Let be a connected, orientable, smooth manifold with or without boundary. Then has exactly two orientations. If two orientations of agree at one point, they are equal. Here is my argument Let and be orientations for . Let , and let . By definition there exist and (continuous) local frames such that and is positively oriented with respect to and is positively oriented with respect to . We can suppose and connected. Since we have that the ordered basis and are consistently oriented, meaning that the transition matrix has positive determinant. The map det det is continuous (where is the transition matrix between the ordered basis and ) and since is connected and det we have that det is always positive on . This implies that , and thus is open in . Analogously we show that is open in . Since is connected we have or . In the second case we have . In the first case and are two distinct orientations of and any other orientation of would have or , and thus we would have or . To be precise I should also prove the existence of two distinct orientations. But if is the orientation which exists by hypothesis, then is another orientation. So we have at least two (distinct) orientations of . Please let me know if my proof is correct and if it can be shortened/ simplified.","M M M \mathcal{O}=\{\mathcal{O}_p:p\in M\} \tilde{\mathcal{O}}=\{\tilde{\mathcal{O}}_p:p\in M\} M \mathcal {C}=\{p\in M:\mathcal O_p=\tilde{\mathcal O}_p\} p\in \mathcal C (E_i:U\to TM) (\tilde E_i:\tilde U\to TM) p\in U\cap \tilde U (E_i) \mathcal O (\tilde E_i) \tilde {\mathcal O} U\subseteq \tilde U U \mathcal O_p=\tilde{\mathcal O}_p (E_1|_p,\dots,E_n|_p) (\tilde E_1|_p,\dots,\tilde E_n|_p) A(p)=(A_i^j(p)) _A:U\to \mathbb{R}, q \mapsto A(q) A(q) (E_1|_q,\dots,E_n|_q) (\tilde E_1|_q,\dots,\tilde E_n|_q) U A(p)>0 _A U U\subseteq \mathcal C \mathcal C M M-\mathcal C M M \mathcal C=\emptyset \mathcal C=M \mathcal O=\tilde{\mathcal O} \mathcal O \tilde{\mathcal O} M \hat{\mathcal O} M \hat{\mathcal O_p}=\mathcal O_p \hat{\mathcal O_p}=\tilde{\mathcal O_p} \hat{\mathcal O}=\mathcal O \hat{\mathcal O}=\tilde{\mathcal O} \qquad\square \mathcal O -\mathcal O M","['differential-geometry', 'manifolds', 'smooth-manifolds', 'orientation']"
28,Finding a metric to write a vector field as a gradient of a given function,Finding a metric to write a vector field as a gradient of a given function,,"Let $M$ be a smooth manifold, and $f$ a smooth function with an isolated local minimum at $p$. Furthermore, let $X$ be a vector field vanishing at $p$ such that for some neighborhood $U$ of $p$, $df_q(X_q)<0$ for all $q\in U\setminus\{p\}$. Is it possible to find a Riemannian metric g on $U$ such that $X|_U=-\text{grad}_gf$? If not, what is a counterexample?","Let $M$ be a smooth manifold, and $f$ a smooth function with an isolated local minimum at $p$. Furthermore, let $X$ be a vector field vanishing at $p$ such that for some neighborhood $U$ of $p$, $df_q(X_q)<0$ for all $q\in U\setminus\{p\}$. Is it possible to find a Riemannian metric g on $U$ such that $X|_U=-\text{grad}_gf$? If not, what is a counterexample?",,"['differential-geometry', 'riemannian-geometry', 'vector-analysis', 'gradient-flows']"
29,What do we know about the geometry and topology of the space of Riemannian metrics with non negative scalar curvature on $\mathbb{R}^n$?,What do we know about the geometry and topology of the space of Riemannian metrics with non negative scalar curvature on ?,\mathbb{R}^n,"In these days I was trying to minimize a Riemannian functional on the space of Riemannian metrics  with non negative scalar curvature over a manifold, and I suddenly realize that I don't know nothing about how this space looks like. In particular I don't even know if it is a vector space, if it is convex, star shaped, path connected or connected.  This led me to ask the following questions. Consider $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ the topological space of the Riemannian metrics on $\mathbb{R}^n$ that have non negative scalar curvature. We give to it the topology induced by the inclusion $\mathcal{M}_{\geq 0}(\mathbb{R}^n)\subset C^{\infty}(T^0_2 \mathbb{R}^n)$ in the space  of sections of (0,2)-tensors.  $C^{\infty}(T^0_2 \mathbb{R}^n)$ has the norm given by the usual inner product between (0,2) tensors integrated over the manifold. Is $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ connected? Path connected? $C^1$ path connected? Star shaped? Convex? Vector space? Is there any interesting dense subset? For example is the set of non negative sectional curvature a dense subset? What happens if instead of considering the scalar curvature, which is the first elementary symmetric function in the eigenvalues of the (2,2) type Riemann tensor we consider other elementary symmetric functions? If we consider a generic $n$-manifold, the space $\mathcal{M}_{\geq 0}(\mathbb{M}^n)$ can be empty, if not what remains true?","In these days I was trying to minimize a Riemannian functional on the space of Riemannian metrics  with non negative scalar curvature over a manifold, and I suddenly realize that I don't know nothing about how this space looks like. In particular I don't even know if it is a vector space, if it is convex, star shaped, path connected or connected.  This led me to ask the following questions. Consider $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ the topological space of the Riemannian metrics on $\mathbb{R}^n$ that have non negative scalar curvature. We give to it the topology induced by the inclusion $\mathcal{M}_{\geq 0}(\mathbb{R}^n)\subset C^{\infty}(T^0_2 \mathbb{R}^n)$ in the space  of sections of (0,2)-tensors.  $C^{\infty}(T^0_2 \mathbb{R}^n)$ has the norm given by the usual inner product between (0,2) tensors integrated over the manifold. Is $\mathcal{M}_{\geq 0}(\mathbb{R}^n)$ connected? Path connected? $C^1$ path connected? Star shaped? Convex? Vector space? Is there any interesting dense subset? For example is the set of non negative sectional curvature a dense subset? What happens if instead of considering the scalar curvature, which is the first elementary symmetric function in the eigenvalues of the (2,2) type Riemann tensor we consider other elementary symmetric functions? If we consider a generic $n$-manifold, the space $\mathcal{M}_{\geq 0}(\mathbb{M}^n)$ can be empty, if not what remains true?",,"['differential-geometry', 'riemannian-geometry', 'curvature']"
30,Calculate the extrinsic distance between two points on an embedded 2-manifold.,Calculate the extrinsic distance between two points on an embedded 2-manifold.,,"Given an embedded closed 2-manifold with intrinsic metric $g_{ab}(\sigma_1,\sigma_2)$ embedded in $\mathbb{R}^3$. The surface is analytic (not just $C^\infty$). We are given only the metric and not the equation of the surface. What is the formula to calculate the extrinsic distance between two points $(\sigma_1,\sigma_2)$ and $(\sigma_1',\sigma_2')$. That is the straight line in 3 dimensions, written only in terms of the intrinsic metric? I think it must have something to do with the second fundamental form which gives the local embedding or the Ricci tensor. My guess would be it would be an integral of some functional of $g$ on a curve between the two points on the surface. $L=\int F[g].d\sigma$. If such a formula could exist. (The formula won't exist when the 2-manifold has zero intrinsic curvature.) As an example, take a sphere with the sphere metric and then the distance we're looking for is the distance between two points on a sphere with a straight line going inside the sphere.) Edit: The answer must apply to analytic surfaces only . (Not just $C^\infty$ continuously differentiable.) An analytic surface is one in which the surface can be expressed as functions which can be expanded as taylor series - not piecewise surfaces such as the bump function. Edit: I know the second fundamental $I_{ab}$ form is connected to the Riemann tensor by $R_{abcd}[g] = I_{ab}I_{cd}-I_{ac}I_{bd}$ which gives the metric in terms of the fundamental form. But what is needed is the reverse, a way to get the fundamental form in terms of the metric in cases where there is a unique embedding up to translations and rotations.","Given an embedded closed 2-manifold with intrinsic metric $g_{ab}(\sigma_1,\sigma_2)$ embedded in $\mathbb{R}^3$. The surface is analytic (not just $C^\infty$). We are given only the metric and not the equation of the surface. What is the formula to calculate the extrinsic distance between two points $(\sigma_1,\sigma_2)$ and $(\sigma_1',\sigma_2')$. That is the straight line in 3 dimensions, written only in terms of the intrinsic metric? I think it must have something to do with the second fundamental form which gives the local embedding or the Ricci tensor. My guess would be it would be an integral of some functional of $g$ on a curve between the two points on the surface. $L=\int F[g].d\sigma$. If such a formula could exist. (The formula won't exist when the 2-manifold has zero intrinsic curvature.) As an example, take a sphere with the sphere metric and then the distance we're looking for is the distance between two points on a sphere with a straight line going inside the sphere.) Edit: The answer must apply to analytic surfaces only . (Not just $C^\infty$ continuously differentiable.) An analytic surface is one in which the surface can be expressed as functions which can be expanded as taylor series - not piecewise surfaces such as the bump function. Edit: I know the second fundamental $I_{ab}$ form is connected to the Riemann tensor by $R_{abcd}[g] = I_{ab}I_{cd}-I_{ac}I_{bd}$ which gives the metric in terms of the fundamental form. But what is needed is the reverse, a way to get the fundamental form in terms of the metric in cases where there is a unique embedding up to translations and rotations.",,"['differential-geometry', 'riemannian-geometry']"
31,Changes of coordinates in differential geometry,Changes of coordinates in differential geometry,,"I'm taking an undergraduate differential geometry class, and because either because the professor has chosen to forgo rigor (as a background in analysis isn't required and most of the class has negligible proof-writing experience) or else because I'm just not getting it, I'm having a lot of difficulty understanding the way he discusses changes of coordinates. This is the general description he gives: If we change local coordinates from $\{x^1, ..., x^i, ... x^n\} $ to $\{\hat{x}^1, ..., \hat{x}^{\alpha},..., \hat{x}^n\}$ by the map $F$, the vector field $U = u^iX_i$ to $\hat{U} = \hat{u}^{\alpha}\hat{X}_{\alpha}$ $\hat{U} = DF(U)$ and $\hat{u}^{\alpha} = \frac{\partial \hat{x}^{\alpha}}{\partial x^i}u^i$ I understand (I think) what all the symbols mean, and I'm comfortable with Einstein summation convention, and the idea of a derivative map (again, at an unrigorous, undergrad level). That said, I cannot for the life of me understand why if the coordinates transform under $F$, why the vector transforms under $DF$. I would like a) some intuition about this (if there's an intuitive way to view it) and b) a way to show that this is true (if there's a straightforward, fairly elementary way to show it). Thanks!","I'm taking an undergraduate differential geometry class, and because either because the professor has chosen to forgo rigor (as a background in analysis isn't required and most of the class has negligible proof-writing experience) or else because I'm just not getting it, I'm having a lot of difficulty understanding the way he discusses changes of coordinates. This is the general description he gives: If we change local coordinates from $\{x^1, ..., x^i, ... x^n\} $ to $\{\hat{x}^1, ..., \hat{x}^{\alpha},..., \hat{x}^n\}$ by the map $F$, the vector field $U = u^iX_i$ to $\hat{U} = \hat{u}^{\alpha}\hat{X}_{\alpha}$ $\hat{U} = DF(U)$ and $\hat{u}^{\alpha} = \frac{\partial \hat{x}^{\alpha}}{\partial x^i}u^i$ I understand (I think) what all the symbols mean, and I'm comfortable with Einstein summation convention, and the idea of a derivative map (again, at an unrigorous, undergrad level). That said, I cannot for the life of me understand why if the coordinates transform under $F$, why the vector transforms under $DF$. I would like a) some intuition about this (if there's an intuitive way to view it) and b) a way to show that this is true (if there's a straightforward, fairly elementary way to show it). Thanks!",,"['differential-geometry', 'coordinate-systems', 'change-of-basis']"
32,Why is negative divergence an adjoint of gradient?,Why is negative divergence an adjoint of gradient?,,"In my notes, I have $\langle F, \nabla f\rangle_{L^2(\mathcal{TX})} = \langle   \nabla^* F, f\rangle_{L^2(\mathcal{X})} = \langle -\operatorname{div} F, f\rangle_{L^2(\mathcal{X})}$, where $f$ is a scalar field, $F$ is a vector field, $\mathcal X$ is a manifold and $T\mathcal X$ is a tangent plane. My question is why is negative divergence an adjoint of gradient?","In my notes, I have $\langle F, \nabla f\rangle_{L^2(\mathcal{TX})} = \langle   \nabla^* F, f\rangle_{L^2(\mathcal{X})} = \langle -\operatorname{div} F, f\rangle_{L^2(\mathcal{X})}$, where $f$ is a scalar field, $F$ is a vector field, $\mathcal X$ is a manifold and $T\mathcal X$ is a tangent plane. My question is why is negative divergence an adjoint of gradient?",,['differential-geometry']
33,Mean value property of harmonic functions on manifolds,Mean value property of harmonic functions on manifolds,,"A well-known feature of harmonic functions on (domains of) $\mathbb{R}^n$ is the mean-value property: that is, if $\Delta u = 0$, then $$ u(x_0) = \frac{1}{\text{Vol}(\partial B_r(x_0))}\int_{\partial B_r(x_0)}{u\,dS} = \frac{1}{\text{Vol}(B_r(x_0))}\int_{B_r(x_0)}{u\,dV}. $$ Is the same true on manifolds in general? That is, given a manifold $(M,g)$ and a smooth function $u:M\rightarrow\mathbb{R}$ satisfying $$\Delta_gu = 0\quad\text{where}\quad\Delta_g = \frac{1}{\sqrt{\det g}}\frac{\partial}{\partial x^i}g^{ij}\sqrt{\det g}\frac{\partial}{\partial x^j},$$ is it true that $$ u(x_0) = \frac{1}{\text{Vol}(\partial B_r(x_0))}\int_{\partial B_r(x_0)}{u\,dS}\quad\text{or}\quad u(x_0) = \frac{1}{\text{Vol}(B_r(x_0))}\int_{B_r(x_0)}{u\,dV}?$$ Here, $B_r(x_0)$ is the geodesic ball of radius $r$ around $x_0$. If the equalities do not hold, how would the average value (either over a sphere or over a ball) change with $r$? For example, on a surface the Gaussian curvature appears in the higher-order terms in the Taylor expansion of the length/area of a circle/ball of radius $r$--does a similar phenomenon occur for the mean value?","A well-known feature of harmonic functions on (domains of) $\mathbb{R}^n$ is the mean-value property: that is, if $\Delta u = 0$, then $$ u(x_0) = \frac{1}{\text{Vol}(\partial B_r(x_0))}\int_{\partial B_r(x_0)}{u\,dS} = \frac{1}{\text{Vol}(B_r(x_0))}\int_{B_r(x_0)}{u\,dV}. $$ Is the same true on manifolds in general? That is, given a manifold $(M,g)$ and a smooth function $u:M\rightarrow\mathbb{R}$ satisfying $$\Delta_gu = 0\quad\text{where}\quad\Delta_g = \frac{1}{\sqrt{\det g}}\frac{\partial}{\partial x^i}g^{ij}\sqrt{\det g}\frac{\partial}{\partial x^j},$$ is it true that $$ u(x_0) = \frac{1}{\text{Vol}(\partial B_r(x_0))}\int_{\partial B_r(x_0)}{u\,dS}\quad\text{or}\quad u(x_0) = \frac{1}{\text{Vol}(B_r(x_0))}\int_{B_r(x_0)}{u\,dV}?$$ Here, $B_r(x_0)$ is the geodesic ball of radius $r$ around $x_0$. If the equalities do not hold, how would the average value (either over a sphere or over a ball) change with $r$? For example, on a surface the Gaussian curvature appears in the higher-order terms in the Taylor expansion of the length/area of a circle/ball of radius $r$--does a similar phenomenon occur for the mean value?",,"['differential-geometry', 'harmonic-functions']"
34,Computing the first variation of volume: all around confusion,Computing the first variation of volume: all around confusion,,"$\DeclareMathOperator{\vol}{vol}$I've been working through the computation of the first variation of volume presented in Jost's Riemannian Geometry and Geometric Analysis (page 196 in the sixth edition, section titled: Minimal Submanifolds ), and I've been getting caught up in all the notation, and I've been having a lot of trouble exactly understanding how to interpret the partial derivatives in this context. I'll start with the setup: let $M$ be a smooth submanifold of $N$ and let $F:M\times(-\epsilon,\epsilon)\to N$ be a local variation with compact support. For small enough $t$ we have that $\Phi_t(\cdot):=F(\cdot,t)$ is a diffeomorphism from $M\to M_t\subseteq N$. Now let $\{e_1,\dots,e_m\}$ be an orthonormal frame on $M$. Using this diffeomorphism we can write $$\vol(M_t)=\int_{M}\left\langle\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle^{\frac{1}{2}}\eta_{M},$$ where $\langle{\cdot,\cdot}\rangle$ is the induced inner product on $\bigwedge^m(TN)$, that is $\langle{v_1\wedge\cdots\wedge v_m,w_1\wedge\cdots\wedge w_m}\rangle=\det(\langle{v_i,w_j}\rangle)$, and $\eta_M$ denotes the Riemannian volume form on $M$. Then we differentiate this with respect to $t$ to find that $$ \left.\frac{d}{dt}\vol(M_t)\right|_{t=0}=\left.\sum_{i=1}^{m}\int_{M}\frac{\left\langle\Phi_{t*}e_1\wedge\frac{\partial}{\partial t}\Phi_{t*}e_i\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle}{\|\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\|}\eta_M\right|_{t=0}$$ My first question is about the notation $\frac{\partial}{\partial t}\Phi_{t*}e_i$. Should I interpret this as follows: Let $\gamma:(-\epsilon,\epsilon)\to TN$ be given by $\gamma(t)=\Phi_{t*}e_i\in T_{\Phi_{t}(p)}M$. Then  does $\frac{\partial}{\partial t}\Phi_{t*}e_i$ simply mean $d\gamma\left(\frac{\partial}{\partial t}\right)$, where we naturally identify $T(T_qN)\cong T_qN$? He goes on consider the vector field $X:=\left.\frac{\partial}{\partial t}\Phi_{t}\right|_{t=0}$. I'm assuming the interpretation of this vector field is the same as before. My main confusion is with this next part: To compute $\frac{\partial}{\partial t}\Phi_{t*}e_i$ at $t=0$ we consider a curve $c_i(s)$ in $M$ with $c_i(0)=p$ and $c_i'(0)=e_i$ and let $c_i(s,t):=\Phi_t(c_i(s))$. Then  $$\left.\Phi_{t*}e_i=\frac{\partial}{\partial s}c_i(s,t)\right|_{s=0}.$$ How do I justify this? It definitely lives in the right tangent space since $c_i(0,t)=\Phi_t(p)$, but why does this coincide with the pushforward $d\Phi_t(e_i)$. I'm probably missing something pretty fundamental. Carrying on with the computations we have $$\left.\frac{\partial}{\partial t}\Phi_{t*}e_i\right|_{t=0}=\left.\frac{\partial}{\partial t}\frac{\partial}{\partial s}c_i(s,t)\right|_{s=t=0}=\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}c_i(s,t)\right|_{s=t=0}=\left.\nabla^N_{\frac{\partial}{\partial s}}X\right|_{s=0} =\nabla^N_{e_i}X, $$ where $\nabla^N$ is the Levi-Civita connection on $N$. My question is why do the partial derivatives commute in this case? Again, how should these mixed partials be understood, and what justifies this computation? Even intuitively, it doesn't make sense to me that they should.","$\DeclareMathOperator{\vol}{vol}$I've been working through the computation of the first variation of volume presented in Jost's Riemannian Geometry and Geometric Analysis (page 196 in the sixth edition, section titled: Minimal Submanifolds ), and I've been getting caught up in all the notation, and I've been having a lot of trouble exactly understanding how to interpret the partial derivatives in this context. I'll start with the setup: let $M$ be a smooth submanifold of $N$ and let $F:M\times(-\epsilon,\epsilon)\to N$ be a local variation with compact support. For small enough $t$ we have that $\Phi_t(\cdot):=F(\cdot,t)$ is a diffeomorphism from $M\to M_t\subseteq N$. Now let $\{e_1,\dots,e_m\}$ be an orthonormal frame on $M$. Using this diffeomorphism we can write $$\vol(M_t)=\int_{M}\left\langle\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle^{\frac{1}{2}}\eta_{M},$$ where $\langle{\cdot,\cdot}\rangle$ is the induced inner product on $\bigwedge^m(TN)$, that is $\langle{v_1\wedge\cdots\wedge v_m,w_1\wedge\cdots\wedge w_m}\rangle=\det(\langle{v_i,w_j}\rangle)$, and $\eta_M$ denotes the Riemannian volume form on $M$. Then we differentiate this with respect to $t$ to find that $$ \left.\frac{d}{dt}\vol(M_t)\right|_{t=0}=\left.\sum_{i=1}^{m}\int_{M}\frac{\left\langle\Phi_{t*}e_1\wedge\frac{\partial}{\partial t}\Phi_{t*}e_i\wedge\cdots\wedge\Phi_{t*}e_m,\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\right\rangle}{\|\Phi_{t*}e_1\wedge\cdots\wedge\Phi_{t*}e_m\|}\eta_M\right|_{t=0}$$ My first question is about the notation $\frac{\partial}{\partial t}\Phi_{t*}e_i$. Should I interpret this as follows: Let $\gamma:(-\epsilon,\epsilon)\to TN$ be given by $\gamma(t)=\Phi_{t*}e_i\in T_{\Phi_{t}(p)}M$. Then  does $\frac{\partial}{\partial t}\Phi_{t*}e_i$ simply mean $d\gamma\left(\frac{\partial}{\partial t}\right)$, where we naturally identify $T(T_qN)\cong T_qN$? He goes on consider the vector field $X:=\left.\frac{\partial}{\partial t}\Phi_{t}\right|_{t=0}$. I'm assuming the interpretation of this vector field is the same as before. My main confusion is with this next part: To compute $\frac{\partial}{\partial t}\Phi_{t*}e_i$ at $t=0$ we consider a curve $c_i(s)$ in $M$ with $c_i(0)=p$ and $c_i'(0)=e_i$ and let $c_i(s,t):=\Phi_t(c_i(s))$. Then  $$\left.\Phi_{t*}e_i=\frac{\partial}{\partial s}c_i(s,t)\right|_{s=0}.$$ How do I justify this? It definitely lives in the right tangent space since $c_i(0,t)=\Phi_t(p)$, but why does this coincide with the pushforward $d\Phi_t(e_i)$. I'm probably missing something pretty fundamental. Carrying on with the computations we have $$\left.\frac{\partial}{\partial t}\Phi_{t*}e_i\right|_{t=0}=\left.\frac{\partial}{\partial t}\frac{\partial}{\partial s}c_i(s,t)\right|_{s=t=0}=\left.\frac{\partial}{\partial s}\frac{\partial}{\partial t}c_i(s,t)\right|_{s=t=0}=\left.\nabla^N_{\frac{\partial}{\partial s}}X\right|_{s=0} =\nabla^N_{e_i}X, $$ where $\nabla^N$ is the Levi-Civita connection on $N$. My question is why do the partial derivatives commute in this case? Again, how should these mixed partials be understood, and what justifies this computation? Even intuitively, it doesn't make sense to me that they should.",,"['differential-geometry', 'riemannian-geometry', 'calculus-of-variations', 'minimal-surfaces']"
35,Question on a submanifold of $\mathbb{C}^2$ and tangent vectors,Question on a submanifold of  and tangent vectors,\mathbb{C}^2,"Let $X\subset \mathbb{C}^2$ (with complex coordinates $z,w$) be defined by the equation $|z|^2=|w|^2$. If we see $\mathbb{C}^2$ as $\mathbb{R}^4$ with real coordinates $z=x+iy$, $w=u+iv$ then $X$ is a real submanifold of dimension 3 defined by $x^2+y^2-u^2-v^2=0$. Question 1: is $X$ also a complex submanifold? Question 2: is $(i,0)$ a tangent vector to $X$ in $(1,1)\in X$? I think the answer is no to both questions. In particular for the second one it should be true that $T_{(1,1)}X\simeq Ker(df_{(1,1)})$ with $f= x^2+y^2-u^2-v^2=0$ and $df_{(1,1)}=(2,2,-2,-2)$. But $(i,0)=(0,1,0,0)$ in real coordinates and $df_{(1,1)}(0,1,0,0)\neq 0$. Am I right?","Let $X\subset \mathbb{C}^2$ (with complex coordinates $z,w$) be defined by the equation $|z|^2=|w|^2$. If we see $\mathbb{C}^2$ as $\mathbb{R}^4$ with real coordinates $z=x+iy$, $w=u+iv$ then $X$ is a real submanifold of dimension 3 defined by $x^2+y^2-u^2-v^2=0$. Question 1: is $X$ also a complex submanifold? Question 2: is $(i,0)$ a tangent vector to $X$ in $(1,1)\in X$? I think the answer is no to both questions. In particular for the second one it should be true that $T_{(1,1)}X\simeq Ker(df_{(1,1)})$ with $f= x^2+y^2-u^2-v^2=0$ and $df_{(1,1)}=(2,2,-2,-2)$. But $(i,0)=(0,1,0,0)$ in real coordinates and $df_{(1,1)}(0,1,0,0)\neq 0$. Am I right?",,"['differential-geometry', 'complex-geometry']"
36,Parallel vector fields imply a flat connection?,Parallel vector fields imply a flat connection?,,"Let $M$ be a Riemann surface and let $\nabla$ be its Levi-Cevita connection. In particular, $\nabla$ is torsion free, i.e. $\nabla_X Y - \nabla_Y X = [X,Y]$ for vector fields $X$ and $Y$ . Question: Suppose there exist linearly independent vector fields $X$ and $Y$ on $M$ such that $\nabla_XY = \nabla_YX = 0$ , i.e. each is parallel along the other. Note that, because $\nabla$ is torsion-free, this implies the vector fields commute. Does this imply that the connection $\nabla$ is flat? By ad hoc arguments, I've mostly convinced myself such $X$ and $Y$ cannot exist on any small open subset of the 2-sphere, at least in the case where they are also orthogonal (but not orthonormal, which would make their nonexistence obvious). However, I'm not satisfied with my argument. I suspect the real reason this is not possible is that it would force a flat geometry, but I can't see how to prove this.... Trivial comment: the angle between such $X$ and $Y$ should be constant (at least locally, and it is really the local question I am interested in).","Let be a Riemann surface and let be its Levi-Cevita connection. In particular, is torsion free, i.e. for vector fields and . Question: Suppose there exist linearly independent vector fields and on such that , i.e. each is parallel along the other. Note that, because is torsion-free, this implies the vector fields commute. Does this imply that the connection is flat? By ad hoc arguments, I've mostly convinced myself such and cannot exist on any small open subset of the 2-sphere, at least in the case where they are also orthogonal (but not orthonormal, which would make their nonexistence obvious). However, I'm not satisfied with my argument. I suspect the real reason this is not possible is that it would force a flat geometry, but I can't see how to prove this.... Trivial comment: the angle between such and should be constant (at least locally, and it is really the local question I am interested in).","M \nabla \nabla \nabla_X Y - \nabla_Y X = [X,Y] X Y X Y M \nabla_XY = \nabla_YX = 0 \nabla \nabla X Y X Y","['differential-geometry', 'riemannian-geometry', 'connections']"
37,Interpretation for the curvature and monodromy of a connection - Reality check,Interpretation for the curvature and monodromy of a connection - Reality check,,"Let $P \to M$ be a principal $G$-bundle with connection form $\omega \in \Omega^1(P,\mathfrak{g})$. Here are the statements I'm basing my viewpoint on: A connection is flat (vanishing curvature) iff it is locally the pullback of the maurer cartan form on $G$ i.e. for all $p \in P$   there's a neighborhood $p \in U$ and a map $f:U \to G$ satisfying   $\omega|_U = f^*\omega_G$, where $\omega_G$ is the maurer cartan form of   $G$ (this can be proved via an integrable distribution argument). The monodromy of a flat connection is zero iff it is globally given by the pullback of the maurer cartan form on $G$. i.e. iff   there's a function $f:P \to G$ satisfying $\omega=f^*\omega_G$. Here's what I want to be able to say: A connection $P$ is flat iff the $TP \to P$ admits covariantly constant local sections everywhere. Meaning, for every point $p \in P$ there's a neighborhood $p \in U$ and a section $X: U \to TP$ satisfying $\omega(X)=0$. A flat connection on $P$ has zero monodromy iff $TP \to P$ admits a covariantly constant global section. Meaning there's a global section $\sigma : P \to TP$ satisfying $\omega(\sigma)=0$. I get a bit confused though whenever I try to formalize a proof of the above. Sometimes I think the covariantly constant sections should be of the bundle $P \to M$ and that $TP \to P$ always has a covariantly constant section in the sense I defined, here I also get confused. My questions has two parts: Is the above interpretation a valid one ? If so how can I formalize this with minimal effort and confusion? (a hint might suffice). If not how could it be fixed? Does this picture still hold when moving to the category of associated bundles ? In particular, do covariantly constant local (or global) vector fields all arise in this manner?","Let $P \to M$ be a principal $G$-bundle with connection form $\omega \in \Omega^1(P,\mathfrak{g})$. Here are the statements I'm basing my viewpoint on: A connection is flat (vanishing curvature) iff it is locally the pullback of the maurer cartan form on $G$ i.e. for all $p \in P$   there's a neighborhood $p \in U$ and a map $f:U \to G$ satisfying   $\omega|_U = f^*\omega_G$, where $\omega_G$ is the maurer cartan form of   $G$ (this can be proved via an integrable distribution argument). The monodromy of a flat connection is zero iff it is globally given by the pullback of the maurer cartan form on $G$. i.e. iff   there's a function $f:P \to G$ satisfying $\omega=f^*\omega_G$. Here's what I want to be able to say: A connection $P$ is flat iff the $TP \to P$ admits covariantly constant local sections everywhere. Meaning, for every point $p \in P$ there's a neighborhood $p \in U$ and a section $X: U \to TP$ satisfying $\omega(X)=0$. A flat connection on $P$ has zero monodromy iff $TP \to P$ admits a covariantly constant global section. Meaning there's a global section $\sigma : P \to TP$ satisfying $\omega(\sigma)=0$. I get a bit confused though whenever I try to formalize a proof of the above. Sometimes I think the covariantly constant sections should be of the bundle $P \to M$ and that $TP \to P$ always has a covariantly constant section in the sense I defined, here I also get confused. My questions has two parts: Is the above interpretation a valid one ? If so how can I formalize this with minimal effort and confusion? (a hint might suffice). If not how could it be fixed? Does this picture still hold when moving to the category of associated bundles ? In particular, do covariantly constant local (or global) vector fields all arise in this manner?",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', 'principal-bundles']"
38,Prove that $U(n)$ is a manifold,Prove that  is a manifold,U(n),"I would like to prove that $U(n)$ is a manifold, where $$U(n) = \{A \in M_n(\mathbb C): A^*A = I\}.$$ In order to do so I thought of considering the function $M_n(\mathbb C)\to M_n(\mathbb C)$ such that $A\mapsto A^*A$. Then if I prove that the identity is a regular value of this function I'm done. My problem is that I am struggling in proving that. I tried to consider that $(A^*A)_{ij}=\langle v_i,v_j\rangle $ where $v_i$ are the column vectors of $A$ but from there I don't know how to proceed. Does anyone have any suggestion? Thanks","I would like to prove that $U(n)$ is a manifold, where $$U(n) = \{A \in M_n(\mathbb C): A^*A = I\}.$$ In order to do so I thought of considering the function $M_n(\mathbb C)\to M_n(\mathbb C)$ such that $A\mapsto A^*A$. Then if I prove that the identity is a regular value of this function I'm done. My problem is that I am struggling in proving that. I tried to consider that $(A^*A)_{ij}=\langle v_i,v_j\rangle $ where $v_i$ are the column vectors of $A$ but from there I don't know how to proceed. Does anyone have any suggestion? Thanks",,"['differential-geometry', 'lie-groups', 'smooth-manifolds']"
39,Finding the de Rham cohomology of an open subset of $ \Bbb{R}^{n} $ minus a point.,Finding the de Rham cohomology of an open subset of  minus a point., \Bbb{R}^{n} ,"Here’s my question: Let $ n \in \mathbb{N}_{\geq 2} $. Suppose that $ U \subseteq \Bbb{R}^{n} $ is an open set and that $ x \in U $. Then show that   $$ {H_{\text{dR}}^{n - 1}}(U \setminus \{ x \}) \neq 0. $$ My thoughts: I was trying to use that   $$                 S \hookrightarrow U \setminus \{ x \} \hookrightarrow \Bbb{R}^{n} \setminus \{ x \} $$   (where $ S $ is a small sphere in $ U $ centered at $ x $) should induce a homotopy equivalence, so   $$       {H_{\text{dR}}^{n - 1}}(U \setminus \{ x \}) \cong {H_{\text{dR}}^{n - 1}}(S) \cong \Bbb{R}. $$ I get the feeling that there’s something horribly wrong with this line of thought, so I was wanting some help. I’m okay with a direct answer, as long as you think the solution alone would be illuminating. P.S.: This is my first post. Any advice on how I could make my question better would be appreciated as well.","Here’s my question: Let $ n \in \mathbb{N}_{\geq 2} $. Suppose that $ U \subseteq \Bbb{R}^{n} $ is an open set and that $ x \in U $. Then show that   $$ {H_{\text{dR}}^{n - 1}}(U \setminus \{ x \}) \neq 0. $$ My thoughts: I was trying to use that   $$                 S \hookrightarrow U \setminus \{ x \} \hookrightarrow \Bbb{R}^{n} \setminus \{ x \} $$   (where $ S $ is a small sphere in $ U $ centered at $ x $) should induce a homotopy equivalence, so   $$       {H_{\text{dR}}^{n - 1}}(U \setminus \{ x \}) \cong {H_{\text{dR}}^{n - 1}}(S) \cong \Bbb{R}. $$ I get the feeling that there’s something horribly wrong with this line of thought, so I was wanting some help. I’m okay with a direct answer, as long as you think the solution alone would be illuminating. P.S.: This is my first post. Any advice on how I could make my question better would be appreciated as well.",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'homology-cohomology']"
40,Geometric characterization of critical points of the Gauss map.,Geometric characterization of critical points of the Gauss map.,,Let $\Sigma \subset \mathbb{R}^3$ an oriented surface by Gauss map $N: \Sigma \rightarrow S^2$. How can I find a geometric characterization of critical points of $N$?,Let $\Sigma \subset \mathbb{R}^3$ an oriented surface by Gauss map $N: \Sigma \rightarrow S^2$. How can I find a geometric characterization of critical points of $N$?,,['differential-geometry']
41,Confusion about basic Kahler geometry,Confusion about basic Kahler geometry,,"I am really struggling to understand the basics of Kahler geometry and hope someone can give me some guidance. Suppose we have a complex manifold with some complex structure $J$ and let $g$ be a Hermitian metric. That is, $g$ is a Riemannian metric and satisfies the extra condition $g(JX,JY)=g(X,Y)$ . So we have a Riemannian manifold $(M^{2n},g)$ . Why do we all of a sudden start considering the complexified tangent space? What good does that do? The metric $g$ is of the form $$g=\sum_{i,j=1}^{2n}g_{ij}E^i\otimes E^j,$$ where $\{E^1,\dots, E^{2n}\}=\{dx^1,dy^1,\dots, dx^n, dy^n\}$ . We introduce $\frac{\partial}{\partial z_k}$ and $\frac{\partial}{\partial \overline z_k}$ and $dz_k$ and $d\overline z_k$ and then extend the metric to $TM^\mathbb{C}$ and start doing all these computations. But by doing this we've completely changed the domain of the metric. One metric is in $\Omega^2_\mathbb{C}(M)$ and the other is in $\Omega^2(M)$ . How is this new metric telling us stuff about the original one? What is the relationship between the matrix $g_{k\overline j}$ , where $1\leq j,k\leq n$ and $g_{jk}$ , where $1\leq j,k\leq 2n$ ? We introduce the 'extended' connection and curvature but again, I don't see how this new information tells us something about the original manifold. For example, apparently the 'extended' definition of Ricci curvature on $TM^\mathbb{C}$ is the same as the Ricci curvature on $(M^{2n},g)$ . How can these two things be the same, they are functions on completely different spaces?? Another example I am struggling with is how the Kahler form $\omega$ satisfies $\frac{\omega^n}{n!}=\text{vol}_M$ . We have $\omega=\sqrt{-1}g_{j\overline k}dz^j\wedge d\overline z^k$ an element of $\Omega^2_\mathbb{C}(M)$ . How can this be raised to powers to give an element of $\Omega^{2n}(M)$ ?? Really any help would be greatly appreciated!","I am really struggling to understand the basics of Kahler geometry and hope someone can give me some guidance. Suppose we have a complex manifold with some complex structure and let be a Hermitian metric. That is, is a Riemannian metric and satisfies the extra condition . So we have a Riemannian manifold . Why do we all of a sudden start considering the complexified tangent space? What good does that do? The metric is of the form where . We introduce and and and and then extend the metric to and start doing all these computations. But by doing this we've completely changed the domain of the metric. One metric is in and the other is in . How is this new metric telling us stuff about the original one? What is the relationship between the matrix , where and , where ? We introduce the 'extended' connection and curvature but again, I don't see how this new information tells us something about the original manifold. For example, apparently the 'extended' definition of Ricci curvature on is the same as the Ricci curvature on . How can these two things be the same, they are functions on completely different spaces?? Another example I am struggling with is how the Kahler form satisfies . We have an element of . How can this be raised to powers to give an element of ?? Really any help would be greatly appreciated!","J g g g(JX,JY)=g(X,Y) (M^{2n},g) g g=\sum_{i,j=1}^{2n}g_{ij}E^i\otimes E^j, \{E^1,\dots, E^{2n}\}=\{dx^1,dy^1,\dots, dx^n, dy^n\} \frac{\partial}{\partial z_k} \frac{\partial}{\partial \overline z_k} dz_k d\overline z_k TM^\mathbb{C} \Omega^2_\mathbb{C}(M) \Omega^2(M) g_{k\overline j} 1\leq j,k\leq n g_{jk} 1\leq j,k\leq 2n TM^\mathbb{C} (M^{2n},g) \omega \frac{\omega^n}{n!}=\text{vol}_M \omega=\sqrt{-1}g_{j\overline k}dz^j\wedge d\overline z^k \Omega^2_\mathbb{C}(M) \Omega^{2n}(M)","['differential-geometry', 'kahler-manifolds']"
42,Equivalence of definitions of tangent space,Equivalence of definitions of tangent space,,"For a given manifold $M$ and a point $x \in M$, we can define the tangent space at $x$, $T_xM$ in two ways (more, actually, but I am just concerned about these two for now): 1) Given a chart $(U, \phi)$, where $p \in U$, call two curves $\gamma_1 : (-1,1) \to M $, $ \gamma_2 : (-1,1) \to M $, ($ \gamma_1(0)=\gamma_2(0)=p$) $\textbf{equivalent}$ if $ (\phi \circ \gamma_1)'(0)=(\phi \circ \gamma_2)'(0)$. Call the equivalence classes $[\gamma]$ the $\textbf{tangent vectors of }$M$ \textbf{ at } x$. Define $T_xM$ as the collection of $[\gamma]$'s. These classes map to vectors in $\mathbb{R}^n$ via $[\gamma] \mapsto \frac{d}{dt}(\phi \circ \gamma)(0)$. 2) A $\textbf{derivation at } x$ is a linear map $D_x:C^\infty(M) \to \mathbb{R}$ such that, $\forall f,g \in C^\infty(M)$, $D_x(fg)=D_x(f)g(x)+D_x(g)f(x)$. Call the vector space of all derviations at $x$ the tangent space at $x$, $T_xM$. I understand that, given a $[\gamma]$, we can get a derivation $D_\gamma$ given by $D_\gamma(f) := \frac{d}{dt}(f \circ \gamma)(0)$. I am unclear as to how to go the other direction; given a derivation $D$, how can I get an equivalence class $[\gamma]$ of curves? Thanks!","For a given manifold $M$ and a point $x \in M$, we can define the tangent space at $x$, $T_xM$ in two ways (more, actually, but I am just concerned about these two for now): 1) Given a chart $(U, \phi)$, where $p \in U$, call two curves $\gamma_1 : (-1,1) \to M $, $ \gamma_2 : (-1,1) \to M $, ($ \gamma_1(0)=\gamma_2(0)=p$) $\textbf{equivalent}$ if $ (\phi \circ \gamma_1)'(0)=(\phi \circ \gamma_2)'(0)$. Call the equivalence classes $[\gamma]$ the $\textbf{tangent vectors of }$M$ \textbf{ at } x$. Define $T_xM$ as the collection of $[\gamma]$'s. These classes map to vectors in $\mathbb{R}^n$ via $[\gamma] \mapsto \frac{d}{dt}(\phi \circ \gamma)(0)$. 2) A $\textbf{derivation at } x$ is a linear map $D_x:C^\infty(M) \to \mathbb{R}$ such that, $\forall f,g \in C^\infty(M)$, $D_x(fg)=D_x(f)g(x)+D_x(g)f(x)$. Call the vector space of all derviations at $x$ the tangent space at $x$, $T_xM$. I understand that, given a $[\gamma]$, we can get a derivation $D_\gamma$ given by $D_\gamma(f) := \frac{d}{dt}(f \circ \gamma)(0)$. I am unclear as to how to go the other direction; given a derivation $D$, how can I get an equivalence class $[\gamma]$ of curves? Thanks!",,['differential-geometry']
43,Does a $p$-form eat $p$-vectors or $p$ number of vectors?,Does a -form eat -vectors or  number of vectors?,p p p,A bilinear form is another term for a $2$-form. So does it eat $2$ distinct vectors or a single $2$-vector?,A bilinear form is another term for a $2$-form. So does it eat $2$ distinct vectors or a single $2$-vector?,,"['differential-geometry', 'tensors', 'multilinear-algebra', 'exterior-algebra']"
44,Module of differentials in the functorial approach to schemes and quasi-coherent modules,Module of differentials in the functorial approach to schemes and quasi-coherent modules,,"Recall that for a functor $X : \mathsf{CAlg}(R) \to \mathsf{Set}$ from commutative $R$-algebras to sets one can define quasi-coherent $\mathcal{O}_X$-modules as ""compatible"" families of $A$-modules $M_A$ for $A$-points $s \in X(A)$. The compatibility is given by (coherent) isomorphisms $M_A \otimes_A B \cong M_B$ for homomorphisms $A \to B$ (inducing a  $B$-point of $X$). In other words, $$\mathsf{Qcoh}(X) = \int_{A} \mathsf{Mod}(A)^{X(A)}.$$ In this functorial approach to quasi-coherent modules, I wonder how to define the module of differentials $\Omega^1_{X/R}$ (in such a way that we recover the usual module in the case that $X$ is a scheme)? Notice that $\Omega^1_{X/R}|_A = \Omega^1_{A/R}$ won't be correct; this even fails when $X$ is a scheme. So probably one should first describe the $A$-module $\Omega^1_{X/R} |_A$ if $X$ is a scheme and $\mathrm{Spec}(A) \to X$ is a morphism of schemes. When $\mathrm{Spec}(A) \to X$ is étale, then the result is $\Omega^1_{A/R}$, but otherwise it will be something more complicated. I've tried to use the fundamental sequences for $\Omega^1$, but didn't succeed. Perhaps it's not even possible to describe $\Omega^1_{X/R} |_A$? Are things better in derived algebraic geometry?","Recall that for a functor $X : \mathsf{CAlg}(R) \to \mathsf{Set}$ from commutative $R$-algebras to sets one can define quasi-coherent $\mathcal{O}_X$-modules as ""compatible"" families of $A$-modules $M_A$ for $A$-points $s \in X(A)$. The compatibility is given by (coherent) isomorphisms $M_A \otimes_A B \cong M_B$ for homomorphisms $A \to B$ (inducing a  $B$-point of $X$). In other words, $$\mathsf{Qcoh}(X) = \int_{A} \mathsf{Mod}(A)^{X(A)}.$$ In this functorial approach to quasi-coherent modules, I wonder how to define the module of differentials $\Omega^1_{X/R}$ (in such a way that we recover the usual module in the case that $X$ is a scheme)? Notice that $\Omega^1_{X/R}|_A = \Omega^1_{A/R}$ won't be correct; this even fails when $X$ is a scheme. So probably one should first describe the $A$-module $\Omega^1_{X/R} |_A$ if $X$ is a scheme and $\mathrm{Spec}(A) \to X$ is a morphism of schemes. When $\mathrm{Spec}(A) \to X$ is étale, then the result is $\Omega^1_{A/R}$, but otherwise it will be something more complicated. I've tried to use the fundamental sequences for $\Omega^1$, but didn't succeed. Perhaps it's not even possible to describe $\Omega^1_{X/R} |_A$? Are things better in derived algebraic geometry?",,"['algebraic-geometry', 'differential-geometry', 'category-theory', 'quasicoherent-sheaves']"
45,Curvature of De Sitter's space: where does the sign comes?,Curvature of De Sitter's space: where does the sign comes?,,"Consider $\Bbb L^3 = (\Bbb R^3, {\rm d}s^2)$, where: $${\rm d}s^2 =  {\rm d}x^2 + {\rm d}y^2 - {\rm d}z^2.$$ We have both the hyperbolic space : $$\Bbb H^2(-1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 =- 1\},$$ which has constant Gaussian Curvature $K = -1$, and the De Sitter's space : $$\Bbb S^2_1(1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 = 1\},$$ which has Gaussian Curvature $K=1$. My problem is: I'm trying to actually compute these curvatures, and I'm getting $K=-1$ for both of them. I'm using connection forms just like in $\Bbb R^3$ and bi-dimensional Riemannian manifolds, but I think stuff is going wrong because the De Sitter's space is a timelike surface, while the hyperbolic space is spacelike.. I have not seen a rigorous treatment of this in semi-Riemannian surfaces, so I would like to know exactly where my calculations are failing. Additional explanations would be very welcome, too. Enough talk, let's go to the action: Rotating a hyperbola, we parametrize the De Sitter's space by $${\bf x}(u,v) = ( \cosh u \cos v, \cosh u \sin v, \sinh u),$$ and so: $$\begin{align} {\bf x}_u(u,v) &= (\sinh u \cos v, \sinh u \sin v, \cosh u) \\ {\bf x}_v(u,v) &= (-\cosh u \sin v, \cosh u \cos v, 0) \end{align}.$$ Dropping the point $(u,v)$ from now on, we have: $$E = -1 \quad F = 0 \quad G = \cosh^2u.$$ So, we can take a frame $$E_1 = {\bf x}_u \quad E_2 = \frac{{\bf x}_v}{\cosh u},$$ with dual forms $$\theta_1 = {\rm d}u \quad \theta_2 = \cosh u \ {\rm d}v.$$ So $ {\rm d}\theta_1 = 0 $ and $ {\rm d}\theta_2 = \sinh u \ {\rm d}u \wedge {\rm d}v.$ Now I need the connection form $\omega_{12}$. Write: $$\omega_{12} = \alpha \ {\rm d}u + \beta \ {\rm d}v.$$ Since ${\rm d}\theta_1 = \omega_{12} \wedge \theta_2$, we get $\alpha = 0$. And from $ {\rm d}\theta_2 = - \omega_{12} \wedge \theta_1$, we obtain: $$\begin{align} \sinh u \ {\rm d}u \wedge {\rm d}v &= -(\beta \ {\rm d}v)  \wedge {\rm d}u \\ \sinh u \ {\rm d}u \wedge {\rm d}v &= \beta \  {\rm d}u \wedge {\rm d}v \end{align},$$ so $\beta = \sinh u$. Now $\omega_{12} = \sinh u \ {\rm d}v$ gives us $ {\rm d}\omega_{12} = \cosh u \ {\rm d}u \wedge {\rm d}v$. Rewriting: $$ \cosh u \ {\rm d}u \wedge {\rm d}v = \cosh u \ \theta_1 \wedge \left(\frac{\theta_2}{\cosh u}\right) = -(-1) \ \theta_1 \wedge \theta_2, $$ and ${\rm d}\omega_{12} = -K \ \theta_1 \wedge \theta_2$ wields $K=-1$. What is going wrong? The same calculation gives the right answer for the hyperbolic space. Where does the causal character comes in? Please help. Edit : I have redone the calculations using $E_1 = \frac{{\bf x}_u}{\rm i}$ instead of my previous $E_1$, and I got the right answer. However, using complex numbers felt like cheating, so I'll rephrase my question: is there any way that I can avoid this approach? From what I've studied about $\Bbb L^3$ so far, complex numbers weren't used, so I reckon that must be another way to tackle this.","Consider $\Bbb L^3 = (\Bbb R^3, {\rm d}s^2)$, where: $${\rm d}s^2 =  {\rm d}x^2 + {\rm d}y^2 - {\rm d}z^2.$$ We have both the hyperbolic space : $$\Bbb H^2(-1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 =- 1\},$$ which has constant Gaussian Curvature $K = -1$, and the De Sitter's space : $$\Bbb S^2_1(1) = \{(x,y,z) \in \Bbb L^3 \mid x^2+y^2-z^2 = 1\},$$ which has Gaussian Curvature $K=1$. My problem is: I'm trying to actually compute these curvatures, and I'm getting $K=-1$ for both of them. I'm using connection forms just like in $\Bbb R^3$ and bi-dimensional Riemannian manifolds, but I think stuff is going wrong because the De Sitter's space is a timelike surface, while the hyperbolic space is spacelike.. I have not seen a rigorous treatment of this in semi-Riemannian surfaces, so I would like to know exactly where my calculations are failing. Additional explanations would be very welcome, too. Enough talk, let's go to the action: Rotating a hyperbola, we parametrize the De Sitter's space by $${\bf x}(u,v) = ( \cosh u \cos v, \cosh u \sin v, \sinh u),$$ and so: $$\begin{align} {\bf x}_u(u,v) &= (\sinh u \cos v, \sinh u \sin v, \cosh u) \\ {\bf x}_v(u,v) &= (-\cosh u \sin v, \cosh u \cos v, 0) \end{align}.$$ Dropping the point $(u,v)$ from now on, we have: $$E = -1 \quad F = 0 \quad G = \cosh^2u.$$ So, we can take a frame $$E_1 = {\bf x}_u \quad E_2 = \frac{{\bf x}_v}{\cosh u},$$ with dual forms $$\theta_1 = {\rm d}u \quad \theta_2 = \cosh u \ {\rm d}v.$$ So $ {\rm d}\theta_1 = 0 $ and $ {\rm d}\theta_2 = \sinh u \ {\rm d}u \wedge {\rm d}v.$ Now I need the connection form $\omega_{12}$. Write: $$\omega_{12} = \alpha \ {\rm d}u + \beta \ {\rm d}v.$$ Since ${\rm d}\theta_1 = \omega_{12} \wedge \theta_2$, we get $\alpha = 0$. And from $ {\rm d}\theta_2 = - \omega_{12} \wedge \theta_1$, we obtain: $$\begin{align} \sinh u \ {\rm d}u \wedge {\rm d}v &= -(\beta \ {\rm d}v)  \wedge {\rm d}u \\ \sinh u \ {\rm d}u \wedge {\rm d}v &= \beta \  {\rm d}u \wedge {\rm d}v \end{align},$$ so $\beta = \sinh u$. Now $\omega_{12} = \sinh u \ {\rm d}v$ gives us $ {\rm d}\omega_{12} = \cosh u \ {\rm d}u \wedge {\rm d}v$. Rewriting: $$ \cosh u \ {\rm d}u \wedge {\rm d}v = \cosh u \ \theta_1 \wedge \left(\frac{\theta_2}{\cosh u}\right) = -(-1) \ \theta_1 \wedge \theta_2, $$ and ${\rm d}\omega_{12} = -K \ \theta_1 \wedge \theta_2$ wields $K=-1$. What is going wrong? The same calculation gives the right answer for the hyperbolic space. Where does the causal character comes in? Please help. Edit : I have redone the calculations using $E_1 = \frac{{\bf x}_u}{\rm i}$ instead of my previous $E_1$, and I got the right answer. However, using complex numbers felt like cheating, so I'll rephrase my question: is there any way that I can avoid this approach? From what I've studied about $\Bbb L^3$ so far, complex numbers weren't used, so I reckon that must be another way to tackle this.",,"['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry', 'semi-riemannian-geometry']"
46,Confusion regarding Riemann normal coordinates,Confusion regarding Riemann normal coordinates,,"I'm trying to understand Riemann normal coordinates. This ""simple"" example using the surface of a unit sphere is from http://www.maths.bris.ac.uk/~macpd/gen_rel/snotes.pdf (p26). The “north pole” $\theta=0$ is the initial point. The geodesics radiating from the north pole are lines of constant $\phi$. The new coordinates $\xi$ and $\eta$ are related to the old (ordinary spherical) coordinates by $$\xi=\theta\cos\phi$$ and$$\eta=\theta\sin\phi.$$ I'm assuming (quite possibly incorrectly) that these are arbitrary definitions. They then say the metric is$$ds^{2}=d\theta^{2}+\sin^{2}\theta d\phi^{2}$$  $$=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\eta^{2}\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\xi^{2}\sin^{2}\theta\right)$$  where $\theta=\sqrt{\xi^{2}+\eta^{2}}.$ Can anyone please explain where the second metric comes from and also why $\theta=\sqrt{\xi^{2}+\eta^{2}}$? Thank you. This edit added 18 Sept 2014 Right, I'm going to wander off on my own with this and see where I get. Substituting $\eta$ and $\xi$ into the metric gives $$ds^{2}=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\theta^{2}\sin^{2}\phi\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\theta^{2}\cos^{2}\phi\sin^{2}\theta\right).$$ Note that for a unit sphere (with the $x,y$ plane passing through the equator) $$x=\sin\theta\cos\phi,$$ $$y=\sin\theta\sin\phi.$$   This gives$$ds^{2}=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\theta^{2}y^{2}\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\theta^{2}x^{2}\right)$$ $$ds^{2}=\frac{d\xi^{2}}{\theta^{2}}\left(\xi^{2}+y^{2}\right)+\frac{d\eta^{2}}{\theta^{2}}\left(\eta^{2}+x^{2}\right)$$  $$ds^{2}=d\xi^{2}\frac{\left(\xi^{2}+y^{2}\right)}{\left(\xi^{2}+\eta^{2}\right)}+d\eta^{2}\frac{\left(\eta^{2}+x^{2}\right)}{\left(\xi^{2}+\eta^{2}\right)}.$$  And then I grind to a halt. The metric is supposed to reduce to $\delta_{\alpha\beta}$, but I can't see how it does. Just a thought, but is it useful to point out that for small angles (where $\theta=\sin\theta)$, $\eta\approx y$ and $\xi\approx x$? The above metric then reduces to $$ds^{2}\approx d\xi^{2}+d\eta^{2}.$$ Is this what should happen for Riemann normal coordinates? This edit added 21 September 2014 Following the latest hint from @Semsen $$ds^{2}=\frac{\zeta^{2}}{\zeta^{2}+\eta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\zeta^{2}+\eta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\zeta^{2}+\eta^{2}}d\eta^{2}+\sin^{2}\theta\cos^{4}\phi\{\frac{1}{\zeta^{2}}d\eta^{2}-2\frac{\eta}{\zeta^{3}}d\eta d\zeta+\frac{\eta^{2}}{\zeta^{4}}d\zeta^{2}\}$$ $$ds^{2}=\frac{\zeta^{2}}{\zeta^{2}+\eta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\zeta^{2}+\eta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\zeta^{2}+\eta^{2}}d\eta^{2}+\sin^{2}\theta\frac{\zeta^{4}}{\theta^{4}}\{\frac{1}{\zeta^{2}}d\eta^{2}-2\frac{\eta}{\zeta^{3}}d\eta d\zeta+\frac{\eta^{2}}{\zeta^{4}}d\zeta^{2}\}$$ $$ds^{2}=\frac{\zeta^{2}}{\theta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\theta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\theta^{2}}d\eta^{2}+\sin^{2}\theta\frac{1}{\theta^{4}}\{\zeta^{2}d\eta^{2}-2\eta\zeta d\eta d\zeta+\eta^{2}d\zeta^{2}\}$$  $$ds^{2}=\frac{1}{\theta^{4}}\left(\theta^{2}\zeta^{2}d\zeta^{2}+\theta^{2}2\eta\zeta d\zeta d\eta+\theta^{2}\eta^{2}d\eta^{2}+\sin^{2}\theta\{\zeta^{2}d\eta^{2}-2\eta\zeta d\eta d\zeta+\eta^{2}d\zeta^{2}\}\right)$$  $$ds^{2}=\frac{1}{\theta^{4}}\left(\theta^{2}\zeta^{2}d\zeta^{2}+\theta^{2}2\eta\zeta d\zeta d\eta+\theta^{2}\eta^{2}d\eta^{2}+\sin^{2}\theta\zeta^{2}d\eta^{2}-\sin^{2}\theta2\eta\zeta d\eta d\zeta+\sin^{2}\theta\eta^{2}d\zeta^{2}\right)$$ $$ds^{2}=\frac{d\zeta^{2}}{\theta^{4}}\left(\theta^{2}\zeta^{2}+\eta^{2}\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\theta^{2}\eta^{2}+\zeta^{2}\sin^{2}\theta\right)+\frac{2\eta\zeta d\zeta d\eta}{\theta^{4}}\left(\theta^{2}-\sin^{2}\theta\right)$$ If I could only now get rid of the right-hand term I'd have the original metric. But how to get rid of this term?","I'm trying to understand Riemann normal coordinates. This ""simple"" example using the surface of a unit sphere is from http://www.maths.bris.ac.uk/~macpd/gen_rel/snotes.pdf (p26). The “north pole” $\theta=0$ is the initial point. The geodesics radiating from the north pole are lines of constant $\phi$. The new coordinates $\xi$ and $\eta$ are related to the old (ordinary spherical) coordinates by $$\xi=\theta\cos\phi$$ and$$\eta=\theta\sin\phi.$$ I'm assuming (quite possibly incorrectly) that these are arbitrary definitions. They then say the metric is$$ds^{2}=d\theta^{2}+\sin^{2}\theta d\phi^{2}$$  $$=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\eta^{2}\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\xi^{2}\sin^{2}\theta\right)$$  where $\theta=\sqrt{\xi^{2}+\eta^{2}}.$ Can anyone please explain where the second metric comes from and also why $\theta=\sqrt{\xi^{2}+\eta^{2}}$? Thank you. This edit added 18 Sept 2014 Right, I'm going to wander off on my own with this and see where I get. Substituting $\eta$ and $\xi$ into the metric gives $$ds^{2}=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\theta^{2}\sin^{2}\phi\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\theta^{2}\cos^{2}\phi\sin^{2}\theta\right).$$ Note that for a unit sphere (with the $x,y$ plane passing through the equator) $$x=\sin\theta\cos\phi,$$ $$y=\sin\theta\sin\phi.$$   This gives$$ds^{2}=\frac{d\xi^{2}}{\theta^{4}}\left(\xi^{2}\theta^{2}+\theta^{2}y^{2}\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\eta^{2}\theta^{2}+\theta^{2}x^{2}\right)$$ $$ds^{2}=\frac{d\xi^{2}}{\theta^{2}}\left(\xi^{2}+y^{2}\right)+\frac{d\eta^{2}}{\theta^{2}}\left(\eta^{2}+x^{2}\right)$$  $$ds^{2}=d\xi^{2}\frac{\left(\xi^{2}+y^{2}\right)}{\left(\xi^{2}+\eta^{2}\right)}+d\eta^{2}\frac{\left(\eta^{2}+x^{2}\right)}{\left(\xi^{2}+\eta^{2}\right)}.$$  And then I grind to a halt. The metric is supposed to reduce to $\delta_{\alpha\beta}$, but I can't see how it does. Just a thought, but is it useful to point out that for small angles (where $\theta=\sin\theta)$, $\eta\approx y$ and $\xi\approx x$? The above metric then reduces to $$ds^{2}\approx d\xi^{2}+d\eta^{2}.$$ Is this what should happen for Riemann normal coordinates? This edit added 21 September 2014 Following the latest hint from @Semsen $$ds^{2}=\frac{\zeta^{2}}{\zeta^{2}+\eta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\zeta^{2}+\eta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\zeta^{2}+\eta^{2}}d\eta^{2}+\sin^{2}\theta\cos^{4}\phi\{\frac{1}{\zeta^{2}}d\eta^{2}-2\frac{\eta}{\zeta^{3}}d\eta d\zeta+\frac{\eta^{2}}{\zeta^{4}}d\zeta^{2}\}$$ $$ds^{2}=\frac{\zeta^{2}}{\zeta^{2}+\eta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\zeta^{2}+\eta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\zeta^{2}+\eta^{2}}d\eta^{2}+\sin^{2}\theta\frac{\zeta^{4}}{\theta^{4}}\{\frac{1}{\zeta^{2}}d\eta^{2}-2\frac{\eta}{\zeta^{3}}d\eta d\zeta+\frac{\eta^{2}}{\zeta^{4}}d\zeta^{2}\}$$ $$ds^{2}=\frac{\zeta^{2}}{\theta^{2}}d\zeta^{2}+\frac{2\eta\zeta}{\theta^{2}}d\zeta d\eta+\frac{\eta^{2}}{\theta^{2}}d\eta^{2}+\sin^{2}\theta\frac{1}{\theta^{4}}\{\zeta^{2}d\eta^{2}-2\eta\zeta d\eta d\zeta+\eta^{2}d\zeta^{2}\}$$  $$ds^{2}=\frac{1}{\theta^{4}}\left(\theta^{2}\zeta^{2}d\zeta^{2}+\theta^{2}2\eta\zeta d\zeta d\eta+\theta^{2}\eta^{2}d\eta^{2}+\sin^{2}\theta\{\zeta^{2}d\eta^{2}-2\eta\zeta d\eta d\zeta+\eta^{2}d\zeta^{2}\}\right)$$  $$ds^{2}=\frac{1}{\theta^{4}}\left(\theta^{2}\zeta^{2}d\zeta^{2}+\theta^{2}2\eta\zeta d\zeta d\eta+\theta^{2}\eta^{2}d\eta^{2}+\sin^{2}\theta\zeta^{2}d\eta^{2}-\sin^{2}\theta2\eta\zeta d\eta d\zeta+\sin^{2}\theta\eta^{2}d\zeta^{2}\right)$$ $$ds^{2}=\frac{d\zeta^{2}}{\theta^{4}}\left(\theta^{2}\zeta^{2}+\eta^{2}\sin^{2}\theta\right)+\frac{d\eta^{2}}{\theta^{4}}\left(\theta^{2}\eta^{2}+\zeta^{2}\sin^{2}\theta\right)+\frac{2\eta\zeta d\zeta d\eta}{\theta^{4}}\left(\theta^{2}-\sin^{2}\theta\right)$$ If I could only now get rid of the right-hand term I'd have the original metric. But how to get rid of this term?",,"['differential-geometry', 'riemannian-geometry']"
47,"If $b$ is a regular value of $f$, $f^{-1}(-\infty,b]$ is a regular domain?","If  is a regular value of ,  is a regular domain?","b f f^{-1}(-\infty,b]","I'm trying to prove the first part of Proposition 5.47 of Lee's Smooth Manifolds, which is left to the reader. It says Suppose $M^m$ is a smooth manifold, and $f\colon M\to\mathbb{R}$ smooth. For each regular value $b$ of $f$, the sublevel set $f^{-1}(-\infty,b]$ is a regular domain, that is, a properly embedded codimension $0$ submanifold with boundary. First, $f^{-1}(\infty,b)$ is open, hence an embedded submanifold of codimension $0$. Also, $f^{-1}(-\infty,b]$ is closed in $M$, so if $f^{-1}(-\infty,b]$ is a embedded submanifold, it  is in fact a properly embedded submanifold of codimension $0$. I want to show $S:=f^{-1}(-\infty,b]$ satisfies the local $m$-slice condition. If $p\in f^{-1}(-\infty,b)$, then since this set is open, we can find a chart $(U,\varphi)$ around $p$ in $S$. But then $\varphi(S\cap U)=\varphi(U)$, so $(U,\varphi)$ is an $m$-slice chart around $p$. I suspect $f^{-1}(b)$ is the boundary of $S$. Since $f^{-1}(b)$ is a regular level set, it is a properly embedded submanifold of dimension $m-1$ in $M$. I could then find an $m-1$ slice chart $(U,\varphi)$ in $M$ for $f^{-1}(b)$, so that $$ \varphi(f^{-1}(b)\cap U)=\{(x^1,\dots,x^m)\in\varphi(U):x^m=0\} $$ I want to try to modify it somehow to a chart such that  $$ \varphi(U\cap S)=\{(x^1,\dots,x^m)\in\varphi(U):x^m\geq 0\} $$ to show it is an $m$-dimensional half slice. Is there maybe a way to restrict to a precompact open set, so that the coordinate functions achieve a mimnimum, and then just shift the coordinate map so the last coordinate is always nonnegative?","I'm trying to prove the first part of Proposition 5.47 of Lee's Smooth Manifolds, which is left to the reader. It says Suppose $M^m$ is a smooth manifold, and $f\colon M\to\mathbb{R}$ smooth. For each regular value $b$ of $f$, the sublevel set $f^{-1}(-\infty,b]$ is a regular domain, that is, a properly embedded codimension $0$ submanifold with boundary. First, $f^{-1}(\infty,b)$ is open, hence an embedded submanifold of codimension $0$. Also, $f^{-1}(-\infty,b]$ is closed in $M$, so if $f^{-1}(-\infty,b]$ is a embedded submanifold, it  is in fact a properly embedded submanifold of codimension $0$. I want to show $S:=f^{-1}(-\infty,b]$ satisfies the local $m$-slice condition. If $p\in f^{-1}(-\infty,b)$, then since this set is open, we can find a chart $(U,\varphi)$ around $p$ in $S$. But then $\varphi(S\cap U)=\varphi(U)$, so $(U,\varphi)$ is an $m$-slice chart around $p$. I suspect $f^{-1}(b)$ is the boundary of $S$. Since $f^{-1}(b)$ is a regular level set, it is a properly embedded submanifold of dimension $m-1$ in $M$. I could then find an $m-1$ slice chart $(U,\varphi)$ in $M$ for $f^{-1}(b)$, so that $$ \varphi(f^{-1}(b)\cap U)=\{(x^1,\dots,x^m)\in\varphi(U):x^m=0\} $$ I want to try to modify it somehow to a chart such that  $$ \varphi(U\cap S)=\{(x^1,\dots,x^m)\in\varphi(U):x^m\geq 0\} $$ to show it is an $m$-dimensional half slice. Is there maybe a way to restrict to a precompact open set, so that the coordinate functions achieve a mimnimum, and then just shift the coordinate map so the last coordinate is always nonnegative?",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
48,Curvature of parallel curve for a regular plane curve,Curvature of parallel curve for a regular plane curve,,"Let $\gamma$ be a regular plane curve and let $\lambda$ be a constant. The parallel curve $\gamma^\lambda$ of $\gamma$ is defined as $$\gamma^\lambda(t)=\gamma(t)+\lambda n_s(t)$$ where $n_s$ is the normal of the tangent line. Question: Let $\kappa_s(t)$ be the signed curvature of $\gamma$ at $t$. Show that if $\lambda\kappa_s(t)\neq1$  then $\gamma$ is a regular   curve and its signed curvature is   $\frac{\kappa_s}{|1-\lambda\kappa_s(t)|}$. My work so far: $\gamma^\lambda(t)=\gamma(t)+\lambda n_s(t)$ $\implies$ $\frac{d\gamma^\lambda(t)}{d s^\lambda}\frac{ds^\lambda}{dt} = \frac{d\gamma(t)}{ds}\frac{ds}{dt}+\lambda\frac{dn_s(t)}{ds}\frac{ds}{dt}$. Let $T_\gamma(t)$ denote the tangent vector of $\gamma$ at $t$. Since $n_s'=-\kappa_sT$ we have: $T_{\gamma^\lambda}\frac{ds^\lambda}{dt} = T_\gamma\frac{ds}{dt}+\lambda(-\kappa_sT_\gamma)\frac{ds}{dt}$ $\implies$ $T_{\gamma^\lambda}\frac{ds^\lambda}{dt} = (1-\lambda\kappa_s)T_\gamma\frac{ds}{dt}$. I think that implies that $\frac{ds^\lambda}{dt} = |(1-\lambda\kappa_s)|\frac{ds}{dt}$, since $T_{\gamma^\lambda}$ and $T_\gamma$ are co-linear, and the variance of one is described in relation to the other. I don't know where to go from here, but this feels like the right direction. Also, I'm not really sure what the geometric sense of what I'm proving is. So any advice is much appreciated. Thanks.","Let $\gamma$ be a regular plane curve and let $\lambda$ be a constant. The parallel curve $\gamma^\lambda$ of $\gamma$ is defined as $$\gamma^\lambda(t)=\gamma(t)+\lambda n_s(t)$$ where $n_s$ is the normal of the tangent line. Question: Let $\kappa_s(t)$ be the signed curvature of $\gamma$ at $t$. Show that if $\lambda\kappa_s(t)\neq1$  then $\gamma$ is a regular   curve and its signed curvature is   $\frac{\kappa_s}{|1-\lambda\kappa_s(t)|}$. My work so far: $\gamma^\lambda(t)=\gamma(t)+\lambda n_s(t)$ $\implies$ $\frac{d\gamma^\lambda(t)}{d s^\lambda}\frac{ds^\lambda}{dt} = \frac{d\gamma(t)}{ds}\frac{ds}{dt}+\lambda\frac{dn_s(t)}{ds}\frac{ds}{dt}$. Let $T_\gamma(t)$ denote the tangent vector of $\gamma$ at $t$. Since $n_s'=-\kappa_sT$ we have: $T_{\gamma^\lambda}\frac{ds^\lambda}{dt} = T_\gamma\frac{ds}{dt}+\lambda(-\kappa_sT_\gamma)\frac{ds}{dt}$ $\implies$ $T_{\gamma^\lambda}\frac{ds^\lambda}{dt} = (1-\lambda\kappa_s)T_\gamma\frac{ds}{dt}$. I think that implies that $\frac{ds^\lambda}{dt} = |(1-\lambda\kappa_s)|\frac{ds}{dt}$, since $T_{\gamma^\lambda}$ and $T_\gamma$ are co-linear, and the variance of one is described in relation to the other. I don't know where to go from here, but this feels like the right direction. Also, I'm not really sure what the geometric sense of what I'm proving is. So any advice is much appreciated. Thanks.",,"['differential-geometry', 'curves', 'plane-curves']"
49,The homology of the torus.,The homology of the torus.,,"I am reading ""Riemann surface"" by Donaldson. On page 68, the calculation of the first homology of the torus $T$ is given but there are several steps that I don't understand. Here is the calculation. Consider the torus $T$ and take standard angular co-ordinates $\theta, \phi \in [0, 2\pi]$.   Let $\gamma_1, \gamma_2 \subset T$ be the standard embedded circles corresponding to $\theta=0, \phi=0$, respectively.   Then the map   $$\alpha \mapsto \bigg( \int_{\gamma_1} \alpha, \int_{\gamma_2} \alpha\bigg)$$   induces a linear map from $H^1(T)$ to $\mathbb{R}^2$, since the integral of $df$ around the $\gamma_i$ vanishes for any function $f$ on $T$.   The forms $d\theta$ and $d\phi$ show that this map is surjective.   We claim that the map is also injective, so $H^1(T)=\mathbb{R}^2$.   For, if $\alpha=P d\theta +Q d\phi$ is a closed 1-form with integral $0$ around $\gamma_2$, then for any fixed $\phi$ we have, by Stokes' Theorem,   $$ (1) \int_0^{2\pi} P(\theta, \phi)d\theta=0.$$   This means that the indefinite integral   $$f(\theta, \phi)=\int_0^{\theta} P(u, \phi)du$$   defines a smooth function on $T$ with $\partial f / \partial \theta=P$.   Thus $\tilde{\alpha}=\alpha -df$ is a closed 1-form of the form $\tilde Q d \phi$.    But the closed condition implies that $Q$ is constant and, if the integral around $\gamma_1$ is zero, this constant must be zero and $\alpha=df$. Questions: 1. The first thing I want to understand is how to get (1). How do I useStokes' Theorem here? For which surface and boundary do I use Stokes' Theorem? 2.Why does (1) mean $f(\theta, \phi)$ denies a smooth function on $T$? I appreciate any help.","I am reading ""Riemann surface"" by Donaldson. On page 68, the calculation of the first homology of the torus $T$ is given but there are several steps that I don't understand. Here is the calculation. Consider the torus $T$ and take standard angular co-ordinates $\theta, \phi \in [0, 2\pi]$.   Let $\gamma_1, \gamma_2 \subset T$ be the standard embedded circles corresponding to $\theta=0, \phi=0$, respectively.   Then the map   $$\alpha \mapsto \bigg( \int_{\gamma_1} \alpha, \int_{\gamma_2} \alpha\bigg)$$   induces a linear map from $H^1(T)$ to $\mathbb{R}^2$, since the integral of $df$ around the $\gamma_i$ vanishes for any function $f$ on $T$.   The forms $d\theta$ and $d\phi$ show that this map is surjective.   We claim that the map is also injective, so $H^1(T)=\mathbb{R}^2$.   For, if $\alpha=P d\theta +Q d\phi$ is a closed 1-form with integral $0$ around $\gamma_2$, then for any fixed $\phi$ we have, by Stokes' Theorem,   $$ (1) \int_0^{2\pi} P(\theta, \phi)d\theta=0.$$   This means that the indefinite integral   $$f(\theta, \phi)=\int_0^{\theta} P(u, \phi)du$$   defines a smooth function on $T$ with $\partial f / \partial \theta=P$.   Thus $\tilde{\alpha}=\alpha -df$ is a closed 1-form of the form $\tilde Q d \phi$.    But the closed condition implies that $Q$ is constant and, if the integral around $\gamma_1$ is zero, this constant must be zero and $\alpha=df$. Questions: 1. The first thing I want to understand is how to get (1). How do I useStokes' Theorem here? For which surface and boundary do I use Stokes' Theorem? 2.Why does (1) mean $f(\theta, \phi)$ denies a smooth function on $T$? I appreciate any help.",,"['differential-geometry', 'algebraic-topology']"
50,A $2$-form on $S^2$ is exact if it integrates to zero.,A -form on  is exact if it integrates to zero.,2 S^2,"I'm trying to show that a $2$-form on $S^2$ is exact if and only if it integrates to zero, without appealing to de Rham's theorem (basically only using the Poincaré lemma [that every closed form on a contractible manifold is exact]). One direction is easy, since $\partial S^2=0$, Stokes's theorem shows that if $\omega=d\psi$ for some $(n-1)$-form $\psi$ on $S^2$, then $\int_{S^2}\omega=\int_{S^2}d\psi=\int_{\emptyset}\psi=0$. I know the usual way to go, to decompose $S^2$ into it's northern and southern hemispheres, each of which is contractible. So if $\int_{S^2}\omega=0$, this gives two $(n-1)$-forms $\psi^+$ and $\psi^-$ on the northern and southern hemispheres, respectively with $d\psi^{\pm}=\omega$ on their domains. Moreover, Stokes's theorem shows again that $0=\int_{S^2}\omega=\int_{\{x_3\ge 0\}}d\psi^++\int_{\{x_3\le 0\}}d\psi^-=\int_{\{x_3=0\}}\iota_{\{x_3=0\}}^*(\psi^+)-\iota_{\{x_3=0\}}^*(\psi^-)$ But now I have no idea how to proceed. Thanks in advance for your help! Also, I realize that this question has been answered before, but keep in mind I'm looking for a solution that does not use de Rham's theorem.","I'm trying to show that a $2$-form on $S^2$ is exact if and only if it integrates to zero, without appealing to de Rham's theorem (basically only using the Poincaré lemma [that every closed form on a contractible manifold is exact]). One direction is easy, since $\partial S^2=0$, Stokes's theorem shows that if $\omega=d\psi$ for some $(n-1)$-form $\psi$ on $S^2$, then $\int_{S^2}\omega=\int_{S^2}d\psi=\int_{\emptyset}\psi=0$. I know the usual way to go, to decompose $S^2$ into it's northern and southern hemispheres, each of which is contractible. So if $\int_{S^2}\omega=0$, this gives two $(n-1)$-forms $\psi^+$ and $\psi^-$ on the northern and southern hemispheres, respectively with $d\psi^{\pm}=\omega$ on their domains. Moreover, Stokes's theorem shows again that $0=\int_{S^2}\omega=\int_{\{x_3\ge 0\}}d\psi^++\int_{\{x_3\le 0\}}d\psi^-=\int_{\{x_3=0\}}\iota_{\{x_3=0\}}^*(\psi^+)-\iota_{\{x_3=0\}}^*(\psi^-)$ But now I have no idea how to proceed. Thanks in advance for your help! Also, I realize that this question has been answered before, but keep in mind I'm looking for a solution that does not use de Rham's theorem.",,"['differential-geometry', 'differential-forms']"
51,Differential of smooth function on manifold,Differential of smooth function on manifold,,"In the book I am using, the author defines differentials in the following way. Given smooth manifolds $M,N$ and a smooth mapping $\psi:M\to N$ define the differential $d\psi_m$ at a point $m\in M$ as the following linear mapping: ($M_n$ denotes the tangent space at n, defined here as the space of linear derivations on germs of $m$) $$ d\psi_m:M_m\to N_{\psi(m)} $$ with $d\psi_m(v)g:=v(g\circ\psi)$ for germs $g$ on $\psi(m)$. If $N=\Bbb R,\,\,\,\,\,d\psi(v)=v(\psi)\frac{d}{dx}|_{\psi(m)}$ which is ""identified"" with the dual of $d\psi_m$ evaluated at the dual vector of $\frac{d}{dx}|_{\psi(m)}$, namely $d\psi_m(v)=v(f)$ . Why can we identify them?","In the book I am using, the author defines differentials in the following way. Given smooth manifolds $M,N$ and a smooth mapping $\psi:M\to N$ define the differential $d\psi_m$ at a point $m\in M$ as the following linear mapping: ($M_n$ denotes the tangent space at n, defined here as the space of linear derivations on germs of $m$) $$ d\psi_m:M_m\to N_{\psi(m)} $$ with $d\psi_m(v)g:=v(g\circ\psi)$ for germs $g$ on $\psi(m)$. If $N=\Bbb R,\,\,\,\,\,d\psi(v)=v(\psi)\frac{d}{dx}|_{\psi(m)}$ which is ""identified"" with the dual of $d\psi_m$ evaluated at the dual vector of $\frac{d}{dx}|_{\psi(m)}$, namely $d\psi_m(v)=v(f)$ . Why can we identify them?",,"['differential-geometry', 'manifolds']"
52,Calculation of Gaussian curvature from first fundamental form,Calculation of Gaussian curvature from first fundamental form,,"Let $r(u,v): \mathbb R^2 \rightarrow \mathbb R^3$ be a surface in $\mathbb R^3$. I know how to calculate the Gaussian curvature when both the first and the second fundamental forms are given. Also, it's not quite difficult if only the first fundamental form is known and it is of the form $I=f(u,v)du^2+g(u,v)dv^2$. But what can I do if the coefficient of $du\ dv$ is not $0$ in the first fundamental form? For example, what is the Gaussian curvature if $I = (1+v^2)du^2+2uv\ du\ dv+(1+u^2)dv^2$? Should I replace $u$ and $v$ by linear combinations of them to kill the middle term? Since this involves a lot of calculations, is there any better method?","Let $r(u,v): \mathbb R^2 \rightarrow \mathbb R^3$ be a surface in $\mathbb R^3$. I know how to calculate the Gaussian curvature when both the first and the second fundamental forms are given. Also, it's not quite difficult if only the first fundamental form is known and it is of the form $I=f(u,v)du^2+g(u,v)dv^2$. But what can I do if the coefficient of $du\ dv$ is not $0$ in the first fundamental form? For example, what is the Gaussian curvature if $I = (1+v^2)du^2+2uv\ du\ dv+(1+u^2)dv^2$? Should I replace $u$ and $v$ by linear combinations of them to kill the middle term? Since this involves a lot of calculations, is there any better method?",,['differential-geometry']
53,Uniformization Theorem for compact surface,Uniformization Theorem for compact surface,,"Why in proof of proposition 6 of http://arxiv.org/abs/0909.1665 , they claim that if a embedded surfaces $\Sigma^2 \subset (M^3,g)$ is homeomorphic to $\mathbb{RP}^2$, where $M$ is compact manifold, then, by uniformization theorem, there exist diffeomorphism $\phi: \mathbb{RP}^2 \rightarrow \Sigma$ such that $\phi^{*}g$ is conformal to standard metric on $\mathbb{RP}^2$? Can someone help me?","Why in proof of proposition 6 of http://arxiv.org/abs/0909.1665 , they claim that if a embedded surfaces $\Sigma^2 \subset (M^3,g)$ is homeomorphic to $\mathbb{RP}^2$, where $M$ is compact manifold, then, by uniformization theorem, there exist diffeomorphism $\phi: \mathbb{RP}^2 \rightarrow \Sigma$ such that $\phi^{*}g$ is conformal to standard metric on $\mathbb{RP}^2$? Can someone help me?",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'riemann-surfaces', 'compact-manifolds']"
54,"$D^m\cup_h D^m$, joining $D^m \amalg D^m$ along the boundary $\partial D^m$",", joining  along the boundary",D^m\cup_h D^m D^m \amalg D^m \partial D^m,"Given an orientation-preserving diffeomorphism $h: \partial D^m \to \partial D^m$, we can glue two copies of the closed unit disk $D^m$ along the boundary by identifying $x \sim h(x)$ to form the quotient space $$\Sigma(h) := (D^m \amalg D^m)/\sim$$ Now we can give this quotient a smooth structure such that the obvious inclusions $D^m \hookrightarrow \Sigma(h)$ are smooth embeddings and in fact it turns out that for any two smooth structures, there exists a diffeomorphism between them. So $\Sigma(h)$ is a unique manifold up to diffeomorphism. So far, so good. Now, in Kosinski's 'Differential Manifolds', there is the following Lemma: Lemma: $\Sigma(h)$ is diffeomorphic to $S^m$ if and only if $h$ extends over $D^m$. Moreover, $\Sigma(gh) = \Sigma(h)\# \Sigma(g)$. Here $M\# N$ denotes the connected sum of two manifolds as usual. The proof of this is left as an exercise for the reader, but I'm unsure, how one might construct an extension of $h$ to $D^m$, given that $\Sigma(h)$ is diffeomorphic to $S^m$? I know that in this case $h(\partial D^m)$ necessarily separates $\Sigma(h) = S^m$ into two components, and since $h(\partial D^m)$ is an embedded compact $(m-1)$-manifold (which is smooth), I can also prove that $h(\partial D^m)$ is the boundary of both connected components of its complement. But at this point I get lost. Is it clear that these two components are diffeomorphic to disks? Where might I find a proof of this? I'm fine with the other parts of this Lemma, but I just don't see how to extend $h$ given $\Sigma(h) = S^m$. If you could help me out, this would be very much appreciated. Thank you for your help!","Given an orientation-preserving diffeomorphism $h: \partial D^m \to \partial D^m$, we can glue two copies of the closed unit disk $D^m$ along the boundary by identifying $x \sim h(x)$ to form the quotient space $$\Sigma(h) := (D^m \amalg D^m)/\sim$$ Now we can give this quotient a smooth structure such that the obvious inclusions $D^m \hookrightarrow \Sigma(h)$ are smooth embeddings and in fact it turns out that for any two smooth structures, there exists a diffeomorphism between them. So $\Sigma(h)$ is a unique manifold up to diffeomorphism. So far, so good. Now, in Kosinski's 'Differential Manifolds', there is the following Lemma: Lemma: $\Sigma(h)$ is diffeomorphic to $S^m$ if and only if $h$ extends over $D^m$. Moreover, $\Sigma(gh) = \Sigma(h)\# \Sigma(g)$. Here $M\# N$ denotes the connected sum of two manifolds as usual. The proof of this is left as an exercise for the reader, but I'm unsure, how one might construct an extension of $h$ to $D^m$, given that $\Sigma(h)$ is diffeomorphic to $S^m$? I know that in this case $h(\partial D^m)$ necessarily separates $\Sigma(h) = S^m$ into two components, and since $h(\partial D^m)$ is an embedded compact $(m-1)$-manifold (which is smooth), I can also prove that $h(\partial D^m)$ is the boundary of both connected components of its complement. But at this point I get lost. Is it clear that these two components are diffeomorphic to disks? Where might I find a proof of this? I'm fine with the other parts of this Lemma, but I just don't see how to extend $h$ given $\Sigma(h) = S^m$. If you could help me out, this would be very much appreciated. Thank you for your help!",,"['differential-geometry', 'differential-topology']"
55,Gaussian curvature in $S^3$,Gaussian curvature in,S^3,"I'm trying to read a survey paper on the Willmore conjecture and I'm missing a lot of basic knowledge. In particular, let $u: \mathcal{M} \rightarrow S^3 \rightarrow \mathbb{R}^4$ be a smooth immersion of a compact orientable two dimensional surface into the standard 3-sphere, and let $\mathcal{M}$ take the metric induced by the ambient space. Writing the principal curvatures as $k_1$ and $k_2$, we have the Gaussian curvature given by $1+k_1k_2$. I don't understand where the 1 in $K = 1+k_1k_2$ is coming from. The metric on $\mathbb{R}^4$ is the standard $g_{ij} = \delta_{ij}$, and restricting it to $S^3$ yields the round metric. $S^3$ is our ambient space, and restricting to $u$ gives us our induced metric. I can think of two ways of showing this. The first would simply be to do everything out in local coordinates: for any $p \in \mathcal{M}$, we have a chart $\varphi: U \rightarrow V \subset \mathbb{R}^2$. Writing $u(p) = u(\varphi^{-1}(x^1,x^2)) = (y^1,y^2,y^3,y^4)$ and then projecting stereographically $\sigma: S^3 \rightarrow \mathbb{R}^3$, $\sigma(\vec{y}) = (\frac{y^1}{1-y^4},\dots,\frac{y^3}{1-y^4})$, we could recover $K$ via typical computations. Alternatively, since $2K = \mathcal{R}$, the Ricci scalar, we could compute the curvature tensor and find it that way (unless there is some shortcut? I don't have much experience with these diffgeo objects). I'm wondering if either these approaches would get me what I want, or if there is a naive reason for where the $1$ is coming from. Any help is appreciated. The relevant stuff is on p. 365 of the document, or 5th page from the start, section 2: the S^3 framework.","I'm trying to read a survey paper on the Willmore conjecture and I'm missing a lot of basic knowledge. In particular, let $u: \mathcal{M} \rightarrow S^3 \rightarrow \mathbb{R}^4$ be a smooth immersion of a compact orientable two dimensional surface into the standard 3-sphere, and let $\mathcal{M}$ take the metric induced by the ambient space. Writing the principal curvatures as $k_1$ and $k_2$, we have the Gaussian curvature given by $1+k_1k_2$. I don't understand where the 1 in $K = 1+k_1k_2$ is coming from. The metric on $\mathbb{R}^4$ is the standard $g_{ij} = \delta_{ij}$, and restricting it to $S^3$ yields the round metric. $S^3$ is our ambient space, and restricting to $u$ gives us our induced metric. I can think of two ways of showing this. The first would simply be to do everything out in local coordinates: for any $p \in \mathcal{M}$, we have a chart $\varphi: U \rightarrow V \subset \mathbb{R}^2$. Writing $u(p) = u(\varphi^{-1}(x^1,x^2)) = (y^1,y^2,y^3,y^4)$ and then projecting stereographically $\sigma: S^3 \rightarrow \mathbb{R}^3$, $\sigma(\vec{y}) = (\frac{y^1}{1-y^4},\dots,\frac{y^3}{1-y^4})$, we could recover $K$ via typical computations. Alternatively, since $2K = \mathcal{R}$, the Ricci scalar, we could compute the curvature tensor and find it that way (unless there is some shortcut? I don't have much experience with these diffgeo objects). I'm wondering if either these approaches would get me what I want, or if there is a naive reason for where the $1$ is coming from. Any help is appreciated. The relevant stuff is on p. 365 of the document, or 5th page from the start, section 2: the S^3 framework.",,"['differential-geometry', 'differential-topology']"
56,question on connection on tensor bundle induced by a linear connection,question on connection on tensor bundle induced by a linear connection,,"I have a question regarding the definition of the covariant derivative of tensor fields, as given by John Lee in the book Riemannian Manifolds: An Introduction to Curvature On page 53 he states the following lemma: Let $\triangledown$ be a linear connection on $M$. There is a unique connection in each tensor bundle $T^k_l(M)$, also denoted $\triangledown$, such that the following conditions are satisfied: (a) On TM, $\triangledown$ agrees with the given connection (b) on $T^0M$, $\triangledown$ is given by ordinary differentiation on functions: $$ \triangledown_X f = Xf $$ This connection satisfies the following additional property: For any $F \in \mathcal{T}^k_l(M)$, vector fields $Y_i$ and 1-forms $\omega^j$, $$ \begin{eqnarray} &(\triangledown_X F) (\omega^1, \dots \omega^l,Y_1, \dots Y_k) =   X( F (\omega^1, \dots \omega^l,Y_1, \dots Y_k)) \\ &- \sum_{i = 1}^l F (\omega^1, \dots , \triangledown_X \omega^i, \dots \omega^l,Y_1, \dots Y_k) \\ &- \sum_{i = 1}^k F (\omega^1, \dots ,  \omega^l,Y_1, \dots, \triangledown_X Y_i, \dots Y_k) \end{eqnarray} $$ Now, if I apply this property, say, to the Euclidean metric and the Euclidean connection, I obtain the following. Let $Y = Y^i \partial_i$ and $Z = Z^i \partial_i$ be vector fields in local coordinates. Let the Euclidean Connection $\overline{\triangledown}$ be given by  $$ \overline{\triangledown}_X Y = (X Y^i) \partial_i $$ Let $g$ denote the Euclidean metric, so that $$ g(Y,Z) = \sum_i Y^iZ^i $$ Then, the above property gives  $$ \overline{\triangledown}_X g(Y,Z) = X(\sum_i Y^iZ^i) - \sum_i (XY^i)Z^i - \sum_i Y^i(XZ^i) = 0 $$ .. this does look strange - what am I doing wrong ?","I have a question regarding the definition of the covariant derivative of tensor fields, as given by John Lee in the book Riemannian Manifolds: An Introduction to Curvature On page 53 he states the following lemma: Let $\triangledown$ be a linear connection on $M$. There is a unique connection in each tensor bundle $T^k_l(M)$, also denoted $\triangledown$, such that the following conditions are satisfied: (a) On TM, $\triangledown$ agrees with the given connection (b) on $T^0M$, $\triangledown$ is given by ordinary differentiation on functions: $$ \triangledown_X f = Xf $$ This connection satisfies the following additional property: For any $F \in \mathcal{T}^k_l(M)$, vector fields $Y_i$ and 1-forms $\omega^j$, $$ \begin{eqnarray} &(\triangledown_X F) (\omega^1, \dots \omega^l,Y_1, \dots Y_k) =   X( F (\omega^1, \dots \omega^l,Y_1, \dots Y_k)) \\ &- \sum_{i = 1}^l F (\omega^1, \dots , \triangledown_X \omega^i, \dots \omega^l,Y_1, \dots Y_k) \\ &- \sum_{i = 1}^k F (\omega^1, \dots ,  \omega^l,Y_1, \dots, \triangledown_X Y_i, \dots Y_k) \end{eqnarray} $$ Now, if I apply this property, say, to the Euclidean metric and the Euclidean connection, I obtain the following. Let $Y = Y^i \partial_i$ and $Z = Z^i \partial_i$ be vector fields in local coordinates. Let the Euclidean Connection $\overline{\triangledown}$ be given by  $$ \overline{\triangledown}_X Y = (X Y^i) \partial_i $$ Let $g$ denote the Euclidean metric, so that $$ g(Y,Z) = \sum_i Y^iZ^i $$ Then, the above property gives  $$ \overline{\triangledown}_X g(Y,Z) = X(\sum_i Y^iZ^i) - \sum_i (XY^i)Z^i - \sum_i Y^i(XZ^i) = 0 $$ .. this does look strange - what am I doing wrong ?",,"['differential-geometry', 'riemannian-geometry']"
57,Heat kernel on a noncompact manifold,Heat kernel on a noncompact manifold,,"I'd like to understand some issues about the heat problem related to the Laplacian of a Riemannian manifold especially when the manifold is noncompact. So first recall the heat equation on a Riemannian $C^{\infty}$-Manifold $(M,g)$. When $M$ is compact, there is a unique function, the heat kernel, $K \in C^\infty (M \times M \times \mathbb{R^+})$ satisfying $(\partial_t + \Delta_x)K(x,y,t) = 0$ and $ \lim_{t \rightarrow 0} \ \int\limits_{M} K(x,y,t)f(y)dvol_y = f(x) \ \ \forall f \in L^2(M) $ And as far as I know this fact stays true If $\partial M \neq \varnothing$ when one inserts an appropriate boundary condition (i.e. Dirichlet-condition) for the Problem. When $(M,g)$ is considered to be noncompact (the examples I want to examine are mainly conformally compact metrics) there is, as far as I know, no such $C^{\infty}$-Kernel but a distributional solution of the heat problem defining (as a distributional Schwartz kernel)  a kind of (pseudodifferential ?) operator, that ""has a conormal singularity"" on the diagonal $D:= \{(x,x,0) | x \in M \} \subset M\times M \times \mathbb{R}$. My first question is: Is that correct so far? (1) edit: After further investigation I got confused about the question, if a $C^{\infty}$-heat-kernel for a noncompact manifold exists. In Isaac Chavel's book ""Eigenvalues in Riemannian Geometry"" there is a theorem on page 188 in chapter XIII, that says: There IS a a $C^{\infty}$-kernel. Is that right or did I miss something?  (Here is the Google-books link: http://books.google.de/books?id=0v1VfTWuKGgC&printsec=frontcover&hl=de#v=onepage&q&f=false ) Until now I'm not very familiar with pseudodifferential operator calculus (but I want to improve my knowledge) and so I ask myself the following question: (2) Why can't there be an $C^{\infty}$-Solution like in the compact case? How can one prove that there can't be? Or can anybody refer to a book/paper/lecture note where this question is concerned? (3) What does ""conormal singularity"" with respect to some submanifold $Y$ exactly mean? I just vague know that it means to have a singularity much stronger in normal direction than in tangential direction and it is related to the Fourier transform. Nevertheless it stays mysterious to me. How can the occurence of the conormal singularity of the heat kernel for noncompact manifolds be seen? I would be happy for any comments or small hints, too! Thank you for your help.","I'd like to understand some issues about the heat problem related to the Laplacian of a Riemannian manifold especially when the manifold is noncompact. So first recall the heat equation on a Riemannian $C^{\infty}$-Manifold $(M,g)$. When $M$ is compact, there is a unique function, the heat kernel, $K \in C^\infty (M \times M \times \mathbb{R^+})$ satisfying $(\partial_t + \Delta_x)K(x,y,t) = 0$ and $ \lim_{t \rightarrow 0} \ \int\limits_{M} K(x,y,t)f(y)dvol_y = f(x) \ \ \forall f \in L^2(M) $ And as far as I know this fact stays true If $\partial M \neq \varnothing$ when one inserts an appropriate boundary condition (i.e. Dirichlet-condition) for the Problem. When $(M,g)$ is considered to be noncompact (the examples I want to examine are mainly conformally compact metrics) there is, as far as I know, no such $C^{\infty}$-Kernel but a distributional solution of the heat problem defining (as a distributional Schwartz kernel)  a kind of (pseudodifferential ?) operator, that ""has a conormal singularity"" on the diagonal $D:= \{(x,x,0) | x \in M \} \subset M\times M \times \mathbb{R}$. My first question is: Is that correct so far? (1) edit: After further investigation I got confused about the question, if a $C^{\infty}$-heat-kernel for a noncompact manifold exists. In Isaac Chavel's book ""Eigenvalues in Riemannian Geometry"" there is a theorem on page 188 in chapter XIII, that says: There IS a a $C^{\infty}$-kernel. Is that right or did I miss something?  (Here is the Google-books link: http://books.google.de/books?id=0v1VfTWuKGgC&printsec=frontcover&hl=de#v=onepage&q&f=false ) Until now I'm not very familiar with pseudodifferential operator calculus (but I want to improve my knowledge) and so I ask myself the following question: (2) Why can't there be an $C^{\infty}$-Solution like in the compact case? How can one prove that there can't be? Or can anybody refer to a book/paper/lecture note where this question is concerned? (3) What does ""conormal singularity"" with respect to some submanifold $Y$ exactly mean? I just vague know that it means to have a singularity much stronger in normal direction than in tangential direction and it is related to the Fourier transform. Nevertheless it stays mysterious to me. How can the occurence of the conormal singularity of the heat kernel for noncompact manifolds be seen? I would be happy for any comments or small hints, too! Thank you for your help.",,"['differential-geometry', 'partial-differential-equations']"
58,Is a vector bundle orientable if and only if its dual bundle is orientable?,Is a vector bundle orientable if and only if its dual bundle is orientable?,,"I was reading up on my dual spaces today and I made the following hypothesis: A vector bundle $\xi$ is orientable if and only if $\xi^*$ is orientable. This seems rather intuitive, and although it doesn't seem too hard to prove, I'm not sure how to formally prove it. Any help? EDIT: Also, I guess another assertion that would fall along these lines would be whether the following is true: If the ordered bases $v_1,...,v_n$ and $v'_1,...,v'_n$ for $V$ are equally oriented, then the same is true of the bases $v^*_1,...,v^*_n$ and $v^{'*}_1,...,v^{'*}_n$ for $V^*$. Can anyone help me on the proofs (if they're true)?","I was reading up on my dual spaces today and I made the following hypothesis: A vector bundle $\xi$ is orientable if and only if $\xi^*$ is orientable. This seems rather intuitive, and although it doesn't seem too hard to prove, I'm not sure how to formally prove it. Any help? EDIT: Also, I guess another assertion that would fall along these lines would be whether the following is true: If the ordered bases $v_1,...,v_n$ and $v'_1,...,v'_n$ for $V$ are equally oriented, then the same is true of the bases $v^*_1,...,v^*_n$ and $v^{'*}_1,...,v^{'*}_n$ for $V^*$. Can anyone help me on the proofs (if they're true)?",,"['differential-geometry', 'differential-topology']"
59,Parallel transport of a vector along two distinct curves,Parallel transport of a vector along two distinct curves,,"Let $\mathcal{M}$ be an n-dimensional manifold endowed with an affine connection $\nabla$. Let $\gamma_1:[a,b]\rightarrow M$ and $\gamma_2:[c,d]\rightarrow \mathcal{M}$ be two curves with the same initial and final points, that is, $p=\gamma_1(a)=\gamma_2(c), q=\gamma_1(b)=\gamma_2(d)$. Take  $X\in T_p\mathcal{M}$. Parallelly propagating $X$ along $\gamma_1$ and $\gamma_2$ we obtain two vectors $X_1, X_2\in T_q\mathcal{M}$, respectively. Let $R$ be the curvature tensor of the connection, $R(X,Y)Z=\nabla_X\nabla_Y Z - \nabla_Y\nabla_X Z -\nabla_{[X,Y]}Z$, and $\tau$ its torsion, $\tau(X,Y)=\nabla_X Y-\nabla_Y X -[X,Y]$. The question is: How can I compare the two vectors $X_1$ and $X_2$? Can I write the difference $(X_2-X_1)$ in terms of $R,\tau$ and the curves?","Let $\mathcal{M}$ be an n-dimensional manifold endowed with an affine connection $\nabla$. Let $\gamma_1:[a,b]\rightarrow M$ and $\gamma_2:[c,d]\rightarrow \mathcal{M}$ be two curves with the same initial and final points, that is, $p=\gamma_1(a)=\gamma_2(c), q=\gamma_1(b)=\gamma_2(d)$. Take  $X\in T_p\mathcal{M}$. Parallelly propagating $X$ along $\gamma_1$ and $\gamma_2$ we obtain two vectors $X_1, X_2\in T_q\mathcal{M}$, respectively. Let $R$ be the curvature tensor of the connection, $R(X,Y)Z=\nabla_X\nabla_Y Z - \nabla_Y\nabla_X Z -\nabla_{[X,Y]}Z$, and $\tau$ its torsion, $\tau(X,Y)=\nabla_X Y-\nabla_Y X -[X,Y]$. The question is: How can I compare the two vectors $X_1$ and $X_2$? Can I write the difference $(X_2-X_1)$ in terms of $R,\tau$ and the curves?",,"['differential-geometry', 'differential-topology']"
60,Exterior Derivative and Lie Derivative on infinite dimensional manifolds,Exterior Derivative and Lie Derivative on infinite dimensional manifolds,,"Lately I have been trying to understand the chapter in Abraham and Marsden's Foundations of Mechanics on infinite-dimensional Hamiltonian systems. Now that I've finally got a feeling for the canonical 1-form on an infinite-dimensional cotangent bundle, I can't get how to arrive at the expression of its exterior derivative. I have looked through Chernoff and Marsden's Properties of infinite-dimensional Hamiltonian systems and finally also at Abraham, Marsden and Ratiu's Manifolds, Tensor Analysis, and Applications book to get more exposure to some details, backgrounds and conventions. My precise question is how exactly to arrive from the expression of $\theta (x,\alpha) \cdot (e,\beta)= \alpha(e)$ -where $(x,\alpha)\in T^{\star}M$ is the footpoint and $(e,\beta)\in T_{(x,\alpha)}T^{\star}M$ describes the inserted tangent vector- to the given expression for the canonical symplectic form $\omega= -d\theta$ which is $\omega (e,\alpha) \cdot ((e_{1},\alpha_{1}),(e_{2},\alpha_{2}))= \alpha_{2}(e_{1})-\alpha_{1}(e_{2}) $ . In Abraham and Marsden's chapter they are talking about an induced/pulled back version of this on the tangent bundle, but my question is more about the original idea on the cotangent bundle as briefly presented in Chernoff and Marsden. They supposedly use the local formula for exterior derivative in terms of Lie Derivatives, but I just don't understand how to apply or rather utilize that here, to arrive at this result for $\omega$ , so any comment or help with this step would be much appreciated! Thank you for taking the time and interest :)","Lately I have been trying to understand the chapter in Abraham and Marsden's Foundations of Mechanics on infinite-dimensional Hamiltonian systems. Now that I've finally got a feeling for the canonical 1-form on an infinite-dimensional cotangent bundle, I can't get how to arrive at the expression of its exterior derivative. I have looked through Chernoff and Marsden's Properties of infinite-dimensional Hamiltonian systems and finally also at Abraham, Marsden and Ratiu's Manifolds, Tensor Analysis, and Applications book to get more exposure to some details, backgrounds and conventions. My precise question is how exactly to arrive from the expression of -where is the footpoint and describes the inserted tangent vector- to the given expression for the canonical symplectic form which is . In Abraham and Marsden's chapter they are talking about an induced/pulled back version of this on the tangent bundle, but my question is more about the original idea on the cotangent bundle as briefly presented in Chernoff and Marsden. They supposedly use the local formula for exterior derivative in terms of Lie Derivatives, but I just don't understand how to apply or rather utilize that here, to arrive at this result for , so any comment or help with this step would be much appreciated! Thank you for taking the time and interest :)","\theta (x,\alpha) \cdot (e,\beta)= \alpha(e) (x,\alpha)\in T^{\star}M (e,\beta)\in T_{(x,\alpha)}T^{\star}M \omega= -d\theta \omega (e,\alpha) \cdot ((e_{1},\alpha_{1}),(e_{2},\alpha_{2}))= \alpha_{2}(e_{1})-\alpha_{1}(e_{2})  \omega","['differential-geometry', 'differential-forms', 'classical-mechanics', 'symplectic-geometry', 'exterior-derivative']"
61,Holomorphic tangent bundle over projective line,Holomorphic tangent bundle over projective line,,"I know that the holomorphic tangent bundle to the complex projective line $T^{1,0}\mathbb{CP}^1$ is isomorphic to $\mathcal{O}(2)$ , i.e. the twofold tensor product of the hyperplane bundle of $\mathbb{CP}^1$ . Question : how do I identify under this correspondence the global holomorphic vector fields as sections of this $\mathcal{O}(2)$ ? Setup : the isomorphism between these line bundles can be seen by giving $\mathbb{CP}^1$ the homogeneous atlas given by $$ U_0=\{z_0\neq 0\}\ni (z_0:z_1) \mapsto \frac{z_1}{z_0}=z \in \mathbb{C} $$ $$ U_1=\{z_1\neq 0\}\ni (z_0:z_1) \mapsto -\frac{z_0}{z_1}=w \in \mathbb{C} $$ thus the change of coordinates from $z$ to $w$ reads $-\frac{1}{z}$ and the jacobian, which gives the transition functions for $T^{1,0}\mathbb{CP}^1$ is $$ g_{01}(z) = \frac{1}{z^2} \equiv \left(\frac{z_0}{z_1}\right)^2 $$ This is precisely the transition function of $\mathcal{O}(2)$ ! I already know that global holomorphic sections correspond to homogeneous polynomials in two variables $$H^0(\mathbb{CP}^1,\mathcal{O}(2))\simeq \langle Z_0^2, Z_0Z_1, Z_1^2\rangle$$ As far as I know, the ""derivatives"" $\frac{\partial}{\partial z},\frac{\partial}{\partial w}$ give global vector holomorphic vector fields over $\mathbb{CP}^1$ . But what is the third global holomorphic vector field? How can it be linearly independent from these derivative fields?","I know that the holomorphic tangent bundle to the complex projective line is isomorphic to , i.e. the twofold tensor product of the hyperplane bundle of . Question : how do I identify under this correspondence the global holomorphic vector fields as sections of this ? Setup : the isomorphism between these line bundles can be seen by giving the homogeneous atlas given by thus the change of coordinates from to reads and the jacobian, which gives the transition functions for is This is precisely the transition function of ! I already know that global holomorphic sections correspond to homogeneous polynomials in two variables As far as I know, the ""derivatives"" give global vector holomorphic vector fields over . But what is the third global holomorphic vector field? How can it be linearly independent from these derivative fields?","T^{1,0}\mathbb{CP}^1 \mathcal{O}(2) \mathbb{CP}^1 \mathcal{O}(2) \mathbb{CP}^1 
U_0=\{z_0\neq 0\}\ni (z_0:z_1) \mapsto \frac{z_1}{z_0}=z \in \mathbb{C}
 
U_1=\{z_1\neq 0\}\ni (z_0:z_1) \mapsto -\frac{z_0}{z_1}=w \in \mathbb{C}
 z w -\frac{1}{z} T^{1,0}\mathbb{CP}^1 
g_{01}(z) = \frac{1}{z^2} \equiv \left(\frac{z_0}{z_1}\right)^2
 \mathcal{O}(2) H^0(\mathbb{CP}^1,\mathcal{O}(2))\simeq \langle Z_0^2, Z_0Z_1, Z_1^2\rangle \frac{\partial}{\partial z},\frac{\partial}{\partial w} \mathbb{CP}^1","['differential-geometry', 'complex-geometry', 'projective-space']"
62,What do the fibers of the double tangent bundle look like?,What do the fibers of the double tangent bundle look like?,,"Consider the tangent bundle $\pi:TM\to M$ for some smooth manifold. As outlined in the Wikipedia page , we can then consider the double tangent bundle via the projection $\pi_*:TTM \to TM$ , with $\pi_*$ the pushforward of the canonical projection $\pi$ . In the above page, they then proceed to mention that, given $$\xi =\xi^k \frac{\partial}{\partial x^k}\Bigg|_x\in T_x M, \qquad X =X^k \frac{\partial}{\partial x^k}\Bigg|_x \in T_x M,\tag A$$ and ""applying the associated coordinate system"" $\xi\mapsto (x^1,...,x^n,\xi^1,...,\xi^n)$ on $TM$ , the fiber on $TTM$ at $X\in T_x M$ takes the form $$(\pi_*)^{-1}(X)=\left\{ X^k\frac{\partial}{\partial x^k}\Bigg|_\xi + Y^k\frac{\partial}{\partial \xi^k}\Bigg|_\xi : \,\, \xi\in T_x M,\,\, Y^1,...,Y^n\in\mathbb R \right\}.\tag B$$ I'm struggling to understand where this expression comes from. I think I understand that $(x^1,...,x^n,\xi^1,...,\xi^n)$ is a (local) parametrisation for $TM$ , and I can see that the fiber we are interested in is $T_X TM$ , that is, the set of elements of $TTM$ above $X$ , but I don't understand what the expression in the last equation represents. If I were to write a fiber $T_x M$ of the tangent bundle, this would be the set of pairs $(x,v)$ with $v$ ranging across all (equivalence classes of) smooth curves $I\to M$ passing through $x$ . In local coordinates, and focusing on the ""curve component"" of tangent vectors, I suppose we could write this as the set $$\pi^{-1}(x)=\left\{v^k \frac{\partial}{\partial x^k}\Bigg|_x : \,\, v^k\in\mathbb R\right\}.$$ By way of analogy, I'd guess $T_X TM$ to be the set of pairs $(X,V)$ with $V$ (equivalence classes of) curves $I\to TM$ passing through $X\in T_x M$ . But even switching to local coordinates, I'm not sure how to go from this description to the expression in (B).","Consider the tangent bundle for some smooth manifold. As outlined in the Wikipedia page , we can then consider the double tangent bundle via the projection , with the pushforward of the canonical projection . In the above page, they then proceed to mention that, given and ""applying the associated coordinate system"" on , the fiber on at takes the form I'm struggling to understand where this expression comes from. I think I understand that is a (local) parametrisation for , and I can see that the fiber we are interested in is , that is, the set of elements of above , but I don't understand what the expression in the last equation represents. If I were to write a fiber of the tangent bundle, this would be the set of pairs with ranging across all (equivalence classes of) smooth curves passing through . In local coordinates, and focusing on the ""curve component"" of tangent vectors, I suppose we could write this as the set By way of analogy, I'd guess to be the set of pairs with (equivalence classes of) curves passing through . But even switching to local coordinates, I'm not sure how to go from this description to the expression in (B).","\pi:TM\to M \pi_*:TTM \to TM \pi_* \pi \xi =\xi^k \frac{\partial}{\partial x^k}\Bigg|_x\in T_x M,
\qquad
X =X^k \frac{\partial}{\partial x^k}\Bigg|_x \in T_x M,\tag A \xi\mapsto (x^1,...,x^n,\xi^1,...,\xi^n) TM TTM X\in T_x M (\pi_*)^{-1}(X)=\left\{
X^k\frac{\partial}{\partial x^k}\Bigg|_\xi +
Y^k\frac{\partial}{\partial \xi^k}\Bigg|_\xi :
\,\, \xi\in T_x M,\,\, Y^1,...,Y^n\in\mathbb R
\right\}.\tag B (x^1,...,x^n,\xi^1,...,\xi^n) TM T_X TM TTM X T_x M (x,v) v I\to M x \pi^{-1}(x)=\left\{v^k \frac{\partial}{\partial x^k}\Bigg|_x
: \,\, v^k\in\mathbb R\right\}. T_X TM (X,V) V I\to TM X\in T_x M","['differential-geometry', 'vector-bundles', 'vector-fields', 'tangent-bundle']"
63,Existence of specific sections of vector bundles over a manifold,Existence of specific sections of vector bundles over a manifold,,"I am trying to do the following exercise from Hirsch, one could say that it's 3 exercises but they are all related so I believe it's best to treat them together: Let $\xi=(E,M,p)$ be an $n$ -plane bundle over a connected $k$ -manifold $M$ . a) If $k<n$ then $\xi$ has a non-vanishing section. Here I belive the idea is just to use the transversality theorem, since we can approximate the zero section map $s$ by mapping the transversal to the zero section $h_k$ and for $h_k$ close enough we will get that $p\circ h_k$ is a diffeomorphism. So we can consider $h_k\circ (p\circ h_k)^{-1}$ , and this will be a section, transversal to the zero section. But then by a dimension argument we have to have that their intersection is empty. b) If $k=n$ and $x\in M$ then $\xi$ has a section vanishing only at $x$ . Here let's divide this into two cases. First suppose $M$ has a non-vanishing section $s$ , then we can consider a function $f:M\rightarrow \mathbb{R}$ such that $f^{-1}(0)=x$ , I believe this is always possible, and just consider the section $fs$ . Now from the next question $c)$ and what we just did, we can assume that $\partial M=\emptyset $ and that $M$ is compact. Now if I remove a point from $M$ I get a non-compact manifold with a non-vanishing section, to be proved, and then we can just do an analogous argument to what we just did. c) If $k=n$ , and $\partial M\neq \emptyset $ or $M$ is non-compact, then $\xi$ has a non-vanishing section. Now let's first assume that $\partial M\neq \emptyset $ and that $M$ is compact . My idea is to try and do something similiar to what was done when we proved that a compact connected manifold with boundary has a non-vanishing vector field. So let's take the double $M'$ of $M$ . This will have a section $s$ with a finite number of zeros, by an analogous argument to what we did in $a)$ , which we denote by $F$ . Here I assume I can create a vector bundle over $M'$ by just taking the fibers of the vector bundle over $M$ . I believe this is possible, but would appreciate some input. We will call this $\xi'$ . Since $M'$ is connected there is a diffeomorphism $\phi :M'\rightarrow M'$ that takes $F$ into $M-M'$ . Then we can consider the map $s\circ \phi^{-1}|M :M\rightarrow \xi'$ that has no zeros. Now I would like to have a vector bundle map that goes from $\xi'\rightarrow \xi $ and covers the identity when we restrict to $M$ . But I'm not sure if this is possible since we want this map to not create zeros from the result we get from $s\circ \phi^{-1}$ , and I'm not sure how to create a map without using some partitions of unity. Now for the non-compact case I am kinda lost, have really no ideas on what to do. I thought about using the trivializing charts and then gluing everything together with partitions of unity, but when we glue things together, how can we do it in a way that doesn't create zeros ? I don't think I can have this control. So I am out of ideas and would appreciate some input. Don't really see where I can use the non-compactness hypothesis. Thanks in advance.","I am trying to do the following exercise from Hirsch, one could say that it's 3 exercises but they are all related so I believe it's best to treat them together: Let be an -plane bundle over a connected -manifold . a) If then has a non-vanishing section. Here I belive the idea is just to use the transversality theorem, since we can approximate the zero section map by mapping the transversal to the zero section and for close enough we will get that is a diffeomorphism. So we can consider , and this will be a section, transversal to the zero section. But then by a dimension argument we have to have that their intersection is empty. b) If and then has a section vanishing only at . Here let's divide this into two cases. First suppose has a non-vanishing section , then we can consider a function such that , I believe this is always possible, and just consider the section . Now from the next question and what we just did, we can assume that and that is compact. Now if I remove a point from I get a non-compact manifold with a non-vanishing section, to be proved, and then we can just do an analogous argument to what we just did. c) If , and or is non-compact, then has a non-vanishing section. Now let's first assume that and that is compact . My idea is to try and do something similiar to what was done when we proved that a compact connected manifold with boundary has a non-vanishing vector field. So let's take the double of . This will have a section with a finite number of zeros, by an analogous argument to what we did in , which we denote by . Here I assume I can create a vector bundle over by just taking the fibers of the vector bundle over . I believe this is possible, but would appreciate some input. We will call this . Since is connected there is a diffeomorphism that takes into . Then we can consider the map that has no zeros. Now I would like to have a vector bundle map that goes from and covers the identity when we restrict to . But I'm not sure if this is possible since we want this map to not create zeros from the result we get from , and I'm not sure how to create a map without using some partitions of unity. Now for the non-compact case I am kinda lost, have really no ideas on what to do. I thought about using the trivializing charts and then gluing everything together with partitions of unity, but when we glue things together, how can we do it in a way that doesn't create zeros ? I don't think I can have this control. So I am out of ideas and would appreciate some input. Don't really see where I can use the non-compactness hypothesis. Thanks in advance.","\xi=(E,M,p) n k M k<n \xi s h_k h_k p\circ h_k h_k\circ (p\circ h_k)^{-1} k=n x\in M \xi x M s f:M\rightarrow \mathbb{R} f^{-1}(0)=x fs c) \partial M=\emptyset  M M k=n \partial M\neq \emptyset  M \xi \partial M\neq \emptyset  M M' M s a) F M' M \xi' M' \phi :M'\rightarrow M' F M-M' s\circ \phi^{-1}|M :M\rightarrow \xi' \xi'\rightarrow \xi  M s\circ \phi^{-1}","['differential-geometry', 'manifolds', 'differential-topology', 'vector-bundles']"
64,Embedded submanifold of $\mathbb{S}^3$,Embedded submanifold of,\mathbb{S}^3,"Let's consider $f:\mathbb{S}^3\to \mathbb{R}$ with $f(x,y,z,t)=x^2+y^2-z^2-t^2$ (1) show that $M_0:= f^{-1}(0)$ is an embedded submanifold of $\mathbb{S}^3$ . (2) show that $M_0$ is diffeomorphic to the 2-torus. (3) find all points at which $f$ is a submersion. I have some problem with this exercise because I want to use the regular value theorem but proving that $f$ is a submersion at all points of $f^{-1}(0)$ , with charts of $\mathbb{S}^3$ , needs way too many calculations. How can I solve smartly this problem? My attempt for points (1) and (3): I can consider the natural extension of $f$ to $\mathbb{R}^4$ given by $\widetilde{f}: \mathbb{R}^4\to \mathbb{R}$ with $\widetilde{f}(x,y,z,t)=x^2+y^2-z^2-t^2$ . Clearly $\widetilde{f}$ is a submersion at all points $p\neq 0$ , so also at every $p\in \mathbb{S}^3$ . Therefore, since $f=\widetilde{f}\circ \iota\mid_{\mathbb{S}^3}$ , by chain rule I get, for $p\in \mathbb{S}^3$ , $$(df)_p=(d\widetilde{f})_p\circ (d\iota\mid_{\mathbb{S}^3})_p$$ where I know that $(d\widetilde{f})_p$ is surjective and $(d\iota\mid_{\mathbb{S}^3})_p$ is injective. It seems to be almost done but I don't know how to conclude.","Let's consider with (1) show that is an embedded submanifold of . (2) show that is diffeomorphic to the 2-torus. (3) find all points at which is a submersion. I have some problem with this exercise because I want to use the regular value theorem but proving that is a submersion at all points of , with charts of , needs way too many calculations. How can I solve smartly this problem? My attempt for points (1) and (3): I can consider the natural extension of to given by with . Clearly is a submersion at all points , so also at every . Therefore, since , by chain rule I get, for , where I know that is surjective and is injective. It seems to be almost done but I don't know how to conclude.","f:\mathbb{S}^3\to \mathbb{R} f(x,y,z,t)=x^2+y^2-z^2-t^2 M_0:= f^{-1}(0) \mathbb{S}^3 M_0 f f f^{-1}(0) \mathbb{S}^3 f \mathbb{R}^4 \widetilde{f}: \mathbb{R}^4\to \mathbb{R} \widetilde{f}(x,y,z,t)=x^2+y^2-z^2-t^2 \widetilde{f} p\neq 0 p\in \mathbb{S}^3 f=\widetilde{f}\circ \iota\mid_{\mathbb{S}^3} p\in \mathbb{S}^3 (df)_p=(d\widetilde{f})_p\circ (d\iota\mid_{\mathbb{S}^3})_p (d\widetilde{f})_p (d\iota\mid_{\mathbb{S}^3})_p","['differential-geometry', 'differential-topology']"
65,Is torsion even useful?,Is torsion even useful?,,"I have run across the existence of torsion as I study Reimannian geometry. I also know that in the case of Reimannian geometry, we can always find a unique metric-preserving connection with zero torsion: the Levi-Cevita connection. This begs the question, why is torsion a fruitful concept? I have found certain answers on math.se which provide examples of connections with torsion that look highly unnatural, like this one about torsion in two dimensions . What do we as mathematicians gain by studying torsion? Is there a single ""natural"" example of torsion? This Math overflow question: what is torsion intuitively seems to have fantastic answers that I cannot access - I simply do not know enough math, in particular, Lie groups and solder forms. Is there some way to ""elaborate"" the answers there with an example in 2D or 3D such that the essence is retained? I have often seen this picture: While this picture shows us what torsion is after defining it , it doesn't tell us why we would care to pick such a connection in the first place! So this is not a satisfactory answer for me right now. I want to understand why we even want torsion.","I have run across the existence of torsion as I study Reimannian geometry. I also know that in the case of Reimannian geometry, we can always find a unique metric-preserving connection with zero torsion: the Levi-Cevita connection. This begs the question, why is torsion a fruitful concept? I have found certain answers on math.se which provide examples of connections with torsion that look highly unnatural, like this one about torsion in two dimensions . What do we as mathematicians gain by studying torsion? Is there a single ""natural"" example of torsion? This Math overflow question: what is torsion intuitively seems to have fantastic answers that I cannot access - I simply do not know enough math, in particular, Lie groups and solder forms. Is there some way to ""elaborate"" the answers there with an example in 2D or 3D such that the essence is retained? I have often seen this picture: While this picture shows us what torsion is after defining it , it doesn't tell us why we would care to pick such a connection in the first place! So this is not a satisfactory answer for me right now. I want to understand why we even want torsion.",,"['differential-geometry', 'riemannian-geometry', 'connections']"
66,The Lie bracket of $\mathfrak{gl}_n(\mathbb{R})$ is the matrix commutator,The Lie bracket of  is the matrix commutator,\mathfrak{gl}_n(\mathbb{R}),"Notation/preliminaries. Let $\mathfrak{g}$ denote the Lie algebra (of left-invariant vector fields) on the Lie group $G$ . Its Lie bracket $[.,.]\colon \mathfrak{g}\times\mathfrak{g}\to\mathfrak{g}$ is defined by $$[X,Y]_p(f)=X_p(Y_{\square}(f))-Y_p(X_\square(f))$$ for any vector fields $X,Y\in C^{\infty}(TG)$ , any point $p\in G$ and any smooth function $f\in C^{\infty}(G)$ . Here, $X_\square(f)\colon G\to\mathbb{R}$ is the smooth map defined by $q\mapsto X_q(f)$ . Let $T_eG$ denote the tangent space at the identify element $e$ , consisting of all linear maps $C^{\infty}(G)\to \mathbb{R}$ which satisfy the product rule. The tangent space is equipped with the Lie bracket $[\![.,.]\!]\colon T_eG\times T_eG\to T_eG$ given by $[\![X_e,Y_e]\!]=[X,Y]_e$ . This gives us a Lie algebra isomorphism $\mathfrak{g}\cong T_eG$ . More precisely, one can show that every tangent vector $X_e\in T_eG$ can be extended in a unique way to a left-invariant vector field $X\in \mathfrak{g}$ . For the Lie group $G=\mathrm{GL}_n(\mathbb{R})$ , we can use $x\colon \mathrm{GL}_n(\mathbb{R})\to \mathbb{R}^{n\times n}$ defined by $p\mapsto p$ as global coordinates. We will use $\Big\{\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Big\}_{i,j=1}^n$ as a basis for $T_e\mathrm{GL}_n(\mathbb{R})$ . Here, $\Big(\frac{\partial}{\partial x^{ij}}\Big)_e(f)=\partial_{ij}(f\circ x^{-1})\vert_{x(e)}$ for everh smooth function $f\colon \mathrm{GL}_n(\mathbb{R})\to\mathbb{R}$ . This gives rise to a vector space isomorphism $T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ via $\sum_{i,j} a_{ij}\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\mapsto (a_{ij})$ . For any vector field $X$ on $\mathrm{GL}_n(\mathbb{R})$ , we let $M_X$ denote the matrix associated to $X$ via the identifications $\mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ . Problem. I want to show that under the identifications $\mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n}$ , $[.,.]$ corresponds to the matrix commutator on $\mathbb{R}^{n\times n}$ . Or more precisely: For any vector fields $X$ and $Y$ on $\mathrm{GL}_n(\mathbb{R})$ , it holds that $M_{[X,Y]}=M_XM_Y-M_YM_X$ . Own attempt. I have realized that it suffices to show that for two tangent vectors $X_e=\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e$ and $Y_e=\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e$ , it holds that $$[X,Y]_e=\sum_{i,j,k} \big(a_{ik}b_{kj}-b_{ik}a_{kj}\big)\Big(\frac{\partial}{\partial x^{ij}}\Big)_e.$$ The first step, I guess, is to find the extensions $X$ and $Y$ of $X_e$ and $Y_e$ , respectively. I'm more or less convinced that for any $p=(p_{ij})\in \mathrm{GL}_n(\mathbb{R})$ , it holds that $$X_p=\sum_{i,j,k} p_{ik}a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_p.$$ Can we conclude from this that $X=\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square$ holds? I've then tried to compute $[X,Y]_e(f)$ for an arbtirary $f\in C^\infty(\mathrm{GL}_n(\mathbb{R}))$ , using the formula in (1) above, and end up with the scary expression $$[X,Y]_e(f)=\Bigg(\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)b_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)-\Bigg(\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)\,,$$ from which I have no idea where to go. Am I at all on the right track here? It feels like my main problem is that I get a little bit lost in all the notation and all identifications we make back and forth. Indeed, proofs of this fact can be found in many text books (e.g. Lee's Introduction to Smooth Manifolds p. 194), but the notation there tends to be too coarse for me to follow what is going on.","Notation/preliminaries. Let denote the Lie algebra (of left-invariant vector fields) on the Lie group . Its Lie bracket is defined by for any vector fields , any point and any smooth function . Here, is the smooth map defined by . Let denote the tangent space at the identify element , consisting of all linear maps which satisfy the product rule. The tangent space is equipped with the Lie bracket given by . This gives us a Lie algebra isomorphism . More precisely, one can show that every tangent vector can be extended in a unique way to a left-invariant vector field . For the Lie group , we can use defined by as global coordinates. We will use as a basis for . Here, for everh smooth function . This gives rise to a vector space isomorphism via . For any vector field on , we let denote the matrix associated to via the identifications . Problem. I want to show that under the identifications , corresponds to the matrix commutator on . Or more precisely: For any vector fields and on , it holds that . Own attempt. I have realized that it suffices to show that for two tangent vectors and , it holds that The first step, I guess, is to find the extensions and of and , respectively. I'm more or less convinced that for any , it holds that Can we conclude from this that holds? I've then tried to compute for an arbtirary , using the formula in (1) above, and end up with the scary expression from which I have no idea where to go. Am I at all on the right track here? It feels like my main problem is that I get a little bit lost in all the notation and all identifications we make back and forth. Indeed, proofs of this fact can be found in many text books (e.g. Lee's Introduction to Smooth Manifolds p. 194), but the notation there tends to be too coarse for me to follow what is going on.","\mathfrak{g} G [.,.]\colon \mathfrak{g}\times\mathfrak{g}\to\mathfrak{g} [X,Y]_p(f)=X_p(Y_{\square}(f))-Y_p(X_\square(f)) X,Y\in C^{\infty}(TG) p\in G f\in C^{\infty}(G) X_\square(f)\colon G\to\mathbb{R} q\mapsto X_q(f) T_eG e C^{\infty}(G)\to \mathbb{R} [\![.,.]\!]\colon T_eG\times T_eG\to T_eG [\![X_e,Y_e]\!]=[X,Y]_e \mathfrak{g}\cong T_eG X_e\in T_eG X\in \mathfrak{g} G=\mathrm{GL}_n(\mathbb{R}) x\colon \mathrm{GL}_n(\mathbb{R})\to \mathbb{R}^{n\times n} p\mapsto p \Big\{\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Big\}_{i,j=1}^n T_e\mathrm{GL}_n(\mathbb{R}) \Big(\frac{\partial}{\partial x^{ij}}\Big)_e(f)=\partial_{ij}(f\circ x^{-1})\vert_{x(e)} f\colon \mathrm{GL}_n(\mathbb{R})\to\mathbb{R} T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n} \sum_{i,j} a_{ij}\Big(\frac{\partial}{\partial x^{ij}}\Big)_e\mapsto (a_{ij}) X \mathrm{GL}_n(\mathbb{R}) M_X X \mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n} \mathfrak{gl}_n(\mathbb{R})\cong T_e\mathrm{GL}_n(\mathbb{R})\cong \mathbb{R}^{n\times n} [.,.] \mathbb{R}^{n\times n} X Y \mathrm{GL}_n(\mathbb{R}) M_{[X,Y]}=M_XM_Y-M_YM_X X_e=\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e Y_e=\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e [X,Y]_e=\sum_{i,j,k} \big(a_{ik}b_{kj}-b_{ik}a_{kj}\big)\Big(\frac{\partial}{\partial x^{ij}}\Big)_e. X Y X_e Y_e p=(p_{ij})\in \mathrm{GL}_n(\mathbb{R}) X_p=\sum_{i,j,k} p_{ik}a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_p. X=\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square [X,Y]_e(f) f\in C^\infty(\mathrm{GL}_n(\mathbb{R})) [X,Y]_e(f)=\Bigg(\sum_{i,j} a_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)b_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)-\Bigg(\sum_{i,j} b_{ij} \Big(\frac{\partial}{\partial x^{ij}}\Big)_e\Bigg)\Bigg(\Big(\sum_{i,j,k} x_{ik}(\square)a_{kj}\Big(\frac{\partial}{\partial x^{ij}}\Big)_\square\Big)(f)\Bigg)\,,","['differential-geometry', 'lie-groups', 'lie-algebras', 'smooth-manifolds']"
67,Definition of conjugate momentum on a manifold,Definition of conjugate momentum on a manifold,,"I have trouble understanding this definition: Let $Q$ be some manifold and $L: TQ \to \mathbb{R}$ a smooth function. Then for some local coordinates $(q, \dot{q})$ on $TQ$ the conjugated momentum is defined as $\frac{\partial L}{\partial \dot{q}}$ , which is an element of the co-tangential bundle $T^{*}Q$ . How is the expression $\frac{\partial L}{\partial \dot{q}}$ to be interpreted? If one simply expresses $L$ in local coordinates by $$L \circ(q^{-1}, \dot{q}^{-1}): \mathbb{R}^{2n} \to \mathbb{R}$$ and differentiates it with respect to the second variable one gets a function $\mathbb{R}^n \to \mathbb{R}$ and not an element of the co-tangential bundle $T^{*}Q$ . Is the correct expression $$\partial_2 ( L \circ(q^{-1}, \dot{q}^{-1}))\circ (q, \dot{q}) \in T^{*}Q\ ?$$","I have trouble understanding this definition: Let be some manifold and a smooth function. Then for some local coordinates on the conjugated momentum is defined as , which is an element of the co-tangential bundle . How is the expression to be interpreted? If one simply expresses in local coordinates by and differentiates it with respect to the second variable one gets a function and not an element of the co-tangential bundle . Is the correct expression","Q L: TQ \to \mathbb{R} (q, \dot{q}) TQ \frac{\partial L}{\partial \dot{q}} T^{*}Q \frac{\partial L}{\partial \dot{q}} L L \circ(q^{-1}, \dot{q}^{-1}): \mathbb{R}^{2n} \to \mathbb{R} \mathbb{R}^n \to \mathbb{R} T^{*}Q \partial_2 ( L \circ(q^{-1}, \dot{q}^{-1}))\circ (q, \dot{q}) \in T^{*}Q\ ?","['differential-geometry', 'manifolds', 'differential-topology', 'mathematical-physics', 'classical-mechanics']"
68,Functions on a manifold,Functions on a manifold,,"I am learning about diff geometry and I have a question about ways of defining a function on a manifold. So if we think about manifolds in general we can define a chart on it. Then, through composition of a function and a chart we can analyze this function. My question is this. How can we define a function in the first place since it is on points P which need not be numbers. Dont we need to define the function on a chart in order for it to be defined on a manifold? And dont we then need to define a manifold through charts also? But in order for it to be defined properly we have to look for chart independent ptoperties which are read off the charts... I am confused.","I am learning about diff geometry and I have a question about ways of defining a function on a manifold. So if we think about manifolds in general we can define a chart on it. Then, through composition of a function and a chart we can analyze this function. My question is this. How can we define a function in the first place since it is on points P which need not be numbers. Dont we need to define the function on a chart in order for it to be defined on a manifold? And dont we then need to define a manifold through charts also? But in order for it to be defined properly we have to look for chart independent ptoperties which are read off the charts... I am confused.",,"['differential-geometry', 'manifolds']"
69,Using Stokes's theorem to prove $curl(F) = 0 \implies F$ is conservative.,Using Stokes's theorem to prove  is conservative.,curl(F) = 0 \implies F,"A classical result from vector calculus says that if a vector field $F: \mathbb{R}^3 \to \mathbb{R}^3$ satisfies curl$(F) = 0$, then $F$ is conservative, i.e. $F = \nabla f$ for some $f: \mathbb{R}^3 \to \mathbb{R}$. I am curious about the following rough sketch of a proof of this fact, using Stokes's theorem: ""Proof:"" Recall that $F$ is conservative if and only if $\int_C F \cdot dr = 0$ for every closed curve $C$. To show the latter condition, let $C$ be any curve, and choose an oriented surface $S$ with $\partial S = C$(!). By Stokes's theorem, $\int_C F \cdot dr = \int_S \text{curl}(F) \cdot dS = \int_S 0 \cdot dS = 0.$ Thus $F$ is conservative. I am wondering how the formal details of (!) would go: namely, how does one show that any closed curve $C$ is the boundary of some oriented surface $S$? This seems intuitively obvious. I would be happy with a proof of this fact even under very nice assumptions on $C$, say if $C$ is a simple, closed, smooth curve. I haven't been able to find a reference for this, other than a parenthetical mention in Stewart's calculus, which says 'This can be done, but the proof requires advanced techniques.'","A classical result from vector calculus says that if a vector field $F: \mathbb{R}^3 \to \mathbb{R}^3$ satisfies curl$(F) = 0$, then $F$ is conservative, i.e. $F = \nabla f$ for some $f: \mathbb{R}^3 \to \mathbb{R}$. I am curious about the following rough sketch of a proof of this fact, using Stokes's theorem: ""Proof:"" Recall that $F$ is conservative if and only if $\int_C F \cdot dr = 0$ for every closed curve $C$. To show the latter condition, let $C$ be any curve, and choose an oriented surface $S$ with $\partial S = C$(!). By Stokes's theorem, $\int_C F \cdot dr = \int_S \text{curl}(F) \cdot dS = \int_S 0 \cdot dS = 0.$ Thus $F$ is conservative. I am wondering how the formal details of (!) would go: namely, how does one show that any closed curve $C$ is the boundary of some oriented surface $S$? This seems intuitively obvious. I would be happy with a proof of this fact even under very nice assumptions on $C$, say if $C$ is a simple, closed, smooth curve. I haven't been able to find a reference for this, other than a parenthetical mention in Stewart's calculus, which says 'This can be done, but the proof requires advanced techniques.'",,"['differential-geometry', 'vector-analysis']"
70,"Is the winding number of a simple closed curve always -1, 0 or 1?","Is the winding number of a simple closed curve always -1, 0 or 1?",,"Let $\gamma:[a,b]\to \mathbb{R^2}-\{0\}$ be a closed curve of class $C^1$. Define the 1-form $d\theta$ in $\mathbb{R^2}-\{0\}$ as $d\theta=\frac{-y}{x^2+y^2}dx+\frac{x}{x^2+y^2}dy$ and the winding number of $\gamma$ to be $n(\gamma)=\frac{1}{2\pi}\int_\gamma d\theta$. It is a standard result that $n(\gamma)$ is always an integer number. The question is: if $\gamma:[a,b]\to \mathbb{R^2}-\{0\}$ is a simple (i.e. nonintersecting) closed curve of class $C^1$. Is it always the case that $n(\gamma)=-1$, $0$, or $1$? It intuitively looks to be true, however I can't prove it or find a counterexample.","Let $\gamma:[a,b]\to \mathbb{R^2}-\{0\}$ be a closed curve of class $C^1$. Define the 1-form $d\theta$ in $\mathbb{R^2}-\{0\}$ as $d\theta=\frac{-y}{x^2+y^2}dx+\frac{x}{x^2+y^2}dy$ and the winding number of $\gamma$ to be $n(\gamma)=\frac{1}{2\pi}\int_\gamma d\theta$. It is a standard result that $n(\gamma)$ is always an integer number. The question is: if $\gamma:[a,b]\to \mathbb{R^2}-\{0\}$ is a simple (i.e. nonintersecting) closed curve of class $C^1$. Is it always the case that $n(\gamma)=-1$, $0$, or $1$? It intuitively looks to be true, however I can't prove it or find a counterexample.",,['differential-geometry']
71,Unique differentiable structure on homeomorphic manifolds in low dimension,Unique differentiable structure on homeomorphic manifolds in low dimension,,"When I took the introductory lectures to geometry and topology some years ago our professor mentioned the following result: Let $n\in \{1, 2, 3 \}$ and $M, N$ be two $n$-dimensional differentiable manifolds. Then   $$ M \text{ and } N \text{ homeomorphic} \Rightarrow  M \text{ and } N \text{ diffeomorphic.} $$ I could not find a reference, where this is acutally proved. I'd greatly appreciate if someone could provide my with a paper (or book) containing this result. I read in the comment section of how to prove that every low-dimensional topological manifold has a unique smooth structure up to diffeomorphism? that this should be in Moise's book ""Geometric Topology in Dimensions 2 and 3"", however, I couldn't find such a statement in there.","When I took the introductory lectures to geometry and topology some years ago our professor mentioned the following result: Let $n\in \{1, 2, 3 \}$ and $M, N$ be two $n$-dimensional differentiable manifolds. Then   $$ M \text{ and } N \text{ homeomorphic} \Rightarrow  M \text{ and } N \text{ diffeomorphic.} $$ I could not find a reference, where this is acutally proved. I'd greatly appreciate if someone could provide my with a paper (or book) containing this result. I read in the comment section of how to prove that every low-dimensional topological manifold has a unique smooth structure up to diffeomorphism? that this should be in Moise's book ""Geometric Topology in Dimensions 2 and 3"", however, I couldn't find such a statement in there.",,"['differential-geometry', 'reference-request', 'manifolds']"
72,What’s the relation between local diagonalisation of Riemannian metrics and the eigenprojections for the representation matrix functions?,What’s the relation between local diagonalisation of Riemannian metrics and the eigenprojections for the representation matrix functions?,,"Recently, the topic of smooth diagonalisation of Riemannian metrics came to my interest. Namely, I've read through this paper from Duke Math. J. Volume 51, Number 2 (1984), 243-260 (unfortunately the document doesn't seem to be publicly available). In Theorem 4.2, they state and prove the following: Let $(M^3, g)$ be a three-dimensional $C^\infty$ Riemannian manifold. Then there is an atlas of $C^\infty$ coordinate charts for $M$ such that, in each chart, the metric is diagonal, i.e. $$d s^2 = \lambda_1(x, y, z) d x^2 + \lambda_2 (x, y, z) d y^2 + \lambda_3 (x, y, z) d z^2$$ They furthermore make a similar statement for the case $n = 2$ , namely that for two-manifolds, one has always coordinates in which the metric locally takes the form $$d s^2 = \lambda(x, y) (d x^2 + d y^2)$$ As someone for who Riemannian manifolds are a relatively fresh topic, I'm still confused by how one can understand and interpret this property of diagonalisation and how one can actually diagonalize in practice. First and foremost, I've been trying to wrap my head around the following: let's take a fixed point $p \in M$ and consider the metric $g_p$ at this point $p$ , and let $T(x)$ be it's representation as a matrix, where $x \in T_pM$ . From my understanding, the diagonalisation of $g_p$ would then be equipvalent to finding smooth eigenprojections for the representation matrix $T(x)$ . However, even for a smooth matrix function $T(x)$ , the eigenspaces and eigenprojections do not need to behave smoothly or even exist everywhere. I found the following example in this book by Kato, §5.3: Let $n = 2$ , and: $$T(x) = e^{- \frac 1{x^2}} \pmatrix{\cos \frac 2x & \sin \frac 2x \\ \sin \frac 2x & - \cos \frac 2x}, T(0) = 0$$ Then $T(x)$ is continuous and indefinitely differentiable for all real values of $x$ , and the eigenvalues of $T(x)$ which turn out to be $\pm e^{- \frac 1 {x^2}}$ (for $x \neq 0$ ) and $0$ (for $x = 0$ ) are continuous and indefinitely differentiable aswell. However, the eigenprojections for $x \neq 0$ in this case are: $$ \pmatrix{\cos^2 \frac 1x & \cos \frac 1x \sin \frac 1x \\ \cos \frac 1x \sin \frac 1x & \sin^2 \frac 1x}, \pmatrix{ \sin^2 \frac 1x & - \cos \frac 1x \sin \frac 1x \\ - \cos \frac 1x \sin \frac 1x & \cos^2 \frac 1x}$$ These matrix functions are continuous and indefinitely differentiable on any interval that doesn't contain $0$ , but they cannot be continued to $x = 0$ as continuous functions. Also, one can show that there doesn't exist any eigenvector of $T(x)$ that is continuous in the neighborhood of $x = 0$ and doesn't vanish in $x = 0$ . Sorry for this rather tedious example, but now my question is: Why is this not a contradiction to the diagonalisation? If according to Deturck and Yang all Riemannian metrics are locally diagonalizable for $n = 2, 3$ , then why are there matrix functions like these that are not smoothly diagonalizable? Do these metric diagonalisations not correspond to finding the respective eigenprojection functions of the local metrix representation, and if so, why not? Or if there something else that I'm missing? Any help would be much appreciated – maybe I'm just missing something very simple. I've been trying to wrap my head around this now for some days but without success.","Recently, the topic of smooth diagonalisation of Riemannian metrics came to my interest. Namely, I've read through this paper from Duke Math. J. Volume 51, Number 2 (1984), 243-260 (unfortunately the document doesn't seem to be publicly available). In Theorem 4.2, they state and prove the following: Let be a three-dimensional Riemannian manifold. Then there is an atlas of coordinate charts for such that, in each chart, the metric is diagonal, i.e. They furthermore make a similar statement for the case , namely that for two-manifolds, one has always coordinates in which the metric locally takes the form As someone for who Riemannian manifolds are a relatively fresh topic, I'm still confused by how one can understand and interpret this property of diagonalisation and how one can actually diagonalize in practice. First and foremost, I've been trying to wrap my head around the following: let's take a fixed point and consider the metric at this point , and let be it's representation as a matrix, where . From my understanding, the diagonalisation of would then be equipvalent to finding smooth eigenprojections for the representation matrix . However, even for a smooth matrix function , the eigenspaces and eigenprojections do not need to behave smoothly or even exist everywhere. I found the following example in this book by Kato, §5.3: Let , and: Then is continuous and indefinitely differentiable for all real values of , and the eigenvalues of which turn out to be (for ) and (for ) are continuous and indefinitely differentiable aswell. However, the eigenprojections for in this case are: These matrix functions are continuous and indefinitely differentiable on any interval that doesn't contain , but they cannot be continued to as continuous functions. Also, one can show that there doesn't exist any eigenvector of that is continuous in the neighborhood of and doesn't vanish in . Sorry for this rather tedious example, but now my question is: Why is this not a contradiction to the diagonalisation? If according to Deturck and Yang all Riemannian metrics are locally diagonalizable for , then why are there matrix functions like these that are not smoothly diagonalizable? Do these metric diagonalisations not correspond to finding the respective eigenprojection functions of the local metrix representation, and if so, why not? Or if there something else that I'm missing? Any help would be much appreciated – maybe I'm just missing something very simple. I've been trying to wrap my head around this now for some days but without success.","(M^3, g) C^\infty C^\infty M d s^2 = \lambda_1(x, y, z) d x^2 + \lambda_2 (x, y, z) d y^2 + \lambda_3 (x, y, z) d z^2 n = 2 d s^2 = \lambda(x, y) (d x^2 + d y^2) p \in M g_p p T(x) x \in T_pM g_p T(x) T(x) n = 2 T(x) = e^{- \frac 1{x^2}} \pmatrix{\cos \frac 2x & \sin \frac 2x \\ \sin \frac 2x & - \cos \frac 2x}, T(0) = 0 T(x) x T(x) \pm e^{- \frac 1 {x^2}} x \neq 0 0 x = 0 x \neq 0  \pmatrix{\cos^2 \frac 1x & \cos \frac 1x \sin \frac 1x \\ \cos \frac 1x \sin \frac 1x & \sin^2 \frac 1x}, \pmatrix{ \sin^2 \frac 1x & - \cos \frac 1x \sin \frac 1x \\ - \cos \frac 1x \sin \frac 1x & \cos^2 \frac 1x} 0 x = 0 T(x) x = 0 x = 0 n = 2, 3","['differential-geometry', 'manifolds', 'riemannian-geometry']"
73,Techniques for computing the Brouwer degree of a smooth map,Techniques for computing the Brouwer degree of a smooth map,,"This question is relative to John Milnor's Topology from the Differentiable Viewpoint book, more precisely relative to the problems 13,14 & 15 he is giving at the end of his book. Let $\eta:S^3\to S^2$ be the Hopf fibration, with $S^3\subset\mathbb{C}^2$ and $S^2\subset\mathbb{C}\times\mathbb{R}$. I was able to show easily that for any point $P\in S^2$, $\eta^{-1}(P)$ is homeomorphic to $S^1\subset\mathbb{C}^2$. Furthermore, Milnor suggests that for any two points $P,Q\in S^2$, $P\neq Q$, the circles $\eta^{-1}(P)$ and $\eta^{-1}(Q)$ are linked. From this, we introduce the linking map $\lambda$ which is well defined for disjoints manifolds. Hence, for    $$\lambda:\eta^{-1}(P)\times\eta^{-1}(Q)\to S^2,\qquad \lambda(x,y)=\dfrac{x-y}{||x-y||}$$   we are looking to compute the Brouwer degree of $\lambda$ using elementary methods of computations (we assume that the circles are oriented as submanifolds of $S^3$). I'm asking for elementary methods since Milnor does not introduce integration in his tiny book. If one is able to compute it directly with the definition, I would love to see how. If you have any other suggestions, please share it. Thank you very much.","This question is relative to John Milnor's Topology from the Differentiable Viewpoint book, more precisely relative to the problems 13,14 & 15 he is giving at the end of his book. Let $\eta:S^3\to S^2$ be the Hopf fibration, with $S^3\subset\mathbb{C}^2$ and $S^2\subset\mathbb{C}\times\mathbb{R}$. I was able to show easily that for any point $P\in S^2$, $\eta^{-1}(P)$ is homeomorphic to $S^1\subset\mathbb{C}^2$. Furthermore, Milnor suggests that for any two points $P,Q\in S^2$, $P\neq Q$, the circles $\eta^{-1}(P)$ and $\eta^{-1}(Q)$ are linked. From this, we introduce the linking map $\lambda$ which is well defined for disjoints manifolds. Hence, for    $$\lambda:\eta^{-1}(P)\times\eta^{-1}(Q)\to S^2,\qquad \lambda(x,y)=\dfrac{x-y}{||x-y||}$$   we are looking to compute the Brouwer degree of $\lambda$ using elementary methods of computations (we assume that the circles are oriented as submanifolds of $S^3$). I'm asking for elementary methods since Milnor does not introduce integration in his tiny book. If one is able to compute it directly with the definition, I would love to see how. If you have any other suggestions, please share it. Thank you very much.",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'hopf-fibration']"
74,Orthogonal differentiable family of curves,Orthogonal differentiable family of curves,,"This problem is out of section 4-4 in M. do Carmos' Differential Geometry of Curves and Surfaces : We say that a set of regular curves on a surface $S$ is a differentiable family of curves on $S$ if the tangent lines to the curves of the set make up a differentiable field of directions. Assume that a surface $S$ admits two differentiable orthogonal families of geodesics. Prove that the Gaussian curvature of $S$ is zero. As a tip, he says: Parametrize a neighborhood of $p\in S$ in such a way that the two families of   geodesics are coordinate curves (Corollary 1, Sec. 3-4). Show that this implies   that $F = 0, E_v = 0 = G_u$. Make a change of parameters to obtain that $\bar{F} = 0, \bar{E} = \bar{G} = 1$. I know that for every $p\in S$ we can find a neighbourhood $U\subset S$ of $p$ and a parametrization $X:I\times J\to U$ such that the coordinate curves $\alpha_{v_0}(u)=X(u,v_0)$ belong to one family and $\beta_{u_0}(v)=X(u_0, v)$ belong to the other. That way, $$F=<X_u,X_v>(u_0,v_0)=<\alpha'_{v_0}(u_0), \beta'_{u_0}(v_0)>=0$$ I also know that if I can prove that $E_v=G_u=0$, then I can use the formula for orthogonal parametrizations: $$K=-\frac{1}{2\sqrt{EG}}\left\{\left(\frac{G_u}{\sqrt{EG}}\right)_u+\left(\frac{E_v}{\sqrt{EG}}\right)_v\right\}$$ to prove that $K=0$, but I don't know how to prove that. Besides, I don't see the need of changing parameters to get $\bar{E}=\bar{G}=1$. Any hints?","This problem is out of section 4-4 in M. do Carmos' Differential Geometry of Curves and Surfaces : We say that a set of regular curves on a surface $S$ is a differentiable family of curves on $S$ if the tangent lines to the curves of the set make up a differentiable field of directions. Assume that a surface $S$ admits two differentiable orthogonal families of geodesics. Prove that the Gaussian curvature of $S$ is zero. As a tip, he says: Parametrize a neighborhood of $p\in S$ in such a way that the two families of   geodesics are coordinate curves (Corollary 1, Sec. 3-4). Show that this implies   that $F = 0, E_v = 0 = G_u$. Make a change of parameters to obtain that $\bar{F} = 0, \bar{E} = \bar{G} = 1$. I know that for every $p\in S$ we can find a neighbourhood $U\subset S$ of $p$ and a parametrization $X:I\times J\to U$ such that the coordinate curves $\alpha_{v_0}(u)=X(u,v_0)$ belong to one family and $\beta_{u_0}(v)=X(u_0, v)$ belong to the other. That way, $$F=<X_u,X_v>(u_0,v_0)=<\alpha'_{v_0}(u_0), \beta'_{u_0}(v_0)>=0$$ I also know that if I can prove that $E_v=G_u=0$, then I can use the formula for orthogonal parametrizations: $$K=-\frac{1}{2\sqrt{EG}}\left\{\left(\frac{G_u}{\sqrt{EG}}\right)_u+\left(\frac{E_v}{\sqrt{EG}}\right)_v\right\}$$ to prove that $K=0$, but I don't know how to prove that. Besides, I don't see the need of changing parameters to get $\bar{E}=\bar{G}=1$. Any hints?",,"['differential-geometry', 'surfaces', 'curves', 'curvature']"
75,The only surface with at least three distinct lines through each of its points is the plane,The only surface with at least three distinct lines through each of its points is the plane,,"Wikipedia's article on ruled surfaces includes this remark: The plane is the only surface which contains at least three distinct lines through each of its points. I'd like to see a reference or proof for this fact. I assume that the ""surfaces"" we consider in this proposition are two-dimensional smooth submanifold of $\Bbb R^3$. This may also answer this question .","Wikipedia's article on ruled surfaces includes this remark: The plane is the only surface which contains at least three distinct lines through each of its points. I'd like to see a reference or proof for this fact. I assume that the ""surfaces"" we consider in this proposition are two-dimensional smooth submanifold of $\Bbb R^3$. This may also answer this question .",,"['differential-geometry', 'reference-request', 'smooth-manifolds', 'surfaces']"
76,Dimensions of immersions vs embeddings,Dimensions of immersions vs embeddings,,"Let's say that you have a manifold which you know can be immersed in $\mathbb{R}^n$. Is there a $k$ such that you can say, for sure, that the manifold is embedded in $\mathbb{R}^{n+k}$? I imagine that there is and that this is common knowmedge, but cursory googling did not throw up anything. Thank you in advance!!","Let's say that you have a manifold which you know can be immersed in $\mathbb{R}^n$. Is there a $k$ such that you can say, for sure, that the manifold is embedded in $\mathbb{R}^{n+k}$? I imagine that there is and that this is common knowmedge, but cursory googling did not throw up anything. Thank you in advance!!",,['differential-geometry']
77,Helmholtz decomposition of a vector field on surface,Helmholtz decomposition of a vector field on surface,,"Does it make sense to do Helmholtz decomposition of a vector field defined on a surface or on a manifold? I am mostly interested in the surface case. I was trying to find a reference for this and found only a handful of them mostly from electromagnetics literature. e.g. Scharstein, Robert W. ""Helmholtz decomposition of surface electric current in electromagnetic scattering problems."" System Theory, 1991. Proceedings., Twenty-Third Southeastern Symposium on. IEEE. On the related note, is there a well defined curl operator for a (tangential) vector field defined on a surface?","Does it make sense to do Helmholtz decomposition of a vector field defined on a surface or on a manifold? I am mostly interested in the surface case. I was trying to find a reference for this and found only a handful of them mostly from electromagnetics literature. e.g. Scharstein, Robert W. ""Helmholtz decomposition of surface electric current in electromagnetic scattering problems."" System Theory, 1991. Proceedings., Twenty-Third Southeastern Symposium on. IEEE. On the related note, is there a well defined curl operator for a (tangential) vector field defined on a surface?",,"['differential-geometry', 'vector-analysis', 'mathematical-physics', 'electromagnetism']"
78,Induced bilinear form on exterior powers - Towards a global Hodge Star Operator,Induced bilinear form on exterior powers - Towards a global Hodge Star Operator,,"In all constructions of the hodge star operator I've seen so far there was a part where an inner product on the exterior power of the tangent space was defined by the ungodly local formula: $$\langle v_1 \wedge \cdots \wedge v_k , w_1 \wedge \cdots \wedge w_k \rangle = det(\langle v_i,w_j \rangle)$$ Although i've been able to verify that it is in fact an inner product I have a terrible aversion to such ad hoc constructions. Therefore i was led to this: Given a projective (hence locally free) $R$-module $M$ and a nondegenrate bilinear form $g: M \times M \to R$, i.e. one that gives an isomorphism: $$\varphi: M \to M^* , \varphi: m \to g(-,m)$$ By the non degeneracy, $g$ extends naturally to $M^*$ by: $g(g(-,m_1),g(-,m_2))=g(m_1,m_2)$. What's the canonical way to extend $g$ to the exterior powers $\bigwedge^k M^*$?","In all constructions of the hodge star operator I've seen so far there was a part where an inner product on the exterior power of the tangent space was defined by the ungodly local formula: $$\langle v_1 \wedge \cdots \wedge v_k , w_1 \wedge \cdots \wedge w_k \rangle = det(\langle v_i,w_j \rangle)$$ Although i've been able to verify that it is in fact an inner product I have a terrible aversion to such ad hoc constructions. Therefore i was led to this: Given a projective (hence locally free) $R$-module $M$ and a nondegenrate bilinear form $g: M \times M \to R$, i.e. one that gives an isomorphism: $$\varphi: M \to M^* , \varphi: m \to g(-,m)$$ By the non degeneracy, $g$ extends naturally to $M^*$ by: $g(g(-,m_1),g(-,m_2))=g(m_1,m_2)$. What's the canonical way to extend $g$ to the exterior powers $\bigwedge^k M^*$?",,"['differential-geometry', 'commutative-algebra', 'differential-forms', 'hodge-theory']"
79,Find the interior product of a basic p-form $\alpha = dx_1 \wedge dx_2 \wedge \ldots \wedge dx_p$ and a vector field $X$,Find the interior product of a basic p-form  and a vector field,\alpha = dx_1 \wedge dx_2 \wedge \ldots \wedge dx_p X,"I'm reading Differentiable Manifolds by Nigel Hitchin, that is, his class notes for an Oxford course freely available here . In particular, I'm trying to understand the interior product on manifolds, and how he works out his example. So the example given is of a basic p-form $\alpha = dx_1 \wedge dx_2 \wedge \ldots \wedge dx_p$ and a vector field $X = \sum_{i}a_i \frac{\partial}{\partial x_i}$. It is then stated that the interior product is given by $$i_{X}\alpha = a_1 dx_2 \wedge \ldots \wedge dx_p - a_2dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots$$ Can anyone help me understand how one comes to this conclusion? In the proposition prior to the example, given a vector field $X$ on a manifold $M$, the interior product is characterized as a linear map $i_X: \Omega^p(M) \to \Omega^{p-1}(M)$ s.t. $i_Xdf = X(f)$ and $i_X(\alpha \wedge \beta) = i_X \alpha \wedge \beta + (-1)^p \alpha \wedge i_X \beta$ for $\alpha \in \Omega^p(M)$. Based on this definition I was looking to find a $p-1$-form $\beta$ such that $$X(\beta) = a_1 dx_2 \wedge \ldots \wedge dx_p - a_2dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots,$$ so kind of an ""antiderivative"". To me it looks like $$\beta = x_1 dx_2 \wedge dx_3 \wedge \ldots dx_p + x_2 dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots + x_p dx_1 \wedge \ldots \wedge dx_{p-1}$$ would work, but then $d \beta = p dx_1 \wedge \ldots \wedge dx_p = p \alpha$, isn't it? So if that was my $\beta$, then I wouldn't get the connection between $df$ and $f$ in the first property of $i_X$. Anyway, help here would be greatly appreciated, since I really can't seem to wrap my head around this one. edit: OK, so I've been struggling with this for hours, but minutes after posting I think I'm starting to get it. I think that in order to obtain the expression I can just split $\alpha = \alpha_0 \wedge \alpha_1$, where $\alpha_0 = dx_1$ and $\alpha_1 = dx_2 \wedge \ldots dx_p$. Then I can apply the second property of $i_X$ along with the fact that $i_X(dx_j) = X(x_j) = a_j$. Proceeding inductively I would indeed then get the desired result. Is this the correct way of going about it? Or is there an easier and more straightforward way of doing it?","I'm reading Differentiable Manifolds by Nigel Hitchin, that is, his class notes for an Oxford course freely available here . In particular, I'm trying to understand the interior product on manifolds, and how he works out his example. So the example given is of a basic p-form $\alpha = dx_1 \wedge dx_2 \wedge \ldots \wedge dx_p$ and a vector field $X = \sum_{i}a_i \frac{\partial}{\partial x_i}$. It is then stated that the interior product is given by $$i_{X}\alpha = a_1 dx_2 \wedge \ldots \wedge dx_p - a_2dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots$$ Can anyone help me understand how one comes to this conclusion? In the proposition prior to the example, given a vector field $X$ on a manifold $M$, the interior product is characterized as a linear map $i_X: \Omega^p(M) \to \Omega^{p-1}(M)$ s.t. $i_Xdf = X(f)$ and $i_X(\alpha \wedge \beta) = i_X \alpha \wedge \beta + (-1)^p \alpha \wedge i_X \beta$ for $\alpha \in \Omega^p(M)$. Based on this definition I was looking to find a $p-1$-form $\beta$ such that $$X(\beta) = a_1 dx_2 \wedge \ldots \wedge dx_p - a_2dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots,$$ so kind of an ""antiderivative"". To me it looks like $$\beta = x_1 dx_2 \wedge dx_3 \wedge \ldots dx_p + x_2 dx_1 \wedge dx_3 \wedge \ldots \wedge dx_p + \ldots + x_p dx_1 \wedge \ldots \wedge dx_{p-1}$$ would work, but then $d \beta = p dx_1 \wedge \ldots \wedge dx_p = p \alpha$, isn't it? So if that was my $\beta$, then I wouldn't get the connection between $df$ and $f$ in the first property of $i_X$. Anyway, help here would be greatly appreciated, since I really can't seem to wrap my head around this one. edit: OK, so I've been struggling with this for hours, but minutes after posting I think I'm starting to get it. I think that in order to obtain the expression I can just split $\alpha = \alpha_0 \wedge \alpha_1$, where $\alpha_0 = dx_1$ and $\alpha_1 = dx_2 \wedge \ldots dx_p$. Then I can apply the second property of $i_X$ along with the fact that $i_X(dx_j) = X(x_j) = a_j$. Proceeding inductively I would indeed then get the desired result. Is this the correct way of going about it? Or is there an easier and more straightforward way of doing it?",,"['differential-geometry', 'manifolds', 'differential-forms', 'smooth-manifolds']"
80,basic question about the definition of orientability,basic question about the definition of orientability,,"I am a non-math major student who just started learning differential geometries. Very hard for me but my research needs it. I have trouble understanding the definition of orientability. Why is it related to the determinant of the Jacobian matrix of the transformation of two charts? I just can't figure out what the determinant represents here. The definition is:  We say that an atlas $(U_i,ϕ_i)$ is oriented if the jacobian of the transformation between two charts at the intersection is positive. (i.e. $\det\operatorname{Jac}ϕ_j∘ϕ^{−1}_i>0$). Thank you!","I am a non-math major student who just started learning differential geometries. Very hard for me but my research needs it. I have trouble understanding the definition of orientability. Why is it related to the determinant of the Jacobian matrix of the transformation of two charts? I just can't figure out what the determinant represents here. The definition is:  We say that an atlas $(U_i,ϕ_i)$ is oriented if the jacobian of the transformation between two charts at the intersection is positive. (i.e. $\det\operatorname{Jac}ϕ_j∘ϕ^{−1}_i>0$). Thank you!",,"['differential-geometry', 'differential-topology']"
81,Differential geometry for nonlinear control theory,Differential geometry for nonlinear control theory,,"I am an engineering student and I need to acquire a good understanding of some notions in differential geometry such as manifolds, diffeomorphisms, distributions, etc. I can't find a proper starting path. How should I start to learn the subject from basics? I need the material to study geometric nonlinear control theory. Any further suggestions are appreciated.","I am an engineering student and I need to acquire a good understanding of some notions in differential geometry such as manifolds, diffeomorphisms, distributions, etc. I can't find a proper starting path. How should I start to learn the subject from basics? I need the material to study geometric nonlinear control theory. Any further suggestions are appreciated.",,"['differential-geometry', 'reference-request', 'control-theory']"
82,What is the difference between Nakano Postivity and Griffiths Positivity of Hermitian vector bundles?,What is the difference between Nakano Postivity and Griffiths Positivity of Hermitian vector bundles?,,"I am currently reading ""Complex Differential Geometry"" by FY Zheng on the curvature of Hermitian vector bundles. In section 7.5, he described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be positively curved or Griffiths positive if $$\sqrt{-1}\Theta_{u\bar u}(X,\bar X) >0 \Longleftrightarrow R_{X\bar X u \bar u} >0$$ for any nonzero $(1,0)$ tangent vector $X$ of $M$ and nonvanishing section $u$ of the vector bundle $E$. On the other hand, he described a stronger condition of positivity: He described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be Nakano positive if $\sqrt{-1}Q(\xi, \xi)>0$, where $\xi$ is a nowhere vanishing section of $E \otimes \overline{TM}$, and $Q$ is the Hermitian bilinear form defined on $E \otimes \overline{TM}$ by \begin{equation}Q(u\otimes \bar X, v \otimes \bar Y)=R_{Y\bar X u \bar v} \; \; \; \; (*) \end{equation} He then says that Nakano Positivity implies Griffiths Positivity since ""$R_{X\bar X u \bar u}$ is just the restriction of $Q$ along the diagonalizable element, i.e. elements of the form $u \otimes \bar X$."" My confusion is in $(*)$. If $\xi$ is a section of $E \otimes \overline{TM}$, then isn't $\xi$ of the form $\xi=u \otimes \bar X$? This would yield that $$Q(\xi, \xi)=Q(u\otimes \bar X, u\otimes \bar X)=R_{X\bar X u \bar u}>0$$ which is the same definition as Griffiths Positivity. Am I getting my wires crossed with certain definitions?","I am currently reading ""Complex Differential Geometry"" by FY Zheng on the curvature of Hermitian vector bundles. In section 7.5, he described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be positively curved or Griffiths positive if $$\sqrt{-1}\Theta_{u\bar u}(X,\bar X) >0 \Longleftrightarrow R_{X\bar X u \bar u} >0$$ for any nonzero $(1,0)$ tangent vector $X$ of $M$ and nonvanishing section $u$ of the vector bundle $E$. On the other hand, he described a stronger condition of positivity: He described a Hermitian vector bundle $(E,h)$ over a complex manifold $M$ to be Nakano positive if $\sqrt{-1}Q(\xi, \xi)>0$, where $\xi$ is a nowhere vanishing section of $E \otimes \overline{TM}$, and $Q$ is the Hermitian bilinear form defined on $E \otimes \overline{TM}$ by \begin{equation}Q(u\otimes \bar X, v \otimes \bar Y)=R_{Y\bar X u \bar v} \; \; \; \; (*) \end{equation} He then says that Nakano Positivity implies Griffiths Positivity since ""$R_{X\bar X u \bar u}$ is just the restriction of $Q$ along the diagonalizable element, i.e. elements of the form $u \otimes \bar X$."" My confusion is in $(*)$. If $\xi$ is a section of $E \otimes \overline{TM}$, then isn't $\xi$ of the form $\xi=u \otimes \bar X$? This would yield that $$Q(\xi, \xi)=Q(u\otimes \bar X, u\otimes \bar X)=R_{X\bar X u \bar u}>0$$ which is the same definition as Griffiths Positivity. Am I getting my wires crossed with certain definitions?",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry', 'kahler-manifolds']"
83,The kernel of a differential one-form,The kernel of a differential one-form,,"I'm thinking about the kernel of a differential one-form $\theta\in\Lambda^{1}(M)$: $$ Ker(\theta):=\left\{X\in\mathfrak{X}(M) \;|\; \theta(X)=0\right\} $$ Now suppose $X\in Ker(\theta)$, then is $fX$, with $f$ a function on $M$, in $Ker(\theta)$? Somewhat naively I think it is, in fact: $$ \theta(fX)=f\theta(X)=0 $$ Is it right? More specifically is $Ker(\theta)$ a real vector space or a real module over the functions on $M$? My question arises because I need to understand the relationship between the foliation associated to $\theta$ and $Ker(\theta)$.","I'm thinking about the kernel of a differential one-form $\theta\in\Lambda^{1}(M)$: $$ Ker(\theta):=\left\{X\in\mathfrak{X}(M) \;|\; \theta(X)=0\right\} $$ Now suppose $X\in Ker(\theta)$, then is $fX$, with $f$ a function on $M$, in $Ker(\theta)$? Somewhat naively I think it is, in fact: $$ \theta(fX)=f\theta(X)=0 $$ Is it right? More specifically is $Ker(\theta)$ a real vector space or a real module over the functions on $M$? My question arises because I need to understand the relationship between the foliation associated to $\theta$ and $Ker(\theta)$.",,"['differential-geometry', 'differential-forms']"
84,Second fundamental form without orientability?,Second fundamental form without orientability?,,"Let $F$ be a $C^2$-hypersurface (or $n$-manifold) embedded in $\mathbb{R}^{n+1}$. Suppose $F$ is not orientable. Since I cannot choose a continuous global normal field, what consequences does this have for the second fundamental form? Specifically, if I start computing the mean curvature or Gauss curvature as functions on $F$, do I have no hope for continuity for these functions? Thank you!","Let $F$ be a $C^2$-hypersurface (or $n$-manifold) embedded in $\mathbb{R}^{n+1}$. Suppose $F$ is not orientable. Since I cannot choose a continuous global normal field, what consequences does this have for the second fundamental form? Specifically, if I start computing the mean curvature or Gauss curvature as functions on $F$, do I have no hope for continuity for these functions? Thank you!",,['differential-geometry']
85,De Rham cohomology of $T^*\mathbb{CP}^n$,De Rham cohomology of,T^*\mathbb{CP}^n,"I am a bit rusty on my de Rham cohomology, and I'm hoping that someone here could help me. I want to find the cohomology of $T^*\mathbb{CP}^n$ (seen as a real manifold). Now, this should be equal to the cohomology of $\mathbb{CP}^n$ since the two are homotopic (by homotopy of each fibre with a point), thus the problem reduces to the computation of $H^\bullet(\mathbb{CP}^n)$. How can I proceed to find it? Would something as the third possibility proposed in this answer work (by taking $G=\mathbb{C}^*$ acting on $\mathbb{C}^{n+1}$)?","I am a bit rusty on my de Rham cohomology, and I'm hoping that someone here could help me. I want to find the cohomology of $T^*\mathbb{CP}^n$ (seen as a real manifold). Now, this should be equal to the cohomology of $\mathbb{CP}^n$ since the two are homotopic (by homotopy of each fibre with a point), thus the problem reduces to the computation of $H^\bullet(\mathbb{CP}^n)$. How can I proceed to find it? Would something as the third possibility proposed in this answer work (by taking $G=\mathbb{C}^*$ acting on $\mathbb{C}^{n+1}$)?",,"['differential-geometry', 'algebraic-topology', 'homology-cohomology']"
86,Proving that Hermitian Metric yields Hermitian Structure on Complex Manifold,Proving that Hermitian Metric yields Hermitian Structure on Complex Manifold,,"Let $g$ be a Riemannian metric on an almost complex manifold $(M,J)$. Suppose $g$ is Hermitian in the sense that $$g(JX,JY) = g(X,Y)$$ Let $\Omega$ be the associated fundamental (Kahler) form $$\Omega(X,Y) = g(JX,Y)$$ We may extend $g$ and $\Omega$ complex linearly to be defined on $TM^{\mathbb{C}}$. I've seen it written that the following defines a Hermitian structure on $M$ $$h(X,Y) = g(X,Y) - i\Omega(X,Y)$$ My question is why?! I'm assuming this is defined on $TM^\mathbb{C}$: am I correct? How does it relate to the ""standard"" Hermitian structure on the holomorphic bundle $TM^+$ given by $$h^+(X,Y) = g(X,\overline{Y})\textrm{?}$$ Attempted argument We want to show $\overline{h(X,Y)}=h(Y,X)$. It's easy to prove $\overline{g(X,Y)}=g(\overline{X},\overline{Y})$. We write $$\overline{h(X,Y)} = g(\overline{X},\overline{Y}) + ig(\overline{JX},\overline{Y})$$ We'll try cases. If $X$ and $Y$ are both in $TM^+$ or $TM^-$ one can easily show $$g(X,Y) = g(\overline{X},\overline{Y})=0$$ Note : therefore this is very different from the ""standard"" Hermitian structure. By symmetry we only need try $X\in TM^+, Y\in TM^-$. Then $$\overline{h(X,Y)} = 2g(\overline{X},\overline{Y})$$ $$h(Y,X) = 2g(X,Y)$$ But these aren't equal necessarily! What on earth am I doing wrong here? It should be dead simple, but I'm just going round in circles. If someone could point out the silly mistake I'm making I'd be very grateful!","Let $g$ be a Riemannian metric on an almost complex manifold $(M,J)$. Suppose $g$ is Hermitian in the sense that $$g(JX,JY) = g(X,Y)$$ Let $\Omega$ be the associated fundamental (Kahler) form $$\Omega(X,Y) = g(JX,Y)$$ We may extend $g$ and $\Omega$ complex linearly to be defined on $TM^{\mathbb{C}}$. I've seen it written that the following defines a Hermitian structure on $M$ $$h(X,Y) = g(X,Y) - i\Omega(X,Y)$$ My question is why?! I'm assuming this is defined on $TM^\mathbb{C}$: am I correct? How does it relate to the ""standard"" Hermitian structure on the holomorphic bundle $TM^+$ given by $$h^+(X,Y) = g(X,\overline{Y})\textrm{?}$$ Attempted argument We want to show $\overline{h(X,Y)}=h(Y,X)$. It's easy to prove $\overline{g(X,Y)}=g(\overline{X},\overline{Y})$. We write $$\overline{h(X,Y)} = g(\overline{X},\overline{Y}) + ig(\overline{JX},\overline{Y})$$ We'll try cases. If $X$ and $Y$ are both in $TM^+$ or $TM^-$ one can easily show $$g(X,Y) = g(\overline{X},\overline{Y})=0$$ Note : therefore this is very different from the ""standard"" Hermitian structure. By symmetry we only need try $X\in TM^+, Y\in TM^-$. Then $$\overline{h(X,Y)} = 2g(\overline{X},\overline{Y})$$ $$h(Y,X) = 2g(X,Y)$$ But these aren't equal necessarily! What on earth am I doing wrong here? It should be dead simple, but I'm just going round in circles. If someone could point out the silly mistake I'm making I'd be very grateful!",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'complex-geometry']"
87,Parallel Transport along a curve,Parallel Transport along a curve,,"We had this homework assignment for our geometry course, and we couldn't figure it out, any ideas on how to do this: Consider the Poincare model of Lobachevsky plane, $H^2=\left\lbrace{  (x,y):\quad x \in \mathbb{R},  \quad y > 0,\quad  dl^2 = (dx^2 + dy^2)/y^2  }\right\rbrace$ Show that in the course of parallel transport along the curve $\gamma = \left\lbrace x(t) = t,  y = y_0 = \text{constant} > 0 \right\rbrace $, vectors rotate uniformly with angular velocity $1/y_0$.","We had this homework assignment for our geometry course, and we couldn't figure it out, any ideas on how to do this: Consider the Poincare model of Lobachevsky plane, $H^2=\left\lbrace{  (x,y):\quad x \in \mathbb{R},  \quad y > 0,\quad  dl^2 = (dx^2 + dy^2)/y^2  }\right\rbrace$ Show that in the course of parallel transport along the curve $\gamma = \left\lbrace x(t) = t,  y = y_0 = \text{constant} > 0 \right\rbrace $, vectors rotate uniformly with angular velocity $1/y_0$.",,"['differential-geometry', 'tensors']"
88,Is the set of points in $\mathbb R^n$ with $\sum_{j=1}^n x_j^k = 0$ a submanifold?,Is the set of points in  with  a submanifold?,\mathbb R^n \sum_{j=1}^n x_j^k = 0,"Consider the set $$A:= \{x\in \mathbb R^n :\sum_{j=1}^n x_j^k = 0\}$$ for $k$ an odd integer. Is this a submanifold of $\mathbb R^n$ for every $n$? For $n=1$, it is just 0; for $n = 2$, it is the anti-diagonal $\{(x_1 , -x_1) : x_1 \in \mathbb R\}$, which is a submanifold. However, I cannot find a way to determine this in higher dimensions. Any suggestions?","Consider the set $$A:= \{x\in \mathbb R^n :\sum_{j=1}^n x_j^k = 0\}$$ for $k$ an odd integer. Is this a submanifold of $\mathbb R^n$ for every $n$? For $n=1$, it is just 0; for $n = 2$, it is the anti-diagonal $\{(x_1 , -x_1) : x_1 \in \mathbb R\}$, which is a submanifold. However, I cannot find a way to determine this in higher dimensions. Any suggestions?",,['differential-geometry']
89,Dirac Operators on $S^1$,Dirac Operators on,S^1,"I am trying to understand the Dirac operators associated to the 2 spinor bundles on $S^1.$ I have been getting very confused about why one bundle has nontrivial harmonic spinors and the other doesn't.(Harmonic spinors are solutions $s$ to the equation $Ds = 0$ where $D$ is the Dirac operator and $s$ is a section.) Here is my argument (which must be wrong somewhere). We have 2 spin structures given by the connected 2-fold covering and the disconnected 2-fold covering. Since the tangent bundle $TS^1$ is trivial, we can choose the trivial connection on it given by $f \rightarrow df.$ When considered as a connection on the principal bundle of frames (also isomorphic to $S^1$), i.e. as a Lie algebra valued one form on $S^1,$ it must be the zero form. (As a quick aside, the Lie algebra of $SO(1)$ is just the $0$ Lie algebra, so it seems like there is only one connection on the tangent bundle of $S^1$ since we could only ever have the $0$-form as the connection form on our frame bundle. But this is not true, we can add a 1-form to any connection and get another connection. How can this be?) (EDIT: Answer provided by Eric: because we have implicitly reduced the structure group of the frame bundle to $SO(1),$ an $so(1)$ valued one form corresponds to a connection compatible with the given metric, and there is only one of these since the torsion of any connection on $S^1$ is zero.) Ok, so now given either spin structure, the connection must lift to the $0$ connection. Furthermore, any complex line bundle over the circle is trivial, so both cases look exactly the same, and the Dirac operator appears to be $f \rightarrow i\frac{df}{dx}.$ However, I am told that in the case of the connected double cover we should have an additional condition on our $f,$ namely that it should satisfy $f(-x) = -f(x).$ Where have I gone wrong? (2nd EDIT) I think I know where my confusion stems from. Given a spin structure $P$ on a manifold $M^n$ we can identify sections of the spinor bundle with smooth maps $f: P \rightarrow \mathbf{C}^n$ such that $f(pg) = g \cdot f(p)$ as follows. Take any discontinuous section $s: M \rightarrow P.$ This gives a section $t:M \rightarrow P \times_{Spin(n)} \mathbf{C}^n$ of the spinor bundle by the formula $t(m) = [s(m), f \circ s(m)],$ and by the compatibility condition on $f$ this is independent of the choice of section $s.$ It is via this identification that I understand how sections of the spinor bundle for the connected double cover must be functions $f: S^1 \rightarrow \mathbf{C}$ such that $f(-x) = f(x).$ And, as luck would have it, in this case the Spin structure on $S^1$ is itself, as a space, $S^1,$ so the description of the Dirac operator translates easily via this identification. But in the case of $S^2,$ for example, sections can be identified with maps from $S^3$ to $\mathbf{C}^2$ but the local description of the Dirac operator I see in books (like Lawson/Michelson's Spin Geometry) tells me how to differentiate maps $U \subset S^2 \rightarrow \mathbf{C}^2$ in a trivializing nbhd $U.$ How do I translate the local description of the Dirac operator so that it tells me how to differentiate the map $S^3 \rightarrow \mathbf{C}^2$?","I am trying to understand the Dirac operators associated to the 2 spinor bundles on $S^1.$ I have been getting very confused about why one bundle has nontrivial harmonic spinors and the other doesn't.(Harmonic spinors are solutions $s$ to the equation $Ds = 0$ where $D$ is the Dirac operator and $s$ is a section.) Here is my argument (which must be wrong somewhere). We have 2 spin structures given by the connected 2-fold covering and the disconnected 2-fold covering. Since the tangent bundle $TS^1$ is trivial, we can choose the trivial connection on it given by $f \rightarrow df.$ When considered as a connection on the principal bundle of frames (also isomorphic to $S^1$), i.e. as a Lie algebra valued one form on $S^1,$ it must be the zero form. (As a quick aside, the Lie algebra of $SO(1)$ is just the $0$ Lie algebra, so it seems like there is only one connection on the tangent bundle of $S^1$ since we could only ever have the $0$-form as the connection form on our frame bundle. But this is not true, we can add a 1-form to any connection and get another connection. How can this be?) (EDIT: Answer provided by Eric: because we have implicitly reduced the structure group of the frame bundle to $SO(1),$ an $so(1)$ valued one form corresponds to a connection compatible with the given metric, and there is only one of these since the torsion of any connection on $S^1$ is zero.) Ok, so now given either spin structure, the connection must lift to the $0$ connection. Furthermore, any complex line bundle over the circle is trivial, so both cases look exactly the same, and the Dirac operator appears to be $f \rightarrow i\frac{df}{dx}.$ However, I am told that in the case of the connected double cover we should have an additional condition on our $f,$ namely that it should satisfy $f(-x) = -f(x).$ Where have I gone wrong? (2nd EDIT) I think I know where my confusion stems from. Given a spin structure $P$ on a manifold $M^n$ we can identify sections of the spinor bundle with smooth maps $f: P \rightarrow \mathbf{C}^n$ such that $f(pg) = g \cdot f(p)$ as follows. Take any discontinuous section $s: M \rightarrow P.$ This gives a section $t:M \rightarrow P \times_{Spin(n)} \mathbf{C}^n$ of the spinor bundle by the formula $t(m) = [s(m), f \circ s(m)],$ and by the compatibility condition on $f$ this is independent of the choice of section $s.$ It is via this identification that I understand how sections of the spinor bundle for the connected double cover must be functions $f: S^1 \rightarrow \mathbf{C}$ such that $f(-x) = f(x).$ And, as luck would have it, in this case the Spin structure on $S^1$ is itself, as a space, $S^1,$ so the description of the Dirac operator translates easily via this identification. But in the case of $S^2,$ for example, sections can be identified with maps from $S^3$ to $\mathbf{C}^2$ but the local description of the Dirac operator I see in books (like Lawson/Michelson's Spin Geometry) tells me how to differentiate maps $U \subset S^2 \rightarrow \mathbf{C}^2$ in a trivializing nbhd $U.$ How do I translate the local description of the Dirac operator so that it tells me how to differentiate the map $S^3 \rightarrow \mathbf{C}^2$?",,"['differential-geometry', 'algebraic-topology', 'riemannian-geometry']"
90,$C_0$ Convergence of Metrics under Ricci Flow when $\chi(M) = 0$.,Convergence of Metrics under Ricci Flow when .,C_0 \chi(M) = 0,"I am a beginning graduate student, and I am trying to learn basic aspects of Ricci Flow via the uniformization theorem for compact surfaces.  I am reading Chow and Knopf's introductory book as well as Hamilton's original paper on the subject.  I have a question regarding the following theorem: Theorem : If $(M^2, g_0)$ is a compact surface with metric $g_0$, then a 1-parameter family of metrics $g(t)$ with $g(0) = g_0$ under the Normalized Ricci-Flow equation: $$ \frac{\partial g}{\partial t} = - (R_g - r) g $$ exists for all time and converges in every $C^k$-norm to a metric of constant scalar curvature.  Here $R$ is the scalar curvature and $r = \int_M R_g d\mu_{g}/\int_{M}d \mu_{g} $ is the average scalar curvature.  $r$ is constant by the Gauss-Bonnet Theorem. The proof is divided into three cases, each of increasing difficulty: $r < 0$, $r = 0$, and $r>0$.  I have a question only about the $r = 0$ case.  The idea for both $r = 0$ and $r<0$ is to apply the maximum principle to quantities related to gradient-ricci solitons. In Knopf and Chow's book, they prove that the metrics are equivalent for all time when $r \leq 0$ (Proposition 5.15).  Then they say that it is enough to that $R$ and all of it's derivatives go to zero as $t \to \infty$.  However, they show that $|R| \leq C/(1+t)$, where $C>0$.  This function is not in $L^1([0, \infty))$ and the hypothesis: $$ \int_0^\infty \left|\frac{\partial g}{\partial t}\right|_{g(t)} dt < \infty $$ does not apply (See Lemma 6.49 in Chow and Knopf).  This hypothesis is used to show the metrics converge uniformly. On the other hand Hamilton's paper, he shows that integral bounds of $R$ and its first two derivatives decay exponentially with time.  Then he uses a Sobolev Inequality to get that $|R_{\max}|$ decays expontially, too.  Then the hypothesis above is satisfied by the Normalized-Ricci Flow equation. Question: Is there a basic fact that Chow and Knopf are exploiting that implies that $g$ converges in $C_0$?  They are excellent at including relevant details and have a good view of this subject, so I am eager to know how they are thinking about this.","I am a beginning graduate student, and I am trying to learn basic aspects of Ricci Flow via the uniformization theorem for compact surfaces.  I am reading Chow and Knopf's introductory book as well as Hamilton's original paper on the subject.  I have a question regarding the following theorem: Theorem : If $(M^2, g_0)$ is a compact surface with metric $g_0$, then a 1-parameter family of metrics $g(t)$ with $g(0) = g_0$ under the Normalized Ricci-Flow equation: $$ \frac{\partial g}{\partial t} = - (R_g - r) g $$ exists for all time and converges in every $C^k$-norm to a metric of constant scalar curvature.  Here $R$ is the scalar curvature and $r = \int_M R_g d\mu_{g}/\int_{M}d \mu_{g} $ is the average scalar curvature.  $r$ is constant by the Gauss-Bonnet Theorem. The proof is divided into three cases, each of increasing difficulty: $r < 0$, $r = 0$, and $r>0$.  I have a question only about the $r = 0$ case.  The idea for both $r = 0$ and $r<0$ is to apply the maximum principle to quantities related to gradient-ricci solitons. In Knopf and Chow's book, they prove that the metrics are equivalent for all time when $r \leq 0$ (Proposition 5.15).  Then they say that it is enough to that $R$ and all of it's derivatives go to zero as $t \to \infty$.  However, they show that $|R| \leq C/(1+t)$, where $C>0$.  This function is not in $L^1([0, \infty))$ and the hypothesis: $$ \int_0^\infty \left|\frac{\partial g}{\partial t}\right|_{g(t)} dt < \infty $$ does not apply (See Lemma 6.49 in Chow and Knopf).  This hypothesis is used to show the metrics converge uniformly. On the other hand Hamilton's paper, he shows that integral bounds of $R$ and its first two derivatives decay exponentially with time.  Then he uses a Sobolev Inequality to get that $|R_{\max}|$ decays expontially, too.  Then the hypothesis above is satisfied by the Normalized-Ricci Flow equation. Question: Is there a basic fact that Chow and Knopf are exploiting that implies that $g$ converges in $C_0$?  They are excellent at including relevant details and have a good view of this subject, so I am eager to know how they are thinking about this.",,"['differential-geometry', 'ricci-flow']"
91,Commutation formula for covariant derivative,Commutation formula for covariant derivative,,"Suppose $\nabla$ is the Levi-Civita connection on Riemannian manifold $M$. $X$ be a vector fields on $M$ defined by $X=\nabla r$ where $r$ is the distance function to a fixed point in $M$. $\{e_1, \cdots, e_n\}$ be local orthnormal frame fields. We want to calculate $(|\nabla r|^2)_{kk}=\nabla_{e_k}\nabla_{e_k}|\nabla r|^2$. Let $$\nabla r=\sum r_i e_i$$ so $r_i=\nabla_{e_i}r$. The standard calculation for tensor yields: $$(|X|^2)_{kk}=(\sum r_i^2)_{kk}\\ =2(\sum r_i r_{ik})_{k} \\ =2\sum r_{ik}r_{ik}+2\sum r_i r_{ikk} $$ My question is, how to switch the order of partial derivatives $r_{ikk}$ to $r_{kki}$. I know some curvature terms should apear, but I am very confused by this calculation. My main concern is $r_i$ should be function, when exchange the partial derivatives Lie bracket will apear, how come the curvature term apears? Anyone can help me with this basic calculations?","Suppose $\nabla$ is the Levi-Civita connection on Riemannian manifold $M$. $X$ be a vector fields on $M$ defined by $X=\nabla r$ where $r$ is the distance function to a fixed point in $M$. $\{e_1, \cdots, e_n\}$ be local orthnormal frame fields. We want to calculate $(|\nabla r|^2)_{kk}=\nabla_{e_k}\nabla_{e_k}|\nabla r|^2$. Let $$\nabla r=\sum r_i e_i$$ so $r_i=\nabla_{e_i}r$. The standard calculation for tensor yields: $$(|X|^2)_{kk}=(\sum r_i^2)_{kk}\\ =2(\sum r_i r_{ik})_{k} \\ =2\sum r_{ik}r_{ik}+2\sum r_i r_{ikk} $$ My question is, how to switch the order of partial derivatives $r_{ikk}$ to $r_{kki}$. I know some curvature terms should apear, but I am very confused by this calculation. My main concern is $r_i$ should be function, when exchange the partial derivatives Lie bracket will apear, how come the curvature term apears? Anyone can help me with this basic calculations?",,"['differential-geometry', 'riemannian-geometry']"
92,Why compact surfaces can be regarded as region without boundary?,Why compact surfaces can be regarded as region without boundary?,,"I have been reading DoCarmo and feel quite confused by that he mentioned several times that compact surfaces can be regarded as regions without boundary, which is used in the proof of a corollary of Gauss-Bonnet and several other places. But I can't figure out why this is the case. Thanks!","I have been reading DoCarmo and feel quite confused by that he mentioned several times that compact surfaces can be regarded as regions without boundary, which is used in the proof of a corollary of Gauss-Bonnet and several other places. But I can't figure out why this is the case. Thanks!",,['differential-geometry']
93,Equivalent definitions of connection on a vector field,Equivalent definitions of connection on a vector field,,"Let $X$ be a nice variety resp. a manifold over the complex numbers. One defines a connection on a vector bundle $V$ on over $X$ as a $\mathbb C-$linear sheaf homomorphism $\nabla : V\rightarrow V\otimes \Omega^1$ which satisfies the Leibniz rule. I have read that this is equivalent to giving for each local vector field $Y\in Der_{\mathbb C}(\mathcal O_X)$ a $\mathbb C-$ linear sheaf homomorphism $\nabla_Y : V \rightarrow V$ with (1) Leibniz rule (2) $\nabla_{fY+gZ}=f\nabla_Y+g\nabla_Z$ for $f,g \in \mathcal O_X$ and $Y,Z$ local vector fields. I can prove that each connection in the first sense implies a connection in the second sense. But I don't see how you get from the datum of thhe $\nabla_Y$ a connection in the first sense. Remark: By a vector field I understand a linear derivation of the structure sheaf into itself.","Let $X$ be a nice variety resp. a manifold over the complex numbers. One defines a connection on a vector bundle $V$ on over $X$ as a $\mathbb C-$linear sheaf homomorphism $\nabla : V\rightarrow V\otimes \Omega^1$ which satisfies the Leibniz rule. I have read that this is equivalent to giving for each local vector field $Y\in Der_{\mathbb C}(\mathcal O_X)$ a $\mathbb C-$ linear sheaf homomorphism $\nabla_Y : V \rightarrow V$ with (1) Leibniz rule (2) $\nabla_{fY+gZ}=f\nabla_Y+g\nabla_Z$ for $f,g \in \mathcal O_X$ and $Y,Z$ local vector fields. I can prove that each connection in the first sense implies a connection in the second sense. But I don't see how you get from the datum of thhe $\nabla_Y$ a connection in the first sense. Remark: By a vector field I understand a linear derivation of the structure sheaf into itself.",,"['algebraic-geometry', 'differential-geometry']"
94,Equivalent definitions of differential map,Equivalent definitions of differential map,,"Let $f:M\rightarrow N$ be a smooth map between smooth manifolds, let $p\in M$ and $v\in T_{p}M$. Two different definitions of differential maps on tangent space: let $\gamma$ be a smooth curve on $M$ representing $v$ ($\gamma(0)=p,\gamma'(0)=v)$ and define $df_{p}(v)=(f\circ v)'(0)$. Second definition: let $\mathcal{D}$ be a derivation at $p$, $g:N\rightarrow\mathbb{R}$ be a smooth function, then define $df_{p}(\mathcal{D})(g)=\mathcal{D}(g\circ f)$. We want to show that the two definitions of $df_{p}$ coincide. Consider the matrix representation of the second definition of $df_{p}$ in local coordinates, this is: $$\left[ df_{p}=\frac{\partial\hat{f}^{j}}{\partial x^{i}}\right]$$ where $\hat{f}$ is the coordinate representation of $f$. In the first definition, let $x_{1},\dots,x_{n}$ be local coordinates at $p$. Then, $\gamma(t)=(\gamma_{1}(t),\dots,\gamma_{n}(t))$ where $\gamma_{i}(t)=x_{i}(\gamma(t))$. The matrix representation of $df_{p}$ is:$$\left[ df_{p}=\sum_{i=1}^{n}\frac{\partial f}{\partial x^{i}}\right]$$ I might have gotten the matrix representation of $df_{p}$ in the first definition incorrectly, but of course if these matrices are the same with respect to these coordinates, this means that the two definitions are coincide. I am wondering are the steps I have done right.","Let $f:M\rightarrow N$ be a smooth map between smooth manifolds, let $p\in M$ and $v\in T_{p}M$. Two different definitions of differential maps on tangent space: let $\gamma$ be a smooth curve on $M$ representing $v$ ($\gamma(0)=p,\gamma'(0)=v)$ and define $df_{p}(v)=(f\circ v)'(0)$. Second definition: let $\mathcal{D}$ be a derivation at $p$, $g:N\rightarrow\mathbb{R}$ be a smooth function, then define $df_{p}(\mathcal{D})(g)=\mathcal{D}(g\circ f)$. We want to show that the two definitions of $df_{p}$ coincide. Consider the matrix representation of the second definition of $df_{p}$ in local coordinates, this is: $$\left[ df_{p}=\frac{\partial\hat{f}^{j}}{\partial x^{i}}\right]$$ where $\hat{f}$ is the coordinate representation of $f$. In the first definition, let $x_{1},\dots,x_{n}$ be local coordinates at $p$. Then, $\gamma(t)=(\gamma_{1}(t),\dots,\gamma_{n}(t))$ where $\gamma_{i}(t)=x_{i}(\gamma(t))$. The matrix representation of $df_{p}$ is:$$\left[ df_{p}=\sum_{i=1}^{n}\frac{\partial f}{\partial x^{i}}\right]$$ I might have gotten the matrix representation of $df_{p}$ in the first definition incorrectly, but of course if these matrices are the same with respect to these coordinates, this means that the two definitions are coincide. I am wondering are the steps I have done right.",,"['differential-geometry', 'differential-topology']"
95,The signed curvature of the Catenary,The signed curvature of the Catenary,,"Now I want to show that the signed curvature of the catenary, with parameterization $$(t,\cosh(t))$$ is $k(t)=\frac{1}{\cosh^2(t)}$ Now what I have done (and presumably went astray), is first normalize the tangent vector to $\alpha (t)=(t,\cosh(t))$, to get: $$\gamma (t)=\frac{\alpha '(t)}{|\alpha ' (t)|} = \left(\frac{1}{\cosh(t)},\tanh(t)\right).$$ And using the fact that the normal to $\gamma$ is $n(t)= \left(-\tanh(t),\frac{1}{\cosh(t)}\right)$ and that $$k(t) = \gamma '(t) \cdot n(t) ,$$ I get by inserting $$\gamma ' (t) = \left(-\frac{\sinh(t)}{\cosh^2(t)},\frac{1}{\cosh^2(t)}\right),$$ $$k(t)=\frac{1}{\cosh(t)}.$$ Where did I get it wrong? Thanks in advance.","Now I want to show that the signed curvature of the catenary, with parameterization $$(t,\cosh(t))$$ is $k(t)=\frac{1}{\cosh^2(t)}$ Now what I have done (and presumably went astray), is first normalize the tangent vector to $\alpha (t)=(t,\cosh(t))$, to get: $$\gamma (t)=\frac{\alpha '(t)}{|\alpha ' (t)|} = \left(\frac{1}{\cosh(t)},\tanh(t)\right).$$ And using the fact that the normal to $\gamma$ is $n(t)= \left(-\tanh(t),\frac{1}{\cosh(t)}\right)$ and that $$k(t) = \gamma '(t) \cdot n(t) ,$$ I get by inserting $$\gamma ' (t) = \left(-\frac{\sinh(t)}{\cosh^2(t)},\frac{1}{\cosh^2(t)}\right),$$ $$k(t)=\frac{1}{\cosh(t)}.$$ Where did I get it wrong? Thanks in advance.",,"['differential-geometry', 'plane-curves']"
96,Do we know this homogeneous space by another name?,Do we know this homogeneous space by another name?,,"Consider the homogeneous space $GL(3)/GL(2) = GL(3,\mathbb{R})/GL(2,\mathbb{R})$ where $GL(2)$ fixes the first coordinate axis (so can be identified with the subgroup of $2\times 2$ blocks sitting in the 'bottom right' corner of matrices in $GL(3)$). Is there any 'explicitly known' other homogeneous space which is isomorphic to this one? Say by using orthogonal groups? Is it some sort of Grasmannian/Stiefel manifold? Am I correct in guessing that $GL(3)/GL(2)$ has dimension 5?","Consider the homogeneous space $GL(3)/GL(2) = GL(3,\mathbb{R})/GL(2,\mathbb{R})$ where $GL(2)$ fixes the first coordinate axis (so can be identified with the subgroup of $2\times 2$ blocks sitting in the 'bottom right' corner of matrices in $GL(3)$). Is there any 'explicitly known' other homogeneous space which is isomorphic to this one? Say by using orthogonal groups? Is it some sort of Grasmannian/Stiefel manifold? Am I correct in guessing that $GL(3)/GL(2)$ has dimension 5?",,"['differential-geometry', 'lie-groups', 'manifolds']"
97,Mysterious Coordinates on $S^4$ involving Quaternions,Mysterious Coordinates on  involving Quaternions,S^4,"Let $U$ and $U'$ be $S^4 - x_N$ and $S^4 - x_S$ , respectively, where $x_N$ is the North pole and $x_S$ is the South pole. The usual stereographic projection maps $U$ into $R^4$ and $U'$ into $R^4$ . If we identify $R^4$ with the quaternions, then we can write the coordinates on $U$ as a quaternion $z$ and the coordinates on $U'$ as another quaternion $z'$ . Then, the change of coordinates between these two charts take the remarkably simple form $z'=1/z$ . This is well known, and can be found in many references. My question regards a different choice of coordinates on $S^4$ , which I found on an old paper, that unfortunately skips the details on how its constructed. The two patches $U$ and $U'$ are defined in the same way, but they are mapped to the disk $\{x \in R^4 | |x|^2 <1 \}$ , rather than the full $R^4$ . Such a region is again identified with quaternions via the usual isomorphism; let's say that the quaternion $z$ corresponds to the coordinates on $U$ and $z'$ corresponds to those on $U'$ , as before. The transition function reads: $z'= \frac{1 - ||z||}{||z||}z$ , where $||z||$ is the norm of $z$ . For reference, this question originated when reading the paper ""Homeomorphy classification of total spaces of sphere bundles over sphere"" by Tamura, page 31 (just before section 2). I tried a combination of stereographic coordinates with some conformal mapping of $R^4$ into the unit disk, but I could not obtain the transition function above. I have a feeling that it should be something simple, but I can't think of something that matches the properties that I described. Any suggestions on how these coordinates might be defined? Thanks in advance!","Let and be and , respectively, where is the North pole and is the South pole. The usual stereographic projection maps into and into . If we identify with the quaternions, then we can write the coordinates on as a quaternion and the coordinates on as another quaternion . Then, the change of coordinates between these two charts take the remarkably simple form . This is well known, and can be found in many references. My question regards a different choice of coordinates on , which I found on an old paper, that unfortunately skips the details on how its constructed. The two patches and are defined in the same way, but they are mapped to the disk , rather than the full . Such a region is again identified with quaternions via the usual isomorphism; let's say that the quaternion corresponds to the coordinates on and corresponds to those on , as before. The transition function reads: , where is the norm of . For reference, this question originated when reading the paper ""Homeomorphy classification of total spaces of sphere bundles over sphere"" by Tamura, page 31 (just before section 2). I tried a combination of stereographic coordinates with some conformal mapping of into the unit disk, but I could not obtain the transition function above. I have a feeling that it should be something simple, but I can't think of something that matches the properties that I described. Any suggestions on how these coordinates might be defined? Thanks in advance!",U U' S^4 - x_N S^4 - x_S x_N x_S U R^4 U' R^4 R^4 U z U' z' z'=1/z S^4 U U' \{x \in R^4 | |x|^2 <1 \} R^4 z U z' U' z'= \frac{1 - ||z||}{||z||}z ||z|| z R^4,"['differential-geometry', 'differential-topology', 'quaternions', 'spheres', 'spherical-coordinates']"
98,Why is integration of differential forms defined in this way?,Why is integration of differential forms defined in this way?,,"From what I can say, in most books about differential geometry and differential forms (see for example Flanders, Differential Forms with applications to the Physical Sciences ), the integral of a $p$ -differential form $\omega$ on a chain is defined as follows: one takes a simplex (or a cube) $\Delta$ in $\mathbb R^p$ and maps it into the manifold $M$ on which $\omega$ is defined, with a smooth mapping $\phi:\,\Delta\subseteq\mathbb R^p\to M$ . Then the pullback $\phi^*\omega$ is a $p$ -form on $\mathbb R^p$ which can be uniquely written as $$\phi^*\omega=A(x^1,\,x^2,\,\ldots,\,x^p)\,\mathrm dx^1\wedge\mathrm dx^2\wedge\ldots\wedge\mathrm dx^p. \label{1}\tag{1}$$ The integral is defined as $$ \int_\phi \omega=\int_\Delta A(x^1,\,x^2,\,\ldots,\,x^p)\,\mathrm dx^1\mathrm dx^2\ldots\mathrm dx^p. \label{2}\tag{2} $$ The obvious “problem” with this definition is that, at least in principle, it is dependent on a choice of coordinates. However, thanks to the change of variable formula, the invariance is ensured. Despite the fact that this definition works fine, it seems to me that the change of variable formula should be a consequence of the wedge product rules. Instead, what happens in the definition above is that the wedge product rules just “match” with the change of variable formula, making the integral well defined. Question : why don't we define the integral in an invariant way, such that the change of variable formula follows from the wedge product rules? For example, one could make a construction similar to the one used for the Riemann integral, breaking $\Delta$ into small rectangles, each corresponding to a $p$ -vector, then letting the pullback $\phi^*\omega$ act on these $p$ -vectors, then summing and taking the limit for finer and finer partitions. I know this is exactly the idea behind integration of forms, but why isn't this idea made into an explicit construction, such that the integral is already invariant from the beginning? Is there a textbook that does so? Or am I missing a step?","From what I can say, in most books about differential geometry and differential forms (see for example Flanders, Differential Forms with applications to the Physical Sciences ), the integral of a -differential form on a chain is defined as follows: one takes a simplex (or a cube) in and maps it into the manifold on which is defined, with a smooth mapping . Then the pullback is a -form on which can be uniquely written as The integral is defined as The obvious “problem” with this definition is that, at least in principle, it is dependent on a choice of coordinates. However, thanks to the change of variable formula, the invariance is ensured. Despite the fact that this definition works fine, it seems to me that the change of variable formula should be a consequence of the wedge product rules. Instead, what happens in the definition above is that the wedge product rules just “match” with the change of variable formula, making the integral well defined. Question : why don't we define the integral in an invariant way, such that the change of variable formula follows from the wedge product rules? For example, one could make a construction similar to the one used for the Riemann integral, breaking into small rectangles, each corresponding to a -vector, then letting the pullback act on these -vectors, then summing and taking the limit for finer and finer partitions. I know this is exactly the idea behind integration of forms, but why isn't this idea made into an explicit construction, such that the integral is already invariant from the beginning? Is there a textbook that does so? Or am I missing a step?","p \omega \Delta \mathbb R^p M \omega \phi:\,\Delta\subseteq\mathbb R^p\to M \phi^*\omega p \mathbb R^p \phi^*\omega=A(x^1,\,x^2,\,\ldots,\,x^p)\,\mathrm dx^1\wedge\mathrm dx^2\wedge\ldots\wedge\mathrm dx^p. \label{1}\tag{1} 
\int_\phi \omega=\int_\Delta A(x^1,\,x^2,\,\ldots,\,x^p)\,\mathrm dx^1\mathrm dx^2\ldots\mathrm dx^p. \label{2}\tag{2}
 \Delta p \phi^*\omega p","['differential-geometry', 'differential-forms']"
99,Morse functions invariant under diffeomorphisms,Morse functions invariant under diffeomorphisms,,"Let $f:M \to \mathbb{R}$ be a Morse function of a compact manifold $M$ . Assume $\sigma:M \to M$ is a diffeomorphism such that $f$ is invariant under $\sigma$ , i.e. $f(\sigma x)=f(x)$ for all $x \in M$ . I am trying to understand how $\sigma$ induces homomorphisms of the Morse homology groups $H_k(M)$ and how to describe them explicitly. If we denote the boundary maps by $\partial_k$ , the elements of $H_k(M)$ are linear combinations of cosets of the form $x+\text{im }\partial_{k+1}$ where $x$ is a critical  point of index $k$ with $x \in \ker \partial_k$ . Question: Does $\sigma$ act on $H_k(M)$ by application to representatives of the cosets? That is: Is the map $$x+\text{im }\partial_{k+1} \mapsto \sigma x+\text{im }\partial_{k+1}$$ well defined and does it extend to an automorphism of $H_k(M)$ ? I think I am able to see that $\sigma$ permutes the critical points of a fixed index. This would show that $\sigma$ is an automorphism of the Morse chain groups $C_k(M)$ . However, I don't know how to proceed. The standard approach would be to show that $\sigma$ commutes with the boundary maps $\partial_{k+1}$ but I have no ideas how to do this. I tried to analyze the action of $\sigma$ on the trajectories between critical points but up to now, this didn't result in anything useful for me. Not sure if this is a good strategy here...","Let be a Morse function of a compact manifold . Assume is a diffeomorphism such that is invariant under , i.e. for all . I am trying to understand how induces homomorphisms of the Morse homology groups and how to describe them explicitly. If we denote the boundary maps by , the elements of are linear combinations of cosets of the form where is a critical  point of index with . Question: Does act on by application to representatives of the cosets? That is: Is the map well defined and does it extend to an automorphism of ? I think I am able to see that permutes the critical points of a fixed index. This would show that is an automorphism of the Morse chain groups . However, I don't know how to proceed. The standard approach would be to show that commutes with the boundary maps but I have no ideas how to do this. I tried to analyze the action of on the trajectories between critical points but up to now, this didn't result in anything useful for me. Not sure if this is a good strategy here...",f:M \to \mathbb{R} M \sigma:M \to M f \sigma f(\sigma x)=f(x) x \in M \sigma H_k(M) \partial_k H_k(M) x+\text{im }\partial_{k+1} x k x \in \ker \partial_k \sigma H_k(M) x+\text{im }\partial_{k+1} \mapsto \sigma x+\text{im }\partial_{k+1} H_k(M) \sigma \sigma C_k(M) \sigma \partial_{k+1} \sigma,"['differential-geometry', 'homology-cohomology', 'morse-theory']"
