,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Kendall tau calculation,Kendall tau calculation,,"Can someone explain how the Kendall tau works? I can't seem to find a good explaination/tutorial/example. I've been running corr(x,y,'kendall') from Matlab's Statistics Toolbox, but other than some output, it doesn't give me any good intuition. I've been stepping through with the debugger, but it gets confusing at times. I know that for two matrices, x and y must have the same number of rows, but that's about it. Is there a simple example that will illuminate what the Kendall p-value and Kendall tau really are?","Can someone explain how the Kendall tau works? I can't seem to find a good explaination/tutorial/example. I've been running corr(x,y,'kendall') from Matlab's Statistics Toolbox, but other than some output, it doesn't give me any good intuition. I've been stepping through with the debugger, but it gets confusing at times. I know that for two matrices, x and y must have the same number of rows, but that's about it. Is there a simple example that will illuminate what the Kendall p-value and Kendall tau really are?",,"['statistics', 'matlab']"
1,"In the definition of a complete statistic, what is the expectation taken over?","In the definition of a complete statistic, what is the expectation taken over?",,"I have read lots of answers here attempting (and in my case, failing) to convey the idea of a ""complete statistic."" Even the idea of $E_{\theta}[g(T(x))] = 0$ is hard to parse.  What is the expectation taken over?  Different data?  Different values of $T$ ?  Different functions?  Different values of a given function? Different values of $\theta$ ? The binomial example would suggest it is values of $g(T(x))$ and their probabilities that are being summed over.  Is that correct? If so, is it still a function of $\theta$ ? I have Casella and am scrutinizing it along with lecture notes from a stats class online.  Any pointers to good references or explanations are welcome. EDIT to add detail . So I'm getting the impression that the space is some sort of space of functions that includes every distribution under consideration, I think.  So what else is in that space?  What isn't?  All functions?  All continuous functions? What are we trying to accomplish in that space?  What's the inner product? EDIT to add more detail . I created an example. Suppose I have two dice: one fair, and the other has even numbers twice as likely to come up as odd numbers.  So $\Theta$ consists of two possible values, call them $a$ and $b$ . Suppose $T(X)=1$ if $X$ is even, and $0$ otherwise. Suppose $U(i) = i$ for $i \leq 4, U(5)=3$ and $U(6) = 4$ . I have computed that both $T(X)$ and $U(X)$ are sufficient statistics, and $T(X)$ is a minimal sufficient statistic. So in addition to the desired general explanation, I would also like answered a more specific question, that I would like to see expressly calculated, is, ""Are either $T$ or $U$ complete?""","I have read lots of answers here attempting (and in my case, failing) to convey the idea of a ""complete statistic."" Even the idea of is hard to parse.  What is the expectation taken over?  Different data?  Different values of ?  Different functions?  Different values of a given function? Different values of ? The binomial example would suggest it is values of and their probabilities that are being summed over.  Is that correct? If so, is it still a function of ? I have Casella and am scrutinizing it along with lecture notes from a stats class online.  Any pointers to good references or explanations are welcome. EDIT to add detail . So I'm getting the impression that the space is some sort of space of functions that includes every distribution under consideration, I think.  So what else is in that space?  What isn't?  All functions?  All continuous functions? What are we trying to accomplish in that space?  What's the inner product? EDIT to add more detail . I created an example. Suppose I have two dice: one fair, and the other has even numbers twice as likely to come up as odd numbers.  So consists of two possible values, call them and . Suppose if is even, and otherwise. Suppose for and . I have computed that both and are sufficient statistics, and is a minimal sufficient statistic. So in addition to the desired general explanation, I would also like answered a more specific question, that I would like to see expressly calculated, is, ""Are either or complete?""","E_{\theta}[g(T(x))] = 0 T \theta g(T(x)) \theta \Theta a b T(X)=1 X 0 U(i) = i i \leq 4, U(5)=3 U(6) = 4 T(X) U(X) T(X) T U",['statistics']
2,Book Recommendation on Time Series Statistics,Book Recommendation on Time Series Statistics,,"Professionally I am analysing high-frequency data coming from motion sensors and alike. I would like to ""up my theoretical background game"" in this area and am therefore looking for recommendations to books about (I guess) statistics and probability theory concerning time series pehomena. Concerning my background: I hold a master's degree in theoretical mathematics (Did some Probability Theory, statistics und stochastical analysis, though it was not my focus) Any hints would be greatly appreciated. Thanks in advance!","Professionally I am analysing high-frequency data coming from motion sensors and alike. I would like to ""up my theoretical background game"" in this area and am therefore looking for recommendations to books about (I guess) statistics and probability theory concerning time series pehomena. Concerning my background: I hold a master's degree in theoretical mathematics (Did some Probability Theory, statistics und stochastical analysis, though it was not my focus) Any hints would be greatly appreciated. Thanks in advance!",,"['statistics', 'reference-request', 'book-recommendation', 'time-series']"
3,Prove the order statistic is a minimal sufficient statistic for the logistic pdf $f(x|\theta)=\frac{e^{-(x-\theta)}}{(1+e^{-(x-\theta)})^2}$,Prove the order statistic is a minimal sufficient statistic for the logistic pdf,f(x|\theta)=\frac{e^{-(x-\theta)}}{(1+e^{-(x-\theta)})^2},"I'm going through Statistical Inference by Casella and Berger, and I'm currently on Chapter 6. In particular, I'm doing exercise 6.9 (c), and I'm trying to prove that if $X_1, ..., X_n$ is a random sample from a population with pdf $f(x|\theta)=\frac{e^{-(x-\theta)}}{(1+e^{-(x-\theta)})^2}$ , then the order statistic $T(X) = (X_{(1)},...,X_{(n)})$ is a minimal sufficient statistic for $\theta$ . The joint pdf of the sample is: $$f_X(\boldsymbol{x}|\theta)=e^{n(\theta-\bar{x})}\prod_{i=1}^n \frac{1}{(1+e^{-(x_{(i)}-\theta)})^2}.$$ I want to apply Theorem 6.2.13, so I want to verify that for every two sample points $\boldsymbol{x}$ and $\boldsymbol{y}$ , the ratio $\frac{f(\boldsymbol{x}|\theta)}{f(\boldsymbol{y}|\theta)}$ is independent of $\theta$ if and only if $T(\boldsymbol{x}) = T(\boldsymbol{y})$ . This ratio is: $$e^{n(\bar{y}-\bar{x})} \prod_{i=1}^n \bigg(\frac{1+e^{-(y_{(i)}-\theta)}}{1+e^{-(x_{(i)}-\theta)}}\bigg)^2.$$ Now the first part is independent of $\theta$ , so we just need to verify (dropping the square) that $$\prod_{i=1}^n \frac{1+e^{-(y_{(i)}-\theta)}}{1+e^{-(x_{(i)}-\theta)}}$$ is independent of $\theta$ if and only iff the $T(\boldsymbol{x})=T(\boldsymbol{y})$ are equal. In the solutions and everywhere else I've looked online this is just stated as true, and while the ""if"" direction is obvious, the ""only if"" one isn't. Or rather, sure, it looks like this should only be independent of $\theta$ if the order statistics are equal and I can't find a counterexample, but it doesn't seem necessarily obvious to me. I do believe it's true, but I can't prove it, and I can't even prove this for the case $n=2$ , where the relevant part is $$\frac{1+e^{\theta}(e^{-y_{(1)}}+e^{-y_{(2)}}) + e^{2\theta}e^{-y_{(1)}-y_{(2)}}}{1+e^{\theta}(e^{-x_{(1)}}+e^{-x_{(2)}}) + e^{2\theta}e^{-x_{(1)}-x_{(2)}}}.$$ I'm not sure if I'm missing something obvious, but any help with rigorously proving this would be appreciated (even if you can just answer the question for the special case $n=2$ ).","I'm going through Statistical Inference by Casella and Berger, and I'm currently on Chapter 6. In particular, I'm doing exercise 6.9 (c), and I'm trying to prove that if is a random sample from a population with pdf , then the order statistic is a minimal sufficient statistic for . The joint pdf of the sample is: I want to apply Theorem 6.2.13, so I want to verify that for every two sample points and , the ratio is independent of if and only if . This ratio is: Now the first part is independent of , so we just need to verify (dropping the square) that is independent of if and only iff the are equal. In the solutions and everywhere else I've looked online this is just stated as true, and while the ""if"" direction is obvious, the ""only if"" one isn't. Or rather, sure, it looks like this should only be independent of if the order statistics are equal and I can't find a counterexample, but it doesn't seem necessarily obvious to me. I do believe it's true, but I can't prove it, and I can't even prove this for the case , where the relevant part is I'm not sure if I'm missing something obvious, but any help with rigorously proving this would be appreciated (even if you can just answer the question for the special case ).","X_1, ..., X_n f(x|\theta)=\frac{e^{-(x-\theta)}}{(1+e^{-(x-\theta)})^2} T(X) = (X_{(1)},...,X_{(n)}) \theta f_X(\boldsymbol{x}|\theta)=e^{n(\theta-\bar{x})}\prod_{i=1}^n \frac{1}{(1+e^{-(x_{(i)}-\theta)})^2}. \boldsymbol{x} \boldsymbol{y} \frac{f(\boldsymbol{x}|\theta)}{f(\boldsymbol{y}|\theta)} \theta T(\boldsymbol{x}) = T(\boldsymbol{y}) e^{n(\bar{y}-\bar{x})} \prod_{i=1}^n \bigg(\frac{1+e^{-(y_{(i)}-\theta)}}{1+e^{-(x_{(i)}-\theta)}}\bigg)^2. \theta \prod_{i=1}^n \frac{1+e^{-(y_{(i)}-\theta)}}{1+e^{-(x_{(i)}-\theta)}} \theta T(\boldsymbol{x})=T(\boldsymbol{y}) \theta n=2 \frac{1+e^{\theta}(e^{-y_{(1)}}+e^{-y_{(2)}}) + e^{2\theta}e^{-y_{(1)}-y_{(2)}}}{1+e^{\theta}(e^{-x_{(1)}}+e^{-x_{(2)}}) + e^{2\theta}e^{-x_{(1)}-x_{(2)}}}. n=2","['statistics', 'order-statistics']"
4,Find optimal number of videoclips to watch (depending on length) to get Maximum points.,Find optimal number of videoclips to watch (depending on length) to get Maximum points.,,"Problem: How to find optimal number of video clips to watch (depending on length) to get Maximum points. Description: I request video clip, then I have two options: to watch it (spend time) and receive points or to skip it and not to receive points (not to spend time). Timeout between new video is 5s. (This is statistical histogram where (Y-axis is number of videos, X-axis is video length) Limitations && Assumptions: - We don't know videos in advance (that's why I've gathered data to build a statistical histogram to know their probabilities. ) - When we skip video clip we don't lose points. - We do know video length before watching it. - We receive points for watching video completely. - We receive the same amount of points for every video. So basically we need to skip those videos which are long and watch those videos with an optimal length. (aka to find how to maximize points per unit time)","Problem: How to find optimal number of video clips to watch (depending on length) to get Maximum points. Description: I request video clip, then I have two options: to watch it (spend time) and receive points or to skip it and not to receive points (not to spend time). Timeout between new video is 5s. (This is statistical histogram where (Y-axis is number of videos, X-axis is video length) Limitations && Assumptions: - We don't know videos in advance (that's why I've gathered data to build a statistical histogram to know their probabilities. ) - When we skip video clip we don't lose points. - We do know video length before watching it. - We receive points for watching video completely. - We receive the same amount of points for every video. So basically we need to skip those videos which are long and watch those videos with an optimal length. (aka to find how to maximize points per unit time)",,"['statistics', 'optimization']"
5,F test vs T test. What is the real diference?,F test vs T test. What is the real diference?,,"As I've learnt, a T - test is used to compare 2 populations’ means, whereas an F-test (ANOVA) is used to compare 2/> populations’ variances. At the end is this doing the same thing? My background is from biology and no strong math/stat background. I wonder because whenever I used ANOVA (comparing >2 groups) followed by postHOC Tukey and not observing sig. differences, supervisor asking to use multiple t-test every time. Is this acceptable way of doing statistics. I see there are many publications in biology where they do not follow statistics taught in the Textbooks.","As I've learnt, a T - test is used to compare 2 populations’ means, whereas an F-test (ANOVA) is used to compare 2/> populations’ variances. At the end is this doing the same thing? My background is from biology and no strong math/stat background. I wonder because whenever I used ANOVA (comparing >2 groups) followed by postHOC Tukey and not observing sig. differences, supervisor asking to use multiple t-test every time. Is this acceptable way of doing statistics. I see there are many publications in biology where they do not follow statistics taught in the Textbooks.",,"['statistics', 'normal-distribution', 'statistical-inference', 'variance']"
6,Which theory is used to calculate the position and energy of a point source?,Which theory is used to calculate the position and energy of a point source?,,"Consider an empty room with one point source that emits a stationary signal (constant sound, radioactive radiation, ...). The energy nor the position of the point source is known. We send someone in the room to do some intensity measurements on different positions in the room. With this collected data I want to determine the position and the energy of the point source. Which mathematical theory can be used to do such calculations?","Consider an empty room with one point source that emits a stationary signal (constant sound, radioactive radiation, ...). The energy nor the position of the point source is known. We send someone in the room to do some intensity measurements on different positions in the room. With this collected data I want to determine the position and the energy of the point source. Which mathematical theory can be used to do such calculations?",,"['statistics', 'physics', 'inverse-problems']"
7,Chances of someone being of a certain gender at websites,Chances of someone being of a certain gender at websites,,I have 2 of websites and I know the chances of a visitor being a female or male. Let's say I have 2 website where the chance of a new visitor being a female is 80%. If the visitor comes on website 1 I know the chance of that visitor being female is 80%. But what if that visitor comes on both websites. Is the chance still 80%? Or am I more certain that visitor is a female? If so what is the equation I should use? The website are not dependent of each other.,I have 2 of websites and I know the chances of a visitor being a female or male. Let's say I have 2 website where the chance of a new visitor being a female is 80%. If the visitor comes on website 1 I know the chance of that visitor being female is 80%. But what if that visitor comes on both websites. Is the chance still 80%? Or am I more certain that visitor is a female? If so what is the equation I should use? The website are not dependent of each other.,,['statistics']
8,Greatest common denominator of measurements,Greatest common denominator of measurements,,"In a couple months, I'll do the Millikan experiment. Then, I'll end up with a number of charge measurements and their errors $$((q_i, \Delta q_i))_{i \in \mathbb N}.$$ The idea is that all those $q_i$ can be represented as a multiple of a fixed elementary charge $e$ like $$q_i = n_i e.$$ Now I do not know $e$ in advance. Is there some method to get $(e, \Delta e)$ out of the sequence of measurements? I found this question on StackOverflow , but it does not have any answers that solve the problem in a stable way.","In a couple months, I'll do the Millikan experiment. Then, I'll end up with a number of charge measurements and their errors $$((q_i, \Delta q_i))_{i \in \mathbb N}.$$ The idea is that all those $q_i$ can be represented as a multiple of a fixed elementary charge $e$ like $$q_i = n_i e.$$ Now I do not know $e$ in advance. Is there some method to get $(e, \Delta e)$ out of the sequence of measurements? I found this question on StackOverflow , but it does not have any answers that solve the problem in a stable way.",,['statistics']
9,"X,Y are independent standard normal distributed then what is the distribution of $\frac{X}{X+Y}$","X,Y are independent standard normal distributed then what is the distribution of",\frac{X}{X+Y},"X, Y are independent standard normal random variables, what is the distribution of $$ \frac{X}{X+Y} $$ Could anyone help me with this? Thanks. I have worked the problem by multivariable transformation: Let $$Z=\frac{X}{X+Y} , W=X$$ Consider transformation $$(X,Y)\longrightarrow(Z,W)$$ Then $$X(Z,W)=W , Y(Z,W)=\frac{W(1-Z)}{Z}$$  defines the inverse transformation. The Jacobian is $$J(Z,W)=\frac{w}{z^{2}} $$ So $$f_{Z,W}(z,w)=f_{X,Y}(w,\frac{w(1-z)}{z})\cdot\mid\frac{w}{z^{2}}\mid$$ As X  and Y  are independent. Then the marginal pdf of Z  is $$f_{Z}(z)=\intop_{0}^{\infty}\frac{w}{z^{2}}\cdot f_{X}(w)\cdot f_{Y}(\frac{w(1-z)}{z})dw+\intop_{-\infty}^{0}-\frac{w}{z^{2}}\cdot f_{X}(w)\cdot f_{Y}(\frac{w(1-z)}{z})dw$$  After calculation we get $$f_{Z}(z)=\frac{1}{\pi\cdot\frac{1}{2}\cdot(1+(\frac{z-\frac{1}{2}}{\frac{1}{2}})^{2})}$$ Hence $$Z\sim \mathrm{Cauchy}(\frac{1}{2},\frac{1}{2}).$$","X, Y are independent standard normal random variables, what is the distribution of $$ \frac{X}{X+Y} $$ Could anyone help me with this? Thanks. I have worked the problem by multivariable transformation: Let $$Z=\frac{X}{X+Y} , W=X$$ Consider transformation $$(X,Y)\longrightarrow(Z,W)$$ Then $$X(Z,W)=W , Y(Z,W)=\frac{W(1-Z)}{Z}$$  defines the inverse transformation. The Jacobian is $$J(Z,W)=\frac{w}{z^{2}} $$ So $$f_{Z,W}(z,w)=f_{X,Y}(w,\frac{w(1-z)}{z})\cdot\mid\frac{w}{z^{2}}\mid$$ As X  and Y  are independent. Then the marginal pdf of Z  is $$f_{Z}(z)=\intop_{0}^{\infty}\frac{w}{z^{2}}\cdot f_{X}(w)\cdot f_{Y}(\frac{w(1-z)}{z})dw+\intop_{-\infty}^{0}-\frac{w}{z^{2}}\cdot f_{X}(w)\cdot f_{Y}(\frac{w(1-z)}{z})dw$$  After calculation we get $$f_{Z}(z)=\frac{1}{\pi\cdot\frac{1}{2}\cdot(1+(\frac{z-\frac{1}{2}}{\frac{1}{2}})^{2})}$$ Hence $$Z\sim \mathrm{Cauchy}(\frac{1}{2},\frac{1}{2}).$$",,"['statistics', 'probability-distributions', 'normal-distribution']"
10,TDA - Persistence diagrams and Barcodes,TDA - Persistence diagrams and Barcodes,,"I am relatively new in the field of persistent homology and topological data analysis. I would like to use RIPSER, DIPHA or GUDHI to calculate barcodes which will give a persistence diagram. Here are my questions: 1.) How many data points are possible to analyze with such libraries with respect to an average computer? 2.) Which possible ways to analyze and compare two different persistence diagrams are there? For example I have heard of Wasserstein distance and bottleneck distance. Is there a library or software for analyzing two such diagrams? 3.) How can I interpretate persistence diagrams with many data points? I will get two different persistence diagrams, which should have no big differences. I would like to compare them and find the existing differences. EDIT: Ad question 1. The article ""A Roadmap for the Computation of Persistent Homology"" by Otter et al. gives an idea. The maximum size of the complex $K$ in the case of GUDHI and RIPSER is $3.4\cdot 10^9$, while the size of $K$ is $2^{\mathcal{O}(N)}$, where $N$ is the cardinality of the vertex set. They used in their experiments data sets up to $N=2000$. In the case of SimBa, data sets of $N\ge 250 000$ were used after some reduction by PCA (cf. ""SimBa: An Efficien Tool for Approximating Rips-filtration Persistence via Simplicial Batch-collapse"" by Dey, Shi and Wang). The size of the (sparsified VR) complex $K$, used by SimBa, is given by $\mathcal{O}(N)$.","I am relatively new in the field of persistent homology and topological data analysis. I would like to use RIPSER, DIPHA or GUDHI to calculate barcodes which will give a persistence diagram. Here are my questions: 1.) How many data points are possible to analyze with such libraries with respect to an average computer? 2.) Which possible ways to analyze and compare two different persistence diagrams are there? For example I have heard of Wasserstein distance and bottleneck distance. Is there a library or software for analyzing two such diagrams? 3.) How can I interpretate persistence diagrams with many data points? I will get two different persistence diagrams, which should have no big differences. I would like to compare them and find the existing differences. EDIT: Ad question 1. The article ""A Roadmap for the Computation of Persistent Homology"" by Otter et al. gives an idea. The maximum size of the complex $K$ in the case of GUDHI and RIPSER is $3.4\cdot 10^9$, while the size of $K$ is $2^{\mathcal{O}(N)}$, where $N$ is the cardinality of the vertex set. They used in their experiments data sets up to $N=2000$. In the case of SimBa, data sets of $N\ge 250 000$ were used after some reduction by PCA (cf. ""SimBa: An Efficien Tool for Approximating Rips-filtration Persistence via Simplicial Batch-collapse"" by Dey, Shi and Wang). The size of the (sparsified VR) complex $K$, used by SimBa, is given by $\mathcal{O}(N)$.",,"['statistics', 'algebraic-topology', 'homology-cohomology', 'topological-data-analysis']"
11,Stochastic processes books written with style,Stochastic processes books written with style,,"In Russian many math books are written not only with mathematical clarity, but also adopt author's unique style, which distinguishes their writtings from others and increase pleasure of reading such books. Can you suggest some books written in English, that among other merits adopts a language that is a pleasure to read (similar to what we exercise when we read a classic fiction book)? As I want to be able to undestand such book, it would be good, if this book would cover for example basic Stochastic processes (as I don't know any good general introduction to random processes I like so far but the book by Kelbert and Sukhov that mostly focuses on Markov processes).","In Russian many math books are written not only with mathematical clarity, but also adopt author's unique style, which distinguishes their writtings from others and increase pleasure of reading such books. Can you suggest some books written in English, that among other merits adopts a language that is a pleasure to read (similar to what we exercise when we read a classic fiction book)? As I want to be able to undestand such book, it would be good, if this book would cover for example basic Stochastic processes (as I don't know any good general introduction to random processes I like so far but the book by Kelbert and Sukhov that mostly focuses on Markov processes).",,"['statistics', 'stochastic-processes', 'book-recommendation']"
12,Why hasn't the median function made the mean (effectively) obsolete?,Why hasn't the median function made the mean (effectively) obsolete?,,"I've learned in my AP statistics class that means can really only be used on nearly-normal distributions, but I know that many studies, experiments, etc. don't always give that perfect normal curve that one might find on a histogram. Why use medians? To my knowledge medians are a good averaging function because they are able to eliminate outliers. Consider finding the averages of the amount of money a person makes in a career. Typically, the curve would be skewed and there would be leveraging points (such as the high amount of money people with executive positions in a career would be making). Point: Medians are Means I've noticed that as a data-set becomes more and more normal, or 'better' suited for the use of a mean, the median approaches the value of the mean. If the median takes care of outliers and skewed data and embodies the value of the mean when it meets the 'conditions' of the mean, Why isn't the median always favored over the mean? (especially with the influx of computer based averaging solutions that would effectively eliminate the issue of efficiency of calculation for either averaging function)","I've learned in my AP statistics class that means can really only be used on nearly-normal distributions, but I know that many studies, experiments, etc. don't always give that perfect normal curve that one might find on a histogram. Why use medians? To my knowledge medians are a good averaging function because they are able to eliminate outliers. Consider finding the averages of the amount of money a person makes in a career. Typically, the curve would be skewed and there would be leveraging points (such as the high amount of money people with executive positions in a career would be making). Point: Medians are Means I've noticed that as a data-set becomes more and more normal, or 'better' suited for the use of a mean, the median approaches the value of the mean. If the median takes care of outliers and skewed data and embodies the value of the mean when it meets the 'conditions' of the mean, Why isn't the median always favored over the mean? (especially with the influx of computer based averaging solutions that would effectively eliminate the issue of efficiency of calculation for either averaging function)",,"['statistics', 'median', 'means']"
13,Bayesian versus Classical (frequentist) Statistics,Bayesian versus Classical (frequentist) Statistics,,"Very often in text-books the comparison of Bayesian vs. Classical Statistics are presented upfront in a very abstract way. For example, in the current book I'm studying there's the following postulates of both school of thoughts: ""Within the field of statistics there are two prominent schools of thought, with op­posing views: the Bayesian and the classical (also called frequentist). Their fundamental difference relates to the nature of the unknown models or variables. In the Bayesian view they are treated as random variables with known distributions. In the classical view, they are treated as deterministic quantities that happen to be unknown. "" But as a beginner student in this field there's a lack of 'substance', of something you can 'feel'. So would I like to know, if somebody has a real world example of both cases. Like the same example, but seen from both perspectives to help understanding 'what's going on'. Thanks!","Very often in text-books the comparison of Bayesian vs. Classical Statistics are presented upfront in a very abstract way. For example, in the current book I'm studying there's the following postulates of both school of thoughts: ""Within the field of statistics there are two prominent schools of thought, with op­posing views: the Bayesian and the classical (also called frequentist). Their fundamental difference relates to the nature of the unknown models or variables. In the Bayesian view they are treated as random variables with known distributions. In the classical view, they are treated as deterministic quantities that happen to be unknown. "" But as a beginner student in this field there's a lack of 'substance', of something you can 'feel'. So would I like to know, if somebody has a real world example of both cases. Like the same example, but seen from both perspectives to help understanding 'what's going on'. Thanks!",,"['statistics', 'statistical-inference', 'bayesian']"
14,Is it possible to obtain the Uniform distribution as the difference of two independent random variables?,Is it possible to obtain the Uniform distribution as the difference of two independent random variables?,,"Is it possible to have two independent random variables X,Y with identical distribution, such that  $X-Y \sim \text{Uniform}[a,b]$? I am almost certain that is not, but maybe I am overlooking something?","Is it possible to have two independent random variables X,Y with identical distribution, such that  $X-Y \sim \text{Uniform}[a,b]$? I am almost certain that is not, but maybe I am overlooking something?",,"['statistics', 'probability-distributions', 'convolution']"
15,Computing an Exponential Moving Average Via Convolution,Computing an Exponential Moving Average Via Convolution,,"According to the Wikipedia page on moving averages, ""This is also why sometimes an EMA is referred to as an $N$ -day EMA.  Despite the name suggesting there are $N$ periods, the terminology only specifies the $\alpha$ factor. $N$ is not a stopping point for the calculation in the way it is in an SMA or WMA."" I was very shocked to read this. It seems to be suggesting that the sequence of weights used to compute the Exponential Moving Average via discrete convolution with, i.e., historical market price data goes on forever. I understand that the sum of an infinite number of weights can converge to $1$ , but not how an infinite weight function sequence could be convolved with a finite sequence of historical market price data. How is an $N$ -period Exponential Moving Average computed as the convolution of a weight function and historical data? Is the weight function sequence indeed infinite, or does it only contain $N (\pm 1?)$ elements, or does it contain as many elements as historical data points are available $(\pm 1?)$ which is usually greater than $N$ ? This distinction seems important because adding additional elements will re-normalize the significant elements given that all elements sum to $1$ .  What is a typical example of how this convolution product would be formulated?","According to the Wikipedia page on moving averages, ""This is also why sometimes an EMA is referred to as an -day EMA.  Despite the name suggesting there are periods, the terminology only specifies the factor. is not a stopping point for the calculation in the way it is in an SMA or WMA."" I was very shocked to read this. It seems to be suggesting that the sequence of weights used to compute the Exponential Moving Average via discrete convolution with, i.e., historical market price data goes on forever. I understand that the sum of an infinite number of weights can converge to , but not how an infinite weight function sequence could be convolved with a finite sequence of historical market price data. How is an -period Exponential Moving Average computed as the convolution of a weight function and historical data? Is the weight function sequence indeed infinite, or does it only contain elements, or does it contain as many elements as historical data points are available which is usually greater than ? This distinction seems important because adding additional elements will re-normalize the significant elements given that all elements sum to .  What is a typical example of how this convolution product would be formulated?",N N \alpha N 1 N N (\pm 1?) (\pm 1?) N 1,"['statistics', 'stochastic-processes', 'convolution', 'average', 'time-series']"
16,BFGS Formula from Kullback-Leibler Divergence,BFGS Formula from Kullback-Leibler Divergence,,"On page 411 in this book , the authors give the following BFGS formula $$ \boxed{\boldsymbol C_{\textrm{BFGS}} = \boldsymbol C + \underbrace{\frac{\boldsymbol g^\top\boldsymbol\delta+\boldsymbol g^\top\boldsymbol C\boldsymbol g}{(\boldsymbol g^\top\boldsymbol\delta)^2}\boldsymbol\delta\boldsymbol\delta^\top-\frac{1}{\boldsymbol g^\top\boldsymbol\delta}\left(\boldsymbol\delta\boldsymbol g^\top\boldsymbol C + (\boldsymbol\delta\boldsymbol g^\top\boldsymbol C)^\top\right)}_{\textrm{BFGS update}}}\tag{1} $$ by considering the constrained optimisation problem: $$\begin{array}{rlcll} \min_{\boldsymbol A} & \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) \\ \textrm{subject to}: & \boldsymbol A\boldsymbol g  =  \boldsymbol\delta, \\ & \boldsymbol A ~~=  \boldsymbol A^\top, \end{array}\tag{2}$$ where $$ \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) := \frac12\left(\mathrm{tr}\left(\boldsymbol A^{-1}\boldsymbol C\right) - \log\left(\det(\boldsymbol A^{-1}\boldsymbol C)\right) - n\right)$$ is the Kullback-Leibler divergence between the normal distributions $\mathcal N(\boldsymbol 0, \boldsymbol C)$ and $\mathcal N(\boldsymbol 0, \boldsymbol A)$ . Using Lagrange multipliers with the Lagrangian $$ \mathcal L(\boldsymbol A, \boldsymbol \beta) := \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) + \boldsymbol \beta^\top(\boldsymbol A\boldsymbol g - \boldsymbol \delta)$$ gives (also using symmetry of $\boldsymbol A$ and $\boldsymbol C$ ) $$ \frac{\partial}{\partial\boldsymbol A}\mathcal L(\boldsymbol A, \boldsymbol \beta) = \frac12\left(-\boldsymbol A^{-1}\boldsymbol C\boldsymbol A^{-1} + \boldsymbol A^{-1}\right) + \boldsymbol \beta\boldsymbol g^\top, \quad \boldsymbol{\nabla}_{\boldsymbol \beta}\mathcal L(\boldsymbol A, \boldsymbol \beta) = \boldsymbol A\boldsymbol g - \boldsymbol \delta,$$ and equating these both equal to zero gives $\boldsymbol A\boldsymbol g = \boldsymbol \delta$ and $\boldsymbol A^{-1}(\boldsymbol I - \boldsymbol C\boldsymbol A^{-1}) = -2\boldsymbol \beta \boldsymbol g^\top$ . It is not obvious to me how this last expression could be used to identify the corresponding values of $\boldsymbol \beta$ and $\boldsymbol A$ . I tried multiplying through by $\boldsymbol \delta$ to use the $\boldsymbol A\boldsymbol g = \boldsymbol \delta$ constraint, yielding $\boldsymbol{\delta}\boldsymbol \beta^\top\boldsymbol \delta = \frac12\left(\boldsymbol C\boldsymbol g - \boldsymbol \delta\right)$ , but it is still unclear from this (1) how $\boldsymbol \beta$ is specified and (2) how $\boldsymbol{A}$ would be recovered. What is the correct way to solve the constrained optimisation problem (2) to obtain the BFGS formula (1) with the method of Lagrange multipliers that gives values for $\boldsymbol A$ and $\boldsymbol \beta$ ?","On page 411 in this book , the authors give the following BFGS formula by considering the constrained optimisation problem: where is the Kullback-Leibler divergence between the normal distributions and . Using Lagrange multipliers with the Lagrangian gives (also using symmetry of and ) and equating these both equal to zero gives and . It is not obvious to me how this last expression could be used to identify the corresponding values of and . I tried multiplying through by to use the constraint, yielding , but it is still unclear from this (1) how is specified and (2) how would be recovered. What is the correct way to solve the constrained optimisation problem (2) to obtain the BFGS formula (1) with the method of Lagrange multipliers that gives values for and ?"," \boxed{\boldsymbol C_{\textrm{BFGS}} = \boldsymbol C + \underbrace{\frac{\boldsymbol g^\top\boldsymbol\delta+\boldsymbol g^\top\boldsymbol C\boldsymbol g}{(\boldsymbol g^\top\boldsymbol\delta)^2}\boldsymbol\delta\boldsymbol\delta^\top-\frac{1}{\boldsymbol g^\top\boldsymbol\delta}\left(\boldsymbol\delta\boldsymbol g^\top\boldsymbol C + (\boldsymbol\delta\boldsymbol g^\top\boldsymbol C)^\top\right)}_{\textrm{BFGS update}}}\tag{1}  \begin{array}{rlcll}
\min_{\boldsymbol A} & \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) \\
\textrm{subject to}: & \boldsymbol A\boldsymbol g  =  \boldsymbol\delta, \\
& \boldsymbol A ~~=  \boldsymbol A^\top,
\end{array}\tag{2}  \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) := \frac12\left(\mathrm{tr}\left(\boldsymbol A^{-1}\boldsymbol C\right) - \log\left(\det(\boldsymbol A^{-1}\boldsymbol C)\right) - n\right) \mathcal N(\boldsymbol 0, \boldsymbol C) \mathcal N(\boldsymbol 0, \boldsymbol A)  \mathcal L(\boldsymbol A, \boldsymbol \beta) := \mathcal D(\boldsymbol 0, \boldsymbol C \mid \boldsymbol 0, \boldsymbol A) + \boldsymbol \beta^\top(\boldsymbol A\boldsymbol g - \boldsymbol \delta) \boldsymbol A \boldsymbol C  \frac{\partial}{\partial\boldsymbol A}\mathcal L(\boldsymbol A, \boldsymbol \beta) = \frac12\left(-\boldsymbol A^{-1}\boldsymbol C\boldsymbol A^{-1} + \boldsymbol A^{-1}\right) + \boldsymbol \beta\boldsymbol g^\top, \quad \boldsymbol{\nabla}_{\boldsymbol \beta}\mathcal L(\boldsymbol A, \boldsymbol \beta) = \boldsymbol A\boldsymbol g - \boldsymbol \delta, \boldsymbol A\boldsymbol g = \boldsymbol \delta \boldsymbol A^{-1}(\boldsymbol I - \boldsymbol C\boldsymbol A^{-1}) = -2\boldsymbol \beta \boldsymbol g^\top \boldsymbol \beta \boldsymbol A \boldsymbol \delta \boldsymbol A\boldsymbol g = \boldsymbol \delta \boldsymbol{\delta}\boldsymbol \beta^\top\boldsymbol \delta = \frac12\left(\boldsymbol C\boldsymbol g - \boldsymbol \delta\right) \boldsymbol \beta \boldsymbol{A} \boldsymbol A \boldsymbol \beta","['statistics', 'optimization', 'linear-programming', 'machine-learning', 'newton-raphson']"
17,Maximum of beta-distributed random variables,Maximum of beta-distributed random variables,,"Let $X_i \sim \operatorname{Beta}(\alpha_i, \beta_i)$ be independent beta-distributed random variables for $i = 1, \ldots, k$ .    What can we say about $$X =\max(X_1, \ldots, X_k)?$$ In particular, can we estimate $\alpha$ and $\beta$ so that $X$ is approximately distributed like $\operatorname{Beta}(\alpha, \beta)$ ?  We may assume that $\sum_i \alpha_i + \sum_i \beta_i$ is large if it helps. We can reduce the question to the case $k =2$ , since $$\max(X_1, \ldots, X_k) = \max(\max(\max(X_1, X_2),X_3, \ldots))),$$ although some accuracy might be lost in making successive approximations.  Note also that we have $$P(\max(X_1, X_2) \leq z) = P(X_1 \leq z, X_2 \leq z) = P(X_1 \leq z) P(X_2 \leq z),$$ giving the cumulative distribution function for $X$ . Using Sage I was able to take the case $\alpha_1 = 10,\beta_1 = 15,\alpha_2 = 13,\beta_2 = 12$ and approximate the density function of $X$ pretty well with $\alpha =  16.796, \beta = 14.830$ .  See image. Context: This would be useful for the bandit problem or Monte-Carlo tree search .  Suppose you are playing $k$ games $Y_i$ , and $Y_i$ is either a win, with probability $p_i$ , or a loss.  Then the game $Y$ which consists of a choice of one of the games $Y_i$ can be modeled by a Bernoulli random variable with parameter $p = \max(p_1, \ldots, p_k)$ , since the best strategy is to always choose the game $Y_i$ that has the highest win rate.  If we only have limited information about each $Y_i$ (some samples of each, for example), we can put a prior $p_i \sim \operatorname{Beta}(\alpha_i, \beta_i)$ on each parameter $p_i$ and try to infer information about $p$ from this.","Let be independent beta-distributed random variables for .    What can we say about In particular, can we estimate and so that is approximately distributed like ?  We may assume that is large if it helps. We can reduce the question to the case , since although some accuracy might be lost in making successive approximations.  Note also that we have giving the cumulative distribution function for . Using Sage I was able to take the case and approximate the density function of pretty well with .  See image. Context: This would be useful for the bandit problem or Monte-Carlo tree search .  Suppose you are playing games , and is either a win, with probability , or a loss.  Then the game which consists of a choice of one of the games can be modeled by a Bernoulli random variable with parameter , since the best strategy is to always choose the game that has the highest win rate.  If we only have limited information about each (some samples of each, for example), we can put a prior on each parameter and try to infer information about from this.","X_i \sim \operatorname{Beta}(\alpha_i, \beta_i) i = 1, \ldots, k X =\max(X_1, \ldots, X_k)? \alpha \beta X \operatorname{Beta}(\alpha, \beta) \sum_i \alpha_i + \sum_i \beta_i k =2 \max(X_1, \ldots, X_k) = \max(\max(\max(X_1, X_2),X_3, \ldots))), P(\max(X_1, X_2) \leq z) = P(X_1 \leq z, X_2 \leq z) = P(X_1 \leq z) P(X_2 \leq z), X \alpha_1 = 10,\beta_1 = 15,\alpha_2 = 13,\beta_2 = 12 X \alpha =  16.796, \beta = 14.830 k Y_i Y_i p_i Y Y_i p = \max(p_1, \ldots, p_k) Y_i Y_i p_i \sim \operatorname{Beta}(\alpha_i, \beta_i) p_i p",['statistics']
18,Derivative of multivariate Gaussian PDF with respect to covariance,Derivative of multivariate Gaussian PDF with respect to covariance,,"While trying to derive the M-step of the EM-algorithm for a mixture of Gaussians, I came across this derivative, which I have no idea how to deal with: $$ \frac{\partial}{\partial \mathbf{\Sigma_k}} \left ( (2\pi)^{-d/2}|\mathbf{\Sigma_k}|^{-1/2}e^{-\frac{1}{2}(x-\mathbf{\mu_k})^T\mathbf{\Sigma_k}^{-1}(x-\mathbf{\mu_k})}\right ) $$ Basically, this the derivative of the multivariate Gaussian PDF with respect to the covariance matrix. My matrix calculus is not very good - how do I approach this? I've computed the derivative of the logarithm of this PDF before and that was a bit easier because the $|\mathbf{\Sigma_k}|$ and $\mathbf{\Sigma_k}^{-1}$ were in two separate terms that were added/subtracted. But here they are in two terms that are multiplied together.","While trying to derive the M-step of the EM-algorithm for a mixture of Gaussians, I came across this derivative, which I have no idea how to deal with: $$ \frac{\partial}{\partial \mathbf{\Sigma_k}} \left ( (2\pi)^{-d/2}|\mathbf{\Sigma_k}|^{-1/2}e^{-\frac{1}{2}(x-\mathbf{\mu_k})^T\mathbf{\Sigma_k}^{-1}(x-\mathbf{\mu_k})}\right ) $$ Basically, this the derivative of the multivariate Gaussian PDF with respect to the covariance matrix. My matrix calculus is not very good - how do I approach this? I've computed the derivative of the logarithm of this PDF before and that was a bit easier because the $|\mathbf{\Sigma_k}|$ and $\mathbf{\Sigma_k}^{-1}$ were in two separate terms that were added/subtracted. But here they are in two terms that are multiplied together.",,"['statistics', 'derivatives', 'partial-derivative']"
19,$L^1$ convergence of PDFs vs $L^2$ convergence of CDFs,convergence of PDFs vs  convergence of CDFs,L^1 L^2,"Let $f_n$ denote a sequence of PDFs, and $F_n$ denote the corresponding sequence of CDFs. Given $L^1$ convergence of the PDFs to some PDF $f$, $$\int_\mathbb{R} |f_n(x) -f(x)| dx \rightarrow 0$$ does this imply $L^2$ convergence of the corresponding CDFs to the corresponding CDF $F$, $$\int_\mathbb{R} \left(F_n(x) - F(x)\right)^2 dx \rightarrow 0$$","Let $f_n$ denote a sequence of PDFs, and $F_n$ denote the corresponding sequence of CDFs. Given $L^1$ convergence of the PDFs to some PDF $f$, $$\int_\mathbb{R} |f_n(x) -f(x)| dx \rightarrow 0$$ does this imply $L^2$ convergence of the corresponding CDFs to the corresponding CDF $F$, $$\int_\mathbb{R} \left(F_n(x) - F(x)\right)^2 dx \rightarrow 0$$",,"['statistics', 'probability-distributions', 'convergence-divergence']"
20,Finding the probability of time between two events for a poisson process,Finding the probability of time between two events for a poisson process,,"If two events occur at a rate of 1.8 per hour on average, and this occurrence follows a poisson process, what is the probability that there is at least 1 hour between two events? My approach for this question is the following: $$\lambda = \frac{1}{E(x)} = \frac{1}{1.8} = 0.556$$ The probability of the time being under an hour (using the cumulative probability density for the poisson process): $$P(X<1) = 1-e^{-\lambda x} = 1-e^{-0.556(1)} = 0.4265$$ Therefore the probability of the time being above an hour would be: $$P(X\ge1) = 1-P(X<1) = 1-(1-e^{-0.556}) = e^{-0.556} = 0.573$$ The logic here seems obvious: The probability of a given wait time for independent events following a poisson process is determined by the exponential probability distribution $\lambda e^{-\lambda x}$ with $\lambda = 0.556$ (determined above), so the area under this density curve (the cumulative probability) is 1. Therefore, the probability of any time range would be the integral of this distribution function over the given time range. The integral from 0 to 1 is the probability of the time between events being under 1 hour, which is $0.4265$, and so the probability of the time between events being above 1 hour is $1-0.4265 = 0.573$. ...however, this is apparently not correct. The answer to this in the back of the book I am using is $0.1653$, and by the logic I've outlined above I am not seeing how. I am very much hoping my approach is proper and that the book is wrong, and am hoping someone can help me correct or confirm my logic.","If two events occur at a rate of 1.8 per hour on average, and this occurrence follows a poisson process, what is the probability that there is at least 1 hour between two events? My approach for this question is the following: $$\lambda = \frac{1}{E(x)} = \frac{1}{1.8} = 0.556$$ The probability of the time being under an hour (using the cumulative probability density for the poisson process): $$P(X<1) = 1-e^{-\lambda x} = 1-e^{-0.556(1)} = 0.4265$$ Therefore the probability of the time being above an hour would be: $$P(X\ge1) = 1-P(X<1) = 1-(1-e^{-0.556}) = e^{-0.556} = 0.573$$ The logic here seems obvious: The probability of a given wait time for independent events following a poisson process is determined by the exponential probability distribution $\lambda e^{-\lambda x}$ with $\lambda = 0.556$ (determined above), so the area under this density curve (the cumulative probability) is 1. Therefore, the probability of any time range would be the integral of this distribution function over the given time range. The integral from 0 to 1 is the probability of the time between events being under 1 hour, which is $0.4265$, and so the probability of the time between events being above 1 hour is $1-0.4265 = 0.573$. ...however, this is apparently not correct. The answer to this in the back of the book I am using is $0.1653$, and by the logic I've outlined above I am not seeing how. I am very much hoping my approach is proper and that the book is wrong, and am hoping someone can help me correct or confirm my logic.",,"['statistics', 'poisson-distribution']"
21,How to explain if a quantity is a pivot quantity?,How to explain if a quantity is a pivot quantity?,,"from what i have gathered . I know that pivots are functions that give approximate or exact assumption of CI . I'm not entirely sure what is the quantity the question is referring to. does the quantity mean the mean, standard deviation etc.?","from what i have gathered . I know that pivots are functions that give approximate or exact assumption of CI . I'm not entirely sure what is the quantity the question is referring to. does the quantity mean the mean, standard deviation etc.?",,['statistics']
22,What's the distribution of the exponential of uniformly distributed variable?,What's the distribution of the exponential of uniformly distributed variable?,,"I want to know the distribution of $z = \exp(j\varphi)$, with $\varphi \sim \mathcal{U}[-\pi;+\pi]$. From the book ""Probability, Random Variables and Stochastic Processes"" by Papoulis and Pillai I figured the following: If $y=g(x)$ is a function of random variable $x$ with the density function $f_x(x)$, one can retrieve the density function $f_y(y)$ of $y$ by $f_y(y)=f_x(x)/|g'(x)|$. Therefore, if $g(x)=y=exp(x)$, this yields $f_y(y)=f_x(ln(y))/|exp(x)|$. In my case with $f_x(x)$ being a uniform distribution. Unfortunately, I haven't figured out yet how to include this uniform distribution into the equation and even more important how to transfer the solution to complex variables.","I want to know the distribution of $z = \exp(j\varphi)$, with $\varphi \sim \mathcal{U}[-\pi;+\pi]$. From the book ""Probability, Random Variables and Stochastic Processes"" by Papoulis and Pillai I figured the following: If $y=g(x)$ is a function of random variable $x$ with the density function $f_x(x)$, one can retrieve the density function $f_y(y)$ of $y$ by $f_y(y)=f_x(x)/|g'(x)|$. Therefore, if $g(x)=y=exp(x)$, this yields $f_y(y)=f_x(ln(y))/|exp(x)|$. In my case with $f_x(x)$ being a uniform distribution. Unfortunately, I haven't figured out yet how to include this uniform distribution into the equation and even more important how to transfer the solution to complex variables.",,"['statistics', 'probability-distributions', 'random-variables', 'uniform-distribution']"
23,Why $\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$,Why,\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}},"I'm reviewing probability and statistics.The textbooks said that if the sampled population is infinite, then $$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$$ I'm curious about how does this result come from. Wikipedia does not tell me much. Is there any provement? How does it come from?","I'm reviewing probability and statistics.The textbooks said that if the sampled population is infinite, then $$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$$ I'm curious about how does this result come from. Wikipedia does not tell me much. Is there any provement? How does it come from?",,['statistics']
24,"If two Gaussian random variables are uncorrelated, they are statistically independent","If two Gaussian random variables are uncorrelated, they are statistically independent",,"I read in a textbook that when two gaussian variables are uncorrelated, then they are statistically independent? How can I prove that?","I read in a textbook that when two gaussian variables are uncorrelated, then they are statistically independent? How can I prove that?",,"['statistics', 'probability-distributions', 'correlation']"
25,Proof of $\frac{1}{n}\mathrm{E} \left[ \| \mathbf{X}\mathbf{\hat{w}} - \mathbf{X}\mathbf{w}^{*} \|^{2}_{2} \right] = \sigma^{2}\frac{d}{n}$,Proof of,\frac{1}{n}\mathrm{E} \left[ \| \mathbf{X}\mathbf{\hat{w}} - \mathbf{X}\mathbf{w}^{*} \|^{2}_{2} \right] = \sigma^{2}\frac{d}{n},"I am trying to find a proof for the MSE of a linear regression: \begin{gather} \frac{1}{n}\mathrm{E} \left[ \| \mathbf{X}\mathbf{\hat{w}} - \mathbf{X}\mathbf{w}^{*} \|^{2}_{2} \right] = \sigma^{2}\frac{d}{n} \end{gather} The variables are defined as follows: $\mathbf{X} \in \mathbb{R}^{n \times d}$ : full column rank feature matrix with $n$ features in $d$ dimensions $\mathbf{z} \in \mathbb{R}^{n}$ : gaussian distributed noise vector with $\mathcal{N}(0, \mathrm{diag}(\sigma^2, \cdots, \sigma^2))$ $\mathbf{y} \in \mathbb{R}^{n}$ : noisy measurement of a true signal $\mathbf{y}^{*}$ with additive gaussian noise $\mathbf{y} = \mathbf{y}^{*} + \mathbf{z}$ The computed optimal weights are provided by multiplying the above $\mathbf{y}$ with the pseudo-inverse of $\mathbf{X}$ : \begin{gather} \mathbf{\hat{w}} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal(\mathbf{y}^{*} + \mathbf{z}) \end{gather} With the true optimal weights denoted by $$\mathbf{w}^{*} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y}^{*}$$ The expectation is taken over the noise-vector $\mathbf{z}$ with all other variables assumed to be determined/non-probabilistic. So far I have tried all kinds of shenanigans with the SVD $\mathbf{X} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^\intercal$ but could only come to the result of $$\frac{1}{n}\mathrm{diag}(\sigma^2, \dots, \sigma^2)$$ My main problem is figuring out how $d$ gets into the equation.",I am trying to find a proof for the MSE of a linear regression: The variables are defined as follows: : full column rank feature matrix with features in dimensions : gaussian distributed noise vector with : noisy measurement of a true signal with additive gaussian noise The computed optimal weights are provided by multiplying the above with the pseudo-inverse of : With the true optimal weights denoted by The expectation is taken over the noise-vector with all other variables assumed to be determined/non-probabilistic. So far I have tried all kinds of shenanigans with the SVD but could only come to the result of My main problem is figuring out how gets into the equation.,"\begin{gather}
\frac{1}{n}\mathrm{E} \left[ \| \mathbf{X}\mathbf{\hat{w}} - \mathbf{X}\mathbf{w}^{*} \|^{2}_{2} \right] = \sigma^{2}\frac{d}{n}
\end{gather} \mathbf{X} \in \mathbb{R}^{n \times d} n d \mathbf{z} \in \mathbb{R}^{n} \mathcal{N}(0, \mathrm{diag}(\sigma^2, \cdots, \sigma^2)) \mathbf{y} \in \mathbb{R}^{n} \mathbf{y}^{*} \mathbf{y} = \mathbf{y}^{*} + \mathbf{z} \mathbf{y} \mathbf{X} \begin{gather}
\mathbf{\hat{w}} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal(\mathbf{y}^{*} + \mathbf{z})
\end{gather} \mathbf{w}^{*} = (\mathbf{X}^\intercal\mathbf{X})^{-1}\mathbf{X}^\intercal\mathbf{y}^{*} \mathbf{z} \mathbf{X} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^\intercal \frac{1}{n}\mathrm{diag}(\sigma^2, \dots, \sigma^2) d","['statistics', 'proof-explanation', 'machine-learning', 'linear-regression', 'pseudoinverse']"
26,"Why is it called the ""sampling distribution of the mean""?","Why is it called the ""sampling distribution of the mean""?",,"Is there a good (or even a bad) reason why it's called the ""sampling distribution of the mean"" and not the ""distribution of the sample mean""? If we take multiple samples all of the same size, $n$ , we get a distribution of sample means , $\bar{X}$ . If I get this right, this is called the ""sampling distribution of the mean"". But that seems like an overly confusing name. I can be fussy about names of things. But then sometimes there's a good reason for a ""bad"" name. So why did we give a distribution of sample means this unwieldy name? Is it wrong to call it a ""distribution of sample means""?","Is there a good (or even a bad) reason why it's called the ""sampling distribution of the mean"" and not the ""distribution of the sample mean""? If we take multiple samples all of the same size, , we get a distribution of sample means , . If I get this right, this is called the ""sampling distribution of the mean"". But that seems like an overly confusing name. I can be fussy about names of things. But then sometimes there's a good reason for a ""bad"" name. So why did we give a distribution of sample means this unwieldy name? Is it wrong to call it a ""distribution of sample means""?",n \bar{X},"['statistics', 'terminology', 'descriptive-statistics']"
27,"Calculating the 1st quartile: different result with Excel, Wolfram Alpha and using formula in my math book - why?","Calculating the 1st quartile: different result with Excel, Wolfram Alpha and using formula in my math book - why?",,"I have the following set of numbers: 1, 1, 8, 12, 13, 13, 14, 16, 19, 22, 27, 28, 31 I'm supposed to calculate the value of the 1st quartile (25th percentile) in this data set. Using the formula in my math book gives me 10 . Using Excel's or Google Sheet's built-in QUARTILE function gives me 12 . Using Wolfram Alpha https://www.wolframalpha.com/input/?i=first+quartile+(1,+1,+8,+12,+13,+13,+14,+16,+19,+22,+27,+28,+31) gives me 11 . Somebody has noted in a Stack Overflow post ( https://stackoverflow.com/a/53551756 ) this behavior with Python programming language too. Can someone please explain why the results differ in these different methods? What makes this very specific data set special so that these methods give different values? Which of these values is the correct / most correct one and why? Many thanks in advance!","I have the following set of numbers: 1, 1, 8, 12, 13, 13, 14, 16, 19, 22, 27, 28, 31 I'm supposed to calculate the value of the 1st quartile (25th percentile) in this data set. Using the formula in my math book gives me 10 . Using Excel's or Google Sheet's built-in QUARTILE function gives me 12 . Using Wolfram Alpha https://www.wolframalpha.com/input/?i=first+quartile+(1,+1,+8,+12,+13,+13,+14,+16,+19,+22,+27,+28,+31) gives me 11 . Somebody has noted in a Stack Overflow post ( https://stackoverflow.com/a/53551756 ) this behavior with Python programming language too. Can someone please explain why the results differ in these different methods? What makes this very specific data set special so that these methods give different values? Which of these values is the correct / most correct one and why? Many thanks in advance!",,"['statistics', 'wolfram-alpha']"
28,Causal Inference A Primer Study Question,Causal Inference A Primer Study Question,,"I am reading Pearl's Causal Inference book and attempted at solving study question 1.2.4. Here is the entire problem: In an attempt to estimate the effectiveness of a new drug, a randomized experiment is conducted. In all, 50% of the patients are assigned to receive the new drug and 50% to receive a placebo. A day before the actual experiment, a nurse hands out lollipops to some patients who show signs of depression, mostly among those who have been assigned to treatment the next day (i.e., the nurse’s round happened to take her through the treatment-bound ward). Strangely, the experimental data revealed a Simpson’s reversal: Although the drug proved beneficial to the population as a whole, drug takers were less likely to recover than nontakers, among both lollipop receivers and lollipop nonreceivers. Assuming that lollipop sucking in itself has no effect whatsoever on recovery, answer the following questions: 1. Is the drug beneficial to the population as a whole or harmful? 2. Does your answer contradict our gender example, where sex-specific data was deemed more appropriate? 3. Draw a graph (informally) that more or less captures the story. 4. How would you explain the emergence of Simpson’s reversal in this story? 5. Would your answer change if the lollipops were handed out (by the same criterion) a day after the study? [Hint: Use the fact that receiving a lollipop indicates a greater likelihood of being assigned to drug treatment, as well as depression, which is a symptom of risk factors that lower the likelihood of recovery.] Given the hint, Here is my attempt at forming some assumptions that might have produced the observed data: Lollipop receivers consist of depressed patients (majority) and patients without depression. So depression affects lollipop receipt. Lollipop receivers consist of treated patients (majority) and untreated patients. So treatment affects lollipop receipt. However, depression and treatment assignment cannot be related because treatment assignment was randomized. This means that the number of depressed patients in the treatment group should be similar to the number of depressed patients in the placebo group. Treatment affects recovery. Depression affects recovery. I tried to come up with a concrete extreme case that would be consistent with the problem's description and my assumptions. One extreme scenario for the simpson's reversal to happen is by the following: Within the lollipop group, most treated patients are depressed, and all the untreated patients aren't depressed. Since untreated patients have better health than treated patients, depending on the severeness of depression for the treated patients, placebo group can have a higher recover rate than treatment group within the lollipop group. If 1 is established, within the non-lollipop group, it must be that all the treated patients are not depressed, and the majority of the untreated patients are depressed. In this case, untreated patients should have a lower recovery rate since they are both untreated and are in a worse health condition, contradicting simpson's reversal. I have been trying different scenarios and creating contingency tables but still can't find a satisfying concrete example. Could someone please help me?","I am reading Pearl's Causal Inference book and attempted at solving study question 1.2.4. Here is the entire problem: In an attempt to estimate the effectiveness of a new drug, a randomized experiment is conducted. In all, 50% of the patients are assigned to receive the new drug and 50% to receive a placebo. A day before the actual experiment, a nurse hands out lollipops to some patients who show signs of depression, mostly among those who have been assigned to treatment the next day (i.e., the nurse’s round happened to take her through the treatment-bound ward). Strangely, the experimental data revealed a Simpson’s reversal: Although the drug proved beneficial to the population as a whole, drug takers were less likely to recover than nontakers, among both lollipop receivers and lollipop nonreceivers. Assuming that lollipop sucking in itself has no effect whatsoever on recovery, answer the following questions: 1. Is the drug beneficial to the population as a whole or harmful? 2. Does your answer contradict our gender example, where sex-specific data was deemed more appropriate? 3. Draw a graph (informally) that more or less captures the story. 4. How would you explain the emergence of Simpson’s reversal in this story? 5. Would your answer change if the lollipops were handed out (by the same criterion) a day after the study? [Hint: Use the fact that receiving a lollipop indicates a greater likelihood of being assigned to drug treatment, as well as depression, which is a symptom of risk factors that lower the likelihood of recovery.] Given the hint, Here is my attempt at forming some assumptions that might have produced the observed data: Lollipop receivers consist of depressed patients (majority) and patients without depression. So depression affects lollipop receipt. Lollipop receivers consist of treated patients (majority) and untreated patients. So treatment affects lollipop receipt. However, depression and treatment assignment cannot be related because treatment assignment was randomized. This means that the number of depressed patients in the treatment group should be similar to the number of depressed patients in the placebo group. Treatment affects recovery. Depression affects recovery. I tried to come up with a concrete extreme case that would be consistent with the problem's description and my assumptions. One extreme scenario for the simpson's reversal to happen is by the following: Within the lollipop group, most treated patients are depressed, and all the untreated patients aren't depressed. Since untreated patients have better health than treated patients, depending on the severeness of depression for the treated patients, placebo group can have a higher recover rate than treatment group within the lollipop group. If 1 is established, within the non-lollipop group, it must be that all the treated patients are not depressed, and the majority of the untreated patients are depressed. In this case, untreated patients should have a lower recovery rate since they are both untreated and are in a worse health condition, contradicting simpson's reversal. I have been trying different scenarios and creating contingency tables but still can't find a satisfying concrete example. Could someone please help me?",,"['statistics', 'statistical-inference', 'paradoxes', 'causal-diagrams', 'causality']"
29,What does 'central exposed to risk' mean?,What does 'central exposed to risk' mean?,,"I am currently going through some actuarial lecture notes which, without definition, use the term 'central exposed to risk', which it denotes by $E_{x,t}^c$. Having googled this term, the most easily understandable explanation of this term seems to imply that if we have a population of initial size $p$ at time $x$ and at time $x+t$ the size of this population is $q$ then $$ E_{x,t}^c = p - \frac{p-q}{t} $$ i.e. the average number of lives which are alive within the population between times $x$ and $x+t$. Is this correct?","I am currently going through some actuarial lecture notes which, without definition, use the term 'central exposed to risk', which it denotes by $E_{x,t}^c$. Having googled this term, the most easily understandable explanation of this term seems to imply that if we have a population of initial size $p$ at time $x$ and at time $x+t$ the size of this population is $q$ then $$ E_{x,t}^c = p - \frac{p-q}{t} $$ i.e. the average number of lives which are alive within the population between times $x$ and $x+t$. Is this correct?",,"['statistics', 'actuarial-science']"
30,Can a class test scores with a bimodal distribution provide statistical evidence for cheating?,Can a class test scores with a bimodal distribution provide statistical evidence for cheating?,,"I know the normal distribution can represent many things in nature. Most items are normally distributed . I recently watched a video of a professor who claims that biomodal distributions provide evidence of cheating . He states that biomodal distribution "" when external forces are applied to a data set that creates a systematic bias to a data set "" aka cheating. He compares this information to previous grade distributions of students given the same test in other years when he gave the test and estimated that 1/3 of his students have cheated . My question is does a bimodal distribution really provide statistical evidence of cheating? Can't it be that some students do very poorly and some students do really well, leaving a peak that is low and a peak that is high? Do biomodal distribution really mean there is a higher probability of ""when external forces are applied to a data set that creates a systematic bias to a data set?"" The link to the video is: https://www.youtube.com/watch?v=rbzJTTDO9f4 Yes, I get some students admitted to cheating, but that doesn't answer my question. My question is can a teacher really provide statistical evidence of someone cheating without them admitting it? I know statistics is all about probability, so can a teacher claim that the probability of this is really lower than a certain threshold and say because of this there exist a statistical significance of them cheating? And how can they approximate 1/3 of there students cheated just by comparing the bimodal distribution to a normal distribution. To me, it seems that the teacher is just trying to use scare tactics with his ""statistics"" and guilt students into admitting to cheating rather than have any evidence of them cheating. PS: I know cheating is wrong, but I know there must be a lot of innocent students in his class that were also accused of cheating, so that is why I asked this question. (I don't actually go to that university)","I know the normal distribution can represent many things in nature. Most items are normally distributed . I recently watched a video of a professor who claims that biomodal distributions provide evidence of cheating . He states that biomodal distribution "" when external forces are applied to a data set that creates a systematic bias to a data set "" aka cheating. He compares this information to previous grade distributions of students given the same test in other years when he gave the test and estimated that 1/3 of his students have cheated . My question is does a bimodal distribution really provide statistical evidence of cheating? Can't it be that some students do very poorly and some students do really well, leaving a peak that is low and a peak that is high? Do biomodal distribution really mean there is a higher probability of ""when external forces are applied to a data set that creates a systematic bias to a data set?"" The link to the video is: https://www.youtube.com/watch?v=rbzJTTDO9f4 Yes, I get some students admitted to cheating, but that doesn't answer my question. My question is can a teacher really provide statistical evidence of someone cheating without them admitting it? I know statistics is all about probability, so can a teacher claim that the probability of this is really lower than a certain threshold and say because of this there exist a statistical significance of them cheating? And how can they approximate 1/3 of there students cheated just by comparing the bimodal distribution to a normal distribution. To me, it seems that the teacher is just trying to use scare tactics with his ""statistics"" and guilt students into admitting to cheating rather than have any evidence of them cheating. PS: I know cheating is wrong, but I know there must be a lot of innocent students in his class that were also accused of cheating, so that is why I asked this question. (I don't actually go to that university)",,"['statistics', 'probability-distributions', 'normal-distribution', 'statistical-inference']"
31,"Check answer, How to find Cov(x,y) and Var(2x-y)?","Check answer, How to find Cov(x,y) and Var(2x-y)?",,"I have the following tableau x:   -1          0         1       total  y:  1    0         1/8        3/8      1/2     2    3/8       1/8        0        1/2 total:   3/8       2/8        3/8       1 *)Find Cov(x,y) and Var(2x-y) My work:  I use Cov(x,y)= E(XY)-E(X)E(Y) I have E(x)= 0  E(Y)= 3/2  E(X^2)= 3/4  E(Y^2)= 5/2 After plug the values I have: Cov(xy)=-15/8 And, var(2x-y)= 4 var(x) + var(y) - 2*2 cov(xy)    Var(2x-y)= 10.75 Question: I solve the exercise ok, or I have some problem. I want to check. Thanks!","I have the following tableau x:   -1          0         1       total  y:  1    0         1/8        3/8      1/2     2    3/8       1/8        0        1/2 total:   3/8       2/8        3/8       1 *)Find Cov(x,y) and Var(2x-y) My work:  I use Cov(x,y)= E(XY)-E(X)E(Y) I have E(x)= 0  E(Y)= 3/2  E(X^2)= 3/4  E(Y^2)= 5/2 After plug the values I have: Cov(xy)=-15/8 And, var(2x-y)= 4 var(x) + var(y) - 2*2 cov(xy)    Var(2x-y)= 10.75 Question: I solve the exercise ok, or I have some problem. I want to check. Thanks!",,['statistics']
32,minimum kullback leibler estimator,minimum kullback leibler estimator,,"Suppose that one has independent and identically distributed samples $x_i,i=1,...,n$ from some unknown density and one wants to fit a probability distribution $f_\theta(x)$, where $\theta$ is a (finite-dimensional) parameter, e.g. $\theta \in \mathbb{R}$,  to that data. It seems that one way to estimate $\theta$ could be to minimize the Kullback-Leibler divergence between an estimate of pdf computed from data $x_i$ (using e.g. some kernel estimator) and the model $f_\theta$. I know that KL is used in many problems as a distance measure between two probability distributions (though it not actually a distance since it is not symmetric) but I don't think I have seen any theory about an estimator that it defined as a minimizer of this distance. Also there is a connection to maximum likelihood estimation since if $p(x)$ is the pdf computed from the data we have \begin{align} KL(p || q) &= \int p(x) \log\frac{p(x)}{f_\theta(x)} dx = \int p(x) \log p(x) dx - \int p(x) \log f_\theta(x) dx \\ &= H(p) - E(\log f_\theta(x)),\end{align} where the first term (entropy of $p$) is constant and the latter term can be approximated with $\frac{1}{n}\sum_{i=1}^n \log f_\theta(x_i)$. So maximizing the last term (i.e. ML estimator) gives approximately the minimum KL divergence. So my question is that is there any general theory about such estimator and some (not overly uncommon) applications where such method is used? Or is it so that such estimator typically has not-so-nice properties or is it just overrun by other estimation methods (like maximum likelihood, (generalized) method of moments etc.) that are likely easier to apply. Also I know there is some theory about minimum Hellinger distance estimation which seems to have nice efficiency and robustness properties but I would guess that is not the case with KL then?","Suppose that one has independent and identically distributed samples $x_i,i=1,...,n$ from some unknown density and one wants to fit a probability distribution $f_\theta(x)$, where $\theta$ is a (finite-dimensional) parameter, e.g. $\theta \in \mathbb{R}$,  to that data. It seems that one way to estimate $\theta$ could be to minimize the Kullback-Leibler divergence between an estimate of pdf computed from data $x_i$ (using e.g. some kernel estimator) and the model $f_\theta$. I know that KL is used in many problems as a distance measure between two probability distributions (though it not actually a distance since it is not symmetric) but I don't think I have seen any theory about an estimator that it defined as a minimizer of this distance. Also there is a connection to maximum likelihood estimation since if $p(x)$ is the pdf computed from the data we have \begin{align} KL(p || q) &= \int p(x) \log\frac{p(x)}{f_\theta(x)} dx = \int p(x) \log p(x) dx - \int p(x) \log f_\theta(x) dx \\ &= H(p) - E(\log f_\theta(x)),\end{align} where the first term (entropy of $p$) is constant and the latter term can be approximated with $\frac{1}{n}\sum_{i=1}^n \log f_\theta(x_i)$. So maximizing the last term (i.e. ML estimator) gives approximately the minimum KL divergence. So my question is that is there any general theory about such estimator and some (not overly uncommon) applications where such method is used? Or is it so that such estimator typically has not-so-nice properties or is it just overrun by other estimation methods (like maximum likelihood, (generalized) method of moments etc.) that are likely easier to apply. Also I know there is some theory about minimum Hellinger distance estimation which seems to have nice efficiency and robustness properties but I would guess that is not the case with KL then?",,"['statistics', 'statistical-inference', 'parameter-estimation']"
33,"A good, self-study statistical computing book","A good, self-study statistical computing book",,"I'm looking for a book an introductory statistical computing that has proofs for the methods as well as examples. I'd like proofs that are about the same level as (or lower than) proofs in Statistical Inference by Casella and Berger. I'd also like examples in R or MATLAB. If there aren't any good books that combine these two features, then please recommend two books.","I'm looking for a book an introductory statistical computing that has proofs for the methods as well as examples. I'd like proofs that are about the same level as (or lower than) proofs in Statistical Inference by Casella and Berger. I'd also like examples in R or MATLAB. If there aren't any good books that combine these two features, then please recommend two books.",,"['statistics', 'reference-request', 'self-learning']"
34,Confidence interval of quotient of two random variables,Confidence interval of quotient of two random variables,,"I have random variables $X_1, X_2, \dots, X_n$ and $Y_1, Y_2, \dots, Y_n$, with $n$ a large integer. All pairs $(X_i, Y_i)$ are independent and identically distributed, but every $X_i$ and $Y_i$ within a pair are dependent. All $X_i$ and $Y_i$ yield positive real numbers. I have a sample of each variable, I'll call the values $x_1, x_2, \dots, x_n$ and $y_1, y_2, \dots, y_n$. Then I can calculate $\mu_x = \frac{1}{n} \sum_{i=1}^n x_i$ and $\sigma_x = \frac{1}{n-1} \sum_{i=1}^n (x_i - \mu_x)^2$, and similar formulas for $\mu_y$ and $\sigma_y$. The goal is to estimate $\mu = E[X_1] / E[Y_1]$ and to get a confidence interval with a given confidence (for example 95%). I'm not sure if I may do some assumptions, since the random variables are the output of a process that I do not fully understand. Maybe I may assume that all variables are almost normally distributed, but it would be better if the question can be answered with no assumptions or weaker assumptions. To estimate $\mu$ I can simply calculate $\mu \approx \mu_x / \mu_y$, but the confidence interval gives me headaches. How can I calculate the confidence interval?","I have random variables $X_1, X_2, \dots, X_n$ and $Y_1, Y_2, \dots, Y_n$, with $n$ a large integer. All pairs $(X_i, Y_i)$ are independent and identically distributed, but every $X_i$ and $Y_i$ within a pair are dependent. All $X_i$ and $Y_i$ yield positive real numbers. I have a sample of each variable, I'll call the values $x_1, x_2, \dots, x_n$ and $y_1, y_2, \dots, y_n$. Then I can calculate $\mu_x = \frac{1}{n} \sum_{i=1}^n x_i$ and $\sigma_x = \frac{1}{n-1} \sum_{i=1}^n (x_i - \mu_x)^2$, and similar formulas for $\mu_y$ and $\sigma_y$. The goal is to estimate $\mu = E[X_1] / E[Y_1]$ and to get a confidence interval with a given confidence (for example 95%). I'm not sure if I may do some assumptions, since the random variables are the output of a process that I do not fully understand. Maybe I may assume that all variables are almost normally distributed, but it would be better if the question can be answered with no assumptions or weaker assumptions. To estimate $\mu$ I can simply calculate $\mu \approx \mu_x / \mu_y$, but the confidence interval gives me headaches. How can I calculate the confidence interval?",,['statistics']
35,Sufficient statistic for the Negative-Binomial Distribution,Sufficient statistic for the Negative-Binomial Distribution,,"I am fairly new to this topic but here is my problem: I have stumbled across a paper (Robinson and Smyth, 2008) stating that the sample sum is a sufficient statistic for NB-distributed random variables. I have tried to verify this by using the Fisher–Neyman factorization theorem  $f_\theta(x)=h(x) \, g_\theta(T(x))$. This is how far I have come: $\frac{\prod\Gamma(x_i+r)}{\prod x_i! \Gamma(r)^n}(1-p)^{n*r}p^{\sum{x_i}}$ It would be easy if it weren't for the Gamma function in the numerator as then $h(x)=\frac{1}{\prod x_i!}$ and $g_\theta(T(x))=\Gamma(r)^{-n}(1-p)^{n*r}p^{\sum{x_i}}$. If I am on the wrong path, could somebody please help me solve this?","I am fairly new to this topic but here is my problem: I have stumbled across a paper (Robinson and Smyth, 2008) stating that the sample sum is a sufficient statistic for NB-distributed random variables. I have tried to verify this by using the Fisher–Neyman factorization theorem  $f_\theta(x)=h(x) \, g_\theta(T(x))$. This is how far I have come: $\frac{\prod\Gamma(x_i+r)}{\prod x_i! \Gamma(r)^n}(1-p)^{n*r}p^{\sum{x_i}}$ It would be easy if it weren't for the Gamma function in the numerator as then $h(x)=\frac{1}{\prod x_i!}$ and $g_\theta(T(x))=\Gamma(r)^{-n}(1-p)^{n*r}p^{\sum{x_i}}$. If I am on the wrong path, could somebody please help me solve this?",,['statistics']
36,What is the continuous distribution version of multinomial distribution?,What is the continuous distribution version of multinomial distribution?,,"I am trying to model a distribution, on the number of occurrences of an event in a 24 hour time span. Right now, I discretize the 24 hour time span into hourly intervals, and each hour is taken as a categorical outcome, and I count the number of occurrences of the event in each hour (outcome). Hence, this problem is modeled as a multinomial distribution. As time is a continuous variable, is there a continuous version of multinomial distribution? That is, I can count the number of occurrence of the event in the continuous outcome(time).","I am trying to model a distribution, on the number of occurrences of an event in a 24 hour time span. Right now, I discretize the 24 hour time span into hourly intervals, and each hour is taken as a categorical outcome, and I count the number of occurrences of the event in each hour (outcome). Hence, this problem is modeled as a multinomial distribution. As time is a continuous variable, is there a continuous version of multinomial distribution? That is, I can count the number of occurrence of the event in the continuous outcome(time).",,"['statistics', 'probability-distributions', 'multinomial-distribution']"
37,Intuition of Gamma Family,Intuition of Gamma Family,,"The function $$f(t) = \frac{t^{\alpha-1}e^{-t}}{\Gamma(\alpha)}, \ \ 0 < t < \infty$$ is a pdf. But Why is the gamma family defined as $$f(x| \alpha, \beta) = \frac{1}{\Gamma(\alpha) \beta^{\alpha}} x^{\alpha-1}e^{-x/ \beta}, \ \ 0 < x < \infty, \ \ \ \alpha >0, \ \ \beta >0$$ I know you make the substitution $x = \beta t$. But why do this?","The function $$f(t) = \frac{t^{\alpha-1}e^{-t}}{\Gamma(\alpha)}, \ \ 0 < t < \infty$$ is a pdf. But Why is the gamma family defined as $$f(x| \alpha, \beta) = \frac{1}{\Gamma(\alpha) \beta^{\alpha}} x^{\alpha-1}e^{-x/ \beta}, \ \ 0 < x < \infty, \ \ \ \alpha >0, \ \ \beta >0$$ I know you make the substitution $x = \beta t$. But why do this?",,"['statistics', 'probability-distributions']"
38,Why does confidence interval need to be symmetric about the point estimate and contiguous?,Why does confidence interval need to be symmetric about the point estimate and contiguous?,,"This post could be entitled as ""Interpretation of confidence interval 2"" according to the prior question. ( Interpretation of confidence interval ) I've read the QA but still not gotten to the point. I am not the same person who asked the previous question, but I came upon quite a similar interpretation problem on confidence interval (CI). Mine was why CI needs to be an INTERVAL while we can find arbitrary candidate of 90% or 95% area that contains the true value. This question is partly solved. Above in the very old post, the answer quoted ""Although the various methods are equal from a purely mathematical point of view, the standard method of computing confidence intervals has two desirable properties: each interval is symmetric about the point estimate and each interval is contiguous."" But these listed desirable properties of CI, 1) symmetry and 2) contiguity, do not seem theoretically apparent. Of course, CI is one of the expressions on confidence of an estimator, so these two properties should be full-filled so that CI is human-friendly. But don't we have any further reasons why we choose contiguous symmetric interval for representation of an estimation? (for frequentist?) The reason why this thing is not so much discussed in the quoted article ( http://onlinestatbook.com/2/estimation/confidence.html ) might be partially because CI is often used to show the results of an research and decision making but not directly adopted for future experimental or statistical refinement. But, I want to make clear why the prefered summarized expression of confidence (which is Confidence Interval: CI) should be symmetric (in some sense, in some scale) about the point estimate and contiguous from theoretical, practical and decision making perspectives. The topic may have something to do with Equal-Tail Interval (ETI, one of Credible Interval: CI) in Bayesian interpretation. I am quite a beginner in statistics, so the actual point might be ""In what sense Equal-Tail Interval (for Bayesian) is desirable (for frequentist?)"" or ""Equal-Tail Interval preserves & well-summarize something of the posterior distribution (and if ETI were to be used as a kind of prior in frequentist perspectives, would preserve something?)"". Maybe since I started statistics from Bayesian, I cannot catch up with frequentist approach, so I'm sorry that I only have very vague ideas about these things, but please mention anything. Let me summarize. Why should Confidence Interval: CI (not Credible Interval) symmetric and contiguous? Thank you. P.S. In a declined answer, I found CI like $(-\infty, \alpha)$ is less informative than conventional CIs. But if we consider only the property of 95% confidence, there’s no difference between conventional CI and weird ones (or weird expression of confidence). Something is making conventional CI (contiguous & probability-symmetric ) more informative & well-summarizing. Then, I understood the point is “how CI could be good summary of statistical results”. CI by definition is equal-tail & probability-symmetric , so this property might be enough to decode the point estimate as well as variance of the estimator to some extent on a given distribution. (ex $\sigma^2$ estimation by $\chi^2$ -dist) Is this part of reasons why CI as a summary of data need to be contiguous and probability-symmetric ? Uh…","This post could be entitled as ""Interpretation of confidence interval 2"" according to the prior question. ( Interpretation of confidence interval ) I've read the QA but still not gotten to the point. I am not the same person who asked the previous question, but I came upon quite a similar interpretation problem on confidence interval (CI). Mine was why CI needs to be an INTERVAL while we can find arbitrary candidate of 90% or 95% area that contains the true value. This question is partly solved. Above in the very old post, the answer quoted ""Although the various methods are equal from a purely mathematical point of view, the standard method of computing confidence intervals has two desirable properties: each interval is symmetric about the point estimate and each interval is contiguous."" But these listed desirable properties of CI, 1) symmetry and 2) contiguity, do not seem theoretically apparent. Of course, CI is one of the expressions on confidence of an estimator, so these two properties should be full-filled so that CI is human-friendly. But don't we have any further reasons why we choose contiguous symmetric interval for representation of an estimation? (for frequentist?) The reason why this thing is not so much discussed in the quoted article ( http://onlinestatbook.com/2/estimation/confidence.html ) might be partially because CI is often used to show the results of an research and decision making but not directly adopted for future experimental or statistical refinement. But, I want to make clear why the prefered summarized expression of confidence (which is Confidence Interval: CI) should be symmetric (in some sense, in some scale) about the point estimate and contiguous from theoretical, practical and decision making perspectives. The topic may have something to do with Equal-Tail Interval (ETI, one of Credible Interval: CI) in Bayesian interpretation. I am quite a beginner in statistics, so the actual point might be ""In what sense Equal-Tail Interval (for Bayesian) is desirable (for frequentist?)"" or ""Equal-Tail Interval preserves & well-summarize something of the posterior distribution (and if ETI were to be used as a kind of prior in frequentist perspectives, would preserve something?)"". Maybe since I started statistics from Bayesian, I cannot catch up with frequentist approach, so I'm sorry that I only have very vague ideas about these things, but please mention anything. Let me summarize. Why should Confidence Interval: CI (not Credible Interval) symmetric and contiguous? Thank you. P.S. In a declined answer, I found CI like is less informative than conventional CIs. But if we consider only the property of 95% confidence, there’s no difference between conventional CI and weird ones (or weird expression of confidence). Something is making conventional CI (contiguous & probability-symmetric ) more informative & well-summarizing. Then, I understood the point is “how CI could be good summary of statistical results”. CI by definition is equal-tail & probability-symmetric , so this property might be enough to decode the point estimate as well as variance of the estimator to some extent on a given distribution. (ex estimation by -dist) Is this part of reasons why CI as a summary of data need to be contiguous and probability-symmetric ? Uh…","(-\infty, \alpha) \sigma^2 \chi^2","['statistics', 'statistical-inference', 'bayesian', 'confidence-interval']"
39,Does the law of large numbers hold for covering numbers?,Does the law of large numbers hold for covering numbers?,,"I am self-studying empirical process theory. I have encountered the covering number $N(\delta,\mathcal{G},P)$ , as well as the empirical version $N(\delta,\mathcal{G},P_n)$ . It seems intuitive to expect some kind of convergence: $$ N(\delta,\mathcal{G},P_n)\rightarrow N(\delta,\mathcal{G},P) $$ Yet, I have no idea how to prove this. Can such a result be shown? Or are there counterexamples? Definitions Covering number: Let $P$ be a probability measure on the Borel- $\sigma$ -algebra over $\mathbb{R}$ . For $p\in[1,\infty)$ let $L^p(P)$ be the set of Borel-measurable mappings $\mathbb{R}\rightarrow\mathbb{R}$ , for which $\int_\mathbb{R} |f|^p dP<\infty$ . Let $\mathcal{G}$ be a totally bounded subset of $L^p(P)$ . For some $\delta>0$ , we can define the covering number of $\mathcal{G}$ as the smallest $N\in\mathbb{N}$ , such that there exists a finite subset $G\subset \mathcal{G}$ with the following property: For any $g\in\mathcal{G}$ , there exists a $h\in G$ , such that $||g-h||_p<\delta$ . This number is denoted by $N(\delta,\mathcal{G},P)$ . Empirical measure: Let $P$ be as above. Let $\{X_n\}_{n\in\mathbb{N}}$ be a sequence of independent $P$ -distributed random variables. If $\delta_{X_i}$ denotes the dirac-measure, the empirical measure $P_n$ is defined as: $$ P_n:\mathcal{B}(\mathbb{R})\rightarrow[0,1],\quad E\mapsto \frac{1}{n}\sum_{i=1}^n\delta_{X_i}(E) $$","I am self-studying empirical process theory. I have encountered the covering number , as well as the empirical version . It seems intuitive to expect some kind of convergence: Yet, I have no idea how to prove this. Can such a result be shown? Or are there counterexamples? Definitions Covering number: Let be a probability measure on the Borel- -algebra over . For let be the set of Borel-measurable mappings , for which . Let be a totally bounded subset of . For some , we can define the covering number of as the smallest , such that there exists a finite subset with the following property: For any , there exists a , such that . This number is denoted by . Empirical measure: Let be as above. Let be a sequence of independent -distributed random variables. If denotes the dirac-measure, the empirical measure is defined as:","N(\delta,\mathcal{G},P) N(\delta,\mathcal{G},P_n) 
N(\delta,\mathcal{G},P_n)\rightarrow N(\delta,\mathcal{G},P)
 P \sigma \mathbb{R} p\in[1,\infty) L^p(P) \mathbb{R}\rightarrow\mathbb{R} \int_\mathbb{R} |f|^p dP<\infty \mathcal{G} L^p(P) \delta>0 \mathcal{G} N\in\mathbb{N} G\subset \mathcal{G} g\in\mathcal{G} h\in G ||g-h||_p<\delta N(\delta,\mathcal{G},P) P \{X_n\}_{n\in\mathbb{N}} P \delta_{X_i} P_n 
P_n:\mathcal{B}(\mathbb{R})\rightarrow[0,1],\quad E\mapsto \frac{1}{n}\sum_{i=1}^n\delta_{X_i}(E)
","['statistics', 'machine-learning', 'probability-limit-theorems', 'law-of-large-numbers', 'empirical-processes']"
40,Bayesian Interpretation for Ridge Regression and the Lasso,Bayesian Interpretation for Ridge Regression and the Lasso,,"I'm learning the book ""Introduction to Statistical Learning"" and in the Chapter 6 about ""Linear Model Selection and Regularization"", there is a small part about ""Bayesian Interpretation for Ridge Regression and the Lasso"" that I haven't understood the reasoning. A Bayesian viewpoint for regression assumes that the coefficient vector $\beta$ has some prior distribution, say $p(\beta)$ , where $\beta = (\beta_0, \beta_1, \dots, \beta_p)^\top$ . The likelihood of the data can be written as $f(Y|X, \beta)$ , where $X = (X_1, X_2, \dots, X_p)$ . Multiplying the prior distribution by the likelihood gives us (up to a proportionality constant) the posterior distribution, which takes the form $$p(\beta|X, Y) \propto f(Y|X,\beta)p(\beta|X) = f(Y|X, \beta)p(\beta),$$ where the proportionality above follows from Bayes’ theorem, and the equality above follows from the assumption that X is fixed. The authors assume the linear model: $$Y = \beta_0 + X_1\beta_1 + \dots + X_p\beta_p + \epsilon,$$ and suppose the errors are independent and drawn from a normal distribution. There is also assumption that $p(\beta) = \prod_{j=1}^p g(\beta_j)$ for some density function $g$ . Then from those points, It turns out that ridge regression and the lasso follow naturally from two special cases of $g$ : If $g$ is a Gaussian distribution with mean zero and standard deviation a function of $\lambda$ , then it follows that the posterior mode for $\beta$ $-$ that is, the most likely value for $\beta$ , given the data—is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.) If $g$ is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of $\lambda$ , then it follows that the posterior mode for $\beta$ is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a sparse coefficient vector.) I don't understand why ridge regression and the lasso follow 2 special cases of $g$ like that and why they have such distribution. Would anyone please help me explain this? Thank you so much in advance for all your help!","I'm learning the book ""Introduction to Statistical Learning"" and in the Chapter 6 about ""Linear Model Selection and Regularization"", there is a small part about ""Bayesian Interpretation for Ridge Regression and the Lasso"" that I haven't understood the reasoning. A Bayesian viewpoint for regression assumes that the coefficient vector has some prior distribution, say , where . The likelihood of the data can be written as , where . Multiplying the prior distribution by the likelihood gives us (up to a proportionality constant) the posterior distribution, which takes the form where the proportionality above follows from Bayes’ theorem, and the equality above follows from the assumption that X is fixed. The authors assume the linear model: and suppose the errors are independent and drawn from a normal distribution. There is also assumption that for some density function . Then from those points, It turns out that ridge regression and the lasso follow naturally from two special cases of : If is a Gaussian distribution with mean zero and standard deviation a function of , then it follows that the posterior mode for that is, the most likely value for , given the data—is given by the ridge regression solution. (In fact, the ridge regression solution is also the posterior mean.) If is a double-exponential (Laplace) distribution with mean zero and scale parameter a function of , then it follows that the posterior mode for is the lasso solution. (However, the lasso solution is not the posterior mean, and in fact, the posterior mean does not yield a sparse coefficient vector.) I don't understand why ridge regression and the lasso follow 2 special cases of like that and why they have such distribution. Would anyone please help me explain this? Thank you so much in advance for all your help!","\beta p(\beta) \beta = (\beta_0, \beta_1, \dots, \beta_p)^\top f(Y|X, \beta) X = (X_1, X_2, \dots, X_p) p(\beta|X, Y) \propto f(Y|X,\beta)p(\beta|X) = f(Y|X, \beta)p(\beta), Y = \beta_0 + X_1\beta_1 + \dots + X_p\beta_p + \epsilon, p(\beta) = \prod_{j=1}^p g(\beta_j) g g g \lambda \beta - \beta g \lambda \beta g","['statistics', 'machine-learning', 'linear-regression']"
41,Degrees of Freedom in Covariance: Intuition?,Degrees of Freedom in Covariance: Intuition?,,"If we say $\operatorname{Var}(x)$ has $n-1$ degrees of freedom which are lost after we estimate $\operatorname{Var}(x)$ , this matches how $n-1$ observations are now constrained to be sufficiently close to the remaining observation of $x$ . In my class, $\operatorname{Cov}(x,y)$ is also described as having $n-1$ degrees of freedom which are lost after we estimate $\operatorname{Cov}(x,y)$ . Reference for this use of ""degrees of freedom"" in covariance My confusion is that the covariance does not actually seem to constrain $n-1$ $x$ and $y$ values, like the variance did for $x$ . Can you relate the $n-1$ degrees of freedom in covariance and the intuition for degrees of freedom as how many observations are not free to change after estimating $\operatorname{Cov}(x,y)$ ? Is it possible to explain by counting newly restricted observations, like when explaining why the sample mean has degree of freedom $1,$ or variance degrees of freedom $n-1$ ? The second related question is about the explanation in the reference linked above: ""Initially, we have $2n$ degrees of freedom in the bivariate data. We   lose two by computing the sample means $m(x)$ and $m(y)$ . Of the   remaining $2n−2$ degrees of freedom, we lose $n−1$ by computing the   product deviations. Thus, we are left with $n−1$ degrees of freedom   total."" Do you see what are the ""product deviations"" and how does each one ""lose"" a degree of freedom?","If we say has degrees of freedom which are lost after we estimate , this matches how observations are now constrained to be sufficiently close to the remaining observation of . In my class, is also described as having degrees of freedom which are lost after we estimate . Reference for this use of ""degrees of freedom"" in covariance My confusion is that the covariance does not actually seem to constrain and values, like the variance did for . Can you relate the degrees of freedom in covariance and the intuition for degrees of freedom as how many observations are not free to change after estimating ? Is it possible to explain by counting newly restricted observations, like when explaining why the sample mean has degree of freedom or variance degrees of freedom ? The second related question is about the explanation in the reference linked above: ""Initially, we have degrees of freedom in the bivariate data. We   lose two by computing the sample means and . Of the   remaining degrees of freedom, we lose by computing the   product deviations. Thus, we are left with degrees of freedom   total."" Do you see what are the ""product deviations"" and how does each one ""lose"" a degree of freedom?","\operatorname{Var}(x) n-1 \operatorname{Var}(x) n-1 x \operatorname{Cov}(x,y) n-1 \operatorname{Cov}(x,y) n-1 x y x n-1 \operatorname{Cov}(x,y) 1, n-1 2n m(x) m(y) 2n−2 n−1 n−1","['statistics', 'intuition', 'estimation', 'covariance']"
42,Multivariate Gaussian equivalent for a Gaussian integration identity.,Multivariate Gaussian equivalent for a Gaussian integration identity.,,"For a one-dimensional x, $$\int_{-\infty}^{\infty}x^{2}e^{-x^{2}}dx=\frac{1}{2}\int_{-\infty}^{\infty}e^{-x^{2}}dx$$ This can be shown through integration by parts. There is a good derivation of that here . I'm wondering, does the same exist for a multivariate Gaussian $$\ p(x|\mu,\Sigma)=\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)$$ Where $\Sigma$ (positive-definite) is the variance and  $\mu$ is the mean. Here, I'm using $N$ for the dimension of $x$. That is, does $$\int\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\left[-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right]\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)dx$$ $$=\frac{1}{2}\int\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)dx$$ ? My first thought is that the identity should be identical because after carrying out the inner products ""upstairs"" in the exponential and ""downstairs"" in the coefficient, it becomes a positive scalar. This calculation is involved in determining the differential entropy of a multivariate Gaussian. For my answer to agree with the answer given in theorem 9.4.1 here , there should be an additional factor of N on the right hand side.","For a one-dimensional x, $$\int_{-\infty}^{\infty}x^{2}e^{-x^{2}}dx=\frac{1}{2}\int_{-\infty}^{\infty}e^{-x^{2}}dx$$ This can be shown through integration by parts. There is a good derivation of that here . I'm wondering, does the same exist for a multivariate Gaussian $$\ p(x|\mu,\Sigma)=\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)$$ Where $\Sigma$ (positive-definite) is the variance and  $\mu$ is the mean. Here, I'm using $N$ for the dimension of $x$. That is, does $$\int\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\left[-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right]\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)dx$$ $$=\frac{1}{2}\int\left(2\pi\right)^{-\frac{N}{2}}|\Sigma|^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(x-\mu)^{\textrm{T}}\Sigma^{-1}(x-\mu)\right)dx$$ ? My first thought is that the identity should be identical because after carrying out the inner products ""upstairs"" in the exponential and ""downstairs"" in the coefficient, it becomes a positive scalar. This calculation is involved in determining the differential entropy of a multivariate Gaussian. For my answer to agree with the answer given in theorem 9.4.1 here , there should be an additional factor of N on the right hand side.",,"['statistics', 'multivariable-calculus', 'machine-learning', 'multilinear-algebra']"
43,How to find a flat using game theory?,How to find a flat using game theory?,,"I had the idea that maybe probability/game theory knowledge helps finding a flat more systematically. I assume that I have some online offers with number parameters: prize size (square meters) distance (to work in minutes) I have some limits for all of them, but there are still many offers remaining. Unfortunately, I have to decide immediately if I take a flat or not since otherwise it will be gone. My main idea is to estimate how much more I can contraint these three parameters numerically and still find a flat within some reasonable time. Basically I define a stronger ""soft limit"" rather than the neccessary ""hard limit"". If I filter out too much, there will be too few offers and the search would take too long. From watching the offers I can estimate the distribution of these three parameters. Of course there are more non-numerical parameters so just being within range doesn't qualify the flat completely. It still might be dismissed, due to other factors. Any suggestions? (I know about the related ""Secretary problem"", but it wouldn't give me new limit numbers. And here, I wish a cardinal approach, rather than an ordinal approach)","I had the idea that maybe probability/game theory knowledge helps finding a flat more systematically. I assume that I have some online offers with number parameters: prize size (square meters) distance (to work in minutes) I have some limits for all of them, but there are still many offers remaining. Unfortunately, I have to decide immediately if I take a flat or not since otherwise it will be gone. My main idea is to estimate how much more I can contraint these three parameters numerically and still find a flat within some reasonable time. Basically I define a stronger ""soft limit"" rather than the neccessary ""hard limit"". If I filter out too much, there will be too few offers and the search would take too long. From watching the offers I can estimate the distribution of these three parameters. Of course there are more non-numerical parameters so just being within range doesn't qualify the flat completely. It still might be dismissed, due to other factors. Any suggestions? (I know about the related ""Secretary problem"", but it wouldn't give me new limit numbers. And here, I wish a cardinal approach, rather than an ordinal approach)",,"['statistics', 'game-theory']"
44,Help with convergence in distribution,Help with convergence in distribution,,"$Y$ is a random variable with $$M(t) = \frac{1}{(2-\exp(t))^s}.$$ Does $$\frac{Y-E(Y)}{\sqrt{\operatorname{Var}(Y)}}$$ converge in distribution as $s$ tends to infinity? I let $Z = \frac{Y-E(Y)}{\sqrt{\operatorname{Var}(Y)}}$. Differentiating the MGF of $Y$ and let $t = 0$ we have $$E(Y) = s,$$$$E(Y^2) = s^2 +2s,$$$$\operatorname{Var}(Y) = 2s.$$ Thus Mgf of Z:  \begin{align*}E(\exp(tz)) &= E\left(\exp\left(\frac{t(y-s)}{\sqrt{2s}}\right)\right)\\ &=E\left(\exp\left(\frac{ty}{\sqrt{2s}}\right)\exp\left(\frac{-ts}{\sqrt{2s}}\right)\right)\\ &=E\left(\exp\left(\frac{ty}{\sqrt{2s}}\right)\exp\left(\frac{-ts}{\sqrt{2s}}\right)\right)\\ &=\exp\left(\frac{-ts}{\sqrt{2s}}\right)\frac{1}{\left(2-\exp\left(\frac{t}{\sqrt{2s}}\right)\right)^s}. \end{align*} But I'm not sure how to proceed - seems to me it tends to $0$?","$Y$ is a random variable with $$M(t) = \frac{1}{(2-\exp(t))^s}.$$ Does $$\frac{Y-E(Y)}{\sqrt{\operatorname{Var}(Y)}}$$ converge in distribution as $s$ tends to infinity? I let $Z = \frac{Y-E(Y)}{\sqrt{\operatorname{Var}(Y)}}$. Differentiating the MGF of $Y$ and let $t = 0$ we have $$E(Y) = s,$$$$E(Y^2) = s^2 +2s,$$$$\operatorname{Var}(Y) = 2s.$$ Thus Mgf of Z:  \begin{align*}E(\exp(tz)) &= E\left(\exp\left(\frac{t(y-s)}{\sqrt{2s}}\right)\right)\\ &=E\left(\exp\left(\frac{ty}{\sqrt{2s}}\right)\exp\left(\frac{-ts}{\sqrt{2s}}\right)\right)\\ &=E\left(\exp\left(\frac{ty}{\sqrt{2s}}\right)\exp\left(\frac{-ts}{\sqrt{2s}}\right)\right)\\ &=\exp\left(\frac{-ts}{\sqrt{2s}}\right)\frac{1}{\left(2-\exp\left(\frac{t}{\sqrt{2s}}\right)\right)^s}. \end{align*} But I'm not sure how to proceed - seems to me it tends to $0$?",,"['statistics', 'probability-distributions']"
45,"Show that the posterior density of ($\mu$, $\tau$) is equal to $f(\mu, \tau | x_1, ..., x_n) = f(\mu| \tau, x_1,...,x_n)f(\tau|x_1,...x_n)$","Show that the posterior density of (, ) is equal to","\mu \tau f(\mu, \tau | x_1, ..., x_n) = f(\mu| \tau, x_1,...,x_n)f(\tau|x_1,...x_n)","Here is the full problem: Let $X_1,...,X_n$ be a random sample from a $N(\mu,\sigma^2)$ distribution. Let $\tau = \sigma^{-2}$, so we can write the distribution as $N(\mu,\tau^{-1})$. Suppose the prior for $(\mu,\tau)$ has density $f(\mu,\tau) \propto 1$, $-\infty < \mu < \infty$, $0 < \tau < \infty$. Note that this is an improper prior density. Show that the posterior density of $(\mu,\tau)$ is equal to: $$f(\mu, \tau|x_1,...,x_n) = f(\mu|\tau,x_1,...,x_n)  f(\tau|x_1,...,x_n)\;.$$ where $$f(\mu|\tau,x_1,...,x_n) \sim N(\bar{x},(\tau \  n)^{-1})\;$$ and $$f(\tau|x_1,...,x_n) \sim \text{Gamma}(\frac{n-1}{2},(\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{2})^{-1})$$ I have tried to break down the problem using the standard Bayesian method, but I am having trouble figuring out how we can ""split"" the density up.  Thanks in advance.","Here is the full problem: Let $X_1,...,X_n$ be a random sample from a $N(\mu,\sigma^2)$ distribution. Let $\tau = \sigma^{-2}$, so we can write the distribution as $N(\mu,\tau^{-1})$. Suppose the prior for $(\mu,\tau)$ has density $f(\mu,\tau) \propto 1$, $-\infty < \mu < \infty$, $0 < \tau < \infty$. Note that this is an improper prior density. Show that the posterior density of $(\mu,\tau)$ is equal to: $$f(\mu, \tau|x_1,...,x_n) = f(\mu|\tau,x_1,...,x_n)  f(\tau|x_1,...,x_n)\;.$$ where $$f(\mu|\tau,x_1,...,x_n) \sim N(\bar{x},(\tau \  n)^{-1})\;$$ and $$f(\tau|x_1,...,x_n) \sim \text{Gamma}(\frac{n-1}{2},(\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{2})^{-1})$$ I have tried to break down the problem using the standard Bayesian method, but I am having trouble figuring out how we can ""split"" the density up.  Thanks in advance.",,['statistics']
46,Is the Fisher-Information even continuous in a regular statistical model?,Is the Fisher-Information even continuous in a regular statistical model?,,"Definition (Regular Model [1, p. 203]). A standard statistical model $\big( X, \mathcal F, (\mathbb P_{\vartheta})_{\vartheta \in \Theta}\big)$ , where $\Theta \subset \mathbb R$ is an open interval, $X \ne \emptyset$ , $\mathcal F$ is a $\sigma$ -algebra on $ X$ and $\mathbb P_{\vartheta}$ is a probability measure on $( X, \mathcal F)$ for every $\vartheta \in \Theta$ such that there exists a measure $\mu_0$ with $\mathbb P_{\vartheta} \ll \mu_0$ ( absolute continuity ) for all $\vartheta \in \Theta$ is regular , if the likelihood function $$\rho \colon X \times \Theta \to \mathbb{R}, \qquad (x, \vartheta) \mapsto \frac{\text{d} \mathbb P_{\vartheta}}{\text{d} \mu_0}(x)$$ ( Radon-Nikodym derivative ) is positive and continuously differentiable (almost everyhwere) with respect to $\vartheta$ . Then the score $$ U_{\vartheta}(x) := \frac{\partial}{\partial \vartheta} \ln\big(\rho(x, \vartheta)\big) = \frac{\frac{\partial}{\partial \vartheta} \rho(x, \vartheta)}{ \rho(x, \vartheta)} $$ is well defined. For a regular model, we also require that the Fisher information of the model $I(\vartheta) := \mathbb{V}_{\vartheta}[U_{\vartheta}]$ , where $V_{\vartheta}$ is the variance with respect to $\mathbb P_{\vartheta}$ , is always an element of $(0, \infty)$ and that \begin{equation} \int_{ X} \frac{\partial}{\partial \vartheta} \rho(x, \vartheta) \, \text{d}{\mu_0(x)} \overset{!}{=} \frac{\partial}{\partial \vartheta} \underbrace{\int_{ X} \rho(x, \vartheta) \, \text{d}{\mu_0(x)}}_{= 1} = 0 \end{equation} holds, where we require that the left side is well defined, that is, that $\frac{\partial}{\partial \vartheta} \rho(\cdot, \vartheta)$ is integrable with respect to $\mu_0$ . It is not difficult to show that $\mathbb{E}_{\vartheta}[U_{\vartheta}^2] = 0$ and thus that $I$ is lower continuous due to Fatou's Lemma ). My question: Is $I$ even continuous? Remark. The proof of the Cramér-Rao inequality one shows that if that the inequality is an equality, then $I$ is continuous, but the requirements of that theorem are, among others, that the estimator is regular and that the expected value of the estimator with respect to $\mathbb P_{\vartheta}$ is continuously differentiable with respect to $\vartheta$ with pointwise non-vanishing derivative. 1 Georgii, Hans-Otto , Stochastics. Introduction to probability and statistics. Translated by Marcel Ortgiese, Ellen Baake and the author. , de Gruyter Textbook. Berlin: de Gruyter (ISBN 978-3-11-019145-5/pbk; 978-3-11-020676-0/ebook). ix, 370 p. (2008). ZBL1270.62005 .","Definition (Regular Model [1, p. 203]). A standard statistical model , where is an open interval, , is a -algebra on and is a probability measure on for every such that there exists a measure with ( absolute continuity ) for all is regular , if the likelihood function ( Radon-Nikodym derivative ) is positive and continuously differentiable (almost everyhwere) with respect to . Then the score is well defined. For a regular model, we also require that the Fisher information of the model , where is the variance with respect to , is always an element of and that holds, where we require that the left side is well defined, that is, that is integrable with respect to . It is not difficult to show that and thus that is lower continuous due to Fatou's Lemma ). My question: Is even continuous? Remark. The proof of the Cramér-Rao inequality one shows that if that the inequality is an equality, then is continuous, but the requirements of that theorem are, among others, that the estimator is regular and that the expected value of the estimator with respect to is continuously differentiable with respect to with pointwise non-vanishing derivative. 1 Georgii, Hans-Otto , Stochastics. Introduction to probability and statistics. Translated by Marcel Ortgiese, Ellen Baake and the author. , de Gruyter Textbook. Berlin: de Gruyter (ISBN 978-3-11-019145-5/pbk; 978-3-11-020676-0/ebook). ix, 370 p. (2008). ZBL1270.62005 .","\big( X, \mathcal F, (\mathbb P_{\vartheta})_{\vartheta \in \Theta}\big) \Theta \subset \mathbb R X \ne \emptyset \mathcal F \sigma  X \mathbb P_{\vartheta} ( X, \mathcal F) \vartheta \in \Theta \mu_0 \mathbb P_{\vartheta} \ll \mu_0 \vartheta \in \Theta \rho \colon X \times \Theta \to \mathbb{R}, \qquad (x, \vartheta) \mapsto \frac{\text{d} \mathbb P_{\vartheta}}{\text{d} \mu_0}(x) \vartheta 
U_{\vartheta}(x)
:= \frac{\partial}{\partial \vartheta} \ln\big(\rho(x, \vartheta)\big)
= \frac{\frac{\partial}{\partial \vartheta} \rho(x, \vartheta)}{ \rho(x, \vartheta)}
 I(\vartheta) := \mathbb{V}_{\vartheta}[U_{\vartheta}] V_{\vartheta} \mathbb P_{\vartheta} (0, \infty) \begin{equation}
\int_{ X} \frac{\partial}{\partial \vartheta} \rho(x, \vartheta) \, \text{d}{\mu_0(x)}
\overset{!}{=} \frac{\partial}{\partial \vartheta} \underbrace{\int_{ X} \rho(x, \vartheta) \, \text{d}{\mu_0(x)}}_{= 1}
= 0
\end{equation} \frac{\partial}{\partial \vartheta} \rho(\cdot, \vartheta) \mu_0 \mathbb{E}_{\vartheta}[U_{\vartheta}^2] = 0 I I I \mathbb P_{\vartheta} \vartheta","['statistics', 'continuity', 'variance', 'parameter-estimation', 'fisher-information']"
47,Original reference by Esseen for Berry-Esseen theorem,Original reference by Esseen for Berry-Esseen theorem,,"Does someone have an idea of where I can find an officially published text of the following seminal article by Esseen? ""Esseen, Carl-Gustav (1942). ""On the Liapunoff limit of error in the theory of probability"". Arkiv för Matematik, Astronomi och Fysik. A28: 1–19. ISSN 0365-4133"" I cannot find it. I can only find this short review by Feller. https://mathscinet.ams.org/mathscinet-getitem?mr=11909 It would be astounding to me if there were no way to access such an important paper.","Does someone have an idea of where I can find an officially published text of the following seminal article by Esseen? ""Esseen, Carl-Gustav (1942). ""On the Liapunoff limit of error in the theory of probability"". Arkiv för Matematik, Astronomi och Fysik. A28: 1–19. ISSN 0365-4133"" I cannot find it. I can only find this short review by Feller. https://mathscinet.ams.org/mathscinet-getitem?mr=11909 It would be astounding to me if there were no way to access such an important paper.",,"['statistics', 'central-limit-theorem', 'large-deviation-theory']"
48,What is the expected value of the inverse of a Wishart matrix plus a scaled identity matrix?,What is the expected value of the inverse of a Wishart matrix plus a scaled identity matrix?,,"I'm trying to find the following: $$\mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right]$$ where $\mathbf{W}\sim\mathcal{W}_{p}(n,\mathbf{\Sigma})$ is Wishart-distributed, $\lambda\ge 0$ is a constant, and $\mathbf{I}$ is the identity matrix.  It is known (e.g. Das Gupta, 1968) that $\mathbb{E}\left[\mathbf{W}^{-1}\right]=\frac{\mathbf{\Sigma}^{-1}}{n-p-1}$ , and the expected value of the inverse of a non-central Wishart matrix is also known (Hillier, 2019).  However, it's not clear how $\mathbf{W}+\lambda\mathbf{I}$ could be expressed as a non-central Wishart-distributed matrix. Approximations would also be useful, and I have tried $$\mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right]\approx\mathbb{E}\left[\mathbf{W}^{-1}\right]-\lambda\mathbb{E}\left[\mathbf{W}^{-2}\right]+\lambda^{2}\mathbb{E}\left[\mathbf{W}^{-3}\right]+\mathcal{O}(\lambda^{3})$$ The higher order moments of the inverted Wishart are known (Von Rosen, 1988), so this can be calculated, but the estimate is only valid for very small $\lambda$ , especially when $p$ is close to $n$ . References: Das Gupta, S., ""Some aspects of discrimination function coefficients,"" The Indian Journal of Statistics , Vol. 30, No. 4, 1968. Hillier, G. et al., ""Properties of the inverse of a noncentral Wishart matrix,"" Available at SSRN 3370864 , 2019. Von Rosen, D., ""Moments for the inverted Wishart distribution,"" Scandinavian Journal of Statistics , Vol. 15, No. 2, pp. 97-109, 1988.","I'm trying to find the following: where is Wishart-distributed, is a constant, and is the identity matrix.  It is known (e.g. Das Gupta, 1968) that , and the expected value of the inverse of a non-central Wishart matrix is also known (Hillier, 2019).  However, it's not clear how could be expressed as a non-central Wishart-distributed matrix. Approximations would also be useful, and I have tried The higher order moments of the inverted Wishart are known (Von Rosen, 1988), so this can be calculated, but the estimate is only valid for very small , especially when is close to . References: Das Gupta, S., ""Some aspects of discrimination function coefficients,"" The Indian Journal of Statistics , Vol. 30, No. 4, 1968. Hillier, G. et al., ""Properties of the inverse of a noncentral Wishart matrix,"" Available at SSRN 3370864 , 2019. Von Rosen, D., ""Moments for the inverted Wishart distribution,"" Scandinavian Journal of Statistics , Vol. 15, No. 2, pp. 97-109, 1988.","\mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right] \mathbf{W}\sim\mathcal{W}_{p}(n,\mathbf{\Sigma}) \lambda\ge 0 \mathbf{I} \mathbb{E}\left[\mathbf{W}^{-1}\right]=\frac{\mathbf{\Sigma}^{-1}}{n-p-1} \mathbf{W}+\lambda\mathbf{I} \mathbb{E}\left[\left(\mathbf{W}+\lambda\mathbf{I}\right)^{-1}\right]\approx\mathbb{E}\left[\mathbf{W}^{-1}\right]-\lambda\mathbb{E}\left[\mathbf{W}^{-2}\right]+\lambda^{2}\mathbb{E}\left[\mathbf{W}^{-3}\right]+\mathcal{O}(\lambda^{3}) \lambda p n","['statistics', 'expected-value']"
49,Distribution of sample variance of Cauchy distributed variables,Distribution of sample variance of Cauchy distributed variables,,"Assume $X_i,i\in\left\{1,...,n\right\}$ are i.i.d. standard Cauchy distributed random variables. I know that $\bar{X}_n:=\frac{1}{n}\sum_{i=1}^n X_i$ is standard Cauchy distributed. I would like to know the distribution of the sample variance $$ \frac{1}{n}\sum_{i=1}^n \left(X_i-\bar{X}_n\right)^2 .$$ My foreknowledge: I know that moments like $\mathbb{E}(X),\mathbb{V}(X)$ do not exist for Cauchy distributed $X$ . I know that linear combinations of independent Cauchy random variables is Cauchy distributed as well. Weaker question: If nobody knows the exact distribution of the sample variance, it would be interesting if the distribution is independent of number of samples $n$ ? Like the distribution of the sample mean $\bar{X}_n$ does not depend on $n$ as it is always standard Cauchy for all $n$ . In  the Cauchy distribution Wikipedia article it says: Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. but I think this statement is not correct, because they use a similar (in my opinion very bad) formulation for the sample mean: the sample mean will become increasingly variable as more observations are taken which is not a correct statement, as the distribution of the sample mean $\bar{X}_n$ does not depend on $n$ . After reading the whole (in my opinion very badly written) paragraph Although the sample values $x_{i}$ will be concentrated about the central value $ x_{0}$ , the sample mean will become increasingly variable as more observations are taken, because of the increased probability of encountering sample points with a large absolute value. In fact, the distribution of the sample mean will be equal to the distribution of the observations themselves; i.e., the sample mean of a large sample is no better (or worse) an estimator of $x_{0}$ than any single observation from the sample. Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. I am really not sure what the author of this article wanted to express how the distribution of the sample variance depends on the number of samples $n$ . Do you know more about the distribution of the sample variance of $n$ i.i.d Cauchy distributed random variables?","Assume are i.i.d. standard Cauchy distributed random variables. I know that is standard Cauchy distributed. I would like to know the distribution of the sample variance My foreknowledge: I know that moments like do not exist for Cauchy distributed . I know that linear combinations of independent Cauchy random variables is Cauchy distributed as well. Weaker question: If nobody knows the exact distribution of the sample variance, it would be interesting if the distribution is independent of number of samples ? Like the distribution of the sample mean does not depend on as it is always standard Cauchy for all . In  the Cauchy distribution Wikipedia article it says: Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. but I think this statement is not correct, because they use a similar (in my opinion very bad) formulation for the sample mean: the sample mean will become increasingly variable as more observations are taken which is not a correct statement, as the distribution of the sample mean does not depend on . After reading the whole (in my opinion very badly written) paragraph Although the sample values will be concentrated about the central value , the sample mean will become increasingly variable as more observations are taken, because of the increased probability of encountering sample points with a large absolute value. In fact, the distribution of the sample mean will be equal to the distribution of the observations themselves; i.e., the sample mean of a large sample is no better (or worse) an estimator of than any single observation from the sample. Similarly, calculating the sample variance will result in values that grow larger as more observations are taken. I am really not sure what the author of this article wanted to express how the distribution of the sample variance depends on the number of samples . Do you know more about the distribution of the sample variance of i.i.d Cauchy distributed random variables?","X_i,i\in\left\{1,...,n\right\} \bar{X}_n:=\frac{1}{n}\sum_{i=1}^n X_i  \frac{1}{n}\sum_{i=1}^n \left(X_i-\bar{X}_n\right)^2 . \mathbb{E}(X),\mathbb{V}(X) X n \bar{X}_n n n \bar{X}_n n x_{i}  x_{0} x_{0} n n","['statistics', 'probability-distributions']"
50,Show that the Normal distribution is a member of the exponential family,Show that the Normal distribution is a member of the exponential family,,"I want to show that the Normal distribution is a member of the exponential family. I have been working under the assumption that a distribution is a member of the exponential family if its pdf/pmf can be transformed into the form: $f(x|\theta) = h(x)c(\theta)\exp\{\sum\limits_{i=1}^{k} w_{i}(\theta)t_{i}(x)\}$ This is my approach: $f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp\{-\frac{(x-\mu)^2}{2 \sigma^2}\}$ Taking the logs: $\log f(x|\mu, \sigma^2) = -\frac{1}{2}\log(2\pi\sigma^2) - \frac{(x-\mu)^2}{2 \sigma^2}$ Taking the exponential: $f(x|\mu, \sigma^2) = \exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{(x-\mu)^2}{2\sigma^2}\}$ = $\exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{(x^2 -2\mu + \mu^2)}{2\sigma^2}\}$ = $\exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{x^2}{2\sigma^2} + \frac{2x\mu}{2\sigma^2} - \frac{\mu^2}{2\sigma^2}\}$ = $\exp\{-\frac{1}{2}\log(2\pi\sigma^2)\} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\}$ = $\frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\}$ = $\frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{\mu^2}{2\sigma^2}\} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2}\}$ Now I have: $c(\theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{\mu^2}{2\sigma^2}\}$ , $w_{1}(\theta) = -\frac{1}{2\sigma^2}$ , $t_{1}(x) = x^2$ , $w_{2}(\theta) = \frac{\mu}{\sigma^2}$ , $t_{1}(x) = x$ But I am missing $h(x)$ . Am I missing something?","I want to show that the Normal distribution is a member of the exponential family. I have been working under the assumption that a distribution is a member of the exponential family if its pdf/pmf can be transformed into the form: This is my approach: Taking the logs: Taking the exponential: = = = = = Now I have: , , , , But I am missing . Am I missing something?","f(x|\theta) = h(x)c(\theta)\exp\{\sum\limits_{i=1}^{k} w_{i}(\theta)t_{i}(x)\} f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp\{-\frac{(x-\mu)^2}{2 \sigma^2}\} \log f(x|\mu, \sigma^2) = -\frac{1}{2}\log(2\pi\sigma^2) - \frac{(x-\mu)^2}{2 \sigma^2} f(x|\mu, \sigma^2) = \exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{(x-\mu)^2}{2\sigma^2}\} \exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{(x^2 -2\mu + \mu^2)}{2\sigma^2}\} \exp\{-\frac{1}{2}\log(2\pi\sigma^2)-\frac{x^2}{2\sigma^2} + \frac{2x\mu}{2\sigma^2} - \frac{\mu^2}{2\sigma^2}\} \exp\{-\frac{1}{2}\log(2\pi\sigma^2)\} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{\mu^2}{2\sigma^2}\} \exp\{-\frac{x^2}{2\sigma^2} + \frac{x\mu}{\sigma^2}\} c(\theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{\mu^2}{2\sigma^2}\} w_{1}(\theta) = -\frac{1}{2\sigma^2} t_{1}(x) = x^2 w_{2}(\theta) = \frac{\mu}{\sigma^2} t_{1}(x) = x h(x)","['statistics', 'normal-distribution']"
51,When to use cumulative moving average vs a simple moving average?,When to use cumulative moving average vs a simple moving average?,,"After reviewing the Wikipedia page on moving averages , the difference between the simple moving average and cumulative moving average are clear: 1) Simple moving average only considers the last n observations, and for every additional observation added to the average, the oldest one gets dropped 2) Cumulative moving average considers all prior observations However, I am confused as to which moving average to use to smooth out data and identify trends. As seen in the linked picture above, the cumulative moving average is quite distinctly different from both the observations themselves and the 4 period moving average. Is there a rule of thumb of when to use one or the other?","After reviewing the Wikipedia page on moving averages , the difference between the simple moving average and cumulative moving average are clear: 1) Simple moving average only considers the last n observations, and for every additional observation added to the average, the oldest one gets dropped 2) Cumulative moving average considers all prior observations However, I am confused as to which moving average to use to smooth out data and identify trends. As seen in the linked picture above, the cumulative moving average is quite distinctly different from both the observations themselves and the 4 period moving average. Is there a rule of thumb of when to use one or the other?",,['statistics']
52,What is the expected value of sample mean?,What is the expected value of sample mean?,,"I have a simple question.  $X$ is a random variable with mean $μ$, and there is a sample of size $n$: $X_1, X_2, \cdots, X_n$. Then what is the expected value of the sample mean $\overline{X}$? This is what I thought: $$\overline{X} = \frac{1}{n}(X_1+X_2+X_3+\cdots+X_n),$$ thus $\overline{X}$ is a certain value (constant), therefore $E(\overline{X}) =  \overline{X}$. Similarly, $\overline{X}^2$is also a certain value (constant) and $E(\overline{X}^2) = \overline{X}^2$. But it turns out there's something wrong. Could someone please explain it to me? Thanks in advance.","I have a simple question.  $X$ is a random variable with mean $μ$, and there is a sample of size $n$: $X_1, X_2, \cdots, X_n$. Then what is the expected value of the sample mean $\overline{X}$? This is what I thought: $$\overline{X} = \frac{1}{n}(X_1+X_2+X_3+\cdots+X_n),$$ thus $\overline{X}$ is a certain value (constant), therefore $E(\overline{X}) =  \overline{X}$. Similarly, $\overline{X}^2$is also a certain value (constant) and $E(\overline{X}^2) = \overline{X}^2$. But it turns out there's something wrong. Could someone please explain it to me? Thanks in advance.",,['statistics']
53,Variance of the Euclidean norm of a vector of Gaussians,Variance of the Euclidean norm of a vector of Gaussians,,"Given a vector of correlated Gaussian random variables $\vec{X}=\left(X_1, ..., X_k\right)$ that are normally distributed $\vec{X} \sim \mathcal{N}\left(\vec{\mu}, \Sigma\right)$ with arbitrary $\Sigma$ and $\vec{\mu}$ values what's the variance (i.e. the second central moment) of the random variable $\lVert X \lVert_2$? From length of Gaussian Random Vector we know that the general probability density function of $\sqrt{Q(\vec{X})} = \sqrt{X^TAX}$ does not follow any known laws. However I'm only looking for the variance. From the post we know that when analyzing the quadratic form (see linked post) $$ Q(\vec{X})=\sum_{i=1}^k\lambda_i\left(U_i+b_i\right)^2=\sum_{i=1}^k\lambda_i\left(U_i^2 + 2b_iU_i + b_i^2\right) $$ we obtain a superposition of Chi-Squared-Distributions and zero-mean Gaussian distributions since $\vec{U}$ is multivariate normal with identity covariance matrix and expectation zero. Using these rules we obtain: $var\left(U_i^2\right) = 2$ (Chi-Squared) $var\left(U_i\right) = 1$ (uniform Gaussian) $var\left(2b_iU_i\right) = 4b_i^2$ $var\left(b_i^2\right) = 0$ (constant) $cov\left(U_i^2, 2b_iU_i\right) = E\left[2b_iU_i^3\right] = 2b_iE\left[U_i^3\right] = 0$ $cov\left(U_i^2, b_i^2\right) = 0$ $var\left(U_i^2 + 2b_iU_i + b_i^2\right) = 2 + 4b_i^2$, and hence $$var\left(Q(\vec{X})\right) = \sum_{i=1}^k\lambda_i^2(2 + 4b_i^2)$$ So the only step missing would to find $var\left(\sqrt{Q(\vec{X})}\right)$ given $var\left(Q(\vec{X})\right)$. Unfortunately it doesn't appear that simple according to Mean and variance of $\sqrt{X}$ given mean and variance of X . So how to move on with this? Will the definition of the central moment be helpful? Assuming we are able to come up with the pdf of $\sqrt{Q(\vec{X})}$ I'm afraid this might only yield ugly integral terms that are impossible to solve or even approximate in the general case... edit: fixed the variance of Chi-Squared to 2","Given a vector of correlated Gaussian random variables $\vec{X}=\left(X_1, ..., X_k\right)$ that are normally distributed $\vec{X} \sim \mathcal{N}\left(\vec{\mu}, \Sigma\right)$ with arbitrary $\Sigma$ and $\vec{\mu}$ values what's the variance (i.e. the second central moment) of the random variable $\lVert X \lVert_2$? From length of Gaussian Random Vector we know that the general probability density function of $\sqrt{Q(\vec{X})} = \sqrt{X^TAX}$ does not follow any known laws. However I'm only looking for the variance. From the post we know that when analyzing the quadratic form (see linked post) $$ Q(\vec{X})=\sum_{i=1}^k\lambda_i\left(U_i+b_i\right)^2=\sum_{i=1}^k\lambda_i\left(U_i^2 + 2b_iU_i + b_i^2\right) $$ we obtain a superposition of Chi-Squared-Distributions and zero-mean Gaussian distributions since $\vec{U}$ is multivariate normal with identity covariance matrix and expectation zero. Using these rules we obtain: $var\left(U_i^2\right) = 2$ (Chi-Squared) $var\left(U_i\right) = 1$ (uniform Gaussian) $var\left(2b_iU_i\right) = 4b_i^2$ $var\left(b_i^2\right) = 0$ (constant) $cov\left(U_i^2, 2b_iU_i\right) = E\left[2b_iU_i^3\right] = 2b_iE\left[U_i^3\right] = 0$ $cov\left(U_i^2, b_i^2\right) = 0$ $var\left(U_i^2 + 2b_iU_i + b_i^2\right) = 2 + 4b_i^2$, and hence $$var\left(Q(\vec{X})\right) = \sum_{i=1}^k\lambda_i^2(2 + 4b_i^2)$$ So the only step missing would to find $var\left(\sqrt{Q(\vec{X})}\right)$ given $var\left(Q(\vec{X})\right)$. Unfortunately it doesn't appear that simple according to Mean and variance of $\sqrt{X}$ given mean and variance of X . So how to move on with this? Will the definition of the central moment be helpful? Assuming we are able to come up with the pdf of $\sqrt{Q(\vec{X})}$ I'm afraid this might only yield ugly integral terms that are impossible to solve or even approximate in the general case... edit: fixed the variance of Chi-Squared to 2",,"['statistics', 'random-variables', 'normal-distribution', 'normed-spaces', 'chi-squared']"
54,Efficient way of integrating a 2-dimensional Gaussian over a convex polygonal domain,Efficient way of integrating a 2-dimensional Gaussian over a convex polygonal domain,,"I am looking for a reference for the calculation of integrals of bivariate normal distributions over (convex) polygons. $$P\{X\in\mathcal{A}\} =  \int_{\Omega} \frac{1}{\sqrt{(2\pi)^2|\Sigma|}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}dx$$ $$\Omega:=\{x\in\mathbb{R}^2\,|\,\,Ax\leq b\}$$ For the case of triangular domains, formulae exist and are used for example in the polyCub R package. The approach can be extended to arbitrary polygons, based on a triangulation of the domain. I came across a paper [1] from 1978 that seemingly provides a more efficient solution, without the need for a triangulation. Here the integral over the complement of the region is calculated, based on a partitioning to external angular regions. For these semi-analytical solutions using special functions $(\operatorname{erf}, \operatorname{erfc})$ are given. I was wondering if a more recent work using such an approach exists? The original document is sometimes barely readable due to the scan quality. [1] A. R. DiDonato, M. P. Jarnagin Jr, and R. K. Hageman, “Computation of the bivariate normal distribution over convex polygons,” DTIC Document, 1978.","I am looking for a reference for the calculation of integrals of bivariate normal distributions over (convex) polygons. $$P\{X\in\mathcal{A}\} =  \int_{\Omega} \frac{1}{\sqrt{(2\pi)^2|\Sigma|}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}dx$$ $$\Omega:=\{x\in\mathbb{R}^2\,|\,\,Ax\leq b\}$$ For the case of triangular domains, formulae exist and are used for example in the polyCub R package. The approach can be extended to arbitrary polygons, based on a triangulation of the domain. I came across a paper [1] from 1978 that seemingly provides a more efficient solution, without the need for a triangulation. Here the integral over the complement of the region is calculated, based on a partitioning to external angular regions. For these semi-analytical solutions using special functions $(\operatorname{erf}, \operatorname{erfc})$ are given. I was wondering if a more recent work using such an approach exists? The original document is sometimes barely readable due to the scan quality. [1] A. R. DiDonato, M. P. Jarnagin Jr, and R. K. Hageman, “Computation of the bivariate normal distribution over convex polygons,” DTIC Document, 1978.",,"['statistics', 'reference-request', 'definite-integrals', 'normal-distribution']"
55,Estimate Grade Distribution Based on Performance of Each Question,Estimate Grade Distribution Based on Performance of Each Question,,"As the title states, I would like to be able to estimate the grade distribution of an exam based on the mark distribution of each individual question. To give a quick example of what I mean, suppose an exam has 2 questions worth 2 and 3 marks respectively: Question 1: 20% receive 0 marks, 50% receive 1 mark, 30% receive 2   marks. Question 2: 10% receive 0 marks, 30% receive 1 mark, 40% receive 2   marks,  20% receive 3 marks Based on these individual distributions, I would like to find the overall distribution of marks (from 0 to 5). My initial thoughts were: I could assume the performance on each question is independent of the other questions. However, I thought this unrealistic as a stronger student will likely get both Q1 and Q2 correct whereas a weaker student will likely get both wrong I could initially assign each student a 'strength' based on a normal (or other) distribution. Those at the right tail would be more likely to gain full marks and those at the left tail would be more likely to receive zero marks. However, such a model would not account for 'silly mistakes' or 'flukes'; i.e. even though a student's 'strength' is very large, there is still a probability of making a careless error or the probability a student guesses a question correct even though their 'strength' is very low. I also considered using models from my CT4 (actuarial stats) course, but I struggled with applying assumptions made for mortality investigations to my current problem. Finally, I am familiar with the saying ""all models are wrong but some are useful"", but I would like to try get an accurate model if possible! Note: I do have actual numbers to verify any potential solution presented here and I will be happy to share them if need be :)","As the title states, I would like to be able to estimate the grade distribution of an exam based on the mark distribution of each individual question. To give a quick example of what I mean, suppose an exam has 2 questions worth 2 and 3 marks respectively: Question 1: 20% receive 0 marks, 50% receive 1 mark, 30% receive 2   marks. Question 2: 10% receive 0 marks, 30% receive 1 mark, 40% receive 2   marks,  20% receive 3 marks Based on these individual distributions, I would like to find the overall distribution of marks (from 0 to 5). My initial thoughts were: I could assume the performance on each question is independent of the other questions. However, I thought this unrealistic as a stronger student will likely get both Q1 and Q2 correct whereas a weaker student will likely get both wrong I could initially assign each student a 'strength' based on a normal (or other) distribution. Those at the right tail would be more likely to gain full marks and those at the left tail would be more likely to receive zero marks. However, such a model would not account for 'silly mistakes' or 'flukes'; i.e. even though a student's 'strength' is very large, there is still a probability of making a careless error or the probability a student guesses a question correct even though their 'strength' is very low. I also considered using models from my CT4 (actuarial stats) course, but I struggled with applying assumptions made for mortality investigations to my current problem. Finally, I am familiar with the saying ""all models are wrong but some are useful"", but I would like to try get an accurate model if possible! Note: I do have actual numbers to verify any potential solution presented here and I will be happy to share them if need be :)",,"['statistics', 'probability-distributions']"
56,single variable is significant but overall test is not,single variable is significant but overall test is not,,"I do a multiple regression with 3 independent variables $X_1$, $X_2$ and $X_3$. The correlation between $Y$ and $X_1$, $Y$ and $X_2$, and $Y$ and $X_3$, are each large and statistically significant. When I fit the multiple regression, none of the t-tests on individual coefficients are significant. How could this happen?","I do a multiple regression with 3 independent variables $X_1$, $X_2$ and $X_3$. The correlation between $Y$ and $X_1$, $Y$ and $X_2$, and $Y$ and $X_3$, are each large and statistically significant. When I fit the multiple regression, none of the t-tests on individual coefficients are significant. How could this happen?",,"['statistics', 'regression', 'statistical-inference', 'regression-analysis']"
57,Divergence based robust inference,Divergence based robust inference,,"The term 'divergence' means a function $D$ which takes two probability distributions $g,f$ as input and puts out a non-negative real number $D(g,f)$. I have learnt that the inference based on minimizing the following divergence is robust against those data points which are not compatible with the assumed model (called outliers ), for some specific range of $\alpha \in \mathbb{R}^n$. $$D_{\alpha}(g,f) = \frac{1}{\alpha-1}\log \int g^{\alpha}f^{1-\alpha}~dx,$$ where $g$ stands for the data driven density and $f$ stands for the model density (see, for example here ). There are several names to this $D_\alpha$ in the literature viz., Renyi divergence, power divergence, $\alpha$-divergence etc. Can someone give a justification of how this method is robust? Update: (as suggested by  @Bruce Trumbo) Some Preliminaries: Suppose that $x_1,\dots,x_n$ i.i.d. samples drawn according to a particular member of a parametric family of probability distributions $\mathcal{F} = \{f_\theta\}$ ( model ). (Let us assume, for simplicity, that the $f_{\theta}$'s have a common support set $\mathbb{X}$ which is finite and also that $\mathbb{X}$ is the undelying sample space.) Our objective is to choose a special member $f_{\theta^*}$ of $\mathcal{F}$ which ""best"" explains the observed samples. The Maximum Liklihood Estimate (MLE) is a widely used inference method which asks us to choose the $f_\theta$ for which $\Pi_{i=1}^n f_\theta(x_i)$ is maximum. Let $\hat{f}$ be the empirical measure of the $x_i$'s. Then observe that \begin{eqnarray}  \frac{\prod_{i=1}^n f_\theta(x_i)}{\prod_{i=1}^n \hat{f}(x_i)} & = & \prod_{x\in\mathbb{X}} \left(\frac{f_\theta(x)}{\hat{f}(x)}\right)^{n\hat{f}(x)}\\ & = &\exp\{-nD(\hat{f}\|f_\theta)\}, \end{eqnarray} where $D(\hat{f}\|f_\theta)=\sum_x \hat{f}(x)\log(\hat{f}(x)/f_\theta(x))$ is the well-known Kullback-Leibler divergence. Hence, MLE is a minimizer of $D(\hat{f}\|f_\theta)$ over $\theta$. For minimization, $(\partial/\partial_\theta) D(\hat{f}\|f_\theta) = 0$. This implies $$\sum_{x\in \mathbb{X}} \hat{f}(x) \frac{\partial}{\partial\theta}\log f_\theta(x) = 0.$$ That is, $$\sum_{i=1}^n \frac{\partial}{\partial\theta}\log f_\theta(x_i) = 0,$$ called the score equation . Thus, one needs to solve the score equation for finding the MLE. However, MLE is not robust when few of the $x_i$ are outliers. The inference based on minimizing the power divergence is known to be robust against the outliers. Note that the power divergence $D_\alpha(\cdot\|\cdot)\to D(\cdot\|\cdot)$ as $\alpha\to 1$. I roughly remember that the ""improved"" (or generalized) score equation corresponding to the power divergence to be something like $$\sum_{i=1}^n f_{\theta}(x_i)^c\frac{\partial}{\partial\theta}\log f_\theta(x_i) = 0,$$ for some $c>0$, potentially a function of $\alpha$. The thing I would like to know is whether there is any way by which this generalized score equation can be shown to be derived from the power divergence as in the case of MLE as the score equation is derived from the Kullback-Leibler divergence. PS: I asked a question along the same lines in stats.stackexchange which did not get much attention. The link is here .","The term 'divergence' means a function $D$ which takes two probability distributions $g,f$ as input and puts out a non-negative real number $D(g,f)$. I have learnt that the inference based on minimizing the following divergence is robust against those data points which are not compatible with the assumed model (called outliers ), for some specific range of $\alpha \in \mathbb{R}^n$. $$D_{\alpha}(g,f) = \frac{1}{\alpha-1}\log \int g^{\alpha}f^{1-\alpha}~dx,$$ where $g$ stands for the data driven density and $f$ stands for the model density (see, for example here ). There are several names to this $D_\alpha$ in the literature viz., Renyi divergence, power divergence, $\alpha$-divergence etc. Can someone give a justification of how this method is robust? Update: (as suggested by  @Bruce Trumbo) Some Preliminaries: Suppose that $x_1,\dots,x_n$ i.i.d. samples drawn according to a particular member of a parametric family of probability distributions $\mathcal{F} = \{f_\theta\}$ ( model ). (Let us assume, for simplicity, that the $f_{\theta}$'s have a common support set $\mathbb{X}$ which is finite and also that $\mathbb{X}$ is the undelying sample space.) Our objective is to choose a special member $f_{\theta^*}$ of $\mathcal{F}$ which ""best"" explains the observed samples. The Maximum Liklihood Estimate (MLE) is a widely used inference method which asks us to choose the $f_\theta$ for which $\Pi_{i=1}^n f_\theta(x_i)$ is maximum. Let $\hat{f}$ be the empirical measure of the $x_i$'s. Then observe that \begin{eqnarray}  \frac{\prod_{i=1}^n f_\theta(x_i)}{\prod_{i=1}^n \hat{f}(x_i)} & = & \prod_{x\in\mathbb{X}} \left(\frac{f_\theta(x)}{\hat{f}(x)}\right)^{n\hat{f}(x)}\\ & = &\exp\{-nD(\hat{f}\|f_\theta)\}, \end{eqnarray} where $D(\hat{f}\|f_\theta)=\sum_x \hat{f}(x)\log(\hat{f}(x)/f_\theta(x))$ is the well-known Kullback-Leibler divergence. Hence, MLE is a minimizer of $D(\hat{f}\|f_\theta)$ over $\theta$. For minimization, $(\partial/\partial_\theta) D(\hat{f}\|f_\theta) = 0$. This implies $$\sum_{x\in \mathbb{X}} \hat{f}(x) \frac{\partial}{\partial\theta}\log f_\theta(x) = 0.$$ That is, $$\sum_{i=1}^n \frac{\partial}{\partial\theta}\log f_\theta(x_i) = 0,$$ called the score equation . Thus, one needs to solve the score equation for finding the MLE. However, MLE is not robust when few of the $x_i$ are outliers. The inference based on minimizing the power divergence is known to be robust against the outliers. Note that the power divergence $D_\alpha(\cdot\|\cdot)\to D(\cdot\|\cdot)$ as $\alpha\to 1$. I roughly remember that the ""improved"" (or generalized) score equation corresponding to the power divergence to be something like $$\sum_{i=1}^n f_{\theta}(x_i)^c\frac{\partial}{\partial\theta}\log f_\theta(x_i) = 0,$$ for some $c>0$, potentially a function of $\alpha$. The thing I would like to know is whether there is any way by which this generalized score equation can be shown to be derived from the power divergence as in the case of MLE as the score equation is derived from the Kullback-Leibler divergence. PS: I asked a question along the same lines in stats.stackexchange which did not get much attention. The link is here .",,"['statistics', 'statistical-inference', 'information-theory', 'robust-statistics']"
58,Dirichlet Distribution - the underlying intuition.,Dirichlet Distribution - the underlying intuition.,,"I'm not a math expert, but I need dealing with some math tools for natural language processing research. One of the most common tools is the Dirichlet distribution. I know that with a multinomial distribution I can estimate the probability of a vector of outcomes to happen given a vector of a priori probabilities. I've tried to understand the Dirichlet distribution comparing to the multinomial case, but I'm facing difficulties since most ""tutorials"" use too much formal jargon, which I don't have enough background knowledge to absorb. My guess is that Dirichlet distribution is a multinomial with more ""vectors"" of parameters, but I'm not sure if it's the real thing. Hopefully someone will be capable of bringing a proper answer according to my level of expertise in statistics (if there is any). Thank you in advance.","I'm not a math expert, but I need dealing with some math tools for natural language processing research. One of the most common tools is the Dirichlet distribution. I know that with a multinomial distribution I can estimate the probability of a vector of outcomes to happen given a vector of a priori probabilities. I've tried to understand the Dirichlet distribution comparing to the multinomial case, but I'm facing difficulties since most ""tutorials"" use too much formal jargon, which I don't have enough background knowledge to absorb. My guess is that Dirichlet distribution is a multinomial with more ""vectors"" of parameters, but I'm not sure if it's the real thing. Hopefully someone will be capable of bringing a proper answer according to my level of expertise in statistics (if there is any). Thank you in advance.",,"['statistics', 'intuition', 'multinomial-coefficients']"
59,Showing the Posterior distribution is a Gamma,Showing the Posterior distribution is a Gamma,,"Assume $X\sim \mathrm{iid}\operatorname{Pareto}(a,b)$ , and $b \le \min(X)$ , then $$f_n({\bf x}; \theta) = a^n b^{-n} \prod^n_{i=1}\left( \frac{b}{x_i} \right) ^{1 + a} $$ We assume $b$ is known and choose a Gamma( $\alpha, \beta$ ) prior distribution for $a.$ I aim to show the posterior distribution is a Gamma( $\alpha + n, \beta + \sum^n_{i=1} \ln \frac{x_i}{b}$ ). I begin with; $$p(a\mid {\bf x}) \propto a^n b^{-n} \prod^n_{i=1}\left( \frac{b}{x_i} \right) \frac{\beta^\alpha}{\Gamma(\alpha)}a^{\alpha - 1}\exp(-\beta a)$$ $$\propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)}\exp\left(-\beta a + \ln\prod^n_{i=1}\left(  \frac{b}{x_i} \right) ^{1 + a} \right)$$ $$\propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)}\exp\left(-\beta a + (1 + a)\sum^n_{i=1}\ln\left(  \frac{b}{x_i} \right) \right)$$ $$\propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)} \exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right) + \sum^n_{i=1}\ln\left( \frac{b}{x_i}\right)\right) $$ $$\propto a^{(\alpha + n) - 1} \frac{\beta^\alpha}{\Gamma(\alpha)} \prod^n_{i=1}\left( \frac{1}{x_i} \right)  \exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right)\right) $$ Which is close. I have a to the correct power, and the term in the exponential is what I would like also. Since there is no a term in the other terms; $$\propto a^{(\alpha + n) - 1}  \exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right)\right) $$ Which is what we want. But is it okay to disregard those other terms?","Assume , and , then We assume is known and choose a Gamma( ) prior distribution for I aim to show the posterior distribution is a Gamma( ). I begin with; Which is close. I have a to the correct power, and the term in the exponential is what I would like also. Since there is no a term in the other terms; Which is what we want. But is it okay to disregard those other terms?","X\sim \mathrm{iid}\operatorname{Pareto}(a,b) b \le \min(X) f_n({\bf x}; \theta) = a^n b^{-n} \prod^n_{i=1}\left( \frac{b}{x_i} \right) ^{1 + a}  b \alpha, \beta a. \alpha + n, \beta + \sum^n_{i=1} \ln \frac{x_i}{b} p(a\mid {\bf x}) \propto a^n b^{-n} \prod^n_{i=1}\left( \frac{b}{x_i} \right) \frac{\beta^\alpha}{\Gamma(\alpha)}a^{\alpha - 1}\exp(-\beta a) \propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)}\exp\left(-\beta a + \ln\prod^n_{i=1}\left(  \frac{b}{x_i} \right) ^{1 + a} \right) \propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)}\exp\left(-\beta a + (1 + a)\sum^n_{i=1}\ln\left(  \frac{b}{x_i} \right) \right) \propto a^{(\alpha + n) - 1} b^{-n} \frac{\beta^\alpha}{\Gamma(\alpha)}
\exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right) + \sum^n_{i=1}\ln\left( \frac{b}{x_i}\right)\right)  \propto a^{(\alpha + n) - 1} \frac{\beta^\alpha}{\Gamma(\alpha)} \prod^n_{i=1}\left( \frac{1}{x_i} \right) 
\exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right)\right)  \propto a^{(\alpha + n) - 1} 
\exp \left(-a \left(\beta + \sum^n_{i=1} \ln  \left(\frac{x_i}{b}\right)\right)\right) ",['statistics']
60,Distribution for ratio of dependent quadratic forms.,Distribution for ratio of dependent quadratic forms.,,"Random vector $\mathbf{x}_{0}$ $\sim$ $\mathcal{N}\left(\boldsymbol{\mu}, \mathbf{\Sigma} \right)$ is a sum of two orthogonal random vectors: $\mathbf{x}_{0}$ = $\mathbf{x}_{1}$ + $\mathbf{x}_{1}^{\perp}$, where:  $\mathbf{x}_{1}^{\text{T}} \mathbf{x}_{1}^{\perp}$ = $0$. Can the quadratic form $\mathbf{x}_{0}^{\text{T}} \mathbf{A} \mathbf{x}_{0}$ be expressed in such a way that the quotient: $s$ $=$ $\cfrac{\mathbf{x}_{0}^{\text{T}} \mathbf{A} \mathbf{x}_{0}}{\mathbf{x}_{1}^{\text{T}} \mathbf{A} \mathbf{x}_{1}}$ has a known (documented) distribution? I think a unitary matrix transformation per the helpful comment below, in addition to Cochran's Theorem, may be of utility here.","Random vector $\mathbf{x}_{0}$ $\sim$ $\mathcal{N}\left(\boldsymbol{\mu}, \mathbf{\Sigma} \right)$ is a sum of two orthogonal random vectors: $\mathbf{x}_{0}$ = $\mathbf{x}_{1}$ + $\mathbf{x}_{1}^{\perp}$, where:  $\mathbf{x}_{1}^{\text{T}} \mathbf{x}_{1}^{\perp}$ = $0$. Can the quadratic form $\mathbf{x}_{0}^{\text{T}} \mathbf{A} \mathbf{x}_{0}$ be expressed in such a way that the quotient: $s$ $=$ $\cfrac{\mathbf{x}_{0}^{\text{T}} \mathbf{A} \mathbf{x}_{0}}{\mathbf{x}_{1}^{\text{T}} \mathbf{A} \mathbf{x}_{1}}$ has a known (documented) distribution? I think a unitary matrix transformation per the helpful comment below, in addition to Cochran's Theorem, may be of utility here.",,"['statistics', 'probability-distributions', 'quadratic-forms']"
61,Deconvolution of distribution of diffraction reflexes,Deconvolution of distribution of diffraction reflexes,,"I'm a chemist stuck in a mathematical problem. Please bear with me as I'm trying to express myself in Math language. Let me explain in short terms the experimental method I'm using: X-ray diffraction . For this method, atoms in a solid can be viewed as ordered balls in space. X-rays, having similar wavelength as the distance between atoms, are diffracted by those balls and can be detected as diffraction fringes. The distance between the diffracting atoms (or planes of atoms, aka lattice distance) can then be calculated using Bragg's law We use the method to measure the symmetry of the atom ordering, their distances and placement in space. As chemists, we like to deduce so-called lattice parameters (the lengths of the smallest repeating unit of atoms in all three cartesian coordinates) from three or more characteristic atomic plane distances. In my case the repeating unit has the form of a cuboid. The measured diffraction fringes are equivalent to the points of the fourier transform of the spacing of the atoms in real space and describe the repetition of those atoms. They are linked to the cuboid edge lengths via: 1/d 2 = h 2 /a 2 + k 2 /b 2 + l 2 /c 2 h, k and l are discrete values, characteristic to the specific diffraction fringe, d is the measured lattice distance. Unfortunately, the cuboid is not stiff, but a, b and c have some distribution. As such I have measured an asymmetric distribution of the lattice distances d. I would like to find out how the cuboid edge lengths contribute to the measured distribution. I fitted a normal distribution to my experimental data for 1/d 2 , for which it is easy to deconvolute to get distributions of 1/a 2 and so on. This doesn't reflect my data correctly, though, since I observe an asymmetric distribution of 1/d 2 . Do you have an idea how to extract information of the distribution of a, b and c from those three distributions of lattice spacings? In a first approximation, these three edge lengths are independent variables.","I'm a chemist stuck in a mathematical problem. Please bear with me as I'm trying to express myself in Math language. Let me explain in short terms the experimental method I'm using: X-ray diffraction . For this method, atoms in a solid can be viewed as ordered balls in space. X-rays, having similar wavelength as the distance between atoms, are diffracted by those balls and can be detected as diffraction fringes. The distance between the diffracting atoms (or planes of atoms, aka lattice distance) can then be calculated using Bragg's law We use the method to measure the symmetry of the atom ordering, their distances and placement in space. As chemists, we like to deduce so-called lattice parameters (the lengths of the smallest repeating unit of atoms in all three cartesian coordinates) from three or more characteristic atomic plane distances. In my case the repeating unit has the form of a cuboid. The measured diffraction fringes are equivalent to the points of the fourier transform of the spacing of the atoms in real space and describe the repetition of those atoms. They are linked to the cuboid edge lengths via: 1/d 2 = h 2 /a 2 + k 2 /b 2 + l 2 /c 2 h, k and l are discrete values, characteristic to the specific diffraction fringe, d is the measured lattice distance. Unfortunately, the cuboid is not stiff, but a, b and c have some distribution. As such I have measured an asymmetric distribution of the lattice distances d. I would like to find out how the cuboid edge lengths contribute to the measured distribution. I fitted a normal distribution to my experimental data for 1/d 2 , for which it is easy to deconvolute to get distributions of 1/a 2 and so on. This doesn't reflect my data correctly, though, since I observe an asymmetric distribution of 1/d 2 . Do you have an idea how to extract information of the distribution of a, b and c from those three distributions of lattice spacings? In a first approximation, these three edge lengths are independent variables.",,"['statistics', 'probability-distributions', 'physics', 'mathematical-physics', 'chemistry']"
62,Third Moment of Geometric Series?,Third Moment of Geometric Series?,,"$\sum_{x=1}^{\infty}x(1-p)^{x-1} = \frac{1}{p^2}$ $\sum_{x=1}^{\infty}x^2(1-p)^{x-1} = \frac{2-p}{p^3}$ $\sum_{x=1}^{\infty}x^3(1-p)^{x-1} =$ ... ? The textbook gives the first 2 moments, but not the third one. I could not find the forumla on Google as well. I think it'll be useful in case I need to find $E(X^3)$ where $X$ is a geometric distribution.","$\sum_{x=1}^{\infty}x(1-p)^{x-1} = \frac{1}{p^2}$ $\sum_{x=1}^{\infty}x^2(1-p)^{x-1} = \frac{2-p}{p^3}$ $\sum_{x=1}^{\infty}x^3(1-p)^{x-1} =$ ... ? The textbook gives the first 2 moments, but not the third one. I could not find the forumla on Google as well. I think it'll be useful in case I need to find $E(X^3)$ where $X$ is a geometric distribution.",,"['statistics', 'summation']"
63,Inverse Gaussian distribution,Inverse Gaussian distribution,,"Let $X_1,....X_n$ be a random sample from the inverse Gaussian distribution with pdf $$f(x|\mu,\lambda)=\left(\frac{\lambda}{2\pi x^3}\right)^{1/2} \exp\left(\frac{-\lambda (x-\mu)^2}{2 \mu^2 x}\right),\quad0 \lt x \lt \infty$$ For $n=2$, show that $\overline X$ has an inverse Gaussian distribution, $n\lambda/T$ has a $\chi^2_{n-1}$ distribution, and they are independent. I am working on this question. I would appreciate it if you would like to give me any help. Thanks","Let $X_1,....X_n$ be a random sample from the inverse Gaussian distribution with pdf $$f(x|\mu,\lambda)=\left(\frac{\lambda}{2\pi x^3}\right)^{1/2} \exp\left(\frac{-\lambda (x-\mu)^2}{2 \mu^2 x}\right),\quad0 \lt x \lt \infty$$ For $n=2$, show that $\overline X$ has an inverse Gaussian distribution, $n\lambda/T$ has a $\chi^2_{n-1}$ distribution, and they are independent. I am working on this question. I would appreciate it if you would like to give me any help. Thanks",,['statistics']
64,Order Statistics Expectation and Variance,Order Statistics Expectation and Variance,,"How would we go about finding the expectation and variance of the r$^{\text{th}}$ order statistic $X_{(r)}$ from a random sample $X_1, \ldots, X_n$ from a uniform distribution with density function $$f(x)=1 \quad \quad \text{for} \ x \in (0,1)$$ and $f(x)=0$ otherwise? Intuitively we can see the expectation is $\frac{r}{n+1}$ though I'm keen to see how that is derived from simply knowing the pdf of the distribution.","How would we go about finding the expectation and variance of the r$^{\text{th}}$ order statistic $X_{(r)}$ from a random sample $X_1, \ldots, X_n$ from a uniform distribution with density function $$f(x)=1 \quad \quad \text{for} \ x \in (0,1)$$ and $f(x)=0$ otherwise? Intuitively we can see the expectation is $\frac{r}{n+1}$ though I'm keen to see how that is derived from simply knowing the pdf of the distribution.",,"['statistics', 'order-statistics']"
65,Minimal sufficient statistics for Cauchy distribution,Minimal sufficient statistics for Cauchy distribution,,"I'm trying to find the minimal sufficient statistics for a Cauchy distributed random sample $X_1,...,X_n$ , here \begin{equation} f(x|\theta) = \frac{1}{\pi[1+(x-\theta)^2]} \end{equation} I begin by guessing that the order statistics are the minimal sufficient statistics (first of all, they are sufficient). Then I try to prove that \begin{equation} \frac{f(X|\theta)}{f(Y|\theta)} = \prod_{i=1}^n\frac{1+(y_i-\theta)^2}{1+(x_i-\theta)^2}=C \end{equation} Where $C$ is a constant of $\theta$ , I want to prove that the above equation holds iff $T(X)=T(Y)$ , where $T(X)$ is the order statistics of $X$ . I am really stuck and don't know how to show why that if it holds then $T(X)=T(Y)$ , can anyone help me on this proof? p.s., a similar thread minimal sufficient statistic of Cauchy distribution discusses the problem but offers no proof for the minimal sufficiency.","I'm trying to find the minimal sufficient statistics for a Cauchy distributed random sample , here I begin by guessing that the order statistics are the minimal sufficient statistics (first of all, they are sufficient). Then I try to prove that Where is a constant of , I want to prove that the above equation holds iff , where is the order statistics of . I am really stuck and don't know how to show why that if it holds then , can anyone help me on this proof? p.s., a similar thread minimal sufficient statistic of Cauchy distribution discusses the problem but offers no proof for the minimal sufficiency.","X_1,...,X_n \begin{equation}
f(x|\theta) = \frac{1}{\pi[1+(x-\theta)^2]}
\end{equation} \begin{equation}
\frac{f(X|\theta)}{f(Y|\theta)} = \prod_{i=1}^n\frac{1+(y_i-\theta)^2}{1+(x_i-\theta)^2}=C
\end{equation} C \theta T(X)=T(Y) T(X) X T(X)=T(Y)","['statistics', 'polynomials', 'statistical-inference', 'order-statistics']"
66,prove $\sum_{i=1}^{n}(x_i-\bar{x})^2\lt\sum_{i=1}^{n}(x_i-a)^2$,prove,\sum_{i=1}^{n}(x_i-\bar{x})^2\lt\sum_{i=1}^{n}(x_i-a)^2,"How do we prove that $$ \sum_{i=1}^{n}(x_i-\bar{x})^2\lt\sum_{i=1}^{n}(x_i-a)^2 $$ where $a$ is any value other than $\bar{x}$, the arithmetic mean. My Attempt: $$ \sum_{i=1}^{n}(x_i^2-2x_i\bar{x}+\bar{x}^2)\lt\sum_{i=1}^{n}(x_i^2-2x_ia+a^2)\\\sum_{i=1}^{n}x_i^2-2\bar{x}\sum_{i=1}^{n}x_i+\sum_{i=1}^{n}\bar{x}^2\lt\sum_{i=1}^{n}x_i^2-2a\sum_{i=1}^{n}x_i+\sum_{i=1}^{n}a^2\\-2\bar{x}.n\bar{x}+n.\bar{x}^2\lt-2a.n\bar{x}+n.a^2\\-2\bar{x}^2+\bar{x}^2\lt-2a\bar{x}+a^2\\-\bar{x}^2\lt-2a\bar{x}+a^2 $$ But how do I proceed further or is there any better way ?","How do we prove that $$ \sum_{i=1}^{n}(x_i-\bar{x})^2\lt\sum_{i=1}^{n}(x_i-a)^2 $$ where $a$ is any value other than $\bar{x}$, the arithmetic mean. My Attempt: $$ \sum_{i=1}^{n}(x_i^2-2x_i\bar{x}+\bar{x}^2)\lt\sum_{i=1}^{n}(x_i^2-2x_ia+a^2)\\\sum_{i=1}^{n}x_i^2-2\bar{x}\sum_{i=1}^{n}x_i+\sum_{i=1}^{n}\bar{x}^2\lt\sum_{i=1}^{n}x_i^2-2a\sum_{i=1}^{n}x_i+\sum_{i=1}^{n}a^2\\-2\bar{x}.n\bar{x}+n.\bar{x}^2\lt-2a.n\bar{x}+n.a^2\\-2\bar{x}^2+\bar{x}^2\lt-2a\bar{x}+a^2\\-\bar{x}^2\lt-2a\bar{x}+a^2 $$ But how do I proceed further or is there any better way ?",,"['statistics', 'standard-deviation', 'means']"
67,Why is $\ln(1-x) \approx -x$ when $x$ is small?,Why is  when  is small?,\ln(1-x) \approx -x x,I saw this in a proof for the Central Limit Theorem: $\ln(1-x) \approx -x$ when $x$ is small It seems to be true when I plug in small values of $x$. But why does it work?,I saw this in a proof for the Central Limit Theorem: $\ln(1-x) \approx -x$ when $x$ is small It seems to be true when I plug in small values of $x$. But why does it work?,,['statistics']
68,How to find median from a histogram?,How to find median from a histogram?,,"I am doing a course on machine learning and as part of it i am also learning statistics. I came across one question in which i have to find the median basing on a histogram. Median is the th  element. But in the histogram the hint is confusing me. What does that mean 43 is the median of the frequencies, but it's not the median of the values. For the median of the values, if you sum up all the frequencies below the median, and all the frequencies above the median, you should get the same number. Please help.","I am doing a course on machine learning and as part of it i am also learning statistics. I came across one question in which i have to find the median basing on a histogram. Median is the th  element. But in the histogram the hint is confusing me. What does that mean 43 is the median of the frequencies, but it's not the median of the values. For the median of the values, if you sum up all the frequencies below the median, and all the frequencies above the median, you should get the same number. Please help.",,"['statistics', 'median']"
69,Mean and mode of a Beta random variable,Mean and mode of a Beta random variable,,"A continuous random variable is said to have a $Beta(a,b)$ distribution if its density is given by $f(x) = (1 / \text{B}(a,b))x^{a-1} (1-x)^{b-1}$ if $0 < x < 1$ Find mean , var, mode if $a = 3, b = 5.$ This is throwing me off with the beta distribution. I'm not sure if it changes the way i solve for the mean, var , mode. My approach is that since mean of a continuous random variable which is basically the Expected value of X (EX), so we can just do $\int x * f(x) dx$. We can find $ f(x) = (105) x^{2} (1-x)^{4} $ and then $\int x *f(x) dx =  1/105 \int_{0}^{1} x^3 * (1-x)^4 dx  = 105 * \beta(4,5)  =  105 * ((6*24 )/ 40320)$","A continuous random variable is said to have a $Beta(a,b)$ distribution if its density is given by $f(x) = (1 / \text{B}(a,b))x^{a-1} (1-x)^{b-1}$ if $0 < x < 1$ Find mean , var, mode if $a = 3, b = 5.$ This is throwing me off with the beta distribution. I'm not sure if it changes the way i solve for the mean, var , mode. My approach is that since mean of a continuous random variable which is basically the Expected value of X (EX), so we can just do $\int x * f(x) dx$. We can find $ f(x) = (105) x^{2} (1-x)^{4} $ and then $\int x *f(x) dx =  1/105 \int_{0}^{1} x^3 * (1-x)^4 dx  = 105 * \beta(4,5)  =  105 * ((6*24 )/ 40320)$",,"['statistics', 'random-variables']"
70,Show independence of number of heads and tails,Show independence of number of heads and tails,,"I am independently studying Larry Wasserman's ""All of Statistics"" Chapter 2 exercise 11 is this: Let $N \sim \mathrm{Poisson}(\lambda)$ and suppose we toss a coin $N$ times. Let $X$ and $Y$ be the number of heads and tails. Show that $X$ and $Y$ are independent. First, I don't understand what the significance of the Poisson distribution of $N$ is? Secondly, I am guessing that I'm supposed to show: $$f_{X,Y}(x,y) = f_X(x)f_Y(y)$$ I know that: $f_X(x) = {n \choose x} p^x(1-p)^{n-x}$ because the number of heads would follow a binomial distribution I don't understand how to express $f_Y(y)$ or $f_{X,Y}(x,y)$","I am independently studying Larry Wasserman's ""All of Statistics"" Chapter 2 exercise 11 is this: Let $N \sim \mathrm{Poisson}(\lambda)$ and suppose we toss a coin $N$ times. Let $X$ and $Y$ be the number of heads and tails. Show that $X$ and $Y$ are independent. First, I don't understand what the significance of the Poisson distribution of $N$ is? Secondly, I am guessing that I'm supposed to show: $$f_{X,Y}(x,y) = f_X(x)f_Y(y)$$ I know that: $f_X(x) = {n \choose x} p^x(1-p)^{n-x}$ because the number of heads would follow a binomial distribution I don't understand how to express $f_Y(y)$ or $f_{X,Y}(x,y)$",,"['statistics', 'probability-distributions']"
71,Is UMVUE unique? Is the best unbiased estimator unique?,Is UMVUE unique? Is the best unbiased estimator unique?,,"Here is the question: Is the best unbiased estimator unique? My understanding is that the best unbiased estimator must be the UMVUE, so the original question turns into the uniqueness of UMVUE. So far, as I thought, since Complete Sufficient statistics is not unique, then by Lehmann Scheffe theorem, the UMVUE hence shouldn't be unique. But some descriptions from wikipedia said otherwise. Can anybody help me out? Thanks!","Here is the question: Is the best unbiased estimator unique? My understanding is that the best unbiased estimator must be the UMVUE, so the original question turns into the uniqueness of UMVUE. So far, as I thought, since Complete Sufficient statistics is not unique, then by Lehmann Scheffe theorem, the UMVUE hence shouldn't be unique. But some descriptions from wikipedia said otherwise. Can anybody help me out? Thanks!",,"['statistics', 'statistical-inference', 'parameter-estimation']"
72,Why the expected value of the error when doing regression by OLS is 0?,Why the expected value of the error when doing regression by OLS is 0?,,"What I know to begin with is that the sum will be 0 if there is a y-intercept b0 , why is that? my book doesnt say and can't figure it out. I also know that an importantant assumption for the OLS estimators to be BlUE is that x and the erros can't be corralated otherwise the estimators would be biased.  This correlation assumption may entail problems so we take one step further and we assert that by combining E(u)=0 ( an assumption that the book doesnt explain where it comes from) + E(u|x)  - the average value of u doesnt depend on the value of x) , we get E(u)=0=E(u|x). so this assumption is somehow related to that the sum of residuals should be 0. But how do I mathematically prove that? Sorry if I have been a bit unclear but I am a quite confused, it seems all this topic quite redundant to me , like of the assumptions that jusify the method are infered from the method itself..","What I know to begin with is that the sum will be 0 if there is a y-intercept b0 , why is that? my book doesnt say and can't figure it out. I also know that an importantant assumption for the OLS estimators to be BlUE is that x and the erros can't be corralated otherwise the estimators would be biased.  This correlation assumption may entail problems so we take one step further and we assert that by combining E(u)=0 ( an assumption that the book doesnt explain where it comes from) + E(u|x)  - the average value of u doesnt depend on the value of x) , we get E(u)=0=E(u|x). so this assumption is somehow related to that the sum of residuals should be 0. But how do I mathematically prove that? Sorry if I have been a bit unclear but I am a quite confused, it seems all this topic quite redundant to me , like of the assumptions that jusify the method are infered from the method itself..",,"['statistics', 'order-statistics']"
73,Usefulness of Variance,Usefulness of Variance,,"I've had a look for intuitive explanations of the variance of an RV (e.g. Intuitive explanation of variance and moment in Probability ) but unfortunately for me, I still don't feel comfortable with the concept. Why would you opt to use variance over the standard deviation (which usefully is in the same units as the expectation)? Also, if the expectation, $E(X) = \Sigma_{i=0}^n i P(X = i)$, what is $E(X^2)$? Is it simply $E(X^2) = \Sigma_{i=0}^n i P(X^2 = i)$?","I've had a look for intuitive explanations of the variance of an RV (e.g. Intuitive explanation of variance and moment in Probability ) but unfortunately for me, I still don't feel comfortable with the concept. Why would you opt to use variance over the standard deviation (which usefully is in the same units as the expectation)? Also, if the expectation, $E(X) = \Sigma_{i=0}^n i P(X = i)$, what is $E(X^2)$? Is it simply $E(X^2) = \Sigma_{i=0}^n i P(X^2 = i)$?",,['statistics']
74,reason of the definition of the covariance,reason of the definition of the covariance,,"The covariance of two random variables $X$ and $Y$ is defined to be   $${\rm Cov}(X,Y) =   E[(X-E[X])(Y-E[Y])]. $$ I don't understand it, if someone could explain me this please. Why does this value tell us of some relation about $X$ and $Y$?","The covariance of two random variables $X$ and $Y$ is defined to be   $${\rm Cov}(X,Y) =   E[(X-E[X])(Y-E[Y])]. $$ I don't understand it, if someone could explain me this please. Why does this value tell us of some relation about $X$ and $Y$?",,['statistics']
75,Why are Covid-19 cases shown logarithmic?,Why are Covid-19 cases shown logarithmic?,,"I think this is a really simple and stupid question, I am sorry for that, but I could not find anything while googling it. why are covid-19 cases shown also on a logarithmic scale? on worldometer for example. From my understanding, the ln(x) is the inverse function of the e(x) and so we could better see, if the curve flattens, when plotting the cases on a logarithmic scale? is this true?","I think this is a really simple and stupid question, I am sorry for that, but I could not find anything while googling it. why are covid-19 cases shown also on a logarithmic scale? on worldometer for example. From my understanding, the ln(x) is the inverse function of the e(x) and so we could better see, if the curve flattens, when plotting the cases on a logarithmic scale? is this true?",,"['statistics', 'logarithms']"
76,Calculate skewness and kurtosis fast,Calculate skewness and kurtosis fast,,Calculating the variance and the central moments with a dumb calculator can be a pain. My question is if I have the standard deviation is there a quick way to calculate the skewness and the kurtosis,Calculating the variance and the central moments with a dumb calculator can be a pain. My question is if I have the standard deviation is there a quick way to calculate the skewness and the kurtosis,,['statistics']
77,Why do we divide by the expected value in the chi squared test?,Why do we divide by the expected value in the chi squared test?,,"Chi squared, $\chi ^{2}$, is calculated using the formula: $$ \chi ^{2} = \sum \frac{{(O_i - E_i)}^{2}}{E_i}$$ $\chi ^{2}$ is used to determine how well a particular model fits some observed data.  The way I justify this formula is that we want a model that resembles the data very closely.  Hence, we will need to check how different the model is to the observed data. We can check how different individual data points are from the expected values by $(O_i - E_i)$.  Thus, $(O_i - E_i)$ is justified. To determine how well the model fits the data as a whole we can sum $(O_i - E_i)$ for all data points.  $(O_i - E_i)$ will need to be squared to remove negative terms in the summation.  Negative terms will lower $\chi ^{2}$ and give a flawed goodness of fit.  Thus, $\sum {(O_i - E_i)}^{2}$ is justified. My question is why do we normalize ${(O_i - E_i)}^{2}$ by $E_i$?  This seems unnecessary to me.","Chi squared, $\chi ^{2}$, is calculated using the formula: $$ \chi ^{2} = \sum \frac{{(O_i - E_i)}^{2}}{E_i}$$ $\chi ^{2}$ is used to determine how well a particular model fits some observed data.  The way I justify this formula is that we want a model that resembles the data very closely.  Hence, we will need to check how different the model is to the observed data. We can check how different individual data points are from the expected values by $(O_i - E_i)$.  Thus, $(O_i - E_i)$ is justified. To determine how well the model fits the data as a whole we can sum $(O_i - E_i)$ for all data points.  $(O_i - E_i)$ will need to be squared to remove negative terms in the summation.  Negative terms will lower $\chi ^{2}$ and give a flawed goodness of fit.  Thus, $\sum {(O_i - E_i)}^{2}$ is justified. My question is why do we normalize ${(O_i - E_i)}^{2}$ by $E_i$?  This seems unnecessary to me.",,"['statistics', 'chi-squared']"
78,Can something be statistically impossible?,Can something be statistically impossible?,,"Does it make sense when people say ""statistically impossible""?","Does it make sense when people say ""statistically impossible""?",,['statistics']
79,Sufficient statistic for normal distribution with unknown mean and known variance,Sufficient statistic for normal distribution with unknown mean and known variance,,"Let $X$ be from a normal distribution $N(\theta,1)$ . a) Find a sufficient statistic for $\theta$ . b) Is $S_n^2$ a sufficient statistic for $\theta$ ? My answers For part a) Since the joint p.d.f is $1 \over (2\pi)^{n/2}$ , $e^{{-1 \over 2}\sum(x_i-\theta)^2}$ , I can say that $\sum X_i$ is  a sufficient statistic for $\theta$ because $e^{{-1 \over 2}\sum(x_i-\theta)^2}$ depends on X only through the values of $\sum X_i$ right? Because if I know the value of $\sum X_i$ ,  then I know $\sum X_i^2$ as well. For part b) Expanding the joint p.d.f as $\frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i- \bar x + \bar x-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[\sum(x_i- \bar x)^2+n(\bar x-\theta)^2\Big]} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[{\sum(x_i- \bar x)^2 \over n-1}n-1+n(\bar x-\theta)^2\Big]}$ . Now can I say $S_n^2$ is a sufficient statistic for $\theta$ . Is it a problem that I have $\bar x$ in the function $g(S_n^2,\theta)$ ?. Because $\bar x$ is a particular value I thought $g(S_n^2,\theta)$ depends on $\theta $ only through the values of $S_n^2$ .","Let be from a normal distribution . a) Find a sufficient statistic for . b) Is a sufficient statistic for ? My answers For part a) Since the joint p.d.f is , , I can say that is  a sufficient statistic for because depends on X only through the values of right? Because if I know the value of ,  then I know as well. For part b) Expanding the joint p.d.f as . Now can I say is a sufficient statistic for . Is it a problem that I have in the function ?. Because is a particular value I thought depends on only through the values of .","X N(\theta,1) \theta S_n^2 \theta 1 \over (2\pi)^{n/2} e^{{-1 \over 2}\sum(x_i-\theta)^2} \sum X_i \theta e^{{-1 \over 2}\sum(x_i-\theta)^2} \sum X_i \sum X_i \sum X_i^2 \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\sum(x_i- \bar x + \bar x-\theta)^2} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[\sum(x_i- \bar x)^2+n(\bar x-\theta)^2\Big]} = \frac{1}{(2\pi)^{n/2}}e^{{-1 \over 2}\Big[{\sum(x_i- \bar x)^2 \over n-1}n-1+n(\bar x-\theta)^2\Big]} S_n^2 \theta \bar x g(S_n^2,\theta) \bar x g(S_n^2,\theta) \theta  S_n^2","['statistics', 'statistical-inference', 'parameter-estimation']"
80,Why are there two different versions of the mean and variance for negative binomial distributions,Why are there two different versions of the mean and variance for negative binomial distributions,,"On a wiki proof site, I've seen these formulas used for the mean and variance: $E[X] = \frac{rp}{1-p}$ and $Var[X] = \frac{rp}{(1-p)^2}$. Yet on the Penn State site, they have these two different formulas: $E[X] = \frac{r}{p}$ and $Var[X] = \frac{r(1-p)}{p^2}$.","On a wiki proof site, I've seen these formulas used for the mean and variance: $E[X] = \frac{rp}{1-p}$ and $Var[X] = \frac{rp}{(1-p)^2}$. Yet on the Penn State site, they have these two different formulas: $E[X] = \frac{r}{p}$ and $Var[X] = \frac{r(1-p)}{p^2}$.",,['statistics']
81,Why is median age a better statistic than mean age?,Why is median age a better statistic than mean age?,,If you look at Wolfram Alpha or this Wikipedia page List of countries by median age Clearly median seems to be the statistic of choice when it comes to ages. I am not able to explain to myself why arithmetic mean would be a worse statistic. Why is it so?,If you look at Wolfram Alpha or this Wikipedia page List of countries by median age Clearly median seems to be the statistic of choice when it comes to ages. I am not able to explain to myself why arithmetic mean would be a worse statistic. Why is it so?,,"['statistics', 'average']"
82,Prove the normal approximation of beta distribution,Prove the normal approximation of beta distribution,,"How should I prove the normal approximation of beta distribution as follows: Let $\mathrm B_{r_1, r_2}\sim \mathrm{Beta}(r_1, r_2)$, then prove that $\sqrt{r_1+r_2} (\mathrm B_{r_1, r_2}- \dfrac{r_1}{r_1+r_2}) \to \mathrm N(0, \gamma(1-\gamma))$ where $r_1, r_2 \to \infty$ and $\frac{r_1}{r_1+r_2}\to \gamma$  $(0<\gamma<1)$. My attempt: By some calculation, I figured out that $\mathbb E(\mathrm B_{r_1, r_2})=\dfrac{r_1}{r_1+r_2}$ and $\operatorname{Var}(\mathrm B_{r_1, r_2})=\dfrac{r_1 r_2}{(r_1 + r_2)^2 (r_1 +r_2 +1)}$. Therefore, it remains to prove that $\sqrt{r_1 + r_2}\dfrac{\mathrm B_{r_1, r_2}-\mathbb E(\mathrm B_{r_1, r_2})}{\sqrt{\operatorname{Var}(\mathrm B_{r_1, r_2})}}$ converges to $Z \sim \mathrm N(0, 1)$. Here I think I have to apply CLT, but I don't know how to because the given quantity does not contain sample mean. Does anyone have ideas? Thanks for your help!","How should I prove the normal approximation of beta distribution as follows: Let $\mathrm B_{r_1, r_2}\sim \mathrm{Beta}(r_1, r_2)$, then prove that $\sqrt{r_1+r_2} (\mathrm B_{r_1, r_2}- \dfrac{r_1}{r_1+r_2}) \to \mathrm N(0, \gamma(1-\gamma))$ where $r_1, r_2 \to \infty$ and $\frac{r_1}{r_1+r_2}\to \gamma$  $(0<\gamma<1)$. My attempt: By some calculation, I figured out that $\mathbb E(\mathrm B_{r_1, r_2})=\dfrac{r_1}{r_1+r_2}$ and $\operatorname{Var}(\mathrm B_{r_1, r_2})=\dfrac{r_1 r_2}{(r_1 + r_2)^2 (r_1 +r_2 +1)}$. Therefore, it remains to prove that $\sqrt{r_1 + r_2}\dfrac{\mathrm B_{r_1, r_2}-\mathbb E(\mathrm B_{r_1, r_2})}{\sqrt{\operatorname{Var}(\mathrm B_{r_1, r_2})}}$ converges to $Z \sim \mathrm N(0, 1)$. Here I think I have to apply CLT, but I don't know how to because the given quantity does not contain sample mean. Does anyone have ideas? Thanks for your help!",,"['statistics', 'probability-distributions']"
83,Two-Sample Confidence Interval for Normal Distributions,Two-Sample Confidence Interval for Normal Distributions,,"Let's say I have two independent random samples $X_1, X_2, \dots, X_n$ and $Y_1, Y_2, \dots, Y_n$ from normal distributions with real, unknown means $\mu_x$ and $\mu_y$ and known standard deviations $\sigma_x$ and $\sigma_y$. How would I go about deriving a $100(1 - \alpha)$% confidence interval for $\mu_x - \mu_y$?  This is straight forward (in my mind) assuming the standard deviations are equal, but what if they are unequal?","Let's say I have two independent random samples $X_1, X_2, \dots, X_n$ and $Y_1, Y_2, \dots, Y_n$ from normal distributions with real, unknown means $\mu_x$ and $\mu_y$ and known standard deviations $\sigma_x$ and $\sigma_y$. How would I go about deriving a $100(1 - \alpha)$% confidence interval for $\mu_x - \mu_y$?  This is straight forward (in my mind) assuming the standard deviations are equal, but what if they are unequal?",,"['statistics', 'normal-distribution']"
84,Calculating mean and standard deviation of very large sample sizes,Calculating mean and standard deviation of very large sample sizes,,"I have about 3.5GB worth of data that I need to get statistics from, all split up into about 71MB files, with an (approximately) equal number of samples.  From this data, I would like to gather mean and standard deviation.  Parsing the entirety of the standard deviation is probably a bad idea, since it's 3.5GB. However, I know that with mean, I can at least (with some accuracy, since they're approximately the same size), take the average for each file, and then take the average of each of those sub-averages. With standard deviation, it's a little more tricky, though.  I've taken some time to run tests and found out that the standard deviation of a large sample size seems to be approximately similar to the average of the standard deviations of equivalently sized smaller chunks of samples.  Does this actually hold true, or was that just a coincidence within the few tests that I've run?  If it does hold true, then can I calculate what my percent error is probably going to be?  Finally, is there a more accurate way to test for standard deviation that doesn't require me mulling over 3.5GB of data at a time?","I have about 3.5GB worth of data that I need to get statistics from, all split up into about 71MB files, with an (approximately) equal number of samples.  From this data, I would like to gather mean and standard deviation.  Parsing the entirety of the standard deviation is probably a bad idea, since it's 3.5GB. However, I know that with mean, I can at least (with some accuracy, since they're approximately the same size), take the average for each file, and then take the average of each of those sub-averages. With standard deviation, it's a little more tricky, though.  I've taken some time to run tests and found out that the standard deviation of a large sample size seems to be approximately similar to the average of the standard deviations of equivalently sized smaller chunks of samples.  Does this actually hold true, or was that just a coincidence within the few tests that I've run?  If it does hold true, then can I calculate what my percent error is probably going to be?  Finally, is there a more accurate way to test for standard deviation that doesn't require me mulling over 3.5GB of data at a time?",,"['statistics', 'standard-deviation']"
85,Question about basic strategy in Blackjack,Question about basic strategy in Blackjack,,"I was watching Beating Blackjack with Andy Bloch where he runs through the basic strategy charts that outline the best strategy with playing the game. Later he also talks about the methodologies to count, but that is not relevant to my question. He states in that video that the basic strategy is an outcome of computer simulations, and that suggests to me that its a rather weak method to go about doing it. I have a two-fold question, one is when is a computer solution considered good enough to be ""true"", and the second, surely, this is a much easier problem that does not need computer simulations to solve, are there any known methods to derive the basic strategy.","I was watching Beating Blackjack with Andy Bloch where he runs through the basic strategy charts that outline the best strategy with playing the game. Later he also talks about the methodologies to count, but that is not relevant to my question. He states in that video that the basic strategy is an outcome of computer simulations, and that suggests to me that its a rather weak method to go about doing it. I have a two-fold question, one is when is a computer solution considered good enough to be ""true"", and the second, surely, this is a much easier problem that does not need computer simulations to solve, are there any known methods to derive the basic strategy.",,"['statistics', 'recreational-mathematics']"
86,Regression to the mean - a simple question,Regression to the mean - a simple question,,"In my statistics book there is a following question: In studies dating back over 100 years, it's well established that regression toward the mean occurs between the heights of fathers and the heights of their adult sons. Indicate whether the following statement is true or false: Fathers of tall sons will tend to be taller than their sons. The regression to the mean suggests that sons of tall fathers will be shorter than their fathers but they would still be above average, so they would be in the group of tall sons. So it seems that tall sons would have even taller fathers (otherwise there would be no regression to the mean effect), so the answer to the question should be ""True"" in my opinion, but according to the solution sheet it should be ""False"". What is the error in my reasoning and what is the valid way to answer the question? Thank you in advance for your help.","In my statistics book there is a following question: In studies dating back over 100 years, it's well established that regression toward the mean occurs between the heights of fathers and the heights of their adult sons. Indicate whether the following statement is true or false: Fathers of tall sons will tend to be taller than their sons. The regression to the mean suggests that sons of tall fathers will be shorter than their fathers but they would still be above average, so they would be in the group of tall sons. So it seems that tall sons would have even taller fathers (otherwise there would be no regression to the mean effect), so the answer to the question should be ""True"" in my opinion, but according to the solution sheet it should be ""False"". What is the error in my reasoning and what is the valid way to answer the question? Thank you in advance for your help.",,"['statistics', 'regression', 'linear-regression', 'descriptive-statistics']"
87,Basic exponential regression,Basic exponential regression,,"Background: I'm attempting to learn about basic statistics for the infrastructure asset management industry: Basic math explanation (related to estimating linear regression with no intercept) Problem: I would like to learn how to generate an exponential regression equation for road condition data, just like it was done for me here: Development of a Flexible Framework for Deterioration Modelling in Infrastructure Asset Management Hint: Skip to page 53 (the printed page number, not the PDF page number) In other words, I want to learn how to generate an exponential regression equation, so I can eventually update the coefficient in the existing model (on the full/real dataset). My soloution (mock data): I've mocked up a sample dataset here: +--------------+---------------+ |    X (AGE)   | Y (CONDITION) | +--------------+---------------+ |       0      |       20      | |       1      |       20      | |       2      |       20      | |       3      |       20      | |       4      |       20      | |       5      |       20      | |       6      |       18      | |       7      |       18      | |       8      |       18      | |       9      |       18      | |       10     |       16      | |       11     |       16      | |       12     |       14      | |       13     |       14      | |       14     |       12      | |       15     |       12      | |       16     |       10      | |       17     |        8      | |       18     |        6      | |       19     |        4      | |       20     |        2      | +--------------+---------------+ Steps in Excel: Column C: Convert Y to be more linear using the natural logarithm function Column D: Calculate a straight line that best fits the data, and then return an array that describes the line (using the LINEST function). Column E: Generate a trend-line on D, and use the coefficient from that trend-line to create an exponential regression equation: =21-exp(0.14723*x) Question: How successful was I? Was my approach mathematically correct? Related: Normal equation in Excel (statistics) Tune an exponential regression estimate using calculus Options for tuning exponential regression? Mimic Excel Solver nonlinear regression? (to reduce ESS of exponential regression) Excel: data table (hit and trial)","Background: I'm attempting to learn about basic statistics for the infrastructure asset management industry: Basic math explanation (related to estimating linear regression with no intercept) Problem: I would like to learn how to generate an exponential regression equation for road condition data, just like it was done for me here: Development of a Flexible Framework for Deterioration Modelling in Infrastructure Asset Management Hint: Skip to page 53 (the printed page number, not the PDF page number) In other words, I want to learn how to generate an exponential regression equation, so I can eventually update the coefficient in the existing model (on the full/real dataset). My soloution (mock data): I've mocked up a sample dataset here: +--------------+---------------+ |    X (AGE)   | Y (CONDITION) | +--------------+---------------+ |       0      |       20      | |       1      |       20      | |       2      |       20      | |       3      |       20      | |       4      |       20      | |       5      |       20      | |       6      |       18      | |       7      |       18      | |       8      |       18      | |       9      |       18      | |       10     |       16      | |       11     |       16      | |       12     |       14      | |       13     |       14      | |       14     |       12      | |       15     |       12      | |       16     |       10      | |       17     |        8      | |       18     |        6      | |       19     |        4      | |       20     |        2      | +--------------+---------------+ Steps in Excel: Column C: Convert Y to be more linear using the natural logarithm function Column D: Calculate a straight line that best fits the data, and then return an array that describes the line (using the LINEST function). Column E: Generate a trend-line on D, and use the coefficient from that trend-line to create an exponential regression equation: =21-exp(0.14723*x) Question: How successful was I? Was my approach mathematically correct? Related: Normal equation in Excel (statistics) Tune an exponential regression estimate using calculus Options for tuning exponential regression? Mimic Excel Solver nonlinear regression? (to reduce ESS of exponential regression) Excel: data table (hit and trial)",,"['statistics', 'exponential-function', 'regression', 'linear-regression']"
88,Why isn't the linear regression coefficient not just the average vector to data points?,Why isn't the linear regression coefficient not just the average vector to data points?,,"I am having trouble intuitively understanding the correctness of the formula to compute the coefficient for the regression line in a linear regression. I know the formula is $$\frac{\sum_{i=1}^N (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^N(x_i - \bar{x})^2}$$ I have at some point gone through the proof and mechanically understood it. But intuitively I still don't see why above formula computes the correct coefficient. In fact, intuitively I would have said, the coefficient for the regression line needs to be the average ratio of $y_i$ and $x_i$, $(x_i, y_i)$ being the data points. I wrote a small Jupyter-Notebook to illustrate this . I found that my naive approach is not completely wrong and in fact converges towards the correct value with more data, if the data scatters in a fixed intervall. So... what is the critical points that my naive approach gets wrong and what is the intuitive explanation for why the correct formula works better?","I am having trouble intuitively understanding the correctness of the formula to compute the coefficient for the regression line in a linear regression. I know the formula is $$\frac{\sum_{i=1}^N (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^N(x_i - \bar{x})^2}$$ I have at some point gone through the proof and mechanically understood it. But intuitively I still don't see why above formula computes the correct coefficient. In fact, intuitively I would have said, the coefficient for the regression line needs to be the average ratio of $y_i$ and $x_i$, $(x_i, y_i)$ being the data points. I wrote a small Jupyter-Notebook to illustrate this . I found that my naive approach is not completely wrong and in fact converges towards the correct value with more data, if the data scatters in a fixed intervall. So... what is the critical points that my naive approach gets wrong and what is the intuitive explanation for why the correct formula works better?",,"['statistics', 'regression', 'linear-regression']"
89,Show t-distribution is close to normal distribution when df is large,Show t-distribution is close to normal distribution when df is large,,Prove that t-distribution is close to normal distribution when degree of freedom is large. $$f(x)=\frac{\Gamma[(n+1)/2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1+\frac{x^2}{n}\right)^{-(n+1)/2}$$ using limit of density and Law of large number. Anyone can help me with this question please? Thank you and appreciate your help!,Prove that t-distribution is close to normal distribution when degree of freedom is large. $$f(x)=\frac{\Gamma[(n+1)/2]}{\sqrt{n\pi}\Gamma(n/2)}\left(1+\frac{x^2}{n}\right)^{-(n+1)/2}$$ using limit of density and Law of large number. Anyone can help me with this question please? Thank you and appreciate your help!,,"['statistics', 'probability-distributions']"
90,Find the pdf of Y = 1/X and compute E(Y),Find the pdf of Y = 1/X and compute E(Y),,Let the random variable have a pdf $f_X(x) = 2x$ when $0<x<1$ and $0$ otherwise.  Let the random variable $Y=1/X$. Find the pdf of $Y$ and use it to calculate $E(Y)$. The pdf of $Y$ is $f_Y(y) = \frac{2}{y^3}$. What is the support for $f_Y(y)$?,Let the random variable have a pdf $f_X(x) = 2x$ when $0<x<1$ and $0$ otherwise.  Let the random variable $Y=1/X$. Find the pdf of $Y$ and use it to calculate $E(Y)$. The pdf of $Y$ is $f_Y(y) = \frac{2}{y^3}$. What is the support for $f_Y(y)$?,,"['statistics', 'probability-distributions']"
91,Covariance of multinomial distribution,Covariance of multinomial distribution,,"Let $X = (X_1,\ldots, X_k)$ be multinomially distributed based upon $n$ trials with parameters $p_1,\ldots,p_k$ such that the sum of the parameters is equal to $1$. I am trying to find, for $i \neq j$, $\operatorname{Var}(X_i + X_j)$. Knowing this will be sufficient to find the $\operatorname{Cov}(X_i,X_j)$. Now $X_i \sim \text{Bin}(n, p_i)$. The natural thing to say would be that $X_i + X_j\sim \text{Bin}(n, p_i+p_j)$ (and this would, indeed, yield the right result), but I m not sure if this is indeed so. Suggestions for how to go about this are greatly appreciated! UPDATE :  @grand_chat very nicely answered the question about the distribution of $X_i + X_j$. How would we go about computing the variance of $X_i - X_j$? As @grand_chat correctly points out, this cannot be binomial because it is not guaranteed to be positive. How, then, should one go about computing the variance of this random variable? UPDATE 2 : The answer in this link answers the question in my UPDATE .","Let $X = (X_1,\ldots, X_k)$ be multinomially distributed based upon $n$ trials with parameters $p_1,\ldots,p_k$ such that the sum of the parameters is equal to $1$. I am trying to find, for $i \neq j$, $\operatorname{Var}(X_i + X_j)$. Knowing this will be sufficient to find the $\operatorname{Cov}(X_i,X_j)$. Now $X_i \sim \text{Bin}(n, p_i)$. The natural thing to say would be that $X_i + X_j\sim \text{Bin}(n, p_i+p_j)$ (and this would, indeed, yield the right result), but I m not sure if this is indeed so. Suggestions for how to go about this are greatly appreciated! UPDATE :  @grand_chat very nicely answered the question about the distribution of $X_i + X_j$. How would we go about computing the variance of $X_i - X_j$? As @grand_chat correctly points out, this cannot be binomial because it is not guaranteed to be positive. How, then, should one go about computing the variance of this random variable? UPDATE 2 : The answer in this link answers the question in my UPDATE .",,"['statistics', 'probability-distributions', 'random-variables', 'covariance']"
92,$E(X^2)=E(X)=1$. Find $E(X^{100}).$,. Find,E(X^2)=E(X)=1 E(X^{100}).,"$X$ is a random variable such that $E(X^2)=E(X)=1$. Find $E(X^{100}).$ My attempt: Assuming $X$ is discrete, we have $\sum x_i\mathbb P(X=x_i) = \sum x_i^2\mathbb P(X=x_i) = 1.$ We have something like $x_1p_1+\cdots+x_np_n=x_1^2p_1+\cdots+x_n^2p_n=1$. How do I find out $\sum x_i^{100}\mathbb P(X=x_i)$? I am completely blank. And, I am feeling uneasy as $X$ could well be continuous. How do I proceed then?","$X$ is a random variable such that $E(X^2)=E(X)=1$. Find $E(X^{100}).$ My attempt: Assuming $X$ is discrete, we have $\sum x_i\mathbb P(X=x_i) = \sum x_i^2\mathbb P(X=x_i) = 1.$ We have something like $x_1p_1+\cdots+x_np_n=x_1^2p_1+\cdots+x_n^2p_n=1$. How do I find out $\sum x_i^{100}\mathbb P(X=x_i)$? I am completely blank. And, I am feeling uneasy as $X$ could well be continuous. How do I proceed then?",,"['statistics', 'expectation']"
93,Intuition and the math behind normalization,Intuition and the math behind normalization,,"What exactly is the purpose of normalization. From what I read, it is to adjust two different sets of values so you can compare them, but I don't understand why, nor the math behind it. Could anyone answer this by also giving a concrete example? Thanks!","What exactly is the purpose of normalization. From what I read, it is to adjust two different sets of values so you can compare them, but I don't understand why, nor the math behind it. Could anyone answer this by also giving a concrete example? Thanks!",,"['statistics', 'multivariable-calculus', 'normal-distribution', 'regression']"
94,Probability distribution of dot product?,Probability distribution of dot product?,,"Sorry if this is a basic question. I don't know much about statistics and the closest thing I found involved unit vectors, a case I don't think is easily generalizable to this problem. I have a reference vector $\mathbf V$ in some $\mathbb R^n$. I have another vector in $\mathbb R^n$ of independent random variables, each with Gaussian distribution, each with the same standard deviation $\sigma$. Let's call the vector $\mathbf X$. What is the probability distribution of $\mathbf V\cdot \mathbf X$? Surely this is a famous problem with a widely known solution. Or is there an elegant approach to the problem?","Sorry if this is a basic question. I don't know much about statistics and the closest thing I found involved unit vectors, a case I don't think is easily generalizable to this problem. I have a reference vector $\mathbf V$ in some $\mathbb R^n$. I have another vector in $\mathbb R^n$ of independent random variables, each with Gaussian distribution, each with the same standard deviation $\sigma$. Let's call the vector $\mathbf X$. What is the probability distribution of $\mathbf V\cdot \mathbf X$? Surely this is a famous problem with a widely known solution. Or is there an elegant approach to the problem?",,"['statistics', 'multivariable-calculus']"
95,Statistics Workshop for High School Students,Statistics Workshop for High School Students,,"We are going to hold an introductory workshop about the statistics. The participants will be students who have just finished their 8th or 9th grade. The workshop consists of 10 two-hour sessions. The students have a very limited background about the statistics: They can compute arithmetic average of a set of data, create pie charts, etc. So we’re looking for some good educational material to introduce the students to some of the main statistical ideas, methods and concepts as well as to illustrate the importance of statistics in daily life. Your suggestions would be of great help. Thanks.","We are going to hold an introductory workshop about the statistics. The participants will be students who have just finished their 8th or 9th grade. The workshop consists of 10 two-hour sessions. The students have a very limited background about the statistics: They can compute arithmetic average of a set of data, create pie charts, etc. So we’re looking for some good educational material to introduce the students to some of the main statistical ideas, methods and concepts as well as to illustrate the importance of statistics in daily life. Your suggestions would be of great help. Thanks.",,"['statistics', 'soft-question', 'education']"
96,"Poisson distribution, mean time and probability of waiting","Poisson distribution, mean time and probability of waiting",,"We know that average number of planes landing at particular airport during an hour is 36. a) what is the mean time for waiting for the first landing during an hour? b) find probability of waiting more than 1/2 hour to see the first landing? I assumed this is Poisson distribution as Exponential is memoryless (each minute would have independent probability, am I right?) But to be honest I don't really know what to do next. I wrote down the data from the task: $$\lambda = 36$$ And I'm stuck. Looking more for tips how to solve this task, not full solution. Thank you for help in advance.","We know that average number of planes landing at particular airport during an hour is 36. a) what is the mean time for waiting for the first landing during an hour? b) find probability of waiting more than 1/2 hour to see the first landing? I assumed this is Poisson distribution as Exponential is memoryless (each minute would have independent probability, am I right?) But to be honest I don't really know what to do next. I wrote down the data from the task: $$\lambda = 36$$ And I'm stuck. Looking more for tips how to solve this task, not full solution. Thank you for help in advance.",,"['statistics', 'probability-distributions']"
97,Linear transformation of normal distribution,Linear transformation of normal distribution,,"Not sure if ""linear transformation"" is the correct terminology, but... Let $X$ be a random variable with a normal distribution $f(x)$ with mean $\mu_{X}$ and standard deviation $\sigma_{X}$: $$f(x) = \frac{1}{\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^2\right]}$$ (Here, $\tau=2\pi$) Let $Y$ be a random variable defined by the linear transformation $$Y = u(X) = aX+b$$ Let $v(y) = u^{-1}(y) = \frac{y-b}{a}$. Then $v^\prime(y) = \frac{1}{a}$. Prove : $Y$ is normally distributed, with density function $$g(y)=f\bigl(v(y)\bigr)\,\bigl|v^\prime(y)\bigr|$$ $$= \frac{1}{\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{\frac{y-b}{a}-\mu_{X}}{\sigma_{X}}\right)^2\right]}\,\left|\frac{1}{a}\right|$$ $$= \frac{1}{\left|a\right|\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{y-(a\mu_{X}+b)}{a\sigma_{X}}\right)^2\right]}$$ with mean $\mu_{Y} = a\mu_{X}+b$ and standard deviation $\sigma_{Y} = \left|a\right|\sigma_{X}$.","Not sure if ""linear transformation"" is the correct terminology, but... Let $X$ be a random variable with a normal distribution $f(x)$ with mean $\mu_{X}$ and standard deviation $\sigma_{X}$: $$f(x) = \frac{1}{\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^2\right]}$$ (Here, $\tau=2\pi$) Let $Y$ be a random variable defined by the linear transformation $$Y = u(X) = aX+b$$ Let $v(y) = u^{-1}(y) = \frac{y-b}{a}$. Then $v^\prime(y) = \frac{1}{a}$. Prove : $Y$ is normally distributed, with density function $$g(y)=f\bigl(v(y)\bigr)\,\bigl|v^\prime(y)\bigr|$$ $$= \frac{1}{\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{\frac{y-b}{a}-\mu_{X}}{\sigma_{X}}\right)^2\right]}\,\left|\frac{1}{a}\right|$$ $$= \frac{1}{\left|a\right|\sigma_{X}\sqrt{\tau}}\exp{\left[\frac{-1}{2}\left(\frac{y-(a\mu_{X}+b)}{a\sigma_{X}}\right)^2\right]}$$ with mean $\mu_{Y} = a\mu_{X}+b$ and standard deviation $\sigma_{Y} = \left|a\right|\sigma_{X}$.",,"['calculus', 'statistics', 'normal-distribution']"
98,Proving that the magnitude of the sample correlation coefficient is at most $1$,Proving that the magnitude of the sample correlation coefficient is at most,1,"How can you show that the magnitude of the sample correlation coefficient is at most $1$? The formula is huge, I'm not even sure how to approach this. Can anyone point me in the right direction? Note that this is the sample correlation coefficient: $$r_{xy} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{(n-1)s_xs_y} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\displaystyle \sum_{i=1}^{n} (x_i - \bar{x})^2 \displaystyle \sum_{i=1}^{n} (y_i - \bar{y})^2}}$$","How can you show that the magnitude of the sample correlation coefficient is at most $1$? The formula is huge, I'm not even sure how to approach this. Can anyone point me in the right direction? Note that this is the sample correlation coefficient: $$r_{xy} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{(n-1)s_xs_y} = \dfrac{\displaystyle \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\displaystyle \sum_{i=1}^{n} (x_i - \bar{x})^2 \displaystyle \sum_{i=1}^{n} (y_i - \bar{y})^2}}$$",,"['statistics', 'correlation']"
99,Statistics: Where did this function for normal distribution come from?,Statistics: Where did this function for normal distribution come from?,,"I am studying normal distribution for the first time and I'm having trouble understanding where this formula came from: $$\phi(x) = \frac{1}{\sqrt{2\pi}}\, e^{- \frac{\scriptscriptstyle 1}{\scriptscriptstyle 2} x^2}$$ Could someone derive this equation? How about in the general case? $$\frac{1}{\sigma\sqrt{2\pi}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} }$$","I am studying normal distribution for the first time and I'm having trouble understanding where this formula came from: $$\phi(x) = \frac{1}{\sqrt{2\pi}}\, e^{- \frac{\scriptscriptstyle 1}{\scriptscriptstyle 2} x^2}$$ Could someone derive this equation? How about in the general case? $$\frac{1}{\sigma\sqrt{2\pi}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} }$$",,['statistics']
