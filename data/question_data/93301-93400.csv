,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Complex Integral on an ellipse around $\frac{1}{z}$,Complex Integral on an ellipse around,\frac{1}{z},"I'm working on the following problem: Given $a,b>0$, define the path $\gamma$ whose image is an ellipse.   $$\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$$ traced counterclockwise. By showing that $\int_{\gamma}z^{-1}dz = \int_{\gamma}z^{-1}dz$ for a suitable circle show that    $$\int_0^{2\pi}\frac{1}{a^2\cos^2{t}+b^2\sin^2{t}}dt=\frac{2\pi}{ab}$$ Attempt 1: Suppose $\gamma(t)= a \cos(t) + ib\sin(t)$ then we obtain $$\int_0^{2\pi}\frac{-a \sin(t) + ib\cos(t)}{a \cos(t) + ib\sin(t)}dt$$ I tired rationalizing the numerator but end up with $a^2+b^2$ in the numerator and a mess in the denominator. So I'm unable to obtain the LHS. Attempt 2: Recognize $$\int_{\gamma}\frac{1}{z}=\int\frac{\gamma'(t)}{\gamma(t)}dt=\int\frac{\partial}{\partial t}\log(\gamma(t))dt$$ so that $$\frac{\partial}{\partial t}\log(\gamma(t)) = \frac{1}{a^2\cos^2{t}+b^2\sin^2{t}}$$ Integrating in $t$ and exponentiating to solve for $\gamma$ gives a mess. It doesn't reduce either. I think here, there also maybe an issue of branch cuts that I haven't considered carefully. I also recognize that the denominator factors: $(a \cos(t) + ib\sin(t))(a \cos(t) - ib\sin(t))$ I haven't been able to use this information though. Any ideas? Thanks!","I'm working on the following problem: Given $a,b>0$, define the path $\gamma$ whose image is an ellipse.   $$\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$$ traced counterclockwise. By showing that $\int_{\gamma}z^{-1}dz = \int_{\gamma}z^{-1}dz$ for a suitable circle show that    $$\int_0^{2\pi}\frac{1}{a^2\cos^2{t}+b^2\sin^2{t}}dt=\frac{2\pi}{ab}$$ Attempt 1: Suppose $\gamma(t)= a \cos(t) + ib\sin(t)$ then we obtain $$\int_0^{2\pi}\frac{-a \sin(t) + ib\cos(t)}{a \cos(t) + ib\sin(t)}dt$$ I tired rationalizing the numerator but end up with $a^2+b^2$ in the numerator and a mess in the denominator. So I'm unable to obtain the LHS. Attempt 2: Recognize $$\int_{\gamma}\frac{1}{z}=\int\frac{\gamma'(t)}{\gamma(t)}dt=\int\frac{\partial}{\partial t}\log(\gamma(t))dt$$ so that $$\frac{\partial}{\partial t}\log(\gamma(t)) = \frac{1}{a^2\cos^2{t}+b^2\sin^2{t}}$$ Integrating in $t$ and exponentiating to solve for $\gamma$ gives a mess. It doesn't reduce either. I think here, there also maybe an issue of branch cuts that I haven't considered carefully. I also recognize that the denominator factors: $(a \cos(t) + ib\sin(t))(a \cos(t) - ib\sin(t))$ I haven't been able to use this information though. Any ideas? Thanks!",,"['complex-analysis', 'complex-integration']"
1,Reference requestion for complex analysis with a view towards complex geometry,Reference requestion for complex analysis with a view towards complex geometry,,"As a background, I am a beginning graduate student whose background is primarily algebra and algebraic geometry. I have some background in analysis, but it is weaker. In particular I know the basics of measure theory and complex analysis but only at an undergraduate level. I am really interested in the Riemann-Roch theorem, and am approaching it from an algebraic geometry perspective at the moment, but I thought the best way to learn complex analysis would be to approach from the Riemann surface point of view. With that in mind, I am looking for a complex analysis/complex geometry book that is fairly self contained in terms of complex analytic background. Since I want to learn some complex analysis as well, I would like something that doesn't shy away from analytic arguments when necessary, but I would like something with a definite geometric flavour. I feel like the standard answer here is Griffiths and Harris, so perhaps it would be good if people could give me an idea on how this book would serve me for this purpose? I got the impression is was much more algebraic geometry than complex analysis though. The other is Schlag's Complex Analysis and Riemann Surfaces if anyone is able to give me an idea of how that would serve. Does such a book exist, or an I asking too much? To put it shortly, a self-contained complex analysis and complex geometry which doesn't shy away from complex analytic arguments but has a geometric slant with the view towards proving the Riemann-Roch theorem for complex manifolds.","As a background, I am a beginning graduate student whose background is primarily algebra and algebraic geometry. I have some background in analysis, but it is weaker. In particular I know the basics of measure theory and complex analysis but only at an undergraduate level. I am really interested in the Riemann-Roch theorem, and am approaching it from an algebraic geometry perspective at the moment, but I thought the best way to learn complex analysis would be to approach from the Riemann surface point of view. With that in mind, I am looking for a complex analysis/complex geometry book that is fairly self contained in terms of complex analytic background. Since I want to learn some complex analysis as well, I would like something that doesn't shy away from analytic arguments when necessary, but I would like something with a definite geometric flavour. I feel like the standard answer here is Griffiths and Harris, so perhaps it would be good if people could give me an idea on how this book would serve me for this purpose? I got the impression is was much more algebraic geometry than complex analysis though. The other is Schlag's Complex Analysis and Riemann Surfaces if anyone is able to give me an idea of how that would serve. Does such a book exist, or an I asking too much? To put it shortly, a self-contained complex analysis and complex geometry which doesn't shy away from complex analytic arguments but has a geometric slant with the view towards proving the Riemann-Roch theorem for complex manifolds.",,"['complex-analysis', 'reference-request', 'complex-geometry', 'algebraic-curves', 'riemann-surfaces']"
2,Evaluating 4-dim'l Euclidean integral using spherical coordinates,Evaluating 4-dim'l Euclidean integral using spherical coordinates,,"Scenario: I have an integral originally expressed in Cartesian coordinates which should--in principle--converge, but I have difficulty evaluating it explicitly (due to apparent divergences) in spherical coordinates using the residue theorem. Setup: I want to evaluate the following 4-dimensional integral in Euclidean space, \begin{equation} \mathcal{I}_L(x_1,x_2)=\int_{|y-x_2|\le L} d^4y \frac{1}{(y-x_1)^2 (y-x_2)^2}, \tag{1}\label{1} \end{equation} where $y,x_1,x_2$ are 4-vectors; ""$||$"" denotes the Euclidean distance function;  and $(y-x_1)^2\equiv(y-x_1)\cdot(y-x_1)$ with ""$\cdot$"" the dot product.  Also assume $L>0$ but finite. First note that although the integrand diverges at $y=x_1,x_2$, the integral should be expected to converge on dimensional grounds. Also note that shifting the integration variable, $y\to y+x_2$, in \eqref{1} gives, \begin{align} \mathcal{I}_L(x_1,x_2)=\int_{|y|\le L} d^4y \frac{1}{(y-(x_1-x_2))^2 y^2} \tag{2}\label{2}\\ \end{align} Now this 4-dim'l integral can be simplified to a 2-dim'l integral by switching to 4-dim'l ""spherical coordinates"", \begin{align} y^1&=|y|\cos(\phi_1)\\ y^2&=|y|\sin(\phi_1)\cos(\phi_2)\\ y^3&=|y|\sin(\phi_1)\sin(\phi_2)\cos(\phi_3)\\ y^4&=|y|\sin(\phi_1)\sin(\phi_2)\sin(\phi_3),\\ \end{align} where $\phi_1,\phi_2$  range over $[0,\pi]$ while $\phi_3$ ranges over $[0,2\pi]$. [Notation: superscripts denote components of Cartesian 4-vector--i.e. $y=(y^1,y^2,y^3,y^4)$] Choosing to orient our axes such that $\phi_3$ coincides with the angle between the 4-vectors $y$ and $x_1-x_2$ allows us to write \eqref{2} as \begin{align} \mathcal{I}_L(\sigma)&= \int_0^L d|y|\,|y|^3 \int_{S^3} d\Omega_3 \frac{1}{(|y|^2-2|y|\sigma \cos{\phi_3}+\sigma^2)|y|^2}\\ &=\pi \int_0^L d|y| \int_0^{2\pi} d\phi_3 \frac{|y|}{|y|^2-2|y|\sigma \cos{\phi_3}+\sigma^2}, \label{3}\tag{3}\\ \end{align} where I define the shorthand $\sigma\equiv |x_1-x_2|$. Now, the angular part of the integral in \eqref{3} looks like a good candidate for a calculus of residues approach, so I take $z=e^{i\phi}$ and find \begin{align} \mathcal{I}_L(\sigma)&=\pi i \int_0^L d|y| \oint_{|z|=1}dz \frac{|y| }{(|y|z-\sigma)(\sigma z-|y|)}\\ &=\frac{\pi i}{\sigma}\int_0^L d|y|\oint_{|z|=1}dz\frac{1}{(z-\sigma/|y|)(z-|y|/\sigma)}.\label{4}\tag{4}\\ \end{align} Using the residue theorem, I find \begin{align} \oint_{|z|=1}dz\frac{dz}{(z-\sigma/|y|)(z-|y|/\sigma)}=2\pi i \frac{\sigma |y|}{|y|^2-\sigma^2}\left\{ \theta (\sigma-|y|)-\theta (|y|-\sigma)\right\}, \tag{5}\label{5} \end{align} where $\theta(x>0)=1$ and $\theta(x)=0$ otherwise. Plugging \eqref{5} into \eqref{4}, yields \begin{align} \mathcal{I}_L(\sigma)=-2\pi^2\int_0^L d|y|\frac{|y|}{|y|^2-\sigma^2}\left\{ \theta (\sigma-|y|)-\theta (|y|-\sigma)\right\} \label{*} \tag{*} \end{align} Confusion/Contradiction: For $L<\sigma$, \eqref{*} does seem to give a convergent result: \begin{align} \mathcal{I}_{L<\sigma}(\sigma)=-\pi^2 \ln\left[1-L^2/\sigma^2\right].\\ \end{align} [Recall: I have defined the shorthand $\sigma\equiv |x_1-x_2|$] However, for $L\ge\sigma$, $\eqref{*}$ seems to diverge which contradicts the obvious convergence of $\eqref{1}$. More explicitly, for $L\ge\sigma$, the integral \eqref{*} naturally splits into 2 parts: \begin{align} \mathcal{I}_L(\sigma)&=-2\pi^2\left[ \int_0^\sigma-\int_\sigma^L\right] d|y|\frac{|y|}{|y|^2-\sigma^2}\\ &=-\pi^2 \left[ \ln{(|y|^2-\sigma^2)}\right]^\sigma_0+\pi^2\left[\ln{(|y|^2-\sigma^2)}\right]^L_\sigma\\ &\sim -\infty\\ \end{align} Edit: (elaboration on H.H.Rugh's answer) As correctly pointed out by H.H.Rugh below, $\phi_3$ cannot be chosen to coincide with the angle between $y$ and $x_1-x_2$.  The nature of my mistake can be easily visualized in 3-dimensional Euclidean space, where it is conventional to choose one angle $\phi:[0,2\pi]$ to denote rotations in the ""$x,y$""-plane around the ""$z$-axis"" and one angle $\theta:[0,\pi]$ to denote rotations away from the $z$-axis as follows: \begin{align} x&=r \sin\theta \cos\phi\\ y&=r \sin\theta \sin\phi\\ z&=r \cos\theta,\\ \end{align} where $r^2=x^2+y^2+z^2$. Clearly the $\theta$-component of an arbitrary 3-vector in spherical coordinates, $(r,\phi,\theta)$ coincides with the angle between that 3-vector and one lying along the $z$-axis.  However, the $\phi$-component of that same arbitrary 3-vector does not necessarily coincide with the angle between that 3-vector and one lying along the $x$ or $y$-axis.  This is analogous to my mistake of choosing $\phi_3$ to coincide with the angle between the 4-vectors $y$ and $x_1-x_2$. For completeness, I also explicitly finish the computation started by H.H.Rugh, beginning with \begin{align} \mathcal{I}_L(\sigma)&= 2\pi \int_0^L dr \int_0^{2\pi} d\phi  \frac{r \sin^2 \phi}{r^2 - 2 r \sigma \cos \phi_1 + \sigma^2 } \\ &=\frac{i\pi}{2\sigma}\int_0^L dr \oint_{z=1} dz \frac{(z^2-1)^2}{z^2(z-\sigma/r)(z-r/\sigma)}\\ \end{align} There is now an additional relevant residue at $z=0$.  Applying the residue theorem, I find $$ \mathcal{I}_{L}(\sigma)= \begin{cases} \pi^2 L^2/\sigma^2 & \text{if } L<\sigma  \\ \pi^2 \left(1+\ln(L^2/\sigma)\right) & \text{if } L\ge \sigma\\ \end{cases} $$","Scenario: I have an integral originally expressed in Cartesian coordinates which should--in principle--converge, but I have difficulty evaluating it explicitly (due to apparent divergences) in spherical coordinates using the residue theorem. Setup: I want to evaluate the following 4-dimensional integral in Euclidean space, \begin{equation} \mathcal{I}_L(x_1,x_2)=\int_{|y-x_2|\le L} d^4y \frac{1}{(y-x_1)^2 (y-x_2)^2}, \tag{1}\label{1} \end{equation} where $y,x_1,x_2$ are 4-vectors; ""$||$"" denotes the Euclidean distance function;  and $(y-x_1)^2\equiv(y-x_1)\cdot(y-x_1)$ with ""$\cdot$"" the dot product.  Also assume $L>0$ but finite. First note that although the integrand diverges at $y=x_1,x_2$, the integral should be expected to converge on dimensional grounds. Also note that shifting the integration variable, $y\to y+x_2$, in \eqref{1} gives, \begin{align} \mathcal{I}_L(x_1,x_2)=\int_{|y|\le L} d^4y \frac{1}{(y-(x_1-x_2))^2 y^2} \tag{2}\label{2}\\ \end{align} Now this 4-dim'l integral can be simplified to a 2-dim'l integral by switching to 4-dim'l ""spherical coordinates"", \begin{align} y^1&=|y|\cos(\phi_1)\\ y^2&=|y|\sin(\phi_1)\cos(\phi_2)\\ y^3&=|y|\sin(\phi_1)\sin(\phi_2)\cos(\phi_3)\\ y^4&=|y|\sin(\phi_1)\sin(\phi_2)\sin(\phi_3),\\ \end{align} where $\phi_1,\phi_2$  range over $[0,\pi]$ while $\phi_3$ ranges over $[0,2\pi]$. [Notation: superscripts denote components of Cartesian 4-vector--i.e. $y=(y^1,y^2,y^3,y^4)$] Choosing to orient our axes such that $\phi_3$ coincides with the angle between the 4-vectors $y$ and $x_1-x_2$ allows us to write \eqref{2} as \begin{align} \mathcal{I}_L(\sigma)&= \int_0^L d|y|\,|y|^3 \int_{S^3} d\Omega_3 \frac{1}{(|y|^2-2|y|\sigma \cos{\phi_3}+\sigma^2)|y|^2}\\ &=\pi \int_0^L d|y| \int_0^{2\pi} d\phi_3 \frac{|y|}{|y|^2-2|y|\sigma \cos{\phi_3}+\sigma^2}, \label{3}\tag{3}\\ \end{align} where I define the shorthand $\sigma\equiv |x_1-x_2|$. Now, the angular part of the integral in \eqref{3} looks like a good candidate for a calculus of residues approach, so I take $z=e^{i\phi}$ and find \begin{align} \mathcal{I}_L(\sigma)&=\pi i \int_0^L d|y| \oint_{|z|=1}dz \frac{|y| }{(|y|z-\sigma)(\sigma z-|y|)}\\ &=\frac{\pi i}{\sigma}\int_0^L d|y|\oint_{|z|=1}dz\frac{1}{(z-\sigma/|y|)(z-|y|/\sigma)}.\label{4}\tag{4}\\ \end{align} Using the residue theorem, I find \begin{align} \oint_{|z|=1}dz\frac{dz}{(z-\sigma/|y|)(z-|y|/\sigma)}=2\pi i \frac{\sigma |y|}{|y|^2-\sigma^2}\left\{ \theta (\sigma-|y|)-\theta (|y|-\sigma)\right\}, \tag{5}\label{5} \end{align} where $\theta(x>0)=1$ and $\theta(x)=0$ otherwise. Plugging \eqref{5} into \eqref{4}, yields \begin{align} \mathcal{I}_L(\sigma)=-2\pi^2\int_0^L d|y|\frac{|y|}{|y|^2-\sigma^2}\left\{ \theta (\sigma-|y|)-\theta (|y|-\sigma)\right\} \label{*} \tag{*} \end{align} Confusion/Contradiction: For $L<\sigma$, \eqref{*} does seem to give a convergent result: \begin{align} \mathcal{I}_{L<\sigma}(\sigma)=-\pi^2 \ln\left[1-L^2/\sigma^2\right].\\ \end{align} [Recall: I have defined the shorthand $\sigma\equiv |x_1-x_2|$] However, for $L\ge\sigma$, $\eqref{*}$ seems to diverge which contradicts the obvious convergence of $\eqref{1}$. More explicitly, for $L\ge\sigma$, the integral \eqref{*} naturally splits into 2 parts: \begin{align} \mathcal{I}_L(\sigma)&=-2\pi^2\left[ \int_0^\sigma-\int_\sigma^L\right] d|y|\frac{|y|}{|y|^2-\sigma^2}\\ &=-\pi^2 \left[ \ln{(|y|^2-\sigma^2)}\right]^\sigma_0+\pi^2\left[\ln{(|y|^2-\sigma^2)}\right]^L_\sigma\\ &\sim -\infty\\ \end{align} Edit: (elaboration on H.H.Rugh's answer) As correctly pointed out by H.H.Rugh below, $\phi_3$ cannot be chosen to coincide with the angle between $y$ and $x_1-x_2$.  The nature of my mistake can be easily visualized in 3-dimensional Euclidean space, where it is conventional to choose one angle $\phi:[0,2\pi]$ to denote rotations in the ""$x,y$""-plane around the ""$z$-axis"" and one angle $\theta:[0,\pi]$ to denote rotations away from the $z$-axis as follows: \begin{align} x&=r \sin\theta \cos\phi\\ y&=r \sin\theta \sin\phi\\ z&=r \cos\theta,\\ \end{align} where $r^2=x^2+y^2+z^2$. Clearly the $\theta$-component of an arbitrary 3-vector in spherical coordinates, $(r,\phi,\theta)$ coincides with the angle between that 3-vector and one lying along the $z$-axis.  However, the $\phi$-component of that same arbitrary 3-vector does not necessarily coincide with the angle between that 3-vector and one lying along the $x$ or $y$-axis.  This is analogous to my mistake of choosing $\phi_3$ to coincide with the angle between the 4-vectors $y$ and $x_1-x_2$. For completeness, I also explicitly finish the computation started by H.H.Rugh, beginning with \begin{align} \mathcal{I}_L(\sigma)&= 2\pi \int_0^L dr \int_0^{2\pi} d\phi  \frac{r \sin^2 \phi}{r^2 - 2 r \sigma \cos \phi_1 + \sigma^2 } \\ &=\frac{i\pi}{2\sigma}\int_0^L dr \oint_{z=1} dz \frac{(z^2-1)^2}{z^2(z-\sigma/r)(z-r/\sigma)}\\ \end{align} There is now an additional relevant residue at $z=0$.  Applying the residue theorem, I find $$ \mathcal{I}_{L}(\sigma)= \begin{cases} \pi^2 L^2/\sigma^2 & \text{if } L<\sigma  \\ \pi^2 \left(1+\ln(L^2/\sigma)\right) & \text{if } L\ge \sigma\\ \end{cases} $$",,"['complex-analysis', 'mathematical-physics', 'residue-calculus', 'spherical-coordinates', 'multiple-integral']"
3,Is there a sequence of real polynomials which converge uniformly on an interval in $\mathbb{R}$ but not on a rectangle in $\mathbb{C}$?,Is there a sequence of real polynomials which converge uniformly on an interval in  but not on a rectangle in ?,\mathbb{R} \mathbb{C},"In particular I wondered about the following: The Weierstrass-function $\mathcal{W}$ is continuous and nowhere differentiable. By the Stone-Weierstrass-Theorem we can approximate $\mathcal{W}$ on $[0,1]$ uniformly by real polynomials. Let $p_n(x)$ be such a sequence of polynomials. Now we consider the $p_n$ as complex polynomials. On $[0,1]$ the $p_n$ of course still converge pointwise to $\mathcal{W}$. On $[0,1]\times i[-\frac{1}{2},\frac{1}{2}]\subseteq\mathbb{C}$ however this convergence can not be uniform anymore, as this would imply holomorphy on $(0,1)\times i(-\frac{1}{2},\frac{1}{2})$ which would imply real differentiability on $(0,1)$. I find this very unintuitive, so i would like to see a concrete example of a sequence of polynomials converging uniformly on some $[a,b]\subseteq \mathbb{R}$ but not converging uniformly on any $[a,b]\times i[-\epsilon,\epsilon]\subseteq\mathbb{C}$, if possible with a direct verification that this is (not) the case.","In particular I wondered about the following: The Weierstrass-function $\mathcal{W}$ is continuous and nowhere differentiable. By the Stone-Weierstrass-Theorem we can approximate $\mathcal{W}$ on $[0,1]$ uniformly by real polynomials. Let $p_n(x)$ be such a sequence of polynomials. Now we consider the $p_n$ as complex polynomials. On $[0,1]$ the $p_n$ of course still converge pointwise to $\mathcal{W}$. On $[0,1]\times i[-\frac{1}{2},\frac{1}{2}]\subseteq\mathbb{C}$ however this convergence can not be uniform anymore, as this would imply holomorphy on $(0,1)\times i(-\frac{1}{2},\frac{1}{2})$ which would imply real differentiability on $(0,1)$. I find this very unintuitive, so i would like to see a concrete example of a sequence of polynomials converging uniformly on some $[a,b]\subseteq \mathbb{R}$ but not converging uniformly on any $[a,b]\times i[-\epsilon,\epsilon]\subseteq\mathbb{C}$, if possible with a direct verification that this is (not) the case.",,"['complex-analysis', 'polynomials', 'uniform-convergence']"
4,How to find a conformal map from the upper half-plane to this L-shaped domain?,How to find a conformal map from the upper half-plane to this L-shaped domain?,,"I want to find an integral representation of the conformal map that sends the upper half plane $\text {Im}z>0$ onto the infinite L-shaped region $$ \Omega = \{z = x+iy; \ x > 0, \ y > 0, \ \min(a,\frac yb) < 1 \} $$ which is a slight modification of this question , where we change the vertex of the turn from the point $1+i$ to the more general point $1+bi$ in the first quadrant. (This is an exercise in Gamelin's text) By the Schwarz-Christoffel formula, the solution is of the form $$ F(w) = K\int_{z_1}^w (\zeta-z_0)^{-1}(\zeta-z_1)^{-1/2}(\zeta-z_2)^{-1} \ d\zeta $$ where $z_0, z_1, z_2$ are the numbers that get mapped by the conformal mapping to the vertices at $i \infty, 0, +\infty$ respectively. I do not know what are these preimages of the vertices. In the linked question they are given as $+1, -1, 0, \infty$ for the particular case. Ahlfors says in his book that in general there is no formula for determining the prevertices, and only $3$ of them can be arbitrarily chosen. Since we have $4$ points to determine in this case, we may assume that $3$ of the prevertices are $z_0=-1, z_1=0, z_2=\infty$. I was told that the right decision for the remaining vertex is $b^2$. How can I get this? Is there an intuitive explanation for why this is the right choice of the prevertex $z_2$, perhaps using the symmetry of the domain along the line $y=bx$?","I want to find an integral representation of the conformal map that sends the upper half plane $\text {Im}z>0$ onto the infinite L-shaped region $$ \Omega = \{z = x+iy; \ x > 0, \ y > 0, \ \min(a,\frac yb) < 1 \} $$ which is a slight modification of this question , where we change the vertex of the turn from the point $1+i$ to the more general point $1+bi$ in the first quadrant. (This is an exercise in Gamelin's text) By the Schwarz-Christoffel formula, the solution is of the form $$ F(w) = K\int_{z_1}^w (\zeta-z_0)^{-1}(\zeta-z_1)^{-1/2}(\zeta-z_2)^{-1} \ d\zeta $$ where $z_0, z_1, z_2$ are the numbers that get mapped by the conformal mapping to the vertices at $i \infty, 0, +\infty$ respectively. I do not know what are these preimages of the vertices. In the linked question they are given as $+1, -1, 0, \infty$ for the particular case. Ahlfors says in his book that in general there is no formula for determining the prevertices, and only $3$ of them can be arbitrarily chosen. Since we have $4$ points to determine in this case, we may assume that $3$ of the prevertices are $z_0=-1, z_1=0, z_2=\infty$. I was told that the right decision for the remaining vertex is $b^2$. How can I get this? Is there an intuitive explanation for why this is the right choice of the prevertex $z_2$, perhaps using the symmetry of the domain along the line $y=bx$?",,"['complex-analysis', 'analysis', 'conformal-geometry']"
5,Complex plane iteration of z^z,Complex plane iteration of z^z,,"How can I identify when the iterative sequence $z \to z^z$ is not going to head for infinity for some starting value $z$? For example, $z=1$ is fixed, since $1^1 = 1$. If $z$ is real and between 0 and 1, the iteration heads for 1, where it stays. When starting $z$ is real and greater than 1, then the iteration heads for infinity. When $z$ starts out negative, however, complex numbers quickly come into play. $-1+0i$, for instance, quickly zeros in on $1+0i$; however, $-0.5+0i$ quickly exceeds computing parameters. Restating $z$ as $x + yi$ and showing the iterations to the point of exceeding computing capacity are as follows: $$-0.5 \to -1.414213562i \to 691.6428072-369.0287525i \to NAN.$$ Guidelines for complex exponentiation here: http://mathworld.wolfram.com/ComplexExponentiation.html This reminds me of the iteration behind the Mandelbrot set: $z\to z^2+c$. In the case of the Mandelbrot set, however, it's easy to identify when a $z$ is reached that will head for infinity (when the absolute value of $z$ exceeds 2). When plotting the Mandelbrot set on the complex plane, the program merely needs to catch when 2 is exceeded, and excludes the point being evaluated from the set. I would really like to see a plot of the set of points $x+iy$ on the complex plane where the iteration $x+yi \to (x+yi)^{x+yi}$ does not head for infinity. I suspect all such points zero-in on the value $1+0i$ but I am not sure they do. There may be other 'equilibrium' values, or there may be values where a repeated cycle forms (as is the case for points in the Mandelbrot set). I have done a plot for this, however, in this case I was simply assuming that the iteration was headed for infinity whenever $x$ or $y$ exceeded 10 - I'm not sure this is the case! Another problem is that the plot sometimes exclude points when they come close to $0+0i$ (calculation problem - I could fix this but the other problem of excessively high values remains). Here's the plot image: Obviously, the set is fractal in nature, so I would really like to see it calculated correctly. Most of the points excluded in the plot are excluded because they yield an iteration where $x$ or $y$ exceeds 10. I am pretty sure, however, that there are some very high numbers that do not head for infinity - having the imaginary unit in the exponent means that a very high positive input can become a very high negative input in the next iteration, such that the high negative real number in the exponent creates a real number in the iteration following that one that is very close to zero, thus zeroing-in on $1 + 0i$ in iterations following that. I even suspect that numbers that exceed my computers computing capacity (something like $10^{360}$ or something) may eventually come back to $1+0i$ if my computer could just compute further iterations. Might this in fact be the case for all starting values that contain a non-zero imaginary component? Could this be proven one way or the other?","How can I identify when the iterative sequence $z \to z^z$ is not going to head for infinity for some starting value $z$? For example, $z=1$ is fixed, since $1^1 = 1$. If $z$ is real and between 0 and 1, the iteration heads for 1, where it stays. When starting $z$ is real and greater than 1, then the iteration heads for infinity. When $z$ starts out negative, however, complex numbers quickly come into play. $-1+0i$, for instance, quickly zeros in on $1+0i$; however, $-0.5+0i$ quickly exceeds computing parameters. Restating $z$ as $x + yi$ and showing the iterations to the point of exceeding computing capacity are as follows: $$-0.5 \to -1.414213562i \to 691.6428072-369.0287525i \to NAN.$$ Guidelines for complex exponentiation here: http://mathworld.wolfram.com/ComplexExponentiation.html This reminds me of the iteration behind the Mandelbrot set: $z\to z^2+c$. In the case of the Mandelbrot set, however, it's easy to identify when a $z$ is reached that will head for infinity (when the absolute value of $z$ exceeds 2). When plotting the Mandelbrot set on the complex plane, the program merely needs to catch when 2 is exceeded, and excludes the point being evaluated from the set. I would really like to see a plot of the set of points $x+iy$ on the complex plane where the iteration $x+yi \to (x+yi)^{x+yi}$ does not head for infinity. I suspect all such points zero-in on the value $1+0i$ but I am not sure they do. There may be other 'equilibrium' values, or there may be values where a repeated cycle forms (as is the case for points in the Mandelbrot set). I have done a plot for this, however, in this case I was simply assuming that the iteration was headed for infinity whenever $x$ or $y$ exceeded 10 - I'm not sure this is the case! Another problem is that the plot sometimes exclude points when they come close to $0+0i$ (calculation problem - I could fix this but the other problem of excessively high values remains). Here's the plot image: Obviously, the set is fractal in nature, so I would really like to see it calculated correctly. Most of the points excluded in the plot are excluded because they yield an iteration where $x$ or $y$ exceeds 10. I am pretty sure, however, that there are some very high numbers that do not head for infinity - having the imaginary unit in the exponent means that a very high positive input can become a very high negative input in the next iteration, such that the high negative real number in the exponent creates a real number in the iteration following that one that is very close to zero, thus zeroing-in on $1 + 0i$ in iterations following that. I even suspect that numbers that exceed my computers computing capacity (something like $10^{360}$ or something) may eventually come back to $1+0i$ if my computer could just compute further iterations. Might this in fact be the case for all starting values that contain a non-zero imaginary component? Could this be proven one way or the other?",,"['complex-analysis', 'exponentiation', 'complex-dynamics']"
6,About Terence Tao's blog-notes on complex analysis,About Terence Tao's blog-notes on complex analysis,,"I'm planning to have a first-read in complex analysis before I study advanced texts like Stein-Shakarchi or Remmert . So I was looking for some basic notes or book geared towards setting strong foundations in the concepts. Terence Tao 's complex analysis notes are posted in his blog (Note that the order of the notes are newest-first, i.e. the first post is at the bottom of the page and the last is on the top). Here's the link: https://terrytao.wordpress.com/category/teaching/246a-complex-analysis/ What are the pre-requisites of these sets of notes? Thanks in advance.","I'm planning to have a first-read in complex analysis before I study advanced texts like Stein-Shakarchi or Remmert . So I was looking for some basic notes or book geared towards setting strong foundations in the concepts. Terence Tao 's complex analysis notes are posted in his blog (Note that the order of the notes are newest-first, i.e. the first post is at the bottom of the page and the last is on the top). Here's the link: https://terrytao.wordpress.com/category/teaching/246a-complex-analysis/ What are the pre-requisites of these sets of notes? Thanks in advance.",,"['complex-analysis', 'reference-request']"
7,Evaluating an indefinite integral using complex analysis,Evaluating an indefinite integral using complex analysis,,"Using tools from complex analysis, I have to prove that $$ \int_0^{\infty} \frac{\ln x}{(x^2 + 1)^2}\,dx = - \frac{\pi}{4}.$$ But I'm not really sure where I should start. Any help would be appreciated.","Using tools from complex analysis, I have to prove that $$ \int_0^{\infty} \frac{\ln x}{(x^2 + 1)^2}\,dx = - \frac{\pi}{4}.$$ But I'm not really sure where I should start. Any help would be appreciated.",,"['complex-analysis', 'indefinite-integrals', 'complex-integration']"
8,Laurent Series expansion without geometric series,Laurent Series expansion without geometric series,,"There are several functions in complex analysis which I have not been able to get the Laurent expansion for, both of which are very different from the examples I see online and in the (4) textbooks I have checked out...: I need to find the Laurent expansion about each singularity of the following function:  $$f(z) = {1 \over z^6+1}$$ I had no issue with finding the singular points, but I don't see how to create a Laurent expansion from there---all of the online examples show something like: $$f(x) = {1 \over z(z-1)}$$  In which it is much more clear how to use a geometric series to find the Laurent series. I also have the same issue for the following function: $$f(z) = {1 \over z^4+2z^2+1}$$ I can find the singularities, but where do I go from there? The examples found online are tough to map onto these problems.","There are several functions in complex analysis which I have not been able to get the Laurent expansion for, both of which are very different from the examples I see online and in the (4) textbooks I have checked out...: I need to find the Laurent expansion about each singularity of the following function:  $$f(z) = {1 \over z^6+1}$$ I had no issue with finding the singular points, but I don't see how to create a Laurent expansion from there---all of the online examples show something like: $$f(x) = {1 \over z(z-1)}$$  In which it is much more clear how to use a geometric series to find the Laurent series. I also have the same issue for the following function: $$f(z) = {1 \over z^4+2z^2+1}$$ I can find the singularities, but where do I go from there? The examples found online are tough to map onto these problems.",,"['complex-analysis', 'laurent-series']"
9,Contour integral of $\sqrt{z^{2}+a^{2}}$,Contour integral of,\sqrt{z^{2}+a^{2}},"Suppose $a$ is real and nonnegative. Say we wanted to compute the above function (for whatever reason, be it to solve an improper real integral, or something else) along the curve $C$, as on the picture. I have chosen the contour as to avoid the branch cut connecting the three branch points. Supposing  $arg\left ( z \right ) \in \left [ 0,  2\pi \right )$ I also made parametrisations for each part of the contour. However, I wasn't able to do so for the parts  $C_{i}$, $i=1,2,3$. In several integrals like this and this one Ron talks about assigning a phase to the segments. To me it seems like he is assigning the phase  as if the branch point was now the origin of the plane, and the phase he added was relative to that point, am I right on this one? With that being said I would say that $$C2:  z=iye^{i\pi}$$ $$C3:  z=iye^{-i\pi}$$ $$C1:  z=iye^{i0}$$ However this doesn't look right as the argument wasn't defined for $\left [ -\pi,\pi \right )$. How do we deal with these branch cuts? And how to know what phase to add? Note that I have asked a similar question here for a different function, but I didn't receive satisfactory answers(due to my poor wording, I guess).","Suppose $a$ is real and nonnegative. Say we wanted to compute the above function (for whatever reason, be it to solve an improper real integral, or something else) along the curve $C$, as on the picture. I have chosen the contour as to avoid the branch cut connecting the three branch points. Supposing  $arg\left ( z \right ) \in \left [ 0,  2\pi \right )$ I also made parametrisations for each part of the contour. However, I wasn't able to do so for the parts  $C_{i}$, $i=1,2,3$. In several integrals like this and this one Ron talks about assigning a phase to the segments. To me it seems like he is assigning the phase  as if the branch point was now the origin of the plane, and the phase he added was relative to that point, am I right on this one? With that being said I would say that $$C2:  z=iye^{i\pi}$$ $$C3:  z=iye^{-i\pi}$$ $$C1:  z=iye^{i0}$$ However this doesn't look right as the argument wasn't defined for $\left [ -\pi,\pi \right )$. How do we deal with these branch cuts? And how to know what phase to add? Note that I have asked a similar question here for a different function, but I didn't receive satisfactory answers(due to my poor wording, I guess).",,"['complex-analysis', 'contour-integration', 'branch-cuts']"
10,Mysterious Inverse Mellin transform using residue theorem,Mysterious Inverse Mellin transform using residue theorem,,"The origin of this problem lies in the explanation of the evaluation of the series $\sum_{n\geq1}\frac{\cos(nx)}{n^2}=\frac{x^2}{4}-\frac{2\pi}{4}+\frac{\pi^2}{6}$ see this link ( Series $\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2}$ ) In the proposed solution a complex integral needs to be evaluated, which is a inverse mellin transform. This is done using the residue theorem. Let $Q(s)=-\Gamma(s-2)\zeta(s)\cos(\frac{\pi s}{2})$. The question is how to evaluate $\int_{\frac{5}{2}-i\infty}^{\frac{5}{2}+i\infty} Q(s)/x^s \, ds$ The author states that he integrates over the left plane, I suppose he uses a semi circle as a contour, which includes the 3 poles and if $R\rightarrow +\infty$ the integral over the arc vanishes and the part where $\operatorname{Re}(s)>\frac{5}{2}$ is covered. But how can I prove this? I tried to apply Jensens lemma which didn't work. What am I missing?","The origin of this problem lies in the explanation of the evaluation of the series $\sum_{n\geq1}\frac{\cos(nx)}{n^2}=\frac{x^2}{4}-\frac{2\pi}{4}+\frac{\pi^2}{6}$ see this link ( Series $\sum_{n=1}^{\infty}\frac{\cos(nx)}{n^2}$ ) In the proposed solution a complex integral needs to be evaluated, which is a inverse mellin transform. This is done using the residue theorem. Let $Q(s)=-\Gamma(s-2)\zeta(s)\cos(\frac{\pi s}{2})$. The question is how to evaluate $\int_{\frac{5}{2}-i\infty}^{\frac{5}{2}+i\infty} Q(s)/x^s \, ds$ The author states that he integrates over the left plane, I suppose he uses a semi circle as a contour, which includes the 3 poles and if $R\rightarrow +\infty$ the integral over the arc vanishes and the part where $\operatorname{Re}(s)>\frac{5}{2}$ is covered. But how can I prove this? I tried to apply Jensens lemma which didn't work. What am I missing?",,"['complex-analysis', 'gamma-function', 'residue-calculus', 'zeta-functions', 'mellin-transform']"
11,Triangle Inequality Equality Conditions,Triangle Inequality Equality Conditions,,"I am looking for the conditions on two complex numbers $z_1$ and $z_2$ such that $$|z_1+z_2|=|z_1|+|z_2|$$ Letting $z_n=a_n+ib_n$ and using $|z_n|^2=a_n^2+b_n^2$ yields $$(a_1+a_2)^2+(b_1+b_2)^2=a_1^2+b_1^2+2\sqrt{(a_1^2+b_1^2)(a_2^2+b_2^2)}+a_2^2+b_2^2$$ Expanding and simplifying gives $$a_1a_2+b_1b_2=\sqrt{(a_1^2+b_1^2)(a_2^2+b_2^2)}$$ Squaring, expanding, and simplifying gives $$2a_1a_2b_1b_2=a_1^2b_2^2+a_2^2b_1^2$$ Rearranging gives  $$(a_1b_2-a_2b_1)^2=0$$ Then $a_1b_2=a_2b_1$ I think this is the condition found algebraically.  Intuitively, thinking geometrically, those complex numbers when adding should have the same direction to yield equality.  Are there any other conditions that need to be met, or are there other methods other than algebraically or geometrically that ealisy show these conditions?","I am looking for the conditions on two complex numbers $z_1$ and $z_2$ such that $$|z_1+z_2|=|z_1|+|z_2|$$ Letting $z_n=a_n+ib_n$ and using $|z_n|^2=a_n^2+b_n^2$ yields $$(a_1+a_2)^2+(b_1+b_2)^2=a_1^2+b_1^2+2\sqrt{(a_1^2+b_1^2)(a_2^2+b_2^2)}+a_2^2+b_2^2$$ Expanding and simplifying gives $$a_1a_2+b_1b_2=\sqrt{(a_1^2+b_1^2)(a_2^2+b_2^2)}$$ Squaring, expanding, and simplifying gives $$2a_1a_2b_1b_2=a_1^2b_2^2+a_2^2b_1^2$$ Rearranging gives  $$(a_1b_2-a_2b_1)^2=0$$ Then $a_1b_2=a_2b_1$ I think this is the condition found algebraically.  Intuitively, thinking geometrically, those complex numbers when adding should have the same direction to yield equality.  Are there any other conditions that need to be met, or are there other methods other than algebraically or geometrically that ealisy show these conditions?",,"['complex-analysis', 'proof-verification', 'complex-numbers']"
12,Cauchy Riemann equations necessary and sufficient condition?,Cauchy Riemann equations necessary and sufficient condition?,,"I was taught that $f(z)$ is differentiable at $z_0=x_0+y_0$ iff Cauchy Riemann equations hold at $(x_0,y_0)$. However, I was shown this example: $f(z)=\frac{\operatorname{Re}(z) \cdot \operatorname{Im}(z)}{z}, z \neq 0$ and $f(0)=0$. So Cauchy-Riemann equations hold at $(0,0)$, however the function is not differentiable at $(0,0)$. So is it indeed true that $f(z)$ is differentiable at $z_0=x_0+y_0$ iff Cauchy Riemann equations hold at $(x_0,y_0)$?","I was taught that $f(z)$ is differentiable at $z_0=x_0+y_0$ iff Cauchy Riemann equations hold at $(x_0,y_0)$. However, I was shown this example: $f(z)=\frac{\operatorname{Re}(z) \cdot \operatorname{Im}(z)}{z}, z \neq 0$ and $f(0)=0$. So Cauchy-Riemann equations hold at $(0,0)$, however the function is not differentiable at $(0,0)$. So is it indeed true that $f(z)$ is differentiable at $z_0=x_0+y_0$ iff Cauchy Riemann equations hold at $(x_0,y_0)$?",,"['complex-analysis', 'cauchy-riemann-equations']"
13,Singularities of $ {1}/{\cos(\frac{1}{z})}$,Singularities of, {1}/{\cos(\frac{1}{z})},"I would like to determine the singularities of $f$, given by $$f(z) = \frac{1}{\cos(\frac{1}{z})}.$$ It is clear to me that $z = 0$ and $z = \frac{2}{(1+2k)\pi}$ for $k\in\mathbb Z$ are singularities. However, I don't know how to handle by $$ \cos(\frac{1}{z}) = \sum_{n=0}^\infty \frac{(-1) z^{-2n}}{(2n)!} \;\forall z\neq 0 $$ which are the types of those singularities. I would be very pleased if you give me any hint or explanation.","I would like to determine the singularities of $f$, given by $$f(z) = \frac{1}{\cos(\frac{1}{z})}.$$ It is clear to me that $z = 0$ and $z = \frac{2}{(1+2k)\pi}$ for $k\in\mathbb Z$ are singularities. However, I don't know how to handle by $$ \cos(\frac{1}{z}) = \sum_{n=0}^\infty \frac{(-1) z^{-2n}}{(2n)!} \;\forall z\neq 0 $$ which are the types of those singularities. I would be very pleased if you give me any hint or explanation.",,[]
14,If $f$ has a zero of order m then $f'/f$ has a simple pole,If  has a zero of order m then  has a simple pole,f f'/f,"Let $f$ be analytic in $D_r(z_0)$ and has a zero of order $m$ at $z_0$. I need to show that $f'/f$ has a simple pole at $z_0$. This is part of attempt. Since f has a zero of order $m$ there exists a analytic $g$ such that $$f(z)=g(z)(z-z_0)^m,g(z_0)\neq0$$. Also for some $R_1>0$ such that $0<R_1\leq r$, $g(z)\neq 0$ in $D_{R_1}(z_0)$. Now there are possibilities. $f$ is identically zero or for some $0<R_2\leq r, $ $f(z)\neq 0$ in $D_{R_2}(z_0)$\ {$z_0$}. Assuming the latter is true let $R$=min{$R_1,R_2$}. Let $z\in D_R(z_0)$\ {$z_0$}. Then $$f'(z_0)=mg(z)(z-z_0)^{m-1}+g'(z)(z-z_0)^m \implies \frac{f'(z)}{f(z)}=\frac{m}{z-z_0}+\frac{g'(z)}{g(z)}$$. I am stuck here and don't know how to finish it off. And what about the case where f is identically zero? Any help is appreciated thanks","Let $f$ be analytic in $D_r(z_0)$ and has a zero of order $m$ at $z_0$. I need to show that $f'/f$ has a simple pole at $z_0$. This is part of attempt. Since f has a zero of order $m$ there exists a analytic $g$ such that $$f(z)=g(z)(z-z_0)^m,g(z_0)\neq0$$. Also for some $R_1>0$ such that $0<R_1\leq r$, $g(z)\neq 0$ in $D_{R_1}(z_0)$. Now there are possibilities. $f$ is identically zero or for some $0<R_2\leq r, $ $f(z)\neq 0$ in $D_{R_2}(z_0)$\ {$z_0$}. Assuming the latter is true let $R$=min{$R_1,R_2$}. Let $z\in D_R(z_0)$\ {$z_0$}. Then $$f'(z_0)=mg(z)(z-z_0)^{m-1}+g'(z)(z-z_0)^m \implies \frac{f'(z)}{f(z)}=\frac{m}{z-z_0}+\frac{g'(z)}{g(z)}$$. I am stuck here and don't know how to finish it off. And what about the case where f is identically zero? Any help is appreciated thanks",,"['complex-analysis', 'analysis']"
15,"If f(x)dx is a rectangle with height f(x) and width dx, what is f(z)dz in complex analysis","If f(x)dx is a rectangle with height f(x) and width dx, what is f(z)dz in complex analysis",,"I am trying to intuitively understand the multiplication $f(z)dz$ in complex analysis. For instance, $f(x)dx$, we are all aware, is a rectangle with height $f(x)$ and width $dx$ so its multiplication is an area of this rectangle. Is there a similar way to visualize $f(z)dz$ also?","I am trying to intuitively understand the multiplication $f(z)dz$ in complex analysis. For instance, $f(x)dx$, we are all aware, is a rectangle with height $f(x)$ and width $dx$ so its multiplication is an area of this rectangle. Is there a similar way to visualize $f(z)dz$ also?",,"['complex-analysis', 'intuition']"
16,inverse laplace transform by using complex integral,inverse laplace transform by using complex integral,,"given function $$f(s)=\frac{1}{s}\frac{\sqrt{s}-1}{\sqrt{s}+1}$$ and  $$\int_{0}^{\infty}{\frac{e^{-xt}}{\sqrt{x}(x+1)}dx=\pi e^t {erfc}(\sqrt{t})}$$ my steps: contour:$A->B->C->D->E->F->A$ anti-clockwise $AB$ straight vertical down to up $AB$ $BC$ arc with radius of $R$ $CD$ straight horizontal from $-R$ to $-\epsilon$ $DE$ arc with radius of $-\epsilon$ $EF$ straight horizontal from $-\epsilon$ to $-R$ $FA$ arc with radius of $R$ 1. $\int_{BC}=\int_{FA}=0$ 2.$CD$: $s(x)=xe^{\pi i}$ where $x \in[R -> \epsilon]$ and $s'(x)=e^{\pi i}=-1$ and $\sqrt{s}=i\sqrt{x}$ thus  $$\int_{CD}=\int_{R}^{\epsilon}{\frac{e^{tx{e^{\pi i}}}}{xe^{\pi i}}{\frac{i\sqrt{x}-1}{i\sqrt{x}+1}}{e^{\pi i}}}dx=-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{\frac{i\sqrt{x}-1}{i\sqrt{x}+1}}}dx$$ 3.$EF$ $s(x)=xe^{-\pi i}$ where $x \in[\epsilon -> R]$ and $s'(x)=e^{-\pi i}=-1$ and $\sqrt{s}=-i\sqrt{x}$ thus  $$\int_{EF}=\int_{\epsilon}^{R}{\frac{e^{tx{e^{-\pi i}}}}{xe^{-\pi i}}{\frac{-i\sqrt{x}-1}{-i\sqrt{x}+1}}{e^{-\pi i}}}dx=-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{\frac{i\sqrt{x}+1}{i\sqrt{x}-1}}}dx$$ 4.$DE$ $s(\theta)=\epsilon e^{i \theta}$ where $\theta\in[\pi -> -\pi]$ and $s'(\theta)=i\epsilon e^{i \theta}$ thus $$\int_{\pi}^{-\pi}{\frac{e^{t\epsilon e^{i\theta}}}{\epsilon e^{i\theta}}\frac{\sqrt{\epsilon}{ e^{\frac{i\theta}{2}}-1}}{{\sqrt{\epsilon} e^{\frac{i\theta}{2}}+1}}}{i\epsilon e^{i\theta}}d{\theta}=-i\int_{-\pi}^{\pi}{{e^{t\epsilon e^{i \theta}}}{\frac{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} -1}{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} +1}}}d{\theta}$$ over all $\int_{AB}=-\lim_{R->\infty,\epsilon->0}{[\int_{CD}+\int_{ED}+\int_{EF}]}$ $$\int_{AB}=-\lim_{R->\infty,\epsilon->0}{[-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{(\frac{i\sqrt{x}-1}{i\sqrt{x}+1} + \frac{i\sqrt{x}+1}{i\sqrt{x}-1})}}dx - -i\int_{-\pi}^{\pi}{{e^{t\epsilon e^{i \theta}}}{\frac{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} -1}{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} +1}}}d{\theta}}]$$ $$\int_{AB}=\int_{0}^{\infty}{\frac{e^{-xt}}{x}{\frac{2(x-1)}{x+1}}}dx + i\int_{-\pi}^{\pi}{(-1)d{\theta}}$$ $$=2\int_{0}^{\infty}{\frac{e^{-xt}}{x}{({\frac{x}{x+1}}-{\frac{1}{x+1}})}}dx - 2 \pi i$$ $$=2\int_{0}^{\infty}{{({\frac{e^{-xt}}{x+1}}-{\frac{e^{-xt}}{x(x+1)}})}}dx - 2 \pi i$$ $$=2\int_{0}^{\infty}{{{{\sqrt{x}}\frac{e^{-xt}}{\sqrt{x}(x+1)}}-{\frac{1}{\sqrt{x}}\frac{e^{-xt}}{\sqrt{x}(x+1)}}}}dx - 2 \pi i$$ upto here... then .. I cannot do more.. need help...","given function $$f(s)=\frac{1}{s}\frac{\sqrt{s}-1}{\sqrt{s}+1}$$ and  $$\int_{0}^{\infty}{\frac{e^{-xt}}{\sqrt{x}(x+1)}dx=\pi e^t {erfc}(\sqrt{t})}$$ my steps: contour:$A->B->C->D->E->F->A$ anti-clockwise $AB$ straight vertical down to up $AB$ $BC$ arc with radius of $R$ $CD$ straight horizontal from $-R$ to $-\epsilon$ $DE$ arc with radius of $-\epsilon$ $EF$ straight horizontal from $-\epsilon$ to $-R$ $FA$ arc with radius of $R$ 1. $\int_{BC}=\int_{FA}=0$ 2.$CD$: $s(x)=xe^{\pi i}$ where $x \in[R -> \epsilon]$ and $s'(x)=e^{\pi i}=-1$ and $\sqrt{s}=i\sqrt{x}$ thus  $$\int_{CD}=\int_{R}^{\epsilon}{\frac{e^{tx{e^{\pi i}}}}{xe^{\pi i}}{\frac{i\sqrt{x}-1}{i\sqrt{x}+1}}{e^{\pi i}}}dx=-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{\frac{i\sqrt{x}-1}{i\sqrt{x}+1}}}dx$$ 3.$EF$ $s(x)=xe^{-\pi i}$ where $x \in[\epsilon -> R]$ and $s'(x)=e^{-\pi i}=-1$ and $\sqrt{s}=-i\sqrt{x}$ thus  $$\int_{EF}=\int_{\epsilon}^{R}{\frac{e^{tx{e^{-\pi i}}}}{xe^{-\pi i}}{\frac{-i\sqrt{x}-1}{-i\sqrt{x}+1}}{e^{-\pi i}}}dx=-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{\frac{i\sqrt{x}+1}{i\sqrt{x}-1}}}dx$$ 4.$DE$ $s(\theta)=\epsilon e^{i \theta}$ where $\theta\in[\pi -> -\pi]$ and $s'(\theta)=i\epsilon e^{i \theta}$ thus $$\int_{\pi}^{-\pi}{\frac{e^{t\epsilon e^{i\theta}}}{\epsilon e^{i\theta}}\frac{\sqrt{\epsilon}{ e^{\frac{i\theta}{2}}-1}}{{\sqrt{\epsilon} e^{\frac{i\theta}{2}}+1}}}{i\epsilon e^{i\theta}}d{\theta}=-i\int_{-\pi}^{\pi}{{e^{t\epsilon e^{i \theta}}}{\frac{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} -1}{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} +1}}}d{\theta}$$ over all $\int_{AB}=-\lim_{R->\infty,\epsilon->0}{[\int_{CD}+\int_{ED}+\int_{EF}]}$ $$\int_{AB}=-\lim_{R->\infty,\epsilon->0}{[-\int_{\epsilon}^{R}{\frac{e^{-xt}}{x}{(\frac{i\sqrt{x}-1}{i\sqrt{x}+1} + \frac{i\sqrt{x}+1}{i\sqrt{x}-1})}}dx - -i\int_{-\pi}^{\pi}{{e^{t\epsilon e^{i \theta}}}{\frac{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} -1}{{\sqrt{\epsilon}}{e^{i \frac{\theta}{2}}} +1}}}d{\theta}}]$$ $$\int_{AB}=\int_{0}^{\infty}{\frac{e^{-xt}}{x}{\frac{2(x-1)}{x+1}}}dx + i\int_{-\pi}^{\pi}{(-1)d{\theta}}$$ $$=2\int_{0}^{\infty}{\frac{e^{-xt}}{x}{({\frac{x}{x+1}}-{\frac{1}{x+1}})}}dx - 2 \pi i$$ $$=2\int_{0}^{\infty}{{({\frac{e^{-xt}}{x+1}}-{\frac{e^{-xt}}{x(x+1)}})}}dx - 2 \pi i$$ $$=2\int_{0}^{\infty}{{{{\sqrt{x}}\frac{e^{-xt}}{\sqrt{x}(x+1)}}-{\frac{1}{\sqrt{x}}\frac{e^{-xt}}{\sqrt{x}(x+1)}}}}dx - 2 \pi i$$ upto here... then .. I cannot do more.. need help...",,"['complex-analysis', 'laplace-transform', 'contour-integration']"
17,Show $\sum_n \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z}$,Show,\sum_n \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z},Show $\displaystyle\sum_{n=0}^\infty \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z}$ for $|z|<1$. This is an additional problem for my complex analysis class and I've attempted it for a few hours but ended up taking wrong routes. All of my attempts I haven't used complex analysis at all and I don't see how I could here. edit: this is meant for a BEGINNER complex analysis course so please try keep the solutions to that (if you could) Any help would be great,Show $\displaystyle\sum_{n=0}^\infty \frac{z^{2^n}}{1-z^{2^{n+1}}} = \frac{z}{1-z}$ for $|z|<1$. This is an additional problem for my complex analysis class and I've attempted it for a few hours but ended up taking wrong routes. All of my attempts I haven't used complex analysis at all and I don't see how I could here. edit: this is meant for a BEGINNER complex analysis course so please try keep the solutions to that (if you could) Any help would be great,,['complex-analysis']
18,Show that $\sum \frac{z^n}{n}$ diverges if $z = 1$ but otherwise converges if $|z|=1$.,Show that  diverges if  but otherwise converges if .,\sum \frac{z^n}{n} z = 1 |z|=1,"Hi: I'm reading John D'Angelo's textbook ""An Introduction To Complex Analysis and Geometry"" and trying ( emphasis on trying ) to work on the exercises in Chapter 4. I'm already stuck on only the second one. The question is: Show that $\sum  \frac{z^{n}}{n} $ diverges if $z = 1$ but otherwise converges if $|z| = 1$. I think I might have trouble with each of the exercises and there are 13 more. So, if anyone knows of a existing solution manual for the text, please let me know. I'm not a student so just trying to learn this on my own. Otherwise, I'll just keep trying one per day and posting to this list when I'm stuck. Thanks a lot.","Hi: I'm reading John D'Angelo's textbook ""An Introduction To Complex Analysis and Geometry"" and trying ( emphasis on trying ) to work on the exercises in Chapter 4. I'm already stuck on only the second one. The question is: Show that $\sum  \frac{z^{n}}{n} $ diverges if $z = 1$ but otherwise converges if $|z| = 1$. I think I might have trouble with each of the exercises and there are 13 more. So, if anyone knows of a existing solution manual for the text, please let me know. I'm not a student so just trying to learn this on my own. Otherwise, I'll just keep trying one per day and posting to this list when I'm stuck. Thanks a lot.",,['complex-analysis']
19,How to compute $\int_C {e^{3z}-z\over (z+1)^2z^2}$?,How to compute ?,\int_C {e^{3z}-z\over (z+1)^2z^2},"I am asked to compute the integral $$ \int_C {e^{3z}-z\over (z+1)^2z^2} $$ where $C$ is a circle with the center at the origin and radius ${1 \over 2}$. My approach was to separate the integral as a differentiation of 2 contour integrals: $$ \int_C {e^{3z}-z\over (z+1)^2z^2} = \int_C {e^{3z}\over (z+1)^2z^2} - \int_C {1\over (z+1)^2z} $$ Then I calculated the residue of each contour integral with a Laurent series around $z_0 = 0$: $$ {e^{3z}\over (z+1)^2z^2} = {1\over (z+1^2)}\ .\ e^{3z}\ .\ {1\over z} $$ $$ {e^{3z}\over (z+1)^2z^2} = \sum_{n=0}^\infty {3^nz^{n-2}\over n!}\ .\ (1-2z+3z^2+...) $$ $$ {e^{3z}\over (z+1)^2z^2} = {a_{-2}\over z^2}+{-2+3\over z}+a_0+... $$ So the residue for this contour integral is $1$ and the final result is $2\pi i$ I did the same with the other countour integral: $$ {1\over (z+1)^2z} = {1\over z}\ .\ (1-2z+3z^2+...) $$ $$ {1\over (z+1)^2z} = {1\over z}-2+3z^2+... $$ So the residue for this contour integral is also $1$ and the final result is $2\pi i$ Then I substitute my results in the original contour integral: $$ \int_C {e^{3z}-z\over (z+1)^2z^2} = 2\pi i - 2\pi i $$ And this is where my problem is (I get zero), can someone point to me what I did wrong?","I am asked to compute the integral $$ \int_C {e^{3z}-z\over (z+1)^2z^2} $$ where $C$ is a circle with the center at the origin and radius ${1 \over 2}$. My approach was to separate the integral as a differentiation of 2 contour integrals: $$ \int_C {e^{3z}-z\over (z+1)^2z^2} = \int_C {e^{3z}\over (z+1)^2z^2} - \int_C {1\over (z+1)^2z} $$ Then I calculated the residue of each contour integral with a Laurent series around $z_0 = 0$: $$ {e^{3z}\over (z+1)^2z^2} = {1\over (z+1^2)}\ .\ e^{3z}\ .\ {1\over z} $$ $$ {e^{3z}\over (z+1)^2z^2} = \sum_{n=0}^\infty {3^nz^{n-2}\over n!}\ .\ (1-2z+3z^2+...) $$ $$ {e^{3z}\over (z+1)^2z^2} = {a_{-2}\over z^2}+{-2+3\over z}+a_0+... $$ So the residue for this contour integral is $1$ and the final result is $2\pi i$ I did the same with the other countour integral: $$ {1\over (z+1)^2z} = {1\over z}\ .\ (1-2z+3z^2+...) $$ $$ {1\over (z+1)^2z} = {1\over z}-2+3z^2+... $$ So the residue for this contour integral is also $1$ and the final result is $2\pi i$ Then I substitute my results in the original contour integral: $$ \int_C {e^{3z}-z\over (z+1)^2z^2} = 2\pi i - 2\pi i $$ And this is where my problem is (I get zero), can someone point to me what I did wrong?",,"['complex-analysis', 'contour-integration', 'laurent-series']"
20,Find all entire functions such that $|f(z)|\leq |z^2-1|$ for all $z\in\mathbb C$.,Find all entire functions such that  for all .,|f(z)|\leq |z^2-1| z\in\mathbb C,Find all entire functions such that $|f(z)|\leq |z^2-1|$ for all $z\in\mathbb C$. For large $z$ we have $$|f(z)|\leq 2|z|^2$$ so $f$ is a polynomial of degree $\leq 2$. But how to continue? Could someone give me a hint?,Find all entire functions such that $|f(z)|\leq |z^2-1|$ for all $z\in\mathbb C$. For large $z$ we have $$|f(z)|\leq 2|z|^2$$ so $f$ is a polynomial of degree $\leq 2$. But how to continue? Could someone give me a hint?,,['complex-analysis']
21,Can we prove the Cauchy-Riemann equations using the matrix form of a complex number?,Can we prove the Cauchy-Riemann equations using the matrix form of a complex number?,,"The definition of being complex-differentiable at $z$ can be stated as the existence of $a\in\mathbb C$ such that: $$f(z+h)-f(z)=ah+r(h)|h|$$ For all $h$, where $r(z)\to0$ as $z\to0$. Thinking of complex numbers as elements of $\mathbb R^2$ in the obvious way, this is asserting the existence of a differential for $f:\mathbb R^2\to\mathbb R^2$ at $z$, where that differential is the mapping $z\to az$, which is of course a linear function (its obvious $\mathbb R^2\to\mathbb R^2$ analogue is linear, I mean). But if the mapping if of the form $z\to az$, this implies that its matrix must have a very specific form. The linear mapping $(\Re (z), \Im (z))\to (\Re (az), \Im (az))$ can be shown to always have a matrix in the canonical basis of the form $\bigl(\begin{smallmatrix} x&-y\\ y&x \end{smallmatrix} \bigr)$. But when we compare that to the Jacobian matrix of $f$ at $z$, we get the Cauchy-Riemann equations. Can this be made rigorous? In particular, how could one use it to prove the sufficiency of the CR equations? It seems to me the above only proves necessity.","The definition of being complex-differentiable at $z$ can be stated as the existence of $a\in\mathbb C$ such that: $$f(z+h)-f(z)=ah+r(h)|h|$$ For all $h$, where $r(z)\to0$ as $z\to0$. Thinking of complex numbers as elements of $\mathbb R^2$ in the obvious way, this is asserting the existence of a differential for $f:\mathbb R^2\to\mathbb R^2$ at $z$, where that differential is the mapping $z\to az$, which is of course a linear function (its obvious $\mathbb R^2\to\mathbb R^2$ analogue is linear, I mean). But if the mapping if of the form $z\to az$, this implies that its matrix must have a very specific form. The linear mapping $(\Re (z), \Im (z))\to (\Re (az), \Im (az))$ can be shown to always have a matrix in the canonical basis of the form $\bigl(\begin{smallmatrix} x&-y\\ y&x \end{smallmatrix} \bigr)$. But when we compare that to the Jacobian matrix of $f$ at $z$, we get the Cauchy-Riemann equations. Can this be made rigorous? In particular, how could one use it to prove the sufficiency of the CR equations? It seems to me the above only proves necessity.",,['complex-analysis']
22,Proving the Uniformization Theorem for Elliptic Curves (An Exercise from Silverman's Advanced Topics on Elliptic Curves ),Proving the Uniformization Theorem for Elliptic Curves (An Exercise from Silverman's Advanced Topics on Elliptic Curves ),,"In Silverman's Advanced Topics in the Arithmetic of Elliptic Curves there are two demonstrations of the Uniformization Theorem for the Elliptic Curves (It says that, given an Elliptic Curve $E$, there's a unique lattice such that $E$ is its associated Elliptic Curve). The first proof uses a lot of advanced topics in modular forms, but I'm interested in the second proof. It is left as exercise at the end of the first chapter and it seems to use only elementary instruments. There are four steps in this proof, I need help to solve the following: Define  $$j:\mathbb{H}/SL_2(\mathbb{Z}) \longrightarrow \mathbb{C}$$ as the function that sends $\tau \in \mathbb{H}/SL_2(\mathbb{Z})$ in the $j$-invariant of the torus $\mathbb{C}/\Lambda_{\tau}$, where $\Lambda_{\tau}$ is the lattice $\mathbb{Z}+\tau\mathbb{Z} \subset \mathbb{C}$. Let $j_0 \in \mathbb{C}$, $H$ be a positive real number, $F_H \subset \mathbb{C}$ the set $\{z \in \mathbb{C} | -\frac{1}{2}<Re(z)<\frac{1}{2}, \, |z|>1, \, Im(z)< H\}$  and $\partial F_H$ its boundary with counterclockwise orientation. Suppose furthermore $j(\tau) \neq j_0$ on $\partial F_H$. Prove that $$\lim_{H \rightarrow +\infty}\frac{1}{2\pi i}\int_{\partial F_H} \frac{j'(\tau)}{j(\tau)-j_0}d\tau=1$$ The autor suggest to use the following property of the function $j$  $$j(\tau)=j(\tau+1)=j(-1/\tau)$$ and its series expansion to evaluate the integral, but I don't see how this can help me to evaluate the limit. Could someone help me? Any hints or references? I apologize if this question could be very simple for someone: I'm sure I'm missing something trivial!","In Silverman's Advanced Topics in the Arithmetic of Elliptic Curves there are two demonstrations of the Uniformization Theorem for the Elliptic Curves (It says that, given an Elliptic Curve $E$, there's a unique lattice such that $E$ is its associated Elliptic Curve). The first proof uses a lot of advanced topics in modular forms, but I'm interested in the second proof. It is left as exercise at the end of the first chapter and it seems to use only elementary instruments. There are four steps in this proof, I need help to solve the following: Define  $$j:\mathbb{H}/SL_2(\mathbb{Z}) \longrightarrow \mathbb{C}$$ as the function that sends $\tau \in \mathbb{H}/SL_2(\mathbb{Z})$ in the $j$-invariant of the torus $\mathbb{C}/\Lambda_{\tau}$, where $\Lambda_{\tau}$ is the lattice $\mathbb{Z}+\tau\mathbb{Z} \subset \mathbb{C}$. Let $j_0 \in \mathbb{C}$, $H$ be a positive real number, $F_H \subset \mathbb{C}$ the set $\{z \in \mathbb{C} | -\frac{1}{2}<Re(z)<\frac{1}{2}, \, |z|>1, \, Im(z)< H\}$  and $\partial F_H$ its boundary with counterclockwise orientation. Suppose furthermore $j(\tau) \neq j_0$ on $\partial F_H$. Prove that $$\lim_{H \rightarrow +\infty}\frac{1}{2\pi i}\int_{\partial F_H} \frac{j'(\tau)}{j(\tau)-j_0}d\tau=1$$ The autor suggest to use the following property of the function $j$  $$j(\tau)=j(\tau+1)=j(-1/\tau)$$ and its series expansion to evaluate the integral, but I don't see how this can help me to evaluate the limit. Could someone help me? Any hints or references? I apologize if this question could be very simple for someone: I'm sure I'm missing something trivial!",,"['complex-analysis', 'number-theory', 'algebraic-geometry', 'elliptic-curves', 'modular-forms']"
23,Proof for Complex Analysis Inequality,Proof for Complex Analysis Inequality,,"This is a homework assignment that will be graded; so I'm not specifically asking for an answer.  But I could use a hint, as it's been a few days and I'm still not sure if how I've proved it would really be sufficient. $$ |e^{z^2}| \le e^{|z|^2} $$ As far as my attempt goes, I simplified $ |e^{z^2}| $ to $ |e^{x^2-y^2}| $ which I then stated was less than or equal to $ e^{z^2} $ to get rid of the modulus. Not knowing what to do there, I decided to try to simplify the right term somehow.  All I managed was to square the z, but I couldn't think of a useful way to simplify it further. $ e^{|x^2-y^2+2ixy}| $ So I tried to prove that $ x^2-y^2 \le |x^2-y^2+2ixy| $, but I'm not sure if that would be considered proper.  After that, I figured I would show that, by definition, $|x^2-y^2+2ixy|$ would be $ x^2-y^2 \le ((x^2-y^2)^2+(2xy)^2)^{(1/2)} $.  Squaring both sides, it would end up as $ x^4 - 2x^2y^2 + y^2 \le x^4 + 2x^2y^2 + y^2 $, which would be always true, since x and y are real numbers and they're all being raised to even powers. I'm not sure if my method is flawed, but if it's wrong or I've made a mistake somewhere, I would appreciate if someone informed me.  Thank you!","This is a homework assignment that will be graded; so I'm not specifically asking for an answer.  But I could use a hint, as it's been a few days and I'm still not sure if how I've proved it would really be sufficient. $$ |e^{z^2}| \le e^{|z|^2} $$ As far as my attempt goes, I simplified $ |e^{z^2}| $ to $ |e^{x^2-y^2}| $ which I then stated was less than or equal to $ e^{z^2} $ to get rid of the modulus. Not knowing what to do there, I decided to try to simplify the right term somehow.  All I managed was to square the z, but I couldn't think of a useful way to simplify it further. $ e^{|x^2-y^2+2ixy}| $ So I tried to prove that $ x^2-y^2 \le |x^2-y^2+2ixy| $, but I'm not sure if that would be considered proper.  After that, I figured I would show that, by definition, $|x^2-y^2+2ixy|$ would be $ x^2-y^2 \le ((x^2-y^2)^2+(2xy)^2)^{(1/2)} $.  Squaring both sides, it would end up as $ x^4 - 2x^2y^2 + y^2 \le x^4 + 2x^2y^2 + y^2 $, which would be always true, since x and y are real numbers and they're all being raised to even powers. I'm not sure if my method is flawed, but if it's wrong or I've made a mistake somewhere, I would appreciate if someone informed me.  Thank you!",,['complex-analysis']
24,Do I correctly understand the constructions involved in definition of Cartier divisor?,Do I correctly understand the constructions involved in definition of Cartier divisor?,,"Let $(X,\mathcal O)$ be a ringed space, where $\mathcal O$ is a sheaf of unital commutative integrity domains. Let $\widetilde{\mathcal M}_U$ be the field of fractions of ring $\mathcal O_U$ for any open $U$ and $\widetilde{\mathcal M}$ be the presheaf given by $\widetilde M_U$ over an open $U$. Sheafification $\mathcal M$ of $\widetilde{\mathcal M}$ is called the sheaf of meromorphic functions on $X$. Its sections over an open $U$ will be denoted by $\mathcal M_U$. Then $\mathcal O_U$ is naturally included in $\mathcal M_U$. Now let $\mathcal O^\times$ and $\mathcal M^\times$ be the sheaves of multiplicative groups of invertible elements of $\mathcal O$ and $\mathcal M$. Again, $\mathcal O_U^\times \subset \mathcal M_U^\times$. We can consider the sheaf $\mathcal M^\times / \mathcal O^\times$. Its global sections are called Cartier divisors. If I'm not mistaken, any section of $\mathcal M$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \mid f_i, g_i \in \mathcal O_{U_i}$, $g_i \neq 0 \}$ and such that  $$   f_i|_{U_i \cap U_j} g_j|_{U_i \cap U_j} - g_i|_{U_i \cap U_j} f_j|_{U_i \cap U_j} = 0 $$  if $U_i \cap U_j \neq \varnothing$.Thus the inclusion $\mathcal O_U \to \mathcal M_U$ for any $f \in \mathcal O_U$ is given by the data of the single set $U_1 = U$ and of a single fraction with $f_1 = f$, $g_1 = 1_{\mathcal O_U}$. Then any section of $\mathcal M^\times / \mathcal O^\times$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \cdot \mathcal O_U^\times|_{U_i} \mid f_i, g_i \in \mathcal O_{U_i}$, $f_i, g_i \neq 0 \}$ each of which represents a set and such that  $$ f_i|_{U_i \cap U_j}/ g_i|_{U_i \cap U_j} \cdot \mathcal O^\times_U |_{U_i \cap U_j} = f_j|_{U_i \cap U_j} / g_j|_{U_i \cap U_j} \cdot O^\times_U |_{U_i \cap U_j} \tag{1} $$ if $U_i \cap U_j \neq \varnothing$. Are these considerations correct?","Let $(X,\mathcal O)$ be a ringed space, where $\mathcal O$ is a sheaf of unital commutative integrity domains. Let $\widetilde{\mathcal M}_U$ be the field of fractions of ring $\mathcal O_U$ for any open $U$ and $\widetilde{\mathcal M}$ be the presheaf given by $\widetilde M_U$ over an open $U$. Sheafification $\mathcal M$ of $\widetilde{\mathcal M}$ is called the sheaf of meromorphic functions on $X$. Its sections over an open $U$ will be denoted by $\mathcal M_U$. Then $\mathcal O_U$ is naturally included in $\mathcal M_U$. Now let $\mathcal O^\times$ and $\mathcal M^\times$ be the sheaves of multiplicative groups of invertible elements of $\mathcal O$ and $\mathcal M$. Again, $\mathcal O_U^\times \subset \mathcal M_U^\times$. We can consider the sheaf $\mathcal M^\times / \mathcal O^\times$. Its global sections are called Cartier divisors. If I'm not mistaken, any section of $\mathcal M$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \mid f_i, g_i \in \mathcal O_{U_i}$, $g_i \neq 0 \}$ and such that  $$   f_i|_{U_i \cap U_j} g_j|_{U_i \cap U_j} - g_i|_{U_i \cap U_j} f_j|_{U_i \cap U_j} = 0 $$  if $U_i \cap U_j \neq \varnothing$.Thus the inclusion $\mathcal O_U \to \mathcal M_U$ for any $f \in \mathcal O_U$ is given by the data of the single set $U_1 = U$ and of a single fraction with $f_1 = f$, $g_1 = 1_{\mathcal O_U}$. Then any section of $\mathcal M^\times / \mathcal O^\times$ over an open $U$ is given by an open cover $\{U_i\}$ of $U$ together with a family of elements $\{f_i / g_i \cdot \mathcal O_U^\times|_{U_i} \mid f_i, g_i \in \mathcal O_{U_i}$, $f_i, g_i \neq 0 \}$ each of which represents a set and such that  $$ f_i|_{U_i \cap U_j}/ g_i|_{U_i \cap U_j} \cdot \mathcal O^\times_U |_{U_i \cap U_j} = f_j|_{U_i \cap U_j} / g_j|_{U_i \cap U_j} \cdot O^\times_U |_{U_i \cap U_j} \tag{1} $$ if $U_i \cap U_j \neq \varnothing$. Are these considerations correct?",,"['complex-analysis', 'algebraic-geometry', 'sheaf-theory']"
25,Solve $\cos(z)=\frac{3}{4}+\frac{i}{4}$,Solve,\cos(z)=\frac{3}{4}+\frac{i}{4},"I tried solving this using the definition of $cos(z)=\frac{e^{iz}+e^{-iz}}{2}$ and equating it to $\frac{3}{4}+\frac{i}{4}$ and converting it to a complex quadratic equation through a substitution $t=e^{iz}$ and finding roots via the complex quadratic formula but it didn't seem to work. I would prefer solutions via elementary methods. Here is my attempt: By definition we have $\frac{e^{iz}+e^{-iz}}{2}=\frac{3}{4}+\frac{i}{4} \implies e^{iz}+e^{-iz}=\frac{3}{2}+\frac{i}{2}$. Let $t=e^{iz}$ so then we have $t+\frac{1}{t}=\frac{3}{2}+\frac{i}{2}$ and if we multiply both sides by $t$ we have $t^2+1=(\frac{3}{2}+\frac{i}{2})t$ and hence $t^2+(\frac{3}{2}+\frac{i}{2})t+1=0$ By the quadratic formula for complex numbers we have, $a=1, b=\frac{3}{2}+\frac{i}{2}, c=1 \implies z=\frac{-(\frac{3}{2}+\frac{i}{2}) \pm \sqrt{(\frac{3}{2}+\frac{i}{2})^2-4(1)(1)}}{2(1)}$. Simplyifing we have $z=\frac{-\frac{3}{2}-(\frac{1}{2})i \pm \sqrt{-2+(\frac{3}{2})i}}{2}$ We wish to express $-2+(\frac{3}{3})i$ in polar form so we have $|-2+(\frac{3}{2})i|=\frac{5}{2}$. Now equating the real and imaginary parts we have $\frac{5}{2}\cos(\theta)=-2 \implies \cos(\theta)=-\frac{4}{5}$ and $\frac{5}{2}\sin(\theta)=\frac{3}{2} \implies \sin(\theta)=\frac{3}{5}$. From this we have $\tan(\theta)=-\frac{3}{4} \implies \theta=\arctan(-\frac{3}{4}) \approx -.6435$ rad. So we have $w=-2+(\frac{3}{2})i=\frac{5}{4}(\cos(\theta)+i\sin(\theta))=\frac{5}{4}e^{i\theta}$. By Proposition 1.3.12 we have $\sqrt{w}=\sqrt{\frac{5}{4}}e^{\frac{i\theta}{2}}=\frac{\sqrt{5}}{2}e^{\frac{i\theta}{2}}$. Similarily for $-\frac{3}{2}-(\frac{1}{2})=\frac{\sqrt{10}}{2}e^{i\varphi}$ Where $\varphi=\arctan(\frac{1}{3})$.  So finally we have $z=\frac{-(\frac{3}{2}+\frac{i}{2}) \pm \sqrt{(\frac{3}{2}+\frac{i}{2})^2-4(1)(1)}}{2(1)}=\frac{\sqrt{10}e^{i\varphi} \pm \sqrt{5}e^{\frac{i\theta}{2}}}{4}$ as solutions to $\cos(z)=\frac{3}{4}+\frac{i}{4}$.","I tried solving this using the definition of $cos(z)=\frac{e^{iz}+e^{-iz}}{2}$ and equating it to $\frac{3}{4}+\frac{i}{4}$ and converting it to a complex quadratic equation through a substitution $t=e^{iz}$ and finding roots via the complex quadratic formula but it didn't seem to work. I would prefer solutions via elementary methods. Here is my attempt: By definition we have $\frac{e^{iz}+e^{-iz}}{2}=\frac{3}{4}+\frac{i}{4} \implies e^{iz}+e^{-iz}=\frac{3}{2}+\frac{i}{2}$. Let $t=e^{iz}$ so then we have $t+\frac{1}{t}=\frac{3}{2}+\frac{i}{2}$ and if we multiply both sides by $t$ we have $t^2+1=(\frac{3}{2}+\frac{i}{2})t$ and hence $t^2+(\frac{3}{2}+\frac{i}{2})t+1=0$ By the quadratic formula for complex numbers we have, $a=1, b=\frac{3}{2}+\frac{i}{2}, c=1 \implies z=\frac{-(\frac{3}{2}+\frac{i}{2}) \pm \sqrt{(\frac{3}{2}+\frac{i}{2})^2-4(1)(1)}}{2(1)}$. Simplyifing we have $z=\frac{-\frac{3}{2}-(\frac{1}{2})i \pm \sqrt{-2+(\frac{3}{2})i}}{2}$ We wish to express $-2+(\frac{3}{3})i$ in polar form so we have $|-2+(\frac{3}{2})i|=\frac{5}{2}$. Now equating the real and imaginary parts we have $\frac{5}{2}\cos(\theta)=-2 \implies \cos(\theta)=-\frac{4}{5}$ and $\frac{5}{2}\sin(\theta)=\frac{3}{2} \implies \sin(\theta)=\frac{3}{5}$. From this we have $\tan(\theta)=-\frac{3}{4} \implies \theta=\arctan(-\frac{3}{4}) \approx -.6435$ rad. So we have $w=-2+(\frac{3}{2})i=\frac{5}{4}(\cos(\theta)+i\sin(\theta))=\frac{5}{4}e^{i\theta}$. By Proposition 1.3.12 we have $\sqrt{w}=\sqrt{\frac{5}{4}}e^{\frac{i\theta}{2}}=\frac{\sqrt{5}}{2}e^{\frac{i\theta}{2}}$. Similarily for $-\frac{3}{2}-(\frac{1}{2})=\frac{\sqrt{10}}{2}e^{i\varphi}$ Where $\varphi=\arctan(\frac{1}{3})$.  So finally we have $z=\frac{-(\frac{3}{2}+\frac{i}{2}) \pm \sqrt{(\frac{3}{2}+\frac{i}{2})^2-4(1)(1)}}{2(1)}=\frac{\sqrt{10}e^{i\varphi} \pm \sqrt{5}e^{\frac{i\theta}{2}}}{4}$ as solutions to $\cos(z)=\frac{3}{4}+\frac{i}{4}$.",,"['complex-analysis', 'complex-numbers']"
26,Adjoint of multiplication by $z$ in a Hilbert Space (Bergman space),Adjoint of multiplication by  in a Hilbert Space (Bergman space),z,"I am learning Hilbert space theory from Halmos' ""Introduction to Hilbert space and the theory of spectral multiplicity"". While talking about understanding adjoints (p. 39), he calls special attention to this example, remarking that ""its adjoint is not what at first it might appear to be"": Let $\mathfrak H$ be the set of analytic functions defined in the interior of the unit disk ($D$), square integrable with respect to planar Lebesgue measure. Then $\mathfrak H$ called a Bergman space  is a Hilbert space with the inner product $$\langle f,g \rangle= \int_D f\bar g d\lambda = \int_D f(x+iy)\bar g (x+iy) dxdy .$$ In $\mathfrak H$, consider the multiplication by $z$ opertator $A$, i.e. $(Af)(z)=zf(z).$ In the typical $L^2$ I think $A^*$ would simply be multiplication by $\bar z$, but that ruins the differentiability of $f$, so in this case it must be some other thing. I have thought that this multiplication operator works like the shift operator in sequence spaces if one identifies the function $f$ with its power series terms $(a_0, a_1, ..)$, mapping this sequence to $(0, a_0, a_1,..)$. I know that the usual right shift defined in $l^2$ has as adjoint the left shift when one considers the inner product $\langle \{a_n\},\{b_n\}\rangle = \sum a_n\bar b_n$, but I don't know how the inner product of $\mathfrak H$ would look like translated to the language of its corresponding sequence space, so this approach hasn't helped me much either. How can I construct this adjoint operator?","I am learning Hilbert space theory from Halmos' ""Introduction to Hilbert space and the theory of spectral multiplicity"". While talking about understanding adjoints (p. 39), he calls special attention to this example, remarking that ""its adjoint is not what at first it might appear to be"": Let $\mathfrak H$ be the set of analytic functions defined in the interior of the unit disk ($D$), square integrable with respect to planar Lebesgue measure. Then $\mathfrak H$ called a Bergman space  is a Hilbert space with the inner product $$\langle f,g \rangle= \int_D f\bar g d\lambda = \int_D f(x+iy)\bar g (x+iy) dxdy .$$ In $\mathfrak H$, consider the multiplication by $z$ opertator $A$, i.e. $(Af)(z)=zf(z).$ In the typical $L^2$ I think $A^*$ would simply be multiplication by $\bar z$, but that ruins the differentiability of $f$, so in this case it must be some other thing. I have thought that this multiplication operator works like the shift operator in sequence spaces if one identifies the function $f$ with its power series terms $(a_0, a_1, ..)$, mapping this sequence to $(0, a_0, a_1,..)$. I know that the usual right shift defined in $l^2$ has as adjoint the left shift when one considers the inner product $\langle \{a_n\},\{b_n\}\rangle = \sum a_n\bar b_n$, but I don't know how the inner product of $\mathfrak H$ would look like translated to the language of its corresponding sequence space, so this approach hasn't helped me much either. How can I construct this adjoint operator?",,"['complex-analysis', 'operator-theory', 'hilbert-spaces', 'examples-counterexamples', 'adjoint-operators']"
27,"Conformal mapping of disk, surjective, not injective","Conformal mapping of disk, surjective, not injective",,"Is there an example of a conformal mapping of the disk onto itself which is not injective? If not, how may we prove there does not exist such a map? This came up in the answer to this question.","Is there an example of a conformal mapping of the disk onto itself which is not injective? If not, how may we prove there does not exist such a map? This came up in the answer to this question.",,"['complex-analysis', 'conformal-geometry']"
28,A problem related to Rouche's Theorem.,A problem related to Rouche's Theorem.,,"In Rouche's theorem, If we replace analytic property of functions $f(z)$ and $h(z)$ with meromorphic then this theorem will not be valid anymore. I want to illustrate this fact by producing some $f(z)$ and $h(z)$ which are meromorphic on some bounded domain D (where D have piecewise smooth boundary $\partial D$). Such that $f(z)$ and $h(z)$ have no poles on $\partial D$ and $|h(z)|<|f(z)|$, $\forall z\in\partial D$ but $f+h$ and $h$ have different number of zeros in D.","In Rouche's theorem, If we replace analytic property of functions $f(z)$ and $h(z)$ with meromorphic then this theorem will not be valid anymore. I want to illustrate this fact by producing some $f(z)$ and $h(z)$ which are meromorphic on some bounded domain D (where D have piecewise smooth boundary $\partial D$). Such that $f(z)$ and $h(z)$ have no poles on $\partial D$ and $|h(z)|<|f(z)|$, $\forall z\in\partial D$ but $f+h$ and $h$ have different number of zeros in D.",,['complex-analysis']
29,"Where is $\sqrt{e^z+1}$, $z \in \mathbb{C}$, analytic?","Where is , , analytic?",\sqrt{e^z+1} z \in \mathbb{C},"I'm considering the following question: Where is $f(z)=\sqrt{e^z+1}$, $z \in \mathbb{C}$, analytic? Find $f'(z)$ where it is analytic. My approach has been to simply differentiate $f(z)$ to get $$f'(z)=\frac{\mathrm{e}^z}{2\sqrt{\mathrm{e}^{z}+1}}$$ and note that then $\mathrm{e}^z \neq -1$, giving $z \neq i(2k+1)\pi$, $k \in \mathbb{Z}$. But I realize that the square root isn't continuous on all of $\mathbb{C}$, so are there any intricacies that I should be paying attention to? Looking forward to your replies!","I'm considering the following question: Where is $f(z)=\sqrt{e^z+1}$, $z \in \mathbb{C}$, analytic? Find $f'(z)$ where it is analytic. My approach has been to simply differentiate $f(z)$ to get $$f'(z)=\frac{\mathrm{e}^z}{2\sqrt{\mathrm{e}^{z}+1}}$$ and note that then $\mathrm{e}^z \neq -1$, giving $z \neq i(2k+1)\pi$, $k \in \mathbb{Z}$. But I realize that the square root isn't continuous on all of $\mathbb{C}$, so are there any intricacies that I should be paying attention to? Looking forward to your replies!",,['complex-analysis']
30,Questions regarding the Riemann-Siegel $\theta$ Function,Questions regarding the Riemann-Siegel  Function,\theta,"My questions are a request, please, for help in understanding some comments in the wikipedia article discussing the Riemann-Siegel $\theta$ function http://en.wikipedia.org/wiki/Riemann%E2%80%93Siegel_theta_function : The series for $\theta (t)$: $$\theta(t) = -\frac{\gamma + \log \pi}t - \arctan 2t + \sum_{n = 1}^\infty (\frac{t}{2n} - \arctan (\frac{2t}{4n + 1}))$$ ""For values with imaginary part between -1 and 1, the arctangent function is holomorphic, and it is easily seen that the series converges uniformly on compact sets in the region with imaginary part between -1/2 and 1/2, leading to a holomorphic function on this domain. It follows that the Z function is also holomorphic in this region, which is the critical strip."" -- First, is it correct that the principal branch of the $\arctan$ function is for values of t, Im $s$, imaginary part between $- 1$ and $1$? -- Then, in consideration of the second term on the RHS, $t$ is thus constrained to be between $- 1/2$ and $1/2$? -- a) Lastly, I am confused as to why the domain $- 1/2 < t < 1/2$ is referred to as ""the critical strip."" Especially since ""t"" is in the imaginary direction. Then, b) presumably, it is assumed that $Re (s) = 1/2$, so in an open disk centered at that point with a radius $< 1/2$, $\arctan 2t$ would be holomorphic  - is this thinking correct? c) And further, how is this region then the critical strip. I might guess by analytic continuation. If this is correct, I would also appreciate help as to how that is actually done. Thanks very much.","My questions are a request, please, for help in understanding some comments in the wikipedia article discussing the Riemann-Siegel $\theta$ function http://en.wikipedia.org/wiki/Riemann%E2%80%93Siegel_theta_function : The series for $\theta (t)$: $$\theta(t) = -\frac{\gamma + \log \pi}t - \arctan 2t + \sum_{n = 1}^\infty (\frac{t}{2n} - \arctan (\frac{2t}{4n + 1}))$$ ""For values with imaginary part between -1 and 1, the arctangent function is holomorphic, and it is easily seen that the series converges uniformly on compact sets in the region with imaginary part between -1/2 and 1/2, leading to a holomorphic function on this domain. It follows that the Z function is also holomorphic in this region, which is the critical strip."" -- First, is it correct that the principal branch of the $\arctan$ function is for values of t, Im $s$, imaginary part between $- 1$ and $1$? -- Then, in consideration of the second term on the RHS, $t$ is thus constrained to be between $- 1/2$ and $1/2$? -- a) Lastly, I am confused as to why the domain $- 1/2 < t < 1/2$ is referred to as ""the critical strip."" Especially since ""t"" is in the imaginary direction. Then, b) presumably, it is assumed that $Re (s) = 1/2$, so in an open disk centered at that point with a radius $< 1/2$, $\arctan 2t$ would be holomorphic  - is this thinking correct? c) And further, how is this region then the critical strip. I might guess by analytic continuation. If this is correct, I would also appreciate help as to how that is actually done. Thanks very much.",,['complex-analysis']
31,Multiple-valued analytic functions,Multiple-valued analytic functions,,"Although our definition requires all analytic functions to be single-valued, it is possible to consider such multiple-valued functions as $\sqrt{z}$ , $\log z$ , or $\arccos z$ , provided that they are restricted to a definite region in which it is possible to select a single-valued and analytic branch of the function. For instance, we may choose for $\Omega$ the complement of the negative real axis $z\le 0$ ; this set is indeed open and connected. In $\Omega$ one and only one of the values of $\sqrt{z}$ has a positive real part. With this choice $w=\sqrt{z}$ becomes a single-valued function in $\Omega$ ; let us prove that it is continuous. (The set $\Omega$ is the open set on which $f$ is defined.) I don't really understand what all this means. Why is the negative real axis described by $z\le 0$ (shouldn't it be $x\le 0$ ?) Isn't it always the case that one value of $\sqrt{z}$ has a positive real part, since the two values are negative of each other? And why does $w=\sqrt{z}$ become a single-valued function, when we restrict the domain but not the range?","Although our definition requires all analytic functions to be single-valued, it is possible to consider such multiple-valued functions as , , or , provided that they are restricted to a definite region in which it is possible to select a single-valued and analytic branch of the function. For instance, we may choose for the complement of the negative real axis ; this set is indeed open and connected. In one and only one of the values of has a positive real part. With this choice becomes a single-valued function in ; let us prove that it is continuous. (The set is the open set on which is defined.) I don't really understand what all this means. Why is the negative real axis described by (shouldn't it be ?) Isn't it always the case that one value of has a positive real part, since the two values are negative of each other? And why does become a single-valued function, when we restrict the domain but not the range?",\sqrt{z} \log z \arccos z \Omega z\le 0 \Omega \sqrt{z} w=\sqrt{z} \Omega \Omega f z\le 0 x\le 0 \sqrt{z} w=\sqrt{z},"['complex-analysis', 'definition']"
32,A complex structure on the tangent space,A complex structure on the tangent space,,"I am reading the book Riemann surface by Donaldson. I want to understand the following Lemma (p.74). Lemma. Let $X$ be a Riemann surface. There is a unique way to define a complex structure on $TX_p$ such that the derivative of any holomorphic function, defined on a neighborhood of $p$ in $X$, is complex linear. By definition, a complex structure is an $\mathbb{R}$-linear map $J: TX_p \to TX_p$ such taht $J^2=-1$. First, I don't understand how the derivative of a holomorphic function is related to $TX_p$. Second, it is written that the proof follows from the definition of a holomorphic function but I don't see it. Could you explain these for me?","I am reading the book Riemann surface by Donaldson. I want to understand the following Lemma (p.74). Lemma. Let $X$ be a Riemann surface. There is a unique way to define a complex structure on $TX_p$ such that the derivative of any holomorphic function, defined on a neighborhood of $p$ in $X$, is complex linear. By definition, a complex structure is an $\mathbb{R}$-linear map $J: TX_p \to TX_p$ such taht $J^2=-1$. First, I don't understand how the derivative of a holomorphic function is related to $TX_p$. Second, it is written that the proof follows from the definition of a holomorphic function but I don't see it. Could you explain these for me?",,['complex-analysis']
33,"Arguing that $\lim_{r \to 0}\int_{C_{r}}f(z) \, dz = i \pi \operatorname{Res}[f(z), z_{0}]$, where $C_{r}$ is a semicircle of radius $r$","Arguing that , where  is a semicircle of radius","\lim_{r \to 0}\int_{C_{r}}f(z) \, dz = i \pi \operatorname{Res}[f(z), z_{0}] C_{r} r","I recently made the following observation: Assume that the function $f(z)$ can be expressed near $z=z_{0}$ in the form $$ \sum_{k=-n}^{0} a_{2k-1} (z-z_{0})^{2k-1} + g(z) \, ,$$ where the function $g(z)$ is analytic at $z_{0}$. If $C_{r}$ is a counterclockwise-oriented semicircle of radius $r$ centered at $z_{0}$, then $$\lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi  \, \text{Res}[f(z),z_{0}].$$ Is my observation correct? Attempt at a proof : $$ \begin{align} \int_{C_{r}} f(z) \, dz &= \int_{\alpha}^{\alpha + \pi}f(z_{0}+re^{it}) \ i r e^{it} \, dt \\ &= \int_{\alpha}^{\alpha + \pi} \left(\sum_{k=-n}^{0} a_{2k-1} (re^{it})^{2k-1} + g(z_{0}+re^{it}) \right) i r e^{it} \, dt \\ &= i \sum_{k=-n}^{-1}a_{2k-1} r^{2k} \underbrace{\int_{\alpha}^{\alpha + \pi} e^{2ikt} \, dt}_{0} + i a_{-1} \int_{\alpha}^{\alpha + \pi} \, dt + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \\  &= i \pi a_{-1} + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \end{align}$$ And since $|g(z)|$ is bounded near $z_{0}$, $$ \lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi a_{-1} + 0 = i \pi \, \text{Res}[f(z),z_{0}]$$","I recently made the following observation: Assume that the function $f(z)$ can be expressed near $z=z_{0}$ in the form $$ \sum_{k=-n}^{0} a_{2k-1} (z-z_{0})^{2k-1} + g(z) \, ,$$ where the function $g(z)$ is analytic at $z_{0}$. If $C_{r}$ is a counterclockwise-oriented semicircle of radius $r$ centered at $z_{0}$, then $$\lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi  \, \text{Res}[f(z),z_{0}].$$ Is my observation correct? Attempt at a proof : $$ \begin{align} \int_{C_{r}} f(z) \, dz &= \int_{\alpha}^{\alpha + \pi}f(z_{0}+re^{it}) \ i r e^{it} \, dt \\ &= \int_{\alpha}^{\alpha + \pi} \left(\sum_{k=-n}^{0} a_{2k-1} (re^{it})^{2k-1} + g(z_{0}+re^{it}) \right) i r e^{it} \, dt \\ &= i \sum_{k=-n}^{-1}a_{2k-1} r^{2k} \underbrace{\int_{\alpha}^{\alpha + \pi} e^{2ikt} \, dt}_{0} + i a_{-1} \int_{\alpha}^{\alpha + \pi} \, dt + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \\  &= i \pi a_{-1} + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \end{align}$$ And since $|g(z)|$ is bounded near $z_{0}$, $$ \lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi a_{-1} + 0 = i \pi \, \text{Res}[f(z),z_{0}]$$",,"['complex-analysis', 'contour-integration']"
34,$\sum_{n=1}^{\infty}f(z^n)$ converges uniformly with $f$ holomorphic,converges uniformly with  holomorphic,\sum_{n=1}^{\infty}f(z^n) f,"Let $f$ be an holomorphic function on the unit ball with $f(0)=0$.   Prove that $\sum_{n=1}^{\infty}f(z^n)$ is uniformly locally   convergent in the unit ball. My attemp: It is suffice to prove that $\sum_{n=1}^{\infty}f(z^n)$ converges uniformly  in any $\overline{B_0(r)}$ with $r<1$. $f'$ is also an holomorphic function, defined on a compact set and therfore bounded. Let's say $|f'|\leq M$. Then, for every $z\in \overline{B_0(r)}$, $|f(z^n)-f(0)|\leq M|z^n-0|$, $|f(z^n)|\leq M|z^n| = M|z|^n \leq Mr^n$. The series $\sum_{n=1}^{\infty}r^n$ converges and therefore by the M test our series converges uniformly. Is it correct? Thanks.","Let $f$ be an holomorphic function on the unit ball with $f(0)=0$.   Prove that $\sum_{n=1}^{\infty}f(z^n)$ is uniformly locally   convergent in the unit ball. My attemp: It is suffice to prove that $\sum_{n=1}^{\infty}f(z^n)$ converges uniformly  in any $\overline{B_0(r)}$ with $r<1$. $f'$ is also an holomorphic function, defined on a compact set and therfore bounded. Let's say $|f'|\leq M$. Then, for every $z\in \overline{B_0(r)}$, $|f(z^n)-f(0)|\leq M|z^n-0|$, $|f(z^n)|\leq M|z^n| = M|z|^n \leq Mr^n$. The series $\sum_{n=1}^{\infty}r^n$ converges and therefore by the M test our series converges uniformly. Is it correct? Thanks.",,['complex-analysis']
35,Dirac Orthonormality Proof - Can't Make Sense of Complex Integral,Dirac Orthonormality Proof - Can't Make Sense of Complex Integral,,"I'm having trouble rationalizing  a particular statement that is, surely, present in many quantum mechanics textbooks. The following statement comes from the orthnormalization condition for eigenfunctions of the wavefunction,  $\Psi (x, t) $, subject to the momentum operator, $\hbar/i (d/dx)$, with REAL eigenvalues, $\lambda \in R$. The eigenfunctions are of the form: $\psi_\lambda = e^{i \lambda x / \hbar} $ and then, taking their inner product $ < \psi_\lambda' | \psi_\lambda >  =  |A|^2 \int_{-\infty}^{\infty} e^{i (\lambda - \lambda')x/\hbar} dx = |A|^2 2 \pi \hbar \ \delta(\lambda - \lambda')  $ So I'm quite unclear about that last part. Of course, if $\lambda' \neq \lambda$ , you are integrating a sinusoid, and the answer is zero, however, isn't: $ \left. \int_{-\infty}^{\infty} e^{i (\lambda - \lambda')x/\hbar} dx \right|_{\lambda = \lambda'}  = \int_{-\infty}^{\infty} 1 dx  = \infty $ I mean, $ e^{i (\lambda - \lambda')z/\hbar}$ is analytic everywhere, so you could just complex integrate, treating i as a constant and take limits, (same answer, no?). I also thought about Cauchy's Integral Theorem, and doing a contour integral, and using the maximum modulus principle: $ \lim_{p \rightarrow \infty} \left. \int_{-p}^{p} e^{i (\lambda - \lambda')x/\hbar} dx \right|_{\lambda = \lambda'}  = 2 \pi \sum_i f(z_i) - lim_{p \rightarrow \infty} p \left| e^{i(\lambda - \lambda') p / \hbar} \right| $ where $z_i$ is the location of singularity i. However, as far as I can tell...there are no singularities, and the term on the right is unbounded, ( $\rightarrow \infty$). So why does that evaluate to the delta function? Thanks","I'm having trouble rationalizing  a particular statement that is, surely, present in many quantum mechanics textbooks. The following statement comes from the orthnormalization condition for eigenfunctions of the wavefunction,  $\Psi (x, t) $, subject to the momentum operator, $\hbar/i (d/dx)$, with REAL eigenvalues, $\lambda \in R$. The eigenfunctions are of the form: $\psi_\lambda = e^{i \lambda x / \hbar} $ and then, taking their inner product $ < \psi_\lambda' | \psi_\lambda >  =  |A|^2 \int_{-\infty}^{\infty} e^{i (\lambda - \lambda')x/\hbar} dx = |A|^2 2 \pi \hbar \ \delta(\lambda - \lambda')  $ So I'm quite unclear about that last part. Of course, if $\lambda' \neq \lambda$ , you are integrating a sinusoid, and the answer is zero, however, isn't: $ \left. \int_{-\infty}^{\infty} e^{i (\lambda - \lambda')x/\hbar} dx \right|_{\lambda = \lambda'}  = \int_{-\infty}^{\infty} 1 dx  = \infty $ I mean, $ e^{i (\lambda - \lambda')z/\hbar}$ is analytic everywhere, so you could just complex integrate, treating i as a constant and take limits, (same answer, no?). I also thought about Cauchy's Integral Theorem, and doing a contour integral, and using the maximum modulus principle: $ \lim_{p \rightarrow \infty} \left. \int_{-p}^{p} e^{i (\lambda - \lambda')x/\hbar} dx \right|_{\lambda = \lambda'}  = 2 \pi \sum_i f(z_i) - lim_{p \rightarrow \infty} p \left| e^{i(\lambda - \lambda') p / \hbar} \right| $ where $z_i$ is the location of singularity i. However, as far as I can tell...there are no singularities, and the term on the right is unbounded, ( $\rightarrow \infty$). So why does that evaluate to the delta function? Thanks",,"['complex-analysis', 'quantum-mechanics', 'orthonormal']"
36,"$w_1,w_2$ are distinct complex numbers such that $|w_1|=|w_2|=1$ and $w_1+w_2=1$",are distinct complex numbers such that  and,"w_1,w_2 |w_1|=|w_2|=1 w_1+w_2=1","I am stuck on the following problem: Let $w_1,w_2$ are distinct complex numbers such that $|w_1|=|w_2|=1$ and $w_1+w_2=1$ .Then the triangle in the complex plane with $w_1,w_2,-1$ as vertices must be isosceles ,but not necessarily equilateral must be equilateral I have to decide which of the aforementioned options is correct. I tried with $\,\,w_1=e^{i\theta},w_2=e^{i \phi},w_3=e^{i \pi}$ but messed  it up . Can someone explain how to tackle it?","I am stuck on the following problem: Let are distinct complex numbers such that and .Then the triangle in the complex plane with as vertices must be isosceles ,but not necessarily equilateral must be equilateral I have to decide which of the aforementioned options is correct. I tried with but messed  it up . Can someone explain how to tackle it?","w_1,w_2 |w_1|=|w_2|=1 w_1+w_2=1 w_1,w_2,-1 \,\,w_1=e^{i\theta},w_2=e^{i \phi},w_3=e^{i \pi}","['complex-analysis', 'geometry', 'complex-numbers', 'triangles', 'plane-geometry']"
37,Using calculus of residues to evaluate a trig integral,Using calculus of residues to evaluate a trig integral,,This is my partial attempt at the solution. I am unsure how to proceed further.,This is my partial attempt at the solution. I am unsure how to proceed further.,,['complex-analysis']
38,"$f,g$ are continuous on closed unit disk but analytic on open unit disk and $f(z)=g(z)$",are continuous on closed unit disk but analytic on open unit disk and,"f,g f(z)=g(z)","$f,g$ are continuous on closed unit disk but analytic on open unit disk and $f(z)=g(z)$ on $|z|=1$, we need to show $f\equiv g$ so $h(z)=f(z)-g(z)$ has zero set $S^1$ which is analytic on open unit disk  $D$ and continous on compact unit disk so  has maximum attained at boundary which is $0$ so $\max|h(z)|=0$ so $h(z)\equiv 0\Rightarrow f(z)\equiv g(z)$ on compact unit disk. am I right?","$f,g$ are continuous on closed unit disk but analytic on open unit disk and $f(z)=g(z)$ on $|z|=1$, we need to show $f\equiv g$ so $h(z)=f(z)-g(z)$ has zero set $S^1$ which is analytic on open unit disk  $D$ and continous on compact unit disk so  has maximum attained at boundary which is $0$ so $\max|h(z)|=0$ so $h(z)\equiv 0\Rightarrow f(z)\equiv g(z)$ on compact unit disk. am I right?",,['complex-analysis']
39,"Say $f$ is entire, $|f'(z)|\le e^{|z|}$, and $f$ vanishes on the set $\{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\}$. Why must $f$ be constantly zero?","Say  is entire, , and  vanishes on the set . Why must  be constantly zero?",f |f'(z)|\le e^{|z|} f \{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\} f,"Say $f$ is entire, $|f'(z)|\le e^{|z|}$, and $f$ vanishes on the set $\{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\}$. Why must $f$ be constantly zero?","Say $f$ is entire, $|f'(z)|\le e^{|z|}$, and $f$ vanishes on the set $\{\frac{n}{\sqrt{1+|n|}}: n\in \mathbb{Z}\}$. Why must $f$ be constantly zero?",,['complex-analysis']
40,Finding a trigonometric polynomial,Finding a trigonometric polynomial,,"I'm trying to solve exercise 5 in chapter 14 of Rudin's Real & Complex Analysis: Suppose $f$ is a trigonometric polynomial,   $$f(\theta) = \sum_{k=-n}^n a_k e^{ik\theta}$$   and $f(\theta) > 0$ for all real $\theta$. Prove that there is a polynomial $P(z) = c_0 + c_1z + ... + c_nz^n$ such that $f(\theta)= |P(e^{i\theta})|^2$ ($\theta$ real). I've made good progress but I can not finish it. My thoughts: Define $F(z) = \sum_{k=-n}^n a_k z^k$. This is a rational function that is positive on the unit circle so it must be of the form: $$F(z) = c \prod_{j=1}^n\frac{(z-\beta_j)(1-\overline\beta_j z)}{(z-\gamma_j)(1-\overline\gamma_j z)}$$ where $c > 0$. $\beta_j$ are zeros of $F$. $\gamma_j$ are poles. On the unit circle $$f(\theta) = F(e^{i\theta}) = c \prod_{j=1}^n\frac{(e^{i\theta}-\beta_j)(1-\overline\beta_j e^{i\theta})}{(e^{i\theta}-\gamma_j)(1-\overline\gamma_j e^{i\theta})}$$ The terms in the product simplify to $$\left| \frac{e^{i\theta} - \beta_j}{e^{i\theta} - \gamma_j} \right|^2$$ If I can show that this is a polynomial, I'll solve the exercise, but it doesn't look like a polynomial to me. Is there a better way?","I'm trying to solve exercise 5 in chapter 14 of Rudin's Real & Complex Analysis: Suppose $f$ is a trigonometric polynomial,   $$f(\theta) = \sum_{k=-n}^n a_k e^{ik\theta}$$   and $f(\theta) > 0$ for all real $\theta$. Prove that there is a polynomial $P(z) = c_0 + c_1z + ... + c_nz^n$ such that $f(\theta)= |P(e^{i\theta})|^2$ ($\theta$ real). I've made good progress but I can not finish it. My thoughts: Define $F(z) = \sum_{k=-n}^n a_k z^k$. This is a rational function that is positive on the unit circle so it must be of the form: $$F(z) = c \prod_{j=1}^n\frac{(z-\beta_j)(1-\overline\beta_j z)}{(z-\gamma_j)(1-\overline\gamma_j z)}$$ where $c > 0$. $\beta_j$ are zeros of $F$. $\gamma_j$ are poles. On the unit circle $$f(\theta) = F(e^{i\theta}) = c \prod_{j=1}^n\frac{(e^{i\theta}-\beta_j)(1-\overline\beta_j e^{i\theta})}{(e^{i\theta}-\gamma_j)(1-\overline\gamma_j e^{i\theta})}$$ The terms in the product simplify to $$\left| \frac{e^{i\theta} - \beta_j}{e^{i\theta} - \gamma_j} \right|^2$$ If I can show that this is a polynomial, I'll solve the exercise, but it doesn't look like a polynomial to me. Is there a better way?",,['complex-analysis']
41,Complex Analytic Proof of the Gaussian Integral $\int_{-\infty}^{\infty}e^{-z^2}dz=\sqrt{\pi}$,Complex Analytic Proof of the Gaussian Integral,\int_{-\infty}^{\infty}e^{-z^2}dz=\sqrt{\pi},"Prove that $\int_{-\infty}^{\infty}e^{-z^2}dz=\sqrt{\pi}$. Here is my attempted solution: Define $a:=\sqrt{\pi}e^{\frac{\pi i}{4}}$ and let $f(z) = \frac{e^{-z^2}}{1+e^{-2az}}$. Note that $a^2=\pi i$. Now $f(z)$ has poles of order 1 at $(k+\frac{1}{2})a$ for all $k\in\mathbb{Z}$.  Thus using the Residue Theorem and l'Hpital's Rule: $$\lim_{z\rightarrow (k+\frac{1}{2})a}\frac{(z-(k+\frac{1}{2})a)e^{-z^2}}{1+e^{-2az}}=\lim_{z\rightarrow (k+\frac{1}{2})a}\frac{\frac{d}{dz}(z-(k+\frac{1}{2})a)e^{-z^2}}{\frac{d}{dz}1+e^{-2az}}=\frac{e^{-(k+\frac{1}{2})^2a^2}}{-2ae^{-2(k+\frac{1}{2})a^2}}=\frac{e^{-k^2a^2-ka^2-\frac{a^2}{4}}}{-2ae^{-2ka^2-a^2}}=\frac{e^{-\pi ik^2-\pi ik-\frac{\pi i}{4}}}{-2ae^{-2\pi ik-\pi i}}=\frac{e^{\frac{-\pi i}{4}}}{2\sqrt{\pi}e^{\frac{\pi i}{4}}}=\frac{1}{2\sqrt{\pi}i}$$ It can be shown that $f(z)-f(z+a)=e^{-z^2}$ (I wont prove this but it's most definitely true).  I'm going to integrate this function around the contour which is a rhombus slanting to the right whose bottom two corners lie at $-R$ and $R$.  Thus we have: $$\lim_{R\rightarrow\infty}\bigg[\int_{-R}^{R}f+\int_{R+at}f+\int_{R+a}^{-R+a}f+\int_{R+a(1-t)}f\bigg]=\sum_{k\geq 0}\sqrt{\pi}$$ for $0\leq t\leq 1$. Making the substitutions $u=z-a$ for the third integral and then $v=1-t$ for the fourth, and then taking $R\rightarrow\infty$, we obtain: $$\int_{-\infty}^{\infty}e^{-z^2}dz=\sum_{k\geq 0}\sqrt{\pi}$$ Whew! Ok so clearly all I really want is just one $\sqrt{\pi}$, not an infinite number of them.  But when I take $R\rightarrow\infty$ my rhombus contains all the poles in the upper-half plane.  Can anyone tell where I went wrong?","Prove that $\int_{-\infty}^{\infty}e^{-z^2}dz=\sqrt{\pi}$. Here is my attempted solution: Define $a:=\sqrt{\pi}e^{\frac{\pi i}{4}}$ and let $f(z) = \frac{e^{-z^2}}{1+e^{-2az}}$. Note that $a^2=\pi i$. Now $f(z)$ has poles of order 1 at $(k+\frac{1}{2})a$ for all $k\in\mathbb{Z}$.  Thus using the Residue Theorem and l'Hpital's Rule: $$\lim_{z\rightarrow (k+\frac{1}{2})a}\frac{(z-(k+\frac{1}{2})a)e^{-z^2}}{1+e^{-2az}}=\lim_{z\rightarrow (k+\frac{1}{2})a}\frac{\frac{d}{dz}(z-(k+\frac{1}{2})a)e^{-z^2}}{\frac{d}{dz}1+e^{-2az}}=\frac{e^{-(k+\frac{1}{2})^2a^2}}{-2ae^{-2(k+\frac{1}{2})a^2}}=\frac{e^{-k^2a^2-ka^2-\frac{a^2}{4}}}{-2ae^{-2ka^2-a^2}}=\frac{e^{-\pi ik^2-\pi ik-\frac{\pi i}{4}}}{-2ae^{-2\pi ik-\pi i}}=\frac{e^{\frac{-\pi i}{4}}}{2\sqrt{\pi}e^{\frac{\pi i}{4}}}=\frac{1}{2\sqrt{\pi}i}$$ It can be shown that $f(z)-f(z+a)=e^{-z^2}$ (I wont prove this but it's most definitely true).  I'm going to integrate this function around the contour which is a rhombus slanting to the right whose bottom two corners lie at $-R$ and $R$.  Thus we have: $$\lim_{R\rightarrow\infty}\bigg[\int_{-R}^{R}f+\int_{R+at}f+\int_{R+a}^{-R+a}f+\int_{R+a(1-t)}f\bigg]=\sum_{k\geq 0}\sqrt{\pi}$$ for $0\leq t\leq 1$. Making the substitutions $u=z-a$ for the third integral and then $v=1-t$ for the fourth, and then taking $R\rightarrow\infty$, we obtain: $$\int_{-\infty}^{\infty}e^{-z^2}dz=\sum_{k\geq 0}\sqrt{\pi}$$ Whew! Ok so clearly all I really want is just one $\sqrt{\pi}$, not an infinite number of them.  But when I take $R\rightarrow\infty$ my rhombus contains all the poles in the upper-half plane.  Can anyone tell where I went wrong?",,"['complex-analysis', 'residue-calculus']"
42,How to find the Casorati-Weierstrass' Theorem ? Can we find the phenomenon from a classical function: $\exp\left(\frac{1}{z}\right)$?,How to find the Casorati-Weierstrass' Theorem ? Can we find the phenomenon from a classical function: ?,\exp\left(\frac{1}{z}\right),"The first time when I see Casorati-Weierstrass' Theorem in Complex Analysis,I was shocked: Casorati-Weierstrass' Theorem suppose $f$    is holomorphic in the punctured disc $D_r(z_0)-\{z_0\}$ and has an essential singularity at $z_0$. Then,the image of $D_r(z_0)-\{z_0\}$ under $f$ is dense in the complex plane. How did Casorati and Weierstrass find this theorem? Did they explore some specific example and find this phenomenon? There is a classical complex function to give an example for essential singularity in many books. It is $$f(z)=\exp\left(\frac{1}{z}\right)$$ At $z_0=0$,it is not a removable singularity and Pole singularity.so it is a essential singularity. And I want to see the above phenomenon($f$ is dense in the complex plane) from this special instance. Set $z=re^{i\theta}$,then $$f(z)=\exp\left(\frac{\cos\theta}{r}\right)\cos\left(\frac{\sin\theta}{r}\right)-i\exp\left(\frac{\cos\theta}{r}\right)\sin\left(\frac{\sin\theta}{r}\right)$$ If I consider $f$ as a mapping from $Z$ to $W$. Did they find this phenomenon from studying the image in complex plane $W$? For simplicity, I consider the image of circle in $Z$ plane. For a fixed $r$,and $0\leq\theta <2\pi$,the below parametric equations give a image in $W$ plane: $$\begin{cases}x(r,\theta)=\exp\left(\frac{\cos\theta}{r}\right)\cos\left(\frac{\sin\theta}{r}\right)\\y(r,\theta)=\exp\left(\frac{\cos\theta}{r}\right)\sin\left(\frac{\sin\theta}{r}\right) \end{cases}$$ For a large $r$, the image looks like a point in real axis with coordinate$(1,0)$.so the reason cause its dense in $W$ must be ascirbed to $r$ near $0$. then I want to see the exact image shape in $W$. then I used Maxima to draw the figure for $r$ near $1$.: It is beautiful. and axial symmetry of real-axis. But I can't see some deep phenomenon. How can we find this phenomenon from study this special instance?","The first time when I see Casorati-Weierstrass' Theorem in Complex Analysis,I was shocked: Casorati-Weierstrass' Theorem suppose $f$    is holomorphic in the punctured disc $D_r(z_0)-\{z_0\}$ and has an essential singularity at $z_0$. Then,the image of $D_r(z_0)-\{z_0\}$ under $f$ is dense in the complex plane. How did Casorati and Weierstrass find this theorem? Did they explore some specific example and find this phenomenon? There is a classical complex function to give an example for essential singularity in many books. It is $$f(z)=\exp\left(\frac{1}{z}\right)$$ At $z_0=0$,it is not a removable singularity and Pole singularity.so it is a essential singularity. And I want to see the above phenomenon($f$ is dense in the complex plane) from this special instance. Set $z=re^{i\theta}$,then $$f(z)=\exp\left(\frac{\cos\theta}{r}\right)\cos\left(\frac{\sin\theta}{r}\right)-i\exp\left(\frac{\cos\theta}{r}\right)\sin\left(\frac{\sin\theta}{r}\right)$$ If I consider $f$ as a mapping from $Z$ to $W$. Did they find this phenomenon from studying the image in complex plane $W$? For simplicity, I consider the image of circle in $Z$ plane. For a fixed $r$,and $0\leq\theta <2\pi$,the below parametric equations give a image in $W$ plane: $$\begin{cases}x(r,\theta)=\exp\left(\frac{\cos\theta}{r}\right)\cos\left(\frac{\sin\theta}{r}\right)\\y(r,\theta)=\exp\left(\frac{\cos\theta}{r}\right)\sin\left(\frac{\sin\theta}{r}\right) \end{cases}$$ For a large $r$, the image looks like a point in real axis with coordinate$(1,0)$.so the reason cause its dense in $W$ must be ascirbed to $r$ near $0$. then I want to see the exact image shape in $W$. then I used Maxima to draw the figure for $r$ near $1$.: It is beautiful. and axial symmetry of real-axis. But I can't see some deep phenomenon. How can we find this phenomenon from study this special instance?",,['complex-analysis']
43,composition of non analytic functions can be analytic?,composition of non analytic functions can be analytic?,,I was wondering if the following scenarios are possible: 1) composition of an analytic function with a non-analytic continuous function being analytic (except for trivial cases) 2) composition of two non-analytic functions being analytic.,I was wondering if the following scenarios are possible: 1) composition of an analytic function with a non-analytic continuous function being analytic (except for trivial cases) 2) composition of two non-analytic functions being analytic.,,"['complex-analysis', 'analyticity']"
44,Question Relating with Open Mapping Theorem for Analytic Functions,Question Relating with Open Mapping Theorem for Analytic Functions,,This problem is taken from Section VIII.4 of Theodore Gamelin's Complex Analysis : Let $f(z)$ be an analytic function on the open unit disk $\mathbb{D}=\{|z|<1\}$.  Suppose there is an annulus $U = \{r<|z|<1\}$ such that the restriction of $f(z)$ to $U$ is one-to-one.  Show that $f(z)$ is one-to-one on $\mathbb{D}$. Any hints?,This problem is taken from Section VIII.4 of Theodore Gamelin's Complex Analysis : Let $f(z)$ be an analytic function on the open unit disk $\mathbb{D}=\{|z|<1\}$.  Suppose there is an annulus $U = \{r<|z|<1\}$ such that the restriction of $f(z)$ to $U$ is one-to-one.  Show that $f(z)$ is one-to-one on $\mathbb{D}$. Any hints?,,['complex-analysis']
45,Uniform distribution on the unit circle (in the complex plane),Uniform distribution on the unit circle (in the complex plane),,"I was trying to prove that for a standard complex Gaussian variable $Z$ it holds that $|Z|^2$ is exponentially distributed with parameter 1, $\frac{Z}{|Z|}$ is uniformly distributed on the unit circle $S^1:=\{z\in\mathbb{C} | |z|=1\}$ and that the two are independent. At some point I began asking myself: How does one describe the uniform distribution on the unit circle $S^1$? I resolved to say that it is the complex r.v. $e^{i\theta}$ where $\theta$ is uniformly distributed on $[0,2\pi]$. This seemed to work out fine (c.f. Byron's answer to this question ). However, if this is correct then this small argument will go through: Let $f:S^1 \rightarrow \mathbb{R}$ be bounded. Then $$E[f(Z)]=\int_{0}^{2\pi}{f(e^{i\theta})\frac{1}{2\pi}}d\theta=\frac{1}{2\pi i}\int_{S^1}{\frac{f(z)}{z}}dz,$$ where for the last equation $z=e^{i\theta}$ and thus $\frac{dz}{d\theta}=ie^{i\theta}$ i.e. $\frac{dz}{iz}=\frac{dz}{ie^{i\theta}}={d\theta}$.  So: Is $\frac{1}{2\pi i z}$ some kind of density for a uniformly distributed random variable on $S^1$? (I write ""some kind"" as it cannot be one because the unit circle has Lebesgue-measure 0 and hence the induced probability measure cannot be absolutely continuous to it.) Thanks for clearing my lack of clarity.","I was trying to prove that for a standard complex Gaussian variable $Z$ it holds that $|Z|^2$ is exponentially distributed with parameter 1, $\frac{Z}{|Z|}$ is uniformly distributed on the unit circle $S^1:=\{z\in\mathbb{C} | |z|=1\}$ and that the two are independent. At some point I began asking myself: How does one describe the uniform distribution on the unit circle $S^1$? I resolved to say that it is the complex r.v. $e^{i\theta}$ where $\theta$ is uniformly distributed on $[0,2\pi]$. This seemed to work out fine (c.f. Byron's answer to this question ). However, if this is correct then this small argument will go through: Let $f:S^1 \rightarrow \mathbb{R}$ be bounded. Then $$E[f(Z)]=\int_{0}^{2\pi}{f(e^{i\theta})\frac{1}{2\pi}}d\theta=\frac{1}{2\pi i}\int_{S^1}{\frac{f(z)}{z}}dz,$$ where for the last equation $z=e^{i\theta}$ and thus $\frac{dz}{d\theta}=ie^{i\theta}$ i.e. $\frac{dz}{iz}=\frac{dz}{ie^{i\theta}}={d\theta}$.  So: Is $\frac{1}{2\pi i z}$ some kind of density for a uniformly distributed random variable on $S^1$? (I write ""some kind"" as it cannot be one because the unit circle has Lebesgue-measure 0 and hence the induced probability measure cannot be absolutely continuous to it.) Thanks for clearing my lack of clarity.",,"['complex-analysis', 'probability-theory', 'probability-distributions']"
46,Sum of two absolute values in complex plane,Sum of two absolute values in complex plane,,"I'm trying to find out all $z \in C$ that satisfy the following condition: $|z+1|+|z-i|=3$ I understand that $|z|=r$ represents a circle with a radius of $r$. I also understand that $|z+1|=r$ can be written as $|(x+1)+yi|=\sqrt{(x+1)^2+y^2}=r$ which can then be squared to get $(x+1)^2+y^2=r^2$ which represents the circle with a radius of r, with center in $(-1,0)$. So, back to my problem: Unlike the example with $|z+1|=r$, where it is easy to square the equation, squaring  $|z+1|+|z-i|=3$ written as $\sqrt{(x+1)^2+y^2}+\sqrt{x^2+(y-1)^2}=3$ equals: $(x+1)^2+(y-1)^2+x^2+y^2+2\sqrt{(x+1)^2+y^2}\sqrt{x^2+(y-1)^2}=9$ which is a nightmare to solve, if at all possible. I am sure there must be some elegant way to solve this kind of problem. The way I'm thinking is this: $|z+1|$ by itself seems to represent a circle centered at $(-1,0)$, with an undefined radius, and $|z-i|$ seems to represent a circle centered at $(0,1)$, also with an undefined radius. However, the sum of those two radii must be 3. But I can't seem to wrap my mind around what this would represent (when drawn on Cartesian plane), or how to solve it analytically. So, how would one approach this problem? Even a hint would (probably) suffice.","I'm trying to find out all $z \in C$ that satisfy the following condition: $|z+1|+|z-i|=3$ I understand that $|z|=r$ represents a circle with a radius of $r$. I also understand that $|z+1|=r$ can be written as $|(x+1)+yi|=\sqrt{(x+1)^2+y^2}=r$ which can then be squared to get $(x+1)^2+y^2=r^2$ which represents the circle with a radius of r, with center in $(-1,0)$. So, back to my problem: Unlike the example with $|z+1|=r$, where it is easy to square the equation, squaring  $|z+1|+|z-i|=3$ written as $\sqrt{(x+1)^2+y^2}+\sqrt{x^2+(y-1)^2}=3$ equals: $(x+1)^2+(y-1)^2+x^2+y^2+2\sqrt{(x+1)^2+y^2}\sqrt{x^2+(y-1)^2}=9$ which is a nightmare to solve, if at all possible. I am sure there must be some elegant way to solve this kind of problem. The way I'm thinking is this: $|z+1|$ by itself seems to represent a circle centered at $(-1,0)$, with an undefined radius, and $|z-i|$ seems to represent a circle centered at $(0,1)$, also with an undefined radius. However, the sum of those two radii must be 3. But I can't seem to wrap my mind around what this would represent (when drawn on Cartesian plane), or how to solve it analytically. So, how would one approach this problem? Even a hint would (probably) suffice.",,"['complex-analysis', 'absolute-value']"
47,A sequence of polynomials that converges to $0$ pointwise except at $z=0$,A sequence of polynomials that converges to  pointwise except at,0 z=0,"This is an exercise from John Conway's book on complex analysis: Investigate if there exists a sequence of polynomials $(P_n)$ that fulfills the conditions $P_{n}(0)=1$ for all natural numbers $n$ and $\lim_{n\rightarrow\infty}P_n(z)=0$ for all $z\neq0$ Polynomials obey the maximum principle, but I don't see how to apply it if all we know is point-wise convergence. (Uniform convergence would imply $|P_n|<\epsilon$ on the unit circle for large $n$, contradicting $P_n(0)=1$.)","This is an exercise from John Conway's book on complex analysis: Investigate if there exists a sequence of polynomials $(P_n)$ that fulfills the conditions $P_{n}(0)=1$ for all natural numbers $n$ and $\lim_{n\rightarrow\infty}P_n(z)=0$ for all $z\neq0$ Polynomials obey the maximum principle, but I don't see how to apply it if all we know is point-wise convergence. (Uniform convergence would imply $|P_n|<\epsilon$ on the unit circle for large $n$, contradicting $P_n(0)=1$.)",,"['complex-analysis', 'polynomials']"
48,Finding the number of analytic functions which vanish only on a given set.,Finding the number of analytic functions which vanish only on a given set.,,"Let $S = \{0\}\cup \{\frac{1}{4n+7} : n =1,2\ldots\}$. How to find the number of analytic functions which vanish only on $S$? Options are a: $\infty$ b: $0$ c: $1$ d: $2$","Let $S = \{0\}\cup \{\frac{1}{4n+7} : n =1,2\ldots\}$. How to find the number of analytic functions which vanish only on $S$? Options are a: $\infty$ b: $0$ c: $1$ d: $2$",,['complex-analysis']
49,What is the number of zeroes of $z^4+4z^3+6z^2-4z+3$ inside $|z-1|<1$?,What is the number of zeroes of  inside ?,z^4+4z^3+6z^2-4z+3 |z-1|<1,"I've been practicing some problems on Rouche's theorem, but this one has given me trouble. How can I find how many zeroes of $z^4+4z^3+6z^2-4z+3$ inside $|z-1|<1$? The given polynomial looks similar to $(z-1)^4=z^4-4z^3+6z^2-4z+1$, so I let $g(z)$ be the given polynomial, and take $f(z)=8z^3+2$. Then on the circle $|z-1|=1$, $$ |f(z)-g(z)|=|(z-1)^4|=|z-1|^4=1. $$ If I could show $|f(z)|>1$ on the curve, then I would have that $f$ and $g$ have the same number of zeroes inside the circle, which I think is zero for $f$. Is this the right idea, or have I gone astray? Thanks.","I've been practicing some problems on Rouche's theorem, but this one has given me trouble. How can I find how many zeroes of $z^4+4z^3+6z^2-4z+3$ inside $|z-1|<1$? The given polynomial looks similar to $(z-1)^4=z^4-4z^3+6z^2-4z+1$, so I let $g(z)$ be the given polynomial, and take $f(z)=8z^3+2$. Then on the circle $|z-1|=1$, $$ |f(z)-g(z)|=|(z-1)^4|=|z-1|^4=1. $$ If I could show $|f(z)|>1$ on the curve, then I would have that $f$ and $g$ have the same number of zeroes inside the circle, which I think is zero for $f$. Is this the right idea, or have I gone astray? Thanks.",,['complex-analysis']
50,Order of the entire function: $\prod\limits_{n=1}^{\infty} \left(1-\frac{z}{n^k}\right)$,Order of the entire function:,\prod\limits_{n=1}^{\infty} \left(1-\frac{z}{n^k}\right),Please how to find order of $$ f_k(z) = \prod\limits_{n=1}^{\infty} \left(1-\frac{z}{n^k}\right) .$$ Let $M(r) = \max \{|f_k(z)|:|z| = r\}.$ Then order of $f_k(z)$ is defined as : $$\lambda = \limsup_{r\to \infty} \frac{\log \log M(r)}{\log r}.$$ Can someone help to solve this. Thank you.,Please how to find order of $$ f_k(z) = \prod\limits_{n=1}^{\infty} \left(1-\frac{z}{n^k}\right) .$$ Let $M(r) = \max \{|f_k(z)|:|z| = r\}.$ Then order of $f_k(z)$ is defined as : $$\lambda = \limsup_{r\to \infty} \frac{\log \log M(r)}{\log r}.$$ Can someone help to solve this. Thank you.,,['complex-analysis']
51,Differentiable and analytic function,Differentiable and analytic function,,"I have the following function and I am trying to find if it is analytic and differentiable. I use cauchy-riemann to prove it. $$ f(x)  = x^2 -x+y+i(y^2-5y-x)$$ $$u(x,y) = x^2-x+y$$  $$v(x,y) = y^2-5y-x$$ $$u_x = 2x-1$$ $$u_y = 1$$ $$v_x= -1$$ $$v_y= 2y-5$$ As a result $$u_y = -v_x \Rightarrow 1 = -(-1) \Rightarrow 1 = 1$$ and $$u_x \neq  v_y\Rightarrow y = x+2$$ I was wondering if we can say that there some regions that the function is differentiable or analytic.","I have the following function and I am trying to find if it is analytic and differentiable. I use cauchy-riemann to prove it. $$ f(x)  = x^2 -x+y+i(y^2-5y-x)$$ $$u(x,y) = x^2-x+y$$  $$v(x,y) = y^2-5y-x$$ $$u_x = 2x-1$$ $$u_y = 1$$ $$v_x= -1$$ $$v_y= 2y-5$$ As a result $$u_y = -v_x \Rightarrow 1 = -(-1) \Rightarrow 1 = 1$$ and $$u_x \neq  v_y\Rightarrow y = x+2$$ I was wondering if we can say that there some regions that the function is differentiable or analytic.",,['complex-analysis']
52,What applications of the Residue Theorem to real integration have had the biggest impact outside of pure math?,What applications of the Residue Theorem to real integration have had the biggest impact outside of pure math?,,"A typical undergraduate student (at least in North America) learns about integration of real-valued functions of one real variable, and learns some of its applications to science and probability, e.g. computing things like mass, charge, work, or the expected value of a continuous random variable.  They are also taught several techniques of integration such as change of variables, integration by parts, partial fraction decomposition, etc.  At some point later one, they learn some complex analysis, and in particular the Residue Theorem.  With some ingenuity, one can use this theorem about integrating complex functions over curves in the complex plane to compute integrals of real functions over (parts of) the real line, e.g.: $$\int_0^\infty\frac{\cos(ax)}{x^2+1}dx\ \ \ \ \ \ \ \ \ \ \  (a > 0)$$ My question is as in the title.  For instance, has there been some point in history when physicists benefited greatly from knowing how to calculate a certain real integral, whose computation via non-complex methods was not known at the time, or was perhaps overly difficult?","A typical undergraduate student (at least in North America) learns about integration of real-valued functions of one real variable, and learns some of its applications to science and probability, e.g. computing things like mass, charge, work, or the expected value of a continuous random variable.  They are also taught several techniques of integration such as change of variables, integration by parts, partial fraction decomposition, etc.  At some point later one, they learn some complex analysis, and in particular the Residue Theorem.  With some ingenuity, one can use this theorem about integrating complex functions over curves in the complex plane to compute integrals of real functions over (parts of) the real line, e.g.: $$\int_0^\infty\frac{\cos(ax)}{x^2+1}dx\ \ \ \ \ \ \ \ \ \ \  (a > 0)$$ My question is as in the title.  For instance, has there been some point in history when physicists benefited greatly from knowing how to calculate a certain real integral, whose computation via non-complex methods was not known at the time, or was perhaps overly difficult?",,"['complex-analysis', 'math-history', 'applications', 'definite-integrals']"
53,A representation theorem of harmonic functions,A representation theorem of harmonic functions,,"I am trying to solve a problem in harmonic functions in Rudin's book(Real and Complex analysis 3rd edition) To clarify the problem I want to ask, we need some notations: (1) $U$ is the open unit disc, and $T$ is the unit circle, the boundary of $U$ in the complex plane (2) $P(z,e^{it})$ is the Poisson Kernel. $$P(z,e^{it})=\frac{1-|z|^2}{|e^{it}-z|^2}$$ for $z\in U$, $e^{it}\in T$ (3)$P[f]$ is the Poisson Integral against $f\in L^1(T)$ (4)$P[d\mu]$ is the Poisson Integral against a complex measure on $T$, defined by $$P[d\mu](z)=\int_T P(z,e^{it})d\mu(e^{it})\quad (z\in U)$$ (5)$C(T)$ is the space consisting of all the continuous complex functions on $T$ (6)We associate to any function $u$ in $U$ a family of functions $u_r$ on $T$, defined by $$u_r(e^{it})=u(re^{it})\quad(0\leq r<1)$$ (7)The measure $\sigma$ is defined by $\sigma=m/2\pi$, where $m$ is ordinary Lebesgue measure on $T$ (8)$||u_r||_1$ is defined by $$||u_r||_1=\int_T |u_r|d\sigma\quad(0\leq r<1)$$ The problem is: Suppose $u$ is harmonic in $U$, and $\{u_r:0\leq r<1\}$ is a uniformly integrable subset of $L^1(T)$. Modify the proof of Theorem 11.30 to show that $u=P[f]$ for some $f\in L^1(T)$. Before stating Theorem 11.30, one needs theorem 11.29. Theorem 11.29: Suppose that (a)$X$ is a separable Banach space, (b)${\Lambda_n}$ is a sequence of linear functionals on $X$, (c)$sup_n||\Lambda_n||=M<\infty$ Then there is a subsequence $\{\Lambda_{n_i}\}$ such that the limit $$\Lambda x=\lim_{i\to\infty}\Lambda_{n_i} x$$ exists for every $x\in X$. Moreover, $\Lambda$ is linear, and $||\Lambda||\leq M$ Proof (Sketch): Note that $\{\Lambda_n\}$ is pointwise bounded and equicontinuous. Since each point of $X$ is a compact set, Theorem 11.29 follows from Arzela-Ascoli Theorem. Besides, it is obvious that $||\Lambda||\leq M$ and that $\Lambda$ is linear. Theorem 11.30: Suppose $u$ is harmonic in $U$, and $$sup_{0<r<1} ||u_r||_1=M<\infty$$ It follows that there is a unique complex Borel measure $\mu$ on $T$ so that $u=P[d\mu]$ Proof: Define linear functionals $\Lambda_r$ on $C(T)$ by $$\Lambda_r g=\int_T gu_rd\sigma\quad (0\leq r<1)$$ Therefore, $||\Lambda_r||\leq M$. By Theorem 11.29 and Riesz representation theorem for the dual of $C(T)$ there is a measure $\mu$ on $T$, with $||\mu$$||\leq M$, and a sequence $r_j\to 1$, so that $$\lim_{j\to\infty}\int_T gu_{r_j}d\sigma=\int_T gd\mu\quad (*)$$ for every $g\in C(T)$. Put $h_j(z)=u(r_j z)$. Then $h_j$ is harmonic in $U$, continuous on $\bar{U}$, and is therefore the Poisson integral of its restriction to $T$. Fix $z\in U$, and apply $(*)$ with $$g(e^{it})=P(z,e^{it})$$ Since $h_j(e^{it})=u_{r_j}(e^{it})$, we obtain $$u(z)=\lim_j u(r_j z)=\lim_j h_j(z)$$, and $$\lim_j h_j(z)=\lim_j\int_T P(z,e^{it})h_j(e^{it})d\sigma(e^{it})=\int_T P(z,e^{it})d\mu(e^{it})=P[d\mu](z)$$ To prove uniqueness, it suffices to show that $P[d\mu]=0$ implies $\mu=0$. Pick $f\in C(T)$, put $u=P[f]$, $v=p[d\mu]$. By Fubini's theorem, and the symmetry $P(re^{i\theta},e^{it})=P(re^{it},e^{i\theta})$, $$\int_T u_rd\mu=\int_T v_rfd\sigma\quad (0\leq r<1)$$ When $v=0$ then $v_r=0$, and since $u_r\to f$ uniformly, as $r\to 1$, we conclude that $$\int_T fd\mu=0$$ for every $f\in C(T)$ if $P[d\mu]=0$. By Riesz representation theorem, $\mu=0$. Any hints will be appreciated. I've really no idea how to modify the proof of Themorem 11.30, because the $L^1$-boundedness of the family $\{u_r\}$ seemes to play an important role in the proof. However, I cannot see the relationship between the boundedness and uniformly integrability. I have goolged this problem, but I cannot find anything helpful. Again, any hints will be appreciated.","I am trying to solve a problem in harmonic functions in Rudin's book(Real and Complex analysis 3rd edition) To clarify the problem I want to ask, we need some notations: (1) $U$ is the open unit disc, and $T$ is the unit circle, the boundary of $U$ in the complex plane (2) $P(z,e^{it})$ is the Poisson Kernel. $$P(z,e^{it})=\frac{1-|z|^2}{|e^{it}-z|^2}$$ for $z\in U$, $e^{it}\in T$ (3)$P[f]$ is the Poisson Integral against $f\in L^1(T)$ (4)$P[d\mu]$ is the Poisson Integral against a complex measure on $T$, defined by $$P[d\mu](z)=\int_T P(z,e^{it})d\mu(e^{it})\quad (z\in U)$$ (5)$C(T)$ is the space consisting of all the continuous complex functions on $T$ (6)We associate to any function $u$ in $U$ a family of functions $u_r$ on $T$, defined by $$u_r(e^{it})=u(re^{it})\quad(0\leq r<1)$$ (7)The measure $\sigma$ is defined by $\sigma=m/2\pi$, where $m$ is ordinary Lebesgue measure on $T$ (8)$||u_r||_1$ is defined by $$||u_r||_1=\int_T |u_r|d\sigma\quad(0\leq r<1)$$ The problem is: Suppose $u$ is harmonic in $U$, and $\{u_r:0\leq r<1\}$ is a uniformly integrable subset of $L^1(T)$. Modify the proof of Theorem 11.30 to show that $u=P[f]$ for some $f\in L^1(T)$. Before stating Theorem 11.30, one needs theorem 11.29. Theorem 11.29: Suppose that (a)$X$ is a separable Banach space, (b)${\Lambda_n}$ is a sequence of linear functionals on $X$, (c)$sup_n||\Lambda_n||=M<\infty$ Then there is a subsequence $\{\Lambda_{n_i}\}$ such that the limit $$\Lambda x=\lim_{i\to\infty}\Lambda_{n_i} x$$ exists for every $x\in X$. Moreover, $\Lambda$ is linear, and $||\Lambda||\leq M$ Proof (Sketch): Note that $\{\Lambda_n\}$ is pointwise bounded and equicontinuous. Since each point of $X$ is a compact set, Theorem 11.29 follows from Arzela-Ascoli Theorem. Besides, it is obvious that $||\Lambda||\leq M$ and that $\Lambda$ is linear. Theorem 11.30: Suppose $u$ is harmonic in $U$, and $$sup_{0<r<1} ||u_r||_1=M<\infty$$ It follows that there is a unique complex Borel measure $\mu$ on $T$ so that $u=P[d\mu]$ Proof: Define linear functionals $\Lambda_r$ on $C(T)$ by $$\Lambda_r g=\int_T gu_rd\sigma\quad (0\leq r<1)$$ Therefore, $||\Lambda_r||\leq M$. By Theorem 11.29 and Riesz representation theorem for the dual of $C(T)$ there is a measure $\mu$ on $T$, with $||\mu$$||\leq M$, and a sequence $r_j\to 1$, so that $$\lim_{j\to\infty}\int_T gu_{r_j}d\sigma=\int_T gd\mu\quad (*)$$ for every $g\in C(T)$. Put $h_j(z)=u(r_j z)$. Then $h_j$ is harmonic in $U$, continuous on $\bar{U}$, and is therefore the Poisson integral of its restriction to $T$. Fix $z\in U$, and apply $(*)$ with $$g(e^{it})=P(z,e^{it})$$ Since $h_j(e^{it})=u_{r_j}(e^{it})$, we obtain $$u(z)=\lim_j u(r_j z)=\lim_j h_j(z)$$, and $$\lim_j h_j(z)=\lim_j\int_T P(z,e^{it})h_j(e^{it})d\sigma(e^{it})=\int_T P(z,e^{it})d\mu(e^{it})=P[d\mu](z)$$ To prove uniqueness, it suffices to show that $P[d\mu]=0$ implies $\mu=0$. Pick $f\in C(T)$, put $u=P[f]$, $v=p[d\mu]$. By Fubini's theorem, and the symmetry $P(re^{i\theta},e^{it})=P(re^{it},e^{i\theta})$, $$\int_T u_rd\mu=\int_T v_rfd\sigma\quad (0\leq r<1)$$ When $v=0$ then $v_r=0$, and since $u_r\to f$ uniformly, as $r\to 1$, we conclude that $$\int_T fd\mu=0$$ for every $f\in C(T)$ if $P[d\mu]=0$. By Riesz representation theorem, $\mu=0$. Any hints will be appreciated. I've really no idea how to modify the proof of Themorem 11.30, because the $L^1$-boundedness of the family $\{u_r\}$ seemes to play an important role in the proof. However, I cannot see the relationship between the boundedness and uniformly integrability. I have goolged this problem, but I cannot find anything helpful. Again, any hints will be appreciated.",,['complex-analysis']
54,Two basic complex analysis homework questions,Two basic complex analysis homework questions,,"I have some homework problems from Greene and Krantz' Function Theory of One Complex Variable .  They come from Chapter 5.  I definitely do not want answers, just light prodding in the right direction. Let $f_j: D(0, 1)\to\mathbb C$ be   holomorphic and suppose that each   $f_j$ has at least $k$ roots in $D(0,1)$, counting multiplicities.  Suppose   that $f_j\to f$ uniformly on compact   sets.  Show by example that it does not follow that $f$ has at least $k$ roots counting multiplicities.  In   particular, construct examples, for   each fixed $k$ and each $\ell$,   $0\le\ell\le k$, where $f$ has exactly   $\ell$ roots.  What simple hypothesis   can you add that will guarantee that   $f$ does have at least $k$ roots? I know we require continuity of the $f_j$ on the boundary for the number of zeroes to be the same in the limit, but I'm not clear on why this is.  Presumably, that's the purpose of the question.  In another question, the goal is to prove this when the disk and its boundary are in the region of holomorticity of the $f_j$. I'm tempted to think that the problem we run in to is when the zeroes move to the boundary in the limit, but maybe I'm just not familiar enough to construct an actual example of this.  I'm also confused by their use of at least $k$ roots.  It seems simplest to start with a sequence of functions that all have exactly $k$ roots, but I'm afraid I'm missing something, and that it will only work if the functions have different numbers of zeroes, for some reason. Basically, I would like some intuition about how things can go wrong when we only have holomorticity on the interior of the disk, and maybe a (small) clue about the form the sequence will take. Prove: If $f$ is a polynomial on $\mathbb C$, then the zeroes of $f^\prime$ are contained in the closed convex hull of the zeroes of $f$.  (Here the closed convex hull of a set $S$ is the intersection of all closed convex sets that contain $S$.) [ Hint: If the zeroes of $f$ are contained in a halfplane $V$, then so are the zeroes of $f^\prime$. I would really like to use the maximum modulus theorem to say that the zeroes of $f^\prime$ occur at maxima (minima) of $f$, and therefore that these only happen on the boundary of some set $U$ (where $f$ is continuous on $\overline U$ and holomorphic on $U$), but I can't see a way to relate this statement about general bounded domains and convex hulls. I could be looking at these entirely wrong.  If I need to clarify my thoughts or say more, please let me know, and again, I definitely don't want more than little hints.  Thanks all.","I have some homework problems from Greene and Krantz' Function Theory of One Complex Variable .  They come from Chapter 5.  I definitely do not want answers, just light prodding in the right direction. Let $f_j: D(0, 1)\to\mathbb C$ be   holomorphic and suppose that each   $f_j$ has at least $k$ roots in $D(0,1)$, counting multiplicities.  Suppose   that $f_j\to f$ uniformly on compact   sets.  Show by example that it does not follow that $f$ has at least $k$ roots counting multiplicities.  In   particular, construct examples, for   each fixed $k$ and each $\ell$,   $0\le\ell\le k$, where $f$ has exactly   $\ell$ roots.  What simple hypothesis   can you add that will guarantee that   $f$ does have at least $k$ roots? I know we require continuity of the $f_j$ on the boundary for the number of zeroes to be the same in the limit, but I'm not clear on why this is.  Presumably, that's the purpose of the question.  In another question, the goal is to prove this when the disk and its boundary are in the region of holomorticity of the $f_j$. I'm tempted to think that the problem we run in to is when the zeroes move to the boundary in the limit, but maybe I'm just not familiar enough to construct an actual example of this.  I'm also confused by their use of at least $k$ roots.  It seems simplest to start with a sequence of functions that all have exactly $k$ roots, but I'm afraid I'm missing something, and that it will only work if the functions have different numbers of zeroes, for some reason. Basically, I would like some intuition about how things can go wrong when we only have holomorticity on the interior of the disk, and maybe a (small) clue about the form the sequence will take. Prove: If $f$ is a polynomial on $\mathbb C$, then the zeroes of $f^\prime$ are contained in the closed convex hull of the zeroes of $f$.  (Here the closed convex hull of a set $S$ is the intersection of all closed convex sets that contain $S$.) [ Hint: If the zeroes of $f$ are contained in a halfplane $V$, then so are the zeroes of $f^\prime$. I would really like to use the maximum modulus theorem to say that the zeroes of $f^\prime$ occur at maxima (minima) of $f$, and therefore that these only happen on the boundary of some set $U$ (where $f$ is continuous on $\overline U$ and holomorphic on $U$), but I can't see a way to relate this statement about general bounded domains and convex hulls. I could be looking at these entirely wrong.  If I need to clarify my thoughts or say more, please let me know, and again, I definitely don't want more than little hints.  Thanks all.",,['complex-analysis']
55,"Show that $h(z):=\int_X f(z,t) d\mu(t)$ is holomorphic",Show that  is holomorphic,"h(z):=\int_X f(z,t) d\mu(t)","Let $\mu$ be a $\sigma-$ finite measure on some measure space $X$ , and $\Omega \subseteq \mathbb{C}$ be a domain. Assume that the mapping $(z,t)\in \Omega \times X \rightarrow f(z,t)\in \mathbb{C}$ is measurable for fixed $t \in X$ , the function $z \mapsto f(z,t)$ holomorphic and for every compact set $K \subseteq \Omega$ , $\int_X sup_{z \in K} |f(z,t)| d\mu(t) $ is finite Show that the function $h(z):=\int_X f(z,t) d\mu(t)$ is holomorphic in $\Omega$ Approach: My Idea would be to use Moreas Theorem. Thus I need to show that for every closed piecewise $C^1$ curve $\int_{\gamma}h(z)dz=0$ . $\int_{\gamma}h(z)dz=\int_{\gamma}\int_X f(z,t) d\mu(t)dz$ If I could change the order of Integration I would get $\int_{\gamma}h(z)dz=\int_X \int_{\gamma} f(z,t) dz d\mu(t)$ . Then $\int_{\gamma} f(z,t) dz$ is the integral of a holomorphic function since $t$ is fixed in this case. By Cauchy Theorem I would get $\int_{\gamma} f(z,t) dz=0$ , and thus $\int_X 0 d\mu(t)=0$ . My main problem seems to be that I don't know how to argue that I can interchange both integrals. I assume it has to do with 3). Question: Is my approach even correct? If yes, what is the reason to interchange the integrals?","Let be a finite measure on some measure space , and be a domain. Assume that the mapping is measurable for fixed , the function holomorphic and for every compact set , is finite Show that the function is holomorphic in Approach: My Idea would be to use Moreas Theorem. Thus I need to show that for every closed piecewise curve . If I could change the order of Integration I would get . Then is the integral of a holomorphic function since is fixed in this case. By Cauchy Theorem I would get , and thus . My main problem seems to be that I don't know how to argue that I can interchange both integrals. I assume it has to do with 3). Question: Is my approach even correct? If yes, what is the reason to interchange the integrals?","\mu \sigma- X \Omega \subseteq \mathbb{C} (z,t)\in \Omega \times X \rightarrow f(z,t)\in \mathbb{C} t \in X z \mapsto f(z,t) K \subseteq \Omega \int_X sup_{z \in K} |f(z,t)| d\mu(t)  h(z):=\int_X f(z,t) d\mu(t) \Omega C^1 \int_{\gamma}h(z)dz=0 \int_{\gamma}h(z)dz=\int_{\gamma}\int_X f(z,t) d\mu(t)dz \int_{\gamma}h(z)dz=\int_X \int_{\gamma} f(z,t) dz d\mu(t) \int_{\gamma} f(z,t) dz t \int_{\gamma} f(z,t) dz=0 \int_X 0 d\mu(t)=0","['complex-analysis', 'analysis', 'measure-theory']"
56,Compute $f(z)$ and show it's well defined.,Compute  and show it's well defined.,f(z),"I'm given the function $f$ in integral form as follows $$f(z)=\int_{\gamma} \frac{dw}{w-z},$$ where $\gamma(t)=t, \, 0<t<1$ and $z \notin [0,1]$ . I'm asked to compute this integral and show that $f$ is well defined. So my approach was to compute the integral by definition, $$f(z)=\int_0^1 \frac{dt}{t-z}= \log(1-z)-\log(-z)=\log(|1-z|)-\log(|z|)+i(\arg(1-z)-\arg(-z)).$$ Since $z \notin [0,1]$ there is no risk of the log's of the real part to explode. Now I just have to prove that the imaginary part is not multivalued for any branch of the logarithm I choose. How can I do that? Any hints?","I'm given the function in integral form as follows where and . I'm asked to compute this integral and show that is well defined. So my approach was to compute the integral by definition, Since there is no risk of the log's of the real part to explode. Now I just have to prove that the imaginary part is not multivalued for any branch of the logarithm I choose. How can I do that? Any hints?","f f(z)=\int_{\gamma} \frac{dw}{w-z}, \gamma(t)=t, \, 0<t<1 z \notin [0,1] f f(z)=\int_0^1 \frac{dt}{t-z}= \log(1-z)-\log(-z)=\log(|1-z|)-\log(|z|)+i(\arg(1-z)-\arg(-z)). z \notin [0,1]","['complex-analysis', 'complex-numbers', 'complex-integration']"
57,"If $|f(0)|\geq r$, then $|f(z)|\geq (r-|z|)/(1-r|z|)$ for $|z|<r$","If , then  for",|f(0)|\geq r |f(z)|\geq (r-|z|)/(1-r|z|) |z|<r,"The following is an exercise IX.1.5 in Gamelin Suppose that $f(z)$ is analytic and satisfies $|f(z)|\leq 1$ for $|z|<1$ . Show that if $|f(0)|\geq r$ , then $|f(z)|\geq (r-|z|)/(1-r|z|)$ for $|z|<r$ . Let $\varphi:\Bbb D\to\Bbb D$ be a Blaschke factor $\varphi(z) = {f(0)-z\over 1-\overline{f(0)}z}$ . Then applying Schwarz lemma on $\varphi\circ f$ , we get \begin{align*} & |(\varphi\circ f)(z)|\leq |z|\Rightarrow \left|{f(0)-f(z)\over 1-\overline{f(0)}f(z)}\right|\leq |z|.\\ & |f(0)|-|f(z)|\leq |f(0)-f(z)|\leq |z||1-\overline{f(0)}f(z)|\leq |z|(1+|f(0)||f(z)|).\\ & r(1-|z||f(z)|)\leq |f(0)|(1-|z||f(z)|)\leq |z|+|f(z)|.\\ & {r-|z|\over 1+r|z|}\leq |f(z)|. \end{align*} This is as far as I get. I wonder if there's a way to get the stated inequality.","The following is an exercise IX.1.5 in Gamelin Suppose that is analytic and satisfies for . Show that if , then for . Let be a Blaschke factor . Then applying Schwarz lemma on , we get This is as far as I get. I wonder if there's a way to get the stated inequality.","f(z) |f(z)|\leq 1 |z|<1 |f(0)|\geq r |f(z)|\geq (r-|z|)/(1-r|z|) |z|<r \varphi:\Bbb D\to\Bbb D \varphi(z) = {f(0)-z\over 1-\overline{f(0)}z} \varphi\circ f \begin{align*}
& |(\varphi\circ f)(z)|\leq |z|\Rightarrow \left|{f(0)-f(z)\over 1-\overline{f(0)}f(z)}\right|\leq |z|.\\
& |f(0)|-|f(z)|\leq |f(0)-f(z)|\leq |z||1-\overline{f(0)}f(z)|\leq |z|(1+|f(0)||f(z)|).\\
& r(1-|z||f(z)|)\leq |f(0)|(1-|z||f(z)|)\leq |z|+|f(z)|.\\
& {r-|z|\over 1+r|z|}\leq |f(z)|.
\end{align*}","['complex-analysis', 'inequality']"
58,$\prod_{n=1}^{\infty} (1- z/ a_n) $ is entire iff $\sum_{n=1}^{\infty} 1/(z-a_n) $ is meromorphic,is entire iff  is meromorphic,\prod_{n=1}^{\infty} (1- z/ a_n)  \sum_{n=1}^{\infty} 1/(z-a_n) ,This question was asked in a masters exam previous year paper and I was unable to prove it. Show that the $$\prod_{n=1}^{\infty} (1- \frac{z}{a_{n}}) $$ is entire iff $$\sum_{n=1}^{\infty} \frac{1}{z-a_n} $$ is meromorphic. $\prod_{n=1}^{\infty}( 1- \frac{z}{a_{n}})$ is entire if Convergence of infinite product is uniform and that happens if: $$\sum_{n=1}^{\infty} \frac{z}{a_{n}}$$ converges for all z. But I am not able to correlate it with: $$\sum_{n=1}^{\infty} \frac{1}{z-a_n} $$ . Can you please help by telling which result should be helpful. Thank you!,This question was asked in a masters exam previous year paper and I was unable to prove it. Show that the is entire iff is meromorphic. is entire if Convergence of infinite product is uniform and that happens if: converges for all z. But I am not able to correlate it with: . Can you please help by telling which result should be helpful. Thank you!,\prod_{n=1}^{\infty} (1- \frac{z}{a_{n}})  \sum_{n=1}^{\infty} \frac{1}{z-a_n}  \prod_{n=1}^{\infty}( 1- \frac{z}{a_{n}}) \sum_{n=1}^{\infty} \frac{z}{a_{n}} \sum_{n=1}^{\infty} \frac{1}{z-a_n} ,['complex-analysis']
59,"$f$ is analytic on $D$, prove that $f$ is a constant","is analytic on , prove that  is a constant",f D f,"I've been stuck on this for a while, it is a decade old qualifying exam problem from my university: Let $f$ be a analytic function in the open unit disk $D$ such that $|f(z)|\leq 1$ for all $z\in D$ . Let $g$ be the restriction of $f$ to the real interval $(0,1)$ and assume $\lim_{r\rightarrow 1}g(r)=1$ and $\lim_{r\rightarrow 1}g'(r)=0$ . Prove that $f$ is a constant. Can anyone please give me some hints? I've really tried everything now, but nothing seems to work. The condition given seems to be very localized and I'm not sure how to use them. Thanks in advance!","I've been stuck on this for a while, it is a decade old qualifying exam problem from my university: Let be a analytic function in the open unit disk such that for all . Let be the restriction of to the real interval and assume and . Prove that is a constant. Can anyone please give me some hints? I've really tried everything now, but nothing seems to work. The condition given seems to be very localized and I'm not sure how to use them. Thanks in advance!","f D |f(z)|\leq 1 z\in D g f (0,1) \lim_{r\rightarrow 1}g(r)=1 \lim_{r\rightarrow 1}g'(r)=0 f",['complex-analysis']
60,Understanding the statement and the proof of Bertini's theorem in Griffiths and Harris,Understanding the statement and the proof of Bertini's theorem in Griffiths and Harris,,"I am having trouble understanding the statement and the proof of Bertini's theorem in Griffiths & Harris book (p. $137$ ). Frankly, I do not understand a word even after I read several answers on stack. The theorem is The generic element of a linear system is smooth away from the base locus of the system. First question . Does the statement above refer to linear of general line bundles rather than just line bundles associated to divisors? As far as I can say, it refers to a linear system of a line bundle associated to a divisor. Tell me if I am wrong. Second question . What is the generic element? Or what is the generic pencil? In the proof, the authors start with "" If the generic element of a linear system is singular away from the base locus of the system, then the same will be true for a generic pencil contained in the system; thus it suffices to prove Bertini for a pencil. "" Third question . What does the above sentence mean exactly? Now suppose $\left \{D_{\lambda} \right \}_{\lambda \in \mathbb{P}^1}$ is a pencil Fourth question . Why do the authors write $D_{\lambda} = (f+\lambda g = 0)$ ? What do $f,g$ mean here? The last question relates to the degree of a variety (p. $171$ ). Bertini applied to the smooth locus of $V$ the generic $(n-k)$ -plane $\mathbb{P}^{n-k} \subset \mathbb{P}^n$ will intersect $V$ transversely and so will meet $V$ in exactly $\mathrm{deg}(V) = ^{\#}(\mathbb{P}^{n-k}.V)$ points. Last question . What is generic $(n-k)$ -plane? In this case, why does it intersect $V$ transversely?","I am having trouble understanding the statement and the proof of Bertini's theorem in Griffiths & Harris book (p. ). Frankly, I do not understand a word even after I read several answers on stack. The theorem is The generic element of a linear system is smooth away from the base locus of the system. First question . Does the statement above refer to linear of general line bundles rather than just line bundles associated to divisors? As far as I can say, it refers to a linear system of a line bundle associated to a divisor. Tell me if I am wrong. Second question . What is the generic element? Or what is the generic pencil? In the proof, the authors start with "" If the generic element of a linear system is singular away from the base locus of the system, then the same will be true for a generic pencil contained in the system; thus it suffices to prove Bertini for a pencil. "" Third question . What does the above sentence mean exactly? Now suppose is a pencil Fourth question . Why do the authors write ? What do mean here? The last question relates to the degree of a variety (p. ). Bertini applied to the smooth locus of the generic -plane will intersect transversely and so will meet in exactly points. Last question . What is generic -plane? In this case, why does it intersect transversely?","137 \left \{D_{\lambda} \right \}_{\lambda \in \mathbb{P}^1} D_{\lambda} = (f+\lambda g = 0) f,g 171 V (n-k) \mathbb{P}^{n-k} \subset \mathbb{P}^n V V \mathrm{deg}(V) = ^{\#}(\mathbb{P}^{n-k}.V) (n-k) V","['complex-analysis', 'algebraic-geometry', 'complex-geometry', 'intersection-theory']"
61,Number of zeros of $z^4-z^3-4z+1$ in the ring $\{ 1 < |z| < 2 \}$,Number of zeros of  in the ring,z^4-z^3-4z+1 \{ 1 < |z| < 2 \},"I need to prove that the number of zeros of $z^4-z^3-4z+1$ in the ring $\{ 1 < |z| < 2 \}$ is equal to $3$ . What I have done so far; I've proved there is only one zero in the $\{|z|\leq1\}$ . So the only thing remaining is to prove there is no zeros in the $\{|z|\geq2\}$ . This part, however, creates a lot of issues for me. I've tried the classic way using Rouche's theorem and even adding new polynomials in order to use it, but nothing helped. Also tried assuming $z^4-z^3-4z+1=0$ and $|z|\geq2$ with some clever use of inequalites, that didn't help either. I don't know if I'm missing something, but according to WA, one zero is $\approx1.9325$ so that might be causing troubles in my opinion.","I need to prove that the number of zeros of in the ring is equal to . What I have done so far; I've proved there is only one zero in the . So the only thing remaining is to prove there is no zeros in the . This part, however, creates a lot of issues for me. I've tried the classic way using Rouche's theorem and even adding new polynomials in order to use it, but nothing helped. Also tried assuming and with some clever use of inequalites, that didn't help either. I don't know if I'm missing something, but according to WA, one zero is so that might be causing troubles in my opinion.",z^4-z^3-4z+1 \{ 1 < |z| < 2 \} 3 \{|z|\leq1\} \{|z|\geq2\} z^4-z^3-4z+1=0 |z|\geq2 \approx1.9325,"['complex-analysis', 'roots']"
62,$f : \Bbb{C} \to \Bbb{C}$ is an entire function s.t. $|f(z)| \to \infty$ as $|z| \to \infty$. Prove $f$ is a polynomial.,is an entire function s.t.  as . Prove  is a polynomial.,f : \Bbb{C} \to \Bbb{C} |f(z)| \to \infty |z| \to \infty f,"Let $f : \mathbb{C} \rightarrow \mathbb{C}$ be an entire function such that $|f(z)| \rightarrow  \infty$ as $|z| \rightarrow  \infty$ . Prove that $f$ is a polynomial by following the steps below. (a) Observe that the function $f(1/z)$ defined in $C \setminus\{0\}$ has a pole at the origin. Let $S$ be the singular part of its Laurent series around $0$ . Argue that $g(z) = f(z)  S(1/z)$ approaches finite limits as $z \rightarrow 0$ and as $|z| \rightarrow  \infty$ . (b) Prove that $g$ extends to a bounded entire function and is therefore constant. (c) Deduce that $f$ is a polynomial. I know there are solutions to this but not with these steps. I have been given this as an assignment and really need help to figure out how to write the solution. For point (a) I wrote In order for $|f(z)| \rightarrow  \infty$ as $|z| \rightarrow  \infty$ , is equavalent saying $|f(\frac{1}{z})| \rightarrow  \infty$ as $z \rightarrow 0$ . So $f(z)$ can be written in Laurent series around the point $0$ such that $\sum_{n=-\infty}^\infty a_nz^n = g(z) + s(\frac{1}{z})$ given $g(z)$ is the power series $\sum_{n=0}^\infty a_nz^n$ and $S$ is the singular part of its Laurent series around $0$ . Hence, $ g(z)= f(z) - s(\frac{1}{z})$ and $g(z)$ tends to a  finite limits as $z \rightarrow 0$ and as $|z| \rightarrow  \infty$ given the power series. For (b) I wrote Only removable singularities are left in $g(z)$ . So with Riemann's removable singularity theorem, with $p$ being some removable singularity. $g(z)$ can be extended continuously and holomorphically at $p$ and since $g(z)$ is bonded on some disc around $p$ excluding the point $p$ with a radius bigger than $0$ . Hence the extended function is bounded as well and by Liouville's theorem, it is a constant function. And I have no clue how to answer (c), sorry for the long post and thanks in advance!!!","Let be an entire function such that as . Prove that is a polynomial by following the steps below. (a) Observe that the function defined in has a pole at the origin. Let be the singular part of its Laurent series around . Argue that approaches finite limits as and as . (b) Prove that extends to a bounded entire function and is therefore constant. (c) Deduce that is a polynomial. I know there are solutions to this but not with these steps. I have been given this as an assignment and really need help to figure out how to write the solution. For point (a) I wrote In order for as , is equavalent saying as . So can be written in Laurent series around the point such that given is the power series and is the singular part of its Laurent series around . Hence, and tends to a  finite limits as and as given the power series. For (b) I wrote Only removable singularities are left in . So with Riemann's removable singularity theorem, with being some removable singularity. can be extended continuously and holomorphically at and since is bonded on some disc around excluding the point with a radius bigger than . Hence the extended function is bounded as well and by Liouville's theorem, it is a constant function. And I have no clue how to answer (c), sorry for the long post and thanks in advance!!!",f : \mathbb{C} \rightarrow \mathbb{C} |f(z)| \rightarrow  \infty |z| \rightarrow  \infty f f(1/z) C \setminus\{0\} S 0 g(z) = f(z)  S(1/z) z \rightarrow 0 |z| \rightarrow  \infty g f |f(z)| \rightarrow  \infty |z| \rightarrow  \infty |f(\frac{1}{z})| \rightarrow  \infty z \rightarrow 0 f(z) 0 \sum_{n=-\infty}^\infty a_nz^n = g(z) + s(\frac{1}{z}) g(z) \sum_{n=0}^\infty a_nz^n S 0  g(z)= f(z) - s(\frac{1}{z}) g(z) z \rightarrow 0 |z| \rightarrow  \infty g(z) p g(z) p g(z) p p 0,['complex-analysis']
63,Proposition 3.10 from Conway's book,Proposition 3.10 from Conway's book,,"Definition: If $z_1\in \mathbb{C}_{\infty}$ then $(z_1,z_2,z_3,z_4)$ (the cross ratio of $z_1,z_2,z_3$ and $z_4$ ) is   the image of $z_1$ under the unique Mobius transformation which takes $z_2$ to $1$ , $z_3$ to $0$ and $z_4$ to $\infty$ . Proposition: Let $z_1,z_2,z_3,z_4$ be four distinct points on $\mathbb{C}_{\infty}$ . Then $(z_1,z_2,z_3,z_4)$ is a real number iff all four points lie on a circle. Proof: Let $S:\mathbb{C}_{\infty}\to \mathbb{C}_{\infty}$ be defined by $Sz=(z,z_2,z_3,z_4) $ ; then $S^{-1}(\mathbb{R})=$ the set of $z$ such that $(z,z_2,z_3,z_4)$ is real.  So it is enough to show that the   image of $\mathbb{R}_{\infty}$ under a Mobius transformation is a   circle. This is the excerpt from Conway's book on Complex Analysis of one variable. Can anyone please explain why it is enough to show that $S(\mathbb{R}_{\infty})=\Gamma$ - circle? I have spent about one hour trying to understand it and write down something but I failed to understand it. Would be very grateful for detailed help, please!","Definition: If then (the cross ratio of and ) is   the image of under the unique Mobius transformation which takes to , to and to . Proposition: Let be four distinct points on . Then is a real number iff all four points lie on a circle. Proof: Let be defined by ; then the set of such that is real.  So it is enough to show that the   image of under a Mobius transformation is a   circle. This is the excerpt from Conway's book on Complex Analysis of one variable. Can anyone please explain why it is enough to show that - circle? I have spent about one hour trying to understand it and write down something but I failed to understand it. Would be very grateful for detailed help, please!","z_1\in \mathbb{C}_{\infty} (z_1,z_2,z_3,z_4) z_1,z_2,z_3 z_4 z_1 z_2 1 z_3 0 z_4 \infty z_1,z_2,z_3,z_4 \mathbb{C}_{\infty} (z_1,z_2,z_3,z_4) S:\mathbb{C}_{\infty}\to \mathbb{C}_{\infty} Sz=(z,z_2,z_3,z_4)  S^{-1}(\mathbb{R})= z (z,z_2,z_3,z_4) \mathbb{R}_{\infty} S(\mathbb{R}_{\infty})=\Gamma",['complex-analysis']
64,Power series of $f(z)^8$,Power series of,f(z)^8,"Goal : If $f(z)^8$ is analytic on some domain D and if $f(z)$ is continuous on domain $D$ with $f(0) = 0$ , then the power series $f(z)^8 = \sum a_nz^n$ will begin with $n$ divisible by $8$ My attempt : Allow $g(z) = f(z)^8$ which is analytic on some domain D. Then, we use Cauchy integral to calculate our $a_n$ . $$g^{(n)}(z) = a_n = \frac{n!}{2\pi i}\int_{D} \frac{g(w)}{(w-z)^{n+1}} dw$$ Now, I notice that we can split the integrand up, but I'm not quite sure if it's helpful $$\frac{n!}{2\pi i} \int_D \frac{1}{(w-z)^{j}} \frac{f(w)^8}{(w-z)^{8k+1}} dw$$ . Where $j + 8k + 1 = n + 1$ Can anyone tell me if this is going in the right direction or any hints?","Goal : If is analytic on some domain D and if is continuous on domain with , then the power series will begin with divisible by My attempt : Allow which is analytic on some domain D. Then, we use Cauchy integral to calculate our . Now, I notice that we can split the integrand up, but I'm not quite sure if it's helpful . Where Can anyone tell me if this is going in the right direction or any hints?",f(z)^8 f(z) D f(0) = 0 f(z)^8 = \sum a_nz^n n 8 g(z) = f(z)^8 a_n g^{(n)}(z) = a_n = \frac{n!}{2\pi i}\int_{D} \frac{g(w)}{(w-z)^{n+1}} dw \frac{n!}{2\pi i} \int_D \frac{1}{(w-z)^{j}} \frac{f(w)^8}{(w-z)^{8k+1}} dw j + 8k + 1 = n + 1,"['complex-analysis', 'complex-integration']"
65,Holomorphic function that decays faster than any exponential in a half plane?,Holomorphic function that decays faster than any exponential in a half plane?,,"I'm getting some trouble with the following question. I will use the common notation $z=x+iy$ . It is well-known that $f(z)=e^{-z}$ tends to zero when $x$ tends to $+\infty$ , since $\vert f(z) \vert =e^{-x}$ . Of course, the same happens for the family of functions $f_{\lambda}(z)=e^{-\lambda z}$ where $\lambda >0$ is a positive parameter. In fact, if $\lambda$ is bigger, the decay is faster. My question is if it is possible to find a (non identically zero) $\textbf{holomorphic}$ function (in the right half plane) that decays faster than any function $f_{\lambda}$ . In mathematical terms, the question is if we can find an $\textbf{holomorphic}$ function $g \neq 0$ (in the right half plane) such that for any sequence $x_n+i y_n$ such that $x_n$ goes to $+\infty$ , we have that the limit $$g(x_n+iy_n) \cdot e^{\lambda (x_n + i  y_n)}$$ tends to zero for any $\lambda >0$ . Informally, when we go to the right in the complex plane (ignoring if $y$ changes or not) we must decay faster than any exponential. Remark: If $g$ is not required to be holomorphic the answer is trivially ""yes"". You just make $g(z)$ a function of its real parts (just depending on $x$ ) in a way that in the interval $[n,n+1]$ $g$ decays as $e^{-n}$ .","I'm getting some trouble with the following question. I will use the common notation . It is well-known that tends to zero when tends to , since . Of course, the same happens for the family of functions where is a positive parameter. In fact, if is bigger, the decay is faster. My question is if it is possible to find a (non identically zero) function (in the right half plane) that decays faster than any function . In mathematical terms, the question is if we can find an function (in the right half plane) such that for any sequence such that goes to , we have that the limit tends to zero for any . Informally, when we go to the right in the complex plane (ignoring if changes or not) we must decay faster than any exponential. Remark: If is not required to be holomorphic the answer is trivially ""yes"". You just make a function of its real parts (just depending on ) in a way that in the interval decays as .","z=x+iy f(z)=e^{-z} x +\infty \vert f(z) \vert =e^{-x} f_{\lambda}(z)=e^{-\lambda z} \lambda >0 \lambda \textbf{holomorphic} f_{\lambda} \textbf{holomorphic} g \neq 0 x_n+i y_n x_n +\infty g(x_n+iy_n) \cdot e^{\lambda (x_n + i  y_n)} \lambda >0 y g g(z) x [n,n+1] g e^{-n}",['complex-analysis']
66,Proving upper bound $|\tan(z)| < 2$ on a contour,Proving upper bound  on a contour,|\tan(z)| < 2,"I have to find an upper bound as described in the title. First I'll give some background of the question. For $k \in \mathbb{N}$, let $\alpha_k$ be the boundary of the square with vertices $k\pi(1+i)$, $k\pi(-1+i)$, $k\pi(-1-i)$ and $k\pi(1-i)$. Furthermore let $D = \{ z \in \mathbb{C}: z \neq 0 \quad \text{and} \quad \cos z \neq 0\}$ and define $f:D \rightarrow \mathbb{C}$ : \begin{equation} f(z) = \frac{\tan z}{z^2}. \end{equation} I have to show that $|\tan z|<2$ on $\alpha_k$ for all k. So I thought of first writing the tangent as a quotient of the sine and cosine and then write it with complex powers of $e$. So I end up with: \begin{equation} \tan z = \frac{1}{i} \frac{e^{iz}-e^{-iz}}{e^{iz}+e^{-iz}}. \end{equation} Then I assumed that $z = x + iy$ and after a lot of of trigonometric formulas I've found that: \begin{equation} |\tan z| = |\tan (x+iy)| = \sqrt{\frac{1}{(\cosh(2y)+\cos(2x))^2}\left( \sin^2(2x) + \sinh^2(2y) \right)}. \end{equation} And here I got stuck. Perhaps we can use the fact that we have to show this upper bound on the contour $\alpha_k$ and use that the maximum modulus of z there is $k\pi$, but I don't see how we can arrive on the bound 2 from here. Does anyone have an idea how we can proceed or can tell me if I'm on the right track with this attempt? Thanks in advance! -DS","I have to find an upper bound as described in the title. First I'll give some background of the question. For $k \in \mathbb{N}$, let $\alpha_k$ be the boundary of the square with vertices $k\pi(1+i)$, $k\pi(-1+i)$, $k\pi(-1-i)$ and $k\pi(1-i)$. Furthermore let $D = \{ z \in \mathbb{C}: z \neq 0 \quad \text{and} \quad \cos z \neq 0\}$ and define $f:D \rightarrow \mathbb{C}$ : \begin{equation} f(z) = \frac{\tan z}{z^2}. \end{equation} I have to show that $|\tan z|<2$ on $\alpha_k$ for all k. So I thought of first writing the tangent as a quotient of the sine and cosine and then write it with complex powers of $e$. So I end up with: \begin{equation} \tan z = \frac{1}{i} \frac{e^{iz}-e^{-iz}}{e^{iz}+e^{-iz}}. \end{equation} Then I assumed that $z = x + iy$ and after a lot of of trigonometric formulas I've found that: \begin{equation} |\tan z| = |\tan (x+iy)| = \sqrt{\frac{1}{(\cosh(2y)+\cos(2x))^2}\left( \sin^2(2x) + \sinh^2(2y) \right)}. \end{equation} And here I got stuck. Perhaps we can use the fact that we have to show this upper bound on the contour $\alpha_k$ and use that the maximum modulus of z there is $k\pi$, but I don't see how we can arrive on the bound 2 from here. Does anyone have an idea how we can proceed or can tell me if I'm on the right track with this attempt? Thanks in advance! -DS",,"['complex-analysis', 'contour-integration', 'estimation']"
67,Text about connections between complex analysis and partition theory?,Text about connections between complex analysis and partition theory?,,"I hope this is enough about maths to ask here. As part of my degree I need to do a project consisting of a 7,000-word report on some area of maths (quite a general guideline). I've noticed in studying complex analysis that quite frequently, studying a function's residues winds up giving you an expression for an infinite sum or a generating function for some partition. For instance, there's a well-documented example of using elliptic functions to prove Jacobi's Triple Product. I also know a little bit about partitions, having read the book Integer Partitions by Andrews and Eriksson and done a previous report summarising a large part of it. So I'd like this project to combine the two areas, and I know -- mostly from casual references -- that it's generally agreed that complex analysis and additive number theory are 'closely related'. The two subjects also seem well-adapted for combining because doing the working out in complex analysis is elegant, but the final answer might not be very exciting, while it's the other way round in number theory, where the working out can be very painful but the final answer pretty neat. Can you recommend any online source that explores connections between complex analysis and partition theory? If there's an especially good textbook, that would be welcome too. I've noticed Complex Analysis in Number Theory by Anatoly A. Karatsuba, but it doesn't seem like the right fit based on the Amazon description. EDIT: And if there's a source that links general number theory results with complex analysis, that's cool too. It doesn't have to be partitions. I'm offering a bounty for this now because responses have been extremely scant and it would be really helpful to find a good source. EDIT 2: I should emphasise that this is a project for my final year of an undergraduate degree. Also, I've found a potentially useful source in the textbook Complex Analysis by Eberhard Freitag and Rolf Busam. Chapter 8 is all about additive number theory. But I'll leave the question open in case there are more sources out there.","I hope this is enough about maths to ask here. As part of my degree I need to do a project consisting of a 7,000-word report on some area of maths (quite a general guideline). I've noticed in studying complex analysis that quite frequently, studying a function's residues winds up giving you an expression for an infinite sum or a generating function for some partition. For instance, there's a well-documented example of using elliptic functions to prove Jacobi's Triple Product. I also know a little bit about partitions, having read the book Integer Partitions by Andrews and Eriksson and done a previous report summarising a large part of it. So I'd like this project to combine the two areas, and I know -- mostly from casual references -- that it's generally agreed that complex analysis and additive number theory are 'closely related'. The two subjects also seem well-adapted for combining because doing the working out in complex analysis is elegant, but the final answer might not be very exciting, while it's the other way round in number theory, where the working out can be very painful but the final answer pretty neat. Can you recommend any online source that explores connections between complex analysis and partition theory? If there's an especially good textbook, that would be welcome too. I've noticed Complex Analysis in Number Theory by Anatoly A. Karatsuba, but it doesn't seem like the right fit based on the Amazon description. EDIT: And if there's a source that links general number theory results with complex analysis, that's cool too. It doesn't have to be partitions. I'm offering a bounty for this now because responses have been extremely scant and it would be really helpful to find a good source. EDIT 2: I should emphasise that this is a project for my final year of an undergraduate degree. Also, I've found a potentially useful source in the textbook Complex Analysis by Eberhard Freitag and Rolf Busam. Chapter 8 is all about additive number theory. But I'll leave the question open in case there are more sources out there.",,"['complex-analysis', 'number-theory', 'soft-question', 'integer-partitions']"
68,How to compute the following integral in complex analysis?,How to compute the following integral in complex analysis?,,"Let $C$ denote the unit circle centered at origin in $\mathbb{C}$. Then $$\frac{1}{2\pi i}\int_C|1+z+z^2|\,dz$$  where the integral is taken anti-clockwise in along $C$, equals what? Well I start with putting $z = e^{i \theta}$, $0 \leq \theta \leq 2\pi$. Then $$\frac{1}{2\pi i}\int_C|1+z+z^2|\,dz = \frac{1}{2\pi i} \int_{0}^{2\pi} \sqrt{3+2\cos(\theta)}\,  e^{i \theta} \,i\, d \theta$$ Am I going in the right manner? How do I proceed further?","Let $C$ denote the unit circle centered at origin in $\mathbb{C}$. Then $$\frac{1}{2\pi i}\int_C|1+z+z^2|\,dz$$  where the integral is taken anti-clockwise in along $C$, equals what? Well I start with putting $z = e^{i \theta}$, $0 \leq \theta \leq 2\pi$. Then $$\frac{1}{2\pi i}\int_C|1+z+z^2|\,dz = \frac{1}{2\pi i} \int_{0}^{2\pi} \sqrt{3+2\cos(\theta)}\,  e^{i \theta} \,i\, d \theta$$ Am I going in the right manner? How do I proceed further?",,"['complex-analysis', 'contour-integration']"
69,Holomorphic functions and Wirtinger operators,Holomorphic functions and Wirtinger operators,,"Why do so many textbooks define holomorphic functions $f: \mathbb{C}^n \to \mathbb{C}$ as $\mathbb{R}$-differentiable functions satisfying $$\frac{\partial f}{\partial \overline{z_i}}=0 $$ where we use Wirtinger operators $$\frac{\partial}{\partial z_i} := \frac{1}{2} (\frac{\partial}{\partial x_i} - i \frac{\partial}{\partial y_i}) \ \ \text{and} \ \ \frac{\partial}{\partial \overline{z_i}} := \frac{1}{2} (\frac{\partial}{\partial x_i} + i \frac{\partial}{\partial y_i}) \ ?$$ To me defining $\frac{\partial}{\partial z_i}$ in this manner looks very artificial. A much better approach seems to be using the usual definition of differentiability of maps between affine spaces over $\mathbb{C}$, that is requiring $$f(z-z_0)=L_{z_0} \cdot (z-z_0) + o( \| z - z_0 \|)$$hold for all $z_0$ in the domain we are interested in and where $L_{z_0}: \mathbb{C}^n \to \mathbb{C}$ is complex linear. Then we have the usual Jacobi matrix where $\frac{\partial f}{\partial z_i}$ has its usual meaning as $$\frac{\partial f}{\partial z_i} |_{z_0} = \lim_{h \to 0} \frac{f(z_0 + h\cdot \vec{e_i}) - f(z_0)}{h}, \ \ h \in \mathbb{C}.$$ Then we of course observe that if $f$ is $\mathbb{C}$-differentiable then it is also $\mathbb{R}$-differentiable and we just have the equality: $$\frac{\partial f}{\partial z_i} =  \frac{1}{2} (\frac{\partial f}{\partial x_i} - i \frac{\partial f}{\partial y_i}).$$ This way both sides of the equation have their natural meaning and we are not defining the LHS via the RHS. An advantage of this approach is that we no longer have to perform ad hoc checks of chain rules for Wirtinger operators and the composition of holomorphic functions being again holomorphic becomes a triviality. As another advantage it seems that if one is not interested in Hodge theory and one just wants to define holomorphic tangent bundle and holomorphic bundle of one-forms for a complex manifold there is no longer need to go through the yoga of defining $(1,0)$ and $(0,1)$ splittings and one can proceed in the usual differential-geometric way, defining the holomorphic tangent sheaf as the sheaf of $\mathbb{C}$ derivations of the structure sheaf with the local holonomic basis consisting of $\{ \frac{\partial}{\partial z_i} \}$. To sum it up, is that just a historical way to deal with holomorphic functions as real ones and use Wirtinger operators or is there some important point I am missing here? One possible explanation I can think of is that for a complex manifold those $(p,q)$ decompositions (or more generally the interplay between real and holomorphic) are so much more interesting that people care much less about proper holomorphic objects and hence don't bother laying out a streamlined analytic exposition of them.","Why do so many textbooks define holomorphic functions $f: \mathbb{C}^n \to \mathbb{C}$ as $\mathbb{R}$-differentiable functions satisfying $$\frac{\partial f}{\partial \overline{z_i}}=0 $$ where we use Wirtinger operators $$\frac{\partial}{\partial z_i} := \frac{1}{2} (\frac{\partial}{\partial x_i} - i \frac{\partial}{\partial y_i}) \ \ \text{and} \ \ \frac{\partial}{\partial \overline{z_i}} := \frac{1}{2} (\frac{\partial}{\partial x_i} + i \frac{\partial}{\partial y_i}) \ ?$$ To me defining $\frac{\partial}{\partial z_i}$ in this manner looks very artificial. A much better approach seems to be using the usual definition of differentiability of maps between affine spaces over $\mathbb{C}$, that is requiring $$f(z-z_0)=L_{z_0} \cdot (z-z_0) + o( \| z - z_0 \|)$$hold for all $z_0$ in the domain we are interested in and where $L_{z_0}: \mathbb{C}^n \to \mathbb{C}$ is complex linear. Then we have the usual Jacobi matrix where $\frac{\partial f}{\partial z_i}$ has its usual meaning as $$\frac{\partial f}{\partial z_i} |_{z_0} = \lim_{h \to 0} \frac{f(z_0 + h\cdot \vec{e_i}) - f(z_0)}{h}, \ \ h \in \mathbb{C}.$$ Then we of course observe that if $f$ is $\mathbb{C}$-differentiable then it is also $\mathbb{R}$-differentiable and we just have the equality: $$\frac{\partial f}{\partial z_i} =  \frac{1}{2} (\frac{\partial f}{\partial x_i} - i \frac{\partial f}{\partial y_i}).$$ This way both sides of the equation have their natural meaning and we are not defining the LHS via the RHS. An advantage of this approach is that we no longer have to perform ad hoc checks of chain rules for Wirtinger operators and the composition of holomorphic functions being again holomorphic becomes a triviality. As another advantage it seems that if one is not interested in Hodge theory and one just wants to define holomorphic tangent bundle and holomorphic bundle of one-forms for a complex manifold there is no longer need to go through the yoga of defining $(1,0)$ and $(0,1)$ splittings and one can proceed in the usual differential-geometric way, defining the holomorphic tangent sheaf as the sheaf of $\mathbb{C}$ derivations of the structure sheaf with the local holonomic basis consisting of $\{ \frac{\partial}{\partial z_i} \}$. To sum it up, is that just a historical way to deal with holomorphic functions as real ones and use Wirtinger operators or is there some important point I am missing here? One possible explanation I can think of is that for a complex manifold those $(p,q)$ decompositions (or more generally the interplay between real and holomorphic) are so much more interesting that people care much less about proper holomorphic objects and hence don't bother laying out a streamlined analytic exposition of them.",,"['complex-analysis', 'complex-geometry', 'several-complex-variables']"
70,Showing Green's function on a Riemann surface can be pulled back,Showing Green's function on a Riemann surface can be pulled back,,"I want to prove the following: Let $R,S$ be two Riemann surfaces, and suppose Green's function $g_S$ exists for $S$. Let $f: R \to S$ be a nonconstant analytic function. Prove that Green's function $g_R$ exists for $R$, and $g_R(p,q) \leq g_S(f(p),f(q))$ for all $p,q \in R$. This is an exercise in Gamelin's book, XVI.3.2. The exercise does not forbid $f$ being constant, but it seems evidently necessary. Some thoughts Let $(U, z)$ be a coordinate patch of $R$ containing $q$ with $z(q) = 0$, let $v$ be a subharmonic function in $R \setminus\{q\}$ with compact support such that $$\limsup_{x \to q} v(x)+\log |z(x)|< \infty,$$ then by definition $g_R(\cdot,q)$ is the supremum of all such $v$, so it is enough to prove that $v(p) \leq g_S(f(p), f(q))$. Letting $(V,w)$ be a coordinate chart around $f(q)$ in $S$ with $w(f(q)) = 0$, we know that  $$\lim \limits_{x \to q} g_S(f(x),f(q))+\log |w(f(x))|$$  exists, as the function is even harmonic there. Subtracting, we get that  $$\limsup \limits_{x \to q} \;v(x)- g_S(f(x),f(q))+\log \lvert \frac{z(x)}{w(f(x))}\rvert < \infty.$$ If $w \circ f$ is a coordinate function, which is not always true, then  $\limsup _{x \to q} \;v(x)- g_S(f(x),f(q)) < \infty$ so for every $\epsilon>0$, the function $\varphi_\epsilon(x) := v(x)- (1+\epsilon)g_S(f(x),f(q))$ extends to be subharmonic at all $R$. It is $\leq 0$ off a compact set, the support of $v$, so the maximum principle forces $\varphi_\epsilon \leq 0$. Letting $\epsilon \to 0$ we are done. This question is a slightly more quantitative version of the fact, of which I do not know a proof, that an analytic map from a parabolic Riemann surface to a hyperbolic Riemann surface is constant. The main tool in proofs on this topic seems to be the maximum principle; how can it be leveraged here without adding an assumption on $f$?","I want to prove the following: Let $R,S$ be two Riemann surfaces, and suppose Green's function $g_S$ exists for $S$. Let $f: R \to S$ be a nonconstant analytic function. Prove that Green's function $g_R$ exists for $R$, and $g_R(p,q) \leq g_S(f(p),f(q))$ for all $p,q \in R$. This is an exercise in Gamelin's book, XVI.3.2. The exercise does not forbid $f$ being constant, but it seems evidently necessary. Some thoughts Let $(U, z)$ be a coordinate patch of $R$ containing $q$ with $z(q) = 0$, let $v$ be a subharmonic function in $R \setminus\{q\}$ with compact support such that $$\limsup_{x \to q} v(x)+\log |z(x)|< \infty,$$ then by definition $g_R(\cdot,q)$ is the supremum of all such $v$, so it is enough to prove that $v(p) \leq g_S(f(p), f(q))$. Letting $(V,w)$ be a coordinate chart around $f(q)$ in $S$ with $w(f(q)) = 0$, we know that  $$\lim \limits_{x \to q} g_S(f(x),f(q))+\log |w(f(x))|$$  exists, as the function is even harmonic there. Subtracting, we get that  $$\limsup \limits_{x \to q} \;v(x)- g_S(f(x),f(q))+\log \lvert \frac{z(x)}{w(f(x))}\rvert < \infty.$$ If $w \circ f$ is a coordinate function, which is not always true, then  $\limsup _{x \to q} \;v(x)- g_S(f(x),f(q)) < \infty$ so for every $\epsilon>0$, the function $\varphi_\epsilon(x) := v(x)- (1+\epsilon)g_S(f(x),f(q))$ extends to be subharmonic at all $R$. It is $\leq 0$ off a compact set, the support of $v$, so the maximum principle forces $\varphi_\epsilon \leq 0$. Letting $\epsilon \to 0$ we are done. This question is a slightly more quantitative version of the fact, of which I do not know a proof, that an analytic map from a parabolic Riemann surface to a hyperbolic Riemann surface is constant. The main tool in proofs on this topic seems to be the maximum principle; how can it be leveraged here without adding an assumption on $f$?",,"['complex-analysis', 'analysis', 'riemann-surfaces', 'maximum-principle', 'greens-function']"
71,find all the entire functions that satisfy $|f(z)| \le C^{Im(z)}$,find all the entire functions that satisfy,|f(z)| \le C^{Im(z)},"Find all the entire functions that satisfy :  $$|f(z)| \le C^{Im(z)}$$  for a positive $C$ My solution: I said that if $f(z)$ is entire, then also $e^{-if}$ is entire, and also:  $h(z)=\frac{f}{e^{-if}}$ is entire. ($|e^{-if}|>0$) then:  $$|h(z)|=\frac{|f|}{|e^{-if}|}=\frac{|f|}{e^{Im(z)}}<c$$ so according to Liouville h(z) is bounded and entire. so its constant. if I take the derivative of $h(z)$: $$h'(z)=\frac{f'e^{-if}+ie^{-if}f}{(e^{-if})^2}=0$$ and from here we get that $f'(z)=0$ and $f(z)=0$. any comments?","Find all the entire functions that satisfy :  $$|f(z)| \le C^{Im(z)}$$  for a positive $C$ My solution: I said that if $f(z)$ is entire, then also $e^{-if}$ is entire, and also:  $h(z)=\frac{f}{e^{-if}}$ is entire. ($|e^{-if}|>0$) then:  $$|h(z)|=\frac{|f|}{|e^{-if}|}=\frac{|f|}{e^{Im(z)}}<c$$ so according to Liouville h(z) is bounded and entire. so its constant. if I take the derivative of $h(z)$: $$h'(z)=\frac{f'e^{-if}+ie^{-if}f}{(e^{-if})^2}=0$$ and from here we get that $f'(z)=0$ and $f(z)=0$. any comments?",,['complex-analysis']
72,Laplace and Fourier transform,Laplace and Fourier transform,,"I have a doubt about the equivalence between Fourier Transform and Laplace Transform. It was told me that if I have a function such that: $f(t)=0$ if t<0 $f\in L^1(R) \bigcap L^2(R)$ I can define $F[f(t)]=\int_{0}^{\infty}f(t) e^{-j\omega t}dt$ $L[f(t)]=\int_{0}^{\infty}f(t) e^{-s t}dt$ I can look at the Fourier transform as the Laplace Transform evaluated in $s=j\omega$ IF AND ONLY if the abscisse of convergence is strictly less than zero. (I.e. if the region of convergence includes the imaginary axis. If the abscisse of congence is $\gamma=0$, then (it was told me), I can have poles on the real axes, and I have to define the Fourier transform with indentations in a proper manner. In the Papoulis's book there is written ""if $\gamma=0, $ the Laplace transform has at least one of the singular points on the imaginary axes. So, I think that the situation should be like this: Then, if I extend the frequency in the complex plane, I can consider that -regarding the Fourier transform- the axes are rotated with respect to the axis of the s-plane: So I should have: Finally, I think that these two last steps could explain the word ""real"" related to the poles at the beginning of the question... Please, tell me If the reasoning is wrong and where.. many thanks","I have a doubt about the equivalence between Fourier Transform and Laplace Transform. It was told me that if I have a function such that: $f(t)=0$ if t<0 $f\in L^1(R) \bigcap L^2(R)$ I can define $F[f(t)]=\int_{0}^{\infty}f(t) e^{-j\omega t}dt$ $L[f(t)]=\int_{0}^{\infty}f(t) e^{-s t}dt$ I can look at the Fourier transform as the Laplace Transform evaluated in $s=j\omega$ IF AND ONLY if the abscisse of convergence is strictly less than zero. (I.e. if the region of convergence includes the imaginary axis. If the abscisse of congence is $\gamma=0$, then (it was told me), I can have poles on the real axes, and I have to define the Fourier transform with indentations in a proper manner. In the Papoulis's book there is written ""if $\gamma=0, $ the Laplace transform has at least one of the singular points on the imaginary axes. So, I think that the situation should be like this: Then, if I extend the frequency in the complex plane, I can consider that -regarding the Fourier transform- the axes are rotated with respect to the axis of the s-plane: So I should have: Finally, I think that these two last steps could explain the word ""real"" related to the poles at the beginning of the question... Please, tell me If the reasoning is wrong and where.. many thanks",,"['complex-analysis', 'laplace-transform', 'fourier-transform']"
73,Real part of elliptic integral,Real part of elliptic integral,,"Suppose complete elliptic integral of the first kind: $$ \tag 1 K(k) \equiv \int_{0}^{\frac{\pi}{2}}\frac{\mathrm{d}y}{\sqrt{1-k^2\sin^{2}(x)}}. $$ I need to evaluate its real part on interval $0 < k < \infty$. Since $K(k)$ has discontinuity at $k = 1$ and acquires imaginary part, we need to use analytical continuation: $$ \tag 2 K(k) = \frac{1}{k}\left(K\left(\frac{1}{k}\right) \pm i K\left( \sqrt{1-\frac{1}{k^{2}}}\right)\right). $$ The great surprise for me is that by using the relation $$ K(x) = \frac{1}{1+x}K\left(\frac{2\sqrt{x}}{x+1}\right) $$ for $K(k)$ on the interval $0<k<1$ and for $\dfrac{1}{k}K\left(\dfrac{1}{k}\right)$ on the interval $1<k<\infty$, we find that expressions for $\mathrm{Re}K(k), 0 < k<1$ and $\mathrm{Re}K(k), 1 < k < \infty$ coincide: $$ \mathrm{Re}K(k) = \frac{1}{k+1}K\left(\frac{2\sqrt{k}}{k+1}\right). \quad 0 < k < \infty $$ Why this is true? I didn't expect this because of singularity of $K(k)$ at $k = 1$... For example, imaginary part in the region $0 < k < 1$ is zero, while in the region $1 < z < \infty$ it is non-zero with non-trivial functional dependence, making a jump at $z = 1$. Is this somehow related to general properties of analytical continuation (which in our particular case is given by (2))?","Suppose complete elliptic integral of the first kind: $$ \tag 1 K(k) \equiv \int_{0}^{\frac{\pi}{2}}\frac{\mathrm{d}y}{\sqrt{1-k^2\sin^{2}(x)}}. $$ I need to evaluate its real part on interval $0 < k < \infty$. Since $K(k)$ has discontinuity at $k = 1$ and acquires imaginary part, we need to use analytical continuation: $$ \tag 2 K(k) = \frac{1}{k}\left(K\left(\frac{1}{k}\right) \pm i K\left( \sqrt{1-\frac{1}{k^{2}}}\right)\right). $$ The great surprise for me is that by using the relation $$ K(x) = \frac{1}{1+x}K\left(\frac{2\sqrt{x}}{x+1}\right) $$ for $K(k)$ on the interval $0<k<1$ and for $\dfrac{1}{k}K\left(\dfrac{1}{k}\right)$ on the interval $1<k<\infty$, we find that expressions for $\mathrm{Re}K(k), 0 < k<1$ and $\mathrm{Re}K(k), 1 < k < \infty$ coincide: $$ \mathrm{Re}K(k) = \frac{1}{k+1}K\left(\frac{2\sqrt{k}}{k+1}\right). \quad 0 < k < \infty $$ Why this is true? I didn't expect this because of singularity of $K(k)$ at $k = 1$... For example, imaginary part in the region $0 < k < 1$ is zero, while in the region $1 < z < \infty$ it is non-zero with non-trivial functional dependence, making a jump at $z = 1$. Is this somehow related to general properties of analytical continuation (which in our particular case is given by (2))?",,"['complex-analysis', 'special-functions', 'elliptic-integrals']"
74,"Prove that all roots of $z\tan z = k$ lie in $\Bbb R$, where $k$ is a positive, non-zero real number.","Prove that all roots of  lie in , where  is a positive, non-zero real number.",z\tan z = k \Bbb R k,"The question is that given in the title; Prove that all roots of the equation $z\tan z = k$ lie in $\Bbb R$, where $k$ is a positive non-zero real number. I attempted a somewhat ""brute force"" approach by simply letting $z = a + bi$, with $a, b \in \Bbb R$. Under this assumption, if $a = 0$ (that is, $z$ is purely imaginary), we come to the conclusion that $k$ must be of the form $$-b\tanh b = k.$$ If $b > 0$ then $\tanh b \in (0,1]$ and so $-b\tanh b < 0$. If $b < 0$ then $\tanh b \in [-1, 0)$ since $\tanh$ is odd, and so again, $-b\tanh b < 0$, and so for $k \in \Bbb R_{>0}$, we cannot have purely imaginary $z$. Consider then the case that $z = a + bi$ where $a, b \neq 0$. Then after some manipulation, we end up with $$z\tan z = \frac{\tan a + i\tanh b}{1 - i\tan a \tanh b}.$$ Since both $\tan$ and $\tanh$, with domain restricted to $\Bbb R$, also have codomain $\Bbb R$, this ratio must be complex, since $\tanh b = 0$ iff $b = 0$, which we excluded under assumption, and so $k$ is complex if $z$ is complex. The only remaining possibility is that $z \in \Bbb R$, the result has been proven. I think this is somewhat hand-wavy at best; can anyone give me a more satisfactory/elegant proof of this result?","The question is that given in the title; Prove that all roots of the equation $z\tan z = k$ lie in $\Bbb R$, where $k$ is a positive non-zero real number. I attempted a somewhat ""brute force"" approach by simply letting $z = a + bi$, with $a, b \in \Bbb R$. Under this assumption, if $a = 0$ (that is, $z$ is purely imaginary), we come to the conclusion that $k$ must be of the form $$-b\tanh b = k.$$ If $b > 0$ then $\tanh b \in (0,1]$ and so $-b\tanh b < 0$. If $b < 0$ then $\tanh b \in [-1, 0)$ since $\tanh$ is odd, and so again, $-b\tanh b < 0$, and so for $k \in \Bbb R_{>0}$, we cannot have purely imaginary $z$. Consider then the case that $z = a + bi$ where $a, b \neq 0$. Then after some manipulation, we end up with $$z\tan z = \frac{\tan a + i\tanh b}{1 - i\tan a \tanh b}.$$ Since both $\tan$ and $\tanh$, with domain restricted to $\Bbb R$, also have codomain $\Bbb R$, this ratio must be complex, since $\tanh b = 0$ iff $b = 0$, which we excluded under assumption, and so $k$ is complex if $z$ is complex. The only remaining possibility is that $z \in \Bbb R$, the result has been proven. I think this is somewhat hand-wavy at best; can anyone give me a more satisfactory/elegant proof of this result?",,"['complex-analysis', 'trigonometry']"
75,Motivating the Cross-Ratio and 'the ratio of ratio's' in $\mathbb{R}\mathbb{P}^2$,Motivating the Cross-Ratio and 'the ratio of ratio's' in,\mathbb{R}\mathbb{P}^2,"Trying to come across the idea of the cross ratio naturally by thinking about the projective plane $\mathbb{R} \mathbb{P}^2$, using ideas from Brannan's Geometry book: given 4 collinear points $A,B,C,D$ we note ( for the vectors respresenting these points ) that $$C = aA + bB$$  $$D = cA + dB$$ so that the cross ratio is defined as $(b/a)/(d/c)$. Why is this obvious, and why is it obvious it should be a projective invariant without big calculations? My guess is that you take $$C = aA + bB = a[A + (b/a)B] \sim A + (b/a)B$$  and  $$D \sim A + (d/c)B$$ so that, for some reason, we want to define the discrepancy between these terms, i.e. we want to find the $\lambda$ that would turn $(b/a)$ into $(d/c)$: $$(b/a) = \lambda (d/c)$$ so that $$\lambda = (b/a)/(d/c)$$ tells us that, given two generators of a line ($A$ and $B$) we have a third point specified by the ratio $b/a$ and a fourth point specified by the ratio $d/c$ but because we just consider the factor that turns, for our given starting generators, a third point into a fourth point we expect it to be preserved when we project between lines: This is the best I can do to make the statement that the ratio of ratio's (Stillwell's 4 Pillar's book) is preserved under projections, because it seems to be saying you use this term to turn a third point into a fourth point given two staring points. Still not 100% clear on why it should also make sense when you start taking projections from points in perspective :\ Any thoughts? Any pictures to make it nicer? Any ideas on making the ratio of ratio's , along with the cross-ratio, more obvious? There are some great answers on here, such as https://math.stackexchange.com/a/1023055/82615 or https://math.stackexchange.com/a/627396/82615 but I have not come away with a child-like grasp of this yet, lets hope it can be achieved!","Trying to come across the idea of the cross ratio naturally by thinking about the projective plane $\mathbb{R} \mathbb{P}^2$, using ideas from Brannan's Geometry book: given 4 collinear points $A,B,C,D$ we note ( for the vectors respresenting these points ) that $$C = aA + bB$$  $$D = cA + dB$$ so that the cross ratio is defined as $(b/a)/(d/c)$. Why is this obvious, and why is it obvious it should be a projective invariant without big calculations? My guess is that you take $$C = aA + bB = a[A + (b/a)B] \sim A + (b/a)B$$  and  $$D \sim A + (d/c)B$$ so that, for some reason, we want to define the discrepancy between these terms, i.e. we want to find the $\lambda$ that would turn $(b/a)$ into $(d/c)$: $$(b/a) = \lambda (d/c)$$ so that $$\lambda = (b/a)/(d/c)$$ tells us that, given two generators of a line ($A$ and $B$) we have a third point specified by the ratio $b/a$ and a fourth point specified by the ratio $d/c$ but because we just consider the factor that turns, for our given starting generators, a third point into a fourth point we expect it to be preserved when we project between lines: This is the best I can do to make the statement that the ratio of ratio's (Stillwell's 4 Pillar's book) is preserved under projections, because it seems to be saying you use this term to turn a third point into a fourth point given two staring points. Still not 100% clear on why it should also make sense when you start taking projections from points in perspective :\ Any thoughts? Any pictures to make it nicer? Any ideas on making the ratio of ratio's , along with the cross-ratio, more obvious? There are some great answers on here, such as https://math.stackexchange.com/a/1023055/82615 or https://math.stackexchange.com/a/627396/82615 but I have not come away with a child-like grasp of this yet, lets hope it can be achieved!",,"['complex-analysis', 'projective-geometry', 'conformal-geometry']"
76,Riemann surface of $f(z)=((z-1)(z-2)(z-3))^{2/3}$,Riemann surface of,f(z)=((z-1)(z-2)(z-3))^{2/3},"I try to describe the Riemann surface of $f(z)=((z-1)(z-2)(z-3))^{2/3}$. I found the branch points 1,2, and 3 also realized $\infty$ is not a branch point. Since we take third root, I see three sheet. I am not sure but the line segment $[1,3]$ is my candidate for branch cut. Because in this case i prevent to go around the points 1,2,3. My questions are the followings: What is the appropriate branch cuts in this question? Is its Riemann surface homeomorphic to any well-known surface? Do different branch cuts give rise to same Riemann surface as a topological space? Are branch points among zeroes and poles Also I would be grateful if you could recommend some references about these questions. Thanks","I try to describe the Riemann surface of $f(z)=((z-1)(z-2)(z-3))^{2/3}$. I found the branch points 1,2, and 3 also realized $\infty$ is not a branch point. Since we take third root, I see three sheet. I am not sure but the line segment $[1,3]$ is my candidate for branch cut. Because in this case i prevent to go around the points 1,2,3. My questions are the followings: What is the appropriate branch cuts in this question? Is its Riemann surface homeomorphic to any well-known surface? Do different branch cuts give rise to same Riemann surface as a topological space? Are branch points among zeroes and poles Also I would be grateful if you could recommend some references about these questions. Thanks",,"['complex-analysis', 'riemann-surfaces']"
77,Riemann surface for square root function,Riemann surface for square root function,,"Here , if we take a point $w$ with $w\ne 0$ from where blue colored part of sheet intersects with red one, i.e., from the intersecting 'line', is $f(w)$ unique? I think $f(w)$ takes two different values, $\sqrt w$ and  $-\sqrt w$, but then how is $f$ a function if $f(w)$ can take multiple values?","Here , if we take a point $w$ with $w\ne 0$ from where blue colored part of sheet intersects with red one, i.e., from the intersecting 'line', is $f(w)$ unique? I think $f(w)$ takes two different values, $\sqrt w$ and  $-\sqrt w$, but then how is $f$ a function if $f(w)$ can take multiple values?",,"['complex-analysis', 'riemann-surfaces']"
78,$2^z$ behavior when changing real and imaginary components of $z$,behavior when changing real and imaginary components of,2^z z,"I'm reading The Music of the Primes by du Sautoy and I've come across a section that I'm having difficulty understanding: Euler fed imaginary numbers into the function $2^x$. To his surprise, out came waves which corresponded to a particular musical note. Euler showed that the character of each note depended on the coordinates of the corresponding imaginary number.  The farther north one is, the higher the pitch. The farther east, the louder the volume. My understanding here is that the results are dependent on the sine function and that the real part of the exponent affects the amplitude and the imaginary part of the exponent affects the frequency. I'd like to understand this more intuitively, which I tend to get through visualization.  So I went to Wolfram Alpha and started with graphing $2^{x+iy}$.  That wasn't very helpful. So I tried graphing it with fixed $x$ values , and indeed, I could see the amplitude of the (now 2D) graph changing . I also see that $2^{x+iy}$ is also expressed as $2^x \cos(y \log(2))+i 2^x \sin(y \log(2))$ and I think I can see that changing the value of $x$ would affect the amplitude. I'm unable to demonstrate the frequency changing by setting y to specific values. What am I missing? (...Other than a semester in a Complex Analysis class!) edit: So while reading more online, I came across this blog that makes a similar claim.  I suspect the book of oversimplifying, but wonder if this explains what was simplified? [...] But $x^{z-1} + x^{\bar{z} - 1}$ is just a wave whose amplitude depends on the real part of $z$ and whose frequency depends on the imaginary part (i.e., if $z=a+biz=a+bi$, then $x^{z-1} + x^{\bar{z}-1} = 2x^{a-1} cos (b \log x)$) [...] (I copied this from the blog, but removed some odd \'s ...) Is it the inclusion of the conjugates that causes this amplitude/frequency?","I'm reading The Music of the Primes by du Sautoy and I've come across a section that I'm having difficulty understanding: Euler fed imaginary numbers into the function $2^x$. To his surprise, out came waves which corresponded to a particular musical note. Euler showed that the character of each note depended on the coordinates of the corresponding imaginary number.  The farther north one is, the higher the pitch. The farther east, the louder the volume. My understanding here is that the results are dependent on the sine function and that the real part of the exponent affects the amplitude and the imaginary part of the exponent affects the frequency. I'd like to understand this more intuitively, which I tend to get through visualization.  So I went to Wolfram Alpha and started with graphing $2^{x+iy}$.  That wasn't very helpful. So I tried graphing it with fixed $x$ values , and indeed, I could see the amplitude of the (now 2D) graph changing . I also see that $2^{x+iy}$ is also expressed as $2^x \cos(y \log(2))+i 2^x \sin(y \log(2))$ and I think I can see that changing the value of $x$ would affect the amplitude. I'm unable to demonstrate the frequency changing by setting y to specific values. What am I missing? (...Other than a semester in a Complex Analysis class!) edit: So while reading more online, I came across this blog that makes a similar claim.  I suspect the book of oversimplifying, but wonder if this explains what was simplified? [...] But $x^{z-1} + x^{\bar{z} - 1}$ is just a wave whose amplitude depends on the real part of $z$ and whose frequency depends on the imaginary part (i.e., if $z=a+biz=a+bi$, then $x^{z-1} + x^{\bar{z}-1} = 2x^{a-1} cos (b \log x)$) [...] (I copied this from the blog, but removed some odd \'s ...) Is it the inclusion of the conjugates that causes this amplitude/frequency?",,"['complex-analysis', 'complex-numbers']"
79,Conformal mapping from square to disk as inverse of hypergeometric function,Conformal mapping from square to disk as inverse of hypergeometric function,,"I'd like to write a little program that transforms a fractal generated in the square $(-1,1)^2\subset\mathbb C$ conformally to the unit disk $|z|<1$ . I know that conformal mappings from the unit disk to polygons can be described by Schwarz-Christoffel-Transformations, and with the help of several articles I finally came up with the hypergeometric function $e^{\pi/4 i}z\; _2F_1(1/2,1/4,5/4,z^4)$ that maps - as said - the unit disk conformally to the square $(-1,1)^2$ . I used Mathematica to plot this function, and the result is perfectly fine. My question is now: What is the inverse of this function? There is a wikipedia article that gives a similar definition of the inverse in terms of Jacobi's Elliptic Function $cn$ , but this doesn't work with my plotting. I think I have to adjust this only a bit to get what I want, but I was not able to so far. Thx for your help in advance!","I'd like to write a little program that transforms a fractal generated in the square conformally to the unit disk . I know that conformal mappings from the unit disk to polygons can be described by Schwarz-Christoffel-Transformations, and with the help of several articles I finally came up with the hypergeometric function that maps - as said - the unit disk conformally to the square . I used Mathematica to plot this function, and the result is perfectly fine. My question is now: What is the inverse of this function? There is a wikipedia article that gives a similar definition of the inverse in terms of Jacobi's Elliptic Function , but this doesn't work with my plotting. I think I have to adjust this only a bit to get what I want, but I was not able to so far. Thx for your help in advance!","(-1,1)^2\subset\mathbb C |z|<1 e^{\pi/4 i}z\; _2F_1(1/2,1/4,5/4,z^4) (-1,1)^2 cn","['complex-analysis', 'conformal-geometry']"
80,Possible analytic images of the unit disc?,Possible analytic images of the unit disc?,,"From Picard's theorem, the image of $\mathbb{C}$ under an analytic function has to the whole plane or $\mathbb{C}$ minus a single point. What about other open sets? This may be too broad, so how about the unit disc? Let $B$ be the open unit disc. If $f:B\to \mathbb{C}$ is analytic, what can we say about $f(B)$? We know that $f(B)$ has to be open. Can something further be said? For instance, $f(B)$ need not be simply connected (consider $exp(\alpha z)$ for a large enough $\alpha$).","From Picard's theorem, the image of $\mathbb{C}$ under an analytic function has to the whole plane or $\mathbb{C}$ minus a single point. What about other open sets? This may be too broad, so how about the unit disc? Let $B$ be the open unit disc. If $f:B\to \mathbb{C}$ is analytic, what can we say about $f(B)$? We know that $f(B)$ has to be open. Can something further be said? For instance, $f(B)$ need not be simply connected (consider $exp(\alpha z)$ for a large enough $\alpha$).",,[]
81,"Exist complex $z_{0}$ ,such $|z_{0}|=1$,and $|f(z_{0})|\le|f(z)|,\forall |z|\ge 1$","Exist complex  ,such ,and","z_{0} |z_{0}|=1 |f(z_{0})|\le|f(z)|,\forall |z|\ge 1","Let $a\in (0,1), f(z)=z^2-z+a, z\in \mathbb C$. Does there exist a complex number $z_{0}$ such that $|z_{0}|=1$, and  $$|f(z_{0})|\le|f(z)|,\forall |z|\ge 1$$ I just have no idea where to even begin so any hint will be much appreciated. I apologize for not showing any effort. Any help will be appreciated. Thanks Is there a method without using the Maximum Modulus Principle to solve this problem?","Let $a\in (0,1), f(z)=z^2-z+a, z\in \mathbb C$. Does there exist a complex number $z_{0}$ such that $|z_{0}|=1$, and  $$|f(z_{0})|\le|f(z)|,\forall |z|\ge 1$$ I just have no idea where to even begin so any hint will be much appreciated. I apologize for not showing any effort. Any help will be appreciated. Thanks Is there a method without using the Maximum Modulus Principle to solve this problem?",,['complex-analysis']
82,$n$th roots of entire functions,th roots of entire functions,n,"I am stuck on this complex analysis problem. Let $f$ be an entire function and $n$ a positive integer. Show that   there exists an entire function $g$ such that $f=g^n$ if and only if   the order of each zero of $f$ is divisible by $n$. I can see that locally around each $z_0$ we can write $f(z)=(z-z_0)^{nk}s(z)$ where $s(z)$ has no zeroes in a neighborhood of $z_0$ and so there exists a logarithm of $s(z)$, say $l(z)$, which means that $g(z)=(z-z_0)^ke^{l(z)/n}$ works, but I don't understand how to get an entire function from this. I know that it suffices to show that this construction gives functions that agree on the overlap of these neighborhoods, but I don't see why they would have to agree.","I am stuck on this complex analysis problem. Let $f$ be an entire function and $n$ a positive integer. Show that   there exists an entire function $g$ such that $f=g^n$ if and only if   the order of each zero of $f$ is divisible by $n$. I can see that locally around each $z_0$ we can write $f(z)=(z-z_0)^{nk}s(z)$ where $s(z)$ has no zeroes in a neighborhood of $z_0$ and so there exists a logarithm of $s(z)$, say $l(z)$, which means that $g(z)=(z-z_0)^ke^{l(z)/n}$ works, but I don't understand how to get an entire function from this. I know that it suffices to show that this construction gives functions that agree on the overlap of these neighborhoods, but I don't see why they would have to agree.",,[]
83,Show that $f$ is continuous at $0$ and it satisfies the Cauchy-Riemann conditions but it is not differentiable.,Show that  is continuous at  and it satisfies the Cauchy-Riemann conditions but it is not differentiable.,f 0,"Let $f:\Bbb{C}\to \Bbb{C}$ be defined as $$f(x+iy)= \frac{x^{3}-y^{3}+i(x^{3}+y^{3})}{x^2+y^2} \text{ if} x+iy \neq 0$$ and $f(x+iy)=0$ if $x+iy=0$ Show that $f$ is continuous at $0$ and it satisfies the Cauchy-Riemann conditions but it is not differentiable Ok, so I'm getting messed up when trying to check the continuity. Of course I have to check that $$\lim_{x+iy \to 0}f(x+iy) = 0$$ However, my doubt is the following: I am aware of a result (I have already proved) that says that $$\lim_{z\to z_0} f(z) = a + ib \text{ iff } \lim_{z\to z_0}\operatorname{Re}(f(z)) = a  \text{ and } \lim_{z\to z_0} \operatorname{Im}(f(z)) = b$$ However, with the use of this result (or not), I'm getting mixed up with the $x+iy \to 0$ . Does this imply taking $|x+iy|=x^2+y^2 < \epsilon$ for every $\epsilon >0$ ? And so, how can I proceed? Should I encounter this limit by definition or is there another way?","Let be defined as and if Show that is continuous at and it satisfies the Cauchy-Riemann conditions but it is not differentiable Ok, so I'm getting messed up when trying to check the continuity. Of course I have to check that However, my doubt is the following: I am aware of a result (I have already proved) that says that However, with the use of this result (or not), I'm getting mixed up with the . Does this imply taking for every ? And so, how can I proceed? Should I encounter this limit by definition or is there another way?",f:\Bbb{C}\to \Bbb{C} f(x+iy)= \frac{x^{3}-y^{3}+i(x^{3}+y^{3})}{x^2+y^2} \text{ if} x+iy \neq 0 f(x+iy)=0 x+iy=0 f 0 \lim_{x+iy \to 0}f(x+iy) = 0 \lim_{z\to z_0} f(z) = a + ib \text{ iff } \lim_{z\to z_0}\operatorname{Re}(f(z)) = a  \text{ and } \lim_{z\to z_0} \operatorname{Im}(f(z)) = b x+iy \to 0 |x+iy|=x^2+y^2 < \epsilon \epsilon >0,['complex-analysis']
84,"When proving that f(z) is a polynomial, is it enough to consider just one point instead of keeping z arbitrary?","When proving that f(z) is a polynomial, is it enough to consider just one point instead of keeping z arbitrary?",,"I think so - but I'd rather ask the MSE community too. Say I am given the bound |f(z)| < $|z|^3$, and that f is entire.  Show f must be a polynomial. I used Cauchy's Integral Formula for derivatives and showed that for n>3, all of the derivatives are zero, when we let the closed contour grow to infinity. But, I have only used CIF at the point z = 0 - I didn't keep z arbitrary. Then the CIF shows that, at z = 0, the Taylor series has only finitely many terms and so f(z) must be a polynomial. So I feel there's actually no need to apply the CIF to an arbitrary z. We have enough information on f(z) just from looking at z=0. Thanks,","I think so - but I'd rather ask the MSE community too. Say I am given the bound |f(z)| < $|z|^3$, and that f is entire.  Show f must be a polynomial. I used Cauchy's Integral Formula for derivatives and showed that for n>3, all of the derivatives are zero, when we let the closed contour grow to infinity. But, I have only used CIF at the point z = 0 - I didn't keep z arbitrary. Then the CIF shows that, at z = 0, the Taylor series has only finitely many terms and so f(z) must be a polynomial. So I feel there's actually no need to apply the CIF to an arbitrary z. We have enough information on f(z) just from looking at z=0. Thanks,",,"['complex-analysis', 'polynomials', 'laurent-series', 'taylor-expansion']"
85,Show that the integral of Riemann function is analytic,Show that the integral of Riemann function is analytic,,"I'm trying to resolve this problem. Let $\Omega$ be an open set no empty of $\mathbb C$, $[a,b]$ a compact interval of $\mathbb{R}$, further $f,\ g\colon[a,b] \to \mathbb C$ two integrable  Riemann functions. Suppose that $f(t) \notin \Omega$ for all $t \in [a,b]$. Show that the function $h\colon\Omega \to\mathbb C$ defined by  $$ h(z)=\int_a^b\frac{g(t)}{f(t)-z}\,dt $$  is analytic.  Determine the largest open connected space of $\mathbb C$ where the function  $$ I(z)=\int_0^1\frac{\sin t}{t^2-e^z}\,dt $$  is analytic. Can I have some indications please?","I'm trying to resolve this problem. Let $\Omega$ be an open set no empty of $\mathbb C$, $[a,b]$ a compact interval of $\mathbb{R}$, further $f,\ g\colon[a,b] \to \mathbb C$ two integrable  Riemann functions. Suppose that $f(t) \notin \Omega$ for all $t \in [a,b]$. Show that the function $h\colon\Omega \to\mathbb C$ defined by  $$ h(z)=\int_a^b\frac{g(t)}{f(t)-z}\,dt $$  is analytic.  Determine the largest open connected space of $\mathbb C$ where the function  $$ I(z)=\int_0^1\frac{\sin t}{t^2-e^z}\,dt $$  is analytic. Can I have some indications please?",,['complex-analysis']
86,"If $f:\mathbb{D}\to\mathbb{D}$ is analytic and $f(0)=\frac{1}{2}$, then $|f(\frac{1}{3})|\geq\frac{1}{5}$","If  is analytic and , then",f:\mathbb{D}\to\mathbb{D} f(0)=\frac{1}{2} |f(\frac{1}{3})|\geq\frac{1}{5},"I am studying for a complex analysis exam tomorrow, and I am trying my hand at this problem: Suppose $f$ is analytic in $\mathbb{D}$ and $|f(z)|\leq 1$ in $\mathbb{D}$ and $f(0) = 1/2$ . Prove that $|f(1/3)|\geq 1/5$ . Hint: use the invariant form of Schwarz's Lemma. As I understand it, the hint refers to the result that for any holomorphic $f:\mathbb{D}\to\mathbb{D}$ , we have $$\left|\frac{f(z_1)-f(z_2)}{1-\overline{f(z_1)}f(z_2)}\right|\leq\left|\frac{z_1-z_2}{1-\overline{z_1}z_2}\right|$$ for any $z_1,z_2\in\mathbb{D}$ . Taking $z_1=0$ and $z_2=\frac{1}{3}$ , this gets us $$\frac{|f(\frac{1}{3})-\frac{1}{2}|}{\;\left|1-\overline{f(\frac{1}{3})}\frac{1}{2}\right|\;}\leq\frac{1}{3}$$ but try as I might, I cannot manipulate this to produce the desired result. I'm worried I'm not understanding something correctly, and the exam is tomorrow, so any quick help would be much appreciated. P.S. I found this exercise here , where it is problem 5. Edit: Aha, I have an idea! We know that for any $a\in \mathbb{D}$ , the map $\phi_a:\mathbb{D}\to\mathbb{D}$ defined by $$\phi_a(z)=\dfrac{a-z}{1-\overline{a}z}$$ sends $\phi_a(0)=a$ and $\phi_a(a)=0$ . Observe that $$\phi_{\frac{1}{2}}(\tfrac{1}{3})=\frac{\frac{1}{2}-\frac{1}{3}}{1-\frac{1}{3}\cdot\frac{1}{2}}=\frac{\;\frac{1}{6}\;}{\frac{5}{6}}=\frac{1}{5}.$$ So if we can prove that any other map $f:\mathbb{D}\to\mathbb{D}$ with $f(0)=\frac{1}{2}$ is obtained from $\phi_a$ in a way that can only increase $|f(\frac{1}{3})|$ , then we are done. However , this would seem to be in the opposite direction from what I would expect: one of the consequences of Schwarz's lemma is that any holomorphic map from $\mathbb{D}$ to $\mathbb{D}$ is a contraction in the hyperbolic metric. So distances should be getting smaller.","I am studying for a complex analysis exam tomorrow, and I am trying my hand at this problem: Suppose is analytic in and in and . Prove that . Hint: use the invariant form of Schwarz's Lemma. As I understand it, the hint refers to the result that for any holomorphic , we have for any . Taking and , this gets us but try as I might, I cannot manipulate this to produce the desired result. I'm worried I'm not understanding something correctly, and the exam is tomorrow, so any quick help would be much appreciated. P.S. I found this exercise here , where it is problem 5. Edit: Aha, I have an idea! We know that for any , the map defined by sends and . Observe that So if we can prove that any other map with is obtained from in a way that can only increase , then we are done. However , this would seem to be in the opposite direction from what I would expect: one of the consequences of Schwarz's lemma is that any holomorphic map from to is a contraction in the hyperbolic metric. So distances should be getting smaller.","f \mathbb{D} |f(z)|\leq 1 \mathbb{D} f(0) = 1/2 |f(1/3)|\geq 1/5 f:\mathbb{D}\to\mathbb{D} \left|\frac{f(z_1)-f(z_2)}{1-\overline{f(z_1)}f(z_2)}\right|\leq\left|\frac{z_1-z_2}{1-\overline{z_1}z_2}\right| z_1,z_2\in\mathbb{D} z_1=0 z_2=\frac{1}{3} \frac{|f(\frac{1}{3})-\frac{1}{2}|}{\;\left|1-\overline{f(\frac{1}{3})}\frac{1}{2}\right|\;}\leq\frac{1}{3} a\in \mathbb{D} \phi_a:\mathbb{D}\to\mathbb{D} \phi_a(z)=\dfrac{a-z}{1-\overline{a}z} \phi_a(0)=a \phi_a(a)=0 \phi_{\frac{1}{2}}(\tfrac{1}{3})=\frac{\frac{1}{2}-\frac{1}{3}}{1-\frac{1}{3}\cdot\frac{1}{2}}=\frac{\;\frac{1}{6}\;}{\frac{5}{6}}=\frac{1}{5}. f:\mathbb{D}\to\mathbb{D} f(0)=\frac{1}{2} \phi_a |f(\frac{1}{3})| \mathbb{D} \mathbb{D}",['complex-analysis']
87,Extending a biholomorphic map between two Riemann surfaces,Extending a biholomorphic map between two Riemann surfaces,,"Consider the following problem: $X$ and $Y$ are two compact Riemann surfaces, $S$ is a finite   subset of $Y$ and $f:X\longrightarrow Y$ is a holomorphic map whose set of branch points is $S$. Now suppose that $$  f|_{X\setminus f^{-1}(S)}:X\setminus f^{-1}(S)\longrightarrow  Y\setminus S  $$    is biholomorphic. Does exist a biholomorphic map   $\overline f:X\longrightarrow Y$ that extends $f|_{X\setminus  f^{-1}(S)}$ in a unique way? The answer is yes and one way to see this is by passing to the category of smooth projective curves. In fact $X$ and $Y$ considered as smooth projective curves are birational, and so they must be isomorphic. I'd like a solution for the above problem without thinking to algebraic curves. I want to show the existence of $\overline f$ only with complex analysis tools; for example  I think that it is enough the Riemann removable singularities theorem. Any idea? Thanks in advance","Consider the following problem: $X$ and $Y$ are two compact Riemann surfaces, $S$ is a finite   subset of $Y$ and $f:X\longrightarrow Y$ is a holomorphic map whose set of branch points is $S$. Now suppose that $$  f|_{X\setminus f^{-1}(S)}:X\setminus f^{-1}(S)\longrightarrow  Y\setminus S  $$    is biholomorphic. Does exist a biholomorphic map   $\overline f:X\longrightarrow Y$ that extends $f|_{X\setminus  f^{-1}(S)}$ in a unique way? The answer is yes and one way to see this is by passing to the category of smooth projective curves. In fact $X$ and $Y$ considered as smooth projective curves are birational, and so they must be isomorphic. I'd like a solution for the above problem without thinking to algebraic curves. I want to show the existence of $\overline f$ only with complex analysis tools; for example  I think that it is enough the Riemann removable singularities theorem. Any idea? Thanks in advance",,"['complex-analysis', 'riemann-surfaces']"
88,Line contour integral of complex Gaussian,Line contour integral of complex Gaussian,,"Say I have the entire function $$f(z)=e^{-\frac{1}{2}z^2}.$$ I would like to consider the integral $$I=\int_\Gamma f(x)dz,$$ where $\Gamma$ is a line with negative slope $<1$ in $\mathbb{C}$ (so if you plot it, it look like $Im(z)=cRe(z)$, $-1<c<0$). Though solvers tell me that $I=\sqrt{2\pi}$ and I can intuitively see why this is true (continuously deform $\Gamma$ into the real line), how would I show this rigorously?","Say I have the entire function $$f(z)=e^{-\frac{1}{2}z^2}.$$ I would like to consider the integral $$I=\int_\Gamma f(x)dz,$$ where $\Gamma$ is a line with negative slope $<1$ in $\mathbb{C}$ (so if you plot it, it look like $Im(z)=cRe(z)$, $-1<c<0$). Though solvers tell me that $I=\sqrt{2\pi}$ and I can intuitively see why this is true (continuously deform $\Gamma$ into the real line), how would I show this rigorously?",,"['complex-analysis', 'contour-integration']"
89,"With hypotheses of Schwarz's lemma, estimate the radius around zero where $f$ must be one-to-one","With hypotheses of Schwarz's lemma, estimate the radius around zero where  must be one-to-one",f,"Suppose $f(z)$ is analytic in the open unit disc and $|f(z)|<1$ there.   Suppose further that $f(0) =0$ and $f'(0) = a \neq 0$. Show that there   is a disc of positive radius $|z|<\rho$ such that for $z_1$ and $z_2$   in the disc, $$f(z_1)=f(z_2) \Longrightarrow z_1=z_2.\tag{1}$$ Find an   estimate for $\rho$. Try to make the estimate as sharp as you can. Hint: $$f(z_2)-f(z_1) = \int_{z_1}^{z_2}f'(z)dz = a(z_2-z_1)+ \dotsb .$$ My answer so far: I can show (1) in a neighborhood of zero as follows: $z=0$ is an isolated zero of $f$ by the isolated zero theorem (note $f$ is non-constant since $f'(0)\neq 0$). Therefore there is a closed neighborhood $\overline{B_{\rho}(0)}$ of zero such that $f\neq 0$ on the punctured disc $\overline{B_{\rho}(0)} \setminus \{0\}$. Let $M = \max_{z\in \partial{B_{\rho}(0)}}|f(z)|$. Now for $w\in B_{M}(0)$, we have that $|f(z)-0|> |w-0|$ for $z\in \partial B_\rho(0)$, so $f(z)-0$ and $f(z)-0 + (w-0)=f(z)-w$ have the same number of zeros in $\overline{B_{\rho}(0)}$, meaning that $f$ is one-to-one there. For the estimate, I'm having more trouble. I know by Schwarz's theorem that $|f(z)|<|z|$ in the disc, and $a<1$, unless $f(z)=\lambda z$ for $\lambda \in S^1$, in which case both are equalities. But how can I use this? If I try to use the hint, I get (I think) $$f(z_2)-f(z_1) = a(z_2-z_1)+ \frac12 f''(0)(z_2^2 - z_1^2) + \dotsb$$ but I'm not sure what to do with this.","Suppose $f(z)$ is analytic in the open unit disc and $|f(z)|<1$ there.   Suppose further that $f(0) =0$ and $f'(0) = a \neq 0$. Show that there   is a disc of positive radius $|z|<\rho$ such that for $z_1$ and $z_2$   in the disc, $$f(z_1)=f(z_2) \Longrightarrow z_1=z_2.\tag{1}$$ Find an   estimate for $\rho$. Try to make the estimate as sharp as you can. Hint: $$f(z_2)-f(z_1) = \int_{z_1}^{z_2}f'(z)dz = a(z_2-z_1)+ \dotsb .$$ My answer so far: I can show (1) in a neighborhood of zero as follows: $z=0$ is an isolated zero of $f$ by the isolated zero theorem (note $f$ is non-constant since $f'(0)\neq 0$). Therefore there is a closed neighborhood $\overline{B_{\rho}(0)}$ of zero such that $f\neq 0$ on the punctured disc $\overline{B_{\rho}(0)} \setminus \{0\}$. Let $M = \max_{z\in \partial{B_{\rho}(0)}}|f(z)|$. Now for $w\in B_{M}(0)$, we have that $|f(z)-0|> |w-0|$ for $z\in \partial B_\rho(0)$, so $f(z)-0$ and $f(z)-0 + (w-0)=f(z)-w$ have the same number of zeros in $\overline{B_{\rho}(0)}$, meaning that $f$ is one-to-one there. For the estimate, I'm having more trouble. I know by Schwarz's theorem that $|f(z)|<|z|$ in the disc, and $a<1$, unless $f(z)=\lambda z$ for $\lambda \in S^1$, in which case both are equalities. But how can I use this? If I try to use the hint, I get (I think) $$f(z_2)-f(z_1) = a(z_2-z_1)+ \frac12 f''(0)(z_2^2 - z_1^2) + \dotsb$$ but I'm not sure what to do with this.",,['complex-analysis']
90,Contour Integration on a finite domain,Contour Integration on a finite domain,,Evaluate by contour integration $$\int_{0}^{1}\frac{dx}{(x^2-x^3)^\frac{1}{3}}$$ I am having trouble selecting the right contour for the problem as the usual problems involve selecting real axis from $-R$ to $+R$ and then closing with a semicircle of radius $R$. but that doesn't work here.,Evaluate by contour integration $$\int_{0}^{1}\frac{dx}{(x^2-x^3)^\frac{1}{3}}$$ I am having trouble selecting the right contour for the problem as the usual problems involve selecting real axis from $-R$ to $+R$ and then closing with a semicircle of radius $R$. but that doesn't work here.,,"['complex-analysis', 'contour-integration']"
91,"A Hankel Transform Integral: $\int_0^\infty\frac{1}{k^2-k_p^2}J_0\left(k\rho\right)\;k\,dk$",A Hankel Transform Integral:,"\int_0^\infty\frac{1}{k^2-k_p^2}J_0\left(k\rho\right)\;k\,dk","$$ \int_0^\infty\frac{1}{k^2-k_p^2}J_0\left(k\rho\right)\;k\,dk $$ Suppose that $k_p$ is in the first quadrant in the complex plane, and that $\rho$ is purely real.  $J_0$ is the Bessel function of the first kind and order zero. What is the right set of moves to calculate this integral?  What are the complex analysis arguments you have to use (closing contours around the two poles, residues, etc.; are these applications of the Cauchy integral formula, or the residue theorem)? Do you have extend the integral to the whole real line and replace the Bessel function with a Hankel function?  What's the final result?  Mathematica is happy to tell me the answer is a specific Hankel function, but I would like to know how these things work for THIS particular problem.","$$ \int_0^\infty\frac{1}{k^2-k_p^2}J_0\left(k\rho\right)\;k\,dk $$ Suppose that $k_p$ is in the first quadrant in the complex plane, and that $\rho$ is purely real.  $J_0$ is the Bessel function of the first kind and order zero. What is the right set of moves to calculate this integral?  What are the complex analysis arguments you have to use (closing contours around the two poles, residues, etc.; are these applications of the Cauchy integral formula, or the residue theorem)? Do you have extend the integral to the whole real line and replace the Bessel function with a Hankel function?  What's the final result?  Mathematica is happy to tell me the answer is a specific Hankel function, but I would like to know how these things work for THIS particular problem.",,"['complex-analysis', 'bessel-functions']"
92,Holomorphic function with constant absolute value [duplicate],Holomorphic function with constant absolute value [duplicate],,"This question already has answers here : Why: A holomorphic function with constant magnitude must be constant. (6 answers) Closed 10 years ago . Show that if a holomorphic function has a constant absolute value, it must be a constant. Suppose $f(z)=u(z)+iv(z)$ is holomorphic (where $z=x+iy$ is complex), and that $(u(z))^2+(v(z))^2=C$ for some constant $C$. We have $\dfrac{\partial((u(z))^2+(v(z))^2)}{\partial x}= 0$. Applying the chain rule, we find that $$u(z)\cdot\dfrac{\partial u(z)}{\partial x} + v(z)\cdot\dfrac{\partial v(z)}{\partial x} = 0$$ Similarly, $$u(z)\cdot\dfrac{\partial u(z)}{\partial y} + v(z)\cdot\dfrac{\partial v(z)}{\partial y} = 0$$ Using the Cauchy-Riemann differential equations satisfied by any holomorphic function: $$u(z)\cdot\left(-\dfrac{\partial v(z)}{\partial x}\right) + v(z)\cdot\dfrac{\partial u(z)}{\partial x} = 0$$ We can write as a matrix form: $$\begin{pmatrix} u(z) & v(z) \\ v(z) & -u(z)\end{pmatrix}\begin{pmatrix}\frac{\partial{u(z)}}{\partial{x}}\\\frac{\partial{v(z)}}{\partial{x}}\end{pmatrix} = 0$$ For values of $z$ such that the matrix $A=\begin{pmatrix} u(z) & v(z) \\ v(z) & -u(z)\end{pmatrix}$ is invertible, we get $\dfrac{\partial{u(z)}}{\partial{x}}=\dfrac{\partial{v(z)}}{\partial{x}}=0$. But what can we do for values of $z$ such that the matrix $A$ is not invertible?","This question already has answers here : Why: A holomorphic function with constant magnitude must be constant. (6 answers) Closed 10 years ago . Show that if a holomorphic function has a constant absolute value, it must be a constant. Suppose $f(z)=u(z)+iv(z)$ is holomorphic (where $z=x+iy$ is complex), and that $(u(z))^2+(v(z))^2=C$ for some constant $C$. We have $\dfrac{\partial((u(z))^2+(v(z))^2)}{\partial x}= 0$. Applying the chain rule, we find that $$u(z)\cdot\dfrac{\partial u(z)}{\partial x} + v(z)\cdot\dfrac{\partial v(z)}{\partial x} = 0$$ Similarly, $$u(z)\cdot\dfrac{\partial u(z)}{\partial y} + v(z)\cdot\dfrac{\partial v(z)}{\partial y} = 0$$ Using the Cauchy-Riemann differential equations satisfied by any holomorphic function: $$u(z)\cdot\left(-\dfrac{\partial v(z)}{\partial x}\right) + v(z)\cdot\dfrac{\partial u(z)}{\partial x} = 0$$ We can write as a matrix form: $$\begin{pmatrix} u(z) & v(z) \\ v(z) & -u(z)\end{pmatrix}\begin{pmatrix}\frac{\partial{u(z)}}{\partial{x}}\\\frac{\partial{v(z)}}{\partial{x}}\end{pmatrix} = 0$$ For values of $z$ such that the matrix $A=\begin{pmatrix} u(z) & v(z) \\ v(z) & -u(z)\end{pmatrix}$ is invertible, we get $\dfrac{\partial{u(z)}}{\partial{x}}=\dfrac{\partial{v(z)}}{\partial{x}}=0$. But what can we do for values of $z$ such that the matrix $A$ is not invertible?",,['complex-analysis']
93,Concrete example of an entire function wanted,Concrete example of an entire function wanted,,"Let $X$ be the space of entire functions on $\mathbb{C}$ endowed with the topology of uniform convergence on compact sets. Let $a$ be a nonzero complex number. Let $T: X\to X$ be defined by $T(f)(z)=f(z+a)$. By a result of Birkhoff (see Dynamics of Linear Operators, by F. Bayart and E. Matheron, p. 3), there exists an $f\in X$ such that $O(f,T)=\{T^nf: n=0,1,2,\cdots\}$ is dense in $X$. Does anyone know a concrete example of such $f$?","Let $X$ be the space of entire functions on $\mathbb{C}$ endowed with the topology of uniform convergence on compact sets. Let $a$ be a nonzero complex number. Let $T: X\to X$ be defined by $T(f)(z)=f(z+a)$. By a result of Birkhoff (see Dynamics of Linear Operators, by F. Bayart and E. Matheron, p. 3), there exists an $f\in X$ such that $O(f,T)=\{T^nf: n=0,1,2,\cdots\}$ is dense in $X$. Does anyone know a concrete example of such $f$?",,"['complex-analysis', 'complex-dynamics']"
94,Bergman-Shilov Boundary and Peak Points,Bergman-Shilov Boundary and Peak Points,,Let $\Omega$ be a domain in $\mathbb{C}^n.$ Consider the Banach algebra $A(\Omega):=\mathcal{C}({\overline{\Omega}})\cap\mathcal{O}(\Omega).$ Denote the Bergman-Shilov boundary of $A(\Omega)$ by $\partial_S(\Omega)$ . From the very definiton of peak points we know that every peak point belongs to $\partial_S(\Omega).$ Now the  examples that I know the set of peak points coincides with the $\partial_S(\Omega).$ My question here is if there are domains for which the set of peak points are properly contained in $\partial_S(\Omega)$?,Let $\Omega$ be a domain in $\mathbb{C}^n.$ Consider the Banach algebra $A(\Omega):=\mathcal{C}({\overline{\Omega}})\cap\mathcal{O}(\Omega).$ Denote the Bergman-Shilov boundary of $A(\Omega)$ by $\partial_S(\Omega)$ . From the very definiton of peak points we know that every peak point belongs to $\partial_S(\Omega).$ Now the  examples that I know the set of peak points coincides with the $\partial_S(\Omega).$ My question here is if there are domains for which the set of peak points are properly contained in $\partial_S(\Omega)$?,,"['complex-analysis', 'banach-algebras', 'several-complex-variables']"
95,Residue Formula application,Residue Formula application,,"Using the Residue formula, I've been trying to prove $$\int_0^{2\pi}\frac{1}{a^2\cos^2\theta+b^2\sin^2\theta}\,d\theta=\frac{2\pi}{ab},\quad\quad a,b\in\Bbb R.$$First, it seems like the formula should be wrong (unless perhaps we assume $a,b\in\Bbb R^+$) since the right-hand side can be negative, but the integrand on the left is always non-negative. Currently I'm assuming the additional requirement $a,b>0$. With that said, to approach it, I use Euler's formulas on the trig. functions in the denominator and make a change of variables, $$z=e^{i\theta},\quad \frac{1}{iz}\,dz=d\theta.$$Now, if I have calculated correctly, the integral reduces to $$\int_{|z|=1}\frac{1}{iz}\cdot\frac{1}{\frac{a^2}{4}\left(z+z^{-1}\right)^2-\frac{b^2}{4}\left(z-z^{-1}\right)^2}\,dz.$$We can factor $z^{-2}$ from the right-side denominator to get $$\int_{|z|=1}\frac{z}{i}\cdot\frac{1}{\frac{a^2}{4}\left(z^2+1\right)^2-\frac{b^2}{4}\left(z^2-1\right)^2}\,dz.$$Since the denominator is a difference of squares, we can factor the denominator as $$\int_{|z|=1}\frac{4z}{i}\cdot\left(\frac{1}{a(z^2+1)-b(z^2-1)}\right)\cdot\left(\frac{1}{a(z^2+1)-b(z^2-1)}\right)\,\,dz. $$This is where I really started running into trouble. I tried solving when the denominator of the right term vanished and I found $$z=\pm\sqrt{\frac{b+a}{b-a}}.$$ This didn't seem right because it doesn't always have to be inside the unit circle (I don't think), so I think I might have made an error in calculation. Is my method so far correct, or is there a far better way to calculate this integral using the residue formula? This isn't homework, just prepping for an exam. Thanks!","Using the Residue formula, I've been trying to prove $$\int_0^{2\pi}\frac{1}{a^2\cos^2\theta+b^2\sin^2\theta}\,d\theta=\frac{2\pi}{ab},\quad\quad a,b\in\Bbb R.$$First, it seems like the formula should be wrong (unless perhaps we assume $a,b\in\Bbb R^+$) since the right-hand side can be negative, but the integrand on the left is always non-negative. Currently I'm assuming the additional requirement $a,b>0$. With that said, to approach it, I use Euler's formulas on the trig. functions in the denominator and make a change of variables, $$z=e^{i\theta},\quad \frac{1}{iz}\,dz=d\theta.$$Now, if I have calculated correctly, the integral reduces to $$\int_{|z|=1}\frac{1}{iz}\cdot\frac{1}{\frac{a^2}{4}\left(z+z^{-1}\right)^2-\frac{b^2}{4}\left(z-z^{-1}\right)^2}\,dz.$$We can factor $z^{-2}$ from the right-side denominator to get $$\int_{|z|=1}\frac{z}{i}\cdot\frac{1}{\frac{a^2}{4}\left(z^2+1\right)^2-\frac{b^2}{4}\left(z^2-1\right)^2}\,dz.$$Since the denominator is a difference of squares, we can factor the denominator as $$\int_{|z|=1}\frac{4z}{i}\cdot\left(\frac{1}{a(z^2+1)-b(z^2-1)}\right)\cdot\left(\frac{1}{a(z^2+1)-b(z^2-1)}\right)\,\,dz. $$This is where I really started running into trouble. I tried solving when the denominator of the right term vanished and I found $$z=\pm\sqrt{\frac{b+a}{b-a}}.$$ This didn't seem right because it doesn't always have to be inside the unit circle (I don't think), so I think I might have made an error in calculation. Is my method so far correct, or is there a far better way to calculate this integral using the residue formula? This isn't homework, just prepping for an exam. Thanks!",,"['complex-analysis', 'residue-calculus']"
96,How to prove Schwarz reflection principle?,How to prove Schwarz reflection principle?,,Suppose that $f$ is non-vanishing and continuous on a closed unit disk that is holomorphic in the interior $D$. Show that if $\lvert f(z) \rvert = 1$ whenever $\lvert z \rvert = 1$ then $f$ is constant. I'm not sure where to start with this one or how to go about this proof at all. Any help would be appreciated.,Suppose that $f$ is non-vanishing and continuous on a closed unit disk that is holomorphic in the interior $D$. Show that if $\lvert f(z) \rvert = 1$ whenever $\lvert z \rvert = 1$ then $f$ is constant. I'm not sure where to start with this one or how to go about this proof at all. Any help would be appreciated.,,['complex-analysis']
97,Limits of complex function in a strip,Limits of complex function in a strip,,"I'm solving the following problem. Let $\Omega = \lbrace z \in \mathbb{C} : -1< \operatorname{Im} z <1 \rbrace$ and $f$ be a holomorphic function from $\Omega$ to the unit disk satisfying its limit to $ \infty$ along real axis is 0. Then prove that for any $-1<y<1$, $f(x+iy)\rightarrow 0$ as $x \rightarrow \infty$ I tried to use a LFT to unit disk to avobe strip so that consider the composition of it yields a map from unit disk to itself to use Schwarz lemma. BUT I found that such LFT does not exist.. IS THERE ANYWAY TO APPROACH THIS? any comment will be appreciated.","I'm solving the following problem. Let $\Omega = \lbrace z \in \mathbb{C} : -1< \operatorname{Im} z <1 \rbrace$ and $f$ be a holomorphic function from $\Omega$ to the unit disk satisfying its limit to $ \infty$ along real axis is 0. Then prove that for any $-1<y<1$, $f(x+iy)\rightarrow 0$ as $x \rightarrow \infty$ I tried to use a LFT to unit disk to avobe strip so that consider the composition of it yields a map from unit disk to itself to use Schwarz lemma. BUT I found that such LFT does not exist.. IS THERE ANYWAY TO APPROACH THIS? any comment will be appreciated.",,['complex-analysis']
98,Find entire functions that satisfy certain conditions,Find entire functions that satisfy certain conditions,,"1) Find all entire functions that are uniformly continuous on $\mathbb{C}$. 2) Find all entire functions $f(z)$ such that such that for every integer $n \geq 1$, $$\oint_{\partial\mathbb{D}} f(z)\bar{z}^ndz = 0,$$ where $\mathbb{D}$ is the unit disk. I'm a bit shaky on the first one, but I think it's that an entire function has an infinite radius of convergence, so is everywhere normally convergent. So if each term in it's power series is uniformly continuous on $\mathbb{C}$, then the function will be uniformly continuous on $\mathbb{C}$. Am I on the right track? For the second, I'm not sure how to use the Cauchy Integral Formula since $f(z)\bar{z}^n$ isn't holomorphic.","1) Find all entire functions that are uniformly continuous on $\mathbb{C}$. 2) Find all entire functions $f(z)$ such that such that for every integer $n \geq 1$, $$\oint_{\partial\mathbb{D}} f(z)\bar{z}^ndz = 0,$$ where $\mathbb{D}$ is the unit disk. I'm a bit shaky on the first one, but I think it's that an entire function has an infinite radius of convergence, so is everywhere normally convergent. So if each term in it's power series is uniformly continuous on $\mathbb{C}$, then the function will be uniformly continuous on $\mathbb{C}$. Am I on the right track? For the second, I'm not sure how to use the Cauchy Integral Formula since $f(z)\bar{z}^n$ isn't holomorphic.",,['complex-analysis']
99,Can the Fourier transform be defined as an integration over $\mathbb C$ instead of $\mathbb R$?,Can the Fourier transform be defined as an integration over  instead of ?,\mathbb C \mathbb R,"Can the Fourier transform of a whole function $f:\mathbb R\mapsto\mathbb C$ be defined as integration over $\mathbb C$ instead of $\mathbb R$ as well, such that    $$\tilde f(k) = \frac{\mathcal N}{2\pi} \int_{\mathbb C}f(x) e^{-ikx}\,dx,$$ and (if so) what is the correct value of the normalization $\mathcal N$ for consistency with the $\mathbb R$-integration? Given a whole function $f:\mathbb R\mapsto\mathbb C$, its Fourier transform $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^\infty f(x)e^{-ikx}\,dx$$ can be determined by other integration paths as well by using Cauchy's Residue Theorem, for example by shifting $x$ by an imaginary constant $ic$. Assuming a sufficiently fast decaying function for $\Re(x)\to\pm\infty$ (and using the fact that a whole function has no residues), this results in simply adding that constant to the integration boundaries, i.e. $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty+ic}^{\infty+ic} f(x)e^{-ikx}\,dx,$$ which can be expressed by substitution as well: $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx.$$ One can then average over different values of $c$ to obtain $$ \tilde f(k) = \frac1{2\pi\cdot 2T}\int_{-T}^{T}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx\,dc.$$ Now my question boils down to 1) Since infinity is involved, is this equivalent to $$ \tilde f(k) = \frac1{4\pi T}\int_{\mathbb R\times[-iT,iT]} f(x_1+x_2)e^{-ik(x_1+x_2)}\,d^2x,$$ 2) Can the limit $T\to\infty$ be taken such that $\mathbb R\times[-iT,iT]\to\mathbb C$ and 3) What would the correct normalization be?","Can the Fourier transform of a whole function $f:\mathbb R\mapsto\mathbb C$ be defined as integration over $\mathbb C$ instead of $\mathbb R$ as well, such that    $$\tilde f(k) = \frac{\mathcal N}{2\pi} \int_{\mathbb C}f(x) e^{-ikx}\,dx,$$ and (if so) what is the correct value of the normalization $\mathcal N$ for consistency with the $\mathbb R$-integration? Given a whole function $f:\mathbb R\mapsto\mathbb C$, its Fourier transform $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^\infty f(x)e^{-ikx}\,dx$$ can be determined by other integration paths as well by using Cauchy's Residue Theorem, for example by shifting $x$ by an imaginary constant $ic$. Assuming a sufficiently fast decaying function for $\Re(x)\to\pm\infty$ (and using the fact that a whole function has no residues), this results in simply adding that constant to the integration boundaries, i.e. $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty+ic}^{\infty+ic} f(x)e^{-ikx}\,dx,$$ which can be expressed by substitution as well: $$ \tilde f(k) = \frac1{2\pi}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx.$$ One can then average over different values of $c$ to obtain $$ \tilde f(k) = \frac1{2\pi\cdot 2T}\int_{-T}^{T}\int_{-\infty}^{\infty} f(x-ic)e^{-ik(x-ic)}\,dx\,dc.$$ Now my question boils down to 1) Since infinity is involved, is this equivalent to $$ \tilde f(k) = \frac1{4\pi T}\int_{\mathbb R\times[-iT,iT]} f(x_1+x_2)e^{-ik(x_1+x_2)}\,d^2x,$$ 2) Can the limit $T\to\infty$ be taken such that $\mathbb R\times[-iT,iT]\to\mathbb C$ and 3) What would the correct normalization be?",,"['analysis', 'complex-analysis', 'fourier-analysis']"
