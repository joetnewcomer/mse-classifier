,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conditional expectation as a random variable,Conditional expectation as a random variable,,"We have three random variables $x,y,z$. Is the condition ""$y$ and $z$ are independent"" enough to guarantee that ""$\mathbb{E}(x\,|\,y)$ and $z$ are independent""? Would anyone give me a brief proof or counterexample? Thanks a lot! My problem is that: By intuition I think it is not enough unless we also assume that $x$ is independent to $z$. However, by definition $\mathbb{E}(x\,|\,y)$ is $\sigma(y)$-measurable, which means that the $\sigma$-algebra generated by random variable $\mathbb{E}(x\,|\,y)$ is contained in $\sigma(y)$. Since we know that $\sigma(y)$ and $\sigma(z)$ are independent, it follows that $\mathbb{E}(x\,|\,y)$ and $z$ are independent. What is wrong in this argument?","We have three random variables $x,y,z$. Is the condition ""$y$ and $z$ are independent"" enough to guarantee that ""$\mathbb{E}(x\,|\,y)$ and $z$ are independent""? Would anyone give me a brief proof or counterexample? Thanks a lot! My problem is that: By intuition I think it is not enough unless we also assume that $x$ is independent to $z$. However, by definition $\mathbb{E}(x\,|\,y)$ is $\sigma(y)$-measurable, which means that the $\sigma$-algebra generated by random variable $\mathbb{E}(x\,|\,y)$ is contained in $\sigma(y)$. Since we know that $\sigma(y)$ and $\sigma(z)$ are independent, it follows that $\mathbb{E}(x\,|\,y)$ and $z$ are independent. What is wrong in this argument?",,"['probability', 'measure-theory']"
1,A classical problem in combinatorics/probability,A classical problem in combinatorics/probability,,"I read this problem in Cognition and Chance by Raymond Nickerson (the problem is stated not discussed) A bag has 2n balls, two of which are marked '1', another two marked '2' and so  on. m balls are chosen, find the probability that k pairs are still in the bag. Here's my hand at the solution: The $k$ pairs are chosen by $ n \choose k$. And let $x_i$ be the number of balls chosen of type $i$ (excluding the $k$ previously chosen) and these $x_i$'s should satisfy: $$ x_1 + x_2 + \cdots + x_{n-k} = m .\tag{1}$$ and clearly $$ 1 \leq x_i \leq 2 \tag{2}$$ Taking the generating function to solve this partition problem . $$ (x+x^2)^{n-k} \tag{3}$$ the $x^m$ term in $(3)$ is say $X_m$ and the answer becomes $n\choose k$$X_m$. However applying Binomial Theorem in $(3)$ gives a very simple answer. I am very skepticall about this answer. Generating functions hasn't been my friend lately. I am sure the approach is right though. Where have I gone wrong and what is the final expression for $X_m$","I read this problem in Cognition and Chance by Raymond Nickerson (the problem is stated not discussed) A bag has 2n balls, two of which are marked '1', another two marked '2' and so  on. m balls are chosen, find the probability that k pairs are still in the bag. Here's my hand at the solution: The $k$ pairs are chosen by $ n \choose k$. And let $x_i$ be the number of balls chosen of type $i$ (excluding the $k$ previously chosen) and these $x_i$'s should satisfy: $$ x_1 + x_2 + \cdots + x_{n-k} = m .\tag{1}$$ and clearly $$ 1 \leq x_i \leq 2 \tag{2}$$ Taking the generating function to solve this partition problem . $$ (x+x^2)^{n-k} \tag{3}$$ the $x^m$ term in $(3)$ is say $X_m$ and the answer becomes $n\choose k$$X_m$. However applying Binomial Theorem in $(3)$ gives a very simple answer. I am very skepticall about this answer. Generating functions hasn't been my friend lately. I am sure the approach is right though. Where have I gone wrong and what is the final expression for $X_m$",,"['probability', 'combinatorics', 'generating-functions']"
2,"Random walk, Cat and mouse","Random walk, Cat and mouse",,"Here is the problem. In graph G, on different vertices there is cat and mouse. Cat and mouse do independent random walk, but time is synchronous, in one unit of time both cat and mouse do one step. a)Estimate expected life duration of mouse, if cat eat mouse whenever they are on the same vertices. They can meet on the edge without consequences. Estimate should depend on number of edges and vertices. b) Same as above, but G is cycle $C_{2n}$ and cat and mouse starts in maximal distance from each other. Count exactlz expected mouse life duration. c)Same as B, but graph G is hypercube of dimension k. My progress so far: a) Let $G=(V,E)$, $V=\{1, \dots, n\}$ Let P be the matrix with probability distribution for random walk $P_{ij}=P(M_{t+1}=i|M_t=j)=\frac{1}{d_j}$, where $M_t$ is position of random walk after t steps. Let $v=(\frac{1}{n}, \dots, \frac{1}{n})$ be the initial distribution vektor. Now if we know, that Cat and Mouse distribution is virtually the same, we just need to  do estimate on the probability, that they meet together after at least t steps. Let $C_t$ and $M_t$ be the position of cat and mouse respectively after t steps. And let L to be life duration of Mouse. I propose $P(C_t=M_t)=<P^tv,P^tv>$, where <> is scalar product of distribution Cat and Mouse random walk after t steps. Because probability that they meet at vertex $i$ is the probability $$P(C_t=M_t=i)=P(C_t=i)P(M_t=i)=(P^tv)_i^2$$ Is it correct? Assuming this, I have $P(L\leq t)\geq <P^tv,P^tv>$, I must count the case, that cat and mouse meet earlier than at t, so there are inequalities. In the end I need to estimate $$E(L)=\sum_{k=1}^{\infty}kP(L=t)$$ which is by using $P(L=t)=P(L\leq t)-P(L\leq t-1)$ and telescoping the sum is $$E(L)=\sum_{k=1}^{\infty}P(L\leq t)\geq \sum_{k=1}^{\infty}<P^tv,P^tv>$$ Problem is how to estimate this and if this is good direction if its correct. b) Here again if cats random walk is C_t and Mouse random walk is M_t. First observation is that on on graph $C_{2(2n+1)}$, when cat and mouse start at maximal distance from each other there is no way, they can meet, because there is odd number of edges between them. So I assume the graph is $C_{4n}$  I can maybe do the random walk H_t=(C_t-M_t) in such way, that if graph is $C_{4n}$ then we make from that a path on 2n+1 vertices $(1,\dots, 2n+1)$. With starting point in the middle. Distance of $H_t$ from closer of the ends of the path will correspond to distance of C_t and M_t, so if cat and mouse meet at the vertex $H_t=1$ or $H_t=2n+1$. and distribution for random walk of $H_t$ will be  $$P(H_{t+1}=H_t+1)=1/4$$ Cat moves clockwise and Mouse moves counterclockwise $$P(H_{t+1}=H_t-1)=1/4$$ Cat moves counterclockwise and Mouse moves clockwise $$P(H_{t+1}=H_t)=1/2$$ Both Cat and Mouse moves counterclockwise or both move clockwise I need to count expected time, that $H_t$ meet either of the edges of the path. To simplify I can simplify I can identify first and last vertex of the path  and have random walk of $H_t$ on graph $C_{2n}$ with these probabilities. Now the question is what is the hitting time on cycle $C_{2n}$ with random walk as defined for $H_t$. Starting at one vertex and moving to the vertex with maximal distance on cycle. c) no thoughts yet, also something like b) I will update if think of something. I hope it is understandable, any help appreciated. If I do some progress I will update. John","Here is the problem. In graph G, on different vertices there is cat and mouse. Cat and mouse do independent random walk, but time is synchronous, in one unit of time both cat and mouse do one step. a)Estimate expected life duration of mouse, if cat eat mouse whenever they are on the same vertices. They can meet on the edge without consequences. Estimate should depend on number of edges and vertices. b) Same as above, but G is cycle $C_{2n}$ and cat and mouse starts in maximal distance from each other. Count exactlz expected mouse life duration. c)Same as B, but graph G is hypercube of dimension k. My progress so far: a) Let $G=(V,E)$, $V=\{1, \dots, n\}$ Let P be the matrix with probability distribution for random walk $P_{ij}=P(M_{t+1}=i|M_t=j)=\frac{1}{d_j}$, where $M_t$ is position of random walk after t steps. Let $v=(\frac{1}{n}, \dots, \frac{1}{n})$ be the initial distribution vektor. Now if we know, that Cat and Mouse distribution is virtually the same, we just need to  do estimate on the probability, that they meet together after at least t steps. Let $C_t$ and $M_t$ be the position of cat and mouse respectively after t steps. And let L to be life duration of Mouse. I propose $P(C_t=M_t)=<P^tv,P^tv>$, where <> is scalar product of distribution Cat and Mouse random walk after t steps. Because probability that they meet at vertex $i$ is the probability $$P(C_t=M_t=i)=P(C_t=i)P(M_t=i)=(P^tv)_i^2$$ Is it correct? Assuming this, I have $P(L\leq t)\geq <P^tv,P^tv>$, I must count the case, that cat and mouse meet earlier than at t, so there are inequalities. In the end I need to estimate $$E(L)=\sum_{k=1}^{\infty}kP(L=t)$$ which is by using $P(L=t)=P(L\leq t)-P(L\leq t-1)$ and telescoping the sum is $$E(L)=\sum_{k=1}^{\infty}P(L\leq t)\geq \sum_{k=1}^{\infty}<P^tv,P^tv>$$ Problem is how to estimate this and if this is good direction if its correct. b) Here again if cats random walk is C_t and Mouse random walk is M_t. First observation is that on on graph $C_{2(2n+1)}$, when cat and mouse start at maximal distance from each other there is no way, they can meet, because there is odd number of edges between them. So I assume the graph is $C_{4n}$  I can maybe do the random walk H_t=(C_t-M_t) in such way, that if graph is $C_{4n}$ then we make from that a path on 2n+1 vertices $(1,\dots, 2n+1)$. With starting point in the middle. Distance of $H_t$ from closer of the ends of the path will correspond to distance of C_t and M_t, so if cat and mouse meet at the vertex $H_t=1$ or $H_t=2n+1$. and distribution for random walk of $H_t$ will be  $$P(H_{t+1}=H_t+1)=1/4$$ Cat moves clockwise and Mouse moves counterclockwise $$P(H_{t+1}=H_t-1)=1/4$$ Cat moves counterclockwise and Mouse moves clockwise $$P(H_{t+1}=H_t)=1/2$$ Both Cat and Mouse moves counterclockwise or both move clockwise I need to count expected time, that $H_t$ meet either of the edges of the path. To simplify I can simplify I can identify first and last vertex of the path  and have random walk of $H_t$ on graph $C_{2n}$ with these probabilities. Now the question is what is the hitting time on cycle $C_{2n}$ with random walk as defined for $H_t$. Starting at one vertex and moving to the vertex with maximal distance on cycle. c) no thoughts yet, also something like b) I will update if think of something. I hope it is understandable, any help appreciated. If I do some progress I will update. John",,"['probability', 'graph-theory', 'markov-chains', 'random-walk']"
3,How to make repeat winners unlikely in B.I.N.G.O.,How to make repeat winners unlikely in B.I.N.G.O.,,"My three-year-old son loves BINGO (U.S. version) . This morning I took him to observe ""senior BINGO"" at a local fast food joint, and something interesting (though not surprising) happened: After a certain amount of numbers had been announced, senior ""Paul"" exclaimed that he had finally got one (1) to match his board. Fast forward a few more turns of the ball cage, and another player wins. Now, the caller spins the cage until 5-6 balls are out , THEN replaces all of the balls that had been called, and immediately starts the next round with the 5-6 queued balls that were not replaced. Paul wins the next game, and I start thinking: How many balls would you have to queue between rounds/games (from those not chosen) to ensure, with a certain confidence C (or a certain probability P?) that there is not a back-to-back winner? The problem gets complicated quickly, at least the way I look at it. This would surely depend on the number of players, and on the number of spaces on each board that match the winner's board. If the problem is too tricky, I'd certainly be satisfied with a computer output for a few combinations of players, number of balls announced before a win, etc. (or with a description of how/why it is so complicated).","My three-year-old son loves BINGO (U.S. version) . This morning I took him to observe ""senior BINGO"" at a local fast food joint, and something interesting (though not surprising) happened: After a certain amount of numbers had been announced, senior ""Paul"" exclaimed that he had finally got one (1) to match his board. Fast forward a few more turns of the ball cage, and another player wins. Now, the caller spins the cage until 5-6 balls are out , THEN replaces all of the balls that had been called, and immediately starts the next round with the 5-6 queued balls that were not replaced. Paul wins the next game, and I start thinking: How many balls would you have to queue between rounds/games (from those not chosen) to ensure, with a certain confidence C (or a certain probability P?) that there is not a back-to-back winner? The problem gets complicated quickly, at least the way I look at it. This would surely depend on the number of players, and on the number of spaces on each board that match the winner's board. If the problem is too tricky, I'd certainly be satisfied with a computer output for a few combinations of players, number of balls announced before a win, etc. (or with a description of how/why it is so complicated).",,['probability']
4,"Can you quantify a pattern as being ""more random""","Can you quantify a pattern as being ""more random""",,"(Link to refenced image ) I'm looking into the patterns used to position ""padfeet"" on a padfoot soil compactor.  The point of the feet is to gain an increased ground pressure, the downside is that as you roll over an area you only cover a certain percent of the ground, in this case 15% each time.(I've already calculated average % you will hit with each successive pass"" The pattern that is typically used is the chevron(bottom right, spaces removed).  What is done is that the operator will roll forward and back over and area, and then turn around 180 degrees and repeat up to 6-8 total passes.  The reversing is done to purposely decrease the chance of overlapping the ""V""'s. My question is, I've considered changing this to either the gull wing(bottom left and top with accurate spacing) or a even more scattered pattern such as putting row 5 as the 3rd impact, thus making a double chevron.  Looking at this, I visually perceive this to be a ""more random"" pattern, but is there a way quantify or define a difference between the changing patterns when they are both ""equal"" in their coverage.  Or is it just in my head. Thinking a bit more about it:  What I've calculated previously (with some assistance) is the % coverage from each pass""In general if the compactor affects p fraction of the area each time, after n passes it will have covered 1−(1−p)n of the area. So to cover 90% in 8 passes, you'll need just about 25% coverage on each pass, as 1−(1−.25)8≈90%."" The purpose of the 180 turn is to better mimic this calcuation, because you don't have a unique pattern hit with every pass, and if you overlap while just driving forwards and back you're likely to overlap with all 9 rows.  It seems like introducing a change to the pattern going around the drum, so that the pattern does not repeat identically for all 15 chevrons around the circumference, but adjusts slightly so that even when an overlap takes place it takes place to a lesser percent. That still doesn't tell me if/how the shape of ""each"" pattern matters or not though.","(Link to refenced image ) I'm looking into the patterns used to position ""padfeet"" on a padfoot soil compactor.  The point of the feet is to gain an increased ground pressure, the downside is that as you roll over an area you only cover a certain percent of the ground, in this case 15% each time.(I've already calculated average % you will hit with each successive pass"" The pattern that is typically used is the chevron(bottom right, spaces removed).  What is done is that the operator will roll forward and back over and area, and then turn around 180 degrees and repeat up to 6-8 total passes.  The reversing is done to purposely decrease the chance of overlapping the ""V""'s. My question is, I've considered changing this to either the gull wing(bottom left and top with accurate spacing) or a even more scattered pattern such as putting row 5 as the 3rd impact, thus making a double chevron.  Looking at this, I visually perceive this to be a ""more random"" pattern, but is there a way quantify or define a difference between the changing patterns when they are both ""equal"" in their coverage.  Or is it just in my head. Thinking a bit more about it:  What I've calculated previously (with some assistance) is the % coverage from each pass""In general if the compactor affects p fraction of the area each time, after n passes it will have covered 1−(1−p)n of the area. So to cover 90% in 8 passes, you'll need just about 25% coverage on each pass, as 1−(1−.25)8≈90%."" The purpose of the 180 turn is to better mimic this calcuation, because you don't have a unique pattern hit with every pass, and if you overlap while just driving forwards and back you're likely to overlap with all 9 rows.  It seems like introducing a change to the pattern going around the drum, so that the pattern does not repeat identically for all 15 chevrons around the circumference, but adjusts slightly so that even when an overlap takes place it takes place to a lesser percent. That still doesn't tell me if/how the shape of ""each"" pattern matters or not though.",,"['probability', 'probability-theory']"
5,Unnormalized density function for a random variable,Unnormalized density function for a random variable,,"Usually in probability theory, for a random variable whose value is in $\mathbb{R}$, we talk about its cumulative distribution function $F(x)$ and then its density $f(x)$, in good enough cases $F'(x)=f(x)$. That's the setup I'm familiar with, so I got annoyed when physicists talk about unnormalized ""densities"". E.g. if the probabilistic density of the position of a particle on $\mathbb{R}$ is equal to 1 everywhere, that means it is equally likely to appear anywhere. More generally you can imagine them talking about a non-negative function $f(x)$ being the density of something with the density $f(x)$ is not integrable on $\mathbb{R}$ but locally integrable, i.e. $\int_{[a,b]}f(x)dx$ make sense for $a\leq b, a, b\in\mathbb{R}$. As $\int_{\mathbb{R}}f(x)dx$ is undefined ($=\infty$), one cannot divide by it to normalize. Is there a mathematical way to make sense of such statements? There is one I have in mind, namely, one can talk about the density of some random variable $X$ up to a scalar multiple, such that for any intervals $[a,b]\subset [c,d]$ we can express the conditional probability as a quotient of integrals: $$P(X\in[a,b] \big| X\in[c,d])=\dfrac{\int_{[a,b]}f(x)dx}{\int_{[c,d]}f(x)dx}.$$ I only know very basic probability theory so I don't know if this makes sense. Am I allowed to interpret unnormalized probabilistic density functions this way? Is this what physicists mean? Or are there any other interpretations? Do I have to worry about something else when thinking about things in this way?","Usually in probability theory, for a random variable whose value is in $\mathbb{R}$, we talk about its cumulative distribution function $F(x)$ and then its density $f(x)$, in good enough cases $F'(x)=f(x)$. That's the setup I'm familiar with, so I got annoyed when physicists talk about unnormalized ""densities"". E.g. if the probabilistic density of the position of a particle on $\mathbb{R}$ is equal to 1 everywhere, that means it is equally likely to appear anywhere. More generally you can imagine them talking about a non-negative function $f(x)$ being the density of something with the density $f(x)$ is not integrable on $\mathbb{R}$ but locally integrable, i.e. $\int_{[a,b]}f(x)dx$ make sense for $a\leq b, a, b\in\mathbb{R}$. As $\int_{\mathbb{R}}f(x)dx$ is undefined ($=\infty$), one cannot divide by it to normalize. Is there a mathematical way to make sense of such statements? There is one I have in mind, namely, one can talk about the density of some random variable $X$ up to a scalar multiple, such that for any intervals $[a,b]\subset [c,d]$ we can express the conditional probability as a quotient of integrals: $$P(X\in[a,b] \big| X\in[c,d])=\dfrac{\int_{[a,b]}f(x)dx}{\int_{[c,d]}f(x)dx}.$$ I only know very basic probability theory so I don't know if this makes sense. Am I allowed to interpret unnormalized probabilistic density functions this way? Is this what physicists mean? Or are there any other interpretations? Do I have to worry about something else when thinking about things in this way?",,"['probability', 'probability-theory']"
6,Probability of cycles of length at most $g$ in a random graph,Probability of cycles of length at most  in a random graph,g,"I am working on a homework problem. The essence of it is as follows: Fix some integer $g$, a probability $p\in [0,1]$, and a linear function $f(n)$, where $n$ is the number of vertices of a random graph. If the probability of having a particular edge in a graph is $p$, what is the probability that the number of cycles of length at most $g$ in a random graph with $n$ vertices will surpass $f(n)$? I'd like just some hints in the direction of the solution. The actual question has $p$ as a function of $n$ and $g$, and asks for the result in the limit as $n\to\infty$, but I would like to understand the question in general.","I am working on a homework problem. The essence of it is as follows: Fix some integer $g$, a probability $p\in [0,1]$, and a linear function $f(n)$, where $n$ is the number of vertices of a random graph. If the probability of having a particular edge in a graph is $p$, what is the probability that the number of cycles of length at most $g$ in a random graph with $n$ vertices will surpass $f(n)$? I'd like just some hints in the direction of the solution. The actual question has $p$ as a function of $n$ and $g$, and asks for the result in the limit as $n\to\infty$, but I would like to understand the question in general.",,"['probability', 'combinatorics', 'graph-theory', 'random-graphs']"
7,A question about how to get the limiting probability.,A question about how to get the limiting probability.,,"Suppose $p=\begin{bmatrix}  0& 1\over 3 &0  &2\over 3 \\   0.3&  0& 0.7 &0 \\   0&  2\over 3&0  &1\over3 \\   0.8&  0&  0.2& 0 \end{bmatrix}$is the transition probability matrix of a Markov chain with state space {1, 2, 3, 4}. How to get the limiting probabilities of the Markov chain. I think if more different alternative answer and apporach would be better. In fact i know a little bit about limiting probability but not sure how to apply in this question. Clear step to illustrate how it works or explaination would be appreciated and i wanna learn how others interpret the concept of probability","Suppose $p=\begin{bmatrix}  0& 1\over 3 &0  &2\over 3 \\   0.3&  0& 0.7 &0 \\   0&  2\over 3&0  &1\over3 \\   0.8&  0&  0.2& 0 \end{bmatrix}$is the transition probability matrix of a Markov chain with state space {1, 2, 3, 4}. How to get the limiting probabilities of the Markov chain. I think if more different alternative answer and apporach would be better. In fact i know a little bit about limiting probability but not sure how to apply in this question. Clear step to illustrate how it works or explaination would be appreciated and i wanna learn how others interpret the concept of probability",,"['probability', 'probability-theory', 'markov-chains']"
8,Time to find first copy of a duplicate,Time to find first copy of a duplicate,,"Consider a random process which samples uniformly with replacement from [n]. The expected time to find a duplicate is a constant factor times $\sqrt{n}$. This is a version of the famous Birthday Problem. How can one find the expected time to find the first copy of the first duplicate? This will obviously occur some time before. Also, what is the distribution of this time? If you fix the position of the later copy of the duplicate then the earlier copy seems to occur uniformly before it but I am not sure how helpful that is to answer the questions. By time I simply mean that each sample takes one unit of time so the time is just the number of samples at that point. This is not a question about algorithms or computation.","Consider a random process which samples uniformly with replacement from [n]. The expected time to find a duplicate is a constant factor times $\sqrt{n}$. This is a version of the famous Birthday Problem. How can one find the expected time to find the first copy of the first duplicate? This will obviously occur some time before. Also, what is the distribution of this time? If you fix the position of the later copy of the duplicate then the earlier copy seems to occur uniformly before it but I am not sure how helpful that is to answer the questions. By time I simply mean that each sample takes one unit of time so the time is just the number of samples at that point. This is not a question about algorithms or computation.",,['probability']
9,Evaluating $\int_{0}^{1}\int_{0}^{1}\frac{r^{i+j}(1-r)^{k+l}s^{2m-i-j}(1-s)^{2m-k-l}}{(r+s)^{m}(2-r-s)^{m}}drds$,Evaluating,\int_{0}^{1}\int_{0}^{1}\frac{r^{i+j}(1-r)^{k+l}s^{2m-i-j}(1-s)^{2m-k-l}}{(r+s)^{m}(2-r-s)^{m}}drds,"I'm trying to compute a closed form expression for the integral $$ \int_{0}^{1}\int_{0}^{1}\frac{r^{i+j}(1-r)^{k+l}s^{2m-i-j}(1-s)^{2m-k-l}}{(r+s)^{m}(2-r-s)^{m}}drds \quad i,j,k,l \in\{0,1,\ldots,m\},$$ which occurs in calculating $$\mathrm{Ex}\left[\frac{R^{i}(1-R)^{k}S^{m-i}(1-S)^{m-k}}{(R+S)^{m}(2-R-S)^{m}}\right]$$ where $R$ and $S$ are independent random variables with $R\sim Beta(j+1,l+1)$, $S\sim Beta(m-j+1,m-l+1)$ and $i,j,k,l \in\{0,1,\ldots,m\}$. Right now the only idea I have is to try to find a partial fraction decomposition that will allow me to compute the integral of the resulting terms using integration by parts. However, this would be a lengthy and tedious calculation. I would really appreciate any ideas or suggestions for computing this integral in a more elegant way.","I'm trying to compute a closed form expression for the integral $$ \int_{0}^{1}\int_{0}^{1}\frac{r^{i+j}(1-r)^{k+l}s^{2m-i-j}(1-s)^{2m-k-l}}{(r+s)^{m}(2-r-s)^{m}}drds \quad i,j,k,l \in\{0,1,\ldots,m\},$$ which occurs in calculating $$\mathrm{Ex}\left[\frac{R^{i}(1-R)^{k}S^{m-i}(1-S)^{m-k}}{(R+S)^{m}(2-R-S)^{m}}\right]$$ where $R$ and $S$ are independent random variables with $R\sim Beta(j+1,l+1)$, $S\sim Beta(m-j+1,m-l+1)$ and $i,j,k,l \in\{0,1,\ldots,m\}$. Right now the only idea I have is to try to find a partial fraction decomposition that will allow me to compute the integral of the resulting terms using integration by parts. However, this would be a lengthy and tedious calculation. I would really appreciate any ideas or suggestions for computing this integral in a more elegant way.",,"['calculus', 'probability', 'integration']"
10,Relationship between two random variables?,Relationship between two random variables?,,"What is the relationship between a random variable obeying the subexponential distribution defined here and a random variable $X$ satisfying $P\left(\left|X\right|>t\right)\le\alpha e^{-\beta t}$ for all $t>0$ and some $\alpha,\beta>0$ ? Thanks a lot for any helpful answers.",What is the relationship between a random variable obeying the subexponential distribution defined here and a random variable satisfying for all and some ? Thanks a lot for any helpful answers.,"X P\left(\left|X\right|>t\right)\le\alpha e^{-\beta t} t>0 \alpha,\beta>0","['probability', 'statistics', 'measure-theory', 'probability-theory', 'probability-distributions']"
11,Multivariate Hypergeometric Distribution/Urn Problem,Multivariate Hypergeometric Distribution/Urn Problem,,"I am having a difficulty with the following multivariate hypergeometric distribution problem. The setting is as usual, an urn contains a total of $M$ balls of $K$ unique colors, with $N_1$ balls of color 1, $N_2$ balls of color 2, ..., $N_K$ balls of color $K$ s.t. $N_1+N_2...+N_K = M$. What is the probability that in a sample of size $n$ (without replacement), the ball drawn last has a color not sampled before. For simplicity, we can assume that $N_1=N_2=...=N_K=N$, i.e. $M=KN$. I have been trying to look at particular cases with $K=2$ and $K=3$ (2 or 3 colors) with different values of sample size, $n$, hoping I could generalize the formulas for arbitrary $K$ and $n$. Thus, for example, for $K=2$ and any value of $n$, I showed that the probability in question could be found by $K \cdot \frac{{N_1 \choose n-1}{N_2 \choose 1}}{n {M \choose n}}$. For $K=3$, we may have two different cases: a) only 2 out of the available three colors are sampled (with $n-1$ balls of the same color and 1 ball of a second color). The desired probability is then $K(K-1)\frac{{N_1 \choose 2}{N_2 \choose 0}{N_3 \choose 1}}{n {M \choose 3}}$. And case b) all three colors are sampled (1 ball of each), then the desired probability is $K(K-1) \frac{{N_1 \choose 1}{N_2 \choose 1}{N_3 \choose 1}}{n{M \choose 3}}$ and the final answer is the sum of (a) and (b). Does this logic seem reasonable ? Obviously by increasing the values of $k$ and $n$ the number of cases to keep track of will increase too but it seems that each new case may be simplified into (or represented by) a previously worked out scenario. In short, it seems that I may eventually be able to find some recursive relation but after some tedious work. Any ideas would be greatly appreciated. More specifically - is this a good route to go? If yes, are there any shortcuts that I can take ? Is there a completely different approach that I can try ? Thanks, in advance, Tamar","I am having a difficulty with the following multivariate hypergeometric distribution problem. The setting is as usual, an urn contains a total of $M$ balls of $K$ unique colors, with $N_1$ balls of color 1, $N_2$ balls of color 2, ..., $N_K$ balls of color $K$ s.t. $N_1+N_2...+N_K = M$. What is the probability that in a sample of size $n$ (without replacement), the ball drawn last has a color not sampled before. For simplicity, we can assume that $N_1=N_2=...=N_K=N$, i.e. $M=KN$. I have been trying to look at particular cases with $K=2$ and $K=3$ (2 or 3 colors) with different values of sample size, $n$, hoping I could generalize the formulas for arbitrary $K$ and $n$. Thus, for example, for $K=2$ and any value of $n$, I showed that the probability in question could be found by $K \cdot \frac{{N_1 \choose n-1}{N_2 \choose 1}}{n {M \choose n}}$. For $K=3$, we may have two different cases: a) only 2 out of the available three colors are sampled (with $n-1$ balls of the same color and 1 ball of a second color). The desired probability is then $K(K-1)\frac{{N_1 \choose 2}{N_2 \choose 0}{N_3 \choose 1}}{n {M \choose 3}}$. And case b) all three colors are sampled (1 ball of each), then the desired probability is $K(K-1) \frac{{N_1 \choose 1}{N_2 \choose 1}{N_3 \choose 1}}{n{M \choose 3}}$ and the final answer is the sum of (a) and (b). Does this logic seem reasonable ? Obviously by increasing the values of $k$ and $n$ the number of cases to keep track of will increase too but it seems that each new case may be simplified into (or represented by) a previously worked out scenario. In short, it seems that I may eventually be able to find some recursive relation but after some tedious work. Any ideas would be greatly appreciated. More specifically - is this a good route to go? If yes, are there any shortcuts that I can take ? Is there a completely different approach that I can try ? Thanks, in advance, Tamar",,"['probability', 'combinatorics', 'probability-distributions']"
12,Median of order statistics,Median of order statistics,,"I recently learned that to find the pdf of the median of say $X_1,X_2, X_3$, you first find the Cdf via $$ P(M \le x) =P(\text{at least 2 are}\, \le x) = P( \text{exactly 2 are}\, \le x) + P(\text{all 3 are} \le x)$$ where $M$ denotes the median. Finaly you differentiate to get the required pdf. My questions: How does one find the cdf/pdf of an arbitrary number of order statistics? Is there a generalized formula? Thanks Edit: Let's suppose the $X_i$'s are iid.","I recently learned that to find the pdf of the median of say $X_1,X_2, X_3$, you first find the Cdf via $$ P(M \le x) =P(\text{at least 2 are}\, \le x) = P( \text{exactly 2 are}\, \le x) + P(\text{all 3 are} \le x)$$ where $M$ denotes the median. Finaly you differentiate to get the required pdf. My questions: How does one find the cdf/pdf of an arbitrary number of order statistics? Is there a generalized formula? Thanks Edit: Let's suppose the $X_i$'s are iid.",,"['probability', 'statistics']"
13,Calculation of the moments using Hypergeometric distribution,Calculation of the moments using Hypergeometric distribution,,"Let vector $a\in 2n $ is such that first $l$ of its coordinates are $1$ and the rest are $0$ ($a=(1,\ldots, 1,0, \ldots, 0)$). Let $\pi$ be $k$-th permutation of set $\{1, \ldots, 2n\}$. Define $$g=\left|\sum_{i=1}^n a_{\pi(i)}-\sum_{i=n+1}^{2n}a_{\pi(i)}\right|.$$ Using Hypergeometric distribution  calculate /approximate the $q$-th moment $E|g|^q,$ for any $q\ge 2$. I've got that the $q$-th moment is  $$ E|g|^q=\sum_{k=0}^l\frac{{l \choose k}{2n-l \choose n-k}(2k-l)^q}{{2n\choose n}}. $$ But now I am stuck... Thank you for your help.","Let vector $a\in 2n $ is such that first $l$ of its coordinates are $1$ and the rest are $0$ ($a=(1,\ldots, 1,0, \ldots, 0)$). Let $\pi$ be $k$-th permutation of set $\{1, \ldots, 2n\}$. Define $$g=\left|\sum_{i=1}^n a_{\pi(i)}-\sum_{i=n+1}^{2n}a_{\pi(i)}\right|.$$ Using Hypergeometric distribution  calculate /approximate the $q$-th moment $E|g|^q,$ for any $q\ge 2$. I've got that the $q$-th moment is  $$ E|g|^q=\sum_{k=0}^l\frac{{l \choose k}{2n-l \choose n-k}(2k-l)^q}{{2n\choose n}}. $$ But now I am stuck... Thank you for your help.",,"['probability', 'combinatorics', 'statistics', 'binomial-coefficients']"
14,Generating function for Banach's matchbox problem,Generating function for Banach's matchbox problem,,"Here's the description for Banach's matchbox problem from Concrete Mathematics EXERCISE 8.46 (edited) Stefan Banach used to carry two boxes of matches, one containing $m$ matches and the other one containing $n$ matches. Whenever he needed a light he chose a box at random, each with probability $\frac 1 2$, independent of his previous choices. After taking out a match he'd put the box back in its pocket (even if the box became empty -- all famous mathematicians used to do this). When his chosen box was empty he'd throw it away and reach for the other box. Once he found that the other box was empty too. What's the probability $p_{m,n}$ that this occurs? Generalizing your answer to part (a), find a closed form for the probability $p_{k,m,n}$ that exactly $k$ matches are in the other box when an empty one is first thrown away. The answer to these two problems only show two generating functions and the answer: (a) \[ P(w,z) = 1 + \frac 1 2 (wP(w,z) + zP(w,z)) = (1 - \frac 1 2 (w+z))^{-1} \tag 1 \] hence \[ p_{m,n} = 2^{-m-n} \binom {m+n} n \]   (b) \[ P_k(w,z) = \frac 1 2 (w^k+z^k)P(w,z) \tag 2 \] hence \[ p_{k,m,n} = 2^{k-1-m-n} \left( \binom{m+n-k}m + \binom{m+n-k}n \right) \] where $P(w,z) = \sum_{m,n \ge 0} p_{m,n}w^mz^n$ and $P_k(w,z) = \sum_{m,n \ge 0} p_{k,m,n}w^mz^n$ is generating functions for $p_{m,n}$ and $p_{k,m,n}$. I'm confused that the two equations for generating functions come out first then we get the closed form. I don't know how they come directly. There might be a reasonable explanation for formula (1): We have $p_{m,n} = \frac 1 2 (p_{m-1,n} + p_{m,n-1}) + [m=n=0]$ for all integers $m,n$ where $p_{m,n} = 0$ whenever $m<0$ or $n<0$. $[P]$ is Iverson bracket . Multiplying $z^mw^n$, summing up over all integers $m,n$ we get equation (1), but equation (2) lacks evidence. Although we can interpret $p_{k,m,n} = \frac 1 2 (p_{m-k,n} + p_{m,n-k})$ combinatorially, we cannot explain why the generating function arises, because the preceding formula gives the closed-form directly, without generating function. So I guess that there's a direct way to obtain equation (1) and (2), without the assistant of recurrence relations, just like section 7.1 DOMINO THEORY AND CHANGE , or section 8.4 FLIPPING COINS . Any help? Thanks! Postscript: There's a combinatorial proof for (b). Mention that (a) is a special case of (b). $\newcommand{\length}{\mathrm{length}}$ First, we define the probablility space for the matchbox problem. We use symbol $L$ indicating fetching a match from the left matchbox, and symbol $R$ from the right one. The elementary events are defined as strings of $L$ and $R$ which ends at an attempt of fetching the match from the empty matchbox. For example, when $m=2$ and $n=1$, we have the probability space $\Omega = \{LLL, LLRL, LLRR, LRLL, LRLR, LRR, RLLL, RLLR, RLR, RR\}$. The elementary event $LLRR$ means that the 1st and 2nd matches are from the left matchbox, and the 3rd is from the right one. The 4th time is trying to fetch the match from the right matchbox, but it's empty. $\length(\omega)$ indicates the length of elementary event $\omega$. We have $\Pr(\omega) = 2^{-\length(\omega)}$. Now let's try to enumerate all elementary events for the problem (b). There're two cases: Case 1, the right matchbox remains $k$ matches. We use $\Omega_1$ to indicate such elementary event. For each $\omega \in \Omega_1$, there're $m+1$ $L$'s in $\omega$, and $n-k$ $R$'s in it, and the last symbol of $\omega$ is $L$. For each $\omega \in \Omega_1$, $\Pr(\omega) = 2^{\length(\omega)} = 2^{-(m+n-k+1)}$, and $|\Omega_1| = \dbinom{m+n-k}m$. Case 2, the left matchbox remains $k$ matches, saying $\Omega_2$. We have $|\Omega_2| = \dbinom{m+n-k}n$, and for each $\omega \in \Omega_2$, we have $\Pr(\omega) = 2^{\length(\omega)} = 2^{-(m+n-k+1)}$. Thus \begin{align*} p_{k,m,n} &= \sum_{\omega \in \Omega_1 \cup \Omega_2} \Pr(\omega) \\ &= \sum_{\omega \in \Omega_1} \Pr(\omega) + \sum_{\omega \in \Omega_2} \Pr(\omega) \\ &= 2^{-(m+n-k+1)} \left( \binom{m+n-k}{m} + \binom{m+n-k}{n} \right) \end{align*}","Here's the description for Banach's matchbox problem from Concrete Mathematics EXERCISE 8.46 (edited) Stefan Banach used to carry two boxes of matches, one containing $m$ matches and the other one containing $n$ matches. Whenever he needed a light he chose a box at random, each with probability $\frac 1 2$, independent of his previous choices. After taking out a match he'd put the box back in its pocket (even if the box became empty -- all famous mathematicians used to do this). When his chosen box was empty he'd throw it away and reach for the other box. Once he found that the other box was empty too. What's the probability $p_{m,n}$ that this occurs? Generalizing your answer to part (a), find a closed form for the probability $p_{k,m,n}$ that exactly $k$ matches are in the other box when an empty one is first thrown away. The answer to these two problems only show two generating functions and the answer: (a) \[ P(w,z) = 1 + \frac 1 2 (wP(w,z) + zP(w,z)) = (1 - \frac 1 2 (w+z))^{-1} \tag 1 \] hence \[ p_{m,n} = 2^{-m-n} \binom {m+n} n \]   (b) \[ P_k(w,z) = \frac 1 2 (w^k+z^k)P(w,z) \tag 2 \] hence \[ p_{k,m,n} = 2^{k-1-m-n} \left( \binom{m+n-k}m + \binom{m+n-k}n \right) \] where $P(w,z) = \sum_{m,n \ge 0} p_{m,n}w^mz^n$ and $P_k(w,z) = \sum_{m,n \ge 0} p_{k,m,n}w^mz^n$ is generating functions for $p_{m,n}$ and $p_{k,m,n}$. I'm confused that the two equations for generating functions come out first then we get the closed form. I don't know how they come directly. There might be a reasonable explanation for formula (1): We have $p_{m,n} = \frac 1 2 (p_{m-1,n} + p_{m,n-1}) + [m=n=0]$ for all integers $m,n$ where $p_{m,n} = 0$ whenever $m<0$ or $n<0$. $[P]$ is Iverson bracket . Multiplying $z^mw^n$, summing up over all integers $m,n$ we get equation (1), but equation (2) lacks evidence. Although we can interpret $p_{k,m,n} = \frac 1 2 (p_{m-k,n} + p_{m,n-k})$ combinatorially, we cannot explain why the generating function arises, because the preceding formula gives the closed-form directly, without generating function. So I guess that there's a direct way to obtain equation (1) and (2), without the assistant of recurrence relations, just like section 7.1 DOMINO THEORY AND CHANGE , or section 8.4 FLIPPING COINS . Any help? Thanks! Postscript: There's a combinatorial proof for (b). Mention that (a) is a special case of (b). $\newcommand{\length}{\mathrm{length}}$ First, we define the probablility space for the matchbox problem. We use symbol $L$ indicating fetching a match from the left matchbox, and symbol $R$ from the right one. The elementary events are defined as strings of $L$ and $R$ which ends at an attempt of fetching the match from the empty matchbox. For example, when $m=2$ and $n=1$, we have the probability space $\Omega = \{LLL, LLRL, LLRR, LRLL, LRLR, LRR, RLLL, RLLR, RLR, RR\}$. The elementary event $LLRR$ means that the 1st and 2nd matches are from the left matchbox, and the 3rd is from the right one. The 4th time is trying to fetch the match from the right matchbox, but it's empty. $\length(\omega)$ indicates the length of elementary event $\omega$. We have $\Pr(\omega) = 2^{-\length(\omega)}$. Now let's try to enumerate all elementary events for the problem (b). There're two cases: Case 1, the right matchbox remains $k$ matches. We use $\Omega_1$ to indicate such elementary event. For each $\omega \in \Omega_1$, there're $m+1$ $L$'s in $\omega$, and $n-k$ $R$'s in it, and the last symbol of $\omega$ is $L$. For each $\omega \in \Omega_1$, $\Pr(\omega) = 2^{\length(\omega)} = 2^{-(m+n-k+1)}$, and $|\Omega_1| = \dbinom{m+n-k}m$. Case 2, the left matchbox remains $k$ matches, saying $\Omega_2$. We have $|\Omega_2| = \dbinom{m+n-k}n$, and for each $\omega \in \Omega_2$, we have $\Pr(\omega) = 2^{\length(\omega)} = 2^{-(m+n-k+1)}$. Thus \begin{align*} p_{k,m,n} &= \sum_{\omega \in \Omega_1 \cup \Omega_2} \Pr(\omega) \\ &= \sum_{\omega \in \Omega_1} \Pr(\omega) + \sum_{\omega \in \Omega_2} \Pr(\omega) \\ &= 2^{-(m+n-k+1)} \left( \binom{m+n-k}{m} + \binom{m+n-k}{n} \right) \end{align*}",,"['probability', 'combinatorics', 'probability-distributions', 'generating-functions']"
15,Probability of land ownership,Probability of land ownership,,"During a research related to economy of land ownership, I ran into an interesting probability problem: There are N citizens and N land-plots. A. Initially, each land-plot is given to a citizen selected at random. B. Then, each land is sold with probability $q$. In case it is sold, the buyer is selected at random. C. Then, each citizen that had land before B, and has no land now, is given back ONE OF the land-plots he had before step B, selected at random. This returning is repeated until all citizens that had land before B have some land now. This process (steps B-C) is repeated. The question is: how will the expected number of citizens with no land (""landless"") change as a function of time? I ran some simulations , and found out that it decreases like $\frac{1}{  A t + B}$, where t is time, and A, B are linear regression coefficients. However, I would like to find a closed formula. Currently, the only thing I managed to find is the expected number of landless at time $0$, since the probability to be landless is the probability to get no land at the initial division: $(1 - \frac{1}{N}) ^ N$. I have no idea how to continue from here. Any help will be appreciated!","During a research related to economy of land ownership, I ran into an interesting probability problem: There are N citizens and N land-plots. A. Initially, each land-plot is given to a citizen selected at random. B. Then, each land is sold with probability $q$. In case it is sold, the buyer is selected at random. C. Then, each citizen that had land before B, and has no land now, is given back ONE OF the land-plots he had before step B, selected at random. This returning is repeated until all citizens that had land before B have some land now. This process (steps B-C) is repeated. The question is: how will the expected number of citizens with no land (""landless"") change as a function of time? I ran some simulations , and found out that it decreases like $\frac{1}{  A t + B}$, where t is time, and A, B are linear regression coefficients. However, I would like to find a closed formula. Currently, the only thing I managed to find is the expected number of landless at time $0$, since the probability to be landless is the probability to get no land at the initial division: $(1 - \frac{1}{N}) ^ N$. I have no idea how to continue from here. Any help will be appreciated!",,['probability']
16,Convergence to the stable law,Convergence to the stable law,,"I am reading the book Kolmogorov A.N., Gnedenko B.V. Limit distributions for sums of independent random variables. From the general theory there it is known that if $X_i$ are symmetric i.i.d r.v such that  $P(|X_1|>x)=x^{-\alpha},\, x \geq 1$, then $(X_1+\ldots+X_n)n^{-1/\alpha}\to Y$, where c.f. of $Y$ equals $\varphi_Y(t)=e^{-c|t|^{\alpha}}, \alpha \in (0,2]$, so $Y$ has stable law of distribution. I want to check it without using that general theorems. So I start as the following, $X_1$ has density of distribution $f_X(x)=|x|^{-\alpha-1}\alpha/2, |x|>1$. Using Levy theorem one must prove that $\varphi^n_{X_1}(t/n^{1/\alpha})\to \varphi_Y(t),\, n \to \infty$ for all $t\in \mathbb R$. $$\varphi_{X_1}(t/n^{1/\alpha})=\int_{1}^{\infty}\cos(tx/n^{1/\alpha})\alpha x^{-\alpha-1}\,dx,$$ for all it is evident that $t$ $\varphi_{X_1}(t/n^{1/\alpha})\to 1, n \to \infty$ so we have indeterminate form $1^\infty$. So we are to find $n(\varphi_{X_1}(t/n^{1/\alpha})-1)$, but $\varphi_{X_1}(t/n^{1/\alpha})\sim 1+1/2(2txn^{-1/\alpha})^2$, and I can only say something about $\alpha=2$ and I got stuck here. Perhaps, I made a mistake somewhere. Could you please help me? Thanks.","I am reading the book Kolmogorov A.N., Gnedenko B.V. Limit distributions for sums of independent random variables. From the general theory there it is known that if $X_i$ are symmetric i.i.d r.v such that  $P(|X_1|>x)=x^{-\alpha},\, x \geq 1$, then $(X_1+\ldots+X_n)n^{-1/\alpha}\to Y$, where c.f. of $Y$ equals $\varphi_Y(t)=e^{-c|t|^{\alpha}}, \alpha \in (0,2]$, so $Y$ has stable law of distribution. I want to check it without using that general theorems. So I start as the following, $X_1$ has density of distribution $f_X(x)=|x|^{-\alpha-1}\alpha/2, |x|>1$. Using Levy theorem one must prove that $\varphi^n_{X_1}(t/n^{1/\alpha})\to \varphi_Y(t),\, n \to \infty$ for all $t\in \mathbb R$. $$\varphi_{X_1}(t/n^{1/\alpha})=\int_{1}^{\infty}\cos(tx/n^{1/\alpha})\alpha x^{-\alpha-1}\,dx,$$ for all it is evident that $t$ $\varphi_{X_1}(t/n^{1/\alpha})\to 1, n \to \infty$ so we have indeterminate form $1^\infty$. So we are to find $n(\varphi_{X_1}(t/n^{1/\alpha})-1)$, but $\varphi_{X_1}(t/n^{1/\alpha})\sim 1+1/2(2txn^{-1/\alpha})^2$, and I can only say something about $\alpha=2$ and I got stuck here. Perhaps, I made a mistake somewhere. Could you please help me? Thanks.",,"['probability', 'probability-theory', 'limits', 'stochastic-processes', 'convergence-divergence']"
17,Interpretation of a simple probabilistic term in a calculation,Interpretation of a simple probabilistic term in a calculation,,"I'm reading through my notes on the evolution of random graphs and have come unstuck trying to figure out the meaning of a probabilistic term which appears, and was hoping you could help - it's not very complex, I don't think. I'm working in the space of random graphs $G_{n,p}$; graphs on $n$ vertices with all edges having (independent) probability $p$ of existing. I'm in the final leg of a multi-part proof, and for this final part I want to show that the ""number of vertices on tree components"" is given by a random number satisfying a certain condition which I don't think needs specifying here, though I can do if it will help. We've specified $p = \frac{\gamma \log{n}}{n}$, where $\gamma$ is some number between $\frac{1}{k+1},\,2$ (and $k \geq 1$ is some value needed elsewhere in the proof). So, the line I can't understand is as follows, copied verbatim: $\mu_l = \mathbb{E}(\text{# vertices on } l\text{-tree components}); \sum_{2}^k \mu_l = 2 \sum {n\choose l} l^{l-2} ( \frac{\gamma \log{n}}{n})^{l-1} (1 - \frac{\gamma \log{n}}{n})^{ln}$. I'm unclear precisely what $\mu_l$ is actually meant to be defining the expectation of (the total number of vertices which lie in precisely one tree, of size exactly $l$, perhaps?), but am trying to deduce it from the sum. So, as far as I can figure things, we're saying $\mu_l = 2 {n \choose{l}} l^{l-2}p^{l-1} (1-p)^{ln}$: it looks to me like $n \choose l$ arises as the number of ways you can choose $l$ of the $n$ vertices of the graph, $l^{l-2}$ is the total number of possible trees on these $l$ vertices (Cayley's formula) and $p^{l-1}$ is the probability of having the $(l-1)$ edges of the tree on $l$ vertices, as occurring in the expectation - whatever it is actually an expectation of. However, I can't see where the factor of $2$ and the $(1-p)^{ln}$ come from: $(1-p)^j$  usually corresponds to fixing a certain number $j$ of edges as being not present in the graph, but for $j=nl$ that would suggest you want to have all possible edges from some $l$ vertices to some $n$ vertices not present; but $n$ vertices would of course be the entire graph, so that makes no sense. I wonder if it might be missing something, and should instead be (e.g.) $j=l(n-l)$? Are the notes copied down wrong (I don't think they are, my friend's notes are identical), or is it just a matter of understanding what this expectation is being taken of? Or perhaps my equals sign should be an 'approximately equals'. I'm sure it'll be obvious as soon as someone points out what I'm missing, so don't worry about going into excessive detail with any answers, just a brief explanation of what the term might mean would be warmly welcomed, if you have any better ideas than me. Many thanks.","I'm reading through my notes on the evolution of random graphs and have come unstuck trying to figure out the meaning of a probabilistic term which appears, and was hoping you could help - it's not very complex, I don't think. I'm working in the space of random graphs $G_{n,p}$; graphs on $n$ vertices with all edges having (independent) probability $p$ of existing. I'm in the final leg of a multi-part proof, and for this final part I want to show that the ""number of vertices on tree components"" is given by a random number satisfying a certain condition which I don't think needs specifying here, though I can do if it will help. We've specified $p = \frac{\gamma \log{n}}{n}$, where $\gamma$ is some number between $\frac{1}{k+1},\,2$ (and $k \geq 1$ is some value needed elsewhere in the proof). So, the line I can't understand is as follows, copied verbatim: $\mu_l = \mathbb{E}(\text{# vertices on } l\text{-tree components}); \sum_{2}^k \mu_l = 2 \sum {n\choose l} l^{l-2} ( \frac{\gamma \log{n}}{n})^{l-1} (1 - \frac{\gamma \log{n}}{n})^{ln}$. I'm unclear precisely what $\mu_l$ is actually meant to be defining the expectation of (the total number of vertices which lie in precisely one tree, of size exactly $l$, perhaps?), but am trying to deduce it from the sum. So, as far as I can figure things, we're saying $\mu_l = 2 {n \choose{l}} l^{l-2}p^{l-1} (1-p)^{ln}$: it looks to me like $n \choose l$ arises as the number of ways you can choose $l$ of the $n$ vertices of the graph, $l^{l-2}$ is the total number of possible trees on these $l$ vertices (Cayley's formula) and $p^{l-1}$ is the probability of having the $(l-1)$ edges of the tree on $l$ vertices, as occurring in the expectation - whatever it is actually an expectation of. However, I can't see where the factor of $2$ and the $(1-p)^{ln}$ come from: $(1-p)^j$  usually corresponds to fixing a certain number $j$ of edges as being not present in the graph, but for $j=nl$ that would suggest you want to have all possible edges from some $l$ vertices to some $n$ vertices not present; but $n$ vertices would of course be the entire graph, so that makes no sense. I wonder if it might be missing something, and should instead be (e.g.) $j=l(n-l)$? Are the notes copied down wrong (I don't think they are, my friend's notes are identical), or is it just a matter of understanding what this expectation is being taken of? Or perhaps my equals sign should be an 'approximately equals'. I'm sure it'll be obvious as soon as someone points out what I'm missing, so don't worry about going into excessive detail with any answers, just a brief explanation of what the term might mean would be warmly welcomed, if you have any better ideas than me. Many thanks.",,"['probability', 'graph-theory', 'random']"
18,Poisson distribution process,Poisson distribution process,,"Meteorites hit the surface of the moon, treat as an infinite plane. The meteorites that have hit the moon over the last 1 million yrs  can be modeled as a Poisson process with constant intensity lambda. Suppose that each meteorite leaves a circular crater of random radius, and the craters' radii are i.i.d. from a distribution having density f. Assume that f(r) = 0 for r suciently large. For a bounded (Borel) set A, let V (A) be the area of A that is not covered by a crater from a meteorite that hit in the last million years. Since this is a Poisson process, how can we get the E(Area of A not covered by a crater from a meteorite that hit in the last million years) and the Var(Area of A not covered by a crater from a meteorite that hit in the last million years) I do note that E(X) = 1/p","Meteorites hit the surface of the moon, treat as an infinite plane. The meteorites that have hit the moon over the last 1 million yrs  can be modeled as a Poisson process with constant intensity lambda. Suppose that each meteorite leaves a circular crater of random radius, and the craters' radii are i.i.d. from a distribution having density f. Assume that f(r) = 0 for r suciently large. For a bounded (Borel) set A, let V (A) be the area of A that is not covered by a crater from a meteorite that hit in the last million years. Since this is a Poisson process, how can we get the E(Area of A not covered by a crater from a meteorite that hit in the last million years) and the Var(Area of A not covered by a crater from a meteorite that hit in the last million years) I do note that E(X) = 1/p",,['probability']
19,Implementation of the Baum-Welch algorithm for HMM parameter estimation,Implementation of the Baum-Welch algorithm for HMM parameter estimation,,"In order to learn HMM thoroughly, I am implementing (in Matlab) the various algorithms for the basic questions of HMM. I've implemented the Viterbi, posterior-decoding, and the forward-backward algorithms successfully, but I have one question regarding the Baum-Welch algorithm for the estimation of the HMM parameters. In the classic paper by Rabiner , the re-estimation of the transition probabilities matrix is given in equation (95), in terms of the scaled forward ($\hat\alpha$) and backward ($\hat\beta$) variables. The numerator is $$ \sum_{t=1}^{T-1}\hat\alpha_t(i)a_{ij}b_j(O_{t+1})\hat\beta_{t+1}(j) $$ where $a$ is the transition matrix, $b$ the observation matrix, and $O$ the observation sequence. However, in this HMM project guide , section 4.4, (also by Rabiner), as well is in the implementation in Matlab's function hmmtrain.m (from the statistics toolbox), there is an extra factor of $1/c_{t+1}$ in the numerator, where $c_t$ is the scaling factor of time step $t$. I followed the algebra of the definition of the re-estimation of $a$, and I still fail to understand where this factor is coming from. Any help is appreciated.","In order to learn HMM thoroughly, I am implementing (in Matlab) the various algorithms for the basic questions of HMM. I've implemented the Viterbi, posterior-decoding, and the forward-backward algorithms successfully, but I have one question regarding the Baum-Welch algorithm for the estimation of the HMM parameters. In the classic paper by Rabiner , the re-estimation of the transition probabilities matrix is given in equation (95), in terms of the scaled forward ($\hat\alpha$) and backward ($\hat\beta$) variables. The numerator is $$ \sum_{t=1}^{T-1}\hat\alpha_t(i)a_{ij}b_j(O_{t+1})\hat\beta_{t+1}(j) $$ where $a$ is the transition matrix, $b$ the observation matrix, and $O$ the observation sequence. However, in this HMM project guide , section 4.4, (also by Rabiner), as well is in the implementation in Matlab's function hmmtrain.m (from the statistics toolbox), there is an extra factor of $1/c_{t+1}$ in the numerator, where $c_t$ is the scaling factor of time step $t$. I followed the algebra of the definition of the re-estimation of $a$, and I still fail to understand where this factor is coming from. Any help is appreciated.",,"['probability', 'algorithms', 'machine-learning']"
20,Applications of Compound Poisson Processes,Applications of Compound Poisson Processes,,"I'm reading the book Non-Life Insurance Mathematics, an introduction with Stochastic Processes by Thomas Mikosch and I'm interested in applications of the Cramer-Lundberg Process to concrete examples in insurance. I tried unsuccessfully to search such examples on the Internet. Could someone suggest to me a paper or a book where I can find something? Thanks!","I'm reading the book Non-Life Insurance Mathematics, an introduction with Stochastic Processes by Thomas Mikosch and I'm interested in applications of the Cramer-Lundberg Process to concrete examples in insurance. I tried unsuccessfully to search such examples on the Internet. Could someone suggest to me a paper or a book where I can find something? Thanks!",,"['probability', 'probability-theory', 'stochastic-processes', 'finance', 'poisson-process']"
21,What's the expected value of average absolute deviation from the mean of k randomly picked numbers?,What's the expected value of average absolute deviation from the mean of k randomly picked numbers?,,Say we have to randomly pick k integral numbers out of n. The numbers are from the range < a; b >. What is the expected value of average absolute deviation from the mean for that random subset of k-numbers as the number of drawings approaches infinity? Sorry if didn't make myself clear. Could you explain the answer so that it is understandable for a not so bright high school student? EDIT: This is not homework :) Somobody asked me to program a vizualization of Lotto lottery results and I just got curious about the statistics of that.,Say we have to randomly pick k integral numbers out of n. The numbers are from the range < a; b >. What is the expected value of average absolute deviation from the mean for that random subset of k-numbers as the number of drawings approaches infinity? Sorry if didn't make myself clear. Could you explain the answer so that it is understandable for a not so bright high school student? EDIT: This is not homework :) Somobody asked me to program a vizualization of Lotto lottery results and I just got curious about the statistics of that.,,"['probability', 'statistics']"
22,Numerical gradient of approximated probability function,Numerical gradient of approximated probability function,,"I want to find an approximation of the gradient $\nabla V(J)$ of the following function $V(J) = P(X\in T(J))$. Where $X$ is a multidimensional stochastic vector with a smooth continuous probability density and $T$ is a (convex) set that depends on some parameters $J=(J_1,...,J_n)$. $V(J)$ is considered to be many times continuously differentiable. I have $N$ independent samples $x_n$ drawn from $X$. And $V(J)$ is approximated with the relative frequency $$\hat{V}(J)=\frac{ | \{n \mid x_n\in T(J) \}| }{N}.$$ The approximation is piecewise constant. Now I want to find an operator $\hat{D}$ that approximates the gradient. For example: If J is one-dimensional. The gradient could be approximated by central difference $\hat{D}\hat{V}(J) = \frac{\hat{V}(J+h)-\hat{V}(J-h)}{2h}$. The problem with central difference is that since $\hat{V}$ is piecewise constant if $h$ is chosen too small, the difference is identically $0$ for most $J$. The number of evaluations of $\hat{V}$ should be kept small as it is naturally quite expensive to compute.  The approximation should be consistent in the sense that it becomes more accurate as $N$ increases. Is there a standard way to solve this problem?  Is there a limit on how accurate the approximation could get? Does it exist a theory for this kind of problems and where can I read more about it?","I want to find an approximation of the gradient $\nabla V(J)$ of the following function $V(J) = P(X\in T(J))$. Where $X$ is a multidimensional stochastic vector with a smooth continuous probability density and $T$ is a (convex) set that depends on some parameters $J=(J_1,...,J_n)$. $V(J)$ is considered to be many times continuously differentiable. I have $N$ independent samples $x_n$ drawn from $X$. And $V(J)$ is approximated with the relative frequency $$\hat{V}(J)=\frac{ | \{n \mid x_n\in T(J) \}| }{N}.$$ The approximation is piecewise constant. Now I want to find an operator $\hat{D}$ that approximates the gradient. For example: If J is one-dimensional. The gradient could be approximated by central difference $\hat{D}\hat{V}(J) = \frac{\hat{V}(J+h)-\hat{V}(J-h)}{2h}$. The problem with central difference is that since $\hat{V}$ is piecewise constant if $h$ is chosen too small, the difference is identically $0$ for most $J$. The number of evaluations of $\hat{V}$ should be kept small as it is naturally quite expensive to compute.  The approximation should be consistent in the sense that it becomes more accurate as $N$ increases. Is there a standard way to solve this problem?  Is there a limit on how accurate the approximation could get? Does it exist a theory for this kind of problems and where can I read more about it?",,"['probability', 'numerical-methods']"
23,Measure of value of resources in a competitive game,Measure of value of resources in a competitive game,,"Let we have a competitive survival game in which a player has choice between different resources to earn. The question here is which resource should he prefer to maximize the chance of survival. I tried to find out if there already established measures of such sort, but so far without success. Some thoughts led me to the following measure of the resource' value: $$V=\int_{t_0}^{t_1} e^{\int_0^t \log (p_1(u))du}\log \frac{p_1(t)}{p_0(t)} dt$$ where $p_0(t)$ is the probability density of survival without the resource, $p_1(t)$ is the probability density of survival with the resource and $(t_0,t_1)$ is the period of time through which the resource affects the probability of survival (the time for which the value is evaluated considered t=0) I would like to know if there any similar measures already proposed and about the possible drawbacks of this proposed value. I also wonder to which extent this can be applied to real economics.","Let we have a competitive survival game in which a player has choice between different resources to earn. The question here is which resource should he prefer to maximize the chance of survival. I tried to find out if there already established measures of such sort, but so far without success. Some thoughts led me to the following measure of the resource' value: $$V=\int_{t_0}^{t_1} e^{\int_0^t \log (p_1(u))du}\log \frac{p_1(t)}{p_0(t)} dt$$ where $p_0(t)$ is the probability density of survival without the resource, $p_1(t)$ is the probability density of survival with the resource and $(t_0,t_1)$ is the period of time through which the resource affects the probability of survival (the time for which the value is evaluated considered t=0) I would like to know if there any similar measures already proposed and about the possible drawbacks of this proposed value. I also wonder to which extent this can be applied to real economics.",,"['probability', 'game-theory', 'economics']"
24,What is the Asymptotic Order of the Sum of Random Variables with non-finite Moments?,What is the Asymptotic Order of the Sum of Random Variables with non-finite Moments?,,"Suppose $X_i$ is independently and identically distributed over $i$ , and $E(|X_i|^d)$ with $d>0$ is not finite or undefined: I am wondering whether $\sum_{i=1}^N |X_i|^d$ is of any asymptotic order. Take Cauchy distribution as an example. If $d=1$ , then $N^{-1}\sum_{i=1}^N X_i$ is still Cauchy and hence $$ \sum_{i=1}^N |X_i|\ \mbox{is}\ o_p(N^{1+\delta})\ \mbox{for any}\ \delta>0 $$ That is $N^{-(1+\delta)}\sum_{i=1}^N |X_i|$ converges in probability to $0$ . If $d=2$ , $E(|X_i|^2)$ is infinite. I am not sure whether there exists $\delta>0$ such that $N^{-(1+\delta)}\sum_{i=1}^N |X_i|^2$ converges in probability to $0$ . Another interesting example is related to Central Limit Theorem (CLT) : if $X_i$ follows student t distribution with $3$ degrees of freedom independently over $i$ , then $E(X_i)=0$ , $E(X_i^2)=3$ and any moments of order higher than 3 do not exist. Due to CLT, $N^{-\frac{1}{2}}\sum_{i=1}^N X_i$ converge in distribution to $N(0,3)$ . Hence, $(N^{-\frac{1}{2}}\sum_{i=1}^N X_i)^3\leq 3!N^{-\frac{3}{2}}\sum_{i=1}\sum_{m=1}\sum_{j=0}X_iX_{i+m}X_{i+m+j}+N^{-\frac{3}{2}}\sum_{i=1}^NX_i^3=O_p(1)$ . Since the third moment of normal distribution with zero mean is $0$ , one could conjecture $E[(N^{-\frac{1}{2}}\sum_{i=1}^N X_i)^3]$ tends to $0$ (notation abuse due to the non-existence of $E(X_i^3)$ ). One should have $N^{-\frac{3}{2}}\sum_{i=1}^NX_i^3=o_p(1)$ or $\sum_{i=1}^NX_i^3=o_p(N^{\frac{3}{2}})$ . Similarly, $\sum_{i=1}^NX_i^d=o_p(N^{\frac{d}{2}})$ with $d\geq3$ if the sequence $\lbrace X_i\rbrace$ satisfies the CLT conditions, though such asymptotic orders may not be on the boundary.","Suppose is independently and identically distributed over , and with is not finite or undefined: I am wondering whether is of any asymptotic order. Take Cauchy distribution as an example. If , then is still Cauchy and hence That is converges in probability to . If , is infinite. I am not sure whether there exists such that converges in probability to . Another interesting example is related to Central Limit Theorem (CLT) : if follows student t distribution with degrees of freedom independently over , then , and any moments of order higher than 3 do not exist. Due to CLT, converge in distribution to . Hence, . Since the third moment of normal distribution with zero mean is , one could conjecture tends to (notation abuse due to the non-existence of ). One should have or . Similarly, with if the sequence satisfies the CLT conditions, though such asymptotic orders may not be on the boundary.","X_i i E(|X_i|^d) d>0 \sum_{i=1}^N |X_i|^d d=1 N^{-1}\sum_{i=1}^N X_i 
\sum_{i=1}^N |X_i|\ \mbox{is}\ o_p(N^{1+\delta})\ \mbox{for any}\ \delta>0
 N^{-(1+\delta)}\sum_{i=1}^N |X_i| 0 d=2 E(|X_i|^2) \delta>0 N^{-(1+\delta)}\sum_{i=1}^N |X_i|^2 0 X_i 3 i E(X_i)=0 E(X_i^2)=3 N^{-\frac{1}{2}}\sum_{i=1}^N X_i N(0,3) (N^{-\frac{1}{2}}\sum_{i=1}^N X_i)^3\leq 3!N^{-\frac{3}{2}}\sum_{i=1}\sum_{m=1}\sum_{j=0}X_iX_{i+m}X_{i+m+j}+N^{-\frac{3}{2}}\sum_{i=1}^NX_i^3=O_p(1) 0 E[(N^{-\frac{1}{2}}\sum_{i=1}^N X_i)^3] 0 E(X_i^3) N^{-\frac{3}{2}}\sum_{i=1}^NX_i^3=o_p(1) \sum_{i=1}^NX_i^3=o_p(N^{\frac{3}{2}}) \sum_{i=1}^NX_i^d=o_p(N^{\frac{d}{2}}) d\geq3 \lbrace X_i\rbrace","['probability', 'probability-theory', 'probability-distributions', 'central-limit-theorem', 'law-of-large-numbers']"
25,"Expected number of ""survivors"" of independent Brownian motions on the line","Expected number of ""survivors"" of independent Brownian motions on the line",,"[Edited since originally posted] I'm trying to find a closed form for the expected number of ""survivors"" of $n$ independent standard Brownian motions in $\mathbb{R}$ up to time $t > 0$ where $t$ is scaled as $\lambda/n^2$ for some positive $\lambda$ ?. By ""survivor"", I mean a Brownian motion $W_s^x$ that does not intersect any other Brownian motion up to time $t$ . I'm well aware of the Karlin-McGregor formula which gives the asymptotics of non-intersecting Brownian motions as $t\to\infty$ . I have been looking mostly at the literature for coalescing Brownian motions, but the asymptotics are not very precise. Any suggestions? If we considered three Brownian motions in $d=1$ , it's actually possible to write an explicit formula for the first hitting time. Let $\tau = \inf\left\{t\geq 0: W_t^{x_2} - W_t^{x_1} = 0 \text{ or } W_t^{x_3}-W_t^{x_2} = 0\right\}$ be the first time one of the two increment processes hit $0$ , ( $x^3 > x^2 > x^1$ ), which becomes a sort of hitting time for a cone. From a paper of O'Connell ""Collision times and exit times from cones"", the tail of this hitting time has the distribution $$P(\tau \leq t) = 2(1-\Phi(\frac{x^{2}-x^{1}}{\sqrt{2t}})) + 2(1-\Phi(\frac{x^{3}-x^{2}}{\sqrt{2t}})) - 2(1-\Phi(\frac{x^{3}-x^{1}}{\sqrt{2t}}))$$ which gives the asymptotics $$P(\tau \geq t) \sim \frac{(x^{3}-x^{2})(x^{2}-x^{1})^2+(x^{3}-x^{2})^2(x^{2}-x^{1})}{\sqrt{4\pi}}t^{-3/2}(1+o_t(1)).$$ That's cool, but I'm trying to deal with multiple Brownian motions at the same time, where neighbors from further away can intersect in finite time.","[Edited since originally posted] I'm trying to find a closed form for the expected number of ""survivors"" of independent standard Brownian motions in up to time where is scaled as for some positive ?. By ""survivor"", I mean a Brownian motion that does not intersect any other Brownian motion up to time . I'm well aware of the Karlin-McGregor formula which gives the asymptotics of non-intersecting Brownian motions as . I have been looking mostly at the literature for coalescing Brownian motions, but the asymptotics are not very precise. Any suggestions? If we considered three Brownian motions in , it's actually possible to write an explicit formula for the first hitting time. Let be the first time one of the two increment processes hit , ( ), which becomes a sort of hitting time for a cone. From a paper of O'Connell ""Collision times and exit times from cones"", the tail of this hitting time has the distribution which gives the asymptotics That's cool, but I'm trying to deal with multiple Brownian motions at the same time, where neighbors from further away can intersect in finite time.",n \mathbb{R} t > 0 t \lambda/n^2 \lambda W_s^x t t\to\infty d=1 \tau = \inf\left\{t\geq 0: W_t^{x_2} - W_t^{x_1} = 0 \text{ or } W_t^{x_3}-W_t^{x_2} = 0\right\} 0 x^3 > x^2 > x^1 P(\tau \leq t) = 2(1-\Phi(\frac{x^{2}-x^{1}}{\sqrt{2t}})) + 2(1-\Phi(\frac{x^{3}-x^{2}}{\sqrt{2t}})) - 2(1-\Phi(\frac{x^{3}-x^{1}}{\sqrt{2t}})) P(\tau \geq t) \sim \frac{(x^{3}-x^{2})(x^{2}-x^{1})^2+(x^{3}-x^{2})^2(x^{2}-x^{1})}{\sqrt{4\pi}}t^{-3/2}(1+o_t(1)).,"['probability', 'brownian-motion', 'stochastic-analysis']"
26,Mathematical definition of probability current,Mathematical definition of probability current,,"Probability currents play a role in Quantum Mechanics and Statistical Mechanics. There is a Wikipedia page on such a concept, where I read In quantum mechanics, the probability current (sometimes called probability flux) is a mathematical quantity describing the flow of probability. I would like to know if there is a related concept with a clean mathematical definition (even an implicit definition) within probability theory. I can find only physics-oriented bibliographies on this subject.","Probability currents play a role in Quantum Mechanics and Statistical Mechanics. There is a Wikipedia page on such a concept, where I read In quantum mechanics, the probability current (sometimes called probability flux) is a mathematical quantity describing the flow of probability. I would like to know if there is a related concept with a clean mathematical definition (even an implicit definition) within probability theory. I can find only physics-oriented bibliographies on this subject.",,"['probability', 'probability-theory', 'probability-distributions']"
27,Existence of disjoint paritions of $\mathbb{Z}_m$,Existence of disjoint paritions of,\mathbb{Z}_m,"For any integer $m \in \mathbb{N}$ , let $\mathbb{Z}_m$ denote the integers modulo $m$ . For any two subset $A, B \subset \mathbb{Z}_m$ , and $x \in \mathbb{Z}_m$ , denote $s(A,B,x) := \vert \{(a,b) \mid a \in A, b \in B, a+b = x \} \vert$ . For any 2-partition $A,B$ of $\mathbb{Z}_m$ , denote $c(A, B) := \max_{x \in \mathbb{Z}_m} \vert s(A,A,x) + s(B,B,x) - 2 \times s(A,B,x) \vert$ Show that for every odd $m$ , there exists a 2-partition of $\mathbb{Z}_m, (A,B)$ such that $c(A,B) = \mathcal{O} (\sqrt{m \log  m})$ I tried doing the following: Fix a $x \in \mathbb{Z}_m$ and consider the graph $G = (\mathbb{Z}_m, E)$ , where $ab \in E$ if $a+b = x$ . This graph would be a matching on $\mathbb{Z_m} \setminus \{u\}$ where $u$ is some element of $\mathbb{Z}_m$ and a loop on $u$ . Hence, our question basically becomes to find vertex cut of $G$ such that $C(A,\mathbb{Z}_m\setminus A) = \mathcal{O}(\sqrt{m\log m})$ I tried setting up a randomly sampled set $S$ such that $\Pr(x \in S) = p$ ( we will fix $p$ later ) and tried finding value of $c(S, \mathbb{Z}_M \setminus S)$ but I was not getting an appropriate result. Any hints or solution would be appreciated.","For any integer , let denote the integers modulo . For any two subset , and , denote . For any 2-partition of , denote Show that for every odd , there exists a 2-partition of such that I tried doing the following: Fix a and consider the graph , where if . This graph would be a matching on where is some element of and a loop on . Hence, our question basically becomes to find vertex cut of such that I tried setting up a randomly sampled set such that ( we will fix later ) and tried finding value of but I was not getting an appropriate result. Any hints or solution would be appreciated.","m \in \mathbb{N} \mathbb{Z}_m m A, B \subset \mathbb{Z}_m x \in \mathbb{Z}_m s(A,B,x) := \vert \{(a,b) \mid a \in A, b \in B, a+b = x \} \vert A,B \mathbb{Z}_m c(A, B) := \max_{x \in \mathbb{Z}_m} \vert s(A,A,x) + s(B,B,x) - 2 \times s(A,B,x) \vert m \mathbb{Z}_m, (A,B) c(A,B) = \mathcal{O} (\sqrt{m \log  m}) x \in \mathbb{Z}_m G = (\mathbb{Z}_m, E) ab \in E a+b = x \mathbb{Z_m} \setminus \{u\} u \mathbb{Z}_m u G C(A,\mathbb{Z}_m\setminus A) = \mathcal{O}(\sqrt{m\log m}) S \Pr(x \in S) = p p c(S, \mathbb{Z}_M \setminus S)","['probability', 'combinatorics', 'graph-theory', 'probabilistic-method']"
28,$\alpha$-mixing properties and convergence in distribution,-mixing properties and convergence in distribution,\alpha,"I have a stochastic process $\{W_t\}_{t\geq 1}$ , of uncorrelated but not indipendent random variables, with $\mathbb{E}(W_t) = 0$ and $Var(W_t)=\frac{t-1}{2}$ $\forall, t\geq 1$ (The $\{W_t\}_{t\geq 1}$ are not identically distributed). In particular I have some evidence (by Monte Carlo simulation) that: $$ D_n = 1+\frac{2}{n}\sum_{t = 1}^{n}W_t\to Z\sim Exp(1) \mbox{ as $n\to\infty$} $$ where $""\to""$ represents the convergence in distribution of the new process $D_n$ . By simply calculations $\mathbb{E}(D_n) = 1$ and $Var(D_n) = 1-\frac{1}{n}$ . Classic limit theorems do not apply in this case, because $W_t$ are not indipendent random variables (although uncorrelated). I have just read about the $\alpha$ -mixing condition of a stochastic process, and in general the  concept of ""measure of indipendence"" and ""asymptotic indipendence"". You can find the main definitions for example here: https://encyclopediaofmath.org/wiki/Strong_mixing_conditions I have seen that there are many limit theorems which use this property to prove that some kind of sequence converge in distribution and I really think that one of them will be the key to my case. For example in the following book: https://books.google.it/books/about/Limit_Theory_for_Mixing_Dependent_Random.html?id=GeRT0---hhcC&redir_esc=y there are some of them. If needed I will add the definition of $W_t$ , although I would prefer a general theorem which also covers my particular case (with the assumption that $W_t$ or $D_n$ satisfy the $\alpha$ -mixing condition). Question Do you know a limit theorem which use (or doesn't use) the $\alpha$ -mixing condition and such that my case satisfies its hypothesis? Thank you in advance for your help!","I have a stochastic process , of uncorrelated but not indipendent random variables, with and (The are not identically distributed). In particular I have some evidence (by Monte Carlo simulation) that: where represents the convergence in distribution of the new process . By simply calculations and . Classic limit theorems do not apply in this case, because are not indipendent random variables (although uncorrelated). I have just read about the -mixing condition of a stochastic process, and in general the  concept of ""measure of indipendence"" and ""asymptotic indipendence"". You can find the main definitions for example here: https://encyclopediaofmath.org/wiki/Strong_mixing_conditions I have seen that there are many limit theorems which use this property to prove that some kind of sequence converge in distribution and I really think that one of them will be the key to my case. For example in the following book: https://books.google.it/books/about/Limit_Theory_for_Mixing_Dependent_Random.html?id=GeRT0---hhcC&redir_esc=y there are some of them. If needed I will add the definition of , although I would prefer a general theorem which also covers my particular case (with the assumption that or satisfy the -mixing condition). Question Do you know a limit theorem which use (or doesn't use) the -mixing condition and such that my case satisfies its hypothesis? Thank you in advance for your help!","\{W_t\}_{t\geq 1} \mathbb{E}(W_t) = 0 Var(W_t)=\frac{t-1}{2} \forall, t\geq 1 \{W_t\}_{t\geq 1} 
D_n = 1+\frac{2}{n}\sum_{t = 1}^{n}W_t\to Z\sim Exp(1) \mbox{ as n\to\infty}
 ""\to"" D_n \mathbb{E}(D_n) = 1 Var(D_n) = 1-\frac{1}{n} W_t \alpha W_t W_t D_n \alpha \alpha","['probability', 'stochastic-processes', 'random-variables', 'weak-convergence', 'probability-limit-theorems']"
29,All linear inequalities on probabilities of pairwise intersection of events,All linear inequalities on probabilities of pairwise intersection of events,,"Let $A_1,\cdots,A_n$ be events in some probability space. Let $P_i=\Pr[A_i]$ and $P_{i,j}=\Pr[A_i\cap A_j]$ for $i\neq j$ . I'm looking for an exhaustive list of all linear inequalities that must be satisfied by the $P_i,P_{i,j}$ . Here are a few categories of inequalities: The Boole–Fréchet inequalities tell us that $$P_i+P_j-1\leq P_{i,j}\leq P_i,P_j$$ The Bonferroni inequalities give us some more, as: $$1\geq \Pr[\cup_{1\leq i\leq n} A_i]\geq \sum_{1\leq i\leq n} P_i - \sum_{1\leq i<j\leq n}P_{i,j}$$ We can also apply this inequality to any subset of the $A_i$ to get more inequalities. We can also take inequality 2., and take the conjunction of all terms with one of the events $A_i$ . For example, by applying 2. to $A_1,\cdots,A_n$ and then conjuncting with $A_n$ , we get $$P_n\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j,n}\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j}$$ where above $P_{i,j,n}=\Pr[A_i\cap A_j\cap A_n]$ . Are there any other linear inequalities, besides these above? If not, how do we show that the list above is exhaustive?","Let be events in some probability space. Let and for . I'm looking for an exhaustive list of all linear inequalities that must be satisfied by the . Here are a few categories of inequalities: The Boole–Fréchet inequalities tell us that The Bonferroni inequalities give us some more, as: We can also apply this inequality to any subset of the to get more inequalities. We can also take inequality 2., and take the conjunction of all terms with one of the events . For example, by applying 2. to and then conjuncting with , we get where above . Are there any other linear inequalities, besides these above? If not, how do we show that the list above is exhaustive?","A_1,\cdots,A_n P_i=\Pr[A_i] P_{i,j}=\Pr[A_i\cap A_j] i\neq j P_i,P_{i,j} P_i+P_j-1\leq P_{i,j}\leq P_i,P_j 1\geq \Pr[\cup_{1\leq i\leq n} A_i]\geq \sum_{1\leq i\leq n} P_i - \sum_{1\leq i<j\leq n}P_{i,j} A_i A_i A_1,\cdots,A_n A_n P_n\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j,n}\geq\sum_{1\leq i\leq n-1}P_{i,n}-\sum_{1\leq i<j\leq n-1}P_{i,j} P_{i,j,n}=\Pr[A_i\cap A_j\cap A_n]","['probability', 'probability-theory']"
30,Alternative definitions of regular conditional distribution.,Alternative definitions of regular conditional distribution.,,"Given a probability space $(\Omega,\mathcal{F},\mathbb{P})$ , Durrett (Probability: Theory and Examples, $\S 4.1.3$ ) defines the regular conditional distribution of a random variable $X$ given a sub-sigma-algebra $\mathcal{G}$ by requiring that the map $\mu(\cdot,\omega)$ is a probability measure on the state space only for almost every $\omega\in\Omega$ (that is, $\mathbb{P}$ -a.s.); Billingsley (Probability and Measure, Theorem $33.3$ ) instead requires that it is so for every $\omega\in\Omega$ . Is there any difference in these two approaches, or are they equivalent in terms of the theories that derive from them? Thanks for any explanation you can provide.","Given a probability space , Durrett (Probability: Theory and Examples, ) defines the regular conditional distribution of a random variable given a sub-sigma-algebra by requiring that the map is a probability measure on the state space only for almost every (that is, -a.s.); Billingsley (Probability and Measure, Theorem ) instead requires that it is so for every . Is there any difference in these two approaches, or are they equivalent in terms of the theories that derive from them? Thanks for any explanation you can provide.","(\Omega,\mathcal{F},\mathbb{P}) \S 4.1.3 X \mathcal{G} \mu(\cdot,\omega) \omega\in\Omega \mathbb{P} 33.3 \omega\in\Omega","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'conditional-expectation']"
31,Comparing the inequalities of Azuma and Chernoff,Comparing the inequalities of Azuma and Chernoff,,"Let $n$ be a positive integer and let $p = p(n) \in (0, 1)$ . Let $X$ be the sum of the i.i.d. random variables $Y_1,\ldots, Y_n$ , which are $1$ with probability $p$ and $0$ with probability $1-p$ . Define a martingale $X_0,\ldots, X_n$ that satisfies $X_0 = \mathbb{E}[X]$ and $X_n = X$ . Compare the bound resulting from Azuma's inequality $$\mathbb{P}[X > \mathbb{E}[X] + t]$$ with the bounds that our two versions of Chernoff's inequality give us. Which one is better? Does the answer depend on the choice of $p(n)$ and $t$ ? I will write out the inequalities as we did them in the lecture: Azuma: Let $(X_0, \ldots, X_n)$ be a martingale with $X_0 = 0$ and $\lvert X_i - X_{i-1} \rvert \le 1 \quad (\forall 1 \le i \le n)$ . Then for any $t > 0$ it holds $$\mathbb{P}[X_n \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2n} \bigg)$$ Chernoff 1: Let $X \sim Bin(n,p)$ . Then for any $t > 0$ it holds $$\mathbb{P}[X \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2(\mathbb{E}[X]+t/3} \bigg) = \exp\bigg(-\frac{t^2}{2(np+t/3)} \bigg)$$ Chernoff 2: Let $X \sim Bin(n,p)$ with $\sigma^2 := \mathbb{V}[X]$ . Then for any $t > 0$ it holds $$\mathbb{P}[X \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2(\sigma^2+t/3} \bigg) = \exp\bigg(-\frac{t^2}{2(p(1-p)+t/3)} \bigg)$$ So we need to compare the terms $2n, 2(np+t/3)$ and $2(p(1-p)+t/3)$ .  Since $n \ge 1$ it is clear that $$2(np+t/3) \ge 2(p(1-p)+t/3).$$ On the other hand I can see that for $p(n) \rightarrow 1$ and , $6n(1-p) \le t$ , which I obtained by reordering $2n \le 2np +t/3$ , we have $$2(np+t/3) \ge 2n$$ Similarly I got that for either $6n(1-p) \ge t$ or $p(n) \rightarrow 0$ together with $t \le 3n$ we have $$2(np+t/3) \le 2n.$$ However, I am wondering if a more sophisticated comparsion is possible.","Let be a positive integer and let . Let be the sum of the i.i.d. random variables , which are with probability and with probability . Define a martingale that satisfies and . Compare the bound resulting from Azuma's inequality with the bounds that our two versions of Chernoff's inequality give us. Which one is better? Does the answer depend on the choice of and ? I will write out the inequalities as we did them in the lecture: Azuma: Let be a martingale with and . Then for any it holds Chernoff 1: Let . Then for any it holds Chernoff 2: Let with . Then for any it holds So we need to compare the terms and .  Since it is clear that On the other hand I can see that for and , , which I obtained by reordering , we have Similarly I got that for either or together with we have However, I am wondering if a more sophisticated comparsion is possible.","n p = p(n) \in (0, 1) X Y_1,\ldots, Y_n 1 p 0 1-p X_0,\ldots, X_n X_0 = \mathbb{E}[X] X_n = X \mathbb{P}[X > \mathbb{E}[X] + t] p(n) t (X_0, \ldots, X_n) X_0 = 0 \lvert X_i - X_{i-1} \rvert \le 1 \quad (\forall 1 \le i \le n) t > 0 \mathbb{P}[X_n \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2n} \bigg) X \sim Bin(n,p) t > 0 \mathbb{P}[X \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2(\mathbb{E}[X]+t/3} \bigg) = \exp\bigg(-\frac{t^2}{2(np+t/3)} \bigg) X \sim Bin(n,p) \sigma^2 := \mathbb{V}[X] t > 0 \mathbb{P}[X \ge \mathbb{E}[X]+t] \le \exp\bigg(-\frac{t^2}{2(\sigma^2+t/3} \bigg) = \exp\bigg(-\frac{t^2}{2(p(1-p)+t/3)} \bigg) 2n, 2(np+t/3) 2(p(1-p)+t/3) n \ge 1 2(np+t/3) \ge 2(p(1-p)+t/3). p(n) \rightarrow 1 6n(1-p) \le t 2n \le 2np +t/3 2(np+t/3) \ge 2n 6n(1-p) \ge t p(n) \rightarrow 0 t \le 3n 2(np+t/3) \le 2n.","['probability', 'probability-theory', 'martingales', 'upper-lower-bounds']"
32,How to compare $E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}]$ and $\frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$?,How to compare  and ?,E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}] \frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]},"I have a set of random variables $X_{i}\sim N(\mu_{i},\sigma_{i}^{2}), i\in[1,L]$ , now I want to calculate the following expectation $$E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}]$$ and compare it with $$\frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$$ My guess is $$E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}] \geq \frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}$$ but I have no clues to solve this problem. Can anyone provide me with some hints to solve this problem? Thank you!","I have a set of random variables , now I want to calculate the following expectation and compare it with My guess is but I have no clues to solve this problem. Can anyone provide me with some hints to solve this problem? Thank you!","X_{i}\sim N(\mu_{i},\sigma_{i}^{2}), i\in[1,L] E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}] \frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]} E[\frac{X_i}{\sqrt{\sum_{i} X_i^2}}] \geq \frac{E[X_{i}]}{E[\sqrt{\sum_{i} X_i^2}]}","['probability', 'random-variables', 'expected-value']"
33,Dyck Paths with varying upstep size,Dyck Paths with varying upstep size,,"A problem I have been thinking about for a few years boils down to something very similar to the generalized ballot problem. Consider (something that seems very close to) a Dyck path starting at $(0,I)$ and ending at $(N,0)$ with downsteps $(1,-1)$ . The upsteps are allowed to be one of the 4: $(1,R_1), (1,R_2), (1,R_3), (1,R_4)$ . I am trying to calculate the number of paths/sequences of the $4$ upsteps, and $1$ downstep that ultimately get you from start to finish, while never going below or touching the $x$ -axis. I have been stuck along while just trying to figure this out for a single upstep, so I can't say I have tried much. Any direction appreciated!","A problem I have been thinking about for a few years boils down to something very similar to the generalized ballot problem. Consider (something that seems very close to) a Dyck path starting at and ending at with downsteps . The upsteps are allowed to be one of the 4: . I am trying to calculate the number of paths/sequences of the upsteps, and downstep that ultimately get you from start to finish, while never going below or touching the -axis. I have been stuck along while just trying to figure this out for a single upstep, so I can't say I have tried much. Any direction appreciated!","(0,I) (N,0) (1,-1) (1,R_1), (1,R_2), (1,R_3), (1,R_4) 4 1 x","['probability', 'sequences-and-series', 'combinatorics', 'probability-theory', 'combinations']"
34,A weighted sum of independent Poisson random variables $X_1 + 2X_2 + 3X_3+\dots+nX_n$,A weighted sum of independent Poisson random variables,X_1 + 2X_2 + 3X_3+\dots+nX_n,"I have that for $1 \leq i \leq n$ , the mutually independent random variables $$X_i \sim \text{Poisson}(\mu_i)$$ Then what is the distribution of $$Y \sim \sum_{i=1}^{n}i X_i$$ It looks a bit like an expectation, so I am interested to know if anything is known about it? Otherwise, the best we can do to obtain $P(Y = k)$ is to sum over integer partitions of $k$ with part numbers which are Poissonly distributed with means $\mu_1, \mu_2,\dots$ etc?","I have that for , the mutually independent random variables Then what is the distribution of It looks a bit like an expectation, so I am interested to know if anything is known about it? Otherwise, the best we can do to obtain is to sum over integer partitions of with part numbers which are Poissonly distributed with means etc?","1 \leq i \leq n X_i \sim \text{Poisson}(\mu_i) Y \sim \sum_{i=1}^{n}i X_i P(Y = k) k \mu_1, \mu_2,\dots","['probability', 'probability-distributions', 'poisson-distribution']"
35,Sampling from intersection of sphere and simplex,Sampling from intersection of sphere and simplex,,"I need to isotropically sample vectors in $\mathbb{R}^d$ of given Euclidean norm $C$ with a restriction that components are positive and add up to 1. Can someone suggest a method to do it? I tried sampling from sphere/plane intersection and rejecting points outside of the positive orthant, but the efficiency is bad. Unless $d$ is very low, this has almost 100% probability of rejection. Visualized below for $d=3$ .","I need to isotropically sample vectors in of given Euclidean norm with a restriction that components are positive and add up to 1. Can someone suggest a method to do it? I tried sampling from sphere/plane intersection and rejecting points outside of the positive orthant, but the efficiency is bad. Unless is very low, this has almost 100% probability of rejection. Visualized below for .",\mathbb{R}^d C d d=3,"['probability', 'statistics', 'sampling', 'mathematica']"
36,"If $\int_A f d\mu = \int_A g d\mu$ $\forall A \in \mathcal{F}$, then $f=g$ a.e.","If  , then  a.e.",\int_A f d\mu = \int_A g d\mu \forall A \in \mathcal{F} f=g,"Theorem 16.10. (i) If $f$ and $g$ are nonnegative and $\int_{A} f d \mu=\int_{A} g d \mu$ for all $A$ in $\mathscr{F}$ , and if $\mu$ is $\sigma$ -finite, then $f=g$ almost everywhere. Proof. Suppose that $f$ and $g$ are nonnegative and that $\int_{A} f d \mu \leq \int_{A} g d \mu$ for all $A$ in $\mathscr{F}$ . If $\mu$ is $\sigma$ -finite, there are $\mathscr{F}$ -sets $A_{n}$ such that $A_{n} \uparrow \Omega$ and $\mu\left(A_{n}\right)<\infty$ . If $B_{n}=[0 \leq g<f, g \leq n]$ , then the hypothesized inequality applied to $A_{n} \cap B_{n}$ implies $\int_{A_{n} \cap B_{n}} f d \mu \leq \int_{A_{n} \cap B_{n}} g d \mu<\infty$ (finite because $A_{n} \cap B_{n}$ has finite measure and $g$ is bounded there) and hence $\int I_{A_{n} \cap B_{n}}(f-g) d \mu=0$ . But then by Theorem 15.2(ii), the integrand is 0 almost everywhere, and so $\mu\left(A_{n} \cap B_{n}\right)=0$ . Therefore, $\mu[0 \leq g<f, g<\infty]=$ 0 , so that $f \leq g$ almost everywhere; (i) follows. I am really not understanding this proof. Why do we consider the set $B_{n}=[0 \leq g<f, g \leq n]$ ? Don't these sets miss out on the values of $g$ which are greater than $f$ ? Moreover, how does $f\leq g$ a.e. immply $f=g$ a.e.? It seems there is a case they are missing here.","Theorem 16.10. (i) If and are nonnegative and for all in , and if is -finite, then almost everywhere. Proof. Suppose that and are nonnegative and that for all in . If is -finite, there are -sets such that and . If , then the hypothesized inequality applied to implies (finite because has finite measure and is bounded there) and hence . But then by Theorem 15.2(ii), the integrand is 0 almost everywhere, and so . Therefore, 0 , so that almost everywhere; (i) follows. I am really not understanding this proof. Why do we consider the set ? Don't these sets miss out on the values of which are greater than ? Moreover, how does a.e. immply a.e.? It seems there is a case they are missing here.","f g \int_{A} f d \mu=\int_{A} g d \mu A \mathscr{F} \mu \sigma f=g f g \int_{A} f d \mu \leq \int_{A} g d \mu A \mathscr{F} \mu \sigma \mathscr{F} A_{n} A_{n} \uparrow \Omega \mu\left(A_{n}\right)<\infty B_{n}=[0 \leq g<f, g \leq n] A_{n} \cap B_{n} \int_{A_{n} \cap B_{n}} f d \mu \leq \int_{A_{n} \cap B_{n}} g d \mu<\infty A_{n} \cap B_{n} g \int I_{A_{n} \cap B_{n}}(f-g) d \mu=0 \mu\left(A_{n} \cap B_{n}\right)=0 \mu[0 \leq g<f, g<\infty]= f \leq g B_{n}=[0 \leq g<f, g \leq n] g f f\leq g f=g","['real-analysis', 'probability', 'probability-theory', 'analysis', 'probability-distributions']"
37,1955 Miklós Schweitzer Problem 3 - concentration inequality,1955 Miklós Schweitzer Problem 3 - concentration inequality,,"Source : 1955 Miklós Schweitzer Problem 3 Let the density function $f(x)$ of a random variable $\xi$ be an even function; let further $f(x)$ be monotonically non-increasing for $x > 0$ . Suppose that $$D^2= \int_\mathbb{R} x^2 f(x)\;dx$$ exists. Prove that for $\lambda > 0$ , $$P(\left|\xi\right| \geq \lambda D)\leq \frac{1}{1+\lambda^2}.$$ Attempt : As $f(\cdot)$ is even, $\mathbb{E}(\xi)=0$ . I apply Cantelli's inequality to obtain $$P(|\xi| \geq \lambda D)\leq \frac{2}{1+\lambda^2}.$$ Well, I guess it wasn't meant to be that easy haha... so I assume I must do something using monotonicity of $f(\cdot)$ . Alternatively, I wanted to apply some exponential tail bound - for instance ideally yielding something similar to the following: $$P(|\xi| \geq \lambda D)\leq^* e^{-g(\lambda)}\leq \frac{1}{1+\lambda^2},$$ where $\leq^*$ would follow by showing $\xi$ is sub-Gamma/Gaussian/etc. but I didn't put much thought into this approach. Question : Is there a way to just slightly change the initial lazy approach I took - i.e. maybe another concentration inequality in a clever way? Or is the approach totally different? I appreciate any help - thanks!","Source : 1955 Miklós Schweitzer Problem 3 Let the density function of a random variable be an even function; let further be monotonically non-increasing for . Suppose that exists. Prove that for , Attempt : As is even, . I apply Cantelli's inequality to obtain Well, I guess it wasn't meant to be that easy haha... so I assume I must do something using monotonicity of . Alternatively, I wanted to apply some exponential tail bound - for instance ideally yielding something similar to the following: where would follow by showing is sub-Gamma/Gaussian/etc. but I didn't put much thought into this approach. Question : Is there a way to just slightly change the initial lazy approach I took - i.e. maybe another concentration inequality in a clever way? Or is the approach totally different? I appreciate any help - thanks!","f(x) \xi f(x) x > 0 D^2= \int_\mathbb{R} x^2 f(x)\;dx \lambda > 0 P(\left|\xi\right| \geq \lambda D)\leq \frac{1}{1+\lambda^2}. f(\cdot) \mathbb{E}(\xi)=0 P(|\xi| \geq \lambda D)\leq \frac{2}{1+\lambda^2}. f(\cdot) P(|\xi| \geq \lambda D)\leq^* e^{-g(\lambda)}\leq \frac{1}{1+\lambda^2}, \leq^* \xi","['probability', 'probability-theory']"
38,$N$ lousy shooters in a gunfight,lousy shooters in a gunfight,N,"$N$ players are in a gunfight. Starting from player 1, each player takes turns to act in the order of $1,2,...,N,1,2,...$ . In their turn, a player randomly chooses one of the other remaining players as the target, and fires one shot at them. If hit, the target is eliminated. The game continues until there's only one survivor. All shots hit targets with probability $p$ . Is it true that when $p$ is small enough, player 1 has the highest surviving probability for any $N$ ? ---------- Edit There seems to be some misunderstanding in the comments so let me clarify. I'm asking if there exists some $p^{*}\gt 0$ , such that if everybody has hit probability $p^{*}$ , player 1's position is the best position for any choice of $N$ . For example, if $p=1$ , then player 1's position is not the best for $N=3$ . If $p=0.5$ , then player 1's position is not the best for $N=5$ . But if $p=0.45$ , player 1's position is the best for $N\leq 10000$ . (I haven't checked for more because the algorithm is $\mathcal{O}(N^3)$ and $N\leq 10000$ took me more than 20 minutes)","players are in a gunfight. Starting from player 1, each player takes turns to act in the order of . In their turn, a player randomly chooses one of the other remaining players as the target, and fires one shot at them. If hit, the target is eliminated. The game continues until there's only one survivor. All shots hit targets with probability . Is it true that when is small enough, player 1 has the highest surviving probability for any ? ---------- Edit There seems to be some misunderstanding in the comments so let me clarify. I'm asking if there exists some , such that if everybody has hit probability , player 1's position is the best position for any choice of . For example, if , then player 1's position is not the best for . If , then player 1's position is not the best for . But if , player 1's position is the best for . (I haven't checked for more because the algorithm is and took me more than 20 minutes)","N 1,2,...,N,1,2,... p p N p^{*}\gt 0 p^{*} N p=1 N=3 p=0.5 N=5 p=0.45 N\leq 10000 \mathcal{O}(N^3) N\leq 10000","['probability', 'dynamical-systems', 'recreational-mathematics', 'nonlinear-system']"
39,Suppose $E[g(W) ] = 2E[1_{ \{V\le cW \}} g(W) ]=0$ for all $g$ where $W=V+N$ and $N$ is Gaussian iff $V$ is Gaussian,Suppose  for all  where  and  is Gaussian iff  is Gaussian,E[g(W) ] = 2E[1_{ \{V\le cW \}} g(W) ]=0 g W=V+N N V,"Suppose that $W=V+N$ where $N$ is standard normal independent of $V$ .   Assume that for a given constant $c >0$ , the following equality holds for all functions $g:\mathbb{R} \to \mathbb{R}$ : \begin{align} E[g(W) ] = 2E[1_{ \{V\le cW \}} g(W) ] \end{align} Question: Can we show that the only random variable $V$ that satisfies the above is zero mean gaussian (where variance depends on $c$ )? I know how to prove the forward direction, but not the backward direction. Forward Direction First, note \begin{align} E[  1_{ \{V\le cW \}} g(W) ]&=E \left[ E \left[ 1_{ \{V\le cW \}} |W  \right]g(W) \right]\\ &=E \left[ F_{V|W}(cW|W)g(W) \right] \end{align} thus the equation of interest can be re-written as \begin{align} E[g(W) ]=2E \left[ F_{V|W}(cW|W)g(W) \right], \forall g \end{align} where $F_{V|W}(v|w)$ is a conditional cdf. Now note that if $V$ is gaussian then we have that $V|W=w$ is also gaussian \begin{align} F_{V|W}(v|w)=\Phi \left( \frac{v-E[V|W=w]}{Var(V|W=w)} \right)=\Phi \left( \frac{v-bv}{b} \right) \end{align} where we have used that $E[V|W=w]=bw$ and $Var(V|W=w)=b=\frac{E[VW]}{E[W^2]}=\frac{\sigma_V^2}{1+\sigma_V^2}$ . Therefore, if we choose $c=b$ , then \begin{align} 2E \left[ F_{V|W}(cW|W)g(W) \right]=2E \left[ \Phi \left( \frac{cW-bW}{b} \right) g(W)\right]=2 E \left[ \frac{1}{2} g(W)\right]. \end{align} This concludes the proof of the direct part. Some thoughts I was trying to use the Stein's equation to prove this but never could get it quite right.","Suppose that where is standard normal independent of .   Assume that for a given constant , the following equality holds for all functions : Question: Can we show that the only random variable that satisfies the above is zero mean gaussian (where variance depends on )? I know how to prove the forward direction, but not the backward direction. Forward Direction First, note thus the equation of interest can be re-written as where is a conditional cdf. Now note that if is gaussian then we have that is also gaussian where we have used that and . Therefore, if we choose , then This concludes the proof of the direct part. Some thoughts I was trying to use the Stein's equation to prove this but never could get it quite right.","W=V+N N V c >0 g:\mathbb{R} \to \mathbb{R} \begin{align}
E[g(W) ] = 2E[1_{ \{V\le cW \}} g(W) ]
\end{align} V c \begin{align}
E[  1_{ \{V\le cW \}} g(W) ]&=E \left[ E \left[ 1_{ \{V\le cW \}} |W  \right]g(W) \right]\\
&=E \left[ F_{V|W}(cW|W)g(W) \right]
\end{align} \begin{align}
E[g(W) ]=2E \left[ F_{V|W}(cW|W)g(W) \right], \forall g
\end{align} F_{V|W}(v|w) V V|W=w \begin{align}
F_{V|W}(v|w)=\Phi \left( \frac{v-E[V|W=w]}{Var(V|W=w)} \right)=\Phi \left( \frac{v-bv}{b} \right)
\end{align} E[V|W=w]=bw Var(V|W=w)=b=\frac{E[VW]}{E[W^2]}=\frac{\sigma_V^2}{1+\sigma_V^2} c=b \begin{align}
2E \left[ F_{V|W}(cW|W)g(W) \right]=2E \left[ \Phi \left( \frac{cW-bW}{b} \right) g(W)\right]=2 E \left[ \frac{1}{2} g(W)\right].
\end{align}","['probability', 'probability-theory', 'expected-value']"
40,"Distinguishability of Continuous Probability Distributions, Statistical Distance and Region of Uncertainty","Distinguishability of Continuous Probability Distributions, Statistical Distance and Region of Uncertainty",,"I am reading a dissertation on quantum metrology in which the second chapter deals with the notion of statistical distance. Kullback–Leibler divergence (relative entropy) is introduced as the measure of distance between probability distributions. The author gives a lemma (based on previously given lemmas ad theorems) which asserts that the probability of a type (I think in most references this is referred to as ""frequency"") $\xi$ generated according to the distribution $p$ can be approximated for large number of trials $n$ as: $$p(\xi) \approx Ce^{-nD(\xi || p)}$$ in which $D(\xi || p)$ is the relative entropy and $C$ is a constant. In order to define a Riemmanian metric on the space of probabilities the KL-divergence of $\xi=p+\delta p$ and $p$ is calculated which after approximation becomes: $$D(p+\delta p||p) \approx \frac{1}{2} \sum_a \frac{(\delta p_a)^2}{p_a}$$ Plugging this approximation in the formula for the probability of type $\xi$ we get: $$p(\xi) \propto exp(-\frac{n}{2}\sum_a \frac{(\delta p_a)^2}{p_a}) \qquad (*)$$ I understand everything up to this point. The author claims that for a neighboring probability vector $\tilde{p}=p+\delta p$ to be distinguishable from $p$ , the probability of getting a type $\xi \approx \tilde{p}$ must be low. Hence, the neighboring states will be distinguishable if: $$\sqrt{n}(\sum_a \frac{(\delta p_a)^2}{p_a})^{\frac{1}{2}}>1$$ and The region of probability space where, according to this equation, probabilities are not distinguishable, is called the region of uncertainty. I don't understand the last equation. We can rewrite the last equation as: $$\frac{n}{2}\sum_a \frac{(\delta p_a)^2}{p_a}>\frac{1}{2}$$ So basically the exponent in the $(*)$ equation must be greater than $\frac{1}{2}$ . I don't understand what is so special about $\frac{1}{2}$ . My understanding is that if two probability distributions are distinguishable, their KL-divergence must be greater than zero. In which case the probability given by $(*)$ will be smaller than one. It is very likely that I don't see a very trivial thing here. Any help is appreciated. P.S. for those of you who have access to ProQuest, the dissertation is titled ""Nonlinear quantum metrology"" by Sergio Boixo and my question is related to page 17 of this document.","I am reading a dissertation on quantum metrology in which the second chapter deals with the notion of statistical distance. Kullback–Leibler divergence (relative entropy) is introduced as the measure of distance between probability distributions. The author gives a lemma (based on previously given lemmas ad theorems) which asserts that the probability of a type (I think in most references this is referred to as ""frequency"") generated according to the distribution can be approximated for large number of trials as: in which is the relative entropy and is a constant. In order to define a Riemmanian metric on the space of probabilities the KL-divergence of and is calculated which after approximation becomes: Plugging this approximation in the formula for the probability of type we get: I understand everything up to this point. The author claims that for a neighboring probability vector to be distinguishable from , the probability of getting a type must be low. Hence, the neighboring states will be distinguishable if: and The region of probability space where, according to this equation, probabilities are not distinguishable, is called the region of uncertainty. I don't understand the last equation. We can rewrite the last equation as: So basically the exponent in the equation must be greater than . I don't understand what is so special about . My understanding is that if two probability distributions are distinguishable, their KL-divergence must be greater than zero. In which case the probability given by will be smaller than one. It is very likely that I don't see a very trivial thing here. Any help is appreciated. P.S. for those of you who have access to ProQuest, the dissertation is titled ""Nonlinear quantum metrology"" by Sergio Boixo and my question is related to page 17 of this document.",\xi p n p(\xi) \approx Ce^{-nD(\xi || p)} D(\xi || p) C \xi=p+\delta p p D(p+\delta p||p) \approx \frac{1}{2} \sum_a \frac{(\delta p_a)^2}{p_a} \xi p(\xi) \propto exp(-\frac{n}{2}\sum_a \frac{(\delta p_a)^2}{p_a}) \qquad (*) \tilde{p}=p+\delta p p \xi \approx \tilde{p} \sqrt{n}(\sum_a \frac{(\delta p_a)^2}{p_a})^{\frac{1}{2}}>1 \frac{n}{2}\sum_a \frac{(\delta p_a)^2}{p_a}>\frac{1}{2} (*) \frac{1}{2} \frac{1}{2} (*),"['probability', 'probability-distributions', 'metric-spaces', 'manifolds', 'entropy']"
41,Probability of dense subgraph in a random graph,Probability of dense subgraph in a random graph,,"What is the probability that a random graph with $n$ vertices and degree sequence $\left(d_i\right)_{i=1..n}$ has a subgraph of $k$ vertices and density $\delta$ ? The random graph is typically obtained through the configuration model . The (simpler) case where the degree sequence is not prescribed but only the number $m$ of edges, leading to an Erdős–Rényi random graph , is also of interest. Context: I generate random graphs and then add dense subgraphs to them in order to test an algorithm for detecting them, but I need to know if it is reasonable to assume that the initial graph has no such subgraph.","What is the probability that a random graph with vertices and degree sequence has a subgraph of vertices and density ? The random graph is typically obtained through the configuration model . The (simpler) case where the degree sequence is not prescribed but only the number of edges, leading to an Erdős–Rényi random graph , is also of interest. Context: I generate random graphs and then add dense subgraphs to them in order to test an algorithm for detecting them, but I need to know if it is reasonable to assume that the initial graph has no such subgraph.",n \left(d_i\right)_{i=1..n} k \delta m,"['probability', 'combinatorics', 'graph-theory', 'random-graphs', 'random-matrices']"
42,Optimal stopping of $\mathbb{E}\frac{|B_{\tau}|}{1+\tau}$,Optimal stopping of,\mathbb{E}\frac{|B_{\tau}|}{1+\tau},"Let $(B_t)_{t\ge 0}$ be a standard Brownian motion. Consider $$\sup_{\tau} \mathbb{E}\frac{|B_{\tau}|}{1+\tau},$$ where supremum is taken over stopping times $\tau$ adapted to the natural filtration of $B$ . Is there an easy way of finding this value? I know that there is a whole theory devoted to optimal stopping of stochastic processes (Snell envelope, etc.) but I am pretty sure that there should be a straightforward and short solution - it was given as a one point (out of 5) of a warmup question in lecture notes - the rest of them were more or less obvious....","Let be a standard Brownian motion. Consider where supremum is taken over stopping times adapted to the natural filtration of . Is there an easy way of finding this value? I know that there is a whole theory devoted to optimal stopping of stochastic processes (Snell envelope, etc.) but I am pretty sure that there should be a straightforward and short solution - it was given as a one point (out of 5) of a warmup question in lecture notes - the rest of them were more or less obvious....","(B_t)_{t\ge 0} \sup_{\tau} \mathbb{E}\frac{|B_{\tau}|}{1+\tau}, \tau B","['probability', 'stochastic-processes']"
43,Why should the sum of squares of two Independent normals be memory-less,Why should the sum of squares of two Independent normals be memory-less,,"In section 11.3.1 of Introduction to probability models by Ross (10th edition), a very strange phenomenon is described. If you take two independent standard normal distributions and sum their squares, you get an exponential distribution with rate $\frac{1}{2}$ . This is proven mechanically. I'm looking into some intuitive insight into this. The exponential distribution is known to be memory-less. And it seems this sum of squares of two i.i.d. Gaussians is also memory-less. For the exponential distribution ( $X$ ), this means (from some $t>s$ ): $$P(s <X\; \& \; X<t) = P(X<t | s<X)P(s<X) = P(X>s)P(X<t-s)$$ Now for two Gaussians, $Y$ and $Z$ we get: $$P(Y^2+Z^2 < r^2+t | Y^2+Z^2>r^2) = P(Y^2+Z^2<t)$$ Is there some connection to a fundamental property of the Gaussian that helps get an intuitive explanation for this memoryless behavior?","In section 11.3.1 of Introduction to probability models by Ross (10th edition), a very strange phenomenon is described. If you take two independent standard normal distributions and sum their squares, you get an exponential distribution with rate . This is proven mechanically. I'm looking into some intuitive insight into this. The exponential distribution is known to be memory-less. And it seems this sum of squares of two i.i.d. Gaussians is also memory-less. For the exponential distribution ( ), this means (from some ): Now for two Gaussians, and we get: Is there some connection to a fundamental property of the Gaussian that helps get an intuitive explanation for this memoryless behavior?",\frac{1}{2} X t>s P(s <X\; \& \; X<t) = P(X<t | s<X)P(s<X) = P(X>s)P(X<t-s) Y Z P(Y^2+Z^2 < r^2+t | Y^2+Z^2>r^2) = P(Y^2+Z^2<t),"['probability', 'exponential-distribution', 'gaussian', 'chi-squared']"
44,Probability that at least one triplet of points chosen will fall under the same straight line,Probability that at least one triplet of points chosen will fall under the same straight line,,"While I was observing some houseflies around, I wondered what is the probability that at least one triplet of them chosen will fall under the same straight line . I made some assumptions so as to remove ""infinity"" from the picture. Firstly, let $a$ denote the area occupied by one ""housefly"" (point) and $A$ denote the area of square plane considered. Total number of points (lattice points) is $\lfloor \frac{A}{a} \rfloor$ . Let $n$ denote number of points in one side of the square plane. $n = \sqrt{\lfloor \frac{A}{a} \rfloor}$ . I started from a very simple case. Let us consider a square with $3$ points on its sides. Let me assume that only $3$ points are chosen. For $3$ of them to fall on a straight line is equivalent to chosing $3$ points from any fixed straight line. Since there are $8$ straight lines containing $3$ points, so total number of favorable selections is ${3 \choose 3} . 8 = 8$ and total possible selections is $ {9 \choose 3} = 84$ . Therefore Probability $= 0.095$ . Let us now consider a square with $4$ points on its sides. Let me assume that only $3$ points are chosen. Since there are $10$ straight lines containing $4$ points and $4$ straight lines containing $3$ points, so total number of favorable selections is ${4 \choose 3}.10 + {3 \choose 3}.4 = 44$ and total possible selections is ${16 \choose 3} = 560$ . Therefore probability $= 0.078$ . Let us now consider a square with $5$ points on its sides. Let me assume that only $3$ points are chosen. Since there are $12$ straight lines containing $5$ points, $4$ straight lines containing $4$ points and $4$ straight lines containing $3$ points, so total number of favorable selections is ${5 \choose 3}.12 + {4 \choose 3}.4 + {3 \choose 3}.4 = 140$ and total possible selections is ${25 \choose 3} = 2300$ . Therefore probability $= 0.0608$ . Generalizing this idea we get, $$P(n) = \frac{{n \choose 3}.(2n+2) + ({n-1 \choose 3}+{n-2 \choose 3}+...+{3 \choose 3}).4}{{n^2 \choose 3}}$$ or $$\boxed{P(n) = \frac{{n \choose 3}.(2n-2) + {n+1 \choose 4}.4}{{n^2 \choose 3}}}$$ where $P(n)$ denotes the probability that $3$ points chosen in a plane with lattice points $n^2$ will be collinear. Generalizing this idea to choosing $r$ points, probability that all $r$ points lie on the same straight line is $$P(n,r) = \frac{{n \choose r}.(2n-2) + {n+1 \choose r+1}.4}{{n^2 \choose r}}$$ The $P(n)$ vs $n$ graph is plotted below: Now, coming to the final part of the question, let $x$ denote the total number of points chosen. Total number of triplets is ${x \choose 3}$ . The chances of each triplet being collinear is given by $P(n)$ . Therefore using the concept of probability, it can be concluded that probability that at least one triplet of points chosen will fall under the same straight line $$\boxed{P'(n) = 1 - (1-P(n))^{x \choose 3}}$$ Here is a $P'(n)$ vs $x$ graph for $n = 100$ . The ""strange"" thing is that probability approaches $1$ for $x>30$ . Does that mean if we choose 30 points out of only $100^2$ lattice points we may not be able to make a 30-sided polygon? Am I correct in my deductions? N.B.: This question is different from this because I am not dealing with ""infinity"".","While I was observing some houseflies around, I wondered what is the probability that at least one triplet of them chosen will fall under the same straight line . I made some assumptions so as to remove ""infinity"" from the picture. Firstly, let denote the area occupied by one ""housefly"" (point) and denote the area of square plane considered. Total number of points (lattice points) is . Let denote number of points in one side of the square plane. . I started from a very simple case. Let us consider a square with points on its sides. Let me assume that only points are chosen. For of them to fall on a straight line is equivalent to chosing points from any fixed straight line. Since there are straight lines containing points, so total number of favorable selections is and total possible selections is . Therefore Probability . Let us now consider a square with points on its sides. Let me assume that only points are chosen. Since there are straight lines containing points and straight lines containing points, so total number of favorable selections is and total possible selections is . Therefore probability . Let us now consider a square with points on its sides. Let me assume that only points are chosen. Since there are straight lines containing points, straight lines containing points and straight lines containing points, so total number of favorable selections is and total possible selections is . Therefore probability . Generalizing this idea we get, or where denotes the probability that points chosen in a plane with lattice points will be collinear. Generalizing this idea to choosing points, probability that all points lie on the same straight line is The vs graph is plotted below: Now, coming to the final part of the question, let denote the total number of points chosen. Total number of triplets is . The chances of each triplet being collinear is given by . Therefore using the concept of probability, it can be concluded that probability that at least one triplet of points chosen will fall under the same straight line Here is a vs graph for . The ""strange"" thing is that probability approaches for . Does that mean if we choose 30 points out of only lattice points we may not be able to make a 30-sided polygon? Am I correct in my deductions? N.B.: This question is different from this because I am not dealing with ""infinity"".","a A \lfloor \frac{A}{a} \rfloor n n = \sqrt{\lfloor \frac{A}{a} \rfloor} 3 3 3 3 8 3 {3 \choose 3} . 8 = 8  {9 \choose 3} = 84 = 0.095 4 3 10 4 4 3 {4 \choose 3}.10 + {3 \choose 3}.4 = 44 {16 \choose 3} = 560 = 0.078 5 3 12 5 4 4 4 3 {5 \choose 3}.12 + {4 \choose 3}.4 + {3 \choose 3}.4 = 140 {25 \choose 3} = 2300 = 0.0608 P(n) = \frac{{n \choose 3}.(2n+2) + ({n-1 \choose 3}+{n-2 \choose 3}+...+{3 \choose 3}).4}{{n^2 \choose 3}} \boxed{P(n) = \frac{{n \choose 3}.(2n-2) + {n+1 \choose 4}.4}{{n^2 \choose 3}}} P(n) 3 n^2 r r P(n,r) = \frac{{n \choose r}.(2n-2) + {n+1 \choose r+1}.4}{{n^2 \choose r}} P(n) n x {x \choose 3} P(n) \boxed{P'(n) = 1 - (1-P(n))^{x \choose 3}} P'(n) x n = 100 1 x>30 100^2","['probability', 'solution-verification']"
45,Joint distribution from marginals,Joint distribution from marginals,,"I have a question about a joint distribution calculated in a paper I am reading. There are three random variable a, b and c such that $$ a,b,c \in \{+1,-1\} $$ and then the joint distribution is given by: $$ p(a,b,c) = \frac{1}{8}(1 + aE_{A} + bE_{B} + cE_{C} + abE_{AB} + acE_{AC} + bcE_{BC} + abcE_{ABC})$$ where $E_{A}$ , $E_{B}$ and $E_{C}$ are  the  single-party  marginals, $E_{AB}$ , $E_{BC}$ and $E_{AC}$ the two-party marginals, and $E_{ABC}$ is the three-body correlator. I feel like this should be something I should have seen in an introductory course on probability but I can't seem to prove it. Also if I convince myself that it's just adding up all the possible cases, I think 1 should be part of the other expected values (i.e. it is already considered in them) so I don't see the point in adding it separately. Also would we have the same expression if the possible values were $\{+1,0\}$ (or any other set of size 2) ? I am used to the notation $E$ as the expected value, but this is totally unrelated to that and it is about marginals. Am I correct? I would be pleased to see a complete proof or a link to study this fact. It also adds: Note that the positivity of $p(a,b,c)$ implies  constraints  on  marginals,  in  particular $p(+ + +) + p(−−−) ≥ 0$ implies $$ E_{AB} + E_{AC} + E_{BC} ≥ −1.$$ which I don't understand.","I have a question about a joint distribution calculated in a paper I am reading. There are three random variable a, b and c such that and then the joint distribution is given by: where , and are  the  single-party  marginals, , and the two-party marginals, and is the three-body correlator. I feel like this should be something I should have seen in an introductory course on probability but I can't seem to prove it. Also if I convince myself that it's just adding up all the possible cases, I think 1 should be part of the other expected values (i.e. it is already considered in them) so I don't see the point in adding it separately. Also would we have the same expression if the possible values were (or any other set of size 2) ? I am used to the notation as the expected value, but this is totally unrelated to that and it is about marginals. Am I correct? I would be pleased to see a complete proof or a link to study this fact. It also adds: Note that the positivity of implies  constraints  on  marginals,  in  particular implies which I don't understand."," a,b,c \in \{+1,-1\}   p(a,b,c) = \frac{1}{8}(1 + aE_{A} + bE_{B} + cE_{C} + abE_{AB} + acE_{AC} + bcE_{BC} + abcE_{ABC}) E_{A} E_{B} E_{C} E_{AB} E_{BC} E_{AC} E_{ABC} \{+1,0\} E p(a,b,c) p(+ + +) + p(−−−) ≥ 0  E_{AB} + E_{AC} + E_{BC} ≥ −1.","['probability', 'probability-distributions', 'expected-value', 'marginal-distribution']"
46,The projection of an unit cube by uniformly random orthogonal pair of unit vectors becomes close to a disc as dimension becomes large.,The projection of an unit cube by uniformly random orthogonal pair of unit vectors becomes close to a disc as dimension becomes large.,,"Let $U, V \in \mathbb{R}^n$ are uniformly random orthogonal unit vectors, i.e. $||U||_2=||V||_2=1$ w.p. $1$ , $U^{T}V=0$ w.p. $1$ and $(OU,OV)$ is distributed same as $(U,V)$ for all orthogonal $n \times n$ matrices $O$ . Consider the subset of the plane $$ \mathcal{P}_n := \left\{ (z^{T}U, z^{T}V) : z \in [-1,1]^n \right\}.$$ I am asked to show that for large $n$ , $\mathcal{P}_n$ is close to a disc in the sense that $R_n/r_n$ converges in probability to $1$ , where $$ R_n := \sup \left\{||z||_2 : z \in \mathcal{P}_n \right\}, \; r_n := \inf \left\{||z||_2 : z \in \mathbb{R}^2 \setminus \mathcal{P}_n \right\}.$$ It is clear that $R_n \geq r_n$ . But I am not sure how to approach the other side. I hope convexity of the set $\mathcal{P}_n$ will be crucial and may be the representation of $(U,V)$ by Gaussian vectors might be helpful. Any suggestion is welcome.","Let are uniformly random orthogonal unit vectors, i.e. w.p. , w.p. and is distributed same as for all orthogonal matrices . Consider the subset of the plane I am asked to show that for large , is close to a disc in the sense that converges in probability to , where It is clear that . But I am not sure how to approach the other side. I hope convexity of the set will be crucial and may be the representation of by Gaussian vectors might be helpful. Any suggestion is welcome.","U, V \in \mathbb{R}^n ||U||_2=||V||_2=1 1 U^{T}V=0 1 (OU,OV) (U,V) n \times n O  \mathcal{P}_n := \left\{ (z^{T}U, z^{T}V) : z \in [-1,1]^n \right\}. n \mathcal{P}_n R_n/r_n 1  R_n := \sup \left\{||z||_2 : z \in \mathcal{P}_n \right\}, \; r_n := \inf \left\{||z||_2 : z \in \mathbb{R}^2 \setminus \mathcal{P}_n \right\}. R_n \geq r_n \mathcal{P}_n (U,V)","['probability', 'probability-theory', 'probability-limit-theorems', 'geometric-probability']"
47,A proof for Polya's urn model,A proof for Polya's urn model,,"Question An urn initially contains $r$ red and $b$ blue balls. At each stage, a ball is randomly selected and returned along with $m$ other balls of the same colour. Let $X_k$ be the number of red balls drawn in the first $k$ draws. Conjecture the value of $\mathbb{E}(X_k)$ and verify your conjecture using a conditioning argument. Hints For $1 \leq i \leq k$ , define $$Y_i = \begin{cases} 1 & \quad \mathrm{if\ draw\ } i\ \mathrm{from\ the\ urn\ is\ red}\\ 0 & \quad \mathrm{if\ draw\ } i\ \mathrm{from\ the\ urn\ is\ blue} \end{cases}$$ and evaluate $\mathbb{E}[Y_3 \mid X_2]$ . My working Conjecture: $\mathbb{E}(X_k) = \dfrac {kr} {r + b}$ . Let $R_k$ and $B_k$ be the events that a red or blue ball was drawn in the $k^{th}$ draw respectively. For $k = 2$ , we have $\begin{aligned} \mathbb{P}(R_2) & = \mathbb{P}(R_2 \mid R_1)\mathbb{P}(R_1) + \mathbb{P}(R_2 \mid B_1)\mathbb{P}(B_1)\\[1 mm] & = \frac {(r + b)\left(\frac r {r + b}\right) + m} {r + b + m}\left(\frac r {r + b}\right) + \frac {(r + b)\left(\frac r {r + b}\right)} {r + b + m}\left(1 - \frac r {r + b}\right)\\[1 mm] & = \frac m {r + b + m}\left(\frac r {r + b}\right) + \frac {(r + b)\left(\frac r {r + b}\right)} {r + b + m}\\[1 mm] & = \frac r {r + b}, \end{aligned}$ so the base case is true. Now, suppose the conjecture is true for $k = n$ and for $k = n + 1$ , we have $\begin{aligned} \mathbb{P}(R_{n + 1}) & = \mathbb{P}(R_{n + 1} \mid R_n)\mathbb{P}(R_n) + \mathbb{P}(R_{n + 1} \mid B_n)\mathbb{P}(B_n)\\[1 mm] & = \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right) + m} {r + b + nm} \left(\frac r {r + b}\right) + \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right)} {r + b + nm} \left(1 - \frac r {r + b}\right)\\[1 mm] & = \frac m {r + b + nm} \left(\frac r {r + b}\right) + \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right)} {r + b + nm}\\[1 mm] & = \frac r {r + b} \end{aligned}$ Thus, by induction, we can see that the probability of drawing a red ball at every stage is constant at $\dfrac r {r + b}$ and independent of drawing any ball at any other stage, so $\mathbb{E}(X_k) = \dfrac {kr} {r + b}$ . I know that there are already quite a few proofs out there regarding Polya's urn model and although I believe my proof is valid, I am still posting this as I am not exactly sure how to make use of the hints given. Any intuitive suggestions would be greatly appreciated :)","Question An urn initially contains red and blue balls. At each stage, a ball is randomly selected and returned along with other balls of the same colour. Let be the number of red balls drawn in the first draws. Conjecture the value of and verify your conjecture using a conditioning argument. Hints For , define and evaluate . My working Conjecture: . Let and be the events that a red or blue ball was drawn in the draw respectively. For , we have so the base case is true. Now, suppose the conjecture is true for and for , we have Thus, by induction, we can see that the probability of drawing a red ball at every stage is constant at and independent of drawing any ball at any other stage, so . I know that there are already quite a few proofs out there regarding Polya's urn model and although I believe my proof is valid, I am still posting this as I am not exactly sure how to make use of the hints given. Any intuitive suggestions would be greatly appreciated :)","r b m X_k k \mathbb{E}(X_k) 1 \leq i \leq k Y_i =
\begin{cases}
1 & \quad \mathrm{if\ draw\ } i\ \mathrm{from\ the\ urn\ is\ red}\\
0 & \quad \mathrm{if\ draw\ } i\ \mathrm{from\ the\ urn\ is\ blue}
\end{cases} \mathbb{E}[Y_3 \mid X_2] \mathbb{E}(X_k) = \dfrac {kr} {r + b} R_k B_k k^{th} k = 2 \begin{aligned}
\mathbb{P}(R_2) & = \mathbb{P}(R_2 \mid R_1)\mathbb{P}(R_1) + \mathbb{P}(R_2 \mid B_1)\mathbb{P}(B_1)\\[1 mm]
& = \frac {(r + b)\left(\frac r {r + b}\right) + m} {r + b + m}\left(\frac r {r + b}\right) + \frac {(r + b)\left(\frac r {r + b}\right)} {r + b + m}\left(1 - \frac r {r + b}\right)\\[1 mm]
& = \frac m {r + b + m}\left(\frac r {r + b}\right) + \frac {(r + b)\left(\frac r {r + b}\right)} {r + b + m}\\[1 mm]
& = \frac r {r + b},
\end{aligned} k = n k = n + 1 \begin{aligned}
\mathbb{P}(R_{n + 1}) & = \mathbb{P}(R_{n + 1} \mid R_n)\mathbb{P}(R_n) + \mathbb{P}(R_{n + 1} \mid B_n)\mathbb{P}(B_n)\\[1 mm]
& = \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right) + m} {r + b + nm} \left(\frac r {r + b}\right) + \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right)} {r + b + nm} \left(1 - \frac r {r + b}\right)\\[1 mm]
& = \frac m {r + b + nm} \left(\frac r {r + b}\right) + \frac {[r + b + (n - 1)m]\left(\frac r {r + b}\right)} {r + b + nm}\\[1 mm]
& = \frac r {r + b}
\end{aligned} \dfrac r {r + b} \mathbb{E}(X_k) = \dfrac {kr} {r + b}","['probability', 'solution-verification', 'expected-value', 'conditional-expectation', 'polya-urn-model']"
48,Expectation value of sum of 3 poker cards (variation),Expectation value of sum of 3 poker cards (variation),,"Assume you have a deck of 52 cards with the values K = 13, Q = 12, J = 11, 10 = 10,..., 2 = 2 and A = 1. Suppose you draw 3 cards $X_1, X_2$ and $X_3$ at random from the deck of 52 cards. Then you find out the minimum value from the 3 chosen cards and then remove it from the choice and then uniformly at random choose another card from the remaining deck and put it with your other 2 chosen cards. What is the Expected Value of the Final 3 chosen cards: a) The 3rd card is drawn such that the minimum valued card is put back into the deck b) The 3rd card is drawn such that the minimum valued card is NOT put back into the deck Source : This was asked to me in a quant trading firm interview, so I am guessing that instead of the brute force method of calculating the PMFs for each scenario, there must be a better method which leverages the linearity of the expectation operator. My Views For scenario (a), what I feel is that atleast for the first scenario - the answer should be 7 $\times$ 3 = 21 since even if the minimum card is resampled, it would not affect the other two chosen cards (thus both of them would have an individual expectation of 7) and then since the new card would be chosen from the remaining deck, it would have the same distribution as the minimum valued card But any of the 3 positions in the tuple could have been the minimum value, so essentially all the 3 card choices would have the same distribution, thus the same expectation (= 7) and the answer should be 7 $\times$ 3 = 21. I'm not at all sure how I would proceed with scenario (b) But what I feel is, if we can get the expected value of the minimum of 3 draws, we can subtract it from 7 and that would most probably be the expected value of the last card drawn. For this question, I would really appreciate some different viewpoints or entire solutions themselves, thank you!","Assume you have a deck of 52 cards with the values K = 13, Q = 12, J = 11, 10 = 10,..., 2 = 2 and A = 1. Suppose you draw 3 cards and at random from the deck of 52 cards. Then you find out the minimum value from the 3 chosen cards and then remove it from the choice and then uniformly at random choose another card from the remaining deck and put it with your other 2 chosen cards. What is the Expected Value of the Final 3 chosen cards: a) The 3rd card is drawn such that the minimum valued card is put back into the deck b) The 3rd card is drawn such that the minimum valued card is NOT put back into the deck Source : This was asked to me in a quant trading firm interview, so I am guessing that instead of the brute force method of calculating the PMFs for each scenario, there must be a better method which leverages the linearity of the expectation operator. My Views For scenario (a), what I feel is that atleast for the first scenario - the answer should be 7 3 = 21 since even if the minimum card is resampled, it would not affect the other two chosen cards (thus both of them would have an individual expectation of 7) and then since the new card would be chosen from the remaining deck, it would have the same distribution as the minimum valued card But any of the 3 positions in the tuple could have been the minimum value, so essentially all the 3 card choices would have the same distribution, thus the same expectation (= 7) and the answer should be 7 3 = 21. I'm not at all sure how I would proceed with scenario (b) But what I feel is, if we can get the expected value of the minimum of 3 draws, we can subtract it from 7 and that would most probably be the expected value of the last card drawn. For this question, I would really appreciate some different viewpoints or entire solutions themselves, thank you!","X_1, X_2 X_3 \times \times","['probability', 'expected-value', 'conditional-probability', 'card-games']"
49,Estimating the total variation distance between two continuous distributions with identical support,Estimating the total variation distance between two continuous distributions with identical support,,"Say I am given two datasets $S_{\mathcal{Q}}$ and $S_{\mathcal{P}}$ sampled from the continuous distributions $\mathcal{Q}$ and $\mathcal{P}$ respectively. Assume that both $\mathcal{Q}$ and $\mathcal{P}$ have the same support, namely some compact set of $\mathcal{C} \in \mathbb{R}^{d}$ . Is there an efficient way to measure the total variation distance between $P$ and $Q$ using the samples $S_{\mathcal{Q}}$ and $S_{\mathcal{P}}$ ? My first thought was just to perform density estimation then numerical integration. I guess histograms would be efficient as the integration would be cheap. But is there a more efficient way with theoretical guarantees that perhaps avoids density estimation all together?","Say I am given two datasets and sampled from the continuous distributions and respectively. Assume that both and have the same support, namely some compact set of . Is there an efficient way to measure the total variation distance between and using the samples and ? My first thought was just to perform density estimation then numerical integration. I guess histograms would be efficient as the integration would be cheap. But is there a more efficient way with theoretical guarantees that perhaps avoids density estimation all together?",S_{\mathcal{Q}} S_{\mathcal{P}} \mathcal{Q} \mathcal{P} \mathcal{Q} \mathcal{P} \mathcal{C} \in \mathbb{R}^{d} P Q S_{\mathcal{Q}} S_{\mathcal{P}},"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
50,Local limit theorems for circular/spherical distributions,Local limit theorems for circular/spherical distributions,,"Here are some of the classical density functions for spherical distributions (on the $\mathcal{S}^{d-1}$ sphere, living in the Euclidean space $\mathbb{R}^d$ ): $$\mathbf{x}\mapsto \frac{(\kappa/2)^{d/2-1}}{2 \pi^{d/2} I_{d/2-1}(\kappa)} \exp(\kappa \mathbf{x}^{\top} \boldsymbol{\mu}), \qquad (\text{called the Fisher-von Mises-Langevin density}),$$ $$\mathbf{x}\mapsto \frac{1}{a(\kappa,A)} \exp(\kappa \mathbf{x}^{\top} \boldsymbol{\mu} + \mathbf{x}^{\top} A \mathbf{x}), \qquad (\text{called the Fisher-Bingham density}),$$ $$\mathbf{x}\mapsto \frac{\Gamma(d/2)}{2 \pi^{d/2} M(\frac{1}{2},\frac{d}{2},\kappa)} \exp(\kappa (\mathbf{x}^{\top} \boldsymbol{\mu})^2), \qquad (\text{called the Watson density}),$$ where $\kappa\geq 0$ is a concentration parameter, $\boldsymbol{\mu}\in \mathcal{S}^{d-1}$ is a location parameter, $A$ is a symmetric $d\times d$ matrix, and both $a(\kappa,A)$ and $M(\frac{1}{2},\frac{d}{2},\kappa)$ are the appropriate normalizing constants. I've seen very few central limit theorems in the literature relating to this setting. In particular, I found absolutely nothing regarding local limit theorems. If the parameter $\kappa$ approaches some limit ( $0$ or $\infty$ ), do any of these density functions approach a particular limit density (with a properly normalized argument)? $\textbf{Example:}$ As the intensity parameter $\lambda$ of a Poisson $(\lambda)$ distribution tends to $\infty$ , the probability mass function tends to the density of a $\text{Normal}(\lambda,\lambda)$ distribution. Is there any analogous results/conjectures in the context of spherical distributions?","Here are some of the classical density functions for spherical distributions (on the sphere, living in the Euclidean space ): where is a concentration parameter, is a location parameter, is a symmetric matrix, and both and are the appropriate normalizing constants. I've seen very few central limit theorems in the literature relating to this setting. In particular, I found absolutely nothing regarding local limit theorems. If the parameter approaches some limit ( or ), do any of these density functions approach a particular limit density (with a properly normalized argument)? As the intensity parameter of a Poisson distribution tends to , the probability mass function tends to the density of a distribution. Is there any analogous results/conjectures in the context of spherical distributions?","\mathcal{S}^{d-1} \mathbb{R}^d \mathbf{x}\mapsto \frac{(\kappa/2)^{d/2-1}}{2 \pi^{d/2} I_{d/2-1}(\kappa)} \exp(\kappa \mathbf{x}^{\top} \boldsymbol{\mu}), \qquad (\text{called the Fisher-von Mises-Langevin density}), \mathbf{x}\mapsto \frac{1}{a(\kappa,A)} \exp(\kappa \mathbf{x}^{\top} \boldsymbol{\mu} + \mathbf{x}^{\top} A \mathbf{x}), \qquad (\text{called the Fisher-Bingham density}), \mathbf{x}\mapsto \frac{\Gamma(d/2)}{2 \pi^{d/2} M(\frac{1}{2},\frac{d}{2},\kappa)} \exp(\kappa (\mathbf{x}^{\top} \boldsymbol{\mu})^2), \qquad (\text{called the Watson density}), \kappa\geq 0 \boldsymbol{\mu}\in \mathcal{S}^{d-1} A d\times d a(\kappa,A) M(\frac{1}{2},\frac{d}{2},\kappa) \kappa 0 \infty \textbf{Example:} \lambda (\lambda) \infty \text{Normal}(\lambda,\lambda)","['probability', 'statistics', 'central-limit-theorem', 'probability-limit-theorems']"
51,Changing of variable in a distribution defined by a convolution,Changing of variable in a distribution defined by a convolution,,"Let $f$ , $g$ , and $h$ denote probability distributions such that $$f(x) = \int_0^x g(x')h(x-x')~dx'$$ where $x$ only takes non-negative values. Now, suppose we want to perform a change of variable from $x$ to $y=q(x)$ in the above equation. My question is: how does the convolution equation change when we perform the change of variables. In other words, after changing the variable to $y$ , suppose the distributions corresponding to $f(x)$ , $g(x)$ , and $h(x)$ are $F(y)$ , $G(y)$ , and $H(y)$ , then can we write the equation satisfied by $F$ , $G$ , and $H$ ? Take for example $y=\log x$ . Here is my attempt: We can see that $F(y) = e^yf(e^y)$ where $F(y)$ denotes the distribution of $y$ obtained by performing a change of variable $x$ to $y$ in $f$ . Similarly, we define $y' = \log x'$ , and write $G(y') = e^{y'}g(e^{y'})$ . Now we come to the the part where I am facing some difficulty: dealing with $h(x-x')$ . Approach: Define $z = x-x'$ , and $w = \log z$ . Now, $h(z) = H(w)e^{-w}$ , and substituting $w = \ln(e^y - e^{y'})$ allows us to write $$h(x-x') = \frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}}$$ This would mean, our original convolution can now be written as: $$e^{-y}F(y) = \int_{-\infty}^{e^y} e^{-y'}G(y')\cdot\frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}}~ e^{y'} dy'$$ which gives $$F(y) = \int_{-\infty}^{e^y} e^{y}~G(y')\cdot \frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}}~ dy'.$$ Here, I have literally written each term in the first equation in terms of the corresponding distribution of $y$ . Does this seem correct? If not, can someone point me in the right direction?","Let , , and denote probability distributions such that where only takes non-negative values. Now, suppose we want to perform a change of variable from to in the above equation. My question is: how does the convolution equation change when we perform the change of variables. In other words, after changing the variable to , suppose the distributions corresponding to , , and are , , and , then can we write the equation satisfied by , , and ? Take for example . Here is my attempt: We can see that where denotes the distribution of obtained by performing a change of variable to in . Similarly, we define , and write . Now we come to the the part where I am facing some difficulty: dealing with . Approach: Define , and . Now, , and substituting allows us to write This would mean, our original convolution can now be written as: which gives Here, I have literally written each term in the first equation in terms of the corresponding distribution of . Does this seem correct? If not, can someone point me in the right direction?",f g h f(x) = \int_0^x g(x')h(x-x')~dx' x x y=q(x) y f(x) g(x) h(x) F(y) G(y) H(y) F G H y=\log x F(y) = e^yf(e^y) F(y) y x y f y' = \log x' G(y') = e^{y'}g(e^{y'}) h(x-x') z = x-x' w = \log z h(z) = H(w)e^{-w} w = \ln(e^y - e^{y'}) h(x-x') = \frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}} e^{-y}F(y) = \int_{-\infty}^{e^y} e^{-y'}G(y')\cdot\frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}}~ e^{y'} dy' F(y) = \int_{-\infty}^{e^y} e^{y}~G(y')\cdot \frac{H(\ln(e^y - e^{y'}))}{e^y-e^{y'}}~ dy'. y,"['probability', 'convolution', 'change-of-variable']"
52,Conditional Bias Variance Decomposition,Conditional Bias Variance Decomposition,,"The standard bias variance decomposition says that: $$ E |f(X) - Y|^2 = \int_{\mathbb{R}^d} |f(x) - m(x)|^2 \mu(dx) + E|m(X) - Y|^2, $$ where $\mu$ is some distribution over $X$ . I am trying to understand the conditional version of this decomposition: Let $D_n= \{(X_i,Y_i)\}_{i=1}^n$ be an i.i.d. sample and we construct an estimate $m_n(x) := m_n(x,D_n)$ based on the sample. We then have \begin{align*} E [|m_n(X) - Y|^2\mid D_n]  &= \int_{\mathbb{R}^d} |m_n(x) - m(x)|^2 \mu(dx)  + E|m(X) - Y|^2\\ &= E|m_n(X) - m(X)|^2   + E|m(X) - Y|^2, \end{align*} These are equations 1.1 and 1.2 in the Nonparametric Statistics book by Gyorfi. What I am confused about is the first term in the second equation, should this not be a conditional (on $D_n$ ) expectation? That is: $$ E [|m_n(X) - Y|^2\mid D_n] = E [|m_n(X) - m(X)|^2 \mid D_n]  + E|m(X) - Y|^2 $$ update: I think what is happening is: \begin{align*} E [|m_n(X) - m(X)|^2 \mid D_n]  &= \int_{m_n} \int_x |m_n(x) - m(x)|^2 dP(x,m_n|D_n)\\ &= \int_{m_n} \int_x |m_n(x) - m(x)|^2 d\mu(x) dP(m_n|D_n)\\ &= E\left ( \int_x |m_n(x) - m(x)|^2 d\mu(x) \mid D_n \right )\\ &= E\left ( E[|m_n(X) - m(X)|^2]\mid D_n \right )\\ &= E[|m_n(X) - m(X)|^2], \end{align*} where the second equality is due to $X$ being an independent draw, and the last equality is due to the fact that $m_n$ is measurable with respect to $D_n$ , so the expectation of the inner expectation conditional on $D_n$ is just equal to the inner expectation almost surely.","The standard bias variance decomposition says that: where is some distribution over . I am trying to understand the conditional version of this decomposition: Let be an i.i.d. sample and we construct an estimate based on the sample. We then have These are equations 1.1 and 1.2 in the Nonparametric Statistics book by Gyorfi. What I am confused about is the first term in the second equation, should this not be a conditional (on ) expectation? That is: update: I think what is happening is: where the second equality is due to being an independent draw, and the last equality is due to the fact that is measurable with respect to , so the expectation of the inner expectation conditional on is just equal to the inner expectation almost surely.","
E |f(X) - Y|^2 = \int_{\mathbb{R}^d} |f(x) - m(x)|^2 \mu(dx) + E|m(X) - Y|^2,
 \mu X D_n= \{(X_i,Y_i)\}_{i=1}^n m_n(x) := m_n(x,D_n) \begin{align*}
E [|m_n(X) - Y|^2\mid D_n] 
&= \int_{\mathbb{R}^d} |m_n(x) - m(x)|^2 \mu(dx)  + E|m(X) - Y|^2\\
&= E|m_n(X) - m(X)|^2   + E|m(X) - Y|^2,
\end{align*} D_n 
E [|m_n(X) - Y|^2\mid D_n] = E [|m_n(X) - m(X)|^2 \mid D_n]  + E|m(X) - Y|^2
 \begin{align*}
E [|m_n(X) - m(X)|^2 \mid D_n] 
&= \int_{m_n} \int_x |m_n(x) - m(x)|^2 dP(x,m_n|D_n)\\
&= \int_{m_n} \int_x |m_n(x) - m(x)|^2 d\mu(x) dP(m_n|D_n)\\
&= E\left ( \int_x |m_n(x) - m(x)|^2 d\mu(x) \mid D_n \right )\\
&= E\left ( E[|m_n(X) - m(X)|^2]\mid D_n \right )\\
&= E[|m_n(X) - m(X)|^2],
\end{align*} X m_n D_n D_n","['probability', 'statistics', 'conditional-probability', 'machine-learning']"
53,"Modifying the covariance of Brownian motion, what Gaussian process do we get?","Modifying the covariance of Brownian motion, what Gaussian process do we get?",,"If $(B_t)$ is a Brownian motion, then $Cov(B_t,B_s)=min(t,s)$ . Take a Gaussian process $(X_t)$ with mean $0$ and covariance $Cov(X_t,X_s)=f(min(t,s))$ for a given function $f$ such that the covariance is still positive definite. Is $X$ related to Brownian motion ? For example, let's take an easy function: $f(x)=x+1$ , then clearly $X_t=B_{t+1}$ , or more generally, if $f$ is monotone increasing, then $X_t=B_{f(t)}= \int_0^t \sqrt{f'(s)} \, dB_s$ (where the last equality is valid under integrability/differentiability conditions). But what happens when $f$ is not monotone ? For example, $Cov(X_t,X_s)=min(t,s)(1-min(t,s))$ . This is a covariance function on $[0,1]$ . Can we describe $X$ using Brownian motion on $[0,1]$ ? Idea: decompose $f$ on intervals on which it is increasing and decreasing. Use the above for the increasing parts. But what happens when $f$ is decreasing ? For our example that would be $f(x)=x(1-x)$ on $[0.5,1]$ ?","If is a Brownian motion, then . Take a Gaussian process with mean and covariance for a given function such that the covariance is still positive definite. Is related to Brownian motion ? For example, let's take an easy function: , then clearly , or more generally, if is monotone increasing, then (where the last equality is valid under integrability/differentiability conditions). But what happens when is not monotone ? For example, . This is a covariance function on . Can we describe using Brownian motion on ? Idea: decompose on intervals on which it is increasing and decreasing. Use the above for the increasing parts. But what happens when is decreasing ? For our example that would be on ?","(B_t) Cov(B_t,B_s)=min(t,s) (X_t) 0 Cov(X_t,X_s)=f(min(t,s)) f X f(x)=x+1 X_t=B_{t+1} f X_t=B_{f(t)}= \int_0^t \sqrt{f'(s)} \, dB_s f Cov(X_t,X_s)=min(t,s)(1-min(t,s)) [0,1] X [0,1] f f f(x)=x(1-x) [0.5,1]","['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
54,A very strange continuous stochastic process: can we build one ? Does it exist?,A very strange continuous stochastic process: can we build one ? Does it exist?,,"Let $(\Omega, \mathcal A, \mathbb P)$ be a probability space and $X_t:\Omega \times \mathbb [0,T] \rightarrow \mathbb R$ a continuous stochastic process with the following property: There exists an $n>1$ such that for any real sequence $0<s_1<\ldots<s_n<t<T$ , denoting $\mathbb X=(X_{s_1},\ldots, X_{s_n})$ and $\mathbb A_i= Cov[X_{s_i},\mathbb X]$ , we have $Cov[X_{t},\mathbb X]= \sum\limits_{i=1}^n a_i \mathbb A_i$ for some real coefficients $a_i \neq 0 $ for all $i=1,\ldots, n$ , and if we remove any term from $\sum\limits_{i=1}^n a_i \mathbb A_i$ , then the equation has no solutions anymore. Does such stochastic process exist ? If so, can you give an example ? If not, why ? For $n=1$ , the Brownian bridge has this property. I would be very happy to find such a process for $n=2$ , and over the moon if we can build such a process for any $n$ . EDIT: In the case of Brownian bridge (so $n=1$ ), we have (writing $s_1$ as $s$ ) $Cov[X_{t},\mathbb X]=Cov[X_{t},X_s]$ and $\mathbb A_1= Cov[X_{s}, X_s]$ . We get $$Cov[X_{t},\mathbb X]= \frac{T-t}{T-s} \mathbb A_1$$ so $a_1=\frac{T-t}{T-s}$ which is never $0$ .","Let be a probability space and a continuous stochastic process with the following property: There exists an such that for any real sequence , denoting and , we have for some real coefficients for all , and if we remove any term from , then the equation has no solutions anymore. Does such stochastic process exist ? If so, can you give an example ? If not, why ? For , the Brownian bridge has this property. I would be very happy to find such a process for , and over the moon if we can build such a process for any . EDIT: In the case of Brownian bridge (so ), we have (writing as ) and . We get so which is never .","(\Omega, \mathcal A, \mathbb P) X_t:\Omega \times \mathbb [0,T] \rightarrow \mathbb R n>1 0<s_1<\ldots<s_n<t<T \mathbb X=(X_{s_1},\ldots, X_{s_n}) \mathbb A_i= Cov[X_{s_i},\mathbb X] Cov[X_{t},\mathbb X]= \sum\limits_{i=1}^n a_i \mathbb A_i a_i \neq 0  i=1,\ldots, n \sum\limits_{i=1}^n a_i \mathbb A_i n=1 n=2 n n=1 s_1 s Cov[X_{t},\mathbb X]=Cov[X_{t},X_s] \mathbb A_1= Cov[X_{s}, X_s] Cov[X_{t},\mathbb X]= \frac{T-t}{T-s} \mathbb A_1 a_1=\frac{T-t}{T-s} 0","['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'covariance']"
55,On approximating the distribution of the distance between two random points on an $n$-sphere,On approximating the distribution of the distance between two random points on an -sphere,n,"Let $\tau\in(0,2)$ a given threshold value. What is the probability that the Euclidean distance $D$ between two points $\mathbf{x}$ and $\mathbf{y}$ selected uniformly at random on the $n$ -sphere $\mathcal{S}_n=\{\mathbf{v}\in\mathbb{R}^n:\|\mathbf{v}\|_2=1\}$ , is greater than or equal to $\tau$ ? It is well known that the probability density function of the Euclidean distance $d$ between two points on the $n$ -sphere $\mathcal{S}_n=\{\mathbf{v}\in\mathbb{R}^n:\|\mathbf{v}\|_2=1\}$ is $$f(d)=\frac{\Gamma(n/2) d^{n-2}}{\sqrt{\pi}\,\Gamma((n-1)/2)}\left(1-\left(\frac{d}{2}\right)^2\right)^{\frac{n-3}{2}}~.$$ It is also well known that, as $n$ increases, $f(d)$ approaches the normal distribution $\mathcal{N}\left(\sqrt{2}, \frac{1}{2n}\right)$ . However, even with this knowledge, it is not clear to me how to obtain an analytical expression of $\Pr(d\ge\tau)$ for a finite number of dimensions $n\gg 1$ , because it seems hard to evaluate the corresponding integral. Hence, I want to find an approximation of $\Pr(d\ge\tau)$ . More precisely I want to obtain a meaningful upper bound of $\Pr(d\ge\tau)$ .","Let a given threshold value. What is the probability that the Euclidean distance between two points and selected uniformly at random on the -sphere , is greater than or equal to ? It is well known that the probability density function of the Euclidean distance between two points on the -sphere is It is also well known that, as increases, approaches the normal distribution . However, even with this knowledge, it is not clear to me how to obtain an analytical expression of for a finite number of dimensions , because it seems hard to evaluate the corresponding integral. Hence, I want to find an approximation of . More precisely I want to obtain a meaningful upper bound of .","\tau\in(0,2) D \mathbf{x} \mathbf{y} n \mathcal{S}_n=\{\mathbf{v}\in\mathbb{R}^n:\|\mathbf{v}\|_2=1\} \tau d n \mathcal{S}_n=\{\mathbf{v}\in\mathbb{R}^n:\|\mathbf{v}\|_2=1\} f(d)=\frac{\Gamma(n/2) d^{n-2}}{\sqrt{\pi}\,\Gamma((n-1)/2)}\left(1-\left(\frac{d}{2}\right)^2\right)^{\frac{n-3}{2}}~. n f(d) \mathcal{N}\left(\sqrt{2}, \frac{1}{2n}\right) \Pr(d\ge\tau) n\gg 1 \Pr(d\ge\tau) \Pr(d\ge\tau)","['probability', 'geometry', 'probability-distributions']"
56,"For $X ∼ Pois(λ)$, find $E(2^X)$, if it is finite.","For , find , if it is finite.",X ∼ Pois(λ) E(2^X),"For $X \sim Pois(λ)$ , find $\Bbb E(2^X)$ , if it is finite. Hint: Use these facts, $$\begin{align}\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}&=e^\lambda\\\sum_{k=0}^{\infty}\frac{(k+1)\lambda^k}{k!}&=e^\lambda+\lambda e^\lambda\end{align}$$ The lecture ended before we had time to cover this section and I have no notes to work from. I am having trouble getting to the answer because I am getting confused with my work. Any help would be much appreciated. I have this so far but I am not sure if it is correct, $P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!}$ for $x \in\{ 0, 1, 2, \ldots\}$ $$\begin{align}\mathbb E(2^X) &= \sum_{x=0}^{\infty} 2^x \frac{e^{-\lambda}\lambda^x}{x!}\\&= e^{-\lambda} \mathbb\sum_{x=0}^{\infty} \frac{(2\lambda)^x}{x!}\\&= e^{-\lambda} e^{2\lambda}\end{align}$$ So then $\Bbb E (2^X) = e^\lambda$","For , find , if it is finite. Hint: Use these facts, The lecture ended before we had time to cover this section and I have no notes to work from. I am having trouble getting to the answer because I am getting confused with my work. Any help would be much appreciated. I have this so far but I am not sure if it is correct, for So then","X \sim Pois(λ) \Bbb E(2^X) \begin{align}\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}&=e^\lambda\\\sum_{k=0}^{\infty}\frac{(k+1)\lambda^k}{k!}&=e^\lambda+\lambda e^\lambda\end{align} P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!} x \in\{ 0, 1, 2, \ldots\} \begin{align}\mathbb E(2^X) &= \sum_{x=0}^{\infty} 2^x \frac{e^{-\lambda}\lambda^x}{x!}\\&= e^{-\lambda} \mathbb\sum_{x=0}^{\infty} \frac{(2\lambda)^x}{x!}\\&= e^{-\lambda} e^{2\lambda}\end{align} \Bbb E (2^X) = e^\lambda","['probability', 'expected-value', 'poisson-distribution']"
57,Not following this formula for coincidence rate among 'simultaneous' Gaussian distributions?,Not following this formula for coincidence rate among 'simultaneous' Gaussian distributions?,,"I'm reading this paper, which  describes (among other things) the ""triggering"" system for a peice instrumentation used in the detection of subatomic particles in an astroparticle physics experiment. The experiment is subject to thermal noise, which can be modeled as a Gaussian with $\mu = 0$ and $\sigma = V_{rms}$ . So, given some sampling rate, a waveform can be simulated by making a random pick from the Gaussian for each sample. The instrument in question has $n$ channels, and a ""triggering"" system which is designed to record every time $k$ channels have an excursion over some threshold within a duration $\tau$ . So, for example, a trigger may be defined as $3$ channels having an excursion over $5$ within $10$ nanosecond of the first such excursion. The paper then describes a method to determine this trigger rate, which really confounds me: To determine the expected accidental rate, RL1, of $k$ -fold coincidences among the $n$ = 8 channels, consider a trial event, defined by a hit in any one of the $n$ channels, which then triggers a logic transition out of the discriminator to the logic TRUE state for a duration τ. Then consider the probability during this trial that $k > −1$ or more (k = 3 for [this experiment]) additional sub-band discriminator logic signals arrive while the first is still in TRUE state, corresponding to a hit above threshold for that channel. The rate of TRUE states per channel is $r$ . We do not for now assume $rτ  << 1$ . The probability to observe exactly $k − 1$ out of $n − 1$ additional channels in the TRUE state after one channel has changed its state is given by the binomial (e.g., the $k$ out of n ‘coin toss’) probability: $P(k-1 : n-1) = \frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k}$ The single channel ‘coin-toss’ probability p is just given by the fractional occupancy of the TRUE state per second per channel: $p = > rτ$ . The probability per trial to observe greater than $k − 1$ out of $n − 1$ channels is then just the cumulative probability density of the binomial distribution times the observation interval: $P(\geq k-1 : n-1) = \sum_{j=k-1}^{n-1}  \frac{(n-1)!}{(j)!(n-1-j)!}(r\tau)^j[1-r\tau]^{n-1}dt$ For $rτ << 1$ as it often is in practice, this simplifies to: $P(\geq k-1 : n-1) \approx \frac{(n-1)!}{(k-1)!(n-k)!}(r\tau)^{k-1}$ ...since only the leading term in the sum contributes significantly and the term $1−rτ ≃ 1$ . The rate is then determined by multiplying the single-trial probability by the number of ensemble trials per second, which is just equal to the total number of channels times the singles rate per channel. The singles rate per channel is given simply by $r$ , and the total singles rate across all channels is $nr$ . Thus the total rate in the limit of $rτ << 1$ , is: $\text{rate (RL1)} = nrP(\geq k-1:n-1) \approx  n\frac{(n-1)!}{(k-1)!(n-k)!}r^k\tau^{k-1} =  \frac{(n)!}{(k)!(n-k)!}kr^k\tau^{k-1}$ I can follow most of the logic (the first equation is (as stated) just the binomial probability formula, the second follows trivially from the first), however some of this seems ""pulled out of thin air"" to me (namely, the line involving the summation, and everything after).","I'm reading this paper, which  describes (among other things) the ""triggering"" system for a peice instrumentation used in the detection of subatomic particles in an astroparticle physics experiment. The experiment is subject to thermal noise, which can be modeled as a Gaussian with and . So, given some sampling rate, a waveform can be simulated by making a random pick from the Gaussian for each sample. The instrument in question has channels, and a ""triggering"" system which is designed to record every time channels have an excursion over some threshold within a duration . So, for example, a trigger may be defined as channels having an excursion over within nanosecond of the first such excursion. The paper then describes a method to determine this trigger rate, which really confounds me: To determine the expected accidental rate, RL1, of -fold coincidences among the = 8 channels, consider a trial event, defined by a hit in any one of the channels, which then triggers a logic transition out of the discriminator to the logic TRUE state for a duration τ. Then consider the probability during this trial that or more (k = 3 for [this experiment]) additional sub-band discriminator logic signals arrive while the first is still in TRUE state, corresponding to a hit above threshold for that channel. The rate of TRUE states per channel is . We do not for now assume . The probability to observe exactly out of additional channels in the TRUE state after one channel has changed its state is given by the binomial (e.g., the out of n ‘coin toss’) probability: The single channel ‘coin-toss’ probability p is just given by the fractional occupancy of the TRUE state per second per channel: . The probability per trial to observe greater than out of channels is then just the cumulative probability density of the binomial distribution times the observation interval: For as it often is in practice, this simplifies to: ...since only the leading term in the sum contributes significantly and the term . The rate is then determined by multiplying the single-trial probability by the number of ensemble trials per second, which is just equal to the total number of channels times the singles rate per channel. The singles rate per channel is given simply by , and the total singles rate across all channels is . Thus the total rate in the limit of , is: I can follow most of the logic (the first equation is (as stated) just the binomial probability formula, the second follows trivially from the first), however some of this seems ""pulled out of thin air"" to me (namely, the line involving the summation, and everything after).","\mu = 0 \sigma = V_{rms} n k \tau 3 5 10 k n n k
> −1 r rτ
 << 1 k − 1 n − 1 k P(k-1 : n-1) = \frac{(n-1)!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k} p =
> rτ k − 1 n − 1 P(\geq k-1 : n-1) = \sum_{j=k-1}^{n-1}
 \frac{(n-1)!}{(j)!(n-1-j)!}(r\tau)^j[1-r\tau]^{n-1}dt rτ << 1 P(\geq k-1 : n-1) \approx \frac{(n-1)!}{(k-1)!(n-k)!}(r\tau)^{k-1} 1−rτ ≃ 1 r nr rτ << 1 \text{rate (RL1)} = nrP(\geq k-1:n-1) \approx
 n\frac{(n-1)!}{(k-1)!(n-k)!}r^k\tau^{k-1} =
 \frac{(n)!}{(k)!(n-k)!}kr^k\tau^{k-1}","['probability', 'probability-theory', 'probability-distributions', 'physics', 'mathematical-physics']"
58,"Forming 2 teams of five from 11 people, but first person of each team has the captain role.","Forming 2 teams of five from 11 people, but first person of each team has the captain role.",,"(a) A coach wants to form two (2) teams of five (5) from the eleven players on the team for a scrimmage game (i.e., just a small practice game where player positions are not important). The eleventh player will act as the referee. How many ways can the coach divide the team into two teams of five players? (b) A coach wants to form two (2) teams of five (5) from the eleven players on the team for a scrimmage game, with the eleventh player again acting as the referee, but with a small change. The first person chosen for a team of five will be the captain of the team and will have extra responsibilities. For the rest of the players, their roles and positions are not important. How many ways can the coach divide the team into two teams of five players with one captain for each team? For a), I have 11!/(5!5!2!) = 1386 ways. Dividing by 5! twice because there are two teams of five where the internal order doesn't matter, and then 2! to ignore the order of the two teams. Finally, I ignored the last person (referee). For b), I simply multiplied my answer in a) by 25: 1386 x 5 x 5 = 34650. Because there could be 5 permutations of the captain role in each of the two teams. I'd appreciate it if someone can tell me if my reasoning/answers are correct, thanks.","(a) A coach wants to form two (2) teams of five (5) from the eleven players on the team for a scrimmage game (i.e., just a small practice game where player positions are not important). The eleventh player will act as the referee. How many ways can the coach divide the team into two teams of five players? (b) A coach wants to form two (2) teams of five (5) from the eleven players on the team for a scrimmage game, with the eleventh player again acting as the referee, but with a small change. The first person chosen for a team of five will be the captain of the team and will have extra responsibilities. For the rest of the players, their roles and positions are not important. How many ways can the coach divide the team into two teams of five players with one captain for each team? For a), I have 11!/(5!5!2!) = 1386 ways. Dividing by 5! twice because there are two teams of five where the internal order doesn't matter, and then 2! to ignore the order of the two teams. Finally, I ignored the last person (referee). For b), I simply multiplied my answer in a) by 25: 1386 x 5 x 5 = 34650. Because there could be 5 permutations of the captain role in each of the two teams. I'd appreciate it if someone can tell me if my reasoning/answers are correct, thanks.",,"['probability', 'combinatorics', 'permutations']"
59,Dice Probability: One event happening before another,Dice Probability: One event happening before another,,"A fair die is continuously thrown, what is the probability that a number divisible by two is thrown before a number that is divisible by three is thrown? The answer is 0.6, but I'm somehow unable to understand why. I assumed that to achieve the above, one cannot throw a 6, and hence, as the numbers that are to be considered here would be {2,3,4,6}, and what I got was 2/4, which isn't correct. Would be grateful if someone could give me pointers/tell me what the correct way to calculate this is! Thank you!","A fair die is continuously thrown, what is the probability that a number divisible by two is thrown before a number that is divisible by three is thrown? The answer is 0.6, but I'm somehow unable to understand why. I assumed that to achieve the above, one cannot throw a 6, and hence, as the numbers that are to be considered here would be {2,3,4,6}, and what I got was 2/4, which isn't correct. Would be grateful if someone could give me pointers/tell me what the correct way to calculate this is! Thank you!",,"['probability', 'dice']"
60,Tossing 12 different valued coins at the same time,Tossing 12 different valued coins at the same time,,"I toss $3$ dimes, $4$ nickels, and $5$ pennies all at the same time. What is the chance that all of the ones that land heads up is $30$ cents? This is from a timed competition, fastest answers are the best. My answer: The denominator should be $2^{12}$ since we are throwing $12$ coins. There are $5$ cases of getting $30$ cents. $3$ dimes $2$ dimes, $2$ nickels $2$ dimes, $1$ nickels, $5$ pennies $1$ dimes, $4$ nickels $1$ dimes, $3$ nickels, $5$ pennies For #1, there is only one option For #2, there is $3\choose 2$ $\cdot$ $4\choose 2$ $= 18$ , since we are picking $2$ out of $3$ dimes and $2$ out of $4$ nickels. For #3, it would be $ 3 \cdot 4 = 12$ , since we are picking $2$ out of $3$ dimes and $1$ out of $4$ nickels. For #4, it would be be $3$ For #5, it would be $ 3 \cdot 4 = 12$ . My final answer is $\frac{46}{2^{12}}$ I'm not sure this is 100% correct, and this definitely isn't the fastest way. Can anyone check if I'm correct, and if not, tell me what is wrong? Faster answers is greatly appreciated.","I toss dimes, nickels, and pennies all at the same time. What is the chance that all of the ones that land heads up is cents? This is from a timed competition, fastest answers are the best. My answer: The denominator should be since we are throwing coins. There are cases of getting cents. dimes dimes, nickels dimes, nickels, pennies dimes, nickels dimes, nickels, pennies For #1, there is only one option For #2, there is , since we are picking out of dimes and out of nickels. For #3, it would be , since we are picking out of dimes and out of nickels. For #4, it would be be For #5, it would be . My final answer is I'm not sure this is 100% correct, and this definitely isn't the fastest way. Can anyone check if I'm correct, and if not, tell me what is wrong? Faster answers is greatly appreciated.",3 4 5 30 2^{12} 12 5 30 3 2 2 2 1 5 1 4 1 3 5 3\choose 2 \cdot 4\choose 2 = 18 2 3 2 4  3 \cdot 4 = 12 2 3 1 4 3  3 \cdot 4 = 12 \frac{46}{2^{12}},['probability']
61,"Find the probability distribution of the distance, of a random point in a unit square, from some diagonal","Find the probability distribution of the distance, of a random point in a unit square, from some diagonal",,"I already did some work on this, and would like to know, if I am not wrong. Basically I have a unit square (sides $1\times1$ ). In that square I pick a point, in a random way. Next I will define random variable $X$ , whose value is defined as ""the minimal distance of the randomly picked point, from some diagonal"". I measured  the distance between the point and the diagonal, as the length of a line between the two, with the line being perpendicular to the said diagonal. Next I interpreted the minimal distance as this: I have two diagonals in the square, from which I can measure the distance. So I simply pick the one, who is lesser than the other. With these assumptions, I get following image where the blue area plus pink area (let's name it $A$ ) is the set of all points, for which $X < d$ , where $d$ is chosen minimal distance. This area I calculated as follows: Area of the ""pink strip"" can be stated as ""the area of the triangle with red lining"" minus ""the are of the green triangle"". That I calculated as $\frac{1}{8}-\frac{1}{16}(1-2\sqrt{2}d)^2$ . Next, the area $A$ is eight time the pink strip, so $A = 1 - \frac{1}{2}(1-2\sqrt{2}d)^2 $ . Now, since area of the unit square is one, than with usage of the geometric probability, the probability distribution is given as $P(X \leq d) = 1 - \frac{1}{2}(1-2\sqrt{2}d)^2$ . What I would like to know is whether I am correct or not? And if not, where did I make a mistake? Thanks for help.","I already did some work on this, and would like to know, if I am not wrong. Basically I have a unit square (sides ). In that square I pick a point, in a random way. Next I will define random variable , whose value is defined as ""the minimal distance of the randomly picked point, from some diagonal"". I measured  the distance between the point and the diagonal, as the length of a line between the two, with the line being perpendicular to the said diagonal. Next I interpreted the minimal distance as this: I have two diagonals in the square, from which I can measure the distance. So I simply pick the one, who is lesser than the other. With these assumptions, I get following image where the blue area plus pink area (let's name it ) is the set of all points, for which , where is chosen minimal distance. This area I calculated as follows: Area of the ""pink strip"" can be stated as ""the area of the triangle with red lining"" minus ""the are of the green triangle"". That I calculated as . Next, the area is eight time the pink strip, so . Now, since area of the unit square is one, than with usage of the geometric probability, the probability distribution is given as . What I would like to know is whether I am correct or not? And if not, where did I make a mistake? Thanks for help.",1\times1 X A X < d d \frac{1}{8}-\frac{1}{16}(1-2\sqrt{2}d)^2 A A = 1 - \frac{1}{2}(1-2\sqrt{2}d)^2  P(X \leq d) = 1 - \frac{1}{2}(1-2\sqrt{2}d)^2,"['probability', 'probability-theory', 'probability-distributions']"
62,Topological Markov Property and $D$-condition,Topological Markov Property and -condition,D,"I was reading two different articles and I came across these two definitions below: $(1)$ A subshift $X \subseteq \mathcal{A}^{\mathbb{Z}^d}$ has the topological Markov property (TMP) if for any finite subset $\Lambda$ of $\mathbb{Z}^d$ there exists a finite subset $\Lambda^{\prime}$ of $\mathbb{Z}^d$ with $\Lambda \subset \Lambda^{\prime}$ such that for any $x,y \in X$ , if $x_{\Lambda^{\prime}\setminus \Lambda} = y_{\Lambda^{\prime}\setminus \Lambda}$ , then $x_{\Lambda}y_{\Lambda^c} \in X$ . $(2)$ Given $\{T_n\}$ a Folner sequence for $\mathbb{Z}^d$ , the pais $(X, \{T_n\})$ satisfies the $D$ -condition if for all $n \in \mathbb{N}$ , there exists $T_n \subseteq \tilde{T}_n$ such that $\frac{|\tilde{T}_n|}{|T_n|} \to 1$ , and for all $x, y \in X$ , there exists $z \in X$ such that $z_{T_n} = x_{T_n}$ and $z_{\tilde{T}_n^c} = y_{\tilde{T}_n^c}$ . I was wondering what is the relation (and if there is, of course) between these definitions in the sense that one implies the other. If $\{T_n\}$ is a Folner sequence and $\Lambda$ is a finite set, we also have that $\{F_n\} = \{T_n\} \cup \Lambda$ is a Folner sequence. But I am not sure if assuming that (X, {T_n}) satisfies the $D$ -condition, we would obtain that $(X, \{F_n\})$ also satisfies the $D$ -condition. I guess not. This is one of the difficulties I came across while trying to prove that $D$ -condition implies TMP, which is the direction I think it might be true.","I was reading two different articles and I came across these two definitions below: A subshift has the topological Markov property (TMP) if for any finite subset of there exists a finite subset of with such that for any , if , then . Given a Folner sequence for , the pais satisfies the -condition if for all , there exists such that , and for all , there exists such that and . I was wondering what is the relation (and if there is, of course) between these definitions in the sense that one implies the other. If is a Folner sequence and is a finite set, we also have that is a Folner sequence. But I am not sure if assuming that (X, {T_n}) satisfies the -condition, we would obtain that also satisfies the -condition. I guess not. This is one of the difficulties I came across while trying to prove that -condition implies TMP, which is the direction I think it might be true.","(1) X \subseteq \mathcal{A}^{\mathbb{Z}^d} \Lambda \mathbb{Z}^d \Lambda^{\prime} \mathbb{Z}^d \Lambda \subset \Lambda^{\prime} x,y \in X x_{\Lambda^{\prime}\setminus \Lambda} = y_{\Lambda^{\prime}\setminus \Lambda} x_{\Lambda}y_{\Lambda^c} \in X (2) \{T_n\} \mathbb{Z}^d (X, \{T_n\}) D n \in \mathbb{N} T_n \subseteq \tilde{T}_n \frac{|\tilde{T}_n|}{|T_n|} \to 1 x, y \in X z \in X z_{T_n} = x_{T_n} z_{\tilde{T}_n^c} = y_{\tilde{T}_n^c} \{T_n\} \Lambda \{F_n\} = \{T_n\} \cup \Lambda D (X, \{F_n\}) D D","['probability', 'general-topology', 'dynamical-systems']"
63,"When does $\mathrm{Cov}[g(X),h(X)] \ge 0$ hold for all nondecreasing $g$ and $h$ on $\mathbb R^n$?",When does  hold for all nondecreasing  and  on ?,"\mathrm{Cov}[g(X),h(X)] \ge 0 g h \mathbb R^n","If $X$ is a random variable then the covariance of two nondecreasing transformations of $X$ is nonnegative (see here ). This fact is very intuitive but it turns out that it does not immediately generalize to random vectors. I am wondering what is known about the class of random vectors for which this condition holds. To formalize this question, assume from now on the following: A function $g: \mathbb R^n \to \mathbb R$ is called nondecreasing if it is nondecreasing in each component. Let $$X=(X_1,\dots,X_n): (\Omega, \mathcal A) \to (\mathbb R^n,\mathcal B^n)$$ be a random vector defined on the probability space $(\Omega, \mathcal A, P)$ . Let $g, h: \mathbb R^n \to \mathbb R$ be measurable functions with $E[g(X)^2]<\infty$ , $E[h(X)^2]<\infty$ . Theorem 1: If $g$ and $h$ are nondecreasing and $n=1$ then $$\mathrm{Cov}[g(X),h(X)] \ge 0.$$ Theorem 2: If $g$ and $h$ are nondecreasing and $n\ge 2$ then $\mathrm{Cov}[g(X),h(X)] \ge 0$ does not necessarily hold. Question: For $n\ge 2$ , what is known about the class of random vectors $X$ for which $$\mathrm{Cov}[g(X),h(X)] \ge 0\tag{*}$$ holds whenever $g$ and $h$ are nondecreasing? Some observations: Note that $(*)$ is the same as $$E[g(X)h(X)] \ge E[g(X)]E[h(X)].$$ If $X$ is such that $(*)$ holds for any nondecreasing $g$ and $h$ and $X$ possesses finite second moments then all components of $X$ are nonnegatively correlated. To see this, simply choose $g(x) = x_i$ and $h(x) = x_j$ for $i, j = 1,\dots, n$ . Theorem 3: $(*)$ holds for any nondecreasing $g$ and $h$ if the components of $X$ are stochastically independent. Proof of Theorem 1: See here . Proof of Theorem 2: Let $n = 2$ and suppose $X=(X_1, X_2)$ takes on the values $(1,0)$ and $(0,1)$ with probability $0.5$ each. Define measurable, nondecreasing functions by $g(x_1, x_2) = x_1$ and $h(x_1, x_2) = x_2$ . Then \begin{align} \mathrm{Cov}[g(X), h(X)] &= E[g(X)h(X)]-E[g(X)]E[h(X)]\\                          &= E[X_1 X_2]-E[X_1]E[X_2]\\                          &= 0-0.5\times0.5\\                          &= -0.25. \end{align} Proof of Theorem 3: We proceed by induction on the number of components $n$ . If $n=1$ we can simply apply Theorem 1. Now suppose $X$ has $n+1$ components. Write $X=(X_1, Y)$ where $Y$ consists of the last $n$ components. Then $$E[g(X_1,Y)h(X_1,Y)|Y=y] \ge E[g(X_1,Y)|Y=y]\,E[h(X_1,Y)|Y=y]$$ since $g(\cdot,y)$ and $h(\cdot,y)$ are nondecreasing functions for any $y$ . Therefore \begin{align} E[g(X)h(X)] &= E[\,E[g(X_1,Y)h(X_1,Y)|Y]\,] \\             &\ge E[\,E[g(X_1,Y)|Y]\,E[h(X_1,Y)|Y]\,]. \end{align} further, since $Y$ and $X_1$ are independent, $$\tilde g(y) := E[g(X_1,Y)|Y=y] = E[g(X_1,y)]$$ is a nondecreasing function of the $n$ -dimensional vector $y$ . Hence, by applying the induction assumption, \begin{align} E[\,E[g(X_1,Y)|Y]\,E[h(X_1,Y)|Y]\,] &= E[\,\tilde g(Y)\,\tilde h(Y)\,]\\                                     &\ge E[\,\tilde g(Y)]\,E[\tilde h(Y)\,] \\                                     &= E[g(X)]\,E[h(X)]. \end{align} It follows that $E[g(X)h(X)] \ge E[g(X)]E[h(X)].$","If is a random variable then the covariance of two nondecreasing transformations of is nonnegative (see here ). This fact is very intuitive but it turns out that it does not immediately generalize to random vectors. I am wondering what is known about the class of random vectors for which this condition holds. To formalize this question, assume from now on the following: A function is called nondecreasing if it is nondecreasing in each component. Let be a random vector defined on the probability space . Let be measurable functions with , . Theorem 1: If and are nondecreasing and then Theorem 2: If and are nondecreasing and then does not necessarily hold. Question: For , what is known about the class of random vectors for which holds whenever and are nondecreasing? Some observations: Note that is the same as If is such that holds for any nondecreasing and and possesses finite second moments then all components of are nonnegatively correlated. To see this, simply choose and for . Theorem 3: holds for any nondecreasing and if the components of are stochastically independent. Proof of Theorem 1: See here . Proof of Theorem 2: Let and suppose takes on the values and with probability each. Define measurable, nondecreasing functions by and . Then Proof of Theorem 3: We proceed by induction on the number of components . If we can simply apply Theorem 1. Now suppose has components. Write where consists of the last components. Then since and are nondecreasing functions for any . Therefore further, since and are independent, is a nondecreasing function of the -dimensional vector . Hence, by applying the induction assumption, It follows that","X X g: \mathbb R^n \to \mathbb R X=(X_1,\dots,X_n): (\Omega, \mathcal A) \to (\mathbb R^n,\mathcal B^n) (\Omega, \mathcal A, P) g, h: \mathbb R^n \to \mathbb R E[g(X)^2]<\infty E[h(X)^2]<\infty g h n=1 \mathrm{Cov}[g(X),h(X)] \ge 0. g h n\ge 2 \mathrm{Cov}[g(X),h(X)] \ge 0 n\ge 2 X \mathrm{Cov}[g(X),h(X)] \ge 0\tag{*} g h (*) E[g(X)h(X)] \ge E[g(X)]E[h(X)]. X (*) g h X X g(x) = x_i h(x) = x_j i, j = 1,\dots, n (*) g h X n = 2 X=(X_1, X_2) (1,0) (0,1) 0.5 g(x_1, x_2) = x_1 h(x_1, x_2) = x_2 \begin{align}
\mathrm{Cov}[g(X), h(X)] &= E[g(X)h(X)]-E[g(X)]E[h(X)]\\
                         &= E[X_1 X_2]-E[X_1]E[X_2]\\
                         &= 0-0.5\times0.5\\
                         &= -0.25.
\end{align} n n=1 X n+1 X=(X_1, Y) Y n E[g(X_1,Y)h(X_1,Y)|Y=y] \ge E[g(X_1,Y)|Y=y]\,E[h(X_1,Y)|Y=y] g(\cdot,y) h(\cdot,y) y \begin{align}
E[g(X)h(X)] &= E[\,E[g(X_1,Y)h(X_1,Y)|Y]\,] \\
            &\ge E[\,E[g(X_1,Y)|Y]\,E[h(X_1,Y)|Y]\,].
\end{align} Y X_1 \tilde g(y) := E[g(X_1,Y)|Y=y] = E[g(X_1,y)] n y \begin{align}
E[\,E[g(X_1,Y)|Y]\,E[h(X_1,Y)|Y]\,] &= E[\,\tilde g(Y)\,\tilde h(Y)\,]\\
                                    &\ge E[\,\tilde g(Y)]\,E[\tilde h(Y)\,] \\
                                    &= E[g(X)]\,E[h(X)].
\end{align} E[g(X)h(X)] \ge E[g(X)]E[h(X)].","['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'soft-question']"
64,"Rolling a dice twice, (1,1) = 1/36 not 2/36? (Generalized Counting Principle confusion)","Rolling a dice twice, (1,1) = 1/36 not 2/36? (Generalized Counting Principle confusion)",,"So I am confused over why the sample space of rolling a red die and green die results in (1,4) being different from (4,1), but there can only be one (1,1). Why can't there be (1 -red, 1-green) and (1-green, 1-red), if order matters? In addition, does the generalized counting principle always account for all outcomes possible? I am not sure if the generalized counting principle is counting total number of outcomes where order matters, or order does not matter. It seems that it changes depending on the problem, so I am confused on how to properly apply the generalized counting principle. For example, my textbook says: Let E 1 , E 2 , . . . , E k be sets with n 1 , n 2 , . . . , n k elements, respectively. Then there are n 1 × n 2 × n 3 × · · · × n k ways in which we can, first, choose an element of E 1 , then an element of E 2 , then an element of E 3 , . . . , and finally an element of E k . So it seems to me that order matters for the generalized counting principle? Why don't we multiply by k!, because there are also k! ways to order these Ek sets? Thank you in advance!","So I am confused over why the sample space of rolling a red die and green die results in (1,4) being different from (4,1), but there can only be one (1,1). Why can't there be (1 -red, 1-green) and (1-green, 1-red), if order matters? In addition, does the generalized counting principle always account for all outcomes possible? I am not sure if the generalized counting principle is counting total number of outcomes where order matters, or order does not matter. It seems that it changes depending on the problem, so I am confused on how to properly apply the generalized counting principle. For example, my textbook says: Let E 1 , E 2 , . . . , E k be sets with n 1 , n 2 , . . . , n k elements, respectively. Then there are n 1 × n 2 × n 3 × · · · × n k ways in which we can, first, choose an element of E 1 , then an element of E 2 , then an element of E 3 , . . . , and finally an element of E k . So it seems to me that order matters for the generalized counting principle? Why don't we multiply by k!, because there are also k! ways to order these Ek sets? Thank you in advance!",,"['probability', 'combinatorics', 'factorial', 'dice']"
65,Does proximity of moment generating functions implies proximity of characteristic functions?,Does proximity of moment generating functions implies proximity of characteristic functions?,,"Let's assume that $U$ and $V$ are non-negative random variables.     Suppose that \begin{align}  \sup_{t \ge 0 } \frac{| M_U(-t) - M_V(-t)|}{t} \le \epsilon  \end{align} where $M_U(t)$ and $M_V(t)$ are moment generating functions. A few facts: Technically $M(-t)$ is known as Laplace transform. $M(t)$ unique on an open interval. Therefore, this question is well defined. $ t \to M(-t)$ is decreasing. Question: Does this imply that \begin{align}  \sup_{t \in \mathbb{R} } \frac{| \phi_U(t) - \phi_V(t)| }{|t|}\le f(\epsilon)  \end{align} where $\phi_U(t)$ and $\phi_V(t)$ are characteristic functions, and $f$ is some function that goes to zero as $\epsilon \to 0$ . I was thinking of using that $\phi(t)=M(it)$ , but this doesn't work out.","Let's assume that and are non-negative random variables.     Suppose that where and are moment generating functions. A few facts: Technically is known as Laplace transform. unique on an open interval. Therefore, this question is well defined. is decreasing. Question: Does this imply that where and are characteristic functions, and is some function that goes to zero as . I was thinking of using that , but this doesn't work out.","U V \begin{align}
 \sup_{t \ge 0 } \frac{| M_U(-t) - M_V(-t)|}{t} \le \epsilon 
\end{align} M_U(t) M_V(t) M(-t) M(t)  t \to M(-t) \begin{align}
 \sup_{t \in \mathbb{R} } \frac{| \phi_U(t) - \phi_V(t)| }{|t|}\le f(\epsilon) 
\end{align} \phi_U(t) \phi_V(t) f \epsilon \to 0 \phi(t)=M(it)","['probability', 'probability-theory', 'characteristic-functions', 'moment-generating-functions']"
66,Solve Polya urn with generating function?,Solve Polya urn with generating function?,,"The (simple) Polya urn contains $a \in \mathbf N$ black and $b \in \mathbf N $ white balls at the initial time $t=0$ , and, at each time $t \in \mathbf Z_{+}$ , a ball is picked uniformly at random in the urn and put back in the urn together with a ball of the same color to give the composition of the urn at time $t+1$ . The Polya urn is very well understood : there is a.s. convergence of the proportion of black balls (as a bounded martingale) and the limit is $\beta(a,b)$ distributed. An alternative description of the process is : if $(U_t)_{t \in \mathbf Z_{+}}$ is a sequence of independent uniform random variables on $[0,1]$ , the number of blacks balls at time $t$ satisfies $$X_0=a , \text{ and } X_{t+1}=X_{t}+ 1_\left\{ U_t < \frac{X_t}{t+a+b}\right\}$$ I know two methods to get the aforementioned limiting distribution of the proportion $X_t/(t+a+b)$ : computing explicitly the marginal of $X_t$ (see Durrett, Probability, Theory and Examples, section 4.3.2), using the combinatorics of the problem, or use an alternative construction of the process (the first edition of the book on Markov chains by Levin Peres Wilmer used this derivation) also based on exchangeability. These proofs are not very robust though. My question : is it possible to give a proof based on the recursive equation in distribution displayed above (e.g. using convergence of the generating functions)?","The (simple) Polya urn contains black and white balls at the initial time , and, at each time , a ball is picked uniformly at random in the urn and put back in the urn together with a ball of the same color to give the composition of the urn at time . The Polya urn is very well understood : there is a.s. convergence of the proportion of black balls (as a bounded martingale) and the limit is distributed. An alternative description of the process is : if is a sequence of independent uniform random variables on , the number of blacks balls at time satisfies I know two methods to get the aforementioned limiting distribution of the proportion : computing explicitly the marginal of (see Durrett, Probability, Theory and Examples, section 4.3.2), using the combinatorics of the problem, or use an alternative construction of the process (the first edition of the book on Markov chains by Levin Peres Wilmer used this derivation) also based on exchangeability. These proofs are not very robust though. My question : is it possible to give a proof based on the recursive equation in distribution displayed above (e.g. using convergence of the generating functions)?","a \in \mathbf N b \in \mathbf N  t=0 t \in \mathbf Z_{+} t+1 \beta(a,b) (U_t)_{t \in \mathbf Z_{+}} [0,1] t X_0=a , \text{ and } X_{t+1}=X_{t}+ 1_\left\{ U_t < \frac{X_t}{t+a+b}\right\} X_t/(t+a+b) X_t","['probability', 'combinatorics', 'generating-functions', 'polya-urn-model']"
67,Transforming sum with alternating signs into something less prone to catastrophic cancellation,Transforming sum with alternating signs into something less prone to catastrophic cancellation,,"I'm wrestling with this formula, formally a function of the vector $\pmb{F}$ : $$\begin{aligned} S(\pmb{F}) &:=\sum_{a=0}^A (-1)^{A-a}\,\binom{A}{a}\, \Biggl[\sum_{b=0}^{A} F_b \, \binom{a}{b}\Big/\binom{K}{b}\Biggr]^B \\&\equiv \sum_{a=0}^A (-1)^{a}\,\binom{A}{a}\, \Biggl[\sum_{b=0}^{A} F_b \, \binom{A-a}{b}\Big/\binom{K}{b}\Biggr]^B \end{aligned} $$ (the sums in brackets actually end at $a$ and $A-a$ , remaining terms being zero). The coefficients are all integers and can have these orders of magnitude: $A\sim \text{10 to 1000}$ $B\sim \text{10 to 300}$ $K \sim \text{50000 to 100000}$ and the argument satisfies $0\le F_b<1$ and $\sum_b F_b <1$ , which implies that $S(\pmb{F})\ge0$ . Unfortunately the terms of this sum (in $a$ ) easily assume extremely similar but opposite values, leading to catastrophic cancellation in numerical computations. For example one can get meaningless results with negative sign. Taking $b$ -independent terms out of the brackets doesn't help, because it doesn't change the relative precision of the mutually almost-cancelling terms. I've also tried grouping together the terms with $\tbinom{A}{a}$ and $\tbinom{A}{A-a}$ , but catastrophic cancellation occurs (especially if $A$ is even) even across such groups. Since I'm numerically dealing with this formula in R, I've tried using the Rmpf package for arbitrary-precision computation. It manages to get the correct result (which I can compute with Mathematica) in some cases, as opposed to machine-precision computation, but it still fails in some situations. And it makes the computation much slower. Does anyone have some clever ideas of how to transform this formula to avoid the catastrophic cancellation? I'd be really grateful for your help. Context This formula arises in network theory, in the problem of guessing the number of connections from a set of nodes to another, disjoint set of nodes. The first set has $K$ nodes, the second can be assumed to have infinite nodes. We know that exactly $A$ nodes of the first set connect to exactly $B$ nodes of the second, but we don't know which node connects to which. Each of the $A$ nodes must connect to at least one of the $B$ nodes; but not all $B$ nodes need to be receiving a connection. $F_b$ represents the fraction (relative frequency) of nodes in the second set that receive $b$ connections from the first set. The formula, derivable with some combinatorics, gives the probability (except for a factor independent of $\pmb{F}$ ) for a particular frequency distribution $\pmb{F}$ . The alternating sum appears from the probability-sum rule with more than two terms. Roughly speaking, we're calculating $1$ minus the probability that at least one node from the first set has no connections, or at least two nodes from the first set have no connections, and so on. Ultimately I'd be interested in the logarithm of $S(\pmb{F})$ . From this context, I'd be happy to hear suggestions for slight variations or limits that may lead to a more manageable formula. Cheers!","I'm wrestling with this formula, formally a function of the vector : (the sums in brackets actually end at and , remaining terms being zero). The coefficients are all integers and can have these orders of magnitude: and the argument satisfies and , which implies that . Unfortunately the terms of this sum (in ) easily assume extremely similar but opposite values, leading to catastrophic cancellation in numerical computations. For example one can get meaningless results with negative sign. Taking -independent terms out of the brackets doesn't help, because it doesn't change the relative precision of the mutually almost-cancelling terms. I've also tried grouping together the terms with and , but catastrophic cancellation occurs (especially if is even) even across such groups. Since I'm numerically dealing with this formula in R, I've tried using the Rmpf package for arbitrary-precision computation. It manages to get the correct result (which I can compute with Mathematica) in some cases, as opposed to machine-precision computation, but it still fails in some situations. And it makes the computation much slower. Does anyone have some clever ideas of how to transform this formula to avoid the catastrophic cancellation? I'd be really grateful for your help. Context This formula arises in network theory, in the problem of guessing the number of connections from a set of nodes to another, disjoint set of nodes. The first set has nodes, the second can be assumed to have infinite nodes. We know that exactly nodes of the first set connect to exactly nodes of the second, but we don't know which node connects to which. Each of the nodes must connect to at least one of the nodes; but not all nodes need to be receiving a connection. represents the fraction (relative frequency) of nodes in the second set that receive connections from the first set. The formula, derivable with some combinatorics, gives the probability (except for a factor independent of ) for a particular frequency distribution . The alternating sum appears from the probability-sum rule with more than two terms. Roughly speaking, we're calculating minus the probability that at least one node from the first set has no connections, or at least two nodes from the first set have no connections, and so on. Ultimately I'd be interested in the logarithm of . From this context, I'd be happy to hear suggestions for slight variations or limits that may lead to a more manageable formula. Cheers!","\pmb{F} \begin{aligned}
S(\pmb{F}) &:=\sum_{a=0}^A (-1)^{A-a}\,\binom{A}{a}\,
\Biggl[\sum_{b=0}^{A} F_b \,
\binom{a}{b}\Big/\binom{K}{b}\Biggr]^B
\\&\equiv
\sum_{a=0}^A (-1)^{a}\,\binom{A}{a}\,
\Biggl[\sum_{b=0}^{A} F_b \,
\binom{A-a}{b}\Big/\binom{K}{b}\Biggr]^B
\end{aligned}
 a A-a A\sim \text{10 to 1000} B\sim \text{10 to 300} K \sim \text{50000 to 100000} 0\le F_b<1 \sum_b F_b <1 S(\pmb{F})\ge0 a b \tbinom{A}{a} \tbinom{A}{A-a} A K A B A B B F_b b \pmb{F} \pmb{F} 1 S(\pmb{F})","['probability', 'combinatorics', 'catastrophic-cancellation']"
68,A 19th Century Probability Problems Book Written by a British Monk,A 19th Century Probability Problems Book Written by a British Monk,,"I'm trying to find this book I occasionally used for didactic and fun-inducing purposes when I taught basic probability but I can't remember the author or the title, here are the facts I vaguely recall about it: It was freely available via Google Books as it's from I believe around 19th century Most modern probability and basic combinatorics word problems are based on all those problems in the book, some people don't even realize that The author wrote it during his tenure at a monastery somewhere in modern-day UK It has a bunch of problems with rather exotic/not so popular these days games like bridge It has a problem about men and women dancing in like rows (imagine those country dances of regional British nobility you see in some Jane Austen film adaptations and the whole idea behind such musical endeavors is matchmaking) and the question of the problem had a funny wording like ""in how many way can a marriage be effectuated between the dancers at the ball?"" Any pointers to what the book is or a link to Google Books would be much, much appreciated!","I'm trying to find this book I occasionally used for didactic and fun-inducing purposes when I taught basic probability but I can't remember the author or the title, here are the facts I vaguely recall about it: It was freely available via Google Books as it's from I believe around 19th century Most modern probability and basic combinatorics word problems are based on all those problems in the book, some people don't even realize that The author wrote it during his tenure at a monastery somewhere in modern-day UK It has a bunch of problems with rather exotic/not so popular these days games like bridge It has a problem about men and women dancing in like rows (imagine those country dances of regional British nobility you see in some Jane Austen film adaptations and the whole idea behind such musical endeavors is matchmaking) and the question of the problem had a funny wording like ""in how many way can a marriage be effectuated between the dancers at the ball?"" Any pointers to what the book is or a link to Google Books would be much, much appreciated!",,"['probability', 'probability-theory', 'reference-request', 'math-history']"
69,Proof of lack of memoryless property,Proof of lack of memoryless property,,"Consider a chain which is not Markov that waits a time $T^{*}$ before leaving the current state, where $T^{*}$ has uniform distribution over the set of times $\{1, 2, 3, 4\}$ . I would like to show that it does not hold the memoryless property, i.e: $$\Bbb P(T \gt t+s \mid T \gt t)= \Bbb P(T \gt s)$$ So, here's how I tackle the problem: I deduce that $T^{*}\sim\mathcal U\{1,4\}$ (discretely uniformly distributed on the interval $[1,4]$ . So, the support is $x\in \{1,2,3,4\}$ The cumulative distribution function is: $$\text{CDF}= \frac{\lfloor x \rfloor - 1+1}{4} = \frac{\lfloor x \rfloor}{4}= \Bbb P(T \leq x)$$ $$\Rightarrow 1- \text{CDF} = \Bbb P(T \geq x)= 1- \frac{\lfloor x \rfloor}{4}= \frac{4-\lfloor x \rfloor}{4}$$ $$\Rightarrow \Bbb P(T \geq s+t | T \geq t)= \frac{\Bbb P(T\geq s+t ; T\geq t)}{\Bbb P(T \geq t)}= \frac{\Bbb P(T \geq s+t)}{\Bbb P(T \geq t)} = \frac{\frac{4- \lfloor s+t \rfloor}{4}}{\frac{4- \lfloor t \rfloor}{4}}= \frac{4 - \lfloor s+t \rfloor}{4 - \lfloor t \rfloor} \neq \Bbb P(T\geq s) = \frac{4- \lfloor s \rfloor}{4}$$ Hence $T^{*}$ does not hold the memoryless property Is this alright? Also, if $(W_k)_{k\geq}$ would be a stochastic process constructed so that it stays in each state $i$ for a time distributed to $T^{*}$ , what would be an intuitive explanation of why this is not a Markov chain?","Consider a chain which is not Markov that waits a time before leaving the current state, where has uniform distribution over the set of times . I would like to show that it does not hold the memoryless property, i.e: So, here's how I tackle the problem: I deduce that (discretely uniformly distributed on the interval . So, the support is The cumulative distribution function is: Hence does not hold the memoryless property Is this alright? Also, if would be a stochastic process constructed so that it stays in each state for a time distributed to , what would be an intuitive explanation of why this is not a Markov chain?","T^{*} T^{*} \{1, 2, 3, 4\} \Bbb P(T \gt t+s \mid T \gt t)= \Bbb P(T \gt s) T^{*}\sim\mathcal U\{1,4\} [1,4] x\in \{1,2,3,4\} \text{CDF}= \frac{\lfloor x \rfloor - 1+1}{4} = \frac{\lfloor x \rfloor}{4}= \Bbb P(T \leq x) \Rightarrow 1- \text{CDF} = \Bbb P(T \geq x)= 1- \frac{\lfloor x \rfloor}{4}= \frac{4-\lfloor x \rfloor}{4} \Rightarrow \Bbb P(T \geq s+t | T \geq t)= \frac{\Bbb P(T\geq s+t ; T\geq t)}{\Bbb P(T \geq t)}= \frac{\Bbb P(T \geq s+t)}{\Bbb P(T \geq t)} = \frac{\frac{4- \lfloor s+t \rfloor}{4}}{\frac{4- \lfloor t \rfloor}{4}}= \frac{4 - \lfloor s+t \rfloor}{4 - \lfloor t \rfloor} \neq \Bbb P(T\geq s) = \frac{4- \lfloor s \rfloor}{4} T^{*} (W_k)_{k\geq} i T^{*}","['probability', 'probability-theory']"
70,Sum of weighted independent Bernoulli RVs,Sum of weighted independent Bernoulli RVs,,"Suppose that I have $n$ independent Bernoulli variables $b_i$ with their associated probability of success $p_i$ , and a set of corresponding weights $w_i$ . I would like to say something about the distribution of the random variable defined as: $$ x=\sum_{i=1}^nw_ib_i$$ Is this a known distribution? Are there any useful results about this?","Suppose that I have independent Bernoulli variables with their associated probability of success , and a set of corresponding weights . I would like to say something about the distribution of the random variable defined as: Is this a known distribution? Are there any useful results about this?",n b_i p_i w_i  x=\sum_{i=1}^nw_ib_i,"['probability', 'probability-distributions', 'random-variables']"
71,Box with chocolates probability,Box with chocolates probability,,"I am given a box with 20 chocolates, all of them identical from the outside but 5 of them are with cherry filling, 7 with cream and 8 with nuts.   I ate 10 at random. What is the probability I ate at least one of each kind? My attempt: All different ways to select 10 chocolates out of 20 are $C(20,10)$ . Then the required probability is $1 - ( C(12,10)+C(13,10)+C(15,10) ) / C(20,10)$ I am getting about 98% but this doesn't seem correct to me... Any ideas?","I am given a box with 20 chocolates, all of them identical from the outside but 5 of them are with cherry filling, 7 with cream and 8 with nuts.   I ate 10 at random. What is the probability I ate at least one of each kind? My attempt: All different ways to select 10 chocolates out of 20 are . Then the required probability is I am getting about 98% but this doesn't seem correct to me... Any ideas?","C(20,10) 1 - ( C(12,10)+C(13,10)+C(15,10) ) / C(20,10)","['probability', 'combinatorics']"
72,A reverse Azuma's inequality for martingale,A reverse Azuma's inequality for martingale,,"I thought finding a reverse Azuma's inequality. Are there any inequality or lower bound looks like the following. Suppose $\{X_k:k=0,1,2,3...\}$ is a martingale and $$P(|X_N-X_0|\ge t)\ge f(t)$$ . I saw a similar lower bound for binomial distribution, which is as the following. Suppose $X$ follows Binomial(n,p), $$P(X\ge k) \ge \frac{1}{\sqrt{2n}}\exp(-nD(\frac{k}{n}||p))$$ . Can I find a similar inequality in martingale? Thanks !","I thought finding a reverse Azuma's inequality. Are there any inequality or lower bound looks like the following. Suppose is a martingale and . I saw a similar lower bound for binomial distribution, which is as the following. Suppose follows Binomial(n,p), . Can I find a similar inequality in martingale? Thanks !","\{X_k:k=0,1,2,3...\} P(|X_N-X_0|\ge t)\ge f(t) X P(X\ge k) \ge \frac{1}{\sqrt{2n}}\exp(-nD(\frac{k}{n}||p))","['probability', 'inequality', 'martingales', 'upper-lower-bounds']"
73,Explanation of White Noise,Explanation of White Noise,,"I have been trying to understand what a White Noise is and also a White noise Process and I have been trying to piece together different definitions that I have found online. I was wondering if my understanding of White Noise is correct These notes say that the the mathematical definition of White Noise is and $0$ mean Generalized Gaussian Processes on $S$ (I believe that $S$ needs to be a smooth function of rapid decrease?), namely $Y(\phi)$ , such that the variance of $Y(\phi)$ is $\int_{\mathbb R} \phi(t)^2 dt$ . So from my understanding, let $ \phi(t) \in S $ be a test function then we can consider the generalized stochastic process $$ X(\phi)=\int_{\mathbb R}\phi(t)dB_t $$ where $B_t$ is a brownian motion on $\mathbb R$ . So $X$ here is the Wiener Integral. It is a standard result that $X(\phi)$ is a $0$ -mean Gaussian random variable with variance $\int_{\mathbb R}\phi(t)^2dt $ . So according to the above definition, $X$ is a white noise. But, in the same notes linked above, it says that White Noise can be thought of as the derivative of a Brownian Motion, which i'll refer to as $\dot{B}_t$ . Now using the stochastic integration by parts formula we see that $$ -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)dB_t \tag{1} $$ and now we will informally denote this last integral as $$ \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{2} $$ So putting (1) and (2) together we see that $$ -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{3} $$ And we now see that $\dot{B}_t$ is the weak or distributional dervitive of the Brownian motion $B_t$ . So now in the same notes listed above, the author says that the process $X(\phi)$ , which was already said to be a White Noise, defines a White Noise $\dot{B}$ . My question now is that does White Noise refer to both $X$ and $\dot{B}$ ? If we regard White Noise as the derivative (in the sense of distributions) of a Brownian Motion then $\dot{B}$ is a White Noise. But just using the mathematical definition of a White Noise we also see that $X$ is a White Noise. Any input is appreciated!","I have been trying to understand what a White Noise is and also a White noise Process and I have been trying to piece together different definitions that I have found online. I was wondering if my understanding of White Noise is correct These notes say that the the mathematical definition of White Noise is and mean Generalized Gaussian Processes on (I believe that needs to be a smooth function of rapid decrease?), namely , such that the variance of is . So from my understanding, let be a test function then we can consider the generalized stochastic process where is a brownian motion on . So here is the Wiener Integral. It is a standard result that is a -mean Gaussian random variable with variance . So according to the above definition, is a white noise. But, in the same notes linked above, it says that White Noise can be thought of as the derivative of a Brownian Motion, which i'll refer to as . Now using the stochastic integration by parts formula we see that and now we will informally denote this last integral as So putting (1) and (2) together we see that And we now see that is the weak or distributional dervitive of the Brownian motion . So now in the same notes listed above, the author says that the process , which was already said to be a White Noise, defines a White Noise . My question now is that does White Noise refer to both and ? If we regard White Noise as the derivative (in the sense of distributions) of a Brownian Motion then is a White Noise. But just using the mathematical definition of a White Noise we also see that is a White Noise. Any input is appreciated!",0 S S Y(\phi) Y(\phi) \int_{\mathbb R} \phi(t)^2 dt  \phi(t) \in S   X(\phi)=\int_{\mathbb R}\phi(t)dB_t  B_t \mathbb R X X(\phi) 0 \int_{\mathbb R}\phi(t)^2dt  X \dot{B}_t  -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)dB_t \tag{1}   \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{2}   -\int_{\mathbb R}\phi '(t)B_tdt = \int_{\mathbb R}\phi(t)\dot{B}_tdt \tag{3}  \dot{B}_t B_t X(\phi) \dot{B} X \dot{B} \dot{B} X,"['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
74,Calculating the probability of a sequence having $n$ terms in a certain set.,Calculating the probability of a sequence having  terms in a certain set.,n,"Let $\Delta$ be  the interval $[0,1]$ , then we can consider the probability space $(\Delta , \mathcal{B}(\Delta),m)$ , where $\mathcal{B}(\Delta)$ is the Borel $\sigma$ -algebra and $m$ is the Lebesgue measure. Then we can endow the space $\Delta^{\mathbb{N}}:= \{ (\omega_n)_{n\in \mathbb{N}};\  \omega_n \in \Delta, \ \forall \ n\in \mathbb{N}\}$ with the $\sigma$ -algebr $\mathcal{B}(\Delta^{\mathbb{N}})$ (Borel $\sigma$ -algebra of $\Delta^{\mathbb{N}}$ induced by the  product topology) and the probability measuare $m^{\mathbb{N}}$ in the measurable space $(\Delta^{\mathbb{N}},\mathcal{B}(\Delta^{\mathbb{N}}))$ , such that $$m^{\mathbb{N}} \left(A_1\times A_2\times \ldots \times A_n \times \prod_{i=n+1}^{\infty} \Delta\right)=m(A_1) \cdot \ldots\cdot m(A_n). $$ Now, consider the Bernoulli shift map \begin{align*} \sigma: \Delta^{\mathbb{N}}&\to\Delta^\mathbb{N}\\ (\omega_n)_{n}&\to (\omega_{n+1})_n. \end{align*} It is well known that the measure $m^{\mathbb{N}}$ on $(\Delta^{N}, \mathcal{B}(\Delta^{\mathbb{N}}))$ is invariant under $\sigma$ . Moreover the pair $(\sigma,m^{\mathbb{N}})$ is ergodic. So, Birkhoff's theorem says that for any cilinder $$\Lambda = A_1\times A_2\times \ldots \times A_n \times \prod_{i=n+1}^{\infty} \Delta, $$ where all $A_i$ 's are open subsets of $\Delta$ , $$\lim_{n\to \infty}\frac{1}{n} \sum_{i=0}^{n-1} \chi_{\Lambda}(\sigma^{i}( (\omega_j)_j)) = m^{\mathbb{N}}(\Lambda),\ \text{$m^{\mathbb{N}}$- a.s.} $$ My Question: Birkhoff's theorem says that for almost every $(\omega_n)_n\in \mathbb{\Delta^{\mathbb{N}}}$ , there exists $i = i((\omega_n)_n)\in \mathbb{N}$ such that $(\omega_{i+1},...,\omega_{i+n})\in A_1 \times ...\times A_n$ . Is it possible calculate (or estimate) the following probability $$P_m(\Lambda) := m^{\mathbb{N}}\left(\left\{((\omega_n)_{n};\ \exists\ i \in \{0,...,m\}\ \text{such that }\sigma^{i}(\omega) \in \Lambda\right\}\right)\ ? $$ Moreover, given $\varepsilon>0$ , are there $n_0 \in \mathbb{N}$ , such that $$1- P_n(\Lambda) < \varepsilon, \forall n > n_0  ? $$","Let be  the interval , then we can consider the probability space , where is the Borel -algebra and is the Lebesgue measure. Then we can endow the space with the -algebr (Borel -algebra of induced by the  product topology) and the probability measuare in the measurable space , such that Now, consider the Bernoulli shift map It is well known that the measure on is invariant under . Moreover the pair is ergodic. So, Birkhoff's theorem says that for any cilinder where all 's are open subsets of , My Question: Birkhoff's theorem says that for almost every , there exists such that . Is it possible calculate (or estimate) the following probability Moreover, given , are there , such that","\Delta [0,1] (\Delta , \mathcal{B}(\Delta),m) \mathcal{B}(\Delta) \sigma m \Delta^{\mathbb{N}}:= \{ (\omega_n)_{n\in \mathbb{N}};\  \omega_n \in \Delta, \ \forall \ n\in \mathbb{N}\} \sigma \mathcal{B}(\Delta^{\mathbb{N}}) \sigma \Delta^{\mathbb{N}} m^{\mathbb{N}} (\Delta^{\mathbb{N}},\mathcal{B}(\Delta^{\mathbb{N}})) m^{\mathbb{N}} \left(A_1\times A_2\times \ldots \times A_n \times \prod_{i=n+1}^{\infty} \Delta\right)=m(A_1) \cdot \ldots\cdot m(A_n).  \begin{align*}
\sigma: \Delta^{\mathbb{N}}&\to\Delta^\mathbb{N}\\
(\omega_n)_{n}&\to (\omega_{n+1})_n.
\end{align*} m^{\mathbb{N}} (\Delta^{N}, \mathcal{B}(\Delta^{\mathbb{N}})) \sigma (\sigma,m^{\mathbb{N}}) \Lambda = A_1\times A_2\times \ldots \times A_n \times \prod_{i=n+1}^{\infty} \Delta,  A_i \Delta \lim_{n\to \infty}\frac{1}{n} \sum_{i=0}^{n-1} \chi_{\Lambda}(\sigma^{i}( (\omega_j)_j)) = m^{\mathbb{N}}(\Lambda),\ \text{m^{\mathbb{N}}- a.s.}  (\omega_n)_n\in \mathbb{\Delta^{\mathbb{N}}} i = i((\omega_n)_n)\in \mathbb{N} (\omega_{i+1},...,\omega_{i+n})\in A_1 \times ...\times A_n P_m(\Lambda) := m^{\mathbb{N}}\left(\left\{((\omega_n)_{n};\ \exists\ i \in \{0,...,m\}\ \text{such that }\sigma^{i}(\omega) \in \Lambda\right\}\right)\ ?  \varepsilon>0 n_0 \in \mathbb{N} 1- P_n(\Lambda) < \varepsilon, \forall n > n_0  ? ","['probability', 'probability-theory', 'measure-theory', 'dynamical-systems', 'ergodic-theory']"
75,1D-Biased Random Walk Hitting Time Distribution,1D-Biased Random Walk Hitting Time Distribution,,"Let $X_{s}$ be a Bernoulli r.v such that it returns (1-p) with probability p and returns (-p) with probability (1-p). All $X_s$ are mutually independent. Let $S_n = X_1 + X_2 + \cdots X_n$ and T is the stopping time when $S_n<a$ or $S_n>b$ for some $a<0$ or $b>0$ . What is the distribution of the stopping time T? I guess expected stopping time might be infinity as a random walk does, but I am not sure. Now consider the unbalanced case, so that $X_s$ returns (1-p) with probability q and returns (-p) with probability (1-q). WLOG $q>p$ . Now can we calculate the distribution of the stopping time T? I have read some documents about discrete random walks, and it uses characteristic function to calcualte expected stopping time, but I don't think I can apply that method to this problem. I am now researching about CUSUM(CUmulative SUM), SPRT(Sequential Probability Ratio Test) things and it is necessary for my further research - I need more information than upper bound of stopping time...... Please help......","Let be a Bernoulli r.v such that it returns (1-p) with probability p and returns (-p) with probability (1-p). All are mutually independent. Let and T is the stopping time when or for some or . What is the distribution of the stopping time T? I guess expected stopping time might be infinity as a random walk does, but I am not sure. Now consider the unbalanced case, so that returns (1-p) with probability q and returns (-p) with probability (1-q). WLOG . Now can we calculate the distribution of the stopping time T? I have read some documents about discrete random walks, and it uses characteristic function to calcualte expected stopping time, but I don't think I can apply that method to this problem. I am now researching about CUSUM(CUmulative SUM), SPRT(Sequential Probability Ratio Test) things and it is necessary for my further research - I need more information than upper bound of stopping time...... Please help......",X_{s} X_s S_n = X_1 + X_2 + \cdots X_n S_n<a S_n>b a<0 b>0 X_s q>p,"['probability', 'probability-distributions', 'random-walk', 'stopping-times']"
76,Bayes Estimator under $L_{\eta}$,Bayes Estimator under,L_{\eta},"I am wondering if the following loss function is well known and if it is, does it have a standard name: $$ L_{\eta} (\theta, a) = (\theta-a) (\eta - \mathbb{I}_{(-\infty, a)} (\theta) ), \quad \eta \in (0,1). $$ where $\eta$ is fixed. For the following problem: For a single observation $x \sim \text{Uniform}(0, \theta)$ , with prior on $\theta$ being $\tau(\theta) = \theta e^{-\theta} \mathbb{I}_{(0, \infty)}(\theta)$ , we get the following posterior distribution: \begin{align*}     h_{\Theta|X}(\theta|x) = e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta). \end{align*} I am trying to compute the bayes estimator, $\hat{\theta}$ , under $L_{\eta}$ . I am wondering if my answer is correct, here is my working: We wish to find $\hat{\theta}$ that minimises the expected posterior loss: \begin{align*}     \mathbb{E}[L_{\theta}(\theta, \hat{\theta}) | X] &= \int_{-\infty}^{\infty} (\theta - \hat{\theta}) (\eta - \mathbb{I}_{(-\infty, \hat{\theta})}(\theta)) h(\theta|x) d \theta \\     &=(\eta -1)\int_{-\infty}^{\hat{\theta}} (\theta - \hat{\theta})  h(\theta|x) d \theta  + \eta \int_{\hat{\theta}}^{\infty} (\theta - \hat{\theta})  h(\theta|x) d \theta. \end{align*} Using Leibniz rule to differentiate this wrt $\hat{\theta}$ and setting to zero (and omitting some minor details), we get \begin{align*}     - (\eta -1) \int_{-\infty}^{\hat{\theta}} h(\theta|x) d \theta  - \eta \int_{\hat{\theta}}^{\infty}  h(\theta|x) d \theta = 0. \end{align*} Solving for $\hat{\theta}$ gives \begin{align*}     & -(\eta -1)\int_{-\infty}^{\hat{\theta}}  e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta) d \theta  - \eta \int_{\hat{\theta}}^{\infty}  e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta) d \theta = 0\\     \implies & -(\eta -1) e^{x} \int_{\min \{ \hat{\theta}, x \} }^{\hat{\theta}} e^{-\theta} d \theta  - \eta e^{x} \int_{\max\{\hat{\theta}, x\}}^{\infty}  e^{-\theta}  d \theta = 0\\     \implies & -(\eta -1) e^{x} \int_{ x }^{\hat{\theta}} e^{-\theta} d \theta  - \eta e^{x} \int_{\hat{\theta}}^{\infty}  e^{-\theta} d \theta = 0\\     \implies & -(\eta -1) (1-e^{x- \hat{\theta}}) - \eta e^{x - \hat{\theta}} = 0\\     \implies & \hat{\theta}= x-\log(1-\eta). \end{align*} Note that we have made the assumption that $\hat{\theta} \ge x$ , so that \begin{align*}     \min \{\hat{\theta}, x \} = x, \quad \max \{\hat{\theta}, x \} = \hat{\theta}, \end{align*}","I am wondering if the following loss function is well known and if it is, does it have a standard name: where is fixed. For the following problem: For a single observation , with prior on being , we get the following posterior distribution: I am trying to compute the bayes estimator, , under . I am wondering if my answer is correct, here is my working: We wish to find that minimises the expected posterior loss: Using Leibniz rule to differentiate this wrt and setting to zero (and omitting some minor details), we get Solving for gives Note that we have made the assumption that , so that","
L_{\eta} (\theta, a) = (\theta-a) (\eta - \mathbb{I}_{(-\infty, a)} (\theta) ), \quad \eta \in (0,1).
 \eta x \sim \text{Uniform}(0, \theta) \theta \tau(\theta) = \theta e^{-\theta} \mathbb{I}_{(0, \infty)}(\theta) \begin{align*}
    h_{\Theta|X}(\theta|x) = e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta).
\end{align*} \hat{\theta} L_{\eta} \hat{\theta} \begin{align*}
    \mathbb{E}[L_{\theta}(\theta, \hat{\theta}) | X] &= \int_{-\infty}^{\infty} (\theta - \hat{\theta}) (\eta - \mathbb{I}_{(-\infty, \hat{\theta})}(\theta)) h(\theta|x) d \theta \\
    &=(\eta -1)\int_{-\infty}^{\hat{\theta}} (\theta - \hat{\theta})  h(\theta|x) d \theta  + \eta \int_{\hat{\theta}}^{\infty} (\theta - \hat{\theta})  h(\theta|x) d \theta.
\end{align*} \hat{\theta} \begin{align*}
    - (\eta -1) \int_{-\infty}^{\hat{\theta}} h(\theta|x) d \theta  - \eta \int_{\hat{\theta}}^{\infty}  h(\theta|x) d \theta = 0.
\end{align*} \hat{\theta} \begin{align*}
    & -(\eta -1)\int_{-\infty}^{\hat{\theta}}  e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta) d \theta  - \eta \int_{\hat{\theta}}^{\infty}  e^{x-\theta} \mathbb{I}_{(x, \infty)}(\theta) d \theta = 0\\
    \implies & -(\eta -1) e^{x} \int_{\min \{ \hat{\theta}, x \} }^{\hat{\theta}} e^{-\theta} d \theta  - \eta e^{x} \int_{\max\{\hat{\theta}, x\}}^{\infty}  e^{-\theta}  d \theta = 0\\
    \implies & -(\eta -1) e^{x} \int_{ x }^{\hat{\theta}} e^{-\theta} d \theta  - \eta e^{x} \int_{\hat{\theta}}^{\infty}  e^{-\theta} d \theta = 0\\
    \implies & -(\eta -1) (1-e^{x- \hat{\theta}}) - \eta e^{x - \hat{\theta}} = 0\\
    \implies & \hat{\theta}= x-\log(1-\eta).
\end{align*} \hat{\theta} \ge x \begin{align*}
    \min \{\hat{\theta}, x \} = x, \quad \max \{\hat{\theta}, x \} = \hat{\theta},
\end{align*}","['probability', 'statistics', 'statistical-inference', 'machine-learning', 'bayesian']"
77,Seeking intuition on hat-check probability depending on parity of $n$,Seeking intuition on hat-check probability depending on parity of,n,"In (one version of) the hat-check problem, https://proofwiki.org/wiki/Hat-Check_Problem the question is to find the probability that for $n$ hat-checkers, nobody gets their own hat. If this is called $p_n,$ the solution is to obtain the $n$ th partial sum of the series for $1/e.$ So we have, for $n=1,2,3,\cdots,$ that $$p_n=\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\cdots+\frac{(-1)^n}{n!}.$$ For odd $n,$ the likelihood increases as $n$ does. This seems peculiar (to me) in that for more people checking their hats, it would become more likely that at least one person got their own hat, and so less likely that nobody did. For even $n$ as $n$ goes up the likelihood $p_n$ decreases as expected by the vague (incorrect) intuition proposed above. I'm looking for some reasonable intuitive reason why one would expect this even/odd $n$ behavior for this problem. Also from the answer, for any $m,n$ where $m$ even and $n$ odd, $p_m>p_n,$ which puzzles my intuition more. Any intuitions (not proofs, which can be done and are known anyway) appreciated.","In (one version of) the hat-check problem, https://proofwiki.org/wiki/Hat-Check_Problem the question is to find the probability that for hat-checkers, nobody gets their own hat. If this is called the solution is to obtain the th partial sum of the series for So we have, for that For odd the likelihood increases as does. This seems peculiar (to me) in that for more people checking their hats, it would become more likely that at least one person got their own hat, and so less likely that nobody did. For even as goes up the likelihood decreases as expected by the vague (incorrect) intuition proposed above. I'm looking for some reasonable intuitive reason why one would expect this even/odd behavior for this problem. Also from the answer, for any where even and odd, which puzzles my intuition more. Any intuitions (not proofs, which can be done and are known anyway) appreciated.","n p_n, n 1/e. n=1,2,3,\cdots, p_n=\frac{1}{0!}-\frac{1}{1!}+\frac{1}{2!}-\frac{1}{3!}+\cdots+\frac{(-1)^n}{n!}. n, n n n p_n n m,n m n p_m>p_n,",['probability']
78,The parking problem riddle,The parking problem riddle,,"Assume a street of 300 meters, that you can park your car alongside the pavement. Assume that there is a big parking problem in the area. Assume that the pavement is continuous, without interruptions, and that you can park alongside all of it. Assume that the length of a car is 3 meters long. Assume, for simplicity, that cars can park without space between them (bumper to bumper). Assume, that when a car comes to the street if chooses an equally random parking space (please try to express this randomness) from the free spaces left. Therefore, it may ""ruin"" parking places for other cars. Please try to determine what is the expectancy of cars the can park alongside the street.","Assume a street of 300 meters, that you can park your car alongside the pavement. Assume that there is a big parking problem in the area. Assume that the pavement is continuous, without interruptions, and that you can park alongside all of it. Assume that the length of a car is 3 meters long. Assume, for simplicity, that cars can park without space between them (bumper to bumper). Assume, that when a car comes to the street if chooses an equally random parking space (please try to express this randomness) from the free spaces left. Therefore, it may ""ruin"" parking places for other cars. Please try to determine what is the expectancy of cars the can park alongside the street.",,"['probability', 'random']"
79,"Necklace is made out of ten different red, twenty different orange and thirty same yellow pearls.","Necklace is made out of ten different red, twenty different orange and thirty same yellow pearls.",,"A necklace is made out of $10$ different red, $20$ different orange and $30$ same yellow pearls. If we know that no two red pearls are next to each other, what is the probability that between each couple of red pearls there is at least $1$ orange and from $2$ to $5$ yellow pearls? I got stuck when I tried to count the set $A$ = {no two red pearls are next to each other }. My idea was to fix one red and then from all possible circular permutations subtract the permutations where there is one red pearl right next that fixed one, or where some other two reds are together, then analogously with three reds together, etc. It seems to me that this way I would count a lot more than I should, but I cannot think of any other way.","A necklace is made out of different red, different orange and same yellow pearls. If we know that no two red pearls are next to each other, what is the probability that between each couple of red pearls there is at least orange and from to yellow pearls? I got stuck when I tried to count the set = {no two red pearls are next to each other }. My idea was to fix one red and then from all possible circular permutations subtract the permutations where there is one red pearl right next that fixed one, or where some other two reds are together, then analogously with three reds together, etc. It seems to me that this way I would count a lot more than I should, but I cannot think of any other way.",10 20 30 1 2 5 A,"['probability', 'combinatorics']"
80,Height of the Uniform Random Tree,Height of the Uniform Random Tree,,"Consider $\mathcal{T}_n$ the uniform rooted labelled tree on $n$ vertices (i.e. each spanning tree on $K_n$ has the same probability to be picked, and the root is picked uniformly among the $n$ vertices). Denote $h(t)=\max_v d(\text{root},v)$ be the height of the tree $t$ . I'm interested in understanding $h(\mathcal{T}_n)$ . While Renyi and Szekeres proved in this paper that $\mathbb{E}(\mathcal{T}_n)\to\sqrt{2\pi n}$ (and actually computed the limiting distribution of the scaled height), many authors, like Aldous in here , claim that just realizing that the height behaves like $\sqrt{n}$ should be ""easy"" to derive. Does anybody know of an ""easy"" way to prove this? I would guess the formal fact we want to show is that $h(\mathcal{T}_n)=O(\sqrt{n})$ in probability, but this might be wrong. Thank you very much.","Consider the uniform rooted labelled tree on vertices (i.e. each spanning tree on has the same probability to be picked, and the root is picked uniformly among the vertices). Denote be the height of the tree . I'm interested in understanding . While Renyi and Szekeres proved in this paper that (and actually computed the limiting distribution of the scaled height), many authors, like Aldous in here , claim that just realizing that the height behaves like should be ""easy"" to derive. Does anybody know of an ""easy"" way to prove this? I would guess the formal fact we want to show is that in probability, but this might be wrong. Thank you very much.","\mathcal{T}_n n K_n n h(t)=\max_v d(\text{root},v) t h(\mathcal{T}_n) \mathbb{E}(\mathcal{T}_n)\to\sqrt{2\pi n} \sqrt{n} h(\mathcal{T}_n)=O(\sqrt{n})","['probability', 'combinatorics', 'graph-theory', 'trees']"
81,coupling of distributions vs joint distributions,coupling of distributions vs joint distributions,,"For continuoues variables, how is a coupling of two distributions different from their joint distribution? Are they the same concepts? Update: Coupling is the same as defining a joint distribution on the Cartesian product space of the supports of original random variables, in a way that marginals of the defined joint distribution are equal to the original random variables. What am I missing?","For continuoues variables, how is a coupling of two distributions different from their joint distribution? Are they the same concepts? Update: Coupling is the same as defining a joint distribution on the Cartesian product space of the supports of original random variables, in a way that marginals of the defined joint distribution are equal to the original random variables. What am I missing?",,"['probability', 'probability-distributions', 'coupling']"
82,How many monkeys do I need to have a 95% chance of producing Shakespeare's Romeo and Juliet within one year? [closed],How many monkeys do I need to have a 95% chance of producing Shakespeare's Romeo and Juliet within one year? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question I've heard of the analogy that infinite monkeys with typewriters will eventually produce Shakespeare's Romeo and Juliet, but what if, instead of ""eventually"", I want ""one year"". How many monkeys do I need to produce Romeo and Juliet within one year? What is the function for producing Romeo and Juliet in a certain timeframe as a function of number of monkeys? Assume that the monkey is basically just a random character generator. It only generates any of the characters that are present in Romeo and Juliet : letters, punctuation, numbers (perhaps? I'm not a literary expert). Monkeys type at 12 wpm. Romeo and Juliet is 24545 words long. Also, a good point was made below: let's amend the question to make it a probability. How many monkeys do I need to have a 95 percent chance of producing the work within a year?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 5 years ago . Improve this question I've heard of the analogy that infinite monkeys with typewriters will eventually produce Shakespeare's Romeo and Juliet, but what if, instead of ""eventually"", I want ""one year"". How many monkeys do I need to produce Romeo and Juliet within one year? What is the function for producing Romeo and Juliet in a certain timeframe as a function of number of monkeys? Assume that the monkey is basically just a random character generator. It only generates any of the characters that are present in Romeo and Juliet : letters, punctuation, numbers (perhaps? I'm not a literary expert). Monkeys type at 12 wpm. Romeo and Juliet is 24545 words long. Also, a good point was made below: let's amend the question to make it a probability. How many monkeys do I need to have a 95 percent chance of producing the work within a year?",,[]
83,Product of distributions satisfying log-sobolev inequality,Product of distributions satisfying log-sobolev inequality,,"Let $f,g\in C^\infty(\mathbb{R})$ be two smooth positive functions satisfying $\int f = \int g = 1$ .  Suppose that both $f$ and $g$ satisfy the log-Sobolev inequality (LSI) with constant $C$ , so that $$ \int \phi^2 \log(\phi^2) f(x)\,dx \leq C \int |\phi'|^2 f(x)\,dx $$ for every $\phi$ satisfying $\int \phi^2(x)f(x)\,dx = 1$ , and the same holds with $f$ replaces by $g$ . If $\int f(x)g(x)\,dx = Z > 0$ , does it follow that the density $h(x) = Z^{-1} f(x)g(x)$ also satisfies LSI with the same constant $C$ ? I would be equally interested in a counterexample.","Let be two smooth positive functions satisfying .  Suppose that both and satisfy the log-Sobolev inequality (LSI) with constant , so that for every satisfying , and the same holds with replaces by . If , does it follow that the density also satisfies LSI with the same constant ? I would be equally interested in a counterexample.","f,g\in C^\infty(\mathbb{R}) \int f = \int g = 1 f g C 
\int \phi^2 \log(\phi^2) f(x)\,dx \leq C \int |\phi'|^2 f(x)\,dx
 \phi \int \phi^2(x)f(x)\,dx = 1 f g \int f(x)g(x)\,dx = Z > 0 h(x) = Z^{-1} f(x)g(x) C","['probability', 'functional-inequalities', 'concentration-of-measure']"
84,Bet on the sum of two dice,Bet on the sum of two dice,,"There are two players, and each one has a die with six sides from $1$ to $6$ . The probability of each side landing is equal. Now, the two players roll their dice, and they only know the number of their own die. They will propose prices in turn, until one of them doesn't provide a higher price. The winner will get the money equal to the sum of these two dice minus the price they provided. What is the optimal strategy for playing this game?","There are two players, and each one has a die with six sides from to . The probability of each side landing is equal. Now, the two players roll their dice, and they only know the number of their own die. They will propose prices in turn, until one of them doesn't provide a higher price. The winner will get the money equal to the sum of these two dice minus the price they provided. What is the optimal strategy for playing this game?",1 6,"['probability', 'game-theory', 'dice']"
85,Estimate number of cards needed to be drawn from deck before full house,Estimate number of cards needed to be drawn from deck before full house,,"Imagine we have a well-shuffled deck of cards and we keep drawing cards until there is at least one full house in the drawn cards. How many cards will we draw on average? I would be interested in both the exact solution (which is something around 12) but, more importantly, in a good quick way of estimating this value.","Imagine we have a well-shuffled deck of cards and we keep drawing cards until there is at least one full house in the drawn cards. How many cards will we draw on average? I would be interested in both the exact solution (which is something around 12) but, more importantly, in a good quick way of estimating this value.",,"['probability', 'puzzle', 'card-games']"
86,Integration over convex polytope,Integration over convex polytope,,"I have a small problem (as stated below). Moreover, I am new to this site (asking questions that is) and not a mathematician by trade. I tried to be as precise as possible in asking the question. If anything is unclear, please let me know and I will try to make my point more clear. The problem is the following: I have a convex polytope $A$ which is split by a half space into the two convex polytopes $A_L$ and $A_R$ . Moreover, I have a continuous function $p(x)$ and a probability density function $f(X)$ , where $X$ is an $i.i.d.$ random vector (with mutually independent elements) and I know that $$ \frac{\int_Ap(x)f(x)dx}{\int_Af(x)dx}=\frac{\int_{A_L}p(x)f(x)dx}{\int_{A_L}f(x)dx}=\frac{\int_{A_R}p(x)f(x)dx}{\int_{A_R}f(x)dx} $$ holds for all possible splits of $A$ into $A_L$ and $A_R$ . I want to show that if the above equality holds for all possible splits of $A$ into $A_L$ and $A_R$ , then $p(x)$ must be constant on $A$ . I can show the result in the case of a scalar r.v. $X$ . However, I struggle to show the result for the general case where $X$ is an $i.i.d.$ random vector (with mutually independent elements). However, I also realize that the problem itself is independent of the fact that $f(x)$ is a pdf. Therefore, I was thinking that there might be a general mathematical result which can be used to show the claim. I very much appreciate any pointers towards a way to prove the above statement.","I have a small problem (as stated below). Moreover, I am new to this site (asking questions that is) and not a mathematician by trade. I tried to be as precise as possible in asking the question. If anything is unclear, please let me know and I will try to make my point more clear. The problem is the following: I have a convex polytope which is split by a half space into the two convex polytopes and . Moreover, I have a continuous function and a probability density function , where is an random vector (with mutually independent elements) and I know that holds for all possible splits of into and . I want to show that if the above equality holds for all possible splits of into and , then must be constant on . I can show the result in the case of a scalar r.v. . However, I struggle to show the result for the general case where is an random vector (with mutually independent elements). However, I also realize that the problem itself is independent of the fact that is a pdf. Therefore, I was thinking that there might be a general mathematical result which can be used to show the claim. I very much appreciate any pointers towards a way to prove the above statement.","A A_L A_R p(x) f(X) X i.i.d. 
\frac{\int_Ap(x)f(x)dx}{\int_Af(x)dx}=\frac{\int_{A_L}p(x)f(x)dx}{\int_{A_L}f(x)dx}=\frac{\int_{A_R}p(x)f(x)dx}{\int_{A_R}f(x)dx}
 A A_L A_R A A_L A_R p(x) A X X i.i.d. f(x)","['real-analysis', 'probability', 'integration']"
87,What is the probability of exactly one negative solution in a Fibonacci system of equations?,What is the probability of exactly one negative solution in a Fibonacci system of equations?,,"The Fibonacci numbers denoted by $F_i$ for $i\ge1$ are $$1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,\cdots$$ where they satisfy the property $F_{i+2}=F_{i+1}+F_i$. I have listed the first $15$ numbers of the sequence as they will be useful for reference later. Now define $\theta_i$ as the concatenation of $1.F_i$ so that $1<\theta_i<2$. So for example, $$\theta_1=1.1,\quad\theta_6=1.13,\quad\theta_{15}=1.987.$$ Next, consider the following $3\times3$ system of equations: $$\begin{bmatrix}\theta_i&\theta_{i+1}&\theta_{i+2}\\\theta_{i+4}&\theta_{i+5}&\theta_{i+6}\\\theta_{i+8}&\theta_{i+9}&\theta_{i+10}\end{bmatrix}\begin{bmatrix}X\\Y\\Z\end{bmatrix}=\begin{bmatrix}\theta_{i+3}\\\theta_{i+7}\\\theta_{i+11}\end{bmatrix}$$ from which we can solve for $[X\quad Y\quad Z]^T$ but of course this would be very tedious. When $i=1,2$, both $X$ and $Y$ are negative but $Z$ is positive. When $i=3$, the opposite occurs. Question: For $i\le n$, what is the probability that exactly one of $X,Y,Z$ will be negative?","The Fibonacci numbers denoted by $F_i$ for $i\ge1$ are $$1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,\cdots$$ where they satisfy the property $F_{i+2}=F_{i+1}+F_i$. I have listed the first $15$ numbers of the sequence as they will be useful for reference later. Now define $\theta_i$ as the concatenation of $1.F_i$ so that $1<\theta_i<2$. So for example, $$\theta_1=1.1,\quad\theta_6=1.13,\quad\theta_{15}=1.987.$$ Next, consider the following $3\times3$ system of equations: $$\begin{bmatrix}\theta_i&\theta_{i+1}&\theta_{i+2}\\\theta_{i+4}&\theta_{i+5}&\theta_{i+6}\\\theta_{i+8}&\theta_{i+9}&\theta_{i+10}\end{bmatrix}\begin{bmatrix}X\\Y\\Z\end{bmatrix}=\begin{bmatrix}\theta_{i+3}\\\theta_{i+7}\\\theta_{i+11}\end{bmatrix}$$ from which we can solve for $[X\quad Y\quad Z]^T$ but of course this would be very tedious. When $i=1,2$, both $X$ and $Y$ are negative but $Z$ is positive. When $i=3$, the opposite occurs. Question: For $i\le n$, what is the probability that exactly one of $X,Y,Z$ will be negative?",,"['probability', 'systems-of-equations', 'recreational-mathematics', 'matrix-equations', 'fibonacci-numbers']"
88,Integration of $f^2(x)F(x)^n$,Integration of,f^2(x)F(x)^n,"Is there any general closed form to the following? $$\int^1_0 f^2(x)F^{n-1}(x)dx$$ when F is a CDF with support $[0,1]$ and $f$ is its corresponding pdf. It's easy when it is $\int^1_0 f(x)F^{n-1}(x)dx$, but what happens when the pdf is powered by some number?","Is there any general closed form to the following? $$\int^1_0 f^2(x)F^{n-1}(x)dx$$ when F is a CDF with support $[0,1]$ and $f$ is its corresponding pdf. It's easy when it is $\int^1_0 f(x)F^{n-1}(x)dx$, but what happens when the pdf is powered by some number?",,"['probability', 'integration']"
89,What's the distribution of $L_1$ norm of Gaussian random variables?,What's the distribution of  norm of Gaussian random variables?,L_1,"Suppose we have a Multivariate Gaussian random variable $X\sim N(\mu,\Sigma)$. What's the distribution of $\|X\|_1$? My thinking: There are a lot of articles talking about the distribution of $\|X\|_2$, But how about $L_1$ norm? Finding distribution of distance from origin https://stats.stackexchange.com/questions/25358/what-is-the-distribution-of-the-euclidean-distance-between-two-random-points-in","Suppose we have a Multivariate Gaussian random variable $X\sim N(\mu,\Sigma)$. What's the distribution of $\|X\|_1$? My thinking: There are a lot of articles talking about the distribution of $\|X\|_2$, But how about $L_1$ norm? Finding distribution of distance from origin https://stats.stackexchange.com/questions/25358/what-is-the-distribution-of-the-euclidean-distance-between-two-random-points-in",,"['probability', 'probability-distributions', 'normal-distribution', 'normed-spaces']"
90,How to use the Lindeberg CLT in this scenario ? (analysis problem),How to use the Lindeberg CLT in this scenario ? (analysis problem),,"We have $(X_i)_{i \in \mathbb Z}$ iid random variables with $1\le X_i \le2$ almost surely. We define $X(x,\omega) \equiv X_i (\omega)$ if $x\in [i,i+1[$ and $X_\epsilon (x, \omega) \equiv X(x/\epsilon, \omega)$. A post that solves a very similar problem: Show that those random quantities converge in distribution to a normal variable (hard analysis problem) Define $$u'_\epsilon(x,\omega)= \frac {c_\epsilon(\omega) - F(x)}{X_\epsilon(x,\omega)}$$ where $F$ is an $L^1([0,1])$ function and $c(\omega)$ is defined by $$c_\epsilon(\omega)\equiv \frac{\int_0^1 \frac{F(y)}{X_\epsilon(y,\omega)} \, dy}{\int_0^1\frac 1 {X_\epsilon(y,\omega)}\, dy}$$ Show that $$\epsilon^\alpha\int_0^1 u'_\epsilon(x,\omega) g(x)\, dx \to \mathcal N(?, ?)$$ for a certain $\alpha\in\mathbb R$, in distribution when $\epsilon \downarrow 0$ for any sufficiently smooth function $g$, where we need to characterize the expectation and the variance. A hint says for this problem that we should notice that $u'_\epsilon(x,\omega)$ can be written as a product of a random part and a deterministic part + an error that can be controlled in $L^2(]0,1[ \times \Omega)$. We can easily notice that $$u'_\epsilon(x,\omega)= \frac {F(x)}{X_\epsilon(x,\omega)} + err_\epsilon(x,\omega)$$ where $$err_\epsilon(x,\omega)=\frac {\int_0^1 \frac {F(y)}{X_\epsilon(y,\omega)} dy}{X_\epsilon(x,\omega)\int_0^1 \frac {1}{X_\epsilon(y,\omega)} dy}$$ I have no idea how to control this and how will this help (maybe this is not the intended form). The question related to this control can be found here : Controlling this function in $L^2$ norm Another post that brings more information about $u'_\epsilon$ is the following: Showing an $L^2$ convergence (with convergence rate) EDIT: we can suppose that $F$ is continuous on $[0,1]$ if it helps. EDIT2: Bonus rep will be awarded if, in addition to the above, the convergence is shown using quantitative argument (total variation distance, Wasserstein distance, Kolmogorov distance, Zolotarev distance...)","We have $(X_i)_{i \in \mathbb Z}$ iid random variables with $1\le X_i \le2$ almost surely. We define $X(x,\omega) \equiv X_i (\omega)$ if $x\in [i,i+1[$ and $X_\epsilon (x, \omega) \equiv X(x/\epsilon, \omega)$. A post that solves a very similar problem: Show that those random quantities converge in distribution to a normal variable (hard analysis problem) Define $$u'_\epsilon(x,\omega)= \frac {c_\epsilon(\omega) - F(x)}{X_\epsilon(x,\omega)}$$ where $F$ is an $L^1([0,1])$ function and $c(\omega)$ is defined by $$c_\epsilon(\omega)\equiv \frac{\int_0^1 \frac{F(y)}{X_\epsilon(y,\omega)} \, dy}{\int_0^1\frac 1 {X_\epsilon(y,\omega)}\, dy}$$ Show that $$\epsilon^\alpha\int_0^1 u'_\epsilon(x,\omega) g(x)\, dx \to \mathcal N(?, ?)$$ for a certain $\alpha\in\mathbb R$, in distribution when $\epsilon \downarrow 0$ for any sufficiently smooth function $g$, where we need to characterize the expectation and the variance. A hint says for this problem that we should notice that $u'_\epsilon(x,\omega)$ can be written as a product of a random part and a deterministic part + an error that can be controlled in $L^2(]0,1[ \times \Omega)$. We can easily notice that $$u'_\epsilon(x,\omega)= \frac {F(x)}{X_\epsilon(x,\omega)} + err_\epsilon(x,\omega)$$ where $$err_\epsilon(x,\omega)=\frac {\int_0^1 \frac {F(y)}{X_\epsilon(y,\omega)} dy}{X_\epsilon(x,\omega)\int_0^1 \frac {1}{X_\epsilon(y,\omega)} dy}$$ I have no idea how to control this and how will this help (maybe this is not the intended form). The question related to this control can be found here : Controlling this function in $L^2$ norm Another post that brings more information about $u'_\epsilon$ is the following: Showing an $L^2$ convergence (with convergence rate) EDIT: we can suppose that $F$ is continuous on $[0,1]$ if it helps. EDIT2: Bonus rep will be awarded if, in addition to the above, the convergence is shown using quantitative argument (total variation distance, Wasserstein distance, Kolmogorov distance, Zolotarev distance...)",,"['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'stochastic-processes']"
91,What does it mean that a probability distribution has full support?,What does it mean that a probability distribution has full support?,,"I am reading an article which introduces the following assumption at a certain point: The probability distribution of the (real- valued) random variable $X$ has full support and is absolutely continuous with respect to the Lebesgue measure. I am confused on what is commonly intended by ""full support"". Does the author want to say that the support is $\mathbb{R}$? (which, together with absolute continuity, would then imply that the cumulative distribution function is strictly positive - and, hence, strictly monotone increasing - on $\mathbb{R}$)","I am reading an article which introduces the following assumption at a certain point: The probability distribution of the (real- valued) random variable $X$ has full support and is absolutely continuous with respect to the Lebesgue measure. I am confused on what is commonly intended by ""full support"". Does the author want to say that the support is $\mathbb{R}$? (which, together with absolute continuity, would then imply that the cumulative distribution function is strictly positive - and, hence, strictly monotone increasing - on $\mathbb{R}$)",,"['probability', 'measure-theory', 'probability-distributions', 'random-variables']"
92,number of edges in a transitive closure of a random directed graph,number of edges in a transitive closure of a random directed graph,,"First two definition: (A) Random Directed Graph: Suppose we have a random $DAG(n, p)$. Here is how it's generated: Put n distinct nodes on a line, and connect each node in the $i$th order to any node after that; This would form a complete directed graph with $n$ nodes. Sample each edge with probability $p$. The resulting graph will be directed, and acyclic. (B) Transitive Closure: Transitive closure of a graph $\text{closure}(G)$ is the result of connecting all the node pairs $i-j$ (via a direct edge $i \rightarrow j$) such that there is a path connecting $i$ to $j$. The question is: what is the expected number of edges in $\text{closure}(DAG(n, p))$?","First two definition: (A) Random Directed Graph: Suppose we have a random $DAG(n, p)$. Here is how it's generated: Put n distinct nodes on a line, and connect each node in the $i$th order to any node after that; This would form a complete directed graph with $n$ nodes. Sample each edge with probability $p$. The resulting graph will be directed, and acyclic. (B) Transitive Closure: Transitive closure of a graph $\text{closure}(G)$ is the result of connecting all the node pairs $i-j$ (via a direct edge $i \rightarrow j$) such that there is a path connecting $i$ to $j$. The question is: what is the expected number of edges in $\text{closure}(DAG(n, p))$?",,"['probability', 'graph-theory', 'random-graphs']"
93,Probability not divisible by $k^2$,Probability not divisible by,k^2,"My question is about this problem: Let $s > 1$ and $$\zeta(s) = \sum_{n = 1}^{\infty} n^{-s}.$$ Furthermore let $(\Omega, \mathcal{F}, \mathbb{P}$) be a probability space with $\Omega = \mathbb{N}$, $\mathcal{F} = 2^{\Omega}$ and  $$\mathbb{P}({n}) = \frac{n^{-s}}{\zeta(s)}, n \in \mathbb{N}.$$ We define $\mathcal{P}_n = p$ is a prime number and $p \le n$ and $\mathcal{P}_\infty = \cup_{n \in \mathbb{N}} \mathcal{P}_n$. Prove the following : $\mathbb{P}(n \in \mathbb{N} : k^2$ does not divide $n$ for all $k \ge 2$) means $$\prod_{p \in \mathcal{P}_\infty} (1 - p^{-2s})$$ I do not really how to start this, I am unable to find any link between the right-hand side and the left-hande of the equation. I am grateful for any tip, suggestion and piece of advice","My question is about this problem: Let $s > 1$ and $$\zeta(s) = \sum_{n = 1}^{\infty} n^{-s}.$$ Furthermore let $(\Omega, \mathcal{F}, \mathbb{P}$) be a probability space with $\Omega = \mathbb{N}$, $\mathcal{F} = 2^{\Omega}$ and  $$\mathbb{P}({n}) = \frac{n^{-s}}{\zeta(s)}, n \in \mathbb{N}.$$ We define $\mathcal{P}_n = p$ is a prime number and $p \le n$ and $\mathcal{P}_\infty = \cup_{n \in \mathbb{N}} \mathcal{P}_n$. Prove the following : $\mathbb{P}(n \in \mathbb{N} : k^2$ does not divide $n$ for all $k \ge 2$) means $$\prod_{p \in \mathcal{P}_\infty} (1 - p^{-2s})$$ I do not really how to start this, I am unable to find any link between the right-hand side and the left-hande of the equation. I am grateful for any tip, suggestion and piece of advice",,"['probability', 'number-theory', 'probability-theory', 'prime-numbers']"
94,Conditional Distribution from Gamma Distribution,Conditional Distribution from Gamma Distribution,,"Consider a random sample of size $n$ froma  gamma distribution, $X_i\sim GAM(\theta, \kappa)$ , with $\kappa$ being the shape parameter and $\theta$ being the scale parameter and let $\bar X=\dfrac{1}{n}\sum X_i$ and $\tilde X=(\prod X_i)^{1/n}$ be the sample mean and geometric mean, respectively. Show that the conditional distribution of $\bar X |_{\tilde X = \tilde x}$ does not depend on $\kappa$ . I have absolutely no idea how to find this conditional distribution.  Even if there are some strategies to go about solving this problem without solving for the conditional distribution explicitly, I don't know what they are.  How would you show this?  Is there a general strategy for finding conditional distributions of statistics that I don't know about?  I'm so lost.","Consider a random sample of size froma  gamma distribution, , with being the shape parameter and being the scale parameter and let and be the sample mean and geometric mean, respectively. Show that the conditional distribution of does not depend on . I have absolutely no idea how to find this conditional distribution.  Even if there are some strategies to go about solving this problem without solving for the conditional distribution explicitly, I don't know what they are.  How would you show this?  Is there a general strategy for finding conditional distributions of statistics that I don't know about?  I'm so lost.","n X_i\sim GAM(\theta, \kappa) \kappa \theta \bar X=\dfrac{1}{n}\sum X_i \tilde X=(\prod X_i)^{1/n} \bar X |_{\tilde X = \tilde x} \kappa","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
95,Find probability density function for $\varepsilon \cdot X$.,Find probability density function for .,\varepsilon \cdot X,"Let $ X $ be exponentially distributed with parameter $\lambda > 0$ . $a)$ Find the probability density function for $ Y := exp(X) $. $b)$ Consider $X$ again. Now let $\varepsilon$ be  an independent random variable with $P(\varepsilon = 1 ) = \frac{1}{2}  $ and $P(\varepsilon = -1 ) = \frac{1}{2}  $. Find the probability density function for $\varepsilon \cdot X$. So a) was no big deal. but I'm stucked in $b)$. Remark(Update) : I read that $ \varepsilon  \cdot X $ has to be $Laplace(0,\frac{1}{\lambda})$ distributed. We want to compute CDF of $YX$. [ $Y := \varepsilon$ ]. Let us say that $ a \ge 0 $ We start with $ F(a) = P(YX \le a) = P(X > -a | Y = -1)P( Y=-1) + P(X \le a |Y =1)P(Y=1) = P(X > -a)P( Y=-1) + P(X \le a)P(Y=1)  = \frac{1}{2} + (1-e^{-\lambda \cdot a}) \cdot \frac{1}{2}.   $ Then we take $F'(a)$ and get that $f(a)$ is $\frac{1}{2} \cdot \lambda \cdot e^{-\lambda \cdot a} $. So $YX$ is  $Lap(0,\frac{1}{\lambda})$. Thank you for your help.","Let $ X $ be exponentially distributed with parameter $\lambda > 0$ . $a)$ Find the probability density function for $ Y := exp(X) $. $b)$ Consider $X$ again. Now let $\varepsilon$ be  an independent random variable with $P(\varepsilon = 1 ) = \frac{1}{2}  $ and $P(\varepsilon = -1 ) = \frac{1}{2}  $. Find the probability density function for $\varepsilon \cdot X$. So a) was no big deal. but I'm stucked in $b)$. Remark(Update) : I read that $ \varepsilon  \cdot X $ has to be $Laplace(0,\frac{1}{\lambda})$ distributed. We want to compute CDF of $YX$. [ $Y := \varepsilon$ ]. Let us say that $ a \ge 0 $ We start with $ F(a) = P(YX \le a) = P(X > -a | Y = -1)P( Y=-1) + P(X \le a |Y =1)P(Y=1) = P(X > -a)P( Y=-1) + P(X \le a)P(Y=1)  = \frac{1}{2} + (1-e^{-\lambda \cdot a}) \cdot \frac{1}{2}.   $ Then we take $F'(a)$ and get that $f(a)$ is $\frac{1}{2} \cdot \lambda \cdot e^{-\lambda \cdot a} $. So $YX$ is  $Lap(0,\frac{1}{\lambda})$. Thank you for your help.",,"['probability', 'density-function', 'exponential-distribution']"
96,Expected value of max of a Stochastic process,Expected value of max of a Stochastic process,,"Ciao all, I'm working on some stochastic processes and I'm stuck on this problem. Let $S_t$ be the stochastic process defined by: $$ dS_t = \sigma S_t dW_t $$ with initial data $S_0 \in \mathbb{R}^+$. I'm trying to compute the expected value: $$ \mathbb{E}\left[ \max_{t \in [0, T]}S_t \right] $$ but it's not clear how to fight the problem. For example I cannot use Ito's Lemma since the function is not $C^1$ w.r.t. $S_t$. I've started from a simpler case: $$ \begin{align} \mathbb{E} [\max(S_t, S_T)] & = \mathbb{E}[S_t]\mathbb{P}(S_t > S_T) + \mathbb{E}[S_T]\mathbb{P}(S_T > S_t)\\ & = S_0 \left(\mathbb{P}(S_T > S_t) + \mathbb{P}(S_t > S_T) \right) \end{align} $$ At this point the two terms on the rhs can be computed directly. My idea was to extend this computation for all $t$ but I'm sure I have to take in account in somehow that the expected value at a future time is conditionated by all the past times. Can you help be, even with some ideas? Thank you, ciao! AM","Ciao all, I'm working on some stochastic processes and I'm stuck on this problem. Let $S_t$ be the stochastic process defined by: $$ dS_t = \sigma S_t dW_t $$ with initial data $S_0 \in \mathbb{R}^+$. I'm trying to compute the expected value: $$ \mathbb{E}\left[ \max_{t \in [0, T]}S_t \right] $$ but it's not clear how to fight the problem. For example I cannot use Ito's Lemma since the function is not $C^1$ w.r.t. $S_t$. I've started from a simpler case: $$ \begin{align} \mathbb{E} [\max(S_t, S_T)] & = \mathbb{E}[S_t]\mathbb{P}(S_t > S_T) + \mathbb{E}[S_T]\mathbb{P}(S_T > S_t)\\ & = S_0 \left(\mathbb{P}(S_T > S_t) + \mathbb{P}(S_t > S_T) \right) \end{align} $$ At this point the two terms on the rhs can be computed directly. My idea was to extend this computation for all $t$ but I'm sure I have to take in account in somehow that the expected value at a future time is conditionated by all the past times. Can you help be, even with some ideas? Thank you, ciao! AM",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
97,Probability of the existence of a specific pattern in one million coin flips,Probability of the existence of a specific pattern in one million coin flips,,"I came across this question while preparing for an interview. Given a coin with head-up probability p, flip it $N = 1,000,000$ times. What is the probability that a string of ""HHHHHHTTTTTT"" (i.e. 6 heads followed by 6 tails) exists? Can this pattern be generalized? Any idea on the question? Thanks in advance! This question has two related questions: Average number of the pattern. Average number of the pattern of at least 6 tails in a row. For Question 1, one can solve it using the linearity of expectation. Specifically, let $X_i$ be a binary variable indicating whether there is one such pattern starting at the ith flip. Then the average number of the pattern across all one million flips is just \begin{align*} E \sum_{i=1}^{N-11} X_i &= \sum_{i=1}^{N-11} E X_i \\ &= (N-11) p^6(1-p)^6. \end{align*} Question 2 can be solved in a similar way. The only difference is that this time $X_i=1$ requires that the $(i-1)$th flip is a head. Hence \begin{align*} E \sum_{i=1}^{N-5} X_i &= E X_1 + \sum_{i=2}^{N-5} E X_i \\ &= (1-p)^6+(N-6) p(1-p)^6 \\ &=(1+Np-6p)(1-p)^6. \end{align*}","I came across this question while preparing for an interview. Given a coin with head-up probability p, flip it $N = 1,000,000$ times. What is the probability that a string of ""HHHHHHTTTTTT"" (i.e. 6 heads followed by 6 tails) exists? Can this pattern be generalized? Any idea on the question? Thanks in advance! This question has two related questions: Average number of the pattern. Average number of the pattern of at least 6 tails in a row. For Question 1, one can solve it using the linearity of expectation. Specifically, let $X_i$ be a binary variable indicating whether there is one such pattern starting at the ith flip. Then the average number of the pattern across all one million flips is just \begin{align*} E \sum_{i=1}^{N-11} X_i &= \sum_{i=1}^{N-11} E X_i \\ &= (N-11) p^6(1-p)^6. \end{align*} Question 2 can be solved in a similar way. The only difference is that this time $X_i=1$ requires that the $(i-1)$th flip is a head. Hence \begin{align*} E \sum_{i=1}^{N-5} X_i &= E X_1 + \sum_{i=2}^{N-5} E X_i \\ &= (1-p)^6+(N-6) p(1-p)^6 \\ &=(1+Np-6p)(1-p)^6. \end{align*}",,"['probability', 'probability-theory', 'statistics']"
98,Does an ergodic random process imply stationarity or just wide-sense stationarity?,Does an ergodic random process imply stationarity or just wide-sense stationarity?,,"Let $X(t)$ be a random process. It is well known that stationarity is more strict condition than wide-sense stationarity. In a stationary random process, the pdf of a random variable $X(t_i)$ is the same at any time instance $t_i$. On the other hand, in a wide-sense stationary process, every random variable $X(t_i)$ has the same mean and variance, while the pdf's may be different for different time instances $t_i$. In other words, we can say that the wide-sense stationary random process has the time-invariant ensemble average and variance. The autocorrelation function depends just on the time difference $\tau$, i.e. $R(\tau)$, no matter if we talk about the stationary of the wide-sense stationary process. In an ergodic random process, the time-invariant ensemble average must be equal (with probability one) to the time average of every single realization of the random process $X(t)$. Now assume that we have an ergodic random process $X(t)$. Is $X(t)$ stationary or wide-sense stationary then? I read somewhere that ergodicity implies stationarity, but I think that ergodicity implies just wide-sense stationarity. The reason follows from the definition of ergodic random process. That is, if we have an ergodic random process, we know that it has the time-invariant ensemble average which is the criteria set for the wide-sense stationary process. I would like someone to correct me if I am wrong, or to confirm it.","Let $X(t)$ be a random process. It is well known that stationarity is more strict condition than wide-sense stationarity. In a stationary random process, the pdf of a random variable $X(t_i)$ is the same at any time instance $t_i$. On the other hand, in a wide-sense stationary process, every random variable $X(t_i)$ has the same mean and variance, while the pdf's may be different for different time instances $t_i$. In other words, we can say that the wide-sense stationary random process has the time-invariant ensemble average and variance. The autocorrelation function depends just on the time difference $\tau$, i.e. $R(\tau)$, no matter if we talk about the stationary of the wide-sense stationary process. In an ergodic random process, the time-invariant ensemble average must be equal (with probability one) to the time average of every single realization of the random process $X(t)$. Now assume that we have an ergodic random process $X(t)$. Is $X(t)$ stationary or wide-sense stationary then? I read somewhere that ergodicity implies stationarity, but I think that ergodicity implies just wide-sense stationarity. The reason follows from the definition of ergodic random process. That is, if we have an ergodic random process, we know that it has the time-invariant ensemble average which is the criteria set for the wide-sense stationary process. I would like someone to correct me if I am wrong, or to confirm it.",,"['probability', 'stochastic-processes', 'random-variables', 'stationary-processes']"
99,Additive functionals of simple Markov chain,Additive functionals of simple Markov chain,,"Suppose we have an irreducible and aperiodic discrete-time Markov chain on a finite set $S$ with stationary probability $\pi$; denote it by $(X_0, X_1, X_2,...)$. It is known that for every $x\in S$ and every positive function $f:S\to \mathbb{R}_+$ $$ \frac{1}{n}\sum_{k=0}^{n-1} f(X_k) \to \int f d\pi$$ $\mathbb{P}_x$ almost surely. Are there any good resources where the speed of this convergence, namely, the quantity (for an $f\in L^1(\pi)$) $$ \mathbb{P}_x\bigg( \bigg|\frac{1}{n}\sum_{k=0}^{n-1} f(X_k) -\int f d\pi \bigg| > \varepsilon\bigg)$$ is explored ? I guess this probability decays exponentially for every $x\in S$ in the ""ideal"" (finite, irreducible, aperiodic) case. Are there any books that answer this question in this simple setting ? I am not looking for generalisations to arbitrary spaces, that most recent papers deal with, but rather a simple, clean and concise statement and proof ! More precisely, I am interested in the case where $f(x)=f_y(x)=1\{x=y\}$ for $y \in S$, since I would like to have exact quantitative bounds on the probability that the empirical measure of the Markov chain deviates from the true invariant probability by more than some small amount.","Suppose we have an irreducible and aperiodic discrete-time Markov chain on a finite set $S$ with stationary probability $\pi$; denote it by $(X_0, X_1, X_2,...)$. It is known that for every $x\in S$ and every positive function $f:S\to \mathbb{R}_+$ $$ \frac{1}{n}\sum_{k=0}^{n-1} f(X_k) \to \int f d\pi$$ $\mathbb{P}_x$ almost surely. Are there any good resources where the speed of this convergence, namely, the quantity (for an $f\in L^1(\pi)$) $$ \mathbb{P}_x\bigg( \bigg|\frac{1}{n}\sum_{k=0}^{n-1} f(X_k) -\int f d\pi \bigg| > \varepsilon\bigg)$$ is explored ? I guess this probability decays exponentially for every $x\in S$ in the ""ideal"" (finite, irreducible, aperiodic) case. Are there any books that answer this question in this simple setting ? I am not looking for generalisations to arbitrary spaces, that most recent papers deal with, but rather a simple, clean and concise statement and proof ! More precisely, I am interested in the case where $f(x)=f_y(x)=1\{x=y\}$ for $y \in S$, since I would like to have exact quantitative bounds on the probability that the empirical measure of the Markov chain deviates from the true invariant probability by more than some small amount.",,"['probability', 'probability-theory', 'markov-chains', 'monte-carlo', 'concentration-of-measure']"
