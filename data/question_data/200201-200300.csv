,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Moving a compact submanifold off of another submanifold?,Moving a compact submanifold off of another submanifold?,,"This is an intuitive idea that I see referenced a lot. Consider the following situation. Let $M$ and $N$ be submanifolds, $M$ compact, in some larger manifold $X$. Suppose also that $\dim(M)+\dim(N)<\dim(X)$. Since there are enough dimensions to ""move around,"" we can pull $M$ off of $N$ with a very small perturbation. Is there a rigourous proof of this concept? Let me try to state my question more formally. With $M$ and $N$ as above, does there always exist a deformation $\iota_t(M)$ of $M$ such that $\iota_1(M)\cap N=\emptyset$, but $|m-\iota_1(m)|\leq\epsilon$ for all $m\in M$ where $\epsilon>0$ is arbitrary. (Please let me know if my question doesn't make sense as posed. Thanks.)","This is an intuitive idea that I see referenced a lot. Consider the following situation. Let $M$ and $N$ be submanifolds, $M$ compact, in some larger manifold $X$. Suppose also that $\dim(M)+\dim(N)<\dim(X)$. Since there are enough dimensions to ""move around,"" we can pull $M$ off of $N$ with a very small perturbation. Is there a rigourous proof of this concept? Let me try to state my question more formally. With $M$ and $N$ as above, does there always exist a deformation $\iota_t(M)$ of $M$ such that $\iota_1(M)\cap N=\emptyset$, but $|m-\iota_1(m)|\leq\epsilon$ for all $m\in M$ where $\epsilon>0$ is arbitrary. (Please let me know if my question doesn't make sense as posed. Thanks.)",,"['differential-geometry', 'manifolds', 'differential-topology', 'compact-manifolds']"
1,Evaluate the Integral of a 2-form over a Torus,Evaluate the Integral of a 2-form over a Torus,,"This is a problem from a past qualifying exam that seems a bit too calculation intensive so I was hoping that someone might see a better way to approach this. We are given the 2-form $$\omega = \frac{xdy\wedge dz + y dz\wedge dx +  z dx\wedge dy}{(x^2 + y^2 + z^2)^{3/2}},$$ and asked to verify that it is a closed 2-form on $\mathbb{R}-\{0\}.$ This is straight forward.  Then we are asked to evaluate the the integral $\int_T \omega$ where $T\subset \mathbb{R}^3-\{0\}$ is the torus  $$\left(\sqrt{(x-2)^2 + y^2}-2\right)^2 + z^2 = 1$$obtained by rotating the unit circle in the $xz$-plane about the line $x=2,$ $y=0$. I approached this by finding the parametric equations for the torus, namely $$F(u,v) = (2 + (2+\cos v)\cos u, (2+\cos v)\sin u, \sin v),$$ and calculating $\int_0^{2\pi}\int_0^{2\pi} F^*\omega.$ This is pretty time-intensive and there is a lot of room for computational error, so I figured there may be a different way to approach this.","This is a problem from a past qualifying exam that seems a bit too calculation intensive so I was hoping that someone might see a better way to approach this. We are given the 2-form $$\omega = \frac{xdy\wedge dz + y dz\wedge dx +  z dx\wedge dy}{(x^2 + y^2 + z^2)^{3/2}},$$ and asked to verify that it is a closed 2-form on $\mathbb{R}-\{0\}.$ This is straight forward.  Then we are asked to evaluate the the integral $\int_T \omega$ where $T\subset \mathbb{R}^3-\{0\}$ is the torus  $$\left(\sqrt{(x-2)^2 + y^2}-2\right)^2 + z^2 = 1$$obtained by rotating the unit circle in the $xz$-plane about the line $x=2,$ $y=0$. I approached this by finding the parametric equations for the torus, namely $$F(u,v) = (2 + (2+\cos v)\cos u, (2+\cos v)\sin u, \sin v),$$ and calculating $\int_0^{2\pi}\int_0^{2\pi} F^*\omega.$ This is pretty time-intensive and there is a lot of room for computational error, so I figured there may be a different way to approach this.",,['differential-geometry']
2,Pullback of a $1$-form,Pullback of a -form,1,"All: I looked at the list of similar questions, but none seemed to be done explicitly-enough to be helpful; sorry for the repeat, but maybe seeing more examples will be helpful to many. So, I have a differentiable map $f: M \rightarrow S^1 $ , and I want to pullback $d\theta$ by f. Here is what I have: Say we use the basis $\{ \partial/\partial x^i\}, \, i=1,2,3$ for the tangent space $T_xM$ i)We calculate $Jf=[\partial f/\partial x^1  \partial f/\partial x^2 \partial f/ \partial x^3]$ ii)We use i) to calculate the pushforward of the tangent vectors by f: $ f_* (\partial/ \partial x^i) $=$ (\partial f/\partial x^i) (\partial/ \partial(\theta$)) iii)We evaluate $d\theta$ $(\partial f/ \partial x^i) (\partial/ \partial(\theta))$=$\partial f/ \partial x^i$ iv) We conclude : $f^* (d\theta)$=$ \partial f/ \partial x^1(d\theta)+\partial f/ \partial x^2(d\theta)+\partial f/\partial x^3(d\theta))$ Is this correct? Do I have to consider only chartwise representations, or is this a global representation for $f^*(d\theta)$ ? EDIT: I appreciate both your explanations, but I've been confused with this for so long that I was hoping someone would answer this; I know pulling back a k-form is just the multilinear equivalent of calculating $T^*$ $V^*\rightarrow W^*$ given a linear map $T:V\rightarrow W$ between finite-dimensional vector spaces, so : I'm trying to follow the formula: $f^*= \Sigma_I (wof)d(y^{i_1}of)\wedge d(y^{1_2}of).....\wedge d(y^{i_n}of)$  (##) But maybe I need to express $d(\theta)$ in a different basis? The result I got using (##) is $f^*(d\theta)=(1of)(d(\theta of)=d(\theta)of+(\theta)odf$ Which does not seem to agree with neither answer I would appreciate more than one explanation, but, out of fairness, I will admit now that I will accept the first answer I get, unless (both) the second one comes closely after the first in time and has something substantially better. Unfortunately, at my point level, I'm not allowed to give points for a good answer. Thanks. Thanks for your help.","All: I looked at the list of similar questions, but none seemed to be done explicitly-enough to be helpful; sorry for the repeat, but maybe seeing more examples will be helpful to many. So, I have a differentiable map $f: M \rightarrow S^1 $ , and I want to pullback $d\theta$ by f. Here is what I have: Say we use the basis $\{ \partial/\partial x^i\}, \, i=1,2,3$ for the tangent space $T_xM$ i)We calculate $Jf=[\partial f/\partial x^1  \partial f/\partial x^2 \partial f/ \partial x^3]$ ii)We use i) to calculate the pushforward of the tangent vectors by f: $ f_* (\partial/ \partial x^i) $=$ (\partial f/\partial x^i) (\partial/ \partial(\theta$)) iii)We evaluate $d\theta$ $(\partial f/ \partial x^i) (\partial/ \partial(\theta))$=$\partial f/ \partial x^i$ iv) We conclude : $f^* (d\theta)$=$ \partial f/ \partial x^1(d\theta)+\partial f/ \partial x^2(d\theta)+\partial f/\partial x^3(d\theta))$ Is this correct? Do I have to consider only chartwise representations, or is this a global representation for $f^*(d\theta)$ ? EDIT: I appreciate both your explanations, but I've been confused with this for so long that I was hoping someone would answer this; I know pulling back a k-form is just the multilinear equivalent of calculating $T^*$ $V^*\rightarrow W^*$ given a linear map $T:V\rightarrow W$ between finite-dimensional vector spaces, so : I'm trying to follow the formula: $f^*= \Sigma_I (wof)d(y^{i_1}of)\wedge d(y^{1_2}of).....\wedge d(y^{i_n}of)$  (##) But maybe I need to express $d(\theta)$ in a different basis? The result I got using (##) is $f^*(d\theta)=(1of)(d(\theta of)=d(\theta)of+(\theta)odf$ Which does not seem to agree with neither answer I would appreciate more than one explanation, but, out of fairness, I will admit now that I will accept the first answer I get, unless (both) the second one comes closely after the first in time and has something substantially better. Unfortunately, at my point level, I'm not allowed to give points for a good answer. Thanks. Thanks for your help.",,['differential-geometry']
3,Killing Vector Field determined by one point,Killing Vector Field determined by one point,,"I am trying to prove that if $X$ is a Killing vector field on a connected Riemannian manifold $(M,g)$ (i.e. $\mathfrak L_X g = 0$), then $X$ is determined by $X_p$ and $\nabla X|_p$ for any point $p \in M$. It suffices to prove that if $X_p = 0$ and $\nabla X|_p = 0$ then $X = 0$. Clearly, the condition implies that $X$ is zero along the flow line of $X$ through $p$. However, I am having trouble finding a way to show that $X$ must be 0 on all of $M$. Does anyone have any suggestions?","I am trying to prove that if $X$ is a Killing vector field on a connected Riemannian manifold $(M,g)$ (i.e. $\mathfrak L_X g = 0$), then $X$ is determined by $X_p$ and $\nabla X|_p$ for any point $p \in M$. It suffices to prove that if $X_p = 0$ and $\nabla X|_p = 0$ then $X = 0$. Clearly, the condition implies that $X$ is zero along the flow line of $X$ through $p$. However, I am having trouble finding a way to show that $X$ must be 0 on all of $M$. Does anyone have any suggestions?",,"['differential-geometry', 'riemannian-geometry']"
4,Vector Bundles and Distributions,Vector Bundles and Distributions,,How can I show that following: If $F\subseteq TM$ is a smooth distribution then $F$ is vector bundle and the inclusion $F\hookrightarrow TM$ is a morphism of vector bundles?,How can I show that following: If $F\subseteq TM$ is a smooth distribution then $F$ is vector bundle and the inclusion $F\hookrightarrow TM$ is a morphism of vector bundles?,,"['differential-geometry', 'vector-bundles']"
5,Showing that left-invariant vector fields commute with right-invariant vector fields,Showing that left-invariant vector fields commute with right-invariant vector fields,,"I’m trying to prove that if $G$ is a Lie group, $X$ is a left-invariant vector field on $G$ , and $Y$ is a right-invariant vector field on $G$ , then $[X,Y] =0$ . When I imagine what it means to be left-invariant, I’m thinking of $X$ as a section of the tangent bundle, and left-invariance says that if I act on $G$ by left multiplication, the vector field is preserved, i.e., $L_{g*}X_e = X_g$ , where $X_e \in T_eG$ and $X_g \in T_gG$ are thought of as tangent vectors. On the other hand, when I think of the Lie bracket, I’m used to thinking of vector fields as derivations of $C^\infty(G)$ . That way the $XY$ term in the commutator is simply a composition of derivations. I’m not sure what it would mean to talk about $XY$ when we think of vector fields as sections of the tangent bundle, and I’m getting confused about what it means for a derivation to be left-invariant. Any help would be appreciated!","I’m trying to prove that if is a Lie group, is a left-invariant vector field on , and is a right-invariant vector field on , then . When I imagine what it means to be left-invariant, I’m thinking of as a section of the tangent bundle, and left-invariance says that if I act on by left multiplication, the vector field is preserved, i.e., , where and are thought of as tangent vectors. On the other hand, when I think of the Lie bracket, I’m used to thinking of vector fields as derivations of . That way the term in the commutator is simply a composition of derivations. I’m not sure what it would mean to talk about when we think of vector fields as sections of the tangent bundle, and I’m getting confused about what it means for a derivation to be left-invariant. Any help would be appreciated!","G X G Y G [X,Y] =0 X G L_{g*}X_e = X_g X_e \in T_eG X_g \in T_gG C^\infty(G) XY XY","['differential-geometry', 'lie-groups']"
6,Computing the curvature of a connection (a specific example),Computing the curvature of a connection (a specific example),,"I'm learning about the curvature of a vector bundle, and trying to compute it for a simple example. Let $\nabla$ be the connection on a trivial line bundle over $\mathbb{R}^2$ given by $\nabla s = ds$. I know that curvature is given by $F(X,Y)(s) = \nabla_X\nabla_Ys - \nabla_{Y} \nabla_Xs - \nabla_{[X,Y]}s$. I found that $\nabla_X\nabla_Ys = \nabla_X(ds(Y)) = \nabla(ds(Y))(X) = d(ds(Y))(X) = 0$, and similarly $\nabla_{Y} \nabla_Xs =0$. How do I compute $\nabla_{[X,Y]}s$? I've written it as $(ds)[X,Y] = ds(XY)-ds(YX) = (XY)(s)-(YX)(s)$ but I'm not sure where to go from here.","I'm learning about the curvature of a vector bundle, and trying to compute it for a simple example. Let $\nabla$ be the connection on a trivial line bundle over $\mathbb{R}^2$ given by $\nabla s = ds$. I know that curvature is given by $F(X,Y)(s) = \nabla_X\nabla_Ys - \nabla_{Y} \nabla_Xs - \nabla_{[X,Y]}s$. I found that $\nabla_X\nabla_Ys = \nabla_X(ds(Y)) = \nabla(ds(Y))(X) = d(ds(Y))(X) = 0$, and similarly $\nabla_{Y} \nabla_Xs =0$. How do I compute $\nabla_{[X,Y]}s$? I've written it as $(ds)[X,Y] = ds(XY)-ds(YX) = (XY)(s)-(YX)(s)$ but I'm not sure where to go from here.",,['differential-geometry']
7,proof of preimage theorem for abstract manifolds?,proof of preimage theorem for abstract manifolds?,,"How is the preimage theorem proved for abstract manifolds (not necessarily embedded in $\mathbb{R}^N$)? It states that if $F:M\rightarrow N$ is a smooth map between smooth manifolds and $q\in N$ and $Z=F^{-1}(q)\neq\emptyset$ and $F_*|_p$ (i.e. $D_pF$, or $dF_p$, or various other notations!) is surjective for all $p\in F^{-1}(q)$, then $Z$ is an embedded submanifold of $M$ of dimension $k=\mathrm{dim}(M)-\mathrm{dim}(N)$. I've got as far as showing that for fixed $p\in F^{-1}(q)$, the kernel $K$ of $F_*|_p$ in $T_pM$ must be a subspace of dimension $k$. If $M\subset\mathbb{R}^N$, we can then proceed by taking a linear map $\mu:\mathbb{R}^N\rightarrow\mathbb{R}^k$ such that $\mathrm{ker}(\mu)\cap K=\{0\}$ and then considering the map $(F,\mu)$. But what if we can't assume this? Must there be a map $G:M\rightarrow\mathbb{R}^k$ such that $G_*|_p$ satisfies the condition required for $\mu$ above, or is there a different method? Many thanks for any help with this!","How is the preimage theorem proved for abstract manifolds (not necessarily embedded in $\mathbb{R}^N$)? It states that if $F:M\rightarrow N$ is a smooth map between smooth manifolds and $q\in N$ and $Z=F^{-1}(q)\neq\emptyset$ and $F_*|_p$ (i.e. $D_pF$, or $dF_p$, or various other notations!) is surjective for all $p\in F^{-1}(q)$, then $Z$ is an embedded submanifold of $M$ of dimension $k=\mathrm{dim}(M)-\mathrm{dim}(N)$. I've got as far as showing that for fixed $p\in F^{-1}(q)$, the kernel $K$ of $F_*|_p$ in $T_pM$ must be a subspace of dimension $k$. If $M\subset\mathbb{R}^N$, we can then proceed by taking a linear map $\mu:\mathbb{R}^N\rightarrow\mathbb{R}^k$ such that $\mathrm{ker}(\mu)\cap K=\{0\}$ and then considering the map $(F,\mu)$. But what if we can't assume this? Must there be a map $G:M\rightarrow\mathbb{R}^k$ such that $G_*|_p$ satisfies the condition required for $\mu$ above, or is there a different method? Many thanks for any help with this!",,"['differential-geometry', 'manifolds']"
8,Yang-Mills equations,Yang-Mills equations,,I would like that someone explain to me the Yang-Mills equations as defined in some books: $$ \begin{cases} d_D F = 0 \\ *d_D *F = J \end{cases} $$ What is $ d_D $ ? What is $ F $ ? What are $ *d $ and $ *F $ ? What is $ J $ ? Can we represent those quantities with matrix to simplify the explanation? Thank you very much all of you.,I would like that someone explain to me the Yang-Mills equations as defined in some books: What is ? What is ? What are and ? What is ? Can we represent those quantities with matrix to simplify the explanation? Thank you very much all of you., \begin{cases} d_D F = 0 \\ *d_D *F = J \end{cases}   d_D   F   *d   *F   J ,['differential-geometry']
9,smooth maps between smooth manifolds - Jacobian coordinate independence,smooth maps between smooth manifolds - Jacobian coordinate independence,,"I have question about comment in Lee's Introduction to Smooth Manifolds - page 51. Given smooth map $F:M\to N$ between smooth manifolds $M$ and $N$ we say that the total derivative of $F$ at $p\in M$ (given chart $(U,\varphi)$ around $p$ and $(V,\psi)$ around $F(p)$) is given by $D(\psi\circ F\circ \varphi^{-1})(\varphi(p))$. The comment in the book is that total derivative is chart independent. If there is another chart $(U',\varphi')$ around $p$ then we should have $$D(\psi\circ F\circ\varphi'^{-1})(\varphi'(p))=D(\psi\circ F\circ \varphi^{-1}\circ \varphi \circ \varphi'^{-1})(\varphi'(p))=$$ $$D(\psi\circ F\circ\varphi^{-1})(\varphi(p))\cdot D(\varphi \circ\varphi'^{-1})(\varphi (p)).$$ If total derivative is chart independent we should have $D(\varphi\circ \varphi'^{-1})(\varphi'(p))=\mathbb{Id}$, which doesn't have to be the case. Whats wrong in my reasoning?","I have question about comment in Lee's Introduction to Smooth Manifolds - page 51. Given smooth map $F:M\to N$ between smooth manifolds $M$ and $N$ we say that the total derivative of $F$ at $p\in M$ (given chart $(U,\varphi)$ around $p$ and $(V,\psi)$ around $F(p)$) is given by $D(\psi\circ F\circ \varphi^{-1})(\varphi(p))$. The comment in the book is that total derivative is chart independent. If there is another chart $(U',\varphi')$ around $p$ then we should have $$D(\psi\circ F\circ\varphi'^{-1})(\varphi'(p))=D(\psi\circ F\circ \varphi^{-1}\circ \varphi \circ \varphi'^{-1})(\varphi'(p))=$$ $$D(\psi\circ F\circ\varphi^{-1})(\varphi(p))\cdot D(\varphi \circ\varphi'^{-1})(\varphi (p)).$$ If total derivative is chart independent we should have $D(\varphi\circ \varphi'^{-1})(\varphi'(p))=\mathbb{Id}$, which doesn't have to be the case. Whats wrong in my reasoning?",,['differential-geometry']
10,Wedge product of 1-Forms,Wedge product of 1-Forms,,"I'm trying to write down the wedge product of 2 1-forms on an n-dimensional Manifold. $\alpha = \alpha_1 dx^1 + \alpha_2 dx^2 + \cdots + \alpha_n dx^n$ and $\beta = \beta_1 dx^1 + \beta_2 dx^2 + \cdots + \beta_n dx^n$ I know how to do this for the 2 and 3 dimensional case. But I'm having a problem with the n-dimensional case. More specifically, what sign the individual 2-forms get? What I mean by this is, let's concider a few terms of $\alpha \wedge \beta$: $\cdots \alpha_1 \beta_2 dx^1\wedge dx^2 + \alpha_2 \beta_1 dx^2 \wedge dx^1 \cdots$ Now the problem I'm having is, I think $dx^2\wedge dx^1 = -dx^1\wedge dx^2$. Which allows me to combine the above two terms. For 2 and 3 dimensions, this seems easy, as I can just look at the permutations, but in n-dimensions, (1) how does this permutation look like? Or is it always minus if I switch the $dx$? (2) Does this mean that $\alpha\wedge\alpha = 0$ always for 1 forms?","I'm trying to write down the wedge product of 2 1-forms on an n-dimensional Manifold. $\alpha = \alpha_1 dx^1 + \alpha_2 dx^2 + \cdots + \alpha_n dx^n$ and $\beta = \beta_1 dx^1 + \beta_2 dx^2 + \cdots + \beta_n dx^n$ I know how to do this for the 2 and 3 dimensional case. But I'm having a problem with the n-dimensional case. More specifically, what sign the individual 2-forms get? What I mean by this is, let's concider a few terms of $\alpha \wedge \beta$: $\cdots \alpha_1 \beta_2 dx^1\wedge dx^2 + \alpha_2 \beta_1 dx^2 \wedge dx^1 \cdots$ Now the problem I'm having is, I think $dx^2\wedge dx^1 = -dx^1\wedge dx^2$. Which allows me to combine the above two terms. For 2 and 3 dimensions, this seems easy, as I can just look at the permutations, but in n-dimensions, (1) how does this permutation look like? Or is it always minus if I switch the $dx$? (2) Does this mean that $\alpha\wedge\alpha = 0$ always for 1 forms?",,['differential-geometry']
11,Identification of $T_v(T_pM)$ with $T_pM$,Identification of  with,T_v(T_pM) T_pM,"In some passages of Do Carmo's Riemannian geometry book he identify $T_v(T_pM)$ with $T_pM$, my question: How one see $T_pM$ as a manifold? who is the atlas? What is the expression of a vector $x \in T_v(T_pM)$ in local coordinates?","In some passages of Do Carmo's Riemannian geometry book he identify $T_v(T_pM)$ with $T_pM$, my question: How one see $T_pM$ as a manifold? who is the atlas? What is the expression of a vector $x \in T_v(T_pM)$ in local coordinates?",,['differential-geometry']
12,The Affine Property of Connections on Vector Bundles,The Affine Property of Connections on Vector Bundles,,"Given any two connections $\nabla_1, \nabla_2: \Omega^0 (V) \to \Omega^1 (V)$ on a vector bundle $V \to M$, their difference $\nabla_1 - \nabla_2$ is a $C^\infty (M)$-linear map $\Omega^0 (V) \to \Omega^1 (V)$. Question: I have difficulties swallowing the implication that $\nabla_1 - \nabla_2 \in \Omega^1 (\text{End } V)$. Of course, $\Omega^1 (\text{End } V) = \Gamma (T^\ast M \otimes \text{End } V)$, so this is saying that $\nabla_1 - \nabla_2$ is an endomorphism-valued 1-form. Also, given any section $s \in \Omega^0 (V)$, the difference $(\nabla_1 - \nabla_2) s$ at any point $m \in M$ is completely determined by the value $s(m)$, i.e. the operator $(\nabla_1 - \nabla_2) |_m$ is an endomorphism of the fiber $V|_m$, but I don't see how this is relevant, yet...","Given any two connections $\nabla_1, \nabla_2: \Omega^0 (V) \to \Omega^1 (V)$ on a vector bundle $V \to M$, their difference $\nabla_1 - \nabla_2$ is a $C^\infty (M)$-linear map $\Omega^0 (V) \to \Omega^1 (V)$. Question: I have difficulties swallowing the implication that $\nabla_1 - \nabla_2 \in \Omega^1 (\text{End } V)$. Of course, $\Omega^1 (\text{End } V) = \Gamma (T^\ast M \otimes \text{End } V)$, so this is saying that $\nabla_1 - \nabla_2$ is an endomorphism-valued 1-form. Also, given any section $s \in \Omega^0 (V)$, the difference $(\nabla_1 - \nabla_2) s$ at any point $m \in M$ is completely determined by the value $s(m)$, i.e. the operator $(\nabla_1 - \nabla_2) |_m$ is an endomorphism of the fiber $V|_m$, but I don't see how this is relevant, yet...",,"['differential-geometry', 'vector-bundles']"
13,Proving that a particular submanifold of the cotangent space is Lagrangian,Proving that a particular submanifold of the cotangent space is Lagrangian,,"I have the following problem in my differential topology class: Let $M$ be an $n$-dimensional manifold and let $\omega$ denote the standard symplectic form on the cotangent space $T^*M$. Let $f \in C^{\infty}(M)$ and put $L_f = \{(p,\mathrm{d}f_p) \in T^*M: p \in M\}$. Prove that $L_f$ is a Lagrangian submanifold of $T^*M$ and that $L_f$ is diffeomorphic to $M$. I can prove that $L_f$ is a submanifold of $T^*M$ without any difficulty and the proof that $L_f$ is diffeomorphic to $M$ is similarly easy. I am having difficulty with the computation that $L_f$ is Lagrangian however, so I was hoping that someone could at least get me started in the right direction here.","I have the following problem in my differential topology class: Let $M$ be an $n$-dimensional manifold and let $\omega$ denote the standard symplectic form on the cotangent space $T^*M$. Let $f \in C^{\infty}(M)$ and put $L_f = \{(p,\mathrm{d}f_p) \in T^*M: p \in M\}$. Prove that $L_f$ is a Lagrangian submanifold of $T^*M$ and that $L_f$ is diffeomorphic to $M$. I can prove that $L_f$ is a submanifold of $T^*M$ without any difficulty and the proof that $L_f$ is diffeomorphic to $M$ is similarly easy. I am having difficulty with the computation that $L_f$ is Lagrangian however, so I was hoping that someone could at least get me started in the right direction here.",,"['differential-geometry', 'differential-topology', 'differential-forms', 'symplectic-geometry']"
14,normal bundle of a boundary,normal bundle of a boundary,,"let $X$ and $Y$ be compact, oriented manifolds and assume that $\partial X=Y$. Is it true that the normal bundle of $Y$ in $X$ is trivial? if it is the case, is there a simply explaination? Thanks","let $X$ and $Y$ be compact, oriented manifolds and assume that $\partial X=Y$. Is it true that the normal bundle of $Y$ in $X$ is trivial? if it is the case, is there a simply explaination? Thanks",,"['differential-geometry', 'differential-topology']"
15,Symmetric $k$-tensor,Symmetric -tensor,k,"I've searched on Google but I could not find an example of a symmetric tensor. I've found this blog post but I cannot construct any example of a symmetric tensor. I know that a tensor $T$ is symmetric iff $T= \operatorname{Sym} T$. Could you give the simplest example, say on $\mathbb{R}^n$?","I've searched on Google but I could not find an example of a symmetric tensor. I've found this blog post but I cannot construct any example of a symmetric tensor. I know that a tensor $T$ is symmetric iff $T= \operatorname{Sym} T$. Could you give the simplest example, say on $\mathbb{R}^n$?",,['differential-geometry']
16,A theorem in Morse theory,A theorem in Morse theory,,"If $M$ is a smooth manifold on which there is a smooth function $f:M \to ( - 1,2)$  such that all $[0,1]$ are regular values of $f$ and ${f^{ - 1}}(s)$ is a compact set for all $s \in [0,1]$，then is ${f^{ - 1}}([0,1])$ a compact set in $M$? As we know, if we assume ${f^{ - 1}}([0,1])$ to be a compact set in $M$ as a condition, then according to a theorem in Morse theory, ${f^{ - 1}}(0)$ and ${f^{ - 1}}(1)$ are diffeomorphic. This proof consists of constructing a vector field and using the integral curves related to that field. The crucial part is that since ${f^{ - 1}}([0,1])$ is compact, we can always construct a vector with compact support, therefore the integral curves are complete. In this way the certain diffeomorphism can be defined without problem. Amazingly enough, with the same conditions in the first paragraph, ${f^{ - 1}}(0)$ and ${f^{ - 1}}(1)$ seem to be still diffeomorphic. However, the same method, that is (constructing vector field), cannot be applied to this situation easily since the domain of integral curves are determined by ${M_t} = {f^{ - 1}}(t){\kern 1pt} {\kern 1pt} (t \in [0,1])$, not necessarily uniform. The deficiency can be overcome by proving ${f^{ - 1}}([0,1])$ is a compact set, this is where I got stuck, or constructing the integral curves more intricately","If $M$ is a smooth manifold on which there is a smooth function $f:M \to ( - 1,2)$  such that all $[0,1]$ are regular values of $f$ and ${f^{ - 1}}(s)$ is a compact set for all $s \in [0,1]$，then is ${f^{ - 1}}([0,1])$ a compact set in $M$? As we know, if we assume ${f^{ - 1}}([0,1])$ to be a compact set in $M$ as a condition, then according to a theorem in Morse theory, ${f^{ - 1}}(0)$ and ${f^{ - 1}}(1)$ are diffeomorphic. This proof consists of constructing a vector field and using the integral curves related to that field. The crucial part is that since ${f^{ - 1}}([0,1])$ is compact, we can always construct a vector with compact support, therefore the integral curves are complete. In this way the certain diffeomorphism can be defined without problem. Amazingly enough, with the same conditions in the first paragraph, ${f^{ - 1}}(0)$ and ${f^{ - 1}}(1)$ seem to be still diffeomorphic. However, the same method, that is (constructing vector field), cannot be applied to this situation easily since the domain of integral curves are determined by ${M_t} = {f^{ - 1}}(t){\kern 1pt} {\kern 1pt} (t \in [0,1])$, not necessarily uniform. The deficiency can be overcome by proving ${f^{ - 1}}([0,1])$ is a compact set, this is where I got stuck, or constructing the integral curves more intricately",,"['differential-geometry', 'differential-topology']"
17,Intersection points in a one-parameter family of lines,Intersection points in a one-parameter family of lines,,"Given is a one-parameter family of lines, $$L(t) = \{ a(t) + \lambda w(t) : \quad \lambda \in \mathbb{R} \}$$ in which the base point $a$ and the direction vector $w$ vary smoothly with a parameter $t$ (you may assume that $|w| = 1$ and $w' \neq 0$). There is a unique line segment that joins two nearby lines $L(t)$ and $L(t + \Delta t)$ orthogonally. Let $C$ be the center of this line segment. My question: what is the position of $C$ in the limit, when $\Delta t \rightarrow 0$? EDIT : I realize I should have mentioned that the lines are in $\mathbb{R}^3$, and therefore $L(t)$ and $L(t + \Delta t)$ are supposed to be skew lines. Also, the solution $C$ is known to be located at $$ \bar{\lambda} = -\frac{a'(t) \cdot w'(t)}{w'(t) \cdot w'(t)}$$ for a given $t$. I just don't know how to prove this. EDIT 2 : Based on robjohn's answer below, I've got the following: Let $t_1$ and $t_2 = t_1 + \Delta t$ be two nearby values of the parameter $t$, corresponding to two lines $L_1$ and $L_2$. The perpendicular that joins $L_1$ and $L_2$ has the direction $w_1 \times w_2$, and the plane containing $L_2$ and the perpendicular therefore has the normal $$w_2 \times (w_1 \times w_2)$$ which means that, for any point $x$ in the plane, we get $$(x - a_2) \cdot (w_2 \times (w_1 \times w_2)) = 0$$ We need to find the point $a_1 + \bar{\lambda} w_1$ at which $L_1$ intersects this plane, therefore $$(a_1 + \bar{\lambda} w_1 - a_2) \cdot (w_2 \times (w_1 \times w_2)) = 0$$ or $$\bar{\lambda} = \frac{(a_2 - a_1) \cdot (w_2 \times (w_1 \times w_2))}{\Vert   w_1 \times w_2 \Vert^2}$$ This yields $\bar{\lambda}$ for any finite displacement $\Delta t = t_2 - t_1$. For $\Delta t \rightarrow 0$, the expression gets indeterminate (because $w_2 \rightarrow w_1$ implies $w_1 \times w_2 \rightarrow 0$)... I believe I am close, but I don't see how to obtain the correct limit from this.","Given is a one-parameter family of lines, $$L(t) = \{ a(t) + \lambda w(t) : \quad \lambda \in \mathbb{R} \}$$ in which the base point $a$ and the direction vector $w$ vary smoothly with a parameter $t$ (you may assume that $|w| = 1$ and $w' \neq 0$). There is a unique line segment that joins two nearby lines $L(t)$ and $L(t + \Delta t)$ orthogonally. Let $C$ be the center of this line segment. My question: what is the position of $C$ in the limit, when $\Delta t \rightarrow 0$? EDIT : I realize I should have mentioned that the lines are in $\mathbb{R}^3$, and therefore $L(t)$ and $L(t + \Delta t)$ are supposed to be skew lines. Also, the solution $C$ is known to be located at $$ \bar{\lambda} = -\frac{a'(t) \cdot w'(t)}{w'(t) \cdot w'(t)}$$ for a given $t$. I just don't know how to prove this. EDIT 2 : Based on robjohn's answer below, I've got the following: Let $t_1$ and $t_2 = t_1 + \Delta t$ be two nearby values of the parameter $t$, corresponding to two lines $L_1$ and $L_2$. The perpendicular that joins $L_1$ and $L_2$ has the direction $w_1 \times w_2$, and the plane containing $L_2$ and the perpendicular therefore has the normal $$w_2 \times (w_1 \times w_2)$$ which means that, for any point $x$ in the plane, we get $$(x - a_2) \cdot (w_2 \times (w_1 \times w_2)) = 0$$ We need to find the point $a_1 + \bar{\lambda} w_1$ at which $L_1$ intersects this plane, therefore $$(a_1 + \bar{\lambda} w_1 - a_2) \cdot (w_2 \times (w_1 \times w_2)) = 0$$ or $$\bar{\lambda} = \frac{(a_2 - a_1) \cdot (w_2 \times (w_1 \times w_2))}{\Vert   w_1 \times w_2 \Vert^2}$$ This yields $\bar{\lambda}$ for any finite displacement $\Delta t = t_2 - t_1$. For $\Delta t \rightarrow 0$, the expression gets indeterminate (because $w_2 \rightarrow w_1$ implies $w_1 \times w_2 \rightarrow 0$)... I believe I am close, but I don't see how to obtain the correct limit from this.",,['differential-geometry']
18,Is any foliation on a 2-torus induced by a suitable flow?,Is any foliation on a 2-torus induced by a suitable flow?,,"Consider the 2-dimensional torus $T^2=\mathbb{R}^2/\mathbb{Z}^2$, and a foliation on it (for example a foliation in circles, maybe the partition of the torus obtained form a Hopf -related map). I'm wondering if there are some condition on the foliation to be (the union of) the integral curves of a suitable vector field $X_\tau$ defined on the torus... Note: One can clearly ask something more general (generic group action on a smooth manifold whose orbits are leaves of a given foliation), but I'm really dumb on making good (=well defined) questions so for the moment let's talk about a particular case. Note 2: I'm not requiring much smoothness for $X_\tau$ just because I suspect that the answer will be ""No if you suppose $X_\tau$ is not $C^k$-smooth with $k\ge k_0$"". Thanks a lot!","Consider the 2-dimensional torus $T^2=\mathbb{R}^2/\mathbb{Z}^2$, and a foliation on it (for example a foliation in circles, maybe the partition of the torus obtained form a Hopf -related map). I'm wondering if there are some condition on the foliation to be (the union of) the integral curves of a suitable vector field $X_\tau$ defined on the torus... Note: One can clearly ask something more general (generic group action on a smooth manifold whose orbits are leaves of a given foliation), but I'm really dumb on making good (=well defined) questions so for the moment let's talk about a particular case. Note 2: I'm not requiring much smoothness for $X_\tau$ just because I suspect that the answer will be ""No if you suppose $X_\tau$ is not $C^k$-smooth with $k\ge k_0$"". Thanks a lot!",,['differential-geometry']
19,rescaled metric quantities on rescaling metrics,rescaled metric quantities on rescaling metrics,,"I have the following basic, surely stupid, questions. Assume we have a Riemannian metric $g$ on a manifold $M$. let $a\in\mathbb{R}$ a constant and consider the metric $g_1=ag$. Which are the transformation rules for the scalar and sectional curvature and for the Ricci tensor? For the sectional I guess are the same $K_g(\pi)=K_{g_1}(\pi)$, but what about sectional and Ricci tensor. Moreover how does change the metric on tensors: is it true that $g_1(v,w)=a^{l-m}g(v,w)$ if $v,w$ are $(l,m)$-tensors? Thank you","I have the following basic, surely stupid, questions. Assume we have a Riemannian metric $g$ on a manifold $M$. let $a\in\mathbb{R}$ a constant and consider the metric $g_1=ag$. Which are the transformation rules for the scalar and sectional curvature and for the Ricci tensor? For the sectional I guess are the same $K_g(\pi)=K_{g_1}(\pi)$, but what about sectional and Ricci tensor. Moreover how does change the metric on tensors: is it true that $g_1(v,w)=a^{l-m}g(v,w)$ if $v,w$ are $(l,m)$-tensors? Thank you",,"['differential-geometry', 'riemannian-geometry']"
20,"As a derivation, a tangent vector is independent of the chart.","As a derivation, a tangent vector is independent of the chart.",,"Lee's Smooth Manifolds primarily defines tangent vectors as derivations. That is, functions $v: C^\infty(M) \to \mathbb{R}$ that satisfy the Leibniz rule. By appealing to a chart $(U, \phi)$ , we can write down a derivation $v$ concretely as a linear combination of basis vectors given by $d\phi^{-1}_{\phi(p)} \frac{\partial}{\partial x_i}$ . When we use a different chart, we of course have a different representation. In order to compute how the derivation acts on a function $f \in C^\infty(M)$ , I believe we have the following procedure: Write down $f \circ \phi^{-1}$ , the coordinate representation of $f$ . Compute $v(f) = v(f \circ \phi^{-1} \circ \phi) = d\phi_p (v)(f \circ \phi^{-1})$ . The RHS is simply applying partial derivatives in the ordinary sense, and we are done. Ah! I seem to have resolved my question in the course of writing it. I wanted to ask why it was obvious that, if you write down $v$ with respect to different bases, that computing $v(f)$ gets you the same result (i.e. is well defined), but that is just bullet point 2. (right?) Apologies for frivolous questions! Everything is largely still an indistinct mess of words and symbols for me, so I just want to make sure I understand things in plodding detail. I find a lot of the time that while I can both mechanically compute and regurgitate definitions accurately, I have little understanding of what I am doing all the same.","Lee's Smooth Manifolds primarily defines tangent vectors as derivations. That is, functions that satisfy the Leibniz rule. By appealing to a chart , we can write down a derivation concretely as a linear combination of basis vectors given by . When we use a different chart, we of course have a different representation. In order to compute how the derivation acts on a function , I believe we have the following procedure: Write down , the coordinate representation of . Compute . The RHS is simply applying partial derivatives in the ordinary sense, and we are done. Ah! I seem to have resolved my question in the course of writing it. I wanted to ask why it was obvious that, if you write down with respect to different bases, that computing gets you the same result (i.e. is well defined), but that is just bullet point 2. (right?) Apologies for frivolous questions! Everything is largely still an indistinct mess of words and symbols for me, so I just want to make sure I understand things in plodding detail. I find a lot of the time that while I can both mechanically compute and regurgitate definitions accurately, I have little understanding of what I am doing all the same.","v: C^\infty(M) \to \mathbb{R} (U, \phi) v d\phi^{-1}_{\phi(p)} \frac{\partial}{\partial x_i} f \in C^\infty(M) f \circ \phi^{-1} f v(f) = v(f \circ \phi^{-1} \circ \phi) = d\phi_p (v)(f \circ \phi^{-1}) v v(f)",['differential-geometry']
21,"$Ham(M, \omega)$ acts transitively on $(M,\omega)$",acts transitively on,"Ham(M, \omega) (M,\omega)","Let $M$ be a  compact and connected smooth manifold with a symplectic form $\omega$ . $Ham(M, \omega)$ denotes the space of hamiltonian symplectomorphisms of $(M,\omega)$ . I have the following statement in my lecture notes: Using Darboux’s theorem one can show that the action of $Ham(M, \omega)$ on M is transitive, that is: for any pair of points $p, q \in M$ , there exists $\Phi \in Ham(M, \omega)$ such that $\Phi(p) = q$ . The idea  is that Darboux's theorem to go from local to global, i.e. to show that points that are close to each other in the symplectic manifold can be mapped to each other via a Hamiltonian diffeomorphism. ...which I unsuccesfully tried to prove. How is it done? I know that a symplectomorphism of $(M, \omega)$ is a diffeomorphism $\Phi : M \to M$ such that $\Phi ^∗\omega = \omega$ . $\Phi$ is Hamiltonian if there exists a Hamiltonian isotopy $\phi_t$ such that $\Phi=\phi_1$ . And that $ Ham(M, \omega)$ is a normal subgroup of $Symp(M, \omega)$ (the space of symplectomorphisms ), if that is useful. I am not sure what ""points close to each other"" means here and how to use to arrive to the thesis Following the suggestion: Let p, q be in M then By Darboux theorem there are open charts $(U_p,\phi)$ and $(Uq,\psi)$ with $\phi$ and $\psi$ symplectomorphisms from $\Bbb R^{2n}$ But what do I do with this?","Let be a  compact and connected smooth manifold with a symplectic form . denotes the space of hamiltonian symplectomorphisms of . I have the following statement in my lecture notes: Using Darboux’s theorem one can show that the action of on M is transitive, that is: for any pair of points , there exists such that . The idea  is that Darboux's theorem to go from local to global, i.e. to show that points that are close to each other in the symplectic manifold can be mapped to each other via a Hamiltonian diffeomorphism. ...which I unsuccesfully tried to prove. How is it done? I know that a symplectomorphism of is a diffeomorphism such that . is Hamiltonian if there exists a Hamiltonian isotopy such that . And that is a normal subgroup of (the space of symplectomorphisms ), if that is useful. I am not sure what ""points close to each other"" means here and how to use to arrive to the thesis Following the suggestion: Let p, q be in M then By Darboux theorem there are open charts and with and symplectomorphisms from But what do I do with this?","M \omega Ham(M, \omega) (M,\omega) Ham(M, \omega) p, q \in M \Phi \in Ham(M, \omega) \Phi(p) = q (M, \omega) \Phi : M \to M \Phi ^∗\omega = \omega \Phi \phi_t \Phi=\phi_1  Ham(M, \omega) Symp(M, \omega) (U_p,\phi) (Uq,\psi) \phi \psi \Bbb R^{2n}","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'symplectic-geometry']"
22,Understand the definition of covariant derivative for parameterized set,Understand the definition of covariant derivative for parameterized set,,"A geometric set $S \subset R^n$ is a set having the property that for each point $p \in S$ , there is a vector subspace $T_pS \subset T_p\mathbb R^n$ . Moreover, these subspaces should vary smoothly with $p$ and should all have the same dimension. Let $U\subset\mathbb R^k$ be a domain and let $\phi:U\rightarrow\mathbb R^n(k\leq n)$ be a smooth, one-to-one function that is regular for all $p\in U$ . A parameterized set $S=\phi(U)$ is defined to be the image of $U$ in $\mathbb R^n$ by $\phi$ . The geometric features of the parameterized set $S$ come from “encoding” features of the parameter space $U$ through the function $\phi$ . Then the author ( First Steps in Differential Geometry Riemannian, Contact, Symplectic by Andrew McInerney ) built intuition like Riemannian metrics, Riemannian Connection and curvature on the geometric set or more specifically the parameterized set. Proposition 5.1.9. Let $(U, g)$ be a Riemannian space, $\mathcal{X}(U)$ the set of smooth vector fields on $U$ , and $\Lambda_1(U)$ the set of smooth one-forms on $U$ . Then the map $\gamma: \mathcal{X}(U) \rightarrow \Lambda_1(U)$ given by $\gamma(X)=i(X)$ g for $X \in \mathcal{X}(U)$ , i.e., $\gamma(X)$ is the differential one-form such that for any vector field $Y$ on $U$ , $$ (\gamma(X))(Y)=g(X, Y), $$ induces a vector space isomorphism $\gamma_p: T_p U \rightarrow T_p^* U$ for all $p \in U$ . Definition 5.3.2. Suppose $X$ and $Y$ are smooth vector fields on a Riemannian space $(U, g)$ . Let $\theta_Y=\gamma(Y)$ be the one-form corresponding to the vector field $Y$ under the isomorphism $\gamma$ induced by $g$ defined in Proposition 5.1.9. Construct a new oneform $\theta_{Y, X}$ as follows: $$ \theta_{Y, X}=\frac{1}{2} i(X)\left[\mathcal{L}_Y g+d \theta_Y\right] . $$ The covariant derivative of $Y$ with respect to $X$ (relative to the metric tensor $g$ ), denoted by $\nabla_X Y$ , is the vector field $$ \nabla_X Y=\gamma^{-1}\left(\theta_{Y, X}\right) . $$ The assignment $\nabla:(X, Y) \mapsto \nabla_X Y$ is also known as the Riemannian connection corresponding to $g$ . I didn't understand the motivation behind this definition of the covariant derivative, $\nabla_X Y$ , as others have explained it as the horizontal (or tangential) component of the directional derivative, $D_X Y$ , or as the change of $Y$ in the direction of $X$ using any curve $\gamma$ which goes in the direction of $X$ and uses parallel transport to transport $Y(\gamma(t))$ back to $T_pM$ in order to compare it with $Y(p)$ . However, I couldn't connect Definition 5.3.2. with any of those. It would be greatly appreciated if anyone could shed some light on it. Another question I have is: I didn't come across any examples for computing connections of vector bundles or covariant derivatives on abstract manifolds. Is there a resource where I can find examples or problems to work on? Without seeing these examples, I find it difficult to grasp the complete picture, and I'm starting to forget whatever I've read so far. Thank you in advance.","A geometric set is a set having the property that for each point , there is a vector subspace . Moreover, these subspaces should vary smoothly with and should all have the same dimension. Let be a domain and let be a smooth, one-to-one function that is regular for all . A parameterized set is defined to be the image of in by . The geometric features of the parameterized set come from “encoding” features of the parameter space through the function . Then the author ( First Steps in Differential Geometry Riemannian, Contact, Symplectic by Andrew McInerney ) built intuition like Riemannian metrics, Riemannian Connection and curvature on the geometric set or more specifically the parameterized set. Proposition 5.1.9. Let be a Riemannian space, the set of smooth vector fields on , and the set of smooth one-forms on . Then the map given by g for , i.e., is the differential one-form such that for any vector field on , induces a vector space isomorphism for all . Definition 5.3.2. Suppose and are smooth vector fields on a Riemannian space . Let be the one-form corresponding to the vector field under the isomorphism induced by defined in Proposition 5.1.9. Construct a new oneform as follows: The covariant derivative of with respect to (relative to the metric tensor ), denoted by , is the vector field The assignment is also known as the Riemannian connection corresponding to . I didn't understand the motivation behind this definition of the covariant derivative, , as others have explained it as the horizontal (or tangential) component of the directional derivative, , or as the change of in the direction of using any curve which goes in the direction of and uses parallel transport to transport back to in order to compare it with . However, I couldn't connect Definition 5.3.2. with any of those. It would be greatly appreciated if anyone could shed some light on it. Another question I have is: I didn't come across any examples for computing connections of vector bundles or covariant derivatives on abstract manifolds. Is there a resource where I can find examples or problems to work on? Without seeing these examples, I find it difficult to grasp the complete picture, and I'm starting to forget whatever I've read so far. Thank you in advance.","S \subset R^n p \in S T_pS \subset T_p\mathbb R^n p U\subset\mathbb R^k \phi:U\rightarrow\mathbb R^n(k\leq n) p\in U S=\phi(U) U \mathbb R^n \phi S U \phi (U, g) \mathcal{X}(U) U \Lambda_1(U) U \gamma: \mathcal{X}(U) \rightarrow \Lambda_1(U) \gamma(X)=i(X) X \in \mathcal{X}(U) \gamma(X) Y U 
(\gamma(X))(Y)=g(X, Y),
 \gamma_p: T_p U \rightarrow T_p^* U p \in U X Y (U, g) \theta_Y=\gamma(Y) Y \gamma g \theta_{Y, X} 
\theta_{Y, X}=\frac{1}{2} i(X)\left[\mathcal{L}_Y g+d \theta_Y\right] .
 Y X g \nabla_X Y 
\nabla_X Y=\gamma^{-1}\left(\theta_{Y, X}\right) .
 \nabla:(X, Y) \mapsto \nabla_X Y g \nabla_X Y D_X Y Y X \gamma X Y(\gamma(t)) T_pM Y(p)","['differential-geometry', 'connections']"
23,Exterior derivative of 1,Exterior derivative of 1,,"In one of the examples of Loring W. Tu's Book ""Introduction to Manifolds"" (section 19.7 of 2nd ed.) the author takes the exterior derivative on both sides of the equation $x^2 + y^2 = 1$ wich results in $2x\,dx + 2y\,dy = 0$ . The left-hand side makes sense to me and, intuitively, the right-hand side too. But I don't understand what the exterior derivative of 1 is supposed to mean, since the exterior derivative acts on differential forms, then 1 what kind of differential form is supposed to be? What is its degree? And why should its exterior derivation be 0? Thank you.","In one of the examples of Loring W. Tu's Book ""Introduction to Manifolds"" (section 19.7 of 2nd ed.) the author takes the exterior derivative on both sides of the equation wich results in . The left-hand side makes sense to me and, intuitively, the right-hand side too. But I don't understand what the exterior derivative of 1 is supposed to mean, since the exterior derivative acts on differential forms, then 1 what kind of differential form is supposed to be? What is its degree? And why should its exterior derivation be 0? Thank you.","x^2 + y^2 = 1 2x\,dx + 2y\,dy = 0","['differential-geometry', 'manifolds', 'differential-forms', 'exterior-derivative']"
24,"Divergence, interior products and Lie derivative coincide?","Divergence, interior products and Lie derivative coincide?",,"The divergence on a Riemannian manifold is defined as $$\operatorname{div}X=\operatorname{tr}(Y\mapsto \nabla_YX)$$ for $X,Y\in \mathfrak{X}(M)$ . I found online that this can be apparently defined also as $$d(\iota_XdV_g)= (\operatorname{div}X)dV_g.$$ Here $dV_g$ is the volume form with the metric $g$ . I have a hard time understanding why these two definitions are equivalent. It is also furthermore said that $\mathcal{L}_X(dV_g)=(\operatorname{div}X)dV_g$ which only adds to my confusion. Could anyone elaborate on why these are all equivalent definitions?",The divergence on a Riemannian manifold is defined as for . I found online that this can be apparently defined also as Here is the volume form with the metric . I have a hard time understanding why these two definitions are equivalent. It is also furthermore said that which only adds to my confusion. Could anyone elaborate on why these are all equivalent definitions?,"\operatorname{div}X=\operatorname{tr}(Y\mapsto \nabla_YX) X,Y\in \mathfrak{X}(M) d(\iota_XdV_g)= (\operatorname{div}X)dV_g. dV_g g \mathcal{L}_X(dV_g)=(\operatorname{div}X)dV_g","['differential-geometry', 'riemannian-geometry']"
25,Complex vector bundle valued forms,Complex vector bundle valued forms,,"Let $X$ be a smooth manifold and $E \to X$ a complex vector bundle. A connection on $E$ is a $\mathbb{C}$ -linear map $\nabla \colon \Gamma(X,E) \to \Omega^1(X,E)$ where $\Gamma(X,E)$ denotes the space of sections of $E$ and $\Omega^1(X,E)$ is the space of  the space of sections of $T^{\vee} X \otimes_{\mathbb{R}} E$ , where $T^{\vee} X = \mathrm{Hom}_\mathbb{R}(TX,\mathbb{R})$ . Now if $X$ comes with an almost complex structure $J$ , then one usually considers the complexified spaces. In particular $T^{\vee}_{\mathbb{C}} X = T^{\vee} X \otimes_{\mathbb{R}} \mathbb{C} = \mathrm{Hom}_\mathbb{R}(TX,\mathbb{C})$ . This space comes with a splitting induced by the $\pm \mathrm{i}$ -subspaces of $J$ , i.e. $T^{\vee}_{\mathbb{C}} X = T^{1,0}X^{\vee} \oplus T^{1,0}X^{\vee}$ . This induces a splitting $\Omega_{\mathbb{C}}^1(X,E) = \Omega^{1,0}(X,E)\oplus \Omega^{0,1}(X,E)$ . In many textbooks it is then written that $\nabla = \nabla^{1,0} + \nabla^{0,1}$ . But $\nabla$ was defined as a map into $\Omega^1(X,E)$ . Is this the same space as $\Omega^1_{\mathbb{C}}(X,E)$ ? Because I believe that this is the space of sections of $T^{\vee}_{\mathbb{C}}X \otimes_{\mathbb{C}} E$ , where the tensor product over $\mathbb{C}$ is used. So $$ T^{\vee}_{\mathbb{C}}X \otimes_{\mathbb{C}} E = T^{\vee}X \otimes_{\mathbb{R}} \mathbb{C} \otimes_{\mathbb{C}} E = T^{\vee}X \otimes_{\mathbb{R}} E $$ and hence, $\Omega^1_{\mathbb{C}}(X,E) =\Omega^1(X,E)$ . Or am I missing something? In many textbooks this construction is unfortunately not written clearly.","Let be a smooth manifold and a complex vector bundle. A connection on is a -linear map where denotes the space of sections of and is the space of  the space of sections of , where . Now if comes with an almost complex structure , then one usually considers the complexified spaces. In particular . This space comes with a splitting induced by the -subspaces of , i.e. . This induces a splitting . In many textbooks it is then written that . But was defined as a map into . Is this the same space as ? Because I believe that this is the space of sections of , where the tensor product over is used. So and hence, . Or am I missing something? In many textbooks this construction is unfortunately not written clearly.","X E \to X E \mathbb{C} \nabla \colon \Gamma(X,E) \to \Omega^1(X,E) \Gamma(X,E) E \Omega^1(X,E) T^{\vee} X \otimes_{\mathbb{R}} E T^{\vee} X = \mathrm{Hom}_\mathbb{R}(TX,\mathbb{R}) X J T^{\vee}_{\mathbb{C}} X = T^{\vee} X \otimes_{\mathbb{R}} \mathbb{C} = \mathrm{Hom}_\mathbb{R}(TX,\mathbb{C}) \pm \mathrm{i} J T^{\vee}_{\mathbb{C}} X = T^{1,0}X^{\vee} \oplus T^{1,0}X^{\vee} \Omega_{\mathbb{C}}^1(X,E) = \Omega^{1,0}(X,E)\oplus \Omega^{0,1}(X,E) \nabla = \nabla^{1,0} + \nabla^{0,1} \nabla \Omega^1(X,E) \Omega^1_{\mathbb{C}}(X,E) T^{\vee}_{\mathbb{C}}X \otimes_{\mathbb{C}} E \mathbb{C}  T^{\vee}_{\mathbb{C}}X \otimes_{\mathbb{C}} E = T^{\vee}X \otimes_{\mathbb{R}} \mathbb{C} \otimes_{\mathbb{C}} E = T^{\vee}X \otimes_{\mathbb{R}} E  \Omega^1_{\mathbb{C}}(X,E) =\Omega^1(X,E)","['differential-geometry', 'complex-geometry', 'differential-forms', 'vector-bundles']"
26,Does the distance induced from a Riemannian metric on a manifold determine the Riemannian structure?,Does the distance induced from a Riemannian metric on a manifold determine the Riemannian structure?,,"Let $(M, g), (N,h)$ be Riemannian manifolds and consider $d_g$ and $d_h$ the corresponding distance functions induced from $g$ and $h$ . Suppose $f: M \rightarrow N$ is a bijective isometry in the metric sense i.e. $d_h(f(x), f(y)) = d_g(x,y)$ . Is it true that $f$ must be smooth and, moreover, that $f^* h = g$ ? In more generality, if $M$ and $N$ are only smooth manifolds and $d_M, d_N$ are smooth distance functions, is it true that a bijective isometry $f: M \rightarrow N$ must be smooth?","Let be Riemannian manifolds and consider and the corresponding distance functions induced from and . Suppose is a bijective isometry in the metric sense i.e. . Is it true that must be smooth and, moreover, that ? In more generality, if and are only smooth manifolds and are smooth distance functions, is it true that a bijective isometry must be smooth?","(M, g), (N,h) d_g d_h g h f: M \rightarrow N d_h(f(x), f(y)) = d_g(x,y) f f^* h = g M N d_M, d_N f: M \rightarrow N","['differential-geometry', 'metric-spaces', 'manifolds', 'riemannian-geometry', 'smooth-manifolds']"
27,Integration of surface from compatible first and second fundamental forms,Integration of surface from compatible first and second fundamental forms,,"Let $\Omega\subset\mathbf{R}^2$ be some simply connected domain. Given the functions $(E,F,G)$ and $(L,M,N)$ that satisfy the Gauss–Codazzi–Mainardi equations, we have, according to Bonnet theorem, a unique surface up to rotations and translations in $\mathbf{R}^3$ . After an extensive search I have not found a single example where the integration of a surface, that is the obtaining the function $\mathbf{r}(x,y)\in\mathbf{R}^3$ from the fundamental form coefficients, is done $\textit{from scratch}$ . There are examples where one a priori wants a surface of revolution and assumes a certain special form of $\mathbf{r}(x,y)$ and then proceeds, but in general one has no clue about how the surface will look like. So How to integrate $\mathbf{r}(x,y)$ from the (GMC satisfying) fundamental forms coefficients $(L,M,N)$ and $(E,F,G)$ , without assuming any special form of $\mathbf{r}(x,y)$ ? Are there analytical, non-trivial examples (beyond surfaces of revolution or any other symmetric shapes).","Let be some simply connected domain. Given the functions and that satisfy the Gauss–Codazzi–Mainardi equations, we have, according to Bonnet theorem, a unique surface up to rotations and translations in . After an extensive search I have not found a single example where the integration of a surface, that is the obtaining the function from the fundamental form coefficients, is done . There are examples where one a priori wants a surface of revolution and assumes a certain special form of and then proceeds, but in general one has no clue about how the surface will look like. So How to integrate from the (GMC satisfying) fundamental forms coefficients and , without assuming any special form of ? Are there analytical, non-trivial examples (beyond surfaces of revolution or any other symmetric shapes).","\Omega\subset\mathbf{R}^2 (E,F,G) (L,M,N) \mathbf{R}^3 \mathbf{r}(x,y)\in\mathbf{R}^3 \textit{from scratch} \mathbf{r}(x,y) \mathbf{r}(x,y) (L,M,N) (E,F,G) \mathbf{r}(x,y)","['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'surfaces']"
28,A (maybe) trivial question on trivial vector bundles: alternative definition of trivial vector bundle,A (maybe) trivial question on trivial vector bundles: alternative definition of trivial vector bundle,,"I am studying Loring W. Tu's Differential geometry, Connections, Curvature and Characteristic Classes and I am having a doubt (the same doubt I had when studying the same topic in the author's An Introduction to Manifolds ). The following definition of a vector budle is given Definition 7.1. A $C^{\infty}$ surjection $\pi : E \to M$ is a $C^{\infty}$ vector bundle of rank $r$ if For every $p \in M$ , the set $E_p:=\pi^{−1}(p)$ is a real vector space of dimension $r$ ; every point $p \in M$ has an open neighborhood $U$ such that there is a fiber-preserving diffeomorphism $\phi_U:\pi^{−1}(U) \to U\times \mathbb{R}^r$ that restricts to a linear isomorphism $E_p \to {p}\times \mathbb{R}^r$ on each fiber. The following definition for bundle map is then given: Definition 7.5. Let $\pi_{E}: E \to M$ and $π_F: F \to N$ be $C^{\infty}$ vector bundles. A $C^{\infty}$ bundle map from $E$ to $F$ is a pair of $C^{\infty}$ maps $(\phi: E \to F,  \underline{\phi}: M \to N)$ such that the diagram $$ \newcommand{\ra}[1]{\!\!\!\!\!\xrightarrow{\quad#1\quad}\!\!\!\!\!} \newcommand{\da}[1]{\left\downarrow{\scriptstyle#1}\vphantom{\displaystyle\int_0^1}\right.} % \begin{array}{lllllll} E & \ra{\phi} & F \\ \da{\pi_E} & & \da{\pi_F} \\ M & \ra{\underline{\phi}} & N  \\ \end{array} $$ commutes. ${\phi}$ restricts to a linear map $\phi_p: E_{p} \to F_{\underline{\phi(p)}}$ of fibers for each $p \in M$ . A bundle map over $M$ is when $\underline{\phi}$ is the identity map. The author then says that If there is a bundle map $\psi: F \to E$ over $M$ such that $\psi \circ \phi = \mathbb{1}_E$ and $\phi \circ \psi= \mathbb{1}_F$ , then $\phi$ is called a bundle isomorphism over $M$ , and the vector bundles $E$ and $F$ are said to be isomorphic over $M$ . Finally, here is the definition of trivial bundle: Definition 7.6. A vector bundle $\phi: E \to M$ is said to be trivial if it is isomorphic to a product bundle $M \times \mathbb{R}^r \to M$ over $M$ . Here are my questions: Can we say, equivalently, that a trivial bundle is a bundle in the sense of Definition 7.1 where there exists a open $U = M$ , i.e. when there is a fiber-preserving diffeomorphism with the same properties $\phi_M: \pi^{-1}(M) \to M \times \mathbb{R}^r$ ? To me $\psi \circ \phi = \mathbb{1}_E$ and $\phi \circ \psi= \mathbb{1}_F$ is equivalent to say that $\phi$ is a diffeomorphism, i.e. a bijective $C^{\infty}$ map with $C^{\infty}$ inverse. Can we say that that any manifold with a single chart has trivial tangent bundle? Apologies in advance if my question is obvious or if, on the contrary, I am missing some macroscopic obstruction to my idea. I was wondering why the definition of trivial bundle has been given after the one of bundle isomorphism, while right after definition 7.1 the author defines trivializing open subset ( $U$ ), trivialization ( $\phi_U$ is a trivialization for $\phi^{-1}(U)$ ) and trivializing open cover. thanks","I am studying Loring W. Tu's Differential geometry, Connections, Curvature and Characteristic Classes and I am having a doubt (the same doubt I had when studying the same topic in the author's An Introduction to Manifolds ). The following definition of a vector budle is given Definition 7.1. A surjection is a vector bundle of rank if For every , the set is a real vector space of dimension ; every point has an open neighborhood such that there is a fiber-preserving diffeomorphism that restricts to a linear isomorphism on each fiber. The following definition for bundle map is then given: Definition 7.5. Let and be vector bundles. A bundle map from to is a pair of maps such that the diagram commutes. restricts to a linear map of fibers for each . A bundle map over is when is the identity map. The author then says that If there is a bundle map over such that and , then is called a bundle isomorphism over , and the vector bundles and are said to be isomorphic over . Finally, here is the definition of trivial bundle: Definition 7.6. A vector bundle is said to be trivial if it is isomorphic to a product bundle over . Here are my questions: Can we say, equivalently, that a trivial bundle is a bundle in the sense of Definition 7.1 where there exists a open , i.e. when there is a fiber-preserving diffeomorphism with the same properties ? To me and is equivalent to say that is a diffeomorphism, i.e. a bijective map with inverse. Can we say that that any manifold with a single chart has trivial tangent bundle? Apologies in advance if my question is obvious or if, on the contrary, I am missing some macroscopic obstruction to my idea. I was wondering why the definition of trivial bundle has been given after the one of bundle isomorphism, while right after definition 7.1 the author defines trivializing open subset ( ), trivialization ( is a trivialization for ) and trivializing open cover. thanks","C^{\infty} \pi : E \to M C^{\infty} r p \in M E_p:=\pi^{−1}(p) r p \in M U \phi_U:\pi^{−1}(U) \to U\times \mathbb{R}^r E_p \to {p}\times \mathbb{R}^r \pi_{E}: E \to M π_F: F \to N C^{\infty} C^{\infty} E F C^{\infty} (\phi: E \to F,  \underline{\phi}: M \to N) 
\newcommand{\ra}[1]{\!\!\!\!\!\xrightarrow{\quad#1\quad}\!\!\!\!\!}
\newcommand{\da}[1]{\left\downarrow{\scriptstyle#1}\vphantom{\displaystyle\int_0^1}\right.}
%
\begin{array}{lllllll}
E & \ra{\phi} & F \\
\da{\pi_E} & & \da{\pi_F} \\
M & \ra{\underline{\phi}} & N  \\
\end{array}
 {\phi} \phi_p: E_{p} \to F_{\underline{\phi(p)}} p \in M M \underline{\phi} \psi: F \to E M \psi \circ \phi = \mathbb{1}_E \phi \circ \psi= \mathbb{1}_F \phi M E F M \phi: E \to M M \times \mathbb{R}^r \to M M U = M \phi_M: \pi^{-1}(M) \to M \times \mathbb{R}^r \psi \circ \phi = \mathbb{1}_E \phi \circ \psi= \mathbb{1}_F \phi C^{\infty} C^{\infty} U \phi_U \phi^{-1}(U)","['differential-geometry', 'differential-topology', 'vector-bundles', 'tangent-bundle']"
29,Vanishing first Chern class implies existence of flat connection,Vanishing first Chern class implies existence of flat connection,,"Edit : In the exercise I tried to solve it wasn't stated explicitly that we were dealing with line bundles (though the usage of the symbol $L$ for the vector bundle was a strong suggestion that this was the case), hence why my ponderings in the question post are about vector bundles of arbitrary rank. Let $M$ be a smooth manifold, $E$ a complex rank $r$ vector bundle on $M$ . My definition of the first Chern class $c_1(E)$ of $E$ is $$ c_1(E)=\left[\text{tr}\left(\frac{i}{2\pi}F^\nabla\right)\right] \in H_{\text{dR}}^2(M) $$ where $F^\nabla$ is the curvature tensor corresponding to any connection $\nabla$ on $E$ . If $E$ admits a flat connection $\nabla$ , then $F^\nabla=0$ , and hence $c_1(E)=0$ . I want to prove that the converse is true too: if $c_1(E)=0$ , then $E$ admits a flat connection. I know the identity $c_1(E)=c_1(\Lambda^r E)$ . Since $\Lambda^r E$ is a line bundle, $c_1(\Lambda^r E)$ is simply the cohomology class of the curvature $F^{\nabla^{\Lambda^r E}}$ , where $\nabla^E$ is some connection on $E$ and $\nabla^{\Lambda^r E}$ is the induced connection on $\Lambda^r E$ . So $c_1(\Lambda^r E)=0$ means that $F^{\nabla^{\Lambda^r E}}$ is an exact $2$ -form. Maybe I should first show the case that if a complex line bundle $L$ has vanishing first Chern class, then $L$ admits a flat connection, and maybe I can then show that a flat connection on $\Lambda^r E$ is induced by a flat connection on $E$ ? Any hints are welcome. Context: all I know about characteristic classes is what's treated in chapter 5 of Tu's Differential Geometry book, which I've learned is not the modern way of doing things. And see below the exercise that I'm trying to solve.","Edit : In the exercise I tried to solve it wasn't stated explicitly that we were dealing with line bundles (though the usage of the symbol for the vector bundle was a strong suggestion that this was the case), hence why my ponderings in the question post are about vector bundles of arbitrary rank. Let be a smooth manifold, a complex rank vector bundle on . My definition of the first Chern class of is where is the curvature tensor corresponding to any connection on . If admits a flat connection , then , and hence . I want to prove that the converse is true too: if , then admits a flat connection. I know the identity . Since is a line bundle, is simply the cohomology class of the curvature , where is some connection on and is the induced connection on . So means that is an exact -form. Maybe I should first show the case that if a complex line bundle has vanishing first Chern class, then admits a flat connection, and maybe I can then show that a flat connection on is induced by a flat connection on ? Any hints are welcome. Context: all I know about characteristic classes is what's treated in chapter 5 of Tu's Differential Geometry book, which I've learned is not the modern way of doing things. And see below the exercise that I'm trying to solve.","L M E r M c_1(E) E 
c_1(E)=\left[\text{tr}\left(\frac{i}{2\pi}F^\nabla\right)\right] \in H_{\text{dR}}^2(M)
 F^\nabla \nabla E E \nabla F^\nabla=0 c_1(E)=0 c_1(E)=0 E c_1(E)=c_1(\Lambda^r E) \Lambda^r E c_1(\Lambda^r E) F^{\nabla^{\Lambda^r E}} \nabla^E E \nabla^{\Lambda^r E} \Lambda^r E c_1(\Lambda^r E)=0 F^{\nabla^{\Lambda^r E}} 2 L L \Lambda^r E E","['differential-geometry', 'characteristic-classes']"
30,Why does $|(d\exp_{p})_{v}(w)|$ encodes the rate of spreading of geodesics?,Why does  encodes the rate of spreading of geodesics?,|(d\exp_{p})_{v}(w)|,"I'm reading a discussion in Do Carmo's ""Riemannian Geometry"", about Jacobi's equation. The writer uses the following notation: $$v(s):I\to T_{p}M\ \ \ s.t. \\ v(0)=v,\\ v'(0)=w $$ We identify $T_pM\simeq T_vT_p M $ . The writer motivates the discussion by the following claim: We would like to obtain information on $|(d\exp_{p})_{v}(w)|$ . One of the reasons for this is that $|(d\exp_{p})_{v}(w)|$ denotes, intuitively, the rate of spreading of the geodesics: $$ t \to \exp_{p}(t v(s))  $$ I don't understand the heuristic above. To be concrete, I'd like to know: The spread of which geodesics is encoded in $|(d\exp_{p})_{v}(w)|$ ? Is it some property that relates the following family of geodesics: $$\{t \to \exp_{p}(t v(s)) \}_{s\in I}$$ I'd be glad to hear a bit more about that - Why exactly does the differential encodes spread of geodesics? What is the geometric interpretation of all that? Could anyone point me to some draw of figure explaining this heuristic graphically? It all sort of make sense, but I think some more details could be of tremendous help. Many Thanks!","I'm reading a discussion in Do Carmo's ""Riemannian Geometry"", about Jacobi's equation. The writer uses the following notation: We identify . The writer motivates the discussion by the following claim: We would like to obtain information on . One of the reasons for this is that denotes, intuitively, the rate of spreading of the geodesics: I don't understand the heuristic above. To be concrete, I'd like to know: The spread of which geodesics is encoded in ? Is it some property that relates the following family of geodesics: I'd be glad to hear a bit more about that - Why exactly does the differential encodes spread of geodesics? What is the geometric interpretation of all that? Could anyone point me to some draw of figure explaining this heuristic graphically? It all sort of make sense, but I think some more details could be of tremendous help. Many Thanks!","v(s):I\to T_{p}M\ \ \ s.t. \\
v(0)=v,\\
v'(0)=w
 T_pM\simeq T_vT_p M  |(d\exp_{p})_{v}(w)| |(d\exp_{p})_{v}(w)|  t \to \exp_{p}(t v(s)) 
 |(d\exp_{p})_{v}(w)| \{t \to \exp_{p}(t v(s)) \}_{s\in I}","['differential-geometry', 'riemannian-geometry', 'geodesic']"
31,computing a connection coefficient over a framed open set,computing a connection coefficient over a framed open set,,"It is well known that given a connection on a $\mathbb{K}$ vector bundle $E$ over some manifold $M$ with rank $r$ , there is a $U\subset M$ is a framed open set with frame $e= \{ e_i \}_{i=1}^r $ , such that we have a connection form matrix $\omega \in \Omega ^1 (U, \text{Mat}_{r\times r}(\mathbb{K})$ with respect to this frame. It satisfies $$ \nabla_X(\tilde{e}_i)=\sum_j \omega^i_j(X)e_j $$ if $\tilde{e}_i$ is a globally defined section that agrees with $e_i$ on $U$ . I understand that given a vector bundle, we can always find framed open sets in which we can define the connection locally. Now, my question is given a connection and a framed open set, can we always have a connection form with respect to this frame (we of course still have connection via restriction of $\nabla$ )? I think that this does not hold when the section cannot be extended. Usually, when given a connection, we can compute the connection form by evaluating the expression $\nabla_X(\tilde{e}_i)$ since most cases I have seen, $e_i$ can be extended globally for the given frame so this question never occured to me. But considering my question, does one have to be careful with a choosing a frame in which we wish to find a connection over?","It is well known that given a connection on a vector bundle over some manifold with rank , there is a is a framed open set with frame , such that we have a connection form matrix with respect to this frame. It satisfies if is a globally defined section that agrees with on . I understand that given a vector bundle, we can always find framed open sets in which we can define the connection locally. Now, my question is given a connection and a framed open set, can we always have a connection form with respect to this frame (we of course still have connection via restriction of )? I think that this does not hold when the section cannot be extended. Usually, when given a connection, we can compute the connection form by evaluating the expression since most cases I have seen, can be extended globally for the given frame so this question never occured to me. But considering my question, does one have to be careful with a choosing a frame in which we wish to find a connection over?","\mathbb{K} E M r U\subset M e= \{ e_i \}_{i=1}^r  \omega \in \Omega ^1 (U, \text{Mat}_{r\times r}(\mathbb{K}) 
\nabla_X(\tilde{e}_i)=\sum_j \omega^i_j(X)e_j
 \tilde{e}_i e_i U \nabla \nabla_X(\tilde{e}_i) e_i","['differential-geometry', 'manifolds', 'vector-bundles']"
32,Intuition behind the Riemann curvature as a map $\bigwedge^2 T^*M\to \bigwedge^2 T^*M$?,Intuition behind the Riemann curvature as a map ?,\bigwedge^2 T^*M\to \bigwedge^2 T^*M,"Given a (pseudo)-Riemannian manifold $(M^n ,g)$ , one can naturally define the Levi-Cevita connection $\nabla_g: \Gamma(TM)\to \Omega^1(M,TM)$ as the unique metric-compatible, torsion-free connection on $TM$ . This allows us to define the Riemann Tensor: $R: TM\otimes TM\to \mathrm{End}(TM)$ by $$R(\xi_1,\xi_2)(\xi_3):=([\nabla_{g,\xi_1}, \nabla_{g,\xi_2}]-\nabla_{[\xi_1,\xi_2]})\xi_3.$$ Since the map $(\xi_1,\xi_2,\xi_3,\xi_4)\mapsto \langle R(\xi_1,\xi_2)\xi_3,\xi_4\rangle$ is antisymmetric in the first and second slots, as well as in the third and fourth slots, it descends to a map $\bigwedge^2TM\to \bigwedge^2 T^*M$ or equivalently $\bigwedge^2 T^*M\to \bigwedge^2 T^*M$ by precomposition by the correct bundle isomorphism induced by $g$ . Is there a nice way to think of this endomorphism, i.e. as some sort of shearing/rotation of oriented planes, or is it just a mathematical mirage?","Given a (pseudo)-Riemannian manifold , one can naturally define the Levi-Cevita connection as the unique metric-compatible, torsion-free connection on . This allows us to define the Riemann Tensor: by Since the map is antisymmetric in the first and second slots, as well as in the third and fourth slots, it descends to a map or equivalently by precomposition by the correct bundle isomorphism induced by . Is there a nice way to think of this endomorphism, i.e. as some sort of shearing/rotation of oriented planes, or is it just a mathematical mirage?","(M^n ,g) \nabla_g: \Gamma(TM)\to \Omega^1(M,TM) TM R: TM\otimes TM\to \mathrm{End}(TM) R(\xi_1,\xi_2)(\xi_3):=([\nabla_{g,\xi_1}, \nabla_{g,\xi_2}]-\nabla_{[\xi_1,\xi_2]})\xi_3. (\xi_1,\xi_2,\xi_3,\xi_4)\mapsto \langle R(\xi_1,\xi_2)\xi_3,\xi_4\rangle \bigwedge^2TM\to \bigwedge^2 T^*M \bigwedge^2 T^*M\to \bigwedge^2 T^*M g","['differential-geometry', 'riemannian-geometry', 'curvature']"
33,Proving Chern forms are closed via Bianchi identity,Proving Chern forms are closed via Bianchi identity,,"Let $M$ be a smooth real manifold and $E \rightarrow M$ an Hermitean vector bundle over it. Define Chern classes as $$c(M)=\sum_{i=0}^m c_i(E)t^i=\det \left( \textrm{Id} +\frac{i}{2\pi}F \right) = \prod_i (1 + \lambda_i t),$$ Letting $F \triangleq D^2$ denote the curvature two-form associated with the connection $D$ on $M$ - a ( $\mathfrak{u}(E)$ -valued two-form?), and $\lambda_i$ denote the eigenvalues of the normalization $i/2\pi F$ . I have seen it asserted that one may use the Bianchi identity to show that the Chern forms are closed and hence represent cohomology classes, i.e. $$ DF = 0 \implies dc_i(E) = 0 $$ How does one see this from the definition of the Chern classes as above?","Let be a smooth real manifold and an Hermitean vector bundle over it. Define Chern classes as Letting denote the curvature two-form associated with the connection on - a ( -valued two-form?), and denote the eigenvalues of the normalization . I have seen it asserted that one may use the Bianchi identity to show that the Chern forms are closed and hence represent cohomology classes, i.e. How does one see this from the definition of the Chern classes as above?","M E \rightarrow M c(M)=\sum_{i=0}^m c_i(E)t^i=\det \left( \textrm{Id} +\frac{i}{2\pi}F \right) = \prod_i (1 + \lambda_i t), F \triangleq D^2 D M \mathfrak{u}(E) \lambda_i i/2\pi F  DF = 0 \implies dc_i(E) = 0 ","['differential-geometry', 'complex-geometry', 'vector-bundles', 'curvature', 'characteristic-classes']"
34,"Fixed a symplectic form, any differential of a regular function is a contraction of the symplectic form","Fixed a symplectic form, any differential of a regular function is a contraction of the symplectic form",,"Let $M$ be a smooth manifold over $\mathbb{R}$ and $\omega$ a symplectic form on $M$ , i.e. a regular, non-degenerate, closed 2-form. Given a vector field on $M$ , $X \in \mathcal{V}(M)$ , we define the contraction of $\omega$ with respect to $X$ as $$i_X\omega:=\omega(X,-).$$ The problem I am addressing is the following one For any $f \in \mathcal{O}(M)$ there exists a vector field $X$ such that $i_X\omega = df$ I have two ideas to address this problem. First, fixed $f$ I write explicitly the $1$ -forms $df$ and $i_X\omega$ locally and then I set the equality. This gives me sufficient local conditions to determine $X$ . The second idea (which, if correct, is equivalent to the first one) is the following. Let me write the symplectic form as a skew-symmetric non-degenerate bilinear map $$\omega : \mathcal{V}(M) \times \mathcal{V}(M) \rightarrow \mathcal{O}(M).$$ Then, if we restrict ourselves in a local chart, we have a basis for $\mathcal{V}(M)$ and there exists a matrix $M \in M_{ n \times n}(\mathcal{O}(M))$ such that it expresses $\omega$ with respect to the fixed basis of $\mathcal{V}(M)$ . For the property of $\omega$ I would say that $M$ has an inverse matrix in $M_n(\mathcal{O}(M))$ . This is sufficient to conclude. In fact, in coordinates, by the identity $i_X\omega = df$ , we would have that $$\begin{bmatrix} X_1, & \dots & X_n \end{bmatrix}=\begin{bmatrix} \partial_{x_1}f, & \dots & ,\partial_{x_n}f \end{bmatrix} \cdot M^{-1}$$ which define $X$ locally. Now remain to prove that these ""local definitions"" can be put together to define a global vector fields. I would prove this last step using just the definition (if is there any shortcut I will be happy to know that). A third way to prove it could be the following one. Since $\omega$ is a symplectic form, it defines a smooth bundle isomorphism $$TM \rightarrow T^*M, \ T_pM \ni (p,\nu) \mapsto \omega_p(\nu,-) \in T_p^*M$$ (This can be seen as a consequence of the Bundle homomorphism characterization Lemma ) So, the thesis is straightforward. I would like to know if this is a correct way to proceed. Thank you","Let be a smooth manifold over and a symplectic form on , i.e. a regular, non-degenerate, closed 2-form. Given a vector field on , , we define the contraction of with respect to as The problem I am addressing is the following one For any there exists a vector field such that I have two ideas to address this problem. First, fixed I write explicitly the -forms and locally and then I set the equality. This gives me sufficient local conditions to determine . The second idea (which, if correct, is equivalent to the first one) is the following. Let me write the symplectic form as a skew-symmetric non-degenerate bilinear map Then, if we restrict ourselves in a local chart, we have a basis for and there exists a matrix such that it expresses with respect to the fixed basis of . For the property of I would say that has an inverse matrix in . This is sufficient to conclude. In fact, in coordinates, by the identity , we would have that which define locally. Now remain to prove that these ""local definitions"" can be put together to define a global vector fields. I would prove this last step using just the definition (if is there any shortcut I will be happy to know that). A third way to prove it could be the following one. Since is a symplectic form, it defines a smooth bundle isomorphism (This can be seen as a consequence of the Bundle homomorphism characterization Lemma ) So, the thesis is straightforward. I would like to know if this is a correct way to proceed. Thank you","M \mathbb{R} \omega M M X \in \mathcal{V}(M) \omega X i_X\omega:=\omega(X,-). f \in \mathcal{O}(M) X i_X\omega = df f 1 df i_X\omega X \omega : \mathcal{V}(M) \times \mathcal{V}(M) \rightarrow \mathcal{O}(M). \mathcal{V}(M) M \in M_{ n \times n}(\mathcal{O}(M)) \omega \mathcal{V}(M) \omega M M_n(\mathcal{O}(M)) i_X\omega = df \begin{bmatrix}
X_1, & \dots & X_n \end{bmatrix}=\begin{bmatrix} \partial_{x_1}f, & \dots & ,\partial_{x_n}f \end{bmatrix} \cdot M^{-1} X \omega TM \rightarrow T^*M, \ T_pM \ni (p,\nu) \mapsto \omega_p(\nu,-) \in T_p^*M","['differential-geometry', 'differential-forms', 'symplectic-geometry', 'symplectic-linear-algebra']"
35,Differential forms on $\mathbb{R}^n$,Differential forms on,\mathbb{R}^n,"I just read section 4 of the manifold book by Loring Tu. I can understand the $1$ -form without questions as covector fields. A $k$ -form on $U$ is a function that assigns every $p\in U$ an alternating $k$ -linear function on $T_p(\mathbb{R}^n)$ . I understand that we need to assign a $k$ -linear function for integration to make sense. However, why do we need the alternating instead of just $k$ -linear function?","I just read section 4 of the manifold book by Loring Tu. I can understand the -form without questions as covector fields. A -form on is a function that assigns every an alternating -linear function on . I understand that we need to assign a -linear function for integration to make sense. However, why do we need the alternating instead of just -linear function?",1 k U p\in U k T_p(\mathbb{R}^n) k k,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'differential-forms']"
36,Non-elementary examples of compact Anosov manifolds,Non-elementary examples of compact Anosov manifolds,,"Anosov manifolds (Riemannian manifolds whose geodesic flow is Anosov) are a natural generalisation of negatively curved compact manifolds. I'm wondering how good the generalisation is. In particular, is there any Anosov manifold that has some positivity in its curvature?","Anosov manifolds (Riemannian manifolds whose geodesic flow is Anosov) are a natural generalisation of negatively curved compact manifolds. I'm wondering how good the generalisation is. In particular, is there any Anosov manifold that has some positivity in its curvature?",,"['differential-geometry', 'riemannian-geometry', 'dynamical-systems']"
37,Good reference for self study of Gauge theory [closed],Good reference for self study of Gauge theory [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I am looking for the shortest way possible to study basic gauge theory. I am looking for some inspiring survey notes like this one: Christian Bär, Gauga Theory (rather than the great books by Kobayashi & Nomizu or Steenrod). Dealing, in particular, with: Problem of lifting 'basic' paths to horizontal paths. Why the reduction of the structural group is important. Links between: trivial bundle, flat bundle, $G$ -local system","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I am looking for the shortest way possible to study basic gauge theory. I am looking for some inspiring survey notes like this one: Christian Bär, Gauga Theory (rather than the great books by Kobayashi & Nomizu or Steenrod). Dealing, in particular, with: Problem of lifting 'basic' paths to horizontal paths. Why the reduction of the structural group is important. Links between: trivial bundle, flat bundle, -local system",G,"['differential-geometry', 'reference-request', 'fibration', 'gauge-theory', 'holonomy']"
38,How to write down a loop on $\mathrm{Diff}(\mathbb{S}^2)$ concretely?,How to write down a loop on  concretely?,\mathrm{Diff}(\mathbb{S}^2),"If we regard $\mathbb{S^2}$ as the complex projective line $\mathbb{P}^1$ , and define a loop on its diffeomorphism group: $$\gamma: \mathbb{S}^1\longrightarrow\mathrm{Diff}(\mathbb{S}^2)$$ $$z\mapsto([x,y]\mapsto[\bar{z}^kx,y])$$ Where $|z|=1$ , $[x,y]$ is the homogeneous coordinate, $k$ is an integer, how to show that this mapping defines a nontrivial loop on $\mathrm{Diff}(\mathbb{S}^2 )$ for $k$ odd? Here the ""nontrivial"" means it is not homotopic to the constant loop $\beta(z)=\mathrm{id}_{\mathbb{S}^2}$ , i.e. a non trivial element in the fundamental group $\pi_1(\mathrm{Diff}(\mathbb{S}^2 ))$ .","If we regard as the complex projective line , and define a loop on its diffeomorphism group: Where , is the homogeneous coordinate, is an integer, how to show that this mapping defines a nontrivial loop on for odd? Here the ""nontrivial"" means it is not homotopic to the constant loop , i.e. a non trivial element in the fundamental group .","\mathbb{S^2} \mathbb{P}^1 \gamma: \mathbb{S}^1\longrightarrow\mathrm{Diff}(\mathbb{S}^2) z\mapsto([x,y]\mapsto[\bar{z}^kx,y]) |z|=1 [x,y] k \mathrm{Diff}(\mathbb{S}^2
) k \beta(z)=\mathrm{id}_{\mathbb{S}^2} \pi_1(\mathrm{Diff}(\mathbb{S}^2
))","['differential-geometry', 'algebraic-topology', 'differential-topology', 'complex-geometry']"
39,Are invertibly cobordant manifolds diffeomorphic,Are invertibly cobordant manifolds diffeomorphic,,"Let $M$ and $N$ be oriented, closed, $n-1$ manifolds and $F$ a cobordism from $M$ to $N$ and $G$ a cobordism from $N$ to $M$ such that the composite cobordism $G\circ F\cong M\times I$ and $F\circ G\cong N\times I$ . Does the existence of an ""inverse"" cobordism imply that $M$ is diffeomorphic to $N$ ? My first, naive strategy is to take the following composite: if $j: N\to F$ is the inclusion of $N$ into $F$ , $\psi: G\circ F\to M\times I$ the diffeomorphism, and $\pi: M\times I\to M$ the projection on the first factor, then the composite $\pi \circ \psi \circ j$ is a map from $N\to M$ . However, it is easy to foresee that this map may fail to be injective or surjective. Is there reason to believe this statement to be true?","Let and be oriented, closed, manifolds and a cobordism from to and a cobordism from to such that the composite cobordism and . Does the existence of an ""inverse"" cobordism imply that is diffeomorphic to ? My first, naive strategy is to take the following composite: if is the inclusion of into , the diffeomorphism, and the projection on the first factor, then the composite is a map from . However, it is easy to foresee that this map may fail to be injective or surjective. Is there reason to believe this statement to be true?",M N n-1 F M N G N M G\circ F\cong M\times I F\circ G\cong N\times I M N j: N\to F N F \psi: G\circ F\to M\times I \pi: M\times I\to M \pi \circ \psi \circ j N\to M,"['differential-geometry', 'differential-topology', 'cobordism']"
40,Large charts on smooth manifolds,Large charts on smooth manifolds,,"I suddenly found out that in all the examples coming to my mind a (compact) smooth manifold has a ""large"" coordinate chart whose complement has positive codimension. In other word, is it true that for any smooth compact manifold $M$ there exists a closed (probably singular) submanifold $N$ of positive codimension such that $M\setminus N$ is diffeomorphic to $\mathbb{R}^n$ ? And the same question about topological manifolds with ""diffeomorphic"" replaced by ""homeomorphic"" and the complement of positive codimension replaced by some appropriate notion of ""small"" subset.","I suddenly found out that in all the examples coming to my mind a (compact) smooth manifold has a ""large"" coordinate chart whose complement has positive codimension. In other word, is it true that for any smooth compact manifold there exists a closed (probably singular) submanifold of positive codimension such that is diffeomorphic to ? And the same question about topological manifolds with ""diffeomorphic"" replaced by ""homeomorphic"" and the complement of positive codimension replaced by some appropriate notion of ""small"" subset.",M N M\setminus N \mathbb{R}^n,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'geometric-topology']"
41,Map between Stiefel manifold and the Grassmannian,Map between Stiefel manifold and the Grassmannian,,"I'm working on problem 2-7 in Lee's introduction to Riemannian Manifolds and am having trouble on part (b): Let $V_k(\mathbb{R}^n)$ be the Stiefel manifold and $G_k(\mathbb{R}^n)$ denote the Grassmannian. I want to show that the map $$ \pi : V_k(\mathbb{R}^n) \rightarrow G_k(\mathbb{R}^n)$$ that sends a k-tuple to its span is a surjective smooth submersion. I have already shown that $\pi$ is surjective and that both $V_k(\mathbb{R}^n)$ and $G_k(\mathbb{R}^n)$ are smooth manifolds. Hence if I can show that $\pi$ is a smooth map of constant rank, the result should follow. I appreciate any help.","I'm working on problem 2-7 in Lee's introduction to Riemannian Manifolds and am having trouble on part (b): Let be the Stiefel manifold and denote the Grassmannian. I want to show that the map that sends a k-tuple to its span is a surjective smooth submersion. I have already shown that is surjective and that both and are smooth manifolds. Hence if I can show that is a smooth map of constant rank, the result should follow. I appreciate any help.",V_k(\mathbb{R}^n) G_k(\mathbb{R}^n)  \pi : V_k(\mathbb{R}^n) \rightarrow G_k(\mathbb{R}^n) \pi V_k(\mathbb{R}^n) G_k(\mathbb{R}^n) \pi,"['differential-geometry', 'differential-topology', 'grassmannian', 'stiefel-manifolds']"
42,volume preserving version of Moser's theorem,volume preserving version of Moser's theorem,,"There exists an well-known theorem of Moser : Thereom(Moser) Let $M$ be a compact oriented smooth manifold and $\alpha,\beta$ be volume forms whose total volumes are the same. Then, there exists a diffeomorphism $\phi:M\rightarrow M$ such that $\phi^*\beta=\alpha$ . After that, I modify this theorem under the fixed volume form. ??? Let $M$ be a compact oriented smooth manifold and $\mu_0$ be a volume form. For positive $f,g\in C^\infty(M)$ with $\int_M f\mu_0=\int_M g\mu_0$ , there exists a volume-preserving diffeomorphism $\phi\in \text{Diff}(M,\mu_0)$ such that $f\circ \phi = g$ . Is the theorem is true? How could I prove this? I try to prove this by using Moser's decomposition technique but there is some difficulty to verify the existence of solution of some PDE due to the volume preserving condition.","There exists an well-known theorem of Moser : Thereom(Moser) Let be a compact oriented smooth manifold and be volume forms whose total volumes are the same. Then, there exists a diffeomorphism such that . After that, I modify this theorem under the fixed volume form. ??? Let be a compact oriented smooth manifold and be a volume form. For positive with , there exists a volume-preserving diffeomorphism such that . Is the theorem is true? How could I prove this? I try to prove this by using Moser's decomposition technique but there is some difficulty to verify the existence of solution of some PDE due to the volume preserving condition.","M \alpha,\beta \phi:M\rightarrow M \phi^*\beta=\alpha M \mu_0 f,g\in C^\infty(M) \int_M f\mu_0=\int_M g\mu_0 \phi\in \text{Diff}(M,\mu_0) f\circ \phi = g","['differential-geometry', 'differential-forms', 'volume', 'symplectic-geometry']"
43,Riemannian metric making a submanifold totally geodesic and with positive injectivity radius,Riemannian metric making a submanifold totally geodesic and with positive injectivity radius,,"Consider a manifold $N$ and a submanifold $M$ . We're assuming that $N$ and $M$ can be non-compact. Is it possible to find a metric $g$ of $N$ such that $M$ is totally geodesic with respect to $(N,g)$ and such that the metric $g$ has positive injectivity radius ? This question came to me because I am trying to parametrize a infinite dimensional banach manifold of curves, hence I need the positive injectivity radius, and I also need that these maps satisfy specific boundary conditions, hence the totally geodesic condition. I have been thinking about this but I am have no idea on how to proceed. Edit: This problem came to mind because I wanted to see if  I could find a metric in $T^*M$ such that it has positive injectivity radius and with totally geodesic fibers. An idea would be to consider a metric in the conformal class of the Sasaki metric $g_S$ . We know that the Sasaki metric has totally geodesic fibers. Then if we could consider something like $e^{2f}g_{S}$ such that it would have positive injectivity radius and $\text{grad}(f)$ is tangent to the fibers I belive we could consider this metric to get the desired result. However I have not yet been able to find this smooth function $f$ . Any help is appreciated, thanks in advance.","Consider a manifold and a submanifold . We're assuming that and can be non-compact. Is it possible to find a metric of such that is totally geodesic with respect to and such that the metric has positive injectivity radius ? This question came to me because I am trying to parametrize a infinite dimensional banach manifold of curves, hence I need the positive injectivity radius, and I also need that these maps satisfy specific boundary conditions, hence the totally geodesic condition. I have been thinking about this but I am have no idea on how to proceed. Edit: This problem came to mind because I wanted to see if  I could find a metric in such that it has positive injectivity radius and with totally geodesic fibers. An idea would be to consider a metric in the conformal class of the Sasaki metric . We know that the Sasaki metric has totally geodesic fibers. Then if we could consider something like such that it would have positive injectivity radius and is tangent to the fibers I belive we could consider this metric to get the desired result. However I have not yet been able to find this smooth function . Any help is appreciated, thanks in advance.","N M N M g N M (N,g) g T^*M g_S e^{2f}g_{S} \text{grad}(f) f","['differential-geometry', 'riemannian-geometry', 'differential-topology']"
44,Can an incomplete geodesic intersect a point infinitely many times?,Can an incomplete geodesic intersect a point infinitely many times?,,"Consider a Lorentzian manifold $(M,g)$ . Must a maximal, affinely parameterized geodesic $\gamma: [0,b) \to M$ which intersects a point $p \in M$ infinitely many times be complete (i.e., have $b = \infty$ )? It's easy to show that the answer is positive in the Riemannian setting by considering a normal ball around $p$ and noticing that the geodesic must radially traverse its diameter infinitely many times, accumulating infinite length. The same picture applies in the Lorentzian case, up until the critical conclusion of ""accumulating infinite length"", since the ""diameter"" of a normal neighborhood is no longer meaningful. Indeed, the radial trajectories may, in principle become closer and closer to null with subsequent passings of $p$ in such a way that the accumulated length/proper time is finite (or zero if the geodesic was null in the first place). While the Riemannian reasoning breaks down, is there some other reason that intersecting a single point infinitely many times enforces completeness in general, or can one perhaps find a counterexample? Feel free to assume any causality condition you like, so that the question is really about spacelike geodesics. It is worthwhile to note that the most obvious way to obtain infinitely repeated intersection of a single point is, of course, to consider a closed loop, which is always complete when maximally extended (at least when non-null, which would be the case under even a very lax causality condition). Also worth noting is that maximal, incomplete geodesics with limit points can exist (e.g. in the Misner spacetime), which demonstrates that something too close to the Riemannian reasoning (which also rules this out in a Riemannian setting) can't work. Edit: Didier has helpfully provided the counterexample of the Clifton-Pohl torus . This example, being compact, admits closed timelike curves, however, so I am still interested in the question of whether this is possible under a more restrictive causality condition. In particular, since the issue arising in the above normal neighborhood picture is that the geodesic may become too close to null in normal coordinates, it seems intuitive that $M$ 's being stably causal (i.e. $M$ would not admit closed causal curves even under small perturbations to the metric) may rule this out. Can this intuition be made precise, or could even a less restrictive causality condition suffice?","Consider a Lorentzian manifold . Must a maximal, affinely parameterized geodesic which intersects a point infinitely many times be complete (i.e., have )? It's easy to show that the answer is positive in the Riemannian setting by considering a normal ball around and noticing that the geodesic must radially traverse its diameter infinitely many times, accumulating infinite length. The same picture applies in the Lorentzian case, up until the critical conclusion of ""accumulating infinite length"", since the ""diameter"" of a normal neighborhood is no longer meaningful. Indeed, the radial trajectories may, in principle become closer and closer to null with subsequent passings of in such a way that the accumulated length/proper time is finite (or zero if the geodesic was null in the first place). While the Riemannian reasoning breaks down, is there some other reason that intersecting a single point infinitely many times enforces completeness in general, or can one perhaps find a counterexample? Feel free to assume any causality condition you like, so that the question is really about spacelike geodesics. It is worthwhile to note that the most obvious way to obtain infinitely repeated intersection of a single point is, of course, to consider a closed loop, which is always complete when maximally extended (at least when non-null, which would be the case under even a very lax causality condition). Also worth noting is that maximal, incomplete geodesics with limit points can exist (e.g. in the Misner spacetime), which demonstrates that something too close to the Riemannian reasoning (which also rules this out in a Riemannian setting) can't work. Edit: Didier has helpfully provided the counterexample of the Clifton-Pohl torus . This example, being compact, admits closed timelike curves, however, so I am still interested in the question of whether this is possible under a more restrictive causality condition. In particular, since the issue arising in the above normal neighborhood picture is that the geodesic may become too close to null in normal coordinates, it seems intuitive that 's being stably causal (i.e. would not admit closed causal curves even under small perturbations to the metric) may rule this out. Can this intuition be made precise, or could even a less restrictive causality condition suffice?","(M,g) \gamma: [0,b) \to M p \in M b = \infty p p M M","['differential-geometry', 'geodesic', 'general-relativity', 'semi-riemannian-geometry']"
45,Why is the Legendre transform (of vector bundles) a smooth morphism $\mathbf FL:E\to E^*$?,Why is the Legendre transform (of vector bundles) a smooth morphism ?,\mathbf FL:E\to E^*,"The Legendre transform of convex functions $\mathbb R^n\to\mathbb R^n$ can be given a nice geometric interpretation as a way to characterise a function via the set of the tangent spaces to its graph. The Wikipedia page mentions that this idea can be generalised to define the Legendre transform of smooth functions $L:E\to\mathbb R$ for a generic vector bundle $\pi:E\to M$ with $M$ a smooth manifold. I'm trying to understand how (or if?) this definition connects with the geometric one mentioned above. In the Wiki page, they define the Legendre transform of $L:E\to \mathbb R$ as the smooth morphism $$\mathbf FL:E\to E^*,$$ such that, for all $v\in E$ , $$\mathbf FL(v) \equiv \mathrm d(L|_{E_x})(v),$$ where $L|_{E_x}:E_x\to\mathbb R$ is the restriction of $L$ to the fiber $E_x$ over $x\in M$ such that $x=\pi(v)$ (so that $v\in E_x$ ). As pointed out in the Wikipedia page, this means that $$(\mathbf FL(v)) (w) = (\mathrm d(L|_{E_x})(v))(w) = \partial_t|_0 L(v + tw)\in\mathbb R.$$ There is then some more explanation about what this looks like in local coordinates: $$\mathbf FL(x;v_1,...,v_r) = (x; p_1,...,p_r), \quad\text{where}\quad p_i = \frac{\partial L}{\partial v_i}(x; v_1,...,v_r).$$ However, I can't see how this relates (if it does at all) to the intuition in the simple case of looking at tangent planes to the graph of the function. Sure, given $f:\mathbb R\to\mathbb R$ , to find $\max_x (px-f(x))$ we compute $p=f'(x_0)$ , but the Legendre transform is then obtained replacing $x_0=x_0(p)$ in $px_0-f(x_0)$ , which we are not doing here at all it looks like.","The Legendre transform of convex functions can be given a nice geometric interpretation as a way to characterise a function via the set of the tangent spaces to its graph. The Wikipedia page mentions that this idea can be generalised to define the Legendre transform of smooth functions for a generic vector bundle with a smooth manifold. I'm trying to understand how (or if?) this definition connects with the geometric one mentioned above. In the Wiki page, they define the Legendre transform of as the smooth morphism such that, for all , where is the restriction of to the fiber over such that (so that ). As pointed out in the Wikipedia page, this means that There is then some more explanation about what this looks like in local coordinates: However, I can't see how this relates (if it does at all) to the intuition in the simple case of looking at tangent planes to the graph of the function. Sure, given , to find we compute , but the Legendre transform is then obtained replacing in , which we are not doing here at all it looks like.","\mathbb R^n\to\mathbb R^n L:E\to\mathbb R \pi:E\to M M L:E\to \mathbb R \mathbf FL:E\to E^*, v\in E \mathbf FL(v) \equiv \mathrm d(L|_{E_x})(v), L|_{E_x}:E_x\to\mathbb R L E_x x\in M x=\pi(v) v\in E_x (\mathbf FL(v)) (w) = (\mathrm d(L|_{E_x})(v))(w)
= \partial_t|_0 L(v + tw)\in\mathbb R. \mathbf FL(x;v_1,...,v_r) = (x; p_1,...,p_r),
\quad\text{where}\quad p_i = \frac{\partial L}{\partial v_i}(x; v_1,...,v_r). f:\mathbb R\to\mathbb R \max_x (px-f(x)) p=f'(x_0) x_0=x_0(p) px_0-f(x_0)","['differential-geometry', 'vector-bundles', 'convex-geometry', 'legendre-transformation']"
46,Unifying theorem for the turning number and the Gauss-Bonnet theorem,Unifying theorem for the turning number and the Gauss-Bonnet theorem,,The statement that the turning number of a planar curve is a multiple of $2\pi$ and the Gauss-Bonnet theorem are similar in that they both state that the integral of a curvature measure depends on the topology but not the shape of the manifold. Is there a theorem that unifies the two statements that yields the former for $n=1$ and the latter for $n=2$ ? What does it say for $n=3$ ?,The statement that the turning number of a planar curve is a multiple of and the Gauss-Bonnet theorem are similar in that they both state that the integral of a curvature measure depends on the topology but not the shape of the manifold. Is there a theorem that unifies the two statements that yields the former for and the latter for ? What does it say for ?,2\pi n=1 n=2 n=3,"['differential-geometry', 'manifolds', 'curves', 'surfaces', 'curvature']"
47,"$d\langle \alpha,\beta\rangle$ for two $k$ forms $\alpha,\beta$ on a manifold",for two  forms  on a manifold,"d\langle \alpha,\beta\rangle k \alpha,\beta","I want to write an expression for $d\langle\alpha,\beta\rangle$ where $\alpha,\beta$ are two $k$ forms on a closed Riemannian manifold say $M$ . Now I would want to write something like \begin{align*} d\langle\alpha,\beta\rangle=\langle d\alpha,\beta\rangle+\langle\alpha,d\beta\rangle \end{align*} But it won't be right as $d\alpha$ and $d\beta$ would become $k+1$ forms and also the end product should be a $1$ -form. What should be the correct expression and the interpretation for that? Here the inner product is the usual inner product on forms using Hodge-star operator.",I want to write an expression for where are two forms on a closed Riemannian manifold say . Now I would want to write something like But it won't be right as and would become forms and also the end product should be a -form. What should be the correct expression and the interpretation for that? Here the inner product is the usual inner product on forms using Hodge-star operator.,"d\langle\alpha,\beta\rangle \alpha,\beta k M \begin{align*}
d\langle\alpha,\beta\rangle=\langle d\alpha,\beta\rangle+\langle\alpha,d\beta\rangle
\end{align*} d\alpha d\beta k+1 1","['differential-geometry', 'riemannian-geometry', 'differential-forms']"
48,Question about using Sard's theorem in Whitney's weak embedding theorem,Question about using Sard's theorem in Whitney's weak embedding theorem,,"I'm trying to study about Whitney's embedding theorem (the case for $2k+1$ ). Studying the proof of the theorem: http://staff.ustc.edu.cn/~wangzuoq/Courses/18F-Manifolds/Notes/Lec09.pdf I encountered a few things I'm not sure about. At the end of the third page, it's stated that the image of the map $\alpha:M\times M\setminus \Delta\rightarrow\Bbb{RP}^{K-1}$ $($ where $\Delta=\{(p,p):p\in M\})$ is of measure zero following Sard's theorem (because $M\times M$ is an open submanifold of dimension $2k<K-1$ ), but Sard's theorem speaks about critical points, so why does it imply that? Same question goes about the map $\beta$ mentioned right after it.","I'm trying to study about Whitney's embedding theorem (the case for ). Studying the proof of the theorem: http://staff.ustc.edu.cn/~wangzuoq/Courses/18F-Manifolds/Notes/Lec09.pdf I encountered a few things I'm not sure about. At the end of the third page, it's stated that the image of the map where is of measure zero following Sard's theorem (because is an open submanifold of dimension ), but Sard's theorem speaks about critical points, so why does it imply that? Same question goes about the map mentioned right after it.","2k+1 \alpha:M\times M\setminus \Delta\rightarrow\Bbb{RP}^{K-1} ( \Delta=\{(p,p):p\in M\}) M\times M 2k<K-1 \beta","['differential-geometry', 'proof-explanation', 'differential-topology', 'smooth-manifolds', 'submanifold']"
49,coordinate transformation of the Laplace Beltrami Operator,coordinate transformation of the Laplace Beltrami Operator,,"My Laplace-Beltrami operator isn't transforming correctly under a change of coordinates. What am I doing wrong? The Laplace-Betrami operator has the following expressing in local coordinates of a Riemannian manifold $(M, g)$ , \begin{align} \Delta f(x) = g^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i \partial x_j} + g^{jk}\Gamma^i_{jk} \frac{\partial f(x)}{\partial x_i}, \end{align} where $\Gamma^i_{jk}$ are Christoffel symbols. Written in this way, it is clear that the Laplace-Beltrami operator is a second-order elliptic operator on the manifold. Many books such as Markov Processes by Dynkin (page 151) or Functional Analysis by Yosida (page 426) state that the coefficient functions of elliptic operators must transform in a prescribed way in order to give a consistent result on the manifold. Namely, consider an elliptic operator of the form (written in local coordinates $x$ ) \begin{align} Af(x) = b^i(x) \frac{\partial f(x)}{\partial x_i} + a^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i\partial x_j}. \end{align} Then in another coordinate system $\tilde{x}$ the coefficient functions transform as \begin{align} \tilde{b}^i(x) &= b^k(x) \frac{\partial \tilde{x}_i}{\partial x_k} + a^{kl}(x)\frac{\partial^2 \tilde{x}_i}{\partial x_k\partial x_l} \\\\ \tilde{a}^{ij}(x) &= a^{kl}(x) \frac{\partial \tilde{x}_i}{\partial x_k}\frac{\partial \tilde{x}_j}{\partial x_l}. \end{align} The Laplace-Beltrami operator should then obey this transformation rule with $a^{ij} =g^{ij}$ and $b^i = g^{jk}\Gamma^i_{jk}$ . The fact that $g^{ij}$ obeys the correct transformation rule is apparent; however, I am having a hard time seeing that $g^{jk}\Gamma^i_{jk}$ obeys the correct transformation. What I want to show is that \begin{align} \tilde{g}^{jk}\tilde{\Gamma}^i_{jk} = g^{pq}\Gamma^k_{pq} \frac{\partial \tilde{x}_i}{\partial x_k} + g^{pq}\frac{\partial^2 \tilde{x}_p}{\partial x_k\partial x_q} \end{align} I know that the transformation rule for the Christoffel symbols is as follows: \begin{align}     \tilde{\Gamma}^i_{jk} &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} + \frac{\partial^2 x_r}{\partial \tilde{x}_j\partial \tilde{x}_k} \frac{\partial \tilde{x}_i}{\partial x_r} \\     &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k} \end{align} If I multiply both sides by $\tilde{g}^{jk}$ and use the transformation law of the inverse metric in coordinates, I obtain, \begin{align}     \tilde{g}^{jk} \tilde{\Gamma}^i_{jk} &=  \tilde{g}^{jk} \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \tilde{g}^{jk}\frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k} \\     &= g^{pq} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - g^{pq} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q}. \end{align} This is very nearly what I wanted to show, but differs from the expected result by a negative sign in the second term. What have I done wrong?","My Laplace-Beltrami operator isn't transforming correctly under a change of coordinates. What am I doing wrong? The Laplace-Betrami operator has the following expressing in local coordinates of a Riemannian manifold , where are Christoffel symbols. Written in this way, it is clear that the Laplace-Beltrami operator is a second-order elliptic operator on the manifold. Many books such as Markov Processes by Dynkin (page 151) or Functional Analysis by Yosida (page 426) state that the coefficient functions of elliptic operators must transform in a prescribed way in order to give a consistent result on the manifold. Namely, consider an elliptic operator of the form (written in local coordinates ) Then in another coordinate system the coefficient functions transform as The Laplace-Beltrami operator should then obey this transformation rule with and . The fact that obeys the correct transformation rule is apparent; however, I am having a hard time seeing that obeys the correct transformation. What I want to show is that I know that the transformation rule for the Christoffel symbols is as follows: If I multiply both sides by and use the transformation law of the inverse metric in coordinates, I obtain, This is very nearly what I wanted to show, but differs from the expected result by a negative sign in the second term. What have I done wrong?","(M, g) \begin{align}
\Delta f(x) = g^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i \partial x_j} + g^{jk}\Gamma^i_{jk} \frac{\partial f(x)}{\partial x_i},
\end{align} \Gamma^i_{jk} x \begin{align}
Af(x) = b^i(x) \frac{\partial f(x)}{\partial x_i} + a^{ij}(x) \frac{\partial^2 f(x)}{\partial x_i\partial x_j}.
\end{align} \tilde{x} \begin{align}
\tilde{b}^i(x) &= b^k(x) \frac{\partial \tilde{x}_i}{\partial x_k} + a^{kl}(x)\frac{\partial^2 \tilde{x}_i}{\partial x_k\partial x_l} \\\\
\tilde{a}^{ij}(x) &= a^{kl}(x) \frac{\partial \tilde{x}_i}{\partial x_k}\frac{\partial \tilde{x}_j}{\partial x_l}.
\end{align} a^{ij} =g^{ij} b^i = g^{jk}\Gamma^i_{jk} g^{ij} g^{jk}\Gamma^i_{jk} \begin{align}
\tilde{g}^{jk}\tilde{\Gamma}^i_{jk} = g^{pq}\Gamma^k_{pq} \frac{\partial \tilde{x}_i}{\partial x_k} + g^{pq}\frac{\partial^2 \tilde{x}_p}{\partial x_k\partial x_q}
\end{align} \begin{align}
    \tilde{\Gamma}^i_{jk} &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} + \frac{\partial^2 x_r}{\partial \tilde{x}_j\partial \tilde{x}_k} \frac{\partial \tilde{x}_i}{\partial x_r} \\
    &= \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k}
\end{align} \tilde{g}^{jk} \begin{align}
    \tilde{g}^{jk} \tilde{\Gamma}^i_{jk} &=  \tilde{g}^{jk} \frac{\partial x_p}{\partial\tilde{x_j}}\frac{\partial x_q}{\partial\tilde{x}_k} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - \tilde{g}^{jk}\frac{\partial x_p}{\partial \tilde{x}_j} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q} \frac{\partial x_q}{\partial \tilde{x}_k} \\
    &= g^{pq} \Gamma_{pq}^r \frac{\tilde{x}_i}{\partial x_r} - g^{pq} \frac{\partial^2 \tilde{x}_i}{\partial x_p\partial x_q}.
\end{align}","['differential-geometry', 'riemannian-geometry', 'analytic-geometry', 'elliptic-equations']"
50,Derivative of a $1$-parameter family of Riemannian metrics,Derivative of a -parameter family of Riemannian metrics,1,"Let $S^n$ be a closed manifold and let $(M^{n+1},g)$ be a complete Riemannian manifold. Consider $\varphi: S \to M$ a fixed immersion and let $\varphi_t : S \to M$ , $t\in(-\varepsilon, \varepsilon)$ , be the following $1$ -parameter family of immersions (for sufficiently small $\varepsilon$ ): $$ \varphi_t(p) = \operatorname{exp}_{\varphi(p)}(t f(p) N(p)), $$ where $f \in C^{\infty}(S)$ and $N$ is a unit normal for $S$ along $\varphi$ . How do I compute $$\left. \frac{\mathrm{d}}{\mathrm{d}t} \right\vert_{t=0} \varphi_t^{\ast}g \quad ?$$ Notice that $\varphi_t^{\ast}g$ is a $1$ -parameter family of symmetric $(0,2)$ -tensors on $S$ . The derivative above resembles the definition of the Lie derivative, but there are no flows of vector fields involved.","Let be a closed manifold and let be a complete Riemannian manifold. Consider a fixed immersion and let , , be the following -parameter family of immersions (for sufficiently small ): where and is a unit normal for along . How do I compute Notice that is a -parameter family of symmetric -tensors on . The derivative above resembles the definition of the Lie derivative, but there are no flows of vector fields involved.","S^n (M^{n+1},g) \varphi: S \to M \varphi_t : S \to M t\in(-\varepsilon, \varepsilon) 1 \varepsilon  \varphi_t(p) = \operatorname{exp}_{\varphi(p)}(t f(p) N(p)),  f \in C^{\infty}(S) N S \varphi \left. \frac{\mathrm{d}}{\mathrm{d}t} \right\vert_{t=0} \varphi_t^{\ast}g \quad ? \varphi_t^{\ast}g 1 (0,2) S","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'tensors', 'lie-derivative']"
51,"Example of compact manifold with bdd such that there exists geodesic whose first time of hitting boundary is different form exit time of geodesic,","Example of compact manifold with bdd such that there exists geodesic whose first time of hitting boundary is different form exit time of geodesic,",,"Let M be compact Riemann manifold with boundary. The unit sphere bundle $SM$ is given by $$SM=\{(x, v)||v|_{g}=1,x \in M\}$$ where $g$ is the Riemannian metric in the tangent space at $x$ . Given $(x, v) \in S M$ , let $\gamma_{x, v}$ denote the unique geodesic determined by $(x, v)$ so that $\gamma_{x, v}(0)=x$ and $\dot{\gamma}_{x, v}(0)=v$ . For any $(x, v) \in S M$ the geodesic $\gamma_{x, v}$ is defined on a maximal interval of existence that we denote by $\left[-\tau_{-}(x, v), \tau_{+}(x, v)\right]$ where $\tau_{\pm}(x, v) \in[0, \infty]$ , so that $$ \gamma_{x, v}:\left[-\tau_{-}(x, v), \tau_{+}(x, v)\right] \rightarrow M $$ is a smooth curve that cannot be extended to any larger interval as a smooth curve in $M$ . We let $$ \tau(x, v):=\tau_{+}(x, v) $$ Thus $\tau(x, v)$ is the exit time when the geodesic $\gamma_{x, v}$ exits $M$ . I am interested in finding an example of manifold such that there exists geodesic at point $x$ and direction $v$ such that first time geodesic to hit the boundary is different from exit time of geodesic $\tau_{(x,v)}$ . I could not imagine an example where geodesic reach boundary but come back again inside the manifold. Any help or hint will be appreciated.","Let M be compact Riemann manifold with boundary. The unit sphere bundle is given by where is the Riemannian metric in the tangent space at . Given , let denote the unique geodesic determined by so that and . For any the geodesic is defined on a maximal interval of existence that we denote by where , so that is a smooth curve that cannot be extended to any larger interval as a smooth curve in . We let Thus is the exit time when the geodesic exits . I am interested in finding an example of manifold such that there exists geodesic at point and direction such that first time geodesic to hit the boundary is different from exit time of geodesic . I could not imagine an example where geodesic reach boundary but come back again inside the manifold. Any help or hint will be appreciated.","SM SM=\{(x, v)||v|_{g}=1,x \in M\} g x (x, v) \in S M \gamma_{x, v} (x, v) \gamma_{x, v}(0)=x \dot{\gamma}_{x, v}(0)=v (x, v) \in S M \gamma_{x, v} \left[-\tau_{-}(x, v), \tau_{+}(x, v)\right] \tau_{\pm}(x, v) \in[0, \infty] 
\gamma_{x, v}:\left[-\tau_{-}(x, v), \tau_{+}(x, v)\right] \rightarrow M
 M 
\tau(x, v):=\tau_{+}(x, v)
 \tau(x, v) \gamma_{x, v} M x v \tau_{(x,v)}","['differential-geometry', 'riemannian-geometry', 'examples-counterexamples', 'geodesic']"
52,Why vector field commute but the flow does not commute in this example,Why vector field commute but the flow does not commute in this example,,"I was doing Lee's smooth manifold Problem 9-19. Which is stated as follows: 9-19. Let $M$ be $\mathbb{R}^{3}$ with the $z$ -axis removed. Define $V, W \in \mathfrak{X}(M)$ by $$ V=\frac{\partial}{\partial x}-\frac{y}{x^{2}+y^{2}} \frac{\partial}{\partial z}, \quad W=\frac{\partial}{\partial y}+\frac{x}{x^{2}+y^{2}} \frac{\partial}{\partial z} $$ and let $\theta$ and $\psi$ be the flows of $V$ and $W$ , respectively. Prove that $V$ and $W$ commute, but there exist $p \in M$ and $s, t \in \mathbb{R}$ such that $\theta_{t} \circ \psi_{s}(p)$ and $\psi_{s} \circ \theta_{t}(p)$ are both defined but are not equal. I solve the ODE and gets the solution: $$\theta_t\circ \psi_s = (p_1+t,p_2+s,\arctan(\frac{s+p_2}{p_1})+p_3-\arctan(\frac{p_2}{p_1}))\\\psi_s\circ\theta_t = (p_1+t,p_2+s,-\arctan(\frac{t+p_1}{p_2}) +p_3 + \arctan(\frac{p_1}{p_2}))$$ Which is obvious not equal,they both defined for all $(\Bbb{R}^3\setminus \{z\} )\times \Bbb{R}$ ,but it contradict to the theorem 9.44 that vector field commute if and only if flow commute?If I haven't made mistake in the computation.Is my computation correct,it's so hard to compute.Why does it not consistent with the theorem?","I was doing Lee's smooth manifold Problem 9-19. Which is stated as follows: 9-19. Let be with the -axis removed. Define by and let and be the flows of and , respectively. Prove that and commute, but there exist and such that and are both defined but are not equal. I solve the ODE and gets the solution: Which is obvious not equal,they both defined for all ,but it contradict to the theorem 9.44 that vector field commute if and only if flow commute?If I haven't made mistake in the computation.Is my computation correct,it's so hard to compute.Why does it not consistent with the theorem?","M \mathbb{R}^{3} z V, W \in \mathfrak{X}(M) 
V=\frac{\partial}{\partial x}-\frac{y}{x^{2}+y^{2}} \frac{\partial}{\partial z}, \quad W=\frac{\partial}{\partial y}+\frac{x}{x^{2}+y^{2}} \frac{\partial}{\partial z}
 \theta \psi V W V W p \in M s, t \in \mathbb{R} \theta_{t} \circ \psi_{s}(p) \psi_{s} \circ \theta_{t}(p) \theta_t\circ \psi_s = (p_1+t,p_2+s,\arctan(\frac{s+p_2}{p_1})+p_3-\arctan(\frac{p_2}{p_1}))\\\psi_s\circ\theta_t = (p_1+t,p_2+s,-\arctan(\frac{t+p_1}{p_2}) +p_3 + \arctan(\frac{p_1}{p_2})) (\Bbb{R}^3\setminus \{z\} )\times \Bbb{R}","['differential-geometry', 'smooth-manifolds', 'vector-fields']"
53,"If an exact form vanishes on a submanifold, can I find a primitive that also does?","If an exact form vanishes on a submanifold, can I find a primitive that also does?",,"Let $M$ be a closed smooth manifold and $Q\subset M$ a closed embedded submanifold. Furthermore, let $\omega$ be an exact differential form $\omega\in\Omega^k(M)$ and vanishing identically on $Q$ (i.e. $\omega_q=0$ for any $q\in\ Q$ ). Can we always find a primitive $\alpha\in\Omega^{k-1}(M)$ (i.e. such that $d\alpha=\omega$ ), whose restriction to $Q$ also vanishes? This question came up during class and maybe it is obvious but I can't even seem to convince myself whether it is true or not, so any help is greatly appreciated. Edit: counterexamples are given in the comments for $k=\dim Q+1$ and for the case of $\omega$ being $1$ -form with $Q$ disconnected. In the context of the class, we were specifically considering $\omega$ to be a $2$ -form, but I am also interested in the general case. Edit2: There is an answer dealing with the condition of the pullback of $\omega$ to $Q$ being $0$ . However, I meant that $\omega$ itself vanishes identically in points that belong to the submanifold $Q$ .","Let be a closed smooth manifold and a closed embedded submanifold. Furthermore, let be an exact differential form and vanishing identically on (i.e. for any ). Can we always find a primitive (i.e. such that ), whose restriction to also vanishes? This question came up during class and maybe it is obvious but I can't even seem to convince myself whether it is true or not, so any help is greatly appreciated. Edit: counterexamples are given in the comments for and for the case of being -form with disconnected. In the context of the class, we were specifically considering to be a -form, but I am also interested in the general case. Edit2: There is an answer dealing with the condition of the pullback of to being . However, I meant that itself vanishes identically in points that belong to the submanifold .",M Q\subset M \omega \omega\in\Omega^k(M) Q \omega_q=0 q\in\ Q \alpha\in\Omega^{k-1}(M) d\alpha=\omega Q k=\dim Q+1 \omega 1 Q \omega 2 \omega Q 0 \omega Q,"['differential-geometry', 'smooth-manifolds', 'differential-forms', 'submanifold', 'exterior-derivative']"
54,Confusion about lift in the context of tangent bundle,Confusion about lift in the context of tangent bundle,,"A lift is defined here: https://mathworld.wolfram.com/Lift.html as a tangent vector field $X$ on a manifold, the same way that a section of the tangent bundle gives us $X$ in the context $\dot g = X(g)$ . This answer to a different question: https://mathoverflow.net/a/111198/172470 suggests that a path $g$ can be lifted into the tangent bundle space as $\tilde g \in T_x M$ , and is a smooth curve there. I am confused about this, because of two reasons: Isn't $T_x M$ the set of vectors tangent to a specific point $x$ (the ""tangent space"" at $x$ )? How can we have a curve there, especially a closed loop, like the cited answer suggests? If we can, how is this lift a vector field? Thanks for any help you can give, including any clarification of definitions I may be wrong about. Pictures are nice too since english isn't my second language, and I've already gone down the wrong road with some ideas in differential geometry because I had formed the wrong picture. Thank you!","A lift is defined here: https://mathworld.wolfram.com/Lift.html as a tangent vector field on a manifold, the same way that a section of the tangent bundle gives us in the context . This answer to a different question: https://mathoverflow.net/a/111198/172470 suggests that a path can be lifted into the tangent bundle space as , and is a smooth curve there. I am confused about this, because of two reasons: Isn't the set of vectors tangent to a specific point (the ""tangent space"" at )? How can we have a curve there, especially a closed loop, like the cited answer suggests? If we can, how is this lift a vector field? Thanks for any help you can give, including any clarification of definitions I may be wrong about. Pictures are nice too since english isn't my second language, and I've already gone down the wrong road with some ideas in differential geometry because I had formed the wrong picture. Thank you!",X X \dot g = X(g) g \tilde g \in T_x M T_x M x x,['differential-geometry']
55,Pullback of a vector field under a surjective submersion.,Pullback of a vector field under a surjective submersion.,,"Let $\pi: M \rightarrow N$ be a smooth map. If we consider a vector field $Y$ on $N$ , I know that, if $\pi$ is a local diffeomorphism, there exists a unique vector field $X$ on $M$ such that $\pi_*X = Y$ . I was wondering if we can weaken this hypothesis: Is there a vector field $X$ with $\pi_*X = Y$ if $\pi$ is only surjective submersion, not a local diffeomorphism? It seems quite intuitive because for each $p$ , as $\pi_{*p}$ is surjective, there is at least one $X_p$ such that $\pi_{*p}X_p = Y(p)$ , but I have some difficulties to show that we can construct a smooth $X$ with $X_p = X(p)$ .","Let be a smooth map. If we consider a vector field on , I know that, if is a local diffeomorphism, there exists a unique vector field on such that . I was wondering if we can weaken this hypothesis: Is there a vector field with if is only surjective submersion, not a local diffeomorphism? It seems quite intuitive because for each , as is surjective, there is at least one such that , but I have some difficulties to show that we can construct a smooth with .",\pi: M \rightarrow N Y N \pi X M \pi_*X = Y X \pi_*X = Y \pi p \pi_{*p} X_p \pi_{*p}X_p = Y(p) X X_p = X(p),"['differential-geometry', 'vector-fields', 'pullback']"
56,Emedding of $\mathbb{ RP}^3$,Emedding of,\mathbb{ RP}^3,"Is there a simple formula for an embedding (homeomorphic onto its image) of $\mathbb{RP}^3$ in some Euclidean space? I have seen a simple formula for $\mathbb{RP}^2$ in $\mathbb R^4$ , but I can't find much of anything on $\mathbb{RP}^3$ . I am not asking for an immersion, but a true embedding.","Is there a simple formula for an embedding (homeomorphic onto its image) of in some Euclidean space? I have seen a simple formula for in , but I can't find much of anything on . I am not asking for an immersion, but a true embedding.",\mathbb{RP}^3 \mathbb{RP}^2 \mathbb R^4 \mathbb{RP}^3,"['differential-geometry', 'projective-space', 'submanifold']"
57,"Filling Riemannian manifolds, Gromov, Proposition 5.1.B","Filling Riemannian manifolds, Gromov, Proposition 5.1.B",,"In Gromovs paper Filling Riemannian manifolds, https://projecteuclid.org/download/pdf_1/euclid.jdg/1214509283 it states on page 46: 5.1.B Proposition Let $v$ be a surface with complete Finsler metric, fix a point $v\in V$ and let $R\in[\frac{1}{2}h(v),\frac{1}{2}Sys(V,v)]$ . Then \begin{equation} Area \ B(v,R) \ \geq \ \frac{1}{2}(2R-h(v)). \end{equation} Here $Sys(V,v)$ denotes the length of a shortest noncontractible loop based at $v$ and \begin{equation} h(v)=\inf\{tension(\gamma)|\gamma  \ \text{is either a noncontractible loop or an infinite path through  }v\}, \end{equation} where \begin{equation} tension(\gamma)=\sup\{\delta>0|\text{there is an homotopy from }\gamma \ \text{to } \overline{\gamma}, \text{s.t. } length(\overline{\gamma})=length(\gamma)-\delta\}. \end{equation} Now the proof works as follows: Suppose $R<\frac{1}{2}Sys(V,v)$ , then $B(v,R)$ is contractible. Thus for every connected component of its boundary $S_i\subset \partial B(v,R)$ , there is a surface $D_i$ homeomorphic to a disk, s.t. $\partial D_i=S_i$ . Denote by $B^+(v,R)$ the union of $B(v,r)$ with all the $D_i's$ . Let $\gamma$ be either a noncontractible loop or an infinite path through $v$ . Thus $\gamma$ intersects $\partial B^+(v,R)$ at least two times. Choose the first $x_1$ and the last $x_2$ of this interesections when walking along $\gamma$ . This divides $\partial B^+(v,R)$ in two parts $L_1,L_2$ with $l_1=length(L_1)\leq length(L_2)=l_2$ . Now $\gamma$ is homotopic to the loop $\gamma'$ obtained by the part of $\gamma$ between $x_1$ and $x_2$ union $L_1$ . Thus in particular \begin{equation} tension(\gamma)\geq 2R-l_1, \end{equation} Since $\gamma'$ is at least $2R-l_1$ shorter then $\gamma$ . Thus we get \begin{equation} tension(\gamma)\geq 2R-\frac{1}{2}length(\partial B^+(v,R)), \end{equation} which is equivalent to \begin{equation} length(\partial B^+(v,R))\geq 4R-2tension(\gamma). \end{equation} In the next line it says that we can thus say \begin{equation} length(\partial B^+(v,R))\geq 4R-2h(v). \end{equation} I don't see how this follows. Isn't by definition $h(v)\leq tension(\gamma)$ ? Thank you for any hint!","In Gromovs paper Filling Riemannian manifolds, https://projecteuclid.org/download/pdf_1/euclid.jdg/1214509283 it states on page 46: 5.1.B Proposition Let be a surface with complete Finsler metric, fix a point and let . Then Here denotes the length of a shortest noncontractible loop based at and where Now the proof works as follows: Suppose , then is contractible. Thus for every connected component of its boundary , there is a surface homeomorphic to a disk, s.t. . Denote by the union of with all the . Let be either a noncontractible loop or an infinite path through . Thus intersects at least two times. Choose the first and the last of this interesections when walking along . This divides in two parts with . Now is homotopic to the loop obtained by the part of between and union . Thus in particular Since is at least shorter then . Thus we get which is equivalent to In the next line it says that we can thus say I don't see how this follows. Isn't by definition ? Thank you for any hint!","v v\in V R\in[\frac{1}{2}h(v),\frac{1}{2}Sys(V,v)] \begin{equation}
Area \ B(v,R) \ \geq \ \frac{1}{2}(2R-h(v)).
\end{equation} Sys(V,v) v \begin{equation}
h(v)=\inf\{tension(\gamma)|\gamma  \ \text{is either a noncontractible loop or an infinite path through  }v\},
\end{equation} \begin{equation}
tension(\gamma)=\sup\{\delta>0|\text{there is an homotopy from }\gamma \ \text{to } \overline{\gamma}, \text{s.t. } length(\overline{\gamma})=length(\gamma)-\delta\}.
\end{equation} R<\frac{1}{2}Sys(V,v) B(v,R) S_i\subset \partial B(v,R) D_i \partial D_i=S_i B^+(v,R) B(v,r) D_i's \gamma v \gamma \partial B^+(v,R) x_1 x_2 \gamma \partial B^+(v,R) L_1,L_2 l_1=length(L_1)\leq length(L_2)=l_2 \gamma \gamma' \gamma x_1 x_2 L_1 \begin{equation}
tension(\gamma)\geq 2R-l_1,
\end{equation} \gamma' 2R-l_1 \gamma \begin{equation}
tension(\gamma)\geq 2R-\frac{1}{2}length(\partial B^+(v,R)),
\end{equation} \begin{equation}
length(\partial B^+(v,R))\geq 4R-2tension(\gamma).
\end{equation} \begin{equation}
length(\partial B^+(v,R))\geq 4R-2h(v).
\end{equation} h(v)\leq tension(\gamma)","['differential-geometry', 'riemannian-geometry']"
58,Show that sum of directional derivatives at a point on a manifold doesn't depend on the representation of the curve,Show that sum of directional derivatives at a point on a manifold doesn't depend on the representation of the curve,,"If $ v_1 , v_2 \in T_{p} \mathcal M$ . $p$ is a point on a manifold $\mathcal M$ ,( $p \in \mathcal M$ ), The tangent space $T_p \mathcal M$ is given a vector space structure by defining \begin{align} 	v_1 + v_2 := [\phi^{-1} \circ ( \phi \circ \sigma_1 + \phi \circ \sigma_1 )] \end{align} Here $\phi$ is the map that maps from the open set of $p \in \mathcal M$ to $\mathbb{R}^m$ . $\phi(0) = \mathbf{0}$ And $\sigma_1,\sigma_2 : (-\epsilon,\epsilon) \to \mathcal M$ are curves. Such that $v_1 = [\sigma_1]$ and $v_2 = [\sigma_2]$ I want to prove that this definition is independent of charts. To do that I use the definition of directional derivatives \begin{align} 	v(f) := \left. \frac{d(f\circ \sigma)}{dt}\right|_{t=0} = (f\circ \sigma)'(0) \quad v = [\sigma] \end{align} This is independet of the representation of $[\sigma]$ , (shown here ) I use chain rule as per the multi variable calculus Linearity of derivarives is also used This is my attempt of the proof \begin{align} 	(v_1 + v_2)(f) &= (f \circ \phi^{-1} \circ ( \phi \circ \sigma_1 + \phi \circ \sigma_2 ))'(0)  \tag{1}\label{1} \\ &=  (f \circ \phi^{-1} )'\left(( \phi \circ \sigma_1 + \phi \circ \sigma_2 )(0)\right)\circ( \phi \circ \sigma_1 + \phi \circ \sigma_1 )'(0) \tag{2}\label{2} \\ &=(f \circ \phi^{-1} )'\left(0\right)\circ( \phi \circ \sigma_1 + \phi \circ \sigma_2 )'(0) \tag{3}\label{3} \\ &=(f \circ \phi^{-1} )'\left(0\right)\circ( \phi \circ \sigma_1  )'(0) + (f \circ \phi^{-1} )'\left(0\right)\circ(\phi \circ \sigma_2 )'(0)  \tag{4}\label{4} \\ &=(f \circ\sigma_1  )'(0) +(f \circ\sigma_2 )'(0)   \tag{5}\label{5} \\ &= v_1(f) + v_2(f)\tag{6}\label{6} \end{align} Writing the directional derivative along $ v_1 + v_2$ Using the chain rule $(f \circ g )'(x) = f'(g(x))\circ g'(x)$ Using , $ \sigma_1(0) = \sigma_2(0) = p$ , and $\phi(p) = \mathbf 0$ Using the linearity of derivatives $ f'(0)\circ (g_1 + g_2)(0) = f'(0) \circ g_1(0) + f'(0) \circ g_2(0)$ Reverse usage of chain rule and replacing $\phi^{-1} \circ \phi$ as $1$ Recognizing the forms of directional derivatives In the last step, each term in the expression is independent of the representation of the curve and also independent of the charts around $p \in \mathcal M$ for any arbitrary $f \in C^{\infty} (\mathcal M)$ , so $v_1 + v_2$ doesn't depend on the representation of the curves $\sigma_1$ or $\sigma_2$ , any representation from $[\sigma_1]$ or $[\sigma_2]$ will work. $$\tag*{$\blacksquare$}$$ Is this the right way of doing it? I am unsure about the linearity of the derivative \eqref{4}. P.S: This proof is essential to show that the tangent space is a vector space. I am following this book, Isham, Chris J. , Modern differential geometry for physicists., World Scientific Lecture Notes in Physics. 61. Singapore: World Scientific. xiii, 289 p. (1999). ZBL0931.53002 .","If . is a point on a manifold ,( ), The tangent space is given a vector space structure by defining Here is the map that maps from the open set of to . And are curves. Such that and I want to prove that this definition is independent of charts. To do that I use the definition of directional derivatives This is independet of the representation of , (shown here ) I use chain rule as per the multi variable calculus Linearity of derivarives is also used This is my attempt of the proof Writing the directional derivative along Using the chain rule Using , , and Using the linearity of derivatives Reverse usage of chain rule and replacing as Recognizing the forms of directional derivatives In the last step, each term in the expression is independent of the representation of the curve and also independent of the charts around for any arbitrary , so doesn't depend on the representation of the curves or , any representation from or will work. Is this the right way of doing it? I am unsure about the linearity of the derivative \eqref{4}. P.S: This proof is essential to show that the tangent space is a vector space. I am following this book, Isham, Chris J. , Modern differential geometry for physicists., World Scientific Lecture Notes in Physics. 61. Singapore: World Scientific. xiii, 289 p. (1999). ZBL0931.53002 ."," v_1 , v_2 \in T_{p} \mathcal M p \mathcal M p \in \mathcal M T_p \mathcal M \begin{align}
	v_1 + v_2 := [\phi^{-1} \circ ( \phi \circ \sigma_1 + \phi \circ \sigma_1 )]
\end{align} \phi p \in \mathcal M \mathbb{R}^m \phi(0) = \mathbf{0} \sigma_1,\sigma_2 : (-\epsilon,\epsilon) \to \mathcal M v_1 = [\sigma_1] v_2 = [\sigma_2] \begin{align}
	v(f) := \left. \frac{d(f\circ \sigma)}{dt}\right|_{t=0} = (f\circ \sigma)'(0) \quad v = [\sigma]
\end{align} [\sigma] \begin{align}
	(v_1 + v_2)(f) &= (f \circ \phi^{-1} \circ ( \phi \circ \sigma_1 + \phi \circ \sigma_2 ))'(0) 
\tag{1}\label{1} \\
&=  (f \circ \phi^{-1} )'\left(( \phi \circ \sigma_1 + \phi \circ \sigma_2 )(0)\right)\circ( \phi \circ \sigma_1 + \phi \circ \sigma_1 )'(0) \tag{2}\label{2} \\
&=(f \circ \phi^{-1} )'\left(0\right)\circ( \phi \circ \sigma_1 + \phi \circ \sigma_2 )'(0) \tag{3}\label{3} \\
&=(f \circ \phi^{-1} )'\left(0\right)\circ( \phi \circ \sigma_1  )'(0) +
(f \circ \phi^{-1} )'\left(0\right)\circ(\phi \circ \sigma_2 )'(0)  \tag{4}\label{4}
\\
&=(f \circ\sigma_1  )'(0) +(f \circ\sigma_2 )'(0)   \tag{5}\label{5}
\\
&= v_1(f) + v_2(f)\tag{6}\label{6}
\end{align}  v_1 + v_2 (f \circ g )'(x) = f'(g(x))\circ g'(x)  \sigma_1(0) = \sigma_2(0) = p \phi(p) = \mathbf 0  f'(0)\circ (g_1 + g_2)(0) = f'(0) \circ g_1(0) + f'(0) \circ g_2(0) \phi^{-1} \circ \phi 1 p \in \mathcal M f \in C^{\infty} (\mathcal M) v_1 + v_2 \sigma_1 \sigma_2 [\sigma_1] [\sigma_2] \tag*{\blacksquare}","['differential-geometry', 'manifolds']"
59,Why are effective divisors on $\mathbb{P}^n$ positive?,Why are effective divisors on  positive?,\mathbb{P}^n,"I'm reading Griffiths and Harris, Principles of algebraic geometry , and it's written that ""any effective nonzero divisor on $\mathbb{P}^n$ is positive"" on page 159. Is that obvious? There doesn't seem to be any explanation in the book. Here, a divisor is called positive if the associated line bundle has a hermitian metric whose curvature form is positive. I know that hyperplane divisors are positive since they induce the Fubini-Study metric, but I'm not sure how to deal with a general irreducible hypersurface.","I'm reading Griffiths and Harris, Principles of algebraic geometry , and it's written that ""any effective nonzero divisor on is positive"" on page 159. Is that obvious? There doesn't seem to be any explanation in the book. Here, a divisor is called positive if the associated line bundle has a hermitian metric whose curvature form is positive. I know that hyperplane divisors are positive since they induce the Fubini-Study metric, but I'm not sure how to deal with a general irreducible hypersurface.",\mathbb{P}^n,"['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'divisors-algebraic-geometry']"
60,Every holomorphic function on a compact complex manifold is locally constant？,Every holomorphic function on a compact complex manifold is locally constant？,,"We know that if $X$ is a compact connected complex manifold,then every holomorphic function on $X$ is constant. Now,supposed that $X$ is not necessarily connect, then we can choose a connected component. We know that connected component is closed subset and every closed subset of a compact set is also compact. So the connected component is also compact, then we can deduced that every holomorphic function on the connected component is constant. Then We can deduced that every holomorphic function on $X$ is locally constant. I think this may be not right but I can't find where is the problem in my proof in the above.","We know that if is a compact connected complex manifold,then every holomorphic function on is constant. Now,supposed that is not necessarily connect, then we can choose a connected component. We know that connected component is closed subset and every closed subset of a compact set is also compact. So the connected component is also compact, then we can deduced that every holomorphic function on the connected component is constant. Then We can deduced that every holomorphic function on is locally constant. I think this may be not right but I can't find where is the problem in my proof in the above.",X X X X,"['differential-geometry', 'complex-geometry', 'complex-manifolds']"
61,Can I understand $1$-form this way?,Can I understand -form this way?,1,"It's said a function $f$ on $M$ is a $0$ -form; I think an example of one form is $df=\frac{\partial f}{\partial x_1}dx^1+\dots+\frac{\partial f}{\partial dx^n}dx^n$ , where $(x,U)$ is the local coordinate system, $dx_i$ is basis for tangent space $M_p$ of a manifold $M$ at p, $dx^i$ is dual basis for dual space ${M_p}^*$ . (There may be something that goes wrong here, because when I read the book I am often not sure if the author is refering to vector/basis or dual vector/basis.) Since $dx^i$ is first order tensor, so it's function of a vector, and therefore so is $df$ . When $df$ acts on one-cube or other 1-dim object, say a vector $v$ , we get $df(v)=df=\frac{\partial f}{\partial x_1}dx^1(v)+\dots+\frac{\partial f}{\partial dx^n}dx^n(v)$ which is a number (or  it is a number only when $f$ maps $M$ to $\mathbb{R}$ or $\mathbb{C}$ and so each partical derivative is a number?). And so $df$ is actually a one-tensor, and a measure function giving a 'length' of a vector. We can further simplify the example, for example, let $f$ be the indentity map of $M$ , then $df$ is also identity map of the tangent bundle $TM$ . Then $df(v)=v$ , which means $df$ is not 1-tensor or measure function. Seems to contradict my  thought above. (But if we let $f$ be a function mapping points on $M$ to numbers, then $df(v)$ gives a number. So does $0$ -form $f$ have to be such?) Then what's 1-form? Would anyone give an illuminating example? (Since $k$ -form is related to wedge product, the topic discussed here is related to my another post Is wedge product of n-dimension the length/area/volume,... of an oriented set of n vectors? , which contains a bit of discussion as well.) It is said $k$ -form is alternating covariant tensor field (alternating covariant vector field when k=1), which means it is a section of a subset $\Omega^k(TM)$ of k-fold covariant tensor field $\mathcal{T}^k(TM)$ . $\mathcal{T}^k(TM)$ is a collection of functions $T:TM\times\dots\times TM\rightarrow \mathbb{R}$ . So k-form should be at each point we have products of k 1-tensor, i.e. { $v_{1,p}*\otimes...\otimes v_{k,p}*, p\in M,$ and $v_{i,p}\in M_p$ , i.e. is a tangent vector at $p$ }. So perhaps we can roughly think that given k vector fields, changing every tangent vector to its dual vector, then we get a k-form. And it will act on k tangent vectors at one point, e.g. { $dx_{i,p}$ , $1\leq i\leq k$ }, a subset of the basis of $(x,U)$ where U is a neighborhood of $p$ . Now it seems safe to say $df$ as one tensor can't be identity map of the tangent bundle $TM$ . But still, how should we understand 1-form? (Edited to add:) So 1-form $\omega$ (if exact, = $d\eta$ , where $\eta:M\rightarrow \mathbb{R}^1$ ) is almost completely an analog of $df$ for $f:\mathbb{R}^n\rightarrow :\mathbb{R}^1$ . (It and its integration are more general than a measure function of length, volume, etc.) It's related to tensor because tensor is a linear function (to one dimensional space, whatever the order of tensor!) of several tangent vector (an analog of $dx$ ). So a 1-tensor is linear operator on vector(s), i.e. a $1\times n$ matrix (a transposed vector). It's therefore natural to think of k-tensor as a candidate of first order (linear approximation of) change of a function mapping vector(s) to $\mathbb{R}$ . Considering its variables, 1-form is function of point of $M$ (so is $df$ ), an analog to the f'(x) part (when n=1) or linear operator (matrix) $A$ part of $df$ , both parts being function of $x$ in n-dim Euclidean space domain. 1-form is also a (linear) function of tangent vector, WHEN the point variable is fixed, an analog to ' $\dot \ dx$ ' (dx as scalar or vector) part of $df$ , indicating $df$ being linear transformation (i.e. matrix or having a matrix representation) of or proportional to $dx$ ; however, this fact looks so trivial in the usual calculus that I ignore it. Combining this two facts, we can say 1-form is like a  (variable) matrix (probably named Jacobian matrix) ACTING on 1 vector, whose entries vary with the point variable. In other words, we can say it is, in the usual calculus, similar to case of differential forms on manifold (1-forms is the derivative of a function between two manifolds (one is $\mathbb{R}^1$ ), and so maps a tangent vector to a tangent vector $\in T\mathbb{R}^1$ ), more comprehensive to understand differential of $f$ as $df$ , rather than $f'(x)$ (when n=1) or as matrix $A$ alone (which easily causes us to think $dx$ is not part of but outside the derivative, as we do in writing $\int f'dx$ and 1-order part of function expansion $f'(x)(x'-x)$ , and find the two are the same linear approx of difference.). And we can show the relation better by writing $df$ as $df_x(dx)$ where x and dx are completely independent (except that dx is at x), $df_x$ (x fixed) being a linear transformation ( $t\rightarrow kt, t\rightarrow At$ ). Comparing $df_x(dx)$ with the notation in diff geom, $\omega_{*p}(v)$ or $\omega_*(v_p)$ , we see  the latter can really be understood as at first a function of p, and then when p is fixed, a function of (tangent) vector, i.e. of a linear approximation of displacement of point in $M$ ; or reversely we can understand $df$ directly as a function a $dx_x$ . Another change caused by such an switch from $df$ to 1-form perspective is that now we regard integral as (the limit of) sum of value of 1-form $\omega_{p_r}(v)$ or $df_{x_r}(dx)$ at several $p_r$ or $x_r$ , that is, the linear or 1-st order approximation of change in $\eta$ (the function whose derivative in manifold sense is $\omega$ , if $\omega$ is exact) or $f$ , instead of regarding integral as sum of area; since we can more conveniently obtain it given small displacement at $\omega_{p_r}(v)$ or $df_{x_r}(dx)$ . Note this perspective is different from the fundamental law of calculus as it still involves sum of infinite segmentation. We can also see $\eta$ and $f$ as scalar field on a manifold or Euclidean space. With the new integration perspective and scalar field perspective, now we can look into, for example, length integration $L_\gamma$ of a curve in $\mathbb{R}^3$ . We need to place the curve on a surface $M$ (to illustrate the vector basis' and dual basis' role; note that if we set the basis to be of 2-dim space, we have to do so). Then we can find the 1-form $\omega: \gamma'dt \mapsto \sqrt{\langle \gamma', \gamma'\rangle}dt$ , i.e. $d\gamma \mapsto \sqrt{\langle d\gamma, d\gamma\rangle},\ TM\rightarrow T\mathbb{R}$ , which is the derivative of $\eta:\gamma\mapsto {L_{\gamma(\tau)}}|_0^t,\ M\rightarrow \mathbb{R}$ . (The expression of $\eta$ as function of an element $\in M-\gamma$ remain undefined.) let $\gamma=\{(x, f(x)), f:\mathbb{R}^2\rightarrow\mathbb{R}\}$ , we can find the 1-form $df: ({x^1}'(t), {x^2}'(t))dt\mapsto \frac{df}{dt}dt$ , i.e. $dx\mapsto df(x), T\mathbb{R}^2\rightarrow T\mathbb{R}$ , where $$\frac{df}{dt}dt=\frac{\partial f}{\partial {x^1}}{x^1}'(t)dt+\frac{\partial f}{\partial {x^2}}{x^2}'(t)dt=\frac{df}{dt}dt=\frac{\partial f}{\partial {x^1}}d{x^1}+\frac{\partial f}{\partial {x^2}}d{x^2}.$$ We can find another one form $dg: dx\mapsto \sqrt{(df(x))^2+(dx)^2}, T\mathbb{R}^2\rightarrow T\mathbb{R}$ , (here the square is norm's square). which is the derivative of $g: x\mapsto \int_0^t \sqrt{(df(x(\tau)))^2+(dx(\tau))^2}, \ \mathbb{R}^2\rightarrow\mathbb{R}$ , where $$\int_0^t \sqrt{(df(x(\tau)))^2+(dx(\tau))^2}=\int_0^t \sqrt{(\frac{\partial f}{\partial {x^1}}{x^1}'(\tau)d\tau+\frac{\partial f}{\partial {x^2}}{x^2}'(\tau)d\tau)^2+({x^1}'(\tau), {x^2}'(\tau))d\tau)^2}={L_{\gamma(\tau)}}|_0^t.$$ (The expression of $g$ as function of an element $\in \mathbb{R}^2-\{x|\ (x,f(x))\in \gamma\}$ remain undefined.) So we have two 'measure' functions $\eta, \ g$ for curve length with different domain, whose derivatives are 1-forms. New question : It seems there is an error: though $dg$ is 'integrable', it seems not to be a linear function of the vector ( $dx^1, dx^2$ ), for the sum under $\sqrt{}$ has $\Delta=-4(f_{x_1}^2+f_{x_2}^2+1)\neq 0$ . This state of 'being not 1-form but still integrable' seems weird. Is that common?","It's said a function on is a -form; I think an example of one form is , where is the local coordinate system, is basis for tangent space of a manifold at p, is dual basis for dual space . (There may be something that goes wrong here, because when I read the book I am often not sure if the author is refering to vector/basis or dual vector/basis.) Since is first order tensor, so it's function of a vector, and therefore so is . When acts on one-cube or other 1-dim object, say a vector , we get which is a number (or  it is a number only when maps to or and so each partical derivative is a number?). And so is actually a one-tensor, and a measure function giving a 'length' of a vector. We can further simplify the example, for example, let be the indentity map of , then is also identity map of the tangent bundle . Then , which means is not 1-tensor or measure function. Seems to contradict my  thought above. (But if we let be a function mapping points on to numbers, then gives a number. So does -form have to be such?) Then what's 1-form? Would anyone give an illuminating example? (Since -form is related to wedge product, the topic discussed here is related to my another post Is wedge product of n-dimension the length/area/volume,... of an oriented set of n vectors? , which contains a bit of discussion as well.) It is said -form is alternating covariant tensor field (alternating covariant vector field when k=1), which means it is a section of a subset of k-fold covariant tensor field . is a collection of functions . So k-form should be at each point we have products of k 1-tensor, i.e. { and , i.e. is a tangent vector at }. So perhaps we can roughly think that given k vector fields, changing every tangent vector to its dual vector, then we get a k-form. And it will act on k tangent vectors at one point, e.g. { , }, a subset of the basis of where U is a neighborhood of . Now it seems safe to say as one tensor can't be identity map of the tangent bundle . But still, how should we understand 1-form? (Edited to add:) So 1-form (if exact, = , where ) is almost completely an analog of for . (It and its integration are more general than a measure function of length, volume, etc.) It's related to tensor because tensor is a linear function (to one dimensional space, whatever the order of tensor!) of several tangent vector (an analog of ). So a 1-tensor is linear operator on vector(s), i.e. a matrix (a transposed vector). It's therefore natural to think of k-tensor as a candidate of first order (linear approximation of) change of a function mapping vector(s) to . Considering its variables, 1-form is function of point of (so is ), an analog to the f'(x) part (when n=1) or linear operator (matrix) part of , both parts being function of in n-dim Euclidean space domain. 1-form is also a (linear) function of tangent vector, WHEN the point variable is fixed, an analog to ' ' (dx as scalar or vector) part of , indicating being linear transformation (i.e. matrix or having a matrix representation) of or proportional to ; however, this fact looks so trivial in the usual calculus that I ignore it. Combining this two facts, we can say 1-form is like a  (variable) matrix (probably named Jacobian matrix) ACTING on 1 vector, whose entries vary with the point variable. In other words, we can say it is, in the usual calculus, similar to case of differential forms on manifold (1-forms is the derivative of a function between two manifolds (one is ), and so maps a tangent vector to a tangent vector ), more comprehensive to understand differential of as , rather than (when n=1) or as matrix alone (which easily causes us to think is not part of but outside the derivative, as we do in writing and 1-order part of function expansion , and find the two are the same linear approx of difference.). And we can show the relation better by writing as where x and dx are completely independent (except that dx is at x), (x fixed) being a linear transformation ( ). Comparing with the notation in diff geom, or , we see  the latter can really be understood as at first a function of p, and then when p is fixed, a function of (tangent) vector, i.e. of a linear approximation of displacement of point in ; or reversely we can understand directly as a function a . Another change caused by such an switch from to 1-form perspective is that now we regard integral as (the limit of) sum of value of 1-form or at several or , that is, the linear or 1-st order approximation of change in (the function whose derivative in manifold sense is , if is exact) or , instead of regarding integral as sum of area; since we can more conveniently obtain it given small displacement at or . Note this perspective is different from the fundamental law of calculus as it still involves sum of infinite segmentation. We can also see and as scalar field on a manifold or Euclidean space. With the new integration perspective and scalar field perspective, now we can look into, for example, length integration of a curve in . We need to place the curve on a surface (to illustrate the vector basis' and dual basis' role; note that if we set the basis to be of 2-dim space, we have to do so). Then we can find the 1-form , i.e. , which is the derivative of . (The expression of as function of an element remain undefined.) let , we can find the 1-form , i.e. , where We can find another one form , (here the square is norm's square). which is the derivative of , where (The expression of as function of an element remain undefined.) So we have two 'measure' functions for curve length with different domain, whose derivatives are 1-forms. New question : It seems there is an error: though is 'integrable', it seems not to be a linear function of the vector ( ), for the sum under has . This state of 'being not 1-form but still integrable' seems weird. Is that common?","f M 0 df=\frac{\partial f}{\partial x_1}dx^1+\dots+\frac{\partial f}{\partial dx^n}dx^n (x,U) dx_i M_p M dx^i {M_p}^* dx^i df df v df(v)=df=\frac{\partial f}{\partial x_1}dx^1(v)+\dots+\frac{\partial f}{\partial dx^n}dx^n(v) f M \mathbb{R} \mathbb{C} df f M df TM df(v)=v df f M df(v) 0 f k k \Omega^k(TM) \mathcal{T}^k(TM) \mathcal{T}^k(TM) T:TM\times\dots\times TM\rightarrow \mathbb{R} v_{1,p}*\otimes...\otimes v_{k,p}*, p\in M, v_{i,p}\in M_p p dx_{i,p} 1\leq i\leq k (x,U) p df TM \omega d\eta \eta:M\rightarrow \mathbb{R}^1 df f:\mathbb{R}^n\rightarrow :\mathbb{R}^1 dx 1\times n \mathbb{R} M df A df x \dot \ dx df df dx \mathbb{R}^1 \in T\mathbb{R}^1 f df f'(x) A dx \int f'dx f'(x)(x'-x) df df_x(dx) df_x t\rightarrow kt, t\rightarrow At df_x(dx) \omega_{*p}(v) \omega_*(v_p) M df dx_x df \omega_{p_r}(v) df_{x_r}(dx) p_r x_r \eta \omega \omega f \omega_{p_r}(v) df_{x_r}(dx) \eta f L_\gamma \mathbb{R}^3 M \omega: \gamma'dt \mapsto \sqrt{\langle \gamma', \gamma'\rangle}dt d\gamma \mapsto \sqrt{\langle d\gamma, d\gamma\rangle},\ TM\rightarrow T\mathbb{R} \eta:\gamma\mapsto {L_{\gamma(\tau)}}|_0^t,\ M\rightarrow \mathbb{R} \eta \in M-\gamma \gamma=\{(x, f(x)), f:\mathbb{R}^2\rightarrow\mathbb{R}\} df: ({x^1}'(t), {x^2}'(t))dt\mapsto \frac{df}{dt}dt dx\mapsto df(x), T\mathbb{R}^2\rightarrow T\mathbb{R} \frac{df}{dt}dt=\frac{\partial f}{\partial {x^1}}{x^1}'(t)dt+\frac{\partial f}{\partial {x^2}}{x^2}'(t)dt=\frac{df}{dt}dt=\frac{\partial f}{\partial {x^1}}d{x^1}+\frac{\partial f}{\partial {x^2}}d{x^2}. dg: dx\mapsto \sqrt{(df(x))^2+(dx)^2}, T\mathbb{R}^2\rightarrow T\mathbb{R} g: x\mapsto \int_0^t \sqrt{(df(x(\tau)))^2+(dx(\tau))^2}, \ \mathbb{R}^2\rightarrow\mathbb{R} \int_0^t \sqrt{(df(x(\tau)))^2+(dx(\tau))^2}=\int_0^t \sqrt{(\frac{\partial f}{\partial {x^1}}{x^1}'(\tau)d\tau+\frac{\partial f}{\partial {x^2}}{x^2}'(\tau)d\tau)^2+({x^1}'(\tau), {x^2}'(\tau))d\tau)^2}={L_{\gamma(\tau)}}|_0^t. g \in \mathbb{R}^2-\{x|\ (x,f(x))\in \gamma\} \eta, \ g dg dx^1, dx^2 \sqrt{} \Delta=-4(f_{x_1}^2+f_{x_2}^2+1)\neq 0","['differential-geometry', 'differential-forms']"
62,Can the Killing form induce an endomorphism in a Lie algebra?,Can the Killing form induce an endomorphism in a Lie algebra?,,"Let $\mathfrak{g}$ be a Lie algebra over $\mathbb{R}$ of the finite dimensional Lie group $G$ ; let $\langle \cdot , \cdot \rangle$ be a left-invariant Riemannian metric on $G$ . If $B:\mathfrak{g}\times \mathfrak{g}\to \mathbb{R}$ is the Cartan-Killing form $(X,Y)\mapsto \text{Tr}( \text{ ad}_X \circ \text{ad}_Y)$ . Is it true that there is a symmetric endomorphism $\phi$ on $\mathfrak{g}$ such that for every $X\in \mathfrak{g}$ we have $\langle X,X \rangle=B(\phi(X),X)$ ?.",Let be a Lie algebra over of the finite dimensional Lie group ; let be a left-invariant Riemannian metric on . If is the Cartan-Killing form . Is it true that there is a symmetric endomorphism on such that for every we have ?.,"\mathfrak{g} \mathbb{R} G \langle \cdot , \cdot \rangle G B:\mathfrak{g}\times \mathfrak{g}\to \mathbb{R} (X,Y)\mapsto \text{Tr}( \text{ ad}_X \circ \text{ad}_Y) \phi \mathfrak{g} X\in \mathfrak{g} \langle X,X \rangle=B(\phi(X),X)","['differential-geometry', 'lie-groups', 'lie-algebras']"
63,Wrong proof of $TM$ is diffeomorphic to $M\times \mathbb{R^m}$,Wrong proof of  is diffeomorphic to,TM M\times \mathbb{R^m},"I want to see what's wrong in here: Let $M$ be a smooth manifold with dimension $m$ . I will show $TM$ is diffeomorphic to $M\times \mathbb{R^m}$ . proof ) Define $F:TM\rightarrow M\times \mathbb{R^m}$ by $F(p,v)=(p,v^1,...,v^m)$ where $v=v^i\frac{\partial}{\partial x^i}\in T_pM$ . Let $(U,\phi)$ be a chart containing $p$ . Then, $(\pi^{-1}(U),\widetilde{\phi})$ is a chart containing $(p,v)$ where $\pi:TM\rightarrow M$ given by $\pi(p,v)=p$ and $\widetilde{\phi}(p,v)=(\phi(p),v^1,...,v^m)$ . And $(U\times \mathbb{R^m},\phi \times Id)$ is a chart containing $F(p,v)$ . Using above, $(\phi\times Id)\circ F\circ \widetilde{\phi}^{-1}:\widetilde{\phi} (\pi^{-1}(U))\rightarrow \phi(U)\times \mathbb{R^m}$ is an identity map (Note that $\widetilde{\phi} (\pi^{-1}(U))$ is $\phi(U)\times \mathbb{R^m}$ by calculation.). Thus $F$ is smooth. $F^{-1}:M\times \mathbb{R^m}\rightarrow TM$ is given by $F^{-1}(p,v^1,...,v^m)=(p,v)$ where $v=v^i\frac{\partial}{\partial x^i}\in T_pM$ . With above charts, we have $\widetilde{\phi}\circ F^{-1}\circ (\phi\times Id)^{-1}:\phi(U)\times \mathbb{R^m}\rightarrow \widetilde{\phi}(\pi^{-1}(U))$ is also identity map. Thus $F^{-1}$ is smooth. $\blacksquare$ But I know $TM$ may not diffeomorphic to $M\times \mathbb{R^m}$ . What's wrong in my proof?","I want to see what's wrong in here: Let be a smooth manifold with dimension . I will show is diffeomorphic to . proof ) Define by where . Let be a chart containing . Then, is a chart containing where given by and . And is a chart containing . Using above, is an identity map (Note that is by calculation.). Thus is smooth. is given by where . With above charts, we have is also identity map. Thus is smooth. But I know may not diffeomorphic to . What's wrong in my proof?","M m TM M\times \mathbb{R^m} F:TM\rightarrow M\times \mathbb{R^m} F(p,v)=(p,v^1,...,v^m) v=v^i\frac{\partial}{\partial x^i}\in T_pM (U,\phi) p (\pi^{-1}(U),\widetilde{\phi}) (p,v) \pi:TM\rightarrow M \pi(p,v)=p \widetilde{\phi}(p,v)=(\phi(p),v^1,...,v^m) (U\times \mathbb{R^m},\phi \times Id) F(p,v) (\phi\times Id)\circ F\circ \widetilde{\phi}^{-1}:\widetilde{\phi} (\pi^{-1}(U))\rightarrow \phi(U)\times \mathbb{R^m} \widetilde{\phi} (\pi^{-1}(U)) \phi(U)\times \mathbb{R^m} F F^{-1}:M\times \mathbb{R^m}\rightarrow TM F^{-1}(p,v^1,...,v^m)=(p,v) v=v^i\frac{\partial}{\partial x^i}\in T_pM \widetilde{\phi}\circ F^{-1}\circ (\phi\times Id)^{-1}:\phi(U)\times \mathbb{R^m}\rightarrow \widetilde{\phi}(\pi^{-1}(U)) F^{-1} \blacksquare TM M\times \mathbb{R^m}","['differential-geometry', 'smooth-manifolds']"
64,Sign of $df_x$ is locally constant,Sign of  is locally constant,df_x,"This question is about the book Topology from the Differentiable Viewpoint of Milnor. Let $M$ and $N$ be oriented $n$ -manifolds without boundary, and assume $M$ is compact and $N$ is connected. Let $x\in M$ be a regular point of $f$ , so that $df_X:TM_x\to TN_{f(x)}$ is a vector space isomorphism. Define the sign of $df_x$ to be $+1$ or $-1$ according as $df_x$ preserves or reverses orientation. How can we show that the sign of $df_x$ is locally constant function of $x$ ? Since $M$ is oriented, $x$ has a neighborhood $U$ and a diffeomorphism $h$ of $U$ onto an open subset $V$ of $\Bbb R^n$ which is orientation preserving, in the sense that for each $y\in U$ the isomorphism $dh_y$ carries the specified orientation of $TM_y$ to the standard orientation of $\Bbb R^n=TV_{h(y)}$ . I think I should use this fact, but I can't see how does this imply that the sign of $df_x$ is constant in a neighborhood of $x$ .","This question is about the book Topology from the Differentiable Viewpoint of Milnor. Let and be oriented -manifolds without boundary, and assume is compact and is connected. Let be a regular point of , so that is a vector space isomorphism. Define the sign of to be or according as preserves or reverses orientation. How can we show that the sign of is locally constant function of ? Since is oriented, has a neighborhood and a diffeomorphism of onto an open subset of which is orientation preserving, in the sense that for each the isomorphism carries the specified orientation of to the standard orientation of . I think I should use this fact, but I can't see how does this imply that the sign of is constant in a neighborhood of .",M N n M N x\in M f df_X:TM_x\to TN_{f(x)} df_x +1 -1 df_x df_x x M x U h U V \Bbb R^n y\in U dh_y TM_y \Bbb R^n=TV_{h(y)} df_x x,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'orientation', 'smooth-functions']"
65,Existence of a Parallel Orthonormal Frame Implies Manifold is Flat?,Existence of a Parallel Orthonormal Frame Implies Manifold is Flat?,,"Suppose that $M$ is a Riemannian manifold with Levi-Cevita connection, $\nabla$ and a parallel global orthonormal frame $\{X_1,\ldots,X_n\}$ . This seems to imply that the Riemannian curvature endomorphism, $R(X_i,X_j)X_k$ vanishes by simple reasoning that $\nabla_{X_i}\nabla_{X_j}X_k = 0$ as the frame is parallel and similarly $\nabla_{[X_i,X_j]}X_k = 0$ . By linearity of the curvature endomorphism and the fact that the $X_i$ 's form a frame this implies the curvature endomorphism vanishes on all of $M$ . On the other hand, a Lie group with a bi-invariant metric exhibits such an orthonormal frame by pushing forward an orthonormal basis by left-multiplication. This resulting orthonormal frame, $\{X_1,\ldots,X_n\}$ , appears to be parallel since the connection defined by $\nabla_{Y}(a^iX_i) = Y(a^i)X_i$ ( $a^i$ are smooth component functions) by a quick calculation looks to be g-compatible and torsion free so that $\nabla X_i = 0$ ? As Lie groups under bi-invariant metrics can have positive sectional curvature this contradicts the reasoning in the previous paragraph. A second reformulation of the question is that symmetry of the connection and parallelism implies that $0 = \nabla_{X_i}X_j - \nabla_{X_j}X_i = [X_i,X_j]$ . The vanishing of these Lie brackets then implies that there exist global coordinates of $M$ , $x^i$ , whose coordinate vector fields are the orthonormal $X_i$ 's which again further implies the metric is flat. My guess is that having a parallel frame doesn't imply a manifold is flat but a parallel ON frame does. One cannot use Gram-Schmidt on a parallel non-ON frame to get an orthonormal one as this ruins the parallelism. The question remains as to why the Lie group example is not flat in general; are the left invariant vector fields provided not actually parallel? Thanks for your help.","Suppose that is a Riemannian manifold with Levi-Cevita connection, and a parallel global orthonormal frame . This seems to imply that the Riemannian curvature endomorphism, vanishes by simple reasoning that as the frame is parallel and similarly . By linearity of the curvature endomorphism and the fact that the 's form a frame this implies the curvature endomorphism vanishes on all of . On the other hand, a Lie group with a bi-invariant metric exhibits such an orthonormal frame by pushing forward an orthonormal basis by left-multiplication. This resulting orthonormal frame, , appears to be parallel since the connection defined by ( are smooth component functions) by a quick calculation looks to be g-compatible and torsion free so that ? As Lie groups under bi-invariant metrics can have positive sectional curvature this contradicts the reasoning in the previous paragraph. A second reformulation of the question is that symmetry of the connection and parallelism implies that . The vanishing of these Lie brackets then implies that there exist global coordinates of , , whose coordinate vector fields are the orthonormal 's which again further implies the metric is flat. My guess is that having a parallel frame doesn't imply a manifold is flat but a parallel ON frame does. One cannot use Gram-Schmidt on a parallel non-ON frame to get an orthonormal one as this ruins the parallelism. The question remains as to why the Lie group example is not flat in general; are the left invariant vector fields provided not actually parallel? Thanks for your help.","M \nabla \{X_1,\ldots,X_n\} R(X_i,X_j)X_k \nabla_{X_i}\nabla_{X_j}X_k = 0 \nabla_{[X_i,X_j]}X_k = 0 X_i M \{X_1,\ldots,X_n\} \nabla_{Y}(a^iX_i) = Y(a^i)X_i a^i \nabla X_i = 0 0 = \nabla_{X_i}X_j - \nabla_{X_j}X_i = [X_i,X_j] M x^i X_i","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'smooth-manifolds']"
66,Problem understanding invariant subspaces and foliations,Problem understanding invariant subspaces and foliations,,"I am studying control theory and I am starting the concept of geometric control theory. As a prerequisite to this, I am studying the concet of invariant subspaces, and I having some troubles understanding some concepts. To try to understand my doubts I think I have to start from the beginning, but please correct me if I say something wrong. So, $V$ is an invariant subspace under $A$ if: $AV\subset V$ and in this context, we can find a coordinate transformation such that : $TAT^{-1}=\begin{pmatrix} A_{11} &A_{12} \\  0 & A_{22} \end{pmatrix}$ at this point the notes of my professor say that this implies that the invariant subspace is an eigenspace (but I don't understand why). And so this should implies that the evolutions that start in $V$ remains in $V$ , and this can be seen from the system in the new coordinates: $\dot{z_1}=A_{11}z_1 + A_{12}z_2+B_1u$ $\dot{z_2}=A_{22}z_2+B_2u$ Moreover, it says that if I consider two generic initial conditions whose difference belong to $V$ , their evolution remain if an affine variety of the same class (these last few are the literal words in my note, which I don't understand).  And it says that the structure induced by translation from $V$ is called foliation . I am very confused from this arguments, especially I cannot understand the concept of foliation. To give more context, I am studying this in order to arrive to characterize the reachability and observability in control theory, but don't know if it matters. Can somebody please help me make clarity?","I am studying control theory and I am starting the concept of geometric control theory. As a prerequisite to this, I am studying the concet of invariant subspaces, and I having some troubles understanding some concepts. To try to understand my doubts I think I have to start from the beginning, but please correct me if I say something wrong. So, is an invariant subspace under if: and in this context, we can find a coordinate transformation such that : at this point the notes of my professor say that this implies that the invariant subspace is an eigenspace (but I don't understand why). And so this should implies that the evolutions that start in remains in , and this can be seen from the system in the new coordinates: Moreover, it says that if I consider two generic initial conditions whose difference belong to , their evolution remain if an affine variety of the same class (these last few are the literal words in my note, which I don't understand).  And it says that the structure induced by translation from is called foliation . I am very confused from this arguments, especially I cannot understand the concept of foliation. To give more context, I am studying this in order to arrive to characterize the reachability and observability in control theory, but don't know if it matters. Can somebody please help me make clarity?","V A AV\subset V TAT^{-1}=\begin{pmatrix}
A_{11} &A_{12} \\ 
0 & A_{22}
\end{pmatrix} V V \dot{z_1}=A_{11}z_1 + A_{12}z_2+B_1u \dot{z_2}=A_{22}z_2+B_2u V V","['differential-geometry', 'dynamical-systems', 'control-theory', 'invariant-subspace']"
67,Kostant's connection on $\Lambda^2(M)\oplus TM$,Kostant's connection on,\Lambda^2(M)\oplus TM,"I'm trying to understand the equivalence Killing vector fields $\iff$ parallel sections on $\Lambda^2(M)\oplus TM$ , for a Riemannian manifold $M$ . I suppose that there exists a morphism $\phi:TM\rightarrow \Lambda^2(M)\oplus TM$ and a connection $D$ on $\Lambda^2(M)\oplus TM$ such that $\phi$ yields an isomorphism between the space of Killing vector fields and the space of parallel sections w.r.t $D$ (is it true? it can be that $\phi$ can only be defined for the Killing vector fields, not for all the vector fields...). How do I construct $\phi$ and $D$ ? I might have to use the Levi-Civita connection $\nabla$ on $M$ . Applying $\nabla$ on $X\in TM$ repeatedly I obtain $\nabla X\in T^*M\otimes TM$ and $\nabla^2 X\in \Lambda^2(M)\otimes TM$ . How can I use them to construct $\phi(X)$ ? Maybe I need to pass to local coordinates?","I'm trying to understand the equivalence Killing vector fields parallel sections on , for a Riemannian manifold . I suppose that there exists a morphism and a connection on such that yields an isomorphism between the space of Killing vector fields and the space of parallel sections w.r.t (is it true? it can be that can only be defined for the Killing vector fields, not for all the vector fields...). How do I construct and ? I might have to use the Levi-Civita connection on . Applying on repeatedly I obtain and . How can I use them to construct ? Maybe I need to pass to local coordinates?",\iff \Lambda^2(M)\oplus TM M \phi:TM\rightarrow \Lambda^2(M)\oplus TM D \Lambda^2(M)\oplus TM \phi D \phi \phi D \nabla M \nabla X\in TM \nabla X\in T^*M\otimes TM \nabla^2 X\in \Lambda^2(M)\otimes TM \phi(X),"['differential-geometry', 'riemannian-geometry', 'connections']"
68,Confusion regarding tensor product of redundant k-tensors,Confusion regarding tensor product of redundant k-tensors,,"$\newcommand{\Vs}{V^{\!\star}}\newcommand{\I}{\mathcal{I}}\newcommand{\L}{\mathcal{L}}$ The following is an excerpt from Guillemin and Haine's book on Differential Forms. Note that $\L^k(V)$ denotes the set of $k$ -tensors over $V$ . Definition. A decomposable $k$ -tensor $\ell_1\otimes\cdots\otimes\ell_k$ , with $\ell_1,\dots,\ell_k\in\Vs$ is redundant if for some index $i$ we have $\ell_i=\ell_{i+1}$ .   Let $\I^k(V)\subset\L^k(V)$ be the linear span of the set of redundant $k$ -tensors. (...) Proposition. If $T\in \I^r(V)$ and $T'\in\L^s(V)$ then $T\otimes T'$ and $T'\otimes T$ are in $\I^{r+s}(V)$ . Proof. We can assume that $T$ and $T'$ are decomposable, i.e., $T=\ell_1\otimes\dotsm\otimes \ell_r$ and $T'=\ell_1'\otimes\dotsm\otimes\ell_s'$ and that $T$ is redundant: $\ell_i=\ell_{i+1}$ . Then $$T\otimes T'=\ell_1\otimes\dotsm\otimes\ell_{i-1}\otimes\ell_i\otimes\ell_i\otimes\dotsm\otimes\ell_r\otimes\ell_1'\otimes\dotsm\otimes\ell_s'$$ is redundant and hence in $\I^{r+s}$ . The argument for $T'\otimes T$ is similar. $\square$ The proof of the proposition is rather clear to me, except for the first part: why can we assume that $T'$ is decomposable? Of course we can assume $T$ to be decomposable since the notion of redundancy is one defined for decomposable tensors, but why can we do so for $T'$ since (unless I'm horribly mistaken) there are plenty of tensors which are not decomposable? What am I missing here? Thanks in advance!","The following is an excerpt from Guillemin and Haine's book on Differential Forms. Note that denotes the set of -tensors over . Definition. A decomposable -tensor , with is redundant if for some index we have .   Let be the linear span of the set of redundant -tensors. (...) Proposition. If and then and are in . Proof. We can assume that and are decomposable, i.e., and and that is redundant: . Then is redundant and hence in . The argument for is similar. The proof of the proposition is rather clear to me, except for the first part: why can we assume that is decomposable? Of course we can assume to be decomposable since the notion of redundancy is one defined for decomposable tensors, but why can we do so for since (unless I'm horribly mistaken) there are plenty of tensors which are not decomposable? What am I missing here? Thanks in advance!","\newcommand{\Vs}{V^{\!\star}}\newcommand{\I}{\mathcal{I}}\newcommand{\L}{\mathcal{L}} \L^k(V) k V k \ell_1\otimes\cdots\otimes\ell_k \ell_1,\dots,\ell_k\in\Vs i \ell_i=\ell_{i+1} \I^k(V)\subset\L^k(V) k T\in \I^r(V) T'\in\L^s(V) T\otimes T' T'\otimes T \I^{r+s}(V) T T' T=\ell_1\otimes\dotsm\otimes \ell_r T'=\ell_1'\otimes\dotsm\otimes\ell_s' T \ell_i=\ell_{i+1} T\otimes T'=\ell_1\otimes\dotsm\otimes\ell_{i-1}\otimes\ell_i\otimes\ell_i\otimes\dotsm\otimes\ell_r\otimes\ell_1'\otimes\dotsm\otimes\ell_s' \I^{r+s} T'\otimes T \square T' T T'","['differential-geometry', 'tensor-products', 'differential-forms', 'tensors', 'dual-spaces']"
69,Components of shape operator in graph coordinates,Components of shape operator in graph coordinates,,"Suppose $M \subset \mathbb R^{n+1}$ is the graph of a function $f : U \to \mathbb R$ , for some open subset $U \subset \mathbb R^n$ . I'm trying to find the coefficients of the matrix of the shape operator $s : T_p M \to T_p M$ (for $p \in M$ ) in terms of graph coordinates. These are global coordinates of $M$ given by $\phi : M \to U$ , $\phi(u, f(u)) = u$ . What I've tried. Letting $(x^1, \ldots, x^{n+1})$ denote the usual Cartesian coordinates in $\mathbb R^{n+1}$ , the coordinate tangent vectors of $M$ in graph coordinates are related to the coordinate tangent vectors of $\mathbb R^{n+1}$ via $$ \frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}} $$ (This can be seen by considering the map $\phi^{-1} : U \to M$ , $\phi^{-1}(u) = (u, f(u))$ and explicitly calculating $\frac{\partial\left(\phi^{-1}\right)^j}{\partial u^i} \frac{\partial}{\partial x^j}$ .) The upward unit normal field of $M$ is given by $$ N = \frac{\mathrm{grad} F}{|\mathrm{grad} F|}, $$ where $F : \mathbb R^{n+1} \to \mathbb R$ is the function $F(x,x^{n+1}) = x^{n+1} - f(x)$ (so $M$ is the level set of $F$ for $0$ ). Therefore, $$ N = \left(1+\sum_{i=1}^n \left(\frac{\partial f}{\partial x^i}\right)^2\right)^{-1/2}\left(-\sum_{i=1}^n \frac{\partial f}{\partial x^i}\frac{\partial}{\partial x^i} + \frac{\partial}{\partial x^{n+1}}\right) = -\sum_{i=1}^n \frac{\partial f/\partial x^i}{|\mathrm{grad} F|} \frac{\partial}{\partial x^i} + \frac 1{|\mathrm{grad} F|} \frac{\partial}{\partial x^{n+1}} $$ In particular, if we denote $N = N^i \frac{\partial}{\partial x^i}$ , then $\frac{\partial}{\partial x^{n+1}} N^i \equiv 0$ for every $i$ , and thus $\overline\nabla_{\partial/\partial x^{n+1}} N = 0$ (where $\overline\nabla$ is the Levi-Civita connection of the Euclidean metric on $\mathbb R^{n+1}$ ). Meanwhile, by direct computation, for $1 \leq i, j \leq n$ , $$ \frac{\partial}{\partial x^j} N^i = -\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} + \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j} $$ and $$ \frac{\partial}{\partial x^j} N^{n+1} = -\frac 1{|\mathrm{grad} F|^3}\sum_{i=1}^n\frac{\partial f}{\partial x^i}\frac{\partial^2 f}{\partial x^i \partial x^j} $$ The Weingarten equation for hypersurfaces says $sX = -\overline\nabla_X N$ for $X \in \mathcal X(M)$ . So using what we just calculated, \begin{align} s\frac{\partial}{\partial u^j} &= -\overline\nabla_{\partial/\partial x^j} N - \frac{\partial f}{\partial x^j} \overline\nabla_{\partial/\partial x^{n+1}} N = -\overline\nabla_{\partial/\partial x^j} N = -\sum_{i=1}^n \left(\frac{\partial}{\partial x^j} N^i\right) \frac{\partial}{\partial x^i}\\ &= \sum_{i=1}^n\left(\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} \\ &\qquad \qquad \qquad + \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \\ &= \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \left[ \left(\frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - |\mathrm{grad}F|^2 \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} +\frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \right] \end{align} My problem: In principle, I should be able to now express $s\frac{\partial}{\partial u^i}$ in terms of the basis of coordinate vector fields given by $\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}$ . This will give me the coefficients for $s_{ij}$ I need. But it's not clear to me that I'm able to do that given what I just found. On the other hand, I'm reasonably sure that the expression I've found is orthogonal to $N$ , so it lies in the tangent space of $M$ at each point $p \in M$ . Am I going wrong somewhere? Is there a better way to find the coefficients of the shape operator? EDIT: I now see I was trying to plug a round peg into a square hole. My computations were correct, and agree with the answer below (though are written less elegantly). The coefficients in graph coordinates are $$ s_{ij} = \frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j} $$ since $\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}$ . In particular, comparing this coordinate expression to the $\frac{\partial}{\partial x^{n+1}}$ term above implies $$\sum_{i=1}^n s_{ij} \frac{\partial f}{\partial x^i} = \frac 1{|\mathrm{grad}F|^3} \sum_{k=1}^n \frac{\partial f}{\partial k} \frac{\partial^2 f}{\partial x^k \partial x^j}$$ although explicitly writing out why the above is true would be rather challenging.","Suppose is the graph of a function , for some open subset . I'm trying to find the coefficients of the matrix of the shape operator (for ) in terms of graph coordinates. These are global coordinates of given by , . What I've tried. Letting denote the usual Cartesian coordinates in , the coordinate tangent vectors of in graph coordinates are related to the coordinate tangent vectors of via (This can be seen by considering the map , and explicitly calculating .) The upward unit normal field of is given by where is the function (so is the level set of for ). Therefore, In particular, if we denote , then for every , and thus (where is the Levi-Civita connection of the Euclidean metric on ). Meanwhile, by direct computation, for , and The Weingarten equation for hypersurfaces says for . So using what we just calculated, My problem: In principle, I should be able to now express in terms of the basis of coordinate vector fields given by . This will give me the coefficients for I need. But it's not clear to me that I'm able to do that given what I just found. On the other hand, I'm reasonably sure that the expression I've found is orthogonal to , so it lies in the tangent space of at each point . Am I going wrong somewhere? Is there a better way to find the coefficients of the shape operator? EDIT: I now see I was trying to plug a round peg into a square hole. My computations were correct, and agree with the answer below (though are written less elegantly). The coefficients in graph coordinates are since . In particular, comparing this coordinate expression to the term above implies although explicitly writing out why the above is true would be rather challenging.","M \subset \mathbb R^{n+1} f : U \to \mathbb R U \subset \mathbb R^n s : T_p M \to T_p M p \in M M \phi : M \to U \phi(u, f(u)) = u (x^1, \ldots, x^{n+1}) \mathbb R^{n+1} M \mathbb R^{n+1} 
\frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}}
 \phi^{-1} : U \to M \phi^{-1}(u) = (u, f(u)) \frac{\partial\left(\phi^{-1}\right)^j}{\partial u^i} \frac{\partial}{\partial x^j} M 
N = \frac{\mathrm{grad} F}{|\mathrm{grad} F|},
 F : \mathbb R^{n+1} \to \mathbb R F(x,x^{n+1}) = x^{n+1} - f(x) M F 0 
N = \left(1+\sum_{i=1}^n \left(\frac{\partial f}{\partial x^i}\right)^2\right)^{-1/2}\left(-\sum_{i=1}^n \frac{\partial f}{\partial x^i}\frac{\partial}{\partial x^i} + \frac{\partial}{\partial x^{n+1}}\right) = -\sum_{i=1}^n \frac{\partial f/\partial x^i}{|\mathrm{grad} F|} \frac{\partial}{\partial x^i} + \frac 1{|\mathrm{grad} F|} \frac{\partial}{\partial x^{n+1}}
 N = N^i \frac{\partial}{\partial x^i} \frac{\partial}{\partial x^{n+1}} N^i \equiv 0 i \overline\nabla_{\partial/\partial x^{n+1}} N = 0 \overline\nabla \mathbb R^{n+1} 1 \leq i, j \leq n 
\frac{\partial}{\partial x^j} N^i = -\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} + \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}
 
\frac{\partial}{\partial x^j} N^{n+1} = -\frac 1{|\mathrm{grad} F|^3}\sum_{i=1}^n\frac{\partial f}{\partial x^i}\frac{\partial^2 f}{\partial x^i \partial x^j}
 sX = -\overline\nabla_X N X \in \mathcal X(M) \begin{align}
s\frac{\partial}{\partial u^j} &= -\overline\nabla_{\partial/\partial x^j} N - \frac{\partial f}{\partial x^j} \overline\nabla_{\partial/\partial x^{n+1}} N = -\overline\nabla_{\partial/\partial x^j} N = -\sum_{i=1}^n \left(\frac{\partial}{\partial x^j} N^i\right) \frac{\partial}{\partial x^i}\\
&= \sum_{i=1}^n\left(\frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} \\
&\qquad \qquad \qquad + \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \\
&= \frac 1{|\mathrm{grad} F|^3} \sum_{i=1}^n \left[ \left(\frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - |\mathrm{grad}F|^2 \frac{\partial^2 f}{\partial x^i \partial x^j}\right)\frac{\partial}{\partial x^i} +\frac{\partial^2 f}{\partial x^i \partial x^j} \frac{\partial f}{\partial x^i} \frac{\partial}{\partial x^{n+1}} \right]
\end{align} s\frac{\partial}{\partial u^i} \frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}} s_{ij} N M p \in M 
s_{ij} = \frac 1{|\mathrm{grad} F|^3} \frac{\partial f}{\partial x^i}\sum_{k=1}^n \frac{\partial f}{\partial x^k} \frac{\partial^2f}{\partial x^k \partial x^j} - \frac{1}{|\mathrm{grad} F|} \frac{\partial^2 f}{\partial x^i \partial x^j}
 \frac{\partial}{\partial u^j} = \frac{\partial}{\partial x^j} + \frac{\partial f}{\partial x^j} \frac{\partial}{\partial x^{n+1}} \frac{\partial}{\partial x^{n+1}} \sum_{i=1}^n s_{ij} \frac{\partial f}{\partial x^i} = \frac 1{|\mathrm{grad}F|^3} \sum_{k=1}^n \frac{\partial f}{\partial k} \frac{\partial^2 f}{\partial x^k \partial x^j}","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'curvature', 'submanifold']"
70,Immersed principal subbundles,Immersed principal subbundles,,"In Kobayashi and Nomizu's Foundations of Differential Geometry vol. 1 the authors define immersed principal subbundles (actually, they call them imbeddings ) of a principal $G$ -bundle $\pi: P \to M$ as a principal $G'$ bundle $\pi': P' \to M'$ with an injective immersion $f: P' \hookrightarrow P$ and an injective homomorphism of Lie groups $\phi: G' \hookrightarrow G$ such that $$ f(q \cdot g) = f(q) \phi(g) \quad \text{for all}~q \in P', g \in G'~. $$ This induces a smooth map $h: M' \to M$ such that $h \circ \pi' = \pi \circ f$ . The authors claim that (in the case of a immersed subbundle) this is also an injective immersion. I don't see why the last statement should hold. Take for example $M' = \mathbb{R}$ , $G' = \{e\}$ , so $P' = \mathbb{R} \times \{e\}$ and $P = \{p\} \times \mathbb{R}^2$ , i.e. $M$ is a single point and $G = (\mathbb{R}^2, +)$ . Then the map \begin{align}     \mathbb{R} \times \{e\} &\to \{p\} \times \mathbb{R}^2 \\     (t, e) &\mapsto (p, (t, 0)) \end{align} satisfies the conditions to be an immersed principal subbundle. However the map induced on $\mathbb{R} \to \{p\}$ is not an injective immersion. Am I  missing something (an additional assumption, a different definition)? If not, is there any  assumption that can be added to make the claim in the book true?","In Kobayashi and Nomizu's Foundations of Differential Geometry vol. 1 the authors define immersed principal subbundles (actually, they call them imbeddings ) of a principal -bundle as a principal bundle with an injective immersion and an injective homomorphism of Lie groups such that This induces a smooth map such that . The authors claim that (in the case of a immersed subbundle) this is also an injective immersion. I don't see why the last statement should hold. Take for example , , so and , i.e. is a single point and . Then the map satisfies the conditions to be an immersed principal subbundle. However the map induced on is not an injective immersion. Am I  missing something (an additional assumption, a different definition)? If not, is there any  assumption that can be added to make the claim in the book true?","G \pi: P \to M G' \pi': P' \to M' f: P' \hookrightarrow P \phi: G' \hookrightarrow G 
f(q \cdot g) = f(q) \phi(g) \quad \text{for all}~q \in P', g \in G'~.
 h: M' \to M h \circ \pi' = \pi \circ f M' = \mathbb{R} G' = \{e\} P' = \mathbb{R} \times \{e\} P = \{p\} \times \mathbb{R}^2 M G = (\mathbb{R}^2, +) \begin{align}
    \mathbb{R} \times \{e\} &\to \{p\} \times \mathbb{R}^2 \\
    (t, e) &\mapsto (p, (t, 0))
\end{align} \mathbb{R} \to \{p\}","['differential-geometry', 'manifolds', 'lie-groups', 'smooth-manifolds', 'principal-bundles']"
71,Every compact connected hypersurface with enough symmetry is a sphere,Every compact connected hypersurface with enough symmetry is a sphere,,"I would like to prove that: Lemma. Let $M\subset\mathbb R^{n+1}$ be a connected and compact $n$ -dimensional smooth submanifold (i.e. a hypersurface). Suppose that for every direction, there exists a hyperplane such that $M$ reflected at this hyperplane equals $M$ . Or put more formally, for every $v\in\mathbb R^{n+1}$ with $|v|=1$ , there exists a constant $c(v)\in\mathbb R$ such that $M$ reflected at $$\{x\in\mathbb R^{n+1}\mid \langle x,v\rangle = c(v)\}$$ is equal to $M$ . Then $M$ is a sphere. It is said that this Lemma is due to Hopf, but I don't know how to prove it. I found the following paper: ALEKSANDROV’S  THEOREM:  CLOSED  SURFACES  WITHCONSTANT  MEAN  CURVATURE in which Lemma 1.4 is almost identical to my Lemma. But I can't understand the proof. Also, the Lemma 1.4 has the additional assumption that $M$ is a closed hypersurface. How can I prove this Lemma?","I would like to prove that: Lemma. Let be a connected and compact -dimensional smooth submanifold (i.e. a hypersurface). Suppose that for every direction, there exists a hyperplane such that reflected at this hyperplane equals . Or put more formally, for every with , there exists a constant such that reflected at is equal to . Then is a sphere. It is said that this Lemma is due to Hopf, but I don't know how to prove it. I found the following paper: ALEKSANDROV’S  THEOREM:  CLOSED  SURFACES  WITHCONSTANT  MEAN  CURVATURE in which Lemma 1.4 is almost identical to my Lemma. But I can't understand the proof. Also, the Lemma 1.4 has the additional assumption that is a closed hypersurface. How can I prove this Lemma?","M\subset\mathbb R^{n+1} n M M v\in\mathbb R^{n+1} |v|=1 c(v)\in\mathbb R M \{x\in\mathbb R^{n+1}\mid \langle x,v\rangle = c(v)\} M M M","['differential-geometry', 'surfaces', 'submanifold']"
72,The principal directions bissect the asymptotic directions,The principal directions bissect the asymptotic directions,,"I was trying to prove that: At a hyperbolic point, the principal directions bissect the asymptotic directions. Well, I tried to use the Euler's formula: Being $dN_p$ with eigenvalues $k_1,k_2$ , eigeinvectors $e_1,e_2$ , take $v$ one asymptotic direction. So, write $v=\cos\theta e_1+\sin \theta e_2$ , $\theta $ the angle from $e_1$ . We have: $$II_p(v)=0\iff\\ 0=\cos^2\theta k_1+\sin^2 \theta k_2\iff\\ \sin^2 \theta=\dfrac{-k_1}{k_2-k_1};\cos^2\theta=\dfrac{k_2}{k_2-k_1}.$$ To get bissection, I thought that I should obtain $\sin^2 \theta=\cos^2\theta$ . I cannot finish. Many thanks in advance.","I was trying to prove that: At a hyperbolic point, the principal directions bissect the asymptotic directions. Well, I tried to use the Euler's formula: Being with eigenvalues , eigeinvectors , take one asymptotic direction. So, write , the angle from . We have: To get bissection, I thought that I should obtain . I cannot finish. Many thanks in advance.","dN_p k_1,k_2 e_1,e_2 v v=\cos\theta e_1+\sin \theta e_2 \theta  e_1 II_p(v)=0\iff\\
0=\cos^2\theta k_1+\sin^2 \theta k_2\iff\\
\sin^2 \theta=\dfrac{-k_1}{k_2-k_1};\cos^2\theta=\dfrac{k_2}{k_2-k_1}. \sin^2 \theta=\cos^2\theta","['differential-geometry', 'conic-sections', 'surfaces', 'vector-fields', 'curvature']"
73,If the fiber and the base are Kähler manifolds is the total space also Kähler?,If the fiber and the base are Kähler manifolds is the total space also Kähler?,,Let $E$ be a compact manifold and consider the fiber bundle $$F\to E\to B$$ Assume that $F$ and $B$ are Kähler manifolds. Is $E$ also a Kähler  manifold?,Let be a compact manifold and consider the fiber bundle Assume that and are Kähler manifolds. Is also a Kähler  manifold?,E F\to E\to B F B E,"['differential-geometry', 'algebraic-topology']"
74,"Einstein field equation,pde and differential geometry","Einstein field equation,pde and differential geometry",,"I'm a math undergraduate student with some interest in mathematical physics with basic knowledge of partial differential equation. When I was reading a wikipedia article about einstein field equation,it said when fully written out, the EFE are a system of ten coupled, nonlinear, hyperbolic-elliptic partial differential equations. my question is if einstein equation is a partial differential equation, why can't you solve it normally,why do you need tensor analysis/riemannian geometry for, and can any partial differential equation be written using the languange of tensor, differential geometry,etc? I apologize for my minimal understanding of this subject, but I haven't learn any tensor calculus yet","I'm a math undergraduate student with some interest in mathematical physics with basic knowledge of partial differential equation. When I was reading a wikipedia article about einstein field equation,it said when fully written out, the EFE are a system of ten coupled, nonlinear, hyperbolic-elliptic partial differential equations. my question is if einstein equation is a partial differential equation, why can't you solve it normally,why do you need tensor analysis/riemannian geometry for, and can any partial differential equation be written using the languange of tensor, differential geometry,etc? I apologize for my minimal understanding of this subject, but I haven't learn any tensor calculus yet",,"['differential-geometry', 'partial-differential-equations', 'mathematical-physics', 'general-relativity']"
75,Calculate mean curvature of surface,Calculate mean curvature of surface,,"I've got the following surface $M=\bigl\{(x,y,z) \mid e^z=\frac{\cos x}{\cos y}\bigr\}\subset \mathbb{R}^3$ where $x,y \in \bigl(-\frac{\pi}{2},\frac{\pi}{2}\bigr)$ and want to calculate the mean curvature of it. To do this I used the parametrisation $X(u,v)=(u,v,\ln(\frac{\cos u}{\cos v}))$ but this leads to to a complete mess when using the well known formula $\dfrac{1}{2}\dfrac{eG-2fF+gE}{EG-F^2}$ where $E,F,G$ is from the first and $e,f,g$ is from the second fundamental forms. Someone know how to do this so it doesn't go off the handle? I have Gauss map given by $$N(X(u,v))=(\tan u,-\tan v, 1) \dfrac{1}{\sqrt{\dfrac{-\sin^2u}{\cos^2u}+\dfrac{-\sin^2v}{\cos^2v}+1}}.$$",I've got the following surface where and want to calculate the mean curvature of it. To do this I used the parametrisation but this leads to to a complete mess when using the well known formula where is from the first and is from the second fundamental forms. Someone know how to do this so it doesn't go off the handle? I have Gauss map given by,"M=\bigl\{(x,y,z) \mid e^z=\frac{\cos x}{\cos y}\bigr\}\subset \mathbb{R}^3 x,y \in \bigl(-\frac{\pi}{2},\frac{\pi}{2}\bigr) X(u,v)=(u,v,\ln(\frac{\cos u}{\cos v})) \dfrac{1}{2}\dfrac{eG-2fF+gE}{EG-F^2} E,F,G e,f,g N(X(u,v))=(\tan u,-\tan v, 1) \dfrac{1}{\sqrt{\dfrac{-\sin^2u}{\cos^2u}+\dfrac{-\sin^2v}{\cos^2v}+1}}.","['differential-geometry', 'minimal-surfaces']"
76,Proving this 1-manifold is the Hopf link,Proving this 1-manifold is the Hopf link,,"I encountered this example while reading Scorpan's book ""The wild world of 4-manifolds"". Consider the planes $$\Pi_1 =\{(x,y,0,0) \in \mathbb{R}^4\}$$ $$\Pi_2 =\{(0,0,z,w) \in \mathbb{R}^4\}.$$ I would like to prove that $H:=\mathbb{S}^3\cap (\Pi_1\cup \Pi_2)$ is the Hopf link. Of course $K_1 = \mathbb{S}^3\cap \Pi_1$ can be parametrized by $\{(e^{i\theta},0)\}_{\theta \in \mathbb{R}}\subset \mathbb{C}^2\simeq \mathbb{R}^4$ and similarly $K_2 = \mathbb{S}^3\cap \Pi_2$ can be parametrized by $\{(0,e^{i\theta})\}_{\theta \in \mathbb{R}}\subset \mathbb{C}^2\simeq \mathbb{R}^4$ . I wanted to show that $K_i$ bounds a disk $D_i$ in $\mathbb{S}^3$ and that $D_1$ is pierced by $K_2$ exactly once. I did not manage to find the disks though.","I encountered this example while reading Scorpan's book ""The wild world of 4-manifolds"". Consider the planes I would like to prove that is the Hopf link. Of course can be parametrized by and similarly can be parametrized by . I wanted to show that bounds a disk in and that is pierced by exactly once. I did not manage to find the disks though.","\Pi_1 =\{(x,y,0,0) \in \mathbb{R}^4\} \Pi_2 =\{(0,0,z,w) \in \mathbb{R}^4\}. H:=\mathbb{S}^3\cap (\Pi_1\cup \Pi_2) K_1 = \mathbb{S}^3\cap \Pi_1 \{(e^{i\theta},0)\}_{\theta \in \mathbb{R}}\subset \mathbb{C}^2\simeq \mathbb{R}^4 K_2 = \mathbb{S}^3\cap \Pi_2 \{(0,e^{i\theta})\}_{\theta \in \mathbb{R}}\subset \mathbb{C}^2\simeq \mathbb{R}^4 K_i D_i \mathbb{S}^3 D_1 K_2","['differential-geometry', 'differential-topology', 'geometric-topology', 'knot-theory']"
77,Hamilton's equations arising from a variational principle.,Hamilton's equations arising from a variational principle.,,"In page 16 of McDuff & Salamon's Introduction to Symplectic Topology they prove that the critical points $z = (x,y)\colon [a,b] \to \Bbb R^{2n}$ of the action integral $$\Phi_H(z) = \int_a^b \langle y, \dot{x}\rangle - H(t,x,y)\,{\rm d}t$$ satisfy Hamilton's equations $\dot{x} = \partial_yH$ and $\dot{y} = -\partial_xH$ . Namely, they compute the first variation of $\Phi_H(z)$ as $$\widehat{\Phi_H}(z) = \int_a^b \langle \eta,\dot{x}-\partial_yH\rangle - \langle \xi, \dot{y}+\partial_xH\rangle\,{\rm d}t,$$ where $(\xi,\eta)$ is the variational vector field of a variation of $z$ with fixed endpoints. I have no problems whatsoever with the proof they present, but I am having trouble formulating a generalization of this statement in the setting of differentiable manifolds. What I have in mind is: Let $Q$ be a differentiable manifold and $H\colon T^*Q \to \Bbb R$ a smooth Hamiltonian. Consider the action integral $$\mathscr{A}^H(x,{\sf p}) = \int_a^b \mathbb{F}H(x(t),{\sf p}(t)){\sf p}(t) - H(x(t),{\sf p}(t))\,{\rm d}t,$$ where $(x,{\sf p})\colon [a,b] \to T^*Q$ is a smooth curve and $\mathbb{F}H$ is the fiber derivative of $H$ , given in coordinates by $$\mathbb{F}H(x,{\sf p}) = \sum_{k=1}^n \frac{\partial H}{\partial p_k}(x,{\sf p})\frac{\partial}{\partial q^k}\bigg|_x.$$ Then if $(x,{\sf p})$ is a critical point of $\mathscr{A}^H$ and we write $$(x(t),{\sf p}(t)) = (q^1(t),\ldots, q^n(t),p_1(t),\ldots, p_n(t)),$$ we have Hamilton's equations $$\frac{{\rm d}q^k}{{\rm d}t}(t) = \frac{\partial H}{\partial p_k}(x(t),{\sf p}(t)) \qquad\mbox{and}\qquad \frac{{\rm d}p_k}{{\rm d}t}(t) = -\frac{\partial H}{\partial q^k}(x(t),{\sf p}(t)).$$ However, I'm not entirely sure of this, as a priori there's no relation between $x(t)$ and ${\sf p}(t)$ (except for ${\sf p}(t) \in T_{x(t)}^*Q$ ), in contrast with curves $(x(t),\dot{x}(t))$ in $TQ$ , when analyzing the Lagrangian case. In particular, I cannot reproduce the proof given in McDuff & Salamon, since there's no apparent way to use integration by parts, as we have no $t$ -derivatives in the integrand. I don't really expect anyone to fix the statement and provide the computation (although it would be nice), but I need help figuring out what sort of relation I am missing here (with that I should be able to run the computation of the first variation myself). In particular, I am not assuming that $H$ is hyperregular, and we do not have Legendre transformations at our disposal. What to do?","In page 16 of McDuff & Salamon's Introduction to Symplectic Topology they prove that the critical points of the action integral satisfy Hamilton's equations and . Namely, they compute the first variation of as where is the variational vector field of a variation of with fixed endpoints. I have no problems whatsoever with the proof they present, but I am having trouble formulating a generalization of this statement in the setting of differentiable manifolds. What I have in mind is: Let be a differentiable manifold and a smooth Hamiltonian. Consider the action integral where is a smooth curve and is the fiber derivative of , given in coordinates by Then if is a critical point of and we write we have Hamilton's equations However, I'm not entirely sure of this, as a priori there's no relation between and (except for ), in contrast with curves in , when analyzing the Lagrangian case. In particular, I cannot reproduce the proof given in McDuff & Salamon, since there's no apparent way to use integration by parts, as we have no -derivatives in the integrand. I don't really expect anyone to fix the statement and provide the computation (although it would be nice), but I need help figuring out what sort of relation I am missing here (with that I should be able to run the computation of the first variation myself). In particular, I am not assuming that is hyperregular, and we do not have Legendre transformations at our disposal. What to do?","z = (x,y)\colon [a,b] \to \Bbb R^{2n} \Phi_H(z) = \int_a^b \langle y, \dot{x}\rangle - H(t,x,y)\,{\rm d}t \dot{x} = \partial_yH \dot{y} = -\partial_xH \Phi_H(z) \widehat{\Phi_H}(z) = \int_a^b \langle \eta,\dot{x}-\partial_yH\rangle - \langle \xi, \dot{y}+\partial_xH\rangle\,{\rm d}t, (\xi,\eta) z Q H\colon T^*Q \to \Bbb R \mathscr{A}^H(x,{\sf p}) = \int_a^b \mathbb{F}H(x(t),{\sf p}(t)){\sf p}(t) - H(x(t),{\sf p}(t))\,{\rm d}t, (x,{\sf p})\colon [a,b] \to T^*Q \mathbb{F}H H \mathbb{F}H(x,{\sf p}) = \sum_{k=1}^n \frac{\partial H}{\partial p_k}(x,{\sf p})\frac{\partial}{\partial q^k}\bigg|_x. (x,{\sf p}) \mathscr{A}^H (x(t),{\sf p}(t)) = (q^1(t),\ldots, q^n(t),p_1(t),\ldots, p_n(t)), \frac{{\rm d}q^k}{{\rm d}t}(t) = \frac{\partial H}{\partial p_k}(x(t),{\sf p}(t)) \qquad\mbox{and}\qquad \frac{{\rm d}p_k}{{\rm d}t}(t) = -\frac{\partial H}{\partial q^k}(x(t),{\sf p}(t)). x(t) {\sf p}(t) {\sf p}(t) \in T_{x(t)}^*Q (x(t),\dot{x}(t)) TQ t H","['differential-geometry', 'mathematical-physics', 'calculus-of-variations', 'classical-mechanics', 'symplectic-geometry']"
78,Differential as bundle map and pull back bundle,Differential as bundle map and pull back bundle,,"In the wikipedia article about the pushforward , it is stated that if $f: M\to N$ is smooth, then it induces a bundle map $df: TM \to TN$ . It is then claimed that equivalently $f_*=df$ is a bundle map from $TM$ to the pullback bundle $f^* TN$ . Why is this equivalent? The bundles $TN$ and $f^* TN$ are clearly not the same as they are bundles over different spaces. They could be isomorphic, but is still seems strange that this would hold independently of $f$ . Edit: The full quote is Equivalently (see bundle map), φ∗ = dφ is a bundle map from TM to the pullback bundle φ∗TN over M, which may in turn be viewed as a section of the vector bundle Hom(TM, φ∗TN) over M. The bundle map dφ is also denoted by Tφ and called the tangent map. In this way, T is a functor.","In the wikipedia article about the pushforward , it is stated that if is smooth, then it induces a bundle map . It is then claimed that equivalently is a bundle map from to the pullback bundle . Why is this equivalent? The bundles and are clearly not the same as they are bundles over different spaces. They could be isomorphic, but is still seems strange that this would hold independently of . Edit: The full quote is Equivalently (see bundle map), φ∗ = dφ is a bundle map from TM to the pullback bundle φ∗TN over M, which may in turn be viewed as a section of the vector bundle Hom(TM, φ∗TN) over M. The bundle map dφ is also denoted by Tφ and called the tangent map. In this way, T is a functor.",f: M\to N df: TM \to TN f_*=df TM f^* TN TN f^* TN f,['differential-geometry']
79,Metric of a cross-section in General Relativity,Metric of a cross-section in General Relativity,,"Consider a finite closed region $V=(x,y,z)$ as a simply-connected subset of a 3-dimensional flat Euclidean space ${\Bbb R}^3$ with the metric $\text{d}s^2=\text{d}x^2+\text{d}y^2+\text{d}z^2$ . A surface defined by a single-valued non-singular twice differentiable function $z=F(x,y)$ represents a cross-section of the region $V$ , i.e. for any $(x,y)$ in this region, $z=F(x,y)$ is defined and contained in the region $V$ . The curvature of $F$ defined this way must have certain limitations, because in general, a 2-dimensional surface with an arbitrary intrinsic curvature cannot always be represented as a cross section of ${\Bbb R}^3$ . (I am avoiding the term ""embedding"" to keep things simple.) In other words, the metric (or curvature) of $F$ must obey certain conditions to allow $F$ to be a cross-section of $V$ . Can these conditions be mathematically formulated? What limitations must be put on the metric (or on the curvature) of a 2-space to allow defining this space as a cross-section of ${\Bbb R}^3$ ?","Consider a finite closed region as a simply-connected subset of a 3-dimensional flat Euclidean space with the metric . A surface defined by a single-valued non-singular twice differentiable function represents a cross-section of the region , i.e. for any in this region, is defined and contained in the region . The curvature of defined this way must have certain limitations, because in general, a 2-dimensional surface with an arbitrary intrinsic curvature cannot always be represented as a cross section of . (I am avoiding the term ""embedding"" to keep things simple.) In other words, the metric (or curvature) of must obey certain conditions to allow to be a cross-section of . Can these conditions be mathematically formulated? What limitations must be put on the metric (or on the curvature) of a 2-space to allow defining this space as a cross-section of ?","V=(x,y,z) {\Bbb R}^3 \text{d}s^2=\text{d}x^2+\text{d}y^2+\text{d}z^2 z=F(x,y) V (x,y) z=F(x,y) V F {\Bbb R}^3 F F V {\Bbb R}^3","['general-relativity', 'differential-geometry']"
80,Geometric interpretation of the second Bianchi identity?,Geometric interpretation of the second Bianchi identity?,,"Assuming a torsion free Christoffel symbol, the covariant derivative can be shown to satisfy the second (differential) Bianchi identity: \begin{equation} [[\nabla_a,\nabla_b],\nabla_c]+[[\nabla_c,\nabla_a],\nabla_b]+[[\nabla_b,\nabla_c],\nabla_a]=0 \end{equation} Question: Is there a nice geometric interpretation of this identity? One of my motivations for this question is that this condition can be interpreted as stating that the co-variant derivatives form a Lie algebra (with the algebra product given by the commutator). Thus a geometric interpretation of the second Bianchi identity may motivate why the Jacobi identity is natural/fundamental.","Assuming a torsion free Christoffel symbol, the covariant derivative can be shown to satisfy the second (differential) Bianchi identity: Question: Is there a nice geometric interpretation of this identity? One of my motivations for this question is that this condition can be interpreted as stating that the co-variant derivatives form a Lie algebra (with the algebra product given by the commutator). Thus a geometric interpretation of the second Bianchi identity may motivate why the Jacobi identity is natural/fundamental.","\begin{equation}
[[\nabla_a,\nabla_b],\nabla_c]+[[\nabla_c,\nabla_a],\nabla_b]+[[\nabla_b,\nabla_c],\nabla_a]=0
\end{equation}","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'lie-algebras']"
81,Relationship between $(n - 1)$ forms and flux of a vector field across a hypersurface,Relationship between  forms and flux of a vector field across a hypersurface,(n - 1),"I am currently studying about differential forms and want to deduce the Divergence Theorem (the one in $\mathbb{R}^n$ ) from the general Stokes' Theorem, which is obtained by taking $$\omega = \sum_{i=1}^n (-1)^{i+1}F_idx_1\wedge\dots\widehat{dx_i}\dots,\wedge dx_n$$ However, I also want to find the relation between $\omega$ and the flux of $F$ through a surface $\Sigma$ . Note we defined flux using the integral $$\text{flux} = \int_\Sigma F\cdot \hat{n} $$ It seems to me that if $g$ is a parameterization of $\Sigma$ , then $g^* \omega=F\cdot \hat{n}\ \text{dvol}_\Sigma$ , but I cannot prove this. I tried writing the normal explicitly as a cross product $$ N=\det \begin{bmatrix} e_1 & | & |& |\\   |& \frac{\partial g}{\partial u_1} & \cdots & \frac{\partial g}{\partial u_{n-1}}\\  e_n & | & | & | \end{bmatrix},\ \hat{n}=\frac{N}{||N||}$$ Then if we dot product with $F$ , we do get by opening the determinant a sum of the form $$F\cdot \hat{n} = \sum_{i=1}^n (-1)^{i+1}F_i\circ g \cdot \text{det of a weird minor}$$ I couldn't get any further though. EDIT: I should point out that my knowledge volume forms is basic and stems from the definition $$\text{vol}_M(x)(v_1,\dots,v_k) = \varepsilon \text{vol}_k (v_1,\dots,v_k) ,\ \forall v_i \in T_xM$$ where $\varepsilon$ is chosen such that $(v_1,\dots,v_k ; \varepsilon)$ is a positivly oriented frame. I also know that if I pull back a volume form I get $\sqrt{\det Dg^T Dg} du_1 \wedge \dots \wedge du_k$","I am currently studying about differential forms and want to deduce the Divergence Theorem (the one in ) from the general Stokes' Theorem, which is obtained by taking However, I also want to find the relation between and the flux of through a surface . Note we defined flux using the integral It seems to me that if is a parameterization of , then , but I cannot prove this. I tried writing the normal explicitly as a cross product Then if we dot product with , we do get by opening the determinant a sum of the form I couldn't get any further though. EDIT: I should point out that my knowledge volume forms is basic and stems from the definition where is chosen such that is a positivly oriented frame. I also know that if I pull back a volume form I get","\mathbb{R}^n \omega = \sum_{i=1}^n (-1)^{i+1}F_idx_1\wedge\dots\widehat{dx_i}\dots,\wedge dx_n \omega F \Sigma \text{flux} = \int_\Sigma F\cdot \hat{n}  g \Sigma g^* \omega=F\cdot \hat{n}\ \text{dvol}_\Sigma  N=\det \begin{bmatrix}
e_1 & | & |& |\\ 
 |& \frac{\partial g}{\partial u_1} & \cdots & \frac{\partial g}{\partial u_{n-1}}\\ 
e_n & | & | & |
\end{bmatrix},\ \hat{n}=\frac{N}{||N||} F F\cdot \hat{n} = \sum_{i=1}^n (-1)^{i+1}F_i\circ g \cdot \text{det of a weird minor} \text{vol}_M(x)(v_1,\dots,v_k) = \varepsilon \text{vol}_k (v_1,\dots,v_k) ,\ \forall v_i \in T_xM \varepsilon (v_1,\dots,v_k ; \varepsilon) \sqrt{\det Dg^T Dg} du_1 \wedge \dots \wedge du_k","['calculus', 'differential-geometry', 'vector-analysis', 'differential-forms', 'surface-integrals']"
82,"What is a differetial structure, exactly?","What is a differetial structure, exactly?",,"A structure in general is a set and some operations on that set or ordersrelations of some kind. In algebra and topology this is rather clear, but in differential geometry one often consider ""differential structure"". I understand that an atlas is related to this matter and my impression is that an atlas induces a differential structure. But what is this structure? In topology we can relate the structure to continuity i.e any topological space space that has the same topological structure also have the same continuous functions(even if it is not defined on the exact same sets). Hence one would think that differential structure and differentiable functions have the same dynamics. Something tells me this is related to the tangent spaces and how they look as linear spaces since this is what the atlas induces at each point via the partials of the charts. Does anyone have  good answer for what the differential structure consists of or how to think about it? Two different manifolds with different atlases should be able to have the same ""differential structure"" as far as I understand.","A structure in general is a set and some operations on that set or ordersrelations of some kind. In algebra and topology this is rather clear, but in differential geometry one often consider ""differential structure"". I understand that an atlas is related to this matter and my impression is that an atlas induces a differential structure. But what is this structure? In topology we can relate the structure to continuity i.e any topological space space that has the same topological structure also have the same continuous functions(even if it is not defined on the exact same sets). Hence one would think that differential structure and differentiable functions have the same dynamics. Something tells me this is related to the tangent spaces and how they look as linear spaces since this is what the atlas induces at each point via the partials of the charts. Does anyone have  good answer for what the differential structure consists of or how to think about it? Two different manifolds with different atlases should be able to have the same ""differential structure"" as far as I understand.",,"['differential-geometry', 'riemannian-geometry']"
83,Continuity of homotopy in proof of Hopf's Umlaufsatz,Continuity of homotopy in proof of Hopf's Umlaufsatz,,"The standard proof of Hopf's Umlaufsatz proceeds something like this: We have a unit speed $\mathcal{C}^1$ curve $\beta:\mathbb{R}\to\mathbb{R}^2$ .  Furthermore, $\beta$ is a simple loop with period $L$ . We now define $T=\{(t_1,t_2) \in \mathbb{R}^2 : 0 \leq t_1 \leq t_2 \leq L \}$ and a function $f$ on $T$ as follows: $$ f(t_1,t_2) =   \begin{cases}     \beta'(t_1) & t_1=t_2 \\     -\beta'(0) & (t_1,t_2)=(0,L) \\     \frac{\beta(t_2)-\beta(t_1)}{\|\beta(t_2)-\beta(t_1)\|} & \text{otherwise}   \end{cases} $$ It is visually obvious that $f$ is continuous, but I haven't found a strict proof of this anywhere. Below is my attempt at a proof, but I think it's ugly and long-winded and it also isn't complete.  My question is how to finish it.  I also suspect (or rather hope) that there is a significantly shorter (or more elegant) proof that is nevertheless complete and doesn't use hand-waving. First of all, $f$ is continuous for all $(t_1,t_2)\in T$ with $t_1\neq t_2$ and $(t_1,t_2)\neq(0,L)$ because (as $\beta$ is simple) the denominator of $(\beta(t_2)-\beta(t_1))/(\|\beta(t_2)-\beta(t_1)\|)$ doesn't vanish and $\beta$ and the norm are continuous. Now for the case $t_1=t_2$ .  Fix $t_1\in[0,L]$ .  We have $$ \lim_{t_2\to t_1} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} = \beta'(t_1) $$ by definition.  This implies $$ \lim_{\substack{t_2\to t_1\\t_2>t_1}} \frac{\|\beta(t_2)-\beta(t_1)\|}{t_2-t_1} = \lim_{\substack{t_2\to t_1}} \left\|\frac{\beta(t_2)-\beta(t_1)}{t_2-t_1}\right\| = \|\beta'(t_1)\| = 1 $$ as $\beta$ is a unit speed curve. Combining these two we get $$ \lim_{\substack{t_2\to t_1\\t_2>t_1}} f(t_1,t_2) = \lim_{t_2\to t_1} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} \cdot  \lim_{\substack{t_2\to t_1\\t_2>t_1}} \frac{t_2-t_1}{\|\beta(t_2)-\beta(t_1)\|} = \beta'(t_1) $$ This means that for every $\varepsilon>0$ we can find a $\delta>0$ such that for all $t_2$ with $|t_2-t_1|<\delta$ and $(t_1,t_2)\in T$ we have $\|f(t_1,t_2)-\beta'(t_1)\|<\varepsilon$ . As $[0,L]$ is compact, we can even, for a given $\varepsilon>0$ , find a $\delta_1>0$ such that for all $(t_1,t_2)\in T$ with $|t_2-t_1|<\delta_1$ the inequality $\|f(t_1,t_2)-\beta'(t_1)\|<\varepsilon/2$ holds. Also, as $\beta'$ is continuous and $[0,L]$ is compact, we can find a $\delta_2>0$ such that for all $t_1^\ast,t_1\in[0,L]$ with $|t_1-t_1^\ast|<\delta_2$ we have $\|\beta'(t_1) - \beta'(t_1^\ast)\|<\varepsilon/2$ . Now let $P=(t_1,t_2)\in T$ be arbitrary with $\|P-(t_1^\ast,t_1^\ast)\|<\min\{\delta_1/2,\delta_2\}$ .  That implies $|t_1-t_1^\ast|<\delta_2$ and $|t_2-t_1|<\delta_1$ .  By combining the previous two inequalities we get $\|f(P)-\beta'(t_1^\ast)\|<\varepsilon$ .  We have thus proved that $f$ is continuous in $(t_1^\ast,t_1^\ast)$ . The third case is the point $Q=(0,L)$ .  As $\beta$ is a loop, we have: $$ \lim_{t\to L} \frac{\beta(t)-\beta(0)}{L-t} = -\lim_{t\to L} \frac{\beta(L)-\beta(t)}{L-t} = -\beta'(L) = -\beta'(0) $$ And as a consequence we have: $$ \lim_{\substack{t\to L\\t<L}} \frac{\|\beta(t)-\beta(0)\|}{L-t} = \lim_{\substack{t\to L}} \left\|\frac{\beta(t)-\beta(0)}{L-t}\right\| = \|-\beta'(0)\| = 1 $$ Combining these two we get, as above: $$ \lim_{\substack{t\to L\\t<L}} f(0,t) =  -\beta'(0) $$ At this point I'm stuck.  I think that we need to show that $f$ is uniformly continuous around $Q$ and that maybe this is the case because $\beta$ has unit speed.  If we can prove that, we can approach $Q$ in a way similar to the second case: starting from a point near enough we first move - by virtue of uniform continuity - parallel to the $x$ axis until the first component is zero.  Then we move vertically towards $Q$ . EDIT: Using Ted Shifrin's advice, I've rewritten the second case of the proof. However, it seems to me that this depends on the Taylor remainder $R$ being continuous in both variables (see question mark below) which - if justified in detail - is not much different from what I did above and still doesn't solve the third case.  Or am I missing something? As $\beta$ is differentiable, we can write, for each $t_1\in[0,L]$ , $$ \beta(t_2)=\beta(t_1)+(t_2-t_1)\cdot\beta'(t_1) +(t_2-t_1)\cdot R(t_1,t_2-t_1) $$ with $\lim_{t\to0}R(t_1,t)=\mathbf0$ . We thus have $$ \lim_{(t_1,t_2)\to(t_1^\ast,t_1^\ast)} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} = \lim_{(t_1,t_2)\to(t_1^\ast,t_1^\ast)} (\beta'(t_1) + R(t_1,t_2-t_1)) \stackrel{\color{red}?}{=} \beta'(t_1^\ast) $$ and $$ \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} \frac{\|\beta(t_2)-\beta(t_1)\|}{t_2-t_1} = \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} \left\|\frac{\beta(t_2)-\beta(t_1)}{t_2-t_1}\right\| = \|\beta'(t_1^\ast)\|=1 $$ which eventually leads to $$ \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} f(t_1,t_2) = \beta'(t_1^\ast)  $$ as above.","The standard proof of Hopf's Umlaufsatz proceeds something like this: We have a unit speed curve .  Furthermore, is a simple loop with period . We now define and a function on as follows: It is visually obvious that is continuous, but I haven't found a strict proof of this anywhere. Below is my attempt at a proof, but I think it's ugly and long-winded and it also isn't complete.  My question is how to finish it.  I also suspect (or rather hope) that there is a significantly shorter (or more elegant) proof that is nevertheless complete and doesn't use hand-waving. First of all, is continuous for all with and because (as is simple) the denominator of doesn't vanish and and the norm are continuous. Now for the case .  Fix .  We have by definition.  This implies as is a unit speed curve. Combining these two we get This means that for every we can find a such that for all with and we have . As is compact, we can even, for a given , find a such that for all with the inequality holds. Also, as is continuous and is compact, we can find a such that for all with we have . Now let be arbitrary with .  That implies and .  By combining the previous two inequalities we get .  We have thus proved that is continuous in . The third case is the point .  As is a loop, we have: And as a consequence we have: Combining these two we get, as above: At this point I'm stuck.  I think that we need to show that is uniformly continuous around and that maybe this is the case because has unit speed.  If we can prove that, we can approach in a way similar to the second case: starting from a point near enough we first move - by virtue of uniform continuity - parallel to the axis until the first component is zero.  Then we move vertically towards . EDIT: Using Ted Shifrin's advice, I've rewritten the second case of the proof. However, it seems to me that this depends on the Taylor remainder being continuous in both variables (see question mark below) which - if justified in detail - is not much different from what I did above and still doesn't solve the third case.  Or am I missing something? As is differentiable, we can write, for each , with . We thus have and which eventually leads to as above.","\mathcal{C}^1 \beta:\mathbb{R}\to\mathbb{R}^2 \beta L T=\{(t_1,t_2) \in \mathbb{R}^2 : 0 \leq t_1 \leq t_2 \leq L \} f T  f(t_1,t_2) =
  \begin{cases}
    \beta'(t_1) & t_1=t_2 \\
    -\beta'(0) & (t_1,t_2)=(0,L) \\
    \frac{\beta(t_2)-\beta(t_1)}{\|\beta(t_2)-\beta(t_1)\|} & \text{otherwise}
  \end{cases}  f f (t_1,t_2)\in T t_1\neq t_2 (t_1,t_2)\neq(0,L) \beta (\beta(t_2)-\beta(t_1))/(\|\beta(t_2)-\beta(t_1)\|) \beta t_1=t_2 t_1\in[0,L]  \lim_{t_2\to t_1} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} = \beta'(t_1)   \lim_{\substack{t_2\to t_1\\t_2>t_1}} \frac{\|\beta(t_2)-\beta(t_1)\|}{t_2-t_1} = \lim_{\substack{t_2\to t_1}} \left\|\frac{\beta(t_2)-\beta(t_1)}{t_2-t_1}\right\| = \|\beta'(t_1)\| = 1  \beta  \lim_{\substack{t_2\to t_1\\t_2>t_1}} f(t_1,t_2) = \lim_{t_2\to t_1} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} \cdot 
\lim_{\substack{t_2\to t_1\\t_2>t_1}} \frac{t_2-t_1}{\|\beta(t_2)-\beta(t_1)\|} = \beta'(t_1)  \varepsilon>0 \delta>0 t_2 |t_2-t_1|<\delta (t_1,t_2)\in T \|f(t_1,t_2)-\beta'(t_1)\|<\varepsilon [0,L] \varepsilon>0 \delta_1>0 (t_1,t_2)\in T |t_2-t_1|<\delta_1 \|f(t_1,t_2)-\beta'(t_1)\|<\varepsilon/2 \beta' [0,L] \delta_2>0 t_1^\ast,t_1\in[0,L] |t_1-t_1^\ast|<\delta_2 \|\beta'(t_1) - \beta'(t_1^\ast)\|<\varepsilon/2 P=(t_1,t_2)\in T \|P-(t_1^\ast,t_1^\ast)\|<\min\{\delta_1/2,\delta_2\} |t_1-t_1^\ast|<\delta_2 |t_2-t_1|<\delta_1 \|f(P)-\beta'(t_1^\ast)\|<\varepsilon f (t_1^\ast,t_1^\ast) Q=(0,L) \beta  \lim_{t\to L} \frac{\beta(t)-\beta(0)}{L-t} = -\lim_{t\to L} \frac{\beta(L)-\beta(t)}{L-t} = -\beta'(L) = -\beta'(0)   \lim_{\substack{t\to L\\t<L}} \frac{\|\beta(t)-\beta(0)\|}{L-t} = \lim_{\substack{t\to L}} \left\|\frac{\beta(t)-\beta(0)}{L-t}\right\| = \|-\beta'(0)\| = 1   \lim_{\substack{t\to L\\t<L}} f(0,t) =  -\beta'(0)  f Q \beta Q x Q R \beta t_1\in[0,L]  \beta(t_2)=\beta(t_1)+(t_2-t_1)\cdot\beta'(t_1) +(t_2-t_1)\cdot R(t_1,t_2-t_1)  \lim_{t\to0}R(t_1,t)=\mathbf0  \lim_{(t_1,t_2)\to(t_1^\ast,t_1^\ast)} \frac{\beta(t_2)-\beta(t_1)}{t_2-t_1} = \lim_{(t_1,t_2)\to(t_1^\ast,t_1^\ast)} (\beta'(t_1) + R(t_1,t_2-t_1)) \stackrel{\color{red}?}{=} \beta'(t_1^\ast)   \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} \frac{\|\beta(t_2)-\beta(t_1)\|}{t_2-t_1} = \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} \left\|\frac{\beta(t_2)-\beta(t_1)}{t_2-t_1}\right\| = \|\beta'(t_1^\ast)\|=1   \lim_{\substack{(t_1,t_2)\to(t_1^\ast,t_1^\ast)\\t_2>t_1}} f(t_1,t_2) = \beta'(t_1^\ast)  ","['real-analysis', 'differential-geometry', 'continuity']"
84,Identity Involving Lie Derivative and Local Flows,Identity Involving Lie Derivative and Local Flows,,"I'm trying to show, $$ \frac{d}{dt} \varphi_t^* \omega = \varphi_t^* \left( \mathcal{L}_{X_t} \omega \right)$$ but I have another question as well. Every case in which the lie derivative is mentioned, that notation $\mathcal{L}_{X_t}$ has never been given interpretation and so I would like to understand this notation first. Given $\frac{d}{dt}\bigr|_{t=0} \varphi_t = X_p = X_{\varphi_0(p)}$ and so $\frac{d}{dt} \varphi_t = X_{\varphi_t(p)}$ which we can call $X_t$ . And so, $$\mathcal{L}_{X_t} = \mathcal{L}_{\frac{d}{dt} \varphi_t}$$ Is this correct? Update: attempt to prove identity","I'm trying to show, but I have another question as well. Every case in which the lie derivative is mentioned, that notation has never been given interpretation and so I would like to understand this notation first. Given and so which we can call . And so, Is this correct? Update: attempt to prove identity", \frac{d}{dt} \varphi_t^* \omega = \varphi_t^* \left( \mathcal{L}_{X_t} \omega \right) \mathcal{L}_{X_t} \frac{d}{dt}\bigr|_{t=0} \varphi_t = X_p = X_{\varphi_0(p)} \frac{d}{dt} \varphi_t = X_{\varphi_t(p)} X_t \mathcal{L}_{X_t} = \mathcal{L}_{\frac{d}{dt} \varphi_t},"['differential-geometry', 'differential-topology', 'symplectic-geometry']"
85,Curvature of projection function onto smooth curve,Curvature of projection function onto smooth curve,,"Suppose we have a smooth curve $C$ lying in $\mathbb{R}^2$ , and let us consider the orthogonal projection function $P_C(x)$ onto the curve, described by $$P_C(x) = \arg\min_{y \in C} \Vert x - y \Vert$$ where $\Vert \cdot \Vert$ is a norm, it can be $\Vert \cdot \Vert_2^2$ , or $\Vert \cdot \Vert_1$ . My question is: is there a general relationship between the second derivative of $P_C(x)$ and the curvature of the curve $C$ ? For example, relationship between the norm, whether it is ""positive definite"", etc. If no, under what restrictions on the curve $C$ and/or location of $x$ can we say something about their relationships? Does there exist work that discusses this problem or some problems related to it? To visualize the problem somewhat, we consider the picture below: Denoting the blue curve as $C_1$ and black curve as $C_2$ , $C_1$ clearly has greater curvature than $C_2$ , but what about $\Vert D^2P_{C_1}(x) \Vert$ vs. $\Vert D^2P_{C_2}(x) \Vert$ ?","Suppose we have a smooth curve lying in , and let us consider the orthogonal projection function onto the curve, described by where is a norm, it can be , or . My question is: is there a general relationship between the second derivative of and the curvature of the curve ? For example, relationship between the norm, whether it is ""positive definite"", etc. If no, under what restrictions on the curve and/or location of can we say something about their relationships? Does there exist work that discusses this problem or some problems related to it? To visualize the problem somewhat, we consider the picture below: Denoting the blue curve as and black curve as , clearly has greater curvature than , but what about vs. ?",C \mathbb{R}^2 P_C(x) P_C(x) = \arg\min_{y \in C} \Vert x - y \Vert \Vert \cdot \Vert \Vert \cdot \Vert_2^2 \Vert \cdot \Vert_1 P_C(x) C C x C_1 C_2 C_1 C_2 \Vert D^2P_{C_1}(x) \Vert \Vert D^2P_{C_2}(x) \Vert,"['differential-geometry', 'reference-request', 'optimization', 'convex-analysis', 'convex-optimization']"
86,Gauss-bonnet just for geodesic triangles,Gauss-bonnet just for geodesic triangles,,"I have a question about some ways for proving the Gauss-Bonnet theorem just for small geodesic triangles. The general formula for the Gauss-Bonnet theorem is $$\iint_R KdS+\sum_{i=0}^k\int_{s_i}^{s_{i+1}} k_gds+\sum_{i=0}^k\theta_i=2\pi.$$ The ingredients here are a small portion $R$ of a surface $S$ , its boundary constituted by $k$ arcs (not necessarily geodesic arcs) and the ''exterior'' angles $\theta_i$ measured counterclockwise at the corner of the mentioned boundary, $K$ is the gaussian curvature of the surface and $k_g$ is the geodesic curvature of the portions of the boundary of $R$ . Of course, if we consider the region $R$ to be a small geodesic triangle $T$ , that is, it is contained in some small normal neighborhood of the surface and its boundary is the union of three small geodesic segments, we have the following nice version of Gauss-Bonnet formula $$\iint_T KdS=2\pi-\theta_1-\theta_2-\theta_3,$$ where the $\theta_i$ are just the external angles at the corners of the geodesic boundary triangle of $T$ . My question is, then: is there an elementary way to obtaining the ""geodesic triangle version"" above without using the ""complete version"" (for example, using Stoke's theorem)? Any reference will be of great help! Thanks in advance for all the community!","I have a question about some ways for proving the Gauss-Bonnet theorem just for small geodesic triangles. The general formula for the Gauss-Bonnet theorem is The ingredients here are a small portion of a surface , its boundary constituted by arcs (not necessarily geodesic arcs) and the ''exterior'' angles measured counterclockwise at the corner of the mentioned boundary, is the gaussian curvature of the surface and is the geodesic curvature of the portions of the boundary of . Of course, if we consider the region to be a small geodesic triangle , that is, it is contained in some small normal neighborhood of the surface and its boundary is the union of three small geodesic segments, we have the following nice version of Gauss-Bonnet formula where the are just the external angles at the corners of the geodesic boundary triangle of . My question is, then: is there an elementary way to obtaining the ""geodesic triangle version"" above without using the ""complete version"" (for example, using Stoke's theorem)? Any reference will be of great help! Thanks in advance for all the community!","\iint_R KdS+\sum_{i=0}^k\int_{s_i}^{s_{i+1}} k_gds+\sum_{i=0}^k\theta_i=2\pi. R S k \theta_i K k_g R R T \iint_T KdS=2\pi-\theta_1-\theta_2-\theta_3, \theta_i T","['differential-geometry', 'reference-request', 'curvature', 'geodesic', 'stokes-theorem']"
87,Definition of a submanifold of $\mathbb{R}^n$,Definition of a submanifold of,\mathbb{R}^n,"The definition of a submanifold of $\mathbb{R}^n$ I was given is the following: A subset $M \subseteq \mathbb{R}^n$ is called an $m$ -dimensional submanifold of $\mathbb{R}^n$ if for every point $x \in M$ there exists an open set $U \subseteq \mathbb{R}^n$ containing $x$ and an open subset $V\subseteq \mathbb{R}^n$ together with a diffeomorphism $\phi$ from $U$ to $V$ such that $\phi(M \cap U)=V \cap (\mathbb{R}^m \times \{0\})$ with $0 \in \mathbb{R}^{n-m}$ . I don't quite see why this captures the notion of ""a manifold of dimension $m$ locally looks like $\mathbb{R}^m$ "". If I was asked to make this notion rigorous, I'd define a submanifold of $\mathbb{R}^n$ as follows: A subset $M \subseteq \mathbb{R}^n$ is called an $m$ -dimensional submanifold of $\mathbb{R}^n$ if for every point $x \in M$ there exists an open set $U \subseteq M$ in the subspace topology and an open set $V \subseteq \mathbb{R}^m$ which is diffeomorphic to $U$ , that is there exists a diffeomorphism from $U$ to $V$ . Is there a difference between the two definitions? Isn't $\mathbb{R}^m \times \{0\})$ diffeomorphic to $\mathbb{R}^m$ ? Does it have something to do with wanting the Jacobi-matrix of the diffeomorphism to be invertible?","The definition of a submanifold of I was given is the following: A subset is called an -dimensional submanifold of if for every point there exists an open set containing and an open subset together with a diffeomorphism from to such that with . I don't quite see why this captures the notion of ""a manifold of dimension locally looks like "". If I was asked to make this notion rigorous, I'd define a submanifold of as follows: A subset is called an -dimensional submanifold of if for every point there exists an open set in the subspace topology and an open set which is diffeomorphic to , that is there exists a diffeomorphism from to . Is there a difference between the two definitions? Isn't diffeomorphic to ? Does it have something to do with wanting the Jacobi-matrix of the diffeomorphism to be invertible?",\mathbb{R}^n M \subseteq \mathbb{R}^n m \mathbb{R}^n x \in M U \subseteq \mathbb{R}^n x V\subseteq \mathbb{R}^n \phi U V \phi(M \cap U)=V \cap (\mathbb{R}^m \times \{0\}) 0 \in \mathbb{R}^{n-m} m \mathbb{R}^m \mathbb{R}^n M \subseteq \mathbb{R}^n m \mathbb{R}^n x \in M U \subseteq M V \subseteq \mathbb{R}^m U U V \mathbb{R}^m \times \{0\}) \mathbb{R}^m,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
88,Covariant derivative vs. Ehresmann connection,Covariant derivative vs. Ehresmann connection,,"I know about Ehresmann connections on fiber bundles and covariant derivatives as an (equivalent) way to define linear Ehresmann connections on vector bundles. My question is: Is there any notion of covariant derivative equivalent to Ehresmann connection in the most general setting concerning fiber bundles? When I say ""the most general setting"", I am emphasizing that the fiber bundle do not have any further structure than being just a fiber bundle (it may not be a vector bundle nor a principal bundle). Thanks in advance, Diego PS: I'm concerning the case when the fiber bundles are smooth. I don't worry about the non smooth case.","I know about Ehresmann connections on fiber bundles and covariant derivatives as an (equivalent) way to define linear Ehresmann connections on vector bundles. My question is: Is there any notion of covariant derivative equivalent to Ehresmann connection in the most general setting concerning fiber bundles? When I say ""the most general setting"", I am emphasizing that the fiber bundle do not have any further structure than being just a fiber bundle (it may not be a vector bundle nor a principal bundle). Thanks in advance, Diego PS: I'm concerning the case when the fiber bundles are smooth. I don't worry about the non smooth case.",,['differential-geometry']
89,Inheriting complex structure from a covering space (Griffiths and Harris),Inheriting complex structure from a covering space (Griffiths and Harris),,"On page 16 of Griffiths and Harris' Principles of algebraic geometry ,  they write In general, if $\pi: M\to N$ is a topological covering space and $N$ is a complex manifold, then $\pi$ gives $M$ the structure of a complex manifold as well; if $M$ is a complex manifold and the deck transformations of $M$ are holomorphic, then $N$ inherits the structure of a complex manifold from $M$ . My question is  for the last statement does one need more assumptions on the covering $\pi: M\to N$ ? Or could anyone please explain to me how to construct the complex structure on $N$ ?","On page 16 of Griffiths and Harris' Principles of algebraic geometry ,  they write In general, if is a topological covering space and is a complex manifold, then gives the structure of a complex manifold as well; if is a complex manifold and the deck transformations of are holomorphic, then inherits the structure of a complex manifold from . My question is  for the last statement does one need more assumptions on the covering ? Or could anyone please explain to me how to construct the complex structure on ?",\pi: M\to N N \pi M M M N M \pi: M\to N N,"['differential-geometry', 'complex-geometry', 'covering-spaces']"
90,Fundamental group of $M$ has no subgroup of index $2\Rightarrow M$ is orientable,Fundamental group of  has no subgroup of index  is orientable,M 2\Rightarrow M,"Let $M$ be a connected smooth manifold such that, for every $p\in M$, the fundamental group $\pi_1(M,p)$ has no subgroup of index $2$. Prove that $M$ is orientable. Here's what I know: there is a smooth, orientable manifold $\widetilde{M}$ and a covering map $\pi:\widetilde{M}\to M$ whose fibers have cardinality $2$, and such that $M$ is orientable $\Leftrightarrow\widetilde{M}$ is disconnected. Supposing by contradiction that $M$ is not orientable, $\widetilde{M}$ must be connected. I suppose the ""subgroup of index $2$"" part has to do with the fact that the fibers have cardinality $2$, and probably $\widetilde{M}$ being connected also plays a role. I don't know much about covering spaces except for basic definitions, so I'm pretty much stuck.","Let $M$ be a connected smooth manifold such that, for every $p\in M$, the fundamental group $\pi_1(M,p)$ has no subgroup of index $2$. Prove that $M$ is orientable. Here's what I know: there is a smooth, orientable manifold $\widetilde{M}$ and a covering map $\pi:\widetilde{M}\to M$ whose fibers have cardinality $2$, and such that $M$ is orientable $\Leftrightarrow\widetilde{M}$ is disconnected. Supposing by contradiction that $M$ is not orientable, $\widetilde{M}$ must be connected. I suppose the ""subgroup of index $2$"" part has to do with the fact that the fibers have cardinality $2$, and probably $\widetilde{M}$ being connected also plays a role. I don't know much about covering spaces except for basic definitions, so I'm pretty much stuck.",,"['differential-geometry', 'smooth-manifolds', 'fundamental-groups', 'orientation']"
91,Pointwise conformal vs. conformally diffeomorphic metrics in dimension 2,Pointwise conformal vs. conformally diffeomorphic metrics in dimension 2,,"Let $g$ be any Riemannian metric on the 2-sphere $S^2$ and let $g_0$ be the round metric (of constant curvature $K$, say). Is it true that there exists a smooth positive function $\lambda:S^2\to \mathbb{R}$ such that $g_0=\lambda^2g$? The version of the uniformization theorem that I am familiar with implies that there exists a diffeomorphism $f:S^2\to S^2$ and a smooth function $u:S^2\to \mathbb{R}$ such that the pullback metric $f^{\ast}g$ is conformal to the round metric, i.e. such that $g_0=u^2(f^{\ast}g)$. So my question is equivalent to the following question: can the diffeomorphism $f$ be taken to be the identity? The reason I think this might be true is that a 2-dimensional manifold has constant curvature iff it has constant scalar curvature. For $n\geq 3$, any metric on a closed $n$-manifold is pointwise conformal to a metric with constant scalar curvature (by the solution of the Yamabe problem). Does this also hold for $n=2$ and/or specifically $S^2$?","Let $g$ be any Riemannian metric on the 2-sphere $S^2$ and let $g_0$ be the round metric (of constant curvature $K$, say). Is it true that there exists a smooth positive function $\lambda:S^2\to \mathbb{R}$ such that $g_0=\lambda^2g$? The version of the uniformization theorem that I am familiar with implies that there exists a diffeomorphism $f:S^2\to S^2$ and a smooth function $u:S^2\to \mathbb{R}$ such that the pullback metric $f^{\ast}g$ is conformal to the round metric, i.e. such that $g_0=u^2(f^{\ast}g)$. So my question is equivalent to the following question: can the diffeomorphism $f$ be taken to be the identity? The reason I think this might be true is that a 2-dimensional manifold has constant curvature iff it has constant scalar curvature. For $n\geq 3$, any metric on a closed $n$-manifold is pointwise conformal to a metric with constant scalar curvature (by the solution of the Yamabe problem). Does this also hold for $n=2$ and/or specifically $S^2$?",,"['differential-geometry', 'riemannian-geometry']"
92,Is the image of an equivariant map always a weakly embedded submanifold?,Is the image of an equivariant map always a weakly embedded submanifold?,,"Let $M,N$ be smooth manifolds, with a smooth $G$-action on them, by some Lie group $G$. Suppose also that $M$ has a finite number of orbits under $G$'s-action. Let $f:M \to N$ be a smooth, equivariant, injective immersion . Is $f(M)$ a weakly embedded submanifold of $N$? Weakly embedded here means that for every manifold $Q$ and for every smooth map $h:Q \to N$, with $h(Q)\subset f(M)$,the associated map $h:Q\to f(M)$ is also smooth. In other words, it's always valid to restrict the range. It is known that it suffices to prove that $h:Q\to f(M)$ is continuous. Note that in general $f(M)$ is only an immersed submanifold. In particular, it can have more open sets than those that come from the subspace topology. Weakly embedded is a notion which is between ""immersed"" and ""embedded"". It is also known that every Lie subgroup is weakly embedded. A famous example for a weakly embedded submanifold, which is not embedded is the dense curve on the torus . (In that case, there is also a Lie group action in the background, by $\mathbb{R}$).","Let $M,N$ be smooth manifolds, with a smooth $G$-action on them, by some Lie group $G$. Suppose also that $M$ has a finite number of orbits under $G$'s-action. Let $f:M \to N$ be a smooth, equivariant, injective immersion . Is $f(M)$ a weakly embedded submanifold of $N$? Weakly embedded here means that for every manifold $Q$ and for every smooth map $h:Q \to N$, with $h(Q)\subset f(M)$,the associated map $h:Q\to f(M)$ is also smooth. In other words, it's always valid to restrict the range. It is known that it suffices to prove that $h:Q\to f(M)$ is continuous. Note that in general $f(M)$ is only an immersed submanifold. In particular, it can have more open sets than those that come from the subspace topology. Weakly embedded is a notion which is between ""immersed"" and ""embedded"". It is also known that every Lie subgroup is weakly embedded. A famous example for a weakly embedded submanifold, which is not embedded is the dense curve on the torus . (In that case, there is also a Lie group action in the background, by $\mathbb{R}$).",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'submanifold', 'equivariant-maps']"
93,Is every conformal diffeomorphism isotop (or homotop) to an isometry?,Is every conformal diffeomorphism isotop (or homotop) to an isometry?,,Assume that $M$ is  a  compact simply  connected Riemannian manifold and  $f$ is a  conformal  diffeomeorphism of  $M$. Is it true  to  say that  $f$ is  homotopic (or  isotopic) to  an  isometry of  $M$? What would  be the  answer  if  we drop the  simply  connected assumption?,Assume that $M$ is  a  compact simply  connected Riemannian manifold and  $f$ is a  conformal  diffeomeorphism of  $M$. Is it true  to  say that  $f$ is  homotopic (or  isotopic) to  an  isometry of  $M$? What would  be the  answer  if  we drop the  simply  connected assumption?,,"['differential-geometry', 'riemannian-geometry', 'homotopy-theory', 'conformal-geometry']"
94,Angular rates components order from time-derivative of rotation matrix,Angular rates components order from time-derivative of rotation matrix,,"I'm currently confused at the moment about the components order obtained from a well-known relationship between derivative of a rotation matrix and its angular velocity: $\dot{R} = R \hat{\Omega}$. I constructed the rotation matrix $R$ from consecutive rotations around $Z,Y,X$ axis using the formulae given in https://en.wikipedia.org/wiki/Euler_angles . So is it true that the $\Omega$ vector (whose skew-symmetric form is $\hat{\Omega}$) will be $[\omega_z,\omega_y,\omega_x]^T$? Moreover, if $R$ is a rotation matrix from frame $B$ to frame $A$, is $\Omega$ angular rate written with respect to frame  $B$? I'd very grateful to hear from you. Thanks in advance.","I'm currently confused at the moment about the components order obtained from a well-known relationship between derivative of a rotation matrix and its angular velocity: $\dot{R} = R \hat{\Omega}$. I constructed the rotation matrix $R$ from consecutive rotations around $Z,Y,X$ axis using the formulae given in https://en.wikipedia.org/wiki/Euler_angles . So is it true that the $\Omega$ vector (whose skew-symmetric form is $\hat{\Omega}$) will be $[\omega_z,\omega_y,\omega_x]^T$? Moreover, if $R$ is a rotation matrix from frame $B$ to frame $A$, is $\Omega$ angular rate written with respect to frame  $B$? I'd very grateful to hear from you. Thanks in advance.",,"['differential-geometry', 'rotations', 'control-theory', 'classical-mechanics']"
95,Show that ∂(M×N)=M × ∂N.,Show that ∂(M×N)=M × ∂N.,,"Let M smooth manifolds (without boundary) and N is a smooth manifold with boundary. Could someone help me to show that $∂(M × N) = M × ∂N$? I saw a suggestion here on the site how to do it, but I'm stalling. ps.: sorry, I know that already asked something similar to this problem, but I'm not able to do it.","Let M smooth manifolds (without boundary) and N is a smooth manifold with boundary. Could someone help me to show that $∂(M × N) = M × ∂N$? I saw a suggestion here on the site how to do it, but I'm stalling. ps.: sorry, I know that already asked something similar to this problem, but I'm not able to do it.",,"['differential-geometry', 'manifolds', 'differential-topology', 'manifolds-with-boundary']"
96,Cross product in $\mathbb R^n$ (from Spivak's book),Cross product in  (from Spivak's book),\mathbb R^n,"Spivak defines cross product in this way: $\quad$ We conclude this section with a construction which we will restrict to $\mathbf{R}^n$. If $v_1,\ldots,v_{n-1}\in\mathbf{R}^n$ and $\varphi$ is defined by $$\varphi(w)=\det\pmatrix{v_1 \\ \vdots \\ v_{n-1} \\ w},$$ then $\varphi\in\Lambda^1(\mathbf{R}^n)$; therefore there is a unique $z\in\mathbf{R}^n$ such that $$\langle w,z\rangle=\varphi(w)=\det\pmatrix{v_1 \\ \vdots \\ v_{n-1} \\ w}$$ This $z$ is denoted $v_1\times\cdots\times v_{n-1}$ and called the cross product of $v_1,\ldots,v_{n-1}$. Why such a $z$ exists and why is it unique? When solving problems involving this notion, how do I find this $z$ explicitly (if it's possible)? Also, what's the meaning of this cross product? Many sources say that the usual cross product in $\mathbb R^3$ can't be generalized to higher dimensions.","Spivak defines cross product in this way: $\quad$ We conclude this section with a construction which we will restrict to $\mathbf{R}^n$. If $v_1,\ldots,v_{n-1}\in\mathbf{R}^n$ and $\varphi$ is defined by $$\varphi(w)=\det\pmatrix{v_1 \\ \vdots \\ v_{n-1} \\ w},$$ then $\varphi\in\Lambda^1(\mathbf{R}^n)$; therefore there is a unique $z\in\mathbf{R}^n$ such that $$\langle w,z\rangle=\varphi(w)=\det\pmatrix{v_1 \\ \vdots \\ v_{n-1} \\ w}$$ This $z$ is denoted $v_1\times\cdots\times v_{n-1}$ and called the cross product of $v_1,\ldots,v_{n-1}$. Why such a $z$ exists and why is it unique? When solving problems involving this notion, how do I find this $z$ explicitly (if it's possible)? Also, what's the meaning of this cross product? Many sources say that the usual cross product in $\mathbb R^3$ can't be generalized to higher dimensions.",,"['calculus', 'real-analysis', 'linear-algebra', 'differential-geometry', 'manifolds']"
97,Calculation of traceless second fundamental form,Calculation of traceless second fundamental form,,"The traceless part of second fundamental form is  $$ \mathring A = A -\frac{H}{n}g $$ where $A$ is second fundamental form, $H$ is mean curvature, $g$ is metric. The norm square is  $$ |\mathring A|^2 = |A|^2-\frac{1}{n}H^2. $$ I want to verify it. What I do: \begin{align} |\mathring A|^2  &=g^{ij}g^{kl}\mathring A_{ik}\mathring A_{jl}  \\ &=g^{ij}g^{kl}(A_{ik} -\frac{H}{n}g_{ik})(A_{jl} -\frac{H}{n}g_{jl})  \\ &=g^{ij}g^{kl} (A_{ik}A_{jl}-\frac{H}{n}g_{ik}A_{jl} -\frac{H}{n}g_{jl}A_{ik} +(\frac{H}{n})^2g_{ik}g_{jl})  \\ &=|A|^2 -\frac{2H}{n}g^{ij}A_{ij} + (\frac{H}{n})^2\delta_k^j\delta_j^k \end{align} Then, I don't know how to deal it. I can't think though why $\delta_k^j\delta_j^k =n$ and what is $g^{ij}A_{ij}$.","The traceless part of second fundamental form is  $$ \mathring A = A -\frac{H}{n}g $$ where $A$ is second fundamental form, $H$ is mean curvature, $g$ is metric. The norm square is  $$ |\mathring A|^2 = |A|^2-\frac{1}{n}H^2. $$ I want to verify it. What I do: \begin{align} |\mathring A|^2  &=g^{ij}g^{kl}\mathring A_{ik}\mathring A_{jl}  \\ &=g^{ij}g^{kl}(A_{ik} -\frac{H}{n}g_{ik})(A_{jl} -\frac{H}{n}g_{jl})  \\ &=g^{ij}g^{kl} (A_{ik}A_{jl}-\frac{H}{n}g_{ik}A_{jl} -\frac{H}{n}g_{jl}A_{ik} +(\frac{H}{n})^2g_{ik}g_{jl})  \\ &=|A|^2 -\frac{2H}{n}g^{ij}A_{ij} + (\frac{H}{n})^2\delta_k^j\delta_j^k \end{align} Then, I don't know how to deal it. I can't think though why $\delta_k^j\delta_j^k =n$ and what is $g^{ij}A_{ij}$.",,"['differential-geometry', 'riemannian-geometry']"
98,Do (closed) Riemannian manifolds admit anti-self-adjoint vector fields (locally or globally)?,Do (closed) Riemannian manifolds admit anti-self-adjoint vector fields (locally or globally)?,,"We have the following set up. Let $(M^n,g)$ be a (possibly closed) Riemannian manifold, then a vector field $X\in\mathcal{T}(M)$ is said to be anti-self-adjoint if for any $\phi,\eta\in\mathscr{C}_0^\infty(M)$, we have the identity  $$ \int_M\phi(X\eta)\,\mathrm d\mu_g = -\int_M(X\phi)\eta\,\mathrm d\mu_g. $$ Note that $\mathbb T^n$ admits a global tangent frame of anti-self-adjoint vector fields. But can we find any anti-self-adjoint vector fields in general, or at least locally (i.e. imposing that $\phi$ and $\eta$ vanish outside of some neighborhood)?","We have the following set up. Let $(M^n,g)$ be a (possibly closed) Riemannian manifold, then a vector field $X\in\mathcal{T}(M)$ is said to be anti-self-adjoint if for any $\phi,\eta\in\mathscr{C}_0^\infty(M)$, we have the identity  $$ \int_M\phi(X\eta)\,\mathrm d\mu_g = -\int_M(X\phi)\eta\,\mathrm d\mu_g. $$ Note that $\mathbb T^n$ admits a global tangent frame of anti-self-adjoint vector fields. But can we find any anti-self-adjoint vector fields in general, or at least locally (i.e. imposing that $\phi$ and $\eta$ vanish outside of some neighborhood)?",,"['differential-geometry', 'riemannian-geometry']"
99,Moment maps unitary group acting on matrices,Moment maps unitary group acting on matrices,,"I am reading the fifth chapter of ""An introduction to extremal Kaehler metrics"" by Gabor Szekelyhidi. At the very beginning of that chapter, the author describes moment maps and Hamiltonian action. Here is a short description: Suppose that a connected Lie group $G$ acts on a Kaehler manifold $M$ preserving the Kaehler form $\omega.$ The derivative of the action gives rise to a Lie algebra map $$ \rho: \mathfrak{g} \rightarrow \mathfrak{X}(M)$$ Where $\mathfrak{g}$ is the Lie algebra of $G$ and $\mathfrak{X}$ is the algebra of vector fields on $M.$ Then the action of $G$ on $M$ is said to be Hamiltonian if there exists a $G-$ equivariant map $$ \mu: M \rightarrow \mathfrak{g}^{*} $$ such that for any $\xi \in \mathfrak{g}$ the function $\langle\mu, \xi\rangle$ is a hamiltonian function for the vector field $\rho(\xi):$ $$ d\langle\mu, \xi\rangle = -\iota_{\rho(\xi)} \omega. $$ I got stuck with the following exercise: Let $M_n$ be the set of $n \times n$ complex matrices equipped with the Euclidean metric under the identification $M_n=\mathbb{C}^{n^2}.$ The unitary matrices $U(n)$ act on $M_n$ by conjugation, preserving this metric. I.e. $A \in U(n)$ acts by $M \mapsto A^{-1}MA.$ Find a moment map $\mu: M_n \rightarrow \mathfrak{u}(n)^{*}.$ So far, I've just noticed that if $n=1$ then the action of $U(1)$ by conjugation on complex number is the trivial action, what will be then the moment map? I am trying to see what happens also in dimension 2. I know that $\mathfrak{u}(2)$ is generated by skew-Hermitian matrices, so every skew-hermitian matrix can be diagonalized and the eigenvalues must be pure imaginary. How to find a moment map in this case?","I am reading the fifth chapter of ""An introduction to extremal Kaehler metrics"" by Gabor Szekelyhidi. At the very beginning of that chapter, the author describes moment maps and Hamiltonian action. Here is a short description: Suppose that a connected Lie group acts on a Kaehler manifold preserving the Kaehler form The derivative of the action gives rise to a Lie algebra map Where is the Lie algebra of and is the algebra of vector fields on Then the action of on is said to be Hamiltonian if there exists a equivariant map such that for any the function is a hamiltonian function for the vector field I got stuck with the following exercise: Let be the set of complex matrices equipped with the Euclidean metric under the identification The unitary matrices act on by conjugation, preserving this metric. I.e. acts by Find a moment map So far, I've just noticed that if then the action of by conjugation on complex number is the trivial action, what will be then the moment map? I am trying to see what happens also in dimension 2. I know that is generated by skew-Hermitian matrices, so every skew-hermitian matrix can be diagonalized and the eigenvalues must be pure imaginary. How to find a moment map in this case?","G M \omega.  \rho: \mathfrak{g} \rightarrow \mathfrak{X}(M) \mathfrak{g} G \mathfrak{X} M. G M G-  \mu: M \rightarrow \mathfrak{g}^{*}  \xi \in \mathfrak{g} \langle\mu, \xi\rangle \rho(\xi):  d\langle\mu, \xi\rangle = -\iota_{\rho(\xi)} \omega.  M_n n \times n M_n=\mathbb{C}^{n^2}. U(n) M_n A \in U(n) M \mapsto A^{-1}MA. \mu: M_n \rightarrow \mathfrak{u}(n)^{*}. n=1 U(1) \mathfrak{u}(2)","['differential-geometry', 'complex-geometry', 'kahler-manifolds', 'geometric-invariant-theory', 'moment-map']"
