,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Short Exact Sequences & Rank Nullity,Short Exact Sequences & Rank Nullity,,"This is a well known lemma that consistently appears in textbooks, either as a statement without proof, or as an exercise (see for example pp. 146 of Hatcher) If $0 \stackrel{id}{\to} A \stackrel{f}{\to} B \stackrel{g}{\to} C\stackrel{h}{\to} 0$ is a short exact sequence of finitely generated abelian groups, then $\operatorname{rank} B = \operatorname{rank} A + \operatorname{rank} C$ . I've been trying to prove this unsuccessfully. What do we know? $f$ is injective, $g$ is surjective, $\mathrm{Im} f = \mathrm{ker} g$ , $\mathrm{Im} g = \mathrm{ker} h$ , $C\simeq B/A$ So I start with a maximally linearly independent subset $\{ a_\alpha \}$ of $A$ such that the sum (with only finite non-zero entries) $$\sum n_\alpha a_\alpha=0$$ for $n_\alpha \in \mathbb{Z}$ , implies that $n_\alpha=0$ . Where to go from here is a puzzle? Any hints would be appreciated","This is a well known lemma that consistently appears in textbooks, either as a statement without proof, or as an exercise (see for example pp. 146 of Hatcher) If is a short exact sequence of finitely generated abelian groups, then . I've been trying to prove this unsuccessfully. What do we know? is injective, is surjective, , , So I start with a maximally linearly independent subset of such that the sum (with only finite non-zero entries) for , implies that . Where to go from here is a puzzle? Any hints would be appreciated",0 \stackrel{id}{\to} A \stackrel{f}{\to} B \stackrel{g}{\to} C\stackrel{h}{\to} 0 \operatorname{rank} B = \operatorname{rank} A + \operatorname{rank} C f g \mathrm{Im} f = \mathrm{ker} g \mathrm{Im} g = \mathrm{ker} h C\simeq B/A \{ a_\alpha \} A \sum n_\alpha a_\alpha=0 n_\alpha \in \mathbb{Z} n_\alpha=0,"['abstract-algebra', 'group-theory', 'modules', 'homological-algebra', 'exact-sequence']"
1,"Presentation $\langle x,y,z\mid xyx^{-1}y^{-2},yzy^{-1}z^{-2},zxz^{-1}x^{-2}\rangle$ of group equal to trivial group",Presentation  of group equal to trivial group,"\langle x,y,z\mid xyx^{-1}y^{-2},yzy^{-1}z^{-2},zxz^{-1}x^{-2}\rangle","Problem: Show that the group given by the presentation $$\langle x,y,z  \mid xyx^{-1}y^{-2}\, , \, yzy^{-1}z^{-2}\, , \, zxz^{-1}x^{-2} \rangle $$ is equivalent to the trivial group. I have tried all sorts of manners to try to show that the relations given by the presentation above imply that $x=y=z=e$. However, I am stuck and would appreciate any hints as to how I should move forward.","Problem: Show that the group given by the presentation $$\langle x,y,z  \mid xyx^{-1}y^{-2}\, , \, yzy^{-1}z^{-2}\, , \, zxz^{-1}x^{-2} \rangle $$ is equivalent to the trivial group. I have tried all sorts of manners to try to show that the relations given by the presentation above imply that $x=y=z=e$. However, I am stuck and would appreciate any hints as to how I should move forward.",,"['abstract-algebra', 'group-theory', 'algebraic-topology', 'group-presentation']"
2,Can linear maps between infinite-dimensional spaces be represented as matrices?,Can linear maps between infinite-dimensional spaces be represented as matrices?,,"Any linear map between two finite-dimensional vector spaces can be represented as a matrix under the bases of the two spaces. But if one or all of the vector spaces is infinite dimensional, is the linear map still represented as a matrix under their bases? If there is matrix of infinite dimension, what is it used for if not used as a representation of a linear map between vector spaces? Thanks and regards!","Any linear map between two finite-dimensional vector spaces can be represented as a matrix under the bases of the two spaces. But if one or all of the vector spaces is infinite dimensional, is the linear map still represented as a matrix under their bases? If there is matrix of infinite dimension, what is it used for if not used as a representation of a linear map between vector spaces? Thanks and regards!",,"['abstract-algebra', 'matrices', 'vector-spaces', 'infinite-matrices']"
3,Motivation behind the definition of GCD and LCM,Motivation behind the definition of GCD and LCM,,"According to me, I can find the GCD of two integers (say $a$ and $b$) by finding all the common factors of them, and then finding the maximum of all these common factors. This also justifies the terminology greatest common divisor . However, the general definition used is that $d$ is said to be a GCD of $a$ and $b$ if $d$ divides both $a$ and $b$; and, If $d'$ also divides both $a$ and $b$, then $d'$ divides $d$. My question is that why do we usually accept the second definition over the first. To me the first one seems very intuitive and simple, and does justice to the terminology. The same query goes for LCM as well. Looking forward to your response. Thank you!","According to me, I can find the GCD of two integers (say $a$ and $b$) by finding all the common factors of them, and then finding the maximum of all these common factors. This also justifies the terminology greatest common divisor . However, the general definition used is that $d$ is said to be a GCD of $a$ and $b$ if $d$ divides both $a$ and $b$; and, If $d'$ also divides both $a$ and $b$, then $d'$ divides $d$. My question is that why do we usually accept the second definition over the first. To me the first one seems very intuitive and simple, and does justice to the terminology. The same query goes for LCM as well. Looking forward to your response. Thank you!",,"['abstract-algebra', 'number-theory', 'elementary-number-theory', 'gcd-and-lcm', 'motivation']"
4,Number of subgroups of prime order,Number of subgroups of prime order,,"I've been doing some exercises from my introductory algebra text and came across a problem which I reduced to proving that: The number of distinct subgroups of prime order $p$ of a finite group $G$ is either $0$ or congruent to $1\pmod{p} $. With my little experience I was unable to overcome this (all I was able to conclude is that these groups are disjoint short of the identity), and also did not find any solution with a search on google (except for stronger theorems which I am not interested in because of my novice level). I remember that a similar result is widely known as one of Sylow Theorems. This result was proven by the use of group actions. But can my problem be proved without using the concept of group actions? Can this be proven WITH the use of that concept? EDIT: With help from comments I came up with this: The action Derek proposed is well-defined largely because in a group if $ab = e$ (the identity), then certainly $ba = e$. By Orbit-Stabilizer Theorem we can see that all orbits are either of size 1 or $p$ (here I had most problems, and found out cyclic group of order $p$ acts on the set of solutions in the same way). The orbits of size 1 contain precisely the elements $(x,x,x....,x)$ for some element x in G. In addition, orders of all orbits add up to $|G|^{(p-1)}$ because the orbits are equivalence classes of an equivalence relation. But certainly $(e,e,e....,e)$ is in an orbit of size 1, and that means there has to be more orbits of exactly one element, actually $p-1 + np$ more for some integer $n$. These elements form the disjoint groups I am looking for. if $p-1$ divides $(p-1 + np)$, it's easy to check the result is 1 mod p. Could someone check if I understood this correctly?","I've been doing some exercises from my introductory algebra text and came across a problem which I reduced to proving that: The number of distinct subgroups of prime order $p$ of a finite group $G$ is either $0$ or congruent to $1\pmod{p} $. With my little experience I was unable to overcome this (all I was able to conclude is that these groups are disjoint short of the identity), and also did not find any solution with a search on google (except for stronger theorems which I am not interested in because of my novice level). I remember that a similar result is widely known as one of Sylow Theorems. This result was proven by the use of group actions. But can my problem be proved without using the concept of group actions? Can this be proven WITH the use of that concept? EDIT: With help from comments I came up with this: The action Derek proposed is well-defined largely because in a group if $ab = e$ (the identity), then certainly $ba = e$. By Orbit-Stabilizer Theorem we can see that all orbits are either of size 1 or $p$ (here I had most problems, and found out cyclic group of order $p$ acts on the set of solutions in the same way). The orbits of size 1 contain precisely the elements $(x,x,x....,x)$ for some element x in G. In addition, orders of all orbits add up to $|G|^{(p-1)}$ because the orbits are equivalence classes of an equivalence relation. But certainly $(e,e,e....,e)$ is in an orbit of size 1, and that means there has to be more orbits of exactly one element, actually $p-1 + np$ more for some integer $n$. These elements form the disjoint groups I am looking for. if $p-1$ divides $(p-1 + np)$, it's easy to check the result is 1 mod p. Could someone check if I understood this correctly?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'self-learning']"
5,The units of $\mathbb Z[\sqrt{2}]$,The units of,\mathbb Z[\sqrt{2}],"How can I show that the units $u$ of $R=\mathbb Z[\sqrt{2}]$ with $u>1$ are $(1+ \sqrt{2})^{n}$ ? I have proved that the right ones are units because their module is one, and it is said to me to do it by induction on $b$ and multiplication by $-1+\sqrt{2}$. I have already shown that the units of this ring has norm $1$ and all the numbers with norm $1$ are units, this may help.","How can I show that the units $u$ of $R=\mathbb Z[\sqrt{2}]$ with $u>1$ are $(1+ \sqrt{2})^{n}$ ? I have proved that the right ones are units because their module is one, and it is said to me to do it by induction on $b$ and multiplication by $-1+\sqrt{2}$. I have already shown that the units of this ring has norm $1$ and all the numbers with norm $1$ are units, this may help.",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
6,Why is abstract algebra so important?,Why is abstract algebra so important?,,"In my studies of physics and mathematics, I have encountered a fair bit of geometry, Lie group and representation theory, and real and complex analysis and I understand why these branches of mathematics are important.  But I have learned very few applications of ring theory or other abstract algebra outside abstract algebra itself (save a few in number theory). At the same time, I believe it is considered vital for any aspiring mathematician to learn graduate level abstract algebra. Why is abstract algebra considered to be so important? Examples of applications outside abstract algebra and outside mathematics would be appreciated. To narrow the scope of the question down a bit, I am specifically asking about the theory of rings, fields, etc. I realize that the term 'abstract algebra' is a bit broader than what I intended.","In my studies of physics and mathematics, I have encountered a fair bit of geometry, Lie group and representation theory, and real and complex analysis and I understand why these branches of mathematics are important.  But I have learned very few applications of ring theory or other abstract algebra outside abstract algebra itself (save a few in number theory). At the same time, I believe it is considered vital for any aspiring mathematician to learn graduate level abstract algebra. Why is abstract algebra considered to be so important? Examples of applications outside abstract algebra and outside mathematics would be appreciated. To narrow the scope of the question down a bit, I am specifically asking about the theory of rings, fields, etc. I realize that the term 'abstract algebra' is a bit broader than what I intended.",,"['abstract-algebra', 'soft-question']"
7,"Is there a reason why $Z(G)$ is named the ""centre"" of a group?","Is there a reason why  is named the ""centre"" of a group?",Z(G),I just stumbled upon the definition of the center Z of a group G: $$Z= \{x \in G \mid xz = zx \text{ for all } z \in G\}$$ The name “center” seems to suggest that there is some kind of geometric interpretation of the concept which I fail to see. My question is the following: is there some intuition/motivation behind the choice of naming $Z$ the “center” of a group?,I just stumbled upon the definition of the center Z of a group G: The name “center” seems to suggest that there is some kind of geometric interpretation of the concept which I fail to see. My question is the following: is there some intuition/motivation behind the choice of naming the “center” of a group?,Z= \{x \in G \mid xz = zx \text{ for all } z \in G\} Z,"['abstract-algebra', 'group-theory']"
8,What is this 2D division algebra?,What is this 2D division algebra?,,"Consider the set $A$ of 2-tuples of real values $(a,b)$, equipped with an addition defined as $$ (a,b) + (c,d) = (a+c,b+d)$$ and multiplication defined as $$ (a,b) \times (c,d) = (ac+bd,ad-bc).$$ What is this weird little thing? This algebra has some nice properties. For instance: on both sides multiplication distributes across addition, because the multiplication is bilinear it is a division algebra, as there are no zero divisors a subset is isomorphic to the reals,  $(a,0) \leftrightarrow a$ has a positive definite quadratic form $$ (a,b)\times(a,b) = (a^2+b^2,0) $$ identity on left, $(1,0)\times(a,b) = (a,b)$ But it has some weird properties: there is no identity for multiplication on the right $z=(0,1)$ anti-commutes with the subset noted above as being isomorphic to the reals $$ (a,0)\times z + z \times (a,0) = (0,0)$$ the multiplication is not associative the multiplication is not even power associative, as seen with $z=(0,1)$, $$ z\times(z\times z) = -(z\times z)\times z$$ the center is trivial, as only $(0,0)$ commutes with all elements. So I'm not sure on the terminology, but this can also be viewed as ""extending"" the Reals with an exotic sqrt of 1,  $$ z^2 = 1,$$ which anti-commutes with multiplication of reals, $$\forall a \in \mathbb{R} : az+za=0.$$ Then the set $A = \{a+bz : a,b \in \mathbb{R}\}$. After playing with it a bit I realized it can also be viewed as taking the complex numbers and defining the operation:  $$x \times y = x^*\ y$$ Which means this is also like taking a 1D complex Hilbert space, and treating the inner product as if it is a multiplication because in this case the scalar and vector are the same dimension. This bizarre little thing is simple enough that I assume it has been studied before. Does it have a name? Also, regardless if it has a name, I'd like to know the proper terminology for describing this. Because of the relation to complex numbers, would mathematicians consider it ""just the complex numbers"" since the operations can be represented with complex numbers? It at least isn't isomorphic to the complex numbers, correct? Would you consider this a 2D real division algebra distinct from the complex numbers? Since the structure was defined in terms of operations on the reals, and the elements are a tuple of reals, it feels like this would be some-object ""over the Reals"". Maybe a left semimodule over the Reals. Or does the phrase ""over the reals"" require that the Reals commute with everything? Similarly, if you object to my use of terminology in the discussion of the properties, I'd appreciate if you could point that out and suggest more reasonable terminology with explanation.","Consider the set $A$ of 2-tuples of real values $(a,b)$, equipped with an addition defined as $$ (a,b) + (c,d) = (a+c,b+d)$$ and multiplication defined as $$ (a,b) \times (c,d) = (ac+bd,ad-bc).$$ What is this weird little thing? This algebra has some nice properties. For instance: on both sides multiplication distributes across addition, because the multiplication is bilinear it is a division algebra, as there are no zero divisors a subset is isomorphic to the reals,  $(a,0) \leftrightarrow a$ has a positive definite quadratic form $$ (a,b)\times(a,b) = (a^2+b^2,0) $$ identity on left, $(1,0)\times(a,b) = (a,b)$ But it has some weird properties: there is no identity for multiplication on the right $z=(0,1)$ anti-commutes with the subset noted above as being isomorphic to the reals $$ (a,0)\times z + z \times (a,0) = (0,0)$$ the multiplication is not associative the multiplication is not even power associative, as seen with $z=(0,1)$, $$ z\times(z\times z) = -(z\times z)\times z$$ the center is trivial, as only $(0,0)$ commutes with all elements. So I'm not sure on the terminology, but this can also be viewed as ""extending"" the Reals with an exotic sqrt of 1,  $$ z^2 = 1,$$ which anti-commutes with multiplication of reals, $$\forall a \in \mathbb{R} : az+za=0.$$ Then the set $A = \{a+bz : a,b \in \mathbb{R}\}$. After playing with it a bit I realized it can also be viewed as taking the complex numbers and defining the operation:  $$x \times y = x^*\ y$$ Which means this is also like taking a 1D complex Hilbert space, and treating the inner product as if it is a multiplication because in this case the scalar and vector are the same dimension. This bizarre little thing is simple enough that I assume it has been studied before. Does it have a name? Also, regardless if it has a name, I'd like to know the proper terminology for describing this. Because of the relation to complex numbers, would mathematicians consider it ""just the complex numbers"" since the operations can be represented with complex numbers? It at least isn't isomorphic to the complex numbers, correct? Would you consider this a 2D real division algebra distinct from the complex numbers? Since the structure was defined in terms of operations on the reals, and the elements are a tuple of reals, it feels like this would be some-object ""over the Reals"". Maybe a left semimodule over the Reals. Or does the phrase ""over the reals"" require that the Reals commute with everything? Similarly, if you object to my use of terminology in the discussion of the properties, I'd appreciate if you could point that out and suggest more reasonable terminology with explanation.",,"['abstract-algebra', 'division-algebras']"
9,Proof that no permutation can be expressed both as the product of an even number of transpositions and as a product of an odd number of transpositions,Proof that no permutation can be expressed both as the product of an even number of transpositions and as a product of an odd number of transpositions,,"I am aware that there are a couple of well-known proofs of this theorem, but I'm specifically grappling with the proof given in Fraleigh's A First Course in Abstract Algebra (Theorem 9.15 in the textbook). Let $s$ be a permutation in the symmetric group of degree $n$, and let $t$ be a transposition $(i,j)$ in the same group. If $n$ is $1$ or infinite, we are done. Otherwise, ....[details of the proof omitted.] (We use the right-to-left convention to multiply permutations.) Okay, we have shown that the number of orbits of $s$ and $ts$ differ by 1. This part, I understand. But I don't understand how to infer the theorem from here. I would be very grateful if someone can help me clear my blind spot. Thank you so much! Added by Dylan. Here is Fraleigh's explanation (please don't sue me): We have shown that the number of orbits of $\tau \sigma$ differs from the number of orbits of $\sigma$ by $1$. The identity permutation $\iota$ has $n$ orbits, because each element is the only member of its orbit. Now the number of orbits of a given permutation $\sigma \in S_n$ differs from $n$ by either an even or odd number, but not both. Thus it is impossible to write    $$ \sigma = \tau_1 \tau_2 \cdots \tau_m \iota $$   where the $\tau_k$ are transpositions, in two ways, once with $m$ even and once with $m$ odd.  $\qquad \diamond$","I am aware that there are a couple of well-known proofs of this theorem, but I'm specifically grappling with the proof given in Fraleigh's A First Course in Abstract Algebra (Theorem 9.15 in the textbook). Let $s$ be a permutation in the symmetric group of degree $n$, and let $t$ be a transposition $(i,j)$ in the same group. If $n$ is $1$ or infinite, we are done. Otherwise, ....[details of the proof omitted.] (We use the right-to-left convention to multiply permutations.) Okay, we have shown that the number of orbits of $s$ and $ts$ differ by 1. This part, I understand. But I don't understand how to infer the theorem from here. I would be very grateful if someone can help me clear my blind spot. Thank you so much! Added by Dylan. Here is Fraleigh's explanation (please don't sue me): We have shown that the number of orbits of $\tau \sigma$ differs from the number of orbits of $\sigma$ by $1$. The identity permutation $\iota$ has $n$ orbits, because each element is the only member of its orbit. Now the number of orbits of a given permutation $\sigma \in S_n$ differs from $n$ by either an even or odd number, but not both. Thus it is impossible to write    $$ \sigma = \tau_1 \tau_2 \cdots \tau_m \iota $$   where the $\tau_k$ are transpositions, in two ways, once with $m$ even and once with $m$ odd.  $\qquad \diamond$",,"['abstract-algebra', 'group-theory', 'permutations', 'symmetric-groups']"
10,Can the semidirect product of two groups be abelian group?,Can the semidirect product of two groups be abelian group?,,"while I was working through the examples of semidirect products of Dummit and Foote, I thought that it's possible to show that any semdirect product of two groups can't be abelian if the this semidirect product is not the direct product. Here is my simple idea: Suppose $H,K$ are two groups and $H\rtimes K$ be the semidirect product of $H$ and $K$. Let $f:K \rightarrow Aut(H)$ be our homomorphism from $K$ into $Aut(H)$, now we know that $H \unlhd H\rtimes K$ but not necessarily $K$. If $H\rtimes K$  is abelian, then every subgroup of it is normal, so $K$ must be normal but if $K$ is normal then $f$ is the trivial homomorphism and so the semidirect product turns into the direct product, so the semdidirect product in this case is the direct product, which is a contradiction since we supposed that this semidirect product of $H,K$ is not their direct product. Is this true? Or have I made a mistake and there exists a counterexample?","while I was working through the examples of semidirect products of Dummit and Foote, I thought that it's possible to show that any semdirect product of two groups can't be abelian if the this semidirect product is not the direct product. Here is my simple idea: Suppose $H,K$ are two groups and $H\rtimes K$ be the semidirect product of $H$ and $K$. Let $f:K \rightarrow Aut(H)$ be our homomorphism from $K$ into $Aut(H)$, now we know that $H \unlhd H\rtimes K$ but not necessarily $K$. If $H\rtimes K$  is abelian, then every subgroup of it is normal, so $K$ must be normal but if $K$ is normal then $f$ is the trivial homomorphism and so the semidirect product turns into the direct product, so the semdidirect product in this case is the direct product, which is a contradiction since we supposed that this semidirect product of $H,K$ is not their direct product. Is this true? Or have I made a mistake and there exists a counterexample?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
11,Finding all homomorphisms between two groups - couple of questions,Finding all homomorphisms between two groups - couple of questions,,"Consider $\mathbb{Z}_{15}$, and $\mathbb{Z}_{18}$. Let's say I want to find all homomorphisms $f:\mathbb{Z}_{15}\rightarrow \mathbb{Z}_{18}$. I'm not interested in the answer in particular, mostly I'm concerned about understanding the properties of homomorphism, so I can answer these kind of questions myself. So, first of all, I know that homomorphism of cyclic group is completely determined by it's generator. But, will any mapping do? For example, the easiest one to find is $f(1)=0$, where $Imf=\left\{0\right\}$, and $Ker=G$  (correct me if I'm wrong, this kind of $f$ can be defined between any two groups). Now, what things do I need to consider, when trying to find another one (if it exist)? Can I decide that $f(1)=1$? (It is not onto, but that shouldn't bother me) And what about $f(1)=2$? and so on... My second question is: what about non-cyclic groups? Consider $D_{10}$ and $\mathbb{Z}_{18}$, for example. Do I need to go and define $f$ for each and every $g\in D_{10}$? (it doesn't have a generator) A link to a useful (and simple) summary regarding homomorphisms properties will also be great. Thank you in advance.","Consider $\mathbb{Z}_{15}$, and $\mathbb{Z}_{18}$. Let's say I want to find all homomorphisms $f:\mathbb{Z}_{15}\rightarrow \mathbb{Z}_{18}$. I'm not interested in the answer in particular, mostly I'm concerned about understanding the properties of homomorphism, so I can answer these kind of questions myself. So, first of all, I know that homomorphism of cyclic group is completely determined by it's generator. But, will any mapping do? For example, the easiest one to find is $f(1)=0$, where $Imf=\left\{0\right\}$, and $Ker=G$  (correct me if I'm wrong, this kind of $f$ can be defined between any two groups). Now, what things do I need to consider, when trying to find another one (if it exist)? Can I decide that $f(1)=1$? (It is not onto, but that shouldn't bother me) And what about $f(1)=2$? and so on... My second question is: what about non-cyclic groups? Consider $D_{10}$ and $\mathbb{Z}_{18}$, for example. Do I need to go and define $f$ for each and every $g\in D_{10}$? (it doesn't have a generator) A link to a useful (and simple) summary regarding homomorphisms properties will also be great. Thank you in advance.",,"['abstract-algebra', 'finite-groups']"
12,A polynomial with nowhere surjective derivative,A polynomial with nowhere surjective derivative,,"Let $P:\mathbb {R}^2\rightarrow \mathbb {R}^2$ be a polynomial map. It is given that the Jacobian of $P$ is everywhere not surjective. Must  the following  be true: There exist polynomial maps $f:\mathbb {R}^2 \rightarrow \mathbb {R}$ , $g:\mathbb {R} \rightarrow \mathbb {R}^2$ such that $P= g \circ f $ . Thank you. The reason why I put the tag abstract algebra instead of differential geometry tag only is because I am asking for the existence of morphisms which are polynomial maps and not just any morphisms in the category of smooth manifolds.","Let be a polynomial map. It is given that the Jacobian of is everywhere not surjective. Must  the following  be true: There exist polynomial maps , such that . Thank you. The reason why I put the tag abstract algebra instead of differential geometry tag only is because I am asking for the existence of morphisms which are polynomial maps and not just any morphisms in the category of smooth manifolds.",P:\mathbb {R}^2\rightarrow \mathbb {R}^2 P f:\mathbb {R}^2 \rightarrow \mathbb {R} g:\mathbb {R} \rightarrow \mathbb {R}^2 P= g \circ f ,"['abstract-algebra', 'algebraic-geometry', 'polynomials', 'implicit-function-theorem']"
13,"If $S$ is a nonempty subset of group $G$, then $S^{|G|}$ is a subgroup of $G$.","If  is a nonempty subset of group , then  is a subgroup of .",S G S^{|G|} G,Let $G$ be a group with $|G| = n$ and let $ \emptyset \ne S \subseteq G$ . I want to show that $S^n$ is a subgroup of $G$ where by $S^n$ I mean the set $\lbrace s_1\cdots s_n \; | \; s_i \in S\rbrace$ .,Let be a group with and let . I want to show that is a subgroup of where by I mean the set .,G |G| = n  \emptyset \ne S \subseteq G S^n G S^n \lbrace s_1\cdots s_n \; | \; s_i \in S\rbrace,"['abstract-algebra', 'group-theory', 'finite-groups']"
14,"Why does $PSL(2,\mathbb C)\cong PGL(2,\mathbb C)$ but $PSL(2,\mathbb R) \not\cong PGL(2,\mathbb R)$?",Why does  but ?,"PSL(2,\mathbb C)\cong PGL(2,\mathbb C) PSL(2,\mathbb R) \not\cong PGL(2,\mathbb R)","Why does $PSL(2,\mathbb C)\cong PGL(2,\mathbb C)$ but $PSL(2,\mathbb R) \not\cong PGL(2,\mathbb R)$?","Why does $PSL(2,\mathbb C)\cong PGL(2,\mathbb C)$ but $PSL(2,\mathbb R) \not\cong PGL(2,\mathbb R)$?",,"['abstract-algebra', 'group-theory']"
15,Most wanted reproducible results in computational algebra,Most wanted reproducible results in computational algebra,,"I am interested in suggestions for major computational results obtained with the help of mathematical software but not easily verifiable using computers. ""Most wanted"" could refer, for example, to the following: results which are highly cited/reused in other publications/computations computational proofs of fundamental results counterexamples to central conjectures in a field checking correctness of various mathematical databases producing open source implementations of computations previously performed using another open or closed source software, or when the old code is not available at all landmark computations that one could be interested to reproduce ( in the same way like a chemistry reaction from a textbook could be reproduced by mixing baking soda and vinegar in your kitchen ). If the publication just says ""this result was produced using the system X"", it may be a long way to reproduce it. It may include a reference to exact version of the system, a link to the extra code to download, but again it may happen that that version has to be installed in some particular way to satisfy certain dependencies, the extra code is not well documented so it is unclear how to run it, some other special knowledge or non-trivial computational resources are needed, etc. On the other side, having these results easier reproducible could be crucial for science. Hypothetically, one could e.g. download a virtual machine and re-run the whole experiment, or use the newest version of the system to check whether the experiment still runs with the same outcome. I hope that making such a list of suggested experiments to reproduce will be useful to those interested in checking them twice ;-). For example, one could submit their findings to a journal like ReScience which ""targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research is reproducible"". Remark: suggestions on computational verification of previously obtained theoretical results and pointers to existing reproducible experiments are also welcome.","I am interested in suggestions for major computational results obtained with the help of mathematical software but not easily verifiable using computers. ""Most wanted"" could refer, for example, to the following: results which are highly cited/reused in other publications/computations computational proofs of fundamental results counterexamples to central conjectures in a field checking correctness of various mathematical databases producing open source implementations of computations previously performed using another open or closed source software, or when the old code is not available at all landmark computations that one could be interested to reproduce ( in the same way like a chemistry reaction from a textbook could be reproduced by mixing baking soda and vinegar in your kitchen ). If the publication just says ""this result was produced using the system X"", it may be a long way to reproduce it. It may include a reference to exact version of the system, a link to the extra code to download, but again it may happen that that version has to be installed in some particular way to satisfy certain dependencies, the extra code is not well documented so it is unclear how to run it, some other special knowledge or non-trivial computational resources are needed, etc. On the other side, having these results easier reproducible could be crucial for science. Hypothetically, one could e.g. download a virtual machine and re-run the whole experiment, or use the newest version of the system to check whether the experiment still runs with the same outcome. I hope that making such a list of suggested experiments to reproduce will be useful to those interested in checking them twice ;-). For example, one could submit their findings to a journal like ReScience which ""targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research is reproducible"". Remark: suggestions on computational verification of previously obtained theoretical results and pointers to existing reproducible experiments are also welcome.",,"['abstract-algebra', 'big-list', 'computer-algebra-systems', 'computational-algebra', 'experimental-mathematics']"
16,Splitting field of a separable polynomial is separable,Splitting field of a separable polynomial is separable,,"Probably a stupid question, but.. Why is the splitting field of a separable polynomial necessarily separable? Thanks. Follow up question Show that if $F$ is a splitting field over $K$ for $P \in K[X]$, then $[F:K] \leq n!$ I've proven this by induction on $n$, but I'm convinced there's a more algebraic approach ($n!$ screams $S_n$). If I knew $P$ were separable, then I'd know $F$ was Galois, so $ |\mbox{Gal}(F/K)| = [F:K] $. Considering the action of $ \mbox{Gal}(F/K) $ on the roots of $P$, we'd get an injective homomorphism into $ S_n $, giving the result. But $P$ is not given to be separable, so $P$ could have repeated roots when factorised in $F$. If $G$ is any finite group of $K$-automorphisms of $L$, then I know that $[F:K] \leq |G| $. Considering the action of $G$ on the set of roots of $P$, say $\Omega$, we get an injective homomorphism of $G$ into $S_{|\Omega|}$, where $|\Omega| \leq n$ (I think). I have a feeling I'm wrong here, since I think $G$ is forced to be $\mbox{Aut}(F/K)$. Any advice would be appreciated.","Probably a stupid question, but.. Why is the splitting field of a separable polynomial necessarily separable? Thanks. Follow up question Show that if $F$ is a splitting field over $K$ for $P \in K[X]$, then $[F:K] \leq n!$ I've proven this by induction on $n$, but I'm convinced there's a more algebraic approach ($n!$ screams $S_n$). If I knew $P$ were separable, then I'd know $F$ was Galois, so $ |\mbox{Gal}(F/K)| = [F:K] $. Considering the action of $ \mbox{Gal}(F/K) $ on the roots of $P$, we'd get an injective homomorphism into $ S_n $, giving the result. But $P$ is not given to be separable, so $P$ could have repeated roots when factorised in $F$. If $G$ is any finite group of $K$-automorphisms of $L$, then I know that $[F:K] \leq |G| $. Considering the action of $G$ on the set of roots of $P$, say $\Omega$, we get an injective homomorphism of $G$ into $S_{|\Omega|}$, where $|\Omega| \leq n$ (I think). I have a feeling I'm wrong here, since I think $G$ is forced to be $\mbox{Aut}(F/K)$. Any advice would be appreciated.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
17,A ring such that $(a+b)^2=a^2+b^2$ and $(a+b)^3=a^3+b^3$,A ring such that  and,(a+b)^2=a^2+b^2 (a+b)^3=a^3+b^3,"Let $(A,+,\cdot)$ be a ring such that there are $a,b \in A$ which satisfy $$(a+b)^2=a^2+b^2, \quad (a+b)^3=a^3+b^3$$   Prove that $(a+b)^n=a^n+b^n,$ for all positive integers $n.$ I have found the following solution, but I am not quite satisfied with it. From the hypothesis we get $ab+ba=0$ and $ab^2+ba^2=0.$ We will prove the identity using induction. Suppose that it is true for $1,2,...,n-1, \: n \geq 4.$ We can write $$(a+b)^n=(a+b)^{n-1}(a+b)=(a^{n-1}+b^{n-1})(a+b)=a^n+a^{n-1}b+b^{n-1}a+b^n$$ It is left to prove that $a^{n-1}b+b^{n-1}a=0.$ We can write $$a^{n-1}b+b^{n-1}a=a^{n-2}ab+b^{n-2}ba=-a^{n-2}ba-b^{n-2}ab \quad (*)$$ But $(a+b)^{n-1}=(a+b)^{n-2}(a+b)=(a^{n-2}+b^{n-2})(a+b)=a^{n-1}+b^{n-1},$ so $$a^{n-2}b+b^{n-2}a=0 \Rightarrow b^{n-2}a=-a^{n-2}b$$ Plugging this back in $(*)$ gives $$a^{n-1}b+b^{n-1}a=-a^{n-2}ba+a^{n-2}b^2=a^{n-2}(-ba+b^2)=a^{n-3}ab(-a+b)$$ But $0=ab^2+ba^2=ab^2-aba=ab(b-a),$ so $$a^{n-1}b+b^{n-1}a=a^{n-3}\cdot 0 = 0$$ and this completes the indution. Is there any other solution, maybe quicker or more beautiful?","Let $(A,+,\cdot)$ be a ring such that there are $a,b \in A$ which satisfy $$(a+b)^2=a^2+b^2, \quad (a+b)^3=a^3+b^3$$   Prove that $(a+b)^n=a^n+b^n,$ for all positive integers $n.$ I have found the following solution, but I am not quite satisfied with it. From the hypothesis we get $ab+ba=0$ and $ab^2+ba^2=0.$ We will prove the identity using induction. Suppose that it is true for $1,2,...,n-1, \: n \geq 4.$ We can write $$(a+b)^n=(a+b)^{n-1}(a+b)=(a^{n-1}+b^{n-1})(a+b)=a^n+a^{n-1}b+b^{n-1}a+b^n$$ It is left to prove that $a^{n-1}b+b^{n-1}a=0.$ We can write $$a^{n-1}b+b^{n-1}a=a^{n-2}ab+b^{n-2}ba=-a^{n-2}ba-b^{n-2}ab \quad (*)$$ But $(a+b)^{n-1}=(a+b)^{n-2}(a+b)=(a^{n-2}+b^{n-2})(a+b)=a^{n-1}+b^{n-1},$ so $$a^{n-2}b+b^{n-2}a=0 \Rightarrow b^{n-2}a=-a^{n-2}b$$ Plugging this back in $(*)$ gives $$a^{n-1}b+b^{n-1}a=-a^{n-2}ba+a^{n-2}b^2=a^{n-2}(-ba+b^2)=a^{n-3}ab(-a+b)$$ But $0=ab^2+ba^2=ab^2-aba=ab(b-a),$ so $$a^{n-1}b+b^{n-1}a=a^{n-3}\cdot 0 = 0$$ and this completes the indution. Is there any other solution, maybe quicker or more beautiful?",,"['abstract-algebra', 'ring-theory']"
18,Balls and Boxes,Balls and Boxes,,"Three urns contain marbles. Each urn is large enough to hold all the marbles . The only operation allowed is to move marbles from an urn to another urn, such that the number of marbles in the receiving urn is doubled. Prove that it is possible, regardless of the initial configuration, to obtain a configuration where one urn is empty. This is an exercice from a french old book. I’ve been trying to solve it since 3 years without any issue.","Three urns contain marbles. Each urn is large enough to hold all the marbles . The only operation allowed is to move marbles from an urn to another urn, such that the number of marbles in the receiving urn is doubled. Prove that it is possible, regardless of the initial configuration, to obtain a configuration where one urn is empty. This is an exercice from a french old book. I’ve been trying to solve it since 3 years without any issue.",,"['abstract-algebra', 'number-theory', 'arithmetic']"
19,Lower bounds on the number of elements in Sylow subgroups,Lower bounds on the number of elements in Sylow subgroups,,"Let $p$ be a prime and $n \geq 1$ some integer. Furthermore, let $G$ be a finite group where $p$-Sylow subgroups have order $p^n$. Denote by $n_p(G)$ the number of Sylow $p$-subgroups of $G$. Denote the number of elements in the union of all Sylow $p$-subgroups of $G$ by $f_p(G)$. I am interested in finding lower bounds for $f_p(G)$ that do not depend on the group $G$, but only on $n_p(G)$, the number of Sylow $p$-subgroups. By Sylow's theorem, we know that $n_p(G) = kp + 1$ for some integer $k \geq 0$. If $k = 0$, then it is clear that $f_p(G) = p^n$. If $k = 1$, we can show that $f_p(G) = p^{n+1}$. Furthermore, if $k > 1$, then by a theorem of Miller (see this question ) we have $f_p(G) > p^{n+1}$, so by Frobenius theorem [*] $f_p(G) \geq p^{n+1} + p^n$. We can also improve this with Frobenius theorem to $f_p(G) \geq 2p^{n+1} - p^n$ by noticing that the number $f_p(G) - 1$ is divisible by $p-1$. My question is this: Can we find a better lower bound for $f_p(G)$ when $k > 1$? I guess it would probably make sense that when $G$ has many Sylow subgroups, then there are many distinct elements among the subgroups. Thus I am also interested in the following question: Can we show that $f_p(G) \rightarrow \infty$ as $k \rightarrow \infty$? To make this precise, what I am asking here is for a function $g$ satisfying the following: For any group $G$ with Sylow $p$-subgroups of order $p^n$ and $n_p(G) = kp + 1$, we have $f_p(G) \geq g(k)$. $g(k) \rightarrow \infty$ as $k \rightarrow \infty$ Of course, for both questions the case $n = 1$ is easy, because then we know the value of $f_p(G)$ precisely. If $n = 1$, then $f_p(G) = (kp+1)(p-1)+1$ so for both questions we have a positive answer. I think the following example shows that $f_p(G)$ gets arbitrarily large values. By Dirichlet's theorem, there exist arbitrarily large primes $q$ such that $q \equiv 1 \mod{p}$. Then in a direct product $G = C_{p^{n-1}} \times H$, where $H$ is a non-abelian group of order $pq$, the Sylow subgroups of $G$ have $C_{p^{n-1}}$ as their common intersection. There are exactly $q$ Sylow $p$-subgroups, because otherwise $G$ would be nilpotent but its subgroup $H$ is not. Therefore the number of elements in the $p$-Sylow subgroups is $f_p(G) = q(p^{n} - p^{n-1}) + p^{n-1}$, and this goes to infinity as $q$ goes to infinity. [*] Frobenius' Theorem says that when $G$ is a finite group with order divisible by $k$, the number of solutions to $x^k = 1$ in $G$ is a multiple of $k$. It is easy to see that $f_p(G)$ is the number of solutions to $x^{p^n} = 1$ in $G$. LATER EDIT: Okay, the second question is not so difficult if I have this right. Any Sylow $p$-subgroup consists of $p^n$ elements from the $f_p(G)$ elements in the union, so we have the inequality $f_p(G)^{p^n} \geq n_p(G) = kp + 1$, and thus $$f_p(G) \geq (kp+1)^{p^{-n}}$$ which goes to infinity as $k \rightarrow \infty$. For huge $k$ this is better than the lower bound $f_p(G) \geq 2p^{n+1} - p^n$. However, this is an extremely weak bound and not so interesting, it seems to me useful only for showing that $f_p(G) \rightarrow \infty$ as $k \rightarrow \infty$.","Let $p$ be a prime and $n \geq 1$ some integer. Furthermore, let $G$ be a finite group where $p$-Sylow subgroups have order $p^n$. Denote by $n_p(G)$ the number of Sylow $p$-subgroups of $G$. Denote the number of elements in the union of all Sylow $p$-subgroups of $G$ by $f_p(G)$. I am interested in finding lower bounds for $f_p(G)$ that do not depend on the group $G$, but only on $n_p(G)$, the number of Sylow $p$-subgroups. By Sylow's theorem, we know that $n_p(G) = kp + 1$ for some integer $k \geq 0$. If $k = 0$, then it is clear that $f_p(G) = p^n$. If $k = 1$, we can show that $f_p(G) = p^{n+1}$. Furthermore, if $k > 1$, then by a theorem of Miller (see this question ) we have $f_p(G) > p^{n+1}$, so by Frobenius theorem [*] $f_p(G) \geq p^{n+1} + p^n$. We can also improve this with Frobenius theorem to $f_p(G) \geq 2p^{n+1} - p^n$ by noticing that the number $f_p(G) - 1$ is divisible by $p-1$. My question is this: Can we find a better lower bound for $f_p(G)$ when $k > 1$? I guess it would probably make sense that when $G$ has many Sylow subgroups, then there are many distinct elements among the subgroups. Thus I am also interested in the following question: Can we show that $f_p(G) \rightarrow \infty$ as $k \rightarrow \infty$? To make this precise, what I am asking here is for a function $g$ satisfying the following: For any group $G$ with Sylow $p$-subgroups of order $p^n$ and $n_p(G) = kp + 1$, we have $f_p(G) \geq g(k)$. $g(k) \rightarrow \infty$ as $k \rightarrow \infty$ Of course, for both questions the case $n = 1$ is easy, because then we know the value of $f_p(G)$ precisely. If $n = 1$, then $f_p(G) = (kp+1)(p-1)+1$ so for both questions we have a positive answer. I think the following example shows that $f_p(G)$ gets arbitrarily large values. By Dirichlet's theorem, there exist arbitrarily large primes $q$ such that $q \equiv 1 \mod{p}$. Then in a direct product $G = C_{p^{n-1}} \times H$, where $H$ is a non-abelian group of order $pq$, the Sylow subgroups of $G$ have $C_{p^{n-1}}$ as their common intersection. There are exactly $q$ Sylow $p$-subgroups, because otherwise $G$ would be nilpotent but its subgroup $H$ is not. Therefore the number of elements in the $p$-Sylow subgroups is $f_p(G) = q(p^{n} - p^{n-1}) + p^{n-1}$, and this goes to infinity as $q$ goes to infinity. [*] Frobenius' Theorem says that when $G$ is a finite group with order divisible by $k$, the number of solutions to $x^k = 1$ in $G$ is a multiple of $k$. It is easy to see that $f_p(G)$ is the number of solutions to $x^{p^n} = 1$ in $G$. LATER EDIT: Okay, the second question is not so difficult if I have this right. Any Sylow $p$-subgroup consists of $p^n$ elements from the $f_p(G)$ elements in the union, so we have the inequality $f_p(G)^{p^n} \geq n_p(G) = kp + 1$, and thus $$f_p(G) \geq (kp+1)^{p^{-n}}$$ which goes to infinity as $k \rightarrow \infty$. For huge $k$ this is better than the lower bound $f_p(G) \geq 2p^{n+1} - p^n$. However, this is an extremely weak bound and not so interesting, it seems to me useful only for showing that $f_p(G) \rightarrow \infty$ as $k \rightarrow \infty$.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
20,Showing that $ϕ(x)=x^n$ is a homomorphism from $G\to Z(G)$,Showing that  is a homomorphism from,ϕ(x)=x^n G\to Z(G),"Let $G$ be a group with $|G:Z(G)|=n$ then $\phi(x)=x^n$ is a homomorphism from $G$ to $Z(G)$. I guess it has a proof using transfer theory, I wonder whether it has an elemantary proof or not. Thanks.","Let $G$ be a group with $|G:Z(G)|=n$ then $\phi(x)=x^n$ is a homomorphism from $G$ to $Z(G)$. I guess it has a proof using transfer theory, I wonder whether it has an elemantary proof or not. Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'transfer-theory']"
21,The radical solution of a solvable 17th degree equation,The radical solution of a solvable 17th degree equation,,"(The question is at the bottom of the post.)  Here's a ""natural"" solvable 17-th deg eqn with small coefficients: $$\begin{align*} x^{17}-6 x^{16}&-24 x^{15}-42 x^{14}-31 x^{13}-23 x^{12}-7 x^{11}-x^{10}\\ &\quad-4 x^9-11 x^8-7 x^7-13 x^6-x^5+x^3+x^2+x-1 = 0 \quad\text{(eq.1)} \end{align*}$$ Its unique real root is exactly, $$x = \frac{\zeta_{48} \eta(\tau)}{\sqrt{2}\,\eta(2\tau)} = 9.1630942 \dots$$ with root of unity $\zeta_{48} = \exp(2\pi i/48)$, the Dedekind eta function $\eta(\tau)$, $\tau = (1+\sqrt{-d})/2$, and $d = 383$. This $d$ has class number $h(-d) = 17$. To solve this, depress eq.1 (get rid of its $x^{n-1}$ term), by letting $x = (y+6)/17$ to get, $$\begin{align*} y^{17}&-11832 y^{15}-1124346 y^{14}-55393735 y^{13}-1784741617 y^{12}\\ &\quad-41171464807 y^{11}-711423456455 y^{10}-9455898295636 y^9-99724287747103 y^8\\ &\quad 887992943070295 y^7-7665207188897171 y^6-70479807472769473 y^5\\ &\quad -592167373130143650 y^4-3496187093606980919 y^3-8695712981307573757 y^2\\ &\quad +68265051092799270505 y-427806967360317821039 = 0 \qquad  \text{(eq.2)} \end{align*}$$ Its 16-deg resolvent, a polynomial with INTEGER coefficients, call this $R_{16}$, has roots, $$\begin{align*} z_k &= [(y_1 + w^k y_2 + w^{2k} y_8 + w^{3k} y_7 + w^{4k} y_{16} + w^{5k} y_4 + w^{6k} y_{12} + \\ &\qquad + w^{7k} y_{15} + w^{8k} y_{11} + w^{9k} y_{10} + w^{10k} y_{14} + w^{11k} y_{13} + w^{12k} y_5 +\\ &\qquad + w^{13k} y_{17} + w^{14k} y_6 + w^{15k} y_9 + w^{16k} y_3)/17]^{17} \end{align*}$$ for $k = 1,\dots,16$ where w is any complex 17th root of unity. Note the specific arrangement of the $y_n$. There are $16! \approx 2 \times 10^{13}$ possible permutations of the $y_n$, and out of that huge number, there are only 16 such that $R_{16}$ has integer coefficients, and we have given one of them. Of course, a short cut was used to find it, because even if your computer can check a million permutations a second, it would still take about 8 months to go through them all. The short cut took less than two hours to find $R_{16}$. The $y_n$ follows the root object Root[poly, n] ordering in Mathematica.  Approximately, these are, $$\begin{align*} y_1 &= 149.7726\\ \{y_2, y_3\} &= -27.62 \mp 18.49i\\ \{y_4, y_5\} &= -21.61 \mp 7.52i\\ \{y_6, y_7\} &= -16.58 \mp 6.34i\\ \{y_8, y_9\} &= -10.57 \mp 15.32i\\ \{y_{10}, y_{11}\} &= -5.02 \mp 13.71i\\ \{y_{12}, y_{13}\} &= -2.34 \mp 13.15i\\ \{y_{14}, y_{15}\} &= 2.57 \mp 2.60i\\ \{y_{16}, y_{17}\} &= 6.31 \mp 7.04i \end{align*}$$ $R_{16}$ has extremely large integer coefficients, with the largest being the 248-digit constant term $429534618434587^{17}$ which, naturally enough, is a 17th power.  (Note:  $R_{16}$ can easily be formed using 500-digit precision or more on the $y_n$, and multiplying the 16 factors together to form the polynomial.) The polynomial $R_{16}$ can then be factored into two octics over the radical extension $\sqrt{17}$. This, in turn, can be factored into 2 quartics over $\sqrt{2(17+\sqrt{17})}$. This can be factored further into 2 quadratics using an expression involved in the 17th root of unity. Apparently, to solve $R_{16} = 0$, only square roots of square roots of square roots, etc, are needed. The real root of eq.2 in radicals is then, $$y_1 = {z_1}^{1/17} + {z_2}^{1/17} + {z_3}^{1/17} + \dots + {z_{16}}^{1/17} = 149.7726 \dots$$ Problem : Express the roots of this particular $R_{16}$ purely in terms of the complex 17th root of unity.  (If anyone knows how to contact the mathematician Peter-Lawrence Montgomery, he probably will know how, since he has done something similar with a septic root and the 29th root of unity.)","(The question is at the bottom of the post.)  Here's a ""natural"" solvable 17-th deg eqn with small coefficients: $$\begin{align*} x^{17}-6 x^{16}&-24 x^{15}-42 x^{14}-31 x^{13}-23 x^{12}-7 x^{11}-x^{10}\\ &\quad-4 x^9-11 x^8-7 x^7-13 x^6-x^5+x^3+x^2+x-1 = 0 \quad\text{(eq.1)} \end{align*}$$ Its unique real root is exactly, $$x = \frac{\zeta_{48} \eta(\tau)}{\sqrt{2}\,\eta(2\tau)} = 9.1630942 \dots$$ with root of unity $\zeta_{48} = \exp(2\pi i/48)$, the Dedekind eta function $\eta(\tau)$, $\tau = (1+\sqrt{-d})/2$, and $d = 383$. This $d$ has class number $h(-d) = 17$. To solve this, depress eq.1 (get rid of its $x^{n-1}$ term), by letting $x = (y+6)/17$ to get, $$\begin{align*} y^{17}&-11832 y^{15}-1124346 y^{14}-55393735 y^{13}-1784741617 y^{12}\\ &\quad-41171464807 y^{11}-711423456455 y^{10}-9455898295636 y^9-99724287747103 y^8\\ &\quad 887992943070295 y^7-7665207188897171 y^6-70479807472769473 y^5\\ &\quad -592167373130143650 y^4-3496187093606980919 y^3-8695712981307573757 y^2\\ &\quad +68265051092799270505 y-427806967360317821039 = 0 \qquad  \text{(eq.2)} \end{align*}$$ Its 16-deg resolvent, a polynomial with INTEGER coefficients, call this $R_{16}$, has roots, $$\begin{align*} z_k &= [(y_1 + w^k y_2 + w^{2k} y_8 + w^{3k} y_7 + w^{4k} y_{16} + w^{5k} y_4 + w^{6k} y_{12} + \\ &\qquad + w^{7k} y_{15} + w^{8k} y_{11} + w^{9k} y_{10} + w^{10k} y_{14} + w^{11k} y_{13} + w^{12k} y_5 +\\ &\qquad + w^{13k} y_{17} + w^{14k} y_6 + w^{15k} y_9 + w^{16k} y_3)/17]^{17} \end{align*}$$ for $k = 1,\dots,16$ where w is any complex 17th root of unity. Note the specific arrangement of the $y_n$. There are $16! \approx 2 \times 10^{13}$ possible permutations of the $y_n$, and out of that huge number, there are only 16 such that $R_{16}$ has integer coefficients, and we have given one of them. Of course, a short cut was used to find it, because even if your computer can check a million permutations a second, it would still take about 8 months to go through them all. The short cut took less than two hours to find $R_{16}$. The $y_n$ follows the root object Root[poly, n] ordering in Mathematica.  Approximately, these are, $$\begin{align*} y_1 &= 149.7726\\ \{y_2, y_3\} &= -27.62 \mp 18.49i\\ \{y_4, y_5\} &= -21.61 \mp 7.52i\\ \{y_6, y_7\} &= -16.58 \mp 6.34i\\ \{y_8, y_9\} &= -10.57 \mp 15.32i\\ \{y_{10}, y_{11}\} &= -5.02 \mp 13.71i\\ \{y_{12}, y_{13}\} &= -2.34 \mp 13.15i\\ \{y_{14}, y_{15}\} &= 2.57 \mp 2.60i\\ \{y_{16}, y_{17}\} &= 6.31 \mp 7.04i \end{align*}$$ $R_{16}$ has extremely large integer coefficients, with the largest being the 248-digit constant term $429534618434587^{17}$ which, naturally enough, is a 17th power.  (Note:  $R_{16}$ can easily be formed using 500-digit precision or more on the $y_n$, and multiplying the 16 factors together to form the polynomial.) The polynomial $R_{16}$ can then be factored into two octics over the radical extension $\sqrt{17}$. This, in turn, can be factored into 2 quartics over $\sqrt{2(17+\sqrt{17})}$. This can be factored further into 2 quadratics using an expression involved in the 17th root of unity. Apparently, to solve $R_{16} = 0$, only square roots of square roots of square roots, etc, are needed. The real root of eq.2 in radicals is then, $$y_1 = {z_1}^{1/17} + {z_2}^{1/17} + {z_3}^{1/17} + \dots + {z_{16}}^{1/17} = 149.7726 \dots$$ Problem : Express the roots of this particular $R_{16}$ purely in terms of the complex 17th root of unity.  (If anyone knows how to contact the mathematician Peter-Lawrence Montgomery, he probably will know how, since he has done something similar with a septic root and the 29th root of unity.)",,"['number-theory', 'abstract-algebra', 'polynomials', 'galois-theory']"
22,Galois correspondence and characteristic subgroups,Galois correspondence and characteristic subgroups,,"It is well-known that Galois correspondence sends a normal subgroup to a normal extension of a field. Specifically, given a Galois extension $L/K$ and the corresponding Galois group $G$, normal subgroups of $G$ correspond to normal subextensions $F/K$ . Is there a characterization of the subextensions corresponding to characteristic subgroups?","It is well-known that Galois correspondence sends a normal subgroup to a normal extension of a field. Specifically, given a Galois extension $L/K$ and the corresponding Galois group $G$, normal subgroups of $G$ correspond to normal subextensions $F/K$ . Is there a characterization of the subextensions corresponding to characteristic subgroups?",,"['abstract-algebra', 'field-theory', 'galois-theory']"
23,Galois Group of Composite Field vs. Second Isomorphism Theorem,Galois Group of Composite Field vs. Second Isomorphism Theorem,,"$\DeclareMathOperator{\Gal}{Gal}$ In my abstract algebra class, we learned about how Galois groups interact with composite fields. Namely, if $K/F$ is Galois, and $L/F$ is any extension: $$\Gal(KL/L) \cong \Gal(K/(K \cap L))$$ and $$[KL : F] = \frac{[K : F][L : F]}{[K \cap L : F]}$$ This immediately reminds me of the second isomorphism theorems. For groups: If $H \le G$ and $N \trianglelefteq G$, then: $$ HN/N \cong H/(H \cap N) $$ and $$ |HN| = \frac{|H||N|}{|H \cap N|}, \textrm{ equivalently } |G : HN| = \frac{|G : H||G : N|}{|G : H \cap N|} $$ For rings: if $S$ is a subring and $I$ is an ideal of $R$, then: $$ (S + I)/I \cong S/(S \cap I) $$ and $$ |S + I| = \frac{|S||I|}{|S \cap I|}, \textrm{ equivalently } |R : S + I| = \frac{|R : S||R : I|}{|R : S \cap I|} $$ If $K$ is replaced with $H$ (or $S$), $L$ with $N$ (or $I$), and degree with index, these become the same. I can see the connection between the field and group versions with the Fundamental Theorem of Galois Theory, and the group and ring versions by just verifying that multiplication still checks out. But it feels like this is a statement about algebraic structures in general. Is there a way of showing this holds for certain kinds of structures? It feels like a problem for homological algebra or category theory, but I don't know enough about either to tackle it myself. EDIT: More examples. The second isomorphism theorem for modules fits this mold, and it's proved pretty much the same as for rings. In particular, this works for vector spaces. But the ""size function"" doesn't have to be the index (which is not helpful for $\mathbb{R}$-spaces, for example), it can also be dimension (which is what's going on with the Galois groups). The Subspace Sum-Intersection theorem seems to fit this mold as well: for two subspaces $S$ and $T$ of $V$, $\dim (S + T) = \frac{\dim S + \dim T}{\dim (S \cap T)}$.","$\DeclareMathOperator{\Gal}{Gal}$ In my abstract algebra class, we learned about how Galois groups interact with composite fields. Namely, if $K/F$ is Galois, and $L/F$ is any extension: $$\Gal(KL/L) \cong \Gal(K/(K \cap L))$$ and $$[KL : F] = \frac{[K : F][L : F]}{[K \cap L : F]}$$ This immediately reminds me of the second isomorphism theorems. For groups: If $H \le G$ and $N \trianglelefteq G$, then: $$ HN/N \cong H/(H \cap N) $$ and $$ |HN| = \frac{|H||N|}{|H \cap N|}, \textrm{ equivalently } |G : HN| = \frac{|G : H||G : N|}{|G : H \cap N|} $$ For rings: if $S$ is a subring and $I$ is an ideal of $R$, then: $$ (S + I)/I \cong S/(S \cap I) $$ and $$ |S + I| = \frac{|S||I|}{|S \cap I|}, \textrm{ equivalently } |R : S + I| = \frac{|R : S||R : I|}{|R : S \cap I|} $$ If $K$ is replaced with $H$ (or $S$), $L$ with $N$ (or $I$), and degree with index, these become the same. I can see the connection between the field and group versions with the Fundamental Theorem of Galois Theory, and the group and ring versions by just verifying that multiplication still checks out. But it feels like this is a statement about algebraic structures in general. Is there a way of showing this holds for certain kinds of structures? It feels like a problem for homological algebra or category theory, but I don't know enough about either to tackle it myself. EDIT: More examples. The second isomorphism theorem for modules fits this mold, and it's proved pretty much the same as for rings. In particular, this works for vector spaces. But the ""size function"" doesn't have to be the index (which is not helpful for $\mathbb{R}$-spaces, for example), it can also be dimension (which is what's going on with the Galois groups). The Subspace Sum-Intersection theorem seems to fit this mold as well: for two subspaces $S$ and $T$ of $V$, $\dim (S + T) = \frac{\dim S + \dim T}{\dim (S \cap T)}$.",,"['abstract-algebra', 'soft-question', 'galois-theory']"
24,Abelianization of free group is the free abelian group,Abelianization of free group is the free abelian group,,"How does one prove that if $X$ is a set, then the abelianization of the free group $FX$ on $X$ is the free abelian group on $X$?","How does one prove that if $X$ is a set, then the abelianization of the free group $FX$ on $X$ is the free abelian group on $X$?",,"['abstract-algebra', 'group-theory']"
25,"$x^2 +y^2 + z^2$ is irreducible in $\mathbb C [x,y,z]$",is irreducible in,"x^2 +y^2 + z^2 \mathbb C [x,y,z]","Is $x^2 +y^2 + z^2$ irreducible in $\mathbb C [x,y,z]$? As $(x^2+y^2+z^2)= (x+y+z)^2- 2(xy+yz+zx)$, $$(x^2+y^2+z^2)=\left(x+y+z+\sqrt{2(xy+yz+zx)}\right)\left(x+y+z-\sqrt{2(xy+yz+zx)}\right).$$ But how to show that none of these factors belong to $\mathbb C [x,y,z]$?","Is $x^2 +y^2 + z^2$ irreducible in $\mathbb C [x,y,z]$? As $(x^2+y^2+z^2)= (x+y+z)^2- 2(xy+yz+zx)$, $$(x^2+y^2+z^2)=\left(x+y+z+\sqrt{2(xy+yz+zx)}\right)\left(x+y+z-\sqrt{2(xy+yz+zx)}\right).$$ But how to show that none of these factors belong to $\mathbb C [x,y,z]$?",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
26,Nontrivial subring with unity different from the whole ring?,Nontrivial subring with unity different from the whole ring?,,"Is there an example of a ring $R$ with unity and a nontrivial subring $J$, such that $1_J \ne 1_R$?","Is there an example of a ring $R$ with unity and a nontrivial subring $J$, such that $1_J \ne 1_R$?",,"['abstract-algebra', 'ring-theory']"
27,"If $H$ is a cyclic subgroup of $G$ and $H$ is normal in $G$, then every subgoup of $H$ is normal in $G$.","If  is a cyclic subgroup of  and  is normal in , then every subgoup of  is normal in .",H G H G H G,"Exercise 11, page 45 from Hungerford's book Algebra . If $H$ is a cyclic subgroup of $G$ and $H$ is normal in $G$, then every   subgroup of $H$ is normal in $G$. I am trying to show that $a^{-1}Ka\subset K$, but I got stuck. What I am supposed to do now? Thanks for your kindly help.","Exercise 11, page 45 from Hungerford's book Algebra . If $H$ is a cyclic subgroup of $G$ and $H$ is normal in $G$, then every   subgroup of $H$ is normal in $G$. I am trying to show that $a^{-1}Ka\subset K$, but I got stuck. What I am supposed to do now? Thanks for your kindly help.",,"['abstract-algebra', 'group-theory']"
28,Principal ideal and free module,Principal ideal and free module,,Let $R$ be a commutative ring and $I$ be an ideal of $R$. Is it true that $I$ is a principal ideal if and only if $I$ is a free $R$-module?,Let $R$ be a commutative ring and $I$ be an ideal of $R$. Is it true that $I$ is a principal ideal if and only if $I$ is a free $R$-module?,,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
29,"If every prime ideal is maximal, what can we say about the ring?","If every prime ideal is maximal, what can we say about the ring?",,Suppose $R$ is a ring and every prime ideal of $R$ is also a maximal ideal of $R$. Then what can we say about the ring $R$?,Suppose $R$ is a ring and every prime ideal of $R$ is also a maximal ideal of $R$. Then what can we say about the ring $R$?,,"['abstract-algebra', 'ring-theory']"
30,Localisation is isomorphic to a quotient of polynomial ring,Localisation is isomorphic to a quotient of polynomial ring,,"I am having trouble with the following problem. Let $R$ be an integral domain, and let $a \in R$ be a non-zero element. Let $D = \{1, a, a^2, ...\}$. I need to show that $R_D \cong R[x]/(ax-1)$. I just want a hint. Basically, I've been looking for a surjective homomorphism from $R[x]$ to $R_D$, but everything I've tried has failed. I think the fact that $f(a)$ is a unit, where $f$ is our mapping, is relevant, but I'm not sure. Thanks","I am having trouble with the following problem. Let $R$ be an integral domain, and let $a \in R$ be a non-zero element. Let $D = \{1, a, a^2, ...\}$. I need to show that $R_D \cong R[x]/(ax-1)$. I just want a hint. Basically, I've been looking for a surjective homomorphism from $R[x]$ to $R_D$, but everything I've tried has failed. I think the fact that $f(a)$ is a unit, where $f$ is our mapping, is relevant, but I'm not sure. Thanks",,"['abstract-algebra', 'ring-theory', 'localization']"
31,Ideal Generated by two elements (Notation question),Ideal Generated by two elements (Notation question),,"given two elements $r$,$s$ in a ring $R$, are the following two notations equivalent? $(r,s)$ $(r)+(s)$ For example, in the ring $\mathbb{Z}[X]$, is $(2,X)=(2)+(X)$? Thanks a lot.","given two elements $r$,$s$ in a ring $R$, are the following two notations equivalent? $(r,s)$ $(r)+(s)$ For example, in the ring $\mathbb{Z}[X]$, is $(2,X)=(2)+(X)$? Thanks a lot.",,"['abstract-algebra', 'notation']"
32,Why must a field whose a group of units is cyclic be finite?,Why must a field whose a group of units is cyclic be finite?,,"Let $F$ be a field and $F^\times$ be its group of units. If $F^\times$ is cyclic, then show that $F$ is finite. I'm a bit stuck. I know that I can represent $F^\times = \langle u \rangle$ for some $u \in F^\times$ and that we must have that $|F^\times| = o(u)$ , where $o(u)$ denotes the order of $u$ in $F^\times$ .  I tried assuming $o(u) = \infty$ , but I'm not sure exactly where to go from there. I was wondering if I could get a hint.","Let be a field and be its group of units. If is cyclic, then show that is finite. I'm a bit stuck. I know that I can represent for some and that we must have that , where denotes the order of in .  I tried assuming , but I'm not sure exactly where to go from there. I was wondering if I could get a hint.",F F^\times F^\times F F^\times = \langle u \rangle u \in F^\times |F^\times| = o(u) o(u) u F^\times o(u) = \infty,"['abstract-algebra', 'group-theory', 'field-theory', 'finite-fields', 'cyclic-groups']"
33,"Computing $\mathrm{Hom}(\mathbb Z_n,\mathbb Z_m)$ as $\mathbb Z$-module",Computing  as -module,"\mathrm{Hom}(\mathbb Z_n,\mathbb Z_m) \mathbb Z","My algebra is weak I need help computing $\mathrm{Hom}(\mathbb Z_n,\mathbb Z)$, $\mathrm{Hom}(\mathbb Z_n,\mathbb Z_m)$ and also $\mathrm{Hom}(\mathbb Z,\mathbb Z)$ as $\mathbb Z$-modules. Also books suggestion to improve my basic. Thank you. Regards","My algebra is weak I need help computing $\mathrm{Hom}(\mathbb Z_n,\mathbb Z)$, $\mathrm{Hom}(\mathbb Z_n,\mathbb Z_m)$ and also $\mathrm{Hom}(\mathbb Z,\mathbb Z)$ as $\mathbb Z$-modules. Also books suggestion to improve my basic. Thank you. Regards",,"['abstract-algebra', 'modules', 'abelian-groups']"
34,Bijection between ideals of $R/I$ and ideals containing $I$,Bijection between ideals of  and ideals containing,R/I I,I read that there is a one-one correspondence between the ideals of $R/I$ and the ideals containing $I$. ($R$ is a ring and $I$ is any ideal in $R$) Is this bijection obvious? It's not to me. Can someone tell me what the bijection looks like explicitly? Many thanks for your help!,I read that there is a one-one correspondence between the ideals of $R/I$ and the ideals containing $I$. ($R$ is a ring and $I$ is any ideal in $R$) Is this bijection obvious? It's not to me. Can someone tell me what the bijection looks like explicitly? Many thanks for your help!,,"['abstract-algebra', 'ring-theory']"
35,A Particular Two-Variable System in a Group,A Particular Two-Variable System in a Group,,"Suppose $a$ and $b$ are elements of a group $G$. If $a^{-1}b^{2}a=b^{3}$ and $b^{-1}a^{2}b=a^{3}$, prove $a=e=b$. I've been trying to prove but still inconclusive. Please prove to me.  Thanks very much for proof.","Suppose $a$ and $b$ are elements of a group $G$. If $a^{-1}b^{2}a=b^{3}$ and $b^{-1}a^{2}b=a^{3}$, prove $a=e=b$. I've been trying to prove but still inconclusive. Please prove to me.  Thanks very much for proof.",,"['abstract-algebra', 'group-theory']"
36,What is a blow-up?,What is a blow-up?,,Can anyone explain to me what a blow-up is? If would be great if someone could provide a definition and some examples. Any free introductory texts are welcome too.  Thanks!,Can anyone explain to me what a blow-up is? If would be great if someone could provide a definition and some examples. Any free introductory texts are welcome too.  Thanks!,,"['abstract-algebra', 'algebraic-geometry', 'terminology', 'blowup']"
37,Galois group of $x^4-2$,Galois group of,x^4-2,"I am trying to explicitly compute the Galois group of $x^4-2$ over $\mathbb{Q}$. I found that the resolvent polynomial is reducible and the order of the Galois group is $8$ using the splitting field $K=\mathbb{Q}(2^{1/4}, i)$. Hence I need to find 8 automorphisms. Thus do I just map elements of the same order to each other that fix the base field $\mathbb{Q}$ $2^{1/4}$ to $i2^{1/4}$","I am trying to explicitly compute the Galois group of $x^4-2$ over $\mathbb{Q}$. I found that the resolvent polynomial is reducible and the order of the Galois group is $8$ using the splitting field $K=\mathbb{Q}(2^{1/4}, i)$. Hence I need to find 8 automorphisms. Thus do I just map elements of the same order to each other that fix the base field $\mathbb{Q}$ $2^{1/4}$ to $i2^{1/4}$",,"['abstract-algebra', 'field-theory', 'galois-theory', 'splitting-field']"
38,Prime ideals in a finite direct product of rings,Prime ideals in a finite direct product of rings,,"Let $S=\prod_{i=1}^{n}{R_i}$ where each $R_i$ is a commutative ring with identity. The prime ideals of $S$ are of the form $\prod_{i=1}^{n}{P_i}$ where for some $j$, $P_j$ is a prime ideal of $R_j$ and for $i\neq j$, $P_i=R_i$.","Let $S=\prod_{i=1}^{n}{R_i}$ where each $R_i$ is a commutative ring with identity. The prime ideals of $S$ are of the form $\prod_{i=1}^{n}{P_i}$ where for some $j$, $P_j$ is a prime ideal of $R_j$ and for $i\neq j$, $P_i=R_i$.",,"['abstract-algebra', 'ideals', 'maximal-and-prime-ideals']"
39,Examples of non-obvious isomorphisms following from the first isomorphism theorem,Examples of non-obvious isomorphisms following from the first isomorphism theorem,,"I am learning the first isomorphism theorem, and I am working with some isomorphisms to practice for my upcoming test. I know some of the basic ones like: $\mathbb{R}/\mathbb{Z} \cong \mathcal{C}$, where $\mathcal{C}$ is the unit circle in the complex plane, under the isomorphism $$x+\mathbb{Z}\mapsto e^{2\pi x i}$$ $\dfrac{\mathbb Z \times \mathbb Z}{\langle (m,n)\rangle}\cong\mathbb Z$, where $m,n$ are integers. $\dfrac{\mathbb R^\star}{\{1, -1\}} \cong \mathbb R^+$. I would like to see more examples of such isomorphisms, intended both as a reference and to help me study for the test! Thank you.","I am learning the first isomorphism theorem, and I am working with some isomorphisms to practice for my upcoming test. I know some of the basic ones like: $\mathbb{R}/\mathbb{Z} \cong \mathcal{C}$, where $\mathcal{C}$ is the unit circle in the complex plane, under the isomorphism $$x+\mathbb{Z}\mapsto e^{2\pi x i}$$ $\dfrac{\mathbb Z \times \mathbb Z}{\langle (m,n)\rangle}\cong\mathbb Z$, where $m,n$ are integers. $\dfrac{\mathbb R^\star}{\{1, -1\}} \cong \mathbb R^+$. I would like to see more examples of such isomorphisms, intended both as a reference and to help me study for the test! Thank you.",,"['abstract-algebra', 'group-theory', 'big-list', 'exceptional-isomorphisms']"
40,Is every group the unit group of some ring?,Is every group the unit group of some ring?,,"Let the functor $F\colon\bf Ring\rightarrow\bf Grp$ send the ring $A$ to its group of units $A^\times,$ and the ring homomorphism $f\colon A\rightarrow B$ to the group homomorphism $f^\times\colon A^\times\rightarrow B^\times:a\mapsto f(a)$ . I was curious about this functor, and in particular, whether it is essentially surjective. That is, for any group $G$ (not just finite,) is there a ring $A$ such that $G\cong A^\times$ ? If not, what groups $G$ satisfies this? A similar question was asked in this question, but what can be said for infinite groups, or groups in general? Calling groups that satisfy this condition R-groups, I have proved that any finitely generated abelian group is an R-group. I have no idea what to do from now, but I  have a conjecture that the unit group of the group ring $\mathbb F_2[G]$ is isomorphic to $G.$ If this is true, certainly, all groups are R-groups, and the functor $F$ is essentially surjective, but I am having trouble proving it. Can anyone help me?","Let the functor send the ring to its group of units and the ring homomorphism to the group homomorphism . I was curious about this functor, and in particular, whether it is essentially surjective. That is, for any group (not just finite,) is there a ring such that ? If not, what groups satisfies this? A similar question was asked in this question, but what can be said for infinite groups, or groups in general? Calling groups that satisfy this condition R-groups, I have proved that any finitely generated abelian group is an R-group. I have no idea what to do from now, but I  have a conjecture that the unit group of the group ring is isomorphic to If this is true, certainly, all groups are R-groups, and the functor is essentially surjective, but I am having trouble proving it. Can anyone help me?","F\colon\bf Ring\rightarrow\bf Grp A A^\times, f\colon A\rightarrow B f^\times\colon A^\times\rightarrow B^\times:a\mapsto f(a) G A G\cong A^\times G \mathbb F_2[G] G. F","['abstract-algebra', 'group-theory', 'ring-theory', 'category-theory', 'abelian-groups']"
41,"If the tensor power $M^{\otimes n} = 0$, is it possible that $M^{\otimes n-1}$ is nonzero?","If the tensor power , is it possible that  is nonzero?",M^{\otimes n} = 0 M^{\otimes n-1},"Let $M$ be a module over a commutative ring $R$. It is possible that $M \otimes M = 0$ if $M$ is nonzero, for example when $R = \mathbb{Z}$ and $M = \mathbb{Q}/ \mathbb{Z}$. What about when higher tensor powers of $M$ are zero? If $M \otimes M \otimes M = 0$, is it possible that $M \otimes M$ is nonzero? More generally if $M^{\otimes n} = 0$ for $n \geq 3$, is it possible that $M^{\otimes n-1}$ is nonzero? Can we find examples among $\mathbb{Z}$-modules (abelian groups)? Here $M^{\otimes n} = M \otimes \cdots \otimes M$ denotes the tensor product of $M$ with itself $n$ times.","Let $M$ be a module over a commutative ring $R$. It is possible that $M \otimes M = 0$ if $M$ is nonzero, for example when $R = \mathbb{Z}$ and $M = \mathbb{Q}/ \mathbb{Z}$. What about when higher tensor powers of $M$ are zero? If $M \otimes M \otimes M = 0$, is it possible that $M \otimes M$ is nonzero? More generally if $M^{\otimes n} = 0$ for $n \geq 3$, is it possible that $M^{\otimes n-1}$ is nonzero? Can we find examples among $\mathbb{Z}$-modules (abelian groups)? Here $M^{\otimes n} = M \otimes \cdots \otimes M$ denotes the tensor product of $M$ with itself $n$ times.",,"['abstract-algebra', 'modules', 'examples-counterexamples', 'abelian-groups', 'tensor-products']"
42,"Why the terminology ""monoid""?","Why the terminology ""monoid""?",,"As I am not a native English speaker, I sometimes am bothered a little with the word ""monoid"", which is by definition a semigroup with identity. But why this terminology? I searched some dictionaries (Longman for English, Larousse for Francais, Langenscheidts for Dentsch) but didn't find any result, and it seems to me that it is just a pronounciable word with certain mathematical meaning. So, where does it come from? Is there any etymological explanation? Who was the first mathematician who used it?","As I am not a native English speaker, I sometimes am bothered a little with the word ""monoid"", which is by definition a semigroup with identity. But why this terminology? I searched some dictionaries (Longman for English, Larousse for Francais, Langenscheidts for Dentsch) but didn't find any result, and it seems to me that it is just a pronounciable word with certain mathematical meaning. So, where does it come from? Is there any etymological explanation? Who was the first mathematician who used it?",,"['abstract-algebra', 'terminology', 'math-history', 'monoid']"
43,"For polynomial $f$, does $f$(rational) = rational$^2$ always imply that $f(x) = g(x)^2$?","For polynomial , does (rational) = rational always imply that ?",f f ^2 f(x) = g(x)^2,"If $f(x)$ is a polynomial with rational coefficients such that for every rational number $r$, $f(r)$ is the square of a rational number, can we conclude that $f(x) = g(x)^2$ for some other polynomial $g(x)$ with rational coefficients? I proved the quadratic case in my answer to this question , and am guessing that the general case is true, but don't know how to proceed. Does this extend to polynomials in several variables? What about in different fields of fractions? Note: this is not true for complex numbers, since every complex value is the square of a complex number, but linear polynomials are not perfect squares It seems like the proper formulation of this question is that if $f(x_1, x_2, \ldots x_n)$ is a polynomial with integer coefficients such that every integer specialization of $x_1, x_2, \ldots, x_n$ is a perfect $p$th power, then $f$ is a perfect $p$th power polynomial. A proof is available here , which further shows that it only needs to hold for some $|x_i| < C$ (though it's a humongous $C$). Theorem 4 answers the question above and is similar to that presented by Franklin. The multi-variable case is dealt with via induction.","If $f(x)$ is a polynomial with rational coefficients such that for every rational number $r$, $f(r)$ is the square of a rational number, can we conclude that $f(x) = g(x)^2$ for some other polynomial $g(x)$ with rational coefficients? I proved the quadratic case in my answer to this question , and am guessing that the general case is true, but don't know how to proceed. Does this extend to polynomials in several variables? What about in different fields of fractions? Note: this is not true for complex numbers, since every complex value is the square of a complex number, but linear polynomials are not perfect squares It seems like the proper formulation of this question is that if $f(x_1, x_2, \ldots x_n)$ is a polynomial with integer coefficients such that every integer specialization of $x_1, x_2, \ldots, x_n$ is a perfect $p$th power, then $f$ is a perfect $p$th power polynomial. A proof is available here , which further shows that it only needs to hold for some $|x_i| < C$ (though it's a humongous $C$). Theorem 4 answers the question above and is similar to that presented by Franklin. The multi-variable case is dealt with via induction.",,"['abstract-algebra', 'polynomials']"
44,Difference between centralizer and center groups?,Difference between centralizer and center groups?,,"This is probably stupid question, but I can't see the difference between the two subgroups: $$C_G(A)=\{g\in G| gag^{-1}=a,\forall a\in A\}$$ $$Z(G)=\{g\in G| ga=ag,\forall a\in G\}$$ Is the difference that the centralizer takes a subset $A\in G$ and the center always uses the entire group $G$?","This is probably stupid question, but I can't see the difference between the two subgroups: $$C_G(A)=\{g\in G| gag^{-1}=a,\forall a\in A\}$$ $$Z(G)=\{g\in G| ga=ag,\forall a\in G\}$$ Is the difference that the centralizer takes a subset $A\in G$ and the center always uses the entire group $G$?",,"['abstract-algebra', 'group-theory']"
45,Categorical description of algebraic structures,Categorical description of algebraic structures,,"There is a well-known description of a group as ""a category with one object in which all morphisms are invertible."" As I understand it, the Yoneda Lemma applied to such a category is simply a statement of Cayley's Theorem that every group G is isomorphic to a subset of the symmetric group on G (see the aside at the bottom of this post... I'm still a little confused on this). Assuming that I will make this clear in my own mind in the future, are there similar categorical descriptions of other algebraic object, eg rings, fields, modules, vector spaces? If so, what does the Yoneda Lemma tell us about the representability (or otherwise) of those objects? In particular, are there `nice' characterisations of other algebraic objects which correspond to the characterisation of a group arising from Cayley's Theorem as ""subgroups of Sym(X) for some X""? Aside to (attempt to) work through the details of this: If $C$ is a category with one object $G$, then $h^G=\mathrm{Hom}(G,-)$ corresponds to the regular action of $G$ on itself (it takes $G$ to itself and takes the group element $f$ to the homomorphism $h_f(g)=f\circ g$). Any functor $F:C\to\mathbf{Set}$ with $F(G)=X$ gives a concrete model for the group, and the fact that natural transformations from $h^G$ to $F$ are 1-1 with elements of $X$ tells us that $G$ is isomorphic to a subgroup of $\mathrm{Sym}(X)$... somehow?","There is a well-known description of a group as ""a category with one object in which all morphisms are invertible."" As I understand it, the Yoneda Lemma applied to such a category is simply a statement of Cayley's Theorem that every group G is isomorphic to a subset of the symmetric group on G (see the aside at the bottom of this post... I'm still a little confused on this). Assuming that I will make this clear in my own mind in the future, are there similar categorical descriptions of other algebraic object, eg rings, fields, modules, vector spaces? If so, what does the Yoneda Lemma tell us about the representability (or otherwise) of those objects? In particular, are there `nice' characterisations of other algebraic objects which correspond to the characterisation of a group arising from Cayley's Theorem as ""subgroups of Sym(X) for some X""? Aside to (attempt to) work through the details of this: If $C$ is a category with one object $G$, then $h^G=\mathrm{Hom}(G,-)$ corresponds to the regular action of $G$ on itself (it takes $G$ to itself and takes the group element $f$ to the homomorphism $h_f(g)=f\circ g$). Any functor $F:C\to\mathbf{Set}$ with $F(G)=X$ gives a concrete model for the group, and the fact that natural transformations from $h^G$ to $F$ are 1-1 with elements of $X$ tells us that $G$ is isomorphic to a subgroup of $\mathrm{Sym}(X)$... somehow?",,"['abstract-algebra', 'group-theory', 'category-theory', 'representation-theory', 'intuition']"
46,Product of principal ideals: $(a)\cdot (b) = (a b)$,Product of principal ideals:,(a)\cdot (b) = (a b),"In which kinds of rings $R$ does the following hold: $$(a)\cdot (b) = (ab) \; ?$$ With $a, b\in R$, $(a)$ denoting the (two-sided) ideal generated by $a$ and the multiplication of ideals $I, J\subset R$ defined as  $$ I\cdot J = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I, y_i \in J \biggr\}\, .$$ It seems to me that it only holds for commutative rings with $1$. Is that right? Ok, I'm trying a proof: Let $R$ be commutative with $1\in R$. Then $(a)\cdot (b) = (a b)$ for any $a, b\in R$. First let $I_a := \{ra : r\in R\}$, we're going to show that  $$(a) = I_a\, .$$ $I_a$ is obviously an ideal. Since $1 \in R$ we have $1 \cdot a \in I_a$, so $(a) \subset I_a$. On the other hand, any $x \in I_a$ can be written as $x = ra$ and so must be an element of $(a)$. This proves that $(a) = I_a$. Then $$(a)\cdot (b) = I_a \cdot I_b = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I_a, y_i \in I_b \biggr\}  = \biggl\{\sum_{i=1}^n (r_i a)  (s_i b) : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b \sum_{i=1}^n r_i s_i : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b r : r \in R \biggr\} = I_{ab} = (ab)\, .$$ We obviously had to use that $R$ is commutative. In the last step we also used that every $r \in R$ can be written as $r=\sum_{i=1}^n r_i s_i$. This is because $1 \in R$, so with $n=1$ we have $r = 1\cdot r$.","In which kinds of rings $R$ does the following hold: $$(a)\cdot (b) = (ab) \; ?$$ With $a, b\in R$, $(a)$ denoting the (two-sided) ideal generated by $a$ and the multiplication of ideals $I, J\subset R$ defined as  $$ I\cdot J = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I, y_i \in J \biggr\}\, .$$ It seems to me that it only holds for commutative rings with $1$. Is that right? Ok, I'm trying a proof: Let $R$ be commutative with $1\in R$. Then $(a)\cdot (b) = (a b)$ for any $a, b\in R$. First let $I_a := \{ra : r\in R\}$, we're going to show that  $$(a) = I_a\, .$$ $I_a$ is obviously an ideal. Since $1 \in R$ we have $1 \cdot a \in I_a$, so $(a) \subset I_a$. On the other hand, any $x \in I_a$ can be written as $x = ra$ and so must be an element of $(a)$. This proves that $(a) = I_a$. Then $$(a)\cdot (b) = I_a \cdot I_b = \biggl\{\sum_{i=1}^n x_i y_i : n\in\mathbb{N}, x_i \in I_a, y_i \in I_b \biggr\}  = \biggl\{\sum_{i=1}^n (r_i a)  (s_i b) : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b \sum_{i=1}^n r_i s_i : n\in\mathbb{N}, r_i, s_i \in R \biggr\} = \biggl\{a b r : r \in R \biggr\} = I_{ab} = (ab)\, .$$ We obviously had to use that $R$ is commutative. In the last step we also used that every $r \in R$ can be written as $r=\sum_{i=1}^n r_i s_i$. This is because $1 \in R$, so with $n=1$ we have $r = 1\cdot r$.",,"['abstract-algebra', 'ring-theory']"
47,Order of an element in a finite cyclic group,Order of an element in a finite cyclic group,,"Let $G$ be a cyclic group of order $m$ generated by an element $a$.  I want to show that the order of $a^k$ is $m/d$, where $d:=\gcd(k,m)$.  I have a simple proof, but want to make sure I haven't overlooked anything since the other proofs I've seen (such as in Dummit and Foote) look more complicated. The order of $a^k$ is the cardinality of the set $\{a^{ks}: s \in \mathbb{Z}\}$, which equals the cardinality of the set $\{a^{ks} a^{mt}: s,t \in \mathbb{Z} \}$ since $a^m$ is the identity.  But the set $\{ks+mt: s,t \in \mathbb{Z} \}$ is the set $d \mathbb{Z}$ by the basic properties of integers. So we have that the cardinality of the set is $| \langle a^k \rangle| = |\{1, a^d, a^{2d}, \ldots, a^{m-d} \}| = m/d$.","Let $G$ be a cyclic group of order $m$ generated by an element $a$.  I want to show that the order of $a^k$ is $m/d$, where $d:=\gcd(k,m)$.  I have a simple proof, but want to make sure I haven't overlooked anything since the other proofs I've seen (such as in Dummit and Foote) look more complicated. The order of $a^k$ is the cardinality of the set $\{a^{ks}: s \in \mathbb{Z}\}$, which equals the cardinality of the set $\{a^{ks} a^{mt}: s,t \in \mathbb{Z} \}$ since $a^m$ is the identity.  But the set $\{ks+mt: s,t \in \mathbb{Z} \}$ is the set $d \mathbb{Z}$ by the basic properties of integers. So we have that the cardinality of the set is $| \langle a^k \rangle| = |\{1, a^d, a^{2d}, \ldots, a^{m-d} \}| = m/d$.",,"['abstract-algebra', 'group-theory', 'ring-theory']"
48,What is the significance of Hermitian forms on local rings?,What is the significance of Hermitian forms on local rings?,,"I am a first year math student at UNMSM, in Lima, Peru. My father is an 80-year-old man, a retired university professor, a Ph.D. in pure mathematics, and a passionate algebraist. He kept his mental faculties perfectly until a year ago when a stroke took away some parts of his memory and personality. His love for mathematics did not vanish instantly, but his interest in talking about it waned as he found it increasingly difficult to follow the ideas presented to him. He would usually refrain from making comments when I would share something that I find interesting about some math. He tells me ""sure yes or sure no, but who cares"" (pretty basic things, calculus or basic number theory, mostly). In the past he spoke passionately about ring theory, homological algebra, among other topics. He finds impressive how structures and theories like these exist and the beautiful theorems that are proven in theorems he proved in them. In particular, was on ""Hermitian forms on local rings"" . Could someone give me the significance and interesting results of this field so I can try having conversations with my dad again?","I am a first year math student at UNMSM, in Lima, Peru. My father is an 80-year-old man, a retired university professor, a Ph.D. in pure mathematics, and a passionate algebraist. He kept his mental faculties perfectly until a year ago when a stroke took away some parts of his memory and personality. His love for mathematics did not vanish instantly, but his interest in talking about it waned as he found it increasingly difficult to follow the ideas presented to him. He would usually refrain from making comments when I would share something that I find interesting about some math. He tells me ""sure yes or sure no, but who cares"" (pretty basic things, calculus or basic number theory, mostly). In the past he spoke passionately about ring theory, homological algebra, among other topics. He finds impressive how structures and theories like these exist and the beautiful theorems that are proven in theorems he proved in them. In particular, was on ""Hermitian forms on local rings"" . Could someone give me the significance and interesting results of this field so I can try having conversations with my dad again?",,['abstract-algebra']
49,"$G$ is finite, $A \leq G$ and all double cosets $AxA$ have the same cardinality, show that $A \triangleleft G$ [duplicate]","is finite,  and all double cosets  have the same cardinality, show that  [duplicate]",G A \leq G AxA A \triangleleft G,"This question already has answers here : $|AxA|$ is a constant implies normal subgroup (2 answers) Closed 7 years ago . If $G$ is a finite group and $A$ is a subgroup of $G$ such that all double cosets $AxA$ have the same number of elements, show that $gAg^{-1}=A$ for all $g \in G$. Here is my attempt, I guess it's correct but please verify it. I looked for this problem on the internet but I found it nowhere, so I thought it might be a good idea to have an answer for it on MSE: We know that for $x,y \in G$ we have $|AxA|=|AyA|$ by hypothesis of the problem. In particular for any $g \in G$ we have $|AgA|=|AeA|=|AA|=|A|$. In other words, all double cosets $AgA$ have the same number of elements as $A$ for any $g \in G$. Now, we use the following counting formula: $$|AxB|=\frac{|A||B|}{|A \cap xBx^{-1}|}$$ with $A=B$ and $ \forall g \in G:|AgA|=|A|$  we obtain: $$ |A| = \frac{|A||A|}{|A \cap gAg^{-1}|} \implies |A \cap gAg^{-1}|=|A| $$ But $A \cap gAg^{-1} \subseteq A$ and since $G$ is finite and $|A \cap gAg^{-1}|=|A|$ it forces $A \cap gAg^{-1} = A$. That implies $A \subseteq gAg^{-1}$ for any $g \in G$, which is the same as $g^{-1}Ag \subseteq A$ for any $g \in G$ and this proves the normality of $A$ in $G$. Q.E.D.","This question already has answers here : $|AxA|$ is a constant implies normal subgroup (2 answers) Closed 7 years ago . If $G$ is a finite group and $A$ is a subgroup of $G$ such that all double cosets $AxA$ have the same number of elements, show that $gAg^{-1}=A$ for all $g \in G$. Here is my attempt, I guess it's correct but please verify it. I looked for this problem on the internet but I found it nowhere, so I thought it might be a good idea to have an answer for it on MSE: We know that for $x,y \in G$ we have $|AxA|=|AyA|$ by hypothesis of the problem. In particular for any $g \in G$ we have $|AgA|=|AeA|=|AA|=|A|$. In other words, all double cosets $AgA$ have the same number of elements as $A$ for any $g \in G$. Now, we use the following counting formula: $$|AxB|=\frac{|A||B|}{|A \cap xBx^{-1}|}$$ with $A=B$ and $ \forall g \in G:|AgA|=|A|$  we obtain: $$ |A| = \frac{|A||A|}{|A \cap gAg^{-1}|} \implies |A \cap gAg^{-1}|=|A| $$ But $A \cap gAg^{-1} \subseteq A$ and since $G$ is finite and $|A \cap gAg^{-1}|=|A|$ it forces $A \cap gAg^{-1} = A$. That implies $A \subseteq gAg^{-1}$ for any $g \in G$, which is the same as $g^{-1}Ag \subseteq A$ for any $g \in G$ and this proves the normality of $A$ in $G$. Q.E.D.",,"['abstract-algebra', 'group-theory']"
50,"Difference between free groups, free product of two groups, tensor product of two infinite cyclic groups","Difference between free groups, free product of two groups, tensor product of two infinite cyclic groups",,"Let $\mathbb{Z} * \mathbb{Z}$ be the free product of $\mathbb{Z}$ and $\mathbb{Z}$. Let $\mathbb{Z} \otimes \mathbb{Z}$ be the tensor product. What are differences among $\mathbb{Z} * \mathbb{Z}$, $\mathbb{Z} \otimes \mathbb{Z}$, and the free abelian group with two generators?","Let $\mathbb{Z} * \mathbb{Z}$ be the free product of $\mathbb{Z}$ and $\mathbb{Z}$. Let $\mathbb{Z} \otimes \mathbb{Z}$ be the tensor product. What are differences among $\mathbb{Z} * \mathbb{Z}$, $\mathbb{Z} \otimes \mathbb{Z}$, and the free abelian group with two generators?",,"['abstract-algebra', 'group-theory', 'tensor-products', 'abelian-groups', 'free-product']"
51,Clarifying the homomorphism's definition?,Clarifying the homomorphism's definition?,,"So, I've heard a lot that homomorphism is a structure-preserving mapping between somewhat algebraic objects. Rigorous definition is:  $f(x \circ y) = (f x) \circ (f y)$. And it's not clear enough for me why operation from the left (denoted as $\circ$) remains unchanged on the right ? Does it mean that homomorphism suppose to work only with algebraic objects sharing the same operation? Or this definition is just not enough explicit, shadowing the fact that $\circ$ gets mapped as well to a, let say, $\bullet$ and those are different in general? Intuitively it feels like $f(x \circ y) = (f x) \bullet (f y)$ would be more correct.","So, I've heard a lot that homomorphism is a structure-preserving mapping between somewhat algebraic objects. Rigorous definition is:  $f(x \circ y) = (f x) \circ (f y)$. And it's not clear enough for me why operation from the left (denoted as $\circ$) remains unchanged on the right ? Does it mean that homomorphism suppose to work only with algebraic objects sharing the same operation? Or this definition is just not enough explicit, shadowing the fact that $\circ$ gets mapped as well to a, let say, $\bullet$ and those are different in general? Intuitively it feels like $f(x \circ y) = (f x) \bullet (f y)$ would be more correct.",,"['abstract-algebra', 'definition']"
52,How to prove that the Frobenius endomorphism is surjective?,How to prove that the Frobenius endomorphism is surjective?,,"$R$ is a domain with characteristic $p$ ($p$ is prime). There is a homomorphism $f : R \to R$, $f(a)=a^p$. $f$ is called the Frobenius endomorphism . And I have known this. When $R$ which is mentioned above is also a field, it is said that $f$ is an isomorphism. I think I just need to ensure $f$ is bijective. But I don't know how to prove it's surjective. Actually I have got your ideas. In some of your opinions, if it is finite, then it can be surjective. Then what if it is infinite? In my question, $R$ is a field as well as a domain. Then I wonder whether the ""domain"" is helpful for the proof of surjection or not.","$R$ is a domain with characteristic $p$ ($p$ is prime). There is a homomorphism $f : R \to R$, $f(a)=a^p$. $f$ is called the Frobenius endomorphism . And I have known this. When $R$ which is mentioned above is also a field, it is said that $f$ is an isomorphism. I think I just need to ensure $f$ is bijective. But I don't know how to prove it's surjective. Actually I have got your ideas. In some of your opinions, if it is finite, then it can be surjective. Then what if it is infinite? In my question, $R$ is a field as well as a domain. Then I wonder whether the ""domain"" is helpful for the proof of surjection or not.",,"['abstract-algebra', 'field-theory', 'integral-domain']"
53,Eigenvector and eigenvalue for exponential matrix,Eigenvector and eigenvalue for exponential matrix,,"$X$ is a matrix. Let $v$ be an eigenvector of $X$ with corresponding eigenvalue $a$. Show that $v$ is also an eigenvector of $e^{X}$ with eigenvalue $e^{a}$ If $X$ is diagonalizable, then we can start writing out terms using Taylor expansion of $e^{X}$ but I can't seem to get anywhere. Thanks for the help Edit: Corrected question to read ' Let $v$ be an eigenvector of $X$' instead of ' Let $v$ be an eigenvector of $e^X$'.","$X$ is a matrix. Let $v$ be an eigenvector of $X$ with corresponding eigenvalue $a$. Show that $v$ is also an eigenvector of $e^{X}$ with eigenvalue $e^{a}$ If $X$ is diagonalizable, then we can start writing out terms using Taylor expansion of $e^{X}$ but I can't seem to get anywhere. Thanks for the help Edit: Corrected question to read ' Let $v$ be an eigenvector of $X$' instead of ' Let $v$ be an eigenvector of $e^X$'.",,"['abstract-algebra', 'matrices', 'eigenvalues-eigenvectors', 'exponential-function', 'diagonalization']"
54,"How can a field have a finite characteristic $p$, given that a field has no zero divisors?","How can a field have a finite characteristic , given that a field has no zero divisors?",p,The characteristic of a field is defined to be the smallest positive integer $p$ such that $$p \cdot 1 = 0.$$ But I have learned that field has no zero divisors. How is this possible?,The characteristic of a field is defined to be the smallest positive integer such that But I have learned that field has no zero divisors. How is this possible?,p p \cdot 1 = 0.,"['abstract-algebra', 'field-theory', 'positive-characteristic']"
55,Abelian groups and $\mathbb{Z}$-modules,Abelian groups and -modules,\mathbb{Z},We know that any Abelian group is a $\mathbb{Z}$-module. Is the converse true?,We know that any Abelian group is a $\mathbb{Z}$-module. Is the converse true?,,['abstract-algebra']
56,What are zero divisors used for?,What are zero divisors used for?,,"This is the first time I hear this term. Specifically the assertion is that $\mathbb{Z}$ has no zero divisors. So, from my understanding this is because there are not two non-zero numbers $a,b\in \mathbb{Z}$ such that $ab=0$. Also I can see that this definition is related to the one I learnt in high school that $a$ divides $0$ if $\exists b\in\mathbb{Z}\ (ba=0)$, the difference being that we need to consider the restriction $a,b\neq 0$ when dealing with zero divisors. What is the motivation of zero divisors? what are they used for?","This is the first time I hear this term. Specifically the assertion is that $\mathbb{Z}$ has no zero divisors. So, from my understanding this is because there are not two non-zero numbers $a,b\in \mathbb{Z}$ such that $ab=0$. Also I can see that this definition is related to the one I learnt in high school that $a$ divides $0$ if $\exists b\in\mathbb{Z}\ (ba=0)$, the difference being that we need to consider the restriction $a,b\neq 0$ when dealing with zero divisors. What is the motivation of zero divisors? what are they used for?",,['abstract-algebra']
57,How is graduate abstract algebra different from undergraduate abstract algebra?,How is graduate abstract algebra different from undergraduate abstract algebra?,,"I am currently an undergraduate math student. (In fact, freshmen.) I know that usually abstract algebra is taught somehow late in the undergraduate course, and curious how studies of abstract algebra at graduate level differ from studies at undergraduate level. So, things like what gets new treatment, or what is learned new are what I want to know.","I am currently an undergraduate math student. (In fact, freshmen.) I know that usually abstract algebra is taught somehow late in the undergraduate course, and curious how studies of abstract algebra at graduate level differ from studies at undergraduate level. So, things like what gets new treatment, or what is learned new are what I want to know.",,"['abstract-algebra', 'soft-question']"
58,"Maximal ideals in the ring of real functions on $[0,1]$ [closed]",Maximal ideals in the ring of real functions on  [closed],"[0,1]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $S$ be the ring of all continuous functions from $[0,1]$ to $\mathbb R$. How to prove that all maximal ideals of $S$ have the form $M_{x_0}=\{f\in S \mid f(x_0)=0\}$? Thanks in advance.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Let $S$ be the ring of all continuous functions from $[0,1]$ to $\mathbb R$. How to prove that all maximal ideals of $S$ have the form $M_{x_0}=\{f\in S \mid f(x_0)=0\}$? Thanks in advance.",,"['abstract-algebra', 'analysis', 'ideals', 'maximal-and-prime-ideals']"
59,Show group of order $4n + 2$ has a subgroup of index 2.,Show group of order  has a subgroup of index 2.,4n + 2,"Let $n$ be a positive integer. Show that any group of order $4n + 2$ has a subgroup of index 2. (Hint: Use left regular representation and Cauchy's Theorem to get an odd permutation.) I can easily observe that $\vert G \vert = 2(2n + 1)$ so $2 \mid \vert G \vert$ and 2 is prime. We have satisfied the hypothesis of Cauchy's Theorem so we can say $G$ contains an element of order 2. This is where I am stuck I am confused about how the left regular representation relates to the group. So my understanding at this point is that every group is isomorphic to a subgroup of some symmetric group. My question: is the left regular representation $\varphi : G \to S_G$ an isomorphism? where $G \cong S_G$ or is $S_G$ the same thing as $S_{\vert G \vert}$ and $\varphi$ is only an injection? I'm using Dummit and Foote for definitions. I saw an argument online that said that since we have an element of order 2, there is a $\sigma \in S_G$ of order 2, but it is a product of $2n + 1$ disjoint 2-cycles. I don't understand how they could claim this and tried working it out on my own but didn't get there. -- They then went on to use the parity mapping $\varepsilon : S_G \to \{\pm1\}$ and since we have an odd permutation $\sigma$, we have $[S_G:\text{ker }\varepsilon] = 2$. I understood their computation but not how that directly shows that $G$ has a subgroup of order 2? unless $G \cong S_G$ because of how left regular representation is defined. (but again, I'm not understanding that concept very well yet.) So, to be clear about my questions: What is meant by left regular representation, is it an isomorphism or just an injection? and how would it be used here. If it is an isomorphism, the argument online starts to make more sense, but how can they say that since $\sigma$ is even, it is made up of $2n + 1$ disjoint transpositions? If you have a full, proof, I'd appreciate it, but good hints are just as good! Thanks you!","Let $n$ be a positive integer. Show that any group of order $4n + 2$ has a subgroup of index 2. (Hint: Use left regular representation and Cauchy's Theorem to get an odd permutation.) I can easily observe that $\vert G \vert = 2(2n + 1)$ so $2 \mid \vert G \vert$ and 2 is prime. We have satisfied the hypothesis of Cauchy's Theorem so we can say $G$ contains an element of order 2. This is where I am stuck I am confused about how the left regular representation relates to the group. So my understanding at this point is that every group is isomorphic to a subgroup of some symmetric group. My question: is the left regular representation $\varphi : G \to S_G$ an isomorphism? where $G \cong S_G$ or is $S_G$ the same thing as $S_{\vert G \vert}$ and $\varphi$ is only an injection? I'm using Dummit and Foote for definitions. I saw an argument online that said that since we have an element of order 2, there is a $\sigma \in S_G$ of order 2, but it is a product of $2n + 1$ disjoint 2-cycles. I don't understand how they could claim this and tried working it out on my own but didn't get there. -- They then went on to use the parity mapping $\varepsilon : S_G \to \{\pm1\}$ and since we have an odd permutation $\sigma$, we have $[S_G:\text{ker }\varepsilon] = 2$. I understood their computation but not how that directly shows that $G$ has a subgroup of order 2? unless $G \cong S_G$ because of how left regular representation is defined. (but again, I'm not understanding that concept very well yet.) So, to be clear about my questions: What is meant by left regular representation, is it an isomorphism or just an injection? and how would it be used here. If it is an isomorphism, the argument online starts to make more sense, but how can they say that since $\sigma$ is even, it is made up of $2n + 1$ disjoint transpositions? If you have a full, proof, I'd appreciate it, but good hints are just as good! Thanks you!",,"['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
60,Proving that $\mathbb R^3$ cannot be made into a real division algebra (and that extending complex multiplication would not work),Proving that  cannot be made into a real division algebra (and that extending complex multiplication would not work),\mathbb R^3,"I am trying to solve the following exercise: Prove that complex multiplication does not extend to a multiplication   on $\mathbb R^3$ so as to make $\mathbb R^3$ into a real division   algebra. I am aware of Frobenius' theorem that there are only three finite dimensional real associative division algebras. But the exercise would be pointless if the theorem was assumed. Let $x,y \in \mathbb R^3$. Since $x y$ has to extend the complex multiplication: $$xy = (x_1y_1-x_2y_2, x_1y_2 + x_2 y_1, ?)$$ I have no idea how I can proceed from here. Could someone tell me how to do this? It should be easy as the other exercises I did so far were also easy.","I am trying to solve the following exercise: Prove that complex multiplication does not extend to a multiplication   on $\mathbb R^3$ so as to make $\mathbb R^3$ into a real division   algebra. I am aware of Frobenius' theorem that there are only three finite dimensional real associative division algebras. But the exercise would be pointless if the theorem was assumed. Let $x,y \in \mathbb R^3$. Since $x y$ has to extend the complex multiplication: $$xy = (x_1y_1-x_2y_2, x_1y_2 + x_2 y_1, ?)$$ I have no idea how I can proceed from here. Could someone tell me how to do this? It should be easy as the other exercises I did so far were also easy.",,"['abstract-algebra', 'lie-groups', 'quaternions', 'division-algebras']"
61,Why is an integral domain a commutative ring with unity?,Why is an integral domain a commutative ring with unity?,,"I was wondering why an integral domain is required to be commutative and have a multiplicative neutral element. For example the quaternions would be a non-commutative integral domain. The interesting property is that it has no zero divisors, so why require it to be commutative and have a $1$? In other words: what consequences follow from having a one vs. not having one when investigating rings without zero divisors?","I was wondering why an integral domain is required to be commutative and have a multiplicative neutral element. For example the quaternions would be a non-commutative integral domain. The interesting property is that it has no zero divisors, so why require it to be commutative and have a $1$? In other words: what consequences follow from having a one vs. not having one when investigating rings without zero divisors?",,"['abstract-algebra', 'soft-question', 'ring-theory']"
62,Is there a property that is not preserved by isomorphism? [closed],Is there a property that is not preserved by isomorphism? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Isomorphism preserves the operation of domain, so codomain inherits some properties of domain related to operation. So isomorphism is somewhat like ""Equivalence"". But, if the property of domain is not ""related to operation"", maybe that property is not preserved. So is there a property that is not preserved by isomorphism? Or Isomorphism is a ""generalized equivalence""? Thank you for your answer in advance, and I apologize for my terrible English.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question Isomorphism preserves the operation of domain, so codomain inherits some properties of domain related to operation. So isomorphism is somewhat like ""Equivalence"". But, if the property of domain is not ""related to operation"", maybe that property is not preserved. So is there a property that is not preserved by isomorphism? Or Isomorphism is a ""generalized equivalence""? Thank you for your answer in advance, and I apologize for my terrible English.",,['abstract-algebra']
63,the degree of a splitting field of a polynomial,the degree of a splitting field of a polynomial,,"Let $f(x)\in F[x]$ be a polynomial of degree $n$. Let $K$ be a splitting field of $f(x)$ over $F$. Then [K:F] must divides $n!$. I only know that $[K:F] \le n!$, but how can I show that $[K:F]$ divides $n!$?","Let $f(x)\in F[x]$ be a polynomial of degree $n$. Let $K$ be a splitting field of $f(x)$ over $F$. Then [K:F] must divides $n!$. I only know that $[K:F] \le n!$, but how can I show that $[K:F]$ divides $n!$?",,"['abstract-algebra', 'field-theory']"
64,Maximal order of an element in a symmetric group,Maximal order of an element in a symmetric group,,"If we let $S_n$ denote the symmetric group on $n$ letters, then any element in $S_n$ can be written as the product of disjoint cycles, and for $k$ disjoint cycles, $\sigma_1,\sigma_2,\ldots,\sigma_k$ , we have that $|\sigma_1\sigma_2\ldots\sigma_k|=\operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k)$ . So to find the maximum order of an element in $S_n$ , we need to maximize $\operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k)$ given that $\sum_{i=1}^k{|\sigma_i|}=n$ . So my question: How can we determine $|\sigma_1|,|\sigma_2|,\ldots,|\sigma_k|$ such that $\sum_{i=1}^k{|\sigma_i|}=n$ and $\operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k)$ is at a maximum? Example For $S_{10}$ we have that the maximal order of an element consists of 3 cycles of length 2,3, and 5 (or so I think) resulting in an element order of $\operatorname{lcm}(2,3,5)=30$ . I'm certain that the all of the magnitudes will have to be relatively prime to achieve the greatest lcm, but other than this, I don't know how to proceed. Any thoughts or references? Thanks so much.","If we let denote the symmetric group on letters, then any element in can be written as the product of disjoint cycles, and for disjoint cycles, , we have that . So to find the maximum order of an element in , we need to maximize given that . So my question: How can we determine such that and is at a maximum? Example For we have that the maximal order of an element consists of 3 cycles of length 2,3, and 5 (or so I think) resulting in an element order of . I'm certain that the all of the magnitudes will have to be relatively prime to achieve the greatest lcm, but other than this, I don't know how to proceed. Any thoughts or references? Thanks so much.","S_n n S_n k \sigma_1,\sigma_2,\ldots,\sigma_k |\sigma_1\sigma_2\ldots\sigma_k|=\operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k) S_n \operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k) \sum_{i=1}^k{|\sigma_i|}=n |\sigma_1|,|\sigma_2|,\ldots,|\sigma_k| \sum_{i=1}^k{|\sigma_i|}=n \operatorname{lcm}(\sigma_1,\sigma_2,\ldots,\sigma_k) S_{10} \operatorname{lcm}(2,3,5)=30","['abstract-algebra', 'group-theory', 'optimization', 'finite-groups', 'symmetric-groups']"
65,Finding the number of elements of particular order in the symmetric group,Finding the number of elements of particular order in the symmetric group,,"I know how to find the order of element in any group $G$, for example the order of $2$ in $\mathbb{Z}_5$ is $5$ as $2 + 2 + 2 + 2 + 2 = [10]_5 = 0 0$, which is the identity in $\mathbb{Z}_5$. But, how to calculate number of element of particular order in symmetric group $S_n$? I know how to calculate order of an element in $S_n$, for example in $S_5$, $(123)(45)$ has an order $6$. But how to calculate easily number of such elements? That is, how to calculate number of elements order $5$, number of elements of order $4$ in $S_5$? Is there is any easy formula? Also is there is any formula to calculate the number of elements of particular order in the alternating group $A_n$ as well?","I know how to find the order of element in any group $G$, for example the order of $2$ in $\mathbb{Z}_5$ is $5$ as $2 + 2 + 2 + 2 + 2 = [10]_5 = 0 0$, which is the identity in $\mathbb{Z}_5$. But, how to calculate number of element of particular order in symmetric group $S_n$? I know how to calculate order of an element in $S_n$, for example in $S_5$, $(123)(45)$ has an order $6$. But how to calculate easily number of such elements? That is, how to calculate number of elements order $5$, number of elements of order $4$ in $S_5$? Is there is any easy formula? Also is there is any formula to calculate the number of elements of particular order in the alternating group $A_n$ as well?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
66,Why are there so many universal properties in math?,Why are there so many universal properties in math?,,"I don't really understand why there are so many universal properties in math or why they all need to be highlighted. For example, I'm studying some Algebra right now.  I have found three universal properties that are all basically saying the same thing, although the details are different: Universal property 1 : If $R, S$ are rings and $\theta: R \to S$ is a ring map, then for each $s \in S$ , there is a unique map $\hat{\theta_{s}} : R[x] \to S$ such that if $i: R \to R[x]$ is the inclusion map, we get $\theta = \hat{\theta_{s}} \circ i$ . Universal property 2 : If $D$ is an integral domain and $F$ is a field with $\phi : D \to F$ a one-to-one ring map, then there is a unique map $\hat{\phi} : Q(D) \to F$ such that $\hat{\phi} \circ \pi = \phi$ , where $\pi : D \to Q(D)$ sends $a$ to $\frac{a}{1}$ ( $Q(D)$ the fractional field of $D$ ). Universal property two was used to prove that in a field of characteristic $0$ , the rationals are a subfield, and in a field of characteristic $p$ ( $p$ prime), $\mathbb{Z}_{p}$ is a subfield. Universal property 3 : If $R, S$ are rings, $\phi: R \to S$ is a ring map, and $I$ is an ideal such that $I \subseteq \text{ker}(\phi)$ , then there is a unique map $\overline{\phi} : R/I \to S$ such that $\phi = \overline{\phi} \circ i$ where $i: R \to R/I$ maps $a$ to $\overline{a}$ . It is really hard for me to keep track of all of these universal properties, especially when they are all usually referenced by the single name ""universal property"".  Is there a point to all of these universal properties? Honestly, I don't even know if my question is clear, or how to ask a better question in this regard.","I don't really understand why there are so many universal properties in math or why they all need to be highlighted. For example, I'm studying some Algebra right now.  I have found three universal properties that are all basically saying the same thing, although the details are different: Universal property 1 : If are rings and is a ring map, then for each , there is a unique map such that if is the inclusion map, we get . Universal property 2 : If is an integral domain and is a field with a one-to-one ring map, then there is a unique map such that , where sends to ( the fractional field of ). Universal property two was used to prove that in a field of characteristic , the rationals are a subfield, and in a field of characteristic ( prime), is a subfield. Universal property 3 : If are rings, is a ring map, and is an ideal such that , then there is a unique map such that where maps to . It is really hard for me to keep track of all of these universal properties, especially when they are all usually referenced by the single name ""universal property"".  Is there a point to all of these universal properties? Honestly, I don't even know if my question is clear, or how to ask a better question in this regard.","R, S \theta: R \to S s \in S \hat{\theta_{s}} : R[x] \to S i: R \to R[x] \theta = \hat{\theta_{s}} \circ i D F \phi : D \to F \hat{\phi} : Q(D) \to F \hat{\phi} \circ \pi = \phi \pi : D \to Q(D) a \frac{a}{1} Q(D) D 0 p p \mathbb{Z}_{p} R, S \phi: R \to S I I \subseteq \text{ker}(\phi) \overline{\phi} : R/I \to S \phi = \overline{\phi} \circ i i: R \to R/I a \overline{a}","['abstract-algebra', 'ring-theory', 'category-theory', 'field-theory']"
67,Why are Noetherian Rings important?,Why are Noetherian Rings important?,,"I know they are important in abstract algebra, but why do people study them? Why are they so important to study? Do they make certain things easier to understand?","I know they are important in abstract algebra, but why do people study them? Why are they so important to study? Do they make certain things easier to understand?",,"['abstract-algebra', 'ring-theory', 'noetherian']"
68,Subring of a finitely generated Noetherian ring need not be Noetherian? [duplicate],Subring of a finitely generated Noetherian ring need not be Noetherian? [duplicate],,"This question already has an answer here : Are intermediate rings of finitely generated ring extensions also finitely generated? (1 answer) Closed 5 years ago . A common example showing that a subring of a Noetherian ring is not necessarily Noetherian is to take a polynomial ring over a field $k$ in infinitely many indeterminates, $k[x_1,x_2,\dots]$. The quotient field is then obviously Noetherian, but the subring $k[x_1,x_2,\dots]$ is not since there is an infinite ascending chain of ideals which never stabilizes. Is there an instance of a finitely generated Noetherian ring over some ground ring $R$, that has an intermediate ring which is not finitely generated over $R$, and hence not Noetherian either?","This question already has an answer here : Are intermediate rings of finitely generated ring extensions also finitely generated? (1 answer) Closed 5 years ago . A common example showing that a subring of a Noetherian ring is not necessarily Noetherian is to take a polynomial ring over a field $k$ in infinitely many indeterminates, $k[x_1,x_2,\dots]$. The quotient field is then obviously Noetherian, but the subring $k[x_1,x_2,\dots]$ is not since there is an infinite ascending chain of ideals which never stabilizes. Is there an instance of a finitely generated Noetherian ring over some ground ring $R$, that has an intermediate ring which is not finitely generated over $R$, and hence not Noetherian either?",,"['abstract-algebra', 'ring-theory', 'noetherian']"
69,Stanford math qual: Abelian groups $G$ satisfying $0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0$,Stanford math qual: Abelian groups  satisfying,G 0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0,"I am studying for my qualifying exams and came across the following question: Find all abelian groups $G$ that fit into an exact sequence $0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0$. From another question on this site, I know I can make a diagram  of the form $$\require{AMScd} \begin{CD} 0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}/3\mathbb{Z} @>>> 0. \end{CD} $$ Let us call the three vertical maps, from left to right respectively $f$, $g$ and $h$. By the Snake Lemma, I can extend the diagram above to one that looks like \begin{CD}  @. 0 @>>>0  @>>>0 @. \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \ker f @>>> \ker g @>>> \ker h @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}3\mathbb{Z} @>>> 0\\ @. @VVV @VVV @VV V @. \\  @. 0 @>>>0  @>>>0 @. \\ \end{CD} Question 1: Since $\ker f = \ker h = \Bbb{Z}$, and $\Bbb{Z}$ is projective I know that the top non-zero row splits, and so $\ker g \cong \Bbb{Z}^2$. Can I say that $\ker f \hookrightarrow \ker g$ is inclusion into the first factor, and $\ker g\to \ker h$ is projection onto the second? If this is true, then I can present $G$ as the cokernel of the relations matrix $$\left(\begin{array}{cc}  0 & a \\ 3 & b \\ 0 & 0 \\ 0 & 3  \end{array}\right)$$ for some integers $a,b\in\Bbb{Z}.$ This comes from analyzing the far top right and top left squares, and of course the assumption that question 1 is true. Question 2: How can I simplify this matrix to give me nice information on what $G$ should be? Edit 1: From the statement of the splitting lemma on pg. 147 of Hatcher , it looks as if I can basically arrange so that what I want in question 1 is true.","I am studying for my qualifying exams and came across the following question: Find all abelian groups $G$ that fit into an exact sequence $0\to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to G \to \Bbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} \to 0$. From another question on this site, I know I can make a diagram  of the form $$\require{AMScd} \begin{CD} 0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}/3\mathbb{Z} @>>> 0. \end{CD} $$ Let us call the three vertical maps, from left to right respectively $f$, $g$ and $h$. By the Snake Lemma, I can extend the diagram above to one that looks like \begin{CD}  @. 0 @>>>0  @>>>0 @. \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \ker f @>>> \ker g @>>> \ker h @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z}^2 @>>> \mathbb{Z}^4 @>>> \mathbb{Z}^2 @>>> 0 \\ @. @VVV @VVV @VV V @. \\ 0 @>>> \mathbb{Z} \oplus \Bbb{Z}/3\Bbb{Z} @>>> G @>>> \mathbb{Z}\oplus \mathbb{Z}3\mathbb{Z} @>>> 0\\ @. @VVV @VVV @VV V @. \\  @. 0 @>>>0  @>>>0 @. \\ \end{CD} Question 1: Since $\ker f = \ker h = \Bbb{Z}$, and $\Bbb{Z}$ is projective I know that the top non-zero row splits, and so $\ker g \cong \Bbb{Z}^2$. Can I say that $\ker f \hookrightarrow \ker g$ is inclusion into the first factor, and $\ker g\to \ker h$ is projection onto the second? If this is true, then I can present $G$ as the cokernel of the relations matrix $$\left(\begin{array}{cc}  0 & a \\ 3 & b \\ 0 & 0 \\ 0 & 3  \end{array}\right)$$ for some integers $a,b\in\Bbb{Z}.$ This comes from analyzing the far top right and top left squares, and of course the assumption that question 1 is true. Question 2: How can I simplify this matrix to give me nice information on what $G$ should be? Edit 1: From the statement of the splitting lemma on pg. 147 of Hatcher , it looks as if I can basically arrange so that what I want in question 1 is true.",,"['abstract-algebra', 'group-theory', 'exact-sequence']"
70,Every finite extension of a finite field is separable,Every finite extension of a finite field is separable,,"I'm trying to prove that every finite extension of a finite field is separable. I found a solution on internet which says: Let $F$ be a finite field and $E$ be an extension of $F$ having  $p^n$   elements. Then $E=F(\alpha)$, where $\alpha \in E$ and so   $\alpha^{p^n} -\alpha=0$. This implies $\alpha$ is a separable   element, and hence $F(\alpha)$ is a separable extension of F. I don't understand why $\alpha^{p^n} -\alpha=0$ and why $\alpha$ is a separable element, I need help. Thanks","I'm trying to prove that every finite extension of a finite field is separable. I found a solution on internet which says: Let $F$ be a finite field and $E$ be an extension of $F$ having  $p^n$   elements. Then $E=F(\alpha)$, where $\alpha \in E$ and so   $\alpha^{p^n} -\alpha=0$. This implies $\alpha$ is a separable   element, and hence $F(\alpha)$ is a separable extension of F. I don't understand why $\alpha^{p^n} -\alpha=0$ and why $\alpha$ is a separable element, I need help. Thanks",,"['abstract-algebra', 'field-theory']"
71,Are intermediate rings of finitely generated ring extensions also finitely generated?,Are intermediate rings of finitely generated ring extensions also finitely generated?,,"It's well known that if $K$ is a finitely generated extension of some field $E$, then any intermediate field $F$, $E\subseteq F\subseteq K$, is also finitely generated over $E$. I'm curious, does the same hold for rings? Say $S$ is a ring, and $R\supset S$ is a finitely generated extension of $S$. If $T$ is any intermediate ring, is it necessarily true that $T$ is finitely generated over $S$ as a ring? Is it as simple as saying that for any $t\in T$, $T$ can be generated by the generators of $R$ over $S$? I feel unsure about this statement, since it's not clear to me that the generators of $R$ over $S$ need be in $T$. If not, what is an example what shows otherwise? Thanks.","It's well known that if $K$ is a finitely generated extension of some field $E$, then any intermediate field $F$, $E\subseteq F\subseteq K$, is also finitely generated over $E$. I'm curious, does the same hold for rings? Say $S$ is a ring, and $R\supset S$ is a finitely generated extension of $S$. If $T$ is any intermediate ring, is it necessarily true that $T$ is finitely generated over $S$ as a ring? Is it as simple as saying that for any $t\in T$, $T$ can be generated by the generators of $R$ over $S$? I feel unsure about this statement, since it's not clear to me that the generators of $R$ over $S$ need be in $T$. If not, what is an example what shows otherwise? Thanks.",,"['abstract-algebra', 'ring-theory']"
72,"Are $C([0,1])$ and $C(\mathbb{R})$ elementarily equivalent as rings?",Are  and  elementarily equivalent as rings?,"C([0,1]) C(\mathbb{R})","For a topological space $X$ , let $C(X)$ denote the ring of continuous functions $X\to\mathbb{R}$ , equipped with pointwise addition and multiplication. This question is related to this one of Noah Schweber's; in particular, the question arises from trying to understand how much topological data about $X$ is encoded in the first-order theory of the ring $C(X)$ . For example, $C(X)$ has a non-trivial idempotent if and only if $X$ is disconnected. A natural question to ask is when the first-order theory of $C(X)$ can also detect whether $X$ is compact, and this is the context in which the question below arises. For further elaboration and additional context, see Noah's post and the answers and comments below it. Let $[0,1]$ and $(0,1)$ be the closed and open unit intervals in $\mathbb{R}$ . Note that there is an injective ring morphism $\iota:C([0,1])\hookrightarrow C((0,1))$ that takes a map $\alpha:[0,1]\to\mathbb{R}$ to its restriction $\alpha|_{(0,1)}$ . Question: Is the map $\iota$ elementary? If the answer is no, do we nonetheless have an elementary equivalence $C([0,1])\equiv C((0,1))$ ? I suspect a negative answer, but I don't see a path for showing this. A natural first idea is to somehow try to exploit that $\operatorname{im}\alpha\subseteq\mathbb{R}$ is bounded for every $\alpha\in C([0,1])$ . So, for example, one can define a formula $$u>v\equiv \exists w\big[u-v=w^2\big]\wedge\exists w\big[(u-v)w=1\big].$$ Then, for any space $X$ and any continuous $\alpha,\beta:X \to\mathbb{R}$ , we have $C(X)\models\alpha>\beta$ if and only if $\alpha(x)>\beta(x)$ for each $x\in X$ . Indeed, $C(X)\models \exists w[\alpha-\beta=w^2]$ if and only if $\alpha(x)\geqslant\beta(x)$ for each $x\in X$ , and $C(X)\models \exists w[(\alpha-\beta)w=1]$ if and only if $\alpha(x)\neq\beta(x)$ for each $x\in X$ . With this in hand, it is fairly straightforward to come up with a first-order theory that is satisfiable in $C((0,1))$ but not in $C([0,1])$ , provided we are willing to add an additional constant symbol to our language. Indeed, let $a$ be a new constant symbol, and define a theory $T$ in the language of rings along with $a$ by taking $\neg(a<n)\in T$ for each $n\in\omega$ . Then realizing $a$ as any homeomorphism $(0,1)\to\mathbb{R}$ will make $C((0,1))$ into a model of $T$ , but no realization of $a$ can do the same for $C([0,1])$ , since any continuous image of $[0,1]$ in $\mathbb{R}$ is bounded. However, this is of course not enough to show that $C([0,1])\not\equiv C((0,1))$ as rings, and I don't see an easy way of extending the argument. If there were some way to uniformly define the subring $\mathbb{R}$ in $C([0,1])$ and $C((0,1))$ , then we would be done: if $\theta(w)$ were such a definition, then $C([0,1])$ would be a model of the sentence $\forall v\exists w[\theta(w)\wedge (w>v)]$ and $C((0,1))$ would be a model of its negation. But I'm struggling to come up with such a formula $\theta$ , and I'm not even convinced it can be done. Any insight, either on this approach or on a different one, would be much appreciated.","For a topological space , let denote the ring of continuous functions , equipped with pointwise addition and multiplication. This question is related to this one of Noah Schweber's; in particular, the question arises from trying to understand how much topological data about is encoded in the first-order theory of the ring . For example, has a non-trivial idempotent if and only if is disconnected. A natural question to ask is when the first-order theory of can also detect whether is compact, and this is the context in which the question below arises. For further elaboration and additional context, see Noah's post and the answers and comments below it. Let and be the closed and open unit intervals in . Note that there is an injective ring morphism that takes a map to its restriction . Question: Is the map elementary? If the answer is no, do we nonetheless have an elementary equivalence ? I suspect a negative answer, but I don't see a path for showing this. A natural first idea is to somehow try to exploit that is bounded for every . So, for example, one can define a formula Then, for any space and any continuous , we have if and only if for each . Indeed, if and only if for each , and if and only if for each . With this in hand, it is fairly straightforward to come up with a first-order theory that is satisfiable in but not in , provided we are willing to add an additional constant symbol to our language. Indeed, let be a new constant symbol, and define a theory in the language of rings along with by taking for each . Then realizing as any homeomorphism will make into a model of , but no realization of can do the same for , since any continuous image of in is bounded. However, this is of course not enough to show that as rings, and I don't see an easy way of extending the argument. If there were some way to uniformly define the subring in and , then we would be done: if were such a definition, then would be a model of the sentence and would be a model of its negation. But I'm struggling to come up with such a formula , and I'm not even convinced it can be done. Any insight, either on this approach or on a different one, would be much appreciated.","X C(X) X\to\mathbb{R} X C(X) C(X) X C(X) X [0,1] (0,1) \mathbb{R} \iota:C([0,1])\hookrightarrow C((0,1)) \alpha:[0,1]\to\mathbb{R} \alpha|_{(0,1)} \iota C([0,1])\equiv C((0,1)) \operatorname{im}\alpha\subseteq\mathbb{R} \alpha\in C([0,1]) u>v\equiv \exists w\big[u-v=w^2\big]\wedge\exists w\big[(u-v)w=1\big]. X \alpha,\beta:X \to\mathbb{R} C(X)\models\alpha>\beta \alpha(x)>\beta(x) x\in X C(X)\models \exists w[\alpha-\beta=w^2] \alpha(x)\geqslant\beta(x) x\in X C(X)\models \exists w[(\alpha-\beta)w=1] \alpha(x)\neq\beta(x) x\in X C((0,1)) C([0,1]) a T a \neg(a<n)\in T n\in\omega a (0,1)\to\mathbb{R} C((0,1)) T a C([0,1]) [0,1] \mathbb{R} C([0,1])\not\equiv C((0,1)) \mathbb{R} C([0,1]) C((0,1)) \theta(w) C([0,1]) \forall v\exists w[\theta(w)\wedge (w>v)] C((0,1)) \theta","['abstract-algebra', 'general-topology', 'logic', 'ring-theory', 'model-theory']"
73,Exercises on Galois Theory,Exercises on Galois Theory,,"I need a source for exercises on classical Galois Theory, or to be more specific, Galois extensions of finite fields and the rationals as well as applications (solvability by radicals, for example). So far, I have worked with Tignol's ""Galois Theory of Algebraic Equations"". Any additional suggestions would be appreciated, whether it is a textbook or a website, but the language should be English. Solutions are welcome, but no necessity. Thanks in advance!","I need a source for exercises on classical Galois Theory, or to be more specific, Galois extensions of finite fields and the rationals as well as applications (solvability by radicals, for example). So far, I have worked with Tignol's ""Galois Theory of Algebraic Equations"". Any additional suggestions would be appreciated, whether it is a textbook or a website, but the language should be English. Solutions are welcome, but no necessity. Thanks in advance!",,"['abstract-algebra', 'reference-request', 'galois-theory', 'book-recommendation', 'online-resources']"
74,A problem about an $R$-module that is both injective and projective.,A problem about an -module that is both injective and projective.,R,"Let $R$ be a domain that is not a field, and let $M$ be an $R$-module that is both injective and projective. Prove that $M= \left \{ 0 \right \}$. This is exercise 7.52 of Rotman's Advanced Modern Algebra . Using theorems before exercises, because $M$ is injective and $R$ is a domain, I conclude that $$\forall m\in M ,\forall r\in R\ (r\neq 0) ,\exists {m}'\in M \Rightarrow m=r{m}'$$ and also because $M$ is projective there is a surjective $\psi$ from free $R$-module $F$ with basis $\left \{ e_{i} \right \}_{i\in I}$ to $M$ and thus we can conclude that for every $m\in M$ we have $$m=\sum r_{i}\Psi (e_{i})$$ now I don't know how should I use these together. The idea of what is happening or a suggestion or a hint will be great.","Let $R$ be a domain that is not a field, and let $M$ be an $R$-module that is both injective and projective. Prove that $M= \left \{ 0 \right \}$. This is exercise 7.52 of Rotman's Advanced Modern Algebra . Using theorems before exercises, because $M$ is injective and $R$ is a domain, I conclude that $$\forall m\in M ,\forall r\in R\ (r\neq 0) ,\exists {m}'\in M \Rightarrow m=r{m}'$$ and also because $M$ is projective there is a surjective $\psi$ from free $R$-module $F$ with basis $\left \{ e_{i} \right \}_{i\in I}$ to $M$ and thus we can conclude that for every $m\in M$ we have $$m=\sum r_{i}\Psi (e_{i})$$ now I don't know how should I use these together. The idea of what is happening or a suggestion or a hint will be great.",,"['abstract-algebra', 'modules', 'homological-algebra', 'projective-module', 'injective-module']"
75,Irreducibles are prime in a UFD,Irreducibles are prime in a UFD,,"Any irreducible element of a factorial ring $D$ is a prime element of   $D$. Proof. Let $p$ be an arbitrary irreducible element of $ D$. Thus $ p$  is a non-unit. If $ ab \in (p)\smallsetminus\{0\}$, then $ ab = cp$  with $ c \in D$. We write $ a,\,b,\,c$ as products of irreducibles:  $$\displaystyle a \;=\; p_1\cdots p_l, \quad b \;=\; q_1\cdots q_m,  \quad c \;=\; r_1\cdots r_n.$$ Here, one of those first two products may  be empty, i.e., it may be a unit. We have $$\displaystyle p_1\cdots  p_l\,q_1\cdots q_m \;=\; r_1\cdots r_n\,p\tag{1}$$ Due to the uniqueness of prime factorization, every factor $ r_k$ is   an associate of certain of the $l+m$ irreducibles on the left   hand side of $(1)$. Accordingly, $p$ has to be an associate of one of   the $ p_i$'s or $ q_j$'s. It means that either $ a \in (p)$ or $ b \in  (p)$. Thus, $ (p)$ is a prime ideal of $ D$, and its generator must be   a prime element. It may be too simple, but why $ a \in (p)$ instead of $p_1 \in (p)$? Is it because $p$ has to be an associate of one of the $ p_i$'s or $ q_j$'s? Let's say $p_2$ is an associate of $p$. So, $p_2=pw$, $w\in R$. Since $a=p_1p_2\cdots p_l$ then $a=p_1pwp_3\cdots p_l$ and $a=p(p_1p_3\cdots p_lw)$, $p_1p_3\cdots p_lw \in R$ so $a$ is divisible by $p$ hence $a\in (p)$?","Any irreducible element of a factorial ring $D$ is a prime element of   $D$. Proof. Let $p$ be an arbitrary irreducible element of $ D$. Thus $ p$  is a non-unit. If $ ab \in (p)\smallsetminus\{0\}$, then $ ab = cp$  with $ c \in D$. We write $ a,\,b,\,c$ as products of irreducibles:  $$\displaystyle a \;=\; p_1\cdots p_l, \quad b \;=\; q_1\cdots q_m,  \quad c \;=\; r_1\cdots r_n.$$ Here, one of those first two products may  be empty, i.e., it may be a unit. We have $$\displaystyle p_1\cdots  p_l\,q_1\cdots q_m \;=\; r_1\cdots r_n\,p\tag{1}$$ Due to the uniqueness of prime factorization, every factor $ r_k$ is   an associate of certain of the $l+m$ irreducibles on the left   hand side of $(1)$. Accordingly, $p$ has to be an associate of one of   the $ p_i$'s or $ q_j$'s. It means that either $ a \in (p)$ or $ b \in  (p)$. Thus, $ (p)$ is a prime ideal of $ D$, and its generator must be   a prime element. It may be too simple, but why $ a \in (p)$ instead of $p_1 \in (p)$? Is it because $p$ has to be an associate of one of the $ p_i$'s or $ q_j$'s? Let's say $p_2$ is an associate of $p$. So, $p_2=pw$, $w\in R$. Since $a=p_1p_2\cdots p_l$ then $a=p_1pwp_3\cdots p_l$ and $a=p(p_1p_3\cdots p_lw)$, $p_1p_3\cdots p_lw \in R$ so $a$ is divisible by $p$ hence $a\in (p)$?",,"['abstract-algebra', 'ring-theory', 'proof-explanation', 'unique-factorization-domains']"
76,"Why are particular combinations of algebraic properties ""richer"" than others?","Why are particular combinations of algebraic properties ""richer"" than others?",,"Pedagogically, when students are exposed to algebraic structures it seems standard for the major emphasis, if not all the emphasis, to be on groups, rings, R-modules, and categories. These are rich structures with interesting properties, but in the big picture, I have wondered why some defining properties make for a rich structure, while other properties gives less interesting structures , or nothing worth teaching at all. As a motivating example, a set (or class, whatever) that is closed under some operation seems necessary to talk about anything meaningful; however, why is the particular combination of Having inverse elements Having an identity element Associativity more rich (a group) than simply replacing associativity with commutativity (a structure I don't even know a name for)? I have also wondered why associativity is much more prevalent than commutativity. As another motivating example, we teach much about groups and rings but why not loops, monoids, semilattices, and near-rings? What makes the former set either richer in structure or more pedagogically sound to teach? Even in category theory I can ask what makes the specific combination of defining properties of a category so great. —why associativity and not commutativity? —why categories and not semi categories? I wonder why its particular combination of defining properties is more ""powerful"", deep, and pervasive than another combination of properties.","Pedagogically, when students are exposed to algebraic structures it seems standard for the major emphasis, if not all the emphasis, to be on groups, rings, R-modules, and categories. These are rich structures with interesting properties, but in the big picture, I have wondered why some defining properties make for a rich structure, while other properties gives less interesting structures , or nothing worth teaching at all. As a motivating example, a set (or class, whatever) that is closed under some operation seems necessary to talk about anything meaningful; however, why is the particular combination of Having inverse elements Having an identity element Associativity more rich (a group) than simply replacing associativity with commutativity (a structure I don't even know a name for)? I have also wondered why associativity is much more prevalent than commutativity. As another motivating example, we teach much about groups and rings but why not loops, monoids, semilattices, and near-rings? What makes the former set either richer in structure or more pedagogically sound to teach? Even in category theory I can ask what makes the specific combination of defining properties of a category so great. —why associativity and not commutativity? —why categories and not semi categories? I wonder why its particular combination of defining properties is more ""powerful"", deep, and pervasive than another combination of properties.",,"['abstract-algebra', 'soft-question', 'category-theory', 'universal-algebra']"
77,Group of invertible elements of a ring has never order $5$,Group of invertible elements of a ring has never order,5,"Let $R$ be a ring with unity. How can I prove that group of invertible elements of $R$ is never of order $5$? My teacher told me and my colleagues that problem is very hard to solve. I would be glad if someone can provide me even a small hint because, at this point, I have no clue how to attack the problem.","Let $R$ be a ring with unity. How can I prove that group of invertible elements of $R$ is never of order $5$? My teacher told me and my colleagues that problem is very hard to solve. I would be glad if someone can provide me even a small hint because, at this point, I have no clue how to attack the problem.",,"['abstract-algebra', 'group-theory', 'ring-theory']"
78,Hopkins-Levitzki: an uncanny asymmetry?,Hopkins-Levitzki: an uncanny asymmetry?,,"Not every left Noetherian ring is left Artinian . Take $\mathbb{Z}$ as a quick example. But: Hopkins-Levitzki theorem : a left Artinian ring is left Noetherian. I find this quite amazing. I find this asymmetry shocking. It just seems plain unreasonable that there are rings where every ascending chain of ideals stabilizes but not every descending chain stabilizes, and at the same time every ring with stabilizing descending chains has stabilizing ascending chains. I know asymmetries abound in ring/module theory, but this one strikes me as more elementary and uncanny. My question is: Why does this happen? Of course, this question is at an informal level; I'm not asking for a proof of the theorem. I just want to understand why one chain condition implies the other, but not the other way around. At first glance, it just seems so symmetrical, that I would have expected the conditions to be equivalent, or to have neither condition implying the other. My very naive first observation is that for noetherian rings, we have the characterization ""every ideal is finitely generated"", but for artinian rings there is not (that I know of) a simple analog, which is perhaps the first spark of an asymmetry...","Not every left Noetherian ring is left Artinian . Take $\mathbb{Z}$ as a quick example. But: Hopkins-Levitzki theorem : a left Artinian ring is left Noetherian. I find this quite amazing. I find this asymmetry shocking. It just seems plain unreasonable that there are rings where every ascending chain of ideals stabilizes but not every descending chain stabilizes, and at the same time every ring with stabilizing descending chains has stabilizing ascending chains. I know asymmetries abound in ring/module theory, but this one strikes me as more elementary and uncanny. My question is: Why does this happen? Of course, this question is at an informal level; I'm not asking for a proof of the theorem. I just want to understand why one chain condition implies the other, but not the other way around. At first glance, it just seems so symmetrical, that I would have expected the conditions to be equivalent, or to have neither condition implying the other. My very naive first observation is that for noetherian rings, we have the characterization ""every ideal is finitely generated"", but for artinian rings there is not (that I know of) a simple analog, which is perhaps the first spark of an asymmetry...",,"['abstract-algebra', 'ring-theory']"
79,Topology induced by the completion of a topological group,Topology induced by the completion of a topological group,,"Let $G$ be an abelian topological group and let $\hat{G}$ be its completion, i.e. the group containing the equivalence classes of all Cauchy sequences of $G$. What exactly is the topology of $\hat{G}$?","Let $G$ be an abelian topological group and let $\hat{G}$ be its completion, i.e. the group containing the equivalence classes of all Cauchy sequences of $G$. What exactly is the topology of $\hat{G}$?",,"['abstract-algebra', 'general-topology', 'topological-groups']"
80,Existence of Irreducible polynomials over $\mathbb{Z}$ of any given degree [duplicate],Existence of Irreducible polynomials over  of any given degree [duplicate],\mathbb{Z},"This question already has answers here : Prove that the polynomial $(x-1)(x-2)\cdots(x-n) + 1$, $ n\ge1 $, $ n\ne4 $ is irreducible over $\mathbb Z$ (2 answers) Closed 6 years ago . Question is to prove : Irreducibility of $(x-1)(x-2)\cdots (x-n)- 1$ over  $\mathbb{Z}$ for all $n\geq 1$ Irreducibility of $(x-1)(x-2)\cdots (x-n)+ 1$ over  $\mathbb{Z}$ for all $n\geq 1$ and $n\neq 4$ Hint for first bullet is If the polynomial factors consider the value of the factors at $x=1,2,\dots,n$ For second bullet : Suppose $p(x)=(x-1)(x-2)\cdots (x-n)-1$ is reducible we have: $p(x)=q(x)r(x)$ with $\text {Max {degree of p(x), degree of r(x)}}<n$ Hint is suggesting me to use that $p(i)=-1$ for all $1\leq i\leq n$ i.e., $q(i)r(i)=-1$ for all $1\leq i\leq n$ i.e., $q(i)=-1; r(i)=1$ or $q(i)=1;r(i)=-1$  for all $1\leq i\leq n$ For second bullet : Suppose $p(x)=(x-1)(x-2)\cdots (x-n)+1$ is reducible we have: $p(x)=q(x)r(x)$ with $\text {Max {degree of p(x), degree of r(x)}}<n$ Hint is suggesting me to use that $p(i)=1$ for all $1\leq i\leq n$ i.e., $q(i)r(i)=1$ for all $1\leq i\leq n$ i.e., $q(i)=r(i)=1$ or $q(i)=r(i)=-1$  for all $1\leq i\leq n$ I am getting some vague ideas but could not bind them to prove this. I would be thankful if some one can help me to clear this. Thank you. P.S : Please give ""just hints"". Do not write whole answer at once. This is a ""request"". Thank you :) Edit : I have changed the title from Irreducibility of $(x-1)(x-2)\cdots (x-n)\pm 1$ over $\mathbb{Z}$ to Existence of Irreducible polynomials over $\mathbb{Z}$ of any given degree for two reasons : Irreducibility of $(x-1)(x-2)\cdots (x-n)\pm 1$ over $\mathbb{Z}$ for any $n\geq 1$ implies Existence of Irreducible polynomials over $\mathbb{Z}$ of any given degree The title looks atractive","This question already has answers here : Prove that the polynomial $(x-1)(x-2)\cdots(x-n) + 1$, $ n\ge1 $, $ n\ne4 $ is irreducible over $\mathbb Z$ (2 answers) Closed 6 years ago . Question is to prove : Irreducibility of $(x-1)(x-2)\cdots (x-n)- 1$ over  $\mathbb{Z}$ for all $n\geq 1$ Irreducibility of $(x-1)(x-2)\cdots (x-n)+ 1$ over  $\mathbb{Z}$ for all $n\geq 1$ and $n\neq 4$ Hint for first bullet is If the polynomial factors consider the value of the factors at $x=1,2,\dots,n$ For second bullet : Suppose $p(x)=(x-1)(x-2)\cdots (x-n)-1$ is reducible we have: $p(x)=q(x)r(x)$ with $\text {Max {degree of p(x), degree of r(x)}}<n$ Hint is suggesting me to use that $p(i)=-1$ for all $1\leq i\leq n$ i.e., $q(i)r(i)=-1$ for all $1\leq i\leq n$ i.e., $q(i)=-1; r(i)=1$ or $q(i)=1;r(i)=-1$  for all $1\leq i\leq n$ For second bullet : Suppose $p(x)=(x-1)(x-2)\cdots (x-n)+1$ is reducible we have: $p(x)=q(x)r(x)$ with $\text {Max {degree of p(x), degree of r(x)}}<n$ Hint is suggesting me to use that $p(i)=1$ for all $1\leq i\leq n$ i.e., $q(i)r(i)=1$ for all $1\leq i\leq n$ i.e., $q(i)=r(i)=1$ or $q(i)=r(i)=-1$  for all $1\leq i\leq n$ I am getting some vague ideas but could not bind them to prove this. I would be thankful if some one can help me to clear this. Thank you. P.S : Please give ""just hints"". Do not write whole answer at once. This is a ""request"". Thank you :) Edit : I have changed the title from Irreducibility of $(x-1)(x-2)\cdots (x-n)\pm 1$ over $\mathbb{Z}$ to Existence of Irreducible polynomials over $\mathbb{Z}$ of any given degree for two reasons : Irreducibility of $(x-1)(x-2)\cdots (x-n)\pm 1$ over $\mathbb{Z}$ for any $n\geq 1$ implies Existence of Irreducible polynomials over $\mathbb{Z}$ of any given degree The title looks atractive",,['abstract-algebra']
81,"When is there a ring structure on an abelian group $(A,+)$?",When is there a ring structure on an abelian group ?,"(A,+)","Given an abelian group $(A,+)$, what are conditions on $A$ that ensure there is or isn't a unitary ring structure $(A,+,*)$? That is, an associative bilinear operation $* : A^2 \to A$  with an identity $1_A \in A$. A possible follow-up question would be conditions for a nontrivial rng structure on $A$ (indeed, the multiplication $ab = 0$ always gives a rng structure). For example, if $A$ is finitely generated, then by the structure theorem on finite type abelian groups, $A \simeq \mathbb Z^r \times \prod \mathbb Z/p_i^{a_i} \mathbb Z$ and it has a product ring structure. On the other hand, $\mathbb Q / \mathbb Z$ doesn't: if it did, the unit $u=[p/q]$ would have finite order $q$, and $\forall x \in \mathbb Q / \mathbb Z, qx = q(u*x) = (qu)*x = 0$, but $q(1/2q) = 1/2 \neq 0$. More generally, by this question , if every element has finite order but the orders are not bounded, then there is no ring structure on $A$. Is this condition also necessary? I doubt it: I have trouble envisioning a ring structure on $(\mathbb R / \mathbb Z, +) = (S^1, \cdot)$, but not every element has finite order in $S^1$. The argument also completely fails for rngs. (Note that my question is different from the one I linked: this one simply asked for a counterexample, I'm asking for general conditions)","Given an abelian group $(A,+)$, what are conditions on $A$ that ensure there is or isn't a unitary ring structure $(A,+,*)$? That is, an associative bilinear operation $* : A^2 \to A$  with an identity $1_A \in A$. A possible follow-up question would be conditions for a nontrivial rng structure on $A$ (indeed, the multiplication $ab = 0$ always gives a rng structure). For example, if $A$ is finitely generated, then by the structure theorem on finite type abelian groups, $A \simeq \mathbb Z^r \times \prod \mathbb Z/p_i^{a_i} \mathbb Z$ and it has a product ring structure. On the other hand, $\mathbb Q / \mathbb Z$ doesn't: if it did, the unit $u=[p/q]$ would have finite order $q$, and $\forall x \in \mathbb Q / \mathbb Z, qx = q(u*x) = (qu)*x = 0$, but $q(1/2q) = 1/2 \neq 0$. More generally, by this question , if every element has finite order but the orders are not bounded, then there is no ring structure on $A$. Is this condition also necessary? I doubt it: I have trouble envisioning a ring structure on $(\mathbb R / \mathbb Z, +) = (S^1, \cdot)$, but not every element has finite order in $S^1$. The argument also completely fails for rngs. (Note that my question is different from the one I linked: this one simply asked for a counterexample, I'm asking for general conditions)",,"['abstract-algebra', 'ring-theory']"
82,Is there an algebraic closure for the quaternions?,Is there an algebraic closure for the quaternions?,,"This post is a sequel of: Is the set of quaternions $\mathbb{H}$ algebraically closed? This answer shows that: 1.  $\mathbb{H}$ is algebraically closed for the polynomials of the form $\sum a_r x^r$ 2. It is not for the polynomials freely generated by $\mathbb{H}$ and $x$, because $xi+ix-j$ has no root. Question : Is there an algebraic closure (for the case 2)? If so:   What does it look like?   What's its dimension over $\mathbb{H}$? What's its matrix representations?","This post is a sequel of: Is the set of quaternions $\mathbb{H}$ algebraically closed? This answer shows that: 1.  $\mathbb{H}$ is algebraically closed for the polynomials of the form $\sum a_r x^r$ 2. It is not for the polynomials freely generated by $\mathbb{H}$ and $x$, because $xi+ix-j$ has no root. Question : Is there an algebraic closure (for the case 2)? If so:   What does it look like?   What's its dimension over $\mathbb{H}$? What's its matrix representations?",,"['abstract-algebra', 'quaternions']"
83,Can nonisomorphic groups have near-identical Cayley tables?,Can nonisomorphic groups have near-identical Cayley tables?,,"Nonisomorphic groups can have very similar multiplication (Cayley) tables. For example, the two groups \begin{align*} \mathbb{Z}/9\mathbb{Z}&=\{\overset{a}{0},\overset{b}{1},\overset{c}{2},\overset{d}{3},\overset{e}{4},\overset{f}{5},\overset{g}{6},\overset{h}{7},\overset{i}{8}\}\\ \mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&=\{\underset{a}{(0,0)},\underset{b}{(0,1)},\underset{i}{(0,2)},\underset{d}{(1,0)},\underset{e}{(1,1)},\underset{c}{(1,2)},\underset{g}{(2,0)},\underset{h}{(2,1)},\underset{f}{(2,2)}\} \end{align*} have multiplication (Cayley) tables \begin{array}{r|ccccccccc} \mathbb{Z}/9\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline a&a&b&c&d&e&f&g&h&i\\ b&b&c&d&e&f&g&h&i&a\\ c&c&d&e&f&g&h&i&a&b\\ d&d&e&f&g&h&i&a&b&c\\ e&e&f&g&h&i&a&b&c&d\\ f&f&g&h&i&a&b&c&d&e\\ g&g&h&i&a&b&c&d&e&f\\ h&h&i&a&b&c&d&e&f&g\\ i&i&a&b&c&d&e&f&g&h\\ \end{array} and \begin{array}{r|ccccccccc} \mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline a&a&b&c&d&e&f&g&h&i\\ b&b&\boxed{i}&d&e&\boxed{c}&g&h&\boxed{f}&a\\ c&c&d&\boxed{h}&f&g&\boxed{b}&i&a&\boxed{e}\\ d&d&e&f&g&h&i&a&b&c\\ e&e&\boxed{c}&g&h&\boxed{f}&a&b&\boxed{i}&d\\ f&f&g&\boxed{b}&i&a&\boxed{e}&c&d&\boxed{h}\\ g&g&h&i&a&b&c&d&e&f\\ h&h&\boxed{f}&a&b&\boxed{i}&d&e&\boxed{c}&g\\ i&i&a&\boxed{e}&c&d&\boxed{h}&f&g&\boxed{b}\\ \end{array} respectively (note the boxed elements are different). The proportion of different elements between these two tables is $\frac{18}{9\times 9}=\frac{2}{9}\approx 22.2\%$ . Given a finite group $G=\{g_1\ldots g_n\}$ with a fixed enumeration of its elements, we define its multiplication table to be the unique matrix $M_G\in\{1\ldots n\}^{n\times n}$ such that for all $i,j\le n$ , if $k=(M_G)_{ij}$ then $g_i\cdot g_j=g_k$ . Question. Given $\varepsilon=\frac{1}{1000}$ , does there exist two finite groups $G=\{g_1\ldots g_n\},H=\{h_1\ldots h_n\}$ with multiplication tables $M_G,M_H$ , such that for all but at most $\varepsilon n^2$ many pairs $(i,j)\in\{1\ldots n\}^2$ , it holds that $(M_G)_{ij}=(M_H)_{ij}$ , and $G\not\cong H$ ? Thanks for your help.","Nonisomorphic groups can have very similar multiplication (Cayley) tables. For example, the two groups have multiplication (Cayley) tables and respectively (note the boxed elements are different). The proportion of different elements between these two tables is . Given a finite group with a fixed enumeration of its elements, we define its multiplication table to be the unique matrix such that for all , if then . Question. Given , does there exist two finite groups with multiplication tables , such that for all but at most many pairs , it holds that , and ? Thanks for your help.","\begin{align*}
\mathbb{Z}/9\mathbb{Z}&=\{\overset{a}{0},\overset{b}{1},\overset{c}{2},\overset{d}{3},\overset{e}{4},\overset{f}{5},\overset{g}{6},\overset{h}{7},\overset{i}{8}\}\\
\mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&=\{\underset{a}{(0,0)},\underset{b}{(0,1)},\underset{i}{(0,2)},\underset{d}{(1,0)},\underset{e}{(1,1)},\underset{c}{(1,2)},\underset{g}{(2,0)},\underset{h}{(2,1)},\underset{f}{(2,2)}\}
\end{align*} \begin{array}{r|ccccccccc}
\mathbb{Z}/9\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline
a&a&b&c&d&e&f&g&h&i\\
b&b&c&d&e&f&g&h&i&a\\
c&c&d&e&f&g&h&i&a&b\\
d&d&e&f&g&h&i&a&b&c\\
e&e&f&g&h&i&a&b&c&d\\
f&f&g&h&i&a&b&c&d&e\\
g&g&h&i&a&b&c&d&e&f\\
h&h&i&a&b&c&d&e&f&g\\
i&i&a&b&c&d&e&f&g&h\\
\end{array} \begin{array}{r|ccccccccc}
\mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline
a&a&b&c&d&e&f&g&h&i\\
b&b&\boxed{i}&d&e&\boxed{c}&g&h&\boxed{f}&a\\
c&c&d&\boxed{h}&f&g&\boxed{b}&i&a&\boxed{e}\\
d&d&e&f&g&h&i&a&b&c\\
e&e&\boxed{c}&g&h&\boxed{f}&a&b&\boxed{i}&d\\
f&f&g&\boxed{b}&i&a&\boxed{e}&c&d&\boxed{h}\\
g&g&h&i&a&b&c&d&e&f\\
h&h&\boxed{f}&a&b&\boxed{i}&d&e&\boxed{c}&g\\
i&i&a&\boxed{e}&c&d&\boxed{h}&f&g&\boxed{b}\\
\end{array} \frac{18}{9\times 9}=\frac{2}{9}\approx 22.2\% G=\{g_1\ldots g_n\} M_G\in\{1\ldots n\}^{n\times n} i,j\le n k=(M_G)_{ij} g_i\cdot g_j=g_k \varepsilon=\frac{1}{1000} G=\{g_1\ldots g_n\},H=\{h_1\ldots h_n\} M_G,M_H \varepsilon n^2 (i,j)\in\{1\ldots n\}^2 (M_G)_{ij}=(M_H)_{ij} G\not\cong H","['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'cayley-table']"
84,Name for a ring that also has composition - aka function application?,Name for a ring that also has composition - aka function application?,,"What is the following type of ring? Does it have a name? Suppose $(R,\cdot,+,0,1)$ is a ring with another binary operation, $\circ$ with the properties: $$(a\circ b)\circ c=a\circ(b\circ c)\\ (a+b)\circ c=(a\circ c)+(b\circ c)\\ (a\cdot b)\circ c = (a\circ c)\cdot (b\circ c)\\ 0\circ c = 0; 1\circ c=1$$ Many of these rings have a left-right $\circ$-identity. Foundational Example 1: Given a ring $S$, the set $S^S$ of all functions $S\to S$ with point-wise addition and multiplication and composition for $\circ$: $$(f+g)(s)=f(s)+g(s)\\(fg)(s)=f(s)g(s)(f\circ g)(s)=f(g(s))$$ This has a left-right $\circ$ identity, $I(s)=s$. Every algebra $R$ of this sort with a right $\circ$ identity in this class is isomorphic to a sub-algebra of some $S^S$, specifically, with $S=R$. This is because if $f_a=c\mapsto a\circ c$ then if $f_a=f_b$ then $a=f_a(X)=f_b(X)=b$ where $X$ is the right identity. Foundational example 2: Given a commutative ring $S$, $S[x]$ with polynomial composition. This case has a left-right $\circ$ identity, $x$. Continuous functions: Given a topological ring, the set of continuous functions $S\to S$ satisfies this condition, with the identity function a left-right $\circ$-identity. Entire functions: The ring of entire functions $\mathbb C\to\mathbb C$ is an integral domain, containing (an isomorphic image of) $\mathbb C[x]$, with $\circ$ being standard function composition. Less well-known example: The set of all functions $f:\mathbb Z\to\mathbb Z$ with the condition: $$f(m)\equiv f(n)\pmod{m-n}$$ for all $m,n\in\mathbb Z$. This ring is an odd integral domain that contains an isomorphic image of $\mathbb Z[x]$, since every integer polynomial function is of this sort, but there are more elements that are non-polynomials (and some non-integer polynomial functions, too.) It has $I(n)=n$ as a left-right $\circ$ identity. The condition can be seen as requiring some ""smoothness"" of the functions in all the $p$-adic metrics. They can be seen as matching a certain strong uniform continuity/Lipshitz continuity in all the $p$-adics.In particular, for any $p$, we have that $f$ can be extended to the $p$-adic numbers uniquely to make it continuous, and $\|f(a)-f(b)\|_p\leq \|a-b\|_p$ for all $p$-adic integers $a,b$.  Indeed, it is essentially a ""bounded Lipshitz"" criterion - this doesn't work in general, but does work in non-Archimedian valuation rings. Related: If $(S,\|\|_S)$ is a non-Archimedian valuation ring with bounded valuation $\|s\|_S\leq 1$ (think the $p$-adic integers, or the rational integers under the $p$-adic norm.) Then we can take the ring $R$ of functions $f:S\to S$ with the property: $$\|f(r)-f(s)\|_S\leq \|r-s\|_S$$ This is a ring of the above sort. If we take $S=(\mathbb Z,\|\|_p)$, the integers with the $p$-adic norm, this set $R_p$ is just all functions  $f:\mathbb Z\to\mathbb Z$ such that $p^k\mid f(n+p^k)-f(n)$ for all $n\in\mathbb Z$ and $k>0$. Then the original ring at the beginning of this section can be seen as $\bigcap_p R_p$. The intersection of sub-algebras is always a sub-algebra. Near misses - without multiplicative unit: The ring of meromorphic functions $\mathbb C\to\mathbb C$ is almost of this form, but when $c(x)=C$ is constant and $h(x)$ is not defined at $C$, we don't get a meromorphic function. However, if we relax the condition, and not require $R$ to have a multiplicative unit, we can take the ring of meromorphic functions  $f$ with $f(0)=0$. Then the set of such functions is such a ring. A related near miss: The sub-algebra of $S[[x]]$ of formal power series over a ring $S$, with no constant term. Again, no multiplicative unit, but everything else satisfied. Properties: For any $f\in R$, $R_{f}=\{a\circ f\mid a\in R\}$ is a sub-algebra. The condition that $0\circ f=0,1\circ f=1$ shows that $0,1\in R_f$. Indeed, $R_f$ is a sub-algebra, because $(a\circ f)\circ (b\circ f)=(a\circ f\circ b)\circ f$. More generally, given $g\in R$ and $a\in R_f$ then $g\circ a\in R_f$. So $R_f$ is sort of like a $\circ$-right-ideal. For example, the sub-algebra of even entire functions is $R_{x^2}$. The subring $R_0=\{a\circ 0\mid a\in R\}$ has the property that if $r\in R_0$ then $r\circ f = (a\circ 0)\circ f = a\circ(0\circ f)=a\circ 0=r$ for any $f$. Note that $R_0\subseteq R_f$ for any $f$. Indeed, if $r\in R_0$ then $r=a\circ 0 = a\circ(0\circ f)=(a\circ 0)\circ f$. Now, if $f\in R_0$, we get $R_0=R_f$ because $a=a\circ f =a\circ(f\circ 0) = (a\circ f)\circ 0$. On the other hand, if $a=a\circ f$ for all $f$, then $a=a\circ 0$ so $a\in R_0$. Basically, $R_0$ is really ""all"" of the constant functions. Also, for $f\in R$ and $r\in R_0$, $f\circ r\in R_0$.","What is the following type of ring? Does it have a name? Suppose $(R,\cdot,+,0,1)$ is a ring with another binary operation, $\circ$ with the properties: $$(a\circ b)\circ c=a\circ(b\circ c)\\ (a+b)\circ c=(a\circ c)+(b\circ c)\\ (a\cdot b)\circ c = (a\circ c)\cdot (b\circ c)\\ 0\circ c = 0; 1\circ c=1$$ Many of these rings have a left-right $\circ$-identity. Foundational Example 1: Given a ring $S$, the set $S^S$ of all functions $S\to S$ with point-wise addition and multiplication and composition for $\circ$: $$(f+g)(s)=f(s)+g(s)\\(fg)(s)=f(s)g(s)(f\circ g)(s)=f(g(s))$$ This has a left-right $\circ$ identity, $I(s)=s$. Every algebra $R$ of this sort with a right $\circ$ identity in this class is isomorphic to a sub-algebra of some $S^S$, specifically, with $S=R$. This is because if $f_a=c\mapsto a\circ c$ then if $f_a=f_b$ then $a=f_a(X)=f_b(X)=b$ where $X$ is the right identity. Foundational example 2: Given a commutative ring $S$, $S[x]$ with polynomial composition. This case has a left-right $\circ$ identity, $x$. Continuous functions: Given a topological ring, the set of continuous functions $S\to S$ satisfies this condition, with the identity function a left-right $\circ$-identity. Entire functions: The ring of entire functions $\mathbb C\to\mathbb C$ is an integral domain, containing (an isomorphic image of) $\mathbb C[x]$, with $\circ$ being standard function composition. Less well-known example: The set of all functions $f:\mathbb Z\to\mathbb Z$ with the condition: $$f(m)\equiv f(n)\pmod{m-n}$$ for all $m,n\in\mathbb Z$. This ring is an odd integral domain that contains an isomorphic image of $\mathbb Z[x]$, since every integer polynomial function is of this sort, but there are more elements that are non-polynomials (and some non-integer polynomial functions, too.) It has $I(n)=n$ as a left-right $\circ$ identity. The condition can be seen as requiring some ""smoothness"" of the functions in all the $p$-adic metrics. They can be seen as matching a certain strong uniform continuity/Lipshitz continuity in all the $p$-adics.In particular, for any $p$, we have that $f$ can be extended to the $p$-adic numbers uniquely to make it continuous, and $\|f(a)-f(b)\|_p\leq \|a-b\|_p$ for all $p$-adic integers $a,b$.  Indeed, it is essentially a ""bounded Lipshitz"" criterion - this doesn't work in general, but does work in non-Archimedian valuation rings. Related: If $(S,\|\|_S)$ is a non-Archimedian valuation ring with bounded valuation $\|s\|_S\leq 1$ (think the $p$-adic integers, or the rational integers under the $p$-adic norm.) Then we can take the ring $R$ of functions $f:S\to S$ with the property: $$\|f(r)-f(s)\|_S\leq \|r-s\|_S$$ This is a ring of the above sort. If we take $S=(\mathbb Z,\|\|_p)$, the integers with the $p$-adic norm, this set $R_p$ is just all functions  $f:\mathbb Z\to\mathbb Z$ such that $p^k\mid f(n+p^k)-f(n)$ for all $n\in\mathbb Z$ and $k>0$. Then the original ring at the beginning of this section can be seen as $\bigcap_p R_p$. The intersection of sub-algebras is always a sub-algebra. Near misses - without multiplicative unit: The ring of meromorphic functions $\mathbb C\to\mathbb C$ is almost of this form, but when $c(x)=C$ is constant and $h(x)$ is not defined at $C$, we don't get a meromorphic function. However, if we relax the condition, and not require $R$ to have a multiplicative unit, we can take the ring of meromorphic functions  $f$ with $f(0)=0$. Then the set of such functions is such a ring. A related near miss: The sub-algebra of $S[[x]]$ of formal power series over a ring $S$, with no constant term. Again, no multiplicative unit, but everything else satisfied. Properties: For any $f\in R$, $R_{f}=\{a\circ f\mid a\in R\}$ is a sub-algebra. The condition that $0\circ f=0,1\circ f=1$ shows that $0,1\in R_f$. Indeed, $R_f$ is a sub-algebra, because $(a\circ f)\circ (b\circ f)=(a\circ f\circ b)\circ f$. More generally, given $g\in R$ and $a\in R_f$ then $g\circ a\in R_f$. So $R_f$ is sort of like a $\circ$-right-ideal. For example, the sub-algebra of even entire functions is $R_{x^2}$. The subring $R_0=\{a\circ 0\mid a\in R\}$ has the property that if $r\in R_0$ then $r\circ f = (a\circ 0)\circ f = a\circ(0\circ f)=a\circ 0=r$ for any $f$. Note that $R_0\subseteq R_f$ for any $f$. Indeed, if $r\in R_0$ then $r=a\circ 0 = a\circ(0\circ f)=(a\circ 0)\circ f$. Now, if $f\in R_0$, we get $R_0=R_f$ because $a=a\circ f =a\circ(f\circ 0) = (a\circ f)\circ 0$. On the other hand, if $a=a\circ f$ for all $f$, then $a=a\circ 0$ so $a\in R_0$. Basically, $R_0$ is really ""all"" of the constant functions. Also, for $f\in R$ and $r\in R_0$, $f\circ r\in R_0$.",,"['abstract-algebra', 'terminology']"
85,Why is the Hessian of an irreducible polynomial not zero?,Why is the Hessian of an irreducible polynomial not zero?,,"Let $k$ be an algebraically closed field, $\operatorname{char}k=0$, $F$ be an irreducible homogeneous polynomial of degree$>1$ in $k[X,Y,Z]$, and $H=\det\left(\begin{array}{ccc}F_{xx}&F_{xy}&F_{xz}\\F_{yx}&F_{yy}&F_{yz}\\F_{zx}&F_{zy}&F_{zz}\end{array}\right)$. Make more clear, in this setting, that $H\neq 0$ is always true. Why is $H$ not 0?   Is there a pure algebraic proof of this ? Thanks.","Let $k$ be an algebraically closed field, $\operatorname{char}k=0$, $F$ be an irreducible homogeneous polynomial of degree$>1$ in $k[X,Y,Z]$, and $H=\det\left(\begin{array}{ccc}F_{xx}&F_{xy}&F_{xz}\\F_{yx}&F_{yy}&F_{yz}\\F_{zx}&F_{zy}&F_{zz}\end{array}\right)$. Make more clear, in this setting, that $H\neq 0$ is always true. Why is $H$ not 0?   Is there a pure algebraic proof of this ? Thanks.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
86,Is $z=e^{\frac{1}{\log(x)}}$ a solution to an algebraic equation?,Is  a solution to an algebraic equation?,z=e^{\frac{1}{\log(x)}},"Is $z=e^{\frac{1}{\log(x)}}$ with $x\in\Bbb Q~\cap(0,1)$ a solution to an algebraic equation? Wolfram is telling me $z$ is algebraic but I'm not sure that I believe this. I believe it would follow from Schanuel's conjecture, $$\mathbb{Q}(\ln x,\mathrm{e}^{1/\ln x})$$ has transcendence degree $2$ whenever $x$ is algebraic. Edit 9/22/2021: Transform this into $\log(z)\log(x)=1.$ We can inspect that this is of the form of a hyperbola ( if we use a change of coordinates to linearize the problem). My intuition tells me that there are two ""incompatible"" structures meshed together which need to be untangled. Let's step back and view this problem from a geometric standpoint in higher dimensional space. I will take two distinct spaces, that each have linear structures on them. The mathematical object $\zeta^2$ is simply related to $\Bbb R^2$ in the following way: $$ \exp: \Bbb R^2 \to \zeta^2$$ and this is a diffeomorphism (from a manifold theory standpoint alone). Due to the ""universality"" of the $\exp$ map, Postulate: Every linear structure on $\Bbb R^2$ can be re-constituted as a linear structure on $\zeta^2.$ For example $\exp$ is a group isomorphism and the group structure on $\Bbb R^2$ can be pushed onto an isomorphic group structure on $\zeta^2$ . Using this key fact, a field structure can be encoded in $\zeta^2$ by way of the group structure and constructing a multiplication map. I've proved that a real vector space structure can be placed on $\zeta^2.$ So we have two disjoint objects each with linear structures on them, and a map between these objects. What I believe is the main issue is that $z$ itself is a mixture of two incompatible linear structures (in dim. 1 as opposed to dim. 2) in a way that makes it nearly impossible to determine whether or not $z$ is algebraic. So the objects $\Bbb R^2$ and $\zeta^2$ can be viewed as inherently different structures with their own linear structures on them and a map between the two objects. What are we doing by inserting $\Bbb Q$ into the variable slot for $x$ ? $$z=e^{\frac{1}{\log(x)}}$$ Maybe we're forcing this inherently nonlinear structure (i.e. nonlinear analytic curve with respect to $\Bbb R^2$ ) of $\varphi(x)=e^{\frac{1}{\log(x)}}$ to obey the classical Riemannian metric $ds^2=dx^2+dy^2.$ Using this train of ideas, I have reason to believe that thinking strictly in terms of $\Bbb R^2$ and $\zeta^2$ as different objects, that $\varphi(x)$ is an algebraic curve with respect to $\zeta^2.$ Once I embed this algebraic curve into $\Bbb R^2$ with $\Bbb R^2$ 's  usual metric something is lost and I can't reconcile it. It should be clear that $\varphi(x)$ is not a polynomial in $\zeta^2$ rather its a hyperbola, so it's an algebraic curve in $\zeta^2.$ And we're inserting rational elements with respect to $\Bbb R^2$ into this algebraic curve's independent variable slot (with respect to $\zeta^2$ ).","Is with a solution to an algebraic equation? Wolfram is telling me is algebraic but I'm not sure that I believe this. I believe it would follow from Schanuel's conjecture, has transcendence degree whenever is algebraic. Edit 9/22/2021: Transform this into We can inspect that this is of the form of a hyperbola ( if we use a change of coordinates to linearize the problem). My intuition tells me that there are two ""incompatible"" structures meshed together which need to be untangled. Let's step back and view this problem from a geometric standpoint in higher dimensional space. I will take two distinct spaces, that each have linear structures on them. The mathematical object is simply related to in the following way: and this is a diffeomorphism (from a manifold theory standpoint alone). Due to the ""universality"" of the map, Postulate: Every linear structure on can be re-constituted as a linear structure on For example is a group isomorphism and the group structure on can be pushed onto an isomorphic group structure on . Using this key fact, a field structure can be encoded in by way of the group structure and constructing a multiplication map. I've proved that a real vector space structure can be placed on So we have two disjoint objects each with linear structures on them, and a map between these objects. What I believe is the main issue is that itself is a mixture of two incompatible linear structures (in dim. 1 as opposed to dim. 2) in a way that makes it nearly impossible to determine whether or not is algebraic. So the objects and can be viewed as inherently different structures with their own linear structures on them and a map between the two objects. What are we doing by inserting into the variable slot for ? Maybe we're forcing this inherently nonlinear structure (i.e. nonlinear analytic curve with respect to ) of to obey the classical Riemannian metric Using this train of ideas, I have reason to believe that thinking strictly in terms of and as different objects, that is an algebraic curve with respect to Once I embed this algebraic curve into with 's  usual metric something is lost and I can't reconcile it. It should be clear that is not a polynomial in rather its a hyperbola, so it's an algebraic curve in And we're inserting rational elements with respect to into this algebraic curve's independent variable slot (with respect to ).","z=e^{\frac{1}{\log(x)}} x\in\Bbb Q~\cap(0,1) z \mathbb{Q}(\ln x,\mathrm{e}^{1/\ln x}) 2 x \log(z)\log(x)=1. \zeta^2 \Bbb R^2  \exp: \Bbb R^2 \to \zeta^2 \exp \Bbb R^2 \zeta^2. \exp \Bbb R^2 \zeta^2 \zeta^2 \zeta^2. z z \Bbb R^2 \zeta^2 \Bbb Q x z=e^{\frac{1}{\log(x)}} \Bbb R^2 \varphi(x)=e^{\frac{1}{\log(x)}} ds^2=dx^2+dy^2. \Bbb R^2 \zeta^2 \varphi(x) \zeta^2. \Bbb R^2 \Bbb R^2 \varphi(x) \zeta^2 \zeta^2. \Bbb R^2 \zeta^2","['abstract-algebra', 'polynomials', 'rational-numbers']"
87,$I+J=1 \Rightarrow I^n+J^n = 1$ for ideals (or elements in GCD domain) [Freshman's Dream Binomial Theorem],for ideals (or elements in GCD domain) [Freshman's Dream Binomial Theorem],I+J=1 \Rightarrow I^n+J^n = 1,"Let $R$ be a commutative ring and $I_1, \dots, I_n$ pairwise comaximal ideals in $R$, i.e., $I_i + I_j = R$ for $i \neq j$. Why are the ideals $I_1^{n_1}, ... , I_r^{n_r}$ (for any $n_1,...,n_r \in\mathbb N$) also comaximal?","Let $R$ be a commutative ring and $I_1, \dots, I_n$ pairwise comaximal ideals in $R$, i.e., $I_i + I_j = R$ for $i \neq j$. Why are the ideals $I_1^{n_1}, ... , I_r^{n_r}$ (for any $n_1,...,n_r \in\mathbb N$) also comaximal?",,"['abstract-algebra', 'commutative-algebra']"
88,Prove that $n^2+n+41$ is prime for $n<40$,Prove that  is prime for,n^2+n+41 n<40,"Here's a problem that showed up on an exam I took, I'm interested in seeing if there are other ways to approach it. Let $n\in\{0,1,...,39\}$. Prove that $n^2+n+41$ is prime. I shall provide my own solution, though I am curious does anyone know how to do this without using PIDs?","Here's a problem that showed up on an exam I took, I'm interested in seeing if there are other ways to approach it. Let $n\in\{0,1,...,39\}$. Prove that $n^2+n+41$ is prime. I shall provide my own solution, though I am curious does anyone know how to do this without using PIDs?",,"['abstract-algebra', 'elementary-number-theory', 'prime-numbers', 'principal-ideal-domains']"
89,Does $A$ a UFD imply that  $A[T]$ is also a UFD?,Does  a UFD imply that   is also a UFD?,A A[T],"I'm trying to prove that $A$ a UFD implies that $A[T]$ is a UFD. The only thing I am sure I could try to use is Gauss's lemma. Also, how can we deduce that the polynomial rings $\mathbb{Z}[x_1,\ldots,x_n]$ and $k[x_1,\ldots,x_n]$ are UFDs?","I'm trying to prove that $A$ a UFD implies that $A[T]$ is a UFD. The only thing I am sure I could try to use is Gauss's lemma. Also, how can we deduce that the polynomial rings $\mathbb{Z}[x_1,\ldots,x_n]$ and $k[x_1,\ldots,x_n]$ are UFDs?",,"['abstract-algebra', 'commutative-algebra', 'unique-factorization-domains']"
90,How is addition different than multiplication?,How is addition different than multiplication?,,"Is there a fundamental difference in the things we call multiplication and those we call addition? In a field, both binary operations obey exactly the same rules (commutativity, associativity, identity element, and inverse element [actually this one is the same for all but 1 element: namely $0$]).  In a ring, some of the multiplicative rules of a field are relaxed, but it seems like we could just as easily have relaxed the additive rules. It seems that even the distributive law could also be defined so that addition distributes over multiplication (opposite to the normal way), and thus is only a distinguishing property -- when it even applies -- because we've decided it should be. Other than the fact that often we require both operations on whatever set of ""numbers"" we're considering, is there some property of addition that is never shared by multiplication (and vice versa), no matter which generalization of each we choose?  That is, can we define the necessary and sufficient conditions for a binary operation to be called ""addition"" or ""multiplication""?","Is there a fundamental difference in the things we call multiplication and those we call addition? In a field, both binary operations obey exactly the same rules (commutativity, associativity, identity element, and inverse element [actually this one is the same for all but 1 element: namely $0$]).  In a ring, some of the multiplicative rules of a field are relaxed, but it seems like we could just as easily have relaxed the additive rules. It seems that even the distributive law could also be defined so that addition distributes over multiplication (opposite to the normal way), and thus is only a distinguishing property -- when it even applies -- because we've decided it should be. Other than the fact that often we require both operations on whatever set of ""numbers"" we're considering, is there some property of addition that is never shared by multiplication (and vice versa), no matter which generalization of each we choose?  That is, can we define the necessary and sufficient conditions for a binary operation to be called ""addition"" or ""multiplication""?",,['abstract-algebra']
91,Smallest non-commutative ring with unity,Smallest non-commutative ring with unity,,Find the smallest non-commutative ring with unity. (By smallest it means it has the least cardinal.) I tried rings of size 4 and I found no such ring.,Find the smallest non-commutative ring with unity. (By smallest it means it has the least cardinal.) I tried rings of size 4 and I found no such ring.,,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
92,Is the group of units of a finite ring cyclic?,Is the group of units of a finite ring cyclic?,,"The group of units of a finite field is cyclic.  Is it true that the group of units of a finite ring is also cyclic? If not, where does the ring structure prevents us from obtaining the result that is true for fields?","The group of units of a finite field is cyclic.  Is it true that the group of units of a finite ring is also cyclic? If not, where does the ring structure prevents us from obtaining the result that is true for fields?",,"['abstract-algebra', 'ring-theory', 'finite-rings']"
93,A vector space is an abelian group with some extra structure?,A vector space is an abelian group with some extra structure?,,"Question: A vector space is an abelian group with some extra structure. Given two vector spaces V1 × V2, show that the group V1 × V2 is a vector space. Can someone explain to me the first sentence? Especially why it is commutative? As to the second sentence, is it just saying the product of vector spaces is vector space? Why it mentions ""group"" V1 × V2 particularly? Thx in advance~","Question: A vector space is an abelian group with some extra structure. Given two vector spaces V1 × V2, show that the group V1 × V2 is a vector space. Can someone explain to me the first sentence? Especially why it is commutative? As to the second sentence, is it just saying the product of vector spaces is vector space? Why it mentions ""group"" V1 × V2 particularly? Thx in advance~",,"['abstract-algebra', 'group-theory']"
94,Proof the quaternions are 4-dimensional?,Proof the quaternions are 4-dimensional?,,"The quaternions can be defined as $$\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$$ From these relations, it is relatively easy to prove that $1,X,Y,XY$ span the quaternions over $\mathbb{R}$ . But I cannot find any way to prove that this is a basis. The quaternions could alternatively be constructed as the set $\mathbb{R}^4$ together with the product $$(a_1,b_1,c_1,d_1)\cdot(a_2,b_2,c_2,d_2)=(a_1a_2-b_1b_2-c_1c_2-d_1d_2,a_1b_2+b_1a_2+c_1d_2-d_1c_2,a_1c_3-b_1d_2+c_1a_1+d_1b_2,a_1d_2+b_1c_2-c_1b_2+d_1a_2)$$ From this point you can prove the product is distributive and associative to show that it forms a ring. You can also prove the identities used in constructing $\mathbb{H}$ as a quotient of the free algebra on 2 generators. Hence, using the universal property, you could show that it is a quotient of $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ , so $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ must have dimension at least $4$ . So this is technically an answer. However, this feels very much like going the long way around, so I want to know if there is a neater way to show that $\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX)$ is $4$ dimensional.","The quaternions can be defined as From these relations, it is relatively easy to prove that span the quaternions over . But I cannot find any way to prove that this is a basis. The quaternions could alternatively be constructed as the set together with the product From this point you can prove the product is distributive and associative to show that it forms a ring. You can also prove the identities used in constructing as a quotient of the free algebra on 2 generators. Hence, using the universal property, you could show that it is a quotient of , so must have dimension at least . So this is technically an answer. However, this feels very much like going the long way around, so I want to know if there is a neater way to show that is dimensional.","\mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX) 1,X,Y,XY \mathbb{R} \mathbb{R}^4 (a_1,b_1,c_1,d_1)\cdot(a_2,b_2,c_2,d_2)=(a_1a_2-b_1b_2-c_1c_2-d_1d_2,a_1b_2+b_1a_2+c_1d_2-d_1c_2,a_1c_3-b_1d_2+c_1a_1+d_1b_2,a_1d_2+b_1c_2-c_1b_2+d_1a_2) \mathbb{H} \mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX) \mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX) 4 \mathbb{R}\langle X,Y\rangle/(X^2+1,Y^2+1,XY+YX) 4","['abstract-algebra', 'ring-theory', 'quaternions', 'algebras']"
95,What's an easy way of proving a subgroup is normal?,What's an easy way of proving a subgroup is normal?,,"I think in most situations(for example, in $S_n$ or $D_n$), proving by definition is too complicated because you have to calculate $gng^{-1}$ for every $n$ in $N$ and $g$ in $G$. To prove that all the left cosets are also right cosets is also too complicated because you have to find all those cosets. I wonder if there's a way to do this without having to calculate everything by hand.","I think in most situations(for example, in $S_n$ or $D_n$), proving by definition is too complicated because you have to calculate $gng^{-1}$ for every $n$ in $N$ and $g$ in $G$. To prove that all the left cosets are also right cosets is also too complicated because you have to find all those cosets. I wonder if there's a way to do this without having to calculate everything by hand.",,"['abstract-algebra', 'group-theory']"
96,How to rewrite $7-\sqrt 5$ in root form without a minus sign?,How to rewrite  in root form without a minus sign?,7-\sqrt 5,"How to rewrite $7-\sqrt 5$ in root form without a minus sign ?  For clarity ""root form "" means an expression that only contains a finite amount of positive integers , additions , substractions , multiplications and root extractions (sqrt, cuberoot etc). For example some quintic equations cannot be solved in root form. A "" root form without a minus sign "" means an expression that only contains a finite amount of positive integers , additions , multiplications and root extractions (sqrt , cuberoot etc). So the solution could look something like this : $$ 7-\sqrt5 = \sqrt{...+1+(...)^{\frac{2}{3}}}+\sqrt{...+2(...)^{\frac{1}{3}}}$$ How to solve such problems ? EDIT Warning : $\dfrac{44}{7+\sqrt 5}$ is not a solution , since no divisions are allowed! I got that answer 3 times now so I put it in the OP as a warning , not just the comments.","How to rewrite $7-\sqrt 5$ in root form without a minus sign ?  For clarity ""root form "" means an expression that only contains a finite amount of positive integers , additions , substractions , multiplications and root extractions (sqrt, cuberoot etc). For example some quintic equations cannot be solved in root form. A "" root form without a minus sign "" means an expression that only contains a finite amount of positive integers , additions , multiplications and root extractions (sqrt , cuberoot etc). So the solution could look something like this : $$ 7-\sqrt5 = \sqrt{...+1+(...)^{\frac{2}{3}}}+\sqrt{...+2(...)^{\frac{1}{3}}}$$ How to solve such problems ? EDIT Warning : $\dfrac{44}{7+\sqrt 5}$ is not a solution , since no divisions are allowed! I got that answer 3 times now so I put it in the OP as a warning , not just the comments.",,"['abstract-algebra', 'polynomials', 'radicals']"
97,Examples of faithfully flat modules,Examples of faithfully flat modules,,"I'm studying some results about flatness and faithful flatness and I'd like to keep in my mind some examples about faithfully flat modules. In general, free modules are the typical examples. Another (unusual) example of faithfully flat module is the ""Zariski Covering"". (Let $R$ be a ring, $(f_1,\dots,f_n)=R$ , and let $R_{f_i}$ be a localization $\forall i$ . Then $S:=\bigoplus_{i=1}^n R_{f_i}$ is called Zariski covering.) Do you have any other example?","I'm studying some results about flatness and faithful flatness and I'd like to keep in my mind some examples about faithfully flat modules. In general, free modules are the typical examples. Another (unusual) example of faithfully flat module is the ""Zariski Covering"". (Let be a ring, , and let be a localization . Then is called Zariski covering.) Do you have any other example?","R (f_1,\dots,f_n)=R R_{f_i} \forall i S:=\bigoplus_{i=1}^n R_{f_i}","['abstract-algebra', 'commutative-algebra', 'modules', 'examples-counterexamples', 'flatness']"
98,Is the set of real numbers a group under the operation of multiplication?,Is the set of real numbers a group under the operation of multiplication?,,"Question: Is the set of real numbers a group under the operation of multiplication? My professor answered it by saying: No. There is no identity element (1*0=0). However, isn't the identity element 1, did he mean to say there is no inverse because the number 0 does not have an inverse. Or did my professor try to mean something else? Or maybe I'm just mis-understanding what he wrote.","Question: Is the set of real numbers a group under the operation of multiplication? My professor answered it by saying: No. There is no identity element (1*0=0). However, isn't the identity element 1, did he mean to say there is no inverse because the number 0 does not have an inverse. Or did my professor try to mean something else? Or maybe I'm just mis-understanding what he wrote.",,['abstract-algebra']
99,"$X^n-Y^m$ is irreducible in $\Bbb{C}[X,Y]$ iff $\gcd(n,m)=1$",is irreducible in  iff,"X^n-Y^m \Bbb{C}[X,Y] \gcd(n,m)=1","I am trying to show that $X^n-Y^m$ is irreducible in $\Bbb{C}[X,Y]$ iff $\gcd(n,m)=1$ where $n,m$ are positive integers. I showed that if $\gcd(n,m)$ is not $1$, then $X^n-Y^m$ is reducible. How to show the other direction. Please help.","I am trying to show that $X^n-Y^m$ is irreducible in $\Bbb{C}[X,Y]$ iff $\gcd(n,m)=1$ where $n,m$ are positive integers. I showed that if $\gcd(n,m)$ is not $1$, then $X^n-Y^m$ is reducible. How to show the other direction. Please help.",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
