,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How can I calculate this limit: $\lim\limits_{x\rightarrow 2}\frac{2-\sqrt{2+x}}{2^{\frac{1}{3}}-(4-x)^\frac{1}{3}}$?,How can I calculate this limit: ?,\lim\limits_{x\rightarrow 2}\frac{2-\sqrt{2+x}}{2^{\frac{1}{3}}-(4-x)^\frac{1}{3}},"I was given this limit to solve, without using L'Hospital rule. It's killing me  !! Can I have the solution please ? $$\lim_{x\rightarrow 2}\frac{2-\sqrt{2+x}}{2^{\frac{1}{3}}-(4-x)^\frac{1}{3}}$$","I was given this limit to solve, without using L'Hospital rule. It's killing me  !! Can I have the solution please ? $$\lim_{x\rightarrow 2}\frac{2-\sqrt{2+x}}{2^{\frac{1}{3}}-(4-x)^\frac{1}{3}}$$",,"['calculus', 'limits', 'radicals', 'limits-without-lhopital']"
1,"For the epsilon-delta definition of limits, can you always pick $\delta$ to be $\epsilon/4$?","For the epsilon-delta definition of limits, can you always pick  to be ?",\delta \epsilon/4,"I just want to get a better grasp of this concept. I don't think you can, for example $F(x) = 1000x$. If I want to be within $1000$ of $f(x)$, i.e. $\epsilon = 1000$, then $\delta$ would be $250$. So, $f(249) = 249,000$ - which is not within $1,000$ of $x$, if $x = 1$. Is this correct? Thanks!","I just want to get a better grasp of this concept. I don't think you can, for example $F(x) = 1000x$. If I want to be within $1000$ of $f(x)$, i.e. $\epsilon = 1000$, then $\delta$ would be $250$. So, $f(249) = 249,000$ - which is not within $1,000$ of $x$, if $x = 1$. Is this correct? Thanks!",,"['calculus', 'limits']"
2,Trying to find $\lim_{x \to 0} \frac{x - \sin x}{(x \sin x)^{(3/2)}}$ using L'Hopital's,Trying to find  using L'Hopital's,\lim_{x \to 0} \frac{x - \sin x}{(x \sin x)^{(3/2)}},"I'm trying to use L'Hopital's rule to calculate: $$\lim_{x \to 0^+} \dfrac{x - \sin x}{(x \sin x)^{(3/2)}}$$ Taking a couple of derivatives of the denominator gets quite nasty, so I'd like to find a simpler way to do it. I would like to make a change of variable, say, $t = \sqrt{x \sin x}$, to get a $t^3$ in the denominator.  Unfortunately, that leaves me with problems in the numerator.  Maybe there is some other manipulation or some trig identity that simplifies things that I am missing?  This shouldn't be a difficult problem, but I can't seem to find a slick way to do it. The answer is given as $\frac{1}{6}$.  Thanks for your help.","I'm trying to use L'Hopital's rule to calculate: $$\lim_{x \to 0^+} \dfrac{x - \sin x}{(x \sin x)^{(3/2)}}$$ Taking a couple of derivatives of the denominator gets quite nasty, so I'd like to find a simpler way to do it. I would like to make a change of variable, say, $t = \sqrt{x \sin x}$, to get a $t^3$ in the denominator.  Unfortunately, that leaves me with problems in the numerator.  Maybe there is some other manipulation or some trig identity that simplifies things that I am missing?  This shouldn't be a difficult problem, but I can't seem to find a slick way to do it. The answer is given as $\frac{1}{6}$.  Thanks for your help.",,['calculus']
3,Find the value of : $\lim_{x \to \infty} \sqrt{4x^2 + 4} - (2x + 2)$ [duplicate],Find the value of :  [duplicate],\lim_{x \to \infty} \sqrt{4x^2 + 4} - (2x + 2),"This question already has answers here : Closed 11 years ago . Possible Duplicate: Limits: How to evaluate $\lim\limits_{x\rightarrow \infty}\sqrt[n]{x^{n}+a_{n-1}x^{n-1}+\cdots+a_{0}}-x$ $$\lim_{x \to \infty} \sqrt{4x^2 + 4} - (2x + 2)$$ So, I have an intermediate form of $\infty - \infty$ and I tried multiplying by the conjugate; however, I seem to be left with another intermediate form of $\frac{\infty}{\infty}$ and wasn't sure what else to to do. Is there anything else I can do other than L'Hopital's rule?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Limits: How to evaluate $\lim\limits_{x\rightarrow \infty}\sqrt[n]{x^{n}+a_{n-1}x^{n-1}+\cdots+a_{0}}-x$ $$\lim_{x \to \infty} \sqrt{4x^2 + 4} - (2x + 2)$$ So, I have an intermediate form of $\infty - \infty$ and I tried multiplying by the conjugate; however, I seem to be left with another intermediate form of $\frac{\infty}{\infty}$ and wasn't sure what else to to do. Is there anything else I can do other than L'Hopital's rule?",,"['calculus', 'limits', 'radicals', 'indeterminate-forms']"
4,limit when searching $a^x$,limit when searching,a^x,"Sorry, my mathematical english vocabulary is not as vivid as I would like it to be, therefore my topic touches the main problem in searching limit for this function. $$\lim_{x \to 0} {\left (\frac{1+x\cdot2^x}{1+x\cdot3^x}\right)}^\frac{1}{x^2}$$ I tried several approaches, although it all ended up to having division by $0$ because of $3^x$ or $2^x$. *EDIT: Can it be solved without using l'Hôpital's rule?","Sorry, my mathematical english vocabulary is not as vivid as I would like it to be, therefore my topic touches the main problem in searching limit for this function. $$\lim_{x \to 0} {\left (\frac{1+x\cdot2^x}{1+x\cdot3^x}\right)}^\frac{1}{x^2}$$ I tried several approaches, although it all ended up to having division by $0$ because of $3^x$ or $2^x$. *EDIT: Can it be solved without using l'Hôpital's rule?",,"['limits', 'exponentiation']"
5,Prove that all but finite number of members of sequence are positive if limit is positive,Prove that all but finite number of members of sequence are positive if limit is positive,,"Prove that if $x > 0$ and $x_n$ is a sequence with $\lim\limits_{n \to \infty} x_n = x$, then there is a real number $N$ s.t. whenever $n > N$, $x_n > 0$. This is a homework question and I'm not really sure what methods I should use to prove this, can I get a push in the right direction? I am not expecting a flat out answer as it is a homework problem, but I am stumped!","Prove that if $x > 0$ and $x_n$ is a sequence with $\lim\limits_{n \to \infty} x_n = x$, then there is a real number $N$ s.t. whenever $n > N$, $x_n > 0$. This is a homework question and I'm not really sure what methods I should use to prove this, can I get a push in the right direction? I am not expecting a flat out answer as it is a homework problem, but I am stumped!",,"['sequences-and-series', 'limits']"
6,Finding $a$ and $r$ such that $\lim\limits_{n\to \infty} n^r \cdot \frac12 \cdot \frac34 \cdots \frac{2n-1}{2n}=a$,Finding  and  such that,a r \lim\limits_{n\to \infty} n^r \cdot \frac12 \cdot \frac34 \cdots \frac{2n-1}{2n}=a,"Find $a,r>0$ such that $$\lim_{n\to \infty} n^r \cdot \frac12 \cdot \frac34 \cdots \frac{2n-1}{2n}=a$$ I don't have any idea to solve it. How can I solve it?","Find $a,r>0$ such that $$\lim_{n\to \infty} n^r \cdot \frac12 \cdot \frac34 \cdots \frac{2n-1}{2n}=a$$ I don't have any idea to solve it. How can I solve it?",,"['calculus', 'limits']"
7,Proof of limit and limit point,Proof of limit and limit point,,Let $\{x_n\}_{n=1}^\infty$ be a sequence of points in $\mathbb R$. Let $X$ be a set defined as a collection of all points in the sequence $\{x_n\}_{n=1}^{\infty}$. Is the following claim true? $\left\{x_n\right\}_{n=1}^\infty$ converges to a limit $x^*$ if and only if the set $X$ has a limit point. My intuition is that the claim is true but I'm not quite sure how to go about showing a rigorous proof of it.,Let $\{x_n\}_{n=1}^\infty$ be a sequence of points in $\mathbb R$. Let $X$ be a set defined as a collection of all points in the sequence $\{x_n\}_{n=1}^{\infty}$. Is the following claim true? $\left\{x_n\right\}_{n=1}^\infty$ converges to a limit $x^*$ if and only if the set $X$ has a limit point. My intuition is that the claim is true but I'm not quite sure how to go about showing a rigorous proof of it.,,"['sequences-and-series', 'limits']"
8,Finding the limit of a quotient,Finding the limit of a quotient,,I am trying to find the limit of $(x^2-6x+5)/(x-5)$ as it approaches $5$. I assume that I just plug in $5$ for $x$ and for that I get $0/0$ but my book says $4$. I try and factor and I end up with $(25-30+5)/(5-5)$ which doesnt seem quite right to me but I know that if I factor out $5$ and get rid of the $5-5$ (although that would make it $1-1$ wouldn't it?) that leaves me with $5-6+5$ which is $4$. What do I need to do in this problem?,I am trying to find the limit of $(x^2-6x+5)/(x-5)$ as it approaches $5$. I assume that I just plug in $5$ for $x$ and for that I get $0/0$ but my book says $4$. I try and factor and I end up with $(25-30+5)/(5-5)$ which doesnt seem quite right to me but I know that if I factor out $5$ and get rid of the $5-5$ (although that would make it $1-1$ wouldn't it?) that leaves me with $5-6+5$ which is $4$. What do I need to do in this problem?,,['calculus']
9,Limits in Double Integration,Limits in Double Integration,,"Can someone please help me understand how to find the ‘new’ limits for double integration? I know that you have to split up the area and fix x or y . If you can go through an example with me then I would be grateful as I keep getting this wrong. We have only been taught how to work out the area of a triangle and so a quadrilateral makes no sense to me… B.t.w., please don’t give ‘general’ advice because I seriously won’t get it. I have looked in my books/lecture notes but it’s all just general theory which isn’t helpful. Example question: By making an appropriate substitution, find the area of D and check the substitution is a 1-1 transformation by finding the inverse explicitly. $$ \iint_D \exp{[xy(x-y)]} (x^2-y^2) \, \rm dx\, \rm dy$$ Here is the diagram: Thanks for the help!","Can someone please help me understand how to find the ‘new’ limits for double integration? I know that you have to split up the area and fix x or y . If you can go through an example with me then I would be grateful as I keep getting this wrong. We have only been taught how to work out the area of a triangle and so a quadrilateral makes no sense to me… B.t.w., please don’t give ‘general’ advice because I seriously won’t get it. I have looked in my books/lecture notes but it’s all just general theory which isn’t helpful. Example question: By making an appropriate substitution, find the area of D and check the substitution is a 1-1 transformation by finding the inverse explicitly. Here is the diagram: Thanks for the help!"," \iint_D \exp{[xy(x-y)]} (x^2-y^2) \, \rm dx\, \rm dy","['integration', 'limits']"
10,About a function bounded by two polynomials,About a function bounded by two polynomials,,"Let $P(x)=x^n+\Sigma_{k=0}^{n-1}a_kx^k $ and $Q(x)=x^n+\Sigma_{k=0}^{n-1}b_kx^k $ be polynomials with real coefficients such that $n\ge 4$ is even and $a_{n-1}<b_{n-1} $ . Let $f(x)$ be a function such that $P(x)\le f(x) \le Q(x) \forall x\in \mathbb{R} $ .Then we conclude that (a) $f(x)$ is a bounded function on $\mathbb{R} $ (b) $f(x)$ is a continuous function on $\mathbb{R} $ (c) There exist $x_o \in \mathbb{R} $ such that $f(x_o)=0$ (d) $f(x)$ is continuous at least at one point $x_o \in\mathbb{R} $ My attempt :- $f(x) \ge P(x)$ , and even degree polynomials with positive leading coefficient are unbounded so is $f(x)$ Given condition says $P(x)\neq Q(x)$ for at least one $c \in \mathbb{R} $ We define $$ f(x)= \begin{cases} P(x) & \text{if } x\in \mathbb{Q} , \\ Q(x) & \text{if } x\in \mathbb{R}\setminus \mathbb{Q} . \end{cases} $$ Assuming $ c\in \mathbb{Q} $ it can be shown $f(x) $ is not continous at $c$ by sequential criterion .So $f(x)$ is not continuous. Now $Q(x)-P(x)=(b_{n-1}-a_{n-1})x^{n-1} + \Sigma_{k=0} ^{n-2} (b_k -a_k) x^k$ An odd degree polynomial with leading coefficient positive . So $ \exists m\in \mathbb{R} $ s.t $Q(x)-P(x)\le 0 , \forall x<m $ But given $P(x)\le Q(x) \forall x $ , so we must have $P(x)=f(x)=Q(x) \forall x <m$ So $f(x)$ is continuous at least at one point . I don't really know if I am proceeding right from above. Kindly guide .Thanks in advance !","Let and be polynomials with real coefficients such that is even and . Let be a function such that .Then we conclude that (a) is a bounded function on (b) is a continuous function on (c) There exist such that (d) is continuous at least at one point My attempt :- , and even degree polynomials with positive leading coefficient are unbounded so is Given condition says for at least one We define Assuming it can be shown is not continous at by sequential criterion .So is not continuous. Now An odd degree polynomial with leading coefficient positive . So s.t But given , so we must have So is continuous at least at one point . I don't really know if I am proceeding right from above. Kindly guide .Thanks in advance !","P(x)=x^n+\Sigma_{k=0}^{n-1}a_kx^k  Q(x)=x^n+\Sigma_{k=0}^{n-1}b_kx^k  n\ge 4 a_{n-1}<b_{n-1}  f(x) P(x)\le f(x) \le Q(x) \forall x\in \mathbb{R}  f(x) \mathbb{R}  f(x) \mathbb{R}  x_o \in \mathbb{R}  f(x_o)=0 f(x) x_o \in\mathbb{R}  f(x) \ge P(x) f(x) P(x)\neq Q(x) c \in \mathbb{R}  
f(x)= \begin{cases} P(x) & \text{if } x\in \mathbb{Q} , \\ Q(x) & \text{if } x\in \mathbb{R}\setminus \mathbb{Q} . \end{cases}
  c\in \mathbb{Q}  f(x)  c f(x) Q(x)-P(x)=(b_{n-1}-a_{n-1})x^{n-1} + \Sigma_{k=0} ^{n-2} (b_k -a_k) x^k  \exists m\in \mathbb{R}  Q(x)-P(x)\le 0 , \forall x<m  P(x)\le Q(x) \forall x  P(x)=f(x)=Q(x) \forall x <m f(x)","['real-analysis', 'limits', 'polynomials', 'continuity', 'roots']"
11,Evaluating limit involving integrals,Evaluating limit involving integrals,,"I recently came across a challenging limit problem involving integrals of power functions during an examination, and I’m having trouble figuring out how to solve it. I would greatly appreciate any help or insights you can provide. The problem is to evaluate the following limits: $$ 	\lim_{n\rightarrow +\infty} \frac{\int_0^{1/2}x^{nx}dx}{\int_{1/2}^1x^{nx}dx},\quad \lim_{n\rightarrow +\infty} \frac{\int_0^{1}\frac{x^{nx}}{1+x^2}dx}{\int_{0}^1x^{nx}dx}. $$ I am aware that we might need to consider the function $f(x)=x^x=e^{x\ln x}$ , which attains its maximum value of 1 at 0 and 1, and its minimum value at $e^{-1}$ . However, I’m unsure how to utilize these facts to tackle the problem. Any hints, suggestions or explanations on how to approach these types of limit problems would be greatly appreciated. Thank you in advance for your assistance.","I recently came across a challenging limit problem involving integrals of power functions during an examination, and I’m having trouble figuring out how to solve it. I would greatly appreciate any help or insights you can provide. The problem is to evaluate the following limits: I am aware that we might need to consider the function , which attains its maximum value of 1 at 0 and 1, and its minimum value at . However, I’m unsure how to utilize these facts to tackle the problem. Any hints, suggestions or explanations on how to approach these types of limit problems would be greatly appreciated. Thank you in advance for your assistance.","
	\lim_{n\rightarrow +\infty} \frac{\int_0^{1/2}x^{nx}dx}{\int_{1/2}^1x^{nx}dx},\quad \lim_{n\rightarrow +\infty} \frac{\int_0^{1}\frac{x^{nx}}{1+x^2}dx}{\int_{0}^1x^{nx}dx}.
 f(x)=x^x=e^{x\ln x} e^{-1}","['real-analysis', 'calculus', 'integration', 'limits']"
12,Proving limit to infinity using epsilon - N definition,Proving limit to infinity using epsilon - N definition,,So I'm practicing with proving limits at infinity using $\epsilon$ - $N$ definition. And I ran into this question in my textbook: $$\lim_{x\to\infty}\frac{x-3}{3x-1}=\frac{1}{3}$$ So far I have: $$\left\vert\frac{x-3}{3x-1} - \frac{1}{3}\right\vert = \left\vert\frac{-8}{9x-3}\right\vert  < \epsilon \quad\Rightarrow\quad x > \frac{8}{9\epsilon} + \frac{1}{3} = N$$ and I am not sure how to proceed at this point. Can someone clarify the next steps? Thanks.,So I'm practicing with proving limits at infinity using - definition. And I ran into this question in my textbook: So far I have: and I am not sure how to proceed at this point. Can someone clarify the next steps? Thanks.,\epsilon N \lim_{x\to\infty}\frac{x-3}{3x-1}=\frac{1}{3} \left\vert\frac{x-3}{3x-1} - \frac{1}{3}\right\vert = \left\vert\frac{-8}{9x-3}\right\vert  < \epsilon \quad\Rightarrow\quad x > \frac{8}{9\epsilon} + \frac{1}{3} = N,"['calculus', 'limits']"
13,Proof a sequence is convergent,Proof a sequence is convergent,,"Given 2 sequences $\{x_n\}$ , $\{y_n\}$ such that: $${y_n^{2} \leq \frac{1}{n} + {x_n}{y_n} \sqrt[3]{x_n}}$$ with ${\forall} n \in$ $	\mathbb{N}$ . Suppose that ${x_n} \to 0$ . Prove that $\{y_n\}$ converges and calculate ${\lim_{n\to\infty} {y_n} }$ I tried to do something like this: $${y_n^{2} \leq \frac{1}{n} + {x_n}{y_n} \sqrt[3]{x_n}}$$ $$\equiv {y_n}({y_n} - x_n^{\frac{4}{3}}) \leq {\frac{1}{n}}$$ Because ${x_n} \to 0$ , so that $x_n^{\frac{4}{3}} \to 0$ , so that the left side of the inequality ${y_n}({y_n} - x_n^{\frac{4}{3}}) \to {y_n^2}$ . And, because ${y_n^2} \leq \frac{1}{n}$ so that $y_n$ is bounded and exist ${\lim_{n\to\infty} {y_n} }$ . Is that a good way to solve the first part of problem ? And how to calculate the limit ? P/s: Sorry because my problem with English and thanks for helping !!","Given 2 sequences , such that: with . Suppose that . Prove that converges and calculate I tried to do something like this: Because , so that , so that the left side of the inequality . And, because so that is bounded and exist . Is that a good way to solve the first part of problem ? And how to calculate the limit ? P/s: Sorry because my problem with English and thanks for helping !!",\{x_n\} \{y_n\} {y_n^{2} \leq \frac{1}{n} + {x_n}{y_n} \sqrt[3]{x_n}} {\forall} n \in 	\mathbb{N} {x_n} \to 0 \{y_n\} {\lim_{n\to\infty} {y_n} } {y_n^{2} \leq \frac{1}{n} + {x_n}{y_n} \sqrt[3]{x_n}} \equiv {y_n}({y_n} - x_n^{\frac{4}{3}}) \leq {\frac{1}{n}} {x_n} \to 0 x_n^{\frac{4}{3}} \to 0 {y_n}({y_n} - x_n^{\frac{4}{3}}) \to {y_n^2} {y_n^2} \leq \frac{1}{n} y_n {\lim_{n\to\infty} {y_n} },"['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
14,infinite limit with $n^2$ root of $n!$,infinite limit with  root of,n^2 n!,"If $\displaystyle p=\lim_{n\rightarrow \infty}\frac{\sqrt[n^2]{1!\cdot 2!\cdot 3!\cdots n!}}{n^q}.$ Then finding value of ordered pair $(p,q)$ , Where $p>0 ,q\neq 0$ . What I try: $\displaystyle (1!\cdot 2!\cdot 3!\cdots n!)^{\frac{1}{n^2}}=e^{\ln(1!\cdot 2!\cdots n!)^{\frac{1}{n^2}}}$ $\displaystyle =e^{\frac{1}{n^2}\ln(1!\cdot 2!\cdot 3!\cdots n!)}=e^{\frac{1}{n^2}(n\ln(1)+(n-1)\ln(2)+(n-2)\ln(3)+\cdots +1\ln(n)}$ I have seems that it must be in Riemann sum , but could not understand how do i Convert it, please have a look , Thanks","If Then finding value of ordered pair , Where . What I try: I have seems that it must be in Riemann sum , but could not understand how do i Convert it, please have a look , Thanks","\displaystyle p=\lim_{n\rightarrow \infty}\frac{\sqrt[n^2]{1!\cdot 2!\cdot 3!\cdots n!}}{n^q}. (p,q) p>0 ,q\neq 0 \displaystyle (1!\cdot 2!\cdot 3!\cdots n!)^{\frac{1}{n^2}}=e^{\ln(1!\cdot 2!\cdots n!)^{\frac{1}{n^2}}} \displaystyle =e^{\frac{1}{n^2}\ln(1!\cdot 2!\cdot 3!\cdots n!)}=e^{\frac{1}{n^2}(n\ln(1)+(n-1)\ln(2)+(n-2)\ln(3)+\cdots +1\ln(n)}",['limits']
15,How do I find the limit of $\frac{n^3 \sin(n!)}{n^5 +1}$?,How do I find the limit of ?,\frac{n^3 \sin(n!)}{n^5 +1},"I have to evaluate the following limit $$\lim_{n\to\infty}\frac{n^3\sin(n!)}{n^5+1}$$ I know the answer is zero and since $$\lim_{n\to\infty}\frac{1}{n^5+1}=0$$ I want to show that $n^3\sin(n!)$ is bounded. I know for every $n\in\mathbb{N}$ , $$-1\leq\sin(n!)\leq1$$ But I don't know what can I do with $n^3$ . When I tried to use WolframAlpha, it says $$-69\leq n^3\sin(n!)\leq59$$ However, I have no idea how to get these values.","I have to evaluate the following limit I know the answer is zero and since I want to show that is bounded. I know for every , But I don't know what can I do with . When I tried to use WolframAlpha, it says However, I have no idea how to get these values.",\lim_{n\to\infty}\frac{n^3\sin(n!)}{n^5+1} \lim_{n\to\infty}\frac{1}{n^5+1}=0 n^3\sin(n!) n\in\mathbb{N} -1\leq\sin(n!)\leq1 n^3 -69\leq n^3\sin(n!)\leq59,['limits']
16,Evaluating $\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}}$ without L'Hopital's Rule,Evaluating  without L'Hopital's Rule,\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}},"I was solving the limit $$\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}}$$ I simplified the numerator by multiplying both the numerator and denominator by $\sqrt{\frac{1}{\cos x}}+1$ getting to $$\frac{1-\cos x}{\sin^2 \left(\frac x {16}\right) \left(\sqrt{\frac{1}{\cos x}}+1 \right)\cos x}$$ After this step, Wolfram suggests to use the product rule and calculate separately: $$\lim_{x\to0}\frac{1-\cos x}{\sin^2\left(\frac{x}{16}\right)}\;\cdot\;\lim_{x\to0}\frac 1 {\left(\sqrt{\frac{1}{\cos x}}+1\right)\cos x}$$ which eventually gets to the final result of $64$ using De l'Hopital. I was wondering if there was a better/simpler solution  that doesn't require De l'Hopital as my professor suggests to avoid using that as much as possible. Thanks in advance.","I was solving the limit I simplified the numerator by multiplying both the numerator and denominator by getting to After this step, Wolfram suggests to use the product rule and calculate separately: which eventually gets to the final result of using De l'Hopital. I was wondering if there was a better/simpler solution  that doesn't require De l'Hopital as my professor suggests to avoid using that as much as possible. Thanks in advance.",\lim_{x\to0}\frac{\sqrt{\frac{1}{\cos x}}-1}{\sin^2 {\frac{x}{16}}} \sqrt{\frac{1}{\cos x}}+1 \frac{1-\cos x}{\sin^2 \left(\frac x {16}\right) \left(\sqrt{\frac{1}{\cos x}}+1 \right)\cos x} \lim_{x\to0}\frac{1-\cos x}{\sin^2\left(\frac{x}{16}\right)}\;\cdot\;\lim_{x\to0}\frac 1 {\left(\sqrt{\frac{1}{\cos x}}+1\right)\cos x} 64,"['limits', 'limits-without-lhopital']"
17,Prove that $\lim_{n\rightarrow\infty}\frac{f(n)}{n!}=e$,Prove that,\lim_{n\rightarrow\infty}\frac{f(n)}{n!}=e,"Prove that $$\lim_{n\rightarrow\infty}\frac{f(n+1)}{n!}=e\tag{1}$$ where $$f(n+1)=n(1+f(n))$$ The recurrence relation of $n!$ is $a_n=na_{n-1}$ or $a_{n+1}=(n+1)a_n$ . I thought of making a new recurrence relation but we swap the $n$ and the $a_n$ . Then, I noticed that although $f(n)<n!$ , $f(n)>(n-1)!$ when $n>2$ . At first, I thought the limit of their quotient would be $2$ , but I found that $\frac{f(8)}{7!}\approx2.718$ , so there is a very small chance that $(1)$ is not true. According to Wolfram Alpha, $f(n+1)=c\Gamma(n+1)+en\Gamma(n,1)$ , where $$\Gamma(s,x)=\int_x^\infty t^{s-1}e^{-t}dt$$ is the incomplete gamma function. Setting $c=0$ , our limit becomes $$e\lim_{n\rightarrow\infty}\frac{\Gamma(n,1)}{\Gamma(n)}=e\lim_{n\rightarrow\infty}\left(1-\frac{\gamma(n,1)}{\Gamma(n)}\right)=e$$ Where $\Gamma(n)=\Gamma(n,x)+\gamma(n,x)$ . The last equality is obtained by L'hopital's rule. My question here is either proving $(1)$ in a completely different way or proving the closed form that Wolfram Alpha gives (the proof I give of $(1)$ is technically not valid unless there is proof for that closed form). Apparently, we have $$\frac{f(n+1)}{n!}=\sum_{k=0}^{n-1}\frac1{k!}$$ So proving this obviously proves $(1)$","Prove that where The recurrence relation of is or . I thought of making a new recurrence relation but we swap the and the . Then, I noticed that although , when . At first, I thought the limit of their quotient would be , but I found that , so there is a very small chance that is not true. According to Wolfram Alpha, , where is the incomplete gamma function. Setting , our limit becomes Where . The last equality is obtained by L'hopital's rule. My question here is either proving in a completely different way or proving the closed form that Wolfram Alpha gives (the proof I give of is technically not valid unless there is proof for that closed form). Apparently, we have So proving this obviously proves","\lim_{n\rightarrow\infty}\frac{f(n+1)}{n!}=e\tag{1} f(n+1)=n(1+f(n)) n! a_n=na_{n-1} a_{n+1}=(n+1)a_n n a_n f(n)<n! f(n)>(n-1)! n>2 2 \frac{f(8)}{7!}\approx2.718 (1) f(n+1)=c\Gamma(n+1)+en\Gamma(n,1) \Gamma(s,x)=\int_x^\infty t^{s-1}e^{-t}dt c=0 e\lim_{n\rightarrow\infty}\frac{\Gamma(n,1)}{\Gamma(n)}=e\lim_{n\rightarrow\infty}\left(1-\frac{\gamma(n,1)}{\Gamma(n)}\right)=e \Gamma(n)=\Gamma(n,x)+\gamma(n,x) (1) (1) \frac{f(n+1)}{n!}=\sum_{k=0}^{n-1}\frac1{k!} (1)","['calculus', 'sequences-and-series', 'limits', 'summation', 'recurrence-relations']"
18,Generalization of Dirac delta identity,Generalization of Dirac delta identity,,"The Dirac delta distribution obeys the following identity in $\mathbb{R}$ $$\lim_{\epsilon\to 0}\dfrac{1}{\pi}\dfrac{\epsilon}{\epsilon^2+x^2}=\delta(x)\tag1.$$ I know how to prove this using the Sokhotski–Plemelj theorem, namely $$\lim_{\epsilon\to 0}\dfrac{1}{x\pm i\epsilon}=\mp i\pi\delta(x)+{\cal P}\dfrac{1}{x},\tag2$$ where $\cal P$ means the principal value. Indeed subtracting the formula for the two signs it follows that $$\lim_{\epsilon \to 0}\dfrac{1}{\pi}\left[\dfrac{\epsilon}{x^2+\epsilon^2}\right]=\dfrac{1}{2\pi i}\lim_{\epsilon \to 0}\left[\dfrac{1}{x-i\epsilon}-\dfrac{1}{x+i\epsilon}\right]=\delta(x)\tag{3}.$$ All that said, I'm interested in a generalization. I want to understand the small $\epsilon$ expansion of $$\left(\dfrac{\epsilon}{\epsilon^2+\|x\|^2}\right)^a\tag{4}$$ where $a\in \mathbb{C}$ and $x\in \mathbb{R}^n$ . For example this often appears in some Physics papers when discussing the wave equation in hyperbolic spaces. It is often claimed that one has an expansion of the form $$\left(\dfrac{\epsilon}{\epsilon^2+\|x\|^2}\right)^a=\pi^{n/2}\dfrac{\Gamma\left(a-\frac{n}{2}\right)}{\Gamma(a)}\epsilon^{n-a}\delta^{(n)}(x)+\dfrac{\epsilon^a}{\|x\|^{2a}}+\cdots\tag{5}$$ where the dots denote subleading terms in the small $\epsilon$ expansion. Setting $a=1$ and $n=1$ and taking $\epsilon\to 0$ we recover (1). I would like to understand how to prove (5) and how to identify the order of the small $\epsilon$ corrections. I also want to understand whether some restriction on $a$ has to be made, another reason I want to fully understand the proof of this result. How can this be shown?","The Dirac delta distribution obeys the following identity in I know how to prove this using the Sokhotski–Plemelj theorem, namely where means the principal value. Indeed subtracting the formula for the two signs it follows that All that said, I'm interested in a generalization. I want to understand the small expansion of where and . For example this often appears in some Physics papers when discussing the wave equation in hyperbolic spaces. It is often claimed that one has an expansion of the form where the dots denote subleading terms in the small expansion. Setting and and taking we recover (1). I would like to understand how to prove (5) and how to identify the order of the small corrections. I also want to understand whether some restriction on has to be made, another reason I want to fully understand the proof of this result. How can this be shown?","\mathbb{R} \lim_{\epsilon\to 0}\dfrac{1}{\pi}\dfrac{\epsilon}{\epsilon^2+x^2}=\delta(x)\tag1. \lim_{\epsilon\to 0}\dfrac{1}{x\pm i\epsilon}=\mp i\pi\delta(x)+{\cal P}\dfrac{1}{x},\tag2 \cal P \lim_{\epsilon \to 0}\dfrac{1}{\pi}\left[\dfrac{\epsilon}{x^2+\epsilon^2}\right]=\dfrac{1}{2\pi i}\lim_{\epsilon \to 0}\left[\dfrac{1}{x-i\epsilon}-\dfrac{1}{x+i\epsilon}\right]=\delta(x)\tag{3}. \epsilon \left(\dfrac{\epsilon}{\epsilon^2+\|x\|^2}\right)^a\tag{4} a\in \mathbb{C} x\in \mathbb{R}^n \left(\dfrac{\epsilon}{\epsilon^2+\|x\|^2}\right)^a=\pi^{n/2}\dfrac{\Gamma\left(a-\frac{n}{2}\right)}{\Gamma(a)}\epsilon^{n-a}\delta^{(n)}(x)+\dfrac{\epsilon^a}{\|x\|^{2a}}+\cdots\tag{5} \epsilon a=1 n=1 \epsilon\to 0 \epsilon a","['calculus', 'limits', 'analysis', 'mathematical-physics', 'distribution-theory']"
19,How to evaluate $\lim\limits_{x \to-\infty}\frac{\sqrt{16x^6-x^2}}{6x^3+x^2}$,How to evaluate,\lim\limits_{x \to-\infty}\frac{\sqrt{16x^6-x^2}}{6x^3+x^2},How I approach this problem:- $\displaystyle \lim_{x  \to -\infty} \frac{\sqrt{16x^6 - x^2}}{6x^3+x^2}$ $= \displaystyle \lim_{x  \to -\infty} \frac{\sqrt{x^6(16 - \frac{x^2}{x^6}})}{x^2(6x+1)}$ $= \displaystyle \lim_{x  \to -\infty} \frac{x^3\sqrt{16 - \frac{1}{x^4}}}{x^2(6x+1)}$ $= \displaystyle \lim_{x  \to -\infty} \frac{x\sqrt{16 - \frac{1}{x^4}}}{6x+1}$ $= \displaystyle \lim_{x  \to -\infty} \frac{\sqrt{16 - \frac{1}{x^4}}}{6+\frac{1}{x}}$ Now the answer to this problem is $-\frac{2}{3}$ but it doesn't seems to match with the last expression. What I observe in the initial step is the numerator is positive because of the even powers and denominator is negative because cubic power dominates square power and we get negative in the denominator. Still what if we didn't knew the initial step and knew only the last one. How one will conclude it's $-\frac{2}{3}$ . Whether $x \to -\infty \;\text{or}\; \infty$ the last expression always comes out to be $\frac{\sqrt{16}}{6}$ or my steps are wrong?,How I approach this problem:- Now the answer to this problem is but it doesn't seems to match with the last expression. What I observe in the initial step is the numerator is positive because of the even powers and denominator is negative because cubic power dominates square power and we get negative in the denominator. Still what if we didn't knew the initial step and knew only the last one. How one will conclude it's . Whether the last expression always comes out to be or my steps are wrong?,\displaystyle \lim_{x  \to -\infty} \frac{\sqrt{16x^6 - x^2}}{6x^3+x^2} = \displaystyle \lim_{x  \to -\infty} \frac{\sqrt{x^6(16 - \frac{x^2}{x^6}})}{x^2(6x+1)} = \displaystyle \lim_{x  \to -\infty} \frac{x^3\sqrt{16 - \frac{1}{x^4}}}{x^2(6x+1)} = \displaystyle \lim_{x  \to -\infty} \frac{x\sqrt{16 - \frac{1}{x^4}}}{6x+1} = \displaystyle \lim_{x  \to -\infty} \frac{\sqrt{16 - \frac{1}{x^4}}}{6+\frac{1}{x}} -\frac{2}{3} -\frac{2}{3} x \to -\infty \;\text{or}\; \infty \frac{\sqrt{16}}{6},"['calculus', 'limits']"
20,A limit containing an integral,A limit containing an integral,,"I got stuck evaluating the limit of an expression containing an integral. $$\lim_{n\to+\infty} \frac{e^{(n+1)^2}}{(n+1)\int_{n}^{n+1}e^{x^2}dx}$$ Using Mathematica, I can get the reference answer of $2$ . But I don't know how to compute it by hand. I tried taking Taylor series at $x=n+1$ to cancel $e^{(n+1)^2}$ but it doesn't work - the denominator becomes a polynomial of $n$ , so the limit becomes $0$ , which is certainly wrong. Could somebody help me?","I got stuck evaluating the limit of an expression containing an integral. Using Mathematica, I can get the reference answer of . But I don't know how to compute it by hand. I tried taking Taylor series at to cancel but it doesn't work - the denominator becomes a polynomial of , so the limit becomes , which is certainly wrong. Could somebody help me?",\lim_{n\to+\infty} \frac{e^{(n+1)^2}}{(n+1)\int_{n}^{n+1}e^{x^2}dx} 2 x=n+1 e^{(n+1)^2} n 0,"['integration', 'limits', 'definite-integrals']"
21,Find n given that $\lim\limits_{x\rightarrow0} \frac{1-\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{x^2} = 10$,Find n given that,\lim\limits_{x\rightarrow0} \frac{1-\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{x^2} = 10,"I'm trying to solve this rather interesting problem. We have been given that $\lim\limits_{x\rightarrow0}  \frac{1-\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{x^2}$ = 10   and we are required to find n . This is the $\frac{0}{0}$ form, so we can use L'Hôpital's rule . After taking the derivatives of the numerator and the denominator separately, the problem becomes- $\lim\limits_{x\rightarrow0}  \frac{-\frac{d}{dx}\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{2x}$ = 10 $\lim\limits_{x\rightarrow0}  \frac{-\frac{d}{dx}\prod_{i = 2}^{n} (\cos ix)^\frac{1}{i}}{2x}$ = 10 Now, the numerator looks like a pretty difficult expression to differentiate. Here, I decided to simplify the expression in the numerator first. Let y= $\prod_{i = 2}^{n} (\cos ix)^\frac{1}{i}$ Now, we can simplify the expression by taking the natural logarithm of both sides. $\log(y)$ = $\log(\prod_{i = 2}^{n} (\cos ix)^\frac{1}{i})$ Now we can use the property of logarithms to simplify the expression, $\log(xy)=\log(x)+\log(y)$ $\log(y)$ = $\sum_{i = 2}^{n} \frac{1}{i}.\log(\cos ix)$ This is where I ran out of ideas to simplify this expression any further. Any ideas would be appreciated.","I'm trying to solve this rather interesting problem. We have been given that = 10   and we are required to find n . This is the form, so we can use L'Hôpital's rule . After taking the derivatives of the numerator and the denominator separately, the problem becomes- = 10 = 10 Now, the numerator looks like a pretty difficult expression to differentiate. Here, I decided to simplify the expression in the numerator first. Let y= Now, we can simplify the expression by taking the natural logarithm of both sides. = Now we can use the property of logarithms to simplify the expression, = This is where I ran out of ideas to simplify this expression any further. Any ideas would be appreciated.",\lim\limits_{x\rightarrow0}  \frac{1-\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{x^2} \frac{0}{0} \lim\limits_{x\rightarrow0}  \frac{-\frac{d}{dx}\sqrt{\cos2x}.\sqrt[3]{\cos3x}.\sqrt[4]{\cos4x}...\sqrt[n]{\cos{nx}}}{2x} \lim\limits_{x\rightarrow0}  \frac{-\frac{d}{dx}\prod_{i = 2}^{n} (\cos ix)^\frac{1}{i}}{2x} \prod_{i = 2}^{n} (\cos ix)^\frac{1}{i} \log(y) \log(\prod_{i = 2}^{n} (\cos ix)^\frac{1}{i}) \log(xy)=\log(x)+\log(y) \log(y) \sum_{i = 2}^{n} \frac{1}{i}.\log(\cos ix),['limits']
22,Prove limit $\lim\limits_{n\to\infty} \frac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!} = 0$,Prove limit,\lim\limits_{n\to\infty} \frac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!} = 0,I would like to prove that $\lim\limits_{n\to\infty}\dfrac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!}=0$ I have thought of De L'Hospital but that would require me to differentiate the gamma function which doesn't seem very helpful.,I would like to prove that I have thought of De L'Hospital but that would require me to differentiate the gamma function which doesn't seem very helpful.,\lim\limits_{n\to\infty}\dfrac{2^{2n+1} \cdot r^{2n} \pi^n \cdot n!}{(2n+1)!}=0,"['limits', 'factorial']"
23,Demonstrating non-differentiability with absolute value equations.,Demonstrating non-differentiability with absolute value equations.,,"I have a function $f(x)=|x^2-4|$ . I am able to use the following definition of absolute value to show that $f(x)$ is non-differentiable at $x=\pm2$ $|x| = \begin{cases} x, & x\geq0 \\ -x, & x<0 \end{cases} $ . When I use that definition I find that $\lim \limits_{x \to -2-} f'(x)=-4$ and $\lim \limits_{x \to -2+} f'(x)=4$ However, I am not able to show that with the following definition for the absolute value: $|x|=\sqrt{x^2}$ . $|x^2-4|=\sqrt{(x^2-4)^2}$ $\lim \limits_{x \to -2} \frac{\sqrt{(x^2-4)^2}-\sqrt{((-2)^2-4)^2}}{x-(-2)}$ $=\lim \limits_{x \to -2} \frac{\sqrt{(x^2-4)^2}-0}{x+2}$ $=\lim \limits_{x \to -2} \frac{(x^2-4)^2}{(x+2)^2}$ $=\lim \limits_{x \to -2} \frac{(x+2)^2(x-2)^2}{(x+2)^2}$ $=\lim \limits_{x \to -2} (x-2)^2$ $=((-2)-2)^2=16$ I have bad fundamentals. So, I apologize for missing something basic. Thank you for your help in advance.","I have a function . I am able to use the following definition of absolute value to show that is non-differentiable at . When I use that definition I find that and However, I am not able to show that with the following definition for the absolute value: . I have bad fundamentals. So, I apologize for missing something basic. Thank you for your help in advance.","f(x)=|x^2-4| f(x) x=\pm2 |x| =
\begin{cases}
x, & x\geq0 \\
-x, & x<0
\end{cases}  \lim \limits_{x \to -2-} f'(x)=-4 \lim \limits_{x \to -2+} f'(x)=4 |x|=\sqrt{x^2} |x^2-4|=\sqrt{(x^2-4)^2} \lim \limits_{x \to -2} \frac{\sqrt{(x^2-4)^2}-\sqrt{((-2)^2-4)^2}}{x-(-2)} =\lim \limits_{x \to -2} \frac{\sqrt{(x^2-4)^2}-0}{x+2} =\lim \limits_{x \to -2} \frac{(x^2-4)^2}{(x+2)^2} =\lim \limits_{x \to -2} \frac{(x+2)^2(x-2)^2}{(x+2)^2} =\lim \limits_{x \to -2} (x-2)^2 =((-2)-2)^2=16","['calculus', 'limits', 'derivatives', 'absolute-value']"
24,Two different answers to $\lim_{x \to -\infty} \frac{8x^2-2x^3+1}{6x^2+13x+4}$,Two different answers to,\lim_{x \to -\infty} \frac{8x^2-2x^3+1}{6x^2+13x+4},"Let us evaluate $$\lim_{x \to -\infty} \frac{8x^2-2x^3+1}{6x^2+13x+4}$$ Dividing the numerator and denominator by $x^3$ we will be left with $$\lim_{x \to -\infty} \frac{\frac{8}{x}-2+\frac{1}{x^3}}{\frac{6}{x}+\frac{13}{x^2}+\frac{4}{x^3}}$$ and since all the terms containg $x$ term will go to $0$ ,our resultant limit becomes $-\frac{2}{0}=-\infty$ . But if we do it in another way substituting $x=-t$ ,then our limit becomes after dividing both numerator and denominator by $t$ , $$\lim_{t \to \infty} \frac{\frac{8}{t}+2+\frac{1}{t^3}}{\frac{6}{t}-\frac{13}{t^2}+\frac{4}{t^3}}$$ Here also since terms containing $t$ go to $0$ ,we are left with $\frac{2}{0}=+\infty$ . Why are we getting two different answers? Surely one of the method is invalid. In books,the first answer was marked correct. But i want to know what's wrong with the second approach.","Let us evaluate Dividing the numerator and denominator by we will be left with and since all the terms containg term will go to ,our resultant limit becomes . But if we do it in another way substituting ,then our limit becomes after dividing both numerator and denominator by , Here also since terms containing go to ,we are left with . Why are we getting two different answers? Surely one of the method is invalid. In books,the first answer was marked correct. But i want to know what's wrong with the second approach.",\lim_{x \to -\infty} \frac{8x^2-2x^3+1}{6x^2+13x+4} x^3 \lim_{x \to -\infty} \frac{\frac{8}{x}-2+\frac{1}{x^3}}{\frac{6}{x}+\frac{13}{x^2}+\frac{4}{x^3}} x 0 -\frac{2}{0}=-\infty x=-t t \lim_{t \to \infty} \frac{\frac{8}{t}+2+\frac{1}{t^3}}{\frac{6}{t}-\frac{13}{t^2}+\frac{4}{t^3}} t 0 \frac{2}{0}=+\infty,['limits']
25,calculate the limit of a function,calculate the limit of a function,,"I want to calculate the limite of this function when $x\to\infty$ . $\lim_{x\to\infty}\left(\frac{c+\sqrt{x}}{-c+\sqrt{x}}\right)^x\exp(-2c\sqrt{x})$ , where $c$ is a constant. Numerically, I plot a graphic of this function, and I think the answer is 1. But theoretically, I have no idea how to proceed.","I want to calculate the limite of this function when . , where is a constant. Numerically, I plot a graphic of this function, and I think the answer is 1. But theoretically, I have no idea how to proceed.",x\to\infty \lim_{x\to\infty}\left(\frac{c+\sqrt{x}}{-c+\sqrt{x}}\right)^x\exp(-2c\sqrt{x}) c,"['calculus', 'limits', 'analysis', 'limits-without-lhopital']"
26,Is there an intuitive reason why $\int_{-\infty}^{\infty} x dx$ doesn't exist but $\lim\limits_{N\to \infty} \int_{-N}^N xdx$ exists?,Is there an intuitive reason why  doesn't exist but  exists?,\int_{-\infty}^{\infty} x dx \lim\limits_{N\to \infty} \int_{-N}^N xdx,"Is there some intuitive reason why $\int_{-\infty}^{\infty} x dx$ doesn't exist but $\lim\limits_{N\to \infty} \int_{-N}^N xdx$ does? It would seem they represent the same thing (area beneath $f$ everywhere), but apparently not. Consider the following problem from Ch. 14 ""The Fundamental Theorem of Calculus"" from Spivak's Calculus 27 (b) The improper integral $\int_{-\infty}^a f$ is defined in the obvious way, as $\lim\limits_{N\to -\infty} \int_N^a f$ . But another kind of improper integral $\int_{-\infty}^{\infty} f$ is defined in a nonobvious way: it is $\int_0^{\infty} f + \int_{-\infty}^0 f$ , provided these improper integrals both exist. (b) Explain why $\int_{-\infty}^{\infty} x dx$ does not exist. (But notice that $\lim\limits_{N\to \infty} \int_{-N}^N xdx$ does exist) My calculations are as follows $$\int_{-N}^N xdx = \left . \frac{x^2}{2} \right |_{-N}^N=\frac{N^2-(-N)^2}{2}=0$$ On the other hand $$\int_{-\infty}^{\infty} xdx=\int_{-\infty}^0xdx+\int_0^{\infty}xdx$$ $$=\lim\limits_{N \to -\infty} \int_{N}^0 xdx+\lim\limits_{N\to\infty}\int_0^{N} xdx$$ $$=\lim\limits_{N\to -\infty} \left . \frac{x^2}{2}\right |_N^0+\lim\limits_{N\to\infty} \left . \frac{x^2}{2} \right |_0^N$$ $$\lim\limits_{N\to -\infty} \frac{-N^2}{2}+\lim\limits_{N\to \infty} \frac{N^2}{2}$$ Neither of these limits exists. This seems like a weird result. Furthermore, if we had defined $\int_{-\infty}^a f$ as $\lim\limits_{N\to \infty} \int_{-N}^a f$ then in the calculation above we would have $$\int_{-\infty}^{\infty} xdx=\int_{-\infty}^0xdx+\int_0^{\infty}xdx$$ $$=\lim\limits_{N \to \infty} \int_{-N}^0 xdx+\lim\limits_{N\to\infty}\int_0^{N} xdx$$ $$=\lim\limits_{N \to \infty} \left ( -\frac{(-N)^2}{2}+\frac{N^2}{2} \right )$$ $$=\lim\limits_{N \to \infty} 0$$ $$=0$$","Is there some intuitive reason why doesn't exist but does? It would seem they represent the same thing (area beneath everywhere), but apparently not. Consider the following problem from Ch. 14 ""The Fundamental Theorem of Calculus"" from Spivak's Calculus 27 (b) The improper integral is defined in the obvious way, as . But another kind of improper integral is defined in a nonobvious way: it is , provided these improper integrals both exist. (b) Explain why does not exist. (But notice that does exist) My calculations are as follows On the other hand Neither of these limits exists. This seems like a weird result. Furthermore, if we had defined as then in the calculation above we would have",\int_{-\infty}^{\infty} x dx \lim\limits_{N\to \infty} \int_{-N}^N xdx f \int_{-\infty}^a f \lim\limits_{N\to -\infty} \int_N^a f \int_{-\infty}^{\infty} f \int_0^{\infty} f + \int_{-\infty}^0 f \int_{-\infty}^{\infty} x dx \lim\limits_{N\to \infty} \int_{-N}^N xdx \int_{-N}^N xdx = \left . \frac{x^2}{2} \right |_{-N}^N=\frac{N^2-(-N)^2}{2}=0 \int_{-\infty}^{\infty} xdx=\int_{-\infty}^0xdx+\int_0^{\infty}xdx =\lim\limits_{N \to -\infty} \int_{N}^0 xdx+\lim\limits_{N\to\infty}\int_0^{N} xdx =\lim\limits_{N\to -\infty} \left . \frac{x^2}{2}\right |_N^0+\lim\limits_{N\to\infty} \left . \frac{x^2}{2} \right |_0^N \lim\limits_{N\to -\infty} \frac{-N^2}{2}+\lim\limits_{N\to \infty} \frac{N^2}{2} \int_{-\infty}^a f \lim\limits_{N\to \infty} \int_{-N}^a f \int_{-\infty}^{\infty} xdx=\int_{-\infty}^0xdx+\int_0^{\infty}xdx =\lim\limits_{N \to \infty} \int_{-N}^0 xdx+\lim\limits_{N\to\infty}\int_0^{N} xdx =\lim\limits_{N \to \infty} \left ( -\frac{(-N)^2}{2}+\frac{N^2}{2} \right ) =\lim\limits_{N \to \infty} 0 =0,"['calculus', 'integration', 'limits', 'derivatives']"
27,Evaluating limit using Riemann sums,Evaluating limit using Riemann sums,,"I am preparing for calc II exam, and i have some trouble with 2 problems. $$ \lim_{n \to \infty} \frac{1}{7n^2}+\frac{1}{7n^2+1}+\frac{1}{7n^2+2}+ \dots + \frac{1}{8n^2}$$ $$ \lim_{n \to \infty} \sum_{i=n+1}^{7n} \frac{i}{n^2} $$ Now what i usually do in these kinds of problems is is take out $\frac{1}{n}$ in front of the sum and rearrange rest of the terms in order to get some kind of function with $\frac{i}{n}$ , so that i can treat it as a Riemann Sums (and already solved bunch of examples using this). But for example in first one i end up with: $$\frac{1}{n}\sum_{i=0}^{n} \frac{1}{7n+\frac{i}{n}}  $$ And after playing with it for a while, I was not able to transform it to anything meaningful, same goes with the second example, Hints appreciated.","I am preparing for calc II exam, and i have some trouble with 2 problems. Now what i usually do in these kinds of problems is is take out in front of the sum and rearrange rest of the terms in order to get some kind of function with , so that i can treat it as a Riemann Sums (and already solved bunch of examples using this). But for example in first one i end up with: And after playing with it for a while, I was not able to transform it to anything meaningful, same goes with the second example, Hints appreciated.", \lim_{n \to \infty} \frac{1}{7n^2}+\frac{1}{7n^2+1}+\frac{1}{7n^2+2}+ \dots + \frac{1}{8n^2}  \lim_{n \to \infty} \sum_{i=n+1}^{7n} \frac{i}{n^2}  \frac{1}{n} \frac{i}{n} \frac{1}{n}\sum_{i=0}^{n} \frac{1}{7n+\frac{i}{n}}  ,"['calculus', 'limits', 'riemann-sum']"
28,"If $L=\lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m+m^2}$, then find floor(L).","If , then find floor(L).",L=\lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m+m^2},"If $L=\displaystyle\lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m+m^2}$ , then find floor(L). This is from a preparatory examination for the college entrance exams for high-school students. I first tried to convert it into a definite integral by the conventional way, but the $m^2$ term kept interfering. Now the only other thing that I could think of was the sandwich theorem or the squeeze theorem, for which also I could think about only the upper bound. This was $$L\leq \lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m}= \int_0^1\frac{xdx}{2x+1}=\frac{2-\ln 3}{4}$$ while this gives me the correct value of the floor function, but the solution claims that $L=\frac 12$ .","If , then find floor(L). This is from a preparatory examination for the college entrance exams for high-school students. I first tried to convert it into a definite integral by the conventional way, but the term kept interfering. Now the only other thing that I could think of was the sandwich theorem or the squeeze theorem, for which also I could think about only the upper bound. This was while this gives me the correct value of the floor function, but the solution claims that .",L=\displaystyle\lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m+m^2} m^2 L\leq \lim_{m\to \infty}\sum_{p=1}^m \frac{p}{2p+m}= \int_0^1\frac{xdx}{2x+1}=\frac{2-\ln 3}{4} L=\frac 12,"['calculus', 'limits', 'summation']"
29,Find a limit as product of cos,Find a limit as product of cos,,"$$\lim\limits_{n\to\infty}\cos\frac{1}{n\sqrt{n}}\cos\frac{2}{n\sqrt{n}}\cdots\cos\frac{n}{n\sqrt{n}}$$ It is not hard to prove that the limit exists, but is that possible to calculate the limit? Suggestions are welcome!","It is not hard to prove that the limit exists, but is that possible to calculate the limit? Suggestions are welcome!",\lim\limits_{n\to\infty}\cos\frac{1}{n\sqrt{n}}\cos\frac{2}{n\sqrt{n}}\cdots\cos\frac{n}{n\sqrt{n}},"['calculus', 'limits']"
30,"If $f:\mathbb{R}\to\mathbb{R}$ is a differentiable function with $x^2f'(x)\to 0$ as $x\to\infty,$ then does $f(x)\to c\in\mathbb{R}$ as $x\to\infty$?",If  is a differentiable function with  as  then does  as ?,"f:\mathbb{R}\to\mathbb{R} x^2f'(x)\to 0 x\to\infty, f(x)\to c\in\mathbb{R} x\to\infty","If $f:\mathbb{R}\to\mathbb{R}$ is a differentiable function with $xf'(x)\to 0$ as $x\to\infty,$ then it is not true that $f(x)\to c\in\mathbb{R}$ as $x\to\infty. $ For example, take $f(x) = \log(\log(x)).$ But I cannot figure out the following: If $f:\mathbb{R}\to\mathbb{R}$ is a differentiable function with $x^2f'(x)\to 0$ as $x\to\infty,$ then is it true that $f(x)\to c\in\mathbb{R}$ as $x\to\infty $ ? I'm not certain it is true but cannot think of a counter-example either. I have tried three different methods, but got nowhere: Integration by parts: $$\int_{a}^{\infty} x^2 f'(x) dx = \left[ x^2 f(x) \right]_{a}^{\infty} - \int_{a}^{\infty} 2x f(x) dx $$ but I don't see where to go from here. In fact, I'm pretty sure this is the wrong route. 2. $$ x^2 f'(x)\to 0 \implies \lim_{x\to \infty}\left( x^2 \lim_{h\to 0} \frac{f(x+h)-f(x)}{h} \right)$$ I'm not sure how we can manipulate this to help us. Given $\varepsilon>0,\ \exists\ \gamma\ $ s.t. $\ \vert x^2 f'(x)\vert < \varepsilon\ \forall x>\gamma, \implies \vert f'(x) \vert <\frac{\varepsilon}{\gamma^2}\ \forall x> \gamma.$ But now what?","If is a differentiable function with as then it is not true that as For example, take But I cannot figure out the following: If is a differentiable function with as then is it true that as ? I'm not certain it is true but cannot think of a counter-example either. I have tried three different methods, but got nowhere: Integration by parts: but I don't see where to go from here. In fact, I'm pretty sure this is the wrong route. 2. I'm not sure how we can manipulate this to help us. Given s.t. But now what?","f:\mathbb{R}\to\mathbb{R} xf'(x)\to 0 x\to\infty, f(x)\to
c\in\mathbb{R} x\to\infty.  f(x) = \log(\log(x)). f:\mathbb{R}\to\mathbb{R} x^2f'(x)\to 0 x\to\infty, f(x)\to
c\in\mathbb{R} x\to\infty  \int_{a}^{\infty} x^2 f'(x) dx = \left[ x^2 f(x) \right]_{a}^{\infty} - \int_{a}^{\infty} 2x f(x) dx   x^2 f'(x)\to 0 \implies \lim_{x\to \infty}\left( x^2 \lim_{h\to 0} \frac{f(x+h)-f(x)}{h} \right) \varepsilon>0,\ \exists\ \gamma\  \ \vert x^2 f'(x)\vert < \varepsilon\ \forall x>\gamma, \implies \vert f'(x) \vert <\frac{\varepsilon}{\gamma^2}\ \forall x> \gamma.","['real-analysis', 'limits', 'derivatives', 'logarithms', 'problem-solving']"
31,$\lim_{n \to \infty}\frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2}=0 \; ?$ [duplicate],[duplicate],\lim_{n \to \infty}\frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2}=0 \; ?,"This question already has answers here : $ \lim_{n \to \infty} \frac{\sqrt{n}(\sqrt{1} + \sqrt{2} + ... + \sqrt{n})}{n^2} $ (4 answers) Closed 2 years ago . I was wondering whether this limit converges to zero: $$ \lim_{n \to \infty}\frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2}=0 $$ And i'm pretty sure it is. First, by intuition. I know that $\sum_{i=0}^n{i} = \frac{n(n+1)}{2}$ ~ $O(n^2)$ , so i guess that $\sum_{i=0}^n{\sqrt{i}}$ is ""less powerful"", but i don't really know how much ""lesser"" So, the thing that really interest me was: what is the ""cardinality"" of $\sum_{i=0}^{\infty}{\sqrt{i}} \;? \quad$ Is it ""equal ~"" to $O(n)$ ? (I'm not sure i translated the words correctly. Does 'cardinality' is the right word for my description? I'm not familiar with these words in english, sorry. hope you understood what i meant). Here is my thought: $ {\sum_{i=0}^{n}{\sqrt{i}}} =  {\sqrt{1}+\sqrt{2}+\sqrt{3}+...+\sqrt{n-1}+\sqrt{n}} = {\sqrt{n} \big( \frac{\sqrt{1}}{\sqrt{n}} +\frac{\sqrt{2}}{\sqrt{2}} +...+ \frac{\sqrt{n-1}}{\sqrt{n}} + \frac{\sqrt{n}}{\sqrt{n}} \big)} = {{\sqrt{n} \big( \sqrt{\frac{1}{n}} + \sqrt{\frac{2}{n}} +...+ \sqrt{\frac{n-1}{n}} + \sqrt{\frac{n}{n}} \big)}} $ and so: $$ \lim_{n \to \infty} \frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2} =  \lim_{n \to \infty} \frac{{\sqrt{n} \big( \sqrt{\frac{1}{n}} + \sqrt{\frac{2}{n}} +...+ \sqrt{\frac{n-1}{n}} + \sqrt{\frac{n}{n}} \big)}}{n^2} \overbrace{<}^{(*)} \lim_{n \to \infty} \frac{{\sqrt{n} \big( \sqrt{\frac{n}{n}} + \sqrt{\frac{n}{n}} +...+ \sqrt{\frac{n}{n}} + \sqrt{\frac{n}{n}} \big)}}{n^2} = \lim_{n \to \infty} \frac{{\sqrt{n} \big( \overbrace{1 + 1 +...+ 1 + 1}^{n \, times} \big)}}{n^2} = \lim_{n \to \infty} \frac{ \sqrt{n} *n }{n^2} = \lim_{n \to \infty} \frac{ \sqrt{n} }{n} = \lim_{n \to \infty} \frac{1}{ \sqrt{n} } = 0 $$ But my enlargement in $(*)$ above was too big. I was wondering if you can suggest me some better way :)","This question already has answers here : $ \lim_{n \to \infty} \frac{\sqrt{n}(\sqrt{1} + \sqrt{2} + ... + \sqrt{n})}{n^2} $ (4 answers) Closed 2 years ago . I was wondering whether this limit converges to zero: And i'm pretty sure it is. First, by intuition. I know that ~ , so i guess that is ""less powerful"", but i don't really know how much ""lesser"" So, the thing that really interest me was: what is the ""cardinality"" of Is it ""equal ~"" to ? (I'm not sure i translated the words correctly. Does 'cardinality' is the right word for my description? I'm not familiar with these words in english, sorry. hope you understood what i meant). Here is my thought: and so: But my enlargement in above was too big. I was wondering if you can suggest me some better way :)","
\lim_{n \to \infty}\frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2}=0
 \sum_{i=0}^n{i} = \frac{n(n+1)}{2} O(n^2) \sum_{i=0}^n{\sqrt{i}} \sum_{i=0}^{\infty}{\sqrt{i}} \;? \quad O(n) 
{\sum_{i=0}^{n}{\sqrt{i}}} = 
{\sqrt{1}+\sqrt{2}+\sqrt{3}+...+\sqrt{n-1}+\sqrt{n}} =
{\sqrt{n} \big( \frac{\sqrt{1}}{\sqrt{n}} +\frac{\sqrt{2}}{\sqrt{2}} +...+ \frac{\sqrt{n-1}}{\sqrt{n}} + \frac{\sqrt{n}}{\sqrt{n}} \big)} =
{{\sqrt{n} \big( \sqrt{\frac{1}{n}} + \sqrt{\frac{2}{n}} +...+ \sqrt{\frac{n-1}{n}} + \sqrt{\frac{n}{n}} \big)}}
 
\lim_{n \to \infty} \frac{\sum_{i=0}^{n}{\sqrt{i}}}{n^2} = 
\lim_{n \to \infty} \frac{{\sqrt{n} \big( \sqrt{\frac{1}{n}} + \sqrt{\frac{2}{n}} +...+ \sqrt{\frac{n-1}{n}} + \sqrt{\frac{n}{n}} \big)}}{n^2} \overbrace{<}^{(*)}
\lim_{n \to \infty} \frac{{\sqrt{n} \big( \sqrt{\frac{n}{n}} + \sqrt{\frac{n}{n}} +...+ \sqrt{\frac{n}{n}} + \sqrt{\frac{n}{n}} \big)}}{n^2} =
\lim_{n \to \infty} \frac{{\sqrt{n} \big( \overbrace{1 + 1 +...+ 1 + 1}^{n \, times} \big)}}{n^2} =
\lim_{n \to \infty} \frac{ \sqrt{n} *n }{n^2} =
\lim_{n \to \infty} \frac{ \sqrt{n} }{n} =
\lim_{n \to \infty} \frac{1}{ \sqrt{n} } = 0
 (*)","['limits', 'power-series']"
32,Solve $\lim_{x\to \pi/4} \frac{\sin x - \cos x}{x-\pi/4}$ [duplicate],Solve  [duplicate],\lim_{x\to \pi/4} \frac{\sin x - \cos x}{x-\pi/4},"This question already has answers here : Evaluate: $\lim_{\theta \to \frac {\pi}{4}}\frac {\cos \theta - \sin \theta}{\theta - \frac {\pi}{4}}$ (5 answers) Closed 2 years ago . As the title suggests, we have to solve the limit: $\lim_{x\to \frac\pi4} \frac{\sin x - \cos x}{x-\frac \pi4}$ I'm able to solve it by using L'Hospital's rule and got an answer $\sqrt2$ but the problem is that this rule is not allowed at school level. So I tried another method: $$\lim_{x\to \frac\pi4} \frac{\sin x - \cos x}{x-\frac \pi4}$$ $$\lim_{h\to 0} \frac{\sin(π/4+h) - \cos(π/4+h)}{h}$$ By using the identity of $\sin(a+b)$ and $\cos(a+b)$ , we get: $$\lim_{h\to 0} \frac{[\sin π/4+ \cos π/4][\cos h + \sin h]}{h}$$ If we here substitute $h=0$ , we get $√2/0$ . Can we solve it further? Please help! BTW sorry for the bad formatting.","This question already has answers here : Evaluate: $\lim_{\theta \to \frac {\pi}{4}}\frac {\cos \theta - \sin \theta}{\theta - \frac {\pi}{4}}$ (5 answers) Closed 2 years ago . As the title suggests, we have to solve the limit: I'm able to solve it by using L'Hospital's rule and got an answer but the problem is that this rule is not allowed at school level. So I tried another method: By using the identity of and , we get: If we here substitute , we get . Can we solve it further? Please help! BTW sorry for the bad formatting.",\lim_{x\to \frac\pi4} \frac{\sin x - \cos x}{x-\frac \pi4} \sqrt2 \lim_{x\to \frac\pi4} \frac{\sin x - \cos x}{x-\frac \pi4} \lim_{h\to 0} \frac{\sin(π/4+h) - \cos(π/4+h)}{h} \sin(a+b) \cos(a+b) \lim_{h\to 0} \frac{[\sin π/4+ \cos π/4][\cos h + \sin h]}{h} h=0 √2/0,['limits']
33,Doubt regarding splitting of the limit $ \lim\limits_{x \to 0} \dfrac{\sin^2(3x)}{x^2} $,Doubt regarding splitting of the limit, \lim\limits_{x \to 0} \dfrac{\sin^2(3x)}{x^2} ,"I have a simple question about the logic of the limits of trig functions. For example, let's say you have the following question: $ \lim\limits_{x \to 0} \dfrac{\sin^2(3x)}{x^2} $ What's preventing me from doing this: $ \lim\limits_{x \to 0} \sin(3x)\dfrac{\sin(3x)}{x^2} $ and then simplifying it to this: $ \lim\limits_{x \to 0} \sin(3x) \times  \lim\limits_{x \to 0} \dfrac{\sin(3x)}{x^2} $ and finally this: $0 \times \lim\limits_{x \to 0} \dfrac{\sin(3x)}{x^2}$ Thanks for the help.","I have a simple question about the logic of the limits of trig functions. For example, let's say you have the following question: What's preventing me from doing this: and then simplifying it to this: and finally this: Thanks for the help.", \lim\limits_{x \to 0} \dfrac{\sin^2(3x)}{x^2}   \lim\limits_{x \to 0} \sin(3x)\dfrac{\sin(3x)}{x^2}   \lim\limits_{x \to 0} \sin(3x) \times  \lim\limits_{x \to 0} \dfrac{\sin(3x)}{x^2}  0 \times \lim\limits_{x \to 0} \dfrac{\sin(3x)}{x^2},"['calculus', 'limits']"
34,Why is this limit $\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)$ not $0$?,Why is this limit  not ?,\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right) 0,I have this limit: $$ \lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right) $$ For me my initial answer would be zero as: $$ \lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)=\lim_{x\to \infty}x^2-\lim_{x\to \infty}x^2\cdot\lim_{x\to \infty}\cos\left(\frac{1}{x}\right) $$ Which is: $$ \infty-\infty\cdot1=0 $$ But after looking at wolfram alpha and doing a series expansion of $\cos(x)$ i see that the answer is in fact $1/2.$ Why is my original thinking incorrect?,I have this limit: For me my initial answer would be zero as: Which is: But after looking at wolfram alpha and doing a series expansion of i see that the answer is in fact Why is my original thinking incorrect?,"
\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)
 
\lim_{x\to \infty}x^2-x^2\cdot \cos\left(\frac{1}{x}\right)=\lim_{x\to \infty}x^2-\lim_{x\to \infty}x^2\cdot\lim_{x\to \infty}\cos\left(\frac{1}{x}\right)
 
\infty-\infty\cdot1=0
 \cos(x) 1/2.",['limits']
35,How can we know when the limit given result is wrong if we are trying to prove it by its definition?,How can we know when the limit given result is wrong if we are trying to prove it by its definition?,,"I am currently learning Real Analysis and we learned about the definition of a convergent limit and did some exercises to apply the definition in order to prove the limit's result (i.e: ""Use the definition of a limit to show $\lim_{x\rightarrow\infty}f(x)=L$ ) However, my concern is that what if the given result (i.e: $L$ ) is wrong? It looks to me that I can prove any limit converges to anything this way (I am not worried about this in an exam context or just, that is just some general thoughts). To examine this, I tried proving a wrong result myself, took this: Use the definition of a limit to show that $\lim_{n\rightarrow\infty}\frac{1}{n}=10$ I worked it out just like I did for the real result. Solution: Note: $n,n_0\neq 0$ Let $\epsilon>0$ be arbitrary. We search for $n_0 \in \mathbb{N}$ s.t. $n\geq n_o \Longrightarrow |\frac{1}{n}-10|<\epsilon$ $\frac{1-10n_0}{n_0}<\epsilon \iff n_0>\frac{1}{10+\epsilon}$ We can take, $n_0=\left \lfloor{\frac{1}{10+\epsilon}+1}\right \rfloor $ Done. Obviously, I don't think that I actually proved that this limit converges to $10$ , I just think I am missing something in terms of my understanding or the way this was presented to me was wrong which is why I am posting here.","I am currently learning Real Analysis and we learned about the definition of a convergent limit and did some exercises to apply the definition in order to prove the limit's result (i.e: ""Use the definition of a limit to show ) However, my concern is that what if the given result (i.e: ) is wrong? It looks to me that I can prove any limit converges to anything this way (I am not worried about this in an exam context or just, that is just some general thoughts). To examine this, I tried proving a wrong result myself, took this: Use the definition of a limit to show that I worked it out just like I did for the real result. Solution: Note: Let be arbitrary. We search for s.t. We can take, Done. Obviously, I don't think that I actually proved that this limit converges to , I just think I am missing something in terms of my understanding or the way this was presented to me was wrong which is why I am posting here.","\lim_{x\rightarrow\infty}f(x)=L L \lim_{n\rightarrow\infty}\frac{1}{n}=10 n,n_0\neq 0 \epsilon>0 n_0 \in \mathbb{N} n\geq n_o \Longrightarrow |\frac{1}{n}-10|<\epsilon \frac{1-10n_0}{n_0}<\epsilon \iff n_0>\frac{1}{10+\epsilon} n_0=\left \lfloor{\frac{1}{10+\epsilon}+1}\right \rfloor  10","['real-analysis', 'limits']"
36,nth time differentiability at a point if limit of nth derivative exists at that point,nth time differentiability at a point if limit of nth derivative exists at that point,,"Exercise: Let the function $f$ be defined and continuous in an open interval $A$ . Suppose that $c$ is a point in $A$ and that $f$ has derivatives up to order $m$ on the set $A \backslash\{c\}$ . Suppose further that $\lim\limits _{x \rightarrow c} f^{(k)}(x)$ exists for $k=1, \ldots, m$ and the limits are finite numbers. Show that $f$ has derivatives up to order $m$ in all of $A$ . Moreover $f^{(k)}(c)=\lim\limits _{x \rightarrow c} f^{(k)}(x)$ , for $k=1, \ldots, m$ I know proof of the case when $k=1$ . It has a lot of answers in this site, for example here for complete induction step I was suggested the following expression: $$ f^{(k)}(c)=\lim _{x \rightarrow c} \frac{f^{(k-1)}(x)-f^{(k-1)}(c)}{x-c}=\lim _{x \rightarrow c} \frac{\int_{c}^{x} f^{(k)}(t) d t}{x-c}=\lim _{x \rightarrow c} f^{(k)}(x)$$ but we haven't studied integral yet. Is there any technique to replace integral with that one?? Thank you in advance.","Exercise: Let the function be defined and continuous in an open interval . Suppose that is a point in and that has derivatives up to order on the set . Suppose further that exists for and the limits are finite numbers. Show that has derivatives up to order in all of . Moreover , for I know proof of the case when . It has a lot of answers in this site, for example here for complete induction step I was suggested the following expression: but we haven't studied integral yet. Is there any technique to replace integral with that one?? Thank you in advance.","f A c A f m A \backslash\{c\} \lim\limits _{x \rightarrow c} f^{(k)}(x) k=1, \ldots, m f m A f^{(k)}(c)=\lim\limits _{x \rightarrow c} f^{(k)}(x) k=1, \ldots, m k=1  f^{(k)}(c)=\lim _{x \rightarrow c} \frac{f^{(k-1)}(x)-f^{(k-1)}(c)}{x-c}=\lim _{x \rightarrow c} \frac{\int_{c}^{x} f^{(k)}(t) d t}{x-c}=\lim _{x \rightarrow c} f^{(k)}(x)","['real-analysis', 'calculus', 'limits', 'functions', 'derivatives']"
37,Proving every Cauchy sequence in $\mathbb{R}$ is convergent. Does the following proof work?,Proving every Cauchy sequence in  is convergent. Does the following proof work?,\mathbb{R},"I tried to prove this but my proof did not match with my book's. So I want to verify whether my proof is correct or not. Theorem: Every Cauchy sequence in $\mathbb R$ has a limit. Let us assume the contrary that there is a sequence $(a_n)$ which is Cauchy but not convergent. 1.Since the sequence is not convergent,for all real $a$ , there must be an $\epsilon$ such that for all $n \in \mathbb N$ , $\exists n_0 \geq n$ such that $|a_{n_0}-a|\geq \epsilon$ . 2.Since $(a_n)$ is Cauchy, we can show that that particular $\epsilon$ we talked above,there is a natural $N$ such that for all $n,m\geq N$ , $|a_n-a_m|<\epsilon$ . 3.Go and look $(1)$ . I can thus find $m_0 \geq N$ such that $|a_{m_0}-a| \geq \epsilon >|a_{m_0}-a_n|$ for all $n \geq N$ . Since $a$ is arbitrary, putting $a=a_n$ ,we get contradiction.Thus, the proof.","I tried to prove this but my proof did not match with my book's. So I want to verify whether my proof is correct or not. Theorem: Every Cauchy sequence in has a limit. Let us assume the contrary that there is a sequence which is Cauchy but not convergent. 1.Since the sequence is not convergent,for all real , there must be an such that for all , such that . 2.Since is Cauchy, we can show that that particular we talked above,there is a natural such that for all , . 3.Go and look . I can thus find such that for all . Since is arbitrary, putting ,we get contradiction.Thus, the proof.","\mathbb R (a_n) a \epsilon n \in \mathbb N \exists n_0 \geq n |a_{n_0}-a|\geq \epsilon (a_n) \epsilon N n,m\geq N |a_n-a_m|<\epsilon (1) m_0 \geq N |a_{m_0}-a| \geq \epsilon >|a_{m_0}-a_n| n \geq N a a=a_n","['real-analysis', 'limits']"
38,Calculating $\lim_{x \to 0} \frac{\sin(x^2)-\sin^2(x)}{x^2\ln(\cos x)}$ without L'Hospital's rule,Calculating  without L'Hospital's rule,\lim_{x \to 0} \frac{\sin(x^2)-\sin^2(x)}{x^2\ln(\cos x)},"this is my first post here so excuse the lack of knowledge about how things usually go. My question revolves around calculating the limit as $x$ approaches $0$ of the following function: $$\lim_{x \to 0} \frac{\sin(x^2)-\sin^2(x)}{x^2\ln(\cos x)}$$ The question came up in a test about a month ago and while I couldn't solve it in the test I've been working on it since then but I can't seem to get it. I know the limit is supposed to be $\frac{-2}{3}$ from some online calculators which abused l'hopital rule over and over again. I've tried playing around with it in so many ways but I always seem to get 0 over 0 or the so called indeterminate form. I've even tried calculating it by substituting in the Taylor series for the functions given but no luck. If anyone could show me a method of calculating this without using l'hopital rule or better yet, give me a hint as to how I should proceed I would be grateful.","this is my first post here so excuse the lack of knowledge about how things usually go. My question revolves around calculating the limit as approaches of the following function: The question came up in a test about a month ago and while I couldn't solve it in the test I've been working on it since then but I can't seem to get it. I know the limit is supposed to be from some online calculators which abused l'hopital rule over and over again. I've tried playing around with it in so many ways but I always seem to get 0 over 0 or the so called indeterminate form. I've even tried calculating it by substituting in the Taylor series for the functions given but no luck. If anyone could show me a method of calculating this without using l'hopital rule or better yet, give me a hint as to how I should proceed I would be grateful.",x 0 \lim_{x \to 0} \frac{\sin(x^2)-\sin^2(x)}{x^2\ln(\cos x)} \frac{-2}{3},"['calculus', 'limits', 'functions', 'limits-without-lhopital']"
39,Limit of the sequence $x_{n+1}=x_n(2-ax_n)$ For some real $a$ positive.,Limit of the sequence  For some real  positive.,x_{n+1}=x_n(2-ax_n) a,Find the limit of the following recurrence relation $$x_{n+1}=x_n(2-ax_n)$$ For some real $a$ positive. I don't know how to find a closed form of the given recurrence relation and since I don't have any initial value so I cannot check OEIS sequence for a possible solution.,Find the limit of the following recurrence relation For some real positive. I don't know how to find a closed form of the given recurrence relation and since I don't have any initial value so I cannot check OEIS sequence for a possible solution.,x_{n+1}=x_n(2-ax_n) a,"['calculus', 'sequences-and-series', 'limits', 'recurrence-relations']"
40,$f(ct)=cf(t)$ for all rational numbers $c$ and $f$ is continuous,for all rational numbers  and  is continuous,f(ct)=cf(t) c f,"Given that $f(ct)=cf(t)$ for all rational numbers $c$ and that $f$ is continuous, it must be that $f$ is a straight line. Can the same conclusion can be drawn if $f(2t)=2f(t)$ and $f$ is continuous, i.e. the statement holds only for $c=2$ ? Clearly it cannot if $f$ is not continuous, as you could set $f(0)=0, f(1)=1, f(2)=2, f(4)=4, f(8)=8$ , and then for another ""sequence"" of numbers, set $f(0)=0, f(3)=1, f(6)=2$ , and you would end up with many dots that lie on lines. But I was wondering if the assertion that $f$ is continuous forces $f$ to be a straight line even when the condition is reduced from all rational numbers $c$ to just one number.","Given that for all rational numbers and that is continuous, it must be that is a straight line. Can the same conclusion can be drawn if and is continuous, i.e. the statement holds only for ? Clearly it cannot if is not continuous, as you could set , and then for another ""sequence"" of numbers, set , and you would end up with many dots that lie on lines. But I was wondering if the assertion that is continuous forces to be a straight line even when the condition is reduced from all rational numbers to just one number.","f(ct)=cf(t) c f f f(2t)=2f(t) f c=2 f f(0)=0, f(1)=1, f(2)=2, f(4)=4, f(8)=8 f(0)=0, f(3)=1, f(6)=2 f f c","['real-analysis', 'sequences-and-series', 'limits', 'continuity']"
41,Find $\lim_{n\to\infty}2^nx_n$,Find,\lim_{n\to\infty}2^nx_n,"Find $\lim_{n\to\infty}2^nx_n$ where $$x_{n+1}=\frac{x_n}{1+\sqrt{x_n^2+1}},\forall n\in \mathbb{N}$$ given $x_1=\sqrt{3}$ I tried finding the first few terms which go as follows: $$\sqrt3,\frac{1}{\sqrt3},\frac{1}{2+\sqrt3},\cdots$$ This doesnt seem to follow a definite pattern, and Im not sure how to proceed. Any hint is appreciated!","Find where given I tried finding the first few terms which go as follows: This doesnt seem to follow a definite pattern, and Im not sure how to proceed. Any hint is appreciated!","\lim_{n\to\infty}2^nx_n x_{n+1}=\frac{x_n}{1+\sqrt{x_n^2+1}},\forall n\in \mathbb{N} x_1=\sqrt{3} \sqrt3,\frac{1}{\sqrt3},\frac{1}{2+\sqrt3},\cdots","['limits', 'recurrence-relations']"
42,Let $x_n$ be a bounded sequence. Show that $y_n = n(x_{n+1} - x_n)$ can't have limit $+ \infty$,Let  be a bounded sequence. Show that  can't have limit,x_n y_n = n(x_{n+1} - x_n) + \infty,"I have tried to solve this problem by supposing by contradiction that the limit was $ + \infty$ . Then, you'd have $\forall M > 0, \exists N \in \mathbb{N}: \forall n > N, n(x_{n+1} - x_n) > M$ . This would mean that $(x_n)$ is increasing after a certain order $N$ , which means that it must be convergent. I don't know how to continue past this point.","I have tried to solve this problem by supposing by contradiction that the limit was . Then, you'd have . This would mean that is increasing after a certain order , which means that it must be convergent. I don't know how to continue past this point."," + \infty \forall M > 0, \exists N \in \mathbb{N}: \forall n > N, n(x_{n+1} - x_n) > M (x_n) N","['real-analysis', 'sequences-and-series', 'limits']"
43,Compute $\lim_{n \rightarrow \infty} \left(1 + \frac{i}{n^2 + in}\right)^n$,Compute,\lim_{n \rightarrow \infty} \left(1 + \frac{i}{n^2 + in}\right)^n,"I have a feeling that $$\lim_{n \rightarrow \infty} \left( 1 + \frac{i}{n^2 + in}\right)^n = 1,$$ but I don't know how to justify it. If $i$ was a real number $r > 0$ , I know how to compute this: take logs and then solve $$\lim_{n \rightarrow \infty} n \ln \left( 1 + \frac{r}{n^2 + rn}\right)$$ which after applying L'Hopital's rule gives $0$ , and hence an original limit of $e^0 = 1$ . But since complex numbers are involved I'm don't even know if I'm allowed to apply the same logic. What theorems / results can be applied to efficiently solve the limit, now that complex numbers are involved?","I have a feeling that but I don't know how to justify it. If was a real number , I know how to compute this: take logs and then solve which after applying L'Hopital's rule gives , and hence an original limit of . But since complex numbers are involved I'm don't even know if I'm allowed to apply the same logic. What theorems / results can be applied to efficiently solve the limit, now that complex numbers are involved?","\lim_{n \rightarrow \infty} \left( 1 + \frac{i}{n^2 + in}\right)^n = 1, i r > 0 \lim_{n \rightarrow \infty} n \ln \left( 1 + \frac{r}{n^2 + rn}\right) 0 e^0 = 1","['limits', 'complex-numbers']"
44,Is this step mathematically allowed?,Is this step mathematically allowed?,,"In my signal and systems course, my professor claims that the energy of a signal $x(t)$ over an infinite and continuous time interval is: $$ E_{\infty}=\lim _{T \rightarrow \infty} \int_{-T}^{T}|x(t)|^{2} d t=\int_{-\infty}^{+\infty}|x(t)|^{2} d t $$ My concern is about the substitution of $\infty$ in place of $T$ before evaluating the integral. Is this always correct or is it mathematically more correct to evaluate the integral then compute the limit?","In my signal and systems course, my professor claims that the energy of a signal over an infinite and continuous time interval is: My concern is about the substitution of in place of before evaluating the integral. Is this always correct or is it mathematically more correct to evaluate the integral then compute the limit?","x(t) 
E_{\infty}=\lim _{T \rightarrow \infty} \int_{-T}^{T}|x(t)|^{2} d t=\int_{-\infty}^{+\infty}|x(t)|^{2} d t
 \infty T","['integration', 'limits']"
45,Cannot find limit using epsilon delta definition,Cannot find limit using epsilon delta definition,,"Prove $$\lim\limits_{x\to 2} x^3 = 8$$ using epsilon delta definition. I try as below. Let $\varepsilon>0$ . We choose $\delta>0$ . Consider that \begin{align} \vert x^3-8\vert &= \vert (x-2) (x^2+2x+4)\vert\\ &=\vert (x-2) \vert\vert(x^2+2x+4) \vert \\ &=\vert (x-2) \vert\vert(x-2)^2+6x \vert . \end{align} Now I don't know how to continue this answer. I confused with $6x$ . Anyone can help me? EDIT: I have tried as below as JC12's answer. Let $\vert x-2\vert <1$ , then $\vert x\vert -2< \vert x-2\vert <1$ then we have $$\vert x\vert -2<1 \iff \vert x\vert<3.$$ Now, $$ \vert(x-2)^2+6x \vert < \vert(3-2)^2+6\cdot 3 \vert =19. $$ Thus, \begin{align} \vert x^3-8\vert&= \vert (x-2)  \vert\vert(x-2)^2+6x \vert < 19 \vert (x-2) \vert. \end{align} Now choose $\delta=\min(1,\frac{\varepsilon}{19})$ . We have \begin{align} \vert x^3-8\vert < 19 \vert (x-2) \vert< 19  \frac{\varepsilon}{19} = \varepsilon. \end{align} So, we can conclude $\lim\limits_{x\to 2} x^3 =8$ .","Prove using epsilon delta definition. I try as below. Let . We choose . Consider that Now I don't know how to continue this answer. I confused with . Anyone can help me? EDIT: I have tried as below as JC12's answer. Let , then then we have Now, Thus, Now choose . We have So, we can conclude .","\lim\limits_{x\to 2} x^3 = 8 \varepsilon>0 \delta>0 \begin{align}
\vert x^3-8\vert &= \vert (x-2) (x^2+2x+4)\vert\\
&=\vert (x-2) \vert\vert(x^2+2x+4) \vert \\
&=\vert (x-2) \vert\vert(x-2)^2+6x \vert .
\end{align} 6x \vert x-2\vert <1 \vert x\vert -2< \vert x-2\vert <1 \vert x\vert -2<1 \iff \vert x\vert<3.  \vert(x-2)^2+6x \vert < \vert(3-2)^2+6\cdot 3 \vert =19.  \begin{align} \vert x^3-8\vert&= \vert (x-2)
 \vert\vert(x-2)^2+6x \vert < 19 \vert (x-2) \vert. \end{align} \delta=\min(1,\frac{\varepsilon}{19}) \begin{align} \vert x^3-8\vert < 19 \vert (x-2) \vert< 19
 \frac{\varepsilon}{19} = \varepsilon. \end{align} \lim\limits_{x\to 2} x^3 =8","['limits', 'epsilon-delta']"
46,"Find multivariable limit: as $(x,y) \to (0,0)$ of $ \frac {x\sin y-y\sin x} {x^2+y^2}$",Find multivariable limit: as  of,"(x,y) \to (0,0)  \frac {x\sin y-y\sin x} {x^2+y^2}","How do I evaluate the following limit? $$ \lim_{(x,y) \to (0,0)} \frac {x\sin y-y\sin x} {x^2+y^2}$$ So far I tested the limit along the paths in which $y=mx$ and I got zero. However I have no clue how I can prove the limit exists or find the limit's value.",How do I evaluate the following limit? So far I tested the limit along the paths in which and I got zero. However I have no clue how I can prove the limit exists or find the limit's value.," \lim_{(x,y) \to (0,0)} \frac {x\sin y-y\sin x} {x^2+y^2} y=mx","['calculus', 'limits', 'multivariable-calculus', 'limits-without-lhopital']"
47,Evaluate $\lim_{x\to+∞}\frac{(\sum_{n=0}^∞{(\frac{x^n}{n!})^2})^2}{(\sum_{n=0}^∞{(\frac{x^n}{n!})^1}) (\sum_{n=0}^∞{(\frac{x^n}{n!})^3})}$,Evaluate,\lim_{x\to+∞}\frac{(\sum_{n=0}^∞{(\frac{x^n}{n!})^2})^2}{(\sum_{n=0}^∞{(\frac{x^n}{n!})^1}) (\sum_{n=0}^∞{(\frac{x^n}{n!})^3})},"Prove the following limit: $$ \lim_{x\rightarrow +\infty} \frac{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^2} \right) ^2}{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^1} \right) \left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^3} \right)}=\frac{\sqrt{3}}{2} \tag{1} $$ Mathematica tells me that $$ \sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^2=I_0(2 x)\\ \sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^3 = \, _0F_2\left(;1,1;x^3\right) $$ but they don't make sense to me for calculating the limits, since I don't have any knowledge about Special Functions . How can I prove $(1)$ in an elementary way (not involving special functions)?","Prove the following limit: Mathematica tells me that but they don't make sense to me for calculating the limits, since I don't have any knowledge about Special Functions . How can I prove in an elementary way (not involving special functions)?","
\lim_{x\rightarrow +\infty} \frac{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^2} \right) ^2}{\left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^1} \right) \left( \sum_{n=0}^{\infty}{\left( \frac{x^n}{n!} \right) ^3} \right)}=\frac{\sqrt{3}}{2} \tag{1}
 
\sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^2=I_0(2 x)\\
\sum _{n=0}^{\infty } \left(\frac{x^n}{n!}\right)^3 = \, _0F_2\left(;1,1;x^3\right)
 (1)","['sequences-and-series', 'limits', 'analysis']"
48,Evaluate $\lim_{n\rightarrow \infty} \sqrt[n]{\frac{1^n+2^n+3^n+\cdots +n^n}{1+2!+3!+\cdots +n!}}$,Evaluate,\lim_{n\rightarrow \infty} \sqrt[n]{\frac{1^n+2^n+3^n+\cdots +n^n}{1+2!+3!+\cdots +n!}},"Evaluate the following limit: $$ \lim_{n\rightarrow \infty} \sqrt[n]{\frac{1^n+2^n+3^n+\cdots +n^n}{1+2!+3!+\cdots +n!}} $$ I tried to apply Stirling's approximation , but it seems that it doesn't work. Can anyone help?","Evaluate the following limit: I tried to apply Stirling's approximation , but it seems that it doesn't work. Can anyone help?","
\lim_{n\rightarrow \infty} \sqrt[n]{\frac{1^n+2^n+3^n+\cdots +n^n}{1+2!+3!+\cdots +n!}}
","['calculus', 'limits']"
49,Evaluating limits using a series,Evaluating limits using a series,,"I'm trying to use a Taylor series centered at $0$ to evaluate this limit: $$\lim_{x\to \infty}4x^3(e^\frac{-2}{x^3}-1)$$ I rewrote the function as its Maclaurin series: $$4x^3(e^\frac{-2}{x^3}-1)=\sum_{k=1}^\infty\frac{4x^{3-\frac{2k}{x^3}}}{{k!}}$$ In expanded form: $$\sum_{k=1}^\infty\frac{4x^{3-\frac{2k}{x^3}}}{{k!}}=4x^{3-\frac{2}{x^3}}+\frac{4x^{3-\frac{4}{x^3}}}{2!}+\frac{4x^{3-\frac{6}{x^3}}}{3!}+...$$ As $x$ goes to $\infty$ , $\frac{2}{x^3}$ goes to $0$ .  Thus, the limit of the first term is simply the limit of $4x^3$ , which is $\infty$ .  Based on this fact alone, I would assume, the limit of the entire series is $\infty$ , but apparently the answer is $-8$ .  What did I do wrong?","I'm trying to use a Taylor series centered at to evaluate this limit: I rewrote the function as its Maclaurin series: In expanded form: As goes to , goes to .  Thus, the limit of the first term is simply the limit of , which is .  Based on this fact alone, I would assume, the limit of the entire series is , but apparently the answer is .  What did I do wrong?",0 \lim_{x\to \infty}4x^3(e^\frac{-2}{x^3}-1) 4x^3(e^\frac{-2}{x^3}-1)=\sum_{k=1}^\infty\frac{4x^{3-\frac{2k}{x^3}}}{{k!}} \sum_{k=1}^\infty\frac{4x^{3-\frac{2k}{x^3}}}{{k!}}=4x^{3-\frac{2}{x^3}}+\frac{4x^{3-\frac{4}{x^3}}}{2!}+\frac{4x^{3-\frac{6}{x^3}}}{3!}+... x \infty \frac{2}{x^3} 0 4x^3 \infty \infty -8,"['calculus', 'sequences-and-series', 'limits', 'taylor-expansion']"
50,Is there any function such that $f(x)\to0$ as $x\to \infty$ but $x\log(x) f'(x)\to +\infty$?,Is there any function such that  as  but ?,f(x)\to0 x\to \infty x\log(x) f'(x)\to +\infty,"My question es exactly the one in the title. I am trying to find any smooth function $f\in C^\infty((1,\infty))$ such that $$ f(x)\xrightarrow{x\to+\infty}0 \qquad \hbox{but} \qquad x\log(x)f'(x)\xrightarrow{x\to+\infty}+\infty. $$ So far I've tried with $1/\log(x)$ and $1/\log(\log(x))$ , etc, with no success. Now I am wondering if that kind of function can actually exists. A priory looks like a quite reasonable requirement, but surprisingly I cannot find any such function.","My question es exactly the one in the title. I am trying to find any smooth function such that So far I've tried with and , etc, with no success. Now I am wondering if that kind of function can actually exists. A priory looks like a quite reasonable requirement, but surprisingly I cannot find any such function.","f\in C^\infty((1,\infty)) 
f(x)\xrightarrow{x\to+\infty}0 \qquad \hbox{but} \qquad x\log(x)f'(x)\xrightarrow{x\to+\infty}+\infty.
 1/\log(x) 1/\log(\log(x))","['real-analysis', 'calculus', 'limits']"
51,How to evaluate a limit here?,How to evaluate a limit here?,,"I have a certain limit to evaluate: $\lim_{x\to  0}\frac{4^x-1}{\ln{(7x+1)}}$ Here are the steps I've followed: suppose $4^x-1$ is t. This means that $t\to0$ . This also means that $x=\log_4(t+1)$ My limit is now: $\lim_{t\to  0}\frac{t}{\ln(7log_4(t+1) + 1)}$ Now $\ln(log_4(t+1) +1)$ is equal to $log_4(t+1)$ beacuse the $ln$ function is also $\to0$ This, i suppose, leaves us with the following limit: $\lim_{t\to  0}\frac{t}{7log_4(t+1)}$ At my last step I got really confused. Where else can we go from here? Every time I find myself with an indermediate form of [ $\frac{0}{0}$ ]. Thanks in advance for any help.","I have a certain limit to evaluate: Here are the steps I've followed: suppose is t. This means that . This also means that My limit is now: Now is equal to beacuse the function is also This, i suppose, leaves us with the following limit: At my last step I got really confused. Where else can we go from here? Every time I find myself with an indermediate form of [ ]. Thanks in advance for any help.",\lim_{x\to  0}\frac{4^x-1}{\ln{(7x+1)}} 4^x-1 t\to0 x=\log_4(t+1) \lim_{t\to  0}\frac{t}{\ln(7log_4(t+1) + 1)} \ln(log_4(t+1) +1) log_4(t+1) ln \to0 \lim_{t\to  0}\frac{t}{7log_4(t+1)} \frac{0}{0},"['real-analysis', 'limits']"
52,Solve $\lim_{x\rightarrow +\infty}\frac{1}{x}\log\left(\frac{x+1}{1+x^2}\right) = 0$ without L'Hôpital's rule,Solve  without L'Hôpital's rule,\lim_{x\rightarrow +\infty}\frac{1}{x}\log\left(\frac{x+1}{1+x^2}\right) = 0,How would you solve the limit $$\lim_{x\rightarrow +\infty}\frac{1}{x}\log\left(\frac{x+1}{1+x^2}\right) = 0$$ without using L'Hôpital's rule?,How would you solve the limit without using L'Hôpital's rule?,\lim_{x\rightarrow +\infty}\frac{1}{x}\log\left(\frac{x+1}{1+x^2}\right) = 0,"['limits', 'limits-without-lhopital']"
53,"Why does Stolz- Cesaro fail to evaluate the limit of $\dfrac{n + n^2 + n^3 + n^4 + \ldots + n^n}{1^n + 2^n + 3^n + 4^n + \ldots +n^n}$, [duplicate]","Why does Stolz- Cesaro fail to evaluate the limit of , [duplicate]",\dfrac{n + n^2 + n^3 + n^4 + \ldots + n^n}{1^n + 2^n + 3^n + 4^n + \ldots +n^n},"This question already has answers here : Evaluate $\lim\limits_{n\rightarrow \infty}\frac{n+n^2+n^3+\cdots +n^n}{1^n+2^n+3^n+\cdots +n^n}.$ (3 answers) Closed 4 years ago . I need to find the limit of the sequence $\dfrac{n + n^2 + n^3 + n^4  + \ldots + n^n}{1^n + 2^n + 3^n + 4^n + \ldots +n^n}$ , My strategy is to use Stolz's Cesaro theorem for this sequence. Now, the numerator is given by : $x_r = n^1+ n^2 +n^3 + \ldots +n^r$ , so $x_{n+1} - x_{n} = n^{n+1}$ Similarly for denominator $y_r = 1^n + 2^n + 3^n +\ldots +r^n$ , so $y_{n+1}- y_{n} = (n+1)^n$ Using Stolz Cesaro, this limit is equivalent to $\displaystyle \lim \dfrac{n^{n+1}}{(n + 1)^n}$ , which diverges to $ +\infty$ , However ans given to me is $\dfrac{e-1}{e}$ , Can anyone tell where is the error in my solution ? Thanks.","This question already has answers here : Evaluate $\lim\limits_{n\rightarrow \infty}\frac{n+n^2+n^3+\cdots +n^n}{1^n+2^n+3^n+\cdots +n^n}.$ (3 answers) Closed 4 years ago . I need to find the limit of the sequence , My strategy is to use Stolz's Cesaro theorem for this sequence. Now, the numerator is given by : , so Similarly for denominator , so Using Stolz Cesaro, this limit is equivalent to , which diverges to , However ans given to me is , Can anyone tell where is the error in my solution ? Thanks.",\dfrac{n + n^2 + n^3 + n^4  + \ldots + n^n}{1^n + 2^n + 3^n + 4^n + \ldots +n^n} x_r = n^1+ n^2 +n^3 + \ldots +n^r x_{n+1} - x_{n} = n^{n+1} y_r = 1^n + 2^n + 3^n +\ldots +r^n y_{n+1}- y_{n} = (n+1)^n \displaystyle \lim \dfrac{n^{n+1}}{(n + 1)^n}  +\infty \dfrac{e-1}{e},['real-analysis']
54,"Why does $f(x,y)= \frac{xy^2}{x^2+y^4}$ have different limits when approaching $(0,0)$ along straight lines vs. along the curve $(1/t^2,1/t)$?",Why does  have different limits when approaching  along straight lines vs. along the curve ?,"f(x,y)= \frac{xy^2}{x^2+y^4} (0,0) (1/t^2,1/t)","I have a stupid question about continuity in higher dimensions. There are maps, for example, $f(x,y)=\frac{xy^2}{x^2+y^4}$ , when $(x,y)\neq (0,0)$ and $f(x,y)=(0,0)$ when $(x,y)=(0,0)$ , when we approach $(0,0)$ along every straight line, the limit of the function is $0$ , but when along a curve, for example $(\frac{1}{t^2},\frac{1}{t})$ , the limit of $f$ is not $0$ . But, it feels like all the straight lines can cover a neighbourhood of $(0,0)$ , so every point on a curve is also on a different straight line. Why is it that when the same points are arranged in a different way the limit changes?","I have a stupid question about continuity in higher dimensions. There are maps, for example, , when and when , when we approach along every straight line, the limit of the function is , but when along a curve, for example , the limit of is not . But, it feels like all the straight lines can cover a neighbourhood of , so every point on a curve is also on a different straight line. Why is it that when the same points are arranged in a different way the limit changes?","f(x,y)=\frac{xy^2}{x^2+y^4} (x,y)\neq (0,0) f(x,y)=(0,0) (x,y)=(0,0) (0,0) 0 (\frac{1}{t^2},\frac{1}{t}) f 0 (0,0)","['calculus', 'limits']"
55,Find limit (Riemann sum),Find limit (Riemann sum),,"$\displaystyle a_n=\sum^{n^2}_{k=1}\sqrt{\frac{k^2-k}{n^8+k^2n^4-kn^4}}$ . I tried solving it by changing it a Riemann sum then integrating, however I couldn't manipulate the algebra to its form.",". I tried solving it by changing it a Riemann sum then integrating, however I couldn't manipulate the algebra to its form.",\displaystyle a_n=\sum^{n^2}_{k=1}\sqrt{\frac{k^2-k}{n^8+k^2n^4-kn^4}},"['calculus', 'integration', 'limits', 'riemann-sum']"
56,Limit of a integral $\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt$,Limit of a integral,\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt,Find the limit of $$\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt$$ . My idea to solve it is to use L'Hospital's rule but I am not sure why I can use it and how should i do it. Many thanks to them who are willing to help.,Find the limit of . My idea to solve it is to use L'Hospital's rule but I am not sure why I can use it and how should i do it. Many thanks to them who are willing to help.,\lim_{x\to 0+} \frac{1}{x^2} \int_{0}^{x} t^{1+t} dt,"['real-analysis', 'integration', 'limits']"
57,How do I determine $\lim_{x\to 1}(\sqrt[3]{x}-1)/(\sqrt{x}-1)$ without L'Hopital's Rule? [closed],How do I determine  without L'Hopital's Rule? [closed],\lim_{x\to 1}(\sqrt[3]{x}-1)/(\sqrt{x}-1),"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I need to determine the following limit: $$\lim_{x\to 1}\frac{\sqrt[3]{x}-1}{\sqrt{x}-1}$$ We haven't learned L'Hopital's Rule in class so I can't use it and I have tried substitution, factoring, and multiplying by conjugate but nothing seems to work. Is there a way this problem could be solved without the L'Hopital's Rule?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I need to determine the following limit: We haven't learned L'Hopital's Rule in class so I can't use it and I have tried substitution, factoring, and multiplying by conjugate but nothing seems to work. Is there a way this problem could be solved without the L'Hopital's Rule?",\lim_{x\to 1}\frac{\sqrt[3]{x}-1}{\sqrt{x}-1},['limits']
58,Lagrange theorem in a limit of a summation,Lagrange theorem in a limit of a summation,,"I need to evaluate $$\lim_{n\to +\infty} \frac{1}{\ln n} \sum_{k=1}^{n-1} \frac{1}{k}$$ The solution of this problem says that $$\ln n = \int_{1}^{n} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x$$ Then Lagrange's theorem is used to say that $$\sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \left[\color{red}{\frac{1}{k}-\frac{x-k}{\xi_k^2}}\right]\text{d}x$$ My problem is how the red part is obtained: I know that Lagrange theorem says, for the function $f(x)=\frac{1}{x}$ in the interval $[k,k+1]$ that exists $\xi_k\in(k,k+1)$ such that $$-\frac{1}{\xi_k^2}=\frac{\frac{1}{k+1}-\frac{1}{k}}{k+1-k}$$ I've done my calculations but I can't get the red part. Can someone explain me where it comes from? Thanks.","I need to evaluate The solution of this problem says that Then Lagrange's theorem is used to say that My problem is how the red part is obtained: I know that Lagrange theorem says, for the function in the interval that exists such that I've done my calculations but I can't get the red part. Can someone explain me where it comes from? Thanks.","\lim_{n\to +\infty} \frac{1}{\ln n} \sum_{k=1}^{n-1} \frac{1}{k} \ln n = \int_{1}^{n} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x \sum_{k=1}^{n-1} \int_{k}^{k+1} \frac{1}{x} \text{d}x=\sum_{k=1}^{n-1} \int_{k}^{k+1} \left[\color{red}{\frac{1}{k}-\frac{x-k}{\xi_k^2}}\right]\text{d}x f(x)=\frac{1}{x} [k,k+1] \xi_k\in(k,k+1) -\frac{1}{\xi_k^2}=\frac{\frac{1}{k+1}-\frac{1}{k}}{k+1-k}","['limits', 'analysis', 'definite-integrals', 'summation']"
59,How can I calculate this (rather tricky) limit?,How can I calculate this (rather tricky) limit?,,$$\lim\limits_{n \to \infty} \cos^{n^2} \left (\frac{2x}{n} \right)$$ Any hints and/or help is greatly appreciated.,Any hints and/or help is greatly appreciated.,\lim\limits_{n \to \infty} \cos^{n^2} \left (\frac{2x}{n} \right),"['calculus', 'limits']"
60,Why the following description implies the limit is finite?,Why the following description implies the limit is finite?,,"Let $f:[0,T]\rightarrow \mathbb{R}$ $$V(f) = \lim_{\|\Pi\|\rightarrow 0}\sum_{j=0}^{n-1}|f(t_{j+1})-f(t_j)|$$ where $\Pi$ is a partition of $[0,T]$ and define $\|\Pi\|$ as $$\Pi=\{t_0,t_1,\cdots,t_n\}, \ \ 0=t_0<t_1<\ldots<t_n=T, \ \ \|\Pi\|=\max_i(t_{i+1}-t_i)$$ Now the solution manual says that Suppose $V(f)$ is finite. Then for any $\epsilon>0$ , there exists an $N\geq 1$ , $$\sum_{j=0}^{n-1}|f(t_{j+1})-f(t_j)|<V(f) + \epsilon$$ for all $n\geq N$ . I am confused about the description of $+\epsilon$ and $\forall n \geq N$ parts. How do they and this description imply finite of $V(f)$ ? I believe this is a trick widely used in real analysis; however, cannot still understand this.","Let where is a partition of and define as Now the solution manual says that Suppose is finite. Then for any , there exists an , for all . I am confused about the description of and parts. How do they and this description imply finite of ? I believe this is a trick widely used in real analysis; however, cannot still understand this.","f:[0,T]\rightarrow \mathbb{R} V(f) = \lim_{\|\Pi\|\rightarrow 0}\sum_{j=0}^{n-1}|f(t_{j+1})-f(t_j)| \Pi [0,T] \|\Pi\| \Pi=\{t_0,t_1,\cdots,t_n\}, \ \ 0=t_0<t_1<\ldots<t_n=T, \ \ \|\Pi\|=\max_i(t_{i+1}-t_i) V(f) \epsilon>0 N\geq 1 \sum_{j=0}^{n-1}|f(t_{j+1})-f(t_j)|<V(f) + \epsilon n\geq N +\epsilon \forall n \geq N V(f)","['real-analysis', 'sequences-and-series', 'limits']"
61,Is there a way to tell if a limit is positive infinity or negative infinity without graphing?,Is there a way to tell if a limit is positive infinity or negative infinity without graphing?,,If I have such limit $\displaystyle\lim_{x \to -\infty} \frac{2x^2-4x}{x+1}$ to calculate. How can I know if the result if $-\infty$ or $\infty$ if I don't have a way to graph this function and I don't know how this graph looks like? Because the direct substitution will be like this: $\dfrac{2(-\infty)^2-4(-\infty)}{-\infty+1}$ I am always confused when calculating the limit when it is approaching $-\infty$ because it is not as easy as ones that approach $\infty$,If I have such limit to calculate. How can I know if the result if or if I don't have a way to graph this function and I don't know how this graph looks like? Because the direct substitution will be like this: I am always confused when calculating the limit when it is approaching because it is not as easy as ones that approach,\displaystyle\lim_{x \to -\infty} \frac{2x^2-4x}{x+1} -\infty \infty \dfrac{2(-\infty)^2-4(-\infty)}{-\infty+1} -\infty \infty,"['calculus', 'limits', 'differential']"
62,Evaluating limit of a function at $0$,Evaluating limit of a function at,0,"Yesterday my colleague asked me to find the limit of $$\lfloor\sin (x) \lfloor\cot (x )\rfloor  \rfloor$$ as $x$ approaches zero. It is easy to see that the function inside the outer brackets tends to 1  from the left when $x$ tends to $0$ from the right. Thus the right limit at zero would be $0$ . However, for the left limit, while the function inside the outer brackets approches 1, Wolfram alpha shows that the values of this function at any left  neighborhood of 0 may be less or greater than 1, implying that the  left limit at $0$ for the original function does not exist. How to show that  for negative values of $x$ close to $0$ , $\lfloor \sin (x ) \lfloor\cot (x )\rfloor \rfloor$ oscillates between two values $0$ and $1$ using only algebraic manipulations? We have to provide a sequence of negative numbers tending to $0$ for which the function tends to $1$ with values greater than 1, and another sequence for which the function approaches $1$ with values from the left. What are these two sequences?  Thank you.","Yesterday my colleague asked me to find the limit of as approaches zero. It is easy to see that the function inside the outer brackets tends to 1  from the left when tends to from the right. Thus the right limit at zero would be . However, for the left limit, while the function inside the outer brackets approches 1, Wolfram alpha shows that the values of this function at any left  neighborhood of 0 may be less or greater than 1, implying that the  left limit at for the original function does not exist. How to show that  for negative values of close to , oscillates between two values and using only algebraic manipulations? We have to provide a sequence of negative numbers tending to for which the function tends to with values greater than 1, and another sequence for which the function approaches with values from the left. What are these two sequences?  Thank you.",\lfloor\sin (x) \lfloor\cot (x )\rfloor  \rfloor x x 0 0 0 x 0 \lfloor \sin (x ) \lfloor\cot (x )\rfloor \rfloor 0 1 0 1 1,"['calculus', 'limits']"
63,Multivariate limit,Multivariate limit,,"I have troubles with such limit $$ \lim_{(x,y)\rightarrow(0,0)} \frac{x^3}{y^4+2\sin^2{x}}$$ Nothing works, as I approach on any line or curve I get limit equal to $0$ . I try polar coordinates - also nothing, still $0$ . I try to bound it somehow - I get infinity. However, wolfram tells that there is no limit for the function in $(0,0)$ . If I can get any hint, that would be great.","I have troubles with such limit Nothing works, as I approach on any line or curve I get limit equal to . I try polar coordinates - also nothing, still . I try to bound it somehow - I get infinity. However, wolfram tells that there is no limit for the function in . If I can get any hint, that would be great."," \lim_{(x,y)\rightarrow(0,0)} \frac{x^3}{y^4+2\sin^2{x}} 0 0 (0,0)","['limits', 'multivariable-calculus', 'trigonometry', 'multivalued-functions']"
64,$\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right)$,,\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right),"I'm having trouble with the following limit: $$\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right)$$ I'd be grateful for any help. I've tried to write that as $$\lim_{n\to \infty}\left(\frac {\ln(n^2) + \ln(1+\frac 1 n+\frac {100}{n^2})}{\ln(n^{100})+\ln(1+\frac {999n}{n^{100}}-\frac{1}{n^{100}})}\right)$$ Now we know that two of those limits are equal to $0$ , so that limit should be equal to $\lim_{n\to \infty}(\log_{n^{100}}n^2)= \frac{1}{50}$ ; But my question is: am I not making some mistakes here operating partly on limits and partly on values of those limits? Thank you!","I'm having trouble with the following limit: I'd be grateful for any help. I've tried to write that as Now we know that two of those limits are equal to , so that limit should be equal to ; But my question is: am I not making some mistakes here operating partly on limits and partly on values of those limits? Thank you!",\lim_{n \to \infty}\left(\frac {\ln(n^2+n+100)}{\ln(n^{100}+999n-1)}\right) \lim_{n\to \infty}\left(\frac {\ln(n^2) + \ln(1+\frac 1 n+\frac {100}{n^2})}{\ln(n^{100})+\ln(1+\frac {999n}{n^{100}}-\frac{1}{n^{100}})}\right) 0 \lim_{n\to \infty}(\log_{n^{100}}n^2)= \frac{1}{50},['limits']
65,Limit of $\frac{n!}{2^{(n^{2})}}$,Limit of,\frac{n!}{2^{(n^{2})}},"Find the following limit: $$\lim_{n\to\infty} \frac{n!}{2^{n^2}}$$ I get the feeling that this limit equals to zero. Intuitively, the function $f(n)=2^{n^2}$ grows much more faster than the factorial, however, I wish to prove this limit using only the squeeze theorem or some algebra. I noticed that: $$0\leq \frac{n!}{2^{n^2}}=\frac{n}{2^n} \cdot\frac{n-1}{2^n}\cdots \frac{2}{2^n}\cdot\frac{1}{2^n}$$ I tried to think about cases about wether $n$ is even or odd, hoping that would lead me to a way to simplify the latter expression, but it didn't work. Also, is there a way to generalize the problem? That is, does the limit $$\lim_{n\to\infty} \frac{n!}{a^{n^a}}$$ is always equal to zero, for $a\in\Bbb{N}$ ? Thanks in advance!","Find the following limit: I get the feeling that this limit equals to zero. Intuitively, the function grows much more faster than the factorial, however, I wish to prove this limit using only the squeeze theorem or some algebra. I noticed that: I tried to think about cases about wether is even or odd, hoping that would lead me to a way to simplify the latter expression, but it didn't work. Also, is there a way to generalize the problem? That is, does the limit is always equal to zero, for ? Thanks in advance!",\lim_{n\to\infty} \frac{n!}{2^{n^2}} f(n)=2^{n^2} 0\leq \frac{n!}{2^{n^2}}=\frac{n}{2^n} \cdot\frac{n-1}{2^n}\cdots \frac{2}{2^n}\cdot\frac{1}{2^n} n \lim_{n\to\infty} \frac{n!}{a^{n^a}} a\in\Bbb{N},"['limits', 'exponential-function', 'factorial']"
66,What is the limit of a function which is not defined everywhere?,What is the limit of a function which is not defined everywhere?,,"Let there be a function $f: \mathbb{Q} \to \mathbb{Q}$ , such that $f(x) = 1$ for all rational numbers $x$ . What's the limit of this function if $x$ tends to $0$ ? Does it exist and is $1$ ? Does it not exist? Is asking about the limit invalid here?","Let there be a function , such that for all rational numbers . What's the limit of this function if tends to ? Does it exist and is ? Does it not exist? Is asking about the limit invalid here?",f: \mathbb{Q} \to \mathbb{Q} f(x) = 1 x x 0 1,"['calculus', 'general-topology', 'limits']"
67,Limit of function $f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2}$,Limit of function,f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2},"I tried to calculate limit when $x$ goes to infinity for the following function $$f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2}$$ where $a$ , $b$ , $d$ are some positive constants. It's easy to see that terms before and after minus sign goes to infinity so that gives me indeterminate symbol. Is there some way to solve this problem?","I tried to calculate limit when goes to infinity for the following function where , , are some positive constants. It's easy to see that terms before and after minus sign goes to infinity so that gives me indeterminate symbol. Is there some way to solve this problem?",x f(x) = \sqrt{(xa + d)^2 + x^2 b^2} - \sqrt{(xa - d)^2 + x^2 b^2} a b d,"['real-analysis', 'calculus', 'limits']"
68,Is the graph of $f(x) = (x^2-4)/(x-2)$ the same as $f(x) = (x+2)$?,Is the graph of  the same as ?,f(x) = (x^2-4)/(x-2) f(x) = (x+2),"this might be a dumb question, but I was wondering what is the difference of graphs between $f(x) = (x^2-4)/(x-2)$ and $f(x) = (x+2)$ . I understand if we simply the $f(x) = (x^2-4)/(x-2)$ it will come down to $f(x) = (x+2)$ . But without simplifying it, they both behave differently at x = 2 and how would that impact their graph. I searched online, and all they would draw would be the same graph for both of them, but it doesn't feel right.","this might be a dumb question, but I was wondering what is the difference of graphs between and . I understand if we simply the it will come down to . But without simplifying it, they both behave differently at x = 2 and how would that impact their graph. I searched online, and all they would draw would be the same graph for both of them, but it doesn't feel right.",f(x) = (x^2-4)/(x-2) f(x) = (x+2) f(x) = (x^2-4)/(x-2) f(x) = (x+2),"['limits', 'functions']"
69,Show that $\lim_{x\to \frac{\pi}{2}} \frac{1}{\big(x-\frac{\pi}{2}\big)}+{\tan(x)}=0$.,Show that .,\lim_{x\to \frac{\pi}{2}} \frac{1}{\big(x-\frac{\pi}{2}\big)}+{\tan(x)}=0,Prove that $$\lim_{x\to \frac{\pi}{2}} \frac{1}{\big(x-\frac{\pi}{2}\big)}+{\tan(x)}=0.$$ I'm not really sure how to proceed. I know that I should not try L'Hôpital's rule (tried that) but not sure how I would incorporate into the Squeeze Theorem or how I would use continuity. Thanks! Edit: Turns out I was really dumb and you do use L'Hôpital's rule twice. I made the mistake of differentiating the whole quotient rather than the function on top and the bottom of the vinculum separately.,Prove that I'm not really sure how to proceed. I know that I should not try L'Hôpital's rule (tried that) but not sure how I would incorporate into the Squeeze Theorem or how I would use continuity. Thanks! Edit: Turns out I was really dumb and you do use L'Hôpital's rule twice. I made the mistake of differentiating the whole quotient rather than the function on top and the bottom of the vinculum separately.,\lim_{x\to \frac{\pi}{2}} \frac{1}{\big(x-\frac{\pi}{2}\big)}+{\tan(x)}=0.,"['limits', 'limits-without-lhopital']"
70,Is ${\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2}$ always true?,Is  always true?,{\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2},"Is ${\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2}$ always true? My math teachers were arguing today if the statement is always true. One teacher gave a counterexample of where $f(x) = \sqrt{x-1}$ . Eventually, they said that it came down to different textbook definitions of continuity and limits. Is there any other reasoning to prove this to be true or false?","Is always true? My math teachers were arguing today if the statement is always true. One teacher gave a counterexample of where . Eventually, they said that it came down to different textbook definitions of continuity and limits. Is there any other reasoning to prove this to be true or false?",{\lim\limits_{x \to 0}} \frac{f(x^2+1)}{x^2+2} = {\lim\limits_{t \to 1}} \frac{f(t)}{2} f(x) = \sqrt{x-1},"['calculus', 'limits', 'continuity']"
71,$(a_n) $ is a sequence of positive real numbers. The series $\sum a_n$ will converge if,is a sequence of positive real numbers. The series  will converge if,(a_n)  \sum a_n,"$(a_n) $ is a sequence of positive real numbers. The series $\sum a_n$ will converge if (a) $\sum a_n^2$ converges. (b) $\sum \frac{a_n}{2^n}$ converges (c) $\sum \frac{a_{n+1}}{a_n}$ coverges (d) $\sum \frac{a_n}{a_{n+1}}$ converges a) can't be true, counter example : $\sum\frac{1}{n^2}$ converges but not $\sum \frac1n$ b) can't be true, counter example : $\frac{n}{2^n}$ converges but not $\sum n$ I can't decide between c and d. I think c might be true by taking $a_n = \frac{1}{(2n)!}$ also I think taking $a_n = (2n)!$ will disprove d also. So is c the correct option?","is a sequence of positive real numbers. The series will converge if (a) converges. (b) converges (c) coverges (d) converges a) can't be true, counter example : converges but not b) can't be true, counter example : converges but not I can't decide between c and d. I think c might be true by taking also I think taking will disprove d also. So is c the correct option?",(a_n)  \sum a_n \sum a_n^2 \sum \frac{a_n}{2^n} \sum \frac{a_{n+1}}{a_n} \sum \frac{a_n}{a_{n+1}} \sum\frac{1}{n^2} \sum \frac1n \frac{n}{2^n} \sum n a_n = \frac{1}{(2n)!} a_n = (2n)!,"['sequences-and-series', 'limits', 'power-series', 'limits-without-lhopital']"
72,Multivariable Limit: how to prove it exists?,Multivariable Limit: how to prove it exists?,,"I've recently started Calculus II and I'm not being able to understand how to prove if a limit does exist, or not. Having $f(x,y) = \dfrac{x^2+y^2}{\ln(x^2+y^2)},$ if $x^2+y^2<1$ and $ (x,y)\neq  (0,0),$ and $f(x,y) = 0$ if $(x,y) = (0,0),$ how can I study the continuity of the function at the origin? I've already done this: 1) $\lim_{x\to 0} f(x,0)$ and 2) $\lim_{y\to 0} f(0,y)$ , and they are both equal. Then I've solved the following limits: $\lim_{x\to 0} f(x,mx)$ and $\lim_{x\to 0} f(x,kx^2)$ , and I think they are both 0; is this enough to prove the continuity of the function at (x,y) = (0,0)? And one more thing:  how can I prove if the limit exists by the definition? Thank you very much!","I've recently started Calculus II and I'm not being able to understand how to prove if a limit does exist, or not. Having if and and if how can I study the continuity of the function at the origin? I've already done this: 1) and 2) , and they are both equal. Then I've solved the following limits: and , and I think they are both 0; is this enough to prove the continuity of the function at (x,y) = (0,0)? And one more thing:  how can I prove if the limit exists by the definition? Thank you very much!","f(x,y) = \dfrac{x^2+y^2}{\ln(x^2+y^2)}, x^2+y^2<1  (x,y)\neq  (0,0), f(x,y) = 0 (x,y) = (0,0), \lim_{x\to 0} f(x,0) \lim_{y\to 0} f(0,y) \lim_{x\to 0} f(x,mx) \lim_{x\to 0} f(x,kx^2)","['calculus', 'limits', 'multivariable-calculus', 'continuity']"
73,Calculate $\lim\limits_{ x\to \infty} \frac{\ln(x)}{x^a}$ where $ a > 0 $ [duplicate],Calculate  where  [duplicate],\lim\limits_{ x\to \infty} \frac{\ln(x)}{x^a}  a > 0 ,This question already has answers here : How can I prove that $\log^k(n) = O(n^\epsilon)$? (5 answers) Evaluation $\lim_{n\to \infty}\frac{{\log^k n}}{n^{\epsilon}}$ (5 answers) Closed 5 years ago . I want to calculate $$\lim\limits_{  x\to \infty} \frac{\ln(x)}{x^a}$$ where $ a > 0 $ It looks simple because if $a>0$ then $ x^a $ it grows asymptotically faster than $ \ln(x) $ so $$\lim\limits_{  x\to  \infty} \frac{\ln(x)}{x^a} = 0$$ But I don't know how to formally justify that. I am thinking about something what I was doing in case of sequences: $$\frac{\ln(x+1)}{(x+1)^a} \cdot \frac{x^a}{\ln(x)} $$ But it have no sense because sequences was being considered in $\mathbb N$ but functions like that are considered in $\mathbb R$ I can't use there hospital's rule,This question already has answers here : How can I prove that $\log^k(n) = O(n^\epsilon)$? (5 answers) Evaluation $\lim_{n\to \infty}\frac{{\log^k n}}{n^{\epsilon}}$ (5 answers) Closed 5 years ago . I want to calculate where It looks simple because if then it grows asymptotically faster than so But I don't know how to formally justify that. I am thinking about something what I was doing in case of sequences: But it have no sense because sequences was being considered in but functions like that are considered in I can't use there hospital's rule,\lim\limits_{  x\to \infty} \frac{\ln(x)}{x^a}  a > 0  a>0  x^a   \ln(x)  \lim\limits_{  x\to  \infty} \frac{\ln(x)}{x^a} = 0 \frac{\ln(x+1)}{(x+1)^a} \cdot \frac{x^a}{\ln(x)}  \mathbb N \mathbb R,['real-analysis']
74,Compute the given limit as $x$ approaches $\infty$,Compute the given limit as  approaches,x \infty,"If $f(x) = 8x^3+3x$ then, $$\lim_{x \to \infty} \frac{f^{-1}(8x)-f^{-1}(x)}{x^{1/3}}$$ is? My attempt: It is clear that the function cannot be easily inverted. So, there must be something in the limit given itself that may simplify the problem. Honestly, I have no clue what to do here. There are a few things which I could see is that the function has only $1$ root(i.e $0$ ) and is bijective on $x \in \mathbb R$ . But that gave no benefit except showing that the inverse of the function exists. Any help would be appreciated.","If then, is? My attempt: It is clear that the function cannot be easily inverted. So, there must be something in the limit given itself that may simplify the problem. Honestly, I have no clue what to do here. There are a few things which I could see is that the function has only root(i.e ) and is bijective on . But that gave no benefit except showing that the inverse of the function exists. Any help would be appreciated.",f(x) = 8x^3+3x \lim_{x \to \infty} \frac{f^{-1}(8x)-f^{-1}(x)}{x^{1/3}} 1 0 x \in \mathbb R,"['limits', 'functions']"
75,Find $\lim_{n\to \infty}\sum_{k=1}^{n}(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)})$,Find,\lim_{n\to \infty}\sum_{k=1}^{n}(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)}),Find $\lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)}\right)$ $$\lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)}\right)$$ $$\lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}-\cos\frac{\pi}{2k}+\cos\frac{\pi}{2(k+2)}\right)$$ $$\lim_{n\to \infty}\sum_{k=1}^{n}\left(2\cos\frac{(\frac{\pi}{2k}+\frac{\pi}{2(k+2)})}{2}\sin\frac{(\frac{\pi}{2k}-\frac{\pi}{2(k+2)})}{2}+2\sin\frac{(\frac{\pi}{2k}+\frac{\pi}{2(k+2)})}{2}\sin\frac{(\frac{\pi}{2k}-\frac{\pi}{2(k+2)})}{2}\right)$$ I am stuck here.,Find I am stuck here.,\lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)}\right) \lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\cos\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}+\cos\frac{\pi}{2(k+2)}\right) \lim_{n\to \infty}\sum_{k=1}^{n}\left(\sin\frac{\pi}{2k}-\sin\frac{\pi}{2(k+2)}-\cos\frac{\pi}{2k}+\cos\frac{\pi}{2(k+2)}\right) \lim_{n\to \infty}\sum_{k=1}^{n}\left(2\cos\frac{(\frac{\pi}{2k}+\frac{\pi}{2(k+2)})}{2}\sin\frac{(\frac{\pi}{2k}-\frac{\pi}{2(k+2)})}{2}+2\sin\frac{(\frac{\pi}{2k}+\frac{\pi}{2(k+2)})}{2}\sin\frac{(\frac{\pi}{2k}-\frac{\pi}{2(k+2)})}{2}\right),"['limits', 'trigonometry', 'definite-integrals']"
76,When Should I Use Taylor Series for Limits?,When Should I Use Taylor Series for Limits?,,"I get confused between when to apply L'Hospital Rule and Taylor Series. Is there any set of trigger points in the questions, that would be easier to solve with Taylor Series? For Example, If the denominator is in terms of a large power of $x (>3)$ , then L'Hospital Rule usually becomes complicated and is not advised. Edit: Solve $\lim _{x\to 0}\left(\left(\sin x\right)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin x}\right)$ The options given are: $0, 1, -1, \infty$","I get confused between when to apply L'Hospital Rule and Taylor Series. Is there any set of trigger points in the questions, that would be easier to solve with Taylor Series? For Example, If the denominator is in terms of a large power of , then L'Hospital Rule usually becomes complicated and is not advised. Edit: Solve The options given are:","x (>3) \lim _{x\to 0}\left(\left(\sin x\right)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin x}\right) 0, 1, -1, \infty","['calculus', 'limits', 'taylor-expansion', 'limits-without-lhopital']"
77,"For what $p,q,r$ $\lim_{x \to 0} f(x)=\frac{p + q\cos x + r\sin x}{x^2}=1/2$?",For what  ?,"p,q,r \lim_{x \to 0} f(x)=\frac{p + q\cos x + r\sin x}{x^2}=1/2","Let $$f(x)=\frac{p + q\cos x + r\sin x}{x^2}$$ . Then for what values of $p$ , $q$ and $r$ is the limit $$\lim_{x \to 0} f(x)=1/2.$$ I’ve tried using L’Hospital’s rule but couldn’t get anywhere. Any help would be appreciated.","Let . Then for what values of , and is the limit I’ve tried using L’Hospital’s rule but couldn’t get anywhere. Any help would be appreciated.",f(x)=\frac{p + q\cos x + r\sin x}{x^2} p q r \lim_{x \to 0} f(x)=1/2.,"['real-analysis', 'sequences-and-series', 'limits']"
78,Finding $\lim\limits_{n→∞}n^3(\sqrt{n^2+\sqrt{n^4+1}}-n\sqrt2)$,Finding,\lim\limits_{n→∞}n^3(\sqrt{n^2+\sqrt{n^4+1}}-n\sqrt2),"What is $$\lim_{n→∞}n^3(\sqrt{n^2+\sqrt{n^4+1}}-n\sqrt2)?$$ So it is $$\lim_{n→∞}\frac{n^3(\sqrt{n^2+\sqrt{n^4+1}})^2-(n\sqrt{2})^2}{\sqrt{n^2+\sqrt{n^4+1}}+n\sqrt{2}}=\lim_{n→∞}\frac{n^3(n^2+\sqrt{n^4+1}-2n^2)}{\sqrt{n^2+\sqrt{n^4+1}}+n\sqrt{2}}.$$ I do not know what to do next, because my resuts is $∞$ but the answer from book is $\dfrac{1}{4\sqrt{2}}$ .","What is So it is I do not know what to do next, because my resuts is but the answer from book is .",\lim_{n→∞}n^3(\sqrt{n^2+\sqrt{n^4+1}}-n\sqrt2)? \lim_{n→∞}\frac{n^3(\sqrt{n^2+\sqrt{n^4+1}})^2-(n\sqrt{2})^2}{\sqrt{n^2+\sqrt{n^4+1}}+n\sqrt{2}}=\lim_{n→∞}\frac{n^3(n^2+\sqrt{n^4+1}-2n^2)}{\sqrt{n^2+\sqrt{n^4+1}}+n\sqrt{2}}. ∞ \dfrac{1}{4\sqrt{2}},"['calculus', 'limits']"
79,"Is it possible for the sequence $\{\frac{x_{n+1}}{x_n}\}$ to be unbounded but have $\lim_{n\to\infty} x_n = x$, $x_n \ne 0$","Is it possible for the sequence  to be unbounded but have ,",\{\frac{x_{n+1}}{x_n}\} \lim_{n\to\infty} x_n = x x_n \ne 0,"Given: $$ \begin{cases} \lim_{n\to\infty} x_n = x \\ x_n \ne 0 \\ n \in \mathbb N \end{cases} $$ Is it possible for $\{\frac{x_{n+1}}{x_n}\}$ to be and unbounded sequence? This problem comes in the context of two others which are: Does $\lim_{n\to\infty}\frac{x_{n+1}}{x_n}$ exist? Not necessarily if we for example consider: $$ x_n = \frac{sin{\pi n \over \sqrt2}}{n} $$ If the limit exists and is equal to $q$ , prove $|q| \le 1$ This one is also easy to show using the definition of a monotone sequence. The third part as of the question section asks whether $\{\frac{x_{n+1}}{x_n}\}$ may be unbounded, and the answer suggests that this is indeed possible, but I don't see how. What would be such a sequence?","Given: Is it possible for to be and unbounded sequence? This problem comes in the context of two others which are: Does exist? Not necessarily if we for example consider: If the limit exists and is equal to , prove This one is also easy to show using the definition of a monotone sequence. The third part as of the question section asks whether may be unbounded, and the answer suggests that this is indeed possible, but I don't see how. What would be such a sequence?","
\begin{cases}
\lim_{n\to\infty} x_n = x \\
x_n \ne 0 \\
n \in \mathbb N
\end{cases}
 \{\frac{x_{n+1}}{x_n}\} \lim_{n\to\infty}\frac{x_{n+1}}{x_n} 
x_n = \frac{sin{\pi n \over \sqrt2}}{n}
 q |q| \le 1 \{\frac{x_{n+1}}{x_n}\}","['calculus', 'sequences-and-series', 'limits', 'examples-counterexamples']"
80,"Can we say a function is ""unbounded"" when we mean it''s tending to infinity?","Can we say a function is ""unbounded"" when we mean it''s tending to infinity?",,"I'm watching the Limits series on Khan Academy. In many videos Sal repeatedly says that although some people say that functions that tend to infinity have a limit infinity. (For example, in this video, the says that the function $ y = \frac {2}{x-1} $ (here's a link to the graph ) is unbounded as x approaches 1 from the left side, although ""some"" people would say that the function is tending towards infinity (i.e., the $ \lim_{x \to c} f(x) = \infty $ . Over a series of videos, I caught hold of that argument and always said that function don't tend towards infinity; they're just unbounded. But, in a different video ( here ), Sal essentially says: $$ \lim_{x \to 0} \frac 1{x^2} = \infty $$ $$ \lim_{x \to 0^+} \frac 1{x} = \infty $$ $$ \lim_{x \to 0^-} \frac 1{x} = -\infty $$ There is an answer to this question that says that unbounded sequences don't always tend to infinity. So it seems that we can't say that the limit of unbounded functions as x tends to some number is infinity -- what I'm confused about, and my question is: When do we ever say that the limit of some function is infinity? Specifically, are the limits of the above functions $ \frac 1x $ and $$ \frac 1{x^2} $$ correct? Or are they unbounded? If we can say that these limits are correct, why can't we say this: $$ \lim_{x \to 1^-} \frac 2{x-1} = - \infty $$","I'm watching the Limits series on Khan Academy. In many videos Sal repeatedly says that although some people say that functions that tend to infinity have a limit infinity. (For example, in this video, the says that the function (here's a link to the graph ) is unbounded as x approaches 1 from the left side, although ""some"" people would say that the function is tending towards infinity (i.e., the . Over a series of videos, I caught hold of that argument and always said that function don't tend towards infinity; they're just unbounded. But, in a different video ( here ), Sal essentially says: There is an answer to this question that says that unbounded sequences don't always tend to infinity. So it seems that we can't say that the limit of unbounded functions as x tends to some number is infinity -- what I'm confused about, and my question is: When do we ever say that the limit of some function is infinity? Specifically, are the limits of the above functions and correct? Or are they unbounded? If we can say that these limits are correct, why can't we say this:", y = \frac {2}{x-1}   \lim_{x \to c} f(x) = \infty   \lim_{x \to 0} \frac 1{x^2} = \infty   \lim_{x \to 0^+} \frac 1{x} = \infty   \lim_{x \to 0^-} \frac 1{x} = -\infty   \frac 1x   \frac 1{x^2}   \lim_{x \to 1^-} \frac 2{x-1} = - \infty ,"['calculus', 'limits', 'functions', 'upper-lower-bounds']"
81,Find the sum: $\sum_{n=2}^\infty \frac{1}{n^2-1}$,Find the sum:,\sum_{n=2}^\infty \frac{1}{n^2-1},"Evaluate : $$\sum_{n=2}^\infty \frac{1}{n^2-1}$$ I've tried to rewrite the questions as $$\sum _{n=2}^{\infty \:\:}\left(-\frac{1}{2\left(n+1\right)}+\frac{1}{2\left(n-1\right)}\right)$$ but still couldnt't get any answer as when I substitute numbers $(n)$ into the $Sn \left(-\frac{1}{6}+\frac{1}{2}-\frac{1}{8}+\frac{1}{4}-\frac{1}{10}\right)$ , $Sn$ just keeps going on and on.  So how do I solve this problem and what does this series converge to?","Evaluate : I've tried to rewrite the questions as but still couldnt't get any answer as when I substitute numbers into the , just keeps going on and on.  So how do I solve this problem and what does this series converge to?",\sum_{n=2}^\infty \frac{1}{n^2-1} \sum _{n=2}^{\infty \:\:}\left(-\frac{1}{2\left(n+1\right)}+\frac{1}{2\left(n-1\right)}\right) (n) Sn \left(-\frac{1}{6}+\frac{1}{2}-\frac{1}{8}+\frac{1}{4}-\frac{1}{10}\right) Sn,"['sequences-and-series', 'limits', 'convergence-divergence']"
82,How to make this limit question a indeterminate form? (L-Hopital),How to make this limit question a indeterminate form? (L-Hopital),,"$$\lim_{x\to 1^+}[\ln(x^7 -1) - \ln(x^5 -1)]$$ This is a question from L-Hospital rule question set. My approach was to apply log property in this question and solve it, but $\ln(\frac{0}{0})$ might not be right way to convert it into indeterminate form. How to solve this question?","This is a question from L-Hospital rule question set. My approach was to apply log property in this question and solve it, but might not be right way to convert it into indeterminate form. How to solve this question?",\lim_{x\to 1^+}[\ln(x^7 -1) - \ln(x^5 -1)] \ln(\frac{0}{0}),['limits']
83,Prove convergence of sequence given by $a_{1}=1$ and $a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n}$,Prove convergence of sequence given by  and,a_{1}=1 a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n},For sequence given by $a_{1}=1$ and $a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n}$ I have to prove that it converges to some number and find this number. I tried toshow that it's monotonic by calculating $$ \frac{a_{n+1}}{a_{n}} = \frac{1}{a_{n}(a_1+a_2+\ldots+a_n)} $$ but I cannot say anything about the denominator. How can I try to find it's limit?,For sequence given by and I have to prove that it converges to some number and find this number. I tried toshow that it's monotonic by calculating but I cannot say anything about the denominator. How can I try to find it's limit?,"a_{1}=1 a_{n+1}= \frac{1}{a_1+a_2+\ldots+a_n} 
\frac{a_{n+1}}{a_{n}} = \frac{1}{a_{n}(a_1+a_2+\ldots+a_n)}
","['sequences-and-series', 'limits', 'convergence-divergence']"
84,"Find $a_1$ so that $ a_{n+1}=\frac{1}{4-3a_n}\ ,n\ge1 $ is convergent",Find  so that  is convergent,"a_1  a_{n+1}=\frac{1}{4-3a_n}\ ,n\ge1 ","Let $  \left\{ a_n \right\}  $ be a recursive sequence such that $$a_{n+1}=\frac{1}{4-3a_n}\quad,n\ge1  $$ Determine for which $a_1$ the sequence converges and in case of convergence find its limit. The problem is from the book 'Problems in Mathematical Analysis I by W.J.Kaczor'.",Let be a recursive sequence such that Determine for which the sequence converges and in case of convergence find its limit. The problem is from the book 'Problems in Mathematical Analysis I by W.J.Kaczor'.,"  \left\{ a_n \right\}   a_{n+1}=\frac{1}{4-3a_n}\quad,n\ge1   a_1","['real-analysis', 'sequences-and-series', 'limits']"
85,How does the concept of a derivative solve the problem of instantaneous velocity?,How does the concept of a derivative solve the problem of instantaneous velocity?,,"$$ \color{darkcyan}{\frac{dy}{dx}} = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$ $$ \color{darkcyan}{m} = \lim_{x \to a} \frac{f(x) - f(a)}{x-a} $$ Text source: https://i.sstatic.net/Kn3Bm.png I think I have a fairly solid understanding of the derivative, but I don't get how it helps us find instantaneous velocity at a point. It only gives us the velocity that we can get infinitely close to, but that's not the velocity at the point. The velocity at the point is undefined as x-x in the denominator = 0. I get the following about limits and derivatives: That the limit is an actual value, not an approximation. The limit is the actual value that we are getting infinitely closer to. That the derivative is the limit of the slope of x and a, as a is moved infinitely closer to a. It is the slope that is being approached, as a gets infinitely close to x. But while this lets us know what the velocity is between two points as they get infinitely close to each other, that still doesn't give the actual instantaneous velocity at that point, because to find the actual velocity at that single instant, you have to do f(x)-f(x)/x-x= 0/0 = undefined. So how does the concept of the derivative give us instantaneous velocity? How can this be explained without epsilon delta proofs, at the level of someone learning Khan Academy calculus?","$$ \color{darkcyan}{\frac{dy}{dx}} = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$ $$ \color{darkcyan}{m} = \lim_{x \to a} \frac{f(x) - f(a)}{x-a} $$ Text source: https://i.sstatic.net/Kn3Bm.png I think I have a fairly solid understanding of the derivative, but I don't get how it helps us find instantaneous velocity at a point. It only gives us the velocity that we can get infinitely close to, but that's not the velocity at the point. The velocity at the point is undefined as x-x in the denominator = 0. I get the following about limits and derivatives: That the limit is an actual value, not an approximation. The limit is the actual value that we are getting infinitely closer to. That the derivative is the limit of the slope of x and a, as a is moved infinitely closer to a. It is the slope that is being approached, as a gets infinitely close to x. But while this lets us know what the velocity is between two points as they get infinitely close to each other, that still doesn't give the actual instantaneous velocity at that point, because to find the actual velocity at that single instant, you have to do f(x)-f(x)/x-x= 0/0 = undefined. So how does the concept of the derivative give us instantaneous velocity? How can this be explained without epsilon delta proofs, at the level of someone learning Khan Academy calculus?",,"['calculus', 'limits', 'derivatives']"
86,How to calculate the limit $\lim_{x\to1}\lfloor\sin^{-1}(x)\rfloor$?,How to calculate the limit ?,\lim_{x\to1}\lfloor\sin^{-1}(x)\rfloor,"The question is about finding $$\lim_{x\to1} f(x)$$ where $$f(x) = \lfloor\sin^{-1}(x)\rfloor$$ The function takes the value $1$ at $x = 1$ but while approaching $1$ from the left side, it takes the value $0$ at all points. The function is not defined at $x>1$ so the right limit does not exist. The book mentions $1$ as the answer as $f(1)=1$ but i don't understand why. What is the meaning of a limit?","The question is about finding $$\lim_{x\to1} f(x)$$ where $$f(x) = \lfloor\sin^{-1}(x)\rfloor$$ The function takes the value $1$ at $x = 1$ but while approaching $1$ from the left side, it takes the value $0$ at all points. The function is not defined at $x>1$ so the right limit does not exist. The book mentions $1$ as the answer as $f(1)=1$ but i don't understand why. What is the meaning of a limit?",,"['calculus', 'limits', 'trigonometry', 'ceiling-and-floor-functions']"
87,Find $t$ such that $\lim_{n\to\infty} \frac {\sum_{r=1}^n r^4\cdot\sum_{r=1}^n r^5}{\sum_{r=1}^n r^t\cdot\sum_{r=1}^n r^{9-t}}=\frac 45$,Find  such that,t \lim_{n\to\infty} \frac {\sum_{r=1}^n r^4\cdot\sum_{r=1}^n r^5}{\sum_{r=1}^n r^t\cdot\sum_{r=1}^n r^{9-t}}=\frac 45,"Find $t$ such that $$\lim_{n\to\infty} \frac {\left(\sum_{r=1}^n r^4\right)\cdot\left(\sum_{r=1}^n r^5\right)}{\left(\sum_{r=1}^n r^t\right)\cdot\left(\sum_{r=1}^n r^{9-t}\right)}=\frac 45.$$ At first sight this question scared the hell out of me.  I tried using the general known formulas like $$\sum_{r=1}^n r^4=\frac {n(n+1)(2n+1)(3n^2+3n-1)}{6}$$ and $$\sum_{r=1}^n r^5=\frac {n^2(n+1)^2(2n^2+2n-1)}{12}.$$ But the denominator portion really doesn't go with it.  I tried to write it in form of integrals.  I also searched the internet for some information but it dealt higher level calculus relating the harmonic functions, Bernoulli numbers and the Riemann zeta function.  I read about it but couldn't get much out of it. Any help would be greatly appreciated. Thanks.","Find $t$ such that $$\lim_{n\to\infty} \frac {\left(\sum_{r=1}^n r^4\right)\cdot\left(\sum_{r=1}^n r^5\right)}{\left(\sum_{r=1}^n r^t\right)\cdot\left(\sum_{r=1}^n r^{9-t}\right)}=\frac 45.$$ At first sight this question scared the hell out of me.  I tried using the general known formulas like $$\sum_{r=1}^n r^4=\frac {n(n+1)(2n+1)(3n^2+3n-1)}{6}$$ and $$\sum_{r=1}^n r^5=\frac {n^2(n+1)^2(2n^2+2n-1)}{12}.$$ But the denominator portion really doesn't go with it.  I tried to write it in form of integrals.  I also searched the internet for some information but it dealt higher level calculus relating the harmonic functions, Bernoulli numbers and the Riemann zeta function.  I read about it but couldn't get much out of it. Any help would be greatly appreciated. Thanks.",,"['calculus', 'sequences-and-series', 'limits']"
88,Compute $\lim_{x\to 0^+}\int_{2x}^{3x}\frac{\sin(t)}{\sinh^2(t)}dt$.,Compute .,\lim_{x\to 0^+}\int_{2x}^{3x}\frac{\sin(t)}{\sinh^2(t)}dt,"How can I compute $$\lim_{x\to 0^+}\int_{2x}^{3x}\frac{\sin(t)}{\sinh^2(t)}dt \ \ ?$$ Suppose $x<\pi$. I tried using DCT since $$\left|\frac{\sin(t)}{\sinh^2(t)}\boldsymbol 1_{[2x,3x}(t)\right|\leq \frac{\sin(t)}{\sin^2(t)},$$ but the function on the RHS is not integrable... It should have a trick.","How can I compute $$\lim_{x\to 0^+}\int_{2x}^{3x}\frac{\sin(t)}{\sinh^2(t)}dt \ \ ?$$ Suppose $x<\pi$. I tried using DCT since $$\left|\frac{\sin(t)}{\sinh^2(t)}\boldsymbol 1_{[2x,3x}(t)\right|\leq \frac{\sin(t)}{\sin^2(t)},$$ but the function on the RHS is not integrable... It should have a trick.",,"['real-analysis', 'integration', 'limits']"
89,How do you evaluate limit of $\frac{\sqrt{1+x^2} - \sqrt {1+x}}{\sqrt {1+x^3} - \sqrt {{1+x}}}$ when $x$ tends to $0$?,How do you evaluate limit of  when  tends to ?,\frac{\sqrt{1+x^2} - \sqrt {1+x}}{\sqrt {1+x^3} - \sqrt {{1+x}}} x 0,I tried rationalization method and got as $\frac{x^2-x}{\sqrt {1+x^3} - \sqrt {1+x} ({\sqrt{1+x^2} + \sqrt {1+x}})}$. But i feel the denominator having power of 3 I may be doing it wrong.The answer should be 1. Please help.,I tried rationalization method and got as $\frac{x^2-x}{\sqrt {1+x^3} - \sqrt {1+x} ({\sqrt{1+x^2} + \sqrt {1+x}})}$. But i feel the denominator having power of 3 I may be doing it wrong.The answer should be 1. Please help.,,"['calculus', 'limits']"
90,Limit of composite functions,Limit of composite functions,,"Let $f$ and $g$ be some functions, assuming all right conditions that allow function composition, I want to prove that $$\lim_{x \to \infty} f(g(x))=f\left(\lim_{x \to \infty}g(x)\right) $$ As long as $\lim_{x \to \infty}g(x)$ exists and it's equal to, let's say, $L$ , and $f$ is continuous at $L$ . Basically these conditions must be sufficient to guarantee that $\lim_{x \to \infty} f(g(x))$ exists and it's equal to $f(L)$ . So my proof so far goes as follows: Let $\epsilon>0 $ , since $f$ is continuous at $L$ , then there exists $\delta$ such that $|f(y)-f(L)|<\epsilon$ provided that $|y-L|<\delta$ . Let $y=g(x)$ , then provided that $|g(x)-L|<\delta$ , it follows that $|f(g(x))-f(L)|<\varepsilon$ . But since $\lim_{x \to \infty}g(x)=L$ , for any $\delta>0$ there exists $N\in\Bbb{R}^+$ such that if $x>N$ then $|g(x)-L|<\delta$ . That is, for any $\epsilon>0$ , there exists $N\in\Bbb{R}^+$ such that if $x>N$ then it follows that $$|f(g(x))-f(L)|<\epsilon$$ Which proves that $\lim_{x \to \infty} f(g(x))$ exists and it's equal to $f(L)$ . It's very important to me that the proof includes the existence of this limit, since it has great computational value when calculating limits that look a bit ""messy"". I'd love some notes on the proof, anything that I might be stating wrong or unclear (writing this kind of proofs is not my forte). Thanks in advance!","Let and be some functions, assuming all right conditions that allow function composition, I want to prove that As long as exists and it's equal to, let's say, , and is continuous at . Basically these conditions must be sufficient to guarantee that exists and it's equal to . So my proof so far goes as follows: Let , since is continuous at , then there exists such that provided that . Let , then provided that , it follows that . But since , for any there exists such that if then . That is, for any , there exists such that if then it follows that Which proves that exists and it's equal to . It's very important to me that the proof includes the existence of this limit, since it has great computational value when calculating limits that look a bit ""messy"". I'd love some notes on the proof, anything that I might be stating wrong or unclear (writing this kind of proofs is not my forte). Thanks in advance!",f g \lim_{x \to \infty} f(g(x))=f\left(\lim_{x \to \infty}g(x)\right)  \lim_{x \to \infty}g(x) L f L \lim_{x \to \infty} f(g(x)) f(L) \epsilon>0  f L \delta |f(y)-f(L)|<\epsilon |y-L|<\delta y=g(x) |g(x)-L|<\delta |f(g(x))-f(L)|<\varepsilon \lim_{x \to \infty}g(x)=L \delta>0 N\in\Bbb{R}^+ x>N |g(x)-L|<\delta \epsilon>0 N\in\Bbb{R}^+ x>N |f(g(x))-f(L)|<\epsilon \lim_{x \to \infty} f(g(x)) f(L),"['limits', 'functions', 'proof-verification', 'function-and-relation-composition']"
91,How to evaluate the limit $\int_{0}^{\frac{\pi}{2}}Re^{-R\sin\theta}d\theta \quad (\text{as } R \rightarrow \infty)$,How to evaluate the limit,\int_{0}^{\frac{\pi}{2}}Re^{-R\sin\theta}d\theta \quad (\text{as } R \rightarrow \infty),"While doing a mathematical exercise(stein Complex Analysis chapter2,exercise 3), I managed to reduce the problem to the following one: $$\int_{0}^{\omega}Re^{-R\cos\theta}d\theta  \rightarrow 0  \quad  (\text{as } R \rightarrow \infty)$$ where $0\le \omega <\frac{\pi}{2}$ . I can prove this without much difficulty: $$\int_{0}^{\omega}Re^{-R\cos\theta}d\theta \le \int_{0}^{\omega}Re^{-R\cos\omega}d\theta =\omega Re^{-R\cos\omega}  \rightarrow 0  \quad  (\text{as } R \rightarrow \infty)$$ It is crucial that $\omega $ is strictly less than $\frac{\pi}{2}$ . This lead me to raise another interesting problem: what the limit will be if we replace $\omega$ by $\frac{\pi}{2}$ . After changing $\cos\theta$ to $\sin\theta$ (this doesn't matter), now my question is $$\int_{0}^{\frac{\pi}{2}}Re^{-R\sin\theta}d\theta  \rightarrow ?  \quad  (\text{as } R \rightarrow \infty)$$ I have no idea how to calculate, I even don't know if the limit exists.","While doing a mathematical exercise(stein Complex Analysis chapter2,exercise 3), I managed to reduce the problem to the following one: where . I can prove this without much difficulty: It is crucial that is strictly less than . This lead me to raise another interesting problem: what the limit will be if we replace by . After changing to (this doesn't matter), now my question is I have no idea how to calculate, I even don't know if the limit exists.",\int_{0}^{\omega}Re^{-R\cos\theta}d\theta  \rightarrow 0  \quad  (\text{as } R \rightarrow \infty) 0\le \omega <\frac{\pi}{2} \int_{0}^{\omega}Re^{-R\cos\theta}d\theta \le \int_{0}^{\omega}Re^{-R\cos\omega}d\theta =\omega Re^{-R\cos\omega}  \rightarrow 0  \quad  (\text{as } R \rightarrow \infty) \omega  \frac{\pi}{2} \omega \frac{\pi}{2} \cos\theta \sin\theta \int_{0}^{\frac{\pi}{2}}Re^{-R\sin\theta}d\theta  \rightarrow ?  \quad  (\text{as } R \rightarrow \infty),"['integration', 'limits', 'definite-integrals']"
92,Convergence of a sequence with two indexes,Convergence of a sequence with two indexes,,"Given a sequence $\{a_{n,p}\}$ with $(n,p)\in\Bbb{Z}×\Bbb{N}$. Suppose $\lim\limits_{p\to+\infty}a_{n,p}=a_n\neq 0$ for each $n\in\Bbb{Z}$, $\sum\limits_{n=-\infty}^{+\infty}|a_n|<+\infty$ and  $S=\sum\limits_{n=-\infty}^{+\infty}a_n$. Prove or disprove that: $$\lim_{p\to+\infty}\sum_{n=-p}^{p}a_{n,p}=S.$$ Any hints will welcome!!","Given a sequence $\{a_{n,p}\}$ with $(n,p)\in\Bbb{Z}×\Bbb{N}$. Suppose $\lim\limits_{p\to+\infty}a_{n,p}=a_n\neq 0$ for each $n\in\Bbb{Z}$, $\sum\limits_{n=-\infty}^{+\infty}|a_n|<+\infty$ and  $S=\sum\limits_{n=-\infty}^{+\infty}a_n$. Prove or disprove that: $$\lim_{p\to+\infty}\sum_{n=-p}^{p}a_{n,p}=S.$$ Any hints will welcome!!",,"['sequences-and-series', 'limits']"
93,Approximating the limit of a Cauchy sequence in a Banach space,Approximating the limit of a Cauchy sequence in a Banach space,,Let $E$ be a Banach space and consider a sequence $(x_n)_n$ in $E$ satisfying the following condition: $$||x_n-x_{n-1}||\leq 3^{-n}\mbox{ for all }n\in\mathbb{N}.$$ Clearly $(x_n)_n$ is a Cauchy sequence and therefore converges to an element $x\in E$ . Question: How to prove that $||x-x_n||\leq \frac{1}{2}3^{-n}$ for all $n\in\mathbb{N}$ ?,Let be a Banach space and consider a sequence in satisfying the following condition: Clearly is a Cauchy sequence and therefore converges to an element . Question: How to prove that for all ?,E (x_n)_n E ||x_n-x_{n-1}||\leq 3^{-n}\mbox{ for all }n\in\mathbb{N}. (x_n)_n x\in E ||x-x_n||\leq \frac{1}{2}3^{-n} n\in\mathbb{N},"['real-analysis', 'calculus', 'limits', 'banach-spaces', 'cauchy-sequences']"
94,Evaluate $\lim_{h\to 0}\frac{1}{h^3e^{\frac{1}{\sqrt{h^2}}}}$,Evaluate,\lim_{h\to 0}\frac{1}{h^3e^{\frac{1}{\sqrt{h^2}}}},"Background: I need to find if \begin{cases} \frac{1}{x^2+y^2+z^2}e^{-\frac{1}{\sqrt{x^2+y^2+z^2}}}, \text{     }(x,y,z)\neq (0,0,0)\\ 0,\text{     } (x,y,z)=(0,0,0) \end{cases} Differentiable at $(0,0)$ So I found that the function is continues at (0,0,0) and now I am checking if there are partial derivatives a. why we must derive by definition? So I derived by definition and got $$\lim_{h\to 0}\frac{1}{h^3e^{\frac{1}{\sqrt{h^2}}}}$$ I would use substitution to get to an expression of the form $\frac{t^3}{e^t}$ but I have even and odd powers","Background: I need to find if \begin{cases} \frac{1}{x^2+y^2+z^2}e^{-\frac{1}{\sqrt{x^2+y^2+z^2}}}, \text{     }(x,y,z)\neq (0,0,0)\\ 0,\text{     } (x,y,z)=(0,0,0) \end{cases} Differentiable at $(0,0)$ So I found that the function is continues at (0,0,0) and now I am checking if there are partial derivatives a. why we must derive by definition? So I derived by definition and got $$\lim_{h\to 0}\frac{1}{h^3e^{\frac{1}{\sqrt{h^2}}}}$$ I would use substitution to get to an expression of the form $\frac{t^3}{e^t}$ but I have even and odd powers",,"['real-analysis', 'limits', 'multivariable-calculus']"
95,Is this true: $\lim_{x\to 0} \frac{1-(\cos x)^n}{x^2}=\frac n2$,Is this true:,\lim_{x\to 0} \frac{1-(\cos x)^n}{x^2}=\frac n2,"Does this statement hold $\forall n\in \Bbb R$? $$\lim_{x\to 0} \frac{1-(\cos x)^n}{x^2}=\frac n2$$ I know that it holds for $\forall n \in \Bbb N$, because $1-(\cos x)^n=(1-\cos x)(1+ \cos x + ... + (\cos x)^{n-1})$, and $\lim_{x\to 0} (1+ \cos x + ... + (\cos x)^{n-1})=(1+1+...+1)=n$, but does that stand for, for example, $n=\sqrt2$? If it does, how do I prove it?","Does this statement hold $\forall n\in \Bbb R$? $$\lim_{x\to 0} \frac{1-(\cos x)^n}{x^2}=\frac n2$$ I know that it holds for $\forall n \in \Bbb N$, because $1-(\cos x)^n=(1-\cos x)(1+ \cos x + ... + (\cos x)^{n-1})$, and $\lim_{x\to 0} (1+ \cos x + ... + (\cos x)^{n-1})=(1+1+...+1)=n$, but does that stand for, for example, $n=\sqrt2$? If it does, how do I prove it?",,"['calculus', 'real-analysis', 'limits', 'limits-without-lhopital']"
96,How to find the limit:$\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right)$,How to find the limit:,\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right),How to find the limit:$$\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right)$$ I can't think of any way of this problem Can someone to evaluate this? Thank you.,How to find the limit:$$\lim_{n\to \infty}\left(\sum_{k=n+1}^{2n}\left(2(2k)^{\frac{1}{2k}}-k^{\frac{1}{k}}\right)-n\right)$$ I can't think of any way of this problem Can someone to evaluate this? Thank you.,,"['calculus', 'analysis', 'limits', 'summation']"
97,Trigonometric limit mistake,Trigonometric limit mistake,,"Question: $$\lim_{x\to 0}\frac{\tan x-\sin x}{x^3}$$ The answer, by L'Hopital's rule as well as wolfram and desmos is $\frac{1}{2}$ Here's what I did: $$\lim_{x\to0}({\tan x \over x}\times{1\over x^2}-{\sin x \over x}\times{1\over x^2})$$ $$\lim_{x\to0}({1 \over x^2}-{1 \over x^2})=0$$ Im not sure where the mistake is.","Question: $$\lim_{x\to 0}\frac{\tan x-\sin x}{x^3}$$ The answer, by L'Hopital's rule as well as wolfram and desmos is $\frac{1}{2}$ Here's what I did: $$\lim_{x\to0}({\tan x \over x}\times{1\over x^2}-{\sin x \over x}\times{1\over x^2})$$ $$\lim_{x\to0}({1 \over x^2}-{1 \over x^2})=0$$ Im not sure where the mistake is.",,"['limits', 'limits-without-lhopital']"
98,Which of these $\varepsilon$-$\delta$ limits definitions are right,Which of these - limits definitions are right,\varepsilon \delta,"hello I've been trying to understand how $\varepsilon$-$\delta$ definition is used to demonstrate limits, but i don't get it yet. In the book [Ron Larson, Bruce H. Edwards-Calculus_ Early Transcendental Functions-Brooks Cole (2014)] says the following: So I've develop mi own, and i don't know if the are right, and that's why i need your help, so here we go: $\displaystyle{\lim_{ x \rightarrow 2}}\;(3x-2)=4$ Let $\varepsilon>0$ and $\delta>0$, then $0<|x-2|< \delta \implies |3x-2-4|<\varepsilon$ Find a value for $\delta$: $|3x-2-4|<\varepsilon$ $\implies -\varepsilon<3x-2-4<\varepsilon$ $\implies -\varepsilon<3x-6<\varepsilon$ $\implies -\varepsilon<3(x-2)<\varepsilon$ $\implies -\dfrac{\varepsilon}{3}<x-2<\dfrac{\varepsilon}{3}$ $\implies |x-2|<\dfrac{\varepsilon}{3}$ Choose $\delta=\dfrac{\varepsilon}{3},$  proove that $\delta$ works: $|x-2|<\dfrac{\varepsilon}{3}$ $\implies -\dfrac{\varepsilon}{3}<x-2<\dfrac{\varepsilon}{3}$ $\implies -\varepsilon<3(x-2)<\varepsilon$ $\implies -\varepsilon<3x-6<\varepsilon$ $\implies -\varepsilon<3x-2-4<\varepsilon$ $\implies |3x-2-4|<\varepsilon$ I think in the book what they are trying to say is that: If $|x-2|<\dfrac{\varepsilon}{3}$, then $0<|3x-2-4|<\delta$ $0<|3x-6|<\delta$ $0<|3(x-2)|<\delta$ $0<3|x-2|<\delta$ $0<3\dfrac{\varepsilon}{3}<\delta$ $0<\varepsilon<\delta$","hello I've been trying to understand how $\varepsilon$-$\delta$ definition is used to demonstrate limits, but i don't get it yet. In the book [Ron Larson, Bruce H. Edwards-Calculus_ Early Transcendental Functions-Brooks Cole (2014)] says the following: So I've develop mi own, and i don't know if the are right, and that's why i need your help, so here we go: $\displaystyle{\lim_{ x \rightarrow 2}}\;(3x-2)=4$ Let $\varepsilon>0$ and $\delta>0$, then $0<|x-2|< \delta \implies |3x-2-4|<\varepsilon$ Find a value for $\delta$: $|3x-2-4|<\varepsilon$ $\implies -\varepsilon<3x-2-4<\varepsilon$ $\implies -\varepsilon<3x-6<\varepsilon$ $\implies -\varepsilon<3(x-2)<\varepsilon$ $\implies -\dfrac{\varepsilon}{3}<x-2<\dfrac{\varepsilon}{3}$ $\implies |x-2|<\dfrac{\varepsilon}{3}$ Choose $\delta=\dfrac{\varepsilon}{3},$  proove that $\delta$ works: $|x-2|<\dfrac{\varepsilon}{3}$ $\implies -\dfrac{\varepsilon}{3}<x-2<\dfrac{\varepsilon}{3}$ $\implies -\varepsilon<3(x-2)<\varepsilon$ $\implies -\varepsilon<3x-6<\varepsilon$ $\implies -\varepsilon<3x-2-4<\varepsilon$ $\implies |3x-2-4|<\varepsilon$ I think in the book what they are trying to say is that: If $|x-2|<\dfrac{\varepsilon}{3}$, then $0<|3x-2-4|<\delta$ $0<|3x-6|<\delta$ $0<|3(x-2)|<\delta$ $0<3|x-2|<\delta$ $0<3\dfrac{\varepsilon}{3}<\delta$ $0<\varepsilon<\delta$",,"['calculus', 'limits', 'proof-verification', 'definition', 'epsilon-delta']"
99,Evaluation of given limit where $n \to \infty$,Evaluation of given limit where,n \to \infty,"If $a_1=1$ and $a_n=n(1+a_{n-1})$ $\forall n\geq 2$, then evaluate the given limit. $$\lim_{n\to \infty} \bigg(1+\frac{1}{a_1}\bigg)+\bigg(1+\frac{1}{a_2}\bigg)+\cdots+\bigg(1+\frac{1}{a_n}\bigg)$$ Usually such type of questions are solved by squeeze theorem or by converting them into definite integral but don't see neither working here. Could someone give me little help to proceed","If $a_1=1$ and $a_n=n(1+a_{n-1})$ $\forall n\geq 2$, then evaluate the given limit. $$\lim_{n\to \infty} \bigg(1+\frac{1}{a_1}\bigg)+\bigg(1+\frac{1}{a_2}\bigg)+\cdots+\bigg(1+\frac{1}{a_n}\bigg)$$ Usually such type of questions are solved by squeeze theorem or by converting them into definite integral but don't see neither working here. Could someone give me little help to proceed",,"['calculus', 'sequences-and-series', 'limits']"
