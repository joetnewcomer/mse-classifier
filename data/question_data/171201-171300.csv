,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Understanding one step in the Neyman-Pearson lemma proof,Understanding one step in the Neyman-Pearson lemma proof,,"In Georgii's book they state: Given $(\chi,\mathcal{F},P_0,P_1)$ with simple hypothesis and alternative and $0<\alpha<1\ $ a given significance level. Then: $(a)$ There exists a Neyman-Pearson-test $\phi$ with $E_0(\phi)=\alpha$ . They begin the proof like this: Let $c$ be any $\alpha$ -fractil ( $1-\alpha$ quantil) of $P_0\circ R^{-1}$ where $R$ is the likelihood-quotient. By definition we have: $$P_0(R>c)\leq \alpha \quad P_0(R\geq c)\geq \alpha$$ Exactly this is the part I don't get. How come we have $P_0(R\geq c)\geq \alpha$ ? $P_0(R>c)\leq \alpha$ is exactly by definition of the $1-\alpha$ -quantil but how come taking one more point into consideration we have that it becomes greater than $\alpha$ . Could anyone explain to me how that is derived?",In Georgii's book they state: Given with simple hypothesis and alternative and a given significance level. Then: There exists a Neyman-Pearson-test with . They begin the proof like this: Let be any -fractil ( quantil) of where is the likelihood-quotient. By definition we have: Exactly this is the part I don't get. How come we have ? is exactly by definition of the -quantil but how come taking one more point into consideration we have that it becomes greater than . Could anyone explain to me how that is derived?,"(\chi,\mathcal{F},P_0,P_1) 0<\alpha<1\  (a) \phi E_0(\phi)=\alpha c \alpha 1-\alpha P_0\circ R^{-1} R P_0(R>c)\leq \alpha \quad P_0(R\geq c)\geq \alpha P_0(R\geq c)\geq \alpha P_0(R>c)\leq \alpha 1-\alpha \alpha","['statistics', 'hypothesis-testing']"
1,Understanding exact tests for clinical trial data,Understanding exact tests for clinical trial data,,"A clinical trial is done with 400 persons suffering from a particular disease, to find out whether a treatment is better than placebo. They are randomised to receive treatment or placebo (200 participants each). The outcome studied is how many get cured. The results are shown in the following 2x2 table: \begin{array} {|r|r|} \hline \text{ } & \text{Treatment group} & \text{Placebo group}\\ \hline \text{Cured} & 172 & 151 \\ \hline \text{Not cured} & 28 & 49 \\ \hline \text{Total} & 200 & 200 \\ \hline \end{array} The odds ratio calculated from this table is $1.99$ . The objective now is to test the null hypothesis (odds ratio = 1) against the alternate hypothesis (odds ratio is not 1). Ludbrook's 2008 article describes an exact test for this scenario: The formula for executing a two-sided randomization test, adapted to a 2x2 table with the constraint that the column totals are fixed ( single conditioning ), is: P=(All tables for which the summary statistic is at least as extreme as that observed, in either direction)/All possible tables with the same column totals I am a bit confused about what exactly it means. Does it mean I should form all possible tables with 200 treatment and 200 control participants, with each participant having a 50% chance of getting cured? Then there would be $2^{200} \times 2^{200}=2^{400}$ possible tables, each being equally likely. I would then calculate what fraction of these tables give an odds ratio equally or more extreme than the one I got experimentally, i.e. $1.99$ . This would give me the p-value. Is this the correct interpretation? If not, why? If so, why the assumption of 50% cure rate? Why not 20%, 70%, 90%, or any other number? (I would have contacted the author directly, but it turns out he is deceased. That is why I asked this question here.) Reference John Ludbrook, Analysis of 2 × 2 tables of frequencies: matching test to experimental design, International Journal of Epidemiology, Volume 37, Issue 6, December 2008, Pages 1430–1435, https://doi.org/10.1093/ije/dyn162","A clinical trial is done with 400 persons suffering from a particular disease, to find out whether a treatment is better than placebo. They are randomised to receive treatment or placebo (200 participants each). The outcome studied is how many get cured. The results are shown in the following 2x2 table: The odds ratio calculated from this table is . The objective now is to test the null hypothesis (odds ratio = 1) against the alternate hypothesis (odds ratio is not 1). Ludbrook's 2008 article describes an exact test for this scenario: The formula for executing a two-sided randomization test, adapted to a 2x2 table with the constraint that the column totals are fixed ( single conditioning ), is: P=(All tables for which the summary statistic is at least as extreme as that observed, in either direction)/All possible tables with the same column totals I am a bit confused about what exactly it means. Does it mean I should form all possible tables with 200 treatment and 200 control participants, with each participant having a 50% chance of getting cured? Then there would be possible tables, each being equally likely. I would then calculate what fraction of these tables give an odds ratio equally or more extreme than the one I got experimentally, i.e. . This would give me the p-value. Is this the correct interpretation? If not, why? If so, why the assumption of 50% cure rate? Why not 20%, 70%, 90%, or any other number? (I would have contacted the author directly, but it turns out he is deceased. That is why I asked this question here.) Reference John Ludbrook, Analysis of 2 × 2 tables of frequencies: matching test to experimental design, International Journal of Epidemiology, Volume 37, Issue 6, December 2008, Pages 1430–1435, https://doi.org/10.1093/ije/dyn162","\begin{array} {|r|r|}
\hline
\text{ } & \text{Treatment group} & \text{Placebo group}\\
\hline
\text{Cured} & 172 & 151 \\
\hline
\text{Not cured} & 28 & 49
\\
\hline
\text{Total} & 200 & 200
\\
\hline
\end{array} 1.99 2^{200} \times 2^{200}=2^{400} 1.99","['statistics', 'statistical-inference', 'hypothesis-testing', 'p-value']"
2,Probability cumulative sum of dice is n,Probability cumulative sum of dice is n,,"The following is intuitive: if $p(n)$ is the probability of ""rolling $n$ as the cumulative sum of arbitrarily many fair dice"" then $p(n)\approx p(m)$ for $m$ and $n$ sufficiently large. This is proven in an answer here but I have a few questions: What exactly has been proven? In other words, how can I formulate this probability more precisely? How can we see that the above claim is true without explicitly computing the distribution? It seems like this should follow from some sort of law of large numbers or result about the limiting distribution of the sum of i.i.d. random variables, but I can't see it. Is there a way to see easily, i.e. without too much computation, that the limiting probability has to be the inverse of the expectation of one roll?","The following is intuitive: if is the probability of ""rolling as the cumulative sum of arbitrarily many fair dice"" then for and sufficiently large. This is proven in an answer here but I have a few questions: What exactly has been proven? In other words, how can I formulate this probability more precisely? How can we see that the above claim is true without explicitly computing the distribution? It seems like this should follow from some sort of law of large numbers or result about the limiting distribution of the sum of i.i.d. random variables, but I can't see it. Is there a way to see easily, i.e. without too much computation, that the limiting probability has to be the inverse of the expectation of one roll?",p(n) n p(n)\approx p(m) m n,"['probability', 'statistics', 'dice']"
3,"Transient, Positive Recurrent, or Null Recurrent","Transient, Positive Recurrent, or Null Recurrent",,"\begin{align} P_{1, 2^i} = 2^{-i} ~~&\textrm{and} ~~P_{i+1, i}= 1, ~i\in \mathbb Z^+\\P_{i, 1} = 1/(i+1) ~~&\textrm{and}~~ P_{i, i+1} = I/(I+1), ~i \in \mathbb Z^+. \end{align} Given the following sets of transition probabilities, how do I determine whether the irreducible DTMC is transient, positive recurrent or null recurrent? So I understand that the state is positive recurrent iff its mean recurrent time < infinity, and null recurrent iff its mean recurrent time = infinity. Although how do you determine this given the transition probabilities?","Given the following sets of transition probabilities, how do I determine whether the irreducible DTMC is transient, positive recurrent or null recurrent? So I understand that the state is positive recurrent iff its mean recurrent time < infinity, and null recurrent iff its mean recurrent time = infinity. Although how do you determine this given the transition probabilities?","\begin{align}
P_{1, 2^i} = 2^{-i} ~~&\textrm{and} ~~P_{i+1, i}= 1, ~i\in \mathbb Z^+\\P_{i, 1} = 1/(i+1) ~~&\textrm{and}~~ P_{i, i+1} = I/(I+1), ~i \in \mathbb Z^+.
\end{align}","['probability', 'statistics', 'markov-chains']"
4,"What does it mean that the ""$(X_1,\dots, X_n)$ are drawn from a product distribution""?","What does it mean that the "" are drawn from a product distribution""?","(X_1,\dots, X_n)","In the book High-Dimensional Statistics: A Non-Asymptotic Viewpoint , Wainwright writes: My question: What exactly is the measure $\mathsf P$ (he uses $\mathbb P$ ) here and what are the random variables $(X_1,\dots, X_n)$ ? As far as I can understand, the $(X_1,\dots, X_n)$ are a measurable function from some ""un-important"" event probability space $(\Omega, \mathcal A, \mathsf Q)$ to $\mathcal X^n$ and $\mathsf P$ is given as pushforward measure in the following way: $$\mathsf Q= (X_1,\dots,X_n)_* \mathsf P.$$ But then $\mathsf P$ is a measure on $\mathcal X^n$ , no? So how could something like $\mathsf P(Z\ge\mathsf E(Z)+\delta)$ be well-defined?","In the book High-Dimensional Statistics: A Non-Asymptotic Viewpoint , Wainwright writes: My question: What exactly is the measure (he uses ) here and what are the random variables ? As far as I can understand, the are a measurable function from some ""un-important"" event probability space to and is given as pushforward measure in the following way: But then is a measure on , no? So how could something like be well-defined?","\mathsf P \mathbb P (X_1,\dots, X_n) (X_1,\dots, X_n) (\Omega, \mathcal A, \mathsf Q) \mathcal X^n \mathsf P \mathsf Q= (X_1,\dots,X_n)_* \mathsf P. \mathsf P \mathcal X^n \mathsf P(Z\ge\mathsf E(Z)+\delta)","['probability-theory', 'measure-theory', 'statistics']"
5,Transformation to remove column in regression proof,Transformation to remove column in regression proof,,"I'm trying to show that the $F$ statistic where the smaller model is just the removal of the $j$ th predictor is equivalent to the square of the $t$ statistic for question $3.1$ in Elements of Statistical Learning. $$F = \frac{RSS_0 - RSS_1}{RSS_0/(N-p-1)}$$ $$z_j = \frac{\hat{\beta_j}}{\hat{\sigma}\sqrt{v_{jj}}}$$ where $v_{jj} = (X^TX)^{-1}_{jj}$ , and $RSS_0$ is the residual sum of squares of the bigger model, and $RSS_1$ is the residual sum of squares of the model with predictor $j$ removed. This boils down to showing that $$RSS_0 - RSS_1 = \frac{\hat{\beta_j^2}}{v_{jj}}$$ I try and compute $RSS_0 - RSS_1$ (I will refer to $H = X(X^TX)^{-1}X^Ty$ ): \begin{align} RSS_0 - RSS_1 &= ||y-\hat{y}_{full}||^2 - ||y-\hat{y}_{no \beta_j}||^2 \\&= ||(I-H_{full})y||^2 - ||(I-H_{no\beta_j})y||^2 \\&= y^T(I-H_{full})y - y^T(I-H_{no\beta_j})y = y^T(H_{no\beta_j} - H_{full})y \end{align} It is over here where I am stuck - I don't know how to get an expression for $H_{no\beta_j}$ - If I knew some transformation $T: \mathbb{R}^{n\times p} \rightarrow \mathbb{R}^{n\times (p-1)}$ then maybe I could proceed, but other ideas are appreciated.","I'm trying to show that the statistic where the smaller model is just the removal of the th predictor is equivalent to the square of the statistic for question in Elements of Statistical Learning. where , and is the residual sum of squares of the bigger model, and is the residual sum of squares of the model with predictor removed. This boils down to showing that I try and compute (I will refer to ): It is over here where I am stuck - I don't know how to get an expression for - If I knew some transformation then maybe I could proceed, but other ideas are appreciated.","F j t 3.1 F = \frac{RSS_0 - RSS_1}{RSS_0/(N-p-1)} z_j = \frac{\hat{\beta_j}}{\hat{\sigma}\sqrt{v_{jj}}} v_{jj} = (X^TX)^{-1}_{jj} RSS_0 RSS_1 j RSS_0 - RSS_1 = \frac{\hat{\beta_j^2}}{v_{jj}} RSS_0 - RSS_1 H = X(X^TX)^{-1}X^Ty \begin{align}
RSS_0 - RSS_1 &= ||y-\hat{y}_{full}||^2 - ||y-\hat{y}_{no \beta_j}||^2
\\&= ||(I-H_{full})y||^2 - ||(I-H_{no\beta_j})y||^2
\\&= y^T(I-H_{full})y - y^T(I-H_{no\beta_j})y = y^T(H_{no\beta_j} - H_{full})y
\end{align} H_{no\beta_j} T: \mathbb{R}^{n\times p} \rightarrow \mathbb{R}^{n\times (p-1)}","['linear-algebra', 'statistics', 'hypothesis-testing', 'linear-regression']"
6,Likelihood ratio test question,Likelihood ratio test question,,"If $X_i$ , $i=1,\ldots,n$ , are observations from the normal distribution with known variance $\sigma_i^2$ , respectively, and $X_i$ 's are mutually independent, construct a test for testing that their means are all equal. My approach: $\lambda=\frac{L(\omega)}{L(\Omega)}$ where $\omega$ comes from the space where all means are equal and hence in likelihood means are replaced $\mu$ and $\sigma_i^2$ stay the same. In, $L(\Omega)$ , all means are staying as they were as $\mu_i$ and variances $\sigma_i^2$ . Do, we need to replace means and variances by their maximum likelihood somewhere. I am confused about that.","If , , are observations from the normal distribution with known variance , respectively, and 's are mutually independent, construct a test for testing that their means are all equal. My approach: where comes from the space where all means are equal and hence in likelihood means are replaced and stay the same. In, , all means are staying as they were as and variances . Do, we need to replace means and variances by their maximum likelihood somewhere. I am confused about that.","X_i i=1,\ldots,n \sigma_i^2 X_i \lambda=\frac{L(\omega)}{L(\Omega)} \omega \mu \sigma_i^2 L(\Omega) \mu_i \sigma_i^2","['statistics', 'normal-distribution', 'statistical-inference', 'hypothesis-testing']"
7,UMVUE and complete sufficient statistic,UMVUE and complete sufficient statistic,,"Let $X_1,\cdots,X_n$ be independent random variables with density $$f_{X_i}(x;\theta)=\begin{cases}e^{i\theta-x},&i\theta\leqslant x\\ 0,&\text{otherwise}\end{cases}$$ where $-\infty<\theta<\infty$ , $i=1,2,\cdots,n$ . Find the complete and sufficient statistic for $\theta$ and compute the unique minimum variance unbiased estimator of $\theta$ . My approach: $$f_{X_i}(x;\theta)= e^{i\theta-x}I_{(i\theta\leqslant x)}\\ L(x;\theta)=\prod_{i=1}^{n} e^{i\theta-x}I_{(i\theta\leqslant x)}$$ which on solving tells me that $Y= \min\dfrac{X_i}{i}$ is the sufficient statistic of $\theta$ . Also, how to prove completeness? Now, my question is in order to find UMVUE, we need to have pdf of $Y$ . How to go about that?","Let be independent random variables with density where , . Find the complete and sufficient statistic for and compute the unique minimum variance unbiased estimator of . My approach: which on solving tells me that is the sufficient statistic of . Also, how to prove completeness? Now, my question is in order to find UMVUE, we need to have pdf of . How to go about that?","X_1,\cdots,X_n f_{X_i}(x;\theta)=\begin{cases}e^{i\theta-x},&i\theta\leqslant x\\
0,&\text{otherwise}\end{cases} -\infty<\theta<\infty i=1,2,\cdots,n \theta \theta f_{X_i}(x;\theta)= e^{i\theta-x}I_{(i\theta\leqslant x)}\\
L(x;\theta)=\prod_{i=1}^{n} e^{i\theta-x}I_{(i\theta\leqslant x)} Y= \min\dfrac{X_i}{i} \theta Y","['statistics', 'statistical-inference', 'exponential-distribution', 'parameter-estimation']"
8,How to find fisher information for this pdf?,How to find fisher information for this pdf?,,"Compute the maximum likelihood estimator for the unknown (one or two dimensional) parameter, based on a sample of n i.i.d. random variables with that distribution. In each case, is the Fisher information well defined ? If yes, compute it. We have a shihifted exponential distribution with parameters $\alpha \in \mathbb{R},\:\lambda >0:$ $\:f_{\alpha ,\lambda }\left(x\right)=\lambda e^{-\lambda \left(x-\alpha \right)}1_{x\ge \alpha },\:\forall x\in \mathbb{R}$ I want to find fisher information for this pdf. How can I do that? I tried to find the second derivative of a log-likelihood function of $a$ but it is zero, so fisher information of $a$ is zero?","Compute the maximum likelihood estimator for the unknown (one or two dimensional) parameter, based on a sample of n i.i.d. random variables with that distribution. In each case, is the Fisher information well defined ? If yes, compute it. We have a shihifted exponential distribution with parameters I want to find fisher information for this pdf. How can I do that? I tried to find the second derivative of a log-likelihood function of but it is zero, so fisher information of is zero?","\alpha \in \mathbb{R},\:\lambda >0: \:f_{\alpha ,\lambda }\left(x\right)=\lambda e^{-\lambda \left(x-\alpha \right)}1_{x\ge \alpha },\:\forall x\in \mathbb{R} a a","['statistics', 'fisher-information']"
9,How is the chi-square confidence interval derived from the inverse gamma function?,How is the chi-square confidence interval derived from the inverse gamma function?,,"I had to derive the chi-squared confidence intervals for a AR(1) red noise model generated theoretically to fit the power spectra of a time series. The shape function of the power spectra of the red noise model is given by $$\frac{1-\rho^2}{1-2\rho\cos\frac{k\pi}{f_s}+\rho^2}$$ However, to derive the $95\%$ and $99\%$ confidence intervals I had to first do this (python 3.7): Ci95=(2*sc.gammaincinv(nw2/2, 0.95))/nw2 Ci99=(2*sc.gammaincinv(nw2/2, 0.99))/nw2 where nw2 is, I figured out (and please correct me if I am wrong), the degrees of freedom. Then I had to multiply the theoretically derived red noise spectra with Ci95 and Ci99 to get the confidence levels. Can anyone please explain the connection between the chi-square confidence intervals and the inverse gamma function? I had looked up for the connection between chi-square and gamma function, but none actually touched upon this particular aspect.","I had to derive the chi-squared confidence intervals for a AR(1) red noise model generated theoretically to fit the power spectra of a time series. The shape function of the power spectra of the red noise model is given by However, to derive the and confidence intervals I had to first do this (python 3.7): Ci95=(2*sc.gammaincinv(nw2/2, 0.95))/nw2 Ci99=(2*sc.gammaincinv(nw2/2, 0.99))/nw2 where nw2 is, I figured out (and please correct me if I am wrong), the degrees of freedom. Then I had to multiply the theoretically derived red noise spectra with Ci95 and Ci99 to get the confidence levels. Can anyone please explain the connection between the chi-square confidence intervals and the inverse gamma function? I had looked up for the connection between chi-square and gamma function, but none actually touched upon this particular aspect.",\frac{1-\rho^2}{1-2\rho\cos\frac{k\pi}{f_s}+\rho^2} 95\% 99\%,"['statistics', 'gamma-function', 'confidence-interval', 'gamma-distribution', 'chi-squared']"
10,"$X_1,\ldots, X_{100} \stackrel{iid}{\sim} N(\mu,1)$ iid. Only $X_i <0$ is recorded. 40 observations are less than 0. What is the MLE of $\mu$?",iid. Only  is recorded. 40 observations are less than 0. What is the MLE of ?,"X_1,\ldots, X_{100} \stackrel{iid}{\sim} N(\mu,1) X_i <0 \mu","$X_1,\ldots, X_{100} \stackrel{iid}{\sim} N(\mu,1)$ but only $X_i <0$ is recorded. 40 observations are less than 0. What is the MLE of $\mu$ ? Attempt Let $X_i = \mu + Z_i$ , $Z_i\sim N(0,1)$ let $N$ be the number of $X_i<0$ $P(X<0) = P(\mu+ Z < 0) = P(Z<-\mu) = \Phi(-\mu)$ $P(N=40) = \binom{100}{40}(1-\Phi(-\mu))^{60}(\Phi(-\mu))^{40}$ $\ldots \implies$ the MLE of $\mu$ is $\hat \mu= -\Phi^{-1}(2/5) \approx 0.2533$ is this approach correct?","but only is recorded. 40 observations are less than 0. What is the MLE of ? Attempt Let , let be the number of the MLE of is is this approach correct?","X_1,\ldots, X_{100} \stackrel{iid}{\sim} N(\mu,1) X_i <0 \mu X_i = \mu + Z_i Z_i\sim N(0,1) N X_i<0 P(X<0) = P(\mu+ Z < 0) = P(Z<-\mu) = \Phi(-\mu) P(N=40) = \binom{100}{40}(1-\Phi(-\mu))^{60}(\Phi(-\mu))^{40} \ldots \implies \mu \hat \mu= -\Phi^{-1}(2/5) \approx 0.2533","['probability', 'statistics', 'probability-distributions']"
11,"If $X$ is a nonnegative $\sigma$-subGaussian random variable with $P(X=0)\ge p$, what is a good upper bound for $P(X \ge h)$?","If  is a nonnegative -subGaussian random variable with , what is a good upper bound for ?",X \sigma P(X=0)\ge p P(X \ge h),"Let $X$ be a nonnegative random variable and let $\sigma \in [0,\infty)$ and $p \in (0,1)$ such that (1) $P(X=0) \ge p$ (2) $Var(X) \le \sigma^2$ For $h \ge 0$ , define $c_X(h):=P(X \ge h)$ . The following result was established in a paper of S. Bobkov . For every $h \ge \dfrac{\sigma}{\sqrt{p(1-p)}}$ , it holds that $P(X \ge h) \le \dfrac{p\sigma^2}{ph^2-\sigma^2}$ . In the referenced paper, the above inequality is labeled as (2.6). Now, suppose we replace condition (2) with the following condition (2') $X$ is $\sigma^2$ -subGaussian, meaning that $P(|X-EX| > t) \le 2\exp(-t^2/(2\sigma^2))$ for all $t \ge 0$ . Question. What is a good upper bound for $c_X(h)$ as a function of $p$ , $\sigma$ , and $h$ , in this case ? One would expect to get stronger to obtain a stronger tail-bound than previously. N.B.: Of course, if the worst comes to the worst, I'll be fine with a bound which works only works sufficiently large $h$ .","Let be a nonnegative random variable and let and such that (1) (2) For , define . The following result was established in a paper of S. Bobkov . For every , it holds that . In the referenced paper, the above inequality is labeled as (2.6). Now, suppose we replace condition (2) with the following condition (2') is -subGaussian, meaning that for all . Question. What is a good upper bound for as a function of , , and , in this case ? One would expect to get stronger to obtain a stronger tail-bound than previously. N.B.: Of course, if the worst comes to the worst, I'll be fine with a bound which works only works sufficiently large .","X \sigma \in [0,\infty) p \in (0,1) P(X=0) \ge p Var(X) \le \sigma^2 h \ge 0 c_X(h):=P(X \ge h) h \ge \dfrac{\sigma}{\sqrt{p(1-p)}} P(X \ge h) \le \dfrac{p\sigma^2}{ph^2-\sigma^2} X \sigma^2 P(|X-EX| > t) \le 2\exp(-t^2/(2\sigma^2)) t \ge 0 c_X(h) p \sigma h h","['probability', 'statistics', 'geometric-probability', 'concentration-of-measure', 'distribution-tails']"
12,TV Distance between Bernoulli and Poisson,TV Distance between Bernoulli and Poisson,,"With P=Ber(p) and Q=Poiss(p) where $p\in (0,1)$ , I try to find the TV Distance T(P,Q). To find the Total Variance Distance we can use the discrete formula $$T(P,Q) = 1/2 * \sum_{x\in E} |p_\theta(x) - p_{\theta'(x)}|$$ which I translate to $$ T(P,Q) = 1/2 * \sum_0^\infty |p^x (1-p)^{1-x} - \frac{p^x*e^{-p}}{x!}|$$ I then take the seperate case $x=0$ out of the summation and get $$=1/2 * |(1-p)-e^{-p}| + 1/2 * \sum_1^\infty |p^x (1-p)^{1-x} - \frac{p^x*e^{-p}}{x!}|$$ where due to probability $p\in (0,1)$ the second term is 1-P(x=0), therefore $$=1/2 *( |(1-p)-e^{-p}| + |1- (1-p)+e^{-p}|)$$ $$=1/2 *( |(1-p)-e^{-p}| + |p+e^{-p}|)$$ But it seems I am making a mistake somewhere, as it doesn't seem correct.","With P=Ber(p) and Q=Poiss(p) where , I try to find the TV Distance T(P,Q). To find the Total Variance Distance we can use the discrete formula which I translate to I then take the seperate case out of the summation and get where due to probability the second term is 1-P(x=0), therefore But it seems I am making a mistake somewhere, as it doesn't seem correct.","p\in (0,1) T(P,Q) = 1/2 * \sum_{x\in E} |p_\theta(x) - p_{\theta'(x)}|  T(P,Q) = 1/2 * \sum_0^\infty |p^x (1-p)^{1-x} - \frac{p^x*e^{-p}}{x!}| x=0 =1/2 * |(1-p)-e^{-p}| + 1/2 * \sum_1^\infty |p^x (1-p)^{1-x} - \frac{p^x*e^{-p}}{x!}| p\in (0,1) =1/2 *( |(1-p)-e^{-p}| + |1- (1-p)+e^{-p}|) =1/2 *( |(1-p)-e^{-p}| + |p+e^{-p}|)","['probability', 'statistics', 'total-variation']"
13,Total Variation Distance between two uniform distributions,Total Variation Distance between two uniform distributions,,"Two distributions with $P=Unif([0,s])$ and $Q=Unif([0,t])$ where $0<s<t$ I have the general formula and use the uniform pdf for P and Q $$TV(P,Q) = 1/2 \int_{x\in E} |p_{\theta}-p_{\theta'}| dx$$ $$= 1/2 \int_{x\in E} |\frac{1}{s}-\frac{1}{t}| dx$$ Now I am having trouble with integrating. Which space do I integrate on, from s to t, since we want the distance of the two pdfs? And if so, how do I proceed?","Two distributions with and where I have the general formula and use the uniform pdf for P and Q Now I am having trouble with integrating. Which space do I integrate on, from s to t, since we want the distance of the two pdfs? And if so, how do I proceed?","P=Unif([0,s]) Q=Unif([0,t]) 0<s<t TV(P,Q) = 1/2 \int_{x\in E} |p_{\theta}-p_{\theta'}| dx = 1/2 \int_{x\in E} |\frac{1}{s}-\frac{1}{t}| dx","['probability', 'statistics', 'total-variation']"
14,Calculating the P-value of a T-distribution.,Calculating the P-value of a T-distribution.,,"Learning some statistics here and in the chapter of Linear Regression I wanted to prove the values that I get on summary() from a created model. My summary() output is: Call: lm(formula = Price ~ Taxes + Size, data = HousePrices)  Residuals:     Min      1Q  Median      3Q     Max  -188027  -26138     347   22944  200114   Coefficients:               Estimate Std. Error t value Pr(>|t|)     (Intercept) -28608.744  13519.096  -2.116   0.0369 *   Taxes           39.601      6.917   5.725 1.16e-07 *** Size            66.512     12.817   5.189 1.16e-06 *** --- Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  Residual standard error: 48830 on 97 degrees of freedom Multiple R-squared:  0.7722,    Adjusted R-squared:  0.7675  F-statistic: 164.4 on 2 and 97 DF,  p-value: < 2.2e-16 For example to calculate the t-value for the intercept I do t-value = -28608.744 / 13519.096 = -2.116173 Now I found in other forums that to get the p-value from this H0 I have to find the probability of the tvalue in a lower tail, I do it with the next command. pvalue1 =  pt(-abs(tvalue), 97, lower.tail = T)*2 I get the right value but I got two questions I cant understand. Why do I have to calculate the probability always with a negative value of a t-value? What is the reason to make it with lower tail and then multiply the result by 2?","Learning some statistics here and in the chapter of Linear Regression I wanted to prove the values that I get on summary() from a created model. My summary() output is: Call: lm(formula = Price ~ Taxes + Size, data = HousePrices)  Residuals:     Min      1Q  Median      3Q     Max  -188027  -26138     347   22944  200114   Coefficients:               Estimate Std. Error t value Pr(>|t|)     (Intercept) -28608.744  13519.096  -2.116   0.0369 *   Taxes           39.601      6.917   5.725 1.16e-07 *** Size            66.512     12.817   5.189 1.16e-06 *** --- Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1  Residual standard error: 48830 on 97 degrees of freedom Multiple R-squared:  0.7722,    Adjusted R-squared:  0.7675  F-statistic: 164.4 on 2 and 97 DF,  p-value: < 2.2e-16 For example to calculate the t-value for the intercept I do t-value = -28608.744 / 13519.096 = -2.116173 Now I found in other forums that to get the p-value from this H0 I have to find the probability of the tvalue in a lower tail, I do it with the next command. pvalue1 =  pt(-abs(tvalue), 97, lower.tail = T)*2 I get the right value but I got two questions I cant understand. Why do I have to calculate the probability always with a negative value of a t-value? What is the reason to make it with lower tail and then multiply the result by 2?",,"['statistics', 'linear-regression', 'p-value']"
15,Extracting a smaller Markov chain from a larger Markov chain,Extracting a smaller Markov chain from a larger Markov chain,,"I am not very familiar with Markov chains, hence the probably ill titled questions. If we have 5 random variables $X, Y, Z, W$ and they form a Markov chain such that $$X \rightarrow Y \rightarrow Z \rightarrow W \rightarrow P$$ Is also the case that $$X \rightarrow Y \rightarrow P$$ or $$X \rightarrow Y \rightarrow W $$ Intuitively I would assume it is true because no information about $X$ can be gained as we move along the chain, thus it is okay to remove a link. Secondly if i recall correctly then if $Z = f(Y)$ then $X \rightarrow Y \rightarrow Z$ is a Markov chain. So in my example $f$ is just a composite function. This is obviously a weak understanding at best, so any help is appreciated. Edit: My understanding is that 3 random variables $X, Y, Z$ form a markov chain if $X$ and $Z$ and conditionally independent given $Y$ . So $$X \rightarrow Y \rightarrow Z \iff p(x, y, z)=p(x) p(y | x) p(z | y)$$","I am not very familiar with Markov chains, hence the probably ill titled questions. If we have 5 random variables and they form a Markov chain such that Is also the case that or Intuitively I would assume it is true because no information about can be gained as we move along the chain, thus it is okay to remove a link. Secondly if i recall correctly then if then is a Markov chain. So in my example is just a composite function. This is obviously a weak understanding at best, so any help is appreciated. Edit: My understanding is that 3 random variables form a markov chain if and and conditionally independent given . So","X, Y, Z, W X \rightarrow Y \rightarrow Z \rightarrow W \rightarrow P X \rightarrow Y \rightarrow P X \rightarrow Y \rightarrow W  X Z = f(Y) X \rightarrow Y \rightarrow Z f X, Y, Z X Z Y X \rightarrow Y \rightarrow Z \iff p(x, y, z)=p(x) p(y | x) p(z | y)","['probability', 'statistics', 'stochastic-processes', 'markov-chains']"
16,Doubt about Q function,Doubt about Q function,,"Hi have a doubt about the Q function; I have this problem: $Z\sim N(20; 500)$ and I have to find $P(Z>0)$ , by Q function I have: $Q(\frac{0-20}{\sqrt{500}})=Q(-0.894)$ . Now I have to find $Q(-0.894)$ or $1-Q(0.894)$ on the table? Thank you","Hi have a doubt about the Q function; I have this problem: and I have to find , by Q function I have: . Now I have to find or on the table? Thank you",Z\sim N(20; 500) P(Z>0) Q(\frac{0-20}{\sqrt{500}})=Q(-0.894) Q(-0.894) 1-Q(0.894),"['calculus', 'probability', 'statistics']"
17,When and why do formulae involving sums over $x_i$ change to formulae involving $X$ in statistics? Specifically when dealing with likelihoods.,When and why do formulae involving sums over  change to formulae involving  in statistics? Specifically when dealing with likelihoods.,x_i X,"I've been reading up on stats recently and a question I'm working through involves calculating the log-likelihood of a distribution w.r.t a parameter $\beta$ . From my understanding, for some probability density function $f(x)$ that depends on a parameter $\beta$ , the likelihood is defined as $$[1] \qquad L(\beta) = f(x_1|\beta)\times f(x_2|\beta)\times ... f(x_n|\beta) = \prod_i^n f(x_i|\beta) $$ and the log likelihood as $$[2] \qquad l(\beta) = \sum_i^n \log[f(x_i|\beta)] $$ The answer to the question then goes on to declare $$[3] \qquad l(\beta) = n \log[f(X|\beta)] $$ My question is, why can you change from a sum over $x_i$ in [2] to just a $X$ in [3]? Is [3] just a short hand for [2] or is there an important statistical concept or convention that I've not encountered? From reading books and online searches it seems to be something to do with considering the whole distribution of $X$ , but I've not encountered a proper explanation of this or an intuitive explanation. My intuition is that [3] is wrong and that you can only sum over the $x_i$ 's if $x_1=x_2=...=x_n$ , but then I'm still confused as to why the $x$ 's would change to an $X$ . Thanks in advance. --- Edit with more context --- Thanks for people's help so far. I think i need to explain my question a bit better so I'm going to add some context of the problem I'm trying to solve. The problem that lead me to ask this question was about deriving the Cramer-Rao lower bound using a formula involving the second derivative of $\log[f(x|\beta)]$ . From the book I'm using, I have the CRLB as $$[4] \qquad V(\hat{\beta}) \geq \frac{1}{I(\beta)} $$ and the information as $$[5] \qquad I(\beta) = n i(\beta) = E[-l''(\beta)] = E[U(\beta)^2] $$ I also have some extra information from the question, $$[5] \qquad \frac{d}{d\beta}\log[f(x|\beta)] = \frac{1}{\beta} + log[x] $$ from this I can get the second derivative $$[6] \qquad \frac{d^2}{d\beta^2}\log[f(x|\beta)] = \frac{-1}{\beta^2} $$ This is where I got stuck. From looking at the information given to me, I'm pretty sure I have to use the $I(\beta) = E[-l''(\beta)]$ version of [5] to find the CRLB. And they've given [6] which heavily implies I have to use [2] to find the answer. My logic for the next step was $$[7] \qquad I(\beta) = E\left[-\frac{d^2}{d\beta^2}\left(\sum_i^n \log[f(x_i|\beta)]\right)\right] $$ and you can put the derivative inside the sum to get $$[8] \qquad I(\beta) = E\left[-\sum_i^n\left(\frac{d^2}{d\beta^2}\log[f(x_i|\beta)]\right)\right] $$ Here is where I got stuck, I'm don't know if I can use [6] to solve [8] as [6] involves an $x$ , whereas [8] involves an $x_i$ . I have the answer for this question provided to me, so I looked there for guidance but it was pretty unhelpful. I've copied it below in case it's useful to you guys book answer The CRLB is $\frac{1}{I(\beta)}$ and $I(\beta)=E(-l''(\beta)) $ . so $$ CRLB = \frac{-1}{n E\left(\frac{d^2}{d\beta^2}\log[f(X|\beta)]\right)} = \frac{-1}{n\frac{-1}{\beta^2}} = \frac{\beta^2}{n} $$ I'll call the last equation above [BA] for ""book answer"". I have a few questions about [BA] I've been dealing with $f(x|\beta)$ throughout the question, why does it change to $f(X|\beta)$ now? Also, if [8] is correct, why does $x_i$ change to $X$ ? Where does the $n$ in [BA] come from? I tried working backwards from [BA] towards my equation [7], that's where I got [3] from originally. I think that I'm not understanding some part of the notation regarding $x_i$ $x$ and $X$ . My current thinking is that $X$ is a random variable that has some associated p.d.f, $x_i$ is the $i^{th}$ ""draw"" from $X$ and $x$ are all of the ""draws"" from $X$ collected in a vector. But I'm pretty sure this must be wrong. Thanks again for your help :-)","I've been reading up on stats recently and a question I'm working through involves calculating the log-likelihood of a distribution w.r.t a parameter . From my understanding, for some probability density function that depends on a parameter , the likelihood is defined as and the log likelihood as The answer to the question then goes on to declare My question is, why can you change from a sum over in [2] to just a in [3]? Is [3] just a short hand for [2] or is there an important statistical concept or convention that I've not encountered? From reading books and online searches it seems to be something to do with considering the whole distribution of , but I've not encountered a proper explanation of this or an intuitive explanation. My intuition is that [3] is wrong and that you can only sum over the 's if , but then I'm still confused as to why the 's would change to an . Thanks in advance. --- Edit with more context --- Thanks for people's help so far. I think i need to explain my question a bit better so I'm going to add some context of the problem I'm trying to solve. The problem that lead me to ask this question was about deriving the Cramer-Rao lower bound using a formula involving the second derivative of . From the book I'm using, I have the CRLB as and the information as I also have some extra information from the question, from this I can get the second derivative This is where I got stuck. From looking at the information given to me, I'm pretty sure I have to use the version of [5] to find the CRLB. And they've given [6] which heavily implies I have to use [2] to find the answer. My logic for the next step was and you can put the derivative inside the sum to get Here is where I got stuck, I'm don't know if I can use [6] to solve [8] as [6] involves an , whereas [8] involves an . I have the answer for this question provided to me, so I looked there for guidance but it was pretty unhelpful. I've copied it below in case it's useful to you guys book answer The CRLB is and . so I'll call the last equation above [BA] for ""book answer"". I have a few questions about [BA] I've been dealing with throughout the question, why does it change to now? Also, if [8] is correct, why does change to ? Where does the in [BA] come from? I tried working backwards from [BA] towards my equation [7], that's where I got [3] from originally. I think that I'm not understanding some part of the notation regarding and . My current thinking is that is a random variable that has some associated p.d.f, is the ""draw"" from and are all of the ""draws"" from collected in a vector. But I'm pretty sure this must be wrong. Thanks again for your help :-)",\beta f(x) \beta [1] \qquad L(\beta) = f(x_1|\beta)\times f(x_2|\beta)\times ... f(x_n|\beta) = \prod_i^n f(x_i|\beta)  [2] \qquad l(\beta) = \sum_i^n \log[f(x_i|\beta)]  [3] \qquad l(\beta) = n \log[f(X|\beta)]  x_i X X x_i x_1=x_2=...=x_n x X \log[f(x|\beta)] [4] \qquad V(\hat{\beta}) \geq \frac{1}{I(\beta)}  [5] \qquad I(\beta) = n i(\beta) = E[-l''(\beta)] = E[U(\beta)^2]  [5] \qquad \frac{d}{d\beta}\log[f(x|\beta)] = \frac{1}{\beta} + log[x]  [6] \qquad \frac{d^2}{d\beta^2}\log[f(x|\beta)] = \frac{-1}{\beta^2}  I(\beta) = E[-l''(\beta)] [7] \qquad I(\beta) = E\left[-\frac{d^2}{d\beta^2}\left(\sum_i^n \log[f(x_i|\beta)]\right)\right]  [8] \qquad I(\beta) = E\left[-\sum_i^n\left(\frac{d^2}{d\beta^2}\log[f(x_i|\beta)]\right)\right]  x x_i \frac{1}{I(\beta)} I(\beta)=E(-l''(\beta))   CRLB = \frac{-1}{n E\left(\frac{d^2}{d\beta^2}\log[f(X|\beta)]\right)} = \frac{-1}{n\frac{-1}{\beta^2}} = \frac{\beta^2}{n}  f(x|\beta) f(X|\beta) x_i X n x_i x X X x_i i^{th} X x X,"['statistics', 'statistical-inference', 'density-function', 'log-likelihood']"
18,What is correct ranking for Spearman Correlation?,What is correct ranking for Spearman Correlation?,,"In order to calculate Spearman Correlation Coefficient, the data should be ranked. However, many people do this in different way. Some sort them like an increasing sequence (i.e the smallest number has rank 1 and the greatest has rank $n$ ), others do this in an opposite way, they give the highest rank to the smallest number and rank 1 to the greatest. Can you suggest what is the most appropriate way to do that?","In order to calculate Spearman Correlation Coefficient, the data should be ranked. However, many people do this in different way. Some sort them like an increasing sequence (i.e the smallest number has rank 1 and the greatest has rank ), others do this in an opposite way, they give the highest rank to the smallest number and rank 1 to the greatest. Can you suggest what is the most appropriate way to do that?",n,"['statistics', 'correlation']"
19,"examples of unbiased, biased, high variance, low variance estimator","examples of unbiased, biased, high variance, low variance estimator",,"I have just learnt variance and bias in machine learning and statistics. I still don't understand examples of function that estimates distribution with high bias/variance, or low bias/variance. If function overfitts distribution that means that it has a high variance, but according to MSE loss formula it shouldn't be so, because of my logic: if it fits every data point then MSE loss is zero, hence bias and variance are all zeroes, that contradicts my knowledge. Please help me to answer this question, and also give me examples of estimator of distribution with high/low bias/variance.","I have just learnt variance and bias in machine learning and statistics. I still don't understand examples of function that estimates distribution with high bias/variance, or low bias/variance. If function overfitts distribution that means that it has a high variance, but according to MSE loss formula it shouldn't be so, because of my logic: if it fits every data point then MSE loss is zero, hence bias and variance are all zeroes, that contradicts my knowledge. Please help me to answer this question, and also give me examples of estimator of distribution with high/low bias/variance.",,"['statistics', 'machine-learning', 'variance']"
20,Why does Hanson-Wright inequality give a poor bound in this example?,Why does Hanson-Wright inequality give a poor bound in this example?,,"The following is from High-Dimensional Probability by Roman Vershyni (Hanson-Wright inequality) Let $X = (X_1, \dots, X_n) \in \mathbb{R}^n$ be a random vector with independent, zero-mean, and sub-Gaussian coordinates. Let $A$ be an $n \times n$ matrix. Then, for every $t\geq 0$ , we have $$P(|X^\intercal A X - E[X^\intercal A X ]| \geq t) \leq 2 \exp \Big[ -c \min (\frac{t^2}{K^4 \|A\|_F^2}, \frac{t}{K^2 \|A\|_2})\Big],$$ where $K = \max_i \|X_i\|_{\psi_2}$ . I give an example where this bound is quite poor. Suppose that $A$ is a positive definite matrix and $X_i$ are i.i.d. standard Gaussian. For any vector $X$ it is trivial that $P(X^\intercal A X \leq 0) = 0$ . I apply Hanson-Wright to this probability: \begin{align} P(X^\intercal A X \leq 0) = P(- X^\intercal A X + E[X^\intercal A X] \geq  E[X^\intercal A X]) = P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)]) \end{align} Hanson-Wright gives the following bound \begin{align} P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)]) \leq \Big[ -c \min (\frac{\text{tr}(A)^2}{K^4 \|A\|_F^2}, \frac{\text{tr}(A)}{K^2 \|A\|_2})\Big] \end{align} Now, this bound is poor when $A$ is not well-conditioned, even though the correct probability is zero. For example, if eigenvalues of $A$ are $(1, \epsilon/(n-1), \dots, \epsilon/(n-1))$ , then $$\frac{\text{tr}(A)}{\|A\|_2} = 1+\epsilon.$$ Why does this bound poor in this example? Simulations show that this is also true when $A$ is nearly positive definite (e.g. $A = B^\intercal B - \epsilon x x^\intercal$ ).","The following is from High-Dimensional Probability by Roman Vershyni (Hanson-Wright inequality) Let be a random vector with independent, zero-mean, and sub-Gaussian coordinates. Let be an matrix. Then, for every , we have where . I give an example where this bound is quite poor. Suppose that is a positive definite matrix and are i.i.d. standard Gaussian. For any vector it is trivial that . I apply Hanson-Wright to this probability: Hanson-Wright gives the following bound Now, this bound is poor when is not well-conditioned, even though the correct probability is zero. For example, if eigenvalues of are , then Why does this bound poor in this example? Simulations show that this is also true when is nearly positive definite (e.g. ).","X = (X_1, \dots, X_n) \in \mathbb{R}^n A n \times n t\geq 0 P(|X^\intercal A X - E[X^\intercal A X ]| \geq t) \leq 2 \exp \Big[ -c \min (\frac{t^2}{K^4 \|A\|_F^2}, \frac{t}{K^2 \|A\|_2})\Big], K = \max_i \|X_i\|_{\psi_2} A X_i X P(X^\intercal A X \leq 0) = 0 \begin{align}
P(X^\intercal A X \leq 0) = P(- X^\intercal A X + E[X^\intercal A X] \geq  E[X^\intercal A X]) = P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)])
\end{align} \begin{align}
P(- X^\intercal A X + E[X^\intercal A X] \geq  \text{tr}(A)]) \leq \Big[ -c \min (\frac{\text{tr}(A)^2}{K^4 \|A\|_F^2}, \frac{\text{tr}(A)}{K^2 \|A\|_2})\Big]
\end{align} A A (1, \epsilon/(n-1), \dots, \epsilon/(n-1)) \frac{\text{tr}(A)}{\|A\|_2} = 1+\epsilon. A A = B^\intercal B - \epsilon x x^\intercal","['linear-algebra', 'probability', 'probability-theory', 'statistics', 'normal-distribution']"
21,Measurement of the traffic generated by the packet source,Measurement of the traffic generated by the packet source,,"I'm working on resolving a statistical problem and I came across some difficulties. The content of the task: A measurement of the traffic generated by the packet source indicates that the average traffic is $\lambda$ [packets/s] and maximum traffic is $\sigma$ [packets/s]. The classic exponential distribution is not appropriate for modeling such a source of traffic, because the exponential distribution contains only one parameter (and two parameters were measured). To model such a source of motion, you can use the shifted exponential distribution which is described by two parameters ( $\gamma, \delta > 0$ ): $$f(\tau) = \left\{\begin{matrix} 0 & \tau<d \\  \gamma e^{-\gamma (\tau-d)} & \tau\geq d \end{matrix}\right.$$ Random variable $\tau$ is the time interval between successive packets. Draw a distribution graph (1). What is the relationship between the maximum traffic  and $\delta$ , for the distribution (#)? Designate a mean value of the distribution (#). Based on measurements of traffic sources $(\lambda, \sigma)$ select firstly $\delta$ parameter for distribution (#), then $\gamma$ parameter for distribution (#). So far I've managed to solve the subsection 2. and this is what I've came up with: my solution to subsection 2.","I'm working on resolving a statistical problem and I came across some difficulties. The content of the task: A measurement of the traffic generated by the packet source indicates that the average traffic is [packets/s] and maximum traffic is [packets/s]. The classic exponential distribution is not appropriate for modeling such a source of traffic, because the exponential distribution contains only one parameter (and two parameters were measured). To model such a source of motion, you can use the shifted exponential distribution which is described by two parameters ( ): Random variable is the time interval between successive packets. Draw a distribution graph (1). What is the relationship between the maximum traffic  and , for the distribution (#)? Designate a mean value of the distribution (#). Based on measurements of traffic sources select firstly parameter for distribution (#), then parameter for distribution (#). So far I've managed to solve the subsection 2. and this is what I've came up with: my solution to subsection 2.","\lambda \sigma \gamma, \delta > 0 f(\tau) = \left\{\begin{matrix}
0 & \tau<d \\ 
\gamma e^{-\gamma (\tau-d)} & \tau\geq d
\end{matrix}\right. \tau \delta (\lambda, \sigma) \delta \gamma","['statistics', 'probability-distributions', 'exponential-distribution']"
22,What will be the probability of the sum of n random numbers to be greater than X?,What will be the probability of the sum of n random numbers to be greater than X?,,"I want to figure out a way/formula by which I can compute the probability of the sum of $n$ random numbers to be greater than $X$ . All the random numbers fall in the range of $[-1000 , -1.01]\cup \{0\}\cup [1.01,1000]$ and step size is $0.01$ Each random number is chosen independently. Use Case: I am working on the development project of a gaming engine. For each round a player is awarded a random score in the range of $[-1000 , -1.01]\cup \{0\}\cup [1.01,1000]$ . In the beginning, player can make a bet that after n rounds of the play the total sum of his score will be X. I just want to get the probability of the accuracy of his bet. Current Progress - I was able to somehow get the results using brute force approach ( n rolling dice problem ), however the brute force method is taking lots of computation power. I want an efficient formulae/solution (in terms of computation) I don't know if Convolutions is the right approach for it. Thanks for the help, in advance!","I want to figure out a way/formula by which I can compute the probability of the sum of random numbers to be greater than . All the random numbers fall in the range of and step size is Each random number is chosen independently. Use Case: I am working on the development project of a gaming engine. For each round a player is awarded a random score in the range of . In the beginning, player can make a bet that after n rounds of the play the total sum of his score will be X. I just want to get the probability of the accuracy of his bet. Current Progress - I was able to somehow get the results using brute force approach ( n rolling dice problem ), however the brute force method is taking lots of computation power. I want an efficient formulae/solution (in terms of computation) I don't know if Convolutions is the right approach for it. Thanks for the help, in advance!","n X [-1000 , -1.01]\cup \{0\}\cup [1.01,1000] 0.01 [-1000 , -1.01]\cup \{0\}\cup [1.01,1000]","['probability', 'statistics', 'probability-distributions']"
23,Number of random unit vectors which are less than theta apart,Number of random unit vectors which are less than theta apart,,"Given $n$ unit vectors which are uniformly distributed on a unit sphere, what the expected number of groups of $k$ vectors which are within an angle $\theta$ of one another For example, if I have $n=50$ unit vectors, what is the expected number of triplets of vectors ( $k=3$ ) that are within $\theta=20^\circ$ of one another? From simulation it seems like ~13.5","Given unit vectors which are uniformly distributed on a unit sphere, what the expected number of groups of vectors which are within an angle of one another For example, if I have unit vectors, what is the expected number of triplets of vectors ( ) that are within of one another? From simulation it seems like ~13.5",n k \theta n=50 k=3 \theta=20^\circ,"['probability', 'combinatorics', 'statistics', 'geometric-probability']"
24,Help understanding $D_{KL} (g;f)=0\iff f=g$ a.e.,Help understanding  a.e.,D_{KL} (g;f)=0\iff f=g,"It's seems to be a well know property of the Kullback-Leibler divergence (according to Wikipedia ) that $$D_{KL} (g;f)=0\iff f=g\,\,\, a.e.$$ I am working with the continuous case. The second implication is straightforward and I am more interested in the $``\implies""$ direction. $$D_{KL}(g;f)=\int_{\mathbb R} \log\left(\frac{g(x)}{f(x)}\right)g(x)dx=0$$ I don't quite graps how this implies $f=g$ a.e.  The logarithm is not non-negative, and hence I don't know how to proceed. I've read this follows from Gibb's inequality but I haven't been able to see how. Thanks in advance for any help.","It's seems to be a well know property of the Kullback-Leibler divergence (according to Wikipedia ) that I am working with the continuous case. The second implication is straightforward and I am more interested in the direction. I don't quite graps how this implies a.e.  The logarithm is not non-negative, and hence I don't know how to proceed. I've read this follows from Gibb's inequality but I haven't been able to see how. Thanks in advance for any help.","D_{KL} (g;f)=0\iff f=g\,\,\, a.e. ``\implies"" D_{KL}(g;f)=\int_{\mathbb R} \log\left(\frac{g(x)}{f(x)}\right)g(x)dx=0 f=g","['probability-theory', 'statistics', 'probability-distributions', 'entropy']"
25,Conditional Expectation of joint pdf,Conditional Expectation of joint pdf,,"I have a question about this joint distribution $f(x,y)=4\exp(-2y^2)$ $0<x<y$ and $0<y<\infty$ $Z=1$ if $|X-Y|>2$ $Z=0$ otherwise I need to find $E[Z|Y]$ Here's what I've done so far $E[Z|Y]$ = $P[|X-Y|>2|Y]$ = $P[|X-Y|>2|Y=y]$ = $P[2>X-Y>-2|Y=y]$ Now I'm stuck because I am not able to find the pdf of X.",I have a question about this joint distribution and if otherwise I need to find Here's what I've done so far = = = Now I'm stuck because I am not able to find the pdf of X.,"f(x,y)=4\exp(-2y^2) 0<x<y 0<y<\infty Z=1 |X-Y|>2 Z=0 E[Z|Y] E[Z|Y] P[|X-Y|>2|Y] P[|X-Y|>2|Y=y] P[2>X-Y>-2|Y=y]","['probability', 'statistics', 'conditional-expectation', 'conditional-probability']"
26,"What does the ""standard"" in ""standard deviation"" mean?","What does the ""standard"" in ""standard deviation"" mean?",,"I know what the standard deviation is. However, I can't make sense of its name. What does the word ""standard"" refer to? Is it a synonym for mean, so that the ""standard deviation"" is the ""deviation from the mean value""? Is it a methodology, so that the ""standard deviation"" is the ""standard way of determining the deviation"" from the mean? Wikipedia says that the term standard deviation was coined by Karl Pearson in 1894. As far as I could see, his cited article Contributions to the Mathematical Theory of Evolution does indeed introduce the term, but doesn't comment on the chosen name.","I know what the standard deviation is. However, I can't make sense of its name. What does the word ""standard"" refer to? Is it a synonym for mean, so that the ""standard deviation"" is the ""deviation from the mean value""? Is it a methodology, so that the ""standard deviation"" is the ""standard way of determining the deviation"" from the mean? Wikipedia says that the term standard deviation was coined by Karl Pearson in 1894. As far as I could see, his cited article Contributions to the Mathematical Theory of Evolution does indeed introduce the term, but doesn't comment on the chosen name.",,"['statistics', 'terminology', 'standard-deviation']"
27,How to prefer data vector which has a few peaks?,How to prefer data vector which has a few peaks?,,"In an information retrieval system, I have a vector of values which represent occurrences of a term in documents: Term is preferred when it appears more frequently in very few documents. So, I need a numerical value to prefer vector which has few high peaks. For example: TERM1 is preferred over TERM5 because it has one high peak compared to 4 high peaks  TERM1 is preferred over TERM6 because it has one high peak compared to 1 low value  TERM4 is preferred over TERM5 because it has one high peak and 3 low values compared to 4 high peaks  etc... Is there any formula or calculated value that can give higher weight to preferred vectors? p.s. I am not a mathematician Thanks in advance","In an information retrieval system, I have a vector of values which represent occurrences of a term in documents: Term is preferred when it appears more frequently in very few documents. So, I need a numerical value to prefer vector which has few high peaks. For example: TERM1 is preferred over TERM5 because it has one high peak compared to 4 high peaks  TERM1 is preferred over TERM6 because it has one high peak compared to 1 low value  TERM4 is preferred over TERM5 because it has one high peak and 3 low values compared to 4 high peaks  etc... Is there any formula or calculated value that can give higher weight to preferred vectors? p.s. I am not a mathematician Thanks in advance",,"['statistics', 'soft-question']"
28,Correlation coefficient in finance,Correlation coefficient in finance,,An asset A has volatility estimated as σA = 0.2 An asset B has volatility estimated as σB = 0.4 The assets have covariance = σAB = -0.33 State the hypothesis of correlation and test this at a 10% significance level So firstly I worked out the correlation coefficient which I believe to be -4.125 I did this by p= $-0.33/(0.2*0.4)$ adding to this I am told by the teacher I need to revere engineer the formula for d using a value taken from the Normal table. However I’m even unsure what my normal table value is,An asset A has volatility estimated as σA = 0.2 An asset B has volatility estimated as σB = 0.4 The assets have covariance = σAB = -0.33 State the hypothesis of correlation and test this at a 10% significance level So firstly I worked out the correlation coefficient which I believe to be -4.125 I did this by p= adding to this I am told by the teacher I need to revere engineer the formula for d using a value taken from the Normal table. However I’m even unsure what my normal table value is,-0.33/(0.2*0.4),"['statistics', 'statistical-inference', 'finance', 'hypothesis-testing', 'correlation']"
29,Why do we take into consideration the probability of the events that are more extreme than the observed value in hypothesis testing?,Why do we take into consideration the probability of the events that are more extreme than the observed value in hypothesis testing?,,"I am currently learning about hypothesis testing and I really don't understand why do we take into consideration the probability of the events to the left and to the right of the observed value (or just to the left, or just to the right in the cases when we are interested if a parameter is only greater or smaller than the hypothesized value of the parameter). So it is clear enough that we take into consideration the probability of the observed value, but why do we also take into consideration the probability of the events that are more extreme than the observed value ? It seems to me that if we also take into consideration the events that are more extreme than the observed value, we are overestimating the p-value. I understand that we couldn't consider only the observed value if we are talking about a continuous distribution, since in that case we have to find the area under the curve to find the probability, and we would find the area of a line which would be $0$ . But we could consider a small interval or something like that. And in the case of a discrete distribution we wouldn't have this problem, but we still take into consideration the events that are more extreme than the observed value. So why does this work? I would really appreciate it if you could explain it like you would explain it to someone who is just starting with statistics, since that is the position that I am in.","I am currently learning about hypothesis testing and I really don't understand why do we take into consideration the probability of the events to the left and to the right of the observed value (or just to the left, or just to the right in the cases when we are interested if a parameter is only greater or smaller than the hypothesized value of the parameter). So it is clear enough that we take into consideration the probability of the observed value, but why do we also take into consideration the probability of the events that are more extreme than the observed value ? It seems to me that if we also take into consideration the events that are more extreme than the observed value, we are overestimating the p-value. I understand that we couldn't consider only the observed value if we are talking about a continuous distribution, since in that case we have to find the area under the curve to find the probability, and we would find the area of a line which would be . But we could consider a small interval or something like that. And in the case of a discrete distribution we wouldn't have this problem, but we still take into consideration the events that are more extreme than the observed value. So why does this work? I would really appreciate it if you could explain it like you would explain it to someone who is just starting with statistics, since that is the position that I am in.",0,['statistics']
30,Function of a confidence interval,Function of a confidence interval,,"If we have a confidence interval for a given parameter $\theta$ given as $[\theta_l, \theta_u]$ ( $l$ is for lower and $u$ is for upper) at confidence level $\gamma$ , and we have a monotone (Borel) measurable function $f(\cdot)$ , can we claim that $[f(\theta_l), f(\theta_u)]$ is a confidence interval for the transformed parameter $f(\theta)$ at the same level $\gamma$ ? Can we say anything about the confidence interval if $f$ is not monotone?","If we have a confidence interval for a given parameter given as ( is for lower and is for upper) at confidence level , and we have a monotone (Borel) measurable function , can we claim that is a confidence interval for the transformed parameter at the same level ? Can we say anything about the confidence interval if is not monotone?","\theta [\theta_l, \theta_u] l u \gamma f(\cdot) [f(\theta_l), f(\theta_u)] f(\theta) \gamma f","['probability', 'statistics', 'parameter-estimation', 'confidence-interval']"
31,A man tests for HIV. What is the predictive probability that his second test is negative?,A man tests for HIV. What is the predictive probability that his second test is negative?,,"Can anyone help with this question ? In a population, it is estimated HIV prevalence to be $\lambda$ . For a new test for HIV: $\theta$ is the probability of an HIV positive person to test positive $\eta$ is the probability an HIV negative person tests positive in this test. A person takes the test to check whether they have HIV, he tests positive. What is the predictive probability he tests negative on the second test? Assumption: Repeat tests on the same person are conditionally independent. From my notes predictive probability is given as: $P(\tilde{Y} = \tilde{y} | Y = y) = \int p(\tilde{y}|\tau) p(\theta|\tau)$ here $\tilde{Y}$ is the unknown observable, $y$ is the observed data and $\eta$ the unknown. I am interested in the probability of the second test is negative, given that the first test is positive,without knowing if the man really has HIV or not. To facilitate this I define: $y_1$ as the event of the first test being positive and $\tilde{y_{2}}$ as the second test being negative Would this adaption to the formula given above be the correct/best approach to this problem ? $p(\tilde{y_{2}}, y_{1}|\tau) = p(\tilde{y_{2}}|\tau) p(y_{1}|\tau)p(\tau) $ and this is really $\propto p(\tilde{y_{2}}|\tau) p(\tau|y_{1})$ I've gotten for the $p(\tau|y_{1})$ from Bayes' theorem: $$p(\tau|y_{1}) = \frac{p(\tau)p(y_1|\tau)}{p(y_1)} \\ = \frac{\lambda \theta}{ \lambda \theta + \eta (1 - \lambda) }$$ How could I then find $p(\tilde{y_{2}}|\tau)$ ? Is this the correct approach ? Any hints are welcomed.","Can anyone help with this question ? In a population, it is estimated HIV prevalence to be . For a new test for HIV: is the probability of an HIV positive person to test positive is the probability an HIV negative person tests positive in this test. A person takes the test to check whether they have HIV, he tests positive. What is the predictive probability he tests negative on the second test? Assumption: Repeat tests on the same person are conditionally independent. From my notes predictive probability is given as: here is the unknown observable, is the observed data and the unknown. I am interested in the probability of the second test is negative, given that the first test is positive,without knowing if the man really has HIV or not. To facilitate this I define: as the event of the first test being positive and as the second test being negative Would this adaption to the formula given above be the correct/best approach to this problem ? and this is really I've gotten for the from Bayes' theorem: How could I then find ? Is this the correct approach ? Any hints are welcomed.","\lambda \theta \eta P(\tilde{Y} = \tilde{y} | Y = y) = \int p(\tilde{y}|\tau) p(\theta|\tau) \tilde{Y} y \eta y_1 \tilde{y_{2}} p(\tilde{y_{2}}, y_{1}|\tau) = p(\tilde{y_{2}}|\tau) p(y_{1}|\tau)p(\tau)  \propto p(\tilde{y_{2}}|\tau) p(\tau|y_{1}) p(\tau|y_{1}) p(\tau|y_{1}) = \frac{p(\tau)p(y_1|\tau)}{p(y_1)} \\
= \frac{\lambda \theta}{ \lambda \theta + \eta (1 - \lambda) } p(\tilde{y_{2}}|\tau)","['probability', 'statistics', 'conditional-probability', 'bayesian', 'bayes-theorem']"
32,Find minima for the KL divergence,Find minima for the KL divergence,,"The task is exercise 33.7 from the book Information Theory, Inference, and Learning Algorithms . The question is related to finding three distinc minima by minimizing the reversed KL divergence $KL(q||p)$ . The gist of the questions is as follows. Given the joint distribution $p(x,y)$ where rows represent $y$ and the columns $x$ . $$ \begin{array}{l|llll}  & 1 & 2 & 3 & 4 \\ \hline 1 & 1 / 8 & 1 / 8 & 0 & 0 \\ 2 & 1 / 8 & 1 / 8 & 0 & 0 \\ 3 & 0 & 0 & 1 / 4 & 0 \\ 4 & 0 & 0 & 0 & 1 / 4 \end{array} $$ If we approximate p with q by minimizing $KL(q||p)$ 1) show that there are three distinct minima 2) what is the value of $KL(q||p)$ if we set $q(x,y) = p(x)p(y)$ ? We may use that $q(x,y) = q(x)q(y)$ . My progress so far: $$ \begin{array}{l} \mathrm{KL}(q(x, y) \| p(x, y))=\sum_{x, y} q(x, y) \log \frac{q(x, y)}{p(x, y)}=\sum_{x, y} q(x) q(y) \log \frac{q(x) q(y)}{p(x, y)} \\ =\sum_{x} q(x) \log q(x)+\sum_{y} q(y) \log q(y)-\sum_{x, y} q(x) q(y) \log p(x, y) \end{array} $$ Setting derivative wrt $q(x)$ to zero: $$ \begin{array}{l} \frac{\partial}{\partial q(x)} \operatorname{KL}(q(x, y) \| p(x, y))=0  \iff \\ \frac{\partial}{\partial q(x)} \sum_{x} q(x) \log q(x)+\frac{\partial}{\partial q(x)} \sum_{y} q(y) \log q(y)=\frac{\partial}{\partial q(x)}\sum_{x} q(x) \sum_{y} q(y) \log p(x, y) \end{array} $$ However i am not sure how to do these derivatives, that i suspect needs to be solved to proceed. And then solve wrt. $q(y)$ after. I am not very familiar with variational calculus. Any help is appreciated.","The task is exercise 33.7 from the book Information Theory, Inference, and Learning Algorithms . The question is related to finding three distinc minima by minimizing the reversed KL divergence . The gist of the questions is as follows. Given the joint distribution where rows represent and the columns . If we approximate p with q by minimizing 1) show that there are three distinct minima 2) what is the value of if we set ? We may use that . My progress so far: Setting derivative wrt to zero: However i am not sure how to do these derivatives, that i suspect needs to be solved to proceed. And then solve wrt. after. I am not very familiar with variational calculus. Any help is appreciated.","KL(q||p) p(x,y) y x 
\begin{array}{l|llll} 
& 1 & 2 & 3 & 4 \\
\hline 1 & 1 / 8 & 1 / 8 & 0 & 0 \\
2 & 1 / 8 & 1 / 8 & 0 & 0 \\
3 & 0 & 0 & 1 / 4 & 0 \\
4 & 0 & 0 & 0 & 1 / 4
\end{array}
 KL(q||p) KL(q||p) q(x,y) = p(x)p(y) q(x,y) = q(x)q(y) 
\begin{array}{l}
\mathrm{KL}(q(x, y) \| p(x, y))=\sum_{x, y} q(x, y) \log \frac{q(x, y)}{p(x, y)}=\sum_{x, y} q(x) q(y) \log \frac{q(x) q(y)}{p(x, y)} \\
=\sum_{x} q(x) \log q(x)+\sum_{y} q(y) \log q(y)-\sum_{x, y} q(x) q(y) \log p(x, y)
\end{array}
 q(x) 
\begin{array}{l}
\frac{\partial}{\partial q(x)} \operatorname{KL}(q(x, y) \| p(x, y))=0  \iff \\
\frac{\partial}{\partial q(x)} \sum_{x} q(x) \log q(x)+\frac{\partial}{\partial q(x)} \sum_{y} q(y) \log q(y)=\frac{\partial}{\partial q(x)}\sum_{x} q(x) \sum_{y} q(y) \log p(x, y)
\end{array}
 q(y)","['real-analysis', 'probability']"
33,Who'll win the baseball game when two really good teams play?,Who'll win the baseball game when two really good teams play?,,"Our team is playing another team that wins 70% of its games. Our team is pretty good but wins only 60% of its games. If these teams have never played before and they've played equally hard opponents, what is the chance our team will be victorius? I think I solved it by comparing the game to flipping coins, but was looking for an answer a little more mathematical or rigorous. My approach is based on flipping coins. The other team's ""coin"" comes up heads 70% of the time (and 30% tails) and our team's ""coin"" comes up heads 60% of the time (and 40% tails). If I flip the coins many times and disregard the outcomes when both coins are heads or both coins are tails, I would expect 18% of the flips our team's coin would have a head and their team's coin would be a tail (0.6*0.3); and 28% of the flips the other team would get a head and our team a tail (0.7*0.4). Thus, our team would be expected to win 39% of the games (0.18/(0.18+0.28) and the other team 71%. I thought I'd ask if this makes sense and for a more mathematical approach. Thank you","Our team is playing another team that wins 70% of its games. Our team is pretty good but wins only 60% of its games. If these teams have never played before and they've played equally hard opponents, what is the chance our team will be victorius? I think I solved it by comparing the game to flipping coins, but was looking for an answer a little more mathematical or rigorous. My approach is based on flipping coins. The other team's ""coin"" comes up heads 70% of the time (and 30% tails) and our team's ""coin"" comes up heads 60% of the time (and 40% tails). If I flip the coins many times and disregard the outcomes when both coins are heads or both coins are tails, I would expect 18% of the flips our team's coin would have a head and their team's coin would be a tail (0.6*0.3); and 28% of the flips the other team would get a head and our team a tail (0.7*0.4). Thus, our team would be expected to win 39% of the games (0.18/(0.18+0.28) and the other team 71%. I thought I'd ask if this makes sense and for a more mathematical approach. Thank you",,"['probability', 'statistics']"
34,Bayes Theorem application for second testing based on first test result,Bayes Theorem application for second testing based on first test result,,"I am currently trying to answer this question and am though a bit confused on how to apply Bayes Theorem when a second test is performed based on the result of the first. A test to determine who is under the influence of a drug has a probability of 0.8 of being correct (i.e for both positive and negative results). If the test is positive, a second different test is carried out. The second test always correctly detects if the patient is in fact not under under the influence of the drug, but has a 10% error rate with drug users/under the influence. If 20% of the patients tested are actually users/under the influence we are asked to calculate: a) Proportion of patients that have to be given the second test (i.e proportion of testing positive on the first test) b) probability patients testing positive on the first test are really under the influence/drug users c) probability that patients testing negative on the second test are actually under the influence/drug users; For a) I am not sure I've arrived at the correct solution,as its 30% more than the population of 20% who are actually users. d - drug user/under the influence  c - not under the influence/not a drug user $P(d|+) = \frac{P(+|d)*P(d)}{P(+)*P(+|d) + P(+|c)*P(c)}  = \frac{0.2*0.8}{(0.2*0.8 + 0.2*0.8)} = 0.50 $ i.e % 50% of patients will test positive on first test b) I am immediately confused by this question and c). I have followed the rationale of this question Conditional probability and testing twice , and found the answer below: P1 = first test P2 = second test Then the desired probability is $$\Pr[P_2 \mid P_1] = \frac{\Pr[P_2 \cap P_1]}{\Pr[P_1]} = \frac{\Pr[P_2 \cap P_1 \mid d]\Pr[d] + \Pr[P_2 \cap P_1 \mid c]\Pr[c]}{\Pr[P_1 \mid d]\Pr[d] + \Pr[P_1 \mid c]\Pr[c]} = \frac{(0.8+0.9)*0.2 + (0.8+1)*0.8}{0.8*0.2 + 0.8*0.8} = 5.5625 $$ This is obviously not correct, I am not sure where I went wrong here. Any hints/answers are welcomed I am new to Bayesian Theory.","I am currently trying to answer this question and am though a bit confused on how to apply Bayes Theorem when a second test is performed based on the result of the first. A test to determine who is under the influence of a drug has a probability of 0.8 of being correct (i.e for both positive and negative results). If the test is positive, a second different test is carried out. The second test always correctly detects if the patient is in fact not under under the influence of the drug, but has a 10% error rate with drug users/under the influence. If 20% of the patients tested are actually users/under the influence we are asked to calculate: a) Proportion of patients that have to be given the second test (i.e proportion of testing positive on the first test) b) probability patients testing positive on the first test are really under the influence/drug users c) probability that patients testing negative on the second test are actually under the influence/drug users; For a) I am not sure I've arrived at the correct solution,as its 30% more than the population of 20% who are actually users. d - drug user/under the influence  c - not under the influence/not a drug user i.e % 50% of patients will test positive on first test b) I am immediately confused by this question and c). I have followed the rationale of this question Conditional probability and testing twice , and found the answer below: P1 = first test P2 = second test Then the desired probability is This is obviously not correct, I am not sure where I went wrong here. Any hints/answers are welcomed I am new to Bayesian Theory.",P(d|+) = \frac{P(+|d)*P(d)}{P(+)*P(+|d) + P(+|c)*P(c)}  = \frac{0.2*0.8}{(0.2*0.8 + 0.2*0.8)} = 0.50  \Pr[P_2 \mid P_1] = \frac{\Pr[P_2 \cap P_1]}{\Pr[P_1]} = \frac{\Pr[P_2 \cap P_1 \mid d]\Pr[d] + \Pr[P_2 \cap P_1 \mid c]\Pr[c]}{\Pr[P_1 \mid d]\Pr[d] + \Pr[P_1 \mid c]\Pr[c]} = \frac{(0.8+0.9)*0.2 + (0.8+1)*0.8}{0.8*0.2 + 0.8*0.8} = 5.5625 ,"['probability', 'statistics', 'conditional-probability', 'bayesian', 'bayes-theorem']"
35,Distribution of sample variance of Bernoulli variables,Distribution of sample variance of Bernoulli variables,,"I am facing the following problem, given $X_1 ... X_n$ a random sample of $Bernoulli(\theta)$ variables find the distribution of the sample variance $S^2 = \frac{1}{n} \sum_i(\bar{X} - X_i)^2$ . I have demonstrated that $S^2 = \bar{X} (1 - \bar{X})$ and i know $\bar{nX}$ has distribution $Binomial (n, \theta)$ but I have not been able to deduce the distribution of $S^2$ .","I am facing the following problem, given a random sample of variables find the distribution of the sample variance . I have demonstrated that and i know has distribution but I have not been able to deduce the distribution of .","X_1 ... X_n Bernoulli(\theta) S^2 = \frac{1}{n} \sum_i(\bar{X} - X_i)^2 S^2 = \bar{X} (1 - \bar{X}) \bar{nX} Binomial (n, \theta) S^2","['statistics', 'probability-distributions', 'binomial-distribution']"
36,"Bayes estimate for loss function $\ell(t,\alpha)=\frac{1}{\alpha^2}(t-\alpha^2)^2$?",Bayes estimate for loss function ?,"\ell(t,\alpha)=\frac{1}{\alpha^2}(t-\alpha^2)^2","I am given the following info for $\{X_i\}_{i=1}^{n}$ : $$X\sim f(X|\alpha)=\alpha X^{-(\alpha+1)}I(X>1).$$ Propose a convenient family of priors and find the Bayes estimate for the loss function $\ell(t,\alpha)=\frac{1}{\alpha^2}(t-\alpha^2)^2$ . The joint distribution is of the form $$f(\underline{X}|\alpha)=\alpha^n\prod_{i=1}^{n}X_i^{-(\alpha+1)}I(X_i>1)=\alpha^n e^{-(\alpha+1)\sum_{i=1}^{n}\log(X_i)}I(X_{(1)}>1).$$ Then, $\text{Gamma}(a,b)$ seem like good priors with a posterior $\text{Gamma}(a+n,\sum_{i = 1}^{n}\log(X_i)+b)$ . To find the posterior: $$P(\alpha|X)\propto P(X|\alpha)P(\alpha)\propto\alpha^n e^{-\alpha\sum_{i=1}^{n}\log(X_i)}e^{-b\alpha}\alpha^{a-1}$$ . Adding the like terms gives us the posterior. To find the Bayes estimate we minimize with respect to $t$ , we consider the following Bayes risk function $$\int \ell(t,\alpha)f(\alpha|\underline{X})d\alpha=\int \frac{1}{\alpha^2}(t-\alpha^2)^2f(\alpha|\underline{X})d\alpha.$$ Since $\frac{\partial}{\partial t}\frac{1}{\alpha^2}(t-\alpha^2)^2=\frac{2t}{\alpha^2}-2$ and $\int (\frac{2t}{\alpha^2}-2)f(\alpha|\underline{X})d\alpha<\infty$ , we have $$\frac{\partial}{\partial t}\int \ell(t,\alpha)f(\alpha|\underline{X})d\alpha=2\int \left(\frac{t}{\alpha^2}-1\right)f(\alpha|\underline{X})d\alpha = 2tE\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg]-2.$$ Setting this equal to $0$ implies the Bayes estimate is $$\hat{t}=\frac{1}{E\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg]}.$$ Define $R=\sum_{i = 1}^{n}\log(X_i)$ . Then \begin{align} E\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg] & =\int \alpha^{-2}\frac{(R+b)^{n+a}}{\Gamma(n+a)}\alpha^{n+a-1}e^{-\alpha(R+b)}d\alpha \\ & = \frac{(R+b)^{n+a}}{\Gamma(n+a)}\frac{\Gamma(n+a-2)}{(R+b)^{n+a-2}}\int \frac{(R+b)^{n+a-2}}{\Gamma(n+a-2)}\alpha^{n+a-2-1}e^{-\alpha(R+b)}d\alpha \\ & =\frac{(R+b)^{n+a}}{\Gamma(n+a)}\frac{\Gamma(n+a-2)}{(R+b)^{n+a-2}} \\ & =\frac{(R+b)^2}{(n+a)(n+a-1)} \end{align} Then $\hat{t}=\frac{(n+a)(n+a-1)}{(\sum_{i = 1}^{n}\log(X_i)+b)^2}$ . I am asked to find the asymptotic distribution as well. We have $\frac{(n+a)(n+a-1)}{(\sum_{i = 1}^{n}\log(X_i)+b)^2}\stackrel{p}\to\alpha^2$ so it is a consistent estimator. I am trying to use the Central Limit Theorem, but need to find the variance, is my work up to now correct? If so, how do I find the asymptotic distribution?","I am given the following info for : Propose a convenient family of priors and find the Bayes estimate for the loss function . The joint distribution is of the form Then, seem like good priors with a posterior . To find the posterior: . Adding the like terms gives us the posterior. To find the Bayes estimate we minimize with respect to , we consider the following Bayes risk function Since and , we have Setting this equal to implies the Bayes estimate is Define . Then Then . I am asked to find the asymptotic distribution as well. We have so it is a consistent estimator. I am trying to use the Central Limit Theorem, but need to find the variance, is my work up to now correct? If so, how do I find the asymptotic distribution?","\{X_i\}_{i=1}^{n} X\sim f(X|\alpha)=\alpha X^{-(\alpha+1)}I(X>1). \ell(t,\alpha)=\frac{1}{\alpha^2}(t-\alpha^2)^2 f(\underline{X}|\alpha)=\alpha^n\prod_{i=1}^{n}X_i^{-(\alpha+1)}I(X_i>1)=\alpha^n e^{-(\alpha+1)\sum_{i=1}^{n}\log(X_i)}I(X_{(1)}>1). \text{Gamma}(a,b) \text{Gamma}(a+n,\sum_{i = 1}^{n}\log(X_i)+b) P(\alpha|X)\propto P(X|\alpha)P(\alpha)\propto\alpha^n e^{-\alpha\sum_{i=1}^{n}\log(X_i)}e^{-b\alpha}\alpha^{a-1} t \int \ell(t,\alpha)f(\alpha|\underline{X})d\alpha=\int \frac{1}{\alpha^2}(t-\alpha^2)^2f(\alpha|\underline{X})d\alpha. \frac{\partial}{\partial t}\frac{1}{\alpha^2}(t-\alpha^2)^2=\frac{2t}{\alpha^2}-2 \int (\frac{2t}{\alpha^2}-2)f(\alpha|\underline{X})d\alpha<\infty \frac{\partial}{\partial t}\int \ell(t,\alpha)f(\alpha|\underline{X})d\alpha=2\int \left(\frac{t}{\alpha^2}-1\right)f(\alpha|\underline{X})d\alpha
= 2tE\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg]-2. 0 \hat{t}=\frac{1}{E\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg]}. R=\sum_{i = 1}^{n}\log(X_i) \begin{align}
E\bigg[\frac{1}{\alpha^2}\bigg|\underline{X}\bigg]
& =\int \alpha^{-2}\frac{(R+b)^{n+a}}{\Gamma(n+a)}\alpha^{n+a-1}e^{-\alpha(R+b)}d\alpha \\
& = \frac{(R+b)^{n+a}}{\Gamma(n+a)}\frac{\Gamma(n+a-2)}{(R+b)^{n+a-2}}\int \frac{(R+b)^{n+a-2}}{\Gamma(n+a-2)}\alpha^{n+a-2-1}e^{-\alpha(R+b)}d\alpha \\
& =\frac{(R+b)^{n+a}}{\Gamma(n+a)}\frac{\Gamma(n+a-2)}{(R+b)^{n+a-2}} \\
& =\frac{(R+b)^2}{(n+a)(n+a-1)}
\end{align} \hat{t}=\frac{(n+a)(n+a-1)}{(\sum_{i = 1}^{n}\log(X_i)+b)^2} \frac{(n+a)(n+a-1)}{(\sum_{i = 1}^{n}\log(X_i)+b)^2}\stackrel{p}\to\alpha^2","['statistics', 'statistical-inference', 'bayesian', 'parameter-estimation', 'bayes-theorem']"
37,Non conjugate prior with known posterior,Non conjugate prior with known posterior,,"For a give likelihood function $p(x | \theta)$ , the prior $p(\theta)$ is a conjugate prior if the posterior $p(\theta | x)$ comes from the same family of distributions as $p(\theta)$ . $p(\theta | x) = \frac{p(x | \theta)p(\theta)}{p(x)}$ involves solving an (often intractable) integral so this is very useful. Are there any prior, likelihood pairs such that the posterior's distribution is known but not from the same family as the prior? Meaning, non conjugate priors where the posterior is still easy to find. If so, how is this called?","For a give likelihood function , the prior is a conjugate prior if the posterior comes from the same family of distributions as . involves solving an (often intractable) integral so this is very useful. Are there any prior, likelihood pairs such that the posterior's distribution is known but not from the same family as the prior? Meaning, non conjugate priors where the posterior is still easy to find. If so, how is this called?",p(x | \theta) p(\theta) p(\theta | x) p(\theta) p(\theta | x) = \frac{p(x | \theta)p(\theta)}{p(x)},"['statistics', 'probability-distributions', 'statistical-inference', 'bayesian']"
38,Intervals to estimate the mean of normal distribution,Intervals to estimate the mean of normal distribution,,"$X_1, \dots, X_n$ are independent random variables distribute $N(c,1)$ with $c$ unknown. How to construct the following intervals to estimate $c$ , The first interval is $[i_1(X_1), j_1(X_1)]$ s.t $$p(c \in [i_1(X_1), j_1(X_1)]) = 95\%$$ The second interval is $[i_n(X_1, \dots, X_n), j_n(X_1, \dots, X_n)]$ s.t $$p(c \in [i_n(X_1, \dots, X_n), j_n(X_1, \dots, X_n)]) = 95\%$$ I don't know from where to start! How I can use only the percentage $95\%$ to construct both intervals?","are independent random variables distribute with unknown. How to construct the following intervals to estimate , The first interval is s.t The second interval is s.t I don't know from where to start! How I can use only the percentage to construct both intervals?","X_1, \dots, X_n N(c,1) c c [i_1(X_1), j_1(X_1)] p(c \in [i_1(X_1), j_1(X_1)]) = 95\% [i_n(X_1, \dots, X_n), j_n(X_1, \dots, X_n)] p(c \in [i_n(X_1, \dots, X_n), j_n(X_1, \dots, X_n)]) = 95\% 95\%","['probability', 'statistics', 'normal-distribution', 'parameter-estimation', 'confidence-interval']"
39,Testing significance of patterns of results,Testing significance of patterns of results,,"I'm a high school English teacher conducting an independent study, and I'm a total novice to statistical analysis, so please forgive me if I mischaracterize anything. I have gathered pretest and posttest data about student motivation from three groups of students: one that received normal grades over a six-week period (Group 3), one that received delayed performance-contingent grades and immediate completion-contingent grades (Group 2), and one that received no grades (Group 1). The tool that I used measures seven types of motivation, which I've coded as IMK, IMA, IMS, EMID, EMIJ, EMX, and AM. My hypothesis is that feedback in the form of narrative evaluations without immediate or salient multi-interval grades (i.e., Group 1 and Group 2) will lead to better motivational outcomes for high-school students in autonomy-supportive classrooms than forms of feedback associated with immediate and salient multi-interval grades (Group 3). ""Better,"" in this case, means that IMK, IMA, IMS, and EMID will increase and EMIJ, EMX, and AM will decrease by the end of the six-week period for students in Group 1 and Group 2. My hypothesis for Group 3 is two-tailed; I think both grades and autonomy support will have an effect, but I don't want to make any predictions about what that effect will look like - my only prediction is that the motivational outcome will be worse. I ran a bunch of paired t -tests to check the significance of the difference between pretest and posttest scores for each measured variable. Here's what I came up with: https://i.sstatic.net/NPB82.png Now, at a glance, you can see that the results seem to support my hypothesis. In Group 1 (Withheld), for instance, there was an increase in each of the things that I thought would increase, and there was a decrease in each of the things that I thought would decrease. It doesn't seem intuitively likely that this specific pattern happened randomly, even if the changes for each individual variable didn't pass the significance threshold. What sort of test could I do (ideally in R) to prove this?","I'm a high school English teacher conducting an independent study, and I'm a total novice to statistical analysis, so please forgive me if I mischaracterize anything. I have gathered pretest and posttest data about student motivation from three groups of students: one that received normal grades over a six-week period (Group 3), one that received delayed performance-contingent grades and immediate completion-contingent grades (Group 2), and one that received no grades (Group 1). The tool that I used measures seven types of motivation, which I've coded as IMK, IMA, IMS, EMID, EMIJ, EMX, and AM. My hypothesis is that feedback in the form of narrative evaluations without immediate or salient multi-interval grades (i.e., Group 1 and Group 2) will lead to better motivational outcomes for high-school students in autonomy-supportive classrooms than forms of feedback associated with immediate and salient multi-interval grades (Group 3). ""Better,"" in this case, means that IMK, IMA, IMS, and EMID will increase and EMIJ, EMX, and AM will decrease by the end of the six-week period for students in Group 1 and Group 2. My hypothesis for Group 3 is two-tailed; I think both grades and autonomy support will have an effect, but I don't want to make any predictions about what that effect will look like - my only prediction is that the motivational outcome will be worse. I ran a bunch of paired t -tests to check the significance of the difference between pretest and posttest scores for each measured variable. Here's what I came up with: https://i.sstatic.net/NPB82.png Now, at a glance, you can see that the results seem to support my hypothesis. In Group 1 (Withheld), for instance, there was an increase in each of the things that I thought would increase, and there was a decrease in each of the things that I thought would decrease. It doesn't seem intuitively likely that this specific pattern happened randomly, even if the changes for each individual variable didn't pass the significance threshold. What sort of test could I do (ideally in R) to prove this?",,['statistics']
40,Counter intuitive Prior/Posterior relationship in Bayesian inference for estimated probability fusion,Counter intuitive Prior/Posterior relationship in Bayesian inference for estimated probability fusion,,"I am trying to infer the probability distribution of a binary variable $X$ (True or False) using observations $O = \langle O_1,O_2,\ldots,O_n\rangle$ , mutually independent given X. I also have a ML algorithm that takes an observation $o_i$ and learns to predict a score $s_i$ which, I imagine, is an estimation of the probability of X being True, $\forall i, s_i \approx P(X=T\mid O_i=o_i)$ . Now, I want to compute the probability of $P(X=T\mid O=o)$ since I have multiple observations that should improve the final score by fusing the estimated probabilities given by the ML algorithm. Using Bayes formula I get: $$P(X=T\mid O=o) = \frac{P(O=o_1,o_2,\ldots,o_n\mid X=T)P(X=T)}{P(O=o_1,o_2,\ldots,o_n\mid X=T)P(X=T)+P(O=o_1,o_2,\ldots,o_t\mid X=F)P(X=F)}$$ And since I can now separate each observation probabilities since they are independent given $X$ , I get: $$P(X=T\mid O=o) = \frac{P(X=T)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=T)}{P(X=T)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=T)+P(X=F)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=F)}$$ But now here comes a problem, I can't put a value on $P(o_i\mid X)$ , I only have $s_i \approx P(X=T\mid O_i=o_i)$ and the priors $P(X)$ , so I use Bayes formula once again on $P(o_i\mid X)$ . It seems to go well, the $P(O_i=o_i)$ are also simplified, but at the end I get this: $$P(X=T\mid O=o) \approx \frac{P(X=T)^{-n+1}{\displaystyle\prod_{i}^{n}s_i}}{P(X=T)^{-n+1}\displaystyle\prod_{i}^{n}{s_i} + P(X=F)^{-n+1}{\displaystyle\prod_{i}^{n}(1-s_i)}}$$ It seems like a nice formula, and has nice properties (for instance, predicted scores of 0.5 are neutral to the final posterior probability, given $n$ is constant or given uninformative priors). Unfortunately, it starts to look very wrong once you play with the prior. If you look closely, the priors $P(X)$ are driving the final probability toward the opposite probability. For instance, with a prior $P(X=T)=0.9$ , the final probability goes towards $0$ which is very weird since it seems to me that priors shouldn't work like this at all. However, the formula seems to work quite well when I set $P(X=T)=P(X=F)=0.5$ and doesn't have the usual downsides of computing the average of the score probabilities. So, my questions are: Is there something wrong with the proof, the assumptions or with the interpretation, or is this a correct formula with prior behaving counter-intuitively? Is there already a proof of a formula for doing probability fusion like this? And also, are there other cases of prior driving the posterior to the opposite probability?","I am trying to infer the probability distribution of a binary variable (True or False) using observations , mutually independent given X. I also have a ML algorithm that takes an observation and learns to predict a score which, I imagine, is an estimation of the probability of X being True, . Now, I want to compute the probability of since I have multiple observations that should improve the final score by fusing the estimated probabilities given by the ML algorithm. Using Bayes formula I get: And since I can now separate each observation probabilities since they are independent given , I get: But now here comes a problem, I can't put a value on , I only have and the priors , so I use Bayes formula once again on . It seems to go well, the are also simplified, but at the end I get this: It seems like a nice formula, and has nice properties (for instance, predicted scores of 0.5 are neutral to the final posterior probability, given is constant or given uninformative priors). Unfortunately, it starts to look very wrong once you play with the prior. If you look closely, the priors are driving the final probability toward the opposite probability. For instance, with a prior , the final probability goes towards which is very weird since it seems to me that priors shouldn't work like this at all. However, the formula seems to work quite well when I set and doesn't have the usual downsides of computing the average of the score probabilities. So, my questions are: Is there something wrong with the proof, the assumptions or with the interpretation, or is this a correct formula with prior behaving counter-intuitively? Is there already a proof of a formula for doing probability fusion like this? And also, are there other cases of prior driving the posterior to the opposite probability?","X O = \langle O_1,O_2,\ldots,O_n\rangle o_i s_i \forall i, s_i \approx P(X=T\mid O_i=o_i) P(X=T\mid O=o) P(X=T\mid O=o) = \frac{P(O=o_1,o_2,\ldots,o_n\mid X=T)P(X=T)}{P(O=o_1,o_2,\ldots,o_n\mid X=T)P(X=T)+P(O=o_1,o_2,\ldots,o_t\mid X=F)P(X=F)} X P(X=T\mid O=o) = \frac{P(X=T)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=T)}{P(X=T)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=T)+P(X=F)\displaystyle\prod_{i}^{n}P(O_i=o_i\mid X=F)} P(o_i\mid X) s_i \approx P(X=T\mid O_i=o_i) P(X) P(o_i\mid X) P(O_i=o_i) P(X=T\mid O=o) \approx \frac{P(X=T)^{-n+1}{\displaystyle\prod_{i}^{n}s_i}}{P(X=T)^{-n+1}\displaystyle\prod_{i}^{n}{s_i} + P(X=F)^{-n+1}{\displaystyle\prod_{i}^{n}(1-s_i)}} n P(X) P(X=T)=0.9 0 P(X=T)=P(X=F)=0.5","['probability', 'statistics', 'statistical-inference', 'solution-verification', 'bayesian']"
41,Show the charge of an electron?,Show the charge of an electron?,,"The charge a on one electron is too small to measure. However, one can make measurements of the current I passing through a detector. If N is the number of electrons passing through the detector in one second, then I = a N. Assume N is Poisson. Show that the charge on one electron is given by Variance( I )/Expected Value( I ). What I got so far... since a is the charge of 1 electron, we want to solve a , where a = I /N. And $N$ is poisson, and the the pmf of a poisson random variable with rate $\lambda$ is $(1/x!) \lambda^x e^{-\lambda}$ . So substituting it in for $N$ , now we have $I/\text{(that whole jargon)}$ . I'm confused on how to further this to get Variance( I )/Expected Value( I ). (This is an exercise in my intro to stats book in the random variables section, but I'm completely lost on how to reduce this)","The charge a on one electron is too small to measure. However, one can make measurements of the current I passing through a detector. If N is the number of electrons passing through the detector in one second, then I = a N. Assume N is Poisson. Show that the charge on one electron is given by Variance( I )/Expected Value( I ). What I got so far... since a is the charge of 1 electron, we want to solve a , where a = I /N. And is poisson, and the the pmf of a poisson random variable with rate is . So substituting it in for , now we have . I'm confused on how to further this to get Variance( I )/Expected Value( I ). (This is an exercise in my intro to stats book in the random variables section, but I'm completely lost on how to reduce this)",N \lambda (1/x!) \lambda^x e^{-\lambda} N I/\text{(that whole jargon)},"['statistics', 'random-variables']"
42,Find the variance of $R$ where $R$ = $Z_1 + \dotsb + Z_d$ and $Z_i = |X_i - Y_i|^2$,Find the variance of  where  =  and,R R Z_1 + \dotsb + Z_d Z_i = |X_i - Y_i|^2,"So I am trying to find the Variance $R$ where $R$ = $Z_1 + \dotsb + Z_d$ and $Z_i = |X_i - Y_i|^2$ $X$ and $Y$ are d-dimensional points from a d-dimensional unit cube with a uniform distribution: $X,Y \in [0,1]^d$ which we can view this as drawing random variables $X_1, . . . , X_d$ and $Y_1, . . . , Y_d$ independently and uniformly from $[0, 1]$ Assuming that this is correct: \begin{align*} R &= Z_1 + \dotsb+ Z_d\\ &= d  \cdot Z \\ R^2 &= d^2 \cdot Z^2\\ E[R^2] &= d^2 \cdot E[Z^2]\\ &=\frac{12d^2}{180}\\ &=\frac{d^2}{15} \end{align*} and with the information from: Expectation and variance of the squared distance between $X$ and $Y$ I was able to get to: \begin{align*} Var(R) &= E[R^2]-(E[R])^2\\ &=\frac{d^2}{15}-\frac{d^2}{36} \end{align*} Is this even correct? Or did I make a mistake along the way",So I am trying to find the Variance where = and and are d-dimensional points from a d-dimensional unit cube with a uniform distribution: which we can view this as drawing random variables and independently and uniformly from Assuming that this is correct: and with the information from: Expectation and variance of the squared distance between $X$ and $Y$ I was able to get to: Is this even correct? Or did I make a mistake along the way,"R R Z_1 + \dotsb + Z_d Z_i = |X_i - Y_i|^2 X Y X,Y \in [0,1]^d X_1, . . . , X_d Y_1, . . . , Y_d [0, 1] \begin{align*}
R &= Z_1 + \dotsb+ Z_d\\
&= d  \cdot Z \\
R^2 &= d^2 \cdot Z^2\\
E[R^2] &= d^2 \cdot E[Z^2]\\
&=\frac{12d^2}{180}\\
&=\frac{d^2}{15}
\end{align*} \begin{align*}
Var(R) &= E[R^2]-(E[R])^2\\
&=\frac{d^2}{15}-\frac{d^2}{36}
\end{align*}","['statistics', 'expected-value', 'uniform-distribution', 'variance']"
43,Conjugate prior for the Weibull distribution,Conjugate prior for the Weibull distribution,,"On Wikipedia we find a nice overview on conjugate prior distributions. I am interested in the conjugate prior for a random variable $X$ with density $$f(x;\lambda,k) = \begin{cases} \frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} & x \geq 0 ,\\ 0 & x<0, \end{cases}$$ the Weibull. With known rate parameter $k$ the inverse Gamma distribution with density $$g(\lambda; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} (1/\lambda)^{\alpha + 1}\exp\left(-\beta/\lambda\right)$$ is a conjugate prior for $\lambda$ . The posterior distribution of $\lambda$ then is apparently $g$ with $\alpha_*=\alpha+n$ and $\beta*=\beta+\sum_i x_i^k$ (with $i=1,\ldots,n$ ). I cannot seem to be able to show this. Is this result true? And is there a conjugate prior for $k$ as well?",On Wikipedia we find a nice overview on conjugate prior distributions. I am interested in the conjugate prior for a random variable with density the Weibull. With known rate parameter the inverse Gamma distribution with density is a conjugate prior for . The posterior distribution of then is apparently with and (with ). I cannot seem to be able to show this. Is this result true? And is there a conjugate prior for as well?,"X f(x;\lambda,k) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda}\right)^{k-1}e^{-(x/\lambda)^{k}} & x \geq 0 ,\\
0 & x<0,
\end{cases} k g(\lambda; \alpha, \beta)
= \frac{\beta^\alpha}{\Gamma(\alpha)}
(1/\lambda)^{\alpha + 1}\exp\left(-\beta/\lambda\right) \lambda \lambda g \alpha_*=\alpha+n \beta*=\beta+\sum_i x_i^k i=1,\ldots,n k","['statistics', 'bayesian']"
44,Equivalence of different definitions of sup in expectations,Equivalence of different definitions of sup in expectations,,"So the context of my question comes from the proof of Theorem 7.3.1(Norms of Gaussian random matrices) from High Dimensional Probability by Vershynin. In particular assume $A$ is an $m$ by $n$ matrices with independent $\mathcal{N}(0,1)$ entries. Define $T=\mathbb{S}^{n-1}\times \mathbb{S}^{m-1}$ . Let $X_{uv}=\langle Au,  v\rangle$ where $u\in\mathbb{S}^{n-1}$ and $v\in \mathbb{S}^{m-1}$ . We know that the operator norm of $A$ is equivalently defined as $||A|| = \sup_{(u,v)\in T} X_{uv}$ . Now the book claims the following equivalence. $$E||A|| = \sup_{S\subset T} E \left(\sup_{(u,v)\in S} X_{uv}\right)$$ where the outer $sup$ is over all finite subsets $S$ of $T$ . I do not see why this is true at all. Could someone please explain? More generally, my concern is when it is true for a random process $X_t$ that $$E \sup_{t\in T} X_t= \sup_{S\subset T} E\left( \sup_{t\in S} X_t\right)$$ where again the outer $sup$ is over finite subsets $S$ of $T$ . I ask this because this is how Vershynin defines these expectations in the book by taking the sup over finite subsets to avoid measurability issues. I was wondering what merits these definitions because it seems to be commonplace in a lot of introductory high dimensional statistics/probability books.","So the context of my question comes from the proof of Theorem 7.3.1(Norms of Gaussian random matrices) from High Dimensional Probability by Vershynin. In particular assume is an by matrices with independent entries. Define . Let where and . We know that the operator norm of is equivalently defined as . Now the book claims the following equivalence. where the outer is over all finite subsets of . I do not see why this is true at all. Could someone please explain? More generally, my concern is when it is true for a random process that where again the outer is over finite subsets of . I ask this because this is how Vershynin defines these expectations in the book by taking the sup over finite subsets to avoid measurability issues. I was wondering what merits these definitions because it seems to be commonplace in a lot of introductory high dimensional statistics/probability books.","A m n \mathcal{N}(0,1) T=\mathbb{S}^{n-1}\times \mathbb{S}^{m-1} X_{uv}=\langle Au,  v\rangle u\in\mathbb{S}^{n-1} v\in \mathbb{S}^{m-1} A ||A|| = \sup_{(u,v)\in T} X_{uv} E||A|| = \sup_{S\subset T} E \left(\sup_{(u,v)\in S} X_{uv}\right) sup S T X_t E \sup_{t\in T} X_t= \sup_{S\subset T} E\left( \sup_{t\in S} X_t\right) sup S T","['real-analysis', 'probability', 'probability-theory', 'statistics']"
45,Dependency for coin toss,Dependency for coin toss,,"Hello I have a question regarding dependency. If a fair coin is tossed 6 times, and there is two events: A-there are more heads than tails given that B-the 6th toss is a head. We are trying to find the conditional probability. However, I am confused as to whether these events are independent or dependent. I believe they are dependent because if B is true, then there needs to be at least 3 heads in the first 5 tosses. In other words, the minimum heads in the first 5 depend on whether B is true or not. Is this correct logic?","Hello I have a question regarding dependency. If a fair coin is tossed 6 times, and there is two events: A-there are more heads than tails given that B-the 6th toss is a head. We are trying to find the conditional probability. However, I am confused as to whether these events are independent or dependent. I believe they are dependent because if B is true, then there needs to be at least 3 heads in the first 5 tosses. In other words, the minimum heads in the first 5 depend on whether B is true or not. Is this correct logic?",,"['probability', 'statistics', 'independence']"
46,Can we extract back the value of a vector after convolution with another vector whose first value and absolute values are only known,Can we extract back the value of a vector after convolution with another vector whose first value and absolute values are only known,,"Assume we have Hadamard-Walsh matrix whose size is 4 x 4 as below: And we have random vector, for example: $h=[2, 3,   1,   5]$ . $S$ is the result of convolution operations  between vectors $h$ and one row chosen randomly from the matrix $W$ , let's choose row 2 which is $W_2 = [1, -1, 1, -1]$ . So, the result of $S = h*W_2 = [2,  1,  0,  5,  -7,  4,  -5]$ , where $*$ denote the convolution operation. What I am looking for is to estimate which row from matrix $W$ was convoluted with $h$ based on $S$ , or in other words the possibility to calculate $h$ . As known, that can be done since convolution is nothing but multiplication of toeplitz matrix with a vector. For example, we can build the toeplitz matrix of $h$ , and then calculate the value of $h$ , in case if $h$ has more than one solutions, choose the value which make the equation equal to $|W| = 1$ . For example, taken the case of Hadamard-Walsh matrix whose size is 2 x 2 as below: and $h$ is generated randomly $h = [2, 4]$ , so in that case the result of convolution between $W_2: [1, -1]$ and $h$ is : $S = [2,     2,    -4]$ , Hence, we can calculate the value of $h$ and $W_2$ based on $S$ by creating $S = toelitz_{ matrix} *  W_2$ as follows: Therefore, we should have three equations : 1- $h_1 W_{21} = 2$ ---> since $W_{21}$ is equals to 1 in all cases, so $h_1 = 2$ , $W_{21} = 1$ . 2- $h_2 W_{21} + h_1 W_{22} = 2$ ---> $W_{21}$ and $h_1$ are already known from equation 1, then the equation (2) will be $h_2 + 2 W_{22} = 2$ ---> this is equation 2 3- $h_2 W_{22} = -4$ , ---> this is equation 3 Based on equations 2 and 3, we conclude that either $h_2 = 4$ or $h_2 = -2$ , therefore, $h_2 = 4$ since we know that $|W_{22}| = 1$ , but we don't know it's sign, but based on $h_2 = 4$ and equations 3, we knew that $W_{22} = -1$ . So, as seen above, we could extract the vector $h$ based on first value of vector $W_2$ and the known absolute values of matrix $W$ . My question, Is there an easier method or known algorithm (method) can implemented in that case to avoid the higher complexity resulted in case if size matrix $W$ and length of vector $h$ are big? Or can machine or deep learning algorithm can be used to implemented that easily? Thank you in advance.","Assume we have Hadamard-Walsh matrix whose size is 4 x 4 as below: And we have random vector, for example: . is the result of convolution operations  between vectors and one row chosen randomly from the matrix , let's choose row 2 which is . So, the result of , where denote the convolution operation. What I am looking for is to estimate which row from matrix was convoluted with based on , or in other words the possibility to calculate . As known, that can be done since convolution is nothing but multiplication of toeplitz matrix with a vector. For example, we can build the toeplitz matrix of , and then calculate the value of , in case if has more than one solutions, choose the value which make the equation equal to . For example, taken the case of Hadamard-Walsh matrix whose size is 2 x 2 as below: and is generated randomly , so in that case the result of convolution between and is : , Hence, we can calculate the value of and based on by creating as follows: Therefore, we should have three equations : 1- ---> since is equals to 1 in all cases, so , . 2- ---> and are already known from equation 1, then the equation (2) will be ---> this is equation 2 3- , ---> this is equation 3 Based on equations 2 and 3, we conclude that either or , therefore, since we know that , but we don't know it's sign, but based on and equations 3, we knew that . So, as seen above, we could extract the vector based on first value of vector and the known absolute values of matrix . My question, Is there an easier method or known algorithm (method) can implemented in that case to avoid the higher complexity resulted in case if size matrix and length of vector are big? Or can machine or deep learning algorithm can be used to implemented that easily? Thank you in advance.","h=[2, 3,   1,   5] S h W W_2 = [1, -1, 1, -1] S = h*W_2 = [2,  1,  0,  5,  -7,  4,  -5] * W h S h h h h |W| = 1 h h = [2, 4] W_2: [1, -1] h S = [2,     2,    -4] h W_2 S S = toelitz_{ matrix} *  W_2 h_1 W_{21} = 2 W_{21} h_1 = 2 W_{21} = 1 h_2 W_{21} + h_1 W_{22} = 2 W_{21} h_1 h_2 + 2 W_{22} = 2 h_2 W_{22} = -4 h_2 = 4 h_2 = -2 h_2 = 4 |W_{22}| = 1 h_2 = 4 W_{22} = -1 h W_2 W W h","['linear-algebra', 'statistics', 'machine-learning', 'signal-processing']"
47,Convergence in distribution: Proof strategy,Convergence in distribution: Proof strategy,,"Let $X_i$ and $Y_i$ , $i\in\mathbb{N}$ , be random variables. I want to show that (asymptotic normality) $$\sqrt{n}\bigg(\frac{1}{d_n}\sum_{k=1}^{d_n}X_k +Y_k\bigg)\overset{d}{\to} N(0,\sigma^2), n\to\infty.$$ The problem is that, in my case, $X_t$ is an ugly expression, and I'm struggling to  determine the form of the variance $\sigma^2$ . Although, I know that $\sqrt{n}/d_n\sum_{k=1}^{d_n}X_k\overset{p}{\to} 0$ , i.e., this term is $o_p(1)$ . In addition, $\sqrt{n}/d_n\sum_{k=1}^{d_n}Y_k\overset{d}{\to} N(0,\sigma_1^2)$ , where $\sigma_1^2$ is completely known. Well, Slutsky's theorem says that if $Z_1,Z_2$ are random variables such that $Z_1\overset{d}{\to}Z, Z_2\overset{p}{\to}c $ then $Z_1+Z_2\overset{d}{\to}c+Z$ , for some constant $c$ . I conclude that $$\sqrt{n}\bigg(\frac{1}{d_n}\sum_{k=1}^{d_n}X_k +Y_k\bigg)\overset{d}{\to} N(0,\sigma_1^2), n\to\infty.$$ I suspect that there is something wrong with this argument since I simply ignored the dependence/covariance of $X_k$ and $Y_k$ . Can you give me feedbacks on this? Is there somthing wrong with this? Thanks in advance!","Let and , , be random variables. I want to show that (asymptotic normality) The problem is that, in my case, is an ugly expression, and I'm struggling to  determine the form of the variance . Although, I know that , i.e., this term is . In addition, , where is completely known. Well, Slutsky's theorem says that if are random variables such that then , for some constant . I conclude that I suspect that there is something wrong with this argument since I simply ignored the dependence/covariance of and . Can you give me feedbacks on this? Is there somthing wrong with this? Thanks in advance!","X_i Y_i i\in\mathbb{N} \sqrt{n}\bigg(\frac{1}{d_n}\sum_{k=1}^{d_n}X_k +Y_k\bigg)\overset{d}{\to} N(0,\sigma^2), n\to\infty. X_t \sigma^2 \sqrt{n}/d_n\sum_{k=1}^{d_n}X_k\overset{p}{\to} 0 o_p(1) \sqrt{n}/d_n\sum_{k=1}^{d_n}Y_k\overset{d}{\to} N(0,\sigma_1^2) \sigma_1^2 Z_1,Z_2 Z_1\overset{d}{\to}Z, Z_2\overset{p}{\to}c  Z_1+Z_2\overset{d}{\to}c+Z c \sqrt{n}\bigg(\frac{1}{d_n}\sum_{k=1}^{d_n}X_k +Y_k\bigg)\overset{d}{\to} N(0,\sigma_1^2), n\to\infty. X_k Y_k","['probability-theory', 'statistics', 'stochastic-processes', 'asymptotics']"
48,Maximum Likelihood Estimator for Logarithmic Distribution,Maximum Likelihood Estimator for Logarithmic Distribution,,"I am trying to calculate the MLE for the logarithmic distribution. It holds $$ P(X=k) = -\frac{p^k}{k \cdot \ln(1-p} $$ Thus, the ML function is $$L_p(X_1,\dots, X_n) = \prod_{i=1}^{n} -\frac{p^{x_i}}{x_i \cdot \ln(1-p)} = p^{\sum_{i=1}^n x_i} \left(\frac{1}{\ln(1-p)}\right)^n \prod_{i=1}^n -\frac{1}{x_i} $$ and the log likelihood function is \begin{align} \log L_p(X_1,\dots,X_n)& = \sum_{i=1}^n x_i \cdot \log(p) + n \cdot \log\left(\frac{1}{\log(1-p)}\right) + \log\left(\prod_{i=1}^n -\frac{1}{x_i}\right)  \\&= \sum_{i=1}^n x_i \cdot \log(p) + n \cdot -\log(\log(1-p)) + \log\left(\prod_{i=1}^n -\frac{1}{x_i}\right) \end{align} So: $$\frac{\partial L_p}{\partial p} = \frac{1}{p} \sum_{i=1}^n x_i + n \frac{1}{\log(1-p)(1-p)} \overset{!}{=} 0$$ This is equivalent to: $$\frac{1}{n} \sum_{i=1}^n x_i = - \frac{p}{\log(1-p)(1-p)}$$ Now I don't know how to go on. How do I get the estimator for $p$ ? Thanks in advance, for helping !","I am trying to calculate the MLE for the logarithmic distribution. It holds Thus, the ML function is and the log likelihood function is So: This is equivalent to: Now I don't know how to go on. How do I get the estimator for ? Thanks in advance, for helping !"," P(X=k) = -\frac{p^k}{k \cdot \ln(1-p}  L_p(X_1,\dots, X_n) = \prod_{i=1}^{n} -\frac{p^{x_i}}{x_i \cdot \ln(1-p)} = p^{\sum_{i=1}^n x_i} \left(\frac{1}{\ln(1-p)}\right)^n \prod_{i=1}^n -\frac{1}{x_i}  \begin{align}
\log L_p(X_1,\dots,X_n)& = \sum_{i=1}^n x_i \cdot \log(p) + n \cdot \log\left(\frac{1}{\log(1-p)}\right) + \log\left(\prod_{i=1}^n -\frac{1}{x_i}\right) 
\\&= \sum_{i=1}^n x_i \cdot \log(p) + n \cdot -\log(\log(1-p)) + \log\left(\prod_{i=1}^n -\frac{1}{x_i}\right)
\end{align} \frac{\partial L_p}{\partial p} = \frac{1}{p} \sum_{i=1}^n x_i + n \frac{1}{\log(1-p)(1-p)} \overset{!}{=} 0 \frac{1}{n} \sum_{i=1}^n x_i = - \frac{p}{\log(1-p)(1-p)} p","['statistics', 'probability-distributions', 'maximum-likelihood', 'parameter-estimation']"
49,The set of bounded functions are dense in Hilbert Space?,The set of bounded functions are dense in Hilbert Space?,,"I'm reading the book ""Semiparametric Theory and Missing Data"" by Anastasios A. Tsiatis and I'm having trouble trying to understand the following fact: Let $Z$ be a random variable. We define $\mathcal{H}$ as the Hilbert space of q-dimensional mean-zero real-valued functions. We also require that the covariance matrix is nonsingular. That is, $\mathcal{H} = \{ h : supp(Z) \rightarrow \mathbb{R}^{q} \ | \ \mathbb{E}[h(Z)] = 0^{q \times 1}, \mathbb{E}[hh^T]^{-1} \text{exists} \}$ The space $\mathcal{H}$ is equipped with the covariance inner product $\langle h_1, h_2 \rangle \triangleq \mathbb{E}[h_1^T h_2]$ . On page 69, the author mentioned that ""any element of $\mathcal{H}$ can be approximated by a sequence of bounded $h$ "" (or equivalently, the set of bounded functions is dense in $\mathcal{H}$ ). Does anyone have any idea why this is true?","I'm reading the book ""Semiparametric Theory and Missing Data"" by Anastasios A. Tsiatis and I'm having trouble trying to understand the following fact: Let be a random variable. We define as the Hilbert space of q-dimensional mean-zero real-valued functions. We also require that the covariance matrix is nonsingular. That is, The space is equipped with the covariance inner product . On page 69, the author mentioned that ""any element of can be approximated by a sequence of bounded "" (or equivalently, the set of bounded functions is dense in ). Does anyone have any idea why this is true?","Z \mathcal{H} \mathcal{H} = \{ h : supp(Z) \rightarrow \mathbb{R}^{q} \ | \ \mathbb{E}[h(Z)] = 0^{q \times 1}, \mathbb{E}[hh^T]^{-1} \text{exists} \} \mathcal{H} \langle h_1, h_2 \rangle \triangleq \mathbb{E}[h_1^T h_2] \mathcal{H} h \mathcal{H}","['functional-analysis', 'statistics']"
50,The conditional probability of the evidence on a crime scene?,The conditional probability of the evidence on a crime scene?,,"From page 88, Introduction to Probability (2019 2 edn) by Jessica Hwang and Joseph K. Blitzstein. Suppose that there are $5$ blood types in the population, named type $1$ through type $5$ , with probabilities $p_1, p_2,\cdots ,p_5$ . A crime was committed by two individuals. A suspect,who has blood type $1$ , has prior probability $p$ of being guilty. At the crime scene, blood evidence is collected, which shows that one of the criminals has type $1$ and the other has type $2$ . Find the posterior probability that the suspect is guilty, given the evidence. Does the evidence make it more likely or less likely that the suspect is guilty, or does this depend on the values of the parameters $p, p_1,. . . , p_5$ ? If it depends, give a simple criterion for when the evidence makes it more likely that the suspect is guilty. Proposed solution : Let $A_1$ be the event that the suspect (with blood type 1) is guilty. Let $X$ be the event that one of the criminals have blood type 1 and the other has type 2.  We can then use Bayes' rule to define $$ \begin{aligned}P(A_1|X) &=\frac{P(X|A_1)P(A_1)}{P(X)} \\         &=\frac{P(X|A_1)P(A_1)}{P(X|A_1)P(A_1)+P(X|A_1^c)P(A_1^c)} \\         &=\frac{P(X|A_1)p}{P(X|A_1)p+P(X|A_1^c)(1-p)} \\         &=\frac{P(X|A_1)p}{P(X|A_1)p+P(X|A_1^c)(1-p)} \\         &=\frac{1p}{1p_2p+2p_1p_2(1-p)} \\         \end{aligned} $$ I have two questions on what happens on the last line? The last line I got from the following source here . First ,  where does this equality come from $P(X|A_1) = 1p_2$ ? Let $X_1$ be the event that the first criminal's blood type is blood type 1, and so $P(X_1)=p_1$ if the criminal is unknown. And, let $X_2$ be the event that the second criminal's blood type is blood type 2, so $P(X_2)=p_2$ if that criminal is still unknown.  Assume also that the two criminal's blood type is independent. Is it then that $P(X|A_1) = P(X_1\cap X_2|A_1) = P(X_1|A_1)P(X_2|A_1)=1p_2$ ? In other words, $P(X_1|A_1)=1$ since the suspect is now assumed to be the criminal, and $ P(X_2|A_1)=p_2$ since the second criminal is unknown and thus we equate this with the population parameter. Second ,  where does this other equality come from $P(X|A_1^c) = 2p_1p_2$ ? Here, with the notation and logic in my first question, I regard the following to be true $P(X|A_1^c) = P(X_1\cap X_2|A_1^c) = P(X_1|A_1^c)P(X_2|A_1^c) = p_1p_2$ . Hence, since the two criminals are unknown, the probability of the evidence is just the population parameters occurring simultaneously (the blood of the two criminals being spilled on the crime scene). In other words, where does the 2 come from?","From page 88, Introduction to Probability (2019 2 edn) by Jessica Hwang and Joseph K. Blitzstein. Suppose that there are blood types in the population, named type through type , with probabilities . A crime was committed by two individuals. A suspect,who has blood type , has prior probability of being guilty. At the crime scene, blood evidence is collected, which shows that one of the criminals has type and the other has type . Find the posterior probability that the suspect is guilty, given the evidence. Does the evidence make it more likely or less likely that the suspect is guilty, or does this depend on the values of the parameters ? If it depends, give a simple criterion for when the evidence makes it more likely that the suspect is guilty. Proposed solution : Let be the event that the suspect (with blood type 1) is guilty. Let be the event that one of the criminals have blood type 1 and the other has type 2.  We can then use Bayes' rule to define I have two questions on what happens on the last line? The last line I got from the following source here . First ,  where does this equality come from ? Let be the event that the first criminal's blood type is blood type 1, and so if the criminal is unknown. And, let be the event that the second criminal's blood type is blood type 2, so if that criminal is still unknown.  Assume also that the two criminal's blood type is independent. Is it then that ? In other words, since the suspect is now assumed to be the criminal, and since the second criminal is unknown and thus we equate this with the population parameter. Second ,  where does this other equality come from ? Here, with the notation and logic in my first question, I regard the following to be true . Hence, since the two criminals are unknown, the probability of the evidence is just the population parameters occurring simultaneously (the blood of the two criminals being spilled on the crime scene). In other words, where does the 2 come from?","5 1 5 p_1, p_2,\cdots ,p_5 1 p 1 2 p, p_1,. . . , p_5 A_1 X 
\begin{aligned}P(A_1|X) &=\frac{P(X|A_1)P(A_1)}{P(X)} \\         &=\frac{P(X|A_1)P(A_1)}{P(X|A_1)P(A_1)+P(X|A_1^c)P(A_1^c)} \\         &=\frac{P(X|A_1)p}{P(X|A_1)p+P(X|A_1^c)(1-p)} \\         &=\frac{P(X|A_1)p}{P(X|A_1)p+P(X|A_1^c)(1-p)} \\         &=\frac{1p}{1p_2p+2p_1p_2(1-p)} \\         \end{aligned}
 P(X|A_1) = 1p_2 X_1 P(X_1)=p_1 X_2 P(X_2)=p_2 P(X|A_1) = P(X_1\cap X_2|A_1) = P(X_1|A_1)P(X_2|A_1)=1p_2 P(X_1|A_1)=1  P(X_2|A_1)=p_2 P(X|A_1^c) = 2p_1p_2 P(X|A_1^c) = P(X_1\cap X_2|A_1^c) = P(X_1|A_1^c)P(X_2|A_1^c) = p_1p_2","['probability', 'statistics', 'conditional-probability']"
51,Extension of binary classification to multi-class classification,Extension of binary classification to multi-class classification,,"Multi-class classification is a generalization of logistic regression wherein we are dealing with binary classification. The latter problem is a setting where a number should be mapped to either $0$ or $1$ . Hence, Logistic regression needs to convert the output of a neural network ( $\hat{y}$ ) to to either $0$ or $1$ to decide. Therefore it use the sigmoid function defined as $$\sigma(\hat{y})=\frac{e^\hat{y}}{1+ e^\hat{y}}\tag{1}$$ where $\hat{y} \in \mathbb{R}$ is the output of the network. On the other hand, Multi-class classification uses the softmax function to decide which is defined as $$\text{softmax}(\hat{\textbf{y}})=\frac{e^{\hat{\textbf{y}}_i}}{\sum_{i=1}^{n}e^{\hat{\textbf{y}}_i}}\tag{2}$$ where $\hat{\textbf{y}} \in \mathbb{R}^n$ is the output of the network. Question : How can we can play with $(1)$ to get $(2)$ algebraically or vice versa? If we start with $(1)$ how one can get rid of $1$ in denominator? or if we start with $(2)$ how we can generate $1$ in the denominator where $n=2$ .","Multi-class classification is a generalization of logistic regression wherein we are dealing with binary classification. The latter problem is a setting where a number should be mapped to either or . Hence, Logistic regression needs to convert the output of a neural network ( ) to to either or to decide. Therefore it use the sigmoid function defined as where is the output of the network. On the other hand, Multi-class classification uses the softmax function to decide which is defined as where is the output of the network. Question : How can we can play with to get algebraically or vice versa? If we start with how one can get rid of in denominator? or if we start with how we can generate in the denominator where .",0 1 \hat{y} 0 1 \sigma(\hat{y})=\frac{e^\hat{y}}{1+ e^\hat{y}}\tag{1} \hat{y} \in \mathbb{R} \text{softmax}(\hat{\textbf{y}})=\frac{e^{\hat{\textbf{y}}_i}}{\sum_{i=1}^{n}e^{\hat{\textbf{y}}_i}}\tag{2} \hat{\textbf{y}} \in \mathbb{R}^n (1) (2) (1) 1 (2) 1 n=2,['probability']
52,statistic $t$-test for $2$ means,statistic -test for  means,t 2,"I'm just doing the exercises from Stock&Watson ""Introduction to econometrics"". $3.12$ is about comparing men and women salaries mean for men: $8200,$ SD $= 450, n_1=120$ mean for women: $7900,$ SD $=520, n_2=150$ I took $t= \dfrac{X_1-X_2}{\frac{\text{spooled}}{0.5(n_1+n_2)}}$ I obtained $t=5.03$ I know I have to reject H $0.$ They're asking me to calculate $p$ -value. I looked for it in the tables. There is till $2.9.$ How to calculate $p$ -value in that case? They're asking if the company is guilty of gender discrimination in its compensation policies. If I rejected H $0$ should I claim they are guilty?","I'm just doing the exercises from Stock&Watson ""Introduction to econometrics"". is about comparing men and women salaries mean for men: SD mean for women: SD I took I obtained I know I have to reject H They're asking me to calculate -value. I looked for it in the tables. There is till How to calculate -value in that case? They're asking if the company is guilty of gender discrimination in its compensation policies. If I rejected H should I claim they are guilty?","3.12 8200, = 450, n_1=120 7900, =520, n_2=150 t= \dfrac{X_1-X_2}{\frac{\text{spooled}}{0.5(n_1+n_2)}} t=5.03 0. p 2.9. p 0",['statistics']
53,Copula simulation,Copula simulation,,"Let $(X_1,X_2)$ be a bivariate random vector where $X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2)$ and $X_2 \sim \mathcal{E}(\lambda)$ . We suppose that the dependence function is given by the following copula: $$ C(u_1,u_2) = u_1u_2(1 + \theta (1 - u_1)(1 - u_2))$$ where $\theta \in [-1,1]$ . I would like to simulate the random vector but i can't achieve to do so. My idea is to start by simulating $(U_1,U_2)$ (uniforms in $[0,1]$ ) which have $C$ as cdf : Simulate $U_1$ then simulate $U_2 | U_1$ which has the following cdf : \begin{align*} \mathbb{P}(U_2 \leq u_2 | U_1 = u_1) & = \lim_{\epsilon \to 0} \frac{P(U_2 \leq u_2, U_1 \in [u_1, u_1 + \epsilon])}{P(U_1 \in [u_1, u_1 + \epsilon])} \\ & = \lim_{\epsilon \to 0} \frac{C(u_1+\epsilon,u_2) - C(u_1,u_2)}{\epsilon} \\ & = \partial_{u_1}C(u_1,u_2) \\  & = u_2(1+ \theta(1-u_1)(1-u_2)) -\theta u_1u_2(1-u_2) \\  & = \theta u_2 ^2(2u_1 - 1) + u_2(1 + \theta - 2\theta u_1) \end{align*} My idea is to simulate $U_2 | U_1$ by inverting $\mathbb{P}(U_2 \leq u_2 | U_1 = u_1)$ , but it doesn't seem to be invertible. Any other idea? Thanks","Let be a bivariate random vector where and . We suppose that the dependence function is given by the following copula: where . I would like to simulate the random vector but i can't achieve to do so. My idea is to start by simulating (uniforms in ) which have as cdf : Simulate then simulate which has the following cdf : My idea is to simulate by inverting , but it doesn't seem to be invertible. Any other idea? Thanks","(X_1,X_2) X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2) X_2 \sim \mathcal{E}(\lambda)  C(u_1,u_2) = u_1u_2(1 + \theta (1 - u_1)(1 - u_2)) \theta \in [-1,1] (U_1,U_2) [0,1] C U_1 U_2 | U_1 \begin{align*}
\mathbb{P}(U_2 \leq u_2 | U_1 = u_1) & = \lim_{\epsilon \to 0} \frac{P(U_2 \leq u_2, U_1 \in [u_1, u_1 + \epsilon])}{P(U_1 \in [u_1, u_1 + \epsilon])} \\
& = \lim_{\epsilon \to 0} \frac{C(u_1+\epsilon,u_2) - C(u_1,u_2)}{\epsilon} \\
& = \partial_{u_1}C(u_1,u_2) \\ 
& = u_2(1+ \theta(1-u_1)(1-u_2)) -\theta u_1u_2(1-u_2) \\ 
& = \theta u_2 ^2(2u_1 - 1) + u_2(1 + \theta - 2\theta u_1)
\end{align*} U_2 | U_1 \mathbb{P}(U_2 \leq u_2 | U_1 = u_1)","['probability', 'statistics', 'finance', 'copula']"
54,How to maximize Revenue subject to customer constraints?,How to maximize Revenue subject to customer constraints?,,"Imagine you have N people that want to buy your product. However, each person will buy your product if the price of your product is less than or equal to some price say T n (subscript). What is the price that maximizes your revenue? For example, say you have 3 people and that the first person will buy your product if its less than T1 = \$1 , the second person will buy your product if it is less than T2 = \$3 and the third person will buy your product if its less than T3 = \$5. If i set the price of my product to say $2. Then the first person will not buy my product since \$2 is larger than \$1, however the other two will buy my product and therefore giving a revenue of \$4. However, i can do better. You can easily see that the price that will maximize my revenue in this case is \$3 giving you a revenue of \$6. My question is that given any number of people with any ""constrains"" (T n ), what is the best price that will maximize my revenue? I tried to solve this problem analytically  but i couldn't. I think an approximate solution could probably be given using statistics. I wrote a python code to experiment with this problem and it seems like for a random set of Tn (the constrains that each person sets) the mean of that set is actually a close approximation to that price that maximizes revenue. However, sometimes the mean just differs a lot. Thank you for reading, if what i wrote before is not clear please tell so i can edit it.","Imagine you have N people that want to buy your product. However, each person will buy your product if the price of your product is less than or equal to some price say T n (subscript). What is the price that maximizes your revenue? For example, say you have 3 people and that the first person will buy your product if its less than T1 = \$1 , the second person will buy your product if it is less than T2 = \$3 and the third person will buy your product if its less than T3 = \$5. If i set the price of my product to say $2. Then the first person will not buy my product since \$2 is larger than \$1, however the other two will buy my product and therefore giving a revenue of \$4. However, i can do better. You can easily see that the price that will maximize my revenue in this case is \$3 giving you a revenue of \$6. My question is that given any number of people with any ""constrains"" (T n ), what is the best price that will maximize my revenue? I tried to solve this problem analytically  but i couldn't. I think an approximate solution could probably be given using statistics. I wrote a python code to experiment with this problem and it seems like for a random set of Tn (the constrains that each person sets) the mean of that set is actually a close approximation to that price that maximizes revenue. However, sometimes the mean just differs a lot. Thank you for reading, if what i wrote before is not clear please tell so i can edit it.",,"['calculus', 'statistics', 'optimization', 'calculus-of-variations', 'economics']"
55,"Find sample size given standard deviation, sample mean, confidence interval","Find sample size given standard deviation, sample mean, confidence interval",,"A machine is set up such that the average content of juice per bottle equals u. Assume that the population standard deviation is $5$ cl. A sample of 100 bottles yields to an average of $48$ cl. Calculate a $90\%$ and $95\%$ confidence interval for the average content. Suppose the sample size is unknown. What sample size is required to estimate the average contents to be within $0.5$ cl at the $95\%$ confidence level? For the first question I found that: $\alpha=10\%$ gives $\text{CI} = \bar x\pm t_{1-\alpha/2}\frac\sigma{\sqrt n}=48\pm t_{0.05}\frac5{\sqrt{100}}=(47.175,48.825)$ and similarly $\alpha=5\%$ gives $\text{CI} =48\pm t_{0.025}\frac5{\sqrt{100}}= (47.02,48.98)$ . I have difficulty regarding the second question. I have never faced such a question and don't really know how to tackle the problem.",A machine is set up such that the average content of juice per bottle equals u. Assume that the population standard deviation is cl. A sample of 100 bottles yields to an average of cl. Calculate a and confidence interval for the average content. Suppose the sample size is unknown. What sample size is required to estimate the average contents to be within cl at the confidence level? For the first question I found that: gives and similarly gives . I have difficulty regarding the second question. I have never faced such a question and don't really know how to tackle the problem.,"5 48 90\% 95\% 0.5 95\% \alpha=10\% \text{CI} = \bar x\pm t_{1-\alpha/2}\frac\sigma{\sqrt n}=48\pm t_{0.05}\frac5{\sqrt{100}}=(47.175,48.825) \alpha=5\% \text{CI} =48\pm t_{0.025}\frac5{\sqrt{100}}= (47.02,48.98)","['statistics', 'confidence-interval']"
56,Visualizing Conditional Gaussian,Visualizing Conditional Gaussian,,I am looking at a graph that depicts a conditional Gaussian: I understand what the titled red spheres mean - that the variables are somewhat are correlated with each other. I don't understand the significance of the blue line. I know it's related to conditional gaussian but I can't quite make sense of it. Could someone explain what the blue line means?,I am looking at a graph that depicts a conditional Gaussian: I understand what the titled red spheres mean - that the variables are somewhat are correlated with each other. I don't understand the significance of the blue line. I know it's related to conditional gaussian but I can't quite make sense of it. Could someone explain what the blue line means?,,"['probability', 'statistics', 'bayesian']"
57,Expectation as expectation of indicator in Hoeffding Identity,Expectation as expectation of indicator in Hoeffding Identity,,"I am confused by a step in the proof of the Hoeffding identity as provided in the book by Denuit, Dhaene, Goovaerts and Kaas . The following is a screen shot of the beginning of the proof: I am confused about the transition from the second last to last step here. If $X$ was a non-negative random variable, then it follows that $$ \mathbb{E}X = \mathbb{E}\left ( \int_0^{\infty} 1_{u \le X} du \right ) $$ but the result here seems to hold for non-negative random variables. A similar question was asked here , but the accepted solution is just for the non-negative case, unless I have missed something. I'm looking for a clear justification of the last step highlighted in red.","I am confused by a step in the proof of the Hoeffding identity as provided in the book by Denuit, Dhaene, Goovaerts and Kaas . The following is a screen shot of the beginning of the proof: I am confused about the transition from the second last to last step here. If was a non-negative random variable, then it follows that but the result here seems to hold for non-negative random variables. A similar question was asked here , but the accepted solution is just for the non-negative case, unless I have missed something. I'm looking for a clear justification of the last step highlighted in red.","X 
\mathbb{E}X = \mathbb{E}\left ( \int_0^{\infty} 1_{u \le X} du \right )
","['probability', 'probability-theory', 'statistics', 'expected-value', 'covariance']"
58,"Statistics , confidence interval","Statistics , confidence interval",,"I have a sample of $x_i$ where $ x_i =\xi + \eta$ , $\xi \sim N(0,\sigma^2)$ and $\eta \sim N(a,1)$ i.i.d. So I need to construct  confidence interval with confidence level $\gamma$ for $\sigma^2$ with unknown $a$ . My attempt is, I used the following statistic : $S^2 = \frac{\sum (x_i - \overline{x})^2}{n-1}$ but I get an interval which could be with negative endpoints.","I have a sample of where , and i.i.d. So I need to construct  confidence interval with confidence level for with unknown . My attempt is, I used the following statistic : but I get an interval which could be with negative endpoints.","x_i  x_i =\xi + \eta \xi \sim N(0,\sigma^2) \eta \sim N(a,1) \gamma \sigma^2 a S^2 = \frac{\sum (x_i - \overline{x})^2}{n-1}","['probability-theory', 'statistics']"
59,Smoothness and my typing speed,Smoothness and my typing speed,,"I practice typing on a site called keybr.com. I get statistics of my typing speed in graph format as well. Here, I guess the straight green line is a line fitted to my typing speed data. There is some function called 'Smoothness'. From Wikipedia, I see that smoothing filters noise and modifies some data. I see that as I change the value of smoothness, the line changes its slope and my typing speed apparently decreases when smoothness is high. Can anyone give an intuitive explanation of why does this happen? What is the correct/optimum amount of smoothness so that I get the truest trend of my typing speed over time? According to the graph, does my typing speed actually increase or decrease with time?","I practice typing on a site called keybr.com. I get statistics of my typing speed in graph format as well. Here, I guess the straight green line is a line fitted to my typing speed data. There is some function called 'Smoothness'. From Wikipedia, I see that smoothing filters noise and modifies some data. I see that as I change the value of smoothness, the line changes its slope and my typing speed apparently decreases when smoothness is high. Can anyone give an intuitive explanation of why does this happen? What is the correct/optimum amount of smoothness so that I get the truest trend of my typing speed over time? According to the graph, does my typing speed actually increase or decrease with time?",,"['statistics', 'graphing-functions', 'statistical-inference']"
60,Do mixed moments determine joint distribution?,Do mixed moments determine joint distribution?,,"Let $\vec{X}:=(X_1,X_2,\cdots,X_n)$ be an $n$ -dimensional random vector where $X_i$ takes values in $[N_i]:=\{0,1,\ldots,N_i\}$ for each $i=1,2,\ldots,n$ . Show that the distribution of $\vec{X}$ is uniquely determined by $$\left\lbrace\mathbb{E}\left[\prod_{i=1}^n X_i^{n_i}\right]\,:\,n_i\in[N_i],i=1,2,\ldots,n\right\rbrace.$$",Let be an -dimensional random vector where takes values in for each . Show that the distribution of is uniquely determined by,"\vec{X}:=(X_1,X_2,\cdots,X_n) n X_i [N_i]:=\{0,1,\ldots,N_i\} i=1,2,\ldots,n \vec{X} \left\lbrace\mathbb{E}\left[\prod_{i=1}^n X_i^{n_i}\right]\,:\,n_i\in[N_i],i=1,2,\ldots,n\right\rbrace.","['linear-algebra', 'probability', 'statistics', 'probability-distributions']"
61,Derivative of $\text{Var}(a)$,Derivative of,\text{Var}(a),"Given that $$h(a) = (\mathbb E[a \bar X - \mu])^2 + \text{Var} (a \bar X).$$ I was asked to find the first and second derivative of the function $h(a)$ in respect to $a$ . I did break the function into multiple of pieces: $$h(a) = f(g[a]) + z(a).$$ Thus, $$h'(a) = f'(g[a])g'(a) + z'(a).$$ I only have found the first part of the derivative $f'(g[a])g'(a)$ , but I couldn't find the other part $z'(a)$ . What I am stuck on is the derivative of $\text{Var}(a)$ . Any hints?","Given that I was asked to find the first and second derivative of the function in respect to . I did break the function into multiple of pieces: Thus, I only have found the first part of the derivative , but I couldn't find the other part . What I am stuck on is the derivative of . Any hints?",h(a) = (\mathbb E[a \bar X - \mu])^2 + \text{Var} (a \bar X). h(a) a h(a) = f(g[a]) + z(a). h'(a) = f'(g[a])g'(a) + z'(a). f'(g[a])g'(a) z'(a) \text{Var}(a),"['calculus', 'statistics', 'summation', 'variance']"
62,The Correlation of two Random Variables,The Correlation of two Random Variables,,"I would expect the answer to the problem below to be at least $\frac{1}{2}$ . However, it is not. Therefore, I am thinking I did something wrong. Did I? Problem: Suppose that $X$ is a uniformly distributed random variable over the interval $[-1,1]$ . That is, the density function for $X$ is: $$ f(x) = \begin{cases} \frac{1}{2}, & \text{for } {-1} \leq x \leq 1 \\ 0, & \text{otherwise } \end{cases} $$ Now $Y$ is a random variable that follows the triangle distribution. That is, the density function for $Y$ is: $$ g(y) = \begin{cases} y + 1, & \text{for } {-1} \leq y \leq 0 \\ 1 - y, & \text{for } 0 \leq y \leq 1 \\ 0, & \text{otherwise } \end{cases} $$ We generate a value $x_0$ using the density function $f(x)$ . We then generate a value $y_0$ using the density function $g(y)$ such that $$ \int_{-1}^{x_0} \frac{1}{2} \, dx = \int_{-1}^{y_0} g(y) \, dy $$ What is the correlation between $X$ and $Y$ ? Answer: The formula for correlation is: $$\rho = \frac{\sigma_{xy}}{ \sigma_x \sigma_y } $$ Observe that the $E(X) = E(Y) = 0$ . \begin{align*} E(X^2) &= \int_{-1}^{1} \frac{x^2}{2} \, dx = \frac{x^3}{6} \Big|_{-1}^{1} = \frac{1}{6} - \frac{-1}{6} \\ E(X^2) &= \frac{1}{3} \\ \sigma_x^2 &= E(X^2) - (E(x))^2 = \frac{1}{3} \\ \sigma_x &=\frac{ \sqrt{3} }{3} \\ E(Y^2) &= \int_{-1}^{1} y^2 f(y) \, dy = \int_{-1}^{0} y^2 f(y) \, dy + \int_{0}^{1} y^2 f(y) \, dy \\ \int_{-1}^{0} y^2 (y+1) \, dy &= \int_{-1}^{0} y^3 + y^2 \,\, dy = \frac{y^4}{4} + \frac{y^3}{3} \Big|_{-1}^{0} \\ \int_{-1}^{0} y^2 (y+1) \, dy &= 0 - \left( \frac{1}{4} - \frac{1}{3} \right) \\ \int_{-1}^{0} y^2 (y+1) \, dy &= \frac{1}{12} \\ \sigma_y^2 &= E(Y^2) - (E(y))^2 = \frac{1}{12} \\ \sigma_y &= \frac{1}{\sqrt{12}} = \frac{ \sqrt{3} } {6} \end{align*} Now we need to find $\sigma_{xy}$ .To do this, we need to find $E(XY)$ . Observe that if $-1\leq x \leq 0$ then the area under the $f(x)$ between $x = -1$ and $x = 0$ is $\left( \frac{1}{2}\right) (x + 1)$ . Now we need to find $y$ in terms of $x$ . \begin{align*} \left( \frac{1}{2}\right) (x + 1) &= \int_{-1}^{y} y + 1 \, dy = \frac{y^2}{2} + y \Big|_{-1}^{y} \\ \left( \frac{1}{2}\right) (x + 1) &= \frac{y^2}{2} + y - \left( \frac{1}{2} - 1 \right) \\ \left( \frac{1}{2}\right) (x + 1) &= \frac{y^2}{2} + y + \frac{1}{2} \\ x + 1 &= y^2 + 2y + 1 \\ x &= y^2 + 2y \\ E(XY) &= 2 \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy \\ \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \int_{-1}^{0} y^4 + y^3 + y^3 + y^2 \, dy \\ \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \int_{-1}^{0} y^4 + 2y^3 + y^2 \, dy \\ \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &=  \frac{y^5}{5}+ \frac{2y^4}{4} + \frac{y^3}{3} \Big|_{-1}^{0} \\ \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &=0 - \left( -\frac{1}{5} + \frac{2}{4} - \frac{1}{3} \right) =  	\frac{1}{5} - \frac{2}{4} + \frac{1}{3}  \\ \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \frac{1}{30} \\ E(XY) &= \frac{1}{15} \\ \rho &= \frac{ \left( \frac{1}{15} \right) }{ \left( \frac{ \sqrt{3} }{3}  \right) \left( \frac{ \sqrt{3} } {6} \right)  } = \frac{ \frac{1}{15} } { \frac{3}{18} } \\ \rho &= \frac{2}{5} \end{align*}","I would expect the answer to the problem below to be at least . However, it is not. Therefore, I am thinking I did something wrong. Did I? Problem: Suppose that is a uniformly distributed random variable over the interval . That is, the density function for is: Now is a random variable that follows the triangle distribution. That is, the density function for is: We generate a value using the density function . We then generate a value using the density function such that What is the correlation between and ? Answer: The formula for correlation is: Observe that the . Now we need to find .To do this, we need to find . Observe that if then the area under the between and is . Now we need to find in terms of .","\frac{1}{2} X [-1,1] X  f(x) = \begin{cases}
\frac{1}{2}, & \text{for } {-1} \leq x \leq 1 \\
0, & \text{otherwise }
\end{cases}  Y Y  g(y) = \begin{cases}
y + 1, & \text{for } {-1} \leq y \leq 0 \\
1 - y, & \text{for } 0 \leq y \leq 1 \\
0, & \text{otherwise }
\end{cases}  x_0 f(x) y_0 g(y)  \int_{-1}^{x_0} \frac{1}{2} \, dx = \int_{-1}^{y_0} g(y) \, dy  X Y \rho = \frac{\sigma_{xy}}{ \sigma_x \sigma_y }  E(X) = E(Y) = 0 \begin{align*}
E(X^2) &= \int_{-1}^{1} \frac{x^2}{2} \, dx = \frac{x^3}{6} \Big|_{-1}^{1} = \frac{1}{6} - \frac{-1}{6} \\
E(X^2) &= \frac{1}{3} \\
\sigma_x^2 &= E(X^2) - (E(x))^2 = \frac{1}{3} \\
\sigma_x &=\frac{ \sqrt{3} }{3} \\
E(Y^2) &= \int_{-1}^{1} y^2 f(y) \, dy = \int_{-1}^{0} y^2 f(y) \, dy + \int_{0}^{1} y^2 f(y) \, dy \\
\int_{-1}^{0} y^2 (y+1) \, dy &= \int_{-1}^{0} y^3 + y^2 \,\, dy = \frac{y^4}{4} + \frac{y^3}{3} \Big|_{-1}^{0} \\
\int_{-1}^{0} y^2 (y+1) \, dy &= 0 - \left( \frac{1}{4} - \frac{1}{3} \right) \\
\int_{-1}^{0} y^2 (y+1) \, dy &= \frac{1}{12} \\
\sigma_y^2 &= E(Y^2) - (E(y))^2 = \frac{1}{12} \\
\sigma_y &= \frac{1}{\sqrt{12}} = \frac{ \sqrt{3} } {6}
\end{align*} \sigma_{xy} E(XY) -1\leq x \leq 0 f(x) x = -1 x = 0 \left( \frac{1}{2}\right) (x + 1) y x \begin{align*}
\left( \frac{1}{2}\right) (x + 1) &= \int_{-1}^{y} y + 1 \, dy = \frac{y^2}{2} + y \Big|_{-1}^{y} \\
\left( \frac{1}{2}\right) (x + 1) &= \frac{y^2}{2} + y - \left( \frac{1}{2} - 1 \right) \\
\left( \frac{1}{2}\right) (x + 1) &= \frac{y^2}{2} + y + \frac{1}{2} \\
x + 1 &= y^2 + 2y + 1 \\
x &= y^2 + 2y \\
E(XY) &= 2 \int_{-1}^{0} (y^2+y)(y)(y+1) \, dy \\
\int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \int_{-1}^{0} y^4 + y^3 + y^3 + y^2 \, dy \\
\int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \int_{-1}^{0} y^4 + 2y^3 + y^2 \, dy \\
\int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &=  \frac{y^5}{5}+ \frac{2y^4}{4} + \frac{y^3}{3} \Big|_{-1}^{0} \\
\int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &=0 - \left( -\frac{1}{5} + \frac{2}{4} - \frac{1}{3} \right) = 
	\frac{1}{5} - \frac{2}{4} + \frac{1}{3}  \\
\int_{-1}^{0} (y^2+y)(y)(y+1) \, dy &= \frac{1}{30} \\
E(XY) &= \frac{1}{15} \\
\rho &= \frac{ \left( \frac{1}{15} \right) }{ \left( \frac{ \sqrt{3} }{3}  \right) \left( \frac{ \sqrt{3} } {6} \right)  } =
\frac{ \frac{1}{15} } { \frac{3}{18} } \\
\rho &= \frac{2}{5}
\end{align*}","['probability', 'statistics']"
63,UMVUE help after finding complete and sufficient statistic,UMVUE help after finding complete and sufficient statistic,,"Let $X_1, X_2, \dots, X_n$ be a random sample from the distribution with pdf $$f(x; \theta) = \theta x^{\theta – 1} I_{(0,1)}(x)$$ for $\theta > 0$ (a) Find the UMVUE for $\dfrac{1}{\theta}$ . (b) Find the UMVUE for $\left(\dfrac{\theta}{\theta + 1}\right)^n$ . I found the Fisher Information as $\dfrac{n}{\theta^2} = I(\theta)$ so the CRLB is $\dfrac{\theta^2}{n} $ I computed the joint pdf and rewrote it to be $$f(\bar x; \theta) = I_{(0,1)}(x_i) \theta^n  e^{(\theta – 1)\sum_{i=0}^n \ln(x_i)} $$ Which would prove by exponential-family factorization that $\sum_{i=0}^n \ln(x_i)$ is a sufficient and complete statistic for the distribution right? How do I find the UMVUE from here? I've seen a similar problem that relied on Pareto distribution but this is not Pareto since the exponent is positive right?",Let be a random sample from the distribution with pdf for (a) Find the UMVUE for . (b) Find the UMVUE for . I found the Fisher Information as so the CRLB is I computed the joint pdf and rewrote it to be Which would prove by exponential-family factorization that is a sufficient and complete statistic for the distribution right? How do I find the UMVUE from here? I've seen a similar problem that relied on Pareto distribution but this is not Pareto since the exponent is positive right?,"X_1, X_2, \dots, X_n f(x; \theta) = \theta x^{\theta – 1} I_{(0,1)}(x) \theta > 0 \dfrac{1}{\theta} \left(\dfrac{\theta}{\theta + 1}\right)^n \dfrac{n}{\theta^2} = I(\theta) \dfrac{\theta^2}{n}  f(\bar x; \theta) = I_{(0,1)}(x_i) \theta^n  e^{(\theta – 1)\sum_{i=0}^n \ln(x_i)}  \sum_{i=0}^n \ln(x_i)","['statistics', 'probability-distributions', 'statistical-inference', 'parameter-estimation']"
64,Interpolation Capability of Deep Neural Networks of bounded height,Interpolation Capability of Deep Neural Networks of bounded height,,"The Universal Approximation Theorem shows that deep neural networks can approximate any function in $C(\mathbb{R}^d,\mathbb{R}^n)$ uniformly on compacts.  I'm curious, can the collection of a neural networks with bounded height interpolate any finite set of points?","The Universal Approximation Theorem shows that deep neural networks can approximate any function in uniformly on compacts.  I'm curious, can the collection of a neural networks with bounded height interpolate any finite set of points?","C(\mathbb{R}^d,\mathbb{R}^n)",['statistics']
65,Conditional expected value variable change,Conditional expected value variable change,,"Assume that we have $X_1,X_2,X_3$ that are jointly Gaussian, $E(X_i)=0$ and with non-zero covariances. We also have: $$Y_1=X_1$$ $$Y_2=X_2−X_1$$ $$Y_3=X_3−X_2$$ With $0$ covariances among all $Y_i$ and $E(Y_i^2)=1$ Is the following operation valid: $$E(Y_3^2|X_1,X_2)=E(Y_3^2|Y_1,Y_2)=E(Y_3^2)=1$$ Also consider: $$E(Y_3^2|X_1,X_2)= E(X_3^2|X_1,X_2)-2E(X_3|X_1,X_2)X_2-X_2^2$$ Which should be impossible to solve with the current information. I know that in the case of jointly gaussian variables a correlation of $0$ implies independence and all $X_i$ are jointly gaussian but does this property extend to all the $Y_i$ ?","Assume that we have that are jointly Gaussian, and with non-zero covariances. We also have: With covariances among all and Is the following operation valid: Also consider: Which should be impossible to solve with the current information. I know that in the case of jointly gaussian variables a correlation of implies independence and all are jointly gaussian but does this property extend to all the ?","X_1,X_2,X_3 E(X_i)=0 Y_1=X_1 Y_2=X_2−X_1 Y_3=X_3−X_2 0 Y_i E(Y_i^2)=1 E(Y_3^2|X_1,X_2)=E(Y_3^2|Y_1,Y_2)=E(Y_3^2)=1 E(Y_3^2|X_1,X_2)= E(X_3^2|X_1,X_2)-2E(X_3|X_1,X_2)X_2-X_2^2 0 X_i Y_i","['statistics', 'random-variables', 'conditional-expectation', 'expected-value']"
66,Bessel's Correction,Bessel's Correction,,"I'm trying to understand the intuition behind Bessel's correction where $\sum (x_i - \overline{x})^2 / (n-1)$ . My difficulty is stemming from the fact that the sample mean leads to a standard deviation that, when comparing it to hypothetical population means, is ALWAYS smaller. Why is it that the mean of a sample results in producing a standard deviation that will never be lower by using another mean?","I'm trying to understand the intuition behind Bessel's correction where . My difficulty is stemming from the fact that the sample mean leads to a standard deviation that, when comparing it to hypothetical population means, is ALWAYS smaller. Why is it that the mean of a sample results in producing a standard deviation that will never be lower by using another mean?",\sum (x_i - \overline{x})^2 / (n-1),['statistics']
67,"Degrees of Freedom, Standard Deviation, and the Geometry of it all","Degrees of Freedom, Standard Deviation, and the Geometry of it all",,"This question is going to be a little broad because I'm still quite the novice in about what I'm asking about. Regardless, here goes: I've started learning statistics, and something that I've found really beautiful is the connection between statistics and geometry. As I've come to understand the degrees of freedom, they're the number of dimensions of the sub-space that a random vector is constrained to. Here, let me start by giving a brief example, and then I'll get on with my question: Brief Example: If $\vec{x}$ is a vector with $n$ independent observations of some random variable $X$ , then it has $n$ degrees of freedom, because each of its components can take on whichever value, regardless of the values the other components took. In other words, $\vec{x}$ exists in $n$ dimensional space. As another example, let $\bar{x}$ be the mean of our $n$ datapoints. Then, the error vector... $$\vec{e} = \begin{bmatrix}x_1-\bar{x}\\x_2-\bar{x}\\ x_3-\bar{x}\\ \vdots \\x_n-\bar{x}\end{bmatrix}$$ ...which contains the errors of our sample-set from its mean as its components, is constrained to an $(n-1)$ dimensional subspace, as $\vec{e}\cdot\vec{1}$ , where $\vec{1}$ is a vector with $n$ rows of $1$ , is equal to zero. That is, the sum of the absolute errors from the mean is zero. Wikipedia explains it better than I do btw: https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics) My Question I originally had a longer question...but, as I don't want to say too much because I may very well be extremely confused... What role, geometrically, does $n-1$ play when calculating the standard deviation of a sample set? Here are my thoughts so far... If we know the mean of the population which we took the sample from, and the sample is to be representative of the population, then the mean of the sample must be equal to the mean of the population, and thus it can only exist in $(n-1)$ dimensional space (because once we know $n-1$ rows, we must also know the last component if the sample is to have a specific known mean). Then, for some reason, we need to divide the length of this vector by the square root of the number of dimensions it can exist in...why? .... I know my question isn't yet very clear, but that's because I'm still quite confused. I'll try to update it more as I learn more about degrees of freedom. Thank you.","This question is going to be a little broad because I'm still quite the novice in about what I'm asking about. Regardless, here goes: I've started learning statistics, and something that I've found really beautiful is the connection between statistics and geometry. As I've come to understand the degrees of freedom, they're the number of dimensions of the sub-space that a random vector is constrained to. Here, let me start by giving a brief example, and then I'll get on with my question: Brief Example: If is a vector with independent observations of some random variable , then it has degrees of freedom, because each of its components can take on whichever value, regardless of the values the other components took. In other words, exists in dimensional space. As another example, let be the mean of our datapoints. Then, the error vector... ...which contains the errors of our sample-set from its mean as its components, is constrained to an dimensional subspace, as , where is a vector with rows of , is equal to zero. That is, the sum of the absolute errors from the mean is zero. Wikipedia explains it better than I do btw: https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics) My Question I originally had a longer question...but, as I don't want to say too much because I may very well be extremely confused... What role, geometrically, does play when calculating the standard deviation of a sample set? Here are my thoughts so far... If we know the mean of the population which we took the sample from, and the sample is to be representative of the population, then the mean of the sample must be equal to the mean of the population, and thus it can only exist in dimensional space (because once we know rows, we must also know the last component if the sample is to have a specific known mean). Then, for some reason, we need to divide the length of this vector by the square root of the number of dimensions it can exist in...why? .... I know my question isn't yet very clear, but that's because I'm still quite confused. I'll try to update it more as I learn more about degrees of freedom. Thank you.",\vec{x} n X n \vec{x} n \bar{x} n \vec{e} = \begin{bmatrix}x_1-\bar{x}\\x_2-\bar{x}\\ x_3-\bar{x}\\ \vdots \\x_n-\bar{x}\end{bmatrix} (n-1) \vec{e}\cdot\vec{1} \vec{1} n 1 n-1 (n-1) n-1,"['probability', 'geometry', 'statistics', 'intuition', 'standard-deviation']"
68,Help creating a formula for a rating system with weighed ranks.,Help creating a formula for a rating system with weighed ranks.,,"I am attempting to create a 5 star rating system with a twist. Instead of calculating how many people rated something 5 stars then adding that to the total 4 stars etc..., I want to do something different. I want to use a ranking system that returns a rank between 0 and 5. When someone with a higher rank rates someone else, their rating carries more weight than someone with a lower rank giving the same rate. For example. User A is ranked 4.375 User B is ranked 4.0 User C is ranked 2.0 User A give User B 5 stars. That should dramatically increase User B 's rank. (ie +0.5%) If User C gives User B 5 stars. User B 's rank would go up a little. (ie +0.1%) The percentages are just examples. Second example User A gives User B a 1 star rating. User B 's rank will drop significantly. (ie -0.5%) User C gives User B a 1 star rating. User B 's rank will drop a little. (ie -0.1%) Again the percentages are purely fictional. And only meant to   represent the idea that someone with a lower rank doesn't really   affect someone with a bigger rank than them. I tried something like this which is the weighted rank, but instead of whole numbers (how many people rated someone 5 stars), I used the Raters Rank for the Raters Rank ((My Rank  * Raters Rank) + new rating) / (Raters Rank + 1) I would like to keep at least 3 significant figures and stay clamped between 0 and 5. I will only be storing the user's rank and a count of how many people have rated a user over time. No historical data will be kept. As in, you don't know User A rated User B 1.0","I am attempting to create a 5 star rating system with a twist. Instead of calculating how many people rated something 5 stars then adding that to the total 4 stars etc..., I want to do something different. I want to use a ranking system that returns a rank between 0 and 5. When someone with a higher rank rates someone else, their rating carries more weight than someone with a lower rank giving the same rate. For example. User A is ranked 4.375 User B is ranked 4.0 User C is ranked 2.0 User A give User B 5 stars. That should dramatically increase User B 's rank. (ie +0.5%) If User C gives User B 5 stars. User B 's rank would go up a little. (ie +0.1%) The percentages are just examples. Second example User A gives User B a 1 star rating. User B 's rank will drop significantly. (ie -0.5%) User C gives User B a 1 star rating. User B 's rank will drop a little. (ie -0.1%) Again the percentages are purely fictional. And only meant to   represent the idea that someone with a lower rank doesn't really   affect someone with a bigger rank than them. I tried something like this which is the weighted rank, but instead of whole numbers (how many people rated someone 5 stars), I used the Raters Rank for the Raters Rank ((My Rank  * Raters Rank) + new rating) / (Raters Rank + 1) I would like to keep at least 3 significant figures and stay clamped between 0 and 5. I will only be storing the user's rank and a count of how many people have rated a user over time. No historical data will be kept. As in, you don't know User A rated User B 1.0",,"['statistics', 'average', 'means']"
69,Markov Chain Expectation Variance Covariance,Markov Chain Expectation Variance Covariance,,"Given a Markov chain on {0, 1} defined by: \begin{gather}     P = \begin{bmatrix} 1-p & p \\ q & 1-q  \end{bmatrix}  \end{gather} With an initial distribution $\pi(0)$ = [ $\frac{q}{p+q}$ , $\frac{p}{p+q}$ ]. I have to find the Expectation $\mathbf{E}[X_n]$ , the Variance $\mathbf{V}[X_n]$ and the $\mathbf{Cov}[X_{m+n}, X_n]$ . Intuitively I would say that I can compute the expectation and the variance by multiplying {0,1} with the stationary probabilities. I this correct?  How would I factor in the covariance? Isn't this just equal to 0, because the chain converges to a stable distribution i.e. there is no difference between time m=n and n in the long run?","Given a Markov chain on {0, 1} defined by: With an initial distribution = [ , ]. I have to find the Expectation , the Variance and the . Intuitively I would say that I can compute the expectation and the variance by multiplying {0,1} with the stationary probabilities. I this correct?  How would I factor in the covariance? Isn't this just equal to 0, because the chain converges to a stable distribution i.e. there is no difference between time m=n and n in the long run?","\begin{gather}
    P = \begin{bmatrix} 1-p & p \\ q & 1-q  \end{bmatrix} 
\end{gather} \pi(0) \frac{q}{p+q} \frac{p}{p+q} \mathbf{E}[X_n] \mathbf{V}[X_n] \mathbf{Cov}[X_{m+n}, X_n]","['probability', 'statistics', 'markov-chains']"
70,PDF of product of uniform variables,PDF of product of uniform variables,,"I have encountered a problem in computing the PDF of a variable (call it $y_n$ ) that is the product of n uniformly distributed random variables $x$ : $y_n=\prod_i^n x_i.$ In https://math.stackexchange.com/a/2812234 there is the solution for the case $x \in (0,1),$ but in my case the random variables are distributed in the interval (0.2,1.8), or more generally in the interval (a,b). I have not been able to translate the formula for the product in the interval (0,1) to my case; if I follow the procedure used to retrieve the formula (see link above) I have a problem since the integrand has no pole, hence no residue. Can anyone point out any suggestions on how to proceed, or if there is any reference to books or articles where this kind of case is treated?","I have encountered a problem in computing the PDF of a variable (call it ) that is the product of n uniformly distributed random variables : In https://math.stackexchange.com/a/2812234 there is the solution for the case but in my case the random variables are distributed in the interval (0.2,1.8), or more generally in the interval (a,b). I have not been able to translate the formula for the product in the interval (0,1) to my case; if I follow the procedure used to retrieve the formula (see link above) I have a problem since the integrand has no pole, hence no residue. Can anyone point out any suggestions on how to proceed, or if there is any reference to books or articles where this kind of case is treated?","y_n x y_n=\prod_i^n x_i. x \in (0,1),",['statistics']
71,Show Process is a Poisson Process (Check 3 conditions).,Show Process is a Poisson Process (Check 3 conditions).,,"Suppose $A_t$ is a Process with rate 1. Show that $B_t=A_{2t}$ is a Poisson process. I have to check three conditions: A Poisson process with rate $\lambda$ is a random process $N=(N_t: t\geq 0$ ) so that: $1.$ $N$ is a counting process $2.$ $N$ has independent increments, for any positive integer $m$ , and any $t_0<t_1<...t_m$ , the increments $N_{t_1}-N_{t_0}$ , $N_{t_2}-N_{t_1}$ ,.... $N_{t_m}-N_{t_{m-1}}$ are mutually independent. $3.$ $N(t)-N(s)$ has Poisson( $\lambda(t-s))$ for $t \geq s$ . My main problem is with step 2. My Attempt: Since $A_t$ is a counting process, $B_t=A_{2t}$ must also clearly be a counting process. (Not sure if I should give more explanation...) I'm having trouble writing this part formally or properly, I think some of my logic is a bit confused or not precise: Let $m$ be a positive integer and consider $t_0<t_1<...t_m$ and $t_m< t_{m+1}< t_{m+2},....<t_{2m}$ . We have that the increments $A_{t_1}-A_{t_0}, A_{t_2}-A_{t_1},A_{t_3}-A_{t_2}, A_{t_4}-A_{t_3}...,A_{t_m}-A_{t_{m-1}}, A_{t_{m+1}}-A_{t_{m}},.....A_{t_{2m}}-A_{t_{2m-1}}$ are mutually independent since $A_t$ is a Poisson Process. Thus the increments, $A_{t_{2m}}-A_{t_{2m-1}}+A_{t_{2m-1}}-A_{t_{2m-2}}=A_{t_{2m}}-A_{t_{2m-2}}=B_{t_{m}}-B_{t_{m-1}}$ , $A_{t_{2m-2}}-A_{t_{2m-3}}+A_{t_{2m-3}}-A_{t_{2m-4}}=A_{t_{2m-2}}-A_{t_{2m-4}}=B_{t_{m-1}}-B_{t_{m-2}}$ , ..... $A_{2t_1}-A_{2t_0}=B_{t_{1}}-B_{t_{0}}$ are mutually independent. Hopefully this is right: Let $t \geq s$ .  We have that $B(t)-B(s)=A(2t)-A(2s)=A(2t)-A(2t-1)+A(2t-1)-A(2t-2)+....A(2s+1)-A(2s)$ . We know that $A(2t)-A(2t-1), ....A(s+1)-A(s)$ are all independent Poisson random variables with rate $1$ . We know that the sum of independent Poisson random variables is Poisson with the sum of the rates. There are $2(t-s)$ terms in the above sum. Thus: $A(2t)-A(2s)=A(2t)-A(2t-1)+A(2t-1)-A(2t-2)+....A(2s+1)-A(2s)$ is Poisson with rate $2(t-s)$ . Hence $B(t)-B(s)$ is Poisson with rate $2(t-s)$ for $t \geq s$ . Hence $B_t$ is a Poisson process with rate 2.","Suppose is a Process with rate 1. Show that is a Poisson process. I have to check three conditions: A Poisson process with rate is a random process ) so that: is a counting process has independent increments, for any positive integer , and any , the increments , ,.... are mutually independent. has Poisson( for . My main problem is with step 2. My Attempt: Since is a counting process, must also clearly be a counting process. (Not sure if I should give more explanation...) I'm having trouble writing this part formally or properly, I think some of my logic is a bit confused or not precise: Let be a positive integer and consider and . We have that the increments are mutually independent since is a Poisson Process. Thus the increments, , , ..... are mutually independent. Hopefully this is right: Let .  We have that . We know that are all independent Poisson random variables with rate . We know that the sum of independent Poisson random variables is Poisson with the sum of the rates. There are terms in the above sum. Thus: is Poisson with rate . Hence is Poisson with rate for . Hence is a Poisson process with rate 2.","A_t B_t=A_{2t} \lambda N=(N_t: t\geq 0 1. N 2. N m t_0<t_1<...t_m N_{t_1}-N_{t_0} N_{t_2}-N_{t_1} N_{t_m}-N_{t_{m-1}} 3. N(t)-N(s) \lambda(t-s)) t \geq s A_t B_t=A_{2t} m t_0<t_1<...t_m t_m< t_{m+1}< t_{m+2},....<t_{2m} A_{t_1}-A_{t_0}, A_{t_2}-A_{t_1},A_{t_3}-A_{t_2}, A_{t_4}-A_{t_3}...,A_{t_m}-A_{t_{m-1}}, A_{t_{m+1}}-A_{t_{m}},.....A_{t_{2m}}-A_{t_{2m-1}} A_t A_{t_{2m}}-A_{t_{2m-1}}+A_{t_{2m-1}}-A_{t_{2m-2}}=A_{t_{2m}}-A_{t_{2m-2}}=B_{t_{m}}-B_{t_{m-1}} A_{t_{2m-2}}-A_{t_{2m-3}}+A_{t_{2m-3}}-A_{t_{2m-4}}=A_{t_{2m-2}}-A_{t_{2m-4}}=B_{t_{m-1}}-B_{t_{m-2}} A_{2t_1}-A_{2t_0}=B_{t_{1}}-B_{t_{0}} t \geq s B(t)-B(s)=A(2t)-A(2s)=A(2t)-A(2t-1)+A(2t-1)-A(2t-2)+....A(2s+1)-A(2s) A(2t)-A(2t-1), ....A(s+1)-A(s) 1 2(t-s) A(2t)-A(2s)=A(2t)-A(2t-1)+A(2t-1)-A(2t-2)+....A(2s+1)-A(2s) 2(t-s) B(t)-B(s) 2(t-s) t \geq s B_t","['real-analysis', 'probability', 'probability-theory', 'statistics', 'stochastic-processes']"
72,How many batteries will be working after 280 minutes?,How many batteries will be working after 280 minutes?,,"A study of data collected at a company manufacturing flashlight   batteries shows that a batch of 8000 batteries have a mean life of 250   minutes with a standard deviation of 20 minutes. Assuming a Normal   Distribution, estimate: How many batteries will continue working after 285 minutes? This is my answer to this question does it look correct or are there any improvements I can make? Batch: 8000 Mean: 250 minutes  SD: 20 minutes   (285-250)/20 = 1.75 Z-Score of 1.75 = .4599 (.5-4599)*8000 = 320.8 batteries will be working","A study of data collected at a company manufacturing flashlight   batteries shows that a batch of 8000 batteries have a mean life of 250   minutes with a standard deviation of 20 minutes. Assuming a Normal   Distribution, estimate: How many batteries will continue working after 285 minutes? This is my answer to this question does it look correct or are there any improvements I can make? Batch: 8000 Mean: 250 minutes  SD: 20 minutes   (285-250)/20 = 1.75 Z-Score of 1.75 = .4599 (.5-4599)*8000 = 320.8 batteries will be working",,"['probability', 'statistics', 'normal-distribution']"
73,Hypergeometric Hypothesis Testing,Hypergeometric Hypothesis Testing,,"Suppose I have a jar with 9000 balls, each ball is either black or   red. I pull a sample of 6000 and observe that 53% (3180) are red. I   want to conduct a hypothesis test where $H_{0}:=$ Less than 50% of   balls in the jar are red. However, I am willing to alter that hypothesis if there is a more reasonable way to formulate it that will 'essentially mean the same thing'. I have done some research to try and figure out the best way to go about this, and I discovered the hypergeometric test for over/under representation. The hypergeometric test uses the hypergeometric distribution to measure   the statistical significance of having drawn a sample consisting of a   specific number of $k$ successes (out of $n$ total draws from a population of size $N$ containing $K$ successes. In a   test for over-representation of successes in the sample, the   hypergeometric $p$ -value is calculated as the probability of randomly   drawing $k$ or more successes from the population in $n$ total draws. In a test for under-representation,   the $p$ -value is the probability of randomly drawing $k$ or fewer successes. According to this, I should take $N = 9000, k = 3180, n = 6000, K < 4500$ and then if $f(n,k)$ is the PDF of a hypergeometric distribution with $N = 9000$ and $K < 45000$ , I find my $p$ -value as $$P = \sum_{i = 3180}^{6000} f(i,6000).$$ Does this make sense? How do I handle the fact that $K < 4500$ , should I do the summation for each value of $K < 4500$ ? Or would it make sense to set $K = 4500$ Does my set up accurately reflect the hypothesis I set out to test? Should I alter my approach, or perhaps there is a better hypothesis I could formulate? I have almost no statistics background, just one or two classes when I was in undergrad, so I am not only lacking the ability to set up and solve this problem, but also need help interpreting the results and meaning. Thanks!","Suppose I have a jar with 9000 balls, each ball is either black or   red. I pull a sample of 6000 and observe that 53% (3180) are red. I   want to conduct a hypothesis test where Less than 50% of   balls in the jar are red. However, I am willing to alter that hypothesis if there is a more reasonable way to formulate it that will 'essentially mean the same thing'. I have done some research to try and figure out the best way to go about this, and I discovered the hypergeometric test for over/under representation. The hypergeometric test uses the hypergeometric distribution to measure   the statistical significance of having drawn a sample consisting of a   specific number of successes (out of total draws from a population of size containing successes. In a   test for over-representation of successes in the sample, the   hypergeometric -value is calculated as the probability of randomly   drawing or more successes from the population in total draws. In a test for under-representation,   the -value is the probability of randomly drawing or fewer successes. According to this, I should take and then if is the PDF of a hypergeometric distribution with and , I find my -value as Does this make sense? How do I handle the fact that , should I do the summation for each value of ? Or would it make sense to set Does my set up accurately reflect the hypothesis I set out to test? Should I alter my approach, or perhaps there is a better hypothesis I could formulate? I have almost no statistics background, just one or two classes when I was in undergrad, so I am not only lacking the ability to set up and solve this problem, but also need help interpreting the results and meaning. Thanks!","H_{0}:= k n N K p k n p k N = 9000, k = 3180, n = 6000, K < 4500 f(n,k) N = 9000 K < 45000 p P = \sum_{i = 3180}^{6000} f(i,6000). K < 4500 K < 4500 K = 4500","['statistics', 'statistical-inference', 'hypothesis-testing']"
74,How do I calculate the expected value given this density function?,How do I calculate the expected value given this density function?,,"I want to find the expected value of a random variable whose density function is $$f(x) = \begin{cases} 2xe^{-x^2}, & x > 0 \\ 0, &x \leq 0 \end{cases}.$$ For what's worth, all I know is the way the expected value should be found: that is, I need to put an $x$ beside $f(x)$ and then integrate it (probably, from $0$ to $\infty$ ). Here's where the problem turns up. I tried using Wolfram, and it shows me some weird output. In classes, we haven't covered the material concerning this, but I'm expected to be capable of doing it. But I don't know how.","I want to find the expected value of a random variable whose density function is For what's worth, all I know is the way the expected value should be found: that is, I need to put an beside and then integrate it (probably, from to ). Here's where the problem turns up. I tried using Wolfram, and it shows me some weird output. In classes, we haven't covered the material concerning this, but I'm expected to be capable of doing it. But I don't know how.","f(x) = \begin{cases}
2xe^{-x^2}, & x > 0 \\
0, &x \leq 0
\end{cases}. x f(x) 0 \infty","['probability', 'statistics']"
75,How do I find the variance of $\hat\theta_\text{MLE}$ for $f_{\theta}(x) = \theta x^{\theta-1}$?,How do I find the variance of  for ?,\hat\theta_\text{MLE} f_{\theta}(x) = \theta x^{\theta-1},"Given, $$f_\theta(x) = \theta x^{\theta-1}, x \in [0,1], \theta >0$$ $$\hat\theta_\text{MLE} = \frac{-1}{\frac{1}{n} \sum_{i=1}^n \log(x_i)} $$ $$\operatorname{Var}(\hat\theta_\text{MLE}) = E_\theta(\hat\theta_\text{MLE}^2) - E_\theta(\hat\theta_\text{MLE})^2$$ How do I find the expectations, $E_\theta(\hat\theta_\text{MLE}^2)$ and $E_\theta(\hat\theta_\text{MLE})$ ,  given the presence of both summation and log in the denominator?","Given, How do I find the expectations, and ,  given the presence of both summation and log in the denominator?","f_\theta(x) = \theta x^{\theta-1}, x \in [0,1], \theta >0 \hat\theta_\text{MLE} = \frac{-1}{\frac{1}{n} \sum_{i=1}^n \log(x_i)}  \operatorname{Var}(\hat\theta_\text{MLE}) = E_\theta(\hat\theta_\text{MLE}^2) - E_\theta(\hat\theta_\text{MLE})^2 E_\theta(\hat\theta_\text{MLE}^2) E_\theta(\hat\theta_\text{MLE})","['statistics', 'expected-value', 'variance']"
76,Two sample hypothesis test with unknown standard deviation problem help,Two sample hypothesis test with unknown standard deviation problem help,,"The problem: The International Air Transport Association surveys business travelers to develop quality ratings for transatlantic gateway airports. The maximum possible rating is 10. Suppose a simple random sample of 50 business travelers is selected and each traveler is asked to provide a rating for the Miami International Airport, and another simple random sample of 50 traveling agents that qualified at the Los Angeles airport. The exercise provided the data but I will just give you the summary of each sample: Miami (1): Size: $n_1=50$ Mean: $\overline{x}_1=6.34$ Standard deviation: $s_1=2.1629$ Los Ángeles (2): Size: $n_2=50$ Mean: $\overline{x}_1=6.72$ Standard deviation: $s_1=2.3737$ There are two questions: With α = 0.025, perform hypotheses test to determine that the two airports are highly competitive. Using the information of the first problem, perform a hypothesis test, with α = 0.025, to determine if there is a significant difference between the two airports. This is what I did. $$H_0: μ_1=μ_2$$ $$H_1: μ_1≠μ_2$$ For the critical value: Freedom degrees: $n_1+n_2-2=50+50-2=98$ Since the  α = 0.025 and I believe this is two-tailed $\frac{α}{2}=0.0125$ But this number does not appear in the table of t. So I used a website to give me the critical value. Critical Value: $t=±2.276$ Since there is unknown the population standard deviation or variance, I looked for the pooled sample variance. This is the formula I used: $$s_p^2=\frac{(n_1-1)s_1^2+(n_1-1)s_2^2}{n_1+n_2-2}$$ $$s_p^2=\frac{(50-1)(2.1629)^2+(50-1)(2.3737)^2}{50+50-2}=5.1563$$ $t$ -statistic: $$t=\frac{\overline{x}_1-\overline{x}_2}{\sqrt{\frac{s_p^2}{n_1}+\frac{s_p^2}{n_2}}}$$ $$t=\frac{6.42-6.72}{\sqrt{5.1563(\frac{1}{50}+\frac{1}{50})}}=-0.6609$$ The null hypothesis is not rejected because -0.6609 falls in the region between -2.276 and 2.276. The data does not show that there is a significant difference between the means of the quality ratings for the airports of Miami and Los Angeles. Am I right? If I am, this answers the second question but, what I have to do with hypothesis test to determine that the two airports are highly competitive? Thanks in advance for any help.","The problem: The International Air Transport Association surveys business travelers to develop quality ratings for transatlantic gateway airports. The maximum possible rating is 10. Suppose a simple random sample of 50 business travelers is selected and each traveler is asked to provide a rating for the Miami International Airport, and another simple random sample of 50 traveling agents that qualified at the Los Angeles airport. The exercise provided the data but I will just give you the summary of each sample: Miami (1): Size: Mean: Standard deviation: Los Ángeles (2): Size: Mean: Standard deviation: There are two questions: With α = 0.025, perform hypotheses test to determine that the two airports are highly competitive. Using the information of the first problem, perform a hypothesis test, with α = 0.025, to determine if there is a significant difference between the two airports. This is what I did. For the critical value: Freedom degrees: Since the  α = 0.025 and I believe this is two-tailed But this number does not appear in the table of t. So I used a website to give me the critical value. Critical Value: Since there is unknown the population standard deviation or variance, I looked for the pooled sample variance. This is the formula I used: -statistic: The null hypothesis is not rejected because -0.6609 falls in the region between -2.276 and 2.276. The data does not show that there is a significant difference between the means of the quality ratings for the airports of Miami and Los Angeles. Am I right? If I am, this answers the second question but, what I have to do with hypothesis test to determine that the two airports are highly competitive? Thanks in advance for any help.",n_1=50 \overline{x}_1=6.34 s_1=2.1629 n_2=50 \overline{x}_1=6.72 s_1=2.3737 H_0: μ_1=μ_2 H_1: μ_1≠μ_2 n_1+n_2-2=50+50-2=98 \frac{α}{2}=0.0125 t=±2.276 s_p^2=\frac{(n_1-1)s_1^2+(n_1-1)s_2^2}{n_1+n_2-2} s_p^2=\frac{(50-1)(2.1629)^2+(50-1)(2.3737)^2}{50+50-2}=5.1563 t t=\frac{\overline{x}_1-\overline{x}_2}{\sqrt{\frac{s_p^2}{n_1}+\frac{s_p^2}{n_2}}} t=\frac{6.42-6.72}{\sqrt{5.1563(\frac{1}{50}+\frac{1}{50})}}=-0.6609,"['statistics', 'statistical-inference', 'hypothesis-testing']"
77,Centering data leads to zero intercept in multiple linear regression,Centering data leads to zero intercept in multiple linear regression,,"Suppose that $\hat\beta$ is the OLS estimator of the multiple linear regression given by $$ \hat\beta =\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^px_{ij}\beta_j)^2\Bigr\} $$ and $\hat\beta^c$ is the OLS estimator of the multiple linear regression when the variables are centered, i.e. $$ \hat\beta^c =\underset{\beta^c}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y)-\beta_0^c-\sum_{j=1}^p(x_{ij}-\bar x_j)\beta_j^c)^2\Bigr\}. $$ It seems that $\hat\beta_0^c$ should be equal to $0$ . We have that \begin{align*} 	\hat\beta 	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^px_{ij}\beta_j)^2\Bigr\}\\ 	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y+\bar y)-\beta_0-\sum_{j=1}^p(x_{ij}-\bar x_j+\bar x_j)\beta_j)^2\Bigr\}\\ 	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y)+\underbrace{\bar y-\beta_0-\sum_{j=1}^p\bar x_j\beta_j}_{=\beta_0^c}-\sum_{j=1}^p(x_{ij}-\bar x_j)\underbrace{\beta_j}_{=\beta_j^c})^2\Bigr\}. \end{align*} It is straightforward to see that $\hat\beta_0^c=0$ in the simple linear regression. We have that $$ \bar y-\hat\beta_0-\bar x\hat\beta_1=\bar y-\bar y+\bar x\hat\beta_1-\bar x\hat\beta_1=0. $$ How can we show that this also holds for the multiple linear regression, i.e. how can we show that $\hat\beta_0^c$ is equal to $0$ ? Any help is much appreciated!","Suppose that is the OLS estimator of the multiple linear regression given by and is the OLS estimator of the multiple linear regression when the variables are centered, i.e. It seems that should be equal to . We have that It is straightforward to see that in the simple linear regression. We have that How can we show that this also holds for the multiple linear regression, i.e. how can we show that is equal to ? Any help is much appreciated!","\hat\beta 
\hat\beta
=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^px_{ij}\beta_j)^2\Bigr\}
 \hat\beta^c 
\hat\beta^c
=\underset{\beta^c}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y)-\beta_0^c-\sum_{j=1}^p(x_{ij}-\bar x_j)\beta_j^c)^2\Bigr\}.
 \hat\beta_0^c 0 \begin{align*}
	\hat\beta
	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n(y_i-\beta_0-\sum_{j=1}^px_{ij}\beta_j)^2\Bigr\}\\
	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y+\bar y)-\beta_0-\sum_{j=1}^p(x_{ij}-\bar x_j+\bar x_j)\beta_j)^2\Bigr\}\\
	&=\underset{\beta}{\operatorname{arg\,min}}\Bigl\{\sum_{i=1}^n((y_i-\bar y)+\underbrace{\bar y-\beta_0-\sum_{j=1}^p\bar x_j\beta_j}_{=\beta_0^c}-\sum_{j=1}^p(x_{ij}-\bar x_j)\underbrace{\beta_j}_{=\beta_j^c})^2\Bigr\}.
\end{align*} \hat\beta_0^c=0 
\bar y-\hat\beta_0-\bar x\hat\beta_1=\bar y-\bar y+\bar x\hat\beta_1-\bar x\hat\beta_1=0.
 \hat\beta_0^c 0","['statistics', 'estimation', 'least-squares', 'linear-regression', 'regression-analysis']"
78,Determine asymptotic distribution and efficiency of an estimator,Determine asymptotic distribution and efficiency of an estimator,,"I have the following problem: Let $X_1,..., X_n$ be a sample of independent, identically distributed random variables, with density $$f_{\theta}(x)=\begin{cases} e^{\theta-x}, & \text{if } x\geq \theta\\ 0, & \text{elsewhere}\\ \end{cases}$$ Let $\hat\theta_n$ be the maximum-likelihood estimator (MLE) of $\theta$ . I am asked to find the asymptotic distribution of $\sqrt n (\hat\theta_n-\theta)$ and $\hat\theta_n$ efficiency. So far, I computed the MLE, which is $\hat\theta_n=min\{x_i\}$ , for $i=0,...,n.$ . I also know that if I find that $\sqrt n (\hat\theta_n-\theta)$ converges in distribution to $N(0,I(\theta))$ , we would have both the asymptotic distribution and efficiency of the estimator. Central Limit Theorem could be a way to do it, but I'm really struggling on it. Any hints or solutions would be appreciated.","I have the following problem: Let be a sample of independent, identically distributed random variables, with density Let be the maximum-likelihood estimator (MLE) of . I am asked to find the asymptotic distribution of and efficiency. So far, I computed the MLE, which is , for . I also know that if I find that converges in distribution to , we would have both the asymptotic distribution and efficiency of the estimator. Central Limit Theorem could be a way to do it, but I'm really struggling on it. Any hints or solutions would be appreciated.","X_1,..., X_n f_{\theta}(x)=\begin{cases}
e^{\theta-x}, & \text{if } x\geq \theta\\
0, & \text{elsewhere}\\
\end{cases} \hat\theta_n \theta \sqrt n (\hat\theta_n-\theta) \hat\theta_n \hat\theta_n=min\{x_i\} i=0,...,n. \sqrt n (\hat\theta_n-\theta) N(0,I(\theta))","['statistics', 'probability-distributions', 'maximum-likelihood', 'parameter-estimation']"
79,Actual meaning of Confidence Interval,Actual meaning of Confidence Interval,,"I am a little confusing about the right understanding of confidence interval. $100$ random samples are taken to estimates the mean $\mu$ . A $95$ %   confidence interval on the mean is $0.49 \leq \mu \leq 0.82$ . Consider   the following statement: There is a $95$ % chance that $\mu$ is between $0.49$ and $0.82$ . Is the statement correct? Explain your answer. I suppose the statement is wrong and the right one must be: There is a $95$ % chance that $\mu$ is actually in some interval that are found.For example, by researching, I found 100 different intervals and 95 of them contains $\mu$ in average.","I am a little confusing about the right understanding of confidence interval. random samples are taken to estimates the mean . A %   confidence interval on the mean is . Consider   the following statement: There is a % chance that is between and . Is the statement correct? Explain your answer. I suppose the statement is wrong and the right one must be: There is a % chance that is actually in some interval that are found.For example, by researching, I found 100 different intervals and 95 of them contains in average.",100 \mu 95 0.49 \leq \mu \leq 0.82 95 \mu 0.49 0.82 95 \mu \mu,['statistics']
80,Linear regression model with a known parameter,Linear regression model with a known parameter,,"Question: Consider the following linear regression with one parameter (intercept $\beta_{0}$ known). $ y_{i} = \beta_{0}^{*} + \beta_{1}x_{i} + \epsilon_{i} $ for i = 1,....n a) Compute the LSE , MLE , mean and varience for $\beta_{1}$ . I understand how to derive the following when both the slope and intercept is unknown. However I'm unsure what the effect of knowing what the intercept will have on the new computations. Attempt: We minimsise the LSE by setting $\partial_{\beta_{1}} S(\beta_{1}) = - \sum_{i=1}^{n} 2x_{i}(y_{i}-\beta_{0}^{*}-\beta_{1}x_{i}) = 0 $ After long computations we get $\beta_{1} = \frac{\sum_{i=1}^{n} x_{i} (y_{i} - \beta_{0}^{*})   }{\sum_{i=1}^{n}(x_{i}^2)}$ The computation of the least square estimator doesn't seem to care wether $b_{0}$ is known or unknown so would be get the same LSE,MLE,mean and variance as with the case $b_{0}$ is unknown","Question: Consider the following linear regression with one parameter (intercept known). for i = 1,....n a) Compute the LSE , MLE , mean and varience for . I understand how to derive the following when both the slope and intercept is unknown. However I'm unsure what the effect of knowing what the intercept will have on the new computations. Attempt: We minimsise the LSE by setting After long computations we get The computation of the least square estimator doesn't seem to care wether is known or unknown so would be get the same LSE,MLE,mean and variance as with the case is unknown",\beta_{0}  y_{i} = \beta_{0}^{*} + \beta_{1}x_{i} + \epsilon_{i}  \beta_{1} \partial_{\beta_{1}} S(\beta_{1}) = - \sum_{i=1}^{n} 2x_{i}(y_{i}-\beta_{0}^{*}-\beta_{1}x_{i}) = 0  \beta_{1} = \frac{\sum_{i=1}^{n} x_{i} (y_{i} - \beta_{0}^{*})   }{\sum_{i=1}^{n}(x_{i}^2)} b_{0} b_{0},"['statistics', 'linear-regression']"
81,There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other.,There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other.,,"There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other. Assume that the men and women alternate in a line, how many possible ways are there for the arrangement? Without the condition of Alice and Bob not standing next to eachother, it would be 10! * 10! * 2. Now I need to subtract all the ways in which they could be stuck together, or 9! * 9! * 10 * 2. (I can elaborate on how I got this part if it is wrong) So would the final answer just be 10!10!2 - 9!9!10*2 ??","There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other. Assume that the men and women alternate in a line, how many possible ways are there for the arrangement? Without the condition of Alice and Bob not standing next to eachother, it would be 10! * 10! * 2. Now I need to subtract all the ways in which they could be stuck together, or 9! * 9! * 10 * 2. (I can elaborate on how I got this part if it is wrong) So would the final answer just be 10!10!2 - 9!9!10*2 ??",,"['probability', 'combinatorics', 'statistics']"
82,Statistical Proof of Turán’s Graph Theorem: Weight of Vertex Uniformly Distributed?,Statistical Proof of Turán’s Graph Theorem: Weight of Vertex Uniformly Distributed?,,"If a graph $G = (V, E)$ on $n$ vertices has no $p$ -clique, $p \geq 2$ , then, $|E| \leq (1- \frac{1}{p-1}) \frac{n^2}{2} \cdots (1)$ . We get a proof from the book ""Proofs from THE BOOK"" as given below- Now I could not understand below line- We infer that the maximal value of $f(w)$ is attained for $ w_i = \frac{1}{k} $ on a $k$ -clique... because, then it menas that all vertices have same weight, but earlier, it was assumes that- Suppose $w$ is any distribution In general, can anyone please explain how one can infer that the maximal value of $f(w)$ is attained for $ w_i =\frac{1}{k} $ from $f(w')=f(w)+\epsilon (w_1-w_2)$ ?","If a graph on vertices has no -clique, , then, . We get a proof from the book ""Proofs from THE BOOK"" as given below- Now I could not understand below line- We infer that the maximal value of is attained for on a -clique... because, then it menas that all vertices have same weight, but earlier, it was assumes that- Suppose is any distribution In general, can anyone please explain how one can infer that the maximal value of is attained for from ?","G = (V, E) n p p \geq 2 |E| \leq (1- \frac{1}{p-1}) \frac{n^2}{2} \cdots (1) f(w)  w_i =
\frac{1}{k}  k w f(w)  w_i =\frac{1}{k}  f(w')=f(w)+\epsilon (w_1-w_2)","['statistics', 'probability-distributions', 'graph-theory', 'proof-explanation']"
83,Expected Value of random variables using standard deviation?,Expected Value of random variables using standard deviation?,,"Question: The manager of a popular seafood restaurant estimates that the daily consumption of shrimp is normally distributed with a mean of 15 pounds and a standard deviation of 2.7 pounds. He makes it a point to buy the right amount of shrimp everyday to prevent waste and shortage. Calculate the amount of shrimp that should be bought daily so that it meets demand 92% of the days. I'm under the impression to use the mean/expected value equation: ExP(x), but I'm not sure which values to place into the formula (my textbook doesnt use standard deviation in any of the examples). Or, is this question using binomial distribution probability? Can anyone help me better understand how to compute this? The answers are out of: a.  12.44 b.  19.43 c.  18.93 d.  17.57 e.  10.57","Question: The manager of a popular seafood restaurant estimates that the daily consumption of shrimp is normally distributed with a mean of 15 pounds and a standard deviation of 2.7 pounds. He makes it a point to buy the right amount of shrimp everyday to prevent waste and shortage. Calculate the amount of shrimp that should be bought daily so that it meets demand 92% of the days. I'm under the impression to use the mean/expected value equation: ExP(x), but I'm not sure which values to place into the formula (my textbook doesnt use standard deviation in any of the examples). Or, is this question using binomial distribution probability? Can anyone help me better understand how to compute this? The answers are out of: a.  12.44 b.  19.43 c.  18.93 d.  17.57 e.  10.57",,"['statistics', 'random-variables', 'expected-value']"
84,Why is variance squared rather than cubed (or any other exponent)?,Why is variance squared rather than cubed (or any other exponent)?,,"Variance is $$\dfrac{\sum_{i=1}^{n}(x_i-\bar x)^2}{n-1}$$ But why square the difference? Why not cube it, or any other exponent? Related question .","Variance is But why square the difference? Why not cube it, or any other exponent? Related question .",\dfrac{\sum_{i=1}^{n}(x_i-\bar x)^2}{n-1},"['statistics', 'variance']"
85,"If 0.01% of a population has a disease, what sample size k is needed so that there is a 95% chance that one person with this disease falls into k?","If 0.01% of a population has a disease, what sample size k is needed so that there is a 95% chance that one person with this disease falls into k?",,"I read that this can be done using the Poisson Approximation, which I understand how to do when you are already given a sample size. How would one find the solution to this problem to find the sample size, using a Poisson approximation?","I read that this can be done using the Poisson Approximation, which I understand how to do when you are already given a sample size. How would one find the solution to this problem to find the sample size, using a Poisson approximation?",,"['probability', 'statistics', 'poisson-distribution']"
86,Statistical significance: Test for different (small) sample sizes?,Statistical significance: Test for different (small) sample sizes?,,"I recently finished my simulations which I now need to statistically analyse. I am comparing mean firing rates (FR) of neurons in the same population (Pop1) before and after I change the connectivity probability (Pconn). I have n=140 observations/simulations for the network with the natural connectivity state, but I have only n=5 observations/simulations for the network with varied connectivity. ( I am arbitrarily changing the Pconn, while measuring the FR of a population before and after the change. n=140 observations correspond to BEFORE and n=5 observations correspond to AFTER the change ) I am quite unsure in which statistical test should I use to determine the significance of my results, since the sizes of samples vary so much. Can anyone suggest a solution? Thanks in advance, Tea","I recently finished my simulations which I now need to statistically analyse. I am comparing mean firing rates (FR) of neurons in the same population (Pop1) before and after I change the connectivity probability (Pconn). I have n=140 observations/simulations for the network with the natural connectivity state, but I have only n=5 observations/simulations for the network with varied connectivity. ( I am arbitrarily changing the Pconn, while measuring the FR of a population before and after the change. n=140 observations correspond to BEFORE and n=5 observations correspond to AFTER the change ) I am quite unsure in which statistical test should I use to determine the significance of my results, since the sizes of samples vary so much. Can anyone suggest a solution? Thanks in advance, Tea",,"['statistics', 'descriptive-statistics']"
87,Conditional expectation of a convex function.,Conditional expectation of a convex function.,,say I have a variable $X \sim P(x)$ distributed following some distribution which I do not know. I can estimate the sample mean and variance etc. Suppose I transform as $Y = \exp(X) -1$ . My question is: Is there an analytical formula to connect $\mathbb{E}\big[X\;|\; X>X_0\big]$ to $\mathbb{E}\big[Y\;|\;Y>Y_0\big]$ . Thanks in advance.,say I have a variable distributed following some distribution which I do not know. I can estimate the sample mean and variance etc. Suppose I transform as . My question is: Is there an analytical formula to connect to . Thanks in advance.,X \sim P(x) Y = \exp(X) -1 \mathbb{E}\big[X\;|\; X>X_0\big] \mathbb{E}\big[Y\;|\;Y>Y_0\big],"['probability-theory', 'statistics', 'probability-distributions']"
88,How is the mean represented in boxplots,How is the mean represented in boxplots,,"How is the mean represented in boxplots? In the image below weather situation 3 shows outliers pulling the mean down and so I reasoned that situation 4 would have a higher mean than the rest because the median has a higher Humidity than situation 1 and 2. But, I got the wrong answer. Thank you.","How is the mean represented in boxplots? In the image below weather situation 3 shows outliers pulling the mean down and so I reasoned that situation 4 would have a higher mean than the rest because the median has a higher Humidity than situation 1 and 2. But, I got the wrong answer. Thank you.",,['statistics']
89,Time until next bus,Time until next bus,,"You arrive at a bus stop where buses come at a rate of $3$ per hour. What's the probability distribution of the waiting time for the next bus and its mean if the interarrival times between buses are (a) constant, (b) exponential, (c) either 0 or 60 minutes (groups of 3 buses go by in an hour). I can guess that the mean waiting time for constant is just $c/2$ where $c$ is the constant. In exponential distribution it will be just $\lambda$ . Not so sure about the third one. But getting these means doesn't help me find the distribution. Can anyone suggest me how to do it? I think you need to use the equilibrium distribution, but where do we use the fact that buses come at $3$ per hour? Do I even need this for the constant case?","You arrive at a bus stop where buses come at a rate of per hour. What's the probability distribution of the waiting time for the next bus and its mean if the interarrival times between buses are (a) constant, (b) exponential, (c) either 0 or 60 minutes (groups of 3 buses go by in an hour). I can guess that the mean waiting time for constant is just where is the constant. In exponential distribution it will be just . Not so sure about the third one. But getting these means doesn't help me find the distribution. Can anyone suggest me how to do it? I think you need to use the equilibrium distribution, but where do we use the fact that buses come at per hour? Do I even need this for the constant case?",3 c/2 c \lambda 3,"['probability', 'probability-theory']"
90,Is this method of calculation for the first quartile correct?,Is this method of calculation for the first quartile correct?,,"Given the numbers: $[1,2,3,4,5]$ I want to find the first quartile, so I first find the median $ = 3.$ Now I can split the numbers in the this way: $(1,2)$ $3$ $(4,5)$ Now to find the first quartile or $Q_1$ I must find the median between $(1,2)$ . So that is equal to $(1+2)/2 = 1.5$ . So according to my calculation above $Q_1=1.5$ . If I am correct then why when I search online do I get formulas for the first quartile as such: $Q_1 = \lceil{\frac{1}{4}(n+1)}\rceil th \  term$ using that formula here $Q_1$ would be $\frac{1}{4} (6) = \lceil1.5\rceil = 2$ ,which is position $2$ which is $2$ . Now obviously $2 \neq 1.5$ . So am I wrong in my above calculation ? Also this brings a curious phenomenon. Does $Q_1$ , $Q_3$ never need to be average like the median ? The median in case of even terms needs to be averaged. But why not the other quartiles ? What am I missing here?","Given the numbers: I want to find the first quartile, so I first find the median Now I can split the numbers in the this way: Now to find the first quartile or I must find the median between . So that is equal to . So according to my calculation above . If I am correct then why when I search online do I get formulas for the first quartile as such: using that formula here would be ,which is position which is . Now obviously . So am I wrong in my above calculation ? Also this brings a curious phenomenon. Does , never need to be average like the median ? The median in case of even terms needs to be averaged. But why not the other quartiles ? What am I missing here?","[1,2,3,4,5]  = 3. (1,2) 3 (4,5) Q_1 (1,2) (1+2)/2 = 1.5 Q_1=1.5 Q_1 = \lceil{\frac{1}{4}(n+1)}\rceil th \  term Q_1 \frac{1}{4} (6) = \lceil1.5\rceil = 2 2 2 2 \neq 1.5 Q_1 Q_3","['statistics', 'median']"
91,Why is Chi square test with 1 dof infinite in 0,Why is Chi square test with 1 dof infinite in 0,,"In order to better understand the link between hypothesis testing and likelihood, I was recently trying to compare value of binomial probability and Chi square pearson test in the coin toss (or equivalently random bit generator). If we run 100 coin toss experiments, the probability of finding 50 tails and 50 head is around 8%, given binomial model. Indeed, the likelihood of the binomial model with p=0.5 (my null hypothesis) given the 50/50 outcome is 0.08, which in itself does not means much, but comparing with other models (p=0.1, p=0.2) one can see that this is actually a pretty good likelihood. The problem I have is when I try to analyse the result with chi square pearson test. My null hypothesis is the binomial model with p=0.5. First I don't understand why I can use the Chi square model, what makes it valid in this case, as it is supposed to be used for normally distributed data (what is supposed to be normally distributed here ?) Also, and this is a much bigger issue to me, when computing chi square value with one dof in this case (sist.chi2.pdf(Q,1)), I obtain inf value in the case where the result is 50/50, ie a Q of 0. Why am I seeing this result ? am I right saying that Chi2 test is completely meaningless in the case of 1 dof ? thank you in advance for your help.","In order to better understand the link between hypothesis testing and likelihood, I was recently trying to compare value of binomial probability and Chi square pearson test in the coin toss (or equivalently random bit generator). If we run 100 coin toss experiments, the probability of finding 50 tails and 50 head is around 8%, given binomial model. Indeed, the likelihood of the binomial model with p=0.5 (my null hypothesis) given the 50/50 outcome is 0.08, which in itself does not means much, but comparing with other models (p=0.1, p=0.2) one can see that this is actually a pretty good likelihood. The problem I have is when I try to analyse the result with chi square pearson test. My null hypothesis is the binomial model with p=0.5. First I don't understand why I can use the Chi square model, what makes it valid in this case, as it is supposed to be used for normally distributed data (what is supposed to be normally distributed here ?) Also, and this is a much bigger issue to me, when computing chi square value with one dof in this case (sist.chi2.pdf(Q,1)), I obtain inf value in the case where the result is 50/50, ie a Q of 0. Why am I seeing this result ? am I right saying that Chi2 test is completely meaningless in the case of 1 dof ? thank you in advance for your help.",,"['statistics', 'normal-distribution', 'binomial-distribution', 'hypothesis-testing']"
92,Show that a Weibull distribution belongs to an exponential family,Show that a Weibull distribution belongs to an exponential family,,"I'm studying statistics and came across a problem that I'm having some issues wrapping my head around. I'm given the density function of a Weibull distribution $$ f(y;\lambda,k) = \begin{cases}     \frac k \lambda \left(\frac y \lambda\right)^{k-1}e^{-(y/\lambda)^k},& y\geq 0\\     0,              & y<0 \end{cases} $$ I'm supposed to show that the Weibull distributions with fixed $k$ belongs to the exponential family with the form: $$f_θ(y) = \exp(a(y)b(θ) + c(θ) + d(y))$$ I've taken the logarithm of the function and got: $$\log f(y;λ,k) = \log (k/λ) + (k-1)\log(y/λ) - k(y/λ)$$ I'm unsure how to derive the canonical parameter and determine where the terms belong. Any tips on how to arrange the logs are welcome. EDIT: I've tried rearranging a bit and ended up with $$\log f(y;λ,k) = -y(k/λ) + log(k/λ)-(k-1)*log(y/λ)$$ With a(y) = -y, b(θ) = k/λ, c(θ) = log(k/λ), d(y) = (k-1)*log(y/λ) With the canonic parameter (θ) = k/λ. Though I'm pretty sure this is incorrect.","I'm studying statistics and came across a problem that I'm having some issues wrapping my head around. I'm given the density function of a Weibull distribution I'm supposed to show that the Weibull distributions with fixed belongs to the exponential family with the form: I've taken the logarithm of the function and got: I'm unsure how to derive the canonical parameter and determine where the terms belong. Any tips on how to arrange the logs are welcome. EDIT: I've tried rearranging a bit and ended up with With a(y) = -y, b(θ) = k/λ, c(θ) = log(k/λ), d(y) = (k-1)*log(y/λ) With the canonic parameter (θ) = k/λ. Though I'm pretty sure this is incorrect.","
f(y;\lambda,k) = \begin{cases}
    \frac k \lambda \left(\frac y \lambda\right)^{k-1}e^{-(y/\lambda)^k},& y\geq 0\\
    0,              & y<0
\end{cases}
 k f_θ(y) = \exp(a(y)b(θ) + c(θ) + d(y)) \log f(y;λ,k) = \log (k/λ) + (k-1)\log(y/λ) - k(y/λ) \log f(y;λ,k) = -y(k/λ) + log(k/λ)-(k-1)*log(y/λ)","['statistics', 'logarithms', 'exponential-distribution']"
93,Notation problem for Gaussian Distribution. Vertical Bar,Notation problem for Gaussian Distribution. Vertical Bar,,"In ""Gaussian Process Latent Variable Models forVisualisation of High Dimensional Data"" by Lawrence I stepped over the following definitions of Gaussian Distributions: $p(x) = N(x|0,I)$ $p(y|x,W,\beta) = N(y|Wx,\beta^{-1}I)$ $\rightarrow$ Full definition What is the meaning of the vertical Bar in $N(\cdot|\cdot,\cdot)$ ? And what are the actuall mean $\mu$ of the distrubutions?","In ""Gaussian Process Latent Variable Models forVisualisation of High Dimensional Data"" by Lawrence I stepped over the following definitions of Gaussian Distributions: Full definition What is the meaning of the vertical Bar in ? And what are the actuall mean of the distrubutions?","p(x) = N(x|0,I) p(y|x,W,\beta) = N(y|Wx,\beta^{-1}I) \rightarrow N(\cdot|\cdot,\cdot) \mu","['probability', 'statistics', 'notation', 'normal-distribution', 'machine-learning']"
94,Statistics Question MME and MLE,Statistics Question MME and MLE,,"I have been attempting this question for a while and whenever I get to the standard error question of part (a) I keep getting 0. Ok so ai) $$\ E(X)= 3-2\theta $$ $$\ Var(X) = 2\theta -2\theta^2 $$ for aii) I found my MME by equating first theoretical moment (mu) to the 1st sample moment. First moment is $$ E(X) = 3-2\theta$$ and sample moment is $ 1/n\sum_{i=1}^n X_i =M_k $ ,where n=20 . This can be referred to as X.bar by equating these two I get an estimator of Theta, Theta.hat $$ Theta.hat = (3-2X.bar)/2$$ To get an estimate I plug in Xbar of 1.75 into here and get estimate of $$ \theta=0.625$$ Now to find Standard error I first need to find variance $$Var(theta.hat)= E(theta.hat^2)- E(theta.hat)^2$$ However now as I substitute in my estimator into the equation I find they just cancel, giving me a variance of 0","I have been attempting this question for a while and whenever I get to the standard error question of part (a) I keep getting 0. Ok so ai) for aii) I found my MME by equating first theoretical moment (mu) to the 1st sample moment. First moment is and sample moment is ,where n=20 . This can be referred to as X.bar by equating these two I get an estimator of Theta, Theta.hat To get an estimate I plug in Xbar of 1.75 into here and get estimate of Now to find Standard error I first need to find variance However now as I substitute in my estimator into the equation I find they just cancel, giving me a variance of 0",\ E(X)= 3-2\theta  \ Var(X) = 2\theta -2\theta^2   E(X) = 3-2\theta  1/n\sum_{i=1}^n X_i =M_k   Theta.hat = (3-2X.bar)/2  \theta=0.625 Var(theta.hat)= E(theta.hat^2)- E(theta.hat)^2,['statistics']
95,Finding the True Mean: How to solve this?,Finding the True Mean: How to solve this?,,"This is the last question I have to ask for a project at my university, I have until the 20th of August to answer this, but I have been staring at it all week and have found no clues that I can understand in the book provided to me by the university. I'm bordering on desperate now. Can packaging of a healthy food product influence child´s desire to consume the product? This was the question of interest in an article published in the Journal of Consumer Behaviour (Vol. 10, 2011). A fictitious brand of a healthy food product – sliced apples- was packaged to appeal to children (a smiling cartoon apple was on the front of the package). The researchers showed the packaging to a sample of 408 school children and asked each whether he or she was willing to eat the product. Willingness to eat was measured on a 5-point scale, with 1 = “not willing at all” and 5 = “very willing”. The data are summarized as follows: x-bar = 3.69, s = 2.44. Suppose the researchers knew that the mean willingness to eat an actual brand of sliced apples (which is not packaged for children) is µ = 3. a) Conduct a test to determine whether the true mean willingness to eat the brand of sliced apples packaged for children exceeded 3. Use α = 0.05 to make your conclusion. (2.5 points) b) The data (willingness to eat values) are not normally distributed. How does this impact (if at all) the validity of your conclusion in part a)? (0.5 points) So basically I need the answer to this. I have tried everything I can remember and I find nothing. I'm certain it has something to do with a hypothesis test for the true mean, but I lack the knowledge on how to properly solve it, or if it is the Z-value or the T-value or something else they are asking me to provide. I tried using this formula:     Z=(3.69-3)/(2.44/√408)=5.71. And then I realised that I didn't even use the α =0.05 that part A demands I use.","This is the last question I have to ask for a project at my university, I have until the 20th of August to answer this, but I have been staring at it all week and have found no clues that I can understand in the book provided to me by the university. I'm bordering on desperate now. Can packaging of a healthy food product influence child´s desire to consume the product? This was the question of interest in an article published in the Journal of Consumer Behaviour (Vol. 10, 2011). A fictitious brand of a healthy food product – sliced apples- was packaged to appeal to children (a smiling cartoon apple was on the front of the package). The researchers showed the packaging to a sample of 408 school children and asked each whether he or she was willing to eat the product. Willingness to eat was measured on a 5-point scale, with 1 = “not willing at all” and 5 = “very willing”. The data are summarized as follows: x-bar = 3.69, s = 2.44. Suppose the researchers knew that the mean willingness to eat an actual brand of sliced apples (which is not packaged for children) is µ = 3. a) Conduct a test to determine whether the true mean willingness to eat the brand of sliced apples packaged for children exceeded 3. Use α = 0.05 to make your conclusion. (2.5 points) b) The data (willingness to eat values) are not normally distributed. How does this impact (if at all) the validity of your conclusion in part a)? (0.5 points) So basically I need the answer to this. I have tried everything I can remember and I find nothing. I'm certain it has something to do with a hypothesis test for the true mean, but I lack the knowledge on how to properly solve it, or if it is the Z-value or the T-value or something else they are asking me to provide. I tried using this formula:     Z=(3.69-3)/(2.44/√408)=5.71. And then I realised that I didn't even use the α =0.05 that part A demands I use.",,"['statistics', 'normal-distribution', 'hypothesis-testing']"
96,Linear regression: equivalence of forms of the minimum variance affine unbiased estimator,Linear regression: equivalence of forms of the minimum variance affine unbiased estimator,,"Background Consider the linear regression model: $$y = X\beta + e\\E[e] = 0 \quad E[ee^T] = V$$ It is well known that the minimum variance affine unbiased estimator (MVAUE) of $\beta$ exists if and only if $X$ has linearly independent columns. In this case, the MVAUE is unique and given by $$\hat\beta = My = \arg \min_\beta \, (y - X\beta)^T V_0^+ (y - X\beta)$$ where $$ \begin{align} M &:= (X^T V_0^+ X)^{-1} X^T V_0^+ \\ V_0 &:= V + XUX^T \end{align} $$ and $U$ is any positive semidefinite matrix such that $\mathrm{col}\, X \subseteq \mathrm{col}\, V_0$ , where $V_0 := V + XUX^T$ . The superscript ""+"" denotes Moore-Penrose inverse. Chapter 4 (in particular, section i) of C. R. Rao's ""Linear Statistical Inference and it's Applications"" and Chapter 13 of Magnus and Neudecker's ""Matrix Differential Calculus with Applications in Statistics and Econometrics"" are two good references on the subject, for the curious. My question I want to demonstrate that the matrix $$M = [X^T (V + XUX^T)^+ X]^{-1} X^T (V + XUX^T)^+$$ is independent of the particular choice of $U$ , provided that $X$ has linearly independent columns and that $U$ satisfies the aforementioned conditions (though I would be happy with a solution that strengthened the assumption on $U$ to $U > 0$ ). I have solved the problem for two subcases, $V = 0$ and $V > 0$ , and I offer these solutions below. A proof for the case where $V \geq 0$ is singular, but nonzero, has been elusive. Partial solution: Assume $V = 0$ and $U > 0$ We will show that $M = X^+$ . First note that $MX = I$ . Therefore $XMX = X$ and $MXM = M$ . Now observe $$ \begin{align} X^T(XUX^T)^+X &= (U^{-1}X^+XU) X^T(XUX^T)^+X (U X^T X^{+T} U^{-1}) \\ &= (U^{-1}X^+) (XU X^T) (XUX^T)^+ (X U X^T) (X^{+T} U^{-1}) \\ &= (U^{-1}X^+) (XU X^T) (X^{+T} U^{-1}) \\ &= U^{-1} U U^{-1} \\ &= U^{-1} \end{align} $$ Therefore $$ \begin{align} XM &= X [X^T (XUX^T)^+ X]^{-1} X^T (XUX^T)^+ \\ &= XUX^T (XUX^T)^+ \end{align} $$ is symmetric, due to the properties of $(XUX^T)^+$ . We have demonstrated that $M$ satisfies all four conditions required to be the Moore-Penrose inverse of $X$ . Partial solution: Assume $V > 0$ and $U > 0$ Applying the Woodbury matrix identity gives $$ \begin{align} (V + XUX^T)^{-1} &= V^{-1} - V^{-1}X(X^TV^{-1}X + U^{-1})^{-1}X^TV^{-1} \\ (V + XUX^T)^{-1}X &= V^{-1}X(X^TV^{-1}X + U^{-1})^{-1}U^{-1} \\ X^T(V + XUX^T)^{-1}X &= X^TV^{-1}X(X^TV^{-1}X + U^{-1})^{-1}U^{-1} \\ [X^T(V + XUX^T)^{-1}X]^{-1} &= U + (X^TV^{-1}X)^{-1} \end{align} $$ Combining these results in the correct manner (I'll omit the details for now, for the sake of brevity, but I would be happy to give them upon request), one can derive $$M = (X^TV^{-1}X)^{-1}X^TV^{-1}$$","Background Consider the linear regression model: It is well known that the minimum variance affine unbiased estimator (MVAUE) of exists if and only if has linearly independent columns. In this case, the MVAUE is unique and given by where and is any positive semidefinite matrix such that , where . The superscript ""+"" denotes Moore-Penrose inverse. Chapter 4 (in particular, section i) of C. R. Rao's ""Linear Statistical Inference and it's Applications"" and Chapter 13 of Magnus and Neudecker's ""Matrix Differential Calculus with Applications in Statistics and Econometrics"" are two good references on the subject, for the curious. My question I want to demonstrate that the matrix is independent of the particular choice of , provided that has linearly independent columns and that satisfies the aforementioned conditions (though I would be happy with a solution that strengthened the assumption on to ). I have solved the problem for two subcases, and , and I offer these solutions below. A proof for the case where is singular, but nonzero, has been elusive. Partial solution: Assume and We will show that . First note that . Therefore and . Now observe Therefore is symmetric, due to the properties of . We have demonstrated that satisfies all four conditions required to be the Moore-Penrose inverse of . Partial solution: Assume and Applying the Woodbury matrix identity gives Combining these results in the correct manner (I'll omit the details for now, for the sake of brevity, but I would be happy to give them upon request), one can derive","y = X\beta + e\\E[e] = 0 \quad E[ee^T] = V \beta X \hat\beta = My = \arg \min_\beta \, (y - X\beta)^T V_0^+ (y - X\beta) 
\begin{align}
M &:= (X^T V_0^+ X)^{-1} X^T V_0^+ \\
V_0 &:= V + XUX^T
\end{align}
 U \mathrm{col}\, X \subseteq \mathrm{col}\, V_0 V_0 := V + XUX^T M = [X^T (V + XUX^T)^+ X]^{-1} X^T (V + XUX^T)^+ U X U U U > 0 V = 0 V > 0 V \geq 0 V = 0 U > 0 M = X^+ MX = I XMX = X MXM = M 
\begin{align}
X^T(XUX^T)^+X &= (U^{-1}X^+XU) X^T(XUX^T)^+X (U X^T X^{+T} U^{-1}) \\
&= (U^{-1}X^+) (XU X^T) (XUX^T)^+ (X U X^T) (X^{+T} U^{-1}) \\
&= (U^{-1}X^+) (XU X^T) (X^{+T} U^{-1}) \\
&= U^{-1} U U^{-1} \\
&= U^{-1}
\end{align}
 
\begin{align}
XM &= X [X^T (XUX^T)^+ X]^{-1} X^T (XUX^T)^+ \\
&= XUX^T (XUX^T)^+
\end{align}
 (XUX^T)^+ M X V > 0 U > 0 
\begin{align}
(V + XUX^T)^{-1} &= V^{-1} - V^{-1}X(X^TV^{-1}X + U^{-1})^{-1}X^TV^{-1} \\
(V + XUX^T)^{-1}X &= V^{-1}X(X^TV^{-1}X + U^{-1})^{-1}U^{-1} \\
X^T(V + XUX^T)^{-1}X &= X^TV^{-1}X(X^TV^{-1}X + U^{-1})^{-1}U^{-1} \\
[X^T(V + XUX^T)^{-1}X]^{-1} &= U + (X^TV^{-1}X)^{-1}
\end{align}
 M = (X^TV^{-1}X)^{-1}X^TV^{-1}","['linear-algebra', 'matrices', 'statistics', 'regression', 'pseudoinverse']"
97,Noise Bottleneck of Nassim Taleb,Noise Bottleneck of Nassim Taleb,,"In several of Nassim Taleb's books he mentions a phenomenon referred to as a noise bottleneck where more sampling of something actually decreases your signal to noise relationship: ""Assume further that for what you are observing, at a yearly frequency, the ratio of signal to noise is about one to one (half noise, half signal)—this means that about half the changes are real improvements or degradations, the other half come from randomness. This ratio is what you get from yearly observations. But if you look at the very same data on a daily basis, the composition would change to 95 percent noise, 5 percent signal. And if you observe data on an hourly basis, as people immersed in the news and market price variations do, the split becomes 99.5 percent noise to 0.5 percent signal."" - Antifragile pg. 126 All of the situations I can think of have the opposite effect, where longer sampling times (more data) average out the noise and improve your signal to noise ratio.  Can anyone give a mathematical example of this noise bottleneck?","In several of Nassim Taleb's books he mentions a phenomenon referred to as a noise bottleneck where more sampling of something actually decreases your signal to noise relationship: ""Assume further that for what you are observing, at a yearly frequency, the ratio of signal to noise is about one to one (half noise, half signal)—this means that about half the changes are real improvements or degradations, the other half come from randomness. This ratio is what you get from yearly observations. But if you look at the very same data on a daily basis, the composition would change to 95 percent noise, 5 percent signal. And if you observe data on an hourly basis, as people immersed in the news and market price variations do, the split becomes 99.5 percent noise to 0.5 percent signal."" - Antifragile pg. 126 All of the situations I can think of have the opposite effect, where longer sampling times (more data) average out the noise and improve your signal to noise ratio.  Can anyone give a mathematical example of this noise bottleneck?",,"['probability', 'statistics']"
98,Find joint distribution of same-mean normal variables,Find joint distribution of same-mean normal variables,,"Suppose I have a variable $C$ and a set of $N$ variables $L_1, L_2, ..., L_N$ that are distributed according to: $$\begin{aligned} C &\sim \mathcal N \left(\mu, \delta^2 \right) \\ \forall i. L_i | C=c &\sim \mathcal N\left(c, \sigma_i^2 \right) \end{aligned}$$ That is, conditional on knowing the value of $C$ , the $L_i$ are normally independently distributed with mean $c$ and variance $\sigma_i^2$ . This implies that the vector $\vec L = (L_1, ..., L_N)^T$ is distributed according to a N-dimensional multivariate normal with mean vector $\vec \mu$ and covariance matrix $\mathbf \Sigma$ . When $N=1$ , it is straightforward to see that $L_1 \sim \mathcal N \left(\mu, \delta^2 + \sigma_1^2 \right)$ . It seems to me like this should imply that $\vec \mu = (\mu, ..., \mu)^T$ , and that the diagonal elements of $\mathbf \Sigma$ should be $\delta^2 + \sigma_i^2$ . The off-diagonal elements of the covariance matrix are, of course, not zero, since the variables $L_i$ are not independent when I'm not conditioning on $C$ . Is this true, though? Is there a way for me to prove this in a less tedious way than algebraically working everything out? What are the values of the off-diagonal elements?","Suppose I have a variable and a set of variables that are distributed according to: That is, conditional on knowing the value of , the are normally independently distributed with mean and variance . This implies that the vector is distributed according to a N-dimensional multivariate normal with mean vector and covariance matrix . When , it is straightforward to see that . It seems to me like this should imply that , and that the diagonal elements of should be . The off-diagonal elements of the covariance matrix are, of course, not zero, since the variables are not independent when I'm not conditioning on . Is this true, though? Is there a way for me to prove this in a less tedious way than algebraically working everything out? What are the values of the off-diagonal elements?","C N L_1, L_2, ..., L_N \begin{aligned}
C &\sim \mathcal N \left(\mu, \delta^2 \right) \\
\forall i. L_i | C=c &\sim \mathcal N\left(c, \sigma_i^2 \right)
\end{aligned} C L_i c \sigma_i^2 \vec L = (L_1, ..., L_N)^T \vec \mu \mathbf \Sigma N=1 L_1 \sim \mathcal N \left(\mu, \delta^2 + \sigma_1^2 \right) \vec \mu = (\mu, ..., \mu)^T \mathbf \Sigma \delta^2 + \sigma_i^2 L_i C","['probability-theory', 'statistics', 'probability-distributions', 'normal-distribution', 'bayesian']"
99,Noisy communication: threshold detecting,Noisy communication: threshold detecting,,"I would like to check if my solution to a standard problem in Bayesian statistics is correct. We study a simple noisy communication channel. Suppose that $\mathsf{X}$ is a binary signal that takes value $-1$ and $1$ with equal probability. The received signal is $\mathsf{Y} = \mathsf{X} + \mathsf{N}$ , where $\mathsf{N}$ is a standard normal, independent of $\mathsf{X}$ . The decoder receives the value of $\mathsf{Y}$ and decides whether $\mathsf{X}$ was $1$ or $-1$ using the following decoding rule: $\mathsf{X}$ was $1$ if and only if: $$\mathbb{P}(\mathsf{X} =1 | \mathsf{Y} = y) > 2 \cdot \mathbb{P}(\mathsf{X} =-1 | \mathsf{Y} = y) .$$ It turns out that the decoding rule can be expressed in the form: decide in favour of $1$ if and only if $\mathsf{Y} > t$ for some threshold $t$ . Find the threshold. My solution was to apply the mixed Bayes rule (e.g. $\mathbb{P}(\mathsf{X} =1 | \mathsf{Y}= y) =\frac{f_{\mathsf{Y}|x=1}(y) \cdot \mathbb{P}(\mathsf{X} =1)}{f_{\mathsf{Y}}(y)} $ )  to both sides and solve the inequality in the variable $y$ . After some computations, this led me to the threshold $$t=\frac{\ln(2)}{2}.$$ Does this solution make any sense?","I would like to check if my solution to a standard problem in Bayesian statistics is correct. We study a simple noisy communication channel. Suppose that is a binary signal that takes value and with equal probability. The received signal is , where is a standard normal, independent of . The decoder receives the value of and decides whether was or using the following decoding rule: was if and only if: It turns out that the decoding rule can be expressed in the form: decide in favour of if and only if for some threshold . Find the threshold. My solution was to apply the mixed Bayes rule (e.g. )  to both sides and solve the inequality in the variable . After some computations, this led me to the threshold Does this solution make any sense?",\mathsf{X} -1 1 \mathsf{Y} = \mathsf{X} + \mathsf{N} \mathsf{N} \mathsf{X} \mathsf{Y} \mathsf{X} 1 -1 \mathsf{X} 1 \mathbb{P}(\mathsf{X} =1 | \mathsf{Y} = y) > 2 \cdot \mathbb{P}(\mathsf{X} =-1 | \mathsf{Y} = y) . 1 \mathsf{Y} > t t \mathbb{P}(\mathsf{X} =1 | \mathsf{Y}= y) =\frac{f_{\mathsf{Y}|x=1}(y) \cdot \mathbb{P}(\mathsf{X} =1)}{f_{\mathsf{Y}}(y)}  y t=\frac{\ln(2)}{2}.,"['probability', 'statistics', 'bayesian']"
