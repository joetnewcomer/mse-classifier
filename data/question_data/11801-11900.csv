,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How do you derive the quadratic formula using calculus?,How do you derive the quadratic formula using calculus?,,"The quadratic formula: $$f(x)=ax^2+bx+c=0$$ $$x=\frac{-b \pm \sqrt{b^2-4ac}}{2a}$$ I remember a tutor once showing me a method for deriving the quadratic formula using calculus somehow. This was around 20 years ago and I can't even remember the tutor's name. I'd really like to learn this method. Just to clarify, I do know how to derive it using the ""Completing the square"" method. I was linked to the solution here: https://www.google.com/amp/s/threesixty360.wordpress.com/2008/10/19/using-calculus-to-generate-the-quadratic-formula/amp/ But I am stuck at one step. Start with: $$f(x)=ax^2+bx+c$$ We want: $$f(x)=0$$ The first derivative gives: $$f'(x)=2ax+b$$ Which leads to this: $$f(x)=c+\int_0^x (2at+b)dt$$ I can't see why the $t's$ were introduced here. If anyone has any other methods I'd really like to see them also.","The quadratic formula: $$f(x)=ax^2+bx+c=0$$ $$x=\frac{-b \pm \sqrt{b^2-4ac}}{2a}$$ I remember a tutor once showing me a method for deriving the quadratic formula using calculus somehow. This was around 20 years ago and I can't even remember the tutor's name. I'd really like to learn this method. Just to clarify, I do know how to derive it using the ""Completing the square"" method. I was linked to the solution here: https://www.google.com/amp/s/threesixty360.wordpress.com/2008/10/19/using-calculus-to-generate-the-quadratic-formula/amp/ But I am stuck at one step. Start with: $$f(x)=ax^2+bx+c$$ We want: $$f(x)=0$$ The first derivative gives: $$f'(x)=2ax+b$$ Which leads to this: $$f(x)=c+\int_0^x (2at+b)dt$$ I can't see why the $t's$ were introduced here. If anyone has any other methods I'd really like to see them also.",,"['calculus', 'linear-algebra', 'quadratics']"
1,Length of a Parabolic Curve,Length of a Parabolic Curve,,"I just wanted to know how I can find the length of a curve given by $f(x) = x^2$ from $x=0$ to $x=1$. For appproximation, the length is a bit larger than the hypotenuse of isosceles right triangle with the shorter side being 1 long.  It's definitely less than the sum of two shorter sides.  Thus, if we represent the length by $L$, the following relationship is expected: $\sqrt 2 < L < 2$ I now regard $L$ as the accumulation of hypotenuses of infinitestimally small right triangles around $f(x)$.  Since $f'(x)=2x$, the general right triangle is something like this: If $x$ goes very slightly down the $x$-axis ($\Delta x$), the the $y$ value goes upwards for $2x\Delta x$. Thus the hypontenuse is the square root of the following: $(\Delta x)^2+(2x\Delta x)^2$. The hypotenuse is: $(\Delta x) {( 4x^2 + 1)^{1/2}}$ Since $L$ has been defined as the accumulation of these hypotenuses, it is: $L = \int_0^1 ( 4x^2 + 1)^{1/2} dx$. I am stuck just here.  Could someone tell me if my chain of thoughts so far is right and how I can go from here?  I don't know how to calculate the integral of a function that contains another function in it. Thanks!!","I just wanted to know how I can find the length of a curve given by $f(x) = x^2$ from $x=0$ to $x=1$. For appproximation, the length is a bit larger than the hypotenuse of isosceles right triangle with the shorter side being 1 long.  It's definitely less than the sum of two shorter sides.  Thus, if we represent the length by $L$, the following relationship is expected: $\sqrt 2 < L < 2$ I now regard $L$ as the accumulation of hypotenuses of infinitestimally small right triangles around $f(x)$.  Since $f'(x)=2x$, the general right triangle is something like this: If $x$ goes very slightly down the $x$-axis ($\Delta x$), the the $y$ value goes upwards for $2x\Delta x$. Thus the hypontenuse is the square root of the following: $(\Delta x)^2+(2x\Delta x)^2$. The hypotenuse is: $(\Delta x) {( 4x^2 + 1)^{1/2}}$ Since $L$ has been defined as the accumulation of these hypotenuses, it is: $L = \int_0^1 ( 4x^2 + 1)^{1/2} dx$. I am stuck just here.  Could someone tell me if my chain of thoughts so far is right and how I can go from here?  I don't know how to calculate the integral of a function that contains another function in it. Thanks!!",,"['calculus', 'conic-sections']"
2,Is it possible to formulate variational calculus geometrically?,Is it possible to formulate variational calculus geometrically?,,"In textbooks I've seen differential geometry is done with finite-dimensional manifolds. Is it possible to generalise to banach manifolds so as to formulate the calculus of variations within it, or does this naive approach hit problems? And if so where?","In textbooks I've seen differential geometry is done with finite-dimensional manifolds. Is it possible to generalise to banach manifolds so as to formulate the calculus of variations within it, or does this naive approach hit problems? And if so where?",,"['calculus', 'differential-geometry', 'classical-mechanics']"
3,Tough Nested Integral,Tough Nested Integral,,Does anyone know of any clever tricks that solve $$\large G_n(t) = \int_0^t dt_1 \int_0^{t_1} dt_2 \cdots \int_0^{t_{n-2}}dt_{n-1}\int_0^{t_{n-1}}dt_{n} e^{i\lambda(t_1-t_2+t_3-\cdots + t_{n-1}-t_n)}$$ I've come up with a few recursion relations but I'm finding it hard to pin down the exact answer.,Does anyone know of any clever tricks that solve $$\large G_n(t) = \int_0^t dt_1 \int_0^{t_1} dt_2 \cdots \int_0^{t_{n-2}}dt_{n-1}\int_0^{t_{n-1}}dt_{n} e^{i\lambda(t_1-t_2+t_3-\cdots + t_{n-1}-t_n)}$$ I've come up with a few recursion relations but I'm finding it hard to pin down the exact answer.,,"['calculus', 'integration']"
4,"$\int_0^\infty \frac{u^5 \, J_0\left( u\right)}{\left( u^2+x^2 \right)^{1/2}}\,e^{- u-\left( u^2+x^2 \right)^{1/2} }\,\mathrm{d}u $",,"\int_0^\infty \frac{u^5 \, J_0\left( u\right)}{\left( u^2+x^2 \right)^{1/2}}\,e^{- u-\left( u^2+x^2 \right)^{1/2} }\,\mathrm{d}u ","Consider the following infinite integral that emerged while solving a fluid physical problem involving viscous flow in porous media: $$ f(x) = \int_0^\infty \frac{u^5 \, J_0 \left( u\right) }{\left( u^2+x^2 \right)^{1/2}} \, e^{- u-\left( u^2\,+\,x^2 \right)^{1/2}} \, \mathrm{d} u \, , $$ wherein $x \in \mathbb{R}$ is the real variable. Here, $J_0$ denotes the zeroth-order Bessel function of the first kind. While a closed analytical expression might most likely be delicate and far from being trivial, I was wondering whether the above integral can potentially be transformed into a single infinite sum . What I tried is to use the following infinite series expansion of the Bessel function: $$ J_0 (u) = \sum_{m \ge 0} \frac{(-1)^m}{m!^2} \left( \frac{u}{2} \right)^{2m} \, , $$ together with $$ e^{-\left( u^2\,+\,x^2 \right)^{1/2}} = \sum_{n \ge 0} \frac{(-1)^n}{n!} \left( u^2+x^2 \right)^{n/2} \, , $$ leading to a double sum, which does not seem to be converging to the original function for some reason. Alternatively, I tried to use Poisson's integral to write the Bessel function in the form $$ J_0(u) = \frac{2}{\pi} \int_0^1 \frac{\cos uv}{\left(1-v^2\right)^{1/2}} \, \mathrm{d} v $$ and interchange the order of integration. Unfortunately this trick also does not seem to be of great help. Any hints would be highly appreciated. Thank you! In particular, for $x=0$ , it can readily be shown that $$ f(0) = \frac{21 \sqrt{5}}{625} \, . $$","Consider the following infinite integral that emerged while solving a fluid physical problem involving viscous flow in porous media: wherein is the real variable. Here, denotes the zeroth-order Bessel function of the first kind. While a closed analytical expression might most likely be delicate and far from being trivial, I was wondering whether the above integral can potentially be transformed into a single infinite sum . What I tried is to use the following infinite series expansion of the Bessel function: together with leading to a double sum, which does not seem to be converging to the original function for some reason. Alternatively, I tried to use Poisson's integral to write the Bessel function in the form and interchange the order of integration. Unfortunately this trick also does not seem to be of great help. Any hints would be highly appreciated. Thank you! In particular, for , it can readily be shown that","
f(x) = \int_0^\infty
\frac{u^5 \, J_0 \left( u\right) }{\left( u^2+x^2 \right)^{1/2}} \, e^{- u-\left( u^2\,+\,x^2 \right)^{1/2}}
\, \mathrm{d} u \, ,
 x \in \mathbb{R} J_0 
J_0 (u) = \sum_{m \ge 0} \frac{(-1)^m}{m!^2} \left( \frac{u}{2} \right)^{2m} \, ,
 
e^{-\left( u^2\,+\,x^2 \right)^{1/2}} = \sum_{n \ge 0} \frac{(-1)^n}{n!} \left( u^2+x^2 \right)^{n/2} \, ,
 
J_0(u) = \frac{2}{\pi} \int_0^1 \frac{\cos uv}{\left(1-v^2\right)^{1/2}} \, \mathrm{d} v
 x=0 
f(0) = \frac{21 \sqrt{5}}{625} \, .
","['calculus', 'integration', 'sequences-and-series', 'improper-integrals', 'bessel-functions']"
5,Inequality $(1-e^x)\ln(1-xe^{-x})\leq x^2$,Inequality,(1-e^x)\ln(1-xe^{-x})\leq x^2,"This inequality, which appears to hold for all $x\in\Bbb R$ , $$(1-e^x)\ln(1-xe^{-x})\leq x^2$$ arose when I tried to prove that the positive root of $x-\frac{x^2}{a}-\log(x+1)$ is bounded above by $a-\log(a+1)$ . Note that for the question linked, it suffices to prove the inequality for $x>0$ , but I found it holds for $x<0$ too. The LHS is neither even nor odd so we will need to consider each case separately. Near zero, the bound is very tight; for example, expressing the inequality as an integral $$\int_0^x\left(1-3t-\frac{(t-1)^2}{e^t-t}-e^t \ln\left(1-t e^{-t}\right)\right)\,dt<0$$ fails since both $1-3t-\frac{(t-1)^2}{(e^t-t)}$ and $e^t\ln(1-te^{-t})$ are strictly decreasing. Can the inequality be analytically proven?","This inequality, which appears to hold for all , arose when I tried to prove that the positive root of is bounded above by . Note that for the question linked, it suffices to prove the inequality for , but I found it holds for too. The LHS is neither even nor odd so we will need to consider each case separately. Near zero, the bound is very tight; for example, expressing the inequality as an integral fails since both and are strictly decreasing. Can the inequality be analytically proven?","x\in\Bbb R (1-e^x)\ln(1-xe^{-x})\leq x^2 x-\frac{x^2}{a}-\log(x+1) a-\log(a+1) x>0 x<0 \int_0^x\left(1-3t-\frac{(t-1)^2}{e^t-t}-e^t \ln\left(1-t e^{-t}\right)\right)\,dt<0 1-3t-\frac{(t-1)^2}{(e^t-t)} e^t\ln(1-te^{-t})","['calculus', 'inequality']"
6,Prove that $\int_{0}^{\frac{\pi }{2}}\sin(\cos(x))+\cos(\sin(x))dx\leq \frac{\pi ^{2}}{4}$,Prove that,\int_{0}^{\frac{\pi }{2}}\sin(\cos(x))+\cos(\sin(x))dx\leq \frac{\pi ^{2}}{4},"Let $f:\left [ 0,\frac{\pi }{2} \right ]\rightarrow \mathbb{R}, f(x)=\sin(\cos(x))+\cos(\sin(x))$. Prove that $$\int\limits_{0}^{\pi/2}f(x)\,\mathrm{d}x\leq \frac{\pi ^{2}}{4}\,.$$ I've managed to find that $f$ is decreasing on $\left [ 0,\frac{\pi }{2} \right ]$, hence:  $$ \int\limits_{0}^{\pi/2} f(x)\,\mathrm{d}x      \leq \int\limits_{0}^{\pi/2} f(0)\,\mathrm{d}x       =   \frac{\pi }{2}\cdot (1+\sin(1))$$  But $1+\sin(1)\geq \frac{\pi }{2}$, thus my inequality isn't enough to prove the problem statement.","Let $f:\left [ 0,\frac{\pi }{2} \right ]\rightarrow \mathbb{R}, f(x)=\sin(\cos(x))+\cos(\sin(x))$. Prove that $$\int\limits_{0}^{\pi/2}f(x)\,\mathrm{d}x\leq \frac{\pi ^{2}}{4}\,.$$ I've managed to find that $f$ is decreasing on $\left [ 0,\frac{\pi }{2} \right ]$, hence:  $$ \int\limits_{0}^{\pi/2} f(x)\,\mathrm{d}x      \leq \int\limits_{0}^{\pi/2} f(0)\,\mathrm{d}x       =   \frac{\pi }{2}\cdot (1+\sin(1))$$  But $1+\sin(1)\geq \frac{\pi }{2}$, thus my inequality isn't enough to prove the problem statement.",,"['calculus', 'inequality', 'definite-integrals']"
7,"Extending functions from integers to reals in a ""nice"" way.","Extending functions from integers to reals in a ""nice"" way.",,"For every function $f$ from $\mathbb{Z}$ to $\mathbb{R}$, can we find a function $g$ from $\mathbb{R}$ to $\mathbb{R}$ that is infinitely differentiable and agrees with $f$ on $\mathbb{Z}$? Furthermore, would there be a simple way to explicitly define a $g$ for every $f$? Could we impose stronger conditions on $g$ than this; I feel making $g$ infinitely differentiable wouldn't be too difficult in some piecewise way (perhaps using variations of $e^{-1/x^2}$ that are stretched and stitched together so all derivatives are 0 at every integer, though this seems ugly), but perhaps we can also find a $g$ equal to its Taylor series around a point, or a $g$ satisfying other nice conditions? Thanks.","For every function $f$ from $\mathbb{Z}$ to $\mathbb{R}$, can we find a function $g$ from $\mathbb{R}$ to $\mathbb{R}$ that is infinitely differentiable and agrees with $f$ on $\mathbb{Z}$? Furthermore, would there be a simple way to explicitly define a $g$ for every $f$? Could we impose stronger conditions on $g$ than this; I feel making $g$ infinitely differentiable wouldn't be too difficult in some piecewise way (perhaps using variations of $e^{-1/x^2}$ that are stretched and stitched together so all derivatives are 0 at every integer, though this seems ugly), but perhaps we can also find a $g$ equal to its Taylor series around a point, or a $g$ satisfying other nice conditions? Thanks.",,"['calculus', 'functions']"
8,show $\lim_{x\to 0}\frac{e^x-1}{x}=1$ without L'Hopital,show  without L'Hopital,\lim_{x\to 0}\frac{e^x-1}{x}=1,"how would you show that $$\lim_{x\to 0}\frac{e^x-1}{x}=1$$ without using derivatives or l'hopital but using basic ideas that are generally introduced just before derivatives in a typical introductory calculus course. my attempt.. $$\lim_{x\to 0}\frac{e^x-1}{x}=\lim_{x\to 0}\lim_{n\to \infty}\frac{\left(1+\frac{x}{n}\right)^n-1}{x}$$ then.. this is $$ =\lim_{x\to 0}\lim_{n\to \infty}\frac{1+{n \choose 1}\frac{x}{n} + {n \choose 2}\left(\frac{x}{n}\right)^2 +\cdots+ {n \choose n}\left(\frac{x}{n}\right)^n -1}{x}$$ $$ =\lim_{x\to 0}\lim_{n\to \infty} \left[ 1+ \frac{   {n \choose 2}\left(\frac{x}{n}\right)^2 +\cdots+ {n \choose n}\left(\frac{x}{n}\right)^n }{x}\right]$$ then we could switch the limit order but the justification for this seems to be not very basic and I would like to provide a basic explanation, as basic as possible. by the way I am doing this to provide a pre-derivatives proof of $$\lim_{x\to c}\frac{e^x-e^c}{x-c}=e^c$$ thank you.","how would you show that $$\lim_{x\to 0}\frac{e^x-1}{x}=1$$ without using derivatives or l'hopital but using basic ideas that are generally introduced just before derivatives in a typical introductory calculus course. my attempt.. $$\lim_{x\to 0}\frac{e^x-1}{x}=\lim_{x\to 0}\lim_{n\to \infty}\frac{\left(1+\frac{x}{n}\right)^n-1}{x}$$ then.. this is $$ =\lim_{x\to 0}\lim_{n\to \infty}\frac{1+{n \choose 1}\frac{x}{n} + {n \choose 2}\left(\frac{x}{n}\right)^2 +\cdots+ {n \choose n}\left(\frac{x}{n}\right)^n -1}{x}$$ $$ =\lim_{x\to 0}\lim_{n\to \infty} \left[ 1+ \frac{   {n \choose 2}\left(\frac{x}{n}\right)^2 +\cdots+ {n \choose n}\left(\frac{x}{n}\right)^n }{x}\right]$$ then we could switch the limit order but the justification for this seems to be not very basic and I would like to provide a basic explanation, as basic as possible. by the way I am doing this to provide a pre-derivatives proof of $$\lim_{x\to c}\frac{e^x-e^c}{x-c}=e^c$$ thank you.",,"['calculus', 'limits', 'limits-without-lhopital']"
9,Why is arc length not in the formula for the volume of a solid of revolution?,Why is arc length not in the formula for the volume of a solid of revolution?,,"I have difficulty understanding the difference between calculating the volume of a solid of revolution, and the surface area of a solid of revolution. When calculating the volume , using disc integration, I've been taught to reason in the following way: divide the solid into several cylinders of infinitesimal width $dx$. Then each such cylinder has radius $f(x)$ , so its volume is $\pi\cdot f(x)^2~dx$ . Hence the total volume of the solid of revolution is $V=\pi\int_a^b f(x)^2~dx$ . So when calculating the surface area , I figure I should be able to reason thus: as before, divide the solid into several cylinders, except now calculate the area of each one instead of its volume. This should yield $A=2\pi\int_a^bf(x)~dx$. However, this is the wrong answer. In order to get the proper formula, I need to replace $dx$ with the arc length , which is $\sqrt{1+f'(x)^2}~dx$ . My question is: why is this the case? There's no need to use arc length when calculating volume, so why does it show up when calculating area?","I have difficulty understanding the difference between calculating the volume of a solid of revolution, and the surface area of a solid of revolution. When calculating the volume , using disc integration, I've been taught to reason in the following way: divide the solid into several cylinders of infinitesimal width $dx$. Then each such cylinder has radius $f(x)$ , so its volume is $\pi\cdot f(x)^2~dx$ . Hence the total volume of the solid of revolution is $V=\pi\int_a^b f(x)^2~dx$ . So when calculating the surface area , I figure I should be able to reason thus: as before, divide the solid into several cylinders, except now calculate the area of each one instead of its volume. This should yield $A=2\pi\int_a^bf(x)~dx$. However, this is the wrong answer. In order to get the proper formula, I need to replace $dx$ with the arc length , which is $\sqrt{1+f'(x)^2}~dx$ . My question is: why is this the case? There's no need to use arc length when calculating volume, so why does it show up when calculating area?",,"['calculus', 'integration', 'definite-integrals']"
10,Sum of squares of binomial coefficients,Sum of squares of binomial coefficients,,"I came across the following sum in reference to this question $$\sum_{n=0}^{\infty} \frac{1}{2^{5 n}} \binom{2 n}{n}^2 = \frac{\sqrt{\pi}}{\Gamma \left( \frac{3}{4}\right)^2}$$ The sum on the left was generated from expanding the square root in the integrand of the following elliptic integral: $$K\left( \frac{1}{2}\right) = \int_0^{\pi/2} \frac{d\theta}{\sqrt{1-\frac12 \sin^2{\theta}}} $$ For the life of me, I cannot figure out how to evaluate this sum directly.  Mathematica has no problem in doing so.  Can someone point the way?","I came across the following sum in reference to this question $$\sum_{n=0}^{\infty} \frac{1}{2^{5 n}} \binom{2 n}{n}^2 = \frac{\sqrt{\pi}}{\Gamma \left( \frac{3}{4}\right)^2}$$ The sum on the left was generated from expanding the square root in the integrand of the following elliptic integral: $$K\left( \frac{1}{2}\right) = \int_0^{\pi/2} \frac{d\theta}{\sqrt{1-\frac12 \sin^2{\theta}}} $$ For the life of me, I cannot figure out how to evaluate this sum directly.  Mathematica has no problem in doing so.  Can someone point the way?",,"['calculus', 'sequences-and-series', 'binomial-coefficients']"
11,"How do you evaluate $\int_{0}^{\frac{\pi}{2}} \frac{(\sec x)^{\frac{1}{3}}}{(\sec x)^{\frac{1}{3}}+(\tan x)^{\frac{1}{3}}} \, dx ?$",How do you evaluate,"\int_{0}^{\frac{\pi}{2}} \frac{(\sec x)^{\frac{1}{3}}}{(\sec x)^{\frac{1}{3}}+(\tan x)^{\frac{1}{3}}} \, dx ?","Problem: $$\int_{0}^{\frac{\pi}{2}} \frac{(\sec x)^{\frac{1}{3}}}{(\sec x)^{\frac{1}{3}}+(\tan x)^{\frac{1}{3}}} dx$$ My attempt: I tried applying the property: $\int_{0}^{a} f(x)dx$ = $\int_{0}^{a} f(a-x)dx$ but got nowhere since the denominator changes. Even on adding the two integrals by taking LCM of the denominators, the final expression got more complicated because the numerator and denominator did not have any common factor. I also tried dividing numerator and denominator by $(secx)^{\frac{1}{3}}$ to get  $$\int_{0}^{\frac{\pi}{2}} \frac{1}{1+(\sin x)^{\frac{1}{3}}} dx$$ and then tried substituting $sinx$ = $t^3$ to get a complicated integral in $t$, which I couldn't evaluate. How do you evaluate this integral? (PS: If possible, please evaluate this without using special functions since this is a practice question for an entrance exam and we've only learnt some basic special functions and the gamma function.)","Problem: $$\int_{0}^{\frac{\pi}{2}} \frac{(\sec x)^{\frac{1}{3}}}{(\sec x)^{\frac{1}{3}}+(\tan x)^{\frac{1}{3}}} dx$$ My attempt: I tried applying the property: $\int_{0}^{a} f(x)dx$ = $\int_{0}^{a} f(a-x)dx$ but got nowhere since the denominator changes. Even on adding the two integrals by taking LCM of the denominators, the final expression got more complicated because the numerator and denominator did not have any common factor. I also tried dividing numerator and denominator by $(secx)^{\frac{1}{3}}$ to get  $$\int_{0}^{\frac{\pi}{2}} \frac{1}{1+(\sin x)^{\frac{1}{3}}} dx$$ and then tried substituting $sinx$ = $t^3$ to get a complicated integral in $t$, which I couldn't evaluate. How do you evaluate this integral? (PS: If possible, please evaluate this without using special functions since this is a practice question for an entrance exam and we've only learnt some basic special functions and the gamma function.)",,"['calculus', 'integration', 'definite-integrals', 'contest-math']"
12,"Prove $_2F_1\!\left(\frac76,\frac12;\,\frac13;\,-\phi^2\right)=0$",Prove,"_2F_1\!\left(\frac76,\frac12;\,\frac13;\,-\phi^2\right)=0","Please help me to prove the identity $$_2F_1\!\left(\frac76,\frac12;\,\frac13;\,-\phi^2\right)=0,$$ where $\phi=\frac{1+\sqrt5}2$ is the golden ratio.","Please help me to prove the identity $$_2F_1\!\left(\frac76,\frac12;\,\frac13;\,-\phi^2\right)=0,$$ where $\phi=\frac{1+\sqrt5}2$ is the golden ratio.",,"['calculus', 'special-functions', 'hypergeometric-function', 'golden-ratio']"
13,Does that series converge or diverge?,Does that series converge or diverge?,,"Does the series $$\sum \limits _{n=3}^\infty \frac{(-1)^{[\log n]}}{\sqrt{n}}$$ converge or diverge? As usually, $[x]$ denotes the integer part of $x.$","Does the series $$\sum \limits _{n=3}^\infty \frac{(-1)^{[\log n]}}{\sqrt{n}}$$ converge or diverge? As usually, $[x]$ denotes the integer part of $x.$",,['calculus']
14,Is there an algorithm to determine whether a series converges?,Is there an algorithm to determine whether a series converges?,,"I thought of this question in connection with Calculus II (a course in the US which includes, among other things, techniques of integration and convergence tests for series, both of which are taught as a bunch of techniques that might work for a particular problem) but feel free to make the answers as complicated as necessary. The question of whether an elementary antiderivative of an elementary function $f(x)$ exists is answered by the Risch algorithm and I want to ask a similar question about convergence of series. Let $f(x)$ be an elementary function and $a_n=f(n)$ for $n=0,1,2,\ldots$. Is there an algorithm that will tell us if $\sum_{n=0}^\infty a_n$ converges? Are there examples that are undecidable? The integral test might help convert a solution in one problem to the other but I don't see that it solves the problem entirely.","I thought of this question in connection with Calculus II (a course in the US which includes, among other things, techniques of integration and convergence tests for series, both of which are taught as a bunch of techniques that might work for a particular problem) but feel free to make the answers as complicated as necessary. The question of whether an elementary antiderivative of an elementary function $f(x)$ exists is answered by the Risch algorithm and I want to ask a similar question about convergence of series. Let $f(x)$ be an elementary function and $a_n=f(n)$ for $n=0,1,2,\ldots$. Is there an algorithm that will tell us if $\sum_{n=0}^\infty a_n$ converges? Are there examples that are undecidable? The integral test might help convert a solution in one problem to the other but I don't see that it solves the problem entirely.",,"['calculus', 'sequences-and-series']"
15,Clever derivation of $\arcsin(x)$ Taylor series,Clever derivation of  Taylor series,\arcsin(x),"I was working the other day in the Math Help Centre, trying to help some first years with a calculus problem.  The problem involved investigating the Taylor series of $\arcsin(x)$.  Once the students had derived $$\arcsin(x)=\sum_{n=0}^\infty \frac{(2n)!}{4^n(n!)^2(2n+1)}x^{2n+1}$$ they were asked to rederive it in a different way: Determine the sequence $\{c_n\}_{n\in\mathbb{N}}$ such that $$x=\sum_{n=0}^\infty c_n \left(x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots\right)^n.$$ Here's what I got: I recognized that the object in parentheses is the Taylor series of $\sin(x)$, so the idea is to let $\arcsin(x)=\sum_{n=0}^\infty c_nx^n$ and note that $\arcsin(\sin(x))=x$.  After that it's just an issue of computing the $c_n$'s. There's an obvious brute-force way to do it, where for each $n$ you say ""indices larger than $n$ don't matter, so now it's a finite problem.""  Expand the relevant terms to get relations involving the $c_i$'s that you've already worked out.  The problem is that this will only work for finitely many values, and it was hard to determine a pattern. Is there and obvious pattern I'm missing?  It occurred to me that the ""relevant terms"" that contribute to $c_n$ depend on the divisors on $n$, is this intuition correct? Most importantly, what is the best way to solve the problem of computing $c_n$?","I was working the other day in the Math Help Centre, trying to help some first years with a calculus problem.  The problem involved investigating the Taylor series of $\arcsin(x)$.  Once the students had derived $$\arcsin(x)=\sum_{n=0}^\infty \frac{(2n)!}{4^n(n!)^2(2n+1)}x^{2n+1}$$ they were asked to rederive it in a different way: Determine the sequence $\{c_n\}_{n\in\mathbb{N}}$ such that $$x=\sum_{n=0}^\infty c_n \left(x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\cdots\right)^n.$$ Here's what I got: I recognized that the object in parentheses is the Taylor series of $\sin(x)$, so the idea is to let $\arcsin(x)=\sum_{n=0}^\infty c_nx^n$ and note that $\arcsin(\sin(x))=x$.  After that it's just an issue of computing the $c_n$'s. There's an obvious brute-force way to do it, where for each $n$ you say ""indices larger than $n$ don't matter, so now it's a finite problem.""  Expand the relevant terms to get relations involving the $c_i$'s that you've already worked out.  The problem is that this will only work for finitely many values, and it was hard to determine a pattern. Is there and obvious pattern I'm missing?  It occurred to me that the ""relevant terms"" that contribute to $c_n$ depend on the divisors on $n$, is this intuition correct? Most importantly, what is the best way to solve the problem of computing $c_n$?",,"['calculus', 'taylor-expansion']"
16,Derivatives of functions involving absolute value,Derivatives of functions involving absolute value,,"I noticed that if the absolute value definition $\lvert{x}\rvert=\sqrt{x^2}$ is used, we can get derivatives of functions with absolute value, without having to redefine them as piece-wise. For example, to get the derivative of $f(x)=x\lvert{x}\rvert$ we write $f(x)=x(x^2)^\frac{1}{2}$ and thus $$ \begin{align} f'(x) &= \sqrt{x^2}+x\frac{1}{2}(x^2)^{-\frac{1}{2}}(2x) \\ &=\sqrt{x^2}+\frac{x^2}{\sqrt{x^2}} \\ &=\frac{2x^2}{\sqrt{x^2}} \\ &=\frac{2x^2}{\lvert{x}\rvert} \\ &=2\lvert{x}\rvert \\ \end{align} $$ which is correct. You just have to avoid using the law of exponents to simplify $\lvert{x}\rvert = (x^2)^\frac{1}{2}=x^{2(\frac{1}{2})}=x$. My question is, why does using $\lvert{x}\rvert=\sqrt{x^2}$ to get derivatives work, and why does the law of exponents seem to show that $\lvert{x}\rvert=x$ ?","I noticed that if the absolute value definition $\lvert{x}\rvert=\sqrt{x^2}$ is used, we can get derivatives of functions with absolute value, without having to redefine them as piece-wise. For example, to get the derivative of $f(x)=x\lvert{x}\rvert$ we write $f(x)=x(x^2)^\frac{1}{2}$ and thus $$ \begin{align} f'(x) &= \sqrt{x^2}+x\frac{1}{2}(x^2)^{-\frac{1}{2}}(2x) \\ &=\sqrt{x^2}+\frac{x^2}{\sqrt{x^2}} \\ &=\frac{2x^2}{\sqrt{x^2}} \\ &=\frac{2x^2}{\lvert{x}\rvert} \\ &=2\lvert{x}\rvert \\ \end{align} $$ which is correct. You just have to avoid using the law of exponents to simplify $\lvert{x}\rvert = (x^2)^\frac{1}{2}=x^{2(\frac{1}{2})}=x$. My question is, why does using $\lvert{x}\rvert=\sqrt{x^2}$ to get derivatives work, and why does the law of exponents seem to show that $\lvert{x}\rvert=x$ ?",,"['calculus', 'derivatives', 'absolute-value']"
17,"I'm trying to find where a ""3D logarithmic spiral"" converges.","I'm trying to find where a ""3D logarithmic spiral"" converges.",,"Background and problem It's in quotes because I don't know what I'm talking about. I'm more of an artist who likes to dabble in math so bare with me. I know the title is a little confusing so I have made a pretty animation to illustrate what I mean. I assume this is some type of discrete logarithmic spiral. It always starts the origin with no translations, rotations or scale applied. You'll notice in the video, the 2nd cube has 3 axes coming out of it. It's transform is driving the rest of the cubes as seen in this clip . I can translate, rotate, and scale and as long as the translation and rotation are not 0, and the scale is between 0 and 1 it'll make a spiral. Anything else won't produce a spiral as far as I'm aware. I've searched Google for about 5 hours today and haven't found anything so I either don't know the proper terms, it's never been done before which I doubt, or it's impossible which I don't know but highly doubt. I'm trying to find the $x, y,$ and $z$ for where this would converge in non-polar/spherical form so I can plug them into my software. Why I'm here Some hindrances I'm having are that I've never taken anything on spherical coordinates which I assume would be useful (or even polar coordinates), I don't have a background in linear algebra at all, and I've been out of school about 8 years at this point so I'm very rusty. I've asked this question on Reddit and was given an answer but I don't understand it. They suggested, If your initial vector is v and your linear transformation is T, then the point it converges to is $(1+T+T^2 +T^3...)v=\dfrac v{1-T}.$ For the purpose of computation, you need to write T as a matrix, v as a column vector. Can come one break that down a bit more? Is $v$ my 2nd cube with the axes poking out? I don't understand what $T$ means at all. Is it even right? I'm ok with not being spoon-fed the answer but I need a little bit more than this. If the first answer is any indication, then is way above my ability. I'm not even sure which branch of math I need. I know it's some sort of geometric series because it's decreasing and I can see it converging to some 3d point in space. That reminds me of calculus. I've taken Calc 2 at University but that was a long time ago and we never talked about 3d space. Any help would be useful. Motivation And in case you're wondering why I'm interested in this. I've been interested in these scaling looping animations lately and I wanted to understand the math behind them. I found some videos by the people who make them (one of the guys mentioned in this video did an animation for Justin Bieber so they're legit) and even they don't understand the math. They're using their artistic skills to get close but that can be time-consuming. I want to know the math behind it. And I refuse to believe the math hasn't been worked out already. The point where I'm trying to find is where if you scale the whole spiral from, it has this unique property of looping perfectly. And if it's scaled at an exponential rate $\bigg(\dfrac{1}{s}\bigg)^{\frac{n(f - 1)}{a}}$ where $s$ is the scaling factor, $n$ is the number of cycles you want, $f$ is the current frame and $a$ is the length of the animation in frames, then it ends up looking like it's scaling linear. In this example , on the left you get the illusion of it scaling forever but on the right you can see what's really happening. If it doesn't scale at an exponential rate, then it starts slow and gets faster which also breaks the illusion. It's a 1m square that gets shrunk in half each time $(1 + 1/2 + 1/4 + ...)$ so I know the limit is $2$ . I'm then scaling the whole spiral from $(2, 0, 0)$ by a factor of $2$ over $50$ frames. It only scales perfectly from $(2, 0, 0)$ . This is what happens if I don't use the right point . It slowly drifts away and snaps back each cycle breaking the illusion. So that's why it's important for me for find this location. Updates A user on Reddit found a solution that works in 2D and I can confirm that it works. Their solution is as follows: Let $x'$ and $y'$ be the point where it converges. Then it converges at: $x' = Ax - By$ $y' = Bx + Ay$ where $A$ is the function $\frac{1 - k cos θ}{1 + k^2 - 2k cos θ}$ $B$ is $\frac{k sin θ}{1 + k^2 - 2k cos θ}$ and where $k$ is the scaling factor and $θ$ is the angle. Update 2 I think I'm getting closer. I've been told that: In two dimensions, the transformation T is given by $T = k R(θ) = k [ cos θ , -sin θ ; sin θ , cos θ ]$ , and therefore $T^n = k^n [ cos(nθ) , -sin(nθ) ; sin(nθ) , cos(nθ) ]$ . However, this cannot be easily generalized to three dimensions. You would need to explain more precisely what you mean by a rotation in three dimensions. Do you want a single rotation with respect to a given axis? If you want to apply three rotations with respect to the three coordinate axes, in what order do you apply them? How would I know what order to apply them since I can edit any one of them at any time?","Background and problem It's in quotes because I don't know what I'm talking about. I'm more of an artist who likes to dabble in math so bare with me. I know the title is a little confusing so I have made a pretty animation to illustrate what I mean. I assume this is some type of discrete logarithmic spiral. It always starts the origin with no translations, rotations or scale applied. You'll notice in the video, the 2nd cube has 3 axes coming out of it. It's transform is driving the rest of the cubes as seen in this clip . I can translate, rotate, and scale and as long as the translation and rotation are not 0, and the scale is between 0 and 1 it'll make a spiral. Anything else won't produce a spiral as far as I'm aware. I've searched Google for about 5 hours today and haven't found anything so I either don't know the proper terms, it's never been done before which I doubt, or it's impossible which I don't know but highly doubt. I'm trying to find the and for where this would converge in non-polar/spherical form so I can plug them into my software. Why I'm here Some hindrances I'm having are that I've never taken anything on spherical coordinates which I assume would be useful (or even polar coordinates), I don't have a background in linear algebra at all, and I've been out of school about 8 years at this point so I'm very rusty. I've asked this question on Reddit and was given an answer but I don't understand it. They suggested, If your initial vector is v and your linear transformation is T, then the point it converges to is For the purpose of computation, you need to write T as a matrix, v as a column vector. Can come one break that down a bit more? Is my 2nd cube with the axes poking out? I don't understand what means at all. Is it even right? I'm ok with not being spoon-fed the answer but I need a little bit more than this. If the first answer is any indication, then is way above my ability. I'm not even sure which branch of math I need. I know it's some sort of geometric series because it's decreasing and I can see it converging to some 3d point in space. That reminds me of calculus. I've taken Calc 2 at University but that was a long time ago and we never talked about 3d space. Any help would be useful. Motivation And in case you're wondering why I'm interested in this. I've been interested in these scaling looping animations lately and I wanted to understand the math behind them. I found some videos by the people who make them (one of the guys mentioned in this video did an animation for Justin Bieber so they're legit) and even they don't understand the math. They're using their artistic skills to get close but that can be time-consuming. I want to know the math behind it. And I refuse to believe the math hasn't been worked out already. The point where I'm trying to find is where if you scale the whole spiral from, it has this unique property of looping perfectly. And if it's scaled at an exponential rate where is the scaling factor, is the number of cycles you want, is the current frame and is the length of the animation in frames, then it ends up looking like it's scaling linear. In this example , on the left you get the illusion of it scaling forever but on the right you can see what's really happening. If it doesn't scale at an exponential rate, then it starts slow and gets faster which also breaks the illusion. It's a 1m square that gets shrunk in half each time so I know the limit is . I'm then scaling the whole spiral from by a factor of over frames. It only scales perfectly from . This is what happens if I don't use the right point . It slowly drifts away and snaps back each cycle breaking the illusion. So that's why it's important for me for find this location. Updates A user on Reddit found a solution that works in 2D and I can confirm that it works. Their solution is as follows: Let and be the point where it converges. Then it converges at: where is the function is and where is the scaling factor and is the angle. Update 2 I think I'm getting closer. I've been told that: In two dimensions, the transformation T is given by , and therefore . However, this cannot be easily generalized to three dimensions. You would need to explain more precisely what you mean by a rotation in three dimensions. Do you want a single rotation with respect to a given axis? If you want to apply three rotations with respect to the three coordinate axes, in what order do you apply them? How would I know what order to apply them since I can edit any one of them at any time?","x, y, z (1+T+T^2 +T^3...)v=\dfrac v{1-T}. v T \bigg(\dfrac{1}{s}\bigg)^{\frac{n(f - 1)}{a}} s n f a (1 + 1/2 + 1/4 + ...) 2 (2, 0, 0) 2 50 (2, 0, 0) x' y' x' = Ax - By y' = Bx + Ay A \frac{1 - k cos θ}{1 + k^2 - 2k cos θ} B \frac{k sin θ}{1 + k^2 - 2k cos θ} k θ T = k R(θ) = k [ cos θ , -sin θ ; sin θ , cos θ ] T^n = k^n [ cos(nθ) , -sin(nθ) ; sin(nθ) , cos(nθ) ]","['calculus', 'matrices', 'linear-transformations', 'rotations']"
18,Arc Length Integral of $x^x$ from 0 to 1 in closed form.,Arc Length Integral of  from 0 to 1 in closed form.,x^x,"I was recently trying to compute the arc length of $x^x$ from $0$ to $1$ as follows: $$L=\int_0^1 \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x=$$ $$\int_0^1\sqrt{1+x^{2x}(\ln x+1)^2} \text{d}x=$$ Using the infinite series expansion for the binomial theorem with |x|<1, we can rewrite the square root portion as $\sqrt x=x^{1/2}$ . We can assume a limit for x=1 in the integral bounds: $$\int_0^1 \sum_{n=0}^∞ \binom{\frac 12}{n} (x^{2x}(\ln x+1)^2)^n \text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 e^{2nx\ln(x)}(\ln x+1)^{2n}\text{d}x=$$ It would be maybe easier to expand out the exponential as a series with a different index to have another series with an independent index so that no cauchy products are needed: $$\sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 \sum_{m=0}^∞\frac{2^mn^mx^m\ln^m(x)}{m!}(\ln x+1)^{2n} \text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)(\ln x+1)^{2n}\text{d}x=$$ Then the exponentiated logarithmic part of this expression, if we only focus on it, can be expanded into another similar summation using a binomials expansion because the index of n is an integer by definition: $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)\sum_{l=0}^{2n}\binom{2n}{l}\ln^l(x)\text{d}x=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} \int_0^1 x^m\ln^{l+m}(x)\text{d}x$$ This integral can be found in terms of the factorial and a “factorial coefficient” part. Using the substitution of u=-ln(x) gets us: $$\int_0^1 x^m\ln^{l+m}(x)\text{d}x=$$ $$(-1)^{l+m}\int_0^ ∞e^{-u(m+1)}u^{l+m}\text{d}u=$$ $$-(-1)^{l+m+1}m^{l+m+1}Γ(l+m+1,-(m+1)\ln(x))|_0^1=$$ $$(-1)^{l+m}m^{l+m+1}(l+m)!$$ The incomplete gamma function is here. This means our final possible answer is: $$L=^? \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^{l+m+1}(l+m)!=$$ $$\sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mm^{m+1}n^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^l(l+m)!=^?1.2474...$$ This series diverges maybe because of a bad usage of the summations with the interval of convergence being too small. My main question is if all of these steps are correct as in my previous deleted question. Sorry for the undetailed question. Also, please correct and simplify the problem as much as possible using any widely used function. I.e. do not just do arclength(f(x),a,b). I tried a similar method which also diverges even though the surface area should not of the same figure but with $(y-x^x)(y-x^{-x})=0$ , $0\le x\le 1$ which got me to a similar answer. This one had $$S_y=\int_0^1 x^x \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x$$ . This one experimentally had 5 summations with different indices by accident when I was trying to calculate the arc length. The area of this figure is simply the difference two sophomore dream integrals. This is $$A=\sum_{N=1}^ ∞\frac{1+(-1)^N}{N^N}=.507...$$ as n as an index was already defined. I was also trying to find the perimeter of the lamina and volume of this solid of revolution about both the x and y axes all or which are quite ambitious to figure out and very tricky as I most likely got this wrong except for the area of this figure. Please just figure out the arc length and all will be well: Here is the desmos demo of this arc length series: https://www.desmos.com/calculator/gt0hsg40ah If this is true, please expand the binomial coefficients and simplify the rest. Maybe keep the original form. Thanks, and please give me feedback!","I was recently trying to compute the arc length of from to as follows: Using the infinite series expansion for the binomial theorem with |x|<1, we can rewrite the square root portion as . We can assume a limit for x=1 in the integral bounds: It would be maybe easier to expand out the exponential as a series with a different index to have another series with an independent index so that no cauchy products are needed: Then the exponentiated logarithmic part of this expression, if we only focus on it, can be expanded into another similar summation using a binomials expansion because the index of n is an integer by definition: This integral can be found in terms of the factorial and a “factorial coefficient” part. Using the substitution of u=-ln(x) gets us: The incomplete gamma function is here. This means our final possible answer is: This series diverges maybe because of a bad usage of the summations with the interval of convergence being too small. My main question is if all of these steps are correct as in my previous deleted question. Sorry for the undetailed question. Also, please correct and simplify the problem as much as possible using any widely used function. I.e. do not just do arclength(f(x),a,b). I tried a similar method which also diverges even though the surface area should not of the same figure but with , which got me to a similar answer. This one had . This one experimentally had 5 summations with different indices by accident when I was trying to calculate the arc length. The area of this figure is simply the difference two sophomore dream integrals. This is as n as an index was already defined. I was also trying to find the perimeter of the lamina and volume of this solid of revolution about both the x and y axes all or which are quite ambitious to figure out and very tricky as I most likely got this wrong except for the area of this figure. Please just figure out the arc length and all will be well: Here is the desmos demo of this arc length series: https://www.desmos.com/calculator/gt0hsg40ah If this is true, please expand the binomial coefficients and simplify the rest. Maybe keep the original form. Thanks, and please give me feedback!","x^x 0 1 L=\int_0^1 \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x= \int_0^1\sqrt{1+x^{2x}(\ln x+1)^2} \text{d}x= \sqrt x=x^{1/2} \int_0^1 \sum_{n=0}^∞ \binom{\frac 12}{n} (x^{2x}(\ln x+1)^2)^n \text{d}x= \sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 e^{2nx\ln(x)}(\ln x+1)^{2n}\text{d}x= \sum_{n=0}^∞ \binom{\frac 12}{n} \int_0^1 \sum_{m=0}^∞\frac{2^mn^mx^m\ln^m(x)}{m!}(\ln x+1)^{2n} \text{d}x= \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)(\ln x+1)^{2n}\text{d}x= \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \int_0^1 x^m\ln^m(x)\sum_{l=0}^{2n}\binom{2n}{l}\ln^l(x)\text{d}x= \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} \int_0^1 x^m\ln^{l+m}(x)\text{d}x \int_0^1 x^m\ln^{l+m}(x)\text{d}x= (-1)^{l+m}\int_0^ ∞e^{-u(m+1)}u^{l+m}\text{d}u= -(-1)^{l+m+1}m^{l+m+1}Γ(l+m+1,-(m+1)\ln(x))|_0^1= (-1)^{l+m}m^{l+m+1}(l+m)! L=^? \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mn^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^{l+m+1}(l+m)!= \sum_{n=0}^∞ \binom{\frac 12}{n} \sum_{m=0}^∞\frac{2^mm^{m+1}n^m}{m!} \sum_{l=0}^{2n}\binom{2n}{l} (-1)^{l+m}m^l(l+m)!=^?1.2474... (y-x^x)(y-x^{-x})=0 0\le x\le 1 S_y=\int_0^1 x^x \sqrt{1+\left(\frac{\text{d}}{\text{d}x}x^x\right)^2} \text{d}x A=\sum_{N=1}^ ∞\frac{1+(-1)^N}{N^N}=.507...","['calculus', 'summation', 'exponentiation', 'binomial-theorem', 'arc-length']"
19,Find $\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx$,Find,\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx,"Find: $$\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx$$ This is one of the problems i have to solve so that i could join college. I tried using integration by parts, i tried using notations but nothing works. If someone could please help me i would deeply appreciate it. ! thanks in advance ! I know the answer to the limit is 1. But i need help proving it.","Find: This is one of the problems i have to solve so that i could join college. I tried using integration by parts, i tried using notations but nothing works. If someone could please help me i would deeply appreciate it. ! thanks in advance ! I know the answer to the limit is 1. But i need help proving it.",\lim_{n \to \infty} n \int_0^1 (\cos x - \sin x)^n dx,"['calculus', 'integration']"
20,Asymptotic expression of $\int_{- D}^{D} \frac{\text{tanh}(\xi)}{\xi -\omega}\mathrm{d}\xi$,Asymptotic expression of,\int_{- D}^{D} \frac{\text{tanh}(\xi)}{\xi -\omega}\mathrm{d}\xi,"How to derive the following asymptotic expression ($|\omega| \ll D $)? $$P.V.\int_{- D}^{D} d\xi \frac{\tanh(\beta \xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right),\ \ \  \beta =1/T,\ \  \omega, T \rightarrow 0.$$ Two limiting cases: 1) $\omega=0, \lim_{T\rightarrow 0}\int_{- D}^{D} d\xi \frac{\text{tanh}(\beta \xi)}{\xi} \approx 2  \ln\left(\frac{D}{T}\right) + C \approx 2  \ln\left(\frac{D}{T}\right)$; 2) $T=0, \lim_{\omega \rightarrow 0} \int_{- D}^{D} d\xi \frac{\theta(\xi)-\theta( -\xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\omega}\right).$ Some write $2  \ln\left(\frac{D}{\text{max}(\omega, T)}\right)$ instead of $ 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right).$ Can anyone elaborate Jack's answer? Thank you. Reference. Actually, this is an important expression from physics, which is directly related to the Kondo problem , the divergence at the third order of perturbation theory.","How to derive the following asymptotic expression ($|\omega| \ll D $)? $$P.V.\int_{- D}^{D} d\xi \frac{\tanh(\beta \xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right),\ \ \  \beta =1/T,\ \  \omega, T \rightarrow 0.$$ Two limiting cases: 1) $\omega=0, \lim_{T\rightarrow 0}\int_{- D}^{D} d\xi \frac{\text{tanh}(\beta \xi)}{\xi} \approx 2  \ln\left(\frac{D}{T}\right) + C \approx 2  \ln\left(\frac{D}{T}\right)$; 2) $T=0, \lim_{\omega \rightarrow 0} \int_{- D}^{D} d\xi \frac{\theta(\xi)-\theta( -\xi)}{\xi -\omega} \approx 2  \ln\left(\frac{D}{\omega}\right).$ Some write $2  \ln\left(\frac{D}{\text{max}(\omega, T)}\right)$ instead of $ 2  \ln\left(\frac{D}{\sqrt{\omega^2+T^2}}\right).$ Can anyone elaborate Jack's answer? Thank you. Reference. Actually, this is an important expression from physics, which is directly related to the Kondo problem , the divergence at the third order of perturbation theory.",,"['calculus', 'integration', 'asymptotics', 'cauchy-principal-value']"
21,Sum of $k$-th powers,Sum of -th powers,k,"Given: $$ P_k(n)=\sum_{i=1}^n i^k $$ and $P_k(0)=0$, $P_k(x)-P_k(x-1) = x^k$ show that: $$ P_{k+1}(x)=(k+1) \int^x_0P_k(t) \, dt + C_{k+1} \cdot x $$ For $C_{k+1}$ constant. I believe a proof by induction is the way to go here, and have shown the case for $k=0$. This is where I'm stuck. I have looked at the right hand side for the k+1 case: $$ (k+2)\int^x_0P_{k+1}(t) \, dt + C_{k+2} \cdot x $$ and I don't see how this reduces to $P_{k+2}(x)$. Even if we are assuming the kth case, replacing $P_{k+1}$ in the integrand of the $(k+1)$-st case just makes it more messy. I am not looking for the answer just a push in the right direction. I can see that each sum ends up as a polynomial since expressions like $P_1(x) = 1+2+\cdots+x=\frac{x(x+1)}{2}$, but I don't know how to do that for arbitrary powers, and I believe I don't need to in order to solve this problem.","Given: $$ P_k(n)=\sum_{i=1}^n i^k $$ and $P_k(0)=0$, $P_k(x)-P_k(x-1) = x^k$ show that: $$ P_{k+1}(x)=(k+1) \int^x_0P_k(t) \, dt + C_{k+1} \cdot x $$ For $C_{k+1}$ constant. I believe a proof by induction is the way to go here, and have shown the case for $k=0$. This is where I'm stuck. I have looked at the right hand side for the k+1 case: $$ (k+2)\int^x_0P_{k+1}(t) \, dt + C_{k+2} \cdot x $$ and I don't see how this reduces to $P_{k+2}(x)$. Even if we are assuming the kth case, replacing $P_{k+1}$ in the integrand of the $(k+1)$-st case just makes it more messy. I am not looking for the answer just a push in the right direction. I can see that each sum ends up as a polynomial since expressions like $P_1(x) = 1+2+\cdots+x=\frac{x(x+1)}{2}$, but I don't know how to do that for arbitrary powers, and I believe I don't need to in order to solve this problem.",,"['calculus', 'polynomials']"
22,"Unified notion of what ""$dx$"" means","Unified notion of what """" means",dx,"The symbol $dx$ in calculus is at first introduced just as a form of notation: in differentiation, $$\frac{dy}{dx}$$ means the derivative of the function $y$ with respect to $x$. Letting $f(x) = y$, other notations are $f'(x)$, $\dot{y}$ (Newton's ""fluxion"" notation, used in physics), and $D_x[f]$ (""differential operator"" notation). It also appears in integration: $$\int f(x)\ dx$$ means the anti-derivative of $f$ with respect to the variable $x$, and if the integral is a definite integral, again, it just denotes the variable with which we are integrating ""with respect to"". So it seems that $dx$ is just notation, nothing more, nothing less. Yet then you may come across something weird like this: $$\frac{dy}{dx} = x$$ $$dy = x\ dx$$ $$\int dy = \int x\ dx$$ $$y = \frac{x^2}{2} + C$$ Yet the above bunch of manipulations is, from the ""notation"" point of view, nonsense: ""$dy$"" and ""$dx$"" are not quantities, just pieces of notation. Saying $dy = \mathrm{something}$ is as ridiculous as saying $\sqrt{} = \mathrm{something}$. Yet it works. Now, when we include more advanced math as well as the basic math, it seems we can compile the following list of answers as to ""what $dx$ really is"" -- and they're not one thing!: It's just notation . That's what we just did. But then the above manipulation is nonsense. Someone said on this site that this was only a ""particularly unenlightening"" way to look at it. It's a limit . $dx$ is what happens to $\Delta x$ as it arbitrarily small. Yet this is not rigorous enough -- to make the above manipulation work, it seems we have to pass out of the limit back to $\Delta y$ and $\Delta x$ since the limit of each is $0$. It's a differential form . This gives the first ""rigorous"" definition. But here, we pull in manifold theory and non -Euclidean spaces to do our work, which while it is at home in advanced math, is definitely not something you'd want to put in Calculus class, where we are dealing with the conceptually much simpler Euclidean spaces, and if you want to make rigorous $dx$-manipulations in Euclidean space, seems like serious overkill. This also runs into problems with integration -- what happens if we are integrating dis continuous functions? This brings us to... It's a measure . This definition seems limited only to integration. In this case, $dx$ in the integral stands for a measure -- a function which assigns a ""size"" (""length"", ""area"", ""volume"", etc.) to subsets of the real line or Euclidean space, in particular the Lebesgue measure, which generalizes our usual, intuitive notion of ""length"", ""area"", etc. . Again, this is heavy as we have to delve into the deep structure of the real line but of course it's an advanced concept as well. Nevertheless, it doesn't require non-Euclidean spaces, and can be applied to discontinuous functions, but of course only works with integration (note you can't differentiate a discontinuous function). It's an infinitely small number . This was how it was, in fact, originally conceived by the fathers of calculus. This approach was formalized rigorously by Abraham Robinson's non-standard analysis . This approach seems to be the heaviest of them all, as it requires probing down into mathematical logic to really understand the formalism -- in particular ""model theory"" and ""ultrapowers"" to extend the real line with infinitesimal numbers in such a way as to permit analysis to be done. Now, it seems that 3) and 4) can be thought of as ""differential"" and ""integral"" notions of what ""$dx$"" means. 1) and 2) are not so helpful. My question is: is there a single, unifying notion which ties all these together -- a ""one true meaning of $dx$""? Or is ""$dx$"" a bunch of very, very different concepts, and thus it is silly to point to one or the other and call it the ""real"" meaning?","The symbol $dx$ in calculus is at first introduced just as a form of notation: in differentiation, $$\frac{dy}{dx}$$ means the derivative of the function $y$ with respect to $x$. Letting $f(x) = y$, other notations are $f'(x)$, $\dot{y}$ (Newton's ""fluxion"" notation, used in physics), and $D_x[f]$ (""differential operator"" notation). It also appears in integration: $$\int f(x)\ dx$$ means the anti-derivative of $f$ with respect to the variable $x$, and if the integral is a definite integral, again, it just denotes the variable with which we are integrating ""with respect to"". So it seems that $dx$ is just notation, nothing more, nothing less. Yet then you may come across something weird like this: $$\frac{dy}{dx} = x$$ $$dy = x\ dx$$ $$\int dy = \int x\ dx$$ $$y = \frac{x^2}{2} + C$$ Yet the above bunch of manipulations is, from the ""notation"" point of view, nonsense: ""$dy$"" and ""$dx$"" are not quantities, just pieces of notation. Saying $dy = \mathrm{something}$ is as ridiculous as saying $\sqrt{} = \mathrm{something}$. Yet it works. Now, when we include more advanced math as well as the basic math, it seems we can compile the following list of answers as to ""what $dx$ really is"" -- and they're not one thing!: It's just notation . That's what we just did. But then the above manipulation is nonsense. Someone said on this site that this was only a ""particularly unenlightening"" way to look at it. It's a limit . $dx$ is what happens to $\Delta x$ as it arbitrarily small. Yet this is not rigorous enough -- to make the above manipulation work, it seems we have to pass out of the limit back to $\Delta y$ and $\Delta x$ since the limit of each is $0$. It's a differential form . This gives the first ""rigorous"" definition. But here, we pull in manifold theory and non -Euclidean spaces to do our work, which while it is at home in advanced math, is definitely not something you'd want to put in Calculus class, where we are dealing with the conceptually much simpler Euclidean spaces, and if you want to make rigorous $dx$-manipulations in Euclidean space, seems like serious overkill. This also runs into problems with integration -- what happens if we are integrating dis continuous functions? This brings us to... It's a measure . This definition seems limited only to integration. In this case, $dx$ in the integral stands for a measure -- a function which assigns a ""size"" (""length"", ""area"", ""volume"", etc.) to subsets of the real line or Euclidean space, in particular the Lebesgue measure, which generalizes our usual, intuitive notion of ""length"", ""area"", etc. . Again, this is heavy as we have to delve into the deep structure of the real line but of course it's an advanced concept as well. Nevertheless, it doesn't require non-Euclidean spaces, and can be applied to discontinuous functions, but of course only works with integration (note you can't differentiate a discontinuous function). It's an infinitely small number . This was how it was, in fact, originally conceived by the fathers of calculus. This approach was formalized rigorously by Abraham Robinson's non-standard analysis . This approach seems to be the heaviest of them all, as it requires probing down into mathematical logic to really understand the formalism -- in particular ""model theory"" and ""ultrapowers"" to extend the real line with infinitesimal numbers in such a way as to permit analysis to be done. Now, it seems that 3) and 4) can be thought of as ""differential"" and ""integral"" notions of what ""$dx$"" means. 1) and 2) are not so helpful. My question is: is there a single, unifying notion which ties all these together -- a ""one true meaning of $dx$""? Or is ""$dx$"" a bunch of very, very different concepts, and thus it is silly to point to one or the other and call it the ""real"" meaning?",,['calculus']
23,Mean value theorem functional equation: $ f ' \left ( \frac { x + y } 2 \right ) = \frac { f ( x ) - f ( y ) } { x - y } $,Mean value theorem functional equation:, f ' \left ( \frac { x + y } 2 \right ) = \frac { f ( x ) - f ( y ) } { x - y } ,"I need help solving the following functional equation. I found this question in the book "" Elementary Real Analysis "", right after the section on the mean value theorem. Find all differentiable $ f : \mathbb R \to \mathbb R $ such that $$ f ' \left ( \frac { x + y } 2 \right ) = \frac { f ( x ) - f ( y ) } { x - y } $$ holds for all $ x \ne y $ . I can clearly see that any function of the form $ f ( x ) = \alpha x $ solves this, but I don't know how to find any other solutions or show that this is the only one.","I need help solving the following functional equation. I found this question in the book "" Elementary Real Analysis "", right after the section on the mean value theorem. Find all differentiable such that holds for all . I can clearly see that any function of the form solves this, but I don't know how to find any other solutions or show that this is the only one.", f : \mathbb R \to \mathbb R   f ' \left ( \frac { x + y } 2 \right ) = \frac { f ( x ) - f ( y ) } { x - y }   x \ne y   f ( x ) = \alpha x ,"['calculus', 'functional-equations']"
24,For what values of $a$ does $\sum_{n=1}^\infty \left( 1+\frac12 + \dotsb + \frac1n \right) \frac{\sin (na)}{n}$ converge?,For what values of  does  converge?,a \sum_{n=1}^\infty \left( 1+\frac12 + \dotsb + \frac1n \right) \frac{\sin (na)}{n},"For what values of $a$ does $$\sum_{n=1}^\infty \left( 1+\frac12 +  \dotsb + \frac1n \right) \frac{\sin (na)}{n}$$ converge? To my thinking, $$f(n)=\frac{\left( 1+\frac12 +  \dotsb + \frac1n \right)}{n}$$ will behave like $\frac{\log n}{n}$, which is not convergent, but certainly has terms going to zero (eventually monotonically). By Dirichlet's test, $$\sum_{n=1}^\infty f(n) \sin(an)$$ will converge provided that the partial sums of $\sum_{n=1}^\infty \sin(na)$ are bounded, which they always are. So it should converge for all $a\in \mathbb{R}$. Would appreciate anyone pointing out mistakes in this reasoning. Thanks","For what values of $a$ does $$\sum_{n=1}^\infty \left( 1+\frac12 +  \dotsb + \frac1n \right) \frac{\sin (na)}{n}$$ converge? To my thinking, $$f(n)=\frac{\left( 1+\frac12 +  \dotsb + \frac1n \right)}{n}$$ will behave like $\frac{\log n}{n}$, which is not convergent, but certainly has terms going to zero (eventually monotonically). By Dirichlet's test, $$\sum_{n=1}^\infty f(n) \sin(an)$$ will converge provided that the partial sums of $\sum_{n=1}^\infty \sin(na)$ are bounded, which they always are. So it should converge for all $a\in \mathbb{R}$. Would appreciate anyone pointing out mistakes in this reasoning. Thanks",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'solution-verification']"
25,Integrate $\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}$,Integrate,\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx},"Evaluate integral $$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}$$ Well,I think we have $$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}=\frac{\pi}{e}$$ and $$\int_{0}^{1}{x^{x}(1-x)^{1-x}\sin{\pi x}dx}=\frac{e\pi}{24}$$ With such nice result of these integral,why isn't worth to evaluate it? I found a solution about the second one,but I wonder it will work for the first one Note $$ S=\int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}-\int_{0}^{1}{(1-x)e^{(i\pi+\ln{x}-\ln{(1-x)})x}dx} $$ Let $t=\ln{x}-\ln{(1-x)}$,$x=\frac{e^{t}}{1+e^{t}}$ Thus \begin{align} S&=\int_{-\infty}^{+\infty}{\frac{1}{e^{t}+1}e^{(i\pi+t)\frac{e^{t}}{1+e^t}}\frac{e^{t}}{(1+e^{t})^{2}}dt}\\   &=\int_{-\infty+i\pi}^{-\infty-i\pi}{e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}}dt} \end{align} Due to $$ f(z)=e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}},\qquad D=\{Z\in C|-\pi\leq Im(z) \leq \pi\}$$ Therefore $res(f,0)=-\frac{e}{24}$when $z=0$ with $ \zeta_{R}=\gamma_{R}+o_{R}+\tau_{R}$ $$\oint_{\zeta_{R}}{f(z)dz}=-2\pi i\cdot res(f,0)=\frac{2i\pi e}{24}$$ because $$ \{z_{n}\}\subset D,\qquad |z_{n}|\rightarrow\infty $$ Therefore $$ 2S=2\lim_{R\rightarrow \infty}\int_{\gamma_{R}}{f(z)dz} $$ gives $$ \int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}=Im(S)=\frac{e\pi}{24} $$ My friend tian_275461 told me he use a simliar method to deal with the first one to obtain the result $\frac{\pi}{e}$,but I am not figure it out.","Evaluate integral $$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}$$ Well,I think we have $$\int_{0}^{1}{x^{-x}(1-x)^{x-1}\sin{\pi x}dx}=\frac{\pi}{e}$$ and $$\int_{0}^{1}{x^{x}(1-x)^{1-x}\sin{\pi x}dx}=\frac{e\pi}{24}$$ With such nice result of these integral,why isn't worth to evaluate it? I found a solution about the second one,but I wonder it will work for the first one Note $$ S=\int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}-\int_{0}^{1}{(1-x)e^{(i\pi+\ln{x}-\ln{(1-x)})x}dx} $$ Let $t=\ln{x}-\ln{(1-x)}$,$x=\frac{e^{t}}{1+e^{t}}$ Thus \begin{align} S&=\int_{-\infty}^{+\infty}{\frac{1}{e^{t}+1}e^{(i\pi+t)\frac{e^{t}}{1+e^t}}\frac{e^{t}}{(1+e^{t})^{2}}dt}\\   &=\int_{-\infty+i\pi}^{-\infty-i\pi}{e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}}dt} \end{align} Due to $$ f(z)=e^{\frac{te^{t}}{e^{t}-1} } \frac{e^{t}}{(e^{t}-1)^{3}},\qquad D=\{Z\in C|-\pi\leq Im(z) \leq \pi\}$$ Therefore $res(f,0)=-\frac{e}{24}$when $z=0$ with $ \zeta_{R}=\gamma_{R}+o_{R}+\tau_{R}$ $$\oint_{\zeta_{R}}{f(z)dz}=-2\pi i\cdot res(f,0)=\frac{2i\pi e}{24}$$ because $$ \{z_{n}\}\subset D,\qquad |z_{n}|\rightarrow\infty $$ Therefore $$ 2S=2\lim_{R\rightarrow \infty}\int_{\gamma_{R}}{f(z)dz} $$ gives $$ \int_{0}^{1}{\sin{\pi x}x^{x}(1-x)^{1-x}dx}=Im(S)=\frac{e\pi}{24} $$ My friend tian_275461 told me he use a simliar method to deal with the first one to obtain the result $\frac{\pi}{e}$,but I am not figure it out.",,['calculus']
26,Solve $x^n+y^n = (x+y)^n$,Solve,x^n+y^n = (x+y)^n,Find all positive integers $n$ and real numbers $x$ and $y$ satisfying $x^n+y^n = (x+y)^n$. We first consider the case that $n$ is even. We have $x^{2k}+y^{2k} = \binom{2k}{0}x^{2k}+\binom{2k}{1}yx^{2k-1}+\cdots+\binom{2k}{2k}y^{2k}$. This can be simplified down to $$\binom{2k}{1}yx^{2k-1}+\binom{2k}{2}y^2x^{2k-2}+\cdots+\binom{2k}{2k-1}xy^{2k-1} = 0 \implies$$ $$\binom{2k}{1}x^{2k}+\binom{2k}{2}yx^{2k-1}+\cdots+\binom{2k}{2k-1}y^{2k} = 0.$$ Similarly we can form equations if $n$ is even. The form of the terms remind me of derivatives so that may be useful.,Find all positive integers $n$ and real numbers $x$ and $y$ satisfying $x^n+y^n = (x+y)^n$. We first consider the case that $n$ is even. We have $x^{2k}+y^{2k} = \binom{2k}{0}x^{2k}+\binom{2k}{1}yx^{2k-1}+\cdots+\binom{2k}{2k}y^{2k}$. This can be simplified down to $$\binom{2k}{1}yx^{2k-1}+\binom{2k}{2}y^2x^{2k-2}+\cdots+\binom{2k}{2k-1}xy^{2k-1} = 0 \implies$$ $$\binom{2k}{1}x^{2k}+\binom{2k}{2}yx^{2k-1}+\cdots+\binom{2k}{2k-1}y^{2k} = 0.$$ Similarly we can form equations if $n$ is even. The form of the terms remind me of derivatives so that may be useful.,,['calculus']
27,"Generalized FoxTrot Series $F(a,b,q,x) = \sum_{k=q}^{\infty} \dfrac {(-1)^{k+1} k^a}{k^b+x}$",Generalized FoxTrot Series,"F(a,b,q,x) = \sum_{k=q}^{\infty} \dfrac {(-1)^{k+1} k^a}{k^b+x}","The FoxTrot Series is defined as: $$F = \sum_{k=1}^{\infty} \dfrac {(-1)^{k+1} k^2}{k^3+1}.$$ Using partial fraction decomposition we can show that $$F = \frac 13 \left[ 1 - \ln2 + \pi\operatorname{sech}\left(\frac 12 \sqrt3 \, \pi\right) \right].$$ More details about the evaluation at FoxTros Series MathWorld article or in this math.se answer . Note that we could write $F$ in term of digamma functions : $$F = \frac 13 \left[ 1 - \ln2 - \frac 12 \psi_0\left( \frac 12 (-1)^{1/3} \right) - \frac 12 \psi_0\left( -\frac 12 (-1)^{2/3} \right) + \frac 12 \psi_0\left( \frac 12 \left( 1+ (-1)^{1/3} \right)  \right) + \frac 12 \psi_0\left( \frac 12 \left(1 - 1(-1)^{2/3}  \right)  \right)  \right].$$ Now we define the following parametric series: $$F(a,b,q,x) = \sum_{k=q}^{\infty} \dfrac {(-1)^{k+1} k^a}{k^b+x},$$ where $a,b,q$ are nonnegative integers, $a<b$, and $x\in\mathbb{C}$. Question. Is there a closed-form for $F(a,b,q,x)$? Of course $F=F(2,3,1,1)$. We also know that $F(0,1,1,1)=1-\ln2$. I've evaluated with Maple $F(i,j,1,1)$ for all $(i,j)$ for $0 \leq i <j$, $0 < j \leq 4$. Maple could solve them in term of digamma functions, so I guess that there is a general closed-form. Beside the closed-form maybe we could get or use a nice digamma identity as well.","The FoxTrot Series is defined as: $$F = \sum_{k=1}^{\infty} \dfrac {(-1)^{k+1} k^2}{k^3+1}.$$ Using partial fraction decomposition we can show that $$F = \frac 13 \left[ 1 - \ln2 + \pi\operatorname{sech}\left(\frac 12 \sqrt3 \, \pi\right) \right].$$ More details about the evaluation at FoxTros Series MathWorld article or in this math.se answer . Note that we could write $F$ in term of digamma functions : $$F = \frac 13 \left[ 1 - \ln2 - \frac 12 \psi_0\left( \frac 12 (-1)^{1/3} \right) - \frac 12 \psi_0\left( -\frac 12 (-1)^{2/3} \right) + \frac 12 \psi_0\left( \frac 12 \left( 1+ (-1)^{1/3} \right)  \right) + \frac 12 \psi_0\left( \frac 12 \left(1 - 1(-1)^{2/3}  \right)  \right)  \right].$$ Now we define the following parametric series: $$F(a,b,q,x) = \sum_{k=q}^{\infty} \dfrac {(-1)^{k+1} k^a}{k^b+x},$$ where $a,b,q$ are nonnegative integers, $a<b$, and $x\in\mathbb{C}$. Question. Is there a closed-form for $F(a,b,q,x)$? Of course $F=F(2,3,1,1)$. We also know that $F(0,1,1,1)=1-\ln2$. I've evaluated with Maple $F(i,j,1,1)$ for all $(i,j)$ for $0 \leq i <j$, $0 < j \leq 4$. Maple could solve them in term of digamma functions, so I guess that there is a general closed-form. Beside the closed-form maybe we could get or use a nice digamma identity as well.",,"['calculus', 'sequences-and-series', 'closed-form', 'polygamma']"
28,Beginning of Romance,Beginning of Romance,,"I am a 17-year old student in India, in the standard 12th grade. Recently, I found the fascination in mathematics, and I am eager to dig in further. Currently, the only textbooks I have are the ones at school: M.L Agrawal's of 11th and 12th. I don't find them very supportive. They are educational, but quite exam centered. Almost everything around me is exam centered, as students study math primarily so that they can qualify for board exams and engineering entrances. Not to sell myself short, but hey, not everyone can be Ramanujan and derive wonders from schoolbooks. Could anyone suggest someplace to start? I am really interested in coordinate geometry and calculus. I have considered buying an S.L Loney, but every suggestion would be valuable. Thank you.","I am a 17-year old student in India, in the standard 12th grade. Recently, I found the fascination in mathematics, and I am eager to dig in further. Currently, the only textbooks I have are the ones at school: M.L Agrawal's of 11th and 12th. I don't find them very supportive. They are educational, but quite exam centered. Almost everything around me is exam centered, as students study math primarily so that they can qualify for board exams and engineering entrances. Not to sell myself short, but hey, not everyone can be Ramanujan and derive wonders from schoolbooks. Could anyone suggest someplace to start? I am really interested in coordinate geometry and calculus. I have considered buying an S.L Loney, but every suggestion would be valuable. Thank you.",,"['calculus', 'geometry', 'reference-request', 'self-learning', 'book-recommendation']"
29,Why is an equation necessarily dimensionally correct?,Why is an equation necessarily dimensionally correct?,,"I have just read a fascinating proof of the value of the integral $$ \int_{-\infty}^\infty e^{-ax^2} dx, $$ which proceeds by dimensional analysis , as follows: we know that we can write $$ \int_{-\infty}^\infty e^{-ax^2} dx = f(a) $$ for some $f$. Suppose $x$ represents some length, so that $x$ has dimension $[L]$. The argument of the exponential function must be dimensionless, so $a$ must have dimension $[L]^{-2}$. On the LHS, $e^{-ax^2}$ has dimension $[1]$, and $dx$ has dimension $[L]$, so $f(a)$ must also have dimension $[L]$. Hence, we can write $$ f(a) \sim \frac{1}{\sqrt a} $$ where $\sim$ represents proportionality with respect to a dimensionless constant. Now, we need only invoke the well-known result $$ \int_{-\infty}^\infty e^{-x^2} dx = \sqrt{\pi}, $$ which shows that $f(1) = \sqrt{\pi}$. Thus, we have $f(a) = \frac{\sqrt{\pi}}{\sqrt a}$, and $$ \int_{-\infty}^\infty e^{-ax^2} dx = \frac{\sqrt{\pi}}{\sqrt a}. $$ This approach of evaluating an integral by dimensional analysis is one that I have never seen before, and it is not obvious to me that I should accept its validity. Why should I expect an equation to remain dimensionally correct when I introduce an arbitrary dimensional constraint (in this case, $x$ having dimension $[L]$)? Under what conditions is such a step valid?","I have just read a fascinating proof of the value of the integral $$ \int_{-\infty}^\infty e^{-ax^2} dx, $$ which proceeds by dimensional analysis , as follows: we know that we can write $$ \int_{-\infty}^\infty e^{-ax^2} dx = f(a) $$ for some $f$. Suppose $x$ represents some length, so that $x$ has dimension $[L]$. The argument of the exponential function must be dimensionless, so $a$ must have dimension $[L]^{-2}$. On the LHS, $e^{-ax^2}$ has dimension $[1]$, and $dx$ has dimension $[L]$, so $f(a)$ must also have dimension $[L]$. Hence, we can write $$ f(a) \sim \frac{1}{\sqrt a} $$ where $\sim$ represents proportionality with respect to a dimensionless constant. Now, we need only invoke the well-known result $$ \int_{-\infty}^\infty e^{-x^2} dx = \sqrt{\pi}, $$ which shows that $f(1) = \sqrt{\pi}$. Thus, we have $f(a) = \frac{\sqrt{\pi}}{\sqrt a}$, and $$ \int_{-\infty}^\infty e^{-ax^2} dx = \frac{\sqrt{\pi}}{\sqrt a}. $$ This approach of evaluating an integral by dimensional analysis is one that I have never seen before, and it is not obvious to me that I should accept its validity. Why should I expect an equation to remain dimensionally correct when I introduce an arbitrary dimensional constraint (in this case, $x$ having dimension $[L]$)? Under what conditions is such a step valid?",,"['calculus', 'integration', 'improper-integrals', 'dimensional-analysis']"
30,Elementary proofs about $f(t)=\lim_{n\to\infty}(1+\frac tn)^n$,Elementary proofs about,f(t)=\lim_{n\to\infty}(1+\frac tn)^n,"Please read carefully what I mean by elementary before marking the question as duplicate. I'm starting calculus lessons in High School; that is: no series, no derivatives, no limits of functions, no continuity... I have just stated the axiom of supreme and defined sequence and limit of sequence. I have proved that a monotone, bounded sequence has limit. Just that. Under so 'elementary' conditions, I'd like to prove: For each real $t$ , the sequence $\left(1+\dfrac tn\right)^n$ converges. (I have problems for $t<0$ ). Then I'll define $e^t$ as the limit of this sequence. For every pair $t,s$ , $e^{t+s}=e^te^s$ . Any ideas or bibliography?","Please read carefully what I mean by elementary before marking the question as duplicate. I'm starting calculus lessons in High School; that is: no series, no derivatives, no limits of functions, no continuity... I have just stated the axiom of supreme and defined sequence and limit of sequence. I have proved that a monotone, bounded sequence has limit. Just that. Under so 'elementary' conditions, I'd like to prove: For each real , the sequence converges. (I have problems for ). Then I'll define as the limit of this sequence. For every pair , . Any ideas or bibliography?","t \left(1+\dfrac tn\right)^n t<0 e^t t,s e^{t+s}=e^te^s","['calculus', 'exponential-function']"
31,Ant climbing on bush,Ant climbing on bush,,"An ant is on the ground and trying to climb on a (straight) ivy bush 10m high. It crawls up 0.1m each night, but at day, the bush grows uniformly by 0.5m (in its entire height). Will the ant ever reach the top of the ivy? If yes, in how many days? If no, justify why. Let's convert everything in centimeters. I have made a table with the values of the bush height every night and every day, basis the rules. The ant starts with 1000 cm height above and 0 cm below. Then it advances by 10 cm so it has 990 cm above and 10 cm below. Total height is (still) 1000 cm. In the morning, the height of the bush is proportionally extended by 5% so the up value is now $990*(5/1000)+990 = 1039.5$ and the down is $10*(5/1000)+10 = 10.5$ Total height is of course increased by 50 cm. Then at night, first value is decreased by 10 and second is increased by 10. Height remains the same. We continue this way and have the following values: Bush up (cm)    Bush down (cm)  Total Initially   1000    0   1000 1st night   990 10  1000 1st day     1039,5  10,5    1050 2nd night   1029,5  20,5    1050 2nd day     1078,52381  21,47619048 1100 3rd night   1068,52381  31,47619048 1100 3rd day     1117,093074 32,90692641 1150 4th night   1107,093074 42,90692641 1150 4th day     1155,227555 44,77244495 1200 5th night   1145,227555 54,77244495 1200 We continue this way and now we make a graph of the 3 columns, bush up, bush down and Total. We notice that the 3 curves are declining, which means that they will never intersect. This means that the ant will never reach the top. However, this is not correct. I was told that the problem has a positive reply. Where am I wrong? Thank you very much in anticipation!","An ant is on the ground and trying to climb on a (straight) ivy bush 10m high. It crawls up 0.1m each night, but at day, the bush grows uniformly by 0.5m (in its entire height). Will the ant ever reach the top of the ivy? If yes, in how many days? If no, justify why. Let's convert everything in centimeters. I have made a table with the values of the bush height every night and every day, basis the rules. The ant starts with 1000 cm height above and 0 cm below. Then it advances by 10 cm so it has 990 cm above and 10 cm below. Total height is (still) 1000 cm. In the morning, the height of the bush is proportionally extended by 5% so the up value is now and the down is Total height is of course increased by 50 cm. Then at night, first value is decreased by 10 and second is increased by 10. Height remains the same. We continue this way and have the following values: Bush up (cm)    Bush down (cm)  Total Initially   1000    0   1000 1st night   990 10  1000 1st day     1039,5  10,5    1050 2nd night   1029,5  20,5    1050 2nd day     1078,52381  21,47619048 1100 3rd night   1068,52381  31,47619048 1100 3rd day     1117,093074 32,90692641 1150 4th night   1107,093074 42,90692641 1150 4th day     1155,227555 44,77244495 1200 5th night   1145,227555 54,77244495 1200 We continue this way and now we make a graph of the 3 columns, bush up, bush down and Total. We notice that the 3 curves are declining, which means that they will never intersect. This means that the ant will never reach the top. However, this is not correct. I was told that the problem has a positive reply. Where am I wrong? Thank you very much in anticipation!",990*(5/1000)+990 = 1039.5 10*(5/1000)+10 = 10.5,['calculus']
32,Proof of the relation $\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1)$,Proof of the relation,\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1),"I had the thought that by introducing some parameters into simple integrals and taking derivatives we can get exact values for infinitely many 'complicated' integrals. $$\int_0^1 x^a dx = \frac{1}{a+1}$$ $$\int_0^1 x^a \log x dx = -\frac{1}{(a+1)^2}$$ $$\int_0^1 x^a \log^n x dx = \frac{(-1)^n~ n!}{(a+1)^{n+1}}$$ Since $|x|<1$ the following sum has a closed form: $$\sum_{a=0}^{ \infty } x^a=\frac{1}{1-x}$$ And by definition: $$\sum_{a=0}^{ \infty } \frac{1}{(a+1)^{n+1}}=\zeta(n+1)$$ So we have: $$\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1)$$ Is this proof correct? Can we use this method to find more complicated integrals (assuming the derivatives exist of course)? For example, if we use two more parameters in the original integral: $$\int_0^1 (b+cx)^a dx = \frac{(b+c)^{a+1}-b^{a+1}}{c(a+1)}$$ We can get much more complicated expressions.","I had the thought that by introducing some parameters into simple integrals and taking derivatives we can get exact values for infinitely many 'complicated' integrals. $$\int_0^1 x^a dx = \frac{1}{a+1}$$ $$\int_0^1 x^a \log x dx = -\frac{1}{(a+1)^2}$$ $$\int_0^1 x^a \log^n x dx = \frac{(-1)^n~ n!}{(a+1)^{n+1}}$$ Since $|x|<1$ the following sum has a closed form: $$\sum_{a=0}^{ \infty } x^a=\frac{1}{1-x}$$ And by definition: $$\sum_{a=0}^{ \infty } \frac{1}{(a+1)^{n+1}}=\zeta(n+1)$$ So we have: $$\int^1_0 \frac{\log^n x}{1-x}dx=(-1)^n~ n!~ \zeta(n+1)$$ Is this proof correct? Can we use this method to find more complicated integrals (assuming the derivatives exist of course)? For example, if we use two more parameters in the original integral: $$\int_0^1 (b+cx)^a dx = \frac{(b+c)^{a+1}-b^{a+1}}{c(a+1)}$$ We can get much more complicated expressions.",,"['calculus', 'integration', 'proof-verification', 'definite-integrals']"
33,Dilogarithm identity containing the tribonacci constant,Dilogarithm identity containing the tribonacci constant,,"The motivation of this question is the brilliant conjecture by @Tito Piezas III. In $(4)$ of his question the equation seems to be true for all $n > 1$ real numbers. The case $n=2$ leads us to a dilogarithm identity, where all the dilogarithm terms are known constants. After that I've tried to prove the case $n=3$. Let $\tau$ denotes the tribonacci constant , defined as the following. $$\tau = \frac{1}{3}\left(1+\sqrt[3]{19-3\sqrt{33}}+\sqrt[3]{19+3\sqrt{33}}\right) \approx 1.83928675521416\dots$$ Note that $\tau^3-\tau^2-\tau-1=0$. How could we prove the following conjectured dilogarithm identity? $$\operatorname{Li}_2\left(\frac{1}{\tau^3}\right)+\operatorname{Li}_2\left(\tau^2\right)+\operatorname{Li}_2\left(\frac{\tau}{\tau+1}\right)$$  $$ \stackrel{?}{=} \frac{1}{2}\ln(1-\tau)\ln\tau - \frac{1}{2}\ln\left(\frac{1}{\tau+1}\right)\ln\left(\frac{\tau}{\tau+1}\right)-\frac{1}{4}\ln(\tau^2)\ln(1-\tau^2)-\ln^2(-\tau)-\frac{7\pi^2}{12}, $$ where $\operatorname{Li}_2$ is the dilogarithm function . It is quite easy to show that the imaginary part of the sum of dilogarithms is $-2\pi\ln\tau$.","The motivation of this question is the brilliant conjecture by @Tito Piezas III. In $(4)$ of his question the equation seems to be true for all $n > 1$ real numbers. The case $n=2$ leads us to a dilogarithm identity, where all the dilogarithm terms are known constants. After that I've tried to prove the case $n=3$. Let $\tau$ denotes the tribonacci constant , defined as the following. $$\tau = \frac{1}{3}\left(1+\sqrt[3]{19-3\sqrt{33}}+\sqrt[3]{19+3\sqrt{33}}\right) \approx 1.83928675521416\dots$$ Note that $\tau^3-\tau^2-\tau-1=0$. How could we prove the following conjectured dilogarithm identity? $$\operatorname{Li}_2\left(\frac{1}{\tau^3}\right)+\operatorname{Li}_2\left(\tau^2\right)+\operatorname{Li}_2\left(\frac{\tau}{\tau+1}\right)$$  $$ \stackrel{?}{=} \frac{1}{2}\ln(1-\tau)\ln\tau - \frac{1}{2}\ln\left(\frac{1}{\tau+1}\right)\ln\left(\frac{\tau}{\tau+1}\right)-\frac{1}{4}\ln(\tau^2)\ln(1-\tau^2)-\ln^2(-\tau)-\frac{7\pi^2}{12}, $$ where $\operatorname{Li}_2$ is the dilogarithm function . It is quite easy to show that the imaginary part of the sum of dilogarithms is $-2\pi\ln\tau$.",,"['calculus', 'integration', 'special-functions', 'closed-form', 'polylogarithm']"
34,Series absolute convergence,Series absolute convergence,,"What could you say about absolute convergence of this series? $$ \sum_1^\infty \frac{\sin(n) \sin(n^2)}{n} $$","What could you say about absolute convergence of this series? $$ \sum_1^\infty \frac{\sin(n) \sin(n^2)}{n} $$",,"['calculus', 'sequences-and-series']"
35,Is there a simpler method to compute $\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2n } x\right)} d x$,Is there a simpler method to compute,\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2n } x\right)} d x,"When I encountered the integral $\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x $ , I tried the substitution $x\mapsto \frac{1}{x}  $ and found a wonderful result. $$I=\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x \stackrel{x\mapsto\frac{1}{x}}{=} \int_0^{\infty} \frac{1}{x(1+x)\left(\pi+\ln ^{2 } x\right)} d x  $$ Averaging them yields $$ \begin{aligned} I & =\frac{1}{2} \int_0^{\infty}\left[\frac{1}{(1+x)\left(\pi+\ln ^2 x\right)}+\frac{1}{x(1+x)\left(\pi+\ln ^2 x\right)}\right]dx\\ & =\frac{1}{2} \int_0^{\infty} \frac{1}{x\left(\pi+\ln ^2 x\right)} d x \\ & =\frac{1}{2} \int_0^{\infty} \frac{1}{\pi+\ln ^2 x} d(\ln x) \\ & =\frac{1}{2 \sqrt{\pi}}\left[\tan ^{-1}\left(\frac{\ln x}{\sqrt{\pi}}\right)\right]_0^{\infty}\\ & =\frac{\sqrt{\pi}}{2} \end{aligned} $$ Then I want to generalize the result to the integral $$I_n=\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2n } x\right)} d x $$ By replacing the power $2$ by $2n$ , we have $$ \begin{aligned} I_n & =\frac{1}{2} \int_0^{\infty} \frac{1}{x\left(\pi+\ln ^{2 n} x\right)} d x\\ &=  \frac{\sqrt[2 n]{\pi}}{2\pi} \int_{-\infty}^{\infty} \frac{1}{1+x^{2 n}} d x \quad (\textrm{ via } \ln x \mapsto \sqrt[2 n]{\pi} x) \end{aligned} $$ Using the well-known result $\int_0^{\infty} \frac{d x}{1+x^n}=\frac{\pi}{n} \csc \left(\frac{\pi}{n}\right)$ , we have $$ I_n=\frac{\sqrt[2 n]{\pi}}{2 n} \csc \left(\frac{\pi}{2 n}\right) $$ For simplicity , given any even integer $m$ , we have $$ \boxed{\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{m } x\right)} d x =\frac{\sqrt[m]{\pi}}{m} \csc \left(\frac{\pi}{m}\right)} $$ For examples, $$ \begin{aligned} & \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x =\frac{\sqrt{\pi}}{2} \\ & \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{4 } x\right)} d x =\frac{\sqrt[4]{\pi}}{2 \sqrt{2}} \\ & \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{6 } x\right)} d x =\frac{\sqrt[6]{\pi}}{3} \end{aligned} $$ Are there any other methods? Comments and alternative methods are highly appreciated.","When I encountered the integral , I tried the substitution and found a wonderful result. Averaging them yields Then I want to generalize the result to the integral By replacing the power by , we have Using the well-known result , we have For simplicity , given any even integer , we have For examples, Are there any other methods? Comments and alternative methods are highly appreciated.","\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x  x\mapsto \frac{1}{x}   I=\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x \stackrel{x\mapsto\frac{1}{x}}{=} \int_0^{\infty} \frac{1}{x(1+x)\left(\pi+\ln ^{2 } x\right)} d x   
\begin{aligned}
I & =\frac{1}{2} \int_0^{\infty}\left[\frac{1}{(1+x)\left(\pi+\ln ^2 x\right)}+\frac{1}{x(1+x)\left(\pi+\ln ^2 x\right)}\right]dx\\
& =\frac{1}{2} \int_0^{\infty} \frac{1}{x\left(\pi+\ln ^2 x\right)} d x \\
& =\frac{1}{2} \int_0^{\infty} \frac{1}{\pi+\ln ^2 x} d(\ln x) \\
& =\frac{1}{2 \sqrt{\pi}}\left[\tan ^{-1}\left(\frac{\ln x}{\sqrt{\pi}}\right)\right]_0^{\infty}\\
& =\frac{\sqrt{\pi}}{2}
\end{aligned}
 I_n=\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2n } x\right)} d x  2 2n 
\begin{aligned}
I_n
& =\frac{1}{2} \int_0^{\infty} \frac{1}{x\left(\pi+\ln ^{2 n} x\right)} d x\\ &=  \frac{\sqrt[2 n]{\pi}}{2\pi} \int_{-\infty}^{\infty} \frac{1}{1+x^{2 n}} d x \quad (\textrm{ via } \ln x \mapsto \sqrt[2 n]{\pi} x)
\end{aligned}
 \int_0^{\infty} \frac{d x}{1+x^n}=\frac{\pi}{n} \csc \left(\frac{\pi}{n}\right) 
I_n=\frac{\sqrt[2 n]{\pi}}{2 n} \csc \left(\frac{\pi}{2 n}\right)
 m 
\boxed{\int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{m } x\right)} d x =\frac{\sqrt[m]{\pi}}{m} \csc \left(\frac{\pi}{m}\right)}
 
\begin{aligned}
& \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{2 } x\right)} d x =\frac{\sqrt{\pi}}{2} \\
& \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{4 } x\right)} d x =\frac{\sqrt[4]{\pi}}{2 \sqrt{2}} \\
& \int_0^{\infty} \frac{1}{(1+x)\left(\pi+\ln ^{6 } x\right)} d x =\frac{\sqrt[6]{\pi}}{3}
\end{aligned}
","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'trigonometric-integrals']"
36,"Proving $\sin(\tanh x) \ge \tanh(\sin x)$, for $x \in [0,\pi/2]$","Proving , for","\sin(\tanh x) \ge \tanh(\sin x) x \in [0,\pi/2]","Earlier, a very interesting proof of an inequality has been proposed at MSE: How prove this inequality $\tan{(\sin{x})}>\sin{(\tan{x})}$ Here the question is: How to prove that $$\sin(\tanh x) \ge \tanh(\sin x), ~~ \text{for}~~ x \in [0,\pi/2]$$ Interestingly, the first three terms of the Mclaurin series are identical for both the functions.","Earlier, a very interesting proof of an inequality has been proposed at MSE: How prove this inequality $\tan{(\sin{x})}>\sin{(\tan{x})}$ Here the question is: How to prove that Interestingly, the first three terms of the Mclaurin series are identical for both the functions.","\sin(\tanh x) \ge \tanh(\sin x), ~~ \text{for}~~ x \in [0,\pi/2]","['calculus', 'sequences-and-series', 'inequality']"
37,Proof of concavity of log function,Proof of concavity of log function,,Does anybody have a proof of the concavity of the $\log{x}$ that does not use calculus?,Does anybody have a proof of the concavity of the $\log{x}$ that does not use calculus?,,"['calculus', 'algebra-precalculus', 'logarithms']"
38,"Range of function $ f(x) = x\sqrt{x}+\frac{1}{x\sqrt{x}}-4\left(x+\frac{1}{x}\right),$ Where $x>0$",Range of function  Where," f(x) = x\sqrt{x}+\frac{1}{x\sqrt{x}}-4\left(x+\frac{1}{x}\right), x>0","Find the  range of the function $\displaystyle f(x) = x\sqrt{x}+\frac{1}{x\sqrt{x}}-4\left(x+\frac{1}{x}\right),$ where $x>0$ $\bf{My\; Try::}$ Let $\sqrt{x}=t\;,$ Then $\displaystyle f(t) = t^3+\frac{1}{t^3}-4\left(t^2+\frac{1}{t^2}\right)\;,$ Now After Simplification, We get $\displaystyle f(t) = \left(t+\frac{1}{t}\right)^3-3\left(t+\frac{1}{t}\right)-4\left[\left(t+\frac{1}{t}\right)^2-2\right]$ Now Put $\displaystyle t+\frac{1}{t} = u\;,$ Then $\displaystyle \sqrt{x}+\frac{1}{\sqrt{x}} = u\;,$ So we get $u\geq 2$ (Using $\bf{A.M\geq G.M}$) And our function convert into $\displaystyle f(u) = u^3-4u^2-3u+8\;,$ Where $u\geq 2$ Now Using Second Derivative Test, $f'(u) = 3u^2-8u-3$ and $f''(u) = 6u-8$ So for Max. and Min., We put $\displaystyle f'(u)=0\Rightarrow u=3$ and $f''(3)=10>0$ So $u=3$ is a point of Minimum. So $f(2)=8-4(4)-3(2)+8 = -6$ and $f(3) = -10$ and Graph is Like this So Range is $$\displaystyle \left[-10,\infty \right)$$ My question is can we solve it any other way,  Like using Inequality If yes, Then plz explain here Thanks","Find the  range of the function $\displaystyle f(x) = x\sqrt{x}+\frac{1}{x\sqrt{x}}-4\left(x+\frac{1}{x}\right),$ where $x>0$ $\bf{My\; Try::}$ Let $\sqrt{x}=t\;,$ Then $\displaystyle f(t) = t^3+\frac{1}{t^3}-4\left(t^2+\frac{1}{t^2}\right)\;,$ Now After Simplification, We get $\displaystyle f(t) = \left(t+\frac{1}{t}\right)^3-3\left(t+\frac{1}{t}\right)-4\left[\left(t+\frac{1}{t}\right)^2-2\right]$ Now Put $\displaystyle t+\frac{1}{t} = u\;,$ Then $\displaystyle \sqrt{x}+\frac{1}{\sqrt{x}} = u\;,$ So we get $u\geq 2$ (Using $\bf{A.M\geq G.M}$) And our function convert into $\displaystyle f(u) = u^3-4u^2-3u+8\;,$ Where $u\geq 2$ Now Using Second Derivative Test, $f'(u) = 3u^2-8u-3$ and $f''(u) = 6u-8$ So for Max. and Min., We put $\displaystyle f'(u)=0\Rightarrow u=3$ and $f''(3)=10>0$ So $u=3$ is a point of Minimum. So $f(2)=8-4(4)-3(2)+8 = -6$ and $f(3) = -10$ and Graph is Like this So Range is $$\displaystyle \left[-10,\infty \right)$$ My question is can we solve it any other way,  Like using Inequality If yes, Then plz explain here Thanks",,"['calculus', 'inequality', 'optimization']"
39,What's exactly the deal with differentials? (Confessions of a desperate calculus student),What's exactly the deal with differentials? (Confessions of a desperate calculus student),,"So I don't know if I'm the only one to feel this, but ever since I was introduced to Calculus, I've had a slight (if not to say major) aversion to differentials. This sort of ""phobia"" started from the very first moment I delved into integrals. Riemann sums seemed to make sense, though for me they were not enough for justifying the use of ""dx"" after the integral sign and the function. After all, you could still do without it in practice (what's the need for writing down the base of these rectangles over and over?). I was satisfied by thinking it was something merely symbolic to remind students what they were doing when they calculated definite integrals, and/or to help them remember with respect to what variable they were integrating (kinda like the reason why we sometimes use dy/dx to write a derivative). Or so I thought. Having now been approached to differential equations, I'm starting to realize I was completely wrong! I find ""dy"" and ""dx"" spread out around equations! How could that be possible if they are just a fancy way of transcribing derivatives and integrals? I imagined they had no meaning outside of those particular contexts (i.e.: dy/dx, and to indicate an integration with respect to x or whatever). Could anybody help me out? I'm really confused at the moment. I'd really appreciate it :)  (P.S.: Sorry to bother you all on Thanksgiving - assuming some of you might be from the US.) EDIT: I don't think my question is a duplicate of Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? , as that one doesn't address its use in integrals and in differential equations. Regardless of whether dy/dx is a ratio or not; what I'm really asking is why we use dx and dy separately for integration and diff. equations. Even if they're numbers, if they tend to 0, then dx (or dy) * whatever = 0. Am I wrong in thinking that way?","So I don't know if I'm the only one to feel this, but ever since I was introduced to Calculus, I've had a slight (if not to say major) aversion to differentials. This sort of ""phobia"" started from the very first moment I delved into integrals. Riemann sums seemed to make sense, though for me they were not enough for justifying the use of ""dx"" after the integral sign and the function. After all, you could still do without it in practice (what's the need for writing down the base of these rectangles over and over?). I was satisfied by thinking it was something merely symbolic to remind students what they were doing when they calculated definite integrals, and/or to help them remember with respect to what variable they were integrating (kinda like the reason why we sometimes use dy/dx to write a derivative). Or so I thought. Having now been approached to differential equations, I'm starting to realize I was completely wrong! I find ""dy"" and ""dx"" spread out around equations! How could that be possible if they are just a fancy way of transcribing derivatives and integrals? I imagined they had no meaning outside of those particular contexts (i.e.: dy/dx, and to indicate an integration with respect to x or whatever). Could anybody help me out? I'm really confused at the moment. I'd really appreciate it :)  (P.S.: Sorry to bother you all on Thanksgiving - assuming some of you might be from the US.) EDIT: I don't think my question is a duplicate of Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? , as that one doesn't address its use in integrals and in differential equations. Regardless of whether dy/dx is a ratio or not; what I'm really asking is why we use dx and dy separately for integration and diff. equations. Even if they're numbers, if they tend to 0, then dx (or dy) * whatever = 0. Am I wrong in thinking that way?",,"['calculus', 'integration', 'derivatives']"
40,Convergence of double series $\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2}$,Convergence of double series,\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2},"I was playing around with some integrals and series convergence and computations and after some ugly transformations the following double series occurred. Title says it all, is the following series convergent or divergent? If its convergent can we get a good estimate? $$\displaystyle{ \sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2}}.$$ An elementary solution is preferred. Thanks in advance.","I was playing around with some integrals and series convergence and computations and after some ugly transformations the following double series occurred. Title says it all, is the following series convergent or divergent? If its convergent can we get a good estimate? $$\displaystyle{ \sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{\sin(\sin(nm))}{n^2+m^2}}.$$ An elementary solution is preferred. Thanks in advance.",,['calculus']
41,Proof of Cauchy's Beta Integral $\int_{-\infty}^\infty \frac{dt}{(1+it)^x(1-it)^y}$,Proof of Cauchy's Beta Integral,\int_{-\infty}^\infty \frac{dt}{(1+it)^x(1-it)^y},The Cauchy's Beta Integral is given by $$\int_{-\infty}^\infty \frac{dt}{(1+it)^x(1-it)^y}=\frac{\pi 2^{2-x-y}\Gamma(x+y-1)}{\Gamma(x)\Gamma(y)}$$ I would like to know how it is proved.,The Cauchy's Beta Integral is given by $$\int_{-\infty}^\infty \frac{dt}{(1+it)^x(1-it)^y}=\frac{\pi 2^{2-x-y}\Gamma(x+y-1)}{\Gamma(x)\Gamma(y)}$$ I would like to know how it is proved.,,"['calculus', 'complex-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
42,Maximize function on orthogonal matrices,Maximize function on orthogonal matrices,,"Consider the function $f$ from the set of $n \times n$ real matrices taking $A=(a_{ij})$ to $f(A):= \prod_{(i,j) \neq (k,l)}(a_{ij}-a_{kl}) $. Edit: Note that $f(A) \ge 0$ for all $A$, since grouping pairs we have $$f(A):=(-1)^{\frac{n^2(n^2-1)}{2}}\prod_{(i,j) \lt_ {lex} (k,l)}(a_{ij}-a_{kl})^2$$ and $ n^2(n^2-1) \equiv 0 \, \text{mod} \, 4$ for all $n$, end edit. Is there a way to compute $M:=\text{max}\{  f(A)   : A A^{t}=I  \}$ ?. I know that, since $A$ orhogonal implies $\mid a_{ij} \mid \leq 1$ for all $ 1\leq i,j \leq n $, we have that $2^{2 {n^2 \choose 2}}=2^{n^2(n^2-1)}$ is a trivial upper bound on M, but for example if $n=2$ we have that actually $M=0$ because every $2 \times 2$ orthogonal matrix has at least two equal entries. So if we can't compute $M$ can we at least give a better upper bound?. Following your advice. I estimated $M$ using random orthogonal matrices for $n \le 6$. Here are the results I've got: \begin{array}{|c|c|c|c|} \hline n & \text{# of orth. Matrices} & \text{Estimated} \, M  \\ \hline 2 & \infty & 0 \\ \hline 3 & 5\times 10^4 & 1.13762 \times 10^{-17} \\ \hline 4 & 5\times 10^4 & 3.10228 \times 10^{-80} \\ \hline 5 & 1 \times 10^3 & 5.71162 \times 10^{-248} \\ \hline 6 & 1\times 10^3 & 2.80541 \times 10^{-588}\\ \hline. \end{array} for example this is what the graphic for $n=3$ looks like: So it seems that $M$ is much more smaller than the trivial bound. Does anyone has an idea of how to construct a formal proof?. I'll be offering a bounty as soon as is allowed.","Consider the function $f$ from the set of $n \times n$ real matrices taking $A=(a_{ij})$ to $f(A):= \prod_{(i,j) \neq (k,l)}(a_{ij}-a_{kl}) $. Edit: Note that $f(A) \ge 0$ for all $A$, since grouping pairs we have $$f(A):=(-1)^{\frac{n^2(n^2-1)}{2}}\prod_{(i,j) \lt_ {lex} (k,l)}(a_{ij}-a_{kl})^2$$ and $ n^2(n^2-1) \equiv 0 \, \text{mod} \, 4$ for all $n$, end edit. Is there a way to compute $M:=\text{max}\{  f(A)   : A A^{t}=I  \}$ ?. I know that, since $A$ orhogonal implies $\mid a_{ij} \mid \leq 1$ for all $ 1\leq i,j \leq n $, we have that $2^{2 {n^2 \choose 2}}=2^{n^2(n^2-1)}$ is a trivial upper bound on M, but for example if $n=2$ we have that actually $M=0$ because every $2 \times 2$ orthogonal matrix has at least two equal entries. So if we can't compute $M$ can we at least give a better upper bound?. Following your advice. I estimated $M$ using random orthogonal matrices for $n \le 6$. Here are the results I've got: \begin{array}{|c|c|c|c|} \hline n & \text{# of orth. Matrices} & \text{Estimated} \, M  \\ \hline 2 & \infty & 0 \\ \hline 3 & 5\times 10^4 & 1.13762 \times 10^{-17} \\ \hline 4 & 5\times 10^4 & 3.10228 \times 10^{-80} \\ \hline 5 & 1 \times 10^3 & 5.71162 \times 10^{-248} \\ \hline 6 & 1\times 10^3 & 2.80541 \times 10^{-588}\\ \hline. \end{array} for example this is what the graphic for $n=3$ looks like: So it seems that $M$ is much more smaller than the trivial bound. Does anyone has an idea of how to construct a formal proof?. I'll be offering a bounty as soon as is allowed.",,"['calculus', 'linear-algebra', 'optimization', 'maxima-minima', 'orthogonal-matrices']"
43,Closed form of an integral involving Lambert function,Closed form of an integral involving Lambert function,,"I'm trying to compute the following integral explicitly. $$I=\int_{0}^{+\infty} dx \left(1+\frac{1}{x}\right) \frac{\sqrt{x}}{e^{-1}+xe^x}$$ The best I managed to do is to do a change of variable $x=W(y)$, where W is the Lambert function. The integral is then given by $$I=\int_{0}^{+\infty} \frac{dy}{y}  \frac{\sqrt{W(y)}}{e^{-1}+y}$$ Maybe there could be a way to deform the contour of integration in the complex plane and use a residue formula with the new contour as we could have a pole at $y=-e^{-1}$? I guess we could do the transformation $y=e^x$ and obtain $$I=\int_{-\infty}^{+\infty} dx  \frac{\sqrt{W(e^x)}}{e^{-1}+e^x}$$ The poles would be located at $x=-1\pm i \pi$ but I do not know which contour to choose... I computed numerically the integral on mathematica which gives $I\simeq 3.9965$","I'm trying to compute the following integral explicitly. $$I=\int_{0}^{+\infty} dx \left(1+\frac{1}{x}\right) \frac{\sqrt{x}}{e^{-1}+xe^x}$$ The best I managed to do is to do a change of variable $x=W(y)$, where W is the Lambert function. The integral is then given by $$I=\int_{0}^{+\infty} \frac{dy}{y}  \frac{\sqrt{W(y)}}{e^{-1}+y}$$ Maybe there could be a way to deform the contour of integration in the complex plane and use a residue formula with the new contour as we could have a pole at $y=-e^{-1}$? I guess we could do the transformation $y=e^x$ and obtain $$I=\int_{-\infty}^{+\infty} dx  \frac{\sqrt{W(e^x)}}{e^{-1}+e^x}$$ The poles would be located at $x=-1\pm i \pi$ but I do not know which contour to choose... I computed numerically the integral on mathematica which gives $I\simeq 3.9965$",,"['calculus', 'integration', 'closed-form', 'residue-calculus', 'lambert-w']"
44,How to get the SVD of $2AA^T-\operatorname{diag}(AA^T)$ given $A$ and its SVD $A=USV^T$?,How to get the SVD of  given  and its SVD ?,2AA^T-\operatorname{diag}(AA^T) A A=USV^T,"Given a matrix $A\in R^{n\times d}$ with $n>d$, and we can have some fast ways to (approximately) calculate the SVD (Singular Value Decomposition) of $A$, saying $A=USV^T$ and $V\in R^{d\times d}$. It is straightforward to know that the SVD of $2AA^T$ is $U(2SS)V^T$, that is to say the SVD of  $2AA^T$ requires $O(nd^2)$ time similar to that of $A$. However,  to get the SVD of $2AA^T-\operatorname{diag}(AA^T)\in R^{n\times n}$ where $\operatorname{diag}(AA^T)$ is a square diagonal matrix who only has the diagonal elements of $AA^T$ in its diagonal, if running SVD directly on $2AA^T-\operatorname{diag}(AA^T)$, we might need $O(n^3)$ time. My question is, do you have any method or equation to use $A$ and its SVD $USV^T$ to indirectly get the SVD of  $2AA^T-\operatorname{diag}(AA^T)$? Many thanks for your help.","Given a matrix $A\in R^{n\times d}$ with $n>d$, and we can have some fast ways to (approximately) calculate the SVD (Singular Value Decomposition) of $A$, saying $A=USV^T$ and $V\in R^{d\times d}$. It is straightforward to know that the SVD of $2AA^T$ is $U(2SS)V^T$, that is to say the SVD of  $2AA^T$ requires $O(nd^2)$ time similar to that of $A$. However,  to get the SVD of $2AA^T-\operatorname{diag}(AA^T)\in R^{n\times n}$ where $\operatorname{diag}(AA^T)$ is a square diagonal matrix who only has the diagonal elements of $AA^T$ in its diagonal, if running SVD directly on $2AA^T-\operatorname{diag}(AA^T)$, we might need $O(n^3)$ time. My question is, do you have any method or equation to use $A$ and its SVD $USV^T$ to indirectly get the SVD of  $2AA^T-\operatorname{diag}(AA^T)$? Many thanks for your help.",,"['calculus', 'linear-algebra', 'matrices', 'numerical-linear-algebra', 'svd']"
45,Modern notational alternatives for the indefinite integral?,Modern notational alternatives for the indefinite integral?,,"I like the Leibniz notation, and I think the reason it's survived for over 300 years and continued to be almost the only game in town is that in many respects it's a miracle of design. Nevertheless it's an artifact of an earlier era in the history of mathematics, and anecdotally I seem to encounter a lot of mathematicians who feel that it's ugly, bad, and illogical. There seem to be two fundamental issues involved: (1) it's commonly interpreted using infinitesimals, which didn't get rehabilitated by non-standard analysis (NSA) until ca. 1960; (2) it predates the notion of a function. Issue #1 seems to me to be a non-issue. In fact Blaszczyk et al. (see p. 10) have argued that Leibniz and Fermat had a pretty fully developed notation and terminology for what NSA refers to as the ""standard part:"" they called it ""adequality"" and used the symbol ${}_{\ulcorner\!\urcorner}$. From this perspective what NSA contributed was nothing more than some systematization of long-established practices and some model-theoretic work that showed that this systematization was sufficient logical justification for those practices. But I think the complaints about the Leibniz notation may have more merit when it comes to issue #2. For example, in comments in this mathoverflow question , Andrej Bauer complains that: it's legal to write $\int x^2\: dx=x^3/3+C$ (which exposes the bound variable $x$) I suggested in that comment thread that this could be OK if one simply interpreted the notation $x$ as the identity function, but Andrej Bauer pointed out that that may not be enough to explain all possible uses of this feature of the notation. Are there well thought out modern alternatives to the Leibniz notation that would address issue #2? The closest I can think of is something like this: $ \int x \mapsto x^2 = \{f|\exists C\ f(x)=(x \mapsto x^3/3+C)\}$ This uses the notation $\mapsto$ for constructing anonymous functions, e.g., $x \mapsto x^2$ means the function $f$ such that $f(x)=x^2$. Well, it works here, but it's awfully painful to write. Are there better alternatives that are either used by a significant number of people or that have been ""test-driven"" enough to show that they're really practical?","I like the Leibniz notation, and I think the reason it's survived for over 300 years and continued to be almost the only game in town is that in many respects it's a miracle of design. Nevertheless it's an artifact of an earlier era in the history of mathematics, and anecdotally I seem to encounter a lot of mathematicians who feel that it's ugly, bad, and illogical. There seem to be two fundamental issues involved: (1) it's commonly interpreted using infinitesimals, which didn't get rehabilitated by non-standard analysis (NSA) until ca. 1960; (2) it predates the notion of a function. Issue #1 seems to me to be a non-issue. In fact Blaszczyk et al. (see p. 10) have argued that Leibniz and Fermat had a pretty fully developed notation and terminology for what NSA refers to as the ""standard part:"" they called it ""adequality"" and used the symbol ${}_{\ulcorner\!\urcorner}$. From this perspective what NSA contributed was nothing more than some systematization of long-established practices and some model-theoretic work that showed that this systematization was sufficient logical justification for those practices. But I think the complaints about the Leibniz notation may have more merit when it comes to issue #2. For example, in comments in this mathoverflow question , Andrej Bauer complains that: it's legal to write $\int x^2\: dx=x^3/3+C$ (which exposes the bound variable $x$) I suggested in that comment thread that this could be OK if one simply interpreted the notation $x$ as the identity function, but Andrej Bauer pointed out that that may not be enough to explain all possible uses of this feature of the notation. Are there well thought out modern alternatives to the Leibniz notation that would address issue #2? The closest I can think of is something like this: $ \int x \mapsto x^2 = \{f|\exists C\ f(x)=(x \mapsto x^3/3+C)\}$ This uses the notation $\mapsto$ for constructing anonymous functions, e.g., $x \mapsto x^2$ means the function $f$ such that $f(x)=x^2$. Well, it works here, but it's awfully painful to write. Are there better alternatives that are either used by a significant number of people or that have been ""test-driven"" enough to show that they're really practical?",,['calculus']
46,Help in evaluating $\int \frac {t^4 \tan t}{2 + \cos t}~dt$,Help in evaluating,\int \frac {t^4 \tan t}{2 + \cos t}~dt,Can anybody help me in evaluating this indefinite integral? I can't possibly find a workable substitution: $$\int \dfrac {t^4 \tan t}{2 + \cos t}dt$$ I have already tried substituting $\tan t=\frac{\sin t}{\cos t}$ and it ended up as $\int \frac {t^4\frac {\sin t}{\cos t}}{2+\cos t}~dt \Rightarrow \int \frac {t^4\sin t}{2\cos t + \cos^2 t}~dt$. Substitution fails from here.,Can anybody help me in evaluating this indefinite integral? I can't possibly find a workable substitution: $$\int \dfrac {t^4 \tan t}{2 + \cos t}dt$$ I have already tried substituting $\tan t=\frac{\sin t}{\cos t}$ and it ended up as $\int \frac {t^4\frac {\sin t}{\cos t}}{2+\cos t}~dt \Rightarrow \int \frac {t^4\sin t}{2\cos t + \cos^2 t}~dt$. Substitution fails from here.,,"['calculus', 'integration', 'indefinite-integrals']"
47,proof of l'Hôpital's rule [duplicate],proof of l'Hôpital's rule [duplicate],,"This question already has answers here : Understanding the Proof of L'Hopital's Rule (2 answers) Closed 4 years ago . I've never worked out the general proof of l'Hôpital before, and am taking the opportunity to do so before I return to the soul-crushing grind of college life. I looked in Spivak and found a fine proof of the $(x \rightarrow a$ and $f(x), g(x) \rightarrow 0)$ case; but when he went to prove the $(x \rightarrow \infty, f(x), g(x) \rightarrow 0)$ case, he made a suggestion which actually does not work. (He proposed applying l'Hôpital for the first case above to $f(1/x) / g(1/x)$ as $x \rightarrow 0$, but since he used the fact that $f(0)$ and $g(0)$ could be defined to prove the first case, his version doesn't seem to apply. Correct me if I'm wrong!) I adapted this proof of the second case. Theorem : Suppose that $\lim_{x \to \infty} f(x), \lim_{x \to \infty} g(x) = 0$, and $\lim_{x \to \infty} \frac{f'(x)}{g'(x)} = l$. Then $ \lim_{x \to \infty} \frac{f(x)}{g(x)} = l.$ Proof : Note as a lemma that there exists an interval $I = (c, \infty)$ on which $g'(x) \neq 0$ $g(x) \neq 0$ (The hypothesis implies (1); to prove (2), note that every interval $(\eta, \infty)$ would otherwise have $g(\xi) = 0$, so taking any $\eta ' > \eta$, there would be $g'(x) = 0$ on $(\xi, \xi ')$, and thus on $(\eta, \infty)$, against (1).) Fix $\epsilon > 0$. By hypothesis, $\exists M: x > M \implies |\frac{f'(x)}{g'(x)} - l| <  \frac{\epsilon}{2}$. If $M < c$, choose $M = c$ so $M \in I$. Now pick any $y > M$. By Cauchy, $\forall x > y$ we get $($for $\mu \in (y, x))$ $$\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f'(\mu)}{g'(\mu)}.$$ But if we take $\lim_{x \to \infty}$ of both sides, we find $$\lim_{x \to \infty}\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f(y)}{g(y)} = \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)}. $$ We know that the RHS limit is determinate; we also know that $$ l - \frac{\epsilon}{2} < \frac{f'(\mu)}{g'(\mu)} < l + \frac{\epsilon}{2} \implies l - \frac{\epsilon}{2} \leq \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)} \leq l + \frac{\epsilon}{2}$$ $$\therefore l - \epsilon < \frac{f(y)}{g(y)} < l + \epsilon .$$ We have therefore furnished $M : |\frac{f(x)}{g(x)} - l| < \epsilon$ if $x > M$. This proves the theorem. I now feel a sudden urge to begin overusing l'Hôpital! Someone, please tell me if this is correct, so I can go at it.","This question already has answers here : Understanding the Proof of L'Hopital's Rule (2 answers) Closed 4 years ago . I've never worked out the general proof of l'Hôpital before, and am taking the opportunity to do so before I return to the soul-crushing grind of college life. I looked in Spivak and found a fine proof of the $(x \rightarrow a$ and $f(x), g(x) \rightarrow 0)$ case; but when he went to prove the $(x \rightarrow \infty, f(x), g(x) \rightarrow 0)$ case, he made a suggestion which actually does not work. (He proposed applying l'Hôpital for the first case above to $f(1/x) / g(1/x)$ as $x \rightarrow 0$, but since he used the fact that $f(0)$ and $g(0)$ could be defined to prove the first case, his version doesn't seem to apply. Correct me if I'm wrong!) I adapted this proof of the second case. Theorem : Suppose that $\lim_{x \to \infty} f(x), \lim_{x \to \infty} g(x) = 0$, and $\lim_{x \to \infty} \frac{f'(x)}{g'(x)} = l$. Then $ \lim_{x \to \infty} \frac{f(x)}{g(x)} = l.$ Proof : Note as a lemma that there exists an interval $I = (c, \infty)$ on which $g'(x) \neq 0$ $g(x) \neq 0$ (The hypothesis implies (1); to prove (2), note that every interval $(\eta, \infty)$ would otherwise have $g(\xi) = 0$, so taking any $\eta ' > \eta$, there would be $g'(x) = 0$ on $(\xi, \xi ')$, and thus on $(\eta, \infty)$, against (1).) Fix $\epsilon > 0$. By hypothesis, $\exists M: x > M \implies |\frac{f'(x)}{g'(x)} - l| <  \frac{\epsilon}{2}$. If $M < c$, choose $M = c$ so $M \in I$. Now pick any $y > M$. By Cauchy, $\forall x > y$ we get $($for $\mu \in (y, x))$ $$\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f'(\mu)}{g'(\mu)}.$$ But if we take $\lim_{x \to \infty}$ of both sides, we find $$\lim_{x \to \infty}\frac{f(x) - f(y)}{g(x) - g(y)} = \frac{f(y)}{g(y)} = \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)}. $$ We know that the RHS limit is determinate; we also know that $$ l - \frac{\epsilon}{2} < \frac{f'(\mu)}{g'(\mu)} < l + \frac{\epsilon}{2} \implies l - \frac{\epsilon}{2} \leq \lim_{x \to \infty} \frac{f'(\mu)}{g'(\mu)} \leq l + \frac{\epsilon}{2}$$ $$\therefore l - \epsilon < \frac{f(y)}{g(y)} < l + \epsilon .$$ We have therefore furnished $M : |\frac{f(x)}{g(x)} - l| < \epsilon$ if $x > M$. This proves the theorem. I now feel a sudden urge to begin overusing l'Hôpital! Someone, please tell me if this is correct, so I can go at it.",,"['calculus', 'analysis']"
48,When can you use a triangle to represent trig substitution?,When can you use a triangle to represent trig substitution?,,"I apologize if this seems like a newbie question but it's been really messing with my head. I'm reading about using trig substitution in integration and everyone seems to simply construct a right triangle to get what the trig functions will be (in terms of the original variable). Shouldn't that only work for cases where the angle is acute and positive? What about the cases where the angle is obtuse or where some trig functions might be negative. As far as I know, using the right triangle will always give a positive cos/sin/tan (because sides are always positive). Can you please explain in as much detail as possible how to correctly use a right triangle in cases where the angle is obtuse or one of the trig functions is negative. Thanks a lot in advance.","I apologize if this seems like a newbie question but it's been really messing with my head. I'm reading about using trig substitution in integration and everyone seems to simply construct a right triangle to get what the trig functions will be (in terms of the original variable). Shouldn't that only work for cases where the angle is acute and positive? What about the cases where the angle is obtuse or where some trig functions might be negative. As far as I know, using the right triangle will always give a positive cos/sin/tan (because sides are always positive). Can you please explain in as much detail as possible how to correctly use a right triangle in cases where the angle is obtuse or one of the trig functions is negative. Thanks a lot in advance.",,"['calculus', 'trigonometry']"
49,Integrating $\int_0^{\infty} \frac{e^{\cos(ax)}\cdot \sin(\sin(ax))}{x^2+1} dx$,Integrating,\int_0^{\infty} \frac{e^{\cos(ax)}\cdot \sin(\sin(ax))}{x^2+1} dx,"I am trying to compute the family of integrals: $$\int_0^{\infty} \frac{e^{\cos(ax)}\cdot \cos(\sin(ax))}{x^2+1} dx$$ and $$\int_0^{\infty} \frac{e^{\cos(ax)}\cdot \sin(\sin(ax))}{x^2+1} dx$$ for positive real $a$ I started by defining $$ C(a) = \int_0^{\infty} \frac{e^{cos(ax)} \cdot \cos(\sin(ax))}{x^2+1}dx$$ and $$ S(a) = \int_0^{\infty} \frac{e^{\cos(ax)} \cdot \sin(\sin(ax))}{x^2+1}dx$$ Then $$ C(a) + iS(a) = \int_0^{\infty} \frac{(e^{\cos(ax)}) \cdot (e^{i\sin(ax)})}{x^2+1}dx$$ $$ = \int_0^{\infty} \frac{e^{e^{iax}}}{x^2+1} dx$$ $$ C(a) + iS(a) = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{(e^{iax})^n}{n!} dx = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{(\cos(nax) + i\sin(nax))}{n!} dx $$ This implies that $$ C(a) = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{\cos(nax)}{n!} dx$$ Swapping the summation and integral signs, we get $$ C(a) = \sum_{n=0}^{\infty} \frac{1}{n!}\cdot \int_0^{\infty} \frac{\cos(nax)}{x^2+1} dx $$ The integral inside has a really nice closed form: $$\int_0^{\infty} \frac{\cos(ax)}{x^2+1} = \frac{\pi}{2} \cdot e^{-a}$$ From that, we obtain a satisfying result for $C(a)$ : $$ C(a) = \sum_{n=0}^{\infty} \frac{\pi}{2} \cdot \frac{e^{-na}}{n!} = \frac{\pi}{2} \cdot e^{e^{-a}}$$ But I could not evaluate a closed form for $S(a)$ , which is given by: $$S(a) = \sum_{n=0}^{\infty} \frac{1}{n!} \cdot \int_0^{\infty} \frac{\sin(nax)}{x^2+1} dx$$ This integral inside the sum should converge, by Dirichlet's test for convergence. We can also establish the absolute convergence of the integral with certainty since the absolute value of $\sin(x)$ never exceeds 1. Can someone provide any methods to evaluate this integral's closed form? Also, I doubt whether even obtaining a closed form for the inner integral will be enough - after all, we also have to take the sum of the expression multiplied by $\frac{1}{n!}$ over all $n>0$ . Any help is appreciated. Thanks for reading!","I am trying to compute the family of integrals: and for positive real I started by defining and Then This implies that Swapping the summation and integral signs, we get The integral inside has a really nice closed form: From that, we obtain a satisfying result for : But I could not evaluate a closed form for , which is given by: This integral inside the sum should converge, by Dirichlet's test for convergence. We can also establish the absolute convergence of the integral with certainty since the absolute value of never exceeds 1. Can someone provide any methods to evaluate this integral's closed form? Also, I doubt whether even obtaining a closed form for the inner integral will be enough - after all, we also have to take the sum of the expression multiplied by over all . Any help is appreciated. Thanks for reading!",\int_0^{\infty} \frac{e^{\cos(ax)}\cdot \cos(\sin(ax))}{x^2+1} dx \int_0^{\infty} \frac{e^{\cos(ax)}\cdot \sin(\sin(ax))}{x^2+1} dx a  C(a) = \int_0^{\infty} \frac{e^{cos(ax)} \cdot \cos(\sin(ax))}{x^2+1}dx  S(a) = \int_0^{\infty} \frac{e^{\cos(ax)} \cdot \sin(\sin(ax))}{x^2+1}dx  C(a) + iS(a) = \int_0^{\infty} \frac{(e^{\cos(ax)}) \cdot (e^{i\sin(ax)})}{x^2+1}dx  = \int_0^{\infty} \frac{e^{e^{iax}}}{x^2+1} dx  C(a) + iS(a) = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{(e^{iax})^n}{n!} dx = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{(\cos(nax) + i\sin(nax))}{n!} dx   C(a) = \int_0^{\infty} \frac{1}{x^2+1} \cdot \sum_{n=0}^{\infty} \frac{\cos(nax)}{n!} dx  C(a) = \sum_{n=0}^{\infty} \frac{1}{n!}\cdot \int_0^{\infty} \frac{\cos(nax)}{x^2+1} dx  \int_0^{\infty} \frac{\cos(ax)}{x^2+1} = \frac{\pi}{2} \cdot e^{-a} C(a)  C(a) = \sum_{n=0}^{\infty} \frac{\pi}{2} \cdot \frac{e^{-na}}{n!} = \frac{\pi}{2} \cdot e^{e^{-a}} S(a) S(a) = \sum_{n=0}^{\infty} \frac{1}{n!} \cdot \int_0^{\infty} \frac{\sin(nax)}{x^2+1} dx \sin(x) \frac{1}{n!} n>0,['calculus']
50,What does the second antiderivative of a function represent?,What does the second antiderivative of a function represent?,,If the antiderivative represents the area under the curve from $f(0)$ to $f(x)$ what does the second antiderivative or the antiderivative of the antiderivative represent?,If the antiderivative represents the area under the curve from $f(0)$ to $f(x)$ what does the second antiderivative or the antiderivative of the antiderivative represent?,,['calculus']
51,Has the age at which we teach Mathematics changed over the last two centuries?,Has the age at which we teach Mathematics changed over the last two centuries?,,"My experience of learning Advanced Trigonometry and Calculus is that it was done to 17 and 18 year olds (School Curriculum in Australia). I assumed that it was similar in the UK, US and Europe. In the book Master and Commander we see the main character Jack Albury tell of his childhood learning mathematics. It appears he learned Cotangents and Integration at age 12. Now I'm not saying this is not possible, and that there are probably 12-year-olds out there with untapped potential. I'm trying to understand what Mathematics would have been taught at this point in time (to sailors for navigation). Is it likely that they learned a rote formula for navigation, and understanding the stresses on a ship, or would they have learned first-principles? Now this novel is set in the period of English History [1800-1815] and is generally regarded to be meticulously researched historical fiction . My question is: Has the age at which we teach Mathematics changed over the last two centuries?","My experience of learning Advanced Trigonometry and Calculus is that it was done to 17 and 18 year olds (School Curriculum in Australia). I assumed that it was similar in the UK, US and Europe. In the book Master and Commander we see the main character Jack Albury tell of his childhood learning mathematics. It appears he learned Cotangents and Integration at age 12. Now I'm not saying this is not possible, and that there are probably 12-year-olds out there with untapped potential. I'm trying to understand what Mathematics would have been taught at this point in time (to sailors for navigation). Is it likely that they learned a rote formula for navigation, and understanding the stresses on a ship, or would they have learned first-principles? Now this novel is set in the period of English History [1800-1815] and is generally regarded to be meticulously researched historical fiction . My question is: Has the age at which we teach Mathematics changed over the last two centuries?",,"['calculus', 'trigonometry', 'soft-question', 'education']"
52,How to find probability distribution function given the Moment Generating Function,How to find probability distribution function given the Moment Generating Function,,"After searching, I found two questions like mine, but didn't see my answer to my question. Finding a probability distribution given the moment generating function Finding probability using moment-generating functions My question is how to find any probability distribution function, given its moment generating function. In particular, how to find this from First Principles (and not memorizing a table). Let's try an example: Let $ X \perp Y$.  Define the moment generating functions for $X, Y$   respectively as $$M_X(t)=\exp(2e^t-2), M_Y(t)=\left(\frac{3}{4}e^t+ \frac{1}{4}\right)^{10}$$    Find $P(X+Y = 2)$. First, the problem doesn't tell us whether the distributions are continuous or discrete, so I assume continuous. Now, how do we solve the following for $f_X(x)$? $$M_X(t)= \int_{-\infty}^{\infty}e^{xt} f_X(x) \ dx = \exp ( 2\ e^t - 2)\tag{1}$$ Next, can we take the derivative with respect to $x$ to both sides, to bring us closer to the solution $f_X(x)$? I read that a m.g.f. $m_X(t)$ is characteristic to and unique to the  distribution of $X$. I saw something about Laplace Transforms in another question, but we have learned nothing of that sort in this course.","After searching, I found two questions like mine, but didn't see my answer to my question. Finding a probability distribution given the moment generating function Finding probability using moment-generating functions My question is how to find any probability distribution function, given its moment generating function. In particular, how to find this from First Principles (and not memorizing a table). Let's try an example: Let $ X \perp Y$.  Define the moment generating functions for $X, Y$   respectively as $$M_X(t)=\exp(2e^t-2), M_Y(t)=\left(\frac{3}{4}e^t+ \frac{1}{4}\right)^{10}$$    Find $P(X+Y = 2)$. First, the problem doesn't tell us whether the distributions are continuous or discrete, so I assume continuous. Now, how do we solve the following for $f_X(x)$? $$M_X(t)= \int_{-\infty}^{\infty}e^{xt} f_X(x) \ dx = \exp ( 2\ e^t - 2)\tag{1}$$ Next, can we take the derivative with respect to $x$ to both sides, to bring us closer to the solution $f_X(x)$? I read that a m.g.f. $m_X(t)$ is characteristic to and unique to the  distribution of $X$. I saw something about Laplace Transforms in another question, but we have learned nothing of that sort in this course.",,"['calculus', 'probability-theory', 'moment-generating-functions']"
53,Why do you need to use the chain rule in differentiation of ln?,Why do you need to use the chain rule in differentiation of ln?,,"I understand application of chain rule in the differentiation of a random function $(x^2+3)^3$. But, why do you need to use chain-rule when differentiating something like $\ln(2x-1)$; why won't it just be $\displaystyle\frac 1{2x-1}$? Please help.","I understand application of chain rule in the differentiation of a random function $(x^2+3)^3$. But, why do you need to use chain-rule when differentiating something like $\ln(2x-1)$; why won't it just be $\displaystyle\frac 1{2x-1}$? Please help.",,"['calculus', 'derivatives']"
54,Is there a better way to find the closest point on a line?,Is there a better way to find the closest point on a line?,,"I'm given a question that asks: ""Find the point on $L(x) = 4x-3$ that is closest to the point $(1,3)$."" My best guess was to find the derivative of the distances and set it equal to zero and solve to attempt to find a minimum. I come up with the derivative being$$f'(x)=\frac{1}{2}(17x^2-50x+37)^{-\frac{1}{2}}(34x-50)$$  And solving for x I end up with $50/34$ or about 1.4705. Now all I have to do is just plug that into the original linear equation. And when I graphed it out in desmos that appears to solve the problem correctly. My only issue is that my solution doesn't account for if there was a maximum instead of a minimum on the distance equation. Is there a more correct solution to this problem?","I'm given a question that asks: ""Find the point on $L(x) = 4x-3$ that is closest to the point $(1,3)$."" My best guess was to find the derivative of the distances and set it equal to zero and solve to attempt to find a minimum. I come up with the derivative being$$f'(x)=\frac{1}{2}(17x^2-50x+37)^{-\frac{1}{2}}(34x-50)$$  And solving for x I end up with $50/34$ or about 1.4705. Now all I have to do is just plug that into the original linear equation. And when I graphed it out in desmos that appears to solve the problem correctly. My only issue is that my solution doesn't account for if there was a maximum instead of a minimum on the distance equation. Is there a more correct solution to this problem?",,"['calculus', 'derivatives', 'optimization']"
55,Evaluating the derivative of $\large \;e^{e^x}$? [closed],Evaluating the derivative of ? [closed],\large \;e^{e^x},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I know that the derivative of $\,e^x\,$ is $\,e^x$. But how do I evaluate $\dfrac{d}{dx}{\large\left(e^{e^x}\right)}\,$?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I know that the derivative of $\,e^x\,$ is $\,e^x$. But how do I evaluate $\dfrac{d}{dx}{\large\left(e^{e^x}\right)}\,$?",,"['calculus', 'derivatives']"
56,Can I Square Root A Series?,Can I Square Root A Series?,,"I have a question in Quantum Mechanics where I need to solve a series, and the thing is that I can get the answer to a similar series with the help of the same problem but I am not sure if I can square root my series to use it in the problem. For example I have $$\sum_{n=1,3,5,7...}^{\infty} \frac{1}{n^4} = \frac{\pi^4}{96}$$. But the summation I need is for $\style{Bold}{\frac{1}{n^2}}$ So is it fine to square root both sides and say $$\sum_{n=1,3,5,7...}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{\sqrt{96}}$$","I have a question in Quantum Mechanics where I need to solve a series, and the thing is that I can get the answer to a similar series with the help of the same problem but I am not sure if I can square root my series to use it in the problem. For example I have $$\sum_{n=1,3,5,7...}^{\infty} \frac{1}{n^4} = \frac{\pi^4}{96}$$. But the summation I need is for $\style{Bold}{\frac{1}{n^2}}$ So is it fine to square root both sides and say $$\sum_{n=1,3,5,7...}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{\sqrt{96}}$$",,"['calculus', 'sequences-and-series']"
57,What concepts were most difficult for you to understand in Calculus? [closed],What concepts were most difficult for you to understand in Calculus? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I'm developing some instructional material for a Calculus 1 class and I wanted to know from experience for yourself, tutoring others, and/or helping people on this site where is the most difficulty in Calculus? If you had any good methods of helping people that would be very helpful.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I'm developing some instructional material for a Calculus 1 class and I wanted to know from experience for yourself, tutoring others, and/or helping people on this site where is the most difficulty in Calculus? If you had any good methods of helping people that would be very helpful.",,"['calculus', 'soft-question']"
58,Are the any non-trivial functions where $f(x)=f'(x)$ not of the form $Ae^x$,Are the any non-trivial functions where  not of the form,f(x)=f'(x) Ae^x,"This may seem like a silly question, but I just wanted to check. I know there are proofs that if $f(x)=f'(x)$ then $f(x)=Ae^x$. But can we 'invent' another function that obeys $f(x)=f'(x)$ which is non-trivial ?","This may seem like a silly question, but I just wanted to check. I know there are proofs that if $f(x)=f'(x)$ then $f(x)=Ae^x$. But can we 'invent' another function that obeys $f(x)=f'(x)$ which is non-trivial ?",,"['calculus', 'ordinary-differential-equations', 'derivatives', 'exponential-function']"
59,Solving limit without L'Hôpital,Solving limit without L'Hôpital,,I need to solve this limit without L'Hôpital's rule. These questions always seem to have some algebraic trick which I just can't see this time. $$ \lim_{x\to0} \frac{5-\sqrt{x+25}}{x}$$ Could someone give me a hint as to what I need to do to the fraction to make this work? Thanks!,I need to solve this limit without L'Hôpital's rule. These questions always seem to have some algebraic trick which I just can't see this time. $$ \lim_{x\to0} \frac{5-\sqrt{x+25}}{x}$$ Could someone give me a hint as to what I need to do to the fraction to make this work? Thanks!,,"['calculus', 'limits', 'limits-without-lhopital']"
60,Can one differentiate an infinite sum?,Can one differentiate an infinite sum?,,"Suppose we have $|x|<1$, then $$1+x+x^2+...=(1-x)^{-1}$$ Differentiating both parts we get $$1+2x+3x^2+...=(1-x)^{-2}$$ If yes, then how one can prove that? What about integrating both parts? What if sum diverges?","Suppose we have $|x|<1$, then $$1+x+x^2+...=(1-x)^{-1}$$ Differentiating both parts we get $$1+2x+3x^2+...=(1-x)^{-2}$$ If yes, then how one can prove that? What about integrating both parts? What if sum diverges?",,"['calculus', 'sequences-and-series']"
61,Why the existence of Taylor series doesn't imply it coverges to the original function,Why the existence of Taylor series doesn't imply it coverges to the original function,,"Please note that I've read this question and it did not address mine. I've been presented with the following argument regarding Taylor series: We have a function $f(x)$, now assume that there exists a power series that's equal to it: $$f(x)=a_0 + a_1 x + a_2 x^2 +\dots$$ One can quickly show, using differentiation, that $$f(x) =f(0) + f'(0) x + \dfrac{f''(0)}{2! }x^2 +\dots$$ It seems that this argument implies two things: For the Taylor series around a point to exist, it has to be   continuously differentiable (infinitely many times) and defined at   that point. If the Taylor series for a function exists, then this implies   it's equal to it, or that it converges to the original function at   every point $x$. Now I know very well that point 2 is false (not every smooth function is analytic). But point 2 seems to be implied from the argument I presented above which assumes that if a power series exists such that it's equal to the function or in other words, converges to the function for all $x$, then it will be given by the Taylor series. So what's wrong regarding this argument above?","Please note that I've read this question and it did not address mine. I've been presented with the following argument regarding Taylor series: We have a function $f(x)$, now assume that there exists a power series that's equal to it: $$f(x)=a_0 + a_1 x + a_2 x^2 +\dots$$ One can quickly show, using differentiation, that $$f(x) =f(0) + f'(0) x + \dfrac{f''(0)}{2! }x^2 +\dots$$ It seems that this argument implies two things: For the Taylor series around a point to exist, it has to be   continuously differentiable (infinitely many times) and defined at   that point. If the Taylor series for a function exists, then this implies   it's equal to it, or that it converges to the original function at   every point $x$. Now I know very well that point 2 is false (not every smooth function is analytic). But point 2 seems to be implied from the argument I presented above which assumes that if a power series exists such that it's equal to the function or in other words, converges to the function for all $x$, then it will be given by the Taylor series. So what's wrong regarding this argument above?",,"['calculus', 'taylor-expansion']"
62,Without calculator prove that $9^{\sqrt{2}} < \sqrt{2}^9$,Without calculator prove that,9^{\sqrt{2}} < \sqrt{2}^9,Without calculator prove that $9^{\sqrt{2}} < \sqrt{2}^9$ . My effort: I tried using the fact $9^{\sqrt{2}}<9^{1.5}=27.$ Also We have $512 <729 \Rightarrow 2^9<27^2 \Rightarrow 2^{\frac{9}{2}}<27 \Rightarrow \sqrt{2}^9=2^{4.5}<27$ . But both are below $27$ .,Without calculator prove that . My effort: I tried using the fact Also We have . But both are below .,9^{\sqrt{2}} < \sqrt{2}^9 9^{\sqrt{2}}<9^{1.5}=27. 512 <729 \Rightarrow 2^9<27^2 \Rightarrow 2^{\frac{9}{2}}<27 \Rightarrow \sqrt{2}^9=2^{4.5}<27 27,"['calculus', 'algebra-precalculus', 'inequality', 'number-comparison']"
63,"Evaluating the integral $\int_0^{\infty} \frac{\sin(x)}{\sinh(x)}\,dx$",Evaluating the integral,"\int_0^{\infty} \frac{\sin(x)}{\sinh(x)}\,dx","I was trying to evaluate the following integral,  $$I=\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{\sinh(x)}\,dx$$  but had no success. I first expanded the the hyperbolic sine: $$I=2\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{e^{x}-e^{-x}}\,dx=2\Im \int_\limits {-\infty}^{\infty} \dfrac{e^{ix}}{e^{x}-e^{-x}}\,dx$$ I then substituted $u=e^x$, $$I=2\Im\int_\limits {0}^{\infty} \dfrac{u^i}{u^2-1}\,du$$ Now, I'm not really sure what to do. Also, after exchanging the $\Im$ with the integral seemed to create a non-integrable singularity at $u=1$. When can you not do that?","I was trying to evaluate the following integral,  $$I=\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{\sinh(x)}\,dx$$  but had no success. I first expanded the the hyperbolic sine: $$I=2\int_\limits {-\infty}^{\infty} \dfrac{\sin(x)}{e^{x}-e^{-x}}\,dx=2\Im \int_\limits {-\infty}^{\infty} \dfrac{e^{ix}}{e^{x}-e^{-x}}\,dx$$ I then substituted $u=e^x$, $$I=2\Im\int_\limits {0}^{\infty} \dfrac{u^i}{u^2-1}\,du$$ Now, I'm not really sure what to do. Also, after exchanging the $\Im$ with the integral seemed to create a non-integrable singularity at $u=1$. When can you not do that?",,"['calculus', 'integration', 'improper-integrals']"
64,Does $\lim \frac {a_n}{b_n}=1$ imply $\lim \frac {f(a_n)}{f(b_n)}=1$?,Does  imply ?,\lim \frac {a_n}{b_n}=1 \lim \frac {f(a_n)}{f(b_n)}=1,I wanted to prove the seemingly simple statement: If $\lim \frac {a_n}{b_n}=1$ and $f$ continuous with $f(b_n)\neq0$ then $\lim \frac {f(a_n)}{f(b_n)}=1.$ I started promptly with \begin{align}  \\ \lim \frac {f(a_n)}{f(b_n)} &= \lim \frac { f(b_n \times \frac{a_n}{b_n})}{f(b_n)} \\  &= \frac { f(b_n \times \lim\frac{a_n}{b_n})}{f(b_n)} \\  &= \frac { f(b_n \times 1)}{f(b_n)} \\  &= 1 \end{align} Yet two seconds later I realized what a nonsense it was and that I fell victim of one of the freshman's dreams. I would greatly appreciate a hint for a proof or a counterexample if the statement turns out to be false.,I wanted to prove the seemingly simple statement: If $\lim \frac {a_n}{b_n}=1$ and $f$ continuous with $f(b_n)\neq0$ then $\lim \frac {f(a_n)}{f(b_n)}=1.$ I started promptly with \begin{align}  \\ \lim \frac {f(a_n)}{f(b_n)} &= \lim \frac { f(b_n \times \frac{a_n}{b_n})}{f(b_n)} \\  &= \frac { f(b_n \times \lim\frac{a_n}{b_n})}{f(b_n)} \\  &= \frac { f(b_n \times 1)}{f(b_n)} \\  &= 1 \end{align} Yet two seconds later I realized what a nonsense it was and that I fell victim of one of the freshman's dreams. I would greatly appreciate a hint for a proof or a counterexample if the statement turns out to be false.,,"['calculus', 'sequences-and-series', 'limits', 'fake-proofs']"
65,How to prove $\exp(x)/(\exp(x)+1)^2$ is even?,How to prove  is even?,\exp(x)/(\exp(x)+1)^2,"I've spent some time trying to prove that the function: $$f(x)=\frac{\exp x}{(\exp x+1)^2}$$ is even. I tried expanding the different $\exp x$ as power series, but I had a very difficult time trying to track the different indices. Is that the correct way to proceed or is there some other property that I am no taking into account ? Greetings.","I've spent some time trying to prove that the function: $$f(x)=\frac{\exp x}{(\exp x+1)^2}$$ is even. I tried expanding the different $\exp x$ as power series, but I had a very difficult time trying to track the different indices. Is that the correct way to proceed or is there some other property that I am no taking into account ? Greetings.",,"['calculus', 'functions']"
66,Why is $\int^\infty_{-\infty} \frac{x}{x^2+1} dx$ not zero?,Why is  not zero?,\int^\infty_{-\infty} \frac{x}{x^2+1} dx,"We break up $\int^\infty_{-\infty} \dfrac{x}{x^2+1} dx$ into: $$\lim_{t\to -\infty} \int^0_t \dfrac{x}{x^2+1} dx + \lim_{t\to \infty} \int^t_0 \dfrac{x}{x^2+1} dx$$ So, evaluated, this gives; $$\lim_{t \to \infty} \left(\frac{1}{2} \ln (1+t^2)\right) - \lim_{t \to -\infty} \left(\frac{1}{2} \ln (1+t^2)\right)$$ But those two terms are essentially identical! It should be zero!  Plus, the integrand is an odd function, so why is this undefined?  Is it just an unspoken rule that once you encounter $\infty$ in a mathematical expression you should stop evaluating immediately?","We break up $\int^\infty_{-\infty} \dfrac{x}{x^2+1} dx$ into: $$\lim_{t\to -\infty} \int^0_t \dfrac{x}{x^2+1} dx + \lim_{t\to \infty} \int^t_0 \dfrac{x}{x^2+1} dx$$ So, evaluated, this gives; $$\lim_{t \to \infty} \left(\frac{1}{2} \ln (1+t^2)\right) - \lim_{t \to -\infty} \left(\frac{1}{2} \ln (1+t^2)\right)$$ But those two terms are essentially identical! It should be zero!  Plus, the integrand is an odd function, so why is this undefined?  Is it just an unspoken rule that once you encounter $\infty$ in a mathematical expression you should stop evaluating immediately?",,"['calculus', 'integration']"
67,"Calculus II Professor will not accept my correct integral evaluation that uses a different method, should I bring this up further?","Calculus II Professor will not accept my correct integral evaluation that uses a different method, should I bring this up further?",,"I am a freshman enrolled at an American University. Recently, I took an examination in which the following problem appeared: Evaluate the following integral: $\int_0^4\sqrt{16-x^2}dx$ My answer: 4 $\pi$ , was correct. However, I received reduced credit for this answer because I did not solve it correctly (according to the professor). The exams are time-limited and have a fair amount of content, so when I saw this problem, I noticed it was the equation of the top half of a circle centered at (0, 0) and with radius 4. Knowing this, and my knowledge of the integral indicating the signed area under a curve, I merely took the area of a quarter-circle of radius 4, $\frac{1}{4}$$\pi$$r^2$ and wrote my answer of 4 $\pi$ . The context of the test was surrounding our unit on inverse trigonometry and integration by parts. This section of the test did not list any other instructions besides evaluating the definite integrals. I've talked to my professor about it and his only response was that I solved it wrong: To receive full credit, you would have had to evaluate an integral, as the instructions indicated. Is my interpretation of evaluating the integral different? Does the instruction ""Find the antiderivative and then evaluate"" not need to exist for that to be required? Thank you.","I am a freshman enrolled at an American University. Recently, I took an examination in which the following problem appeared: Evaluate the following integral: My answer: 4 , was correct. However, I received reduced credit for this answer because I did not solve it correctly (according to the professor). The exams are time-limited and have a fair amount of content, so when I saw this problem, I noticed it was the equation of the top half of a circle centered at (0, 0) and with radius 4. Knowing this, and my knowledge of the integral indicating the signed area under a curve, I merely took the area of a quarter-circle of radius 4, and wrote my answer of 4 . The context of the test was surrounding our unit on inverse trigonometry and integration by parts. This section of the test did not list any other instructions besides evaluating the definite integrals. I've talked to my professor about it and his only response was that I solved it wrong: To receive full credit, you would have had to evaluate an integral, as the instructions indicated. Is my interpretation of evaluating the integral different? Does the instruction ""Find the antiderivative and then evaluate"" not need to exist for that to be required? Thank you.",\int_0^4\sqrt{16-x^2}dx \pi \frac{1}{4}\pir^2 \pi,"['calculus', 'integration']"
68,Integral $\int_0^{2π} e^{e^{ix}} dx$,Integral,\int_0^{2π} e^{e^{ix}} dx,"Work out  the integral $$\int_0^{2π}  e^{\large e^{ix}} \, dx.$$ I am now stuck with this for $2$ days, so please help! Here is my try: $$I=\int_0^{2π}  e^{\large e^{ix}} dx=\int_0^{2\pi}  e^{\large{\cos x+i\sin x}}dx$$ $$=\int_0^{2\pi}e^{cos x}\left(\cos(\sin x) +i\sin(\sin x)\right) dx$$ $$\overset{\large2\pi -x \rightarrow x}=\int_0^{2\pi} e^{\cos x} \left(\cos (\sin  x)+i\sin(\sin(2\pi- x)\right)dx$$ $$\Rightarrow 2I=\int_0^{2\pi} e^{{\cos x}} \cdot 2\cos (\sin x)dx$$ $$\text{as}\ \sin(2\pi -x )=-\sin x$$ $$\Rightarrow I=\int_0^{2\pi} e^{\cos x}\cos (\sin x)dx$$ $$=\int_0^{2\pi} \left(e^{\cos x}\cos (\sin x)+e^{\cos (\pi-x)}\cos (\sin x)\right)dx$$ $$=\int_0^{\pi} 2 \left(\frac{e^{\cos x}+e^{-\cos x}}{2}\right)\cos(\sin x)dx$$ $$=2\int_0^\pi \operatorname{cosh}(\cos x)\cos(\sin x)dx $$","Work out  the integral I am now stuck with this for days, so please help! Here is my try:","\int_0^{2π}  e^{\large e^{ix}} \, dx. 2 I=\int_0^{2π}  e^{\large e^{ix}} dx=\int_0^{2\pi}  e^{\large{\cos x+i\sin x}}dx =\int_0^{2\pi}e^{cos x}\left(\cos(\sin x) +i\sin(\sin x)\right) dx \overset{\large2\pi -x \rightarrow x}=\int_0^{2\pi} e^{\cos x} \left(\cos (\sin  x)+i\sin(\sin(2\pi- x)\right)dx \Rightarrow 2I=\int_0^{2\pi} e^{{\cos x}} \cdot 2\cos (\sin x)dx \text{as}\ \sin(2\pi -x )=-\sin x \Rightarrow I=\int_0^{2\pi} e^{\cos x}\cos (\sin x)dx =\int_0^{2\pi} \left(e^{\cos x}\cos (\sin x)+e^{\cos (\pi-x)}\cos (\sin x)\right)dx =\int_0^{\pi} 2 \left(\frac{e^{\cos x}+e^{-\cos x}}{2}\right)\cos(\sin x)dx =2\int_0^\pi \operatorname{cosh}(\cos x)\cos(\sin x)dx ","['calculus', 'integration', 'definite-integrals']"
69,Frullani like Trig integral,Frullani like Trig integral,,$$\int_{0}^{\infty}\frac{\left|\cos\left ( x-\frac{\pi}{4} \right ) \right|- \left|\cos\left ( x+\frac{\pi}{4} \right ) \right| }{x}dx=\sqrt{2}\ln(1+\sqrt{2})$$ The above integral seems to look like a frullani type integral and has a closed form in terms of natural log. I tried to indefinitely integrate it. But the closed form are in terms $\text{Si}(x)$ and $\text{Ci}(x)$ . I would highly  appreciate if there's any method or unique  substitution  to evaluate  this Integral.,The above integral seems to look like a frullani type integral and has a closed form in terms of natural log. I tried to indefinitely integrate it. But the closed form are in terms and . I would highly  appreciate if there's any method or unique  substitution  to evaluate  this Integral.,\int_{0}^{\infty}\frac{\left|\cos\left ( x-\frac{\pi}{4} \right ) \right|- \left|\cos\left ( x+\frac{\pi}{4} \right ) \right| }{x}dx=\sqrt{2}\ln(1+\sqrt{2}) \text{Si}(x) \text{Ci}(x),"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
70,How do I find roots of a single-variate polynomials whose integers coefficients are symmetric wrt their respective powers,How do I find roots of a single-variate polynomials whose integers coefficients are symmetric wrt their respective powers,,"Given a polynomial such as $X^4 + 4X^3 + 6X^2 + 4X + 1,$ where the coefficients are symmetrical, I know there's a trick to quickly find the zeros. Could someone please refresh my memory?","Given a polynomial such as $X^4 + 4X^3 + 6X^2 + 4X + 1,$ where the coefficients are symmetrical, I know there's a trick to quickly find the zeros. Could someone please refresh my memory?",,"['calculus', 'polynomials']"
71,How do I evaluate $\int \frac {x+4}{ 2x+6 } dx $?,How do I evaluate ?,\int \frac {x+4}{ 2x+6 } dx ,"$$\int  \frac {x+4}{ 2x+6 } dx$$ This is a problem from Khan Academy that I was reading about how to solve when I accidentally clicked next and lost the explanation. I was reading something about how there is a clever way to divide the function to make it easier to integrate. Can someone please explain this to me? No actual solution, please. I want to get it by myself.","$$\int  \frac {x+4}{ 2x+6 } dx$$ This is a problem from Khan Academy that I was reading about how to solve when I accidentally clicked next and lost the explanation. I was reading something about how there is a clever way to divide the function to make it easier to integrate. Can someone please explain this to me? No actual solution, please. I want to get it by myself.",,"['calculus', 'integration', 'indefinite-integrals', 'partial-fractions']"
72,How to evaluate $\int\frac{1+x^4}{(1-x^4)^{3/2}}dx$?,How to evaluate ?,\int\frac{1+x^4}{(1-x^4)^{3/2}}dx,How do I start with evaluating this- $$\int\frac{1+x^4}{(1-x^4)^{3/2}}dx$$ What should be my first attempt at this kind of a problem where- The denominator and numerator are of the same degree Denominator involves fractional exponent like $3/2$. Note:I am proficient with all kinds of basic methods of evaluating integrals.,How do I start with evaluating this- $$\int\frac{1+x^4}{(1-x^4)^{3/2}}dx$$ What should be my first attempt at this kind of a problem where- The denominator and numerator are of the same degree Denominator involves fractional exponent like $3/2$. Note:I am proficient with all kinds of basic methods of evaluating integrals.,,"['calculus', 'integration', 'indefinite-integrals']"
73,Limits and algebraic simplification,Limits and algebraic simplification,,"Please let me know what is wrong in the following algebraic simplification which gives a wrong limit value. $$\lim_{x \to \infty} (\sqrt {x^2 - 4x} - x)=\lim_{x \to \infty} (\sqrt {x^2 (1 - 4/x)} - x) $$ $$= \lim_{x \to \infty} (x\sqrt {1 - 4/x} - x)= \lim_{x \to \infty} x(\sqrt {1 - 4/x} - 1) $$ When $x$ tends to infinity, $4/x$ will be negligible and hence $$= \lim_{x \to \infty} x(\sqrt {1 - 0} - 1)=\lim_{x \to \infty} x(1 - 1)=0 $$","Please let me know what is wrong in the following algebraic simplification which gives a wrong limit value. $$\lim_{x \to \infty} (\sqrt {x^2 - 4x} - x)=\lim_{x \to \infty} (\sqrt {x^2 (1 - 4/x)} - x) $$ $$= \lim_{x \to \infty} (x\sqrt {1 - 4/x} - x)= \lim_{x \to \infty} x(\sqrt {1 - 4/x} - 1) $$ When $x$ tends to infinity, $4/x$ will be negligible and hence $$= \lim_{x \to \infty} x(\sqrt {1 - 0} - 1)=\lim_{x \to \infty} x(1 - 1)=0 $$",,"['calculus', 'limits', 'infinity']"
74,"Finding $\lim_{n\to \infty}\sqrt n \int_0^1 \frac{\,dx}{(1+x^2)^n}$",Finding,"\lim_{n\to \infty}\sqrt n \int_0^1 \frac{\,dx}{(1+x^2)^n}",$$  \lim_{n\to\infty} n^{1/2} \int_{0}^{1} \frac{1}{(1+x^2)^n}\mathrm{d}x=0 $$ Is my answer correct? But I am not sure of method by which I have done.,Is my answer correct? But I am not sure of method by which I have done.," 
\lim_{n\to\infty} n^{1/2}
\int_{0}^{1} \frac{1}{(1+x^2)^n}\mathrm{d}x=0
","['calculus', 'integration', 'limits']"
75,What is the difference between necessary condition & sufficient condition?,What is the difference between necessary condition & sufficient condition?,,"My book says : For having extreme point $a$ of function $f$, the necessary condition is that $f'(a) = 0$. However, it isn't a sufficient condition. Now, what is the difference between necessary & sufficient condition? And also what is the sufficient condition for a function to have an extreme point?","My book says : For having extreme point $a$ of function $f$, the necessary condition is that $f'(a) = 0$. However, it isn't a sufficient condition. Now, what is the difference between necessary & sufficient condition? And also what is the sufficient condition for a function to have an extreme point?",,['calculus']
76,Are indefinite integrals unique up to the constant of integration?,Are indefinite integrals unique up to the constant of integration?,,"We often write e.g. $$\int x^2 dx=\tfrac{1}{3}x^3+c$$ for any $c \in \mathbb{R}$, where $c$ is the constant of integration . We can show (via limits) that, if $g(x)=\frac{1}{3}x^3+c$, then $\frac{dg}{dx}=x^2$ for any $c \in \mathbb{R}$.  But this doesn't exclude the possibility that some function $f=f(x)$ that doesn't have the form $\tfrac{1}{3}x^3+c$ also has the derivative $\frac{df}{dx}=x^2$.  So... Q : Are indefinite integrals unique up to the constant of integration?  If so, how do we know?","We often write e.g. $$\int x^2 dx=\tfrac{1}{3}x^3+c$$ for any $c \in \mathbb{R}$, where $c$ is the constant of integration . We can show (via limits) that, if $g(x)=\frac{1}{3}x^3+c$, then $\frac{dg}{dx}=x^2$ for any $c \in \mathbb{R}$.  But this doesn't exclude the possibility that some function $f=f(x)$ that doesn't have the form $\tfrac{1}{3}x^3+c$ also has the derivative $\frac{df}{dx}=x^2$.  So... Q : Are indefinite integrals unique up to the constant of integration?  If so, how do we know?",,"['calculus', 'integration', 'indefinite-integrals']"
77,Evaluating $\int_{-\infty}^\infty\frac1{1+x^2+x^4+\cdots}\ \text{dx}$,Evaluating,\int_{-\infty}^\infty\frac1{1+x^2+x^4+\cdots}\ \text{dx},"I have calculated that $$\begin{align} \int_{-\infty}^\infty\frac1{1+x^2}\ \text{dx}&=\pi \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4}\ \text{dx}&=\frac\pi{\sqrt3} \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4+x^6}\ \text{dx}&=\frac\pi2 \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4+x^6+x^8}\ \text{dx}&=\frac1 5\sqrt{10-2\sqrt5}\ \pi \end{align} $$ And thus I am trying to evaluate $$ \lim_{\mathtt k\rightarrow\infty}\int_{-\infty}^\infty\frac1{1+x^2+\cdots+x^{2\mathtt k}}\ \text{dx} = \lim_{\mathtt k\rightarrow\infty}\int_{-\infty}^\infty\frac1{\sum_{n=0}^\mathtt kx^{2n}}\ \text{dx}=\ ? $$ I intend to post a self-answer to this question, assuming a satisfactory answer is not posted within a few hours.","I have calculated that $$\begin{align} \int_{-\infty}^\infty\frac1{1+x^2}\ \text{dx}&=\pi \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4}\ \text{dx}&=\frac\pi{\sqrt3} \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4+x^6}\ \text{dx}&=\frac\pi2 \\ \int_{-\infty}^\infty\frac1{1+x^2+x^4+x^6+x^8}\ \text{dx}&=\frac1 5\sqrt{10-2\sqrt5}\ \pi \end{align} $$ And thus I am trying to evaluate $$ \lim_{\mathtt k\rightarrow\infty}\int_{-\infty}^\infty\frac1{1+x^2+\cdots+x^{2\mathtt k}}\ \text{dx} = \lim_{\mathtt k\rightarrow\infty}\int_{-\infty}^\infty\frac1{\sum_{n=0}^\mathtt kx^{2n}}\ \text{dx}=\ ? $$ I intend to post a self-answer to this question, assuming a satisfactory answer is not posted within a few hours.",,"['calculus', 'integration', 'sequences-and-series', 'summation']"
78,Shortest path between two points on a surface,Shortest path between two points on a surface,,"Let $S$ be a surface on $\mathbb{R}^3$ defined by equation $f(x,y,z)=0$. Let $\gamma(t)=(x(t),y(t),z(t))$ be a parametric curve on $S$ joining two points $p$ and $q$, that is $\gamma(0)=p$ and $\gamma(T)=q$. How to find the shortest (abstract) curve on S connecting $p$ and $q$? The length $L$ of the curve connecting $p$ and $q$ is given by $$L=\int_0^T \sqrt{x'(t)^2+y'(t)^2+z'(t)^2}\,dt.$$ Without surface $S$ constraint, the curve that minimize $L$ would be a straight line. I don't know how to put the surface constraint into account.","Let $S$ be a surface on $\mathbb{R}^3$ defined by equation $f(x,y,z)=0$. Let $\gamma(t)=(x(t),y(t),z(t))$ be a parametric curve on $S$ joining two points $p$ and $q$, that is $\gamma(0)=p$ and $\gamma(T)=q$. How to find the shortest (abstract) curve on S connecting $p$ and $q$? The length $L$ of the curve connecting $p$ and $q$ is given by $$L=\int_0^T \sqrt{x'(t)^2+y'(t)^2+z'(t)^2}\,dt.$$ Without surface $S$ constraint, the curve that minimize $L$ would be a straight line. I don't know how to put the surface constraint into account.",,"['calculus', 'differential-geometry', 'geodesic']"
79,Show that $\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}?$,Show that,\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}?,How may we show that $$\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}\color{red}?\tag1$$ $u={x\over 2}\implies 2du=dx$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\coth(\pi u)\mathrm du\tag2$$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\cdot{e^{2u}+1\over e^{2u}-1}\mathrm du\tag3$$ $v=4u^2\implies du={dv\over 8u}$ $${1\over 2}\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot{\mathrm dv\over (1+v)^2}\tag4$$ $${1\over 2}\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot v^k \mathrm dv\tag5$$ $e^{\sqrt{v}}=t\implies dv=2\sqrt{v}e^{\sqrt{v}}dt$ $$\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{1}^{\infty}t\cdot{t+1\over t-1}\cdot \ln^{2k+1}(t) \mathrm dt\tag6$$ I don't what to do next ...,How may we show that $$\int_{0}^{\infty}{x\over (1+x^2)^2}\cdot{\mathrm dx\over \tanh\left({\pi x\over 2}\right)}={\pi^2\over 8}-{1\over 2}\color{red}?\tag1$$ $u={x\over 2}\implies 2du=dx$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\coth(\pi u)\mathrm du\tag2$$ $$4\int_{0}^{\infty}{u\over (1+4u^2)^2}\cdot{e^{2u}+1\over e^{2u}-1}\mathrm du\tag3$$ $v=4u^2\implies du={dv\over 8u}$ $${1\over 2}\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot{\mathrm dv\over (1+v)^2}\tag4$$ $${1\over 2}\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{0}^{\infty}{e^{\sqrt{v}}+1\over e^{\sqrt{v}}-1}\cdot v^k \mathrm dv\tag5$$ $e^{\sqrt{v}}=t\implies dv=2\sqrt{v}e^{\sqrt{v}}dt$ $$\sum_{k=0}^{\infty}{(2)_k\over k!}(-1)^k\int_{1}^{\infty}t\cdot{t+1\over t-1}\cdot \ln^{2k+1}(t) \mathrm dt\tag6$$ I don't what to do next ...,,['calculus']
80,Can an ordered field be finite?,Can an ordered field be finite?,,I came across this question in a calculus book. Is it possible to prove that an ordered field must be infinite? Also - does this mean that there is only one such field? Thanks,I came across this question in a calculus book. Is it possible to prove that an ordered field must be infinite? Also - does this mean that there is only one such field? Thanks,,"['calculus', 'abstract-algebra', 'ordered-fields']"
81,Evaluating $\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}$,Evaluating,\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n},"Question: How can we evaluate $$\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n},$$ where $H_n=\frac11+\frac12+\cdots+\frac1n$ ? Quick Results This series converges because $$\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}=O\left(\frac{\ln^2n}{n^{3/2}}\right).$$ My Attempt Recall the integral representation of harmonic number $$H_n=\int_0^1\frac{1-x^n}{1-x}d x$$ we have $$ S=\sum_{n=1}^\infty\frac1n\frac{\binom{2n}n}{4^n}\iint_{[0,1]^2}\frac{(1-x^n)(1-y^n)}{(1-x)(1-y)}d xd y\\ =\tiny\iint_{[0,1]^2}\frac{x y \log (4)-2 x y \log \left(\sqrt{1-x}+1\right)-2 x y \log \left(\sqrt{1-y}+1\right)+2 x y \log \left(\frac{1}{2} \left(\sqrt{1-x y}+1\right)\right)}{\left(\sqrt{1-x y}-1\right) \left(\sqrt{1-x y}+1\right)}dxdy\\ $$ This integral is too hard for me and Mathematica to compute. Numerical integration returns $12.6178$ , it agrees with the numerical summation of the original series. I tried to integrate with respect to $x$ , but failed.","Question: How can we evaluate where ? Quick Results This series converges because My Attempt Recall the integral representation of harmonic number we have This integral is too hard for me and Mathematica to compute. Numerical integration returns , it agrees with the numerical summation of the original series. I tried to integrate with respect to , but failed.","\sum_{n=1}^\infty\frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}, H_n=\frac11+\frac12+\cdots+\frac1n \frac{(H_n)^2}{n}\frac{\binom{2n}n}{4^n}=O\left(\frac{\ln^2n}{n^{3/2}}\right). H_n=\int_0^1\frac{1-x^n}{1-x}d x 
S=\sum_{n=1}^\infty\frac1n\frac{\binom{2n}n}{4^n}\iint_{[0,1]^2}\frac{(1-x^n)(1-y^n)}{(1-x)(1-y)}d xd y\\
=\tiny\iint_{[0,1]^2}\frac{x y \log (4)-2 x y \log \left(\sqrt{1-x}+1\right)-2 x y \log \left(\sqrt{1-y}+1\right)+2 x y \log \left(\frac{1}{2} \left(\sqrt{1-x y}+1\right)\right)}{\left(\sqrt{1-x y}-1\right) \left(\sqrt{1-x y}+1\right)}dxdy\\
 12.6178 x","['calculus', 'sequences-and-series', 'definite-integrals', 'harmonic-numbers']"
82,"Which methods to use to integrate $\int{\frac{x^4 + 1}{x^2 +1}}\, dx$",Which methods to use to integrate,"\int{\frac{x^4 + 1}{x^2 +1}}\, dx","I have this integral to evaluate: $$\int{\frac{x^4 + 1}{x^2 +1}}\, dx$$ I have tried substitution, trig identity and integration by parts but I'm just going round in circles. Can anyone explain the method I need to work this out?","I have this integral to evaluate: $$\int{\frac{x^4 + 1}{x^2 +1}}\, dx$$ I have tried substitution, trig identity and integration by parts but I'm just going round in circles. Can anyone explain the method I need to work this out?",,"['calculus', 'integration']"
83,How to prove that $ \sum_{n \in \mathbb{N} } | \frac{\sin( n)}{n} | $ diverges?,How to prove that  diverges?, \sum_{n \in \mathbb{N} } | \frac{\sin( n)}{n} | ,It is stated as a problem in Spivak's Calculus and I can't wrap my head around it.,It is stated as a problem in Spivak's Calculus and I can't wrap my head around it.,,"['calculus', 'sequences-and-series']"
84,Solving $\lim\limits_{x \to 0^+} \frac{\ln[\cos(x)]}{x}$,Solving,\lim\limits_{x \to 0^+} \frac{\ln[\cos(x)]}{x},"I had a test today which involved solving the following limit: $$\lim\limits_{x \to 0^+} \frac{\ln[\cos(x)]}{x}$$ I didn't figure out how to solve. After the test, I asked a couple of classmates and they told me that it was supposed to be solved by first transporting the multiplication by $\frac{1}{x}$ inside the logarithm as an exponent and then replacing $\cos(x)$ with $\sqrt{1-\sin^2(x)}$, giving the following expression: $$\lim\limits_{x \to 0^+} \ln[(1-\sin^2(x))^\frac{1}{2x}]$$ However, I don't know how to proceed from here. It's not like it matters a lot at this point, but I'd still like to know how I'm supposed to solve this. I'm not sure if it's applicable here, but we haven't learned L'Hôpital's rule.","I had a test today which involved solving the following limit: $$\lim\limits_{x \to 0^+} \frac{\ln[\cos(x)]}{x}$$ I didn't figure out how to solve. After the test, I asked a couple of classmates and they told me that it was supposed to be solved by first transporting the multiplication by $\frac{1}{x}$ inside the logarithm as an exponent and then replacing $\cos(x)$ with $\sqrt{1-\sin^2(x)}$, giving the following expression: $$\lim\limits_{x \to 0^+} \ln[(1-\sin^2(x))^\frac{1}{2x}]$$ However, I don't know how to proceed from here. It's not like it matters a lot at this point, but I'd still like to know how I'm supposed to solve this. I'm not sure if it's applicable here, but we haven't learned L'Hôpital's rule.",,"['calculus', 'limits']"
85,How to find the sum of this infinite series: $\sum_{n=1}^{ \infty } \frac1n \cdot \frac{H_{n+2}}{n+2}$ [closed],How to find the sum of this infinite series:  [closed],\sum_{n=1}^{ \infty } \frac1n \cdot \frac{H_{n+2}}{n+2},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do I find this particular sum? $$\sum_{n=1}^{ \infty } \frac1n \cdot \frac{H_{n+2}}{n+2}$$ where $H_n = \sum_{k=1}^{n}\frac1k$. This was given to me by a friend and I have absolutely no idea how to proceed as I have never done these questions before. If possible, please give a way out without using polylogarithmic functions or other non-elementary functions.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How do I find this particular sum? $$\sum_{n=1}^{ \infty } \frac1n \cdot \frac{H_{n+2}}{n+2}$$ where $H_n = \sum_{k=1}^{n}\frac1k$. This was given to me by a friend and I have absolutely no idea how to proceed as I have never done these questions before. If possible, please give a way out without using polylogarithmic functions or other non-elementary functions.",,"['calculus', 'sequences-and-series', 'algebra-precalculus', 'harmonic-numbers']"
86,Finding partial fractions expansions mentally,Finding partial fractions expansions mentally,,"On a problem on a test, my students were asked to find $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^3-2x^2} dx$, and one student began by writing $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^2(x-2)} dx=\int\left(\frac{3}{x^2}+6x+\frac{2}{x-2}+\frac{8}{x}+5\right)dx$. My question is how someone can get this result without doing any division or partial fraction decomposition -- what techniques can be used to get this?","On a problem on a test, my students were asked to find $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^3-2x^2} dx$, and one student began by writing $\displaystyle\int\frac{6x^4-7x^3-13x-6}{x^2(x-2)} dx=\int\left(\frac{3}{x^2}+6x+\frac{2}{x-2}+\frac{8}{x}+5\right)dx$. My question is how someone can get this result without doing any division or partial fraction decomposition -- what techniques can be used to get this?",,"['calculus', 'integration']"
87,$\sin^2(x)+\cos^2(x) = 1$ using power series,using power series,\sin^2(x)+\cos^2(x) = 1,"In an example I had to prove that $\sin^2(x)+\cos^2(x)=1$ which is fairly easy using the unit circle. My teacher then asked me to show the same thing using the following power series:$$\sin(x)=\sum_{k=0}^\infty\frac{(-1)^kx^{2k+1}}{(2k+1)!}$$ and $$\cos(x)=\sum_{k=0}^\infty\frac{(-1)^kx^{2k}}{(2k)!}$$ However, if I now take the squares of these values I get a really messy result that I can't simplify to 1. Could anyone give me a hint on how to deal with this question?","In an example I had to prove that $\sin^2(x)+\cos^2(x)=1$ which is fairly easy using the unit circle. My teacher then asked me to show the same thing using the following power series:$$\sin(x)=\sum_{k=0}^\infty\frac{(-1)^kx^{2k+1}}{(2k+1)!}$$ and $$\cos(x)=\sum_{k=0}^\infty\frac{(-1)^kx^{2k}}{(2k)!}$$ However, if I now take the squares of these values I get a really messy result that I can't simplify to 1. Could anyone give me a hint on how to deal with this question?",,"['calculus', 'trigonometry', 'power-series']"
88,How can I find the fifth root of unity?,How can I find the fifth root of unity?,,"I need to find fifth root of unity in the form $x+iy$.  I'm new to this topic and would appreciate a detailed ""dummies guide to..."" explanation! I understand the formula, whereby for this question I would write: $1^{1/5} = r^{1/5}e^{2ki\pi/5}$. However, I don't know what to do next. Any help is appreciated.","I need to find fifth root of unity in the form $x+iy$.  I'm new to this topic and would appreciate a detailed ""dummies guide to..."" explanation! I understand the formula, whereby for this question I would write: $1^{1/5} = r^{1/5}e^{2ki\pi/5}$. However, I don't know what to do next. Any help is appreciated.",,"['calculus', 'roots-of-unity']"
89,Can we compute $\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x$ without Feynman’s trick?,Can we compute  without Feynman’s trick?,\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x,"When I came across the integral $$I=\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x,$$ I immediately thought of the Feynman’s trick after the substitution $x\mapsto \frac{1}{x}$ . $$ I=\int_0^1 \frac{\sin ^2(\ln x)}{\ln ^2 x} d x $$ Considering the parameterised integral $$ I(a)=\int_0^1 \frac{\sin ^2(a \ln x)}{\ln ^2 x} d x $$ Differentiating $I(a)$ w.r.t. $a$ twice, we get $$ I^{\prime}(a)=\int_0^1 \frac{\sin (2a \ln x)}{\ln x}dx $$ and $$ I^{\prime \prime}(a) =2 \int_0^1 \cos (2 a \ln x) d x =\frac{2}{4 a^2+1} $$ Integrating back yields $$ I ^{\prime}(a)=I^{\prime}(a)-I^{\prime}(0)= \int_0^a \frac{2}{4 t^2+1} d t =\tan ^{-1}(2 a) $$ Further integration gives $$ \boxed{\int_0^1 \frac{\sin ^2(a \ln x)}{\ln ^2 x} d x =\int_0^a \tan ^{-1}(2 t) d t=a \tan ^{-1}(2 a)-\frac{1}{4} \ln \left(4 a^2+1\right)} $$ Now we can conclude that $$\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x =I(1)=  \tan ^{-1} 2-\frac{\ln 5}{4} $$ My question: Can we compute $$\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x$$ without Feynman’s trick? Your comments and alternative methods are highly appreciated.","When I came across the integral I immediately thought of the Feynman’s trick after the substitution . Considering the parameterised integral Differentiating w.r.t. twice, we get and Integrating back yields Further integration gives Now we can conclude that My question: Can we compute without Feynman’s trick? Your comments and alternative methods are highly appreciated.","I=\int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x, x\mapsto \frac{1}{x} 
I=\int_0^1 \frac{\sin ^2(\ln x)}{\ln ^2 x} d x
 
I(a)=\int_0^1 \frac{\sin ^2(a \ln x)}{\ln ^2 x} d x
 I(a) a 
I^{\prime}(a)=\int_0^1 \frac{\sin (2a \ln x)}{\ln x}dx
 
I^{\prime \prime}(a) =2 \int_0^1 \cos (2 a \ln x) d x =\frac{2}{4 a^2+1}
 
I ^{\prime}(a)=I^{\prime}(a)-I^{\prime}(0)= \int_0^a \frac{2}{4 t^2+1} d t =\tan ^{-1}(2 a)
 
\boxed{\int_0^1 \frac{\sin ^2(a \ln x)}{\ln ^2 x} d x =\int_0^a \tan ^{-1}(2 t) d t=a \tan ^{-1}(2 a)-\frac{1}{4} \ln \left(4 a^2+1\right)}
 \int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x =I(1)= 
\tan ^{-1} 2-\frac{\ln 5}{4}
 \int_1^{\infty} \frac{\sin ^2(\ln x)}{x^2 \ln ^2 x} d x","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'trigonometric-integrals']"
90,Factorial Calculation for Non-Integers?,Factorial Calculation for Non-Integers?,,I was playing with numbers on calculator and to my amaze i could see that calculator calculated $(4.5)!$ or any real numbers but factorial is defined for integers how is this done any advanced function. (Note I am grade $11$ student),I was playing with numbers on calculator and to my amaze i could see that calculator calculated $(4.5)!$ or any real numbers but factorial is defined for integers how is this done any advanced function. (Note I am grade $11$ student),,"['calculus', 'factorial']"
91,"Is there a convergent, alternating series that fails the AST?","Is there a convergent, alternating series that fails the AST?",,"The alternating series test (AST) says, briefly, that if $a_k>0$ $a_k \geq a_{k+1}$, and $a_k \to 0$ as $k \to \infty$ then $\sum_k (-1)^k a_k$ converges. This seems to be a one-way test (that is, if an alternating series fails the test, we don't know that it diverges). This document says so explicitly. It then gives an example of an alternating series which fails the AST. That doesn't prove the series is divergent (but it turns out to be divergent, anyway, by $n$th term test). Is there a convergent, alternating series that fails the AST? Of course, if the series fails condition 3, then it also fails the $n$th term test, and must diverge. And if it fails the first condition, then it's not strictly alternating, anyway. So it must be a series that is not getting smaller (condition 2), but still converges.","The alternating series test (AST) says, briefly, that if $a_k>0$ $a_k \geq a_{k+1}$, and $a_k \to 0$ as $k \to \infty$ then $\sum_k (-1)^k a_k$ converges. This seems to be a one-way test (that is, if an alternating series fails the test, we don't know that it diverges). This document says so explicitly. It then gives an example of an alternating series which fails the AST. That doesn't prove the series is divergent (but it turns out to be divergent, anyway, by $n$th term test). Is there a convergent, alternating series that fails the AST? Of course, if the series fails condition 3, then it also fails the $n$th term test, and must diverge. And if it fails the first condition, then it's not strictly alternating, anyway. So it must be a series that is not getting smaller (condition 2), but still converges.",,"['calculus', 'sequences-and-series']"
92,Can these two limits be true at the same time,Can these two limits be true at the same time,,Is it possible to have $$\lim_{x\to+\infty}x\left[f(x)\right]^5=0$$ and $$\lim_{x\to+\infty}x\left[f(x)\right]^3=+\infty$$ for some function $f$ at the same time?,Is it possible to have $$\lim_{x\to+\infty}x\left[f(x)\right]^5=0$$ and $$\lim_{x\to+\infty}x\left[f(x)\right]^3=+\infty$$ for some function $f$ at the same time?,,"['calculus', 'limits']"
93,"Finding $x^8+y^8+z^8$, given $x+y+z=0$, $\;xy +xz+yz=-1$, $\;xyz=-1$","Finding , given , ,",x^8+y^8+z^8 x+y+z=0 \;xy +xz+yz=-1 \;xyz=-1,"The system says $$x+y+z=0$$ $$xy +xz+yz=-1$$ $$xyz=-1$$ Find $$x^8+y^8+z^8$$ With the first equation I squared and I found that $$x^2+y^2+z^2 =2$$ trying with $$(x + y + z)^3 =   x^3 + y^3 + z^3 +  3 x^2 y + 3 x y^2 + 3 x^2 z++ 3 y^2 z + 3 x z^2 +    3 y z^2 + 6 x y z$$ taking advantage of the fact that there is an $xyz=-1$ in the equation, but I'm not getting anywhere, someone less myopic than me.how to solve it? Thanks Edit : Will there be any university way to solve this problem , they posed it to a high school friend and told him it was just manipulations of remarkable products. His answers I understand to some extent but I don't think my friend understands all of it.","The system says Find With the first equation I squared and I found that trying with taking advantage of the fact that there is an in the equation, but I'm not getting anywhere, someone less myopic than me.how to solve it? Thanks Edit : Will there be any university way to solve this problem , they posed it to a high school friend and told him it was just manipulations of remarkable products. His answers I understand to some extent but I don't think my friend understands all of it.","x+y+z=0 xy +xz+yz=-1 xyz=-1 x^8+y^8+z^8 x^2+y^2+z^2 =2 (x + y + z)^3 = 
 x^3 + y^3 + z^3 +  3 x^2 y + 3 x y^2 + 3 x^2 z++ 3 y^2 z + 3 x z^2 + 
  3 y z^2 + 6 x y z xyz=-1","['calculus', 'algebra-precalculus', 'systems-of-equations', 'roots', 'symmetric-polynomials']"
94,How was Zeno's paradox solved using the limits of infinite series?,How was Zeno's paradox solved using the limits of infinite series?,,"This is a not necessarily the exact paradox Zeno is thought to have come up with, but it's similar enough: A man (In this photo, a dot 1 ) is to walk a distance of one unit from where he's standing to the wall. He, however, is to walk half the distance first, then half the remaining distance, then half of that, then half of that and so on. This means the man will never get to the wall, as there's always a half remaining. This defies common sense. We know a man(or woman, of course) can just walk up to a wall and get to it. My calculus book says this was solved when the idea of a limit of an infinite series was developed. The idea says that if the distances the man is passing are getting closer and closer to the total area from where he started to the wall, this means that the total distance is the limit of that. What I don't understand is this: mathematics tells us that the sum of the infinite little distances is finite, but, in real life, doesn't walking an infinite number of distances require an infinite amount of time, which means we didn't really solve anything, since that's what troubled Zeno? Thanks.","This is a not necessarily the exact paradox Zeno is thought to have come up with, but it's similar enough: A man (In this photo, a dot 1 ) is to walk a distance of one unit from where he's standing to the wall. He, however, is to walk half the distance first, then half the remaining distance, then half of that, then half of that and so on. This means the man will never get to the wall, as there's always a half remaining. This defies common sense. We know a man(or woman, of course) can just walk up to a wall and get to it. My calculus book says this was solved when the idea of a limit of an infinite series was developed. The idea says that if the distances the man is passing are getting closer and closer to the total area from where he started to the wall, this means that the total distance is the limit of that. What I don't understand is this: mathematics tells us that the sum of the infinite little distances is finite, but, in real life, doesn't walking an infinite number of distances require an infinite amount of time, which means we didn't really solve anything, since that's what troubled Zeno? Thanks.",,"['calculus', 'limits', 'intuition']"
95,"Definite integral - closed form: $\int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x$",Definite integral - closed form:,"\int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x","I'm struggling with this definite integral: $$  \int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x. $$ Any help will be greatly appreciated.","I'm struggling with this definite integral: $$  \int_{0}^{\infty}\cos\left(x^{4} + 1 \over x^{2}\right)\,{\rm d}x. $$ Any help will be greatly appreciated.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
96,How can we show that $\int_{0}^{2\pi}{x\over \phi-\cos^2(x)}\mathrm dx=2\pi^2?$,How can we show that,\int_{0}^{2\pi}{x\over \phi-\cos^2(x)}\mathrm dx=2\pi^2?,"We have the integral $$\int_{0}^{2\pi}{x\over \phi-\cos^2(x)}\mathrm dx=2\pi^2\tag1$$   $\phi$; Golden ratio What method do we employ to prove $(1)$? An attempt: If we use $u=\phi-\cos^2 x$ then $\int_{\phi-1}^{\phi-1}(...)du=0$ Another way, $(1)$ becomes $${1\over 2\sqrt{\phi}}\int_{0}^{2\pi}\left({x\over \sqrt{\phi}-\cos x}-{x\over \sqrt{\phi}+\cos x} \right)\mathrm dx\tag2$$ We got a hint by using $z=\tan{x\over 2}$, $dx={2dz\over 1+z^2}$, $\cos x={1-z^2\over 1+z^2}$ and $\sin x={2z\over 1+z^2}$ Let try on $$\int_{0}^{2\pi}{x\over \sqrt{\phi}+\cos x}\mathrm dx=4\int_{0}^{0}{\tan^{-1} z\over (1+z^2)\sqrt{\phi}+1-z^2}\cdot (1-z^2)\mathrm dz=0?\tag3$$ Doesn't seem to work. How else can we prove $(1)$?","We have the integral $$\int_{0}^{2\pi}{x\over \phi-\cos^2(x)}\mathrm dx=2\pi^2\tag1$$   $\phi$; Golden ratio What method do we employ to prove $(1)$? An attempt: If we use $u=\phi-\cos^2 x$ then $\int_{\phi-1}^{\phi-1}(...)du=0$ Another way, $(1)$ becomes $${1\over 2\sqrt{\phi}}\int_{0}^{2\pi}\left({x\over \sqrt{\phi}-\cos x}-{x\over \sqrt{\phi}+\cos x} \right)\mathrm dx\tag2$$ We got a hint by using $z=\tan{x\over 2}$, $dx={2dz\over 1+z^2}$, $\cos x={1-z^2\over 1+z^2}$ and $\sin x={2z\over 1+z^2}$ Let try on $$\int_{0}^{2\pi}{x\over \sqrt{\phi}+\cos x}\mathrm dx=4\int_{0}^{0}{\tan^{-1} z\over (1+z^2)\sqrt{\phi}+1-z^2}\cdot (1-z^2)\mathrm dz=0?\tag3$$ Doesn't seem to work. How else can we prove $(1)$?",,"['calculus', 'integration', 'definite-integrals']"
97,The square of minimum area with three vertices on a parabola,The square of minimum area with three vertices on a parabola,,"I was given this question by a friend and after working tirelessly on it I have not come up with anything substantial. I was hoping someone in the community could provide a pointer or possibly a solution. The person who gave me the question says he has the answer to it, but I am more curious about the working. Here is the question: Three points $(B, C, D)$ lie on parabola  $y = x^2$ and a fourth point $A$ is placed such that $ABCD$ forms a square. Find the minimal area of $ABCD$. So far my working out has involved a collection of distance/mid-point formula's and I haven't even reached the point where I differentiate to minimize the area. Any pointers would be welcome. Edit Apparently the correct answer is $\sqrt{2}$ units squared.","I was given this question by a friend and after working tirelessly on it I have not come up with anything substantial. I was hoping someone in the community could provide a pointer or possibly a solution. The person who gave me the question says he has the answer to it, but I am more curious about the working. Here is the question: Three points $(B, C, D)$ lie on parabola  $y = x^2$ and a fourth point $A$ is placed such that $ABCD$ forms a square. Find the minimal area of $ABCD$. So far my working out has involved a collection of distance/mid-point formula's and I haven't even reached the point where I differentiate to minimize the area. Any pointers would be welcome. Edit Apparently the correct answer is $\sqrt{2}$ units squared.",,"['calculus', 'geometry']"
98,Integral:$ \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx $,Integral:, \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx ,"How to evaluate: $$ \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx $$ Maybe we can evaluate it using the well-known result:$\int_{0}^{\frac{\pi}{2}} \ln{\sin t} \text{d}t=\int_{0}^{\frac{\pi}{2}} \ln{\cos t} \text{d}t=-\frac{\pi}{2}\ln{2}$ But how do I evaluate it, using that ?","How to evaluate: $$ \int^\infty_{-\infty}\frac{\ln(x^{2}+1)}{x^{2}+1}dx $$ Maybe we can evaluate it using the well-known result:$\int_{0}^{\frac{\pi}{2}} \ln{\sin t} \text{d}t=\int_{0}^{\frac{\pi}{2}} \ln{\cos t} \text{d}t=-\frac{\pi}{2}\ln{2}$ But how do I evaluate it, using that ?",,"['calculus', 'integration']"
99,Probability that a random permutation has no fixed point among the first $k$ elements,Probability that a random permutation has no fixed point among the first  elements,k,"Is it true that $\frac1{n!} \int_0^\infty x^{n-k} (x-1)^k e^{-x}\,dx \approx e^{-k/n}$ when $k$ and $n$ are large integers with $k \le n$? This quantity is the probability that a random permutation of $n$ elements does not fix any of the first $k$ elements.","Is it true that $\frac1{n!} \int_0^\infty x^{n-k} (x-1)^k e^{-x}\,dx \approx e^{-k/n}$ when $k$ and $n$ are large integers with $k \le n$? This quantity is the probability that a random permutation of $n$ elements does not fix any of the first $k$ elements.",,"['calculus', 'probability', 'combinatorics', 'analysis', 'permutations']"
