,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"The set $\{\|f\|_\alpha \leq 1 \}$ has compact closure in $C([0,1])$",The set  has compact closure in,"\{\|f\|_\alpha \leq 1 \} C([0,1])","Recall the Holder norm  $(0<\alpha\leq 1) $   $$\|f\|_\alpha = \max\bigg\{ |f(x)| +  \frac{|f(x) - f(y)|}{|x-y|^\alpha} : x,y \in [0,1], x\neq y\bigg\}$$ I want to show that the set $\mathcal F :=\{ \|f\|_\alpha \leq 1 \}$ has a   compact closure in $C([0,1])$. My attempt: Using Arzela-Ascoli theorem, it suffice to show that $\mathcal F$ is equicontinuous and uniformly bounded which implies every sequence in $\mathcal F$ has a Cauchy subsequence. Uniform boundedness follows from the fact that $\|f\|_\infty \leq \|f\|_\alpha\leq 1$, then  $$|f(x)| \leq 1 \text{ on } [0,1] \text{ for each } f\in \mathcal F.$$ For equicontinuity, let $x_0$ and $\epsilon$ be given, we use the fact that  $$\frac{|f(x_0) - f(y)|}{|x_0-y|^\alpha} \leq \|f\|_\alpha \leq 1$$  to get $\delta = \epsilon^{1/\alpha}$. Then, for each $f\in \mathcal F$, we get $$|f(x_0) - f(y)| \leq |x_0 - y|^\alpha \leq  (\epsilon^{1/\alpha})^\alpha = \epsilon.$$ is this okay? thank you very much!","Recall the Holder norm  $(0<\alpha\leq 1) $   $$\|f\|_\alpha = \max\bigg\{ |f(x)| +  \frac{|f(x) - f(y)|}{|x-y|^\alpha} : x,y \in [0,1], x\neq y\bigg\}$$ I want to show that the set $\mathcal F :=\{ \|f\|_\alpha \leq 1 \}$ has a   compact closure in $C([0,1])$. My attempt: Using Arzela-Ascoli theorem, it suffice to show that $\mathcal F$ is equicontinuous and uniformly bounded which implies every sequence in $\mathcal F$ has a Cauchy subsequence. Uniform boundedness follows from the fact that $\|f\|_\infty \leq \|f\|_\alpha\leq 1$, then  $$|f(x)| \leq 1 \text{ on } [0,1] \text{ for each } f\in \mathcal F.$$ For equicontinuity, let $x_0$ and $\epsilon$ be given, we use the fact that  $$\frac{|f(x_0) - f(y)|}{|x_0-y|^\alpha} \leq \|f\|_\alpha \leq 1$$  to get $\delta = \epsilon^{1/\alpha}$. Then, for each $f\in \mathcal F$, we get $$|f(x_0) - f(y)| \leq |x_0 - y|^\alpha \leq  (\epsilon^{1/\alpha})^\alpha = \epsilon.$$ is this okay? thank you very much!",,"['real-analysis', 'functional-analysis', 'compactness']"
1,"Most general type of $L^p(X,\ V)$ space where compactly-supported continuous functions are dense",Most general type of  space where compactly-supported continuous functions are dense,"L^p(X,\ V)","Let $(X,\ \tau)$ be a topological (locally compact?) space, $(X,\ \mathcal{F},\ \mu)$ a measure space, $(V,\ \|\cdot\|)$ a Banach space, $1\leq p < \infty$ and $\|\cdot\|_p$ a function defined for a measurable function (with respect to a Borel $\sigma$-algebra on $V$) $f:X\to V$ as $$\|f\|_p=(\int\limits_X \|f\|^p\mathrm{d}\mu)^\frac{1}{p}.$$ $L^p(X,\ V)$ space is a Banach space of measureable functions $f:X\to V$ such that $\|f\|_p<\infty$, where functions equal almost everywhere are identified, with a norm $\|\cdot\|_p$. I'm looking for the most general conditions under which a set of compactly-supported continuous functions is dense in $L^p(X,\ V)$. The case of compact $X$ will be the most important for me, so I prefer this constraint to others. Could someone point me to a book or a paper containing such a result?","Let $(X,\ \tau)$ be a topological (locally compact?) space, $(X,\ \mathcal{F},\ \mu)$ a measure space, $(V,\ \|\cdot\|)$ a Banach space, $1\leq p < \infty$ and $\|\cdot\|_p$ a function defined for a measurable function (with respect to a Borel $\sigma$-algebra on $V$) $f:X\to V$ as $$\|f\|_p=(\int\limits_X \|f\|^p\mathrm{d}\mu)^\frac{1}{p}.$$ $L^p(X,\ V)$ space is a Banach space of measureable functions $f:X\to V$ such that $\|f\|_p<\infty$, where functions equal almost everywhere are identified, with a norm $\|\cdot\|_p$. I'm looking for the most general conditions under which a set of compactly-supported continuous functions is dense in $L^p(X,\ V)$. The case of compact $X$ will be the most important for me, so I prefer this constraint to others. Could someone point me to a book or a paper containing such a result?",,"['functional-analysis', 'lp-spaces']"
2,Borel Measure on Banach Space,Borel Measure on Banach Space,,"While thinking about what some measure on an infinite dimensional Banach space could look like a came across the point that if I'd like to assign a size to all epsilon balls, they by Riesz' lemma necessarily will have to have either zero or infinite size. But then every bounded set will have zero or infinite size too. Moreover every countable union of these will have zero or infinite size as well... Now I'm wondering what nontrivial finite(!) translation invariant Borel measures on Banach spaces there are. Do you have some concrete examples?","While thinking about what some measure on an infinite dimensional Banach space could look like a came across the point that if I'd like to assign a size to all epsilon balls, they by Riesz' lemma necessarily will have to have either zero or infinite size. But then every bounded set will have zero or infinite size too. Moreover every countable union of these will have zero or infinite size as well... Now I'm wondering what nontrivial finite(!) translation invariant Borel measures on Banach spaces there are. Do you have some concrete examples?",,"['functional-analysis', 'measure-theory', 'banach-spaces']"
3,$C(X)$ is separable when $X$ is compact,is separable when  is compact,C(X) X,"Let $X$ be a compact space and let $\Bbb U =\{(U,V); U,V \mbox{ are open subsets of }X \mbox{ and }\mathrm{cl} U \subset V\} $. for $u=(U,V)$ in $\Bbb U$ , let $F_u:X\to [0,1]$ be a continuous function such that $f_u=1$ on $\mathrm{cl} U$ and $f_u=0$ on $X \setminus V$. Show a- the linear span of $\{f_u;u\in \Bbb U\}$ is dense in $C(X)$. b- If X is a metric space, then $C(X)$ is separable. c-If X is a $\sigma-$ compact metrizable locally compact space, then $C_0(X)$ is separable. My attempt: a- put $M=\{f_u; u\in \Bbb U\}$. suppose $\mu \in M^{\perp}$. thus  for every open subset $U$, $\mu(U)=0$. Also  $||\mu||=|\mu|(X) =0$ which shows that $M^{\perp}=0$. b- For every $n$, put $B_n=\{B(x,\frac{1}{n}) ; x\in X\}$. X is compact so there is a finite set $F_n\subset X$ such that  $\{B(x,\frac{1}{n}) ; x\in F_n\}$ is an open finite cover for X. put $F=\cup F_n$. I can show F is dense in X. put $u_x= (B(x,\frac{1}{n}), B(x,\frac{1}{n-1}))$ for every $x\in F.$ I want to show $M=\{f_{u_x}, x\in F\}$ is dense in $C(X)$. But I can not. c- $X=\cup X_n$ when every $X_n $ is compact.suppose $A_n$ is a countable dense set for  each $X_n$. put $A=\cup A_n$. clearly A is dense in X. Can I claim $C_0(X)=\cup C(X_n)$?  so in this case $C_0(X)$ is separable. I do not know my proof in part (a) is correct or not. Also I have problem in parts b,c. Please help me. Thanks in advance.","Let $X$ be a compact space and let $\Bbb U =\{(U,V); U,V \mbox{ are open subsets of }X \mbox{ and }\mathrm{cl} U \subset V\} $. for $u=(U,V)$ in $\Bbb U$ , let $F_u:X\to [0,1]$ be a continuous function such that $f_u=1$ on $\mathrm{cl} U$ and $f_u=0$ on $X \setminus V$. Show a- the linear span of $\{f_u;u\in \Bbb U\}$ is dense in $C(X)$. b- If X is a metric space, then $C(X)$ is separable. c-If X is a $\sigma-$ compact metrizable locally compact space, then $C_0(X)$ is separable. My attempt: a- put $M=\{f_u; u\in \Bbb U\}$. suppose $\mu \in M^{\perp}$. thus  for every open subset $U$, $\mu(U)=0$. Also  $||\mu||=|\mu|(X) =0$ which shows that $M^{\perp}=0$. b- For every $n$, put $B_n=\{B(x,\frac{1}{n}) ; x\in X\}$. X is compact so there is a finite set $F_n\subset X$ such that  $\{B(x,\frac{1}{n}) ; x\in F_n\}$ is an open finite cover for X. put $F=\cup F_n$. I can show F is dense in X. put $u_x= (B(x,\frac{1}{n}), B(x,\frac{1}{n-1}))$ for every $x\in F.$ I want to show $M=\{f_{u_x}, x\in F\}$ is dense in $C(X)$. But I can not. c- $X=\cup X_n$ when every $X_n $ is compact.suppose $A_n$ is a countable dense set for  each $X_n$. put $A=\cup A_n$. clearly A is dense in X. Can I claim $C_0(X)=\cup C(X_n)$?  so in this case $C_0(X)$ is separable. I do not know my proof in part (a) is correct or not. Also I have problem in parts b,c. Please help me. Thanks in advance.",,"['functional-analysis', 'banach-spaces']"
4,Stone's theorem,Stone's theorem,,"I have some basic doubts about Stone's theorem. 1) Can we apply Stone's theorem to conclude that given any Unitary operator U , we can find a self adjoint operator A such that U = exp(i A ). That is, is any unitary operator part of a one parameter group? 2) Is there some version of Stone's theorem for real Hilbert spaces like in finite dimensions?","I have some basic doubts about Stone's theorem. 1) Can we apply Stone's theorem to conclude that given any Unitary operator U , we can find a self adjoint operator A such that U = exp(i A ). That is, is any unitary operator part of a one parameter group? 2) Is there some version of Stone's theorem for real Hilbert spaces like in finite dimensions?",,['functional-analysis']
5,p-norm of a function,p-norm of a function,,"Let $f\in L^1(\mu)\cap L^\infty(\mu)$. I have proved for any $1<p<\infty$, $f\in L^p(\mu)$, $w(p)=||f||_p$ is continuous w.r.t. $p$, and  $\lim_{p\to \infty}||f||_p=||f||_\infty$. Is $w(p)$ differentiable? Will $w(p)$ be a concave or convex function w.r.t. $p$ when $p$ sufficiently large?","Let $f\in L^1(\mu)\cap L^\infty(\mu)$. I have proved for any $1<p<\infty$, $f\in L^p(\mu)$, $w(p)=||f||_p$ is continuous w.r.t. $p$, and  $\lim_{p\to \infty}||f||_p=||f||_\infty$. Is $w(p)$ differentiable? Will $w(p)$ be a concave or convex function w.r.t. $p$ when $p$ sufficiently large?",,"['real-analysis', 'integration', 'functional-analysis', 'measure-theory', 'lp-spaces']"
6,Composition of Partial Isometries,Composition of Partial Isometries,,"Let $H$ be a complex Hilbert space and $S,T \in B(H)$ partial isometries. Then $S T$ is a partial isometrie, if and only if $T^*(\ker(S)) \subseteq \ker(ST)$. Edit: My attempts so far: $\Rightarrow$: Let  $x \in \ker(S)$, then $||STT^*(x)||^2=<STT^*(x), STT^*(x)>=<PT^*(x),T^*(x)>$, where P is the orthogonal projection onto  $ker(ST)^\perp$. I've tried many different angles but this is where I always end up","Let $H$ be a complex Hilbert space and $S,T \in B(H)$ partial isometries. Then $S T$ is a partial isometrie, if and only if $T^*(\ker(S)) \subseteq \ker(ST)$. Edit: My attempts so far: $\Rightarrow$: Let  $x \in \ker(S)$, then $||STT^*(x)||^2=<STT^*(x), STT^*(x)>=<PT^*(x),T^*(x)>$, where P is the orthogonal projection onto  $ker(ST)^\perp$. I've tried many different angles but this is where I always end up",,"['functional-analysis', 'hilbert-spaces']"
7,Pure states and irreducible *-representations,Pure states and irreducible *-representations,,"If $A$ is a $C^*$-algebra, then a $*$-representations of $A$ is irreducible if and only if the corresponding state is a pure state. What happens if don't insist on $A$ being a $C^*$-algebra? Is one of the two directions still true? Are there examples in which this Theorem fails? To give a detailed version of my question: Let $A$ be an unital algebra over $\mathbb{C}$ with involution $*$. Let $\varphi: A \to \mathbb{C}$ be a state, i.e. a $\mathbb{C}$-linear map which satisfies $\varphi(a^* a) \geq 0$ for all $a \in A$ and $\varphi(1)=1$. The set of states on $A$ is convex and we call $\varphi$ a pure state if it is an extreme point of this set. The set $N_{\varphi}=\{a \in A: \varphi(a^*a)=0\}$ is a left ideal of $A$. When does one of the following hold: $\varphi$ is a pure state $\Rightarrow$ $N_{\varphi}$ is a maximal left ideal $\varphi$ is a pure state $\Leftarrow$ $N_{\varphi}$ is a maximal left ideal ? Edit: Why is $N_{\varphi}$ a left ideal? To see this, we first have to prove the CSI: $|\varphi(b^* a)|^2 \leq \varphi(a^*a) \varphi(b^* b)$. We have for all $v=(v_1,v_2) \in \mathbb{C}^2$ that $\varphi((v_1 a + v_2 b)^* (v_1 a + v_2 b))\geq 0$. This means that the matrix $\begin{pmatrix} \varphi(a^*a) & \varphi(b^* a) \\ \varphi(a^* b) & \varphi(b^*b) \end{pmatrix}$ is positive semidefinite. Taking the determinant implies the CSI. Now using the CSI, the claim is easy: $\varphi((ua)^*ua)=\varphi(a^*(u^*ua))$, thus $\varphi(a^*a)=0$ implies $\varphi((ua)^*ua)=0$. One checks similarly the additive property.","If $A$ is a $C^*$-algebra, then a $*$-representations of $A$ is irreducible if and only if the corresponding state is a pure state. What happens if don't insist on $A$ being a $C^*$-algebra? Is one of the two directions still true? Are there examples in which this Theorem fails? To give a detailed version of my question: Let $A$ be an unital algebra over $\mathbb{C}$ with involution $*$. Let $\varphi: A \to \mathbb{C}$ be a state, i.e. a $\mathbb{C}$-linear map which satisfies $\varphi(a^* a) \geq 0$ for all $a \in A$ and $\varphi(1)=1$. The set of states on $A$ is convex and we call $\varphi$ a pure state if it is an extreme point of this set. The set $N_{\varphi}=\{a \in A: \varphi(a^*a)=0\}$ is a left ideal of $A$. When does one of the following hold: $\varphi$ is a pure state $\Rightarrow$ $N_{\varphi}$ is a maximal left ideal $\varphi$ is a pure state $\Leftarrow$ $N_{\varphi}$ is a maximal left ideal ? Edit: Why is $N_{\varphi}$ a left ideal? To see this, we first have to prove the CSI: $|\varphi(b^* a)|^2 \leq \varphi(a^*a) \varphi(b^* b)$. We have for all $v=(v_1,v_2) \in \mathbb{C}^2$ that $\varphi((v_1 a + v_2 b)^* (v_1 a + v_2 b))\geq 0$. This means that the matrix $\begin{pmatrix} \varphi(a^*a) & \varphi(b^* a) \\ \varphi(a^* b) & \varphi(b^*b) \end{pmatrix}$ is positive semidefinite. Taking the determinant implies the CSI. Now using the CSI, the claim is easy: $\varphi((ua)^*ua)=\varphi(a^*(u^*ua))$, thus $\varphi(a^*a)=0$ implies $\varphi((ua)^*ua)=0$. One checks similarly the additive property.",,"['functional-analysis', 'c-star-algebras', 'noncommutative-algebra']"
8,Convegence of regularized sequence in $L^2$,Convegence of regularized sequence in,L^2,"Let $(\rho_n)_{n \geq 0}$ be a standard regularizing sequence on $\mathbb R$. Let $P$ be a probability measure on $\mathbb R$ such that the sequence $(P*\rho_n)_{n \geq 0}$ is bounded in $L^2$. Then, does the probability measure $P$ admit a density in $ L^2$? i.e., is there a $p \in L^2(\mathbb R)$ satisfying \begin{align} P(dx) = p (x) dx? \end{align} My understanding is that, due to the boundedness in $L^2$, the sequence $(P*\rho_n)_{n \geq 0}$ contains a subsequence, which converges weakly to a limit in $L^2$. But, how do we know that the density $p$ is the limit?","Let $(\rho_n)_{n \geq 0}$ be a standard regularizing sequence on $\mathbb R$. Let $P$ be a probability measure on $\mathbb R$ such that the sequence $(P*\rho_n)_{n \geq 0}$ is bounded in $L^2$. Then, does the probability measure $P$ admit a density in $ L^2$? i.e., is there a $p \in L^2(\mathbb R)$ satisfying \begin{align} P(dx) = p (x) dx? \end{align} My understanding is that, due to the boundedness in $L^2$, the sequence $(P*\rho_n)_{n \geq 0}$ contains a subsequence, which converges weakly to a limit in $L^2$. But, how do we know that the density $p$ is the limit?",,"['functional-analysis', 'probability-theory', 'probability-distributions', 'weak-convergence']"
9,Want to show that an operator is not surjective,Want to show that an operator is not surjective,,"So here is my problem, Let $$M_1:L^1\rightarrow L^1$$ $$f(x)\mapsto \arctan(x)f(x)$$ In order to compute the spectrum of $M_1$ I am investigating for which $\lambda\in\mathbb C$ the following map is surjective, $$M_1-\lambda\operatorname{id}_{L^1}$$ I think it is never surjective, therefore I tryied to compose a proof. The idea was to assume for contradiction that there exists some $\lambda$ such that the upper map is surjective. Hence there must exist an integrable function $f$ s.t $M_1f(x)=\mathcal X_{[0,1]}(x)$ is the indicator function of $[0,1]$. By assumption it follows then that $f(x)=\frac{1}{\arctan(x)-\lambda}$ which is not $L^1$. A contradiction! Since I am not sure if my proof is correct and I wanted to ask if there is a different way to show this? Thanks in advance! EDIT My hypothesis was wrong, $M_1-\lambda\operatorname{id}_{L^1}$ is bijective for all $\lambda\in\mathbb C\setminus[-\pi/2,\pi/2]$","So here is my problem, Let $$M_1:L^1\rightarrow L^1$$ $$f(x)\mapsto \arctan(x)f(x)$$ In order to compute the spectrum of $M_1$ I am investigating for which $\lambda\in\mathbb C$ the following map is surjective, $$M_1-\lambda\operatorname{id}_{L^1}$$ I think it is never surjective, therefore I tryied to compose a proof. The idea was to assume for contradiction that there exists some $\lambda$ such that the upper map is surjective. Hence there must exist an integrable function $f$ s.t $M_1f(x)=\mathcal X_{[0,1]}(x)$ is the indicator function of $[0,1]$. By assumption it follows then that $f(x)=\frac{1}{\arctan(x)-\lambda}$ which is not $L^1$. A contradiction! Since I am not sure if my proof is correct and I wanted to ask if there is a different way to show this? Thanks in advance! EDIT My hypothesis was wrong, $M_1-\lambda\operatorname{id}_{L^1}$ is bijective for all $\lambda\in\mathbb C\setminus[-\pi/2,\pi/2]$",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
10,Comparison of versions of the spectral theorem,Comparison of versions of the spectral theorem,,"Definition: (Resolution of Identity) A projection valued measure that is finitely additive and factors over intersections. Theorem 1: Let $A$ be a normal operator in $H$ a Hilbert Space where everything is over the complex field.  Then there exists an $(X, \Sigma, \mu)$ measure space and a unitary equivalence between $H$ and $L^2(X)$ so that $A$ is represented as a multiplication operator of an $L^\infty$ function. I have already compared the versions of the spectral theorem for compact normal operators that involve no measure theory, as well as the interpretation of the bounded Borel functional calculus as a spectral theoretic result, and how this relates to the resolution of the identity.  The latter two are basically identical principles, whereas the first is sort of a special case.  The above theorem also seems to share the same basic idea as the bounded borel functional calculus and the existence and uniqueness resolution of identity corresponding to a normal operator. (This is usually called the spectral measure) Question 1: I do not see how to even derive the above theorem from either of these two other versions of the spectral theorem, and would be especially interested in a proof of this sort because it would also show relationships between these supposedly intuitively similar ideas.  I ask this because I suppose that the argument could probably be done quickly if the ideologies are basically the same, whereas were I to read separate arguments (which are hard to find on the web anyway) for this level of generality of theorem 1, I would then be left in the dark as to how it relates to anything resembling spectral theory.  The subject of resolution of identity was quite technical, and so one would hope that there is a way to not repeat this technical stuff for what seems to be another type of analogy between spectral decomposition and measure theory. Theorem 2: If $A$ is a bounded linear operator on $L^2(\mathbb{R}^N)$ commuting with translations, then there exists an $L^\infty$ function $M$ such that $Af=\mathcal{F}^{-1} M \mathcal{F}f$ for all $f \in L^2$ In both the theorems here, the multiplier has infinity norm equal to the norm of $A$. Question 2: I observed that this actually implies, without assuming it, that in the context of theorem 2 $A$ is normal.  Is there a direct and easy argument verifying this without the full blown effort to prove the theorem? Question 3: since $A$ is normal, I see theorem 2 as saying that with additional hypotheses, you can pick a special unitary equivalence to a special $L^2$ space as the data realizing the conclusion of theorem 1.  Is there a deeper relationship between theorem 1 and 2 here? Question 4: We obviously have that the only reasonable uniqueness claim for theorem 2 is true.  But for theorem 1, if we fix a particular measure space that is among those that work, and fix a unitary equivalence (both these seem necessary) can we at least claim uniqueness of the multiplier?  It seems false without sigma finiteness, and so perhaps the following is not an interesting question but one could still ask if it's possible to select a measure space and unitary equivalence so that it is unique, even if the selection may not be sigma finite?  Is it always possible to make a sigma finite selection?  It would seem that the fact that $||A||$ being the same as the infinity norm of the multiplier in the context of theorem 1 is something you must be able to choose to have, but is not true of all otherwise valid choices. (For otherwise uniqueness of the multiplier would be guaranteed) I am most interested in questions 1-3, but answers to any subset of the 4 would be greatly appreciated.","Definition: (Resolution of Identity) A projection valued measure that is finitely additive and factors over intersections. Theorem 1: Let $A$ be a normal operator in $H$ a Hilbert Space where everything is over the complex field.  Then there exists an $(X, \Sigma, \mu)$ measure space and a unitary equivalence between $H$ and $L^2(X)$ so that $A$ is represented as a multiplication operator of an $L^\infty$ function. I have already compared the versions of the spectral theorem for compact normal operators that involve no measure theory, as well as the interpretation of the bounded Borel functional calculus as a spectral theoretic result, and how this relates to the resolution of the identity.  The latter two are basically identical principles, whereas the first is sort of a special case.  The above theorem also seems to share the same basic idea as the bounded borel functional calculus and the existence and uniqueness resolution of identity corresponding to a normal operator. (This is usually called the spectral measure) Question 1: I do not see how to even derive the above theorem from either of these two other versions of the spectral theorem, and would be especially interested in a proof of this sort because it would also show relationships between these supposedly intuitively similar ideas.  I ask this because I suppose that the argument could probably be done quickly if the ideologies are basically the same, whereas were I to read separate arguments (which are hard to find on the web anyway) for this level of generality of theorem 1, I would then be left in the dark as to how it relates to anything resembling spectral theory.  The subject of resolution of identity was quite technical, and so one would hope that there is a way to not repeat this technical stuff for what seems to be another type of analogy between spectral decomposition and measure theory. Theorem 2: If $A$ is a bounded linear operator on $L^2(\mathbb{R}^N)$ commuting with translations, then there exists an $L^\infty$ function $M$ such that $Af=\mathcal{F}^{-1} M \mathcal{F}f$ for all $f \in L^2$ In both the theorems here, the multiplier has infinity norm equal to the norm of $A$. Question 2: I observed that this actually implies, without assuming it, that in the context of theorem 2 $A$ is normal.  Is there a direct and easy argument verifying this without the full blown effort to prove the theorem? Question 3: since $A$ is normal, I see theorem 2 as saying that with additional hypotheses, you can pick a special unitary equivalence to a special $L^2$ space as the data realizing the conclusion of theorem 1.  Is there a deeper relationship between theorem 1 and 2 here? Question 4: We obviously have that the only reasonable uniqueness claim for theorem 2 is true.  But for theorem 1, if we fix a particular measure space that is among those that work, and fix a unitary equivalence (both these seem necessary) can we at least claim uniqueness of the multiplier?  It seems false without sigma finiteness, and so perhaps the following is not an interesting question but one could still ask if it's possible to select a measure space and unitary equivalence so that it is unique, even if the selection may not be sigma finite?  Is it always possible to make a sigma finite selection?  It would seem that the fact that $||A||$ being the same as the infinity norm of the multiplier in the context of theorem 1 is something you must be able to choose to have, but is not true of all otherwise valid choices. (For otherwise uniqueness of the multiplier would be guaranteed) I am most interested in questions 1-3, but answers to any subset of the 4 would be greatly appreciated.",,"['analysis', 'functional-analysis', 'spectral-theory']"
11,Dense subspace of the space of measures on the torus $\mathbb{T}$.,Dense subspace of the space of measures on the torus .,\mathbb{T},"Every measure $\mu$ on the torus $\mathbb{T}$ is the weak-$\ast$ limit of a sequence of absolutely continuous measures on $\mathbb{T}$ with $C^{\infty}$ densities. I'd like to see a proof of this fact. I've read that the Stone–Weierstrass theorem may be involved. Could someone point me to a reference for the proof or help me to correct/make rigourous the following one? ""Proof:"" Let $f \in C^{\infty}(\mathbb{T})$ and $f_{\epsilon}(x) = \epsilon^{-1}f(\epsilon^{-1}x)$. $\mu \ast f_{\epsilon} \rightarrow \mu$ in weak-$\ast$ [?] $\mu \ast f_{\epsilon}$ is continuous [?] By the Stone-Weierstrass theorem, $\forall \eta > 0$, $\forall \epsilon > 0$, $\exists g_{\eta,\epsilon} \in C^{\infty}(\mathbb{T})$ such that $$ \|\mu \ast f_{\epsilon} - g_{\eta,\epsilon} \|_{\infty} < \eta. $$ $g_{\eta,\epsilon} \rightarrow \mu$ in weak-$\ast$ [?]","Every measure $\mu$ on the torus $\mathbb{T}$ is the weak-$\ast$ limit of a sequence of absolutely continuous measures on $\mathbb{T}$ with $C^{\infty}$ densities. I'd like to see a proof of this fact. I've read that the Stone–Weierstrass theorem may be involved. Could someone point me to a reference for the proof or help me to correct/make rigourous the following one? ""Proof:"" Let $f \in C^{\infty}(\mathbb{T})$ and $f_{\epsilon}(x) = \epsilon^{-1}f(\epsilon^{-1}x)$. $\mu \ast f_{\epsilon} \rightarrow \mu$ in weak-$\ast$ [?] $\mu \ast f_{\epsilon}$ is continuous [?] By the Stone-Weierstrass theorem, $\forall \eta > 0$, $\forall \epsilon > 0$, $\exists g_{\eta,\epsilon} \in C^{\infty}(\mathbb{T})$ such that $$ \|\mu \ast f_{\epsilon} - g_{\eta,\epsilon} \|_{\infty} < \eta. $$ $g_{\eta,\epsilon} \rightarrow \mu$ in weak-$\ast$ [?]",,"['real-analysis', 'analysis', 'functional-analysis', 'measure-theory', 'convergence-divergence']"
12,Are rank of $T$ and $T^*$ equal?,Are rank of  and  equal?,T T^*,Let $H$ be a infinite dimensional Hilbert space and $T:H\to H$ be an operator on $H$ .Is it true that $\operatorname{rank}T=\operatorname{rank}T^*$ . We know that this is true for finite dimension. Is it true for infinite dimensional Hilbert space or is there any example of $T$ and $T^*$ that their rank are different? Thanks!,Let be a infinite dimensional Hilbert space and be an operator on .Is it true that . We know that this is true for finite dimension. Is it true for infinite dimensional Hilbert space or is there any example of and that their rank are different? Thanks!,H T:H\to H H \operatorname{rank}T=\operatorname{rank}T^* T T^*,"['functional-analysis', 'operator-theory']"
13,Hardy-Littlewood-Sobolev fractional integration inequality fails at endpoints,Hardy-Littlewood-Sobolev fractional integration inequality fails at endpoints,,"Here's a version of the theorem: If $1 < p, r < \infty$ and $ 0 < \alpha < n $ be such that $ \frac{1}{p} + \frac{ \alpha }{ n} = \frac{1}{r} + 1 $. Then for any $ f \in L^p ( \mathbb R ^n )$, the function $$I_\alpha f (x): = \int_{ \mathbb R^n } \frac{f (y) }{  |x - y| ^\alpha } d y $$ is well defined almost everywhere and lies in $L^r ( \mathbb R^n )$. Moreover, $$|| I_ \alpha f ||_{ L^r ( \mathbb R ^n )} \le C_{p ,\alpha , n } ||f||_{ L^ p(\mathbb R^n )} $$ for some constant $ C_{ p ,\alpha , n } > 0$. I want to show the theorem fails for $ p =1 ,r = \infty$, or $\alpha = n$. I tried a long time but don't make any progress. Any help is appreciated.","Here's a version of the theorem: If $1 < p, r < \infty$ and $ 0 < \alpha < n $ be such that $ \frac{1}{p} + \frac{ \alpha }{ n} = \frac{1}{r} + 1 $. Then for any $ f \in L^p ( \mathbb R ^n )$, the function $$I_\alpha f (x): = \int_{ \mathbb R^n } \frac{f (y) }{  |x - y| ^\alpha } d y $$ is well defined almost everywhere and lies in $L^r ( \mathbb R^n )$. Moreover, $$|| I_ \alpha f ||_{ L^r ( \mathbb R ^n )} \le C_{p ,\alpha , n } ||f||_{ L^ p(\mathbb R^n )} $$ for some constant $ C_{ p ,\alpha , n } > 0$. I want to show the theorem fails for $ p =1 ,r = \infty$, or $\alpha = n$. I tried a long time but don't make any progress. Any help is appreciated.",,"['functional-analysis', 'sobolev-spaces', 'interpolation']"
14,Compactness of set of projections,Compactness of set of projections,,"In a proof I am reading I saw the statement that the set of projections onto one fixed finite dimensional subspace of a Banach space $X$ is compact. Is this obvious, for some reason I just don't see the proof of this apparently simple fact? Edit 1: All projections have the same range. Edit 2: The statement in the paper is that there always exists a projection of the smallest norm on a fixed finite dimensional subspace (the inf is attained), and that it follows from a ""compactness argument"". I wrongly assumed that the set of projections must be compact (thank you Martin). I think what is enough is to consider the set of projection with norm smaller than dimension of the finite dimensional subspace. Is the set compact in this case? If it is, it will prove the claim, as the continuous function $P\to\|P\|$ would attain the minimum on this set.","In a proof I am reading I saw the statement that the set of projections onto one fixed finite dimensional subspace of a Banach space $X$ is compact. Is this obvious, for some reason I just don't see the proof of this apparently simple fact? Edit 1: All projections have the same range. Edit 2: The statement in the paper is that there always exists a projection of the smallest norm on a fixed finite dimensional subspace (the inf is attained), and that it follows from a ""compactness argument"". I wrongly assumed that the set of projections must be compact (thank you Martin). I think what is enough is to consider the set of projection with norm smaller than dimension of the finite dimensional subspace. Is the set compact in this case? If it is, it will prove the claim, as the continuous function $P\to\|P\|$ would attain the minimum on this set.",,"['functional-analysis', 'operator-theory']"
15,"Determining if the span of a set is dense in $L^2(0,1)$",Determining if the span of a set is dense in,"L^2(0,1)","I am trying to determine whether or not the following statement is true: If $f \in L^2(0,1)$ and $\int_0^1 x^nf(x) = 0$ for all positive integers $n$.  Then $f(x) = 0$ I have already verified this when $L^2(0,1)$ is replaced with $C[0,1]$ and I believe that it continues to hold in this case. My thought as far as $L^2(0,1)$ goes is to treat it as a Hilbert space. (Maybe this is the wrong approach?)  We can rephrase in terms of inner products: If $f \in L^2(0,1)$ and $<f,x^n> = 0$ for all positive integers $n$, then $f(x)=0$ Let $S = \{x^n\}_{n=1}^{\infty}$.  Then we can rephrase the statement: If $f \in L^2(0,1)$ and $f \in S^\perp$, then $f=0$ Equivalently $S^\perp = \{0\}$ Equivalently span($S$) is dense in $L^2(0,1)$ Now it seems very likely that this is in fact true since the span of $S$ is almost the set of all polynomials. The only polynomials not included in the span of $S$ would be the nonzero constant polynomials.  So it would seem that we have the following sequence of dense sets (I have not verified all of these so let me know if I am wrong).  Span of $S$ is dense in the polynomials on $(0,1)$ which are dense in $C(0,1)$ by Weierstrass's Theorem which is dense in $L^2(0,1)$.  And thus if all of these inclusions are true then the span of $S$ is dense in $L^2(0,1)$. So I would appreciate help in proving this sequence of dense subsets or if you can provide a counterexample that will be helpful also.  Or a suggestion on another more direct way to approach the question would be nice. Thanks in advance!","I am trying to determine whether or not the following statement is true: If $f \in L^2(0,1)$ and $\int_0^1 x^nf(x) = 0$ for all positive integers $n$.  Then $f(x) = 0$ I have already verified this when $L^2(0,1)$ is replaced with $C[0,1]$ and I believe that it continues to hold in this case. My thought as far as $L^2(0,1)$ goes is to treat it as a Hilbert space. (Maybe this is the wrong approach?)  We can rephrase in terms of inner products: If $f \in L^2(0,1)$ and $<f,x^n> = 0$ for all positive integers $n$, then $f(x)=0$ Let $S = \{x^n\}_{n=1}^{\infty}$.  Then we can rephrase the statement: If $f \in L^2(0,1)$ and $f \in S^\perp$, then $f=0$ Equivalently $S^\perp = \{0\}$ Equivalently span($S$) is dense in $L^2(0,1)$ Now it seems very likely that this is in fact true since the span of $S$ is almost the set of all polynomials. The only polynomials not included in the span of $S$ would be the nonzero constant polynomials.  So it would seem that we have the following sequence of dense sets (I have not verified all of these so let me know if I am wrong).  Span of $S$ is dense in the polynomials on $(0,1)$ which are dense in $C(0,1)$ by Weierstrass's Theorem which is dense in $L^2(0,1)$.  And thus if all of these inclusions are true then the span of $S$ is dense in $L^2(0,1)$. So I would appreciate help in proving this sequence of dense subsets or if you can provide a counterexample that will be helpful also.  Or a suggestion on another more direct way to approach the question would be nice. Thanks in advance!",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
16,"Vector spaces isomorphic, then dual spaces isomorphic","Vector spaces isomorphic, then dual spaces isomorphic",,"If we know that there is a (topological) isomorphism between two Banach spaces $X,Y$ called $\phi \in L(X,Y)$. Then the appropriate isomorphism between the dual spaces $X',Y'$ is given by $\phi' \in L(Y',X')$. I was wondering: What is the fastest way to see that this $ \phi'$ is actually an isomorphism? Does anybody here have a good idea to show this fast? I mean sure, you could show that it is onto and injective, but this does not seem to be a fast idea.","If we know that there is a (topological) isomorphism between two Banach spaces $X,Y$ called $\phi \in L(X,Y)$. Then the appropriate isomorphism between the dual spaces $X',Y'$ is given by $\phi' \in L(Y',X')$. I was wondering: What is the fastest way to see that this $ \phi'$ is actually an isomorphism? Does anybody here have a good idea to show this fast? I mean sure, you could show that it is onto and injective, but this does not seem to be a fast idea.",,"['real-analysis', 'linear-algebra']"
17,On the convexity of a particular form of integrals,On the convexity of a particular form of integrals,,"EDIT: I made some critical corrections below. Let $\mathcal{H}\colon\mathbf{w}\cdot\mathbf{x}+c=0$ be a hypeplane in $\mathbb{R}^n$. Also, let $g\colon\mathbb{R}^n\to\mathbb{R}_+$, be a non-negative, real-valued function. I would like to decide on the convexity of the function $f\colon\mathbb{R}^n\times\mathbb{R}\to\mathbb{R}$, given by $$ f(\mathbf{a},b)=\int_{\Omega}\! (\mathbf{a}\cdot\mathbf{x}+b)g(\mathbf{x}) \,\mathrm{d}\mathbf{x}, $$ where $\mathbf{x}\in\mathbb{R}^n$, $b\in\mathbb{R}$, and $\Omega$ is the half-space defined by $\mathcal{H}$ as $\Omega=\{\mathbf{x}\in\mathbb{R}^n\rvert\mathbf{w}\cdot\mathbf{x}+c\geq0\}$. What I have thought so far is to express the integral as a sum (if such a thing is feasible) and use the property of the affine (and consequently convex) quantity $(\mathbf{a}\cdot\mathbf{x}+b)\cdot k$, where $k\in\mathbb{R}$. Albeit, I am not sure at all this is going to work. In addition, I am not sure in what direction should I work to... Is there any appropriate argument I could use instead?","EDIT: I made some critical corrections below. Let $\mathcal{H}\colon\mathbf{w}\cdot\mathbf{x}+c=0$ be a hypeplane in $\mathbb{R}^n$. Also, let $g\colon\mathbb{R}^n\to\mathbb{R}_+$, be a non-negative, real-valued function. I would like to decide on the convexity of the function $f\colon\mathbb{R}^n\times\mathbb{R}\to\mathbb{R}$, given by $$ f(\mathbf{a},b)=\int_{\Omega}\! (\mathbf{a}\cdot\mathbf{x}+b)g(\mathbf{x}) \,\mathrm{d}\mathbf{x}, $$ where $\mathbf{x}\in\mathbb{R}^n$, $b\in\mathbb{R}$, and $\Omega$ is the half-space defined by $\mathcal{H}$ as $\Omega=\{\mathbf{x}\in\mathbb{R}^n\rvert\mathbf{w}\cdot\mathbf{x}+c\geq0\}$. What I have thought so far is to express the integral as a sum (if such a thing is feasible) and use the property of the affine (and consequently convex) quantity $(\mathbf{a}\cdot\mathbf{x}+b)\cdot k$, where $k\in\mathbb{R}$. Albeit, I am not sure at all this is going to work. In addition, I am not sure in what direction should I work to... Is there any appropriate argument I could use instead?",,"['integration', 'functional-analysis', 'convex-analysis', 'locally-convex-spaces']"
18,I would like to show that $\ell^1$ is separable,I would like to show that  is separable,\ell^1,"So here is my question, I want to prove that $\ell^1$ is separable. So i need to show that there exists a countable dense subset in $\ell^1$. Since I am not sure if my idea was right i hoped someone could look over my proof. My idea was, Let $Q:=\{(x_n)\subset\mathbb Q:\exists j\in\mathbb N $ s.t $ \forall n\geq j:x_n=0\}$. Clearly $Q$ is countable so it is left to show that $Q$ is dense in $\ell^1$. For that we will show that for all $x\in\ell^1\backslash A$ we have, $$\{y\in\ell^1:\|x-y\|_{\ell^1}=\sum_{n=1}^{\infty}|x_n-y_n|<\epsilon\}=:B_{\epsilon}(x)\bigcap A\neq\emptyset$$ for an arbitrary $\epsilon>0$. Notice that there exists $n_0\in\mathbb N :\sum_{n=n_0}^{\infty}|x_n|<\epsilon/2$.  Furthermore since $\mathbb Q$ is dense in $\mathbb R$, for every $x_j$ with $j\in\{1,...,n_0-1\}$ we can find $q_j\in\mathbb Q$ s.t $|x_j-q_j|<\frac{\epsilon}{(n_0-1)2}$. For this $q_j$'s we define, $$(q_n):=(q_1,...,q_{n_0-1},0,0,...)\in A$$ Since, $$\|x-q\|=\sum_{n=1}^{\infty}|x_n-q_n|=\sum_{n=1}^{n_0-1}|x_n-q_n|+\sum_{n=n_0}^{\infty}|x_n|<(n_0-1)\frac{\epsilon}{(n_0-1)2}+\epsilon/2=\epsilon$$ it follows that $\overline{A}=\ell^1$ what proves that $\ell^1$ is separble. Since I am not sure if there is no mistake I wanted to ask if someone could look over my prove and correct it if there are mistakes. Thanks a lot!","So here is my question, I want to prove that $\ell^1$ is separable. So i need to show that there exists a countable dense subset in $\ell^1$. Since I am not sure if my idea was right i hoped someone could look over my proof. My idea was, Let $Q:=\{(x_n)\subset\mathbb Q:\exists j\in\mathbb N $ s.t $ \forall n\geq j:x_n=0\}$. Clearly $Q$ is countable so it is left to show that $Q$ is dense in $\ell^1$. For that we will show that for all $x\in\ell^1\backslash A$ we have, $$\{y\in\ell^1:\|x-y\|_{\ell^1}=\sum_{n=1}^{\infty}|x_n-y_n|<\epsilon\}=:B_{\epsilon}(x)\bigcap A\neq\emptyset$$ for an arbitrary $\epsilon>0$. Notice that there exists $n_0\in\mathbb N :\sum_{n=n_0}^{\infty}|x_n|<\epsilon/2$.  Furthermore since $\mathbb Q$ is dense in $\mathbb R$, for every $x_j$ with $j\in\{1,...,n_0-1\}$ we can find $q_j\in\mathbb Q$ s.t $|x_j-q_j|<\frac{\epsilon}{(n_0-1)2}$. For this $q_j$'s we define, $$(q_n):=(q_1,...,q_{n_0-1},0,0,...)\in A$$ Since, $$\|x-q\|=\sum_{n=1}^{\infty}|x_n-q_n|=\sum_{n=1}^{n_0-1}|x_n-q_n|+\sum_{n=n_0}^{\infty}|x_n|<(n_0-1)\frac{\epsilon}{(n_0-1)2}+\epsilon/2=\epsilon$$ it follows that $\overline{A}=\ell^1$ what proves that $\ell^1$ is separble. Since I am not sure if there is no mistake I wanted to ask if someone could look over my prove and correct it if there are mistakes. Thanks a lot!",,"['functional-analysis', 'lp-spaces']"
19,Unit in the image of a cp map,Unit in the image of a cp map,,"This is another question which looks non-trivial to me. Suppose that we have a completely positive map $f\colon M_n \to M_m$ such that $f(a) = I_m$, the identity matrix on $M_m$. Is there a positive element $b\in M_n$ such that $f(b)=I_m$?","This is another question which looks non-trivial to me. Suppose that we have a completely positive map $f\colon M_n \to M_m$ such that $f(a) = I_m$, the identity matrix on $M_m$. Is there a positive element $b\in M_n$ such that $f(b)=I_m$?",,"['functional-analysis', 'operator-algebras']"
20,difference between weak* convergence and convergence,difference between weak* convergence and convergence,,"I am trying to prove the following: If $X$ is a finite-dimensional space, then for sequences $\left\{x_n\right\}\subseteq X$ and $\left\{f_n^*\right\}\subseteq X^*$, if there exists an $x\in X^*$ such that $x_n \rightharpoonup x$ and $f_n\stackrel{*}{\rightharpoonup} f$, then we have $x_n\rightarrow x$ and $f_n \rightarrow f$. I already figured out how to prove that weak convergence implies regular convergence: Suppose $x_n \rightharpoonup x$ and that $X$ is of finite dimension $m$. Let $\left\{e_1, \ldots, e_m\right\}$ be the basis of $X$. Then we can write any $x_n=\displaystyle \sum_{i=1}^m c_{i,n}e_i$ and $x=\displaystyle \sum_{i=1}^m c_ie_i$, where $c_{i,n}, c_i \in \mathbb{R}$. Let $\left\{f(e_1), \ldots , f(e_m)\right\}$ be the basis of $X^*$. Since $f(x_n)\rightarrow f(x)$ in $X^*$, this implies that  $$\left\|f(\sum_{i=1}^m c_{i,n}e_i)-f(\sum_{i=1}^m c_ie_i)\right\|=\left\|f(\sum_{i=1}^m (c_{i,n}-c_i)e_i) \right\| \rightarrow 0,$$ which is true if and only if $c_{i,n}\rightarrow c_i$ for all $i\in \left\{1, \ldots, m\right\}$. Thus, $\left\|x_n-x\right\|=\left\|\sum_{i=1}^m (c_{i,n}-c_i)e_i\right\|\leq \sum_{i=1}^m |c_{i,n}-c_i|\left\|e_i\right\| \rightarrow 0$, that is, $x_n \rightarrow x$. \ I don't know how to show that $f_n\stackrel{*}{\rightharpoonup} f$ implies $f_n \rightarrow f$ and I think it's mostly because I don't see the difference between the two. Can someone show me how to prove this? Thank you!","I am trying to prove the following: If $X$ is a finite-dimensional space, then for sequences $\left\{x_n\right\}\subseteq X$ and $\left\{f_n^*\right\}\subseteq X^*$, if there exists an $x\in X^*$ such that $x_n \rightharpoonup x$ and $f_n\stackrel{*}{\rightharpoonup} f$, then we have $x_n\rightarrow x$ and $f_n \rightarrow f$. I already figured out how to prove that weak convergence implies regular convergence: Suppose $x_n \rightharpoonup x$ and that $X$ is of finite dimension $m$. Let $\left\{e_1, \ldots, e_m\right\}$ be the basis of $X$. Then we can write any $x_n=\displaystyle \sum_{i=1}^m c_{i,n}e_i$ and $x=\displaystyle \sum_{i=1}^m c_ie_i$, where $c_{i,n}, c_i \in \mathbb{R}$. Let $\left\{f(e_1), \ldots , f(e_m)\right\}$ be the basis of $X^*$. Since $f(x_n)\rightarrow f(x)$ in $X^*$, this implies that  $$\left\|f(\sum_{i=1}^m c_{i,n}e_i)-f(\sum_{i=1}^m c_ie_i)\right\|=\left\|f(\sum_{i=1}^m (c_{i,n}-c_i)e_i) \right\| \rightarrow 0,$$ which is true if and only if $c_{i,n}\rightarrow c_i$ for all $i\in \left\{1, \ldots, m\right\}$. Thus, $\left\|x_n-x\right\|=\left\|\sum_{i=1}^m (c_{i,n}-c_i)e_i\right\|\leq \sum_{i=1}^m |c_{i,n}-c_i|\left\|e_i\right\| \rightarrow 0$, that is, $x_n \rightarrow x$. \ I don't know how to show that $f_n\stackrel{*}{\rightharpoonup} f$ implies $f_n \rightarrow f$ and I think it's mostly because I don't see the difference between the two. Can someone show me how to prove this? Thank you!",,"['real-analysis', 'linear-algebra', 'analysis', 'functional-analysis']"
21,"""$L^\infty$ in the sense of distributions""",""" in the sense of distributions""",L^\infty,"The following is Exercise 3 of Chapter 3 in Stein & Shakarchi Book 4: Show that a bounded function $f$ on $\mathbb{R}^d$ satisfies a Lipschitz condition   $$|f(x)-f(y)| \leq C|x-y| \qquad\text{ for all } x,y\in\mathbb{R}^d,$$   if and only if $f\in L^\infty$ and all the first order partial derivatives $\partial f/\partial x^j$ ($1\leq j\leq d$), belong to $L^\infty$ in the sense of distributions. The right side of the $\Leftrightarrow$ doesn't make any sense to me. Of course we can take derivatives of $f$ in the sense of distributions, but what would it mean for a distribution to be $L^\infty$? The book doesn't make mention of it, and it looks like it could easily be a typo. My google search got me nothing, and I can't find errata for this book. Distributions are linear functions, so they can't strictly speaking have an $L^\infty$ norm in the usual sense. My best guess is that it's a bounded linear functional on $D(\Omega)$. Is this a common notation? Do any of you know what it might mean?","The following is Exercise 3 of Chapter 3 in Stein & Shakarchi Book 4: Show that a bounded function $f$ on $\mathbb{R}^d$ satisfies a Lipschitz condition   $$|f(x)-f(y)| \leq C|x-y| \qquad\text{ for all } x,y\in\mathbb{R}^d,$$   if and only if $f\in L^\infty$ and all the first order partial derivatives $\partial f/\partial x^j$ ($1\leq j\leq d$), belong to $L^\infty$ in the sense of distributions. The right side of the $\Leftrightarrow$ doesn't make any sense to me. Of course we can take derivatives of $f$ in the sense of distributions, but what would it mean for a distribution to be $L^\infty$? The book doesn't make mention of it, and it looks like it could easily be a typo. My google search got me nothing, and I can't find errata for this book. Distributions are linear functions, so they can't strictly speaking have an $L^\infty$ norm in the usual sense. My best guess is that it's a bounded linear functional on $D(\Omega)$. Is this a common notation? Do any of you know what it might mean?",,"['functional-analysis', 'distribution-theory']"
22,Orthogonal representation of finite operator,Orthogonal representation of finite operator,,"I would like to know if my proof is correct. Statement: Let $T$ be a finite rank operator on a Hilbert space $\mathscr{H}$. Show that $\forall \, h \, \in \mathscr{H}, \, T(h)$ can be written as $T(h) = \sum_{i=1}^n\langle h, e_i \rangle f_i$ where $\{e_i\}$ is an orthonormal basis of $\mathscr{H}$ Attempted Proof: $T(h)$ can be written as $T(h) = \sum_{i=1}^n\langle T(h), e_i \rangle e_i = \sum_{i=1}^n\langle h, T^*(e_i) \rangle e_i$. Now, if we let $f_i=T^*(e_i)$ then: $T(h) = \sum_{i=1}^n\langle T(h), e_i \rangle e_i = \sum_{i=1}^n\langle h, T^*(e_i) \rangle e_i = \sum_{i=1}^n\langle h, f_i \rangle e_i$ And this is where I get stuck.","I would like to know if my proof is correct. Statement: Let $T$ be a finite rank operator on a Hilbert space $\mathscr{H}$. Show that $\forall \, h \, \in \mathscr{H}, \, T(h)$ can be written as $T(h) = \sum_{i=1}^n\langle h, e_i \rangle f_i$ where $\{e_i\}$ is an orthonormal basis of $\mathscr{H}$ Attempted Proof: $T(h)$ can be written as $T(h) = \sum_{i=1}^n\langle T(h), e_i \rangle e_i = \sum_{i=1}^n\langle h, T^*(e_i) \rangle e_i$. Now, if we let $f_i=T^*(e_i)$ then: $T(h) = \sum_{i=1}^n\langle T(h), e_i \rangle e_i = \sum_{i=1}^n\langle h, T^*(e_i) \rangle e_i = \sum_{i=1}^n\langle h, f_i \rangle e_i$ And this is where I get stuck.",,"['analysis', 'functional-analysis', 'proof-verification', 'hilbert-spaces']"
23,An exercise about nuclear map Von Neumann algebra,An exercise about nuclear map Von Neumann algebra,,"There is a quotation below: Let $M\subset B(H)$ be a von Neumann algebra and $\{P_{i}\}_{i\in L}$ be a net of finite-rank projections which increases to the identity (in the strong operator topology). If $P_{i}$ has rank $k(i)$, then we define contractive completely positive $$\phi_{i}:M\rightarrow M_{k(i)}(\mathbb{C})\cong P_{i}B(H)P_{i}$$ by compression (i.e., $\phi_{i}(T)=P_{i}TP_{i}$) and we let $$\psi_{i}: M_{k(i)}(\mathbb{C})\rightarrow B(H)$$  be the natural inclusion maps. Since the predual of $B(H)$ is the trace class operators, a routine exercise shows that the maps $\psi_{i}\circ\phi_{i}$ converge to the identity (on all of $B(H)$, in fact) in the point-ultraweak topology. I do know the how to do the ""so call"" routine exercise. Could someone give me some hints or show me more details?","There is a quotation below: Let $M\subset B(H)$ be a von Neumann algebra and $\{P_{i}\}_{i\in L}$ be a net of finite-rank projections which increases to the identity (in the strong operator topology). If $P_{i}$ has rank $k(i)$, then we define contractive completely positive $$\phi_{i}:M\rightarrow M_{k(i)}(\mathbb{C})\cong P_{i}B(H)P_{i}$$ by compression (i.e., $\phi_{i}(T)=P_{i}TP_{i}$) and we let $$\psi_{i}: M_{k(i)}(\mathbb{C})\rightarrow B(H)$$  be the natural inclusion maps. Since the predual of $B(H)$ is the trace class operators, a routine exercise shows that the maps $\psi_{i}\circ\phi_{i}$ converge to the identity (on all of $B(H)$, in fact) in the point-ultraweak topology. I do know the how to do the ""so call"" routine exercise. Could someone give me some hints or show me more details?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
24,An exercise on nuclear maps in C*-algebra,An exercise on nuclear maps in C*-algebra,,"Definition 2.1.1 Let $A, B$ be the C*-algebra, a map $\theta: A\rightarrow B$ is called nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}:M_{k(n)}(\mathbb{C}) \rightarrow B$ such that  $$||\psi_{n}\circ\phi_{n}(a)-\theta(a)||\rightarrow0$$ for all $a\in A$. Then, there is an exercise below( I do not know how to do the exercise): Exercise 2.1.1 Show that $\theta:A \rightarrow B$ is nuclear if and only if for each finite set $F\subset A$ and $\varepsilon>0$ there exsit $n\in \mathbb{N}$ and contractive completely positive maps $\phi: A\rightarrow M_{n}(\mathbb{C})$, $\psi:M_{n}(\mathbb{C})\rightarrow B$ such that $||\theta(a)-\psi\circ\phi(a)||<\varepsilon$ for all $a\in F$. I suppose the ""if"" is clear from the definition. But how to prove the ""only if""? I guess we need to use the finite set to construct a sequence of contractive completely positive map (just as in the definition.)","Definition 2.1.1 Let $A, B$ be the C*-algebra, a map $\theta: A\rightarrow B$ is called nuclear if there exist contractive completely positive maps $\phi_{n}: A\rightarrow M_{k(n)}(\mathbb{C})$ and $\psi_{n}:M_{k(n)}(\mathbb{C}) \rightarrow B$ such that  $$||\psi_{n}\circ\phi_{n}(a)-\theta(a)||\rightarrow0$$ for all $a\in A$. Then, there is an exercise below( I do not know how to do the exercise): Exercise 2.1.1 Show that $\theta:A \rightarrow B$ is nuclear if and only if for each finite set $F\subset A$ and $\varepsilon>0$ there exsit $n\in \mathbb{N}$ and contractive completely positive maps $\phi: A\rightarrow M_{n}(\mathbb{C})$, $\psi:M_{n}(\mathbb{C})\rightarrow B$ such that $||\theta(a)-\psi\circ\phi(a)||<\varepsilon$ for all $a\in F$. I suppose the ""if"" is clear from the definition. But how to prove the ""only if""? I guess we need to use the finite set to construct a sequence of contractive completely positive map (just as in the definition.)",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
25,Projection operator in Hilbert space,Projection operator in Hilbert space,,"Let $H$ be a Hilbert space, can we find an increasing net of finite rank projections which converge to the identity in the strong operator topology? And I think if $H$ is separable, we can find an orthonormal basis $\{v_{n}\}_{n=1}^{\infty}$ and let $p_{n}$ be the projection (from $H$) onto span$\{v_{1}, ..., v_{n}\}$. Then, we can verify $||p_{n}x-x||\rightarrow 0$ for all $x\in H$. But what about the case that $H$ is not separable ?","Let $H$ be a Hilbert space, can we find an increasing net of finite rank projections which converge to the identity in the strong operator topology? And I think if $H$ is separable, we can find an orthonormal basis $\{v_{n}\}_{n=1}^{\infty}$ and let $p_{n}$ be the projection (from $H$) onto span$\{v_{1}, ..., v_{n}\}$. Then, we can verify $||p_{n}x-x||\rightarrow 0$ for all $x\in H$. But what about the case that $H$ is not separable ?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'operator-algebras']"
26,"$g, f, \hat {f} \in L^{1}(\mathbb R)\cap L^{2}(\mathbb R) \cap C_{0}(\mathbb R) \implies \widehat{(fg)}= \hat{f} \ast \hat{g} ? $",,"g, f, \hat {f} \in L^{1}(\mathbb R)\cap L^{2}(\mathbb R) \cap C_{0}(\mathbb R) \implies \widehat{(fg)}= \hat{f} \ast \hat{g} ? ","Let $f, g\in L^{1}(\mathbb R)$ and it Fourier transform of $f$, $\hat{f} (y)  = \int _ {\mathbb R} f(x) e^{-2\pi i x \cdot y} dx, \ (y\in \mathbb R)$ and the convolution of $f $ and $g$;  $f\ast g (x)= \int_{\mathbb R} f(y) g(x-y) dy, \ (x\in \mathbb R); $ whenever this integral exists. It is well-known that, (1)If $f, g \in L^{1}(\mathbb R)$, then $\widehat{(f\ast g)} = \hat{f}\cdot \hat{g}.$ (2) If $f, g, \hat{f}, \hat{g} \in L^{1}(\mathbb R)$, then, by inversion formula, and using above relation in (1), we get, $\widehat{(fg)}= \hat{f}\ast \hat{g}.$  [Indeed, Fourier inversion formula gives us, $\widehat{(\hat{f})}(x) =f(-x)$; and we put, $\check{f}(x)= f(-x)$ and $\Phi(f)=\hat{f}$; now we using  relation in (1), by $\hat{f}$ and $\hat{g}$, in place of $f$ and $g$, we get $\Phi(\hat {f}\ast \hat{g})= \Phi(\hat{f})\cdot\Phi(\hat{g})= \Phi^{2}(f)\cdot\Phi^{2}(g) =\check{f}\check{g}= \check{(fg)}= \Phi^{2}(fg)$; now applying $\Phi^{-1}$ both side, we get, $\widehat{(fg)}= \hat{f}\ast \hat{g}.$] My question : Let $g\in L^{1}(\mathbb R)\cap L^{2}(\mathbb R) \cap C_{0}(\mathbb R) $ and $f, \hat{f} \in L^{1}(\mathbb R).$    (A) Can we expect $\widehat{(fg)}= \hat{f} \ast \hat{g}$ ? (B) If not, firstly, can we produce counter example, secondly, what optimal(minimal) condition, one can think of on $g$, so this formula will be valid ? (where $C_{0} (\mathbb R)=\{f:\mathbb R \to \mathbb C: f \text { is continuous on} \ \mathbb R \  \text  {and } \lim_{|x|\to \pm \infty}f(x)=0 \}$) (We notice that, by Plancherel theorem, we can say $\hat{g} \in L^{2}(\mathbb R)$; and hence, by Young's inequality, we get, $\hat{f}\ast \hat{g} \in L^{2} (\mathbb R)$) ;Thanks,","Let $f, g\in L^{1}(\mathbb R)$ and it Fourier transform of $f$, $\hat{f} (y)  = \int _ {\mathbb R} f(x) e^{-2\pi i x \cdot y} dx, \ (y\in \mathbb R)$ and the convolution of $f $ and $g$;  $f\ast g (x)= \int_{\mathbb R} f(y) g(x-y) dy, \ (x\in \mathbb R); $ whenever this integral exists. It is well-known that, (1)If $f, g \in L^{1}(\mathbb R)$, then $\widehat{(f\ast g)} = \hat{f}\cdot \hat{g}.$ (2) If $f, g, \hat{f}, \hat{g} \in L^{1}(\mathbb R)$, then, by inversion formula, and using above relation in (1), we get, $\widehat{(fg)}= \hat{f}\ast \hat{g}.$  [Indeed, Fourier inversion formula gives us, $\widehat{(\hat{f})}(x) =f(-x)$; and we put, $\check{f}(x)= f(-x)$ and $\Phi(f)=\hat{f}$; now we using  relation in (1), by $\hat{f}$ and $\hat{g}$, in place of $f$ and $g$, we get $\Phi(\hat {f}\ast \hat{g})= \Phi(\hat{f})\cdot\Phi(\hat{g})= \Phi^{2}(f)\cdot\Phi^{2}(g) =\check{f}\check{g}= \check{(fg)}= \Phi^{2}(fg)$; now applying $\Phi^{-1}$ both side, we get, $\widehat{(fg)}= \hat{f}\ast \hat{g}.$] My question : Let $g\in L^{1}(\mathbb R)\cap L^{2}(\mathbb R) \cap C_{0}(\mathbb R) $ and $f, \hat{f} \in L^{1}(\mathbb R).$    (A) Can we expect $\widehat{(fg)}= \hat{f} \ast \hat{g}$ ? (B) If not, firstly, can we produce counter example, secondly, what optimal(minimal) condition, one can think of on $g$, so this formula will be valid ? (where $C_{0} (\mathbb R)=\{f:\mathbb R \to \mathbb C: f \text { is continuous on} \ \mathbb R \  \text  {and } \lim_{|x|\to \pm \infty}f(x)=0 \}$) (We notice that, by Plancherel theorem, we can say $\hat{g} \in L^{2}(\mathbb R)$; and hence, by Young's inequality, we get, $\hat{f}\ast \hat{g} \in L^{2} (\mathbb R)$) ;Thanks,",,"['functional-analysis', 'fourier-analysis', 'lp-spaces', 'convolution', 'harmonic-analysis']"
27,"If $u_m \rightharpoonup u$, how to show using monotonicity that $f(u_m) \rightharpoonup f(u)$?","If , how to show using monotonicity that ?",u_m \rightharpoonup u f(u_m) \rightharpoonup f(u),"Let  $$u_m \rightharpoonup u \quad \text{(weakly) in $L^\infty(0,T;L^2(\Omega)) \cap L^2(0,T;H^1(\Omega))$}.$$ We are given $f:\mathbb R \to \mathbb R$, a Lipschitz continuous invertible map which is monotone: $$(f(x)-f(y))(x-y) \geq 0\quad\text{for all $x, y$}$$ and satisfies $f'> 0$. Suppose we have $$f(u_m) \rightharpoonup f(v) \quad \text{in $L^2(0,T;H^1(\Omega))$}$$ for some $v \in L^2(0,T;H^1(\Omega))$ (assume that for $u \in L^2(0,T;H^1)$, $f(u)$ and $f^{-1}(u)$ are in $L^2(0,T;H^{1}(\Omega))$.) Is it possible to show that indeed $v=u$, i.e. $f(u_m) \rightharpoonup f(u)$? I can't seem to do it by using the monotonicity method. (Despite posting this on MO I still did not solve this problem)","Let  $$u_m \rightharpoonup u \quad \text{(weakly) in $L^\infty(0,T;L^2(\Omega)) \cap L^2(0,T;H^1(\Omega))$}.$$ We are given $f:\mathbb R \to \mathbb R$, a Lipschitz continuous invertible map which is monotone: $$(f(x)-f(y))(x-y) \geq 0\quad\text{for all $x, y$}$$ and satisfies $f'> 0$. Suppose we have $$f(u_m) \rightharpoonup f(v) \quad \text{in $L^2(0,T;H^1(\Omega))$}$$ for some $v \in L^2(0,T;H^1(\Omega))$ (assume that for $u \in L^2(0,T;H^1)$, $f(u)$ and $f^{-1}(u)$ are in $L^2(0,T;H^{1}(\Omega))$.) Is it possible to show that indeed $v=u$, i.e. $f(u_m) \rightharpoonup f(u)$? I can't seem to do it by using the monotonicity method. (Despite posting this on MO I still did not solve this problem)",,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'sobolev-spaces', 'bochner-spaces']"
28,Weighted Dirac comb as a tempered distribution?,Weighted Dirac comb as a tempered distribution?,,"I'm trying to determine when a ""weighted"" Dirac comb is a tempered distribution. More precisely, trying to prove: $$u=\sum_{k=1}^{\infty}c_k \delta_k\in\mathcal{S}'(\mathbb{R})\iff\exists N\in\mathbb{N},\,\exists B>0:\forall k\in\mathbb{N},\,|c_k|\leq Bk^N$$ I have managed to prove the $\Leftarrow$ direction by showing that $u$ would be a linear functional which is sequentially continuous, so clearly an element of $\mathcal{S}'(\mathbb{R})$. However, I'm struggling with the remaining implication ($\Rightarrow$), which I intuitively believe to be correct. My idea was to proceed by contradiction: assume $\forall N\in\mathbb{N},\,\forall B>0,\,\exists k\in\mathbb{N}:|c_k|> Bk^N$ and then try to find a $\phi\in\mathcal{S}(\mathbb{R})$ such that $|u(\phi)|=|\sum_{k=1}^{\infty}c_k\phi(k)|=\infty$, which would then imply that $u\notin\mathcal{S}'(\mathbb{R})$. Unfortunately this has not gotten me very far. Any ideas?","I'm trying to determine when a ""weighted"" Dirac comb is a tempered distribution. More precisely, trying to prove: $$u=\sum_{k=1}^{\infty}c_k \delta_k\in\mathcal{S}'(\mathbb{R})\iff\exists N\in\mathbb{N},\,\exists B>0:\forall k\in\mathbb{N},\,|c_k|\leq Bk^N$$ I have managed to prove the $\Leftarrow$ direction by showing that $u$ would be a linear functional which is sequentially continuous, so clearly an element of $\mathcal{S}'(\mathbb{R})$. However, I'm struggling with the remaining implication ($\Rightarrow$), which I intuitively believe to be correct. My idea was to proceed by contradiction: assume $\forall N\in\mathbb{N},\,\forall B>0,\,\exists k\in\mathbb{N}:|c_k|> Bk^N$ and then try to find a $\phi\in\mathcal{S}(\mathbb{R})$ such that $|u(\phi)|=|\sum_{k=1}^{\infty}c_k\phi(k)|=\infty$, which would then imply that $u\notin\mathcal{S}'(\mathbb{R})$. Unfortunately this has not gotten me very far. Any ideas?",,"['analysis', 'functional-analysis', 'distribution-theory', 'schwartz-space', 'dirac-delta']"
29,How to find adjoint operator?,How to find adjoint operator?,,"Let $(X,\langle\cdot,\cdot\rangle)$ be a Hilbert Space over $K$ with orthonormal basis $(x_n)$, and let $(\lambda_n)\in K$ be a bounded sequence. The mapping $T:X\to X$ is defined by $Tx:=\sum\limits_{n=1}^\infty\lambda_n\langle x,x_n\rangle x_n$, $x\in X$. Find the adjoint operator $T^*$ of $T$.","Let $(X,\langle\cdot,\cdot\rangle)$ be a Hilbert Space over $K$ with orthonormal basis $(x_n)$, and let $(\lambda_n)\in K$ be a bounded sequence. The mapping $T:X\to X$ is defined by $Tx:=\sum\limits_{n=1}^\infty\lambda_n\langle x,x_n\rangle x_n$, $x\in X$. Find the adjoint operator $T^*$ of $T$.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
30,Example for weak convergence in $L^2(\mathbb{R}^n)$-Norm,Example for weak convergence in -Norm,L^2(\mathbb{R}^n),"We had in the lecture the following example for weak convergence to 0: $f_k(x) = {k^{-n/2}} f(x/k)$, where $f \in C^\infty (\mathbb{R}^n)$  fixed and $f$ has support in the unit ball $B_1(0)$. Somehow I don't see why that is true. I tried to use Hölder but did not get the desired result. I'd be happy to get some hints (I think the $n=1$ case suffices).","We had in the lecture the following example for weak convergence to 0: $f_k(x) = {k^{-n/2}} f(x/k)$, where $f \in C^\infty (\mathbb{R}^n)$  fixed and $f$ has support in the unit ball $B_1(0)$. Somehow I don't see why that is true. I tried to use Hölder but did not get the desired result. I'd be happy to get some hints (I think the $n=1$ case suffices).",,"['functional-analysis', 'lp-spaces', 'weak-convergence']"
31,"Metric Space, Normed Space, and Inner Product space hierarcy","Metric Space, Normed Space, and Inner Product space hierarcy",,"I'm having trouble understanding the intuition of the hierarchy of metric space, normed space, and inner product space. What additional structure do I gain at every level? I'm going to list my understanding, I hope others can either fill in more detail or verify that my understanding is correct. Ok: A metric space gives me a notion of distance A normed space introduces a metric to a VS. So it buys me a notion of vector magnitude. An inner product space enforces a particular norm. This norm, by virtue of being an inner product space, is also a linear functional. I can explicitly leverage my notion of magnitude with my linear functional to build a description of my VS (e.g. compute basis vectors, compute dimension, etc.). I had no way to do this before. Essentially, I have some generic dot product. is this right?","I'm having trouble understanding the intuition of the hierarchy of metric space, normed space, and inner product space. What additional structure do I gain at every level? I'm going to list my understanding, I hope others can either fill in more detail or verify that my understanding is correct. Ok: A metric space gives me a notion of distance A normed space introduces a metric to a VS. So it buys me a notion of vector magnitude. An inner product space enforces a particular norm. This norm, by virtue of being an inner product space, is also a linear functional. I can explicitly leverage my notion of magnitude with my linear functional to build a description of my VS (e.g. compute basis vectors, compute dimension, etc.). I had no way to do this before. Essentially, I have some generic dot product. is this right?",,"['functional-analysis', 'metric-spaces']"
32,A use of Hahn-Banach and Riesz Representation,A use of Hahn-Banach and Riesz Representation,,"Let $X$ be a compact Hausdorff topological space.  Suppose $X$ is not a singleton set and $C(X)$ denotes the space of continuous functions on $X$.  Do we have that for all $L \subset C(X)$ a nondense subspace, there exist two probability measures which agree in integration against all elements of $L$ but not on $C(X)$?  Here $L$ is assumed to contain the constants. (This last sentence was added after my comment, but before the answer.)","Let $X$ be a compact Hausdorff topological space.  Suppose $X$ is not a singleton set and $C(X)$ denotes the space of continuous functions on $X$.  Do we have that for all $L \subset C(X)$ a nondense subspace, there exist two probability measures which agree in integration against all elements of $L$ but not on $C(X)$?  Here $L$ is assumed to contain the constants. (This last sentence was added after my comment, but before the answer.)",,['functional-analysis']
33,Properties of the operator $T: f\to f*g$,Properties of the operator,T: f\to f*g,"Let g be the characteristic function of [-1/2,1/2]. $T: f\to f*g$ (convolution). I have managed to prove that T is a linear,bounded,self adjoint,injective operator and it's immage is inclused in the space $H^1(R)$. Can anyone help me to find out if  T is also compact/surjective? Thank you in advance.","Let g be the characteristic function of [-1/2,1/2]. $T: f\to f*g$ (convolution). I have managed to prove that T is a linear,bounded,self adjoint,injective operator and it's immage is inclused in the space $H^1(R)$. Can anyone help me to find out if  T is also compact/surjective? Thank you in advance.",,"['functional-analysis', 'operator-theory', 'convolution']"
34,Why is this quotient algebra contractible? (Blackadar 21.4.3),Why is this quotient algebra contractible? (Blackadar 21.4.3),,"I ran into this question when reading the proof of Theorem 21.4.3 in Bruce Blackadar, K-theory for Operator Algebras The question is as follows: Given $A$, $B$ Banach algebras, and a surjective homomorphism $q: A \to B$. Define $T=\{(f, g): g(0)=q(f(0))\} \subset C_0((-1, 0], A) \oplus C_0([0, 1), B)$. Then $T/C_0((0,1), B)$ is contractible. I know the algebra $T$ is kinda like glueing CA and CB along 0, but I don't know how does mod-ing out $C_0((0,1), B)$ help make thing contractible. Any hint / suggestion would be greatly appreciated! For those who are less familiar with the homotopy of Banach algebra homomorphism, here is the definition [Blackadar 5.2.2]: Two homomorphisms $\phi, \psi: A \to B$ are homotopic if there is a path of homomorphisms $w_t: A \to B$ for $0 \leq t \leq 1$, continuous in $t$ in the topology of pointwise norm-convergence, with $w_0=\phi$, $w_1=\psi$. This is equivalent to the existence of a homomorphism $w: A \to C([0, 1], B)$ with $\pi_0 \circ w = \phi$ and $\pi_1 \circ w =\psi$. An algebra $A$ is contractible if the identity map is homotopic to the 0 map.","I ran into this question when reading the proof of Theorem 21.4.3 in Bruce Blackadar, K-theory for Operator Algebras The question is as follows: Given $A$, $B$ Banach algebras, and a surjective homomorphism $q: A \to B$. Define $T=\{(f, g): g(0)=q(f(0))\} \subset C_0((-1, 0], A) \oplus C_0([0, 1), B)$. Then $T/C_0((0,1), B)$ is contractible. I know the algebra $T$ is kinda like glueing CA and CB along 0, but I don't know how does mod-ing out $C_0((0,1), B)$ help make thing contractible. Any hint / suggestion would be greatly appreciated! For those who are less familiar with the homotopy of Banach algebra homomorphism, here is the definition [Blackadar 5.2.2]: Two homomorphisms $\phi, \psi: A \to B$ are homotopic if there is a path of homomorphisms $w_t: A \to B$ for $0 \leq t \leq 1$, continuous in $t$ in the topology of pointwise norm-convergence, with $w_0=\phi$, $w_1=\psi$. This is equivalent to the existence of a homomorphism $w: A \to C([0, 1], B)$ with $\pi_0 \circ w = \phi$ and $\pi_1 \circ w =\psi$. An algebra $A$ is contractible if the identity map is homotopic to the 0 map.",,"['functional-analysis', 'banach-algebras']"
35,${\rm dist}_A (x)= \inf\limits_{y\in A}\|y-x\|$ is continuous in the weak topology?,is continuous in the weak topology?,{\rm dist}_A (x)= \inf\limits_{y\in A}\|y-x\|,For which Banach spaces $X$ the function ${\rm dist}_A (x)=\inf\limits_{y\in A} \| y-x\| $ is weak continuous for all weakly closed subsets of $X$ ? Can anyone give me any suggestion ? Thank you in advance.,For which Banach spaces $X$ the function ${\rm dist}_A (x)=\inf\limits_{y\in A} \| y-x\| $ is weak continuous for all weakly closed subsets of $X$ ? Can anyone give me any suggestion ? Thank you in advance.,,"['functional-analysis', 'weak-convergence']"
36,Using the Extension Operator Theorem for Sobolev Spaces,Using the Extension Operator Theorem for Sobolev Spaces,,"I want to know if certain conditions hold after applying the Sobolev Extension Theorem: Assume $U$ is a bounded open subset of $\mathbb{R}^{n}$ and $\partial U$ is $C^{1}$. Suppose $1 \leq p < n$. If we fix $1 \leq q < p^{*}$, where $p^{*}$ is the Sobolev conjugate of $p$, then since we also have that $U$ is bounded it follows from Nirenberg-Gagliardo-Sobolev Inequaity that $W^{1,p}(U) \subset L^{q}(U)$ and $||u||_{L^{q}(U)} \leq C||u||_{W^{1,p}(U)}$. If we consider the linear extension operator $P: W^{1,p}(U) \rightarrow W^{1,p}(\mathbb{R}^{n})$, then does the above assumptions still hold? In other words is the following true? $W^{1,p}(\mathbb{R}^{n}) \subset L^{q}(\mathbb{R}^{n})$ and the inequality $||Pu||_{L^{q}(\mathbb{R}^{n})} \leq C||Pu||_{W^{1,p}(\mathbb{R}^{n})}$. Thanks for any assistance.","I want to know if certain conditions hold after applying the Sobolev Extension Theorem: Assume $U$ is a bounded open subset of $\mathbb{R}^{n}$ and $\partial U$ is $C^{1}$. Suppose $1 \leq p < n$. If we fix $1 \leq q < p^{*}$, where $p^{*}$ is the Sobolev conjugate of $p$, then since we also have that $U$ is bounded it follows from Nirenberg-Gagliardo-Sobolev Inequaity that $W^{1,p}(U) \subset L^{q}(U)$ and $||u||_{L^{q}(U)} \leq C||u||_{W^{1,p}(U)}$. If we consider the linear extension operator $P: W^{1,p}(U) \rightarrow W^{1,p}(\mathbb{R}^{n})$, then does the above assumptions still hold? In other words is the following true? $W^{1,p}(\mathbb{R}^{n}) \subset L^{q}(\mathbb{R}^{n})$ and the inequality $||Pu||_{L^{q}(\mathbb{R}^{n})} \leq C||Pu||_{W^{1,p}(\mathbb{R}^{n})}$. Thanks for any assistance.",,"['functional-analysis', 'inequality', 'sobolev-spaces']"
37,"Convergence of the translation operator in $L^2(\mathbb{R}, e^{-x^2}dx)$",Convergence of the translation operator in,"L^2(\mathbb{R}, e^{-x^2}dx)","For $t \ge 0$, let $T_t : L^2(\mathbb{R}, e^{-x^2}dx) \to L^2(\mathbb{R}, e^{-x^2}dx)$ be the translation operator given by $f(x) \mapsto f(x + t)$. I would like to: Find the norm of $T_t$. Determine whether $T_t$ converges to an operator in the weak, strong, or uniform topologies, as $t \to \infty$. This is a homework problem, so I would appreciate suggestions and hints only. I have used this previous post, Convergence of translation operator , to help me answer this question when we consider $T_t$ as an operator $L^2(\mathbb{R}, dx) \to L^2(\mathbb{R}, dx)$. In this situation, $||T_t|| = 1$ and $T_t$ just converges weakly. But now I am finding the modified problem considerably harder. In fact, I'm even having trouble showing $T_t$ is bounded (i.e., $||f(x + t)||_{L^2(\mathbb{R}, e^{-x^2}dx)} \le C || f(x)||_{L^2(\mathbb{R}, e^{-x^2}dx)}$). Is there some clever way to rewrite $$\int_{\mathbb{R}}|f(x + t)|^2 e^{-x^2} dx$$ in terms of just $\int_{\mathbb{R}}|f(x)|^2 e^{-x^2} dx$? I think this is what I need to accomplish to the show the boundedness and get a handle on the norm of $T_t$. Also, any hints about convergence in the various topologies is greatly appreciated.","For $t \ge 0$, let $T_t : L^2(\mathbb{R}, e^{-x^2}dx) \to L^2(\mathbb{R}, e^{-x^2}dx)$ be the translation operator given by $f(x) \mapsto f(x + t)$. I would like to: Find the norm of $T_t$. Determine whether $T_t$ converges to an operator in the weak, strong, or uniform topologies, as $t \to \infty$. This is a homework problem, so I would appreciate suggestions and hints only. I have used this previous post, Convergence of translation operator , to help me answer this question when we consider $T_t$ as an operator $L^2(\mathbb{R}, dx) \to L^2(\mathbb{R}, dx)$. In this situation, $||T_t|| = 1$ and $T_t$ just converges weakly. But now I am finding the modified problem considerably harder. In fact, I'm even having trouble showing $T_t$ is bounded (i.e., $||f(x + t)||_{L^2(\mathbb{R}, e^{-x^2}dx)} \le C || f(x)||_{L^2(\mathbb{R}, e^{-x^2}dx)}$). Is there some clever way to rewrite $$\int_{\mathbb{R}}|f(x + t)|^2 e^{-x^2} dx$$ in terms of just $\int_{\mathbb{R}}|f(x)|^2 e^{-x^2} dx$? I think this is what I need to accomplish to the show the boundedness and get a handle on the norm of $T_t$. Also, any hints about convergence in the various topologies is greatly appreciated.",,"['functional-analysis', 'measure-theory']"
38,Spectral theorem for $n$-tuples of selfadjoint operators,Spectral theorem for -tuples of selfadjoint operators,n,"I need a 'good' reference to the following version of the Spectral Theorem: Given $n$ commuting selfadjoint operators on an infinite-dimensional Hilbert space, there exist a Borel measure $\mu$ on $\mathbb R^n$ and auxiliary Hilbert spaces $h(x)$ such that the construction is unitarily equivalent to $\int\oplus h(x)\,d\mu(x)$ with selfadjoint operators of multiplication by $x_k$, $k=1, \dots, n$. It is important that the construction be based on a measure in $\mathbb R^n$. Thanks in advance.","I need a 'good' reference to the following version of the Spectral Theorem: Given $n$ commuting selfadjoint operators on an infinite-dimensional Hilbert space, there exist a Borel measure $\mu$ on $\mathbb R^n$ and auxiliary Hilbert spaces $h(x)$ such that the construction is unitarily equivalent to $\int\oplus h(x)\,d\mu(x)$ with selfadjoint operators of multiplication by $x_k$, $k=1, \dots, n$. It is important that the construction be based on a measure in $\mathbb R^n$. Thanks in advance.",,"['functional-analysis', 'reference-request', 'spectral-theory']"
39,Closure of the range of a compact operator,Closure of the range of a compact operator,,"Let $X$ be an infinite-dimensional Banach space, and let $Y$ be a banach. Let $T$ be a compact operator from $X$ to $Y$, ie. if $(x_n)$ is a sequence in $X$ then there is a subsequence s.t. $T(x_{n(k)})$ converges. We wish to show that 0 is in the closure of $\{Tx,||x||=1\}$. I've been working on this problem for a while, and have been entirely unable to solve it without resorting to the spectral theorem, but I've been told there is an elementary solution involving only the fact that we can find a sequence of unit vectors $X$ s.t. that the distance between the elements is greater than or zero (ie. Riesz Lemma).","Let $X$ be an infinite-dimensional Banach space, and let $Y$ be a banach. Let $T$ be a compact operator from $X$ to $Y$, ie. if $(x_n)$ is a sequence in $X$ then there is a subsequence s.t. $T(x_{n(k)})$ converges. We wish to show that 0 is in the closure of $\{Tx,||x||=1\}$. I've been working on this problem for a while, and have been entirely unable to solve it without resorting to the spectral theorem, but I've been told there is an elementary solution involving only the fact that we can find a sequence of unit vectors $X$ s.t. that the distance between the elements is greater than or zero (ie. Riesz Lemma).",,"['functional-analysis', 'convergence-divergence', 'banach-spaces', 'compact-operators']"
40,"Two norms $\|\cdot\|_a$ and $\|\cdot\|_b$ on $X$, and a function $f:X\to Y$ Fréchet differentiable with one of the norms but not with the other one?","Two norms  and  on , and a function  Fréchet differentiable with one of the norms but not with the other one?",\|\cdot\|_a \|\cdot\|_b X f:X\to Y,"There is a theorem that if $f : (X,\|\cdot\|_{X1}) \to (Y,\|\cdot\|_{Y1}) $  is Fréchet differentiable, then replacing the norms with some equivalent norms $\|\cdot\|_{X2}$ and $\|\cdot\|_{Y2}$ preserves the differentiability. I was trying to construct an example where a function is not Fréchet differentiable anymore after replacing the norms with norms that aren't equivalent. The easiest example with not equivalent norms known to me is $\|x\|_\infty$ and $\|x\|_1$ on $C[0,1]$. Yet I can't think of any function, say, $f: C[0,1] \to \mathbb R$, that would be Fréchet differentiable with one of the norms but not with the other one. Any help with finding such an example (not necessarily with the above mentioned norms) is highly appreciated.","There is a theorem that if $f : (X,\|\cdot\|_{X1}) \to (Y,\|\cdot\|_{Y1}) $  is Fréchet differentiable, then replacing the norms with some equivalent norms $\|\cdot\|_{X2}$ and $\|\cdot\|_{Y2}$ preserves the differentiability. I was trying to construct an example where a function is not Fréchet differentiable anymore after replacing the norms with norms that aren't equivalent. The easiest example with not equivalent norms known to me is $\|x\|_\infty$ and $\|x\|_1$ on $C[0,1]$. Yet I can't think of any function, say, $f: C[0,1] \to \mathbb R$, that would be Fréchet differentiable with one of the norms but not with the other one. Any help with finding such an example (not necessarily with the above mentioned norms) is highly appreciated.",,"['real-analysis', 'functional-analysis', 'normed-spaces']"
41,Is space of measures Inner product space,Is space of measures Inner product space,,"Let $(X, \mathcal{F})$ be measurable space and let $\mathcal{M}$ be space of all signed measures on it. It is clear that, $\mathcal{M}$ is a Real vector space. I am interested to know if there is any non-trivial inner product on this space and can we make it as Hilbert space. Thanks","Let $(X, \mathcal{F})$ be measurable space and let $\mathcal{M}$ be space of all signed measures on it. It is clear that, $\mathcal{M}$ is a Real vector space. I am interested to know if there is any non-trivial inner product on this space and can we make it as Hilbert space. Thanks",,"['real-analysis', 'analysis', 'functional-analysis', 'measure-theory']"
42,Is this function Lebesgue integrable? [duplicate],Is this function Lebesgue integrable? [duplicate],,"This question already has an answer here : Is $\frac{1}x\cos\left(\frac{1}x\right)$ Lebesgue integrable on $[0,1]$? (1 answer) Closed 10 years ago . I have to decice if the following function is Lebesgue-integrable on $[0,1]$: $$g(x)=\frac{1}x\cos\left(\frac{1}x\right) $$ where $x\in[0,1]$. $g(x)$ is Lebesgue integrable if and only if the integral of $|g(x)|$ is finite So, $\int_{[0,1]} |\frac{1}x\cos\left(\frac{1}x\right)| dm < infinite???$ I don't know how to proof that, I have thought about using the monotone convergence theorem but I don't have any idea of how to define $f_n$ a sequence of measurable functions.","This question already has an answer here : Is $\frac{1}x\cos\left(\frac{1}x\right)$ Lebesgue integrable on $[0,1]$? (1 answer) Closed 10 years ago . I have to decice if the following function is Lebesgue-integrable on $[0,1]$: $$g(x)=\frac{1}x\cos\left(\frac{1}x\right) $$ where $x\in[0,1]$. $g(x)$ is Lebesgue integrable if and only if the integral of $|g(x)|$ is finite So, $\int_{[0,1]} |\frac{1}x\cos\left(\frac{1}x\right)| dm < infinite???$ I don't know how to proof that, I have thought about using the monotone convergence theorem but I don't have any idea of how to define $f_n$ a sequence of measurable functions.",,"['functional-analysis', 'measure-theory', 'lebesgue-integral']"
43,Upper Bound for Operator Norm in Marcinkiewicz Interpolation Theorem,Upper Bound for Operator Norm in Marcinkiewicz Interpolation Theorem,,"Exercise 1.3.3(c) Let $0<p_0<p<p_1<\infty$ and let $T$ be an operator as in Theorem 1.3.2($\|T(f)\|_{L^{p_0,\infty}(Y)}\leq A_0\|f\|_{L^{p_0}(X)}$ for all $f\in L^{p_0}(X)$ and $\|T(f)\|_{L^{p_1,\infty}(Y)}\leq A_1\|f\|_{L^{p_1}(X)}$ for all $f\in L^{p_1}(X)$) that also satisfies $|T(f)|\leq T(|f|)$, for all $f\in L^{p_0}+L^{p_1}$. (c) When $0<p_0<p_1<\infty$, then the norm of $T$ from $L^p$ to $L^p$ is at most \[\min_{0<\lambda<1}p^{\frac{1}{p}}\left(\frac{B(p-p_0,p_0+1)}{(1-\lambda)^{p_0}}+\frac{\frac{p_1-p+1}{p_1-p}}{\lambda^{p_1}}\right)^{\frac{1}{p}}A_0^{\frac{1/p-1/p_1}{1/p_0-1/p_1}}A_1^{\frac{1/p_0-1/p}{1/p_0-1/p_1}}\] where $B(s,t)$ is the Beta function. [Hint: When $p_1<\infty$ write $f=f_0+f_1$, where $f_0=f-\delta\alpha$ when $f\geq\delta\alpha$ and zero otherwise. Use that $|\{|T(f)|>\alpha\}|\leq|\{|T(f_0)|>(1-\lambda)\alpha\}|+|\{|T(f_1)|>\lambda\alpha\}|$ and optimize over $\delta>0$.] MY ATTEMPT:  From the hint, $f_0=\max(f-\delta\alpha,0)$ and $f_1=\min(f,\delta\alpha)$. We have \begin{align*} & d_{T(f)}(\alpha)\leq d_{T(f_0)}((1-\lambda)\alpha)+d_{T(f_1)}(\lambda\alpha)\\ \leq&\left(\frac{A_0}{(1-\lambda)\alpha}\right)^{p_0}\|f_0\|_{L^{p_0}}^{p_0}+\left(\frac{A_1}{\lambda\alpha}\right)^{p_1}\|f_1\|_{L^{p_1}}^{p_1}\\ =&\left(\frac{A_0}{(1-\lambda)\alpha}\right)^{p_0}\int_{f\leq\delta\alpha}(f-\delta\alpha)^{p_0}d\mu+\left(\frac{A_1}{\lambda\alpha}\right)^{p_1}\left[\int_{f>\delta\alpha}(\delta\alpha)^{p_1}d\mu+\int_{f\leq\delta\alpha}f^{p_1}d\mu\right] \end{align*} Hence, \begin{align*} &\|T(f)\|_{L^p}^p=\int_0^\infty p\alpha^{p-1}d_{T(f)}(\alpha)d\alpha\\ \leq&\left(\frac{A_0}{1-\lambda}\right)^{p_0}\int_0^\infty p\alpha^{p-p_0-1}\int_{f\leq\delta\alpha}(f-\delta\alpha)^{p_0}d\mu d\alpha\\ &+\left(\frac{A_1}{\lambda}\right)^{p_1}\left[\int_0^\infty p\alpha^{p-1}\int_{f>\delta\alpha}\delta^{p_1}d\mu d\alpha+\int_0^\infty p\alpha^{p-p_1-1}\int_{f\leq\delta\alpha}f^{p_1}d\mu d\alpha \right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\int_X\int_0^{f/\delta}f^{p_0}(1-\alpha\cdot\frac{\delta}{f})^{p_0}(\alpha\cdot\frac{\delta}{f})^{p-p_0-1}d(\alpha\cdot\frac{\delta}{f})(\frac{f}{\delta})^{p-p_0}d\mu\\ &+\left(\frac{A_1}{\lambda}\right)^{p_1}\left[\int_X\int_{f/\delta}^\infty p\alpha^{p-1}\delta^{p_1}d\alpha d\mu+\int_X f^{p_1}\int_{f/\delta}^\infty p\alpha^{p-p_1-1}d\alpha d\mu\right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\delta^{p_0-p}\|f\|_{L^p}^pB(p_0+1,p-p_0)+\frac{A_1^{p_1}}{\lambda^{p_1}}\left[\delta^{p_1-p}\|f\|_{L^p}^p+\frac{p}{p_1-p}\delta^{p_1-p}\|f\|_{L^p}^p\right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\delta^{p_0-p}\|f\|_{L^p}^pB(p_0+1,p-p_0)+\frac{p_1A_1^{p_1}}{(p_1-p)\lambda^{p_1}}\delta^{p_1-p}\|f\|_{L^p}^p \end{align*} when optimizing $\delta$ by taking derivatives of $\delta$, I cannot conclude the result.","Exercise 1.3.3(c) Let $0<p_0<p<p_1<\infty$ and let $T$ be an operator as in Theorem 1.3.2($\|T(f)\|_{L^{p_0,\infty}(Y)}\leq A_0\|f\|_{L^{p_0}(X)}$ for all $f\in L^{p_0}(X)$ and $\|T(f)\|_{L^{p_1,\infty}(Y)}\leq A_1\|f\|_{L^{p_1}(X)}$ for all $f\in L^{p_1}(X)$) that also satisfies $|T(f)|\leq T(|f|)$, for all $f\in L^{p_0}+L^{p_1}$. (c) When $0<p_0<p_1<\infty$, then the norm of $T$ from $L^p$ to $L^p$ is at most \[\min_{0<\lambda<1}p^{\frac{1}{p}}\left(\frac{B(p-p_0,p_0+1)}{(1-\lambda)^{p_0}}+\frac{\frac{p_1-p+1}{p_1-p}}{\lambda^{p_1}}\right)^{\frac{1}{p}}A_0^{\frac{1/p-1/p_1}{1/p_0-1/p_1}}A_1^{\frac{1/p_0-1/p}{1/p_0-1/p_1}}\] where $B(s,t)$ is the Beta function. [Hint: When $p_1<\infty$ write $f=f_0+f_1$, where $f_0=f-\delta\alpha$ when $f\geq\delta\alpha$ and zero otherwise. Use that $|\{|T(f)|>\alpha\}|\leq|\{|T(f_0)|>(1-\lambda)\alpha\}|+|\{|T(f_1)|>\lambda\alpha\}|$ and optimize over $\delta>0$.] MY ATTEMPT:  From the hint, $f_0=\max(f-\delta\alpha,0)$ and $f_1=\min(f,\delta\alpha)$. We have \begin{align*} & d_{T(f)}(\alpha)\leq d_{T(f_0)}((1-\lambda)\alpha)+d_{T(f_1)}(\lambda\alpha)\\ \leq&\left(\frac{A_0}{(1-\lambda)\alpha}\right)^{p_0}\|f_0\|_{L^{p_0}}^{p_0}+\left(\frac{A_1}{\lambda\alpha}\right)^{p_1}\|f_1\|_{L^{p_1}}^{p_1}\\ =&\left(\frac{A_0}{(1-\lambda)\alpha}\right)^{p_0}\int_{f\leq\delta\alpha}(f-\delta\alpha)^{p_0}d\mu+\left(\frac{A_1}{\lambda\alpha}\right)^{p_1}\left[\int_{f>\delta\alpha}(\delta\alpha)^{p_1}d\mu+\int_{f\leq\delta\alpha}f^{p_1}d\mu\right] \end{align*} Hence, \begin{align*} &\|T(f)\|_{L^p}^p=\int_0^\infty p\alpha^{p-1}d_{T(f)}(\alpha)d\alpha\\ \leq&\left(\frac{A_0}{1-\lambda}\right)^{p_0}\int_0^\infty p\alpha^{p-p_0-1}\int_{f\leq\delta\alpha}(f-\delta\alpha)^{p_0}d\mu d\alpha\\ &+\left(\frac{A_1}{\lambda}\right)^{p_1}\left[\int_0^\infty p\alpha^{p-1}\int_{f>\delta\alpha}\delta^{p_1}d\mu d\alpha+\int_0^\infty p\alpha^{p-p_1-1}\int_{f\leq\delta\alpha}f^{p_1}d\mu d\alpha \right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\int_X\int_0^{f/\delta}f^{p_0}(1-\alpha\cdot\frac{\delta}{f})^{p_0}(\alpha\cdot\frac{\delta}{f})^{p-p_0-1}d(\alpha\cdot\frac{\delta}{f})(\frac{f}{\delta})^{p-p_0}d\mu\\ &+\left(\frac{A_1}{\lambda}\right)^{p_1}\left[\int_X\int_{f/\delta}^\infty p\alpha^{p-1}\delta^{p_1}d\alpha d\mu+\int_X f^{p_1}\int_{f/\delta}^\infty p\alpha^{p-p_1-1}d\alpha d\mu\right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\delta^{p_0-p}\|f\|_{L^p}^pB(p_0+1,p-p_0)+\frac{A_1^{p_1}}{\lambda^{p_1}}\left[\delta^{p_1-p}\|f\|_{L^p}^p+\frac{p}{p_1-p}\delta^{p_1-p}\|f\|_{L^p}^p\right]\\ =&\frac{pA_0^{p_0}}{(1-\lambda)^{p_0}}\delta^{p_0-p}\|f\|_{L^p}^pB(p_0+1,p-p_0)+\frac{p_1A_1^{p_1}}{(p_1-p)\lambda^{p_1}}\delta^{p_1-p}\|f\|_{L^p}^p \end{align*} when optimizing $\delta$ by taking derivatives of $\delta$, I cannot conclude the result.",,"['functional-analysis', 'measure-theory', 'harmonic-analysis', 'interpolation', 'weak-lp-spaces']"
44,$\mathcal{L}_{1}$ space criterion.,space criterion.,\mathcal{L}_{1},"$\bf{\text{Definition:}}$  Let $X$ be a Banach space.  $X$ is an $\mathcal{L}_{1,\lambda}$-space if, for all finite-dimensional subspaces $M$ of $X$, there exists a finite dimensional subspace $N$ of $X$ containing $M$, and an isomorphism $T\in B(N,\ell_{1}^{k})$ (where $k=\text{dim}(N))$ such that $\|T\|\cdot\|T^{-1}\|\leq \lambda$. $\bf{\text{Exercise:}}$ Show that the following are equivalent for a Banach space $X$. This appears as a remark in Raymond Ryan's ""Introduction to Tensor Products of Banach Spaces"". (1) For all $\epsilon > 0$, $X$ is an $\mathcal{L}_{1,1+\epsilon}$ space. (2) For all $\epsilon > 0$, and for all finite-dimensional subspaces $M\subset X$, there exists a finite-dimensional subspace $N\subset X$ containing $M$ and an isomorphism $T\in B(N,\ell_{1}^{k})$ (where $k=\text{dim}(N)$) such that for all $x\in N$, $\left|\|Tx\| - \|x\|\right| \leq \epsilon\|x\|$. After unwinding all the quantifiers, the $(2)\Rightarrow (1)$ direction was straightforward. $\bf{\text{Sketch:}}$ Let $\epsilon > 0$ be given, and $M$ be a finite-dimensional subspace of $X$.  Then choose $\delta > 0$ so that $\frac{2\delta}{1 + \delta} < \epsilon$.  By assumption, there exists $N\subset X$ containing $M$ and an isomorphism $T\in B(N,\ell_{1}^{k})$ such that for all $x\in N$, $\left|\|Tx\| - \|x\|\right| \leq \epsilon\|x\|$. Using the triangle inequality and the given condition on $T$, it follows that $\|T\|\leq 1 + \delta$ and $\|T^{-1}\|\leq \frac{1}{1-\delta}$.  Therefore $\|T\|\cdot \|T^{-1}\|\leq 1 + \epsilon$, by the way $\delta$ was chosen. $\bf{\text{My Problem:}}$ But the $(1)\Rightarrow (2)$ direction has me totally stumped.  When I try to apply the hypothesis given in $(1)$, I can't seem to get the conclusion of $(2)$.  Is there some obvious thing I'm missing? or is there some slippery trick?","$\bf{\text{Definition:}}$  Let $X$ be a Banach space.  $X$ is an $\mathcal{L}_{1,\lambda}$-space if, for all finite-dimensional subspaces $M$ of $X$, there exists a finite dimensional subspace $N$ of $X$ containing $M$, and an isomorphism $T\in B(N,\ell_{1}^{k})$ (where $k=\text{dim}(N))$ such that $\|T\|\cdot\|T^{-1}\|\leq \lambda$. $\bf{\text{Exercise:}}$ Show that the following are equivalent for a Banach space $X$. This appears as a remark in Raymond Ryan's ""Introduction to Tensor Products of Banach Spaces"". (1) For all $\epsilon > 0$, $X$ is an $\mathcal{L}_{1,1+\epsilon}$ space. (2) For all $\epsilon > 0$, and for all finite-dimensional subspaces $M\subset X$, there exists a finite-dimensional subspace $N\subset X$ containing $M$ and an isomorphism $T\in B(N,\ell_{1}^{k})$ (where $k=\text{dim}(N)$) such that for all $x\in N$, $\left|\|Tx\| - \|x\|\right| \leq \epsilon\|x\|$. After unwinding all the quantifiers, the $(2)\Rightarrow (1)$ direction was straightforward. $\bf{\text{Sketch:}}$ Let $\epsilon > 0$ be given, and $M$ be a finite-dimensional subspace of $X$.  Then choose $\delta > 0$ so that $\frac{2\delta}{1 + \delta} < \epsilon$.  By assumption, there exists $N\subset X$ containing $M$ and an isomorphism $T\in B(N,\ell_{1}^{k})$ such that for all $x\in N$, $\left|\|Tx\| - \|x\|\right| \leq \epsilon\|x\|$. Using the triangle inequality and the given condition on $T$, it follows that $\|T\|\leq 1 + \delta$ and $\|T^{-1}\|\leq \frac{1}{1-\delta}$.  Therefore $\|T\|\cdot \|T^{-1}\|\leq 1 + \epsilon$, by the way $\delta$ was chosen. $\bf{\text{My Problem:}}$ But the $(1)\Rightarrow (2)$ direction has me totally stumped.  When I try to apply the hypothesis given in $(1)$, I can't seem to get the conclusion of $(2)$.  Is there some obvious thing I'm missing? or is there some slippery trick?",,['functional-analysis']
45,Measurability of integral,Measurability of integral,,"Consider a function $f: \mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}$ which is continuous in the first argument, measurable in the second. Let $m: \mathcal{B}(\mathbb{R}^m) \rightarrow [0,1]$ be a finite measure. I am wondering if the function $F: \mathbb{R}^n \rightarrow [0,1]$ defined as  $$ F(x) := m\left( \{ y \in \mathbb{R}^m \mid f(x,y) \leq 0 \} \right) $$ is measurable. What I tried to do is to claim that $F$ is upper semicontinuous. This should imply measurability.","Consider a function $f: \mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}$ which is continuous in the first argument, measurable in the second. Let $m: \mathcal{B}(\mathbb{R}^m) \rightarrow [0,1]$ be a finite measure. I am wondering if the function $F: \mathbb{R}^n \rightarrow [0,1]$ defined as  $$ F(x) := m\left( \{ y \in \mathbb{R}^m \mid f(x,y) \leq 0 \} \right) $$ is measurable. What I tried to do is to claim that $F$ is upper semicontinuous. This should imply measurability.",,"['functional-analysis', 'measure-theory', 'probability-distributions']"
46,Reflexivity of $X \times Y$,Reflexivity of,X \times Y,"I want to prove the following Theorem. Let $X,Y$ be reflexive. Then $X \times Y$ is reflexive. Here my try. Proof. Let $J_X, J_Y$ be the canonical injections of $X$ onto $X''$ and of $Y$ onto $Y''$ respectively. Define $J := ( J_X, J_Y )$ (in the sense that $J(x,y) = ( J_X (x), J_Y (y) )$ for all $(x,y) \in X\times Y$). Thus $J : X\times Y \to X'' \times Y''$ and $J$ is surjective, so that $X'' \times Y''$ is reflexive. Now, if we show that $X'' \times Y''$ and $(X \times Y)''$ are isometrically isomorphic, we have done. Assume that $K : X \times Y \to (X \times Y)''$ is the canonical injection of $X\times Y$ into $(X \times Y)''$. Since $J$ is an isometric isomorphism, we have that $K \circ J^{-1} : X'' \times Y'' \to (X \times Y)''$ is an isometric isomorphism. Does it work? I'm not really sure about my last statements. Edit - Last part deleted (I answered myself!)","I want to prove the following Theorem. Let $X,Y$ be reflexive. Then $X \times Y$ is reflexive. Here my try. Proof. Let $J_X, J_Y$ be the canonical injections of $X$ onto $X''$ and of $Y$ onto $Y''$ respectively. Define $J := ( J_X, J_Y )$ (in the sense that $J(x,y) = ( J_X (x), J_Y (y) )$ for all $(x,y) \in X\times Y$). Thus $J : X\times Y \to X'' \times Y''$ and $J$ is surjective, so that $X'' \times Y''$ is reflexive. Now, if we show that $X'' \times Y''$ and $(X \times Y)''$ are isometrically isomorphic, we have done. Assume that $K : X \times Y \to (X \times Y)''$ is the canonical injection of $X\times Y$ into $(X \times Y)''$. Since $J$ is an isometric isomorphism, we have that $K \circ J^{-1} : X'' \times Y'' \to (X \times Y)''$ is an isometric isomorphism. Does it work? I'm not really sure about my last statements. Edit - Last part deleted (I answered myself!)",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
47,Is this proof correct? (left inverse and topologically complementary subsets),Is this proof correct? (left inverse and topologically complementary subsets),,"I want to prove the following theorem: Theorem . Assume $T \in \mathcal L ( X, Y )$ is injective. The following statements are equivalent: $T$ admits a left inverse; Im($T$) is closed and admits a complement in $Y$. Notation. $\mathcal L(X,Y)$ is the space of all continuous linear transformation from $X$ to $Y$. Im($T$) is the image (or the range ) of $T$. Ker($T$) shall denote the kernel of $T$. When $M$ and $N$, closed linear subset of a Banach space $X$, are complentary we write $X = M \bigoplus N$. It is a well known theorem (for example, is the theorem 2.13 of Brezis's book on functional analysis) and should be simple to prove, but all proofs I saw seem to be too concise, therefore some doubts hold on correctness of my try. Let's recall a Lemma (for example, Lemma 4.47 in Rynne and Youngson) Lemma. Suppose $X$ is a Banach space, $Y$ is a normed space and $T \in \mathcal L (X, Y)$. If there exists $\alpha > 0$ such that $\lVert Tx \rVert \geq \alpha \lVert x \rVert$ for all $x \in X$, then Im($T$) is closed. and the characterization of topological complementarity: Lemma. Assume $M$ is a closed linear subspace of a Banach space $X$. $M$ admits a complement in $X$ iff there exits $P \in \mathcal L(X)$ projection such that Im($P$) = $M$. and finally (Lemma 5.61(b) in Rynne and Youngson) Lemma. Suppose that $P$ is a projection on $X$. Then the subspaces Im($P$), Im($I-P$) are complementary. So here my try. Proof . (1) $\Rightarrow$ (2). Let $R\in \mathcal L(Y,X)$ the left inverse of $T$. So $RT = Id_X$ and $\lVert x \rVert = \lVert RT x \rVert \leq \lVert R \rVert \lVert Tx \rVert$. Hence $\lVert Tx \rVert \geq \alpha \lVert x \rVert$, $\alpha = \lVert R \rVert^{-1}$ (that is finite because $R$ is bounded) and Im($T$) is closed. Let $P = TR$; then $P$ is a projection and Im($P$) = Im($T$). Furthermore, Im($I - P$) is a complement of Im($P$) and Im($I - P$) = Ker($P$) = Ker($TR$) = Ker($R$) (because $T$ is injective). [ Is it correct? ] (2) $\Rightarrow$ (1). Assume that Im($T$) is closed and admits a complement, $N$, in $Y$. Then exists $P \in \mathcal L(Y)$, $P^2 = P$ such that Im($P$) = Im($T$). Since $Py \in$ Im($T$), there exists a unique $x \in X$ such that $T x = Py$. Set $Ry = x$. So $RT = Id_X$ and $R$ is continuous by theorem of inverse operator. The second part is the same as Brezis's one but the first part is different. He only says that it is an obvious fact that Im($T$) is closed. So my questions are: Why does he state that it is so obvious? Which is the quickest way to verify that an operator has closed image? Are there other possible complements? Sorry for such a long question, but since notations are not universal in this subject I preferred to be explicit. Thank you. References: H. Brezis, Functional analysis, Sobolev spaces and partial differential equations B. P. Rynne, M.A. Youngson, Linear functional analysis","I want to prove the following theorem: Theorem . Assume $T \in \mathcal L ( X, Y )$ is injective. The following statements are equivalent: $T$ admits a left inverse; Im($T$) is closed and admits a complement in $Y$. Notation. $\mathcal L(X,Y)$ is the space of all continuous linear transformation from $X$ to $Y$. Im($T$) is the image (or the range ) of $T$. Ker($T$) shall denote the kernel of $T$. When $M$ and $N$, closed linear subset of a Banach space $X$, are complentary we write $X = M \bigoplus N$. It is a well known theorem (for example, is the theorem 2.13 of Brezis's book on functional analysis) and should be simple to prove, but all proofs I saw seem to be too concise, therefore some doubts hold on correctness of my try. Let's recall a Lemma (for example, Lemma 4.47 in Rynne and Youngson) Lemma. Suppose $X$ is a Banach space, $Y$ is a normed space and $T \in \mathcal L (X, Y)$. If there exists $\alpha > 0$ such that $\lVert Tx \rVert \geq \alpha \lVert x \rVert$ for all $x \in X$, then Im($T$) is closed. and the characterization of topological complementarity: Lemma. Assume $M$ is a closed linear subspace of a Banach space $X$. $M$ admits a complement in $X$ iff there exits $P \in \mathcal L(X)$ projection such that Im($P$) = $M$. and finally (Lemma 5.61(b) in Rynne and Youngson) Lemma. Suppose that $P$ is a projection on $X$. Then the subspaces Im($P$), Im($I-P$) are complementary. So here my try. Proof . (1) $\Rightarrow$ (2). Let $R\in \mathcal L(Y,X)$ the left inverse of $T$. So $RT = Id_X$ and $\lVert x \rVert = \lVert RT x \rVert \leq \lVert R \rVert \lVert Tx \rVert$. Hence $\lVert Tx \rVert \geq \alpha \lVert x \rVert$, $\alpha = \lVert R \rVert^{-1}$ (that is finite because $R$ is bounded) and Im($T$) is closed. Let $P = TR$; then $P$ is a projection and Im($P$) = Im($T$). Furthermore, Im($I - P$) is a complement of Im($P$) and Im($I - P$) = Ker($P$) = Ker($TR$) = Ker($R$) (because $T$ is injective). [ Is it correct? ] (2) $\Rightarrow$ (1). Assume that Im($T$) is closed and admits a complement, $N$, in $Y$. Then exists $P \in \mathcal L(Y)$, $P^2 = P$ such that Im($P$) = Im($T$). Since $Py \in$ Im($T$), there exists a unique $x \in X$ such that $T x = Py$. Set $Ry = x$. So $RT = Id_X$ and $R$ is continuous by theorem of inverse operator. The second part is the same as Brezis's one but the first part is different. He only says that it is an obvious fact that Im($T$) is closed. So my questions are: Why does he state that it is so obvious? Which is the quickest way to verify that an operator has closed image? Are there other possible complements? Sorry for such a long question, but since notations are not universal in this subject I preferred to be explicit. Thank you. References: H. Brezis, Functional analysis, Sobolev spaces and partial differential equations B. P. Rynne, M.A. Youngson, Linear functional analysis",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
48,supremum as a norm,supremum as a norm,,"What is it the intuition behind letting the limit of the $p$-norm $(\int |f(x)|^{p}dx)^\frac{1}{p}$ to be defined as $\sup f$? Is this similar to taking as particular Hölder means functions$$M_p(s,t)=\left(\frac{s^p+t^p}{2}\right)^{\frac{1}{p}}$$ the two functions $M_{-\infty}(s,p)=\min\{s,p\}$ and $M_{\infty}(s,p)=\max\{s,p\}$?","What is it the intuition behind letting the limit of the $p$-norm $(\int |f(x)|^{p}dx)^\frac{1}{p}$ to be defined as $\sup f$? Is this similar to taking as particular Hölder means functions$$M_p(s,t)=\left(\frac{s^p+t^p}{2}\right)^{\frac{1}{p}}$$ the two functions $M_{-\infty}(s,p)=\min\{s,p\}$ and $M_{\infty}(s,p)=\max\{s,p\}$?",,"['real-analysis', 'functional-analysis']"
49,"Density of a subspace in $\mathcal{D}(0,T;V)$ under $H^1$ norm",Density of a subspace in  under  norm,"\mathcal{D}(0,T;V) H^1","Let $V$ be Hilbert. Let $\mathcal{D}((0,T);V)$ be space of infinite differentiable functions with values in $V$ with compact support. Are functions of the form $$\sum_j \psi_n(t)w_n$$ where $\psi_n \in \mathcal{D}(0,T)$ and $w_n \in V$, dense under the norm $$\lVert {u}\rVert_{W} = \sqrt{\int_0^T \lVert {u}\rVert_{V}^2 + \lVert {u'}\rVert_{V}^2}$$ in $\mathcal{D}((0,T);V)$? If $V=\mathbb{R}$, the question seems stupid.. Otherwise I don't know...","Let $V$ be Hilbert. Let $\mathcal{D}((0,T);V)$ be space of infinite differentiable functions with values in $V$ with compact support. Are functions of the form $$\sum_j \psi_n(t)w_n$$ where $\psi_n \in \mathcal{D}(0,T)$ and $w_n \in V$, dense under the norm $$\lVert {u}\rVert_{W} = \sqrt{\int_0^T \lVert {u}\rVert_{V}^2 + \lVert {u'}\rVert_{V}^2}$$ in $\mathcal{D}((0,T);V)$? If $V=\mathbb{R}$, the question seems stupid.. Otherwise I don't know...",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
50,Core of multiplication operator,Core of multiplication operator,,"Suppose $\phi$ is a continuous function on $\mathbb{R}$. Suppose we have an operator on $L^{2}(\mathbb{R})$ defined by: $$ D(T) = \{ f \in L^{2}(\mathbb{R}) \; | \; f\cdot \phi \in L^{2}(\mathbb{R}) \} $$ $$ (Tf)(x) = \phi(x)\cdot f(x) $$ The question is to prove that $C_{c}^{\infty}(\mathbb{R})$ is a core for $T$. Being a core means there exists a sequence $g_{n}$ in $C_{c}^{\infty}(\mathbb{R})$ such that $g_{n} \rightarrow f$ in $L^{2}(\mathbb{R})$ and $Tg_{n} \rightarrow Tf$ in $L^{2}(\mathbb{R})$. I can easily see this if we have a finite interval instead of $\mathbb{R}$ using density of $C_{c}^{\infty}$ in $L^{2}$ and DCT. This is what I tried. Given $f \in D(T)$, There exists a sequence $g_{n}$ of $C_{c}^{\infty}(\mathbb{R})$ functions such that $g_{n} \rightarrow f$ in $L^{2}$. Thus, there exists a subsequence $g_{n_{k}}$ such that $g_{n_{k}}(x) \rightarrow f(x)$ for almost all $x$. That means $\phi(x)\cdot g_{n_{k}}(x) \rightarrow \phi(x)\cdot f(x)$ for almost all $x$. However, now I am unable to use DCT as I do not have a bound for $\phi(x)\cdot g_{n_{k}}(x)$. This is where I am stuck. Thanks in advance for any help.","Suppose $\phi$ is a continuous function on $\mathbb{R}$. Suppose we have an operator on $L^{2}(\mathbb{R})$ defined by: $$ D(T) = \{ f \in L^{2}(\mathbb{R}) \; | \; f\cdot \phi \in L^{2}(\mathbb{R}) \} $$ $$ (Tf)(x) = \phi(x)\cdot f(x) $$ The question is to prove that $C_{c}^{\infty}(\mathbb{R})$ is a core for $T$. Being a core means there exists a sequence $g_{n}$ in $C_{c}^{\infty}(\mathbb{R})$ such that $g_{n} \rightarrow f$ in $L^{2}(\mathbb{R})$ and $Tg_{n} \rightarrow Tf$ in $L^{2}(\mathbb{R})$. I can easily see this if we have a finite interval instead of $\mathbb{R}$ using density of $C_{c}^{\infty}$ in $L^{2}$ and DCT. This is what I tried. Given $f \in D(T)$, There exists a sequence $g_{n}$ of $C_{c}^{\infty}(\mathbb{R})$ functions such that $g_{n} \rightarrow f$ in $L^{2}$. Thus, there exists a subsequence $g_{n_{k}}$ such that $g_{n_{k}}(x) \rightarrow f(x)$ for almost all $x$. That means $\phi(x)\cdot g_{n_{k}}(x) \rightarrow \phi(x)\cdot f(x)$ for almost all $x$. However, now I am unable to use DCT as I do not have a bound for $\phi(x)\cdot g_{n_{k}}(x)$. This is where I am stuck. Thanks in advance for any help.",,"['functional-analysis', 'operator-theory']"
51,Question on $\liminf$ and $\limsup$,Question on  and,\liminf \limsup,"Let $f:[0,2\pi]\times \mathbb{R} \rightarrow \mathbb{R}$ a differential function satisfying :  $\displaystyle k^2\leq \liminf_{|x|\rightarrow \infty} \frac{f(t,x)}{x}\leq \limsup_{|x|\rightarrow \infty}\frac{f(t,x)}{x} \leq (k+1)^2$ Let $(x_n)\subset H^1([0,2\pi],\mathbb{R})=\lbrace x\in L^2([0,2\pi],\mathbb{R}),x'\in L^2([0,2\pi],\mathbb{R}),x(0)=x(2\pi)\rbrace$ such that $\|x_n\|\rightarrow \infty$ when $n \rightarrow \infty$ Why : the sequence $(\displaystyle\frac{f(t,x_n)-k^2 x_n}{\|x_n\|})$ is bounded ? This is an answer of a professor and I don't understand the line 6. How to use : $$\displaystyle k^2\leq \liminf_{|x|\rightarrow \infty} \frac{f(t,x)}{x}\leq \limsup_{|x|\rightarrow \infty}\frac{f(t,x)}{x} \leq (k+1)^2$$ to find : $\displaystyle \| f(t,x_n)\|_{L^2}^2 =\int_0^{2\pi} f(t,x_n)^2 dt \leq  \max\lbrace (k+1)^4\int_0^{2\pi} |x_n|^2 dt , 2\pi M\rbrace$ where : $\displaystyle M=\sup_{(t,x)\in [0,2\pi]\times[-a,a]}|f(t,x)|$ Please help me , Thank you .","Let $f:[0,2\pi]\times \mathbb{R} \rightarrow \mathbb{R}$ a differential function satisfying :  $\displaystyle k^2\leq \liminf_{|x|\rightarrow \infty} \frac{f(t,x)}{x}\leq \limsup_{|x|\rightarrow \infty}\frac{f(t,x)}{x} \leq (k+1)^2$ Let $(x_n)\subset H^1([0,2\pi],\mathbb{R})=\lbrace x\in L^2([0,2\pi],\mathbb{R}),x'\in L^2([0,2\pi],\mathbb{R}),x(0)=x(2\pi)\rbrace$ such that $\|x_n\|\rightarrow \infty$ when $n \rightarrow \infty$ Why : the sequence $(\displaystyle\frac{f(t,x_n)-k^2 x_n}{\|x_n\|})$ is bounded ? This is an answer of a professor and I don't understand the line 6. How to use : $$\displaystyle k^2\leq \liminf_{|x|\rightarrow \infty} \frac{f(t,x)}{x}\leq \limsup_{|x|\rightarrow \infty}\frac{f(t,x)}{x} \leq (k+1)^2$$ to find : $\displaystyle \| f(t,x_n)\|_{L^2}^2 =\int_0^{2\pi} f(t,x_n)^2 dt \leq  \max\lbrace (k+1)^4\int_0^{2\pi} |x_n|^2 dt , 2\pi M\rbrace$ where : $\displaystyle M=\sup_{(t,x)\in [0,2\pi]\times[-a,a]}|f(t,x)|$ Please help me , Thank you .",,"['analysis', 'functional-analysis', 'limsup-and-liminf']"
52,"Orthogonal complement at $L^2[-1,1]$",Orthogonal complement at,"L^2[-1,1]","Find the orthogonal complement at $L^2[-1,1]$ of the subspace generated by: a) polynomials with constant term equal $0$; b) even polynomials. I think that the answer to the second part is the odd functions (almost everywhere) set in $L^2[-1,1]$, because that's the unique case such that the integral is $0$. Am I correct? The first one, I have no idea.","Find the orthogonal complement at $L^2[-1,1]$ of the subspace generated by: a) polynomials with constant term equal $0$; b) even polynomials. I think that the answer to the second part is the odd functions (almost everywhere) set in $L^2[-1,1]$, because that's the unique case such that the integral is $0$. Am I correct? The first one, I have no idea.",,"['functional-analysis', 'orthogonal-polynomials']"
53,Gelfand-Naimark Theorem with separable algebras,Gelfand-Naimark Theorem with separable algebras,,"If a C$^{\star}$- algebra is separable, is there a representation in a ,also separable,  Hilbert space ? Probably it's not hard to adapt the proof of the Gelfand-Naimark Theorem, but can someone give me some references ? Thank you.","If a C$^{\star}$- algebra is separable, is there a representation in a ,also separable,  Hilbert space ? Probably it's not hard to adapt the proof of the Gelfand-Naimark Theorem, but can someone give me some references ? Thank you.",,"['functional-analysis', 'reference-request']"
54,"An equality in $L^2(0,T;V')$!? Weak solution to PDE via Galerkin approximations",An equality in !? Weak solution to PDE via Galerkin approximations,"L^2(0,T;V')","I have the heat equation $$u' - \Delta u = f$$ as equality in $L^2(0,T;V')$,i.e., $$(u',v) + (\nabla u, \nabla v) = (f,v)$$ for all $v \in L^2(0,T;V)$, where I used the same brackets for duality pairing and inner product for succinctness. Let $w_j$ be the basis in $V$ and $H$. I read in a book that the finite dimensional (Galerkin) approximations to the PDE  $$(u_n',w_j) + (\nabla u_n, \nabla w_j) = (f, w_j), \quad\text{for $j=1,...,n$}$$ can be written as $$\frac{d}{dt}u_n - \Delta u_n = P_nf\tag{1}$$ where $P_n$ is a projection operator. In what sense is this latter equation an equality? Presumable not an equality in $L^2(0,T;V')$ because the weak form I wrote above only holds for the basis functions. However, the author later takes an inner product of (1) with an element on $L^2(0,T;V)$, how can he do that?","I have the heat equation $$u' - \Delta u = f$$ as equality in $L^2(0,T;V')$,i.e., $$(u',v) + (\nabla u, \nabla v) = (f,v)$$ for all $v \in L^2(0,T;V)$, where I used the same brackets for duality pairing and inner product for succinctness. Let $w_j$ be the basis in $V$ and $H$. I read in a book that the finite dimensional (Galerkin) approximations to the PDE  $$(u_n',w_j) + (\nabla u_n, \nabla w_j) = (f, w_j), \quad\text{for $j=1,...,n$}$$ can be written as $$\frac{d}{dt}u_n - \Delta u_n = P_nf\tag{1}$$ where $P_n$ is a projection operator. In what sense is this latter equation an equality? Presumable not an equality in $L^2(0,T;V')$ because the weak form I wrote above only holds for the basis functions. However, the author later takes an inner product of (1) with an element on $L^2(0,T;V)$, how can he do that?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
55,Proving an inequality about an $L^2$ function,Proving an inequality about an  function,L^2,"Let $u \in L^2(\mathbb{R}^2)$ be a function of two variables $x$ and $y$. I want to know if there is a relation between the Fourier tranform (with respect to $x$) of the $L^2$ norm (with respect to $y$) of $u$ and the $L^2$-norm (with respect to $y$) of the Fourier transform of $u$ (with respect to $x$). In particular, I am interested in knowing if something like the following holds: $$\bigg|\int e^{-i\xi .x}\left(\int|u(x,y)|^2dy\right)^{1/2}dx\bigg| \leq \bigg(\int\bigg|\int e^{-i\xi .x}u(x,y)dx\bigg|^2dy\bigg)^{1/2}$$ Thanks a lot for your help!","Let $u \in L^2(\mathbb{R}^2)$ be a function of two variables $x$ and $y$. I want to know if there is a relation between the Fourier tranform (with respect to $x$) of the $L^2$ norm (with respect to $y$) of $u$ and the $L^2$-norm (with respect to $y$) of the Fourier transform of $u$ (with respect to $x$). In particular, I am interested in knowing if something like the following holds: $$\bigg|\int e^{-i\xi .x}\left(\int|u(x,y)|^2dy\right)^{1/2}dx\bigg| \leq \bigg(\int\bigg|\int e^{-i\xi .x}u(x,y)dx\bigg|^2dy\bigg)^{1/2}$$ Thanks a lot for your help!",,"['functional-analysis', 'integration', 'inequality', 'lp-spaces']"
56,"Is $K=\{f\mid f\in \Pi_n , \|f\|\le 1\}$ equicontinuous or not?",Is  equicontinuous or not?,"K=\{f\mid f\in \Pi_n , \|f\|\le 1\}","I am trying find that below set is equicontinuous or not: $$K=\{f\mid f\in \Pi_n , \|f\|\le 1\}$$ $$\Pi_n=\{\text{polynomials of degree }\le n \text{ over } [a,b]\}$$ with norm : $$||f||=\sup_{x\in \mathcal{D}(f)}|f(x)|$$ I proved that if we change the condition $f\in \Pi_n$ to $f\in \mathcal{C}$ it isn't equicontinuous with use of  Weierstrass theorem: $$W_\varepsilon:\mathcal{C} \to \Pi \quad st \quad \|W_\epsilon(f)-f\|<\epsilon$$ So for every $0 < \varepsilon <1$ and $0<\delta$ we have the function $f_\delta(x)=W_\frac{1}{5}\left(\frac{4}{5}\sin(n\pi x)\right)$ where $\frac{1}{n}<\delta$ st equcontinuity doesn't hold: $$\left|0-\frac{1}{n}\right|<\delta\text{ but }\left|f_\delta(0)-f_\delta\left(\frac{1}{n}\right)\right|>\varepsilon$$ Which side of conjecture is true?","I am trying find that below set is equicontinuous or not: $$K=\{f\mid f\in \Pi_n , \|f\|\le 1\}$$ $$\Pi_n=\{\text{polynomials of degree }\le n \text{ over } [a,b]\}$$ with norm : $$||f||=\sup_{x\in \mathcal{D}(f)}|f(x)|$$ I proved that if we change the condition $f\in \Pi_n$ to $f\in \mathcal{C}$ it isn't equicontinuous with use of  Weierstrass theorem: $$W_\varepsilon:\mathcal{C} \to \Pi \quad st \quad \|W_\epsilon(f)-f\|<\epsilon$$ So for every $0 < \varepsilon <1$ and $0<\delta$ we have the function $f_\delta(x)=W_\frac{1}{5}\left(\frac{4}{5}\sin(n\pi x)\right)$ where $\frac{1}{n}<\delta$ st equcontinuity doesn't hold: $$\left|0-\frac{1}{n}\right|<\delta\text{ but }\left|f_\delta(0)-f_\delta\left(\frac{1}{n}\right)\right|>\varepsilon$$ Which side of conjecture is true?",,"['functional-analysis', 'examples-counterexamples']"
57,A problem from distribution theory.,A problem from distribution theory.,,"Let $f$, $g\in C(\Omega)$, and suppose that $f \neq g$ in $C(\Omega)$. How can we prove that $f \neq g$ as distributions? Here's the idea of my proof. $f$ and $g$ are continuous functions, so they will be locally integrable. Now, take any $\phi \neq 0 \in D(\Omega)$. Let us suppose that $\langle T_f,\phi\rangle =\langle T_g,\phi \rangle $ and $f\neq g$ $\langle T_f,\phi \rangle = \langle T_g,\phi \rangle$ $\implies \int_\Omega f(x) \phi(x) dx = \int_\Omega g(x) \phi(x) dx$ $\implies \int_\Omega \phi(x)[f(x)-g(x)] dx =0$ i.e., the area under above function is zero. We know that $\phi$ is non zero, we just need to prove that this integral will be zero only when $f(x)-g(x)=0$ and it will make contradiction to our supposition that $f$ and $g$ are not equal. [Please help me prove the last point]","Let $f$, $g\in C(\Omega)$, and suppose that $f \neq g$ in $C(\Omega)$. How can we prove that $f \neq g$ as distributions? Here's the idea of my proof. $f$ and $g$ are continuous functions, so they will be locally integrable. Now, take any $\phi \neq 0 \in D(\Omega)$. Let us suppose that $\langle T_f,\phi\rangle =\langle T_g,\phi \rangle $ and $f\neq g$ $\langle T_f,\phi \rangle = \langle T_g,\phi \rangle$ $\implies \int_\Omega f(x) \phi(x) dx = \int_\Omega g(x) \phi(x) dx$ $\implies \int_\Omega \phi(x)[f(x)-g(x)] dx =0$ i.e., the area under above function is zero. We know that $\phi$ is non zero, we just need to prove that this integral will be zero only when $f(x)-g(x)=0$ and it will make contradiction to our supposition that $f$ and $g$ are not equal. [Please help me prove the last point]",,"['functional-analysis', 'distribution-theory']"
58,An operator whose adjoint has dense range is injective,An operator whose adjoint has dense range is injective,,How can I solve this question: An operator $A$ whose adjoint has dense range is injective.,How can I solve this question: An operator $A$ whose adjoint has dense range is injective.,,"['real-analysis', 'functional-analysis']"
59,Is there an easy way to see that all derivatives are bounded?,Is there an easy way to see that all derivatives are bounded?,,Show that all derivatives of $f:\mathbb{R}\to\mathbb{R}$ given by $$f(x):=\frac{1}{\sqrt{x^2+1}+1}$$ are bounded. It's easy to see that all derivatives are continuous. So the only potential problem is that a derivative might blow up at $\infty$. Is there an easy way to see that this does not happen? I guess deriving an explicit form of the n-th derivative is not the way to do it (I'd doubt there is an easy closed form).,Show that all derivatives of $f:\mathbb{R}\to\mathbb{R}$ given by $$f(x):=\frac{1}{\sqrt{x^2+1}+1}$$ are bounded. It's easy to see that all derivatives are continuous. So the only potential problem is that a derivative might blow up at $\infty$. Is there an easy way to see that this does not happen? I guess deriving an explicit form of the n-th derivative is not the way to do it (I'd doubt there is an easy closed form).,,"['real-analysis', 'functional-analysis']"
60,Relation of the kernels of one bounded operator and its extension,Relation of the kernels of one bounded operator and its extension,,"Sorry for this long and formal post. The application in PDEs is mentioned just at the end. Let  $$V \hookrightarrow H \text{  and } Q_H' \hookrightarrow Q',$$  where $V$ and $Q$ are Banach and $H$ and $Q_H$ are Hilbert spaces. The hooked arrow $\hookrightarrow$ denotes the continuous embedding, which is basically $V \subset H$ and $\|v\|_V \geq \|v\|_H$ for all $v\in V$. The same with $Q_H'\hookrightarrow Q'$. Also, assume that the embeddings are dense, i.e. $\overline V = H$ and $\overline {Q_H'} = Q'$, where the overline denotes the closure of the space with respect to the norm of its superspace. Consider the linear bounded operator $$J\colon V \to Q_H'.$$ Then $V_0:=\ker(J)$ is a closed subspace of $V$. From an inf-sup condition, I have that  $$\|Jv\|_{Q_H'} \geq \gamma \|v\|_V\quad (1)$$  for all $v \in V_1$, where $V_1$ is complementary to $V_0$, i.e. $V=V_0 \oplus V_1$. Furthermore I have that $J\colon V\subset H\to Q'$ is bounded, so that one can define the natural extension $\bar J\colon H \to Q'$, using that $V$ is dense in $H$, that is bounded as well. Also for $\bar J$ I assume this boundedness from below, see $(1)$, for functions that are not in the kernel of $\bar J$. Now my question is: Is the kernel of $J$ dense in the kernel of $\bar J$? Or, equivalently, is $\overline V_0 = H_0$, where $H_0$ is the kernel of $\bar J$? What I have tried so far: I have shown that $\overline{V_0} \subset H_0$. To show the converse direction, I thought of taking $h \in H_0$ and show that there is a sequence $\{v_{0,n}\} \subset V_0$ that goes to $h_0$ (in the norm of $H$). Since $\overline V = H$, there is $\{v_n\} \subset V$ that goes to $h_0$ (in the norm of $H$). Because of $(1)$ there is a bounded projector $P_V\colon V \to V$, with $P(V)=V_0$. Then one can split up every $v_n$ into $v_{0,n}:=Pv_n$ and the remainder $v_{1,n}$ that is in $V_1$. Now I want to show, that $\{v_{1,n}\}$ goes to $0$ (in $H$) what would make $\{v_{0,n}\} \subset V_0$ approaching $h_0$. ...... In terms of PDEs, this would answer the questions, whether the (sub)space of divergence free elements of $H_0^1(\Omega)^3$ is dense in the (sub)space of these functions in $L^2(\Omega)^3$. In this case: $J:=div$ $V:= H_0^1(\Omega)^3$ and $H:=L^2(\Omega)^3$ $Q_H := L^2(\Omega)/\mathbb R$ and $Q' = (H^1(\Omega)/\mathbb R)'$ And the question becomes: Is  $$ \{v\in H_0^1(\Omega)^3:\text{div } v = 0 \in L^2(\Omega)/\mathbb R \} \text{ dense in } \{v \in L^2(\Omega)^3:\text{div } v = 0 \in (H^1(\Omega)/\mathbb R)' \} $$","Sorry for this long and formal post. The application in PDEs is mentioned just at the end. Let  $$V \hookrightarrow H \text{  and } Q_H' \hookrightarrow Q',$$  where $V$ and $Q$ are Banach and $H$ and $Q_H$ are Hilbert spaces. The hooked arrow $\hookrightarrow$ denotes the continuous embedding, which is basically $V \subset H$ and $\|v\|_V \geq \|v\|_H$ for all $v\in V$. The same with $Q_H'\hookrightarrow Q'$. Also, assume that the embeddings are dense, i.e. $\overline V = H$ and $\overline {Q_H'} = Q'$, where the overline denotes the closure of the space with respect to the norm of its superspace. Consider the linear bounded operator $$J\colon V \to Q_H'.$$ Then $V_0:=\ker(J)$ is a closed subspace of $V$. From an inf-sup condition, I have that  $$\|Jv\|_{Q_H'} \geq \gamma \|v\|_V\quad (1)$$  for all $v \in V_1$, where $V_1$ is complementary to $V_0$, i.e. $V=V_0 \oplus V_1$. Furthermore I have that $J\colon V\subset H\to Q'$ is bounded, so that one can define the natural extension $\bar J\colon H \to Q'$, using that $V$ is dense in $H$, that is bounded as well. Also for $\bar J$ I assume this boundedness from below, see $(1)$, for functions that are not in the kernel of $\bar J$. Now my question is: Is the kernel of $J$ dense in the kernel of $\bar J$? Or, equivalently, is $\overline V_0 = H_0$, where $H_0$ is the kernel of $\bar J$? What I have tried so far: I have shown that $\overline{V_0} \subset H_0$. To show the converse direction, I thought of taking $h \in H_0$ and show that there is a sequence $\{v_{0,n}\} \subset V_0$ that goes to $h_0$ (in the norm of $H$). Since $\overline V = H$, there is $\{v_n\} \subset V$ that goes to $h_0$ (in the norm of $H$). Because of $(1)$ there is a bounded projector $P_V\colon V \to V$, with $P(V)=V_0$. Then one can split up every $v_n$ into $v_{0,n}:=Pv_n$ and the remainder $v_{1,n}$ that is in $V_1$. Now I want to show, that $\{v_{1,n}\}$ goes to $0$ (in $H$) what would make $\{v_{0,n}\} \subset V_0$ approaching $h_0$. ...... In terms of PDEs, this would answer the questions, whether the (sub)space of divergence free elements of $H_0^1(\Omega)^3$ is dense in the (sub)space of these functions in $L^2(\Omega)^3$. In this case: $J:=div$ $V:= H_0^1(\Omega)^3$ and $H:=L^2(\Omega)^3$ $Q_H := L^2(\Omega)/\mathbb R$ and $Q' = (H^1(\Omega)/\mathbb R)'$ And the question becomes: Is  $$ \{v\in H_0^1(\Omega)^3:\text{div } v = 0 \in L^2(\Omega)/\mathbb R \} \text{ dense in } \{v \in L^2(\Omega)^3:\text{div } v = 0 \in (H^1(\Omega)/\mathbb R)' \} $$",,"['functional-analysis', 'partial-differential-equations']"
61,Smoothness in Banach space,Smoothness in Banach space,,"I need a reference about a definition. Let $n$ be an integer and $G$ be a group of $H^n$(Sobolev) automorphisms of a vector bundle $E$ on some manifold $M$ and $C$ be the space of connections of class $H^{n-1}$, what is the definition that $G$ acts ""smoothly"" on $A$?","I need a reference about a definition. Let $n$ be an integer and $G$ be a group of $H^n$(Sobolev) automorphisms of a vector bundle $E$ on some manifold $M$ and $C$ be the space of connections of class $H^{n-1}$, what is the definition that $G$ acts ""smoothly"" on $A$?",,"['functional-analysis', 'ordinary-differential-equations', 'differential-geometry', 'differential-topology', 'gauge-theory']"
62,Null spaces and projections,Null spaces and projections,,"I'm following Kreyszig's exposition of projections in ""Introduction to Functional Analysis with applications"". I'm trying to follow the proof of the following theorem (9.6-1 on pp. 486-487) regarding projections and their relationship to the following partial ordering: Definition (Partial ordering via $\leq$) Take $T_{1},T_{2}:H\to H$ to be bounded self-adjoint linear operators on a complex Hilbert space $H$. We write $T_{1}\leq T_{2}$ iff $\left\langle T_{1}x,x\right\rangle \leq\left\langle T_{2}x,x\right\rangle $ for each $x\in H$. Theorem Suppose that $P_{1}$ and $P_{2}$ are projections on the Hilbert space $H$. Let $P_{1}\left(H\right)$ and $P_{2}\left(H\right)$ be the subspaces onto which $H$ is projected by $P_{1}$ and $P_{2}$. Furthermore, let $\mathscr{N}\left(P_{1}\right)$ and $\mathscr{N}\left(P_{2}\right)$ be the null spaces of $ $$P_{1}$ and $P_{2}$, respectively. T.f.a.e.: 1) $P_{2}P_{1}=P_{1}P_{2}=P_{1}$; 2) $\left\Vert P_{1}x\right\Vert \leq\left\Vert P_{2}x\right\Vert ,\forall x\in H$; 3) $P_{1}\leq P_{2}$; 4) $\mathscr{N}\left(P_{2}\right)\subseteq\mathscr{N}\left(P_{1}\right)$; 5) $P_{1}\left(H\right)\subseteq P_{2}\left(H\right)$. I'm struggling to justify Kreyszig's justification for 4) implies 5). He uses the following Lemma, which I think I understand: Lemma The orthogonal complement $Y^{\perp}$ of a closed subspace $Y$ of a Hilbert space is the null space $\mathscr{N}\left(P\right)$ of the orthogonal projection $P$ of $H$ onto $Y$. Indeed, to prove 4) implies 5), Kreyszig says, "" This is clear since $\mathscr N \left(P_j \right)$ is the orthogonal complement of $P_j(H)$ in $H$. "" I understand this to mean that we have that $\mathscr{N}\left(P_{i}\right)=\left(P_{i}\left(H\right)\right)^{\perp}$. Hence, from 4), $$\left(P_{2}\left(H\right)\right)^{\perp} \subseteq \left(P_{1}\left(H\right)\right)^{\perp}.$$ Am I right? And if I am, how does this help us to get 5)?","I'm following Kreyszig's exposition of projections in ""Introduction to Functional Analysis with applications"". I'm trying to follow the proof of the following theorem (9.6-1 on pp. 486-487) regarding projections and their relationship to the following partial ordering: Definition (Partial ordering via $\leq$) Take $T_{1},T_{2}:H\to H$ to be bounded self-adjoint linear operators on a complex Hilbert space $H$. We write $T_{1}\leq T_{2}$ iff $\left\langle T_{1}x,x\right\rangle \leq\left\langle T_{2}x,x\right\rangle $ for each $x\in H$. Theorem Suppose that $P_{1}$ and $P_{2}$ are projections on the Hilbert space $H$. Let $P_{1}\left(H\right)$ and $P_{2}\left(H\right)$ be the subspaces onto which $H$ is projected by $P_{1}$ and $P_{2}$. Furthermore, let $\mathscr{N}\left(P_{1}\right)$ and $\mathscr{N}\left(P_{2}\right)$ be the null spaces of $ $$P_{1}$ and $P_{2}$, respectively. T.f.a.e.: 1) $P_{2}P_{1}=P_{1}P_{2}=P_{1}$; 2) $\left\Vert P_{1}x\right\Vert \leq\left\Vert P_{2}x\right\Vert ,\forall x\in H$; 3) $P_{1}\leq P_{2}$; 4) $\mathscr{N}\left(P_{2}\right)\subseteq\mathscr{N}\left(P_{1}\right)$; 5) $P_{1}\left(H\right)\subseteq P_{2}\left(H\right)$. I'm struggling to justify Kreyszig's justification for 4) implies 5). He uses the following Lemma, which I think I understand: Lemma The orthogonal complement $Y^{\perp}$ of a closed subspace $Y$ of a Hilbert space is the null space $\mathscr{N}\left(P\right)$ of the orthogonal projection $P$ of $H$ onto $Y$. Indeed, to prove 4) implies 5), Kreyszig says, "" This is clear since $\mathscr N \left(P_j \right)$ is the orthogonal complement of $P_j(H)$ in $H$. "" I understand this to mean that we have that $\mathscr{N}\left(P_{i}\right)=\left(P_{i}\left(H\right)\right)^{\perp}$. Hence, from 4), $$\left(P_{2}\left(H\right)\right)^{\perp} \subseteq \left(P_{1}\left(H\right)\right)^{\perp}.$$ Am I right? And if I am, how does this help us to get 5)?",,"['functional-analysis', 'spectral-theory']"
63,Spectrum of the unbounded operator $i\partial_x$,Spectrum of the unbounded operator,i\partial_x,"I've been puzzling over this for some time now, and can't quite make my intuitions precise.  I need to find the resolvent set and spectrum of the operator $$ Lu=i\frac{du}{dx} $$ taken to be (densely) defined over $L^2([0,\infty))$, and eventually its adjoint, which is the same operator but on the set (assuming I've computed it correctly): $$ \text{Dom}(L^*)=\{v\in L^2[0,\infty):v(0)=0\} $$ The pointwise spectrum of $L$ is easy to compute: $(\lambda I-L)u=0$ is a simple ODE, whose solution along with the $L^2$ condition implies $$ \sigma_p(L)=\{\lambda=a+bi\in\Bbb{C}:b<0\},  $$the lower half-plane.  Now intuitively, since $\sigma(L)$ is a closed set, I expect $\rho(L)$ to be the upper half-plane, the residual spectrum to to be the real axis, and the continuous spectrum to be empty.  However I'm struggling to show this rigorously since $L$ is an unbounded operator, and all the theory I find pertains to bounded linear operators. So here are my questions: Is there a (somewhat) direct way to characterize the residual spectrum of an operator without explicitly computing $(\lambda I-L)^{-1}$? Or am I just being a whimp and should find $(\lambda I-L)^{-1}$? The adjoint clearly has no pointwise spectrum because of the domain restriction.  Does this mean its resolvent set will be all of $\Bbb{C}$ or am I missing something? Feel free to direct me to your favorite book on spectral/operator theory if necessary - I can't seem to find answers to my questions after looking in 4 or 5.  Thanks!","I've been puzzling over this for some time now, and can't quite make my intuitions precise.  I need to find the resolvent set and spectrum of the operator $$ Lu=i\frac{du}{dx} $$ taken to be (densely) defined over $L^2([0,\infty))$, and eventually its adjoint, which is the same operator but on the set (assuming I've computed it correctly): $$ \text{Dom}(L^*)=\{v\in L^2[0,\infty):v(0)=0\} $$ The pointwise spectrum of $L$ is easy to compute: $(\lambda I-L)u=0$ is a simple ODE, whose solution along with the $L^2$ condition implies $$ \sigma_p(L)=\{\lambda=a+bi\in\Bbb{C}:b<0\},  $$the lower half-plane.  Now intuitively, since $\sigma(L)$ is a closed set, I expect $\rho(L)$ to be the upper half-plane, the residual spectrum to to be the real axis, and the continuous spectrum to be empty.  However I'm struggling to show this rigorously since $L$ is an unbounded operator, and all the theory I find pertains to bounded linear operators. So here are my questions: Is there a (somewhat) direct way to characterize the residual spectrum of an operator without explicitly computing $(\lambda I-L)^{-1}$? Or am I just being a whimp and should find $(\lambda I-L)^{-1}$? The adjoint clearly has no pointwise spectrum because of the domain restriction.  Does this mean its resolvent set will be all of $\Bbb{C}$ or am I missing something? Feel free to direct me to your favorite book on spectral/operator theory if necessary - I can't seem to find answers to my questions after looking in 4 or 5.  Thanks!",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
64,Unitary Equivalence of Two Irreducible $ * $-Representations of a GCR $ C^{*} $-Algebra that Have the Same Kernel.,Unitary Equivalence of Two Irreducible -Representations of a GCR -Algebra that Have the Same Kernel., *   C^{*} ,"In general, if two irreducible $ * $-representations of a $ C^{*} $-algebra $ A $ have the same kernel, then we can say that they are approximately unitarily equivalent. When $ A $ is GCR, how can we prove that they are actually unitarily equivalent?","In general, if two irreducible $ * $-representations of a $ C^{*} $-algebra $ A $ have the same kernel, then we can say that they are approximately unitarily equivalent. When $ A $ is GCR, how can we prove that they are actually unitarily equivalent?",,"['functional-analysis', 'representation-theory', 'c-star-algebras', 'banach-algebras']"
65,Block Matrices of Operators,Block Matrices of Operators,,"I'm trying to prove the following: Consider the vector space of matrices of size $n\times n$ whose entries in $\mathcal B(H)$. Denote this vector space by $M_{n,n}(\mathcal{B(H)})$. We can define involution on $M_{n,n}(\mathcal{B(H)})$ by  $$ T^*=[T_{ij}]^*=[T_{ji}^*],\qquad\text{where}\quad T=[T_{ij}]\in M_{n,n}(\mathcal{B(H)}). $$ Thus we have an involutive algebra $M_{n,n}(\mathcal{B(H)})$. I want to prove that there exist a norm on $M_{n,n}(\mathcal{B(H)})$ which makes it a $C^*$-algebra. First I try to prove that there exists a $*$ isomorphism between $M_{n,n}(\mathcal{B(H)})$ and $\mathcal{B}\left(\bigoplus\limits_{k=1}^n\mathcal H\right)$. So I define the following map:  $$J:M_{n,n}(\mathcal{A})\to\mathcal{B}\left(\bigoplus\limits_{k=1}^n H\right):[T_{ij}]\mapsto\left((x_1,.....,x_n)\mapsto\left(\sum\limits_{j=1}^n(T_{1j})x_j,\ldots,\sum\limits_{j=1}^n(T_{nj})x_j\right)\right) $$ I proved that this map is $1-1$. My question is : is it onto ? or does it have a closed range? Also , to prove that $J([T_{ij}]^*)= J([T_{ji}^*])=J^*([T_{ij}]))$. I did the following using the definition of the adjoint operator, but I'm not sure where things go wrong: I take $x=(x_1,......,x_n), y=(y_1,.....,y_n)\in \bigoplus\limits_{k=1}^n H $, then $$\begin{align}(J(T)^*x)(y)= x(J(T)y)&= x(\sum\limits_{j=1}^n(T_{1j})y_j,....,\sum\limits_{j=1}^n(T_{nj})y_j)\\& = \sum\limits_{i=1}^n \left [x_i(\sum\limits_{j=1}^n(T_{1j})y_j,....,\sum\limits_{j=1}^n(T_{nj})y_j)\right] \\&=\sum_{i=1}^n \sum_{j=1}^n (T_{ij}y_j)(x_i)\\&=\sum_{j=1}^n \sum_{i=1}^n (y_j)(T^*_{ij}(x_i)) \end{align}$$","I'm trying to prove the following: Consider the vector space of matrices of size $n\times n$ whose entries in $\mathcal B(H)$. Denote this vector space by $M_{n,n}(\mathcal{B(H)})$. We can define involution on $M_{n,n}(\mathcal{B(H)})$ by  $$ T^*=[T_{ij}]^*=[T_{ji}^*],\qquad\text{where}\quad T=[T_{ij}]\in M_{n,n}(\mathcal{B(H)}). $$ Thus we have an involutive algebra $M_{n,n}(\mathcal{B(H)})$. I want to prove that there exist a norm on $M_{n,n}(\mathcal{B(H)})$ which makes it a $C^*$-algebra. First I try to prove that there exists a $*$ isomorphism between $M_{n,n}(\mathcal{B(H)})$ and $\mathcal{B}\left(\bigoplus\limits_{k=1}^n\mathcal H\right)$. So I define the following map:  $$J:M_{n,n}(\mathcal{A})\to\mathcal{B}\left(\bigoplus\limits_{k=1}^n H\right):[T_{ij}]\mapsto\left((x_1,.....,x_n)\mapsto\left(\sum\limits_{j=1}^n(T_{1j})x_j,\ldots,\sum\limits_{j=1}^n(T_{nj})x_j\right)\right) $$ I proved that this map is $1-1$. My question is : is it onto ? or does it have a closed range? Also , to prove that $J([T_{ij}]^*)= J([T_{ji}^*])=J^*([T_{ij}]))$. I did the following using the definition of the adjoint operator, but I'm not sure where things go wrong: I take $x=(x_1,......,x_n), y=(y_1,.....,y_n)\in \bigoplus\limits_{k=1}^n H $, then $$\begin{align}(J(T)^*x)(y)= x(J(T)y)&= x(\sum\limits_{j=1}^n(T_{1j})y_j,....,\sum\limits_{j=1}^n(T_{nj})y_j)\\& = \sum\limits_{i=1}^n \left [x_i(\sum\limits_{j=1}^n(T_{1j})y_j,....,\sum\limits_{j=1}^n(T_{nj})y_j)\right] \\&=\sum_{i=1}^n \sum_{j=1}^n (T_{ij}y_j)(x_i)\\&=\sum_{j=1}^n \sum_{i=1}^n (y_j)(T^*_{ij}(x_i)) \end{align}$$",,"['functional-analysis', 'operator-theory']"
66,PDE weak solution problem,PDE weak solution problem,,"My professor grades really  strictly (details). I would be very happy if you could help me with this problem: Let $U \subset R^n$ be a bounded set. Consider $ \Delta^2 u = f$ on $U$ and $u=\frac{\partial u}{\partial n}=0$ on $\partial U$. Part (a): Prove Poincare inequality for $H_0^2(U)$, i.e. $\int_U u^2 dx \leq C\int_U |\Delta u|^2 dx$ for all $u \in H_0^2(U)$. Part (b): Define the notion of weak solution. Part (c): Let $f \in L^2(U)$. Show that the problem has a unique weak solution in an appropriately chosen Sobolev space. Part (d): Consider the same problem with boundary conditions $u=\Delta u = 0$ on $\partial U$ and prove the existence of a weak solution in the appropriate Sobolev space. My work: (a): $u \in H_0^2 (U) \subset H_0^1(U)$ and therefore we can use the Poincare inequality for $H_0^1$ $(\int_U u^2 dx \leq \widetilde{C} \int_U |Du|^2 dx)$ twice: $$ \int_U u^2 dx \leq \widetilde{C} \int_U |Du|^2 dx \leq \widetilde{C} \widetilde{\widetilde{C}} \int_U |D^2u|^2 dx $$ since $Du \in H_0^1 (U)$. (b): Multiply $\Delta^2 u = f$ on $U$ by a test function $v \in H_0^2(U)$ and integrate over $U$. Green's identity for operator $L= \Delta^2$:  $$ \int_U v \Delta^2 u dx= \int_{\partial U} (v \frac{\partial \Delta u}{\partial n} - \frac{\partial v}{\partial n}\Delta u)dS + \int_U \Delta v \Delta u dx = \int_U \Delta v \Delta u dx. $$ since $v$ is a test function and therefore the integral on the boundary vanishes. (i assumed $\frac{\partial v}{\partial n}= 0$. is this ok?)  We can now define weak solution in the following way. Function $u \in H_0^2(U)$ is a weak solution if  $$ B[u,v]:= \int_U \Delta v \Delta u dx = \int_U fv dx \textrm{ for any } v \in H_0^2(U). $$ The weak solution of our fourth order problem will lie in the Hilbert space $H_0^2(U)$. Do you agree? (c): Define an inner product on the Hilbert space $H_0^2(U)$: $$  <u,v>_2 = \int_U \Delta u \Delta v dx $$ which implies the norm  $$  ||u||_2 = (\int_U |\Delta u|^2 dx)^{\frac{1}{2}} = (\int_U |D^2 u|^2 dx)^{\frac{1}{2}}. $$ Norm $||\cdot||_2$ is equivalent to the standard norm on $H_0^2$: $||u||_1 := \big( \int_U (u^2 + |Du|^2 + |D^2u|^2)dx  \big)^{\frac{1}{2}}$. It is obvious that $||u||_2 \leq ||u||_1$. On the other hand, \begin{align*} ||u||_1^2 &= \int_U (u^2 + |Du|^2 + |D^2u|^2 )dx\\ & = \int_U u^2dx + \int_U |Du|^2dx + \int_U |D^2u|^2 dx\\ & \leq C_1 \int_U |D^2u|^2dx + C_2 \int_U |D^2u|^2dx +  \int_U |D^2u|^2 dx\\ &= (1+C_1+C_2)||u||_2^2 \end{align*} using Poincare inequalities as in (a). Define a linear functional $F_f \in H_0^{2*}(U)$: $$F_f(v) = \int_U fv dx \quad (=<f,v>_{L^2}).$$ $F_f$ is bounded which follows from Cauchy-Schwarz inequality and Poincare inequality (is this ok?): $$ |\int_U fv dx | \leq ||f||_{L^2}||v||_{L^2} \leq ||f||_{L^2}||v||_{H_0^2}.$$ Linearity is easy. Equip $H_0^2$ with the inner product $<,>_2$ .Apply Riesz representation theorem and you have weak solution. But is not that already a strong solution? Confused here (d): Denote $-\Delta u = t$. Since $\Delta u = 0$ on $\partial U$, $t=0$ on $\partial U$. We know existence of weak solution $t \in H_0^1(U)$ for $-\Delta t = f$, $f \in L^2(U)$ from previous homework. Remains $-\Delta u = t$ on $U$ and $u=0$ on $\partial U$. We can find unique $u \in H_0^1(U)$ that is a weak solution (if $t \in L^2(U)$ but here only $t \in H_0^1(U) ?)$ Would be grateful if someone could shed some light on me. Is at least the general idea of the solution ok?","My professor grades really  strictly (details). I would be very happy if you could help me with this problem: Let $U \subset R^n$ be a bounded set. Consider $ \Delta^2 u = f$ on $U$ and $u=\frac{\partial u}{\partial n}=0$ on $\partial U$. Part (a): Prove Poincare inequality for $H_0^2(U)$, i.e. $\int_U u^2 dx \leq C\int_U |\Delta u|^2 dx$ for all $u \in H_0^2(U)$. Part (b): Define the notion of weak solution. Part (c): Let $f \in L^2(U)$. Show that the problem has a unique weak solution in an appropriately chosen Sobolev space. Part (d): Consider the same problem with boundary conditions $u=\Delta u = 0$ on $\partial U$ and prove the existence of a weak solution in the appropriate Sobolev space. My work: (a): $u \in H_0^2 (U) \subset H_0^1(U)$ and therefore we can use the Poincare inequality for $H_0^1$ $(\int_U u^2 dx \leq \widetilde{C} \int_U |Du|^2 dx)$ twice: $$ \int_U u^2 dx \leq \widetilde{C} \int_U |Du|^2 dx \leq \widetilde{C} \widetilde{\widetilde{C}} \int_U |D^2u|^2 dx $$ since $Du \in H_0^1 (U)$. (b): Multiply $\Delta^2 u = f$ on $U$ by a test function $v \in H_0^2(U)$ and integrate over $U$. Green's identity for operator $L= \Delta^2$:  $$ \int_U v \Delta^2 u dx= \int_{\partial U} (v \frac{\partial \Delta u}{\partial n} - \frac{\partial v}{\partial n}\Delta u)dS + \int_U \Delta v \Delta u dx = \int_U \Delta v \Delta u dx. $$ since $v$ is a test function and therefore the integral on the boundary vanishes. (i assumed $\frac{\partial v}{\partial n}= 0$. is this ok?)  We can now define weak solution in the following way. Function $u \in H_0^2(U)$ is a weak solution if  $$ B[u,v]:= \int_U \Delta v \Delta u dx = \int_U fv dx \textrm{ for any } v \in H_0^2(U). $$ The weak solution of our fourth order problem will lie in the Hilbert space $H_0^2(U)$. Do you agree? (c): Define an inner product on the Hilbert space $H_0^2(U)$: $$  <u,v>_2 = \int_U \Delta u \Delta v dx $$ which implies the norm  $$  ||u||_2 = (\int_U |\Delta u|^2 dx)^{\frac{1}{2}} = (\int_U |D^2 u|^2 dx)^{\frac{1}{2}}. $$ Norm $||\cdot||_2$ is equivalent to the standard norm on $H_0^2$: $||u||_1 := \big( \int_U (u^2 + |Du|^2 + |D^2u|^2)dx  \big)^{\frac{1}{2}}$. It is obvious that $||u||_2 \leq ||u||_1$. On the other hand, \begin{align*} ||u||_1^2 &= \int_U (u^2 + |Du|^2 + |D^2u|^2 )dx\\ & = \int_U u^2dx + \int_U |Du|^2dx + \int_U |D^2u|^2 dx\\ & \leq C_1 \int_U |D^2u|^2dx + C_2 \int_U |D^2u|^2dx +  \int_U |D^2u|^2 dx\\ &= (1+C_1+C_2)||u||_2^2 \end{align*} using Poincare inequalities as in (a). Define a linear functional $F_f \in H_0^{2*}(U)$: $$F_f(v) = \int_U fv dx \quad (=<f,v>_{L^2}).$$ $F_f$ is bounded which follows from Cauchy-Schwarz inequality and Poincare inequality (is this ok?): $$ |\int_U fv dx | \leq ||f||_{L^2}||v||_{L^2} \leq ||f||_{L^2}||v||_{H_0^2}.$$ Linearity is easy. Equip $H_0^2$ with the inner product $<,>_2$ .Apply Riesz representation theorem and you have weak solution. But is not that already a strong solution? Confused here (d): Denote $-\Delta u = t$. Since $\Delta u = 0$ on $\partial U$, $t=0$ on $\partial U$. We know existence of weak solution $t \in H_0^1(U)$ for $-\Delta t = f$, $f \in L^2(U)$ from previous homework. Remains $-\Delta u = t$ on $U$ and $u=0$ on $\partial U$. We can find unique $u \in H_0^1(U)$ that is a weak solution (if $t \in L^2(U)$ but here only $t \in H_0^1(U) ?)$ Would be grateful if someone could shed some light on me. Is at least the general idea of the solution ok?",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces']"
67,Confused about Proof of Thm 4.9 Gilbarg Trudinger,Confused about Proof of Thm 4.9 Gilbarg Trudinger,,"Thm 4.9 in Gilbarg-Trudinger's book states that : if $B$ is a ball in $\mathbb{R}^n$ centred at $x_0$ and $f\in C^{\alpha}(B): \sup_{x\in B} (\text{dist}(x, \partial B))^{2-\beta}\vert f(x)\vert \leq N<\infty$ for some $\beta\in (0, 1)$. Then there is a unique function $u\in C^{2}(B)\cap C(\overline{B})$, satisfying $\Delta u=f$ in $B$ and $u=0$ on $\partial B$. Furthermore $u$ satisfies an estimate: \begin{equation} \sup_{x\in B} \ \text{dist}(x, \partial B)^{-\beta}\vert u(x)\vert\leq CN, \end{equation} where $C=C(\beta)$. I am following the proof of this theorem and I am happy with everything upto the point they start to prove the existence of $u$. To show the existence of $u$ they first let \begin{equation} f_m=\left\{\begin{aligned} m &\quad\text{if } f\geq m\\ f &\quad\text{if }\vert f\vert\leq m\\ -m &\quad\text{if } f\leq -m\end{aligned}\right. \end{equation} and let $\{B_k\}_{k=n}^{\infty}$, $n=\lceil \inf_{x\in B} \vert f\vert\rceil$, be a collection of concentric balls about $x_0$ such that: \begin{equation} B_k\subset\subset B_{k+1}, \quad x\in B_{k}\Rightarrow \vert f(x)\vert\leq k\quad\text{and} \quad \bigcup_k B_{k}=B. \end{equation} With this setup they define the set $\{u_m\}$ to be the set of functions that satisfy: \begin{align*} \Delta u_m &=f_m\quad\text{in } B\\ u_m &=0\quad\text{on } \partial B. \end{align*} By the estimate provided above (this was proved first in their argument) we know that $u_m$ is uniformly bounded and that for $m\geq k$ \begin{equation} \Delta u_m=f\quad\text{in } B_k. \end{equation} Now they say that if we apply Corollary 4.7 successively to the balls $B_k$ then we get a subsequence that converges to a function $u\in C^{2}(B)$ that satisfies $\Delta u=f$ in $B$. Corollary 4.7 says that if $u_n$ is a uniformly bounded sequence of solution to Poisson's equation, $\Delta u=f$ in a domain $\Omega$ with $f\in C^{\alpha}(\Omega)$ then for any $\Omega'\subset\subset \Omega$ there is a subsequence that converges uniformly to a solution. I tried to apply this Corollary 4.7 in this way, however, I find myself taking subsequences infinitely often as follows: If $B_k\subset\subset B_{k+1}$ then: \begin{equation} \Delta u_m=f\quad\text{in } B_{k+1}\ \forall m\geq k+1\Rightarrow \exists\  u_{m_j}\rightrightarrows u: \Delta u=f \ \text{in } B_{k}. \end{equation} So certainly this subsequence converges to a $u\in C^{2}(B_k)$ that satisfies Poisson's equation in $B_{k}$ and if I repeat the process for $B_{k+1}\subset\subset B_{k+2}$ then I take a subsequence of $u_{m_j}$ to get the result for $B_{k+1}$ and so on. I don't understand how this process will stop such that I find one subsequence that works throughout $B$ as claimed by [G-T]. If we are to use Corollary 4.7 in this way then shouldn't we find ourselves stopping this procedure once $B$ becomes compactly contained in some bigger set in which Poisson's equation is satisfied by $u_m$? This is clearly not the case.","Thm 4.9 in Gilbarg-Trudinger's book states that : if $B$ is a ball in $\mathbb{R}^n$ centred at $x_0$ and $f\in C^{\alpha}(B): \sup_{x\in B} (\text{dist}(x, \partial B))^{2-\beta}\vert f(x)\vert \leq N<\infty$ for some $\beta\in (0, 1)$. Then there is a unique function $u\in C^{2}(B)\cap C(\overline{B})$, satisfying $\Delta u=f$ in $B$ and $u=0$ on $\partial B$. Furthermore $u$ satisfies an estimate: \begin{equation} \sup_{x\in B} \ \text{dist}(x, \partial B)^{-\beta}\vert u(x)\vert\leq CN, \end{equation} where $C=C(\beta)$. I am following the proof of this theorem and I am happy with everything upto the point they start to prove the existence of $u$. To show the existence of $u$ they first let \begin{equation} f_m=\left\{\begin{aligned} m &\quad\text{if } f\geq m\\ f &\quad\text{if }\vert f\vert\leq m\\ -m &\quad\text{if } f\leq -m\end{aligned}\right. \end{equation} and let $\{B_k\}_{k=n}^{\infty}$, $n=\lceil \inf_{x\in B} \vert f\vert\rceil$, be a collection of concentric balls about $x_0$ such that: \begin{equation} B_k\subset\subset B_{k+1}, \quad x\in B_{k}\Rightarrow \vert f(x)\vert\leq k\quad\text{and} \quad \bigcup_k B_{k}=B. \end{equation} With this setup they define the set $\{u_m\}$ to be the set of functions that satisfy: \begin{align*} \Delta u_m &=f_m\quad\text{in } B\\ u_m &=0\quad\text{on } \partial B. \end{align*} By the estimate provided above (this was proved first in their argument) we know that $u_m$ is uniformly bounded and that for $m\geq k$ \begin{equation} \Delta u_m=f\quad\text{in } B_k. \end{equation} Now they say that if we apply Corollary 4.7 successively to the balls $B_k$ then we get a subsequence that converges to a function $u\in C^{2}(B)$ that satisfies $\Delta u=f$ in $B$. Corollary 4.7 says that if $u_n$ is a uniformly bounded sequence of solution to Poisson's equation, $\Delta u=f$ in a domain $\Omega$ with $f\in C^{\alpha}(\Omega)$ then for any $\Omega'\subset\subset \Omega$ there is a subsequence that converges uniformly to a solution. I tried to apply this Corollary 4.7 in this way, however, I find myself taking subsequences infinitely often as follows: If $B_k\subset\subset B_{k+1}$ then: \begin{equation} \Delta u_m=f\quad\text{in } B_{k+1}\ \forall m\geq k+1\Rightarrow \exists\  u_{m_j}\rightrightarrows u: \Delta u=f \ \text{in } B_{k}. \end{equation} So certainly this subsequence converges to a $u\in C^{2}(B_k)$ that satisfies Poisson's equation in $B_{k}$ and if I repeat the process for $B_{k+1}\subset\subset B_{k+2}$ then I take a subsequence of $u_{m_j}$ to get the result for $B_{k+1}$ and so on. I don't understand how this process will stop such that I find one subsequence that works throughout $B$ as claimed by [G-T]. If we are to use Corollary 4.7 in this way then shouldn't we find ourselves stopping this procedure once $B$ becomes compactly contained in some bigger set in which Poisson's equation is satisfied by $u_m$? This is clearly not the case.",,"['real-analysis', 'analysis', 'functional-analysis', 'partial-differential-equations']"
68,Strong convergence of multiplication operator,Strong convergence of multiplication operator,,"I am looking for a necessary and sufficient condition for a sequence of multiplication operators $T^{(k)}$ to converge to zero strongly. (i.e. $\forall x \in \mathcal{H} \quad ||T^{(k)}x - 0|| \to 0$ as $k \to \infty$) Here $T^{(k)}$ is the operator $$T^{(k)}: \ell^2 \to \ell^2$$ given by coordinate-wise multiplication, i.e.  $$T^{(k)}\left( \underline{x} \right) = (t^{k}_nx_n)_{n \in \mathbb{N}}$$ where $(t^{k}_n)_{n \in \mathbb{N}}$ is a bounded sequence for each $k$. I suppose it is obvious that it is necessary that $|t^{k}_n| \to 0$ as $k\to \infty$  for all $n\in\mathbb{N}$, but since $(t^{k}_n)_{n \in \mathbb{N}} \in \ell^\infty$ I think this is also sufficient because we have that $$ \sum|x_n|^2|t^{(k)}_n|^2 \le (\sup{|t^{(k)}_n|})^2\sum|x|^2 \to 0 \text{  as } k\to\infty  $$ since $$ \sum|x|^2 < \infty \quad \text{and} \quad \sup{|t^{(k)}_n|} \to 0 \text{ as } k\to \infty $$ I am wondering whether this reasoning is correct or whether I have misunderstood something, because I am looking at a much more involved exposition that tries to achieve a necessary and sufficient condition but makes use of dominated convergence to do so.","I am looking for a necessary and sufficient condition for a sequence of multiplication operators $T^{(k)}$ to converge to zero strongly. (i.e. $\forall x \in \mathcal{H} \quad ||T^{(k)}x - 0|| \to 0$ as $k \to \infty$) Here $T^{(k)}$ is the operator $$T^{(k)}: \ell^2 \to \ell^2$$ given by coordinate-wise multiplication, i.e.  $$T^{(k)}\left( \underline{x} \right) = (t^{k}_nx_n)_{n \in \mathbb{N}}$$ where $(t^{k}_n)_{n \in \mathbb{N}}$ is a bounded sequence for each $k$. I suppose it is obvious that it is necessary that $|t^{k}_n| \to 0$ as $k\to \infty$  for all $n\in\mathbb{N}$, but since $(t^{k}_n)_{n \in \mathbb{N}} \in \ell^\infty$ I think this is also sufficient because we have that $$ \sum|x_n|^2|t^{(k)}_n|^2 \le (\sup{|t^{(k)}_n|})^2\sum|x|^2 \to 0 \text{  as } k\to\infty  $$ since $$ \sum|x|^2 < \infty \quad \text{and} \quad \sup{|t^{(k)}_n|} \to 0 \text{ as } k\to \infty $$ I am wondering whether this reasoning is correct or whether I have misunderstood something, because I am looking at a much more involved exposition that tries to achieve a necessary and sufficient condition but makes use of dominated convergence to do so.",,"['analysis', 'functional-analysis', 'convergence-divergence', 'operator-theory']"
69,unconditional convergent,unconditional convergent,,"I have to decide whether the following statement is true or false : every permutation of a basic sequence is equivalent to the entire sequence ! where a sequence $(x_n)$ in a Banach space $X$ is called basic if it's a basis of $[x_1,x_2,x_3,.........]$ (it's closed span). I think it's false, and I think that if it's true then  $\displaystyle\sum_{1}^{\infty}x_n$ converges unconditionaly . Any ideas. Thank you!","I have to decide whether the following statement is true or false : every permutation of a basic sequence is equivalent to the entire sequence ! where a sequence $(x_n)$ in a Banach space $X$ is called basic if it's a basis of $[x_1,x_2,x_3,.........]$ (it's closed span). I think it's false, and I think that if it's true then  $\displaystyle\sum_{1}^{\infty}x_n$ converges unconditionaly . Any ideas. Thank you!",,[]
70,Projection of the third dual of a Banach space onto the first dual,Projection of the third dual of a Banach space onto the first dual,,"Let $j_X:X\rightarrow X^{**}$ denote the canonical embedding. I've read several articles where it is assumed that the reader is familiar with the idea that there is a norm one projection from $X^{***}$ to $X^*$. More precisely, $P:=j_{X^*}(j_X)^*$ seems to be that projection. However, I couldn't find any material that would explain it in detail, and I can't really figure out how this operator works on my own. If we take $x^{***} \in X^{***}$, then what exactly happens to it when we apply $P$, in other words, what kind of an operator is $j_{X^*}(j_X)^*x^{***}: X^{**} \rightarrow \mathbb{K}$?","Let $j_X:X\rightarrow X^{**}$ denote the canonical embedding. I've read several articles where it is assumed that the reader is familiar with the idea that there is a norm one projection from $X^{***}$ to $X^*$. More precisely, $P:=j_{X^*}(j_X)^*$ seems to be that projection. However, I couldn't find any material that would explain it in detail, and I can't really figure out how this operator works on my own. If we take $x^{***} \in X^{***}$, then what exactly happens to it when we apply $P$, in other words, what kind of an operator is $j_{X^*}(j_X)^*x^{***}: X^{**} \rightarrow \mathbb{K}$?",,"['functional-analysis', 'operator-theory']"
71,"Why is there no space whose dual is $C_\mathbb{R}[0,1]$? [duplicate]",Why is there no space whose dual is ? [duplicate],"C_\mathbb{R}[0,1]","This question already has answers here : Closed 11 years ago . Possible Duplicate: $C_0(X)$ is not the dual of a complete normed space Is any Banach space a dual space? While studying for a course of functional analysis I read somewhere that there is no normed vector space $X$ with $X^*=C_\mathbb{R}[0,1]$. I also found what at first glance seems like a complete proof of this fact: Assume there is such a space $X$, then by Alaoglu's theorem the closed unit ball $B^*$ in $X^*$ is weak* compact. The unique extremal points of $B^*$ are the constant functions $f(x) = \pm 1$, and their closed convex hull is not all of $B^*$. This is a contradiction to Krein-Milman's theorem. Now, I have a problem with this proof: to apply Krein-Milman to a set you need it to be convex and compact with respect to the topology induced by the norm , at least according to how it is usually stated. My hypothesis is that actually you can apply it to sets which are only compact in the weak* topology. Is this true? How do you prove it?","This question already has answers here : Closed 11 years ago . Possible Duplicate: $C_0(X)$ is not the dual of a complete normed space Is any Banach space a dual space? While studying for a course of functional analysis I read somewhere that there is no normed vector space $X$ with $X^*=C_\mathbb{R}[0,1]$. I also found what at first glance seems like a complete proof of this fact: Assume there is such a space $X$, then by Alaoglu's theorem the closed unit ball $B^*$ in $X^*$ is weak* compact. The unique extremal points of $B^*$ are the constant functions $f(x) = \pm 1$, and their closed convex hull is not all of $B^*$. This is a contradiction to Krein-Milman's theorem. Now, I have a problem with this proof: to apply Krein-Milman to a set you need it to be convex and compact with respect to the topology induced by the norm , at least according to how it is usually stated. My hypothesis is that actually you can apply it to sets which are only compact in the weak* topology. Is this true? How do you prove it?",,['functional-analysis']
72,Nullspace of $T'$ for continuous bounded functions.,Nullspace of  for continuous bounded functions.,T',"Given  $f\in C_b(\mathbb{R})$, let $Tf(x) = e^{-|x|}f(x)$. Show that $T$ defines a bounded linear map into itself such that $\ker T' \neq {0}$. My try: look at the space $A = \{ f \in C_b : \exists \lim_{x\rightarrow \infty} f(x)\}$ define $\ell_0 \in A' : \ell_0 (f) = \lim_{x\rightarrow \infty} f(x)$. Then $|\ell_0| (f) \leq \|f\|$ so we can expand $\tilde{\ell_0}$ to $C_b$. I have some trouble with the finish, how do I get $\tilde{\ell_0} (Tf) = 0 \;\; \forall f \in C_b$? Edit: It would work if $\lim_{x\rightarrow \infty} e^{-|x|} f(x) = 0$ I guess.","Given  $f\in C_b(\mathbb{R})$, let $Tf(x) = e^{-|x|}f(x)$. Show that $T$ defines a bounded linear map into itself such that $\ker T' \neq {0}$. My try: look at the space $A = \{ f \in C_b : \exists \lim_{x\rightarrow \infty} f(x)\}$ define $\ell_0 \in A' : \ell_0 (f) = \lim_{x\rightarrow \infty} f(x)$. Then $|\ell_0| (f) \leq \|f\|$ so we can expand $\tilde{\ell_0}$ to $C_b$. I have some trouble with the finish, how do I get $\tilde{\ell_0} (Tf) = 0 \;\; \forall f \in C_b$? Edit: It would work if $\lim_{x\rightarrow \infty} e^{-|x|} f(x) = 0$ I guess.",,"['functional-analysis', 'operator-theory']"
73,Questions about operator norm,Questions about operator norm,,"I'm reading about functional analysis and I found the definition of the operator norm, if you have $(X,\|\|_1)$ and $(Y,\|\|_2)$ normed spaces then the set $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) := \{T:X \to Y \text{ linear }: \sup\{ \|T(v)\|_2: \|v\|_1 = 1 \} < \infty \}$ has a norm defined by $\|\|_1$ and $\|\|_2$ and son on. My questions are: If $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) = \mathcal{L}_{\|\|'_1,\|\|_2}(X,Y)$ then, can I ensure that $\|\|_1$ and $\|\|'_1$ are equivalents? Note that this generalizes the fact that all the norms in $\mathbb{R}^n$ are equivalents, because any linear operator is continuos with any norm in $\mathbb{R}^n$. Similarly with the other side, If $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) \subseteq \mathcal{L}_{\|\|'_1,\|\|_2}(X,Y)$, can I say something? And like before with the other side, If I have a subspace $Z$ of $\mathbb{L}(X,Y)$ then there exist norms such that $Z = \mathcal{L}_{\|\|_1,\|\|_2}(X,Y)$. I apologize if my questions are not interesting, thank for your help.","I'm reading about functional analysis and I found the definition of the operator norm, if you have $(X,\|\|_1)$ and $(Y,\|\|_2)$ normed spaces then the set $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) := \{T:X \to Y \text{ linear }: \sup\{ \|T(v)\|_2: \|v\|_1 = 1 \} < \infty \}$ has a norm defined by $\|\|_1$ and $\|\|_2$ and son on. My questions are: If $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) = \mathcal{L}_{\|\|'_1,\|\|_2}(X,Y)$ then, can I ensure that $\|\|_1$ and $\|\|'_1$ are equivalents? Note that this generalizes the fact that all the norms in $\mathbb{R}^n$ are equivalents, because any linear operator is continuos with any norm in $\mathbb{R}^n$. Similarly with the other side, If $\mathcal{L}_{\|\|_1,\|\|_2}(X,Y) \subseteq \mathcal{L}_{\|\|'_1,\|\|_2}(X,Y)$, can I say something? And like before with the other side, If I have a subspace $Z$ of $\mathbb{L}(X,Y)$ then there exist norms such that $Z = \mathcal{L}_{\|\|_1,\|\|_2}(X,Y)$. I apologize if my questions are not interesting, thank for your help.",,['functional-analysis']
74,bounded operator between continuous functions,bounded operator between continuous functions,,"Let $M: C([0,1]) \rightarrow C([0,1])$ be defined by  $$ Mf(x) = f(x/2), \;\; x\in[0,1]$$ Show that $M$ is bounded and that its spectrum is containd in the closed unit disc $\{ \lambda \in \mathbb{C} |\lambda| \leq 1 \}$ my try:  $$ \|M\| = \sup_{\|f\| \leq 1} \|Mf\| = \sup_{\|f\| \leq 1} \|f(x/2) \| \leq \|f\|$$ since $\lim_{k\rightarrow \infty} M^kf(x) = f(0)$ and the spectral radius $\sigma (M) = \lim_{k\rightarrow \infty} |M^k|^{1/k} = |f(0)|^{1/k} = 1$ Is this correct?","Let $M: C([0,1]) \rightarrow C([0,1])$ be defined by  $$ Mf(x) = f(x/2), \;\; x\in[0,1]$$ Show that $M$ is bounded and that its spectrum is containd in the closed unit disc $\{ \lambda \in \mathbb{C} |\lambda| \leq 1 \}$ my try:  $$ \|M\| = \sup_{\|f\| \leq 1} \|Mf\| = \sup_{\|f\| \leq 1} \|f(x/2) \| \leq \|f\|$$ since $\lim_{k\rightarrow \infty} M^kf(x) = f(0)$ and the spectral radius $\sigma (M) = \lim_{k\rightarrow \infty} |M^k|^{1/k} = |f(0)|^{1/k} = 1$ Is this correct?",,"['functional-analysis', 'operator-theory']"
75,Bounded linear maps in Banach spaces,Bounded linear maps in Banach spaces,,"Let $X$ be a Banach space and let $M: X \rightarrow X$ be a linear map.  Prov that M is bounded iff there exists a set $S \subset X'$, dense in X', such that for each $\ell \in S$ the functional $m_l$ defined by $$m_\ell(x) = \ell M (x)$$ is continuous on X. My try: If $M$ is bounded then $\ell M$ is bounded for all $\ell$, hence all $m_\ell$ are continuous, for all subsets $S$. So we need to find a dense one? On the other hand: suppose all $m_\ell$ is continuous, since the weak limit is unique, $Mx_n \rightarrow y$ and $x_n \rightarrow x$ $\Longrightarrow$ $Mx = y$ and by the closed graph M is bounded/continuous. It feels like I'm missing something with the denseness of $S$. Should I look at   $\ell \in S^c$ also? and do some $\epsilon/2$ argument?","Let $X$ be a Banach space and let $M: X \rightarrow X$ be a linear map.  Prov that M is bounded iff there exists a set $S \subset X'$, dense in X', such that for each $\ell \in S$ the functional $m_l$ defined by $$m_\ell(x) = \ell M (x)$$ is continuous on X. My try: If $M$ is bounded then $\ell M$ is bounded for all $\ell$, hence all $m_\ell$ are continuous, for all subsets $S$. So we need to find a dense one? On the other hand: suppose all $m_\ell$ is continuous, since the weak limit is unique, $Mx_n \rightarrow y$ and $x_n \rightarrow x$ $\Longrightarrow$ $Mx = y$ and by the closed graph M is bounded/continuous. It feels like I'm missing something with the denseness of $S$. Should I look at   $\ell \in S^c$ also? and do some $\epsilon/2$ argument?",,"['functional-analysis', 'banach-spaces', 'operator-theory']"
76,what are conormal distributions?,what are conormal distributions?,,"According to the first answer in this post, a conormal distribution $u$ on a manifold $X$ relative to a (closed, embedded) submanifold $Y$ is an element of a Banach (or Hilbert) space $H$ such that for any positive integer $k$, we have $$ V_1\cdots V_k u \in H $$ where $V_i$ denotes a vector field that is tangent to $Y$ (smooth and unconstrained away from $Y$). I would like to better understand these objects. Hence I was wondering whether somebody could suggest a good example for a conormal distribution, or more detailed explanation of what these distributions ""look like"" ?","According to the first answer in this post, a conormal distribution $u$ on a manifold $X$ relative to a (closed, embedded) submanifold $Y$ is an element of a Banach (or Hilbert) space $H$ such that for any positive integer $k$, we have $$ V_1\cdots V_k u \in H $$ where $V_i$ denotes a vector field that is tangent to $Y$ (smooth and unconstrained away from $Y$). I would like to better understand these objects. Hence I was wondering whether somebody could suggest a good example for a conormal distribution, or more detailed explanation of what these distributions ""look like"" ?",,"['real-analysis', 'functional-analysis', 'differential-geometry', 'partial-differential-equations']"
77,How to calculate values of the Hahn-Banach-extended integral functional?,How to calculate values of the Hahn-Banach-extended integral functional?,,"Let $\Phi: C[0,1]\longrightarrow\mathbb{R}$ the linear functional defined by $\Phi(f)=\int_0^1 f(x)dx$. Let $\tilde{\Phi}$ an extension of $\Phi$ to the normed space $(B[0,1]$ (of bounded functions on $[0,1]$, with the $\sup$ norm) such that $\|\Phi\|=\|\tilde{\Phi}\|$. Such an extension is guaranteed by the Hahn-Banach theorem. Let $h(x)$ be as follows: $h(x)=1$ if $x\leq 1/2$ and $h(x)=-1$ if $x>1/2$. How to calculate $\tilde{\Phi}(h)$? My difficulty is that it is impossible to approximate $h$ uniformly by continuous function.","Let $\Phi: C[0,1]\longrightarrow\mathbb{R}$ the linear functional defined by $\Phi(f)=\int_0^1 f(x)dx$. Let $\tilde{\Phi}$ an extension of $\Phi$ to the normed space $(B[0,1]$ (of bounded functions on $[0,1]$, with the $\sup$ norm) such that $\|\Phi\|=\|\tilde{\Phi}\|$. Such an extension is guaranteed by the Hahn-Banach theorem. Let $h(x)$ be as follows: $h(x)=1$ if $x\leq 1/2$ and $h(x)=-1$ if $x>1/2$. How to calculate $\tilde{\Phi}(h)$? My difficulty is that it is impossible to approximate $h$ uniformly by continuous function.",,['functional-analysis']
78,Determine the operator T in a Hilbert space,Determine the operator T in a Hilbert space,,"Let $H$ be a Hilbert space and let $\{e_n, n \geq 1\}$ be an orthonormal basis for $H$ . a) Determine the operator $T\in B(H)$ that satisfies $$ Te_1 = 0,\; Te_n = \frac{1}{n}e_{n-1}, n >1.$$ b) Show that $T$ is compact and determine its spectrum. My try: $$Tx = T(\sum_i \alpha_i e_i) = \sum_i\alpha_iTe_i = \sum_{i=2}^\infty \frac{1}{i}\alpha_{i}e_{i-1},$$ where $x = \sum_i \alpha_ie_i.$ Is this correct? For b) Im not sure how to prove that the image of T is pre compact and how do I find the spectrum?",Let be a Hilbert space and let be an orthonormal basis for . a) Determine the operator that satisfies b) Show that is compact and determine its spectrum. My try: where Is this correct? For b) Im not sure how to prove that the image of T is pre compact and how do I find the spectrum?,"H \{e_n, n \geq 1\} H T\in B(H)  Te_1 = 0,\; Te_n = \frac{1}{n}e_{n-1}, n >1. T Tx = T(\sum_i \alpha_i e_i) = \sum_i\alpha_iTe_i = \sum_{i=2}^\infty \frac{1}{i}\alpha_{i}e_{i-1}, x = \sum_i \alpha_ie_i.","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
79,Eigenvalues of Hilbert-Schmith operator,Eigenvalues of Hilbert-Schmith operator,,"I am having trouble determining the eigenvalues and eigenvectors of the operator $Kv(x)= \int_0^1((x+t)v(t)dt$, where the kernel is $k=x+t$. I have tried to solve the equation $Kv(x)=\lambda v(x)$, and I know that I should get two eigenvalues, but I can't seem to find them. Is there a standard method to finding the lambda's other than solving the equation $Kv(x)=v(x)$? Thanks for the help!","I am having trouble determining the eigenvalues and eigenvectors of the operator $Kv(x)= \int_0^1((x+t)v(t)dt$, where the kernel is $k=x+t$. I have tried to solve the equation $Kv(x)=\lambda v(x)$, and I know that I should get two eigenvalues, but I can't seem to find them. Is there a standard method to finding the lambda's other than solving the equation $Kv(x)=v(x)$? Thanks for the help!",,"['functional-analysis', 'eigenvalues-eigenvectors', 'spectral-theory', 'compact-operators']"
80,Pythagorean theorem in unitary vector spaces,Pythagorean theorem in unitary vector spaces,,"In euclidean (i.e. real) vector spaces the pythagorean theorem holds, i.e. $$  ||x+y||^2 = ||x||^2 + ||y||^2 \Leftrightarrow x \perp y. $$ But for unitary (i.e. complex) vector spaces it fails because  $$  \langle x , y \rangle + \langle y, x \rangle =  \langle x , y \rangle + \overline{\langle x, y \rangle} = 2\operatorname{Re}(x,y). $$ And I have a counterexample, let $X = \mathbb{C}$ be the 1-dimensional $\mathbb{C}$-vector space. Consider $x = 1$ and $y = i$. Then $2\operatorname{Re}(x,y) = 0$ but it is not the case that $x \perp y$. But here is my question, sure it is the case that $i$ is perpedicular to $1$, so why it is said that its not? Or is there another notion of perpendicularity in a unitary vector space, one that is not as intuitive? Another example is $1+i$ and $1-i$, when I draw them they are of course perpendicular, but \begin{align*}  \langle 1+i,1-i \rangle     & = \langle 1,1 \rangle + \langle i,1 \rangle + \langle 1,-i \rangle + \langle i,-i \rangle \\    & = 1 + (-i)\langle 1, 1 \rangle + (-i) \langle 1, 1 \rangle + i^2 \langle 1, 1 \rangle \\    & = 1 - i -i - 1 = -2i \ne 0 \end{align*} (using that $\langle 1,1 \rangle$, guess that holds) so they are not perpendicular?","In euclidean (i.e. real) vector spaces the pythagorean theorem holds, i.e. $$  ||x+y||^2 = ||x||^2 + ||y||^2 \Leftrightarrow x \perp y. $$ But for unitary (i.e. complex) vector spaces it fails because  $$  \langle x , y \rangle + \langle y, x \rangle =  \langle x , y \rangle + \overline{\langle x, y \rangle} = 2\operatorname{Re}(x,y). $$ And I have a counterexample, let $X = \mathbb{C}$ be the 1-dimensional $\mathbb{C}$-vector space. Consider $x = 1$ and $y = i$. Then $2\operatorname{Re}(x,y) = 0$ but it is not the case that $x \perp y$. But here is my question, sure it is the case that $i$ is perpedicular to $1$, so why it is said that its not? Or is there another notion of perpendicularity in a unitary vector space, one that is not as intuitive? Another example is $1+i$ and $1-i$, when I draw them they are of course perpendicular, but \begin{align*}  \langle 1+i,1-i \rangle     & = \langle 1,1 \rangle + \langle i,1 \rangle + \langle 1,-i \rangle + \langle i,-i \rangle \\    & = 1 + (-i)\langle 1, 1 \rangle + (-i) \langle 1, 1 \rangle + i^2 \langle 1, 1 \rangle \\    & = 1 - i -i - 1 = -2i \ne 0 \end{align*} (using that $\langle 1,1 \rangle$, guess that holds) so they are not perpendicular?",,"['linear-algebra', 'geometry', 'functional-analysis']"
81,Prove this inequality from functional analysis,Prove this inequality from functional analysis,,"I want to prove this equality used in out lecture notes: Let $D=(0,r)^2 \subset \mathbb{R}^2, r\geqslant 0$. Then, for any $u \in  H^1(D)$, there holds $$\lVert u\rVert  \leqslant \frac 1 r \left|\int_D u(x)dx\right| + \sqrt{2}r \lVert\nabla u\rVert$$ where $\lVert\cdot\rVert$ is the $L^2$-norm on $D$. I have no clue how to prove this estimate on $D$.  Can  somebody  help me?","I want to prove this equality used in out lecture notes: Let $D=(0,r)^2 \subset \mathbb{R}^2, r\geqslant 0$. Then, for any $u \in  H^1(D)$, there holds $$\lVert u\rVert  \leqslant \frac 1 r \left|\int_D u(x)dx\right| + \sqrt{2}r \lVert\nabla u\rVert$$ where $\lVert\cdot\rVert$ is the $L^2$-norm on $D$. I have no clue how to prove this estimate on $D$.  Can  somebody  help me?",,"['functional-analysis', 'inequality', 'sobolev-spaces']"
82,Weak Convergence of Positive Part,Weak Convergence of Positive Part,,"Suppose $\Omega\subset\mathbb{R}^n$ is a bounded domain and $p\in (1,\infty)$. Suppose $u_n\in L^p(\Omega)$ is such that $u_n\rightharpoonup u$ in $L^p(\Omega)$. Define the positive part of $u$ by $u^+=\max(u,0)$. Is it true that $$u^+_n\rightharpoonup u^+\,?$$ Thanks.","Suppose $\Omega\subset\mathbb{R}^n$ is a bounded domain and $p\in (1,\infty)$. Suppose $u_n\in L^p(\Omega)$ is such that $u_n\rightharpoonup u$ in $L^p(\Omega)$. Define the positive part of $u$ by $u^+=\max(u,0)$. Is it true that $$u^+_n\rightharpoonup u^+\,?$$ Thanks.",,"['real-analysis', 'functional-analysis', 'convergence-divergence']"
83,An elementary question on Sobolev space,An elementary question on Sobolev space,,"I have a question on Sobolev space.  This is one of exercises in Evans PDE textbook.  Let $U=\{(x,y) | |x|<1, |y<1|\} \subset \mathbb{R}^2$. Define a function $u(x,y)$ by $$ u(x,y)=\begin{cases} 1-x & \text{if } x>0, \ |y|<x \\ 1+x & \text{if } x<0, \ |y|<-x \\ 1-y & \text{if } y>0, \ |x|<y \\ 1+y & \text{if } y<0, \ |x|<-y \end{cases} $$ I would like to know for which $p$ the function $u$ in $W^{1,p}(U)$. It seems to me that weak derivatives are given by $u_x(x,y)=-1,1,0,0$ and $u_y(x,y)=0,0,-1,1$ in each region respectively, but then this question is too trivial. Could someone point out any mistake I made?","I have a question on Sobolev space.  This is one of exercises in Evans PDE textbook.  Let $U=\{(x,y) | |x|<1, |y<1|\} \subset \mathbb{R}^2$. Define a function $u(x,y)$ by $$ u(x,y)=\begin{cases} 1-x & \text{if } x>0, \ |y|<x \\ 1+x & \text{if } x<0, \ |y|<-x \\ 1-y & \text{if } y>0, \ |x|<y \\ 1+y & \text{if } y<0, \ |x|<-y \end{cases} $$ I would like to know for which $p$ the function $u$ in $W^{1,p}(U)$. It seems to me that weak derivatives are given by $u_x(x,y)=-1,1,0,0$ and $u_y(x,y)=0,0,-1,1$ in each region respectively, but then this question is too trivial. Could someone point out any mistake I made?",,"['functional-analysis', 'sobolev-spaces']"
84,A nonlinear version of the Riesz isomorphism,A nonlinear version of the Riesz isomorphism,,"The present question regards the proof of the following theorem which is found in Adams' Sobolev spaces , §2.30 - 2.33. Here $(\Omega, \mathcal{M}, \mu)$ denotes some arbitrary measure space and $L^p$ always stands for $L^p(\Omega)$. Riesz Representation Theorem Let $1<p<\infty$ and let $p'=p/(p-1)$. For any $v \in L^{p'}$ denote $L_v$ to be the linear functional on $L^p$ defined by the following equation:   $$\langle L_v, w\rangle =\int_{\Omega} vw\, d\mu.$$   Then the mapping $v\mapsto L_v$ is an isometric isomorphism of $L^{p'}$ onto $[L^p]^\star$. The most interesting thing to prove is that this mapping $L$ is surjective, which as far as I know is usually done by means of the Radon-Nikodym's theorem of measure theory. On the contrary, Adams' book employs uniform convexity of $L^p$ space and two of the four Clarkson's inequalities, precisely: $$\tag{38} \forall u, v \in L^p, 2\le p <\infty,\quad \left\lVert \frac{u+v}{2}\right\rVert_p^{p'}+\left\lVert \frac{u-v}{2}\right\rVert_p^{p'}\ge\left( \frac{1}{2}\lVert u \rVert_p^p+\frac{1}{2}\lVert v\rVert_p^p\right)^{p'-1}, $$ $$\tag{40} \forall u, v \in L^p, 1< p \le 2,\quad \left\lVert \frac{u+v}{2}\right\rVert_p^{p}+\left\lVert \frac{u-v}{2}\right\rVert_p^{p}\ge \frac{1}{2}\lVert u \rVert_p^p+\frac{1}{2}\lVert v\rVert_p^p. $$ His proof follows those steps: Because of uniform convexity, there exists a duality mapping $$\left[ F\in \left( L^p\right)^\star \right] \to \left[\text{the unique}\ w\in L^p\ \text{s.t.}\ \lVert w\rVert_p=\lVert F \rVert_\star\ \text{and}\ \langle F, w\rangle=\lVert F\rVert_\star^2\right].$$ The duality mapping has an explicitly known left inverse $$\left[ L_v\in (L^p)^\star\ \text{where}\ v=\frac{\lvert w\rvert^{p-1}\text{signum}(w)}{\left(\int \lvert w\rvert^p\,d\mu\right)^{\frac{p-2}{p}}}\right] \leftarrow \left[ w\in L^p\right].$$ Because of inequalities (38) and (40), the duality mapping is injective. This means that the duality mapping is bijective and so, in particular, that any linear functional $T$ is of the form $L_v$, which is what Adams wanted to prove. However, it seems to me that he actually proved much more than that: namely, this proof introduces the duality mapping, which is (as far as I can understand) a generalization of the Riesz isomorphism between a Hilbert space and its dual. Also, it looks like this mapping only depends on some easily generalizable properties of $L^p$ such as uniform convexity. So: Question How much is it known about the duality mapping in an abstract Banach space? What are the minimal hypotheses that guarantee its existence? In what spaces has it got an explicit analytical expression? Thank you for reading.","The present question regards the proof of the following theorem which is found in Adams' Sobolev spaces , §2.30 - 2.33. Here $(\Omega, \mathcal{M}, \mu)$ denotes some arbitrary measure space and $L^p$ always stands for $L^p(\Omega)$. Riesz Representation Theorem Let $1<p<\infty$ and let $p'=p/(p-1)$. For any $v \in L^{p'}$ denote $L_v$ to be the linear functional on $L^p$ defined by the following equation:   $$\langle L_v, w\rangle =\int_{\Omega} vw\, d\mu.$$   Then the mapping $v\mapsto L_v$ is an isometric isomorphism of $L^{p'}$ onto $[L^p]^\star$. The most interesting thing to prove is that this mapping $L$ is surjective, which as far as I know is usually done by means of the Radon-Nikodym's theorem of measure theory. On the contrary, Adams' book employs uniform convexity of $L^p$ space and two of the four Clarkson's inequalities, precisely: $$\tag{38} \forall u, v \in L^p, 2\le p <\infty,\quad \left\lVert \frac{u+v}{2}\right\rVert_p^{p'}+\left\lVert \frac{u-v}{2}\right\rVert_p^{p'}\ge\left( \frac{1}{2}\lVert u \rVert_p^p+\frac{1}{2}\lVert v\rVert_p^p\right)^{p'-1}, $$ $$\tag{40} \forall u, v \in L^p, 1< p \le 2,\quad \left\lVert \frac{u+v}{2}\right\rVert_p^{p}+\left\lVert \frac{u-v}{2}\right\rVert_p^{p}\ge \frac{1}{2}\lVert u \rVert_p^p+\frac{1}{2}\lVert v\rVert_p^p. $$ His proof follows those steps: Because of uniform convexity, there exists a duality mapping $$\left[ F\in \left( L^p\right)^\star \right] \to \left[\text{the unique}\ w\in L^p\ \text{s.t.}\ \lVert w\rVert_p=\lVert F \rVert_\star\ \text{and}\ \langle F, w\rangle=\lVert F\rVert_\star^2\right].$$ The duality mapping has an explicitly known left inverse $$\left[ L_v\in (L^p)^\star\ \text{where}\ v=\frac{\lvert w\rvert^{p-1}\text{signum}(w)}{\left(\int \lvert w\rvert^p\,d\mu\right)^{\frac{p-2}{p}}}\right] \leftarrow \left[ w\in L^p\right].$$ Because of inequalities (38) and (40), the duality mapping is injective. This means that the duality mapping is bijective and so, in particular, that any linear functional $T$ is of the form $L_v$, which is what Adams wanted to prove. However, it seems to me that he actually proved much more than that: namely, this proof introduces the duality mapping, which is (as far as I can understand) a generalization of the Riesz isomorphism between a Hilbert space and its dual. Also, it looks like this mapping only depends on some easily generalizable properties of $L^p$ such as uniform convexity. So: Question How much is it known about the duality mapping in an abstract Banach space? What are the minimal hypotheses that guarantee its existence? In what spaces has it got an explicit analytical expression? Thank you for reading.",,"['functional-analysis', 'banach-spaces', 'riesz-representation-theorem']"
85,Morrey space and Campanato space.,Morrey space and Campanato space.,,"I'd like to know a lot about Morrey space and Campanato spaces. For example, I'd like to know how can I see the details presents here . I'd like some reference about this. I thank you very much.","I'd like to know a lot about Morrey space and Campanato spaces. For example, I'd like to know how can I see the details presents here . I'd like some reference about this. I thank you very much.",,"['functional-analysis', 'reference-request', 'banach-spaces']"
86,Showing a certain operator is trace class.,Showing a certain operator is trace class.,,"Let $E \to M$ be a vector bundle over a closed manifold $M$.  Suppose $T$ is an endomorphism from $L^2$ sections of $E$ to itself.  How does one prove that $T$ is trace class if the image of $T$ is contained in smooth sections of $E$? Thanks. EDIT Yea I guess I should provide context since there may be assumptions I'm not stating.  This is from Singer's "" Recent applications of index theory for elliptic operators "". Specifically the part in the middle of the second paragraph of the proof, beginning with To show $P_j {_j S_f} P_j$ is trace class, it suffices to show that $_j S_f P_j$ maps $L_2(E_j)$ continuously into $C^\infty(E_j)$...","Let $E \to M$ be a vector bundle over a closed manifold $M$.  Suppose $T$ is an endomorphism from $L^2$ sections of $E$ to itself.  How does one prove that $T$ is trace class if the image of $T$ is contained in smooth sections of $E$? Thanks. EDIT Yea I guess I should provide context since there may be assumptions I'm not stating.  This is from Singer's "" Recent applications of index theory for elliptic operators "". Specifically the part in the middle of the second paragraph of the proof, beginning with To show $P_j {_j S_f} P_j$ is trace class, it suffices to show that $_j S_f P_j$ maps $L_2(E_j)$ continuously into $C^\infty(E_j)$...",,"['analysis', 'functional-analysis', 'differential-geometry']"
87,Challenge question for normed linear spaces.,Challenge question for normed linear spaces.,,"I have come across the following challenging problem in my analysis course: Let $K$ be a compact convex set in a normed linear space. Suppose that  $$\sup_{x,y\in K}\{||x-y||\}=\delta>0.$$ Show there exists $x_0\in K$ such that  $$\sup_{y\in K}\{||x_0-y||\}<\delta$$ We were given the following hint: since $K$ is compact, choose $a,b\in K$ such that $||a-b||=\delta$. Let $K_0$ be a maximal subset of $K$ containing $a$ and $b$ such that $||x-y||$ is either $0$ or $\delta$ whenever $x,y\in K_0$. Now, I've made this progress so far: The set $K_0$ as described above is a discrete subset of a compact set; thus, it must be finite. My strategy so far has thus been: suppose, towards a contradiction that I can't find such an $x_0$. Then, since $K$ is compact, this means that for any $x\in K$, there is some $y\in K$ such that $||x-y||=\delta$. Using this, and convexity, I am then trying to show that I can add another point to $K_0$. I've experimented with just assuming for a bit that $K_0$ only has two elements and playing around with what this give me using the triangle inequality, but I haven't had much luck. If anyone has some ideas on how to tackle this, it'd be much appreciated.","I have come across the following challenging problem in my analysis course: Let $K$ be a compact convex set in a normed linear space. Suppose that  $$\sup_{x,y\in K}\{||x-y||\}=\delta>0.$$ Show there exists $x_0\in K$ such that  $$\sup_{y\in K}\{||x_0-y||\}<\delta$$ We were given the following hint: since $K$ is compact, choose $a,b\in K$ such that $||a-b||=\delta$. Let $K_0$ be a maximal subset of $K$ containing $a$ and $b$ such that $||x-y||$ is either $0$ or $\delta$ whenever $x,y\in K_0$. Now, I've made this progress so far: The set $K_0$ as described above is a discrete subset of a compact set; thus, it must be finite. My strategy so far has thus been: suppose, towards a contradiction that I can't find such an $x_0$. Then, since $K$ is compact, this means that for any $x\in K$, there is some $y\in K$ such that $||x-y||=\delta$. Using this, and convexity, I am then trying to show that I can add another point to $K_0$. I've experimented with just assuming for a bit that $K_0$ only has two elements and playing around with what this give me using the triangle inequality, but I haven't had much luck. If anyone has some ideas on how to tackle this, it'd be much appreciated.",,"['geometry', 'functional-analysis', 'metric-spaces']"
88,real part of a holomorphic function from a PDE,real part of a holomorphic function from a PDE,,I have some problem that I can't figure out myself. Hope that someone can help me out. The problem is: Let $f : U \to \mathbb{R}$ be some real function on a simply-connected domain $U \subset \mathbb{C}^{n}$ with $\partial\bar{\partial}f = 0$ on $U$. Then $f$ is the real part of a holomorphic function on $U$. The question is: Is this holomorphic function unique? If not what choices are there to choose such a function? Are there any choices? How does the proof go? I hope that someone has some answers for me and I will be very happy for a lot of answers. I have to apologize if this question is too trivial for some of you :). Best regards  philippe,I have some problem that I can't figure out myself. Hope that someone can help me out. The problem is: Let $f : U \to \mathbb{R}$ be some real function on a simply-connected domain $U \subset \mathbb{C}^{n}$ with $\partial\bar{\partial}f = 0$ on $U$. Then $f$ is the real part of a holomorphic function on $U$. The question is: Is this holomorphic function unique? If not what choices are there to choose such a function? Are there any choices? How does the proof go? I hope that someone has some answers for me and I will be very happy for a lot of answers. I have to apologize if this question is too trivial for some of you :). Best regards  philippe,,"['complex-analysis', 'functional-analysis', 'differential-geometry', 'complex-geometry']"
89,Necessary and sufficient conditions for $G$ to have $A(G)$ isomorphic to an operator algebra?,Necessary and sufficient conditions for  to have  isomorphic to an operator algebra?,G A(G),Let $G$ be a locally compact group. We denote by $A(G)$ the Fourier algebra of $G$. An operator algebra is a closed subalgebra of $B(H)$ where $H$ is a Hilbert space. What are the necessary and sufficient conditions for $G$ to have a Fourier algbra which is isomorphic to an operator algebra?,Let $G$ be a locally compact group. We denote by $A(G)$ the Fourier algebra of $G$. An operator algebra is a closed subalgebra of $B(H)$ where $H$ is a Hilbert space. What are the necessary and sufficient conditions for $G$ to have a Fourier algbra which is isomorphic to an operator algebra?,,"['group-theory', 'functional-analysis', 'reference-request', 'operator-algebras', 'harmonic-analysis']"
90,Fredholm operators,Fredholm operators,,"How can I get the (Volterra) operator from an equation of the type $$u''(x)+xu'(x)+u(x)=0\text{ ?}$$ I know that there is a general way of doing it, if you could point me at the proper book I'd be thankful!","How can I get the (Volterra) operator from an equation of the type $$u''(x)+xu'(x)+u(x)=0\text{ ?}$$ I know that there is a general way of doing it, if you could point me at the proper book I'd be thankful!",,"['functional-analysis', 'operator-theory']"
91,"Is ""$K$ convex + absorbing $\not\Rightarrow$ $0\in \mathrm{Int }\, K$"" dependent on AC?","Is "" convex + absorbing  "" dependent on AC?","K \not\Rightarrow 0\in \mathrm{Int }\, K","I have encountered the following problem in Dirk Werner's ""Funktionalanalysis"" (English translation by me): Definition: A convex set $K\subset X$ is called absorbing, if given $x\in X$ there exists $\lambda>0$ such that $\lambda x\in K$. Let $X$ be a normed vector space. If $K$ is convex, is it necessarily true that ""$K$ absorbing $\implies$ $0 \in \mathrm{Int }K$""? If $X$ is only assumed to be a normed space (not Banach), then I think $X = L^1[0,1]\cap L^\infty[0,1]$ equipped with the $L^1$-norm, and $K = \{f\in X\mid \Vert f\Vert_\infty \le 1\}$ gives a counterexample. $K$ is clearly absorbing and convex, but we can find a sequence $f_n \in X$ with $\Vert f_n\Vert_1 = 1/n \to 0$ and $\Vert f_n\Vert_{\infty} = 2$ for all $n$. So no ball around $0$ can be contained in $K$. I also tried to find a counter-example, where $X$ is Banach. This seemed much more difficult. I could so far only find a counter-example under the assumption of the existence of a non-continuous linear functional: If $f$ is such a functional on $X$, set $K = \{x\in X\mid  |f(x)|\le 1\}$. Then $K$ is convex and absorbing, but $\mathrm{Int }K = \emptyset$. This leads to the question, whether the axiom of choice is necessary to construct a counter-example on Banach spaces or not. Question: Is there an explicit example (i.e. one whose construction does not involve the axiom of choice) of a convex set $K$ which is absorbing, but does not contain $0$ in its interior?","I have encountered the following problem in Dirk Werner's ""Funktionalanalysis"" (English translation by me): Definition: A convex set $K\subset X$ is called absorbing, if given $x\in X$ there exists $\lambda>0$ such that $\lambda x\in K$. Let $X$ be a normed vector space. If $K$ is convex, is it necessarily true that ""$K$ absorbing $\implies$ $0 \in \mathrm{Int }K$""? If $X$ is only assumed to be a normed space (not Banach), then I think $X = L^1[0,1]\cap L^\infty[0,1]$ equipped with the $L^1$-norm, and $K = \{f\in X\mid \Vert f\Vert_\infty \le 1\}$ gives a counterexample. $K$ is clearly absorbing and convex, but we can find a sequence $f_n \in X$ with $\Vert f_n\Vert_1 = 1/n \to 0$ and $\Vert f_n\Vert_{\infty} = 2$ for all $n$. So no ball around $0$ can be contained in $K$. I also tried to find a counter-example, where $X$ is Banach. This seemed much more difficult. I could so far only find a counter-example under the assumption of the existence of a non-continuous linear functional: If $f$ is such a functional on $X$, set $K = \{x\in X\mid  |f(x)|\le 1\}$. Then $K$ is convex and absorbing, but $\mathrm{Int }K = \emptyset$. This leads to the question, whether the axiom of choice is necessary to construct a counter-example on Banach spaces or not. Question: Is there an explicit example (i.e. one whose construction does not involve the axiom of choice) of a convex set $K$ which is absorbing, but does not contain $0$ in its interior?",,"['functional-analysis', 'axiom-of-choice']"
92,Compact operator and compact embeddings,Compact operator and compact embeddings,,"Here, all spaces are Banach spaces. Definition : A map $S:X \to X$ is compact if for every bounded sequence $\{u_n\}$, there exists a subsequence $\{u_{n_k}\}$ such that $\{S(u_{n_k})\}$ converges in $X$. Question : suppose $A$ is compactly embedded in $B$. Suppose a map $T:A \to A$ is continuous. Is there any chance that $T:A \to A$ is compact? ($T:B \to A$ is not definable or is ill-defined). If context is important: take $A=C^{2, \alpha}$ and $B=C^{0, \alpha}$, Hölder continuous functions. It is true that $A$ is compactly embedded in $B$ (the norms are different on $A$ and $B$ -- they are the standard norms on Wikipedia). Thoughts : I don't think so in general. I can't see any way, unless there's some cool theorem I'm not aware of (and I'm not aware of a lot of things so maybe this is possible). Motivation : want to show existence to a PDE problem.","Here, all spaces are Banach spaces. Definition : A map $S:X \to X$ is compact if for every bounded sequence $\{u_n\}$, there exists a subsequence $\{u_{n_k}\}$ such that $\{S(u_{n_k})\}$ converges in $X$. Question : suppose $A$ is compactly embedded in $B$. Suppose a map $T:A \to A$ is continuous. Is there any chance that $T:A \to A$ is compact? ($T:B \to A$ is not definable or is ill-defined). If context is important: take $A=C^{2, \alpha}$ and $B=C^{0, \alpha}$, Hölder continuous functions. It is true that $A$ is compactly embedded in $B$ (the norms are different on $A$ and $B$ -- they are the standard norms on Wikipedia). Thoughts : I don't think so in general. I can't see any way, unless there's some cool theorem I'm not aware of (and I'm not aware of a lot of things so maybe this is possible). Motivation : want to show existence to a PDE problem.",,"['functional-analysis', 'compact-operators']"
93,A Hölder norm bound that I need help with,A Hölder norm bound that I need help with,,"Define the seminorm on the space $S=[0,1]\times[0,T]$ $$[u]_{\alpha} = \sup\frac{|u(x, t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}}.$$ Define the norms on the same space $$\lVert u \rVert_{C^{0, \alpha}} = \lVert u \rVert_{C^0} + [u]_{\alpha}$$ and $$\lVert u \rVert_{C^{2, \alpha}} = \lVert u \rVert_{C^0} +\lVert u_x \rVert_{C^0}+\lVert u_{xx} \rVert_{C^0}+\lVert u_t \rVert_{C^0}+ [u_{xx}]_{\alpha} + [u_t]_{\alpha}.$$ I want to show that $[u_x]_\alpha \leq C\lVert u \rVert_{C^{2, \alpha}}$ where $C$ doesn't depend on $u_{xt}$. Does anyone have any hints how to do this? I tried using the MVT but that gives me a $u_{xt}$ which I can't bound above. Or is there something I can do with $u_{xt}$? Alternatively, is there anything I can do (as in bound above) with $$\sup\frac{|u_x(x, t) - u_x(x,s)|}{|t-s|^{\frac{\alpha}{2}}}?$$ I can't seem to avoid getting a mixed derivative $u_{xt}$ here. Thanks for any help. ADDED: $u$ solves the equation $$u_t = a_1u_{xx} + b_1u_x + c_1u + (f_1 + a_2v_{xx} + b_2v_x + c_2v)$$ where $v$ solves $$v_t = a_3v_{xx} + b_3v_x + c_3v + f_3$$ and the $a_i$, etc, are functions of $(x,t)$ in $C^{0, \alpha}$.","Define the seminorm on the space $S=[0,1]\times[0,T]$ $$[u]_{\alpha} = \sup\frac{|u(x, t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}}.$$ Define the norms on the same space $$\lVert u \rVert_{C^{0, \alpha}} = \lVert u \rVert_{C^0} + [u]_{\alpha}$$ and $$\lVert u \rVert_{C^{2, \alpha}} = \lVert u \rVert_{C^0} +\lVert u_x \rVert_{C^0}+\lVert u_{xx} \rVert_{C^0}+\lVert u_t \rVert_{C^0}+ [u_{xx}]_{\alpha} + [u_t]_{\alpha}.$$ I want to show that $[u_x]_\alpha \leq C\lVert u \rVert_{C^{2, \alpha}}$ where $C$ doesn't depend on $u_{xt}$. Does anyone have any hints how to do this? I tried using the MVT but that gives me a $u_{xt}$ which I can't bound above. Or is there something I can do with $u_{xt}$? Alternatively, is there anything I can do (as in bound above) with $$\sup\frac{|u_x(x, t) - u_x(x,s)|}{|t-s|^{\frac{\alpha}{2}}}?$$ I can't seem to avoid getting a mixed derivative $u_{xt}$ here. Thanks for any help. ADDED: $u$ solves the equation $$u_t = a_1u_{xx} + b_1u_x + c_1u + (f_1 + a_2v_{xx} + b_2v_x + c_2v)$$ where $v$ solves $$v_t = a_3v_{xx} + b_3v_x + c_3v + f_3$$ and the $a_i$, etc, are functions of $(x,t)$ in $C^{0, \alpha}$.",,"['functional-analysis', 'holder-spaces']"
94,Norms on spaces of unbounded holomorphic functions,Norms on spaces of unbounded holomorphic functions,,I am looking at a space of holomorphic functions defined on an unbounded set in C.  This space contains unbounded functions (but bounded on compact subsets). What is the classical/typical norm one would use on such a function space? Thanks,I am looking at a space of holomorphic functions defined on an unbounded set in C.  This space contains unbounded functions (but bounded on compact subsets). What is the classical/typical norm one would use on such a function space? Thanks,,"['complex-analysis', 'functional-analysis']"
95,Application of closed graph theorem.,Application of closed graph theorem.,,"I'm having a problem applying the closed graph theorem, which I think stems from distributions still being very new to me. I am reading a proof in Stein and Weiss, Introduction to Fourier Analysis on Euclidean Spaces , 4.13 in Chapter 1 , in the Further Results section, which begins: Suppose for the sake of contradiction that the Fourier transform of every function $f\in L^p (\mathbb{R})$, as a tempered distribution, is a function. The closed graph theorem easily shows, for all $f\in L^p, p>2$, there is a constant $A$ so that the following holds: $$\int_{|x|\le 1} | \ \hat f(x)| \ dx \le A ||f||_p. $$ I don't see how this follows from the closed graph theorem. Any help would be greatly appreciated.","I'm having a problem applying the closed graph theorem, which I think stems from distributions still being very new to me. I am reading a proof in Stein and Weiss, Introduction to Fourier Analysis on Euclidean Spaces , 4.13 in Chapter 1 , in the Further Results section, which begins: Suppose for the sake of contradiction that the Fourier transform of every function $f\in L^p (\mathbb{R})$, as a tempered distribution, is a function. The closed graph theorem easily shows, for all $f\in L^p, p>2$, there is a constant $A$ so that the following holds: $$\int_{|x|\le 1} | \ \hat f(x)| \ dx \le A ||f||_p. $$ I don't see how this follows from the closed graph theorem. Any help would be greatly appreciated.",,"['functional-analysis', 'distribution-theory']"
96,Generate Bernoulli polynomials in one integration.,Generate Bernoulli polynomials in one integration.,,"This is a follow up to one of my previous questions: Formula for integration bounds of recursively defined polynomial sequence . One aspect unfortunately wasn't answered at the time. That isn't a whine (in fact i was really pleased with the answer i got), i hold my hands up that the question wasn't specific enough - that's what this question is for. Bernoulli polynomials have a neat characterization: For $k \geq 1$ $$\displaystyle \frac{\partial }{\partial x}B_k(x)=k\cdot B_{k-1}(x)$$ $$\displaystyle \int_0^1 B_k(t) \, dt=\frac{1}{k+1}(B_{k+1}(1)-B_{k+1}(0))=0$$ Starting with $B_0(x)=1$ this generates all the polynomials. However, this is a two step process: first determine the indefinite integral $\tilde{B}_k = k\cdot \int B_k(t)\textrm{d}t$ and then determine the definite integral $\int_0^1\tilde{B}_k(t)\textrm{d}t$ to find out the integration constant that was unspecified in the indefinite integral so that the integral over $[0,1]$ is $0$. It is possible to compress this into one integration with $$B_{k+1}(x) = (k+1) \int_{c_k}^x B_k(t)\textrm{d}t$$ where the $c_k$ determine the constant of integration, but they change with each $k$. As in my other question it turns out that there are multiple possible $c_k$ for each $k$. In fact the number of possibilities is proportional to $k$ (since it involves solving a polynomial equation who's degree goes up with $k$). Is there some formula that generates one $c_k$ for each $k$? Because then $B_{k+1}(x) = (k+1) \int_{F(k)}^x B_k(t)\textrm{d}t$ solves the problem. Here is a list of the all the possible values for $c_k$ from $k=1..14$ and here are the corresponding polynomials (the possible $c_k$ are the roots of these polynomials), generated with octave, so please excuse the lack of formatting. For $k=5$ there is probably some numerical glitch (and others - also sometimes the root-finding fails to find all the roots). EDIT: It turns out that these polynomials are just the Bernoulli polynomials again. So for odd $k$ the values $c_k=0,~0.5$ and $1$ work because those are always roots of odd Bernoulli polynomials. For even $k$ it is more tricky since the roots are more complicated, but those polynomials have roots that converge to $0.25$ and $0.75$. These are the roots of $\sin(2\pi x)$ and $\cos(2\pi x)$ in the interval $[0,1]$ that a scaled version of the Bernoulli polynomials converges to. EDIT2: It is really obvious that this works, because if $r$ is a root of $B_{k+1}(x)$ then with property 1. we have: $$(k+1) \int_{r}^x B_k(t)\textrm{d}t = B_{k+1}(x)-B_{k+1}(r)=B_{k+1}(x).$$ If we integrate over $[0,x]$ this doesn't work because $B_k(0)$ isn't zero for even $k$ - in fact $B_k(0)$ are the Bernoulli numbers .","This is a follow up to one of my previous questions: Formula for integration bounds of recursively defined polynomial sequence . One aspect unfortunately wasn't answered at the time. That isn't a whine (in fact i was really pleased with the answer i got), i hold my hands up that the question wasn't specific enough - that's what this question is for. Bernoulli polynomials have a neat characterization: For $k \geq 1$ $$\displaystyle \frac{\partial }{\partial x}B_k(x)=k\cdot B_{k-1}(x)$$ $$\displaystyle \int_0^1 B_k(t) \, dt=\frac{1}{k+1}(B_{k+1}(1)-B_{k+1}(0))=0$$ Starting with $B_0(x)=1$ this generates all the polynomials. However, this is a two step process: first determine the indefinite integral $\tilde{B}_k = k\cdot \int B_k(t)\textrm{d}t$ and then determine the definite integral $\int_0^1\tilde{B}_k(t)\textrm{d}t$ to find out the integration constant that was unspecified in the indefinite integral so that the integral over $[0,1]$ is $0$. It is possible to compress this into one integration with $$B_{k+1}(x) = (k+1) \int_{c_k}^x B_k(t)\textrm{d}t$$ where the $c_k$ determine the constant of integration, but they change with each $k$. As in my other question it turns out that there are multiple possible $c_k$ for each $k$. In fact the number of possibilities is proportional to $k$ (since it involves solving a polynomial equation who's degree goes up with $k$). Is there some formula that generates one $c_k$ for each $k$? Because then $B_{k+1}(x) = (k+1) \int_{F(k)}^x B_k(t)\textrm{d}t$ solves the problem. Here is a list of the all the possible values for $c_k$ from $k=1..14$ and here are the corresponding polynomials (the possible $c_k$ are the roots of these polynomials), generated with octave, so please excuse the lack of formatting. For $k=5$ there is probably some numerical glitch (and others - also sometimes the root-finding fails to find all the roots). EDIT: It turns out that these polynomials are just the Bernoulli polynomials again. So for odd $k$ the values $c_k=0,~0.5$ and $1$ work because those are always roots of odd Bernoulli polynomials. For even $k$ it is more tricky since the roots are more complicated, but those polynomials have roots that converge to $0.25$ and $0.75$. These are the roots of $\sin(2\pi x)$ and $\cos(2\pi x)$ in the interval $[0,1]$ that a scaled version of the Bernoulli polynomials converges to. EDIT2: It is really obvious that this works, because if $r$ is a root of $B_{k+1}(x)$ then with property 1. we have: $$(k+1) \int_{r}^x B_k(t)\textrm{d}t = B_{k+1}(x)-B_{k+1}(r)=B_{k+1}(x).$$ If we integrate over $[0,x]$ this doesn't work because $B_k(0)$ isn't zero for even $k$ - in fact $B_k(0)$ are the Bernoulli numbers .",,"['calculus', 'analysis']"
97,Is functional integration useful in theoretical economics?,Is functional integration useful in theoretical economics?,,"Definition of functional integration here Functional integration is a collection of results in mathematics and   physics where the domain of an integral is no longer a region of   space, but a space of functions. Functional integrals arise in   probability, in the study of partial differential equations and in   Feynman's approach to the quantum mechanics of particles and fields","Definition of functional integration here Functional integration is a collection of results in mathematics and   physics where the domain of an integral is no longer a region of   space, but a space of functions. Functional integrals arise in   probability, in the study of partial differential equations and in   Feynman's approach to the quantum mechanics of particles and fields",,"['functional-analysis', 'economics']"
98,"A Hilbert basis for $L^2 ([0,1]\times[0,1])$",A Hilbert basis for,"L^2 ([0,1]\times[0,1])","Let $\{f_n(x)\}$ and $\{g_n(x)\}$ be two Hilbert basis of $L^2 ([0,1])$ then $\{g_n(x)f_k(y)\}$ is a Hilbert basis for $L^2 ([0,1]\times[0,1])$. Obs: That is Orthogonal, and unitary is I proved with a slight use of Fubini-Tonelli. It is only missing the density part of the span.","Let $\{f_n(x)\}$ and $\{g_n(x)\}$ be two Hilbert basis of $L^2 ([0,1])$ then $\{g_n(x)f_k(y)\}$ is a Hilbert basis for $L^2 ([0,1]\times[0,1])$. Obs: That is Orthogonal, and unitary is I proved with a slight use of Fubini-Tonelli. It is only missing the density part of the span.",,"['real-analysis', 'analysis', 'functional-analysis']"
99,Pointwise convergence resisting averaging,Pointwise convergence resisting averaging,,"Can you give an example of a sequence of continuous functions $f_n:[0,1]\to [0,1]$, such that $f_n\to 0$ pointwise and there is no subsequence $(f_{n_k})$ for which $\frac 1 m\sum_{k=1}^{m}f_{n_k}$ tends to zero uniformly? I think it's the same as asking whether the Banach space of continuous real valued functions has the ""weak Banach-Saks property"", but I was unable to find out the answer.","Can you give an example of a sequence of continuous functions $f_n:[0,1]\to [0,1]$, such that $f_n\to 0$ pointwise and there is no subsequence $(f_{n_k})$ for which $\frac 1 m\sum_{k=1}^{m}f_{n_k}$ tends to zero uniformly? I think it's the same as asking whether the Banach space of continuous real valued functions has the ""weak Banach-Saks property"", but I was unable to find out the answer.",,['functional-analysis']
