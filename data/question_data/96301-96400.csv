,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Characterization of entire functions to be a polynomial,Characterization of entire functions to be a polynomial,,I need some help with this proposition: If $f:\mathbb{C}\longrightarrow \mathbb{C}$ is an entire function such that $\{z\in \mathbb{C}:f(z)=w\}$ is finite for all $w\in \mathrm{Im} (f)$ then $f$ is a polynomial. Any hint would be appreciated.,I need some help with this proposition: If $f:\mathbb{C}\longrightarrow \mathbb{C}$ is an entire function such that $\{z\in \mathbb{C}:f(z)=w\}$ is finite for all $w\in \mathrm{Im} (f)$ then $f$ is a polynomial. Any hint would be appreciated.,,['complex-analysis']
1,"That for a polynomial of degree $n$, $\frac{M(r)}{r^n}$ is a non-decreasing function of $r$.","That for a polynomial of degree ,  is a non-decreasing function of .",n \frac{M(r)}{r^n} r,"Where the $M(r)=\operatorname{Max}_{\mid z\mid=r}f(z)$, where $f(z)=p_n(x)$, a polynomial of degree $n$. My first attempt: maybe this is related to the Cauchy's inequality of estimating derivatives. Maybe consider the integral $\displaystyle \int \frac{f(z)}{z^{n+1}}\mathrm{d}z$? Another attempt: The inequality $\displaystyle \frac{M(r)}{r^{n}}\leq\frac{M(R)}{R^n}$ remotely assembles the Hadamard three circle theorem.","Where the $M(r)=\operatorname{Max}_{\mid z\mid=r}f(z)$, where $f(z)=p_n(x)$, a polynomial of degree $n$. My first attempt: maybe this is related to the Cauchy's inequality of estimating derivatives. Maybe consider the integral $\displaystyle \int \frac{f(z)}{z^{n+1}}\mathrm{d}z$? Another attempt: The inequality $\displaystyle \frac{M(r)}{r^{n}}\leq\frac{M(R)}{R^n}$ remotely assembles the Hadamard three circle theorem.",,['complex-analysis']
2,radius of convergence for $\sum_{n=1}^{\infty} \frac{z^{n} n^{n}}{n!}$ and $\sum_{n=1}^{\infty} z^{n!}$,radius of convergence for  and,\sum_{n=1}^{\infty} \frac{z^{n} n^{n}}{n!} \sum_{n=1}^{\infty} z^{n!},"Exercise 4:10 in John D'Angelo's text is to find the radius of convergence for : A) $\sum_{n=1}^\infty \frac{z^n n^n}{n!}$ and B)  $\sum_{n=1}^\infty z^{n!}$ I got half of an answer for A) which I wanted to check and I got totally stuck on B). Thanks for the help. I know from the Theorem in the section that $\frac{1}{R} = \limsup |a_n|^{\frac{1}{n}}$ where $R$ is the radius of convergence. So, for A: $$\frac{1}{R} = \frac{n}{n!^{\frac{1}{n}}}\text{ so }\frac{1}{R} = \limsup \frac{n!^\left({\frac{1}{n}}\right)}{n}$$ which I think is $0$ but I'm not positive. I doubt this is correct because that would mean that the radius of convergence is $\infty$ which seems wrong. for B: $z^{n!} = z^{(n \times(n-1)!)}$ but I don't know how to eliminate the $(n-1)!$ so I can just have a $z^{n}$ so that I can use the theorem above regarding $R$. Thanks again. Oh, I know I asked this before but if anyone knows of a solution manual to this text, I'd appreciate it. I'm not a student so not trying to cheat on the homework but rather just trying to understand the basics.","Exercise 4:10 in John D'Angelo's text is to find the radius of convergence for : A) $\sum_{n=1}^\infty \frac{z^n n^n}{n!}$ and B)  $\sum_{n=1}^\infty z^{n!}$ I got half of an answer for A) which I wanted to check and I got totally stuck on B). Thanks for the help. I know from the Theorem in the section that $\frac{1}{R} = \limsup |a_n|^{\frac{1}{n}}$ where $R$ is the radius of convergence. So, for A: $$\frac{1}{R} = \frac{n}{n!^{\frac{1}{n}}}\text{ so }\frac{1}{R} = \limsup \frac{n!^\left({\frac{1}{n}}\right)}{n}$$ which I think is $0$ but I'm not positive. I doubt this is correct because that would mean that the radius of convergence is $\infty$ which seems wrong. for B: $z^{n!} = z^{(n \times(n-1)!)}$ but I don't know how to eliminate the $(n-1)!$ so I can just have a $z^{n}$ so that I can use the theorem above regarding $R$. Thanks again. Oh, I know I asked this before but if anyone knows of a solution manual to this text, I'd appreciate it. I'm not a student so not trying to cheat on the homework but rather just trying to understand the basics.",,['complex-analysis']
3,Problem about Eisenstein series on $\Gamma_1(N)$,Problem about Eisenstein series on,\Gamma_1(N),"I'm learning about Eisenstein series on $\Gamma_1(N)$ and it seems to me that I have misunderstood something. I imagine the following situation : Let $\nu$ be a function on $(\mathbb{Z}/ N \mathbb{Z})$ to $\mathbb{C}$. One can define an ""Eisenstein form"" for $k\geq 3$, $$G_k(\nu,\tau)=\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{(m\tau +n)^k}}$$ Since  \begin{align} G_k\left(\nu,\frac{a\tau+b}{c\tau +d}\right) &= (c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{((am+cn)\tau +(bm+dn))^k}} \\ &=(c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{u,v}{\frac{\nu(\overline{du-cv})}{(u\tau +v)^k}} \\ &=(c\tau+d)^k G_k(\nu,\tau) \end{align} when $ad-bc=1$, $c\equiv 0 \pmod{N}$, $d\equiv 1 \pmod N$, $G_k(\nu,\cdot)$ is a modular form of weight $k$ on $\Gamma_1(N)$. But we also have the Fourier serie : $$G_k(\nu,\tau)=-\frac{B_k}{2k}+\sum_{n=1}^{+\infty}{\sigma_{k-1}(\nu,n)q^n} \quad \quad q=e^{2i\pi \tau}$$ where $$\sigma_{k-1}(\nu,n)=\sum_{d|n}{\nu(\bar{d})\left(\frac{n}{d}\right)^{k-1}}$$ So $G_k \in E_k(\Gamma_1(N))$ - the space of Eisenstein series - when $k$ is even. Then for $k\geq 4$ even and $N=4$, since $\dim(E_k(\Gamma_1(4)))=3$, one can find $(a,b,c,d) \in \mathbb{C}^4$ such that $$aG_k(\alpha,\tau)+bG_k(\beta,\tau)+cG_k(\gamma,\tau)+dG_k(\delta,\tau)=0$$ but it's false in general (for instance, try $(\alpha,\beta,\gamma,\delta)=(\nu_0,\nu_1,\nu_2,\nu_3)$ where $\nu_i(\bar{m})$ is $1$ if $m\equiv i \pmod 4$ and $0$ otherwise). So where am I wrong ? Thanks a lot for your help !","I'm learning about Eisenstein series on $\Gamma_1(N)$ and it seems to me that I have misunderstood something. I imagine the following situation : Let $\nu$ be a function on $(\mathbb{Z}/ N \mathbb{Z})$ to $\mathbb{C}$. One can define an ""Eisenstein form"" for $k\geq 3$, $$G_k(\nu,\tau)=\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{(m\tau +n)^k}}$$ Since  \begin{align} G_k\left(\nu,\frac{a\tau+b}{c\tau +d}\right) &= (c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{m,n}{\frac{\nu(\bar{m})}{((am+cn)\tau +(bm+dn))^k}} \\ &=(c\tau+d)^k\frac{(k-1)!}{2(2i\pi)^k}\sum_{u,v}{\frac{\nu(\overline{du-cv})}{(u\tau +v)^k}} \\ &=(c\tau+d)^k G_k(\nu,\tau) \end{align} when $ad-bc=1$, $c\equiv 0 \pmod{N}$, $d\equiv 1 \pmod N$, $G_k(\nu,\cdot)$ is a modular form of weight $k$ on $\Gamma_1(N)$. But we also have the Fourier serie : $$G_k(\nu,\tau)=-\frac{B_k}{2k}+\sum_{n=1}^{+\infty}{\sigma_{k-1}(\nu,n)q^n} \quad \quad q=e^{2i\pi \tau}$$ where $$\sigma_{k-1}(\nu,n)=\sum_{d|n}{\nu(\bar{d})\left(\frac{n}{d}\right)^{k-1}}$$ So $G_k \in E_k(\Gamma_1(N))$ - the space of Eisenstein series - when $k$ is even. Then for $k\geq 4$ even and $N=4$, since $\dim(E_k(\Gamma_1(4)))=3$, one can find $(a,b,c,d) \in \mathbb{C}^4$ such that $$aG_k(\alpha,\tau)+bG_k(\beta,\tau)+cG_k(\gamma,\tau)+dG_k(\delta,\tau)=0$$ but it's false in general (for instance, try $(\alpha,\beta,\gamma,\delta)=(\nu_0,\nu_1,\nu_2,\nu_3)$ where $\nu_i(\bar{m})$ is $1$ if $m\equiv i \pmod 4$ and $0$ otherwise). So where am I wrong ? Thanks a lot for your help !",,"['complex-analysis', 'number-theory', 'vector-spaces', 'congruences', 'modular-forms']"
4,Identify all the holomorphic functions $f$ such that $|f(z)|=1$ for every $z$ with $|z|=1$.,Identify all the holomorphic functions  such that  for every  with .,f |f(z)|=1 z |z|=1,"Find all the holomorphic functions $f$ holomorphic on an open set $G$ containing the closed unit ball $\bar{\mathbb{D}}$ such that $|f(z)|=1$ for every $z$ with $|z|=1$. I think that the functions are of the form $f(z)=cz^n$ for $n\geq 0$ and $|c|=1$. I am also looking, if possible, for a solution that does not make any use of the Schwarz's Reflection Principle.","Find all the holomorphic functions $f$ holomorphic on an open set $G$ containing the closed unit ball $\bar{\mathbb{D}}$ such that $|f(z)|=1$ for every $z$ with $|z|=1$. I think that the functions are of the form $f(z)=cz^n$ for $n\geq 0$ and $|c|=1$. I am also looking, if possible, for a solution that does not make any use of the Schwarz's Reflection Principle.",,['complex-analysis']
5,Singularities in Complex Analysis,Singularities in Complex Analysis,,"Determine the singular points of the following functions, the nature of these singular points and compute the residues in these points. $$(a)\:\dfrac{\cos z}{z^3},\qquad (b)\:\dfrac z{\sin z},\qquad(c)\:\dfrac{e^{z+10}}{z^{10}}.$$ Hi there - For $(a)$ and $(b)$, I know that the singularities are both $0$, with orders of $3$ and $10$ respectively. I know that the singularity of $(b)$ is $\sin(z)=o$, i.e. $nπ$. But I am not sure of the order of this one. Would it not be infinity (the $n$'s can keep on increasing)? Thanks for your help.","Determine the singular points of the following functions, the nature of these singular points and compute the residues in these points. $$(a)\:\dfrac{\cos z}{z^3},\qquad (b)\:\dfrac z{\sin z},\qquad(c)\:\dfrac{e^{z+10}}{z^{10}}.$$ Hi there - For $(a)$ and $(b)$, I know that the singularities are both $0$, with orders of $3$ and $10$ respectively. I know that the singularity of $(b)$ is $\sin(z)=o$, i.e. $nπ$. But I am not sure of the order of this one. Would it not be infinity (the $n$'s can keep on increasing)? Thanks for your help.",,['complex-analysis']
6,winding number in several complex variables,winding number in several complex variables,,"Is there any analogue of the concept of winding numbers in the theory of several complex variables? If so, can anyone provide me references for studying it?","Is there any analogue of the concept of winding numbers in the theory of several complex variables? If so, can anyone provide me references for studying it?",,"['complex-analysis', 'reference-request', 'several-complex-variables']"
7,Computing integral using complex analysis methods,Computing integral using complex analysis methods,,"I'm trying to compute the integral $$ \int_0^{\infty} \frac{\ln(x)}{x^2 + 1} \, dx $$ using complex analysis methods. We haven't learned residue calculus yet though, only contour integrals up through the Cauchy integral formula. I'm trying to make use of a half circle centered at the origin of radius $R$ and then let $R$ tend to infinity, but there is a definite singularity for the $\ln(x)$ function. Does anybody have a suggestion?","I'm trying to compute the integral $$ \int_0^{\infty} \frac{\ln(x)}{x^2 + 1} \, dx $$ using complex analysis methods. We haven't learned residue calculus yet though, only contour integrals up through the Cauchy integral formula. I'm trying to make use of a half circle centered at the origin of radius $R$ and then let $R$ tend to infinity, but there is a definite singularity for the $\ln(x)$ function. Does anybody have a suggestion?",,['complex-analysis']
8,Boundary behaviour of holomorphic function on unit disk,Boundary behaviour of holomorphic function on unit disk,,"Let $\mathbb{D}=\{z \in \mathbb{C} \ | \ |z|<1 \} $ be the open unit disk in the complex plane. I would like to see explicit examples of the following phenomena: a holomorphic function $f$ on $\mathbb{D}$ which extends continuously to the boundary but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) a holomorphic function $f$ on $\mathbb{D}$ which is bounded on $\mathbb{D}$ but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) Such functions should exist according to this answer to a previous post . Thanks for any reference/advice.","Let $\mathbb{D}=\{z \in \mathbb{C} \ | \ |z|<1 \} $ be the open unit disk in the complex plane. I would like to see explicit examples of the following phenomena: a holomorphic function $f$ on $\mathbb{D}$ which extends continuously to the boundary but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) a holomorphic function $f$ on $\mathbb{D}$ which is bounded on $\mathbb{D}$ but has no holomorphic extension beyond any boundary point (i.e. on sets of the form $\mathbb{D} \cup B(z_0,r)$ for some $r>0$ and $z_0 \in \partial \mathbb{D}$) Such functions should exist according to this answer to a previous post . Thanks for any reference/advice.",,"['complex-analysis', 'analyticity']"
9,asymptotical behavior of integral,asymptotical behavior of integral,,I'm interest in the asymptotical of $$\int_{-\pi}^{\pi}\exp\Big((\cos z+i\alpha\sin z-1)t\Big)dz\hspace{3mm}\text{as}\hspace{2mm}t\to\infty$$ for $-1<\alpha<1$. Numberical result suggest that for $\alpha =0$ the integral behave like $\frac{c}{\sqrt{t}}$ and for $\alpha\neq 0$ it behave like $\exp(ct)$ for some $c<0$. I don't think Laplace method work for this problem. Thank you to suggest other method.,I'm interest in the asymptotical of $$\int_{-\pi}^{\pi}\exp\Big((\cos z+i\alpha\sin z-1)t\Big)dz\hspace{3mm}\text{as}\hspace{2mm}t\to\infty$$ for $-1<\alpha<1$. Numberical result suggest that for $\alpha =0$ the integral behave like $\frac{c}{\sqrt{t}}$ and for $\alpha\neq 0$ it behave like $\exp(ct)$ for some $c<0$. I don't think Laplace method work for this problem. Thank you to suggest other method.,,"['real-analysis', 'complex-analysis', 'fourier-analysis', 'asymptotics']"
10,Help undersanding meromorphics Herglotz functions,Help undersanding meromorphics Herglotz functions,,"A meromorphic function $f$ is called  meromorphic herglotz function if $\mathrm{Im}(z)>0$ implies $\mathrm{Im}(f(z))>0$ I need to prove that all the poles and zeros of $f$ are in $\mathbb{R}$. Morover, each pole and zero is simple and the poles and zeros alterante. There is a proof here, but I can't understand why $\operatorname{arg}(f)$ takes all the values in $[0,2\pi)$ and why that implies that all the zeros and poles are in $\mathbb{R}$.","A meromorphic function $f$ is called  meromorphic herglotz function if $\mathrm{Im}(z)>0$ implies $\mathrm{Im}(f(z))>0$ I need to prove that all the poles and zeros of $f$ are in $\mathbb{R}$. Morover, each pole and zero is simple and the poles and zeros alterante. There is a proof here, but I can't understand why $\operatorname{arg}(f)$ takes all the values in $[0,2\pi)$ and why that implies that all the zeros and poles are in $\mathbb{R}$.",,['complex-analysis']
11,Analytic bijective function is either $az$ or $\frac{a}{z}$,Analytic bijective function is either  or,az \frac{a}{z},"I am trying to solve the following problem: Let $\mathbb{C}^* = \{z: 0 < |z| < \infty\}$ and $f: \mathbb{C}^* \to \mathbb{C}^*$, analytic and bijective function. Show that $f(z) = az$ or $f(z) = \frac{a}{z}$ for some $a \in \mathbb{C}$ I don't know where to start and would appreciate a hint. Thanks! Edit: I'm adding my (fairly) detailed solution for anyone who needs it. If you are looking for hints, you will find them in the comments.","I am trying to solve the following problem: Let $\mathbb{C}^* = \{z: 0 < |z| < \infty\}$ and $f: \mathbb{C}^* \to \mathbb{C}^*$, analytic and bijective function. Show that $f(z) = az$ or $f(z) = \frac{a}{z}$ for some $a \in \mathbb{C}$ I don't know where to start and would appreciate a hint. Thanks! Edit: I'm adding my (fairly) detailed solution for anyone who needs it. If you are looking for hints, you will find them in the comments.",,['complex-analysis']
12,Isomorphism between Hilbert spaces,Isomorphism between Hilbert spaces,,"I want to show that the function $$ L^2(\Omega,\mathcal{O})\longrightarrow L^2(\widetilde{\Omega},\mathcal{O}) \colon f \longmapsto f|_{\widetilde{\Omega}}$$ is a isomorphism, where $L^2(\mathbb{C},\mathcal{O})$ is the hilbert space of square-integrable holomorphic functions on $\mathbb{C}$ and $\Omega \subset \mathbb{C}$ is a bounded domain and for $E\subset \Omega$ finite we define $\widetilde{\Omega}:=\Omega \setminus E$.","I want to show that the function $$ L^2(\Omega,\mathcal{O})\longrightarrow L^2(\widetilde{\Omega},\mathcal{O}) \colon f \longmapsto f|_{\widetilde{\Omega}}$$ is a isomorphism, where $L^2(\mathbb{C},\mathcal{O})$ is the hilbert space of square-integrable holomorphic functions on $\mathbb{C}$ and $\Omega \subset \mathbb{C}$ is a bounded domain and for $E\subset \Omega$ finite we define $\widetilde{\Omega}:=\Omega \setminus E$.",,"['complex-analysis', 'analysis', 'hilbert-spaces', 'vector-space-isomorphism']"
13,Cover of a sheaf,Cover of a sheaf,,"We define $U_1:=\mathbb{P}^1\setminus\left\lbrace \infty\right\rbrace$ and $U_2:=\mathbb{P}^1\setminus\left\lbrace 0\right\rbrace$. $\Omega$ is the sheaf of holomorphic $1$-forms. How can I understand that $U=(U_1,U_2)$ is a Leray cover of $\mathbb{P}^1$ relating to the sheaf $\Omega$? I think therefor I have to show that $H^1(U_1,\Omega|_{U_1})=H^1(U_2,\Omega|_{U_2})=0.$","We define $U_1:=\mathbb{P}^1\setminus\left\lbrace \infty\right\rbrace$ and $U_2:=\mathbb{P}^1\setminus\left\lbrace 0\right\rbrace$. $\Omega$ is the sheaf of holomorphic $1$-forms. How can I understand that $U=(U_1,U_2)$ is a Leray cover of $\mathbb{P}^1$ relating to the sheaf $\Omega$? I think therefor I have to show that $H^1(U_1,\Omega|_{U_1})=H^1(U_2,\Omega|_{U_2})=0.$",,"['complex-analysis', 'sheaf-theory']"
14,Solve $\mathscr{F}^{-1} [ \cot{a \omega} \times \mathscr{F} \{ U(t) \sin{\omega_0 t} \} ] $ using contour integration,Solve  using contour integration,\mathscr{F}^{-1} [ \cot{a \omega} \times \mathscr{F} \{ U(t) \sin{\omega_0 t} \} ] ,"I wish to evaluate $y(t) = \mathscr{F}^{-1} [ \cot{a \omega} \times \mathscr{F} \{ U(t)  \sin{\omega_0 t} \} ]  $, where $\mathscr{F}$ represents the Fourier transform, and U(t) represents the Heaviside step function. I seek to use contour integration to remove the singularities introduced by $\cot{a \omega}$ and express the result as an infinite sum of residues. I have attempted this myself and believe there must be a mistake because the answer doesn't seem to make sense. Can anybody help me? My attempt at the problem: 1) Substitute the Fourier transform of the right-hand sine into the problem. $$ y(t) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \cot{a \omega} \Big[ \frac{\pi}{2j} [ \delta(\omega - \omega_0) - \delta(\omega + \omega_0) ] + \frac{\omega_0}{\omega_0^2 - \omega^2} \Big] e^{j \omega t} \, d \omega $$ 2) Use the translation property of the delta function. $$ y(t) = - \frac{j}{2} \cot{a \omega_0} \cos{\omega_0 t} + \frac{1}{2 \pi} \int_{-\infty}^{\infty} \frac{\omega_0 \cot{a \omega} }{ \omega_0^2 - \omega^2} e^{j \omega t} \, d \omega$$ 3) Evaluate the infinite integral $I = \int_{-\infty}^{\infty} \frac{\omega_0 \cot{a \omega} }{ \omega_0^2 - \omega^2} e^{j \omega t} \, d \omega$ by indenting the contour to avoid the set of poles lying on the real axis, and assuming the integral of the path around the large arc is 0 (Jordan's Lemma). Thus $$ I = - j \pi \sum \text{res}, $$ where the residues at the infinite set of first order poles $\omega = \pm n\pi /a $, ($n = 0,1,2...$), and the two first order poles $\omega = \pm \omega_0$ are given by $$ \mathrm{res}_\omega = \frac{ \omega_0 \cos{a\omega} e^{j \omega t} }{ (\omega_0^2 - \omega^2) a \cos{a \omega} - 2 \omega \sin{a \omega} },$$ and so $$ \begin{align} I & = - j \pi \Big( - \frac{1}{2} \cot{a \omega_0} e^{j \omega_0 t} - \frac{1}{2} \cot{a \omega_0} e^{-j \omega_0 t}  \Big) -  j \pi \Big( \sum_{n=-\infty}^{\infty} \frac{\omega_0 \cos{a \omega_n} e^{j \omega_n t}}{ (\omega_0^2 - \omega_n^2) a \cos{a \omega_n} } \Big) \\ & = j \pi \cot{a \omega_0} \cos{\omega_0 t} + j \pi \sum_{n=0}^{\infty} \epsilon_n \frac{\cos{w_n t} }{a (\omega_n^2 - \omega_0^2) }\end{align}$$ 4) Substitute the result into the expression for $y(t)$... $$ y(t) = 0 + \frac{j}{2a} \sum_{n=0}^{\infty} \epsilon_n \frac{\cos{w_n t} }{ (\omega_n^2 - \omega_0^2) } $$ I believe that this is incorrect since I would anticipate that $$ y(t) \rightarrow \cot{a \omega_0} \sin{\omega_0 t} \quad \text{as} \quad t \rightarrow \infty. $$","I wish to evaluate $y(t) = \mathscr{F}^{-1} [ \cot{a \omega} \times \mathscr{F} \{ U(t)  \sin{\omega_0 t} \} ]  $, where $\mathscr{F}$ represents the Fourier transform, and U(t) represents the Heaviside step function. I seek to use contour integration to remove the singularities introduced by $\cot{a \omega}$ and express the result as an infinite sum of residues. I have attempted this myself and believe there must be a mistake because the answer doesn't seem to make sense. Can anybody help me? My attempt at the problem: 1) Substitute the Fourier transform of the right-hand sine into the problem. $$ y(t) = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \cot{a \omega} \Big[ \frac{\pi}{2j} [ \delta(\omega - \omega_0) - \delta(\omega + \omega_0) ] + \frac{\omega_0}{\omega_0^2 - \omega^2} \Big] e^{j \omega t} \, d \omega $$ 2) Use the translation property of the delta function. $$ y(t) = - \frac{j}{2} \cot{a \omega_0} \cos{\omega_0 t} + \frac{1}{2 \pi} \int_{-\infty}^{\infty} \frac{\omega_0 \cot{a \omega} }{ \omega_0^2 - \omega^2} e^{j \omega t} \, d \omega$$ 3) Evaluate the infinite integral $I = \int_{-\infty}^{\infty} \frac{\omega_0 \cot{a \omega} }{ \omega_0^2 - \omega^2} e^{j \omega t} \, d \omega$ by indenting the contour to avoid the set of poles lying on the real axis, and assuming the integral of the path around the large arc is 0 (Jordan's Lemma). Thus $$ I = - j \pi \sum \text{res}, $$ where the residues at the infinite set of first order poles $\omega = \pm n\pi /a $, ($n = 0,1,2...$), and the two first order poles $\omega = \pm \omega_0$ are given by $$ \mathrm{res}_\omega = \frac{ \omega_0 \cos{a\omega} e^{j \omega t} }{ (\omega_0^2 - \omega^2) a \cos{a \omega} - 2 \omega \sin{a \omega} },$$ and so $$ \begin{align} I & = - j \pi \Big( - \frac{1}{2} \cot{a \omega_0} e^{j \omega_0 t} - \frac{1}{2} \cot{a \omega_0} e^{-j \omega_0 t}  \Big) -  j \pi \Big( \sum_{n=-\infty}^{\infty} \frac{\omega_0 \cos{a \omega_n} e^{j \omega_n t}}{ (\omega_0^2 - \omega_n^2) a \cos{a \omega_n} } \Big) \\ & = j \pi \cot{a \omega_0} \cos{\omega_0 t} + j \pi \sum_{n=0}^{\infty} \epsilon_n \frac{\cos{w_n t} }{a (\omega_n^2 - \omega_0^2) }\end{align}$$ 4) Substitute the result into the expression for $y(t)$... $$ y(t) = 0 + \frac{j}{2a} \sum_{n=0}^{\infty} \epsilon_n \frac{\cos{w_n t} }{ (\omega_n^2 - \omega_0^2) } $$ I believe that this is incorrect since I would anticipate that $$ y(t) \rightarrow \cot{a \omega_0} \sin{\omega_0 t} \quad \text{as} \quad t \rightarrow \infty. $$",,"['complex-analysis', 'fourier-analysis', 'improper-integrals', 'contour-integration', 'residue-calculus']"
15,Integral $\int_{0}^{\infty} \frac{\sin{x}}{x^2+1} dx$,Integral,\int_{0}^{\infty} \frac{\sin{x}}{x^2+1} dx,"How to evaluate : $$\int_{0}^{\infty} \frac{\sin{x}}{x^2+1} dx$$ The integral from $-\infty$ to $\infty$ is quite easy, but how could we integrate this function from $0$ to $\infty$ ?","How to evaluate : The integral from to is quite easy, but how could we integrate this function from to ?",\int_{0}^{\infty} \frac{\sin{x}}{x^2+1} dx -\infty \infty 0 \infty,"['complex-analysis', 'analysis', 'definite-integrals', 'improper-integrals']"
16,Integrating $ \int_0^1 \frac{e^{ix}}{x^6+1}dx $,Integrating, \int_0^1 \frac{e^{ix}}{x^6+1}dx ,"Integrating $$ \int_0^1 \frac{e^{ix}}{x^6+1}dx $$ but having trouble.    I factored $x^6+1$ but does not work for the problem.  I used identity $e^{ix}=\cos x +i\sin x$, but got nowhere.  I  can say with certainty  $$ x^6+1=0, \ x=(-1)^{1/6} $$ and has 6 roots in the complex plane . Very much glad for the help.","Integrating $$ \int_0^1 \frac{e^{ix}}{x^6+1}dx $$ but having trouble.    I factored $x^6+1$ but does not work for the problem.  I used identity $e^{ix}=\cos x +i\sin x$, but got nowhere.  I  can say with certainty  $$ x^6+1=0, \ x=(-1)^{1/6} $$ and has 6 roots in the complex plane . Very much glad for the help.",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals']"
17,Maximum of an analytic function on the unit disk.,Maximum of an analytic function on the unit disk.,,"This question is a old question but in that question one condition was not explained well. Let $f$ be analytic on the unit disk $D$. Assume that $f(r)=\max\limits_{|z|=r} |f(z)|$. (Note that here we are not defining a new function. It just means  that $f(z)$ attains its maximum at a point $z=r$.) Why $f′(r)>0$, if $f$ is not a constant? And why if $f(0)=0$, then $rf'(r)\geq f(r)$ and the equality holds if and only if $f(z)=cz$ for some nonnegative constant $c$ ? Why $f'(r)$ is real number and even positive? Why not negative or some complex number? It is pretty strange for me!","This question is a old question but in that question one condition was not explained well. Let $f$ be analytic on the unit disk $D$. Assume that $f(r)=\max\limits_{|z|=r} |f(z)|$. (Note that here we are not defining a new function. It just means  that $f(z)$ attains its maximum at a point $z=r$.) Why $f′(r)>0$, if $f$ is not a constant? And why if $f(0)=0$, then $rf'(r)\geq f(r)$ and the equality holds if and only if $f(z)=cz$ for some nonnegative constant $c$ ? Why $f'(r)$ is real number and even positive? Why not negative or some complex number? It is pretty strange for me!",,['complex-analysis']
18,Computing $\int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz|$ when $0 > \rho \ne |a|$,Computing  when,\int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| 0 > \rho \ne |a|,"Goal: In what follows we let $\gamma = \rho e^{it}$ on $0 \le t \le 2\pi$ serve as the paramaterization of the curve $|z| = \rho$.  We also assume that $\rho > 0$ (else the computation is trivially equal to zero). We wish to compute $$ \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz|  $$ when $0 < \rho \ne |a|$. Attempt, with questions in step (3) and (4): We have that \begin{align*} = & \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 \overline{(z - a)^2}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 (\overline{z} - \overline{a})^2}\ |dz| \\ = & \int_0^{2 \pi} {1 \over (\rho e^{i t} - a)^2 (\rho e^{-i t} - \overline{a})^2} |i\rho e^{i t}|\ dt\\ = & \rho \int_0^{2 \pi} {1 \over (\rho e^{i t} - a)^2 (\rho e^{-i t} - \overline{a})^2} \ dt\\ \end{align*} As a consequence, we can say either of the following: \begin{equation*} \tag{*} \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| = \rho \int_0^{2 \pi} {{1 \over (\rho e^{i t} - a)^2} \over (\rho e^{-i t} - \overline{a})^2} \ dt \end{equation*} or also \begin{equation*} \tag{**} \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| = \rho \int_0^{2 \pi} {{1 \over (\rho e^{-i t} - \overline{a})^2} \over (\rho e^{i t} - a)^2} \ dt \end{equation*} Now if $\rho < |a|$, then doesn't the fact that ${1 \over (z-a)^4}$ is analytic on the disk of size $\rho$ imply that the integral is zero (via Cauchy's integral theorem on a disk)? On the other hand, if $\rho > |a|$, can we apply Cauchy's Integral Formula to the numerator of, say, $(*)$  to yield the computation? EDIT: Substituting $|dz| = {-i\rho \over z}\  dz$ and $\overline{z} = {\rho^2 \over z}$ yields: \begin{align*} = & \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 \overline{(z - a)^2}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 (\overline{z} - \overline{a})^2}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 ({\rho^2 \over z} - \overline{a})^2}\ {-i\rho \over z}\  dz \\ = & \int_{|z| = \rho} {{-i\rho \over z({\rho^2 \over z} - \overline{a})^2} \over (z-a)^2 }\ \  dz \\ \end{align*} But it seems like here Cauchy's Integral Formula doesn't apply since ${-i\rho \over z({\rho^2 \over z} - \overline{a})^2}$ is undefined at $0$ and hence not analytic inside $\gamma$.","Goal: In what follows we let $\gamma = \rho e^{it}$ on $0 \le t \le 2\pi$ serve as the paramaterization of the curve $|z| = \rho$.  We also assume that $\rho > 0$ (else the computation is trivially equal to zero). We wish to compute $$ \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz|  $$ when $0 < \rho \ne |a|$. Attempt, with questions in step (3) and (4): We have that \begin{align*} = & \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 \overline{(z - a)^2}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 (\overline{z} - \overline{a})^2}\ |dz| \\ = & \int_0^{2 \pi} {1 \over (\rho e^{i t} - a)^2 (\rho e^{-i t} - \overline{a})^2} |i\rho e^{i t}|\ dt\\ = & \rho \int_0^{2 \pi} {1 \over (\rho e^{i t} - a)^2 (\rho e^{-i t} - \overline{a})^2} \ dt\\ \end{align*} As a consequence, we can say either of the following: \begin{equation*} \tag{*} \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| = \rho \int_0^{2 \pi} {{1 \over (\rho e^{i t} - a)^2} \over (\rho e^{-i t} - \overline{a})^2} \ dt \end{equation*} or also \begin{equation*} \tag{**} \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| = \rho \int_0^{2 \pi} {{1 \over (\rho e^{-i t} - \overline{a})^2} \over (\rho e^{i t} - a)^2} \ dt \end{equation*} Now if $\rho < |a|$, then doesn't the fact that ${1 \over (z-a)^4}$ is analytic on the disk of size $\rho$ imply that the integral is zero (via Cauchy's integral theorem on a disk)? On the other hand, if $\rho > |a|$, can we apply Cauchy's Integral Formula to the numerator of, say, $(*)$  to yield the computation? EDIT: Substituting $|dz| = {-i\rho \over z}\  dz$ and $\overline{z} = {\rho^2 \over z}$ yields: \begin{align*} = & \int_{|z|=\rho} {1 \over |z-a|^{4}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 \overline{(z - a)^2}}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 (\overline{z} - \overline{a})^2}\ |dz| \\ = & \int_{|z| = \rho} {1 \over (z-a)^2 ({\rho^2 \over z} - \overline{a})^2}\ {-i\rho \over z}\  dz \\ = & \int_{|z| = \rho} {{-i\rho \over z({\rho^2 \over z} - \overline{a})^2} \over (z-a)^2 }\ \  dz \\ \end{align*} But it seems like here Cauchy's Integral Formula doesn't apply since ${-i\rho \over z({\rho^2 \over z} - \overline{a})^2}$ is undefined at $0$ and hence not analytic inside $\gamma$.",,"['complex-analysis', 'analysis']"
19,functions orthogonal to the exponential Bell polynomials,functions orthogonal to the exponential Bell polynomials,,"Consider the single variable Bell polynomials $\phi_{n}(x)$ given by: $$\phi_{n}(x)=e^{-x}\sum_{k=0}^{\infty}\frac{k^{n}x^{k}}{k!}$$ I am looking for a set of functions $\tilde{\phi}_{n}(x)$ such that, for some inner product, the pair $\phi_{n}(x)$ , and $\tilde{\phi}_{m}(x)$ is orthogonal. Boyadzhiev proved a semi-orthogonality property for the polynomials $\;\phi_{n}(x)$ : $$\int_{-\infty}^{0}\phi_{n}(x)\phi_{m}(x)\frac{e^{2x}}{x}dx=(-1)^{n}\frac{2^{n+m}-1}{n+m}B_{n+m}$$ $B_{k}$ being the kth Bernoulli number. But i wish for complete orthogonality ! i have tried the following : It's easy to check the validity of $$\int_{0}^{\infty}e^{-x}\phi_{n}(-x)x^{s-1}dx=(-s)^{n}\Gamma(s)\;\;\;\;(\Re(s)>0)$$ By Parseval's theorem for the Mellin transform, we have: $$\int_{0}^{\infty}\phi_{n}(-x)\tilde{\phi}_{m}(x)e^{-x}\frac{dx}{x}=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}(-s)^{n}\Gamma(s)\Phi_{m}(-s)ds$$ Where : $$\Phi_{m}(s)=\int_{0}^{\infty}\tilde{\phi}_{m}(x)x^{s-1}dx$$ And $\sigma$ lies in the common domain of analycity of $\Gamma(s)\;$ and $\; \Phi_{m}(s)$ . But that is the farthest I could go trying to get (weighted) Kronecker delta from the integral !! EDIT 1 Using the generating function of $\phi_{n}(x)$ : $$\sum_{n=0}^{\infty}\frac{\phi_{n}(x)}{n!}t^{n}=\exp\left[x\left(e^{t}-1 \right ) \right ]$$ We have: $$\frac{\phi_{m}(x)}{m!}=\frac{1}{2\pi}\int_{0}^{2\pi}\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]e^{-imt}dt$$ Now, for a suitable choice of the domain of integration $I$ , we put: $$\int_{I}\frac{\phi_{m}(x)\tilde{\phi}_{n}(x)}{m!}dx=\frac{1}{2\pi}\int_{I}\int_{0}^{2\pi}\tilde{\phi}_{n}(x)\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]e^{-imt}dtdx$$ And we get orthogonality by requiring : $$\int_{I}\tilde{\phi}_{n}(x)\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]dx=e^{int}$$ Or, by a suitable choice of the branch cut of $\log$ : $$\int_{I}\tilde{\phi}_{n}(x)\exp\left[x\left(z-1 \right ) \right ]dx=(\log z)^{n}$$ EDIT 2 We use the integral representation of the gamma function to obtain: $$\int_{0}^{\infty}x^{a}e^{-sx}dx=\frac{\Gamma(a+1)}{s^{a+1}}\;\;\;\;\Re(s)>0$$ Thus: $$\int_{0}^{\infty}\left(\log x \right )^{n}e^{-sx}dx=\lim_{a\rightarrow 0}\frac{d^{n}}{da^{n}}\frac{\Gamma(a+1)}{s^{a+1}}=\frac{1}{s}\sum_{k=0}^{n}a_{k}(\log s)^{k}$$ Therefore, there exist nth order polynomials in $\log x$ , that we'll denote by $f_{n}(x)$ , such that: $$\int_{0}^{\infty}f_{n}(x)e^{-sx}dx=\frac{(\log s)^{n}}{s}$$ Now we put $s=e^{z}$ , and obtain: $$\int_{0}^{\infty}e^{-x}f_{n}(x)e^{-x(e^{z}-1)}dx=e^{-z}z^{n}$$ Or: $$\sum_{m=0}^{\infty}\int_{0}^{\infty} e^{-x}f_{n}(x)\frac{\phi_{m}(-x)}{m!}z^{m}dx=e^{-z}z^{n}$$ This is the closest i got !","Consider the single variable Bell polynomials given by: I am looking for a set of functions such that, for some inner product, the pair , and is orthogonal. Boyadzhiev proved a semi-orthogonality property for the polynomials : being the kth Bernoulli number. But i wish for complete orthogonality ! i have tried the following : It's easy to check the validity of By Parseval's theorem for the Mellin transform, we have: Where : And lies in the common domain of analycity of and . But that is the farthest I could go trying to get (weighted) Kronecker delta from the integral !! EDIT 1 Using the generating function of : We have: Now, for a suitable choice of the domain of integration , we put: And we get orthogonality by requiring : Or, by a suitable choice of the branch cut of : EDIT 2 We use the integral representation of the gamma function to obtain: Thus: Therefore, there exist nth order polynomials in , that we'll denote by , such that: Now we put , and obtain: Or: This is the closest i got !",\phi_{n}(x) \phi_{n}(x)=e^{-x}\sum_{k=0}^{\infty}\frac{k^{n}x^{k}}{k!} \tilde{\phi}_{n}(x) \phi_{n}(x) \tilde{\phi}_{m}(x) \;\phi_{n}(x) \int_{-\infty}^{0}\phi_{n}(x)\phi_{m}(x)\frac{e^{2x}}{x}dx=(-1)^{n}\frac{2^{n+m}-1}{n+m}B_{n+m} B_{k} \int_{0}^{\infty}e^{-x}\phi_{n}(-x)x^{s-1}dx=(-s)^{n}\Gamma(s)\;\;\;\;(\Re(s)>0) \int_{0}^{\infty}\phi_{n}(-x)\tilde{\phi}_{m}(x)e^{-x}\frac{dx}{x}=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}(-s)^{n}\Gamma(s)\Phi_{m}(-s)ds \Phi_{m}(s)=\int_{0}^{\infty}\tilde{\phi}_{m}(x)x^{s-1}dx \sigma \Gamma(s)\; \; \Phi_{m}(s) \phi_{n}(x) \sum_{n=0}^{\infty}\frac{\phi_{n}(x)}{n!}t^{n}=\exp\left[x\left(e^{t}-1 \right ) \right ] \frac{\phi_{m}(x)}{m!}=\frac{1}{2\pi}\int_{0}^{2\pi}\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]e^{-imt}dt I \int_{I}\frac{\phi_{m}(x)\tilde{\phi}_{n}(x)}{m!}dx=\frac{1}{2\pi}\int_{I}\int_{0}^{2\pi}\tilde{\phi}_{n}(x)\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]e^{-imt}dtdx \int_{I}\tilde{\phi}_{n}(x)\exp\left[x\left(e^{e^{it}}-1 \right ) \right ]dx=e^{int} \log \int_{I}\tilde{\phi}_{n}(x)\exp\left[x\left(z-1 \right ) \right ]dx=(\log z)^{n} \int_{0}^{\infty}x^{a}e^{-sx}dx=\frac{\Gamma(a+1)}{s^{a+1}}\;\;\;\;\Re(s)>0 \int_{0}^{\infty}\left(\log x \right )^{n}e^{-sx}dx=\lim_{a\rightarrow 0}\frac{d^{n}}{da^{n}}\frac{\Gamma(a+1)}{s^{a+1}}=\frac{1}{s}\sum_{k=0}^{n}a_{k}(\log s)^{k} \log x f_{n}(x) \int_{0}^{\infty}f_{n}(x)e^{-sx}dx=\frac{(\log s)^{n}}{s} s=e^{z} \int_{0}^{\infty}e^{-x}f_{n}(x)e^{-x(e^{z}-1)}dx=e^{-z}z^{n} \sum_{m=0}^{\infty}\int_{0}^{\infty} e^{-x}f_{n}(x)\frac{\phi_{m}(-x)}{m!}z^{m}dx=e^{-z}z^{n},"['complex-analysis', 'hilbert-spaces', 'orthogonal-polynomials']"
20,How can the winding number change under a holomorphic map?,How can the winding number change under a holomorphic map?,,"This question comes from an old complex analysis qual.  First denote $\mathbb{C}^{\times} = \mathbb{C} \backslash \{ 0 \}$, $u = \{ e^{it} : 0 \leq t < 2 \pi \}$, and let $f : \mathbb{C}^{\times} \to \mathbb{C}^{\times}$ be some holomorphic function.  Then the winding number $$ \frac{1}{2 \pi i} \int_{f(u)} \frac{dz}{z} $$ can take any integer value depending on $f$ (by letting $f(z) = z^n$, for example).  However, if we change the domain and codomain of $f$ to something like $\{ z \in \mathbb{C} : \frac{1}{4} < |z| < 4 \}$, then we can't use those $f$'s we used before.  The winding number can still be $1$ of course by using the identity.  I see that it can also be $0$ by letting $f(z) = 1$.  We can also get the winding number to be $-1$ by setting $f(z) = z^{-1}$.  Can we get the winding number to be $2$?  I suspect not but am having trouble showing it.  Thoughts?","This question comes from an old complex analysis qual.  First denote $\mathbb{C}^{\times} = \mathbb{C} \backslash \{ 0 \}$, $u = \{ e^{it} : 0 \leq t < 2 \pi \}$, and let $f : \mathbb{C}^{\times} \to \mathbb{C}^{\times}$ be some holomorphic function.  Then the winding number $$ \frac{1}{2 \pi i} \int_{f(u)} \frac{dz}{z} $$ can take any integer value depending on $f$ (by letting $f(z) = z^n$, for example).  However, if we change the domain and codomain of $f$ to something like $\{ z \in \mathbb{C} : \frac{1}{4} < |z| < 4 \}$, then we can't use those $f$'s we used before.  The winding number can still be $1$ of course by using the identity.  I see that it can also be $0$ by letting $f(z) = 1$.  We can also get the winding number to be $-1$ by setting $f(z) = z^{-1}$.  Can we get the winding number to be $2$?  I suspect not but am having trouble showing it.  Thoughts?",,['complex-analysis']
21,Computing $\int_{|z|=2} z^n(1 - z)^m\ dz$,Computing,\int_{|z|=2} z^n(1 - z)^m\ dz,"My two questions are bolded below. Hypothesis: Let $\gamma$ denote the circle about the origin of radius $2$. Goal: Compute $$ \int_{\gamma} z^n(1 - z)^m\ dz $$ Attempt: We have that $$ \int_{\gamma} z^n(1 - z)^m\ dz = \int_{\gamma} z^n(-1)^m(z-1)^m\ dz $$ Take the integral of the inverse of the integrand.  Once we figure out an answer to this question, we can inverse that answer to find the integral of our original integrand. Is this correct reasoning? Assuming this is correct reasoning, we have that $$ \int_\gamma {1 \over z^n(-1)^m(z-1)^m}\ dz = \int_\gamma {{1 \over z^n}(-1)^{(m-1)+1} \over (z-1)^{(m-1)+1}}\ dz =  {2 \pi i \over n!} f^{(m-1)}(1) \text{ s.t. } f(z) = ?? $$ Here is $f(z) = {(-1)^{m} \over z^n}$?  I'm trying to make heavy use of Cauchy's integral formula but think I've computationally confused myself in that pursuit.  How does one finish this computation?","My two questions are bolded below. Hypothesis: Let $\gamma$ denote the circle about the origin of radius $2$. Goal: Compute $$ \int_{\gamma} z^n(1 - z)^m\ dz $$ Attempt: We have that $$ \int_{\gamma} z^n(1 - z)^m\ dz = \int_{\gamma} z^n(-1)^m(z-1)^m\ dz $$ Take the integral of the inverse of the integrand.  Once we figure out an answer to this question, we can inverse that answer to find the integral of our original integrand. Is this correct reasoning? Assuming this is correct reasoning, we have that $$ \int_\gamma {1 \over z^n(-1)^m(z-1)^m}\ dz = \int_\gamma {{1 \over z^n}(-1)^{(m-1)+1} \over (z-1)^{(m-1)+1}}\ dz =  {2 \pi i \over n!} f^{(m-1)}(1) \text{ s.t. } f(z) = ?? $$ Here is $f(z) = {(-1)^{m} \over z^n}$?  I'm trying to make heavy use of Cauchy's integral formula but think I've computationally confused myself in that pursuit.  How does one finish this computation?",,['complex-analysis']
22,Determine the number of zeros in the first quadrant,Determine the number of zeros in the first quadrant,,This is a homework question: $$f(z) = z^2 - z + 1$$ sorry for the poor code!,This is a homework question: $$f(z) = z^2 - z + 1$$ sorry for the poor code!,,"['complex-analysis', 'functions', 'roots']"
23,Elliptic Operators and Continuity,Elliptic Operators and Continuity,,"I am reading a book on Hodge theory (Ref: http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/hodge-smf.pdf ) or for english ( http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/hodge-ams.pdf ). In the french version I was reading about this finiteness theorem of elliptic operators (page 18) (Finiteness Theorem) Let $E$ and $F$ two hermitian vector bundles on a compact manifold $M$ such that the rank of $E$ and $F$ are the same and equals to $r$. Let $P:C^{\infty}(M,E)\rightarrow C^{\infty}(M,F)$ be an elliptic differential operator of degree $\delta$. Then 1) $\ker P$ is finite dimensional. In the proof it says: Garding's inequality shows that $||u||_{s+\delta}\leq C_{s}(||u||_{0})$ for all $u\in\ker P$. By Sobolev's lemma, this means $\ker P$ is closed in $W^{0}(M,E)$. Why should this be so?","I am reading a book on Hodge theory (Ref: http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/hodge-smf.pdf ) or for english ( http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/hodge-ams.pdf ). In the french version I was reading about this finiteness theorem of elliptic operators (page 18) (Finiteness Theorem) Let $E$ and $F$ two hermitian vector bundles on a compact manifold $M$ such that the rank of $E$ and $F$ are the same and equals to $r$. Let $P:C^{\infty}(M,E)\rightarrow C^{\infty}(M,F)$ be an elliptic differential operator of degree $\delta$. Then 1) $\ker P$ is finite dimensional. In the proof it says: Garding's inequality shows that $||u||_{s+\delta}\leq C_{s}(||u||_{0})$ for all $u\in\ker P$. By Sobolev's lemma, this means $\ker P$ is closed in $W^{0}(M,E)$. Why should this be so?",,"['complex-analysis', 'algebraic-geometry', 'partial-differential-equations', 'complex-geometry', 'hodge-theory']"
24,Soft Question about Möbius Transformations,Soft Question about Möbius Transformations,,"Very soft question and I may be completely wrong about this, but does it make any sense to think about the Möbius transformation matrix as a change of basis for $\mathbb C$?","Very soft question and I may be completely wrong about this, but does it make any sense to think about the Möbius transformation matrix as a change of basis for $\mathbb C$?",,"['linear-algebra', 'complex-analysis', 'soft-question', 'mobius-transformation']"
25,Minimize norm of a polynomial on a circle,Minimize norm of a polynomial on a circle,,"Let $P=\sum_{k=0}^n a_kX^k$ ba a polynomial of degree $n \gt 0$, and let $r\gt 0$. Suppose that $P$ is not the monomial $a_nX^n$, in other words there is at least an $i<n$ such that $a_i\neq 0$. Denote by $C$ the  circle $\big\lbrace z \ \big| \ |z|=r\big\rbrace$. Clearly, the continuous function $|P|$ attains a minimum value (let us denote it by $\mu$) on the compact set $C$. Let $M=\big\lbrace z\in C \ \big| \  |P(z)|=\mu\big\rbrace$.  How many elements can we have in $M$ ? When $\mu=0$, $M$ contains  only roots of $P$, so that the maximum cardinality is $n$. For $l\in[-n,n]$, let us put   $$b_l=\sum_{j=-n+{\sf max}(0,-l)}^{n+{\sf min}(0,-l)}  \bar{a_j}a_{j+l}r^{2j+l}, B(X)=\sum_{l=-n}^{n}b_lX^{l+n}, D(X)=\frac{B(X)}{X^n}  $$. Then we have the identity $|P(re^{i\theta})|^2=D(e^{i\theta})$ for any $\theta\in{\mathbb R}$.  Since $D'(X)=\frac{XB'(X)-B(X)}{X^{n+1}}$, we see that   $|M| \leq |M'|$ where $M'=\big\lbrace z \in {\mathbb C} \ \big| \ zB’(z)-B(z)=0, |z|=1  \big\rbrace$. Remark that $D'$ is zero iff $B$ is a monomial in $X$, iff  $P$ itself is a monomial in $X$. As the degree of $XB'(X)-B(X)$ is exactly $2n$, we deduce $|M| \leq 2n$. Note however that we have only counted local extrema here, and the question is about the global extrema. Thus, one expects $|M|$ to be significatively  lower than the upper bound $2n$. In fact, I conjecture the following : Conjecture. $|M| \leq n$. I have checked this conjecture on a few random numerical examples.  Does anyone have an idea about how to prove or find a counterexample to  this conjecture ?","Let $P=\sum_{k=0}^n a_kX^k$ ba a polynomial of degree $n \gt 0$, and let $r\gt 0$. Suppose that $P$ is not the monomial $a_nX^n$, in other words there is at least an $i<n$ such that $a_i\neq 0$. Denote by $C$ the  circle $\big\lbrace z \ \big| \ |z|=r\big\rbrace$. Clearly, the continuous function $|P|$ attains a minimum value (let us denote it by $\mu$) on the compact set $C$. Let $M=\big\lbrace z\in C \ \big| \  |P(z)|=\mu\big\rbrace$.  How many elements can we have in $M$ ? When $\mu=0$, $M$ contains  only roots of $P$, so that the maximum cardinality is $n$. For $l\in[-n,n]$, let us put   $$b_l=\sum_{j=-n+{\sf max}(0,-l)}^{n+{\sf min}(0,-l)}  \bar{a_j}a_{j+l}r^{2j+l}, B(X)=\sum_{l=-n}^{n}b_lX^{l+n}, D(X)=\frac{B(X)}{X^n}  $$. Then we have the identity $|P(re^{i\theta})|^2=D(e^{i\theta})$ for any $\theta\in{\mathbb R}$.  Since $D'(X)=\frac{XB'(X)-B(X)}{X^{n+1}}$, we see that   $|M| \leq |M'|$ where $M'=\big\lbrace z \in {\mathbb C} \ \big| \ zB’(z)-B(z)=0, |z|=1  \big\rbrace$. Remark that $D'$ is zero iff $B$ is a monomial in $X$, iff  $P$ itself is a monomial in $X$. As the degree of $XB'(X)-B(X)$ is exactly $2n$, we deduce $|M| \leq 2n$. Note however that we have only counted local extrema here, and the question is about the global extrema. Thus, one expects $|M|$ to be significatively  lower than the upper bound $2n$. In fact, I conjecture the following : Conjecture. $|M| \leq n$. I have checked this conjecture on a few random numerical examples.  Does anyone have an idea about how to prove or find a counterexample to  this conjecture ?",,"['complex-analysis', 'polynomials']"
26,"Laplace transform of and impulse sampled function using ""frequency"" convolution","Laplace transform of and impulse sampled function using ""frequency"" convolution",,"This is a long question, but assume we have this: The book uses the frequency convolution theorem to solve this problem. To solve the integral, it uses a contour + residue theorem to solve it. The only problem is you can form this path to the left or right: Now, the book says if you evaluation the path on the left side, then: My first question is why does the integral along TL vanish for this side? For the right side, the book says: My second question is why do we have to consider two cases for this side? It seems as if we can apply the logic for the first case here and assume the integral along TL vanishes.  Anyway, for the first case the book says: My third question is why do they use the initial value theorem to justify the path integral is zero? Lastly, for the second case: My fourth question is how do they obtain that the path integral along TL for this case is $-1/2*x(0+)$? My thanks to anyone who took the time to read all this! Furthermore if there seems to be a consistent misunderstanding of some basic concept it would be great to get resources to read on this subject. EDIT: Btw, this is taken from a text book called Discrete Time Control Systems by Ogata.","This is a long question, but assume we have this: The book uses the frequency convolution theorem to solve this problem. To solve the integral, it uses a contour + residue theorem to solve it. The only problem is you can form this path to the left or right: Now, the book says if you evaluation the path on the left side, then: My first question is why does the integral along TL vanish for this side? For the right side, the book says: My second question is why do we have to consider two cases for this side? It seems as if we can apply the logic for the first case here and assume the integral along TL vanishes.  Anyway, for the first case the book says: My third question is why do they use the initial value theorem to justify the path integral is zero? Lastly, for the second case: My fourth question is how do they obtain that the path integral along TL for this case is $-1/2*x(0+)$? My thanks to anyone who took the time to read all this! Furthermore if there seems to be a consistent misunderstanding of some basic concept it would be great to get resources to read on this subject. EDIT: Btw, this is taken from a text book called Discrete Time Control Systems by Ogata.",,"['calculus', 'complex-analysis', 'complex-numbers', 'laplace-transform', 'contour-integration']"
27,Counting roots of polynomial inside $S^1$,Counting roots of polynomial inside,S^1,"I would like to ask for a hint to this problem: Let $p$ a polynomial function on $C$ with no root on $S^1$. Show that the number of roots of $p$ with $|z|<1$ is the degree of the map $q: S^1 \to S^1$ given by $ q(z)=p(z)/|p(z)|$. This problem appears in Peter May's book, concise course in Algebraic Topology. Assuming the fundamental theorem of algebra, my idea so far is to collapse every zero inside $S^1$  through a homotopy to zero, explicitly, if $a_1, ..., a_k$ are the roots inside $S^1$  take $h(z,t)=(z-t*a_1)...(z-t*a_k)*p_2(z)$, where $p_2(z)$ is the part of the polynomial that has the zeros outside $S^1$, and consider $h(z,t)/|h(z,t)|$. Then, I end up with something like $z^k*p_2(z)/|p_2(z)|$. Next, I think of vanishing, somehow, the part involving $p_2$, but don't know how. Any advice would be appreciated.","I would like to ask for a hint to this problem: Let $p$ a polynomial function on $C$ with no root on $S^1$. Show that the number of roots of $p$ with $|z|<1$ is the degree of the map $q: S^1 \to S^1$ given by $ q(z)=p(z)/|p(z)|$. This problem appears in Peter May's book, concise course in Algebraic Topology. Assuming the fundamental theorem of algebra, my idea so far is to collapse every zero inside $S^1$  through a homotopy to zero, explicitly, if $a_1, ..., a_k$ are the roots inside $S^1$  take $h(z,t)=(z-t*a_1)...(z-t*a_k)*p_2(z)$, where $p_2(z)$ is the part of the polynomial that has the zeros outside $S^1$, and consider $h(z,t)/|h(z,t)|$. Then, I end up with something like $z^k*p_2(z)/|p_2(z)|$. Next, I think of vanishing, somehow, the part involving $p_2$, but don't know how. Any advice would be appreciated.",,"['complex-analysis', 'algebraic-topology']"
28,"How do I maximize $|t-e^z|$, for $z\in D$, the unit disk?","How do I maximize , for , the unit disk?",|t-e^z| z\in D,"I guess this question doesn't have a closed form solution for all $t\in \Bbb C$, but I know one for $t=1$ provided by Daniel Fischer in a question I asked. $$\begin{align} \left\lvert e^w-1\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!}\right\rvert\\ &\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!}\\ &= e^{\lvert w\rvert}-1, \end{align}$$ with equality for $w \geqslant 0$. So this $|1-e^z|$ maximized by $z=1$. I tried doing the same for other values of $t$, but without success. Here is an attempt for $t=8$ $$\begin{align} \left\lvert e^w-8\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!} -7\right\rvert\\ &\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!} + 7\\ &= e^{\lvert w\rvert}+6, \end{align}$$ But I don't get equality for $w \geqslant 0$. Is there a way to maximize $|t-e^z|$ for $z\in D$, the unit disk, for other values of $t$ besides $0,1$?","I guess this question doesn't have a closed form solution for all $t\in \Bbb C$, but I know one for $t=1$ provided by Daniel Fischer in a question I asked. $$\begin{align} \left\lvert e^w-1\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!}\right\rvert\\ &\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!}\\ &= e^{\lvert w\rvert}-1, \end{align}$$ with equality for $w \geqslant 0$. So this $|1-e^z|$ maximized by $z=1$. I tried doing the same for other values of $t$, but without success. Here is an attempt for $t=8$ $$\begin{align} \left\lvert e^w-8\right\rvert &= \left\lvert \sum_{m=1}^\infty \frac{w^m}{m!} -7\right\rvert\\ &\leqslant \sum_{m=1}^\infty \frac{\lvert w\rvert^m}{m!} + 7\\ &= e^{\lvert w\rvert}+6, \end{align}$$ But I don't get equality for $w \geqslant 0$. Is there a way to maximize $|t-e^z|$ for $z\in D$, the unit disk, for other values of $t$ besides $0,1$?",,"['complex-analysis', 'optimization']"
29,Finding complex power series with interesting boundary behavior,Finding complex power series with interesting boundary behavior,,"I need to find one (or more) interesting complex power series to give to my students for their analysis exam. Ideally, this would be a power series that has interesting behavior at the boundary, i.e. does not converge everywhere/nowhere, but only at select points. To check this, they have at their disposal Abel's criterion, Dirichlet's criterion and Weierstrass' M-test. The classic examples (that they've seen) are of course the ones with coefficients $1, \frac{1}{n}$, and $\frac{1}{n^2}$. Others seem hard to find.","I need to find one (or more) interesting complex power series to give to my students for their analysis exam. Ideally, this would be a power series that has interesting behavior at the boundary, i.e. does not converge everywhere/nowhere, but only at select points. To check this, they have at their disposal Abel's criterion, Dirichlet's criterion and Weierstrass' M-test. The classic examples (that they've seen) are of course the ones with coefficients $1, \frac{1}{n}$, and $\frac{1}{n^2}$. Others seem hard to find.",,"['real-analysis', 'complex-analysis', 'analysis', 'power-series']"
30,Sheaf of a complex analytic function,Sheaf of a complex analytic function,,"Let  $$ F(U) = \left\{ \mbox{ all complex analytic functions } f \mbox{ on } U \mid z \frac{df}{dz}=1 \right\}$$ for any domain $U$ in $\mathbb{C}$. I want to show that: $F$ is a sheaf. The stalk of $F$ at $0$ is empty. The stalk at any other point is non-canonically isomorphic to $\mathbb{C}$. I know that the presheaf of continuous function is a sheaf (as they have the gluing property over open coverings), so also analytic functions (which are $C^\infty$) are sheaf. However, there are two problems is: a function that satisfy $d \frac{df}{dz}=1$ actually is $$\frac{df}{dz} = \frac{1}{z}$$ which is not analytic in 0. Moreover, is not the differential equation $\frac{df}{dz}=\frac{1}{z}$ is unique up to a constant - the family of solution is $f(z) = \ln(z) + c$ with $c \in \mathbb{C}$? Then it follows that $F$ is a sheaf with stalk $$\{f(z) = \ln(z) + c \mid c \in \mathbb{C} \} \cong \mathbb{C}$$ and empty stalk at 0 since there is no analytic function such that $0 \cdot \frac{df}{dt} = 1$. Are my consideration here are correct? Added in edit: We can define $\ln(z)$ as the extension of  $$ \ln(x) = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n}(x-1)^n $$ to the complex number. Of course one needs to check where it converges and well-defined, and then arise the issue of branch cuts. I am no expert on complex analysis but my intuition says that $\frac{df}{dz}=\frac{1}{z}$ has a family of solutions differ by constants. Is this correct?","Let  $$ F(U) = \left\{ \mbox{ all complex analytic functions } f \mbox{ on } U \mid z \frac{df}{dz}=1 \right\}$$ for any domain $U$ in $\mathbb{C}$. I want to show that: $F$ is a sheaf. The stalk of $F$ at $0$ is empty. The stalk at any other point is non-canonically isomorphic to $\mathbb{C}$. I know that the presheaf of continuous function is a sheaf (as they have the gluing property over open coverings), so also analytic functions (which are $C^\infty$) are sheaf. However, there are two problems is: a function that satisfy $d \frac{df}{dz}=1$ actually is $$\frac{df}{dz} = \frac{1}{z}$$ which is not analytic in 0. Moreover, is not the differential equation $\frac{df}{dz}=\frac{1}{z}$ is unique up to a constant - the family of solution is $f(z) = \ln(z) + c$ with $c \in \mathbb{C}$? Then it follows that $F$ is a sheaf with stalk $$\{f(z) = \ln(z) + c \mid c \in \mathbb{C} \} \cong \mathbb{C}$$ and empty stalk at 0 since there is no analytic function such that $0 \cdot \frac{df}{dt} = 1$. Are my consideration here are correct? Added in edit: We can define $\ln(z)$ as the extension of  $$ \ln(x) = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n}(x-1)^n $$ to the complex number. Of course one needs to check where it converges and well-defined, and then arise the issue of branch cuts. I am no expert on complex analysis but my intuition says that $\frac{df}{dz}=\frac{1}{z}$ has a family of solutions differ by constants. Is this correct?",,"['complex-analysis', 'sheaf-theory']"
31,Number of zeros equal number of linearly independent analytic functions,Number of zeros equal number of linearly independent analytic functions,,"I'm trying to read this paper and I'm stuck on a particular point. The authors are constructing an analytic function $f(z)$ which have to satisfy the following boundary conditions: $\frac{f(z+L_1)}{f(z)}=e^{i\phi_1}\ \ $ and $\ \ \frac{f(z+L_2e^{i\theta})}{f(z)}e^{i\pi N_s\big(2z+L_2e^{i\theta}\big)/L_1}=e^{i\phi_2}\ \ \ \ \ \ \ $ (1) where $z=x+iy$, $N_s\in \boldsymbol{N}$, $\theta\in[0,\pi/2]$ and $L_1,L_2\in \boldsymbol{R}_+$. Using the residue theorem they argue that this means $f(z)$ has $N_s$ zeros in the parallelogram defined by $\boldsymbol{L}_1=(L_1,0)$ and $\boldsymbol{L}_2=(L_2\cos\theta,L_2\sin\theta)$. Then comes my problem: The authors write that this implies (1) has $N_s$ linearly independent solutions. I don't understand why exactly; is this a general theorem about numbers of zeros and linearly independent functions? EDIT: I've thought of the following approach, with one especially uncertain point: Since $f(z)$ is analytic it converges to its Taylor series. Having $N_s$ roots it can be written as a polynomial of degree $N_s$ (this is where I'm the most unsure, especially with $\sin(z)$ etc in mind). Thinking of the function space as a vector space with basis $B=\{1,z,z^2,\ldots\}$ this means that there are exactly $N_s$ linearly independent functions with this number of roots. Can anyone see a flaw in this argument? Or a way to strengthen it?","I'm trying to read this paper and I'm stuck on a particular point. The authors are constructing an analytic function $f(z)$ which have to satisfy the following boundary conditions: $\frac{f(z+L_1)}{f(z)}=e^{i\phi_1}\ \ $ and $\ \ \frac{f(z+L_2e^{i\theta})}{f(z)}e^{i\pi N_s\big(2z+L_2e^{i\theta}\big)/L_1}=e^{i\phi_2}\ \ \ \ \ \ \ $ (1) where $z=x+iy$, $N_s\in \boldsymbol{N}$, $\theta\in[0,\pi/2]$ and $L_1,L_2\in \boldsymbol{R}_+$. Using the residue theorem they argue that this means $f(z)$ has $N_s$ zeros in the parallelogram defined by $\boldsymbol{L}_1=(L_1,0)$ and $\boldsymbol{L}_2=(L_2\cos\theta,L_2\sin\theta)$. Then comes my problem: The authors write that this implies (1) has $N_s$ linearly independent solutions. I don't understand why exactly; is this a general theorem about numbers of zeros and linearly independent functions? EDIT: I've thought of the following approach, with one especially uncertain point: Since $f(z)$ is analytic it converges to its Taylor series. Having $N_s$ roots it can be written as a polynomial of degree $N_s$ (this is where I'm the most unsure, especially with $\sin(z)$ etc in mind). Thinking of the function space as a vector space with basis $B=\{1,z,z^2,\ldots\}$ this means that there are exactly $N_s$ linearly independent functions with this number of roots. Can anyone see a flaw in this argument? Or a way to strengthen it?",,"['complex-analysis', 'vector-spaces', 'roots', 'residue-calculus']"
32,Finding the radius of convergence of the given power series.,Finding the radius of convergence of the given power series.,,"Consider the power series $\sum\limits_{n=1}^{\infty}$$a_nZ^n$ , where $a_n$ is the number of divisor of $n^{50}$ . Find the radius of convergence.","Consider the power series $\sum\limits_{n=1}^{\infty}$$a_nZ^n$ , where $a_n$ is the number of divisor of $n^{50}$ . Find the radius of convergence.",,['complex-analysis']
33,Runge's theorem and polynomially convex hull,Runge's theorem and polynomially convex hull,,"Runge's theorem says that an analytic function $f$ in an open set containing compact set $K$ can be approximated by a rational function with poles in $E$,where $E$ is a subset of $\mathbb{C}_\infty-K$,and more importantly,$E$ meets every component of $\mathbb{C}_\infty-K$. Now the problem is for any compact set $K$ contained on an open set $G_1\subset G$,can functions in $H(G_1)$ be approximated on $K$ by functions in $H(G)$?If the choice of $K,G,G_1$ is arbitrary,of course it's false,such as an annulus.We are now trying to establish a criteria for a fixed $K$ and $G$ such that this can be done for any $G_1$. Thus we need to prove the equivalence of following three statements: (a)If $f$ is analytic in a neighborhood of $K$ and $\epsilon >0$ then there is a $g$ in $H(G)$ with $|f(z)-g(z)|<\epsilon$ for all $z$ in $K$; (b)If $D$ is a bounded component of $G-K$ then $D^{-}\cap G\neq \emptyset$; (c)If $z$ is any point in $G-K$ then there is a function $f$ in $H(G)$ with $|f(z)|>sup\{|f(\omega)|:\omega \in K\}$; $(b)\Rightarrow (a)$ is directly from Runge's Theorem when noticing that $(b)$ implies every component of $\mathbb{C}_\infty-K$ contains a component of $\mathbb{C}_\infty-G$ . I found it difficult to prove $(a)\Rightarrow(c)$,in which $(c)$ asserts that holomorphic convex hull of $K$ in $G$ is $K$ itself.I don't know how to build connection between Runge's theorem and convex hull. This is the exercise from J.Conway's textbook of complex analysis.Looking forward to any kind of help.","Runge's theorem says that an analytic function $f$ in an open set containing compact set $K$ can be approximated by a rational function with poles in $E$,where $E$ is a subset of $\mathbb{C}_\infty-K$,and more importantly,$E$ meets every component of $\mathbb{C}_\infty-K$. Now the problem is for any compact set $K$ contained on an open set $G_1\subset G$,can functions in $H(G_1)$ be approximated on $K$ by functions in $H(G)$?If the choice of $K,G,G_1$ is arbitrary,of course it's false,such as an annulus.We are now trying to establish a criteria for a fixed $K$ and $G$ such that this can be done for any $G_1$. Thus we need to prove the equivalence of following three statements: (a)If $f$ is analytic in a neighborhood of $K$ and $\epsilon >0$ then there is a $g$ in $H(G)$ with $|f(z)-g(z)|<\epsilon$ for all $z$ in $K$; (b)If $D$ is a bounded component of $G-K$ then $D^{-}\cap G\neq \emptyset$; (c)If $z$ is any point in $G-K$ then there is a function $f$ in $H(G)$ with $|f(z)|>sup\{|f(\omega)|:\omega \in K\}$; $(b)\Rightarrow (a)$ is directly from Runge's Theorem when noticing that $(b)$ implies every component of $\mathbb{C}_\infty-K$ contains a component of $\mathbb{C}_\infty-G$ . I found it difficult to prove $(a)\Rightarrow(c)$,in which $(c)$ asserts that holomorphic convex hull of $K$ in $G$ is $K$ itself.I don't know how to build connection between Runge's theorem and convex hull. This is the exercise from J.Conway's textbook of complex analysis.Looking forward to any kind of help.",,['complex-analysis']
34,Complex integral with $1-\sin z$ as denominator,Complex integral with  as denominator,1-\sin z,"I want to evaluate $$\int_{|z|=8}\dfrac{1+z}{1-\sin z}dz$$ using the residue theorem. But I'm not sure what the residues are. In $|z|=8$, for $z$ real, we have $\sin z=1$ for $z=-3\pi/2,\pi/2,5\pi/2$. But what about $z$ complex? I only know how to write $\sin$ as a power series, but then it's hard to determine when it equals $1$.","I want to evaluate $$\int_{|z|=8}\dfrac{1+z}{1-\sin z}dz$$ using the residue theorem. But I'm not sure what the residues are. In $|z|=8$, for $z$ real, we have $\sin z=1$ for $z=-3\pi/2,\pi/2,5\pi/2$. But what about $z$ complex? I only know how to write $\sin$ as a power series, but then it's hard to determine when it equals $1$.",,"['integration', 'complex-analysis']"
35,Schwarz's Lemma and functions with positive real part,Schwarz's Lemma and functions with positive real part,,"Problem: Let $D = \{ z \in \mathbb C : |z| < 1 \}$. Suppose $f : D \to \mathbb C$ is a non-constant analytic function such that $\mathrm{Re} f(z) \geq 0$ for all $z \in D$. (a) Show that $\mathrm{Re} f(z) \neq 0$ for all $z \in D$. (b) Using a Möbius transformation and Schwarz's lemma, prove that if   $f(0) = 1$, then $$ |f(z)| \leq {1+|z| \over 1-|z|}. $$ What can be said if $f(0) \neq 1$? (c) Show that if $f(0) = 1$, then $f$ also satisfies $$ |f(z)| \geq {1-|z| \over 1+|z|}. $$ Progress: (a) We can use the open mapping theorem. (b) We can compose a Möbius transformation $m$ that sends the right-half plane to $D$ with $f$. Then $h = m \circ f$ satisfies the hypotheses of Schwarz's lemma by construction. Simple manipulations of the inequality from Schwarz's lemma give the result. (c) Looking at part (a), we know that $\mathrm{Re} f(z) \neq 0$, and so $f(z) \neq 0$. Thus, we can use the function $g = 1/f$ in the statement of part (b). Question: What about when $f(0) \neq 1$? I don't think you can get anything from $f(z)-f(0)+1$ unless $\mathrm{Re} f(0) < 1$. And you can't in general rearrange the inputs of $f$ because $1$ isn't necessarily in the image of $f$. Also, I don't think you can get anything from $f(z)/f(0)$ unless $f(0)$ is real, because otherwise the range of $f(z)/f(0)$ could extend into the left-half plane.","Problem: Let $D = \{ z \in \mathbb C : |z| < 1 \}$. Suppose $f : D \to \mathbb C$ is a non-constant analytic function such that $\mathrm{Re} f(z) \geq 0$ for all $z \in D$. (a) Show that $\mathrm{Re} f(z) \neq 0$ for all $z \in D$. (b) Using a Möbius transformation and Schwarz's lemma, prove that if   $f(0) = 1$, then $$ |f(z)| \leq {1+|z| \over 1-|z|}. $$ What can be said if $f(0) \neq 1$? (c) Show that if $f(0) = 1$, then $f$ also satisfies $$ |f(z)| \geq {1-|z| \over 1+|z|}. $$ Progress: (a) We can use the open mapping theorem. (b) We can compose a Möbius transformation $m$ that sends the right-half plane to $D$ with $f$. Then $h = m \circ f$ satisfies the hypotheses of Schwarz's lemma by construction. Simple manipulations of the inequality from Schwarz's lemma give the result. (c) Looking at part (a), we know that $\mathrm{Re} f(z) \neq 0$, and so $f(z) \neq 0$. Thus, we can use the function $g = 1/f$ in the statement of part (b). Question: What about when $f(0) \neq 1$? I don't think you can get anything from $f(z)-f(0)+1$ unless $\mathrm{Re} f(0) < 1$. And you can't in general rearrange the inputs of $f$ because $1$ isn't necessarily in the image of $f$. Also, I don't think you can get anything from $f(z)/f(0)$ unless $f(0)$ is real, because otherwise the range of $f(z)/f(0)$ could extend into the left-half plane.",,['complex-analysis']
36,"$( \mathrm{Aut}(\mathbb{D}),\| \cdot \|_{\infty})$ is complete",is complete,"( \mathrm{Aut}(\mathbb{D}),\| \cdot \|_{\infty})","I need to show $(\mathrm{Aut}(\mathbb{D}),\| \cdot \|_{\infty})$ is complete, where $\mathbb{D}$ is an open unit disk in the complex plane. I know $$f\in \mathrm{Aut}(\mathbb{D})\Rightarrow f(z)=e^{i\phi}{z-\alpha\over 1-\bar{\alpha}z},-\pi<\phi\le \pi,|\alpha|<1$$ so I took $$f_n(z)=e^{i\phi}{z-\alpha_n\over 1-\bar{\alpha}_nz},-\pi<\phi\le \pi,|\alpha_n|<1$$ Say $f_n\to f$ in sup norm, $f_n$ is cauchy, then the  convergence is  uniform convergence right? Can now just say $$f(z)={z-\beta\over 1-\bar{\beta}z},-\pi<\phi\le \pi,|\beta|<1$$ where $\alpha_n\to\beta$? Thank you for help.","I need to show $(\mathrm{Aut}(\mathbb{D}),\| \cdot \|_{\infty})$ is complete, where $\mathbb{D}$ is an open unit disk in the complex plane. I know $$f\in \mathrm{Aut}(\mathbb{D})\Rightarrow f(z)=e^{i\phi}{z-\alpha\over 1-\bar{\alpha}z},-\pi<\phi\le \pi,|\alpha|<1$$ so I took $$f_n(z)=e^{i\phi}{z-\alpha_n\over 1-\bar{\alpha}_nz},-\pi<\phi\le \pi,|\alpha_n|<1$$ Say $f_n\to f$ in sup norm, $f_n$ is cauchy, then the  convergence is  uniform convergence right? Can now just say $$f(z)={z-\beta\over 1-\bar{\beta}z},-\pi<\phi\le \pi,|\beta|<1$$ where $\alpha_n\to\beta$? Thank you for help.",,['complex-analysis']
37,Find the integral of $\frac{f'(z)}{f(z)}$,Find the integral of,\frac{f'(z)}{f(z)},"Let a function $f$ be defined and holomorphic on some neighborhood of the disk $\lbrace |z|<1 \rbrace$. Suppose that $|f(z)| \neq 0$ for all $z$ with $|z| = R$. Prove that $$\int_{C_R(0)} \frac{f'(z)}{f(z)} dz= 2 \pi i\sum_{|a|<R} (ord_a f(z))$$ In the right-hand side, the summation is performed over all points a in the disk $\lbrace |z|<R \rbrace$, such that $f(a) = 0$ (at all other points, we have $ord_a(f) = 0$). I look at the function $\frac{f'(z)}{f(z)}dz = d(log f(z))$. $log$ is not globally defined function, but in a neighborhood of $u_0 \neq 0$ there is a barnch of $\log$ holomorphic : $g:u \rightarrow \mathbb{C}$ such that $e^{g(z)}=z$ $\frac{1}{2\pi i} \int_{C_R(0)}  d (arg(f(z)))=$ number of full turns $f(z)$ makes around zero. On the other hand $\sum_{|a|<R} ord_a f= |\lbrace f(z)=0 \; ; \; |z|<R \rbrace$|. Did I do right? And if yes, give me some hint to continue.","Let a function $f$ be defined and holomorphic on some neighborhood of the disk $\lbrace |z|<1 \rbrace$. Suppose that $|f(z)| \neq 0$ for all $z$ with $|z| = R$. Prove that $$\int_{C_R(0)} \frac{f'(z)}{f(z)} dz= 2 \pi i\sum_{|a|<R} (ord_a f(z))$$ In the right-hand side, the summation is performed over all points a in the disk $\lbrace |z|<R \rbrace$, such that $f(a) = 0$ (at all other points, we have $ord_a(f) = 0$). I look at the function $\frac{f'(z)}{f(z)}dz = d(log f(z))$. $log$ is not globally defined function, but in a neighborhood of $u_0 \neq 0$ there is a barnch of $\log$ holomorphic : $g:u \rightarrow \mathbb{C}$ such that $e^{g(z)}=z$ $\frac{1}{2\pi i} \int_{C_R(0)}  d (arg(f(z)))=$ number of full turns $f(z)$ makes around zero. On the other hand $\sum_{|a|<R} ord_a f= |\lbrace f(z)=0 \; ; \; |z|<R \rbrace$|. Did I do right? And if yes, give me some hint to continue.",,['complex-analysis']
38,Maclaurin series for $e^z /\cos z$.,Maclaurin series for .,e^z /\cos z,"I want to find the Maclaurin series for the function $$f(z)=\frac{e^z}{\cos z}.$$ Right away I can tell that the radius of convergence will be $\pi/2$, since it's the distance to the nearest singularity (not sure if this explanation is rigorous enough, but I can't think of anything else). Calculating the coefficients as n'th derivatives at $0$ strikes me as fruitless here, so I'm guessing I have to resort to tricks. Of course I could just divide the series formally but that doesn't get me an explicit formula for the coefficient $a_n$. I tried rewriting the cosine as an exponential, but that too produces nothing of interest. I'm looking for a hint to get me started.","I want to find the Maclaurin series for the function $$f(z)=\frac{e^z}{\cos z}.$$ Right away I can tell that the radius of convergence will be $\pi/2$, since it's the distance to the nearest singularity (not sure if this explanation is rigorous enough, but I can't think of anything else). Calculating the coefficients as n'th derivatives at $0$ strikes me as fruitless here, so I'm guessing I have to resort to tricks. Of course I could just divide the series formally but that doesn't get me an explicit formula for the coefficient $a_n$. I tried rewriting the cosine as an exponential, but that too produces nothing of interest. I'm looking for a hint to get me started.",,"['complex-analysis', 'power-series', 'taylor-expansion']"
39,Is harmonicity preserved when taking limits (normal convergence) on the unit disk.,Is harmonicity preserved when taking limits (normal convergence) on the unit disk.,,"I'm reading Koosis's book on $H^p$ spaces and have a question. He is proving a $L^p$ version of the Dirichlet problem which states that if $F(t)$ is in $L^p$ on the unit circle then $$ U_{r}(\theta)=F\ast P_{r}(\theta)$$  is harmonic in the open unit disk. He does this by noticing  $$ U_{r}(\theta)=\sum_{n=-\infty}^{\infty} A_n r^{|n|} e^{i n \theta}. $$ We get this from noting that the Poisson kernel has the form $$ P_{r}(\theta)=\sum_{n=-\infty}^{\infty}r^{|n|} e^{i n\theta}, $$ where the sum converges uniformly on compact subsets of the open unit disk. Since we have uniform convergence, we can interchange the summation and integral to get the form above. My question is this: if the partial sums $$ \sum_{n=-N}^{N}A_n r^{|n|}e^{i n \theta} $$ satisfy Laplace's equation, does the limit satisfy it as well? The limit function would have the mean value property since the partial sums do, but is this equivalent to harmonicity? EDIT: I actually proved the result myself. The last summand, when split between summing $n\geq 0$ and $n<0$, is the sum of an analytic function and a conjugate analytic function. We know this because the partial sums converge uniformly on compact subsets, preserving holomorphicity. Thus, the real and imaginary parts are harmonic. However, if anyone has anything interesting to add I'd love to hear it.","I'm reading Koosis's book on $H^p$ spaces and have a question. He is proving a $L^p$ version of the Dirichlet problem which states that if $F(t)$ is in $L^p$ on the unit circle then $$ U_{r}(\theta)=F\ast P_{r}(\theta)$$  is harmonic in the open unit disk. He does this by noticing  $$ U_{r}(\theta)=\sum_{n=-\infty}^{\infty} A_n r^{|n|} e^{i n \theta}. $$ We get this from noting that the Poisson kernel has the form $$ P_{r}(\theta)=\sum_{n=-\infty}^{\infty}r^{|n|} e^{i n\theta}, $$ where the sum converges uniformly on compact subsets of the open unit disk. Since we have uniform convergence, we can interchange the summation and integral to get the form above. My question is this: if the partial sums $$ \sum_{n=-N}^{N}A_n r^{|n|}e^{i n \theta} $$ satisfy Laplace's equation, does the limit satisfy it as well? The limit function would have the mean value property since the partial sums do, but is this equivalent to harmonicity? EDIT: I actually proved the result myself. The last summand, when split between summing $n\geq 0$ and $n<0$, is the sum of an analytic function and a conjugate analytic function. We know this because the partial sums converge uniformly on compact subsets, preserving holomorphicity. Thus, the real and imaginary parts are harmonic. However, if anyone has anything interesting to add I'd love to hear it.",,"['analysis', 'fourier-series', 'harmonic-analysis', 'complex-analysis']"
40,Entire extension of a function on a set with an accumulation point,Entire extension of a function on a set with an accumulation point,,"While thinking about the identity theorem the following question came in my mind: Let $A\subset \mathbb{C}$ be a set with an accumulation point in $\mathbb{C}$.    What properties does a function $f:A\to \mathbb{C}$ need, such that we can find an extension $\tilde{f}:\mathbb{C} \to \mathbb{C}$ with $\tilde{f}(z)=f(z)$ for all $z\in A$ and $\tilde{f}$ is an entire function ? My actual thoughts are: $f$ must be local lipschitz continuous We could try to calculate the coefficients of the Taylor Series, (my first thought is doing something like a limit of polnoymial interpolation, so taking a converging sequence $(b_n)_{n\in \mathbb{N}}$ with values in $A$ and solving $V_{(b_n)_{n\in \mathbb{N}}}\cdot (a_n)_{n\in \mathbb{N}}= (f(b_n))_{n\in \mathbb{N}}$, where $V$ is an $\infty \times \infty$  Vandermonde-matrix). If this work we have the only possible canditate for $\tilde{f}$ namely $$\tilde{f}(z)=\sum_{n=0}^\infty a_n \cdot z^n$$ because of the identity theorem. So we just need to check whether $f(z)=\tilde{f}(z)$ for all elements of $A$, and wheter the radius of convergence of $\tilde{f}$ is infinity. From my very naive point of view this should  work iff $f$ admits such an extension, because the sums in the linear equation are unconditional convergent. So what are conditions for the equation to have a solution?","While thinking about the identity theorem the following question came in my mind: Let $A\subset \mathbb{C}$ be a set with an accumulation point in $\mathbb{C}$.    What properties does a function $f:A\to \mathbb{C}$ need, such that we can find an extension $\tilde{f}:\mathbb{C} \to \mathbb{C}$ with $\tilde{f}(z)=f(z)$ for all $z\in A$ and $\tilde{f}$ is an entire function ? My actual thoughts are: $f$ must be local lipschitz continuous We could try to calculate the coefficients of the Taylor Series, (my first thought is doing something like a limit of polnoymial interpolation, so taking a converging sequence $(b_n)_{n\in \mathbb{N}}$ with values in $A$ and solving $V_{(b_n)_{n\in \mathbb{N}}}\cdot (a_n)_{n\in \mathbb{N}}= (f(b_n))_{n\in \mathbb{N}}$, where $V$ is an $\infty \times \infty$  Vandermonde-matrix). If this work we have the only possible canditate for $\tilde{f}$ namely $$\tilde{f}(z)=\sum_{n=0}^\infty a_n \cdot z^n$$ because of the identity theorem. So we just need to check whether $f(z)=\tilde{f}(z)$ for all elements of $A$, and wheter the radius of convergence of $\tilde{f}$ is infinity. From my very naive point of view this should  work iff $f$ admits such an extension, because the sums in the linear equation are unconditional convergent. So what are conditions for the equation to have a solution?",,['complex-analysis']
41,On the extension to boundary for some analytic function,On the extension to boundary for some analytic function,,"Given analytic function $f(z)$ on $\mathbb{H}:=\{x>0\}$ satisfying $$0\leq \Re{f(z)}\leq M\Re{z}$$ for some $M>0$ and $z \in \mathbb{H}$ I want to show that $f$ takes form $$f(z)=mz+ic$$ where $m\in[0,M],c\in\mathbb{R}$. [Observation] If $f$ can be extended to $\partial{\mathbb{H}}$, then the condition implies that $f$ must takes purely imaginary number on $\{x=0\}$. By proper rotation we can extend $f$ to the whole plane by Reflection Principle and thus the entire function $e^{f(z)}$ have at most growth order of 1, whence by Hadamard's factorization theorem with some detailed argument we get the conclusion. Here's the only obstacle that left within the argument: Can $f(z)$ be continuously extended to the boundary $\{x=0\}$ from the assumptions?","Given analytic function $f(z)$ on $\mathbb{H}:=\{x>0\}$ satisfying $$0\leq \Re{f(z)}\leq M\Re{z}$$ for some $M>0$ and $z \in \mathbb{H}$ I want to show that $f$ takes form $$f(z)=mz+ic$$ where $m\in[0,M],c\in\mathbb{R}$. [Observation] If $f$ can be extended to $\partial{\mathbb{H}}$, then the condition implies that $f$ must takes purely imaginary number on $\{x=0\}$. By proper rotation we can extend $f$ to the whole plane by Reflection Principle and thus the entire function $e^{f(z)}$ have at most growth order of 1, whence by Hadamard's factorization theorem with some detailed argument we get the conclusion. Here's the only obstacle that left within the argument: Can $f(z)$ be continuously extended to the boundary $\{x=0\}$ from the assumptions?",,['complex-analysis']
42,Proving $|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)}$,Proving,|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)},"Studying for a preliminary exam, I came across the following question: Let $D = \{z \in \Bbb C : \text{Re}( z )> 0\}$ and $f : D \to D $ be a holomorphic function. Prove that $$|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)}\quad \text{for all }z\in D.$$ I thought the best way might be to use the fact that harmonic functions satisfy the maximum modulus principle, too, along with the limit definition of the derivative, but I wasn't able to get it worked out. How should I approach this problem?","Studying for a preliminary exam, I came across the following question: Let $D = \{z \in \Bbb C : \text{Re}( z )> 0\}$ and $f : D \to D $ be a holomorphic function. Prove that $$|f'(z)|\leq\frac{\text{Re}(f(z))}{\text{Re}(z)}\quad \text{for all }z\in D.$$ I thought the best way might be to use the fact that harmonic functions satisfy the maximum modulus principle, too, along with the limit definition of the derivative, but I wasn't able to get it worked out. How should I approach this problem?",,['complex-analysis']
43,Understanding the image of this complex transformation,Understanding the image of this complex transformation,,"Find the image of the infinite strip $$0<y<1/(2c)$$ under the transformation $w=1/z$. Sketch the strip and its image. Attempt: Clearly $$\dfrac{-v}{u^2+v^2}<\dfrac{1}{2c}$$ gives $$u^2 + (v+c)^2 > c^2$$ and the condition $y>0$, gives that $$v<0$$ I am having trouble drawing the image of this strip. Doesn't the equation above tell us that it consists of all points outside the circle $u^2+(v+c)^2 = c^2$? But another problem about the image of a half plane $$x<c_1$$ under the same transformation, states that the image should be the interior of a circle. I fail to see how the image in the above question as well as this one could be interior of a circle. Thanks!","Find the image of the infinite strip $$0<y<1/(2c)$$ under the transformation $w=1/z$. Sketch the strip and its image. Attempt: Clearly $$\dfrac{-v}{u^2+v^2}<\dfrac{1}{2c}$$ gives $$u^2 + (v+c)^2 > c^2$$ and the condition $y>0$, gives that $$v<0$$ I am having trouble drawing the image of this strip. Doesn't the equation above tell us that it consists of all points outside the circle $u^2+(v+c)^2 = c^2$? But another problem about the image of a half plane $$x<c_1$$ under the same transformation, states that the image should be the interior of a circle. I fail to see how the image in the above question as well as this one could be interior of a circle. Thanks!",,['complex-analysis']
44,Is my proof correct? (the product $\prod_{n=1}^\infty (1+\frac{z}{n} ) \mathrm{e}^{-\frac{z}{n}}$ converges absolutely and uniformly on compact sets.),Is my proof correct? (the product  converges absolutely and uniformly on compact sets.),\prod_{n=1}^\infty (1+\frac{z}{n} ) \mathrm{e}^{-\frac{z}{n}},"I want to prove that the product $$\prod_{n=1}^\infty \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}}$$ converges absolutely, and uniformly on compact subsets of $\mathbb C$: My book (Ahlfors) defines the absolute convergence of the product $\prod a_n$ by the absolute convergence of the series $\sum \text{Log } a_n$, where only a finite number of terms can be zero, and they must be removed from the sequence. ($\text{Log}$ denotes the principal branch of the logarithm, where the argument is in $(-\pi ,\pi]$.) Thus, in order to prove absolute convergence, I fix $z \in \mathbb C$, and look at the series whose terms are $\text{Log } \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right]$. It is well known that if $\text{Arg }z_1,\text{Arg }z_2$ both lie in $(-\frac{\pi}{2},\frac{\pi}{2})$, then $\text{Log } (z_1z_2)= \text{Log } z_1+\text{Log } z_2$. For large enough $n$ both factors $z_1=\left( 1+\frac{z}{n} \right),z_2=\mathrm{e}^{-\frac{z}{n}}$ satisfy this, so $\text{Log } \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right]=\text{Log } \left(1+\frac{z}{n}\right)+\text{Log } \mathrm{e}^{-\frac{z}{n}}$. It is also possible to prove that $\text{Log } \mathrm{e}^{-\frac{z}{n}}=-\frac{z}{n}$ for large enough $n$. The problem thus reduces into the convergence of $$\sum  \left\lvert \text{Log } \left(1+\frac{z}{n} \right)-\frac{z}{n} \right\rvert $$ Taylor's theorem states that $$\text{Log }(1+w)=w+w^2 g(z) .$$ I've estimated the remainder and found that for $|w|<\frac{1}{2}$, $$| g(w)| \leq 2(\ln 2+\pi), $$ therefore, for large enough $n$ (so that $|\frac{z}{n}| < \frac{1}{2}$), the terms of the last series are dominated by $2(\ln2+\pi)\frac{|z|^2}{n^2}$, and $\sum 2(\ln2+\pi)\frac{|z|^2}{n^2}$ converges. I deliberately left the $\Sigma$'s unindexed, since $z$ might be a zero of one of the factors. In that case only a tail of the series is taken into account. The proof of uniform convergence on compact sets follows the same lines. Let $K \subset \mathbb C $ be a compact set, as such it lies in some ball $|z| \leq M$. Taking large enough $n$, we find similarly, that the series $\sum \left\lvert \text{Log }  \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right] \right\rvert$ is dominated by $\sum 2(\ln2+\pi)\frac{M^2}{n^2}$ which converges. The Weierstrass M-test says that the series is uniformly convergent, and hence, so is the product. I'd love to hear any thoughts/remarks about these proofs.","I want to prove that the product $$\prod_{n=1}^\infty \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}}$$ converges absolutely, and uniformly on compact subsets of $\mathbb C$: My book (Ahlfors) defines the absolute convergence of the product $\prod a_n$ by the absolute convergence of the series $\sum \text{Log } a_n$, where only a finite number of terms can be zero, and they must be removed from the sequence. ($\text{Log}$ denotes the principal branch of the logarithm, where the argument is in $(-\pi ,\pi]$.) Thus, in order to prove absolute convergence, I fix $z \in \mathbb C$, and look at the series whose terms are $\text{Log } \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right]$. It is well known that if $\text{Arg }z_1,\text{Arg }z_2$ both lie in $(-\frac{\pi}{2},\frac{\pi}{2})$, then $\text{Log } (z_1z_2)= \text{Log } z_1+\text{Log } z_2$. For large enough $n$ both factors $z_1=\left( 1+\frac{z}{n} \right),z_2=\mathrm{e}^{-\frac{z}{n}}$ satisfy this, so $\text{Log } \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right]=\text{Log } \left(1+\frac{z}{n}\right)+\text{Log } \mathrm{e}^{-\frac{z}{n}}$. It is also possible to prove that $\text{Log } \mathrm{e}^{-\frac{z}{n}}=-\frac{z}{n}$ for large enough $n$. The problem thus reduces into the convergence of $$\sum  \left\lvert \text{Log } \left(1+\frac{z}{n} \right)-\frac{z}{n} \right\rvert $$ Taylor's theorem states that $$\text{Log }(1+w)=w+w^2 g(z) .$$ I've estimated the remainder and found that for $|w|<\frac{1}{2}$, $$| g(w)| \leq 2(\ln 2+\pi), $$ therefore, for large enough $n$ (so that $|\frac{z}{n}| < \frac{1}{2}$), the terms of the last series are dominated by $2(\ln2+\pi)\frac{|z|^2}{n^2}$, and $\sum 2(\ln2+\pi)\frac{|z|^2}{n^2}$ converges. I deliberately left the $\Sigma$'s unindexed, since $z$ might be a zero of one of the factors. In that case only a tail of the series is taken into account. The proof of uniform convergence on compact sets follows the same lines. Let $K \subset \mathbb C $ be a compact set, as such it lies in some ball $|z| \leq M$. Taking large enough $n$, we find similarly, that the series $\sum \left\lvert \text{Log }  \left[ \left(1+\frac{z}{n} \right) \mathrm{e}^{-\frac{z}{n}} \right] \right\rvert$ is dominated by $\sum 2(\ln2+\pi)\frac{M^2}{n^2}$ which converges. The Weierstrass M-test says that the series is uniformly convergent, and hence, so is the product. I'd love to hear any thoughts/remarks about these proofs.",,"['sequences-and-series', 'complex-analysis', 'uniform-convergence', 'products', 'proof-verification']"
45,Is a complex polynomial a regular covering? What is its group of deck tranformations?,Is a complex polynomial a regular covering? What is its group of deck tranformations?,,"We know that a complex polynomial $P$ of degree $n$ is an $n$-sheeted covering from $$\{\mathbb{C} - P^{-1}\{\text{critical values of }P\}\} \to \{\mathbb{C} - \{\text{critical values of }P\}\}. $$  So the question is how to determine whether such a cover is regular or not, and its group of deck transformations. The specific example I was trying was $P(Z)=Z^3 - 3Z$. The critical values are $\{2,-2\}$. So the group is $F_2$, i.e. the free group on 2 generators, and $$P^{-1}\{\text{critical values of }P\} = \underset{\text{corr. to }2}{\{2,-1\}} \cup \underset{\text{corr. to }-2}{\{-2,1\}}.$$ So here the group is $F_4$. I see the facts that a small simple loop around $2$ maps to a simple loop around $2$, and small simple loop around $-1$ maps to a double loop around $2$. And similar for preimage of $-2$. We know that if the image of the fundamental group of domain is normal in fundamental group of codomain, then the covering is regular. So can we fix a point and say that a simple loop just going around 2 will map to a simple loop going around 2 and similarly for other points? I guess not (because then the image would be whole group, which contradicts the fact that it is a $3$-sheeted cover). So how to proceed? Can anybody help?","We know that a complex polynomial $P$ of degree $n$ is an $n$-sheeted covering from $$\{\mathbb{C} - P^{-1}\{\text{critical values of }P\}\} \to \{\mathbb{C} - \{\text{critical values of }P\}\}. $$  So the question is how to determine whether such a cover is regular or not, and its group of deck transformations. The specific example I was trying was $P(Z)=Z^3 - 3Z$. The critical values are $\{2,-2\}$. So the group is $F_2$, i.e. the free group on 2 generators, and $$P^{-1}\{\text{critical values of }P\} = \underset{\text{corr. to }2}{\{2,-1\}} \cup \underset{\text{corr. to }-2}{\{-2,1\}}.$$ So here the group is $F_4$. I see the facts that a small simple loop around $2$ maps to a simple loop around $2$, and small simple loop around $-1$ maps to a double loop around $2$. And similar for preimage of $-2$. We know that if the image of the fundamental group of domain is normal in fundamental group of codomain, then the covering is regular. So can we fix a point and say that a simple loop just going around 2 will map to a simple loop going around 2 and similarly for other points? I guess not (because then the image would be whole group, which contradicts the fact that it is a $3$-sheeted cover). So how to proceed? Can anybody help?",,"['complex-analysis', 'algebraic-topology', 'riemann-surfaces']"
46,Laplace equation upper plane using conformal mapping,Laplace equation upper plane using conformal mapping,,"Find a solution $u(x,y)$ of Laplace’s equation on the domain $-\infty< x < \infty$  and $0 <y<$ $\infty$ for which $u(x,0)=x^{1/2}$ for $0<x< \infty$. What is $u(x,0)$ for $-\infty <x< 0$? I am solving older qualifying on Applied, complex part. And we study the conformal mapping has application for Laplace equation. Usually intersection between two circles with constant boundaries condition that we send to a strip with conformal mapping and we can see that the solution does not depend of one of the variables so.. you get the solution has linear form $cx+d$ and then you use the boundaries condition and get the answer. But here... The condition is not constant, and it is only on some part of the boundary. So... My question is , if I send it to a strip too with a $\ln z$ I only have the boundary condition for $y=0$ that is $x^{1/2}$ and I need to find an answer for the region and for the boundary $y= \pi$. Or what could be another region I can send it? The idea is use the less PDE theory, so I do not want to send it to the circle and use Poisson. (Since this for people who has no PDE courses too) Should be the other part of the boundary condition $u(x,0)= -(-x)^{1/2}$ for $-\infty <x< 0$ ?","Find a solution $u(x,y)$ of Laplace’s equation on the domain $-\infty< x < \infty$  and $0 <y<$ $\infty$ for which $u(x,0)=x^{1/2}$ for $0<x< \infty$. What is $u(x,0)$ for $-\infty <x< 0$? I am solving older qualifying on Applied, complex part. And we study the conformal mapping has application for Laplace equation. Usually intersection between two circles with constant boundaries condition that we send to a strip with conformal mapping and we can see that the solution does not depend of one of the variables so.. you get the solution has linear form $cx+d$ and then you use the boundaries condition and get the answer. But here... The condition is not constant, and it is only on some part of the boundary. So... My question is , if I send it to a strip too with a $\ln z$ I only have the boundary condition for $y=0$ that is $x^{1/2}$ and I need to find an answer for the region and for the boundary $y= \pi$. Or what could be another region I can send it? The idea is use the less PDE theory, so I do not want to send it to the circle and use Poisson. (Since this for people who has no PDE courses too) Should be the other part of the boundary condition $u(x,0)= -(-x)^{1/2}$ for $-\infty <x< 0$ ?",,"['complex-analysis', 'partial-differential-equations']"
47,"Complex integral, correct?","Complex integral, correct?",,"I am supposed to do the integral $$ \int_{\gamma_2} \frac{\sin(z)}{z+\frac{i}{2}} dz$$ where $\gamma_2:[-\pi, 3\pi] \rightarrow \mathbb{C}$ , $\gamma_2(t)=\exp(it)$ for $ t\in [-\pi,\pi]$, $\gamma_2(t)=(1+t-\pi)\exp(it)$ for $t\in [\pi,2\pi)$ and $\gamma_2(t)=(1+3\pi-t) \exp(it)$ for $t\in[2\pi,3\pi]$. My idea was to say that this is equal to $2 \cdot 2\pi i \sin(-\frac{i}{2})$. Since we have two loops and the rest is cauchy's integral formula, is this correct?","I am supposed to do the integral $$ \int_{\gamma_2} \frac{\sin(z)}{z+\frac{i}{2}} dz$$ where $\gamma_2:[-\pi, 3\pi] \rightarrow \mathbb{C}$ , $\gamma_2(t)=\exp(it)$ for $ t\in [-\pi,\pi]$, $\gamma_2(t)=(1+t-\pi)\exp(it)$ for $t\in [\pi,2\pi)$ and $\gamma_2(t)=(1+3\pi-t) \exp(it)$ for $t\in[2\pi,3\pi]$. My idea was to say that this is equal to $2 \cdot 2\pi i \sin(-\frac{i}{2})$. Since we have two loops and the rest is cauchy's integral formula, is this correct?",,['calculus']
48,Contour integration with branch cut,Contour integration with branch cut,,"This is an exercise in a course on complex analysis I am taking: Determine the function $f$ using complex contour integration: $$\lim_{R\to\infty}\frac{1}{2\pi i}\int_{c-iR}^{c+iR}\frac{\exp(tz)}{(z-i)^{\frac{1}{2}}(z+i)^{\frac{1}{2}}} dz$$ Where $c>0$ and the branch cut for $z^\frac{1}{2}$ is to be chosen on $\{z;\Re z=0, \Im z \leq0\}$. Make a distinction between: $$t>0, \quad t=0, \quad t<0$$ I think I showed that for $t<0$, $f(t)=0$ by using Jordan's Lemma. For $t=0$ I think the answer must be $f(0)=\frac{1}{2}$. For $t>0$ however, I have no idea what contour I have to define, nor how I have to calculate the residues in $i$ and $-i$.","This is an exercise in a course on complex analysis I am taking: Determine the function $f$ using complex contour integration: $$\lim_{R\to\infty}\frac{1}{2\pi i}\int_{c-iR}^{c+iR}\frac{\exp(tz)}{(z-i)^{\frac{1}{2}}(z+i)^{\frac{1}{2}}} dz$$ Where $c>0$ and the branch cut for $z^\frac{1}{2}$ is to be chosen on $\{z;\Re z=0, \Im z \leq0\}$. Make a distinction between: $$t>0, \quad t=0, \quad t<0$$ I think I showed that for $t<0$, $f(t)=0$ by using Jordan's Lemma. For $t=0$ I think the answer must be $f(0)=\frac{1}{2}$. For $t>0$ however, I have no idea what contour I have to define, nor how I have to calculate the residues in $i$ and $-i$.",,"['complex-analysis', 'contour-integration']"
49,Prove that: $f$ is a polynomial of degree $\le m$.,Prove that:  is a polynomial of degree .,f \le m,"I have a problem: Suppose $f \in \mathcal{H}(U,F)=\left \{ f: U \to F,~ \text{f is holomorphic mapping} \right \}$. Where $E,F$ are two complex Banach spaces, $U$ is an open set in $E$. We assume $\exists m \in \mathbb{N}_0=\{0,1, \ldots\}$ and $c>0$ such that  $$\left \|f(x)  \right \| \le c (\left \| x \right \|^m+1),~ \forall x \in E$$. Prove that: $f$ is a polynomial of degree $\le m$. Ps: I need your help. Thanks.","I have a problem: Suppose $f \in \mathcal{H}(U,F)=\left \{ f: U \to F,~ \text{f is holomorphic mapping} \right \}$. Where $E,F$ are two complex Banach spaces, $U$ is an open set in $E$. We assume $\exists m \in \mathbb{N}_0=\{0,1, \ldots\}$ and $c>0$ such that  $$\left \|f(x)  \right \| \le c (\left \| x \right \|^m+1),~ \forall x \in E$$. Prove that: $f$ is a polynomial of degree $\le m$. Ps: I need your help. Thanks.",,"['complex-analysis', 'polynomials']"
50,Does there exist $g$ s.t $g'=f$?,Does there exist  s.t ?,g g'=f,"I have the following homework question: Let G be the bounded open set shown in gray in this picture, whose   boundary consists of eight line segments. The endpoints of those   segments are, as shown , the points $-2,-1,-1+4i,1+4i,1,2,2+5i,-2+5i$. Let $f:\, G\to\mathbb{C}$ be an arbitrary function which is   holomorphic in $G$. Does there a function $g:\, G\to\mathbb{C}$ which   satisfies $g'(z)=f(z)$ for all $z\in G$ ? one tool that might be   useful here is the Identity Theorem. What I did: I believe that I can construct such a function, but I am unsure if my construction is correct: I would take some sequence of points $\{z_{i}\}_{i=1}^{\infty}$, s.t there exist $\{r_{i}\}_{i=1}^{\infty}$ s.t $D(z_{i},r_{i})\subseteq G$ and s.t $$\cup_{i=1}^{\infty}D(z_{i},r_{i})=G$$ I believe that such a sequence of points can be obtained by choosing all the points $x+iy\in G$ s.t $x,y\in\mathbb{Q}$. Moreover, I think that the points can be arranged s.t $$D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$ We first consider $D(z_{0},r_{0})$ - there is some $g_{0}:\, D(z_{0},r_{0})\to\mathbb{\mathbb{C}}$ s.t  $g_{0}'=f$ in $D(z_{0},r_{0})$, since $f$ is holomorphic. We continue with $z_{1}$and get $\widetilde{g_{1}}$, since $g_{0}'=\widetilde{g_{1}}'$ for all points in $D(z_{0},r_{0})\cap D(z_{1},r_{1})$ then $g_{0}-\widetilde{g_{1}}$ is a constant $c$, and we can pick $g_{1}=\widetilde{g_{1}}+c$. We take $g(z)$ will be eventually defined for every $z\in G$ as one of the $g_{i}$'s. This construction looks a bit fishy to me, I am not sure about the ""moreover"" part and even if so, I am not totally convinced I can arrange the constants to fit to get a holomorphic function $g$. ADDED: Instead of $$D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$   we can relax the condition to be $$\cup_{i=1}^{r}D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$ Is my construction correct ? I would also appreciate to see another approach (maybe one that uses the Identity Theorem as suggested)","I have the following homework question: Let G be the bounded open set shown in gray in this picture, whose   boundary consists of eight line segments. The endpoints of those   segments are, as shown , the points $-2,-1,-1+4i,1+4i,1,2,2+5i,-2+5i$. Let $f:\, G\to\mathbb{C}$ be an arbitrary function which is   holomorphic in $G$. Does there a function $g:\, G\to\mathbb{C}$ which   satisfies $g'(z)=f(z)$ for all $z\in G$ ? one tool that might be   useful here is the Identity Theorem. What I did: I believe that I can construct such a function, but I am unsure if my construction is correct: I would take some sequence of points $\{z_{i}\}_{i=1}^{\infty}$, s.t there exist $\{r_{i}\}_{i=1}^{\infty}$ s.t $D(z_{i},r_{i})\subseteq G$ and s.t $$\cup_{i=1}^{\infty}D(z_{i},r_{i})=G$$ I believe that such a sequence of points can be obtained by choosing all the points $x+iy\in G$ s.t $x,y\in\mathbb{Q}$. Moreover, I think that the points can be arranged s.t $$D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$ We first consider $D(z_{0},r_{0})$ - there is some $g_{0}:\, D(z_{0},r_{0})\to\mathbb{\mathbb{C}}$ s.t  $g_{0}'=f$ in $D(z_{0},r_{0})$, since $f$ is holomorphic. We continue with $z_{1}$and get $\widetilde{g_{1}}$, since $g_{0}'=\widetilde{g_{1}}'$ for all points in $D(z_{0},r_{0})\cap D(z_{1},r_{1})$ then $g_{0}-\widetilde{g_{1}}$ is a constant $c$, and we can pick $g_{1}=\widetilde{g_{1}}+c$. We take $g(z)$ will be eventually defined for every $z\in G$ as one of the $g_{i}$'s. This construction looks a bit fishy to me, I am not sure about the ""moreover"" part and even if so, I am not totally convinced I can arrange the constants to fit to get a holomorphic function $g$. ADDED: Instead of $$D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$   we can relax the condition to be $$\cup_{i=1}^{r}D(z_{i},r_{i})\cap D(z_{i+1},r_{i+1})\neq\emptyset$$ Is my construction correct ? I would also appreciate to see another approach (maybe one that uses the Identity Theorem as suggested)",,['complex-analysis']
51,Interchanging the limiting operations,Interchanging the limiting operations,,"How to remember the conditions for interchanging the limiting operations , for example between limits and integrals or integrals and sums or derivation of any order and integrals, i mean every one of these requires more or less different conditions from uniform continuity to normal continuity and the continuity of the derivatives , but i think they all have the same spirit , so what i'm looking for is some 'general statement' to remember them , also if there is an aid like a diagram that may help to easily calling the right statement when it is needed.","How to remember the conditions for interchanging the limiting operations , for example between limits and integrals or integrals and sums or derivation of any order and integrals, i mean every one of these requires more or less different conditions from uniform continuity to normal continuity and the continuity of the derivatives , but i think they all have the same spirit , so what i'm looking for is some 'general statement' to remember them , also if there is an aid like a diagram that may help to easily calling the right statement when it is needed.",,"['real-analysis', 'complex-analysis', 'integration']"
52,Complex differentiable implies analytic,Complex differentiable implies analytic,,"The only proof of this that I am aware of, uses complex line integration. This tool allows for elegant proof, but has deprived me of any intuitive or geometric understanding of why this is the case. Is there a deeper, more enlightening reason for why this is true?","The only proof of this that I am aware of, uses complex line integration. This tool allows for elegant proof, but has deprived me of any intuitive or geometric understanding of why this is the case. Is there a deeper, more enlightening reason for why this is true?",,['complex-analysis']
53,Can't prove this limit of complex numbers from a paper,Can't prove this limit of complex numbers from a paper,,"Okay so I found in a paper, marked as ""simple exercise"", the following thing: for $z,b \in \mathbb{C}$, $$\lim_{b\to0} \frac{1}{z-b} + \frac{1}{2b} - \frac{1}{\overline{b}{\vphantom{b}}^2(z-\frac{1}{\overline{b}})} - \frac{1}{2\overline{b}} = z + \frac{1}{z} + Constant$$ And no one has so far managed to confirm it. Can someone please help me.","Okay so I found in a paper, marked as ""simple exercise"", the following thing: for $z,b \in \mathbb{C}$, $$\lim_{b\to0} \frac{1}{z-b} + \frac{1}{2b} - \frac{1}{\overline{b}{\vphantom{b}}^2(z-\frac{1}{\overline{b}})} - \frac{1}{2\overline{b}} = z + \frac{1}{z} + Constant$$ And no one has so far managed to confirm it. Can someone please help me.",,"['complex-analysis', 'limits', 'complex-numbers']"
54,An analytic function is onto,An analytic function is onto,,"All sets are subsets of $\mathbb{C}$. Suppose $f: U \to D$ is analytic where $U$ is bounded and open, and $D$ is the open unit disk. Now suppose we can continuously extend $f$ to $\bar{f}: \bar{U} \to \bar D$, such that $\bar{f}(\partial U) \subseteq \partial D$.  To show that $f$ is onto, I was thinking maybe I could show that $f(U)$ is  a dense subset of $\bar{D}$ , and since $\bar{f}(U) = f(U)$ is open by the open mapping theorem, it must be $D$.  But to do this I would need to know that $f(\partial U) = \partial D$.  Is this true? Some advice or other approaches would be greatly appreciated. Thank you.","All sets are subsets of $\mathbb{C}$. Suppose $f: U \to D$ is analytic where $U$ is bounded and open, and $D$ is the open unit disk. Now suppose we can continuously extend $f$ to $\bar{f}: \bar{U} \to \bar D$, such that $\bar{f}(\partial U) \subseteq \partial D$.  To show that $f$ is onto, I was thinking maybe I could show that $f(U)$ is  a dense subset of $\bar{D}$ , and since $\bar{f}(U) = f(U)$ is open by the open mapping theorem, it must be $D$.  But to do this I would need to know that $f(\partial U) = \partial D$.  Is this true? Some advice or other approaches would be greatly appreciated. Thank you.",,"['complex-analysis', 'continuity']"
55,"If $\mu$ is a complex measure, every set $E$ has $A \subset E$ so that $|\mu(A)| \ge \frac{1}{\pi}|\mu|(E).$","If  is a complex measure, every set  has  so that",\mu E A \subset E |\mu(A)| \ge \frac{1}{\pi}|\mu|(E).,"If $\mu$ is a complex measure on a $\sigma$-algebra $M$, show that every set $E \in M$ has a subset $A$ for which $$|\mu(A)| \ge \frac{1}{\pi}|\mu|(E).$$ The suggestion is as follows: Put $d\mu=e^{i\theta}d|\mu|$.  Let $A_\alpha$ be the subset of $E$ where $cos(\theta - \alpha) > 0$.  Show that $$Re[e^{-i\alpha}\mu(A_\alpha)]=\int_Ecos^+(\theta-\alpha) d|\mu|,$$ and integrate with respect to $\alpha$. Show, by an example, that $1/\pi$ is the best constant in this inequality. Thanks for the help.","If $\mu$ is a complex measure on a $\sigma$-algebra $M$, show that every set $E \in M$ has a subset $A$ for which $$|\mu(A)| \ge \frac{1}{\pi}|\mu|(E).$$ The suggestion is as follows: Put $d\mu=e^{i\theta}d|\mu|$.  Let $A_\alpha$ be the subset of $E$ where $cos(\theta - \alpha) > 0$.  Show that $$Re[e^{-i\alpha}\mu(A_\alpha)]=\int_Ecos^+(\theta-\alpha) d|\mu|,$$ and integrate with respect to $\alpha$. Show, by an example, that $1/\pi$ is the best constant in this inequality. Thanks for the help.",,"['complex-analysis', 'analysis', 'measure-theory']"
56,Evaluation of definite integral using residue theorem：$ \int^{+\infty}_{-\infty} \frac{x-1}{x^3-1} dx$,Evaluation of definite integral using residue theorem：, \int^{+\infty}_{-\infty} \frac{x-1}{x^3-1} dx,"$$ \int^{+\infty}_{-\infty} \frac{x-1}{x^3-1} dx$$ I need to evaluate the above integral . My idea is to consider the same integral but with the $x$'s as $z$'s, over the complex plane, have a closed contour integral over $\gamma$, and then use the residue theorem. i.e. consider: $$ \int^{+\infty}_{-\infty} \frac{z-1}{z^3-1} dz$$ I'm stuck on how to formulate $\gamma$ though. I know this has 3 poles: at $z=1$, $z= \frac{-1}{2} + i\frac{\sqrt3}{2}$ and $z= \frac{-1}{2} - i\frac{\sqrt3}{2}$ How do I use this to divide up gamma over contours to which I can then use the residue theorem? And then do I have to either evaluate directly or apply the ML inequality to each individual contour?","$$ \int^{+\infty}_{-\infty} \frac{x-1}{x^3-1} dx$$ I need to evaluate the above integral . My idea is to consider the same integral but with the $x$'s as $z$'s, over the complex plane, have a closed contour integral over $\gamma$, and then use the residue theorem. i.e. consider: $$ \int^{+\infty}_{-\infty} \frac{z-1}{z^3-1} dz$$ I'm stuck on how to formulate $\gamma$ though. I know this has 3 poles: at $z=1$, $z= \frac{-1}{2} + i\frac{\sqrt3}{2}$ and $z= \frac{-1}{2} - i\frac{\sqrt3}{2}$ How do I use this to divide up gamma over contours to which I can then use the residue theorem? And then do I have to either evaluate directly or apply the ML inequality to each individual contour?",,['complex-analysis']
57,show that Joukowski transform is one-to-one in the upper half outside the unit disk,show that Joukowski transform is one-to-one in the upper half outside the unit disk,,"I have a problem on showing how the Joukowski transform $w=J(z) = .5(z + 1/z)$ takes the upper half plane, $|z| \gt 1$, one-to-one into the w upper half plane. I have shown how the unit disk itself collapses onto the real axis and how points outside it approach $(x,0)$ as $|z| \rightarrow 1$ from above. But I think I am supposed to show that there is a single-valued inverse function, and this is what I'm stuck on. Solving $J(z)=w$ for $z = w±\sqrt{w^2-1}$ and I have a rather larger formula for w in terms of $z = x + iy$, which seems like maybe more what I should be concerned with since after all the other condition is that $Im(z) \gt 0$, but also maybe I should be looking at the branch cuts except I'm not quite sure how to deal with that either. Any thoughts? Thank you.","I have a problem on showing how the Joukowski transform $w=J(z) = .5(z + 1/z)$ takes the upper half plane, $|z| \gt 1$, one-to-one into the w upper half plane. I have shown how the unit disk itself collapses onto the real axis and how points outside it approach $(x,0)$ as $|z| \rightarrow 1$ from above. But I think I am supposed to show that there is a single-valued inverse function, and this is what I'm stuck on. Solving $J(z)=w$ for $z = w±\sqrt{w^2-1}$ and I have a rather larger formula for w in terms of $z = x + iy$, which seems like maybe more what I should be concerned with since after all the other condition is that $Im(z) \gt 0$, but also maybe I should be looking at the branch cuts except I'm not quite sure how to deal with that either. Any thoughts? Thank you.",,['complex-analysis']
58,Potential for the Haar measure on the unit circle,Potential for the Haar measure on the unit circle,,"Consider the measure on the complex plane define by $\mu = d d^c \log^+ |z| = \frac{i}{\pi}\partial \bar \partial \log^+ |z|$, where $\log^+ = \max(\log,0)$ and the derivatives are taken in the sense of distributions (or currents). From the fact that $\log^+$ is zero on $\{|z|<1\}$ and harmonic on $\{|z|>1\}$ we see that the support of $\mu$ is contained in $S^1$ and in fact one can show that it is equal to $S^1$. What I am trying to see is that $\mu$ is the Haar measure on $S^1$. This measure is clearly invariant under translations, so if its mass is finite it should be a multiple of the Haar measure. My question is: how can we see that the mass is finite and that this multiple is 1?","Consider the measure on the complex plane define by $\mu = d d^c \log^+ |z| = \frac{i}{\pi}\partial \bar \partial \log^+ |z|$, where $\log^+ = \max(\log,0)$ and the derivatives are taken in the sense of distributions (or currents). From the fact that $\log^+$ is zero on $\{|z|<1\}$ and harmonic on $\{|z|>1\}$ we see that the support of $\mu$ is contained in $S^1$ and in fact one can show that it is equal to $S^1$. What I am trying to see is that $\mu$ is the Haar measure on $S^1$. This measure is clearly invariant under translations, so if its mass is finite it should be a multiple of the Haar measure. My question is: how can we see that the mass is finite and that this multiple is 1?",,"['complex-analysis', 'measure-theory', 'probability-theory']"
59,small circle inside embedding of complete graph in the plane,small circle inside embedding of complete graph in the plane,,"On the web, I found this beautiful drawing of the complete graph on 13 vertices: It is on the Geometry Daily tumblr page.  A computer scientist drew a more interactive version up to about 40 vertices . One way to think about it is the complex roots of unity $V = \{ e^{2\pi i k/3}: 0 \leq k < 13 \}$ and all the lines between them \[ \ell_{a,b} = \big\{ t  e^{2\pi i a /13} + (1-t)  e^{2\pi i b /13}: 0 < t < 1 \big\} \] Oops!  This is not a complete graph since we are missing $\ell_{k, k+1}$.  Is there a name for this new graph and it's realization on $\mathbb{R}^2$. I'd like to know what's been said about this embedding.  In the middle, for odd $n$ there is definitely a circle.  The envelope of the lines $\ell_{k, k+6}, \ell_{k+6, k+12}, \dots$ In fact, a circle for every arithmetic sequence $C_{k,d} = \text{envelope} \{ \ell_{k, k+d}, \ell_{k+d, k+2d}, \dots \}$ These are orbits of the billiard on the circle or something. What are the radii of these circles as a function of number of points? http://dl.dropbox.com/u/17949100/stars.png","On the web, I found this beautiful drawing of the complete graph on 13 vertices: It is on the Geometry Daily tumblr page.  A computer scientist drew a more interactive version up to about 40 vertices . One way to think about it is the complex roots of unity $V = \{ e^{2\pi i k/3}: 0 \leq k < 13 \}$ and all the lines between them \[ \ell_{a,b} = \big\{ t  e^{2\pi i a /13} + (1-t)  e^{2\pi i b /13}: 0 < t < 1 \big\} \] Oops!  This is not a complete graph since we are missing $\ell_{k, k+1}$.  Is there a name for this new graph and it's realization on $\mathbb{R}^2$. I'd like to know what's been said about this embedding.  In the middle, for odd $n$ there is definitely a circle.  The envelope of the lines $\ell_{k, k+6}, \ell_{k+6, k+12}, \dots$ In fact, a circle for every arithmetic sequence $C_{k,d} = \text{envelope} \{ \ell_{k, k+d}, \ell_{k+d, k+2d}, \dots \}$ These are orbits of the billiard on the circle or something. What are the radii of these circles as a function of number of points? http://dl.dropbox.com/u/17949100/stars.png",,"['geometry', 'complex-analysis', 'graph-theory', 'euclidean-geometry', 'dynamical-systems']"
60,Derivation of poisson kernel for disk of radius $R$ from unit disk,Derivation of poisson kernel for disk of radius  from unit disk,R,Is there a way to derive poisson kernel for disk of radius $R$ from unit disk?,Is there a way to derive poisson kernel for disk of radius $R$ from unit disk?,,"['real-analysis', 'complex-analysis', 'analysis']"
61,Show that satisfaction of Cauchy-Riemann Equations in polar coordinates implies analyticity,Show that satisfaction of Cauchy-Riemann Equations in polar coordinates implies analyticity,,"Suppose that $U(r,\theta),V(r, \theta)$ are continuously differentiable functions on some polar rectangle $R = \{(r, \theta) \colon r \in (a,b), \theta \in (\theta_1, \theta_2) \} \subseteq \mathbb{R}^2.$ Furthermore, assume that $U$ and $V$ satisfy the polar Cauchy-Riemann equations in $R$: $$rU_r = V_\theta, U_\theta = -rV_r.$$ If we now view $R$ as a subset of $\mathbb{C}$ rather than $\mathbb{R}^2$, we can define the function $f : R \to \mathbb{C}$ by $f(re^{i\theta}) = U(r, \theta) + iV(r,\theta).$ Prove that $f$ is analytic on $R$. I am linking this problem to a previous post: Proof of Cauchy Riemann Equations in Polar Coordinates . I believe I am asking a similar question. However, to my best knowledge, the answers to the linked post actually establish the converse of my statement above. That is, they show that analyticity of $f$ implies that these polar Cauchy-Riemann equations are satisfied. Here's what I have so far: I do know that a function $f(x + iy) = U(x,y) + iV(x,y)$ is analytic when its real and imaginary parts are continuously differentiable and satisfy the rectangular Cauchy-Riemann equations $U_x = V_y, U_y = -V_x$. The proof I have seen of this fact comes from Stein, and the key to the argument is to expand $U$ and $V$ via Taylor's formula for $C^1$ functions. That is, for a point $(x_0, y_0) \in \mathbb{R}^2$, we can write: $$U(x,y) = U(x_0,y_0) + U_x(x_0,y_0)(x - x_0) + U_y(x_0, y_0)(y - y_0) + R(x,y),$$ and a similar formula for $V(x,y)$. Here, $R(x,y)$ is a remainder term with $\frac{R(x,y)}{|(x,y) - (x_0,y_0)|} \to 0$ as $(x,y) \to (x_0,y_0)$. I'm wondering if there is some way I can adapt this proof from Stein to the polar case? Hints are solutions are greatly appreciated.","Suppose that $U(r,\theta),V(r, \theta)$ are continuously differentiable functions on some polar rectangle $R = \{(r, \theta) \colon r \in (a,b), \theta \in (\theta_1, \theta_2) \} \subseteq \mathbb{R}^2.$ Furthermore, assume that $U$ and $V$ satisfy the polar Cauchy-Riemann equations in $R$: $$rU_r = V_\theta, U_\theta = -rV_r.$$ If we now view $R$ as a subset of $\mathbb{C}$ rather than $\mathbb{R}^2$, we can define the function $f : R \to \mathbb{C}$ by $f(re^{i\theta}) = U(r, \theta) + iV(r,\theta).$ Prove that $f$ is analytic on $R$. I am linking this problem to a previous post: Proof of Cauchy Riemann Equations in Polar Coordinates . I believe I am asking a similar question. However, to my best knowledge, the answers to the linked post actually establish the converse of my statement above. That is, they show that analyticity of $f$ implies that these polar Cauchy-Riemann equations are satisfied. Here's what I have so far: I do know that a function $f(x + iy) = U(x,y) + iV(x,y)$ is analytic when its real and imaginary parts are continuously differentiable and satisfy the rectangular Cauchy-Riemann equations $U_x = V_y, U_y = -V_x$. The proof I have seen of this fact comes from Stein, and the key to the argument is to expand $U$ and $V$ via Taylor's formula for $C^1$ functions. That is, for a point $(x_0, y_0) \in \mathbb{R}^2$, we can write: $$U(x,y) = U(x_0,y_0) + U_x(x_0,y_0)(x - x_0) + U_y(x_0, y_0)(y - y_0) + R(x,y),$$ and a similar formula for $V(x,y)$. Here, $R(x,y)$ is a remainder term with $\frac{R(x,y)}{|(x,y) - (x_0,y_0)|} \to 0$ as $(x,y) \to (x_0,y_0)$. I'm wondering if there is some way I can adapt this proof from Stein to the polar case? Hints are solutions are greatly appreciated.",,['complex-analysis']
62,"If $\,f(z)=\exp((z+1)/(z-1))\,$ then all singular points of $1/(f(z)-a)$ are simple poles",If  then all singular points of  are simple poles,"\,f(z)=\exp((z+1)/(z-1))\, 1/(f(z)-a)","Here is a question from an old qualifying exam. Let $f(z)=e^{\frac{z+1}{z-1}}$ . Show that $f$ maps the unit disc $D$ in to the unit disk.(I can show this using properties of LFT. Let $0 <|a|<1$ . Prove that all isolated singular points of $\frac{1}{f(z)-a}$ in the unit disc are simple poles. Enumerate the poles explicitely. I know that this maps the unit disk into an outer disk, but how does that show that we have simple poles. Any hints or comments?","Here is a question from an old qualifying exam. Let . Show that maps the unit disc in to the unit disk.(I can show this using properties of LFT. Let . Prove that all isolated singular points of in the unit disc are simple poles. Enumerate the poles explicitely. I know that this maps the unit disk into an outer disk, but how does that show that we have simple poles. Any hints or comments?",f(z)=e^{\frac{z+1}{z-1}} f D 0 <|a|<1 \frac{1}{f(z)-a},"['complex-analysis', 'residue-calculus']"
63,Application of Schwarz lemma,Application of Schwarz lemma,,Each analytic function mapping the right half complex plane into itself must satisfy $$ \left|\frac{f(z)-f(1)}{f(z)+f(1)}\right| \leqslant \left|\frac {z-1}{z+1} \right|$$ for $\text{Re}\; z > 0.$ I have a hunch that this is an application of Schwarz's Lemma. I don't know how to proceed though. Thanks in advance.,Each analytic function mapping the right half complex plane into itself must satisfy $$ \left|\frac{f(z)-f(1)}{f(z)+f(1)}\right| \leqslant \left|\frac {z-1}{z+1} \right|$$ for $\text{Re}\; z > 0.$ I have a hunch that this is an application of Schwarz's Lemma. I don't know how to proceed though. Thanks in advance.,,"['complex-analysis', 'inequality']"
64,Help in understanding the proof of the Principle of deformation of paths,Help in understanding the proof of the Principle of deformation of paths,,"I am studying the book ""Complex variables and applications"" by James Ward Brown, Ruel Vance Churchill and I don't understand the proof given in the text. The proof uses a theorm: Proof: How can we apply the theorm ? isn't $-C_1$ and $C_2$ in different orientation (in terms of clockwise direction) so we can't apply the theorm ?","I am studying the book ""Complex variables and applications"" by James Ward Brown, Ruel Vance Churchill and I don't understand the proof given in the text. The proof uses a theorm: Proof: How can we apply the theorm ? isn't $-C_1$ and $C_2$ in different orientation (in terms of clockwise direction) so we can't apply the theorm ?",,['complex-analysis']
65,Sequence of analytic functions,Sequence of analytic functions,,"Let $G,H$ be disjoint open subsets of $\mathbb{C}$ and $f_n:G\to H$ be analytic functions. If $f_n(z)\to f(z)$ for all $z\in G$, then prove that $f$ is analytic and $f(G)\subset H$. Any help is appreciated.","Let $G,H$ be disjoint open subsets of $\mathbb{C}$ and $f_n:G\to H$ be analytic functions. If $f_n(z)\to f(z)$ for all $z\in G$, then prove that $f$ is analytic and $f(G)\subset H$. Any help is appreciated.",,['complex-analysis']
66,Uniform convergence of complex exponent derivative,Uniform convergence of complex exponent derivative,,"I'm trying to prove the following: Let $\Re z > 0$. Then $$\lim_{\varepsilon \to 0} \frac{t^{z + \varepsilon} - t^z}{\varepsilon} = t^z \log t$$ uniformly in $t \in [0,1]$. I've tried to bound it in a straight forward way to no avail. Also, assuming the convergence is among real positive epsilons, I could reduce it to the purely real case ($\Im z$ does not matter) and apply Dini's theorem. However, it does not seem to work well for arbitary $\varepsilon$. How to prove it for the general complex case?","I'm trying to prove the following: Let $\Re z > 0$. Then $$\lim_{\varepsilon \to 0} \frac{t^{z + \varepsilon} - t^z}{\varepsilon} = t^z \log t$$ uniformly in $t \in [0,1]$. I've tried to bound it in a straight forward way to no avail. Also, assuming the convergence is among real positive epsilons, I could reduce it to the purely real case ($\Im z$ does not matter) and apply Dini's theorem. However, it does not seem to work well for arbitary $\varepsilon$. How to prove it for the general complex case?",,"['complex-analysis', 'convergence-divergence', 'derivatives', 'uniform-convergence']"
67,Help with an irregular integral,Help with an irregular integral,,"I am looking for help with doing the following integral : $$\frac{1}{2\pi i}\int_{1}^{\infty}\ln\left(\frac{1-e^{-2\pi i x}}{1-e^{2\pi i x}} \right )\frac{dx}{x\left(\ln x+z\right)}\;\;\;\;z\in \mathbb{C}$$ i tried to transform it into a complex integral along a 'keyhole contour', with a branch cut along the +ive real line $\left[1,\infty\right)$. but then $\;\ln x\;$ would be transformed into $\;\ln x+2\pi i\;$ when doing the integral along the segment parallel to and below $\left(\infty,1\right]\;$  which doesn't add up nicely to the portion along the segment parallel to and above $\left[1,\infty\right)$  . any insights are  appreciated. EDIT: the above integral is equivalent to: $$\int_{1}^{\infty}\sum_{n=1}^{\infty}\frac{\sin(2\pi n x)}{n\pi}\left(\frac{1}{x\left(\ln x+z\right)}\right)dx$$ And $$\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor  \right )\left(\frac{1}{x\left(\ln x+z\right)}\right)dx$$ Also, we can prove that it's equivalent to the limit: $$e^{-z}\text{Ei}(z)+\lim_{N\rightarrow \infty}\sum_{n=1}^{N}\left(n+\frac{1}{2} \right )\ln\left(\frac{\ln(n+1)+z}{\ln(n)+z} \right )-e^{-z}\text{Ei}(z+\ln (N+1)) $$ or: $$e^{-z}\text{Ei}(z)-\frac{3}{2}\ln(z)-\left(\lim_{N\rightarrow \infty}\sum_{n=1}^{N}\ln\left(\ln(n+1)+z \right )+e^{-z}\text{Ei}\left(\ln (N+1) + z\right)-\frac{2N+1}{2}\ln(\ln(N+1)+z)\right)$$ EDIT: using the definition of the zeta function - eq. 3 - : $$\zeta(s)=\frac{s}{s-1}-s\int_{1}^{\infty}(x-\left \lfloor x \right \rfloor )x^{-s-1}dx\;\;\;\;\;\Re(s)>0$$ We have: $$\frac{\zeta(s)}{s}+\frac{1}{2s}-\frac{1}{s-1}=\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor\right)x^{-s-1}dx$$ And: $$\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor  \right )\left(\frac{1}{x\left(\ln x+z\right)}\right)dx=\int_{0}^{\infty}\left(\frac{\zeta(s)}{s}+\frac{1}{2s}-\frac{1}{s-1}\right)e^{-zs}ds$$","I am looking for help with doing the following integral : $$\frac{1}{2\pi i}\int_{1}^{\infty}\ln\left(\frac{1-e^{-2\pi i x}}{1-e^{2\pi i x}} \right )\frac{dx}{x\left(\ln x+z\right)}\;\;\;\;z\in \mathbb{C}$$ i tried to transform it into a complex integral along a 'keyhole contour', with a branch cut along the +ive real line $\left[1,\infty\right)$. but then $\;\ln x\;$ would be transformed into $\;\ln x+2\pi i\;$ when doing the integral along the segment parallel to and below $\left(\infty,1\right]\;$  which doesn't add up nicely to the portion along the segment parallel to and above $\left[1,\infty\right)$  . any insights are  appreciated. EDIT: the above integral is equivalent to: $$\int_{1}^{\infty}\sum_{n=1}^{\infty}\frac{\sin(2\pi n x)}{n\pi}\left(\frac{1}{x\left(\ln x+z\right)}\right)dx$$ And $$\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor  \right )\left(\frac{1}{x\left(\ln x+z\right)}\right)dx$$ Also, we can prove that it's equivalent to the limit: $$e^{-z}\text{Ei}(z)+\lim_{N\rightarrow \infty}\sum_{n=1}^{N}\left(n+\frac{1}{2} \right )\ln\left(\frac{\ln(n+1)+z}{\ln(n)+z} \right )-e^{-z}\text{Ei}(z+\ln (N+1)) $$ or: $$e^{-z}\text{Ei}(z)-\frac{3}{2}\ln(z)-\left(\lim_{N\rightarrow \infty}\sum_{n=1}^{N}\ln\left(\ln(n+1)+z \right )+e^{-z}\text{Ei}\left(\ln (N+1) + z\right)-\frac{2N+1}{2}\ln(\ln(N+1)+z)\right)$$ EDIT: using the definition of the zeta function - eq. 3 - : $$\zeta(s)=\frac{s}{s-1}-s\int_{1}^{\infty}(x-\left \lfloor x \right \rfloor )x^{-s-1}dx\;\;\;\;\;\Re(s)>0$$ We have: $$\frac{\zeta(s)}{s}+\frac{1}{2s}-\frac{1}{s-1}=\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor\right)x^{-s-1}dx$$ And: $$\int_{1}^{\infty}\left(\frac{1}{2}-x+\left \lfloor x \right \rfloor  \right )\left(\frac{1}{x\left(\ln x+z\right)}\right)dx=\int_{0}^{\infty}\left(\frac{\zeta(s)}{s}+\frac{1}{2s}-\frac{1}{s-1}\right)e^{-zs}ds$$",,"['complex-analysis', 'integration', 'limits', 'definite-integrals', 'contour-integration']"
68,singularities and residues,singularities and residues,,"Consider the function $$f(z)=\frac{z^3}{1-\cosh(z)}$$. Find its singularities and compute residues. I know the denominator vanishes for $z_k=2k\pi i$, $k$ integer. I first consider $k=0$, so the function is analytic in $0<|z|<2\pi$, and i can write in this punctured disc the following Laurent expansion: starting from $$\cos(z)=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n}}{(2n)!}$$ i get $$\cosh(z)=\cos(iz)=\sum_{n=0}^{\infty}\frac{z^{2n}}{(2n)!}$$Hence $$1-\cosh(z)=-\frac{z^2}{2!}-\frac{z^4}{4!}\ldots$$ thus i can write $$\frac{1}{1-\cosh(z)}=\frac{1}{-\frac{z^2}{2!}-\ldots}=-\frac{2}{z^2(1-h)}=-\frac{2}{z^2}(1+h+h^2\ldots)$$ where $h=-\frac{2z^2}{4!}-\frac{2z^4}{6!}-\ldots$. So we have $\frac{1}{1-\cosh(z)}=-\frac{2}{z^2}+\frac{4}{4!}+$ higther terms. Finally, we get $\frac{z^3}{1-\cosh(z)}=-2z+\frac{4z^3}{4!}$+ higther terms, from which i desume that $z_0=0$ is a removable singularity for f. But now i don't know how to deal with $z_k$ with $k\neq 0$. I imagine those to be all poles of order 2 for $f$, but how to prove? A last question: is it correct to say: the poles $z_k$ accumulates to $\infty$, hence $\infty$ is not an isolated singularity, thus i cannot compute $Res(f;\infty)$?","Consider the function $$f(z)=\frac{z^3}{1-\cosh(z)}$$. Find its singularities and compute residues. I know the denominator vanishes for $z_k=2k\pi i$, $k$ integer. I first consider $k=0$, so the function is analytic in $0<|z|<2\pi$, and i can write in this punctured disc the following Laurent expansion: starting from $$\cos(z)=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n}}{(2n)!}$$ i get $$\cosh(z)=\cos(iz)=\sum_{n=0}^{\infty}\frac{z^{2n}}{(2n)!}$$Hence $$1-\cosh(z)=-\frac{z^2}{2!}-\frac{z^4}{4!}\ldots$$ thus i can write $$\frac{1}{1-\cosh(z)}=\frac{1}{-\frac{z^2}{2!}-\ldots}=-\frac{2}{z^2(1-h)}=-\frac{2}{z^2}(1+h+h^2\ldots)$$ where $h=-\frac{2z^2}{4!}-\frac{2z^4}{6!}-\ldots$. So we have $\frac{1}{1-\cosh(z)}=-\frac{2}{z^2}+\frac{4}{4!}+$ higther terms. Finally, we get $\frac{z^3}{1-\cosh(z)}=-2z+\frac{4z^3}{4!}$+ higther terms, from which i desume that $z_0=0$ is a removable singularity for f. But now i don't know how to deal with $z_k$ with $k\neq 0$. I imagine those to be all poles of order 2 for $f$, but how to prove? A last question: is it correct to say: the poles $z_k$ accumulates to $\infty$, hence $\infty$ is not an isolated singularity, thus i cannot compute $Res(f;\infty)$?",,"['calculus', 'complex-analysis']"
69,When is $F(a)=\int_0^af(x)\mathrm{d}x$ holomorphic?,When is  holomorphic?,F(a)=\int_0^af(x)\mathrm{d}x,Let $f : \mathbb{C} \rightarrow \mathbb{C}$ and let $\gamma_a$ be a continuous family of paths in the complex plane going from $0$ to $a$. Which restrictions have to be imposed on $f$ to make $F(a)=\int_{\gamma_a}f(x)\mathrm{d}x$ holomorphic on some open set U?,Let $f : \mathbb{C} \rightarrow \mathbb{C}$ and let $\gamma_a$ be a continuous family of paths in the complex plane going from $0$ to $a$. Which restrictions have to be imposed on $f$ to make $F(a)=\int_{\gamma_a}f(x)\mathrm{d}x$ holomorphic on some open set U?,,['complex-analysis']
70,Hurwitz's Theorem Proof Question,Hurwitz's Theorem Proof Question,,"Hurwitz's Theorem Can anyone explain in the proof of Hurwitz's Theorem on the wikipedia page, the line where it says $ \frac{f_k'(z)}{f_k(z)}$ converges uniformly by Morera's Theorem?  I do not see how that follows from Morera's Theorem.","Hurwitz's Theorem Can anyone explain in the proof of Hurwitz's Theorem on the wikipedia page, the line where it says $ \frac{f_k'(z)}{f_k(z)}$ converges uniformly by Morera's Theorem?  I do not see how that follows from Morera's Theorem.",,['complex-analysis']
71,Null homolog cycle,Null homolog cycle,,Let $\gamma$ be a cycle on open set $A$. Suppose that for all analytic functions $f:A\to \mathbb{C}$ we have that $\int\limits_\gamma f(z)dz=0$. Does it follow that $\gamma$ is null-homolog?,Let $\gamma$ be a cycle on open set $A$. Suppose that for all analytic functions $f:A\to \mathbb{C}$ we have that $\int\limits_\gamma f(z)dz=0$. Does it follow that $\gamma$ is null-homolog?,,['complex-analysis']
72,"How to prove$|a-b|^p\leq \max(1,2^{p-1})(|a|^p+|b|^P)$?",How to prove?,"|a-b|^p\leq \max(1,2^{p-1})(|a|^p+|b|^P)","I am stuck with this question: How to prove$|a-b|^p\leq \max(1,2^{p-1})(|a|^p+|b|^p)$ I forgot to say a ,b are both complex number","I am stuck with this question: How to prove$|a-b|^p\leq \max(1,2^{p-1})(|a|^p+|b|^p)$ I forgot to say a ,b are both complex number",,"['complex-analysis', 'complex-numbers']"
73,maybe maximum modulus principle $ |f(z)| \leqslant 1 + |z|^{\frac{3} {2}} \forall z $,maybe maximum modulus principle, |f(z)| \leqslant 1 + |z|^{\frac{3} {2}} \forall z ,"Let $f$ be an entire function such that :  $$ |f(z)| \leqslant 1 + |z|^{\frac{3} {2}} \forall z $$ What we can conclude about $f$ . Sorry for asking this , but I want to see some examples of the contents of the chapter that I'm reading, this problem it's from the chapter of maximum modulus principle.","Let $f$ be an entire function such that :  $$ |f(z)| \leqslant 1 + |z|^{\frac{3} {2}} \forall z $$ What we can conclude about $f$ . Sorry for asking this , but I want to see some examples of the contents of the chapter that I'm reading, this problem it's from the chapter of maximum modulus principle.",,['complex-analysis']
74,Proving $\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt$ is bounded for $\Re(z) \leq 0$,Proving  is bounded for,\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt \Re(z) \leq 0,"I've been given the following equations; $$\psi_1(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt$$ (i.e. integrate over the straight line contour {$t + z: -\infty\lt t \lt 0 $}) $$\psi_2(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{\infty}^{z}e^{-t^2}dt$$ (i.e. integrate over the straight line contour {$t + z: \infty\gt t \gt 0 $}) I am asked to show $\psi_1(z)$ is bounded for Re(z)$\leq$0 and similarly show $\psi_2(z)$ is bounded for Re(z)$\geq$0. Also I want to show the limit of $\psi_1(x)$ as $x\rightarrow -\infty$ and $\psi_2(x)$ as $x\rightarrow \infty$ What I have done so far is to show that these equations can be represented in terms of the error function, that is; \begin{align} \psi_1(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)+1) \\ \psi_2(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)-1) \end{align} Yet am having trouble finding an upper bound for the above functions.","I've been given the following equations; $$\psi_1(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{-\infty}^{z}e^{-t^2}dt$$ (i.e. integrate over the straight line contour {$t + z: -\infty\lt t \lt 0 $}) $$\psi_2(z)=\frac{e^{z^2}}{\sqrt{\pi}}\int_{\infty}^{z}e^{-t^2}dt$$ (i.e. integrate over the straight line contour {$t + z: \infty\gt t \gt 0 $}) I am asked to show $\psi_1(z)$ is bounded for Re(z)$\leq$0 and similarly show $\psi_2(z)$ is bounded for Re(z)$\geq$0. Also I want to show the limit of $\psi_1(x)$ as $x\rightarrow -\infty$ and $\psi_2(x)$ as $x\rightarrow \infty$ What I have done so far is to show that these equations can be represented in terms of the error function, that is; \begin{align} \psi_1(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)+1) \\ \psi_2(z)&=\frac{e^{z^2}}{2}(\operatorname{erf}(z)-1) \end{align} Yet am having trouble finding an upper bound for the above functions.",,"['complex-analysis', 'integration']"
75,Show that for any polynomial $p(z)$ there is a $z$ with $|z|=1$ such that $|p(z)-1/z|\geq 1$.,Show that for any polynomial  there is a  with  such that .,p(z) z |z|=1 |p(z)-1/z|\geq 1,"I'm having a bit of trouble on another problem, and I'm not sure where to start: Show that for any polynomial $p(z)$ there is a $z$ with $|z|=1$ such that $|p(z)-1/z|\geq 1$. Could anybody get me started with a tip or two? Thanks in advance.","I'm having a bit of trouble on another problem, and I'm not sure where to start: Show that for any polynomial $p(z)$ there is a $z$ with $|z|=1$ such that $|p(z)-1/z|\geq 1$. Could anybody get me started with a tip or two? Thanks in advance.",,['complex-analysis']
76,What are applications of Lagrange's identity?,What are applications of Lagrange's identity?,,"I recently proved for homework the following identity on $\mathbb{C}$: if $a_1, \ldots , a_n, b_1, \ldots, b_n\in\mathbb{C}$, then $$ \left|\sum_{i=1}^na_ib_i\right|^2 = \left(\sum_{i=1}^n|a_i|^2\right)\left(\sum_{i=1}^n|b_i|^2\right) - \sum_{1\leq i<j\leq n} |a_i\overline{b_j}-a_j\overline{b_i}|^2. $$ This identity is called Lagrange's identity. I was wondering what are some applications of this identity. I know that one can infer Cauchy's inequality, but I was wondering if there were any other uses of it. Thanks!!","I recently proved for homework the following identity on $\mathbb{C}$: if $a_1, \ldots , a_n, b_1, \ldots, b_n\in\mathbb{C}$, then $$ \left|\sum_{i=1}^na_ib_i\right|^2 = \left(\sum_{i=1}^n|a_i|^2\right)\left(\sum_{i=1}^n|b_i|^2\right) - \sum_{1\leq i<j\leq n} |a_i\overline{b_j}-a_j\overline{b_i}|^2. $$ This identity is called Lagrange's identity. I was wondering what are some applications of this identity. I know that one can infer Cauchy's inequality, but I was wondering if there were any other uses of it. Thanks!!",,"['real-analysis', 'linear-algebra', 'complex-analysis', 'complex-numbers', 'applications']"
77,Explicit counter-example to corona problem,Explicit counter-example to corona problem,,"The corona problem is known to fail for the complex polydisk, for dimension greater than 2. Does anyone has an explicit example of such functions?","The corona problem is known to fail for the complex polydisk, for dimension greater than 2. Does anyone has an explicit example of such functions?",,"['complex-analysis', 'examples-counterexamples', 'several-complex-variables']"
78,Complex series: $\frac{z}{(z-1)(z-3)} = -3 \sum\limits_{n=0}^\infty \frac {(z-1)^n}{2^{n+2}} - \frac{1}{2(z-1)}$ for  $0 < |z-1| < 2$,Complex series:  for,\frac{z}{(z-1)(z-3)} = -3 \sum\limits_{n=0}^\infty \frac {(z-1)^n}{2^{n+2}} - \frac{1}{2(z-1)} 0 < |z-1| < 2,"Show that when $0 < |z-1| < 2$,   $$\frac{z}{(z-1)(z-3)} = -3 \sum_{n=0}^\infty \frac {(z-1)^n}{2^{n+2}} - \frac{1}{2(z-1)}$$ I thought to attack this using a partial fraction decomposition and then breaking the partial fractions into Maclaurin series. I got the $$-\frac{1}{2(z-1)}$$ from that, but the other part has me a bit stumped. I have: $$ \frac{3}{2(z-3)}$$ for the other partial fraction. And I factor out the 3/2 and then have: $$\frac{1}{z-3}$$ So I get: $$\frac{1}{1 - (-(z-2))}$$ but this does not give me what I need.","Show that when $0 < |z-1| < 2$,   $$\frac{z}{(z-1)(z-3)} = -3 \sum_{n=0}^\infty \frac {(z-1)^n}{2^{n+2}} - \frac{1}{2(z-1)}$$ I thought to attack this using a partial fraction decomposition and then breaking the partial fractions into Maclaurin series. I got the $$-\frac{1}{2(z-1)}$$ from that, but the other part has me a bit stumped. I have: $$ \frac{3}{2(z-3)}$$ for the other partial fraction. And I factor out the 3/2 and then have: $$\frac{1}{z-3}$$ So I get: $$\frac{1}{1 - (-(z-2))}$$ but this does not give me what I need.",,['complex-analysis']
79,Power series expansion for analytic functions,Power series expansion for analytic functions,,"Theorem Let $\Omega\subseteq \mathbb{C}$ be open and $f\in H(\Omega)$ ($f$ analytic on $\Omega$). If $ C(z_{0},R)\subseteq\Omega$ (where $C(z_0,R)$ is the circle with origin $z_0$ and radius $R$), then we can represent $f$ on $C(z_{0},R)$ as a power series with convergence radius $\geq R$. Proof Let $0<r<R$ and $\gamma:[0,2\pi]\rightarrow\Omega$ be the path $\gamma(t)=z_{0}+re^{it}$. Because $C(z_{0},R)$ is convex and $\gamma$ is in this circle, we have the following from the Cauchy integral formula: $$  f(z)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(\xi)}{\xi-z}\mathrm{d}\xi\ , (z\in C(z_{0},\ r)) $$ $\color{red}{\text{(1) Why not directly on } C(z_{0},\ R)? }$ Because $C(z_{0},\ r)\subseteq \mathbb{C}\backslash \gamma^{*}$ it follows that $f(z)=\displaystyle \sum_{n=0}^{\infty}c_{n}(z-z_{0})^{n}$ for a power series with convergence radius $\geq r$. Because $ r\in (0,\ R)$ is chosen arbitrarily and because the the coefficients $c_{n}$ are determined by the differentials $f^{(n)}(z_{0})$, the power series $\displaystyle \Sigma_{n=0}^{\infty}c_{n}(z-z_{0})^{n}$ has the convergence radius $\geq R$. $\color{red}{\text{(2) Why are the coefficients calculated via }f^{(n)}(z_{0})? }$ $\color{red}{\text{(3) Why does it follow that the convergence radius is } \geq R? }$","Theorem Let $\Omega\subseteq \mathbb{C}$ be open and $f\in H(\Omega)$ ($f$ analytic on $\Omega$). If $ C(z_{0},R)\subseteq\Omega$ (where $C(z_0,R)$ is the circle with origin $z_0$ and radius $R$), then we can represent $f$ on $C(z_{0},R)$ as a power series with convergence radius $\geq R$. Proof Let $0<r<R$ and $\gamma:[0,2\pi]\rightarrow\Omega$ be the path $\gamma(t)=z_{0}+re^{it}$. Because $C(z_{0},R)$ is convex and $\gamma$ is in this circle, we have the following from the Cauchy integral formula: $$  f(z)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(\xi)}{\xi-z}\mathrm{d}\xi\ , (z\in C(z_{0},\ r)) $$ $\color{red}{\text{(1) Why not directly on } C(z_{0},\ R)? }$ Because $C(z_{0},\ r)\subseteq \mathbb{C}\backslash \gamma^{*}$ it follows that $f(z)=\displaystyle \sum_{n=0}^{\infty}c_{n}(z-z_{0})^{n}$ for a power series with convergence radius $\geq r$. Because $ r\in (0,\ R)$ is chosen arbitrarily and because the the coefficients $c_{n}$ are determined by the differentials $f^{(n)}(z_{0})$, the power series $\displaystyle \Sigma_{n=0}^{\infty}c_{n}(z-z_{0})^{n}$ has the convergence radius $\geq R$. $\color{red}{\text{(2) Why are the coefficients calculated via }f^{(n)}(z_{0})? }$ $\color{red}{\text{(3) Why does it follow that the convergence radius is } \geq R? }$",,['complex-analysis']
80,Interchange of Limsup and sup,Interchange of Limsup and sup,,"Let $\phi_n: U(\subset\mathbb R^2\sim\mathbb C)\to \mathbb R$, be sequence of continuous functions. Then for any compact set $K\subset U$, what are the necessary and sufficient condition on $\phi_ns$ or on domain of $\phi_ns$ to hold: $$\sup_{z\in K}[\limsup_n\phi_n(z)]= \limsup_n[\sup_{z\in K}\phi_n(z)] $$","Let $\phi_n: U(\subset\mathbb R^2\sim\mathbb C)\to \mathbb R$, be sequence of continuous functions. Then for any compact set $K\subset U$, what are the necessary and sufficient condition on $\phi_ns$ or on domain of $\phi_ns$ to hold: $$\sup_{z\in K}[\limsup_n\phi_n(z)]= \limsup_n[\sup_{z\in K}\phi_n(z)] $$",,"['analysis', 'complex-analysis']"
81,"Complex integral revision, this is just Cauchy's Theorem right?","Complex integral revision, this is just Cauchy's Theorem right?",,"(a) Give the definition of $e^z$ for a complex number $z = x+iy$ ( 2 marks ) (b) Use the Cauchy-Riemann equations to prove that $f\colon \mathbb C \to \mathbb C$ , $f(z) = e^{2z+i}$ is differentiable at every point of $\mathbb C$ , and that $f'(z) = 2f(z)$ . ( 6 marks ) (c) Explain why the function $f(z) = e^{2z+i}$ , $z \in \mathbb C$ , is analytic at all points of $\mathbb C$ . ( 2 marks ) (d) Determine the value of the integral $$\int_\gamma e^{2z+i}\, dz,$$ where $\gamma$ is the triangle in $\mathbb C$ with vertices in the 3rd roots of $1+i$ , oriented clockwise. ( 5 marks ) In part (d) of this question...As the function $e^{2z+i}$ is analytic everywhere in the complex plane, particularly on and inside the curve $\gamma$ by Cauchy's Theorem $\int e^{2z+i}dz$ = 0. Is that correct...I dont have to bother with any of the triangle related stuff? And for (c), I have proved in (b) that this function is differentiable everywhere in C so I can't see why I am being asked why it is analytic at all point in C. Am I basically just supposed to repeat what I found in (b)? That f(z) is analytic at all points of C as because it is differentiable at all points of C, as it is a composition of analytic functions?","(a) Give the definition of for a complex number ( 2 marks ) (b) Use the Cauchy-Riemann equations to prove that , is differentiable at every point of , and that . ( 6 marks ) (c) Explain why the function , , is analytic at all points of . ( 2 marks ) (d) Determine the value of the integral where is the triangle in with vertices in the 3rd roots of , oriented clockwise. ( 5 marks ) In part (d) of this question...As the function is analytic everywhere in the complex plane, particularly on and inside the curve by Cauchy's Theorem = 0. Is that correct...I dont have to bother with any of the triangle related stuff? And for (c), I have proved in (b) that this function is differentiable everywhere in C so I can't see why I am being asked why it is analytic at all point in C. Am I basically just supposed to repeat what I found in (b)? That f(z) is analytic at all points of C as because it is differentiable at all points of C, as it is a composition of analytic functions?","e^z z = x+iy f\colon \mathbb C \to \mathbb C f(z) = e^{2z+i} \mathbb C f'(z) = 2f(z) f(z) = e^{2z+i} z \in \mathbb C \mathbb C \int_\gamma e^{2z+i}\, dz, \gamma \mathbb C 1+i e^{2z+i} \gamma \int e^{2z+i}dz",['complex-analysis']
82,Complex analysis: Coefficients of Laurent series,Complex analysis: Coefficients of Laurent series,,"I have some past exam questions that I am confused with http://i39.tinypic.com/vuwxl.png sorry, can't embed images yet I'm not sure how to approach this, I'm completely lost and just attempted to solve a few: a) it says $f(z)$ has a pole of order 5, so $ f(z) = \frac{g(z)}{z^5}, g(z)\neq0 $ so then I guess the condition is $a_{4} = \frac{g^{(4)}(0)}{4!}$? c) $f(\frac{1}{z}) = \frac{g(\frac{1}{z})}{z^5} => f(z) = z^5g(z)$ so the coefficients are $a_{n} = \frac{1}{2\pi i} \oint_\gamma z^5g(z) dz$? d) $\frac{1}{f(z)} = \frac{g(z)}{z^5} => f(z) = \frac{z^5}{g(z)}$ so, $a_{n} = \frac{1}{2\pi i} \oint_\gamma \frac{z^5}{g(z)} dz$ g) $a_{-1} = \frac{1}{2\pi i} \oint_ \gamma f(z) dz = \frac{1}{2\pi i} = Res(f; c)*I(\gamma; c) = -Res(f; c)$ h) $\frac{a_{n}}{16} = 4^{n}a_{n} => 0 = a_{n}(4^{n} - 4^{-2}) => a_{n} = 0$ or $n = -2$ for e) and f), I'm not sure what the relevance of the essential singularity is Well, I think you can see I'm clearly lost, would appreciate if you could help me out.","I have some past exam questions that I am confused with http://i39.tinypic.com/vuwxl.png sorry, can't embed images yet I'm not sure how to approach this, I'm completely lost and just attempted to solve a few: a) it says $f(z)$ has a pole of order 5, so $ f(z) = \frac{g(z)}{z^5}, g(z)\neq0 $ so then I guess the condition is $a_{4} = \frac{g^{(4)}(0)}{4!}$? c) $f(\frac{1}{z}) = \frac{g(\frac{1}{z})}{z^5} => f(z) = z^5g(z)$ so the coefficients are $a_{n} = \frac{1}{2\pi i} \oint_\gamma z^5g(z) dz$? d) $\frac{1}{f(z)} = \frac{g(z)}{z^5} => f(z) = \frac{z^5}{g(z)}$ so, $a_{n} = \frac{1}{2\pi i} \oint_\gamma \frac{z^5}{g(z)} dz$ g) $a_{-1} = \frac{1}{2\pi i} \oint_ \gamma f(z) dz = \frac{1}{2\pi i} = Res(f; c)*I(\gamma; c) = -Res(f; c)$ h) $\frac{a_{n}}{16} = 4^{n}a_{n} => 0 = a_{n}(4^{n} - 4^{-2}) => a_{n} = 0$ or $n = -2$ for e) and f), I'm not sure what the relevance of the essential singularity is Well, I think you can see I'm clearly lost, would appreciate if you could help me out.",,"['sequences-and-series', 'complex-analysis']"
83,Polynomial interpolation of the residues of a rational function,Polynomial interpolation of the residues of a rational function,,"Let $g(z) = a\prod_{i=1}^N (z-\lambda_i) \in \mathbb{Q}[z]$ be square-free.  At each root $\lambda_i \in \mathbb{C}$, let $r_i$ denote the residue $\mathrm{Res}_{\lambda_i} 1/g(z)$.  Let $I_g(z)$ denote the unique function of degree less than $N$ such that $I_g(\lambda_i) = r_i$ for all $i$.  Note that $I_{ag}(z) = aI_{g}(z)$, so we may take $g(z) \in \mathbb{Z}[t]$ if so desired.  For some basic examples, I've computed $$I_g(z) = \frac{1}{5}(2z-1) \qquad \text{for} \qquad g(z) = z^2-z-1$$ $$I_g(z) = \frac{1}{22}(2z-1)(z-3) \qquad \text{for} \qquad  g(z) = z^3 -z^2+z+1$$ Has anyone seen reference to such a construction in the literature?  My main questions are the following: Q1: Do we have $I_g(z) \in \mathbb{Q}[z]$ for $g \in \mathbb{Q}[z]$? Q2: Where $\Delta(g)$ denotes the discriminant of $g$, do we have $I_g(z) \in \frac{1}{\Delta(g)} \mathbb{Z}[z]$ for $g \in \mathbb{Z}[z]$? (A strengthening of Q1 .) Final note: the generalizations for $g$ not necessarily square-free are not difficult: take $I_g(z)$ be the unique function of degree less than $\deg g$ such that $I_g(\lambda_i)=r_i$, attained with multiplicity at least that of $\mathrm{ord}_{\lambda_i}g(z)$.  We may also consider generalizations for polynomials with coefficients in a general number field.","Let $g(z) = a\prod_{i=1}^N (z-\lambda_i) \in \mathbb{Q}[z]$ be square-free.  At each root $\lambda_i \in \mathbb{C}$, let $r_i$ denote the residue $\mathrm{Res}_{\lambda_i} 1/g(z)$.  Let $I_g(z)$ denote the unique function of degree less than $N$ such that $I_g(\lambda_i) = r_i$ for all $i$.  Note that $I_{ag}(z) = aI_{g}(z)$, so we may take $g(z) \in \mathbb{Z}[t]$ if so desired.  For some basic examples, I've computed $$I_g(z) = \frac{1}{5}(2z-1) \qquad \text{for} \qquad g(z) = z^2-z-1$$ $$I_g(z) = \frac{1}{22}(2z-1)(z-3) \qquad \text{for} \qquad  g(z) = z^3 -z^2+z+1$$ Has anyone seen reference to such a construction in the literature?  My main questions are the following: Q1: Do we have $I_g(z) \in \mathbb{Q}[z]$ for $g \in \mathbb{Q}[z]$? Q2: Where $\Delta(g)$ denotes the discriminant of $g$, do we have $I_g(z) \in \frac{1}{\Delta(g)} \mathbb{Z}[z]$ for $g \in \mathbb{Z}[z]$? (A strengthening of Q1 .) Final note: the generalizations for $g$ not necessarily square-free are not difficult: take $I_g(z)$ be the unique function of degree less than $\deg g$ such that $I_g(\lambda_i)=r_i$, attained with multiplicity at least that of $\mathrm{ord}_{\lambda_i}g(z)$.  We may also consider generalizations for polynomials with coefficients in a general number field.",,"['complex-analysis', 'polynomials', 'algebraic-number-theory', 'galois-theory', 'interpolation']"
84,The derivative of a complex function.,The derivative of a complex function.,,"Question: Find all points at which the complex valued function $f$ define by $$f(z)=(2+i)z^3-iz^2+4z-(1+7i)$$ has a derivative. I know that $z^3$,$z^2$, and $z$ are differentiable everywhere in the domain of $f$, but how can I write my answer formally? Please can somebody help? Note:I want to solve the problem without using Cauchy-Riemann equations.","Question: Find all points at which the complex valued function $f$ define by $$f(z)=(2+i)z^3-iz^2+4z-(1+7i)$$ has a derivative. I know that $z^3$,$z^2$, and $z$ are differentiable everywhere in the domain of $f$, but how can I write my answer formally? Please can somebody help? Note:I want to solve the problem without using Cauchy-Riemann equations.",,['complex-analysis']
85,Homotopy invariance of winding number in complex analysis.,Homotopy invariance of winding number in complex analysis.,,"In topology, the winding number is homotopy invariant under the definition $n(\gamma,a)=\frac{\tilde{\theta}(\beta)-\tilde{\theta}(\alpha)}{2\pi}.$ I assume the must be true in the framework of complex analysis. Suppose you take as definition for the winding number $n(C,a)$ of a curve $C$ through $a$ to be  $$ n(C,a)=\frac{1}{2\pi i}\int_C\frac{dz}{z-a}. $$ Is is still true that $n(C,a)$ is hopotopy invariant under smooth curves $C$ not going through $a$? Thank you.","In topology, the winding number is homotopy invariant under the definition $n(\gamma,a)=\frac{\tilde{\theta}(\beta)-\tilde{\theta}(\alpha)}{2\pi}.$ I assume the must be true in the framework of complex analysis. Suppose you take as definition for the winding number $n(C,a)$ of a curve $C$ through $a$ to be  $$ n(C,a)=\frac{1}{2\pi i}\int_C\frac{dz}{z-a}. $$ Is is still true that $n(C,a)$ is hopotopy invariant under smooth curves $C$ not going through $a$? Thank you.",,['complex-analysis']
86,Help with integrals in Gunning's book,Help with integrals in Gunning's book,,"In Gunning's book Introduction to Holomorphic Functions of Severals Variables, Vol I, on pages 44 and 45 have some statements about integrals that I can not understand. First, on page 44, equation $(3)$ we have the integral $$\iint_{D_{r}} \frac{\partial f(\zeta)}{\partial \overline{\zeta}} \frac{d \overline{\zeta} \wedge d \zeta}{\zeta - z},$$ where f is a $\mathcal{C}^{\infty}$ function in an open neighborhood of $\overline{D}$, $D$ an open subset of the complex plane bounded by a rectifiable simple curve $\gamma$, $z \in D$ and $D_{r} = D - \overline{\Delta}(z; r)$ for $r$ such that the disc is in $D$. Gunning says that since $(\zeta - z)^{-1} d \overline{\zeta} \wedge d \zeta$ is a bounded measure in the plane, the integral above converges to the integral over $D$ as $r$ tends to zero. I can not understand $(\zeta - z)^{-1} d \overline{\zeta} \wedge d \zeta$ as a measure, much less bounded in the plane. On page 45, we have the integral $$g(z) = \frac{1}{2\pi i} \iint_{\mathbb{C}^{1}} \frac{f(\zeta)}{\zeta - z} d \zeta \wedge d \overline{\zeta},$$ where $f$ is a $\mathcal{C}^{\infty}$ function that vanishes outside a compact subset of $\mathbb{C}$. Gunning says that this function is $\mathcal{C}^{\infty}$ in $\mathbb{C}^{1}$ (if $f$ is holomorphic, then $g$ is holomorphic). Why, if we have $(\zeta - z)$ in the denominator? I think this is related to the first question. Perhaps I just need references to study more about integrals. Thanks.","In Gunning's book Introduction to Holomorphic Functions of Severals Variables, Vol I, on pages 44 and 45 have some statements about integrals that I can not understand. First, on page 44, equation $(3)$ we have the integral $$\iint_{D_{r}} \frac{\partial f(\zeta)}{\partial \overline{\zeta}} \frac{d \overline{\zeta} \wedge d \zeta}{\zeta - z},$$ where f is a $\mathcal{C}^{\infty}$ function in an open neighborhood of $\overline{D}$, $D$ an open subset of the complex plane bounded by a rectifiable simple curve $\gamma$, $z \in D$ and $D_{r} = D - \overline{\Delta}(z; r)$ for $r$ such that the disc is in $D$. Gunning says that since $(\zeta - z)^{-1} d \overline{\zeta} \wedge d \zeta$ is a bounded measure in the plane, the integral above converges to the integral over $D$ as $r$ tends to zero. I can not understand $(\zeta - z)^{-1} d \overline{\zeta} \wedge d \zeta$ as a measure, much less bounded in the plane. On page 45, we have the integral $$g(z) = \frac{1}{2\pi i} \iint_{\mathbb{C}^{1}} \frac{f(\zeta)}{\zeta - z} d \zeta \wedge d \overline{\zeta},$$ where $f$ is a $\mathcal{C}^{\infty}$ function that vanishes outside a compact subset of $\mathbb{C}$. Gunning says that this function is $\mathcal{C}^{\infty}$ in $\mathbb{C}^{1}$ (if $f$ is holomorphic, then $g$ is holomorphic). Why, if we have $(\zeta - z)$ in the denominator? I think this is related to the first question. Perhaps I just need references to study more about integrals. Thanks.",,"['complex-analysis', 'measure-theory']"
87,"Curve integrals, Polynomial conjugated, inserting $e^{it}$ inverse","Curve integrals, Polynomial conjugated, inserting  inverse",e^{it},"I attempted to solve these questions from old examination papers, the first I could do, whether they are correct or not I don't know, and the following I am sure I got up with the wrong foot to begin with: Compute a) $\int_{\partial B_{r}(0)} \overline{z} dz$; b) $\int_{\partial B_{r}(0)}Re(z)dz$ Prove that : if p is y polynomial, then $\int_{\partial B_{r}(0)} \overline{p(z)}dz = 2\pi r^{2}\overline{p'(0)} $ Prove that : $\int_{\partial B_{1}(0)}f(z)dz = \int_{\partial B_{1}(0) }f(\frac{1}{z})\frac{dz}{z^{2}}$ a) I used this parametrization : $re^{it}, t\in [0,2\pi]$ and get the following $\int_{0}^{2\pi}re^{-it} ire^{it}dt = ir^{2}\int_{0}^{2\pi}1dt = 2\pi ir^{2} $ b) $\int_{0}^{2\pi} Re( re^{it}) dz = \int_{0}^{2\pi} rcos(t) ire^{it}dt = ir^{2}\int_{0}^{2\pi}cos(t)e^{it}dt = 2\pi ir^{2}$ I put p as polynomial of degree n : $z^{n}+z^{n-1}...+z_{0}$, then if we insert the parametrization we get: $\int_{0}^{2\pi} \overline{(r^{n}e^{nit}+r^{n-1}e^{(n-1)it}+...+z_{0}})(ire^{it})dt$ $= ir\int_{0}^{2\pi}(r^{n}e^{(-n+1)it}+r^{n-1}e^{(-n-1+1)it} + r^{n-2}e^{(-n-1)it}+... \overline{z_{0}})dt$ $=ir\int_{0}^{2\pi}r^{n}e^{(-n+1)it}dt + ir\int_{0}^{2\pi} r^{n-1}e^{-nit}dt ... + ir\int_{0}^{2 \pi}\overline{z_{0}}dt $ 3 ) $\int_{\partial B_{1}(0)}f(z)dz = \int_{0}^{2\pi}f(e^{it})ie^{it}dt$ then insert here something  and $ =\int_{0}^{2\pi} f(e^{-it})e^{-2it}ie^{it}dt = \int_{\partial B_{1}(0)}f(z^{-1})z^{-2}dz$ How to fill in the missing parts? Are my beginnings OK? Would be very glad if somebody would help me out . Thanks for every effort. (Sorry if this is a little bit much at once. )","I attempted to solve these questions from old examination papers, the first I could do, whether they are correct or not I don't know, and the following I am sure I got up with the wrong foot to begin with: Compute a) $\int_{\partial B_{r}(0)} \overline{z} dz$; b) $\int_{\partial B_{r}(0)}Re(z)dz$ Prove that : if p is y polynomial, then $\int_{\partial B_{r}(0)} \overline{p(z)}dz = 2\pi r^{2}\overline{p'(0)} $ Prove that : $\int_{\partial B_{1}(0)}f(z)dz = \int_{\partial B_{1}(0) }f(\frac{1}{z})\frac{dz}{z^{2}}$ a) I used this parametrization : $re^{it}, t\in [0,2\pi]$ and get the following $\int_{0}^{2\pi}re^{-it} ire^{it}dt = ir^{2}\int_{0}^{2\pi}1dt = 2\pi ir^{2} $ b) $\int_{0}^{2\pi} Re( re^{it}) dz = \int_{0}^{2\pi} rcos(t) ire^{it}dt = ir^{2}\int_{0}^{2\pi}cos(t)e^{it}dt = 2\pi ir^{2}$ I put p as polynomial of degree n : $z^{n}+z^{n-1}...+z_{0}$, then if we insert the parametrization we get: $\int_{0}^{2\pi} \overline{(r^{n}e^{nit}+r^{n-1}e^{(n-1)it}+...+z_{0}})(ire^{it})dt$ $= ir\int_{0}^{2\pi}(r^{n}e^{(-n+1)it}+r^{n-1}e^{(-n-1+1)it} + r^{n-2}e^{(-n-1)it}+... \overline{z_{0}})dt$ $=ir\int_{0}^{2\pi}r^{n}e^{(-n+1)it}dt + ir\int_{0}^{2\pi} r^{n-1}e^{-nit}dt ... + ir\int_{0}^{2 \pi}\overline{z_{0}}dt $ 3 ) $\int_{\partial B_{1}(0)}f(z)dz = \int_{0}^{2\pi}f(e^{it})ie^{it}dt$ then insert here something  and $ =\int_{0}^{2\pi} f(e^{-it})e^{-2it}ie^{it}dt = \int_{\partial B_{1}(0)}f(z^{-1})z^{-2}dz$ How to fill in the missing parts? Are my beginnings OK? Would be very glad if somebody would help me out . Thanks for every effort. (Sorry if this is a little bit much at once. )",,['complex-analysis']
88,Do the solutions to the unit equation lie dense in the complex numbers,Do the solutions to the unit equation lie dense in the complex numbers,,"Let $S\subset  \overline{\mathbf{Q}}$  be the  set of solutions to the unit equation, i.e., $S$ consists of algebraic integers $a$ such that $a$ and $1-a$ are units in the ring of algebraic integers. Let $U$ be a non-empty open subset in the Euclidean topology on $\mathbf{C}$. Does $U$ contain infinitely many solutions to the unit equation. That is, does the intersection $S\cap U$ contain infinitely many elements? Since there werent't any replies, I also asked this question on Mathoverflow.","Let $S\subset  \overline{\mathbf{Q}}$  be the  set of solutions to the unit equation, i.e., $S$ consists of algebraic integers $a$ such that $a$ and $1-a$ are units in the ring of algebraic integers. Let $U$ be a non-empty open subset in the Euclidean topology on $\mathbf{C}$. Does $U$ contain infinitely many solutions to the unit equation. That is, does the intersection $S\cap U$ contain infinitely many elements? Since there werent't any replies, I also asked this question on Mathoverflow.",,"['number-theory', 'complex-analysis', 'algebraic-geometry', 'algebraic-number-theory', 'diophantine-equations']"
89,square root of complex number in a resolvent operator,square root of complex number in a resolvent operator,,"Let $ R_\lambda (x,y) = \frac{1}{2\sqrt{-\lambda}} e^{-\sqrt{-\lambda}|x-y|}$ . Now according to the book I am following if $\lambda > 0$ and we shift $\lambda \rightarrow \lambda + i\epsilon$, we get $ R_\lambda (x,y) = \frac{1}{2\sqrt{-\lambda}} e^{-\sqrt{-\lambda}|x-y|} \rightarrow \frac{i}{2\sqrt{\lambda}}e^{i\sqrt{\lambda}|x-y| -\epsilon|x-y|/2\sqrt{\lambda}}$ To show this I had $\sqrt{-\lambda}=\sqrt{|\lambda|}e^{-i\pi/2} = -i \sqrt{|\lambda|}$, and then I expanded $\sqrt{-\lambda -i\epsilon} = -i\sqrt{|\lambda|} + \frac{i\epsilon}{-2i\sqrt{\lambda}}$. However, this gives a positive sign for the $\epsilon$ term of the exponential in the resolvent. Is there anything I am missing here? Any help will be appreciated.","Let $ R_\lambda (x,y) = \frac{1}{2\sqrt{-\lambda}} e^{-\sqrt{-\lambda}|x-y|}$ . Now according to the book I am following if $\lambda > 0$ and we shift $\lambda \rightarrow \lambda + i\epsilon$, we get $ R_\lambda (x,y) = \frac{1}{2\sqrt{-\lambda}} e^{-\sqrt{-\lambda}|x-y|} \rightarrow \frac{i}{2\sqrt{\lambda}}e^{i\sqrt{\lambda}|x-y| -\epsilon|x-y|/2\sqrt{\lambda}}$ To show this I had $\sqrt{-\lambda}=\sqrt{|\lambda|}e^{-i\pi/2} = -i \sqrt{|\lambda|}$, and then I expanded $\sqrt{-\lambda -i\epsilon} = -i\sqrt{|\lambda|} + \frac{i\epsilon}{-2i\sqrt{\lambda}}$. However, this gives a positive sign for the $\epsilon$ term of the exponential in the resolvent. Is there anything I am missing here? Any help will be appreciated.",,['complex-analysis']
90,Derived analytic function from real part,Derived analytic function from real part,,"I saw Ahlfors's book Complex Analysis . It mentioned that analytic function $f(z)$ can be derived from a given real part $u(x,y)$, where $x$ and $y$ are real. It said that $$ u(x,y)=\frac{1}{2}[f(x+iy)+\bar{f}(x-iy)].     \tag{1} $$ However, it mentioned that it is 'reasonable' that (1) holds even when $x$ and $y$ are 'complex'. Why? I think that, if $x$ and $y$ are real, then real part $u(x,y)$ should be written down by $$ u(x,y)=\frac{1}{2}[f(z)+\bar{f}(\bar{z})], \tag{2} $$ where $z=x+iy$. Hence, if $x$ and $y$ are complex, (2) should be equal to $$ u(x,y)=\frac{1}{2}[f(x+iy)+\bar{f}(\bar{x}-i\bar{y})]. \tag{3} $$ It confused me for a long time. Please help me. Thanks!","I saw Ahlfors's book Complex Analysis . It mentioned that analytic function $f(z)$ can be derived from a given real part $u(x,y)$, where $x$ and $y$ are real. It said that $$ u(x,y)=\frac{1}{2}[f(x+iy)+\bar{f}(x-iy)].     \tag{1} $$ However, it mentioned that it is 'reasonable' that (1) holds even when $x$ and $y$ are 'complex'. Why? I think that, if $x$ and $y$ are real, then real part $u(x,y)$ should be written down by $$ u(x,y)=\frac{1}{2}[f(z)+\bar{f}(\bar{z})], \tag{2} $$ where $z=x+iy$. Hence, if $x$ and $y$ are complex, (2) should be equal to $$ u(x,y)=\frac{1}{2}[f(x+iy)+\bar{f}(\bar{x}-i\bar{y})]. \tag{3} $$ It confused me for a long time. Please help me. Thanks!",,['complex-analysis']
91,"Integrating Around ""Poles""?","Integrating Around ""Poles""?",,"In complex analysis and the calculus of ""residues,"" Cauchy's integral theorem gives a ""shortcut"": The integral is $2\pi i$ times the sum of the ""residues."" This works because there are ""singularities,"" in the area in question. Normally, Green's theorem (real case) is a fairly cut and dried matter. But if there is a ""singularity"" at say, $(0,0)$ then you need to multiply by $2 \pi$ to get the value of the integral. These two phenomena look suspiciously similar, except for the fact that in the real case, you multiply by $2\pi$, and in the complex case, by $2 \pi i$. Are they, in fact, somehow connected? Or is this a ""false"" analogy that happens to be coincidental?","In complex analysis and the calculus of ""residues,"" Cauchy's integral theorem gives a ""shortcut"": The integral is $2\pi i$ times the sum of the ""residues."" This works because there are ""singularities,"" in the area in question. Normally, Green's theorem (real case) is a fairly cut and dried matter. But if there is a ""singularity"" at say, $(0,0)$ then you need to multiply by $2 \pi$ to get the value of the integral. These two phenomena look suspiciously similar, except for the fact that in the real case, you multiply by $2\pi$, and in the complex case, by $2 \pi i$. Are they, in fact, somehow connected? Or is this a ""false"" analogy that happens to be coincidental?",,['complex-analysis']
92,Lifting of a tangent bundle,Lifting of a tangent bundle,,"I have a problem with Kuranishi's theorem in deformation theory. I'll try to formulate it in general terms, and then describe the particular situation. Let $\pi : M \to S$ be a smooth fiber bundle - i.e. $M$ and $S$ are smooth manifolds, and $\pi$ is a surjective submersion. There is an associated surjective morphism of vector bundles $ \pi_* : T_M \to \pi^* T_S$. I want to find a lifting of $\pi^* T_S$ into $T_M$. Suppose I can find a smooth map $f : S \to M$ which satisfies $\pi \circ f = id_S$. This induces an injective map $T_S \to f^*T_M$. Can I lift this to a map $\pi^* T_S \to T_M$? How about if some extra data is given, like a metric on $S$, or a family of metrics $g_s$ on the fibers $T_M |_{M_s}$ (where $s$ is a parameter in $S$)? Basically I'm trying to use Kuranishi's theorem to get something like Siu's canonical lifts. In this situation $M$ is the product of a fixed smooth manifold and the space of its complex structures, and $S$ is a complex manifold (open ball, even). The map $\pi$ is the passing to the quotient by the action of the group of diffeomorphisms. If we fix a hermitian metric $h$ on $M_0$, then Kuranishi gives a map $f : S \to M$ which satisfies the above hypothesis. I'm told that Kuranishi should induce a lifting of $\pi^*T_S$ into $T_M$, but I can't seem to figure out how.","I have a problem with Kuranishi's theorem in deformation theory. I'll try to formulate it in general terms, and then describe the particular situation. Let $\pi : M \to S$ be a smooth fiber bundle - i.e. $M$ and $S$ are smooth manifolds, and $\pi$ is a surjective submersion. There is an associated surjective morphism of vector bundles $ \pi_* : T_M \to \pi^* T_S$. I want to find a lifting of $\pi^* T_S$ into $T_M$. Suppose I can find a smooth map $f : S \to M$ which satisfies $\pi \circ f = id_S$. This induces an injective map $T_S \to f^*T_M$. Can I lift this to a map $\pi^* T_S \to T_M$? How about if some extra data is given, like a metric on $S$, or a family of metrics $g_s$ on the fibers $T_M |_{M_s}$ (where $s$ is a parameter in $S$)? Basically I'm trying to use Kuranishi's theorem to get something like Siu's canonical lifts. In this situation $M$ is the product of a fixed smooth manifold and the space of its complex structures, and $S$ is a complex manifold (open ball, even). The map $\pi$ is the passing to the quotient by the action of the group of diffeomorphisms. If we fix a hermitian metric $h$ on $M_0$, then Kuranishi gives a map $f : S \to M$ which satisfies the above hypothesis. I'm told that Kuranishi should induce a lifting of $\pi^*T_S$ into $T_M$, but I can't seem to figure out how.",,"['differential-geometry', 'differential-topology', 'complex-analysis']"
93,Characterizing functions that satisfy the reflection $f(z)f(-z)=1$,Characterizing functions that satisfy the reflection,f(z)f(-z)=1,"Context: During a mathematical discussion with a good friend, I was brought to think about the functional equation $q(t)q(1-t) = 1$ for $q$ with some regularity. (To be honest the exact context doesn't really matter, since I am not trying to solve the original problem that this stemmed from). Upon brainstorming a few solutions ( $exp(t-1/2)$ , $\Gamma(t)\sqrt{\sin \pi t}$ up to a constant)), I came to realize that the solutions are plentiful. By reparameterizing the functions and choosing the regularity to be meromorphic (motivated by the fact that all the pretty solutions were meromorphic), I set myself to the following challenge: Characterise/Classify all the functions $f \in \mathcal{M}(\mathbb{D})$ which satisfy the reflection $f(z)f(-z)=1$ My attempt goes as follows: Denote by $G$ the set of such functions. After some verifications, it becomes clear that $G$ is actually a group with respect to the operation of pointwise multiplication* of functions (*one has to take care of removable singularities). Moreover, define the function \begin{align} K : \mathcal{M}(\mathbb{D})  &\to \mathcal{M}(\mathbb{D}) \\\\ f(z) &\to K(f)(z) = f(z)/f(-z) \end{align} Easy computations show the following three facts: The image of $K$ is inside $G$ , ie $Im(K) \subset G$ K is in fact a morphism of groups with respect to multiplication The kernel of $K$ is the subgroup of even meromorphic functions on the unit disk, let's call it $\mathcal{E}(\mathbb{D})$ Now using the first isomorphism theorem, one obtains the following isomorphism of groups: $\mathcal{M}(\mathbb{D})/\mathcal{E}(\mathbb{D}) \cong Im(K)$ Obviously for my purpose, I'd like $K$ to be onto $G$ , in other words, I want to be able to express every $g \in G$ as $g(z) = f(z) / f(-z)$ for some meromorphic $f$ , obtaining the isomorphism of groups: $\mathcal{M}(\mathbb{D})/\mathcal{E}(\mathbb{D}) \cong G$ There is some non formal evidence for that being the case, but I'd like to formalize it. The path I took was the following: if $g \in G$ is without any zeroes, then it is also without poles, so there exists a holomorphic branch of its square root on $\mathbb{D}$ . Then $f(z) = \sqrt{g(z)}$ satisfies the following: $f(z) / f(-z) = \sqrt{g(z)}/\sqrt{g(-z)} = g(z) / (\sqrt{g(z)}\sqrt{g(-z)})$ , where the last denominators square is equal to one (since $g \in G$ ), so that it itself must be equal to one (if one takes the correct branch?). Thus any $g\in G$ without zeroes can be expressed as $f(z) / f(-z)$ for some meromorphic $f$ . To tackle the case where $g$ is allowed to be zero, we'll show a little lemma: lemma: $g\in G$ admits the desired decomposition iff there exists an even meromorphic $e$ such that there exists a meromorphic branch of $\sqrt{e(z)g(z)}$ proof: if such an $e$ exists then one can set $f(z) = \sqrt{e(z)g(z)}$ and redo the previous computations. For the converse, consider $f^2(z) / g(z) \blacksquare$ In our case, the poles and zeros of $g$ come in pairs: if $z$ is a zero of order $n$ then $-z$ is a pole of order $n$ and vice versa. By multiplying by our magic $e$ , we want to make all the orders of the zeroes/poles even, then $eg$ will admit a square root. An easy example is if $g$ has a finite number of zeroes of odd order, say $\alpha_1, ..., \alpha_n$ : one considers: $e(z) = \prod_k (z^2 - \alpha_k^2)$ . This finite product is an even function that has simple zeroes at all the points where $g$ has an odd ordered zero, thus $eg$ will only have even ordered zeroes and hence admits a square root. (and obviously the problem of the poles is also taken care of, since for any odd ordered pole $-\alpha_k$ , the product $eg$ will have the pole's order decreased by one, giving an even ordered pole) This is where the problem comes: what if $g$ has an infinite number of odd ordered zeroes? In that case the aforementioned product has no reason to converge (that I'm aware of). Is there a workaround with more well chosen functions than $(z^2 - \alpha^2)$ to make the infinite product converge? Or is this approach just not good enough to obtain the full result?","Context: During a mathematical discussion with a good friend, I was brought to think about the functional equation for with some regularity. (To be honest the exact context doesn't really matter, since I am not trying to solve the original problem that this stemmed from). Upon brainstorming a few solutions ( , up to a constant)), I came to realize that the solutions are plentiful. By reparameterizing the functions and choosing the regularity to be meromorphic (motivated by the fact that all the pretty solutions were meromorphic), I set myself to the following challenge: Characterise/Classify all the functions which satisfy the reflection My attempt goes as follows: Denote by the set of such functions. After some verifications, it becomes clear that is actually a group with respect to the operation of pointwise multiplication* of functions (*one has to take care of removable singularities). Moreover, define the function Easy computations show the following three facts: The image of is inside , ie K is in fact a morphism of groups with respect to multiplication The kernel of is the subgroup of even meromorphic functions on the unit disk, let's call it Now using the first isomorphism theorem, one obtains the following isomorphism of groups: Obviously for my purpose, I'd like to be onto , in other words, I want to be able to express every as for some meromorphic , obtaining the isomorphism of groups: There is some non formal evidence for that being the case, but I'd like to formalize it. The path I took was the following: if is without any zeroes, then it is also without poles, so there exists a holomorphic branch of its square root on . Then satisfies the following: , where the last denominators square is equal to one (since ), so that it itself must be equal to one (if one takes the correct branch?). Thus any without zeroes can be expressed as for some meromorphic . To tackle the case where is allowed to be zero, we'll show a little lemma: lemma: admits the desired decomposition iff there exists an even meromorphic such that there exists a meromorphic branch of proof: if such an exists then one can set and redo the previous computations. For the converse, consider In our case, the poles and zeros of come in pairs: if is a zero of order then is a pole of order and vice versa. By multiplying by our magic , we want to make all the orders of the zeroes/poles even, then will admit a square root. An easy example is if has a finite number of zeroes of odd order, say : one considers: . This finite product is an even function that has simple zeroes at all the points where has an odd ordered zero, thus will only have even ordered zeroes and hence admits a square root. (and obviously the problem of the poles is also taken care of, since for any odd ordered pole , the product will have the pole's order decreased by one, giving an even ordered pole) This is where the problem comes: what if has an infinite number of odd ordered zeroes? In that case the aforementioned product has no reason to converge (that I'm aware of). Is there a workaround with more well chosen functions than to make the infinite product converge? Or is this approach just not good enough to obtain the full result?","q(t)q(1-t) = 1 q exp(t-1/2) \Gamma(t)\sqrt{\sin \pi t} f \in \mathcal{M}(\mathbb{D}) f(z)f(-z)=1 G G \begin{align} K : \mathcal{M}(\mathbb{D})  &\to \mathcal{M}(\mathbb{D}) \\\\ f(z) &\to K(f)(z) = f(z)/f(-z) \end{align} K G Im(K) \subset G K \mathcal{E}(\mathbb{D}) \mathcal{M}(\mathbb{D})/\mathcal{E}(\mathbb{D}) \cong Im(K) K G g \in G g(z) = f(z) / f(-z) f \mathcal{M}(\mathbb{D})/\mathcal{E}(\mathbb{D}) \cong G g \in G \mathbb{D} f(z) = \sqrt{g(z)} f(z) / f(-z) = \sqrt{g(z)}/\sqrt{g(-z)} = g(z) / (\sqrt{g(z)}\sqrt{g(-z)}) g \in G g\in G f(z) / f(-z) f g g\in G e \sqrt{e(z)g(z)} e f(z) = \sqrt{e(z)g(z)} f^2(z) / g(z) \blacksquare g z n -z n e eg g \alpha_1, ..., \alpha_n e(z) = \prod_k (z^2 - \alpha_k^2) g eg -\alpha_k eg g (z^2 - \alpha^2)","['complex-analysis', 'meromorphic-functions']"
94,Analytical continuation of a Matsubara sum,Analytical continuation of a Matsubara sum,,"I want to numerically calculate the low temperature limit of the following Matsubara sum $$ S(\Omega) = \pi T \sum_{\omega_n} \frac{4\Delta^2+\Omega^2}{s_1 s_2 (s_1 + s_2)},$$ with $\omega_n = \pi T (2n+1)$ , $s_1(\omega_n) = \sqrt{\omega_n^2 + \Delta^2}$ and $s_2(\omega_n) = \sqrt{(\omega_n+\Omega)^2 + \Delta^2}$ . In fact, in the limit $T\rightarrow0$ , I get $$ S(\Omega) = \frac{2\sqrt{4\Delta^2 + \Omega^2}}{\Omega} \tanh^{-1}{\frac{\Omega}{\sqrt{4\Delta^2 + \Omega^2}}}.$$ When I calculate the sum above directly I get the same result. This is nice but I am really interested in the real frequency analytical continuation of $S(\Omega)$ . To get it I do the usual change $\Omega \rightarrow i \Omega$ . This simply gives me $$ S_a(\Omega) = \frac{2\sqrt{4\Delta^2 - \Omega^2}}{\Omega} \tan^{-1}{\frac{\Omega}{\sqrt{4\Delta^2 - \Omega^2}}}.$$ This is the correct result. Nonetheless, when I try to calculate numerically the Matsubara sum above with the change $\Omega \rightarrow i \Omega$ , I only get the correct result for $\Omega < \Delta$ . I suspect that it comes from the fact that the real part inside the square root of $s_2(\omega_n)$ changes sign at $\Omega = \Delta$ . One trick I used was to do the change of variable $\omega_n \rightarrow \omega_n - \Omega/2$ . In this case the change of sign of the real part inside $s_2(\omega_n)$ changes at $\Omega = 2\Delta$ . And indeed the analytical result $S_a$ and the direct sum calculation give the same results for $\Omega <2\Delta$ . But the results remain different for $\Omega > 2 \Delta$ . My question is: what should I do to get perfect agreement between the sum and the analytical solution $S_a$ for all $\Omega$ ? To be clear, after the analytical continuation $\Omega \rightarrow i \Omega$ , I use the positive real part value for $s_2(\omega_n)$ for all $\Omega$ . Edit: I use a python script to calculate the sum where the square root has branch cut in the negatif axis $] - \infty, 0]$ . I can provide my script on request.","I want to numerically calculate the low temperature limit of the following Matsubara sum with , and . In fact, in the limit , I get When I calculate the sum above directly I get the same result. This is nice but I am really interested in the real frequency analytical continuation of . To get it I do the usual change . This simply gives me This is the correct result. Nonetheless, when I try to calculate numerically the Matsubara sum above with the change , I only get the correct result for . I suspect that it comes from the fact that the real part inside the square root of changes sign at . One trick I used was to do the change of variable . In this case the change of sign of the real part inside changes at . And indeed the analytical result and the direct sum calculation give the same results for . But the results remain different for . My question is: what should I do to get perfect agreement between the sum and the analytical solution for all ? To be clear, after the analytical continuation , I use the positive real part value for for all . Edit: I use a python script to calculate the sum where the square root has branch cut in the negatif axis . I can provide my script on request."," S(\Omega) = \pi T \sum_{\omega_n} \frac{4\Delta^2+\Omega^2}{s_1 s_2 (s_1 + s_2)}, \omega_n = \pi T (2n+1) s_1(\omega_n) = \sqrt{\omega_n^2 + \Delta^2} s_2(\omega_n) = \sqrt{(\omega_n+\Omega)^2 + \Delta^2} T\rightarrow0  S(\Omega) = \frac{2\sqrt{4\Delta^2 + \Omega^2}}{\Omega} \tanh^{-1}{\frac{\Omega}{\sqrt{4\Delta^2 + \Omega^2}}}. S(\Omega) \Omega \rightarrow i \Omega  S_a(\Omega) = \frac{2\sqrt{4\Delta^2 - \Omega^2}}{\Omega} \tan^{-1}{\frac{\Omega}{\sqrt{4\Delta^2 - \Omega^2}}}. \Omega \rightarrow i \Omega \Omega < \Delta s_2(\omega_n) \Omega = \Delta \omega_n \rightarrow \omega_n - \Omega/2 s_2(\omega_n) \Omega = 2\Delta S_a \Omega <2\Delta \Omega > 2 \Delta S_a \Omega \Omega \rightarrow i \Omega s_2(\omega_n) \Omega ] - \infty, 0]","['calculus', 'sequences-and-series', 'complex-analysis', 'numerical-methods', 'analytic-continuation']"
95,Contour Integrating,Contour Integrating,,"$$ I = \int_{0}^{\infty} \frac{\sqrt{2} \left( e^{-2vz - 2b\sinh(z)}\cos\left(\pi\left(\frac{1}{4} + v\right)\right) + e^{2vz - 2b\sinh(z)}\sin\left(\pi\left(\frac{1}{4} + v\right)\right) \right)}{\sqrt{e^z - e^{-z}}} \, \mathrm{d}z $$ Going through Desmos, the function does converge. $f(z)$ , the integrand, is holomorphic in its domain, and the limits at $+\infty$ and $-\infty$ give me zero as long as $v \in \mathbb{R}$ and $\text{Re}(b) > 0$ . Edit : As FShrike had mentioned, there's a branch cut at $0$ . This is the reason for the keyhole contour. For further context, see the comments. I wanted to also first show the Proof of Convergence from Desmos and two interesting cases of the integral. $$\\$$ Case 1: If I have $I(b)$ equal to the integral and vary $v$ , I get close similarities to the Modified Bessel Function of the Second Kind. $$\\$$ Case 2: If I have $I(v)$ equal to the integral, and vary $b$ , the graph and its properites can be seen below. $\\$ I also wanted to provide an alternative contour that might work as well. After realization, there's a branch cut at $z=i\pi$ as well. Also, as I tested equivalencies for the bounds of the integral, I got these odd results: Note : This might not be necessary but may aid in a solution, here's how the integral behaves under various values of $v$ and $b$ Question: If stated correctly, the contour integral evaluates to 0 due to Cauchy's Integral Theorem. However, the path integrals of the contour would have to be evaluated. How would you evaluate the path integrals and evaluate the integral with the given notes above? $$ \oint_{c} \frac{{\sqrt{2} \times (e^{-2vz - 2b\sinh(z)}\cos(\pi(1/4 + v)) + e^{2vz - 2b\sinh(z)}\sin(\pi(1/4 + v)))}}{{\sqrt{e^z - e^{-z}}}} \, dz $$ Using the contour $$ \oint_c = \lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right) $$ And with what I had stated: $$ 0 =\lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right) $$ Please excuse my drawing as I am not an artist, Keyhole Contour: Choosen Contour Alternative Contour Progress Made $$ \lim_{{R \to \infty \atop \epsilon \to 0}} \left(\int_{-R}^{-\epsilon} + \int_{\epsilon}^{R}\right)$$ $\\$ Which is equal to: $\int_{-\infty}^{0} + I$ . And in connection to my notes: $I=-\int_{-\infty}^{0} f(z) dz$ . Now, things get messy, so I'll keep it concise. $\\$ Evaluating: $\int_{-\infty}^{0} f(z) \, dz$ $\\$ First I made the substitution $ w = e^{z},dw = e^{z} \, dz $ . $$\int_{-\infty}^{\infty} \frac{e^{b(1/w-w)}w^{-1-2v}\left(\cos \left(\pi \left(\frac{1}{4}+v\right)\right)+w^{4v}\sin \left(\pi \left(\frac{1}{4}+v\right)\right) \right)}{\sqrt{-\frac{1}{w}+w}} dw $$ Distribute the $\pi$ , use the sum and difference formulas for $\cos$ and $\sin$ , and distribute throughout. Next I factor out $\frac{\sqrt{2}}{2}$ which cancels out At this point, the integral is: $$ \int_{-\infty}^{\infty} \frac{\left(e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\cos(\pi v) - e^{-bw + \frac{b}{w}} w^{(2v - 1)}\cos(\pi v)\right) + \left(-e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\sin(\pi v) + e^{-bw + \frac{b}{w}} w^{(2v - 1)}\sin(\pi v)\right)}{\sqrt{w - w^{-1}}} \, dw$$ Split into two fractions, $$I_{1} = \int_{-\infty}^{\infty} \frac{\cos(\pi v) e^{-bw + \frac{b}{w}} (w^{-1 - 2v} - w^{2v - 1})}{\sqrt{w - w^{-1}}} dw$$ And, $$I_{2}=\int_{-\infty}^{\infty}\frac{\sin\left(\pi v\right)e^{-bw+\frac{b}{w}}\left(w^{\left(-1-2v\right)}+w^{\left(2v-1\right)}\right)}{\sqrt{w-w^{-1}}}dw$$ Therefore, $I=-(I_1+I_2)$ I have also assumed both path integrals evaluate to zero. However, I'm uncertain.","Going through Desmos, the function does converge. , the integrand, is holomorphic in its domain, and the limits at and give me zero as long as and . Edit : As FShrike had mentioned, there's a branch cut at . This is the reason for the keyhole contour. For further context, see the comments. I wanted to also first show the Proof of Convergence from Desmos and two interesting cases of the integral. Case 1: If I have equal to the integral and vary , I get close similarities to the Modified Bessel Function of the Second Kind. Case 2: If I have equal to the integral, and vary , the graph and its properites can be seen below. I also wanted to provide an alternative contour that might work as well. After realization, there's a branch cut at as well. Also, as I tested equivalencies for the bounds of the integral, I got these odd results: Note : This might not be necessary but may aid in a solution, here's how the integral behaves under various values of and Question: If stated correctly, the contour integral evaluates to 0 due to Cauchy's Integral Theorem. However, the path integrals of the contour would have to be evaluated. How would you evaluate the path integrals and evaluate the integral with the given notes above? Using the contour And with what I had stated: Please excuse my drawing as I am not an artist, Keyhole Contour: Choosen Contour Alternative Contour Progress Made Which is equal to: . And in connection to my notes: . Now, things get messy, so I'll keep it concise. Evaluating: First I made the substitution . Distribute the , use the sum and difference formulas for and , and distribute throughout. Next I factor out which cancels out At this point, the integral is: Split into two fractions, And, Therefore, I have also assumed both path integrals evaluate to zero. However, I'm uncertain."," I = \int_{0}^{\infty} \frac{\sqrt{2} \left( e^{-2vz - 2b\sinh(z)}\cos\left(\pi\left(\frac{1}{4} + v\right)\right) + e^{2vz - 2b\sinh(z)}\sin\left(\pi\left(\frac{1}{4} + v\right)\right) \right)}{\sqrt{e^z - e^{-z}}} \, \mathrm{d}z  f(z) +\infty -\infty v \in \mathbb{R} \text{Re}(b) > 0 0 \\ I(b) v \\ I(v) b \\ z=i\pi v b 
\oint_{c} \frac{{\sqrt{2} \times (e^{-2vz - 2b\sinh(z)}\cos(\pi(1/4 + v)) + e^{2vz - 2b\sinh(z)}\sin(\pi(1/4 + v)))}}{{\sqrt{e^z - e^{-z}}}} \, dz
 
\oint_c = \lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right)   0 =\lim_{{R \to \infty, \epsilon \to 0}} \left( \int_{\Gamma} + \int_{-R}^{-\epsilon} + \int_{\psi} + \int_{\epsilon}^{R} \right)  
\lim_{{R \to \infty \atop \epsilon \to 0}} \left(\int_{-R}^{-\epsilon} + \int_{\epsilon}^{R}\right) \\ \int_{-\infty}^{0} + I I=-\int_{-\infty}^{0} f(z) dz \\ \int_{-\infty}^{0} f(z) \, dz \\  w = e^{z},dw = e^{z} \, dz  \int_{-\infty}^{\infty} \frac{e^{b(1/w-w)}w^{-1-2v}\left(\cos \left(\pi \left(\frac{1}{4}+v\right)\right)+w^{4v}\sin \left(\pi \left(\frac{1}{4}+v\right)\right) \right)}{\sqrt{-\frac{1}{w}+w}} dw  \pi \cos \sin \frac{\sqrt{2}}{2} 
\int_{-\infty}^{\infty} \frac{\left(e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\cos(\pi v) - e^{-bw + \frac{b}{w}} w^{(2v - 1)}\cos(\pi v)\right) + \left(-e^{-bw + \frac{b}{w}} w^{(-1 - 2v)}\sin(\pi v) + e^{-bw + \frac{b}{w}} w^{(2v - 1)}\sin(\pi v)\right)}{\sqrt{w - w^{-1}}} \, dw I_{1} = \int_{-\infty}^{\infty} \frac{\cos(\pi v) e^{-bw + \frac{b}{w}} (w^{-1 - 2v} - w^{2v - 1})}{\sqrt{w - w^{-1}}} dw I_{2}=\int_{-\infty}^{\infty}\frac{\sin\left(\pi v\right)e^{-bw+\frac{b}{w}}\left(w^{\left(-1-2v\right)}+w^{\left(2v-1\right)}\right)}{\sqrt{w-w^{-1}}}dw I=-(I_1+I_2)","['calculus', 'integration', 'complex-analysis', 'contour-integration']"
96,Residue of $\dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z}$ at $z=0$,Residue of  at,\dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z} z=0,"I know that $\dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z}$ has an essential singularity at $z=0$ . Now I don't know how to find the residue of a function with an essential singularity. I tried: \begin{align} \dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z}&=(1+z+\frac{z^2}{2!}+\frac{z^3}{3!}+\frac{z^4}{4!}+...)\cdot (\frac{1}{z^2}-\frac{1}{3!}\cdot \frac{1}{z^4}+\frac{1}{5!}\cdot \frac{1}{z^6}-\frac{1}{7!}\cdot \frac{1}{z^8}+...)=\\\\  &=...+\frac{1}{z}\cdot(\sum_{k=0}^{\infty} \frac{(-1)^k}{((2k+1)!)^2})+... \end{align} So my residue would be $\sum_{k=0}^{\infty} \frac{(-1)^k}{((2k+1)!)^2}$ . This series obviously converges, but I can't calculate it's value. So I think that there is an easier way to find the residue?","I know that has an essential singularity at . Now I don't know how to find the residue of a function with an essential singularity. I tried: So my residue would be . This series obviously converges, but I can't calculate it's value. So I think that there is an easier way to find the residue?","\dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z} z=0 \begin{align}
\dfrac{\mathbb{e}^z \sin(\frac{1}{z})}{z}&=(1+z+\frac{z^2}{2!}+\frac{z^3}{3!}+\frac{z^4}{4!}+...)\cdot (\frac{1}{z^2}-\frac{1}{3!}\cdot \frac{1}{z^4}+\frac{1}{5!}\cdot \frac{1}{z^6}-\frac{1}{7!}\cdot \frac{1}{z^8}+...)=\\\\ 
&=...+\frac{1}{z}\cdot(\sum_{k=0}^{\infty} \frac{(-1)^k}{((2k+1)!)^2})+...
\end{align} \sum_{k=0}^{\infty} \frac{(-1)^k}{((2k+1)!)^2}","['complex-analysis', 'residue-calculus']"
97,Approximating $\sqrt{x}$ by a rational function in the complex plane,Approximating  by a rational function in the complex plane,\sqrt{x},"Newman (1963) proved the following. Theorem 1. Let $d \in \mathbb{N}$ . Define $$p(x) = \prod_{k=0}^{d-1} \left(x+\exp\left(\frac{-k}{\sqrt{d}}\right)\right)$$ and $$r(x) = \frac{\sqrt{x} \cdot (p(\sqrt{x}) - p(-\sqrt{x}))}{p(\sqrt{x}) + p(-\sqrt{x})}.$$ Then $r(x)$ is a rational function of degree $\lceil d/2 \rceil$ with real coefficients. (Specifically, $r(x)$ is the ratio where the numerator is a polynomial in $x$ of degree $\lceil d/2 \rceil$ and the denominator is a polynomial in $x$ of degree $\lfloor d/2 \rfloor$ .) Furthermore, $$\sup_{x \in [0,1]} |r(x)-\sqrt{x}| \le 3 \cdot \exp(-\sqrt{d}).$$ Subsequent work has obtained optimal constants and generalized to powers other than the square root;  see Stahl (1993) and references therein. I'm interested in extending to the complex plane. I.e., rather than $x \in [0,1]$ , I want the approximation guarantee to hold for all $x \in \mathbb{C}$ with $|x-\frac12|\le\frac12$ . The following gives a specific strong conjecture. Conjecture 2. There exists a universal constant $c>0$ such that the following holds. Let $d \in \mathbb{N}$ .  There exists a rational function $r(x)$ of degree $\le d$ with real coefficients such that $$\sup \left\{ \left| r(x) - \sqrt{x} \right| :  x \in \mathbb{C}, \left|x-\frac12\right|\le\frac12 \right\} \le \exp(-c \cdot \sqrt{d} +1/c).$$ (Some technicalities: Implicit in Conjecture 2's conclusion is that $r(x)$ has no poles with $|x-\frac12|\le\frac12$ . We take the principal branch of the square root so that it matches Newman's result on the positive real interval $[0,1]$ and the square root is continuous in the region of interest, since the branch cut is on the negative real axis.) Numerically, it seems that Newman's construction works on the complex plane without modification. Here is a plot of the error as we go around the boundary of the disc for varying degree. Here is a plot showing that the error is maximal at the boundary. That is, we vary the radius of the circle centered at $\frac12$ and compute the maximum error on that circle. Finally, here is a plot showing how the error decreases with degree. This seems consistent with $\exp(-c\sqrt{d})$ asymptotic error. For my application, it would suffice to prove something weaker than Conjecture 2 above. In particular, we can shrink the disc slightly, as in Conjecture 3 below. It would also suffice to prove some kind of weighted average error bound. But the statement becomes messy, so I'll leave it at this. Conjecture 3. There exists a universal constant $c>0$ such that the following holds. Let $d \in \mathbb{N}$ .  There exists a rational function $r(x)$ of degree $\le d$ with real coeficients such that $$\sup \left\{ \left| r(x) - \sqrt{x} \right| :  x \in \mathbb{C}, \left|x-\frac12\right|\le\frac12-\varepsilon \right\} \le \varepsilon,$$ where $\varepsilon = \exp(-c \cdot \sqrt{d} +1/c)$ . This seems like a question that should have been studied.  Any pointers or suggestions would be greatly appreciated.","Newman (1963) proved the following. Theorem 1. Let . Define and Then is a rational function of degree with real coefficients. (Specifically, is the ratio where the numerator is a polynomial in of degree and the denominator is a polynomial in of degree .) Furthermore, Subsequent work has obtained optimal constants and generalized to powers other than the square root;  see Stahl (1993) and references therein. I'm interested in extending to the complex plane. I.e., rather than , I want the approximation guarantee to hold for all with . The following gives a specific strong conjecture. Conjecture 2. There exists a universal constant such that the following holds. Let .  There exists a rational function of degree with real coefficients such that (Some technicalities: Implicit in Conjecture 2's conclusion is that has no poles with . We take the principal branch of the square root so that it matches Newman's result on the positive real interval and the square root is continuous in the region of interest, since the branch cut is on the negative real axis.) Numerically, it seems that Newman's construction works on the complex plane without modification. Here is a plot of the error as we go around the boundary of the disc for varying degree. Here is a plot showing that the error is maximal at the boundary. That is, we vary the radius of the circle centered at and compute the maximum error on that circle. Finally, here is a plot showing how the error decreases with degree. This seems consistent with asymptotic error. For my application, it would suffice to prove something weaker than Conjecture 2 above. In particular, we can shrink the disc slightly, as in Conjecture 3 below. It would also suffice to prove some kind of weighted average error bound. But the statement becomes messy, so I'll leave it at this. Conjecture 3. There exists a universal constant such that the following holds. Let .  There exists a rational function of degree with real coeficients such that where . This seems like a question that should have been studied.  Any pointers or suggestions would be greatly appreciated.","d \in \mathbb{N} p(x) = \prod_{k=0}^{d-1} \left(x+\exp\left(\frac{-k}{\sqrt{d}}\right)\right) r(x) = \frac{\sqrt{x} \cdot (p(\sqrt{x}) - p(-\sqrt{x}))}{p(\sqrt{x}) + p(-\sqrt{x})}. r(x) \lceil d/2 \rceil r(x) x \lceil d/2 \rceil x \lfloor d/2 \rfloor \sup_{x \in [0,1]} |r(x)-\sqrt{x}| \le 3 \cdot \exp(-\sqrt{d}). x \in [0,1] x \in \mathbb{C} |x-\frac12|\le\frac12 c>0 d \in \mathbb{N} r(x) \le d \sup \left\{ \left| r(x) - \sqrt{x} \right| :  x \in \mathbb{C}, \left|x-\frac12\right|\le\frac12 \right\} \le \exp(-c \cdot \sqrt{d} +1/c). r(x) |x-\frac12|\le\frac12 [0,1] \frac12 \exp(-c\sqrt{d}) c>0 d \in \mathbb{N} r(x) \le d \sup \left\{ \left| r(x) - \sqrt{x} \right| :  x \in \mathbb{C}, \left|x-\frac12\right|\le\frac12-\varepsilon \right\} \le \varepsilon, \varepsilon = \exp(-c \cdot \sqrt{d} +1/c)","['complex-analysis', 'radicals', 'rational-functions', 'approximation-theory']"
98,Bypassing a singularity at the zero-frequency in a numerical integral,Bypassing a singularity at the zero-frequency in a numerical integral,,"I am attempting to implement a model outlined in this paper: General magnetostatic shape–shape interactions Background This model allows the calculation of magnetostatic interaction energies between objects of arbitrary shape. I am trying to numerically evaluate the integral shown here: $$E_m=\dfrac{\overline{K}_d}{4\pi^3}\Re\left[\int d^3\mathbf{k} D_1(\mathbf{k})D_1^*(\mathbf{k})\times (\mathbf{\hat{m}_{1}}\cdot \mathbf{\hat{k}}) (\mathbf{\hat{m}_{2}}\cdot \mathbf{\hat{k}})e^{i\mathbf{k}\cdot\mathbf{\rho}}\right]$$ Part of the computation involves the computation of unit vectors in reciprocal space: $$\mathbf{\hat{k}}= \dfrac{[k_x,k_y,k_z]}{\sqrt{k_x^2+k_y^2+k_z^2}}= \dfrac{[k_x,k_y,k_z]}{k}$$ Where $k_\alpha$ is a frequency in the $x$ , $y$ , or $z$ axis. These vectors are grouped in way that you are left with factors like this in the final expression: $\dfrac{k_x k_z}{k^2}$ or $\dfrac{k_y k_y}{k^2}$ These create singularities at $k=0$ which must be bypassed to complete the numerical calculation. Question When I try to evaluate the limit (naively with L'Hopital's rule), I find as $\mathbf{k}$ tends to zero for $\dfrac{1}{k^2}$ or $\dfrac{k_x k_z}{k^2}$ , the limit is zero or undefined depending on case. That doesn't seem right, because the $k=0$ term corresponds to the large, DC value of $D(\mathbf{k})$ , and that shouldn't simply be zeroed or ignored. A colleague suggested I read into ""numerical inverse laplacians"" but I wasn't able to find anything that seemed relevant. How can this singularity be bypassed? Any help is greatly appreciated.","I am attempting to implement a model outlined in this paper: General magnetostatic shape–shape interactions Background This model allows the calculation of magnetostatic interaction energies between objects of arbitrary shape. I am trying to numerically evaluate the integral shown here: Part of the computation involves the computation of unit vectors in reciprocal space: Where is a frequency in the , , or axis. These vectors are grouped in way that you are left with factors like this in the final expression: or These create singularities at which must be bypassed to complete the numerical calculation. Question When I try to evaluate the limit (naively with L'Hopital's rule), I find as tends to zero for or , the limit is zero or undefined depending on case. That doesn't seem right, because the term corresponds to the large, DC value of , and that shouldn't simply be zeroed or ignored. A colleague suggested I read into ""numerical inverse laplacians"" but I wasn't able to find anything that seemed relevant. How can this singularity be bypassed? Any help is greatly appreciated.","E_m=\dfrac{\overline{K}_d}{4\pi^3}\Re\left[\int d^3\mathbf{k} D_1(\mathbf{k})D_1^*(\mathbf{k})\times (\mathbf{\hat{m}_{1}}\cdot \mathbf{\hat{k}}) (\mathbf{\hat{m}_{2}}\cdot \mathbf{\hat{k}})e^{i\mathbf{k}\cdot\mathbf{\rho}}\right] \mathbf{\hat{k}}= \dfrac{[k_x,k_y,k_z]}{\sqrt{k_x^2+k_y^2+k_z^2}}= \dfrac{[k_x,k_y,k_z]}{k} k_\alpha x y z \dfrac{k_x k_z}{k^2} \dfrac{k_y k_y}{k^2} k=0 \mathbf{k} \dfrac{1}{k^2} \dfrac{k_x k_z}{k^2} k=0 D(\mathbf{k})","['complex-analysis', 'numerical-methods', 'fourier-transform', 'singularity', 'singularity-theory']"
99,Characterizing smooth functions in polar coordinates,Characterizing smooth functions in polar coordinates,,"This is a question about representing smooth functions in polar coordinates. I'll write $\mathbb{C}$ for the complex plane with coordinates denoted interchangeably by $z=x+iy=(x,y)$ . Meanwhile, I'll write $\mathbb{R}^2$ for the $(r,\theta)$ -plane. I'll give a bit of a lengthy preamble, but you are welcome to scroll down for the question. I titled it in bold. OK, let's suppose $f:\mathbb{C}\to\mathbb{C}$ is a $C^\infty$ smooth function. Correspondingly, we get a $C^\infty$ smooth function $g:\mathbb{R}^2 \to \mathbb{C}$ defined by $g(r,\theta)=f(re^{i\theta})$ . Let's ask ourselves the question ""what kind of smooth functions $g$ can arise this way?"". Clearly it's not all of them. For one thing, $g(0,\theta)=f(0)$ for all $\theta$ . Another thing: $g$ is $2\pi$ -periodic in the $\theta$ variable [ Correction: actually it must satisfy the stronger symmetry condition $g(r,\theta)=g(-r,\theta+\pi)$ ]. But is that the whole story? No it is not. We also have to account for infinitesimal behaviour. For example, it is quite easy to check that $$ g_r(0,\theta) =  f_x(0) \cos \theta +  f_y(0) \sin \theta,$$ $$g_{rr}(0,\theta) = f_{xx}(0)\cos^2 \theta  + 2f_{xy}(0)\cos\theta \sin\theta +f_{yy}(0) \sin^2 \theta $$ and so on,  using subscript shorthand for partial derivatives. OK, so it seems that the $r$ partial derivatives of $g$ are forced to have very particular forms along the $\theta$ -axis. What is really going on here? How can we formalize this and understand better what exactly the restriction on $g$ is? Here is my attempt to make sense of things. We have a usual Taylor expansion for $f$ at the origin: $$ f(x,y) \sim \sum_{m,n \geq 0} a_{m,n} x^m y^n.$$ That is not too helpful for understanding what's going on with $g$ .  However, I believe it should also make sense (and be equivalent) to talk about the Taylor expansion of $f$ in the variables $z=x+iy$ and $\overline z = x-iy$ : $$ f(x,y) \sim \sum_{m,n \geq 0} b_{m,n} z^m \overline z^n.$$ I guess that, into this expansion, we can directly substitute $z=re^{i\theta}$ , $\overline z=re^{-i\theta}$ to obtain: $$g(r,\theta) \sim \sum_{m,n \geq 0} b_{m,n} r^{m+n} e^{i(m-n)\theta}$$ where this should be thought of as a kind of asymptotic expansion along the $\theta$ -axis,  as $r \to 0$ . We could also rewrite this as: $$g(r,\theta) \sim \sum_{n \geq 0}  p_n(e^{i\theta}) r^n$$ where $p_n$ is a polynomial of the form $p_n(u) = \sum_{m=0}^n c_{m,n} u^{n-2m}$ . The above is all to sketch a proof of the following claim. Claim: If $f(x+iy)$ smooth function $\mathbb{C} \to \mathbb{C}$ , then  the function $g(r,\theta)=f(re^{i\theta})$ has the property $\frac{\partial^n}{\partial r^n} g(0,\theta) = p_n(e^{i\theta})$ where $p_n(u) = \sum_{m=0}^n c_{m,n} u^{n-2m}$ where all the $c_{m,n}\in\mathbb{C}$ . OK, so now we have a pretty good idea of what the restriction should be and the question is: Question: Does the converse hold? If $g(r,\theta)$ is a smooth function with the property in the claim above that is also $2\pi$ -periodic in $\theta$ (and constant on the $\theta$ -axis), does it follow that $g(r,\theta)=f(re^{i\theta})$ for some smooth function $f:\mathbb{C}\to\mathbb{C}$ ? Assuming the answer is ""yes"", I would be happy to be pointed to a reference. I'm not overly concerned with seeing a proof, just wanted some reinforcement that this is correct. I can somewhat imagine how this might go even. Given such a function $g$ , I suppose we can subtract off a function $h(re^{i\theta})$ with the same expansion as $g$ along the $\theta$ axis using Borel's theorem. Then we have a $g$ with an identically vanishing expansion and the problem becomes to show under that assumption that we can push it forward to a smooth function while keeping it smooth which sounds pretty believable to me. Also welcome would be a nice rephrasing of what I've written in better language! I feel like I should be trying to package this more in terms of harmonic analysis or representation theory, but I'll leave it in the above form for now. Thanks for reading this long rambling question! Added 13/Aug/2023 Two things to add: Firstly, it should be pointed out that I missed a necessary condition above. Given $f(x,y)$ smooth, the corresponding $g(r,\theta) =f(re^{i \theta})$ is clearly not simply $2\pi$ -periodic in $\theta$ , but actually satisfies the stronger symmetry condition $g(-r,\theta+\pi) = g(r,\theta)$ of which $2\pi$ -periodicity in $\theta$ is a consequence. Secondly, here is a bit more information about pushing forward a given smooth function $g(r,\theta)$ that satisfies the symmetry condition $g(-r,\theta+\pi) = g(r,\theta)$ and vanishes to infinite order along $r=0$ . Let me write $T(r,\theta)=re^{i\theta}$ for the polar coordinates transformation, which is a local diffeomorphism away from $r=0$ .  Note that $\frac{\partial}{\partial x}$ and $\frac{\partial}{\partial_y}$ pull back under $T$ to mercifully nice operators vector fields. Specifically: \begin{align*} T^*(\frac{\partial}{\partial x}) = \cos \theta \frac{\partial}{\partial r} - \frac{\sin \theta}{r} \frac{\partial}{\partial \theta} && T^*(\frac{\partial}{\partial y}) = \sin \theta \frac{\partial}{\partial r} + \frac{\cos \theta}{r} \frac{\partial}{\partial \theta} \end{align*} From the symmetry condition alone, it follows that there is a unique function $f$ such that $g=f \circ T$ . The problem is smoothness of $f$ . Firstly, clearly $f$ is $C^\infty$ away the origin (where $T$ is a local diffeomorphism). It is also clear that $f$ vanishes to infinite order at the origin, in the sense that it vanishes faster than any power of $r$ . This already implies that $f$ is differentiable at $0$ with vanishing Jacobian. On the other hand, from the above pullback formulas, it can be seen that the first order partials of $f$ are the pushforwards of functions in the same class as $g$ (vanishing to infinite order on $r=0$ and with the same symmetry condition). So, by induction, all the partial derivatives of $f$ exist and vanish at the origin.","This is a question about representing smooth functions in polar coordinates. I'll write for the complex plane with coordinates denoted interchangeably by . Meanwhile, I'll write for the -plane. I'll give a bit of a lengthy preamble, but you are welcome to scroll down for the question. I titled it in bold. OK, let's suppose is a smooth function. Correspondingly, we get a smooth function defined by . Let's ask ourselves the question ""what kind of smooth functions can arise this way?"". Clearly it's not all of them. For one thing, for all . Another thing: is -periodic in the variable [ Correction: actually it must satisfy the stronger symmetry condition ]. But is that the whole story? No it is not. We also have to account for infinitesimal behaviour. For example, it is quite easy to check that and so on,  using subscript shorthand for partial derivatives. OK, so it seems that the partial derivatives of are forced to have very particular forms along the -axis. What is really going on here? How can we formalize this and understand better what exactly the restriction on is? Here is my attempt to make sense of things. We have a usual Taylor expansion for at the origin: That is not too helpful for understanding what's going on with .  However, I believe it should also make sense (and be equivalent) to talk about the Taylor expansion of in the variables and : I guess that, into this expansion, we can directly substitute , to obtain: where this should be thought of as a kind of asymptotic expansion along the -axis,  as . We could also rewrite this as: where is a polynomial of the form . The above is all to sketch a proof of the following claim. Claim: If smooth function , then  the function has the property where where all the . OK, so now we have a pretty good idea of what the restriction should be and the question is: Question: Does the converse hold? If is a smooth function with the property in the claim above that is also -periodic in (and constant on the -axis), does it follow that for some smooth function ? Assuming the answer is ""yes"", I would be happy to be pointed to a reference. I'm not overly concerned with seeing a proof, just wanted some reinforcement that this is correct. I can somewhat imagine how this might go even. Given such a function , I suppose we can subtract off a function with the same expansion as along the axis using Borel's theorem. Then we have a with an identically vanishing expansion and the problem becomes to show under that assumption that we can push it forward to a smooth function while keeping it smooth which sounds pretty believable to me. Also welcome would be a nice rephrasing of what I've written in better language! I feel like I should be trying to package this more in terms of harmonic analysis or representation theory, but I'll leave it in the above form for now. Thanks for reading this long rambling question! Added 13/Aug/2023 Two things to add: Firstly, it should be pointed out that I missed a necessary condition above. Given smooth, the corresponding is clearly not simply -periodic in , but actually satisfies the stronger symmetry condition of which -periodicity in is a consequence. Secondly, here is a bit more information about pushing forward a given smooth function that satisfies the symmetry condition and vanishes to infinite order along . Let me write for the polar coordinates transformation, which is a local diffeomorphism away from .  Note that and pull back under to mercifully nice operators vector fields. Specifically: From the symmetry condition alone, it follows that there is a unique function such that . The problem is smoothness of . Firstly, clearly is away the origin (where is a local diffeomorphism). It is also clear that vanishes to infinite order at the origin, in the sense that it vanishes faster than any power of . This already implies that is differentiable at with vanishing Jacobian. On the other hand, from the above pullback formulas, it can be seen that the first order partials of are the pushforwards of functions in the same class as (vanishing to infinite order on and with the same symmetry condition). So, by induction, all the partial derivatives of exist and vanish at the origin.","\mathbb{C} z=x+iy=(x,y) \mathbb{R}^2 (r,\theta) f:\mathbb{C}\to\mathbb{C} C^\infty C^\infty g:\mathbb{R}^2 \to \mathbb{C} g(r,\theta)=f(re^{i\theta}) g g(0,\theta)=f(0) \theta g 2\pi \theta g(r,\theta)=g(-r,\theta+\pi)  g_r(0,\theta) =  f_x(0) \cos \theta +  f_y(0) \sin \theta, g_{rr}(0,\theta) = f_{xx}(0)\cos^2 \theta  + 2f_{xy}(0)\cos\theta \sin\theta +f_{yy}(0) \sin^2 \theta  r g \theta g f  f(x,y) \sim \sum_{m,n \geq 0} a_{m,n} x^m y^n. g f z=x+iy \overline z = x-iy  f(x,y) \sim \sum_{m,n \geq 0} b_{m,n} z^m \overline z^n. z=re^{i\theta} \overline z=re^{-i\theta} g(r,\theta) \sim \sum_{m,n \geq 0} b_{m,n} r^{m+n} e^{i(m-n)\theta} \theta r \to 0 g(r,\theta) \sim \sum_{n \geq 0}  p_n(e^{i\theta}) r^n p_n p_n(u) = \sum_{m=0}^n c_{m,n} u^{n-2m} f(x+iy) \mathbb{C} \to \mathbb{C} g(r,\theta)=f(re^{i\theta}) \frac{\partial^n}{\partial r^n} g(0,\theta) = p_n(e^{i\theta}) p_n(u) = \sum_{m=0}^n c_{m,n} u^{n-2m} c_{m,n}\in\mathbb{C} g(r,\theta) 2\pi \theta \theta g(r,\theta)=f(re^{i\theta}) f:\mathbb{C}\to\mathbb{C} g h(re^{i\theta}) g \theta g f(x,y) g(r,\theta) =f(re^{i \theta}) 2\pi \theta g(-r,\theta+\pi) = g(r,\theta) 2\pi \theta g(r,\theta) g(-r,\theta+\pi) = g(r,\theta) r=0 T(r,\theta)=re^{i\theta} r=0 \frac{\partial}{\partial x} \frac{\partial}{\partial_y} T \begin{align*}
T^*(\frac{\partial}{\partial x}) = \cos \theta \frac{\partial}{\partial r} - \frac{\sin \theta}{r} \frac{\partial}{\partial \theta} &&
T^*(\frac{\partial}{\partial y}) = \sin \theta \frac{\partial}{\partial r} + \frac{\cos \theta}{r} \frac{\partial}{\partial \theta}
\end{align*} f g=f \circ T f f C^\infty T f r f 0 f g r=0 f","['complex-analysis', 'taylor-expansion', 'polar-coordinates', 'smooth-functions']"
